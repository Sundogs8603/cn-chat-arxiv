<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#39640;&#25928;&#30340;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#20934;&#30830;&#23398;&#20064;&#20855;&#26377;&#20219;&#24847;&#31934;&#24230;&#30340;&#33258;&#28982;&#21442;&#25968;&#30340;&#25351;&#25968;&#26063;&#20998;&#24067;&#12290;&#35813;&#20272;&#35745;&#22120;&#26159;&#19968;&#33268;&#30340;&#12289;&#28176;&#36817;&#27491;&#24577;&#30340;&#65292;&#24182;&#21487;&#35270;&#20026;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#37325;&#26032;&#21442;&#25968;&#21270;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2309.06413</link><description>&lt;p&gt;
&#35745;&#31639;&#26377;&#25928;&#23398;&#20064;&#25351;&#25968;&#26063;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
On Computationally Efficient Learning of Exponential Family Distributions. (arXiv:2309.06413v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06413
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#39640;&#25928;&#30340;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#20934;&#30830;&#23398;&#20064;&#20855;&#26377;&#20219;&#24847;&#31934;&#24230;&#30340;&#33258;&#28982;&#21442;&#25968;&#30340;&#25351;&#25968;&#26063;&#20998;&#24067;&#12290;&#35813;&#20272;&#35745;&#22120;&#26159;&#19968;&#33268;&#30340;&#12289;&#28176;&#36817;&#27491;&#24577;&#30340;&#65292;&#24182;&#21487;&#35270;&#20026;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#37325;&#26032;&#21442;&#25968;&#21270;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#32771;&#34385;&#20102;&#20197;&#35745;&#31639;&#21644;&#32479;&#35745;&#30340;&#39640;&#25928;&#26041;&#24335;&#65292;&#20934;&#30830;&#23398;&#20064;&#20855;&#26377;&#20219;&#24847;&#31934;&#24230;&#30340;&#33258;&#28982;&#21442;&#25968;&#30340;$k$&#21442;&#25968;&#25130;&#26029;\textit{&#26368;&#23567;}&#25351;&#25968;&#26063;&#20998;&#24067;&#12290;&#25105;&#20204;&#20851;&#27880;&#30340;&#26159;&#25903;&#25345;&#21644;&#33258;&#28982;&#21442;&#25968;&#36866;&#24403;&#26377;&#30028;&#30340;&#24773;&#20917;&#12290;&#34429;&#28982;&#20256;&#32479;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#23545;&#20110;&#36825;&#31867;&#25351;&#25968;&#26063;&#20998;&#24067;&#26159;&#19968;&#33268;&#30340;&#12289;&#28176;&#36817;&#27491;&#24577;&#30340;&#21644;&#28176;&#36817;&#26377;&#25928;&#30340;&#65292;&#20294;&#20854;&#35745;&#31639;&#22797;&#26434;&#24230;&#24456;&#39640;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#21644;&#35745;&#31639;&#39640;&#25928;&#30340;&#20272;&#35745;&#22120;&#65292;&#22312;&#28201;&#21644;&#26465;&#20214;&#19979;&#19968;&#33268;&#19988;&#28176;&#36817;&#27491;&#24577;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#24635;&#20307;&#27700;&#24179;&#19978;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#21516;&#19968;&#31867;&#25351;&#25968;&#26063;&#20998;&#24067;&#30340;&#21442;&#25968;&#21270;&#20998;&#24067;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#21487;&#20197;&#35299;&#37322;&#20026;&#26368;&#23567;&#21270;&#29305;&#23450;Bregman&#24471;&#20998;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the classical problem of learning, with arbitrary accuracy, the natural parameters of a $k$-parameter truncated \textit{minimal} exponential family from i.i.d. samples in a computationally and statistically efficient manner. We focus on the setting where the support as well as the natural parameters are appropriately bounded. While the traditional maximum likelihood estimator for this class of exponential family is consistent, asymptotically normal, and asymptotically efficient, evaluating it is computationally hard. In this work, we propose a novel loss function and a computationally efficient estimator that is consistent as well as asymptotically normal under mild conditions. We show that, at the population level, our method can be viewed as the maximum likelihood estimation of a re-parameterized distribution belonging to the same class of exponential family. Further, we show that our estimator can be interpreted as a solution to minimizing a particular Bregman score as w
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#23545;&#20351;&#29992;&#20998;&#25968;&#21518;&#39564;&#27010;&#29575;&#30340;&#27748;&#26222;&#26862;&#25277;&#26679;&#31639;&#27861;&#36827;&#34892;&#20102;&#24191;&#20041;&#36951;&#25022;&#20998;&#26512;&#65292;&#33719;&#24471;&#20102;&#20381;&#36182;&#20110;&#23454;&#20363;&#21644;&#23454;&#20363;&#29420;&#31435;&#30340;&#39057;&#29575;&#36951;&#25022;&#30028;&#12290;&#36825;&#23545;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#30340;&#35299;&#20915;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2309.06349</link><description>&lt;p&gt;
&#20351;&#29992;&#20998;&#25968;&#21518;&#39564;&#27010;&#29575;&#23545;&#27748;&#26222;&#26862;&#25277;&#26679;&#36827;&#34892;&#24191;&#20041;&#36951;&#25022;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Generalized Regret Analysis of Thompson Sampling using Fractional Posteriors. (arXiv:2309.06349v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06349
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#23545;&#20351;&#29992;&#20998;&#25968;&#21518;&#39564;&#27010;&#29575;&#30340;&#27748;&#26222;&#26862;&#25277;&#26679;&#31639;&#27861;&#36827;&#34892;&#20102;&#24191;&#20041;&#36951;&#25022;&#20998;&#26512;&#65292;&#33719;&#24471;&#20102;&#20381;&#36182;&#20110;&#23454;&#20363;&#21644;&#23454;&#20363;&#29420;&#31435;&#30340;&#39057;&#29575;&#36951;&#25022;&#30028;&#12290;&#36825;&#23545;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#30340;&#35299;&#20915;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27748;&#26222;&#26862;&#25277;&#26679;&#65288;TS&#65289;&#26159;&#35299;&#20915;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#30340;&#26368;&#27969;&#34892;&#21644;&#26368;&#26089;&#30340;&#31639;&#27861;&#20043;&#19968;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;TS&#30340;&#19968;&#20010;&#21464;&#31181;&#65292;&#31216;&#20026;&#945;-TS&#65292;&#20854;&#20013;&#25105;&#20204;&#20351;&#29992;&#20998;&#25968;&#25110;&#945;-&#21518;&#39564;&#65288;&#945;&#8712;&#65288;0,1&#65289;&#65289;&#20195;&#26367;&#26631;&#20934;&#21518;&#39564;&#20998;&#24067;&#12290;&#20026;&#20102;&#35745;&#31639;&#945;-&#21518;&#39564;&#65292;&#26631;&#20934;&#21518;&#39564;&#30340;&#23450;&#20041;&#20013;&#30340;&#20284;&#28982;&#20989;&#25968;&#34987;&#19968;&#20010;&#22240;&#23376;&#945;&#25605;&#25292;&#12290;&#23545;&#20110;&#945;-TS&#65292;&#25105;&#20204;&#22312;&#38750;&#24120;&#28201;&#21644;&#30340;&#20808;&#39564;&#21644;&#22870;&#21169;&#20998;&#24067;&#26465;&#20214;&#19979;&#33719;&#24471;&#20102;&#26082;&#20381;&#36182;&#20110;&#23454;&#20363;&#30340;&#927;&#65288;&#8721;_{k&#8800;i^*}&#916;_k&#65288;\frac{\log(T)}{C(&#945;)&#916;_k^2}+\frac{1}{2}&#65289;&#65289;&#20063;&#20381;&#36182;&#20110;&#23454;&#20363;&#29420;&#31435;&#30340;&#927;&#65288;\sqrt{KT\log K}&#65289;&#39057;&#29575;&#36951;&#25022;&#30028;&#65292;&#20854;&#20013;&#916;_k&#26159;&#31532;k&#20010;&#21644;&#26368;&#22909;&#30340;&#33218;&#30340;&#30495;&#23454;&#22343;&#20540;&#22870;&#21169;&#20043;&#38388;&#30340;&#24046;&#65292;&#32780;C(&#945;)&#26159;&#24050;&#30693;&#30340;&#24120;&#25968;&#12290;&#23376;&#39640;&#26031;&#21644;&#25351;&#25968;&#26063;&#27169;&#22411;&#37117;&#28385;&#36275;&#25105;&#20204;&#23545;&#22870;&#21169;&#20998;&#24067;&#30340;&#19968;&#33324;&#26465;&#20214;&#12290;&#25105;&#20204;&#23545;&#20808;&#39564;&#30340;&#26465;&#20214;&#26159;...
&lt;/p&gt;
&lt;p&gt;
Thompson sampling (TS) is one of the most popular and earliest algorithms to solve stochastic multi-armed bandit problems. We consider a variant of TS, named $\alpha$-TS, where we use a fractional or $\alpha$-posterior ($\alpha\in(0,1)$) instead of the standard posterior distribution. To compute an $\alpha$-posterior, the likelihood in the definition of the standard posterior is tempered with a factor $\alpha$. For $\alpha$-TS we obtain both instance-dependent $\mathcal{O}\left(\sum_{k \neq i^*} \Delta_k\left(\frac{\log(T)}{C(\alpha)\Delta_k^2} + \frac{1}{2} \right)\right)$ and instance-independent $\mathcal{O}(\sqrt{KT\log K})$ frequentist regret bounds under very mild conditions on the prior and reward distributions, where $\Delta_k$ is the gap between the true mean rewards of the $k^{th}$ and the best arms, and $C(\alpha)$ is a known constant. Both the sub-Gaussian and exponential family models satisfy our general conditions on the reward distribution. Our conditions on the prior di
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#22312;&#20844;&#20849;&#20132;&#36890;&#31995;&#32479;&#20013;&#24314;&#31435;&#20102;&#20379;&#38656;&#27169;&#22411;&#65292;&#21033;&#29992;&#25968;&#25454;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#25581;&#31034;&#20102;&#36816;&#33829;&#26381;&#21153;&#20013;&#30340;&#31354;&#32570;&#12290;</title><link>http://arxiv.org/abs/2309.06299</link><description>&lt;p&gt;
&#22312;&#20844;&#20849;&#20132;&#36890;&#31995;&#32479;&#20013;&#24314;&#27169;&#20379;&#38656;
&lt;/p&gt;
&lt;p&gt;
Modeling Supply and Demand in Public Transportation Systems. (arXiv:2309.06299v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06299
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#22312;&#20844;&#20849;&#20132;&#36890;&#31995;&#32479;&#20013;&#24314;&#31435;&#20102;&#20379;&#38656;&#27169;&#22411;&#65292;&#21033;&#29992;&#25968;&#25454;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#25581;&#31034;&#20102;&#36816;&#33829;&#26381;&#21153;&#20013;&#30340;&#31354;&#32570;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21704;&#37324;&#26862;&#22561;&#20844;&#20849;&#20132;&#36890;&#37096;&#38376;&#26088;&#22312;&#21033;&#29992;&#20854;&#25968;&#25454;&#25552;&#39640;&#36816;&#33829;&#25928;&#29575;&#21644;&#25928;&#26524;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#20004;&#20010;&#20379;&#38656;&#27169;&#22411;&#65292;&#24110;&#21161;&#37096;&#38376;&#35782;&#21035;&#26381;&#21153;&#20013;&#30340;&#31354;&#32570;&#12290;&#27169;&#22411;&#32771;&#34385;&#20102;&#35768;&#22810;&#21464;&#37327;&#65292;&#21253;&#25324;&#21704;&#37324;&#26862;&#22561;&#24066;&#21521;&#32852;&#37030;&#25919;&#24220;&#25253;&#21578;&#30340;&#26041;&#24335;&#20197;&#21450;&#26368;&#33030;&#24369;&#20154;&#21475;&#32858;&#38598;&#30340;&#21306;&#22495;&#12290;&#25105;&#20204;&#37319;&#29992;&#25968;&#25454;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#36827;&#34892;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Harrisonburg Department of Public Transportation (HDPT) aims to leverage their data to improve the efficiency and effectiveness of their operations. We construct two supply and demand models that help the department identify gaps in their service. The models take many variables into account, including the way that the HDPT reports to the federal government and the areas with the most vulnerable populations in Harrisonburg City. We employ data analysis and machine learning techniques to make our predictions.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#20219;&#21153;&#20013;&#22522;&#20110;&#26041;&#24046;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#24230;&#37327;&#30340;&#39564;&#35777;&#65292;&#21457;&#29616;&#19968;&#33268;&#24615;&#21644;&#36866;&#24212;&#24615;&#26159;&#20114;&#34917;&#30340;&#39564;&#35777;&#30446;&#26631;&#65292;&#24182;&#25552;&#20986;&#20102;&#36866;&#24212;&#24615;&#39564;&#35777;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.06240</link><description>&lt;p&gt;
&#19968;&#33268;&#24615;&#21644;&#36866;&#24212;&#24615;&#26159;&#39564;&#35777;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#20219;&#21153;&#20013;&#22522;&#20110;&#26041;&#24046;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#24230;&#37327;&#30340;&#20114;&#34917;&#30446;&#26631;
&lt;/p&gt;
&lt;p&gt;
Consistency and adaptivity are complementary targets for the validation of variance-based uncertainty quantification metrics in machine learning regression tasks. (arXiv:2309.06240v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06240
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#20219;&#21153;&#20013;&#22522;&#20110;&#26041;&#24046;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#24230;&#37327;&#30340;&#39564;&#35777;&#65292;&#21457;&#29616;&#19968;&#33268;&#24615;&#21644;&#36866;&#24212;&#24615;&#26159;&#20114;&#34917;&#30340;&#39564;&#35777;&#30446;&#26631;&#65292;&#24182;&#25552;&#20986;&#20102;&#36866;&#24212;&#24615;&#39564;&#35777;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26159;&#26448;&#26009;&#21644;&#21270;&#23398;&#31185;&#23398;&#20013;&#35768;&#22810;&#30740;&#31350;&#30340;&#28966;&#28857;&#12290;&#30446;&#21069;&#24050;&#32463;&#35748;&#35782;&#21040;&#24179;&#22343;&#26657;&#20934;&#26159;&#19981;&#36275;&#22815;&#30340;&#65292;&#22823;&#22810;&#25968;&#30740;&#31350;&#37117;&#20351;&#29992;&#39069;&#22806;&#30340;&#26041;&#27861;&#26469;&#27979;&#35797;&#26465;&#20214;&#26657;&#20934;&#65292;&#21363;&#19968;&#33268;&#24615;&#12290;&#19968;&#33268;&#24615;&#20027;&#35201;&#36890;&#36807;&#21487;&#38752;&#24615;&#22270;&#26469;&#35780;&#20272;&#12290;&#28982;&#32780;&#65292;&#38500;&#20102;&#24179;&#22343;&#26657;&#20934;&#20043;&#22806;&#36824;&#23384;&#22312;&#19968;&#31181;&#26041;&#27861;&#65292;&#21363;&#22522;&#20110;&#36755;&#20837;&#29305;&#24449;&#30340;&#26465;&#20214;&#26657;&#20934;&#65292;&#20063;&#23601;&#26159;&#36866;&#24212;&#24615;&#12290;&#23454;&#38469;&#19978;&#65292;&#36866;&#24212;&#24615;&#26159;ML-UQ&#26041;&#27861;&#30340;&#26368;&#32456;&#29992;&#25143;&#20851;&#27880;&#30340;&#20027;&#35201;&#38382;&#39064;&#65292;&#20182;&#20204;&#23547;&#27714;&#23545;&#29305;&#24449;&#31354;&#38388;&#20013;&#30340;&#20219;&#20309;&#28857;&#30340;&#39044;&#27979;&#21644;&#19981;&#30830;&#23450;&#24615;&#30340;&#21487;&#38752;&#24615;&#12290;&#26412;&#25991;&#26088;&#22312;&#23637;&#31034;&#19968;&#33268;&#24615;&#21644;&#36866;&#24212;&#24615;&#26159;&#20114;&#34917;&#30340;&#39564;&#35777;&#30446;&#26631;&#65292;&#24182;&#19988;&#22909;&#30340;&#19968;&#33268;&#24615;&#24182;&#19981;&#24847;&#21619;&#30528;&#22909;&#30340;&#36866;&#24212;&#24615;&#12290;&#25991;&#31456;&#25552;&#20986;&#24182;&#22312;&#19968;&#20010;&#20856;&#22411;&#31034;&#20363;&#19978;&#36827;&#34892;&#20102;&#36866;&#24212;&#24615;&#39564;&#35777;&#26041;&#27861;&#30340;&#35828;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reliable uncertainty quantification (UQ) in machine learning (ML) regression tasks is becoming the focus of many studies in materials and chemical science. It is now well understood that average calibration is insufficient, and most studies implement additional methods testing the conditional calibration with respect to uncertainty, i.e. consistency. Consistency is assessed mostly by so-called reliability diagrams. There exists however another way beyond average calibration, which is conditional calibration with respect to input features, i.e. adaptivity. In practice, adaptivity is the main concern of the final users of a ML-UQ method, seeking for the reliability of predictions and uncertainties for any point in features space. This article aims to show that consistency and adaptivity are complementary validation targets, and that a good consistency does not imply a good adaptivity. Adapted validation methods are proposed and illustrated on a representative example.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#39640;&#32500;&#21333;&#25351;&#25968;&#27169;&#22411;&#20013;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#30340;&#19968;&#33268;&#24615;&#21644;&#21487;&#25193;&#23637;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#24191;&#20041;&#20449;&#24687;&#20934;&#21017;&#26469;&#30830;&#23450;&#25903;&#25345;&#30340;&#22238;&#24402;&#31995;&#25968;&#22823;&#23567;&#65292;&#28040;&#38500;&#20102;&#27169;&#22411;&#36873;&#25321;&#30340;&#35843;&#20248;&#38656;&#27714;&#65292;&#24182;&#20855;&#26377;&#23376;&#38598;&#36873;&#25321;&#19968;&#33268;&#24615;&#21644;&#39640;&#27010;&#29575;&#19979;&#30340;&#29702;&#24819;&#23646;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.06230</link><description>&lt;p&gt;
&#21333;&#25351;&#25968;&#27169;&#22411;&#20013;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#30340;&#19968;&#33268;&#24615;&#21644;&#21487;&#25193;&#23637;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Consistent and Scalable Algorithm for Best Subset Selection in Single Index Models. (arXiv:2309.06230v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06230
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#39640;&#32500;&#21333;&#25351;&#25968;&#27169;&#22411;&#20013;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#30340;&#19968;&#33268;&#24615;&#21644;&#21487;&#25193;&#23637;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#24191;&#20041;&#20449;&#24687;&#20934;&#21017;&#26469;&#30830;&#23450;&#25903;&#25345;&#30340;&#22238;&#24402;&#31995;&#25968;&#22823;&#23567;&#65292;&#28040;&#38500;&#20102;&#27169;&#22411;&#36873;&#25321;&#30340;&#35843;&#20248;&#38656;&#27714;&#65292;&#24182;&#20855;&#26377;&#23376;&#38598;&#36873;&#25321;&#19968;&#33268;&#24615;&#21644;&#39640;&#27010;&#29575;&#19979;&#30340;&#29702;&#24819;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#25968;&#25454;&#30340;&#20998;&#26512;&#24341;&#21457;&#20102;&#23545;&#21333;&#25351;&#25968;&#27169;&#22411;&#65288;SIMs&#65289;&#21644;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#30340;&#22686;&#21152;&#20852;&#36259;&#12290;SIMs&#20026;&#39640;&#32500;&#25968;&#25454;&#25552;&#20379;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#21644;&#28789;&#27963;&#30340;&#24314;&#27169;&#26694;&#26550;&#65292;&#32780;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#26088;&#22312;&#20174;&#22823;&#37327;&#30340;&#39044;&#27979;&#22240;&#23376;&#20013;&#25214;&#21040;&#31232;&#30095;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#22312;&#39640;&#32500;&#27169;&#22411;&#20013;&#30340;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#34987;&#35748;&#20026;&#26159;&#35745;&#31639;&#19978;&#38590;&#20197;&#22788;&#29702;&#30340;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#20542;&#21521;&#20110;&#25918;&#23485;&#36873;&#25321;&#65292;&#20294;&#19981;&#33021;&#24471;&#21040;&#26368;&#20339;&#23376;&#38598;&#35299;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#31532;&#19968;&#20010;&#32463;&#36807;&#35777;&#26126;&#30340;&#38024;&#23545;&#39640;&#32500;SIMs&#20013;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#30340;&#21487;&#25193;&#23637;&#31639;&#27861;&#65292;&#30452;&#25509;&#35299;&#20915;&#20102;&#35745;&#31639;&#38590;&#39064;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#35299;&#20855;&#26377;&#23376;&#38598;&#36873;&#25321;&#19968;&#33268;&#24615;&#65292;&#24182;&#19988;&#20960;&#20046;&#32943;&#23450;&#20855;&#26377;&#29992;&#20110;&#21442;&#25968;&#20272;&#35745;&#30340;&#34394;&#25311;&#23646;&#24615;&#12290;&#35813;&#31639;&#27861;&#21253;&#25324;&#19968;&#20010;&#24191;&#20041;&#20449;&#24687;&#20934;&#21017;&#26469;&#30830;&#23450;&#22238;&#24402;&#31995;&#25968;&#30340;&#25903;&#25345;&#22823;&#23567;&#65292;&#28040;&#38500;&#27169;&#22411;&#36873;&#25321;&#35843;&#25972;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#20551;&#35774;&#35823;&#24046;&#20998;&#24067;&#25110;&#29305;&#23450;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Analysis of high-dimensional data has led to increased interest in both single index models (SIMs) and best subset selection. SIMs provide an interpretable and flexible modeling framework for high-dimensional data, while best subset selection aims to find a sparse model from a large set of predictors. However, best subset selection in high-dimensional models is known to be computationally intractable. Existing methods tend to relax the selection, but do not yield the best subset solution. In this paper, we directly tackle the intractability by proposing the first provably scalable algorithm for best subset selection in high-dimensional SIMs. Our algorithmic solution enjoys the subset selection consistency and has the oracle property with a high probability. The algorithm comprises a generalized information criterion to determine the support size of the regression coefficients, eliminating the model selection tuning. Moreover, our method does not assume an error distribution or a specif
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26657;&#20934;&#30340;Lipschitz&#36793;&#30028;&#35823;&#24046;&#65288;CLL&#65289;&#26469;&#25552;&#39640;&#35748;&#35777;&#40065;&#26834;&#24615;&#65292;&#36890;&#36807;&#35299;&#20915;&#36793;&#30028;&#35823;&#24046;&#19981;&#20250;&#26681;&#25454;&#25910;&#32553;&#30340;&#36755;&#20986;&#20998;&#24067;&#35843;&#25972;&#24809;&#32602;&#21644;&#26368;&#23567;&#21270;Lipschitz&#24120;&#25968;&#23548;&#33268;&#36807;&#24230;&#24179;&#28369;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.06166</link><description>&lt;p&gt;
&#20855;&#26377;&#24377;&#24615;&#25511;&#21046;&#21644;&#36739;&#22823;Lipschitz&#24120;&#25968;&#30340;&#35748;&#35777;&#40065;&#26834;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Certified Robust Models with Slack Control and Large Lipschitz Constants. (arXiv:2309.06166v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06166
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26657;&#20934;&#30340;Lipschitz&#36793;&#30028;&#35823;&#24046;&#65288;CLL&#65289;&#26469;&#25552;&#39640;&#35748;&#35777;&#40065;&#26834;&#24615;&#65292;&#36890;&#36807;&#35299;&#20915;&#36793;&#30028;&#35823;&#24046;&#19981;&#20250;&#26681;&#25454;&#25910;&#32553;&#30340;&#36755;&#20986;&#20998;&#24067;&#35843;&#25972;&#24809;&#32602;&#21644;&#26368;&#23567;&#21270;Lipschitz&#24120;&#25968;&#23548;&#33268;&#36807;&#24230;&#24179;&#28369;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#26368;&#36817;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#30446;&#21069;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;&#23398;&#20064;&#30340;&#27169;&#22411;&#20173;&#28982;&#23545;&#36755;&#20837;&#21464;&#21270;&#65292;&#22914;&#23545;&#25239;&#26679;&#26412;&#65292;&#38750;&#24120;&#23481;&#26131;&#21463;&#21040;&#25915;&#20987;&#12290;&#20026;&#20102;&#33719;&#24471;&#23545;&#36825;&#31181;&#25200;&#21160;&#30340;&#21487;&#35777;&#26126;&#30340;&#40065;&#26834;&#24615;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#32771;&#34385;&#20102;&#22522;&#20110;Lipschitz&#30340;&#27491;&#21017;&#21270;&#22120;&#25110;&#32422;&#26463;&#65292;&#21516;&#26102;&#22686;&#21152;&#20102;&#39044;&#27979;&#36793;&#30028;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#26679;&#20570;&#20250;&#26174;&#33879;&#38477;&#20302;&#20934;&#30830;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26657;&#20934;&#30340;Lipschitz&#36793;&#30028;&#35823;&#24046;&#65288;CLL&#65289;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#35299;&#20915;&#20004;&#20010;&#38382;&#39064;&#26469;&#25552;&#39640;&#35748;&#35777;&#40065;&#26834;&#24615;&#65306;&#39318;&#20808;&#65292;&#24120;&#29992;&#30340;&#36793;&#30028;&#35823;&#24046;&#19981;&#20250;&#26681;&#25454;&#25910;&#32553;&#30340;&#36755;&#20986;&#20998;&#24067;&#35843;&#25972;&#24809;&#32602;&#65292;&#36825;&#26159;&#30001;&#20110;&#26368;&#23567;&#21270;Lipschitz&#24120;&#25968;K&#25152;&#36896;&#25104;&#30340;&#12290;&#20854;&#27425;&#65292;&#26368;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#26368;&#23567;&#21270;K&#21487;&#20197;&#23548;&#33268;&#20915;&#31574;&#20989;&#25968;&#36807;&#24230;&#24179;&#28369;&#12290;&#36825;&#38480;&#21046;&#20102;&#27169;&#22411;&#30340;&#22797;&#26434;&#24615;&#65292;&#20174;&#32780;&#38477;&#20302;&#20102;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#30340;CLL&#36890;&#36807;&#26126;&#30830;&#26657;&#20934;&#25439;&#22833;&#19982;&#36793;&#30028;&#21644;Lipschitz&#24120;&#25968;&#30340;&#20851;&#31995;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20174;&#32780;&#30830;&#20445;&#27169;&#22411;&#20855;&#26377;&#36739;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite recent success, state-of-the-art learning-based models remain highly vulnerable to input changes such as adversarial examples. In order to obtain certifiable robustness against such perturbations, recent work considers Lipschitz-based regularizers or constraints while at the same time increasing prediction margin. Unfortunately, this comes at the cost of significantly decreased accuracy. In this paper, we propose a Calibrated Lipschitz-Margin Loss (CLL) that addresses this issue and improves certified robustness by tackling two problems: Firstly, commonly used margin losses do not adjust the penalties to the shrinking output distribution; caused by minimizing the Lipschitz constant $K$. Secondly, and most importantly, we observe that minimization of $K$ can lead to overly smooth decision functions. This limits the model's complexity and thus reduces accuracy. Our CLL addresses these issues by explicitly calibrating the loss w.r.t. margin and Lipschitz constant, thereby establis
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#35299;&#20915;&#27491;&#21017;&#31232;&#30095;&#36923;&#36753;&#22238;&#24402;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;$\ell_1$&#27491;&#21017;&#21270;&#31232;&#30095;&#36923;&#36753;&#22238;&#24402;&#21644;&#19968;&#20123;&#28385;&#36275;&#20808;&#20915;&#26465;&#20214;&#30340;&#38750;&#20984;&#24809;&#32602;&#27491;&#21017;&#21270;&#31232;&#30095;&#36923;&#36753;&#22238;&#24402;&#12290;&#32463;&#39564;&#23454;&#39564;&#34920;&#26126;&#65292;&#36825;&#20123;&#31639;&#27861;&#33021;&#22815;&#20197;&#36739;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#26377;&#25928;&#22320;&#36827;&#34892;&#20998;&#31867;&#21644;&#29305;&#24449;&#36873;&#25321;&#12290;</title><link>http://arxiv.org/abs/2309.05925</link><description>&lt;p&gt;
&#20851;&#20110;&#27491;&#21017;&#31232;&#30095;&#36923;&#36753;&#22238;&#24402;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Regularized Sparse Logistic Regression. (arXiv:2309.05925v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05925
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#35299;&#20915;&#27491;&#21017;&#31232;&#30095;&#36923;&#36753;&#22238;&#24402;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;$\ell_1$&#27491;&#21017;&#21270;&#31232;&#30095;&#36923;&#36753;&#22238;&#24402;&#21644;&#19968;&#20123;&#28385;&#36275;&#20808;&#20915;&#26465;&#20214;&#30340;&#38750;&#20984;&#24809;&#32602;&#27491;&#21017;&#21270;&#31232;&#30095;&#36923;&#36753;&#22238;&#24402;&#12290;&#32463;&#39564;&#23454;&#39564;&#34920;&#26126;&#65292;&#36825;&#20123;&#31639;&#27861;&#33021;&#22815;&#20197;&#36739;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#26377;&#25928;&#22320;&#36827;&#34892;&#20998;&#31867;&#21644;&#29305;&#24449;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#36923;&#36753;&#22238;&#24402;&#26088;&#22312;&#21516;&#26102;&#36827;&#34892;&#39640;&#32500;&#25968;&#25454;&#30340;&#20998;&#31867;&#21644;&#29305;&#24449;&#36873;&#25321;&#12290;&#34429;&#28982;&#26377;&#35768;&#22810;&#30740;&#31350;&#35299;&#20915;&#20102;$\ell_1$&#27491;&#21017;&#21270;&#36923;&#36753;&#22238;&#24402;&#38382;&#39064;&#65292;&#20294;&#23545;&#20110;&#19982;&#38750;&#20984;&#24809;&#32602;&#30456;&#20851;&#30340;&#31232;&#30095;&#36923;&#36753;&#22238;&#24402;&#35299;&#20915;&#26041;&#26696;&#24182;&#27809;&#26377;&#31561;&#37327;&#30340;&#25991;&#29486;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#35299;&#20915;$\ell_1$&#27491;&#21017;&#21270;&#31232;&#30095;&#36923;&#36753;&#22238;&#24402;&#21644;&#19968;&#20123;&#28385;&#36275;&#19968;&#23450;&#20808;&#20915;&#26465;&#20214;&#30340;&#38750;&#20984;&#24809;&#32602;&#27491;&#21017;&#21270;&#31232;&#30095;&#36923;&#36753;&#22238;&#24402;&#30340;&#26041;&#27861;&#65292;&#24182;&#37319;&#29992;&#31867;&#20284;&#30340;&#20248;&#21270;&#26694;&#26550;&#12290;&#22312;&#25552;&#20986;&#30340;&#20248;&#21270;&#26694;&#26550;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#19981;&#21516;&#30340;&#32447;&#25628;&#32034;&#20934;&#21017;&#26469;&#20445;&#35777;&#19981;&#21516;&#27491;&#21017;&#21270;&#39033;&#30340;&#33391;&#22909;&#25910;&#25947;&#24615;&#33021;&#12290;&#36890;&#36807;&#23545;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#30340;&#20108;&#20803;&#20998;&#31867;&#20219;&#21153;&#36827;&#34892;&#32463;&#39564;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#33021;&#22815;&#20197;&#36739;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#26377;&#25928;&#22320;&#36827;&#34892;&#20998;&#31867;&#21644;&#29305;&#24449;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse logistic regression aims to perform classification and feature selection simultaneously for high-dimensional data. Although many studies have been done to solve $\ell_1$-regularized logistic regression, there is no equivalently abundant literature about solving sparse logistic regression associated with nonconvex penalties. In this paper, we propose to solve $\ell_1$-regularized sparse logistic regression and some nonconvex penalties-regularized sparse logistic regression, when the nonconvex penalties satisfy some prerequisites, with similar optimization frameworks. In the proposed optimization frameworks, we utilize different line search criteria to guarantee good convergence performance for different regularization terms. Empirical experiments on binary classification tasks with real-world datasets demonstrate our proposed algorithms are capable of performing classification and feature selection effectively with a lower computational cost.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#27969;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#31216;&#20026;&#21453;&#24212;&#22352;&#26631;&#27969;&#65292;&#29992;&#20110;&#21457;&#29616;&#20998;&#23376;&#31995;&#32479;&#20302;&#32500;&#21160;&#21147;&#23398;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#20197;&#36830;&#32493;&#26102;&#38388;&#21644;&#31354;&#38388;&#20013;&#30340;&#21487;&#35757;&#32451;&#21644;&#21487;&#22788;&#29702;&#30340;&#26041;&#24335;&#36827;&#34892;&#27169;&#22411;&#31616;&#21270;&#65292;&#20135;&#29983;&#20934;&#30830;&#21644;&#21487;&#35299;&#37322;&#30340;&#20302;&#32500;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2309.05878</link><description>&lt;p&gt;
&#21453;&#24212;&#22352;&#26631;&#27969;&#22312;&#20998;&#23376;&#21160;&#21147;&#23398;&#27169;&#22411;&#31616;&#21270;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Reaction coordinate flows for model reduction of molecular kinetics. (arXiv:2309.05878v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05878
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#27969;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#31216;&#20026;&#21453;&#24212;&#22352;&#26631;&#27969;&#65292;&#29992;&#20110;&#21457;&#29616;&#20998;&#23376;&#31995;&#32479;&#20302;&#32500;&#21160;&#21147;&#23398;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#20197;&#36830;&#32493;&#26102;&#38388;&#21644;&#31354;&#38388;&#20013;&#30340;&#21487;&#35757;&#32451;&#21644;&#21487;&#22788;&#29702;&#30340;&#26041;&#24335;&#36827;&#34892;&#27169;&#22411;&#31616;&#21270;&#65292;&#20135;&#29983;&#20934;&#30830;&#21644;&#21487;&#35299;&#37322;&#30340;&#20302;&#32500;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#27969;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#31216;&#20026;&#21453;&#24212;&#22352;&#26631;&#65288;RC&#65289;&#27969;&#65292;&#29992;&#20110;&#21457;&#29616;&#20998;&#23376;&#31995;&#32479;&#20302;&#32500;&#21160;&#21147;&#23398;&#27169;&#22411;&#12290;RC&#27969;&#21033;&#29992;&#24402;&#19968;&#21270;&#27969;&#35774;&#35745;&#22352;&#26631;&#21464;&#25442;&#65292;&#24182;&#20351;&#29992;&#24067;&#26391;&#21160;&#21147;&#23398;&#27169;&#22411;&#26469;&#36817;&#20284;RC&#30340;&#21160;&#21147;&#23398;&#65292;&#25152;&#26377;&#27169;&#22411;&#21442;&#25968;&#21487;&#20197;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#36827;&#34892;&#20272;&#35745;&#12290;&#19982;&#29616;&#26377;&#30340;&#20998;&#23376;&#21160;&#21147;&#23398;&#27169;&#22411;&#31616;&#21270;&#26041;&#27861;&#19981;&#21516;&#65292;&#30001;&#20110;&#24402;&#19968;&#21270;&#27969;&#30340;&#21487;&#36870;&#24615;&#65292;RC&#27969;&#22312;&#36830;&#32493;&#26102;&#38388;&#21644;&#31354;&#38388;&#20013;&#25552;&#20379;&#20102;&#21487;&#35757;&#32451;&#21644;&#21487;&#22788;&#29702;&#30340;&#31616;&#21270;&#21160;&#21147;&#23398;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#30740;&#31350;&#30340;&#22522;&#20110;&#24067;&#26391;&#21160;&#21147;&#23398;&#30340;&#31616;&#21270;&#21160;&#21147;&#23398;&#27169;&#22411;&#22312;&#20998;&#23376;&#31995;&#32479;&#30340;&#30456;&#31354;&#38388;&#20013;&#20135;&#29983;&#20102;&#26131;&#20110;&#36776;&#21035;&#30340;&#20122;&#31283;&#24577;&#34920;&#31034;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#25152;&#25552;&#26041;&#27861;&#22914;&#20309;&#26377;&#25928;&#22320;&#21457;&#29616;&#32473;&#23450;&#30340;&#23436;&#25972;&#29366;&#24577;&#21160;&#21147;&#23398;&#30340;&#21487;&#35299;&#37322;&#21644;&#20934;&#30830;&#30340;&#20302;&#32500;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we introduce a flow based machine learning approach, called reaction coordinate (RC) flow, for discovery of low-dimensional kinetic models of molecular systems. The RC flow utilizes a normalizing flow to design the coordinate transformation and a Brownian dynamics model to approximate the kinetics of RC, where all model parameters can be estimated in a data-driven manner. In contrast to existing model reduction methods for molecular kinetics, RC flow offers a trainable and tractable model of reduced kinetics in continuous time and space due to the invertibility of the normalizing flow. Furthermore, the Brownian dynamics-based reduced kinetic model investigated in this work yields a readily discernible representation of metastable states within the phase space of the molecular system. Numerical experiments demonstrate how effectively the proposed method discovers interpretable and accurate low-dimensional representations of given full-state kinetics from simulations.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#22914;&#20309;&#20351;&#29992;&#24191;&#20041;&#32447;&#24615;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#65288;GLMM&#65289;&#26641;&#26469;&#35782;&#21035;&#32447;&#24615;&#22686;&#38271;&#26354;&#32447;&#27169;&#22411;&#20013;&#30340;&#23376;&#32676;&#65292;&#25193;&#23637;&#30340;GLMM&#26641;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#26356;&#20934;&#30830;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#21487;&#20197;&#21516;&#26102;&#24314;&#27169;&#31163;&#25955;&#21644;&#36830;&#32493;&#30340;&#39044;&#27979;&#21464;&#37327;&#12290;</title><link>http://arxiv.org/abs/2309.05862</link><description>&lt;p&gt;
&#32447;&#24615;&#22686;&#38271;&#26354;&#32447;&#27169;&#22411;&#20013;&#30340;&#23376;&#32676;&#26816;&#27979;&#19982;&#24191;&#20041;&#32447;&#24615;&#28151;&#21512;&#27169;&#22411;&#65288;GLMM&#65289;&#26641;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Subgroup detection in linear growth curve models with generalized linear mixed model (GLMM) trees. (arXiv:2309.05862v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05862
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#22914;&#20309;&#20351;&#29992;&#24191;&#20041;&#32447;&#24615;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#65288;GLMM&#65289;&#26641;&#26469;&#35782;&#21035;&#32447;&#24615;&#22686;&#38271;&#26354;&#32447;&#27169;&#22411;&#20013;&#30340;&#23376;&#32676;&#65292;&#25193;&#23637;&#30340;GLMM&#26641;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#26356;&#20934;&#30830;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#21487;&#20197;&#21516;&#26102;&#24314;&#27169;&#31163;&#25955;&#21644;&#36830;&#32493;&#30340;&#39044;&#27979;&#21464;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22686;&#38271;&#26354;&#32447;&#27169;&#22411;&#26159;&#30740;&#31350;&#38543;&#26102;&#38388;&#22312;&#20010;&#20307;&#20869;&#37096;&#21457;&#23637;&#30340;&#21709;&#24212;&#21464;&#37327;&#30340;&#24120;&#29992;&#24037;&#20855;&#12290;&#36825;&#31181;&#27169;&#22411;&#20013;&#32463;&#24120;&#23384;&#22312;&#20010;&#20307;&#20043;&#38388;&#30340;&#24322;&#36136;&#24615;&#65292;&#30740;&#31350;&#32773;&#36890;&#24120;&#23545;&#35299;&#37322;&#25110;&#39044;&#27979;&#36825;&#31181;&#24322;&#36136;&#24615;&#24863;&#20852;&#36259;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#24191;&#20041;&#32447;&#24615;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#65288;GLMM&#65289;&#26641;&#26469;&#35782;&#21035;&#32447;&#24615;&#22686;&#38271;&#26354;&#32447;&#27169;&#22411;&#20013;&#20855;&#26377;&#19981;&#21516;&#24418;&#29366;&#36712;&#36857;&#30340;&#23376;&#32676;&#12290;&#26368;&#21021;&#26159;&#38024;&#23545;&#32858;&#31867;&#30340;&#27178;&#26029;&#38754;&#25968;&#25454;&#24320;&#21457;&#30340;GLMM&#26641;&#22312;&#36825;&#37324;&#34987;&#25193;&#23637;&#21040;&#32437;&#21521;&#25968;&#25454;&#12290;&#24471;&#21040;&#30340;&#25193;&#23637;GLMM&#26641;&#21487;&#30452;&#25509;&#24212;&#29992;&#20110;&#22686;&#38271;&#26354;&#32447;&#27169;&#22411;&#20316;&#20026;&#19968;&#20010;&#37325;&#35201;&#30340;&#29305;&#20363;&#12290;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#20013;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#25193;&#23637;&#30340;&#24615;&#33021;&#65292;&#24182;&#19982;&#20854;&#20182;&#29992;&#20110;&#22686;&#38271;&#26354;&#32447;&#27169;&#22411;&#30340;&#20998;&#21106;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#25193;&#23637;&#30340;GLMM&#26641;&#30340;&#24615;&#33021;&#27604;&#21407;&#22987;&#31639;&#27861;&#21644;LongCART&#26356;&#20934;&#30830;&#65292;&#24182;&#19988;&#19982;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#65288;SEM&#65289;&#26641;&#30340;&#20934;&#30830;&#24615;&#30456;&#20284;&#12290;&#27492;&#22806;&#65292;GLMM&#26641;&#21487;&#20197;&#23545;&#31163;&#25955;&#21644;&#36830;&#32493;&#30340;&#39044;&#27979;&#21464;&#37327;&#24314;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;
Growth curve models are popular tools for studying the development of a response variable within subjects over time. Heterogeneity between subjects is common in such models, and researchers are typically interested in explaining or predicting this heterogeneity. We show how generalized linear mixed effects model (GLMM) trees can be used to identify subgroups with differently shaped trajectories in linear growth curve models. Originally developed for clustered cross-sectional data, GLMM trees are extended here to longitudinal data. The resulting extended GLMM trees are directly applicable to growth curve models as an important special case. In simulated and real-world data, we assess the performance of the extensions and compare against other partitioning methods for growth curve models. Extended GLMM trees perform more accurately than the original algorithm and LongCART, and similarly accurate as structural equation model (SEM) trees. In addition, GLMM trees allow for modeling both dis
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#24320;&#21457;&#20102;Ridge&#21644;&#21016;&#22411;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#28151;&#21512;&#27850;&#26494;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#30149;&#24577;&#35774;&#35745;&#30697;&#38453;&#65292;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.05838</link><description>&lt;p&gt;
&#37319;&#29992;&#21016;&#22411;&#25910;&#32553;&#20272;&#35745;&#30340;&#28151;&#21512;&#27850;&#26494;&#22238;&#24402;&#26041;&#27861;&#22312;&#24515;&#33039;&#30149;&#30740;&#31350;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Liu-type Shrinkage Estimators for Mixture of Poisson Regressions with Experts: A Heart Disease Study. (arXiv:2309.05838v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05838
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#24320;&#21457;&#20102;Ridge&#21644;&#21016;&#22411;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#28151;&#21512;&#27850;&#26494;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#30149;&#24577;&#35774;&#35745;&#30697;&#38453;&#65292;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35745;&#25968;&#25968;&#25454;&#22312;&#21307;&#23398;&#30740;&#31350;&#20013;&#65292;&#22914;&#24515;&#33039;&#30149;&#30740;&#31350;&#20013;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#27850;&#26494;&#22238;&#24402;&#27169;&#22411;&#26159;&#35780;&#20272;&#19968;&#32452;&#21327;&#21464;&#37327;&#23545;&#35745;&#25968;&#21709;&#24212;&#24433;&#21709;&#30340;&#24120;&#29992;&#25216;&#26415;&#12290;&#28151;&#21512;&#27850;&#26494;&#22238;&#24402;&#27169;&#22411;&#19982;&#19987;&#23478;&#26041;&#27861;&#26159;&#19968;&#31181;&#23454;&#29992;&#24037;&#20855;&#65292;&#19981;&#20165;&#21487;&#20197;&#22788;&#29702;&#27850;&#26494;&#22238;&#24402;&#20013;&#30340;&#24322;&#36136;&#24615;&#65292;&#36824;&#21487;&#20197;&#23398;&#20064;&#20154;&#32676;&#30340;&#28151;&#21512;&#32467;&#26500;&#12290;&#22810;&#37325;&#20849;&#32447;&#24615;&#26159;&#22238;&#24402;&#27169;&#22411;&#20013;&#24120;&#35265;&#30340;&#25361;&#25112;&#20043;&#19968;&#65292;&#23548;&#33268;&#27850;&#26494;&#22238;&#24402;&#20998;&#37327;&#21644;&#19987;&#23478;&#31867;&#30340;&#35774;&#35745;&#30697;&#38453;&#30149;&#24577;&#12290;&#26368;&#22823;&#20284;&#28982;&#26041;&#27861;&#22312;&#22810;&#37325;&#20849;&#32447;&#24615;&#20013;&#20135;&#29983;&#19981;&#21487;&#38752;&#21644;&#35823;&#23548;&#24615;&#30340;&#20272;&#35745;&#32467;&#26524;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;Ridge&#21644;&#21016;&#22411;&#26041;&#27861;&#20316;&#20026;&#20004;&#31181;&#25910;&#32553;&#26041;&#27861;&#65292;&#29992;&#20110;&#24212;&#23545;&#28151;&#21512;&#27850;&#26494;&#22238;&#24402;&#27169;&#22411;&#19982;&#19987;&#23478;&#30340;&#30149;&#24577;&#35774;&#35745;&#30697;&#38453;&#12290;&#36890;&#36807;&#22810;&#31181;&#25968;&#20540;&#30740;&#31350;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25910;&#32553;&#26041;&#27861;&#22312;&#35299;&#20915;&#27850;&#26494;&#22238;&#24402;&#27169;&#22411;&#19982;&#19987;&#23478;&#30340;&#30149;&#24577;&#35774;&#35745;&#30697;&#38453;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Count data play a critical role in medical research, such as heart disease. The Poisson regression model is a common technique for evaluating the impact of a set of covariates on the count responses. The mixture of Poisson regression models with experts is a practical tool to exploit the covariates, not only to handle the heterogeneity in the Poisson regressions but also to learn the mixing structure of the population. Multicollinearity is one of the most common challenges with regression models, leading to ill-conditioned design matrices of Poisson regression components and expert classes. The maximum likelihood method produces unreliable and misleading estimates for the effects of the covariates in multicollinearity. In this research, we develop Ridge and Liu-type methods as two shrinkage approaches to cope with the ill-conditioned design matrices of the mixture of Poisson regression models with experts. Through various numerical studies, we demonstrate that the shrinkage methods off
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21487;&#35299;&#37322;&#23398;&#20064;&#26377;&#25928;&#21160;&#21147;&#23398;&#65288;iLED&#65289;&#26694;&#26550;&#65292;&#23427;&#36890;&#36807;&#24341;&#20837;&#28145;&#24230;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#25216;&#26415;&#65292;&#22312;&#20445;&#25345;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#25552;&#20379;&#20102;&#21487;&#35299;&#37322;&#24615;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#31070;&#32463;&#32593;&#32476;&#22312;&#22797;&#26434;&#31995;&#32479;&#20013;&#24212;&#29992;&#21463;&#38480;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.05812</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#22810;&#23610;&#24230;&#31995;&#32479;&#26377;&#25928;&#21160;&#21147;&#23398;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Interpretable learning of effective dynamics for multiscale systems. (arXiv:2309.05812v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05812
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21487;&#35299;&#37322;&#23398;&#20064;&#26377;&#25928;&#21160;&#21147;&#23398;&#65288;iLED&#65289;&#26694;&#26550;&#65292;&#23427;&#36890;&#36807;&#24341;&#20837;&#28145;&#24230;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#25216;&#26415;&#65292;&#22312;&#20445;&#25345;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#25552;&#20379;&#20102;&#21487;&#35299;&#37322;&#24615;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#31070;&#32463;&#32593;&#32476;&#22312;&#22797;&#26434;&#31995;&#32479;&#20013;&#24212;&#29992;&#21463;&#38480;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#22810;&#23610;&#24230;&#31995;&#32479;&#30340;&#24314;&#27169;&#21644;&#20223;&#30495;&#26159;&#31185;&#23398;&#21644;&#24037;&#31243;&#39046;&#22495;&#38754;&#20020;&#30340;&#37325;&#35201;&#25361;&#25112;&#12290;&#23613;&#31649;&#29616;&#20170;&#30340;&#35745;&#31639;&#26426;&#25216;&#26415;&#19981;&#26029;&#36827;&#27493;&#65292;&#35299;&#20915;&#30001;&#25511;&#21046;&#26041;&#31243;&#25551;&#36848;&#30340;&#25152;&#26377;&#26102;&#31354;&#23610;&#24230;&#20173;&#28982;&#26159;&#19968;&#20010;&#36965;&#19981;&#21487;&#21450;&#30340;&#30446;&#26631;&#12290;&#36825;&#31181;&#35748;&#35782;&#20419;&#20351;&#20154;&#20204;&#22823;&#21147;&#21457;&#23637;&#27169;&#22411;&#38477;&#38454;&#25216;&#26415;&#12290;&#36817;&#24180;&#26469;&#65292;&#22522;&#20110;&#28145;&#24230;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#30340;&#25216;&#26415;&#22312;&#22797;&#26434;&#26102;&#31354;&#31995;&#32479;&#30340;&#24314;&#27169;&#21644;&#20223;&#30495;&#26041;&#38754;&#21462;&#24471;&#20102;&#20196;&#20154;&#40723;&#33310;&#30340;&#25104;&#26524;&#65292;&#24182;&#19988;&#20855;&#26377;&#27169;&#22411;&#24320;&#21457;&#30340;&#28789;&#27963;&#24615;&#65292;&#22240;&#20026;&#23427;&#20204;&#21487;&#20197;&#32467;&#21512;&#23454;&#39564;&#21644;&#35745;&#31639;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#31070;&#32463;&#32593;&#32476;&#32570;&#20047;&#21487;&#35299;&#37322;&#24615;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#22797;&#26434;&#31995;&#32479;&#20013;&#30340;&#23454;&#29992;&#24615;&#21644;&#26222;&#36866;&#24615;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21487;&#35299;&#37322;&#23398;&#20064;&#26377;&#25928;&#21160;&#21147;&#23398;&#65288;iLED&#65289;&#26694;&#26550;&#65292;&#23427;&#20855;&#26377;&#19982;&#22522;&#20110;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#26032;&#26041;&#27861;&#30456;&#24403;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#39069;&#22806;&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
The modeling and simulation of high-dimensional multiscale systems is a critical challenge across all areas of science and engineering. It is broadly believed that even with today's computer advances resolving all spatiotemporal scales described by the governing equations remains a remote target. This realization has prompted intense efforts to develop model order reduction techniques. In recent years, techniques based on deep recurrent neural networks have produced promising results for the modeling and simulation of complex spatiotemporal systems and offer large flexibility in model development as they can incorporate experimental and computational data. However, neural networks lack interpretability, which limits their utility and generalizability across complex systems. Here we propose a novel framework of Interpretable Learning Effective Dynamics (iLED) that offers comparable accuracy to state-of-the-art recurrent neural network-based approaches while providing the added benefit o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#21453;&#36716;&#29983;&#25104;&#27169;&#22411;&#30340;&#35745;&#31639;&#38590;&#24230;&#30340;&#32454;&#31890;&#24230;&#35270;&#22270;&#65292;&#24314;&#31435;&#20102;&#23545;&#31934;&#30830;&#21644;&#36817;&#20284;&#27169;&#22411;&#21453;&#36716;&#30340;&#26032;&#30340;&#38590;&#24230;&#19979;&#30028;&#12290;</title><link>http://arxiv.org/abs/2309.05795</link><description>&lt;p&gt;
&#20851;&#20110;&#21453;&#36716;&#29983;&#25104;&#27169;&#22411;&#30340;&#32454;&#31890;&#24230;&#38590;&#24230;
&lt;/p&gt;
&lt;p&gt;
On the Fine-Grained Hardness of Inverting Generative Models. (arXiv:2309.05795v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05795
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#21453;&#36716;&#29983;&#25104;&#27169;&#22411;&#30340;&#35745;&#31639;&#38590;&#24230;&#30340;&#32454;&#31890;&#24230;&#35270;&#22270;&#65292;&#24314;&#31435;&#20102;&#23545;&#31934;&#30830;&#21644;&#36817;&#20284;&#27169;&#22411;&#21453;&#36716;&#30340;&#26032;&#30340;&#38590;&#24230;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27169;&#22411;&#21453;&#36716;&#30340;&#30446;&#26631;&#26159;&#35782;&#21035;&#19968;&#20010;&#22823;&#23567;&#20026;$n$&#30340;&#28508;&#22312;&#21521;&#37327;&#65292;&#35813;&#21521;&#37327;&#33021;&#22815;&#20135;&#29983;&#19982;&#32473;&#23450;&#30446;&#26631;&#23494;&#20999;&#21305;&#37197;&#30340;&#29983;&#25104;&#27169;&#22411;&#36755;&#20986;&#12290;&#36825;&#20010;&#38382;&#39064;&#22312;&#28041;&#21450;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#35768;&#22810;&#29616;&#20195;&#24212;&#29992;&#20013;&#26159;&#26680;&#24515;&#30340;&#35745;&#31639;&#21407;&#35821;&#12290;&#28982;&#32780;&#65292;&#35813;&#38382;&#39064;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#34987;&#35748;&#20026;&#26159;&#35745;&#31639;&#19978;&#20855;&#26377;&#25361;&#25112;&#24615;&#21644;NP&#38590;&#35299;&#30340;&#12290;&#26412;&#25991;&#26088;&#22312;&#25552;&#20379;&#23545;&#36825;&#20010;&#38382;&#39064;&#30340;&#35745;&#31639;&#38590;&#24230;&#30340;&#32454;&#31890;&#24230;&#35270;&#22270;&#12290;&#25105;&#20204;&#38024;&#23545;&#31934;&#30830;&#21644;&#36817;&#20284;&#27169;&#22411;&#21453;&#36716;&#24314;&#31435;&#20102;&#20960;&#20010;&#26032;&#30340;&#38590;&#24230;&#19979;&#30028;&#12290;&#22312;&#31934;&#30830;&#21453;&#36716;&#20013;&#65292;&#30446;&#26631;&#26159;&#30830;&#23450;&#19968;&#20010;&#30446;&#26631;&#26159;&#21542;&#21253;&#21547;&#22312;&#32473;&#23450;&#29983;&#25104;&#27169;&#22411;&#30340;&#33539;&#22260;&#20869;&#12290;&#22312;&#24378;&#25351;&#25968;&#26102;&#38388;&#20551;&#35774;&#65288;SETH&#65289;&#19979;&#65292;&#25105;&#20204;&#36890;&#36807;&#20174;$k$-SAT&#30340;&#32422;&#31616;&#26469;&#35777;&#26126;&#65292;&#31934;&#30830;&#21453;&#36716;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#19979;&#30028;&#20026;$\Omega(2^n)$&#65307;&#36825;&#26159;&#24050;&#30693;&#32467;&#26524;&#30340;&#21152;&#24378;&#29256;&#12290;&#23545;&#20110;&#26356;&#20855;&#23454;&#38469;&#24847;&#20041;&#30340;&#36817;&#20284;&#21453;&#36716;&#38382;&#39064;&#65292;&#30446;&#26631;&#26159;&#23547;&#25214;&#19968;&#20010;&#28508;&#22312;&#21521;&#37327;&#65292;&#20351;&#24471;&#29983;&#25104;&#27169;&#22411;&#36755;&#20986;&#19982;&#32473;&#23450;&#30446;&#26631;&#23613;&#21487;&#33021;&#25509;&#36817;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23384;&#22312;&#19968;&#20010;&#24120;&#25968;$\gamma$&#65292;&#20351;&#24471;&#38500;&#38750;$\text{NP}\subseteq \text{BPTIME}(2^{O(n^\gamma)})$&#65292;&#21542;&#21017;&#36817;&#20284;&#21453;&#36716;&#38382;&#39064;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#26080;&#27861;&#31361;&#30772;$\Omega(2^{n/2})$&#12290;
&lt;/p&gt;
&lt;p&gt;
The objective of generative model inversion is to identify a size-$n$ latent vector that produces a generative model output that closely matches a given target. This operation is a core computational primitive in numerous modern applications involving computer vision and NLP. However, the problem is known to be computationally challenging and NP-hard in the worst case. This paper aims to provide a fine-grained view of the landscape of computational hardness for this problem. We establish several new hardness lower bounds for both exact and approximate model inversion. In exact inversion, the goal is to determine whether a target is contained within the range of a given generative model. Under the strong exponential time hypothesis (SETH), we demonstrate that the computational complexity of exact inversion is lower bounded by $\Omega(2^n)$ via a reduction from $k$-SAT; this is a strengthening of known results. For the more practically relevant problem of approximate inversion, the goal 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20869;&#22312;&#32500;&#24230;&#23545;&#21387;&#32553;&#19979;&#30340;&#24230;&#37327;&#23398;&#20064;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#22312;&#23545;&#25968;&#25454;&#36827;&#34892;&#38543;&#26426;&#21387;&#32553;&#21518;&#22312;&#20302;&#32500;&#31354;&#38388;&#20869;&#35757;&#32451;&#20840;&#31209;&#24230;&#37327;&#30340;&#26041;&#27861;&#12290;&#29702;&#35770;&#20445;&#35777;&#20102;&#22312;&#19981;&#20381;&#36182;&#29615;&#22659;&#32500;&#24230;&#30340;&#24773;&#20917;&#19979;&#65292;&#24230;&#37327;&#23398;&#20064;&#30340;&#35823;&#24046;&#21487;&#20197;&#34987;&#25511;&#21046;&#65292;&#24182;&#19988;&#22312;&#23384;&#22312;&#33391;&#24615;&#20960;&#20309;&#32467;&#26500;&#26102;&#25928;&#26524;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2309.05751</link><description>&lt;p&gt;
&#20869;&#22312;&#32500;&#24230;&#23545;&#21387;&#32553;&#19979;&#30340;&#24230;&#37327;&#23398;&#20064;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
The Effect of Intrinsic Dimension on Metric Learning under Compression. (arXiv:2309.05751v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05751
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20869;&#22312;&#32500;&#24230;&#23545;&#21387;&#32553;&#19979;&#30340;&#24230;&#37327;&#23398;&#20064;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#22312;&#23545;&#25968;&#25454;&#36827;&#34892;&#38543;&#26426;&#21387;&#32553;&#21518;&#22312;&#20302;&#32500;&#31354;&#38388;&#20869;&#35757;&#32451;&#20840;&#31209;&#24230;&#37327;&#30340;&#26041;&#27861;&#12290;&#29702;&#35770;&#20445;&#35777;&#20102;&#22312;&#19981;&#20381;&#36182;&#29615;&#22659;&#32500;&#24230;&#30340;&#24773;&#20917;&#19979;&#65292;&#24230;&#37327;&#23398;&#20064;&#30340;&#35823;&#24046;&#21487;&#20197;&#34987;&#25511;&#21046;&#65292;&#24182;&#19988;&#22312;&#23384;&#22312;&#33391;&#24615;&#20960;&#20309;&#32467;&#26500;&#26102;&#25928;&#26524;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24230;&#37327;&#23398;&#20064;&#26088;&#22312;&#22312;&#36755;&#20837;&#31354;&#38388;&#20013;&#25214;&#21040;&#36866;&#24403;&#30340;&#36317;&#31163;&#24230;&#37327;&#65292;&#20197;&#25913;&#21892;&#22522;&#20110;&#36317;&#31163;&#30340;&#23398;&#20064;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;&#22312;&#39640;&#32500;&#29615;&#22659;&#20013;&#65292;&#24230;&#37327;&#23398;&#20064;&#36824;&#21487;&#20197;&#20316;&#20026;&#38477;&#32500;&#30340;&#25163;&#27573;&#65292;&#36890;&#36807;&#23545;&#23398;&#20064;&#30340;&#24230;&#37327;&#26045;&#21152;&#19968;&#20010;&#20302;&#31209;&#32422;&#26463;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#30340;&#26159;&#23545;&#25968;&#25454;&#30340;&#19968;&#20010;&#38543;&#26426;&#21387;&#32553;&#29256;&#26412;&#65292;&#28982;&#21518;&#22312;&#20854;&#20013;&#35757;&#32451;&#19968;&#20010;&#20840;&#31209;&#30340;&#24230;&#37327;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#20851;&#20110;&#36317;&#31163;&#24230;&#37327;&#23398;&#20064;&#30340;&#35823;&#24046;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#36825;&#20123;&#20445;&#35777;&#19981;&#20381;&#36182;&#20110;&#29615;&#22659;&#32500;&#24230;&#12290;&#25105;&#20204;&#30340;&#36793;&#30028;&#38500;&#20102;&#23545;&#26469;&#33258;&#26377;&#30028;&#25903;&#25345;&#30340;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#27809;&#26377;&#26174;&#24335;&#30340;&#20551;&#35774;&#20043;&#22806;&#65292;&#24182;&#19988;&#22312;&#23384;&#22312;&#33391;&#24615;&#20960;&#20309;&#32467;&#26500;&#26102;&#33258;&#21160;&#25910;&#25947;&#12290;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#25903;&#25345;&#25105;&#20204;&#22312;&#39640;&#32500;&#29615;&#22659;&#20013;&#30340;&#29702;&#35770;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Metric learning aims at finding a suitable distance metric over the input space, to improve the performance of distance-based learning algorithms. In high-dimensional settings, metric learning can also play the role of dimensionality reduction, by imposing a low-rank restriction to the learnt metric. In this paper, instead of training a low-rank metric on high-dimensional data, we consider a randomly compressed version of the data, and train a full-rank metric there. We give theoretical guarantees on the error of distance-based metric learning, with respect to the random compression, which do not depend on the ambient dimension. Our bounds do not make any explicit assumptions, aside from i.i.d. data from a bounded support, and automatically tighten when benign geometrical structures are present. Experimental results on both synthetic and real data sets support our theoretical findings in high-dimensional settings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#25191;&#34892;&#25193;&#25955;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;softmax&#20989;&#25968;&#24212;&#29992;&#20110;&#38463;&#24681;&#26031;&#22374;-&#20044;&#20262;&#36125;&#20811;&#36807;&#31243;&#65292;&#21487;&#20197;&#22312;&#22788;&#29702;&#36830;&#32493;&#24615;&#21644;&#31163;&#25955;&#24615;&#23545;&#35937;&#20043;&#38388;&#30340;&#32039;&#24352;&#20851;&#31995;&#26102;&#21462;&#24471;&#33391;&#22909;&#25928;&#26524;&#12290;&#36825;&#31181;&#26041;&#27861;&#20063;&#21487;&#20197;&#25193;&#23637;&#21040;&#21333;&#20301;&#31435;&#26041;&#20307;&#19978;&#65292;&#20174;&#32780;&#22312;&#26377;&#30028;&#22270;&#20687;&#29983;&#25104;&#26041;&#38754;&#20855;&#26377;&#24212;&#29992;&#21069;&#26223;&#12290;</title><link>http://arxiv.org/abs/2309.02530</link><description>&lt;p&gt;
&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#25193;&#25955;
&lt;/p&gt;
&lt;p&gt;
Diffusion on the Probability Simplex. (arXiv:2309.02530v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02530
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#25191;&#34892;&#25193;&#25955;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;softmax&#20989;&#25968;&#24212;&#29992;&#20110;&#38463;&#24681;&#26031;&#22374;-&#20044;&#20262;&#36125;&#20811;&#36807;&#31243;&#65292;&#21487;&#20197;&#22312;&#22788;&#29702;&#36830;&#32493;&#24615;&#21644;&#31163;&#25955;&#24615;&#23545;&#35937;&#20043;&#38388;&#30340;&#32039;&#24352;&#20851;&#31995;&#26102;&#21462;&#24471;&#33391;&#22909;&#25928;&#26524;&#12290;&#36825;&#31181;&#26041;&#27861;&#20063;&#21487;&#20197;&#25193;&#23637;&#21040;&#21333;&#20301;&#31435;&#26041;&#20307;&#19978;&#65292;&#20174;&#32780;&#22312;&#26377;&#30028;&#22270;&#20687;&#29983;&#25104;&#26041;&#38754;&#20855;&#26377;&#24212;&#29992;&#21069;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#36890;&#36807;&#23398;&#20064;&#36870;&#36716;&#25968;&#25454;&#20998;&#24067;&#30340;&#36880;&#28176;&#22122;&#22768;&#21270;&#26469;&#21019;&#24314;&#19968;&#20010;&#29983;&#25104;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#36830;&#32493;&#30340;&#22122;&#22768;&#21270;&#36807;&#31243;&#19982;&#31163;&#25955;&#25968;&#25454;&#20043;&#38388;&#30340;&#26399;&#26395;&#19981;&#19968;&#33268;&#12290;&#20026;&#20102;&#35299;&#20915;&#36830;&#32493;&#24615;&#21644;&#31163;&#25955;&#24615;&#23545;&#35937;&#20043;&#38388;&#30340;&#32039;&#24352;&#20851;&#31995;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#25191;&#34892;&#25193;&#25955;&#30340;&#26041;&#27861;&#12290;&#20351;&#29992;&#27010;&#29575;&#21333;&#32431;&#24418;&#33258;&#28982;&#22320;&#21019;&#24314;&#20102;&#19968;&#31181;&#35299;&#37322;&#65292;&#20854;&#20013;&#28857;&#23545;&#24212;&#20110;&#20998;&#31867;&#27010;&#29575;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#29992;&#23545;&#38463;&#24681;&#26031;&#22374;-&#20044;&#20262;&#36125;&#20811;&#36807;&#31243;&#20043;&#38388;&#36827;&#34892;softmax&#20989;&#25968;&#30340;&#24212;&#29992;&#65292;&#36825;&#26159;&#19968;&#20010;&#20247;&#25152;&#21608;&#30693;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#12290;&#25105;&#20204;&#21457;&#29616;&#25105;&#20204;&#30340;&#26041;&#27861;&#20063;&#33258;&#28982;&#22320;&#25193;&#23637;&#21040;&#21253;&#25324;&#23545;&#21333;&#20301;&#31435;&#26041;&#20307;&#30340;&#25193;&#25955;&#65292;&#36825;&#23545;&#20110;&#26377;&#30028;&#22270;&#20687;&#29983;&#25104;&#24212;&#29992;&#20855;&#26377;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models learn to reverse the progressive noising of a data distribution to create a generative model. However, the desired continuous nature of the noising process can be at odds with discrete data. To deal with this tension between continuous and discrete objects, we propose a method of performing diffusion on the probability simplex. Using the probability simplex naturally creates an interpretation where points correspond to categorical probability distributions. Our method uses the softmax function applied to an Ornstein-Unlenbeck Process, a well-known stochastic differential equation. We find that our methodology also naturally extends to include diffusion on the unit cube which has applications for bounded image generation.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#36235;&#21183;&#28388;&#27874;&#26041;&#27861;&#23545;&#20855;&#26377;&#26102;&#31354;&#20381;&#36182;&#24615;&#30340;&#25968;&#25454;&#36827;&#34892;&#20102;&#38750;&#21442;&#25968;&#22238;&#24402;&#20989;&#25968;&#30340;&#20272;&#35745;&#65292;&#30740;&#31350;&#20102;&#35813;&#26041;&#27861;&#22312;&#21333;&#21464;&#37327;&#21644;&#22810;&#21464;&#37327;&#24773;&#20917;&#19979;&#30340;&#24212;&#29992;&#65292;&#24182;&#39564;&#35777;&#20102;&#20854;&#26497;&#23567;&#21270;&#24615;&#12290;&#30740;&#31350;&#21457;&#29616;&#20102;&#20197;&#24448;&#26410;&#26366;&#25506;&#32034;&#30340;&#29420;&#29305;&#30456;&#21464;&#29616;&#35937;&#65292;&#24182;&#36890;&#36807;&#20223;&#30495;&#21644;&#23454;&#38469;&#25968;&#25454;&#24212;&#29992;&#39564;&#35777;&#20102;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.16172</link><description>&lt;p&gt;
&#36890;&#36807;&#36235;&#21183;&#28388;&#27874;&#36827;&#34892;&#26102;&#31354;&#27169;&#22411;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Temporal-spatial model via Trend Filtering. (arXiv:2308.16172v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16172
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#36235;&#21183;&#28388;&#27874;&#26041;&#27861;&#23545;&#20855;&#26377;&#26102;&#31354;&#20381;&#36182;&#24615;&#30340;&#25968;&#25454;&#36827;&#34892;&#20102;&#38750;&#21442;&#25968;&#22238;&#24402;&#20989;&#25968;&#30340;&#20272;&#35745;&#65292;&#30740;&#31350;&#20102;&#35813;&#26041;&#27861;&#22312;&#21333;&#21464;&#37327;&#21644;&#22810;&#21464;&#37327;&#24773;&#20917;&#19979;&#30340;&#24212;&#29992;&#65292;&#24182;&#39564;&#35777;&#20102;&#20854;&#26497;&#23567;&#21270;&#24615;&#12290;&#30740;&#31350;&#21457;&#29616;&#20102;&#20197;&#24448;&#26410;&#26366;&#25506;&#32034;&#30340;&#29420;&#29305;&#30456;&#21464;&#29616;&#35937;&#65292;&#24182;&#36890;&#36807;&#20223;&#30495;&#21644;&#23454;&#38469;&#25968;&#25454;&#24212;&#29992;&#39564;&#35777;&#20102;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20391;&#37325;&#20110;&#23545;&#20855;&#26377;&#21516;&#26102;&#26102;&#38388;&#21644;&#31354;&#38388;&#20381;&#36182;&#24615;&#30340;&#25968;&#25454;&#36827;&#34892;&#38750;&#21442;&#25968;&#22238;&#24402;&#20989;&#25968;&#30340;&#20272;&#35745;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#36235;&#21183;&#28388;&#27874;&#65292;&#36825;&#26159;&#19968;&#31181;&#38750;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#30001;Mammen&#21644;Rudin&#25552;&#20986;&#12290;&#22312;&#21333;&#21464;&#37327;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#30340;&#20449;&#21495;&#20551;&#35774;&#20855;&#26377;&#26377;&#30028;&#24635;&#21464;&#24322;&#24230;&#30340;k&#27425;&#24369;&#23548;&#25968;&#65292;&#20801;&#35768;&#19968;&#23450;&#31243;&#24230;&#30340;&#24179;&#28369;&#24615;&#12290;&#22312;&#22810;&#21464;&#37327;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;Padilla&#31561;&#20154;&#30340;K&#26368;&#36817;&#37051;&#34701;&#21512;&#22871;&#32034;&#20272;&#35745;&#22120;&#65292;&#37319;&#29992;&#36866;&#29992;&#20110;&#20855;&#26377;&#26377;&#30028;&#21464;&#24322;&#24230;&#19988;&#31526;&#21512;&#20998;&#27573;&#21033;&#26222;&#24076;&#33576;&#36830;&#32493;&#24615;&#20934;&#21017;&#30340;&#20449;&#21495;&#30340;ADMM&#31639;&#27861;&#12290;&#36890;&#36807;&#19982;&#19979;&#30028;&#23545;&#40784;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25105;&#20204;&#20272;&#35745;&#22120;&#30340;&#26497;&#23567;&#21270;&#24615;&#12290;&#36890;&#36807;&#20998;&#26512;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#20197;&#24448;&#36235;&#21183;&#28388;&#27874;&#30740;&#31350;&#20013;&#26410;&#26366;&#25506;&#32034;&#36807;&#30340;&#29420;&#29305;&#30456;&#21464;&#29616;&#35937;&#12290;&#20223;&#30495;&#30740;&#31350;&#21644;&#23454;&#38469;&#25968;&#25454;&#24212;&#29992;&#37117;&#31361;&#20986;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#20986;&#33394;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This research focuses on the estimation of a non-parametric regression function designed for data with simultaneous time and space dependencies. In such a context, we study the Trend Filtering, a nonparametric estimator introduced by \cite{mammen1997locally} and \cite{rudin1992nonlinear}. For univariate settings, the signals we consider are assumed to have a kth weak derivative with bounded total variation, allowing for a general degree of smoothness. In the multivariate scenario, we study a $K$-Nearest Neighbor fused lasso estimator as in \cite{padilla2018adaptive}, employing an ADMM algorithm, suitable for signals with bounded variation that adhere to a piecewise Lipschitz continuity criterion. By aligning with lower bounds, the minimax optimality of our estimators is validated. A unique phase transition phenomenon, previously uncharted in Trend Filtering studies, emerges through our analysis. Both Simulation studies and real data applications underscore the superior performance of o
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24809;&#32602;&#21270;&#21644;&#38408;&#20540;&#21270;&#20272;&#35745;&#30340;&#27169;&#24335;&#24674;&#22797;&#26041;&#27861;&#65292;&#24182;&#23450;&#20041;&#20102;&#27169;&#24335;&#21644;&#24674;&#22797;&#26465;&#20214;&#12290;&#23545;&#20110;LASSO&#65292;&#26080;&#22122;&#22768;&#24674;&#22797;&#26465;&#20214;&#21644;&#20114;&#19981;&#34920;&#31034;&#26465;&#20214;&#36215;&#21040;&#20102;&#30456;&#21516;&#30340;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2307.10158</link><description>&lt;p&gt;
&#24809;&#32602;&#21270;&#21644;&#38408;&#20540;&#21270;&#20272;&#35745;&#20013;&#30340;&#27169;&#24335;&#24674;&#22797;&#21450;&#20854;&#20960;&#20309;
&lt;/p&gt;
&lt;p&gt;
Pattern Recovery in Penalized and Thresholded Estimation and its Geometry. (arXiv:2307.10158v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10158
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24809;&#32602;&#21270;&#21644;&#38408;&#20540;&#21270;&#20272;&#35745;&#30340;&#27169;&#24335;&#24674;&#22797;&#26041;&#27861;&#65292;&#24182;&#23450;&#20041;&#20102;&#27169;&#24335;&#21644;&#24674;&#22797;&#26465;&#20214;&#12290;&#23545;&#20110;LASSO&#65292;&#26080;&#22122;&#22768;&#24674;&#22797;&#26465;&#20214;&#21644;&#20114;&#19981;&#34920;&#31034;&#26465;&#20214;&#36215;&#21040;&#20102;&#30456;&#21516;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#24809;&#32602;&#20272;&#35745;&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;&#24809;&#32602;&#39033;&#30001;&#23454;&#20540;&#30340;&#22810;&#38754;&#20307;&#35268;&#33539;&#32473;&#20986;&#65292;&#20854;&#20013;&#21253;&#25324;&#35832;&#22914;LASSO&#65288;&#20197;&#21450;&#20854;&#35768;&#22810;&#21464;&#20307;&#22914;&#24191;&#20041;LASSO&#65289;&#12289;SLOPE&#12289;OSCAR&#12289;PACS&#31561;&#26041;&#27861;&#12290;&#27599;&#20010;&#20272;&#35745;&#22120;&#21487;&#20197;&#25581;&#31034;&#26410;&#30693;&#21442;&#25968;&#21521;&#37327;&#30340;&#19981;&#21516;&#32467;&#26500;&#25110;&#8220;&#27169;&#24335;&#8221;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#22522;&#20110;&#27425;&#24494;&#20998;&#30340;&#27169;&#24335;&#30340;&#19968;&#33324;&#27010;&#24565;&#65292;&#24182;&#24418;&#24335;&#21270;&#20102;&#19968;&#31181;&#34913;&#37327;&#20854;&#22797;&#26434;&#24615;&#30340;&#26041;&#27861;&#12290;&#23545;&#20110;&#27169;&#24335;&#24674;&#22797;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#29305;&#23450;&#27169;&#24335;&#20197;&#27491;&#27010;&#29575;&#34987;&#35813;&#36807;&#31243;&#26816;&#27979;&#21040;&#30340;&#26368;&#23567;&#26465;&#20214;&#65292;&#21363;&#25152;&#35859;&#30340;&#21487;&#36798;&#24615;&#26465;&#20214;&#12290;&#21033;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#26356;&#24378;&#30340;&#26080;&#22122;&#22768;&#24674;&#22797;&#26465;&#20214;&#12290;&#23545;&#20110;LASSO&#65292;&#20247;&#25152;&#21608;&#30693;&#65292;&#20114;&#19981;&#34920;&#31034;&#26465;&#20214;&#26159;&#20351;&#27169;&#24335;&#24674;&#22797;&#30340;&#27010;&#29575;&#22823;&#20110;1/2&#25152;&#24517;&#38656;&#30340;&#65292;&#24182;&#19988;&#25105;&#20204;&#23637;&#31034;&#20102;&#26080;&#22122;&#22768;&#24674;&#22797;&#36215;&#21040;&#20102;&#23436;&#20840;&#30456;&#21516;&#30340;&#20316;&#29992;&#65292;&#20174;&#32780;&#25193;&#23637;&#21644;&#32479;&#19968;&#20102;&#20114;&#19981;&#34920;&#31034;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the framework of penalized estimation where the penalty term is given by a real-valued polyhedral gauge, which encompasses methods such as LASSO (and many variants thereof such as the generalized LASSO), SLOPE, OSCAR, PACS and others. Each of these estimators can uncover a different structure or ``pattern'' of the unknown parameter vector. We define a general notion of patterns based on subdifferentials and formalize an approach to measure their complexity. For pattern recovery, we provide a minimal condition for a particular pattern to be detected by the procedure with positive probability, the so-called accessibility condition. Using our approach, we also introduce the stronger noiseless recovery condition. For the LASSO, it is well known that the irrepresentability condition is necessary for pattern recovery with probability larger than $1/2$ and we show that the noiseless recovery plays exactly the same role, thereby extending and unifying the irrepresentability conditi
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#24102;&#21560;&#25910;&#30340;&#27867;&#27946;&#65288;FwA&#65289;&#30340;&#26032;&#21327;&#35758;&#65292;&#29992;&#20110;&#35299;&#20915;&#22797;&#26434;&#32593;&#32476;&#19978;&#30340;&#24322;&#26500;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#36890;&#36807;&#20005;&#26684;&#30340;&#36951;&#25022;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#35813;&#21327;&#35758;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.05445</link><description>&lt;p&gt;
&#24102;&#21560;&#25910;&#30340;&#27867;&#27946;&#65306;&#22797;&#26434;&#32593;&#32476;&#19978;&#24322;&#26500;&#36172;&#21338;&#26426;&#30340;&#39640;&#25928;&#21327;&#35758;
&lt;/p&gt;
&lt;p&gt;
Flooding with Absorption: An Efficient Protocol for Heterogeneous Bandits over Complex Networks. (arXiv:2303.05445v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.05445
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#24102;&#21560;&#25910;&#30340;&#27867;&#27946;&#65288;FwA&#65289;&#30340;&#26032;&#21327;&#35758;&#65292;&#29992;&#20110;&#35299;&#20915;&#22797;&#26434;&#32593;&#32476;&#19978;&#30340;&#24322;&#26500;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#36890;&#36807;&#20005;&#26684;&#30340;&#36951;&#25022;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#35813;&#21327;&#35758;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#33218;&#36172;&#21338;&#26426;&#24191;&#27867;&#29992;&#20110;&#24314;&#27169;&#39034;&#24207;&#20915;&#31574;&#65292;&#22312;&#35768;&#22810;&#29616;&#23454;&#24212;&#29992;&#20013;&#22914;&#22312;&#32447;&#25512;&#33616;&#31995;&#32479;&#21644;&#26080;&#32447;&#32593;&#32476;&#20013;&#26080;&#22788;&#19981;&#22312;&#12290;&#25105;&#20204;&#32771;&#34385;&#19968;&#20010;&#22810;&#20195;&#29702;&#30340;&#22330;&#26223;&#65292;&#27599;&#20010;&#20195;&#29702;&#35299;&#20915;&#33258;&#24049;&#30340;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#36172;&#21338;&#26426;&#25317;&#26377;&#19981;&#21516;&#30340;&#33218;&#12290;&#20182;&#20204;&#30340;&#30446;&#26631;&#26159;&#22312;&#36890;&#36807;&#32473;&#23450;&#32593;&#32476;&#30340;&#36890;&#20449;&#21327;&#35758;&#21327;&#20316;&#30340;&#21516;&#26102;&#26368;&#23567;&#21270;&#20182;&#20204;&#30340;&#38598;&#20307;&#36951;&#25022;&#12290;&#20808;&#21069;&#20851;&#20110;&#27492;&#38382;&#39064;&#30340;&#25991;&#29486;&#21482;&#32771;&#34385;&#20102;&#33218;&#30340;&#24322;&#36136;&#24615;&#21644;&#32593;&#32476;&#21270;&#20195;&#29702;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#21516;&#26102;&#21253;&#21547;&#36825;&#20004;&#20010;&#29305;&#24615;&#30340;&#35774;&#32622;&#12290;&#38024;&#23545;&#36825;&#19968;&#26032;&#39062;&#30340;&#35774;&#32622;&#65292;&#25105;&#20204;&#39318;&#20808;&#23545;&#26631;&#20934;&#27867;&#27946;&#21327;&#35758;&#32467;&#21512;&#32463;&#20856;&#30340;&#19978;&#32622;&#20449;&#30028;&#31574;&#30053;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#36951;&#25022;&#20998;&#26512;&#12290;&#28982;&#21518;&#65292;&#20026;&#20102;&#20943;&#36731;&#22312;&#22797;&#26434;&#32593;&#32476;&#20013;&#27867;&#27946;&#36896;&#25104;&#30340;&#39640;&#36890;&#20449;&#25104;&#26412;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21327;&#35758;&#65292;&#31216;&#20026;&#24102;&#21560;&#25910;&#30340;&#27867;&#27946;&#65288;FwA&#65289;&#12290;&#25105;&#20204;&#23545;&#30001;&#27492;&#20135;&#29983;&#30340;&#36951;&#25022;&#19978;&#30028;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#24182;&#35752;&#35770;&#20102;&#35813;&#21327;&#35758;&#30340;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-armed bandits are extensively used to model sequential decision-making, making them ubiquitous in many real-life applications such as online recommender systems and wireless networking. We consider a multi-agent setting where each agent solves their own bandit instance endowed with a different set of arms. Their goal is to minimize their group regret while collaborating via some communication protocol over a given network. Previous literature on this problem only considered arm heterogeneity and networked agents separately. In this work, we introduce a setting that encompasses both features. For this novel setting, we first provide a rigorous regret analysis for a standard flooding protocol combined with the classic UCB policy. Then, to mitigate the issue of high communication costs incurred by flooding in complex networks, we propose a new protocol called Flooding with Absorption (FwA). We provide a theoretical analysis of the resulting regret bound and discuss the advantages of
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#21322;&#32676;&#20013;&#30340;&#36816;&#31639;&#31526;&#65292;&#21487;&#20197;&#23558;&#26410;&#30693;&#33258;&#20027;&#21160;&#21147;&#31995;&#32479;&#24314;&#27169;&#20026;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#22312;&#19981;&#21516;&#26102;&#38388;&#28382;&#21518;&#19979;&#25910;&#38598;&#12290;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#23398;&#20064;&#20855;&#26377;&#21487;&#21464;&#26102;&#38388;&#27493;&#38271;&#30340;&#28436;&#21270;&#31639;&#31526;&#65292;&#26500;&#25104;&#33258;&#20027;&#31995;&#32479;&#30340;&#21322;&#32676;&#12290;</title><link>http://arxiv.org/abs/2302.03358</link><description>&lt;p&gt;
Deep-OSG&#65306;&#21322;&#32676;&#20013;&#30340;&#36816;&#31639;&#31526;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Deep-OSG: Deep Learning of Operators in Semigroup. (arXiv:2302.03358v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03358
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#21322;&#32676;&#20013;&#30340;&#36816;&#31639;&#31526;&#65292;&#21487;&#20197;&#23558;&#26410;&#30693;&#33258;&#20027;&#21160;&#21147;&#31995;&#32479;&#24314;&#27169;&#20026;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#22312;&#19981;&#21516;&#26102;&#38388;&#28382;&#21518;&#19979;&#25910;&#38598;&#12290;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#23398;&#20064;&#20855;&#26377;&#21487;&#21464;&#26102;&#38388;&#27493;&#38271;&#30340;&#28436;&#21270;&#31639;&#31526;&#65292;&#26500;&#25104;&#33258;&#20027;&#31995;&#32479;&#30340;&#21322;&#32676;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#21322;&#32676;&#20013;&#30340;&#36816;&#31639;&#31526;&#65292;&#24182;&#24212;&#29992;&#20110;&#20351;&#29992;&#22312;&#19981;&#21516;&#26102;&#38388;&#28382;&#21518;&#19979;&#25910;&#38598;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#23545;&#26410;&#30693;&#33258;&#20027;&#21160;&#21147;&#31995;&#32479;&#36827;&#34892;&#24314;&#27169;&#12290;&#26412;&#25991;&#26159;&#20043;&#21069;&#27969;&#22270;&#23398;&#20064;(FML)&#24037;&#20316;&#30340;&#32493;&#38598;&#65292;&#35813;&#24037;&#20316;&#20027;&#35201;&#38598;&#20013;&#22312;&#23398;&#20064;&#20855;&#26377;&#22266;&#23450;&#26102;&#38388;&#27493;&#38271;&#30340;&#21333;&#19968;&#28436;&#21270;&#31639;&#31526;&#12290;&#26412;&#25991;&#26088;&#22312;&#23398;&#20064;&#19968;&#26063;&#20855;&#26377;&#21487;&#21464;&#26102;&#38388;&#27493;&#38271;&#30340;&#28436;&#21270;&#31639;&#31526;&#65292;&#26500;&#25104;&#33258;&#20027;&#31995;&#32479;&#30340;&#21322;&#32676;&#12290;&#21322;&#32676;&#24615;&#36136;&#23545;&#20110;&#32852;&#31995;&#31995;&#32479;&#22312;&#19981;&#21516;&#26102;&#38388;&#23610;&#24230;&#19978;&#30340;&#28436;&#21270;&#34892;&#20026;&#38750;&#24120;&#37325;&#35201;&#65292;&#20294;&#22312;&#20197;&#21069;&#30340;&#30740;&#31350;&#20013;&#27809;&#26377;&#32771;&#34385;&#21040;&#36825;&#19968;&#28857;&#12290;&#25105;&#20204;&#39318;&#27425;&#25552;&#20986;&#20102;&#23558;&#21322;&#32676;&#24615;&#36136;&#23884;&#20837;&#25968;&#25454;&#39537;&#21160;&#23398;&#20064;&#36807;&#31243;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a novel deep learning approach for learning operators in semigroup, with applications to modeling unknown autonomous dynamical systems using time series data collected at varied time lags. It is a sequel to the previous flow map learning (FML) works [T. Qin, K. Wu, and D. Xiu, J. Comput. Phys., 395:620--635, 2019], [K. Wu and D. Xiu, J. Comput. Phys., 408:109307, 2020], and [Z. Chen, V. Churchill, K. Wu, and D. Xiu, J. Comput. Phys., 449:110782, 2022], which focused on learning single evolution operator with a fixed time step. This paper aims to learn a family of evolution operators with variable time steps, which constitute a semigroup for an autonomous system. The semigroup property is very crucial and links the system's evolutionary behaviors across varying time scales, but it was not considered in the previous works. We propose for the first time a framework of embedding the semigroup property into the data-driven learning process, through a novel neural network
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#27169;&#22411;&#20272;&#35745;&#30340;&#40065;&#26834;MDPs&#31639;&#27861;&#65292;&#36890;&#36807;&#23558;&#21407;&#22987;&#38382;&#39064;&#36716;&#21270;&#20026;&#21478;&#19968;&#31181;&#24418;&#24335;&#65292;&#24182;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#26041;&#27861;&#27714;&#35299;&#65292;&#20174;&#32780;&#21435;&#38500;&#20102;&#23545;&#20248;&#21270;&#22120;&#30340;&#20381;&#36182;&#12290;</title><link>http://arxiv.org/abs/2302.01248</link><description>&lt;p&gt;
&#26080;&#38656;&#27169;&#22411;&#20272;&#35745;&#30340;&#40065;&#26834;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Robust Markov Decision Processes without Model Estimation. (arXiv:2302.01248v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.01248
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#27169;&#22411;&#20272;&#35745;&#30340;&#40065;&#26834;MDPs&#31639;&#27861;&#65292;&#36890;&#36807;&#23558;&#21407;&#22987;&#38382;&#39064;&#36716;&#21270;&#20026;&#21478;&#19968;&#31181;&#24418;&#24335;&#65292;&#24182;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#26041;&#27861;&#27714;&#35299;&#65292;&#20174;&#32780;&#21435;&#38500;&#20102;&#23545;&#20248;&#21270;&#22120;&#30340;&#20381;&#36182;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#40065;&#26834;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#22312;&#23398;&#20064;&#19968;&#20010;&#23545;&#29615;&#22659;&#21464;&#21270;&#19981;&#25935;&#24863;&#30340;&#40065;&#26834;&#31574;&#30053;&#26041;&#38754;&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#30446;&#21069;&#26377;&#36234;&#26469;&#36234;&#22810;&#30340;&#24037;&#20316;&#20998;&#26512;&#40065;&#26834;MDPs&#30340;&#37319;&#26679;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#24212;&#29992;&#40065;&#26834;MDPs&#23384;&#22312;&#20004;&#20010;&#20027;&#35201;&#38556;&#30861;&#12290;&#39318;&#20808;&#65292;&#22823;&#22810;&#25968;&#24037;&#20316;&#37117;&#26159;&#22312;&#27169;&#22411;&#20026;&#22522;&#30784;&#30340;&#24773;&#20917;&#19979;&#30740;&#31350;&#40065;&#26834;MDPs&#65292;&#20854;&#20013;&#36716;&#31227;&#27010;&#29575;&#38656;&#35201;&#36827;&#34892;&#20272;&#35745;&#65292;&#38656;&#35201;&#22823;&#37327;&#30340;&#35760;&#24518;&#65288;O(|S|&#178;|A|)&#65289;&#12290;&#20854;&#27425;&#65292;&#20043;&#21069;&#30340;&#24037;&#20316;&#36890;&#24120;&#20551;&#35774;&#23384;&#22312;&#19968;&#20010;&#24378;&#22823;&#30340;&#20248;&#21270;&#22120;&#26469;&#33719;&#24471;&#26368;&#20248;&#35299;&#65292;&#29992;&#20316;&#35299;&#20915;&#40065;&#26834;MDPs&#30340;&#20013;&#38388;&#27493;&#39588;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#36890;&#24120;&#24182;&#19981;&#23384;&#22312;&#36825;&#26679;&#30340;&#20248;&#21270;&#22120;&#12290;&#20026;&#20102;&#21435;&#38500;&#20248;&#21270;&#22120;&#30340;&#20381;&#36182;&#65292;&#25105;&#20204;&#23558;&#21407;&#22987;&#30340;&#40065;&#26834;MDPs&#36716;&#21270;&#20026;&#21478;&#19968;&#31181;&#24418;&#24335;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#26041;&#27861;&#26469;&#27714;&#35299;&#40065;&#26834;MDPs&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#26367;&#20195;&#24418;&#24335;&#20173;&#28982;&#20855;&#26377;&#31867;&#20284;&#30340;&#20316;&#29992;&#12290;&#36890;&#36807;&#36825;&#31181;&#26032;&#30340;&#20844;&#24335;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#37319;&#26679;&#26377;&#25928;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#40065;&#26834;MDPs&#12290;
&lt;/p&gt;
&lt;p&gt;
Robust Markov Decision Processes (MDPs) are receiving much attention in learning a robust policy which is less sensitive to environment changes. There are an increasing number of works analyzing sample-efficiency of robust MDPs. However, there are two major barriers to applying robust MDPs in practice. First, most works study robust MDPs in a model-based regime, where the transition probability needs to be estimated and requires a large amount of memories $\mathcal{O}(|\mathcal{S}|^2|\mathcal{A}|)$. Second, prior work typically assumes a strong oracle to obtain the optimal solution as an intermediate step to solve robust MDPs. However, in practice, such an oracle does not exist usually. To remove the oracle, we transform the original robust MDPs into an alternative form, which allows us to use stochastic gradient methods to solve the robust MDPs. Moreover, we prove the alternative form still plays a similar role as the original form. With this new formulation, we devise a sample-effici
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;Neyman-Scott&#36807;&#31243;&#65288;NSPs&#65289;&#21644;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#28151;&#21512;&#27169;&#22411;&#65288;DPMM&#65289;&#20043;&#38388;&#30340;&#26032;&#39062;&#32852;&#31995;&#65292;&#24182;&#25506;&#35752;&#20102;NSP&#22312;&#26102;&#31354;&#25968;&#25454;&#24314;&#27169;&#20013;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2201.05044</link><description>&lt;p&gt;
&#36890;&#36807;&#19982;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#28151;&#21512;&#27169;&#22411;&#30340;&#32852;&#31995;&#65292;&#20351;&#29992;Neyman-Scott&#36807;&#31243;&#36827;&#34892;&#26102;&#31354;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Spatiotemporal Clustering with Neyman-Scott Processes via Connections to Bayesian Nonparametric Mixture Models. (arXiv:2201.05044v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.05044
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;Neyman-Scott&#36807;&#31243;&#65288;NSPs&#65289;&#21644;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#28151;&#21512;&#27169;&#22411;&#65288;DPMM&#65289;&#20043;&#38388;&#30340;&#26032;&#39062;&#32852;&#31995;&#65292;&#24182;&#25506;&#35752;&#20102;NSP&#22312;&#26102;&#31354;&#25968;&#25454;&#24314;&#27169;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Neyman-Scott&#36807;&#31243;&#65288;NSPs&#65289;&#26159;&#29983;&#25104;&#26102;&#38388;&#25110;&#31354;&#38388;&#20013;&#28857;&#31751;&#30340;&#28857;&#36807;&#31243;&#27169;&#22411;&#12290;&#23427;&#20204;&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#24191;&#27867;&#29616;&#35937;&#30340;&#33258;&#28982;&#27169;&#22411;&#65292;&#20174;&#31070;&#32463;&#33033;&#20914;&#24207;&#21015;&#21040;&#25991;&#26723;&#27969;&#12290;&#32858;&#31867;&#23646;&#24615;&#26159;&#36890;&#36807;&#21452;&#37325;&#38543;&#26426;&#20844;&#24335;&#23454;&#29616;&#30340;&#65306;&#39318;&#20808;&#65292;&#20174;&#27850;&#26494;&#36807;&#31243;&#20013;&#32472;&#21046;&#19968;&#32452;&#28508;&#22312;&#20107;&#20214;&#65307;&#28982;&#21518;&#65292;&#27599;&#20010;&#28508;&#22312;&#20107;&#20214;&#26681;&#25454;&#21478;&#19968;&#20010;&#27850;&#26494;&#36807;&#31243;&#29983;&#25104;&#19968;&#32452;&#35266;&#27979;&#25968;&#25454;&#28857;&#12290;&#36825;&#20010;&#32467;&#26500;&#31867;&#20284;&#20110;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#28151;&#21512;&#27169;&#22411;&#65292;&#22914;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#28151;&#21512;&#27169;&#22411;&#65288;DPMM&#65289;&#65292;&#20854;&#20013;&#28508;&#22312;&#20107;&#20214;&#65288;&#21363;&#31751;&#65289;&#30340;&#25968;&#37327;&#26159;&#19968;&#20010;&#38543;&#26426;&#21464;&#37327;&#65292;&#20294;&#28857;&#36807;&#31243;&#30340;&#26500;&#36896;&#20351;&#24471;NSP&#29305;&#21035;&#36866;&#21512;&#20110;&#24314;&#27169;&#26102;&#31354;&#25968;&#25454;&#12290;&#34429;&#28982;&#20026;DPMM&#24320;&#21457;&#20102;&#35768;&#22810;&#19987;&#38376;&#31639;&#27861;&#65292;&#20294;&#30456;&#23545;&#36739;&#23569;&#30340;&#24037;&#20316;&#38598;&#20013;&#22312;NSP&#30340;&#25512;&#26029;&#19978;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;NSP&#19982;DPMM&#20043;&#38388;&#30340;&#26032;&#39062;&#32852;&#31995;&#65292;&#20851;&#38190;&#30340;&#36830;&#25509;&#26159;&#31532;&#19977;&#31867;&#36125;&#21494;&#26031;&#28151;&#21512;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Neyman-Scott processes (NSPs) are point process models that generate clusters of points in time or space. They are natural models for a wide range of phenomena, ranging from neural spike trains to document streams. The clustering property is achieved via a doubly stochastic formulation: first, a set of latent events is drawn from a Poisson process; then, each latent event generates a set of observed data points according to another Poisson process. This construction is similar to Bayesian nonparametric mixture models like the Dirichlet process mixture model (DPMM) in that the number of latent events (i.e. clusters) is a random variable, but the point process formulation makes the NSP especially well suited to modeling spatiotemporal data. While many specialized algorithms have been developed for DPMMs, comparatively fewer works have focused on inference in NSPs. Here, we present novel connections between NSPs and DPMMs, with the key link being a third class of Bayesian mixture models c
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#22238;&#24402;&#20219;&#21153;&#20013;&#30340;&#31163;&#32676;&#26679;&#26412;&#26816;&#27979;&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#65292;&#21457;&#29616;&#36890;&#36807;&#23398;&#20064;&#22810;&#26679;&#30340;&#39044;&#27979;&#22120;&#21487;&#20197;&#20272;&#35745;&#26032;&#35266;&#27979;&#23454;&#20363;&#30340;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#65292;&#20294;&#21442;&#25968;&#30340;&#22810;&#26679;&#24615;&#24182;&#19981;&#19968;&#23450;&#33021;&#36716;&#21270;&#20026;&#39044;&#27979;&#22120;&#30340;&#22810;&#26679;&#24615;&#12290;</title><link>http://arxiv.org/abs/2010.12995</link><description>&lt;p&gt;
&#22238;&#24402;&#20219;&#21153;&#20013;&#30340;&#31163;&#32676;&#26679;&#26412;&#26816;&#27979;&#65306;&#21442;&#25968;&#19982;&#39044;&#27979;&#22120;&#29109;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Out-of-distribution detection for regression tasks: parameter versus predictor entropy. (arXiv:2010.12995v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2010.12995
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#22238;&#24402;&#20219;&#21153;&#20013;&#30340;&#31163;&#32676;&#26679;&#26412;&#26816;&#27979;&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#65292;&#21457;&#29616;&#36890;&#36807;&#23398;&#20064;&#22810;&#26679;&#30340;&#39044;&#27979;&#22120;&#21487;&#20197;&#20272;&#35745;&#26032;&#35266;&#27979;&#23454;&#20363;&#30340;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#65292;&#20294;&#21442;&#25968;&#30340;&#22810;&#26679;&#24615;&#24182;&#19981;&#19968;&#23450;&#33021;&#36716;&#21270;&#20026;&#39044;&#27979;&#22120;&#30340;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26469;&#35828;&#65292;&#26816;&#27979;&#26679;&#26412;&#19982;&#35757;&#32451;&#26679;&#26412;&#30456;&#36317;&#22826;&#36828;&#26102;&#33267;&#20851;&#37325;&#35201;&#65292;&#36825;&#34987;&#31216;&#20026;&#31163;&#32676;&#26679;&#26412;&#65288;OOD&#65289;&#26816;&#27979;&#12290;&#23545;&#20110;&#31070;&#32463;&#32593;&#32476;&#32780;&#35328;&#65292;&#19968;&#31181;&#22788;&#29702;&#36825;&#20010;&#20219;&#21153;&#30340;&#26041;&#27861;&#26159;&#23398;&#20064;&#22810;&#26679;&#30340;&#39044;&#27979;&#22120;&#65292;&#36825;&#20123;&#39044;&#27979;&#22120;&#37117;&#33021;&#35299;&#37322;&#35757;&#32451;&#25968;&#25454;&#12290;&#36825;&#20123;&#20449;&#24687;&#21487;&#20197;&#29992;&#26469;&#20272;&#35745;&#26032;&#35266;&#27979;&#23454;&#20363;&#30340;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#65292;&#36890;&#36807;&#39044;&#27979;&#32467;&#26524;&#30340;&#19981;&#19968;&#33268;&#24615;&#26469;&#34913;&#37327;&#12290;&#35780;&#20272;&#21644;&#35748;&#35777;&#26041;&#27861;&#26816;&#27979;OOD&#30340;&#33021;&#21147;&#38656;&#35201;&#25351;&#23450;&#22312;&#37096;&#32626;&#20013;&#21487;&#33021;&#21457;&#29983;&#20294;&#27809;&#26377;&#21487;&#29992;&#39044;&#27979;&#30340;&#23454;&#20363;&#12290;&#25105;&#20204;&#36873;&#25321;&#22238;&#24402;&#20219;&#21153;&#20316;&#20026;&#30740;&#31350;&#37325;&#28857;&#65292;&#22312;&#27492;&#20219;&#21153;&#20013;&#36873;&#25321;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#27934;&#23519;&#21147;&#30340;&#27169;&#22411;&#26469;&#34920;&#31034;OOD&#20998;&#24067;&#65292;&#24182;&#23545;&#21508;&#31181;&#26041;&#27861;&#22312;&#21306;&#20998;OOD&#26679;&#26412;&#21644;&#25968;&#25454;&#20013;&#30340;&#33021;&#21147;&#36827;&#34892;&#23454;&#35777;&#35780;&#20272;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#35777;&#25454;&#34920;&#26126;&#65292;&#21442;&#25968;&#30340;&#22810;&#26679;&#24615;&#21487;&#33021;&#26080;&#27861;&#36716;&#21270;&#20026;&#39044;&#27979;&#22120;&#30340;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is crucial to detect when an instance lies downright too far from the training samples for the machine learning model to be trusted, a challenge known as out-of-distribution (OOD) detection. For neural networks, one approach to this task consists of learning a diversity of predictors that all can explain the training data. This information can be used to estimate the epistemic uncertainty at a given newly observed instance in terms of a measure of the disagreement of the predictions. Evaluation and certification of the ability of a method to detect OOD require specifying instances which are likely to occur in deployment yet on which no prediction is available. Focusing on regression tasks, we choose a simple yet insightful model for this OOD distribution and conduct an empirical evaluation of the ability of various methods to discriminate OOD samples from the data. Moreover, we exhibit evidence that a diversity of parameters may fail to translate to a diversity of predictors. Based 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22312;&#19981;&#23436;&#25972;&#30340;&#35266;&#23519;&#25968;&#25454;&#19979;&#23398;&#20064;&#20998;&#24067;&#40065;&#26834;&#30340;&#31574;&#30053;&#65292;&#36890;&#36807;&#24341;&#20837;&#31574;&#30053;&#35780;&#20272;&#36807;&#31243;&#21644;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#31867;&#22411;&#30340;&#20445;&#35777;&#65292;&#23454;&#29616;&#20102;&#38024;&#23545;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#29615;&#22659;&#36716;&#21464;&#30340;&#31574;&#30053;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2006.05630</link><description>&lt;p&gt;
&#20998;&#24067;&#40065;&#26834;&#30340;&#25209;&#27425;&#24773;&#22659;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Distributionally Robust Batch Contextual Bandits. (arXiv:2006.05630v7 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.05630
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22312;&#19981;&#23436;&#25972;&#30340;&#35266;&#23519;&#25968;&#25454;&#19979;&#23398;&#20064;&#20998;&#24067;&#40065;&#26834;&#30340;&#31574;&#30053;&#65292;&#36890;&#36807;&#24341;&#20837;&#31574;&#30053;&#35780;&#20272;&#36807;&#31243;&#21644;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#31867;&#22411;&#30340;&#20445;&#35777;&#65292;&#23454;&#29616;&#20102;&#38024;&#23545;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#29615;&#22659;&#36716;&#21464;&#30340;&#31574;&#30053;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#21382;&#21490;&#35266;&#23519;&#25968;&#25454;&#36827;&#34892;&#31574;&#30053;&#23398;&#20064;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#38382;&#39064;&#65292;&#24050;&#32463;&#22312;&#24191;&#27867;&#30340;&#24212;&#29992;&#20013;&#24471;&#21040;&#24212;&#29992;&#12290;&#20363;&#22914;&#65292;&#36873;&#25321;&#21521;&#23458;&#25143;&#21457;&#36865;&#30340;&#20248;&#24800;&#12289;&#20215;&#26684;&#12289;&#24191;&#21578;&#65292;&#20197;&#21450;&#36873;&#25321;&#32473;&#24739;&#32773;&#24320;&#20855;&#21738;&#31181;&#33647;&#29289;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#25991;&#29486;&#22522;&#20110;&#19968;&#20010;&#20851;&#38190;&#20551;&#35774;&#65292;&#21363;&#23398;&#20064;&#21040;&#30340;&#31574;&#30053;&#23558;&#34987;&#37096;&#32626;&#21040;&#30340;&#26410;&#26469;&#29615;&#22659;&#19982;&#29983;&#25104;&#25968;&#25454;&#30340;&#36807;&#21435;&#29615;&#22659;&#30456;&#21516;&#65292;&#32780;&#36825;&#20010;&#20551;&#35774;&#24448;&#24448;&#26159;&#38169;&#35823;&#30340;&#25110;&#32773;&#36807;&#20110;&#31895;&#30053;&#30340;&#36817;&#20284;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25918;&#23485;&#20102;&#36825;&#20010;&#20551;&#35774;&#65292;&#24182;&#26088;&#22312;&#23398;&#20064;&#19968;&#20010;&#20855;&#26377;&#19981;&#23436;&#25972;&#35266;&#23519;&#25968;&#25454;&#30340;&#20998;&#24067;&#40065;&#26834;&#31574;&#30053;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#20010;&#31574;&#30053;&#35780;&#20272;&#36807;&#31243;&#65292;&#20197;&#35780;&#20272;&#31574;&#30053;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#29615;&#22659;&#36716;&#21464;&#19979;&#30340;&#34920;&#29616;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#36825;&#20010;&#25552;&#20986;&#30340;&#31574;&#30053;&#35780;&#20272;&#26041;&#26696;&#30340;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#31867;&#22411;&#30340;&#20445;&#35777;&#12290;&#21033;&#29992;&#36825;&#20010;&#35780;&#20272;&#26041;&#26696;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#33021;&#22815;&#23398;&#20064;&#19968;&#20010;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Policy learning using historical observational data is an important problem that has found widespread applications. Examples include selecting offers, prices, advertisements to send to customers, as well as selecting which medication to prescribe to a patient. However, existing literature rests on the crucial assumption that the future environment where the learned policy will be deployed is the same as the past environment that has generated the data -- an assumption that is often false or too coarse an approximation. In this paper, we lift this assumption and aim to learn a distributionally robust policy with incomplete observational data. We first present a policy evaluation procedure that allows us to assess how well the policy does under the worst-case environment shift. We then establish a central limit theorem type guarantee for this proposed policy evaluation scheme. Leveraging this evaluation scheme, we further propose a novel learning algorithm that is able to learn a policy 
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#35777;&#21644;&#23454;&#20363;&#20381;&#36182;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#28151;&#21512;&#26102;&#38388;&#12290;&#25105;&#20204;&#22522;&#20110;&#25910;&#32553;&#31995;&#25968;&#26469;&#20272;&#35745;&#28151;&#21512;&#26102;&#38388;&#65292;&#35813;&#31995;&#25968;&#33021;&#22815;&#25511;&#21046;&#28151;&#21512;&#26102;&#38388;&#30452;&#21040;&#24378;&#30340;&#26222;&#36941;&#24120;&#25968;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#38750;&#21487;&#36870;&#38142;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#35745;&#31639;&#26356;&#23481;&#26131;&#19988;&#32622;&#20449;&#21306;&#38388;&#26356;&#31934;&#30830;&#65292;&#36824;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#26512;&#26041;&#27861;&#26469;&#32771;&#34385;&#36716;&#31227;&#30697;&#38453;&#30340;&#38468;&#21152;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/1912.06845</link><description>&lt;p&gt;
&#39532;&#23572;&#21487;&#22827;&#38142;&#21644;&#28151;&#21512;&#26102;&#38388;&#30340;&#23454;&#35777;&#21644;&#23454;&#20363;&#20381;&#36182;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Empirical and Instance-Dependent Estimation of Markov Chain and Mixing Time. (arXiv:1912.06845v4 [math.PR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1912.06845
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#35777;&#21644;&#23454;&#20363;&#20381;&#36182;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#28151;&#21512;&#26102;&#38388;&#12290;&#25105;&#20204;&#22522;&#20110;&#25910;&#32553;&#31995;&#25968;&#26469;&#20272;&#35745;&#28151;&#21512;&#26102;&#38388;&#65292;&#35813;&#31995;&#25968;&#33021;&#22815;&#25511;&#21046;&#28151;&#21512;&#26102;&#38388;&#30452;&#21040;&#24378;&#30340;&#26222;&#36941;&#24120;&#25968;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#38750;&#21487;&#36870;&#38142;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#35745;&#31639;&#26356;&#23481;&#26131;&#19988;&#32622;&#20449;&#21306;&#38388;&#26356;&#31934;&#30830;&#65292;&#36824;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#26512;&#26041;&#27861;&#26469;&#32771;&#34385;&#36716;&#31227;&#30697;&#38453;&#30340;&#38468;&#21152;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35299;&#20915;&#20102;&#20174;&#21333;&#20010;&#35266;&#27979;&#36712;&#36857;&#20272;&#35745;&#39532;&#23572;&#21487;&#22827;&#38142;&#28151;&#21512;&#26102;&#38388;&#30340;&#38382;&#39064;&#12290;&#19982;&#22823;&#22810;&#25968;&#20808;&#21069;&#20351;&#29992;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26041;&#27861;&#20272;&#35745;&#35889;&#32570;&#21475;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#25105;&#20204;&#36873;&#25321;&#37319;&#29992;&#22522;&#20110;&#24635;&#21464;&#24046;&#25910;&#32553;&#30340;&#26041;&#27861;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#20272;&#35745;&#20102;Wolfer [2020]&#20013;&#24341;&#20837;&#30340;&#25910;&#32553;&#31995;&#25968;&#65292;&#21463;&#21040;Dobrushin&#30340;&#21551;&#21457;&#12290;&#19982;&#35889;&#32570;&#21475;&#19981;&#21516;&#65292;&#36825;&#20010;&#25968;&#37327;&#25511;&#21046;&#30528;&#28151;&#21512;&#26102;&#38388;&#30452;&#21040;&#24378;&#30340;&#26222;&#36941;&#24120;&#25968;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#38750;&#21487;&#36870;&#38142;&#12290;&#25105;&#20204;&#25913;&#36827;&#20102;&#29616;&#26377;&#30340;&#23436;&#20840;&#20381;&#36182;&#25968;&#25454;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#36825;&#20123;&#21306;&#38388;&#27604;&#35889;&#30456;&#20851;&#25968;&#37327;&#26356;&#23481;&#26131;&#35745;&#31639;&#19988;&#26356;&#34180;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#21033;&#29992;&#20851;&#20110;&#36716;&#31227;&#30697;&#38453;&#30340;&#38468;&#21152;&#20449;&#24687;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#36229;&#36807;&#26368;&#22351;&#24773;&#20917;&#20998;&#26512;&#30340;&#26032;&#26041;&#27861;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#38024;&#23545;&#35825;&#23548;&#22343;&#21248;&#33539;&#25968;&#21644;&#19968;&#20123;&#28151;&#21512;&#23646;&#24615;&#65292;&#23548;&#20986;&#19982;&#30697;&#38453;&#20272;&#35745;&#26377;&#20851;&#30340;&#23454;&#20363;&#20381;&#36182;&#30340;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We address the problem of estimating the mixing time of a Markov chain from a single trajectory of observations. Unlike most previous works which employed Hilbert space methods to estimate spectral gaps, we opt for an approach based on contraction with respect to total variation. Specifically, we estimate the contraction coefficient introduced in Wolfer [2020], inspired from Dobrushin's. This quantity, unlike the spectral gap, controls the mixing time up to strong universal constants and remains applicable to non-reversible chains. We improve existing fully data-dependent confidence intervals around this contraction coefficient, which are both easier to compute and thinner than spectral counterparts. Furthermore, we introduce a novel analysis beyond the worst-case scenario by leveraging additional information about the transition matrix. This allows us to derive instance-dependent rates for estimating the matrix with respect to the induced uniform norm, and some of its mixing propertie
&lt;/p&gt;</description></item></channel></rss>