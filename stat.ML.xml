<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#27169;&#22411;&#36873;&#25321;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26681;&#25454;&#19981;&#21516;&#30340;&#29366;&#24577;&#36873;&#25321;&#26368;&#20248;&#30340;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#23545;&#21160;&#24577;&#35268;&#21010;&#38382;&#39064;&#36827;&#34892;&#36817;&#20284;&#21644;&#20272;&#35745;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#37325;&#26032;&#24179;&#34913;&#25104;&#26412;&#19979;&#20999;&#25442;&#25237;&#36164;&#32452;&#21512;&#27169;&#22411;&#26102;&#65292;&#20351;&#29992;&#23439;&#35266;&#32463;&#27982;&#20449;&#24687;&#30340;&#24615;&#33021;&#20248;&#20110;&#20107;&#21518;&#36873;&#25321;&#26368;&#20339;&#25237;&#36164;&#32452;&#21512;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2307.04754</link><description>&lt;p&gt;
&#21160;&#20316;&#29366;&#24577;&#30456;&#20851;&#30340;&#21160;&#24577;&#27169;&#22411;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Action-State Dependent Dynamic Model Selection. (arXiv:2307.04754v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04754
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#27169;&#22411;&#36873;&#25321;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26681;&#25454;&#19981;&#21516;&#30340;&#29366;&#24577;&#36873;&#25321;&#26368;&#20248;&#30340;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#23545;&#21160;&#24577;&#35268;&#21010;&#38382;&#39064;&#36827;&#34892;&#36817;&#20284;&#21644;&#20272;&#35745;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#37325;&#26032;&#24179;&#34913;&#25104;&#26412;&#19979;&#20999;&#25442;&#25237;&#36164;&#32452;&#21512;&#27169;&#22411;&#26102;&#65292;&#20351;&#29992;&#23439;&#35266;&#32463;&#27982;&#20449;&#24687;&#30340;&#24615;&#33021;&#20248;&#20110;&#20107;&#21518;&#36873;&#25321;&#26368;&#20339;&#25237;&#36164;&#32452;&#21512;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19990;&#30028;&#30340;&#26576;&#20123;&#29366;&#24577;&#19979;&#65292;&#22810;&#20010;&#27169;&#22411;&#20013;&#30340;&#19968;&#20010;&#21487;&#33021;&#21482;&#22312;&#20854;&#20013;&#26576;&#20123;&#29366;&#24577;&#19979;&#34920;&#29616;&#26368;&#20339;&#12290;&#32780;&#22312;&#27169;&#22411;&#20043;&#38388;&#30340;&#20999;&#25442;&#20063;&#21487;&#33021;&#20195;&#20215;&#39640;&#26114;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#23547;&#25214;&#19968;&#31181;&#33021;&#22815;&#21160;&#24577;&#36873;&#25321;&#27169;&#22411;&#30340;&#36807;&#31243;&#38656;&#35201;&#35299;&#20915;&#19968;&#20010;&#22797;&#26434;&#30340;&#20272;&#35745;&#38382;&#39064;&#21644;&#21160;&#24577;&#35268;&#21010;&#38382;&#39064;&#12290;&#26412;&#25991;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#26469;&#20174;&#25968;&#25454;&#20013;&#36817;&#20284;&#21644;&#20272;&#35745;&#36825;&#20010;&#21160;&#24577;&#35268;&#21010;&#38382;&#39064;&#30340;&#26368;&#20248;&#35299;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#19968;&#33268;&#22320;&#20272;&#35745;&#20986;&#26681;&#25454;&#19968;&#32452;&#21327;&#21464;&#37327;&#36873;&#25321;&#19981;&#21516;&#27169;&#22411;&#30340;&#26368;&#20248;&#31574;&#30053;&#12290;&#20855;&#20307;&#24212;&#29992;&#26041;&#38754;&#65292;&#20363;&#22914;&#22312;&#37325;&#26032;&#24179;&#34913;&#25104;&#26412;&#19979;&#20999;&#25442;&#19981;&#21516;&#25237;&#36164;&#32452;&#21512;&#27169;&#22411;&#65292;&#20351;&#29992;&#23439;&#35266;&#32463;&#27982;&#20449;&#24687;&#36827;&#34892;&#20915;&#31574;&#12290;&#36890;&#36807;&#19968;&#32452;&#23439;&#35266;&#32463;&#27982;&#21464;&#37327;&#21644;&#20215;&#26684;&#25968;&#25454;&#65292;&#32463;&#39564;&#24212;&#29992;&#20110;&#19978;&#36848;&#25237;&#36164;&#32452;&#21512;&#38382;&#39064;&#34920;&#29616;&#20986;&#27604;&#20107;&#21518;&#36873;&#25321;&#26368;&#20339;&#25237;&#36164;&#32452;&#21512;&#27169;&#22411;&#26356;&#20248;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
A model among many may only be best under certain states of the world. Switching from a model to another can also be costly. Finding a procedure to dynamically choose a model in these circumstances requires to solve a complex estimation procedure and a dynamic programming problem. A Reinforcement learning algorithm is used to approximate and estimate from the data the optimal solution to this dynamic programming problem. The algorithm is shown to consistently estimate the optimal policy that may choose different models based on a set of covariates. A typical example is the one of switching between different portfolio models under rebalancing costs, using macroeconomic information. Using a set of macroeconomic variables and price data, an empirical application to the aforementioned portfolio problem shows superior performance to choosing the best portfolio model with hindsight.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21010;&#20998;&#12289;&#35780;&#20272;&#21644;&#32454;&#21270;&#30340;&#26041;&#27861;&#26469;&#25913;&#21892;&#25991;&#26412;&#21040;&#22270;&#20687;&#23545;&#40784;&#12290;&#36890;&#36807;&#20998;&#35299;&#22797;&#26434;&#30340;&#25552;&#31034;&#24182;&#20351;&#29992;VQA&#27169;&#22411;&#36827;&#34892;&#27979;&#37327;&#65292;&#26368;&#32456;&#24471;&#21040;&#25991;&#26412;&#21040;&#22270;&#20687;&#30340;&#23545;&#40784;&#20998;&#25968;&#12290;</title><link>http://arxiv.org/abs/2307.04749</link><description>&lt;p&gt;
&#21010;&#20998;&#12289;&#35780;&#20272;&#21644;&#32454;&#21270;&#65306;&#36890;&#36807;&#36845;&#20195;VQA&#21453;&#39304;&#35780;&#20272;&#21644;&#25913;&#21892;&#25991;&#26412;&#21040;&#22270;&#20687;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Divide, Evaluate, and Refine: Evaluating and Improving Text-to-Image Alignment with Iterative VQA Feedback. (arXiv:2307.04749v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04749
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21010;&#20998;&#12289;&#35780;&#20272;&#21644;&#32454;&#21270;&#30340;&#26041;&#27861;&#26469;&#25913;&#21892;&#25991;&#26412;&#21040;&#22270;&#20687;&#23545;&#40784;&#12290;&#36890;&#36807;&#20998;&#35299;&#22797;&#26434;&#30340;&#25552;&#31034;&#24182;&#20351;&#29992;VQA&#27169;&#22411;&#36827;&#34892;&#27979;&#37327;&#65292;&#26368;&#32456;&#24471;&#21040;&#25991;&#26412;&#21040;&#22270;&#20687;&#30340;&#23545;&#40784;&#20998;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#30340;&#26368;&#26032;&#20986;&#29616;&#65292;&#20197;&#25991;&#26412;&#20026;&#26465;&#20214;&#30340;&#22270;&#20687;&#29983;&#25104;&#39046;&#22495;&#21462;&#24471;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#20855;&#26377;&#26174;&#33879;&#24615;&#65292;&#20294;&#26159;&#38543;&#30528;&#25991;&#26412;&#36755;&#20837;&#30340;&#22797;&#26434;&#24615;&#22686;&#21152;&#65292;&#26368;&#20808;&#36827;&#30340;&#25193;&#25955;&#27169;&#22411;&#20173;&#21487;&#33021;&#26080;&#27861;&#29983;&#25104;&#20934;&#30830;&#20256;&#36798;&#32473;&#23450;&#25552;&#31034;&#35821;&#20041;&#30340;&#22270;&#20687;&#12290;&#27492;&#22806;&#65292;&#35266;&#23519;&#21040;&#36825;&#31181;&#19981;&#23545;&#40784;&#24448;&#24448;&#34987;&#39044;&#35757;&#32451;&#30340;&#22810;&#27169;&#22411;&#65288;&#22914;CLIP&#65289;&#26410;&#33021;&#26816;&#27979;&#21040;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#19968;&#31181;&#31616;&#21333;&#19988;&#26377;&#25928;&#30340;&#20998;&#35299;&#26041;&#27861;&#26469;&#35780;&#20272;&#21644;&#25913;&#21892;&#25991;&#26412;&#21040;&#22270;&#20687;&#23545;&#40784;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#24341;&#20837;&#20102;&#19968;&#31181;&#20998;&#35299;&#23545;&#40784;&#20998;&#25968;&#65292;&#23427;&#23558;&#22797;&#26434;&#25552;&#31034;&#20998;&#35299;&#20026;&#19968;&#32452;&#19981;&#30456;&#20132;&#30340;&#26029;&#35328;&#12290;&#28982;&#21518;&#65292;&#20351;&#29992;VQA&#27169;&#22411;&#26469;&#27979;&#37327;&#27599;&#20010;&#26029;&#35328;&#19982;&#29983;&#25104;&#30340;&#22270;&#20687;&#30340;&#23545;&#40784;&#24773;&#20917;&#12290;&#26368;&#21518;&#65292;&#23558;&#19981;&#21516;&#26029;&#35328;&#30340;&#23545;&#40784;&#20998;&#25968;&#21512;&#24182;&#21518;&#65292;&#24471;&#21040;&#26368;&#32456;&#30340;&#25991;&#26412;&#21040;&#22270;&#20687;&#23545;&#40784;&#20998;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
The field of text-conditioned image generation has made unparalleled progress with the recent advent of latent diffusion models. While remarkable, as the complexity of given text input increases, the state-of-the-art diffusion models may still fail in generating images which accurately convey the semantics of the given prompt. Furthermore, it has been observed that such misalignments are often left undetected by pretrained multi-modal models such as CLIP. To address these problems, in this paper we explore a simple yet effective decompositional approach towards both evaluation and improvement of text-to-image alignment. In particular, we first introduce a Decompositional-Alignment-Score which given a complex prompt decomposes it into a set of disjoint assertions. The alignment of each assertion with generated images is then measured using a VQA model. Finally, alignment scores for different assertions are combined aposteriori to give the final text-to-image alignment score. Experimenta
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26102;&#24207;&#39640;&#26031;&#36807;&#31243;&#30340;&#23398;&#20064;&#25511;&#21046;&#26041;&#27861;&#65292;&#36890;&#36807;&#25512;&#23548;&#39044;&#27979;&#35823;&#24046;&#36793;&#30028;&#20197;&#21450;&#19968;&#31181;&#22522;&#20110;&#20869;&#26680;&#30340;&#25968;&#25454;&#23494;&#24230;&#24230;&#37327;&#65292;&#23454;&#29616;&#20102;&#26102;&#21464;&#30340;&#36319;&#36394;&#31934;&#24230;&#20445;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#36319;&#36394;&#35823;&#24046;&#30340;&#28040;&#22833;&#12290;</title><link>http://arxiv.org/abs/2307.04415</link><description>&lt;p&gt;
&#22522;&#20110;&#26102;&#24207;&#39640;&#26031;&#36807;&#31243;&#30340;&#23398;&#20064;&#25511;&#21046;&#65292;&#23454;&#29616;&#28040;&#22833;&#30340;&#36319;&#36394;&#35823;&#24046;
&lt;/p&gt;
&lt;p&gt;
Episodic Gaussian Process-Based Learning Control with Vanishing Tracking Errors. (arXiv:2307.04415v1 [eess.SY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04415
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26102;&#24207;&#39640;&#26031;&#36807;&#31243;&#30340;&#23398;&#20064;&#25511;&#21046;&#26041;&#27861;&#65292;&#36890;&#36807;&#25512;&#23548;&#39044;&#27979;&#35823;&#24046;&#36793;&#30028;&#20197;&#21450;&#19968;&#31181;&#22522;&#20110;&#20869;&#26680;&#30340;&#25968;&#25454;&#23494;&#24230;&#24230;&#37327;&#65292;&#23454;&#29616;&#20102;&#26102;&#21464;&#30340;&#36319;&#36394;&#31934;&#24230;&#20445;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#36319;&#36394;&#35823;&#24046;&#30340;&#28040;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#25216;&#26415;&#31995;&#32479;&#30340;&#22797;&#26434;&#24615;&#22686;&#21152;&#65292;&#24448;&#24448;&#26080;&#27861;&#33719;&#24471;&#20934;&#30830;&#30340;&#31532;&#19968;&#21407;&#29702;&#27169;&#22411;&#12290;&#36890;&#36807;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#21487;&#20197;&#20174;&#27979;&#37327;&#25968;&#25454;&#20013;&#25512;&#26029;&#27169;&#22411;&#65292;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#29305;&#21035;&#36866;&#29992;&#20110;&#27492;&#30446;&#30340;&#65292;&#22240;&#20026;&#23427;&#20855;&#26377;&#39640;&#30340;&#25968;&#25454;&#25928;&#29575;&#21644;&#26126;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#34920;&#31034;&#65292;&#21487;&#20197;&#25512;&#23548;&#20986;&#39044;&#27979;&#35823;&#24046;&#36793;&#30028;&#12290;&#36825;&#20123;&#35823;&#24046;&#36793;&#30028;&#24050;&#34987;&#29992;&#20110;&#23637;&#31034;&#19981;&#21516;&#25511;&#21046;&#26041;&#27861;&#30340;&#36319;&#36394;&#31934;&#24230;&#20445;&#35777;&#65292;&#20294;&#20854;&#30452;&#25509;&#20381;&#36182;&#20110;&#35757;&#32451;&#25968;&#25454;&#36890;&#24120;&#19981;&#26126;&#30830;&#12290;&#25105;&#20204;&#36890;&#36807;&#25512;&#23548;&#22522;&#20110;&#36125;&#21494;&#26031;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#39044;&#27979;&#35823;&#24046;&#36793;&#30028;&#26469;&#35299;&#20915;&#27492;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20854;&#38543;&#30528;&#19968;&#31181;&#22522;&#20110;&#20869;&#26680;&#30340;&#25968;&#25454;&#23494;&#24230;&#24230;&#37327;&#30340;&#22686;&#38271;&#32780;&#20943;&#23567;&#12290;&#22522;&#20110;&#39044;&#27979;&#35823;&#24046;&#36793;&#30028;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23398;&#20064;&#21040;&#30340;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#20316;&#20026;&#26410;&#30693;&#38750;&#32447;&#24615;&#30340;&#21453;&#39304;&#34917;&#20607;&#65292;&#21487;&#20197;&#23454;&#29616;&#26102;&#21464;&#30340;&#36319;&#36394;&#31934;&#24230;&#20445;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#38543;&#30528;&#26102;&#38388;&#22686;&#21152;&#32780;&#28040;&#22833;&#30340;&#36319;&#36394;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Due to the increasing complexity of technical systems, accurate first principle models can often not be obtained. Supervised machine learning can mitigate this issue by inferring models from measurement data. Gaussian process regression is particularly well suited for this purpose due to its high data-efficiency and its explicit uncertainty representation, which allows the derivation of prediction error bounds. These error bounds have been exploited to show tracking accuracy guarantees for a variety of control approaches, but their direct dependency on the training data is generally unclear. We address this issue by deriving a Bayesian prediction error bound for GP regression, which we show to decay with the growth of a novel, kernel-based measure of data density. Based on the prediction error bound, we prove time-varying tracking accuracy guarantees for learned GP models used as feedback compensation of unknown nonlinearities, and show to achieve vanishing tracking error with increasi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#29305;&#24449;&#20998;&#24067;&#34987;&#38169;&#35823;&#20272;&#35745;&#25110;&#20272;&#35745;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#32806;&#21512;&#27169;&#22411;-X Knockoffs&#36807;&#31243;&#19982;&#36817;&#20284;Knockoffs&#36807;&#31243;&#65292;&#23454;&#29616;&#20102;&#22312;&#30446;&#26631;&#27700;&#24179;&#19978;&#30340;&#40065;&#26834;&#30340;FDR&#25110;FWER&#25511;&#21046;&#12290;</title><link>http://arxiv.org/abs/2307.04400</link><description>&lt;p&gt;
ARK: &#40065;&#26834;&#30340;&#32806;&#21512;&#22411;Robust Knockoffs&#25512;&#29702;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
ARK: Robust Knockoffs Inference with Coupling. (arXiv:2307.04400v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04400
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#29305;&#24449;&#20998;&#24067;&#34987;&#38169;&#35823;&#20272;&#35745;&#25110;&#20272;&#35745;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#32806;&#21512;&#27169;&#22411;-X Knockoffs&#36807;&#31243;&#19982;&#36817;&#20284;Knockoffs&#36807;&#31243;&#65292;&#23454;&#29616;&#20102;&#22312;&#30446;&#26631;&#27700;&#24179;&#19978;&#30340;&#40065;&#26834;&#30340;FDR&#25110;FWER&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#22312;&#29305;&#24449;&#20998;&#24067;&#34987;&#38169;&#35823;&#20272;&#35745;&#25110;&#20272;&#35745;&#30340;&#24773;&#20917;&#19979;&#65292;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;&#23454;&#38469;&#23454;&#29616;&#30340;&#36817;&#20284;Knockoffs&#31639;&#27861;&#30340;&#29305;&#24449;&#36873;&#25321;&#24615;&#33021;&#65292;&#20854;&#20013;&#25105;&#20204;&#23558;&#35813;&#31639;&#27861;&#31216;&#20026;&#36817;&#20284;Knockoffs&#65288;ARK&#65289;&#36807;&#31243;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#20851;&#38190;&#25216;&#26415;&#26159;&#23558;&#36817;&#20284;Knockoffs&#36807;&#31243;&#19982;&#27169;&#22411;-X Knockoffs&#36807;&#31243;&#32806;&#21512;&#65292;&#20197;&#20351;&#36825;&#20004;&#20010;&#36807;&#31243;&#20013;&#30340;&#38543;&#26426;&#21464;&#37327;&#22312;&#23454;&#29616;&#20013;&#25509;&#36817;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22914;&#26524;&#23384;&#22312;&#36825;&#26679;&#30340;&#32806;&#21512;&#27169;&#22411;-X Knockoffs&#36807;&#31243;&#65292;&#36817;&#20284;Knockoffs&#36807;&#31243;&#21487;&#20197;&#22312;&#30446;&#26631;&#27700;&#24179;&#19978;&#36798;&#21040;&#28176;&#36817;&#30340;FDR&#25110;FWER&#25511;&#21046;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19977;&#31181;&#20855;&#20307;&#30340;&#26500;&#24314;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the robustness of the model-X knockoffs framework with respect to the misspecified or estimated feature distribution. We achieve such a goal by theoretically studying the feature selection performance of a practically implemented knockoffs algorithm, which we name as the approximate knockoffs (ARK) procedure, under the measures of the false discovery rate (FDR) and family wise error rate (FWER). The approximate knockoffs procedure differs from the model-X knockoffs procedure only in that the former uses the misspecified or estimated feature distribution. A key technique in our theoretical analyses is to couple the approximate knockoffs procedure with the model-X knockoffs procedure so that random variables in these two procedures can be close in realizations. We prove that if such coupled model-X knockoffs procedure exists, the approximate knockoffs procedure can achieve the asymptotic FDR or FWER control at the target level. We showcase three specific constructions of s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21033;&#29992;&#31163;&#32447;&#25968;&#25454;&#38598;&#35774;&#35745;&#21333;&#19968;&#30340;&#38750;&#21453;&#24212;&#24615;&#31574;&#30053;&#36827;&#34892;&#25506;&#32034;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#23545;&#26368;&#32456;&#31574;&#30053;&#30340;&#36136;&#37327;&#36827;&#34892;&#20102;&#37327;&#21270;&#12290;</title><link>http://arxiv.org/abs/2307.04354</link><description>&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20013;&#21033;&#29992;&#31163;&#32447;&#25968;&#25454;&#36890;&#36807;&#23454;&#39564;&#35774;&#35745;&#36827;&#34892;&#31574;&#30053;&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
Policy Finetuning in Reinforcement Learning via Design of Experiments using Offline Data. (arXiv:2307.04354v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04354
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21033;&#29992;&#31163;&#32447;&#25968;&#25454;&#38598;&#35774;&#35745;&#21333;&#19968;&#30340;&#38750;&#21453;&#24212;&#24615;&#31574;&#30053;&#36827;&#34892;&#25506;&#32034;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#23545;&#26368;&#32456;&#31574;&#30053;&#30340;&#36136;&#37327;&#36827;&#34892;&#20102;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#30340;&#19968;&#20123;&#24212;&#29992;&#20013;&#65292;&#24050;&#32463;&#26377;&#19968;&#20221;&#39044;&#20808;&#25910;&#38598;&#22909;&#30340;&#32463;&#39564;&#25968;&#25454;&#38598;&#65292;&#20294;&#20063;&#21487;&#20197;&#33719;&#21462;&#19968;&#20123;&#39069;&#22806;&#30340;&#22312;&#32447;&#25968;&#25454;&#20197;&#24110;&#21161;&#25552;&#39640;&#31574;&#30053;&#30340;&#36136;&#37327;&#12290;&#28982;&#32780;&#65292;&#26356;&#20542;&#21521;&#20110;&#20351;&#29992;&#21333;&#19968;&#30340;&#38750;&#21453;&#24212;&#24615;&#25506;&#32034;&#31574;&#30053;&#25910;&#38598;&#39069;&#22806;&#25968;&#25454;&#65292;&#20197;&#36991;&#20813;&#20999;&#25442;&#31574;&#30053;&#24102;&#26469;&#30340;&#24037;&#31243;&#25104;&#26412;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20855;&#26377;&#21487;&#35777;&#26126;&#20445;&#35777;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#21033;&#29992;&#31163;&#32447;&#25968;&#25454;&#38598;&#35774;&#35745;&#19968;&#20010;&#21333;&#19968;&#30340;&#38750;&#21453;&#24212;&#24615;&#31574;&#30053;&#36827;&#34892;&#25506;&#32034;&#12290;&#25105;&#20204;&#23545;&#31639;&#27861;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#24182;&#23558;&#26368;&#32456;&#31574;&#30053;&#30340;&#36136;&#37327;&#20316;&#20026;&#21407;&#22987;&#25968;&#25454;&#38598;&#30340;&#23616;&#37096;&#35206;&#30422;&#21644;&#39069;&#22806;&#25968;&#25454;&#25910;&#38598;&#37327;&#30340;&#20989;&#25968;&#36827;&#34892;&#20102;&#24230;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
In some applications of reinforcement learning, a dataset of pre-collected experience is already available but it is also possible to acquire some additional online data to help improve the quality of the policy. However, it may be preferable to gather additional data with a single, non-reactive exploration policy and avoid the engineering costs associated with switching policies.  In this paper we propose an algorithm with provable guarantees that can leverage an offline dataset to design a single non-reactive policy for exploration. We theoretically analyze the algorithm and measure the quality of the final policy as a function of the local coverage of the original dataset and the amount of additional data collected.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#38750;&#32447;&#24615;&#20805;&#20998;&#38477;&#32500;&#25216;&#26415;&#30340;&#20805;&#20998;&#22270;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#19981;&#20381;&#36182;&#39640;&#32500;&#26680;&#26469;&#25551;&#36848;&#26465;&#20214;&#29420;&#31435;&#24615;&#65292;&#24182;&#19988;&#36991;&#20813;&#20102;&#39640;&#32500;&#26680;&#24102;&#26469;&#30340;&#32500;&#24230;&#28798;&#38590;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#22312;&#39640;&#26031;&#20998;&#24067;&#25110;&#21516;&#26102;&#39640;&#26031;&#20998;&#24067;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2307.04353</link><description>&lt;p&gt;
&#20851;&#20110;&#20805;&#20998;&#22270;&#27169;&#22411;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Sufficient Graphical Models. (arXiv:2307.04353v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04353
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#38750;&#32447;&#24615;&#20805;&#20998;&#38477;&#32500;&#25216;&#26415;&#30340;&#20805;&#20998;&#22270;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#19981;&#20381;&#36182;&#39640;&#32500;&#26680;&#26469;&#25551;&#36848;&#26465;&#20214;&#29420;&#31435;&#24615;&#65292;&#24182;&#19988;&#36991;&#20813;&#20102;&#39640;&#32500;&#26680;&#24102;&#26469;&#30340;&#32500;&#24230;&#28798;&#38590;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#22312;&#39640;&#26031;&#20998;&#24067;&#25110;&#21516;&#26102;&#39640;&#26031;&#20998;&#24067;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24212;&#29992;&#26368;&#36817;&#21457;&#23637;&#30340;&#38750;&#32447;&#24615;&#20805;&#20998;&#38477;&#32500;&#25216;&#26415;&#26469;&#35780;&#20272;&#26465;&#20214;&#29420;&#31435;&#24615;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#20805;&#20998;&#22270;&#27169;&#22411;&#12290;&#35813;&#22270;&#27169;&#22411;&#26159;&#38750;&#21442;&#25968;&#30340;&#65292;&#22240;&#20026;&#23427;&#19981;&#23545;&#20998;&#24067;&#20570;&#20986;&#20551;&#35774;&#65292;&#22914;&#39640;&#26031;&#20998;&#24067;&#25110;&#21516;&#26102;&#39640;&#26031;&#20998;&#24067;&#12290;&#28982;&#32780;&#65292;&#19982;&#23436;&#20840;&#38750;&#21442;&#25968;&#30340;&#22270;&#27169;&#22411;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#22270;&#27169;&#22411;&#22522;&#20110;&#32473;&#23450;&#19968;&#32452;&#20943;&#23569;&#32500;&#24230;&#30340;&#20805;&#20998;&#39044;&#27979;&#21464;&#37327;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;&#25105;&#20204;&#36991;&#20813;&#20102;&#39640;&#32500;&#26680;&#25152;&#24102;&#26469;&#30340;&#32500;&#24230;&#28798;&#38590;&#12290;&#25105;&#20204;&#36824;&#21457;&#23637;&#20102;&#20272;&#35745;&#30340;&#24635;&#20307;&#32423;&#24615;&#36136;&#12289;&#25910;&#25947;&#36895;&#24230;&#21644;&#21464;&#37327;&#36873;&#25321;&#19968;&#33268;&#24615;&#12290;&#36890;&#36807;&#27169;&#25311;&#27604;&#36739;&#21644;&#23545;DREAM 4&#25361;&#25112;&#25968;&#25454;&#38598;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#39640;&#26031;&#20998;&#24067;&#25110;&#21516;&#26102;&#39640;&#26031;&#20998;&#24067;&#20551;&#35774;&#26102;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a sufficient graphical model by applying the recently developed nonlinear sufficient dimension reduction techniques to the evaluation of conditional independence. The graphical model is nonparametric in nature, as it does not make distributional assumptions such as the Gaussian or copula Gaussian assumptions. However, unlike a fully nonparametric graphical model, which relies on the high-dimensional kernel to characterize conditional independence, our graphical model is based on conditional independence given a set of sufficient predictors with a substantially reduced dimension. In this way we avoid the curse of dimensionality that comes with a high-dimensional kernel. We develop the population-level properties, convergence rate, and variable selection consistency of our estimate. By simulation comparisons and an analysis of the DREAM 4 Challenge data set, we demonstrate that our method outperforms the existing methods when the Gaussian or copula Gaussian assumptions are v
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21435;&#22122;&#25193;&#25955;&#38544;&#24335;&#27169;&#22411;&#21644;&#37325;&#37319;&#26679;&#30340;&#22320;&#38663;&#25968;&#25454;&#25554;&#20540;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#21644;&#20313;&#24358;&#22122;&#22768;&#35745;&#21010;&#65292;&#23454;&#29616;&#20102;&#31283;&#23450;&#35757;&#32451;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65292;&#24182;&#25552;&#39640;&#20102;&#24050;&#30693;&#36857;&#32447;&#20449;&#24687;&#30340;&#21033;&#29992;&#29575;&#12290;</title><link>http://arxiv.org/abs/2307.04226</link><description>&lt;p&gt;
&#22522;&#20110;&#21435;&#22122;&#25193;&#25955;&#38544;&#24335;&#27169;&#22411;&#21644;&#37325;&#37319;&#26679;&#30340;&#22320;&#38663;&#25968;&#25454;&#25554;&#20540;
&lt;/p&gt;
&lt;p&gt;
Seismic Data Interpolation based on Denoising Diffusion Implicit Models with Resampling. (arXiv:2307.04226v1 [physics.geo-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04226
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21435;&#22122;&#25193;&#25955;&#38544;&#24335;&#27169;&#22411;&#21644;&#37325;&#37319;&#26679;&#30340;&#22320;&#38663;&#25968;&#25454;&#25554;&#20540;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#21644;&#20313;&#24358;&#22122;&#22768;&#35745;&#21010;&#65292;&#23454;&#29616;&#20102;&#31283;&#23450;&#35757;&#32451;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65292;&#24182;&#25552;&#39640;&#20102;&#24050;&#30693;&#36857;&#32447;&#20449;&#24687;&#30340;&#21033;&#29992;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22320;&#38663;&#25968;&#25454;&#31354;&#38388;&#25193;&#23637;&#19978;&#32570;&#22833;&#21078;&#38754;&#23548;&#33268;&#22320;&#38663;&#25968;&#25454;&#19981;&#23436;&#25972;&#26159;&#22320;&#38663;&#37319;&#38598;&#20013;&#26222;&#36941;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#30001;&#20110;&#38556;&#30861;&#29289;&#21644;&#32463;&#27982;&#38480;&#21046;&#65292;&#36825;&#20005;&#37325;&#24433;&#21709;&#20102;&#22320;&#19979;&#22320;&#36136;&#32467;&#26500;&#30340;&#25104;&#20687;&#36136;&#37327;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#22320;&#38663;&#25554;&#20540;&#26041;&#27861;&#21462;&#24471;&#20102;&#20196;&#20154;&#26399;&#24453;&#30340;&#36827;&#23637;&#65292;&#20294;&#31283;&#23450;&#35757;&#32451;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#24182;&#19981;&#23481;&#26131;&#65292;&#22914;&#26524;&#27979;&#35797;&#21644;&#35757;&#32451;&#20013;&#30340;&#32570;&#22833;&#27169;&#24335;&#19981;&#21305;&#37197;&#65292;&#24615;&#33021;&#36864;&#21270;&#36890;&#24120;&#26159;&#26174;&#33879;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22320;&#38663;&#21435;&#22122;&#25193;&#25955;&#38544;&#24335;&#27169;&#22411;&#21644;&#37325;&#37319;&#26679;&#26041;&#27861;&#12290;&#27169;&#22411;&#35757;&#32451;&#24314;&#31435;&#22312;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#65292;&#20854;&#20013;U-Net&#37197;&#22791;&#20102;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#20197;&#21305;&#37197;&#27599;&#20010;&#27493;&#39588;&#20013;&#30340;&#22122;&#22768;&#12290;&#20313;&#24358;&#22122;&#22768;&#35745;&#21010;&#20316;&#20026;&#20840;&#23616;&#22122;&#22768;&#37197;&#32622;&#65292;&#36890;&#36807;&#21152;&#36895;&#36807;&#24230;&#20449;&#24687;&#30340;&#20256;&#36882;&#26469;&#20419;&#36827;&#24050;&#30693;&#36857;&#32447;&#20449;&#24687;&#30340;&#39640;&#24230;&#21033;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
The incompleteness of the seismic data caused by missing traces along the spatial extension is a common issue in seismic acquisition due to the existence of obstacles and economic constraints, which severely impairs the imaging quality of subsurface geological structures. Recently, deep learning-based seismic interpolation methods have attained promising progress, while achieving stable training of generative adversarial networks is not easy, and performance degradation is usually notable if the missing patterns in the testing and training do not match. In this paper, we propose a novel seismic denoising diffusion implicit model with resampling. The model training is established on the denoising diffusion probabilistic model, where U-Net is equipped with the multi-head self-attention to match the noise in each step. The cosine noise schedule, serving as the global noise configuration, promotes the high utilization of known trace information by accelerating the passage of the excessive 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#35777;&#26126;&#20102;&#26799;&#24230;&#19979;&#38477;&#36712;&#36857;&#19978;&#30340;&#31283;&#23450;&#36793;&#32536;&#29616;&#35937;&#65292;&#24182;&#19988;&#23545;&#20110;&#29305;&#23450;&#30340;&#32593;&#32476;&#32467;&#26500;&#36827;&#34892;&#20102;&#36712;&#36857;&#23545;&#40784;&#20998;&#26512;&#65292;&#24314;&#31435;&#20102;&#28176;&#36827;&#23574;&#38160;&#21270;&#21644;&#31283;&#23450;&#36793;&#32536;&#29616;&#35937;&#65292;&#25193;&#23637;&#20102;&#24403;&#21069;&#25991;&#29486;&#30340;&#30740;&#31350;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.04204</link><description>&lt;p&gt;
&#36712;&#36857;&#23545;&#40784;&#65306;&#36890;&#36807;&#20998;&#21449;&#29702;&#35770;&#29702;&#35299;&#31283;&#23450;&#36793;&#32536;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
Trajectory Alignment: Understanding the Edge of Stability Phenomenon via Bifurcation Theory. (arXiv:2307.04204v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04204
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#35777;&#26126;&#20102;&#26799;&#24230;&#19979;&#38477;&#36712;&#36857;&#19978;&#30340;&#31283;&#23450;&#36793;&#32536;&#29616;&#35937;&#65292;&#24182;&#19988;&#23545;&#20110;&#29305;&#23450;&#30340;&#32593;&#32476;&#32467;&#26500;&#36827;&#34892;&#20102;&#36712;&#36857;&#23545;&#40784;&#20998;&#26512;&#65292;&#24314;&#31435;&#20102;&#28176;&#36827;&#23574;&#38160;&#21270;&#21644;&#31283;&#23450;&#36793;&#32536;&#29616;&#35937;&#65292;&#25193;&#23637;&#20102;&#24403;&#21069;&#25991;&#29486;&#30340;&#30740;&#31350;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Cohen&#31561;&#20154;&#65288;2021&#65289;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#36712;&#36857;&#19978;&#25439;&#22833;Hessian&#30340;&#26368;&#22823;&#29305;&#24449;&#20540;&#65288;&#21363;&#38160;&#24230;&#65289;&#65292;&#35266;&#23519;&#21040;&#19968;&#31181;&#31216;&#20026;&#31283;&#23450;&#36793;&#32536;&#65288;EoS&#65289;&#30340;&#29616;&#35937;&#12290;&#38160;&#24230;&#22312;&#22521;&#35757;&#30340;&#26089;&#26399;&#38454;&#27573;&#22686;&#21152;&#65288;&#31216;&#20026;&#28176;&#36827;&#23574;&#38160;&#21270;&#65289;&#65292;&#26368;&#32456;&#25509;&#36817;&#38408;&#20540;$2/\text{(&#27493;&#38271;)}$&#38468;&#36817;&#20572;&#28382;&#12290;&#26412;&#25991;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#39318;&#20808;&#35777;&#26126;&#20102;&#24403;EoS&#29616;&#35937;&#21457;&#29983;&#26102;&#65292;&#19981;&#21516;&#30340;GD&#36712;&#36857;&#65288;&#32463;&#36807;&#36866;&#24403;&#30340;&#21442;&#25968;&#21270;&#65289;&#22312;&#19968;&#20010;&#29305;&#23450;&#30340;&#20998;&#21449;&#22270;&#19978;&#23545;&#40784;&#65292;&#32780;&#19982;&#21021;&#22987;&#21270;&#26080;&#20851;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23545;&#19968;&#20010;&#20108;&#23618;&#20840;&#36830;&#25509;&#32447;&#24615;&#32593;&#32476;&#21644;&#19968;&#20010;&#20351;&#29992;&#21333;&#20010;&#25968;&#25454;&#28857;&#35757;&#32451;&#30340;&#21333;&#31070;&#32463;&#20803;&#38750;&#32447;&#24615;&#32593;&#32476;&#20005;&#26684;&#35777;&#26126;&#20102;&#36825;&#31181;&#36712;&#36857;&#23545;&#40784;&#29616;&#35937;&#12290;&#25105;&#20204;&#30340;&#36712;&#36857;&#23545;&#40784;&#20998;&#26512;&#24314;&#31435;&#20102;&#28176;&#36827;&#23574;&#38160;&#21270;&#21644;EoS&#29616;&#35937;&#65292;&#28085;&#30422;&#24182;&#25193;&#23637;&#20102;&#26368;&#36817;&#25991;&#29486;&#20013;&#30340;&#30740;&#31350;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cohen et al. (2021) empirically study the evolution of the largest eigenvalue of the loss Hessian, also known as sharpness, along the gradient descent (GD) trajectory and observe a phenomenon called the Edge of Stability (EoS). The sharpness increases at the early phase of training (referred to as progressive sharpening), and eventually saturates close to the threshold of $2 / \text{(step size)}$. In this paper, we start by demonstrating through empirical studies that when the EoS phenomenon occurs, different GD trajectories (after a proper reparameterization) align on a specific bifurcation diagram independent of initialization. We then rigorously prove this trajectory alignment phenomenon for a two-layer fully-connected linear network and a single-neuron nonlinear network trained with a single data point. Our trajectory alignment analysis establishes both progressive sharpening and EoS phenomena, encompassing and extending recent findings in the literature.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36923;&#36753;&#22238;&#24402;&#27169;&#22411;&#22312;&#26631;&#20934;&#27491;&#24577;&#21327;&#21464;&#37327;&#19979;&#30340;&#21442;&#25968;&#20272;&#35745;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#21457;&#29616;&#26679;&#26412;&#22797;&#26434;&#24230;&#26354;&#32447;&#22312;&#36870;&#28201;&#24230;&#26041;&#38754;&#26377;&#20004;&#20010;&#36716;&#25240;&#28857;&#65292;&#26126;&#30830;&#21010;&#20998;&#20102;&#20302;&#12289;&#20013;&#21644;&#39640;&#28201;&#24230;&#21306;&#22495;&#12290;</title><link>http://arxiv.org/abs/2307.04191</link><description>&lt;p&gt;
&#20851;&#20110;&#36923;&#36753;&#22238;&#24402;&#20013;&#21442;&#25968;&#20272;&#35745;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the sample complexity of estimation in logistic regression. (arXiv:2307.04191v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04191
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36923;&#36753;&#22238;&#24402;&#27169;&#22411;&#22312;&#26631;&#20934;&#27491;&#24577;&#21327;&#21464;&#37327;&#19979;&#30340;&#21442;&#25968;&#20272;&#35745;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#21457;&#29616;&#26679;&#26412;&#22797;&#26434;&#24230;&#26354;&#32447;&#22312;&#36870;&#28201;&#24230;&#26041;&#38754;&#26377;&#20004;&#20010;&#36716;&#25240;&#28857;&#65292;&#26126;&#30830;&#21010;&#20998;&#20102;&#20302;&#12289;&#20013;&#21644;&#39640;&#28201;&#24230;&#21306;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36923;&#36753;&#22238;&#24402;&#27169;&#22411;&#26159;&#22122;&#22768;&#20108;&#20803;&#20998;&#31867;&#38382;&#39064;&#20013;&#26368;&#24120;&#35265;&#30340;&#25968;&#25454;&#29983;&#25104;&#27169;&#22411;&#20043;&#19968;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26631;&#20934;&#27491;&#24577;&#21327;&#21464;&#37327;&#19979;&#65292;&#20197;$\ell_2$&#35823;&#24046;&#20026;&#38480;&#65292;&#20272;&#35745;&#36923;&#36753;&#22238;&#24402;&#27169;&#22411;&#21442;&#25968;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#32771;&#34385;&#20102;&#32500;&#24230;&#21644;&#36870;&#28201;&#24230;&#30340;&#24433;&#21709;&#12290;&#36870;&#28201;&#24230;&#25511;&#21046;&#20102;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#20013;&#30340;&#20449;&#22122;&#27604;&#12290;&#34429;&#28982;&#36923;&#36753;&#22238;&#24402;&#30340;&#24191;&#20041;&#30028;&#38480;&#21644;&#28176;&#36817;&#24615;&#33021;&#24050;&#32463;&#26377;&#20102;&#28145;&#20837;&#30740;&#31350;&#65292;&#20294;&#20851;&#20110;&#21442;&#25968;&#20272;&#35745;&#30340;&#38750;&#28176;&#36817;&#26679;&#26412;&#22797;&#26434;&#24230;&#22312;&#20043;&#21069;&#30340;&#20998;&#26512;&#20013;&#27809;&#26377;&#35752;&#35770;&#20854;&#19982;&#35823;&#24046;&#21644;&#36870;&#28201;&#24230;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#26354;&#32447;&#22312;&#36870;&#28201;&#24230;&#26041;&#38754;&#20855;&#26377;&#20004;&#20010;&#36716;&#25240;&#28857;&#65288;&#25110;&#20020;&#30028;&#28857;&#65289;&#65292;&#26126;&#30830;&#21010;&#20998;&#20102;&#20302;&#12289;&#20013;&#21644;&#39640;&#28201;&#24230;&#21306;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
The logistic regression model is one of the most popular data generation model in noisy binary classification problems. In this work, we study the sample complexity of estimating the parameters of the logistic regression model up to a given $\ell_2$ error, in terms of the dimension and the inverse temperature, with standard normal covariates. The inverse temperature controls the signal-to-noise ratio of the data generation process. While both generalization bounds and asymptotic performance of the maximum-likelihood estimator for logistic regression are well-studied, the non-asymptotic sample complexity that shows the dependence on error and the inverse temperature for parameter estimation is absent from previous analyses. We show that the sample complexity curve has two change-points (or critical points) in terms of the inverse temperature, clearly separating the low, moderate, and high temperature regimes.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35299;&#20915;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#26469;&#25551;&#36848;&#26465;&#20214;&#20998;&#24067;&#30340;&#38750;&#21442;&#25968;&#29983;&#25104;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20351;&#29992;&#22359;&#19977;&#35282;&#36755;&#36816;&#26144;&#23556;&#23558;&#21442;&#32771;&#26679;&#26412;&#36845;&#20195;&#26144;&#23556;&#21040;&#30446;&#26631;&#26679;&#26412;&#65292;&#20174;&#32780;&#20811;&#26381;&#20102;&#21442;&#25968;&#20559;&#24046;&#21644;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#22120;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2307.04102</link><description>&lt;p&gt;
&#19968;&#31181;&#36890;&#36807;&#26368;&#20248;&#36755;&#36816;&#36827;&#34892;&#26465;&#20214;&#37319;&#26679;&#30340;&#29983;&#25104;&#27969;
&lt;/p&gt;
&lt;p&gt;
A generative flow for conditional sampling via optimal transport. (arXiv:2307.04102v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04102
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35299;&#20915;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#26469;&#25551;&#36848;&#26465;&#20214;&#20998;&#24067;&#30340;&#38750;&#21442;&#25968;&#29983;&#25104;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20351;&#29992;&#22359;&#19977;&#35282;&#36755;&#36816;&#26144;&#23556;&#23558;&#21442;&#32771;&#26679;&#26412;&#36845;&#20195;&#26144;&#23556;&#21040;&#30446;&#26631;&#26679;&#26412;&#65292;&#20174;&#32780;&#20811;&#26381;&#20102;&#21442;&#25968;&#20559;&#24046;&#21644;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#22120;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26465;&#20214;&#20998;&#24067;&#30340;&#37319;&#26679;&#26159;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#23494;&#24230;&#20272;&#35745;&#30340;&#22522;&#26412;&#20219;&#21153;&#12290;&#29983;&#25104;&#27169;&#22411;&#65292;&#22914;&#24402;&#19968;&#21270;&#27969;&#21644;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65292;&#36890;&#36807;&#23398;&#20064;&#23558;&#31616;&#21333;&#21442;&#32771;&#27169;&#22411;&#65288;&#22914;&#26631;&#20934;&#39640;&#26031;&#20998;&#24067;&#65289;&#25512;&#21521;&#30446;&#26631;&#20998;&#24067;&#30340;&#36755;&#36816;&#26144;&#23556;&#65292;&#26469;&#25551;&#36848;&#26465;&#20214;&#20998;&#24067;&#12290;&#34429;&#28982;&#36825;&#20123;&#26041;&#27861;&#25104;&#21151;&#22320;&#25551;&#36848;&#20102;&#35768;&#22810;&#38750;&#39640;&#26031;&#38382;&#39064;&#65292;&#20294;&#23427;&#20204;&#30340;&#24615;&#33021;&#36890;&#24120;&#21463;&#21040;&#21442;&#25968;&#20559;&#24046;&#21644;&#22522;&#20110;&#26799;&#24230;&#30340;&#65288;&#23545;&#25239;&#24615;&#65289;&#20248;&#21270;&#22120;&#23398;&#20064;&#36825;&#20123;&#36716;&#25442;&#30340;&#21487;&#38752;&#24615;&#30340;&#38480;&#21046;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#36845;&#20195;&#22320;&#23558;&#21442;&#32771;&#26679;&#26412;&#26144;&#23556;&#21040;&#30446;&#26631;&#26679;&#26412;&#26469;&#25551;&#36848;&#26465;&#20214;&#20998;&#24067;&#12290;&#35813;&#27169;&#22411;&#20351;&#29992;&#22359;&#19977;&#35282;&#36755;&#36816;&#26144;&#23556;&#65292;&#20854;&#32452;&#20214;&#34987;&#35777;&#26126;&#21487;&#20197;&#34920;&#24449;&#30446;&#26631;&#20998;&#24067;&#30340;&#26465;&#20214;&#20998;&#24067;&#12290;&#36825;&#20123;&#26144;&#23556;&#26159;&#36890;&#36807;&#35299;&#20915;&#24102;&#26435; $L^2$ &#25439;&#22833;&#20989;&#25968;&#30340;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#24471;&#21040;&#30340;&#65292;&#20174;&#32780;&#25193;&#23637;&#20102;[Trigila and Tabak, 2016]&#20013;&#30340;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#29992;&#20110;&#26465;&#20214;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sampling conditional distributions is a fundamental task for Bayesian inference and density estimation. Generative models, such as normalizing flows and generative adversarial networks, characterize conditional distributions by learning a transport map that pushes forward a simple reference (e.g., a standard Gaussian) to a target distribution. While these approaches successfully describe many non-Gaussian problems, their performance is often limited by parametric bias and the reliability of gradient-based (adversarial) optimizers to learn these transformations. This work proposes a non-parametric generative model that iteratively maps reference samples to the target. The model uses block-triangular transport maps, whose components are shown to characterize conditionals of the target distribution. These maps arise from solving an optimal transport problem with a weighted $L^2$ cost function, thereby extending the data-driven approach in [Trigila and Tabak, 2016] for conditional sampling
&lt;/p&gt;</description></item><item><title>&#21452;&#21521;&#27880;&#24847;&#21147;&#27169;&#22411;&#20855;&#26377;&#28151;&#21512;&#19987;&#23478;&#26435;&#37325;&#65292;&#31867;&#20284;&#20110;&#36830;&#32493;&#35789;&#34955;&#27169;&#22411;&#65288;CBOW&#65289;&#30340;&#32479;&#35745;&#27169;&#22411;&#65292;&#23427;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#36215;&#21040;&#20102;&#37325;&#35201;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2307.04057</link><description>&lt;p&gt;
&#21452;&#21521;&#27880;&#24847;&#21147;&#20316;&#20026;&#36830;&#32493;&#35789;&#19987;&#23478;&#30340;&#28151;&#21512;&#29289;
&lt;/p&gt;
&lt;p&gt;
Bidirectional Attention as a Mixture of Continuous Word Experts. (arXiv:2307.04057v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04057
&lt;/p&gt;
&lt;p&gt;
&#21452;&#21521;&#27880;&#24847;&#21147;&#27169;&#22411;&#20855;&#26377;&#28151;&#21512;&#19987;&#23478;&#26435;&#37325;&#65292;&#31867;&#20284;&#20110;&#36830;&#32493;&#35789;&#34955;&#27169;&#22411;&#65288;CBOW&#65289;&#30340;&#32479;&#35745;&#27169;&#22411;&#65292;&#23427;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#36215;&#21040;&#20102;&#37325;&#35201;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21452;&#21521;&#27880;&#24847;&#21147;&#30001;&#20301;&#32622;&#32534;&#30721;&#21644;&#23631;&#34109;&#35821;&#35328;&#27169;&#22411;&#65288;MLM&#65289;&#30446;&#26631;&#32452;&#25104;&#30340;&#33258;&#27880;&#24847;&#21147;&#26500;&#25104;&#65292;&#24050;&#25104;&#20026;&#29616;&#20195;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20851;&#38190;&#32452;&#20214;&#12290;&#23613;&#31649;&#23427;&#22312;&#23454;&#36341;&#20013;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#24456;&#23569;&#26377;&#30740;&#31350;&#25506;&#35752;&#23427;&#30340;&#32479;&#35745;&#22522;&#30784;&#65306;&#21452;&#21521;&#27880;&#24847;&#21147;&#38544;&#21547;&#22320;&#25311;&#21512;&#20102;&#20160;&#20040;&#32479;&#35745;&#27169;&#22411;&#65311;&#23427;&#19982;&#38750;&#27880;&#24847;&#26426;&#21046;&#30340;&#20808;&#39537;&#26377;&#20309;&#19981;&#21516;&#65311;&#26412;&#25991;&#25506;&#35752;&#20102;&#36825;&#20123;&#38382;&#39064;&#12290;&#20851;&#38190;&#35266;&#23519;&#26159;&#65292;&#37325;&#26032;&#21442;&#25968;&#21270;&#21518;&#65292;&#25311;&#21512;&#21333;&#23618;&#21333;&#22836;&#21452;&#21521;&#27880;&#24847;&#21147;&#31561;&#20110;&#25311;&#21512;&#20855;&#26377;&#28151;&#21512;&#19987;&#23478;&#26435;&#37325;&#30340;&#36830;&#32493;&#35789;&#34955;&#65288;CBOW&#65289;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#20855;&#26377;&#22810;&#20010;&#22836;&#21644;&#22810;&#20010;&#23618;&#30340;&#21452;&#21521;&#27880;&#24847;&#21147;&#31561;&#20215;&#20110;&#22534;&#21472;&#30340;MoEs&#21644;MoEs&#30340;&#28151;&#21512;&#12290;&#36825;&#20010;&#32479;&#35745;&#35266;&#28857;&#25581;&#31034;&#20102;MoE&#22312;&#21452;&#21521;&#27880;&#24847;&#21147;&#20013;&#30340;&#29420;&#29305;&#29992;&#36884;&#65292;&#36825;&#19982;&#20854;&#22312;&#22788;&#29702;&#24322;&#26500;&#24615;&#26041;&#38754;&#30340;&#23454;&#38469;&#26377;&#25928;&#24615;&#30456;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bidirectional attention $\unicode{x2013}$ composed of self-attention with positional encodings and the masked language model (MLM) objective $\unicode{x2013}$ has emerged as a key component of modern large language models (LLMs). Despite its empirical success, few studies have examined its statistical underpinnings: What statistical model is bidirectional attention implicitly fitting? What sets it apart from its non-attention predecessors? We explore these questions in this paper. The key observation is that fitting a single-layer single-head bidirectional attention, upon reparameterization, is equivalent to fitting a continuous bag of words (CBOW) model with mixture-of-experts (MoE) weights. Further, bidirectional attention with multiple heads and multiple layers is equivalent to stacked MoEs and a mixture of MoEs, respectively. This statistical viewpoint reveals the distinct use of MoE in bidirectional attention, which aligns with its practical effectiveness in handling heterogeneous
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31867;&#31216;&#20026;&#27969;&#24418;&#28388;&#27874;-&#32452;&#21512;&#32593;&#32476;&#30340;&#22823;&#22411;&#27969;&#24418;&#31070;&#32463;&#32593;&#32476;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26500;&#24314;&#25968;&#25454;&#39537;&#21160;&#22270;&#30340;&#26041;&#27861;&#26469;&#23454;&#29616;&#36825;&#31181;&#32593;&#32476;&#65292;&#24182;&#25552;&#20379;&#20102;&#25910;&#25947;&#21040;&#36830;&#32493;&#26497;&#38480;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#20854;&#25910;&#25947;&#36895;&#24230;&#19981;&#20381;&#36182;&#20110;&#28388;&#27874;&#22120;&#25968;&#37327;&#12290;</title><link>http://arxiv.org/abs/2307.04056</link><description>&lt;p&gt;
&#27969;&#24418;&#28388;&#27874;-&#32452;&#21512;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Manifold Filter-Combine Networks. (arXiv:2307.04056v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04056
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31867;&#31216;&#20026;&#27969;&#24418;&#28388;&#27874;-&#32452;&#21512;&#32593;&#32476;&#30340;&#22823;&#22411;&#27969;&#24418;&#31070;&#32463;&#32593;&#32476;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26500;&#24314;&#25968;&#25454;&#39537;&#21160;&#22270;&#30340;&#26041;&#27861;&#26469;&#23454;&#29616;&#36825;&#31181;&#32593;&#32476;&#65292;&#24182;&#25552;&#20379;&#20102;&#25910;&#25947;&#21040;&#36830;&#32493;&#26497;&#38480;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#20854;&#25910;&#25947;&#36895;&#24230;&#19981;&#20381;&#36182;&#20110;&#28388;&#27874;&#22120;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31867;&#22823;&#22411;&#27969;&#24418;&#31070;&#32463;&#32593;&#32476;(MNNs)&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#27969;&#24418;&#28388;&#27874;-&#32452;&#21512;&#32593;&#32476;&#12290;&#36825;&#20010;&#31867;&#21035;&#21253;&#25324;&#20102;Wang&#12289;Ruiz&#21644;Ribeiro&#20043;&#21069;&#30340;&#30740;&#31350;&#20013;&#32771;&#34385;&#30340;MNNs&#65292;&#27969;&#24418;&#25955;&#23556;&#21464;&#25442;(&#19968;&#31181;&#22522;&#20110;&#23567;&#27874;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;)&#65292;&#20197;&#21450;&#20854;&#20182;&#26377;&#36259;&#30340;&#20043;&#21069;&#22312;&#25991;&#29486;&#20013;&#26410;&#32771;&#34385;&#30340;&#31034;&#20363;&#65292;&#22914;Kipf&#21644;Welling&#30340;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#27969;&#24418;&#31561;&#25928;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31181;&#22522;&#20110;&#26500;&#24314;&#25968;&#25454;&#39537;&#21160;&#22270;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#27809;&#26377;&#23545;&#27969;&#24418;&#26377;&#20840;&#23616;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#36825;&#26679;&#30340;&#32593;&#32476;&#65292;&#32780;&#21482;&#33021;&#35775;&#38382;&#26377;&#38480;&#25968;&#37327;&#30340;&#26679;&#26412;&#28857;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#32593;&#32476;&#22312;&#26679;&#26412;&#28857;&#25968;&#36235;&#20110;&#26080;&#31351;&#22823;&#26102;&#33021;&#22815;&#20445;&#35777;&#25910;&#25947;&#21040;&#20854;&#36830;&#32493;&#26497;&#38480;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;(&#20027;&#35201;&#20851;&#27880;&#29305;&#23450;&#30340;MNN&#32467;&#26500;&#21644;&#22270;&#26500;&#24314;)&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#25910;&#25947;&#36895;&#24230;&#24182;&#19981;&#20381;&#36182;&#20110;&#20351;&#29992;&#30340;&#28388;&#27874;&#22120;&#25968;&#37327;&#12290;&#32780;&#19988;&#65292;&#23427;&#34920;&#29616;&#20986;&#32447;&#24615;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a large class of manifold neural networks (MNNs) which we call Manifold Filter-Combine Networks. This class includes as special cases, the MNNs considered in previous work by Wang, Ruiz, and Ribeiro, the manifold scattering transform (a wavelet-based model of neural networks), and other interesting examples not previously considered in the literature such as the manifold equivalent of Kipf and Welling's graph convolutional network. We then consider a method, based on building a data-driven graph, for implementing such networks when one does not have global knowledge of the manifold, but merely has access to finitely many sample points. We provide sufficient conditions for the network to provably converge to its continuum limit as the number of sample points tends to infinity. Unlike previous work (which focused on specific MNN architectures and graph constructions), our rate of convergence does not explicitly depend on the number of filters used. Moreover, it exhibits line
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#31574;&#30053;&#24615;&#20080;&#23478;&#30340;&#24773;&#22659;&#21160;&#24577;&#23450;&#20215;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31574;&#30053;&#21160;&#24577;&#23450;&#20215;&#31574;&#30053;&#65292;&#23558;&#20080;&#23478;&#30340;&#31574;&#30053;&#34892;&#20026;&#32435;&#20837;&#22312;&#32447;&#23398;&#20064;&#20013;&#65292;&#20197;&#26368;&#22823;&#21270;&#21334;&#26041;&#30340;&#32047;&#35745;&#25910;&#30410;&#12290;</title><link>http://arxiv.org/abs/2307.04055</link><description>&lt;p&gt;
&#20855;&#26377;&#31574;&#30053;&#24615;&#20080;&#23478;&#30340;&#24773;&#22659;&#21160;&#24577;&#23450;&#20215;
&lt;/p&gt;
&lt;p&gt;
Contextual Dynamic Pricing with Strategic Buyers. (arXiv:2307.04055v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04055
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#31574;&#30053;&#24615;&#20080;&#23478;&#30340;&#24773;&#22659;&#21160;&#24577;&#23450;&#20215;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31574;&#30053;&#21160;&#24577;&#23450;&#20215;&#31574;&#30053;&#65292;&#23558;&#20080;&#23478;&#30340;&#31574;&#30053;&#34892;&#20026;&#32435;&#20837;&#22312;&#32447;&#23398;&#20064;&#20013;&#65292;&#20197;&#26368;&#22823;&#21270;&#21334;&#26041;&#30340;&#32047;&#35745;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#23450;&#20215;&#26159;&#20225;&#19994;&#24120;&#29992;&#30340;&#19968;&#31181;&#38024;&#23545;&#20010;&#20307;&#29305;&#24449;&#21046;&#23450;&#20215;&#26684;&#30340;&#31574;&#30053;&#12290;&#22312;&#36825;&#20010;&#36807;&#31243;&#20013;&#65292;&#20080;&#23478;&#20063;&#21487;&#20197;&#36890;&#36807;&#25805;&#32437;&#29305;&#24449;&#25968;&#25454;&#26469;&#33719;&#21462;&#26356;&#20302;&#30340;&#20215;&#26684;&#65292;&#20294;&#36825;&#20063;&#20250;&#23548;&#33268;&#29305;&#23450;&#30340;&#25805;&#20316;&#25104;&#26412;&#12290;&#36825;&#31181;&#31574;&#30053;&#34892;&#20026;&#21487;&#33021;&#20250;&#38459;&#30861;&#20225;&#19994;&#26368;&#22823;&#21270;&#21033;&#28070;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#31574;&#30053;&#24615;&#20080;&#23478;&#30340;&#24773;&#22659;&#21160;&#24577;&#23450;&#20215;&#38382;&#39064;&#12290;&#21334;&#26041;&#26080;&#27861;&#35266;&#23519;&#21040;&#20080;&#23478;&#30340;&#30495;&#23454;&#29305;&#24449;&#65292;&#32780;&#21482;&#33021;&#35266;&#23519;&#21040;&#20080;&#23478;&#26681;&#25454;&#31574;&#30053;&#34892;&#20026;&#25805;&#32437;&#21518;&#30340;&#29305;&#24449;&#12290;&#27492;&#22806;&#65292;&#21334;&#26041;&#21482;&#33021;&#35266;&#23519;&#21040;&#20080;&#23478;&#23545;&#20135;&#21697;&#30340;&#20272;&#20540;&#65292;&#32780;&#26080;&#27861;&#30452;&#25509;&#33719;&#21462;&#20855;&#20307;&#25968;&#20540;&#65292;&#21482;&#33021;&#24471;&#21040;&#19968;&#20010;&#20108;&#36827;&#21046;&#30340;&#21709;&#24212;&#65292;&#34920;&#31034;&#26159;&#21542;&#21457;&#29983;&#38144;&#21806;&#12290;&#37492;&#20110;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31574;&#30053;&#21160;&#24577;&#23450;&#20215;&#31574;&#30053;&#65292;&#23558;&#20080;&#23478;&#30340;&#31574;&#30053;&#34892;&#20026;&#32435;&#20837;&#22312;&#32447;&#23398;&#20064;&#20013;&#65292;&#20197;&#26368;&#22823;&#21270;&#21334;&#26041;&#30340;&#32047;&#35745;&#25910;&#30410;&#12290;&#39318;&#20808;&#35777;&#26126;&#20102;&#29616;&#26377;&#30340;&#19981;&#32771;&#34385;&#31574;&#30053;&#24615;&#30340;&#23450;&#20215;&#31574;&#30053;&#30340;&#23384;&#22312;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Personalized pricing, which involves tailoring prices based on individual characteristics, is commonly used by firms to implement a consumer-specific pricing policy. In this process, buyers can also strategically manipulate their feature data to obtain a lower price, incurring certain manipulation costs. Such strategic behavior can hinder firms from maximizing their profits. In this paper, we study the contextual dynamic pricing problem with strategic buyers. The seller does not observe the buyer's true feature, but a manipulated feature according to buyers' strategic behavior. In addition, the seller does not observe the buyers' valuation of the product, but only a binary response indicating whether a sale happens or not. Recognizing these challenges, we propose a strategic dynamic pricing policy that incorporates the buyers' strategic behavior into the online learning to maximize the seller's cumulative revenue. We first prove that existing non-strategic pricing policies that neglect
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#23545;&#25239;&#35757;&#32451;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20272;&#35745;&#22120;&#22312;&#38750;&#21442;&#25968;&#22238;&#24402;&#20013;&#30340;&#36229;&#33539;&#25968;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#21457;&#29616;&#26222;&#36890;&#30340;&#23545;&#25239;&#35757;&#32451;&#20351;&#24471;&#31070;&#32463;&#20272;&#35745;&#22120;&#19981;&#19968;&#33268;&#65292;&#20294;&#36890;&#36807;&#25152;&#25552;&#20986;&#30340;&#24102;&#20462;&#27491;&#30340;&#23545;&#25239;&#35757;&#32451;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20272;&#35745;&#22120;&#22312;&#36229;&#33539;&#25968;&#24847;&#20041;&#19979;&#36798;&#21040;&#26368;&#20248;&#36895;&#29575;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#23454;&#20102;&#36825;&#20123;&#29702;&#35770;&#21457;&#29616;&#12290;</title><link>http://arxiv.org/abs/2307.04042</link><description>&lt;p&gt;
&#20351;&#29992;&#23545;&#25239;&#35757;&#32451;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20272;&#35745;&#22120;&#22312;&#38750;&#21442;&#25968;&#22238;&#24402;&#20013;&#30340;&#36229;&#33539;&#25968;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Sup-Norm Convergence of Deep Neural Network Estimator for Nonparametric Regression by Adversarial Training. (arXiv:2307.04042v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04042
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#23545;&#25239;&#35757;&#32451;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20272;&#35745;&#22120;&#22312;&#38750;&#21442;&#25968;&#22238;&#24402;&#20013;&#30340;&#36229;&#33539;&#25968;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#21457;&#29616;&#26222;&#36890;&#30340;&#23545;&#25239;&#35757;&#32451;&#20351;&#24471;&#31070;&#32463;&#20272;&#35745;&#22120;&#19981;&#19968;&#33268;&#65292;&#20294;&#36890;&#36807;&#25152;&#25552;&#20986;&#30340;&#24102;&#20462;&#27491;&#30340;&#23545;&#25239;&#35757;&#32451;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20272;&#35745;&#22120;&#22312;&#36229;&#33539;&#25968;&#24847;&#20041;&#19979;&#36798;&#21040;&#26368;&#20248;&#36895;&#29575;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#23454;&#20102;&#36825;&#20123;&#29702;&#35770;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#23545;&#25239;&#35757;&#32451;&#26041;&#26696;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20272;&#35745;&#22120;&#30340;&#36229;&#33539;&#25968;&#25910;&#25947;&#24615;&#12290;&#38024;&#23545;&#38750;&#21442;&#25968;&#22238;&#24402;&#38382;&#39064;&#65292;&#24050;&#32463;&#35777;&#26126;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#20272;&#35745;&#22120;&#22312;$L2$-&#33539;&#25968;&#24847;&#20041;&#19979;&#21487;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#30001;&#20110;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#28145;&#24230;&#32467;&#26500;&#65292;&#20351;&#29992;&#26368;&#23567;&#20108;&#20056;&#27861;&#30340;&#31070;&#32463;&#20272;&#35745;&#22120;&#24456;&#38590;&#36798;&#21040;&#36229;&#33539;&#25968;&#25910;&#25947;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#21457;&#23637;&#20102;&#19968;&#31181;&#23545;&#25239;&#35757;&#32451;&#26041;&#26696;&#65292;&#24182;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20272;&#35745;&#22120;&#30340;&#36229;&#33539;&#25968;&#25910;&#25947;&#24615;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#21457;&#29616;&#26222;&#36890;&#30340;&#23545;&#25239;&#35757;&#32451;&#20351;&#24471;&#31070;&#32463;&#20272;&#35745;&#22120;&#19981;&#19968;&#33268;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#25152;&#25552;&#20986;&#30340;&#24102;&#20462;&#27491;&#30340;&#23545;&#25239;&#35757;&#32451;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20272;&#35745;&#22120;&#22312;&#36229;&#33539;&#25968;&#24847;&#20041;&#19979;&#36798;&#21040;&#26368;&#20248;&#36895;&#29575;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#23545;&#25239;&#35757;&#32451;&#25193;&#23637;&#21040;&#20102;&#19968;&#33324;&#30340;&#25439;&#22833;&#20989;&#25968;&#21644;&#25968;&#25454;&#29983;&#25104;&#20989;&#25968;&#30340;&#35774;&#32622;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#25903;&#25345;&#20102;&#29702;&#35770;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show the sup-norm convergence of deep neural network estimators with a novel adversarial training scheme. For the nonparametric regression problem, it has been shown that an estimator using deep neural networks can achieve better performances in the sense of the $L2$-norm. In contrast, it is difficult for the neural estimator with least-squares to achieve the sup-norm convergence, due to the deep structure of neural network models. In this study, we develop an adversarial training scheme and investigate the sup-norm convergence of deep neural network estimators. First, we find that ordinary adversarial training makes neural estimators inconsistent. Second, we show that a deep neural network estimator achieves the optimal rate in the sup-norm sense by the proposed adversarial training with correction. We extend our adversarial training to general setups of a loss function and a data-generating function. Our experiments support the theoretical findings.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#24555;&#36895;&#30340;&#32463;&#39564;&#22330;&#26223;&#25552;&#21462;&#31639;&#27861;&#65292;&#19968;&#31181;&#35782;&#21035;&#20043;&#21069;&#26410;&#35266;&#23519;&#21040;&#30340;&#22330;&#26223;&#24182;&#25552;&#20379;&#22330;&#26223;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#34920;&#31034;&#65292;&#21478;&#19968;&#31181;&#20174;&#24050;&#23454;&#29616;&#30340;&#19990;&#30028;&#29366;&#24577;&#20013;&#36873;&#25321;&#37325;&#35201;&#30340;&#25968;&#25454;&#28857;&#65292;&#24182;&#19982;&#39640;&#38454;&#26679;&#26412;&#30697;&#19968;&#33268;&#65292;&#36825;&#20123;&#31639;&#27861;&#35745;&#31639;&#25928;&#29575;&#39640;&#19988;&#36866;&#29992;&#20110;&#19968;&#33268;&#30340;&#22522;&#20110;&#22330;&#26223;&#30340;&#24314;&#27169;&#21644;&#39640;&#32500;&#25968;&#20540;&#31215;&#20998;&#12290;</title><link>http://arxiv.org/abs/2307.03927</link><description>&lt;p&gt;
&#24555;&#36895;&#32463;&#39564;&#22330;&#26223;
&lt;/p&gt;
&lt;p&gt;
Fast Empirical Scenarios. (arXiv:2307.03927v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03927
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#24555;&#36895;&#30340;&#32463;&#39564;&#22330;&#26223;&#25552;&#21462;&#31639;&#27861;&#65292;&#19968;&#31181;&#35782;&#21035;&#20043;&#21069;&#26410;&#35266;&#23519;&#21040;&#30340;&#22330;&#26223;&#24182;&#25552;&#20379;&#22330;&#26223;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#34920;&#31034;&#65292;&#21478;&#19968;&#31181;&#20174;&#24050;&#23454;&#29616;&#30340;&#19990;&#30028;&#29366;&#24577;&#20013;&#36873;&#25321;&#37325;&#35201;&#30340;&#25968;&#25454;&#28857;&#65292;&#24182;&#19982;&#39640;&#38454;&#26679;&#26412;&#30697;&#19968;&#33268;&#65292;&#36825;&#20123;&#31639;&#27861;&#35745;&#31639;&#25928;&#29575;&#39640;&#19988;&#36866;&#29992;&#20110;&#19968;&#33268;&#30340;&#22522;&#20110;&#22330;&#26223;&#30340;&#24314;&#27169;&#21644;&#39640;&#32500;&#25968;&#20540;&#31215;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24076;&#26395;&#20174;&#22823;&#22411;&#21644;&#39640;&#32500;&#38754;&#26495;&#25968;&#25454;&#20013;&#25552;&#21462;&#19968;&#23567;&#37096;&#20998;&#19982;&#26679;&#26412;&#30697;&#19968;&#33268;&#30340;&#20195;&#34920;&#24615;&#22330;&#26223;&#12290;&#22312;&#20004;&#31181;&#26032;&#31639;&#27861;&#20013;&#65292;&#31532;&#19968;&#31181;&#31639;&#27861;&#35782;&#21035;&#20043;&#21069;&#26410;&#35266;&#23519;&#21040;&#30340;&#22330;&#26223;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#22330;&#26223;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#34920;&#31034;&#12290;&#31532;&#20108;&#31181;&#31639;&#27861;&#20174;&#24050;&#23454;&#29616;&#30340;&#19990;&#30028;&#29366;&#24577;&#20013;&#36873;&#25321;&#37325;&#35201;&#30340;&#25968;&#25454;&#28857;&#65292;&#24182;&#19982;&#39640;&#38454;&#26679;&#26412;&#30697;&#20449;&#24687;&#19968;&#33268;&#12290;&#36825;&#20004;&#31181;&#31639;&#27861;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#24182;&#21487;&#29992;&#20110;&#19968;&#33268;&#30340;&#22522;&#20110;&#22330;&#26223;&#30340;&#24314;&#27169;&#21644;&#39640;&#32500;&#25968;&#20540;&#31215;&#20998;&#12290;&#24191;&#27867;&#30340;&#25968;&#20540;&#22522;&#20934;&#27979;&#35797;&#30740;&#31350;&#21644;&#22312;&#25237;&#36164;&#32452;&#21512;&#20248;&#21270;&#20013;&#30340;&#24212;&#29992;&#25903;&#25345;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We seek to extract a small number of representative scenarios from large and high-dimensional panel data that are consistent with sample moments. Among two novel algorithms, the first identifies scenarios that have not been observed before, and comes with a scenario-based representation of covariance matrices. The second proposal picks important data points from states of the world that have already realized, and are consistent with higher-order sample moment information. Both algorithms are efficient to compute, and lend themselves to consistent scenario-based modeling and high-dimensional numerical integration. Extensive numerical benchmarking studies and an application in portfolio optimization favor the proposed algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#23558;&#20808;&#39564;&#30693;&#35782;&#21644;&#31526;&#21495;&#35268;&#21017;&#20197;&#26631;&#31614;&#32422;&#26463;&#30340;&#24418;&#24335;&#34920;&#36798;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#27604;&#36739;&#27491;&#21017;&#21270;&#21644;&#32422;&#26463;&#25512;&#29702;&#20004;&#31181;&#24120;&#35265;&#30340;&#32534;&#30721;&#26631;&#31614;&#32422;&#26463;&#30340;&#31574;&#30053;&#65292;&#21457;&#29616;&#27491;&#21017;&#21270;&#32553;&#23567;&#20102;&#27867;&#21270;&#24046;&#36317;&#20294;&#24341;&#20837;&#20102;&#23545;&#27425;&#20248;&#27169;&#22411;&#30340;&#20559;&#32622;&#65292;&#32780;&#32422;&#26463;&#25512;&#29702;&#36890;&#36807;&#32416;&#27491;&#27169;&#22411;&#30340;&#36829;&#35268;&#34892;&#20026;&#23558;&#36829;&#35268;&#34892;&#20026;&#36716;&#21270;&#20026;&#20248;&#21183;&#12290;&#36827;&#19968;&#27493;&#25506;&#32034;&#20102;&#23558;&#36825;&#20004;&#31181;&#26041;&#27861;&#32467;&#21512;&#20351;&#29992;&#30340;&#21487;&#33021;&#65292;&#24182;&#25552;&#20986;&#20102;&#29992;&#32422;&#26463;&#25512;&#29702;&#26469;&#34917;&#20607;&#27491;&#21017;&#21270;&#24341;&#20837;&#30340;&#20559;&#32622;&#30340;&#26465;&#20214;&#65292;&#26088;&#22312;&#25552;&#39640;&#27169;&#22411;&#22797;&#26434;&#24615;&#21644;&#26368;&#20248;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2307.03886</link><description>&lt;p&gt;
&#20851;&#20110;&#27491;&#21017;&#21270;&#21644;&#26631;&#31614;&#32422;&#26463;&#25512;&#29702;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Regularization and Inference with Label Constraints. (arXiv:2307.03886v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03886
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#23558;&#20808;&#39564;&#30693;&#35782;&#21644;&#31526;&#21495;&#35268;&#21017;&#20197;&#26631;&#31614;&#32422;&#26463;&#30340;&#24418;&#24335;&#34920;&#36798;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#27604;&#36739;&#27491;&#21017;&#21270;&#21644;&#32422;&#26463;&#25512;&#29702;&#20004;&#31181;&#24120;&#35265;&#30340;&#32534;&#30721;&#26631;&#31614;&#32422;&#26463;&#30340;&#31574;&#30053;&#65292;&#21457;&#29616;&#27491;&#21017;&#21270;&#32553;&#23567;&#20102;&#27867;&#21270;&#24046;&#36317;&#20294;&#24341;&#20837;&#20102;&#23545;&#27425;&#20248;&#27169;&#22411;&#30340;&#20559;&#32622;&#65292;&#32780;&#32422;&#26463;&#25512;&#29702;&#36890;&#36807;&#32416;&#27491;&#27169;&#22411;&#30340;&#36829;&#35268;&#34892;&#20026;&#23558;&#36829;&#35268;&#34892;&#20026;&#36716;&#21270;&#20026;&#20248;&#21183;&#12290;&#36827;&#19968;&#27493;&#25506;&#32034;&#20102;&#23558;&#36825;&#20004;&#31181;&#26041;&#27861;&#32467;&#21512;&#20351;&#29992;&#30340;&#21487;&#33021;&#65292;&#24182;&#25552;&#20986;&#20102;&#29992;&#32422;&#26463;&#25512;&#29702;&#26469;&#34917;&#20607;&#27491;&#21017;&#21270;&#24341;&#20837;&#30340;&#20559;&#32622;&#30340;&#26465;&#20214;&#65292;&#26088;&#22312;&#25552;&#39640;&#27169;&#22411;&#22797;&#26434;&#24615;&#21644;&#26368;&#20248;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#39564;&#30693;&#35782;&#21644;&#31526;&#21495;&#35268;&#21017;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#36890;&#24120;&#20197;&#26631;&#31614;&#32422;&#26463;&#30340;&#24418;&#24335;&#34920;&#36798;&#65292;&#29305;&#21035;&#26159;&#22312;&#32467;&#26500;&#39044;&#27979;&#38382;&#39064;&#20013;&#12290;&#26412;&#25991;&#36890;&#36807;&#37327;&#21270;&#20854;&#23545;&#27169;&#22411;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#27604;&#36739;&#20102;&#26426;&#22120;&#23398;&#20064;&#27969;&#31243;&#20013;&#20004;&#31181;&#24120;&#35265;&#30340;&#32534;&#30721;&#26631;&#31614;&#32422;&#26463;&#30340;&#31574;&#30053;&#65306;&#24102;&#32422;&#26463;&#30340;&#27491;&#21017;&#21270;&#21644;&#32422;&#26463;&#25512;&#29702;&#12290;&#23545;&#20110;&#27491;&#21017;&#21270;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23427;&#36890;&#36807;&#25490;&#38500;&#19982;&#32422;&#26463;&#19981;&#19968;&#33268;&#30340;&#27169;&#22411;&#26469;&#32553;&#23567;&#27867;&#21270;&#24046;&#36317;&#30340;&#25928;&#26524;&#12290;&#28982;&#32780;&#65292;&#27491;&#21017;&#21270;&#23545;&#23567;&#36829;&#35268;&#30340;&#20559;&#22909;&#23548;&#33268;&#20102;&#23545;&#27425;&#20248;&#27169;&#22411;&#30340;&#20559;&#32622;&#12290;&#23545;&#20110;&#32422;&#26463;&#25512;&#29702;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23427;&#36890;&#36807;&#32416;&#27491;&#27169;&#22411;&#30340;&#36829;&#35268;&#34892;&#20026;&#26469;&#20943;&#23567;&#24635;&#20307;&#39118;&#38505;&#65292;&#24182;&#23558;&#36829;&#35268;&#34892;&#20026;&#36716;&#21270;&#20026;&#20248;&#21183;&#12290;&#37492;&#20110;&#36825;&#20123;&#24046;&#24322;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25506;&#32034;&#20102;&#23558;&#36825;&#20004;&#31181;&#26041;&#27861;&#32467;&#21512;&#20351;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#32422;&#26463;&#25512;&#29702;&#26469;&#34917;&#20607;&#27491;&#21017;&#21270;&#24341;&#20837;&#30340;&#20559;&#32622;&#30340;&#26465;&#20214;&#65292;&#26088;&#22312;&#25552;&#39640;&#27169;&#22411;&#22797;&#26434;&#24615;&#21644;&#26368;&#20248;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;
Prior knowledge and symbolic rules in machine learning are often expressed in the form of label constraints, especially in structured prediction problems. In this work, we compare two common strategies for encoding label constraints in a machine learning pipeline, regularization with constraints and constrained inference, by quantifying their impact on model performance. For regularization, we show that it narrows the generalization gap by precluding models that are inconsistent with the constraints. However, its preference for small violations introduces a bias toward a suboptimal model. For constrained inference, we show that it reduces the population risk by correcting a model's violation, and hence turns the violation into an advantage. Given these differences, we further explore the use of two approaches together and propose conditions for constrained inference to compensate for the bias introduced by regularization, aiming to improve both the model complexity and optimal risk.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21487;&#23454;&#29616;&#22238;&#24402;&#38382;&#39064;&#30340;PAC&#23398;&#20064;&#21644;&#22312;&#32447;&#23398;&#20064;&#30340;&#32479;&#35745;&#22797;&#26434;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;&#20110;&#21487;&#23398;&#20064;&#24615;&#30340;&#24517;&#35201;&#26465;&#20214;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2307.03848</link><description>&lt;p&gt;
&#21487;&#23454;&#29616;&#22238;&#24402;&#30340;&#26368;&#20248;&#23398;&#20064;&#31639;&#27861;&#65306;PAC&#23398;&#20064;&#21644;&#22312;&#32447;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Optimal Learners for Realizable Regression: PAC Learning and Online Learning. (arXiv:2307.03848v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03848
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21487;&#23454;&#29616;&#22238;&#24402;&#38382;&#39064;&#30340;PAC&#23398;&#20064;&#21644;&#22312;&#32447;&#23398;&#20064;&#30340;&#32479;&#35745;&#22797;&#26434;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;&#20110;&#21487;&#23398;&#20064;&#24615;&#30340;&#24517;&#35201;&#26465;&#20214;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#23545;&#21487;&#23454;&#29616;&#22238;&#24402;&#22312;PAC&#23398;&#20064;&#21644;&#22312;&#32447;&#23398;&#20064;&#30340;&#32479;&#35745;&#22797;&#26434;&#24230;&#36827;&#34892;&#21051;&#30011;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#35777;&#26126;&#20102;&#26377;&#38480;&#30340;fat shattering&#32500;&#24230;&#23545;&#20110;PAC&#23398;&#20064;&#30340;&#20805;&#20998;&#24615;&#20197;&#21450;&#26377;&#38480;&#30340;scaled Natarajan&#32500;&#24230;&#23545;&#20110;&#24517;&#35201;&#24615;&#30340;&#23384;&#22312;&#65292;&#20294;&#33258;&#20174;Simon 1997&#65288;SICOMP '97&#65289;&#30340;&#24037;&#20316;&#20197;&#26469;&#65292;&#23545;&#20110;&#26356;&#23436;&#25972;&#30340;&#21051;&#30011;&#30340;&#36827;&#23637;&#29978;&#23569;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#39318;&#20808;&#24341;&#20837;&#20102;&#19968;&#31181;&#26368;&#23567;&#21270;&#23454;&#20363;&#26368;&#20248;&#23398;&#20064;&#31639;&#27861;&#26469;&#23545;&#21487;&#23454;&#29616;&#22238;&#24402;&#36827;&#34892;&#23398;&#20064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26082;&#23450;&#24615;&#21448;&#23450;&#37327;&#22320;&#21051;&#30011;&#20102;&#21738;&#20123;&#31867;&#30340;&#23454;&#25968;&#39044;&#27979;&#22120;&#21487;&#20197;&#34987;&#23398;&#20064;&#30340;&#26032;&#39062;&#32500;&#24230;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#19968;&#20010;&#19982;&#22270;&#32500;&#24230;&#30456;&#20851;&#30340;&#32452;&#21512;&#32500;&#24230;&#65292;&#35813;&#32500;&#24230;&#21051;&#30011;&#20102;&#22312;&#21487;&#23454;&#29616;&#35774;&#32622;&#20013;&#30340;ERM&#21487;&#23398;&#20064;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#26681;&#25454;&#19982;DS&#32500;&#24230;&#30456;&#20851;&#30340;&#32452;&#21512;&#32500;&#24230;&#24314;&#31435;&#20102;&#23398;&#20064;&#21487;&#34892;&#24615;&#30340;&#24517;&#35201;&#26465;&#20214;&#65292;&#24182;&#29468;&#27979;&#23427;&#20063;&#21487;&#33021;&#26159;&#20805;&#20998;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we aim to characterize the statistical complexity of realizable regression both in the PAC learning setting and the online learning setting.  Previous work had established the sufficiency of finiteness of the fat shattering dimension for PAC learnability and the necessity of finiteness of the scaled Natarajan dimension, but little progress had been made towards a more complete characterization since the work of Simon 1997 (SICOMP '97). To this end, we first introduce a minimax instance optimal learner for realizable regression and propose a novel dimension that both qualitatively and quantitatively characterizes which classes of real-valued predictors are learnable. We then identify a combinatorial dimension related to the Graph dimension that characterizes ERM learnability in the realizable setting. Finally, we establish a necessary condition for learnability based on a combinatorial dimension related to the DS dimension, and conjecture that it may also be sufficient in 
&lt;/p&gt;</description></item><item><title>URL&#22522;&#20934;&#26159;&#19968;&#20010;&#35780;&#20272;&#39044;&#35757;&#32451;&#27169;&#22411;&#21487;&#36716;&#31227;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#26041;&#24335;&#65292;&#30740;&#31350;&#21457;&#29616;&#19987;&#27880;&#20110;&#34920;&#31034;&#26412;&#36523;&#19981;&#30830;&#23450;&#24615;&#25110;&#30452;&#25509;&#20272;&#35745;&#39044;&#27979;&#39118;&#38505;&#30340;&#26041;&#27861;&#25928;&#26524;&#20248;&#20110;&#22522;&#20110;&#27010;&#29575;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.03810</link><description>&lt;p&gt;
URL&#65306;&#19968;&#31181;&#21487;&#36716;&#31227;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#34920;&#31034;&#23398;&#20064;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
URL: A Representation Learning Benchmark for Transferable Uncertainty Estimates. (arXiv:2307.03810v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03810
&lt;/p&gt;
&lt;p&gt;
URL&#22522;&#20934;&#26159;&#19968;&#20010;&#35780;&#20272;&#39044;&#35757;&#32451;&#27169;&#22411;&#21487;&#36716;&#31227;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#26041;&#24335;&#65292;&#30740;&#31350;&#21457;&#29616;&#19987;&#27880;&#20110;&#34920;&#31034;&#26412;&#36523;&#19981;&#30830;&#23450;&#24615;&#25110;&#30452;&#25509;&#20272;&#35745;&#39044;&#27979;&#39118;&#38505;&#30340;&#26041;&#27861;&#25928;&#26524;&#20248;&#20110;&#22522;&#20110;&#27010;&#29575;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34920;&#31034;&#23398;&#20064;&#26174;&#33879;&#25512;&#21160;&#20102;&#35813;&#39046;&#22495;&#21457;&#23637;&#20986;&#33021;&#22815;&#20316;&#20026;&#20174;&#38646;&#24320;&#22987;&#36801;&#31227;&#21040;&#26032;&#25968;&#25454;&#38598;&#26102;&#30340;&#26377;&#20215;&#20540;&#36215;&#28857;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#12290;&#38543;&#30528;&#23545;&#21487;&#38752;&#26426;&#22120;&#23398;&#20064;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#38656;&#27714;&#19981;&#26029;&#22686;&#21152;&#65292;&#38656;&#35201;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#19981;&#20165;&#33021;&#25552;&#20379;&#23884;&#20837;&#21521;&#37327;&#65292;&#36824;&#33021;&#25552;&#20379;&#21487;&#36716;&#31227;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#20026;&#20102;&#24341;&#23548;&#36825;&#26679;&#30340;&#27169;&#22411;&#30340;&#24320;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;URL&#65288;Uncertainty-aware Representation Learning&#65289;&#22522;&#20934;&#12290;&#38500;&#20102;&#34920;&#31034;&#30340;&#21487;&#36716;&#31227;&#24615;&#20043;&#22806;&#65292;&#23427;&#36824;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#24230;&#37327;&#26631;&#20934;&#26469;&#27979;&#37327;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#38646;&#26679;&#26412;&#21487;&#36716;&#31227;&#24615;&#12290;&#25105;&#20204;&#24212;&#29992;URL&#26469;&#35780;&#20272;11&#31181;&#22312;ImageNet&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#24182;&#36716;&#31227;&#21040;8&#20010;&#19979;&#28216;&#25968;&#25454;&#38598;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#22120;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#30528;&#37325;&#20110;&#34920;&#31034;&#26412;&#36523;&#30340;&#19981;&#30830;&#23450;&#24615;&#25110;&#30452;&#25509;&#20272;&#35745;&#39044;&#27979;&#39118;&#38505;&#30340;&#26041;&#27861;&#20248;&#20110;&#22522;&#20110;&#19978;&#28216;&#31867;&#21035;&#30340;&#27010;&#29575;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#23454;&#29616;&#21487;&#36716;&#31227;&#30340;&#19981;&#30830;&#23450;&#24615;&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Representation learning has significantly driven the field to develop pretrained models that can act as a valuable starting point when transferring to new datasets. With the rising demand for reliable machine learning and uncertainty quantification, there is a need for pretrained models that not only provide embeddings but also transferable uncertainty estimates. To guide the development of such models, we propose the Uncertainty-aware Representation Learning (URL) benchmark. Besides the transferability of the representations, it also measures the zero-shot transferability of the uncertainty estimate using a novel metric. We apply URL to evaluate eleven uncertainty quantifiers that are pretrained on ImageNet and transferred to eight downstream datasets. We find that approaches that focus on the uncertainty of the representation itself or estimate the prediction risk directly outperform those that are based on the probabilities of upstream classes. Yet, achieving transferable uncertaint
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#20165;&#20381;&#36182;ERM&#39044;&#35328;&#26426;&#35843;&#29992;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#21487;&#23454;&#29616;&#24773;&#20917;&#19979;&#20855;&#26377;&#26377;&#38480;&#30340;&#36951;&#25022;&#65292;&#24182;&#22312;&#19981;&#21487;&#30693;&#24773;&#20917;&#19979;&#20855;&#26377;&#20122;&#32447;&#24615;&#22686;&#38271;&#30340;&#36951;&#25022;&#12290;&#21516;&#26102;&#65292;&#36824;&#25552;&#20379;&#20102;&#31867;&#20284;&#30340;&#32467;&#26524;&#29992;&#20110;&#38750;&#21442;&#25968;&#21338;&#24328;&#29615;&#22659;&#20013;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#21363;&#20165;&#20381;&#36182;&#26368;&#20339;&#21709;&#24212;&#39044;&#35328;&#26426;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#25910;&#25947;&#21040;&#36817;&#20284;&#26497;&#23567;-&#26497;&#22823;&#22343;&#34913;&#28857;&#12290;</title><link>http://arxiv.org/abs/2307.01689</link><description>&lt;p&gt;
&#22312;&#32447;&#23398;&#20064;&#21644;&#20351;&#29992;ERM&#39044;&#35328;&#26426;&#35299;&#20915;&#26080;&#31351;&#21338;&#24328;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Online Learning and Solving Infinite Games with an ERM Oracle. (arXiv:2307.01689v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01689
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#20165;&#20381;&#36182;ERM&#39044;&#35328;&#26426;&#35843;&#29992;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#21487;&#23454;&#29616;&#24773;&#20917;&#19979;&#20855;&#26377;&#26377;&#38480;&#30340;&#36951;&#25022;&#65292;&#24182;&#22312;&#19981;&#21487;&#30693;&#24773;&#20917;&#19979;&#20855;&#26377;&#20122;&#32447;&#24615;&#22686;&#38271;&#30340;&#36951;&#25022;&#12290;&#21516;&#26102;&#65292;&#36824;&#25552;&#20379;&#20102;&#31867;&#20284;&#30340;&#32467;&#26524;&#29992;&#20110;&#38750;&#21442;&#25968;&#21338;&#24328;&#29615;&#22659;&#20013;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#21363;&#20165;&#20381;&#36182;&#26368;&#20339;&#21709;&#24212;&#39044;&#35328;&#26426;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#25910;&#25947;&#21040;&#36817;&#20284;&#26497;&#23567;-&#26497;&#22823;&#22343;&#34913;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#20110;&#22312;&#32447;&#23398;&#20064;&#30340;&#24773;&#20917;&#19979;&#65292;ERM&#36275;&#20197;&#36798;&#21040;&#25509;&#36817;&#26368;&#20248;&#27867;&#21270;&#35823;&#24046;&#30340;&#30446;&#26631;&#65292;&#20294;&#22312;&#22312;&#32447;&#23398;&#20064;&#29615;&#22659;&#19979;&#24182;&#38750;&#22914;&#27492;&#65292;&#36890;&#24120;&#30340;&#27010;&#24565;&#31867;&#31639;&#27861;&#20381;&#36182;&#35745;&#31639;&#25928;&#29575;&#36739;&#20302;&#30340;&#39044;&#35328;&#26426;&#65292;&#22914;&#26631;&#20934;&#26368;&#20248;&#31639;&#27861;(SOA)&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20165;&#20381;&#36182;ERM&#39044;&#35328;&#26426;&#35843;&#29992;&#30340;&#22312;&#32447;&#20108;&#20998;&#31867;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#22312;&#21487;&#23454;&#29616;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#26377;&#38480;&#30340;&#36951;&#25022;(regret)&#65292;&#22312;&#19981;&#21487;&#30693;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#20122;&#32447;&#24615;&#22686;&#38271;&#30340;&#36951;&#25022;&#12290;&#25105;&#20204;&#36890;&#36807;&#24213;&#23618;&#27010;&#24565;&#31867;&#30340;Littlestone&#21644;&#38408;&#20540;&#32500;&#24230;&#26469;&#38480;&#21046;&#36951;&#25022;&#12290;&#25105;&#20204;&#33719;&#24471;&#20102;&#31867;&#20284;&#30340;&#32467;&#26524;&#29992;&#20110;&#38750;&#21442;&#25968;&#21338;&#24328;&#65292;&#20854;&#20013;ERM&#39044;&#35328;&#26426;&#21487;&#20197;&#34987;&#29702;&#35299;&#20026;&#26368;&#20339;&#21709;&#24212;&#39044;&#35328;&#26426;&#65292;&#26681;&#25454;&#20854;&#20182;&#29609;&#23478;&#30340;&#28216;&#25103;&#21382;&#21490;&#25214;&#21040;&#19968;&#20010;&#29609;&#23478;&#30340;&#26368;&#20339;&#21709;&#24212;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20165;&#20381;&#36182;&#26368;&#20339;&#21709;&#24212;&#39044;&#35328;&#26426;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#25910;&#25947;&#21040;&#20004;&#20154;&#38646;&#21644;&#21338;&#24328;&#30340;&#36817;&#20284;&#26497;&#23567;-&#26497;&#22823;&#22343;&#34913;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
While ERM suffices to attain near-optimal generalization error in the stochastic learning setting, this is not known to be the case in the online learning setting, where algorithms for general concept classes rely on computationally inefficient oracles such as the Standard Optimal Algorithm (SOA). In this work, we propose an algorithm for online binary classification setting that relies solely on ERM oracle calls, and show that it has finite regret in the realizable setting and sublinearly growing regret in the agnostic setting. We bound the regret in terms of the Littlestone and threshold dimensions of the underlying concept class.  We obtain similar results for nonparametric games, where the ERM oracle can be interpreted as a best response oracle, finding the best response of a player to a given history of play of the other players. In this setting, we provide learning algorithms that only rely on best response oracles and converge to approximate-minimax equilibria in two-player zero
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#20540;&#25968;&#25454;&#22635;&#34917;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#26368;&#36817;&#37051;&#20272;&#35745;&#21644;&#39640;&#26031;&#26680;&#23494;&#24230;&#20272;&#35745;&#32467;&#21512;&#65292;&#33021;&#22815;&#26377;&#25928;&#22788;&#29702;&#22810;&#27169;&#24577;&#25968;&#25454;&#38598;&#20013;&#30340;&#32570;&#22833;&#20540;&#65292;&#24182;&#25552;&#20379;&#27604;&#24403;&#21069;&#26041;&#27861;&#26356;&#39640;&#30340;&#27010;&#29575;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2306.16906</link><description>&lt;p&gt;
&#25968;&#20540;&#25968;&#25454;&#22635;&#34917;&#30340;&#22810;&#27169;&#24577;&#25968;&#25454;&#38598;:&#19968;&#31181;&#27010;&#29575;&#26368;&#36817;&#37051;&#26680;&#23494;&#24230;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Numerical Data Imputation for Multimodal Data Sets: A Probabilistic Nearest-Neighbor Kernel Density Approach. (arXiv:2306.16906v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16906
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#20540;&#25968;&#25454;&#22635;&#34917;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#26368;&#36817;&#37051;&#20272;&#35745;&#21644;&#39640;&#26031;&#26680;&#23494;&#24230;&#20272;&#35745;&#32467;&#21512;&#65292;&#33021;&#22815;&#26377;&#25928;&#22788;&#29702;&#22810;&#27169;&#24577;&#25968;&#25454;&#38598;&#20013;&#30340;&#32570;&#22833;&#20540;&#65292;&#24182;&#25552;&#20379;&#27604;&#24403;&#21069;&#26041;&#27861;&#26356;&#39640;&#30340;&#27010;&#29575;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#20540;&#25968;&#25454;&#22635;&#34917;&#26041;&#27861;&#36890;&#36807;&#20272;&#35745;&#26367;&#25442;&#32570;&#22833;&#30340;&#20540;&#20197;&#21033;&#29992;&#19981;&#23436;&#25972;&#30340;&#25968;&#25454;&#38598;&#12290;&#24403;&#21069;&#30340;&#22635;&#34917;&#26041;&#27861;&#35797;&#22270;&#26368;&#23567;&#21270;&#26410;&#35266;&#23519;&#21040;&#30340;&#30495;&#23454;&#20540;&#21644;&#22635;&#34917;&#20540;&#20043;&#38388;&#30340;&#35823;&#24046;&#12290;&#20294;&#26159;&#65292;&#22312;&#22810;&#27169;&#24577;&#25110;&#22797;&#26434;&#20998;&#24067;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#31181;&#31574;&#30053;&#21487;&#33021;&#20250;&#20135;&#29983;&#20266;&#20687;&#65292;&#23548;&#33268;&#22635;&#34917;&#25928;&#26524;&#36739;&#24046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;$k$NN$\times$KDE&#31639;&#27861;: &#19968;&#31181;&#23558;&#26368;&#36817;&#37051;&#20272;&#35745;($k$NN)&#21644;&#20351;&#29992;&#39640;&#26031;&#26680;&#36827;&#34892;&#23494;&#24230;&#20272;&#35745;(KDE)&#32467;&#21512;&#30340;&#25968;&#25454;&#22635;&#34917;&#26041;&#27861;&#12290;&#25105;&#20204;&#20351;&#29992;&#20154;&#24037;&#21644;&#30495;&#23454;&#25968;&#25454;&#36827;&#34892;&#20102;&#19982;&#20043;&#21069;&#25968;&#25454;&#22635;&#34917;&#26041;&#27861;&#30340;&#27604;&#36739;&#65292;&#28041;&#21450;&#20102;&#19981;&#21516;&#30340;&#25968;&#25454;&#32570;&#22833;&#24773;&#20917;&#21644;&#19981;&#21516;&#30340;&#25968;&#25454;&#32570;&#22833;&#29575;&#65292;&#24182;&#19988;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#22788;&#29702;&#22797;&#26434;&#30340;&#21407;&#22987;&#25968;&#25454;&#32467;&#26500;&#65292;&#20135;&#29983;&#26356;&#20302;&#30340;&#25968;&#25454;&#22635;&#34917;&#35823;&#24046;&#65292;&#24182;&#25552;&#20379;&#27604;&#24403;&#21069;&#26041;&#27861;&#26356;&#39640;&#30340;&#27010;&#29575;&#20272;&#35745;&#12290;&#25105;&#20204;&#23558;&#20195;&#30721;&#20197;&#24320;&#28304;&#24418;&#24335;&#21457;&#24067;&#32473;&#31038;&#21306;&#65306;https://github.com/DeltaFloflo/knnxkde
&lt;/p&gt;
&lt;p&gt;
Numerical data imputation algorithms replace missing values by estimates to leverage incomplete data sets. Current imputation methods seek to minimize the error between the unobserved ground truth and the imputed values. But this strategy can create artifacts leading to poor imputation in the presence of multimodal or complex distributions. To tackle this problem, we introduce the $k$NN$\times$KDE algorithm: a data imputation method combining nearest neighbor estimation ($k$NN) and density estimation with Gaussian kernels (KDE). We compare our method with previous data imputation methods using artificial and real-world data with different data missing scenarios and various data missing rates, and show that our method can cope with complex original data structure, yields lower data imputation errors, and provides probabilistic estimates with higher likelihood than current methods. We release the code in open-source for the community: https://github.com/DeltaFloflo/knnxkde
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#65292;&#26412;&#30740;&#31350;&#26500;&#24314;&#20102;&#19968;&#20010;&#33258;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#65292;&#29992;&#20110;&#23398;&#20064;&#20195;&#29702;&#24066;&#22330;&#35746;&#21333;&#30340;&#34920;&#31034;&#12290;&#36827;&#19968;&#27493;&#22320;&#65292;&#25105;&#20204;&#20351;&#29992;K&#22343;&#20540;&#32858;&#31867;&#31639;&#27861;&#23545;&#20195;&#29702;&#35746;&#21333;&#30340;&#23398;&#20064;&#34920;&#31034;&#21521;&#37327;&#36827;&#34892;&#32858;&#31867;&#65292;&#20197;&#30830;&#23450;&#27599;&#20010;&#31751;&#20013;&#30340;&#19981;&#21516;&#34892;&#20026;&#31867;&#22411;&#12290;</title><link>http://arxiv.org/abs/2306.05987</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#30340;&#20195;&#29702;&#24066;&#22330;&#35746;&#21333;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Agent market orders representation through a contrastive learning approach. (arXiv:2306.05987v1 [q-fin.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05987
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#65292;&#26412;&#30740;&#31350;&#26500;&#24314;&#20102;&#19968;&#20010;&#33258;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#65292;&#29992;&#20110;&#23398;&#20064;&#20195;&#29702;&#24066;&#22330;&#35746;&#21333;&#30340;&#34920;&#31034;&#12290;&#36827;&#19968;&#27493;&#22320;&#65292;&#25105;&#20204;&#20351;&#29992;K&#22343;&#20540;&#32858;&#31867;&#31639;&#27861;&#23545;&#20195;&#29702;&#35746;&#21333;&#30340;&#23398;&#20064;&#34920;&#31034;&#21521;&#37327;&#36827;&#34892;&#32858;&#31867;&#65292;&#20197;&#30830;&#23450;&#27599;&#20010;&#31751;&#20013;&#30340;&#19981;&#21516;&#34892;&#20026;&#31867;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#35775;&#38382;Euronext&#30340;CAC40&#25968;&#25454;&#20013;&#30340;&#26631;&#35760;&#35746;&#21333;&#65292;&#20998;&#26512;&#20195;&#29702;&#22312;&#24066;&#22330;&#20013;&#26681;&#25454;&#20854;&#19979;&#36798;&#30340;&#35746;&#21333;&#30340;&#34892;&#20026;&#12290;&#26412;&#30740;&#31350;&#26500;&#24314;&#20102;&#19968;&#20010;&#33258;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#65292;&#20351;&#29992;&#19977;&#20803;&#32452;&#25439;&#22833;&#26469;&#26377;&#25928;&#22320;&#23398;&#20064;&#20195;&#29702;&#24066;&#22330;&#35746;&#21333;&#30340;&#34920;&#31034;&#12290;&#36890;&#36807;&#33719;&#21462;&#36825;&#20010;&#23398;&#20064;&#34920;&#31034;&#65292;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#21464;&#24471;&#21487;&#34892;&#12290;&#26412;&#30740;&#31350;&#20351;&#29992;K&#22343;&#20540;&#32858;&#31867;&#31639;&#27861;&#23545;&#20195;&#29702;&#35746;&#21333;&#30340;&#23398;&#20064;&#34920;&#31034;&#21521;&#37327;&#36827;&#34892;&#32858;&#31867;&#65292;&#20197;&#30830;&#23450;&#27599;&#20010;&#31751;&#20013;&#30340;&#19981;&#21516;&#34892;&#20026;&#31867;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Due to the access to the labeled orders on the CAC40 data from Euronext, we are able to analyse agents' behaviours in the market based on their placed orders. In this study, we construct a self-supervised learning model using triplet loss to effectively learn the representation of agent market orders. By acquiring this learned representation, various downstream tasks become feasible. In this work, we utilise the K-means clustering algorithm on the learned representation vectors of agent orders to identify distinct behaviour types within each cluster.
&lt;/p&gt;</description></item><item><title>&#20998;&#25955;SGD&#21644;&#24179;&#22343;&#26041;&#21521;SAM&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#26159;&#31561;&#20215;&#30340;&#65292;D-SGD&#34920;&#29616;&#20986;&#26799;&#24230;&#24179;&#28369;&#25928;&#24212;&#21644;&#38160;&#24230;&#27491;&#21017;&#21270;&#25928;&#24212;&#65292;&#32780;&#19988;&#21487;&#20197;&#25552;&#39640;&#21518;&#39564;&#35780;&#20272;&#65292;&#24182;&#35777;&#26126;&#20102;&#28508;&#22312;&#30340;&#27867;&#21270;&#33021;&#21147;</title><link>http://arxiv.org/abs/2306.02913</link><description>&lt;p&gt;
&#20998;&#25955;&#21270;SGD&#21644;&#24179;&#22343;&#26041;&#21521;SAM&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#26159;&#31561;&#20215;&#30340;
&lt;/p&gt;
&lt;p&gt;
Decentralized SGD and Average-direction SAM are Asymptotically Equivalent. (arXiv:2306.02913v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02913
&lt;/p&gt;
&lt;p&gt;
&#20998;&#25955;SGD&#21644;&#24179;&#22343;&#26041;&#21521;SAM&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#26159;&#31561;&#20215;&#30340;&#65292;D-SGD&#34920;&#29616;&#20986;&#26799;&#24230;&#24179;&#28369;&#25928;&#24212;&#21644;&#38160;&#24230;&#27491;&#21017;&#21270;&#25928;&#24212;&#65292;&#32780;&#19988;&#21487;&#20197;&#25552;&#39640;&#21518;&#39564;&#35780;&#20272;&#65292;&#24182;&#35777;&#26126;&#20102;&#28508;&#22312;&#30340;&#27867;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#25955;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;D-SGD&#65289;&#20801;&#35768;&#22312;&#27809;&#26377;&#20013;&#22830;&#26381;&#21153;&#22120;&#30340;&#25511;&#21046;&#19979;&#65292;&#22823;&#37327;&#35774;&#22791;&#21516;&#26102;&#36827;&#34892;&#21327;&#20316;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#29702;&#35770;&#35748;&#20026;&#65292;&#20998;&#25955;&#21270;&#19981;&#21487;&#36991;&#20813;&#22320;&#21066;&#24369;&#20102;&#27867;&#21270;&#33021;&#21147;&#12290;&#26412;&#25991;&#25361;&#25112;&#20256;&#32479;&#20449;&#24565;&#65292;&#25552;&#20986;&#20102;&#23436;&#20840;&#26032;&#30340;&#35282;&#24230;&#26469;&#29702;&#35299;&#20998;&#25955;&#23398;&#20064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19968;&#33324;&#38750;&#20984;&#38750;-$\beta$-&#24179;&#28369;&#35774;&#32622;&#19979;&#65292;D-SGD&#38544;&#24335;&#22320;&#26368;&#23567;&#21270;&#20102;&#24179;&#22343;&#26041;&#21521;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#65288;SAM&#65289;&#31639;&#27861;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;&#36825;&#31181;&#24778;&#20154;&#30340;&#28176;&#36817;&#31561;&#20215;&#25581;&#31034;&#20102;&#20869;&#22312;&#30340;&#27491;&#21017;&#21270;-&#20248;&#21270;&#26435;&#34913;&#20197;&#21450;&#20998;&#25955;&#21270;&#30340;&#19977;&#20010;&#20248;&#28857;&#65306;&#65288;1&#65289;D-SGD&#20013;&#23384;&#22312;&#19968;&#20010;&#33258;&#30001;&#30340;&#19981;&#30830;&#23450;&#24615;&#35780;&#20272;&#26426;&#21046;&#65292;&#21487;&#20197;&#25552;&#39640;&#21518;&#39564;&#20272;&#35745;&#65307;&#65288;2&#65289;D-SGD&#34920;&#29616;&#20986;&#26799;&#24230;&#24179;&#28369;&#25928;&#24212;&#65307;&#65288;3&#65289;D-SGD&#30340;&#38160;&#24230;&#27491;&#21017;&#21270;&#25928;&#24212;&#19981;&#20250;&#38543;&#30528;&#24635;&#25209;&#22788;&#29702;&#22823;&#23567;&#30340;&#22686;&#21152;&#32780;&#20943;&#23569;&#65292;&#36825;&#35777;&#26126;&#20102;&#28508;&#22312;&#30340;&#27867;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Decentralized stochastic gradient descent (D-SGD) allows collaborative learning on massive devices simultaneously without the control of a central server. However, existing theories claim that decentralization invariably undermines generalization. In this paper, we challenge the conventional belief and present a completely new perspective for understanding decentralized learning. We prove that D-SGD implicitly minimizes the loss function of an average-direction Sharpness-aware minimization (SAM) algorithm under general non-convex non-$\beta$-smooth settings. This surprising asymptotic equivalence reveals an intrinsic regularization-optimization trade-off and three advantages of decentralization: (1) there exists a free uncertainty evaluation mechanism in D-SGD to improve posterior estimation; (2) D-SGD exhibits a gradient smoothing effect; and (3) the sharpness regularization effect of D-SGD does not decrease as total batch size increases, which justifies the potential generalization b
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22914;&#20309;&#21033;&#29992;&#31526;&#21512;&#24615;&#39044;&#27979;&#25216;&#26415;&#65292;&#22312;&#22810;&#39033;&#36873;&#25321;&#39064;&#22238;&#31572;&#20219;&#21153;&#20013;&#20026;&#35821;&#35328;&#27169;&#22411;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#21457;&#29616;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#19982;&#39044;&#27979;&#20934;&#30830;&#24615;&#23494;&#20999;&#30456;&#20851;&#12290;</title><link>http://arxiv.org/abs/2305.18404</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#39033;&#36873;&#25321;&#39064;&#31572;&#26696;&#30830;&#35748;&#39044;&#27979;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Conformal Prediction with Large Language Models for Multi-Choice Question Answering. (arXiv:2305.18404v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18404
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22914;&#20309;&#21033;&#29992;&#31526;&#21512;&#24615;&#39044;&#27979;&#25216;&#26415;&#65292;&#22312;&#22810;&#39033;&#36873;&#25321;&#39064;&#22238;&#31572;&#20219;&#21153;&#20013;&#20026;&#35821;&#35328;&#27169;&#22411;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#21457;&#29616;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#19982;&#39044;&#27979;&#20934;&#30830;&#24615;&#23494;&#20999;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24191;&#27867;&#24320;&#21457;&#65292;&#23545;&#23427;&#20204;&#36827;&#34892;&#20581;&#22766;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#25216;&#26415;&#23558;&#25104;&#20026;&#23427;&#20204;&#22312;&#39640;&#39118;&#38505;&#22330;&#26223;&#19979;&#23433;&#20840;&#37096;&#32626;&#30340;&#20851;&#38190;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22914;&#20309;&#21033;&#29992;&#31526;&#21512;&#24615;&#39044;&#27979;&#25216;&#26415;&#65292;&#22312;&#22810;&#39033;&#36873;&#25321;&#39064;&#22238;&#31572;&#20219;&#21153;&#20013;&#20026;&#35821;&#35328;&#27169;&#22411;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#21457;&#29616;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#19982;&#39044;&#27979;&#20934;&#30830;&#24615;&#23494;&#20999;&#30456;&#20851;&#12290;&#36825;&#31181;&#35266;&#23519;&#23545;&#20110;&#19979;&#28216;&#24212;&#29992;&#65292;&#22914;&#36873;&#25321;&#24615;&#20998;&#31867;&#21644;&#36807;&#28388;&#20302;&#36136;&#37327;&#39044;&#27979;&#65292;&#21487;&#33021;&#20250;&#26377;&#29992;&#12290;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#31526;&#21512;&#24615;&#39044;&#27979;&#23545;&#20110;&#36229;&#20986;&#20027;&#39064;&#30340;&#38382;&#39064;&#30340;&#20132;&#25442;&#24615;&#20551;&#35774;&#65292;&#36825;&#21487;&#33021;&#26159;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#30340;&#26356;&#20026;&#29616;&#23454;&#30340;&#22330;&#26223;&#12290;&#26412;&#30740;&#31350;&#20026;&#22312;&#38656;&#35201;&#21487;&#38752;&#20445;&#35777;&#38169;&#35823;&#29575;&#30340;&#23433;&#20840;&#20851;&#38190;&#24773;&#20917;&#19979;&#26356;&#21152;&#20540;&#24471;&#20449;&#36182;&#21644;&#21487;&#38752;&#22320;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
As large language models continue to be widely developed, robust uncertainty quantification techniques will become crucial for their safe deployment in high-stakes scenarios. In this work, we explore how conformal prediction can be used to provide uncertainty quantification in language models for the specific task of multiple-choice question-answering. We find that the uncertainty estimates from conformal prediction are tightly correlated with prediction accuracy. This observation can be useful for downstream applications such as selective classification and filtering out low-quality predictions. We also investigate the exchangeability assumption required by conformal prediction to out-of-subject questions, which may be a more realistic scenario for many practical applications. Our work contributes towards more trustworthy and reliable usage of large language models in safety-critical situations, where robust guarantees of error rate are required.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20351;&#29992;&#38750;&#23545;&#31216;&#26680;&#65288;asymmetric kernels&#65289;&#23454;&#29616;Toeplitz&#31070;&#32463;&#32593;&#32476;&#65288;TNNs&#65289;&#30340;&#21152;&#36895;&#65292;&#36890;&#36807;&#31232;&#30095;&#21152;&#20302;&#31209;Toeplitz&#30697;&#38453;&#20998;&#35299;&#12289;&#23567;&#22411;1D&#21367;&#31215;&#21644;&#26367;&#25442;&#30456;&#23545;&#20301;&#32622;&#32534;&#30721;&#22120;&#65288;RPE&#65289;&#22810;&#23618;&#24863;&#30693;&#22120;&#65288;MLP&#65289;&#23454;&#29616;O&#65288;n&#65289;&#22797;&#26434;&#24230;&#65292;&#38024;&#23545;&#22240;&#26524;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#8220;&#24555;&#36895;&#8221;&#22240;&#26524;&#23631;&#34109;&#26469;&#25269;&#28040;&#36825;&#31181;&#26041;&#27861;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2305.09028</link><description>&lt;p&gt;
SKI&#21152;&#36895;Toeplitz&#31070;&#32463;&#32593;&#32476;&#65306;&#36890;&#36807;&#38750;&#23545;&#31216;&#26680;&#23454;&#29616;&#21152;&#36895;
&lt;/p&gt;
&lt;p&gt;
SKI to go Faster: Accelerating Toeplitz Neural Networks via Asymmetric Kernels. (arXiv:2305.09028v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09028
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20351;&#29992;&#38750;&#23545;&#31216;&#26680;&#65288;asymmetric kernels&#65289;&#23454;&#29616;Toeplitz&#31070;&#32463;&#32593;&#32476;&#65288;TNNs&#65289;&#30340;&#21152;&#36895;&#65292;&#36890;&#36807;&#31232;&#30095;&#21152;&#20302;&#31209;Toeplitz&#30697;&#38453;&#20998;&#35299;&#12289;&#23567;&#22411;1D&#21367;&#31215;&#21644;&#26367;&#25442;&#30456;&#23545;&#20301;&#32622;&#32534;&#30721;&#22120;&#65288;RPE&#65289;&#22810;&#23618;&#24863;&#30693;&#22120;&#65288;MLP&#65289;&#23454;&#29616;O&#65288;n&#65289;&#22797;&#26434;&#24230;&#65292;&#38024;&#23545;&#22240;&#26524;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#8220;&#24555;&#36895;&#8221;&#22240;&#26524;&#23631;&#34109;&#26469;&#25269;&#28040;&#36825;&#31181;&#26041;&#27861;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Toeplitz&#31070;&#32463;&#32593;&#32476;&#65288;TNNs&#65289;&#26159;&#26368;&#36817;&#20986;&#29616;&#24182;&#21462;&#24471;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#32467;&#26524;&#30340;&#24207;&#21015;&#27169;&#22411;&#12290;&#23427;&#20204;&#38656;&#35201;O(n log n)&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#21644;O(n)&#30340;&#30456;&#23545;&#20301;&#32622;&#32534;&#30721;&#22120;&#65288;RPE&#65289;&#22810;&#23618;&#24863;&#30693;&#22120;&#65288;MLP&#65289;&#21644;&#34928;&#20943;&#20559;&#24046;&#35843;&#29992;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20943;&#23569;&#23427;&#20204;&#12290;&#25105;&#20204;&#39318;&#20808;&#25351;&#20986;&#65292;RPE&#26159;&#19968;&#20010;&#38750;&#23545;&#31216;&#27491;&#23450;&#26680;&#65292;&#32780;Toeplitz&#30697;&#38453;&#26159;&#20266;&#26684;&#25289;&#22982;&#30697;&#38453;&#12290;&#27492;&#22806;&#65306;1&#65289;&#23398;&#20064;&#30340;&#26680;&#22312;&#20027;&#23545;&#35282;&#32447;&#38468;&#36817;&#26174;&#31034;&#20986;&#21050;&#29366;&#34892;&#20026;&#65292;&#32780;&#22312;&#20854;&#20182;&#20301;&#32622;&#21017;&#34920;&#29616;&#20986;&#24179;&#28369;&#34892;&#20026;&#65307;2&#65289;RPE MLP&#36739;&#24930;&#12290;&#23545;&#20110;&#21452;&#21521;&#27169;&#22411;&#65292;&#36825;&#20419;&#20351;&#25105;&#20204;&#36827;&#34892;&#31232;&#30095;&#21152;&#20302;&#31209;Toeplitz&#30697;&#38453;&#20998;&#35299;&#12290;&#23545;&#20110;&#31232;&#30095;&#32452;&#20214;&#30340;&#25805;&#20316;&#65292;&#25105;&#20204;&#36827;&#34892;&#23567;&#22411;1D&#21367;&#31215;&#12290;&#23545;&#20110;&#20302;&#31209;&#32452;&#20214;&#65292;&#25105;&#20204;&#23558;RPE MLP&#26367;&#25442;&#20026;&#32447;&#24615;&#25554;&#20540;&#65292;&#24182;&#20351;&#29992;&#38750;&#23545;&#31216;&#26377;&#32467;&#26500;&#30340;&#20869;&#26680;&#25554;&#20540;&#65288;SKI&#65289;&#65288;Wilson&#31561;&#65292;2015&#65289;&#20197;&#23454;&#29616;O&#65288;n&#65289;&#22797;&#26434;&#24230;&#65306;&#25105;&#20204;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#35823;&#24046;&#20998;&#26512;&#12290;&#23545;&#20110;&#22240;&#26524;&#27169;&#22411;&#65292;&#8220;&#24555;&#36895;&#8221;&#22240;&#26524;&#23631;&#34109;&#65288;Katharopoulos&#31561;&#65292;2020&#65289;&#25269;&#28040;&#20102;SKI&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
Toeplitz Neural Networks (TNNs) (Qin et. al. 2023) are a recent sequence model with impressive results. They require O(n log n) computational complexity and O(n) relative positional encoder (RPE) multi-layer perceptron (MLP) and decay bias calls. We aim to reduce both. We first note that the RPE is a non-SPD (symmetric positive definite) kernel and the Toeplitz matrices are pseudo-Gram matrices. Further 1) the learned kernels display spiky behavior near the main diagonals with otherwise smooth behavior; 2) the RPE MLP is slow. For bidirectional models, this motivates a sparse plus low-rank Toeplitz matrix decomposition. For the sparse component's action, we do a small 1D convolution. For the low rank component, we replace the RPE MLP with linear interpolation and use asymmetric Structured Kernel Interpolation (SKI) (Wilson et. al. 2015) for O(n) complexity: we provide rigorous error analysis. For causal models, "fast" causal masking (Katharopoulos et. al. 2020) negates SKI's benefits. 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#19977;&#27493;&#39588;&#26041;&#27861;&#65292;&#31616;&#21270;&#20102;&#21464;&#20998;&#36125;&#21494;&#26031;&#36817;&#20284;&#25512;&#26029;&#26041;&#27861;&#30340;&#25512;&#23548;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2304.14251</link><description>&lt;p&gt;
&#31616;&#21270;&#21464;&#20998;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#25512;&#23548;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Variational Bayes Made Easy. (arXiv:2304.14251v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14251
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#19977;&#27493;&#39588;&#26041;&#27861;&#65292;&#31616;&#21270;&#20102;&#21464;&#20998;&#36125;&#21494;&#26031;&#36817;&#20284;&#25512;&#26029;&#26041;&#27861;&#30340;&#25512;&#23548;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#36125;&#21494;&#26031;&#26041;&#27861;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#36817;&#20284;&#25512;&#26029;&#26041;&#27861;&#65292;&#20294;&#20854;&#25512;&#23548;&#36807;&#31243;&#21487;&#33021;&#24456;&#32321;&#29712;&#12290;&#20026;&#20102;&#31616;&#21270;&#36825;&#20010;&#36807;&#31243;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#20010;&#19977;&#27493;&#39588;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26174;&#24335;&#23547;&#25214;&#20851;&#20110;&#24050;&#30693;&#20998;&#24067;&#26399;&#26395;&#30340;&#32447;&#24615;&#24615;&#65292;&#26469;&#30830;&#23450;&#21518;&#39564;&#20998;&#24067;&#24418;&#24335;&#12290;&#28982;&#21518;&#25105;&#20204;&#21487;&#20197;&#30452;&#25509;&#36890;&#36807;&#8220;&#35835;&#21462;&#8221;&#36825;&#20123;&#26399;&#26395;&#21069;&#30340;&#39033;&#65292;&#20889;&#20986;&#26356;&#26032;&#12290;&#36825;&#20010;&#26041;&#27861;&#20351;&#24471;&#25512;&#23548;&#26356;&#21152;&#31616;&#21333;&#65292;&#24555;&#36895;&#65292;&#31616;&#30701;&#21644;&#36890;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational Bayes is a popular method for approximate inference but its derivation can be cumbersome. To simplify the process, we give a 3-step recipe to identify the posterior form by explicitly looking for linearity with respect to expectations of well-known distributions. We can then directly write the update by simply ``reading-off'' the terms in front of those expectations. The recipe makes the derivation easier, faster, shorter, and more general.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36125;&#21494;&#26031;&#31639;&#27861;&#30340;&#33258;&#36866;&#24212;&#23454;&#39564;&#26694;&#26550;&#65292;&#21487;&#28789;&#27963;&#22788;&#29702;&#20219;&#20309;&#25209;&#22788;&#29702;&#22823;&#23567;&#12290;&#36890;&#36807;&#27491;&#24577;&#36817;&#20284;&#25351;&#23548;&#21487;&#25193;&#23637;&#33258;&#36866;&#24212;&#35774;&#35745;&#65292;&#37319;&#29992;&#27531;&#20313;&#26102;&#38480;&#20248;&#21270;&#36873;&#25321;&#37319;&#26679;&#20998;&#37197;&#65292;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2303.11582</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#36866;&#24212;&#24615;&#23454;&#39564;&#65306;&#28789;&#27963;&#25209;&#22788;&#29702;&#30340;&#36125;&#21494;&#26031;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Adaptive Experimentation at Scale: Bayesian Algorithms for Flexible Batches. (arXiv:2303.11582v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11582
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36125;&#21494;&#26031;&#31639;&#27861;&#30340;&#33258;&#36866;&#24212;&#23454;&#39564;&#26694;&#26550;&#65292;&#21487;&#28789;&#27963;&#22788;&#29702;&#20219;&#20309;&#25209;&#22788;&#29702;&#22823;&#23567;&#12290;&#36890;&#36807;&#27491;&#24577;&#36817;&#20284;&#25351;&#23548;&#21487;&#25193;&#23637;&#33258;&#36866;&#24212;&#35774;&#35745;&#65292;&#37319;&#29992;&#27531;&#20313;&#26102;&#38480;&#20248;&#21270;&#36873;&#25321;&#37319;&#26679;&#20998;&#37197;&#65292;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934;&#30340;&#36125;&#21494;&#26031;&#31639;&#27861;&#20551;&#23450;&#25345;&#32493;&#37325;&#26032;&#20998;&#37197;&#27979;&#37327;&#24037;&#20316;&#65292;&#36825;&#22312;&#23454;&#29616;&#36807;&#31243;&#20013;&#23384;&#22312;&#24310;&#36831;&#21453;&#39304;&#21644;&#22522;&#30784;&#35774;&#26045;/&#32452;&#32455;&#38590;&#39064;&#31561;&#25361;&#25112;&#12290;&#26412;&#25991;&#38024;&#23545;&#20165;&#26377;&#23569;&#25968;&#37325;&#26032;&#20998;&#37197;&#38454;&#27573;&#30340;&#23454;&#38469;&#24773;&#20917;&#65292;&#20854;&#20013;&#27979;&#37327;&#32467;&#26524;&#26159;&#20197;&#25209;&#22788;&#29702;&#24418;&#24335;&#27979;&#37327;&#30340;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36866;&#24212;&#24615;&#23454;&#39564;&#26694;&#26550;&#65292;&#21487;&#28789;&#27963;&#22788;&#29702;&#20219;&#20309;&#25209;&#22788;&#29702;&#22823;&#23567;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#35266;&#23519;&#26159;&#65292;&#22312;&#32479;&#35745;&#25512;&#26029;&#20013;&#26222;&#36941;&#20351;&#29992;&#30340;&#27491;&#24577;&#36817;&#20284;&#20063;&#21487;&#20197;&#25351;&#23548;&#21487;&#25193;&#23637;&#33258;&#36866;&#24212;&#35774;&#35745;&#12290;&#36890;&#36807;&#25512;&#23548;&#28176;&#36827;&#39034;&#24207;&#23454;&#39564;&#65292;&#25105;&#20204;&#21046;&#23450;&#20102;&#19968;&#31181;&#21160;&#24577;&#35268;&#21010;&#65292;&#21487;&#20197;&#21033;&#29992;&#24179;&#22343;&#22238;&#25253;&#30340;&#20808;&#39564;&#20449;&#24687;&#12290;&#21160;&#24577;&#35268;&#21010;&#30340;&#29366;&#24577;&#36716;&#31227;&#30456;&#23545;&#20110;&#37319;&#26679;&#20998;&#37197;&#26159;&#21487;&#24494;&#30340;&#65292;&#20801;&#35768;&#20351;&#29992;&#22522;&#20110;&#26799;&#24230;&#30340;&#26041;&#27861;&#36827;&#34892;&#35268;&#21010;&#21644;&#31574;&#30053;&#20248;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#36845;&#20195;&#35268;&#21010;&#26041;&#27861;&#65292;&#21363;&#27531;&#20313;&#26102;&#38480;&#20248;&#21270;&#65292;&#36890;&#36807;&#20248;&#21270;&#24179;&#34913;&#25506;&#32034;&#21644;&#21033;&#29992;&#30340;&#35268;&#21010;&#30446;&#26631;&#26469;&#36873;&#25321;&#37319;&#26679;&#20998;&#37197;&#12290;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#22522;&#20934;&#27979;&#35797;&#38382;&#39064;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#20855;&#26377;&#27169;&#22359;&#21270;&#21644;&#26131;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Standard bandit algorithms that assume continual reallocation of measurement effort are challenging to implement due to delayed feedback and infrastructural/organizational difficulties. Motivated by practical instances involving a handful of reallocation epochs in which outcomes are measured in batches, we develop a new adaptive experimentation framework that can flexibly handle any batch size. Our main observation is that normal approximations universal in statistical inference can also guide the design of scalable adaptive designs. By deriving an asymptotic sequential experiment, we formulate a dynamic program that can leverage prior information on average rewards. State transitions of the dynamic program are differentiable with respect to the sampling allocations, allowing the use of gradient-based methods for planning and policy optimization. We propose a simple iterative planning method, Residual Horizon Optimization, which selects sampling allocations by optimizing a planning obj
&lt;/p&gt;</description></item><item><title>&#24102;&#26377;&#32972;&#21253;&#30340;&#25504;&#22842;&#32773;&#38382;&#39064;&#22312;&#38543;&#26426;&#21644;&#25932;&#23545;&#24773;&#20917;&#19979;&#23384;&#22312;&#24040;&#22823;&#30340;&#24046;&#36317;&#65292;&#23588;&#20854;&#26159;&#22312;&#25932;&#23545;&#24773;&#20917;&#19979;&#65292;&#24403;&#39044;&#31639;&#26356;&#21152;&#32039;&#32570;&#26102;&#20445;&#35777;&#24615;&#33021;&#21464;&#24471;&#26356;&#24046;&#12290;</title><link>http://arxiv.org/abs/2302.14686</link><description>&lt;p&gt;
&#24102;&#26377;&#32972;&#21253;&#30340;&#36817;&#20284;&#31283;&#23450;&#25504;&#22842;&#32773;
&lt;/p&gt;
&lt;p&gt;
Approximately Stationary Bandits with Knapsacks. (arXiv:2302.14686v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.14686
&lt;/p&gt;
&lt;p&gt;
&#24102;&#26377;&#32972;&#21253;&#30340;&#25504;&#22842;&#32773;&#38382;&#39064;&#22312;&#38543;&#26426;&#21644;&#25932;&#23545;&#24773;&#20917;&#19979;&#23384;&#22312;&#24040;&#22823;&#30340;&#24046;&#36317;&#65292;&#23588;&#20854;&#26159;&#22312;&#25932;&#23545;&#24773;&#20917;&#19979;&#65292;&#24403;&#39044;&#31639;&#26356;&#21152;&#32039;&#32570;&#26102;&#20445;&#35777;&#24615;&#33021;&#21464;&#24471;&#26356;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24102;&#26377;&#32972;&#21253;&#30340;&#25504;&#22842;&#32773;&#38382;&#39064;&#65288;BwK&#65289;&#26159;&#22312;&#20840;&#23616;&#39044;&#31639;&#32422;&#26463;&#19979;&#23558;&#25504;&#22842;&#32773;&#38382;&#39064;&#36827;&#34892;&#27867;&#21270;&#30340;&#30740;&#31350;&#65292;&#36817;&#24180;&#26469;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#20851;&#27880;&#30340;&#26159;&#20004;&#20010;&#26497;&#31471;&#20043;&#19968;&#65306;&#38543;&#26426;BwK&#65292;&#22312;&#27599;&#19968;&#36718;&#20013;&#65292;&#22870;&#21169;&#21644;&#36164;&#28304;&#30340;&#28040;&#32791;&#20174;&#19968;&#20010;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#20998;&#24067;&#20013;&#37319;&#26679;&#65307;&#32780;&#25932;&#23545;BwK&#65292;&#21017;&#30001;&#23545;&#25163;&#36873;&#25321;&#36825;&#20123;&#21442;&#25968;&#12290;&#36825;&#20004;&#31181;&#24773;&#20917;&#19979;&#30340;&#21487;&#23454;&#29616;&#20445;&#35777;&#23384;&#22312;&#24040;&#22823;&#30340;&#24046;&#36317;&#65306;&#22312;&#38543;&#26426;&#24773;&#20917;&#19979;&#21487;&#20197;&#36798;&#21040;&#26080;&#24724;&#23398;&#20064;&#65292;&#32780;&#22312;&#25932;&#23545;&#24773;&#20917;&#19979;&#21482;&#33021;&#36798;&#21040;&#22522;&#20110;&#31454;&#20105;&#27604;&#30340;&#20445;&#35777;&#65292;&#20854;&#20013;&#31454;&#20105;&#27604;&#21462;&#20915;&#20110;&#39044;&#31639;&#25110;&#21516;&#26102;&#21462;&#20915;&#20110;&#26102;&#38388;&#21644;&#36164;&#28304;&#25968;&#37327;&#12290;&#36825;&#31181;&#24046;&#36317;&#20043;&#25152;&#20197;&#22914;&#27492;&#24040;&#22823;&#65292;&#22312;&#25932;&#23545;BwK&#30340;&#20856;&#22411;&#24773;&#20917;&#19979;&#65292;&#20445;&#35777;&#24615;&#33021;&#21464;&#24471;&#26356;&#24046;&#26102;&#65292;&#39044;&#31639;&#26356;&#21152;&#32039;&#32570;&#12290;&#34429;&#28982;&#24050;&#30693;&#23384;&#22312;&#8220;&#20004;&#20840;&#20854;&#32654;&#8221;&#31867;&#22411;&#30340;&#31639;&#27861;&#65288;&#21333;&#20010;&#31639;&#27861;&#21487;&#20197;&#22312;&#20004;&#20010;&#26497;&#31471;&#24773;&#20917;&#19979;&#25552;&#20379;&#26368;&#20339;&#30340;&#21487;&#23454;&#29616;&#20445;&#35777;&#65289;&#65292;&#23427;&#20204;&#30340;&#30028;&#38480;&#21017;&#20250;&#21464;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bandits with Knapsacks (BwK), the generalization of the Bandits problem under global budget constraints, has received a lot of attention in recent years. Previous work has focused on one of the two extremes: Stochastic BwK where the rewards and consumptions of the resources of each round are sampled from an i.i.d. distribution, and Adversarial BwK where these parameters are picked by an adversary. Achievable guarantees in the two cases exhibit a massive gap: No-regret learning is achievable in the stochastic case, but in the adversarial case only competitive ratio style guarantees are achievable, where the competitive ratio depends either on the budget or on both the time and the number of resources. What makes this gap so vast is that in Adversarial BwK the guarantees get worse in the typical case when the budget is more binding. While ``best-of-both-worlds'' type algorithms are known (single algorithms that provide the best achievable guarantee in each extreme case), their bounds deg
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#33258;&#36866;&#24212;&#31232;&#30095;&#39640;&#26031;&#36807;&#31243;&#65292;&#33021;&#22815;&#22312;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#36827;&#34892;&#39640;&#25928;&#30340;&#27169;&#22411;&#26356;&#26032;&#65292;&#24182;&#20855;&#26377;&#24555;&#36895;&#30340;&#25512;&#29702;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.10325</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#31232;&#30095;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Adaptive Sparse Gaussian Process. (arXiv:2302.10325v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10325
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#33258;&#36866;&#24212;&#31232;&#30095;&#39640;&#26031;&#36807;&#31243;&#65292;&#33021;&#22815;&#22312;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#36827;&#34892;&#39640;&#25928;&#30340;&#27169;&#22411;&#26356;&#26032;&#65292;&#24182;&#20855;&#26377;&#24555;&#36895;&#30340;&#25512;&#29702;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#36866;&#24212;&#23398;&#20064;&#23545;&#20110;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#30340;&#23398;&#20064;&#26426;&#22120;&#26159;&#24517;&#35201;&#30340;&#65292;&#22240;&#20026;&#23427;&#38656;&#35201;&#24536;&#35760;&#36807;&#21435;&#30340;&#25968;&#25454;&#20998;&#24067;&#12290;&#39640;&#25928;&#30340;&#31639;&#27861;&#38656;&#35201;&#32039;&#20945;&#30340;&#27169;&#22411;&#26356;&#26032;&#65292;&#20197;&#20415;&#19981;&#38543;&#30528;&#26032;&#25968;&#25454;&#30340;&#21040;&#26469;&#32780;&#22686;&#21152;&#35745;&#31639;&#36127;&#25285;&#65292;&#24182;&#20197;&#26368;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#36827;&#34892;&#22312;&#32447;&#21442;&#25968;&#26356;&#26032;&#12290;&#29616;&#26377;&#30340;&#35299;&#20915;&#26041;&#26696;&#21482;&#26159;&#37096;&#20998;&#28385;&#36275;&#36825;&#20123;&#38656;&#27714;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#33021;&#22815;&#35299;&#20915;&#25152;&#26377;&#36825;&#20123;&#38382;&#39064;&#30340;&#33258;&#36866;&#24212;&#31232;&#30095;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#12290;&#25105;&#20204;&#39318;&#20808;&#36890;&#36807;&#36951;&#24536;&#22240;&#23376;&#37325;&#26032;&#23450;&#20041;&#20102;&#21464;&#20998;&#31232;&#30095;GP&#31639;&#27861;&#65292;&#20351;&#20854;&#20855;&#26377;&#33258;&#36866;&#24212;&#24615;&#12290;&#25509;&#19979;&#26469;&#65292;&#20026;&#20102;&#20351;&#27169;&#22411;&#25512;&#29702;&#23613;&#21487;&#33021;&#31616;&#21333;&#65292;&#25105;&#20204;&#24314;&#35758;&#27599;&#24403;&#20986;&#29616;&#26032;&#26679;&#26412;&#26102;&#21516;&#26102;&#26356;&#26032;&#31232;&#30095;GP&#27169;&#22411;&#30340;&#19968;&#20010;&#21333;&#20010;&#24341;&#23548;&#28857;&#21644;&#20854;&#20182;&#27169;&#22411;&#21442;&#25968;&#12290;&#32467;&#26524;&#65292;&#35813;&#31639;&#27861;&#21576;&#29616;&#20986;&#25512;&#29702;&#36807;&#31243;&#30340;&#24555;&#36895;&#25910;&#25947;&#24615;&#65292;&#21363;&#20351;&#22312;&#39640;&#24230;&#38750;&#24179;&#31283;&#30340;&#29615;&#22659;&#20013;&#20063;&#33021;&#36827;&#34892;&#39640;&#25928;&#30340;&#27169;&#22411;&#26356;&#26032;&#65288;&#21482;&#38656;&#19968;&#27425;&#25512;&#29702;&#36845;&#20195;&#65289;&#12290;&#35797;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#31639;&#27861;&#22312;&#22810;&#31181;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#20102;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adaptive learning is necessary for non-stationary environments where the learning machine needs to forget past data distribution. Efficient algorithms require a compact model update to not grow in computational burden with the incoming data and with the lowest possible computational cost for online parameter updating. Existing solutions only partially cover these needs. Here, we propose the first adaptive sparse Gaussian Process (GP) able to address all these issues. We first reformulate a variational sparse GP algorithm to make it adaptive through a forgetting factor. Next, to make the model inference as simple as possible, we propose updating a single inducing point of the sparse GP model together with the remaining model parameters every time a new sample arrives. As a result, the algorithm presents a fast convergence of the inference process, which allows an efficient model update (with a single inference iteration) even in highly non-stationary environments. Experimental results d
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#28145;&#24230;&#23398;&#29983;&#26426;&#22120;&#30340;&#25945;&#24072;-&#23398;&#29983;&#35774;&#32622;&#65292;&#36890;&#36807;&#23398;&#29983;&#26426;&#22120;&#30340;&#38598;&#21512;&#26469;&#30740;&#31350;&#30001;&#20855;&#26377;&#22823;&#37327;&#21487;&#35843;&#21442;&#25968;&#30340;DNN&#30340;&#30417;&#30563;&#23398;&#20064;&#12290;&#30740;&#31350;&#34920;&#26126;DNN&#30340;&#23398;&#20064;&#22312;&#32593;&#32476;&#31354;&#38388;&#20013;&#30456;&#24403;&#24322;&#36136;&#12290;</title><link>http://arxiv.org/abs/2302.07419</link><description>&lt;p&gt;
&#36890;&#36807;&#28145;&#24230;&#23398;&#29983;&#26426;&#22120;&#23454;&#29616;&#31354;&#38388;&#24322;&#36136;&#24615;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Spatially heterogeneous learning by a deep student machine. (arXiv:2302.07419v3 [cond-mat.dis-nn] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07419
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#28145;&#24230;&#23398;&#29983;&#26426;&#22120;&#30340;&#25945;&#24072;-&#23398;&#29983;&#35774;&#32622;&#65292;&#36890;&#36807;&#23398;&#29983;&#26426;&#22120;&#30340;&#38598;&#21512;&#26469;&#30740;&#31350;&#30001;&#20855;&#26377;&#22823;&#37327;&#21487;&#35843;&#21442;&#25968;&#30340;DNN&#30340;&#30417;&#30563;&#23398;&#20064;&#12290;&#30740;&#31350;&#34920;&#26126;DNN&#30340;&#23398;&#20064;&#22312;&#32593;&#32476;&#31354;&#38388;&#20013;&#30456;&#24403;&#24322;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#21462;&#24471;&#20102;&#38750;&#20961;&#30340;&#25104;&#21151;&#65292;&#20294;&#30001;&#20110;&#20855;&#26377;&#22823;&#37327;&#21487;&#35843;&#21442;&#25968;&#65292;&#20854;&#20173;&#28982;&#26159;&#40657;&#21283;&#23376;&#12290;&#20026;&#20102;&#30740;&#31350;DNN&#30340;&#38544;&#34255;&#23618;&#65292;&#26412;&#25991;&#36890;&#36807;&#19968;&#31181;&#32479;&#35745;&#21147;&#23398;&#26041;&#27861;&#31216;&#20026;&#25945;&#24072;-&#23398;&#29983;&#35774;&#32622;&#65292;&#30740;&#31350;&#20102;&#30001;&#23485;&#24230;&#20026;N&#65292;&#28145;&#24230;&#20026;L&#65292;&#30001;&#20855;&#26377;c&#20010;&#36755;&#20837;&#30340;&#24863;&#30693;&#26426;&#32452;&#25104;&#30340;DNN&#30340;&#30417;&#30563;&#23398;&#20064;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#23398;&#29983;&#26426;&#22120;&#30340;&#38598;&#21512;&#65292;&#35813;&#38598;&#21512;&#21487;&#20197;&#31934;&#30830;&#37325;&#29616;&#30001;&#25945;&#24072;&#26426;&#22120;&#25552;&#20379;&#30340;M&#32452;N&#32500;&#36755;&#20837;/&#36755;&#20986;&#20851;&#31995;&#12290;&#25105;&#20204;&#20351;&#29992;&#21103;&#26412;&#26041;&#27861;&#65288;H. Yoshino&#65288;2020&#65289;&#65289;&#29702;&#35770;&#20998;&#26512;&#20102;&#38598;&#21512;&#65292;&#24182;&#36827;&#34892;&#20102;&#36138;&#23146;&#30340;Monte Carlo&#27169;&#25311;&#12290;&#23545;&#20110;&#39640;&#32500;&#25968;&#25454;$N \gg 1$&#65292;&#29702;&#35770;&#22312;'&#23494;&#38598;&#26497;&#38480;' $N \gg c \gg 1$ &#21644; $M \gg 1$ &#19988;&#22266;&#23450;$\alpha=M/c$&#26102;&#21464;&#24471;&#31934;&#30830;&#12290;&#29702;&#35770;&#21644;&#27169;&#25311;&#37117;&#34920;&#26126;&#65292;DNN&#30340;&#23398;&#20064;&#22312;&#32593;&#32476;&#31354;&#38388;&#20013;&#30456;&#24403;&#24322;&#36136;&#65306;&#26426;&#22120;&#30340;&#37197;&#32622;&#22312;&#38752;&#36817;&#36755;&#20837;/&#36755;&#20986;&#30340;&#23618;&#20869;&#26356;&#21152;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the spectacular successes, deep neural networks (DNN) with a huge number of adjustable parameters remain largely black boxes. To shed light on the hidden layers of DNN, we study supervised learning by a DNN of width $N$ and depth $L$ consisting of perceptrons with $c$ inputs by a statistical mechanics approach called the teacher-student setting. We consider an ensemble of student machines that exactly reproduce $M$ sets of $N$ dimensional input/output relations provided by a teacher machine. We analyze the ensemble theoretically using a replica method (H. Yoshino (2020)) and numerically performing greedy Monte Carlo simulations. The replica theory which works on high dimensional data $N \gg 1$ becomes exact in 'dense limit' $N \gg c \gg 1$ and $M \gg 1$ with fixed $\alpha=M/c$. Both the theory and the simulation suggest learning by the DNN is quite heterogeneous in the network space: configurations of the machines are more correlated within the layers closer to the input/output
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#23637;&#24320;&#26041;&#27861;&#65292;&#21487;&#20197;&#24471;&#21040;&#26080;&#32452;&#21512;&#30340;&#24046;&#20998;&#25130;&#38754;&#24182;&#19988;&#21487;&#20197;&#21078;&#26512;&#24178;&#25200;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/2302.05390</link><description>&lt;p&gt;
&#26080;&#32452;&#21512;&#24335;&#27010;&#35980;&#23637;&#24320;
&lt;/p&gt;
&lt;p&gt;
Unbinned Profiled Unfolding. (arXiv:2302.05390v3 [hep-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05390
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#23637;&#24320;&#26041;&#27861;&#65292;&#21487;&#20197;&#24471;&#21040;&#26080;&#32452;&#21512;&#30340;&#24046;&#20998;&#25130;&#38754;&#24182;&#19988;&#21487;&#20197;&#21078;&#26512;&#24178;&#25200;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23637;&#24320;&#26159;&#31890;&#23376;&#29289;&#29702;&#23454;&#39564;&#20013;&#30340;&#37325;&#35201;&#36807;&#31243;&#65292;&#23427;&#32416;&#27491;&#20102;&#25506;&#27979;&#22120;&#25928;&#24212;&#65292;&#24182;&#25552;&#20379;&#20102;&#21487;&#29992;&#20110;&#25552;&#21462;&#22522;&#26412;&#29289;&#29702;&#21442;&#25968;&#31561;&#19968;&#31995;&#21015;&#21518;&#32493;&#20219;&#21153;&#30340;&#24046;&#20998;&#25130;&#38754;&#27979;&#37327;&#12290;&#20256;&#32479;&#19978;&#65292;&#23637;&#24320;&#26159;&#36890;&#36807;&#23558;&#30446;&#26631;&#30456;&#31354;&#38388;&#31163;&#25955;&#21270;&#20026;&#26377;&#38480;&#25968;&#37327;&#30340;&#21306;&#38388;&#26469;&#36827;&#34892;&#30340;&#65292;&#24182;&#19988;&#22312;&#23637;&#24320;&#21464;&#37327;&#30340;&#25968;&#37327;&#19978;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#26368;&#36817;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#19968;&#20123;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#36827;&#34892;&#26080;&#32452;&#21512;&#23637;&#24320;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#65288;&#22914;&#22823;&#22810;&#25968;&#23637;&#24320;&#26041;&#27861;&#65289;&#37117;&#19981;&#20801;&#35768;&#21516;&#26102;&#32422;&#26463;&#65288;&#21078;&#26512;&#65289;&#24178;&#25200;&#21442;&#25968;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#23637;&#24320;&#26041;&#27861;&#65292;&#21487;&#20197;&#24471;&#21040;&#26080;&#32452;&#21512;&#30340;&#24046;&#20998;&#25130;&#38754;&#24182;&#21487;&#20197;&#21078;&#26512;&#24178;&#25200;&#21442;&#25968;&#12290;&#26426;&#22120;&#23398;&#20064;&#25439;&#22833;&#20989;&#25968;&#26159;&#22522;&#20110;&#25506;&#27979;&#22120;&#32423;&#21035;&#30340;&#20998;&#21306;&#36755;&#20837;&#30340;&#20840;&#27010;&#29575;&#20989;&#25968;&#12290;&#25105;&#20204;&#39318;&#20808;&#29992;&#31616;&#21333;&#30340;&#39640;&#26031;&#31034;&#20363;&#28436;&#31034;&#20102;&#35813;&#26041;&#27861;&#65292;&#28982;&#21518;&#23637;&#31034;&#20102;&#23545;&#27169;&#25311;&#25968;&#25454;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unfolding is an important procedure in particle physics experiments which corrects for detector effects and provides differential cross section measurements that can be used for a number of downstream tasks, such as extracting fundamental physics parameters. Traditionally, unfolding is done by discretizing the target phase space into a finite number of bins and is limited in the number of unfolded variables. Recently, there have been a number of proposals to perform unbinned unfolding with machine learning. However, none of these methods (like most unfolding methods) allow for simultaneously constraining (profiling) nuisance parameters. We propose a new machine learning-based unfolding method that results in an unbinned differential cross section and can profile nuisance parameters. The machine learning loss function is the full likelihood function, based on binned inputs at detector-level. We first demonstrate the method with simple Gaussian examples and then show the impact on a simu
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#22522;&#20110;&#25968;&#25454;&#20381;&#36182;&#30340;&#20998;&#24418;&#32500;&#24230;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#19981;&#38656;&#35201;Lipschitz&#20551;&#35774;&#65292;&#24182;&#33021;&#25511;&#21046;&#27867;&#21270;&#35823;&#24046;&#21644;&#20114;&#20449;&#24687;&#39033;&#12290;</title><link>http://arxiv.org/abs/2302.02766</link><description>&lt;p&gt;
&#25968;&#25454;&#20381;&#36182;&#20998;&#24418;&#32500;&#24230;&#30340;&#27867;&#21270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Generalization Bounds with Data-dependent Fractal Dimensions. (arXiv:2302.02766v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02766
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#22522;&#20110;&#25968;&#25454;&#20381;&#36182;&#30340;&#20998;&#24418;&#32500;&#24230;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#19981;&#38656;&#35201;Lipschitz&#20551;&#35774;&#65292;&#24182;&#33021;&#25511;&#21046;&#27867;&#21270;&#35823;&#24046;&#21644;&#20114;&#20449;&#24687;&#39033;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32479;&#35745;&#23398;&#20064;&#20013;&#65292;&#20026;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#25552;&#20379;&#27867;&#21270;&#20445;&#35777;&#26159;&#19968;&#39033;&#20851;&#38190;&#20219;&#21153;&#12290;&#26368;&#36817;&#65292;&#19968;&#20123;&#30740;&#31350;&#23581;&#35797;&#20351;&#29992;&#20998;&#24418;&#20960;&#20309;&#30340;&#24037;&#20855;&#26469;&#20998;&#26512;&#36825;&#31181;&#24773;&#20917;&#19979;&#30340;&#27867;&#21270;&#35823;&#24046;&#12290;&#23613;&#31649;&#36825;&#20123;&#24037;&#20316;&#25104;&#21151;&#22320;&#24341;&#20837;&#20102;&#26032;&#30340;&#25968;&#23398;&#24037;&#20855;&#26469;&#29702;&#35299;&#27867;&#21270;&#65292;&#20294;&#23427;&#20204;&#20005;&#37325;&#20381;&#36182;&#20110;Lipschitz&#36830;&#32493;&#24615;&#20551;&#35774;&#65292;&#32780;&#36825;&#19968;&#20551;&#35774;&#36890;&#24120;&#19981;&#36866;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#19988;&#21487;&#33021;&#20351;&#30028;&#38480;&#21464;&#24471;&#26080;&#25928;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#19981;&#38656;&#35201;&#20219;&#20309;Lipschitz&#20551;&#35774;&#30340;&#22522;&#20110;&#20998;&#24418;&#20960;&#20309;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#22312;&#23398;&#20064;&#29702;&#35770;&#20013;&#22522;&#20110;&#32463;&#20856;&#30340;&#35206;&#30422;&#35770;&#35777;&#65292;&#24182;&#24341;&#20837;&#20102;&#25968;&#25454;&#20381;&#36182;&#30340;&#20998;&#24418;&#32500;&#24230;&#12290;&#23613;&#31649;&#24341;&#20837;&#20102;&#22823;&#37327;&#30340;&#25216;&#26415;&#22797;&#26434;&#24615;&#65292;&#20294;&#36825;&#20010;&#26032;&#27010;&#24565;&#20351;&#25105;&#20204;&#33021;&#22815;&#25511;&#21046;&#27867;&#21270;&#35823;&#24046;&#65288;&#22312;&#22266;&#23450;&#25110;&#38543;&#26426;&#30340;&#20551;&#35774;&#31354;&#38388;&#19978;&#65289;&#20197;&#21450;&#29305;&#23450;&#30340;&#20114;&#20449;&#24687;&#65288;MI&#65289;&#39033;&#12290;
&lt;/p&gt;
&lt;p&gt;
Providing generalization guarantees for modern neural networks has been a crucial task in statistical learning. Recently, several studies have attempted to analyze the generalization error in such settings by using tools from fractal geometry. While these works have successfully introduced new mathematical tools to apprehend generalization, they heavily rely on a Lipschitz continuity assumption, which in general does not hold for neural networks and might make the bounds vacuous. In this work, we address this issue and prove fractal geometry-based generalization bounds without requiring any Lipschitz assumption. To achieve this goal, we build up on a classical covering argument in learning theory and introduce a data-dependent fractal dimension. Despite introducing a significant amount of technical complications, this new notion lets us control the generalization error (over either fixed or random hypothesis spaces) along with certain mutual information (MI) terms. To provide a clearer
&lt;/p&gt;</description></item><item><title /><link>http://arxiv.org/abs/2302.00160</link><description>&lt;p&gt;
&#20174;&#19968;&#20010;&#25968;&#25454;&#31354;&#38388;&#21040;&#21478;&#19968;&#20010;&#25968;&#25454;&#31354;&#38388;&#30340;&#26412;&#22320;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Local transfer learning from one data space to another. (arXiv:2302.00160v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00160
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27969;&#24418;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#26159;&#22312;&#20174;&#25903;&#25345;&#22312;&#39640;&#32500;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#30340;&#20302;&#32500;&#23376;&#27969;&#24418;&#19978;&#38543;&#26426;&#36873;&#25321;&#30340;&#25968;&#25454;&#19978;&#36817;&#20284;&#19968;&#20010;&#20989;&#25968;&#20851;&#31995;&#12290;&#27969;&#24418;&#26412;&#36136;&#19978;&#30001;&#25968;&#25454;&#38598;&#26412;&#36523;&#23450;&#20041;&#65292;&#24182;&#19988;&#36890;&#24120;&#35774;&#35745;&#20026;&#25968;&#25454;&#22312;&#26576;&#31181;&#24847;&#20041;&#19978;&#22312;&#27969;&#24418;&#19978;&#31264;&#23494;&#12290;&#25968;&#25454;&#31354;&#38388;&#30340;&#27010;&#24565;&#26159;&#19968;&#20010;&#25277;&#35937;&#30340;&#27969;&#24418;&#65292;&#23553;&#35013;&#20102;&#20801;&#35768;&#36827;&#34892;&#20989;&#25968;&#36924;&#36817;&#30340;&#22522;&#26412;&#23646;&#24615;&#12290;&#36801;&#31227;&#23398;&#20064;&#65288;&#20803;&#23398;&#20064;&#65289;&#38382;&#39064;&#26159;&#21033;&#29992;&#22312;&#19968;&#20010;&#25968;&#25454;&#38598;&#19978;&#23398;&#20064;&#19968;&#20010;&#20989;&#25968;&#26469;&#23398;&#20064;&#22312;&#21478;&#19968;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#31867;&#20284;&#20989;&#25968;&#12290;&#22312;&#20989;&#25968;&#36924;&#36817;&#26041;&#38754;&#65292;&#36825;&#24847;&#21619;&#30528;&#23558;&#19968;&#20010;&#25968;&#25454;&#31354;&#38388;&#19978;&#30340;&#20989;&#25968;&#65288;&#22522;&#26412;&#25968;&#25454;&#31354;&#38388;&#65289;&#25552;&#21319;&#21040;&#21478;&#19968;&#20010;&#25968;&#25454;&#31354;&#38388;&#65288;&#30446;&#26631;&#25968;&#25454;&#31354;&#38388;&#65289;&#12290;&#36825;&#20010;&#35266;&#28857;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;&#24212;&#29992;&#25968;&#23398;&#20013;&#30340;&#19968;&#20123;&#36870;&#38382;&#39064;&#65288;&#22914;&#36870;Radon&#21464;&#25442;&#65289;&#19982;&#36801;&#31227;&#23398;&#20064;&#32852;&#31995;&#36215;&#26469;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#36825;&#31181;&#25552;&#21319;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
A fundamental problem in manifold learning is to approximate a functional relationship in a data chosen randomly from a probability distribution supported on a low dimensional sub-manifold of a high dimensional ambient Euclidean space. The manifold is essentially defined by the data set itself and, typically, designed so that the data is dense on the manifold in some sense. The notion of a data space is an abstraction of a manifold encapsulating the essential properties that allow for function approximation. The problem of transfer learning (meta-learning) is to use the learning of a function on one data set to learn a similar function on a new data set. In terms of function approximation, this means lifting a function on one data space (the base data space) to another (the target data space). This viewpoint enables us to connect some inverse problems in applied mathematics (such as inverse Radon transform) with transfer learning. In this paper we examine the question of such lifting w
&lt;/p&gt;</description></item><item><title>D-Adaptation&#26159;&#19968;&#31181;&#21487;&#20197;&#33258;&#21160;&#35774;&#32622;&#23398;&#20064;&#29575;&#30340;&#26041;&#27861;&#65292;&#38024;&#23545;&#26368;&#23567;&#21270;&#20984;&#24615;Lipschitz&#20989;&#25968;&#65292;&#29992;&#20110;&#23454;&#29616;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#65292;&#32780;&#26080;&#38656;&#36229;&#21442;&#25968;&#65292;&#20063;&#26080;&#38656;&#39069;&#22806;&#23545;&#25968;&#22240;&#23376;&#25913;&#36827;&#65292;&#33021;&#22815;&#22312;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#33258;&#21160;&#21305;&#37197;&#25163;&#21160;&#35843;&#25972;&#30340;&#23398;&#20064;&#29575;&#12290;</title><link>http://arxiv.org/abs/2301.07733</link><description>&lt;p&gt;
&#36890;&#36807;D&#36866;&#24212;&#23454;&#29616;&#23398;&#20064;&#29575;&#33258;&#30001;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Learning-Rate-Free Learning by D-Adaptation. (arXiv:2301.07733v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.07733
&lt;/p&gt;
&lt;p&gt;
D-Adaptation&#26159;&#19968;&#31181;&#21487;&#20197;&#33258;&#21160;&#35774;&#32622;&#23398;&#20064;&#29575;&#30340;&#26041;&#27861;&#65292;&#38024;&#23545;&#26368;&#23567;&#21270;&#20984;&#24615;Lipschitz&#20989;&#25968;&#65292;&#29992;&#20110;&#23454;&#29616;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#65292;&#32780;&#26080;&#38656;&#36229;&#21442;&#25968;&#65292;&#20063;&#26080;&#38656;&#39069;&#22806;&#23545;&#25968;&#22240;&#23376;&#25913;&#36827;&#65292;&#33021;&#22815;&#22312;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#33258;&#21160;&#21305;&#37197;&#25163;&#21160;&#35843;&#25972;&#30340;&#23398;&#20064;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
D&#36866;&#24212;&#26159;&#19968;&#31181;&#33258;&#21160;&#35774;&#32622;&#23398;&#20064;&#29575;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#28176;&#36817;&#22320;&#23454;&#29616;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#65292;&#29992;&#20110;&#26368;&#23567;&#21270;&#20984;&#24615;Lipschitz&#20989;&#25968;&#65292;&#26080;&#38656;&#22238;&#28335;&#25110;&#32447;&#24615;&#25628;&#32034;&#65292;&#24182;&#19988;&#27599;&#27493;&#26080;&#38656;&#36827;&#34892;&#39069;&#22806;&#30340;&#20989;&#25968;&#20540;&#25110;&#26799;&#24230;&#35780;&#20272;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#36825;&#19968;&#31867;&#38382;&#39064;&#30340;&#31532;&#19968;&#20010;&#26080;&#36229;&#21442;&#25968;&#19988;&#25910;&#25947;&#36895;&#29575;&#26080;&#38656;&#39069;&#22806;&#23545;&#25968;&#22240;&#23376;&#25913;&#36827;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#38024;&#23545;SGD&#21644;Adam&#21464;&#20307;&#23637;&#31034;&#20102;&#24191;&#27867;&#30340;&#23454;&#39564;&#65292;&#20854;&#20013;&#35813;&#26041;&#27861;&#33258;&#21160;&#21305;&#37197;&#25163;&#21160;&#35843;&#25972;&#30340;&#23398;&#20064;&#29575;&#65292;&#22312;&#21313;&#22810;&#20010;&#19981;&#21516;&#30340;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#24212;&#29992;&#65292;&#21253;&#25324;&#22823;&#35268;&#27169;&#30340;&#35270;&#35273;&#21644;&#35821;&#35328;&#38382;&#39064;&#12290;&#24320;&#28304;&#23454;&#29616;&#22312; \url{https://github.com/facebookresearch/dadaptation}.
&lt;/p&gt;
&lt;p&gt;
D-Adaptation is an approach to automatically setting the learning rate which asymptotically achieves the optimal rate of convergence for minimizing convex Lipschitz functions, with no back-tracking or line searches, and no additional function value or gradient evaluations per step. Our approach is the first hyper-parameter free method for this class without additional multiplicative log factors in the convergence rate. We present extensive experiments for SGD and Adam variants of our method, where the method automatically matches hand-tuned learning rates across more than a dozen diverse machine learning problems, including large-scale vision and language problems.  An open-source implementation is available at \url{https://github.com/facebookresearch/dadaptation}.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#40723;&#21169;&#30446;&#26631;&#22495;&#20013;&#30340;&#39044;&#27979;&#19982;&#20854;&#21069;&#20960;&#20010;&#22855;&#24322;&#21521;&#37327;&#23545;&#40784;&#26469;&#23454;&#29616;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#36825;&#20010;&#26041;&#27861;&#36890;&#36807;&#27491;&#21017;&#21270;&#20998;&#31867;&#22120;&#19982;&#26080;&#30417;&#30563;&#30446;&#26631;&#25968;&#25454;&#23545;&#40784;&#65292;&#32780;&#19981;&#26159;&#27491;&#21017;&#21270;&#34920;&#31034;&#12290;&#36890;&#36807;&#28040;&#38500;&#23545;&#26368;&#20248;&#32852;&#21512;&#39118;&#38505;&#20551;&#35774;&#30340;&#20381;&#36182;&#65292;&#35813;&#26041;&#27861;&#23637;&#31034;&#20102;&#24456;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2211.14960</link><description>&lt;p&gt;
&#20998;&#24067;&#20559;&#31227;&#30340;&#26631;&#31614;&#23545;&#40784;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Label Alignment Regularization for Distribution Shift. (arXiv:2211.14960v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.14960
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#40723;&#21169;&#30446;&#26631;&#22495;&#20013;&#30340;&#39044;&#27979;&#19982;&#20854;&#21069;&#20960;&#20010;&#22855;&#24322;&#21521;&#37327;&#23545;&#40784;&#26469;&#23454;&#29616;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#36825;&#20010;&#26041;&#27861;&#36890;&#36807;&#27491;&#21017;&#21270;&#20998;&#31867;&#22120;&#19982;&#26080;&#30417;&#30563;&#30446;&#26631;&#25968;&#25454;&#23545;&#40784;&#65292;&#32780;&#19981;&#26159;&#27491;&#21017;&#21270;&#34920;&#31034;&#12290;&#36890;&#36807;&#28040;&#38500;&#23545;&#26368;&#20248;&#32852;&#21512;&#39118;&#38505;&#20551;&#35774;&#30340;&#20381;&#36182;&#65292;&#35813;&#26041;&#27861;&#23637;&#31034;&#20102;&#24456;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#24378;&#35843;&#20102;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#26631;&#31614;&#23545;&#40784;&#23646;&#24615;&#65288;LAP&#65289;&#65292;&#21363;&#25968;&#25454;&#38598;&#20013;&#25152;&#26377;&#26631;&#31614;&#30340;&#21521;&#37327;&#22823;&#37096;&#20998;&#22312;&#25968;&#25454;&#30697;&#38453;&#30340;&#21069;&#20960;&#20010;&#22855;&#24322;&#21521;&#37327;&#30340;&#24352;&#25104;&#31354;&#38388;&#20869;&#12290;&#21463;&#21040;&#36825;&#19968;&#35266;&#23519;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#40723;&#21169;&#30446;&#26631;&#22495;&#20013;&#30340;&#39044;&#27979;&#19982;&#20854;&#21069;&#20960;&#20010;&#22855;&#24322;&#21521;&#37327;&#23545;&#40784;&#12290;&#19982;&#20256;&#32479;&#30340;&#39046;&#22495;&#36866;&#24212;&#26041;&#27861;&#19987;&#27880;&#20110;&#27491;&#21017;&#21270;&#34920;&#31034;&#19981;&#21516;&#65292;&#25105;&#20204;&#30456;&#21453;&#65292;&#36890;&#36807;&#22312;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#20013;&#20351;&#29992;LAP&#65292;&#29992;&#27491;&#21017;&#21270;&#20998;&#31867;&#22120;&#19982;&#26080;&#30417;&#30563;&#30446;&#26631;&#25968;&#25454;&#23545;&#40784;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#22312;&#19968;&#23450;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#30340;&#35299;&#20915;&#26041;&#26696;&#20301;&#20110;&#30446;&#26631;&#22495;&#25968;&#25454;&#30340;&#21069;&#20960;&#20010;&#21491;&#22855;&#24322;&#21521;&#37327;&#30340;&#24352;&#25104;&#31354;&#38388;&#20869;&#65292;&#24182;&#19982;&#26368;&#20248;&#35299;&#23545;&#40784;&#12290;&#36890;&#36807;&#28040;&#38500;&#32463;&#20856;&#39046;&#22495;&#36866;&#24212;&#29702;&#35770;&#20013;&#24120;&#35265;&#30340;&#26368;&#20248;&#32852;&#21512;&#39118;&#38505;&#20551;&#35774;&#30340;&#20381;&#36182;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work has highlighted the label alignment property (LAP) in supervised learning, where the vector of all labels in the dataset is mostly in the span of the top few singular vectors of the data matrix. Drawing inspiration from this observation, we propose a regularization method for unsupervised domain adaptation that encourages alignment between the predictions in the target domain and its top singular vectors. Unlike conventional domain adaptation approaches that focus on regularizing representations, we instead regularize the classifier to align with the unsupervised target data, guided by the LAP in both the source and target domains. Theoretical analysis demonstrates that, under certain assumptions, our solution resides within the span of the top right singular vectors of the target domain data and aligns with the optimal solution. By removing the reliance on the commonly used optimal joint risk assumption found in classic domain adaptation theory, we showcase the effectivene
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36136;&#30097;&#20102;&#36882;&#24402;&#21010;&#20998;&#22312;&#20915;&#31574;&#26641;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#36890;&#36807;&#35777;&#26126;&#23427;&#20204;&#21487;&#33021;&#26080;&#27861;&#23454;&#29616;&#19968;&#33268;&#33539;&#25968;&#30340;&#22810;&#39033;&#24335;&#25910;&#25947;&#36895;&#29575;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#38543;&#26426;&#26862;&#26519;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#23558;&#20302;&#24615;&#33021;&#30340;&#26641;&#36716;&#21270;&#20026;&#20960;&#20046;&#26368;&#20248;&#30340;&#36807;&#31243;&#65292;&#20294;&#20195;&#20215;&#26159;&#22833;&#21435;&#20102;&#35299;&#37322;&#24615;&#65292;&#24182;&#24341;&#20837;&#20102;&#20004;&#20010;&#39069;&#22806;&#30340;&#35843;&#25972;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/2211.10805</link><description>&lt;p&gt;
&#20851;&#20110;&#36882;&#24402;&#21010;&#20998;&#30340;&#36880;&#28857;&#34892;&#20026;&#21450;&#20854;&#23545;&#24322;&#36136;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
On the Pointwise Behavior of Recursive Partitioning and Its Implications for Heterogeneous Causal Effect Estimation. (arXiv:2211.10805v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.10805
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36136;&#30097;&#20102;&#36882;&#24402;&#21010;&#20998;&#22312;&#20915;&#31574;&#26641;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#36890;&#36807;&#35777;&#26126;&#23427;&#20204;&#21487;&#33021;&#26080;&#27861;&#23454;&#29616;&#19968;&#33268;&#33539;&#25968;&#30340;&#22810;&#39033;&#24335;&#25910;&#25947;&#36895;&#29575;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#38543;&#26426;&#26862;&#26519;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#23558;&#20302;&#24615;&#33021;&#30340;&#26641;&#36716;&#21270;&#20026;&#20960;&#20046;&#26368;&#20248;&#30340;&#36807;&#31243;&#65292;&#20294;&#20195;&#20215;&#26159;&#22833;&#21435;&#20102;&#35299;&#37322;&#24615;&#65292;&#24182;&#24341;&#20837;&#20102;&#20004;&#20010;&#39069;&#22806;&#30340;&#35843;&#25972;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20915;&#31574;&#26641;&#23398;&#20064;&#22312;&#36880;&#28857;&#25512;&#26029;&#20013;&#30340;&#24212;&#29992;&#26085;&#30410;&#22686;&#22810;&#12290;&#37325;&#35201;&#30340;&#24212;&#29992;&#21253;&#25324;&#24322;&#36136;&#22240;&#26524;&#27835;&#30103;&#25928;&#24212;&#21644;&#21160;&#24577;&#25919;&#31574;&#20915;&#31574;&#65292;&#20197;&#21450;&#26465;&#20214;&#20998;&#20301;&#25968;&#22238;&#24402;&#21644;&#23454;&#39564;&#35774;&#35745;&#65292;&#22312;&#36825;&#20123;&#24212;&#29992;&#20013;&#65292;&#26641;&#30340;&#20272;&#35745;&#21644;&#25512;&#26029;&#26159;&#22312;&#29305;&#23450;&#30340;&#21327;&#21464;&#37327;&#20540;&#19978;&#36827;&#34892;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23545;&#20351;&#29992;&#20915;&#31574;&#26641;&#65288;&#36890;&#36807;&#33258;&#36866;&#24212;&#36882;&#24402;&#21010;&#20998;&#35757;&#32451;&#65289;&#36827;&#34892;&#27492;&#31867;&#30446;&#30340;&#25552;&#20986;&#20102;&#36136;&#30097;&#65292;&#36890;&#36807;&#35777;&#26126;&#23427;&#20204;&#29978;&#33267;&#21487;&#20197;&#22312;&#20462;&#21098;&#30340;&#24773;&#20917;&#19979;&#26080;&#27861;&#23454;&#29616;&#19968;&#33268;&#33539;&#25968;&#30340;&#22810;&#39033;&#24335;&#25910;&#25947;&#36895;&#29575;&#12290;&#30456;&#21453;&#65292;&#25910;&#25947;&#36895;&#24230;&#21487;&#33021;&#26159;&#22810;&#39033;&#24335;&#23545;&#25968;&#32423;&#21035;&#30340;&#65292;&#25110;&#32773;&#22312;&#19968;&#20123;&#37325;&#35201;&#30340;&#29305;&#27530;&#24773;&#20917;&#19979;&#65292;&#20363;&#22914;&#35802;&#23454;&#22238;&#24402;&#26641;&#65292;&#23436;&#20840;&#22833;&#36133;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#38543;&#26426;&#26862;&#26519;&#21487;&#20197;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#23558;&#20302;&#24615;&#33021;&#30340;&#26641;&#36716;&#21270;&#20026;&#20960;&#20046;&#26368;&#20248;&#30340;&#36807;&#31243;&#65292;&#20294;&#20195;&#20215;&#26159;&#22833;&#21435;&#20102;&#35299;&#37322;&#24615;&#65292;&#24182;&#24341;&#20837;&#20102;&#20004;&#20010;&#39069;&#22806;&#30340;&#35843;&#25972;&#21442;&#25968;&#12290;&#38543;&#26426;&#26862;&#26519;&#30340;&#20004;&#20010;&#26631;&#24535;&#24615;&#29305;&#24449;&#26159;&#23376;&#37319;&#26679;&#21644;&#38543;&#26426;&#29305;&#24449;&#36873;&#25321;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Decision tree learning is increasingly being used for pointwise inference. Important applications include causal heterogenous treatment effects and dynamic policy decisions, as well as conditional quantile regression and design of experiments, where tree estimation and inference is conducted at specific values of the covariates. In this paper, we call into question the use of decision trees (trained by adaptive recursive partitioning) for such purposes by demonstrating that they can fail to achieve polynomial rates of convergence in uniform norm, even with pruning. Instead, the convergence may be poly-logarithmic or, in some important special cases, such as honest regression trees, fail completely. We show that random forests can remedy the situation, turning poor performing trees into nearly optimal procedures, at the cost of losing interpretability and introducing two additional tuning parameters. The two hallmarks of random forests, subsampling and the random feature selection mecha
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#20559;&#22909;&#23376;&#37319;&#26679;&#30340;&#26041;&#27861;&#26469;&#23545;&#38543;&#26426;&#26799;&#24230;Langevin&#21160;&#21147;&#23398;&#36827;&#34892;&#20248;&#21270;&#65292;&#36890;&#36807;&#20351;&#29992;&#38750;&#22343;&#21248;&#27010;&#29575;&#20998;&#24067;&#23376;&#37319;&#26679;&#23545;&#20855;&#26377;&#26356;&#22823;&#24433;&#21709;&#30340;&#25968;&#25454;&#28857;&#36827;&#34892;&#21152;&#26435;&#65292;&#21516;&#26102;&#36824;&#36890;&#36807;&#33258;&#36866;&#24212;&#35843;&#25972;&#23376;&#37319;&#26679;&#22823;&#23567;&#26469;&#25552;&#39640;&#26799;&#24230;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#12290;&#23454;&#39564;&#35777;&#26126;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#22312;&#20943;&#23569;&#23376;&#37319;&#26679;&#25968;&#30340;&#21516;&#26102;&#20445;&#25345;&#30456;&#21516;&#30340;&#31934;&#24230;&#27700;&#24179;&#12290;</title><link>http://arxiv.org/abs/2210.16189</link><description>&lt;p&gt;
&#20559;&#22909;&#23376;&#37319;&#26679;&#23545;&#20110;&#38543;&#26426;&#26799;&#24230;Langevin&#21160;&#21147;&#23398;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Preferential Subsampling for Stochastic Gradient Langevin Dynamics. (arXiv:2210.16189v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.16189
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#20559;&#22909;&#23376;&#37319;&#26679;&#30340;&#26041;&#27861;&#26469;&#23545;&#38543;&#26426;&#26799;&#24230;Langevin&#21160;&#21147;&#23398;&#36827;&#34892;&#20248;&#21270;&#65292;&#36890;&#36807;&#20351;&#29992;&#38750;&#22343;&#21248;&#27010;&#29575;&#20998;&#24067;&#23376;&#37319;&#26679;&#23545;&#20855;&#26377;&#26356;&#22823;&#24433;&#21709;&#30340;&#25968;&#25454;&#28857;&#36827;&#34892;&#21152;&#26435;&#65292;&#21516;&#26102;&#36824;&#36890;&#36807;&#33258;&#36866;&#24212;&#35843;&#25972;&#23376;&#37319;&#26679;&#22823;&#23567;&#26469;&#25552;&#39640;&#26799;&#24230;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#12290;&#23454;&#39564;&#35777;&#26126;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#22312;&#20943;&#23569;&#23376;&#37319;&#26679;&#25968;&#30340;&#21516;&#26102;&#20445;&#25345;&#30456;&#21516;&#30340;&#31934;&#24230;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;MCMC&#65288;SGMCMC&#65289;&#36890;&#36807;&#20351;&#29992;&#23567;&#22411;&#12289;&#22343;&#21248;&#21152;&#26435;&#30340;&#25968;&#25454;&#23376;&#26679;&#26412;&#26500;&#24314;&#23545;&#20110;&#23545;&#25968;&#21518;&#39564;&#26799;&#24230;&#30340;&#26080;&#20559;&#20272;&#35745;&#65292;&#20026;&#20256;&#32479;MCMC&#25552;&#20379;&#20102;&#21487;&#25193;&#23637;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;&#34429;&#28982;&#35745;&#31639;&#39640;&#25928;&#65292;&#20294;&#30001;&#27492;&#20135;&#29983;&#30340;&#26799;&#24230;&#20272;&#35745;&#21487;&#33021;&#20855;&#26377;&#36739;&#39640;&#30340;&#26041;&#24046;&#65292;&#24182;&#19988;&#20250;&#24433;&#21709;&#37319;&#26679;&#22120;&#24615;&#33021;&#12290;&#20256;&#32479;&#19978;&#65292;&#26041;&#24046;&#25511;&#21046;&#38382;&#39064;&#36890;&#36807;&#26500;&#24314;&#26356;&#22909;&#30340;&#38543;&#26426;&#26799;&#24230;&#20272;&#35745;&#22120;&#26469;&#35299;&#20915;&#65292;&#36890;&#24120;&#20351;&#29992;&#25511;&#21046;&#21464;&#37327;&#12290;&#25105;&#20204;&#25552;&#35758;&#20351;&#29992;&#31163;&#25955;&#30340;&#38750;&#22343;&#21248;&#27010;&#29575;&#20998;&#24067;&#26469;&#20559;&#22909;&#22320;&#23376;&#37319;&#26679;&#23545;&#20110;&#23545;&#26799;&#24230;&#20135;&#29983;&#26356;&#22823;&#24433;&#21709;&#30340;&#25968;&#25454;&#28857;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#22312;&#31639;&#27861;&#30340;&#27599;&#27425;&#36845;&#20195;&#20013;&#33258;&#36866;&#24212;&#22320;&#35843;&#25972;&#23376;&#37319;&#26679;&#22823;&#23567;&#30340;&#26041;&#27861;&#65292;&#20197;&#20415;&#22312;&#38590;&#20197;&#20272;&#35745;&#26799;&#24230;&#30340;&#26679;&#26412;&#31354;&#38388;&#20013;&#22686;&#21152;&#23376;&#37319;&#26679;&#22823;&#23567;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#22312;&#22823;&#24133;&#20943;&#23569;&#24179;&#22343;&#23376;&#37319;&#26679;&#25968;&#30340;&#21516;&#26102;&#20445;&#25345;&#30456;&#21516;&#30340;&#31934;&#24230;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic gradient MCMC (SGMCMC) offers a scalable alternative to traditional MCMC, by constructing an unbiased estimate of the gradient of the log-posterior with a small, uniformly-weighted subsample of the data. While efficient to compute, the resulting gradient estimator may exhibit a high variance and impact sampler performance. The problem of variance control has been traditionally addressed by constructing a better stochastic gradient estimator, often using control variates. We propose to use a discrete, non-uniform probability distribution to preferentially subsample data points that have a greater impact on the stochastic gradient. In addition, we present a method of adaptively adjusting the subsample size at each iteration of the algorithm, so that we increase the subsample size in areas of the sample space where the gradient is harder to estimate. We demonstrate that such an approach can maintain the same level of accuracy while substantially reducing the average subsample s
&lt;/p&gt;</description></item><item><title>&#35774;&#35745;&#20986;&#20102;&#31532;&#19968;&#20010;&#20855;&#26377;&#22312;&#32447;&#36951;&#25022;&#20445;&#35777;&#30340;&#39118;&#38505;&#21388;&#24694;&#30340;&#19978;&#19979;&#25991;&#36172;&#21338;&#31639;&#27861;&#65292;&#24182;&#22312;&#22810;&#20010;&#23454;&#39564;&#22330;&#26223;&#20013;&#23637;&#31034;&#20102;&#20854;&#36866;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2210.13573</link><description>&lt;p&gt;
&#26377;&#26465;&#20214;&#39118;&#38505;&#21388;&#24694;&#30340;&#19978;&#19979;&#25991;&#36172;&#21338;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Conditionally Risk-Averse Contextual Bandits. (arXiv:2210.13573v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.13573
&lt;/p&gt;
&lt;p&gt;
&#35774;&#35745;&#20986;&#20102;&#31532;&#19968;&#20010;&#20855;&#26377;&#22312;&#32447;&#36951;&#25022;&#20445;&#35777;&#30340;&#39118;&#38505;&#21388;&#24694;&#30340;&#19978;&#19979;&#25991;&#36172;&#21338;&#31639;&#27861;&#65292;&#24182;&#22312;&#22810;&#20010;&#23454;&#39564;&#22330;&#26223;&#20013;&#23637;&#31034;&#20102;&#20854;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39118;&#38505;&#21388;&#24694;&#30340;&#24773;&#20917;&#19979;&#65292;&#20855;&#26377;&#24179;&#22343;&#32479;&#35745;&#20445;&#35777;&#30340;&#19978;&#19979;&#25991;&#36172;&#21338;&#38382;&#39064;&#26159;&#19981;&#36275;&#22815;&#30340;&#65292;&#22240;&#20026;&#23427;&#20204;&#21487;&#33021;&#36890;&#36807;&#29306;&#29298;&#26368;&#22351;&#24773;&#20917;&#30340;&#34920;&#29616;&#26469;&#33719;&#24471;&#26356;&#22909;&#30340;&#24179;&#22343;&#24615;&#33021;&#12290;&#35774;&#35745;&#19968;&#20010;&#39118;&#38505;&#21388;&#24694;&#30340;&#19978;&#19979;&#25991;&#36172;&#21338;&#31639;&#27861;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#25506;&#32034;&#26159;&#24517;&#35201;&#30340;&#65292;&#20294;&#39118;&#38505;&#21388;&#24694;&#23545;&#25972;&#20010;&#22870;&#21169;&#20998;&#24067;&#37117;&#24456;&#25935;&#24863;&#65307;&#23613;&#31649;&#22914;&#27492;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#31532;&#19968;&#20010;&#20855;&#26377;&#22312;&#32447;&#36951;&#25022;&#20445;&#35777;&#30340;&#39118;&#38505;&#21388;&#24694;&#30340;&#19978;&#19979;&#25991;&#36172;&#21338;&#31639;&#27861;&#12290;&#25105;&#20204;&#22312;&#22810;&#31181;&#22330;&#26223;&#19979;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#36825;&#20123;&#22330;&#26223;&#20013;&#26368;&#22351;&#24773;&#20917;&#30340;&#32467;&#26524;&#24212;&#35813;&#34987;&#36991;&#20813;&#65292;&#21253;&#25324;&#21160;&#24577;&#23450;&#20215;&#12289;&#24211;&#23384;&#31649;&#29702;&#21644;&#33258;&#25105;&#35843;&#25972;&#36719;&#20214;&#65307;&#20854;&#20013;&#36824;&#21253;&#25324;&#19968;&#20010;&#29983;&#20135;&#32423;&#30340;&#25193;&#23637;&#25968;&#25454;&#22788;&#29702;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
Contextual bandits with average-case statistical guarantees are inadequate in risk-averse situations because they might trade off degraded worst-case behaviour for better average performance. Designing a risk-averse contextual bandit is challenging because exploration is necessary but risk-aversion is sensitive to the entire distribution of rewards; nonetheless we exhibit the first risk-averse contextual bandit algorithm with an online regret guarantee. We conduct experiments from diverse scenarios where worst-case outcomes should be avoided, from dynamic pricing, inventory management, and self-tuning software; including a production exascale data processing system.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36807;&#24230;&#21442;&#25968;&#21270;&#23398;&#20064;&#20013;Bagging&#39044;&#27979;&#22120;&#30340;&#39118;&#38505;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#36890;&#29992;&#31574;&#30053;&#26469;&#20998;&#26512;Bagging&#39044;&#27979;&#22120;&#30340;&#39118;&#38505;&#12290;&#36890;&#36807;&#20855;&#20307;&#21270;&#31574;&#30053;&#65292;&#25105;&#20204;&#24471;&#20986;&#20102;Bagging Ridge&#21644;Ridgeless&#39044;&#27979;&#22120;&#30340;&#31934;&#30830;&#28176;&#36817;&#39118;&#38505;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#20132;&#21449;&#39564;&#35777;&#36807;&#31243;&#26469;&#36873;&#25321;Bagging&#30340;&#26368;&#20339;&#23376;&#26679;&#26412;&#22823;&#23567;&#65292;&#20197;&#28040;&#38500;&#39118;&#38505;&#30340;&#38750;&#21333;&#35843;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2210.11445</link><description>&lt;p&gt;
Bagging&#22312;&#36807;&#24230;&#21442;&#25968;&#21270;&#23398;&#20064;&#20013;&#30340;&#39118;&#38505;&#21051;&#30011;&#21644;&#39118;&#38505;&#21333;&#35843;&#21270;
&lt;/p&gt;
&lt;p&gt;
Bagging in overparameterized learning: Risk characterization and risk monotonization. (arXiv:2210.11445v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.11445
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36807;&#24230;&#21442;&#25968;&#21270;&#23398;&#20064;&#20013;Bagging&#39044;&#27979;&#22120;&#30340;&#39118;&#38505;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#36890;&#29992;&#31574;&#30053;&#26469;&#20998;&#26512;Bagging&#39044;&#27979;&#22120;&#30340;&#39118;&#38505;&#12290;&#36890;&#36807;&#20855;&#20307;&#21270;&#31574;&#30053;&#65292;&#25105;&#20204;&#24471;&#20986;&#20102;Bagging Ridge&#21644;Ridgeless&#39044;&#27979;&#22120;&#30340;&#31934;&#30830;&#28176;&#36817;&#39118;&#38505;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#20132;&#21449;&#39564;&#35777;&#36807;&#31243;&#26469;&#36873;&#25321;Bagging&#30340;&#26368;&#20339;&#23376;&#26679;&#26412;&#22823;&#23567;&#65292;&#20197;&#28040;&#38500;&#39118;&#38505;&#30340;&#38750;&#21333;&#35843;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Bagging&#26159;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#24120;&#29992;&#30340;&#38598;&#25104;&#25216;&#26415;&#65292;&#29992;&#20110;&#25552;&#39640;&#39044;&#27979;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#27604;&#20363;&#28176;&#36817;&#24773;&#20917;&#19979;&#65292;&#21508;&#31181;&#21464;&#20307;&#30340;Bagging&#39044;&#27979;&#22120;&#30340;&#39044;&#27979;&#39118;&#38505;&#65292;&#20854;&#20013;&#29305;&#24449;&#25968;&#19982;&#35266;&#27979;&#25968;&#30340;&#27604;&#20540;&#25910;&#25947;&#21040;&#24120;&#25968;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#26512;Bagging&#39044;&#27979;&#22120;&#22312;&#24179;&#26041;&#35823;&#24046;&#25439;&#22833;&#19979;&#30340;&#39044;&#27979;&#39118;&#38505;&#30340;&#36890;&#29992;&#31574;&#30053;&#65292;&#21033;&#29992;&#31616;&#21333;&#38543;&#26426;&#25277;&#26679;&#30340;&#32463;&#20856;&#32467;&#26524;&#12290;&#36890;&#36807;&#29305;&#27530;&#21270;&#35813;&#31574;&#30053;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#20855;&#26377;&#20219;&#24847;&#25968;&#37327;&#30340;&#21253;&#30340;Bagging Ridge&#21644;Ridgeless&#39044;&#27979;&#22120;&#22312;&#20855;&#26377;&#20219;&#24847;&#29305;&#24449;&#21327;&#26041;&#24046;&#30697;&#38453;&#21644;&#20449;&#21495;&#21521;&#37327;&#30340;&#33391;&#22909;&#25351;&#23450;&#32447;&#24615;&#27169;&#22411;&#19979;&#30340;&#31934;&#30830;&#28176;&#36817;&#39118;&#38505;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#20132;&#21449;&#39564;&#35777;&#36807;&#31243;&#65292;&#29992;&#20110;&#36873;&#25321;Bagging&#30340;&#26368;&#20339;&#23376;&#26679;&#26412;&#22823;&#23567;&#65292;&#24182;&#35752;&#35770;&#20854;&#22312;&#28040;&#38500;&#26679;&#26412;&#22823;&#23567;&#30340;&#39118;&#38505;&#30340;&#38750;&#21333;&#35843;&#34892;&#20026;&#26041;&#38754;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bagging is a commonly used ensemble technique in statistics and machine learning to improve the performance of prediction procedures. In this paper, we study the prediction risk of variants of bagged predictors under the proportional asymptotics regime, in which the ratio of the number of features to the number of observations converges to a constant. Specifically, we propose a general strategy to analyze the prediction risk under squared error loss of bagged predictors using classical results on simple random sampling. Specializing the strategy, we derive the exact asymptotic risk of the bagged ridge and ridgeless predictors with an arbitrary number of bags under a well-specified linear model with arbitrary feature covariance matrices and signal vectors. Furthermore, we prescribe a generic cross-validation procedure to select the optimal subsample size for bagging and discuss its utility to eliminate the non-monotonic behavior of the limiting risk in the sample size (i.e., double or m
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26465;&#20214;&#35780;&#20998;&#24314;&#27169;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22788;&#29702;&#22522;&#20110;&#22810;&#20010;&#35266;&#27979;&#26465;&#20214;&#19979;&#24471;&#21040;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#21516;&#26102;&#20855;&#26377;&#39640;&#26679;&#26412;&#25928;&#29575;&#21644;&#32858;&#21512;&#22810;&#20010;&#35266;&#27979;&#20540;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2209.14249</link><description>&lt;p&gt;
&#22522;&#20110;&#32452;&#21512;&#35780;&#20998;&#24314;&#27169;&#30340;&#22522;&#20110;&#27169;&#25311;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Compositional Score Modeling for Simulation-based Inference. (arXiv:2209.14249v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.14249
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26465;&#20214;&#35780;&#20998;&#24314;&#27169;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22788;&#29702;&#22522;&#20110;&#22810;&#20010;&#35266;&#27979;&#26465;&#20214;&#19979;&#24471;&#21040;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#21516;&#26102;&#20855;&#26377;&#39640;&#26679;&#26412;&#25928;&#29575;&#21644;&#32858;&#21512;&#22810;&#20010;&#35266;&#27979;&#20540;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#25311;&#25512;&#26029;&#30340;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#26041;&#27861;&#22312;&#22788;&#29702;&#22522;&#20110;&#22810;&#20010;&#35266;&#27979;&#26465;&#20214;&#19979;&#24471;&#21040;&#30340;&#21518;&#39564;&#20998;&#24067;&#26102;&#21487;&#33021;&#19981;&#22826;&#36866;&#29992;&#65292;&#22240;&#20026;&#23427;&#20204;&#20542;&#21521;&#20110;&#38656;&#35201;&#22823;&#37327;&#30340;&#27169;&#25311;&#22120;&#35843;&#29992;&#26469;&#23398;&#20064;&#20934;&#30830;&#30340;&#36817;&#20284;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#31070;&#32463;&#20284;&#28982;&#20272;&#35745;&#26041;&#27861;&#21487;&#20197;&#22312;&#23398;&#20064;&#20102;&#21333;&#29420;&#35266;&#27979;&#20540;&#21518;&#65292;&#22788;&#29702;&#25512;&#26029;&#26102;&#30340;&#22810;&#20010;&#35266;&#27979;&#20540;&#65292;&#20294;&#23427;&#20204;&#20381;&#36182;&#20110;&#26631;&#20934;&#30340;&#25512;&#26029;&#26041;&#27861;&#65292;&#22914;MCMC&#25110;&#21464;&#20998;&#25512;&#26029;&#65292;&#36825;&#20123;&#25512;&#26029;&#26041;&#27861;&#26377;&#19968;&#23450;&#30340;&#24615;&#33021;&#32570;&#38519;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#26465;&#20214;&#35780;&#20998;&#24314;&#27169;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#34701;&#21512;&#20102;&#20004;&#31181;&#26041;&#27861;&#30340;&#20248;&#28857;&#12290;&#25105;&#20204;&#23545;&#30001;&#21333;&#20010;&#35266;&#27979;&#24341;&#36215;&#30340;&#65288;&#25193;&#25955;&#30340;&#65289;&#21518;&#39564;&#20998;&#24067;&#24314;&#27169;&#65292;&#28982;&#21518;&#24341;&#20837;&#20102;&#19968;&#31181;&#32452;&#21512;&#23398;&#20064;&#20998;&#25968;&#20197;&#36817;&#20284;&#20174;&#30446;&#26631;&#21518;&#39564;&#20998;&#24067;&#20013;&#37319;&#26679;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26679;&#26412;&#25928;&#29575;&#19978;&#20855;&#26377;&#20248;&#21183;&#65292;&#22312;&#25512;&#26029;&#26102;&#21487;&#20197;&#33258;&#28982;&#22320;&#32858;&#21512;&#22810;&#20010;&#35266;&#27979;&#20540;&#65292;&#24182;&#36991;&#20813;&#20102;&#20256;&#32479;&#25512;&#26029;&#26041;&#27861;&#30340;&#32570;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural Posterior Estimation methods for simulation-based inference can be ill-suited for dealing with posterior distributions obtained by conditioning on multiple observations, as they tend to require a large number of simulator calls to learn accurate approximations. In contrast, Neural Likelihood Estimation methods can handle multiple observations at inference time after learning from individual observations, but they rely on standard inference methods, such as MCMC or variational inference, which come with certain performance drawbacks. We introduce a new method based on conditional score modeling that enjoys the benefits of both approaches. We model the scores of the (diffused) posterior distributions induced by individual observations, and introduce a way of combining the learned scores to approximately sample from the target posterior distribution. Our approach is sample-efficient, can naturally aggregate multiple observations at inference time, and avoids the drawbacks of standa
&lt;/p&gt;</description></item><item><title>DynDepNet&#26159;&#19968;&#31181;&#23398;&#20064;fMRI&#25968;&#25454;&#20013;&#26102;&#21464;&#20381;&#36182;&#32467;&#26500;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#24615;&#21035;&#20998;&#31867;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2209.13513</link><description>&lt;p&gt;
DynDepNet:&#36890;&#36807;&#21160;&#24577;&#22270;&#32467;&#26500;&#23398;&#20064;&#20174;fMRI&#25968;&#25454;&#20013;&#23398;&#20064;&#26102;&#21464;&#30340;&#20381;&#36182;&#20851;&#31995;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
DynDepNet: Learning Time-Varying Dependency Structures from fMRI Data via Dynamic Graph Structure Learning. (arXiv:2209.13513v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.13513
&lt;/p&gt;
&lt;p&gt;
DynDepNet&#26159;&#19968;&#31181;&#23398;&#20064;fMRI&#25968;&#25454;&#20013;&#26102;&#21464;&#20381;&#36182;&#32467;&#26500;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#24615;&#21035;&#20998;&#31867;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#22312;&#23398;&#20064;&#22522;&#20110;&#21151;&#33021;&#30913;&#20849;&#25391;&#25104;&#20687;&#65288;fMRI&#65289;&#25968;&#25454;&#30340;&#22823;&#33041;&#22270;&#34920;&#31034;&#26041;&#38754;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;GNN&#26041;&#27861;&#20551;&#35774;&#22823;&#33041;&#22270;&#22312;&#26102;&#38388;&#19978;&#26159;&#38745;&#24577;&#30340;&#65292;&#24182;&#19988;&#22312;&#27169;&#22411;&#35757;&#32451;&#20043;&#21069;&#24050;&#30693;&#22270;&#37051;&#25509;&#30697;&#38453;&#12290;&#36825;&#20123;&#20551;&#35774;&#19982;&#35777;&#25454;&#30456;&#30683;&#30462;&#65292;&#21363;&#22823;&#33041;&#22270;&#22312;&#26102;&#38388;&#19978;&#26159;&#21464;&#21270;&#30340;&#65292;&#24182;&#19988;&#20854;&#36830;&#25509;&#32467;&#26500;&#21462;&#20915;&#20110;&#21151;&#33021;&#36830;&#25509;&#27979;&#37327;&#30340;&#36873;&#25321;&#12290;&#29992;&#22122;&#22768;&#22823;&#33041;&#22270;&#38169;&#35823;&#22320;&#34920;&#31034;fMRI&#25968;&#25454;&#20250;&#23545;GNN&#30340;&#24615;&#33021;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;DynDepNet&#65292;&#19968;&#31181;&#36890;&#36807;&#19979;&#28216;&#39044;&#27979;&#20219;&#21153;&#25152;&#24341;&#21457;&#30340;fMRI&#25968;&#25454;&#30340;&#26368;&#20248;&#26102;&#21464;&#20381;&#36182;&#32467;&#26500;&#30340;&#23398;&#20064;&#26041;&#27861;&#12290;&#23545;&#20110;&#24615;&#21035;&#20998;&#31867;&#20219;&#21153;&#65292;&#23545;&#30495;&#23454;&#19990;&#30028;&#30340;fMRI&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#23454;&#39564;&#35777;&#26126;DynDepNet&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#20934;&#30830;&#29575;&#20998;&#21035;&#27604;&#26368;&#20339;&#22522;&#20934;&#32447;&#25552;&#39640;&#20102;&#32422;8&#20010;&#30334;&#20998;&#28857;&#21644;6&#20010;&#30334;&#20998;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks (GNNs) have demonstrated success in learning representations of brain graphs derived from functional magnetic resonance imaging (fMRI) data. However, existing GNN methods assume brain graphs are static over time and the graph adjacency matrix is known prior to model training. These assumptions contradict evidence that brain graphs are time-varying with a connectivity structure that depends on the choice of functional connectivity measure. Incorrectly representing fMRI data with noisy brain graphs can adversely affect GNN performance. To address this, we propose DynDepNet, a novel method for learning the optimal time-varying dependency structure of fMRI data induced by downstream prediction tasks. Experiments on real-world fMRI datasets, for the task of sex classification, demonstrate that DynDepNet achieves state-of-the-art results, outperforming the best baseline in terms of accuracy by approximately 8 and 6 percentage points, respectively. Furthermore, analysis 
&lt;/p&gt;</description></item><item><title>&#19981;&#21516;&#20998;&#24067;&#30340;&#25968;&#25454;&#21487;&#20197;&#23545;&#20219;&#21153;&#30340;&#27867;&#21270;&#35823;&#24046;&#20135;&#29983;&#38750;&#21333;&#35843;&#30340;&#24433;&#21709;&#65292;&#20351;&#29992;&#23569;&#37327;&#19981;&#21516;&#20998;&#24067;&#30340;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#26159;&#26377;&#20215;&#20540;&#30340;&#12290;</title><link>http://arxiv.org/abs/2208.10967</link><description>&lt;p&gt;
&#19981;&#21516;&#20998;&#24067;&#30340;&#25968;&#25454;&#20215;&#20540;
&lt;/p&gt;
&lt;p&gt;
The Value of Out-of-Distribution Data. (arXiv:2208.10967v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.10967
&lt;/p&gt;
&lt;p&gt;
&#19981;&#21516;&#20998;&#24067;&#30340;&#25968;&#25454;&#21487;&#20197;&#23545;&#20219;&#21153;&#30340;&#27867;&#21270;&#35823;&#24046;&#20135;&#29983;&#38750;&#21333;&#35843;&#30340;&#24433;&#21709;&#65292;&#20351;&#29992;&#23569;&#37327;&#19981;&#21516;&#20998;&#24067;&#30340;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#26159;&#26377;&#20215;&#20540;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#26399;&#26395;&#38543;&#30528;&#31867;&#20284;&#20219;&#21153;&#26679;&#26412;&#30340;&#22686;&#21152;&#65292;&#27867;&#21270;&#35823;&#24046;&#20250;&#20943;&#23567;&#65307;&#32780;&#38543;&#30528;&#26469;&#33258;&#19981;&#21516;&#20998;&#24067;&#65288;OOD&#65289;&#20219;&#21153;&#26679;&#26412;&#30340;&#22686;&#21152;&#65292;&#27867;&#21270;&#35823;&#24046;&#20250;&#22686;&#22823;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#21453;&#30452;&#35273;&#30340;&#29616;&#35937;&#65306;&#20219;&#21153;&#30340;&#27867;&#21270;&#35823;&#24046;&#21487;&#20197;&#26159;&#26679;&#26412;&#20174;OOD&#20219;&#21153;&#20013;&#30340;&#25968;&#37327;&#30340;&#38750;&#21333;&#35843;&#20989;&#25968;&#12290;&#38543;&#30528;OOD&#26679;&#26412;&#25968;&#37327;&#30340;&#22686;&#21152;&#65292;&#30446;&#26631;&#20219;&#21153;&#30340;&#27867;&#21270;&#35823;&#24046;&#22312;&#36229;&#36807;&#19968;&#20010;&#38408;&#20540;&#20043;&#21069;&#20250;&#20808;&#20943;&#23567;&#21518;&#22686;&#22823;&#12290;&#25442;&#21477;&#35805;&#35828;&#65292;&#20351;&#29992;&#23569;&#37327;OOD&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#26159;&#26377;&#20215;&#20540;&#30340;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#20351;&#29992;Fisher&#32447;&#24615;&#21028;&#21035;&#21644;&#35745;&#31639;&#26426;&#35270;&#35273;&#22522;&#20934;&#25968;&#25454;&#38598;&#65288;&#22914;MNIST&#12289;CIFAR-10&#12289;CINIC-10&#12289;PACS&#21644;DomainNet&#65289;&#19978;&#30340;&#28145;&#24230;&#32593;&#32476;&#26469;&#23637;&#31034;&#21644;&#20998;&#26512;&#36825;&#19968;&#29616;&#35937;&#12290;&#22312;&#25105;&#20204;&#30693;&#36947;&#21738;&#20123;&#26679;&#26412;&#23646;&#20110;OOD&#30340;&#29702;&#24819;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#21033;&#29992;&#30446;&#26631;&#21644;OOD&#32463;&#39564;&#39118;&#38505;&#30340;&#36866;&#24403;&#21152;&#26435;&#30446;&#26631;&#26469;&#21033;&#29992;&#36825;&#20123;&#38750;&#21333;&#35843;&#36235;&#21183;&#12290;&#23613;&#31649;&#23454;&#38469;&#24212;&#29992;&#26377;&#38480;&#65292;&#20294;&#36825;&#34920;&#26126;&#22914;&#26524;&#25105;&#20204;&#33021;&#22815;&#26816;&#27979;&#21040;OOD&#26679;&#26412;&#65292;&#36825;&#31181;&#26041;&#27861;&#21487;&#33021;&#26159;&#26377;&#20215;&#20540;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We expect the generalization error to improve with more samples from a similar task, and to deteriorate with more samples from an out-of-distribution (OOD) task. In this work, we show a counter-intuitive phenomenon: the generalization error of a task can be a non-monotonic function of the number of OOD samples. As the number of OOD samples increases, the generalization error on the target task improves before deteriorating beyond a threshold. In other words, there is value in training on small amounts of OOD data. We use Fisher's Linear Discriminant on synthetic datasets and deep networks on computer vision benchmarks such as MNIST, CIFAR-10, CINIC-10, PACS and DomainNet to demonstrate and analyze this phenomenon. In the idealistic setting where we know which samples are OOD, we show that these non-monotonic trends can be exploited using an appropriately weighted objective of the target and OOD empirical risk. While its practical utility is limited, this does suggest that if we can det
&lt;/p&gt;</description></item><item><title>Survival Kernets &#26159;&#19968;&#31181;&#21487;&#25193;&#23637;&#19988;&#21487;&#35299;&#37322;&#30340;&#28145;&#24230;&#26680;&#29983;&#23384;&#20998;&#26512;&#27169;&#22411;&#65292;&#33021;&#22815;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#27169;&#22411;&#35299;&#37322;&#21644;&#29702;&#35770;&#20998;&#26512;&#12290;&#23427;&#21033;&#29992;&#26680;&#20989;&#25968;&#20272;&#35745;&#20010;&#20307;&#30340;&#29983;&#23384;&#20998;&#24067;&#65292;&#36890;&#36807;&#35757;&#32451;&#38598;&#21387;&#32553;&#26041;&#26696;&#36827;&#34892;&#25968;&#25454;&#20998;&#31751;&#65292;&#22240;&#27492;&#20855;&#26377;&#36739;&#39640;&#30340;&#21487;&#35270;&#21270;&#33021;&#21147;&#21644;&#39044;&#27979;&#20934;&#30830;&#24615;&#20445;&#35777;&#12290;&#35813;&#27169;&#22411;&#22312;&#29305;&#23450;&#24773;&#20917;&#19979;&#30340;&#39044;&#27979;&#29983;&#23384;&#20998;&#24067;&#35823;&#24046;&#30028;&#38480;&#26368;&#20248;&#65292;&#19988;&#22312;&#27979;&#35797;&#26102;&#20855;&#26377;&#21487;&#25193;&#23637;&#24615;&#12290;</title><link>http://arxiv.org/abs/2206.10477</link><description>&lt;p&gt;
Survival Kernets: &#21487;&#25193;&#23637;&#19988;&#21487;&#35299;&#37322;&#30340;&#28145;&#24230;&#26680;&#29983;&#23384;&#20998;&#26512;&#27169;&#22411;&#65292;&#24182;&#20855;&#26377;&#20934;&#30830;&#24615;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Survival Kernets: Scalable and Interpretable Deep Kernel Survival Analysis with an Accuracy Guarantee. (arXiv:2206.10477v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.10477
&lt;/p&gt;
&lt;p&gt;
Survival Kernets &#26159;&#19968;&#31181;&#21487;&#25193;&#23637;&#19988;&#21487;&#35299;&#37322;&#30340;&#28145;&#24230;&#26680;&#29983;&#23384;&#20998;&#26512;&#27169;&#22411;&#65292;&#33021;&#22815;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#27169;&#22411;&#35299;&#37322;&#21644;&#29702;&#35770;&#20998;&#26512;&#12290;&#23427;&#21033;&#29992;&#26680;&#20989;&#25968;&#20272;&#35745;&#20010;&#20307;&#30340;&#29983;&#23384;&#20998;&#24067;&#65292;&#36890;&#36807;&#35757;&#32451;&#38598;&#21387;&#32553;&#26041;&#26696;&#36827;&#34892;&#25968;&#25454;&#20998;&#31751;&#65292;&#22240;&#27492;&#20855;&#26377;&#36739;&#39640;&#30340;&#21487;&#35270;&#21270;&#33021;&#21147;&#21644;&#39044;&#27979;&#20934;&#30830;&#24615;&#20445;&#35777;&#12290;&#35813;&#27169;&#22411;&#22312;&#29305;&#23450;&#24773;&#20917;&#19979;&#30340;&#39044;&#27979;&#29983;&#23384;&#20998;&#24067;&#35823;&#24046;&#30028;&#38480;&#26368;&#20248;&#65292;&#19988;&#22312;&#27979;&#35797;&#26102;&#20855;&#26377;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#29983;&#23384;&#20998;&#26512;&#27169;&#22411;&#36890;&#36807;&#26680;&#20989;&#25968;&#26469;&#20272;&#35745;&#20010;&#20307;&#30340;&#29983;&#23384;&#20998;&#24067;&#65292;&#26680;&#20989;&#25968;&#24230;&#37327;&#20219;&#24847;&#20004;&#20010;&#25968;&#25454;&#28857;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28145;&#24230;&#26680;&#29983;&#23384;&#27169;&#22411;&#8212;&#8212;&#29983;&#23384;kernet&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#65292;&#24182;&#19988;&#26131;&#20110;&#35299;&#37322;&#21644;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35757;&#32451;&#25968;&#25454;&#26681;&#25454;&#19968;&#31181;&#26368;&#36817;&#21457;&#23637;&#30340;&#29992;&#20110;&#20998;&#31867;&#21644;&#22238;&#24402;&#30340;&#35757;&#32451;&#38598;&#21387;&#32553;&#26041;&#26696;&#65288;&#31216;&#20026;&#26680;&#32676;&#65289;&#36827;&#34892;&#20998;&#31751;&#12290;&#22312;&#27979;&#35797;&#26102;&#65292;&#27599;&#20010;&#25968;&#25454;&#28857;&#34987;&#34920;&#31034;&#20026;&#36825;&#20123;&#31751;&#30340;&#21152;&#26435;&#32452;&#21512;&#65292;&#27599;&#20010;&#31751;&#21487;&#20197;&#36827;&#34892;&#21487;&#35270;&#21270;&#23637;&#31034;&#12290;&#23545;&#20110;&#29983;&#23384;kernet&#30340;&#19968;&#20010;&#29305;&#27530;&#24773;&#20917;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#26377;&#38480;&#26679;&#26412;&#35823;&#24046;&#30028;&#38480;&#65292;&#39044;&#27979;&#30340;&#29983;&#23384;&#20998;&#24067;&#22312;&#35813;&#30028;&#38480;&#19979;&#26159;&#26368;&#20248;&#30340;&#65288;&#38500;&#21435;&#19968;&#20010;&#23545;&#25968;&#22240;&#23376;&#65289;&#12290;&#22312;&#27979;&#35797;&#26102;&#20855;&#26377;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernel survival analysis models estimate individual survival distributions with the help of a kernel function, which measures the similarity between any two data points. Such a kernel function can be learned using deep kernel survival models. In this paper, we present a new deep kernel survival model called a survival kernet, which scales to large datasets in a manner that is amenable to model interpretation and also theoretical analysis. Specifically, the training data are partitioned into clusters based on a recently developed training set compression scheme for classification and regression called kernel netting that we extend to the survival analysis setting. At test time, each data point is represented as a weighted combination of these clusters, and each such cluster can be visualized. For a special case of survival kernets, we establish a finite-sample error bound on predicted survival distributions that is, up to a log factor, optimal. Whereas scalability at test time is achiev
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DORA&#30340;&#25968;&#25454;&#19981;&#21487;&#30693;&#26694;&#26550;&#65292;&#29992;&#20110;&#20998;&#26512;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#34920;&#24449;&#31354;&#38388;&#65292;&#24182;&#21487;&#20197;&#35782;&#21035;&#19981;&#31526;&#21512;&#20154;&#31867;&#30452;&#35266;&#35748;&#30693;&#30340;&#34920;&#24449;&#12290;</title><link>http://arxiv.org/abs/2206.04530</link><description>&lt;p&gt;
DORA&#65306;&#25506;&#32034;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#24322;&#24120;&#20540;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
DORA: Exploring outlier representations in Deep Neural Networks. (arXiv:2206.04530v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.04530
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DORA&#30340;&#25968;&#25454;&#19981;&#21487;&#30693;&#26694;&#26550;&#65292;&#29992;&#20110;&#20998;&#26512;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#34920;&#24449;&#31354;&#38388;&#65292;&#24182;&#21487;&#20197;&#35782;&#21035;&#19981;&#31526;&#21512;&#20154;&#31867;&#30452;&#35266;&#35748;&#30693;&#30340;&#34920;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#22312;&#23398;&#20064;&#22797;&#26434;&#25277;&#35937;&#26041;&#38754;&#38750;&#24120;&#26377;&#25928;&#65292;&#20294;&#23427;&#20204;&#23481;&#26131;&#24847;&#22806;&#22320;&#20174;&#35757;&#32451;&#25968;&#25454;&#20013;&#23398;&#20064;&#21040;&#34394;&#20551;&#30340;&#29305;&#24449;&#12290;&#20026;&#20102;&#30830;&#20445;&#27169;&#22411;&#30340;&#36879;&#26126;&#24230;&#65292;&#26816;&#26597;&#23398;&#20064;&#34920;&#31034;&#20043;&#38388;&#30340;&#20851;&#31995;&#33267;&#20851;&#37325;&#35201;&#65292;&#22240;&#20026;&#24847;&#22806;&#30340;&#27010;&#24565;&#24448;&#24448;&#34920;&#29616;&#20026;&#19982;&#25152;&#38656;&#30340;&#20219;&#21153;&#19981;&#31526;&#30340;&#24322;&#24120;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;DORA&#65288;Data-agnOstic Representation Analysis&#65289;&#65306;&#29992;&#20110;&#20998;&#26512;DNN&#34920;&#31034;&#31354;&#38388;&#30340;&#31532;&#19968;&#20010;&#25968;&#25454;&#19981;&#21487;&#30693;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#37319;&#29992;&#20102;&#25152;&#25552;&#20986;&#30340;&#34920;&#31034;&#20043;&#38388;&#30340;&#26497;&#31471;&#28608;&#27963;&#65288;EA&#65289;&#36317;&#31163;&#24230;&#37327;&#65292;&#22312;&#19981;&#35775;&#38382;&#20219;&#20309;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#21033;&#29992;&#32593;&#32476;&#20869;&#33258;&#35828;&#26126;&#33021;&#21147;&#12290;&#25105;&#20204;&#23450;&#37327;&#39564;&#35777;&#20102;&#24230;&#37327;&#30340;&#27491;&#30830;&#24615;&#21644;&#19982;&#20154;&#20026;&#23450;&#20041;&#30340;&#35821;&#20041;&#36317;&#31163;&#30340;&#19968;&#33268;&#24615;&#12290;EA&#36317;&#31163;&#19982;&#20154;&#31867;&#21028;&#26029;&#20043;&#38388;&#30340;&#19968;&#33268;&#24615;&#20351;&#25105;&#20204;&#33021;&#22815;&#30830;&#23450;&#34920;&#24449;&#65292;&#20854;&#22522;&#26412;&#27010;&#24565;&#34987;&#35748;&#20026;&#26159;&#19981;&#33258;&#28982;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Although Deep Neural Networks (DNNs) are incredibly effective in learning complex abstractions, they are susceptible to unintentionally learning spurious artifacts from the training data. To ensure model transparency, it is crucial to examine the relationships between learned representations, as unintended concepts often manifest themselves to be anomalous to the desired task. In this work, we introduce DORA (Data-agnOstic Representation Analysis): the first data-agnostic framework for the analysis of the representation space of DNNs. Our framework employs the proposed Extreme-Activation (EA) distance measure between representations that utilizes self-explaining capabilities within the network without accessing any data. We quantitatively validate the metric's correctness and alignment with human-defined semantic distances. The coherence between the EA distance and human judgment enables us to identify representations whose underlying concepts would be considered unnatural by humans by
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Cal-PIT&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#19968;&#20010;&#27010;&#29575;-&#27010;&#29575;&#26144;&#23556;&#65292;&#35299;&#20915;&#20102;&#39044;&#27979;&#20998;&#24067;&#30340;&#35786;&#26029;&#21644;&#26657;&#20934;&#38382;&#39064;&#65292;&#26469;&#23454;&#29616;&#26377;&#26465;&#20214;&#26657;&#20934;&#12290;</title><link>http://arxiv.org/abs/2205.14568</link><description>&lt;p&gt;
&#36890;&#36807;&#27010;&#29575;-&#27010;&#29575;&#26144;&#23556;&#23454;&#29616;&#26377;&#26465;&#20214;&#26657;&#20934;&#30340;&#39044;&#27979;&#20998;&#24067;&#65306;&#22312;&#38134;&#27827;&#32418;&#31227;&#20272;&#35745;&#21644;&#27010;&#29575;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Conditionally Calibrated Predictive Distributions by Probability-Probability Map: Application to Galaxy Redshift Estimation and Probabilistic Forecasting. (arXiv:2205.14568v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.14568
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Cal-PIT&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#19968;&#20010;&#27010;&#29575;-&#27010;&#29575;&#26144;&#23556;&#65292;&#35299;&#20915;&#20102;&#39044;&#27979;&#20998;&#24067;&#30340;&#35786;&#26029;&#21644;&#26657;&#20934;&#38382;&#39064;&#65292;&#26469;&#23454;&#29616;&#26377;&#26465;&#20214;&#26657;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#23545;&#20110;&#35780;&#20272;AI&#31639;&#27861;&#30340;&#39044;&#27979;&#33021;&#21147;&#33267;&#20851;&#37325;&#35201;&#12290;&#36807;&#21435;&#30340;&#30740;&#31350;&#33268;&#21147;&#20110;&#25551;&#36848;&#30446;&#26631;&#21464;&#37327;$y \in \mathbb{R}$&#22312;&#32473;&#23450;&#22797;&#26434;&#36755;&#20837;&#29305;&#24449;$\mathbf{x} \in \mathcal{X}$&#30340;&#26465;&#20214;&#19979;&#30340;&#39044;&#27979;&#20998;&#24067;$F(y|\mathbf{x})$&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#39044;&#27979;&#20998;&#24067;&#65288;&#20363;&#22914;&#65292;&#24402;&#19968;&#21270;&#27969;&#21644;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65289;&#24448;&#24448;&#32570;&#20047;&#26465;&#20214;&#26657;&#20934;&#65292;&#21363;&#32473;&#23450;&#36755;&#20837;$\mathbf{x}$&#30340;&#20107;&#20214;&#21457;&#29983;&#30340;&#27010;&#29575;&#19982;&#39044;&#27979;&#27010;&#29575;&#26174;&#33879;&#19981;&#21516;&#12290;&#24403;&#21069;&#30340;&#26657;&#20934;&#26041;&#27861;&#19981;&#33021;&#23436;&#20840;&#35780;&#20272;&#21644;&#23454;&#26045;&#26377;&#26465;&#20214;&#26657;&#20934;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Cal-PIT&#30340;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#20174;&#26657;&#20934;&#25968;&#25454;&#20013;&#23398;&#20064;&#19968;&#20010;&#27010;&#29575;-&#27010;&#29575;&#26144;&#23556;&#26469;&#21516;&#26102;&#35299;&#20915;&#39044;&#27979;&#20998;&#24067;&#30340;&#35786;&#26029;&#21644;&#26657;&#20934;&#38382;&#39064;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#23545;&#27010;&#29575;&#31215;&#20998;&#21464;&#25442;&#20998;&#25968;&#36827;&#34892;$\mathbf{x}$&#30340;&#22238;&#24402;&#12290;&#20272;&#35745;&#30340;&#22238;&#24402;&#25552;&#20379;&#20102;&#23545;&#29305;&#24449;&#31354;&#38388;&#20013;&#26465;&#20214;&#35206;&#30422;&#30340;&#21487;&#35299;&#37322;&#35786;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty quantification is crucial for assessing the predictive ability of AI algorithms. Much research has been devoted to describing the predictive distribution (PD) $F(y|\mathbf{x})$ of a target variable $y \in \mathbb{R}$ given complex input features $\mathbf{x} \in \mathcal{X}$. However, off-the-shelf PDs (from, e.g., normalizing flows and Bayesian neural networks) often lack conditional calibration with the probability of occurrence of an event given input $\mathbf{x}$ being significantly different from the predicted probability. Current calibration methods do not fully assess and enforce conditionally calibrated PDs. Here we propose \texttt{Cal-PIT}, a method that addresses both PD diagnostics and recalibration by learning a single probability-probability map from calibration data. The key idea is to regress probability integral transform scores against $\mathbf{x}$. The estimated regression provides interpretable diagnostics of conditional coverage across the feature space. 
&lt;/p&gt;</description></item><item><title>DDAC-SpAM&#26159;&#19968;&#31181;&#22312;&#39640;&#32500;&#31232;&#30095;&#21152;&#24615;&#27169;&#22411;&#20013;&#21033;&#29992;&#29305;&#24449;&#21010;&#20998;&#21644;&#21435;&#30456;&#20851;&#30340;&#20998;&#24067;&#24335;&#31639;&#27861;&#12290;&#21435;&#30456;&#20851;&#25805;&#20316;&#20351;&#24471;&#27599;&#20010;&#23616;&#37096;&#20272;&#35745;&#22120;&#33021;&#22815;&#24674;&#22797;&#27599;&#20010;&#21152;&#24615;&#32452;&#20998;&#30340;&#31232;&#30095;&#27169;&#24335;&#65292;&#21516;&#26102;&#19981;&#23545;&#21464;&#37327;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#32467;&#26500;&#26045;&#21152;&#20005;&#26684;&#30340;&#32422;&#26463;&#12290;&#35813;&#31639;&#27861;&#22312;&#29702;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#20013;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#21644;&#25928;&#29575;&#65292;&#20026;&#25311;&#21512;&#31232;&#30095;&#21152;&#24615;&#27169;&#22411;&#25552;&#20379;&#20102;&#23454;&#38469;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2205.07932</link><description>&lt;p&gt;
DDAC-SpAM: &#19968;&#31181;&#29992;&#29305;&#24449;&#21010;&#20998;&#21644;&#21435;&#30456;&#20851;&#24615;&#30340;&#26041;&#27861;&#25311;&#21512;&#39640;&#32500;&#31232;&#30095;&#21152;&#24615;&#27169;&#22411;&#30340;&#20998;&#24067;&#24335;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
DDAC-SpAM: A Distributed Algorithm for Fitting High-dimensional Sparse Additive Models with Feature Division and Decorrelation. (arXiv:2205.07932v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.07932
&lt;/p&gt;
&lt;p&gt;
DDAC-SpAM&#26159;&#19968;&#31181;&#22312;&#39640;&#32500;&#31232;&#30095;&#21152;&#24615;&#27169;&#22411;&#20013;&#21033;&#29992;&#29305;&#24449;&#21010;&#20998;&#21644;&#21435;&#30456;&#20851;&#30340;&#20998;&#24067;&#24335;&#31639;&#27861;&#12290;&#21435;&#30456;&#20851;&#25805;&#20316;&#20351;&#24471;&#27599;&#20010;&#23616;&#37096;&#20272;&#35745;&#22120;&#33021;&#22815;&#24674;&#22797;&#27599;&#20010;&#21152;&#24615;&#32452;&#20998;&#30340;&#31232;&#30095;&#27169;&#24335;&#65292;&#21516;&#26102;&#19981;&#23545;&#21464;&#37327;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#32467;&#26500;&#26045;&#21152;&#20005;&#26684;&#30340;&#32422;&#26463;&#12290;&#35813;&#31639;&#27861;&#22312;&#29702;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#20013;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#21644;&#25928;&#29575;&#65292;&#20026;&#25311;&#21512;&#31232;&#30095;&#21152;&#24615;&#27169;&#22411;&#25552;&#20379;&#20102;&#23454;&#38469;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#24335;&#32479;&#35745;&#23398;&#20064;&#24050;&#25104;&#20026;&#22823;&#35268;&#27169;&#25968;&#25454;&#20998;&#26512;&#30340;&#24120;&#29992;&#25216;&#26415;&#12290;&#29616;&#26377;&#30340;&#22823;&#37096;&#20998;&#24037;&#20316;&#37117;&#26159;&#20851;&#27880;&#35266;&#23519;&#20540;&#30340;&#21010;&#20998;&#65292;&#20294;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;DDAC-SpAM&#65292;&#22312;&#39640;&#32500;&#31232;&#30095;&#21152;&#24615;&#27169;&#22411;&#20013;&#23545;&#29305;&#24449;&#36827;&#34892;&#21010;&#20998;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21253;&#25324;&#19977;&#20010;&#27493;&#39588;&#65306;&#21010;&#20998;&#12289;&#21435;&#30456;&#20851;&#21644;&#24449;&#26381;&#12290;&#21435;&#30456;&#20851;&#25805;&#20316;&#20351;&#27599;&#20010;&#23616;&#37096;&#20272;&#35745;&#22120;&#33021;&#22815;&#24674;&#22797;&#27599;&#20010;&#21152;&#24615;&#32452;&#20998;&#30340;&#31232;&#30095;&#27169;&#24335;&#65292;&#32780;&#19981;&#23545;&#21464;&#37327;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#32467;&#26500;&#26045;&#21152;&#20005;&#26684;&#30340;&#32422;&#26463;&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#30340;&#23454;&#35777;&#32467;&#26524;&#65292;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#25928;&#29575;&#12290;&#29702;&#35770;&#32467;&#26524;&#21253;&#25324;&#19968;&#33268;&#30340;&#31232;&#30095;&#27169;&#24335;&#24674;&#22797;&#20197;&#21450;&#23545;&#27599;&#20010;&#21152;&#24615;&#20989;&#25968;&#32452;&#25104;&#37096;&#20998;&#30340;&#32479;&#35745;&#25512;&#26029;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20026;&#25311;&#21512;&#31232;&#30095;&#21152;&#24615;&#27169;&#22411;&#25552;&#20379;&#20102;&#23454;&#38469;&#21487;&#34892;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#22312;&#21508;&#20010;&#39046;&#22495;&#26377;&#30528;&#24191;&#27867;&#30340;&#24212;&#29992;&#21069;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distributed statistical learning has become a popular technique for large-scale data analysis. Most existing work in this area focuses on dividing the observations, but we propose a new algorithm, DDAC-SpAM, which divides the features under a high-dimensional sparse additive model. Our approach involves three steps: divide, decorrelate, and conquer. The decorrelation operation enables each local estimator to recover the sparsity pattern for each additive component without imposing strict constraints on the correlation structure among variables. The effectiveness and efficiency of the proposed algorithm are demonstrated through theoretical analysis and empirical results on both synthetic and real data. The theoretical results include both the consistent sparsity pattern recovery as well as statistical inference for each additive functional component. Our approach provides a practical solution for fitting sparse additive models, with promising applications in a wide range of domains.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#22312;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#20013;&#35777;&#26126;&#20102;&#23398;&#20064;&#26410;&#30693;&#37193;&#30340;&#36234;&#22495;&#27867;&#21270;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#20351;&#29992;&#20056;&#31215;&#24577;&#26469;&#23398;&#20064;&#37193;&#23545;&#32416;&#32544;&#24577;&#30340;&#20316;&#29992;&#65292;&#20174;&#32780;&#25512;&#21160;&#20102;&#22312;&#36817;&#26399;&#37327;&#23376;&#30828;&#20214;&#19978;&#23398;&#20064;&#37327;&#23376;&#21160;&#21147;&#23398;&#30340;&#21069;&#26223;&#65292;&#24182;&#20026;&#32463;&#20856;&#21644;&#37327;&#23376;&#30005;&#36335;&#30340;&#32534;&#35793;&#25552;&#20379;&#20102;&#26032;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2204.10268</link><description>&lt;p&gt;
&#23398;&#20064;&#37327;&#23376;&#21160;&#21147;&#23398;&#30340;&#36234;&#22495;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Out-of-distribution generalization for learning quantum dynamics. (arXiv:2204.10268v3 [quant-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.10268
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#22312;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#20013;&#35777;&#26126;&#20102;&#23398;&#20064;&#26410;&#30693;&#37193;&#30340;&#36234;&#22495;&#27867;&#21270;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#20351;&#29992;&#20056;&#31215;&#24577;&#26469;&#23398;&#20064;&#37193;&#23545;&#32416;&#32544;&#24577;&#30340;&#20316;&#29992;&#65292;&#20174;&#32780;&#25512;&#21160;&#20102;&#22312;&#36817;&#26399;&#37327;&#23376;&#30828;&#20214;&#19978;&#23398;&#20064;&#37327;&#23376;&#21160;&#21147;&#23398;&#30340;&#21069;&#26223;&#65292;&#24182;&#20026;&#32463;&#20856;&#21644;&#37327;&#23376;&#30005;&#36335;&#30340;&#32534;&#35793;&#25552;&#20379;&#20102;&#26032;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27867;&#21270;&#36793;&#30028;&#26159;&#35780;&#20272;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#65288;QML&#65289;&#35757;&#32451;&#25968;&#25454;&#35201;&#27714;&#30340;&#20851;&#38190;&#24037;&#20855;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#24050;&#32463;&#24314;&#31435;&#20102;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#65288;QNNs&#65289;&#22312;&#22495;&#20869;&#27867;&#21270;&#30340;&#20445;&#35777;&#65292;&#20854;&#20013;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#26469;&#33258;&#21516;&#19968;&#25968;&#25454;&#20998;&#24067;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#36824;&#27809;&#26377;&#20851;&#20110;QML&#20013;&#22495;&#22806;&#27867;&#21270;&#30340;&#32467;&#26524;&#65292;&#20854;&#20013;&#25105;&#20204;&#35201;&#27714;&#35757;&#32451;&#20986;&#30340;&#27169;&#22411;&#22312;&#26469;&#33258;&#19982;&#35757;&#32451;&#20998;&#24067;&#19981;&#21516;&#30340;&#25968;&#25454;&#19978;&#34920;&#29616;&#33391;&#22909;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#23398;&#20064;&#26410;&#30693;&#37193;&#30340;&#36234;&#22495;&#27867;&#21270;&#30340;&#33021;&#21147;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21363;&#20351;&#20165;&#20165;&#35757;&#32451;&#21040;&#20102;&#20056;&#31215;&#24577;&#65292;&#25105;&#20204;&#20063;&#21487;&#20197;&#23398;&#20064;&#21040;&#37193;&#23545;&#32416;&#32544;&#24577;&#30340;&#20316;&#29992;&#12290;&#30001;&#20110;&#20056;&#31215;&#24577;&#21482;&#38656;&#35201;&#20351;&#29992;&#21333;&#27604;&#29305;&#38376;&#23601;&#21487;&#20197;&#21046;&#22791;&#65292;&#36825;&#25512;&#21160;&#20102;&#22312;&#36817;&#26399;&#37327;&#23376;&#30828;&#20214;&#19978;&#23398;&#20064;&#37327;&#23376;&#21160;&#21147;&#23398;&#30340;&#21069;&#26223;&#65292;&#24182;&#36827;&#19968;&#27493;&#20026;&#32463;&#20856;&#21644;&#37327;&#23376;&#30005;&#36335;&#30340;&#32534;&#35793;&#25552;&#20379;&#20102;&#26032;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generalization bounds are a critical tool to assess the training data requirements of Quantum Machine Learning (QML). Recent work has established guarantees for in-distribution generalization of quantum neural networks (QNNs), where training and testing data are drawn from the same data distribution. However, there are currently no results on out-of-distribution generalization in QML, where we require a trained model to perform well even on data drawn from a different distribution to the training distribution. Here, we prove out-of-distribution generalization for the task of learning an unknown unitary. In particular, we show that one can learn the action of a unitary on entangled states having trained only product states. Since product states can be prepared using only single-qubit gates, this advances the prospects of learning quantum dynamics on near term quantum hardware, and further opens up new methods for both the classical and quantum compilation of quantum circuits.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20851;&#32852;&#32447;&#24615;&#28909;&#26041;&#31243;&#30340;&#35299;&#65292;&#24471;&#21040;&#20102;&#23545;&#31216;&#21452;&#33218;&#20271;&#21162;&#21033;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;minmax&#26368;&#20248;&#36951;&#25022;&#21644;&#20266;&#36951;&#25022;&#30340;&#39046;&#20808;&#39033;&#12290;&#26032;&#30340;&#32467;&#26524;&#25913;&#36827;&#20102;&#20808;&#21069;&#30340;&#30740;&#31350;&#65292;&#24182;&#25552;&#20379;&#20102;&#26032;&#30340;&#38750;&#28176;&#36817;&#36793;&#30028;&#12290;</title><link>http://arxiv.org/abs/2202.05767</link><description>&lt;p&gt;
&#22522;&#20110;PDE&#30340;&#23545;&#31216;&#21452;&#33218;&#20271;&#21162;&#21033;&#36172;&#21338;&#26426;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A PDE-Based Analysis of the Symmetric Two-Armed Bernoulli Bandit. (arXiv:2202.05767v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.05767
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20851;&#32852;&#32447;&#24615;&#28909;&#26041;&#31243;&#30340;&#35299;&#65292;&#24471;&#21040;&#20102;&#23545;&#31216;&#21452;&#33218;&#20271;&#21162;&#21033;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;minmax&#26368;&#20248;&#36951;&#25022;&#21644;&#20266;&#36951;&#25022;&#30340;&#39046;&#20808;&#39033;&#12290;&#26032;&#30340;&#32467;&#26524;&#25913;&#36827;&#20102;&#20808;&#21069;&#30340;&#30740;&#31350;&#65292;&#24182;&#25552;&#20379;&#20102;&#26032;&#30340;&#38750;&#28176;&#36817;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#19968;&#20010;&#29256;&#26412;&#30340;&#21452;&#33218;&#20271;&#21162;&#21033;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#20854;&#20013;&#20004;&#20010;&#33218;&#30340;&#24179;&#22343;&#20540;&#20043;&#21644;&#20026;1&#65288;&#21363;&#23545;&#31216;&#30340;&#21452;&#33218;&#20271;&#21162;&#21033;&#36172;&#21338;&#26426;&#65289;&#12290;&#22312;&#33218;&#20043;&#38388;&#30340;&#24046;&#36317;&#36235;&#36817;&#20110;&#38646;&#19988;&#39044;&#27979;&#26399;&#25968;&#36235;&#36817;&#20110;&#26080;&#31351;&#22823;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#36890;&#36807;&#23558;&#27599;&#20010;&#35299;&#19982;&#32447;&#24615;&#28909;&#26041;&#31243;&#30340;&#35299;&#20851;&#32852;&#65292;&#24471;&#21040;&#20102;&#35813;&#38382;&#39064;&#30340;minmax&#26368;&#20248;&#36951;&#25022;&#21644;&#20266;&#36951;&#25022;&#30340;&#39046;&#20808;&#39033;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25913;&#36827;&#20102;&#20808;&#21069;&#24050;&#30693;&#30340;&#32467;&#26524;&#65307;&#20855;&#20307;&#32780;&#35328;&#65292;&#22312;&#19977;&#31181;&#19981;&#21516;&#30340;&#24046;&#36317;&#32553;&#25918;&#27169;&#24335;&#19979;&#65292;&#25105;&#20204;&#26126;&#30830;&#35745;&#31639;&#20102;&#36825;&#20123;&#39046;&#20808;&#39033;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24471;&#21040;&#20102;&#20219;&#20309;&#32473;&#23450;&#26102;&#38388;&#33539;&#22260;&#30340;&#26032;&#30340;&#38750;&#28176;&#36817;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work addresses a version of the two-armed Bernoulli bandit problem where the sum of the means of the arms is one (the symmetric two-armed Bernoulli bandit). In a regime where the gap between these means goes to zero and the number of prediction periods approaches infinity, we obtain the leading order terms of the minmax optimal regret and pseudoregret for this problem by associating each of them with a solution of a linear heat equation. Our results improve upon the previously known results; specifically, we explicitly compute these leading order terms in three different scaling regimes for the gap. Additionally, we obtain new non-asymptotic bounds for any given time horizon.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24352;&#37327;&#20998;&#35299;&#26469;&#23454;&#29616;&#19968;&#33268;&#21327;&#21516;&#36807;&#28388;&#30340;&#26032;&#27169;&#22411;&#65292;&#23427;&#33021;&#22815;&#25193;&#23637;&#20256;&#32479;&#30340;&#29992;&#25143;-&#29289;&#21697;&#20559;&#22909;&#35745;&#31639;&#26041;&#27861;&#65292;&#20351;&#24471;&#22312;&#35780;&#20272;&#29289;&#21697;&#30456;&#23545;&#20559;&#22909;&#26102;&#20135;&#29983;&#29289;&#21697;&#20043;&#38388;&#30340;&#20132;&#20114;&#65292;&#20855;&#26377;&#28508;&#22312;&#30340;&#38750;&#32447;&#24615;&#24577;&#24230;&#12290;</title><link>http://arxiv.org/abs/2201.11936</link><description>&lt;p&gt;
&#36890;&#36807;&#24352;&#37327;&#20998;&#35299;&#23454;&#29616;&#19968;&#33268;&#30340;&#21327;&#21516;&#36807;&#28388;
&lt;/p&gt;
&lt;p&gt;
Consistent Collaborative Filtering via Tensor Decomposition. (arXiv:2201.11936v3 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.11936
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24352;&#37327;&#20998;&#35299;&#26469;&#23454;&#29616;&#19968;&#33268;&#21327;&#21516;&#36807;&#28388;&#30340;&#26032;&#27169;&#22411;&#65292;&#23427;&#33021;&#22815;&#25193;&#23637;&#20256;&#32479;&#30340;&#29992;&#25143;-&#29289;&#21697;&#20559;&#22909;&#35745;&#31639;&#26041;&#27861;&#65292;&#20351;&#24471;&#22312;&#35780;&#20272;&#29289;&#21697;&#30456;&#23545;&#20559;&#22909;&#26102;&#20135;&#29983;&#29289;&#21697;&#20043;&#38388;&#30340;&#20132;&#20114;&#65292;&#20855;&#26377;&#28508;&#22312;&#30340;&#38750;&#32447;&#24615;&#24577;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21327;&#21516;&#36807;&#28388;&#26159;&#20998;&#26512;&#29992;&#25143;&#27963;&#21160;&#21644;&#26500;&#24314;&#29289;&#21697;&#25512;&#33616;&#31995;&#32479;&#30340;&#20107;&#23454;&#26631;&#20934;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38544;&#24335;&#21453;&#39304;&#30340;&#21327;&#21516;&#36807;&#28388;&#26032;&#27169;&#22411;&#8212;&#8212;&#20999;&#21106;&#21453;&#23545;&#31216;&#20998;&#35299;&#65288;SAD&#65289;&#12290;&#19982;&#20256;&#32479;&#25216;&#26415;&#19981;&#21516;&#65292;SAD&#36890;&#36807;&#23545;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#30340;&#26032;&#39062;&#19977;&#32500;&#24352;&#37327;&#35270;&#22270;&#24341;&#20837;&#20102;&#19968;&#20010;&#39069;&#22806;&#30340;&#29289;&#21697;&#30340;&#38544;&#21547;&#21521;&#37327;&#12290;&#35813;&#21521;&#37327;&#23558;&#36890;&#36807;&#26631;&#20934;&#28857;&#20056;&#35745;&#31639;&#20986;&#30340;&#29992;&#25143;-&#29289;&#21697;&#20559;&#22909;&#25193;&#23637;&#21040;&#19968;&#33324;&#20869;&#31215;&#65292;&#20174;&#32780;&#22312;&#35780;&#20272;&#29289;&#21697;&#30340;&#30456;&#23545;&#20559;&#22909;&#26102;&#20135;&#29983;&#29289;&#21697;&#20043;&#38388;&#30340;&#20132;&#20114;&#12290;&#24403;&#21521;&#37327;&#25240;&#21472;&#20026;1&#26102;&#65292;SAD&#38477;&#20026;&#26368;&#20808;&#36827;&#30340;&#21327;&#21516;&#36807;&#28388;&#27169;&#22411;&#65288;SOTA&#65289;&#65292;&#32780;&#26412;&#25991;&#20801;&#35768;&#20174;&#25968;&#25454;&#20013;&#20272;&#35745;&#20854;&#20540;&#12290;&#20801;&#35768;&#26032;&#29289;&#21697;&#21521;&#37327;&#30340;&#20540;&#19982;1&#19981;&#21516;&#20855;&#26377;&#28145;&#36828;&#30340;&#24433;&#21709;&#12290;&#36825;&#34920;&#26126;&#29992;&#25143;&#21487;&#33021;&#20855;&#26377;&#38750;&#32447;&#24615;&#24577;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Collaborative filtering is the de facto standard for analyzing users' activities and building recommendation systems for items. In this work we develop Sliced Anti-symmetric Decomposition (SAD), a new model for collaborative filtering based on implicit feedback. In contrast to traditional techniques where a latent representation of users (user vectors) and items (item vectors) are estimated, SAD introduces one additional latent vector to each item, using a novel three-way tensor view of user-item interactions. This new vector extends user-item preferences calculated by standard dot products to general inner products, producing interactions between items when evaluating their relative preferences. SAD reduces to state-of-the-art (SOTA) collaborative filtering models when the vector collapses to 1, while in this paper we allow its value to be estimated from data. Allowing the values of the new item vector to be different from 1 has profound implications. It suggests users may have nonlin
&lt;/p&gt;</description></item><item><title>FIGS&#26159;&#19968;&#31181;&#24555;&#36895;&#21487;&#35299;&#37322;&#30340;&#36138;&#23146;&#26641;&#27714;&#21644;&#31639;&#27861;&#65292;&#36890;&#36807;&#23558;&#36923;&#36753;&#35268;&#21017;&#19982;&#21152;&#27861;&#30456;&#32467;&#21512;&#65292;&#33021;&#22815;&#36866;&#24212;&#21152;&#24615;&#32467;&#26500;&#21516;&#26102;&#20445;&#25345;&#39640;&#24230;&#21487;&#35299;&#37322;&#24615;&#12290;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;FIGS&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#24182;&#22312;&#39640;&#39118;&#38505;&#39046;&#22495;&#22914;&#21307;&#23398;&#20013;&#23637;&#31034;&#20102;&#20854;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2201.11931</link><description>&lt;p&gt;
&#24555;&#36895;&#21487;&#35299;&#37322;&#30340;&#36138;&#23146;&#26641;&#27714;&#21644;
&lt;/p&gt;
&lt;p&gt;
Fast Interpretable Greedy-Tree Sums. (arXiv:2201.11931v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.11931
&lt;/p&gt;
&lt;p&gt;
FIGS&#26159;&#19968;&#31181;&#24555;&#36895;&#21487;&#35299;&#37322;&#30340;&#36138;&#23146;&#26641;&#27714;&#21644;&#31639;&#27861;&#65292;&#36890;&#36807;&#23558;&#36923;&#36753;&#35268;&#21017;&#19982;&#21152;&#27861;&#30456;&#32467;&#21512;&#65292;&#33021;&#22815;&#36866;&#24212;&#21152;&#24615;&#32467;&#26500;&#21516;&#26102;&#20445;&#25345;&#39640;&#24230;&#21487;&#35299;&#37322;&#24615;&#12290;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;FIGS&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#24182;&#22312;&#39640;&#39118;&#38505;&#39046;&#22495;&#22914;&#21307;&#23398;&#20013;&#23637;&#31034;&#20102;&#20854;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#21462;&#24471;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#20294;&#36890;&#24120;&#20250;&#29306;&#29298;&#35299;&#37322;&#24615;&#65292;&#36825;&#22312;&#39640;&#39118;&#38505;&#39046;&#22495;&#22914;&#21307;&#23398;&#20013;&#26159;&#19968;&#20010;&#20851;&#38190;&#32771;&#34385;&#22240;&#32032;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20174;&#19994;&#32773;&#36890;&#24120;&#20351;&#29992;&#39640;&#24230;&#21487;&#35299;&#37322;&#30340;&#20915;&#31574;&#26641;&#27169;&#22411;&#65292;&#20294;&#36825;&#20123;&#27169;&#22411;&#23545;&#21152;&#24615;&#32467;&#26500;&#23384;&#22312;&#24402;&#32435;&#20559;&#24046;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#31181;&#20559;&#24046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24555;&#36895;&#21487;&#35299;&#37322;&#30340;&#36138;&#23146;&#26641;&#27714;&#21644;&#65288;FIGS&#65289;&#65292;&#23427;&#23558;CART&#31639;&#27861;&#25512;&#24191;&#21040;&#21516;&#26102;&#22686;&#38271;&#21487;&#21464;&#25968;&#37327;&#30340;&#26641;&#36827;&#34892;&#27714;&#21644;&#12290;&#36890;&#36807;&#23558;&#36923;&#36753;&#35268;&#21017;&#19982;&#21152;&#27861;&#30456;&#32467;&#21512;&#65292;FIGS&#33021;&#22815;&#36866;&#24212;&#21152;&#24615;&#32467;&#26500;&#21516;&#26102;&#20445;&#25345;&#39640;&#24230;&#21487;&#35299;&#37322;&#24615;&#12290;&#23545;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#22823;&#37327;&#23454;&#39564;&#34920;&#26126;&#65292;FIGS&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#20026;&#20102;&#23637;&#31034;FIGS&#22312;&#39640;&#39118;&#38505;&#39046;&#22495;&#30340;&#23454;&#29992;&#24615;&#65292;&#25105;&#20204;&#23558;FIGS&#25913;&#36827;&#20026;&#23398;&#20064;&#20020;&#24202;&#20915;&#31574;&#24037;&#20855;&#65288;CDIs&#65289;&#65292;CDIs&#26159;&#25351;&#23548;&#20020;&#24202;&#20915;&#31574;&#30340;&#24037;&#20855;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;FIGS&#30340;&#19968;&#20010;&#21464;&#31181;&#65292;&#31216;&#20026;G-FIGS&#65292;&#23427;&#32771;&#34385;&#20102;&#21152;&#24615;&#32467;&#26500;&#30340;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern machine learning has achieved impressive prediction performance, but often sacrifices interpretability, a critical consideration in high-stakes domains such as medicine. In such settings, practitioners often use highly interpretable decision tree models, but these suffer from inductive bias against additive structure. To overcome this bias, we propose Fast Interpretable Greedy-Tree Sums (FIGS), which generalizes the CART algorithm to simultaneously grow a flexible number of trees in summation. By combining logical rules with addition, FIGS is able to adapt to additive structure while remaining highly interpretable. Extensive experiments on real-world datasets show that FIGS achieves state-of-the-art prediction performance. To demonstrate the usefulness of FIGS in high-stakes domains, we adapt FIGS to learn clinical decision instruments (CDIs), which are tools for guiding clinical decision-making. Specifically, we introduce a variant of FIGS known as G-FIGS that accounts for the 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24212;&#29992;&#20110;&#32852;&#37030;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#30340;&#26032;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#36873;&#25321;&#19968;&#32452;&#22522;&#30784;&#33218;&#26469;&#26368;&#22823;&#21270;&#36229;&#32423;&#33218;&#22870;&#21169;&#65292;&#24182;&#21516;&#26102;&#28385;&#36275;&#32452;&#22870;&#21169;&#32422;&#26463;&#12290;&#31639;&#27861;&#21033;&#29992;&#20004;&#36755;&#20986;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#20026;&#27599;&#20010;&#22522;&#30784;&#33218;&#30340;&#32467;&#26524;&#25552;&#20379;&#26356;&#22823;&#30340;&#28789;&#27963;&#24615;&#12290;</title><link>http://arxiv.org/abs/2111.14778</link><description>&lt;p&gt;
&#19978;&#19979;&#25991;&#32452;&#21512;&#22810;&#36755;&#20986; GP Bandits &#24102;&#26377;&#32452;&#32422;&#26463;
&lt;/p&gt;
&lt;p&gt;
Contextual Combinatorial Multi-output GP Bandits with Group Constraints. (arXiv:2111.14778v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.14778
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24212;&#29992;&#20110;&#32852;&#37030;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#30340;&#26032;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#36873;&#25321;&#19968;&#32452;&#22522;&#30784;&#33218;&#26469;&#26368;&#22823;&#21270;&#36229;&#32423;&#33218;&#22870;&#21169;&#65292;&#24182;&#21516;&#26102;&#28385;&#36275;&#32452;&#22870;&#21169;&#32422;&#26463;&#12290;&#31639;&#27861;&#21033;&#29992;&#20004;&#36755;&#20986;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#20026;&#27599;&#20010;&#22522;&#30784;&#33218;&#30340;&#32467;&#26524;&#25552;&#20379;&#26356;&#22823;&#30340;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32852;&#37030;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#20013;&#65292;&#26368;&#22823;&#21270;&#20840;&#23616;&#22870;&#21169;&#21516;&#26102;&#28385;&#36275;&#20445;&#25252;&#23458;&#25143;&#30340;&#26368;&#20302;&#38544;&#31169;&#35201;&#27714;&#26159;&#20027;&#35201;&#30446;&#26631;&#12290;&#20026;&#20102;&#24314;&#31435;&#36825;&#26679;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#20855;&#26377;&#32452;&#21644;&#21464;&#21270;&#21160;&#20316;&#38598;&#30340;&#32452;&#21512;&#19978;&#19979;&#25991;&#36172;&#21338;&#35774;&#23450;&#65292;&#20854;&#20013;&#30456;&#20284;&#30340;&#22522;&#30784;&#33218;&#20197;&#32452;&#30340;&#24418;&#24335;&#20986;&#29616;&#65292;&#24182;&#19988;&#24517;&#39035;&#22312;&#27599;&#19968;&#36718;&#36873;&#25321;&#19968;&#32452;&#22522;&#30784;&#33218;&#65288;&#31216;&#20026;&#36229;&#32423;&#33218;&#65289;&#65292;&#20197;&#26368;&#22823;&#21270;&#36229;&#32423;&#33218;&#30340;&#22870;&#21169;&#21516;&#26102;&#28385;&#36275;&#26469;&#33258;&#36873;&#25321;&#22522;&#30784;&#33218;&#30340;&#32452;&#30340;&#22870;&#21169;&#32422;&#26463;&#12290;&#20026;&#20102;&#22686;&#21152;&#28789;&#27963;&#24615;&#65292;&#25105;&#20204;&#35753;&#27599;&#20010;&#22522;&#30784;&#33218;&#20855;&#26377;&#20004;&#20010;&#32467;&#26524;&#65292;&#34987;&#24314;&#27169;&#20026;&#20004;&#36755;&#20986;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#30340;&#36755;&#20986;&#65292;&#20854;&#20013;&#19968;&#20010;&#32467;&#26524;&#29992;&#20110;&#35745;&#31639;&#36229;&#32423;&#33218;&#30340;&#22870;&#21169;&#65292;&#21478;&#19968;&#20010;&#29992;&#20110;&#32452;&#30340;&#22870;&#21169;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21452;-UCB GP-bandit &#31639;&#27861;&#65292;&#31216;&#20026;&#38408;&#20540;&#32452;&#21512;&#39640;&#26031;&#36807;&#31243;&#19978;&#32622;&#20449;&#36793;&#30028;&#65288;TCGP-UCB&#65289;&#65292;&#23427;&#22312;&#26368;&#22823;&#21270;&#32047;&#31215;&#36229;&#32423;&#33218;&#22870;&#21169;&#21644;&#28385;&#36275;&#32452;&#22870;&#21169;&#32422;&#26463;&#20043;&#38388;&#25214;&#21040;&#24179;&#34913;&#65292;&#24182;&#19988;&#21487;&#20197;&#35843;&#25972;&#20026;&#20559;&#22909;&#19968;&#26041;&#12290;
&lt;/p&gt;
&lt;p&gt;
In federated multi-armed bandit problems, maximizing global reward while satisfying minimum privacy requirements to protect clients is the main goal. To formulate such problems, we consider a combinatorial contextual bandit setting with groups and changing action sets, where similar base arms arrive in groups and a set of base arms, called a super arm, must be chosen in each round to maximize super arm reward while satisfying the constraints of the rewards of groups from which base arms were chosen. To allow for greater flexibility, we let each base arm have two outcomes, modeled as the output of a two-output Gaussian process (GP), where one outcome is used to compute super arm reward and the other for group reward. We then propose a novel double-UCB GP-bandit algorithm, called Thresholded Combinatorial Gaussian Process Upper Confidence Bounds (TCGP-UCB), which balances between maximizing cumulative super arm reward and satisfying group reward constraints and can be tuned to prefer one
&lt;/p&gt;</description></item><item><title>GFlowNets&#26159;&#19968;&#31181;&#29983;&#25104;&#27969;&#32593;&#32476;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20027;&#21160;&#23398;&#20064;&#29615;&#22659;&#20013;&#37319;&#26679;&#22810;&#26679;&#21270;&#30340;&#20505;&#36873;&#38598;&#12290;&#23427;&#20204;&#20855;&#26377;&#20272;&#35745;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#21644;&#36793;&#38469;&#20998;&#24067;&#30340;&#33021;&#21147;&#65292;&#21487;&#20197;&#34920;&#31034;&#20851;&#20110;&#22797;&#21512;&#23545;&#35937;&#65288;&#22914;&#38598;&#21512;&#21644;&#22270;&#65289;&#30340;&#20998;&#24067;&#12290;&#36890;&#36807;&#21333;&#27425;&#35757;&#32451;&#30340;&#29983;&#25104;&#20256;&#36882;&#65292;GFlowNets&#20998;&#25674;&#20102;&#35745;&#31639;&#26114;&#36149;&#30340;MCMC&#26041;&#27861;&#30340;&#24037;&#20316;&#12290;</title><link>http://arxiv.org/abs/2111.09266</link><description>&lt;p&gt;
GFlowNet&#22522;&#30784;
&lt;/p&gt;
&lt;p&gt;
GFlowNet Foundations. (arXiv:2111.09266v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.09266
&lt;/p&gt;
&lt;p&gt;
GFlowNets&#26159;&#19968;&#31181;&#29983;&#25104;&#27969;&#32593;&#32476;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20027;&#21160;&#23398;&#20064;&#29615;&#22659;&#20013;&#37319;&#26679;&#22810;&#26679;&#21270;&#30340;&#20505;&#36873;&#38598;&#12290;&#23427;&#20204;&#20855;&#26377;&#20272;&#35745;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#21644;&#36793;&#38469;&#20998;&#24067;&#30340;&#33021;&#21147;&#65292;&#21487;&#20197;&#34920;&#31034;&#20851;&#20110;&#22797;&#21512;&#23545;&#35937;&#65288;&#22914;&#38598;&#21512;&#21644;&#22270;&#65289;&#30340;&#20998;&#24067;&#12290;&#36890;&#36807;&#21333;&#27425;&#35757;&#32451;&#30340;&#29983;&#25104;&#20256;&#36882;&#65292;GFlowNets&#20998;&#25674;&#20102;&#35745;&#31639;&#26114;&#36149;&#30340;MCMC&#26041;&#27861;&#30340;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27969;&#32593;&#32476;&#65288;GFlowNets&#65289;&#34987;&#24341;&#20837;&#20026;&#22312;&#20027;&#21160;&#23398;&#20064;&#29615;&#22659;&#20013;&#37319;&#26679;&#22810;&#26679;&#21270;&#30340;&#20505;&#36873;&#38598;&#30340;&#26041;&#27861;&#65292;&#20854;&#35757;&#32451;&#30446;&#26631;&#20351;&#20854;&#36817;&#20284;&#25353;&#29031;&#32473;&#23450;&#30340;&#22870;&#21169;&#20989;&#25968;&#36827;&#34892;&#37319;&#26679;&#12290;&#26412;&#25991;&#23637;&#31034;&#20102;GFlowNets&#30340;&#19968;&#20123;&#39069;&#22806;&#30340;&#29702;&#35770;&#24615;&#36136;&#12290;&#23427;&#20204;&#21487;&#20197;&#29992;&#20110;&#20272;&#35745;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#21644;&#30456;&#24212;&#30340;&#36793;&#38469;&#20998;&#24067;&#65292;&#20854;&#20013;&#19968;&#20123;&#21464;&#37327;&#26410;&#25351;&#23450;&#65292;&#29305;&#21035;&#26159;&#21487;&#20197;&#34920;&#31034;&#20851;&#20110;&#22797;&#21512;&#23545;&#35937;&#65288;&#22914;&#38598;&#21512;&#21644;&#22270;&#65289;&#30340;&#20998;&#24067;&#12290;GFlowNets&#36890;&#36807;&#21333;&#27425;&#35757;&#32451;&#30340;&#29983;&#25104;&#20256;&#36882;&#26469;&#20998;&#25674;&#36890;&#24120;&#30001;&#35745;&#31639;&#26114;&#36149;&#30340;MCMC&#26041;&#27861;&#23436;&#25104;&#30340;&#24037;&#20316;&#12290;&#23427;&#20204;&#36824;&#21487;&#20197;&#29992;&#20110;&#20272;&#35745;&#20998;&#21306;&#20989;&#25968;&#21644;&#33258;&#30001;&#33021;&#65292;&#32473;&#23450;&#19968;&#20010;&#23376;&#38598;&#65288;&#23376;&#22270;&#65289;&#30340;&#36229;&#38598;&#65288;&#36229;&#22270;&#65289;&#30340;&#26465;&#20214;&#27010;&#29575;&#65292;&#20197;&#21450;&#32473;&#23450;&#19968;&#20010;&#38598;&#21512;&#65288;&#22270;&#65289;&#30340;&#25152;&#26377;&#36229;&#38598;&#65288;&#36229;&#22270;&#65289;&#30340;&#36793;&#38469;&#20998;&#24067;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20123;&#21464;&#20307;&#65292;&#20351;&#24471;&#21487;&#20197;&#20272;&#35745;&#29109;&#30340;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative Flow Networks (GFlowNets) have been introduced as a method to sample a diverse set of candidates in an active learning context, with a training objective that makes them approximately sample in proportion to a given reward function. In this paper, we show a number of additional theoretical properties of GFlowNets. They can be used to estimate joint probability distributions and the corresponding marginal distributions where some variables are unspecified and, of particular interest, can represent distributions over composite objects like sets and graphs. GFlowNets amortize the work typically done by computationally expensive MCMC methods in a single but trained generative pass. They could also be used to estimate partition functions and free energies, conditional probabilities of supersets (supergraphs) given a subset (subgraph), as well as marginal distributions over all supersets (supergraphs) of a given set (graph). We introduce variations enabling the estimation of entro
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#21644;&#31232;&#30095;&#19987;&#23478;&#28151;&#21512;&#30340;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;E$^3$&#30340;&#39640;&#25928;&#31232;&#30095;MoEs&#38598;&#25104;&#26041;&#27861;&#65292;&#22312;&#20943;&#23569;&#35745;&#31639;&#22797;&#26434;&#24230;&#30340;&#21516;&#26102;&#21462;&#24471;&#20102;&#22312;&#20934;&#30830;&#24615;&#12289;&#40065;&#26834;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#26041;&#38754;&#30340;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2110.03360</link><description>&lt;p&gt;
&#31232;&#30095;MoEs&#28385;&#36275;&#39640;&#25928;&#30340;&#27169;&#22411;&#38598;&#25104;
&lt;/p&gt;
&lt;p&gt;
Sparse MoEs meet Efficient Ensembles. (arXiv:2110.03360v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.03360
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#21644;&#31232;&#30095;&#19987;&#23478;&#28151;&#21512;&#30340;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;E$^3$&#30340;&#39640;&#25928;&#31232;&#30095;MoEs&#38598;&#25104;&#26041;&#27861;&#65292;&#22312;&#20943;&#23569;&#35745;&#31639;&#22797;&#26434;&#24230;&#30340;&#21516;&#26102;&#21462;&#24471;&#20102;&#22312;&#20934;&#30830;&#24615;&#12289;&#40065;&#26834;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#26041;&#38754;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#23376;&#27169;&#22411;&#30340;&#32858;&#21512;&#36755;&#20986;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#26080;&#35770;&#26159;&#22312;&#28608;&#27963;&#36824;&#26159;&#39044;&#27979;&#27700;&#24179;&#19978;&#65292;&#24448;&#24448;&#30456;&#23545;&#20110;&#21333;&#20010;&#27169;&#22411;&#26174;&#31034;&#20986;&#24456;&#24378;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#31181;&#27969;&#34892;&#27169;&#22411;&#30340;&#30456;&#20114;&#20316;&#29992;&#65306;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#21644;&#31232;&#30095;&#19987;&#23478;&#28151;&#21512;&#65288;&#31232;&#30095;MoEs&#65289;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20004;&#31181;&#26041;&#27861;&#20855;&#26377;&#20114;&#34917;&#30340;&#29305;&#28857;&#65292;&#23427;&#20204;&#30340;&#32467;&#21512;&#26159;&#26377;&#30410;&#30340;&#12290;&#36825;&#21253;&#25324;&#23545;&#31232;&#30095;MoEs&#22312;&#19981;&#30830;&#23450;&#24615;&#30456;&#20851;&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;&#20840;&#38754;&#35780;&#20272;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#39640;&#25928;&#30340;&#19987;&#23478;&#38598;&#25104;&#65288;E$^3$&#65289;&#65292;&#19968;&#31181;&#21487;&#25193;&#23637;&#19988;&#31616;&#21333;&#30340;&#31232;&#30095;MoEs&#38598;&#25104;&#26041;&#27861;&#65292;&#23427;&#20860;&#20855;&#20004;&#31867;&#27169;&#22411;&#30340;&#20248;&#28857;&#65292;&#21516;&#26102;&#20351;&#29992;&#30340;&#28014;&#28857;&#36816;&#31639;&#65288;FLOPs&#65289;&#27604;&#28145;&#24230;&#38598;&#25104;&#23569;&#22810;&#36798;45&#65285;&#12290;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;E$^3$&#22312;&#22810;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22522;&#20110;Transformer&#30340;&#35270;&#35273;&#22522;&#32447;&#27169;&#22411;&#19978;&#30340;&#20934;&#30830;&#24615;&#12289;&#23545;&#25968;&#20284;&#28982;&#12289;&#23569;&#26679;&#26412;&#23398;&#20064;&#12289;&#40065;&#26834;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#25913;&#36827;&#12290;E$^3$&#22312;&#25193;&#23637;&#21040;&#20855;&#26377;&#39640;&#36798;27&#20159;&#21442;&#25968;&#30340;&#27169;&#22411;&#26102;&#19981;&#20165;&#20445;&#25345;&#20854;&#25928;&#29575;&#65292;&#32780;&#19988;&#36824;&#33021;&#25552;&#20379;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning models based on the aggregated outputs of submodels, either at the activation or prediction levels, often exhibit strong performance compared to individual models. We study the interplay of two popular classes of such models: ensembles of neural networks and sparse mixture of experts (sparse MoEs). First, we show that the two approaches have complementary features whose combination is beneficial. This includes a comprehensive evaluation of sparse MoEs in uncertainty related benchmarks. Then, we present Efficient Ensemble of Experts (E$^3$), a scalable and simple ensemble of sparse MoEs that takes the best of both classes of models, while using up to 45% fewer FLOPs than a deep ensemble. Extensive experiments demonstrate the accuracy, log-likelihood, few-shot learning, robustness, and uncertainty improvements of E$^3$ over several challenging vision Transformer-based baselines. E$^3$ not only preserves its efficiency while scaling to models with up to 2.7B parameters, b
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;Riemannian Gauss-Newton&#26041;&#27861;&#36827;&#34892;&#20302;&#31209;&#24352;&#37327;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#22312;&#22122;&#22768;&#29615;&#22659;&#19979;&#30340;&#23616;&#37096;&#20108;&#27425;&#25910;&#25947;&#24615;&#21644;&#32479;&#35745;&#26368;&#20248;&#24615;&#12290;</title><link>http://arxiv.org/abs/2104.12031</link><description>&lt;p&gt;
&#36890;&#36807;Riemannian Gauss-Newton&#36827;&#34892;&#20302;&#31209;&#24352;&#37327;&#20272;&#35745;&#65306;&#32479;&#35745;&#26368;&#20248;&#24615;&#21644;&#20108;&#38454;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Low-rank Tensor Estimation via Riemannian Gauss-Newton: Statistical Optimality and Second-Order Convergence. (arXiv:2104.12031v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2104.12031
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;Riemannian Gauss-Newton&#26041;&#27861;&#36827;&#34892;&#20302;&#31209;&#24352;&#37327;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#22312;&#22122;&#22768;&#29615;&#22659;&#19979;&#30340;&#23616;&#37096;&#20108;&#27425;&#25910;&#25947;&#24615;&#21644;&#32479;&#35745;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20174;&#19968;&#31995;&#21015;&#26377;&#22122;&#32447;&#24615;&#27979;&#37327;&#20013;&#20272;&#35745;&#20302;Tucker&#31209;&#24352;&#37327;&#30340;&#38382;&#39064;&#12290;&#35813;&#38382;&#39064;&#28085;&#30422;&#20102;&#35768;&#22810;&#20855;&#20307;&#30340;&#24212;&#29992;&#31034;&#20363;&#65292;&#21253;&#25324;&#24352;&#37327;&#22238;&#24402;&#12289;&#24352;&#37327;&#34917;&#20840;&#21644;&#24352;&#37327;PCA / SVD&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;Riemannian Gauss-Newton&#65288;RGN&#65289;&#26041;&#27861;&#26469;&#20272;&#35745;&#20302;Tucker&#31209;&#24352;&#37327;&#12290;&#19982;&#25991;&#29486;&#20013;&#23545;RGN&#30340;&#65288;&#36229;&#65289;&#32447;&#24615;&#25910;&#25947;&#20445;&#35777;&#19981;&#21516;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#22122;&#22768;&#29615;&#22659;&#19979;RGN&#22312;&#20302;&#31209;&#24352;&#37327;&#20272;&#35745;&#20013;&#30340;&#31532;&#19968;&#31181;&#23616;&#37096;&#20108;&#27425;&#25910;&#25947;&#20445;&#35777;&#65292;&#24182;&#25552;&#20379;&#30456;&#24212;&#30340;&#20272;&#35745;&#35823;&#24046;&#19978;&#30028;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#30830;&#23450;&#24615;&#20272;&#35745;&#35823;&#24046;&#19979;&#30028;&#65292;&#35813;&#19979;&#30028;&#19982;&#19978;&#30028;&#30456;&#21305;&#37197;&#65292;&#35777;&#26126;&#20102;RGN&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#20004;&#20010;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#65288;&#24352;&#37327;&#22238;&#24402;&#21644;&#24352;&#37327;SVD&#65289;&#26469;&#35828;&#26126;RGN&#30340;&#20248;&#28857;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#27169;&#25311;&#32467;&#26524;&#26469;&#35777;&#23454;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider the estimation of a low Tucker rank tensor from a number of noisy linear measurements. The general problem covers many specific examples arising from applications, including tensor regression, tensor completion, and tensor PCA/SVD. We consider an efficient Riemannian Gauss-Newton (RGN) method for low Tucker rank tensor estimation. Different from the generic (super)linear convergence guarantee of RGN in the literature, we prove the first local quadratic convergence guarantee of RGN for low-rank tensor estimation in the noisy setting under some regularity conditions and provide the corresponding estimation error upper bounds. A deterministic estimation error lower bound, which matches the upper bound, is provided that demonstrates the statistical optimality of RGN. The merit of RGN is illustrated through two machine learning applications: tensor regression and tensor SVD. Finally, we provide the simulation results to corroborate our theoretical findings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#33258;&#32467;&#26500;&#37325;&#35201;&#24615;&#37319;&#26679;&#26041;&#27861;&#65292;&#36890;&#36807;&#22797;&#21046;&#22312;&#36739;&#19981;&#32597;&#35265;&#30340;&#26679;&#26412;&#20013;&#35266;&#23519;&#21040;&#30340;&#27987;&#24230;&#29305;&#24615;&#65292;&#38544;&#24335;&#35825;&#23548;&#20986;&#19968;&#31181;&#26377;&#25928;&#30340;IS&#20998;&#24067;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#20272;&#35745;&#24615;&#33021;&#24230;&#37327;&#30340;&#20998;&#24067;&#23614;&#37096;&#30340;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2102.07060</link><description>&lt;p&gt;
&#20351;&#29992;&#33258;&#32467;&#26500;&#37325;&#35201;&#24615;&#37319;&#26679;&#23454;&#29616;&#40657;&#30418;&#27169;&#25311;&#20998;&#24067;&#23614;&#37096;&#30340;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;
Achieving Efficiency in Black Box Simulation of Distribution Tails with Self-structuring Importance Samplers. (arXiv:2102.07060v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.07060
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#33258;&#32467;&#26500;&#37325;&#35201;&#24615;&#37319;&#26679;&#26041;&#27861;&#65292;&#36890;&#36807;&#22797;&#21046;&#22312;&#36739;&#19981;&#32597;&#35265;&#30340;&#26679;&#26412;&#20013;&#35266;&#23519;&#21040;&#30340;&#27987;&#24230;&#29305;&#24615;&#65292;&#38544;&#24335;&#35825;&#23548;&#20986;&#19968;&#31181;&#26377;&#25928;&#30340;IS&#20998;&#24067;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#20272;&#35745;&#24615;&#33021;&#24230;&#37327;&#30340;&#20998;&#24067;&#23614;&#37096;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#37325;&#35201;&#24615;&#37319;&#26679;&#65288;IS&#65289;&#26041;&#26696;&#65292;&#29992;&#20110;&#20272;&#35745;&#37319;&#29992;&#20016;&#23500;&#24037;&#20855;&#27169;&#25311;&#30340;&#24615;&#33021;&#24230;&#37327;&#30340;&#20998;&#24067;&#23614;&#37096;&#65292;&#36825;&#20123;&#24037;&#20855;&#21253;&#25324;&#32447;&#24615;&#35268;&#21010;&#12289;&#25972;&#25968;&#32447;&#24615;&#35268;&#21010;&#12289;&#20998;&#27573;&#32447;&#24615;/&#20108;&#27425;&#30446;&#26631;&#12289;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25351;&#23450;&#30340;&#29305;&#24449;&#26144;&#23556;&#31561;&#12290;&#20256;&#32479;&#30340;&#26126;&#30830;&#35782;&#21035;&#26377;&#25928;&#30340;&#27979;&#24230;&#21464;&#21270;&#30340;&#26041;&#27861;&#22312;&#39640;&#24230;&#26684;&#24335;&#21270;&#30340;&#27169;&#22411;&#20043;&#22806;&#21463;&#21040;&#21487;&#34892;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#30340;&#38480;&#21046;&#65292;&#22240;&#20026;&#23427;&#20204;&#38656;&#35201;&#19982;&#30446;&#26631;&#21644;&#27010;&#29575;&#20998;&#24067;&#31934;&#24515;&#35843;&#25972;&#12290;&#22312;&#25152;&#25552;&#20986;&#30340;&#26041;&#26696;&#20013;&#65292;&#36890;&#36807;&#19968;&#31181;&#22522;&#26412;&#36716;&#25442;&#20811;&#26381;&#20102;&#36825;&#20010;&#29942;&#39048;&#65292;&#35813;&#36716;&#25442;&#21487;&#20197;&#36890;&#36807;&#22797;&#21046;&#22312;&#36739;&#19981;&#32597;&#35265;&#30340;&#26679;&#26412;&#20013;&#35266;&#23519;&#21040;&#30340;&#27987;&#24230;&#29305;&#24615;&#26469;&#22312;&#21508;&#31181;&#27169;&#22411;&#20013;&#38544;&#24335;&#35825;&#23548;&#20986;&#19968;&#20010;&#26377;&#25928;&#30340;IS&#20998;&#24067;&#12290;&#36825;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26159;&#36890;&#36807;&#21457;&#23637;&#19968;&#20010;&#22823;&#20559;&#24046;&#21407;&#29702;&#26469;&#25351;&#23548;&#30340;&#65292;&#36825;&#31181;&#21407;&#29702;&#25581;&#31034;&#20102;&#26368;&#20248;IS&#20998;&#24067;&#30340;&#33258;&#30456;&#20284;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a novel Importance Sampling (IS) scheme for estimating distribution tails of performance measures modeled with a rich set of tools such as linear programs, integer linear programs, piecewise linear/quadratic objectives, feature maps specified with deep neural networks, etc. The conventional approach of explicitly identifying efficient changes of measure suffers from feasibility and scalability concerns beyond highly stylized models, due to their need to be tailored intricately to the objective and the underlying probability distribution. This bottleneck is overcome in the proposed scheme with an elementary transformation which is capable of implicitly inducing an effective IS distribution in a variety of models by replicating the concentration properties observed in less rare samples. This novel approach is guided by developing a large deviations principle that brings out the phenomenon of self-similarity of optimal IS distributions. The proposed sampler is the firs
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#26641;&#25552;&#21319;&#31639;&#27861;&#65292;&#36890;&#36807;&#25311;&#21512;&#21472;&#21152;&#26641;&#38598;&#21512;&#26469;&#25512;&#26029;&#29420;&#31435;&#21516;&#20998;&#24067;&#26679;&#26412;&#30340;&#28508;&#22312;&#37319;&#26679;&#20998;&#24067;&#65292;&#20854;&#20013;&#20851;&#38190;&#26159;&#24341;&#20837;&#20102;&#26032;&#30340;&#27010;&#29575;&#20998;&#24067;&#19978;&#30340;"&#21152;&#27861;"&#27010;&#24565;&#21644;&#19982;&#20043;&#30456;&#23545;&#24212;&#30340;"&#21097;&#20313;&#21270;"&#25805;&#20316;&#12290;&#36825;&#20123;&#27010;&#24565;&#36890;&#36807;&#19968;&#32500;&#32047;&#31215;&#20998;&#24067;&#20989;&#25968;&#65288;CDF&#65289;&#21464;&#25442;&#21644;&#32452;&#21512;&#33258;&#28982;&#32780;&#28982;&#22320;&#20986;&#29616;&#65292;&#24182;&#25193;&#23637;&#21040;&#20102;&#22810;&#20803;&#35774;&#32622;&#20013;&#12290;</title><link>http://arxiv.org/abs/2101.11083</link><description>&lt;p&gt;
&#26080;&#30417;&#30563;&#26641;&#25552;&#21319;&#23398;&#20064;&#27010;&#29575;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Unsupervised tree boosting for learning probability distributions. (arXiv:2101.11083v7 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2101.11083
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#26641;&#25552;&#21319;&#31639;&#27861;&#65292;&#36890;&#36807;&#25311;&#21512;&#21472;&#21152;&#26641;&#38598;&#21512;&#26469;&#25512;&#26029;&#29420;&#31435;&#21516;&#20998;&#24067;&#26679;&#26412;&#30340;&#28508;&#22312;&#37319;&#26679;&#20998;&#24067;&#65292;&#20854;&#20013;&#20851;&#38190;&#26159;&#24341;&#20837;&#20102;&#26032;&#30340;&#27010;&#29575;&#20998;&#24067;&#19978;&#30340;"&#21152;&#27861;"&#27010;&#24565;&#21644;&#19982;&#20043;&#30456;&#23545;&#24212;&#30340;"&#21097;&#20313;&#21270;"&#25805;&#20316;&#12290;&#36825;&#20123;&#27010;&#24565;&#36890;&#36807;&#19968;&#32500;&#32047;&#31215;&#20998;&#24067;&#20989;&#25968;&#65288;CDF&#65289;&#21464;&#25442;&#21644;&#32452;&#21512;&#33258;&#28982;&#32780;&#28982;&#22320;&#20986;&#29616;&#65292;&#24182;&#25193;&#23637;&#21040;&#20102;&#22810;&#20803;&#35774;&#32622;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#26641;&#25552;&#21319;&#31639;&#27861;&#65292;&#29992;&#20110;&#26681;&#25454;&#25311;&#21512;&#21472;&#21152;&#26641;&#38598;&#21512;&#26469;&#25512;&#26029;&#29420;&#31435;&#21516;&#20998;&#24067;&#26679;&#26412;&#30340;&#28508;&#22312;&#37319;&#26679;&#20998;&#24067;&#65292;&#20854;&#31867;&#20284;&#20110;&#30417;&#30563;&#26641;&#25552;&#21319;&#12290;&#35813;&#31639;&#27861;&#30340;&#26680;&#24515;&#26159;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#20998;&#24067;&#19978;&#30340;"&#21152;&#27861;"&#27010;&#24565;&#65292;&#35813;&#27010;&#24565;&#24341;&#20986;&#20102;"&#21097;&#20313;&#21270;"&#30340;&#19968;&#33268;&#27010;&#24565;&#65292;&#21363;&#20174;&#35266;&#27979;&#20013;&#20943;&#21435;&#27010;&#29575;&#20998;&#24067;&#65292;&#20197;&#28040;&#38500;&#21518;&#32773;&#30340;&#37319;&#26679;&#20998;&#24067;&#20013;&#30340;&#20998;&#24067;&#32467;&#26500;&#12290;&#25105;&#20204;&#36890;&#36807;&#32047;&#31215;&#20998;&#24067;&#20989;&#25968;&#65288;CDF&#65289;&#21464;&#25442;&#21644;&#32452;&#21512;&#23637;&#31034;&#20102;&#36825;&#20123;&#27010;&#24565;&#22312;&#19968;&#32500;&#20998;&#24067;&#20013;&#30340;&#33258;&#28982;&#20986;&#29616;&#65292;&#30001;&#20110;&#19968;&#32500;CDF&#30340;&#20960;&#20010;"&#31867;&#20284;&#32676;&#20307;"&#23646;&#24615;&#12290;&#34429;&#28982;&#20256;&#32479;&#30340;&#22810;&#20803;CDF&#19981;&#20445;&#30041;&#36825;&#20123;&#23646;&#24615;&#65292;&#20294;&#26032;&#30340;&#22810;&#20803;CDF&#23450;&#20041;&#21487;&#20197;&#24674;&#22797;&#36825;&#20123;&#23646;&#24615;&#65292;&#20174;&#32780;&#20351;"&#21152;&#27861;"&#21644;"&#21097;&#20313;&#21270;"&#30340;&#27010;&#24565;&#20063;&#21487;&#20197;&#22312;&#22810;&#20803;&#35774;&#32622;&#20013;&#24471;&#21040;&#35268;&#33539;&#12290;&#36825;&#26679;&#23601;&#20135;&#29983;&#20102;
&lt;/p&gt;
&lt;p&gt;
We propose an unsupervised tree boosting algorithm for inferring the underlying sampling distribution of an i.i.d. sample based on fitting additive tree ensembles in a fashion analogous to supervised tree boosting. Integral to the algorithm is a new notion of "addition" on probability distributions that leads to a coherent notion of "residualization", i.e., subtracting a probability distribution from an observation to remove the distributional structure from the sampling distribution of the latter. We show that these notions arise naturally for univariate distributions through cumulative distribution function (CDF) transforms and compositions due to several "group-like" properties of univariate CDFs. While the traditional multivariate CDF does not preserve these properties, a new definition of multivariate CDF can restore these properties, thereby allowing the notions of "addition" and "residualization" to be formulated for multivariate settings as well. This then gives rise to the uns
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#32467;&#26500;&#21270;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#22312;&#23384;&#22312;&#32467;&#26500;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#65292;&#35774;&#35745;&#20102;&#19968;&#31181;&#33021;&#22815;&#21033;&#29992;&#32467;&#26500;&#20449;&#24687;&#20197;&#26368;&#23567;&#21270;&#21518;&#24724;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2007.07302</link><description>&lt;p&gt;
&#32467;&#26500;&#21270;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#26368;&#20248;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Optimal Learning for Structured Bandits. (arXiv:2007.07302v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2007.07302
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32467;&#26500;&#21270;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#22312;&#23384;&#22312;&#32467;&#26500;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#65292;&#35774;&#35745;&#20102;&#19968;&#31181;&#33021;&#22815;&#21033;&#29992;&#32467;&#26500;&#20449;&#24687;&#20197;&#26368;&#23567;&#21270;&#21518;&#24724;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32467;&#26500;&#21270;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#21363;&#22312;&#23384;&#22312;&#32467;&#26500;&#20449;&#24687;&#30340;&#19981;&#30830;&#23450;&#24615;&#29615;&#22659;&#19979;&#36827;&#34892;&#22312;&#32447;&#20915;&#31574;&#12290;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#20915;&#31574;&#32773;&#38656;&#35201;&#22312;&#35266;&#23519;&#21040;&#19981;&#30830;&#23450;&#30340;&#22870;&#21169;&#38543;&#26102;&#38388;&#21464;&#21270;&#26102;&#25214;&#20986;&#26368;&#20339;&#34892;&#21160;&#26041;&#38024;&#12290;&#20915;&#31574;&#32773;&#24050;&#32463;&#20102;&#35299;&#21040;&#22870;&#21169;&#20998;&#24067;&#23646;&#20110;&#19968;&#20010;&#20984;&#32039;&#33268;&#38598;&#21512;&#30340;&#26576;&#31181;&#20984;&#32467;&#26500;&#20449;&#24687;&#12290;&#22312;&#26377;&#36825;&#31181;&#32467;&#26500;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#65292;&#20915;&#31574;&#32773;&#24076;&#26395;&#36890;&#36807;&#21033;&#29992;&#36825;&#20123;&#20449;&#24687;&#26469;&#26368;&#23567;&#21270;&#21518;&#24724;&#65288;&#19982;&#25552;&#21069;&#30693;&#36947;&#26368;&#20339;&#34892;&#21160;&#30340;&#22522;&#20934;&#31574;&#30053;&#30456;&#27604;&#30340;&#24615;&#33021;&#24046;&#24322;&#65289;&#12290;&#22312;&#27809;&#26377;&#32467;&#26500;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#65292;&#32463;&#20856;&#30340;&#19978;&#30028;&#32622;&#20449;&#21306;&#38388;&#65288;UCB&#65289;&#21644;&#27748;&#22982;&#36874;&#21462;&#26679;&#31639;&#27861;&#24050;&#34987;&#35777;&#26126;&#20855;&#26377;&#26368;&#23567;&#21518;&#24724;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#25351;&#20986;&#65292;&#36825;&#20004;&#31181;&#31639;&#27861;&#37117;&#26080;&#27861;&#21033;&#29992;&#22797;&#26434;&#32467;&#26500;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study structured multi-armed bandits, which is the problem of online decision-making under uncertainty in the presence of structural information. In this problem, the decision-maker needs to discover the best course of action despite observing only uncertain rewards over time. The decision-maker is aware of certain convex structural information regarding the reward distributions; that is, the decision-maker knows the reward distributions of the arms belong to a convex compact set. In the presence such structural information, they then would like to minimize their regret by exploiting this information, where the regret is its performance difference against a benchmark policy that knows the best action ahead of time. In the absence of structural information, the classical upper confidence bound (UCB) and Thomson sampling algorithms are well known to suffer minimal regret. As recently pointed out, neither algorithms are, however, capable of exploiting structural information that is com
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;18&#31181;&#26032;&#30340;&#23545;&#25239;&#25915;&#20987;&#65292;&#24182;&#20351;&#29992;&#36825;&#20123;&#25915;&#20987;&#21019;&#24314;&#20102;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#23545;&#21508;&#31181;&#26410;&#39044;&#26009;&#21040;&#30340;&#23545;&#25163;&#30340;&#40065;&#26834;&#24615;&#30340;&#26032;&#22522;&#20934;&#12290;&#20316;&#32773;&#36824;&#21457;&#29616;&#20102;&#19968;&#31995;&#21015;&#38450;&#24481;&#31574;&#30053;&#65292;&#21487;&#20197;&#24110;&#21161;&#20811;&#26381;&#35757;&#32451;&#26399;&#38388;&#26410;&#32771;&#34385;&#21040;&#30340;&#23545;&#25163;&#30340;&#27867;&#21270;&#24046;&#36317;&#12290;&#35813;&#30740;&#31350;&#30340;&#32467;&#26524;&#23558;&#20026;&#30740;&#31350;&#29616;&#23454;&#19990;&#30028;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#40065;&#26834;&#24615;&#25552;&#20379;&#26377;&#29992;&#24037;&#20855;&#65292;&#20419;&#36827;&#24320;&#21457;&#26356;&#24378;&#22823;&#30340;&#38450;&#24481;&#25514;&#26045;&#12290;</title><link>http://arxiv.org/abs/1908.08016</link><description>&lt;p&gt;
&#38024;&#23545;&#26410;&#39044;&#26009;&#21040;&#30340;&#23545;&#25163;&#27979;&#35797;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Testing Robustness Against Unforeseen Adversaries. (arXiv:1908.08016v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1908.08016
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;18&#31181;&#26032;&#30340;&#23545;&#25239;&#25915;&#20987;&#65292;&#24182;&#20351;&#29992;&#36825;&#20123;&#25915;&#20987;&#21019;&#24314;&#20102;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#23545;&#21508;&#31181;&#26410;&#39044;&#26009;&#21040;&#30340;&#23545;&#25163;&#30340;&#40065;&#26834;&#24615;&#30340;&#26032;&#22522;&#20934;&#12290;&#20316;&#32773;&#36824;&#21457;&#29616;&#20102;&#19968;&#31995;&#21015;&#38450;&#24481;&#31574;&#30053;&#65292;&#21487;&#20197;&#24110;&#21161;&#20811;&#26381;&#35757;&#32451;&#26399;&#38388;&#26410;&#32771;&#34385;&#21040;&#30340;&#23545;&#25163;&#30340;&#27867;&#21270;&#24046;&#36317;&#12290;&#35813;&#30740;&#31350;&#30340;&#32467;&#26524;&#23558;&#20026;&#30740;&#31350;&#29616;&#23454;&#19990;&#30028;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#40065;&#26834;&#24615;&#25552;&#20379;&#26377;&#29992;&#24037;&#20855;&#65292;&#20419;&#36827;&#24320;&#21457;&#26356;&#24378;&#22823;&#30340;&#38450;&#24481;&#25514;&#26045;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32771;&#34385;&#29616;&#23454;&#19990;&#30028;&#30340;&#23545;&#25239;&#29615;&#22659;&#26102;&#65292;&#38450;&#24481;&#32773;&#22312;&#35757;&#32451;&#26399;&#38388;&#19981;&#22826;&#21487;&#33021;&#23545;&#25152;&#26377;&#21487;&#33021;&#30340;&#23545;&#25163;&#36827;&#34892;&#35757;&#32451;&#65292;&#24182;&#19988;&#23545;&#25163;&#24456;&#21487;&#33021;&#20351;&#29992;&#36924;&#30495;&#30340;&#23545;&#25239;&#25197;&#26354;&#65292;&#32780;&#19981;&#38480;&#20110;&#23567;&#30340;L_p&#32422;&#26463;&#25200;&#21160;&#12290;&#20026;&#20102;&#32553;&#23567;&#30740;&#31350;&#21644;&#29616;&#23454;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;18&#31181;&#26032;&#30340;&#23545;&#25239;&#25915;&#20987;&#65292;&#24182;&#20351;&#29992;&#23427;&#20204;&#21019;&#24314;&#20102;ImageNet-UA&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#27169;&#22411;&#23545;&#21508;&#31181;&#26410;&#39044;&#26009;&#21040;&#30340;&#23545;&#25163;&#30340;&#40065;&#26834;&#24615;&#30340;&#26032;&#22522;&#20934;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20010;&#22522;&#20934;&#26469;&#35782;&#21035;&#19968;&#31995;&#21015;&#33021;&#22815;&#24110;&#21161;&#20811;&#26381;&#36825;&#31181;&#27867;&#21270;&#24046;&#36317;&#30340;&#38450;&#24481;&#31574;&#30053;&#65292;&#21457;&#29616;&#20102;&#21487;&#20197;&#25552;&#39640;&#23545;&#26410;&#39044;&#26009;&#21040;&#30340;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#30340;&#25216;&#26415;&#30340;&#20016;&#23500;&#31354;&#38388;&#12290;&#25105;&#20204;&#24076;&#26395;ImageNet-UA&#30340;&#26356;&#22810;&#26679;&#24615;&#21644;&#36924;&#30495;&#24615;&#23558;&#25104;&#20026;&#37027;&#20123;&#30740;&#31350;&#29616;&#23454;&#19990;&#30028;&#26368;&#22351;&#24773;&#20917;&#30340;&#40065;&#26834;&#24615;&#30340;&#20154;&#30340;&#26377;&#29992;&#24037;&#20855;&#65292;&#20174;&#32780;&#20419;&#36827;&#24320;&#21457;&#33021;&#22815;&#22312;&#35757;&#32451;&#26399;&#38388;&#30475;&#19981;&#21040;&#30340;&#25915;&#20987;&#20013;&#36827;&#34892;&#27867;&#21270;&#30340;&#26356;&#24378;&#22823;&#30340;&#38450;&#24481;&#25514;&#26045;&#12290;
&lt;/p&gt;
&lt;p&gt;
When considering real-world adversarial settings, defenders are unlikely to have access to the full range of deployment-time adversaries during training, and adversaries are likely to use realistic adversarial distortions that will not be limited to small L_p-constrained perturbations. To narrow in on this discrepancy between research and reality we introduce eighteen novel adversarial attacks, which we use to create ImageNet-UA, a new benchmark for evaluating model robustness against a wide range of unforeseen adversaries. We make use of our benchmark to identify a range of defense strategies which can help overcome this generalization gap, finding a rich space of techniques which can improve unforeseen robustness. We hope the greater variety and realism of ImageNet-UA will make it a useful tool for those working on real-world worst-case robustness, enabling development of more robust defenses which can generalize beyond attacks seen during training.
&lt;/p&gt;</description></item></channel></rss>