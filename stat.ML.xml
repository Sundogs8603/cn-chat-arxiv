<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;SE(3)&#27969;&#21305;&#37197;&#30340;&#22270;&#26696;&#25903;&#26550;&#26041;&#27861;&#65292;&#36890;&#36807;&#22270;&#26696;&#25674;&#38144;&#21644;&#22270;&#26696;&#24341;&#23548;&#20004;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#29983;&#25104;&#32467;&#26500;&#19978;&#22810;&#26679;&#24615;&#26356;&#39640;&#30340;&#25903;&#26550;&#65292;&#19982;&#20043;&#21069;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#30456;&#27604;&#65292;&#25104;&#21151;&#29575;&#30456;&#24403;&#29978;&#33267;&#26356;&#39640;&#12290;</title><link>http://arxiv.org/abs/2401.04082</link><description>&lt;p&gt;
&#20351;&#29992;SE(3)&#27969;&#21305;&#37197;&#25913;&#36827;&#20102;&#22270;&#26696;&#25903;&#26550;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Improved motif-scaffolding with SE(3) flow matching. (arXiv:2401.04082v1 [q-bio.QM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04082
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;SE(3)&#27969;&#21305;&#37197;&#30340;&#22270;&#26696;&#25903;&#26550;&#26041;&#27861;&#65292;&#36890;&#36807;&#22270;&#26696;&#25674;&#38144;&#21644;&#22270;&#26696;&#24341;&#23548;&#20004;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#29983;&#25104;&#32467;&#26500;&#19978;&#22810;&#26679;&#24615;&#26356;&#39640;&#30340;&#25903;&#26550;&#65292;&#19982;&#20043;&#21069;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#30456;&#27604;&#65292;&#25104;&#21151;&#29575;&#30456;&#24403;&#29978;&#33267;&#26356;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34507;&#30333;&#36136;&#35774;&#35745;&#36890;&#24120;&#20174;&#19968;&#20010;&#22270;&#26696;&#30340;&#26399;&#26395;&#21151;&#33021;&#24320;&#22987;&#65292;&#22270;&#26696;&#25903;&#26550;&#26088;&#22312;&#26500;&#24314;&#19968;&#20010;&#21151;&#33021;&#24615;&#34507;&#30333;&#36136;&#12290;&#26368;&#36817;&#65292;&#29983;&#25104;&#27169;&#22411;&#22312;&#35774;&#35745;&#21508;&#31181;&#22270;&#26696;&#30340;&#25903;&#26550;&#26041;&#38754;&#21462;&#24471;&#20102;&#31361;&#30772;&#24615;&#30340;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#29983;&#25104;&#30340;&#25903;&#26550;&#24448;&#24448;&#32570;&#20047;&#32467;&#26500;&#22810;&#26679;&#24615;&#65292;&#36825;&#21487;&#33021;&#20250;&#24433;&#21709;&#28287;&#23454;&#39564;&#39564;&#35777;&#30340;&#25104;&#21151;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;FrameFlow&#65292;&#19968;&#31181;&#29992;&#20110;&#34507;&#30333;&#36136;&#20027;&#38142;&#29983;&#25104;&#30340;SE(3)&#27969;&#21305;&#37197;&#27169;&#22411;&#25193;&#23637;&#21040;&#20351;&#29992;&#20004;&#31181;&#20114;&#34917;&#30340;&#26041;&#27861;&#36827;&#34892;&#22270;&#26696;&#25903;&#26550;&#12290;&#31532;&#19968;&#31181;&#26041;&#27861;&#26159;&#22270;&#26696;&#25674;&#38144;&#65292;&#21363;&#20351;&#29992;&#25968;&#25454;&#22686;&#24378;&#31574;&#30053;&#65292;&#23558;FrameFlow&#35757;&#32451;&#20026;&#20197;&#22270;&#26696;&#20026;&#36755;&#20837;&#12290;&#31532;&#20108;&#31181;&#26041;&#27861;&#26159;&#22270;&#26696;&#24341;&#23548;&#65292;&#23427;&#20351;&#29992;FrameFlow&#30340;&#26465;&#20214;&#20998;&#25968;&#20272;&#35745;&#36827;&#34892;&#25903;&#26550;&#26500;&#24314;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#35757;&#32451;&#12290;&#36825;&#20004;&#31181;&#26041;&#27861;&#30340;&#25104;&#21151;&#29575;&#19982;&#20043;&#21069;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#30456;&#24403;&#25110;&#26356;&#39640;&#65292;&#24182;&#19988;&#21487;&#20197;&#20135;&#29983;&#32467;&#26500;&#19978;&#22810;&#26679;&#24615;&#26356;&#39640;2.5&#20493;&#30340;&#25903;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Protein design often begins with knowledge of a desired function from a motif which motif-scaffolding aims to construct a functional protein around. Recently, generative models have achieved breakthrough success in designing scaffolds for a diverse range of motifs. However, the generated scaffolds tend to lack structural diversity, which can hinder success in wet-lab validation. In this work, we extend FrameFlow, an SE(3) flow matching model for protein backbone generation, to perform motif-scaffolding with two complementary approaches. The first is motif amortization, in which FrameFlow is trained with the motif as input using a data augmentation strategy. The second is motif guidance, which performs scaffolding using an estimate of the conditional score from FrameFlow, and requires no additional training. Both approaches achieve an equivalent or higher success rate than previous state-of-the-art methods, with 2.5 times more structurally diverse scaffolds. Code: https://github.com/ mi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#30340;PCA&#21644;&#20854;&#21464;&#31181;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#22522;&#20110;&#32447;&#24615;&#23376;&#31354;&#38388;&#26071;&#24092;&#65292;&#24182;&#24341;&#20837;&#20102;&#23545;&#24322;&#24120;&#20540;&#21644;&#25968;&#25454;&#27969;&#24418;&#30340;&#32771;&#34385;&#12290;&#36890;&#36807;&#22312;&#26071;&#24092;&#27969;&#24418;&#19978;&#36827;&#34892;&#20248;&#21270;&#38382;&#39064;&#30340;&#27714;&#35299;&#65292;&#32467;&#21512;&#20027;&#27979;&#22320;&#32447;&#36817;&#20284;&#65292;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#26032;&#30340;&#38477;&#32500;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.04071</link><description>&lt;p&gt;
&#26071;&#24092;&#28216;&#25103;&#65306;&#36890;&#36807;&#26071;&#24092;&#27969;&#24418;&#26469;&#33719;&#24471;&#40065;&#26834;&#30340;&#20027;&#26041;&#21521;
&lt;/p&gt;
&lt;p&gt;
Fun with Flags: Robust Principal Directions via Flag Manifolds. (arXiv:2401.04071v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04071
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#30340;PCA&#21644;&#20854;&#21464;&#31181;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#22522;&#20110;&#32447;&#24615;&#23376;&#31354;&#38388;&#26071;&#24092;&#65292;&#24182;&#24341;&#20837;&#20102;&#23545;&#24322;&#24120;&#20540;&#21644;&#25968;&#25454;&#27969;&#24418;&#30340;&#32771;&#34385;&#12290;&#36890;&#36807;&#22312;&#26071;&#24092;&#27969;&#24418;&#19978;&#36827;&#34892;&#20248;&#21270;&#38382;&#39064;&#30340;&#27714;&#35299;&#65292;&#32467;&#21512;&#20027;&#27979;&#22320;&#32447;&#36817;&#20284;&#65292;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#26032;&#30340;&#38477;&#32500;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#21450;&#20854;&#23545;&#27969;&#24418;&#21644;&#24322;&#24120;&#25968;&#25454;&#30340;&#25193;&#23637;&#65292;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#26159;&#19981;&#21487;&#25110;&#32570;&#30340;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;PCA&#21450;&#20854;&#21464;&#31181;&#30340;&#32479;&#19968;&#24418;&#24335;&#65292;&#24341;&#20837;&#20102;&#22522;&#20110;&#32447;&#24615;&#23376;&#31354;&#38388;&#26071;&#24092;&#30340;&#26694;&#26550;&#65292;&#21363;&#36880;&#28176;&#22686;&#21152;&#32500;&#24230;&#30340;&#23884;&#22871;&#32447;&#24615;&#23376;&#31354;&#38388;&#30340;&#23618;&#27425;&#32467;&#26500;&#65292;&#19981;&#20165;&#20801;&#35768;&#20849;&#21516;&#23454;&#29616;&#65292;&#36824;&#20135;&#29983;&#20102;&#26032;&#30340;&#26410;&#26366;&#25506;&#32034;&#30340;&#21464;&#31181;&#12290;&#25105;&#20204;&#20174;&#24191;&#20041;&#21270;&#20256;&#32479;&#30340;PCA&#26041;&#27861;&#24320;&#22987;&#65292;&#36825;&#20123;&#26041;&#27861;&#35201;&#20040;&#26368;&#22823;&#21270;&#26041;&#24046;&#65292;&#35201;&#20040;&#26368;&#23567;&#21270;&#37325;&#26500;&#35823;&#24046;&#12290;&#25105;&#20204;&#25193;&#23637;&#36825;&#20123;&#35299;&#37322;&#65292;&#36890;&#36807;&#32771;&#34385;&#24322;&#24120;&#20540;&#21644;&#25968;&#25454;&#27969;&#24418;&#65292;&#24320;&#21457;&#20986;&#20102;&#22823;&#37327;&#26032;&#30340;&#38477;&#32500;&#31639;&#27861;&#12290;&#20026;&#20102;&#35774;&#35745;&#19968;&#31181;&#36890;&#29992;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#25105;&#20204;&#23558;&#40065;&#26834;&#21644;&#23545;&#20598;&#24418;&#24335;&#30340;PCA&#37325;&#26032;&#26500;&#24314;&#20026;&#22312;&#26071;&#24092;&#27969;&#24418;&#19978;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#20027;&#27979;&#22320;&#32447;&#36817;&#20284;&#65288;&#20999;&#32447;PCA&#65289;&#25972;&#21512;&#21040;&#36825;&#20010;&#22522;&#20110;&#26071;&#24092;&#30340;&#26694;&#26550;&#20013;&#65292;&#21019;&#36896;&#20986;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Principal component analysis (PCA), along with its extensions to manifolds and outlier contaminated data, have been indispensable in computer vision and machine learning. In this work, we present a unifying formalism for PCA and its variants, and introduce a framework based on the flags of linear subspaces, \ie a hierarchy of nested linear subspaces of increasing dimension, which not only allows for a common implementation but also yields novel variants, not explored previously. We begin by generalizing traditional PCA methods that either maximize variance or minimize reconstruction error. We expand these interpretations to develop a wide array of new dimensionality reduction algorithms by accounting for outliers and the data manifold. To devise a common computational approach, we recast robust and dual forms of PCA as optimization problems on flag manifolds. We then integrate tangent space approximations of principal geodesic analysis (tangent-PCA) into this flag-based framework, crea
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#31639;&#27861;&#22312;&#21442;&#25968;&#21160;&#21147;&#23398;&#20013;&#30340;&#32447;&#24615;&#32467;&#26500;&#65292;&#21457;&#29616;&#36825;&#31181;&#32447;&#24615;&#21270;&#29616;&#35937;&#26159;&#30001;&#20110;&#21021;&#22987;&#20540;&#38468;&#36817;&#20551;&#35774;&#20989;&#25968;&#30340;&#19968;&#38454;&#21644;&#39640;&#38454;&#23548;&#25968;&#20043;&#38388;&#30340;&#24369;&#30456;&#20851;&#24615;&#25152;&#33268;&#12290;&#36825;&#19968;&#21457;&#29616;&#20026;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#32447;&#24615;&#21270;&#25552;&#20379;&#20102;&#26032;&#30340;&#35748;&#35782;&#12290;</title><link>http://arxiv.org/abs/2401.04013</link><description>&lt;p&gt;
&#20197;&#24369;&#30456;&#20851;&#24615;&#20316;&#20026;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#31995;&#32479;&#32447;&#24615;&#21270;&#30340;&#22522;&#26412;&#21407;&#21017;
&lt;/p&gt;
&lt;p&gt;
Weak Correlations as the Underlying Principle for Linearization of Gradient-Based Learning Systems. (arXiv:2401.04013v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04013
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#31639;&#27861;&#22312;&#21442;&#25968;&#21160;&#21147;&#23398;&#20013;&#30340;&#32447;&#24615;&#32467;&#26500;&#65292;&#21457;&#29616;&#36825;&#31181;&#32447;&#24615;&#21270;&#29616;&#35937;&#26159;&#30001;&#20110;&#21021;&#22987;&#20540;&#38468;&#36817;&#20551;&#35774;&#20989;&#25968;&#30340;&#19968;&#38454;&#21644;&#39640;&#38454;&#23548;&#25968;&#20043;&#38388;&#30340;&#24369;&#30456;&#20851;&#24615;&#25152;&#33268;&#12290;&#36825;&#19968;&#21457;&#29616;&#20026;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#32447;&#24615;&#21270;&#25552;&#20379;&#20102;&#26032;&#30340;&#35748;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#22914;&#23485;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#20197;&#34987;&#27010;&#24565;&#21270;&#20026;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#29289;&#29702;&#31995;&#32479;&#65292;&#20854;&#20855;&#26377;&#22810;&#20010;&#30456;&#20114;&#20316;&#29992;&#30340;&#33258;&#30001;&#24230;&#12290;&#22312;&#26080;&#38480;&#26497;&#38480;&#19979;&#65292;&#36825;&#20123;&#31995;&#32479;&#36235;&#21521;&#20110;&#34920;&#29616;&#20986;&#31616;&#21270;&#30340;&#21160;&#21147;&#23398;&#12290;&#26412;&#25991;&#28145;&#20837;&#30740;&#31350;&#20102;&#22522;&#20110;&#26799;&#24230;&#19979;&#38477;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#20854;&#21442;&#25968;&#21160;&#21147;&#23398;&#20013;&#23637;&#31034;&#20986;&#19982;&#31070;&#32463;&#20999;&#21521;&#26680;&#31867;&#20284;&#30340;&#32447;&#24615;&#32467;&#26500;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#36825;&#31181;&#26126;&#26174;&#30340;&#32447;&#24615;&#21270;&#26159;&#22240;&#20026;&#22312;&#21021;&#22987;&#20540;&#38468;&#36817;&#65292;&#20551;&#35774;&#20989;&#25968;&#30340;&#19968;&#38454;&#21644;&#39640;&#38454;&#23548;&#25968;&#20043;&#38388;&#30340;&#24369;&#30456;&#20851;&#24615;&#12290;&#36825;&#19968;&#27934;&#35265;&#34920;&#26126;&#65292;&#36825;&#20123;&#24369;&#30456;&#20851;&#24615;&#21487;&#33021;&#26159;&#27492;&#31867;&#31995;&#32479;&#20013;&#35266;&#23519;&#21040;&#30340;&#32447;&#24615;&#21270;&#30340;&#28508;&#22312;&#21407;&#22240;&#12290;&#20316;&#20026;&#19968;&#20010;&#20363;&#35777;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#23485;&#24230;&#24456;&#22823;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#23384;&#22312;&#30340;&#36825;&#31181;&#24369;&#30456;&#20851;&#24615;&#32467;&#26500;&#12290;&#21033;&#29992;&#32447;&#24615;&#21644;&#24369;&#30456;&#20851;&#24615;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#32447;&#24615;&#24230;&#20559;&#31163;&#30340;&#19968;&#20010;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning models, such as wide neural networks, can be conceptualized as nonlinear dynamical physical systems characterized by a multitude of interacting degrees of freedom. Such systems in the infinite limit, tend to exhibit simplified dynamics. This paper delves into gradient descent-based learning algorithms, that display a linear structure in their parameter dynamics, reminiscent of the neural tangent kernel. We establish this apparent linearity arises due to weak correlations between the first and higher-order derivatives of the hypothesis function, concerning the parameters, taken around their initial values. This insight suggests that these weak correlations could be the underlying reason for the observed linearization in such systems. As a case in point, we showcase this weak correlations structure within neural networks in the large width limit. Exploiting the relationship between linearity and weak correlations, we derive a bound on deviations from linearity observed duri
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#24320;&#21457;&#19968;&#31181;&#38750;&#28176;&#36817;&#20998;&#24067;&#29305;&#24449;&#65292;&#20026;&#31232;&#30095;&#21644;&#40065;&#26834;&#22238;&#24402;&#38382;&#39064;&#30340;&#36817;&#20284;&#20256;&#36882;&#28040;&#24687;&#31639;&#27861;&#65288;AMP&#65289;&#24314;&#31435;&#20102;&#26377;&#38480;&#26679;&#26412;&#38750;&#28176;&#36817;&#20998;&#24067;&#29702;&#35770;&#65292;&#21253;&#25324;&#22810;&#39033;&#24335;&#27425;&#25968;&#30340;&#36845;&#20195;&#12290;</title><link>http://arxiv.org/abs/2401.03923</link><description>&lt;p&gt;
&#19968;&#31181;&#38750;&#28176;&#36817;&#20998;&#24067;&#29702;&#35770;&#30340;&#36817;&#20284;&#20256;&#36882;&#28040;&#24687;&#31639;&#27861;&#29992;&#20110;&#31232;&#30095;&#21644;&#40065;&#26834;&#22238;&#24402;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
A non-asymptotic distributional theory of approximate message passing for sparse and robust regression. (arXiv:2401.03923v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03923
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#24320;&#21457;&#19968;&#31181;&#38750;&#28176;&#36817;&#20998;&#24067;&#29305;&#24449;&#65292;&#20026;&#31232;&#30095;&#21644;&#40065;&#26834;&#22238;&#24402;&#38382;&#39064;&#30340;&#36817;&#20284;&#20256;&#36882;&#28040;&#24687;&#31639;&#27861;&#65288;AMP&#65289;&#24314;&#31435;&#20102;&#26377;&#38480;&#26679;&#26412;&#38750;&#28176;&#36817;&#20998;&#24067;&#29702;&#35770;&#65292;&#21253;&#25324;&#22810;&#39033;&#24335;&#27425;&#25968;&#30340;&#36845;&#20195;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#32463;&#20856;&#28176;&#36817;&#29702;&#35770;&#22312;&#39640;&#32500;&#24230;&#20013;&#22833;&#25928;&#65292;&#34920;&#24449;&#39640;&#32500;&#32479;&#35745;&#20272;&#35745;&#37327;&#30340;&#20998;&#24067;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#26412;&#25991;&#36890;&#36807;&#20026;&#36817;&#20284;&#20256;&#36882;&#28040;&#24687;&#31639;&#27861;&#65288;AMP&#65289;&#24320;&#21457;&#38750;&#28176;&#36817;&#20998;&#24067;&#29305;&#24449;&#26469;&#21462;&#24471;&#36827;&#23637;&#65292;&#36825;&#26159;&#19968;&#31867;&#26082;&#20316;&#20026;&#24555;&#36895;&#20272;&#35745;&#22120;&#21448;&#20316;&#20026;&#24378;&#22823;&#30340;&#29702;&#35770;&#24037;&#20855;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#29992;&#20110;&#31232;&#30095;&#21644;&#40065;&#26834;&#22238;&#24402;&#38382;&#39064;&#12290;&#20043;&#21069;&#30340;AMP&#29702;&#35770;&#20027;&#35201;&#20851;&#27880;&#39640;&#32500;&#28176;&#36817;&#24615;&#65292;&#26410;&#33021;&#25551;&#36848;&#24403;&#36845;&#20195;&#27425;&#25968;&#36229;&#36807;$o\big({\log n}/{\log \log n}\big)$&#26102;&#65288;&#20854;&#20013;$n$&#26159;&#26679;&#26412;&#22823;&#23567;&#65289;AMP&#30340;&#34892;&#20026;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#39318;&#20010;&#36866;&#29992;&#20110;&#31232;&#30095;&#21644;&#40065;&#26834;&#22238;&#24402;&#30340;AMP&#26377;&#38480;&#26679;&#26412;&#38750;&#28176;&#36817;&#20998;&#24067;&#29702;&#35770;&#65292;&#21253;&#25324;&#22810;&#39033;&#24335;&#27425;&#25968;&#30340;&#36845;&#20195;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#24471;&#21040;&#20102;AMP&#36845;&#20195;&#30340;&#39640;&#26031;&#36817;&#20284;&#30340;&#36817;&#20284;&#31934;&#24230;&#65292;&#25913;&#36827;&#20102;&#20043;&#21069;&#30340;&#25152;&#26377;&#32467;&#26524;&#65292;&#24182;&#26263;&#31034;&#30528;
&lt;/p&gt;
&lt;p&gt;
Characterizing the distribution of high-dimensional statistical estimators is a challenging task, due to the breakdown of classical asymptotic theory in high dimension. This paper makes progress towards this by developing non-asymptotic distributional characterizations for approximate message passing (AMP) -- a family of iterative algorithms that prove effective as both fast estimators and powerful theoretical machinery -- for both sparse and robust regression. Prior AMP theory, which focused on high-dimensional asymptotics for the most part, failed to describe the behavior of AMP when the number of iterations exceeds $o\big({\log n}/{\log \log n}\big)$ (with $n$ the sample size). We establish the first finite-sample non-asymptotic distributional theory of AMP for both sparse and robust regression that accommodates a polynomial number of iterations. Our results derive approximate accuracy of Gaussian approximation of the AMP iterates, which improves upon all prior results and implies e
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#20010;&#23545;&#22797;&#26434;&#39640;&#32500;&#22122;&#22768;&#40065;&#26834;&#30340;&#24230;&#37327;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#25928;&#30340;&#27969;&#24418;&#21435;&#22122;&#65292;&#21487;&#20197;&#28789;&#27963;&#22788;&#29702;&#22810;&#31181;&#35774;&#32622;&#65292;&#24182;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#36827;&#34892;&#20102;&#31995;&#32479;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2401.03921</link><description>&lt;p&gt;
&#35774;&#35745;&#19968;&#20010;&#23545;&#22797;&#26434;&#39640;&#32500;&#22122;&#22768;&#40065;&#26834;&#30340;&#24230;&#37327;&#26041;&#27861;&#20197;&#23454;&#29616;&#39640;&#25928;&#30340;&#27969;&#24418;&#21435;&#22122;
&lt;/p&gt;
&lt;p&gt;
Design a Metric Robust to Complicated High Dimensional Noise for Efficient Manifold Denoising. (arXiv:2401.03921v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03921
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#20010;&#23545;&#22797;&#26434;&#39640;&#32500;&#22122;&#22768;&#40065;&#26834;&#30340;&#24230;&#37327;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#25928;&#30340;&#27969;&#24418;&#21435;&#22122;&#65292;&#21487;&#20197;&#28789;&#27963;&#22788;&#29702;&#22810;&#31181;&#35774;&#32622;&#65292;&#24182;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#36827;&#34892;&#20102;&#31995;&#32479;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22320;&#26631;&#25193;&#25955;&#21644;&#26368;&#20248;&#25910;&#32553;&#30340;&#39640;&#25928;&#27969;&#24418;&#21435;&#22122;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22797;&#26434;&#30340;&#39640;&#32500;&#22122;&#22768;&#21644;&#32039;&#20945;&#27969;&#24418;&#35774;&#32622;&#12290;&#23427;&#21487;&#20197;&#28789;&#27963;&#22788;&#29702;&#22810;&#31181;&#35774;&#32622;&#65292;&#21253;&#25324;&#39640;&#29615;&#22659;&#31354;&#38388;&#32500;&#24230;&#30340;&#27969;&#24418;&#23884;&#20837;&#65288;&#21344;&#25454;&#39640;&#32500;&#25110;&#20302;&#32500;&#23376;&#31354;&#38388;&#65289;&#20197;&#21450;&#21487;&#33021;&#26159;&#26377;&#33394;&#19988;&#30456;&#20851;&#30340;&#22122;&#22768;&#12290;&#25105;&#20204;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#23545;&#35813;&#26041;&#27861;&#19982;&#20854;&#20182;&#29616;&#26377;&#31639;&#27861;&#36827;&#34892;&#20102;&#31995;&#32479;&#27604;&#36739;&#12290;&#26412;&#35770;&#25991;&#20027;&#35201;&#26159;&#31639;&#27861;&#24615;&#36136;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#25253;&#21578;&#20102;&#19968;&#20123;&#29616;&#26377;&#24037;&#20855;&#21644;&#25968;&#20540;&#32467;&#26524;&#12290;&#26356;&#22810;&#30340;&#29702;&#35770;&#20445;&#35777;&#21644;&#27604;&#36739;&#23558;&#22312;&#27491;&#24335;&#35770;&#25991;&#20013;&#25253;&#21578;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this manuscript, we propose an efficient manifold denoiser based on landmark diffusion and optimal shrinkage under the complicated high dimensional noise and compact manifold setup. It is flexible to handle several setups, including the high ambient space dimension with a manifold embedding that occupies a subspace of high or low dimensions, and the noise could be colored and dependent. A systematic comparison with other existing algorithms on both simulated and real datasets is provided. This manuscript is mainly algorithmic and we report several existing tools and numerical results. Theoretical guarantees and more comparisons will be reported in the official paper of this manuscript.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#38750;&#32447;&#24615;&#21452;&#26102;&#38388;&#23610;&#24230;&#38543;&#26426;&#36924;&#36817;&#20013;&#26377;&#38480;&#26102;&#38388;&#35299;&#32806;&#25910;&#25947;&#30340;&#28508;&#21147;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#23884;&#22871;&#23616;&#37096;&#32447;&#24615;&#26465;&#20214;&#35777;&#26126;&#20102;&#20854;&#21487;&#34892;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.03893</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#21452;&#26102;&#38388;&#23610;&#24230;&#38543;&#26426;&#36924;&#36817;&#20013;&#30340;&#26377;&#38480;&#26102;&#38388;&#35299;&#32806;&#25910;&#25947;
&lt;/p&gt;
&lt;p&gt;
Finite-Time Decoupled Convergence in Nonlinear Two-Time-Scale Stochastic Approximation. (arXiv:2401.03893v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03893
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#38750;&#32447;&#24615;&#21452;&#26102;&#38388;&#23610;&#24230;&#38543;&#26426;&#36924;&#36817;&#20013;&#26377;&#38480;&#26102;&#38388;&#35299;&#32806;&#25910;&#25947;&#30340;&#28508;&#21147;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#23884;&#22871;&#23616;&#37096;&#32447;&#24615;&#26465;&#20214;&#35777;&#26126;&#20102;&#20854;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21452;&#26102;&#38388;&#23610;&#24230;&#38543;&#26426;&#36924;&#36817;&#20013;&#65292;&#20351;&#29992;&#19981;&#21516;&#30340;&#27493;&#38271;&#20197;&#19981;&#21516;&#30340;&#36895;&#24230;&#26356;&#26032;&#20004;&#20010;&#36845;&#20195;&#65292;&#27599;&#27425;&#26356;&#26032;&#37117;&#20250;&#24433;&#21709;&#21478;&#19968;&#20010;&#12290;&#20808;&#21069;&#30340;&#32447;&#24615;&#21452;&#26102;&#38388;&#23610;&#24230;&#38543;&#26426;&#36924;&#36817;&#30740;&#31350;&#21457;&#29616;&#65292;&#36825;&#20123;&#26356;&#26032;&#30340;&#22343;&#26041;&#35823;&#24046;&#30340;&#25910;&#25947;&#36895;&#24230;&#20165;&#20165;&#21462;&#20915;&#20110;&#23427;&#20204;&#21508;&#33258;&#30340;&#27493;&#38271;&#65292;&#23548;&#33268;&#20102;&#25152;&#35859;&#30340;&#35299;&#32806;&#25910;&#25947;&#12290;&#28982;&#32780;&#65292;&#22312;&#38750;&#32447;&#24615;&#38543;&#26426;&#36924;&#36817;&#20013;&#23454;&#29616;&#36825;&#31181;&#35299;&#32806;&#25910;&#25947;&#30340;&#21487;&#33021;&#24615;&#20173;&#19981;&#26126;&#30830;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25506;&#35752;&#20102;&#38750;&#32447;&#24615;&#21452;&#26102;&#38388;&#23610;&#24230;&#38543;&#26426;&#36924;&#36817;&#20013;&#26377;&#38480;&#26102;&#38388;&#35299;&#32806;&#25910;&#25947;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#36739;&#24369;&#30340;Lipschitz&#26465;&#20214;&#19979;&#65292;&#20256;&#32479;&#20998;&#26512;&#26080;&#27861;&#23454;&#29616;&#35299;&#32806;&#25910;&#25947;&#12290;&#36825;&#19968;&#21457;&#29616;&#22312;&#25968;&#20540;&#19978;&#24471;&#21040;&#20102;&#36827;&#19968;&#27493;&#30340;&#25903;&#25345;&#12290;&#20294;&#26159;&#36890;&#36807;&#24341;&#20837;&#19968;&#20010;&#23884;&#22871;&#23616;&#37096;&#32447;&#24615;&#26465;&#20214;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#36866;&#24403;&#36873;&#25321;&#19982;&#24179;&#28369;&#24230;&#30456;&#20851;&#30340;&#27493;&#38271;&#30340;&#24773;&#20917;&#19979;&#65292;&#35299;&#32806;&#25910;&#25947;&#20173;&#28982;&#26159;&#21487;&#34892;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
In two-time-scale stochastic approximation (SA), two iterates are updated at varying speeds using different step sizes, with each update influencing the other. Previous studies in linear two-time-scale SA have found that the convergence rates of the mean-square errors for these updates are dependent solely on their respective step sizes, leading to what is referred to as decoupled convergence. However, the possibility of achieving this decoupled convergence in nonlinear SA remains less understood. Our research explores the potential for finite-time decoupled convergence in nonlinear two-time-scale SA. We find that under a weaker Lipschitz condition, traditional analyses are insufficient for achieving decoupled convergence. This finding is further numerically supported by a counterexample. But by introducing an additional condition of nested local linearity, we show that decoupled convergence is still feasible, contingent on the appropriate choice of step sizes associated with smoothnes
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#26680;Fisher-Rao&#27969;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#21333;&#20301;&#26102;&#38388;&#20869;&#20174;&#38750;&#24402;&#19968;&#21270;&#30446;&#26631;&#23494;&#24230;&#25110;&#36125;&#21494;&#26031;&#21518;&#39564;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#26041;&#27861;&#20351;&#29992;&#20102;&#22343;&#22330;ODE&#21644;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#31995;&#32479;&#65292;&#26080;&#38656;&#26799;&#24230;&#65292;&#21482;&#38656;&#35201;&#33021;&#22815;&#20174;&#21442;&#32771;&#23494;&#24230;&#20013;&#37319;&#26679;&#24182;&#35745;&#31639;&#30446;&#26631;&#23545;&#21442;&#32771;&#23494;&#24230;&#30340;&#27604;&#29575;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#22312;&#20960;&#20309;&#28151;&#21512;&#30340;&#36335;&#24452;&#19978;&#27839;&#36895;&#24230;&#22330;&#36816;&#36755;&#26679;&#26412;&#65292;&#24452;&#21521;&#36755;&#36816;&#26679;&#26412;&#12290;&#26041;&#27861;&#36890;&#36807;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#27714;&#35299;&#27850;&#26494;&#26041;&#31243;&#65292;&#20351;&#27850;&#26494;&#26041;&#31243;&#30340;&#27714;&#35299;&#21464;&#24471;&#21487;&#34892;&#65292;&#24182;&#23558;&#20854;&#31163;&#25955;&#21270;&#20026;&#26377;&#38480;&#26679;&#26412;&#30340;&#22343;&#22330;ODE&#65292;&#20316;&#20026;&#23454;&#29616;&#31616;&#21333;&#30340;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#31995;&#32479;&#12290;&#21516;&#26102;&#65292;&#36825;&#31181;&#26041;&#27861;&#20063;&#21487;&#20197;&#20174;&#31163;&#25955;&#26102;&#38388;&#30340;&#35282;&#24230;&#25512;&#23548;&#20986;&#22343;&#22330;ODE&#65292;&#20316;&#20026;&#33945;&#26480;-&#23433;&#26222;&#23572;&#26041;&#31243;&#36830;&#32493;&#32447;&#24615;&#21270;&#30340;&#26497;&#38480;&#12290;</title><link>http://arxiv.org/abs/2401.03892</link><description>&lt;p&gt;
&#20197;&#26680;Fisher-Rao&#27969;&#36827;&#34892;&#21333;&#20301;&#26102;&#38388;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Sampling in Unit Time with Kernel Fisher-Rao Flow. (arXiv:2401.03892v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03892
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#26680;Fisher-Rao&#27969;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#21333;&#20301;&#26102;&#38388;&#20869;&#20174;&#38750;&#24402;&#19968;&#21270;&#30446;&#26631;&#23494;&#24230;&#25110;&#36125;&#21494;&#26031;&#21518;&#39564;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#26041;&#27861;&#20351;&#29992;&#20102;&#22343;&#22330;ODE&#21644;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#31995;&#32479;&#65292;&#26080;&#38656;&#26799;&#24230;&#65292;&#21482;&#38656;&#35201;&#33021;&#22815;&#20174;&#21442;&#32771;&#23494;&#24230;&#20013;&#37319;&#26679;&#24182;&#35745;&#31639;&#30446;&#26631;&#23545;&#21442;&#32771;&#23494;&#24230;&#30340;&#27604;&#29575;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#22312;&#20960;&#20309;&#28151;&#21512;&#30340;&#36335;&#24452;&#19978;&#27839;&#36895;&#24230;&#22330;&#36816;&#36755;&#26679;&#26412;&#65292;&#24452;&#21521;&#36755;&#36816;&#26679;&#26412;&#12290;&#26041;&#27861;&#36890;&#36807;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#27714;&#35299;&#27850;&#26494;&#26041;&#31243;&#65292;&#20351;&#27850;&#26494;&#26041;&#31243;&#30340;&#27714;&#35299;&#21464;&#24471;&#21487;&#34892;&#65292;&#24182;&#23558;&#20854;&#31163;&#25955;&#21270;&#20026;&#26377;&#38480;&#26679;&#26412;&#30340;&#22343;&#22330;ODE&#65292;&#20316;&#20026;&#23454;&#29616;&#31616;&#21333;&#30340;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#31995;&#32479;&#12290;&#21516;&#26102;&#65292;&#36825;&#31181;&#26041;&#27861;&#20063;&#21487;&#20197;&#20174;&#31163;&#25955;&#26102;&#38388;&#30340;&#35282;&#24230;&#25512;&#23548;&#20986;&#22343;&#22330;ODE&#65292;&#20316;&#20026;&#33945;&#26480;-&#23433;&#26222;&#23572;&#26041;&#31243;&#36830;&#32493;&#32447;&#24615;&#21270;&#30340;&#26497;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#22343;&#22330;ODE&#21644;&#30456;&#24212;&#30340;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#31995;&#32479;&#65292;&#29992;&#20110;&#20174;&#38750;&#24402;&#19968;&#21270;&#30340;&#30446;&#26631;&#23494;&#24230;&#25110;&#36125;&#21494;&#26031;&#21518;&#39564;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#31995;&#32479;&#26080;&#38656;&#26799;&#24230;&#65292;&#21487;&#20197;&#38381;&#21512;&#24418;&#24335;&#33719;&#24471;&#65292;&#24182;&#19988;&#21482;&#38656;&#35201;&#33021;&#22815;&#20174;&#21442;&#32771;&#23494;&#24230;&#20013;&#37319;&#26679;&#24182;&#35745;&#31639;&#65288;&#38750;&#24402;&#19968;&#21270;&#30340;&#65289;&#30446;&#26631;&#23545;&#21442;&#32771;&#23494;&#24230;&#30340;&#27604;&#29575;&#12290;&#36890;&#36807;&#27714;&#35299;&#36816;&#36755;&#26679;&#26412;&#27839;&#20004;&#20010;&#23494;&#24230;&#30340;&#20960;&#20309;&#28151;&#21512;&#30340;&#36895;&#24230;&#22330;&#30340;&#27850;&#26494;&#26041;&#31243;&#26469;&#33719;&#24471;&#22343;&#22330;ODE&#65292;&#36825;&#26159;&#19968;&#31181;&#29305;&#23450;&#30340;Fisher-Rao&#26799;&#24230;&#27969;&#30340;&#36335;&#24452;&#12290;&#25105;&#20204;&#37319;&#29992;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26041;&#27861;&#26469;&#33719;&#24471;&#36895;&#24230;&#22330;&#30340;&#27850;&#26494;&#26041;&#31243;&#65292;&#36825;&#20351;&#24471;&#27850;&#26494;&#26041;&#31243;&#21487;&#22788;&#29702;&#65292;&#24182;&#20351;&#25105;&#20204;&#33021;&#22815;&#31163;&#25955;&#21270;&#26377;&#38480;&#26679;&#26412;&#30340;&#32467;&#26524;&#22343;&#22330;ODE&#65292;&#24418;&#25104;&#19968;&#20010;&#31616;&#21333;&#30340;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#31995;&#32479;&#12290;&#22343;&#22330;ODE&#36824;&#21487;&#20197;&#36890;&#36807;&#31163;&#25955;&#26102;&#38388;&#35270;&#35282;&#20174;&#33945;&#26480;-&#23433;&#26222;&#23572;&#26041;&#31243;&#30340;&#36830;&#32493;&#32447;&#24615;&#21270;&#30340;&#26497;&#38480;&#20013;&#25512;&#23548;&#20986;&#26469;&#65292;&#36825;&#22312;&#19968;&#20010;&#24050;&#30693;&#30340;&#26694;&#26550;&#20869;&#36827;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new mean-field ODE and corresponding interacting particle systems for sampling from an unnormalized target density or Bayesian posterior. The interacting particle systems are gradient-free, available in closed form, and only require the ability to sample from the reference density and compute the (unnormalized) target-to-reference density ratio. The mean-field ODE is obtained by solving a Poisson equation for a velocity field that transports samples along the geometric mixture of the two densities, which is the path of a particular Fisher-Rao gradient flow. We employ a reproducing kernel Hilbert space ansatz for the velocity field, which makes the Poisson equation tractable and enables us to discretize the resulting mean-field ODE over finite samples, as a simple interacting particle system. The mean-field ODE can be additionally be derived from a discrete-time perspective as the limit of successive linearizations of the Monge-Amp\`ere equations within a framework known 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Betti&#25968;&#30340;&#25299;&#25169;&#24230;&#37327;&#65292;&#29992;&#20110;&#35780;&#20272;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#25439;&#22833;&#30340;&#22797;&#26434;&#24615;&#65292;&#24182;&#21457;&#29616;&#22797;&#26434;&#24615;&#21463;&#21040;&#38544;&#34255;&#21333;&#20803;&#25968;&#37327;&#12289;&#35757;&#32451;&#27169;&#22411;&#21644;&#28608;&#27963;&#20989;&#25968;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2401.03824</link><description>&lt;p&gt;
&#22522;&#20110;Betti&#25968;&#30340;&#25439;&#22833;&#26354;&#38754;&#30340;&#25299;&#25169;&#25551;&#36848;
&lt;/p&gt;
&lt;p&gt;
A topological description of loss surfaces based on Betti Numbers. (arXiv:2401.03824v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03824
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Betti&#25968;&#30340;&#25299;&#25169;&#24230;&#37327;&#65292;&#29992;&#20110;&#35780;&#20272;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#25439;&#22833;&#30340;&#22797;&#26434;&#24615;&#65292;&#24182;&#21457;&#29616;&#22797;&#26434;&#24615;&#21463;&#21040;&#38544;&#34255;&#21333;&#20803;&#25968;&#37327;&#12289;&#35757;&#32451;&#27169;&#22411;&#21644;&#28608;&#27963;&#20989;&#25968;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#32972;&#26223;&#19979;&#65292;&#30740;&#31350;&#25439;&#22833;&#20989;&#25968;&#30340;&#26354;&#38754;&#24050;&#32463;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#65292;&#20197;&#26356;&#22909;&#22320;&#29702;&#35299;&#22522;&#20110;&#26799;&#24230;&#19979;&#38477;&#30340;&#35757;&#32451;&#26041;&#27861;&#12290;&#36825;&#31181;&#23545;&#19968;&#20010;&#21512;&#36866;&#30340;&#25551;&#36848;&#30340;&#23547;&#27714;&#65292;&#26082;&#21253;&#25324;&#20998;&#26512;&#21448;&#21253;&#25324;&#25299;&#25169;&#65292;&#24050;&#32463;&#23548;&#33268;&#20102;&#22823;&#37327;&#21162;&#21147;&#26469;&#35782;&#21035;&#34394;&#20551;&#26368;&#23567;&#20540;&#21644;&#34920;&#24449;&#26799;&#24230;&#21160;&#24577;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#26088;&#22312;&#20026;&#36825;&#19968;&#39046;&#22495;&#20570;&#20986;&#36129;&#29486;&#65292;&#36890;&#36807;&#25552;&#20379;&#19968;&#20010;&#25299;&#25169;&#24230;&#37327;&#26469;&#35780;&#20272;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#25439;&#22833;&#30340;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#25512;&#23548;&#28145;&#23618;&#21644;&#27973;&#23618;&#26550;&#26500;&#30340;&#25439;&#22833;&#20989;&#25968;&#22797;&#26434;&#24615;&#30340;&#19978;&#19979;&#30028;&#20197;&#21450;&#25581;&#31034;&#36825;&#31181;&#22797;&#26434;&#24615;&#22914;&#20309;&#21463;&#38544;&#34255;&#21333;&#20803;&#25968;&#37327;&#12289;&#35757;&#32451;&#27169;&#22411;&#21644;&#28608;&#27963;&#20989;&#25968;&#24433;&#21709;&#65292;&#27604;&#36739;&#20102;&#20351;&#29992;&#24120;&#35265;&#30340;Sigmoid&#28608;&#27963;&#20989;&#25968;&#30340;&#28145;&#23618;&#21644;&#27973;&#23618;&#26550;&#26500;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#25439;&#22833;&#20989;&#25968;&#25110;&#27169;&#22411;&#26550;&#26500;&#30340;&#26576;&#20123;&#21464;&#21270;&#65292;&#27604;&#22914;&#22312;&#21069;&#39304;&#32593;&#32476;&#20013;&#28155;&#21152;$\ell_2$&#27491;&#21017;&#21270;&#39033;&#25110;&#23454;&#26045;&#36339;&#36291;&#36830;&#25509;
&lt;/p&gt;
&lt;p&gt;
In the context of deep learning models, attention has recently been paid to studying the surface of the loss function in order to better understand training with methods based on gradient descent. This search for an appropriate description, both analytical and topological, has led to numerous efforts to identify spurious minima and characterize gradient dynamics. Our work aims to contribute to this field by providing a topological measure to evaluate loss complexity in the case of multilayer neural networks. We compare deep and shallow architectures with common sigmoidal activation functions by deriving upper and lower bounds on the complexity of their loss function and revealing how that complexity is influenced by the number of hidden units, training models, and the activation function used. Additionally, we found that certain variations in the loss function or model architecture, such as adding an $\ell_2$ regularization term or implementing skip connections in a feedforward network
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#23574;&#23792;&#21327;&#26041;&#24046;&#27169;&#22411;&#20013;&#30340;&#26368;&#20248;&#24046;&#20998;&#38544;&#31169;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;&#21327;&#26041;&#24046;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#39640;&#25928;&#30340;&#24046;&#20998;&#38544;&#31169;&#20272;&#35745;&#22120;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#26368;&#23567;&#26368;&#22823;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.03820</link><description>&lt;p&gt;
&#22312;&#24102;&#26377;&#23574;&#23792;&#21327;&#26041;&#24046;&#30697;&#38453;&#20013;&#30340;&#26368;&#20248;&#24046;&#20998;&#38544;&#31169;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Optimal Differentially Private PCA and Estimation for Spiked Covariance Matrices. (arXiv:2401.03820v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03820
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#23574;&#23792;&#21327;&#26041;&#24046;&#27169;&#22411;&#20013;&#30340;&#26368;&#20248;&#24046;&#20998;&#38544;&#31169;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;&#21327;&#26041;&#24046;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#39640;&#25928;&#30340;&#24046;&#20998;&#38544;&#31169;&#20272;&#35745;&#22120;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#26368;&#23567;&#26368;&#22823;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24403;&#20195;&#32479;&#35745;&#23398;&#20013;&#65292;&#20272;&#35745;&#21327;&#26041;&#24046;&#30697;&#38453;&#21450;&#20854;&#30456;&#20851;&#30340;&#20027;&#25104;&#20998;&#26159;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#12290;&#23613;&#31649;&#24050;&#24320;&#21457;&#20986;&#20855;&#26377;&#33391;&#22909;&#24615;&#36136;&#30340;&#26368;&#20248;&#20272;&#35745;&#31243;&#24207;&#65292;&#20294;&#23545;&#38544;&#31169;&#20445;&#25252;&#30340;&#22686;&#21152;&#38656;&#27714;&#32473;&#36825;&#20010;&#32463;&#20856;&#38382;&#39064;&#24341;&#20837;&#20102;&#26032;&#30340;&#22797;&#26434;&#24615;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#23574;&#23792;&#21327;&#26041;&#24046;&#27169;&#22411;&#20013;&#30340;&#26368;&#20248;&#24046;&#20998;&#38544;&#31169;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#21644;&#21327;&#26041;&#24046;&#20272;&#35745;&#12290;&#25105;&#20204;&#31934;&#30830;&#22320;&#21051;&#30011;&#20102;&#22312;&#35813;&#27169;&#22411;&#19979;&#29305;&#24449;&#20540;&#21644;&#29305;&#24449;&#21521;&#37327;&#30340;&#25935;&#24863;&#24615;&#65292;&#24182;&#24314;&#31435;&#20102;&#20272;&#35745;&#20027;&#25104;&#20998;&#21644;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#26368;&#23567;&#26368;&#22823;&#25910;&#25947;&#29575;&#12290;&#36825;&#20123;&#25910;&#25947;&#29575;&#21253;&#25324;&#19968;&#33324;&#30340;Schatten&#33539;&#25968;&#65292;&#21253;&#25324;&#35889;&#33539;&#25968;&#65292;Frobenius&#33539;&#25968;&#21644;&#26680;&#33539;&#25968;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#35745;&#31639;&#39640;&#25928;&#30340;&#24046;&#20998;&#38544;&#31169;&#20272;&#35745;&#22120;&#65292;&#24182;&#35777;&#26126;&#23427;&#20204;&#30340;&#26368;&#23567;&#26368;&#22823;&#24615;&#65292;&#30452;&#21040;&#23545;&#25968;&#22240;&#23376;&#12290;&#21478;&#22806;&#65292;&#21305;&#37197;&#30340;minimax&#26368;&#23567;&#26368;&#22823;&#29575;&#20063;&#24471;&#21040;&#20102;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating a covariance matrix and its associated principal components is a fundamental problem in contemporary statistics. While optimal estimation procedures have been developed with well-understood properties, the increasing demand for privacy preservation introduces new complexities to this classical problem. In this paper, we study optimal differentially private Principal Component Analysis (PCA) and covariance estimation within the spiked covariance model.  We precisely characterize the sensitivity of eigenvalues and eigenvectors under this model and establish the minimax rates of convergence for estimating both the principal components and covariance matrix. These rates hold up to logarithmic factors and encompass general Schatten norms, including spectral norm, Frobenius norm, and nuclear norm as special cases.  We introduce computationally efficient differentially private estimators and prove their minimax optimality, up to logarithmic factors. Additionally, matching minimax l
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20010;&#24615;&#21270;&#27835;&#30103;&#25512;&#33616;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#19978;&#19979;&#25991;&#22266;&#23450;&#39044;&#31639;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#27169;&#22411;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;&#21644;&#31574;&#30053;&#23398;&#20064;&#26469;&#25512;&#33616;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#65292;&#24182;&#36890;&#36807;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#26469;&#34913;&#37327;&#25512;&#33616;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.03756</link><description>&lt;p&gt;
&#19978;&#19979;&#25991;&#22266;&#23450;&#39044;&#31639;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#65306;&#36866;&#24212;&#24615;&#23454;&#39564;&#35774;&#35745;&#19982;&#31574;&#30053;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Contextual Fixed-Budget Best Arm Identification: Adaptive Experimental Design with Policy Learning. (arXiv:2401.03756v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03756
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20010;&#24615;&#21270;&#27835;&#30103;&#25512;&#33616;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#19978;&#19979;&#25991;&#22266;&#23450;&#39044;&#31639;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#27169;&#22411;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;&#21644;&#31574;&#30053;&#23398;&#20064;&#26469;&#25512;&#33616;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#65292;&#24182;&#36890;&#36807;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#26469;&#34913;&#37327;&#25512;&#33616;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#27835;&#30103;&#25512;&#33616;&#26159;&#22522;&#20110;&#35777;&#25454;&#30340;&#20915;&#31574;&#20013;&#30340;&#20851;&#38190;&#20219;&#21153;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#20219;&#21153;&#20316;&#20026;&#19968;&#20010;&#24102;&#26377;&#19978;&#19979;&#25991;&#20449;&#24687;&#30340;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#65288;Best Arm Identification, BAI&#65289;&#38382;&#39064;&#26469;&#36827;&#34892;&#24314;&#27169;&#12290;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#32473;&#23450;&#22810;&#20010;&#27835;&#30103;&#33218;&#30340;&#33258;&#36866;&#24212;&#35797;&#39564;&#12290;&#22312;&#27599;&#19968;&#36718;&#20013;&#65292;&#20915;&#31574;&#32773;&#35266;&#23519;&#19968;&#20010;&#21051;&#30011;&#23454;&#39564;&#21333;&#20301;&#30340;&#19978;&#19979;&#25991;&#65288;&#21327;&#21464;&#37327;&#65289;&#65292;&#24182;&#23558;&#35813;&#21333;&#20301;&#20998;&#37197;&#32473;&#20854;&#20013;&#19968;&#20010;&#27835;&#30103;&#33218;&#12290;&#22312;&#23454;&#39564;&#32467;&#26463;&#26102;&#65292;&#20915;&#31574;&#32773;&#25512;&#33616;&#19968;&#20010;&#22312;&#32473;&#23450;&#19978;&#19979;&#25991;&#26465;&#20214;&#19979;&#39044;&#35745;&#20135;&#29983;&#26368;&#39640;&#26399;&#26395;&#32467;&#26524;&#30340;&#27835;&#30103;&#33218;&#65288;&#26368;&#20339;&#27835;&#30103;&#33218;&#65289;&#12290;&#35813;&#20915;&#31574;&#30340;&#26377;&#25928;&#24615;&#36890;&#36807;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#65288;&#31574;&#30053;&#36951;&#25022;&#65289;&#26469;&#34913;&#37327;&#65292;&#35813;&#36951;&#25022;&#34920;&#31034;&#22312;&#32473;&#23450;&#19978;&#19979;&#25991;&#26465;&#20214;&#19979;&#65292;&#26368;&#20339;&#27835;&#30103;&#33218;&#21644;&#25512;&#33616;&#27835;&#30103;&#33218;&#30340;&#26465;&#20214;&#26399;&#26395;&#32467;&#26524;&#20043;&#38388;&#30340;&#26368;&#22823;&#24046;&#24322;&#12290;&#25105;&#20204;&#30340;&#21021;&#22987;&#27493;&#39588;&#26159;&#25512;&#23548;&#26368;&#22351;&#24773;&#20917;&#19979;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#30340;&#28176;&#36817;&#19979;&#30028;&#65292;&#35813;&#19979;&#30028;&#36824;&#26263;&#31034;&#30528;&#35299;&#20915;&#35813;&#38382;&#39064;&#30340;&#19968;&#20123;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Individualized treatment recommendation is a crucial task in evidence-based decision-making. In this study, we formulate this task as a fixed-budget best arm identification (BAI) problem with contextual information. In this setting, we consider an adaptive experiment given multiple treatment arms. At each round, a decision-maker observes a context (covariate) that characterizes an experimental unit and assigns the unit to one of the treatment arms. At the end of the experiment, the decision-maker recommends a treatment arm estimated to yield the highest expected outcome conditioned on a context (best treatment arm). The effectiveness of this decision is measured in terms of the worst-case expected simple regret (policy regret), which represents the largest difference between the conditional expected outcomes of the best and recommended treatment arms given a context. Our initial step is to derive asymptotic lower bounds for the worst-case expected simple regret, which also implies idea
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23558;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#24212;&#29992;&#20110;&#20020;&#24202;&#35797;&#39564;&#32467;&#26524;&#39044;&#27979;&#65292;&#25552;&#39640;&#27169;&#22411;&#23545;&#24494;&#22937;&#24046;&#24322;&#30340;&#35782;&#21035;&#33021;&#21147;&#65292;&#20174;&#32780;&#25913;&#21892;&#20854;&#25972;&#20307;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.03482</link><description>&lt;p&gt;
&#20020;&#24202;&#35797;&#39564;&#32467;&#26524;&#39044;&#27979;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Uncertainty Quantification on Clinical Trial Outcome Prediction. (arXiv:2401.03482v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03482
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#24212;&#29992;&#20110;&#20020;&#24202;&#35797;&#39564;&#32467;&#26524;&#39044;&#27979;&#65292;&#25552;&#39640;&#27169;&#22411;&#23545;&#24494;&#22937;&#24046;&#24322;&#30340;&#35782;&#21035;&#33021;&#21147;&#65292;&#20174;&#32780;&#25913;&#21892;&#20854;&#25972;&#20307;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#22312;&#26426;&#22120;&#23398;&#20064;&#30340;&#19981;&#21516;&#39046;&#22495;&#20013;&#30340;&#37325;&#35201;&#24615;&#26085;&#30410;&#34987;&#35748;&#35782;&#21040;&#12290;&#20934;&#30830;&#35780;&#20272;&#27169;&#22411;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#21487;&#20197;&#24110;&#21161;&#30740;&#31350;&#20154;&#21592;&#21644;&#20174;&#19994;&#20154;&#21592;&#26356;&#28145;&#20837;&#22320;&#29702;&#35299;&#21644;&#22686;&#21152;&#20449;&#24515;&#12290;&#36825;&#22312;&#21307;&#23398;&#35786;&#26029;&#21644;&#33647;&#29289;&#21457;&#29616;&#39046;&#22495;&#23588;&#20026;&#37325;&#35201;&#65292;&#22240;&#20026;&#21487;&#38752;&#30340;&#39044;&#27979;&#30452;&#25509;&#24433;&#21709;&#30740;&#31350;&#36136;&#37327;&#21644;&#24739;&#32773;&#20581;&#24247;&#12290;&#26412;&#25991;&#25552;&#20986;&#23558;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#32435;&#20837;&#20020;&#24202;&#35797;&#39564;&#32467;&#26524;&#39044;&#27979;&#20013;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#25552;&#39640;&#27169;&#22411;&#36776;&#21035;&#24494;&#22937;&#24046;&#24322;&#30340;&#33021;&#21147;&#65292;&#20174;&#32780;&#26174;&#33879;&#25913;&#21892;&#20854;&#25972;&#20307;&#24615;&#33021;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#19968;&#31181;&#36873;&#25321;&#24615;&#20998;&#31867;&#26041;&#27861;&#26469;&#23454;&#29616;&#25105;&#20204;&#30340;&#30446;&#26631;&#65292;&#24182;&#23558;&#20854;&#19982;&#23618;&#27425;&#20132;&#20114;&#32593;&#32476;(HINT)&#26080;&#32541;&#38598;&#25104;&#65292;HINT&#26159;&#20020;&#24202;&#35797;&#39564;&#39044;&#27979;&#24314;&#27169;&#30340;&#26368;&#21069;&#27839;&#12290;&#36873;&#25321;&#24615;&#20998;&#31867;&#28085;&#30422;&#20102;&#19968;&#31995;&#21015;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#20351;&#27169;&#22411;&#33021;&#22815;&#20445;&#30041;&#20449;&#24687;&#20197;&#20379;&#36827;&#19968;&#27493;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
The importance of uncertainty quantification is increasingly recognized in the diverse field of machine learning. Accurately assessing model prediction uncertainty can help provide deeper understanding and confidence for researchers and practitioners. This is especially critical in medical diagnosis and drug discovery areas, where reliable predictions directly impact research quality and patient health.  In this paper, we proposed incorporating uncertainty quantification into clinical trial outcome predictions. Our main goal is to enhance the model's ability to discern nuanced differences, thereby significantly improving its overall performance.  We have adopted a selective classification approach to fulfill our objective, integrating it seamlessly with the Hierarchical Interaction Network (HINT), which is at the forefront of clinical trial prediction modeling. Selective classification, encompassing a spectrum of methods for uncertainty quantification, empowers the model to withhold de
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;G-$\Delta$UQ&#65292;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#26694;&#26550;&#65292;&#26088;&#22312;&#25913;&#21892;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#30340;&#20869;&#22312;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#22270;&#38170;&#23450;&#31574;&#30053;&#23558;&#38543;&#26426;&#25968;&#25454;&#20013;&#24515;&#21270;&#24212;&#29992;&#20110;&#22270;&#25968;&#25454;&#65292;&#24182;&#19988;&#33021;&#22815;&#25903;&#25345;&#37096;&#20998;&#38543;&#26426;&#30340;GNN&#12290;</title><link>http://arxiv.org/abs/2401.03350</link><description>&lt;p&gt;
&#20934;&#30830;&#21487;&#25193;&#23637;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#34920;&#35266;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Accurate and Scalable Estimation of Epistemic Uncertainty for Graph Neural Networks. (arXiv:2401.03350v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03350
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;G-$\Delta$UQ&#65292;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#26694;&#26550;&#65292;&#26088;&#22312;&#25913;&#21892;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#30340;&#20869;&#22312;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#22270;&#38170;&#23450;&#31574;&#30053;&#23558;&#38543;&#26426;&#25968;&#25454;&#20013;&#24515;&#21270;&#24212;&#29992;&#20110;&#22270;&#25968;&#25454;&#65292;&#24182;&#19988;&#33021;&#22815;&#25903;&#25345;&#37096;&#20998;&#38543;&#26426;&#30340;GNN&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#24191;&#27867;&#29992;&#20110;&#33410;&#28857;&#21644;&#22270;&#34920;&#31034;&#23398;&#20064;&#20219;&#21153;&#65292;&#20294;&#22312;&#20998;&#24067;&#21464;&#21270;&#19979;GNN&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#21487;&#38752;&#24615;&#20173;&#30456;&#23545;&#36739;&#23569;&#25506;&#32034;&#12290;&#20107;&#23454;&#19978;&#65292;&#34429;&#28982;&#20107;&#21518;&#26657;&#20934;&#31574;&#30053;&#21487;&#20197;&#29992;&#20110;&#25913;&#21892;&#20869;&#37096;&#20998;&#24067;&#26657;&#20934;&#65292;&#20294;&#23427;&#20204;&#19981;&#19968;&#23450;&#20063;&#33021;&#25913;&#36827;&#20998;&#24067;&#21464;&#21270;&#19979;&#30340;&#26657;&#20934;&#12290;&#28982;&#32780;&#65292;&#20135;&#29983;&#26356;&#22909;&#30340;&#20869;&#37096;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#25216;&#26415;&#23588;&#20854;&#26377;&#20215;&#20540;&#65292;&#22240;&#20026;&#23427;&#20204;&#21487;&#20197;&#38543;&#21518;&#19982;&#20107;&#21518;&#31574;&#30053;&#32467;&#21512;&#20351;&#29992;&#12290;&#22240;&#27492;&#65292;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;G-$\Delta$UQ&#30340;&#26032;&#22411;&#35757;&#32451;&#26694;&#26550;&#65292;&#26088;&#22312;&#25913;&#21892;&#20869;&#22312;&#30340;GNN&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#36890;&#36807;&#26032;&#39062;&#30340;&#22270;&#38170;&#23450;&#31574;&#30053;&#23558;&#38543;&#26426;&#25968;&#25454;&#20013;&#24515;&#21270;&#21407;&#21017;&#24212;&#29992;&#20110;&#22270;&#25968;&#25454;&#65292;&#24182;&#33021;&#22815;&#25903;&#25345;&#37096;&#20998;&#38543;&#26426;&#30340;GNN&#12290;&#34429;&#28982;&#20027;&#27969;&#35266;&#28857;&#26159;&#20026;&#20102;&#33719;&#24471;&#21487;&#38752;&#30340;&#20272;&#35745;&#65292;&#38656;&#35201;&#23436;&#20840;&#38543;&#26426;&#32593;&#32476;&#65292;&#20294;&#25105;&#20204;&#21457;&#29616;&#36890;&#36807;&#21151;&#33021;&#22810;&#26679;&#24615;&#24341;&#20837;&#30340;&#20013;&#35266;&#38170;&#23450;&#21487;&#20197;&#22312;&#20445;&#35777;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
While graph neural networks (GNNs) are widely used for node and graph representation learning tasks, the reliability of GNN uncertainty estimates under distribution shifts remains relatively under-explored. Indeed, while post-hoc calibration strategies can be used to improve in-distribution calibration, they need not also improve calibration under distribution shift. However, techniques which produce GNNs with better intrinsic uncertainty estimates are particularly valuable, as they can always be combined with post-hoc strategies later. Therefore, in this work, we propose G-$\Delta$UQ, a novel training framework designed to improve intrinsic GNN uncertainty estimates. Our framework adapts the principle of stochastic data centering to graph data through novel graph anchoring strategies, and is able to support partially stochastic GNNs. While, the prevalent wisdom is that fully stochastic networks are necessary to obtain reliable estimates, we find that the functional diversity induced b
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAEs&#65289;&#21644;&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#30456;&#32467;&#21512;&#30340;&#26032;&#39062;&#29983;&#25104;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#65288;TSAD&#65289;&#20013;&#30001;&#20110;&#25968;&#25454;&#31232;&#32570;&#24341;&#36215;&#30340;&#28508;&#22312;&#31354;&#38388;&#30340;&#19981;&#36830;&#32493;&#24615;&#23548;&#33268;&#30340;&#37325;&#24314;&#19981;&#31283;&#23450;&#24615;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.03341</link><description>&lt;p&gt;
&#24369;&#22686;&#24378;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#22312;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Weakly Augmented Variational Autoencoder in Time Series Anomaly Detection. (arXiv:2401.03341v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03341
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAEs&#65289;&#21644;&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#30456;&#32467;&#21512;&#30340;&#26032;&#39062;&#29983;&#25104;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#65288;TSAD&#65289;&#20013;&#30001;&#20110;&#25968;&#25454;&#31232;&#32570;&#24341;&#36215;&#30340;&#28508;&#22312;&#31354;&#38388;&#30340;&#19981;&#36830;&#32493;&#24615;&#23548;&#33268;&#30340;&#37325;&#24314;&#19981;&#31283;&#23450;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20854;&#26080;&#30417;&#30563;&#35757;&#32451;&#21644;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#28145;&#24230;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAEs&#65289;&#24050;&#32463;&#25104;&#20026;&#22522;&#20110;&#37325;&#24314;&#30340;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#65288;TSAD&#65289;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#29616;&#26377;&#30340;&#22522;&#20110;VAE&#30340;TSAD&#26041;&#27861;&#65292;&#19981;&#35770;&#26159;&#32479;&#35745;&#26041;&#27861;&#36824;&#26159;&#28145;&#24230;&#26041;&#27861;&#65292;&#37117;&#35843;&#25972;&#20803;&#20808;&#39564;&#20197;&#20272;&#35745;&#26377;&#25928;&#25429;&#33719;&#25968;&#25454;&#20013;&#30340;&#26102;&#31354;&#20381;&#36182;&#20851;&#31995;&#30340;&#20284;&#28982;&#27010;&#29575;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#38754;&#20020;&#30528;&#20869;&#22312;&#25968;&#25454;&#31232;&#32570;&#30340;&#25361;&#25112;&#65292;&#36825;&#22312;&#24322;&#24120;&#26816;&#27979;&#20219;&#21153;&#20013;&#32463;&#24120;&#20986;&#29616;&#12290;&#36825;&#31181;&#31232;&#32570;&#23481;&#26131;&#23548;&#33268;&#28508;&#22312;&#31354;&#38388;&#20013;&#30340;&#28508;&#22312;&#31354;&#27934;&#65292;&#21363;&#28508;&#22312;&#31354;&#38388;&#20013;&#30340;&#19981;&#36830;&#32493;&#21306;&#22495;&#65292;&#23548;&#33268;&#22312;&#36825;&#20123;&#19981;&#36830;&#32493;&#30340;&#31354;&#38388;&#19978;&#30340;&#38750;&#40065;&#26834;&#37325;&#26500;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;VAEs&#19982;&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#32467;&#21512;&#30340;&#26032;&#39062;&#29983;&#25104;&#26694;&#26550;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Due to their unsupervised training and uncertainty estimation, deep Variational Autoencoders (VAEs) have become powerful tools for reconstruction-based Time Series Anomaly Detection (TSAD). Existing VAE-based TSAD methods, either statistical or deep, tune meta-priors to estimate the likelihood probability for effectively capturing spatiotemporal dependencies in the data. However, these methods confront the challenge of inherent data scarcity, which is often the case in anomaly detection tasks. Such scarcity easily leads to latent holes, discontinuous regions in latent space, resulting in non-robust reconstructions on these discontinuous spaces. We propose a novel generative framework that combines VAEs with self-supervised learning (SSL) to address this issue.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24773;&#20917;&#19979;&#26816;&#27979;&#21644;&#20998;&#31867;&#33041;&#32959;&#30244;&#65292;&#24182;&#35299;&#20915;&#20102;&#22312;&#32597;&#35265;&#24773;&#20917;&#19979;&#30340;&#32959;&#30244;&#26816;&#27979;&#38382;&#39064;&#12290;&#30740;&#31350;&#20351;&#29992;&#20102;&#26469;&#33258;&#22269;&#23478;&#33041;&#26144;&#23556;&#23454;&#39564;&#23460;&#30340;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#20462;&#25913;&#26679;&#26412;&#25968;&#37327;&#21644;&#24739;&#32773;&#20998;&#24067;&#65292;&#20351;&#27169;&#22411;&#33021;&#22815;&#24212;&#23545;&#30495;&#23454;&#19990;&#30028;&#22330;&#26223;&#20013;&#30340;&#24322;&#24120;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2401.03302</link><description>&lt;p&gt;
&#34892;&#21160;&#20013;&#30340;&#29616;&#23454;&#20027;&#20041;&#65306;&#20351;&#29992;YOLOv8&#21644;DeiT&#20174;&#21307;&#23398;&#22270;&#20687;&#20013;&#35786;&#26029;&#33041;&#32959;&#30244;&#30340;&#24322;&#24120;&#24863;&#30693;
&lt;/p&gt;
&lt;p&gt;
Realism in Action: Anomaly-Aware Diagnosis of Brain Tumors from Medical Images Using YOLOv8 and DeiT. (arXiv:2401.03302v1 [eess.IV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03302
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24773;&#20917;&#19979;&#26816;&#27979;&#21644;&#20998;&#31867;&#33041;&#32959;&#30244;&#65292;&#24182;&#35299;&#20915;&#20102;&#22312;&#32597;&#35265;&#24773;&#20917;&#19979;&#30340;&#32959;&#30244;&#26816;&#27979;&#38382;&#39064;&#12290;&#30740;&#31350;&#20351;&#29992;&#20102;&#26469;&#33258;&#22269;&#23478;&#33041;&#26144;&#23556;&#23454;&#39564;&#23460;&#30340;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#20462;&#25913;&#26679;&#26412;&#25968;&#37327;&#21644;&#24739;&#32773;&#20998;&#24067;&#65292;&#20351;&#27169;&#22411;&#33021;&#22815;&#24212;&#23545;&#30495;&#23454;&#19990;&#30028;&#22330;&#26223;&#20013;&#30340;&#24322;&#24120;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21307;&#23398;&#31185;&#23398;&#39046;&#22495;&#65292;&#30001;&#20110;&#33041;&#32959;&#30244;&#22312;&#24739;&#32773;&#20013;&#30340;&#32597;&#35265;&#31243;&#24230;&#65292;&#21487;&#38752;&#22320;&#26816;&#27979;&#21644;&#20998;&#31867;&#33041;&#32959;&#30244;&#20173;&#28982;&#26159;&#19968;&#20010;&#33392;&#24040;&#30340;&#25361;&#25112;&#12290;&#22240;&#27492;&#65292;&#22312;&#24322;&#24120;&#24773;&#20917;&#19979;&#26816;&#27979;&#32959;&#30244;&#30340;&#33021;&#21147;&#23545;&#20110;&#30830;&#20445;&#21450;&#26102;&#24178;&#39044;&#21644;&#25913;&#21892;&#24739;&#32773;&#32467;&#26524;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#30740;&#31350;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24773;&#20917;&#19979;&#26816;&#27979;&#21644;&#20998;&#31867;&#33041;&#32959;&#30244;&#12290;&#26469;&#33258;&#22269;&#23478;&#33041;&#26144;&#23556;&#23454;&#39564;&#23460;&#65288;NBML&#65289;&#30340;&#31934;&#36873;&#25968;&#25454;&#38598;&#21253;&#25324;81&#21517;&#24739;&#32773;&#65292;&#20854;&#20013;&#21253;&#25324;30&#20363;&#32959;&#30244;&#30149;&#20363;&#21644;51&#20363;&#27491;&#24120;&#30149;&#20363;&#12290;&#26816;&#27979;&#21644;&#20998;&#31867;&#27969;&#31243;&#34987;&#20998;&#20026;&#20004;&#20010;&#36830;&#32493;&#30340;&#20219;&#21153;&#12290;&#26816;&#27979;&#38454;&#27573;&#21253;&#25324;&#20840;&#38754;&#30340;&#25968;&#25454;&#20998;&#26512;&#21644;&#39044;&#22788;&#29702;&#65292;&#20197;&#20462;&#25913;&#22270;&#20687;&#26679;&#26412;&#21644;&#27599;&#20010;&#31867;&#21035;&#30340;&#24739;&#32773;&#25968;&#37327;&#65292;&#20197;&#31526;&#21512;&#30495;&#23454;&#19990;&#30028;&#22330;&#26223;&#20013;&#30340;&#24322;&#24120;&#20998;&#24067;&#65288;9&#20010;&#27491;&#24120;&#26679;&#26412;&#23545;&#24212;1&#20010;&#32959;&#30244;&#26679;&#26412;&#65289;&#12290;&#27492;&#22806;&#65292;&#22312;&#27979;&#35797;&#20013;&#38500;&#20102;&#24120;&#35265;&#30340;&#35780;&#20272;&#25351;&#26631;&#22806;&#65292;&#25105;&#20204;&#36824;&#37319;&#29992;&#20102;... [&#25688;&#35201;&#38271;&#24230;&#24050;&#36798;&#21040;&#19978;&#38480;]
&lt;/p&gt;
&lt;p&gt;
In the field of medical sciences, reliable detection and classification of brain tumors from images remains a formidable challenge due to the rarity of tumors within the population of patients. Therefore, the ability to detect tumors in anomaly scenarios is paramount for ensuring timely interventions and improved patient outcomes. This study addresses the issue by leveraging deep learning (DL) techniques to detect and classify brain tumors in challenging situations. The curated data set from the National Brain Mapping Lab (NBML) comprises 81 patients, including 30 Tumor cases and 51 Normal cases. The detection and classification pipelines are separated into two consecutive tasks. The detection phase involved comprehensive data analysis and pre-processing to modify the number of image samples and the number of patients of each class to anomaly distribution (9 Normal per 1 Tumor) to comply with real world scenarios. Next, in addition to common evaluation metrics for the testing, we emplo
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20272;&#35745;&#31471;&#21040;&#31471;ASR&#20449;&#20219;&#24230;&#30340;&#26102;&#24577;&#35789;&#20803;&#30456;&#20284;&#24230;&#20998;&#25968;TeLeS&#65292;&#24182;&#29992;&#32553;&#20943;&#25439;&#22833;&#26469;&#35299;&#20915;CEM&#35757;&#32451;&#20013;&#30446;&#26631;&#24471;&#20998;&#25968;&#25454;&#19981;&#24179;&#34913;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.03251</link><description>&lt;p&gt;
TeLeS&#65306;&#29992;&#20110;&#20272;&#35745;&#31471;&#21040;&#31471;ASR&#20449;&#20219;&#24230;&#30340;&#26102;&#24577;&#35789;&#20803;&#30456;&#20284;&#24230;&#20998;&#25968;
&lt;/p&gt;
&lt;p&gt;
TeLeS: Temporal Lexeme Similarity Score to Estimate Confidence in End-to-End ASR. (arXiv:2401.03251v1 [eess.AS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03251
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20272;&#35745;&#31471;&#21040;&#31471;ASR&#20449;&#20219;&#24230;&#30340;&#26102;&#24577;&#35789;&#20803;&#30456;&#20284;&#24230;&#20998;&#25968;TeLeS&#65292;&#24182;&#29992;&#32553;&#20943;&#25439;&#22833;&#26469;&#35299;&#20915;CEM&#35757;&#32451;&#20013;&#30446;&#26631;&#24471;&#20998;&#25968;&#25454;&#19981;&#24179;&#34913;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#31471;&#21040;&#31471;&#65288;E2E&#65289;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#65288;ASR&#65289;&#27169;&#22411;&#30340;&#39044;&#27979;&#20013;&#24471;&#20986;&#20449;&#24515;&#20272;&#35745;&#26377;&#21161;&#20110;ASR&#30340;&#19979;&#28216;&#21644;&#19978;&#28216;&#20219;&#21153;&#12290;&#22522;&#20110;&#31867;&#21035;&#27010;&#29575;&#30340;&#32622;&#20449;&#24230;&#24471;&#20998;&#19981;&#33021;&#20934;&#30830;&#22320;&#34920;&#31034;&#36807;&#20110;&#33258;&#20449;&#30340;ASR&#39044;&#27979;&#30340;&#36136;&#37327;&#12290;&#36741;&#21161;&#32622;&#20449;&#24230;&#20272;&#35745;&#27169;&#22411;&#65288;CEM&#65289;&#21487;&#26657;&#20934;&#36825;&#20123;&#39044;&#27979;&#12290;&#26368;&#20808;&#36827;&#30340;&#35299;&#20915;&#26041;&#26696;&#20351;&#29992;&#20108;&#36827;&#21046;&#30446;&#26631;&#24471;&#20998;&#36827;&#34892;CEM&#35757;&#32451;&#12290;&#28982;&#32780;&#65292;&#20108;&#36827;&#21046;&#26631;&#31614;&#19981;&#33021;&#25581;&#31034;&#39044;&#27979;&#35789;&#30340;&#32454;&#31890;&#24230;&#20449;&#24687;&#65292;&#22914;&#21442;&#32771;&#35821;&#38899;&#21644;&#20551;&#35774;&#35821;&#38899;&#20043;&#38388;&#30340;&#26102;&#24577;&#23545;&#40784;&#20197;&#21450;&#39044;&#27979;&#35789;&#26159;&#21542;&#23436;&#20840;&#38169;&#35823;&#25110;&#21253;&#21547;&#25340;&#20889;&#38169;&#35823;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26102;&#24577;&#35789;&#20803;&#30456;&#20284;&#24230;&#65288;TeLeS&#65289;&#32622;&#20449;&#24230;&#20998;&#25968;&#26469;&#35757;&#32451;CEM&#12290;&#20026;&#20102;&#35299;&#20915;CEM&#35757;&#32451;&#20013;&#30446;&#26631;&#24471;&#20998;&#30340;&#25968;&#25454;&#19981;&#24179;&#34913;&#38382;&#39064;&#65292;&#25105;&#20204;&#20351;&#29992;&#32553;&#20943;&#25439;&#22833;&#26469;&#32858;&#28966;&#20110;&#38590;&#20197;&#23398;&#20064;&#30340;&#25968;&#25454;&#28857;&#24182;&#26368;&#23567;&#21270;&#36731;&#26131;&#23398;&#20064;&#30340;&#25968;&#25454;&#28857;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#22312;&#19977;&#31181;&#35821;&#35328;&#35757;&#32451;&#30340;ASR&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Confidence estimation of predictions from an End-to-End (E2E) Automatic Speech Recognition (ASR) model benefits ASR's downstream and upstream tasks. Class-probability-based confidence scores do not accurately represent the quality of overconfident ASR predictions. An ancillary Confidence Estimation Model (CEM) calibrates the predictions. State-of-the-art (SOTA) solutions use binary target scores for CEM training. However, the binary labels do not reveal the granular information of predicted words, such as temporal alignment between reference and hypothesis and whether the predicted word is entirely incorrect or contains spelling errors. Addressing this issue, we propose a novel Temporal-Lexeme Similarity (TeLeS) confidence score to train CEM. To address the data imbalance of target scores while training CEM, we use shrinkage loss to focus on hard-to-learn data points and minimise the impact of easily learned data points. We conduct experiments with ASR models trained in three languages
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#31070;&#32463;&#20803;&#22914;&#20309;&#36890;&#36807;&#39044;&#27979;&#26102;&#38388;&#24207;&#21015;&#30340;&#26410;&#26469;&#26469;&#29983;&#25104;&#34892;&#20026;&#12290;&#36890;&#36807;&#27491;&#24120;&#27169;&#24577;&#20998;&#35299;&#21487;&#20197;&#23454;&#29616;&#31616;&#21333;&#30340;&#39044;&#27979;&#65292;&#20854;&#20013;&#31070;&#32463;&#20803;&#36890;&#36807;&#23398;&#20064;&#39030;&#23618;&#27169;&#24577;&#24182;&#23558;&#20854;&#36755;&#20837;&#25237;&#24433;&#21040;&#30456;&#20851;&#23376;&#31354;&#38388;&#12290;&#26681;&#25454;&#20449;&#22122;&#27604;&#30340;&#19981;&#21516;&#65292;&#26102;&#38388;&#28388;&#27874;&#22120;&#30340;&#24418;&#29366;&#20250;&#26377;&#25152;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2401.03248</link><description>&lt;p&gt;
&#31070;&#32463;&#20803;&#26102;&#38388;&#28388;&#27874;&#22120;&#20316;&#20026;&#27491;&#24120;&#27169;&#24577;&#25552;&#21462;&#22120;
&lt;/p&gt;
&lt;p&gt;
Neuronal Temporal Filters as Normal Mode Extractors. (arXiv:2401.03248v1 [q-bio.NC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03248
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#31070;&#32463;&#20803;&#22914;&#20309;&#36890;&#36807;&#39044;&#27979;&#26102;&#38388;&#24207;&#21015;&#30340;&#26410;&#26469;&#26469;&#29983;&#25104;&#34892;&#20026;&#12290;&#36890;&#36807;&#27491;&#24120;&#27169;&#24577;&#20998;&#35299;&#21487;&#20197;&#23454;&#29616;&#31616;&#21333;&#30340;&#39044;&#27979;&#65292;&#20854;&#20013;&#31070;&#32463;&#20803;&#36890;&#36807;&#23398;&#20064;&#39030;&#23618;&#27169;&#24577;&#24182;&#23558;&#20854;&#36755;&#20837;&#25237;&#24433;&#21040;&#30456;&#20851;&#23376;&#31354;&#38388;&#12290;&#26681;&#25454;&#20449;&#22122;&#27604;&#30340;&#19981;&#21516;&#65292;&#26102;&#38388;&#28388;&#27874;&#22120;&#30340;&#24418;&#29366;&#20250;&#26377;&#25152;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#22312;&#29983;&#29702;&#24310;&#36831;&#24773;&#20917;&#19979;&#20135;&#29983;&#34892;&#20026;&#65292;&#22823;&#33041;&#24517;&#39035;&#39044;&#27979;&#26410;&#26469;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#36890;&#36807;&#32771;&#34385;&#19968;&#20010;&#31070;&#32463;&#20803;&#23545;&#26631;&#37327;&#26102;&#38388;&#24207;&#21015;&#36755;&#20837;&#30340;&#26410;&#26469;&#36827;&#34892;&#39044;&#27979;&#65292;&#25506;&#35752;&#20102;&#39044;&#27979;&#21487;&#33021;&#26159;&#22823;&#33041;&#21151;&#33021;&#30340;&#26680;&#24515;&#12290;&#20551;&#35774;&#28382;&#21518;&#21521;&#37327;&#65288;&#30001;&#26102;&#38388;&#24207;&#21015;&#30340;&#33509;&#24178;&#36830;&#32493;&#20803;&#32032;&#32452;&#25104;&#30340;&#21521;&#37327;&#65289;&#30340;&#21160;&#21147;&#23398;&#26159;&#23616;&#37096;&#32447;&#24615;&#30340;&#65292;&#27491;&#24120;&#27169;&#24577;&#20998;&#35299;&#23558;&#21160;&#21147;&#23398;&#20998;&#35299;&#20026;&#30456;&#20114;&#29420;&#31435;&#28436;&#21270;&#30340;&#65288;&#29305;&#24449;&#65289;&#27169;&#24577;&#65292;&#20174;&#32780;&#23454;&#29616;&#31616;&#21333;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#25552;&#20986;&#65292;&#31070;&#32463;&#20803;&#23398;&#20064;&#39030;&#23618;&#27169;&#24577;&#65292;&#24182;&#23558;&#20854;&#36755;&#20837;&#25237;&#24433;&#21040;&#30456;&#20851;&#23376;&#31354;&#38388;&#12290;&#26681;&#25454;&#36825;&#20010;&#35299;&#37322;&#65292;&#31070;&#32463;&#20803;&#30340;&#26102;&#38388;&#28388;&#27874;&#22120;&#23545;&#24212;&#20110;&#24191;&#20041;&#29305;&#24449;&#20540;&#38382;&#39064;&#30340;&#24038;&#29305;&#24449;&#21521;&#37327;&#12290;&#25105;&#20204;&#22312;&#30001;&#32447;&#24615;&#31995;&#32479;&#29983;&#25104;&#30340;&#21512;&#25104;&#25968;&#25454;&#30340;&#22122;&#22768;&#35266;&#27979;&#19978;&#23545;&#27492;&#31639;&#27861;&#30340;&#25805;&#20316;&#36827;&#34892;&#20102;&#25968;&#23398;&#20998;&#26512;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#26102;&#38388;&#28388;&#27874;&#22120;&#30340;&#24418;&#29366;&#38543;&#20449;&#22122;&#27604;&#65288;SNR&#65289;&#32780;&#21464;&#21270;&#65306;&#22024;&#26434;&#30340;&#36755;&#20837;&#20135;&#29983;&#19968;&#20010;&#21333;&#30456;&#28388;&#27874;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
To generate actions in the face of physiological delays, the brain must predict the future. Here we explore how prediction may lie at the core of brain function by considering a neuron predicting the future of a scalar time series input. Assuming that the dynamics of the lag vector (a vector composed of several consecutive elements of the time series) are locally linear, Normal Mode Decomposition decomposes the dynamics into independently evolving (eigen-)modes allowing for straightforward prediction. We propose that a neuron learns the top mode and projects its input onto the associated subspace. Under this interpretation, the temporal filter of a neuron corresponds to the left eigenvector of a generalized eigenvalue problem. We mathematically analyze the operation of such an algorithm on noisy observations of synthetic data generated by a linear system. Interestingly, the shape of the temporal filter varies with the signal-to-noise ratio (SNR): a noisy input yields a monophasic filte
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;&#26377;&#30028;&#22495;&#20869;&#29983;&#25104;&#25968;&#25454;&#30340;&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#26041;&#27861;&#65292;&#36890;&#36807;&#25512;&#23548;&#20986;&#24102;&#26377;&#36793;&#30028;&#26465;&#20214;&#30340;&#21453;&#23556;&#27491;&#21521;-&#21453;&#21521;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65292;&#35299;&#20915;&#20102;&#21453;&#23556;&#25193;&#25955;&#27169;&#22411;&#22312;&#36866;&#24212;&#22810;&#26679;&#24615;&#39046;&#22495;&#26102;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2401.03228</link><description>&lt;p&gt;
&#26377;&#32422;&#26463;&#29983;&#25104;&#24314;&#27169;&#30340;&#21453;&#23556;Schr\"odinger&#26725;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Reflected Schr\"odinger Bridge for Constrained Generative Modeling. (arXiv:2401.03228v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03228
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;&#26377;&#30028;&#22495;&#20869;&#29983;&#25104;&#25968;&#25454;&#30340;&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#26041;&#27861;&#65292;&#36890;&#36807;&#25512;&#23548;&#20986;&#24102;&#26377;&#36793;&#30028;&#26465;&#20214;&#30340;&#21453;&#23556;&#27491;&#21521;-&#21453;&#21521;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65292;&#35299;&#20915;&#20102;&#21453;&#23556;&#25193;&#25955;&#27169;&#22411;&#22312;&#36866;&#24212;&#22810;&#26679;&#24615;&#39046;&#22495;&#26102;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#24050;&#32463;&#25104;&#20026;&#23454;&#38469;&#24212;&#29992;&#20013;&#22823;&#35268;&#27169;&#29983;&#25104;&#27169;&#22411;&#30340;&#39318;&#36873;&#26041;&#27861;&#12290;&#36825;&#20123;&#24212;&#29992;&#36890;&#24120;&#28041;&#21450;&#22312;&#26377;&#30028;&#22495;&#20869;&#38480;&#21046;&#30340;&#25968;&#25454;&#20998;&#24067;&#65292;&#36890;&#24120;&#38656;&#35201; ad-hoc &#38408;&#20540;&#25216;&#26415;&#26469;&#24378;&#21046;&#36793;&#30028;&#12290;&#21453;&#23556;&#25193;&#25955;&#27169;&#22411;&#26088;&#22312;&#36890;&#36807;&#30001;&#21453;&#23556;&#24067;&#26391;&#36816;&#21160;&#25511;&#21046;&#30340;&#21518;&#21521;&#36807;&#31243;&#29983;&#25104;&#25968;&#25454;&#20998;&#24067;&#65292;&#20197;&#22686;&#21152;&#27867;&#21270;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#21453;&#23556;&#25193;&#25955;&#27169;&#22411;&#21487;&#33021;&#19981;&#23481;&#26131;&#36866;&#24212;&#21508;&#31181;&#39046;&#22495;&#65292;&#38656;&#35201;&#27491;&#30830;&#23548;&#20986;&#30340;&#24046;&#21516;&#32986;&#26144;&#23556;&#65292;&#24182;&#19988;&#19981;&#33021;&#20445;&#35777;&#26368;&#20248;&#36755;&#36816;&#29305;&#24615;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#21453;&#23556;Schr\"odinger&#26725;&#31639;&#27861;&#65306;&#19968;&#31181;&#29992;&#20110;&#22312;&#21508;&#31181;&#26377;&#30028;&#22495;&#20869;&#29983;&#25104;&#25968;&#25454;&#30340;&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#26041;&#27861;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#24102;&#26377; Neumann &#21644; Robin &#36793;&#30028;&#26465;&#20214;&#30340;&#20248;&#38597;&#21453;&#23556;&#27491;&#21521;-&#21453;&#21521;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65292;&#24182;&#23558;&#22522;&#20110;&#25955;&#24230;&#30340;&#20284;&#28982;&#35757;&#32451;&#25193;&#23637;&#21040;&#26377;&#30028;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models have become the go-to method for large-scale generative models in real-world applications. These applications often involve data distributions confined within bounded domains, typically requiring ad-hoc thresholding techniques for boundary enforcement. Reflected diffusion models (Lou23) aim to enhance generalizability by generating the data distribution through a backward process governed by reflected Brownian motion. However, reflected diffusion models may not easily adapt to diverse domains without the derivation of proper diffeomorphic mappings and do not guarantee optimal transport properties. To overcome these limitations, we introduce the Reflected Schrodinger Bridge algorithm: an entropy-regularized optimal transport approach tailored for generating data within diverse bounded domains. We derive elegant reflected forward-backward stochastic differential equations with Neumann and Robin boundary conditions, extend divergence-based likelihood training to bounded d
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#20808;&#39564;&#20449;&#24687;&#65292;&#25913;&#36827;&#20102;Robbins-Monro&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#20808;&#39564;&#20449;&#24687;&#30340;Robbins-Monro&#24207;&#21015;&#27604;&#26631;&#20934;&#24207;&#21015;&#25910;&#25947;&#26356;&#24555;&#65292;&#29305;&#21035;&#26159;&#22312;&#21069;&#20960;&#27493;&#12290;</title><link>http://arxiv.org/abs/2401.03206</link><description>&lt;p&gt;
&#19968;&#31181;&#21487;&#20197;&#21033;&#29992;&#20808;&#39564;&#20449;&#24687;&#21152;&#24555;&#25910;&#25947;&#36895;&#24230;&#30340;Robbins-Monro&#24207;&#21015;
&lt;/p&gt;
&lt;p&gt;
A Robbins--Monro Sequence That Can Exploit Prior Information For Faster Convergence. (arXiv:2401.03206v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03206
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#20808;&#39564;&#20449;&#24687;&#65292;&#25913;&#36827;&#20102;Robbins-Monro&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#20808;&#39564;&#20449;&#24687;&#30340;Robbins-Monro&#24207;&#21015;&#27604;&#26631;&#20934;&#24207;&#21015;&#25910;&#25947;&#26356;&#24555;&#65292;&#29305;&#21035;&#26159;&#22312;&#21069;&#20960;&#27493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#30446;&#26631;&#28857;&#30340;&#20808;&#39564;&#20449;&#24687;&#24341;&#20837;Robbins-Monro&#36845;&#20195;&#26469;&#25913;&#21892;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#23454;&#29616;&#20102;&#19981;&#38656;&#35201;&#22238;&#24402;&#27169;&#22411;&#30340;&#20808;&#39564;&#20449;&#24687;&#30340;&#34701;&#21512;&#65292;&#36825;&#20063;&#20250;&#24102;&#26469;&#39069;&#22806;&#30340;&#32422;&#26463;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#20808;&#39564;&#20449;&#24687;&#30340;Robbins-Monro&#24207;&#21015;&#23545;&#20110;&#24191;&#27867;&#30340;&#20808;&#39564;&#20998;&#24067;&#37117;&#26159;&#25910;&#25947;&#30340;&#65292;&#21363;&#20351;&#26159;&#38169;&#35823;&#30340;&#20808;&#39564;&#20998;&#24067;&#65292;&#22914;&#39640;&#26031;&#20998;&#24067;&#12289;&#39640;&#26031;&#20998;&#24067;&#30340;&#21152;&#26435;&#21644;&#65288;&#20363;&#22914;&#22312;&#26680;&#23494;&#24230;&#20272;&#35745;&#20013;&#65289;&#65292;&#20197;&#21450;&#22823;&#20110;&#38646;&#30340;&#26377;&#30028;&#20219;&#24847;&#20998;&#24067;&#20989;&#25968;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#25968;&#20540;&#20998;&#26512;&#26469;&#20102;&#35299;&#24207;&#21015;&#30340;&#24615;&#33021;&#21644;&#21442;&#25968;&#30340;&#24433;&#21709;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#20808;&#39564;&#20449;&#24687;&#30340;Robbins-Monro&#24207;&#21015;&#27604;&#26631;&#20934;&#24207;&#21015;&#25910;&#25947;&#26356;&#24555;&#65292;&#29305;&#21035;&#26159;&#22312;&#21069;&#20960;&#27493;&#65292;&#36825;&#23545;&#20110;&#27979;&#37327;&#20989;&#25968;&#25968;&#30446;&#26377;&#38480;&#21644;&#35823;&#24046;&#36739;&#22823;&#30340;&#24212;&#29992;&#29305;&#21035;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new method to improve the convergence speed of the Robbins-Monro algorithm by introducing prior information about the target point into the Robbins-Monro iteration. We achieve the incorporation of prior information without the need of a -- potentially wrong -- regression model, which would also entail additional constraints. We show that this prior-information Robbins-Monro sequence is convergent for a wide range of prior distributions, even wrong ones, such as Gaussian, weighted sum of Gaussians, e.g., in a kernel density estimate, as well as bounded arbitrary distribution functions greater than zero. We furthermore analyse the sequence numerically to understand its performance and the influence of parameters. The results demonstrate that the prior-information Robbins-Monro sequence converges faster than the standard one, especially during the first steps, which are particularly important for applications where the number of function measurements is limited, and when the 
&lt;/p&gt;</description></item><item><title>SPQR&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#23574;&#23792;&#38543;&#26426;&#27169;&#22411;&#26469;&#25511;&#21046;&#24378;&#21270;&#23398;&#20064;&#20013;Q-&#38598;&#21512;&#30340;&#29420;&#31435;&#24615;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#27491;&#21017;&#21270;&#25439;&#22833;&#26469;&#20811;&#26381;&#36807;&#39640;&#20272;&#35745;&#20559;&#24046;&#12290;</title><link>http://arxiv.org/abs/2401.03137</link><description>&lt;p&gt;
SPQR:&#20351;&#29992;&#23574;&#23792;&#38543;&#26426;&#27169;&#22411;&#25511;&#21046;Q-&#38598;&#21512;&#30340;&#29420;&#31435;&#24615;&#65292;&#29992;&#20110;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
SPQR: Controlling Q-ensemble Independence with Spiked Random Model for Reinforcement Learning. (arXiv:2401.03137v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03137
&lt;/p&gt;
&lt;p&gt;
SPQR&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#23574;&#23792;&#38543;&#26426;&#27169;&#22411;&#26469;&#25511;&#21046;&#24378;&#21270;&#23398;&#20064;&#20013;Q-&#38598;&#21512;&#30340;&#29420;&#31435;&#24615;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#27491;&#21017;&#21270;&#25439;&#22833;&#26469;&#20811;&#26381;&#36807;&#39640;&#20272;&#35745;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32531;&#35299;&#36807;&#39640;&#20272;&#35745;&#20559;&#24046;&#26159;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#22312;&#26356;&#22797;&#26434;&#20219;&#21153;&#25110;&#21253;&#21547;&#36229;&#20986;&#20998;&#24067;&#25968;&#25454;&#30340;&#31163;&#32447;&#25968;&#25454;&#38598;&#19978;&#33719;&#24471;&#25104;&#21151;&#34920;&#29616;&#30340;&#20851;&#38190;&#25361;&#25112;&#12290;&#20026;&#20102;&#20811;&#26381;&#36807;&#39640;&#20272;&#35745;&#20559;&#24046;&#65292;&#30740;&#31350;&#20102;Q-learning&#30340;&#38598;&#25104;&#26041;&#27861;&#26469;&#21033;&#29992;&#22810;&#20010;Q&#20989;&#25968;&#30340;&#22810;&#26679;&#24615;&#12290;&#30001;&#20110;&#32593;&#32476;&#21021;&#22987;&#21270;&#19968;&#30452;&#26159;&#20419;&#36827;Q&#20989;&#25968;&#22810;&#26679;&#24615;&#30340;&#20027;&#35201;&#26041;&#27861;&#65292;&#22240;&#27492;&#22312;&#25991;&#29486;&#20013;&#30740;&#31350;&#20102;&#21551;&#21457;&#24335;&#35774;&#35745;&#30340;&#22810;&#26679;&#24615;&#27880;&#20837;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#24182;&#26410;&#23581;&#35797;&#20174;&#29702;&#35770;&#35282;&#24230;&#20445;&#35777;&#38598;&#25104;&#30340;&#29420;&#31435;&#24615;&#12290;&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;Q-&#38598;&#21512;&#29420;&#31435;&#24615;&#30340;&#26032;&#22411;&#27491;&#21017;&#21270;&#25439;&#22833;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#23574;&#23792;Wishart Q-&#38598;&#21512;&#29420;&#31435;&#24615;&#27491;&#21017;&#21270;&#26041;&#27861;&#65288;SPQR&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Alleviating overestimation bias is a critical challenge for deep reinforcement learning to achieve successful performance on more complex tasks or offline datasets containing out-of-distribution data. In order to overcome overestimation bias, ensemble methods for Q-learning have been investigated to exploit the diversity of multiple Q-functions. Since network initialization has been the predominant approach to promote diversity in Q-functions, heuristically designed diversity injection methods have been studied in the literature. However, previous studies have not attempted to approach guaranteed independence over an ensemble from a theoretical perspective. By introducing a novel regularization loss for Q-ensemble independence based on random matrix theory, we propose spiked Wishart Q-ensemble independence regularization (SPQR) for reinforcement learning. Specifically, we modify the intractable hypothesis testing criterion for the Q-ensemble independence into a tractable KL divergence 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23376;&#31354;&#38388;&#31435;&#26041;&#27491;&#21017;&#21270;&#29275;&#39039;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#35299;&#20915;&#20984;&#20248;&#21270;&#38382;&#39064;&#26102;&#23454;&#29616;&#26080;&#32500;&#24230;&#30456;&#20851;&#30340;&#20840;&#23616;&#25910;&#25947;&#36895;&#24230;&#65292;&#36890;&#36807;&#22312;&#20302;&#32500;&#23376;&#31354;&#38388;&#19978;&#36827;&#34892;&#20108;&#38454;&#26356;&#26032;&#65292;&#20811;&#26381;&#20102;&#39640;&#32500;&#38382;&#39064;&#20013;&#20869;&#23384;&#38656;&#27714;&#21644;&#35745;&#31639;&#25104;&#26412;&#22823;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.03058</link><description>&lt;p&gt;
Krylov&#31435;&#26041;&#27491;&#21017;&#21270;&#29275;&#39039;&#27861;&#65306;&#20855;&#26377;&#26080;&#32500;&#25910;&#25947;&#36895;&#24230;&#30340;&#23376;&#31354;&#38388;&#20108;&#38454;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Krylov Cubic Regularized Newton: A Subspace Second-Order Method with Dimension-Free Convergence Rate. (arXiv:2401.03058v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03058
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23376;&#31354;&#38388;&#31435;&#26041;&#27491;&#21017;&#21270;&#29275;&#39039;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#35299;&#20915;&#20984;&#20248;&#21270;&#38382;&#39064;&#26102;&#23454;&#29616;&#26080;&#32500;&#24230;&#30456;&#20851;&#30340;&#20840;&#23616;&#25910;&#25947;&#36895;&#24230;&#65292;&#36890;&#36807;&#22312;&#20302;&#32500;&#23376;&#31354;&#38388;&#19978;&#36827;&#34892;&#20108;&#38454;&#26356;&#26032;&#65292;&#20811;&#26381;&#20102;&#39640;&#32500;&#38382;&#39064;&#20013;&#20869;&#23384;&#38656;&#27714;&#21644;&#35745;&#31639;&#25104;&#26412;&#22823;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20108;&#38454;&#20248;&#21270;&#31639;&#27861;&#65292;&#22914;&#31435;&#26041;&#27491;&#21017;&#21270;&#29275;&#39039;&#27861;&#65292;&#20197;&#20854;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;&#32780;&#38395;&#21517;&#65307;&#28982;&#32780;&#65292;&#22312;&#39640;&#32500;&#38382;&#39064;&#20013;&#65292;&#23427;&#20204;&#21464;&#24471;&#19981;&#23454;&#29992;&#65292;&#22240;&#20026;&#38656;&#35201;&#22823;&#37327;&#30340;&#20869;&#23384;&#21644;&#35745;&#31639;&#25104;&#26412;&#12290;&#19968;&#20010;&#26377;&#21069;&#26223;&#30340;&#26041;&#27861;&#26159;&#22312;&#20302;&#32500;&#23376;&#31354;&#38388;&#20013;&#25191;&#34892;&#20108;&#38454;&#26356;&#26032;&#65292;&#20174;&#32780;&#20135;&#29983;&#23376;&#31354;&#38388;&#20108;&#38454;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22823;&#22810;&#25968;&#23376;&#31354;&#38388;&#20108;&#38454;&#26041;&#27861;&#38543;&#26426;&#36873;&#25321;&#23376;&#31354;&#38388;&#65292;&#22240;&#27492;&#25910;&#25947;&#36895;&#24230;&#36739;&#24930;&#65292;&#36825;&#21462;&#20915;&#20110;&#38382;&#39064;&#30340;&#32500;&#24230;d&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23376;&#31354;&#38388;&#31435;&#26041;&#27491;&#21017;&#21270;&#29275;&#39039;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#36798;&#21040;&#20102;&#19968;&#20010;&#32500;&#24230;&#26080;&#20851;&#30340;&#20840;&#23616;&#25910;&#25947;&#36895;&#24230;&#65292;&#20026;${O}\left(\frac{1}{mk}+\frac{1}{k^2}\right)$&#12290;&#36825;&#37324;&#65292;m&#34920;&#31034;&#23376;&#31354;&#38388;&#32500;&#24230;&#65292;&#21487;&#20197;&#26174;&#33879;&#23567;&#20110;d&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#21019;&#26032;&#19981;&#26159;&#37319;&#29992;&#38543;&#26426;&#23376;&#31354;&#38388;&#65292;&#32780;&#26159;&#36827;&#34892;&#31435;&#26041;&#27491;&#21017;&#21270;...
&lt;/p&gt;
&lt;p&gt;
Second-order optimization methods, such as cubic regularized Newton methods, are known for their rapid convergence rates; nevertheless, they become impractical in high-dimensional problems due to their substantial memory requirements and computational costs. One promising approach is to execute second-order updates within a lower-dimensional subspace, giving rise to subspace second-order methods. However, the majority of existing subspace second-order methods randomly select subspaces, consequently resulting in slower convergence rates depending on the problem's dimension $d$. In this paper, we introduce a novel subspace cubic regularized Newton method that achieves a dimension-independent global convergence rate of ${O}\left(\frac{1}{mk}+\frac{1}{k^2}\right)$ for solving convex optimization problems. Here, $m$ represents the subspace dimension, which can be significantly smaller than $d$. Instead of adopting a random subspace, our primary innovation involves performing the cubic regul
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#40065;&#26834;&#30340;&#20998;&#20301;&#25968;Huber&#25439;&#22833;&#20989;&#25968;&#65292;&#22312;&#20998;&#24067;&#24378;&#21270;&#23398;&#20064;&#20013;&#36890;&#36807;&#25429;&#25417;&#22122;&#22768;&#24182;&#35843;&#25972;&#21442;&#25968;&#26469;&#22686;&#24378;&#23545;&#24322;&#24120;&#20540;&#30340;&#40065;&#26834;&#24615;&#12290;&#23454;&#35777;&#27979;&#35797;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.02325</link><description>&lt;p&gt;
&#20998;&#24067;&#24378;&#21270;&#23398;&#20064;&#20013;&#20855;&#26377;&#21487;&#35299;&#37322;&#21442;&#25968;&#35843;&#25972;&#30340;&#40065;&#26834;&#20998;&#20301;&#25968;Huber&#25439;&#22833;
&lt;/p&gt;
&lt;p&gt;
A Robust Quantile Huber Loss With Interpretable Parameter Adjustment In Distributional Reinforcement Learning. (arXiv:2401.02325v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02325
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#40065;&#26834;&#30340;&#20998;&#20301;&#25968;Huber&#25439;&#22833;&#20989;&#25968;&#65292;&#22312;&#20998;&#24067;&#24378;&#21270;&#23398;&#20064;&#20013;&#36890;&#36807;&#25429;&#25417;&#22122;&#22768;&#24182;&#35843;&#25972;&#21442;&#25968;&#26469;&#22686;&#24378;&#23545;&#24322;&#24120;&#20540;&#30340;&#40065;&#26834;&#24615;&#12290;&#23454;&#35777;&#27979;&#35797;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#24378;&#21270;&#23398;&#20064;&#36890;&#36807;&#26368;&#23567;&#21270;&#20998;&#20301;&#25968;Huber&#25439;&#22833;&#20989;&#25968;&#26469;&#20272;&#35745;&#22238;&#25253;&#20998;&#24067;&#65292;&#35813;&#20989;&#25968;&#20174;&#39640;&#26031;&#20998;&#24067;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#35745;&#31639;&#20013;&#20135;&#29983;&#65292;&#25429;&#25417;&#21040;&#24403;&#21069;&#21644;&#30446;&#26631;&#20998;&#20301;&#25968;&#20540;&#20013;&#30340;&#22122;&#22768;&#12290;&#19982;&#32463;&#20856;&#30340;&#20998;&#20301;&#25968;Huber&#25439;&#22833;&#30456;&#27604;&#65292;&#36825;&#31181;&#21019;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#22686;&#24378;&#20102;&#23545;&#24322;&#24120;&#20540;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#19988;&#36890;&#36807;&#36817;&#20284;&#25968;&#25454;&#20013;&#22122;&#22768;&#30340;&#25968;&#37327;&#26469;&#35843;&#25972;&#21442;&#25968;&#12290;&#23454;&#35777;&#27979;&#35797;&#22312;&#20998;&#24067;&#24378;&#21270;&#23398;&#20064;&#30340;&#24120;&#35265;&#24212;&#29992;Atari&#28216;&#25103;&#21644;&#26368;&#36817;&#30340;&#23545;&#20914;&#31574;&#30053;&#20013;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distributional Reinforcement Learning (RL) estimates return distribution mainly by learning quantile values via minimizing the quantile Huber loss function, entailing a threshold parameter often selected heuristically or via hyperparameter search, which may not generalize well and can be suboptimal. This paper introduces a generalized quantile Huber loss function derived from Wasserstein distance (WD) calculation between Gaussian distributions, capturing noise in predicted (current) and target (Bellman-updated) quantile values. Compared to the classical quantile Huber loss, this innovative loss function enhances robustness against outliers. Notably, the classical Huber loss function can be seen as an approximation of our proposed loss, enabling parameter adjustment by approximating the amount of noise in the data during the learning process. Empirical tests on Atari games, a common application in distributional RL, and a recent hedging strategy using distributional RL, validate the eff
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25345;&#32493;&#33021;&#37327;&#26041;&#27861;&#30740;&#31350;&#20102;${\Lambda}$CDM&#23431;&#23449;&#23398;&#20013;&#30340;&#23618;&#27425;&#32858;&#31867;&#65292;&#21457;&#29616;&#25345;&#32493;&#33021;&#37327;&#19982;&#32418;&#31227;&#20540;&#20043;&#38388;&#23384;&#22312;&#30456;&#20851;&#24615;&#65292;&#25581;&#31034;&#20102;&#23431;&#23449;&#32467;&#26500;&#30340;&#21160;&#21147;&#23398;&#29305;&#24449;&#12290;</title><link>http://arxiv.org/abs/2401.01988</link><description>&lt;p&gt;
${\Lambda}$CDM&#23431;&#23449;&#23398;&#20013;&#30340;&#23618;&#27425;&#32858;&#31867;&#36890;&#36807;&#25345;&#32493;&#33021;&#37327;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Hierarchical Clustering in ${\Lambda}$CDM Cosmologies via Persistence Energy. (arXiv:2401.01988v1 [astro-ph.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01988
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25345;&#32493;&#33021;&#37327;&#26041;&#27861;&#30740;&#31350;&#20102;${\Lambda}$CDM&#23431;&#23449;&#23398;&#20013;&#30340;&#23618;&#27425;&#32858;&#31867;&#65292;&#21457;&#29616;&#25345;&#32493;&#33021;&#37327;&#19982;&#32418;&#31227;&#20540;&#20043;&#38388;&#23384;&#22312;&#30456;&#20851;&#24615;&#65292;&#25581;&#31034;&#20102;&#23431;&#23449;&#32467;&#26500;&#30340;&#21160;&#21147;&#23398;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#30340;&#20808;&#36827;&#26041;&#27861;&#65292;&#30740;&#31350;&#23431;&#23449;&#32593;&#32476;&#30340;&#32467;&#26500;&#28436;&#21270;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#21040;&#21033;&#29992;&#25345;&#32493;&#20449;&#21495;&#36825;&#19968;&#21019;&#26032;&#26041;&#27861;&#65292;&#23558;&#25345;&#32493;&#22270;&#37325;&#26032;&#27010;&#24565;&#21270;&#20026;$\mathbb R^2_+$&#31354;&#38388;&#20013;&#30340;&#20449;&#21495;&#65292;&#20174;&#32780;&#23454;&#29616;&#25345;&#32493;&#22270;&#30340;&#23884;&#20837;&#12290;&#21033;&#29992;&#36825;&#31181;&#26041;&#27861;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#19977;&#31181;&#20856;&#22411;&#30340;&#23431;&#23449;&#32467;&#26500;&#65306;&#22242;&#31751;&#12289;&#32420;&#32500;&#21644;&#34394;&#31354;&#12290;&#20854;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#21457;&#29616;&#26159;&#25345;&#32493;&#33021;&#37327;&#19982;&#32418;&#31227;&#20540;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#23558;&#25345;&#32493;&#21516;&#35843;&#19982;&#23431;&#23449;&#32467;&#26500;&#30340;&#28436;&#21270;&#32852;&#31995;&#36215;&#26469;&#65292;&#24182;&#25552;&#20379;&#20102;&#26377;&#20851;&#23431;&#23449;&#32467;&#26500;&#21160;&#21147;&#23398;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this research, we investigate the structural evolution of the cosmic web, employing advanced methodologies from Topological Data Analysis. Our approach involves leveraging $Persistence$ $Signals$, an innovative method from recent literature that facilitates the embedding of persistence diagrams into vector spaces by re-conceptualizing them as signals in $\mathbb R^2_+$. Utilizing this methodology, we analyze three quintessential cosmic structures: clusters, filaments, and voids. A central discovery is the correlation between $Persistence$ $Energy$ and redshift values, linking persistent homology with cosmic evolution and providing insights into the dynamics of cosmic structures.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#32593;&#32476;&#37325;&#24314;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#27425;&#20108;&#27425;&#26102;&#38388;&#20869;&#23454;&#29616;&#32467;&#26524;&#65292;&#36890;&#36807;&#38543;&#26426;&#30340;&#20108;&#38454;&#37051;&#23621;&#25628;&#32034;&#20135;&#29983;&#26368;&#20339;&#30340;&#36793;&#20505;&#36873;&#12290;</title><link>http://arxiv.org/abs/2401.01404</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#30340;&#23376;&#20108;&#27425;&#26102;&#38388;&#32593;&#32476;&#37325;&#24314;
&lt;/p&gt;
&lt;p&gt;
Scalable network reconstruction in subquadratic time. (arXiv:2401.01404v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01404
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#32593;&#32476;&#37325;&#24314;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#27425;&#20108;&#27425;&#26102;&#38388;&#20869;&#23454;&#29616;&#32467;&#26524;&#65292;&#36890;&#36807;&#38543;&#26426;&#30340;&#20108;&#38454;&#37051;&#23621;&#25628;&#32034;&#20135;&#29983;&#26368;&#20339;&#30340;&#36793;&#20505;&#36873;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#37325;&#24314;&#26159;&#25351;&#22312;&#21482;&#26377;&#20851;&#20110;&#26465;&#20214;&#20598;&#32852;&#30340;&#35266;&#27979;&#25968;&#25454;&#65292;&#20363;&#22914;&#26102;&#38388;&#24207;&#21015;&#25110;&#22270;&#27169;&#22411;&#30340;&#29420;&#31435;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#65292;&#30830;&#23450;N&#20010;&#33410;&#28857;&#20043;&#38388;&#26410;&#35266;&#27979;&#21040;&#30340;&#25104;&#23545;&#32806;&#21512;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#25552;&#20986;&#30340;&#31639;&#27861;&#30340;&#21487;&#25193;&#23637;&#24615;&#30340;&#20027;&#35201;&#38556;&#30861;&#26159;&#20284;&#20046;&#26080;&#27861;&#36991;&#20813;&#30340;&#20108;&#27425;&#22797;&#26434;&#24230;O(N^2)&#65292;&#21363;&#35201;&#32771;&#34385;&#27599;&#31181;&#21487;&#33021;&#30340;&#25104;&#23545;&#32806;&#21512;&#33267;&#23569;&#19968;&#27425;&#65292;&#23613;&#31649;&#22823;&#22810;&#25968;&#24863;&#20852;&#36259;&#30340;&#32593;&#32476;&#37117;&#26159;&#31232;&#30095;&#30340;&#65292;&#38750;&#38646;&#32806;&#21512;&#30340;&#25968;&#37327;&#21482;&#26377;O(N)&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#24191;&#27867;&#37325;&#24314;&#38382;&#39064;&#30340;&#36890;&#29992;&#31639;&#27861;&#65292;&#20854;&#22312;&#23376;&#20108;&#27425;&#26102;&#38388;&#20869;&#23454;&#29616;&#32467;&#26524;&#65292;&#20854;&#25968;&#25454;&#30456;&#20851;&#22797;&#26434;&#24230;&#23485;&#26494;&#19978;&#30028;&#20026;O(N^(3/2)logN)&#65292;&#20294;&#20855;&#26377;&#26356;&#20856;&#22411;&#30340;&#23545;&#25968;&#32447;&#24615;&#22797;&#26434;&#24230;O(Nlog^2 N)&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20381;&#36182;&#20110;&#19968;&#20010;&#38543;&#26426;&#30340;&#20108;&#38454;&#37051;&#23621;&#25628;&#32034;&#65292;&#20135;&#29983;&#20102;&#26368;&#20339;&#30340;&#36793;&#20505;&#36873;&#12290;
&lt;/p&gt;
&lt;p&gt;
Network reconstruction consists in determining the unobserved pairwise couplings between $N$ nodes given only observational data on the resulting behavior that is conditioned on those couplings -- typically a time-series or independent samples from a graphical model. A major obstacle to the scalability of algorithms proposed for this problem is a seemingly unavoidable quadratic complexity of $O(N^2)$, corresponding to the requirement of each possible pairwise coupling being contemplated at least once, despite the fact that most networks of interest are sparse, with a number of non-zero couplings that is only $O(N)$. Here we present a general algorithm applicable to a broad range of reconstruction problems that achieves its result in subquadratic time, with a data-dependent complexity loosely upper bounded by $O(N^{3/2}\log N)$, but with a more typical log-linear complexity of $O(N\log^2N)$. Our algorithm relies on a stochastic second neighbor search that produces the best edge candidat
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#23558;&#40065;&#26834;&#30340;&#39640;&#26031;&#36807;&#31243;&#22343;&#21248;&#35823;&#24046;&#30028;&#38480;&#25193;&#23637;&#21040;&#22810;&#20219;&#21153;&#35774;&#32622;&#20013;&#65292;&#20197;&#35299;&#20915;&#23433;&#20840;&#22312;&#32447;&#20248;&#21270;&#20013;&#36229;&#21442;&#25968;&#26410;&#30693;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2312.07281</link><description>&lt;p&gt;
&#23433;&#20840;&#30340;&#22810;&#20219;&#21153;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Safe Multi-Task Bayesian Optimization. (arXiv:2312.07281v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.07281
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#23558;&#40065;&#26834;&#30340;&#39640;&#26031;&#36807;&#31243;&#22343;&#21248;&#35823;&#24046;&#30028;&#38480;&#25193;&#23637;&#21040;&#22810;&#20219;&#21153;&#35774;&#32622;&#20013;&#65292;&#20197;&#35299;&#20915;&#23433;&#20840;&#22312;&#32447;&#20248;&#21270;&#20013;&#36229;&#21442;&#25968;&#26410;&#30693;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#24050;&#25104;&#20026;&#23433;&#20840;&#22312;&#32447;&#31995;&#32479;&#20248;&#21270;&#30340;&#24378;&#22823;&#24037;&#20855;&#65292;&#22240;&#20854;&#39640;&#26679;&#26412;&#25928;&#29575;&#21644;&#22122;&#22768;&#20581;&#22766;&#24615;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#21152;&#24555;&#36807;&#31243;&#65292;&#21487;&#20197;&#23558;&#20943;&#23569;&#30340;&#29289;&#29702;&#27169;&#22411;&#32435;&#20837;&#20248;&#21270;&#36807;&#31243;&#20013;&#20197;&#21152;&#36895;&#36807;&#31243;&#65292;&#22240;&#20026;&#36825;&#20123;&#27169;&#22411;&#33021;&#22815;&#25552;&#20379;&#23545;&#23454;&#38469;&#31995;&#32479;&#30340;&#36817;&#20284;&#65292;&#24182;&#19988;&#20174;&#20013;&#36827;&#34892;&#37319;&#26679;&#35201;&#20415;&#23452;&#24471;&#22810;&#12290;&#27169;&#22411;&#19982;&#29616;&#23454;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#30001;&#39069;&#22806;&#30340;&#36229;&#21442;&#25968;&#34920;&#31034;&#65292;&#24182;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#23398;&#20064;&#12290;&#23433;&#20840;&#24615;&#26159;&#36125;&#21494;&#26031;&#20248;&#21270;&#31561;&#22312;&#32447;&#20248;&#21270;&#26041;&#27861;&#30340;&#37325;&#35201;&#26631;&#20934;&#65292;&#26368;&#36817;&#30340;&#25991;&#29486;&#24050;&#32463;&#35299;&#20915;&#20102;&#27492;&#38382;&#39064;&#65292;&#24182;&#22312;&#24050;&#30693;&#36229;&#21442;&#25968;&#30340;&#20551;&#35774;&#19979;&#25552;&#20379;&#20102;&#23433;&#20840;&#20445;&#38556;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#36825;&#26159;&#19981;&#36866;&#29992;&#30340;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#40065;&#26834;&#39640;&#26031;&#36807;&#31243;&#22343;&#21248;&#35823;&#24046;&#30028;&#38480;&#65292;&#20197;&#28385;&#36275;&#22810;&#20219;&#21153;&#35774;&#32622;&#65292;&#20854;&#20013;&#28041;&#21450;&#20174;&#36229;&#21442;&#25968;&#21518;&#39564;&#20998;&#24067;&#35745;&#31639;&#32622;&#20449;&#21306;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization has become a powerful tool for safe online optimization of systems, due to its high sample efficiency and noise robustness. For further speed-up reduced physical models of the system can be incorporated into the optimization to accelerate the process, since the models are able to offer an approximation of the actual system, and sampling from them is significantly cheaper. The similarity between model and reality is represented by additional hyperparameters and learned within the optimization process. Safety is an important criteria for online optimization methods like Bayesian optimization, which has been addressed by recent literature, which provide safety guarantees under the assumption of known hyperparameters. However, in practice this is not applicable. Therefore, we extend the robust Gaussian process uniform error bounds to meet the multi-task setting, which involves the calculation of a confidence region from the hyperparameter posterior distribution utiliz
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#38598;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#24341;&#20837;&#21464;&#20998;&#25512;&#29702;&#26694;&#26550;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#39640;&#26031;&#36807;&#31243;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#24182;&#19988;&#26377;&#25928;&#22320;&#21033;&#29992;&#20102;&#28508;&#22312;&#29366;&#24577;&#21644;&#21160;&#21147;&#23398;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#20943;&#23569;&#20102;&#21464;&#20998;&#21442;&#25968;&#30340;&#25968;&#37327;&#12290;</title><link>http://arxiv.org/abs/2312.05910</link><description>&lt;p&gt;
&#38598;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#19982;&#39640;&#26031;&#36807;&#31243;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#22312;&#38750;&#22343;&#22330;&#21644;&#22312;&#32447;&#25512;&#29702;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Ensemble Kalman Filtering Meets Gaussian Process SSM for Non-Mean-Field and Online Inference. (arXiv:2312.05910v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.05910
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#38598;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#24341;&#20837;&#21464;&#20998;&#25512;&#29702;&#26694;&#26550;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#39640;&#26031;&#36807;&#31243;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#24182;&#19988;&#26377;&#25928;&#22320;&#21033;&#29992;&#20102;&#28508;&#22312;&#29366;&#24577;&#21644;&#21160;&#21147;&#23398;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#20943;&#23569;&#20102;&#21464;&#20998;&#21442;&#25968;&#30340;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65288;GPSSMs&#65289;&#26159;&#19968;&#31181;&#22810;&#21151;&#33021;&#21644;&#21407;&#21017;&#24615;&#30340;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;GPSSMs&#21464;&#20998;&#23398;&#20064;&#21644;&#25512;&#29702;&#26041;&#27861;&#36890;&#24120;&#38656;&#35201;&#20248;&#21270;&#22823;&#37327;&#21464;&#20998;&#21442;&#25968;&#65292;&#23548;&#33268;&#24615;&#33021;&#21644;&#25928;&#29575;&#19981;&#36275;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#23558;&#38598;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#65288;EnKF&#65289;&#65292;&#19968;&#31181;&#25104;&#29087;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#28388;&#27874;&#25216;&#26415;&#65292;&#32435;&#20837;&#21464;&#20998;&#25512;&#29702;&#26694;&#26550;&#20013;&#65292;&#20197;&#36817;&#20284;&#28508;&#22312;&#29366;&#24577;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#36825;&#31181;&#21033;&#29992;EnKF&#30340;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#22320;&#21033;&#29992;&#28508;&#22312;&#29366;&#24577;&#21644;GP&#21160;&#21147;&#23398;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#21516;&#26102;&#28040;&#38500;&#20102;&#23545;&#21464;&#20998;&#20998;&#24067;&#36827;&#34892;&#21442;&#25968;&#21270;&#30340;&#38656;&#27714;&#65292;&#20174;&#32780;&#26174;&#33879;&#20943;&#23569;&#20102;&#21464;&#20998;&#21442;&#25968;&#30340;&#25968;&#37327;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#21487;&#20197;&#36890;&#36807;&#31616;&#21333;&#22320;&#23545;&#22810;&#20010;&#39033;&#36827;&#34892;&#27714;&#21644;&#26469;&#30452;&#25509;&#35780;&#20272;&#21464;&#20998;&#25512;&#29702;&#20013;&#30340;&#36817;&#20284;&#35777;&#25454;&#19979;&#30028;&#65288;ELBO&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian process state-space models (GPSSMs) are a versatile and principled family of nonlinear dynamical system models. However, existing variational learning and inference methods for GPSSMs often necessitate optimizing a substantial number of variational parameters, leading to inadequate performance and efficiency. To overcome this issue, we propose incorporating the ensemble Kalman filter (EnKF), a well-established model-based filtering technique, into the variational inference framework to approximate the posterior distribution of latent states. This utilization of EnKF can effectively exploit the dependencies between latent states and GP dynamics, while eliminating the need for parameterizing the variational distribution, thereby significantly reducing the number of variational parameters. Moreover, we show that our proposed algorithm allows straightforward evaluation of an approximated evidence lower bound (ELBO) in variational inference via simply summating multiple terms with 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#24102;&#26377;&#22823;&#23398;&#20064;&#29575;&#21644;&#23398;&#20064;&#29575;&#39044;&#28909;&#30340;&#21160;&#37327;&#26799;&#24230;&#19979;&#38477;&#26174;&#31034;&#20986;&#22823;&#22411;&#24377;&#23556;&#25928;&#24212;&#65292;&#23558;&#36845;&#20195;&#26397;&#30528;&#27604;&#26799;&#24230;&#19979;&#38477;&#21457;&#29616;&#30340;&#26356;&#24179;&#32531;&#30340;&#26497;&#23567;&#20540;&#26041;&#21521;&#25512;&#36827;&#12290;</title><link>http://arxiv.org/abs/2311.15051</link><description>&lt;p&gt;
&#24102;&#39044;&#28909;&#30340;&#21160;&#37327;&#26799;&#24230;&#19979;&#38477;&#30340;&#22823;&#22411;&#24377;&#23556;&#27010;&#24565;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Large Catapults in Momentum Gradient Descent with Warmup: An Empirical Study. (arXiv:2311.15051v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.15051
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#24102;&#26377;&#22823;&#23398;&#20064;&#29575;&#21644;&#23398;&#20064;&#29575;&#39044;&#28909;&#30340;&#21160;&#37327;&#26799;&#24230;&#19979;&#38477;&#26174;&#31034;&#20986;&#22823;&#22411;&#24377;&#23556;&#25928;&#24212;&#65292;&#23558;&#36845;&#20195;&#26397;&#30528;&#27604;&#26799;&#24230;&#19979;&#38477;&#21457;&#29616;&#30340;&#26356;&#24179;&#32531;&#30340;&#26497;&#23567;&#20540;&#26041;&#21521;&#25512;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#21160;&#37327;&#26799;&#24230;&#19979;&#38477;&#22312;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#23545;&#20854;&#23545;&#35757;&#32451;&#36712;&#36857;&#30340;&#24433;&#21709;&#30340;&#20855;&#20307;&#29702;&#35299;&#20173;&#28982;&#38590;&#20197;&#25417;&#25720;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#24102;&#26377;&#22823;&#23398;&#20064;&#29575;&#21644;&#23398;&#20064;&#29575;&#39044;&#28909;&#30340;&#21160;&#37327;&#26799;&#24230;&#19979;&#38477;&#26174;&#31034;&#20986;&#22823;&#22411;&#24377;&#23556;&#25928;&#24212;&#65292;&#23558;&#36845;&#20195;&#26397;&#30528;&#27604;&#26799;&#24230;&#19979;&#38477;&#21457;&#29616;&#30340;&#26356;&#24179;&#32531;&#30340;&#26497;&#23567;&#20540;&#26041;&#21521;&#25512;&#36827;&#12290;&#28982;&#21518;&#25105;&#20204;&#25552;&#20379;&#20102;&#23454;&#35777;&#35777;&#25454;&#21644;&#29702;&#35770;&#30452;&#35273;&#65292;&#34920;&#26126;&#22823;&#22411;&#24377;&#23556;&#25928;&#24212;&#26159;&#30001;&#20110;&#21160;&#37327;&#8220;&#25918;&#22823;&#8221;&#20102;&#33258;&#31283;&#23450;&#25928;&#24212;&#65288;Damian&#31561;&#65292;2023&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Although gradient descent with momentum is widely used in modern deep learning, a concrete understanding of its effects on the training trajectory still remains elusive. In this work, we empirically show that momentum gradient descent with a large learning rate and learning rate warmup displays large catapults, driving the iterates towards flatter minima than those found by gradient descent. We then provide empirical evidence and theoretical intuition that the large catapult is caused by momentum "amplifying" the self-stabilization effect (Damian et al., 2023).B.1
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#24046;&#20998;&#38544;&#31169;&#25490;&#21015;&#26816;&#39564;&#30340;&#26694;&#26550;&#65292;&#25193;&#23637;&#20102;&#32463;&#20856;&#30340;&#38750;&#31169;&#26377;&#25490;&#21015;&#26816;&#39564;&#65292;&#20197;&#22312;&#31169;&#26377;&#29615;&#22659;&#20013;&#20445;&#25345;&#26377;&#38480;&#26679;&#26412;&#26377;&#25928;&#24615;&#21644;&#24046;&#20998;&#38544;&#31169;&#24615;&#36136;&#12290;&#35813;&#26816;&#39564;&#30340;&#21151;&#29575;&#21462;&#20915;&#20110;&#26816;&#39564;&#32479;&#35745;&#37327;&#30340;&#36873;&#25321;&#65292;&#24182;&#24314;&#31435;&#20102;&#19968;&#33324;&#26465;&#20214;&#26469;&#20445;&#35777;&#19968;&#33268;&#24615;&#21644;&#38750;&#28176;&#36827;&#22343;&#21248;&#30340;&#21151;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.19043</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#25490;&#21015;&#26816;&#39564;&#65306;&#24212;&#29992;&#20110;&#26680;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Permutation Tests: Applications to Kernel Methods. (arXiv:2310.19043v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19043
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#24046;&#20998;&#38544;&#31169;&#25490;&#21015;&#26816;&#39564;&#30340;&#26694;&#26550;&#65292;&#25193;&#23637;&#20102;&#32463;&#20856;&#30340;&#38750;&#31169;&#26377;&#25490;&#21015;&#26816;&#39564;&#65292;&#20197;&#22312;&#31169;&#26377;&#29615;&#22659;&#20013;&#20445;&#25345;&#26377;&#38480;&#26679;&#26412;&#26377;&#25928;&#24615;&#21644;&#24046;&#20998;&#38544;&#31169;&#24615;&#36136;&#12290;&#35813;&#26816;&#39564;&#30340;&#21151;&#29575;&#21462;&#20915;&#20110;&#26816;&#39564;&#32479;&#35745;&#37327;&#30340;&#36873;&#25321;&#65292;&#24182;&#24314;&#31435;&#20102;&#19968;&#33324;&#26465;&#20214;&#26469;&#20445;&#35777;&#19968;&#33268;&#24615;&#21644;&#38750;&#28176;&#36827;&#22343;&#21248;&#30340;&#21151;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#20154;&#20204;&#23545;&#25935;&#24863;&#25968;&#25454;&#30340;&#38544;&#31169;&#38382;&#39064;&#36234;&#26469;&#36234;&#20851;&#27880;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#38382;&#39064;&#65292;&#24046;&#20998;&#38544;&#31169;&#20316;&#20026;&#19968;&#31181;&#20005;&#26684;&#30340;&#38544;&#31169;&#20445;&#25252;&#26694;&#26550;&#24212;&#36816;&#32780;&#29983;&#65292;&#22312;&#23398;&#26415;&#30028;&#21644;&#24037;&#19994;&#30028;&#24191;&#27867;&#35748;&#21487;&#12290;&#23613;&#31649;&#22312;&#31169;&#26377;&#25968;&#25454;&#20998;&#26512;&#26041;&#38754;&#21462;&#24471;&#20102;&#30456;&#24403;&#22823;&#30340;&#36827;&#23637;&#65292;&#20294;&#29616;&#26377;&#30340;&#26041;&#27861;&#24448;&#24448;&#23384;&#22312;&#19981;&#23454;&#29992;&#25110;&#26126;&#26174;&#30340;&#32479;&#35745;&#25928;&#29575;&#25439;&#22833;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#24341;&#20837;&#24046;&#20998;&#38544;&#31169;&#25490;&#21015;&#26816;&#39564;&#26469;&#32531;&#35299;&#36825;&#20123;&#25285;&#24551;&#12290;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#23558;&#32463;&#20856;&#30340;&#38750;&#31169;&#26377;&#25490;&#21015;&#26816;&#39564;&#25193;&#23637;&#21040;&#31169;&#26377;&#29615;&#22659;&#20013;&#65292;&#20197;&#20005;&#26684;&#30340;&#26041;&#24335;&#20445;&#25345;&#26377;&#38480;&#26679;&#26412;&#26377;&#25928;&#24615;&#21644;&#24046;&#20998;&#38544;&#31169;&#24615;&#36136;&#12290;&#25152;&#25552;&#20986;&#30340;&#26816;&#39564;&#30340;&#21151;&#29575;&#21462;&#20915;&#20110;&#19968;&#20010;&#26816;&#39564;&#32479;&#35745;&#37327;&#30340;&#36873;&#25321;&#65292;&#24182;&#24314;&#31435;&#20102;&#19968;&#33324;&#26465;&#20214;&#20445;&#35777;&#20102;&#19968;&#33268;&#24615;&#21644;&#38750;&#28176;&#36827;&#22343;&#21248;&#30340;&#21151;&#29575;&#12290;&#20026;&#20102;&#35777;&#26126;&#25105;&#20204;&#26694;&#26550;&#30340;&#23454;&#29992;&#24615;&#21644;&#21487;&#34892;&#24615;&#65292;&#25105;&#20204;&#37325;&#28857;&#20851;&#27880;&#37325;&#29616;&#26680;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent years have witnessed growing concerns about the privacy of sensitive data. In response to these concerns, differential privacy has emerged as a rigorous framework for privacy protection, gaining widespread recognition in both academic and industrial circles. While substantial progress has been made in private data analysis, existing methods often suffer from impracticality or a significant loss of statistical efficiency. This paper aims to alleviate these concerns in the context of hypothesis testing by introducing differentially private permutation tests. The proposed framework extends classical non-private permutation tests to private settings, maintaining both finite-sample validity and differential privacy in a rigorous manner. The power of the proposed test depends on the choice of a test statistic, and we establish general conditions for consistency and non-asymptotic uniform power. To demonstrate the utility and practicality of our framework, we focus on reproducing kerne
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#26694;&#26550;&#26469;&#25552;&#21319;&#25968;&#25454;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#22312;&#27492;&#26041;&#27861;&#20013;&#65292;&#20351;&#29992;&#20808;&#36827;&#27169;&#22411;&#29983;&#25104;&#39640;&#36924;&#30495;&#24230;&#30340;&#21512;&#25104;&#25968;&#25454;&#65292;&#24182;&#37319;&#29992;&#32479;&#35745;&#26041;&#27861;&#36827;&#34892;&#20998;&#26512;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#30340;&#32479;&#35745;&#26041;&#27861;&#38169;&#35823;&#38543;&#30528;&#21512;&#25104;&#25968;&#25454;&#30340;&#22686;&#21152;&#32780;&#20943;&#23569;&#65292;&#20294;&#26368;&#32456;&#21487;&#33021;&#20250;&#22686;&#21152;&#25110;&#20572;&#28382;&#12290;</title><link>http://arxiv.org/abs/2310.17848</link><description>&lt;p&gt;
&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#25193;&#23637;&#25552;&#21319;&#25968;&#25454;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Boosting Data Analytics With Synthetic Volume Expansion. (arXiv:2310.17848v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17848
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#26694;&#26550;&#26469;&#25552;&#21319;&#25968;&#25454;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#22312;&#27492;&#26041;&#27861;&#20013;&#65292;&#20351;&#29992;&#20808;&#36827;&#27169;&#22411;&#29983;&#25104;&#39640;&#36924;&#30495;&#24230;&#30340;&#21512;&#25104;&#25968;&#25454;&#65292;&#24182;&#37319;&#29992;&#32479;&#35745;&#26041;&#27861;&#36827;&#34892;&#20998;&#26512;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#30340;&#32479;&#35745;&#26041;&#27861;&#38169;&#35823;&#38543;&#30528;&#21512;&#25104;&#25968;&#25454;&#30340;&#22686;&#21152;&#32780;&#20943;&#23569;&#65292;&#20294;&#26368;&#32456;&#21487;&#33021;&#20250;&#22686;&#21152;&#25110;&#20572;&#28382;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#20316;&#20026;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#30340;&#22522;&#30707;&#65292;&#22312;&#35299;&#20915;&#25968;&#25454;&#31232;&#32570;&#21644;&#38544;&#31169;&#38382;&#39064;&#30340;&#21516;&#26102;&#65292;&#23454;&#29616;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#24615;&#33021;&#12290;&#38543;&#30528;&#21512;&#25104;&#25968;&#25454;&#30340;&#26085;&#30410;&#37325;&#35201;&#65292;&#20154;&#20204;&#24320;&#22987;&#20851;&#27880;&#32479;&#35745;&#26041;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#19982;&#21407;&#22987;&#25968;&#25454;&#19978;&#30340;&#20934;&#30830;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#29992;&#20110;&#20998;&#26512;&#30340;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#26694;&#26550;&#12290;&#35813;&#26694;&#26550;&#20351;&#29992;&#39640;&#36924;&#30495;&#24230;&#30340;&#21512;&#25104;&#25968;&#25454;&#65292;&#36890;&#36807;&#20808;&#36827;&#27169;&#22411;&#22914;&#34920;&#26684;&#25193;&#25955;&#21644;&#29983;&#25104;&#24335;&#39044;&#35757;&#32451;&#36716;&#25442;&#22120;&#27169;&#22411;&#29983;&#25104;&#65292;&#24182;&#32467;&#21512;&#30456;&#20851;&#30740;&#31350;&#27934;&#23519;&#36827;&#19968;&#27493;&#22686;&#24378;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#21457;&#29616;&#26159;&#29983;&#25104;&#25928;&#24212;&#65306;&#32479;&#35745;&#26041;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#30340;&#38169;&#35823;&#38543;&#30528;&#21512;&#25104;&#25968;&#25454;&#30340;&#22686;&#21152;&#19968;&#24320;&#22987;&#20943;&#23569;&#65292;&#20294;&#26368;&#32456;&#21487;&#33021;&#20250;&#22686;&#21152;&#25110;&#20572;&#28382;&#12290;&#36825;&#20010;&#29616;&#35937;&#26681;&#28304;&#20110;&#22797;&#21046;&#21407;&#22987;&#25968;&#25454;&#20998;&#24067;&#30340;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Synthetic data generation, a cornerstone of Generative Artificial Intelligence, signifies a paradigm shift in data science by addressing data scarcity and privacy while enabling unprecedented performance. As synthetic data gains prominence, questions arise concerning the accuracy of statistical methods when applied to synthetic data compared to raw data. In this article, we introduce the Synthetic Data Generation for Analytics framework. This framework employs statistical methods on high-fidelity synthetic data generated by advanced models such as tabular diffusion and Generative Pre-trained Transformer models. These models, trained on raw data, are further enhanced with insights from pertinent studies. A significant discovery within this framework is the generational effect: the error of a statistical method on synthetic data initially diminishes with added synthetic data but may eventually increase or plateau. This phenomenon, rooted in the complexities of replicating raw data distri
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#26102;&#38388;&#30456;&#20851;&#30340;Cox&#27169;&#22411;&#20013;&#36827;&#34892;&#21464;&#37327;&#36873;&#25321;&#65292;&#24182;&#36866;&#24212;&#21508;&#31181;&#22797;&#26434;&#30340;&#20998;&#32452;&#32467;&#26500;&#65292;&#20855;&#26377;&#36739;&#20302;&#30340;&#35823;&#35686;&#29575;&#21644;&#24555;&#36895;&#30340;&#35745;&#31639;&#12290;</title><link>http://arxiv.org/abs/2306.12528</link><description>&lt;p&gt;
&#26102;&#38388;&#30456;&#20851;&#30340;Cox&#27169;&#22411;&#20013;&#30340;&#32467;&#26500;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Structured Learning in Time-dependent Cox Models. (arXiv:2306.12528v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12528
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#26102;&#38388;&#30456;&#20851;&#30340;Cox&#27169;&#22411;&#20013;&#36827;&#34892;&#21464;&#37327;&#36873;&#25321;&#65292;&#24182;&#36866;&#24212;&#21508;&#31181;&#22797;&#26434;&#30340;&#20998;&#32452;&#32467;&#26500;&#65292;&#20855;&#26377;&#36739;&#20302;&#30340;&#35823;&#35686;&#29575;&#21644;&#24555;&#36895;&#30340;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20855;&#26377;&#26102;&#38388;&#30456;&#20851;&#31995;&#25968;&#21644;&#21327;&#21464;&#37327;&#30340;Cox&#27169;&#22411;&#22312;&#29983;&#23384;&#20998;&#26512;&#20013;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#12290;&#22312;&#39640;&#32500;&#29615;&#22659;&#20013;&#65292;&#37319;&#29992;&#31232;&#30095;&#27491;&#21017;&#21270;&#25216;&#26415;&#36827;&#34892;&#21464;&#37327;&#36873;&#25321;&#65292;&#20294;&#29616;&#26377;&#30340;&#26102;&#38388;&#30456;&#20851;&#30340;Cox&#27169;&#22411;&#26041;&#27861;&#32570;&#20047;&#22312;&#24378;&#21046;&#29305;&#23450;&#31232;&#30095;&#27169;&#24335;&#65288;&#21363;&#21327;&#21464;&#37327;&#32467;&#26500;&#65289;&#26041;&#38754;&#30340;&#28789;&#27963;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#26102;&#38388;&#30456;&#20851;&#30340;Cox&#27169;&#22411;&#20013;&#36827;&#34892;&#21464;&#37327;&#36873;&#25321;&#65292;&#21487;&#36866;&#24212;&#22797;&#26434;&#30340;&#36873;&#25321;&#35268;&#21017;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#36866;&#24212;&#20219;&#24847;&#20998;&#32452;&#32467;&#26500;&#65292;&#21253;&#25324;&#20132;&#20114;&#36873;&#25321;&#65292;&#26102;&#38388;&#24615;&#65292;&#31354;&#38388;&#24615;&#65292;&#26641;&#21644;&#26377;&#21521;&#26080;&#29615;&#22270;&#32467;&#26500;&#12290;&#23427;&#21487;&#20197;&#36890;&#36807;&#38477;&#20302;&#35823;&#35686;&#29575;&#23454;&#29616;&#20934;&#30830;&#30340;&#20272;&#35745;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;sox&#36719;&#20214;&#21253;&#65292;&#23454;&#29616;&#20102;&#19968;&#31181;&#32593;&#32476;&#27969;&#31639;&#27861;&#65292;&#29992;&#20110;&#39640;&#25928;&#22320;&#35299;&#20915;&#20855;&#26377;&#22797;&#26434;&#21327;&#21464;&#37327;&#32467;&#26500;&#30340;&#27169;&#22411;&#12290;Sox&#25552;&#20379;&#20102;&#19968;&#20010;&#29992;&#25143;&#21451;&#22909;&#30340;&#25509;&#21475;&#65292;&#29992;&#20110;&#25351;&#23450;&#20998;&#32452;&#32467;&#26500;&#65292;&#24182;&#25552;&#20379;&#24555;&#36895;&#30340;&#35745;&#31639;&#12290;&#36890;&#36807;&#26696;&#20363;&#30740;&#31350;&#65292;&#21253;&#25324;&#19968;&#20010;&#29992;&#20110;&#30830;&#23450;&#25152;&#26377;&#33268;&#27515;&#26102;&#38388;&#39044;&#27979;&#22240;&#32032;&#30340;&#26696;&#20363;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cox models with time-dependent coefficients and covariates are widely used in survival analysis. In high-dimensional settings, sparse regularization techniques are employed for variable selection, but existing methods for time-dependent Cox models lack flexibility in enforcing specific sparsity patterns (i.e., covariate structures). We propose a flexible framework for variable selection in time-dependent Cox models, accommodating complex selection rules. Our method can adapt to arbitrary grouping structures, including interaction selection, temporal, spatial, tree, and directed acyclic graph structures. It achieves accurate estimation with low false alarm rates. We develop the sox package, implementing a network flow algorithm for efficiently solving models with complex covariate structures. Sox offers a user-friendly interface for specifying grouping structures and delivers fast computation. Through examples, including a case study on identifying predictors of time to all-cause death 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32039;&#26680;&#30340;&#31639;&#23376;&#29702;&#35770;&#26041;&#27861;&#26469;&#35299;&#20915;&#26465;&#20214;&#26399;&#26395;&#20272;&#35745;&#38382;&#39064;&#65292;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#23454;&#29616;&#65292;&#26131;&#20110;&#23454;&#29616;&#65292;&#19988;&#25104;&#21151;&#24212;&#29992;&#20110;&#23454;&#38469;&#38382;&#39064;&#20013;&#12290;</title><link>http://arxiv.org/abs/2306.10592</link><description>&lt;p&gt;
&#22522;&#20110;&#32039;&#26680;&#30340;&#26465;&#20214;&#26399;&#26395;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Conditional expectation via compact kernels. (arXiv:2306.10592v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10592
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32039;&#26680;&#30340;&#31639;&#23376;&#29702;&#35770;&#26041;&#27861;&#26469;&#35299;&#20915;&#26465;&#20214;&#26399;&#26395;&#20272;&#35745;&#38382;&#39064;&#65292;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#23454;&#29616;&#65292;&#26131;&#20110;&#23454;&#29616;&#65292;&#19988;&#25104;&#21151;&#24212;&#29992;&#20110;&#23454;&#38469;&#38382;&#39064;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21435;&#22122;&#12289;&#26465;&#20214;&#26399;&#26395;&#21644;&#27969;&#24418;&#23398;&#20064;&#20219;&#21153;&#36890;&#24120;&#21487;&#20197;&#22312;&#23547;&#25214;&#20004;&#20010;&#38543;&#26426;&#21464;&#37327;&#31215;&#30340;&#26465;&#20214;&#26399;&#26395;&#30340;&#20844;&#20849;&#29615;&#22659;&#19979;&#34920;&#36848;&#12290;&#26412;&#25991;&#38024;&#23545;&#36825;&#20010;&#26356;&#19968;&#33324;&#30340;&#38382;&#39064;&#65292;&#25551;&#36848;&#20102;&#19968;&#31181;&#31639;&#23376;&#29702;&#35770;&#26041;&#27861;&#26469;&#20272;&#35745;&#26465;&#20214;&#26399;&#26395;&#12290;&#26680;&#31215;&#20998;&#31639;&#23376;&#34987;&#29992;&#20316;&#32039;&#33268;&#21270;&#24037;&#20855;&#65292;&#23558;&#20272;&#35745;&#38382;&#39064;&#35774;&#32622;&#20026;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#32447;&#24615;&#36870;&#38382;&#39064;&#12290;&#35813;&#26041;&#31243;&#30340;&#35299;&#34987;&#35777;&#26126;&#23545;&#25968;&#20540;&#36924;&#36817;&#26159;&#31283;&#23450;&#30340;&#65292;&#20174;&#32780;&#30830;&#20445;&#20102;&#25968;&#25454;&#39537;&#21160;&#23454;&#29616;&#30340;&#25910;&#25947;&#24615;&#12290;&#24635;&#20307;&#25216;&#26415;&#26131;&#20110;&#23454;&#29616;&#65292;&#36824;&#23637;&#31034;&#20102;&#20854;&#22312;&#19968;&#20123;&#23454;&#38469;&#38382;&#39064;&#20013;&#30340;&#25104;&#21151;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
The separate tasks of denoising, conditional expectation and manifold learning can often be posed in a common setting of finding the conditional expectations arising from a product of two random variables. This paper focuses on this more general problem and describes an operator theoretic approach to estimating the conditional expectation. Kernel integral operators are used as a compactification tool, to set up the estimation problem as a linear inverse problem in a reproducing kernel Hilbert space. This equation is shown to have solutions that are stable to numerical approximation, thus guaranteeing the convergence of data-driven implementations. The overall technique is easy to implement, and their successful application to some real-world problems are also shown.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#23454;&#20102;&#24403;Transformer&#22788;&#29702;&#19968;&#31995;&#21015;token&#26102;&#65292;&#20986;&#29616;&#8220;&#39046;&#23548;&#32773;&#8221;&#30340;&#32463;&#39564;&#35266;&#23519;&#65292;&#21363;&#38543;&#30528;&#26102;&#38388;&#36235;&#20110;&#26080;&#31351;&#22823;&#65292;&#20195;&#34920;token&#30340;&#31890;&#23376;&#20250;&#32858;&#38598;&#22312;&#29305;&#23450;&#30340;&#26497;&#38480;&#23545;&#35937;&#38468;&#36817;&#65292;&#36825;&#21462;&#20915;&#20110;&#20215;&#20540;&#30697;&#38453;&#30340;&#35889;&#12290;</title><link>http://arxiv.org/abs/2305.05465</link><description>&lt;p&gt;
&#33258;&#27880;&#24847;&#21147;&#21160;&#24577;&#20013;&#30340;&#32858;&#31867;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
The emergence of clusters in self-attention dynamics. (arXiv:2305.05465v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05465
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#23454;&#20102;&#24403;Transformer&#22788;&#29702;&#19968;&#31995;&#21015;token&#26102;&#65292;&#20986;&#29616;&#8220;&#39046;&#23548;&#32773;&#8221;&#30340;&#32463;&#39564;&#35266;&#23519;&#65292;&#21363;&#38543;&#30528;&#26102;&#38388;&#36235;&#20110;&#26080;&#31351;&#22823;&#65292;&#20195;&#34920;token&#30340;&#31890;&#23376;&#20250;&#32858;&#38598;&#22312;&#29305;&#23450;&#30340;&#26497;&#38480;&#23545;&#35937;&#38468;&#36817;&#65292;&#36825;&#21462;&#20915;&#20110;&#20215;&#20540;&#30697;&#38453;&#30340;&#35889;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;Transformer&#35270;&#20026;&#30456;&#20114;&#20316;&#29992;&#30340;&#31890;&#23376;&#31995;&#32479;&#65292;&#24403;&#26435;&#37325;&#19981;&#38543;&#26102;&#38388;&#21464;&#21270;&#26102;&#65292;&#26412;&#25991;&#25551;&#36848;&#20102;&#23398;&#20064;&#34920;&#31034;&#30340;&#20960;&#20309;&#24418;&#29366;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20195;&#34920;token&#30340;&#31890;&#23376;&#38543;&#30528;&#26102;&#38388;&#36235;&#20110;&#26080;&#31351;&#22823;&#32780;&#36235;&#21521;&#20110;&#29305;&#23450;&#30340;&#26497;&#38480;&#23545;&#35937;&#12290;&#20986;&#29616;&#30340;&#26497;&#38480;&#23545;&#35937;&#31867;&#22411;&#21462;&#20915;&#20110;&#20215;&#20540;&#30697;&#38453;&#30340;&#35889;&#12290;&#27492;&#22806;&#65292;&#22312;&#19968;&#32500;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#33258;&#25105;&#27880;&#24847;&#21147;&#30697;&#38453;&#25910;&#25947;&#20110;&#20302;&#31209;&#24067;&#23572;&#30697;&#38453;&#12290;&#36825;&#20123;&#32467;&#26524;&#30340;&#32452;&#21512;&#22312;&#25968;&#23398;&#19978;&#35777;&#23454;&#20102;Vaswani&#31561;&#20154;&#30340;&#32463;&#39564;&#35266;&#23519;&#65292;&#21363;Transformer&#22788;&#29702;&#19968;&#31995;&#21015;token&#26102;&#20250;&#20986;&#29616;&#8220;&#39046;&#23548;&#32773;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;
Viewing Transformers as interacting particle systems, we describe the geometry of learned representations when the weights are not time dependent. We show that particles, representing tokens, tend to cluster toward particular limiting objects as time tends to infinity. The type of limiting object that emerges depends on the spectrum of the value matrix. Additionally, in the one-dimensional case we prove that the self-attention matrix converges to a low-rank Boolean matrix. The combination of these results mathematically confirms the empirical observation made by Vaswani et al. \cite{vaswani2017attention} that \emph{leaders} appear in a sequence of tokens when processed by Transformers.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#23485;&#26494;&#24347;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#35777;&#26126;&#36866;&#24403;&#26089;&#20572;&#30340;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#22810;&#23618;&#23485;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#23454;&#29616;&#26368;&#23567;&#26497;&#22823;&#29575;&#65292;&#21069;&#25552;&#26159;&#22238;&#24402;&#20989;&#25968;&#22312;&#23545;&#24212;&#30340;NTK&#30456;&#20851;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#65292;&#20294;&#36807;&#24230;&#25311;&#21512;&#30340;&#22810;&#23618;&#23485;&#31070;&#32463;&#32593;&#32476;&#22312;$\mathbb S^{d}$&#19978;&#19981;&#33021;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;</title><link>http://arxiv.org/abs/2305.02657</link><description>&lt;p&gt;
&#28145;&#24230;&#23485;&#26494;&#24347;&#31070;&#32463;&#32593;&#32476;&#30340;&#32479;&#35745;&#20248;&#21270;&#24615;
&lt;/p&gt;
&lt;p&gt;
Statistical Optimality of Deep Wide Neural Networks. (arXiv:2305.02657v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02657
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#23485;&#26494;&#24347;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#35777;&#26126;&#36866;&#24403;&#26089;&#20572;&#30340;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#22810;&#23618;&#23485;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#23454;&#29616;&#26368;&#23567;&#26497;&#22823;&#29575;&#65292;&#21069;&#25552;&#26159;&#22238;&#24402;&#20989;&#25968;&#22312;&#23545;&#24212;&#30340;NTK&#30456;&#20851;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#65292;&#20294;&#36807;&#24230;&#25311;&#21512;&#30340;&#22810;&#23618;&#23485;&#31070;&#32463;&#32593;&#32476;&#22312;$\mathbb S^{d}$&#19978;&#19981;&#33021;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23450;&#20041;&#22312;&#26377;&#30028;&#22495;$\mathcal X \subset \mathbb R^{d}$&#19978;&#30340;&#28145;&#24230;&#23485;&#26494;&#24347;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#39318;&#20808;&#35777;&#26126;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#21487;&#20197;&#34987;&#30456;&#24212;&#30340;&#28145;&#24230;&#31070;&#32463;&#20999;&#21521;&#26680;&#22238;&#24402;&#25152;&#23436;&#20840;&#25551;&#32472;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#20999;&#21521;&#26680;&#30340;&#35889;&#29305;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#28145;&#24230;&#31070;&#32463;&#20999;&#21521;&#26680;&#22312;$\mathcal{X}$&#19978;&#20026;&#27491;&#23450;&#65292;&#20854;&#29305;&#24449;&#20540;&#34928;&#20943;&#29575;&#20026;$(d+1)/d$&#12290;&#30001;&#20110;&#26680;&#22238;&#24402;&#20013;&#24050;&#32463;&#24314;&#31435;&#30340;&#29702;&#35770;&#65292;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65292;&#36866;&#24403;&#26089;&#20572;&#30340;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#22810;&#23618;&#23485;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#23454;&#29616;&#26368;&#23567;&#26497;&#22823;&#29575;&#65292;&#21069;&#25552;&#26159;&#22238;&#24402;&#20989;&#25968;&#22312;&#23545;&#24212;&#30340;NTK&#30456;&#20851;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#36807;&#24230;&#25311;&#21512;&#30340;&#22810;&#23618;&#23485;&#31070;&#32463;&#32593;&#32476;&#22312;$\mathbb S^{d}$&#19978;&#19981;&#33021;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider the generalization ability of deep wide feedforward ReLU neural networks defined on a bounded domain $\mathcal X \subset \mathbb R^{d}$. We first demonstrate that the generalization ability of the neural network can be fully characterized by that of the corresponding deep neural tangent kernel (NTK) regression. We then investigate on the spectral properties of the deep NTK and show that the deep NTK is positive definite on $\mathcal{X}$ and its eigenvalue decay rate is $(d+1)/d$. Thanks to the well established theories in kernel regression, we then conclude that multilayer wide neural networks trained by gradient descent with proper early stopping achieve the minimax rate, provided that the regression function lies in the reproducing kernel Hilbert space (RKHS) associated with the corresponding NTK. Finally, we illustrate that the overfitted multilayer wide neural networks can not generalize well on $\mathbb S^{d}$.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#39118;&#38505;&#20998;&#35299;&#65292;&#25552;&#20986;&#22235;&#20010;&#35823;&#24046;&#37096;&#20998;&#35780;&#20272;&#33258;&#30417;&#30563;&#23398;&#20064;&#23545;169&#20010;&#35270;&#35273;&#27169;&#22411;&#30340;&#24433;&#21709;&#65292;&#20026;SSL&#30340;&#35774;&#35745;&#21644;&#20351;&#29992;&#25552;&#20379;&#23453;&#36149;&#30340;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2302.03068</link><description>&lt;p&gt;
&#36890;&#36807;&#39118;&#38505;&#20998;&#35299;&#35780;&#20272;&#33258;&#30417;&#30563;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Evaluating Self-Supervised Learning via Risk Decomposition. (arXiv:2302.03068v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03068
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#39118;&#38505;&#20998;&#35299;&#65292;&#25552;&#20986;&#22235;&#20010;&#35823;&#24046;&#37096;&#20998;&#35780;&#20272;&#33258;&#30417;&#30563;&#23398;&#20064;&#23545;169&#20010;&#35270;&#35273;&#27169;&#22411;&#30340;&#24433;&#21709;&#65292;&#20026;SSL&#30340;&#35774;&#35745;&#21644;&#20351;&#29992;&#25552;&#20379;&#23453;&#36149;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#30340;&#27969;&#31243;&#35774;&#35745;&#28041;&#21450;&#26550;&#26500;&#12289;&#22686;&#24378;&#21644;&#39044;&#35757;&#32451;&#25968;&#25454;&#31561;&#35832;&#22810;&#36873;&#25321;&#12290;&#28982;&#32780;&#65292;SSL&#36890;&#24120;&#20351;&#29992;&#21333;&#19968;&#24230;&#37327;&#26469;&#35780;&#20272;&#65292;&#36825;&#24182;&#19981;&#33021;&#25552;&#20379;&#28145;&#20837;&#30340;&#27934;&#23519;&#21644;&#25913;&#36827;&#26041;&#26696;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;SSL&#39118;&#38505;&#20998;&#35299;&#65292;&#20174;&#36924;&#36817;&#12289;&#34920;&#31034;&#21487;&#29992;&#24615;&#12289;&#25506;&#38024;&#27867;&#21270;&#21644;&#32534;&#30721;&#22120;&#27867;&#21270;&#31561;&#35282;&#24230;&#23545;&#38169;&#35823;&#36827;&#34892;&#20998;&#35299;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;30&#20010;&#35774;&#35745;&#36873;&#25321;&#23545;169&#20010;&#22312;ImageNet&#19978;&#35780;&#20272;&#30340;SSL&#35270;&#35273;&#27169;&#22411;&#30340;&#24433;&#21709;&#65292;&#24182;&#20026;&#27599;&#20010;&#32452;&#20214;&#25552;&#20379;&#20102;&#39640;&#25928;&#30340;&#20272;&#35745;&#22120;&#65292;&#20026;SSL&#27169;&#22411;&#30340;&#35774;&#35745;&#21644;&#20351;&#29992;&#25552;&#20379;&#23453;&#36149;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-supervised learning (SSL) pipelines differ in many design choices such as the architecture, augmentations, or pretraining data. Yet SSL is typically evaluated using a single metric: linear probing on ImageNet. This does not provide much insight into why or when a model is better, now how to improve it. To address this, we propose an SSL risk decomposition, which generalizes the classical supervised approximation-estimation decomposition by considering errors arising from the representation learning step. Our decomposition consists of four error components: approximation, representation usability, probe generalization, and encoder generalization. We provide efficient estimators for each component and use them to analyze the effect of 30 design choices on 169 SSL vision models evaluated on ImageNet. Our analysis gives valuable insights for designing and using SSL models. For example, it highlights the main sources of error and shows how to improve SSL in specific settings (full- vs 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29702;&#35770;&#65292;&#20801;&#35768;&#22312;&#21387;&#32553;&#30340;&#25913;&#21464;&#27010;&#29575;&#19978;&#20445;&#25345;&#25511;&#21046;&#65292;&#24182;&#33719;&#24471;&#20102;&#32039;&#23494;&#30340;&#26377;&#38480;&#26679;&#26412;&#36793;&#30028;&#26469;&#35780;&#20272;&#21387;&#32553;&#30340;&#25913;&#21464;&#27010;&#29575;&#12290;&#36825;&#23545;&#23398;&#20064;&#24212;&#29992;&#20013;&#30340;&#38169;&#35823;&#20998;&#31867;&#21644;&#38169;&#35823;&#39044;&#27979;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2301.12767</link><description>&lt;p&gt;
&#21387;&#32553;&#12289;&#27867;&#21270;&#21644;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Compression, Generalization and Learning. (arXiv:2301.12767v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12767
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29702;&#35770;&#65292;&#20801;&#35768;&#22312;&#21387;&#32553;&#30340;&#25913;&#21464;&#27010;&#29575;&#19978;&#20445;&#25345;&#25511;&#21046;&#65292;&#24182;&#33719;&#24471;&#20102;&#32039;&#23494;&#30340;&#26377;&#38480;&#26679;&#26412;&#36793;&#30028;&#26469;&#35780;&#20272;&#21387;&#32553;&#30340;&#25913;&#21464;&#27010;&#29575;&#12290;&#36825;&#23545;&#23398;&#20064;&#24212;&#29992;&#20013;&#30340;&#38169;&#35823;&#20998;&#31867;&#21644;&#38169;&#35823;&#39044;&#27979;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21387;&#32553;&#20989;&#25968;&#26159;&#19968;&#31181;&#23558;&#35266;&#27979;&#38598;&#32553;&#23567;&#20026;&#23610;&#23544;&#20943;&#23567;&#30340;&#23376;&#38598;&#30340;&#26144;&#23556;&#65292;&#21516;&#26102;&#20445;&#30041;&#20854;&#20449;&#24687;&#20869;&#23481;&#12290;&#22312;&#22810;&#20010;&#24212;&#29992;&#20013;&#65292;&#26032;&#35266;&#27979;&#20351;&#21387;&#32553;&#38598;&#21457;&#29983;&#21464;&#21270;&#30340;&#26465;&#20214;&#34987;&#35299;&#37322;&#20026;&#26032;&#35266;&#27979;&#24102;&#26469;&#20102;&#39069;&#22806;&#30340;&#20449;&#24687;&#65292;&#22312;&#23398;&#20064;&#29702;&#35770;&#20013;&#65292;&#36825;&#23545;&#24212;&#20110;&#38169;&#35823;&#20998;&#31867;&#25110;&#38169;&#35823;&#39044;&#27979;&#12290;&#26412;&#25991;&#24314;&#31435;&#20102;&#19968;&#20010;&#26032;&#29702;&#35770;&#30340;&#22522;&#30784;&#65292;&#20801;&#35768;&#22312;&#21387;&#32553;&#30340;&#25913;&#21464;&#27010;&#29575;&#19978;&#20445;&#25345;&#25511;&#21046;&#65288;&#19982;&#23398;&#20064;&#24212;&#29992;&#20013;&#30340;&#32479;&#35745;&#8220;&#39118;&#38505;&#8221;&#30456;&#23545;&#24212;&#65289;&#12290;&#22312;&#36866;&#24403;&#30340;&#26465;&#20214;&#19979;&#65292;&#21387;&#32553;&#38598;&#30340;&#22522;&#25968;&#34987;&#35777;&#26126;&#26159;&#21387;&#32553;&#30340;&#25913;&#21464;&#27010;&#29575;&#30340;&#19968;&#33268;&#20272;&#35745;&#37327;&#65288;&#19981;&#23545;&#21387;&#32553;&#38598;&#30340;&#23610;&#23544;&#35774;&#32622;&#19978;&#38480;&#65289;&#65307;&#27492;&#22806;&#65292;&#22312;&#26222;&#36941;&#36866;&#29992;&#30340;&#20559;&#22909;&#26465;&#20214;&#19979;&#33719;&#24471;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#32039;&#23494;&#30340;&#26377;&#38480;&#26679;&#26412;&#36793;&#30028;&#26469;&#35780;&#20272;&#21387;&#32553;&#30340;&#25913;&#21464;&#27010;&#29575;&#12290;&#25152;&#26377;&#32467;&#26524;&#37117;&#21487;&#20197;&#22312;&#23436;&#20840;&#24212;&#29992;&#20013;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
A compression function is a map that slims down an observational set into a subset of reduced size, while preserving its informational content. In multiple applications, the condition that one new observation makes the compressed set change is interpreted that this observation brings in extra information and, in learning theory, this corresponds to misclassification, or misprediction. In this paper, we lay the foundations of a new theory that allows one to keep control on the probability of change of compression (which maps into the statistical "risk" in learning applications). Under suitable conditions, the cardinality of the compressed set is shown to be a consistent estimator of the probability of change of compression (without any upper limit on the size of the compressed set); moreover, unprecedentedly tight finite-sample bounds to evaluate the probability of change of compression are obtained under a generally applicable condition of preference. All results are usable in a fully 
&lt;/p&gt;</description></item><item><title>ddml&#26159;Stata&#20013;&#30340;&#21452;&#37325;/&#26080;&#20559;&#26426;&#22120;&#23398;&#20064;&#21253;&#65292;&#25903;&#25345;&#20116;&#31181;&#19981;&#21516;&#35745;&#37327;&#27169;&#22411;&#30340;&#22240;&#26524;&#21442;&#25968;&#20272;&#35745;&#65292;&#21487;&#20197;&#28789;&#27963;&#20272;&#35745;&#20869;&#29983;&#21464;&#37327;&#30340;&#22240;&#26524;&#25928;&#24212;&#65292;&#22312;&#35768;&#22810;&#29616;&#26377;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#31243;&#24207;&#20013;&#20860;&#23481;&#12290;&#25512;&#33616;&#19982;&#22534;&#21472;&#20272;&#35745;&#32467;&#21512;&#20351;&#29992;&#65292;&#25552;&#20379;&#20102;&#33945;&#29305;&#21345;&#27931;&#35777;&#25454;&#25903;&#25345;&#12290;</title><link>http://arxiv.org/abs/2301.09397</link><description>&lt;p&gt;
ddml: Stata&#20013;&#30340;&#21452;&#37325;/&#26080;&#20559;&#26426;&#22120;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
ddml: Double/debiased machine learning in Stata. (arXiv:2301.09397v2 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.09397
&lt;/p&gt;
&lt;p&gt;
ddml&#26159;Stata&#20013;&#30340;&#21452;&#37325;/&#26080;&#20559;&#26426;&#22120;&#23398;&#20064;&#21253;&#65292;&#25903;&#25345;&#20116;&#31181;&#19981;&#21516;&#35745;&#37327;&#27169;&#22411;&#30340;&#22240;&#26524;&#21442;&#25968;&#20272;&#35745;&#65292;&#21487;&#20197;&#28789;&#27963;&#20272;&#35745;&#20869;&#29983;&#21464;&#37327;&#30340;&#22240;&#26524;&#25928;&#24212;&#65292;&#22312;&#35768;&#22810;&#29616;&#26377;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#31243;&#24207;&#20013;&#20860;&#23481;&#12290;&#25512;&#33616;&#19982;&#22534;&#21472;&#20272;&#35745;&#32467;&#21512;&#20351;&#29992;&#65292;&#25552;&#20379;&#20102;&#33945;&#29305;&#21345;&#27931;&#35777;&#25454;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;Stata&#20013;&#24341;&#20837;&#20102;&#19968;&#20010;&#21517;&#20026;ddml&#30340;&#21253;&#65292;&#29992;&#20110;&#21452;&#37325;/&#26080;&#20559;&#26426;&#22120;&#23398;&#20064;&#65288;DDML&#65289;&#12290;&#25903;&#25345;&#20116;&#31181;&#19981;&#21516;&#35745;&#37327;&#27169;&#22411;&#30340;&#22240;&#26524;&#21442;&#25968;&#20272;&#35745;&#65292;&#20801;&#35768;&#22312;&#26410;&#30693;&#20989;&#25968;&#24418;&#24335;&#21644;/&#25110;&#35768;&#22810;&#22806;&#29983;&#21464;&#37327;&#30340;&#35774;&#32622;&#20013;&#28789;&#27963;&#20272;&#35745;&#20869;&#29983;&#21464;&#37327;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;ddml&#19982;Stata&#20013;&#30340;&#35768;&#22810;&#29616;&#26377;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#31243;&#24207;&#20860;&#23481;&#12290;&#25105;&#20204;&#25512;&#33616;&#23558;DDML&#19982;&#22534;&#21472;&#20272;&#35745;&#32467;&#21512;&#20351;&#29992;&#65292;&#23558;&#22810;&#20010;&#26426;&#22120;&#23398;&#20064;&#22120;&#32452;&#21512;&#25104;&#26368;&#32456;&#39044;&#27979;&#22120;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#33945;&#29305;&#21345;&#27931;&#35777;&#25454;&#26469;&#25903;&#25345;&#25105;&#20204;&#30340;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce the package ddml for Double/Debiased Machine Learning (DDML) in Stata. Estimators of causal parameters for five different econometric models are supported, allowing for flexible estimation of causal effects of endogenous variables in settings with unknown functional forms and/or many exogenous variables. ddml is compatible with many existing supervised machine learning programs in Stata. We recommend using DDML in combination with stacking estimation which combines multiple machine learners into a final predictor. We provide Monte Carlo evidence to support our recommendation.
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#30740;&#31350;&#20171;&#32461;&#20102;&#29983;&#23384;&#24378;&#30423;&#38382;&#39064;&#65292;&#36825;&#26159;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#19968;&#20010;&#26032;&#21464;&#31181;&#12290;&#35813;&#38382;&#39064;&#30340;&#30446;&#26631;&#26159;&#26368;&#23567;&#21270;&#29983;&#23384;&#36951;&#25022;&#65292;&#21516;&#26102;&#35201;&#27714;&#31639;&#27861;&#21152;&#36895;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2206.03019</link><description>&lt;p&gt;
&#29983;&#23384;&#24378;&#30423;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
The Survival Bandit Problem. (arXiv:2206.03019v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.03019
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#30740;&#31350;&#20171;&#32461;&#20102;&#29983;&#23384;&#24378;&#30423;&#38382;&#39064;&#65292;&#36825;&#26159;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#19968;&#20010;&#26032;&#21464;&#31181;&#12290;&#35813;&#38382;&#39064;&#30340;&#30446;&#26631;&#26159;&#26368;&#23567;&#21270;&#29983;&#23384;&#36951;&#25022;&#65292;&#21516;&#26102;&#35201;&#27714;&#31639;&#27861;&#21152;&#36895;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#24182;&#30740;&#31350;&#20102;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;(MAB)&#30340;&#19968;&#20010;&#26032;&#21464;&#31181;&#65292;&#31216;&#20026;&#29983;&#23384;&#24378;&#30423;&#38382;&#39064;(S-MAB)&#12290;&#34429;&#28982;&#22312;&#36825;&#20004;&#20010;&#38382;&#39064;&#20013;&#65292;&#30446;&#26631;&#37117;&#26159;&#26368;&#22823;&#21270;&#25152;&#35859;&#30340;&#32047;&#31215;&#22870;&#21169;&#65292;&#20294;&#22312;&#36825;&#20010;&#26032;&#30340;&#21464;&#31181;&#20013;&#65292;&#22914;&#26524;&#32047;&#31215;&#22870;&#21169;&#20302;&#20110;&#39044;&#35774;&#30340;&#38408;&#20540;&#65292;&#31243;&#24207;&#23558;&#34987;&#20013;&#26029;&#12290;&#36825;&#20010;&#31616;&#21333;&#20294;&#26410;&#34987;&#25506;&#35752;&#30340;MAB&#25193;&#23637;&#28304;&#33258;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#12290;&#20363;&#22914;&#65292;&#24403;&#23545;&#33258;&#24895;&#24739;&#32773;&#36827;&#34892;&#20004;&#31181;&#33647;&#29289;&#30340;&#27979;&#35797;&#26102;&#65292;&#20154;&#20204;&#30340;&#20581;&#24247;&#38382;&#39064;&#33267;&#20851;&#37325;&#35201;&#65292;&#22914;&#26524;&#20986;&#29616;&#20005;&#37325;&#21103;&#20316;&#29992;&#25110;&#32773;&#30142;&#30149;&#32508;&#21512;&#30151;&#27809;&#26377;&#24471;&#21040;&#27835;&#30103;&#65292;&#26377;&#24517;&#35201;&#33021;&#22815;&#20013;&#26029;&#23454;&#39564;&#12290;&#20174;&#29702;&#35770;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;S-MAB&#26159;&#31532;&#19968;&#31181;&#21487;&#33021;&#20013;&#26029;&#25110;&#19981;&#20013;&#26029;&#30340;MAB&#21464;&#31181;&#12290;&#25105;&#20204;&#39318;&#20808;&#23545;S-MAB&#36827;&#34892;&#24418;&#24335;&#21270;&#65292;&#23558;&#20854;&#30446;&#26631;&#23450;&#20041;&#20026;&#25152;&#35859;&#30340;&#29983;&#23384;&#36951;&#25022;&#30340;&#26368;&#23567;&#21270;&#65292;&#33258;&#28982;&#25512;&#24191;&#20102;MAB&#30340;&#36951;&#25022;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21516;&#26102;&#26368;&#23567;&#21270;&#29983;&#23384;&#36951;&#25022;&#21644;&#21152;&#36895;&#25910;&#25947;&#30340;&#36866;&#29992;&#20110;S-MAB&#30340;&#31639;&#27861;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce and study a new variant of the multi-armed bandit problem (MAB), called the survival bandit problem (S-MAB). While in both problems, the objective is to maximize the so-called cumulative reward, in this new variant, the procedure is interrupted if the cumulative reward falls below a preset threshold. This simple yet unexplored extension of the MAB follows from many practical applications. For example, when testing two medicines against each other on voluntary patients, people's health are at stake, and it is necessary to be able to interrupt experiments if serious side effects occur or if the disease syndromes are not dissipated by the treatment. From a theoretical perspective, the S-MAB is the first variant of the MAB where the procedure may or may not be interrupted. We start by formalizing the S-MAB and we define its objective as the minimization of the so-called survival regret, which naturally generalizes the regret of the MAB. Then, we show that the objective of the 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26377;&#25928;&#30340;&#31639;&#27861;&#26469;&#23558;&#26631;&#31614;&#20449;&#24687;&#19982;&#31232;&#30095;&#22270;&#32467;&#26500;&#30456;&#32467;&#21512;&#65292;&#35299;&#20915;&#20102;&#22522;&#20110;&#32593;&#32476;&#25299;&#25169;&#30340;&#32858;&#31867;&#22312;&#31232;&#30095;&#22270;&#19978;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2205.11677</link><description>&lt;p&gt;
&#31232;&#30095;&#22270;&#30340;&#21322;&#30417;&#30563;&#32858;&#31867;&#65306;&#36328;&#36234;&#20102;&#20449;&#24687;&#29702;&#35770;&#38376;&#27099;
&lt;/p&gt;
&lt;p&gt;
Semi-Supervised Clustering of Sparse Graphs: Crossing the Information-Theoretic Threshold. (arXiv:2205.11677v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.11677
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26377;&#25928;&#30340;&#31639;&#27861;&#26469;&#23558;&#26631;&#31614;&#20449;&#24687;&#19982;&#31232;&#30095;&#22270;&#32467;&#26500;&#30456;&#32467;&#21512;&#65292;&#35299;&#20915;&#20102;&#22522;&#20110;&#32593;&#32476;&#25299;&#25169;&#30340;&#32858;&#31867;&#22312;&#31232;&#30095;&#22270;&#19978;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#22359;&#27169;&#22411;&#26159;&#19968;&#31181;&#29992;&#20110;&#32593;&#32476;&#32467;&#26500;&#25968;&#25454;&#32858;&#31867;&#21644;&#31038;&#21306;&#26816;&#27979;&#30340;&#22522;&#26412;&#38543;&#26426;&#22270;&#27169;&#22411;&#12290;&#25968;&#21313;&#24180;&#26469;&#23545;&#35813;&#38382;&#39064;&#30340;&#24191;&#27867;&#30740;&#31350;&#24050;&#32463;&#24314;&#31435;&#20102;&#35768;&#22810;&#28145;&#21051;&#30340;&#32467;&#26524;&#65292;&#20854;&#20013;Kesten-Stigum&#38376;&#27099;&#22788;&#30340;&#30456;&#21464;&#29616;&#35937;&#29305;&#21035;&#26377;&#36259;&#65292;&#20174;&#25968;&#23398;&#21644;&#24212;&#29992;&#35282;&#24230;&#37117;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#23427;&#34920;&#26126;&#65292;&#22914;&#26524;&#27169;&#22411;&#21442;&#25968;&#22312;&#26576;&#20010;&#38376;&#27099;&#20197;&#19979;&#65292;&#22522;&#20110;&#32593;&#32476;&#25299;&#25169;&#30340;&#20219;&#20309;&#20272;&#35745;&#22120;&#22312;&#31232;&#30095;&#22270;&#19978;&#37117;&#19981;&#33021;&#27604;&#38543;&#26426;&#29468;&#27979;&#26356;&#22909;&#12290;&#28982;&#32780;&#65292;&#22914;&#26524;&#25105;&#20204;&#31245;&#24494;&#25193;&#23637;&#35270;&#37326;&#21040;&#26222;&#36941;&#23384;&#22312;&#30340;&#21322;&#30417;&#30563;&#35774;&#32622;&#65292;&#36825;&#26679;&#30340;&#22522;&#26412;&#38480;&#21046;&#23558;&#23436;&#20840;&#28040;&#22833;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#36890;&#36807;&#25581;&#31034;&#20986;&#20219;&#24847;&#19968;&#37096;&#20998;&#26631;&#35760;&#65292;&#21487;&#20197;&#22312;&#25972;&#20010;&#21442;&#25968;&#22495;&#20869;&#23545;&#26816;&#27979;&#38382;&#39064;&#36827;&#34892;&#22788;&#29702;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#31181;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#19968;&#31181;&#26159;&#22522;&#20110;&#32452;&#21512;&#30340;&#65292;&#19968;&#31181;&#26159;&#22522;&#20110;&#20248;&#21270;&#30340;&#65292;&#29992;&#20110;&#23558;&#26631;&#31614;&#20449;&#24687;&#19982;&#22270;&#32467;&#26500;&#30456;&#32467;&#21512;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#20026;&#38543;&#26426;&#22359;&#27169;&#22411;&#21644;&#21322;&#30417;&#30563;&#23398;&#20064;&#24102;&#26469;&#20102;&#20840;&#26032;&#30340;&#35270;&#35282;&#65292;&#26631;&#24535;&#30528;&#31232;&#30095;&#22270;&#32858;&#31867;&#39046;&#22495;&#30340;&#37325;&#22823;&#31361;&#30772;&#12290;
&lt;/p&gt;
&lt;p&gt;
The stochastic block model is a canonical random graph model for clustering and community detection on network-structured data. Decades of extensive study on the problem have established many profound results, among which the phase transition at the Kesten-Stigum threshold is particularly interesting both from a mathematical and an applied standpoint. It states that no estimator based on the network topology can perform substantially better than chance on sparse graphs if the model parameter is below certain threshold. Nevertheless, if we slightly extend the horizon to the ubiquitous semi-supervised setting, such a fundamental limitation will disappear completely. We prove that with arbitrary fraction of the labels revealed, the detection problem is feasible throughout the parameter domain. Moreover, we introduce two efficient algorithms, one combinatorial and one based on optimization, to integrate label information with graph structures. Our work brings a new perspective to stochasti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#38750;&#21442;&#25968;&#27169;&#22411;&#20013;&#20351;&#29992;&#24037;&#20855;&#21464;&#37327;&#30340;&#26368;&#20248;&#20272;&#35745;&#21644;&#25512;&#26029;&#65307;&#39318;&#20808;&#26159;&#36873;&#25321;&#26368;&#20339;&#31579;&#36873;&#32500;&#25968;&#30340;&#20272;&#35745;&#22120;&#65292;&#20351;&#24471;&#32467;&#26500;&#20989;&#25968;&#21644;&#20854;&#23548;&#25968;&#30340;&#20272;&#35745;&#22120;&#20197;&#26368;&#23567;&#21270;&#36229;&#33539;&#25968;&#30340;&#25910;&#25947;&#36895;&#24230;&#25910;&#25947;&#65307;&#20854;&#27425;&#26159;&#26500;&#24314;&#22343;&#21248;&#32622;&#20449;&#24102;&#26469;&#33719;&#21462;&#32467;&#26500;&#20989;&#25968;&#21644;&#20854;&#23548;&#25968;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#27169;&#25311;&#32467;&#26524;&#34920;&#26126;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#33391;&#22909;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2107.11869</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;&#32467;&#26500;&#20989;&#25968;&#21644;&#24377;&#24615;&#30340;&#33258;&#36866;&#24212;&#20272;&#35745;&#21644;&#22343;&#21248;&#32622;&#20449;&#24102;
&lt;/p&gt;
&lt;p&gt;
Adaptive Estimation and Uniform Confidence Bands for Nonparametric Structural Functions and Elasticities. (arXiv:2107.11869v3 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.11869
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#38750;&#21442;&#25968;&#27169;&#22411;&#20013;&#20351;&#29992;&#24037;&#20855;&#21464;&#37327;&#30340;&#26368;&#20248;&#20272;&#35745;&#21644;&#25512;&#26029;&#65307;&#39318;&#20808;&#26159;&#36873;&#25321;&#26368;&#20339;&#31579;&#36873;&#32500;&#25968;&#30340;&#20272;&#35745;&#22120;&#65292;&#20351;&#24471;&#32467;&#26500;&#20989;&#25968;&#21644;&#20854;&#23548;&#25968;&#30340;&#20272;&#35745;&#22120;&#20197;&#26368;&#23567;&#21270;&#36229;&#33539;&#25968;&#30340;&#25910;&#25947;&#36895;&#24230;&#25910;&#25947;&#65307;&#20854;&#27425;&#26159;&#26500;&#24314;&#22343;&#21248;&#32622;&#20449;&#24102;&#26469;&#33719;&#21462;&#32467;&#26500;&#20989;&#25968;&#21644;&#20854;&#23548;&#25968;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#27169;&#25311;&#32467;&#26524;&#34920;&#26126;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#33391;&#22909;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#20004;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#38750;&#21442;&#25968;&#27169;&#22411;&#20013;&#20351;&#29992;&#24037;&#20855;&#21464;&#37327;&#30340;&#26368;&#20248;&#20272;&#35745;&#21644;&#25512;&#26029;&#12290;&#31532;&#19968;&#31181;&#26159;&#23545;&#19968;&#31867;&#24120;&#29992;&#31579;&#36873;&#20004;&#38454;&#27573;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#37327;&#30340;&#31579;&#36873;&#32500;&#25968;&#30340;&#25968;&#25454;&#39537;&#21160;&#36873;&#25321;&#12290;&#24403;&#20351;&#29992;&#35813;&#36873;&#25321;&#36827;&#34892;&#23454;&#29616;&#26102;&#65292;&#32467;&#26500;&#20989;&#25968;$h_0$&#21450;&#20854;&#23548;&#25968;&#65288;&#22914;&#24377;&#24615;&#65289;&#30340;&#20272;&#35745;&#22120;&#20197;&#26368;&#24555;&#30340;&#65288;&#21363;&#26368;&#23567;&#21270;&#65289;&#36229;&#33539;&#25968;&#25910;&#25947;&#36895;&#24230;&#25910;&#25947;&#12290;&#31532;&#20108;&#31181;&#26159;&#26500;&#24314;&#29992;&#20110;$h_0$&#21450;&#20854;&#23548;&#25968;&#30340;&#22343;&#21248;&#32622;&#20449;&#24102;&#65288;UCBs&#65289;&#12290;&#25105;&#20204;&#30340;UCBs&#22312;&#19968;&#20010;&#36890;&#29992;&#30340;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#31867;&#21035;&#19978;&#20445;&#35777;&#20102;&#35206;&#30422;&#65292;&#24182;&#20197;&#26368;&#23567;&#21270;&#36895;&#29575;&#25910;&#32553;&#65292;&#21487;&#33021;&#26377;&#23545;&#25968;&#22240;&#23376;&#12290;&#22240;&#27492;&#65292;&#19982;&#36890;&#24120;&#30340;&#27424;&#24179;&#28369;&#26041;&#27861;&#30340;UCBs&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;UCBs&#22312;&#28176;&#36817;&#19978;&#20855;&#26377;&#26356;&#39640;&#30340;&#25928;&#29575;&#12290;&#20316;&#20026;&#24212;&#29992;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#22269;&#38469;&#36152;&#26131;&#30340;&#22404;&#26029;&#31454;&#20105;&#27169;&#22411;&#20013;&#20225;&#19994;&#20986;&#21475;&#30340;&#23494;&#38598;&#36793;&#38469;&#30340;&#24377;&#24615;&#12290;&#27169;&#25311;&#32467;&#26524;&#26174;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#33391;&#22909;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce two data-driven procedures for optimal estimation and inference in nonparametric models using instrumental variables. The first is a data-driven choice of sieve dimension for a popular class of sieve two-stage least squares estimators. When implemented with this choice, estimators of both the structural function $h_0$ and its derivatives (such as elasticities) converge at the fastest possible (i.e., minimax) rates in sup-norm. The second is for constructing uniform confidence bands (UCBs) for $h_0$ and its derivatives. Our UCBs guarantee coverage over a generic class of data-generating processes and contract at the minimax rate, possibly up to a logarithmic factor. As such, our UCBs are asymptotically more efficient than UCBs based on the usual approach of undersmoothing. As an application, we estimate the elasticity of the intensive margin of firm exports in a monopolistic competition model of international trade. Simulations illustrate the good performance of our procedu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26494;&#24347;&#20248;&#21270;&#29702;&#35770;&#65292;&#25506;&#35752;&#20102;&#39118;&#38505;&#19982;&#22797;&#26434;&#24230;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#25552;&#20986;&#20102;&#21487;&#20197;&#20174;&#22797;&#26434;&#24230;&#20272;&#35745;&#39118;&#38505;&#30340;&#26041;&#27861;&#65292;&#30740;&#31350;&#20102;&#25903;&#25345;&#21521;&#37327;&#26041;&#27861;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2004.05839</link><description>&lt;p&gt;
&#36890;&#36807;&#26494;&#24347;&#20248;&#21270;&#29702;&#35770;&#21450;&#20854;&#22312;&#25903;&#25345;&#21521;&#37327;&#26426;&#20013;&#30340;&#24212;&#29992;&#65292;&#23545;&#39118;&#38505;&#36827;&#34892;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Theory of the Risk for Optimization with Relaxation and its Application to Support Vector Machines. (arXiv:2004.05839v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2004.05839
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26494;&#24347;&#20248;&#21270;&#29702;&#35770;&#65292;&#25506;&#35752;&#20102;&#39118;&#38505;&#19982;&#22797;&#26434;&#24230;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#25552;&#20986;&#20102;&#21487;&#20197;&#20174;&#22797;&#26434;&#24230;&#20272;&#35745;&#39118;&#38505;&#30340;&#26041;&#27861;&#65292;&#30740;&#31350;&#20102;&#25903;&#25345;&#21521;&#37327;&#26041;&#27861;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#26494;&#24347;&#20248;&#21270;&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#25968;&#25454;&#39537;&#21160;&#35774;&#35745;&#30340;&#24191;&#27867;&#33539;&#20363;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;"&#39118;&#38505;"&#65288;&#26410;&#33021;&#28385;&#36275;&#26032;&#30340;&#12289;&#26679;&#26412;&#22806;&#32422;&#26463;&#30340;&#27010;&#29575;&#65289;&#21644;"&#22797;&#26434;&#24230;"&#65288;&#26681;&#25454;Garatti&#21644;Campi&#65288;2019&#65289;&#20013;&#20171;&#32461;&#30340;&#23450;&#20041;&#65289;&#20043;&#38388;&#30340;&#28145;&#23618;&#32852;&#31995;&#65292;&#24182;&#21457;&#29616;&#36825;&#31181;&#32852;&#31995;&#23545;&#24212;&#29992;&#26377;&#28145;&#36828;&#24433;&#21709;&#65292;&#22240;&#20026;&#23427;&#24847;&#21619;&#30528;&#21487;&#20197;&#20174;&#22797;&#26434;&#24230;&#20272;&#35745;&#39118;&#38505;&#65292;&#32780;&#22797;&#26434;&#24230;&#21487;&#20197;&#36890;&#36807;&#25968;&#25454;&#36827;&#34892;&#27979;&#37327;&#65292;&#19981;&#38656;&#35201;&#20102;&#35299;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#26032;&#30340;&#32467;&#26524;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25193;&#22823;&#20102;Garatti&#21644;Campi&#65288;2019&#65289;&#30340;&#33539;&#22260;&#65292;&#20197;&#28085;&#30422;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#21508;&#31181;&#31639;&#27861;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#32463;&#20856;&#30340;&#25903;&#25345;&#21521;&#37327;&#26041;&#27861;&#65292;&#21253;&#25324;&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#12289;&#25903;&#25345;&#21521;&#37327;&#22238;&#24402;&#65288;SVR&#65289;&#21644;&#25903;&#25345;&#21521;&#37327;&#25968;&#25454;&#25551;&#36848;&#65288;SVDD&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we consider optimization with relaxation, an ample paradigm to make data-driven designs. This approach was previously considered by the same authors of this work in Garatti and Campi (2019), a study that revealed a deep-seated connection between two concepts: risk (probability of not satisfying a new, out-of-sample, constraint) and complexity (according to a definition introduced in paper Garatti and Campi (2019)). This connection was shown to have profound implications in applications because it implied that the risk can be estimated from the complexity, a quantity that can be measured from the data without any knowledge of the data-generation mechanism. In the present work we establish new results. First, we expand the scope of Garatti and Campi (2019) so as to embrace a more general setup that covers various algorithms in machine learning. Then, we study classical support vector methods - including SVM (Support Vector Machine), SVR (Support Vector Regression) and SVDD 
&lt;/p&gt;</description></item></channel></rss>