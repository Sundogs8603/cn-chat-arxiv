<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#21033;&#29992;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#24314;&#31435;&#20102;&#19968;&#33268;&#24615;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#32032;&#25551;&#23725;&#22238;&#24402;&#38598;&#21512;&#30340;&#39044;&#27979;&#39118;&#38505;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#27491;&#21017;&#21270;&#21644;&#32032;&#25551;&#21442;&#25968;&#30340;&#39640;&#25928;&#19968;&#33268;&#35843;&#25972;&#12290;</title><link>http://arxiv.org/abs/2310.04357</link><description>&lt;p&gt;
&#28176;&#36827;&#20813;&#36153;&#32032;&#25551;&#31232;&#30095;&#23725;&#38598;&#21512;&#65306;&#39118;&#38505;&#65292;&#20132;&#21449;&#39564;&#35777;&#21644;&#35843;&#25972;
&lt;/p&gt;
&lt;p&gt;
Asymptotically free sketched ridge ensembles: Risks, cross-validation, and tuning. (arXiv:2310.04357v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04357
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#21033;&#29992;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#24314;&#31435;&#20102;&#19968;&#33268;&#24615;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#32032;&#25551;&#23725;&#22238;&#24402;&#38598;&#21512;&#30340;&#39044;&#27979;&#39118;&#38505;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#27491;&#21017;&#21270;&#21644;&#32032;&#25551;&#21442;&#25968;&#30340;&#39640;&#25928;&#19968;&#33268;&#35843;&#25972;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#21033;&#29992;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#65292;&#24314;&#31435;&#20102;&#25512;&#24191;&#20132;&#21449;&#39564;&#35777;&#65288;GCV&#65289;&#29992;&#20110;&#20272;&#35745;&#32032;&#25551;&#23725;&#22238;&#24402;&#38598;&#21512;&#30340;&#39044;&#27979;&#39118;&#38505;&#30340;&#19968;&#33268;&#24615;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#27491;&#21017;&#21270;&#21644;&#32032;&#25551;&#21442;&#25968;&#30340;&#39640;&#25928;&#19968;&#33268;&#35843;&#25972;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#19968;&#31867;&#24191;&#27867;&#30340;&#28176;&#36827;&#20813;&#36153;&#32032;&#25551;&#65292;&#23545;&#25968;&#25454;&#20551;&#35774;&#38750;&#24120;&#28201;&#21644;&#12290;&#23545;&#20110;&#24179;&#26041;&#39044;&#27979;&#39118;&#38505;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#20998;&#35299;&#25104;&#31561;&#25928;&#38750;&#32032;&#25551;&#38544;&#21547;&#23725;&#20559;&#24046;&#21644;&#22522;&#20110;&#32032;&#25551;&#30340;&#26041;&#24046;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#39118;&#38505;&#21487;&#20197;&#36890;&#36807;&#20165;&#35843;&#25972;&#26080;&#38480;&#38598;&#21512;&#20013;&#30340;&#32032;&#25551;&#22823;&#23567;&#26469;&#20840;&#23616;&#20248;&#21270;&#12290;&#23545;&#20110;&#19968;&#33324;&#30340;&#20122;&#20108;&#27425;&#39044;&#27979;&#39118;&#38505;&#20989;&#25968;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;GCV&#26469;&#26500;&#24314;&#19968;&#33268;&#30340;&#39118;&#38505;&#20272;&#35745;&#65292;&#20174;&#32780;&#22312;Wasserstein-2&#24230;&#37327;&#19979;&#33719;&#24471;&#20102;GCV&#20462;&#27491;&#30340;&#39044;&#27979;&#30340;&#20998;&#24067;&#25910;&#25947;&#24615;&#12290;&#36825;&#29305;&#21035;&#20801;&#35768;&#22312;&#35757;&#32451;&#25968;&#25454;&#26465;&#20214;&#19979;&#26500;&#24314;&#20855;&#26377;&#28176;&#36827;&#27491;&#30830;&#35206;&#30422;&#29575;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#8220;&#38598;&#21512;&#25216;&#24039;&#8221;&#65292;&#36890;&#36807;&#36825;&#31181;&#25216;&#24039;&#21487;&#20197;&#25512;&#26029;&#26410;&#32463;&#36807;&#25551;&#32472;&#30340;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;
We employ random matrix theory to establish consistency of generalized cross validation (GCV) for estimating prediction risks of sketched ridge regression ensembles, enabling efficient and consistent tuning of regularization and sketching parameters. Our results hold for a broad class of asymptotically free sketches under very mild data assumptions. For squared prediction risk, we provide a decomposition into an unsketched equivalent implicit ridge bias and a sketching-based variance, and prove that the risk can be globally optimized by only tuning sketch size in infinite ensembles. For general subquadratic prediction risk functionals, we extend GCV to construct consistent risk estimators, and thereby obtain distributional convergence of the GCV-corrected predictions in Wasserstein-2 metric. This in particular allows construction of prediction intervals with asymptotically correct coverage conditional on the training data. We also propose an "ensemble trick" whereby the risk for unsket
&lt;/p&gt;</description></item><item><title>beta&#25193;&#25955;&#26159;&#19968;&#31181;&#26032;&#22411;&#29983;&#25104;&#27169;&#22411;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#21435;&#25513;&#30422;&#21644;&#21435;&#22122;&#30340;&#25216;&#26415;&#65292;&#21033;&#29992;&#32553;&#25918;&#21644;&#20559;&#31227;&#30340;beta&#20998;&#24067;&#36827;&#34892;&#20056;&#27861;&#36716;&#25442;&#65292;&#23454;&#29616;&#22312;&#26377;&#30028;&#33539;&#22260;&#20869;&#29983;&#25104;&#25968;&#25454;&#12290;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;KL&#25955;&#24230;&#19978;&#30028;&#36827;&#34892;&#20248;&#21270;&#65292;&#35777;&#26126;&#20102;&#25928;&#26524;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2309.07867</link><description>&lt;p&gt;
Beta Diffusion. (arXiv:2309.07867v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
Beta Diffusion. (arXiv:2309.07867v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07867
&lt;/p&gt;
&lt;p&gt;
beta&#25193;&#25955;&#26159;&#19968;&#31181;&#26032;&#22411;&#29983;&#25104;&#27169;&#22411;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#21435;&#25513;&#30422;&#21644;&#21435;&#22122;&#30340;&#25216;&#26415;&#65292;&#21033;&#29992;&#32553;&#25918;&#21644;&#20559;&#31227;&#30340;beta&#20998;&#24067;&#36827;&#34892;&#20056;&#27861;&#36716;&#25442;&#65292;&#23454;&#29616;&#22312;&#26377;&#30028;&#33539;&#22260;&#20869;&#29983;&#25104;&#25968;&#25454;&#12290;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;KL&#25955;&#24230;&#19978;&#30028;&#36827;&#34892;&#20248;&#21270;&#65292;&#35777;&#26126;&#20102;&#25928;&#26524;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;beta&#25193;&#25955;&#65292;&#19968;&#31181;&#23558;&#21435;&#25513;&#30422;&#21644;&#21435;&#22122;&#38598;&#25104;&#21040;&#19968;&#36215;&#30340;&#26032;&#22411;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#26377;&#30028;&#33539;&#22260;&#20869;&#29983;&#25104;&#25968;&#25454;&#12290;&#20351;&#29992;&#20102;&#32553;&#25918;&#21644;&#20559;&#31227;&#30340;beta&#20998;&#24067;&#65292;beta&#25193;&#25955;&#21033;&#29992;&#20102;&#38543;&#26102;&#38388;&#30340;&#20056;&#27861;&#36716;&#25442;&#26469;&#21019;&#24314;&#27491;&#21521;&#21644;&#21453;&#21521;&#30340;&#25193;&#25955;&#36807;&#31243;&#65292;&#21516;&#26102;&#32500;&#25345;&#30528;&#27491;&#21521;&#36793;&#32536;&#20998;&#24067;&#21644;&#21453;&#21521;&#26465;&#20214;&#20998;&#24067;&#65292;&#32473;&#23450;&#20219;&#24847;&#26102;&#38388;&#28857;&#30340;&#25968;&#25454;&#12290;&#19982;&#20256;&#32479;&#30340;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#19981;&#21516;&#65292;&#20256;&#32479;&#27169;&#22411;&#20381;&#36182;&#20110;&#21152;&#24615;&#39640;&#26031;&#22122;&#22768;&#21644;&#37325;&#26032;&#21152;&#26435;&#30340;&#35777;&#25454;&#19979;&#30028;&#65288;ELBO&#65289;&#65292;beta&#25193;&#25955;&#26159;&#20056;&#27861;&#30340;&#65292;&#24182;&#19988;&#36890;&#36807;&#20174;KL&#25955;&#24230;&#30340;&#20984;&#24615;&#25512;&#23548;&#20986;&#26469;&#30340;KL&#25955;&#24230;&#19978;&#30028;&#65288;KLUB&#65289;&#36827;&#34892;&#20248;&#21270;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;KLUB&#30456;&#23545;&#20110;&#36127;ELBO&#26469;&#35828;&#23545;&#20110;&#20248;&#21270;beta&#25193;&#25955;&#26356;&#21152;&#26377;&#25928;&#65292;&#36127;ELBO&#20063;&#21487;&#20197;&#20316;&#20026;&#30456;&#21516;KL&#25955;&#24230;&#30340;KLUB&#65292;&#21482;&#26159;&#20854;&#20004;&#20010;&#21442;&#25968;&#20132;&#25442;&#20102;&#20301;&#32622;&#12290;beta&#25193;&#25955;&#30340;&#25439;&#22833;&#20989;&#25968;&#20197;Bregman&#25955;&#24230;&#20026;&#25351;&#26631;&#26469;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce beta diffusion, a novel generative modeling method that integrates demasking and denoising to generate data within bounded ranges. Using scaled and shifted beta distributions, beta diffusion utilizes multiplicative transitions over time to create both forward and reverse diffusion processes, maintaining beta distributions in both the forward marginals and the reverse conditionals, given the data at any point in time. Unlike traditional diffusion-based generative models relying on additive Gaussian noise and reweighted evidence lower bounds (ELBOs), beta diffusion is multiplicative and optimized with KL-divergence upper bounds (KLUBs) derived from the convexity of the KL divergence. We demonstrate that the proposed KLUBs are more effective for optimizing beta diffusion compared to negative ELBOs, which can also be derived as the KLUBs of the same KL divergence with its two arguments swapped. The loss function of beta diffusion, expressed in terms of Bregman divergence, furt
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#38543;&#26426;&#38646;&#38454;&#20248;&#21270;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20108;&#27425;&#22411;&#30446;&#26631;&#20989;&#25968;&#21450;&#20854;&#23616;&#37096;&#20960;&#20309;&#32467;&#26500;&#30340;&#26368;&#20248;Hessian&#30456;&#20851;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#20174;&#20449;&#24687;&#35770;&#35282;&#24230;&#25552;&#20379;Hessian&#30456;&#20851;&#22797;&#26434;&#24230;&#30340;&#19979;&#30028;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;Hessian&#26080;&#20851;&#30340;&#31639;&#27861;&#21487;&#26222;&#36941;&#23454;&#29616;&#25152;&#26377;Hessian&#23454;&#20363;&#30340;&#28176;&#36817;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.12383</link><description>&lt;p&gt;
&#20108;&#27425;&#22411;&#36172;&#33218;&#26426;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65306;Hessian&#30456;&#20851;&#24615;&#30028;&#38480;&#21644;&#26368;&#20248;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sample Complexity for Quadratic Bandits: Hessian Dependent Bounds and Optimal Algorithms. (arXiv:2306.12383v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12383
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#38543;&#26426;&#38646;&#38454;&#20248;&#21270;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20108;&#27425;&#22411;&#30446;&#26631;&#20989;&#25968;&#21450;&#20854;&#23616;&#37096;&#20960;&#20309;&#32467;&#26500;&#30340;&#26368;&#20248;Hessian&#30456;&#20851;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#20174;&#20449;&#24687;&#35770;&#35282;&#24230;&#25552;&#20379;Hessian&#30456;&#20851;&#22797;&#26434;&#24230;&#30340;&#19979;&#30028;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;Hessian&#26080;&#20851;&#30340;&#31639;&#27861;&#21487;&#26222;&#36941;&#23454;&#29616;&#25152;&#26377;Hessian&#23454;&#20363;&#30340;&#28176;&#36817;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#38543;&#26426;&#38646;&#38454;&#20248;&#21270;&#20013;&#65292;&#20102;&#35299;&#22914;&#20309;&#20805;&#20998;&#21033;&#29992;&#24213;&#23618;&#30446;&#26631;&#20989;&#25968;&#30340;&#23616;&#37096;&#20960;&#20309;&#32467;&#26500;&#26159;&#19968;&#20010;&#23454;&#38469;&#30456;&#20851;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#32771;&#34385;&#19968;&#31181;&#22522;&#26412;&#24773;&#20917;&#65292;&#21363;&#30446;&#26631;&#20989;&#25968;&#26159;&#20108;&#27425;&#22411;&#30340;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#26368;&#20248;Hessian&#30456;&#20851;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#31532;&#19968;&#20010;&#32039;&#23494;&#21051;&#30011;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#20855;&#26377;&#21452;&#37325;&#24615;&#36136;&#12290;&#39318;&#20808;&#65292;&#20174;&#20449;&#24687;&#35770;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#31216;&#20026;&#33021;&#37327;&#20998;&#37197;&#30340;&#27010;&#24565;&#26469;&#25429;&#25417;&#25628;&#32034;&#31639;&#27861;&#21644;&#30446;&#26631;&#20989;&#25968;&#20960;&#20309;&#32467;&#26500;&#20043;&#38388;&#30340;&#20132;&#20114;&#65292;&#35777;&#26126;&#20102;Hessian&#30456;&#20851;&#22797;&#26434;&#24230;&#30340;&#32039;&#23494;&#19979;&#30028;&#12290;&#36890;&#36807;&#35299;&#20915;&#26368;&#20248;&#33021;&#37327;&#35889;&#65292;&#24471;&#21040;&#20102;&#37197;&#22871;&#30340;&#19978;&#38480;&#12290;&#20854;&#27425;&#65292;&#31639;&#27861;&#26041;&#38754;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23384;&#22312;&#19968;&#31181;Hessian&#26080;&#20851;&#30340;&#31639;&#27861;&#65292;&#33021;&#22815;&#26222;&#36941;&#23454;&#29616;&#25152;&#26377;Hessian&#23454;&#20363;&#30340;&#28176;&#36817;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#31639;&#27861;&#33021;&#22815;&#23454;&#29616;&#30340;&#28176;&#36817;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#23545;&#20110;&#37325;&#23614;&#22122;&#22768;&#20998;&#24067;&#20173;&#28982;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
In stochastic zeroth-order optimization, a problem of practical relevance is understanding how to fully exploit the local geometry of the underlying objective function. We consider a fundamental setting in which the objective function is quadratic, and provide the first tight characterization of the optimal Hessian-dependent sample complexity. Our contribution is twofold. First, from an information-theoretic point of view, we prove tight lower bounds on Hessian-dependent complexities by introducing a concept called energy allocation, which captures the interaction between the searching algorithm and the geometry of objective functions. A matching upper bound is obtained by solving the optimal energy spectrum. Then, algorithmically, we show the existence of a Hessian-independent algorithm that universally achieves the asymptotic optimal sample complexities for all Hessian instances. The optimal sample complexities achieved by our algorithm remain valid for heavy-tailed noise distributio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27979;&#37327;&#20102;Barron&#31354;&#38388;&#21644;&#35889;Barron&#31354;&#38388;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#25552;&#20379;&#20102;&#23884;&#20837;&#19981;&#31561;&#24335;&#12290;</title><link>http://arxiv.org/abs/2305.19082</link><description>&lt;p&gt;
Barron&#22411;&#31354;&#38388;&#30340;&#23884;&#20837;&#19981;&#31561;&#24335;
&lt;/p&gt;
&lt;p&gt;
Embedding Inequalities for Barron-type Spaces. (arXiv:2305.19082v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19082
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27979;&#37327;&#20102;Barron&#31354;&#38388;&#21644;&#35889;Barron&#31354;&#38388;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#25552;&#20379;&#20102;&#23884;&#20837;&#19981;&#31561;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#26159;&#29702;&#35299;&#39640;&#32500;&#26465;&#20214;&#19979;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#21644;&#27867;&#21270;&#24615;&#36136;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#30740;&#31350;&#20154;&#21592;&#24341;&#20837;&#20102;Barron&#31354;&#38388;$\mathcal{B}_s(\Omega)$&#21644;&#35889;Barron&#31354;&#38388;$\mathcal{F}_s(\Omega)$&#65292;&#20854;&#20013;&#25351;&#25968;$s$&#34920;&#24449;&#20102;&#36825;&#20123;&#31354;&#38388;&#20013;&#20989;&#25968;&#30340;&#24179;&#28369;&#24615;&#65292;$\Omega\subset\mathbb{R}^d$&#34920;&#31034;&#36755;&#20837;&#22495;&#12290;&#28982;&#32780;&#65292;&#20004;&#31181;&#31867;&#22411;&#30340;Barron&#31354;&#38388;&#20043;&#38388;&#30340;&#20851;&#31995;&#20173;&#19981;&#28165;&#26970;&#12290;&#26412;&#25991;&#36890;&#36807;&#20197;&#19979;&#19981;&#31561;&#24335;&#24314;&#31435;&#20102;&#36825;&#20123;&#31354;&#38388;&#20043;&#38388;&#30340;&#36830;&#32493;&#23884;&#20837;&#65306;&#23545;&#20110;&#20219;&#24847;$\delta\in(0,1),s\in\mathbb{N}^{+}$&#21644;$f:\Omega \mapsto \mathbb{R}$&#65292;&#37117;&#26377;\[ \delta\gamma^{\delta-s}_{\Omega}\|f\|_{\mathcal{F}_{s-\delta}(\Omega)}\lesssim_s \|f\|_{\mathcal{B}_s(\Omega)}\lesssim_s \|f\|_{\mathcal{F}_{s+1}(\Omega)}, \]&#20854;&#20013;$\gamma_{\Omega}=\sup_{\|v\|_2=1,x\in\Omega}|v^Tx|$&#65292;$\lesssim_s$&#34920;&#31034;&#20165;&#19982;&#24179;&#28369;&#21442;&#25968;$s$&#26377;&#20851;&#30340;&#24120;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
One of the fundamental problems in deep learning theory is understanding the approximation and generalization properties of two-layer neural networks in high dimensions. In order to tackle this issue, researchers have introduced the Barron space $\mathcal{B}_s(\Omega)$ and the spectral Barron space $\mathcal{F}_s(\Omega)$, where the index $s$ characterizes the smoothness of functions within these spaces and $\Omega\subset\mathbb{R}^d$ represents the input domain. However, it is still not clear what is the relationship between the two types of Barron spaces. In this paper, we establish continuous embeddings between these spaces as implied by the following inequality: for any $\delta\in (0,1), s\in \mathbb{N}^{+}$ and $f: \Omega \mapsto\mathbb{R}$, it holds that \[ \delta\gamma^{\delta-s}_{\Omega}\|f\|_{\mathcal{F}_{s-\delta}(\Omega)}\lesssim_s \|f\|_{\mathcal{B}_s(\Omega)}\lesssim_s \|f\|_{\mathcal{F}_{s+1}(\Omega)}, \] where $\gamma_{\Omega}=\sup_{\|v\|_2=1,x\in\Omega}|v^Tx|$ and notab
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#29702;&#35770;&#23618;&#38754;&#25506;&#31350;&#20102;&#24102;&#26377;&#8220;&#24605;&#32500;&#38142;&#8221;&#25552;&#31034;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35299;&#20915;&#22522;&#26412;&#25968;&#23398;&#21644;&#20915;&#31574;&#38382;&#39064;&#20013;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#33258;&#22238;&#24402;Transformer&#22823;&#23567;&#24658;&#23450;&#21363;&#21487;&#35299;&#20915;&#20219;&#21153;&#65292;&#25581;&#31034;&#20102;&#8220;&#24605;&#32500;&#38142;&#8221;&#25552;&#31034;&#30340;&#32972;&#21518;&#26426;&#21046;&#12290;</title><link>http://arxiv.org/abs/2305.15408</link><description>&lt;p&gt;
&#20174;&#29702;&#35770;&#35282;&#24230;&#25581;&#31034;&#8220;&#24605;&#32500;&#38142;&#8221;&#32972;&#21518;&#30340;&#22885;&#31192;
&lt;/p&gt;
&lt;p&gt;
Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective. (arXiv:2305.15408v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15408
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#29702;&#35770;&#23618;&#38754;&#25506;&#31350;&#20102;&#24102;&#26377;&#8220;&#24605;&#32500;&#38142;&#8221;&#25552;&#31034;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35299;&#20915;&#22522;&#26412;&#25968;&#23398;&#21644;&#20915;&#31574;&#38382;&#39064;&#20013;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#33258;&#22238;&#24402;Transformer&#22823;&#23567;&#24658;&#23450;&#21363;&#21487;&#35299;&#20915;&#20219;&#21153;&#65292;&#25581;&#31034;&#20102;&#8220;&#24605;&#32500;&#38142;&#8221;&#25552;&#31034;&#30340;&#32972;&#21518;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;"&#24605;&#32500;&#38142;"&#25552;&#31034;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#22312;&#28041;&#21450;&#25968;&#23398;&#25110;&#25512;&#29702;&#30340;&#22797;&#26434;&#20219;&#21153;&#20013;&#12290;&#23613;&#31649;&#33719;&#24471;&#20102;&#24040;&#22823;&#30340;&#23454;&#35777;&#25104;&#21151;&#65292;&#20294;&#8220;&#24605;&#32500;&#38142;&#8221;&#32972;&#21518;&#30340;&#26426;&#21046;&#20197;&#21450;&#23427;&#22914;&#20309;&#37322;&#25918;LLMs&#30340;&#28508;&#21147;&#20173;&#28982;&#26159;&#31070;&#31192;&#30340;&#12290;&#26412;&#25991;&#39318;&#27425;&#20174;&#29702;&#35770;&#19978;&#22238;&#31572;&#20102;&#36825;&#20123;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;LLMs&#24102;&#26377;&#8220;&#24605;&#32500;&#38142;&#8221;&#22312;&#35299;&#20915;&#22522;&#26412;&#25968;&#23398;&#21644;&#20915;&#31574;&#38382;&#39064;&#20013;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#39318;&#20808;&#32473;&#20986;&#19968;&#20010;&#19981;&#21487;&#33021;&#30340;&#32467;&#26524;&#65292;&#34920;&#26126;&#20219;&#20309;&#26377;&#38480;&#28145;&#24230;&#30340;Transformer&#37117;&#19981;&#33021;&#30452;&#25509;&#36755;&#20986;&#27491;&#30830;&#30340;&#22522;&#26412;&#31639;&#26415;/&#26041;&#31243;&#20219;&#21153;&#30340;&#31572;&#26696;&#65292;&#38500;&#38750;&#27169;&#22411;&#22823;&#23567;&#38543;&#30528;&#36755;&#20837;&#38271;&#24230;&#30340;&#22686;&#21152;&#21576;&#36229;&#22810;&#39033;&#24335;&#22686;&#38271;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#36890;&#36807;&#26500;&#36896;&#35777;&#26126;&#65292;&#22823;&#23567;&#24658;&#23450;&#30340;&#33258;&#22238;&#24402;Transformer&#36275;&#20197;&#36890;&#36807;&#20351;&#29992;&#24120;&#29992;&#30340;&#25968;&#23398;&#35821;&#35328;&#24418;&#24335;&#29983;&#25104;&#8220;&#24605;&#32500;&#38142;&#8221;&#25512;&#23548;&#26469;&#35299;&#20915;&#36825;&#20004;&#20010;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent studies have discovered that Chain-of-Thought prompting (CoT) can dramatically improve the performance of Large Language Models (LLMs), particularly when dealing with complex tasks involving mathematics or reasoning. Despite the enormous empirical success, the underlying mechanisms behind CoT and how it unlocks the potential of LLMs remain elusive. In this paper, we take a first step towards theoretically answering these questions. Specifically, we examine the capacity of LLMs with CoT in solving fundamental mathematical and decision-making problems. We start by giving an impossibility result showing that any bounded-depth Transformer cannot directly output correct answers for basic arithmetic/equation tasks unless the model size grows super-polynomially with respect to the input length. In contrast, we then prove by construction that autoregressive Transformers of a constant size suffice to solve both tasks by generating CoT derivations using a commonly-used math language forma
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#30340;&#31639;&#27861;&#26159;&#23398;&#20064;&#29575;&#26080;&#20851;&#30340;&#32422;&#26463;&#22495;&#37319;&#26679;&#31639;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#65292;&#33021;&#22815;&#22788;&#29702;&#22810;&#31181;&#32422;&#26463;&#37319;&#26679;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#19982;&#29616;&#26377;&#31639;&#27861;&#30456;&#31454;&#20105;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.14943</link><description>&lt;p&gt;
&#23398;&#20064;&#29575;&#26080;&#20851;&#30340;&#32422;&#26463;&#22495;Bayesian&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Learning Rate Free Bayesian Inference in Constrained Domains. (arXiv:2305.14943v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14943
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30340;&#31639;&#27861;&#26159;&#23398;&#20064;&#29575;&#26080;&#20851;&#30340;&#32422;&#26463;&#22495;&#37319;&#26679;&#31639;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#65292;&#33021;&#22815;&#22788;&#29702;&#22810;&#31181;&#32422;&#26463;&#37319;&#26679;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#19982;&#29616;&#26377;&#31639;&#27861;&#30456;&#31454;&#20105;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#22871;&#26032;&#30340;&#22522;&#20110;&#31890;&#23376;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#32422;&#26463;&#22495;&#20869;&#36827;&#34892;&#37319;&#26679;&#65292;&#36825;&#26159;&#23436;&#20840;&#19982;&#23398;&#20064;&#29575;&#26080;&#20851;&#30340;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20102;&#20984;&#20248;&#21270;&#20013;&#30340;&#30828;&#24065;&#25237;&#27880;&#24605;&#24819;&#65292;&#20197;&#21450;&#32422;&#26463;&#37319;&#26679;&#20316;&#20026;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#19978;&#38236;&#20687;&#20248;&#21270;&#38382;&#39064;&#30340;&#35266;&#28857;&#12290;&#22522;&#20110;&#36825;&#20010;&#35266;&#28857;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#65292;&#29992;&#20110;&#20960;&#31181;&#29616;&#26377;&#30340;&#32422;&#26463;&#37319;&#26679;&#31639;&#27861;&#65292;&#21253;&#25324;&#38236;&#20687;Langevin&#21160;&#21147;&#23398;&#21644;&#38236;&#20687;Stein&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#30340;&#25968;&#20540;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#31639;&#27861;&#30340;&#24615;&#33021;&#65292;&#21253;&#25324;&#20174;&#21333;&#32431;&#24418;&#30446;&#26631;&#36827;&#34892;&#37319;&#26679;&#12289;&#24102;&#20844;&#24179;&#24615;&#32422;&#26463;&#36827;&#34892;&#37319;&#26679;&#20197;&#21450;&#21518;&#36873;&#25321;&#25512;&#26029;&#20013;&#30340;&#32422;&#26463;&#37319;&#26679;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#19981;&#38656;&#35201;&#35843;&#25972;&#20219;&#20309;&#36229;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#23454;&#29616;&#20102;&#19982;&#29616;&#26377;&#32422;&#26463;&#37319;&#26679;&#26041;&#27861;&#30456;&#31454;&#20105;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a suite of new particle-based algorithms for sampling on constrained domains which are entirely learning rate free. Our approach leverages coin betting ideas from convex optimisation, and the viewpoint of constrained sampling as a mirrored optimisation problem on the space of probability measures. Based on this viewpoint, we also introduce a unifying framework for several existing constrained sampling algorithms, including mirrored Langevin dynamics and mirrored Stein variational gradient descent. We demonstrate the performance of our algorithms on a range of numerical examples, including sampling from targets on the simplex, sampling with fairness constraints, and constrained sampling problems in post-selection inference. Our results indicate that our algorithms achieve competitive performance with existing constrained sampling methods, without the need to tune any hyperparameters.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#22870;&#21169;&#20998;&#24067;&#37325;&#23614;&#30340;MAB&#38382;&#39064;&#30340;&#38544;&#24335;&#35268;&#33539;&#21270;&#39044;&#27979;&#22120;&#65292;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#37325;&#23614;&#38543;&#26426;MAB&#38382;&#39064;&#19978;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2305.06743</link><description>&lt;p&gt;
&#38024;&#23545;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#37325;&#23614;&#22810;&#33218;&#32769;&#34382;&#26426;&#30340;&#38544;&#24335;&#33539;&#25968;&#39044;&#27979;&#22120;&#30340;&#20462;&#21098;
&lt;/p&gt;
&lt;p&gt;
Implicitly normalized forecaster with clipping for linear and non-linear heavy-tailed multi-armed bandits. (arXiv:2305.06743v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06743
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#22870;&#21169;&#20998;&#24067;&#37325;&#23614;&#30340;MAB&#38382;&#39064;&#30340;&#38544;&#24335;&#35268;&#33539;&#21270;&#39044;&#27979;&#22120;&#65292;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#37325;&#23614;&#38543;&#26426;MAB&#38382;&#39064;&#19978;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24050;&#30693;&#38544;&#24335;&#33539;&#25968;&#39044;&#27979;&#22120;&#65288;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#65292;&#20197;Tsallis&#29109;&#20316;&#20026;prox&#20989;&#25968;&#65289;&#26159;&#23545;&#25239;&#24615;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#65288;MAB&#65289;&#30340;&#26368;&#20339;&#31639;&#27861;&#12290;&#20294;&#26159;&#65292;&#22823;&#22810;&#25968;&#22797;&#26434;&#24615;&#32467;&#26524;&#37117;&#20381;&#36182;&#20110;&#26377;&#30028;&#22870;&#21169;&#25110;&#20854;&#20182;&#38480;&#21046;&#24615;&#20551;&#35774;&#12290;&#26368;&#36817;&#26377;&#20851;&#26368;&#20339;&#20108;&#32773;&#32467;&#21512;&#31639;&#27861;&#30340;&#30740;&#31350;&#24050;&#32463;&#38024;&#23545;&#23545;&#25163;&#24615;&#21644;&#38543;&#26426;&#37325;&#23614;MAB&#35774;&#32622;&#36827;&#34892;&#20102;&#25506;&#35752;&#12290;&#36825;&#20010;&#31639;&#27861;&#22312;&#36825;&#20004;&#31181;&#24773;&#20917;&#19979;&#37117;&#26159;&#26368;&#20248;&#30340;&#65292;&#20294;&#19981;&#33021;&#20805;&#20998;&#21033;&#29992;&#25968;&#25454;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#38024;&#23545;&#22870;&#21169;&#20998;&#24067;&#37325;&#23614;&#30340;MAB&#38382;&#39064;&#25552;&#20986;&#20102;&#24102;&#21098;&#36753;&#30340;&#38544;&#24335;&#35268;&#33539;&#21270;&#39044;&#27979;&#22120;&#12290;&#25105;&#20204;&#22312;&#22870;&#21169;&#20998;&#24067;&#19978;&#25552;&#20986;&#28176;&#36827;&#25910;&#25947;&#24615;&#32467;&#26524;&#65292;&#24182;&#35777;&#26126;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#23545;&#20110;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#37325;&#23614;&#38543;&#26426;MAB&#38382;&#39064;&#26159;&#26368;&#20248;&#30340;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#19982;&#26368;&#22909;&#30340;&#20108;&#32773;&#32467;&#21512;&#31639;&#27861;&#30456;&#27604;&#65292;&#35813;&#31639;&#27861;&#36890;&#24120;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Implicitly Normalized Forecaster (online mirror descent with Tsallis entropy as prox-function) is known to be an optimal algorithm for adversarial multi-armed problems (MAB). However, most of the complexity results rely on bounded rewards or other restrictive assumptions. Recently closely related best-of-both-worlds algorithm were proposed for both adversarial and stochastic heavy-tailed MAB settings. This algorithm is known to be optimal in both settings, but fails to exploit data fully. In this paper, we propose Implicitly Normalized Forecaster with clipping for MAB problems with heavy-tailed distribution on rewards. We derive convergence results under mild assumptions on rewards distribution and show that the proposed method is optimal for both linear and non-linear heavy-tailed stochastic MAB problems. Also we show that algorithm usually performs better compared to best-of-two-worlds algorithm.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#35299;&#37322;&#32422;&#26463;&#19979;&#30340;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;EPAC&#27169;&#22411;&#65292;&#25506;&#35752;&#20102;&#20351;&#29992;&#36825;&#20123;&#35299;&#37322;&#26102;&#27169;&#22411;&#30340;&#30410;&#22788;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#21464;&#20998;&#36817;&#20284;&#30340;&#31639;&#27861;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2303.14496</link><description>&lt;p&gt;
&#35299;&#37322;&#32422;&#26463;&#19979;&#30340;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Learning with Explanation Constraints. (arXiv:2303.14496v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14496
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35299;&#37322;&#32422;&#26463;&#19979;&#30340;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;EPAC&#27169;&#22411;&#65292;&#25506;&#35752;&#20102;&#20351;&#29992;&#36825;&#20123;&#35299;&#37322;&#26102;&#27169;&#22411;&#30340;&#30410;&#22788;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#21464;&#20998;&#36817;&#20284;&#30340;&#31639;&#27861;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#30417;&#30563;&#23398;&#20064;&#20551;&#35774;&#23384;&#22312;&#26631;&#27880;&#25968;&#25454;&#65292;&#20294;&#25105;&#20204;&#21487;&#33021;&#26377;&#20851;&#20110;&#27169;&#22411;&#24212;&#22914;&#20309;&#36816;&#34892;&#30340;&#20808;&#39564;&#20449;&#24687;&#12290;&#26412;&#25991;&#23558;&#20854;&#24418;&#24335;&#21270;&#20026;&#20174;&#35299;&#37322;&#32422;&#26463;&#20013;&#23398;&#20064;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#23398;&#20064;&#29702;&#35770;&#26694;&#26550;&#65292;&#20998;&#26512;&#20102;&#36825;&#20123;&#35299;&#37322;&#22914;&#20309;&#25552;&#39640;&#27169;&#22411;&#30340;&#23398;&#20064;&#33021;&#21147;&#12290;&#26412;&#25991;&#30340;&#31532;&#19968;&#39033;&#20851;&#38190;&#36129;&#29486;&#26159;&#36890;&#36807;&#23450;&#20041;&#25105;&#20204;&#31216;&#20043;&#20026;EPAC&#27169;&#22411;&#65288;&#22312;&#26032;&#25968;&#25454;&#26399;&#26395;&#20013;&#28385;&#36275;&#36825;&#20123;&#32422;&#26463;&#30340;&#27169;&#22411;&#65289;&#26469;&#22238;&#31572;&#21738;&#20123;&#27169;&#22411;&#20250;&#21463;&#30410;&#20110;&#35299;&#37322;&#36825;&#19968;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#26631;&#20934;&#30340;&#23398;&#20064;&#29702;&#35770;&#24037;&#20855;&#20998;&#26512;&#20102;&#36825;&#31867;&#27169;&#22411;&#12290;&#31532;&#20108;&#20010;&#20851;&#38190;&#36129;&#29486;&#26159;&#23545;&#20110;&#30001;&#32447;&#24615;&#27169;&#22411;&#21644;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26799;&#24230;&#20449;&#24687;&#32473;&#20986;&#30340;&#35268;&#33539;&#35299;&#37322;&#30340;&#38480;&#21046;&#65288;&#20197;&#20854;Rademacher&#22797;&#26434;&#24230;&#20026;&#34913;&#37327;&#26631;&#20934;&#65289;&#36827;&#34892;&#20102;&#34920;&#24449;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#31181;&#21464;&#20998;&#36817;&#20284;&#25552;&#20379;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#30340;&#31639;&#27861;&#35299;&#20915;&#26041;&#26696;&#65292;&#23427;&#33021;&#22815;&#23454;&#29616;&#26356;&#22909;&#30340;&#24615;&#33021;&#24182;&#28385;&#36275;&#36825;&#20123;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;
While supervised learning assumes the presence of labeled data, we may have prior information about how models should behave. In this paper, we formalize this notion as learning from explanation constraints and provide a learning theoretic framework to analyze how such explanations can improve the learning of our models. For what models would explanations be helpful? Our first key contribution addresses this question via the definition of what we call EPAC models (models that satisfy these constraints in expectation over new data), and we analyze this class of models using standard learning theoretic tools. Our second key contribution is to characterize these restrictions (in terms of their Rademacher complexities) for a canonical class of explanations given by gradient information for linear models and two layer neural networks. Finally, we provide an algorithmic solution for our framework, via a variational approximation that achieves better performance and satisfies these constraint
&lt;/p&gt;</description></item><item><title>FuNVol&#26159;&#19968;&#20010;&#22810;&#36164;&#20135;&#38544;&#21547;&#27874;&#21160;&#29575;&#24066;&#22330;&#27169;&#25311;&#22120;&#65292;&#20351;&#29992;&#20989;&#25968;&#20027;&#25104;&#20998;&#21644;&#31070;&#32463;SDE&#29983;&#25104;&#30495;&#23454;&#21382;&#21490;&#20215;&#26684;&#30340;IV&#34920;&#38754;&#24207;&#21015;&#65292;&#24182;&#22312;&#26080;&#38745;&#24577;&#22871;&#21033;&#30340;&#34920;&#38754;&#27425;&#27969;&#24418;&#20869;&#20135;&#29983;&#19968;&#33268;&#30340;&#24066;&#22330;&#24773;&#26223;&#12290;&#21516;&#26102;&#65292;&#20351;&#29992;&#27169;&#25311;&#34920;&#38754;&#36827;&#34892;&#23545;&#20914;&#21487;&#20197;&#29983;&#25104;&#19982;&#23454;&#29616;P&#65286;L&#19968;&#33268;&#30340;&#25439;&#30410;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2303.00859</link><description>&lt;p&gt;
FuNVol&#65306;&#20351;&#29992;&#20989;&#25968;&#20027;&#25104;&#20998;&#21644;&#31070;&#32463;SDE&#30340;&#22810;&#36164;&#20135;&#38544;&#21547;&#27874;&#21160;&#29575;&#24066;&#22330;&#27169;&#25311;&#22120;
&lt;/p&gt;
&lt;p&gt;
FuNVol: A Multi-Asset Implied Volatility Market Simulator using Functional Principal Components and Neural SDEs. (arXiv:2303.00859v2 [q-fin.CP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.00859
&lt;/p&gt;
&lt;p&gt;
FuNVol&#26159;&#19968;&#20010;&#22810;&#36164;&#20135;&#38544;&#21547;&#27874;&#21160;&#29575;&#24066;&#22330;&#27169;&#25311;&#22120;&#65292;&#20351;&#29992;&#20989;&#25968;&#20027;&#25104;&#20998;&#21644;&#31070;&#32463;SDE&#29983;&#25104;&#30495;&#23454;&#21382;&#21490;&#20215;&#26684;&#30340;IV&#34920;&#38754;&#24207;&#21015;&#65292;&#24182;&#22312;&#26080;&#38745;&#24577;&#22871;&#21033;&#30340;&#34920;&#38754;&#27425;&#27969;&#24418;&#20869;&#20135;&#29983;&#19968;&#33268;&#30340;&#24066;&#22330;&#24773;&#26223;&#12290;&#21516;&#26102;&#65292;&#20351;&#29992;&#27169;&#25311;&#34920;&#38754;&#36827;&#34892;&#23545;&#20914;&#21487;&#20197;&#29983;&#25104;&#19982;&#23454;&#29616;P&#65286;L&#19968;&#33268;&#30340;&#25439;&#30410;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#21644;&#31070;&#32463;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65292;&#32467;&#21512;&#27010;&#29575;&#31215;&#20998;&#21464;&#25442;&#24809;&#32602;&#26469;&#29983;&#25104;&#22810;&#20010;&#36164;&#20135;&#30340;&#38544;&#21547;&#27874;&#21160;&#29575;&#34920;&#38754;&#24207;&#21015;&#65292;&#35813;&#26041;&#27861;&#24544;&#23454;&#20110;&#21382;&#21490;&#20215;&#26684;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23398;&#20064;IV&#34920;&#38754;&#21644;&#20215;&#26684;&#30340;&#32852;&#21512;&#21160;&#24577;&#20135;&#29983;&#30340;&#24066;&#22330;&#24773;&#26223;&#19982;&#21382;&#21490;&#29305;&#24449;&#19968;&#33268;&#65292;&#24182;&#19988;&#22312;&#27809;&#26377;&#38745;&#24577;&#22871;&#21033;&#30340;&#34920;&#38754;&#27425;&#27969;&#24418;&#20869;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20351;&#29992;&#27169;&#25311;&#34920;&#38754;&#36827;&#34892;&#23545;&#20914;&#20250;&#29983;&#25104;&#19982;&#23454;&#29616;P&#65286;L&#19968;&#33268;&#30340;&#25439;&#30410;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
Here, we introduce a new approach for generating sequences of implied volatility (IV) surfaces across multiple assets that is faithful to historical prices. We do so using a combination of functional data analysis and neural stochastic differential equations (SDEs) combined with a probability integral transform penalty to reduce model misspecification. We demonstrate that learning the joint dynamics of IV surfaces and prices produces market scenarios that are consistent with historical features and lie within the sub-manifold of surfaces that are essentially free of static arbitrage. Finally, we demonstrate that delta hedging using the simulated surfaces generates profit and loss (P&amp;L) distributions that are consistent with realised P&amp;Ls.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#36890;&#36807;&#30740;&#31350;&#37327;&#23376;&#23398;&#20064;&#29702;&#35770;&#25299;&#23637;&#20102;&#25209;&#22788;&#29702;&#22810;&#31867;&#23398;&#20064;&#12289;&#22312;&#32447;&#24067;&#23572;&#23398;&#20064;&#21644;&#22312;&#32447;&#22810;&#31867;&#23398;&#20064;&#65292;&#24182;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#20855;&#26377;&#37327;&#23376;&#31034;&#20363;&#30340;&#22312;&#32447;&#23398;&#20064;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2302.07409</link><description>&lt;p&gt;
&#12298;&#36229;&#36234;&#25209;&#22788;&#29702;&#20108;&#20803;&#20998;&#31867;&#30340;&#37327;&#23376;&#23398;&#20064;&#29702;&#35770;&#12299;
&lt;/p&gt;
&lt;p&gt;
Quantum Learning Theory Beyond Batch Binary Classification. (arXiv:2302.07409v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07409
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#36890;&#36807;&#30740;&#31350;&#37327;&#23376;&#23398;&#20064;&#29702;&#35770;&#25299;&#23637;&#20102;&#25209;&#22788;&#29702;&#22810;&#31867;&#23398;&#20064;&#12289;&#22312;&#32447;&#24067;&#23572;&#23398;&#20064;&#21644;&#22312;&#32447;&#22810;&#31867;&#23398;&#20064;&#65292;&#24182;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#20855;&#26377;&#37327;&#23376;&#31034;&#20363;&#30340;&#22312;&#32447;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Arunachalam&#21644;de Wolf&#65288;2018&#65289;&#35777;&#26126;&#20102;&#22312;&#21487;&#23454;&#29616;&#21644;&#31946;&#28034;&#35774;&#32622;&#19979;&#65292;&#37327;&#23376;&#25209;&#22788;&#29702;&#23398;&#20064;&#24067;&#23572;&#20989;&#25968;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#19982;&#30456;&#24212;&#30340;&#32463;&#20856;&#26679;&#26412;&#22797;&#26434;&#24615;&#20855;&#26377;&#30456;&#21516;&#30340;&#24418;&#24335;&#21644;&#25968;&#37327;&#32423;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#26126;&#26174;&#20196;&#20154;&#24778;&#35766;&#30340;&#32467;&#26524;&#25512;&#24191;&#21040;&#20102;&#25209;&#22788;&#29702;&#22810;&#31867;&#23398;&#20064;&#12289;&#22312;&#32447;&#24067;&#23572;&#23398;&#20064;&#21644;&#22312;&#32447;&#22810;&#31867;&#23398;&#20064;&#12290;&#23545;&#20110;&#25105;&#20204;&#30340;&#22312;&#32447;&#23398;&#20064;&#32467;&#26524;&#65292;&#25105;&#20204;&#39318;&#20808;&#32771;&#34385;&#20102;Dawid&#21644;Tewari&#65288;2022&#65289;&#32463;&#20856;&#27169;&#22411;&#30340;&#33258;&#36866;&#24212;&#23545;&#25163;&#21464;&#20307;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31532;&#19968;&#20010;&#65288;&#25454;&#25105;&#20204;&#25152;&#30693;&#65289;&#20855;&#26377;&#37327;&#23376;&#31034;&#20363;&#30340;&#22312;&#32447;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Arunachalam and de Wolf (2018) showed that the sample complexity of quantum batch learning of boolean functions, in the realizable and agnostic settings, has the same form and order as the corresponding classical sample complexities. In this paper, we extend this, ostensibly surprising, message to batch multiclass learning, online boolean learning, and online multiclass learning. For our online learning results, we first consider an adaptive adversary variant of the classical model of Dawid and Tewari (2022). Then, we introduce the first (to the best of our knowledge) model of online learning with quantum examples.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#22914;&#20309;&#22312;&#24046;&#20998;&#38544;&#31169;&#26465;&#20214;&#19979;&#20272;&#35745;&#19968;&#20010;&#20998;&#24067;&#30340;&#22810;&#20010;&#20998;&#20301;&#25968;&#12290;&#23427;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#65306;&#19968;&#31181;&#26159;&#36890;&#36807;&#31169;&#26377;&#22320;&#20272;&#35745;&#26679;&#26412;&#30340;&#32463;&#39564;&#20998;&#20301;&#25968;&#26469;&#20272;&#35745;&#20998;&#24067;&#30340;&#20998;&#20301;&#25968;&#65292;&#21478;&#19968;&#31181;&#26159;&#20351;&#29992;&#23494;&#24230;&#20272;&#35745;&#25216;&#26415;&#36827;&#34892;&#20998;&#20301;&#25968;&#20989;&#25968;&#20272;&#35745;&#65292;&#24182;&#19988;&#23637;&#31034;&#20102;&#20004;&#31181;&#26041;&#27861;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2302.06943</link><description>&lt;p&gt;
&#22810;&#20010;&#20998;&#20301;&#25968;&#30340;&#31169;&#26377;&#32479;&#35745;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Private Statistical Estimation of Many Quantiles. (arXiv:2302.06943v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06943
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#22914;&#20309;&#22312;&#24046;&#20998;&#38544;&#31169;&#26465;&#20214;&#19979;&#20272;&#35745;&#19968;&#20010;&#20998;&#24067;&#30340;&#22810;&#20010;&#20998;&#20301;&#25968;&#12290;&#23427;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#65306;&#19968;&#31181;&#26159;&#36890;&#36807;&#31169;&#26377;&#22320;&#20272;&#35745;&#26679;&#26412;&#30340;&#32463;&#39564;&#20998;&#20301;&#25968;&#26469;&#20272;&#35745;&#20998;&#24067;&#30340;&#20998;&#20301;&#25968;&#65292;&#21478;&#19968;&#31181;&#26159;&#20351;&#29992;&#23494;&#24230;&#20272;&#35745;&#25216;&#26415;&#36827;&#34892;&#20998;&#20301;&#25968;&#20989;&#25968;&#20272;&#35745;&#65292;&#24182;&#19988;&#23637;&#31034;&#20102;&#20004;&#31181;&#26041;&#27861;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22312;&#24046;&#20998;&#38544;&#31169;&#26465;&#20214;&#19979;&#20272;&#35745;&#35768;&#22810;&#32479;&#35745;&#20998;&#20301;&#25968;&#30340;&#38382;&#39064;&#12290;&#26356;&#20855;&#20307;&#22320;&#65292;&#32473;&#23450;&#19968;&#20010;&#20998;&#24067;&#24182;&#19988;&#33021;&#22815;&#35775;&#38382;&#26469;&#33258;&#20854;&#29420;&#31435;&#21516;&#20998;&#24067;&#26679;&#26412;&#65292;&#25105;&#20204;&#32771;&#34385;&#22312;&#29305;&#23450;&#28857;&#19978;&#20272;&#35745;&#20854;&#32047;&#31215;&#20998;&#24067;&#20989;&#25968;&#30340;&#36870;&#20989;&#25968;&#65288;&#20998;&#20301;&#25968;&#20989;&#25968;&#65289;&#12290;&#20363;&#22914;&#65292;&#36825;&#39033;&#20219;&#21153;&#22312;&#31169;&#26377;&#25968;&#25454;&#29983;&#25104;&#20013;&#38750;&#24120;&#37325;&#35201;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#19981;&#21516;&#30340;&#26041;&#27861;&#12290;&#31532;&#19968;&#31181;&#26041;&#27861;&#26159;&#31169;&#19979;&#20272;&#35745;&#26679;&#26412;&#30340;&#32463;&#39564;&#20998;&#20301;&#25968;&#65292;&#24182;&#23558;&#27492;&#32467;&#26524;&#29992;&#20316;&#20998;&#24067;&#30340;&#20998;&#20301;&#25968;&#20272;&#35745;&#22120;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102; Kaplan&#31561;&#20154;&#26368;&#36817;&#21457;&#34920;&#30340;&#36882;&#24402;&#20272;&#35745;&#20998;&#20301;&#25968;&#30340;&#38544;&#31169;&#31639;&#27861;&#30340;&#32479;&#35745;&#24615;&#36136;&#12290;&#31532;&#20108;&#31181;&#26041;&#27861;&#26159;&#20351;&#29992;&#23494;&#24230;&#20272;&#35745;&#25216;&#26415;&#36827;&#34892;&#22343;&#21248;&#38388;&#38548;&#20869;&#30340;&#20998;&#20301;&#25968;&#20989;&#25968;&#20272;&#35745;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20004;&#31181;&#26041;&#27861;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#24403;&#25105;&#20204;&#24819;&#35201;&#20272;&#35745;&#35768;&#22810;&#20998;&#20301;&#25968;&#26102;&#65292;&#26368;&#22909;&#20351;&#29992;&#31532;&#19968;&#31181;&#26041;&#27861;&#21333;&#29420;&#20272;&#35745;&#23427;&#20204;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#24403;&#25105;&#20204;&#24819;&#35201;&#22312;&#22823;&#21306;&#38388;&#19978;&#20272;&#35745;&#20998;&#20301;&#25968;&#20989;&#25968;&#26102;&#65292;&#31532;&#20108;&#31181;&#26041;&#27861;&#26356;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work studies the estimation of many statistical quantiles under differential privacy. More precisely, given a distribution and access to i.i.d. samples from it, we study the estimation of the inverse of its cumulative distribution function (the quantile function) at specific points. For instance, this task is of key importance in private data generation. We present two different approaches. The first one consists in privately estimating the empirical quantiles of the samples and using this result as an estimator of the quantiles of the distribution. In particular, we study the statistical properties of the recently published algorithm introduced by Kaplan et al. 2022 that privately estimates the quantiles recursively. The second approach is to use techniques of density estimation in order to uniformly estimate the quantile function on an interval. In particular, we show that there is a tradeoff between the two methods. When we want to estimate many quantiles, it is better to estim
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;PAC-Bayesian&#29702;&#35770;&#25552;&#20379;&#20102;&#20803;&#23398;&#20064;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#25512;&#23548;&#20986;&#20102;&#26368;&#20339;&#24615;&#33021;&#20445;&#35777;&#30340;&#38381;&#24335;&#20248;&#21270;&#36229;&#21518;&#39564;(PACOH)&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#26696;&#20363;&#30740;&#31350;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#20445;&#35777;&#22312;&#20803;&#23398;&#20064;&#20013;&#30456;&#23545;&#20110;PAC-Bayesian&#27599;&#20010;&#20219;&#21153;&#23398;&#20064;&#30028;&#38480;&#30340;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2211.07206</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#30340;PAC-Bayesian&#20803;&#23398;&#20064;&#65306;&#20174;&#29702;&#35770;&#21040;&#23454;&#36341;&#30340;PAC-Optimal&#36229;&#21518;&#39564;
&lt;/p&gt;
&lt;p&gt;
Scalable PAC-Bayesian Meta-Learning via the PAC-Optimal Hyper-Posterior: From Theory to Practice. (arXiv:2211.07206v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.07206
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;PAC-Bayesian&#29702;&#35770;&#25552;&#20379;&#20102;&#20803;&#23398;&#20064;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#25512;&#23548;&#20986;&#20102;&#26368;&#20339;&#24615;&#33021;&#20445;&#35777;&#30340;&#38381;&#24335;&#20248;&#21270;&#36229;&#21518;&#39564;(PACOH)&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#26696;&#20363;&#30740;&#31350;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#20445;&#35777;&#22312;&#20803;&#23398;&#20064;&#20013;&#30456;&#23545;&#20110;PAC-Bayesian&#27599;&#20010;&#20219;&#21153;&#23398;&#20064;&#30028;&#38480;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20803;&#23398;&#20064;&#26088;&#22312;&#36890;&#36807;&#20174;&#30456;&#20851;&#23398;&#20064;&#20219;&#21153;&#30340;&#25968;&#25454;&#38598;&#20013;&#33719;&#21462;&#26377;&#29992;&#30340;&#24402;&#32435;&#20559;&#22909;&#65292;&#21152;&#36895;&#23545;&#26032;&#20219;&#21153;&#30340;&#23398;&#20064;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#21487;&#29992;&#30340;&#30456;&#20851;&#20219;&#21153;&#25968;&#37327;&#36890;&#24120;&#24456;&#23567;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#20551;&#35774;&#20219;&#21153;&#25968;&#37327;&#20016;&#23500;&#65292;&#20351;&#23427;&#20204;&#19981;&#20999;&#23454;&#38469;&#19988;&#23481;&#26131;&#36807;&#25311;&#21512;&#12290;&#20803;&#23398;&#20064;&#25991;&#29486;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#26159;&#22914;&#20309;&#36827;&#34892;&#27491;&#21017;&#21270;&#20197;&#30830;&#20445;&#23545;&#26410;&#35265;&#20219;&#21153;&#30340;&#27867;&#21270;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;PAC-Bayesian&#29702;&#35770;&#25552;&#20379;&#20102;&#19968;&#31181;&#29702;&#35770;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#20102;&#20803;&#23398;&#20064;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#36825;&#26159;&#30001;Rothfuss&#31561;&#20154;&#65288;2021&#65289;&#39318;&#27425;&#25512;&#23548;&#20986;&#26469;&#30340;&#12290;&#20851;&#38190;&#26159;&#65292;&#35813;&#30028;&#38480;&#20351;&#25105;&#20204;&#33021;&#22815;&#24471;&#21040;&#26368;&#20339;&#24615;&#33021;&#20445;&#35777;&#30340;&#38381;&#24335;&#20248;&#21270;&#36229;&#21518;&#39564;&#65292;&#31216;&#20026;PACOH&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#35777;&#26696;&#20363;&#30740;&#31350;&#65292;&#22312;&#21738;&#20123;&#26465;&#20214;&#19979;&#20197;&#21450;&#22312;&#22810;&#22823;&#31243;&#24230;&#19978;&#36825;&#20123;&#20803;&#23398;&#20064;&#30340;&#20445;&#35777;&#25913;&#36827;&#20102;PAC-Bayesian&#27599;&#20010;&#20219;&#21153;&#23398;&#20064;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Meta-Learning aims to speed up the learning process on new tasks by acquiring useful inductive biases from datasets of related learning tasks. While, in practice, the number of related tasks available is often small, most of the existing approaches assume an abundance of tasks; making them unrealistic and prone to overfitting. A central question in the meta-learning literature is how to regularize to ensure generalization to unseen tasks. In this work, we provide a theoretical analysis using the PAC-Bayesian theory and present a generalization bound for meta-learning, which was first derived by Rothfuss et al. (2021). Crucially, the bound allows us to derive the closed form of the optimal hyper-posterior, referred to as PACOH, which leads to the best performance guarantees. We provide a theoretical analysis and empirical case study under which conditions and to what extent these guarantees for meta-learning improve upon PAC-Bayesian per-task learning bounds. The closed-form PACOH inspi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;Hessian-based&#20998;&#26512;&#65292;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#36317;&#31163;&#30340;&#27867;&#21270;&#24230;&#37327;&#26041;&#27861;&#65292;&#29992;&#20110;&#29702;&#35299;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#24494;&#35843;&#30340;&#27867;&#21270;&#29305;&#24615;&#12290;&#36890;&#36807;PAC-Bayesian&#20998;&#26512;&#65292;&#32473;&#20986;&#20102;&#22522;&#20110;Hessian&#36317;&#31163;&#30340;&#24494;&#35843;&#27169;&#22411;&#27867;&#21270;&#30028;&#12290;&#27492;&#22806;&#65292;&#36824;&#23545;&#24494;&#35843;&#38754;&#23545;&#26631;&#31614;&#22122;&#22768;&#30340;&#38382;&#39064;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#30456;&#20851;&#31639;&#27861;&#21644;&#27867;&#21270;&#35823;&#24046;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2206.02659</link><description>&lt;p&gt;
&#20855;&#26377;&#22522;&#20110;Hessian&#30340;&#27867;&#21270;&#20445;&#35777;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#40065;&#26834;&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
Robust Fine-Tuning of Deep Neural Networks with Hessian-based Generalization Guarantees. (arXiv:2206.02659v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.02659
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;Hessian-based&#20998;&#26512;&#65292;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#36317;&#31163;&#30340;&#27867;&#21270;&#24230;&#37327;&#26041;&#27861;&#65292;&#29992;&#20110;&#29702;&#35299;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#24494;&#35843;&#30340;&#27867;&#21270;&#29305;&#24615;&#12290;&#36890;&#36807;PAC-Bayesian&#20998;&#26512;&#65292;&#32473;&#20986;&#20102;&#22522;&#20110;Hessian&#36317;&#31163;&#30340;&#24494;&#35843;&#27169;&#22411;&#27867;&#21270;&#30028;&#12290;&#27492;&#22806;&#65292;&#36824;&#23545;&#24494;&#35843;&#38754;&#23545;&#26631;&#31614;&#22122;&#22768;&#30340;&#38382;&#39064;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#30456;&#20851;&#31639;&#27861;&#21644;&#27867;&#21270;&#35823;&#24046;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#30446;&#26631;&#20219;&#21153;&#19978;&#23545;&#39044;&#35757;&#32451;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#24494;&#35843;&#12290;&#25105;&#20204;&#30740;&#31350;&#24494;&#35843;&#30340;&#27867;&#21270;&#29305;&#24615;&#65292;&#20197;&#29702;&#35299;&#36807;&#25311;&#21512;&#38382;&#39064;&#65292;&#36825;&#22312;&#30446;&#26631;&#25968;&#25454;&#38598;&#36739;&#23567;&#25110;&#35757;&#32451;&#26631;&#31614;&#22122;&#22768;&#26102;&#32463;&#24120;&#35266;&#23519;&#21040;&#12290;&#29616;&#26377;&#30340;&#28145;&#24230;&#32593;&#32476;&#27867;&#21270;&#24230;&#37327;&#20381;&#36182;&#20110;&#19982;&#24494;&#35843;&#27169;&#22411;&#30340;&#21021;&#22987;&#21270;&#65288;&#21363;&#39044;&#35757;&#32451;&#32593;&#32476;&#65289;&#36317;&#31163;&#21644;&#28145;&#24230;&#32593;&#32476;&#30340;&#22122;&#22768;&#31283;&#23450;&#24615;&#31561;&#27010;&#24565;&#12290;&#26412;&#25991;&#36890;&#36807;PAC-Bayesian&#20998;&#26512;&#30830;&#23450;&#20102;&#19968;&#31181;&#22522;&#20110;Hessian&#30340;&#36317;&#31163;&#24230;&#37327;&#65292;&#23427;&#19982;&#24494;&#35843;&#27169;&#22411;&#30340;&#35266;&#23519;&#21040;&#30340;&#27867;&#21270;&#24046;&#36317;&#30456;&#20851;&#24615;&#24456;&#24378;&#12290;&#20174;&#29702;&#35770;&#19978;&#25105;&#20204;&#35777;&#26126;&#20102;&#22522;&#20110;Hessian&#36317;&#31163;&#30340;&#24494;&#35843;&#27169;&#22411;&#30340;&#27867;&#21270;&#30028;&#12290;&#25105;&#20204;&#36824;&#23545;&#24494;&#35843;&#23545;&#25239;&#26631;&#31614;&#22122;&#22768;&#36827;&#34892;&#20102;&#25193;&#23637;&#30740;&#31350;&#65292;&#36807;&#25311;&#21512;&#26159;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#65307;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#24182;&#22312;&#31867;&#26465;&#20214;&#29420;&#31435;&#20551;&#35774;&#19979;&#32473;&#20986;&#20102;&#35813;&#31639;&#27861;&#30340;&#27867;&#21270;&#35823;&#24046;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider fine-tuning a pretrained deep neural network on a target task. We study the generalization properties of fine-tuning to understand the problem of overfitting, which has often been observed (e.g., when the target dataset is small or when the training labels are noisy). Existing generalization measures for deep networks depend on notions such as distance from the initialization (i.e., the pretrained network) of the fine-tuned model and noise stability properties of deep networks. This paper identifies a Hessian-based distance measure through PAC-Bayesian analysis, which is shown to correlate well with observed generalization gaps of fine-tuned models. Theoretically, we prove Hessian distance-based generalization bounds for fine-tuned models. We also describe an extended study of fine-tuning against label noise, where overfitting is against a critical problem; We present an algorithm and a generalization error guarantee for this algorithm under a class conditional independent 
&lt;/p&gt;</description></item></channel></rss>