<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#36890;&#36807;&#22522;&#20110;&#20114;&#32852;&#39532;&#23572;&#31185;&#22827;&#38142;&#30340;&#19981;&#20559;&#24494;&#20998;&#65292;&#24320;&#21457;&#20986;&#19968;&#31181;&#26080;&#20559;&#12289;&#20302;&#26041;&#24046;&#21644;&#33258;&#21160;&#30340;&#26041;&#27861;&#23545;&#22797;&#26434;&#23494;&#24230;&#36827;&#34892;&#29983;&#25104;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545; MH &#37319;&#26679;&#22120;&#30340;&#20248;&#21270;&#12290;</title><link>http://arxiv.org/abs/2306.07961</link><description>&lt;p&gt;
&#36890;&#36807;&#19981;&#20559;&#24494;&#20998;&#23545;&#25239;&#22797;&#26434;&#23494;&#24230;&#29983;&#25104;&#65292;&#22522;&#20110;&#20114;&#32852;&#39532;&#23572;&#31185;&#22827;&#38142;&#19981;&#20559;&#24494;&#20998;&#20248;&#21270; MH &#37319;&#26679;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Differentiating Metropolis-Hastings to Optimize Intractable Densities. (arXiv:2306.07961v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07961
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#22522;&#20110;&#20114;&#32852;&#39532;&#23572;&#31185;&#22827;&#38142;&#30340;&#19981;&#20559;&#24494;&#20998;&#65292;&#24320;&#21457;&#20986;&#19968;&#31181;&#26080;&#20559;&#12289;&#20302;&#26041;&#24046;&#21644;&#33258;&#21160;&#30340;&#26041;&#27861;&#23545;&#22797;&#26434;&#23494;&#24230;&#36827;&#34892;&#29983;&#25104;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545; MH &#37319;&#26679;&#22120;&#30340;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#27010;&#29575;&#27169;&#22411;&#25512;&#29702;&#20013;&#65292;&#30446;&#26631;&#23494;&#24230;&#20989;&#25968;&#36890;&#24120;&#21464;&#24471;&#38590;&#20197;&#35745;&#31639;&#65292;&#38656;&#35201;&#20351;&#29992; Monte Carlo &#35745;&#31639;&#12290;&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#19981;&#20559;&#24494;&#20998; Metropolis-Hastings &#37319;&#26679;&#22120;&#30340;&#26041;&#27861;&#65292;&#20351;&#25105;&#20204;&#21487;&#20197;&#36890;&#36807;&#27010;&#29575;&#25512;&#29702;&#26469;&#36827;&#34892;&#24494;&#20998;&#12290;&#36890;&#36807;&#23558;&#38543;&#26426;&#24494;&#20998;&#30340;&#26368;&#26032;&#36827;&#23637;&#19982; Markov &#38142;&#32806;&#21512;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#23454;&#29616;&#26080;&#20559;&#65292;&#20302;&#26041;&#24046;&#21644;&#33258;&#21160;&#30340;&#31243;&#24207;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#24212;&#29992;&#20110;&#30001;&#20110;&#32321;&#29712;&#30340;&#30446;&#26631;&#23494;&#24230;&#23548;&#33268;&#26399;&#26395;&#30340;&#24773;&#20917;&#19979;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20013;&#25214;&#21040;&#19968;&#20010;&#27169;&#26865;&#20004;&#21487;&#30340;&#35266;&#23519;&#21644;&#22312; Ising &#27169;&#22411;&#20013;&#26368;&#22823;&#21270;&#27604;&#28909;&#26469;&#28436;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
When performing inference on probabilistic models, target densities often become intractable, necessitating the use of Monte Carlo samplers. We develop a methodology for unbiased differentiation of the Metropolis-Hastings sampler, allowing us to differentiate through probabilistic inference. By fusing recent advances in stochastic differentiation with Markov chain coupling schemes, the procedure can be made unbiased, low-variance, and automatic. This allows us to apply gradient-based optimization to objectives expressed as expectations over intractable target densities. We demonstrate our approach by finding an ambiguous observation in a Gaussian mixture model and by maximizing the specific heat in an Ising model.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#33021;&#22815;&#22788;&#29702;&#22797;&#26434;&#21644;&#38388;&#25509;&#35266;&#27979;&#30340;&#20013;&#20171;&#22240;&#32032;&#30340;&#22240;&#26524;&#20013;&#20171;&#20998;&#26512;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2306.07918</link><description>&lt;p&gt;
&#22810;&#32500;&#21644;&#38388;&#25509;&#35266;&#27979;&#20013;&#20171;&#22240;&#32032;&#30340;&#22240;&#26524;&#20013;&#20171;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Causal Mediation Analysis with Multi-dimensional and Indirectly Observed Mediators. (arXiv:2306.07918v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07918
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#33021;&#22815;&#22788;&#29702;&#22797;&#26434;&#21644;&#38388;&#25509;&#35266;&#27979;&#30340;&#20013;&#20171;&#22240;&#32032;&#30340;&#22240;&#26524;&#20013;&#20171;&#20998;&#26512;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#20013;&#20171;&#20998;&#26512;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#28508;&#22312;&#32467;&#26524;&#26694;&#26550;&#20869;&#23558;&#22788;&#29702;&#30340;&#24635;&#25928;&#24212;&#20998;&#35299;&#20026;&#30452;&#25509;&#21644;&#20171;&#23548;&#25928;&#24212;&#12290;&#36825;&#22312;&#35768;&#22810;&#31185;&#23398;&#24212;&#29992;&#20013;&#24456;&#37325;&#35201;&#65292;&#21487;&#20197;&#35782;&#21035;&#20986;&#22788;&#29702;&#25928;&#24212;&#30340;&#28508;&#22312;&#26426;&#21046;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#31185;&#23398;&#24212;&#29992;&#20013;&#65292;&#20013;&#20171;&#22240;&#32032;&#26410;&#34987;&#35266;&#23519;&#21040;&#65292;&#20294;&#21487;&#33021;&#23384;&#22312;&#30456;&#20851;&#27979;&#37327;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;CMA&#26694;&#26550;&#65292;&#23427;&#21487;&#20197;&#22788;&#29702;&#22522;&#20110;&#21487;&#36776;&#35782;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;iVAE&#65289;&#20307;&#31995;&#32467;&#26500;&#30340;&#22797;&#26434;&#21644;&#38388;&#25509;&#35266;&#27979;&#30340;&#20013;&#20171;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal mediation analysis (CMA) is a powerful method to dissect the total effect of a treatment into direct and mediated effects within the potential outcome framework. This is important in many scientific applications to identify the underlying mechanisms of a treatment effect. However, in many scientific applications the mediator is unobserved, but there may exist related measurements. For example, we may want to identify how changes in brain activity or structure mediate an antidepressant's effect on behavior, but we may only have access to electrophysiological or imaging brain measurements. To date, most CMA methods assume that the mediator is one-dimensional and observable, which oversimplifies such real-world scenarios. To overcome this limitation, we introduce a CMA framework that can handle complex and indirectly observed mediators based on the identifiable variational autoencoder (iVAE) architecture. We prove that the true joint distribution over observed and latent variables 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#35266;&#27979;&#21464;&#37327;&#30001;&#22240;&#26524;&#30456;&#20851;&#30340;&#28508;&#21464;&#37327;&#29983;&#25104;&#30340;&#38750;&#32447;&#24615;&#28508;&#21464;&#37327;&#23618;&#27425;&#22240;&#26524;&#27169;&#22411;&#20013;&#23454;&#29616;&#22240;&#26524;&#32467;&#26500;&#21644;&#28508;&#21464;&#37327;&#30340;&#21487;&#35782;&#21035;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.07916</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#28508;&#21464;&#37327;&#23618;&#27425;&#27169;&#22411;&#30340;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Identification of Nonlinear Latent Hierarchical Models. (arXiv:2306.07916v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07916
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#35266;&#27979;&#21464;&#37327;&#30001;&#22240;&#26524;&#30456;&#20851;&#30340;&#28508;&#21464;&#37327;&#29983;&#25104;&#30340;&#38750;&#32447;&#24615;&#28508;&#21464;&#37327;&#23618;&#27425;&#22240;&#26524;&#27169;&#22411;&#20013;&#23454;&#29616;&#22240;&#26524;&#32467;&#26500;&#21644;&#28508;&#21464;&#37327;&#30340;&#21487;&#35782;&#21035;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#35782;&#21035;&#28508;&#21464;&#37327;&#21644;&#22240;&#26524;&#32467;&#26500;&#23545;&#20110;&#35768;&#22810;&#28041;&#21450;&#29983;&#29289;&#25968;&#25454;&#12289;&#21307;&#23398;&#25968;&#25454;&#21644;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#65288;&#22914;&#22270;&#20687;&#21644;&#35821;&#35328;&#65289;&#30340;&#23454;&#38469;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#24403;&#35266;&#27979;&#21464;&#37327;&#30001;&#22240;&#26524;&#30456;&#20851;&#30340;&#28508;&#21464;&#37327;&#29983;&#25104;&#65292;&#24182;&#19988;&#20851;&#31995;&#26159;&#38750;&#32447;&#24615;&#30340;&#26102;&#65292;&#36825;&#39033;&#20219;&#21153;&#21487;&#33021;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38750;&#32447;&#24615;&#28508;&#21464;&#37327;&#23618;&#27425;&#22240;&#26524;&#27169;&#22411;&#30340;&#35782;&#21035;&#38382;&#39064;&#65292;&#22312;&#36825;&#31181;&#27169;&#22411;&#20013;&#65292;&#35266;&#27979;&#21464;&#37327;&#30001;&#19968;&#32452;&#22240;&#26524;&#30456;&#20851;&#30340;&#28508;&#21464;&#37327;&#29983;&#25104;&#65292;&#26377;&#20123;&#28508;&#21464;&#37327;&#21487;&#33021;&#27809;&#26377;&#35266;&#23519;&#21040;&#30340;&#21518;&#20195;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#21487;&#20197;&#23454;&#29616;&#22240;&#26524;&#32467;&#26500;&#21644;&#28508;&#21464;&#37327;&#30340;&#21487;&#35782;&#21035;&#24615;&#65306;&#23545;&#20110;&#22240;&#26524;&#32467;&#26500;&#65292;&#25105;&#20204;&#20801;&#35768;&#22270;&#20013;&#20219;&#24847;&#20004;&#20010;&#21464;&#37327;&#20043;&#38388;&#23384;&#22312;&#22810;&#26465;&#36335;&#24452;&#65292;&#36825;&#25918;&#23485;&#20102;&#20808;&#21069;&#24037;&#20316;&#20013;&#30340;&#28508;&#21464;&#37327;&#26641;&#20551;&#35774;&#65307;&#23545;&#20110;&#32467;&#26500;&#20989;&#25968;&#65292;&#25105;&#20204;&#27809;&#26377;&#36827;&#34892;&#21442;&#25968;&#20551;&#35774;&#65292;&#22240;&#27492;&#21487;&#20197;&#20801;&#35768;&#22522;&#22240;
&lt;/p&gt;
&lt;p&gt;
Identifying latent variables and causal structures from observational data is essential to many real-world applications involving biological data, medical data, and unstructured data such as images and languages. However, this task can be highly challenging, especially when observed variables are generated by causally related latent variables and the relationships are nonlinear. In this work, we investigate the identification problem for nonlinear latent hierarchical causal models in which observed variables are generated by a set of causally related latent variables, and some latent variables may not have observed children. We show that the identifiability of both causal structure and latent variables can be achieved under mild assumptions: on causal structures, we allow for the existence of multiple paths between any pair of variables in the graph, which relaxes latent tree assumptions in prior work; on structural functions, we do not make parametric assumptions, thus permitting gene
&lt;/p&gt;</description></item><item><title>Omega&#26159;&#19968;&#31181;&#20248;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#21152;&#20837;&#21382;&#21490;&#26799;&#24230;EMA&#26469;&#20943;&#36731;&#22122;&#22768;&#30340;&#24433;&#21709;&#24182;&#22312;&#38543;&#26426;&#28216;&#25103;&#19978;&#34920;&#29616;&#26356;&#20339;&#12290;</title><link>http://arxiv.org/abs/2306.07905</link><description>&lt;p&gt;
Omega: &#20048;&#35266;EMA Gradients
&lt;/p&gt;
&lt;p&gt;
Omega: Optimistic EMA Gradients. (arXiv:2306.07905v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07905
&lt;/p&gt;
&lt;p&gt;
Omega&#26159;&#19968;&#31181;&#20248;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#21152;&#20837;&#21382;&#21490;&#26799;&#24230;EMA&#26469;&#20943;&#36731;&#22122;&#22768;&#30340;&#24433;&#21709;&#24182;&#22312;&#38543;&#26426;&#28216;&#25103;&#19978;&#34920;&#29616;&#26356;&#20339;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;GAN&#21644;&#23545;&#25239;&#24615;&#35757;&#32451;&#30340;&#36827;&#27493;&#65292;&#38543;&#26426;min-max&#20248;&#21270;&#21463;&#21040;&#20102;&#26426;&#22120;&#23398;&#20064;&#30028;&#30340;&#20851;&#27880;&#12290;&#23613;&#31649;&#30830;&#23450;&#24615;&#29366;&#24577;&#19979;&#30340;&#21338;&#24328;&#20248;&#21270;&#24050;&#32463;&#30456;&#24403;&#22909;&#22320;&#29702;&#35299;&#20102;&#65292;&#20294;&#22312;&#38543;&#26426;&#29366;&#24577;&#19979;&#20173;&#23384;&#22312;&#19968;&#20123;&#38382;&#39064;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#20687;&#20048;&#35266;&#26799;&#24230;&#36825;&#26679;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;-&#19978;&#21319;&#26041;&#27861;&#23545;&#22122;&#22768;&#38750;&#24120;&#25935;&#24863;&#25110;&#32773;&#20250;&#23548;&#33268;&#22833;&#36133;&#12290;&#34429;&#28982;&#23384;&#22312;&#26367;&#20195;&#31574;&#30053;&#65292;&#20294;&#36825;&#20123;&#31574;&#30053;&#21487;&#33021;&#25104;&#26412;&#36807;&#39640;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;Omega&#65292;&#19968;&#31181;&#20855;&#26377;&#31867;&#20284;&#20110;&#20048;&#35266;&#26356;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#20854;&#26356;&#26032;&#35268;&#21017;&#20013;&#21512;&#24182;&#21382;&#21490;&#26799;&#24230;&#30340;EMA&#26469;&#20943;&#36731;&#22122;&#22768;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#19968;&#31181;&#21253;&#21547;&#21160;&#37327;&#30340;&#35813;&#31639;&#27861;&#30340;&#21464;&#20307;&#12290;&#34429;&#28982;&#25105;&#20204;&#27809;&#26377;&#25552;&#20379;&#25910;&#25947;&#24615;&#20445;&#35777;&#65292;&#20294;&#25105;&#20204;&#22312;&#38543;&#26426;&#28216;&#25103;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#24403;&#24212;&#29992;&#20110;&#32447;&#24615;&#29609;&#23478;&#26102;&#65292;Omega&#20248;&#20110;&#20048;&#35266;&#26799;&#24230;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic min-max optimization has gained interest in the machine learning community with the advancements in GANs and adversarial training. Although game optimization is fairly well understood in the deterministic setting, some issues persist in the stochastic regime. Recent work has shown that stochastic gradient descent-ascent methods such as the optimistic gradient are highly sensitive to noise or can fail to converge. Although alternative strategies exist, they can be prohibitively expensive. We introduce Omega, a method with optimistic-like updates that mitigates the impact of noise by incorporating an EMA of historic gradients in its update rule. We also explore a variation of this algorithm that incorporates momentum. Although we do not provide convergence guarantees, our experiments on stochastic games show that Omega outperforms the optimistic gradient method when applied to linear players.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#23545;&#24191;&#27867;&#28608;&#27963;&#20989;&#25968;&#26063;&#20013;&#30340;&#31070;&#32463;&#20803;&#30340;&#26368;&#20248;$L_2^2$&#35823;&#24046;&#36827;&#34892;&#36817;&#20284;&#30340;&#26377;&#25928;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.07892</link><description>&lt;p&gt;
&#36890;&#36807;Sharpness&#24378;&#20581;&#22320;&#23398;&#20064;&#21333;&#20010;&#31070;&#32463;&#20803;
&lt;/p&gt;
&lt;p&gt;
Robustly Learning a Single Neuron via Sharpness. (arXiv:2306.07892v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07892
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#23545;&#24191;&#27867;&#28608;&#27963;&#20989;&#25968;&#26063;&#20013;&#30340;&#31070;&#32463;&#20803;&#30340;&#26368;&#20248;$L_2^2$&#35823;&#24046;&#36827;&#34892;&#36817;&#20284;&#30340;&#26377;&#25928;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#23384;&#22312;&#23545;&#25239;&#24615;&#26631;&#31614;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65292;&#23398;&#20064;&#21333;&#20010;&#31070;&#32463;&#20803;&#23545;$L_2^2$&#25439;&#22833;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#23545;&#21253;&#25324;ReLU&#22312;&#20869;&#30340;&#24191;&#27867;&#28608;&#27963;&#20989;&#25968;&#26063;&#20013;&#65292;&#36817;&#20284;&#20110;&#26368;&#20248;$L_2^2$&#35823;&#24046;&#12290;&#30456;&#36739;&#20110;&#20197;&#21069;&#30340;&#24037;&#20316;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#26356;&#28201;&#21644;&#30340;&#20998;&#24067;&#20551;&#35774;&#12290;&#20351;&#25105;&#20204;&#32467;&#26524;&#21487;&#34892;&#30340;&#20851;&#38190;&#22240;&#32032;&#26159;&#19982;&#20248;&#21270;&#29702;&#35770;&#30340;&#23616;&#37096;&#35823;&#24046;&#30028;&#30340;&#26032;&#39062;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of learning a single neuron with respect to the $L_2^2$-loss in the presence of adversarial label noise. We give an efficient algorithm that, for a broad family of activations including ReLUs, approximates the optimal $L_2^2$-error within a constant factor. Our algorithm applies under much milder distributional assumptions compared to prior work. The key ingredient enabling our results is a novel connection to local error bounds from optimization theory.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#19968;&#20010;&#23454;&#23545;&#31216;&#24352;&#37327;&#20998;&#35299;&#25104;&#31209;&#20026;1&#39033;&#20043;&#21644;&#30340;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24471;&#21040;&#20102;&#31934;&#30830;&#30340;&#20998;&#26512;&#20272;&#35745;&#65292;&#24182;&#21457;&#29616;&#20102;&#21508;&#31181;&#38459;&#30861;&#23616;&#37096;&#20248;&#21270;&#26041;&#27861;&#30340;&#20960;&#20309;&#38556;&#30861;&#21644;&#30001;&#20110;&#23545;&#31216;&#24615;&#23548;&#33268;&#30340;&#20016;&#23500;&#30340;&#20020;&#30028;&#28857;&#38598;&#21512;&#12290;</title><link>http://arxiv.org/abs/2306.07886</link><description>&lt;p&gt;
&#23545;&#31216;&#24352;&#37327;&#20998;&#35299;&#38382;&#39064;&#30340;&#23545;&#31216;&#24615;&#19982;&#20020;&#30028;&#28857;
&lt;/p&gt;
&lt;p&gt;
Symmetry &amp; Critical Points for Symmetric Tensor Decompositions Problems. (arXiv:2306.07886v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07886
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#19968;&#20010;&#23454;&#23545;&#31216;&#24352;&#37327;&#20998;&#35299;&#25104;&#31209;&#20026;1&#39033;&#20043;&#21644;&#30340;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24471;&#21040;&#20102;&#31934;&#30830;&#30340;&#20998;&#26512;&#20272;&#35745;&#65292;&#24182;&#21457;&#29616;&#20102;&#21508;&#31181;&#38459;&#30861;&#23616;&#37096;&#20248;&#21270;&#26041;&#27861;&#30340;&#20960;&#20309;&#38556;&#30861;&#21644;&#30001;&#20110;&#23545;&#31216;&#24615;&#23548;&#33268;&#30340;&#20016;&#23500;&#30340;&#20020;&#30028;&#28857;&#38598;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#23558;&#19968;&#20010;&#23454;&#23545;&#31216;&#24352;&#37327;&#20998;&#35299;&#25104;&#31209;&#20026;1&#39033;&#20043;&#21644;&#30340;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#21033;&#29992;&#20854;&#20016;&#23500;&#30340;&#23545;&#31216;&#32467;&#26500;&#65292;&#23548;&#20986;Puiseux&#32423;&#25968;&#34920;&#31034;&#30340;&#19968;&#31995;&#21015;&#20020;&#30028;&#28857;&#65292;&#24182;&#33719;&#24471;&#20102;&#20851;&#20110;&#20020;&#30028;&#20540;&#21644;Hessian&#35889;&#30340;&#31934;&#30830;&#20998;&#26512;&#20272;&#35745;&#12290;&#36825;&#20123;&#32467;&#26524;&#25581;&#31034;&#20102;&#21508;&#31181;&#20960;&#20309;&#38556;&#30861;&#65292;&#38459;&#30861;&#20102;&#23616;&#37096;&#20248;&#21270;&#26041;&#27861;&#30340;&#20351;&#29992;&#65292;&#26368;&#21518;&#65292;&#21033;&#29992;&#19968;&#20010;&#29275;&#39039;&#22810;&#38754;&#20307;&#35770;&#35777;&#20102;&#22266;&#23450;&#23545;&#31216;&#24615;&#30340;&#25152;&#26377;&#20020;&#30028;&#28857;&#30340;&#23436;&#20840;&#26522;&#20030;&#65292;&#24182;&#35777;&#26126;&#20102;&#19982;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#38598;&#21512;&#30456;&#27604;&#65292;&#30001;&#20110;&#23545;&#31216;&#24615;&#30340;&#23384;&#22312;&#65292;&#20020;&#30028;&#28857;&#30340;&#38598;&#21512;&#21487;&#33021;&#20250;&#26174;&#31034;&#20986;&#32452;&#21512;&#30340;&#20016;&#23500;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the non-convex optimization problem associated with the decomposition of a real symmetric tensor into a sum of rank one terms. Use is made of the rich symmetry structure to derive Puiseux series representations of families of critical points, and so obtain precise analytic estimates on the critical values and the Hessian spectrum. The sharp results make possible an analytic characterization of various geometric obstructions to local optimization methods, revealing in particular a complex array of saddles and local minima which differ by their symmetry, structure and analytic properties. A desirable phenomenon, occurring for all critical points considered, concerns the index of a point, i.e., the number of negative Hessian eigenvalues, increasing with the value of the objective function. Lastly, a Newton polytope argument is used to give a complete enumeration of all critical points of fixed symmetry, and it is shown that contrarily to the set of global minima which remains 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35752;&#35770;&#20102;&#22240;&#26524;&#36172;&#21338;&#26426;&#20013;&#36873;&#25321;&#34892;&#21160;&#30340;&#31639;&#27861;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21152;&#24615;&#32452;&#21512;&#32447;&#24615;&#36172;&#21338;&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#27861;&#20197;&#35299;&#20915;&#26410;&#30693;&#22270;&#35889;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.07858</link><description>&lt;p&gt;
&#24102;&#26410;&#30693;&#22270;&#35889;&#30340;&#21152;&#24615;&#22240;&#26524;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
Additive Causal Bandits with Unknown Graph. (arXiv:2306.07858v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07858
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35752;&#35770;&#20102;&#22240;&#26524;&#36172;&#21338;&#26426;&#20013;&#36873;&#25321;&#34892;&#21160;&#30340;&#31639;&#27861;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21152;&#24615;&#32452;&#21512;&#32447;&#24615;&#36172;&#21338;&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#27861;&#20197;&#35299;&#20915;&#26410;&#30693;&#22270;&#35889;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25506;&#35752;&#20102;&#36873;&#25321;&#34892;&#21160;&#30340;&#31639;&#27861;&#65292;&#22312;&#22240;&#26524;&#36172;&#21338;&#35774;&#32622;&#19979;&#65292;&#23398;&#20064;&#32773;&#21487;&#20197;&#36873;&#25321;&#24178;&#39044;&#19968;&#32452;&#30001;&#22240;&#26524;&#22270;&#30456;&#20851;&#30340;&#38543;&#26426;&#21464;&#37327;&#65292;&#23398;&#20064;&#32773;&#39034;&#24207;&#36873;&#25321;&#24178;&#39044;&#65292;&#24182;&#20174;&#24178;&#39044;&#20998;&#24067;&#20013;&#35266;&#23519;&#26679;&#26412;&#12290;&#23398;&#20064;&#32773;&#30340;&#30446;&#26631;&#26159;&#24555;&#36895;&#25214;&#21040;&#26368;&#22823;&#21270;&#32467;&#26524;&#21464;&#37327;&#26399;&#26395;&#30340;&#65292;&#25152;&#26377;&#21487;&#35266;&#23519;&#21464;&#37327;&#24178;&#39044;&#20013;&#30340;&#24178;&#39044;&#12290;&#25105;&#20204;&#20551;&#35774;&#27809;&#26377;&#20851;&#20110;&#22240;&#26524;&#22270;&#30340;&#20219;&#20309;&#30693;&#35782;&#65292;&#38500;&#20102;&#32467;&#26524;&#21644;&#20854;&#31062;&#20808;&#20043;&#38388;&#30340;&#28508;&#22312;&#28151;&#28102;&#22240;&#32032;&#19981;&#23384;&#22312;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#26410;&#30693;&#22270;&#38382;&#39064;&#22312;&#32467;&#26524;&#30340;&#29238;&#27597;&#20013;&#21487;&#20197;&#26159;&#25351;&#25968;&#32423;&#38590;&#20197;&#35299;&#20915;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#23545;&#32467;&#26524;&#37319;&#21462;&#39069;&#22806;&#30340;&#21152;&#24615;&#20551;&#35774;&#65292;&#36890;&#36807;&#23558;&#38382;&#39064;&#24314;&#27169;&#20026;&#20855;&#26377;&#20840;&#36172;&#21338;&#21453;&#39304;&#30340;&#21152;&#24615;&#32452;&#21512;&#32447;&#24615;&#36172;&#21338;&#38382;&#39064;&#26469;&#35299;&#20915;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#34892;&#21160;&#28040;&#38500;&#31639;&#27861;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#27492;&#31639;&#27861;&#24212;&#29992;&#20110;&#36825;&#20010;&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;
We explore algorithms to select actions in the causal bandit setting where the learner can choose to intervene on a set of random variables related by a causal graph, and the learner sequentially chooses interventions and observes a sample from the interventional distribution. The learner's goal is to quickly find the intervention, among all interventions on observable variables, that maximizes the expectation of an outcome variable. We depart from previous literature by assuming no knowledge of the causal graph except that latent confounders between the outcome and its ancestors are not present. We first show that the unknown graph problem can be exponentially hard in the parents of the outcome. To remedy this, we adopt an additional additive assumption on the outcome which allows us to solve the problem by casting it as an additive combinatorial linear bandit problem with full-bandit feedback. We propose a novel action-elimination algorithm for this setting, show how to apply this al
&lt;/p&gt;</description></item><item><title>PDCA&#26159;&#19968;&#31181;&#29992;&#20110;&#31163;&#32447;&#32422;&#26463;&#24378;&#21270;&#23398;&#20064;&#30340;&#31639;&#27861;&#65292;&#23427;&#21487;&#20197;&#36890;&#36807;&#22312;Lagrangian&#20989;&#25968;&#19978;&#36816;&#34892;&#21407;&#22987;-&#23545;&#20598;&#31639;&#27861;&#26469;&#25214;&#21040;&#36817;&#20284;&#38797;&#28857;&#65292;&#32780;&#26080;&#38656;&#38598;&#20013;&#24615;&#21644;&#24378;Bellman&#23436;&#22791;&#24615;&#20551;&#35774;&#12290;</title><link>http://arxiv.org/abs/2306.07818</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#21407;&#22987;-&#23545;&#20598;-&#35780;&#35770;&#23478;&#31639;&#27861;&#30340;&#31163;&#32447;&#32422;&#26463;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
A Primal-Dual-Critic Algorithm for Offline Constrained Reinforcement Learning. (arXiv:2306.07818v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07818
&lt;/p&gt;
&lt;p&gt;
PDCA&#26159;&#19968;&#31181;&#29992;&#20110;&#31163;&#32447;&#32422;&#26463;&#24378;&#21270;&#23398;&#20064;&#30340;&#31639;&#27861;&#65292;&#23427;&#21487;&#20197;&#36890;&#36807;&#22312;Lagrangian&#20989;&#25968;&#19978;&#36816;&#34892;&#21407;&#22987;-&#23545;&#20598;&#31639;&#27861;&#26469;&#25214;&#21040;&#36817;&#20284;&#38797;&#28857;&#65292;&#32780;&#26080;&#38656;&#38598;&#20013;&#24615;&#21644;&#24378;Bellman&#23436;&#22791;&#24615;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#32422;&#26463;&#24378;&#21270;&#23398;&#20064;&#26088;&#22312;&#23398;&#20064;&#19968;&#31181;&#31574;&#30053;&#65292;&#20197;&#22312;&#29616;&#26377;&#25968;&#25454;&#38598;&#19978;&#28385;&#36275;&#23545;&#25104;&#26412;&#20989;&#25968;&#26399;&#26395;&#20540;&#30340;&#38480;&#21046;&#26465;&#20214;&#19979;&#26368;&#22823;&#21270;&#39044;&#26399;&#30340;&#32047;&#31215;&#22870;&#21169;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#21407;&#22987;-&#23545;&#20598;-&#35780;&#35770;&#23478;&#31639;&#27861;&#65288;PDCA&#65289;&#30340;&#26032;&#31639;&#27861;&#65292;&#29992;&#20110;&#20855;&#26377;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#30340;&#31163;&#32447;&#32422;&#26463;&#24378;&#21270;&#23398;&#20064;&#12290;PDCA&#22312;&#35780;&#35770;&#23478;&#20272;&#35745;&#30340;Lagrangian&#20989;&#25968;&#19978;&#36816;&#34892;&#21407;&#22987;-&#23545;&#20598;&#31639;&#27861;&#12290;&#21407;&#22987;&#29609;&#23478;&#37319;&#29992;&#26080;&#24724;&#31574;&#30053;&#20248;&#21270;&#31070;&#35861;&#65292;&#22312;&#32473;&#23450;&#20219;&#20309;&#35780;&#35770;&#23478;&#21644;&#23545;&#20598;&#29609;&#23478;&#30340;&#36873;&#25321;&#30340;&#24773;&#20917;&#19979;&#26368;&#22823;&#21270;&#25289;&#26684;&#26391;&#26085;&#20989;&#25968;&#30340;&#20272;&#35745;&#12290;&#23545;&#20598;&#29609;&#23478;&#36890;&#36807;&#37319;&#29992;&#26080;&#24724;&#22312;&#32447;&#32447;&#24615;&#20248;&#21270;&#31070;&#35861;&#65292;&#22312;&#32473;&#23450;&#35780;&#35770;&#23478;&#21644;&#21407;&#22987;&#29609;&#23478;&#30340;&#20219;&#20309;&#36873;&#25321;&#30340;&#24773;&#20917;&#19979;&#26368;&#23567;&#21270;&#25289;&#26684;&#26391;&#26085;&#20989;&#25968;&#30340;&#20272;&#35745;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;PDCA&#21487;&#20197;&#25104;&#21151;&#22320;&#25214;&#21040;&#25289;&#26684;&#26391;&#26085;&#20989;&#25968;&#30340;&#36817;&#20284;&#38797;&#28857;&#65292;&#36825;&#23545;&#20110;&#32422;&#26463;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#20960;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;&#19982;&#20197;&#21069;&#38656;&#35201;&#38598;&#20013;&#24615;&#21644;&#24378;Bellman&#23436;&#22791;&#24615;&#20551;&#35774;&#30340;&#20316;&#21697;&#19981;&#21516;&#65292;PDCA&#21482;&#38656;&#35201;&#19968;&#33268;&#24615;&#21644;&#33258;&#38381;&#24615;&#36825;&#20004;&#20010;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
Offline constrained reinforcement learning (RL) aims to learn a policy that maximizes the expected cumulative reward subject to constraints on expected value of cost functions using an existing dataset. In this paper, we propose Primal-Dual-Critic Algorithm (PDCA), a novel algorithm for offline constrained RL with general function approximation. PDCA runs a primal-dual algorithm on the Lagrangian function estimated by critics. The primal player employs a no-regret policy optimization oracle to maximize the Lagrangian estimate given any choices of the critics and the dual player. The dual player employs a no-regret online linear optimization oracle to minimize the Lagrangian estimate given any choices of the critics and the primal player. We show that PDCA can successfully find a near saddle point of the Lagrangian, which is nearly optimal for the constrained RL problem. Unlike previous work that requires concentrability and strong Bellman completeness assumptions, PDCA only requires co
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36817;&#20284;&#39640;&#26031;&#28388;&#27874;&#21644;&#24179;&#28369;&#26041;&#27861;&#65292;&#23427;&#23558;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20302;&#31209;&#36817;&#20284;&#20256;&#25773;&#65292;&#36890;&#36807;&#23558;Lyapunov&#26041;&#31243;&#25237;&#24433;&#21040;&#20302;&#31209;&#30697;&#38453;&#30340;&#27969;&#24418;&#19978;&#65292;&#20351;&#29992;&#25968;&#20540;&#31283;&#23450;&#30340;&#21160;&#24577;&#20302;&#31209;&#31215;&#20998;&#22120;&#27714;&#35299;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2306.07774</link><description>&lt;p&gt;
&#38477;&#31209;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65306;&#22312;&#39640;&#32500;&#20013;&#36827;&#34892;&#36817;&#20284;&#20302;&#31209;&#21160;&#24577;&#28388;&#27874;
&lt;/p&gt;
&lt;p&gt;
The Rank-Reduced Kalman Filter: Approximate Dynamical-Low-Rank Filtering In High Dimensions. (arXiv:2306.07774v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07774
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36817;&#20284;&#39640;&#26031;&#28388;&#27874;&#21644;&#24179;&#28369;&#26041;&#27861;&#65292;&#23427;&#23558;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20302;&#31209;&#36817;&#20284;&#20256;&#25773;&#65292;&#36890;&#36807;&#23558;Lyapunov&#26041;&#31243;&#25237;&#24433;&#21040;&#20302;&#31209;&#30697;&#38453;&#30340;&#27969;&#24418;&#19978;&#65292;&#20351;&#29992;&#25968;&#20540;&#31283;&#23450;&#30340;&#21160;&#24577;&#20302;&#31209;&#31215;&#20998;&#22120;&#27714;&#35299;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#21160;&#24577;&#31995;&#32479;&#30340;&#25512;&#26029;&#21644;&#27169;&#25311;&#20013;&#65292;&#38656;&#35201;&#36827;&#34892;&#26576;&#31181;&#24418;&#24335;&#30340;&#38477;&#32500;&#25165;&#33021;&#20351;&#38382;&#39064;&#20855;&#26377;&#21487;&#22788;&#29702;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36817;&#20284;&#39640;&#26031;&#28388;&#27874;&#21644;&#24179;&#28369;&#26041;&#27861;&#65292;&#23427;&#23558;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20302;&#31209;&#36817;&#20284;&#20256;&#25773;&#12290;&#36825;&#26159;&#36890;&#36807;&#23558;&#39044;&#27979;&#27493;&#39588;&#30456;&#20851;&#30340;Lyapunov&#26041;&#31243;&#25237;&#24433;&#21040;&#20302;&#31209;&#30697;&#38453;&#30340;&#27969;&#24418;&#19978;&#26469;&#23454;&#29616;&#30340;&#65292;&#28982;&#21518;&#36890;&#36807;&#26368;&#36817;&#24320;&#21457;&#30340;&#25968;&#20540;&#31283;&#23450;&#12289;&#21160;&#24577;&#20302;&#31209;&#31215;&#20998;&#22120;&#27714;&#35299;&#36825;&#20123;&#26041;&#31243;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#36890;&#36807;&#27880;&#24847;&#21327;&#26041;&#24046;&#26356;&#26032;&#20165;&#36716;&#25442;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#21015;&#31354;&#38388;&#65292;&#32780;&#35813;&#31354;&#38388;&#30001;&#26500;&#36896;&#24471;&#21040;&#65292;&#20174;&#32780;&#20351;&#26356;&#26032;&#27493;&#39588;&#20855;&#26377;&#21487;&#22788;&#29702;&#24615;&#12290;&#31639;&#27861;&#19982;&#29616;&#26377;&#30340;&#22522;&#20110;&#38598;&#21512;&#30340;&#26041;&#27861;&#19981;&#21516;&#20043;&#22788;&#22312;&#20110;&#65292;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20302;&#31209;&#36817;&#20284;&#26159;&#30830;&#23450;&#24615;&#30340;&#65292;&#32780;&#19981;&#26159;&#38543;&#26426;&#30340;&#12290;&#20851;&#38190;&#22312;&#20110;&#65292;&#36825;&#20351;&#24471;&#35813;&#26041;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inference and simulation in the context of high-dimensional dynamical systems remain computationally challenging problems. Some form of dimensionality reduction is required to make the problem tractable in general. In this paper, we propose a novel approximate Gaussian filtering and smoothing method which propagates low-rank approximations of the covariance matrices. This is accomplished by projecting the Lyapunov equations associated with the prediction step to a manifold of low-rank matrices, which are then solved by a recently developed, numerically stable, dynamical low-rank integrator. Meanwhile, the update steps are made tractable by noting that the covariance update only transforms the column space of the covariance matrix, which is low-rank by construction. The algorithm differentiates itself from existing ensemble-based approaches in that the low-rank approximations of the covariance matrices are deterministic, rather than stochastic. Crucially, this enables the method to repr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#25311;&#30340;&#21487;&#22788;&#29702;&#21644;&#19981;&#21487;&#22788;&#29702;&#20284;&#28982;&#20989;&#25968;&#30340;&#39057;&#29575;&#27966;&#25512;&#26029;&#26041;&#27861;&#65292;&#24182;&#22312;&#23431;&#23449;&#23398;&#12289;&#39640;&#33021;&#29289;&#29702;&#12289;&#22825;&#25991;&#23398;&#21644;&#27969;&#34892;&#30149;&#23398;&#39046;&#22495;&#36827;&#34892;&#20102;&#28436;&#31034;&#12290;</title><link>http://arxiv.org/abs/2306.07769</link><description>&lt;p&gt;
&#22522;&#20110;&#27169;&#25311;&#30340;&#21487;&#22788;&#29702;&#21644;&#19981;&#21487;&#22788;&#29702;&#20284;&#28982;&#20989;&#25968;&#30340;&#39057;&#29575;&#27966;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Simulation-Based Frequentist Inference with Tractable and Intractable Likelihoods. (arXiv:2306.07769v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07769
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#25311;&#30340;&#21487;&#22788;&#29702;&#21644;&#19981;&#21487;&#22788;&#29702;&#20284;&#28982;&#20989;&#25968;&#30340;&#39057;&#29575;&#27966;&#25512;&#26029;&#26041;&#27861;&#65292;&#24182;&#22312;&#23431;&#23449;&#23398;&#12289;&#39640;&#33021;&#29289;&#29702;&#12289;&#22825;&#25991;&#23398;&#21644;&#27969;&#34892;&#30149;&#23398;&#39046;&#22495;&#36827;&#34892;&#20102;&#28436;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#31185;&#23398;&#39046;&#22495;&#20013;&#65292;&#36830;&#25509;&#29702;&#35770;&#27169;&#22411;&#21644;&#35266;&#23519;&#32467;&#26524;&#30340;&#39640;&#20445;&#30495;&#24230;&#27169;&#25311;&#22120;&#26159;&#19981;&#21487;&#25110;&#32570;&#30340;&#24037;&#20855;&#12290;&#24403;&#19982;&#26426;&#22120;&#23398;&#20064;&#30456;&#32467;&#21512;&#26102;&#65292;&#27169;&#25311;&#22120;&#20351;&#24471;&#30452;&#25509;&#20174;&#30495;&#23454;&#21644;&#27169;&#25311;&#35266;&#23519;&#32467;&#26524;&#20013;&#25512;&#26029;&#29702;&#35770;&#27169;&#22411;&#30340;&#21442;&#25968;&#25104;&#20026;&#21487;&#33021;&#65292;&#32780;&#19981;&#38656;&#35201;&#26126;&#30830;&#20351;&#29992;&#20284;&#28982;&#20989;&#25968;&#65292;&#29305;&#21035;&#26159;&#22312;&#20284;&#28982;&#20989;&#25968;&#19981;&#21487;&#22788;&#29702;&#30340;&#24773;&#20917;&#19979;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#26368;&#36817;&#25552;&#20986;&#30340;&#26080;&#20284;&#28982;&#39057;&#29575;&#23398;&#25512;&#26029;&#65288;LF2I&#65289;&#26041;&#27861;&#30340;&#19968;&#20010;&#31616;&#21333;&#20462;&#25913;&#65292;&#36825;&#20010;&#20462;&#25913;&#20855;&#26377;&#19968;&#20123;&#35745;&#31639;&#19978;&#30340;&#20248;&#21183;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#35813;&#31639;&#27861;&#24212;&#29992;&#20110;&#19977;&#20010;&#25945;&#23398;&#19978;&#26377;&#36259;&#30340;&#20363;&#23376;&#26469;&#35828;&#26126;&#20854;&#23454;&#29992;&#24615;&#65306;&#31532;&#19968;&#20010;&#20363;&#23376;&#26469;&#33258;&#23431;&#23449;&#23398;&#65292;&#31532;&#20108;&#20010;&#20363;&#23376;&#26469;&#33258;&#39640;&#33021;&#29289;&#29702;&#21644;&#22825;&#25991;&#23398;&#65292;&#20004;&#32773;&#37117;&#20855;&#26377;&#21487;&#22788;&#29702;&#30340;&#20284;&#28982;&#20989;&#25968;&#65292;&#32780;&#31532;&#19977;&#20010;&#20855;&#26377;&#19981;&#21487;&#22788;&#29702;&#30340;&#20284;&#28982;&#20989;&#25968;&#65292;&#26469;&#33258;&#20110;&#27969;&#34892;&#30149;&#23398;&#12290;
&lt;/p&gt;
&lt;p&gt;
High-fidelity simulators that connect theoretical models with observations are indispensable tools in many sciences. When coupled with machine learning, a simulator makes it possible to infer the parameters of a theoretical model directly from real and simulated observations without explicit use of the likelihood function. This is of particular interest when the latter is intractable. We introduce a simple modification of the recently proposed likelihood-free frequentist inference (LF2I) approach that has some computational advantages. The utility of our algorithm is illustrated by applying it to three pedagogically interesting examples: the first is from cosmology, the second from high-energy physics and astronomy, both with tractable likelihoods, while the third, with an intractable likelihood, is from epidemiology.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#20445;&#30495;&#24230;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#31639;&#27861;&#26694;&#26550;&#65292;&#24182;&#36827;&#19968;&#27493;&#30740;&#31350;&#20102;&#20445;&#30495;&#24230;&#36873;&#25321;&#30340;&#20195;&#20215;&#22797;&#26434;&#24230;&#19978;&#19979;&#30028;&#65292;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36951;&#25022;&#23450;&#20041;&#24182;&#35777;&#26126;&#20102;&#30456;&#24212;&#30340;&#38382;&#39064;&#26080;&#20851;&#21644;&#38382;&#39064;&#30456;&#20851;&#19979;&#30028;&#12290;</title><link>http://arxiv.org/abs/2306.07761</link><description>&lt;p&gt;
&#22810;&#20445;&#30495;&#24230;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#20877;&#25506;&#35752;
&lt;/p&gt;
&lt;p&gt;
Multi-Fidelity Multi-Armed Bandits Revisited. (arXiv:2306.07761v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07761
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#20445;&#30495;&#24230;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#31639;&#27861;&#26694;&#26550;&#65292;&#24182;&#36827;&#19968;&#27493;&#30740;&#31350;&#20102;&#20445;&#30495;&#24230;&#36873;&#25321;&#30340;&#20195;&#20215;&#22797;&#26434;&#24230;&#19978;&#19979;&#30028;&#65292;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36951;&#25022;&#23450;&#20041;&#24182;&#35777;&#26126;&#20102;&#30456;&#24212;&#30340;&#38382;&#39064;&#26080;&#20851;&#21644;&#38382;&#39064;&#30456;&#20851;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#32463;&#20856;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#25193;&#23637;&#8212;&#8212;&#22810;&#20445;&#30495;&#24230;&#22810;&#33218;&#36172;&#21338;&#26426;(MF-MAB)&#12290;MF-MAB&#20801;&#35768;&#27599;&#20010;&#33218;&#26681;&#25454;&#19981;&#21516;&#30340;&#20195;&#20215;(&#20445;&#30495;&#24230;)&#21644;&#35266;&#27979;&#31934;&#24230;&#26469;&#36827;&#34892;&#25289;&#21160;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#26368;&#20339;&#33218;&#35782;&#21035;&#20197;&#21450;&#36951;&#25022;&#26368;&#23567;&#21270;&#20004;&#20010;&#30446;&#26631;&#12290;&#23545;&#20110;&#26368;&#20339;&#33218;&#35782;&#21035;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20197;&#19979;&#20869;&#23481;&#65306;(a)&#20195;&#20215;&#22797;&#26434;&#24230;&#19979;&#30028;&#65292;(b)&#20004;&#31181;&#19981;&#21516;&#20445;&#30495;&#24230;&#36873;&#25321;&#26041;&#27861;&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;(c)&#20004;&#31181;&#26041;&#27861;&#30340;&#20195;&#20215;&#22797;&#26434;&#24230;&#19978;&#30028;&#12290;&#30001;MF-MAB&#30340;&#36825;&#20004;&#20010;&#20195;&#20215;&#22797;&#26434;&#24230;&#19979;&#30028;&#21487;&#20197;&#24674;&#22797;&#32463;&#20856;&#65288;&#21333;&#20445;&#30495;&#24230;&#65289;MAB&#30340;&#26631;&#20934;&#26679;&#26412;&#22797;&#26434;&#24230;&#19979;&#30028;&#12290;&#23545;&#20110;MF-MAB&#30340;&#36951;&#25022;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36951;&#25022;&#23450;&#20041;&#65292;&#35777;&#26126;&#20102;&#23427;&#30340;&#38382;&#39064;&#26080;&#20851;&#30340;&#36951;&#25022;&#19979;&#30028;&#20026;$\Omega(K^{1/3}\Lambda^{2/3})&#8203;$&#21644;&#38382;&#39064;&#30456;&#20851;&#30340;&#19979;&#30028;$\Omega(K\log \Lambda)&#8203;$&#65292;&#20854;&#20013;$K$&#26159;&#33218;&#25968;&#65292;$\Lambda$&#26159;&#20197;&#20195;&#20215;&#20026;&#21333;&#20301;&#30340;&#20915;&#31574;&#39044;&#31639;&#65292;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28120;&#27760;&#30340;&#31639;&#27861;&#65292;&#20854;&#26435;&#34913;&#20102;&#19981;&#21516;&#30340;&#20195;&#20215;&#32452;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the multi-fidelity multi-armed bandit (MF-MAB), an extension of the canonical multi-armed bandit (MAB) problem. MF-MAB allows each arm to be pulled with different costs (fidelities) and observation accuracy. We study both the best arm identification with fixed confidence (BAI) and the regret minimization objectives. For BAI, we present (a) a cost complexity lower bound, (b) an algorithmic framework with two alternative fidelity selection procedures, and (c) both procedures' cost complexity upper bounds. From both cost complexity bounds of MF-MAB, one can recover the standard sample complexity bounds of the classic (single-fidelity) MAB. For regret minimization of MF-MAB, we propose a new regret definition, prove its problem-independent regret lower bound $\Omega(K^{1/3}\Lambda^{2/3})$ and problem-dependent lower bound $\Omega(K\log \Lambda)$, where $K$ is the number of arms and $\Lambda$ is the decision budget in terms of cost, and devise an elimination-based algorithm whose w
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;$\pi$-KRVI&#30340;&#20048;&#35266;&#20462;&#25913;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#26680;&#23725;&#22238;&#24402;&#36827;&#34892;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#12290;&#35770;&#25991;&#35777;&#26126;&#20102;&#22312;&#19968;&#33324;&#35774;&#32622;&#19979;&#31532;&#19968;&#20010;&#26368;&#20248;&#36951;&#25022;&#20445;&#35777;&#65292;&#24182;&#30456;&#23545;&#20110;&#29616;&#26377;&#26368;&#20248;&#32467;&#26524;&#23454;&#29616;&#20102;&#26174;&#30528;&#30340;&#22810;&#39033;&#24335;&#20302;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2306.07745</link><description>&lt;p&gt;
&#26680;&#21270;&#24378;&#21270;&#23398;&#20064;&#21450;&#20854;&#36817;&#20284;&#26041;&#27861;&#30340;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Kernelized Reinforcement Learning with Order Optimal Regret Bounds. (arXiv:2306.07745v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07745
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;$\pi$-KRVI&#30340;&#20048;&#35266;&#20462;&#25913;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#26680;&#23725;&#22238;&#24402;&#36827;&#34892;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#12290;&#35770;&#25991;&#35777;&#26126;&#20102;&#22312;&#19968;&#33324;&#35774;&#32622;&#19979;&#31532;&#19968;&#20010;&#26368;&#20248;&#36951;&#25022;&#20445;&#35777;&#65292;&#24182;&#30456;&#23545;&#20110;&#29616;&#26377;&#26368;&#20248;&#32467;&#26524;&#23454;&#29616;&#20102;&#26174;&#30528;&#30340;&#22810;&#39033;&#24335;&#20302;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#22312;&#21508;&#31181;&#20855;&#26377;&#22797;&#26434;&#27169;&#22411;&#21644;&#22823;&#29366;&#24577;-&#34892;&#20026;&#31354;&#38388;&#30340;&#23454;&#38469;&#22330;&#26223;&#20013;&#26174;&#31034;&#20986;&#20102;&#23454;&#35777;&#30340;&#25104;&#21151;&#12290;&#20294;&#26159;&#65292;&#29616;&#26377;&#30340;&#20998;&#26512;&#32467;&#26524;&#36890;&#24120;&#38598;&#20013;&#20110;&#20855;&#26377;&#23569;&#37327;&#29366;&#24577;-&#34892;&#20026;&#25110;&#31616;&#21333;&#27169;&#22411;&#65288;&#20363;&#22914;&#32447;&#24615;&#24314;&#27169;&#29366;&#24577;-&#34892;&#20026;&#20540;&#20989;&#25968;&#65289;&#30340;&#35774;&#32622;&#12290; &#20026;&#20102;&#25512;&#23548;&#26377;&#25928;&#22788;&#29702;&#26356;&#24191;&#27867;&#20540;&#20989;&#25968;&#30340;&#22823;&#29366;&#24577;-&#34892;&#20026;&#31354;&#38388;&#30340;RL&#31574;&#30053;&#65292;&#19968;&#20123;&#26368;&#26032;&#24037;&#20316;&#32771;&#34385;&#20351;&#29992;&#26680;&#23725;&#22238;&#24402;&#36827;&#34892;&#38750;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#12290; &#25105;&#20204;&#25552;&#20986;&#20102;&#31216;&#20026;$\pi$-KRVI&#30340;&#26041;&#27861;&#65292;&#23427;&#26159;&#26368;&#23567;&#20108;&#20056;&#20540;&#36845;&#20195;&#30340;&#19968;&#31181;&#20048;&#35266;&#20462;&#25913;&#65292;&#24403;&#29366;&#24577;-&#34892;&#20026;&#20540;&#20989;&#25968;&#30001;RKHS&#34920;&#31034;&#26102;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19968;&#33324;&#35774;&#32622;&#19979;&#31532;&#19968;&#20010;&#26368;&#20248;&#36951;&#25022;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;&#65292;&#22312;&#35768;&#22810;&#20855;&#26377;&#39640;&#24230;&#38750;&#20809;&#28369;&#20869;&#26680;&#65288;&#20363;&#22914;&#31070;&#32463;&#20999;&#21521;&#20869;&#26680;&#25110;&#26576;&#20123;Mat\'ern&#20869;&#26680;&#65289;&#30340;&#24773;&#20917;&#19979;&#65292;&#30456;&#23545;&#20110;&#29616;&#26377;&#26368;&#20248;&#32467;&#26524;&#65292;&#23384;&#22312;&#26174;&#30528;&#30340;&#22810;&#39033;&#24335;&#20302;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning (RL) has shown empirical success in various real world settings with complex models and large state-action spaces. The existing analytical results, however, typically focus on settings with a small number of state-actions or simple models such as linearly modeled state-action value functions. To derive RL policies that efficiently handle large state-action spaces with more general value functions, some recent works have considered nonlinear function approximation using kernel ridge regression. We propose $\pi$-KRVI, an optimistic modification of least-squares value iteration, when the state-action value function is represented by an RKHS. We prove the first order-optimal regret guarantees under a general setting. Our results show a significant polynomial in the number of episodes improvement over the state of the art. In particular, with highly non-smooth kernels (such as Neural Tangent kernel or some Mat\'ern kernels) the existing results lead to trivial (superl
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20174;&#29702;&#35770;&#35282;&#24230;&#25506;&#35752;&#20102;&#23545;&#25239;&#40065;&#26834;&#24615;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#20854;&#40065;&#26834;&#24615;&#21644;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.07723</link><description>&lt;p&gt;
&#23545;&#25239;&#40065;&#26834;&#24615;&#23398;&#20064;&#30340;&#29702;&#35770;&#22522;&#30784;
&lt;/p&gt;
&lt;p&gt;
Theoretical Foundations of Adversarially Robust Learning. (arXiv:2306.07723v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07723
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20174;&#29702;&#35770;&#35282;&#24230;&#25506;&#35752;&#20102;&#23545;&#25239;&#40065;&#26834;&#24615;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#20854;&#40065;&#26834;&#24615;&#21644;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#21462;&#24471;&#20102;&#38750;&#20961;&#30340;&#36827;&#23637;&#65292;&#20294;&#24050;&#32463;&#35777;&#26126;&#23427;&#20204;&#23545;&#20110;&#23545;&#25239;&#26679;&#26412;&#26159;&#33030;&#24369;&#30340;&#65306;&#23545;&#27979;&#35797;&#26679;&#26412;&#36827;&#34892;&#32454;&#24494;&#20294;&#26377;&#24847;&#30340;&#25200;&#21160;&#65292;&#23601;&#20250;&#23548;&#33268;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#38169;&#35823;&#20998;&#31867;&#12290;&#26412;&#35770;&#25991;&#26088;&#22312;&#20174;&#29702;&#35770;&#35282;&#24230;&#35299;&#20915;&#36825;&#19968;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#65292;&#25506;&#35752;&#25105;&#20204;&#21487;&#20197;&#24076;&#26395;&#20445;&#35777;&#20160;&#20040;&#26679;&#30340;&#40065;&#26834;&#24615;&#24615;&#36136;&#65292;&#24182;&#25552;&#20379;&#21487;&#23454;&#29616;&#31639;&#27861;&#20445;&#35777;&#36825;&#20123;&#24615;&#36136;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite extraordinary progress, current machine learning systems have been shown to be brittle against adversarial examples: seemingly innocuous but carefully crafted perturbations of test examples that cause machine learning predictors to misclassify. Can we learn predictors robust to adversarial examples? and how? There has been much empirical interest in this contemporary challenge in machine learning, and in this thesis, we address it from a theoretical perspective.  In this thesis, we explore what robustness properties can we hope to guarantee against adversarial examples and develop an understanding of how to algorithmically guarantee them. We illustrate the need to go beyond traditional approaches and principles such as empirical risk minimization and uniform convergence, and make contributions that can be categorized as follows: (1) introducing problem formulations capturing aspects of emerging practical challenges in robust learning, (2) designing new learning algorithms with 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#24046;&#20998;&#38544;&#31169;&#26465;&#20214;&#19979;&#30340;&#19968;&#27425;&#25490;&#21015;&#21704;&#24076;&#26041;&#27861;&#21644;&#22522;&#20110; Bin &#30340;&#19968;&#33268;&#21152;&#26435;&#37319;&#26679;&#65292;&#20026;&#22823;&#35268;&#27169;&#25628;&#32034;&#21644;&#23398;&#20064;&#24212;&#29992;&#31243;&#24207;&#25552;&#20379;&#20102;&#26356;&#39640;&#25928;&#12289;&#26356;&#26041;&#20415;&#30340;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2306.07674</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#19979;&#30340;&#19968;&#27425;&#25490;&#21015;&#21704;&#24076;&#21644;&#22522;&#20110; Bin &#30340;&#19968;&#33268;&#21152;&#26435;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Differentially Private One Permutation Hashing and Bin-wise Consistent Weighted Sampling. (arXiv:2306.07674v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07674
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#24046;&#20998;&#38544;&#31169;&#26465;&#20214;&#19979;&#30340;&#19968;&#27425;&#25490;&#21015;&#21704;&#24076;&#26041;&#27861;&#21644;&#22522;&#20110; Bin &#30340;&#19968;&#33268;&#21152;&#26435;&#37319;&#26679;&#65292;&#20026;&#22823;&#35268;&#27169;&#25628;&#32034;&#21644;&#23398;&#20064;&#24212;&#29992;&#31243;&#24207;&#25552;&#20379;&#20102;&#26356;&#39640;&#25928;&#12289;&#26356;&#26041;&#20415;&#30340;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#23567;&#21704;&#24076;&#65288;MinHash&#65289;&#26159;&#19968;&#31181;&#26631;&#20934;&#31639;&#27861;&#65292;&#24191;&#27867;&#24212;&#29992;&#20110;&#20855;&#26377;&#20108;&#36827;&#21046;&#65288;0/1&#65289;Jaccard&#30456;&#20284;&#24230;&#30340;&#22823;&#35268;&#27169;&#25628;&#32034;&#21644;&#23398;&#20064;&#24212;&#29992;&#31243;&#24207;&#12290;MinHash &#30340;&#24120;&#35265;&#29992;&#36884;&#26159;&#22788;&#29702;&#22823;&#35268;&#27169; n-gram &#25991;&#26412;&#34920;&#31034;&#65292;&#20197;&#20415;&#23454;&#36341;&#32773;&#19981;&#24517;&#23454;&#29616;&#21407;&#22987;&#25968;&#25454;&#65288;&#36825;&#23558;&#26159;&#31105;&#27490;&#30340;&#65289;&#12290;MinHash &#30340;&#21478;&#19968;&#20010;&#27969;&#34892;&#29992;&#36884;&#26159;&#26500;&#24314;&#21704;&#24076;&#34920;&#65292;&#20197;&#23454;&#29616;&#20122;&#32447;&#24615;&#26102;&#38388;&#30340;&#36817;&#20284;&#26368;&#36817;&#37051;&#25628;&#32034;&#12290;MinHash &#36824;&#29992;&#20316;&#26500;&#24314;&#22823;&#35268;&#27169;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#30340;&#24037;&#20855;&#12290;&#26631;&#20934;&#30340; MinHash &#23454;&#29616;&#38656;&#35201;&#24212;&#29992; K &#20010;&#38543;&#26426;&#25490;&#21015;&#65292;&#32780;&#19968;&#27425;&#25490;&#21015;&#21704;&#24076;&#26041;&#27861;&#65288;OPH&#65289;&#21017;&#26159; MinHash &#30340;&#19968;&#31181;&#39640;&#25928;&#26367;&#20195;&#26041;&#27861;&#65292;&#23427;&#23558;&#25968;&#25454;&#30690;&#37327;&#21010;&#20998;&#20026; K &#20010; bin&#65292;&#24182;&#22312;&#27599;&#20010; bin &#20013;&#29983;&#25104;&#21704;&#24076;&#20540;&#12290;OPH &#26356;&#21152;&#39640;&#25928;&#65292;&#26356;&#21152;&#20415;&#21033;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#19982; OPH&#65288;&#20197;&#21450; MinHash&#65289;&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#19979;&#30340;&#19968;&#27425;&#25490;&#21015;&#21704;&#24076;&#21644;&#22522;&#20110; Bin &#30340;&#19968;&#33268;&#21152;&#26435;&#37319;&#26679;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Minwise hashing (MinHash) is a standard algorithm widely used in the industry, for large-scale search and learning applications with the binary (0/1) Jaccard similarity. One common use of MinHash is for processing massive n-gram text representations so that practitioners do not have to materialize the original data (which would be prohibitive). Another popular use of MinHash is for building hash tables to enable sub-linear time approximate near neighbor (ANN) search. MinHash has also been used as a tool for building large-scale machine learning systems. The standard implementation of MinHash requires applying $K$ random permutations. In comparison, the method of one permutation hashing (OPH), is an efficient alternative of MinHash which splits the data vectors into $K$ bins and generates hash values within each bin. OPH is substantially more efficient and also more convenient to use.  In this paper, we combine the differential privacy (DP) with OPH (as well as MinHash), to propose the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#32034;&#20102;&#22312;&#31232;&#30095;&#25968;&#25454;&#20013;&#20351;&#29992;&#22522;&#20110;&#22270;&#30340;ANN&#31639;&#27861;&#36827;&#34892;&#39640;&#25928;&#25628;&#32034;&#65292;&#29305;&#21035;&#26159;HNSW&#31639;&#27861;&#22312;&#25628;&#32034;&#31232;&#30095;&#23884;&#20837;&#26041;&#38754;&#29305;&#21035;&#26377;&#25928;&#12290;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#23454;&#38469;&#20013;&#24120;&#35265;&#30340;&#31232;&#30095;&#23884;&#20837;&#30340;SGN&#21464;&#20307;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#21487;&#20197;&#36798;&#21040;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#27700;&#24179;&#12290;</title><link>http://arxiv.org/abs/2306.07607</link><description>&lt;p&gt;
&#22522;&#20110;&#22270;&#30340;ANN&#31639;&#27861;&#22312;&#31232;&#30095;&#25968;&#25454;&#19978;&#30340;&#24212;&#29992;&#65306;&#21345;&#26041;&#21452;&#22612;&#27169;&#22411;&#12289;HNSW&#12289;&#31526;&#21495;&#26607;&#35199;&#25237;&#24433;
&lt;/p&gt;
&lt;p&gt;
Practice with Graph-based ANN Algorithms on Sparse Data: Chi-square Two-tower model, HNSW, Sign Cauchy Projections. (arXiv:2306.07607v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07607
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#22312;&#31232;&#30095;&#25968;&#25454;&#20013;&#20351;&#29992;&#22522;&#20110;&#22270;&#30340;ANN&#31639;&#27861;&#36827;&#34892;&#39640;&#25928;&#25628;&#32034;&#65292;&#29305;&#21035;&#26159;HNSW&#31639;&#27861;&#22312;&#25628;&#32034;&#31232;&#30095;&#23884;&#20837;&#26041;&#38754;&#29305;&#21035;&#26377;&#25928;&#12290;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#23454;&#38469;&#20013;&#24120;&#35265;&#30340;&#31232;&#30095;&#23884;&#20837;&#30340;SGN&#21464;&#20307;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#21487;&#20197;&#36798;&#21040;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#31232;&#30095;&#25968;&#25454;&#24456;&#24120;&#35265;&#12290;&#20256;&#32479;&#30340;&#8220;&#25163;&#24037;&#21046;&#20316;&#8221;&#30340;&#29305;&#24449;&#36890;&#24120;&#26159;&#31232;&#30095;&#30340;&#12290;&#36890;&#36807;&#35757;&#32451;&#24471;&#21040;&#30340;&#23884;&#20837;&#21521;&#37327;&#20063;&#21487;&#33021;&#38750;&#24120;&#31232;&#30095;&#65292;&#20363;&#22914;&#20351;&#29992;&#8220;ReLu&#8221;&#28608;&#27963;&#20989;&#25968;&#35757;&#32451;&#30340;&#23884;&#20837;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#20351;&#29992;&#22522;&#20110;&#22270;&#30340;ANN&#31639;&#27861;&#65288;&#20363;&#22914;&#65292;HNSW&#25110;&#20854;GPU&#29256;&#26412;SONG&#65289;&#36827;&#34892;&#31232;&#30095;&#25968;&#25454;&#20013;&#30340;&#39640;&#25928;&#25628;&#32034;&#65292;&#36825;&#20123;&#31639;&#27861;&#22312;&#24037;&#19994;&#23454;&#36341;&#20013;&#38750;&#24120;&#27969;&#34892;&#65292;&#20363;&#22914;&#25628;&#32034;&#21644;&#24191;&#21578;&#65288;&#24191;&#21578;&#25237;&#25918;&#65289;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#19987;&#21033;&#24191;&#21578;&#23450;&#21521;&#24212;&#29992;&#30340;&#23454;&#39564;&#65292;&#24182;&#27979;&#35797;&#20102;&#22522;&#20934;&#20844;&#20849;&#25968;&#25454;&#38598;&#12290;&#23545;&#20110;&#24191;&#21578;&#23450;&#21521;&#65292;&#25105;&#20204;&#20351;&#29992;&#26631;&#20934;&#30340;&#8220;&#20313;&#24358;&#21452;&#22612;&#8221;&#27169;&#22411;&#21644;&#24320;&#21457;&#30340;&#8220;&#21345;&#26041;&#21452;&#22612;&#8221;&#27169;&#22411;&#35757;&#32451;&#23884;&#20837;&#65292;&#36825;&#20004;&#31181;&#27169;&#22411;&#37117;&#33021;&#22815;&#20135;&#29983;&#65288;&#38750;&#24120;&#65289;&#31232;&#30095;&#30340;&#23884;&#20837;&#65292;&#24403;&#23427;&#20204;&#19982;&#8220;ReLu&#8221;&#28608;&#27963;&#20989;&#25968;&#38598;&#25104;&#26102;&#12290;&#22312;&#23884;&#20837;&#24335;&#26816;&#32034;&#65288;EBR&#65289;&#24212;&#29992;&#20013;&#65292;&#22312;&#35757;&#32451;&#23436;&#23884;&#20837;&#21521;&#37327;&#21518;&#65292;&#19979;&#19968;&#20010;&#33267;&#20851;&#37325;&#35201;&#30340;&#20219;&#21153;&#26159;&#29992;&#20110;&#26381;&#21153;&#30340;&#36817;&#20284;&#26368;&#36817;&#37051;&#65288;ANN&#65289;&#25628;&#32034;&#12290;&#34429;&#28982;&#26377;&#35768;&#22810;ANN&#31639;&#27861;&#21487;&#29992;&#65292;&#20294;&#22522;&#20110;&#22270;&#30340;&#31639;&#27861;&#24050;&#30693;&#26159;&#39640;&#25928;&#19988;&#21487;&#25193;&#23637;&#30340;&#12290;&#25105;&#20204;&#32463;&#39564;&#35777;&#26126;&#65292;&#22522;&#20110;&#22270;&#30340;&#31639;&#27861;&#65292;&#29305;&#21035;&#26159;HNSW&#22312;&#25628;&#32034;&#31232;&#30095;&#23884;&#20837;&#65288;&#39640;&#36798;97&#65285;&#30340;&#31232;&#30095;&#24230;&#65289;&#26041;&#38754;&#29305;&#21035;&#26377;&#25928;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#23454;&#38469;&#20013;&#24120;&#35265;&#30340;&#31232;&#30095;&#23884;&#20837;&#30340;SGN&#21464;&#20307;&#65288;&#31526;&#21495;&#26607;&#35199;&#25237;&#24433;&#65289;&#12290;&#25105;&#20204;&#23558;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#20844;&#20849;&#25968;&#25454;&#38598;&#20197;&#21450;&#26469;&#33258;&#24191;&#21578;&#24212;&#29992;&#30340;&#23454;&#38469;&#25968;&#25454;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#21487;&#20197;&#36798;&#21040;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse data are common. The traditional ``handcrafted'' features are often sparse. Embedding vectors from trained models can also be very sparse, for example, embeddings trained via the ``ReLu'' activation function. In this paper, we report our exploration of efficient search in sparse data with graph-based ANN algorithms (e.g., HNSW, or SONG which is the GPU version of HNSW), which are popular in industrial practice, e.g., search and ads (advertising).  We experiment with the proprietary ads targeting application, as well as benchmark public datasets. For ads targeting, we train embeddings with the standard ``cosine two-tower'' model and we also develop the ``chi-square two-tower'' model. Both models produce (highly) sparse embeddings when they are integrated with the ``ReLu'' activation function. In EBR (embedding-based retrieval) applications, after we the embeddings are trained, the next crucial task is the approximate near neighbor (ANN) search for serving. While there are many AN
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#36873;&#25321;&#24615;&#26631;&#35760;&#25968;&#25454;&#30340;&#23398;&#20064;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#21033;&#29992;&#21382;&#21490;&#20915;&#31574;&#30001;&#19968;&#32452;&#24322;&#36136;&#20915;&#31574;&#32773;&#20570;&#20986;&#30340;&#20107;&#23454;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#31181;&#26377;&#21407;&#29702;&#30340;&#24037;&#20855;&#21464;&#37327;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#35268;&#21017;&#12290;</title><link>http://arxiv.org/abs/2306.07566</link><description>&lt;p&gt;
&#23398;&#20064;&#36873;&#25321;&#26631;&#31614;&#19979;&#30340;&#24322;&#36136;&#20915;&#31574;&#32773;&#65306;&#19968;&#31181;&#24037;&#20855;&#21464;&#37327;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Learning under Selective Labels with Heterogeneous Decision-makers: An Instrumental Variable Approach. (arXiv:2306.07566v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07566
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#36873;&#25321;&#24615;&#26631;&#35760;&#25968;&#25454;&#30340;&#23398;&#20064;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#21033;&#29992;&#21382;&#21490;&#20915;&#31574;&#30001;&#19968;&#32452;&#24322;&#36136;&#20915;&#31574;&#32773;&#20570;&#20986;&#30340;&#20107;&#23454;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#31181;&#26377;&#21407;&#29702;&#30340;&#24037;&#20855;&#21464;&#37327;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#35268;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#36873;&#25321;&#24615;&#26631;&#35760;&#25968;&#25454;&#19979;&#30340;&#23398;&#20064;&#38382;&#39064;&#12290;&#36825;&#31181;&#38382;&#39064;&#22312;&#21382;&#21490;&#20915;&#31574;&#23548;&#33268;&#32467;&#26524;&#20165;&#37096;&#20998;&#26631;&#35760;&#26102;&#20986;&#29616;&#12290;&#26631;&#35760;&#25968;&#25454;&#20998;&#24067;&#21487;&#33021;&#19982;&#25972;&#20307;&#20154;&#32676;&#26377;&#26174;&#33879;&#24046;&#24322;&#65292;&#29305;&#21035;&#26159;&#24403;&#21382;&#21490;&#20915;&#31574;&#21644;&#30446;&#26631;&#32467;&#26524;&#21487;&#20197;&#21516;&#26102;&#21463;&#26576;&#20123;&#26410;&#35266;&#23519;&#21040;&#30340;&#22240;&#32032;&#24433;&#21709;&#26102;&#12290;&#22240;&#27492;&#65292;&#20165;&#22522;&#20110;&#26631;&#35760;&#25968;&#25454;&#36827;&#34892;&#23398;&#20064;&#21487;&#33021;&#20250;&#23548;&#33268;&#22312;&#25972;&#20307;&#20154;&#32676;&#20013;&#30340;&#20005;&#37325;&#20559;&#24046;&#12290;&#25105;&#20204;&#30340;&#35770;&#25991;&#36890;&#36807;&#21033;&#29992;&#35768;&#22810;&#24212;&#29992;&#20013;&#21382;&#21490;&#20915;&#31574;&#30001;&#19968;&#32452;&#24322;&#36136;&#20915;&#31574;&#32773;&#20570;&#20986;&#30340;&#20107;&#23454;&#26469;&#35299;&#20915;&#27492;&#25361;&#25112;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22312;&#19968;&#20010;&#26377;&#21407;&#29702;&#30340;&#24037;&#20855;&#21464;&#37327;&#26694;&#26550;&#19979;&#20998;&#26512;&#20102;&#36825;&#31181;&#35774;&#32622;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#28385;&#36275;&#35266;&#23519;&#21040;&#30340;&#25968;&#25454;&#26102;&#20219;&#20309;&#32473;&#23450;&#39044;&#27979;&#35268;&#21017;&#30340;&#20840;&#20307;&#39118;&#38505;&#30340;&#28857;&#35782;&#21035;&#26465;&#20214;&#65292;&#24182;&#22312;&#28857;&#35782;&#21035;&#22833;&#36133;&#26102;&#25552;&#20379;&#20102;&#23574;&#38160;&#30340;&#39118;&#38505;&#30028;&#38480;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#35268;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of learning with selectively labeled data, which arises when outcomes are only partially labeled due to historical decision-making. The labeled data distribution may substantially differ from the full population, especially when the historical decisions and the target outcome can be simultaneously affected by some unobserved factors. Consequently, learning with only the labeled data may lead to severely biased results when deployed to the full population. Our paper tackles this challenge by exploiting the fact that in many applications the historical decisions were made by a set of heterogeneous decision-makers. In particular, we analyze this setup in a principled instrumental variable (IV) framework. We establish conditions for the full-population risk of any given prediction rule to be point-identified from the observed data and provide sharp risk bounds when the point identification fails. We further propose a weighted learning approach that learns prediction ru
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#25913;&#36827;BAI&#31639;&#27861;&#65292;SHVar&#36866;&#29992;&#20110;&#24050;&#30693;&#22870;&#21169;&#26041;&#24046;&#24773;&#20917;&#65292;SHAdaVar&#36866;&#29992;&#20110;&#26410;&#30693;&#22870;&#21169;&#26041;&#24046;&#24773;&#20917;&#65292;&#31639;&#27861;&#36890;&#36807;&#22312;&#19981;&#21516;&#33218;&#20043;&#38388;&#20998;&#37197;&#19981;&#21516;&#27604;&#20363;&#30340;&#39044;&#31639;&#65292;&#26356;&#22810;&#22320;&#36873;&#25321;&#26041;&#24046;&#26356;&#39640;&#30340;&#33218;&#65292;SHAdaVar&#36890;&#36807;&#36807;&#24230;&#20272;&#35745;&#26410;&#30693;&#22870;&#21169;&#26041;&#24046;&#20197;&#36138;&#24515;&#22320;&#20998;&#37197;&#39044;&#31639;&#12290;&#21019;&#26032;&#20043;&#22788;&#22312;&#20110;&#26080;&#38656;&#20851;&#38381;&#39044;&#31639;&#20998;&#37197;&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#26696;&#30340;&#33218;&#25289;&#21160;&#27425;&#25968;&#19979;&#30028;&#12290;</title><link>http://arxiv.org/abs/2306.07549</link><description>&lt;p&gt;
&#24322;&#26500;&#22870;&#21169;&#26041;&#24046;&#19979;&#30340;&#23450;&#38271;&#26368;&#20248;&#33218;&#35782;&#21035;&#38382;&#39064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Fixed-Budget Best-Arm Identification with Heterogeneous Reward Variances. (arXiv:2306.07549v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07549
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#25913;&#36827;BAI&#31639;&#27861;&#65292;SHVar&#36866;&#29992;&#20110;&#24050;&#30693;&#22870;&#21169;&#26041;&#24046;&#24773;&#20917;&#65292;SHAdaVar&#36866;&#29992;&#20110;&#26410;&#30693;&#22870;&#21169;&#26041;&#24046;&#24773;&#20917;&#65292;&#31639;&#27861;&#36890;&#36807;&#22312;&#19981;&#21516;&#33218;&#20043;&#38388;&#20998;&#37197;&#19981;&#21516;&#27604;&#20363;&#30340;&#39044;&#31639;&#65292;&#26356;&#22810;&#22320;&#36873;&#25321;&#26041;&#24046;&#26356;&#39640;&#30340;&#33218;&#65292;SHAdaVar&#36890;&#36807;&#36807;&#24230;&#20272;&#35745;&#26410;&#30693;&#22870;&#21169;&#26041;&#24046;&#20197;&#36138;&#24515;&#22320;&#20998;&#37197;&#39044;&#31639;&#12290;&#21019;&#26032;&#20043;&#22788;&#22312;&#20110;&#26080;&#38656;&#20851;&#38381;&#39044;&#31639;&#20998;&#37197;&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#26696;&#30340;&#33218;&#25289;&#21160;&#27425;&#25968;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#24322;&#26500;&#22870;&#21169;&#26041;&#24046;&#19979;&#30340;&#23450;&#38271;&#26368;&#20248;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#24212;&#29992;&#20110;&#19981;&#21516;&#22870;&#21169;&#26041;&#24046;&#24773;&#20917;&#19979;&#30340;&#25913;&#36827;BAI&#31639;&#27861;&#65306;SHVar&#36866;&#29992;&#20110;&#24050;&#30693;&#22870;&#21169;&#26041;&#24046;&#24773;&#20917;&#65292;SHAdaVar&#36866;&#29992;&#20110;&#26410;&#30693;&#22870;&#21169;&#26041;&#24046;&#24773;&#20917;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#36890;&#36807;&#22312;&#19981;&#21516;&#33218;&#20043;&#38388;&#20998;&#37197;&#19981;&#21516;&#27604;&#20363;&#30340;&#39044;&#31639;&#65292;&#26356;&#22810;&#22320;&#36873;&#25321;&#26041;&#24046;&#26356;&#39640;&#30340;&#33218;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#21019;&#26032;&#22312;&#20110;SHAdaVar&#30340;&#35774;&#35745;&#65292;&#20854;&#36890;&#36807;&#36807;&#24230;&#20272;&#35745;&#26410;&#30693;&#22870;&#21169;&#26041;&#24046;&#20197;&#36138;&#24515;&#22320;&#20998;&#37197;&#39044;&#31639;&#12290;&#25105;&#20204;&#20998;&#21035;&#23545;SHVar&#21644;SHAdaVar&#20013;&#35823;&#35782;&#21035;&#26368;&#20248;&#33218;&#30340;&#27010;&#29575;&#36827;&#34892;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#20381;&#36182;&#20110;&#26032;&#39062;&#30340;&#26080;&#38656;&#20851;&#38381;&#39044;&#31639;&#20998;&#37197;&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#26696;&#30340;&#33218;&#25289;&#21160;&#27425;&#25968;&#19979;&#30028;&#12290;&#30001;&#20110;&#25105;&#20204;&#30340;&#19968;&#20010;&#39044;&#31639;&#20998;&#37197;&#38382;&#39064;&#31867;&#20284;&#20110;&#26410;&#30693;&#26041;&#24046;&#30340;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#65292;&#22240;&#27492;&#25105;&#20204;&#35748;&#20026;&#25105;&#20204;&#30340;&#32467;&#26524;&#20855;&#26377;&#24191;&#27867;&#30340;&#20852;&#36259;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of best-arm identification (BAI) in the fixed-budget setting with heterogeneous reward variances. We propose two variance-adaptive BAI algorithms for this setting: SHVar for known reward variances and SHAdaVar for unknown reward variances. Our algorithms rely on non-uniform budget allocations among the arms where the arms with higher reward variances are pulled more often than those with lower variances. The main algorithmic novelty is in the design of SHAdaVar, which allocates budget greedily based on overestimating the unknown reward variances. We bound probabilities of misidentifying the best arms in both SHVar and SHAdaVar. Our analyses rely on novel lower bounds on the number of pulls of an arm that do not require closed-form solutions to the budget allocation problem. Since one of our budget allocation problems is analogous to the optimal experiment design with unknown variances, we believe that our results are of a broad interest. Our experiments validate ou
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#26368;&#20248;&#23545;&#25239;&#39044;&#27979;&#22120;&#30340;&#21508;&#31181;&#22522;&#26412;&#29305;&#24615;&#65292;&#24182;&#32467;&#21512;&#26032;&#30340;Rademacher&#22797;&#26434;&#24230;&#30028;&#38480;&#35777;&#26126;&#20102;&#65292;&#22312;&#27973;&#23618;&#32593;&#32476;&#19978;&#36827;&#34892;&#23545;&#25239;&#35757;&#32451;&#65292;&#37319;&#29992;&#26089;&#20572;&#21644;&#29702;&#24819;&#30340;&#26368;&#20248;&#23545;&#25163;&#65292;&#33021;&#22815;&#23454;&#29616;&#26368;&#20248;&#23545;&#25239;&#27979;&#35797;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2306.07544</link><description>&lt;p&gt;
&#20851;&#20110;&#23454;&#29616;&#26368;&#20248;&#23545;&#25239;&#27979;&#35797;&#35823;&#24046;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Achieving Optimal Adversarial Test Error. (arXiv:2306.07544v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07544
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#26368;&#20248;&#23545;&#25239;&#39044;&#27979;&#22120;&#30340;&#21508;&#31181;&#22522;&#26412;&#29305;&#24615;&#65292;&#24182;&#32467;&#21512;&#26032;&#30340;Rademacher&#22797;&#26434;&#24230;&#30028;&#38480;&#35777;&#26126;&#20102;&#65292;&#22312;&#27973;&#23618;&#32593;&#32476;&#19978;&#36827;&#34892;&#23545;&#25239;&#35757;&#32451;&#65292;&#37319;&#29992;&#26089;&#20572;&#21644;&#29702;&#24819;&#30340;&#26368;&#20248;&#23545;&#25163;&#65292;&#33021;&#22815;&#23454;&#29616;&#26368;&#20248;&#23545;&#25239;&#27979;&#35797;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#20808;&#38416;&#36848;&#20102;&#26368;&#20248;&#23545;&#25239;&#39044;&#27979;&#22120;&#30340;&#21508;&#31181;&#22522;&#26412;&#29305;&#24615;&#65306;&#26368;&#20248;&#23545;&#25239;&#20984;&#39044;&#27979;&#22120;&#30340;&#32467;&#26500;&#12289;&#23558;&#23545;&#25239;&#20984;&#25439;&#22833;&#19982;&#23545;&#25239;0-1&#25439;&#22833;&#30456;&#20851;&#32852;&#30340;&#30028;&#38480;&#20197;&#21450;&#36830;&#32493;&#39044;&#27979;&#22120;&#21487;&#20197;&#22312;&#20984;&#21644;0-1&#25439;&#22833;&#19979;&#26080;&#38480;&#25509;&#36817;&#26368;&#20248;&#23545;&#25239;&#35823;&#24046;&#12290;&#26412;&#25991;&#36824;&#23558;&#36825;&#20123;&#32467;&#26524;&#19982;&#23545;&#25239;&#35757;&#32451;&#22312;&#21021;&#22987;&#21270;&#38468;&#36817;&#30340;&#26032;Rademacher&#22797;&#26434;&#24230;&#30028;&#38480;&#30456;&#32467;&#21512;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#19968;&#33324;&#30340;&#25968;&#25454;&#20998;&#24067;&#21644;&#25200;&#21160;&#38598;&#65292;&#22312;&#27973;&#23618;&#32593;&#32476;&#19978;&#36827;&#34892;&#23545;&#25239;&#35757;&#32451;&#65292;&#37319;&#29992;&#26089;&#20572;&#21644;&#29702;&#24819;&#30340;&#26368;&#20248;&#23545;&#25163;&#65292;&#33021;&#22815;&#23454;&#29616;&#26368;&#20248;&#23545;&#25239;&#27979;&#35797;&#35823;&#24046;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#20808;&#21069;&#30340;&#29702;&#35770;&#24037;&#20316;&#21482;&#32771;&#34385;&#20102;&#29305;&#23450;&#30340;&#25968;&#25454;&#20998;&#24067;&#25110;&#20165;&#25552;&#20379;&#20102;&#35757;&#32451;&#35823;&#24046;&#30340;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We first elucidate various fundamental properties of optimal adversarial predictors: the structure of optimal adversarial convex predictors in terms of optimal adversarial zero-one predictors, bounds relating the adversarial convex loss to the adversarial zero-one loss, and the fact that continuous predictors can get arbitrarily close to the optimal adversarial error for both convex and zero-one losses. Applying these results along with new Rademacher complexity bounds for adversarial training near initialization, we prove that for general data distributions and perturbation sets, adversarial training on shallow networks with early stopping and an idealized optimal adversary is able to achieve optimal adversarial test error. By contrast, prior theoretical work either considered specialized data distributions or only provided training error guarantees.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#25512;&#33616;&#31995;&#32479;&#20013;&#28608;&#21169;&#39640;&#36136;&#37327;&#20869;&#23481;&#30340;&#31639;&#27861;&#38382;&#39064;&#65292;&#32463;&#20856;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#20250;&#28608;&#21169;&#29983;&#20135;&#32773;&#21019;&#24314;&#20302;&#36136;&#37327;&#30340;&#20869;&#23481;&#65292;&#20294;&#26412;&#25991;&#25552;&#20986;&#30340;&#19968;&#31181;&#31639;&#27861;&#36890;&#36807;&#24809;&#32602;&#20302;&#36136;&#37327;&#20869;&#23481;&#30340;&#21019;&#24314;&#32773;&#65292;&#25104;&#21151;&#22320;&#28608;&#21169;&#20102;&#29983;&#20135;&#32773;&#21019;&#36896;&#39640;&#36136;&#37327;&#30340;&#20869;&#23481;&#12290;</title><link>http://arxiv.org/abs/2306.07479</link><description>&lt;p&gt;
&#22312;&#22312;&#32447;&#25512;&#33616;&#31995;&#32479;&#20013;&#28608;&#21169;&#39640;&#36136;&#37327;&#20869;&#23481;
&lt;/p&gt;
&lt;p&gt;
Incentivizing High-Quality Content in Online Recommender Systems. (arXiv:2306.07479v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07479
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#25512;&#33616;&#31995;&#32479;&#20013;&#28608;&#21169;&#39640;&#36136;&#37327;&#20869;&#23481;&#30340;&#31639;&#27861;&#38382;&#39064;&#65292;&#32463;&#20856;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#20250;&#28608;&#21169;&#29983;&#20135;&#32773;&#21019;&#24314;&#20302;&#36136;&#37327;&#30340;&#20869;&#23481;&#65292;&#20294;&#26412;&#25991;&#25552;&#20986;&#30340;&#19968;&#31181;&#31639;&#27861;&#36890;&#36807;&#24809;&#32602;&#20302;&#36136;&#37327;&#20869;&#23481;&#30340;&#21019;&#24314;&#32773;&#65292;&#25104;&#21151;&#22320;&#28608;&#21169;&#20102;&#29983;&#20135;&#32773;&#21019;&#36896;&#39640;&#36136;&#37327;&#30340;&#20869;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#20687;TikTok&#21644;YouTube&#36825;&#26679;&#30340;&#20869;&#23481;&#25512;&#33616;&#31995;&#32479;&#65292;&#24179;&#21488;&#30340;&#20915;&#31574;&#31639;&#27861;&#22609;&#36896;&#20102;&#20869;&#23481;&#29983;&#20135;&#32773;&#30340;&#28608;&#21169;&#65292;&#21253;&#25324;&#29983;&#20135;&#32773;&#22312;&#20869;&#23481;&#36136;&#37327;&#19978;&#25237;&#20837;&#22810;&#23569;&#21162;&#21147;&#12290;&#35768;&#22810;&#24179;&#21488;&#37319;&#29992;&#22312;&#32447;&#23398;&#20064;&#65292;&#36825;&#20250;&#20135;&#29983;&#36328;&#26102;&#38388;&#30340;&#28608;&#21169;&#65292;&#22240;&#20026;&#20170;&#22825;&#29983;&#20135;&#30340;&#20869;&#23481;&#20250;&#24433;&#21709;&#26410;&#26469;&#20869;&#23481;&#30340;&#25512;&#33616;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#23398;&#20064;&#20135;&#29983;&#30340;&#28608;&#21169;&#65292;&#20998;&#26512;&#20102;&#22312;&#32435;&#20160;&#22343;&#34913;&#19979;&#29983;&#20135;&#30340;&#20869;&#23481;&#36136;&#37327;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#20687;Hedge&#21644;EXP3&#36825;&#26679;&#30340;&#32463;&#20856;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#20250;&#28608;&#21169;&#29983;&#20135;&#32773;&#21019;&#24314;&#20302;&#36136;&#37327;&#30340;&#20869;&#23481;&#12290;&#29305;&#21035;&#22320;&#65292;&#20869;&#23481;&#36136;&#37327;&#22312;&#23398;&#20064;&#29575;&#26041;&#38754;&#26377;&#19978;&#38480;&#65292;&#24182;&#19988;&#38543;&#30528;&#20856;&#22411;&#23398;&#20064;&#29575;&#36827;&#23637;&#32780;&#36235;&#36817;&#20110;&#38646;&#12290;&#22312;&#36825;&#19968;&#36127;&#38754;&#32467;&#26524;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#19981;&#21516;&#30340;&#23398;&#20064;&#31639;&#27861;&#8212;&#8212;&#22522;&#20110;&#24809;&#32602;&#21019;&#24314;&#20302;&#36136;&#37327;&#20869;&#23481;&#30340;&#29983;&#20135;&#32773;&#8212;&#8212;&#27491;&#30830;&#28608;&#21169;&#29983;&#20135;&#32773;&#21019;&#24314;&#39640;&#36136;&#37327;&#20869;&#23481;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20381;&#36182;&#20110;&#26032;&#39062;&#30340;&#31574;&#30053;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#24182;&#20811;&#26381;&#20102;&#22312;&#32452;&#21512;&#35774;&#32622;&#20013;&#24212;&#29992;&#23545;&#25239;&#24615;&#25216;&#26415;&#30340;&#25361;&#25112;&#12290;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#25104;&#21151;&#22320;&#28608;&#21169;&#29983;&#20135;&#32773;&#21019;&#24314;&#39640;&#36136;&#37327;&#20869;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
For content recommender systems such as TikTok and YouTube, the platform's decision algorithm shapes the incentives of content producers, including how much effort the content producers invest in the quality of their content. Many platforms employ online learning, which creates intertemporal incentives, since content produced today affects recommendations of future content. In this paper, we study the incentives arising from online learning, analyzing the quality of content produced at a Nash equilibrium. We show that classical online learning algorithms, such as Hedge and EXP3, unfortunately incentivize producers to create low-quality content. In particular, the quality of content is upper bounded in terms of the learning rate and approaches zero for typical learning rate schedules. Motivated by this negative result, we design a different learning algorithm -- based on punishing producers who create low-quality content -- that correctly incentivizes producers to create high-quality co
&lt;/p&gt;</description></item><item><title>&#20256;&#32479;&#30340;&#20998;&#23376;&#20960;&#20309;&#32467;&#26500;&#37319;&#26679;&#26041;&#27861;&#35745;&#31639;&#25104;&#26412;&#24456;&#39640;&#65292;&#32780;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22810;&#25968;&#19987;&#27880;&#20110;&#20998;&#24067;&#20013;&#30340;&#27169;&#24335;&#35782;&#21035;&#12290;&#26412;&#25991;&#25552;&#20986;&#30340;Von Mises&#28151;&#21512;&#20998;&#24067;&#29992;&#20110;&#29983;&#25104;&#26356;&#20934;&#30830;&#30340;&#26679;&#26412;&#12290;</title><link>http://arxiv.org/abs/2306.07472</link><description>&lt;p&gt;
Von Mises&#28151;&#21512;&#20998;&#24067;&#29992;&#20110;&#20998;&#23376;&#26500;&#35937;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Von Mises Mixture Distributions for Molecular Conformation Generation. (arXiv:2306.07472v1 [physics.chem-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07472
&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#20998;&#23376;&#20960;&#20309;&#32467;&#26500;&#37319;&#26679;&#26041;&#27861;&#35745;&#31639;&#25104;&#26412;&#24456;&#39640;&#65292;&#32780;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22810;&#25968;&#19987;&#27880;&#20110;&#20998;&#24067;&#20013;&#30340;&#27169;&#24335;&#35782;&#21035;&#12290;&#26412;&#25991;&#25552;&#20986;&#30340;Von Mises&#28151;&#21512;&#20998;&#24067;&#29992;&#20110;&#29983;&#25104;&#26356;&#20934;&#30830;&#30340;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#23376;&#32463;&#24120;&#34987;&#34920;&#31034;&#20026;&#22270;&#24418;&#65292;&#20294;&#26159;&#22522;&#30784;&#30340;&#19977;&#32500;&#20998;&#23376;&#20960;&#20309;&#32467;&#26500;&#65288;&#21407;&#23376;&#30340;&#20301;&#32622;&#65289;&#26368;&#32456;&#20915;&#23450;&#20102;&#22823;&#22810;&#25968;&#20998;&#23376;&#24615;&#36136;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#20998;&#23376;&#22312;&#24120;&#28201;&#19979;&#37117;&#19981;&#26159;&#38745;&#24577;&#30340;&#65292;&#24182;&#37319;&#21462;&#21508;&#31181;&#21508;&#26679;&#30340;&#20960;&#20309;&#32467;&#26500;&#25110;$\textit{&#26500;&#35937;}$&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#20960;&#20309;&#32467;&#26500;&#20998;&#24067;$p(x)$&#31216;&#20026;&#29627;&#23572;&#20857;&#26364;&#20998;&#24067;&#65292;&#35768;&#22810;&#20998;&#23376;&#24615;&#36136;&#37117;&#26159;&#22312;&#35813;&#20998;&#24067;&#19979;&#35745;&#31639;&#30340;&#26399;&#26395;&#12290;&#22240;&#27492;&#65292;&#20934;&#30830;&#22320;&#20174;&#29627;&#23572;&#20857;&#26364;&#20998;&#24067;&#20013;&#29983;&#25104;&#26679;&#26412;&#23545;&#20110;&#20934;&#30830;&#35745;&#31639;&#36825;&#20123;&#26399;&#26395;&#33267;&#20851;&#37325;&#35201;&#12290;&#20256;&#32479;&#30340;&#22522;&#20110;&#37319;&#26679;&#30340;&#26041;&#27861;&#35745;&#31639;&#25104;&#26412;&#24456;&#39640;&#65292;&#22823;&#37096;&#20998;&#26368;&#36817;&#30340;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26041;&#27861;&#19987;&#27880;&#20110;&#35782;&#21035;&#35813;&#20998;&#24067;&#20013;&#30340;$\textit{&#27169;&#24335;}$&#65292;&#32780;&#19981;&#26159;&#29983;&#25104;&#30495;&#27491;&#30340;$\textit{&#26679;&#26412;}$&#12290;&#29983;&#25104;&#36825;&#26679;&#30340;&#26679;&#26412;&#38656;&#35201;&#25429;&#25417;&#26500;&#35937;&#21464;&#24322;&#24615;&#65292;&#20154;&#20204;&#24191;&#27867;&#35748;&#20026;&#20998;&#23376;&#30340;&#22823;&#22810;&#25968;&#26500;&#35937;&#21464;&#24322;&#24615;&#26469;&#33258;&#20110;&#21270;&#23398;&#38190;&#30340;&#26059;&#36716;&#12290;
&lt;/p&gt;
&lt;p&gt;
Molecules are frequently represented as graphs, but the underlying 3D molecular geometry (the locations of the atoms) ultimately determines most molecular properties. However, most molecules are not static and at room temperature adopt a wide variety of geometries or $\textit{conformations}$. The resulting distribution on geometries $p(x)$ is known as the Boltzmann distribution, and many molecular properties are expectations computed under this distribution. Generating accurate samples from the Boltzmann distribution is therefore essential for computing these expectations accurately. Traditional sampling-based methods are computationally expensive, and most recent machine learning-based methods have focused on identifying $\textit{modes}$ in this distribution rather than generating true $\textit{samples}$. Generating such samples requires capturing conformational variability, and it has been widely recognized that the majority of conformational variability in molecules arises from rota
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#40657;&#30418;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22810;&#31181;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#21487;&#20197;&#22312;&#38750;&#24179;&#31283;&#29615;&#22659;&#19979;&#23454;&#29616;&#20302;&#36951;&#25022;&#29575;&#30340;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2306.07465</link><description>&lt;p&gt;
&#38754;&#21521;&#38750;&#24179;&#31283;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#30340;&#40657;&#30418;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Black-box Approach for Non-stationary Multi-agent Reinforcement Learning. (arXiv:2306.07465v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07465
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#40657;&#30418;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22810;&#31181;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#21487;&#20197;&#22312;&#38750;&#24179;&#31283;&#29615;&#22659;&#19979;&#23454;&#29616;&#20302;&#36951;&#25022;&#29575;&#30340;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38750;&#24179;&#31283;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#20013;&#23398;&#20064;&#22343;&#34913;&#30340;&#26041;&#27861;&#65292;&#24182;&#35299;&#20915;&#20102;&#21306;&#21035;&#20110;&#21333;&#26234;&#33021;&#20307;&#23398;&#20064;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#37325;&#28857;&#20851;&#27880;&#24102;&#26377;&#36172;&#24466;&#21453;&#39304;&#30340;&#28216;&#25103;&#65292;&#20854;&#20013;&#21363;&#20351;&#24453;&#27979;&#35797;&#30340;&#24046;&#36317;&#24456;&#23567;&#65292;&#27979;&#35797;&#19968;&#20010;&#22343;&#34913;&#20063;&#21487;&#33021;&#23548;&#33268;&#22823;&#37327;&#30340;&#36951;&#25022;&#65292;&#24182;&#19988;&#22312;&#38745;&#24577;&#28216;&#25103;&#20013;&#23384;&#22312;&#22810;&#20010;&#26368;&#20248;&#35299;&#65288;&#22343;&#34913;&#65289;&#20250;&#24102;&#26469;&#39069;&#22806;&#30340;&#38590;&#39064;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38556;&#30861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#40657;&#30418;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#38382;&#39064;&#65292;&#22914;&#19968;&#33324;&#21644;&#21338;&#24328;&#12289;&#28508;&#22312;&#21338;&#24328;&#21644;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#65292;&#21482;&#35201;&#22312;&#38745;&#24577;&#29615;&#22659;&#19979;&#37197;&#22791;&#36866;&#24403;&#30340;&#23398;&#20064;&#21644;&#27979;&#35797;&#31070;&#35861;&#12290;&#24403;&#38750;&#24179;&#31283;&#31243;&#24230;&#65288;&#36890;&#36807;&#24635;&#21464;&#21270;&#37327; $\Delta$ &#27979;&#37327;&#65289;&#24050;&#30693;&#26102;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#20197;&#23454;&#29616; $\widetilde{O}\left(\Delta^{1/4}T^{3/4}\right)$ &#30340;&#36951;&#25022;&#65292;&#24403; $\Delta$ &#26410;&#30693;&#26102;&#65292;&#21487;&#20197;&#23454;&#29616; $\widetilde{O}\left(\Delta^{1/5}T^{4/5}\right)$ &#30340;&#36951;&#25022;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate learning the equilibria in non-stationary multi-agent systems and address the challenges that differentiate multi-agent learning from single-agent learning. Specifically, we focus on games with bandit feedback, where testing an equilibrium can result in substantial regret even when the gap to be tested is small, and the existence of multiple optimal solutions (equilibria) in stationary games poses extra challenges. To overcome these obstacles, we propose a versatile black-box approach applicable to a broad spectrum of problems, such as general-sum games, potential games, and Markov games, when equipped with appropriate learning and testing oracles for stationary environments. Our algorithms can achieve $\widetilde{O}\left(\Delta^{1/4}T^{3/4}\right)$ regret when the degree of nonstationarity, as measured by total variation $\Delta$, is known, and $\widetilde{O}\left(\Delta^{1/5}T^{4/5}\right)$ regret when $\Delta$ is unknown, where $T$ is the number of rounds. Meanwhile, 
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#24320;&#21457;&#20102;&#19968;&#27454;&#21517;&#20026; Account Prioritizer &#30340;&#26234;&#33021;&#38144;&#21806;&#36134;&#25143;&#20248;&#20808;&#32423;&#24341;&#25806;&#65292;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#21644;&#35299;&#37322;&#31639;&#27861;&#33258;&#21160;&#21270;&#38144;&#21806;&#31807;&#20248;&#21270;&#65292;&#22312; LinkedIn Business &#20013;&#25104;&#21151;&#24102;&#26469;&#20102; +8.08% &#30340;&#32493;&#35746;&#35746;&#38405;&#22686;&#38271;&#12290;</title><link>http://arxiv.org/abs/2306.07464</link><description>&lt;p&gt;
&#35299;&#38145;&#38144;&#21806;&#22686;&#38271;&#65306;&#20855;&#26377;&#21487;&#35299;&#37322; AI &#30340;&#36134;&#25143;&#20248;&#20808;&#32423;&#24341;&#25806;
&lt;/p&gt;
&lt;p&gt;
Unlocking Sales Growth: Account Prioritization Engine with Explainable AI. (arXiv:2306.07464v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07464
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#24320;&#21457;&#20102;&#19968;&#27454;&#21517;&#20026; Account Prioritizer &#30340;&#26234;&#33021;&#38144;&#21806;&#36134;&#25143;&#20248;&#20808;&#32423;&#24341;&#25806;&#65292;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#21644;&#35299;&#37322;&#31639;&#27861;&#33258;&#21160;&#21270;&#38144;&#21806;&#31807;&#20248;&#21270;&#65292;&#22312; LinkedIn Business &#20013;&#25104;&#21151;&#24102;&#26469;&#20102; +8.08% &#30340;&#32493;&#35746;&#35746;&#38405;&#22686;&#38271;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
B2B &#38144;&#21806;&#38656;&#35201;&#26377;&#25928;&#39044;&#27979;&#23458;&#25143;&#22686;&#38271;&#65292;&#35782;&#21035;&#21319;&#32423;&#28508;&#21147;&#20197;&#21450;&#38477;&#20302;&#27969;&#22833;&#39118;&#38505;&#12290;LinkedIn &#30340;&#38144;&#21806;&#20195;&#34920;&#20256;&#32479;&#19978;&#20381;&#36182;&#30452;&#35273;&#21644;&#30862;&#29255;&#21270;&#25968;&#25454;&#20449;&#21495;&#26469;&#35780;&#20272;&#23458;&#25143;&#32489;&#25928;&#12290;&#36825;&#23548;&#33268;&#22312;&#25968;&#25454;&#29702;&#35299;&#21644;&#31574;&#30053;&#21046;&#23450;&#26041;&#38754;&#25237;&#20837;&#20102;&#22823;&#37327;&#26102;&#38388;&#65292;&#32780;&#22312;&#31215;&#26497;&#38144;&#21806;&#26041;&#38754;&#25237;&#36164;&#19981;&#36275;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#25968;&#25454;&#20135;&#21697;&#65292;&#31216;&#20026; Account Prioritizer&#65292;&#23427;&#26159;&#26234;&#33021;&#38144;&#21806;&#36134;&#25143;&#20248;&#20808;&#32423;&#24341;&#25806;&#12290;&#23427;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#25512;&#33616;&#27169;&#22411;&#21644;&#38598;&#25104;&#30340;&#36134;&#25143;&#32423;&#35299;&#37322;&#31639;&#27861;&#22312;&#38144;&#21806; CRM &#20013;&#33258;&#21160;&#21270;&#38144;&#21806;&#31807;&#20248;&#21270;&#30340;&#25163;&#21160;&#36807;&#31243;&#12290;&#19968;&#27425;&#25104;&#21151;&#30340; A/B &#27979;&#35797;&#34920;&#26126;&#65292;Account Prioritizer &#20026; LinkedIn Business &#24102;&#26469;&#20102;&#26174;&#33879;&#30340; +8.08% &#32493;&#35746;&#35746;&#38405;&#22686;&#38271;&#12290;
&lt;/p&gt;
&lt;p&gt;
B2B sales requires effective prediction of customer growth, identification of upsell potential, and mitigation of churn risks. LinkedIn sales representatives traditionally relied on intuition and fragmented data signals to assess customer performance. This resulted in significant time investment in data understanding as well as strategy formulation and under-investment in active selling. To overcome this challenge, we developed a data product called Account Prioritizer, an intelligent sales account prioritization engine. It uses machine learning recommendation models and integrated account-level explanation algorithms within the sales CRM to automate the manual process of sales book prioritization. A successful A/B test demonstrated that the Account Prioritizer generated a substantial +8.08% increase in renewal bookings for the LinkedIn Business.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Removal-Based&#29305;&#24449;&#24402;&#22240;&#30340;&#40065;&#26834;&#24615;&#65292;&#25552;&#20379;&#20102;&#20840;&#38754;&#30340;&#29702;&#35770;&#21644;&#23454;&#39564;&#20998;&#26512;&#65292;&#24182;&#35777;&#26126;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#23454;&#38469;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.07462</link><description>&lt;p&gt;
&#20851;&#20110;Removal-Based&#29305;&#24449;&#24402;&#22240;&#30340;&#40065;&#26834;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Robustness of Removal-Based Feature Attributions. (arXiv:2306.07462v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07462
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Removal-Based&#29305;&#24449;&#24402;&#22240;&#30340;&#40065;&#26834;&#24615;&#65292;&#25552;&#20379;&#20102;&#20840;&#38754;&#30340;&#29702;&#35770;&#21644;&#23454;&#39564;&#20998;&#26512;&#65292;&#24182;&#35777;&#26126;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#23454;&#38469;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#35299;&#37322;&#22522;&#20110;&#36755;&#20837;&#30340;&#22797;&#26434;&#27169;&#22411;&#65292;&#24320;&#21457;&#20102;&#35768;&#22810;&#29305;&#24449;&#24402;&#22240;&#26041;&#27861;&#26469;&#20998;&#37197;&#36755;&#20837;&#29305;&#24449;&#30340;&#37325;&#35201;&#24615;&#20998;&#25968;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#19968;&#20123;&#30740;&#31350;&#25361;&#25112;&#20102;&#29305;&#24449;&#24402;&#22240;&#30340;&#40065;&#26834;&#24615;&#65292;&#25351;&#20986;&#36825;&#20123;&#26041;&#27861;&#23545;&#36755;&#20837;&#21644;&#27169;&#22411;&#25200;&#21160;&#25935;&#24863;&#65292;&#32780;&#20854;&#20182;&#30740;&#31350;&#36890;&#36807;&#25552;&#20986;&#40065;&#26834;&#24402;&#22240;&#26041;&#27861;&#21644;&#27169;&#22411;&#20462;&#25913;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#20197;&#24448;&#30340;&#24402;&#22240;&#40065;&#26834;&#24615;&#30740;&#31350;&#20027;&#35201;&#20391;&#37325;&#20110;&#22522;&#20110;&#26799;&#24230;&#30340;&#29305;&#24449;&#24402;&#22240;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;Removal-Based&#24402;&#22240;&#26041;&#27861;&#30340;&#40065;&#26834;&#24615;&#36136;&#23578;&#26410;&#20840;&#38754;&#22320;&#24471;&#21040;&#29702;&#35299;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#23545;Removal-Based&#29305;&#24449;&#24402;&#22240;&#30340;&#40065;&#26834;&#24615;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#38416;&#36848;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23545;&#36825;&#31181;&#26041;&#27861;&#36827;&#34892;&#20102;&#32479;&#19968;&#30340;&#20998;&#26512;&#65292;&#24182;&#22312;&#36755;&#20837;&#21644;&#27169;&#22411;&#25200;&#21160;&#30340;&#24773;&#20917;&#19979;&#35777;&#26126;&#20102;&#23436;&#22909;&#21644;&#21463;&#25200;&#21160;&#30340;&#24402;&#22240;&#20043;&#38388;&#30340;&#24046;&#24322;&#30340;&#19978;&#38480;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#24182;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#23454;&#38469;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
To explain complex models based on their inputs, many feature attribution methods have been developed that assign importance scores to input features. However, some recent work challenges the robustness of feature attributions by showing that these methods are sensitive to input and model perturbations, while other work addresses this robustness issue by proposing robust attribution methods and model modifications. Nevertheless, previous work on attribution robustness has focused primarily on gradient-based feature attributions. In contrast, the robustness properties of removal-based attribution methods are not comprehensively well understood. To bridge this gap, we theoretically characterize the robustness of removal-based feature attributions. Specifically, we provide a unified analysis of such methods and prove upper bounds for the difference between intact and perturbed attributions, under settings of both input and model perturbations. Our empirical experiments on synthetic and re
&lt;/p&gt;</description></item><item><title>FIRE&#26159;&#19968;&#31181;&#29992;&#20110;&#20174;&#26641;&#38598;&#21512;&#20013;&#25552;&#21462;&#26131;&#20110;&#23457;&#26597;&#30340;&#31232;&#30095;&#35268;&#21017;&#23376;&#38598;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#21487;&#20197;&#40723;&#21169;&#22312;&#36873;&#25321;&#26102;&#34701;&#21512;&#35268;&#21017;&#65292;&#20174;&#32780;&#22686;&#24378;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#19988;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#26356;&#39640;&#30340;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.07432</link><description>&lt;p&gt;
FIRE&#65306;&#19968;&#31181;&#29992;&#20110;&#24555;&#36895;&#21487;&#35299;&#37322;&#35268;&#21017;&#25552;&#21462;&#30340;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
FIRE: An Optimization Approach for Fast Interpretable Rule Extraction. (arXiv:2306.07432v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07432
&lt;/p&gt;
&lt;p&gt;
FIRE&#26159;&#19968;&#31181;&#29992;&#20110;&#20174;&#26641;&#38598;&#21512;&#20013;&#25552;&#21462;&#26131;&#20110;&#23457;&#26597;&#30340;&#31232;&#30095;&#35268;&#21017;&#23376;&#38598;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#21487;&#20197;&#40723;&#21169;&#22312;&#36873;&#25321;&#26102;&#34701;&#21512;&#35268;&#21017;&#65292;&#20174;&#32780;&#22686;&#24378;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#19988;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#26356;&#39640;&#30340;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;FIRE&#65292;&#21363;Fast Interpretable Rule Extraction&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;&#20248;&#21270;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#20174;&#26641;&#38598;&#21512;&#20013;&#25552;&#21462;&#23569;&#37327;&#20294;&#26377;&#29992;&#30340;&#20915;&#31574;&#35268;&#21017;&#12290; FIRE&#20174;&#26641;&#38598;&#21512;&#20013;&#36873;&#25321;&#31232;&#30095;&#30340;&#20195;&#34920;&#24615;&#35268;&#21017;&#23376;&#38598;&#65292;&#36825;&#20123;&#23376;&#38598;&#26131;&#20110;&#30001;&#23454;&#36341;&#32773;&#26816;&#26597;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#22686;&#24378;&#25152;&#25552;&#21462;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;FIRE&#40723;&#21169;&#22312;&#36873;&#25321;&#26102;&#34701;&#21512;&#35268;&#21017;&#65292;&#20197;&#20415;&#35768;&#22810;&#25152;&#36873;&#20915;&#31574;&#35268;&#21017;&#20849;&#20139;&#30456;&#21516;&#30340;&#21069;&#25552;&#26465;&#20214;&#12290;&#35813;&#20248;&#21270;&#26694;&#26550;&#21033;&#29992;&#34701;&#21512;&#27491;&#21017;&#21270;&#24809;&#32602;&#26469;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#21516;&#26102;&#37319;&#29992;&#38750;&#20984;&#31232;&#30095;&#24341;&#20837;&#24809;&#32602;&#20197;&#31215;&#26497;&#36873;&#21462;&#35268;&#21017;&#12290;FIRE&#20013;&#30340;&#20248;&#21270;&#38382;&#39064;&#30001;&#20110;&#38382;&#39064;&#35268;&#27169;&#21644;&#24809;&#32602;&#30340;&#38750;&#20984;&#24615;&#32780;&#23545;&#29616;&#25104;&#27714;&#35299;&#22120;&#26500;&#25104;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#21033;&#29992;&#38382;&#39064;&#32467;&#26500;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#22522;&#20110;&#22359;&#22352;&#26631;&#19979;&#38477;&#21407;&#29702;&#30340;&#19987;&#38376;&#27714;&#35299;&#22120;&#65307; &#25105;&#20204;&#30340;&#27714;&#35299;&#22120;&#27604;&#29616;&#26377;&#27714;&#35299;&#22120;&#36816;&#34892;&#36895;&#24230;&#24555;40&#20493;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#19982;&#29616;&#26377;&#30340;&#35268;&#21017;&#25552;&#21462;&#26041;&#27861;&#30456;&#27604;&#65292;FIRE&#33021;&#22815;&#20135;&#29983;&#26356;&#20934;&#30830;&#19988;&#21487;&#35299;&#37322;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present FIRE, Fast Interpretable Rule Extraction, an optimization-based framework to extract a small but useful collection of decision rules from tree ensembles. FIRE selects sparse representative subsets of rules from tree ensembles, that are easy for a practitioner to examine. To further enhance the interpretability of the extracted model, FIRE encourages fusing rules during selection, so that many of the selected decision rules share common antecedents. The optimization framework utilizes a fusion regularization penalty to accomplish this, along with a non-convex sparsity-inducing penalty to aggressively select rules. Optimization problems in FIRE pose a challenge to off-the-shelf solvers due to problem scale and the non-convexity of the penalties. To address this, making use of problem-structure, we develop a specialized solver based on block coordinate descent principles; our solver performs up to 40x faster than existing solvers. We show in our experiments that FIRE outperform
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#24191;&#21578;&#24066;&#22330;&#19978;&#39044;&#31639;&#38480;&#21046;&#21644;&#25293;&#21334;&#38750;&#28608;&#21169;&#20860;&#23481;&#38382;&#39064;&#30340;&#20248;&#21270;&#31454;&#26631;&#31574;&#30053;&#65292;&#22312;&#28385;&#36275;&#24191;&#21578;&#20027;&#39044;&#26399;&#39044;&#31639;&#38480;&#21046;&#30340;&#21516;&#26102;&#26368;&#22823;&#21270;&#39044;&#26399;&#24635;&#25928;&#29992;&#65307;&#24182;&#30740;&#31350;&#20102;&#36328;&#24179;&#21488;&#25552;&#20132;&#31454;&#26631;&#30340;&#22312;&#32447;&#35774;&#32622;&#12290;</title><link>http://arxiv.org/abs/2306.07352</link><description>&lt;p&gt;
&#22312;&#38750; IC &#25293;&#21334;&#24191;&#21578;&#24066;&#22330;&#19978;&#30340;&#22810;&#24179;&#21488;&#39044;&#31639;&#31649;&#29702;
&lt;/p&gt;
&lt;p&gt;
Multi-Platform Budget Management in Ad Markets with Non-IC Auctions. (arXiv:2306.07352v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07352
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#24191;&#21578;&#24066;&#22330;&#19978;&#39044;&#31639;&#38480;&#21046;&#21644;&#25293;&#21334;&#38750;&#28608;&#21169;&#20860;&#23481;&#38382;&#39064;&#30340;&#20248;&#21270;&#31454;&#26631;&#31574;&#30053;&#65292;&#22312;&#28385;&#36275;&#24191;&#21578;&#20027;&#39044;&#26399;&#39044;&#31639;&#38480;&#21046;&#30340;&#21516;&#26102;&#26368;&#22823;&#21270;&#39044;&#26399;&#24635;&#25928;&#29992;&#65307;&#24182;&#30740;&#31350;&#20102;&#36328;&#24179;&#21488;&#25552;&#20132;&#31454;&#26631;&#30340;&#22312;&#32447;&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22312;&#32447;&#24191;&#21578;&#24066;&#22330;&#19978;&#65292;&#26377;&#39044;&#31639;&#38480;&#21046;&#30340;&#24191;&#21578;&#20027;&#36890;&#36807;&#22312;&#21508;&#31181;&#24179;&#21488;&#19978;&#21453;&#22797;&#31454;&#26631;&#33719;&#24471;&#24191;&#21578;&#20301;&#32622;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31574;&#30053;&#65292;&#29992;&#20110;&#22312;&#21487;&#33021;&#23384;&#22312;&#39044;&#31639;&#38480;&#21046;&#30340;&#28608;&#21169;&#20860;&#23481;&#25110;&#38750;&#28608;&#21169;&#20860;&#23481;&#24773;&#20917;&#19979;&#65292;&#20248;&#21270;&#31454;&#26631;&#19968;&#32452;&#25293;&#21334;&#21697;&#12290;&#25105;&#20204;&#30340;&#31574;&#30053;&#26368;&#22823;&#21270;&#39044;&#26399;&#22312;&#21508;&#20010;&#25293;&#21334;&#20013;&#30340;&#24635;&#25928;&#29992;&#65292;&#21516;&#26102;&#28385;&#36275;&#24191;&#21578;&#20027;&#39044;&#26399;&#30340;&#39044;&#31639;&#38480;&#21046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#24191;&#21578;&#20027;&#24517;&#39035;&#22312;&#23398;&#20064;&#20854;&#20182;&#31454;&#26631;&#32773;&#30340;&#20986;&#20215;&#24773;&#20917;&#30340;&#21516;&#26102;&#65292;&#36328;&#24179;&#21488;&#25552;&#20132;&#31454;&#26631;&#30340;&#22312;&#32447;&#35774;&#32622;&#12290;&#22312;&#20840;&#20449;&#24687;&#35774;&#32622;&#19979;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#20855;&#26377; $O(T^{3/4})$ &#30340;&#36951;&#25022;&#20540;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#30456;&#27604;&#29616;&#26377;&#30340;&#33258;&#36866;&#24212;&#27493;&#20240;&#31639;&#27861;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#24191;&#21578;&#25918;&#32622;&#25293;&#21334;&#30340;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#26356;&#20248;&#31168;&#30340;&#32047;&#31215;&#36951;&#25022;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
In online advertising markets, budget-constrained advertisers acquire ad placements through repeated bidding in auctions on various platforms. We present a strategy for bidding optimally in a set of auctions that may or may not be incentive-compatible under the presence of budget constraints. Our strategy maximizes the expected total utility across auctions while satisfying the advertiser's budget constraints in expectation. Additionally, we investigate the online setting where the advertiser must submit bids across platforms while learning about other bidders' bids over time. Our algorithm has $O(T^{3/4})$ regret under the full-information setting. Finally, we demonstrate that our algorithms have superior cumulative regret on both synthetic and real-world datasets of ad placement auctions, compared to existing adaptive pacing algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#22810;&#29289;&#29702;&#37327;&#20195;&#29702;&#24314;&#27169;&#20013;&#39640;&#32500;&#39044;&#27979;&#35757;&#32451;&#25968;&#25454;&#26377;&#38480;&#12289;&#29616;&#26377;&#20195;&#29702;&#27169;&#22411;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#39640;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21152;&#24615;&#22810;&#25351;&#26631;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;(AdMIn-GP)&#12290;&#35813;&#27169;&#22411;&#21033;&#29992;&#21442;&#25968;&#31354;&#38388;&#20869;&#20302;&#32500;&#23884;&#20837;&#30340;&#28789;&#27963;&#21152;&#24615;&#32467;&#26500;&#65292;&#20805;&#20998;&#21033;&#29992;&#31185;&#23398;&#20808;&#21069;&#30693;&#35782;&#25351;&#23548;&#12290;</title><link>http://arxiv.org/abs/2306.07299</link><description>&lt;p&gt;
&#21152;&#24615;&#22810;&#25351;&#26631;&#39640;&#26031;&#36807;&#31243;&#24314;&#27169;&#21450;&#20854;&#22312;&#22840;&#20811;&#33014;&#23376;&#31561;&#31163;&#23376;&#20307;&#22810;&#29289;&#29702;&#37327;&#20195;&#29702;&#24314;&#27169;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Additive Multi-Index Gaussian process modeling, with application to multi-physics surrogate modeling of the quark-gluon plasma. (arXiv:2306.07299v1 [nucl-th])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07299
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#22810;&#29289;&#29702;&#37327;&#20195;&#29702;&#24314;&#27169;&#20013;&#39640;&#32500;&#39044;&#27979;&#35757;&#32451;&#25968;&#25454;&#26377;&#38480;&#12289;&#29616;&#26377;&#20195;&#29702;&#27169;&#22411;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#39640;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21152;&#24615;&#22810;&#25351;&#26631;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;(AdMIn-GP)&#12290;&#35813;&#27169;&#22411;&#21033;&#29992;&#21442;&#25968;&#31354;&#38388;&#20869;&#20302;&#32500;&#23884;&#20837;&#30340;&#28789;&#27963;&#21152;&#24615;&#32467;&#26500;&#65292;&#20805;&#20998;&#21033;&#29992;&#31185;&#23398;&#20808;&#21069;&#30693;&#35782;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22840;&#20811;&#33014;&#23376;&#31561;&#31163;&#23376;&#20307;&#26159;&#19968;&#31181;&#29420;&#29305;&#30340;&#26680;&#29289;&#36136;&#30456;&#65292;&#29702;&#35770;&#19978;&#35748;&#20026;&#22312;&#23431;&#23449;&#22823;&#29190;&#28856;&#21518;&#19981;&#20037;&#23601;&#22635;&#28385;&#20102;&#23431;&#23449;&#12290;&#30740;&#31350;&#22840;&#20811;&#33014;&#23376;&#31561;&#31163;&#23376;&#20307;&#30340;&#20851;&#38190;&#25361;&#25112;&#26159;&#38656;&#35201;&#22312;&#39640;&#32500;&#21442;&#25968;&#31354;&#38388;&#20869;&#36816;&#34892;&#22797;&#26434;&#30340;&#29289;&#29702;&#27169;&#22411;&#65292;&#20197;&#23558;&#23454;&#39564;&#21487;&#35266;&#27979;&#37327;&#19982;&#29702;&#35770;&#21442;&#25968;&#36827;&#34892;&#21327;&#35843;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#27599;&#27425;&#36816;&#34892;&#37117;&#38656;&#35201;&#25968;&#21315;&#20010;CPU&#23567;&#26102;&#65292;&#22240;&#27492;&#29289;&#29702;&#23398;&#23478;&#21482;&#33021;&#36827;&#34892;&#20960;&#30334;&#27425;&#36816;&#34892;&#65292;&#20174;&#32780;&#23548;&#33268;&#39640;&#32500;&#39044;&#27979;&#30340;&#35757;&#32451;&#25968;&#25454;&#26377;&#38480;&#65292;&#29616;&#26377;&#30340;&#20195;&#29702;&#27169;&#22411;&#36890;&#24120;&#20250;&#20135;&#29983;&#39640;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21152;&#24615;&#22810;&#25351;&#26631;&#39640;&#26031;&#36807;&#31243;(AdMIn-GP)&#27169;&#22411;&#65292;&#23427;&#21033;&#29992;&#21442;&#25968;&#31354;&#38388;&#20869;&#20302;&#32500;&#23884;&#20837;&#30340;&#28789;&#27963;&#21152;&#24615;&#32467;&#26500;&#12290;&#36825;&#26159;&#30001;&#31185;&#23398;&#20808;&#21069;&#30693;&#35782;&#25351;&#23548;&#30340;&#65292;&#21363;&#22840;&#20811;&#33014;&#23376;&#31561;&#31163;&#23376;&#20307;&#21463;&#22810;&#20010;&#19981;&#21516;&#29289;&#29702;&#29616;&#35937;(&#21363;&#22810;&#29289;&#29702;&#37327;)&#30340;&#25903;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Quark-Gluon Plasma (QGP) is a unique phase of nuclear matter, theorized to have filled the Universe shortly after the Big Bang. A critical challenge in studying the QGP is that, to reconcile experimental observables with theoretical parameters, one requires many simulation runs of a complex physics model over a high-dimensional parameter space. Each run is computationally very expensive, requiring thousands of CPU hours, thus limiting physicists to only several hundred runs. Given limited training data for high-dimensional prediction, existing surrogate models often yield poor predictions with high predictive uncertainties, leading to imprecise scientific findings. To address this, we propose a new Additive Multi-Index Gaussian process (AdMIn-GP) model, which leverages a flexible additive structure on low-dimensional embeddings of the parameter space. This is guided by prior scientific knowledge that the QGP is dominated by multiple distinct physical phenomena (i.e., multiphysics),
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20869;&#26680;&#38543;&#26426;&#25237;&#24433;&#28145;&#24230;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#25968;&#25454;&#20113;&#20013;&#30340;&#22810;&#27169;&#24335;&#21644;&#38750;&#20984;&#24615;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2306.07056</link><description>&lt;p&gt;
&#20869;&#26680;&#38543;&#26426;&#25237;&#24433;&#28145;&#24230;&#29992;&#20110;&#31163;&#32676;&#28857;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Kernel Random Projection Depth for Outlier Detection. (arXiv:2306.07056v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07056
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20869;&#26680;&#38543;&#26426;&#25237;&#24433;&#28145;&#24230;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#25968;&#25454;&#20113;&#20013;&#30340;&#22810;&#27169;&#24335;&#21644;&#38750;&#20984;&#24615;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#30340;&#38543;&#26426;&#25237;&#24433;&#28145;&#24230;&#65288;RPD&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#25968;&#25454;&#20113;&#20013;&#30340;&#22810;&#27169;&#24335;&#21644;&#38750;&#20984;&#24615;&#12290;&#22312;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#26694;&#26550;&#20013;&#65292;RPD&#22312;&#20877;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#35745;&#31639;&#12290;&#20511;&#21161;&#20869;&#26680;&#20027;&#25104;&#20998;&#20998;&#26512;&#65292;&#25105;&#20204;&#26399;&#26395;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#22788;&#29702;&#19978;&#36848;&#22810;&#31181;&#27169;&#24335;&#21644;&#38750;&#20984;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20248;&#20110;RPD&#65292;&#24182;&#21487;&#19982;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#29616;&#26377;&#30340;&#26816;&#27979;&#27169;&#22411;&#30456;&#23218;&#32654;&#65292;&#20851;&#20110;&#25509;&#25910;&#25805;&#20316;&#29305;&#24449;&#26354;&#32447;&#65288;ROC&#65289;&#19979;&#30340;&#26354;&#32447;&#19979;&#38754;&#31215;&#65288;AUC&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes an extension of Random Projection Depth (RPD) to cope with multiple modalities and non-convexity on data clouds. In the framework of the proposed method, the RPD is computed in a reproducing kernel Hilbert space. With the help of kernel principal component analysis, we expect that the proposed method can cope with the above multiple modalities and non-convexity. The experimental results demonstrate that the proposed method outperforms RPD and is comparable to other existing detection models on benchmark datasets regarding Area Under the Curves (AUCs) of Receiver Operating Characteristic (ROC).
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#65292;&#20854;&#20013;iDP-SignRP&#31639;&#27861;&#22312;&#20010;&#20307;&#24046;&#20998;&#38544;&#31169;&#35774;&#32622;&#19979;&#25928;&#26524;&#26174;&#33879;&#65292;DP-SignOPORP&#31639;&#27861;&#25913;&#36827;&#20102;&#29616;&#26377;&#31639;&#27861;&#65292;DP-OPORP&#31639;&#27861;&#34920;&#29616;&#26368;&#20248;&#65292;iDP&#25552;&#20379;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#29305;&#23450;&#25968;&#25454;&#38598;&#30340;&#38544;&#31169;&#20445;&#25252;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2306.01751</link><description>&lt;p&gt;
&#38543;&#26426;&#25237;&#24433;&#21644;&#31526;&#21495;&#38543;&#26426;&#25237;&#24433;&#30340;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Differential Privacy with Random Projections and Sign Random Projections. (arXiv:2306.01751v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01751
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#65292;&#20854;&#20013;iDP-SignRP&#31639;&#27861;&#22312;&#20010;&#20307;&#24046;&#20998;&#38544;&#31169;&#35774;&#32622;&#19979;&#25928;&#26524;&#26174;&#33879;&#65292;DP-SignOPORP&#31639;&#27861;&#25913;&#36827;&#20102;&#29616;&#26377;&#31639;&#27861;&#65292;DP-OPORP&#31639;&#27861;&#34920;&#29616;&#26368;&#20248;&#65292;iDP&#25552;&#20379;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#29305;&#23450;&#25968;&#25454;&#38598;&#30340;&#38544;&#31169;&#20445;&#25252;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#22522;&#20110;&#38543;&#26426;&#25237;&#24433;&#65288;RP&#65289;&#30340;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#31639;&#27861;&#65292;&#36866;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#12289;&#25968;&#25454;&#25366;&#25496;&#21644;&#20449;&#24687;&#26816;&#32034;&#31561;&#21508;&#31181;&#24212;&#29992;&#12290;&#20854;&#20013;&#65292;&#22522;&#20110;&#31526;&#21495;&#38543;&#26426;&#25237;&#24433;&#65288;SignRP&#65289;&#30340;iDP-SignRP&#31639;&#27861;&#22312;&#20010;&#20307;&#24046;&#20998;&#38544;&#31169;&#65288;iDP&#65289;&#35774;&#32622;&#19979;&#38750;&#24120;&#26377;&#25928;&#65292;&#32780;DP-SignOPORP&#31639;&#27861;&#22312;&#26631;&#20934;DP&#35774;&#32622;&#19979;&#21033;&#29992;&#8220;&#19968;&#27425;&#25490;&#21015;+&#19968;&#27425;&#38543;&#26426;&#25237;&#24433;&#8221;&#65288;OPORP&#65289;&#26497;&#22823;&#22320;&#25913;&#36827;&#20102;&#25991;&#29486;&#20013;&#29616;&#26377;&#30340;&#31639;&#27861;&#12290;&#38500;&#19981;&#32771;&#34385;&#31526;&#21495;&#20043;&#22806;&#65292;&#22312;DP-RP&#23478;&#26063;&#20013;&#65292;DP-OPORP&#31639;&#27861;&#34920;&#29616;&#26368;&#20339;&#12290;iDP&#65288;&#20010;&#20307;&#24046;&#20998;&#38544;&#31169;&#65289;&#30340;&#27010;&#24565;&#20165;&#36866;&#29992;&#20110;&#29305;&#23450;&#30340;&#25968;&#25454;&#38598;&#12290;&#34429;&#28982;iDP&#19981;&#26159;&#20005;&#26684;&#30340;DP&#65292;&#20294;&#22312;&#26576;&#20123;&#24212;&#29992;&#20013;&#65288;&#22914;&#21521;&#23567;&#32452;&#29992;&#25143;&#21457;&#24067;&#21253;&#25324;&#23884;&#20837;&#20449;&#24687;&#25110;&#20010;&#24615;&#21270;&#25512;&#33616;&#31561;&#20869;&#23481;&#30340;&#25968;&#25454;&#38598;&#65292;&#32780;&#19981;&#27844;&#38706;&#19981;&#23646;&#20110;&#35813;&#32452;&#30340;&#20010;&#20154;&#30340;&#20219;&#20309;&#31169;&#20154;&#20449;&#24687;&#65289;&#21487;&#33021;&#24456;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we develop a series of differential privacy (DP) algorithms from a family of random projections (RP), for general applications in machine learning, data mining, and information retrieval. Among the presented algorithms, \textbf{iDP-SignRP} is remarkably effective under the setting of ``individual differential privacy'' (iDP), based on sign random projections (SignRP). Also, \textbf{DP-SignOPORP} considerably improves existing algorithms in the literature under the standard DP setting, using ``one permutation + one random projection'' (OPORP), where OPORP is a variant of the celebrated count-sketch method with fixed-length binning and normalization. Without taking signs, among the DP-RP family, \textbf{DP-OPORP} achieves the best performance.  The concept of iDP (individual differential privacy) is defined only on a particular dataset of interest. While iDP is not strictly DP, iDP might be useful in certain applications, such as releasing a dataset (including sharing embe
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#31163;&#25955;&#20998;&#24067;&#26679;&#26412;&#23545;&#20110;&#31867;&#21035;&#38388;&#30340;&#22343;&#21248;&#20998;&#24067;&#25311;&#21512;&#38382;&#39064;&#19979;&#30340;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;&#65292;&#22312;&#32570;&#23569;&#29699;&#24418;&#26367;&#20195;&#26041;&#26696;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20102;&#35752;&#35770;&#65292;&#36890;&#36807;&#31163;&#25955;&#30452;&#26041;&#22270;&#36827;&#34892;&#26816;&#39564;&#65292;&#33719;&#24471;&#20102;&#19968;&#31181;&#20855;&#26377;&#31934;&#30830;&#21051;&#30011;&#30340;&#26816;&#39564;&#26041;&#27861;&#65292;&#24182;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#20102;&#26174;&#33879;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.18111</link><description>&lt;p&gt;
&#22312;&#32570;&#23569;&#29699;&#24418;&#26367;&#20195;&#26041;&#26696;&#19979;&#27979;&#35797;&#31163;&#25955;&#20998;&#24067;&#30452;&#26041;&#22270;&#22343;&#21248;&#24615;&#30340;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;
The minimax risk in testing the histogram of discrete distributions for uniformity under missing ball alternatives. (arXiv:2305.18111v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18111
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#31163;&#25955;&#20998;&#24067;&#26679;&#26412;&#23545;&#20110;&#31867;&#21035;&#38388;&#30340;&#22343;&#21248;&#20998;&#24067;&#25311;&#21512;&#38382;&#39064;&#19979;&#30340;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;&#65292;&#22312;&#32570;&#23569;&#29699;&#24418;&#26367;&#20195;&#26041;&#26696;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20102;&#35752;&#35770;&#65292;&#36890;&#36807;&#31163;&#25955;&#30452;&#26041;&#22270;&#36827;&#34892;&#26816;&#39564;&#65292;&#33719;&#24471;&#20102;&#19968;&#31181;&#20855;&#26377;&#31934;&#30830;&#21051;&#30011;&#30340;&#26816;&#39564;&#26041;&#27861;&#65292;&#24182;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#20102;&#26174;&#33879;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#27979;&#35797;&#19968;&#20010;&#26469;&#33258;&#35768;&#22810;&#31867;&#21035;&#30340;&#31163;&#25955;&#26679;&#26412;&#23545;&#20110;&#31867;&#21035;&#38388;&#30340;&#22343;&#21248;&#20998;&#24067;&#25311;&#21512;&#30340;&#38382;&#39064;&#12290;&#20316;&#20026;&#21478;&#19968;&#31867;&#26367;&#20195;&#20551;&#35774;&#65292;&#25105;&#20204;&#32771;&#34385;&#21435;&#38500;&#21322;&#24452;&#20026;$\epsilon$&#30340;$\ell_p$&#29699;&#24418;&#26367;&#20195;&#26041;&#26696;&#65292;&#20854;&#20013;$p\leq 2$&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#22522;&#20110;&#30452;&#26041;&#22270;&#65288;&#32570;&#22833;&#31867;&#21035;&#12289;&#21333;&#20363;&#12289;&#30896;&#25758;&#30340;&#25968;&#37327;&#65289;&#30340;&#26816;&#39564;&#22312;&#26679;&#26412;&#25968;&#21644;&#32500;&#25968;&#36235;&#21521;&#26080;&#31351;&#22823;&#65292;$\epsilon\to0$&#26102;&#65292;&#28176;&#36827;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;&#30340;&#19968;&#20010;&#31934;&#30830;&#21051;&#30011;&#12290;&#20363;&#22914;&#65292;&#24403;$p=1$&#19988;&#26399;&#26395;&#26679;&#26412;&#25968;$n$&#19982;&#31867;&#21035;&#25968;$N$&#30340;&#27604;&#20540;&#24456;&#23567;&#65288;&#20063;&#31216;&#20026;&#8220;&#27425;&#32447;&#24615;&#8221;&#21306;&#22495;&#65289;&#26102;&#65292;&#28176;&#36827;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;$R^*_\epsilon$&#36235;&#36817;&#20110;$2\bar{\Phi}\left(n\epsilon^2/\sqrt{8N}\right)$&#65292;&#20854;&#20013;$\bar{\Phi}(x)$&#26159;&#27491;&#24577;&#27531;&#23384;&#20989;&#25968;&#12290;&#22312;&#19968;&#31995;&#21015;&#38382;&#39064;&#21442;&#25968;&#33539;&#22260;&#20869;&#30340;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;&#36825;&#20010;&#20272;&#35745;&#22312;&#26377;&#38480;&#26679;&#26412;&#20013;&#24456;&#31934;&#30830;&#65292;&#24182;&#19988;&#25105;&#20204;&#30340;&#26816;&#39564;&#26174;&#33879;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of testing the fit of a discrete sample of items from many categories to the uniform distribution over the categories. As a class of alternative hypotheses, we consider the removal of an $\ell_p$ ball of radius $\epsilon$ around the uniform rate sequence for $p \leq 2$. We deliver a sharp characterization of the asymptotic minimax risk when $\epsilon \to 0$ as the number of samples and number of dimensions go to infinity, for testing based on the occurrences' histogram (number of absent categories, singletons, collisions, ...). For example, for $p=1$ and in the limit of a small expected number of samples $n$ compared to the number of categories $N$ (aka "sub-linear" regime), the minimax risk $R^*_\epsilon$ asymptotes to $2 \bar{\Phi}\left(n \epsilon^2/\sqrt{8N}\right) $, with $\bar{\Phi}(x)$ the normal survival function. Empirical studies over a range of problem parameters show that this estimate is accurate in finite samples, and that our test is significantly 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;DIVA&#31639;&#27861;&#65292;&#19968;&#20010;&#22522;&#20110;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#30340;&#22686;&#37327;&#28145;&#24230;&#32858;&#31867;&#26694;&#26550;&#65292;&#21033;&#29992;&#26080;&#38480;&#28151;&#21512;&#39640;&#26031;&#20316;&#20026;&#20808;&#39564;&#65292;&#24182;&#21033;&#29992;&#19968;&#31181;&#35760;&#24518;&#21270;&#30340;&#22312;&#32447;&#21464;&#20998;&#25512;&#29702;&#26041;&#27861;&#23454;&#29616;&#31751;&#30340;&#21160;&#24577;&#36866;&#24212;&#31227;&#21160;&#65292;&#32780;&#19981;&#38656;&#35201;&#20808;&#30693;&#36947;&#29305;&#24449;&#30340;&#25968;&#37327;&#12290;&#35813;&#31639;&#27861;&#34920;&#29616;&#20248;&#36234;&#65292;&#29305;&#21035;&#26159;&#22312;&#22686;&#37327;&#29305;&#24449;&#30340;&#24773;&#20917;&#19979;&#12290;</title><link>http://arxiv.org/abs/2305.14067</link><description>&lt;p&gt;
DIVA&#65306;&#22522;&#20110;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#30340;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#22686;&#37327;&#28145;&#24230;&#32858;&#31867;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
DIVA: A Dirichlet Process Based Incremental Deep Clustering Algorithm via Variational Auto-Encoder. (arXiv:2305.14067v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14067
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;DIVA&#31639;&#27861;&#65292;&#19968;&#20010;&#22522;&#20110;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#30340;&#22686;&#37327;&#28145;&#24230;&#32858;&#31867;&#26694;&#26550;&#65292;&#21033;&#29992;&#26080;&#38480;&#28151;&#21512;&#39640;&#26031;&#20316;&#20026;&#20808;&#39564;&#65292;&#24182;&#21033;&#29992;&#19968;&#31181;&#35760;&#24518;&#21270;&#30340;&#22312;&#32447;&#21464;&#20998;&#25512;&#29702;&#26041;&#27861;&#23454;&#29616;&#31751;&#30340;&#21160;&#24577;&#36866;&#24212;&#31227;&#21160;&#65292;&#32780;&#19981;&#38656;&#35201;&#20808;&#30693;&#36947;&#29305;&#24449;&#30340;&#25968;&#37327;&#12290;&#35813;&#31639;&#27861;&#34920;&#29616;&#20248;&#36234;&#65292;&#29305;&#21035;&#26159;&#22312;&#22686;&#37327;&#29305;&#24449;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#29983;&#25104;&#27169;&#22411;&#30340;&#28145;&#24230;&#32858;&#31867;&#26694;&#26550;&#22312;&#20998;&#31867;&#22797;&#26434;&#25968;&#25454;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#22788;&#29702;&#21160;&#24577;&#21644;&#22797;&#26434;&#29305;&#24449;&#26041;&#38754;&#21463;&#21040;&#38480;&#21046;&#65292;&#22240;&#20026;&#23427;&#20204;&#38656;&#35201;&#20808;&#30693;&#36947;&#31751;&#30340;&#25968;&#37327;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#21442;&#25968;&#28145;&#24230;&#32858;&#31867;&#26694;&#26550;&#65292;&#37319;&#29992;&#26080;&#38480;&#28151;&#21512;&#39640;&#26031;&#20316;&#20026;&#20808;&#39564;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21033;&#29992;&#19968;&#31181;&#35760;&#24518;&#21270;&#30340;&#22312;&#32447;&#21464;&#20998;&#25512;&#29702;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#31751;&#30340;&#8220;&#20986;&#29983;&#8221;&#21644;&#8220;&#21512;&#24182;&#8221;&#31227;&#21160;&#65292;&#20351;&#25105;&#20204;&#30340;&#26694;&#26550;&#33021;&#22815;&#20197;&#8220;&#21160;&#24577;&#36866;&#24212;&#8221;&#30340;&#26041;&#24335;&#32858;&#31867;&#25968;&#25454;&#65292;&#32780;&#19981;&#38656;&#35201;&#20808;&#30693;&#36947;&#29305;&#24449;&#30340;&#25968;&#37327;&#12290;&#25105;&#20204;&#25226;&#35813;&#26694;&#26550;&#21629;&#21517;&#20026;DIVA&#65292;&#21363;&#22522;&#20110;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#30340;&#22686;&#37327;&#28145;&#24230;&#32858;&#31867;&#26694;&#26550;&#30340;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#22312;&#20998;&#31867;&#20855;&#26377;&#21160;&#24577;&#21464;&#21270;&#29305;&#24449;&#30340;&#22797;&#26434;&#25968;&#25454;&#26041;&#38754;&#34920;&#29616;&#20248;&#36234;&#65292;&#29305;&#21035;&#26159;&#22312;&#22686;&#37327;&#29305;&#24449;&#30340;&#24773;&#20917;&#19979;&#65292;&#36229;&#36807;&#20102;&#26368;&#20808;&#36827;&#30340;&#22522;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative model-based deep clustering frameworks excel in classifying complex data, but are limited in handling dynamic and complex features because they require prior knowledge of the number of clusters. In this paper, we propose a nonparametric deep clustering framework that employs an infinite mixture of Gaussians as a prior. Our framework utilizes a memoized online variational inference method that enables the "birth" and "merge" moves of clusters, allowing our framework to cluster data in a "dynamic-adaptive" manner, without requiring prior knowledge of the number of features. We name the framework as DIVA, a Dirichlet Process-based Incremental deep clustering framework via Variational Auto-Encoder. Our framework, which outperforms state-of-the-art baselines, exhibits superior performance in classifying complex data with dynamically changing features, particularly in the case of incremental features.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26680;&#30697;&#27861;&#20272;&#35745;&#22120;&#65292;&#31216;&#20026;KMM&#65292;&#20854;&#29992;&#20110;&#36229;&#36234;&#25968;&#25454;&#37325;&#26032;&#21152;&#26435;&#30340;&#30697;&#26041;&#27861;&#27169;&#22411;&#65292;&#35299;&#38500;&#20102;&#20851;&#20110;&#20351;&#29992; $\varphi$-&#25955;&#24230;&#30456;&#20851;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2305.10898</link><description>&lt;p&gt;
&#36229;&#36234;&#25968;&#25454;&#37325;&#26032;&#21152;&#26435;&#65306;&#26680;&#30697;&#27861;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Estimation Beyond Data Reweighting: Kernel Method of Moments. (arXiv:2305.10898v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10898
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26680;&#30697;&#27861;&#20272;&#35745;&#22120;&#65292;&#31216;&#20026;KMM&#65292;&#20854;&#29992;&#20110;&#36229;&#36234;&#25968;&#25454;&#37325;&#26032;&#21152;&#26435;&#30340;&#30697;&#26041;&#27861;&#27169;&#22411;&#65292;&#35299;&#38500;&#20102;&#20851;&#20110;&#20351;&#29992; $\varphi$-&#25955;&#24230;&#30456;&#20851;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#19982;&#32479;&#35745;&#23398;&#31561;&#22810;&#20010;&#39046;&#22495;&#20013;&#37117;&#20250;&#20986;&#29616;&#30697;&#32422;&#26463;&#21644;&#26465;&#20214;&#23545;&#24212;&#65292;&#20854;&#20013;&#65292;&#24191;&#20041;&#30697;&#27861;&#65288;GMM&#65289;&#20316;&#20026;&#19968;&#20010;&#20272;&#35745;&#27169;&#22411;&#24050;&#32463;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#24448;&#24448;&#30001;&#20110;&#20351;&#29992; $\varphi$-&#25955;&#24230;&#30340;&#30456;&#20851;&#38480;&#21046;&#23558;&#20505;&#36873;&#20998;&#24067;&#38480;&#21046;&#20026;&#25968;&#25454;&#26679;&#26412;&#30340;&#37325;&#26032;&#21152;&#26435;&#12290;&#32780;&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30697;&#20272;&#35745;&#26041;&#27861;&#8212;&#8212;&#22522;&#20110;&#26368;&#22823;&#22343;&#20540;&#20559;&#24046;&#30340;&#32463;&#39564;&#20284;&#28982;&#20272;&#35745;&#22120;&#65292;&#21363;&#26680;&#30697;&#27861;(KMM)&#65292;&#20854;&#23454;&#29616;&#36229;&#36234;&#20102;&#23545;&#25968;&#25454;&#30340;&#37325;&#26032;&#21152;&#26435;&#12290;
&lt;/p&gt;
&lt;p&gt;
Moment restrictions and their conditional counterparts emerge in many areas of machine learning and statistics ranging from causal inference to reinforcement learning. Estimators for these tasks, generally called methods of moments, include the prominent generalized method of moments (GMM) which has recently gained attention in causal inference. GMM is a special case of the broader family of empirical likelihood estimators which are based on approximating a population distribution by means of minimizing a $\varphi$-divergence to an empirical distribution. However, the use of $\varphi$-divergences effectively limits the candidate distributions to reweightings of the data samples. We lift this long-standing limitation and provide a method of moments that goes beyond data reweighting. This is achieved by defining an empirical likelihood estimator based on maximum mean discrepancy which we term the kernel method of moments (KMM). We provide a variant of our estimator for conditional moment
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21457;&#29616;&#65292;&#20855;&#26377;&#23545;&#25968;S&#22411;&#28608;&#27963;&#20989;&#25968;&#30340;&#20219;&#24847;&#28145;&#24230;&#30340;&#19968;&#32500;&#31070;&#32463;&#32593;&#32476;&#26368;&#22810;&#21482;&#26377;&#19977;&#20010;&#19981;&#21160;&#28857;&#65292;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#24212;&#29992;&#21644;&#29702;&#35770;&#20043;&#38388;&#26500;&#24314;&#20102;&#19968;&#20010;&#24517;&#35201;&#30340;&#26725;&#26753;&#12290;</title><link>http://arxiv.org/abs/2303.12814</link><description>&lt;p&gt;
&#20219;&#24847;&#28145;&#24230;&#30340;&#19968;&#32500;&#31070;&#32463;&#32593;&#32476;&#30340;&#19981;&#21160;&#28857;
&lt;/p&gt;
&lt;p&gt;
Fixed points of arbitrarily deep 1-dimensional neural networks. (arXiv:2303.12814v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12814
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21457;&#29616;&#65292;&#20855;&#26377;&#23545;&#25968;S&#22411;&#28608;&#27963;&#20989;&#25968;&#30340;&#20219;&#24847;&#28145;&#24230;&#30340;&#19968;&#32500;&#31070;&#32463;&#32593;&#32476;&#26368;&#22810;&#21482;&#26377;&#19977;&#20010;&#19981;&#21160;&#28857;&#65292;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#24212;&#29992;&#21644;&#29702;&#35770;&#20043;&#38388;&#26500;&#24314;&#20102;&#19968;&#20010;&#24517;&#35201;&#30340;&#26725;&#26753;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#22312;$\mathbb{R}$&#19978;&#20855;&#26377;&#21512;&#25104;&#24615;&#19988;&#21253;&#21547;&#23545;&#25968;S&#22411;&#20989;&#25968;&#30340;&#26032;&#20989;&#25968;&#31867;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#20010;&#31867;&#26469;&#35777;&#26126;&#20855;&#26377;&#23545;&#25968;S&#22411;&#28608;&#27963;&#20989;&#25968;&#30340;&#20219;&#24847;&#28145;&#24230;&#30340;&#19968;&#32500;&#31070;&#32463;&#32593;&#32476;&#26368;&#22810;&#21482;&#26377;&#19977;&#20010;&#19981;&#21160;&#28857;&#12290;&#34429;&#28982;&#36825;&#26679;&#30340;&#31070;&#32463;&#32593;&#32476;&#36828;&#31163;&#23454;&#38469;&#24212;&#29992;&#65292;&#20294;&#25105;&#20204;&#33021;&#22815;&#23436;&#20840;&#29702;&#35299;&#23427;&#20204;&#30340;&#19981;&#21160;&#28857;&#65292;&#24182;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#24212;&#29992;&#21644;&#29702;&#35770;&#20043;&#38388;&#26500;&#24314;&#20102;&#19968;&#20010;&#24517;&#35201;&#30340;&#26725;&#26753;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce a new class of functions on $\mathbb{R}$ that is closed under composition, and contains the logistic sigmoid function. We use this class to show that any 1-dimensional neural network of arbitrary depth with logistic sigmoid activation functions has at most three fixed points. While such neural networks are far from real world applications, we are able to completely understand their fixed points, providing a foundation to the much needed connection between application and theory of deep neural networks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#25289;&#26222;&#25289;&#26031;&#20272;&#35745;&#22120;&#30340;&#38598;&#20013;&#30028;&#38480;&#65292;&#35752;&#35770;&#20102;&#22312;KL&#25955;&#24230;&#20013;&#31163;&#25955;&#20998;&#24067;&#20272;&#35745;&#30340;&#38382;&#39064;&#65292;&#24182;&#23454;&#29616;&#20102;&#26356;&#20248;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2302.06869</link><description>&lt;p&gt;
KL&#25955;&#24230;&#20013;&#31163;&#25955;&#20998;&#24067;&#20272;&#35745;&#30340;&#38598;&#20013;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Concentration Bounds for Discrete Distribution Estimation in KL Divergence. (arXiv:2302.06869v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06869
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#25289;&#26222;&#25289;&#26031;&#20272;&#35745;&#22120;&#30340;&#38598;&#20013;&#30028;&#38480;&#65292;&#35752;&#35770;&#20102;&#22312;KL&#25955;&#24230;&#20013;&#31163;&#25955;&#20998;&#24067;&#20272;&#35745;&#30340;&#38382;&#39064;&#65292;&#24182;&#23454;&#29616;&#20102;&#26356;&#20248;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;KL&#25955;&#24230;&#20013;&#31163;&#25955;&#20998;&#24067;&#20272;&#35745;&#30340;&#38382;&#39064;&#65292;&#24182;&#20026;&#25289;&#26222;&#25289;&#26031;&#20272;&#35745;&#22120;&#25552;&#20379;&#20102;&#38598;&#20013;&#30028;&#38480;&#12290;&#24403;$n \geq k$&#26102;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20174;&#24179;&#22343;&#20540;&#20559;&#24046;&#30340;&#32553;&#25918;&#20026;$\sqrt{k} / n$&#65292;&#36825;&#27604;&#20808;&#21069;&#26368;&#22909;&#30340;&#32467;&#26524;$k/n$&#26377;&#25152;&#25913;&#36827;&#12290;&#25105;&#20204;&#36824;&#24314;&#31435;&#20102;&#19968;&#20010;&#21305;&#37197;&#30340;&#19979;&#30028;&#65292;&#34920;&#26126;&#25105;&#20204;&#30340;&#30028;&#38480;&#22312;&#22810;&#39033;&#24335;&#23545;&#25968;&#22240;&#23376;&#19978;&#26159;&#32039;&#23494;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of discrete distribution estimation in KL divergence and provide concentration bounds for the Laplace estimator. We show that the deviation from mean scales as $\sqrt{k}/n$ when $n \ge k$, improving upon the best prior result of $k/n$. We also establish a matching lower bound that shows that our bounds are tight up to polylogarithmic factors.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Density-Softmax&#30340;&#24555;&#36895;&#30830;&#23450;&#24615;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#23494;&#24230;&#20989;&#25968;&#19982;softmax&#32467;&#21512;&#26469;&#25552;&#39640;&#20998;&#24067;&#21464;&#21270;&#19979;&#30340;&#26657;&#20934;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#20855;&#26377;&#36739;&#39640;&#30340;&#25928;&#29575;&#21644;&#21487;&#34892;&#24615;</title><link>http://arxiv.org/abs/2302.06495</link><description>&lt;p&gt;
Density-Softmax: &#22312;&#20998;&#24067;&#21464;&#21270;&#19979;&#25552;&#39640;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#24555;&#36895;&#30830;&#23450;&#24615;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Density-Softmax: Scalable and Calibrated Uncertainty Estimation under Distribution Shifts. (arXiv:2302.06495v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06495
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Density-Softmax&#30340;&#24555;&#36895;&#30830;&#23450;&#24615;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#23494;&#24230;&#20989;&#25968;&#19982;softmax&#32467;&#21512;&#26469;&#25552;&#39640;&#20998;&#24067;&#21464;&#21270;&#19979;&#30340;&#26657;&#20934;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#20855;&#26377;&#36739;&#39640;&#30340;&#25928;&#29575;&#21644;&#21487;&#34892;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24120;&#35265;&#30830;&#23450;&#24615;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22312;&#20998;&#24067;&#21464;&#21270;&#19979;&#23384;&#22312;&#36739;&#22823;&#30340;&#36807;&#24230;&#33258;&#20449;&#38382;&#39064;&#65292;&#27010;&#29575;&#26041;&#27861;&#34429;&#28982;&#33021;&#32531;&#35299;&#27492;&#38382;&#39064;&#20294;&#35745;&#31639;&#25928;&#29575;&#19981;&#20339;&#12290;&#26412;&#25991;&#25552;&#20986;Density-Softmax&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#23494;&#24230;&#20989;&#25968;&#19982;softmax&#32467;&#21512;&#65292;&#20197;&#24555;&#36895;&#19988;&#36731;&#37327;&#32423;&#30340;&#26041;&#24335;&#25552;&#39640;&#26657;&#20934;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#28508;&#22312;&#34920;&#31034;&#30340;&#20284;&#28982;&#20540;&#65292;&#22312;&#27979;&#35797;&#26102;&#22312;&#36828;&#31163;&#35757;&#32451;&#26679;&#26412;&#26102;&#22686;&#21152;&#19981;&#30830;&#23450;&#24615;&#12290;&#22312;&#29702;&#35770;&#35777;&#26126;&#21644;&#23454;&#39564;&#19978;&#65292;Density-Softmax&#35777;&#26126;&#20102;&#22312;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#24773;&#20917;&#19979;&#21487;&#20197;&#23454;&#29616;&#39640;&#36136;&#37327;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#20174;&#32780;&#20943;&#23569;&#20102;&#26631;&#20934;softmax&#30340;&#36807;&#24230;&#33258;&#20449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Prevalent deterministic deep-learning models suffer from significant over-confidence under distribution shifts. Probabilistic approaches can reduce this problem but struggle with computational efficiency. In this paper, we propose Density-Softmax, a fast and lightweight deterministic method to improve calibrated uncertainty estimation via a combination of density function with the softmax layer. By using the latent representation's likelihood value, our approach produces more uncertain predictions when test samples are distant from the training samples. Theoretically, we show that Density-Softmax can produce high-quality uncertainty estimation with neural networks, as it is the solution of minimax uncertainty risk and is distance-aware, thus reducing the over-confidence of the standard softmax. Empirically, our method enjoys similar computational efficiency as a single forward pass deterministic with standard softmax on the shifted toy, vision, and language datasets across modern deep-
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39118;&#38505;&#25511;&#21046;&#39044;&#27979;&#38598;&#65288;RCPS&#65289;&#31243;&#24207;&#30340;&#25512;&#24191;&#65292;&#31216;&#20026;$K$-RCPS&#65292;&#23427;&#20801;&#35768;&#20026;&#20219;&#20309;&#25193;&#25955;&#27169;&#22411;&#25552;&#20379;&#36880;&#20010;&#26657;&#20934;&#30340;&#26410;&#26469;&#26679;&#26412;&#38388;&#38548;&#65292;&#24182;&#25511;&#21046;&#30456;&#23545;&#20110;&#22522;&#20934;&#30495;&#23454;&#22270;&#20687;&#30340;&#26576;&#31181;&#39118;&#38505;&#27010;&#24565;&#65292;&#21516;&#26102;&#20445;&#25345;&#26368;&#23567;&#24179;&#22343;&#21306;&#38388;&#38271;&#24230;&#12290;</title><link>http://arxiv.org/abs/2302.03791</link><description>&lt;p&gt;
&#22914;&#20309;&#20449;&#20219;&#24744;&#30340;&#25193;&#25955;&#27169;&#22411;&#65306;&#19968;&#31181;&#20984;&#20248;&#21270;&#26041;&#27861;&#24212;&#23545;&#31526;&#21512;&#39118;&#38505;&#25511;&#21046;&#30340;&#22240;&#24335;&#20998;&#35299;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
How to Trust Your Diffusion Model: A Convex Optimization Approach to Conformal Risk Control. (arXiv:2302.03791v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03791
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39118;&#38505;&#25511;&#21046;&#39044;&#27979;&#38598;&#65288;RCPS&#65289;&#31243;&#24207;&#30340;&#25512;&#24191;&#65292;&#31216;&#20026;$K$-RCPS&#65292;&#23427;&#20801;&#35768;&#20026;&#20219;&#20309;&#25193;&#25955;&#27169;&#22411;&#25552;&#20379;&#36880;&#20010;&#26657;&#20934;&#30340;&#26410;&#26469;&#26679;&#26412;&#38388;&#38548;&#65292;&#24182;&#25511;&#21046;&#30456;&#23545;&#20110;&#22522;&#20934;&#30495;&#23454;&#22270;&#20687;&#30340;&#26576;&#31181;&#39118;&#38505;&#27010;&#24565;&#65292;&#21516;&#26102;&#20445;&#25345;&#26368;&#23567;&#24179;&#22343;&#21306;&#38388;&#38271;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#65292;&#31616;&#31216;&#25193;&#25955;&#27169;&#22411;&#65292;&#22312;&#22810;&#20010;&#37325;&#35201;&#39046;&#22495;&#21644;&#20219;&#21153;&#20013;&#32487;&#32493;&#22686;&#38271;&#12290;&#23613;&#31649;&#23427;&#20204;&#25552;&#20379;&#20102;&#26469;&#33258;&#32463;&#39564;&#20998;&#24067;&#30340;&#39640;&#36136;&#37327;&#21644;&#22810;&#26679;&#21270;&#26679;&#26412;&#65292;&#20294;&#22312;&#20854;&#36127;&#36131;&#20219;&#22320;&#29992;&#20110;&#20851;&#38190;&#22330;&#26223;&#26041;&#38754;&#30340;&#21487;&#38752;&#24615;&#21644;&#21487;&#20449;&#24230;&#20173;&#23384;&#22312;&#37325;&#35201;&#38382;&#39064;&#12290;&#25910;&#25947;&#39044;&#27979;&#26159;&#19968;&#31181;&#29616;&#20195;&#24037;&#20855;&#65292;&#29992;&#20110;&#20026;&#20219;&#20309;&#40657;&#30418;&#23376;&#39044;&#27979;&#22120;&#26500;&#24314;&#26377;&#38480;&#26679;&#26412;&#12289;&#20998;&#24067;&#33258;&#30001;&#30340;&#19981;&#30830;&#23450;&#24615;&#20445;&#35777;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#22270;&#20687;&#21040;&#22270;&#20687;&#22238;&#24402;&#20219;&#21153;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#39118;&#38505;&#25511;&#21046;&#39044;&#27979;&#38598;&#65288;RCPS&#65289;&#31243;&#24207;&#30340;&#25512;&#24191;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;$K$-RCPS&#65292;&#23427;&#20801;&#35768;$(i)$&#20026;&#20219;&#20309;&#25193;&#25955;&#27169;&#22411;&#25552;&#20379;&#36880;&#20010;&#26657;&#20934;&#30340;&#26410;&#26469;&#26679;&#26412;&#38388;&#38548;&#65292;&#24182;$(ii)$&#25511;&#21046;&#30456;&#23545;&#20110;&#22522;&#20934;&#30495;&#23454;&#22270;&#20687;&#30340;&#26576;&#31181;&#39118;&#38505;&#27010;&#24565;&#65292;&#21516;&#26102;&#20445;&#25345;&#26368;&#23567;&#24179;&#22343;&#21306;&#38388;&#38271;&#24230;&#12290;&#19982;&#29616;&#26377;&#30340;&#25910;&#25947;&#39118;&#38505;&#25511;&#21046;&#36807;&#31243;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#36807;&#31243;&#20381;&#38752;&#19968;&#31181;&#26032;&#22411;&#30340;&#20984;&#20248;&#21270;&#20844;&#24335;&#65292;&#20351;&#20854;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#21644;&#26131;&#20110;&#23454;&#29616;&#30340;&#29305;&#28857;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#22270;&#20687;&#21040;&#22270;&#20687;&#22238;&#24402;&#20219;&#21153;&#19978;&#20351;&#29992;&#24471;&#20998;&#20026;&#22522;&#30784;&#30340;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#26469;&#35828;&#26126;&#25105;&#20204;&#30340;&#31243;&#24207;&#30340;&#26377;&#25928;&#24615;&#65292;&#23637;&#31034;&#20102;&#39640;&#24230;&#26657;&#20934;&#21644;&#33391;&#22909;&#25511;&#21046;&#30340;&#39044;&#27979;&#38388;&#38548;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score-based generative modeling, informally referred to as diffusion models, continue to grow in popularity across several important domains and tasks. While they provide high-quality and diverse samples from empirical distributions, important questions remain on the reliability and trustworthiness of these sampling procedures for their responsible use in critical scenarios. Conformal prediction is a modern tool to construct finite-sample, distribution-free uncertainty guarantees for any black-box predictor. In this work, we focus on image-to-image regression tasks and we present a generalization of the Risk-Controlling Prediction Sets (RCPS) procedure, that we term $K$-RCPS, which allows to $(i)$ provide entrywise calibrated intervals for future samples of any diffusion model, and $(ii)$ control a certain notion of risk with respect to a ground truth image with minimal mean interval length. Differently from existing conformal risk control procedures, ours relies on a novel convex opti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#32479;&#35745;&#29289;&#29702;&#21644;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#20998;&#26512;&#24037;&#20855;&#65292;&#31934;&#30830;&#22320;&#34920;&#24449;&#20102;&#31616;&#21333;&#22270;&#21367;&#31215;&#32593;&#32476;&#22312;&#32972;&#26223;&#38543;&#26426;&#22359;&#27169;&#22411;&#19978;&#30340;&#27867;&#21270;&#65292;&#25552;&#20986;&#20102;&#21516;&#36136;&#24615;&#22312;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#27867;&#21270;&#20013;&#30340;&#35843;&#21046;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2212.13069</link><description>&lt;p&gt;
&#21516;&#36136;&#24615;&#22312;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#21452;&#19979;&#38477;&#27867;&#21270;&#20013;&#30340;&#35843;&#21046;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Homophily modulates double descent generalization in graph convolution networks. (arXiv:2212.13069v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.13069
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#32479;&#35745;&#29289;&#29702;&#21644;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#20998;&#26512;&#24037;&#20855;&#65292;&#31934;&#30830;&#22320;&#34920;&#24449;&#20102;&#31616;&#21333;&#22270;&#21367;&#31215;&#32593;&#32476;&#22312;&#32972;&#26223;&#38543;&#26426;&#22359;&#27169;&#22411;&#19978;&#30340;&#27867;&#21270;&#65292;&#25552;&#20986;&#20102;&#21516;&#36136;&#24615;&#22312;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#27867;&#21270;&#20013;&#30340;&#35843;&#21046;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#26159;&#29992;&#20110;&#20851;&#31995;&#25968;&#25454;&#38598;&#65288;&#22914;&#20195;&#35874;&#12289;&#20132;&#36890;&#21644;&#31038;&#20132;&#32593;&#32476;&#65289;&#30340;&#26368;&#25104;&#21151;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#23545;&#25968;&#25454;&#20013;&#32534;&#30721;&#30340;&#21508;&#31181;&#20132;&#20114;&#30340;&#24378;&#22823;&#27867;&#21270;&#30340;&#20915;&#23450;&#22240;&#32032;&#24182;&#19981;&#20026;&#20154;&#25152;&#30693;&#12290;&#26469;&#33258;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#30340;&#26041;&#27861;&#26080;&#27861;&#35299;&#37322;&#20986;&#29616;&#30340;&#29616;&#35937;&#65292;&#22914;&#21452;&#19979;&#38477;&#25110;&#39118;&#38505;&#21462;&#20915;&#20110;&#20132;&#20114;&#24615;&#36136;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#32479;&#35745;&#29289;&#29702;&#21644;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#20998;&#26512;&#24037;&#20855;&#26469;&#31934;&#30830;&#22320;&#34920;&#24449;&#31616;&#21333;&#22270;&#21367;&#31215;&#32593;&#32476;&#22312;&#32972;&#26223;&#38543;&#26426;&#22359;&#27169;&#22411;&#19978;&#30340;&#27867;&#21270;&#12290;&#23548;&#20986;&#30340;&#26354;&#32447;&#29616;&#35937;&#23398;&#19978;&#21313;&#20998;&#20016;&#23500;&#65306;&#23427;&#20204;&#35299;&#37322;&#20102;&#21516;&#36136;&#24615;&#21644;&#24322;&#36136;&#24615;&#23398;&#20064;&#20043;&#38388;&#30340;&#21306;&#21035;&#65292;&#24182;&#39044;&#27979;&#20102;&#26368;&#36817;&#20316;&#21697;&#25152;&#36136;&#30097;&#30340;GNN&#20013;&#21452;&#19979;&#38477;&#29616;&#35937;&#30340;&#23384;&#22312;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#39118;&#38505;&#22914;&#20309;&#21462;&#20915;&#20110;&#22270;&#20013;&#30340;&#22122;&#22768;&#12289;&#29305;&#24449;&#20013;&#30340;&#22122;&#22768;&#21644;&#29992;&#20110;&#35757;&#32451;&#30340;&#33410;&#28857;&#27604;&#20363;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#20026;&#29702;&#35299;&#21516;&#36136;&#24615;&#22914;&#20309;&#35843;&#21046;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#25552;&#20379;&#20102;&#31532;&#19968;&#27493;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks are among the most successful machine learning models for relational datasets like metabolic, transportation, and social networks. Yet the determinants of their strong generalization for diverse interactions encoded in the data are not well understood. Methods from statistical learning theory do not explain emergent phenomena such as double descent or the dependence of risk on the nature of interactions. We use analytical tools from statistical physics and random matrix theory to precisely characterize generalization in simple graph convolution networks on the contextual stochastic block model. The derived curves are phenomenologically rich: they explain the distinction between learning on homophilic and heterophilic and they predict double descent whose existence in GNNs has been questioned by recent work. We show how risk depends on the interplay between the noise in the graph, noise in the features, and the proportion of nodes used for training. Our analysis pr
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#33268;&#21147;&#20110;&#35299;&#20915;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#28151;&#28102;&#21464;&#37327;&#23548;&#33268;&#31574;&#30053;&#35780;&#20272;&#21644;&#20248;&#21270;&#23384;&#22312;&#25361;&#25112;&#30340;&#38382;&#39064;&#65292;&#21253;&#25324;&#26080;&#27861;&#33719;&#24471;&#19968;&#33268;&#20215;&#20540;&#20272;&#35745;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#20445;&#35777;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#20855;&#26377;&#20445;&#35777;&#30340;&#19979;&#38480;&#31639;&#27861;&#21644;&#23616;&#37096;&#25910;&#25947;&#30340;&#25913;&#36827;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2211.16583</link><description>&lt;p&gt;
&#22312;&#28151;&#28102;&#19979;&#30340;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#21644;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Offline Policy Evaluation and Optimization under Confounding. (arXiv:2211.16583v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.16583
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#33268;&#21147;&#20110;&#35299;&#20915;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#28151;&#28102;&#21464;&#37327;&#23548;&#33268;&#31574;&#30053;&#35780;&#20272;&#21644;&#20248;&#21270;&#23384;&#22312;&#25361;&#25112;&#30340;&#38382;&#39064;&#65292;&#21253;&#25324;&#26080;&#27861;&#33719;&#24471;&#19968;&#33268;&#20215;&#20540;&#20272;&#35745;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#20445;&#35777;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#20855;&#26377;&#20445;&#35777;&#30340;&#19979;&#38480;&#31639;&#27861;&#21644;&#23616;&#37096;&#25910;&#25947;&#30340;&#25913;&#36827;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#35780;&#20272;&#21644;&#20248;&#21270;&#31574;&#30053;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#21464;&#37327;&#26102;&#26159;&#19968;&#20010;&#22791;&#21463;&#20851;&#27880;&#30340;&#38382;&#39064;&#12290;&#20351;&#29992;&#20256;&#32479;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#26469;&#22788;&#29702;&#28151;&#28102;&#38382;&#39064;&#19981;&#20165;&#21487;&#33021;&#23548;&#33268;&#31967;&#31957;&#30340;&#20915;&#31574;&#21644;&#31574;&#30053;&#65292;&#32780;&#19988;&#22312;&#20851;&#38190;&#24212;&#29992;&#39046;&#22495;&#22914;&#21307;&#30103;&#21644;&#25945;&#32946;&#20013;&#21487;&#33021;&#20250;&#20135;&#29983;&#28798;&#38590;&#24615;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#21246;&#21202;&#20102;&#28151;&#28102;&#30340; MDP &#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#30340;&#38754;&#35980;&#65292;&#24182;&#26681;&#25454;&#28151;&#28102;&#23545;&#25968;&#25454;&#25910;&#38598;&#31574;&#30053;&#30340;&#26102;&#38388;&#28436;&#21464;&#21644;&#24433;&#21709;&#26469;&#21306;&#20998;&#28151;&#28102;&#30340;&#20551;&#35774;&#12290;&#22312;&#19968;&#20123;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#19968;&#20123;&#26080;&#27861;&#33719;&#24471;&#19968;&#33268;&#20215;&#20540;&#20272;&#35745;&#30340;&#24773;&#20917;&#65292;&#24182;&#25552;&#20379;&#21644;&#35752;&#35770;&#20102;&#35745;&#31639;&#20855;&#26377;&#20445;&#35777;&#30340;&#19979;&#38480;&#30340;&#31639;&#27861;&#12290;&#24403;&#19968;&#33268;&#30340;&#20272;&#35745;&#21487;&#34892;&#26102;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#20445;&#35777;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#26032;&#30340;&#31163;&#32447;&#31574;&#30053;&#25913;&#36827;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#23616;&#37096;&#25910;&#25947;&#30340;&#20445;&#35777;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22312;&#26684;&#23376;&#19990;&#30028;&#21644;&#27169;&#25311;&#21307;&#30103;&#22330;&#26223;&#20013;&#23545;&#31639;&#27861;&#36827;&#34892;&#20102;&#23454;&#39564;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Evaluating and optimizing policies in the presence of unobserved confounders is a problem of growing interest in offline reinforcement learning. Using conventional methods for offline RL in the presence of confounding can not only lead to poor decisions and poor policies, but can also have disastrous effects in critical applications such as healthcare and education. We map out the landscape of offline policy evaluation for confounded MDPs, distinguishing assumptions on confounding based on their time-evolution and effect on the data-collection policies. We determine when consistent value estimates are not achievable, providing and discussing algorithms to estimate lower bounds with guarantees in those cases. When consistent estimates are achievable, we provide sample complexity guarantees. We also present new algorithms for offline policy improvement and prove local convergence guarantees. Finally, we experimentally evaluate our algorithms on gridworld and a simulated healthcare settin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#36817;&#26399;&#22312;&#35774;&#23450;&#39044;&#27979;&#19979;&#30340;&#36827;&#23637;&#65292;&#26500;&#24314;&#20102;&#39044;&#27979;&#38598;&#20197;&#36866;&#24212;&#24402;&#32435;&#23398;&#20064;&#22330;&#26223;&#19979;&#30340;&#33410;&#28857;&#20998;&#31867;&#65292;&#35777;&#26126;&#20102;&#25552;&#20379;&#20102;&#27604;&#31616;&#21333;&#30340;&#31526;&#21512;&#39044;&#27979;&#24212;&#29992;&#26356;&#21152;&#32039;&#33268;&#21644;&#33391;&#22909;&#26657;&#20934;&#30340;&#39044;&#27979;&#38598;&#12290;</title><link>http://arxiv.org/abs/2211.14555</link><description>&lt;p&gt;
&#26080;&#20998;&#24067;&#20551;&#35774;&#30340;&#33410;&#28857;&#20998;&#31867;&#39044;&#27979;&#38598;
&lt;/p&gt;
&lt;p&gt;
Distribution Free Prediction Sets for Node Classification. (arXiv:2211.14555v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.14555
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#36817;&#26399;&#22312;&#35774;&#23450;&#39044;&#27979;&#19979;&#30340;&#36827;&#23637;&#65292;&#26500;&#24314;&#20102;&#39044;&#27979;&#38598;&#20197;&#36866;&#24212;&#24402;&#32435;&#23398;&#20064;&#22330;&#26223;&#19979;&#30340;&#33410;&#28857;&#20998;&#31867;&#65292;&#35777;&#26126;&#20102;&#25552;&#20379;&#20102;&#27604;&#31616;&#21333;&#30340;&#31526;&#21512;&#39044;&#27979;&#24212;&#29992;&#26356;&#21152;&#32039;&#33268;&#21644;&#33391;&#22909;&#26657;&#20934;&#30340;&#39044;&#27979;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#36890;&#24120;&#21487;&#20197;&#22312;&#35768;&#22810;&#37325;&#35201;&#30340;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36798;&#21040;&#39640;&#31934;&#24230;&#20998;&#31867;&#30340;&#25928;&#26524;&#65292;&#20294;&#20854;&#26080;&#27861;&#25552;&#20379;&#20005;&#26684;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#23450;&#20041;&#12290;&#30001;&#20110;&#22270;&#32467;&#26500;&#24341;&#36215;&#30340;&#25968;&#25454;&#28857;&#20381;&#36182;&#24615;&#65292;&#37327;&#21270;GNN&#27169;&#22411;&#30340;&#32622;&#20449;&#24230;&#24456;&#22256;&#38590;&#12290;&#26412;&#25991;&#21033;&#29992;&#36817;&#26399;&#22312;&#35774;&#23450;&#39044;&#27979;&#19979;&#30340;&#36827;&#23637;&#65292;&#26500;&#24314;&#20102;&#39044;&#27979;&#38598;&#20197;&#36866;&#24212;&#24402;&#32435;&#23398;&#20064;&#22330;&#26223;&#19979;&#30340;&#33410;&#28857;&#20998;&#31867;&#12290;&#25105;&#20204;&#23545;&#29616;&#26377;&#30340;&#25442;&#20301;&#20998;&#31867;&#26041;&#27861;&#36827;&#34892;&#20102;&#25913;&#36827;&#65292;&#36890;&#36807;&#36866;&#24403;&#21152;&#26435;&#31526;&#21512;&#20998;&#25968;&#26469;&#21453;&#26144;&#32593;&#32476;&#32467;&#26500;&#12290;&#36890;&#36807;&#22312;&#24120;&#29992;&#26631;&#20934;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#20351;&#29992;&#27969;&#34892;&#30340;GNN&#27169;&#22411;&#36827;&#34892;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#27604;&#31616;&#21333;&#30340;&#31526;&#21512;&#39044;&#27979;&#24212;&#29992;&#26356;&#21152;&#32039;&#33268;&#21644;&#33391;&#22909;&#26657;&#20934;&#30340;&#39044;&#27979;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) are able to achieve high classification accuracy on many important real world datasets, but provide no rigorous notion of predictive uncertainty. Quantifying the confidence of GNN models is difficult due to the dependence between datapoints induced by the graph structure.  We leverage recent advances in conformal prediction to construct prediction sets for node classification in inductive learning scenarios. We do this by taking an existing approach for conformal classification that relies on \textit{exchangeable} data and modifying it by appropriately weighting the conformal scores to reflect the network structure. We show through experiments on standard benchmark datasets using popular GNN models that our approach provides tighter and better calibrated prediction sets than a naive application of conformal prediction.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36229;&#22270;&#30340;&#26426;&#22120;&#23398;&#20064;&#38598;&#25104;&#32593;&#32476;&#20837;&#20405;&#26816;&#27979;&#31995;&#32479;&#65292;&#20351;&#29992;&#36229;&#22270;&#25429;&#25417;&#31471;&#21475;&#25195;&#25551;&#25915;&#20987;&#30340;&#28436;&#21270;&#27169;&#24335;&#65292;&#24182;&#20351;&#29992;&#27966;&#29983;&#30340;&#24230;&#37327;&#26469;&#35757;&#32451;NIDS&#65292;&#20174;&#32780;&#20801;&#35768;&#22312;&#39640;&#31934;&#24230;&#12289;&#39640;&#20934;&#30830;&#29575;&#12289;&#39640;&#21484;&#22238;&#29575;&#24615;&#33021;&#19979;&#23454;&#26102;&#30417;&#27979;&#21644;&#26816;&#27979;&#31471;&#21475;&#25195;&#25551;&#27963;&#21160;&#12289;&#20854;&#20182;&#31867;&#22411;&#30340;&#25915;&#20987;&#21644;&#25932;&#23545;&#20837;&#20405;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;NIDS&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2211.03933</link><description>&lt;p&gt;
&#22522;&#20110;&#36229;&#22270;&#30340;&#26426;&#22120;&#23398;&#20064;&#38598;&#25104;&#32593;&#32476;&#20837;&#20405;&#26816;&#27979;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
A Hypergraph-Based Machine Learning Ensemble Network Intrusion Detection System. (arXiv:2211.03933v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.03933
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36229;&#22270;&#30340;&#26426;&#22120;&#23398;&#20064;&#38598;&#25104;&#32593;&#32476;&#20837;&#20405;&#26816;&#27979;&#31995;&#32479;&#65292;&#20351;&#29992;&#36229;&#22270;&#25429;&#25417;&#31471;&#21475;&#25195;&#25551;&#25915;&#20987;&#30340;&#28436;&#21270;&#27169;&#24335;&#65292;&#24182;&#20351;&#29992;&#27966;&#29983;&#30340;&#24230;&#37327;&#26469;&#35757;&#32451;NIDS&#65292;&#20174;&#32780;&#20801;&#35768;&#22312;&#39640;&#31934;&#24230;&#12289;&#39640;&#20934;&#30830;&#29575;&#12289;&#39640;&#21484;&#22238;&#29575;&#24615;&#33021;&#19979;&#23454;&#26102;&#30417;&#27979;&#21644;&#26816;&#27979;&#31471;&#21475;&#25195;&#25551;&#27963;&#21160;&#12289;&#20854;&#20182;&#31867;&#22411;&#30340;&#25915;&#20987;&#21644;&#25932;&#23545;&#20837;&#20405;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;NIDS&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#20837;&#20405;&#26816;&#27979;&#31995;&#32479;(NIDS)&#22312;&#26816;&#27979;&#24694;&#24847;&#25915;&#20987;&#26102;&#20173;&#28982;&#38754;&#20020;&#25361;&#25112;&#12290;NIDS&#36890;&#24120;&#22312;&#31163;&#32447;&#29366;&#24577;&#19979;&#24320;&#21457;&#65292;&#20294;&#38754;&#23545;&#33258;&#21160;&#29983;&#25104;&#30340;&#31471;&#21475;&#25195;&#25551;&#28183;&#36879;&#23581;&#35797;&#26102;&#65292;&#20250;&#23548;&#33268;&#20174;&#23545;&#25163;&#36866;&#24212;&#21040;NIDS&#21709;&#24212;&#30340;&#26174;&#30528;&#26102;&#38388;&#28382;&#21518;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#20351;&#29992;&#20197;Internet&#21327;&#35758;&#22320;&#22336;&#21644;&#30446;&#26631;&#31471;&#21475;&#20026;&#37325;&#28857;&#30340;&#36229;&#22270;&#26469;&#25429;&#25417;&#31471;&#21475;&#25195;&#25551;&#25915;&#20987;&#30340;&#28436;&#21270;&#27169;&#24335;&#12290;&#28982;&#21518;&#20351;&#29992;&#27966;&#29983;&#30340;&#22522;&#20110;&#36229;&#22270;&#30340;&#24230;&#37327;&#26469;&#35757;&#32451;&#19968;&#20010;&#38598;&#25104;&#26426;&#22120;&#23398;&#20064;(ML)&#30340;NIDS&#65292;&#20174;&#32780;&#20801;&#35768;&#22312;&#39640;&#31934;&#24230;&#12289;&#39640;&#20934;&#30830;&#29575;&#12289;&#39640;&#21484;&#22238;&#29575;&#24615;&#33021;&#19979;&#23454;&#26102;&#35843;&#25972;&#65292;&#30417;&#27979;&#21644;&#26816;&#27979;&#31471;&#21475;&#25195;&#25551;&#27963;&#21160;&#12289;&#20854;&#20182;&#31867;&#22411;&#30340;&#25915;&#20987;&#21644;&#25932;&#23545;&#20837;&#20405;&#12290;&#36825;&#20010;ML&#33258;&#36866;&#24212;&#30340;NIDS&#26159;&#36890;&#36807;&#20197;&#19979;&#20960;&#20010;&#37096;&#20998;&#30340;&#32452;&#21512;&#24320;&#21457;&#20986;&#26469;&#30340;&#65306;(1)&#20837;&#20405;&#31034;&#20363;&#65292;(2)NIDS&#26356;&#26032;&#35268;&#21017;&#65292;(3)&#35302;&#21457;NIDS&#37325;&#26032;&#35757;&#32451;&#35831;&#27714;&#30340;&#25915;&#20987;&#38408;&#20540;&#36873;&#25321;&#65292;&#20197;&#21450;(4)&#22312;&#27809;&#26377;&#20808;&#21069;&#32593;&#32476;&#24615;&#36136;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#30340;&#29983;&#20135;&#29615;&#22659;&#12290;
&lt;/p&gt;
&lt;p&gt;
Network intrusion detection systems (NIDS) to detect malicious attacks continue to meet challenges. NIDS are often developed offline while they face auto-generated port scan infiltration attempts, resulting in a significant time lag from adversarial adaption to NIDS response. To address these challenges, we use hypergraphs focused on internet protocol addresses and destination ports to capture evolving patterns of port scan attacks. The derived set of hypergraph-based metrics are then used to train an ensemble machine learning (ML) based NIDS that allows for real-time adaption in monitoring and detecting port scanning activities, other types of attacks, and adversarial intrusions at high accuracy, precision and recall performances. This ML adapting NIDS was developed through the combination of (1) intrusion examples, (2) NIDS update rules, (3) attack threshold choices to trigger NIDS retraining requests, and (4) a production environment with no prior knowledge of the nature of network 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#31038;&#21306;&#26816;&#27979;&#30446;&#26631;&#19982;&#20854;&#23545;&#24212;&#30340;&#38544;&#24335;&#32593;&#32476;&#29983;&#25104;&#27169;&#22411;&#30456;&#32852;&#31995;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#20197;&#35745;&#31639;&#32593;&#32476;&#22312;&#20219;&#24847;&#30446;&#26631;&#19979;&#30340;&#25551;&#36848;&#38271;&#24230;&#65292;&#27604;&#36739;&#19981;&#21516;&#31639;&#27861;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#36824;&#21487;&#20197;&#35775;&#38382;&#38544;&#24335;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2210.09186</link><description>&lt;p&gt;
&#38544;&#24335;&#27169;&#22411;&#12289;&#28508;&#22312;&#21387;&#32553;&#12289;&#20869;&#22312;&#20559;&#24046;&#21644;&#24265;&#20215;&#21320;&#39184;&#22312;&#31038;&#21306;&#26816;&#27979;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Implicit models, latent compression, intrinsic biases, and cheap lunches in community detection. (arXiv:2210.09186v6 [cs.SI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.09186
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#31038;&#21306;&#26816;&#27979;&#30446;&#26631;&#19982;&#20854;&#23545;&#24212;&#30340;&#38544;&#24335;&#32593;&#32476;&#29983;&#25104;&#27169;&#22411;&#30456;&#32852;&#31995;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#20197;&#35745;&#31639;&#32593;&#32476;&#22312;&#20219;&#24847;&#30446;&#26631;&#19979;&#30340;&#25551;&#36848;&#38271;&#24230;&#65292;&#27604;&#36739;&#19981;&#21516;&#31639;&#27861;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#36824;&#21487;&#20197;&#35775;&#38382;&#38544;&#24335;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#21306;&#26816;&#27979;&#30340;&#20219;&#21153;&#26088;&#22312;&#23558;&#32593;&#32476;&#21010;&#20998;&#20026;&#33410;&#28857;&#38598;&#32676;&#65292;&#20197;&#24635;&#32467;&#20854;&#22823;&#35268;&#27169;&#32467;&#26500;&#65292;&#24050;&#32463;&#24341;&#20986;&#20102;&#35768;&#22810;&#20855;&#26377;&#19981;&#21516;&#30446;&#26631;&#30340;&#31454;&#20105;&#31639;&#27861;&#12290; &#19968;&#20123;&#31038;&#21306;&#26816;&#27979;&#26041;&#27861;&#26159;&#25512;&#26029;&#24615;&#30340;&#65292;&#36890;&#36807;&#27010;&#29575;&#29983;&#25104;&#27169;&#22411;&#26126;&#30830;&#22320;&#23548;&#20986;&#32858;&#31867;&#30446;&#26631;&#65292;&#32780;&#20854;&#20182;&#26041;&#27861;&#26159;&#25551;&#36848;&#24615;&#30340;&#65292;&#26681;&#25454;&#29305;&#23450;&#24212;&#29992;&#30340;&#30446;&#26631;&#23558;&#32593;&#32476;&#20998;&#25104;&#23376;&#38598;&#65292;&#36825;&#20351;&#24471;&#22312;&#21516;&#19968;&#35268;&#27169;&#19979;&#27604;&#36739;&#36825;&#20123;&#26041;&#27861;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#23558;&#20219;&#20309;&#31038;&#21306;&#26816;&#27979;&#30446;&#26631;&#65288;&#25512;&#26029;&#24615;&#25110;&#25551;&#36848;&#24615;&#65289;&#19982;&#20854;&#30456;&#24212;&#30340;&#38544;&#24335;&#32593;&#32476;&#29983;&#25104;&#27169;&#22411;&#30456;&#32852;&#31995;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#35745;&#31639;&#32593;&#32476;&#21450;&#20854;&#22312;&#20219;&#24847;&#30446;&#26631;&#19979;&#30340;&#20998;&#21306;&#30340;&#25551;&#36848;&#38271;&#24230;&#65292;&#26080;&#38656;&#8220;&#22320;&#38754;&#23454;&#20917;&#8221;&#26631;&#31614;&#21363;&#21487;&#27604;&#36739;&#19981;&#21516;&#31639;&#27861;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#36824;&#21487;&#20197;&#35775;&#38382;&#38544;&#24335;&#27169;&#22411;&#65292;&#36825;&#26159;&#20854;&#20182;&#26041;&#27861;&#25152;&#19981;&#20855;&#22791;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
The task of community detection, which aims to partition a network into clusters of nodes to summarize its large-scale structure, has spawned the development of many competing algorithms with varying objectives. Some community detection methods are inferential, explicitly deriving the clustering objective through a probabilistic generative model, while other methods are descriptive, dividing a network according to an objective motivated by a particular application, making it challenging to compare these methods on the same scale. Here we present a solution to this problem that associates any community detection objective, inferential or descriptive, with its corresponding implicit network generative model. This allows us to compute the description length of a network and its partition under arbitrary objectives, providing a principled measure to compare the performance of different algorithms without the need for "ground truth" labels. Our approach also gives access to instances of the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26102;&#21464;&#26377;&#21521;&#32593;&#32476;&#30340;&#20998;&#25955;&#24335;&#36229;&#26799;&#24230;&#35745;&#31639;&#26041;&#27861;&#65292;&#36991;&#20813;&#20102;&#38745;&#24577;&#26080;&#21521;&#32593;&#32476;&#36890;&#20449; Hessian &#30697;&#38453;&#23548;&#33268;&#30340;&#39640;&#36890;&#20449;&#25104;&#26412;&#21644;&#26080;&#27861;&#20351;&#29992;&#26102;&#21464;&#26377;&#21521;&#32593;&#32476;&#20248;&#21183;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2210.02129</link><description>&lt;p&gt;
&#22522;&#20110;&#26102;&#21464;&#26377;&#21521;&#32593;&#32476;&#30340;&#20998;&#25955;&#24335;&#36229;&#26799;&#24230;&#35745;&#31639;
&lt;/p&gt;
&lt;p&gt;
Decentralized Hyper-Gradient Computation over Time-Varying Directed Networks. (arXiv:2210.02129v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.02129
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26102;&#21464;&#26377;&#21521;&#32593;&#32476;&#30340;&#20998;&#25955;&#24335;&#36229;&#26799;&#24230;&#35745;&#31639;&#26041;&#27861;&#65292;&#36991;&#20813;&#20102;&#38745;&#24577;&#26080;&#21521;&#32593;&#32476;&#36890;&#20449; Hessian &#30697;&#38453;&#23548;&#33268;&#30340;&#39640;&#36890;&#20449;&#25104;&#26412;&#21644;&#26080;&#27861;&#20351;&#29992;&#26102;&#21464;&#26377;&#21521;&#32593;&#32476;&#20248;&#21183;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#20998;&#25955;&#24335;&#32852;&#37030;&#23398;&#20064;&#20013;&#20272;&#35745;&#36229;&#26799;&#24230;&#26102;&#30340;&#36890;&#20449;&#38382;&#39064;&#12290;&#22312;&#20998;&#25955;&#24335;&#32852;&#37030;&#23398;&#20064;&#20013;&#65292;&#36229;&#26799;&#24230;&#37327;&#21270;&#20102;&#20840;&#23616;&#20849;&#20139;&#26368;&#20248;&#27169;&#22411;&#30340;&#24615;&#33021;&#22914;&#20309;&#21463;&#21040;&#23458;&#25143;&#31471;&#36229;&#21442;&#25968;&#25200;&#21160;&#30340;&#24433;&#21709;&#12290;&#22312;&#20808;&#21069;&#30340;&#24037;&#20316;&#20013;&#65292;&#23458;&#25143;&#31471;&#36890;&#36807;&#22312;&#38745;&#24577;&#26080;&#21521;&#32593;&#32476;&#19978;&#36890;&#20449; Hess &#30697;&#38453;&#26469;&#36319;&#36394;&#36825;&#31181;&#24433;&#21709;&#65292;&#23548;&#33268;&#20102;&#65288;i&#65289;&#36807;&#39640;&#30340;&#36890;&#20449;&#25104;&#26412;&#21644;&#65288;ii&#65289;&#19981;&#33021;&#21033;&#29992;&#26356;&#39640;&#25928;&#21644;&#26356;&#24378;&#22823;&#30340;&#32593;&#32476;&#65292;&#21363;&#26102;&#21464;&#26377;&#21521;&#32593;&#32476;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#22522;&#20110;&#27169;&#22411;&#21442;&#25968;&#21644;&#26799;&#24230;&#30340;&#24179;&#22343;&#25805;&#20316;&#30340; FL &#26367;&#20195;&#24615;&#20248;&#21270;&#26465;&#20214;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#37319;&#29992; Push-Sum &#20316;&#20026;&#24179;&#22343;&#25805;&#20316;&#65292;&#22312;&#26102;&#21464;&#26377;&#21521;&#32593;&#32476;&#19978;&#36827;&#34892;&#20849;&#35782;&#20248;&#21270;&#25216;&#26415;&#12290;&#22240;&#27492;&#65292;&#20174;&#25105;&#20204;&#30340;&#26368;&#20248;&#26465;&#20214;&#25512;&#23548;&#20986;&#30340;&#36229;&#26799;&#24230;&#20272;&#35745;&#22120;&#20855;&#26377;&#20004;&#20010;&#29702;&#24819;&#29305;&#24615;&#65292;&#65288;i&#65289;&#23427;&#21482;&#38656;&#35201; Push-Sum &#36890;&#20449;
&lt;/p&gt;
&lt;p&gt;
This paper addresses the communication issues when estimating hyper-gradients in decentralized federated learning (FL). Hyper-gradients in decentralized FL quantifies how the performance of globally shared optimal model is influenced by the perturbations in clients' hyper-parameters. In prior work, clients trace this influence through the communication of Hessian matrices over a static undirected network, resulting in (i) excessive communication costs and (ii) inability to make use of more efficient and robust networks, namely, time-varying directed networks. To solve these issues, we introduce an alternative optimality condition for FL using an averaging operation on model parameters and gradients. We then employ Push-Sum as the averaging operation, which is a consensus optimization technique for time-varying directed networks. As a result, the hyper-gradient estimator derived from our optimality condition enjoys two desirable properties; (i) it only requires Push-Sum communication of
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;Fisher-Rao&#33258;&#28982;&#26799;&#24230;&#19979;&#38477;&#26368;&#20339;&#36924;&#36817;&#36830;&#32493;&#26102;&#38388;&#22797;&#21046;&#23376;&#26041;&#31243;&#65292;&#36825;&#19968;&#23545;&#24212;&#20851;&#31995;&#31216;&#20026;&#8220;&#20849;&#36717;&#33258;&#28982;&#36873;&#25321;&#8221;&#65292;&#20026;&#36827;&#21270;&#35745;&#31639;&#25552;&#20379;&#20102;&#26367;&#20195;&#26041;&#27861;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#36830;&#32493;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;&#26368;&#20339;&#36817;&#20284;&#12290;</title><link>http://arxiv.org/abs/2208.13898</link><description>&lt;p&gt;
&#20849;&#36717;&#33258;&#28982;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Conjugate Natural Selection. (arXiv:2208.13898v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.13898
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;Fisher-Rao&#33258;&#28982;&#26799;&#24230;&#19979;&#38477;&#26368;&#20339;&#36924;&#36817;&#36830;&#32493;&#26102;&#38388;&#22797;&#21046;&#23376;&#26041;&#31243;&#65292;&#36825;&#19968;&#23545;&#24212;&#20851;&#31995;&#31216;&#20026;&#8220;&#20849;&#36717;&#33258;&#28982;&#36873;&#25321;&#8221;&#65292;&#20026;&#36827;&#21270;&#35745;&#31639;&#25552;&#20379;&#20102;&#26367;&#20195;&#26041;&#27861;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#36830;&#32493;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;&#26368;&#20339;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;Fisher-Rao&#33258;&#28982;&#26799;&#24230;&#19979;&#38477;&#65288;FR-NGD&#65289;&#26368;&#20339;&#36924;&#36817;&#20102;&#36830;&#32493;&#26102;&#38388;&#22797;&#21046;&#23376;&#26041;&#31243;&#65288;&#19968;&#31181;&#22522;&#26412;&#30340;&#36827;&#21270;&#21160;&#21147;&#23398;&#27169;&#22411;&#65289;&#65292;&#24182;&#23558;&#27492;&#23545;&#24212;&#20851;&#31995;&#31216;&#20026;&#8220;&#20849;&#36717;&#33258;&#28982;&#36873;&#25321;&#8221;&#12290;&#35813;&#23545;&#24212;&#20851;&#31995;&#20026;&#22312;&#36830;&#32493;&#25110;&#39640;&#32500;&#24230;&#20551;&#35774;&#31354;&#38388;&#19978;&#36827;&#34892;&#36827;&#21270;&#35745;&#31639;&#25552;&#20379;&#20102;&#26367;&#20195;&#26041;&#27861;&#12290;&#20316;&#20026;&#19968;&#20010;&#29305;&#20363;&#65292;FR-NGD&#36824;&#25552;&#20379;&#20102;&#36830;&#32493;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;&#26368;&#20339;&#36817;&#20284;&#65292;&#24403;&#20551;&#35774;&#22522;&#20110;&#39044;&#27979;&#23454;&#38469;&#35266;&#27979;&#32467;&#26524;&#32780;&#30456;&#20114;&#31454;&#20105;&#26102;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#35813;&#26041;&#27861;&#36991;&#20813;&#20102;&#35745;&#31639;&#20808;&#39564;&#27010;&#29575;&#30340;&#38656;&#35201;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#21644;&#19968;&#20010;&#20855;&#26377;&#26102;&#21464;&#21442;&#25968;&#30340;&#38543;&#26426;&#36807;&#31243;&#30340;&#31995;&#32479;&#35782;&#21035;&#20219;&#21153;&#28436;&#31034;&#20102;&#25105;&#20204;&#30340;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We prove that Fisher-Rao natural gradient descent (FR-NGD) optimally approximates the continuous time replicator equation (an essential model of evolutionary dynamics), and term this correspondence "conjugate natural selection". This correspondence promises alternative approaches for evolutionary computation over continuous or high-dimensional hypothesis spaces. As a special case, FR-NGD also provides the optimal approximation of continuous Bayesian inference when hypotheses compete on the basis of predicting actual observations. In this case, the method avoids the need to compute prior probabilities. We demonstrate our findings on a non-convex optimization problem and a system identification task for a stochastic process with time-varying parameters.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#30028;&#23450;&#26080;&#27861;&#36890;&#36807;&#28857;&#20272;&#35745;&#36827;&#34892;&#35782;&#21035;&#30340;&#36830;&#32493;&#20540;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#33539;&#22260;&#65292;&#20197;&#35299;&#20915;&#23384;&#22312;&#38544;&#34255;&#28151;&#28102;&#22240;&#32032;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2204.11206</link><description>&lt;p&gt;
&#38544;&#34255;&#28151;&#28102;&#22240;&#32032;&#19979;&#21058;&#37327;&#21709;&#24212;&#30340;&#37096;&#20998;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Partial Identification of Dose Responses with Hidden Confounders. (arXiv:2204.11206v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.11206
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#30028;&#23450;&#26080;&#27861;&#36890;&#36807;&#28857;&#20272;&#35745;&#36827;&#34892;&#35782;&#21035;&#30340;&#36830;&#32493;&#20540;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#33539;&#22260;&#65292;&#20197;&#35299;&#20915;&#23384;&#22312;&#38544;&#34255;&#28151;&#28102;&#22240;&#32032;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#25512;&#26029;&#36830;&#32493;&#20540;&#22788;&#29702;&#30340;&#22240;&#26524;&#25928;&#24212;&#26159;&#19968;&#39033;&#20851;&#38190;&#20219;&#21153;&#65292;&#26377;&#26395;&#26356;&#22909;&#22320;&#20026;&#25919;&#31574;&#21644;&#20915;&#31574;&#21046;&#23450;&#32773;&#25552;&#20379;&#20449;&#24687;&#12290; &#30830;&#23450;&#36825;&#20123;&#25928;&#24212;&#25152;&#38656;&#30340;&#20851;&#38190;&#20551;&#35774;&#26159;&#21253;&#25324;&#25152;&#26377;&#28151;&#28102;&#21464;&#37327;&#8212;&#8212;&#22788;&#29702;&#21644;&#32467;&#26524;&#30340;&#22240;&#26524;&#29238;&#27597;&#8212;&#8212;&#20316;&#20026;&#21327;&#21464;&#37327;&#12290; &#19981;&#24184;&#30340;&#26159;&#65292;&#20165;&#20973;&#35266;&#27979;&#25968;&#25454;&#65292;&#25105;&#20204;&#26080;&#27861;&#30830;&#23450;&#36825;&#20010;&#26631;&#20934;&#26159;&#21542;&#24471;&#21040;&#28385;&#36275;&#12290; &#24403;&#28151;&#28102;&#21464;&#37327;&#34987;&#38544;&#34255;&#26102;&#65292;&#25935;&#24863;&#24615;&#20998;&#26512;&#25552;&#20379;&#20102;&#19968;&#31181;&#21407;&#21017;&#24615;&#30340;&#26041;&#24335;&#26469;&#20026;&#22240;&#26524;&#20272;&#35745;&#25552;&#20379;&#30028;&#38480;&#12290; &#34429;&#28982;&#22312;&#31163;&#25955;&#20540;&#22788;&#29702;&#30340;&#28789;&#25935;&#24230;&#20998;&#26512;&#20013;&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#20294;&#23545;&#20110;&#36830;&#32493;&#20540;&#22788;&#29702;&#65292;&#21364;&#20184;&#20986;&#20102;&#26356;&#23569;&#30340;&#20851;&#27880;&#12290; &#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#30028;&#23450;&#26080;&#27861;&#36890;&#36807;&#28857;&#20272;&#35745;&#36827;&#34892;&#35782;&#21035;&#30340;&#24179;&#22343;&#21644;&#26465;&#20214;&#24179;&#22343;&#36830;&#32493;&#20540;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#30340;&#33539;&#22260;&#65292;&#22240;&#20026;&#23384;&#22312;&#38544;&#34255;&#30340;&#28151;&#28102;&#12290; &#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#21322;&#21512;&#25104;&#22522;&#20934;&#27979;&#35797;&#26174;&#31034;&#20986;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#26356;&#32039;&#23494;&#30340;&#35206;&#30422;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inferring causal effects of continuous-valued treatments from observational data is a crucial task promising to better inform policy- and decision-makers. A critical assumption needed to identify these effects is that all confounding variables -- causal parents of both the treatment and the outcome -- are included as covariates. Unfortunately, given observational data alone, we cannot know with certainty that this criterion is satisfied. Sensitivity analyses provide principled ways to give bounds on causal estimates when confounding variables are hidden. While much attention is focused on sensitivity analyses for discrete-valued treatments, much less is paid to continuous-valued treatments. We present novel methodology to bound both average and conditional average continuous-valued treatment-effect estimates when they cannot be point identified due to hidden confounding. A semi-synthetic benchmark on multiple datasets shows our method giving tighter coverage of the true dose-response c
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#21709;&#24212;&#26426;&#21046;&#30340;&#25193;&#23637;&#65292;&#21487;&#22312;&#23616;&#37096;&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#19979;&#35745;&#31639;&#38750;&#21442;&#25968;&#38750;&#28176;&#36827;&#32479;&#35745;&#25512;&#26029;&#65292;&#30001;&#27492;&#24471;&#21040;&#30340;&#32467;&#26524;&#21487;&#29992;&#20110;&#29983;&#25104;&#25928;&#29575;&#39640;&#30340;&#32622;&#20449;&#21306;&#38388;&#21644;&#26102;&#38388;&#22343;&#21248;&#32622;&#20449;&#24207;&#21015;&#12290;&#21033;&#29992;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#36827;&#34892;&#23454;&#35777;&#30740;&#31350;&#24182;&#20135;&#29983;&#31169;&#26377;&#27169;&#25311;&#12290;</title><link>http://arxiv.org/abs/2202.08728</link><description>&lt;p&gt;
&#38543;&#26426;&#21709;&#24212;&#31169;&#26377;&#32622;&#20449;&#38598;&#30340;&#38750;&#21442;&#25968;&#25193;&#23637;
&lt;/p&gt;
&lt;p&gt;
Nonparametric extensions of randomized response for private confidence sets. (arXiv:2202.08728v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.08728
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#21709;&#24212;&#26426;&#21046;&#30340;&#25193;&#23637;&#65292;&#21487;&#22312;&#23616;&#37096;&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#19979;&#35745;&#31639;&#38750;&#21442;&#25968;&#38750;&#28176;&#36827;&#32479;&#35745;&#25512;&#26029;&#65292;&#30001;&#27492;&#24471;&#21040;&#30340;&#32467;&#26524;&#21487;&#29992;&#20110;&#29983;&#25104;&#25928;&#29575;&#39640;&#30340;&#32622;&#20449;&#21306;&#38388;&#21644;&#26102;&#38388;&#22343;&#21248;&#32622;&#20449;&#24207;&#21015;&#12290;&#21033;&#29992;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#36827;&#34892;&#23454;&#35777;&#30740;&#31350;&#24182;&#20135;&#29983;&#31169;&#26377;&#27169;&#25311;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23616;&#37096;&#24046;&#20998;&#38544;&#31169;&#65288;LDP&#65289;&#32422;&#26463;&#19979;&#25191;&#34892;&#38750;&#21442;&#25968;&#12289;&#38750;&#28176;&#36827;&#32479;&#35745;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35745;&#31639;&#20855;&#26377;&#22343;&#20540;$\mu^\star$&#30340;&#26377;&#30028;&#35266;&#27979;$(X_1,\dots,X_n)$&#30340;&#32622;&#20449;&#21306;&#38388;&#65288;CI&#65289;&#21644;&#26102;&#38388;&#22343;&#21248;&#32622;&#20449;&#24207;&#21015;&#65288;CS&#65289;&#65292;&#24403;&#21482;&#26377;&#35775;&#38382;&#31169;&#26377;&#25968;&#25454;$(Z_1,\dots,Z_n)$&#26102;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#38750;&#21442;&#25968;&#30340;&#12289;&#39034;&#24207;&#20132;&#20114;&#30340; Warner &#30340;&#33879;&#21517;&#8220;&#38543;&#26426;&#21709;&#24212;&#8221;&#26426;&#21046;&#30340;&#25512;&#24191;&#65292;&#20026;&#20219;&#24847;&#26377;&#30028;&#38543;&#26426;&#21464;&#37327;&#28385;&#36275; LDP&#65292;&#24182;&#25552;&#20379; CIs &#21644; CSs&#65292;&#29992;&#20110;&#35775;&#38382;&#25152;&#24471;&#31169;&#26377;&#21270;&#30340;&#35266;&#27979;&#20540;&#30340;&#22343;&#20540;&#12290;&#20363;&#22914;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#22312;&#22266;&#23450;&#26102;&#38388;&#21644;&#26102;&#38388;&#22343;&#21248;&#21306;&#22495;&#37117;&#20135;&#29983;&#20102; Hoeffding &#19981;&#31561;&#24335;&#30340;&#31169;&#26377;&#27169;&#25311;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123; Hoeffding  &#31867;&#22411;&#30340; CSs &#25193;&#23637;&#21040;&#25429;&#33719;&#26102;&#38388;&#21464;&#21270;&#65288;&#38750;&#24179;&#31283;&#65289;&#30340;&#22343;&#20540;&#65292;&#26368;&#21518;&#35828;&#26126;&#20102;&#22914;&#20309;&#21033;&#29992;&#36825;&#20123;&#26041;&#27861;&#36827;&#34892;&#23454;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work derives methods for performing nonparametric, nonasymptotic statistical inference for population means under the constraint of local differential privacy (LDP). Given bounded observations $(X_1, \dots, X_n)$ with mean $\mu^\star$ that are privatized into $(Z_1, \dots, Z_n)$, we present confidence intervals (CI) and time-uniform confidence sequences (CS) for $\mu^\star$ when only given access to the privatized data. To achieve this, we introduce a nonparametric and sequentially interactive generalization of Warner's famous ``randomized response'' mechanism, satisfying LDP for arbitrary bounded random variables, and then provide CIs and CSs for their means given access to the resulting privatized observations. For example, our results yield private analogues of Hoeffding's inequality in both fixed-time and time-uniform regimes. We extend these Hoeffding-type CSs to capture time-varying (non-stationary) means, and conclude by illustrating how these methods can be used to conduct
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25214;&#21040;&#20102;&#24102;&#26435;&#37325;&#34928;&#20943;&#21644;&#38543;&#26426;&#31070;&#32463;&#20803;&#30340;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#65292;&#32467;&#26524;&#34920;&#26126;&#26435;&#37325;&#34928;&#20943;&#19982;&#27169;&#22411;&#26550;&#26500;&#30340;&#24378;&#28872;&#20132;&#20114;&#20316;&#29992;&#20250;&#22312;&#22810;&#20110;1&#20010;&#38544;&#34255;&#23618;&#30340;&#32593;&#32476;&#20013;&#21019;&#24314;&#19981;&#33391;&#26497;&#23567;&#20540;&#65292;&#24182;&#34920;&#26126;&#24120;&#35265;&#30340;&#28145;&#24230;&#23398;&#20064;&#21021;&#22987;&#21270;&#26041;&#27861;&#26080;&#27861;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#32531;&#35299;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2202.04777</link><description>&lt;p&gt;
&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#30340;&#31934;&#30830;&#35299;&#26512;&#35299;
&lt;/p&gt;
&lt;p&gt;
Exact Solutions of a Deep Linear Network. (arXiv:2202.04777v6 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.04777
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25214;&#21040;&#20102;&#24102;&#26435;&#37325;&#34928;&#20943;&#21644;&#38543;&#26426;&#31070;&#32463;&#20803;&#30340;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#65292;&#32467;&#26524;&#34920;&#26126;&#26435;&#37325;&#34928;&#20943;&#19982;&#27169;&#22411;&#26550;&#26500;&#30340;&#24378;&#28872;&#20132;&#20114;&#20316;&#29992;&#20250;&#22312;&#22810;&#20110;1&#20010;&#38544;&#34255;&#23618;&#30340;&#32593;&#32476;&#20013;&#21019;&#24314;&#19981;&#33391;&#26497;&#23567;&#20540;&#65292;&#24182;&#34920;&#26126;&#24120;&#35265;&#30340;&#28145;&#24230;&#23398;&#20064;&#21021;&#22987;&#21270;&#26041;&#27861;&#26080;&#27861;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#32531;&#35299;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25214;&#21040;&#20102;&#24102;&#26435;&#37325;&#34928;&#20943;&#21644;&#38543;&#26426;&#31070;&#32463;&#20803;&#30340;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#65292;&#36825;&#26159;&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#29702;&#35770;&#20013;&#30340;&#22522;&#30784;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#20013;&#65292;&#38646;&#26159;&#19968;&#20010;&#29305;&#27530;&#30340;&#28857;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26435;&#37325;&#34928;&#20943;&#19982;&#27169;&#22411;&#26550;&#26500;&#30340;&#24378;&#28872;&#20132;&#20114;&#20316;&#29992;&#65292;&#24182;&#33021;&#22815;&#22312;&#20855;&#26377;&#36229;&#36807; $1$ &#20010;&#38544;&#34255;&#23618;&#30340;&#32593;&#32476;&#20013;&#21019;&#24314;&#19981;&#33391;&#26497;&#23567;&#20540;&#65292;&#36825;&#19982;&#20165;&#26377; $1$ &#20010;&#38544;&#34255;&#23618;&#30340;&#32593;&#32476;&#26377;&#36136;&#30340;&#19981;&#21516;&#12290;&#23454;&#38469;&#19978;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#24847;&#21619;&#30528;&#24120;&#35265;&#30340;&#28145;&#24230;&#23398;&#20064;&#21021;&#22987;&#21270;&#26041;&#27861;&#26080;&#27861;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#32531;&#35299;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work finds the analytical expression of the global minima of a deep linear network with weight decay and stochastic neurons, a fundamental model for understanding the landscape of neural networks. Our result implies that zero is a special point in deep neural network architecture. We show that weight decay strongly interacts with the model architecture and can create bad minima at zero in a network with more than $1$ hidden layer, qualitatively different from a network with only $1$ hidden layer. Practically, our result implies that common deep learning initialization methods are insufficient to ease the optimization of neural networks in general.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#23376;&#22686;&#24378;&#30340;&#26641;&#38598;&#21512;&#26041;&#27861;&#65292;&#33021;&#22815;&#22788;&#29702;&#22810;&#31181;&#19981;&#35268;&#21017;&#39044;&#27979;&#21464;&#37327;&#65292;&#20026;&#22788;&#29702;&#23439;&#35266;&#37329;&#34701;&#38382;&#39064;&#25552;&#20379;&#19968;&#31181;&#21487;&#38752;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2111.14000</link><description>&lt;p&gt;
&#22240;&#23376;&#22686;&#24378;&#30340;&#26641;&#38598;&#21512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Factor-augmented tree ensembles. (arXiv:2111.14000v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.14000
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#23376;&#22686;&#24378;&#30340;&#26641;&#38598;&#21512;&#26041;&#27861;&#65292;&#33021;&#22815;&#22788;&#29702;&#22810;&#31181;&#19981;&#35268;&#21017;&#39044;&#27979;&#21464;&#37327;&#65292;&#20026;&#22788;&#29702;&#23439;&#35266;&#37329;&#34701;&#38382;&#39064;&#25552;&#20379;&#19968;&#31181;&#21487;&#38752;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21033;&#29992;&#29366;&#24577;&#31354;&#38388;&#26041;&#27861;&#25552;&#21462;&#28508;&#22312;&#31283;&#24577;&#22240;&#23376;&#26469;&#25193;&#23637;&#26102;&#38388;&#24207;&#21015;&#22238;&#24402;&#26641;&#20449;&#24687;&#38598;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#36825;&#26679;&#20570;&#65292;&#35813;&#26041;&#27861;&#23558;&#26102;&#38388;&#24207;&#21015;&#22238;&#24402;&#26641;&#30340;&#24212;&#29992;&#25193;&#23637;&#21040;&#20004;&#20010;&#26041;&#38754;&#12290;&#31532;&#19968;&#65292;&#23427;&#21487;&#20197;&#22788;&#29702;&#27979;&#37327;&#35823;&#24046;&#12289;&#38750;&#24179;&#31283;&#36235;&#21183;&#12289;&#23395;&#33410;&#24615;&#21644;/&#25110;&#32570;&#22833;&#35266;&#27979;&#31561;&#19981;&#35268;&#21017;&#30340;&#39044;&#27979;&#21464;&#37327;&#12290;&#31532;&#20108;&#65292;&#23427;&#25552;&#20379;&#20102;&#19968;&#31181;&#26126;&#30830;&#30340;&#21033;&#29992;&#39046;&#22495;&#19987;&#19994;&#29702;&#35770;&#26469;&#25351;&#23548;&#26102;&#38388;&#24207;&#21015;&#22238;&#24402;&#26641;&#30340;&#26041;&#27861;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20123;&#22240;&#23376;&#22686;&#24378;&#30340;&#26641;&#38598;&#21512;&#26041;&#27861;&#22312;&#23439;&#35266;&#37329;&#34701;&#38382;&#39064;&#26041;&#38754;&#25552;&#20379;&#20102;&#19968;&#31181;&#21487;&#38752;&#30340;&#26041;&#27861;&#12290;&#26412;&#25991;&#37325;&#28857;&#20171;&#32461;&#20102;&#32654;&#22269;&#32929;&#31080;&#27874;&#21160;&#29575;&#19982;&#21830;&#19994;&#21608;&#26399;&#20043;&#38388;&#30340;&#20808;&#23548;&#28382;&#21518;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
This manuscript proposes to extend the information set of time-series regression trees with latent stationary factors extracted via state-space methods. In doing so, this approach generalises time-series regression trees on two dimensions. First, it allows to handle predictors that exhibit measurement error, non-stationary trends, seasonality and/or irregularities such as missing observations. Second, it gives a transparent way for using domain-specific theory to inform time-series regression trees. Empirically, ensembles of these factor-augmented trees provide a reliable approach for macro-finance problems. This article highlights it focussing on the lead-lag effect between equity volatility and the business cycle in the United States.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#28982;lasso&#21464;&#20307;&#30340;MARS&#26041;&#27861;&#65292;&#36890;&#36807;&#20943;&#23569;&#23545;&#32500;&#24230;&#30340;&#20381;&#36182;&#26469;&#33719;&#24471;&#25910;&#25947;&#29575;&#65292;&#24182;&#19982;&#20351;&#29992;&#24179;&#28369;&#24615;&#32422;&#26463;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;&#25216;&#26415;&#32852;&#31995;&#22312;&#19968;&#36215;&#12290;</title><link>http://arxiv.org/abs/2111.11694</link><description>&lt;p&gt;
MARS via LASSO.&#65288;arXiv:2111.11694v2 [math.ST] &#24050;&#26356;&#26032;&#65289;
&lt;/p&gt;
&lt;p&gt;
MARS via LASSO. (arXiv:2111.11694v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.11694
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#28982;lasso&#21464;&#20307;&#30340;MARS&#26041;&#27861;&#65292;&#36890;&#36807;&#20943;&#23569;&#23545;&#32500;&#24230;&#30340;&#20381;&#36182;&#26469;&#33719;&#24471;&#25910;&#25947;&#29575;&#65292;&#24182;&#19982;&#20351;&#29992;&#24179;&#28369;&#24615;&#32422;&#26463;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;&#25216;&#26415;&#32852;&#31995;&#22312;&#19968;&#36215;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20803;&#33258;&#36866;&#24212;&#22238;&#24402;&#26679;&#26465;&#65288;Multivariate Adaptive Regression Splines&#65292;MARS&#65289;&#26159;Friedman&#22312;1991&#24180;&#25552;&#20986;&#30340;&#19968;&#31181;&#38750;&#21442;&#25968;&#22238;&#24402;&#26041;&#27861;&#12290;MARS&#23558;&#31616;&#21333;&#30340;&#38750;&#32447;&#24615;&#21644;&#38750;&#21152;&#24615;&#20989;&#25968;&#25311;&#21512;&#21040;&#22238;&#24402;&#25968;&#25454;&#19978;&#12290;&#26412;&#25991;&#25552;&#20986;&#24182;&#30740;&#31350;&#20102;MARS&#26041;&#27861;&#30340;&#19968;&#31181;&#33258;&#28982;lasso&#21464;&#20307;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#22522;&#20110;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#65292;&#36890;&#36807;&#32771;&#34385;MARS&#22522;&#30784;&#20989;&#25968;&#30340;&#26080;&#38480;&#32500;&#32447;&#24615;&#32452;&#21512;&#24182;&#24378;&#21152;&#22522;&#20110;&#21464;&#20998;&#30340;&#22797;&#26434;&#24230;&#32422;&#26463;&#26465;&#20214;&#26469;&#33719;&#24471;&#20989;&#25968;&#30340;&#20984;&#31867;&#12290;&#34429;&#28982;&#25105;&#20204;&#30340;&#20272;&#35745;&#26159;&#23450;&#20041;&#20026;&#26080;&#38480;&#32500;&#20248;&#21270;&#38382;&#39064;&#30340;&#35299;&#65292;&#20294;&#20854;&#21487;&#20197;&#36890;&#36807;&#26377;&#38480;&#32500;&#20984;&#20248;&#21270;&#26469;&#35745;&#31639;&#12290;&#22312;&#19968;&#20123;&#26631;&#20934;&#35774;&#35745;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#20165;&#22312;&#32500;&#24230;&#19978;&#23545;&#25968;&#25910;&#25947;&#65292;&#22240;&#27492;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#36991;&#20813;&#20102;&#36890;&#24120;&#30340;&#32500;&#24230;&#28798;&#38590;&#12290;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33258;&#28982;&#22320;&#19982;&#22522;&#20110;&#24179;&#28369;&#24615;&#32422;&#26463;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;&#25216;&#26415;&#30456;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multivariate adaptive regression splines (MARS) is a popular method for nonparametric regression introduced by Friedman in 1991. MARS fits simple nonlinear and non-additive functions to regression data. We propose and study a natural lasso variant of the MARS method. Our method is based on least squares estimation over a convex class of functions obtained by considering infinite-dimensional linear combinations of functions in the MARS basis and imposing a variation based complexity constraint. Our estimator can be computed via finite-dimensional convex optimization, although it is defined as a solution to an infinite-dimensional optimization problem. Under a few standard design assumptions, we prove that our estimator achieves a rate of convergence that depends only logarithmically on dimension and thus avoids the usual curse of dimensionality to some extent. We also show that our method is naturally connected to nonparametric estimation techniques based on smoothness constraints. We i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24212;&#29992;&#31070;&#32463;&#32593;&#32476;&#35299;&#20915; Monge-Amp\`ere &#26041;&#31243;&#30340;&#36842;&#21033;&#20811;&#38647;&#38382;&#39064;&#65292;&#20351;&#29992;&#28145;&#24230;&#20984;&#36755;&#20837;&#31070;&#32463;&#32593;&#32476;&#30340;&#20551;&#35774;&#21487;&#20197;&#29992;&#26469;&#25214;&#21040;&#21807;&#19968;&#30340;&#20984;&#35299;&#65292;&#26041;&#27861;&#23545;&#22855;&#24322;&#28857;&#12289;&#19981;&#36830;&#32493;&#28857;&#21644;&#28304;&#20989;&#25968;&#20013;&#30340;&#22122;&#22768;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#20063;&#33021;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>http://arxiv.org/abs/2110.03310</link><description>&lt;p&gt;
&#24212;&#29992;&#31070;&#32463;&#32593;&#32476;&#35299;&#20915; Monge-Amp\`ere &#26041;&#31243;&#30340;&#36842;&#21033;&#20811;&#38647;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Solving the Dirichlet problem for the Monge-Amp\`ere equation using neural networks. (arXiv:2110.03310v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.03310
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24212;&#29992;&#31070;&#32463;&#32593;&#32476;&#35299;&#20915; Monge-Amp\`ere &#26041;&#31243;&#30340;&#36842;&#21033;&#20811;&#38647;&#38382;&#39064;&#65292;&#20351;&#29992;&#28145;&#24230;&#20984;&#36755;&#20837;&#31070;&#32463;&#32593;&#32476;&#30340;&#20551;&#35774;&#21487;&#20197;&#29992;&#26469;&#25214;&#21040;&#21807;&#19968;&#30340;&#20984;&#35299;&#65292;&#26041;&#27861;&#23545;&#22855;&#24322;&#28857;&#12289;&#19981;&#36830;&#32493;&#28857;&#21644;&#28304;&#20989;&#25968;&#20013;&#30340;&#22122;&#22768;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#20063;&#33021;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Monge-Amp\`ere &#26041;&#31243;&#26159;&#20998;&#26512;&#12289;&#20960;&#20309;&#21644;&#24212;&#29992;&#31185;&#23398;&#20013;&#38750;&#24120;&#37325;&#35201;&#30340;&#19968;&#20010;&#20840;&#38750;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#26412;&#25991;&#24212;&#29992;&#31070;&#32463;&#32593;&#32476;&#35299;&#20915;&#20102;&#19982; Monge-Amp\`ere &#26041;&#31243;&#30456;&#20851;&#30340;&#36842;&#21033;&#20811;&#38647;&#38382;&#39064;&#65292;&#24182;&#19988;&#23637;&#31034;&#20102;&#20351;&#29992;&#28145;&#24230;&#20984;&#36755;&#20837;&#31070;&#32463;&#32593;&#32476;&#30340;&#20551;&#35774;&#21487;&#20197;&#29992;&#26469;&#25214;&#21040;&#21807;&#19968;&#30340;&#20984;&#35299;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#22855;&#24322;&#28857;&#12289;&#19981;&#36830;&#32493;&#28857;&#21644;&#28304;&#20989;&#25968;&#20013;&#30340;&#22122;&#22768;&#23545;&#26041;&#27861;&#25928;&#26524;&#30340;&#24433;&#21709;&#65292;&#32771;&#34385;&#20102;&#38750;&#24179;&#20961;&#22495;&#65292;&#24182;&#30740;&#31350;&#20102;&#26041;&#27861;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#20998;&#26512;&#30740;&#31350;&#20102;&#25910;&#25947;&#24615;&#24182;&#22522;&#20110;&#31283;&#23450;&#24615;&#32467;&#26524;&#32473;&#20986;&#20102;&#35823;&#24046;&#20272;&#35745;&#12290;&#25105;&#20204;&#36824;&#23558;&#27492;&#26041;&#27861;&#19982;&#20351;&#29992;&#24809;&#32602;&#32570;&#20047;&#20984;&#24615;&#30340;&#25439;&#22833;&#20989;&#25968;&#20197;&#21450;&#26631;&#20934;&#21069;&#39304;&#32593;&#32476;&#32467;&#21512;&#20351;&#29992;&#30340;&#26367;&#20195;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Monge-Amp\`ere equation is a fully nonlinear partial differential equation (PDE) of fundamental importance in analysis, geometry and in the applied sciences. In this paper we solve the Dirichlet problem associated with the Monge-Amp\`ere equation using neural networks and we show that an ansatz using deep input convex neural networks can be used to find the unique convex solution. As part of our analysis we study the effect of singularities, discontinuities and noise in the source function, we consider nontrivial domains, and we investigate how the method performs in higher dimensions. We investigate the convergence numerically and present error estimates based on a stability result. We also compare this method to an alternative approach in which standard feed-forward networks are used together with a loss function which penalizes lack of convexity.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#38543;&#26426;&#22352;&#26631;&#21464;&#25442;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23618;&#32423;&#24352;&#37327;&#31215;&#23637;&#24320;&#26469;&#36924;&#36817;&#38543;&#26426;&#36807;&#31243;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#22120;&#23545;&#25237;&#24433;&#31995;&#25968;&#36827;&#34892;&#26816;&#27979;&#12290;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#32988;&#36807;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2110.01729</link><description>&lt;p&gt;
&#38543;&#26426;&#22352;&#26631;&#21464;&#25442;&#21450;&#20854;&#22312;&#40065;&#26834;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Stochastic coordinate transformations with applications to robust machine learning. (arXiv:2110.01729v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.01729
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#38543;&#26426;&#22352;&#26631;&#21464;&#25442;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23618;&#32423;&#24352;&#37327;&#31215;&#23637;&#24320;&#26469;&#36924;&#36817;&#38543;&#26426;&#36807;&#31243;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#22120;&#23545;&#25237;&#24433;&#31995;&#25968;&#36827;&#34892;&#26816;&#27979;&#12290;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#32988;&#36807;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#32452;&#26032;&#30340;&#29305;&#24449;&#65292;&#21033;&#29992;Karhunen-Loeve&#23637;&#24320;&#27861;&#26469;&#35782;&#21035;&#36755;&#20837;&#25968;&#25454;&#30340;&#28508;&#22312;&#38543;&#26426;&#34892;&#20026;&#12290;&#36825;&#20123;&#26032;&#29305;&#24449;&#26159;&#36890;&#36807;&#22522;&#20110;&#26368;&#36817;&#30340;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#29702;&#35770;&#36827;&#34892;&#30340;&#22352;&#26631;&#21464;&#25442;&#26500;&#24314;&#30340;&#65292;&#29992;&#20110;&#24322;&#24120;&#26816;&#27979;&#12290;&#30456;&#20851;&#30340;&#20449;&#21495;&#20998;&#35299;&#26159;&#29992;&#24050;&#30693;&#20248;&#21270;&#23646;&#24615;&#30340;&#23618;&#32423;&#24352;&#37327;&#31215;&#23637;&#24320;&#26469;&#36924;&#36817;&#20855;&#26377;&#26377;&#38480;&#21151;&#33021;&#31354;&#38388;&#30340;&#38543;&#26426;&#36807;&#31243;&#65288;&#38543;&#26426;&#22330;&#65289;&#12290;&#21407;&#21017;&#19978;&#65292;&#36825;&#20123;&#20302;&#32500;&#31354;&#38388;&#21487;&#20197;&#25429;&#25417;&#32473;&#23450;&#21517;&#20041;&#31867;&#21035;&#30340;'&#24213;&#23618;&#20449;&#21495;'&#30340;&#22823;&#37096;&#20998;&#38543;&#26426;&#21464;&#21270;&#65292;&#24182;&#19988;&#21487;&#20197;&#23558;&#26469;&#33258;&#20854;&#23427;&#31867;&#21035;&#30340;&#20449;&#21495;&#25298;&#32477;&#20026;&#38543;&#26426;&#24322;&#24120;&#12290;&#36890;&#36807;&#21517;&#20041;&#31867;&#21035;&#30340;&#23618;&#32423;&#26377;&#38480;&#32500;&#23637;&#24320;&#65292;&#26500;&#24314;&#20102;&#19968;&#31995;&#21015;&#29992;&#20110;&#26816;&#27979;&#24322;&#24120;&#20449;&#21495;&#32452;&#20214;&#30340;&#27491;&#20132;&#23884;&#22871;&#23376;&#31354;&#38388;&#12290;&#28982;&#21518;&#20351;&#29992;&#36825;&#20123;&#23376;&#31354;&#38388;&#20013;&#30340;&#25237;&#24433;&#31995;&#25968;&#26469;&#35757;&#32451;&#29992;&#20110;&#24322;&#24120;&#26816;&#27979;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#32467;&#26524;&#34920;&#26126;&#20854;&#32988;&#36807;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we introduce a set of novel features for identifying underlying stochastic behavior of input data using the Karhunen-Loeve expansion. These novel features are constructed by applying a coordinate transformation based on the recent Functional Data Analysis theory for anomaly detection. The associated signal decomposition is an exact hierarchical tensor product expansion with known optimality properties for approximating stochastic processes (random fields) with finite dimensional function spaces. In principle these low dimensional spaces can capture most of the stochastic behavior of `underlying signals' in a given nominal class, and can reject signals in alternative classes as stochastic anomalies. Using a hierarchical finite dimensional expansion of the nominal class, a series of orthogonal nested subspaces is constructed for detecting anomalous signal components. Projection coefficients of input data in these subspaces are then used to train a Machine Learning (ML) clas
&lt;/p&gt;</description></item><item><title>WildWood&#26159;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#26862;&#26519;&#31639;&#27861;&#65292;&#20351;&#29992;&#25351;&#25968;&#26435;&#37325;&#32858;&#21512;&#21253;&#22806;&#26679;&#26412;&#20197;&#25913;&#36827;&#39044;&#27979;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#30452;&#26041;&#22270;&#31574;&#30053;&#21152;&#36895;&#20998;&#35010;&#26597;&#25214;&#65292;&#20855;&#26377;&#27604;&#26631;&#20934;RF&#21644;&#26497;&#38480;&#26799;&#24230;&#25552;&#21319;&#31639;&#27861;&#26356;&#24555;&#21644;&#26356;&#20855;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2109.08010</link><description>&lt;p&gt;
WildWood&#65306;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#26862;&#26519;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
WildWood: a new Random Forest algorithm. (arXiv:2109.08010v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.08010
&lt;/p&gt;
&lt;p&gt;
WildWood&#26159;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#26862;&#26519;&#31639;&#27861;&#65292;&#20351;&#29992;&#25351;&#25968;&#26435;&#37325;&#32858;&#21512;&#21253;&#22806;&#26679;&#26412;&#20197;&#25913;&#36827;&#39044;&#27979;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#30452;&#26041;&#22270;&#31574;&#30053;&#21152;&#36895;&#20998;&#35010;&#26597;&#25214;&#65292;&#20855;&#26377;&#27604;&#26631;&#20934;RF&#21644;&#26497;&#38480;&#26799;&#24230;&#25552;&#21319;&#31639;&#27861;&#26356;&#24555;&#21644;&#26356;&#20855;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;WildWood&#65288;WW&#65289;&#36825;&#31181;&#26032;&#30340;&#29992;&#20110;&#30417;&#30563;&#23398;&#20064;&#30340;&#38598;&#21512;&#31639;&#27861;&#65292;&#37319;&#29992;&#20102;Random Forest&#65288;RF&#65289;&#31867;&#22411;&#12290;&#26631;&#20934;&#30340;RF&#31639;&#27861;&#20351;&#29992;&#33258;&#21161;&#27861;&#26679;&#26412;&#26469;&#35745;&#31639;&#21253;&#22806;&#65288;out-of-bag&#65289;&#20998;&#25968;&#65292;WW&#20351;&#29992;&#36825;&#20123;&#26679;&#26412;&#20135;&#29983;&#25913;&#36827;&#30340;&#39044;&#27979;&#65292;&#32473;&#20986;&#27599;&#20010;&#23436;&#20840;&#29983;&#38271;&#30340;&#26641;&#30340;&#25152;&#26377;&#21487;&#33021;&#23376;&#26641;&#39044;&#27979;&#30340;&#32858;&#21512;&#12290;&#36825;&#26159;&#36890;&#36807;&#20351;&#29992;&#22312;&#21253;&#22806;&#26679;&#26412;&#19978;&#35745;&#31639;&#30340;&#25351;&#25968;&#26435;&#37325;&#32858;&#21512;&#23454;&#29616;&#30340;&#65292;&#36825;&#20123;&#26679;&#26412;&#30001;&#31216;&#20026;&#19978;&#19979;&#25991;&#26641;&#21152;&#26435;&#65288;context tree weighting&#65289;&#30340;&#31639;&#27861;&#31934;&#30830;&#19988;&#39640;&#25928;&#22320;&#35745;&#31639;&#20986;&#26469;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#19982;&#20854;&#20182;&#25104;&#29087;&#30340;&#38598;&#21512;&#26041;&#27861;&#65292;&#22914;&#26631;&#20934;RF&#21644;&#26497;&#38480;&#26799;&#24230;&#25552;&#21319;&#65288;extreme gradient boosting&#65289;&#31639;&#27861;&#30456;&#27604;&#65292;WildWoods&#24555;&#36895;&#19988;&#20855;&#26377;&#31454;&#20105;&#21147;&#65292;&#20854;&#20013;&#21253;&#25324;&#37319;&#29992;&#21152;&#36895;&#20998;&#35010;&#26597;&#25214;&#30340;&#30452;&#26041;&#22270;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce WildWood (WW), a new ensemble algorithm for supervised learning of Random Forest (RF) type. While standard RF algorithms use bootstrap out-of-bag samples to compute out-of-bag scores, WW uses these samples to produce improved predictions given by an aggregation of the predictions of all possible subtrees of each fully grown tree in the forest. This is achieved by aggregation with exponential weights computed over out-of-bag samples, that are computed exactly and very efficiently thanks to an algorithm called context tree weighting. This improvement, combined with a histogram strategy to accelerate split finding, makes WW fast and competitive compared with other well-established ensemble methods, such as standard RF and extreme gradient boosting algorithms.
&lt;/p&gt;</description></item><item><title>&#22522;&#20110;&#36172;&#21338;&#26426;&#30340;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#24179;&#34913;&#25506;&#32034;&#21644;&#21033;&#29992;&#65292;&#23454;&#29616;&#23545;&#19968;&#32452;&#20256;&#24863;&#22120;&#30340;&#26368;&#24555;&#21464;&#28857;&#26816;&#27979;&#65292;&#20174;&#32780;&#33410;&#30465;&#36164;&#28304;&#21644;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2107.10492</link><description>&lt;p&gt;
&#24322;&#24120;&#26368;&#24555;&#21464;&#28857;&#26816;&#27979;&#20013;&#30340;&#36172;&#21338;&#26426;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Bandit Quickest Changepoint Detection. (arXiv:2107.10492v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.10492
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#36172;&#21338;&#26426;&#30340;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#24179;&#34913;&#25506;&#32034;&#21644;&#21033;&#29992;&#65292;&#23454;&#29616;&#23545;&#19968;&#32452;&#20256;&#24863;&#22120;&#30340;&#26368;&#24555;&#21464;&#28857;&#26816;&#27979;&#65292;&#20174;&#32780;&#33410;&#30465;&#36164;&#28304;&#21644;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#24037;&#19994;&#21644;&#23433;&#20840;&#24212;&#29992;&#31243;&#24207;&#20351;&#29992;&#19968;&#32452;&#20256;&#24863;&#22120;&#26469;&#26816;&#27979;&#26102;&#38388;&#34892;&#20026;&#27169;&#24335;&#20013;&#30340;&#31361;&#21464;&#12290;&#36825;&#20123;&#31361;&#21464;&#36890;&#24120;&#22312;&#23616;&#37096;&#34920;&#29616;&#20986;&#26469;&#65292;&#20165;&#20351;&#19968;&#23567;&#37096;&#20998;&#20256;&#24863;&#22120;&#26377;&#20449;&#24687;&#12290;&#30001;&#20110;&#36164;&#28304;&#38480;&#21046;&#65292;&#30417;&#25511;&#27599;&#20010;&#20256;&#24863;&#22120;&#21487;&#33021;&#24456;&#26114;&#36149;&#65292;&#36825;&#26159;&#36827;&#34892;&#36172;&#21338;&#26426;&#26368;&#24555;&#21464;&#28857;&#26816;&#27979;&#38382;&#39064;&#30340;&#21160;&#26426;&#65292;&#20854;&#20013;&#36873;&#25321;&#19968;&#31995;&#21015;&#20256;&#24863;&#21160;&#20316;&#65288;&#25110;&#20256;&#24863;&#22120;&#65289;&#65292;&#24182;&#19988;&#21482;&#35266;&#23519;&#19982;&#25152;&#36873;&#21160;&#20316;&#23545;&#24212;&#30340;&#27979;&#37327;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#26377;&#38480;&#21442;&#25968;&#27010;&#29575;&#20998;&#24067;&#31867;&#21035;&#30340;&#26816;&#27979;&#24310;&#36831;&#30340;&#20449;&#24687;&#29702;&#35770;&#19979;&#30028;&#12290;&#25105;&#20204;&#38543;&#21518;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#26377;&#25928;&#30340;&#22312;&#32447;&#24863;&#30693;&#26041;&#26696;&#65292;&#23427;&#26080;&#32541;&#24179;&#34913;&#20102;&#23545;&#19981;&#21516;&#20256;&#24863;&#36873;&#39033;&#30340;&#25506;&#32034;&#38656;&#27714;&#19982;&#35810;&#38382;&#20449;&#24687;&#21160;&#20316;&#30340;&#21033;&#29992;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#25152;&#25552;&#20986;&#26041;&#26696;&#30340;&#39044;&#26399;&#24310;&#36831;&#30028;&#38480;&#65292;&#21516;&#26102;&#35777;&#26126;&#20102;&#36825;&#20123;&#30028;&#38480;&#19982;&#25105;&#20204;&#30340;&#20449;&#24687;&#29702;&#35770;&#19979;&#30028;&#22312;&#20302;&#32500;&#31354;&#38388;&#30340;&#21305;&#37197;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many industrial and security applications employ a suite of sensors for detecting abrupt changes in temporal behavior patterns. These abrupt changes typically manifest locally, rendering only a small subset of sensors informative. Continuous monitoring of every sensor can be expensive due to resource constraints, and serves as a motivation for the bandit quickest changepoint detection problem, where sensing actions (or sensors) are sequentially chosen, and only measurements corresponding to chosen actions are observed. We derive an information-theoretic lower bound on the detection delay for a general class of finitely parameterized probability distributions. We then propose a computationally efficient online sensing scheme, which seamlessly balances the need for exploration of different sensing options with exploitation of querying informative actions. We derive expected delay bounds for the proposed scheme and show that these bounds match our information-theoretic lower bounds at low
&lt;/p&gt;</description></item><item><title>&#26680;&#32454;&#21270;&#26159;&#19968;&#31181;&#26356;&#26377;&#25928;&#30340;&#21387;&#32553;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#23558;$n$&#28857;&#36817;&#20284;&#30340;&#20998;&#24067;&#21387;&#32553;&#21040;&#20855;&#26377;&#21487;&#27604;&#36739;&#26368;&#22351;&#31215;&#20998;&#35823;&#24046;&#30340;$\sqrt{n}$&#28857;&#36817;&#20284;&#65292;&#20854;&#20122;&#25351;&#25968;&#20445;&#35777;&#31867;&#20284;&#20110;&#22312;$[0,1]^d$&#19978;&#22343;&#21248;$\mathbb{P}$&#30340;&#32463;&#20856;&#20934;&#33945;&#29305;&#21345;&#32599;&#35823;&#24046;&#29575;&#65292;&#20294;&#36866;&#29992;&#20110;$\mathbb{R}^d$&#19978;&#30340;&#19968;&#33324;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2105.05842</link><description>&lt;p&gt;
&#26680;&#32454;&#21270;
&lt;/p&gt;
&lt;p&gt;
Kernel Thinning. (arXiv:2105.05842v9 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.05842
&lt;/p&gt;
&lt;p&gt;
&#26680;&#32454;&#21270;&#26159;&#19968;&#31181;&#26356;&#26377;&#25928;&#30340;&#21387;&#32553;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#23558;$n$&#28857;&#36817;&#20284;&#30340;&#20998;&#24067;&#21387;&#32553;&#21040;&#20855;&#26377;&#21487;&#27604;&#36739;&#26368;&#22351;&#31215;&#20998;&#35823;&#24046;&#30340;$\sqrt{n}$&#28857;&#36817;&#20284;&#65292;&#20854;&#20122;&#25351;&#25968;&#20445;&#35777;&#31867;&#20284;&#20110;&#22312;$[0,1]^d$&#19978;&#22343;&#21248;$\mathbb{P}$&#30340;&#32463;&#20856;&#20934;&#33945;&#29305;&#21345;&#32599;&#35823;&#24046;&#29575;&#65292;&#20294;&#36866;&#29992;&#20110;$\mathbb{R}^d$&#19978;&#30340;&#19968;&#33324;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#26680;&#32454;&#21270;&#65292;&#19968;&#31181;&#27604;&#29420;&#31435;&#21516;&#20998;&#24067;&#37319;&#26679;&#25110;&#26631;&#20934;&#32454;&#21270;&#26356;&#26377;&#25928;&#22320;&#21387;&#32553;&#20998;&#24067;$\mathbb{P}$&#30340;&#26032;&#26041;&#27861;&#12290;&#32473;&#23450;&#19968;&#20010;&#21512;&#36866;&#30340;&#20877;&#29983;&#26680;$\mathbf{k}_{\star}$&#21644;$\mathcal{O}(n^2)$&#26102;&#38388;&#65292;&#26680;&#32454;&#21270;&#23558;&#19968;&#20010;$n$&#28857;&#36817;&#20284;&#30340;$\mathbb{P}$&#21387;&#32553;&#25104;&#19968;&#20010;&#20855;&#26377;&#19982;&#30456;&#20851;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#21487;&#27604;&#36739;&#26368;&#22351;&#31215;&#20998;&#35823;&#24046;&#30340;$\sqrt{n}$&#28857;&#36817;&#20284;&#12290;&#22312;&#27010;&#29575;&#19978;&#65292;&#32039;&#25903;&#25745;&#30340;$\mathbb{P}$&#30340;&#31215;&#20998;&#35823;&#24046;&#26368;&#22823;&#24046;&#21035;&#20026;$\mathcal{O}_d(n^{-1/2}\sqrt{\log n})$&#65292;&#22312;$\mathbb{R}^d$&#19978;&#30340;&#20122;&#25351;&#25968;$\mathbb{P}$&#20026;$\mathcal{O}_d(n^{-\frac{1}{2}} (\log n)^{(d+1)/2}\sqrt{\log\log n})$&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#26469;&#33258;$\mathbb{P}$&#30340;&#31561;&#22823;&#23567;i.i.d.&#26679;&#26412;&#38754;&#20020;$\Omega(n^{-1/4})$&#30340;&#31215;&#20998;&#35823;&#24046;&#12290;&#25105;&#20204;&#30340;&#20122;&#25351;&#25968;&#20445;&#35777;&#31867;&#20284;&#20110;&#22312;$[0,1]^d$&#19978;&#22343;&#21248;$\mathbb{P}$&#30340;&#32463;&#20856;&#20934;&#33945;&#29305;&#21345;&#32599;&#35823;&#24046;&#29575;&#65292;&#20294;&#36866;&#29992;&#20110;$\mathbb{R}^d$&#19978;&#30340;&#19968;&#33324;&#20998;&#24067;&#21644;&#19968;&#20010;&#22823;
&lt;/p&gt;
&lt;p&gt;
We introduce kernel thinning, a new procedure for compressing a distribution $\mathbb{P}$ more effectively than i.i.d. sampling or standard thinning. Given a suitable reproducing kernel $\mathbf{k}_{\star}$ and $\mathcal{O}(n^2)$ time, kernel thinning compresses an $n$-point approximation to $\mathbb{P}$ into a $\sqrt{n}$-point approximation with comparable worst-case integration error across the associated reproducing kernel Hilbert space. The maximum discrepancy in integration error is $\mathcal{O}_d(n^{-1/2}\sqrt{\log n})$ in probability for compactly supported $\mathbb{P}$ and $\mathcal{O}_d(n^{-\frac{1}{2}} (\log n)^{(d+1)/2}\sqrt{\log\log n})$ for sub-exponential $\mathbb{P}$ on $\mathbb{R}^d$. In contrast, an equal-sized i.i.d. sample from $\mathbb{P}$ suffers $\Omega(n^{-1/4})$ integration error. Our sub-exponential guarantees resemble the classical quasi-Monte Carlo error rates for uniform $\mathbb{P}$ on $[0,1]^d$ but apply to general distributions on $\mathbb{R}^d$ and a wid
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#25193;&#23637;I-prior&#26041;&#27861;&#20197;&#35299;&#20915;&#21152;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#20132;&#20114;&#20316;&#29992;&#30340;&#25361;&#25112;&#65292;&#35813;&#26041;&#27861;&#29702;&#35770;&#21644;&#23454;&#36341;&#19978;&#37117;&#27604;&#20854;&#20182;&#26041;&#27861;&#26356;&#20248;&#65292;&#21487;&#20197;&#20351;&#29992;EM&#31639;&#27861;&#20272;&#35745;&#23610;&#24230;&#21442;&#25968;&#65292;&#24182;&#25552;&#20986;&#20102;&#20132;&#20114;&#27169;&#22411;&#30340;&#31616;&#26126;&#35268;&#33539;&#12290;</title><link>http://arxiv.org/abs/2007.15766</link><description>&lt;p&gt;
&#20351;&#29992;I-priors&#36827;&#34892;&#21152;&#24615;&#20132;&#20114;&#20316;&#29992;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Additive interaction modelling using I-priors. (arXiv:2007.15766v4 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2007.15766
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#25193;&#23637;I-prior&#26041;&#27861;&#20197;&#35299;&#20915;&#21152;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#20132;&#20114;&#20316;&#29992;&#30340;&#25361;&#25112;&#65292;&#35813;&#26041;&#27861;&#29702;&#35770;&#21644;&#23454;&#36341;&#19978;&#37117;&#27604;&#20854;&#20182;&#26041;&#27861;&#26356;&#20248;&#65292;&#21487;&#20197;&#20351;&#29992;EM&#31639;&#27861;&#20272;&#35745;&#23610;&#24230;&#21442;&#25968;&#65292;&#24182;&#25552;&#20986;&#20102;&#20132;&#20114;&#27169;&#22411;&#30340;&#31616;&#26126;&#35268;&#33539;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21152;&#24615;&#22238;&#24402;&#27169;&#22411;&#19982;&#20132;&#20114;&#20316;&#29992;&#22312;&#25991;&#29486;&#20013;&#24471;&#21040;&#24191;&#27867;&#30740;&#31350;&#65292;&#37319;&#29992;&#20102;&#26679;&#26465;&#25110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#31561;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23384;&#22312;&#35768;&#22810;&#24179;&#28369;&#21442;&#25968;&#24182;&#19988;&#32570;&#20047;&#21512;&#36866;&#30340;&#20934;&#21017;&#65292;&#36825;&#20123;&#26041;&#27861;&#21487;&#33021;&#20250;&#23545;&#20272;&#35745;&#21644;&#27169;&#22411;&#36873;&#25321;&#26500;&#25104;&#25361;&#25112;&#12290;&#26412;&#25991;&#25552;&#20986;&#36890;&#36807;&#23558;I-prior&#26041;&#27861;&#65288;Bergsma&#65292;2020&#65289;&#25193;&#23637;&#21040;&#22810;&#20010;&#21487;&#33021;&#20026;&#22810;&#32500;&#30340;&#21327;&#21464;&#37327;&#26469;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#12290;I-prior&#26041;&#27861;&#22312;&#29702;&#35770;&#21644;&#23454;&#36341;&#19978;&#37117;&#27604;&#20854;&#20182;&#26041;&#27861;&#65288;&#22914;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#21644;Tikhonov&#27491;&#21017;&#21270;&#65289;&#20855;&#26377;&#19968;&#20123;&#20248;&#21183;&#12290;&#29305;&#21035;&#22320;&#65292;I-prior&#26159;&#19968;&#20010;&#36866;&#24403;&#30340;&#20808;&#39564;&#65292;&#22522;&#20110;&#26368;&#23569;&#30340;&#20551;&#35774;&#65292;&#20135;&#29983;&#19968;&#20010;&#21487;&#25509;&#21463;&#30340;&#21518;&#39564;&#22343;&#20540;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#20855;&#26377;&#31616;&#21333;E&#21644;M&#27493;&#30340;EM&#31639;&#27861;&#26469;&#20272;&#35745;&#23610;&#24230;&#65288;&#25110;&#24179;&#28369;&#65289;&#21442;&#25968;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#20132;&#20114;&#27169;&#22411;&#30340;&#31616;&#26126;&#35268;&#33539;&#65292;&#23427;&#20855;&#26377;&#20004;&#20010;&#22909;&#22788;&#65306;&#65288;i&#65289;&#23427;&#38477;&#20302;&#20102;&#23610;&#24230;&#21442;&#25968;&#30340;&#25968;&#37327;
&lt;/p&gt;
&lt;p&gt;
Additive regression models with interactions are widely studied in the literature, using methods such as splines or Gaussian process regression. However, these methods can pose challenges for estimation and model selection, due to the presence of many smoothing parameters and the lack of suitable criteria. We propose to address these challenges by extending the I-prior methodology (Bergsma, 2020) to multiple covariates, which may be multidimensional. The I-prior methodology has some advantages over other methods, such as Gaussian process regression and Tikhonov regularization, both theoretically and practically. In particular, the I-prior is a proper prior, is based on minimal assumptions, yields an admissible posterior mean, and estimation of the scale (or smoothing) parameters can be done using an EM algorithm with simple E and M steps. Moreover, we introduce a parsimonious specification of models with interactions, which has two benefits: (i) it reduces the number of scale parameter
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#30340;&#20869;&#26680;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#20572;&#27490;&#20934;&#21017;&#65292;&#20351;&#29992;&#32463;&#39564;&#26377;&#25928;&#32500;&#24230;&#26469;&#37327;&#21270;&#22686;&#37327;&#24182;&#25512;&#23548;&#20986;&#21487;&#25191;&#34892;&#30340;&#25552;&#21069;&#20572;&#27490;&#31574;&#30053;&#12290;&#36890;&#36807;&#20351;&#29992;&#31215;&#20998;&#31639;&#23376;&#26041;&#27861;&#24471;&#20986;&#35777;&#26126;&#65292;&#35268;&#21017;&#20855;&#26377;&#20248;&#21270;&#23398;&#20064;&#36895;&#29575;&#30340;&#26368;&#20248;&#24615;&#65292;&#24182;&#19988;&#25552;&#20986;&#30340;&#20572;&#27490;&#31574;&#30053;&#20855;&#26377;&#35745;&#31639;&#19978;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2001.02879</link><description>&lt;p&gt;
&#22522;&#20110;&#20869;&#26680;&#30340;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#33258;&#36866;&#24212;&#20572;&#27490;&#20934;&#21017;
&lt;/p&gt;
&lt;p&gt;
Adaptive Stopping Rule for Kernel-based Gradient Descent Algorithms. (arXiv:2001.02879v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2001.02879
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#30340;&#20869;&#26680;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#20572;&#27490;&#20934;&#21017;&#65292;&#20351;&#29992;&#32463;&#39564;&#26377;&#25928;&#32500;&#24230;&#26469;&#37327;&#21270;&#22686;&#37327;&#24182;&#25512;&#23548;&#20986;&#21487;&#25191;&#34892;&#30340;&#25552;&#21069;&#20572;&#27490;&#31574;&#30053;&#12290;&#36890;&#36807;&#20351;&#29992;&#31215;&#20998;&#31639;&#23376;&#26041;&#27861;&#24471;&#20986;&#35777;&#26126;&#65292;&#35268;&#21017;&#20855;&#26377;&#20248;&#21270;&#23398;&#20064;&#36895;&#29575;&#30340;&#26368;&#20248;&#24615;&#65292;&#24182;&#19988;&#25552;&#20986;&#30340;&#20572;&#27490;&#31574;&#30053;&#20855;&#26377;&#35745;&#31639;&#19978;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#20869;&#26680;&#30340;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#33258;&#36866;&#24212;&#20572;&#27490;&#20934;&#21017;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#32463;&#39564;&#26377;&#25928;&#32500;&#24230;&#26469;&#37327;&#21270;KGD&#36845;&#20195;&#30340;&#22686;&#37327;&#24182;&#25512;&#23548;&#20986;&#21487;&#23454;&#26045;&#30340;&#25552;&#21069;&#20572;&#27490;&#31574;&#30053;&#12290;&#25105;&#20204;&#22312;&#23398;&#20064;&#29702;&#35770;&#26694;&#26550;&#19979;&#20998;&#26512;&#20102;&#33258;&#36866;&#24212;&#20572;&#27490;&#20934;&#21017;&#30340;&#24615;&#33021;&#12290;&#20351;&#29992;&#26368;&#36817;&#21457;&#23637;&#30340;&#31215;&#20998;&#31639;&#23376;&#26041;&#27861;&#65292;&#25105;&#20204;&#20005;&#26684;&#35777;&#26126;&#20102;&#37197;&#22791;&#27492;&#35268;&#21017;&#30340;KGD&#30340;&#26368;&#20248;&#23398;&#20064;&#36895;&#29575;&#30340;&#26368;&#20248;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#32473;&#20986;&#20102;&#37197;&#22791;&#25152;&#36848;&#25552;&#21069;&#20572;&#27490;&#35268;&#21017;&#30340;KGD&#30340;&#36845;&#20195;&#27425;&#25968;&#30340;&#23574;&#38160;&#30028;&#38480;&#65292;&#20197;&#35828;&#26126;&#20854;&#35745;&#31639;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose an adaptive stopping rule for kernel-based gradient descent (KGD) algorithms. We introduce the empirical effective dimension to quantify the increments of iterations in KGD and derive an implementable early stopping strategy. We analyze the performance of the adaptive stopping rule in the framework of learning theory. Using the recently developed integral operator approach, we rigorously prove the optimality of the adaptive stopping rule in terms of showing the optimal learning rates for KGD equipped with this rule. Furthermore, a sharp bound on the number of iterations in KGD equipped with the proposed early stopping rule is also given to demonstrate its computational advantage.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21160;&#24577;&#35780;&#20272;&#23454;&#20307;&#30456;&#20851;&#24615;&#65292;&#21033;&#29992;&#38598;&#20307;&#27880;&#24847;&#20316;&#20026;&#30417;&#30563;&#65292;&#33021;&#23398;&#20064;&#21040;&#20016;&#23500;&#32780;&#19981;&#21516;&#30340;&#23454;&#20307;&#34920;&#31034;&#65292;&#33021;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#27604;&#31454;&#20105;&#22522;&#32447;&#33719;&#24471;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/1808.08316</link><description>&lt;p&gt;
&#19968;&#31181;&#19977;&#20803;&#31070;&#32463;&#27169;&#22411;&#29992;&#20110;&#21160;&#24577;&#23454;&#20307;&#30456;&#20851;&#24615;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
A Trio Neural Model for Dynamic Entity Relatedness Ranking. (arXiv:1808.08316v4 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1808.08316
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21160;&#24577;&#35780;&#20272;&#23454;&#20307;&#30456;&#20851;&#24615;&#65292;&#21033;&#29992;&#38598;&#20307;&#27880;&#24847;&#20316;&#20026;&#30417;&#30563;&#65292;&#33021;&#23398;&#20064;&#21040;&#20016;&#23500;&#32780;&#19981;&#21516;&#30340;&#23454;&#20307;&#34920;&#31034;&#65292;&#33021;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#27604;&#31454;&#20105;&#22522;&#32447;&#33719;&#24471;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27979;&#37327;&#23454;&#20307;&#30456;&#20851;&#24615;&#26159;&#35768;&#22810;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#20449;&#24687;&#26816;&#32034;&#24212;&#29992;&#30340;&#22522;&#26412;&#20219;&#21153;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#36890;&#24120;&#22312;&#38745;&#24577;&#35774;&#32622;&#21644;&#38750;&#30417;&#30563;&#26041;&#24335;&#19979;&#30740;&#31350;&#23454;&#20307;&#30456;&#20851;&#24615;&#12290;&#28982;&#32780;&#65292;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#23454;&#20307;&#24448;&#24448;&#28041;&#21450;&#35768;&#22810;&#19981;&#21516;&#30340;&#20851;&#31995;&#65292;&#22240;&#27492;&#23454;&#20307;&#20851;&#31995;&#38543;&#26102;&#38388;&#21464;&#24471;&#38750;&#24120;&#21160;&#24577;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#26469;&#21160;&#24577;&#35780;&#20272;&#23454;&#20307;&#30456;&#20851;&#24615;&#65292;&#21033;&#29992;&#38598;&#20307;&#27880;&#24847;&#21147;&#20316;&#20026;&#30417;&#30563;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#33021;&#22815;&#22312;&#32852;&#21512;&#26694;&#26550;&#20013;&#23398;&#20064;&#20016;&#23500;&#32780;&#19981;&#21516;&#30340;&#23454;&#20307;&#34920;&#31034;&#12290;&#36890;&#36807;&#23545;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#30340;&#24191;&#27867;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#27604;&#31454;&#20105;&#22522;&#32447;&#33719;&#24471;&#20102;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Measuring entity relatedness is a fundamental task for many natural language processing and information retrieval applications. Prior work often studies entity relatedness in static settings and an unsupervised manner. However, entities in real-world are often involved in many different relationships, consequently entity-relations are very dynamic over time. In this work, we propose a neural networkbased approach for dynamic entity relatedness, leveraging the collective attention as supervision. Our model is capable of learning rich and different entity representations in a joint framework. Through extensive experiments on large-scale datasets, we demonstrate that our method achieves better results than competitive baselines.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#38543;&#26426;&#23454;&#39564;&#20013;&#20272;&#31639;&#21644;&#25512;&#26029;&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#24212;&#30340;&#20851;&#38190;&#29305;&#24449;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#21360;&#24230;&#20813;&#30123;&#35745;&#21010;&#30340;&#25968;&#25454;&#20013;&#65292;&#33719;&#24471;&#26377;&#25928;&#25512;&#26029;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/1712.04802</link><description>&lt;p&gt;
Fischer-Schultz &#35762;&#24231;&#65306;&#38543;&#26426;&#23454;&#39564;&#20013;&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#24212;&#30340;&#36890;&#29992;&#26426;&#22120;&#23398;&#20064;&#25512;&#26029;&#65292;&#20197;&#21360;&#24230;&#20813;&#30123;&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
Fischer-Schultz Lecture: Generic Machine Learning Inference on Heterogenous Treatment Effects in Randomized Experiments, with an Application to Immunization in India. (arXiv:1712.04802v7 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1712.04802
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#38543;&#26426;&#23454;&#39564;&#20013;&#20272;&#31639;&#21644;&#25512;&#26029;&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#24212;&#30340;&#20851;&#38190;&#29305;&#24449;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#21360;&#24230;&#20813;&#30123;&#35745;&#21010;&#30340;&#25968;&#25454;&#20013;&#65292;&#33719;&#24471;&#26377;&#25928;&#25512;&#26029;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31574;&#30053;&#65292;&#29992;&#20110;&#22312;&#38543;&#26426;&#23454;&#39564;&#20013;&#20272;&#31639;&#21644;&#25512;&#26029;&#24322;&#36136;&#24615;&#25928;&#24212;&#30340;&#20851;&#38190;&#29305;&#24449;&#12290;&#36825;&#20123;&#20851;&#38190;&#29305;&#24449;&#21253;&#25324;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#20195;&#29702;&#30340;&#25928;&#24212;&#30340;&#26368;&#20339;&#32447;&#24615;&#39044;&#27979;&#22120;&#65292;&#25353;&#24433;&#21709;&#32452;&#25490;&#24207;&#30340;&#24179;&#22343;&#25928;&#24212;&#20197;&#21450;&#26368;&#21463;&#24433;&#21709;&#21333;&#20301;&#30340;&#24179;&#22343;&#29305;&#24449;&#21644;&#26368;&#19981;&#21463;&#24433;&#21709;&#30340;&#21333;&#20301;&#12290;&#35813;&#26041;&#27861;&#22312;&#39640;&#32500;&#35774;&#32622;&#20013;&#26377;&#25928;&#65292;&#20854;&#20013;&#25928;&#24212;&#30001;&#39044;&#27979;&#21644;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#20195;&#29702;&#65288;&#20294;&#19981;&#19968;&#23450;&#26159;&#19968;&#33268;&#20272;&#35745;&#30340;&#65289;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#20195;&#29702;&#21518;&#22788;&#29702;&#25104;&#20851;&#38190;&#29305;&#24449;&#30340;&#20272;&#35745;&#20540;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#36890;&#29992;&#30340;&#65292;&#21487;&#20197;&#19982;&#26377;&#24809;&#32602;&#30340;&#26041;&#27861;&#65292;&#31070;&#32463;&#32593;&#32476;&#65292;&#38543;&#26426;&#26862;&#26519;&#65292;&#25552;&#21319;&#26641;&#21644;&#38598;&#25104;&#26041;&#27861;&#19968;&#36215;&#20351;&#29992;&#65292;&#26082;&#21487;&#20197;&#36827;&#34892;&#39044;&#27979;&#20063;&#21487;&#20197;&#36827;&#34892;&#22240;&#26524;&#20998;&#26512;&#12290;&#20272;&#35745;&#21644;&#25512;&#26029;&#22522;&#20110;&#37325;&#22797;&#25968;&#25454;&#20998;&#21106;&#65292;&#20197;&#36991;&#20813;&#36807;&#24230;&#25311;&#21512;&#24182;&#23454;&#29616;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#32467;&#26524;&#30340;&#20998;&#20301;&#32858;&#21512;&#26469;&#33258;&#35768;&#22810;&#28508;&#22312;&#30340;&#20998;&#21106;&#65292;&#29305;&#21035;&#26159;&#21462;p&#20540;&#30340;&#20013;&#20301;&#25968;&#21644;&#32622;&#20449;&#21306;&#38388;&#30340;&#20013;&#20301;&#25968;&#21644;&#20854;&#20182;&#20998;&#20301;&#25968;&#12290;&#25105;&#20204;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#21360;&#24230;&#19968;&#39033;&#22823;&#22411;&#20813;&#30123;&#35745;&#21010;&#30340;&#25968;&#25454;&#20013;&#65292;&#20272;&#35745;&#20813;&#30123;&#23545;&#20799;&#31461;&#21457;&#30149;&#29575;&#21644;&#27515;&#20129;&#29575;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#39640;&#32500;&#24230;&#65292;&#24322;&#36136;&#24615;&#22788;&#29702;&#35774;&#32622;&#20013;&#20135;&#29983;&#26377;&#25928;&#30340;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose strategies to estimate and make inference on key features of heterogeneous effects in randomized experiments. These key features include best linear predictors of the effects using machine learning proxies, average effects sorted by impact groups, and average characteristics of most and least impacted units. The approach is valid in high dimensional settings, where the effects are proxied (but not necessarily consistently estimated) by predictive and causal machine learning methods. We post-process these proxies into estimates of the key features. Our approach is generic, it can be used in conjunction with penalized methods, neural networks, random forests, boosted trees, and ensemble methods, both predictive and causal. Estimation and inference are based on repeated data splitting to avoid overfitting and achieve validity. We use quantile aggregation of the results across many potential splits, in particular taking medians of p-values and medians and other quantiles of conf
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#29305;&#23450;&#30340;&#26680;&#20989;&#25968;&#31867;&#20013;&#65292;$l^{q}$ &#27491;&#21017;&#21270;&#23398;&#20064;&#22312;&#19981;&#21516;&#38454;&#25968; $q$ &#19979;&#37117;&#20855;&#26377;&#30456;&#20284;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/1307.6616</link><description>&lt;p&gt;
$l^q$&#27491;&#21017;&#21270;&#23398;&#20064;&#30340;&#27867;&#21270;&#24615;&#33021;&#26159;&#21542;&#20381;&#36182;&#20110;$q$&#65311;&#19968;&#20010;&#21542;&#23450;&#30340;&#20363;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;
Does generalization performance of $l^q$ regularization learning depend on $q$? A negative example. (arXiv:1307.6616v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1307.6616
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#29305;&#23450;&#30340;&#26680;&#20989;&#25968;&#31867;&#20013;&#65292;$l^{q}$ &#27491;&#21017;&#21270;&#23398;&#20064;&#22312;&#19981;&#21516;&#38454;&#25968; $q$ &#19979;&#37117;&#20855;&#26377;&#30456;&#20284;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
$l^q$-&#27491;&#21017;&#21270;&#24050;&#32463;&#34987;&#35777;&#26126;&#26159;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#24314;&#27169;&#20013;&#19968;&#31181;&#26377;&#21560;&#24341;&#21147;&#30340;&#25216;&#26415;&#12290;&#23427;&#36890;&#36807;&#36866;&#24403;&#32553;&#23567;&#31995;&#25968;&#26469;&#25552;&#39640;&#26426;&#22120;&#65288;&#27169;&#22411;&#65289;&#30340;&#27867;&#21270;&#65288;&#39044;&#27979;&#65289;&#33021;&#21147;&#12290;&#22312;&#19981;&#21516;&#30340;&#27491;&#21017;&#21270;&#38454;&#25968; $q$ &#36873;&#25321;&#19979;&#65292;$l^q$ &#20272;&#35745;&#22120;&#30340;&#24418;&#29366;&#19981;&#21516;&#12290;&#29305;&#21035;&#22320;&#65292;$l^1$ &#23548;&#33268; LASSO &#20272;&#35745;&#65292;&#32780; $l^{2}$ &#23545;&#24212;&#20110;&#24179;&#28369;&#30340;&#23725;&#22238;&#24402;&#12290;&#36825;&#20351;&#24471;&#38454;&#25968; $q$ &#25104;&#20026;&#24212;&#29992;&#20013;&#30340;&#19968;&#20010;&#28508;&#22312;&#35843;&#21442;&#21442;&#25968;&#12290;&#20026;&#20102;&#20419;&#36827; $l^{q}$-&#27491;&#21017;&#21270;&#30340;&#20351;&#29992;&#65292;&#25105;&#20204;&#25171;&#31639;&#23547;&#25214;&#19968;&#31181;&#24314;&#27169;&#31574;&#30053;&#65292;&#21487;&#20197;&#36991;&#20813;&#22312; $q$ &#19978;&#36827;&#34892;&#31934;&#32454;&#30340;&#36873;&#25321;&#12290;&#22312;&#36825;&#26679;&#30340;&#31934;&#31070;&#19979;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#30740;&#31350;&#32622;&#20110;&#19968;&#20010;&#26679;&#26412;&#30456;&#20851;&#20551;&#35774;&#31354;&#38388;&#65288;SDHS&#65289;&#19979;&#30340; $l^{q}$-&#27491;&#21017;&#21270;&#26680;&#23398;&#20064;&#30340;&#19968;&#33324;&#26694;&#26550;&#20013;&#12290;&#23545;&#20110;&#19968;&#31867;&#25351;&#23450;&#30340;&#26680;&#20989;&#25968;&#65292;&#22312; $0&lt;q&lt;\infty$ &#30340;&#25152;&#26377; $l^{q}$ &#20272;&#35745;&#20540;&#37117;&#20855;&#26377;&#31867;&#20284;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#12290;&#36825;&#20123;&#20272;&#35745;&#36793;&#30028;&#26159;&#19968;&#20010;...
&lt;/p&gt;
&lt;p&gt;
$l^q$-regularization has been demonstrated to be an attractive technique in machine learning and statistical modeling. It attempts to improve the generalization (prediction) capability of a machine (model) through appropriately shrinking its coefficients. The shape of a $l^q$ estimator differs in varying choices of the regularization order $q$. In particular, $l^1$ leads to the LASSO estimate, while $l^{2}$ corresponds to the smooth ridge regression. This makes the order $q$ a potential tuning parameter in applications. To facilitate the use of $l^{q}$-regularization, we intend to seek for a modeling strategy where an elaborative selection on $q$ is avoidable. In this spirit, we place our investigation within a general framework of $l^{q}$-regularized kernel learning under a sample dependent hypothesis space (SDHS). For a designated class of kernel functions, we show that all $l^{q}$ estimators for $0&lt; q &lt; \infty$ attain similar generalization error bounds. These estimated bounds are a
&lt;/p&gt;</description></item></channel></rss>