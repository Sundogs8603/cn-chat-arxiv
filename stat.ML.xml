<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#22810;&#21464;&#37327;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#22312;Banach&#31354;&#38388;&#30340;&#20248;&#21270;&#24615;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#31867;&#26032;&#30340;Banach&#31354;&#38388;&#23478;&#26063;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#23398;&#20064;&#38382;&#39064;&#30340;&#35299;&#38598;&#23436;&#20840;&#30001;&#20855;&#26377;&#22810;&#21464;&#37327;&#38750;&#32447;&#24615;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#26469;&#25551;&#36848;&#12290;&#36825;&#20123;&#26368;&#20248;&#26550;&#26500;&#20855;&#26377;&#36339;&#36291;&#36830;&#25509;&#65292;&#24182;&#19982;&#27491;&#20132;&#26435;&#37325;&#24402;&#19968;&#21270;&#21644;&#22810;&#32034;&#24341;&#27169;&#22411;&#23494;&#20999;&#30456;&#20851;&#12290;</title><link>http://arxiv.org/abs/2310.03696</link><description>&lt;p&gt;
&#20855;&#26377;&#22810;&#21464;&#37327;&#38750;&#32447;&#24615;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;Banach&#31354;&#38388;&#20248;&#21270;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Banach Space Optimality of Neural Architectures With Multivariate Nonlinearities. (arXiv:2310.03696v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03696
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#22810;&#21464;&#37327;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#22312;Banach&#31354;&#38388;&#30340;&#20248;&#21270;&#24615;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#31867;&#26032;&#30340;Banach&#31354;&#38388;&#23478;&#26063;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#23398;&#20064;&#38382;&#39064;&#30340;&#35299;&#38598;&#23436;&#20840;&#30001;&#20855;&#26377;&#22810;&#21464;&#37327;&#38750;&#32447;&#24615;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#26469;&#25551;&#36848;&#12290;&#36825;&#20123;&#26368;&#20248;&#26550;&#26500;&#20855;&#26377;&#36339;&#36291;&#36830;&#25509;&#65292;&#24182;&#19982;&#27491;&#20132;&#26435;&#37325;&#24402;&#19968;&#21270;&#21644;&#22810;&#32034;&#24341;&#27169;&#22411;&#23494;&#20999;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#22823;&#31867;&#20855;&#26377;&#22810;&#21464;&#37327;&#38750;&#32447;&#24615;/&#28608;&#27963;&#20989;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#21464;&#20998;&#20248;&#21270;&#24615;&#65288;&#20855;&#20307;&#32780;&#35328;&#65292;&#26159;Banach&#31354;&#38388;&#20248;&#21270;&#24615;&#65289;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#36890;&#36807;&#27491;&#21017;&#21270;&#31639;&#23376;&#21644;k-&#24179;&#38754;&#21464;&#25442;&#26500;&#24314;&#20102;&#19968;&#31867;&#26032;&#30340;Banach&#31354;&#38388;&#23478;&#26063;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#34920;&#31034;&#23450;&#29702;&#65292;&#35813;&#23450;&#29702;&#35828;&#26126;&#22312;&#36825;&#20123;Banach&#31354;&#38388;&#19978;&#25552;&#20986;&#30340;&#23398;&#20064;&#38382;&#39064;&#30340;&#35299;&#38598;&#23436;&#20840;&#30001;&#20855;&#26377;&#22810;&#21464;&#37327;&#38750;&#32447;&#24615;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#26469;&#25551;&#36848;&#12290;&#36825;&#20123;&#26368;&#20248;&#30340;&#26550;&#26500;&#20855;&#26377;&#36339;&#36291;&#36830;&#25509;&#65292;&#24182;&#19982;&#27491;&#20132;&#26435;&#37325;&#24402;&#19968;&#21270;&#21644;&#22810;&#32034;&#24341;&#27169;&#22411;&#24687;&#24687;&#30456;&#20851;&#65292;&#36825;&#20004;&#20010;&#27169;&#22411;&#22312;&#31070;&#32463;&#32593;&#32476;&#30028;&#24341;&#36215;&#20102;&#30456;&#24403;&#22823;&#30340;&#20852;&#36259;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#36866;&#29992;&#20110;&#21253;&#25324;&#20462;&#27491;&#32447;&#24615;&#21333;&#20803;&#65288;ReLU&#65289;&#28608;&#27963;&#20989;&#25968;&#12289;&#33539;&#25968;&#28608;&#27963;&#20989;&#25968;&#20197;&#21450;&#22312;&#34180;&#26495;/&#22810;&#27425;&#35856;&#27874;&#26679;&#26465;&#29702;&#35770;&#20013;&#25214;&#21040;&#30340;&#24452;&#21521;&#22522;&#20989;&#25968;&#22312;&#20869;&#30340;&#22810;&#31181;&#32463;&#20856;&#38750;&#32447;&#24615;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the variational optimality (specifically, the Banach space optimality) of a large class of neural architectures with multivariate nonlinearities/activation functions. To that end, we construct a new family of Banach spaces defined via a regularization operator and the $k$-plane transform. We prove a representer theorem that states that the solution sets to learning problems posed over these Banach spaces are completely characterized by neural architectures with multivariate nonlinearities. These optimal architectures have skip connections and are tightly connected to orthogonal weight normalization and multi-index models, both of which have received considerable interest in the neural network community. Our framework is compatible with a number of classical nonlinearities including the rectified linear unit (ReLU) activation function, the norm activation function, and the radial basis functions found in the theory of thin-plate/polyharmonic splines. We also show that the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21010;&#20998;&#12289;&#35780;&#20272;&#21644;&#32454;&#21270;&#30340;&#26041;&#27861;&#26469;&#25913;&#21892;&#25991;&#26412;&#21040;&#22270;&#20687;&#23545;&#40784;&#12290;&#36890;&#36807;&#20998;&#35299;&#22797;&#26434;&#30340;&#25552;&#31034;&#24182;&#20351;&#29992;VQA&#27169;&#22411;&#36827;&#34892;&#27979;&#37327;&#65292;&#26368;&#32456;&#24471;&#21040;&#25991;&#26412;&#21040;&#22270;&#20687;&#30340;&#23545;&#40784;&#20998;&#25968;&#12290;</title><link>http://arxiv.org/abs/2307.04749</link><description>&lt;p&gt;
&#21010;&#20998;&#12289;&#35780;&#20272;&#21644;&#32454;&#21270;&#65306;&#36890;&#36807;&#36845;&#20195;VQA&#21453;&#39304;&#35780;&#20272;&#21644;&#25913;&#21892;&#25991;&#26412;&#21040;&#22270;&#20687;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Divide, Evaluate, and Refine: Evaluating and Improving Text-to-Image Alignment with Iterative VQA Feedback. (arXiv:2307.04749v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04749
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21010;&#20998;&#12289;&#35780;&#20272;&#21644;&#32454;&#21270;&#30340;&#26041;&#27861;&#26469;&#25913;&#21892;&#25991;&#26412;&#21040;&#22270;&#20687;&#23545;&#40784;&#12290;&#36890;&#36807;&#20998;&#35299;&#22797;&#26434;&#30340;&#25552;&#31034;&#24182;&#20351;&#29992;VQA&#27169;&#22411;&#36827;&#34892;&#27979;&#37327;&#65292;&#26368;&#32456;&#24471;&#21040;&#25991;&#26412;&#21040;&#22270;&#20687;&#30340;&#23545;&#40784;&#20998;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#30340;&#26368;&#26032;&#20986;&#29616;&#65292;&#20197;&#25991;&#26412;&#20026;&#26465;&#20214;&#30340;&#22270;&#20687;&#29983;&#25104;&#39046;&#22495;&#21462;&#24471;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#20855;&#26377;&#26174;&#33879;&#24615;&#65292;&#20294;&#26159;&#38543;&#30528;&#25991;&#26412;&#36755;&#20837;&#30340;&#22797;&#26434;&#24615;&#22686;&#21152;&#65292;&#26368;&#20808;&#36827;&#30340;&#25193;&#25955;&#27169;&#22411;&#20173;&#21487;&#33021;&#26080;&#27861;&#29983;&#25104;&#20934;&#30830;&#20256;&#36798;&#32473;&#23450;&#25552;&#31034;&#35821;&#20041;&#30340;&#22270;&#20687;&#12290;&#27492;&#22806;&#65292;&#35266;&#23519;&#21040;&#36825;&#31181;&#19981;&#23545;&#40784;&#24448;&#24448;&#34987;&#39044;&#35757;&#32451;&#30340;&#22810;&#27169;&#22411;&#65288;&#22914;CLIP&#65289;&#26410;&#33021;&#26816;&#27979;&#21040;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#19968;&#31181;&#31616;&#21333;&#19988;&#26377;&#25928;&#30340;&#20998;&#35299;&#26041;&#27861;&#26469;&#35780;&#20272;&#21644;&#25913;&#21892;&#25991;&#26412;&#21040;&#22270;&#20687;&#23545;&#40784;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#24341;&#20837;&#20102;&#19968;&#31181;&#20998;&#35299;&#23545;&#40784;&#20998;&#25968;&#65292;&#23427;&#23558;&#22797;&#26434;&#25552;&#31034;&#20998;&#35299;&#20026;&#19968;&#32452;&#19981;&#30456;&#20132;&#30340;&#26029;&#35328;&#12290;&#28982;&#21518;&#65292;&#20351;&#29992;VQA&#27169;&#22411;&#26469;&#27979;&#37327;&#27599;&#20010;&#26029;&#35328;&#19982;&#29983;&#25104;&#30340;&#22270;&#20687;&#30340;&#23545;&#40784;&#24773;&#20917;&#12290;&#26368;&#21518;&#65292;&#23558;&#19981;&#21516;&#26029;&#35328;&#30340;&#23545;&#40784;&#20998;&#25968;&#21512;&#24182;&#21518;&#65292;&#24471;&#21040;&#26368;&#32456;&#30340;&#25991;&#26412;&#21040;&#22270;&#20687;&#23545;&#40784;&#20998;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
The field of text-conditioned image generation has made unparalleled progress with the recent advent of latent diffusion models. While remarkable, as the complexity of given text input increases, the state-of-the-art diffusion models may still fail in generating images which accurately convey the semantics of the given prompt. Furthermore, it has been observed that such misalignments are often left undetected by pretrained multi-modal models such as CLIP. To address these problems, in this paper we explore a simple yet effective decompositional approach towards both evaluation and improvement of text-to-image alignment. In particular, we first introduce a Decompositional-Alignment-Score which given a complex prompt decomposes it into a set of disjoint assertions. The alignment of each assertion with generated images is then measured using a VQA model. Finally, alignment scores for different assertions are combined aposteriori to give the final text-to-image alignment score. Experimenta
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#26031;&#21327;&#21464;&#37327;&#19979;&#30340;&#36807;&#21442;&#25968;&#21270;&#32447;&#24615;&#27169;&#22411;&#22312;&#22810;&#31867;&#20998;&#31867;&#38382;&#39064;&#20013;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#25104;&#21151;&#35299;&#20915;&#20102;&#20043;&#21069;&#30340;&#29468;&#24819;&#65292;&#24182;&#25552;&#20986;&#30340;&#26032;&#19979;&#30028;&#20855;&#26377;&#20449;&#24687;&#35770;&#20013;&#30340;&#24378;&#23545;&#20598;&#23450;&#29702;&#30340;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2306.13255</link><description>&lt;p&gt;
&#36807;&#21442;&#25968;&#21270;&#32447;&#24615;&#27169;&#22411;&#19979;&#22810;&#31867;&#20998;&#31867;&#30340;&#28176;&#36827;&#27867;&#21270;&#31934;&#24230;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Precise Asymptotic Generalization for Multiclass Classification with Overparameterized Linear Models. (arXiv:2306.13255v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13255
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#26031;&#21327;&#21464;&#37327;&#19979;&#30340;&#36807;&#21442;&#25968;&#21270;&#32447;&#24615;&#27169;&#22411;&#22312;&#22810;&#31867;&#20998;&#31867;&#38382;&#39064;&#20013;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#25104;&#21151;&#35299;&#20915;&#20102;&#20043;&#21069;&#30340;&#29468;&#24819;&#65292;&#24182;&#25552;&#20986;&#30340;&#26032;&#19979;&#30028;&#20855;&#26377;&#20449;&#24687;&#35770;&#20013;&#30340;&#24378;&#23545;&#20598;&#23450;&#29702;&#30340;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20855;&#26377;&#39640;&#26031;&#21327;&#21464;&#37327;&#21452;&#23618;&#27169;&#22411;&#19979;&#65292;&#36807;&#21442;&#25968;&#21270;&#32447;&#24615;&#27169;&#22411;&#22312;&#22810;&#31867;&#20998;&#31867;&#20013;&#30340;&#28176;&#36827;&#27867;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#25968;&#25454;&#28857;&#25968;&#12289;&#29305;&#24449;&#21644;&#31867;&#21035;&#25968;&#37117;&#21516;&#26102;&#22686;&#38271;&#12290;&#25105;&#20204;&#23436;&#20840;&#35299;&#20915;&#20102;Subramanian&#31561;&#20154;&#22312;'22&#24180;&#25152;&#25552;&#20986;&#30340;&#29468;&#24819;&#65292;&#19982;&#39044;&#27979;&#30340;&#27867;&#21270;&#21306;&#38388;&#30456;&#21305;&#37197;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26032;&#30340;&#19979;&#30028;&#31867;&#20284;&#20110;&#20449;&#24687;&#35770;&#20013;&#30340;&#24378;&#23545;&#20598;&#23450;&#29702;&#65306;&#23427;&#20204;&#33021;&#22815;&#30830;&#31435;&#35823;&#20998;&#31867;&#29575;&#36880;&#28176;&#36235;&#36817;&#20110;0&#25110;1.&#25105;&#20204;&#32039;&#23494;&#30340;&#32467;&#26524;&#30340;&#19968;&#20010;&#20196;&#20154;&#24778;&#35766;&#30340;&#32467;&#26524;&#26159;&#65292;&#26368;&#23567;&#33539;&#25968;&#25554;&#20540;&#20998;&#31867;&#22120;&#22312;&#26368;&#23567;&#33539;&#25968;&#25554;&#20540;&#22238;&#24402;&#22120;&#26368;&#20248;&#30340;&#33539;&#22260;&#20869;&#65292;&#21487;&#20197;&#22312;&#28176;&#36827;&#19978;&#27425;&#20248;&#12290;&#25105;&#20204;&#20998;&#26512;&#30340;&#20851;&#38190;&#22312;&#20110;&#19968;&#31181;&#26032;&#30340;Hanson-Wright&#19981;&#31561;&#24335;&#21464;&#20307;&#65292;&#35813;&#21464;&#20307;&#22312;&#20855;&#26377;&#31232;&#30095;&#26631;&#31614;&#30340;&#22810;&#31867;&#38382;&#39064;&#20013;&#20855;&#26377;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#12290;&#20316;&#20026;&#24212;&#29992;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#30456;&#21516;&#31867;&#22411;&#20998;&#26512;&#22312;&#20960;&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#20998;&#31867;&#27169;&#22411;&#19978;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the asymptotic generalization of an overparameterized linear model for multiclass classification under the Gaussian covariates bi-level model introduced in Subramanian et al.~'22, where the number of data points, features, and classes all grow together. We fully resolve the conjecture posed in Subramanian et al.~'22, matching the predicted regimes for generalization. Furthermore, our new lower bounds are akin to an information-theoretic strong converse: they establish that the misclassification rate goes to 0 or 1 asymptotically. One surprising consequence of our tight results is that the min-norm interpolating classifier can be asymptotically suboptimal relative to noninterpolating classifiers in the regime where the min-norm interpolating regressor is known to be optimal.  The key to our tight analysis is a new variant of the Hanson-Wright inequality which is broadly useful for multiclass problems with sparse labels. As an application, we show that the same type of analysis 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#21151;&#33021;&#27969;&#21305;&#37197;&#65288;FFM&#65289;&#30340;&#20989;&#25968;&#31354;&#38388;&#29983;&#25104;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21033;&#29992;&#27010;&#29575;&#27979;&#24230;&#25554;&#20540;&#21644;&#23398;&#20064;&#24213;&#23618;&#20989;&#25968;&#31354;&#38388;&#19978;&#29983;&#25104;&#27979;&#24230;&#30340;&#21521;&#37327;&#22330;&#26469;&#29983;&#25104;&#25968;&#25454;&#20998;&#24067;&#12290;&#36825;&#31181;&#26080;&#38656;&#20284;&#28982;&#25110;&#27169;&#25311;&#30340;&#26041;&#27861;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#65292;&#20248;&#20110;&#26368;&#36817;&#25552;&#20986;&#30340;&#20960;&#31181;&#20989;&#25968;&#31354;&#38388;&#29983;&#25104;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2305.17209</link><description>&lt;p&gt;
&#21151;&#33021;&#27969;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Functional Flow Matching. (arXiv:2305.17209v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17209
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#21151;&#33021;&#27969;&#21305;&#37197;&#65288;FFM&#65289;&#30340;&#20989;&#25968;&#31354;&#38388;&#29983;&#25104;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21033;&#29992;&#27010;&#29575;&#27979;&#24230;&#25554;&#20540;&#21644;&#23398;&#20064;&#24213;&#23618;&#20989;&#25968;&#31354;&#38388;&#19978;&#29983;&#25104;&#27979;&#24230;&#30340;&#21521;&#37327;&#22330;&#26469;&#29983;&#25104;&#25968;&#25454;&#20998;&#24067;&#12290;&#36825;&#31181;&#26080;&#38656;&#20284;&#28982;&#25110;&#27169;&#25311;&#30340;&#26041;&#27861;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#65292;&#20248;&#20110;&#26368;&#36817;&#25552;&#20986;&#30340;&#20960;&#31181;&#20989;&#25968;&#31354;&#38388;&#29983;&#25104;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21151;&#33021;&#27969;&#21305;&#37197;&#65288;Functional Flow Matching, FFM&#65289;&#30340;&#20989;&#25968;&#31354;&#38388;&#29983;&#25104;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#23558;&#26368;&#36817;&#24341;&#20837;&#30340;&#27969;&#21305;&#37197;&#65288;Flow Matching&#65289;&#30452;&#25509;&#25512;&#24191;&#21040;&#26080;&#38480;&#32500;&#31354;&#38388;&#20013;&#36827;&#34892;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#39318;&#20808;&#23450;&#20041;&#20102;&#19968;&#32452;&#27010;&#29575;&#27979;&#24230;&#36335;&#24452;&#65292;&#22312;&#22266;&#23450;&#30340;&#39640;&#26031;&#27979;&#24230;&#21644;&#25968;&#25454;&#20998;&#24067;&#20043;&#38388;&#36827;&#34892;&#25554;&#20540;&#65292;&#28982;&#21518;&#23398;&#20064;&#20989;&#25968;&#30340;&#24213;&#23618;&#31354;&#38388;&#19978;&#29983;&#25104;&#27492;&#27979;&#24230;&#36335;&#24452;&#30340;&#21521;&#37327;&#22330;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#20381;&#36182;&#20110;&#20284;&#28982;&#25110;&#27169;&#25311;&#65292;&#22240;&#27492;&#38750;&#24120;&#36866;&#21512;&#20989;&#25968;&#31354;&#38388;&#30340;&#35774;&#32622;&#12290;&#25105;&#20204;&#19981;&#20165;&#25552;&#20379;&#26500;&#24314;&#36825;&#31181;&#27169;&#22411;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#36824;&#23545;&#25105;&#20204;&#30340;&#25216;&#26415;&#36827;&#34892;&#20102;&#32463;&#39564;&#35780;&#20272;&#12290;&#36890;&#36807;&#23545;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#22522;&#20934;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;FFM&#26041;&#27861;&#20248;&#20110;&#26368;&#36817;&#25552;&#20986;&#30340;&#20960;&#31181;&#20989;&#25968;&#31354;&#38388;&#29983;&#25104;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we propose Functional Flow Matching (FFM), a function-space generative model that generalizes the recently-introduced Flow Matching model to operate directly in infinite-dimensional spaces. Our approach works by first defining a path of probability measures that interpolates between a fixed Gaussian measure and the data distribution, followed by learning a vector field on the underlying space of functions that generates this path of measures. Our method does not rely on likelihoods or simulations, making it well-suited to the function space setting. We provide both a theoretical framework for building such models and an empirical evaluation of our techniques. We demonstrate through experiments on synthetic and real-world benchmarks that our proposed FFM method outperforms several recently proposed function-space generative models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#39044;&#27979;&#26657;&#27491;&#26041;&#26696;&#65292;&#25552;&#39640;&#20102;&#22522;&#20110;&#24471;&#20998;&#25193;&#25955;&#27169;&#22411;&#30340;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.14164</link><description>&lt;p&gt;
&#36890;&#36807;&#39044;&#27979;&#20462;&#27491;&#25552;&#39640;&#22522;&#20110;&#24471;&#20998;&#25193;&#25955;&#27169;&#22411;&#30340;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Improved Convergence of Score-Based Diffusion Models via Prediction-Correction. (arXiv:2305.14164v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14164
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#39044;&#27979;&#26657;&#27491;&#26041;&#26696;&#65292;&#25552;&#39640;&#20102;&#22522;&#20110;&#24471;&#20998;&#25193;&#25955;&#27169;&#22411;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;SGM&#65289;&#26159;&#20174;&#22797;&#26434;&#25968;&#25454;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#20854;&#22522;&#26412;&#24605;&#24819;&#26159;&#65288;i&#65289;&#36890;&#36807;&#21521;&#25968;&#25454;&#28155;&#21152;&#22122;&#22768;&#36816;&#34892;&#26102;&#38388;&#20026;$T_1$&#30340;&#27491;&#21521;&#36807;&#31243;&#65292;&#65288;ii&#65289;&#20272;&#35745;&#20854;&#24471;&#20998;&#20989;&#25968;&#65292;&#24182;&#65288;iii&#65289;&#20351;&#29992;&#27492;&#20272;&#35745;&#20540;&#36816;&#34892;&#21453;&#21521;&#36807;&#31243;&#12290;&#30001;&#20110;&#21453;&#21521;&#36807;&#31243;&#20197;&#27491;&#21521;&#36807;&#31243;&#30340;&#24179;&#31283;&#20998;&#24067;&#20316;&#20026;&#21021;&#22987;&#20540;&#65292;&#22240;&#27492;&#29616;&#26377;&#30340;&#20998;&#26512;&#33539;&#24335;&#35201;&#27714;$T_1\to\infty$&#12290;&#28982;&#32780;&#65292;&#20174;&#29702;&#35770;&#35282;&#24230;&#26469;&#30475;&#65292;&#23545;&#20110;&#32473;&#23450;&#30340;&#20998;&#25968;&#36924;&#36817;&#31934;&#24230;&#65292;&#24403;$T_1$&#21457;&#25955;&#26102;&#65292;&#25910;&#25947;&#20445;&#35777;&#23558;&#22833;&#36133;&#65307;&#20174;&#23454;&#38469;&#35282;&#24230;&#26469;&#30475;&#65292;$T_1$&#36234;&#22823;&#65292;&#35745;&#31639;&#25104;&#26412;&#23601;&#36234;&#39640;&#65292;&#24182;&#19988;&#20250;&#23548;&#33268;&#35823;&#24046;&#20256;&#25773;&#12290;&#26412;&#25991;&#36890;&#36807;&#32771;&#34385;&#27969;&#34892;&#30340;&#39044;&#27979;&#22120;&#26657;&#27491;&#26041;&#26696;&#30340;&#19968;&#20010;&#29256;&#26412;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65306;&#22312;&#36816;&#34892;&#27491;&#21521;&#36807;&#31243;&#20043;&#21518;&#65292;&#25105;&#20204;&#39318;&#20808;&#36890;&#36807;&#19981;&#31934;&#30830;&#30340; Langevin &#21160;&#21147;&#23398;&#20272;&#35745;&#26368;&#32456;&#20998;&#24067;&#65292;&#28982;&#21518;&#24674;&#22797;&#35813;&#36807;&#31243;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#25216;&#26415;&#36129;&#29486;&#26159;&#25552;&#20379;&#20102;&#25910;&#25947;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score-based generative models (SGMs) are powerful tools to sample from complex data distributions. Their underlying idea is to (i) run a forward process for time $T_1$ by adding noise to the data, (ii) estimate its score function, and (iii) use such estimate to run a reverse process. As the reverse process is initialized with the stationary distribution of the forward one, the existing analysis paradigm requires $T_1\to\infty$. This is however problematic: from a theoretical viewpoint, for a given precision of the score approximation, the convergence guarantee fails as $T_1$ diverges; from a practical viewpoint, a large $T_1$ increases computational costs and leads to error propagation. This paper addresses the issue by considering a version of the popular predictor-corrector scheme: after running the forward process, we first estimate the final distribution via an inexact Langevin dynamics and then revert the process. Our key technical contribution is to provide convergence guarantees
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27010;&#29575;&#21435;&#30456;&#20851;&#24341;&#29702;&#21644;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#20013;&#19968;&#20123;&#20854;&#20182;&#25216;&#26415;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#21487;&#20197;&#24471;&#21040;&#26032;&#30340;&#23398;&#20064;&#31639;&#27861;&#30340;&#20449;&#24687;&#35770;&#27867;&#21270;&#19978;&#38480;&#65292;&#24182;&#19988;&#33021;&#22815;&#24674;&#22797;&#35768;&#22810;&#29616;&#26377;&#30340;&#27867;&#21270;&#30028;&#65292;&#22914;&#22522;&#20110;&#20114;&#20449;&#24687;&#12289;&#26465;&#20214;&#20114;&#20449;&#24687;&#12289;&#38543;&#26426;chaining&#21644;PAC-Bayes&#19981;&#31561;&#24335;&#30340;&#30028;&#12290;</title><link>http://arxiv.org/abs/2305.11042</link><description>&lt;p&gt;
&#19968;&#31181;&#20449;&#24687;&#35770;&#36890;&#29992;&#27867;&#21270;&#30028;&#32479;&#19968;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A unified framework for information-theoretic generalization bounds. (arXiv:2305.11042v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11042
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27010;&#29575;&#21435;&#30456;&#20851;&#24341;&#29702;&#21644;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#20013;&#19968;&#20123;&#20854;&#20182;&#25216;&#26415;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#21487;&#20197;&#24471;&#21040;&#26032;&#30340;&#23398;&#20064;&#31639;&#27861;&#30340;&#20449;&#24687;&#35770;&#27867;&#21270;&#19978;&#38480;&#65292;&#24182;&#19988;&#33021;&#22815;&#24674;&#22797;&#35768;&#22810;&#29616;&#26377;&#30340;&#27867;&#21270;&#30028;&#65292;&#22914;&#22522;&#20110;&#20114;&#20449;&#24687;&#12289;&#26465;&#20214;&#20114;&#20449;&#24687;&#12289;&#38543;&#26426;chaining&#21644;PAC-Bayes&#19981;&#31561;&#24335;&#30340;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#26041;&#27861;&#26469;&#23548;&#20986;&#23398;&#20064;&#31639;&#27861;&#30340;&#20449;&#24687;&#35770;&#27867;&#21270;&#30028;&#12290;&#20027;&#35201;&#30340;&#25216;&#26415;&#24037;&#20855;&#26159;&#22522;&#20110;&#25913;&#21464;&#27979;&#24230;&#21644;&#26494;&#24347;Young&#19981;&#31561;&#24335;&#22312;$L_{\psi_p}$Orlicz&#31354;&#38388;&#20013;&#30340;&#27010;&#29575;&#21435;&#30456;&#20851;&#24615;&#24341;&#29702;&#12290;&#37319;&#29992;&#21435;&#30456;&#20851;&#24615;&#24341;&#29702;&#19982;&#20854;&#20182;&#25216;&#26415;&#65292;&#22914;&#23545;&#31216;&#21270;&#12289;&#32806;&#21512;&#21644;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#20013;&#30340;chaining&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#26032;&#30340;&#27867;&#21270;&#35823;&#24046;&#19978;&#38480;&#65292;&#21253;&#25324;&#26399;&#26395;&#21644;&#39640;&#27010;&#29575;&#65292;&#21516;&#26102;&#65292;&#25105;&#20204;&#20063;&#24674;&#22797;&#20102;&#35768;&#22810;&#29616;&#26377;&#30340;&#27867;&#21270;&#30028;&#65292;&#21253;&#25324;&#22522;&#20110;&#20114;&#20449;&#24687;&#12289;&#26465;&#20214;&#20114;&#20449;&#24687;&#12289;&#38543;&#26426;chaining&#21644;PAC-Bayes&#19981;&#31561;&#24335;&#30340;&#30028;&#12290;&#27492;&#22806;&#65292;Fernique-Talagrand&#19978;&#30028;&#20063;&#20316;&#20026;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#21576;&#29616;&#20986;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a general methodology for deriving information-theoretic generalization bounds for learning algorithms. The main technical tool is a probabilistic decorrelation lemma based on a change of measure and a relaxation of Young's inequality in $L_{\psi_p}$ Orlicz spaces. Using the decorrelation lemma in combination with other techniques, such as symmetrization, couplings, and chaining in the space of probability measures, we obtain new upper bounds on the generalization error, both in expectation and in high probability, and recover as special cases many of the existing generalization bounds, including the ones based on mutual information, conditional mutual information, stochastic chaining, and PAC-Bayes inequalities. In addition, the Fernique-Talagrand upper bound on the expected supremum of a subgaussian process emerges as a special case.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#30340;&#24494;&#27491;&#21017; Langevin Monte Carlo &#26041;&#27861;&#33021;&#22815;&#39640;&#25928;&#22320;&#37319;&#26679; $\exp[-S(\x)]$ &#20998;&#24067;&#65292;&#21516;&#26102;&#20855;&#26377;&#26080;&#20559;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.18221</link><description>&lt;p&gt;
&#24494;&#27491;&#21017; Langevin Monte Carlo
&lt;/p&gt;
&lt;p&gt;
Microcanonical Langevin Monte Carlo. (arXiv:2303.18221v1 [hep-lat])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.18221
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#30340;&#24494;&#27491;&#21017; Langevin Monte Carlo &#26041;&#27861;&#33021;&#22815;&#39640;&#25928;&#22320;&#37319;&#26679; $\exp[-S(\x)]$ &#20998;&#24067;&#65292;&#21516;&#26102;&#20855;&#26377;&#26080;&#20559;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#20197;&#21487;&#29992;&#28176;&#21464; $ \nabla S(\x)$ &#30340;&#24418;&#24335;&#37319;&#26679;&#33258;&#19968;&#20219;&#24847;&#20998;&#24067; $ \exp[-S(\x)]$&#65292;&#35813;&#26041;&#27861;&#34987;&#21046;&#23450;&#20026;&#20445;&#25345;&#33021;&#37327;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986; Fokker-Planck &#26041;&#31243;&#65292;&#24182;&#35777;&#26126;&#30830;&#23450;&#24615;&#28418;&#31227;&#21644;&#38543;&#26426;&#25193;&#25955;&#20998;&#21035;&#20445;&#25345;&#24179;&#31283;&#20998;&#24067;&#12290;&#36825;&#24847;&#21619;&#30528;&#28418;&#31227;&#25193;&#25955;&#31163;&#25955;&#21270;&#26041;&#26696;&#26080;&#20559;&#65292;&#32780;&#26631;&#20934; Langevin &#21160;&#21147;&#23398;&#21017;&#19981;&#26159;&#12290;&#25105;&#20204;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110; $\phi^4$ &#26230;&#26684;&#22330;&#35770;&#65292;&#23637;&#31034;&#20102;&#32467;&#26524;&#19982;&#26631;&#20934;&#37319;&#26679;&#26041;&#27861;&#19968;&#33268;&#65292;&#20294;&#27604;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#37319;&#26679;&#22120;&#25928;&#29575;&#26174;&#33879;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a method for sampling from an arbitrary distribution $\exp[-S(\x)]$ with an available gradient $\nabla S(\x)$, formulated as an energy-preserving stochastic differential equation (SDE). We derive the Fokker-Planck equation and show that both the deterministic drift and the stochastic diffusion separately preserve the stationary distribution. This implies that the drift-diffusion discretization schemes are bias-free, in contrast to the standard Langevin dynamics. We apply the method to the $\phi^4$ lattice field theory, showing the results agree with the standard sampling methods but with significantly higher efficiency compared to the current state-of-the-art samplers.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#21033;&#29992;&#20854;&#29702;&#35770;&#22522;&#30784;&#21644;&#23454;&#26045;&#30340;&#21487;&#34892;&#24615;&#65292;&#20174;&#32780;&#20272;&#35745;&#36830;&#32493;&#26292;&#38706;/&#27835;&#30103;&#30340;&#20998;&#24067;&#23545;&#25919;&#31574;&#30456;&#20851;&#32467;&#26524;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#25105;&#20204;&#23558;&#27492;&#26041;&#27861;&#24212;&#29992;&#20110;&#21253;&#21547;6800&#19975;&#20010;&#20010;&#20307;&#21644;2700&#19975;&#20010;&#32654;&#22269;&#22659;&#20869;&#27515;&#20129;&#20107;&#20214;&#30340;&#25968;&#25454;&#20013;&#65292;&#36890;&#36807;&#35780;&#20272;&#32654;&#22269;&#22269;&#23478;&#29615;&#22659;&#20445;&#25252;&#23616;&#65288;EPA&#65289;&#23545;PM2.5&#30340;&#22269;&#23478;&#29615;&#22659;&#31354;&#27668;&#36136;&#37327;&#26631;&#20934;&#65288;NAAQS&#65289;&#36827;&#34892;&#20462;&#35746;&#21518;&#30340;&#20581;&#24247;&#25928;&#30410;&#12290;</title><link>http://arxiv.org/abs/2302.02560</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#22312;&#22240;&#26524;&#20272;&#35745;&#20013;&#30340;&#24212;&#29992;: &#22312;&#32654;&#22269;&#35780;&#20272;&#26356;&#20005;&#26684;&#30340;&#31354;&#27668;&#36136;&#37327;&#26631;&#20934;&#30340;&#20581;&#24247;&#25928;&#30410;
&lt;/p&gt;
&lt;p&gt;
Causal Estimation of Exposure Shifts with Neural Networks: Evaluating the Health Benefits of Stricter Air Quality Standards in the US. (arXiv:2302.02560v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02560
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#21033;&#29992;&#20854;&#29702;&#35770;&#22522;&#30784;&#21644;&#23454;&#26045;&#30340;&#21487;&#34892;&#24615;&#65292;&#20174;&#32780;&#20272;&#35745;&#36830;&#32493;&#26292;&#38706;/&#27835;&#30103;&#30340;&#20998;&#24067;&#23545;&#25919;&#31574;&#30456;&#20851;&#32467;&#26524;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#25105;&#20204;&#23558;&#27492;&#26041;&#27861;&#24212;&#29992;&#20110;&#21253;&#21547;6800&#19975;&#20010;&#20010;&#20307;&#21644;2700&#19975;&#20010;&#32654;&#22269;&#22659;&#20869;&#27515;&#20129;&#20107;&#20214;&#30340;&#25968;&#25454;&#20013;&#65292;&#36890;&#36807;&#35780;&#20272;&#32654;&#22269;&#22269;&#23478;&#29615;&#22659;&#20445;&#25252;&#23616;&#65288;EPA&#65289;&#23545;PM2.5&#30340;&#22269;&#23478;&#29615;&#22659;&#31354;&#27668;&#36136;&#37327;&#26631;&#20934;&#65288;NAAQS&#65289;&#36827;&#34892;&#20462;&#35746;&#21518;&#30340;&#20581;&#24247;&#25928;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25919;&#31574;&#30740;&#31350;&#20013;&#65292;&#20272;&#35745;&#36830;&#32493;&#24615;&#26292;&#38706;/&#27835;&#30103;&#30340;&#20998;&#24067;&#23545;&#24863;&#20852;&#36259;&#30340;&#32467;&#26524;&#30340;&#22240;&#26524;&#25928;&#24212;&#26159;&#26368;&#20851;&#38190;&#30340;&#20998;&#26512;&#20219;&#21153;&#20043;&#19968;&#12290;&#25105;&#20204;&#31216;&#20043;&#20026;&#20559;&#31227;-&#21709;&#24212;&#20989;&#25968;&#65288;SRF&#65289;&#20272;&#35745;&#38382;&#39064;&#12290;&#29616;&#26377;&#30340;&#28041;&#21450;&#24378;&#20581;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#22120;&#30340;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#32570;&#20047;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#38469;&#23454;&#29616;&#65292;&#29992;&#20110;SRF&#20272;&#35745;&#12290;&#21463;&#20844;&#20849;&#21355;&#29983;&#20013;&#30340;&#20851;&#38190;&#25919;&#31574;&#38382;&#39064;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#21450;&#20854;&#29702;&#35770;&#22522;&#30784;&#65292;&#20197;&#25552;&#20379;&#20855;&#26377;&#24378;&#20581;&#24615;&#21644;&#25928;&#29575;&#20445;&#35777;&#30340;SRF&#20272;&#35745;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#21253;&#21547;6800&#19975;&#20010;&#20010;&#20307;&#21644;2700&#19975;&#20010;&#32654;&#22269;&#22659;&#20869;&#27515;&#20129;&#20107;&#20214;&#30340;&#25968;&#25454;&#20013;&#65292;&#20197;&#20272;&#35745;&#23558;&#32654;&#22269;&#22269;&#23478;&#29615;&#22659;&#20445;&#25252;&#23616;&#65288;EPA&#65289;&#26368;&#36817;&#25552;&#35758;&#20174;12 &#956;g/m&#179;&#25913;&#20026;9 &#956;g/m&#179;&#30340;PM2.5&#30340;&#32654;&#22269;&#22269;&#23478;&#29615;&#22659;&#31354;&#27668;&#36136;&#37327;&#26631;&#20934;&#65288;NAAQS&#65289;&#30340;&#20462;&#35746;&#23545;&#32467;&#26524;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#39318;&#27425;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
In policy research, one of the most critical analytic tasks is to estimate the causal effect of a policy-relevant shift to the distribution of a continuous exposure/treatment on an outcome of interest. We call this problem shift-response function (SRF) estimation. Existing neural network methods involving robust causal-effect estimators lack theoretical guarantees and practical implementations for SRF estimation. Motivated by a key policy-relevant question in public health, we develop a neural network method and its theoretical underpinnings to estimate SRFs with robustness and efficiency guarantees. We then apply our method to data consisting of 68 million individuals and 27 million deaths across the U.S. to estimate the causal effect from revising the US National Ambient Air Quality Standards (NAAQS) for PM 2.5 from 12 $\mu g/m^3$ to 9 $\mu g/m^3$. This change has been recently proposed by the US Environmental Protection Agency (EPA). Our goal is to estimate, for the first time, the 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26680;&#24046;&#24322;&#24230;&#37327;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#26032;&#30340;&#20805;&#20998;&#24517;&#35201;&#26465;&#20214;&#65292;&#23454;&#29616;&#20102;&#23558;&#30446;&#26631;&#20998;&#31163;&#20986;&#26469;&#65292;&#20197;&#21450;&#25511;&#21046;&#23545;&#30446;&#26631;&#30340;&#24369;&#25910;&#25947;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;$\mathbb{R}^d$&#19978;&#20351;&#29992;&#20102;&#36825;&#20123;&#32467;&#26524;&#26469;&#25193;&#23637;&#20102;&#26680;Stein&#24046;&#24322;&#20998;&#31163;&#21644;&#25910;&#25947;&#25511;&#21046;&#30340;&#24050;&#30693;&#26465;&#20214;&#65292;&#24182;&#24320;&#21457;&#20102;&#33021;&#22815;&#31934;&#30830;&#24230;&#37327;&#30446;&#26631;&#30340;&#24369;&#25910;&#25947;&#24615;&#30340;&#26680;&#24046;&#24322;&#24230;&#37327;&#12290;</title><link>http://arxiv.org/abs/2209.12835</link><description>&lt;p&gt;
&#36890;&#36807;&#26680;&#24046;&#24322;&#23454;&#29616;&#26377;&#38024;&#23545;&#24615;&#30340;&#20998;&#31163;&#19982;&#25910;&#25947;
&lt;/p&gt;
&lt;p&gt;
Targeted Separation and Convergence with Kernel Discrepancies. (arXiv:2209.12835v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.12835
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26680;&#24046;&#24322;&#24230;&#37327;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#26032;&#30340;&#20805;&#20998;&#24517;&#35201;&#26465;&#20214;&#65292;&#23454;&#29616;&#20102;&#23558;&#30446;&#26631;&#20998;&#31163;&#20986;&#26469;&#65292;&#20197;&#21450;&#25511;&#21046;&#23545;&#30446;&#26631;&#30340;&#24369;&#25910;&#25947;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;$\mathbb{R}^d$&#19978;&#20351;&#29992;&#20102;&#36825;&#20123;&#32467;&#26524;&#26469;&#25193;&#23637;&#20102;&#26680;Stein&#24046;&#24322;&#20998;&#31163;&#21644;&#25910;&#25947;&#25511;&#21046;&#30340;&#24050;&#30693;&#26465;&#20214;&#65292;&#24182;&#24320;&#21457;&#20102;&#33021;&#22815;&#31934;&#30830;&#24230;&#37327;&#30446;&#26631;&#30340;&#24369;&#25910;&#25947;&#24615;&#30340;&#26680;&#24046;&#24322;&#24230;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65288;MMDs&#65289;&#22914;&#26680;Stein&#24046;&#24322;&#65288;KSD&#65289;&#24050;&#32463;&#25104;&#20026;&#24191;&#27867;&#24212;&#29992;&#30340;&#20013;&#24515;&#65292;&#21253;&#25324;&#20551;&#35774;&#26816;&#39564;&#12289;&#37319;&#26679;&#22120;&#36873;&#25321;&#12289;&#20998;&#24067;&#36817;&#20284;&#21644;&#21464;&#20998;&#25512;&#26029;&#12290;&#22312;&#27599;&#20010;&#35774;&#32622;&#20013;&#65292;&#36825;&#20123;&#22522;&#20110;&#26680;&#30340;&#24046;&#24322;&#24230;&#37327;&#38656;&#35201;&#23454;&#29616;&#65288;i&#65289;&#23558;&#30446;&#26631;P&#19982;&#20854;&#20182;&#27010;&#29575;&#27979;&#24230;&#20998;&#31163;&#65292;&#29978;&#33267;&#65288;ii&#65289;&#25511;&#21046;&#23545;P&#30340;&#24369;&#25910;&#25947;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#30830;&#20445;&#65288;i&#65289;&#21644;&#65288;ii&#65289;&#30340;&#26032;&#30340;&#20805;&#20998;&#24517;&#35201;&#26465;&#20214;&#12290;&#23545;&#20110;&#21487;&#20998;&#30340;&#24230;&#37327;&#31354;&#38388;&#19978;&#30340;MMDs&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#20998;&#31163;Bochner&#21487;&#23884;&#20837;&#27979;&#24230;&#30340;&#26680;&#65292;&#24182;&#24341;&#20837;&#31616;&#21333;&#30340;&#26465;&#20214;&#26469;&#20998;&#31163;&#25152;&#26377;&#20855;&#26377;&#26080;&#30028;&#26680;&#30340;&#27979;&#24230;&#21644;&#29992;&#26377;&#30028;&#26680;&#26469;&#25511;&#21046;&#25910;&#25947;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20123;&#32467;&#26524;&#22312;$\mathbb{R}^d$&#19978;&#22823;&#22823;&#25193;&#23637;&#20102;KSD&#20998;&#31163;&#21644;&#25910;&#25947;&#25511;&#21046;&#30340;&#24050;&#30693;&#26465;&#20214;&#65292;&#24182;&#24320;&#21457;&#20102;&#39318;&#20010;&#33021;&#22815;&#31934;&#30830;&#24230;&#37327;&#23545;P&#30340;&#24369;&#25910;&#25947;&#30340;KSDs&#12290;&#22312;&#36825;&#20010;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;&#25105;&#20204;&#30340;&#32467;&#26524;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Maximum mean discrepancies (MMDs) like the kernel Stein discrepancy (KSD) have grown central to a wide range of applications, including hypothesis testing, sampler selection, distribution approximation, and variational inference. In each setting, these kernel-based discrepancy measures are required to (i) separate a target P from other probability measures or even (ii) control weak convergence to P. In this article we derive new sufficient and necessary conditions to ensure (i) and (ii). For MMDs on separable metric spaces, we characterize those kernels that separate Bochner embeddable measures and introduce simple conditions for separating all measures with unbounded kernels and for controlling convergence with bounded kernels. We use these results on $\mathbb{R}^d$ to substantially broaden the known conditions for KSD separation and convergence control and to develop the first KSDs known to exactly metrize weak convergence to P. Along the way, we highlight the implications of our res
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38024;&#23545;&#39640;&#32500;&#30697;&#38453;&#25968;&#25454;&#30340;&#29305;&#24449;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#20351;&#29992;&#21152;&#26435;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#24046;&#24322;&#20316;&#20026;&#19981;&#30456;&#20284;&#24230;&#27979;&#37327;&#30340;&#23618;&#27425;&#32858;&#31867;&#31639;&#27861;&#65292;&#29702;&#35770;&#19978;&#23454;&#29616;&#20102;&#32858;&#31867;&#19968;&#33268;&#24615;&#65292;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#31034;&#20363;&#20013;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2112.12909</link><description>&lt;p&gt;
&#38024;&#23545;&#39640;&#32500;&#30697;&#38453;&#25968;&#25454;&#30340;&#26368;&#20248;&#21464;&#37327;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Optimal Variable Clustering for High-Dimensional Matrix Valued Data. (arXiv:2112.12909v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.12909
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38024;&#23545;&#39640;&#32500;&#30697;&#38453;&#25968;&#25454;&#30340;&#29305;&#24449;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#20351;&#29992;&#21152;&#26435;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#24046;&#24322;&#20316;&#20026;&#19981;&#30456;&#20284;&#24230;&#27979;&#37327;&#30340;&#23618;&#27425;&#32858;&#31867;&#31639;&#27861;&#65292;&#29702;&#35770;&#19978;&#23454;&#29616;&#20102;&#32858;&#31867;&#19968;&#33268;&#24615;&#65292;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#31034;&#20363;&#20013;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30697;&#38453;&#20540;&#25968;&#25454;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#26085;&#30410;&#26222;&#21450;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#36825;&#31181;&#31867;&#22411;&#25968;&#25454;&#30340;&#32858;&#31867;&#26041;&#27861;&#26159;&#38024;&#23545;&#24179;&#22343;&#27169;&#22411;&#35774;&#35745;&#30340;&#65292;&#19981;&#32771;&#34385;&#29305;&#24449;&#30340;&#20381;&#36182;&#32467;&#26500;&#65292;&#32780;&#35813;&#32467;&#26500;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#23588;&#20026;&#37325;&#35201;&#12290;&#20026;&#20102;&#20174;&#20381;&#36182;&#32467;&#26500;&#20013;&#25552;&#21462;&#20449;&#24687;&#36827;&#34892;&#32858;&#31867;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29305;&#24449;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#23558;&#29305;&#24449;&#25490;&#21015;&#25104;&#30697;&#38453;&#24418;&#24335;&#65292;&#24182;&#20351;&#29992;&#19968;&#20123;&#26410;&#30693;&#30340;&#25104;&#21592;&#30697;&#38453;&#34920;&#31034;&#34892;&#21644;&#21015;&#30340;&#32858;&#31867;&#12290;&#22312;&#27492;&#27169;&#22411;&#19979;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#31867;&#20351;&#29992;&#21152;&#26435;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#24046;&#24322;&#20316;&#20026;&#19981;&#30456;&#20284;&#24230;&#27979;&#37327;&#30340;&#23618;&#27425;&#32858;&#31867;&#31639;&#27861;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#20197;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#23454;&#29616;&#32858;&#31867;&#19968;&#33268;&#24615;&#12290;&#34429;&#28982;&#36825;&#31181;&#19968;&#33268;&#24615;&#32467;&#26524;&#36866;&#29992;&#20110;&#25105;&#20204;&#30340;&#31639;&#27861;&#21644;&#24191;&#27867;&#30340;&#21152;&#26435;&#21327;&#26041;&#24046;&#30697;&#38453;&#31867;&#21035;&#65292;&#20294;&#36825;&#20010;&#32467;&#26524;&#30340;&#26465;&#20214;&#20381;&#36182;&#20110;&#21327;&#26041;&#24046;&#20989;&#25968;&#21644;&#21152;&#26435;&#26426;&#21046;&#30340;&#36873;&#25321;&#12290;&#36890;&#36807;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#31034;&#20363;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#32858;&#31867;&#24615;&#33021;&#21644;&#29305;&#24449;&#36873;&#25321;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Matrix valued data has become increasingly prevalent in many applications. Most of the existing clustering methods for this type of data are tailored to the mean model and do not account for the dependence structure of the features, which can be very informative, especially in high-dimensional settings. To extract the information from the dependence structure for clustering, we propose a new latent variable model for the features arranged in matrix form, with some unknown membership matrices representing the clusters for the rows and columns. Under this model, we further propose a class of hierarchical clustering algorithms using the difference of a weighted covariance matrix as the dissimilarity measure. Theoretically, we show that under mild conditions, our algorithm attains clustering consistency in the high-dimensional setting. While this consistency result holds for our algorithm with a broad class of weighted covariance matrices, the conditions for this result depend on the choic
&lt;/p&gt;</description></item></channel></rss>