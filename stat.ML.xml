<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25193;&#25955;&#27169;&#22411;&#21464;&#20998;&#25512;&#26029;&#65288;DMVI&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#27010;&#29575;&#32534;&#31243;&#35821;&#35328;&#20013;&#36827;&#34892;&#33258;&#21160;&#36817;&#20284;&#25512;&#26029;&#12290;DMVI&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#36827;&#34892;&#21518;&#39564;&#25512;&#26029;&#65292;&#32780;&#19988;&#26131;&#20110;&#23454;&#29616;&#21644;&#20351;&#29992;&#65292;&#23545;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#27809;&#26377;&#20219;&#20309;&#32422;&#26463;&#12290;</title><link>http://arxiv.org/abs/2311.00474</link><description>&lt;p&gt;
&#27010;&#29575;&#32534;&#31243;&#30340;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Diffusion models for probabilistic programming. (arXiv:2311.00474v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00474
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25193;&#25955;&#27169;&#22411;&#21464;&#20998;&#25512;&#26029;&#65288;DMVI&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#27010;&#29575;&#32534;&#31243;&#35821;&#35328;&#20013;&#36827;&#34892;&#33258;&#21160;&#36817;&#20284;&#25512;&#26029;&#12290;DMVI&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#36827;&#34892;&#21518;&#39564;&#25512;&#26029;&#65292;&#32780;&#19988;&#26131;&#20110;&#23454;&#29616;&#21644;&#20351;&#29992;&#65292;&#23545;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#27809;&#26377;&#20219;&#20309;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#25193;&#25955;&#27169;&#22411;&#21464;&#20998;&#25512;&#26029;&#65288;DMVI&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#22312;&#27010;&#29575;&#32534;&#31243;&#35821;&#35328;&#65288;PPL&#65289;&#20013;&#36827;&#34892;&#33258;&#21160;&#36817;&#20284;&#25512;&#26029;&#30340;&#26032;&#26041;&#27861;&#12290;DMVI&#21033;&#29992;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#23545;&#30495;&#23454;&#21518;&#39564;&#20998;&#24067;&#30340;&#21464;&#20998;&#36817;&#20284;&#65292;&#36890;&#36807;&#23548;&#20986;&#36125;&#21494;&#26031;&#24314;&#27169;&#20013;&#20351;&#29992;&#30340;&#36793;&#38469;&#20284;&#28982;&#30446;&#26631;&#30340;&#26032;&#32422;&#26463;&#12290;DMVI&#26131;&#20110;&#23454;&#29616;&#65292;&#22312;PPL&#20013;&#36827;&#34892;&#26080;&#38556;&#30861;&#25512;&#26029;&#65292;&#19981;&#20687;&#20351;&#29992;&#24402;&#19968;&#21270;&#27969;&#30340;&#21464;&#20998;&#25512;&#26029;&#37027;&#26679;&#20855;&#26377;&#32570;&#28857;&#65292;&#24182;&#19988;&#23545;&#22522;&#30784;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#19981;&#20570;&#20219;&#20309;&#32422;&#26463;&#12290;&#25105;&#20204;&#22312;&#19968;&#32452;&#24120;&#35265;&#30340;&#36125;&#21494;&#26031;&#27169;&#22411;&#19978;&#35780;&#20272;&#20102;DMVI&#65292;&#24182;&#34920;&#26126;&#23427;&#30340;&#21518;&#39564;&#25512;&#26029;&#19968;&#33324;&#27604;PPL&#20013;&#20351;&#29992;&#30340;&#29616;&#20195;&#26041;&#27861;&#26356;&#20934;&#30830;&#65292;&#21516;&#26102;&#20855;&#26377;&#31867;&#20284;&#30340;&#35745;&#31639;&#25104;&#26412;&#24182;&#19988;&#38656;&#35201;&#36739;&#23569;&#30340;&#25163;&#21160;&#35843;&#25972;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose Diffusion Model Variational Inference (DMVI), a novel method for automated approximate inference in probabilistic programming languages (PPLs). DMVI utilizes diffusion models as variational approximations to the true posterior distribution by deriving a novel bound to the marginal likelihood objective used in Bayesian modelling. DMVI is easy to implement, allows hassle-free inference in PPLs without the drawbacks of, e.g., variational inference using normalizing flows, and does not make any constraints on the underlying neural network model. We evaluate DMVI on a set of common Bayesian models and show that its posterior inferences are in general more accurate than those of contemporary methods used in PPLs while having a similar computational cost and requiring less manual tuning.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#20174;&#20154;&#31867;&#20559;&#22909;&#20013;&#23398;&#20064;&#30340;&#23454;&#38469;&#31639;&#27861;&#30340;&#29702;&#35770;&#22522;&#30784;&#65292;&#25512;&#23548;&#20986;&#19968;&#20010;&#26032;&#30340;&#19968;&#33324;&#30446;&#26631;&#65292;&#32469;&#36807;&#20102;&#20004;&#20010;&#37325;&#35201;&#30340;&#36817;&#20284;&#12290;&#36825;&#31181;&#26041;&#27861;&#20801;&#35768;&#30452;&#25509;&#20174;&#25910;&#38598;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#31574;&#30053;&#32780;&#26080;&#38656;&#22870;&#21169;&#27169;&#22411;&#30340;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2310.12036</link><description>&lt;p&gt;
&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#29702;&#35299;&#20174;&#20154;&#31867;&#20559;&#22909;&#20013;&#23398;&#20064;&#30340;&#19968;&#33324;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A General Theoretical Paradigm to Understand Learning from Human Preferences. (arXiv:2310.12036v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12036
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#20174;&#20154;&#31867;&#20559;&#22909;&#20013;&#23398;&#20064;&#30340;&#23454;&#38469;&#31639;&#27861;&#30340;&#29702;&#35770;&#22522;&#30784;&#65292;&#25512;&#23548;&#20986;&#19968;&#20010;&#26032;&#30340;&#19968;&#33324;&#30446;&#26631;&#65292;&#32469;&#36807;&#20102;&#20004;&#20010;&#37325;&#35201;&#30340;&#36817;&#20284;&#12290;&#36825;&#31181;&#26041;&#27861;&#20801;&#35768;&#30452;&#25509;&#20174;&#25910;&#38598;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#31574;&#30053;&#32780;&#26080;&#38656;&#22870;&#21169;&#27169;&#22411;&#30340;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#20174;&#20154;&#31867;&#20559;&#22909;&#20013;&#23398;&#20064;&#30340;&#27969;&#34892;&#26041;&#27861;&#20381;&#36182;&#20110;&#20004;&#20010;&#37325;&#35201;&#30340;&#36817;&#20284;&#65306;&#31532;&#19968;&#20551;&#35774;&#21487;&#20197;&#29992;&#36880;&#28857;&#22870;&#21169;&#26367;&#20195;&#25104;&#23545;&#20559;&#22909;&#12290;&#31532;&#20108;&#20010;&#20551;&#35774;&#26159;&#22312;&#36825;&#20123;&#36880;&#28857;&#22870;&#21169;&#19978;&#35757;&#32451;&#30340;&#22870;&#21169;&#27169;&#22411;&#21487;&#20197;&#20174;&#25910;&#38598;&#21040;&#30340;&#25968;&#25454;&#27867;&#21270;&#21040;&#31574;&#30053;&#37319;&#26679;&#30340;&#36229;&#20986;&#20998;&#24067;&#30340;&#25968;&#25454;&#12290;&#26368;&#36817;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;(DPO)&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#32469;&#36807;&#20102;&#31532;&#20108;&#20010;&#36817;&#20284;&#65292;&#24182;&#30452;&#25509;&#20174;&#25910;&#38598;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#31574;&#30053;&#32780;&#26080;&#38656;&#22870;&#21169;&#27169;&#22411;&#38454;&#27573;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#20173;&#28982;&#20005;&#37325;&#20381;&#36182;&#20110;&#31532;&#19968;&#20010;&#36817;&#20284;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35797;&#22270;&#23545;&#36825;&#20123;&#23454;&#38469;&#31639;&#27861;&#36827;&#34892;&#26356;&#28145;&#20837;&#30340;&#29702;&#35770;&#29702;&#35299;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#19968;&#33324;&#30446;&#26631;&#65292;&#31216;&#20026;&#936;PO&#65292;&#29992;&#20110;&#20174;&#20154;&#31867;&#20559;&#22909;&#20013;&#23398;&#20064;&#65292;&#35813;&#30446;&#26631;&#20197;&#25104;&#23545;&#20559;&#22909;&#30340;&#24418;&#24335;&#34920;&#36798;&#65292;&#22240;&#27492;&#32469;&#36807;&#20102;&#36825;&#20004;&#20010;&#36817;&#20284;&#12290;&#36825;&#20010;&#26032;&#30340;&#19968;&#33324;&#30446;&#26631;&#20351;&#25105;&#20204;&#33021;&#22815;&#36827;&#34892;&#19968;&#31181;&#26032;&#30340;&#20174;&#35757;&#32451;&#25968;&#25454;&#30452;&#25509;&#23398;&#20064;&#31574;&#30053;&#30340;&#26041;&#27861;&#32780;&#26080;&#38656;&#36827;&#34892;&#22870;&#21169;&#27169;&#22411;&#30340;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
The prevalent deployment of learning from human preferences through reinforcement learning (RLHF) relies on two important approximations: the first assumes that pairwise preferences can be substituted with pointwise rewards. The second assumes that a reward model trained on these pointwise rewards can generalize from collected data to out-of-distribution data sampled by the policy. Recently, Direct Preference Optimisation (DPO) has been proposed as an approach that bypasses the second approximation and learn directly a policy from collected data without the reward modelling stage. However, this method still heavily relies on the first approximation.  In this paper we try to gain a deeper theoretical understanding of these practical algorithms. In particular we derive a new general objective called $\Psi$PO for learning from human preferences that is expressed in terms of pairwise preferences and therefore bypasses both approximations. This new general objective allows us to perform an 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23558;&#33258;&#36866;&#24212;&#26680;&#26041;&#27861;&#24212;&#29992;&#20110;&#20004;&#20010;&#24072;&#29983;&#27169;&#22411;&#65292;&#39044;&#27979;&#20102;&#29305;&#24449;&#23398;&#20064;&#21644; Grokking &#30340;&#24615;&#36136;&#65292;&#24182;&#23637;&#31034;&#20102; Grokking &#19982;&#30456;&#21464;&#29702;&#35770;&#20043;&#38388;&#30340;&#26144;&#23556;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2310.03789</link><description>&lt;p&gt;
&#22909;&#34920;&#31034;&#30340;&#28082;&#28404;&#65306;&#22312;&#20004;&#23618;&#32593;&#32476;&#20013; grokking &#20316;&#20026;&#19968;&#38454;&#30456;&#21464;
&lt;/p&gt;
&lt;p&gt;
Droplets of Good Representations: Grokking as a First Order Phase Transition in Two Layer Networks. (arXiv:2310.03789v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03789
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#33258;&#36866;&#24212;&#26680;&#26041;&#27861;&#24212;&#29992;&#20110;&#20004;&#20010;&#24072;&#29983;&#27169;&#22411;&#65292;&#39044;&#27979;&#20102;&#29305;&#24449;&#23398;&#20064;&#21644; Grokking &#30340;&#24615;&#36136;&#65292;&#24182;&#23637;&#31034;&#20102; Grokking &#19982;&#30456;&#21464;&#29702;&#35770;&#20043;&#38388;&#30340;&#26144;&#23556;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476; (DNN) &#30340;&#19968;&#20010;&#20851;&#38190;&#29305;&#24615;&#26159;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#33021;&#22815;&#23398;&#20064;&#26032;&#30340;&#29305;&#24449;&#12290;&#36825;&#31181;&#28145;&#24230;&#23398;&#20064;&#30340;&#26377;&#36259;&#26041;&#38754;&#22312;&#26368;&#36817;&#25253;&#36947;&#30340; Grokking &#29616;&#35937;&#20013;&#34920;&#29616;&#24471;&#26368;&#20026;&#26126;&#26174;&#12290;&#34429;&#28982;&#20027;&#35201;&#20307;&#29616;&#20026;&#27979;&#35797;&#20934;&#30830;&#24615;&#30340;&#31361;&#21464;&#22686;&#21152;&#65292;&#20294; Grokking &#20063;&#34987;&#35748;&#20026;&#26159;&#19968;&#31181;&#36229;&#36234;&#25042;&#24816;&#23398;&#20064;/&#39640;&#26031;&#36807;&#31243; (GP) &#30340;&#29616;&#35937;&#65292;&#28041;&#21450;&#29305;&#24449;&#23398;&#20064;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#23558;&#29305;&#24449;&#23398;&#20064;&#29702;&#35770;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#33258;&#36866;&#24212;&#26680;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#20855;&#26377;&#31435;&#26041;&#22810;&#39033;&#24335;&#21644;&#27169;&#21152;&#27861;&#25945;&#24072;&#30340;&#20004;&#20010;&#24072;&#29983;&#27169;&#22411;&#12290;&#25105;&#20204;&#22312;&#36825;&#20123;&#27169;&#22411;&#19978;&#25552;&#20379;&#20102;&#20851;&#20110;&#29305;&#24449;&#23398;&#20064;&#21644; Grokking &#24615;&#36136;&#30340;&#20998;&#26512;&#39044;&#27979;&#65292;&#24182;&#23637;&#31034;&#20102; Grokking &#19982;&#30456;&#21464;&#29702;&#35770;&#20043;&#38388;&#30340;&#26144;&#23556;&#20851;&#31995;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312; Grokking &#20043;&#21518;&#65292;DNN &#30340;&#29366;&#24577;&#31867;&#20284;&#20110;&#19968;&#38454;&#30456;&#21464;&#21518;&#30340;&#28151;&#21512;&#30456;&#12290;&#22312;&#36825;&#20010;&#28151;&#21512;&#30456;&#20013;&#65292;DNN &#29983;&#25104;&#20102;&#19982;&#20043;&#21069;&#26126;&#26174;&#19981;&#21516;&#30340;&#25945;&#24072;&#30340;&#26377;&#29992;&#20869;&#37096;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
A key property of deep neural networks (DNNs) is their ability to learn new features during training. This intriguing aspect of deep learning stands out most clearly in recently reported Grokking phenomena. While mainly reflected as a sudden increase in test accuracy, Grokking is also believed to be a beyond lazy-learning/Gaussian Process (GP) phenomenon involving feature learning. Here we apply a recent development in the theory of feature learning, the adaptive kernel approach, to two teacher-student models with cubic-polynomial and modular addition teachers. We provide analytical predictions on feature learning and Grokking properties of these models and demonstrate a mapping between Grokking and the theory of phase transitions. We show that after Grokking, the state of the DNN is analogous to the mixed phase following a first-order phase transition. In this mixed phase, the DNN generates useful internal representations of the teacher that are sharply distinct from those before the 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26080;&#32422;&#26463;&#30446;&#26631;&#65292;&#36890;&#36807;&#24212;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#21040;CCA&#30446;&#26631;&#65292;&#23454;&#29616;&#20102;&#19968;&#31995;&#21015;&#24555;&#36895;&#31639;&#27861;&#65292;&#21253;&#25324;&#38543;&#26426;PLS&#12289;&#38543;&#26426;CCA&#21644;&#28145;&#24230;CCA&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#21508;&#31181;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#27604;&#20808;&#21069;&#26368;&#20808;&#36827;&#26041;&#27861;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#26356;&#39640;&#30340;&#30456;&#20851;&#24615;&#24674;&#22797;&#12290;</title><link>http://arxiv.org/abs/2310.01012</link><description>&lt;p&gt;
CCA&#23478;&#26063;&#30340;&#39640;&#25928;&#31639;&#27861;&#65306;&#26080;&#32422;&#26463;&#30446;&#26631;&#19982;&#26080;&#20559;&#26799;&#24230;
&lt;/p&gt;
&lt;p&gt;
Efficient Algorithms for the CCA Family: Unconstrained Objectives with Unbiased Gradients. (arXiv:2310.01012v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01012
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26080;&#32422;&#26463;&#30446;&#26631;&#65292;&#36890;&#36807;&#24212;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#21040;CCA&#30446;&#26631;&#65292;&#23454;&#29616;&#20102;&#19968;&#31995;&#21015;&#24555;&#36895;&#31639;&#27861;&#65292;&#21253;&#25324;&#38543;&#26426;PLS&#12289;&#38543;&#26426;CCA&#21644;&#28145;&#24230;CCA&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#21508;&#31181;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#27604;&#20808;&#21069;&#26368;&#20808;&#36827;&#26041;&#27861;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#26356;&#39640;&#30340;&#30456;&#20851;&#24615;&#24674;&#22797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20856;&#22411;&#30456;&#20851;&#20998;&#26512;&#65288;CCA&#65289;&#26041;&#27861;&#22312;&#22810;&#35270;&#35282;&#23398;&#20064;&#20013;&#20855;&#26377;&#22522;&#30784;&#24615;&#20316;&#29992;&#12290;&#27491;&#21017;&#21270;&#32447;&#24615;CCA&#26041;&#27861;&#21487;&#20197;&#30475;&#20316;&#26159;&#20559;&#26368;&#23567;&#20108;&#20056;&#65288;PLS&#65289;&#30340;&#25512;&#24191;&#65292;&#24182;&#19982;&#24191;&#20041;&#29305;&#24449;&#20540;&#38382;&#39064;&#65288;GEP&#65289;&#26694;&#26550;&#32479;&#19968;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#32447;&#24615;&#26041;&#27861;&#30340;&#20256;&#32479;&#31639;&#27861;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#19978;&#35745;&#31639;&#19978;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#28145;&#24230;CCA&#30340;&#25193;&#23637;&#26174;&#31034;&#20986;&#24456;&#22823;&#30340;&#28508;&#21147;&#65292;&#20294;&#30446;&#21069;&#30340;&#35757;&#32451;&#36807;&#31243;&#32531;&#24930;&#19988;&#22797;&#26434;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#20010;&#25551;&#36848;GEPs&#30340;&#39030;&#32423;&#23376;&#31354;&#38388;&#30340;&#26032;&#39062;&#26080;&#32422;&#26463;&#30446;&#26631;&#12290;&#25105;&#20204;&#30340;&#26680;&#24515;&#36129;&#29486;&#26159;&#19968;&#31995;&#21015;&#24555;&#36895;&#31639;&#27861;&#65292;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#24212;&#29992;&#20110;&#30456;&#24212;&#30340;CCA&#30446;&#26631;&#65292;&#20174;&#32780;&#33719;&#24471;&#38543;&#26426;PLS&#12289;&#38543;&#26426;CCA&#21644;&#28145;&#24230;CCA&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#25152;&#26377;&#26631;&#20934;CCA&#21644;&#28145;&#24230;CCA&#22522;&#20934;&#27979;&#35797;&#20013;&#26174;&#31034;&#20986;&#27604;&#20808;&#21069;&#26368;&#20808;&#36827;&#26041;&#27861;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#26356;&#39640;&#30340;&#30456;&#20851;&#24615;&#24674;&#22797;&#12290;&#36825;&#26679;&#30340;&#36895;&#24230;&#20351;&#25105;&#20204;&#33021;&#22815;&#39318;&#27425;&#36827;&#34892;&#22823;&#35268;&#27169;&#29983;&#29289;&#25968;&#25454;&#30340;PLS&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Canonical Correlation Analysis (CCA) family of methods is foundational in multi-view learning. Regularised linear CCA methods can be seen to generalise Partial Least Squares (PLS) and unified with a Generalized Eigenvalue Problem (GEP) framework. However, classical algorithms for these linear methods are computationally infeasible for large-scale data. Extensions to Deep CCA show great promise, but current training procedures are slow and complicated. First we propose a novel unconstrained objective that characterizes the top subspace of GEPs. Our core contribution is a family of fast algorithms for stochastic PLS, stochastic CCA, and Deep CCA, simply obtained by applying stochastic gradient descent (SGD) to the corresponding CCA objectives. These methods show far faster convergence and recover higher correlations than the previous state-of-the-art on all standard CCA and Deep CCA benchmarks. This speed allows us to perform a first-of-its-kind PLS analysis of an extremely large bio
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#33258;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#65292;&#31216;&#20026;TSDiff&#12290;&#35813;&#27169;&#22411;&#19981;&#38656;&#35201;&#36741;&#21161;&#32593;&#32476;&#25110;&#35757;&#32451;&#36807;&#31243;&#30340;&#25913;&#21464;&#65292;&#22312;&#39044;&#27979;&#12289;&#25913;&#36827;&#21644;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#31561;&#26102;&#38388;&#24207;&#21015;&#20219;&#21153;&#19978;&#23637;&#29616;&#20986;&#20102;&#31454;&#20105;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.11494</link><description>&lt;p&gt;
&#39044;&#27979;&#12289;&#25913;&#36827;&#12289;&#21512;&#25104;&#65306;&#38754;&#21521;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#33258;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Predict, Refine, Synthesize: Self-Guiding Diffusion Models for Probabilistic Time Series Forecasting. (arXiv:2307.11494v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11494
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#33258;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#65292;&#31216;&#20026;TSDiff&#12290;&#35813;&#27169;&#22411;&#19981;&#38656;&#35201;&#36741;&#21161;&#32593;&#32476;&#25110;&#35757;&#32451;&#36807;&#31243;&#30340;&#25913;&#21464;&#65292;&#22312;&#39044;&#27979;&#12289;&#25913;&#36827;&#21644;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#31561;&#26102;&#38388;&#24207;&#21015;&#20219;&#21153;&#19978;&#23637;&#29616;&#20986;&#20102;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#29983;&#25104;&#24314;&#27169;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#20043;&#21069;&#20851;&#20110;&#26102;&#38388;&#24207;&#21015;&#25193;&#25955;&#27169;&#22411;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#24320;&#21457;&#38024;&#23545;&#29305;&#23450;&#39044;&#27979;&#25110;&#22635;&#34917;&#20219;&#21153;&#30340;&#26465;&#20214;&#27169;&#22411;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#38754;&#21521;&#22810;&#31181;&#26102;&#38388;&#24207;&#21015;&#24212;&#29992;&#30340;&#20219;&#21153;&#19981;&#21487;&#30693;&#26465;&#20214;&#19979;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;TSDiff&#65292;&#19968;&#31181;&#38754;&#21521;&#26102;&#38388;&#24207;&#21015;&#30340;&#26080;&#26465;&#20214;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#33258;&#24341;&#23548;&#26426;&#21046;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#20351;&#24471;TSDiff&#33021;&#22815;&#20026;&#19979;&#28216;&#20219;&#21153;&#36827;&#34892;&#26465;&#20214;&#35774;&#32622;&#65292;&#32780;&#26080;&#38656;&#36741;&#21161;&#32593;&#32476;&#25110;&#25913;&#21464;&#35757;&#32451;&#36807;&#31243;&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#19981;&#21516;&#30340;&#26102;&#38388;&#24207;&#21015;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65306;&#39044;&#27979;&#12289;&#25913;&#36827;&#21644;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#34920;&#26126;TSDiff&#19982;&#20960;&#31181;&#20219;&#21153;&#29305;&#23450;&#30340;&#26465;&#20214;&#39044;&#27979;&#26041;&#27861;&#30456;&#31454;&#20105;&#65288;&#39044;&#27979;&#65289;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#21033;&#29992;TSDiff&#23398;&#21040;&#30340;&#38544;&#24615;&#27010;&#29575;&#23494;&#24230;&#26469;&#36845;&#20195;&#22320;&#25913;&#36827;p
&lt;/p&gt;
&lt;p&gt;
Diffusion models have achieved state-of-the-art performance in generative modeling tasks across various domains. Prior works on time series diffusion models have primarily focused on developing conditional models tailored to specific forecasting or imputation tasks. In this work, we explore the potential of task-agnostic, unconditional diffusion models for several time series applications. We propose TSDiff, an unconditionally trained diffusion model for time series. Our proposed self-guidance mechanism enables conditioning TSDiff for downstream tasks during inference, without requiring auxiliary networks or altering the training procedure. We demonstrate the effectiveness of our method on three different time series tasks: forecasting, refinement, and synthetic data generation. First, we show that TSDiff is competitive with several task-specific conditional forecasting methods (predict). Second, we leverage the learned implicit probability density of TSDiff to iteratively refine the p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#30340;&#31639;&#27861;&#31283;&#23450;&#24615;&#65292;&#20998;&#26512;&#20102;&#38543;&#26426;&#32452;&#21512;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#31283;&#23450;&#24615;&#21644;&#27867;&#21270;&#24615;&#65292;&#24341;&#20837;&#20102;&#32452;&#21512;&#19968;&#33268;&#31283;&#23450;&#24615;&#27010;&#24565;&#24182;&#19982;SCO&#38382;&#39064;&#30340;&#27867;&#21270;&#24615;&#24314;&#31435;&#20102;&#23450;&#37327;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2307.03357</link><description>&lt;p&gt;
&#38543;&#26426;&#32452;&#21512;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#31283;&#23450;&#24615;&#21644;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Stability and Generalization of Stochastic Compositional Gradient Descent Algorithms. (arXiv:2307.03357v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03357
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#30340;&#31639;&#27861;&#31283;&#23450;&#24615;&#65292;&#20998;&#26512;&#20102;&#38543;&#26426;&#32452;&#21512;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#31283;&#23450;&#24615;&#21644;&#27867;&#21270;&#24615;&#65292;&#24341;&#20837;&#20102;&#32452;&#21512;&#19968;&#33268;&#31283;&#23450;&#24615;&#27010;&#24565;&#24182;&#19982;SCO&#38382;&#39064;&#30340;&#27867;&#21270;&#24615;&#24314;&#31435;&#20102;&#23450;&#37327;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#21487;&#20197;&#34987;&#24418;&#24335;&#21270;&#20026;&#38543;&#26426;&#32452;&#21512;&#20248;&#21270;&#65288;SCO&#65289;&#38382;&#39064;&#65292;&#20363;&#22914;&#24378;&#21270;&#23398;&#20064;&#12289;AUC&#26368;&#22823;&#21270;&#21644;&#20803;&#23398;&#20064;&#65292;&#20854;&#20013;&#30446;&#26631;&#20989;&#25968;&#28041;&#21450;&#19982;&#26399;&#26395;&#30456;&#20851;&#30340;&#23884;&#22871;&#32452;&#21512;&#12290;&#34429;&#28982;&#24050;&#32463;&#26377;&#22823;&#37327;&#30740;&#31350;&#33268;&#21147;&#20110;&#30740;&#31350;SCO&#31639;&#27861;&#30340;&#25910;&#25947;&#34892;&#20026;&#65292;&#20294;&#23545;&#20110;&#23427;&#20204;&#30340;&#27867;&#21270;&#24615;&#33021;&#22914;&#20309;&#65292;&#21363;&#20174;&#35757;&#32451;&#31034;&#20363;&#26500;&#24314;&#30340;&#23398;&#20064;&#31639;&#27861;&#22312;&#26410;&#26469;&#30340;&#27979;&#35797;&#31034;&#20363;&#19978;&#30340;&#34892;&#20026;&#22914;&#20309;&#65292;&#21364;&#24456;&#23569;&#26377;&#30740;&#31350;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#26694;&#26550;&#19979;&#30340;&#31639;&#27861;&#31283;&#23450;&#24615;&#65292;&#25552;&#20379;&#20102;&#38543;&#26426;&#32452;&#21512;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#31283;&#23450;&#24615;&#21644;&#27867;&#21270;&#24615;&#20998;&#26512;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31283;&#23450;&#24615;&#27010;&#24565;&#65292;&#31216;&#20026;&#32452;&#21512;&#19968;&#33268;&#31283;&#23450;&#24615;&#65292;&#24182;&#24314;&#31435;&#20102;&#23427;&#19982;SCO&#38382;&#39064;&#30340;&#27867;&#21270;&#24615;&#20043;&#38388;&#30340;&#23450;&#37327;&#20851;&#31995;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20026;&#20004;&#31181;&#27969;&#34892;&#30340;&#38543;&#26426;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#24314;&#31435;&#20102;&#32452;&#21512;&#19968;&#33268;&#31283;&#23450;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many machine learning tasks can be formulated as a stochastic compositional optimization (SCO) problem such as reinforcement learning, AUC maximization, and meta-learning, where the objective function involves a nested composition associated with an expectation. While a significant amount of studies has been devoted to studying the convergence behavior of SCO algorithms, there is little work on understanding their generalization, i.e., how these learning algorithms built from training examples would behave on future test examples. In this paper, we provide the stability and generalization analysis of stochastic compositional gradient descent algorithms through the lens of algorithmic stability in the framework of statistical learning theory. Firstly, we introduce a stability concept called compositional uniform stability and establish its quantitative relation with generalization for SCO problems. Then, we establish the compositional uniform stability results for two popular stochastic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25968;&#20540;&#30740;&#31350;&#25506;&#35752;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#36924;&#36817;&#21644;&#23398;&#20064;&#39640;&#39057;&#29575;&#26041;&#38754;&#30340;&#22256;&#38590;&#65292;&#37325;&#28857;&#26159;&#36890;&#36807;&#20998;&#26512;&#28608;&#27963;&#20989;&#25968;&#30340;&#35889;&#20998;&#26512;&#26469;&#29702;&#35299;&#38382;&#39064;&#30340;&#21407;&#22240;&#12290;</title><link>http://arxiv.org/abs/2306.17301</link><description>&lt;p&gt;
&#27973;&#23618;&#32593;&#32476;&#22312;&#36924;&#36817;&#21644;&#23398;&#20064;&#39640;&#39057;&#29575;&#26041;&#38754;&#30340;&#22256;&#38590;&#65306;&#19968;&#20010;&#25968;&#20540;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Why Shallow Networks Struggle with Approximating and Learning High Frequency: A Numerical Study. (arXiv:2306.17301v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17301
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25968;&#20540;&#30740;&#31350;&#25506;&#35752;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#36924;&#36817;&#21644;&#23398;&#20064;&#39640;&#39057;&#29575;&#26041;&#38754;&#30340;&#22256;&#38590;&#65292;&#37325;&#28857;&#26159;&#36890;&#36807;&#20998;&#26512;&#28608;&#27963;&#20989;&#25968;&#30340;&#35889;&#20998;&#26512;&#26469;&#29702;&#35299;&#38382;&#39064;&#30340;&#21407;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#20998;&#26512;&#21644;&#23454;&#39564;&#30340;&#32508;&#21512;&#25968;&#20540;&#30740;&#31350;&#65292;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#26426;&#22120;&#31934;&#24230;&#21644;&#35745;&#31639;&#25104;&#26412;&#31561;&#23454;&#38469;&#22240;&#32032;&#20013;&#65292;&#22788;&#29702;&#39640;&#39057;&#29575;&#30340;&#36924;&#36817;&#21644;&#23398;&#20064;&#23384;&#22312;&#22256;&#38590;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#30740;&#31350;&#20102;&#20197;&#19979;&#22522;&#26412;&#35745;&#31639;&#38382;&#39064;&#65306;&#65288;1&#65289;&#22312;&#26377;&#38480;&#30340;&#26426;&#22120;&#31934;&#24230;&#19979;&#21487;&#20197;&#36798;&#21040;&#30340;&#26368;&#20339;&#31934;&#24230;&#65292;&#65288;2&#65289;&#23454;&#29616;&#32473;&#23450;&#31934;&#24230;&#25152;&#38656;&#30340;&#35745;&#31639;&#25104;&#26412;&#65292;&#20197;&#21450;&#65288;3&#65289;&#23545;&#25200;&#21160;&#30340;&#31283;&#23450;&#24615;&#12290;&#30740;&#31350;&#30340;&#20851;&#38190;&#26159;&#30456;&#24212;&#28608;&#27963;&#20989;&#25968;&#30340;&#26684;&#25289;&#22982;&#30697;&#38453;&#30340;&#35889;&#20998;&#26512;&#65292;&#35813;&#20998;&#26512;&#36824;&#26174;&#31034;&#20102;&#28608;&#27963;&#20989;&#25968;&#23646;&#24615;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, a comprehensive numerical study involving analysis and experiments shows why a two-layer neural network has difficulties handling high frequencies in approximation and learning when machine precision and computation cost are important factors in real practice. In particular, the following fundamental computational issues are investigated: (1) the best accuracy one can achieve given a finite machine precision, (2) the computation cost to achieve a given accuracy, and (3) stability with respect to perturbations. The key to the study is the spectral analysis of the corresponding Gram matrix of the activation functions which also shows how the properties of the activation function play a role in the picture.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#27491;&#20132;&#24207;&#21015;&#30340;FLORAS&#26041;&#27861;&#65292;&#21487;&#28040;&#38500;&#21457;&#36865;&#31471;&#30340;&#20449;&#36947;&#29366;&#24577;&#20449;&#24687;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#39033;&#30446;&#32423;&#21644;&#23458;&#25143;&#32423;&#30340;&#24046;&#20998;&#38544;&#31169;&#20445;&#35777;&#12290;FLORAS&#21487;&#20197;&#28789;&#27963;&#22320;&#23454;&#29616;&#19981;&#21516;&#30340;&#24046;&#20998;&#38544;&#31169;&#31561;&#32423;&#65292;&#24182;&#19988;&#36890;&#36807;&#25512;&#23548;&#25910;&#25947;&#30028;&#38480;&#65292;&#23454;&#29616;&#20102;&#25910;&#25947;&#36895;&#24230;&#21644;&#38544;&#31169;&#20445;&#35777;&#20043;&#38388;&#30340;&#24179;&#31283;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2306.08280</link><description>&lt;p&gt;
&#20351;&#29992;&#27491;&#20132;&#24207;&#21015;&#30340;&#24046;&#20998;&#38544;&#31169;&#26080;&#32447;&#32852;&#21512;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Wireless Federated Learning Using Orthogonal Sequences. (arXiv:2306.08280v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08280
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#27491;&#20132;&#24207;&#21015;&#30340;FLORAS&#26041;&#27861;&#65292;&#21487;&#28040;&#38500;&#21457;&#36865;&#31471;&#30340;&#20449;&#36947;&#29366;&#24577;&#20449;&#24687;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#39033;&#30446;&#32423;&#21644;&#23458;&#25143;&#32423;&#30340;&#24046;&#20998;&#38544;&#31169;&#20445;&#35777;&#12290;FLORAS&#21487;&#20197;&#28789;&#27963;&#22320;&#23454;&#29616;&#19981;&#21516;&#30340;&#24046;&#20998;&#38544;&#31169;&#31561;&#32423;&#65292;&#24182;&#19988;&#36890;&#36807;&#25512;&#23548;&#25910;&#25947;&#30028;&#38480;&#65292;&#23454;&#29616;&#20102;&#25910;&#25947;&#36895;&#24230;&#21644;&#38544;&#31169;&#20445;&#35777;&#20043;&#38388;&#30340;&#24179;&#31283;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38544;&#31169;&#20445;&#25252;&#19978;&#34892;&#31354;&#20013;&#35745;&#31639;&#26041;&#27861;FLORAS&#65292;&#29992;&#20110;&#21333;&#36755;&#20837;&#21333;&#36755;&#20986;&#65288;SISO&#65289;&#26080;&#32447;&#32852;&#21512;&#23398;&#20064;&#65288;FL&#65289;&#31995;&#32479;&#12290;FLORAS&#20174;&#36890;&#20449;&#35774;&#35745;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#21033;&#29992;&#27491;&#20132;&#24207;&#21015;&#30340;&#24615;&#36136;&#28040;&#38500;&#20102;&#21457;&#36865;&#31471;&#30340;&#20449;&#36947;&#29366;&#24577;&#20449;&#24687;&#65288;CSIT&#65289;&#35201;&#27714;&#12290;&#20174;&#38544;&#31169;&#20445;&#25252;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#25105;&#20204;&#35777;&#26126;FLORAS&#21487;&#20197;&#25552;&#20379;&#39033;&#30446;&#32423;&#21644;&#23458;&#25143;&#32423;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#35843;&#25972;&#31995;&#32479;&#21442;&#25968;&#65292;FLORAS&#21487;&#20197;&#22312;&#19981;&#22686;&#21152;&#25104;&#26412;&#30340;&#24773;&#20917;&#19979;&#28789;&#27963;&#22320;&#23454;&#29616;&#19981;&#21516;&#30340;DP&#31561;&#32423;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;FL&#25910;&#25947;&#30028;&#38480;&#65292;&#32467;&#21512;&#38544;&#31169;&#20445;&#35777;&#65292;&#21487;&#20197;&#22312;&#25910;&#25947;&#36895;&#24230;&#21644;&#24046;&#20998;&#38544;&#31169;&#32423;&#21035;&#20043;&#38388;&#23454;&#29616;&#24179;&#31283;&#30340;&#26435;&#34913;&#12290;&#25968;&#20540;&#32467;&#26524;&#35777;&#26126;&#20102;FLORAS&#30456;&#23545;&#20110;&#22522;&#20934;AirComp&#26041;&#27861;&#30340;&#20248;&#21183;&#65292;&#24182;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#20998;&#26512;&#32467;&#26524;&#21487;&#20197;&#25351;&#23548;&#19981;&#21516;&#26435;&#34913;&#26465;&#20214;&#19979;&#30340;&#38544;&#31169;&#20445;&#25252;FL&#30340;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel privacy-preserving uplink over-the-air computation (AirComp) method, termed FLORAS, for single-input single-output (SISO) wireless federated learning (FL) systems. From the communication design perspective, FLORAS eliminates the requirement of channel state information at the transmitters (CSIT) by leveraging the properties of orthogonal sequences. From the privacy perspective, we prove that FLORAS can offer both item-level and client-level differential privacy (DP) guarantees. Moreover, by adjusting the system parameters, FLORAS can flexibly achieve different DP levels at no additional cost. A novel FL convergence bound is derived which, combined with the privacy guarantees, allows for a smooth tradeoff between convergence rate and differential privacy levels. Numerical results demonstrate the advantages of FLORAS compared with the baseline AirComp method, and validate that our analytical results can guide the design of privacy-preserving FL with different tradeoff 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Wasserstein&#36317;&#31163;&#30340;&#25439;&#22833;&#20989;&#25968;hinge-Wasserstein&#65292;&#29992;&#20110;&#32531;&#35299;&#22238;&#24402;&#20219;&#21153;&#20013;&#30001;&#20110;&#36807;&#24230;&#33258;&#20449;&#23548;&#33268;&#30340;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#12290;&#36825;&#31181;&#25439;&#22833;&#20989;&#25968;&#26377;&#25928;&#25552;&#39640;&#20102;aleatoric&#21644;epistemic&#19981;&#30830;&#23450;&#24615;&#30340;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2306.00560</link><description>&lt;p&gt;
Hinge-Wasserstein: &#36890;&#36807;&#20998;&#31867;&#36991;&#20813;&#22238;&#24402;&#20013;&#30340;&#36807;&#24230;&#33258;&#20449;
&lt;/p&gt;
&lt;p&gt;
Hinge-Wasserstein: Mitigating Overconfidence in Regression by Classification. (arXiv:2306.00560v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00560
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Wasserstein&#36317;&#31163;&#30340;&#25439;&#22833;&#20989;&#25968;hinge-Wasserstein&#65292;&#29992;&#20110;&#32531;&#35299;&#22238;&#24402;&#20219;&#21153;&#20013;&#30001;&#20110;&#36807;&#24230;&#33258;&#20449;&#23548;&#33268;&#30340;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#12290;&#36825;&#31181;&#25439;&#22833;&#20989;&#25968;&#26377;&#25928;&#25552;&#39640;&#20102;aleatoric&#21644;epistemic&#19981;&#30830;&#23450;&#24615;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#24615;&#33021;&#26041;&#38754;&#24471;&#21040;&#20102;&#24040;&#22823;&#30340;&#25552;&#39640;&#65292;&#20294;&#23427;&#20204;&#23481;&#26131;&#20135;&#29983;&#36807;&#24230;&#33258;&#20449;&#12290;&#22312;&#27169;&#31946;&#29978;&#33267;&#19981;&#21487;&#39044;&#27979;&#30340;&#29616;&#23454;&#19990;&#30028;&#22330;&#26223;&#20013;&#65292;&#36825;&#31181;&#36807;&#24230;&#33258;&#20449;&#21487;&#33021;&#23545;&#24212;&#29992;&#31243;&#24207;&#30340;&#23433;&#20840;&#24615;&#26500;&#25104;&#37325;&#22823;&#39118;&#38505;&#12290;&#38024;&#23545;&#22238;&#24402;&#20219;&#21153;&#65292;&#37319;&#29992;&#22238;&#24402;-&#20998;&#31867;&#26041;&#27861;&#26377;&#28508;&#21147;&#32531;&#35299;&#36825;&#20123;&#27495;&#20041;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#39044;&#27979;&#25152;&#38656;&#36755;&#20986;&#30340;&#31163;&#25955;&#27010;&#29575;&#23494;&#24230;&#12290;&#28982;&#32780;&#65292;&#23494;&#24230;&#20272;&#35745;&#20173;&#28982;&#20542;&#21521;&#20110;&#36807;&#24230;&#33258;&#20449;&#65292;&#23588;&#20854;&#26159;&#22312;&#20351;&#29992;&#24120;&#35265;&#30340;NLL&#25439;&#22833;&#20989;&#25968;&#35757;&#32451;&#26102;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#31181;&#36807;&#24230;&#33258;&#20449;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Wasserstein&#36317;&#31163;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#21363;hinge-Wasserstein&#12290;&#19982;&#20197;&#21069;&#30340;&#24037;&#20316;&#30456;&#27604;&#65292;&#27492;&#25439;&#22833;&#26174;&#30528;&#25552;&#39640;&#20102;&#20004;&#31181;&#19981;&#30830;&#23450;&#24615;&#30340;&#36136;&#37327;&#65306; aleatoric&#19981;&#30830;&#23450;&#24615;&#21644;epistemic&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#26032;&#25439;&#22833;&#30340;&#33021;&#21147;&#65292;&#20854;&#20013;&#20004;&#31181;&#31867;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#21487;&#20197;&#20998;&#21035;&#25511;&#21046;&#12290;&#27492;&#22806;&#65292;&#20316;&#20026;&#29616;&#23454;&#19990;&#30028;&#22330;&#26223;&#30340;&#28436;&#31034;&#65292;&#25105;&#20204;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern deep neural networks are prone to being overconfident despite their drastically improved performance. In ambiguous or even unpredictable real-world scenarios, this overconfidence can pose a major risk to the safety of applications. For regression tasks, the regression-by-classification approach has the potential to alleviate these ambiguities by instead predicting a discrete probability density over the desired output. However, a density estimator still tends to be overconfident when trained with the common NLL loss. To mitigate the overconfidence problem, we propose a loss function, hinge-Wasserstein, based on the Wasserstein Distance. This loss significantly improves the quality of both aleatoric and epistemic uncertainty, compared to previous work. We demonstrate the capabilities of the new loss on a synthetic dataset, where both types of uncertainty are controlled separately. Moreover, as a demonstration for real-world scenarios, we evaluate our approach on the benchmark dat
&lt;/p&gt;</description></item></channel></rss>