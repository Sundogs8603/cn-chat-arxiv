<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;Lipschitz&#24120;&#25968;&#65292;&#23545;&#20110;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;Lipschitz&#24120;&#25968;&#30340;&#31934;&#30830;&#21051;&#30011;&#65292;&#23545;&#20110;&#36275;&#22815;&#23485;&#24230;&#30340;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19978;&#19979;&#30028;&#65292;&#24182;&#21305;&#37197;&#19968;&#20010;&#20381;&#36182;&#20110;&#28145;&#24230;&#30340;&#23545;&#25968;&#22240;&#23376;&#12290;</title><link>http://arxiv.org/abs/2311.01356</link><description>&lt;p&gt;
&#20851;&#20110;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#30340;Lipschitz&#24120;&#25968;
&lt;/p&gt;
&lt;p&gt;
On the Lipschitz constant of random neural networks. (arXiv:2311.01356v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01356
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;Lipschitz&#24120;&#25968;&#65292;&#23545;&#20110;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;Lipschitz&#24120;&#25968;&#30340;&#31934;&#30830;&#21051;&#30011;&#65292;&#23545;&#20110;&#36275;&#22815;&#23485;&#24230;&#30340;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19978;&#19979;&#30028;&#65292;&#24182;&#21305;&#37197;&#19968;&#20010;&#20381;&#36182;&#20110;&#28145;&#24230;&#30340;&#23545;&#25968;&#22240;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#35777;&#30740;&#31350;&#24191;&#27867;&#35777;&#26126;&#31070;&#32463;&#32593;&#32476;&#23545;&#36755;&#20837;&#30340;&#24494;&#23567;&#23545;&#25239;&#24615;&#25200;&#21160;&#38750;&#24120;&#25935;&#24863;&#12290;&#36825;&#20123;&#25152;&#35859;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#30340;&#26368;&#22351;&#24773;&#20917;&#40065;&#26834;&#24615;&#21487;&#20197;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#30340;Lipschitz&#24120;&#25968;&#26469;&#37327;&#21270;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#36825;&#20010;&#37327;&#30340;&#29702;&#35770;&#32467;&#26524;&#22312;&#25991;&#29486;&#20013;&#20165;&#26377;&#23569;&#25968;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#22987;&#30740;&#31350;&#38543;&#26426;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;Lipschitz&#24120;&#25968;&#65292;&#21363;&#36873;&#25321;&#38543;&#26426;&#26435;&#37325;&#24182;&#37319;&#29992;ReLU&#28608;&#27963;&#20989;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#23545;&#20110;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#23558;Lipschitz&#24120;&#25968;&#21051;&#30011;&#21040;&#19968;&#20010;&#32477;&#23545;&#25968;&#20540;&#24120;&#25968;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#20998;&#26512;&#25193;&#23637;&#21040;&#36275;&#22815;&#23485;&#24230;&#30340;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;Lipschitz&#24120;&#25968;&#30340;&#19978;&#19979;&#30028;&#12290;&#36825;&#20123;&#30028;&#21305;&#37197;&#21040;&#19968;&#20010;&#20381;&#36182;&#20110;&#28145;&#24230;&#30340;&#23545;&#25968;&#22240;&#23376;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
Empirical studies have widely demonstrated that neural networks are highly sensitive to small, adversarial perturbations of the input. The worst-case robustness against these so-called adversarial examples can be quantified by the Lipschitz constant of the neural network. However, only few theoretical results regarding this quantity exist in the literature. In this paper, we initiate the study of the Lipschitz constant of random ReLU neural networks, i.e., neural networks whose weights are chosen at random and which employ the ReLU activation function. For shallow neural networks, we characterize the Lipschitz constant up to an absolute numerical constant. Moreover, we extend our analysis to deep neural networks of sufficiently large width where we prove upper and lower bounds for the Lipschitz constant. These bounds match up to a logarithmic factor that depends on the depth.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19978;&#19979;&#25991;&#21270;&#25919;&#31574;&#24674;&#22797;&#26041;&#27861;&#29992;&#20110;&#24314;&#27169;&#22797;&#26434;&#30340;&#21307;&#30103;&#20915;&#31574;&#36807;&#31243;&#65292;&#20197;&#35299;&#20915;&#29616;&#26377;&#27169;&#22411;&#22312;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#23558;&#20915;&#31574;&#31574;&#30053;&#25286;&#20998;&#20026;&#19978;&#19979;&#25991;&#29305;&#23450;&#31574;&#30053;&#65292;&#36890;&#36807;&#22810;&#20219;&#21153;&#23398;&#20064;&#26469;&#23454;&#29616;&#24314;&#27169;&#65292;&#24182;&#25552;&#20379;&#22797;&#26434;&#34892;&#20026;&#30340;&#31616;&#27905;&#25551;&#36848;&#12290;</title><link>http://arxiv.org/abs/2310.07918</link><description>&lt;p&gt;
&#19978;&#19979;&#25991;&#21270;&#25919;&#31574;&#24674;&#22797;&#65306;&#36890;&#36807;&#33258;&#36866;&#24212;&#27169;&#20223;&#23398;&#20064;&#23545;&#21307;&#30103;&#20915;&#31574;&#36827;&#34892;&#24314;&#27169;&#21644;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Contextualized Policy Recovery: Modeling and Interpreting Medical Decisions with Adaptive Imitation Learning. (arXiv:2310.07918v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07918
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19978;&#19979;&#25991;&#21270;&#25919;&#31574;&#24674;&#22797;&#26041;&#27861;&#29992;&#20110;&#24314;&#27169;&#22797;&#26434;&#30340;&#21307;&#30103;&#20915;&#31574;&#36807;&#31243;&#65292;&#20197;&#35299;&#20915;&#29616;&#26377;&#27169;&#22411;&#22312;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#23558;&#20915;&#31574;&#31574;&#30053;&#25286;&#20998;&#20026;&#19978;&#19979;&#25991;&#29305;&#23450;&#31574;&#30053;&#65292;&#36890;&#36807;&#22810;&#20219;&#21153;&#23398;&#20064;&#26469;&#23454;&#29616;&#24314;&#27169;&#65292;&#24182;&#25552;&#20379;&#22797;&#26434;&#34892;&#20026;&#30340;&#31616;&#27905;&#25551;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#31574;&#30053;&#23398;&#20064;&#26088;&#22312;&#20174;&#35266;&#23519;&#21040;&#30340;&#34892;&#20026;&#20013;&#20272;&#35745;&#21487;&#29702;&#35299;&#30340;&#20915;&#31574;&#31574;&#30053;&#65307;&#28982;&#32780;&#65292;&#29616;&#26377;&#27169;&#22411;&#22312;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#20043;&#38388;&#23384;&#22312;&#26435;&#34913;&#12290;&#36825;&#31181;&#26435;&#34913;&#38480;&#21046;&#20102;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#23545;&#20154;&#31867;&#20915;&#31574;&#36807;&#31243;&#30340;&#35299;&#37322;&#65292;&#20363;&#22914;&#65292;&#23457;&#35745;&#21307;&#30103;&#20915;&#31574;&#30340;&#20559;&#35265;&#21644;&#27425;&#20248;&#23454;&#36341;&#65292;&#25105;&#20204;&#38656;&#35201;&#20915;&#31574;&#36807;&#31243;&#30340;&#27169;&#22411;&#65292;&#33021;&#22815;&#25552;&#20379;&#22797;&#26434;&#34892;&#20026;&#30340;&#31616;&#27905;&#25551;&#36848;&#12290;&#29616;&#26377;&#26041;&#27861;&#22522;&#26412;&#19978;&#30001;&#20110;&#23558;&#28508;&#22312;&#20915;&#31574;&#36807;&#31243;&#34920;&#31034;&#20026;&#36890;&#29992;&#31574;&#30053;&#32780;&#36127;&#25285;&#20102;&#36825;&#31181;&#26435;&#34913;&#65292;&#32780;&#23454;&#38469;&#19978;&#20154;&#31867;&#20915;&#31574;&#26159;&#21160;&#24577;&#30340;&#65292;&#21487;&#20197;&#38543;&#19978;&#19979;&#25991;&#20449;&#24687;&#32780;&#22823;&#24133;&#25913;&#21464;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19978;&#19979;&#25991;&#21270;&#25919;&#31574;&#24674;&#22797;&#65288;CPR&#65289;&#65292;&#23558;&#24314;&#27169;&#22797;&#26434;&#20915;&#31574;&#36807;&#31243;&#30340;&#38382;&#39064;&#37325;&#26032;&#23450;&#20041;&#20026;&#22810;&#20219;&#21153;&#23398;&#20064;&#38382;&#39064;&#65292;&#20854;&#20013;&#22797;&#26434;&#20915;&#31574;&#31574;&#30053;&#30001;&#29305;&#23450;&#19978;&#19979;&#25991;&#30340;&#31574;&#30053;&#32452;&#25104;&#12290;CPR&#23558;&#27599;&#20010;&#19978;&#19979;&#25991;&#29305;&#23450;&#31574;&#30053;&#24314;&#27169;&#20026;&#32447;&#24615;&#30340;&#35266;&#23519;-&#21160;&#20316;&#26144;&#23556;
&lt;/p&gt;
&lt;p&gt;
Interpretable policy learning seeks to estimate intelligible decision policies from observed actions; however, existing models fall short by forcing a tradeoff between accuracy and interpretability. This tradeoff limits data-driven interpretations of human decision-making process. e.g. to audit medical decisions for biases and suboptimal practices, we require models of decision processes which provide concise descriptions of complex behaviors. Fundamentally, existing approaches are burdened by this tradeoff because they represent the underlying decision process as a universal policy, when in fact human decisions are dynamic and can change drastically with contextual information. Thus, we propose Contextualized Policy Recovery (CPR), which re-frames the problem of modeling complex decision processes as a multi-task learning problem in which complex decision policies are comprised of context-specific policies. CPR models each context-specific policy as a linear observation-to-action mapp
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;WSINDy&#36827;&#34892;&#31895;&#31890;&#21270;&#21704;&#23494;&#39039;&#31995;&#32479;&#30340;&#38382;&#39064;&#65292;&#25193;&#23637;&#20102;WSINDy&#22312;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#31995;&#32479;&#20013;&#30340;&#31895;&#31890;&#21270;&#33021;&#21147;&#12290;&#36890;&#36807;&#35782;&#21035;&#36817;&#20284;&#23545;&#31216;&#24615;&#21644;&#22788;&#29702;&#22806;&#37096;&#25200;&#21160;&#65292;WSINDy&#25104;&#21151;&#22320;&#35782;&#21035;&#20986;&#38477;&#32500;&#30340;&#21704;&#23494;&#39039;&#31995;&#32479;&#65292;&#20174;&#32780;&#26377;&#25928;&#22320;&#25429;&#25417;&#20102;&#30456;&#20851;&#33258;&#30001;&#24230;&#30340;&#21160;&#21147;&#23398;&#12290;</title><link>http://arxiv.org/abs/2310.05879</link><description>&lt;p&gt;
&#20351;&#29992;WSINDy&#36827;&#34892;&#31895;&#31890;&#21270;&#21704;&#23494;&#39039;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Coarse-Graining Hamiltonian Systems Using WSINDy. (arXiv:2310.05879v1 [physics.comp-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05879
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;WSINDy&#36827;&#34892;&#31895;&#31890;&#21270;&#21704;&#23494;&#39039;&#31995;&#32479;&#30340;&#38382;&#39064;&#65292;&#25193;&#23637;&#20102;WSINDy&#22312;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#31995;&#32479;&#20013;&#30340;&#31895;&#31890;&#21270;&#33021;&#21147;&#12290;&#36890;&#36807;&#35782;&#21035;&#36817;&#20284;&#23545;&#31216;&#24615;&#21644;&#22788;&#29702;&#22806;&#37096;&#25200;&#21160;&#65292;WSINDy&#25104;&#21151;&#22320;&#35782;&#21035;&#20986;&#38477;&#32500;&#30340;&#21704;&#23494;&#39039;&#31995;&#32479;&#65292;&#20174;&#32780;&#26377;&#25928;&#22320;&#25429;&#25417;&#20102;&#30456;&#20851;&#33258;&#30001;&#24230;&#30340;&#21160;&#21147;&#23398;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#31995;&#32479;&#30340;&#32972;&#26223;&#19979;&#65292;&#24050;&#32463;&#35777;&#26126;&#20102;&#24369;&#24418;&#24577;&#31232;&#30095;&#35782;&#21035;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#31639;&#27861;(WSINDy)&#20855;&#26377;&#31895;&#31890;&#21270;&#33021;&#21147;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;&#36825;&#31181;&#33021;&#21147;&#25193;&#23637;&#21040;&#20855;&#26377;&#36817;&#20284;&#23545;&#31216;&#24615;&#30340;&#21704;&#23494;&#39039;&#21160;&#21147;&#23398;&#30340;&#31895;&#31890;&#21270;&#38382;&#39064;&#19978;&#12290;&#36825;&#31181;&#36817;&#20284;&#23545;&#31216;&#24615;&#36890;&#24120;&#23548;&#33268;&#23384;&#22312;&#19968;&#20010;&#38477;&#32500;&#30340;&#21704;&#23494;&#39039;&#31995;&#32479;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#25429;&#25417;&#30456;&#20851;&#33258;&#30001;&#24230;&#30340;&#21160;&#21147;&#23398;&#12290;&#23548;&#20986;&#36825;&#26679;&#30340;&#38477;&#32500;&#31995;&#32479;&#65292;&#25110;&#32773;&#36890;&#36807;&#25968;&#20540;&#26041;&#27861;&#23545;&#20854;&#36827;&#34892;&#36817;&#20284;&#65292;&#26159;&#19968;&#20010;&#25345;&#32493;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;WSINDy&#21487;&#20197;&#25104;&#21151;&#22320;&#22312;&#23545;&#31216;&#19981;&#31934;&#30830;&#24615;&#21644;&#22806;&#37096;&#22122;&#22768;&#30340;&#24433;&#21709;&#19979;&#35782;&#21035;&#20986;&#36825;&#20010;&#38477;&#32500;&#30340;&#21704;&#23494;&#39039;&#31995;&#32479;&#12290;&#36825;&#22312;&#19968;&#37096;&#20998;&#26159;&#22240;&#20026;&#36825;&#26679;&#30340;&#31995;&#32479;&#22914;&#20309;&#34987;&#35299;&#26512;&#22320;&#23548;&#20986;&#26159;&#38750;&#24179;&#20961;&#30340;&#12290;WSINDy&#33258;&#28982;&#22320;&#20445;&#30041;&#20102;&#21704;&#23494;&#39039;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Weak-form Sparse Identification of Nonlinear Dynamics algorithm (WSINDy) has been demonstrated to offer coarse-graining capabilities in the context of interacting particle systems ( https://doi.org/10.1016/j.physd.2022.133406 ). In this work we extend this capability to the problem of coarse-graining Hamiltonian dynamics which possess approximate symmetries. Such approximate symmetries often lead to the existence of a Hamiltonian system of reduced dimension that may be used to efficiently capture the dynamics of the relevant degrees of freedom. Deriving such reduced systems, or approximating them numerically, is an ongoing challenge. We demonstrate that WSINDy can successfully identify this reduced Hamiltonian system in the presence of large perturbations imparted from both the inexact nature of the symmetry and extrinsic noise. This is significant in part due to the nontrivial means by which such systems are derived analytically. WSINDy naturally preserves the Hamiltonian structur
&lt;/p&gt;</description></item><item><title>beta&#25193;&#25955;&#26159;&#19968;&#31181;&#26032;&#22411;&#29983;&#25104;&#27169;&#22411;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#21435;&#25513;&#30422;&#21644;&#21435;&#22122;&#30340;&#25216;&#26415;&#65292;&#21033;&#29992;&#32553;&#25918;&#21644;&#20559;&#31227;&#30340;beta&#20998;&#24067;&#36827;&#34892;&#20056;&#27861;&#36716;&#25442;&#65292;&#23454;&#29616;&#22312;&#26377;&#30028;&#33539;&#22260;&#20869;&#29983;&#25104;&#25968;&#25454;&#12290;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;KL&#25955;&#24230;&#19978;&#30028;&#36827;&#34892;&#20248;&#21270;&#65292;&#35777;&#26126;&#20102;&#25928;&#26524;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2309.07867</link><description>&lt;p&gt;
Beta Diffusion. (arXiv:2309.07867v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
Beta Diffusion. (arXiv:2309.07867v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07867
&lt;/p&gt;
&lt;p&gt;
beta&#25193;&#25955;&#26159;&#19968;&#31181;&#26032;&#22411;&#29983;&#25104;&#27169;&#22411;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#21435;&#25513;&#30422;&#21644;&#21435;&#22122;&#30340;&#25216;&#26415;&#65292;&#21033;&#29992;&#32553;&#25918;&#21644;&#20559;&#31227;&#30340;beta&#20998;&#24067;&#36827;&#34892;&#20056;&#27861;&#36716;&#25442;&#65292;&#23454;&#29616;&#22312;&#26377;&#30028;&#33539;&#22260;&#20869;&#29983;&#25104;&#25968;&#25454;&#12290;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;KL&#25955;&#24230;&#19978;&#30028;&#36827;&#34892;&#20248;&#21270;&#65292;&#35777;&#26126;&#20102;&#25928;&#26524;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;beta&#25193;&#25955;&#65292;&#19968;&#31181;&#23558;&#21435;&#25513;&#30422;&#21644;&#21435;&#22122;&#38598;&#25104;&#21040;&#19968;&#36215;&#30340;&#26032;&#22411;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#26377;&#30028;&#33539;&#22260;&#20869;&#29983;&#25104;&#25968;&#25454;&#12290;&#20351;&#29992;&#20102;&#32553;&#25918;&#21644;&#20559;&#31227;&#30340;beta&#20998;&#24067;&#65292;beta&#25193;&#25955;&#21033;&#29992;&#20102;&#38543;&#26102;&#38388;&#30340;&#20056;&#27861;&#36716;&#25442;&#26469;&#21019;&#24314;&#27491;&#21521;&#21644;&#21453;&#21521;&#30340;&#25193;&#25955;&#36807;&#31243;&#65292;&#21516;&#26102;&#32500;&#25345;&#30528;&#27491;&#21521;&#36793;&#32536;&#20998;&#24067;&#21644;&#21453;&#21521;&#26465;&#20214;&#20998;&#24067;&#65292;&#32473;&#23450;&#20219;&#24847;&#26102;&#38388;&#28857;&#30340;&#25968;&#25454;&#12290;&#19982;&#20256;&#32479;&#30340;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#19981;&#21516;&#65292;&#20256;&#32479;&#27169;&#22411;&#20381;&#36182;&#20110;&#21152;&#24615;&#39640;&#26031;&#22122;&#22768;&#21644;&#37325;&#26032;&#21152;&#26435;&#30340;&#35777;&#25454;&#19979;&#30028;&#65288;ELBO&#65289;&#65292;beta&#25193;&#25955;&#26159;&#20056;&#27861;&#30340;&#65292;&#24182;&#19988;&#36890;&#36807;&#20174;KL&#25955;&#24230;&#30340;&#20984;&#24615;&#25512;&#23548;&#20986;&#26469;&#30340;KL&#25955;&#24230;&#19978;&#30028;&#65288;KLUB&#65289;&#36827;&#34892;&#20248;&#21270;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;KLUB&#30456;&#23545;&#20110;&#36127;ELBO&#26469;&#35828;&#23545;&#20110;&#20248;&#21270;beta&#25193;&#25955;&#26356;&#21152;&#26377;&#25928;&#65292;&#36127;ELBO&#20063;&#21487;&#20197;&#20316;&#20026;&#30456;&#21516;KL&#25955;&#24230;&#30340;KLUB&#65292;&#21482;&#26159;&#20854;&#20004;&#20010;&#21442;&#25968;&#20132;&#25442;&#20102;&#20301;&#32622;&#12290;beta&#25193;&#25955;&#30340;&#25439;&#22833;&#20989;&#25968;&#20197;Bregman&#25955;&#24230;&#20026;&#25351;&#26631;&#26469;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce beta diffusion, a novel generative modeling method that integrates demasking and denoising to generate data within bounded ranges. Using scaled and shifted beta distributions, beta diffusion utilizes multiplicative transitions over time to create both forward and reverse diffusion processes, maintaining beta distributions in both the forward marginals and the reverse conditionals, given the data at any point in time. Unlike traditional diffusion-based generative models relying on additive Gaussian noise and reweighted evidence lower bounds (ELBOs), beta diffusion is multiplicative and optimized with KL-divergence upper bounds (KLUBs) derived from the convexity of the KL divergence. We demonstrate that the proposed KLUBs are more effective for optimizing beta diffusion compared to negative ELBOs, which can also be derived as the KLUBs of the same KL divergence with its two arguments swapped. The loss function of beta diffusion, expressed in terms of Bregman divergence, furt
&lt;/p&gt;</description></item><item><title>QuantEase&#26159;&#19968;&#31181;&#22522;&#20110;&#20248;&#21270;&#30340;&#35821;&#35328;&#27169;&#22411;&#37327;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#36880;&#23618;&#37327;&#21270;&#21644;&#22522;&#20110;&#22352;&#26631;&#19979;&#38477;&#30340;&#31639;&#27861;&#65292;&#39640;&#36136;&#37327;&#22320;&#35299;&#20915;&#20102;&#22797;&#26434;&#30340;&#38750;&#20984;&#37327;&#21270;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#23545;&#24322;&#24120;&#20540;&#25935;&#24863;&#30340;&#21464;&#31181;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.01885</link><description>&lt;p&gt;
QuantEase: &#22522;&#20110;&#20248;&#21270;&#30340;&#35821;&#35328;&#27169;&#22411;&#37327;&#21270;--&#19968;&#31181;&#39640;&#25928;&#32780;&#30452;&#35266;&#30340;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
QuantEase: Optimization-based Quantization for Language Models -- An Efficient and Intuitive Algorithm. (arXiv:2309.01885v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01885
&lt;/p&gt;
&lt;p&gt;
QuantEase&#26159;&#19968;&#31181;&#22522;&#20110;&#20248;&#21270;&#30340;&#35821;&#35328;&#27169;&#22411;&#37327;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#36880;&#23618;&#37327;&#21270;&#21644;&#22522;&#20110;&#22352;&#26631;&#19979;&#38477;&#30340;&#31639;&#27861;&#65292;&#39640;&#36136;&#37327;&#22320;&#35299;&#20915;&#20102;&#22797;&#26434;&#30340;&#38750;&#20984;&#37327;&#21270;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#23545;&#24322;&#24120;&#20540;&#25935;&#24863;&#30340;&#21464;&#31181;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#26222;&#21450;&#65292;&#23545;&#20110;&#33021;&#22815;&#23454;&#29616;&#20854;&#39640;&#25928;&#37096;&#32626;&#30340;&#21387;&#32553;&#25216;&#26415;&#30340;&#20852;&#36259;&#26085;&#30410;&#22686;&#21152;&#12290;&#26412;&#30740;&#31350;&#20391;&#37325;&#20110;LLM&#30340;&#21518;&#35757;&#32451;&#37327;&#21270;&#65288;PTQ&#65289;&#12290;&#20511;&#37492;&#26368;&#36817;&#30340;&#36827;&#23637;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#24341;&#20837;&#20102;QuantEase&#65292;&#19968;&#20010;&#36880;&#23618;&#37327;&#21270;&#26694;&#26550;&#65292;&#20854;&#20013;&#21508;&#20010;&#23618;&#38754;&#32463;&#36807;&#21333;&#29420;&#30340;&#37327;&#21270;&#12290;&#35813;&#38382;&#39064;&#34987;&#35270;&#20026;&#31163;&#25955;&#32467;&#26500;&#21270;&#30340;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#20419;&#20351;&#25105;&#20204;&#24320;&#21457;&#20102;&#22522;&#20110;&#22352;&#26631;&#19979;&#38477;&#65288;CD&#65289;&#25216;&#26415;&#30340;&#31639;&#27861;&#12290;&#36825;&#20123;&#22522;&#20110;CD&#30340;&#26041;&#27861;&#20026;&#22797;&#26434;&#30340;&#38750;&#20984;&#36880;&#23618;&#37327;&#21270;&#38382;&#39064;&#25552;&#20379;&#20102;&#39640;&#36136;&#37327;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;CD&#26041;&#27861;&#20855;&#26377;&#31616;&#21333;&#30340;&#26356;&#26032;&#27493;&#39588;&#65292;&#20165;&#20381;&#36182;&#20110;&#30697;&#38453;&#21644;&#21521;&#37327;&#36816;&#31639;&#65292;&#36991;&#20813;&#20102;&#30697;&#38453;&#27714;&#36870;&#25110;&#20998;&#35299;&#30340;&#38656;&#35201;&#12290;&#25105;&#20204;&#36824;&#25506;&#32034;&#20102;&#19968;&#31181;&#23545;&#24322;&#24120;&#20540;&#25935;&#24863;&#30340;&#21464;&#31181;&#26041;&#27861;&#65292;&#20801;&#35768;&#20445;&#30041;&#20855;&#26377;&#23436;&#20840;&#31934;&#24230;&#30340;&#37325;&#35201;&#26435;&#37325;&#65288;&#24322;&#24120;&#20540;&#65289;&#12290;&#25105;&#20204;&#30340;&#25552;&#35758;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#29366;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the rising popularity of Large Language Models (LLMs), there has been an increasing interest in compression techniques that enable their efficient deployment. This study focuses on the Post-Training Quantization (PTQ) of LLMs. Drawing from recent advances, our work introduces QuantEase, a layer-wise quantization framework where individual layers undergo separate quantization. The problem is framed as a discrete-structured non-convex optimization, prompting the development of algorithms rooted in Coordinate Descent (CD) techniques. These CD-based methods provide high-quality solutions to the complex non-convex layer-wise quantization problems. Notably, our CD-based approach features straightforward updates, relying solely on matrix and vector operations, circumventing the need for matrix inversion or decomposition. We also explore an outlier-aware variant of our approach, allowing for retaining significant weights (outliers) with complete precision. Our proposal attains state-of-th
&lt;/p&gt;</description></item><item><title>GeoPhy&#26159;&#19968;&#31181;&#21019;&#26032;&#30340;&#12289;&#23436;&#20840;&#21487;&#24494;&#30340;&#31995;&#32479;&#21457;&#32946;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#36830;&#32493;&#20960;&#20309;&#31354;&#38388;&#20013;&#34920;&#31034;&#25299;&#25169;&#20998;&#24067;&#65292;&#23454;&#29616;&#20102;&#21487;&#25193;&#23637;&#30340;&#21464;&#20998;&#25512;&#26029;&#65292;&#20811;&#26381;&#20102;&#19981;&#38480;&#21046;&#25299;&#25169;&#32467;&#26500;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2307.03675</link><description>&lt;p&gt;
GeoPhy: &#21033;&#29992;&#20960;&#20309;&#26799;&#24230;&#23454;&#29616;&#21487;&#24494;&#20998;&#30340;&#31995;&#32479;&#21457;&#32946;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
GeoPhy: Differentiable Phylogenetic Inference via Geometric Gradients of Tree Topologies. (arXiv:2307.03675v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03675
&lt;/p&gt;
&lt;p&gt;
GeoPhy&#26159;&#19968;&#31181;&#21019;&#26032;&#30340;&#12289;&#23436;&#20840;&#21487;&#24494;&#30340;&#31995;&#32479;&#21457;&#32946;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#36830;&#32493;&#20960;&#20309;&#31354;&#38388;&#20013;&#34920;&#31034;&#25299;&#25169;&#20998;&#24067;&#65292;&#23454;&#29616;&#20102;&#21487;&#25193;&#23637;&#30340;&#21464;&#20998;&#25512;&#26029;&#65292;&#20811;&#26381;&#20102;&#19981;&#38480;&#21046;&#25299;&#25169;&#32467;&#26500;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31995;&#32479;&#21457;&#32946;&#25512;&#26029;&#26159;&#22312;&#20998;&#23376;&#36827;&#21270;&#27169;&#22411;&#22522;&#30784;&#19978;&#36827;&#34892;&#30340;&#65292;&#23427;&#23545;&#20110;&#29702;&#35299;&#29983;&#29289;&#25968;&#25454;&#20013;&#30340;&#36827;&#21270;&#20851;&#31995;&#33267;&#20851;&#37325;&#35201;&#12290;&#32771;&#34385;&#21040;&#36827;&#21270;&#26641;&#21464;&#37327;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#21253;&#25324;&#26641;&#25299;&#25169;&#32467;&#26500;&#21644;&#20998;&#25903;&#19978;&#30340;&#36827;&#21270;&#36317;&#31163;&#65292;&#23545;&#20110;&#20934;&#30830;&#22320;&#20174;&#20998;&#23376;&#25968;&#25454;&#20013;&#25512;&#26029;&#29289;&#31181;&#20851;&#31995;&#20197;&#21450;&#38656;&#35201;&#36827;&#34892;&#21464;&#37327;&#36793;&#32536;&#21270;&#30340;&#20219;&#21153;&#26469;&#35828;&#33267;&#20851;&#37325;&#35201;&#12290;&#21464;&#20998;&#36125;&#21494;&#26031;&#26041;&#27861;&#26159;&#24320;&#21457;&#21487;&#25193;&#23637;&#12289;&#23454;&#29992;&#27169;&#22411;&#30340;&#20851;&#38190;&#65292;&#28982;&#32780;&#65292;&#22312;&#19981;&#38480;&#21046;&#21487;&#33021;&#30340;&#26641;&#25299;&#25169;&#32467;&#26500;&#30340;&#32452;&#21512;&#25968;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#31995;&#32479;&#21457;&#32946;&#25512;&#26029;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#12289;&#23436;&#20840;&#21487;&#24494;&#30340;&#31995;&#32479;&#21457;&#32946;&#25512;&#26029;&#20844;&#24335;&#65292;&#21033;&#29992;&#36830;&#32493;&#20960;&#20309;&#31354;&#38388;&#20013;&#30340;&#25299;&#25169;&#20998;&#24067;&#26469;&#34920;&#31034;&#12290;&#36890;&#36807;&#23545;&#35774;&#35745;&#31354;&#38388;&#21644;&#28176;&#36817;&#30697;&#30340;&#23454;&#38469;&#32771;&#34385;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;GeoPhy&#21487;&#20197;&#23454;&#29616;&#21464;&#20998;&#25512;&#26029;&#32780;&#19981;&#38480;&#21046;&#25299;&#25169;&#32467;&#26500;&#30340;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Phylogenetic inference, grounded in molecular evolution models, is essential for understanding the evolutionary relationships in biological data. Accounting for the uncertainty of phylogenetic tree variables, which include tree topologies and evolutionary distances on branches, is crucial for accurately inferring species relationships from molecular data and tasks requiring variable marginalization. Variational Bayesian methods are key to developing scalable, practical models; however, it remains challenging to conduct phylogenetic inference without restricting the combinatorially vast number of possible tree topologies. In this work, we introduce a novel, fully differentiable formulation of phylogenetic inference that leverages a unique representation of topological distributions in continuous geometric spaces. Through practical considerations on design spaces and control variates for gradient estimations, our approach, GeoPhy, enables variational inference without limiting the topolo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23450;&#20041;&#29420;&#31435;&#22240;&#26524;&#26426;&#21046;&#65292;&#25552;&#20986;&#20102;ICM-VAE&#26694;&#26550;&#65292;&#20351;&#24471;&#23398;&#20064;&#22240;&#26524;&#35299;&#32544;&#32469;&#34920;&#31034;&#26356;&#20934;&#30830;</title><link>http://arxiv.org/abs/2306.01213</link><description>&lt;p&gt;
&#22522;&#20110;&#29420;&#31435;&#22240;&#26524;&#26426;&#21046;&#21407;&#21017;&#23398;&#20064;&#22240;&#26524;&#35299;&#32544;&#32469;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Learning Causally Disentangled Representations via the Principle of Independent Causal Mechanisms. (arXiv:2306.01213v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01213
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23450;&#20041;&#29420;&#31435;&#22240;&#26524;&#26426;&#21046;&#65292;&#25552;&#20986;&#20102;ICM-VAE&#26694;&#26550;&#65292;&#20351;&#24471;&#23398;&#20064;&#22240;&#26524;&#35299;&#32544;&#32469;&#34920;&#31034;&#26356;&#20934;&#30830;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#35299;&#32544;&#32469;&#30340;&#22240;&#26524;&#34920;&#31034;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#65292;&#36817;&#24180;&#26469;&#22240;&#20854;&#23545;&#25552;&#21462;&#19979;&#28216;&#20219;&#21153;&#30340;&#26377;&#24847;&#20041;&#20449;&#24687;&#32780;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#26412;&#25991;&#20174;&#29420;&#31435;&#22240;&#26524;&#26426;&#21046;&#30340;&#35282;&#24230;&#23450;&#20041;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#35299;&#32544;&#32469;&#27010;&#24565;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;ICM-VAE&#26694;&#26550;&#65292;&#36890;&#36807;&#22240;&#22240;&#26524;&#20851;&#31995;&#35266;&#23519;&#26631;&#31614;&#26469;&#30417;&#30563;&#23398;&#20064;&#22240;&#26524;&#35299;&#32544;&#32469;&#34920;&#31034;&#12290;&#25105;&#20204;&#20351;&#29992;&#21487;&#23398;&#20064;&#30340;&#22522;&#20110;&#27969;&#30340;&#24494;&#20998;&#21516;&#32986;&#20989;&#25968;&#23558;&#22122;&#22768;&#21464;&#37327;&#26144;&#23556;&#21040;&#28508;&#22312;&#22240;&#26524;&#21464;&#37327;&#20013;&#26469;&#24314;&#27169;&#22240;&#26524;&#26426;&#21046;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#20419;&#36827;&#22240;&#26524;&#35201;&#32032;&#30340;&#35299;&#32544;&#32469;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#35299;&#32544;&#32469;&#20808;&#39564;&#65292;&#21033;&#29992;&#24050;&#30693;&#30340;&#22240;&#26524;&#32467;&#26500;&#26469;&#40723;&#21169;&#22312;&#28508;&#22312;&#31354;&#38388;&#20013;&#23398;&#20064;&#22240;&#26524;&#20998;&#35299;&#20998;&#24067;&#12290;&#22312;&#30456;&#23545;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#32467;&#26524;&#65292;&#26174;&#31034;&#20102;&#22240;&#26524;&#35201;&#32032;&#21644;&#26426;&#21046;&#30340;&#21487;&#35782;&#21035;&#24615;&#65292;&#30452;&#21040;&#25490;&#21015;&#21644;&#36880;&#20803;&#37325;&#21442;&#25968;&#21270;&#30340;&#38480;&#24230;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#23454;&#35777;&#30740;&#31350;...
&lt;/p&gt;
&lt;p&gt;
Learning disentangled causal representations is a challenging problem that has gained significant attention recently due to its implications for extracting meaningful information for downstream tasks. In this work, we define a new notion of causal disentanglement from the perspective of independent causal mechanisms. We propose ICM-VAE, a framework for learning causally disentangled representations supervised by causally related observed labels. We model causal mechanisms using learnable flow-based diffeomorphic functions to map noise variables to latent causal variables. Further, to promote the disentanglement of causal factors, we propose a causal disentanglement prior that utilizes the known causal structure to encourage learning a causally factorized distribution in the latent space. Under relatively mild conditions, we provide theoretical results showing the identifiability of causal factors and mechanisms up to permutation and elementwise reparameterization. We empirically demons
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#28151;&#28102;&#37096;&#20998;&#21487;&#35266;&#27979;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#26032;&#22411;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#31163;&#32447;&#35774;&#32622;&#19979;&#21487;&#21516;&#26102;&#22788;&#29702;&#36830;&#32493;&#29366;&#24577;&#21644;&#35266;&#23519;&#31354;&#38388;&#65292;&#20855;&#26377;&#39640;&#25928;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.17083</link><description>&lt;p&gt;
&#19968;&#31181;&#38024;&#23545;&#28151;&#28102;&#37096;&#20998;&#21487;&#35266;&#27979;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Policy Gradient Method for Confounded POMDPs. (arXiv:2305.17083v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17083
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#28151;&#28102;&#37096;&#20998;&#21487;&#35266;&#27979;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#26032;&#22411;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#31163;&#32447;&#35774;&#32622;&#19979;&#21487;&#21516;&#26102;&#22788;&#29702;&#36830;&#32493;&#29366;&#24577;&#21644;&#35266;&#23519;&#31354;&#38388;&#65292;&#20855;&#26377;&#39640;&#25928;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20855;&#26377;&#36830;&#32493;&#29366;&#24577;&#21644;&#35266;&#23519;&#31354;&#38388;&#30340;&#28151;&#28102;&#37096;&#20998;&#21487;&#35266;&#27979;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;POMDP&#65289;&#30340;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#65292;&#22312;&#31163;&#32447;&#35774;&#32622;&#19979;&#20351;&#29992;&#12290;&#25105;&#20204;&#39318;&#20808;&#24314;&#31435;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#35782;&#21035;&#32467;&#26524;&#65292;&#20197;&#22312;&#31163;&#32447;&#25968;&#25454;&#19979;&#38750;&#21442;&#25968;&#22320;&#20272;&#35745;POMDP&#20013;&#30340;&#20219;&#20309;&#21382;&#21490;&#20381;&#36182;&#31574;&#30053;&#26799;&#24230;&#12290;&#35782;&#21035;&#32467;&#26524;&#20351;&#25105;&#20204;&#33021;&#22815;&#35299;&#20915;&#19968;&#31995;&#21015;&#26465;&#20214;&#30697;&#38480;&#21046;&#65292;&#24182;&#37319;&#29992;&#20855;&#26377;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#30340;&#26368;&#23567;&#26368;&#22823;&#23398;&#20064;&#36807;&#31243;&#26469;&#20272;&#35745;&#31574;&#30053;&#26799;&#24230;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#38024;&#23545;&#39044;&#20808;&#25351;&#23450;&#30340;&#31574;&#30053;&#31867;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#38480;&#26679;&#26412;&#30340;&#38750;&#28176;&#36817;&#20272;&#35745;&#30028;&#38480;&#65292;&#20197;&#20102;&#35299;&#26679;&#26412;&#22823;&#23567;&#12289;&#26102;&#38388;&#38271;&#24230;&#12289;&#38598;&#20013;&#24230;&#31995;&#25968;&#21644;&#27714;&#35299;&#26465;&#20214;&#30697;&#38480;&#21046;&#30340;&#20266;&#27491;&#21017;&#24230;&#37327;&#23545;&#20110;&#22343;&#21248;&#20272;&#35745;&#26799;&#24230;&#30340;&#24433;&#21709;&#12290;&#26368;&#21518;&#65292;&#36890;&#36807;&#22312;&#26799;&#24230;&#19978;&#21319;&#31639;&#27861;&#20013;&#20351;&#29992;&#25152;&#25552;&#20986;&#30340;&#26799;&#24230;&#20272;&#35745;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#25214;&#21040;&#21382;&#21490;&#20381;&#36182;&#24615;&#31574;&#30053;&#26799;&#24230;&#26041;&#38754;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a policy gradient method for confounded partially observable Markov decision processes (POMDPs) with continuous state and observation spaces in the offline setting. We first establish a novel identification result to non-parametrically estimate any history-dependent policy gradient under POMDPs using the offline data. The identification enables us to solve a sequence of conditional moment restrictions and adopt the min-max learning procedure with general function approximation for estimating the policy gradient. We then provide a finite-sample non-asymptotic bound for estimating the gradient uniformly over a pre-specified policy class in terms of the sample size, length of horizon, concentratability coefficient and the measure of ill-posedness in solving the conditional moment restrictions. Lastly, by deploying the proposed gradient estimation in the gradient ascent algorithm, we show the global convergence of the proposed algorithm in finding the history-depe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#39532;&#23572;&#31185;&#22827;&#36716;&#25442;&#27169;&#22411;&#30340;&#21487;&#36776;&#35782;&#24615;&#65292;&#36890;&#36807;&#38750;&#32447;&#24615;&#39640;&#26031;&#21442;&#25968;&#21270;&#36801;&#31227;&#20998;&#24067;&#23454;&#29616;&#31532;&#19968;&#38454;&#27573;&#39532;&#23572;&#31185;&#22827;&#20381;&#36182;&#32467;&#26500;&#20013;&#30340;&#21487;&#36776;&#35782;&#24615;&#26465;&#20214;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#20381;&#36182;&#20110;&#25919;&#26435;&#30340;&#22240;&#26524;&#21457;&#29616;&#21644;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#20998;&#21106;&#12290;</title><link>http://arxiv.org/abs/2305.15925</link><description>&lt;p&gt;
&#20851;&#20110;&#39532;&#23572;&#31185;&#22827;&#36716;&#25442;&#27169;&#22411;&#30340;&#21487;&#36776;&#35782;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Identifiability of Markov Switching Models. (arXiv:2305.15925v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15925
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39532;&#23572;&#31185;&#22827;&#36716;&#25442;&#27169;&#22411;&#30340;&#21487;&#36776;&#35782;&#24615;&#65292;&#36890;&#36807;&#38750;&#32447;&#24615;&#39640;&#26031;&#21442;&#25968;&#21270;&#36801;&#31227;&#20998;&#24067;&#23454;&#29616;&#31532;&#19968;&#38454;&#27573;&#39532;&#23572;&#31185;&#22827;&#20381;&#36182;&#32467;&#26500;&#20013;&#30340;&#21487;&#36776;&#35782;&#24615;&#26465;&#20214;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#20381;&#36182;&#20110;&#25919;&#26435;&#30340;&#22240;&#26524;&#21457;&#29616;&#21644;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#20998;&#21106;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#21487;&#36776;&#35782;&#24615;&#22240;&#20854;&#22312;&#21487;&#35299;&#37322;&#24615;&#25110;&#20998;&#24067;&#27867;&#21270;&#26041;&#38754;&#30340;&#24212;&#29992;&#32780;&#22791;&#21463;&#20851;&#27880;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#20316;&#20026;&#23558;&#26368;&#36817;&#30340;&#32467;&#26524;&#25193;&#23637;&#21040;&#24207;&#21015;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#31532;&#19968;&#27493;&#30340;&#39532;&#23572;&#31185;&#22827;&#36716;&#25442;&#27169;&#22411;&#30340;&#21487;&#36776;&#35782;&#24615;&#12290;&#25105;&#20204;&#22312;&#31532;&#19968;&#38454;&#27573;&#39532;&#23572;&#31185;&#22827;&#20381;&#36182;&#32467;&#26500;&#20013;&#25552;&#20986;&#20102;&#21487;&#36776;&#35782;&#24615;&#26465;&#20214;&#65292;&#24182;&#36890;&#36807;&#38750;&#32447;&#24615;&#39640;&#26031;&#21442;&#25968;&#21270;&#36801;&#31227;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#22312;&#20381;&#36182;&#20110;&#25919;&#26435;&#30340;&#22240;&#26524;&#21457;&#29616;&#21644;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#20998;&#21106;&#26041;&#38754;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Identifiability of latent variable models has recently gained interest in terms of its applications to interpretability or out of distribution generalisation. In this work, we study identifiability of Markov Switching Models as a first step towards extending recent results to sequential latent variable models. We present identifiability conditions within first-order Markov dependency structures, and parametrise the transition distribution via non-linear Gaussians. Our experiments showcase the applicability of our approach for regime-dependent causal discovery and high-dimensional time series segmentation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#30417;&#30563;&#39044;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#31867;&#20869;&#22810;&#26679;&#24615;&#21644;&#31867;&#38388;&#22810;&#26679;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#23545;&#19979;&#28216;&#20219;&#21153;&#34920;&#29616;&#30340;&#24433;&#21709;&#65292;&#24182;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#19979;&#28216;&#24615;&#33021;&#21333;&#35843;&#22320;&#21462;&#20915;&#20110;&#36825;&#20004;&#31181;&#22810;&#26679;&#24615;&#12290;&#26368;&#20339;&#30340;&#31867;&#21035;&#26679;&#26412;&#27604;&#65288;#&#31867;&#21035; / #&#27599;&#31867;&#26679;&#26412;&#25968;&#65289;&#19982;&#39044;&#35757;&#32451;&#25968;&#25454;&#38598;&#22823;&#23567;&#26080;&#20851;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#39044;&#27979;&#26368;&#20339;&#30340;&#39044;&#35757;&#32451;&#31867;&#21035;&#25968;&#12290;</title><link>http://arxiv.org/abs/2305.12224</link><description>&lt;p&gt;
&#30417;&#30563;&#39044;&#35757;&#32451;&#20013;&#31867;&#20869;/&#31867;&#38388;&#22810;&#26679;&#24615;&#30340;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
On the Trade-off of Intra-/Inter-class Diversity for Supervised Pre-training. (arXiv:2305.12224v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12224
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#30417;&#30563;&#39044;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#31867;&#20869;&#22810;&#26679;&#24615;&#21644;&#31867;&#38388;&#22810;&#26679;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#23545;&#19979;&#28216;&#20219;&#21153;&#34920;&#29616;&#30340;&#24433;&#21709;&#65292;&#24182;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#19979;&#28216;&#24615;&#33021;&#21333;&#35843;&#22320;&#21462;&#20915;&#20110;&#36825;&#20004;&#31181;&#22810;&#26679;&#24615;&#12290;&#26368;&#20339;&#30340;&#31867;&#21035;&#26679;&#26412;&#27604;&#65288;#&#31867;&#21035; / #&#27599;&#31867;&#26679;&#26412;&#25968;&#65289;&#19982;&#39044;&#35757;&#32451;&#25968;&#25454;&#38598;&#22823;&#23567;&#26080;&#20851;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#39044;&#27979;&#26368;&#20339;&#30340;&#39044;&#35757;&#32451;&#31867;&#21035;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#25968;&#25454;&#38598;&#23545;&#20110;&#26500;&#24314;&#26368;&#20808;&#36827;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#33267;&#20851;&#37325;&#35201;&#65292;&#22240;&#27492;&#38656;&#35201;&#23545;&#23427;&#20204;&#23545;&#19979;&#28216;&#20219;&#21153;&#30340;&#24433;&#21709;&#36827;&#34892;&#20005;&#26684;&#30740;&#31350;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#30417;&#30563;&#39044;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#31867;&#20869;&#22810;&#26679;&#24615;&#65288;&#27599;&#20010;&#31867;&#21035;&#30340;&#26679;&#26412;&#25968;&#65289;&#21644;&#31867;&#38388;&#22810;&#26679;&#24615;&#65288;&#31867;&#21035;&#25968;&#65289;&#20043;&#38388;&#30340;&#26435;&#34913;&#23545;&#19979;&#28216;&#34920;&#29616;&#30340;&#24433;&#21709;&#12290;&#23454;&#35777;&#34920;&#26126;&#65292;&#24403;&#39044;&#35757;&#32451;&#25968;&#25454;&#38598;&#22823;&#23567;&#22266;&#23450;&#26102;&#65292;&#26368;&#20339;&#30340;&#19979;&#28216;&#34920;&#29616;&#21462;&#20915;&#20110;&#31867;&#20869;/&#31867;&#38388;&#22810;&#26679;&#24615;&#30340;&#24179;&#34913;&#12290;&#20026;&#20102;&#20102;&#35299;&#20854;&#22522;&#26412;&#26426;&#21046;&#65292;&#25105;&#20204;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#19979;&#28216;&#34920;&#29616;&#21333;&#35843;&#22320;&#21462;&#20915;&#20110;&#20004;&#31181;&#22810;&#26679;&#24615;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#29702;&#35770;&#25581;&#31034;&#20102;&#26368;&#20339;&#30340;&#31867;&#21035;&#26679;&#26412;&#27604;&#65288;#&#31867;&#21035; / #&#27599;&#31867;&#26679;&#26412;&#25968;&#65289;&#19981;&#21463;&#39044;&#35757;&#32451;&#25968;&#25454;&#38598;&#22823;&#23567;&#30340;&#24433;&#21709;&#65292;&#36825;&#21551;&#21457;&#25105;&#20204;&#24212;&#29992;&#39044;&#27979;&#26368;&#20339;&#30340;&#39044;&#35757;&#32451;&#31867;&#21035;&#25968;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#31181;&#24212;&#29992;&#30340;&#26377;&#25928;&#24615;&#65292;&#24615;&#33021;&#25552;&#21319;&#32422;&#20026;2&#20010;&#30334;&#20998;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pre-training datasets are critical for building state-of-the-art machine learning models, motivating rigorous study on their impact on downstream tasks. In this work, we study the impact of the trade-off between the intra-class diversity (the number of samples per class) and the inter-class diversity (the number of classes) of a supervised pre-training dataset. Empirically, we found that with the size of the pre-training dataset fixed, the best downstream performance comes with a balance on the intra-/inter-class diversity. To understand the underlying mechanism, we show theoretically that the downstream performance depends monotonically on both types of diversity. Notably, our theory reveals that the optimal class-to-sample ratio (#classes / #samples per class) is invariant to the size of the pre-training dataset, which motivates an application of predicting the optimal number of pre-training classes. We demonstrate the effectiveness of this application by an improvement of around 2 p
&lt;/p&gt;</description></item><item><title>RAFT&#26694;&#26550;&#24341;&#20837;&#20102;&#22870;&#21169;&#25490;&#21517;&#24494;&#35843;&#26041;&#27861;&#65292;&#29992;&#20110;&#23545;&#40784;&#29983;&#25104;&#22411;&#22522;&#30784;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#24102;&#26469;&#30340;&#20302;&#25928;&#21644;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2304.06767</link><description>&lt;p&gt;
RAFT: &#22870;&#21169;&#25490;&#21517;&#24494;&#35843;&#29992;&#20110;&#29983;&#25104;&#22411;&#22522;&#30784;&#27169;&#22411;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment. (arXiv:2304.06767v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06767
&lt;/p&gt;
&lt;p&gt;
RAFT&#26694;&#26550;&#24341;&#20837;&#20102;&#22870;&#21169;&#25490;&#21517;&#24494;&#35843;&#26041;&#27861;&#65292;&#29992;&#20110;&#23545;&#40784;&#29983;&#25104;&#22411;&#22522;&#30784;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#24102;&#26469;&#30340;&#20302;&#25928;&#21644;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#22411;&#22522;&#30784;&#27169;&#22411;&#23481;&#26131;&#21463;&#21040;&#24191;&#27867;&#30340;&#26080;&#30417;&#30563;&#35757;&#32451;&#25968;&#25454;&#24102;&#26469;&#30340;&#38544;&#24335;&#20559;&#35265;&#30340;&#24433;&#21709;&#12290;&#36825;&#20123;&#20559;&#35265;&#21487;&#33021;&#23548;&#33268;&#23376;&#20248;&#26679;&#26412;&#12289;&#25197;&#26354;&#30340;&#32467;&#26524;&#21644;&#19981;&#20844;&#24179;&#65292;&#21487;&#33021;&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#12290;&#22240;&#27492;&#65292;&#23558;&#36825;&#20123;&#27169;&#22411;&#19982;&#20154;&#30340;&#20262;&#29702;&#21644;&#20559;&#22909;&#23545;&#40784;&#26159;&#30830;&#20445;&#23427;&#20204;&#22312;&#30495;&#23454;&#24212;&#29992;&#20013;&#36127;&#36131;&#20219;&#21644;&#26377;&#25928;&#30340;&#37096;&#32626;&#30340;&#20851;&#38190;&#27493;&#39588;&#12290;&#20197;&#24448;&#30340;&#30740;&#31350;&#20027;&#35201;&#37319;&#29992;&#20154;&#31867;&#21453;&#39304;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288; RLHF&#65289;&#20316;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#25163;&#27573;&#12290;&#22312; RL &#31639;&#27861;&#30340;&#25351;&#23548;&#19979;&#65292;&#29992;&#20154;&#31867;&#21453;&#39304;&#25351;&#23548;&#30340;&#22870;&#21169;&#27169;&#22411;&#23545;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#12290;&#28982;&#32780;&#65292; RL &#31639;&#27861;&#30340;&#20302;&#25928;&#24615;&#21644;&#19981;&#31283;&#23450;&#24615;&#24120;&#24120;&#20250;&#23545;&#29983;&#25104;&#27169;&#22411;&#30340;&#25104;&#21151;&#23545;&#40784;&#20135;&#29983;&#37325;&#22823;&#38556;&#30861;&#65292;&#22240;&#27492;&#38656;&#35201;&#24320;&#21457;&#19968;&#31181;&#26356;&#20026;&#24378;&#22823;&#21644;&#31616;&#21270;&#30340;&#26041;&#27861;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#21363;&#22870;&#21169;&#25490;&#21517;&#24494;&#35843;&#65288; RAFT &#65289;&#65292;&#26088;&#22312;&#23545;&#40784;&#29983;&#25104;&#22522;&#30784;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative foundation models are susceptible to implicit biases that can arise from extensive unsupervised training data. Such biases can produce suboptimal samples, skewed outcomes, and unfairness, with potentially significant repercussions. Consequently, aligning these models with human ethics and preferences is an essential step toward ensuring their responsible and effective deployment in real-world applications. Prior research has primarily employed Reinforcement Learning from Human Feedback (RLHF) as a means of addressing this problem, wherein generative models are fine-tuned using RL algorithms guided by a human-feedback-informed reward model. However, the inefficiencies and instabilities associated with RL algorithms frequently present substantial obstacles to the successful alignment of generative models, necessitating the development of a more robust and streamlined approach. To this end, we introduce a new framework, Reward rAnked FineTuning (RAFT), designed to align generat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38597;&#21487;&#27604;&#25511;&#21046;&#30340;&#24102;&#23485;&#36873;&#25321;&#21551;&#21457;&#24335;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#38381;&#24335;&#12289;&#35745;&#31639;&#38750;&#24120;&#36731;&#30340;&#29305;&#28857;&#65292;&#24182;&#19988;&#22312;&#20851;&#27880;&#24102;&#23485;&#30340;&#21516;&#26102;&#21487;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#27169;&#22411;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2205.11956</link><description>&lt;p&gt;
&#36890;&#36807;&#38597;&#21487;&#27604;&#25511;&#21046;&#36873;&#25321;&#39640;&#26031;&#26680;&#23725;&#22238;&#24402;&#24102;&#23485;
&lt;/p&gt;
&lt;p&gt;
Bandwidth Selection for Gaussian Kernel Ridge Regression via Jacobian Control. (arXiv:2205.11956v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.11956
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38597;&#21487;&#27604;&#25511;&#21046;&#30340;&#24102;&#23485;&#36873;&#25321;&#21551;&#21457;&#24335;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#38381;&#24335;&#12289;&#35745;&#31639;&#38750;&#24120;&#36731;&#30340;&#29305;&#28857;&#65292;&#24182;&#19988;&#22312;&#20851;&#27880;&#24102;&#23485;&#30340;&#21516;&#26102;&#21487;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#27169;&#22411;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#38656;&#35201;&#35843;&#25972;&#36229;&#21442;&#25968;&#12290;&#23545;&#20110;&#39640;&#26031;&#26680;&#23725;&#22238;&#24402;&#65292;&#36229;&#21442;&#25968;&#26159;&#24102;&#23485;&#12290;&#24102;&#23485;&#25351;&#23450;&#26680;&#20989;&#25968;&#30340;&#38271;&#24230;&#23610;&#24230;&#65292;&#24517;&#39035;&#23567;&#24515;&#36873;&#25321;&#25165;&#33021;&#33719;&#24471;&#20855;&#26377;&#33391;&#22909;&#27867;&#21270;&#24615;&#33021;&#27169;&#22411;&#12290;&#24102;&#23485;&#36873;&#25321;&#30340;&#40664;&#35748;&#26041;&#27861;&#26159;&#20132;&#21449;&#39564;&#35777;&#21644;&#36793;&#32536;&#20284;&#28982;&#26368;&#22823;&#21270;&#65292;&#36825;&#36890;&#24120;&#20250;&#20135;&#29983;&#33391;&#22909;&#30340;&#32467;&#26524;&#65292;&#23613;&#31649;&#35745;&#31639;&#25104;&#26412;&#39640;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#26041;&#27861;&#25552;&#20379;&#30340;&#20272;&#35745;&#24448;&#24448;&#20855;&#26377;&#38750;&#24120;&#39640;&#30340;&#26041;&#24046;&#65292;&#29305;&#21035;&#26159;&#22312;&#35757;&#32451;&#25968;&#25454;&#19981;&#36275;&#26102;&#12290;&#21463;&#38597;&#21487;&#27604;&#27491;&#21017;&#21270;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#21046;&#23450;&#20102;&#19968;&#20010;&#36817;&#20284;&#34920;&#36798;&#24335;&#65292;&#29992;&#20110;&#25551;&#36848;&#39640;&#26031;&#26680;&#23725;&#22238;&#24402;&#25512;&#26029;&#20989;&#25968;&#30340;&#23548;&#25968;&#22914;&#20309;&#21462;&#20915;&#20110;&#26680;&#24102;&#23485;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#36825;&#20010;&#34920;&#36798;&#24335;&#26469;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#38597;&#21487;&#27604;&#25511;&#21046;&#30340;&#38381;&#24335;&#12289;&#35745;&#31639;&#38750;&#24120;&#36731;&#30340;&#24102;&#23485;&#36873;&#25321;&#21551;&#21457;&#24335;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#36825;&#20010;&#38597;&#21487;&#27604;&#34920;&#36798;&#24335;&#34920;&#26126;&#20102;&#22312;&#26816;&#26597;&#24102;&#23485;&#36873;&#25321;&#30340;&#36136;&#37327;&#26102;&#24212;&#20851;&#27880;&#20160;&#20040;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most machine learning methods require tuning of hyper-parameters. For kernel ridge regression with the Gaussian kernel, the hyper-parameter is the bandwidth. The bandwidth specifies the length-scale of the kernel and has to be carefully selected in order to obtain a model with good generalization. The default methods for bandwidth selection is cross-validation and marginal likelihood maximization, which often yields good results, albeit at high computational costs. Furthermore, the estimates provided by these methods tend to have very high variance, especially when training data are scarce. Inspired by Jacobian regularization, we formulate an approximate expression for how the derivatives of the functions inferred by kernel ridge regression with the Gaussian kernel depend on the kernel bandwidth. We then use this expression to propose a closed-form, computationally feather-light, bandwidth selection heuristic based on controlling the Jacobian. In addition, the Jacobian expression illum
&lt;/p&gt;</description></item></channel></rss>