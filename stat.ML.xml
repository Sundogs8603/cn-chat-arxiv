<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25193;&#23637;&#20102;&#20043;&#21069;&#30340;&#30740;&#31350;&#65292;&#23558;&#35777;&#26126;&#30340;&#33539;&#22260;&#20174;&#29420;&#31435;&#21516;&#20998;&#24067;&#26435;&#37325;&#25193;&#23637;&#21040;&#20102;&#26356;&#22823;&#30340;&#26435;&#37325;&#20998;&#24067;&#31867;&#21035;(PSEUDO-IID)&#65292;&#21253;&#25324;&#20302;&#31209;&#21644;&#31232;&#30095;&#35774;&#32622;&#12290;&#20316;&#32773;&#21457;&#29616;&#20351;&#29992;PSEUDO-IID&#20998;&#24067;&#21021;&#22987;&#21270;&#30340;&#20840;&#36830;&#25509;&#21644;&#21367;&#31215;&#32593;&#32476;&#22312;&#26041;&#24046;&#19978;&#37117;&#26159;&#31561;&#25928;&#30340;&#12290;&#36825;&#20123;&#32467;&#26524;&#21487;&#20197;&#24110;&#21161;&#25105;&#20204;&#35782;&#21035;&#26356;&#24191;&#27867;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#36793;&#30028;&#28151;&#27788;&#29366;&#24577;&#65292;&#24182;&#36827;&#34892;&#24615;&#33021;&#35843;&#20248;&#12290;</title><link>http://arxiv.org/abs/2310.16597</link><description>&lt;p&gt;
&#36229;&#36234;&#29420;&#31435;&#21516;&#20998;&#24067;&#26435;&#37325;&#65306;&#31232;&#30095;&#21644;&#20302;&#31209;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20063;&#26159;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Beyond IID weights: sparse and low-rank deep Neural Networks are also Gaussian Processes. (arXiv:2310.16597v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16597
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25193;&#23637;&#20102;&#20043;&#21069;&#30340;&#30740;&#31350;&#65292;&#23558;&#35777;&#26126;&#30340;&#33539;&#22260;&#20174;&#29420;&#31435;&#21516;&#20998;&#24067;&#26435;&#37325;&#25193;&#23637;&#21040;&#20102;&#26356;&#22823;&#30340;&#26435;&#37325;&#20998;&#24067;&#31867;&#21035;(PSEUDO-IID)&#65292;&#21253;&#25324;&#20302;&#31209;&#21644;&#31232;&#30095;&#35774;&#32622;&#12290;&#20316;&#32773;&#21457;&#29616;&#20351;&#29992;PSEUDO-IID&#20998;&#24067;&#21021;&#22987;&#21270;&#30340;&#20840;&#36830;&#25509;&#21644;&#21367;&#31215;&#32593;&#32476;&#22312;&#26041;&#24046;&#19978;&#37117;&#26159;&#31561;&#25928;&#30340;&#12290;&#36825;&#20123;&#32467;&#26524;&#21487;&#20197;&#24110;&#21161;&#25105;&#20204;&#35782;&#21035;&#26356;&#24191;&#27867;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#36793;&#30028;&#28151;&#27788;&#29366;&#24577;&#65292;&#24182;&#36827;&#34892;&#24615;&#33021;&#35843;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#38480;&#23485;&#31070;&#32463;&#32593;&#32476;&#24050;&#32463;&#34987;&#35777;&#26126;&#26159;&#19968;&#20010;&#26377;&#29992;&#19988;&#21487;&#31649;&#29702;&#30340;&#25968;&#23398;&#27169;&#22411;&#65292;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#29702;&#35299;&#28145;&#24230;&#23398;&#20064;&#20013;&#20986;&#29616;&#30340;&#35768;&#22810;&#29616;&#35937;&#12290;&#20854;&#20013;&#19968;&#20010;&#20363;&#23376;&#26159;&#38543;&#26426;&#28145;&#23618;&#32593;&#32476;&#25910;&#25947;&#21040;&#39640;&#26031;&#36807;&#31243;&#65292;&#20174;&#32780;&#33021;&#22815;&#23545;&#28608;&#27963;&#20989;&#25968;&#21644;&#32593;&#32476;&#26435;&#37325;&#36873;&#25321;&#23545;&#35757;&#32451;&#21160;&#24577;&#30340;&#24433;&#21709;&#36827;&#34892;&#20005;&#26684;&#20998;&#26512;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;Matthews&#31561;&#20154;(2018)&#30340;&#24320;&#21019;&#24615;&#35777;&#26126;&#25193;&#23637;&#21040;&#26356;&#22823;&#30340;&#21021;&#22987;&#26435;&#37325;&#20998;&#24067;&#31867;&#21035;(&#25105;&#20204;&#31216;&#20043;&#20026;PSEUDO-IID)&#65292;&#20854;&#20013;&#21253;&#25324;&#29420;&#31435;&#21516;&#20998;&#24067;&#21644;&#27491;&#20132;&#26435;&#37325;&#30340;&#24050;&#26377;&#24773;&#20917;&#65292;&#20197;&#21450;&#22240;&#20854;&#35745;&#31639;&#21152;&#36895;&#20248;&#21183;&#32780;&#21463;&#21040;&#36190;&#35465;&#30340;&#26032;&#20852;&#20302;&#31209;&#21644;&#32467;&#26500;&#31232;&#30095;&#35774;&#32622;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#20351;&#29992;PSEUDO-IID&#20998;&#24067;&#21021;&#22987;&#21270;&#30340;&#20840;&#36830;&#25509;&#21644;&#21367;&#31215;&#32593;&#32476;&#22312;&#26041;&#24046;&#19978;&#37117;&#26159;&#31561;&#25928;&#30340;&#12290;&#21033;&#29992;&#25105;&#20204;&#30340;&#32467;&#26524;&#65292;&#21487;&#20197;&#35782;&#21035;&#26356;&#24191;&#27867;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#36793;&#30028;&#28151;&#27788;&#29366;&#24577;&#65292;&#24182;&#35843;&#25972;&#23427;&#20204;&#30340;&#20020;&#30028;&#24615;&#65292;&#20197;&#22686;&#24378;&#35757;&#32451;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The infinitely wide neural network has been proven a useful and manageable mathematical model that enables the understanding of many phenomena appearing in deep learning. One example is the convergence of random deep networks to Gaussian processes that allows a rigorous analysis of the way the choice of activation function and network weights impacts the training dynamics. In this paper, we extend the seminal proof of Matthews et al. (2018) to a larger class of initial weight distributions (which we call PSEUDO-IID), including the established cases of IID and orthogonal weights, as well as the emerging low-rank and structured sparse settings celebrated for their computational speed-up benefits. We show that fully-connected and convolutional networks initialized with PSEUDO-IID distributions are all effectively equivalent up to their variance. Using our results, one can identify the Edge-of-Chaos for a broader class of neural networks and tune them at criticality in order to enhance the
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#36866;&#24212;&#30340;&#37319;&#26679;&#31574;&#30053;&#65292;&#29992;&#20110;&#29983;&#25104;&#24335;&#21387;&#32553;&#24863;&#30693;&#20013;&#30340;&#20449;&#21495;&#24674;&#22797;&#65292;&#36890;&#36807;&#20248;&#21270;&#37319;&#26679;&#20998;&#24067;&#21644;&#26032;&#30340;&#29702;&#35770;&#24674;&#22797;&#20445;&#35777;&#25216;&#26415;&#65292;&#33021;&#22815;&#26174;&#33879;&#20943;&#23569;&#25152;&#38656;&#27979;&#37327;&#30340;&#25968;&#37327;&#12290;</title><link>http://arxiv.org/abs/2310.04984</link><description>&lt;p&gt;
&#27169;&#22411;&#36866;&#24212;&#30340;&#20613;&#31435;&#21494;&#37319;&#26679;&#29992;&#20110;&#29983;&#25104;&#24335;&#21387;&#32553;&#24863;&#30693;
&lt;/p&gt;
&lt;p&gt;
Model-adapted Fourier sampling for generative compressed sensing. (arXiv:2310.04984v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04984
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#36866;&#24212;&#30340;&#37319;&#26679;&#31574;&#30053;&#65292;&#29992;&#20110;&#29983;&#25104;&#24335;&#21387;&#32553;&#24863;&#30693;&#20013;&#30340;&#20449;&#21495;&#24674;&#22797;&#65292;&#36890;&#36807;&#20248;&#21270;&#37319;&#26679;&#20998;&#24067;&#21644;&#26032;&#30340;&#29702;&#35770;&#24674;&#22797;&#20445;&#35777;&#25216;&#26415;&#65292;&#33021;&#22815;&#26174;&#33879;&#20943;&#23569;&#25152;&#38656;&#27979;&#37327;&#30340;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#24403;&#27979;&#37327;&#30697;&#38453;&#26159;&#20174;&#19968;&#20010;&#37193;&#30697;&#38453;&#20013;&#38543;&#26426;&#23376;&#37319;&#26679;&#24471;&#21040;&#26102;&#30340;&#29983;&#25104;&#24335;&#21387;&#32553;&#24863;&#30693;&#38382;&#39064;&#65288;&#31163;&#25955;&#20613;&#31435;&#21494;&#21464;&#25442;&#26159;&#37325;&#35201;&#30340;&#29305;&#27530;&#24773;&#20917;&#65289;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#24403;&#27599;&#20010;&#20613;&#31435;&#21494;&#21521;&#37327;&#19982;&#31070;&#32463;&#32593;&#32476;&#30340;&#21462;&#20540;&#33539;&#22260;&#23545;&#40784;&#26102;&#65292;&#21482;&#38656;&#35201;$O(kdn\|\boldsymbol{\alpha}\|_{\infty}^{2})$&#20010;&#22343;&#21248;&#38543;&#26426;&#20613;&#31435;&#21494;&#27979;&#37327;&#23601;&#36275;&#20197;&#24674;&#22797;&#36755;&#20986;&#20449;&#21495;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#27169;&#22411;&#36866;&#24212;&#30340;&#37319;&#26679;&#31574;&#30053;&#65292;&#20854;&#26679;&#26412;&#22797;&#26434;&#24230;&#24471;&#21040;&#20102;&#25913;&#36827;&#65292;&#21482;&#38656;&#35201;$O(kd\|\boldsymbol{\alpha}\|_{2}^{2})$&#20010;&#27979;&#37327;&#12290;&#36825;&#26159;&#36890;&#36807;&#20197;&#19979;&#27493;&#39588;&#23454;&#29616;&#30340;&#65306;&#65288;1&#65289;&#25105;&#20204;&#24320;&#21457;&#20102;&#36866;&#29992;&#20110;&#38750;&#22343;&#21248;&#38543;&#26426;&#37319;&#26679;&#20998;&#24067;  &#30340;&#26032;&#30340;&#29702;&#35770;&#24674;&#22797;&#20445;&#35777;&#65292;&#28982;&#21518;&#65288;2&#65289;&#20248;&#21270;&#37319;&#26679;&#20998;&#24067;&#20197;&#26368;&#23567;&#21270;&#36825;&#20123;&#20445;&#35777;&#25152;&#38656;&#30340;&#27979;&#37327;&#25968;&#37327;&#12290;&#36825;&#31181;&#25216;&#26415;&#21457;&#23637;&#25552;&#20379;&#20102;&#36866;&#29992;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study generative compressed sensing when the measurement matrix is randomly subsampled from a unitary matrix (with the DFT as an important special case). It was recently shown that $\textit{O}(kdn\| \boldsymbol{\alpha}\|_{\infty}^{2})$ uniformly random Fourier measurements are sufficient to recover signals in the range of a neural network $G:\mathbb{R}^k \to \mathbb{R}^n$ of depth $d$, where each component of the so-called local coherence vector $\boldsymbol{\alpha}$ quantifies the alignment of a corresponding Fourier vector with the range of $G$. We construct a model-adapted sampling strategy with an improved sample complexity of $\textit{O}(kd\| \boldsymbol{\alpha}\|_{2}^{2})$ measurements. This is enabled by: (1) new theoretical recovery guarantees that we develop for nonuniformly random sampling distributions and then (2) optimizing the sampling distribution to minimize the number of measurements needed for these guarantees. This development offers a sample complexity applicable
&lt;/p&gt;</description></item><item><title>&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;Wasserstein&#32479;&#35745;&#22312;&#20223;&#23556;&#21464;&#24418;&#32479;&#35745;&#27169;&#22411;&#20013;&#30340;&#20449;&#24687;&#20960;&#20309;&#29305;&#24449;&#65292;&#27604;&#36739;&#20102;&#20449;&#24687;&#20960;&#20309;&#21644;Wasserstein&#20960;&#20309;&#30340;&#20272;&#35745;&#22120;&#30340;&#20248;&#32570;&#28857;&#65292;&#24182;&#21457;&#29616;Wasserstein&#20272;&#35745;&#37327;&#22312;&#26925;&#22278;&#23545;&#31216;&#20223;&#23556;&#21464;&#24418;&#27169;&#22411;&#20013;&#26159;&#30697;&#20272;&#35745;&#37327;&#65292;&#22312;&#27874;&#24418;&#20026;&#39640;&#26031;&#20998;&#24067;&#26102;&#19982;&#20449;&#24687;&#20960;&#20309;&#20272;&#35745;&#37327;&#37325;&#21512;&#12290;</title><link>http://arxiv.org/abs/2307.12508</link><description>&lt;p&gt;
&#24418;&#29366;&#21644;&#20223;&#23556;&#21464;&#24418;&#30340;Wasserstein&#32479;&#35745;&#30340;&#20449;&#24687;&#20960;&#20309;
&lt;/p&gt;
&lt;p&gt;
Information Geometry of Wasserstein Statistics on Shapes and Affine Deformations. (arXiv:2307.12508v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12508
&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;Wasserstein&#32479;&#35745;&#22312;&#20223;&#23556;&#21464;&#24418;&#32479;&#35745;&#27169;&#22411;&#20013;&#30340;&#20449;&#24687;&#20960;&#20309;&#29305;&#24449;&#65292;&#27604;&#36739;&#20102;&#20449;&#24687;&#20960;&#20309;&#21644;Wasserstein&#20960;&#20309;&#30340;&#20272;&#35745;&#22120;&#30340;&#20248;&#32570;&#28857;&#65292;&#24182;&#21457;&#29616;Wasserstein&#20272;&#35745;&#37327;&#22312;&#26925;&#22278;&#23545;&#31216;&#20223;&#23556;&#21464;&#24418;&#27169;&#22411;&#20013;&#26159;&#30697;&#20272;&#35745;&#37327;&#65292;&#22312;&#27874;&#24418;&#20026;&#39640;&#26031;&#20998;&#24067;&#26102;&#19982;&#20449;&#24687;&#20960;&#20309;&#20272;&#35745;&#37327;&#37325;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#20960;&#20309;&#21644;Wasserstein&#20960;&#20309;&#26159;&#20171;&#32461;&#27010;&#29575;&#20998;&#24067;&#27969;&#24418;&#20013;&#30340;&#20004;&#20010;&#20027;&#35201;&#32467;&#26500;&#65292;&#23427;&#20204;&#25429;&#25417;&#20102;&#19981;&#21516;&#30340;&#29305;&#24449;&#12290;&#25105;&#20204;&#22312;&#20223;&#23556;&#21464;&#24418;&#32479;&#35745;&#27169;&#22411;&#30340;Li&#21644;Zhao&#65288;2023&#65289;&#26694;&#26550;&#20013;&#30740;&#31350;&#20102;Wasserstein&#20960;&#20309;&#30340;&#29305;&#24449;&#65292;&#23427;&#26159;&#20301;&#32622;-&#23610;&#24230;&#27169;&#22411;&#30340;&#22810;&#32500;&#27867;&#21270;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#22522;&#20110;&#20449;&#24687;&#20960;&#20309;&#21644;Wasserstein&#20960;&#20309;&#30340;&#20272;&#35745;&#22120;&#30340;&#20248;&#28857;&#21644;&#32570;&#28857;&#12290;&#22312;Wasserstein&#20960;&#20309;&#20013;&#65292;&#27010;&#29575;&#20998;&#24067;&#30340;&#24418;&#29366;&#21644;&#20223;&#23556;&#21464;&#24418;&#26159;&#20998;&#31163;&#30340;&#65292;&#34920;&#26126;&#22312;&#23545;&#27874;&#24418;&#25200;&#21160;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#21516;&#26102;&#65292;&#20250;&#25439;&#22833;Fisher&#25928;&#29575;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#26925;&#22278;&#23545;&#31216;&#20223;&#23556;&#21464;&#24418;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;Wasserstein&#20272;&#35745;&#37327;&#26159;&#30697;&#20272;&#35745;&#37327;&#12290;&#23427;&#19982;&#20449;&#24687;&#20960;&#20309;&#20272;&#35745;&#37327;&#65288;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#37327;&#65289;&#20165;&#22312;&#27874;&#24418;&#20026;&#39640;&#26031;&#20998;&#24067;&#26102;&#37325;&#21512;&#12290;Wasserstein&#25928;&#29575;&#30340;&#20316;&#29992;&#26159;...
&lt;/p&gt;
&lt;p&gt;
Information geometry and Wasserstein geometry are two main structures introduced in a manifold of probability distributions, and they capture its different characteristics. We study characteristics of Wasserstein geometry in the framework of Li and Zhao (2023) for the affine deformation statistical model, which is a multi-dimensional generalization of the location-scale model. We compare merits and demerits of estimators based on information geometry and Wasserstein geometry. The shape of a probability distribution and its affine deformation are separated in the Wasserstein geometry, showing its robustness against the waveform perturbation in exchange for the loss in Fisher efficiency. We show that the Wasserstein estimator is the moment estimator in the case of the elliptically symmetric affine deformation model. It coincides with the information-geometrical estimator (maximum-likelihood estimator) when and only when the waveform is Gaussian. The role of the Wasserstein efficiency is 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#38750;&#21442;&#25968;&#24773;&#22659;&#36172;&#21338;&#20013;&#30340;&#26368;&#26174;&#33879;&#21464;&#21270;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21482;&#35745;&#31639;&#26174;&#33879;&#21464;&#21270;&#30340;&#26041;&#27861;&#65292;&#26469;&#35299;&#20915;&#23616;&#37096;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.05341</link><description>&lt;p&gt;
&#36319;&#36394;&#38750;&#21442;&#25968;&#24773;&#22659;&#36172;&#21338;&#20013;&#26368;&#26174;&#33879;&#21464;&#21270;
&lt;/p&gt;
&lt;p&gt;
Tracking Most Significant Shifts in Nonparametric Contextual Bandits. (arXiv:2307.05341v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05341
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#38750;&#21442;&#25968;&#24773;&#22659;&#36172;&#21338;&#20013;&#30340;&#26368;&#26174;&#33879;&#21464;&#21270;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21482;&#35745;&#31639;&#26174;&#33879;&#21464;&#21270;&#30340;&#26041;&#27861;&#65292;&#26469;&#35299;&#20915;&#23616;&#37096;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#38750;&#21442;&#25968;&#24773;&#22659;&#36172;&#21338;&#65292;&#20854;&#20013;Lipschitz&#22343;&#20540;&#22870;&#21169;&#20989;&#25968;&#21487;&#33021;&#38543;&#26102;&#38388;&#21464;&#21270;&#12290;&#25105;&#20204;&#39318;&#20808;&#22312;&#36825;&#20010;&#36739;&#23569;&#34987;&#29702;&#35299;&#30340;&#24773;&#22659;&#19979;&#24314;&#31435;&#20102;&#21160;&#24577;&#36951;&#25022;&#29575;&#30340;&#26497;&#23567;&#26497;&#22823;&#20540;&#65292;&#36825;&#20123;&#20540;&#19982;&#21464;&#21270;&#25968;&#37327;L&#21644;&#24635;&#21464;&#24046;V&#26377;&#20851;&#65292;&#20004;&#32773;&#37117;&#21487;&#20197;&#25429;&#25417;&#21040;&#19978;&#19979;&#25991;&#31354;&#38388;&#30340;&#25152;&#26377;&#20998;&#24067;&#21464;&#21270;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#30446;&#21069;&#30340;&#26041;&#27861;&#22312;&#36825;&#20010;&#24773;&#22659;&#19979;&#26159;&#27425;&#20248;&#30340;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#36825;&#31181;&#24773;&#22659;&#19979;&#30340;&#36866;&#24212;&#24615;&#38382;&#39064;&#65292;&#21363;&#22312;&#19981;&#30693;&#36947;L&#25110;V&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#26497;&#23567;&#26497;&#22823;&#20540;&#12290;&#38750;&#24120;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#35748;&#20026;&#65292;&#22312;&#32473;&#23450;&#30340;&#19978;&#19979;&#25991;X_t&#22788;&#65292;&#36172;&#21338;&#38382;&#39064;&#22312;&#19978;&#19979;&#25991;&#31354;&#38388;&#20854;&#20182;&#37096;&#20998;&#20013;&#30340;&#22870;&#21169;&#21464;&#21270;&#19981;&#24212;&#35813;&#20135;&#29983;&#24433;&#21709;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21464;&#21270;&#30340;&#27010;&#24565;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#32463;&#39564;&#26174;&#33879;&#21464;&#21270;&#65292;&#26356;&#22909;&#22320;&#32771;&#34385;&#20102;&#23616;&#37096;&#24615;&#65292;&#22240;&#27492;&#27604;L&#21644;V&#35745;&#25968;&#26356;&#23569;&#12290;&#27492;&#22806;&#65292;&#31867;&#20284;&#20110;&#26368;&#36817;&#22312;&#38750;&#24179;&#31283;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#30340;&#24037;&#20316;&#65288;Suk&#21644;Kpotufe&#65292;2022&#65289;&#65292;&#32463;&#39564;&#26174;&#33879;&#21464;&#21270;&#21482;&#35745;&#31639;&#26174;&#33879;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study nonparametric contextual bandits where Lipschitz mean reward functions may change over time. We first establish the minimax dynamic regret rate in this less understood setting in terms of number of changes $L$ and total-variation $V$, both capturing all changes in distribution over context space, and argue that state-of-the-art procedures are suboptimal in this setting.  Next, we tend to the question of an adaptivity for this setting, i.e. achieving the minimax rate without knowledge of $L$ or $V$. Quite importantly, we posit that the bandit problem, viewed locally at a given context $X_t$, should not be affected by reward changes in other parts of context space $\cal X$. We therefore propose a notion of change, which we term experienced significant shifts, that better accounts for locality, and thus counts considerably less changes than $L$ and $V$. Furthermore, similar to recent work on non-stationary MAB (Suk &amp; Kpotufe, 2022), experienced significant shifts only count the m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#22312;&#32447;&#22810;&#31867;&#20998;&#31867;&#30340;&#21464;&#20307;&#65292;&#20854;&#20013;&#20351;&#29992;&#38598;&#21512;&#22411;&#21453;&#39304;&#12290;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#32452;&#21512;&#32500;&#24230;&#65292;&#35813;&#35770;&#25991;&#34920;&#26126;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#24615;&#30340;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;&#22312;&#23454;&#29616;&#35774;&#32622;&#19979;&#19981;&#31561;&#20215;&#65292;&#24182;&#23558;&#22312;&#32447;&#22810;&#26631;&#31614;&#25490;&#21517;&#21644;&#22312;&#32447;&#22810;&#26631;&#31614;&#20998;&#31867;&#31561;&#23454;&#38469;&#23398;&#20064;&#35774;&#32622;&#20316;&#20026;&#20854;&#29305;&#23450;&#23454;&#20363;&#12290;</title><link>http://arxiv.org/abs/2306.06247</link><description>&lt;p&gt;
&#20351;&#29992;&#38598;&#21512;&#22411;&#21453;&#39304;&#30340;&#22312;&#32447;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Online Learning with Set-Valued Feedback. (arXiv:2306.06247v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06247
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#22312;&#32447;&#22810;&#31867;&#20998;&#31867;&#30340;&#21464;&#20307;&#65292;&#20854;&#20013;&#20351;&#29992;&#38598;&#21512;&#22411;&#21453;&#39304;&#12290;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#32452;&#21512;&#32500;&#24230;&#65292;&#35813;&#35770;&#25991;&#34920;&#26126;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#24615;&#30340;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;&#22312;&#23454;&#29616;&#35774;&#32622;&#19979;&#19981;&#31561;&#20215;&#65292;&#24182;&#23558;&#22312;&#32447;&#22810;&#26631;&#31614;&#25490;&#21517;&#21644;&#22312;&#32447;&#22810;&#26631;&#31614;&#20998;&#31867;&#31561;&#23454;&#38469;&#23398;&#20064;&#35774;&#32622;&#20316;&#20026;&#20854;&#29305;&#23450;&#23454;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#22810;&#31867;&#20998;&#31867;&#30340;&#19968;&#31181;&#21464;&#20307;&#65292;&#20854;&#20013;&#23398;&#20064;&#22120;&#39044;&#27979;&#21333;&#20010;&#26631;&#31614;&#65292;&#20294;&#25509;&#25910;&#21040;&#19968;&#20010;&#26631;&#31614;&#30340;&#38598;&#21512;&#20316;&#20026;&#21453;&#39304;&#12290;&#22312;&#35813;&#27169;&#22411;&#20013;&#65292;&#22914;&#26524;&#23398;&#20064;&#22120;&#27809;&#26377;&#36755;&#20986;&#21253;&#21547;&#22312;&#21453;&#39304;&#38598;&#21512;&#20013;&#30340;&#26631;&#31614;&#65292;&#21017;&#20250;&#21463;&#21040;&#24809;&#32602;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#19982;&#20855;&#26377;&#21333;&#26631;&#31614;&#21453;&#39304;&#30340;&#22312;&#32447;&#22810;&#31867;&#23398;&#20064;&#19981;&#21516;&#65292;&#22312;&#23454;&#29616;&#35774;&#32622;&#20013;&#20351;&#29992;&#38598;&#21512;&#22411;&#21453;&#39304;&#26102;&#65292;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#21270;&#30340;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;\textit{&#19981;&#31561;&#20215;}&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#20010;&#26032;&#30340;&#32452;&#21512;&#32500;&#24230;&#65292;&#20998;&#21035;&#21629;&#21517;&#20026;&#38598;&#21512;&#23567;&#30707;&#21644;&#24230;&#37327;&#30772;&#35010;&#32500;&#24230;&#65292;&#20005;&#26684;&#25551;&#36848;&#20102;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#21270;&#30340;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#34920;&#26126;&#24230;&#37327;&#30772;&#35010;&#32500;&#24230;&#22312;&#24735;&#24615;&#35774;&#32622;&#19979;&#20005;&#26684;&#25551;&#36848;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#32447;&#22810;&#26631;&#31614;&#25490;&#21517;&#21644;&#22312;&#32447;&#22810;&#26631;&#31614;&#20998;&#31867;&#31561;&#23454;&#38469;&#23398;&#20064;&#35774;&#32622;&#26159;&#25105;&#20204;&#36890;&#29992;&#22312;&#32447;&#23398;&#20064;&#26694;&#26550;&#30340;&#20855;&#20307;&#23454;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a variant of online multiclass classification where the learner predicts a single label but receives a \textit{set of labels} as feedback. In this model, the learner is penalized for not outputting a label contained in the revealed set. We show that unlike online multiclass learning with single-label feedback, deterministic and randomized online learnability are \textit{not equivalent} even in the realizable setting with set-valued feedback. Accordingly, we give two new combinatorial dimensions, named the Set Littlestone and Measure Shattering dimension, that tightly characterize deterministic and randomized online learnability respectively in the realizable setting. In addition, we show that the Measure Shattering dimension tightly characterizes online learnability in the agnostic setting. Finally, we show that practical learning settings like online multilabel ranking and online multilabel classification are specific instances of our general online learning framework.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#29992;&#26550;&#26500;&#20960;&#20309;&#20195;&#25968;&#21464;&#25442;&#22120;&#65288;GATr&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#20960;&#20309;&#25968;&#25454;&#38382;&#39064;&#12290;GATr&#20351;&#29992;&#25237;&#24433;&#20960;&#20309;&#20195;&#25968;&#34920;&#31034;&#36755;&#20837;&#36755;&#20986;&#21644;&#29366;&#24577;&#65292;&#20855;&#26377;&#21487;&#32553;&#25918;&#24615;&#12289;&#34920;&#36798;&#24615;&#12289;&#22810;&#21151;&#33021;&#24615;&#12290;&#22312;n&#20307;&#24314;&#27169;&#21644;&#26426;&#22120;&#20154;&#35268;&#21010;&#30340;&#23454;&#39564;&#20013;&#65292;GATr&#30456;&#23545;&#20110;&#38750;&#20960;&#20309;&#22522;&#32447;&#34920;&#29616;&#20986;&#24378;&#22823;&#30340;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2305.18415</link><description>&lt;p&gt;
&#20960;&#20309;&#20195;&#25968;&#21464;&#25442;&#22120;
&lt;/p&gt;
&lt;p&gt;
Geometric Algebra Transformers. (arXiv:2305.18415v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18415
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#29992;&#26550;&#26500;&#20960;&#20309;&#20195;&#25968;&#21464;&#25442;&#22120;&#65288;GATr&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#20960;&#20309;&#25968;&#25454;&#38382;&#39064;&#12290;GATr&#20351;&#29992;&#25237;&#24433;&#20960;&#20309;&#20195;&#25968;&#34920;&#31034;&#36755;&#20837;&#36755;&#20986;&#21644;&#29366;&#24577;&#65292;&#20855;&#26377;&#21487;&#32553;&#25918;&#24615;&#12289;&#34920;&#36798;&#24615;&#12289;&#22810;&#21151;&#33021;&#24615;&#12290;&#22312;n&#20307;&#24314;&#27169;&#21644;&#26426;&#22120;&#20154;&#35268;&#21010;&#30340;&#23454;&#39564;&#20013;&#65292;GATr&#30456;&#23545;&#20110;&#38750;&#20960;&#20309;&#22522;&#32447;&#34920;&#29616;&#20986;&#24378;&#22823;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20960;&#20309;&#25968;&#25454;&#38382;&#39064;&#28041;&#21450;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#26426;&#22120;&#20154;&#12289;&#21270;&#23398;&#21644;&#29289;&#29702;&#39046;&#22495;&#12290;&#36825;&#20123;&#25968;&#25454;&#21487;&#20197;&#37319;&#29992;&#35768;&#22810;&#24418;&#24335;&#65292;&#20363;&#22914;&#28857;&#12289;&#26041;&#21521;&#21521;&#37327;&#12289;&#24179;&#38754;&#25110;&#21464;&#25442;&#65292;&#20294;&#36804;&#20170;&#20026;&#27490;&#36824;&#27809;&#26377;&#19968;&#31181;&#21333;&#19968;&#30340;&#26550;&#26500;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#22914;&#27492;&#22810;&#31181;&#20960;&#20309;&#31867;&#22411;, &#21516;&#26102;&#23562;&#37325;&#23427;&#20204;&#30340;&#23545;&#31216;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#20960;&#20309;&#20195;&#25968;&#21464;&#25442;&#22120;&#65288;GATr&#65289;&#65292;&#19968;&#31181;&#29992;&#20110;&#20960;&#20309;&#25968;&#25454;&#30340;&#36890;&#29992;&#26550;&#26500;&#12290;GATr&#20351;&#29992;&#25237;&#24433;&#20960;&#20309;&#20195;&#25968;&#26469;&#34920;&#31034;&#36755;&#20837;&#12289;&#36755;&#20986;&#21644;&#38544;&#34255;&#29366;&#24577;&#65292;&#20854;&#25552;&#20379;&#24120;&#35265;&#20960;&#20309;&#23545;&#35937;&#30340;&#39640;&#25928;16&#32500;&#21521;&#37327;&#31354;&#38388;&#34920;&#31034;&#20197;&#21450;&#20316;&#29992;&#20110;&#23427;&#20204;&#30340;&#36816;&#31639;&#31526;&#12290;GATr&#26159;&#30456;&#23545;&#20110;E(3)&#65288;3D&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#30340;&#23545;&#31216;&#32676;&#65289;&#31561;&#21464;&#30340;&#12290;&#20316;&#20026;&#21464;&#25442;&#22120;&#65292;GATr&#21487;&#25193;&#23637;&#12289;&#34920;&#36798;&#20016;&#23500;&#19988;&#22810;&#21151;&#33021;&#12290;&#22312;n&#20307;&#24314;&#27169;&#21644;&#26426;&#22120;&#20154;&#35268;&#21010;&#30340;&#23454;&#39564;&#20013;&#65292;GATr&#30456;&#23545;&#20110;&#38750;&#20960;&#20309;&#22522;&#32447;&#22343;&#34920;&#29616;&#20986;&#24378;&#22823;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Problems involving geometric data arise in a variety of fields, including computer vision, robotics, chemistry, and physics. Such data can take numerous forms, such as points, direction vectors, planes, or transformations, but to date there is no single architecture that can be applied to such a wide variety of geometric types while respecting their symmetries. In this paper we introduce the Geometric Algebra Transformer (GATr), a general-purpose architecture for geometric data. GATr represents inputs, outputs, and hidden states in the projective geometric algebra, which offers an efficient 16-dimensional vector space representation of common geometric objects as well as operators acting on them. GATr is equivariant with respect to E(3), the symmetry group of 3D Euclidean space. As a transformer, GATr is scalable, expressive, and versatile. In experiments with n-body modeling and robotic planning, GATr shows strong improvements over non-geometric baselines.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340; Gram &#30697;&#38453;&#32467;&#26500;&#65292;&#35777;&#26126;&#20102;&#28608;&#27963;&#20989;&#25968;&#21644;&#23618;&#35268;&#33539;&#21270;&#32467;&#21512;&#20351;&#29992;&#21487;&#20197;&#22312;&#21021;&#22987;&#21270;&#26102;&#20559;&#21521;&#25351;&#25968;&#32423;&#28145;&#24230;&#31561;&#36317;&#65292;&#20174;&#32780;&#24357;&#34917;&#20102;&#29616;&#26377;&#29702;&#35770;&#30340;&#31354;&#30333;&#12290;</title><link>http://arxiv.org/abs/2305.18399</link><description>&lt;p&gt;
&#20851;&#20110;&#28608;&#27963;&#20989;&#25968;&#21644;&#35268;&#33539;&#21270;&#23545;&#21021;&#22987;&#21270;&#31561;&#36317;&#23884;&#20837;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
On the impact of activation and normalization in obtaining isometric embeddings at initialization. (arXiv:2305.18399v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18399
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340; Gram &#30697;&#38453;&#32467;&#26500;&#65292;&#35777;&#26126;&#20102;&#28608;&#27963;&#20989;&#25968;&#21644;&#23618;&#35268;&#33539;&#21270;&#32467;&#21512;&#20351;&#29992;&#21487;&#20197;&#22312;&#21021;&#22987;&#21270;&#26102;&#20559;&#21521;&#25351;&#25968;&#32423;&#28145;&#24230;&#31561;&#36317;&#65292;&#20174;&#32780;&#24357;&#34917;&#20102;&#29616;&#26377;&#29702;&#35770;&#30340;&#31354;&#30333;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#20498;&#25968;&#31532;&#20108;&#20010; Gram &#30697;&#38453;&#30340;&#32467;&#26500;&#65292;&#35813;&#30697;&#38453;&#21253;&#21547;&#19982;&#19968;&#25209;&#36755;&#20837;&#23545;&#24212;&#30340;&#36755;&#20986;&#20043;&#38388;&#30340;&#25104;&#23545;&#20869;&#31215;&#12290;&#22312;&#20960;&#31181;&#26550;&#26500;&#20013;&#65292;&#35266;&#23519;&#21040;&#22312;&#21021;&#22987;&#21270;&#26102;&#35813; Gram &#30697;&#38453;&#20250;&#38543;&#30528;&#28145;&#24230;&#21464;&#24471;&#36864;&#21270;&#65292;&#20174;&#32780;&#20005;&#37325;&#20943;&#32531;&#35757;&#32451;&#36895;&#24230;&#12290;&#35268;&#33539;&#21270;&#23618;&#22914;&#25209;&#22788;&#29702;&#35268;&#33539;&#21270;&#25110;&#23618;&#35268;&#33539;&#21270;&#65292;&#22312;&#38450;&#27490;&#31209;&#23849;&#28291;&#38382;&#39064;&#26041;&#38754;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#28982;&#32780;&#29616;&#26377;&#30340;&#29702;&#35770;&#32467;&#26524;&#26080;&#27861;&#20840;&#38754;&#35206;&#30422;&#24191;&#27867;&#29992;&#20110; transformer &#20013;&#30340;&#23618;&#35268;&#33539;&#21270;&#21644;&#26377;&#38480;&#28145;&#24230;&#19979;&#35268;&#33539;&#21270;&#30340;&#37327;&#21270;&#20559;&#24046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#21021;&#22987;&#21270;&#26102;&#65292;&#32467;&#21512;&#28608;&#27963;&#20989;&#25968;&#23618;&#20351;&#29992;&#30340;&#23618;&#35268;&#33539;&#21270;&#21487;&#20197;&#20351;&#22810;&#23618;&#24863;&#30693;&#26426;&#30340; Gram &#30697;&#38453;&#20559;&#21521;&#25351;&#25968;&#32423;&#28145;&#24230;&#31561;&#36317;&#65292;&#24182;&#20351;&#29992;&#28608;&#27963;&#20989;&#25968;&#30340; Hermite &#23637;&#24320;&#26469;&#37327;&#21270;&#36825;&#20010;&#36895;&#24230;&#65292;&#20174;&#32780;&#22635;&#34917;&#20102;&#29616;&#26377;&#29702;&#35770;&#30340;&#31354;&#30333;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we explore the structure of the penultimate Gram matrix in deep neural networks, which contains the pairwise inner products of outputs corresponding to a batch of inputs. In several architectures it has been observed that this Gram matrix becomes degenerate with depth at initialization, which dramatically slows training. Normalization layers, such as batch or layer normalization, play a pivotal role in preventing the rank collapse issue. Despite promising advances, the existing theoretical results (i) do not extend to layer normalization, which is widely used in transformers, (ii) can not characterize the bias of normalization quantitatively at finite depth.  To bridge this gap, we provide a proof that layer normalization, in conjunction with activation layers, biases the Gram matrix of a multilayer perceptron towards isometry at an exponential rate with depth at initialization. We quantify this rate using the Hermite expansion of the activation function, highlighting th
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#31163;&#25955;&#20998;&#24067;&#26679;&#26412;&#23545;&#20110;&#31867;&#21035;&#38388;&#30340;&#22343;&#21248;&#20998;&#24067;&#25311;&#21512;&#38382;&#39064;&#19979;&#30340;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;&#65292;&#22312;&#32570;&#23569;&#29699;&#24418;&#26367;&#20195;&#26041;&#26696;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20102;&#35752;&#35770;&#65292;&#36890;&#36807;&#31163;&#25955;&#30452;&#26041;&#22270;&#36827;&#34892;&#26816;&#39564;&#65292;&#33719;&#24471;&#20102;&#19968;&#31181;&#20855;&#26377;&#31934;&#30830;&#21051;&#30011;&#30340;&#26816;&#39564;&#26041;&#27861;&#65292;&#24182;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#20102;&#26174;&#33879;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.18111</link><description>&lt;p&gt;
&#22312;&#32570;&#23569;&#29699;&#24418;&#26367;&#20195;&#26041;&#26696;&#19979;&#27979;&#35797;&#31163;&#25955;&#20998;&#24067;&#30452;&#26041;&#22270;&#22343;&#21248;&#24615;&#30340;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;
The minimax risk in testing the histogram of discrete distributions for uniformity under missing ball alternatives. (arXiv:2305.18111v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18111
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#31163;&#25955;&#20998;&#24067;&#26679;&#26412;&#23545;&#20110;&#31867;&#21035;&#38388;&#30340;&#22343;&#21248;&#20998;&#24067;&#25311;&#21512;&#38382;&#39064;&#19979;&#30340;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;&#65292;&#22312;&#32570;&#23569;&#29699;&#24418;&#26367;&#20195;&#26041;&#26696;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20102;&#35752;&#35770;&#65292;&#36890;&#36807;&#31163;&#25955;&#30452;&#26041;&#22270;&#36827;&#34892;&#26816;&#39564;&#65292;&#33719;&#24471;&#20102;&#19968;&#31181;&#20855;&#26377;&#31934;&#30830;&#21051;&#30011;&#30340;&#26816;&#39564;&#26041;&#27861;&#65292;&#24182;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#20102;&#26174;&#33879;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#27979;&#35797;&#19968;&#20010;&#26469;&#33258;&#35768;&#22810;&#31867;&#21035;&#30340;&#31163;&#25955;&#26679;&#26412;&#23545;&#20110;&#31867;&#21035;&#38388;&#30340;&#22343;&#21248;&#20998;&#24067;&#25311;&#21512;&#30340;&#38382;&#39064;&#12290;&#20316;&#20026;&#21478;&#19968;&#31867;&#26367;&#20195;&#20551;&#35774;&#65292;&#25105;&#20204;&#32771;&#34385;&#21435;&#38500;&#21322;&#24452;&#20026;$\epsilon$&#30340;$\ell_p$&#29699;&#24418;&#26367;&#20195;&#26041;&#26696;&#65292;&#20854;&#20013;$p\leq 2$&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#22522;&#20110;&#30452;&#26041;&#22270;&#65288;&#32570;&#22833;&#31867;&#21035;&#12289;&#21333;&#20363;&#12289;&#30896;&#25758;&#30340;&#25968;&#37327;&#65289;&#30340;&#26816;&#39564;&#22312;&#26679;&#26412;&#25968;&#21644;&#32500;&#25968;&#36235;&#21521;&#26080;&#31351;&#22823;&#65292;$\epsilon\to0$&#26102;&#65292;&#28176;&#36827;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;&#30340;&#19968;&#20010;&#31934;&#30830;&#21051;&#30011;&#12290;&#20363;&#22914;&#65292;&#24403;$p=1$&#19988;&#26399;&#26395;&#26679;&#26412;&#25968;$n$&#19982;&#31867;&#21035;&#25968;$N$&#30340;&#27604;&#20540;&#24456;&#23567;&#65288;&#20063;&#31216;&#20026;&#8220;&#27425;&#32447;&#24615;&#8221;&#21306;&#22495;&#65289;&#26102;&#65292;&#28176;&#36827;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;$R^*_\epsilon$&#36235;&#36817;&#20110;$2\bar{\Phi}\left(n\epsilon^2/\sqrt{8N}\right)$&#65292;&#20854;&#20013;$\bar{\Phi}(x)$&#26159;&#27491;&#24577;&#27531;&#23384;&#20989;&#25968;&#12290;&#22312;&#19968;&#31995;&#21015;&#38382;&#39064;&#21442;&#25968;&#33539;&#22260;&#20869;&#30340;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;&#36825;&#20010;&#20272;&#35745;&#22312;&#26377;&#38480;&#26679;&#26412;&#20013;&#24456;&#31934;&#30830;&#65292;&#24182;&#19988;&#25105;&#20204;&#30340;&#26816;&#39564;&#26174;&#33879;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of testing the fit of a discrete sample of items from many categories to the uniform distribution over the categories. As a class of alternative hypotheses, we consider the removal of an $\ell_p$ ball of radius $\epsilon$ around the uniform rate sequence for $p \leq 2$. We deliver a sharp characterization of the asymptotic minimax risk when $\epsilon \to 0$ as the number of samples and number of dimensions go to infinity, for testing based on the occurrences' histogram (number of absent categories, singletons, collisions, ...). For example, for $p=1$ and in the limit of a small expected number of samples $n$ compared to the number of categories $N$ (aka "sub-linear" regime), the minimax risk $R^*_\epsilon$ asymptotes to $2 \bar{\Phi}\left(n \epsilon^2/\sqrt{8N}\right) $, with $\bar{\Phi}(x)$ the normal survival function. Empirical studies over a range of problem parameters show that this estimate is accurate in finite samples, and that our test is significantly 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;GFlowNets&#30340;&#26426;&#22120;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#35299;&#20915;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#65292;&#21516;&#26102;&#22312;&#35757;&#32451;&#26041;&#38754;&#36827;&#34892;&#20102;&#20248;&#21270;&#65292;&#32467;&#26524;&#34920;&#26126;&#20854;&#21487;&#20197;&#39640;&#25928;&#22320;&#25214;&#21040;&#39640;&#36136;&#37327;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2305.17010</link><description>&lt;p&gt;
&#21033;&#29992;GFlowNets&#35299;&#20915;&#22270;&#24418;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Let the Flows Tell: Solving Graph Combinatorial Optimization Problems with GFlowNets. (arXiv:2305.17010v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17010
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;GFlowNets&#30340;&#26426;&#22120;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#35299;&#20915;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#65292;&#21516;&#26102;&#22312;&#35757;&#32451;&#26041;&#38754;&#36827;&#34892;&#20102;&#20248;&#21270;&#65292;&#32467;&#26524;&#34920;&#26126;&#20854;&#21487;&#20197;&#39640;&#25928;&#22320;&#25214;&#21040;&#39640;&#36136;&#37327;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#36890;&#24120;&#26159;NP&#38590;&#39064;&#65292;&#22240;&#27492;&#19981;&#36866;&#29992;&#20110;&#31934;&#30830;&#31639;&#27861;&#65292;&#36825;&#20351;&#23427;&#20204;&#25104;&#20026;&#24212;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#29702;&#24819;&#39046;&#22495;&#12290;&#36825;&#20123;&#38382;&#39064;&#20013;&#39640;&#24230;&#32467;&#26500;&#21270;&#30340;&#38480;&#21046;&#21487;&#33021;&#20250;&#30452;&#25509;&#38459;&#30861;&#20248;&#21270;&#25110;&#37319;&#26679;&#35299;&#20915;&#26041;&#26696;&#30340;&#31354;&#38388;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;GFlowNets&#26368;&#36817;&#34987;&#21457;&#29616;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#26426;&#22120;&#65292;&#21487;&#20197;&#39034;&#24207;&#22320;&#20174;&#22797;&#21512;&#38750;&#35268;&#33539;&#21270;&#23494;&#24230;&#20013;&#26377;&#25928;&#22320;&#37319;&#26679;&#65292;&#24182;&#20855;&#26377;&#22312;CO&#20013;&#20998;&#25674;&#27492;&#31867;&#35299;&#20915;&#26041;&#26696;&#25628;&#32034;&#36807;&#31243;&#20197;&#21450;&#29983;&#25104;&#19981;&#21516;&#30340;&#35299;&#20915;&#26041;&#26696;&#20505;&#36873;&#39033;&#30340;&#28508;&#21147;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#36866;&#29992;&#20110;&#19981;&#21516;&#32452;&#21512;&#38382;&#39064;&#30340;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#65292;&#24182;&#25552;&#20986;&#35757;&#32451;&#26377;&#26465;&#20214;&#30340;GFlowNets&#20174;&#35299;&#31354;&#38388;&#20013;&#37319;&#26679;&#30340;&#31574;&#30053;&#12290;&#36824;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#35757;&#32451;&#25216;&#26415;&#26469;&#21463;&#30410;&#20110;&#36828;&#31243;&#20449;&#29992;&#20998;&#37197;&#12290;&#36890;&#36807;&#23545;&#21508;&#31181;&#20351;&#29992;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#30340;&#19981;&#21516;CO&#20219;&#21153;&#30340;&#24191;&#27867;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;GFlowNet&#31574;&#30053;&#21487;&#20197;&#26377;&#25928;&#22320;&#25214;&#21040;&#39640;&#36136;&#37327;&#30340;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Combinatorial optimization (CO) problems are often NP-hard and thus out of reach for exact algorithms, making them a tempting domain to apply machine learning methods. The highly structured constraints in these problems can hinder either optimization or sampling directly in the solution space. On the other hand, GFlowNets have recently emerged as a powerful machinery to efficiently sample from composite unnormalized densities sequentially and have the potential to amortize such solution-searching processes in CO, as well as generate diverse solution candidates. In this paper, we design Markov decision processes (MDPs) for different combinatorial problems and propose to train conditional GFlowNets to sample from the solution space. Efficient training techniques are also developed to benefit long-range credit assignment. Through extensive experiments on a variety of different CO tasks with synthetic and realistic data, we demonstrate that GFlowNet policies can efficiently find high-quali
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20851;&#27880;&#22312;&#26080;&#27861;&#33719;&#24471;&#26410;&#26469;&#20449;&#36947;&#29366;&#24577;&#20449;&#24687;&#26102;&#65292;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#35299;&#20915;&#19981;&#21516;&#36164;&#28304;&#20998;&#37197;&#23545;&#24212;&#30340;&#22833;&#35823;&#27010;&#29575;&#38382;&#39064;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#29702;&#35770;&#26368;&#20248;&#12289;&#21487;&#35299;&#37322;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#32463;&#36807;&#27169;&#25311;&#39564;&#35777;&#20854;&#22312;&#22833;&#35823;&#27010;&#29575;&#12289;&#23398;&#20064;&#36895;&#24230;&#21644;&#25910;&#25947;&#31561;&#26041;&#38754;&#30340;&#34920;&#29616;&#20248;&#20110;&#19968;&#20123;&#24120;&#35265;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2305.09739</link><description>&lt;p&gt;
ML&#36741;&#21161;&#36164;&#28304;&#20998;&#37197;&#30340;&#22833;&#35823;&#24615;&#33021;&#21644;&#26032;&#22411;&#25439;&#22833;&#20989;&#25968;: &#19968;&#31181;&#31934;&#30830;&#20998;&#26512;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Outage Performance and Novel Loss Function for an ML-Assisted Resource Allocation: An Exact Analytical Framework. (arXiv:2305.09739v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09739
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#22312;&#26080;&#27861;&#33719;&#24471;&#26410;&#26469;&#20449;&#36947;&#29366;&#24577;&#20449;&#24687;&#26102;&#65292;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#35299;&#20915;&#19981;&#21516;&#36164;&#28304;&#20998;&#37197;&#23545;&#24212;&#30340;&#22833;&#35823;&#27010;&#29575;&#38382;&#39064;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#29702;&#35770;&#26368;&#20248;&#12289;&#21487;&#35299;&#37322;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#32463;&#36807;&#27169;&#25311;&#39564;&#35777;&#20854;&#22312;&#22833;&#35823;&#27010;&#29575;&#12289;&#23398;&#20064;&#36895;&#24230;&#21644;&#25910;&#25947;&#31561;&#26041;&#38754;&#30340;&#34920;&#29616;&#20248;&#20110;&#19968;&#20123;&#24120;&#35265;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#26159;&#20351;6G&#21450;&#20197;&#19978;&#36890;&#20449;&#25104;&#20026;&#21487;&#33021;&#30340;&#37325;&#35201;&#24037;&#20855;&#12290;&#26412;&#25991;&#33268;&#21147;&#20110;&#23558;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20110;&#35299;&#20915;&#36825;&#20123;&#31995;&#32479;&#26222;&#36941;&#36935;&#21040;&#30340;&#22833;&#35823;&#27010;&#29575;&#38382;&#39064;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#32771;&#34385;&#21333;&#29992;&#25143;&#22810;&#36164;&#28304;&#36138;&#23146;&#20998;&#37197;&#31574;&#30053;&#65292;&#20854;&#20013;&#19968;&#20010;ML&#20108;&#20998;&#31867;&#39044;&#27979;&#22120;&#22312;&#36873;&#25321;&#20805;&#36275;&#36164;&#28304;&#26102;&#36827;&#34892;&#36741;&#21161;&#12290;&#24403;&#39044;&#27979;&#22120;&#36935;&#21040;&#30456;&#20449;&#20250;&#28385;&#24847;&#30340;&#36164;&#28304;&#26102;&#65292;&#23427;&#23558;&#20854;&#20998;&#37197;&#32473;&#29992;&#25143;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#24314;&#31435;&#20102;&#35813;&#31995;&#32479;&#22833;&#35823;&#27010;&#29575;&#30340;&#31934;&#30830;&#21644;&#28176;&#36827;&#34920;&#36798;&#24335;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#21046;&#23450;&#20102;&#19968;&#31181;&#29702;&#35770;&#26368;&#20248;&#30340;&#12289;&#21487;&#24494;&#30340;&#25439;&#22833;&#20989;&#25968;&#26469;&#35757;&#32451;&#39044;&#27979;&#22120;&#12290;&#25105;&#20204;&#36890;&#36807;&#22823;&#37327;&#27169;&#25311;&#27604;&#36739;&#20351;&#29992;&#27492;&#25439;&#22833;&#20989;&#25968;&#35757;&#32451;&#30340;&#39044;&#27979;&#22120;&#21644;&#20351;&#29992;&#20854;&#20182;&#24120;&#29992;&#25439;&#22833;&#20989;&#25968;&#35757;&#32451;&#30340;&#39044;&#27979;&#22120;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#24322;&#12290;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#25152;&#25552;&#20986;&#30340;&#25439;&#22833;&#20989;&#25968;&#23545;&#39044;&#27979;&#22120;&#36879;&#26126;&#24230;&#21644;&#26080;&#32447;&#20449;&#36947;&#32467;&#26500;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#25439;&#22833;&#20989;&#25968;&#22312;&#22833;&#35823;&#27010;&#29575;&#12289;&#31471;&#21040;&#31471;&#23398;&#20064;&#36895;&#24230;&#21644;&#25910;&#25947;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#30340;&#22522;&#20110;&#20108;&#20803;&#20132;&#21449;&#29109;&#30340;&#25439;&#22833;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#25439;&#22833;&#20989;&#25968;&#21046;&#23450;&#36171;&#20104;&#20102;&#21487;&#35299;&#37322;&#30340;&#39044;&#27979;&#22120;&#35757;&#32451;&#65292;&#33021;&#22815;&#31283;&#20581;&#22320;&#22788;&#29702;&#20449;&#36947;&#30340;&#26102;&#21464;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine Learning (ML) is a popular tool that will be pivotal in enabling 6G and beyond communications. This paper focuses on applying ML solutions to address outage probability issues commonly encountered in these systems. In particular, we consider a single-user multi-resource greedy allocation strategy, where an ML binary classification predictor assists in seizing an adequate resource. With no access to future channel state information, this predictor foresees each resource's likely future outage status. When the predictor encounters a resource it believes will be satisfactory, it allocates it to the user. Critically, the goal of the predictor is to ensure that a user avoids an unsatisfactory resource since this is likely to cause an outage. Our main result establishes exact and asymptotic expressions for this system's outage probability. With this, we formulate a theoretically optimal, differentiable loss function to train our predictor. We then compare predictors trained using thi
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22870;&#21169;&#25945;&#23398;&#24605;&#24819;&#30340;&#32852;&#37030;&#22810;&#33218;&#32769;&#34382;&#26426;&#35774;&#35745;&#65292;&#36890;&#36807;&#38544;&#24335;&#26412;&#22320;&#22870;&#21169;&#35843;&#25972;&#26469;&#25351;&#23548;&#23458;&#25143;&#31471;&#26397;&#30528;&#20840;&#23616;&#26368;&#20248;&#24615;&#65292;&#38431;&#26381;&#21153;&#31471;&#25552;&#20986;&#20102;&#32769;&#34382;&#26426;&#23398;&#20064;&#21644;&#30446;&#26631;&#25945;&#23398;&#20219;&#21153;&#36827;&#34892;&#20102;&#20248;&#21270;&#12290;</title><link>http://arxiv.org/abs/2305.02441</link><description>&lt;p&gt;
&#22522;&#20110;&#22870;&#21169;&#25945;&#23398;&#30340;&#32852;&#37030;&#22810;&#33218;&#32769;&#34382;&#26426;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Reward Teaching for Federated Multi-armed Bandits. (arXiv:2305.02441v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02441
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22870;&#21169;&#25945;&#23398;&#24605;&#24819;&#30340;&#32852;&#37030;&#22810;&#33218;&#32769;&#34382;&#26426;&#35774;&#35745;&#65292;&#36890;&#36807;&#38544;&#24335;&#26412;&#22320;&#22870;&#21169;&#35843;&#25972;&#26469;&#25351;&#23548;&#23458;&#25143;&#31471;&#26397;&#30528;&#20840;&#23616;&#26368;&#20248;&#24615;&#65292;&#38431;&#26381;&#21153;&#31471;&#25552;&#20986;&#20102;&#32769;&#34382;&#26426;&#23398;&#20064;&#21644;&#30446;&#26631;&#25945;&#23398;&#20219;&#21153;&#36827;&#34892;&#20102;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#22823;&#37096;&#20998;&#24050;&#26377;&#30340;&#32852;&#37030;&#22810;&#33218;&#32769;&#34382;&#26426;&#65288;FMAB&#65289;&#35774;&#35745;&#37117;&#22522;&#20110;&#20551;&#35774;&#23458;&#25143;&#31471;&#20250;&#23454;&#29616;&#25351;&#23450;&#30340;&#35774;&#35745;&#26469;&#19982;&#26381;&#21153;&#22120;&#21327;&#20316;&#12290;&#20294;&#23454;&#38469;&#19978;&#65292;&#21487;&#33021;&#26080;&#27861;&#20462;&#25913;&#23458;&#25143;&#31471;&#29616;&#26377;&#30340;&#21327;&#35758;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#19968;&#25361;&#25112;&#65292;&#35813;&#24037;&#20316;&#20851;&#27880;&#22987;&#32456;&#26368;&#22823;&#21270;&#20854;&#20010;&#20307;&#32047;&#31215;&#22870;&#21169;&#30340;&#23458;&#25143;&#31471;&#65292;&#24182;&#24341;&#20837;&#20102;&#8220;&#22870;&#21169;&#25945;&#23398;&#8221;&#30340;&#26032;&#24605;&#24819;&#65292;&#21363;&#36890;&#36807;&#38544;&#24335;&#30340;&#26412;&#22320;&#22870;&#21169;&#35843;&#25972;&#25351;&#23548;&#23458;&#25143;&#31471;&#26397;&#30528;&#20840;&#23616;&#26368;&#20248;&#24615;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#19979;&#65292;&#26381;&#21153;&#22120;&#38754;&#20020;&#20004;&#20010;&#23494;&#20999;&#32806;&#21512;&#30340;&#20219;&#21153;&#65292;&#21363;&#32769;&#34382;&#26426;&#23398;&#20064;&#21644;&#30446;&#26631;&#25945;&#23398;&#65292;&#23427;&#20204;&#30340;&#32467;&#21512;&#38750;&#24120;&#22797;&#26434;&#21644;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#39318;&#20808;&#35774;&#35745;&#20102;&#19968;&#20010;&#21517;&#20026; &#8220;Teaching-After-Learning&#65288;TAL&#65289;&#8221; &#30340;&#20998;&#38454;&#27573;&#26041;&#27861;&#65292;&#20998;&#21035;&#40723;&#21169;&#21644;&#38480;&#21046;&#23458;&#25143;&#31471;&#30340;&#25506;&#32034;&#12290;&#24403;&#23458;&#25143;&#31471;&#31574;&#30053;&#28385;&#36275;&#19968;&#23450;&#30340;&#28201;&#21644;&#35201;&#27714;&#26102;&#65292;&#24314;&#31435;&#20102;TAL&#30340;&#32508;&#21512;&#24615;&#33021;&#20998;&#26512;&#12290;&#36890;&#36807;&#24320;&#21457;&#26032;&#30340;&#25216;&#26415;&#26041;&#27861;&#26469;&#20998;&#26512;TAL&#30340;&#28909;&#21551;&#21160;&#21644;&#31639;&#27861;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;TAL&#21487;&#20197;&#27604;&#29616;&#26377;&#30340;FMAB&#35774;&#35745;&#24102;&#26469;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most of the existing federated multi-armed bandits (FMAB) designs are based on the presumption that clients will implement the specified design to collaborate with the server. In reality, however, it may not be possible to modify the client's existing protocols. To address this challenge, this work focuses on clients who always maximize their individual cumulative rewards, and introduces a novel idea of "reward teaching", where the server guides the clients towards global optimality through implicit local reward adjustments. Under this framework, the server faces two tightly coupled tasks of bandit learning and target teaching, whose combination is non-trivial and challenging. A phased approach, called Teaching-After-Learning (TAL), is first designed to encourage and discourage clients' explorations separately. General performance analyses of TAL are established when the clients' strategies satisfy certain mild requirements. With novel technical approaches developed to analyze the warm
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33021;&#37327;&#25193;&#25955;&#27169;&#22411;&#21644;MCMC&#30340;&#32452;&#21512;&#29983;&#25104;&#26041;&#27861;&#65292;&#26088;&#22312;&#35299;&#20915;&#29616;&#26377;&#25216;&#26415;&#22312;&#32452;&#21512;&#29983;&#25104;&#20013;&#30340;&#22833;&#36133;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#25104;&#21151;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2302.11552</link><description>&lt;p&gt;
&#20943;&#23569;&#12289;&#37325;&#22797;&#21033;&#29992;&#12289;&#22238;&#25910;&#65306;&#22522;&#20110;&#33021;&#37327;&#25193;&#25955;&#27169;&#22411;&#21644;MCMC&#30340;&#32452;&#21512;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Reduce, Reuse, Recycle: Compositional Generation with Energy-Based Diffusion Models and MCMC. (arXiv:2302.11552v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.11552
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33021;&#37327;&#25193;&#25955;&#27169;&#22411;&#21644;MCMC&#30340;&#32452;&#21512;&#29983;&#25104;&#26041;&#27861;&#65292;&#26088;&#22312;&#35299;&#20915;&#29616;&#26377;&#25216;&#26415;&#22312;&#32452;&#21512;&#29983;&#25104;&#20013;&#30340;&#22833;&#36133;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#25104;&#21151;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#20174;&#25193;&#25955;&#27169;&#22411;&#38382;&#19990;&#20197;&#26469;&#65292;&#23427;&#22312;&#35768;&#22810;&#39046;&#22495;&#20013;&#24050;&#32463;&#36805;&#36895;&#25104;&#20026;&#29983;&#25104;&#27169;&#22411;&#30340;&#20027;&#35201;&#26041;&#27861;&#12290;&#23427;&#20204;&#21487;&#20197;&#34987;&#35299;&#37322;&#20026;&#23398;&#20064;&#19968;&#31995;&#21015;&#26102;&#21464;&#30340;&#23545;&#25968;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#30340;&#26799;&#24230;&#12290;&#36825;&#31181;&#35299;&#37322;&#24050;&#32463;&#28608;&#21457;&#20102;&#22522;&#20110;&#20998;&#31867;&#22120;&#21644;&#26080;&#20998;&#31867;&#22120;&#25351;&#23548;&#30340;&#24605;&#24819;&#25104;&#20026;&#21518;&#32493;&#25511;&#21046;&#25193;&#25955;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#22312;&#36825;&#20123;&#24819;&#27861;&#30340;&#22522;&#30784;&#19978;&#65292;&#21033;&#29992;&#25193;&#25955;&#27169;&#22411;&#30340;&#20998;&#25968;-based&#35299;&#37322;&#65292;&#25506;&#32034;&#20102;&#29992;&#20110;&#28041;&#21450;&#32452;&#21512;&#29983;&#25104;&#21644;&#25351;&#23548;&#30340;&#26465;&#20214;&#12289;&#20462;&#25913;&#21644;&#37325;&#22797;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#20026;&#20160;&#20040;&#26576;&#20123;&#31867;&#22411;&#30340;&#32452;&#21512;&#20351;&#29992;&#24403;&#21069;&#25216;&#26415;&#22833;&#36133;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#20123;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65292;&#37319;&#26679;&#32773;(&#32780;&#19981;&#26159;&#27169;&#22411;)&#23545;&#27492;&#22833;&#36133;&#36127;&#26377;&#36131;&#20219;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#37319;&#26679;&#22120;&#65292;&#21463;MCMC&#30340;&#21551;&#21457;&#65292;&#20351;&#32452;&#21512;&#29983;&#25104;&#25104;&#21151;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33021;&#37327;&#30340;&#25193;&#25955;&#27169;&#22411;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#23427;&#20351;&#24471;&#36924;&#36817;&#30446;&#26631;&#20998;&#24067;&#26356;&#21152;&#23481;&#26131;&#12290;
&lt;/p&gt;
&lt;p&gt;
Since their introduction, diffusion models have quickly become the prevailing approach to generative modeling in many domains. They can be interpreted as learning the gradients of a time-varying sequence of log-probability density functions. This interpretation has motivated classifier-based and classifier-free guidance as methods for post-hoc control of diffusion models. In this work, we build upon these ideas using the score-based interpretation of diffusion models, and explore alternative ways to condition, modify, and reuse diffusion models for tasks involving compositional generation and guidance. In particular, we investigate why certain types of composition fail using current techniques and present a number of solutions. We conclude that the sampler (not the model) is responsible for this failure and propose new samplers, inspired by MCMC, which enable successful compositional generation. Further, we propose an energy-based parameterization of diffusion models which enables the 
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#24179;&#22343;&#22330; Langevin &#21160;&#21147;&#23398;&#65292;&#35777;&#26126;&#20102;&#36793;&#32536;&#20998;&#24067; $L^p$ &#25910;&#25947;&#24615;&#21644;&#28151;&#27788;&#29616;&#35937;&#30340;&#22343;&#21248;&#26102;&#38388;&#20256;&#25773;&#12290;</title><link>http://arxiv.org/abs/2212.03050</link><description>&lt;p&gt;
&#22343;&#21248;&#26102;&#38388;&#20256;&#25773;&#28151;&#27788;&#30340;&#24179;&#22343;&#22330; Langevin &#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
Uniform-in-time propagation of chaos for mean field Langevin dynamics. (arXiv:2212.03050v2 [math.PR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.03050
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#24179;&#22343;&#22330; Langevin &#21160;&#21147;&#23398;&#65292;&#35777;&#26126;&#20102;&#36793;&#32536;&#20998;&#24067; $L^p$ &#25910;&#25947;&#24615;&#21644;&#28151;&#27788;&#29616;&#35937;&#30340;&#22343;&#21248;&#26102;&#38388;&#20256;&#25773;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24179;&#22343;&#22330; Langevin &#21160;&#21147;&#23398;&#21450;&#20854;&#30456;&#20851;&#31890;&#23376;&#31995;&#32479;&#12290;&#36890;&#36807;&#20551;&#35774;&#33021;&#37327;&#20989;&#25968;&#30340;&#20984;&#24615;&#65292;&#25105;&#20204;&#24471;&#20986;&#20102;&#36793;&#32536;&#20998;&#24067;&#25910;&#25947;&#21040;&#24179;&#22343;&#22330;&#21160;&#21147;&#23398;&#21807;&#19968;&#19981;&#21464;&#27979;&#24230;&#30340; $L^p$ &#25910;&#25947;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312; $L^2$ Wasserstein &#36317;&#31163;&#21644;&#30456;&#23545;&#29109;&#20004;&#26041;&#38754;&#65292;&#28151;&#27788;&#29616;&#35937;&#30340;&#22343;&#21248;&#26102;&#38388;&#20256;&#25773;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the mean field Langevin dynamics and the associated particle system. By assuming the functional convexity of the energy, we obtain the $L^p$-convergence of the marginal distributions towards the unique invariant measure for the mean field dynamics. Furthermore, we prove the uniform-in-time propagation of chaos in both the $L^2$-Wasserstein metric and relative entropy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;PopArt&#30340;&#39640;&#25928;&#31232;&#30095;&#32447;&#24615;&#20272;&#35745;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;Lasso&#65292;&#22312;&#35768;&#22810;&#38382;&#39064;&#20013;&#20855;&#26377;&#26356;&#32039;&#30340;$\ell_1$&#24674;&#22797;&#20445;&#35777;&#65292;&#24182;&#22522;&#20110;&#27492;&#25512;&#23548;&#20986;&#31232;&#30095;&#32447;&#24615;&#25671;&#33218;&#31639;&#27861;&#65292;&#20855;&#26377;&#25913;&#36827;&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#25968;&#25454;&#31232;&#32570;&#24773;&#20917;&#19979;&#31232;&#30095;&#32447;&#24615;&#25671;&#33218;&#30340;&#21305;&#37197;&#19979;&#30028;&#12290;</title><link>http://arxiv.org/abs/2210.15345</link><description>&lt;p&gt;
PopArt: &#39640;&#25928;&#31232;&#30095;&#22238;&#24402;&#21644;&#20248;&#21270;&#31232;&#30095;&#32447;&#24615;&#25671;&#33218;&#30340;&#23454;&#39564;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
PopArt: Efficient Sparse Regression and Experimental Design for Optimal Sparse Linear Bandits. (arXiv:2210.15345v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.15345
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;PopArt&#30340;&#39640;&#25928;&#31232;&#30095;&#32447;&#24615;&#20272;&#35745;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;Lasso&#65292;&#22312;&#35768;&#22810;&#38382;&#39064;&#20013;&#20855;&#26377;&#26356;&#32039;&#30340;$\ell_1$&#24674;&#22797;&#20445;&#35777;&#65292;&#24182;&#22522;&#20110;&#27492;&#25512;&#23548;&#20986;&#31232;&#30095;&#32447;&#24615;&#25671;&#33218;&#31639;&#27861;&#65292;&#20855;&#26377;&#25913;&#36827;&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#25968;&#25454;&#31232;&#32570;&#24773;&#20917;&#19979;&#31232;&#30095;&#32447;&#24615;&#25671;&#33218;&#30340;&#21305;&#37197;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31232;&#30095;&#32447;&#24615;&#25671;&#33218;&#20013;&#65292;&#23398;&#20064;&#20195;&#29702;&#25353;&#39034;&#24207;&#36873;&#25321;&#19968;&#20010;&#21160;&#20316;&#24182;&#25509;&#25910;&#22870;&#21169;&#21453;&#39304;&#65292;&#32780;&#22870;&#21169;&#20989;&#25968;&#32447;&#24615;&#20381;&#36182;&#20110;&#21160;&#20316;&#30340;&#19968;&#20123;&#22352;&#26631;&#30340;&#21327;&#21464;&#37327;&#12290;&#36825;&#22312;&#35768;&#22810;&#23454;&#38469;&#30340;&#39034;&#24207;&#20915;&#31574;&#38382;&#39064;&#20013;&#37117;&#26377;&#24212;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#35745;&#31639;&#39640;&#25928;&#30340;&#31232;&#30095;&#32447;&#24615;&#20272;&#35745;&#26041;&#27861;&#65292;&#31216;&#20026;PopArt&#65292;&#19982;Lasso&#65288;Tibshirani, 1996&#65289;&#30456;&#27604;&#65292;&#23427;&#22312;&#35768;&#22810;&#38382;&#39064;&#20013;&#20855;&#26377;&#26356;&#32039;&#30340;$\ell_1$&#24674;&#22797;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#33258;&#28982;&#22320;&#28608;&#21457;&#20102;&#19968;&#31181;&#20984;&#23454;&#39564;&#35774;&#35745;&#20934;&#21017;&#65292;&#22240;&#27492;&#22312;&#35745;&#31639;&#19978;&#26159;&#39640;&#25928;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;&#26032;&#20272;&#35745;&#22120;&#21644;&#35774;&#35745;&#20934;&#21017;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#31232;&#30095;&#32447;&#24615;&#25671;&#33218;&#31639;&#27861;&#65292;&#20854;&#22312;&#32473;&#23450;&#21160;&#20316;&#38598;&#30340;&#20960;&#20309;&#24615;&#26041;&#38754;&#30456;&#23545;&#20110;&#29616;&#26377;&#25216;&#26415;&#65288;Hao et al., 2020&#65289;&#20855;&#26377;&#25913;&#36827;&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#25968;&#25454;&#31232;&#32570;&#24773;&#20917;&#19979;&#31232;&#30095;&#32447;&#24615;&#25671;&#33218;&#30340;&#21305;&#37197;&#19979;&#30028;&#65292;&#36825;&#22635;&#34917;&#20102;&#19978;&#30028;&#21644;&#19979;&#30028;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
In sparse linear bandits, a learning agent sequentially selects an action and receive reward feedback, and the reward function depends linearly on a few coordinates of the covariates of the actions. This has applications in many real-world sequential decision making problems. In this paper, we propose a simple and computationally efficient sparse linear estimation method called PopArt that enjoys a tighter $\ell_1$ recovery guarantee compared to Lasso (Tibshirani, 1996) in many problems. Our bound naturally motivates an experimental design criterion that is convex and thus computationally efficient to solve. Based on our novel estimator and design criterion, we derive sparse linear bandit algorithms that enjoy improved regret upper bounds upon the state of the art (Hao et al., 2020), especially w.r.t. the geometry of the given action set. Finally, we prove a matching lower bound for sparse linear bandits in the data-poor regime, which closes the gap between upper and lower bounds in pr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#26080;&#20284;&#28982;&#20551;&#35774;&#19979;&#30340;&#39057;&#29575;&#23398;&#27966;&#25512;&#26029;&#65288;LF2I&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;&#32463;&#20856;&#32479;&#35745;&#21644;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#65292;&#23454;&#29616;&#20102;&#26500;&#24314;&#20855;&#26377;&#27491;&#30830;&#26465;&#20214;&#35206;&#30422;&#30340;&#32622;&#20449;&#21306;&#38388;&#30340;&#23454;&#29992;&#31243;&#24207;&#21644;&#35786;&#26029;&#26041;&#27861;&#65292;&#22312;&#21253;&#25324;&#23431;&#23449;&#23398;&#21442;&#25968;&#25512;&#26029;&#22312;&#20869;&#30340;&#22810;&#20010;&#20363;&#23376;&#20013;&#37117;&#23454;&#29616;&#20102;&#35206;&#30422;&#24615;&#36136;&#24471;&#21040;&#22823;&#24133;&#25913;&#21892;&#12290;</title><link>http://arxiv.org/abs/2107.03920</link><description>&lt;p&gt;
&#26080;&#20284;&#28982;&#20551;&#35774;&#19979;&#22522;&#20110;&#39057;&#29575;&#23398;&#27966;&#25512;&#26029;&#65306;&#20855;&#26377;&#27491;&#30830;&#26465;&#20214;&#35206;&#30422;&#30340;&#32622;&#20449;&#21306;&#38388;
&lt;/p&gt;
&lt;p&gt;
Likelihood-Free Frequentist Inference: Confidence Sets with Correct Conditional Coverage. (arXiv:2107.03920v6 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.03920
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#26080;&#20284;&#28982;&#20551;&#35774;&#19979;&#30340;&#39057;&#29575;&#23398;&#27966;&#25512;&#26029;&#65288;LF2I&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;&#32463;&#20856;&#32479;&#35745;&#21644;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#65292;&#23454;&#29616;&#20102;&#26500;&#24314;&#20855;&#26377;&#27491;&#30830;&#26465;&#20214;&#35206;&#30422;&#30340;&#32622;&#20449;&#21306;&#38388;&#30340;&#23454;&#29992;&#31243;&#24207;&#21644;&#35786;&#26029;&#26041;&#27861;&#65292;&#22312;&#21253;&#25324;&#23431;&#23449;&#23398;&#21442;&#25968;&#25512;&#26029;&#22312;&#20869;&#30340;&#22810;&#20010;&#20363;&#23376;&#20013;&#37117;&#23454;&#29616;&#20102;&#35206;&#30422;&#24615;&#36136;&#24471;&#21040;&#22823;&#24133;&#25913;&#21892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#31185;&#23398;&#39046;&#22495;&#37117;&#24191;&#27867;&#20351;&#29992;&#35745;&#31639;&#26426;&#27169;&#25311;&#22120;&#20197;&#38544;&#21547;&#22797;&#26434;&#31995;&#32479;&#30340;&#20284;&#28982;&#20989;&#25968;&#12290;&#20256;&#32479;&#30340;&#32479;&#35745;&#26041;&#27861;&#24182;&#19981;&#36866;&#29992;&#20110;&#36825;&#20123;&#31216;&#20026;&#26080;&#20284;&#28982;&#20551;&#35774;&#19979;&#25512;&#26029;&#65288;LFI&#65289;&#30340;&#24773;&#20917;&#65292;&#23588;&#20854;&#26159;&#22312;&#28176;&#36817;&#21644;&#20302;&#32500;&#30340;&#26465;&#20214;&#19979;&#12290;&#34429;&#28982;&#26032;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#22914;&#24402;&#19968;&#21270;&#27969;&#65292;&#24050;&#32463;&#38761;&#26032;&#20102;LFI&#26041;&#27861;&#30340;&#26679;&#26412;&#25928;&#29575;&#21644;&#23481;&#37327;&#65292;&#20294;&#23427;&#20204;&#26159;&#21542;&#33021;&#20026;&#23567;&#26679;&#26412;&#22823;&#23567;&#20135;&#29983;&#20855;&#26377;&#27491;&#30830;&#26465;&#20214;&#35206;&#30422;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#12290;&#26412;&#25991;&#23558;&#32463;&#20856;&#32479;&#35745;&#21644;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#65288;i&#65289;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#21517;&#20041;&#35206;&#30422;&#30340;&#20869;&#26364;&#21306;&#38388;&#24314;&#35774;&#30340;&#23454;&#29992;&#31243;&#24207;&#65292;&#20197;&#21450;&#65288;ii&#65289;&#20272;&#35745;&#25972;&#20010;&#21442;&#25968;&#31354;&#38388;&#30340;&#26465;&#20214;&#35206;&#30422;&#30340;&#35786;&#26029;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26694;&#26550;&#31216;&#20026;&#26080;&#20284;&#28982;&#20551;&#35774;&#19979;&#30340;&#39057;&#29575;&#23398;&#27966;&#25512;&#26029;&#65288;LF2I&#65289;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#20351;&#29992;&#23450;&#20041;&#27979;&#35797;&#32479;&#35745;&#37327;&#30340;&#20219;&#20309;&#26041;&#27861;&#65292;&#22914;&#20284;&#28982;&#27604;&#65292;&#22240;&#27492;&#20855;&#26377;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#20960;&#20010;&#21512;&#25104;&#21644;&#23454;&#38469;&#30340;&#20363;&#23376;&#65292;&#21253;&#25324;&#23431;&#23449;&#23398;&#21442;&#25968;&#25512;&#26029;&#65292;&#24182;&#35777;&#26126;&#19982;&#29616;&#26377;&#30340;LFI&#26041;&#27861;&#30456;&#27604;&#65292;&#35206;&#30422;&#24615;&#36136;&#24471;&#21040;&#20102;&#22823;&#24133;&#25913;&#21892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many areas of science make extensive use of computer simulators that implicitly encode likelihood functions of complex systems. Classical statistical methods are poorly suited for these so-called likelihood-free inference (LFI) settings, particularly outside asymptotic and low-dimensional regimes. Although new machine learning methods, such as normalizing flows, have revolutionized the sample efficiency and capacity of LFI methods, it remains an open question whether they produce confidence sets with correct conditional coverage for small sample sizes. This paper unifies classical statistics with modern machine learning to present (i) a practical procedure for the Neyman construction of confidence sets with finite-sample guarantees of nominal coverage, and (ii) diagnostics that estimate conditional coverage over the entire parameter space. We refer to our framework as likelihood-free frequentist inference (LF2I). Any method that defines a test statistic, like the likelihood ratio, can 
&lt;/p&gt;</description></item></channel></rss>