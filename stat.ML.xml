<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22522;&#20110;&#20302;&#31209;&#21152;&#23545;&#35282;&#32447;&#21442;&#25968;&#21270;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#21051;&#30011;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#35823;&#24046;&#30340;&#33258;&#30456;&#20851;&#24615;&#65292;&#24182;&#20855;&#26377;&#22797;&#26434;&#24230;&#20302;&#12289;&#26657;&#20934;&#39044;&#27979;&#20934;&#30830;&#24615;&#39640;&#31561;&#20248;&#28857;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01000</link><description>&lt;p&gt;
&#22810;&#20803;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#19982;&#30456;&#20851;&#35823;&#24046;
&lt;/p&gt;
&lt;p&gt;
Multivariate Probabilistic Time Series Forecasting with Correlated Errors
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01000
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22522;&#20110;&#20302;&#31209;&#21152;&#23545;&#35282;&#32447;&#21442;&#25968;&#21270;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#21051;&#30011;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#35823;&#24046;&#30340;&#33258;&#30456;&#20851;&#24615;&#65292;&#24182;&#20855;&#26377;&#22797;&#26434;&#24230;&#20302;&#12289;&#26657;&#20934;&#39044;&#27979;&#20934;&#30830;&#24615;&#39640;&#31561;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24314;&#27169;&#35823;&#24046;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#19982;&#27169;&#22411;&#33021;&#22815;&#20934;&#30830;&#37327;&#21270;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#23494;&#20999;&#30456;&#20851;&#12290;&#26368;&#36817;&#30340;&#22810;&#20803;&#27169;&#22411;&#22312;&#32771;&#34385;&#35823;&#24046;&#20043;&#38388;&#30340;&#21516;&#26102;&#30456;&#20851;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#28982;&#32780;&#65292;&#23545;&#20110;&#32479;&#35745;&#31616;&#21270;&#30340;&#30446;&#30340;&#65292;&#23545;&#36825;&#20123;&#35823;&#24046;&#30340;&#24120;&#35265;&#20551;&#35774;&#26159;&#23427;&#20204;&#22312;&#26102;&#38388;&#19978;&#26159;&#29420;&#31435;&#30340;&#12290;&#28982;&#32780;&#65292;&#23454;&#38469;&#35266;&#27979;&#24448;&#24448;&#20559;&#31163;&#20102;&#36825;&#20010;&#20551;&#35774;&#65292;&#22240;&#20026;&#35823;&#24046;&#36890;&#24120;&#30001;&#20110;&#21508;&#31181;&#22240;&#32032;&#65288;&#22914;&#25490;&#38500;&#26102;&#38388;&#30456;&#20851;&#30340;&#21327;&#21464;&#37327;&#65289;&#32780;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#33258;&#30456;&#20851;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20302;&#31209;&#21152;&#23545;&#35282;&#32447;&#21442;&#25968;&#21270;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#21051;&#30011;&#35823;&#24046;&#30340;&#33258;&#30456;&#20851;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20855;&#26377;&#20960;&#20010;&#21487;&#21462;&#30340;&#29305;&#24615;&#65306;&#22797;&#26434;&#24230;&#19981;&#38543;&#26102;&#38388;&#24207;&#21015;&#25968;&#30446;&#22686;&#21152;&#65292;&#24471;&#21040;&#30340;&#21327;&#26041;&#24046;&#21487;&#20197;&#29992;&#20110;&#26657;&#20934;&#39044;&#27979;&#65292;&#19988;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modeling the correlations among errors is closely associated with how accurately the model can quantify predictive uncertainty in probabilistic time series forecasting. Recent multivariate models have made significant progress in accounting for contemporaneous correlations among errors, while a common assumption on these errors is that they are temporally independent for the sake of statistical simplicity. However, real-world observations often deviate from this assumption, since errors usually exhibit substantial autocorrelation due to various factors such as the exclusion of temporally correlated covariates. In this work, we propose an efficient method, based on a low-rank-plus-diagonal parameterization of the covariance matrix, which can effectively characterize the autocorrelation of errors. The proposed method possesses several desirable properties: the complexity does not scale with the number of time series, the resulting covariance can be used for calibrating predictions, and i
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#25512;&#23548;PAC-Bayes&#27867;&#21270;&#30028;&#38480;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#25554;&#20540;&#22312;&#19981;&#21516;&#27010;&#29575;&#24046;&#24322;&#20043;&#38388;&#36873;&#25321;&#26368;&#20339;&#26041;&#26696;&#65292;&#23637;&#31034;&#20102;&#32039;&#23494;&#24615;&#21644;&#23454;&#38469;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.05101</link><description>&lt;p&gt;
&#36890;&#36807;&#25554;&#20540;&#23454;&#29616;&#26356;&#32039;&#23494;&#30340;&#27867;&#21270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Tighter Generalisation Bounds via Interpolation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05101
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#25512;&#23548;PAC-Bayes&#27867;&#21270;&#30028;&#38480;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#25554;&#20540;&#22312;&#19981;&#21516;&#27010;&#29575;&#24046;&#24322;&#20043;&#38388;&#36873;&#25321;&#26368;&#20339;&#26041;&#26696;&#65292;&#23637;&#31034;&#20102;&#32039;&#23494;&#24615;&#21644;&#23454;&#38469;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#25512;&#23548;&#26032;&#30340;&#22522;&#20110;$(f, \Gamma)$-divergence&#30340;PAC-Bayes&#27867;&#21270;&#30028;&#38480;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#19968;&#31995;&#21015;&#27010;&#29575;&#24046;&#24322;&#65288;&#21253;&#25324;&#20294;&#19981;&#38480;&#20110;KL&#12289;Wasserstein&#21644;&#24635;&#21464;&#24046;&#65289;&#20043;&#38388;&#36827;&#34892;&#25554;&#20540;&#30340;PAC-Bayes&#27867;&#21270;&#30028;&#38480;&#65292;&#26681;&#25454;&#21518;&#39564;&#20998;&#24067;&#30340;&#23646;&#24615;&#36873;&#25321;&#26368;&#20339;&#26041;&#26696;&#12290;&#25105;&#20204;&#25506;&#32034;&#20102;&#36825;&#20123;&#30028;&#38480;&#30340;&#32039;&#23494;&#24615;&#65292;&#24182;&#23558;&#20854;&#19982;&#32479;&#35745;&#23398;&#20064;&#20013;&#30340;&#26089;&#26399;&#32467;&#26524;&#32852;&#31995;&#36215;&#26469;&#65292;&#36825;&#20123;&#32467;&#26524;&#26159;&#29305;&#23450;&#26696;&#20363;&#12290;&#25105;&#20204;&#36824;&#23558;&#25105;&#20204;&#30340;&#30028;&#38480;&#23454;&#20363;&#21270;&#20026;&#35757;&#32451;&#30446;&#26631;&#65292;&#20135;&#29983;&#20102;&#38750;&#24179;&#20961;&#30340;&#20445;&#35777;&#21644;&#23454;&#38469;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper contains a recipe for deriving new PAC-Bayes generalisation bounds based on the $(f, \Gamma)$-divergence, and, in addition, presents PAC-Bayes generalisation bounds where we interpolate between a series of probability divergences (including but not limited to KL, Wasserstein, and total variation), making the best out of many worlds depending on the posterior distributions properties. We explore the tightness of these bounds and connect them to earlier results from statistical learning, which are specific cases. We also instantiate our bounds as training objectives, yielding non-trivial guarantees and practical performances.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#35757;&#32451;&#25193;&#25955;&#27169;&#22411;&#20197;&#20174;&#32473;&#23450;&#20998;&#24067;&#20013;&#37319;&#26679;&#30340;&#38382;&#39064;&#65292;&#24182;&#38024;&#23545;&#38543;&#26426;&#25511;&#21046;&#21644;&#37319;&#26679;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25506;&#32034;&#31574;&#30053;&#65292;&#36890;&#36807;&#22522;&#20934;&#27979;&#35797;&#27604;&#36739;&#20102;&#19981;&#21516;&#25512;&#26029;&#26041;&#27861;&#30340;&#30456;&#23545;&#20248;&#21155;&#65292;&#24182;&#23545;&#36807;&#21435;&#30340;&#24037;&#20316;&#25552;&#20986;&#20102;&#36136;&#30097;&#12290;</title><link>https://arxiv.org/abs/2402.05098</link><description>&lt;p&gt;
&#20851;&#20110;&#20998;&#25955;&#25512;&#26029;&#27169;&#22411;&#30340;&#25193;&#25955;&#27169;&#22411;&#65306;&#22522;&#20934;&#27979;&#35797;&#21644;&#25913;&#36827;&#38543;&#26426;&#25511;&#21046;&#21644;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
On diffusion models for amortized inference: Benchmarking and improving stochastic control and sampling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05098
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#35757;&#32451;&#25193;&#25955;&#27169;&#22411;&#20197;&#20174;&#32473;&#23450;&#20998;&#24067;&#20013;&#37319;&#26679;&#30340;&#38382;&#39064;&#65292;&#24182;&#38024;&#23545;&#38543;&#26426;&#25511;&#21046;&#21644;&#37319;&#26679;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25506;&#32034;&#31574;&#30053;&#65292;&#36890;&#36807;&#22522;&#20934;&#27979;&#35797;&#27604;&#36739;&#20102;&#19981;&#21516;&#25512;&#26029;&#26041;&#27861;&#30340;&#30456;&#23545;&#20248;&#21155;&#65292;&#24182;&#23545;&#36807;&#21435;&#30340;&#24037;&#20316;&#25552;&#20986;&#20102;&#36136;&#30097;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#35757;&#32451;&#25193;&#25955;&#27169;&#22411;&#20197;&#20174;&#32473;&#23450;&#30340;&#38750;&#26631;&#20934;&#21270;&#23494;&#24230;&#25110;&#33021;&#37327;&#20989;&#25968;&#20998;&#24067;&#20013;&#37319;&#26679;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#23545;&#20960;&#31181;&#25193;&#25955;&#32467;&#26500;&#25512;&#26029;&#26041;&#27861;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#65292;&#21253;&#25324;&#22522;&#20110;&#27169;&#25311;&#30340;&#21464;&#20998;&#26041;&#27861;&#21644;&#31163;&#31574;&#30053;&#26041;&#27861;&#65288;&#36830;&#32493;&#29983;&#25104;&#27969;&#32593;&#32476;&#65289;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25581;&#31034;&#20102;&#29616;&#26377;&#31639;&#27861;&#30340;&#30456;&#23545;&#20248;&#21183;&#65292;&#21516;&#26102;&#23545;&#36807;&#21435;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20123;&#36136;&#30097;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31163;&#31574;&#30053;&#26041;&#27861;&#25506;&#32034;&#31574;&#30053;&#65292;&#22522;&#20110;&#30446;&#26631;&#31354;&#38388;&#20013;&#30340;&#23616;&#37096;&#25628;&#32034;&#21644;&#22238;&#25918;&#32531;&#20914;&#21306;&#30340;&#20351;&#29992;&#65292;&#24182;&#35777;&#26126;&#23427;&#21487;&#20197;&#25913;&#21892;&#21508;&#31181;&#30446;&#26631;&#20998;&#24067;&#19978;&#30340;&#26679;&#26412;&#36136;&#37327;&#12290;&#25105;&#20204;&#30740;&#31350;&#30340;&#37319;&#26679;&#26041;&#27861;&#21644;&#22522;&#20934;&#27979;&#35797;&#30340;&#20195;&#30721;&#24050;&#20844;&#24320;&#22312;https://github.com/GFNOrg/gfn-diffusion&#65292;&#20316;&#20026;&#26410;&#26469;&#22312;&#20998;&#25955;&#25512;&#26029;&#27169;&#22411;&#19978;&#24037;&#20316;&#30340;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of training diffusion models to sample from a distribution with a given unnormalized density or energy function. We benchmark several diffusion-structured inference methods, including simulation-based variational approaches and off-policy methods (continuous generative flow networks). Our results shed light on the relative advantages of existing algorithms while bringing into question some claims from past work. We also propose a novel exploration strategy for off-policy methods, based on local search in the target space with the use of a replay buffer, and show that it improves the quality of samples on a variety of target distributions. Our code for the sampling methods and benchmarks studied is made public at https://github.com/GFNOrg/gfn-diffusion as a base for future work on diffusion models for amortized inference.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#36830;&#24102;&#20559;&#24207;&#29305;&#24615;&#30340;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#38454;&#31639;&#27861;&#30340;&#36866;&#29992;&#33539;&#22260;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#22797;&#26434;&#24230;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2402.05071</link><description>&lt;p&gt;
&#25193;&#23637;&#20855;&#26377;&#36830;&#24102;&#20559;&#24207;&#29305;&#24615;&#30340;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#19968;&#38454;&#31639;&#27861;&#30340;&#36866;&#29992;&#33539;&#22260;
&lt;/p&gt;
&lt;p&gt;
Extending the Reach of First-Order Algorithms for Nonconvex Min-Max Problems with Cohypomonotonicity
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05071
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#36830;&#24102;&#20559;&#24207;&#29305;&#24615;&#30340;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#38454;&#31639;&#27861;&#30340;&#36866;&#29992;&#33539;&#22260;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#22797;&#26434;&#24230;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#28385;&#36275;rho-&#36830;&#24102;&#20559;&#24207;&#29305;&#24615;&#25110;&#22312;rho-&#24369;Minty&#21464;&#20998;&#19981;&#31561;&#24335;&#65288;MVI&#65289;&#20013;&#23384;&#22312;&#35299;&#30340;&#32422;&#26463;&#65292;L-&#20809;&#28369;&#30340;&#38750;&#20984;&#38750;&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#20854;&#20013;&#21442;&#25968;rho&gt;0&#30340;&#36739;&#22823;&#20540;&#23545;&#24212;&#26356;&#39640;&#30340;&#38750;&#20984;&#24615;&#31243;&#24230;&#12290;&#36825;&#20123;&#38382;&#39064;&#31867;&#21253;&#25324;&#20004;&#20010;&#29609;&#23478;&#24378;&#21270;&#23398;&#20064;&#65292;&#20132;&#20114;&#20027;&#23548;&#30340;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#20197;&#21450;&#26576;&#20123;&#32463;&#20856;&#26497;&#23567;&#26497;&#22823;&#31639;&#27861;&#26080;&#27861;&#35299;&#20915;&#30340;&#21512;&#25104;&#27979;&#35797;&#38382;&#39064;&#12290;&#24050;&#26377;&#29468;&#24819;&#35748;&#20026;&#19968;&#38454;&#26041;&#27861;&#21487;&#23481;&#24525;&#26368;&#22823;rho&#20026;1/L&#65292;&#20294;&#29616;&#26377;&#25991;&#29486;&#20013;&#30340;&#32467;&#26524;&#24050;&#20572;&#28382;&#22312;&#26356;&#20005;&#26684;&#30340;&#35201;&#27714;rho&lt;1/2L&#12290;&#36890;&#36807;&#31616;&#21333;&#30340;&#35770;&#35777;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#20855;&#26377;&#36830;&#24102;&#20559;&#24207;&#29305;&#24615;&#25110;&#24369;MVI&#26465;&#20214;&#19979;&#65292;rho&lt;1/L&#30340;&#26368;&#20248;&#25110;&#26368;&#20339;&#24050;&#30693;&#22797;&#26434;&#24230;&#20445;&#35777;&#12290;&#25105;&#20204;&#20998;&#26512;&#30340;&#31639;&#27861;&#26159;Halpern&#21644;Krasnosel'ski&#301;-Mann (KM)&#36845;&#20195;&#30340;&#38750;&#31934;&#30830;&#21464;&#31181;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#31639;&#27861;&#21644;&#22797;&#26434;&#24230;g...
&lt;/p&gt;
&lt;p&gt;
We focus on constrained, $L$-smooth, nonconvex-nonconcave min-max problems either satisfying $\rho$-cohypomonotonicity or admitting a solution to the $\rho$-weakly Minty Variational Inequality (MVI), where larger values of the parameter $\rho&gt;0$ correspond to a greater degree of nonconvexity. These problem classes include examples in two player reinforcement learning, interaction dominant min-max problems, and certain synthetic test problems on which classical min-max algorithms fail. It has been conjectured that first-order methods can tolerate value of $\rho$ no larger than $\frac{1}{L}$, but existing results in the literature have stagnated at the tighter requirement $\rho &lt; \frac{1}{2L}$. With a simple argument, we obtain optimal or best-known complexity guarantees with cohypomonotonicity or weak MVI conditions for $\rho &lt; \frac{1}{L}$. The algorithms we analyze are inexact variants of Halpern and Krasnosel'ski\u{\i}-Mann (KM) iterations. We also provide algorithms and complexity g
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#12289;&#23436;&#20840;&#38750;&#21442;&#25968;&#30340;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#35774;&#32622;&#65292;&#26088;&#22312;&#22312;&#22810;&#20010;&#20998;&#24067;&#20043;&#38388;&#23398;&#20064;&#22240;&#26524;&#20851;&#31995;&#65292;&#26080;&#38656;&#20551;&#35774;&#30828;&#24178;&#39044;&#12290;&#36890;&#36807;&#31232;&#30095;&#24615;&#32422;&#26463;&#65292;&#21487;&#20197;&#20174;&#22810;&#20010;&#20998;&#24067;&#20013;&#24674;&#22797;&#20986;&#22240;&#26524;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2402.05052</link><description>&lt;p&gt;
&#20174;&#22810;&#20010;&#20998;&#24067;&#20013;&#36827;&#34892;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#65306;&#19968;&#20010;&#36890;&#29992;&#35774;&#32622;
&lt;/p&gt;
&lt;p&gt;
Causal Representation Learning from Multiple Distributions: A General Setting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05052
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#12289;&#23436;&#20840;&#38750;&#21442;&#25968;&#30340;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#35774;&#32622;&#65292;&#26088;&#22312;&#22312;&#22810;&#20010;&#20998;&#24067;&#20043;&#38388;&#23398;&#20064;&#22240;&#26524;&#20851;&#31995;&#65292;&#26080;&#38656;&#20551;&#35774;&#30828;&#24178;&#39044;&#12290;&#36890;&#36807;&#31232;&#30095;&#24615;&#32422;&#26463;&#65292;&#21487;&#20197;&#20174;&#22810;&#20010;&#20998;&#24067;&#20013;&#24674;&#22797;&#20986;&#22240;&#26524;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#38382;&#39064;&#20013;&#65292;&#27979;&#37327;&#21464;&#37327;&#65288;&#20363;&#22914;&#22270;&#20687;&#20687;&#32032;&#65289;&#21482;&#26159;&#38544;&#34255;&#30340;&#22240;&#26524;&#21464;&#37327;&#65288;&#20363;&#22914;&#28508;&#22312;&#30340;&#27010;&#24565;&#25110;&#23545;&#35937;&#65289;&#30340;&#25968;&#23398;&#20989;&#25968;&#12290;&#20026;&#20102;&#22312;&#19981;&#26029;&#21464;&#21270;&#30340;&#29615;&#22659;&#20013;&#36827;&#34892;&#39044;&#27979;&#25110;&#23545;&#31995;&#32479;&#36827;&#34892;&#36866;&#24403;&#30340;&#26356;&#25913;&#65292;&#24674;&#22797;&#38544;&#34255;&#30340;&#22240;&#26524;&#21464;&#37327;$Z_i$&#20197;&#21450;&#30001;&#22270;$\mathcal{G}_Z$&#34920;&#31034;&#30340;&#23427;&#20204;&#30340;&#22240;&#26524;&#20851;&#31995;&#26159;&#26377;&#24110;&#21161;&#30340;&#12290;&#36825;&#20010;&#38382;&#39064;&#26368;&#36817;&#34987;&#31216;&#20026;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#12290;&#26412;&#25991;&#20851;&#27880;&#26469;&#33258;&#22810;&#20010;&#20998;&#24067;&#65288;&#26469;&#33258;&#24322;&#26500;&#25968;&#25454;&#25110;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#65289;&#30340;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#30340;&#36890;&#29992;&#12289;&#23436;&#20840;&#38750;&#21442;&#25968;&#30340;&#35774;&#32622;&#65292;&#19981;&#38656;&#35201;&#20551;&#35774;&#20998;&#24067;&#25913;&#21464;&#32972;&#21518;&#23384;&#22312;&#30828;&#24178;&#39044;&#12290;&#25105;&#20204;&#26088;&#22312;&#22312;&#36825;&#20010;&#22522;&#26412;&#24773;&#20917;&#19979;&#24320;&#21457;&#36890;&#29992;&#35299;&#20915;&#26041;&#26696;&#65307;&#20316;&#20026;&#21103;&#20135;&#21697;&#65292;&#36825;&#26377;&#21161;&#20110;&#30475;&#21040;&#20854;&#20182;&#20551;&#35774;&#65288;&#22914;&#21442;&#25968;&#22240;&#26524;&#27169;&#22411;&#25110;&#30828;&#24178;&#39044;&#65289;&#25552;&#20379;&#30340;&#29420;&#29305;&#22909;&#22788;&#12290;&#25105;&#20204;&#35777;&#26126;&#22312;&#24674;&#22797;&#36807;&#31243;&#20013;&#23545;&#22270;&#30340;&#31232;&#30095;&#24615;&#32422;&#26463;&#19979;&#65292;&#21487;&#20197;&#20174;&#22810;&#20010;&#20998;&#24067;&#20013;&#23398;&#20064;&#20986;&#22240;&#26524;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many problems, the measured variables (e.g., image pixels) are just mathematical functions of the hidden causal variables (e.g., the underlying concepts or objects). For the purpose of making predictions in changing environments or making proper changes to the system, it is helpful to recover the hidden causal variables $Z_i$ and their causal relations represented by graph $\mathcal{G}_Z$. This problem has recently been known as causal representation learning. This paper is concerned with a general, completely nonparametric setting of causal representation learning from multiple distributions (arising from heterogeneous data or nonstationary time series), without assuming hard interventions behind distribution changes. We aim to develop general solutions in this fundamental case; as a by product, this helps see the unique benefit offered by other assumptions such as parametric causal models or hard interventions. We show that under the sparsity constraint on the recovered graph over
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#22312;&#33258;&#32534;&#30721;&#22120;&#20013;&#65292;&#21363;&#20351;&#37319;&#29992;&#27973;&#23618;&#32467;&#26500;&#65292;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#20250;&#23436;&#20840;&#24573;&#30053;&#31232;&#30095;&#25968;&#25454;&#30340;&#32467;&#26500;&#65292;&#24182;&#19988;&#23545;&#20110;&#19968;&#33324;&#25968;&#25454;&#20998;&#24067;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#26799;&#24230;&#19979;&#38477;&#26368;&#23567;&#21270;&#22120;&#22312;&#25968;&#25454;&#31232;&#30095;&#24615;&#20020;&#30028;&#28857;&#22788;&#30340;&#30456;&#21464;&#29616;&#35937;&#12290;</title><link>https://arxiv.org/abs/2402.05013</link><description>&lt;p&gt;
&#29992;&#33258;&#32534;&#30721;&#22120;&#23545;&#32467;&#26500;&#21270;&#25968;&#25454;&#36827;&#34892;&#21387;&#32553;&#65306;&#38750;&#32447;&#24615;&#21644;&#28145;&#24230;&#30340;&#21487;&#35777;&#26126;&#20248;&#21183;
&lt;/p&gt;
&lt;p&gt;
Compression of Structured Data with Autoencoders: Provable Benefit of Nonlinearities and Depth
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05013
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#22312;&#33258;&#32534;&#30721;&#22120;&#20013;&#65292;&#21363;&#20351;&#37319;&#29992;&#27973;&#23618;&#32467;&#26500;&#65292;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#20250;&#23436;&#20840;&#24573;&#30053;&#31232;&#30095;&#25968;&#25454;&#30340;&#32467;&#26500;&#65292;&#24182;&#19988;&#23545;&#20110;&#19968;&#33324;&#25968;&#25454;&#20998;&#24067;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#26799;&#24230;&#19979;&#38477;&#26368;&#23567;&#21270;&#22120;&#22312;&#25968;&#25454;&#31232;&#30095;&#24615;&#20020;&#30028;&#28857;&#22788;&#30340;&#30456;&#21464;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#32534;&#30721;&#22120;&#26159;&#26426;&#22120;&#23398;&#20064;&#21644;&#26377;&#25439;&#25968;&#25454;&#21387;&#32553;&#30340;&#22810;&#20010;&#23454;&#35777;&#20998;&#25903;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#21363;&#20351;&#22312;&#27973;&#23618;&#20004;&#23618;&#35774;&#32622;&#19979;&#65292;&#22522;&#26412;&#30340;&#29702;&#35770;&#38382;&#39064;&#20173;&#28982;&#27809;&#26377;&#31572;&#26696;&#12290;&#29305;&#21035;&#26159;&#65292;&#22312;&#27973;&#23618;&#33258;&#32534;&#30721;&#22120;&#20013;&#33021;&#22815;&#22810;&#22823;&#31243;&#24230;&#19978;&#25429;&#25417;&#21040;&#24213;&#23618;&#25968;&#25454;&#20998;&#24067;&#30340;&#32467;&#26500;&#65311;&#23545;&#20110;&#20856;&#22411;&#30340;&#31232;&#30095;&#39640;&#26031;&#25968;&#25454;&#30340;1&#20301;&#21387;&#32553;&#38382;&#39064;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#25910;&#25947;&#20110;&#19968;&#20010;&#23436;&#20840;&#24573;&#30053;&#36755;&#20837;&#30340;&#31232;&#30095;&#32467;&#26500;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25442;&#21477;&#35805;&#35828;&#65292;&#31639;&#27861;&#30340;&#24615;&#33021;&#19982;&#21387;&#32553;&#39640;&#26031;&#28304;&#65288;&#27809;&#26377;&#31232;&#30095;&#24615;&#65289;&#30340;&#24615;&#33021;&#30456;&#21516;&#12290;&#23545;&#20110;&#19968;&#33324;&#30340;&#25968;&#25454;&#20998;&#24067;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#20851;&#20110;&#26799;&#24230;&#19979;&#38477;&#26368;&#23567;&#21270;&#22120;&#30340;&#24418;&#29366;&#30340;&#30456;&#21464;&#29616;&#35937;&#30340;&#35777;&#25454;&#65292;&#20316;&#20026;&#25968;&#25454;&#31232;&#30095;&#24615;&#30340;&#20989;&#25968;&#65306;&#22312;&#20020;&#30028;&#31232;&#30095;&#27700;&#24179;&#20197;&#19979;&#65292;&#26368;&#23567;&#21270;&#22120;&#26159;&#19968;&#20010;&#38543;&#26426;&#22343;&#21248;&#36873;&#25321;&#30340;&#26059;&#36716;&#65288;&#23601;&#20687;&#38750;&#31232;&#30095;&#25968;&#25454;&#30340;&#21387;&#32553;&#19968;&#26679;&#65289;&#65307;&#22312;&#20020;&#30028;&#31232;&#30095;&#27700;&#24179;&#20197;&#19978;&#65292;&#26368;&#23567;&#21270;&#22120;&#26159;&#36523;&#20221;&#21464;&#25442;&#65288;&#38500;&#20102;&#19968;&#20010;+1&#30340;&#20559;&#31227;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Autoencoders are a prominent model in many empirical branches of machine learning and lossy data compression. However, basic theoretical questions remain unanswered even in a shallow two-layer setting. In particular, to what degree does a shallow autoencoder capture the structure of the underlying data distribution? For the prototypical case of the 1-bit compression of sparse Gaussian data, we prove that gradient descent converges to a solution that completely disregards the sparse structure of the input. Namely, the performance of the algorithm is the same as if it was compressing a Gaussian source - with no sparsity. For general data distributions, we give evidence of a phase transition phenomenon in the shape of the gradient descent minimizer, as a function of the data sparsity: below the critical sparsity level, the minimizer is a rotation taken uniformly at random (just like in the compression of non-sparse data); above the critical sparsity, the minimizer is the identity (up to a
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#31163;&#25955;&#27969;&#27169;&#22411;&#65288;DFMs&#65289;&#65292;&#36890;&#36807;&#36830;&#32493;&#26102;&#38388;&#39532;&#23572;&#21487;&#22827;&#38142;&#23454;&#29616;&#31163;&#25955;&#31354;&#38388;&#27969;&#21305;&#37197;&#30340;&#31163;&#25955;&#31561;&#25928;&#65292;&#20026;&#23558;&#22522;&#20110;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#24212;&#29992;&#20110;&#22810;&#27169;&#24577;&#36830;&#32493;&#21644;&#31163;&#25955;&#25968;&#25454;&#38382;&#39064;&#25552;&#20379;&#20102;&#35299;&#20915;&#26041;&#26696;&#12290;&#27492;&#26041;&#27861;&#22312;&#34507;&#30333;&#36136;&#20849;&#35774;&#35745;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.04997</link><description>&lt;p&gt;
&#22312;&#31163;&#25955;&#29366;&#24577;&#31354;&#38388;&#19978;&#30340;&#29983;&#25104;&#22411;&#27969;&#65306;&#23454;&#29616;&#22810;&#27169;&#24577;&#27969;&#24182;&#24212;&#29992;&#20110;&#34507;&#30333;&#36136;&#20849;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Generative Flows on Discrete State-Spaces: Enabling Multimodal Flows with Applications to Protein Co-Design
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04997
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#31163;&#25955;&#27969;&#27169;&#22411;&#65288;DFMs&#65289;&#65292;&#36890;&#36807;&#36830;&#32493;&#26102;&#38388;&#39532;&#23572;&#21487;&#22827;&#38142;&#23454;&#29616;&#31163;&#25955;&#31354;&#38388;&#27969;&#21305;&#37197;&#30340;&#31163;&#25955;&#31561;&#25928;&#65292;&#20026;&#23558;&#22522;&#20110;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#24212;&#29992;&#20110;&#22810;&#27169;&#24577;&#36830;&#32493;&#21644;&#31163;&#25955;&#25968;&#25454;&#38382;&#39064;&#25552;&#20379;&#20102;&#35299;&#20915;&#26041;&#26696;&#12290;&#27492;&#26041;&#27861;&#22312;&#34507;&#30333;&#36136;&#20849;&#35774;&#35745;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#31163;&#25955;&#21644;&#36830;&#32493;&#25968;&#25454;&#30456;&#32467;&#21512;&#23545;&#20110;&#29983;&#25104;&#27169;&#22411;&#26469;&#35828;&#26159;&#19968;&#39033;&#37325;&#35201;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#31163;&#25955;&#27969;&#27169;&#22411;&#65288;DFMs&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#27969;&#30340;&#31163;&#25955;&#25968;&#25454;&#27169;&#22411;&#65292;&#21487;&#20197;&#23454;&#29616;&#23558;&#22522;&#20110;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#24212;&#29992;&#20110;&#22810;&#27169;&#24577;&#36830;&#32493;&#21644;&#31163;&#25955;&#25968;&#25454;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#35265;&#35299;&#26159;&#65292;&#31163;&#25955;&#31354;&#38388;&#27969;&#21305;&#37197;&#30340;&#31163;&#25955;&#31561;&#25928;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#36830;&#32493;&#26102;&#38388;&#39532;&#23572;&#21487;&#22827;&#38142;&#26469;&#23454;&#29616;&#12290;DFMs&#36890;&#36807;&#31616;&#21333;&#30340;&#25512;&#23548;&#21253;&#25324;&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#29305;&#23450;&#23454;&#20363;&#65292;&#21516;&#26102;&#20801;&#35768;&#22312;&#29616;&#26377;&#22522;&#20110;&#25193;&#25955;&#30340;&#26041;&#27861;&#19978;&#25913;&#36827;&#24615;&#33021;&#12290;&#25105;&#20204;&#21033;&#29992;DFMs&#26041;&#27861;&#26500;&#24314;&#20102;&#19968;&#20010;&#22810;&#27169;&#24577;&#22522;&#20110;&#27969;&#30340;&#24314;&#27169;&#26694;&#26550;&#12290;&#25105;&#20204;&#23558;&#27492;&#33021;&#21147;&#24212;&#29992;&#20110;&#34507;&#30333;&#36136;&#20849;&#35774;&#35745;&#30340;&#20219;&#21153;&#65292;&#20854;&#20013;&#25105;&#20204;&#23398;&#20064;&#20102;&#19968;&#20010;&#33021;&#22815;&#21516;&#26102;&#29983;&#25104;&#34507;&#30333;&#36136;&#32467;&#26500;&#21644;&#24207;&#21015;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20849;&#35774;&#35745;&#24615;&#33021;&#19978;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#27700;&#24179;&#65292;&#21516;&#26102;&#20801;&#35768;&#20351;&#29992;&#21516;&#19968;&#20010;&#22810;&#27169;&#24577;&#27169;&#22411;&#36827;&#34892;&#24207;&#21015;&#25110;&#32467;&#26500;&#30340;&#28789;&#27963;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
Combining discrete and continuous data is an important capability for generative models. We present Discrete Flow Models (DFMs), a new flow-based model of discrete data that provides the missing link in enabling flow-based generative models to be applied to multimodal continuous and discrete data problems. Our key insight is that the discrete equivalent of continuous space flow matching can be realized using Continuous Time Markov Chains. DFMs benefit from a simple derivation that includes discrete diffusion models as a specific instance while allowing improved performance over existing diffusion-based approaches. We utilize our DFMs method to build a multimodal flow-based modeling framework. We apply this capability to the task of protein co-design, wherein we learn a model for jointly generating protein structure and sequence. Our approach achieves state-of-the-art co-design performance while allowing the same multimodal model to be used for flexible generation of the sequence or str
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30740;&#31350;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#19968;&#27425;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#21518;&#30340;&#29305;&#24449;&#23398;&#20064;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#22312;&#39640;&#32500;&#26497;&#38480;&#19979;&#36890;&#29992;&#21270;&#35823;&#24046;&#30340;&#31934;&#30830;&#28176;&#36817;&#25551;&#36848;&#65292;&#24182;&#21457;&#29616;&#22312;&#36866;&#24212;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#32593;&#32476;&#33021;&#22815;&#39640;&#25928;&#22320;&#23398;&#20064;&#26799;&#24230;&#26041;&#21521;&#19978;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#12290;</title><link>https://arxiv.org/abs/2402.04980</link><description>&lt;p&gt;
&#19968;&#27425;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#21518;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#29305;&#24449;&#23398;&#20064;&#20013;&#30340;&#28176;&#36817;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
Asymptotics of feature learning in two-layer networks after one gradient-step
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04980
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30740;&#31350;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#19968;&#27425;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#21518;&#30340;&#29305;&#24449;&#23398;&#20064;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#22312;&#39640;&#32500;&#26497;&#38480;&#19979;&#36890;&#29992;&#21270;&#35823;&#24046;&#30340;&#31934;&#30830;&#28176;&#36817;&#25551;&#36848;&#65292;&#24182;&#21457;&#29616;&#22312;&#36866;&#24212;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#32593;&#32476;&#33021;&#22815;&#39640;&#25928;&#22320;&#23398;&#20064;&#26799;&#24230;&#26041;&#21521;&#19978;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#29305;&#24449;&#65292;&#24182;&#22312;&#20351;&#29992;&#21333;&#19968;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#35757;&#32451;&#21518;&#22914;&#20309;&#25913;&#36827;&#26680;&#24515;&#26041;&#27861;&#30340;&#38382;&#39064;&#12290;&#20511;&#21161;&#20110;&#65288;Ba et al., 2022&#65289;&#19982;&#38750;&#32447;&#24615;&#23574;&#23792;&#30697;&#38453;&#27169;&#22411;&#30340;&#20851;&#32852;&#20197;&#21450;&#23545;&#39640;&#26031;&#27867;&#21270;&#24615;&#30340;&#26368;&#26032;&#36827;&#23637;&#65288;Dandi et al., 2023&#65289;&#65292;&#25105;&#20204;&#22312;&#26679;&#26412;&#25968;$n$&#12289;&#23485;&#24230;$p$&#21644;&#36755;&#20837;&#32500;&#24230;$d$&#25104;&#27604;&#20363;&#22686;&#38271;&#30340;&#39640;&#32500;&#26497;&#38480;&#19979;&#65292;&#32473;&#20986;&#20102;&#19968;&#31181;&#31934;&#30830;&#30340;&#19968;&#33268;&#24615;&#35823;&#24046;&#25551;&#36848;&#12290;&#25105;&#20204;&#20934;&#30830;&#22320;&#21051;&#30011;&#20102;&#36866;&#24212;&#25968;&#25454;&#23545;&#20110;&#32593;&#32476;&#22312;&#26799;&#24230;&#26041;&#21521;&#19978;&#39640;&#25928;&#23398;&#20064;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#37325;&#35201;&#24615;&#8212;&#8212;&#22312;&#21021;&#22987;&#21270;&#38454;&#27573;&#65292;&#32593;&#32476;&#21482;&#33021;&#34920;&#36798;&#32447;&#24615;&#20989;&#25968;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#25552;&#20379;&#20102;&#22312;&#22823;&#23398;&#20064;&#29575;$\eta=\Theta_{d}(d)$&#30340;&#24773;&#20917;&#19979;&#29305;&#24449;&#23398;&#20064;&#23545;&#20110;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#30340;&#39318;&#20010;&#20934;&#30830;&#25551;&#36848;&#65292;&#36229;&#36234;&#20102;&#26680;&#24515;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this manuscript we investigate the problem of how two-layer neural networks learn features from data, and improve over the kernel regime, after being trained with a single gradient descent step. Leveraging a connection from (Ba et al., 2022) with a non-linear spiked matrix model and recent progress on Gaussian universality (Dandi et al., 2023), we provide an exact asymptotic description of the generalization error in the high-dimensional limit where the number of samples $n$, the width $p$ and the input dimension $d$ grow at a proportional rate. We characterize exactly how adapting to the data is crucial for the network to efficiently learn non-linear functions in the direction of the gradient -- where at initialization it can only express linear functions in this regime. To our knowledge, our results provides the first tight description of the impact of feature learning in the generalization of two-layer neural networks in the large learning rate regime $\eta=\Theta_{d}(d)$, beyond
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19977;&#20010;&#26032;&#30340;&#36317;&#31163;&#24230;&#37327;&#25351;&#26631;&#65288;s/c&#36317;&#31163;&#12289;&#39532;&#23572;&#31185;&#22827;&#36317;&#31163;&#21644;&#24544;&#23454;&#24230;&#36317;&#31163;&#65289;&#65292;&#29992;&#20110;&#35780;&#20272;&#22240;&#26524;&#25512;&#26029;&#31639;&#27861;&#30340;&#36755;&#20986;&#22270;&#19982;&#30495;&#23454;&#24773;&#20917;&#30340;&#20998;&#31163;/&#36830;&#25509;&#31243;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.04952</link><description>&lt;p&gt;
&#35780;&#20272;&#22240;&#26524;&#25512;&#26029;&#31639;&#27861;&#30340;&#39532;&#23572;&#31185;&#22827;&#31561;&#20215;&#31867;&#25351;&#26631;
&lt;/p&gt;
&lt;p&gt;
Metrics on Markov Equivalence Classes for Evaluating Causal Discovery Algorithms
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04952
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19977;&#20010;&#26032;&#30340;&#36317;&#31163;&#24230;&#37327;&#25351;&#26631;&#65288;s/c&#36317;&#31163;&#12289;&#39532;&#23572;&#31185;&#22827;&#36317;&#31163;&#21644;&#24544;&#23454;&#24230;&#36317;&#31163;&#65289;&#65292;&#29992;&#20110;&#35780;&#20272;&#22240;&#26524;&#25512;&#26029;&#31639;&#27861;&#30340;&#36755;&#20986;&#22270;&#19982;&#30495;&#23454;&#24773;&#20917;&#30340;&#20998;&#31163;/&#36830;&#25509;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#26368;&#20808;&#36827;&#30340;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#26088;&#22312;&#29983;&#25104;&#19968;&#20010;&#36755;&#20986;&#22270;&#65292;&#35813;&#22270;&#32534;&#30721;&#20102;&#29983;&#25104;&#25968;&#25454;&#36807;&#31243;&#30340;&#22240;&#26524;&#22270;&#30340;&#22270;&#24418;&#20998;&#31163;&#21644;&#36830;&#25509;&#38472;&#36848;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35748;&#20026;&#65292;&#23545;&#21512;&#25104;&#25968;&#25454;&#30340;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#36827;&#34892;&#35780;&#20272;&#24212;&#35813;&#21253;&#25324;&#20998;&#26512;&#35813;&#26041;&#27861;&#30340;&#36755;&#20986;&#19982;&#30495;&#23454;&#24773;&#20917;&#30340;&#20998;&#31163;/&#36830;&#25509;&#31243;&#24230;&#65292;&#20197;&#34913;&#37327;&#36825;&#19968;&#26126;&#30830;&#30446;&#26631;&#30340;&#23454;&#29616;&#24773;&#20917;&#12290;&#25105;&#20204;&#35777;&#26126;&#29616;&#26377;&#30340;&#35780;&#20272;&#25351;&#26631;&#19981;&#33021;&#20934;&#30830;&#25429;&#25417;&#21040;&#20004;&#20010;&#22240;&#26524;&#22270;&#30340;&#20998;&#31163;/&#36830;&#25509;&#24046;&#24322;&#65292;&#24182;&#24341;&#20837;&#20102;&#19977;&#20010;&#26032;&#30340;&#36317;&#31163;&#24230;&#37327;&#25351;&#26631;&#65292;&#21363;s/c&#36317;&#31163;&#12289;&#39532;&#23572;&#31185;&#22827;&#36317;&#31163;&#21644;&#24544;&#23454;&#24230;&#36317;&#31163;&#65292;&#20197;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#36890;&#36807;&#29609;&#20855;&#31034;&#20363;&#12289;&#23454;&#35777;&#23454;&#39564;&#21644;&#20266;&#20195;&#30721;&#26469;&#34917;&#20805;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many state-of-the-art causal discovery methods aim to generate an output graph that encodes the graphical separation and connection statements of the causal graph that underlies the data-generating process. In this work, we argue that an evaluation of a causal discovery method against synthetic data should include an analysis of how well this explicit goal is achieved by measuring how closely the separations/connections of the method's output align with those of the ground truth. We show that established evaluation measures do not accurately capture the difference in separations/connections of two causal graphs, and we introduce three new measures of distance called s/c-distance, Markov distance and Faithfulness distance that address this shortcoming. We complement our theoretical analysis with toy examples, empirical experiments and pseudocode.
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;Voronoi&#20505;&#36873;&#28857;&#36793;&#30028;&#21487;&#20197;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#26377;&#25928;&#22320;&#20248;&#21270;&#40657;&#30418;&#20989;&#25968;&#65292;&#25552;&#39640;&#20102;&#22810;&#36215;&#22987;&#36830;&#32493;&#25628;&#32034;&#30340;&#25191;&#34892;&#26102;&#38388;&#12290;</title><link>https://arxiv.org/abs/2402.04922</link><description>&lt;p&gt;
Voronoi Candidates&#29992;&#20110;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Voronoi Candidates for Bayesian Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04922
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;Voronoi&#20505;&#36873;&#28857;&#36793;&#30028;&#21487;&#20197;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#26377;&#25928;&#22320;&#20248;&#21270;&#40657;&#30418;&#20989;&#25968;&#65292;&#25552;&#39640;&#20102;&#22810;&#36215;&#22987;&#36830;&#32493;&#25628;&#32034;&#30340;&#25191;&#34892;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#20026;&#39640;&#25928;&#20248;&#21270;&#40657;&#30418;&#20989;&#25968;&#25552;&#20379;&#20102;&#19968;&#31181;&#20248;&#38597;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#37319;&#38598;&#20934;&#21017;&#38656;&#35201;&#36827;&#34892;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20869;&#37096;&#20248;&#21270;&#65292;&#36825;&#21487;&#33021;&#24341;&#36215;&#24456;&#22823;&#30340;&#24320;&#38144;&#12290;&#35768;&#22810;&#23454;&#38469;&#30340;BO&#26041;&#27861;&#65292;&#23588;&#20854;&#26159;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#19981;&#37319;&#29992;&#23545;&#37319;&#38598;&#20989;&#25968;&#36827;&#34892;&#24418;&#24335;&#21270;&#36830;&#32493;&#20248;&#21270;&#65292;&#32780;&#26159;&#22312;&#26377;&#38480;&#30340;&#31354;&#38388;&#22635;&#20805;&#20505;&#36873;&#38598;&#19978;&#36827;&#34892;&#31163;&#25955;&#25628;&#32034;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#35758;&#20351;&#29992;&#20505;&#36873;&#28857;&#65292;&#20854;&#20301;&#20110;&#24403;&#21069;&#35774;&#35745;&#28857;&#30340;Voronoi&#38262;&#23884;&#36793;&#30028;&#19978;&#65292;&#22240;&#27492;&#23427;&#20204;&#19982;&#20004;&#20010;&#25110;&#22810;&#20010;&#35774;&#35745;&#28857;&#31561;&#36317;&#31163;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#36890;&#36807;&#30452;&#25509;&#37319;&#26679;Voronoi&#36793;&#30028;&#32780;&#19981;&#26126;&#30830;&#29983;&#25104;&#38262;&#23884;&#30340;&#31574;&#30053;&#65292;&#20174;&#32780;&#36866;&#24212;&#39640;&#32500;&#24230;&#20013;&#30340;&#22823;&#35774;&#35745;&#12290;&#36890;&#36807;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#21644;&#26399;&#26395;&#25913;&#36827;&#26469;&#23545;&#19968;&#32452;&#27979;&#35797;&#38382;&#39064;&#36827;&#34892;&#20248;&#21270;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#19981;&#25439;&#22833;&#20934;&#30830;&#24615;&#30340;&#24773;&#20917;&#19979;&#26174;&#33879;&#25552;&#39640;&#20102;&#22810;&#36215;&#22987;&#36830;&#32493;&#25628;&#32034;&#30340;&#25191;&#34892;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization (BO) offers an elegant approach for efficiently optimizing black-box functions. However, acquisition criteria demand their own challenging inner-optimization, which can induce significant overhead. Many practical BO methods, particularly in high dimension, eschew a formal, continuous optimization of the acquisition function and instead search discretely over a finite set of space-filling candidates. Here, we propose to use candidates which lie on the boundary of the Voronoi tessellation of the current design points, so they are equidistant to two or more of them. We discuss strategies for efficient implementation by directly sampling the Voronoi boundary without explicitly generating the tessellation, thus accommodating large designs in high dimension. On a battery of test problems optimized via Gaussian processes with expected improvement, our proposed approach significantly improves the execution time of a multi-start continuous search without a loss in accuracy
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21363;&#19968;&#33268;&#24615;&#33945;&#29305;&#21345;&#27931;&#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#29992;&#20110;&#39044;&#27979;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#12290;&#36890;&#36807;&#21033;&#29992;&#19968;&#33268;&#24615;&#39044;&#27979;&#31995;&#32479;&#12289;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#21644;CATE&#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#29983;&#25104;&#21487;&#29992;&#20110;&#20010;&#24615;&#21270;&#20915;&#31574;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#35813;&#26041;&#27861;&#22312;&#20445;&#25345;&#36739;&#23567;&#21306;&#38388;&#23485;&#24230;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#24378;&#22823;&#30340;&#23454;&#39564;&#35206;&#30422;&#33539;&#22260;&#65292;&#21487;&#20197;&#25552;&#20379;&#30495;&#23454;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#30340;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2402.04906</link><description>&lt;p&gt;
&#39044;&#27979;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#30340;&#19968;&#33268;&#24615;&#33945;&#29305;&#21345;&#27931;&#20803;&#23398;&#20064;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Conformal Monte Carlo Meta-learners for Predictive Inference of Individual Treatment Effects
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04906
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21363;&#19968;&#33268;&#24615;&#33945;&#29305;&#21345;&#27931;&#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#29992;&#20110;&#39044;&#27979;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#12290;&#36890;&#36807;&#21033;&#29992;&#19968;&#33268;&#24615;&#39044;&#27979;&#31995;&#32479;&#12289;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#21644;CATE&#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#29983;&#25104;&#21487;&#29992;&#20110;&#20010;&#24615;&#21270;&#20915;&#31574;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#35813;&#26041;&#27861;&#22312;&#20445;&#25345;&#36739;&#23567;&#21306;&#38388;&#23485;&#24230;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#24378;&#22823;&#30340;&#23454;&#39564;&#35206;&#30422;&#33539;&#22260;&#65292;&#21487;&#20197;&#25552;&#20379;&#30495;&#23454;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35748;&#35782;&#24178;&#39044;&#25928;&#26524;&#65292;&#21363;&#27835;&#30103;&#25928;&#26524;&#65292;&#23545;&#20110;&#20915;&#31574;&#33267;&#20851;&#37325;&#35201;&#12290;&#29992;&#26465;&#20214;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524; (CATE) &#20272;&#35745;&#31561;&#26041;&#27861;&#36890;&#24120;&#21482;&#25552;&#20379;&#27835;&#30103;&#25928;&#26524;&#30340;&#28857;&#20272;&#35745;&#65292;&#32780;&#24120;&#24120;&#38656;&#35201;&#39069;&#22806;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#26041;&#27861;&#65292;&#21363;&#19968;&#33268;&#24615;&#33945;&#29305;&#21345;&#27931; (CMC) &#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#21033;&#29992;&#19968;&#33268;&#24615;&#39044;&#27979;&#31995;&#32479;&#12289;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#21644; CATE &#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#26469;&#20135;&#29983;&#21487;&#29992;&#20110;&#20010;&#24615;&#21270;&#20915;&#31574;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#32467;&#26524;&#22122;&#22768;&#20998;&#24067;&#30340;&#29305;&#23450;&#20551;&#35774;&#22914;&#20309;&#20005;&#37325;&#24433;&#21709;&#36825;&#20123;&#19981;&#30830;&#23450;&#24615;&#39044;&#27979;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;CMC&#26694;&#26550;&#23637;&#31034;&#20102;&#24378;&#22823;&#30340;&#23454;&#39564;&#35206;&#30422;&#33539;&#22260;&#65292;&#21516;&#26102;&#20445;&#25345;&#36739;&#23567;&#30340;&#21306;&#38388;&#23485;&#24230;&#65292;&#20197;&#25552;&#20379;&#30495;&#23454;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge of the effect of interventions, called the treatment effect, is paramount for decision-making. Approaches to estimating this treatment effect, e.g. by using Conditional Average Treatment Effect (CATE) estimators, often only provide a point estimate of this treatment effect, while additional uncertainty quantification is frequently desired instead. Therefore, we present a novel method, the Conformal Monte Carlo (CMC) meta-learners, leveraging conformal predictive systems, Monte Carlo sampling, and CATE meta-learners, to instead produce a predictive distribution usable in individualized decision-making. Furthermore, we show how specific assumptions on the noise distribution of the outcome heavily affect these uncertainty predictions. Nonetheless, the CMC framework shows strong experimental coverage while retaining small interval widths to provide estimates of the true individual treatment effect.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#20998;&#25903;&#21644;&#23884;&#22871;&#21442;&#25968;&#20043;&#38388;&#30340;&#26465;&#20214;&#20381;&#36182;&#20851;&#31995;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#20248;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#36229;&#21442;&#25968;&#36873;&#25321;&#21644;&#35843;&#25972;&#12290;</title><link>https://arxiv.org/abs/2402.04885</link><description>&lt;p&gt;
&#19968;&#20010;&#32479;&#19968;&#30340;&#39640;&#26031;&#36807;&#31243;&#29992;&#20110;&#20998;&#25903;&#21644;&#23884;&#22871;&#36229;&#21442;&#25968;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
A Unified Gaussian Process for Branching and Nested Hyperparameter Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04885
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#20998;&#25903;&#21644;&#23884;&#22871;&#21442;&#25968;&#20043;&#38388;&#30340;&#26465;&#20214;&#20381;&#36182;&#20851;&#31995;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#20248;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#36229;&#21442;&#25968;&#36873;&#25321;&#21644;&#35843;&#25972;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31070;&#32463;&#32593;&#32476;&#30340;&#25104;&#21151;&#20013;&#65292;&#36873;&#25321;&#21512;&#36866;&#30340;&#36229;&#21442;&#25968;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#22240;&#20026;&#36229;&#21442;&#25968;&#30452;&#25509;&#25511;&#21046;&#35757;&#32451;&#31639;&#27861;&#30340;&#34892;&#20026;&#21644;&#24615;&#33021;&#12290;&#20026;&#20102;&#33719;&#24471;&#39640;&#25928;&#30340;&#35843;&#21442;&#65292;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#34987;&#24191;&#27867;&#24212;&#29992;&#12290;&#23613;&#31649;&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#20855;&#26377;&#35768;&#22810;&#24212;&#29992;&#65292;&#20294;&#29616;&#26377;&#30340;&#26041;&#27861;&#37117;&#22522;&#20110;&#19968;&#20010;&#26041;&#20415;&#20294;&#38480;&#21046;&#24615;&#30340;&#20551;&#35774;&#65292;&#21363;&#35843;&#21442;&#21442;&#25968;&#24444;&#27492;&#29420;&#31435;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#26465;&#20214;&#20381;&#36182;&#30340;&#35843;&#21442;&#21442;&#25968;&#26159;&#24120;&#35265;&#30340;&#12290;&#26412;&#25991;&#37325;&#28857;&#30740;&#31350;&#20102;&#20004;&#31181;&#31867;&#22411;&#30340;&#35843;&#21442;&#21442;&#25968;&#65306;&#20998;&#25903;&#21644;&#23884;&#22871;&#21442;&#25968;&#12290;&#23884;&#22871;&#21442;&#25968;&#25351;&#30340;&#26159;&#37027;&#20123;&#20165;&#23384;&#22312;&#20110;&#21478;&#19968;&#20010;&#35843;&#21442;&#21442;&#25968;&#29305;&#23450;&#35774;&#32622;&#20013;&#30340;&#35843;&#21442;&#21442;&#25968;&#65292;&#32780;&#20854;&#23427;&#21442;&#25968;&#22312;&#20854;&#20013;&#23884;&#22871;&#30340;&#21442;&#25968;&#31216;&#20026;&#20998;&#25903;&#21442;&#25968;&#12290;&#20026;&#20102;&#25429;&#25417;&#20998;&#25903;&#21644;&#23884;&#22871;&#21442;&#25968;&#20043;&#38388;&#30340;&#26465;&#20214;&#20381;&#36182;&#20851;&#31995;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Choosing appropriate hyperparameters plays a crucial role in the success of neural networks as hyper-parameters directly control the behavior and performance of the training algorithms. To obtain efficient tuning, Bayesian optimization methods based on Gaussian process (GP) models are widely used. Despite numerous applications of Bayesian optimization in deep learning, the existing methodologies are developed based on a convenient but restrictive assumption that the tuning parameters are independent of each other. However, tuning parameters with conditional dependence are common in practice. In this paper, we focus on two types of them: branching and nested parameters. Nested parameters refer to those tuning parameters that exist only within a particular setting of another tuning parameter, and a parameter within which other parameters are nested is called a branching parameter. To capture the conditional dependence between branching and nested parameters, a unified Bayesian optimizati
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#21253;&#25324;&#28145;&#24230;&#38598;&#21512;&#12289;&#21464;&#21387;&#22120;&#12289;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21644;&#31616;&#21333;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#31561;&#22810;&#31181;&#26550;&#26500;&#65292;&#25506;&#32034;&#20102;&#21487;&#35777;&#26126;&#30340;&#38271;&#24230;&#21644;&#32452;&#21512;&#27867;&#21270;&#65292;&#35748;&#20026;&#23545;&#20110;&#38271;&#24230;&#21644;&#32452;&#21512;&#27867;&#21270;&#65292;&#19981;&#21516;&#26550;&#26500;&#38656;&#35201;&#19981;&#21516;&#31243;&#24230;&#30340;&#34920;&#31034;&#35782;&#21035;&#12290;</title><link>https://arxiv.org/abs/2402.04875</link><description>&lt;p&gt;
&#20851;&#20110;&#21487;&#35777;&#26126;&#30340;&#38271;&#24230;&#21644;&#32452;&#21512;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
On Provable Length and Compositional Generalization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04875
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#21253;&#25324;&#28145;&#24230;&#38598;&#21512;&#12289;&#21464;&#21387;&#22120;&#12289;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21644;&#31616;&#21333;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#31561;&#22810;&#31181;&#26550;&#26500;&#65292;&#25506;&#32034;&#20102;&#21487;&#35777;&#26126;&#30340;&#38271;&#24230;&#21644;&#32452;&#21512;&#27867;&#21270;&#65292;&#35748;&#20026;&#23545;&#20110;&#38271;&#24230;&#21644;&#32452;&#21512;&#27867;&#21270;&#65292;&#19981;&#21516;&#26550;&#26500;&#38656;&#35201;&#19981;&#21516;&#31243;&#24230;&#30340;&#34920;&#31034;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38271;&#24230;&#27867;&#21270;&#8212;&#8212;&#23545;&#35757;&#32451;&#26102;&#26410;&#35265;&#21040;&#30340;&#26356;&#38271;&#24207;&#21015;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#20197;&#21450;&#32452;&#21512;&#27867;&#21270;&#8212;&#8212;&#23545;&#35757;&#32451;&#26102;&#26410;&#35265;&#21040;&#30340;&#20196;&#29260;&#32452;&#21512;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#22312;&#24207;&#21015;&#21040;&#24207;&#21015;&#27169;&#22411;&#20013;&#26159;&#37325;&#35201;&#30340;&#38750;&#20998;&#24067;&#21270;&#27867;&#21270;&#24418;&#24335;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#22312;&#21253;&#25324;&#28145;&#24230;&#38598;&#21512;&#12289;&#21464;&#21387;&#22120;&#12289;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21644;&#31616;&#21333;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#22312;&#20869;&#30340;&#19968;&#31995;&#21015;&#26550;&#26500;&#20013;&#65292;&#26397;&#30528;&#21487;&#35777;&#26126;&#30340;&#38271;&#24230;&#21644;&#32452;&#21512;&#27867;&#21270;&#36808;&#20986;&#20102;&#31532;&#19968;&#27493;&#12290;&#26681;&#25454;&#26550;&#26500;&#30340;&#19981;&#21516;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19981;&#21516;&#31243;&#24230;&#30340;&#34920;&#31034;&#35782;&#21035;&#30340;&#24517;&#35201;&#24615;&#65292;&#20363;&#22914;&#19982;&#30495;&#23454;&#34920;&#31034;&#20855;&#26377;&#32447;&#24615;&#25110;&#25490;&#21015;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Length generalization -- the ability to generalize to longer sequences than ones seen during training, and compositional generalization -- the ability to generalize to token combinations not seen during training, are crucial forms of out-of-distribution generalization in sequence-to-sequence models. In this work, we take the first steps towards provable length and compositional generalization for a range of architectures, including deep sets, transformers, state space models, and simple recurrent neural nets. Depending on the architecture, we prove different degrees of representation identification, e.g., a linear or a permutation relation with ground truth representation, is necessary for length and compositional generalization.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24471;&#20998;&#30340;&#24555;&#36895;&#25628;&#32034;&#31639;&#27861;&#65292;&#29992;&#20110;&#20351;&#29992;&#29109;&#30340;&#26368;&#22823;&#31062;&#20808;&#22270;&#12290;&#36890;&#36807;&#24341;&#20837;imsets&#26694;&#26550;&#21644;&#31934;&#21270;&#39532;&#23572;&#31185;&#22827;&#23646;&#24615;&#65292;&#25105;&#20204;&#25913;&#36827;&#20102;MAG&#30340;&#35780;&#20998;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#25628;&#32034;&#31639;&#27861;&#30340;&#22810;&#39033;&#24335;&#22797;&#26434;&#24230;&#12290;&#22312;&#27169;&#25311;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#34920;&#29616;&#20986;&#20102;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.04777</link><description>&lt;p&gt;
&#22522;&#20110;&#24471;&#20998;&#30340;&#24555;&#36895;&#25628;&#32034;&#31639;&#27861;&#22312;&#20351;&#29992;&#29109;&#30340;&#26368;&#22823;&#31062;&#20808;&#22270;&#20013;
&lt;/p&gt;
&lt;p&gt;
A fast score-based search algorithm for maximal ancestral graphs using entropy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04777
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24471;&#20998;&#30340;&#24555;&#36895;&#25628;&#32034;&#31639;&#27861;&#65292;&#29992;&#20110;&#20351;&#29992;&#29109;&#30340;&#26368;&#22823;&#31062;&#20808;&#22270;&#12290;&#36890;&#36807;&#24341;&#20837;imsets&#26694;&#26550;&#21644;&#31934;&#21270;&#39532;&#23572;&#31185;&#22827;&#23646;&#24615;&#65292;&#25105;&#20204;&#25913;&#36827;&#20102;MAG&#30340;&#35780;&#20998;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#25628;&#32034;&#31639;&#27861;&#30340;&#22810;&#39033;&#24335;&#22797;&#26434;&#24230;&#12290;&#22312;&#27169;&#25311;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#34920;&#29616;&#20986;&#20102;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#22823;&#31062;&#20808;&#22270;&#65288;MAGs&#65289;&#26159;&#19968;&#31867;&#22312;&#23384;&#22312;&#28508;&#22312;&#28151;&#26434;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#25193;&#23637;&#20102;&#33879;&#21517;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#30340;&#22270;&#27169;&#22411;&#12290;&#22823;&#22810;&#25968;&#22522;&#20110;&#35780;&#20998;&#30340;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;BIC&#35780;&#20998;&#20174;&#32463;&#39564;&#25968;&#25454;&#20013;&#25512;&#26029;&#26410;&#30693;MAG&#65292;&#20294;&#35813;&#26041;&#27861;&#23384;&#22312;&#19981;&#31283;&#23450;&#24615;&#21644;&#35745;&#31639;&#22797;&#26434;&#24615;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;imsets&#26694;&#26550;&#36890;&#36807;&#32463;&#39564;&#29109;&#20272;&#35745;&#21644;&#26032;&#25552;&#20986;&#30340;&#31934;&#21270;&#39532;&#23572;&#31185;&#22827;&#23646;&#24615;&#23545;MAG&#36827;&#34892;&#35780;&#20998;&#12290;&#25105;&#20204;&#30340;&#22270;&#25628;&#32034;&#36807;&#31243;&#19982;\citet{claassen2022greedy}&#31867;&#20284;&#65292;&#20294;&#26159;&#26681;&#25454;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#36827;&#34892;&#20102;&#25913;&#36827;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#25628;&#32034;&#31639;&#27861;&#22312;&#33410;&#28857;&#25968;&#19978;&#26159;&#22810;&#39033;&#24335;&#22797;&#26434;&#24230;&#30340;&#65292;&#36890;&#36807;&#38480;&#21046;&#24230;&#25968;&#12289;&#26368;&#22823;&#22836;&#37096;&#22823;&#23567;&#21644;&#27495;&#35270;&#36335;&#24452;&#25968;&#12290;&#22312;&#27169;&#25311;&#23454;&#39564;&#20013;&#65292;&#19982;&#20854;&#20182;&#29616;&#26377;&#30340;MAG&#23398;&#20064;&#31639;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#34920;&#29616;&#20986;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
\emph{Maximal ancestral graph} (MAGs) is a class of graphical model that extend the famous \emph{directed acyclic graph} in the presence of latent confounders. Most score-based approaches to learn the unknown MAG from empirical data rely on BIC score which suffers from instability and heavy computations. We propose to use the framework of imsets \citep{studeny2006probabilistic} to score MAGs using empirical entropy estimation and the newly proposed \emph{refined Markov property} \citep{hu2023towards}. Our graphical search procedure is similar to \citet{claassen2022greedy} but improved from our theoretical results. We show that our search algorithm is polynomial in number of nodes by restricting degree, maximal head size and number of discriminating paths. In simulated experiment, our algorithm shows superior performance compared to other state of art MAG learning algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20132;&#26367;&#26497;&#23567;&#21270;&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#28176;&#36817;&#21160;&#21147;&#23398;&#29305;&#24615;&#65292;&#36890;&#36807;&#22797;&#21046;&#26041;&#27861;&#36861;&#36394;&#28436;&#21270;&#36807;&#31243;&#65292;&#21457;&#29616;&#20854;&#21487;&#29992;&#20108;&#32500;&#31163;&#25955;&#38543;&#26426;&#36807;&#31243;&#26377;&#25928;&#25551;&#36848;&#65292;&#23384;&#22312;&#35760;&#24518;&#20381;&#36182;&#24615;&#12290;&#35813;&#29702;&#35770;&#26694;&#26550;&#36866;&#29992;&#20110;&#20998;&#26512;&#21508;&#31181;&#36845;&#20195;&#31639;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.04751</link><description>&lt;p&gt;
&#38750;&#20984;&#20248;&#21270;&#20013;Alternating Minimization&#30340;&#28176;&#36817;&#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
Asymptotic Dynamics of Alternating Minimization for Non-Convex Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04751
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20132;&#26367;&#26497;&#23567;&#21270;&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#28176;&#36817;&#21160;&#21147;&#23398;&#29305;&#24615;&#65292;&#36890;&#36807;&#22797;&#21046;&#26041;&#27861;&#36861;&#36394;&#28436;&#21270;&#36807;&#31243;&#65292;&#21457;&#29616;&#20854;&#21487;&#29992;&#20108;&#32500;&#31163;&#25955;&#38543;&#26426;&#36807;&#31243;&#26377;&#25928;&#25551;&#36848;&#65292;&#23384;&#22312;&#35760;&#24518;&#20381;&#36182;&#24615;&#12290;&#35813;&#29702;&#35770;&#26694;&#26550;&#36866;&#29992;&#20110;&#20998;&#26512;&#21508;&#31181;&#36845;&#20195;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#20855;&#26377;&#27491;&#24577;&#20998;&#24067;&#21327;&#21464;&#37327;&#30340;&#21452;&#32447;&#24615;&#38750;&#20984;&#20989;&#25968;&#20248;&#21270;&#20013;&#24212;&#29992;&#20132;&#26367;&#26497;&#23567;&#21270;&#30340;&#28176;&#36817;&#21160;&#21147;&#23398;&#12290;&#25105;&#20204;&#37319;&#29992;&#32479;&#35745;&#29289;&#29702;&#23398;&#20013;&#30340;&#22797;&#21046;&#26041;&#27861;&#65292;&#36890;&#36807;&#22810;&#27493;&#26041;&#27861;&#31934;&#30830;&#36861;&#36394;&#31639;&#27861;&#30340;&#28436;&#21464;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#21160;&#21147;&#23398;&#21487;&#20197;&#26377;&#25928;&#22320;&#29992;&#19968;&#20010;&#20108;&#32500;&#31163;&#25955;&#38543;&#26426;&#36807;&#31243;&#26469;&#25551;&#36848;&#65292;&#27599;&#19968;&#27493;&#37117;&#20381;&#36182;&#20110;&#25152;&#26377;&#20808;&#21069;&#30340;&#26102;&#38388;&#27493;&#38271;&#65292;&#25581;&#31034;&#20102;&#36807;&#31243;&#20013;&#30340;&#35760;&#24518;&#20381;&#36182;&#24615;&#12290;&#26412;&#25991;&#24320;&#21457;&#30340;&#29702;&#35770;&#26694;&#26550;&#24191;&#27867;&#36866;&#29992;&#20110;&#21508;&#31181;&#36845;&#20195;&#31639;&#27861;&#30340;&#20998;&#26512;&#65292;&#36229;&#36234;&#20102;&#20132;&#26367;&#26497;&#23567;&#21270;&#30340;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study investigates the asymptotic dynamics of alternating minimization applied to optimize a bilinear non-convex function with normally distributed covariates. We employ the replica method from statistical physics in a multi-step approach to precisely trace the algorithm's evolution. Our findings indicate that the dynamics can be described effectively by a two--dimensional discrete stochastic process, where each step depends on all previous time steps, revealing a memory dependency in the procedure. The theoretical framework developed in this work is broadly applicable for the analysis of various iterative algorithms, extending beyond the scope of alternating minimization.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#20272;&#35745;&#26631;&#35760;Hawkes&#36807;&#31243;&#26465;&#20214;&#24378;&#24230;&#30340;&#26041;&#27861;&#65292;&#24341;&#20837;&#20102;&#20004;&#31181;&#27169;&#22411;&#26469;&#22788;&#29702;&#20855;&#26377;&#19981;&#21516;&#20869;&#26680;&#21644;&#38750;&#32447;&#24615;&#29305;&#24449;&#30340;Hawkes&#36807;&#31243;&#65292;&#36890;&#36807;&#23558;&#36807;&#21435;&#30340;&#21040;&#36798;&#26102;&#38388;&#21644;&#26631;&#35760;&#20316;&#20026;&#36755;&#20837;&#65292;&#33719;&#24471;&#21040;&#36798;&#24378;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.04740</link><description>&lt;p&gt;
&#22810;&#32500;&#26631;&#35760;Hawkes&#36807;&#31243;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Non-Parametric Estimation of Multi-dimensional Marked Hawkes Processes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04740
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#20272;&#35745;&#26631;&#35760;Hawkes&#36807;&#31243;&#26465;&#20214;&#24378;&#24230;&#30340;&#26041;&#27861;&#65292;&#24341;&#20837;&#20102;&#20004;&#31181;&#27169;&#22411;&#26469;&#22788;&#29702;&#20855;&#26377;&#19981;&#21516;&#20869;&#26680;&#21644;&#38750;&#32447;&#24615;&#29305;&#24449;&#30340;Hawkes&#36807;&#31243;&#65292;&#36890;&#36807;&#23558;&#36807;&#21435;&#30340;&#21040;&#36798;&#26102;&#38388;&#21644;&#26631;&#35760;&#20316;&#20026;&#36755;&#20837;&#65292;&#33719;&#24471;&#21040;&#36798;&#24378;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#35760;Hawkes&#36807;&#31243;&#26159;Hawkes&#36807;&#31243;&#30340;&#19968;&#20010;&#25193;&#23637;&#65292;&#20854;&#29305;&#28857;&#26159;&#27599;&#20010;&#20107;&#20214;&#30340;&#36339;&#36291;&#22823;&#23567;&#19981;&#21516;&#65292;&#19982;&#27809;&#26377;&#26631;&#35760;&#30340;Hawkes&#36807;&#31243;&#20013;&#35266;&#23519;&#21040;&#30340;&#24658;&#23450;&#36339;&#36291;&#22823;&#23567;&#19981;&#21516;&#12290;&#23613;&#31649;&#22312;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;Hawkes&#36807;&#31243;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;&#19978;&#24050;&#32463;&#26377;&#20102;&#24191;&#27867;&#30340;&#25991;&#29486;&#65292;&#20294;&#22312;&#26631;&#35760;Hawkes&#36807;&#31243;&#26041;&#38754;&#30340;&#25991;&#29486;&#20173;&#23384;&#22312;&#37325;&#22823;&#31354;&#30333;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20272;&#35745;&#26631;&#35760;Hawkes&#36807;&#31243;&#26465;&#20214;&#24378;&#24230;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#20010;&#19981;&#21516;&#30340;&#27169;&#22411;&#65306;&#8220;&#20855;&#26377;&#26631;&#35760;&#30340;&#27973;&#23618;&#31070;&#32463;Hawkes&#27169;&#22411;&#8221;-&#29992;&#20110;&#20855;&#26377;&#20852;&#22859;&#24615;&#20869;&#26680;&#30340;Hawkes&#36807;&#31243;&#65292;&#20197;&#21450;&#8220;&#38750;&#32447;&#24615;Hawkes&#20855;&#26377;&#26631;&#35760;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#8221;-&#29992;&#20110;&#38750;&#32447;&#24615;Hawkes&#36807;&#31243;&#12290;&#36825;&#20004;&#31181;&#26041;&#27861;&#23558;&#36807;&#21435;&#30340;&#21040;&#36798;&#26102;&#38388;&#21450;&#20854;&#30456;&#24212;&#30340;&#26631;&#35760;&#20316;&#20026;&#36755;&#20837;&#65292;&#20197;&#33719;&#21462;&#21040;&#36798;&#24378;&#24230;&#12290;&#36825;&#31181;&#26041;&#27861;&#26159;&#23436;&#20840;&#38750;&#21442;&#25968;&#30340;&#65292;&#20445;&#25345;&#20102;&#26631;&#35760;Hawkes&#36807;&#31243;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
An extension of the Hawkes process, the Marked Hawkes process distinguishes itself by featuring variable jump size across each event, in contrast to the constant jump size observed in a Hawkes process without marks. While extensive literature has been dedicated to the non-parametric estimation of both the linear and non-linear Hawkes process, there remains a significant gap in the literature regarding the marked Hawkes process. In response to this, we propose a methodology for estimating the conditional intensity of the marked Hawkes process. We introduce two distinct models: \textit{Shallow Neural Hawkes with marks}- for Hawkes processes with excitatory kernels and \textit{Neural Network for Non-Linear Hawkes with Marks}- for non-linear Hawkes processes. Both these approaches take the past arrival times and their corresponding marks as the input to obtain the arrival intensity. This approach is entirely non-parametric, preserving the interpretability associated with the marked Hawkes 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#30456;&#20851;&#20998;&#37327;&#30340;&#35299;&#37322;&#26041;&#24046;&#21040;&#26080;&#27491;&#20132;&#32422;&#26463;&#30340;&#20027;&#25104;&#20998;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#34913;&#37327;&#25968;&#25454;&#30697;&#38453;A&#20013;&#30001;&#30456;&#20851;&#20998;&#37327;Y = AZ&#35299;&#37322;&#30340;&#26041;&#24046;&#37096;&#20998;&#30340;&#26032;&#30446;&#26631;&#20989;&#25968;expvar(Y)&#65292;&#25918;&#26494;&#20102;&#21152;&#36733;&#30340;&#27491;&#20132;&#32422;&#26463;&#12290;</title><link>https://arxiv.org/abs/2402.04692</link><description>&lt;p&gt;
&#20174;&#30456;&#20851;&#20998;&#37327;&#30340;&#35299;&#37322;&#26041;&#24046;&#21040;&#26080;&#27491;&#20132;&#32422;&#26463;&#30340;&#20027;&#25104;&#20998;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
From explained variance of correlated components to PCA without orthogonality constraints
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04692
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#30456;&#20851;&#20998;&#37327;&#30340;&#35299;&#37322;&#26041;&#24046;&#21040;&#26080;&#27491;&#20132;&#32422;&#26463;&#30340;&#20027;&#25104;&#20998;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#34913;&#37327;&#25968;&#25454;&#30697;&#38453;A&#20013;&#30001;&#30456;&#20851;&#20998;&#37327;Y = AZ&#35299;&#37322;&#30340;&#26041;&#24046;&#37096;&#20998;&#30340;&#26032;&#30446;&#26631;&#20989;&#25968;expvar(Y)&#65292;&#25918;&#26494;&#20102;&#21152;&#36733;&#30340;&#27491;&#20132;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#25968;&#25454;&#30697;&#38453;A&#30340;&#22359;&#29366;&#20027;&#25104;&#20998;&#20998;&#26512;(Block PCA)&#20013;&#30340;&#21152;&#36733;Z&#30001;&#20110;&#22312;&#21333;&#20301;&#33539;&#25968;&#27491;&#20132;&#21152;&#36733;&#19978;&#26368;&#22823;&#21270;AZ&#30340;&#22256;&#38590;&#65292;&#20351;&#24471;&#20351;&#29992;1&#27491;&#21017;&#21270;&#26469;&#35774;&#35745;&#31232;&#30095;PCA&#21464;&#24471;&#22256;&#38590;&#65292;&#22240;&#20026;&#24456;&#38590;&#21516;&#26102;&#22788;&#29702;&#21152;&#36733;&#30340;&#27491;&#20132;&#32422;&#26463;&#21644;&#19981;&#21487;&#24494;&#30340;1&#24809;&#32602;&#12290;&#26412;&#25991;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#24341;&#20837;&#34913;&#37327;&#25968;&#25454;&#30697;&#38453;A&#20013;&#30001;&#30456;&#20851;&#20998;&#37327;Y = AZ&#35299;&#37322;&#30340;&#26041;&#24046;&#37096;&#20998;&#30340;&#26032;&#30446;&#26631;&#20989;&#25968;expvar(Y)&#26469;&#25918;&#26494;&#21152;&#36733;&#30340;&#27491;&#20132;&#32422;&#26463;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#39318;&#20808;&#23545;&#20004;&#20010;&#29616;&#26377;&#23450;&#20041;Zou et al. [2006]&#21644;Shen and Huang [2008]&#30340;expvar(Y)&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#25968;&#23398;&#21644;&#25968;&#20540;&#23646;&#24615;&#30740;&#31350;&#65292;&#24182;&#25552;&#20986;&#20102;&#22235;&#20010;&#26032;&#30340;&#23450;&#20041;&#12290;&#28982;&#21518;&#25105;&#20204;&#35777;&#26126;&#21482;&#26377;&#36825;&#20004;&#20010;&#35299;&#37322;&#26041;&#24046;&#25165;&#36866;&#21512;&#20316;&#20026;&#22359;&#29366;PCA&#24418;&#24335;&#20013;&#21435;&#38500;&#27491;&#20132;&#32422;&#26463;&#30340;&#30446;&#26631;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Block Principal Component Analysis (Block PCA) of a data matrix A, where loadings Z are determined by maximization of AZ 2 over unit norm orthogonal loadings, is difficult to use for the design of sparse PCA by 1 regularization, due to the difficulty of taking care of both the orthogonality constraint on loadings and the non differentiable 1 penalty. Our objective in this paper is to relax the orthogonality constraint on loadings by introducing new objective functions expvar(Y) which measure the part of the variance of the data matrix A explained by correlated components Y = AZ. So we propose first a comprehensive study of mathematical and numerical properties of expvar(Y) for two existing definitions Zou et al. [2006], Shen and Huang [2008] and four new definitions. Then we show that only two of these explained variance are fit to use as objective function in block PCA formulations for A rid of orthogonality constraints.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22312;&#19968;&#33324;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#23398;&#20064;&#31639;&#23376;&#65292;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#30446;&#26631;&#31639;&#23376;&#30340;&#35268;&#21017;&#26465;&#20214;&#65292;&#24182;&#24314;&#31435;&#20102;SGD&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#19978;&#30028;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#23545;&#20110;&#38750;&#32447;&#24615;&#31639;&#23376;&#23398;&#20064;&#30340;&#26377;&#25928;&#24615;&#21450;&#32447;&#24615;&#36817;&#20284;&#25910;&#25947;&#29305;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.04691</link><description>&lt;p&gt;
&#22312;&#19968;&#33324;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#31639;&#23376;
&lt;/p&gt;
&lt;p&gt;
Learning Operators with Stochastic Gradient Descent in General Hilbert Spaces
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04691
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#19968;&#33324;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#23398;&#20064;&#31639;&#23376;&#65292;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#30446;&#26631;&#31639;&#23376;&#30340;&#35268;&#21017;&#26465;&#20214;&#65292;&#24182;&#24314;&#31435;&#20102;SGD&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#19978;&#30028;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#23545;&#20110;&#38750;&#32447;&#24615;&#31639;&#23376;&#23398;&#20064;&#30340;&#26377;&#25928;&#24615;&#21450;&#32447;&#24615;&#36817;&#20284;&#25910;&#25947;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#21033;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#22312;&#19968;&#33324;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#23398;&#20064;&#31639;&#23376;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#38024;&#23545;&#30446;&#26631;&#31639;&#23376;&#30340;&#24369;&#21644;&#24378;&#35268;&#21017;&#26465;&#20214;&#65292;&#20197;&#25551;&#36848;&#20854;&#20869;&#22312;&#32467;&#26500;&#21644;&#22797;&#26434;&#24615;&#12290;&#22312;&#36825;&#20123;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;SGD&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#30340;&#19978;&#30028;&#65292;&#24182;&#36827;&#34892;&#20102;&#26497;&#23567;&#20540;&#19979;&#30028;&#20998;&#26512;&#65292;&#36827;&#19968;&#27493;&#35828;&#26126;&#25105;&#20204;&#30340;&#25910;&#25947;&#20998;&#26512;&#21644;&#35268;&#21017;&#26465;&#20214;&#23450;&#37327;&#22320;&#21051;&#30011;&#20102;&#20351;&#29992;SGD&#31639;&#27861;&#35299;&#20915;&#31639;&#23376;&#23398;&#20064;&#38382;&#39064;&#30340;&#21487;&#34892;&#24615;&#12290;&#20540;&#24471;&#24378;&#35843;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#25910;&#25947;&#20998;&#26512;&#23545;&#20110;&#38750;&#32447;&#24615;&#31639;&#23376;&#23398;&#20064;&#20173;&#28982;&#26377;&#25928;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;SGD&#20272;&#35745;&#22120;&#23558;&#25910;&#25947;&#20110;&#38750;&#32447;&#24615;&#30446;&#26631;&#31639;&#23376;&#30340;&#26368;&#20339;&#32447;&#24615;&#36817;&#20284;&#12290;&#27492;&#22806;&#65292;&#23558;&#25105;&#20204;&#30340;&#20998;&#26512;&#24212;&#29992;&#20110;&#22522;&#20110;&#30690;&#37327;&#20540;&#21644;&#23454;&#20540;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;&#31639;&#23376;&#23398;&#20064;&#38382;&#39064;&#65292;&#20135;&#29983;&#20102;&#26032;&#30340;&#25910;&#25947;&#32467;&#26524;&#65292;&#20174;&#32780;&#23436;&#21892;&#20102;&#29616;&#26377;&#25991;&#29486;&#30340;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study investigates leveraging stochastic gradient descent (SGD) to learn operators between general Hilbert spaces. We propose weak and strong regularity conditions for the target operator to depict its intrinsic structure and complexity. Under these conditions, we establish upper bounds for convergence rates of the SGD algorithm and conduct a minimax lower bound analysis, further illustrating that our convergence analysis and regularity conditions quantitatively characterize the tractability of solving operator learning problems using the SGD algorithm. It is crucial to highlight that our convergence analysis is still valid for nonlinear operator learning. We show that the SGD estimator will converge to the best linear approximation of the nonlinear target operator. Moreover, applying our analysis to operator learning problems based on vector-valued and real-valued reproducing kernel Hilbert spaces yields new convergence results, thereby refining the conclusions of existing litera
&lt;/p&gt;</description></item><item><title>Stein Boltzmann&#25277;&#26679;&#65288;SBS&#65289;&#26159;&#19968;&#31181;&#20840;&#23616;&#20248;&#21270;&#30340;&#21464;&#20998;&#26041;&#27861;&#65292;&#36890;&#36807;&#20174;Boltzmann&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#30001;Stein Variational Gradient Descent&#31639;&#27861;&#23454;&#29616;&#65292;&#20855;&#26377;&#28176;&#36817;&#25910;&#25947;&#24615;&#65292;&#24182;&#22312;&#21508;&#31181;&#22522;&#20934;&#20989;&#25968;&#19978;&#27604;&#36739;&#20102;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;&#20840;&#23616;&#20248;&#21270;&#31639;&#27861;&#65292;&#23588;&#20854;&#36866;&#21512;&#20316;&#20026;&#39640;&#25928;&#20840;&#23616;&#20248;&#21270;&#26041;&#27861;&#30340;&#24310;&#32493;&#65292;&#33021;&#22815;&#20135;&#29983;&#26356;&#22909;&#30340;&#35299;&#20915;&#26041;&#26696;&#24182;&#26377;&#25928;&#21033;&#29992;&#39044;&#31639;&#12290;</title><link>https://arxiv.org/abs/2402.04689</link><description>&lt;p&gt;
Stein Boltzmann&#25277;&#26679;&#65306;&#19968;&#31181;&#20840;&#23616;&#20248;&#21270;&#30340;&#21464;&#20998;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Stein Boltzmann Sampling: A Variational Approach for Global Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04689
&lt;/p&gt;
&lt;p&gt;
Stein Boltzmann&#25277;&#26679;&#65288;SBS&#65289;&#26159;&#19968;&#31181;&#20840;&#23616;&#20248;&#21270;&#30340;&#21464;&#20998;&#26041;&#27861;&#65292;&#36890;&#36807;&#20174;Boltzmann&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#30001;Stein Variational Gradient Descent&#31639;&#27861;&#23454;&#29616;&#65292;&#20855;&#26377;&#28176;&#36817;&#25910;&#25947;&#24615;&#65292;&#24182;&#22312;&#21508;&#31181;&#22522;&#20934;&#20989;&#25968;&#19978;&#27604;&#36739;&#20102;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;&#20840;&#23616;&#20248;&#21270;&#31639;&#27861;&#65292;&#23588;&#20854;&#36866;&#21512;&#20316;&#20026;&#39640;&#25928;&#20840;&#23616;&#20248;&#21270;&#26041;&#27861;&#30340;&#24310;&#32493;&#65292;&#33021;&#22815;&#20135;&#29983;&#26356;&#22909;&#30340;&#35299;&#20915;&#26041;&#26696;&#24182;&#26377;&#25928;&#21033;&#29992;&#39044;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#27969;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;Lipschitz&#20989;&#25968;&#30340;&#20840;&#23616;&#20248;&#21270;&#65292;&#31216;&#20026;Stein Boltzmann&#25277;&#26679;&#65288;SBS&#65289;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20174;Boltzmann&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#35813;&#20998;&#24067;&#22312;&#20248;&#21270;&#20989;&#25968;&#30340;&#26368;&#23567;&#20540;&#38598;&#21512;&#19978;&#28176;&#36817;&#22343;&#21248;&#12290;&#20505;&#36873;&#35299;&#36890;&#36807;Stein Variational Gradient Descent&#31639;&#27861;&#36827;&#34892;&#37319;&#26679;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#28176;&#36817;&#25910;&#25947;&#24615;&#65292;&#24341;&#20837;&#20102;&#20004;&#31181;SBS&#21464;&#20307;&#65292;&#24182;&#22312;&#21508;&#31181;&#22522;&#20934;&#20989;&#25968;&#19978;&#19982;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;&#20840;&#23616;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#35814;&#32454;&#27604;&#36739;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#35774;&#35745;&#12289;&#29702;&#35770;&#32467;&#26524;&#21644;&#23454;&#39564;&#34920;&#26126;&#65292;SBS&#29305;&#21035;&#36866;&#21512;&#20316;&#20026;&#39640;&#25928;&#20840;&#23616;&#20248;&#21270;&#26041;&#27861;&#30340;&#24310;&#32493;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#22312;&#24456;&#22909;&#22320;&#21033;&#29992;&#39044;&#31639;&#30340;&#21516;&#26102;&#20135;&#29983;&#26356;&#22909;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce a new flow-based method for global optimization of Lipschitz functions, called Stein Boltzmann Sampling (SBS). Our method samples from the Boltzmann distribution that becomes asymptotically uniform over the set of the minimizers of the function to be optimized. Candidate solutions are sampled via the \emph{Stein Variational Gradient Descent} algorithm. We prove the asymptotic convergence of our method, introduce two SBS variants, and provide a detailed comparison with several state-of-the-art global optimization algorithms on various benchmark functions. The design of our method, the theoretical results, and our experiments, suggest that SBS is particularly well-suited to be used as a continuation of efficient global optimization methods as it can produce better solutions while making a good use of the budget.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#35780;&#20272;&#20102;&#22312;&#22240;&#26524;&#25512;&#26029;&#20013;&#20351;&#29992;&#21452;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#39044;&#27979;&#24615;&#33021;&#19982;&#22240;&#26524;&#20272;&#35745;&#20043;&#38388;&#20851;&#31995;&#65292;&#24182;&#25552;&#20379;&#20102;&#36229;&#21442;&#25968;&#35843;&#25972;&#21644;&#20854;&#20182;&#23454;&#38469;&#20915;&#31574;&#23545;&#20110;DML&#30340;&#22240;&#26524;&#20272;&#35745;&#30340;&#23454;&#35777;&#35265;&#35299;&#12290;</title><link>https://arxiv.org/abs/2402.04674</link><description>&lt;p&gt;
&#29992;&#20110;&#21452;&#26426;&#22120;&#23398;&#20064;&#30340;&#22240;&#26524;&#25512;&#26029;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#65306;&#19968;&#39033;&#27169;&#25311;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Hyperparameter Tuning for Causal Inference with Double Machine Learning: A Simulation Study
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04674
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#35780;&#20272;&#20102;&#22312;&#22240;&#26524;&#25512;&#26029;&#20013;&#20351;&#29992;&#21452;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#39044;&#27979;&#24615;&#33021;&#19982;&#22240;&#26524;&#20272;&#35745;&#20043;&#38388;&#20851;&#31995;&#65292;&#24182;&#25552;&#20379;&#20102;&#36229;&#21442;&#25968;&#35843;&#25972;&#21644;&#20854;&#20182;&#23454;&#38469;&#20915;&#31574;&#23545;&#20110;DML&#30340;&#22240;&#26524;&#20272;&#35745;&#30340;&#23454;&#35777;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39044;&#27979;&#20219;&#21153;&#20013;&#65292;&#36866;&#24403;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#23545;&#20110;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#26368;&#20339;&#24615;&#33021;&#33267;&#20851;&#37325;&#35201;&#12290;&#23613;&#31649;&#26377;&#22823;&#37327;&#20851;&#20110;&#20026;&#39044;&#27979;&#35843;&#25972;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#25991;&#29486;&#65292;&#20294;&#20851;&#20110;&#23545;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#35843;&#25972;&#21644;&#22312;&#19981;&#21516;&#31639;&#27861;&#20043;&#38388;&#36827;&#34892;&#36873;&#25321;&#26041;&#38754;&#30340;&#25351;&#23548;&#38750;&#24120;&#26377;&#38480;&#12290;&#26412;&#25991;&#36890;&#36807;Chernozhukov&#31561;&#20154;&#65288;2018&#65289;&#30340;&#21452;&#26426;&#22120;&#23398;&#20064;&#65288;DML&#65289;&#26041;&#27861;&#65292;&#20174;&#23454;&#35777;&#35282;&#24230;&#35780;&#20272;&#20102;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#39044;&#27979;&#24615;&#33021;&#19982;&#20854;&#20135;&#29983;&#30340;&#22240;&#26524;&#20272;&#35745;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;DML&#20381;&#36182;&#20110;&#36890;&#36807;&#23558;&#20854;&#35270;&#20026;&#30417;&#30563;&#23398;&#20064;&#38382;&#39064;&#24182;&#23558;&#20854;&#29992;&#20316;&#25554;&#20214;&#20272;&#35745;&#26469;&#20272;&#35745;&#25152;&#35859;&#30340;&#24178;&#25200;&#21442;&#25968;&#65292;&#24182;&#21033;&#29992;&#23427;&#20204;&#26469;&#35299;&#20915;&#65288;&#22240;&#26524;&#65289;&#21442;&#25968;&#12290;&#25105;&#20204;&#20351;&#29992;2019&#24180;&#22823;&#35199;&#27915;&#22240;&#26524;&#25512;&#26029;&#20250;&#35758;&#25968;&#25454;&#25361;&#25112;&#30340;&#25968;&#25454;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#27169;&#25311;&#30740;&#31350;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#36229;&#21442;&#25968;&#35843;&#25972;&#21644;&#20854;&#20182;&#23454;&#38469;&#20915;&#31574;&#23545;&#20110;DML&#30340;&#22240;&#26524;&#20272;&#35745;&#30340;&#20316;&#29992;&#30340;&#23454;&#35777;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Proper hyperparameter tuning is essential for achieving optimal performance of modern machine learning (ML) methods in predictive tasks. While there is an extensive literature on tuning ML learners for prediction, there is only little guidance available on tuning ML learners for causal machine learning and how to select among different ML learners. In this paper, we empirically assess the relationship between the predictive performance of ML methods and the resulting causal estimation based on the Double Machine Learning (DML) approach by Chernozhukov et al. (2018). DML relies on estimating so-called nuisance parameters by treating them as supervised learning problems and using them as plug-in estimates to solve for the (causal) parameter. We conduct an extensive simulation study using data from the 2019 Atlantic Causal Inference Conference Data Challenge. We provide empirical insights on the role of hyperparameter tuning and other practical decisions for causal estimation with DML. Fi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#22122;&#22768;&#35843;&#24230;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#30446;&#26631;&#20998;&#24067;&#21644;&#20272;&#35745;&#20998;&#24067;&#20043;&#38388;KL&#25955;&#24230;&#30340;&#19978;&#30028;&#20197;&#21450;Wasserstein&#36317;&#31163;&#30340;&#25913;&#36827;&#35823;&#24046;&#30028;&#38480;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#33258;&#21160;&#35843;&#33410;&#22122;&#22768;&#35843;&#24230;&#30340;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.04650</link><description>&lt;p&gt;
&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#22122;&#22768;&#35843;&#24230;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
An analysis of the noise schedule for score-based generative models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04650
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#22122;&#22768;&#35843;&#24230;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#30446;&#26631;&#20998;&#24067;&#21644;&#20272;&#35745;&#20998;&#24067;&#20043;&#38388;KL&#25955;&#24230;&#30340;&#19978;&#30028;&#20197;&#21450;Wasserstein&#36317;&#31163;&#30340;&#25913;&#36827;&#35823;&#24046;&#30028;&#38480;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#33258;&#21160;&#35843;&#33410;&#22122;&#22768;&#35843;&#24230;&#30340;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;SGMs&#65289;&#26088;&#22312;&#36890;&#36807;&#20165;&#20351;&#29992;&#30446;&#26631;&#25968;&#25454;&#30340;&#22122;&#22768;&#25200;&#21160;&#26679;&#26412;&#26469;&#23398;&#20064;&#24471;&#20998;&#20989;&#25968;&#65292;&#20174;&#32780;&#20272;&#35745;&#30446;&#26631;&#25968;&#25454;&#20998;&#24067;&#12290;&#26368;&#36817;&#30340;&#25991;&#29486;&#20027;&#35201;&#20851;&#27880;&#35780;&#20272;&#30446;&#26631;&#20998;&#24067;&#21644;&#20272;&#35745;&#20998;&#24067;&#20043;&#38388;&#30340;&#35823;&#24046;&#65292;&#36890;&#36807;KL&#25955;&#24230;&#21644;Wasserstein&#36317;&#31163;&#26469;&#34913;&#37327;&#29983;&#25104;&#36136;&#37327;&#12290;&#33267;&#20170;&#20026;&#27490;&#65292;&#25152;&#26377;&#29616;&#26377;&#32467;&#26524;&#37117;&#26159;&#38024;&#23545;&#26102;&#38388;&#22343;&#21248;&#21464;&#21270;&#30340;&#22122;&#22768;&#35843;&#24230;&#24471;&#21040;&#30340;&#12290;&#22312;&#23545;&#25968;&#25454;&#20998;&#24067;&#36827;&#34892;&#28201;&#21644;&#20551;&#35774;&#30340;&#21069;&#25552;&#19979;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#30446;&#26631;&#20998;&#24067;&#21644;&#20272;&#35745;&#20998;&#24067;&#20043;&#38388;KL&#25955;&#24230;&#30340;&#19978;&#30028;&#65292;&#26126;&#30830;&#20381;&#36182;&#20110;&#20219;&#20309;&#26102;&#38388;&#30456;&#20851;&#30340;&#22122;&#22768;&#35843;&#24230;&#12290;&#20551;&#35774;&#24471;&#20998;&#26159;&#21033;&#26222;&#24076;&#33576;&#36830;&#32493;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;Wasserstein&#36317;&#31163;&#35823;&#24046;&#30028;&#38480;&#65292;&#21033;&#29992;&#20102;&#26377;&#21033;&#30340;&#25910;&#32553;&#26426;&#21046;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25152;&#25552;&#20986;&#30340;&#19978;&#30028;&#33258;&#21160;&#35843;&#33410;&#22122;&#22768;&#35843;&#24230;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score-based generative models (SGMs) aim at estimating a target data distribution by learning score functions using only noise-perturbed samples from the target. Recent literature has focused extensively on assessing the error between the target and estimated distributions, gauging the generative quality through the Kullback-Leibler (KL) divergence and Wasserstein distances.  All existing results  have been obtained so far for time-homogeneous speed of the noise schedule.  Under mild assumptions on the data distribution, we establish an upper bound for the KL divergence between the target and the estimated distributions, explicitly depending on any time-dependent noise schedule. Assuming that the score is Lipschitz continuous, we provide an improved error bound in Wasserstein distance, taking advantage of favourable underlying contraction mechanisms. We also propose an algorithm to automatically tune the noise schedule using the proposed upper bound. We illustrate empirically the perfo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#20351;&#29992;Moreau&#21253;&#32476;&#26469;&#23545;&#27979;&#24230;f-&#24046;&#24322;&#36827;&#34892;&#27491;&#21017;&#21270;&#30340;&#26041;&#27861;&#65292;&#24182;&#21033;&#29992;&#35813;&#26041;&#27861;&#20998;&#26512;&#20102;Wasserstein&#26799;&#24230;&#27969;&#12290;</title><link>https://arxiv.org/abs/2402.04613</link><description>&lt;p&gt;
&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;Moreau&#21253;&#32476;&#30340;f-&#24046;&#24322;&#30340;Wasserstein&#26799;&#24230;&#27969;
&lt;/p&gt;
&lt;p&gt;
Wasserstein Gradient Flows for Moreau Envelopes of f-Divergences in Reproducing Kernel Hilbert Spaces
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04613
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#20351;&#29992;Moreau&#21253;&#32476;&#26469;&#23545;&#27979;&#24230;f-&#24046;&#24322;&#36827;&#34892;&#27491;&#21017;&#21270;&#30340;&#26041;&#27861;&#65292;&#24182;&#21033;&#29992;&#35813;&#26041;&#27861;&#20998;&#26512;&#20102;Wasserstein&#26799;&#24230;&#27969;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#24120;&#29992;&#30340;&#27979;&#24230;f-&#24046;&#24322;&#65292;&#20363;&#22914;Kullback-Leibler&#24046;&#24322;&#65292;&#23545;&#20110;&#25152;&#28041;&#21450;&#30340;&#27979;&#24230;&#30340;&#25903;&#25345;&#23384;&#22312;&#38480;&#21046;&#12290;&#35299;&#20915;&#21150;&#27861;&#26159;&#36890;&#36807;&#19982;&#29305;&#24449;&#26680;K&#30456;&#20851;&#30340;&#24179;&#26041;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;(MMD)&#23545;f-&#24046;&#24322;&#36827;&#34892;&#27491;&#21017;&#21270;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#25152;&#35859;&#30340;&#26680;&#22343;&#20540;&#23884;&#20837;&#26469;&#26174;&#31034;&#30456;&#24212;&#30340;&#27491;&#21017;&#21270;&#21487;&#20197;&#37325;&#20889;&#20026;&#19982;K&#30456;&#20851;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#26576;&#20123;&#20989;&#25968;&#30340;Moreau&#21253;&#32476;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#20851;&#20110;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;Moreau&#21253;&#32476;&#30340;&#20247;&#25152;&#21608;&#30693;&#30340;&#32467;&#26524;&#26469;&#35777;&#26126;MMD&#27491;&#21017;&#21270;&#30340;f-&#24046;&#24322;&#21450;&#20854;&#26799;&#24230;&#30340;&#23646;&#24615;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#26469;&#20998;&#26512;&#21463;MMD&#27491;&#21017;&#21270;&#30340;f-&#24046;&#24322;&#30340;Wasserstein&#26799;&#24230;&#27969;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#32771;&#34385;&#20174;&#32463;&#39564;&#27979;&#24230;&#24320;&#22987;&#30340;Wasserstein&#26799;&#24230;&#27969;&#65292;&#24182;&#25552;&#20379;&#20351;&#29992;Tsallis-$\alpha$&#24046;&#24322;&#30340;&#27010;&#24565;&#24615;&#25968;&#20540;&#31034;&#20363;&#30340;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most commonly used $f$-divergences of measures, e.g., the Kullback-Leibler divergence, are subject to limitations regarding the support of the involved measures. A remedy consists of regularizing the $f$-divergence by a squared maximum mean discrepancy (MMD) associated with a characteristic kernel $K$. In this paper, we use the so-called kernel mean embedding to show that the corresponding regularization can be rewritten as the Moreau envelope of some function in the reproducing kernel Hilbert space associated with $K$. Then, we exploit well-known results on Moreau envelopes in Hilbert spaces to prove properties of the MMD-regularized $f$-divergences and, in particular, their gradients. Subsequently, we use our findings to analyze Wasserstein gradient flows of MMD-regularized $f$-divergences. Finally, we consider Wasserstein gradient flows starting from empirical measures and provide proof-of-the-concept numerical examples with Tsallis-$\alpha$ divergences.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#21069;&#21521;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#38477;&#32500;&#20195;&#29702;&#27169;&#22411;&#30340;&#26500;&#24314;&#26041;&#27861;&#65292;&#36890;&#36807;&#25552;&#21462;&#38477;&#32500;&#32467;&#26524;&#24418;&#25104;&#19968;&#20010;&#38543;&#26426;&#27169;&#25311;&#22120;&#65292;&#33021;&#22815;&#36866;&#29992;&#20110;&#39640;&#32500;&#36755;&#20837;&#31354;&#38388;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.04582</link><description>&lt;p&gt;
&#38477;&#32500;&#25216;&#26415;&#21487;&#20197;&#29992;&#20316;&#39640;&#32500;&#21069;&#21521;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#20195;&#29702;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Dimensionality reduction can be used as a surrogate model for high-dimensional forward uncertainty quantification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04582
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#21069;&#21521;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#38477;&#32500;&#20195;&#29702;&#27169;&#22411;&#30340;&#26500;&#24314;&#26041;&#27861;&#65292;&#36890;&#36807;&#25552;&#21462;&#38477;&#32500;&#32467;&#26524;&#24418;&#25104;&#19968;&#20010;&#38543;&#26426;&#27169;&#25311;&#22120;&#65292;&#33021;&#22815;&#36866;&#29992;&#20110;&#39640;&#32500;&#36755;&#20837;&#31354;&#38388;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#20174;&#38477;&#32500;&#32467;&#26524;&#20013;&#26500;&#24314;&#19968;&#20010;&#38543;&#26426;&#20195;&#29702;&#27169;&#22411;&#29992;&#20110;&#21069;&#21521;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#30340;&#20551;&#35774;&#26159;&#65292;&#36890;&#36807;&#35745;&#31639;&#27169;&#22411;&#30340;&#36755;&#20986;&#22686;&#24378;&#30340;&#39640;&#32500;&#36755;&#20837;&#21487;&#20197;&#24471;&#21040;&#19968;&#20010;&#20302;&#32500;&#34920;&#31034;&#12290;&#36825;&#20010;&#20551;&#35774;&#36866;&#29992;&#20110;&#35768;&#22810;&#22522;&#20110;&#29289;&#29702;&#30340;&#35745;&#31639;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#24212;&#29992;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#19982;&#25353;&#39034;&#24207;&#36827;&#34892;&#38477;&#32500;&#28982;&#21518;&#36827;&#34892;&#20195;&#29702;&#24314;&#27169;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#22240;&#20026;&#25105;&#20204;&#26159;&#20174;&#36755;&#20837;-&#36755;&#20986;&#31354;&#38388;&#30340;&#38477;&#32500;&#32467;&#26524;&#20013;&#8220;&#25552;&#21462;&#8221;&#20986;&#19968;&#20010;&#20195;&#29702;&#27169;&#22411;&#12290;&#24403;&#36755;&#20837;&#31354;&#38388;&#30495;&#27491;&#26159;&#39640;&#32500;&#26102;&#65292;&#36825;&#20010;&#29305;&#28857;&#21464;&#24471;&#26377;&#21560;&#24341;&#21147;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#36824;&#19981;&#21516;&#20110;&#22312;&#27969;&#24418;&#19978;&#30340;&#27010;&#29575;&#24615;&#23398;&#20064;&#65292;&#22240;&#20026;&#36991;&#20813;&#20102;&#20174;&#29305;&#24449;&#31354;&#38388;&#21040;&#36755;&#20837;-&#36755;&#20986;&#31354;&#38388;&#30340;&#37325;&#26500;&#26144;&#23556;&#12290;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#26368;&#32456;&#20135;&#29289;&#26159;&#19968;&#20010;&#23558;&#30830;&#23450;&#24615;&#36755;&#20837;&#20256;&#25773;&#21040;&#38543;&#26426;&#27169;&#25311;&#22120;&#20013;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a method to construct a stochastic surrogate model from the results of dimensionality reduction in forward uncertainty quantification. The hypothesis is that the high-dimensional input augmented by the output of a computational model admits a low-dimensional representation. This assumption can be met by numerous uncertainty quantification applications with physics-based computational models. The proposed approach differs from a sequential application of dimensionality reduction followed by surrogate modeling, as we "extract" a surrogate model from the results of dimensionality reduction in the input-output space. This feature becomes desirable when the input space is genuinely high-dimensional. The proposed method also diverges from the Probabilistic Learning on Manifold, as a reconstruction mapping from the feature space to the input-output space is circumvented. The final product of the proposed method is a stochastic simulator that propagates a deterministic input into 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38598;&#25104;&#26041;&#27861;Riemann-Lebesgue Forest (RLF)&#29992;&#20110;&#22238;&#24402;&#38382;&#39064;&#65292;&#36890;&#36807;&#21010;&#20998;&#20989;&#25968;&#30340;&#20540;&#22495;&#20026;&#22810;&#20010;&#21306;&#38388;&#26469;&#36924;&#36817;&#21487;&#27979;&#20989;&#25968;&#30340;&#24605;&#24819;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#26641;&#23398;&#20064;&#31639;&#27861;Riemann-Lebesgue Tree&#12290;&#36890;&#36807;Hoeffding&#20998;&#35299;&#21644;Stein&#26041;&#27861;&#25512;&#23548;&#20102;RLF&#22312;&#19981;&#21516;&#21442;&#25968;&#35774;&#32622;&#19979;&#30340;&#28176;&#36817;&#24615;&#33021;&#65292;&#24182;&#22312;&#20223;&#30495;&#25968;&#25454;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;RLF&#19982;&#21407;&#22987;&#38543;&#26426;&#26862;&#26519;&#30456;&#27604;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.04550</link><description>&lt;p&gt;
Riemann-Lebesgue Forest&#22238;&#24402;&#26041;&#27861;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Riemann-Lebesgue Forest for Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04550
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38598;&#25104;&#26041;&#27861;Riemann-Lebesgue Forest (RLF)&#29992;&#20110;&#22238;&#24402;&#38382;&#39064;&#65292;&#36890;&#36807;&#21010;&#20998;&#20989;&#25968;&#30340;&#20540;&#22495;&#20026;&#22810;&#20010;&#21306;&#38388;&#26469;&#36924;&#36817;&#21487;&#27979;&#20989;&#25968;&#30340;&#24605;&#24819;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#26641;&#23398;&#20064;&#31639;&#27861;Riemann-Lebesgue Tree&#12290;&#36890;&#36807;Hoeffding&#20998;&#35299;&#21644;Stein&#26041;&#27861;&#25512;&#23548;&#20102;RLF&#22312;&#19981;&#21516;&#21442;&#25968;&#35774;&#32622;&#19979;&#30340;&#28176;&#36817;&#24615;&#33021;&#65292;&#24182;&#22312;&#20223;&#30495;&#25968;&#25454;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;RLF&#19982;&#21407;&#22987;&#38543;&#26426;&#26862;&#26519;&#30456;&#27604;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29992;&#20110;&#22238;&#24402;&#38382;&#39064;&#30340;&#38598;&#25104;&#26041;&#27861;&#65292;&#31216;&#20026;Riemann-Lebesgue Forest (RLF)&#12290;RLF&#30340;&#26680;&#24515;&#24605;&#24819;&#26159;&#36890;&#36807;&#23558;&#20989;&#25968;&#30340;&#20540;&#22495;&#21010;&#20998;&#20026;&#20960;&#20010;&#21306;&#38388;&#26469;&#27169;&#25311;&#21487;&#27979;&#20989;&#25968;&#30340;&#36924;&#36817;&#26041;&#24335;&#12290;&#22522;&#20110;&#36825;&#20010;&#24605;&#24819;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#26641;&#23398;&#20064;&#31639;&#27861;&#65292;&#31216;&#20026;Riemann-Lebesgue Tree&#65292;&#23427;&#22312;&#27599;&#20010;&#38750;&#21494;&#33410;&#28857;&#19978;&#26377;&#26426;&#20250;&#20174;&#21709;&#24212;Y&#25110;&#29305;&#24449;&#31354;&#38388;X&#20013;&#30340;&#26041;&#21521;&#36827;&#34892;&#20999;&#21106;&#12290;&#25105;&#20204;&#36890;&#36807;Hoeffding&#20998;&#35299;&#21644;Stein&#26041;&#27861;&#26469;&#25512;&#23548;&#19981;&#21516;&#21442;&#25968;&#35774;&#32622;&#19979;RLF&#30340;&#28176;&#36817;&#24615;&#33021;&#12290;&#24403;&#24213;&#23618;&#20989;&#25968;Y=f(X)&#36981;&#24490;&#21152;&#27861;&#22238;&#24402;&#27169;&#22411;&#26102;&#65292;RLF&#19982;Scornet&#31561;&#20154;&#30340;&#35770;&#35777;&#65288;2014&#24180;&#65289;&#20445;&#25345;&#19968;&#33268;&#12290;&#36890;&#36807;&#22312;&#20223;&#30495;&#25968;&#25454;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;RLF&#19982;&#21407;&#22987;&#38543;&#26426;&#26862;&#26519;&#30456;&#27604;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel ensemble method called Riemann-Lebesgue Forest (RLF) for regression. The core idea of RLF is to mimic the way how a measurable function can be approximated by partitioning its range into a few intervals. With this idea in mind, we develop a new tree learner named Riemann-Lebesgue Tree which has a chance to split the node from response $Y$ or a direction in feature space $\mathbf{X}$ at each non-terminal node. We generalize the asymptotic performance of RLF under different parameter settings mainly through Hoeffding decomposition \cite{Vaart} and Stein's method \cite{Chen2010NormalAB}. When the underlying function $Y=f(\mathbf{X})$ follows an additive regression model, RLF is consistent with the argument from \cite{Scornet2014ConsistencyOR}. The competitive performance of RLF against original random forest \cite{Breiman2001RandomF} is demonstrated by experiments in simulation data and real world datasets.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#32454;&#31890;&#24230;&#22797;&#26434;&#24615;&#20998;&#26512;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#29616;&#20195;Hopfield&#27169;&#22411;&#30340;&#35760;&#24518;&#26816;&#32034;&#35745;&#31639;&#38480;&#21046;&#65292;&#21457;&#29616;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#24335;&#33539;&#25968;&#30340;&#30456;&#21464;&#34892;&#20026;&#65292;&#24182;&#19988;&#24314;&#31435;&#20102;&#26377;&#25928;&#21464;&#20307;&#30340;&#19978;&#30028;&#26465;&#20214;&#12290;&#20351;&#29992;&#20302;&#31209;&#36924;&#36817;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#26377;&#25928;&#26500;&#36896;&#30340;&#31034;&#20363;&#65292;&#21516;&#26102;&#35777;&#26126;&#20102;&#35745;&#31639;&#26102;&#38388;&#19979;&#30028;&#12289;&#35760;&#24518;&#26816;&#32034;&#35823;&#24046;&#30028;&#21644;&#25351;&#25968;&#35760;&#24518;&#23481;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.04520</link><description>&lt;p&gt;
&#20851;&#20110;&#29616;&#20195;Hopfield&#27169;&#22411;&#35745;&#31639;&#38480;&#21046;&#30340;&#19968;&#20010;&#32454;&#31890;&#24230;&#22797;&#26434;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04520
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#32454;&#31890;&#24230;&#22797;&#26434;&#24615;&#20998;&#26512;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#29616;&#20195;Hopfield&#27169;&#22411;&#30340;&#35760;&#24518;&#26816;&#32034;&#35745;&#31639;&#38480;&#21046;&#65292;&#21457;&#29616;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#24335;&#33539;&#25968;&#30340;&#30456;&#21464;&#34892;&#20026;&#65292;&#24182;&#19988;&#24314;&#31435;&#20102;&#26377;&#25928;&#21464;&#20307;&#30340;&#19978;&#30028;&#26465;&#20214;&#12290;&#20351;&#29992;&#20302;&#31209;&#36924;&#36817;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#26377;&#25928;&#26500;&#36896;&#30340;&#31034;&#20363;&#65292;&#21516;&#26102;&#35777;&#26126;&#20102;&#35745;&#31639;&#26102;&#38388;&#19979;&#30028;&#12289;&#35760;&#24518;&#26816;&#32034;&#35823;&#24046;&#30028;&#21644;&#25351;&#25968;&#35760;&#24518;&#23481;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20174;&#32454;&#31890;&#24230;&#22797;&#26434;&#24615;&#20998;&#26512;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#29616;&#20195;Hopfield&#27169;&#22411;&#30340;&#35760;&#24518;&#26816;&#32034;&#21160;&#21147;&#23398;&#30340;&#35745;&#31639;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#22522;&#20110;&#27169;&#24335;&#30340;&#33539;&#25968;&#23545;&#25152;&#26377;&#21487;&#33021;&#30340;&#29616;&#20195;Hopfield&#27169;&#22411;&#30340;&#25928;&#29575;&#36827;&#34892;&#30456;&#21464;&#34892;&#20026;&#30340;&#21051;&#30011;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#23545;&#36755;&#20837;&#26597;&#35810;&#27169;&#24335;&#21644;&#35760;&#24518;&#27169;&#24335;&#30340;&#33539;&#25968;&#30340;&#19978;&#30028;&#26631;&#20934;&#12290;&#20165;&#22312;&#36825;&#20010;&#26631;&#20934;&#20043;&#19979;&#65292;&#20551;&#35774;&#28385;&#36275;Strong Exponential Time Hypothesis (SETH)&#65292;&#23384;&#22312;&#23376;&#20108;&#27425;&#65288;&#39640;&#25928;&#65289;&#21464;&#20307;&#30340;&#29616;&#20195;Hopfield&#27169;&#22411;&#12290;&#20026;&#20102;&#23637;&#31034;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#24403;&#26377;&#25928;&#26631;&#20934;&#25104;&#31435;&#26102;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#29616;&#20195;Hopfield&#27169;&#22411;&#20351;&#29992;&#20302;&#31209;&#36924;&#36817;&#30340;&#26377;&#25928;&#26500;&#36896;&#30340;&#27491;&#24335;&#31034;&#20363;&#12290;&#36825;&#21253;&#25324;&#19968;&#20010;&#35745;&#31639;&#26102;&#38388;&#30340;&#19979;&#30028;&#23548;&#20986;&#65292;&#19982;$\Max\{$&#23384;&#20648;&#30340;&#35760;&#24518;&#27169;&#24335;&#25968;&#37327;&#65292;&#36755;&#20837;&#26597;&#35810;&#24207;&#21015;&#30340;&#38271;&#24230;$\}$&#32447;&#24615;&#32553;&#25918;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35760;&#24518;&#26816;&#32034;&#35823;&#24046;&#30028;&#21644;&#25351;&#25968;&#35760;&#24518;&#23481;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the computational limits of the memory retrieval dynamics of modern Hopfield models from the fine-grained complexity analysis. Our key contribution is the characterization of a phase transition behavior in the efficiency of all possible modern Hopfield models based on the norm of patterns. Specifically, we establish an upper bound criterion for the norm of input query patterns and memory patterns. Only below this criterion, sub-quadratic (efficient) variants of the modern Hopfield model exist, assuming the Strong Exponential Time Hypothesis (SETH). To showcase our theory, we provide a formal example of efficient constructions of modern Hopfield models using low-rank approximation when the efficient criterion holds. This includes a derivation of a lower bound on the computational time, scaling linearly with $\Max\{$# of stored memory patterns, length of input query sequence$\}$. In addition, we prove its memory retrieval error bound and exponential memory capacity.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#30740;&#31350;&#20102;&#25903;&#25345;&#22312;&#22270;&#24230;&#37327;&#31354;&#38388;&#19978;&#30340;&#27979;&#24230;&#30340;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#19981;&#21516;&#20960;&#20309;&#32467;&#26500;&#30340;&#22270;&#19978;&#27010;&#29575;&#27979;&#24230;&#20256;&#36755;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#36229;&#21147; Wassestein&#65288;OW&#65289;&#30340;&#27010;&#24565;&#65292;&#20026;&#26576;&#20123;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#21457;&#23637;&#24102;&#26469;&#20102;&#26032;&#30340;&#26426;&#36935;&#12290;</title><link>https://arxiv.org/abs/2402.04516</link><description>&lt;p&gt;
&#22270;&#19978;&#27010;&#29575;&#27979;&#24230;&#30340;&#24191;&#20041; Sobolev &#20256;&#36755;
&lt;/p&gt;
&lt;p&gt;
Generalized Sobolev Transport for Probability Measures on a Graph
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04516
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#25903;&#25345;&#22312;&#22270;&#24230;&#37327;&#31354;&#38388;&#19978;&#30340;&#27979;&#24230;&#30340;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#19981;&#21516;&#20960;&#20309;&#32467;&#26500;&#30340;&#22270;&#19978;&#27010;&#29575;&#27979;&#24230;&#20256;&#36755;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#36229;&#21147; Wassestein&#65288;OW&#65289;&#30340;&#27010;&#24565;&#65292;&#20026;&#26576;&#20123;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#21457;&#23637;&#24102;&#26469;&#20102;&#26032;&#30340;&#26426;&#36935;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#25903;&#25345;&#22312;&#22270;&#24230;&#37327;&#31354;&#38388;&#19978;&#30340;&#27979;&#24230;&#30340;&#26368;&#20248;&#20256;&#36755;&#65288;OT&#65289;&#38382;&#39064;&#12290;&#26368;&#36817;&#65292;Le &#31561;&#20154;&#65288;2022&#65289;&#21033;&#29992;&#22270;&#32467;&#26500;&#25552;&#20986;&#20102;&#19968;&#31181; OT &#30340;&#21464;&#20307;&#65292;&#31216;&#20026; Sobolev &#20256;&#36755;&#65288;ST&#65289;&#65292;&#23427;&#25552;&#20379;&#20102;&#19968;&#31181;&#38381;&#24335;&#34920;&#36798;&#24335;&#29992;&#20110;&#24555;&#36895;&#35745;&#31639;&#12290;&#28982;&#32780;&#65292;ST &#30340;&#23450;&#20041;&#20013;&#23454;&#36136;&#19978;&#19982; $L^p$ &#20960;&#20309;&#32467;&#26500;&#32806;&#21512;&#22312;&#19968;&#36215;&#65292;&#36825;&#20351;&#24471;&#22312;&#20854;&#20182;&#20808;&#39564;&#32467;&#26500;&#20013;&#21033;&#29992; ST &#21464;&#24471;&#38750;&#24120;&#22256;&#38590;&#12290;&#30456;&#21453;&#65292;&#32463;&#20856;&#30340; OT &#36890;&#36807;&#20462;&#25913;&#24213;&#23618;&#25104;&#26412;&#20989;&#25968;&#20855;&#26377;&#36866;&#24212;&#21508;&#31181;&#20960;&#20309;&#32467;&#26500;&#30340;&#28789;&#27963;&#24615;&#12290;&#19968;&#20010;&#37325;&#35201;&#30340;&#20363;&#23376;&#26159;&#36229;&#21147; Wassestein&#65288;OW&#65289;&#65292;&#23427;&#36890;&#36807;&#21033;&#29992;\emph{Orlicz &#20960;&#20309;&#32467;&#26500;}&#36229;&#36234;&#20102; $L^p$ &#32467;&#26500;&#12290;&#19982;&#20351;&#29992;&#26631;&#20934; $p$-&#38454; Wassestein &#30456;&#27604;&#65292;OW &#26174;&#33879;&#25552;&#39640;&#20102;&#26576;&#20123;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20854;&#20004;&#23618;&#20248;&#21270; formulation&#65292;OW &#22312;&#20854;&#35745;&#31639;&#19978;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#20102;&#19968;&#31867;&#29305;&#23450;&#30340;&#20984;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the optimal transport (OT) problem for measures supported on a graph metric space. Recently, Le et al. (2022) leverage the graph structure and propose a variant of OT, namely Sobolev transport (ST), which yields a closed-form expression for a fast computation. However, ST is essentially coupled with the $L^p$ geometric structure within its definition which makes it nontrivial to utilize ST for other prior structures. In contrast, the classic OT has the flexibility to adapt to various geometric structures by modifying the underlying cost function. An important instance is the Orlicz-Wasserstein (OW) which moves beyond the $L^p$ structure by leveraging the \emph{Orlicz geometric structure}. Comparing to the usage of standard $p$-order Wasserstein, OW remarkably helps to advance certain machine learning approaches. Nevertheless, OW brings up a new challenge on its computation due to its two-level optimization formulation. In this work, we leverage a specific class of convex funct
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#36335;&#24452;&#31354;&#38388;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;PKF&#65289;&#30340;&#25193;&#23637;&#31639;&#27861;&#65292;&#21487;&#20197;&#21160;&#24577;&#36319;&#36394;&#25968;&#25454;&#21644;&#20808;&#21069;&#30693;&#35782;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#29992;&#36125;&#21494;&#26031;&#26041;&#27861;&#37327;&#21270;&#19981;&#21516;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#12290;&#36890;&#36807;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#25968;&#20540;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;PKF&#20248;&#20110;&#20256;&#32479;KF&#26041;&#27861;&#65292;&#24182;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#29983;&#29289;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#12290;</title><link>https://arxiv.org/abs/2402.04498</link><description>&lt;p&gt;
&#24102;&#26377;&#21160;&#24577;&#36807;&#31243;&#19981;&#30830;&#23450;&#24615;&#30340;&#36335;&#24452;&#31354;&#38388;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Pathspace Kalman Filters with Dynamic Process Uncertainty for Analyzing Time-course Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04498
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#36335;&#24452;&#31354;&#38388;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;PKF&#65289;&#30340;&#25193;&#23637;&#31639;&#27861;&#65292;&#21487;&#20197;&#21160;&#24577;&#36319;&#36394;&#25968;&#25454;&#21644;&#20808;&#21069;&#30693;&#35782;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#29992;&#36125;&#21494;&#26031;&#26041;&#27861;&#37327;&#21270;&#19981;&#21516;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#12290;&#36890;&#36807;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#25968;&#20540;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;PKF&#20248;&#20110;&#20256;&#32479;KF&#26041;&#27861;&#65292;&#24182;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#29983;&#29289;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;KF&#65289;&#26159;&#19968;&#31181;&#26368;&#20248;&#32447;&#24615;&#29366;&#24577;&#39044;&#27979;&#31639;&#27861;&#65292;&#24191;&#27867;&#24212;&#29992;&#20110;&#24037;&#31243;&#23398;&#12289;&#32463;&#27982;&#23398;&#12289;&#26426;&#22120;&#20154;&#23398;&#21644;&#22826;&#31354;&#25506;&#32034;&#31561;&#39046;&#22495;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21457;&#23637;&#20102;KF&#30340;&#25193;&#23637;&#65292;&#31216;&#20026;&#36335;&#24452;&#31354;&#38388;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;PKF&#65289;&#65292;&#23427;&#20801;&#35768;&#25105;&#20204;&#21160;&#24577;&#36319;&#36394;&#19982;&#24213;&#23618;&#25968;&#25454;&#21644;&#20808;&#21069;&#30693;&#35782;&#30456;&#20851;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#20351;&#29992;&#36125;&#21494;&#26031;&#26041;&#27861;&#37327;&#21270;&#19981;&#21516;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#12290;&#35813;&#31639;&#27861;&#30340;&#19968;&#20010;&#24212;&#29992;&#26159;&#33258;&#21160;&#26816;&#27979;&#20869;&#37096;&#26426;&#21046;&#27169;&#22411;&#19982;&#25968;&#25454;&#22312;&#26102;&#38388;&#19978;&#21457;&#29983;&#21464;&#21270;&#30340;&#26102;&#38388;&#31383;&#21475;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#25551;&#36848;PKF&#31639;&#27861;&#25910;&#25947;&#24615;&#30340;&#23450;&#29702;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;PKF&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#20248;&#20110;&#20256;&#32479;KF&#26041;&#27861;&#65292;&#24179;&#22343;&#22343;&#26041;&#35823;&#24046;&#38477;&#20302;&#20102;&#25968;&#20010;&#25968;&#37327;&#32423;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#29983;&#29289;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kalman Filter (KF) is an optimal linear state prediction algorithm, with applications in fields as diverse as engineering, economics, robotics, and space exploration. Here, we develop an extension of the KF, called a Pathspace Kalman Filter (PKF) which allows us to a) dynamically track the uncertainties associated with the underlying data and prior knowledge, and b) take as input an entire trajectory and an underlying mechanistic model, and using a Bayesian methodology quantify the different sources of uncertainty. An application of this algorithm is to automatically detect temporal windows where the internal mechanistic model deviates from the data in a time-dependent manner. First, we provide theorems characterizing the convergence of the PKF algorithm. Then, we numerically demonstrate that the PKF outperforms conventional KF methods on a synthetic dataset lowering the mean-squared-error by several orders of magnitude. Finally, we apply this method to biological time-course dataset i
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#22312;&#24222;&#22823;&#30340;&#22269;&#38469;&#35937;&#26827;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#20351;&#29992;&#20102;&#19968;&#20010;270M&#21442;&#25968;&#30340;Transformer&#27169;&#22411;&#65292;&#19981;&#20381;&#36182;&#20110;&#22797;&#26434;&#30340;&#21551;&#21457;&#24335;&#31639;&#27861;&#25110;&#26174;&#24335;&#25628;&#32034;&#65292;&#21462;&#24471;&#20102;&#22823;&#24072;&#32423;&#27700;&#24179;&#30340;&#22269;&#38469;&#35937;&#26827;&#23545;&#23616;&#30340;&#25104;&#21151;&#12290;&#27169;&#22411;&#22312;Lichess&#38378;&#30005;&#25112;&#35780;&#20998;&#19978;&#36798;&#21040;&#20102;2895&#65292;&#35299;&#20915;&#20102;&#19968;&#31995;&#21015;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22269;&#38469;&#35937;&#26827;&#35868;&#39064;&#65292;&#20248;&#20110;AlphaZero&#21644;GPT-3.5-turbo-instruct&#12290;&#36890;&#36807;&#31995;&#32479;&#30740;&#31350;&#65292;&#25105;&#20204;&#21457;&#29616;&#22823;&#35268;&#27169;&#30340;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#23545;&#20110;&#23454;&#29616;&#24378;&#22823;&#30340;&#22269;&#38469;&#35937;&#26827;&#23545;&#23616;&#25928;&#26524;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;</title><link>https://arxiv.org/abs/2402.04494</link><description>&lt;p&gt;
&#19981;&#38656;&#25628;&#32034;&#21363;&#21487;&#23454;&#29616;&#22823;&#24072;&#32423;&#22269;&#38469;&#35937;&#26827;&#23545;&#23616;
&lt;/p&gt;
&lt;p&gt;
Grandmaster-Level Chess Without Search
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04494
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#22312;&#24222;&#22823;&#30340;&#22269;&#38469;&#35937;&#26827;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#20351;&#29992;&#20102;&#19968;&#20010;270M&#21442;&#25968;&#30340;Transformer&#27169;&#22411;&#65292;&#19981;&#20381;&#36182;&#20110;&#22797;&#26434;&#30340;&#21551;&#21457;&#24335;&#31639;&#27861;&#25110;&#26174;&#24335;&#25628;&#32034;&#65292;&#21462;&#24471;&#20102;&#22823;&#24072;&#32423;&#27700;&#24179;&#30340;&#22269;&#38469;&#35937;&#26827;&#23545;&#23616;&#30340;&#25104;&#21151;&#12290;&#27169;&#22411;&#22312;Lichess&#38378;&#30005;&#25112;&#35780;&#20998;&#19978;&#36798;&#21040;&#20102;2895&#65292;&#35299;&#20915;&#20102;&#19968;&#31995;&#21015;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22269;&#38469;&#35937;&#26827;&#35868;&#39064;&#65292;&#20248;&#20110;AlphaZero&#21644;GPT-3.5-turbo-instruct&#12290;&#36890;&#36807;&#31995;&#32479;&#30740;&#31350;&#65292;&#25105;&#20204;&#21457;&#29616;&#22823;&#35268;&#27169;&#30340;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#23545;&#20110;&#23454;&#29616;&#24378;&#22823;&#30340;&#22269;&#38469;&#35937;&#26827;&#23545;&#23616;&#25928;&#26524;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#26032;&#30340;&#26426;&#22120;&#23398;&#20064;&#30340;&#31361;&#30772;&#24615;&#25104;&#21151;&#20027;&#35201;&#24402;&#21151;&#20110;&#35268;&#27169;&#21270;&#65292;&#21363;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#22823;&#35268;&#27169;&#26550;&#26500;&#21644;&#31354;&#21069;&#35268;&#27169;&#30340;&#25968;&#25454;&#38598;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#22269;&#38469;&#35937;&#26827;&#30340;&#22823;&#35268;&#27169;&#35757;&#32451;&#30340;&#24433;&#21709;&#12290;&#19982;&#20256;&#32479;&#30340;&#20381;&#36182;&#22797;&#26434;&#21551;&#21457;&#24335;&#31639;&#27861;&#12289;&#26174;&#24335;&#25628;&#32034;&#25110;&#20108;&#32773;&#32467;&#21512;&#30340;&#22269;&#38469;&#35937;&#26827;&#24341;&#25806;&#19981;&#21516;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;1000&#19975;&#23616;&#22269;&#38469;&#35937;&#26827;&#23545;&#23616;&#30340;&#25968;&#25454;&#38598;&#19978;&#20351;&#29992;&#30417;&#30563;&#23398;&#20064;&#35757;&#32451;&#20102;&#19968;&#20010;&#25317;&#26377;2.7&#20159;&#21442;&#25968;&#30340;Transformer&#27169;&#22411;&#12290;&#25105;&#20204;&#29992;&#24378;&#22823;&#30340;Stockfish 16&#24341;&#25806;&#25552;&#20379;&#30340;&#21160;&#20316;&#20540;&#26469;&#27880;&#37322;&#25968;&#25454;&#38598;&#20013;&#30340;&#27599;&#20010;&#26827;&#23616;&#65292;&#20135;&#29983;&#22823;&#32422;150&#20159;&#20010;&#25968;&#25454;&#28857;&#12290;&#25105;&#20204;&#26368;&#22823;&#30340;&#27169;&#22411;&#22312;Lichess&#38378;&#30005;&#25112;Elo&#19978;&#36798;&#21040;&#20102;2895&#65292;&#25104;&#21151;&#35299;&#20915;&#20102;&#19968;&#31995;&#21015;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22269;&#38469;&#35937;&#26827;&#35868;&#39064;&#65292;&#32780;&#26080;&#38656;&#20219;&#20309;&#29305;&#23450;&#39046;&#22495;&#30340;&#35843;&#25972;&#25110;&#26174;&#24335;&#25628;&#32034;&#31639;&#27861;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#20248;&#20110;AlphaZero&#30340;&#31574;&#30053;&#21644;&#20215;&#20540;&#32593;&#32476;&#65288;&#26080;MCTS&#65289;&#20197;&#21450;GPT-3.5-turbo-instruct&#12290;&#23545;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#35268;&#27169;&#30340;&#31995;&#32479;&#30740;&#31350;&#34920;&#26126;&#65292;&#24378;&#22823;&#30340;&#22269;&#38469;&#35937;&#26827;&#23545;&#23616;&#21487;&#20197;&#22312;&#35268;&#27169;&#19978;&#21462;&#24471;&#26368;&#20339;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recent breakthrough successes in machine learning are mainly attributed to scale: namely large-scale attention-based architectures and datasets of unprecedented scale. This paper investigates the impact of training at scale for chess. Unlike traditional chess engines that rely on complex heuristics, explicit search, or a combination of both, we train a 270M parameter transformer model with supervised learning on a dataset of 10 million chess games. We annotate each board in the dataset with action-values provided by the powerful Stockfish 16 engine, leading to roughly 15 billion data points. Our largest model reaches a Lichess blitz Elo of 2895 against humans, and successfully solves a series of challenging chess puzzles, without any domain-specific tweaks or explicit search algorithms. We also show that our model outperforms AlphaZero's policy and value networks (without MCTS) and GPT-3.5-turbo-instruct. A systematic investigation of model and dataset size shows that strong chess 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#20302;&#31209;MDPs&#19978;&#30340;&#31163;&#32447;&#32422;&#26463;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#37096;&#20998;&#25968;&#25454;&#35206;&#30422;&#20551;&#35774;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#35745;&#31639;&#25928;&#29575;&#24182;&#36798;&#21040;&#20102;$O(\epsilon^{-2})$&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#27492;&#22806;&#65292;&#35813;&#31639;&#27861;&#36824;&#25903;&#25345;&#39069;&#22806;&#22870;&#21169;&#20449;&#21495;&#30340;&#32422;&#26463;&#12290;</title><link>https://arxiv.org/abs/2402.04493</link><description>&lt;p&gt;
&#31163;&#32447;&#32422;&#26463;&#24378;&#21270;&#23398;&#20064;&#20013;&#19968;&#31181;&#22522;&#26412;&#23545;&#20598;&#31639;&#27861;&#22312;&#20302;&#31209;MDPs&#19978;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
A Primal-Dual Algorithm for Offline Constrained Reinforcement Learning with Low-Rank MDPs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04493
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#20302;&#31209;MDPs&#19978;&#30340;&#31163;&#32447;&#32422;&#26463;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#37096;&#20998;&#25968;&#25454;&#35206;&#30422;&#20551;&#35774;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#35745;&#31639;&#25928;&#29575;&#24182;&#36798;&#21040;&#20102;$O(\epsilon^{-2})$&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#27492;&#22806;&#65292;&#35813;&#31639;&#27861;&#36824;&#25903;&#25345;&#39069;&#22806;&#22870;&#21169;&#20449;&#21495;&#30340;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26088;&#22312;&#36890;&#36807;&#39044;&#20808;&#25910;&#38598;&#30340;&#25968;&#25454;&#38598;&#23398;&#20064;&#19968;&#31181;&#26368;&#22823;&#21270;&#26399;&#26395;&#32047;&#31215;&#22870;&#21169;&#30340;&#31574;&#30053;&#12290;&#26368;&#36817;&#65292;&#23545;&#20110;&#20302;&#31209;MDPs&#25110;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#36827;&#34892;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#26159;&#29616;&#26377;&#31639;&#27861;&#22312;&#25214;&#21040;$\epsilon$-&#20248;&#21270;&#31574;&#30053;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$O(\epsilon^{-2})$&#26102;&#65292;&#35201;&#20040;&#38656;&#35201;&#22343;&#21248;&#30340;&#25968;&#25454;&#35206;&#30422;&#20551;&#35774;&#65292;&#35201;&#20040;&#35745;&#31639;&#25928;&#29575;&#20302;&#19979;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#25240;&#25187;&#26080;&#31351;&#26102;&#27573;&#35774;&#32622;&#19979;&#65292;&#29992;&#20110;&#20302;&#31209;MDPs&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#22522;&#26412;&#23545;&#20598;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#26159;&#22312;&#37096;&#20998;&#25968;&#25454;&#35206;&#30422;&#20551;&#35774;&#19979;&#65292;&#35813;&#35774;&#32622;&#20013;&#31532;&#19968;&#20010;&#26679;&#26412;&#22797;&#26434;&#24230;&#36798;&#21040;$O(\epsilon^{-2})$&#30340;&#35745;&#31639;&#26377;&#25928;&#30340;&#31639;&#27861;&#12290;&#36825;&#20248;&#20110;&#26368;&#36817;&#30340;&#19968;&#39033;&#24037;&#20316;&#65292;&#20854;&#38656;&#35201;$O(\epsilon^{-4})$&#20010;&#26679;&#26412;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#36890;&#36807;&#25903;&#25345;&#39069;&#22806;&#22870;&#21169;&#20449;&#21495;&#30340;&#32422;&#26463;&#65292;&#23558;&#20043;&#21069;&#30340;&#24037;&#20316;&#25193;&#23637;&#21040;&#31163;&#32447;&#32422;&#26463;&#24378;&#21270;&#23398;&#20064;&#35774;&#32622;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Offline reinforcement learning (RL) aims to learn a policy that maximizes the expected cumulative reward using a pre-collected dataset. Offline RL with low-rank MDPs or general function approximation has been widely studied recently, but existing algorithms with sample complexity $O(\epsilon^{-2})$ for finding an $\epsilon$-optimal policy either require a uniform data coverage assumptions or are computationally inefficient. In this paper, we propose a primal dual algorithm for offline RL with low-rank MDPs in the discounted infinite-horizon setting. Our algorithm is the first computationally efficient algorithm in this setting that achieves sample complexity of $O(\epsilon^{-2})$ with partial data coverage assumption. This improves upon a recent work that requires $O(\epsilon^{-4})$ samples. Moreover, our algorithm extends the previous work to the offline constrained RL setting by supporting constraints on additional reward signals.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#23616;&#37096;&#30456;&#20851;&#24615;&#35299;&#37322;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#22522;&#20110;&#25968;&#25454;&#27969;&#24418;&#19978;&#30340;&#36317;&#31163;&#36827;&#34892;&#32858;&#31867;&#65292;&#24182;&#20351;&#29992;&#24635;&#30456;&#20851;&#24615;&#26469;&#25429;&#33719;&#39640;&#38454;&#21464;&#37327;&#20043;&#38388;&#30340;&#20132;&#20114;&#12290;&#36890;&#36807;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#20013;&#24212;&#29992;&#35813;&#26041;&#27861;&#65292;&#21487;&#20197;&#25552;&#21462;&#20851;&#20110;&#25968;&#25454;&#32467;&#26500;&#30340;&#38544;&#34255;&#27934;&#23519;&#21147;&#65292;&#24182;&#29992;&#20110;&#25506;&#32034;&#21644;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#30340;&#20869;&#37096;&#36816;&#20316;&#12290;</title><link>https://arxiv.org/abs/2402.04440</link><description>&lt;p&gt;
&#25506;&#32034;&#20855;&#26377;&#24635;&#30456;&#20851;&#24615;&#30340;&#39640;&#38454;&#31070;&#32463;&#32593;&#32476;&#33410;&#28857;&#20132;&#20114;
&lt;/p&gt;
&lt;p&gt;
Exploring higher-order neural network node interactions with total correlation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04440
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#23616;&#37096;&#30456;&#20851;&#24615;&#35299;&#37322;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#22522;&#20110;&#25968;&#25454;&#27969;&#24418;&#19978;&#30340;&#36317;&#31163;&#36827;&#34892;&#32858;&#31867;&#65292;&#24182;&#20351;&#29992;&#24635;&#30456;&#20851;&#24615;&#26469;&#25429;&#33719;&#39640;&#38454;&#21464;&#37327;&#20043;&#38388;&#30340;&#20132;&#20114;&#12290;&#36890;&#36807;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#20013;&#24212;&#29992;&#35813;&#26041;&#27861;&#65292;&#21487;&#20197;&#25552;&#21462;&#20851;&#20110;&#25968;&#25454;&#32467;&#26500;&#30340;&#38544;&#34255;&#27934;&#23519;&#21147;&#65292;&#24182;&#29992;&#20110;&#25506;&#32034;&#21644;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#30340;&#20869;&#37096;&#36816;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29983;&#24577;&#31995;&#32479;&#12289;&#21327;&#20316;&#21644;&#20154;&#33041;&#31561;&#39046;&#22495;&#20013;&#65292;&#21464;&#37327;&#20197;&#22797;&#26434;&#30340;&#26041;&#24335;&#30456;&#20114;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#20934;&#30830;&#22320;&#25551;&#36848;&#39640;&#38454;&#21464;&#37327;&#20043;&#38388;&#30340;&#20132;&#20114;&#26159;&#19968;&#20010;&#22256;&#38590;&#30340;&#38382;&#39064;&#65292;&#23588;&#20854;&#26159;&#24403;&#36825;&#20123;&#20132;&#20114;&#38543;&#30528;&#25968;&#25454;&#30340;&#21464;&#21270;&#32780;&#25913;&#21464;&#26102;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#23616;&#37096;&#30456;&#20851;&#24615;&#35299;&#37322;&#65288;CorEx&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#39318;&#20808;&#22522;&#20110;&#25968;&#25454;&#27969;&#24418;&#19978;&#30340;&#36317;&#31163;&#26469;&#23545;&#25968;&#25454;&#28857;&#36827;&#34892;&#32858;&#31867;&#65292;&#20174;&#32780;&#22312;&#23616;&#37096;&#23610;&#24230;&#19978;&#25429;&#33719;&#39640;&#38454;&#20132;&#20114;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#31181;&#31216;&#20026;&#24635;&#30456;&#20851;&#24615;&#30340;&#22810;&#20803;&#20114;&#20449;&#24687;&#30340;&#21464;&#20307;&#26469;&#26500;&#24314;&#25968;&#25454;&#22312;&#27599;&#20010;&#32858;&#31867;&#20013;&#30340;&#28508;&#22312;&#22240;&#23376;&#34920;&#31034;&#65292;&#20197;&#23398;&#20064;&#23616;&#37096;&#30340;&#20132;&#20114;&#12290;&#25105;&#20204;&#20351;&#29992;&#23616;&#37096;&#30456;&#20851;&#24615;&#35299;&#37322;&#26469;&#25506;&#32034;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#20013;&#30340;&#39640;&#38454;&#20132;&#20114;&#65292;&#20197;&#25552;&#21462;&#20851;&#20110;&#25968;&#25454;&#32467;&#26500;&#30340;&#38544;&#34255;&#27934;&#23519;&#21147;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23616;&#37096;&#30456;&#20851;&#24615;&#35299;&#37322;&#30340;&#36866;&#29992;&#24615;&#65292;&#29992;&#20110;&#25506;&#32034;&#21644;&#35299;&#37322;&#35757;&#32451;&#22909;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#20869;&#37096;&#36816;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
In domains such as ecological systems, collaborations, and the human brain the variables interact in complex ways. Yet accurately characterizing higher-order variable interactions (HOIs) is a difficult problem that is further exacerbated when the HOIs change across the data. To solve this problem we propose a new method called Local Correlation Explanation (CorEx) to capture HOIs at a local scale by first clustering data points based on their proximity on the data manifold. We then use a multivariate version of the mutual information called the total correlation, to construct a latent factor representation of the data within each cluster to learn the local HOIs. We use Local CorEx to explore HOIs in synthetic and real world data to extract hidden insights about the data structure. Lastly, we demonstrate Local CorEx's suitability to explore and interpret the inner workings of trained neural networks.
&lt;/p&gt;</description></item><item><title>&#36830;&#32493;&#22810;&#32500;&#26631;&#24230;&#26159;&#20851;&#20110;&#23558;&#36317;&#31163;&#20449;&#24687;&#23884;&#20837;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#30340;&#36807;&#31243;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#23545;&#35937;&#38598;&#19981;&#26029;&#22686;&#21152;&#30340;&#24773;&#20917;&#19979;&#65292;&#23558;&#25972;&#20010;&#23884;&#20837;&#38382;&#39064;&#24207;&#21015;&#35270;&#20026;&#19968;&#20010;&#22266;&#23450;&#31354;&#38388;&#20013;&#30340;&#19968;&#31995;&#21015;&#20248;&#21270;&#38382;&#39064;&#30340;&#26041;&#27861;&#21644;&#32467;&#35770;&#12290;</title><link>https://arxiv.org/abs/2402.04436</link><description>&lt;p&gt;
&#36830;&#32493;&#22810;&#32500;&#26631;&#24230;
&lt;/p&gt;
&lt;p&gt;
Continuous Multidimensional Scaling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04436
&lt;/p&gt;
&lt;p&gt;
&#36830;&#32493;&#22810;&#32500;&#26631;&#24230;&#26159;&#20851;&#20110;&#23558;&#36317;&#31163;&#20449;&#24687;&#23884;&#20837;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#30340;&#36807;&#31243;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#23545;&#35937;&#38598;&#19981;&#26029;&#22686;&#21152;&#30340;&#24773;&#20917;&#19979;&#65292;&#23558;&#25972;&#20010;&#23884;&#20837;&#38382;&#39064;&#24207;&#21015;&#35270;&#20026;&#19968;&#20010;&#22266;&#23450;&#31354;&#38388;&#20013;&#30340;&#19968;&#31995;&#21015;&#20248;&#21270;&#38382;&#39064;&#30340;&#26041;&#27861;&#21644;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#32500;&#26631;&#24230;(MDS)&#26159;&#23558;&#20851;&#20110;&#19968;&#32452;$n$&#20010;&#23545;&#35937;&#30340;&#36317;&#31163;&#20449;&#24687;&#23884;&#20837;&#21040;$d$&#32500;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#30340;&#36807;&#31243;&#12290;&#26368;&#21021;&#30001;&#24515;&#29702;&#27979;&#37327;&#23398;&#30028;&#26500;&#24605;&#65292;MDS&#20851;&#27880;&#30340;&#26159;&#23884;&#20837;&#21040;&#19968;&#32452;&#22266;&#23450;&#23545;&#35937;&#19978;&#30340;&#19968;&#32452;&#22266;&#23450;&#36317;&#31163;&#12290;&#29616;&#20195;&#20851;&#27880;&#30340;&#38382;&#39064;&#26356;&#24120;&#28041;&#21450;&#21040;&#30740;&#31350;&#19982;&#19968;&#32452;&#19981;&#26029;&#22686;&#21152;&#30340;&#23545;&#35937;&#30456;&#20851;&#32852;&#30340;&#19968;&#31995;&#21015;&#36317;&#31163;&#30340;&#26497;&#38480;&#34892;&#20026;&#65292;&#22914;&#22312;&#38543;&#26426;&#22270;&#30340;&#32479;&#35745;&#25512;&#26029;&#30340;&#28176;&#36817;&#29702;&#35770;&#20013;&#20986;&#29616;&#30340;&#38382;&#39064;&#12290;&#28857;&#21040;&#38598;&#21512;&#26144;&#23556;&#29702;&#35770;&#20013;&#30340;&#26631;&#20934;&#32467;&#26524;&#34920;&#26126;&#65292;&#33509;$n$&#22266;&#23450;&#65292;&#21017;&#23884;&#20837;&#32467;&#26500;&#30340;&#26497;&#38480;&#26159;&#26497;&#38480;&#36317;&#31163;&#30340;&#23884;&#20837;&#32467;&#26500;&#12290;&#20294;&#22914;&#26524;$n$&#22686;&#21152;&#24590;&#20040;&#21150;&#21602;&#65311;&#37027;&#20040;&#23601;&#38656;&#35201;&#37325;&#26032;&#21046;&#23450;MDS&#65292;&#20197;&#20415;&#23558;&#25972;&#20010;&#23884;&#20837;&#38382;&#39064;&#24207;&#21015;&#35270;&#20026;&#19968;&#20010;&#22266;&#23450;&#31354;&#38388;&#20013;&#30340;&#19968;&#31995;&#21015;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#36825;&#26679;&#19968;&#31181;&#37325;&#26032;&#21046;&#23450;&#65292;&#24182;&#25512;&#23548;&#20986;&#19968;&#20123;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multidimensional scaling (MDS) is the act of embedding proximity information about a set of $n$ objects in $d$-dimensional Euclidean space. As originally conceived by the psychometric community, MDS was concerned with embedding a fixed set of proximities associated with a fixed set of objects. Modern concerns, e.g., that arise in developing asymptotic theories for statistical inference on random graphs, more typically involve studying the limiting behavior of a sequence of proximities associated with an increasing set of objects. Standard results from the theory of point-to-set maps imply that, if $n$ is fixed, then the limit of the embedded structures is the embedded structure of the limiting proximities. But what if $n$ increases? It then becomes necessary to reformulate MDS so that the entire sequence of embedding problems can be viewed as a sequence of optimization problems in a fixed space. We present such a reformulation and derive some consequences.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#22312;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;CUSUM&#36807;&#31243;&#30340;&#39640;&#21152;&#26435;&#32479;&#35745;&#37327;&#65292;&#20197;&#30830;&#20445;&#21450;&#26102;&#26816;&#27979;&#21040;&#26089;&#26399;&#21457;&#29983;&#30340;&#21464;&#28857;&#12290;&#36890;&#36807;&#20351;&#29992;&#19981;&#21516;&#30340;&#21152;&#26435;&#26041;&#26696;&#26500;&#36896;&#22797;&#21512;&#32479;&#35745;&#37327;&#65292;&#24182;&#20351;&#29992;&#26368;&#22823;&#32479;&#35745;&#37327;&#20316;&#20026;&#26631;&#35760;&#21464;&#28857;&#30340;&#20915;&#31574;&#35268;&#21017;&#65292;&#23454;&#29616;&#20102;&#24555;&#36895;&#26816;&#27979;&#26080;&#35770;&#21464;&#28857;&#20301;&#32622;&#22312;&#21738;&#37324;&#12290;&#27492;&#26041;&#27861;&#36866;&#29992;&#20110;&#20960;&#20046;&#25152;&#26377;&#32463;&#27982;&#23398;&#12289;&#21307;&#23398;&#21644;&#20854;&#20182;&#24212;&#29992;&#31185;&#23398;&#20013;&#30340;&#26102;&#38388;&#24207;&#21015;&#12290;&#22312;&#33945;&#29305;&#21345;&#32599;&#27169;&#25311;&#20013;&#39564;&#35777;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.04433</link><description>&lt;p&gt;
&#24555;&#36895;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Fast Online Changepoint Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04433
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#22312;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;CUSUM&#36807;&#31243;&#30340;&#39640;&#21152;&#26435;&#32479;&#35745;&#37327;&#65292;&#20197;&#30830;&#20445;&#21450;&#26102;&#26816;&#27979;&#21040;&#26089;&#26399;&#21457;&#29983;&#30340;&#21464;&#28857;&#12290;&#36890;&#36807;&#20351;&#29992;&#19981;&#21516;&#30340;&#21152;&#26435;&#26041;&#26696;&#26500;&#36896;&#22797;&#21512;&#32479;&#35745;&#37327;&#65292;&#24182;&#20351;&#29992;&#26368;&#22823;&#32479;&#35745;&#37327;&#20316;&#20026;&#26631;&#35760;&#21464;&#28857;&#30340;&#20915;&#31574;&#35268;&#21017;&#65292;&#23454;&#29616;&#20102;&#24555;&#36895;&#26816;&#27979;&#26080;&#35770;&#21464;&#28857;&#20301;&#32622;&#22312;&#21738;&#37324;&#12290;&#27492;&#26041;&#27861;&#36866;&#29992;&#20110;&#20960;&#20046;&#25152;&#26377;&#32463;&#27982;&#23398;&#12289;&#21307;&#23398;&#21644;&#20854;&#20182;&#24212;&#29992;&#31185;&#23398;&#20013;&#30340;&#26102;&#38388;&#24207;&#21015;&#12290;&#22312;&#33945;&#29305;&#21345;&#32599;&#27169;&#25311;&#20013;&#39564;&#35777;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#22312;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#30340;&#32972;&#26223;&#19979;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31867;&#22522;&#20110;&#22238;&#24402;&#27531;&#24046;&#30340;&#32047;&#31215;&#21644;&#65288;CUSUM&#65289;&#36807;&#31243;&#30340;&#39640;&#21152;&#26435;&#32479;&#35745;&#37327;&#65292;&#36825;&#20123;&#32479;&#35745;&#37327;&#19987;&#38376;&#35774;&#35745;&#29992;&#20110;&#30830;&#20445;&#22312;&#30417;&#27979;&#26102;&#38388;&#27573;&#30340;&#26089;&#26399;&#21450;&#26102;&#26816;&#27979;&#21040;&#21464;&#28857;&#12290;&#25105;&#20204;&#38543;&#21518;&#25552;&#20986;&#20102;&#19968;&#31867;&#22797;&#21512;&#32479;&#35745;&#37327;&#65292;&#20351;&#29992;&#19981;&#21516;&#30340;&#21152;&#26435;&#26041;&#26696;&#26500;&#36896;&#65307;&#26631;&#35760;&#21464;&#28857;&#30340;&#20915;&#31574;&#35268;&#21017;&#22522;&#20110;&#21508;&#20010;&#26435;&#37325;&#20013;&#26368;&#22823;&#30340;&#32479;&#35745;&#37327;&#65292;&#20174;&#32780;&#26377;&#25928;&#22320;&#20687;&#21542;&#20915;&#21046;&#25237;&#31080;&#26426;&#21046;&#19968;&#26679;&#24037;&#20316;&#65292;&#30830;&#20445;&#26080;&#35770;&#21464;&#28857;&#20301;&#32622;&#22312;&#21738;&#37324;&#65292;&#37117;&#33021;&#24555;&#36895;&#26816;&#27979;&#21040;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#25512;&#23548;&#22522;&#20110;&#19968;&#31181;&#38750;&#24120;&#26222;&#36941;&#30340;&#24369;&#30456;&#20851;&#24615;&#24418;&#24335;&#65292;&#22240;&#27492;&#33021;&#22815;&#23558;&#25105;&#20204;&#30340;&#27979;&#35797;&#24212;&#29992;&#20110;&#32463;&#27982;&#23398;&#12289;&#21307;&#23398;&#21644;&#20854;&#20182;&#24212;&#29992;&#31185;&#23398;&#20013;&#36935;&#21040;&#30340;&#20960;&#20046;&#25152;&#26377;&#26102;&#38388;&#24207;&#21015;&#12290;&#33945;&#29305;&#21345;&#32599;&#27169;&#25311;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#25511;&#21046;&#31243;&#24207;&#32423;&#21035;&#30340;I&#22411;&#38169;&#35823;&#65292;&#24182;&#19988;&#22312;&#23384;&#22312;&#21464;&#28857;&#26102;&#20855;&#26377;&#36739;&#30701;&#30340;&#26816;&#27979;&#24310;&#36831;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study online changepoint detection in the context of a linear regression model. We propose a class of heavily weighted statistics based on the CUSUM process of the regression residuals, which are specifically designed to ensure timely detection of breaks occurring early on during the monitoring horizon. We subsequently propose a class of composite statistics, constructed using different weighing schemes; the decision rule to mark a changepoint is based on the largest statistic across the various weights, thus effectively working like a veto-based voting mechanism, which ensures fast detection irrespective of the location of the changepoint. Our theory is derived under a very general form of weak dependence, thus being able to apply our tests to virtually all time series encountered in economics, medicine, and other applied sciences. Monte Carlo simulations show that our methodologies are able to control the procedure-wise Type I Error, and have short detection delays in the presence
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;VampPrior&#28151;&#21512;&#27169;&#22411;&#65288;VMM&#65289;&#65292;&#23427;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;DLVM&#20808;&#39564;&#65292;&#21487;&#29992;&#20110;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#38598;&#25104;&#21644;&#32858;&#31867;&#65292;&#36890;&#36807;&#25913;&#21892;&#24403;&#21069;&#32858;&#31867;&#20808;&#39564;&#30340;&#19981;&#36275;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#28165;&#26224;&#21306;&#20998;&#21464;&#20998;&#21644;&#20808;&#39564;&#21442;&#25968;&#30340;&#25512;&#29702;&#36807;&#31243;&#12290;&#20351;&#29992;VMM&#30340;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#24378;&#22823;&#30340;&#32858;&#31867;&#24615;&#33021;&#65292;&#23558;VMM&#19982;scVI&#30456;&#32467;&#21512;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#20854;&#24615;&#33021;&#65292;&#24182;&#33258;&#21160;&#23558;&#32454;&#32990;&#20998;&#32452;&#20026;&#20855;&#26377;&#29983;&#29289;&#24847;&#20041;&#30340;&#32858;&#31867;&#12290;</title><link>https://arxiv.org/abs/2402.04412</link><description>&lt;p&gt;
VampPrior&#28151;&#21512;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
The VampPrior Mixture Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04412
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;VampPrior&#28151;&#21512;&#27169;&#22411;&#65288;VMM&#65289;&#65292;&#23427;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;DLVM&#20808;&#39564;&#65292;&#21487;&#29992;&#20110;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#38598;&#25104;&#21644;&#32858;&#31867;&#65292;&#36890;&#36807;&#25913;&#21892;&#24403;&#21069;&#32858;&#31867;&#20808;&#39564;&#30340;&#19981;&#36275;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#28165;&#26224;&#21306;&#20998;&#21464;&#20998;&#21644;&#20808;&#39564;&#21442;&#25968;&#30340;&#25512;&#29702;&#36807;&#31243;&#12290;&#20351;&#29992;VMM&#30340;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#24378;&#22823;&#30340;&#32858;&#31867;&#24615;&#33021;&#65292;&#23558;VMM&#19982;scVI&#30456;&#32467;&#21512;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#20854;&#24615;&#33021;&#65292;&#24182;&#33258;&#21160;&#23558;&#32454;&#32990;&#20998;&#32452;&#20026;&#20855;&#26377;&#29983;&#29289;&#24847;&#20041;&#30340;&#32858;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#29992;&#20110;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#65288;DLVMs&#65289;&#30340;&#32858;&#31867;&#20808;&#39564;&#38656;&#35201;&#39044;&#20808;&#23450;&#20041;&#32858;&#31867;&#30340;&#25968;&#37327;&#65292;&#24182;&#19988;&#23481;&#26131;&#21463;&#21040;&#36739;&#24046;&#30340;&#21021;&#22987;&#21270;&#30340;&#24433;&#21709;&#12290;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#21487;&#20197;&#36890;&#36807;&#21516;&#26102;&#25191;&#34892;&#38598;&#25104;&#21644;&#32858;&#31867;&#30340;&#26041;&#24335;&#26497;&#22823;&#22320;&#25913;&#36827;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;scRNA-seq&#20998;&#26512;&#12290;&#25105;&#20204;&#23558;VampPrior&#65288;Tomczak&#21644;Welling&#65292;2018&#65289;&#35843;&#25972;&#20026;Dirichlet&#36807;&#31243;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65292;&#24471;&#21040;VampPrior&#28151;&#21512;&#27169;&#22411;&#65288;VMM&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;DLVM&#20808;&#39564;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25512;&#29702;&#36807;&#31243;&#65292;&#20132;&#26367;&#20351;&#29992;&#21464;&#20998;&#25512;&#29702;&#21644;&#32463;&#39564;&#36125;&#21494;&#26031;&#65292;&#20197;&#28165;&#26970;&#22320;&#21306;&#20998;&#21464;&#20998;&#21644;&#20808;&#39564;&#21442;&#25968;&#12290;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#20351;&#29992;VMM&#30340;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#33719;&#24471;&#20102;&#26497;&#20855;&#31454;&#20105;&#21147;&#30340;&#32858;&#31867;&#24615;&#33021;&#12290;&#23558;VMM&#19982;&#24191;&#21463;&#27426;&#36814;&#30340;scRNA-seq&#38598;&#25104;&#26041;&#27861;scVI&#65288;Lopez&#31561;&#65292;2018&#65289;&#30456;&#32467;&#21512;&#65292;&#26174;&#33879;&#25913;&#21892;&#20102;&#20854;&#24615;&#33021;&#65292;&#24182;&#33258;&#21160;&#23558;&#32454;&#32990;&#20998;&#32452;&#20026;&#20855;&#26377;&#29983;&#29289;&#24847;&#20041;&#30340;&#32858;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
Current clustering priors for deep latent variable models (DLVMs) require defining the number of clusters a-priori and are susceptible to poor initializations. Addressing these deficiencies could greatly benefit deep learning-based scRNA-seq analysis by performing integration and clustering simultaneously. We adapt the VampPrior (Tomczak &amp; Welling, 2018) into a Dirichlet process Gaussian mixture model, resulting in the VampPrior Mixture Model (VMM), a novel prior for DLVMs. We propose an inference procedure that alternates between variational inference and Empirical Bayes to cleanly distinguish variational and prior parameters. Using the VMM in a Variational Autoencoder attains highly competitive clustering performance on benchmark datasets. Augmenting scVI (Lopez et al., 2018), a popular scRNA-seq integration method, with the VMM significantly improves its performance and automatically arranges cells into biologically meaningful clusters.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#26102;&#38388;&#24207;&#21015;&#19979;&#22788;&#29702;&#26102;&#38388;&#26631;&#31614;&#22122;&#22768;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#20174;&#25968;&#25454;&#20013;&#30452;&#25509;&#20272;&#35745;&#26102;&#38388;&#26631;&#31614;&#22122;&#22768;&#20989;&#25968;&#24182;&#35757;&#32451;&#20986;&#22122;&#22768;&#23481;&#24525;&#20998;&#31867;&#22120;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22312;&#21508;&#31181;&#26102;&#38388;&#26631;&#31614;&#22122;&#22768;&#20989;&#25968;&#19979;&#37117;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.04398</link><description>&lt;p&gt;
&#23398;&#20064;&#22312;&#26102;&#38388;&#24207;&#21015;&#19979;&#22788;&#29702;&#26102;&#38388;&#26631;&#31614;&#22122;&#22768;
&lt;/p&gt;
&lt;p&gt;
Learning from Time Series under Temporal Label Noise
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04398
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#26102;&#38388;&#24207;&#21015;&#19979;&#22788;&#29702;&#26102;&#38388;&#26631;&#31614;&#22122;&#22768;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#20174;&#25968;&#25454;&#20013;&#30452;&#25509;&#20272;&#35745;&#26102;&#38388;&#26631;&#31614;&#22122;&#22768;&#20989;&#25968;&#24182;&#35757;&#32451;&#20986;&#22122;&#22768;&#23481;&#24525;&#20998;&#31867;&#22120;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22312;&#21508;&#31181;&#26102;&#38388;&#26631;&#31614;&#22122;&#22768;&#20989;&#25968;&#19979;&#37117;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#39034;&#24207;&#20998;&#31867;&#20219;&#21153;&#21463;&#21040;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#26631;&#31614;&#22122;&#22768;&#30340;&#24433;&#21709;&#12290;&#36825;&#31181;&#22122;&#22768;&#21487;&#33021;&#20250;&#23548;&#33268;&#26631;&#31614;&#36136;&#37327;&#38543;&#26102;&#38388;&#25913;&#21892;&#12289;&#24694;&#21270;&#25110;&#21608;&#26399;&#24615;&#21464;&#21270;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#21644;&#31995;&#32479;&#21270;&#20102;&#26102;&#38388;&#26631;&#31614;&#22122;&#22768;&#30340;&#27010;&#24565;&#65292;&#36825;&#26159;&#20851;&#20110;&#26102;&#38388;&#24207;&#21015;&#39034;&#24207;&#20998;&#31867;&#30340;&#19968;&#20010;&#26410;&#32463;&#30740;&#31350;&#30340;&#38382;&#39064;&#12290;&#22312;&#36825;&#31181;&#35774;&#32622;&#19979;&#65292;&#22810;&#20010;&#26631;&#31614;&#36830;&#32493;&#35760;&#24405;&#65292;&#21516;&#26102;&#21463;&#21040;&#19968;&#20010;&#19982;&#26102;&#38388;&#30456;&#20851;&#30340;&#22122;&#22768;&#20989;&#25968;&#30340;&#24178;&#25200;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#24314;&#27169;&#26102;&#38388;&#26631;&#31614;&#22122;&#22768;&#20989;&#25968;&#30340;&#37325;&#35201;&#24615;&#65292;&#20197;&#21450;&#29616;&#26377;&#26041;&#27861;&#30340;&#25345;&#32493;&#20302;&#25928;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#30452;&#25509;&#20174;&#25968;&#25454;&#20013;&#20272;&#35745;&#26102;&#38388;&#26631;&#31614;&#22122;&#22768;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#35757;&#32451;&#20986;&#23545;&#22122;&#22768;&#20855;&#26377;&#23481;&#24525;&#24615;&#30340;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21508;&#31181;&#21508;&#26679;&#30340;&#26102;&#38388;&#26631;&#31614;&#22122;&#22768;&#20989;&#25968;&#19979;&#65292;&#20351;&#29992;&#30495;&#23454;&#21644;&#21512;&#25104;&#25968;&#25454;&#22312;&#24615;&#33021;&#19978;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many sequential classification tasks are affected by label noise that varies over time. Such noise can cause label quality to improve, worsen, or periodically change over time. We first propose and formalize temporal label noise, an unstudied problem for sequential classification of time series. In this setting, multiple labels are recorded in sequence while being corrupted by a time-dependent noise function. We first demonstrate the importance of modelling the temporal nature of the label noise function and how existing methods will consistently underperform. We then propose methods that can train noise-tolerant classifiers by estimating the temporal label noise function directly from data. We show that our methods lead to state-of-the-art performance in the presence of diverse temporal label noise functions using real and synthetic data.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#21333;&#12289;&#20840;&#38754;&#12289;&#24178;&#20928;&#19988;&#28165;&#26224;&#30340;&#20171;&#32461;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DDPM&#65289;&#30340;&#26041;&#27861;&#65292;&#24378;&#35843;&#20102;&#20174;&#36830;&#32493;&#26102;&#38388;&#26497;&#38480;&#30340;&#35270;&#35282;&#20986;&#21457;&#65292;&#20197;&#25552;&#20379;&#26356;&#22909;&#30340;&#29702;&#35299;&#21644;&#23454;&#38469;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.04384</link><description>&lt;p&gt;
&#22312;&#20845;&#20010;&#31616;&#21333;&#30340;&#27493;&#39588;&#20013;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Denoising Diffusion Probabilistic Models in Six Simple Steps
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04384
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#21333;&#12289;&#20840;&#38754;&#12289;&#24178;&#20928;&#19988;&#28165;&#26224;&#30340;&#20171;&#32461;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DDPM&#65289;&#30340;&#26041;&#27861;&#65292;&#24378;&#35843;&#20102;&#20174;&#36830;&#32493;&#26102;&#38388;&#26497;&#38480;&#30340;&#35270;&#35282;&#20986;&#21457;&#65292;&#20197;&#25552;&#20379;&#26356;&#22909;&#30340;&#29702;&#35299;&#21644;&#23454;&#38469;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DDPM&#65289;&#26159;&#19968;&#31867;&#38750;&#24120;&#27969;&#34892;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#24050;&#25104;&#21151;&#24212;&#29992;&#20110;&#21253;&#25324;&#22270;&#20687;&#21644;&#35270;&#39057;&#29983;&#25104;&#12289;&#34507;&#30333;&#36136;&#21644;&#26448;&#26009;&#21512;&#25104;&#12289;&#22825;&#27668;&#39044;&#27979;&#21644;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#31070;&#32463;&#26367;&#20195;&#31561;&#22810;&#20010;&#38382;&#39064;&#12290;&#23613;&#31649;&#20854;&#26222;&#21450;&#24230;&#24456;&#39640;&#65292;&#20294;&#24456;&#38590;&#25214;&#21040;&#19968;&#20010;&#31616;&#21333;&#12289;&#20840;&#38754;&#12289;&#24178;&#20928;&#19988;&#28165;&#26224;&#30340;DDPM&#20171;&#32461;&#12290;&#30740;&#31350;&#35770;&#25991;&#20013;&#24517;&#35201;&#30340;&#31616;&#27905;&#35299;&#37322;&#26080;&#27861;&#38416;&#26126;&#21046;&#23450;DDPM&#25152;&#37319;&#21462;&#30340;&#19981;&#21516;&#35774;&#35745;&#27493;&#39588;&#20197;&#21450;&#30465;&#30053;&#20102;&#27493;&#39588;&#30340;&#29702;&#30001;&#20197;&#33410;&#30465;&#31354;&#38388;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#35770;&#36848;&#36890;&#24120;&#20174;&#21464;&#20998;&#19979;&#30028;&#30340;&#35270;&#35282;&#20986;&#21457;&#65292;&#36825;&#26159;&#19981;&#24517;&#35201;&#19988;&#21487;&#33021;&#26377;&#23475;&#30340;&#65292;&#22240;&#20026;&#23427;&#28151;&#28102;&#20102;&#26041;&#27861;&#22863;&#25928;&#30340;&#21407;&#22240;&#24182;&#26263;&#31034;&#20102;&#23454;&#36341;&#20013;&#34920;&#29616;&#19981;&#20339;&#30340;&#27867;&#21270;&#24615;&#36136;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#37319;&#29992;&#36830;&#32493;&#26102;&#38388;&#26497;&#38480;&#30340;&#35270;&#35282;&#26159;&#32654;&#20029;&#19988;&#26222;&#36941;&#30340;&#65292;&#20294;&#26159;...
&lt;/p&gt;
&lt;p&gt;
Denoising Diffusion Probabilistic Models (DDPMs) are a very popular class of deep generative model that have been successfully applied to a diverse range of problems including image and video generation, protein and material synthesis, weather forecasting, and neural surrogates of partial differential equations. Despite their ubiquity it is hard to find an introduction to DDPMs which is simple, comprehensive, clean and clear. The compact explanations necessary in research papers are not able to elucidate all of the different design steps taken to formulate the DDPM and the rationale of the steps that are presented is often omitted to save space. Moreover, the expositions are typically presented from the variational lower bound perspective which is unnecessary and arguably harmful as it obfuscates why the method is working and suggests generalisations that do not perform well in practice. On the other hand, perspectives that take the continuous time-limit are beautiful and general, but 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#23558;&#26367;&#20195;&#25968;&#25454;&#19982;&#30495;&#23454;&#25968;&#25454;&#25972;&#21512;&#20197;&#36827;&#34892;&#35757;&#32451;&#30340;&#26041;&#26696;&#65292;&#21457;&#29616;&#25972;&#21512;&#26367;&#20195;&#25968;&#25454;&#33021;&#22815;&#26174;&#33879;&#38477;&#20302;&#27979;&#35797;&#35823;&#24046;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#25193;&#23637;&#35268;&#24459;&#26469;&#25551;&#36848;&#28151;&#21512;&#27169;&#22411;&#30340;&#27979;&#35797;&#35823;&#24046;&#65292;&#21487;&#20197;&#29992;&#20110;&#39044;&#27979;&#26368;&#20248;&#21152;&#26435;&#21644;&#25910;&#30410;&#12290;</title><link>https://arxiv.org/abs/2402.04376</link><description>&lt;p&gt;
&#20351;&#29992;&#30495;&#23454;&#25968;&#25454;&#21644;&#26367;&#20195;&#25968;&#25454;&#36827;&#34892;&#23398;&#20064;&#30340;&#25193;&#23637;&#35268;&#24459;
&lt;/p&gt;
&lt;p&gt;
Scaling laws for learning with real and surrogate data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04376
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#23558;&#26367;&#20195;&#25968;&#25454;&#19982;&#30495;&#23454;&#25968;&#25454;&#25972;&#21512;&#20197;&#36827;&#34892;&#35757;&#32451;&#30340;&#26041;&#26696;&#65292;&#21457;&#29616;&#25972;&#21512;&#26367;&#20195;&#25968;&#25454;&#33021;&#22815;&#26174;&#33879;&#38477;&#20302;&#27979;&#35797;&#35823;&#24046;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#25193;&#23637;&#35268;&#24459;&#26469;&#25551;&#36848;&#28151;&#21512;&#27169;&#22411;&#30340;&#27979;&#35797;&#35823;&#24046;&#65292;&#21487;&#20197;&#29992;&#20110;&#39044;&#27979;&#26368;&#20248;&#21152;&#26435;&#21644;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25910;&#38598;&#22823;&#37327;&#39640;&#36136;&#37327;&#30340;&#25968;&#25454;&#36890;&#24120;&#34987;&#38480;&#21046;&#22312;&#25104;&#26412;&#26114;&#36149;&#25110;&#19981;&#20999;&#23454;&#38469;&#30340;&#33539;&#22260;&#20869;, &#36825;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#29942;&#39048;&#12290;&#30456;&#21453;&#22320;, &#21487;&#20197;&#23558;&#26469;&#33258;&#30446;&#26631;&#20998;&#24067;&#30340;&#23567;&#35268;&#27169;&#25968;&#25454;&#38598;&#19982;&#26469;&#33258;&#20844;&#20849;&#25968;&#25454;&#38598;&#12289;&#19981;&#21516;&#24773;&#20917;&#19979;&#25910;&#38598;&#30340;&#25968;&#25454;&#25110;&#30001;&#29983;&#25104;&#27169;&#22411;&#21512;&#25104;&#30340;&#25968;&#25454;&#30456;&#32467;&#21512;, &#20316;&#20026;&#26367;&#20195;&#25968;&#25454;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#26696;&#26469;&#23558;&#26367;&#20195;&#25968;&#25454;&#25972;&#21512;&#21040;&#35757;&#32451;&#20013;, &#24182;&#20351;&#29992;&#29702;&#35770;&#27169;&#22411;&#21644;&#23454;&#35777;&#30740;&#31350;&#25506;&#32034;&#20854;&#34892;&#20026;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#21457;&#29616;&#26159;&#65306;(i) &#25972;&#21512;&#26367;&#20195;&#25968;&#25454;&#21487;&#20197;&#26174;&#33879;&#38477;&#20302;&#21407;&#22987;&#20998;&#24067;&#30340;&#27979;&#35797;&#35823;&#24046;&#65307;(ii) &#20026;&#20102;&#33719;&#24471;&#36825;&#31181;&#25928;&#30410;, &#20351;&#29992;&#26368;&#20248;&#21152;&#26435;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#38750;&#24120;&#20851;&#38190;&#65307;(iii) &#22312;&#28151;&#21512;&#20351;&#29992;&#30495;&#23454;&#25968;&#25454;&#21644;&#26367;&#20195;&#25968;&#25454;&#35757;&#32451;&#30340;&#27169;&#22411;&#30340;&#27979;&#35797;&#35823;&#24046;&#21487;&#20197;&#24456;&#22909;&#22320;&#29992;&#19968;&#20010;&#25193;&#23637;&#35268;&#24459;&#26469;&#25551;&#36848;&#12290;&#36825;&#21487;&#20197;&#29992;&#26469;&#39044;&#27979;&#26368;&#20248;&#21152;&#26435;&#21644;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
Collecting large quantities of high-quality data is often prohibitively expensive or impractical, and a crucial bottleneck in machine learning. One may instead augment a small set of $n$ data points from the target distribution with data from more accessible sources like public datasets, data collected under different circumstances, or synthesized by generative models. Blurring distinctions, we refer to such data as `surrogate data'.   We define a simple scheme for integrating surrogate data into training and use both theoretical models and empirical studies to explore its behavior. Our main findings are: $(i)$ Integrating surrogate data can significantly reduce the test error on the original distribution; $(ii)$ In order to reap this benefit, it is crucial to use optimally weighted empirical risk minimization; $(iii)$ The test error of models trained on mixtures of real and surrogate data is well described by a scaling law. This can be used to predict the optimal weighting and the gai
&lt;/p&gt;</description></item><item><title>PQMass&#26159;&#19968;&#31181;&#20351;&#29992;&#27010;&#29575;&#36136;&#37327;&#20272;&#35745;&#26469;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#36136;&#37327;&#30340;&#20840;&#38754;&#26041;&#27861;&#65292;&#33021;&#22815;&#30452;&#25509;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#65292;&#19981;&#20381;&#36182;&#20110;&#20551;&#35774;&#25110;&#35757;&#32451;&#20854;&#20182;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2402.04355</link><description>&lt;p&gt;
PQMass: &#20351;&#29992;&#27010;&#29575;&#36136;&#37327;&#20272;&#35745;&#30340;&#29983;&#25104;&#27169;&#22411;&#36136;&#37327;&#30340;&#27010;&#29575;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
PQMass: Probabilistic Assessment of the Quality of Generative Models using Probability Mass Estimation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04355
&lt;/p&gt;
&lt;p&gt;
PQMass&#26159;&#19968;&#31181;&#20351;&#29992;&#27010;&#29575;&#36136;&#37327;&#20272;&#35745;&#26469;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#36136;&#37327;&#30340;&#20840;&#38754;&#26041;&#27861;&#65292;&#33021;&#22815;&#30452;&#25509;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#65292;&#19981;&#20381;&#36182;&#20110;&#20551;&#35774;&#25110;&#35757;&#32451;&#20854;&#20182;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#38754;&#30340;&#22522;&#20110;&#26679;&#26412;&#30340;&#26041;&#27861;&#26469;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#30340;&#36136;&#37327;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#33021;&#22815;&#20272;&#35745;&#20004;&#20010;&#26679;&#26412;&#38598;&#21512;&#26469;&#33258;&#21516;&#19968;&#20998;&#24067;&#30340;&#27010;&#29575;&#65292;&#20026;&#35780;&#20272;&#21333;&#20010;&#29983;&#25104;&#27169;&#22411;&#30340;&#24615;&#33021;&#25110;&#27604;&#36739;&#22312;&#21516;&#19968;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#22810;&#20010;&#31454;&#20105;&#27169;&#22411;&#25552;&#20379;&#20102;&#19968;&#20010;&#32479;&#35745;&#19978;&#20005;&#26684;&#30340;&#26041;&#27861;&#12290;&#35813;&#27604;&#36739;&#21487;&#20197;&#36890;&#36807;&#23558;&#31354;&#38388;&#21010;&#20998;&#20026;&#38750;&#37325;&#21472;&#30340;&#21306;&#22495;&#24182;&#27604;&#36739;&#27599;&#20010;&#21306;&#22495;&#20013;&#30340;&#25968;&#25454;&#26679;&#26412;&#25968;&#37327;&#26469;&#36827;&#34892;&#12290;&#35813;&#26041;&#27861;&#20165;&#38656;&#35201;&#29983;&#25104;&#27169;&#22411;&#21644;&#27979;&#35797;&#25968;&#25454;&#30340;&#26679;&#26412;&#12290;&#23427;&#33021;&#22815;&#30452;&#25509;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#65292;&#26080;&#38656;&#38477;&#32500;&#12290;&#26174;&#33879;&#30340;&#26159;&#65292;&#35813;&#26041;&#27861;&#19981;&#20381;&#36182;&#20110;&#20851;&#20110;&#30495;&#23454;&#20998;&#24067;&#23494;&#24230;&#30340;&#20551;&#35774;&#65292;&#24182;&#19988;&#19981;&#20381;&#36182;&#20110;&#35757;&#32451;&#25110;&#25311;&#21512;&#20219;&#20309;&#36741;&#21161;&#27169;&#22411;&#12290;&#30456;&#21453;&#65292;&#23427;&#30528;&#37325;&#20110;&#36817;&#20284;&#35745;&#31639;&#23494;&#24230;&#30340;&#31215;&#20998;&#65288;&#27010;&#29575;&#36136;&#37327;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a comprehensive sample-based method for assessing the quality of generative models. The proposed approach enables the estimation of the probability that two sets of samples are drawn from the same distribution, providing a statistically rigorous method for assessing the performance of a single generative model or the comparison of multiple competing models trained on the same dataset. This comparison can be conducted by dividing the space into non-overlapping regions and comparing the number of data samples in each region. The method only requires samples from the generative model and the test data. It is capable of functioning directly on high-dimensional data, obviating the need for dimensionality reduction. Significantly, the proposed method does not depend on assumptions regarding the density of the true distribution, and it does not rely on training or fitting any auxiliary models. Instead, it focuses on approximating the integral of the density (probability mass) acros
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21040;&#32039;&#25903;&#25345;&#22522;&#30340;&#26680;&#20998;&#32452;&#30340;&#36890;&#29992;&#29702;&#35770;&#65292;&#35813;&#29702;&#35770;&#21487;&#20197;&#29992;&#20110;&#38477;&#20302;&#39640;&#26031;&#36807;&#31243;&#30340;&#35757;&#32451;&#21644;&#39044;&#27979;&#26102;&#38388;&#65292;&#24182;&#19988;&#36890;&#36807;&#36866;&#24403;&#30340;&#32447;&#24615;&#32452;&#21512;&#20135;&#29983;&#20102;$m$&#20010;&#32039;&#25903;&#25345;&#30340;&#26680;&#20998;&#32452;&#20989;&#25968;&#12290;</title><link>https://arxiv.org/abs/2402.04022</link><description>&lt;p&gt;
&#19968;&#31181;&#20174;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21040;&#32039;&#25903;&#25345;&#22522;&#30340;&#26680;&#20998;&#32452;&#30340;&#36890;&#29992;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
A General Theory for Kernel Packets: from state space model to compactly supported basis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04022
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21040;&#32039;&#25903;&#25345;&#22522;&#30340;&#26680;&#20998;&#32452;&#30340;&#36890;&#29992;&#29702;&#35770;&#65292;&#35813;&#29702;&#35770;&#21487;&#20197;&#29992;&#20110;&#38477;&#20302;&#39640;&#26031;&#36807;&#31243;&#30340;&#35757;&#32451;&#21644;&#39044;&#27979;&#26102;&#38388;&#65292;&#24182;&#19988;&#36890;&#36807;&#36866;&#24403;&#30340;&#32447;&#24615;&#32452;&#21512;&#20135;&#29983;&#20102;$m$&#20010;&#32039;&#25903;&#25345;&#30340;&#26680;&#20998;&#32452;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#30340;&#29366;&#24577;&#31354;&#38388;&#65288;SS&#65289;&#27169;&#22411;&#20844;&#24335;&#21487;&#20197;&#23558;&#20854;&#35757;&#32451;&#21644;&#39044;&#27979;&#26102;&#38388;&#38477;&#20302;&#21040;O&#65288;n&#65289;&#65288;n&#20026;&#25968;&#25454;&#28857;&#20010;&#25968;&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;m&#32500;&#30340;GP&#30340;SS&#27169;&#22411;&#20844;&#24335;&#31561;&#20215;&#20110;&#25105;&#20204;&#24341;&#20837;&#30340;&#19968;&#20010;&#27010;&#24565;&#65292;&#31216;&#20026;&#36890;&#29992;&#21491;&#26680;&#20998;&#32452;&#65288;KP&#65289;&#65306;&#19968;&#31181;&#29992;&#20110;GP&#21327;&#26041;&#24046;&#20989;&#25968;K&#30340;&#21464;&#25442;&#65292;&#20351;&#24471;&#23545;&#20110;&#20219;&#24847;$t \leq t_1$&#65292;$0 \leq j \leq m-1$&#21644;$m+1$&#20010;&#36830;&#32493;&#28857;$t_i$&#65292;&#37117;&#28385;&#36275;$\sum_{i=0}^{m}a_iD_t^{(j)}K(t,t_i)=0$&#65292;&#20854;&#20013;${D}_t^{(j)}f(t)$&#34920;&#31034;&#22312;$t$&#19978;&#20316;&#29992;&#30340;&#31532;j&#38454;&#23548;&#25968;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#24605;&#24819;&#25193;&#23637;&#21040;&#20102;GP&#30340;&#21521;&#21518;SS&#27169;&#22411;&#20844;&#24335;&#65292;&#24471;&#21040;&#20102;&#19979;&#19968;&#20010;$m$&#20010;&#36830;&#32493;&#28857;&#30340;&#24038;&#26680;&#20998;&#32452;&#30340;&#27010;&#24565;&#65306;$\sum_{i=0}^{m}b_i{D}_t^{(j)}K(t,t_{m+i})=0$&#65292;&#23545;&#20110;&#20219;&#24847;$t\geq t_{2m}$&#12290;&#36890;&#36807;&#32467;&#21512;&#24038;&#21491;&#26680;&#20998;&#32452;&#65292;&#21487;&#20197;&#35777;&#26126;&#36825;&#20123;&#21327;&#26041;&#24046;&#20989;&#25968;&#30340;&#36866;&#24403;&#32447;&#24615;&#32452;&#21512;&#20135;&#29983;&#20102;$m$&#20010;&#32039;&#25903;&#25345;&#30340;&#26680;&#20998;&#32452;&#20989;&#25968;&#65306;&#23545;&#20110;&#20219;&#24847;$t\not\in(t_0,t_{2m})$&#21644;$j=0,\cdots,m-1$&#65292;$\phi^{(j)}(t)=0$&#12290;
&lt;/p&gt;
&lt;p&gt;
It is well known that the state space (SS) model formulation of a Gaussian process (GP) can lower its training and prediction time both to O(n) for n data points. We prove that an $m$-dimensional SS model formulation of GP is equivalent to a concept we introduce as the general right Kernel Packet (KP): a transformation for the GP covariance function $K$ such that $\sum_{i=0}^{m}a_iD_t^{(j)}K(t,t_i)=0$ holds for any $t \leq t_1$, 0 $\leq j \leq m-1$, and $m+1$ consecutive points $t_i$, where ${D}_t^{(j)}f(t) $ denotes $j$-th order derivative acting on $t$. We extend this idea to the backward SS model formulation of the GP, leading to the concept of the left KP for next $m$ consecutive points: $\sum_{i=0}^{m}b_i{D}_t^{(j)}K(t,t_{m+i})=0$ for any $t\geq t_{2m}$. By combining both left and right KPs, we can prove that a suitable linear combination of these covariance functions yields $m$ compactly supported KP functions: $\phi^{(j)}(t)=0$ for any $t\not\in(t_0,t_{2m})$ and $j=0,\cdots,m-1$
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32447;&#24615;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;LG-GNN&#65289;&#26550;&#26500;&#65292;&#36890;&#36807;&#35745;&#31639;&#36793;&#32536;&#27010;&#29575;&#26469;&#39044;&#27979;&#22270;&#20013;&#30340;&#38142;&#25509;&#65292;&#24182;&#25512;&#23548;&#20102;&#20854;&#22312;&#38142;&#25509;&#39044;&#27979;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#32479;&#35745;&#20445;&#35777;&#12290;&#36825;&#31181;&#26550;&#26500;&#23545;&#20110;&#31232;&#30095;&#21644;&#31264;&#23494;&#22270;&#37117;&#36866;&#29992;&#65292;&#24182;&#22312;&#30495;&#23454;&#21644;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#39564;&#35777;&#20102;&#20854;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2402.02692</link><description>&lt;p&gt;
&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#38142;&#25509;&#39044;&#27979;&#30340;&#32479;&#35745;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Statistical Guarantees for Link Prediction using Graph Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02692
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32447;&#24615;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;LG-GNN&#65289;&#26550;&#26500;&#65292;&#36890;&#36807;&#35745;&#31639;&#36793;&#32536;&#27010;&#29575;&#26469;&#39044;&#27979;&#22270;&#20013;&#30340;&#38142;&#25509;&#65292;&#24182;&#25512;&#23548;&#20102;&#20854;&#22312;&#38142;&#25509;&#39044;&#27979;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#32479;&#35745;&#20445;&#35777;&#12290;&#36825;&#31181;&#26550;&#26500;&#23545;&#20110;&#31232;&#30095;&#21644;&#31264;&#23494;&#22270;&#37117;&#36866;&#29992;&#65292;&#24182;&#22312;&#30495;&#23454;&#21644;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#39564;&#35777;&#20102;&#20854;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#30001;&#22270;&#19978;&#29983;&#25104;&#30340;&#22270;&#32593;&#32476;&#20013;&#30340;&#38142;&#25509;&#39044;&#27979;&#20219;&#21153;&#65292;&#25512;&#23548;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#24615;&#33021;&#30340;&#32479;&#35745;&#20445;&#35777;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32447;&#24615;GNN&#26550;&#26500;&#65288;LG-GNN&#65289;&#65292;&#21487;&#20197;&#20135;&#29983;&#23545;&#28508;&#22312;&#36793;&#32536;&#27010;&#29575;&#30340;&#19968;&#33268;&#20272;&#35745;&#12290;&#25105;&#20204;&#23545;&#22343;&#26041;&#35823;&#24046;&#36827;&#34892;&#20102;&#30028;&#23450;&#65292;&#24182;&#23545;LG-GNN&#22312;&#26816;&#27979;&#39640;&#27010;&#29575;&#36793;&#32536;&#30340;&#33021;&#21147;&#32473;&#20986;&#20102;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#20445;&#35777;&#36866;&#29992;&#20110;&#31232;&#30095;&#21644;&#31264;&#23494;&#22270;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#32463;&#20856;GCN&#26550;&#26500;&#30340;&#19968;&#20123;&#32570;&#28857;&#65292;&#24182;&#22312;&#30495;&#23454;&#21644;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper derives statistical guarantees for the performance of Graph Neural Networks (GNNs) in link prediction tasks on graphs generated by a graphon. We propose a linear GNN architecture (LG-GNN) that produces consistent estimators for the underlying edge probabilities. We establish a bound on the mean squared error and give guarantees on the ability of LG-GNN to detect high-probability edges. Our guarantees hold for both sparse and dense graphs. Finally, we demonstrate some of the shortcomings of the classical GCN architecture, as well as verify our results on real and synthetic datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#38750;&#32447;&#24615;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#22120;&#30340;&#27491;&#21017;&#21270;&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#29305;&#24449;&#31354;&#38388;&#32500;&#24230;&#39640;&#20110;&#35757;&#32451;&#25968;&#25454;&#22823;&#23567;&#26102;&#25968;&#25454;&#21327;&#26041;&#24046;&#30697;&#38453;&#30149;&#24577;&#23548;&#33268;&#25928;&#29575;&#20302;&#19979;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2401.17760</link><description>&lt;p&gt;
&#20351;&#29992;&#38750;&#32447;&#24615;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#22120;&#30340;&#27491;&#21017;&#21270;&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Regularized Linear Discriminant Analysis Using a Nonlinear Covariance Matrix Estimator
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.17760
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#38750;&#32447;&#24615;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#22120;&#30340;&#27491;&#21017;&#21270;&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#29305;&#24449;&#31354;&#38388;&#32500;&#24230;&#39640;&#20110;&#35757;&#32451;&#25968;&#25454;&#22823;&#23567;&#26102;&#25968;&#25454;&#21327;&#26041;&#24046;&#30697;&#38453;&#30149;&#24577;&#23548;&#33268;&#25928;&#29575;&#20302;&#19979;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#65288;LDA&#65289;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#25968;&#25454;&#20998;&#31867;&#25216;&#26415;&#12290;&#35813;&#26041;&#27861;&#22312;&#35768;&#22810;&#20998;&#31867;&#38382;&#39064;&#20013;&#20855;&#26377;&#33391;&#22909;&#30340;&#24615;&#33021;&#65292;&#20294;&#22312;&#25968;&#25454;&#21327;&#26041;&#24046;&#30697;&#38453;&#30149;&#24577;&#26465;&#20214;&#19979;&#25928;&#29575;&#20302;&#19979;&#12290;&#36825;&#36890;&#24120;&#21457;&#29983;&#22312;&#29305;&#24449;&#31354;&#38388;&#30340;&#32500;&#24230;&#39640;&#20110;&#25110;&#25509;&#36817;&#35757;&#32451;&#25968;&#25454;&#22823;&#23567;&#30340;&#24773;&#20917;&#19979;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#31181;&#24773;&#20917;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#27491;&#21017;&#21270;&#32447;&#24615;&#20272;&#35745;&#22120;&#30340;&#27491;&#21017;&#21270;LDA&#65288;RLDA&#65289;&#26041;&#27861;&#12290;RLDA&#26041;&#27861;&#30340;&#24615;&#33021;&#24050;&#24471;&#21040;&#20805;&#20998;&#30740;&#31350;&#65292;&#24182;&#24050;&#25552;&#20986;&#20102;&#26368;&#20248;&#30340;&#27491;&#21017;&#21270;&#26041;&#26696;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19982;&#38750;&#32447;&#24615;&#65288;NL&#65289;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#22120;&#30456;&#19968;&#33268;&#30340;&#27491;&#21322;&#23450; Ridge &#22411;&#36870;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#22120;&#30340;&#33021;&#21147;&#12290;&#36890;&#36807;&#37325;&#26032;&#21046;&#23450;&#21033;&#29992;&#32447;&#24615;&#20272;&#35745;&#26041;&#27861;&#30340;&#26368;&#20248;&#20998;&#31867;&#22120;&#30340;&#24471;&#20998;&#20989;&#25968;&#65292;&#24471;&#21040;&#20102;&#35813;&#20272;&#35745;&#22120;&#65292;&#26368;&#32456;&#24418;&#25104;&#20102;&#25152;&#25552;&#20986;&#30340;NL-RLDA&#20998;&#31867;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Linear discriminant analysis (LDA) is a widely used technique for data classification. The method offers adequate performance in many classification problems, but it becomes inefficient when the data covariance matrix is ill-conditioned. This often occurs when the feature space's dimensionality is higher than or comparable to the training data size. Regularized LDA (RLDA) methods based on regularized linear estimators of the data covariance matrix have been proposed to cope with such a situation. The performance of RLDA methods is well studied, with optimal regularization schemes already proposed. In this paper, we investigate the capability of a positive semidefinite ridge-type estimator of the inverse covariance matrix that coincides with a nonlinear (NL) covariance matrix estimator. The estimator is derived by reformulating the score function of the optimal classifier utilizing linear estimation methods, which eventually results in the proposed NL-RLDA classifier. We derive asymptot
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#20551;&#35774;&#31616;&#21270;&#21644;&#25968;&#25454;&#33258;&#36866;&#24212;&#30340;&#21518;&#39044;&#27979;&#25512;&#26029;&#65288;POP-Inf&#65289;&#36807;&#31243;&#65292;&#21487;&#20197;&#26377;&#25928;&#19988;&#26377;&#21147;&#22320;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#32467;&#26524;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#12290;</title><link>https://arxiv.org/abs/2311.14220</link><description>&lt;p&gt;
&#20551;&#35774;&#31616;&#21270;&#21644;&#25968;&#25454;&#33258;&#36866;&#24212;&#30340;&#21518;&#39044;&#27979;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Assumption-lean and Data-adaptive Post-Prediction Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.14220
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#20551;&#35774;&#31616;&#21270;&#21644;&#25968;&#25454;&#33258;&#36866;&#24212;&#30340;&#21518;&#39044;&#27979;&#25512;&#26029;&#65288;POP-Inf&#65289;&#36807;&#31243;&#65292;&#21487;&#20197;&#26377;&#25928;&#19988;&#26377;&#21147;&#22320;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#32467;&#26524;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#31185;&#23398;&#30740;&#31350;&#38754;&#20020;&#30340;&#20027;&#35201;&#25361;&#25112;&#26159;&#40644;&#37329;&#26631;&#20934;&#25968;&#25454;&#30340;&#26377;&#38480;&#21487;&#29992;&#24615;&#65292;&#32780;&#33719;&#21462;&#36825;&#20123;&#25968;&#25454;&#26082;&#32791;&#36153;&#26102;&#38388;&#21448;&#36153;&#21147;&#12290;&#38543;&#30528;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#30340;&#24555;&#36895;&#21457;&#23637;&#65292;&#31185;&#23398;&#23478;&#20204;&#20381;&#36182;&#20110;ML&#31639;&#27861;&#20351;&#29992;&#26131;&#24471;&#30340;&#21327;&#21464;&#37327;&#26469;&#39044;&#27979;&#36825;&#20123;&#40644;&#37329;&#26631;&#20934;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#39044;&#27979;&#32467;&#26524;&#24120;&#24120;&#30452;&#25509;&#29992;&#20110;&#21518;&#32493;&#30340;&#32479;&#35745;&#20998;&#26512;&#20013;&#65292;&#24573;&#30053;&#20102;&#39044;&#27979;&#36807;&#31243;&#24341;&#20837;&#30340;&#19981;&#31934;&#30830;&#24615;&#21644;&#24322;&#36136;&#24615;&#12290;&#36825;&#21487;&#33021;&#23548;&#33268;&#34394;&#20551;&#30340;&#27491;&#38754;&#32467;&#26524;&#21644;&#26080;&#25928;&#30340;&#31185;&#23398;&#32467;&#35770;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#20551;&#35774;&#31616;&#21270;&#21644;&#25968;&#25454;&#33258;&#36866;&#24212;&#30340;&#21518;&#39044;&#27979;&#25512;&#26029;&#65288;POP-Inf&#65289;&#36807;&#31243;&#65292;&#23427;&#20801;&#35768;&#22522;&#20110;ML&#39044;&#27979;&#32467;&#26524;&#36827;&#34892;&#26377;&#25928;&#21644;&#26377;&#21147;&#30340;&#25512;&#26029;&#12290;&#23427;&#30340;&#8220;&#20551;&#35774;&#31616;&#21270;&#8221;&#23646;&#24615;&#20445;&#35777;&#22312;&#24191;&#27867;&#30340;&#32479;&#35745;&#37327;&#19978;&#19981;&#22522;&#20110;ML&#39044;&#27979;&#20570;&#20986;&#21487;&#38752;&#30340;&#32479;&#35745;&#25512;&#26029;&#12290;&#23427;&#30340;&#8220;&#25968;&#25454;&#33258;&#36866;&#24212;&#8221;&#29305;&#24615;&#20445;&#35777;&#20102;&#30456;&#36739;&#20110;&#29616;&#26377;&#26041;&#27861;&#30340;&#25928;&#29575;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
A primary challenge facing modern scientific research is the limited availability of gold-standard data which can be both costly and labor-intensive to obtain. With the rapid development of machine learning (ML), scientists have relied on ML algorithms to predict these gold-standard outcomes with easily obtained covariates. However, these predicted outcomes are often used directly in subsequent statistical analyses, ignoring imprecision and heterogeneity introduced by the prediction procedure. This will likely result in false positive findings and invalid scientific conclusions. In this work, we introduce an assumption-lean and data-adaptive Post-Prediction Inference (POP-Inf) procedure that allows valid and powerful inference based on ML-predicted outcomes. Its "assumption-lean" property guarantees reliable statistical inference without assumptions on the ML-prediction, for a wide range of statistical quantities. Its "data-adaptive'" feature guarantees an efficiency gain over existing
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#38598;&#25104;&#23398;&#20064;&#22810;&#26679;&#24615;&#29702;&#35770;&#65292;&#35299;&#37322;&#20102;&#22810;&#26679;&#24615;&#22312;&#21508;&#31181;&#30417;&#30563;&#23398;&#20064;&#22330;&#26223;&#20013;&#30340;&#26412;&#36136;&#12290;&#23427;&#25581;&#31034;&#20102;&#22810;&#26679;&#24615;&#22312;&#38598;&#25104;&#25439;&#22833;&#30340;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;&#20013;&#30340;&#20316;&#29992;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#37327;&#21270;&#22810;&#26679;&#24615;&#25928;&#26524;&#30340;&#26041;&#27861;&#12290;&#36825;&#20010;&#29702;&#35770;&#23545;&#20110;&#25552;&#39640;&#38598;&#25104;&#27169;&#22411;&#30340;&#24615;&#33021;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>https://arxiv.org/abs/2301.03962</link><description>&lt;p&gt;
&#38598;&#25104;&#23398;&#20064;&#22810;&#26679;&#24615;&#30340;&#32479;&#19968;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
A Unified Theory of Diversity in Ensemble Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2301.03962
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#38598;&#25104;&#23398;&#20064;&#22810;&#26679;&#24615;&#29702;&#35770;&#65292;&#35299;&#37322;&#20102;&#22810;&#26679;&#24615;&#22312;&#21508;&#31181;&#30417;&#30563;&#23398;&#20064;&#22330;&#26223;&#20013;&#30340;&#26412;&#36136;&#12290;&#23427;&#25581;&#31034;&#20102;&#22810;&#26679;&#24615;&#22312;&#38598;&#25104;&#25439;&#22833;&#30340;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;&#20013;&#30340;&#20316;&#29992;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#37327;&#21270;&#22810;&#26679;&#24615;&#25928;&#26524;&#30340;&#26041;&#27861;&#12290;&#36825;&#20010;&#29702;&#35770;&#23545;&#20110;&#25552;&#39640;&#38598;&#25104;&#27169;&#22411;&#30340;&#24615;&#33021;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38598;&#25104;&#22810;&#26679;&#24615;&#30340;&#29702;&#35770;&#65292;&#35299;&#37322;&#20102;&#22312;&#21508;&#31181;&#30417;&#30563;&#23398;&#20064;&#22330;&#26223;&#20013;&#22810;&#26679;&#24615;&#30340;&#26412;&#36136;&#12290;&#36825;&#20010;&#25361;&#25112;&#34987;&#31216;&#20026;&#38598;&#25104;&#23398;&#20064;&#30340;&#22307;&#26479;&#65292;&#26159;&#19968;&#20010;&#24320;&#25918;&#30340;&#30740;&#31350;&#38382;&#39064;&#24050;&#32463;&#26377;30&#22810;&#24180;&#20102;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#25581;&#31034;&#20102;&#22810;&#26679;&#24615;&#23454;&#38469;&#19978;&#26159;&#38598;&#25104;&#25439;&#22833;&#30340;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;&#20013;&#30340;&#19968;&#20010;&#38544;&#34255;&#32500;&#24230;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#26063;&#31934;&#30830;&#30340;&#20559;&#24046;-&#26041;&#24046;-&#22810;&#26679;&#24615;&#20998;&#35299;&#65292;&#36866;&#29992;&#20110;&#22238;&#24402;&#21644;&#20998;&#31867;&#30340;&#21508;&#31181;&#25439;&#22833;&#20989;&#25968;&#65292;&#20363;&#22914;&#24179;&#26041;&#25439;&#22833;&#12289;&#20132;&#21449;&#29109;&#25439;&#22833;&#21644;&#27850;&#26494;&#25439;&#22833;&#12290;&#23545;&#20110;&#27809;&#26377;&#21487;&#21152;&#24615;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;&#30340;&#25439;&#22833;&#20989;&#25968;&#65288;&#20363;&#22914;0/1&#25439;&#22833;&#65289;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#26041;&#27861;&#65306;&#37327;&#21270;&#22810;&#26679;&#24615;&#30340;&#25928;&#26524;&#65292;&#32467;&#26524;&#20381;&#36182;&#20110;&#26631;&#31614;&#20998;&#24067;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35748;&#20026;&#22810;&#26679;&#24615;&#26159;&#27169;&#22411;&#25311;&#21512;&#24230;&#30340;&#24230;&#37327;&#65292;&#19982;&#20559;&#24046;&#21644;&#26041;&#24046;&#20855;&#26377;&#30456;&#21516;&#30340;&#24847;&#20041;&#65292;&#20294;&#32771;&#34385;&#20102;&#38598;&#25104;&#25104;&#21592;&#20043;&#38388;&#30340;&#32479;&#35745;&#20381;&#36182;&#20851;&#31995;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#19981;&#24212;&#35813;&#26368;&#22823;&#21270;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a theory of ensemble diversity, explaining the nature of diversity for a wide range of supervised learning scenarios. This challenge has been referred to as the holy grail of ensemble learning, an open research issue for over 30 years. Our framework reveals that diversity is in fact a hidden dimension in the bias-variance decomposition of the ensemble loss. We prove a family of exact bias-variance-diversity decompositions, for a wide range of losses in both regression and classification, e.g., squared, cross-entropy, and Poisson losses. For losses where an additive bias-variance decomposition is not available (e.g., 0/1 loss) we present an alternative approach: quantifying the effects of diversity, which turn out to be dependent on the label distribution. Overall, we argue that diversity is a measure of model fit, in precisely the same sense as bias and variance, but accounting for statistical dependencies between ensemble members. Thus, we should not be maximising diversity
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23616;&#37096;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#30340;&#25910;&#32553;&#24615;&#36136;, &#24182;&#32473;&#20986;&#20102;&#36755;&#20986;&#20998;&#24067;&#19982;&#36755;&#20837;&#20998;&#24067;&#20043;&#38388;&#24046;&#24322;&#30340;&#19978;&#30028;&#65292;&#36825;&#23545;&#20110;&#30028;&#23450;&#26497;&#23567;&#26497;&#22823;&#20272;&#35745;&#39118;&#38505;&#38750;&#24120;&#26377;&#29992;&#12290;</title><link>https://arxiv.org/abs/2210.13386</link><description>&lt;p&gt;
&#23616;&#37096;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#30340;&#25910;&#32553;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Contraction of Locally Differentially Private Mechanisms
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2210.13386
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23616;&#37096;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#30340;&#25910;&#32553;&#24615;&#36136;, &#24182;&#32473;&#20986;&#20102;&#36755;&#20986;&#20998;&#24067;&#19982;&#36755;&#20837;&#20998;&#24067;&#20043;&#38388;&#24046;&#24322;&#30340;&#19978;&#30028;&#65292;&#36825;&#23545;&#20110;&#30028;&#23450;&#26497;&#23567;&#26497;&#22823;&#20272;&#35745;&#39118;&#38505;&#38750;&#24120;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#23616;&#37096;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#30340;&#25910;&#32553;&#24615;&#36136;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#20010;&#20851;&#20110;&#36755;&#20837;&#20998;&#24067;&#20043;&#38388;&#30340;&#24046;&#24322;&#21644;&#36755;&#20986;&#20998;&#24067;&#20043;&#38388;&#30340;&#24046;&#24322;&#30340;&#19978;&#30028;&#65292;&#29992;&#20110;&#24230;&#37327;&#1013;-&#23616;&#37096;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;K&#30340;&#36755;&#20986;&#20998;&#24067;PK&#21644;QK&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#20998;&#21035;&#23545;&#24212;&#20110;&#36755;&#20837;&#20998;&#24067;P&#21644;Q&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#25105;&#20204;&#30340;&#31532;&#19968;&#20010;&#20027;&#35201;&#25216;&#26415;&#32467;&#26524;&#32473;&#20986;&#20102;&#19968;&#20010;&#20851;&#20110;&#967;^2-&#36317;&#31163;&#967;^2(PK}&#8741;QK)&#30340;&#23574;&#38160;&#19978;&#30028;&#65292;&#35813;&#19978;&#30028;&#19982;&#967;^2(P&#8741;Q)&#21644;&#1013;&#26377;&#20851;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#35813;&#32467;&#26524;&#23545;&#19968;&#22823;&#31867;&#36317;&#31163;&#30340;&#19978;&#30028;&#25104;&#31435;&#65292;&#21253;&#25324;KL-&#36317;&#31163;&#21644;&#24179;&#26041;Hellinger&#36317;&#31163;&#12290;&#31532;&#20108;&#20010;&#20027;&#35201;&#25216;&#26415;&#32467;&#26524;&#32473;&#20986;&#20102;&#19968;&#20010;&#20851;&#20110;&#967;^2(PK&#8741;QK)&#30340;&#19978;&#30028;&#65292;&#35813;&#19978;&#30028;&#19982;&#24635;&#21464;&#24046;&#36317;&#31163;TV(P,Q)&#21644;&#1013;&#26377;&#20851;&#12290;&#28982;&#21518;&#25105;&#20204;&#21033;&#29992;&#36825;&#20123;&#19978;&#30028;&#24314;&#31435;&#20102;van Trees&#19981;&#31561;&#24335;&#12289;Le Cam&#27663;&#19981;&#31561;&#24335;&#12289;Assouad&#19981;&#31561;&#24335;&#21644;&#20114;&#20449;&#24687;&#26041;&#27861;&#30340;&#23616;&#37096;&#38544;&#31169;&#29256;&#26412;&#65292;&#36825;&#20123;&#26041;&#27861;&#23545;&#20110;&#30028;&#23450;&#26497;&#23567;&#26497;&#22823;&#20272;&#35745;&#39118;&#38505;&#38750;&#24120;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the contraction properties of locally differentially private mechanisms. More specifically, we derive tight upper bounds on the divergence between $PK$ and $QK$ output distributions of an $\epsilon$-LDP mechanism $K$ in terms of a divergence between the corresponding input distributions $P$ and $Q$, respectively. Our first main technical result presents a sharp upper bound on the $\chi^2$-divergence $\chi^2(PK}\|QK)$ in terms of $\chi^2(P\|Q)$ and $\varepsilon$. We also show that the same result holds for a large family of divergences, including KL-divergence and squared Hellinger distance. The second main technical result gives an upper bound on $\chi^2(PK\|QK)$ in terms of total variation distance $\mathsf{TV}(P, Q)$ and $\epsilon$. We then utilize these bounds to establish locally private versions of the van Trees inequality, Le Cam's, Assouad's, and the mutual information methods, which are powerful tools for bounding minimax estimation risks. These results are shown
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23545;&#25239;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#38024;&#23545;&#20219;&#24847;&#31574;&#30053;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#26041;&#27861;&#30340;&#20027;&#25511;&#22522;&#30784;&#26694;&#26550;&#65292;&#24182;&#20351;&#29992;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#30340;OMD&#26469;&#20943;&#36731;&#26041;&#24046;&#30340;&#24433;&#21709;&#65292;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2205.14839</link><description>&lt;p&gt;
&#23545;&#25239;&#24615;&#36172;&#21338;&#26426;&#38024;&#23545;&#20219;&#24847;&#31574;&#30053;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Adversarial Bandits against Arbitrary Strategies
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2205.14839
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23545;&#25239;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#38024;&#23545;&#20219;&#24847;&#31574;&#30053;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#26041;&#27861;&#30340;&#20027;&#25511;&#22522;&#30784;&#26694;&#26550;&#65292;&#24182;&#20351;&#29992;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#30340;OMD&#26469;&#20943;&#36731;&#26041;&#24046;&#30340;&#24433;&#21709;&#65292;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#38024;&#23545;&#20219;&#24847;&#31574;&#30053;&#30340;&#23545;&#25239;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#20854;&#20013;S&#26159;&#38382;&#39064;&#38590;&#24230;&#30340;&#21442;&#25968;&#65292;&#35813;&#21442;&#25968;&#23545;&#20110;&#20195;&#29702;&#20154;&#26469;&#35828;&#26159;&#26410;&#30693;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#20351;&#29992;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#26041;&#27861;&#65288;OMD&#65289;&#30340;&#20027;&#25511;&#22522;&#30784;&#26694;&#26550;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20379;&#20102;&#19968;&#20010;&#20855;&#26377;&#31616;&#21333;OMD&#30340;&#20027;&#25511;&#22522;&#30784;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;$\tilde{O}(S^{1/2}K^{1/3}T^{2/3})$&#30340;&#32467;&#26524;&#65292;&#20854;&#20013;$T^{2/3}$&#26469;&#33258;&#25439;&#22833;&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#12290;&#20026;&#20102;&#20943;&#36731;&#26041;&#24046;&#30340;&#24433;&#21709;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#30340;OMD&#65292;&#24182;&#23454;&#29616;&#20102;$\tilde{O}(\min\{\mathbb{E}[\sqrt{SKT\rho_T(h^\dagger)}],S\sqrt{KT}\})$&#30340;&#32467;&#26524;&#65292;&#20854;&#20013;$\rho_T(h^\dagger)$&#26159;&#25439;&#22833;&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#39033;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the adversarial bandit problem against arbitrary strategies, in which $S$ is the parameter for the hardness of the problem and this parameter is not given to the agent. To handle this problem, we adopt the master-base framework using the online mirror descent method (OMD). We first provide a master-base algorithm with simple OMD, achieving $\tilde{O}(S^{1/2}K^{1/3}T^{2/3})$, in which $T^{2/3}$ comes from the variance of loss estimators. To mitigate the impact of the variance, we propose using adaptive learning rates for OMD and achieve $\tilde{O}(\min\{\mathbb{E}[\sqrt{SKT\rho_T(h^\dagger)}],S\sqrt{KT}\})$, where $\rho_T(h^\dagger)$ is a variance term for loss estimators.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25551;&#36848;&#20102;&#36125;&#21494;&#26031;&#20808;&#39564;&#21644;&#21464;&#20998;&#25512;&#29702;&#20013;&#30340;&#24809;&#32602;&#20043;&#38388;&#30340;&#31561;&#20215;&#20851;&#31995;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#35745;&#31639;&#32473;&#23450;&#24809;&#32602;&#39033;&#25152;&#23545;&#24212;&#30340;&#20808;&#39564;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2002.00178</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#20808;&#39564;&#21644;&#21464;&#20998;&#25512;&#29702;&#20013;&#30340;&#24809;&#32602;&#20043;&#38388;&#30340;&#31561;&#20215;&#20851;&#31995;
&lt;/p&gt;
&lt;p&gt;
An Equivalence between Bayesian Priors and Penalties in Variational Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2002.00178
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25551;&#36848;&#20102;&#36125;&#21494;&#26031;&#20808;&#39564;&#21644;&#21464;&#20998;&#25512;&#29702;&#20013;&#30340;&#24809;&#32602;&#20043;&#38388;&#30340;&#31561;&#20215;&#20851;&#31995;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#35745;&#31639;&#32473;&#23450;&#24809;&#32602;&#39033;&#25152;&#23545;&#24212;&#30340;&#20808;&#39564;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#24120;&#24120;&#36890;&#36807;&#35843;&#33410;&#26576;&#20123;&#21442;&#25968;&#20540;&#30340;&#24809;&#32602;&#39033;&#26469;&#20248;&#21270;&#27010;&#29575;&#27169;&#22411;&#30340;&#21442;&#25968;&#12290;&#27491;&#21017;&#21270;&#39033;&#22312;&#21464;&#20998;&#25512;&#29702;&#20013;&#26159;&#33258;&#28982;&#22320;&#20986;&#29616;&#30340;&#65292;&#23427;&#26159;&#19968;&#31181;&#21487;&#34892;&#30340;&#36817;&#20284;&#36125;&#21494;&#26031;&#21518;&#39564;&#30340;&#26041;&#27861;&#65306;&#35201;&#20248;&#21270;&#30340;&#25439;&#22833;&#20989;&#25968;&#21253;&#21547;&#20102;&#36817;&#20284;&#21518;&#39564;&#19982;&#36125;&#21494;&#26031;&#20808;&#39564;&#20043;&#38388;&#30340;Kullback-Leibler&#25955;&#24230;&#39033;&#12290;&#25105;&#20204;&#23436;&#20840;&#25551;&#36848;&#20102;&#36825;&#20010;&#36807;&#31243;&#20013;&#21487;&#33021;&#20986;&#29616;&#30340;&#27491;&#21017;&#21270;&#39033;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#31995;&#32479;&#30340;&#26041;&#27861;&#26469;&#35745;&#31639;&#19982;&#32473;&#23450;&#24809;&#32602;&#39033;&#30456;&#23545;&#24212;&#30340;&#20808;&#39564;&#12290;&#36825;&#31181;&#29305;&#24449;&#21270;&#21487;&#20197;&#29992;&#26469;&#21457;&#29616;&#23545;&#24809;&#32602;&#20989;&#25968;&#30340;&#32422;&#26463;&#26465;&#20214;&#65292;&#20197;&#20445;&#25345;&#25972;&#20010;&#36807;&#31243;&#20855;&#26377;&#36125;&#21494;&#26031;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
In machine learning, it is common to optimize the parameters of a probabilistic model, modulated by an ad hoc regularization term that penalizes some values of the parameters. Regularization terms appear naturally in Variational Inference, a tractable way to approximate Bayesian posteriors: the loss to optimize contains a Kullback--Leibler divergence term between the approximate posterior and a Bayesian prior. We fully characterize the regularizers that can arise according to this procedure, and provide a systematic way to compute the prior corresponding to a given penalty. Such a characterization can be used to discover constraints over the penalty function, so that the overall procedure remains Bayesian.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;lil'HDoC&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#23567;&#38408;&#20540;&#38388;&#38553;&#19979;&#30340;&#22909;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#31639;&#27861;&#22312;&#26679;&#26412;&#25928;&#29575;&#19978;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.15879</link><description>&lt;p&gt;
&#23567;&#38408;&#20540;&#38388;&#38553;&#19979;&#30340;&#22909;&#33218;&#35782;&#21035;&#31639;&#27861;: lil'HDoC
&lt;/p&gt;
&lt;p&gt;
lil'HDoC: An Algorithm for Good Arm Identification under Small Threshold Gap. (arXiv:2401.15879v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15879
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;lil'HDoC&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#23567;&#38408;&#20540;&#38388;&#38553;&#19979;&#30340;&#22909;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#31639;&#27861;&#22312;&#26679;&#26412;&#25928;&#29575;&#19978;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22909;&#33218;&#35782;&#21035;&#65288;GAI&#65289;&#26159;&#19968;&#20010;&#32431;&#25506;&#32034;&#24615;&#30340;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#19968;&#20010;&#21333;&#29420;&#30340;&#23398;&#20064;&#22120;&#20250;&#22312;&#30830;&#23450;&#19968;&#20010;&#33218;&#26159;&#22909;&#33218;&#26102;&#31435;&#21363;&#36755;&#20986;&#35813;&#33218;&#12290;&#22909;&#33218;&#34987;&#23450;&#20041;&#20026;&#26399;&#26395;&#22238;&#25253;&#22823;&#20110;&#31561;&#20110;&#32473;&#23450;&#38408;&#20540;&#30340;&#33218;&#12290;&#26412;&#25991;&#32858;&#28966;&#20110;&#23567;&#38408;&#20540;&#38388;&#38553;&#19979;&#30340;GAI&#38382;&#39064;&#65292;&#35813;&#38388;&#38553;&#25351;&#30340;&#26159;&#33218;&#30340;&#26399;&#26395;&#22238;&#25253;&#19982;&#32473;&#23450;&#38408;&#20540;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;lil'HDoC&#30340;&#26032;&#31639;&#27861;&#65292;&#26174;&#33879;&#25913;&#21892;&#20102;HDoC&#31639;&#27861;&#30340;&#24635;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#23567;&#38408;&#20540;&#38388;&#38553;&#19979;&#65292;lil'HDoC&#31639;&#27861;&#36755;&#20986;&#30340;&#31532;&#19968;&#20010;&#955;&#33218;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#19982;&#21407;&#22987;HDoC&#31639;&#27861;&#30456;&#27604;&#20165;&#26377;&#24494;&#23567;&#30340;&#24046;&#24322;&#12290;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Good arm identification (GAI) is a pure-exploration bandit problem in which a single learner outputs an arm as soon as it is identified as a good arm. A good arm is defined as an arm with an expected reward greater than or equal to a given threshold. This paper focuses on the GAI problem under a small threshold gap, which refers to the distance between the expected rewards of arms and the given threshold. We propose a new algorithm called lil'HDoC to significantly improve the total sample complexity of the HDoC algorithm. We demonstrate that the sample complexity of the first $\lambda$ output arm in lil'HDoC is bounded by the original HDoC algorithm, except for one negligible term, when the distance between the expected reward and threshold is small. Extensive experiments confirm that our algorithm outperforms the state-of-the-art algorithms in both synthetic and real-world datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#25193;&#25955;&#27169;&#22411;&#20013;&#20998;&#25968;&#20272;&#35745;&#30340;&#20248;&#21270;&#21644;&#27867;&#21270;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#23545;&#20998;&#25968;&#20272;&#35745;&#36827;&#34892;&#20998;&#26512;&#30340;&#25968;&#23398;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2401.15604</link><description>&lt;p&gt;
&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#25193;&#25955;&#27169;&#22411;&#20013;&#30340;&#20998;&#25968;&#20272;&#35745;&#65306;&#20248;&#21270;&#21644;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Neural Network-Based Score Estimation in Diffusion Models: Optimization and Generalization. (arXiv:2401.15604v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15604
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#25193;&#25955;&#27169;&#22411;&#20013;&#20998;&#25968;&#20272;&#35745;&#30340;&#20248;&#21270;&#21644;&#27867;&#21270;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#23545;&#20998;&#25968;&#20272;&#35745;&#36827;&#34892;&#20998;&#26512;&#30340;&#25968;&#23398;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#24050;&#32463;&#25104;&#20026;&#19982;GANs&#30456;&#23218;&#32654;&#30340;&#24378;&#22823;&#24037;&#20855;&#65292;&#21487;&#20197;&#29983;&#25104;&#20855;&#26377;&#25913;&#36827;&#20445;&#30495;&#24230;&#65292;&#28789;&#27963;&#24615;&#21644;&#40065;&#26834;&#24615;&#30340;&#39640;&#36136;&#37327;&#26679;&#26412;&#12290;&#36825;&#20123;&#27169;&#22411;&#30340;&#19968;&#20010;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#26159;&#36890;&#36807;&#20998;&#25968;&#21305;&#37197;&#26469;&#23398;&#20064;&#20998;&#25968;&#20989;&#25968;&#12290;&#23613;&#31649;&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#23454;&#35777;&#25104;&#21151;&#65292;&#20294;&#23578;&#19981;&#28165;&#26970;&#22522;&#20110;&#26799;&#24230;&#30340;&#31639;&#27861;&#26159;&#21542;&#21487;&#20197;&#20197;&#21487;&#35777;&#23454;&#30340;&#20934;&#30830;&#24615;&#23398;&#20064;&#20998;&#25968;&#20989;&#25968;&#12290;&#20316;&#20026;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#30340;&#39318;&#35201;&#27493;&#39588;&#65292;&#26412;&#25991;&#24314;&#31435;&#20102;&#19968;&#20010;&#25968;&#23398;&#26694;&#26550;&#65292;&#29992;&#20110;&#20998;&#26512;&#29992;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#26469;&#36827;&#34892;&#20998;&#25968;&#20272;&#35745;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#21253;&#25324;&#23398;&#20064;&#36807;&#31243;&#30340;&#20248;&#21270;&#21644;&#27867;&#21270;&#26041;&#38754;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21442;&#25968;&#21270;&#24418;&#24335;&#26469;&#23558;&#21435;&#22122;&#20998;&#25968;&#21305;&#37197;&#38382;&#39064;&#21046;&#23450;&#20026;&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#22238;&#24402;&#38382;&#39064;&#12290;&#19982;&#26631;&#20934;&#30340;&#30417;&#30563;&#23398;&#20064;&#35774;&#32622;&#30456;&#27604;&#65292;&#20998;&#25968;&#21305;&#37197;&#38382;&#39064;&#24341;&#20837;&#20102;&#29420;&#29305;&#30340;&#25361;&#25112;&#65292;&#21253;&#25324;&#26080;&#30028;&#36755;&#20837;&#65292;&#21521;&#37327;&#20540;&#36755;&#20986;&#21644;&#39069;&#22806;&#30340;&#26102;&#38388;&#21464;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models have emerged as a powerful tool rivaling GANs in generating high-quality samples with improved fidelity, flexibility, and robustness. A key component of these models is to learn the score function through score matching. Despite empirical success on various tasks, it remains unclear whether gradient-based algorithms can learn the score function with a provable accuracy. As a first step toward answering this question, this paper establishes a mathematical framework for analyzing score estimation using neural networks trained by gradient descent. Our analysis covers both the optimization and the generalization aspects of the learning procedure. In particular, we propose a parametric form to formulate the denoising score-matching problem as a regression with noisy labels. Compared to the standard supervised learning setup, the score-matching problem introduces distinct challenges, including unbounded input, vector-valued output, and an additional time variable, preventing
&lt;/p&gt;</description></item><item><title>&#36861;&#27714;&#26368;&#20248;&#32479;&#35745;&#27700;&#21360;&#25216;&#26415;&#12290;&#36890;&#36807;&#23558;&#32479;&#35745;&#27700;&#21360;&#25216;&#26415;&#35270;&#20026;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#24182;&#24341;&#20837;&#20266;&#38543;&#26426;&#29983;&#25104;&#22120;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#36755;&#20986;&#20196;&#29260;&#21644;&#25298;&#32477;&#21306;&#22495;&#30340;&#32806;&#21512;&#65292;&#23454;&#29616;&#20102;&#31532;&#19968;&#31867;&#38169;&#35823;&#21644;&#31532;&#20108;&#31867;&#38169;&#35823;&#20043;&#38388;&#30340;&#38750;&#24179;&#20961;&#26435;&#34913;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#26368;&#32479;&#19968;&#26368;&#26377;&#21147;&#30340;&#27700;&#21360;&#21644;&#26368;&#23567;&#21270;&#31532;&#20108;&#31867;&#38169;&#35823;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#29420;&#31435;&#21516;&#20998;&#24067;&#20196;&#29260;&#25968;&#37327;&#30340;&#19978;&#19979;&#30028;&#65292;&#31361;&#26174;&#20102;&#25913;&#36827;&#30340;&#28508;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#40065;&#26834;&#24615;&#27700;&#21360;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2312.07930</link><description>&lt;p&gt;
&#36861;&#27714;&#26368;&#20248;&#32479;&#35745;&#27700;&#21360;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Towards Optimal Statistical Watermarking. (arXiv:2312.07930v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.07930
&lt;/p&gt;
&lt;p&gt;
&#36861;&#27714;&#26368;&#20248;&#32479;&#35745;&#27700;&#21360;&#25216;&#26415;&#12290;&#36890;&#36807;&#23558;&#32479;&#35745;&#27700;&#21360;&#25216;&#26415;&#35270;&#20026;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#24182;&#24341;&#20837;&#20266;&#38543;&#26426;&#29983;&#25104;&#22120;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#36755;&#20986;&#20196;&#29260;&#21644;&#25298;&#32477;&#21306;&#22495;&#30340;&#32806;&#21512;&#65292;&#23454;&#29616;&#20102;&#31532;&#19968;&#31867;&#38169;&#35823;&#21644;&#31532;&#20108;&#31867;&#38169;&#35823;&#20043;&#38388;&#30340;&#38750;&#24179;&#20961;&#26435;&#34913;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#26368;&#32479;&#19968;&#26368;&#26377;&#21147;&#30340;&#27700;&#21360;&#21644;&#26368;&#23567;&#21270;&#31532;&#20108;&#31867;&#38169;&#35823;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#29420;&#31435;&#21516;&#20998;&#24067;&#20196;&#29260;&#25968;&#37327;&#30340;&#19978;&#19979;&#30028;&#65292;&#31361;&#26174;&#20102;&#25913;&#36827;&#30340;&#28508;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#40065;&#26834;&#24615;&#27700;&#21360;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;&#32479;&#35745;&#27700;&#21360;&#25216;&#26415;&#20316;&#20026;&#19968;&#20010;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#36827;&#34892;&#30740;&#31350;&#65292;&#36825;&#26159;&#19968;&#20010;&#27867;&#21270;&#20102;&#25152;&#26377;&#20043;&#21069;&#32479;&#35745;&#27700;&#21360;&#26041;&#27861;&#30340;&#36890;&#29992;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#26159;&#36890;&#36807;&#23454;&#36341;&#20013;&#30340;&#20266;&#38543;&#26426;&#29983;&#25104;&#22120;&#23454;&#29616;&#36755;&#20986;&#20196;&#29260;&#21644;&#25298;&#32477;&#21306;&#22495;&#30340;&#32806;&#21512;&#65292;&#20174;&#32780;&#20801;&#35768;&#22312;&#31532;&#19968;&#31867;&#38169;&#35823;&#21644;&#31532;&#20108;&#31867;&#38169;&#35823;&#20043;&#38388;&#36827;&#34892;&#38750;&#24179;&#20961;&#30340;&#26435;&#34913;&#12290;&#25105;&#20204;&#22312;&#19968;&#33324;&#30340;&#20551;&#35774;&#26816;&#39564;&#29615;&#22659;&#19979;&#34920;&#24449;&#20102;&#26368;&#32479;&#19968;&#26368;&#26377;&#21147;&#30340;&#27700;&#21360;&#20197;&#21450;&#22312;&#27169;&#22411;&#26080;&#20851;&#30340;&#29615;&#22659;&#20013;&#26368;&#23567;&#21270;&#31532;&#20108;&#31867;&#38169;&#35823;&#12290;&#22312;&#36755;&#20986;&#26159;$n$&#20010;&#20196;&#29260;&#30340;&#24120;&#35265;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23545;&#38656;&#35201;&#20445;&#35777;&#23567;&#30340;&#31532;&#19968;&#31867;&#21644;&#31532;&#20108;&#31867;&#38169;&#35823;&#30340;&#29420;&#31435;&#21516;&#20998;&#24067;&#20196;&#29260;&#25968;&#37327;&#24314;&#31435;&#20102;&#36817;&#20046;&#21305;&#37197;&#30340;&#19978;&#19979;&#30028;&#12290;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;&#20013;&#30340;$ h ^ {-2} $&#36895;&#29575;&#30456;&#27604;&#65292;&#25105;&#20204;&#30456;&#23545;&#20110;&#27599;&#20010;&#20196;&#29260;&#30340;&#24179;&#22343;&#29109;$h$&#30340;&#36895;&#29575;&#20026;$ \Theta(h ^ {-1} \log (1/h)) $&#65292;&#31361;&#26174;&#20102;&#25913;&#36827;&#30340;&#28508;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#40065;&#26834;&#24615;&#27700;&#21360;&#38382;&#39064;&#65292;&#20854;&#20013;&#29992;&#25143;&#37117;&#26159;...
&lt;/p&gt;
&lt;p&gt;
We study statistical watermarking by formulating it as a hypothesis testing problem, a general framework which subsumes all previous statistical watermarking methods. Key to our formulation is a coupling of the output tokens and the rejection region, realized by pseudo-random generators in practice, that allows non-trivial trade-off between the Type I error and Type II error. We characterize the Uniformly Most Powerful (UMP) watermark in the general hypothesis testing setting and the minimax Type II error in the model-agnostic setting. In the common scenario where the output is a sequence of $n$ tokens, we establish nearly matching upper and lower bounds on the number of i.i.d. tokens required to guarantee small Type I and Type II errors. Our rate of $\Theta(h^{-1} \log (1/h))$ with respect to the average entropy per token $h$ highlights potentials for improvement from the rate of $h^{-2}$ in the previous works. Moreover, we formulate the robust watermarking problem where users are all
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36845;&#20195;&#26041;&#27861;&#65292;&#36890;&#36807;&#22686;&#21152;&#19981;&#30830;&#23450;&#24615;&#26469;&#38477;&#20302;&#35745;&#31639;&#37327;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#35757;&#32451;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.20285</link><description>&lt;p&gt;
&#36890;&#36807;&#20197;&#35745;&#31639;&#20026;&#20195;&#20215;&#21152;&#36895;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Accelerating Generalized Linear Models by Trading off Computation for Uncertainty. (arXiv:2310.20285v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20285
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36845;&#20195;&#26041;&#27861;&#65292;&#36890;&#36807;&#22686;&#21152;&#19981;&#30830;&#23450;&#24615;&#26469;&#38477;&#20302;&#35745;&#31639;&#37327;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#35757;&#32451;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65288;GLMs&#65289;&#23450;&#20041;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#29992;&#20110;&#24314;&#27169;&#20998;&#31867;&#12289;&#26377;&#24207;&#21644;&#36830;&#32493;&#25968;&#25454;&#65292;&#24182;&#19988;&#22312;&#23454;&#36341;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#65292;GLMs&#30340;&#31934;&#30830;&#25512;&#26029;&#20195;&#20215;&#22826;&#39640;&#65292;&#22240;&#27492;&#38656;&#35201;&#22312;&#23454;&#36341;&#20013;&#36827;&#34892;&#36817;&#20284;&#12290;&#36896;&#25104;&#30340;&#36817;&#20284;&#35823;&#24046;&#23545;&#27169;&#22411;&#30340;&#21487;&#38752;&#24615;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#65292;&#24182;&#19988;&#27809;&#26377;&#34987;&#32771;&#34385;&#22312;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#20013;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31995;&#21015;&#36845;&#20195;&#26041;&#27861;&#65292;&#26126;&#30830;&#22320;&#23545;&#36825;&#20010;&#35823;&#24046;&#24314;&#27169;&#12290;&#23427;&#20204;&#38750;&#24120;&#36866;&#21512;&#24182;&#34892;&#35745;&#31639;&#30828;&#20214;&#65292;&#26377;&#25928;&#22320;&#22238;&#25910;&#35745;&#31639;&#24182;&#21387;&#32553;&#20449;&#24687;&#65292;&#20197;&#20943;&#23569;GLMs&#30340;&#26102;&#38388;&#21644;&#20869;&#23384;&#38656;&#27714;&#12290;&#27491;&#22914;&#25105;&#20204;&#22312;&#19968;&#20010;&#23454;&#38469;&#30340;&#22823;&#22411;&#20998;&#31867;&#38382;&#39064;&#19978;&#23637;&#31034;&#30340;&#37027;&#26679;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#26126;&#30830;&#22320;&#23558;&#20943;&#23569;&#35745;&#31639;&#19982;&#22686;&#21152;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#26435;&#34913;&#26469;&#26174;&#33879;&#21152;&#36895;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian Generalized Linear Models (GLMs) define a flexible probabilistic framework to model categorical, ordinal and continuous data, and are widely used in practice. However, exact inference in GLMs is prohibitively expensive for large datasets, thus requiring approximations in practice. The resulting approximation error adversely impacts the reliability of the model and is not accounted for in the uncertainty of the prediction. In this work, we introduce a family of iterative methods that explicitly model this error. They are uniquely suited to parallel modern computing hardware, efficiently recycle computations, and compress information to reduce both the time and memory requirements for GLMs. As we demonstrate on a realistically large classification problem, our method significantly accelerates training by explicitly trading off reduced computation for increased uncertainty.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#22810;&#31181;&#24773;&#22659;&#19979;&#35777;&#26126;&#20102;&#27748;&#26222;&#26862;&#37319;&#26679;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;&#65292;&#24182;&#36890;&#36807;&#23545;&#20449;&#24687;&#27604;&#30340;&#31934;&#30830;&#20998;&#26512;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#26102;&#38388;&#19981;&#22343;&#21248;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#19978;&#30028;&#20272;&#35745;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#25214;&#21040;&#20102;&#21508;&#31181;&#35774;&#32622;&#20013;&#20855;&#20307;&#30340;&#30028;&#38480;&#65292;&#24182;&#35752;&#35770;&#20102;&#36825;&#20123;&#32467;&#26524;&#26159;&#31532;&#19968;&#20010;&#20854;&#31867;&#21035;&#25110;&#25913;&#36827;&#20102;&#26368;&#20808;&#36827;&#26041;&#27861;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2310.20007</link><description>&lt;p&gt;
&#25552;&#21319;&#24378;&#21270;&#23398;&#20064;&#20013;&#27748;&#26222;&#26862;&#37319;&#26679;&#30340;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;
&lt;/p&gt;
&lt;p&gt;
Improved Bayesian Regret Bounds for Thompson Sampling in Reinforcement Learning. (arXiv:2310.20007v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20007
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#22810;&#31181;&#24773;&#22659;&#19979;&#35777;&#26126;&#20102;&#27748;&#26222;&#26862;&#37319;&#26679;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;&#65292;&#24182;&#36890;&#36807;&#23545;&#20449;&#24687;&#27604;&#30340;&#31934;&#30830;&#20998;&#26512;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#26102;&#38388;&#19981;&#22343;&#21248;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#19978;&#30028;&#20272;&#35745;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#25214;&#21040;&#20102;&#21508;&#31181;&#35774;&#32622;&#20013;&#20855;&#20307;&#30340;&#30028;&#38480;&#65292;&#24182;&#35752;&#35770;&#20102;&#36825;&#20123;&#32467;&#26524;&#26159;&#31532;&#19968;&#20010;&#20854;&#31867;&#21035;&#25110;&#25913;&#36827;&#20102;&#26368;&#20808;&#36827;&#26041;&#27861;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#22312;&#22810;&#31181;&#24773;&#22659;&#19979;&#65292;&#27748;&#26222;&#26862;&#37319;&#26679;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#31532;&#19968;&#20010;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;&#12290;&#25105;&#20204;&#21033;&#29992;&#31163;&#25955;&#30340;&#20195;&#29702;&#29615;&#22659;&#31616;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#21518;&#39564;&#19968;&#33268;&#24615;&#23545;&#20449;&#24687;&#27604;&#36827;&#34892;&#20102;&#31934;&#30830;&#20998;&#26512;&#12290;&#36825;&#23548;&#33268;&#20102;&#19968;&#20010;&#22522;&#20110;&#26102;&#38388;&#19981;&#22343;&#21248;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#19978;&#30028;&#20272;&#35745;&#20026;$\widetilde{O}(H\sqrt{d_{l_1}T})$&#65292;&#20854;&#20013;$H$&#20026;&#22238;&#21512;&#38271;&#24230;&#65292;$d_{l_1}$&#20026;&#29615;&#22659;&#31354;&#38388;&#30340;Kolmogorov $l_1$&#32500;&#24230;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#22312;&#21508;&#31181;&#35774;&#32622;&#20013;&#25214;&#21040;&#20102;$d_{l_1}$&#30340;&#20855;&#20307;&#30028;&#38480;&#65292;&#27604;&#22914;&#34920;&#26684;&#12289;&#32447;&#24615;&#21644;&#26377;&#38480;&#28151;&#21512;&#65292;&#35752;&#35770;&#20102;&#25105;&#20204;&#30340;&#32467;&#26524;&#26159;&#31532;&#19968;&#20010;&#20854;&#31867;&#21035;&#25110;&#25913;&#36827;&#20102;&#26368;&#20808;&#36827;&#26041;&#27861;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we prove the first Bayesian regret bounds for Thompson Sampling in reinforcement learning in a multitude of settings. We simplify the learning problem using a discrete set of surrogate environments, and present a refined analysis of the information ratio using posterior consistency. This leads to an upper bound of order $\widetilde{O}(H\sqrt{d_{l_1}T})$ in the time inhomogeneous reinforcement learning problem where $H$ is the episode length and $d_{l_1}$ is the Kolmogorov $l_1-$dimension of the space of environments. We then find concrete bounds of $d_{l_1}$ in a variety of settings, such as tabular, linear and finite mixtures, and discuss how how our results are either the first of their kind or improve the state-of-the-art.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;Entropy-MCMC&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#20010;&#36741;&#21161;&#30340;&#24341;&#23548;&#21464;&#37327;&#26469;&#22312;&#24179;&#22374;&#30406;&#22320;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#20197;&#35299;&#20915;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#20998;&#24067;&#30340;&#22810;&#27169;&#24577;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.05401</link><description>&lt;p&gt;
Entropy-MCMC: &#36731;&#26494;&#20174;&#24179;&#22374;&#30406;&#22320;&#36827;&#34892;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Entropy-MCMC: Sampling from Flat Basins with Ease. (arXiv:2310.05401v1 [cs.LG] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05401
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;Entropy-MCMC&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#20010;&#36741;&#21161;&#30340;&#24341;&#23548;&#21464;&#37327;&#26469;&#22312;&#24179;&#22374;&#30406;&#22320;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#20197;&#35299;&#20915;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#20998;&#24067;&#30340;&#22810;&#27169;&#24577;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#20381;&#36182;&#20110;&#23545;&#21518;&#39564;&#20998;&#24067;&#30340;&#36136;&#37327;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#21518;&#39564;&#20998;&#24067;&#22312;&#24615;&#36136;&#19978;&#26159;&#39640;&#24230;&#22810;&#27169;&#24577;&#30340;&#65292;&#23616;&#37096;&#27169;&#24335;&#34920;&#29616;&#20986;&#19981;&#21516;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#22312;&#26377;&#38480;&#30340;&#35745;&#31639;&#36164;&#28304;&#19979;&#65292;&#20174;&#21407;&#22987;&#21518;&#39564;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#21487;&#33021;&#20250;&#23548;&#33268;&#27425;&#20248;&#24615;&#33021;&#65292;&#22240;&#20026;&#19968;&#20123;&#26679;&#26412;&#21487;&#33021;&#20250;&#38519;&#20837;&#8220;&#22351;&#8221;&#27169;&#24335;&#24182;&#20986;&#29616;&#36807;&#25311;&#21512;&#12290;&#22522;&#20110;&#35266;&#23519;&#21040;&#20302;&#27867;&#21270;&#35823;&#24046;&#30340;&#8220;&#22909;&#8221;&#27169;&#24335;&#36890;&#24120;&#23384;&#22312;&#20110;&#33021;&#37327;&#26223;&#35266;&#30340;&#24179;&#22374;&#30406;&#22320;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#20559;&#32622;&#37319;&#26679;&#26397;&#21521;&#36825;&#20123;&#24179;&#22374;&#21306;&#22495;&#30340;&#21518;&#39564;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#36741;&#21161;&#24341;&#23548;&#21464;&#37327;&#65292;&#20854;&#31283;&#24577;&#20998;&#24067;&#31867;&#20284;&#20110;&#24179;&#28369;&#21518;&#39564;&#20998;&#24067;&#65292;&#24182;&#19988;&#27809;&#26377;&#23574;&#38160;&#30340;&#27169;&#24577;&#65292;&#20197;&#24341;&#23548;MCMC&#37319;&#26679;&#22120;&#22312;&#24179;&#22374;&#30340;&#30406;&#22320;&#20013;&#37319;&#26679;&#12290;&#36890;&#36807;&#23558;&#27492;&#24341;&#23548;&#21464;&#37327;&#19982;&#27169;&#22411;&#21442;&#25968;&#30456;&#32467;&#21512;&#65292;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#32852;&#21512;&#20998;&#24067;&#65292;&#21487;&#20197;&#22312;&#26368;&#23567;&#35745;&#31639;&#24320;&#38144;&#19979;&#23454;&#29616;&#39640;&#25928;&#37319;&#26679;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#20803;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian deep learning counts on the quality of posterior distribution estimation. However, the posterior of deep neural networks is highly multi-modal in nature, with local modes exhibiting varying generalization performance. Given a practical budget, sampling from the original posterior can lead to suboptimal performance, as some samples may become trapped in "bad" modes and suffer from overfitting. Leveraging the observation that "good" modes with low generalization error often reside in flat basins of the energy landscape, we propose to bias sampling on the posterior toward these flat regions. Specifically, we introduce an auxiliary guiding variable, the stationary distribution of which resembles a smoothed posterior free from sharp modes, to lead the MCMC sampler to flat basins. By integrating this guiding variable with the model parameter, we create a simple joint distribution that enables efficient sampling with minimal computational overhead. We prove the convergence of our met
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#25968;&#25454;&#39640;&#25928;&#30340;&#22810;&#27169;&#24577;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#25506;&#32034;&#20102;&#29420;&#31435;&#38477;&#32500;&#21644;&#21516;&#26102;&#38477;&#32500;&#20004;&#31181;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#29983;&#25104;&#32447;&#24615;&#27169;&#22411;&#35780;&#20272;&#20102;&#20854;&#30456;&#23545;&#20934;&#30830;&#24615;&#21644;&#25968;&#25454;&#38598;&#22823;&#23567;&#35201;&#27714;&#12290;</title><link>http://arxiv.org/abs/2310.04458</link><description>&lt;p&gt;
&#21516;&#26102;&#38477;&#32500;&#65306;&#19968;&#31181;&#25968;&#25454;&#39640;&#25928;&#30340;&#22810;&#27169;&#24577;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Simultaneous Dimensionality Reduction: A Data Efficient Approach for Multimodal Representations Learning. (arXiv:2310.04458v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04458
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#25968;&#25454;&#39640;&#25928;&#30340;&#22810;&#27169;&#24577;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#25506;&#32034;&#20102;&#29420;&#31435;&#38477;&#32500;&#21644;&#21516;&#26102;&#38477;&#32500;&#20004;&#31181;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#29983;&#25104;&#32447;&#24615;&#27169;&#22411;&#35780;&#20272;&#20102;&#20854;&#30456;&#23545;&#20934;&#30830;&#24615;&#21644;&#25968;&#25454;&#38598;&#22823;&#23567;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#20004;&#31181;&#20027;&#35201;&#30340;&#38477;&#32500;&#26041;&#27861;&#65306;&#29420;&#31435;&#38477;&#32500;(IDR)&#21644;&#21516;&#26102;&#38477;&#32500;(SDR)&#12290;&#22312;IDR&#26041;&#27861;&#20013;&#65292;&#27599;&#20010;&#27169;&#24577;&#37117;&#34987;&#29420;&#31435;&#21387;&#32553;&#65292;&#21147;&#22270;&#20445;&#30041;&#27599;&#20010;&#27169;&#24577;&#20869;&#30340;&#23613;&#21487;&#33021;&#22810;&#30340;&#21464;&#21270;&#12290;&#30456;&#21453;&#65292;&#22312;SDR&#20013;&#65292;&#21516;&#26102;&#21387;&#32553;&#27169;&#24577;&#20197;&#26368;&#22823;&#21270;&#20943;&#23569;&#25551;&#36848;&#20043;&#38388;&#30340;&#21327;&#21464;&#24615;&#65292;&#21516;&#26102;&#23545;&#20445;&#30041;&#21333;&#20010;&#21464;&#21270;&#30340;&#31243;&#24230;&#19981;&#22826;&#20851;&#27880;&#12290;&#20856;&#22411;&#30340;&#20363;&#23376;&#21253;&#25324;&#20559;&#26368;&#23567;&#20108;&#20056;&#27861;&#21644;&#20856;&#22411;&#30456;&#20851;&#20998;&#26512;&#12290;&#34429;&#28982;&#36825;&#20123;&#38477;&#32500;&#26041;&#27861;&#26159;&#32479;&#35745;&#23398;&#30340;&#20027;&#35201;&#26041;&#27861;&#65292;&#20294;&#23427;&#20204;&#30340;&#30456;&#23545;&#31934;&#24230;&#21644;&#25968;&#25454;&#38598;&#22823;&#23567;&#35201;&#27714;&#23578;&#19981;&#28165;&#26970;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#29983;&#25104;&#32447;&#24615;&#27169;&#22411;&#26469;&#21512;&#25104;&#20855;&#26377;&#24050;&#30693;&#26041;&#24046;&#21644;&#21327;&#26041;&#24046;&#32467;&#26500;&#30340;&#22810;&#27169;&#24577;&#25968;&#25454;&#65292;&#20197;&#30740;&#31350;&#36825;&#20123;&#38382;&#39064;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#21327;&#26041;&#24046;&#30340;&#37325;&#26500;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We explore two primary classes of approaches to dimensionality reduction (DR): Independent Dimensionality Reduction (IDR) and Simultaneous Dimensionality Reduction (SDR). In IDR methods, of which Principal Components Analysis is a paradigmatic example, each modality is compressed independently, striving to retain as much variation within each modality as possible. In contrast, in SDR, one simultaneously compresses the modalities to maximize the covariation between the reduced descriptions while paying less attention to how much individual variation is preserved. Paradigmatic examples include Partial Least Squares and Canonical Correlations Analysis. Even though these DR methods are a staple of statistics, their relative accuracy and data set size requirements are poorly understood. We introduce a generative linear model to synthesize multimodal data with known variance and covariance structures to examine these questions. We assess the accuracy of the reconstruction of the covariance s
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#22312;&#21482;&#33021;&#36890;&#36807;&#19968;&#33268;&#24615;&#39044;&#35328;&#26426;&#35775;&#38382;&#31867;&#30340;&#27169;&#22411;&#19979;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#31616;&#21333;&#19988;&#25928;&#26524;&#26356;&#22909;&#30340;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#26368;&#22810;&#20250;&#29359;O(256^d)&#20010;&#38169;&#35823;&#65292;&#24182;&#35266;&#23519;&#21040;&#19981;&#23384;&#22312;&#19968;&#20010;&#26368;&#22810;&#20250;&#29359;2^(d+1)-2&#20010;&#38169;&#35823;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.08055</link><description>&lt;p&gt;
&#36890;&#36807;&#19968;&#33268;&#24615;&#39044;&#35328;&#26426;&#36827;&#34892;&#31616;&#21333;&#30340;&#22312;&#32447;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Simple online learning with consistency oracle. (arXiv:2308.08055v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08055
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#22312;&#21482;&#33021;&#36890;&#36807;&#19968;&#33268;&#24615;&#39044;&#35328;&#26426;&#35775;&#38382;&#31867;&#30340;&#27169;&#22411;&#19979;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#31616;&#21333;&#19988;&#25928;&#26524;&#26356;&#22909;&#30340;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#26368;&#22810;&#20250;&#29359;O(256^d)&#20010;&#38169;&#35823;&#65292;&#24182;&#35266;&#23519;&#21040;&#19981;&#23384;&#22312;&#19968;&#20010;&#26368;&#22810;&#20250;&#29359;2^(d+1)-2&#20010;&#38169;&#35823;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#21482;&#33021;&#36890;&#36807;&#19968;&#33268;&#24615;&#39044;&#35328;&#26426;&#35775;&#38382;&#31867;&#30340;&#27169;&#22411;&#19979;&#30340;&#22312;&#32447;&#23398;&#20064;&#8212;&#8212;&#22312;&#20219;&#20309;&#26102;&#21051;&#65292;&#39044;&#35328;&#26426;&#37117;&#33021;&#32473;&#20986;&#19982;&#30446;&#21069;&#20026;&#27490;&#30475;&#21040;&#30340;&#25152;&#26377;&#31034;&#20363;&#19968;&#33268;&#30340;&#31867;&#20989;&#25968;&#12290;&#35813;&#27169;&#22411;&#26368;&#36817;&#30001;Assos&#31561;&#20154;&#65288;COLT'23&#65289;&#32771;&#34385;&#12290;&#36825;&#20010;&#27169;&#22411;&#30340;&#21160;&#26426;&#26159;&#26631;&#20934;&#30340;&#22312;&#32447;&#23398;&#20064;&#26041;&#27861;&#20381;&#36182;&#20110;&#35745;&#31639;&#23376;&#31867;&#30340;Littlestone&#32500;&#24230;&#65292;&#36825;&#26159;&#19968;&#20010;&#35745;&#31639;&#22797;&#26434;&#30340;&#38382;&#39064;&#12290;Assos&#31561;&#20154;&#22312;&#36825;&#20010;&#27169;&#22411;&#20013;&#32473;&#20986;&#20102;&#19968;&#20010;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#23545;&#20110;Littlestone&#32500;&#24230;&#20026;d&#30340;&#31867;&#65292;&#26368;&#22810;&#20250;&#29359;C^d&#20010;&#38169;&#35823;&#65292;&#20854;&#20013;C&#26159;&#19968;&#20010;&#26410;&#25351;&#23450;&#30340;&#32477;&#23545;&#24120;&#25968;&#19988;&#22823;&#20110;0&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#31639;&#27861;&#65292;&#26368;&#22810;&#20250;&#29359;O(256^d)&#20010;&#38169;&#35823;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#26356;&#31616;&#21333;&#65292;&#21482;&#20351;&#29992;&#20102;Littlestone&#32500;&#24230;&#30340;&#22522;&#26412;&#23646;&#24615;&#12290;&#25105;&#20204;&#36824;&#35266;&#23519;&#21040;&#65292;&#19981;&#23384;&#22312;&#19968;&#20010;&#22312;&#36825;&#20010;&#27169;&#22411;&#20013;&#26368;&#22810;&#20250;&#29359;2^(d+1)-2&#20010;&#38169;&#35823;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#36824;&#35266;&#23519;&#21040;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#65288;&#20197;&#21450;Assos&#31561;&#20154;&#30340;&#31639;&#27861;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider online learning in the model where a learning algorithm can access the class only via the consistency oracle -- an oracle, that, at any moment, can give a function from the class that agrees with all examples seen so far. This model was recently considered by Assos et al. (COLT'23). It is motivated by the fact that standard methods of online learning rely on computing the Littlestone dimension of subclasses, a problem that is computationally intractable. Assos et al. gave an online learning algorithm in this model that makes at most $C^d$ mistakes on classes of Littlestone dimension $d$, for some absolute unspecified constant $C &gt; 0$. We give a novel algorithm that makes at most $O(256^d)$ mistakes. Our proof is significantly simpler and uses only very basic properties of the Littlestone dimension. We also observe that there exists no algorithm in this model that makes at most $2^{d+1}-2$ mistakes. We also observe that our algorithm (as well as the algorithm of Assos et al.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#22823;&#20559;&#24046;&#29702;&#35770;&#65292;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20989;&#25968;&#30340;&#24179;&#28369;&#27169;&#22411;&#29305;&#24449;&#25551;&#36848;&#26041;&#27861;&#65292;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#19968;&#20123;&#25554;&#20540;&#22120;&#26377;&#24456;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#20197;&#21450;&#29616;&#20195;&#23398;&#20064;&#25216;&#26415;&#20026;&#20160;&#20040;&#33021;&#22815;&#25214;&#21040;&#23427;&#20204;&#12290;</title><link>http://arxiv.org/abs/2306.10947</link><description>&lt;p&gt;
&#20351;&#29992;&#36895;&#29575;&#20989;&#25968;&#29702;&#35299;&#25554;&#20540;&#21306;&#38388;&#30340;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Understanding Generalization in the Interpolation Regime using the Rate Function. (arXiv:2306.10947v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10947
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#22823;&#20559;&#24046;&#29702;&#35770;&#65292;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20989;&#25968;&#30340;&#24179;&#28369;&#27169;&#22411;&#29305;&#24449;&#25551;&#36848;&#26041;&#27861;&#65292;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#19968;&#20123;&#25554;&#20540;&#22120;&#26377;&#24456;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#20197;&#21450;&#29616;&#20195;&#23398;&#20064;&#25216;&#26415;&#20026;&#20160;&#20040;&#33021;&#22815;&#25214;&#21040;&#23427;&#20204;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22522;&#20110;&#22823;&#20559;&#24046;&#29702;&#35770;&#30340;&#22522;&#26412;&#21407;&#29702;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#24179;&#28369;&#24230;&#30340;&#26032;&#29305;&#24449;&#25551;&#36848;&#26041;&#27861;&#12290;&#19982;&#20197;&#24448;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#20197;&#24448;&#30340;&#24037;&#20316;&#36890;&#24120;&#29992;&#23454;&#25968;&#20540;&#65288;&#22914;&#26435;&#37325;&#33539;&#25968;&#65289;&#26469;&#34920;&#24449;&#27169;&#22411;&#30340;&#24179;&#28369;&#24230;&#65292;&#25105;&#20204;&#34920;&#26126;&#21487;&#20197;&#29992;&#31616;&#21333;&#30340;&#23454;&#20540;&#20989;&#25968;&#26469;&#25551;&#36848;&#24179;&#28369;&#24230;&#12290;&#22522;&#20110;&#27169;&#22411;&#24179;&#28369;&#24230;&#30340;&#36825;&#19968;&#27010;&#24565;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#29702;&#35770;&#35299;&#37322;&#65292;&#20026;&#20160;&#20040;&#19968;&#20123;&#25554;&#20540;&#22120;&#34920;&#29616;&#20986;&#38750;&#24120;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#20197;&#21450;&#20026;&#20160;&#20040;&#24191;&#27867;&#20351;&#29992;&#30340;&#29616;&#20195;&#23398;&#20064;&#25216;&#26415;&#65288;&#22914;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65292;$\ell_2$-&#35268;&#33539;&#21270;&#65292;&#25968;&#25454;&#22686;&#24378;&#65292;&#19981;&#21464;&#30340;&#26550;&#26500;&#21644;&#36229;&#21442;&#25968;&#21270;&#65289;&#33021;&#22815;&#25214;&#21040;&#23427;&#20204;&#12290;&#25105;&#20204;&#24471;&#20986;&#30340;&#32467;&#35770;&#26159;&#65292;&#25152;&#26377;&#36825;&#20123;&#26041;&#27861;&#37117;&#25552;&#20379;&#20102;&#20114;&#34917;&#30340;&#36807;&#31243;&#65292;&#36825;&#20123;&#36807;&#31243;&#20351;&#20248;&#21270;&#22120;&#20559;&#21521;&#20110;&#26356;&#24179;&#28369;&#30340;&#25554;&#20540;&#22120;&#65292;&#32780;&#26681;&#25454;&#36825;&#31181;&#29702;&#35770;&#20998;&#26512;&#65292;&#26356;&#24179;&#28369;&#30340;&#25554;&#20540;&#22120;&#26159;&#20855;&#26377;&#26356;&#22909;&#30340;&#27867;&#21270;&#35823;&#24046;&#30340;&#25554;&#20540;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present a novel characterization of the smoothness of a model based on basic principles of Large Deviation Theory. In contrast to prior work, where the smoothness of a model is normally characterized by a real value (e.g., the weights' norm), we show that smoothness can be described by a simple real-valued function. Based on this concept of smoothness, we propose an unifying theoretical explanation of why some interpolators generalize remarkably well and why a wide range of modern learning techniques (i.e., stochastic gradient descent, $\ell_2$-norm regularization, data augmentation, invariant architectures, and overparameterization) are able to find them. The emergent conclusion is that all these methods provide complimentary procedures that bias the optimizer to smoother interpolators, which, according to this theoretical analysis, are the ones with better generalization error.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;&#31614;&#21517;&#26465;&#30721;&#26469;&#31283;&#23450;&#21521;&#37327;&#21270;&#22810;&#21442;&#25968;&#25345;&#20037;&#21516;&#35843;&#65292;&#23558;&#22810;&#21442;&#25968;&#25345;&#20037;&#21516;&#35843;&#30340;&#20016;&#23500;&#20449;&#24687;&#21644;&#31283;&#23450;&#21521;&#37327;&#21270;&#30340;&#20248;&#21183;&#30456;&#32467;&#21512;&#12290;</title><link>http://arxiv.org/abs/2306.03801</link><description>&lt;p&gt;
&#31614;&#21517;&#26465;&#30721;&#20316;&#20026;&#24230;&#37327;&#30340;&#22810;&#21442;&#25968;&#25345;&#20037;&#21516;&#35843;&#30340;&#31283;&#23450;&#21521;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Stable Vectorization of Multiparameter Persistent Homology using Signed Barcodes as Measures. (arXiv:2306.03801v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03801
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;&#31614;&#21517;&#26465;&#30721;&#26469;&#31283;&#23450;&#21521;&#37327;&#21270;&#22810;&#21442;&#25968;&#25345;&#20037;&#21516;&#35843;&#65292;&#23558;&#22810;&#21442;&#25968;&#25345;&#20037;&#21516;&#35843;&#30340;&#20016;&#23500;&#20449;&#24687;&#21644;&#31283;&#23450;&#21521;&#37327;&#21270;&#30340;&#20248;&#21183;&#30456;&#32467;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25345;&#20037;&#21516;&#35843;&#65288;PH&#65289;&#25552;&#20379;&#20102;&#20960;&#20309;&#25968;&#25454;&#65288;&#20363;&#22914;&#21152;&#26435;&#22270;&#65289;&#30340;&#25299;&#25169;&#25551;&#36848;&#31526;&#65292;&#23427;&#20204;&#26159;&#21487;&#35299;&#37322;&#30340;&#65292;&#23545;&#25200;&#21160;&#31283;&#23450;&#65292;&#24182;&#20855;&#26377;&#35832;&#22914;&#37325;&#26631;&#35760;&#31561;&#19981;&#21464;&#24615;&#12290;&#22823;&#22810;&#25968;PH&#24212;&#29992;&#20851;&#27880;&#19968;&#21442;&#25968;&#24773;&#20917;&#8212;&#8212;&#25551;&#36848;&#31526;&#24635;&#32467;&#25968;&#25454;&#30340;&#25299;&#25169;&#38543;&#30528;&#21333;&#20010;&#24863;&#20852;&#36259;&#22240;&#32032;&#30340;&#28388;&#27874;&#32780;&#21457;&#29983;&#21464;&#21270;&#65307;&#29616;&#22312;&#65292;&#26377;&#21508;&#31181;&#26041;&#27861;&#20351;&#24471;&#19968;&#21442;&#25968;PH&#25551;&#36848;&#31526;&#22312;&#25968;&#25454;&#31185;&#23398;&#20013;&#24471;&#21040;&#24212;&#29992;&#65292;&#24182;&#19988;&#20381;&#36182;&#20110;&#23558;&#36825;&#20123;&#25551;&#36848;&#31526;&#31283;&#23450;&#21521;&#37327;&#21270;&#20026;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;&#20803;&#32032;&#12290;&#34429;&#28982;&#30001;&#20960;&#20010;&#24863;&#20852;&#36259;&#22240;&#32032;&#36807;&#28388;&#30340;&#25968;&#25454;&#30340;&#22810;&#21442;&#25968;PH&#65288;MPH&#65289;&#32534;&#30721;&#27604;&#20854;&#19968;&#21442;&#25968;&#21516;&#22411;&#30340;&#20449;&#24687;&#26356;&#20016;&#23500;&#65292;&#20294;&#36804;&#20170;&#20026;&#27490;&#65292;MPH&#25551;&#36848;&#31526;&#30340;&#31283;&#23450;&#24615;&#32467;&#26524;&#30340;&#31232;&#32570;&#24615;&#24050;&#32463;&#38480;&#21046;&#20102;MPH&#30340;&#31283;&#23450;&#21521;&#37327;&#21270;&#30340;&#21487;&#29992;&#36873;&#39033;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#36890;&#36807;&#23637;&#31034;&#22914;&#20309;&#35299;&#37322;&#31614;&#21517;&#26465;&#30721;&#26469;&#38598;&#32467;&#20004;&#26041;&#38754;&#30340;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Persistent homology (PH) provides topological descriptors for geometric data, such as weighted graphs, which are interpretable, stable to perturbations, and invariant under, e.g., relabeling. Most applications of PH focus on the one-parameter case -- where the descriptors summarize the changes in topology of data as it is filtered by a single quantity of interest -- and there is now a wide array of methods enabling the use of one-parameter PH descriptors in data science, which rely on the stable vectorization of these descriptors as elements of a Hilbert space. Although the multiparameter PH (MPH) of data that is filtered by several quantities of interest encodes much richer information than its one-parameter counterpart, the scarceness of stability results for MPH descriptors has so far limited the available options for the stable vectorization of MPH. In this paper, we aim to bring together the best of both worlds by showing how the interpretation of signed barcodes -- a recent famil
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#30452;&#25509;&#26368;&#23567;&#21270;&#36125;&#21494;&#26031;&#36951;&#25022;&#19978;&#30028;&#30340;&#26032;&#26041;&#27861;&#65292;&#33719;&#24471;&#26356;&#22909;&#30340;&#29702;&#35770;&#31163;&#32447;&#36951;&#25022;&#30028;&#21644;&#25968;&#20540;&#27169;&#25311;&#32467;&#26524;&#65292;&#24182;&#25552;&#20379;&#20102;&#35777;&#25454;&#34920;&#26126;&#27969;&#34892;&#30340;LCB-style&#31639;&#27861;&#21487;&#33021;&#19981;&#36866;&#29992;&#12290;</title><link>http://arxiv.org/abs/2306.01237</link><description>&lt;p&gt;
&#31163;&#32447;&#36172;&#21338;&#20013;&#36125;&#21494;&#26031;&#36951;&#25022;&#26368;&#23567;&#21270;&#30340;&#20984;&#26494;&#24347;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Convex Relaxation Approach to Bayesian Regret Minimization in Offline Bandits. (arXiv:2306.01237v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01237
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#30452;&#25509;&#26368;&#23567;&#21270;&#36125;&#21494;&#26031;&#36951;&#25022;&#19978;&#30028;&#30340;&#26032;&#26041;&#27861;&#65292;&#33719;&#24471;&#26356;&#22909;&#30340;&#29702;&#35770;&#31163;&#32447;&#36951;&#25022;&#30028;&#21644;&#25968;&#20540;&#27169;&#25311;&#32467;&#26524;&#65292;&#24182;&#25552;&#20379;&#20102;&#35777;&#25454;&#34920;&#26126;&#27969;&#34892;&#30340;LCB-style&#31639;&#27861;&#21487;&#33021;&#19981;&#36866;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#36172;&#21338;&#31639;&#27861;&#24517;&#39035;&#20165;&#21033;&#29992;&#31163;&#32447;&#25968;&#25454;&#22312;&#19981;&#30830;&#23450;&#29615;&#22659;&#20013;&#20248;&#21270;&#20915;&#31574;&#12290;&#31163;&#32447;&#36172;&#21338;&#20013;&#19968;&#31181;&#24341;&#20154;&#27880;&#30446;&#19988;&#36880;&#28176;&#27969;&#34892;&#30340;&#30446;&#26631;&#26159;&#23398;&#20064;&#19968;&#20010;&#23454;&#29616;&#20302;&#36125;&#21494;&#26031;&#36951;&#25022;&#24182;&#20855;&#26377;&#39640;&#32622;&#20449;&#24230;&#30340;&#31574;&#30053;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#30452;&#25509;&#21033;&#29992;&#39640;&#25928;&#30340;&#38181;&#20248;&#21270;&#27714;&#35299;&#22120;&#26469;&#26368;&#23567;&#21270;&#36125;&#21494;&#26031;&#36951;&#25022;&#30340;&#19978;&#30028;&#12290;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#29702;&#35770;&#19978;&#33719;&#24471;&#20102;&#26356;&#20248;&#30340;&#31163;&#32447;&#36951;&#25022;&#30028;&#65292;&#24182;&#22312;&#25968;&#20540;&#27169;&#25311;&#20013;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#19968;&#20123;&#35777;&#25454;&#34920;&#26126;&#27969;&#34892;&#30340;LCB&#65288;lower confidence bound&#65289;-style&#31639;&#27861;&#21487;&#33021;&#19981;&#36866;&#21512;&#31163;&#32447;&#36172;&#21338;&#20013;&#26368;&#23567;&#21270;&#36125;&#21494;&#26031;&#36951;&#25022;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithms for offline bandits must optimize decisions in uncertain environments using only offline data. A compelling and increasingly popular objective in offline bandits is to learn a policy which achieves low Bayesian regret with high confidence. An appealing approach to this problem, inspired by recent offline reinforcement learning results, is to maximize a form of lower confidence bound (LCB). This paper proposes a new approach that directly minimizes upper bounds on Bayesian regret using efficient conic optimization solvers. Our bounds build on connections among Bayesian regret, Value-at-Risk (VaR), and chance-constrained optimization. Compared to prior work, our algorithm attains superior theoretical offline regret bounds and better results in numerical simulations. Finally, we provide some evidence that popular LCB-style algorithms may be unsuitable for minimizing Bayesian regret in offline bandits.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#30053;&#24494;&#36229;&#21442;&#25968;&#21270;&#30340;ReLU&#32593;&#32476;&#22312;&#26377;&#38480;&#36755;&#20837;&#25968;&#25454;&#38598;&#19978;&#30340;&#25439;&#22833;&#26223;&#35266;&#65292;&#35777;&#26126;&#20102;&#22823;&#22810;&#25968;&#28608;&#27963;&#27169;&#24335;&#23545;&#24212;&#30340;&#21442;&#25968;&#21306;&#22495;&#27809;&#26377;&#22351;&#30340;&#21487;&#24494;&#23616;&#37096;&#26497;&#23567;&#20540;&#65292;&#23545;&#20110;&#19968;&#32500;&#36755;&#20837;&#25968;&#25454;&#65292;&#32593;&#32476;&#21487;&#20197;&#36890;&#36807;&#22823;&#22810;&#25968;&#28608;&#27963;&#27169;&#24335;&#23454;&#29616;&#39640;&#32500;&#20840;&#23616;&#26497;&#23567;&#20540;&#38598;&#21512;&#32780;&#19981;&#20855;&#26377;&#22351;&#30340;&#23616;&#37096;&#26497;&#23567;&#20540;&#12290;</title><link>http://arxiv.org/abs/2305.19510</link><description>&lt;p&gt;
&#30053;&#24494;&#36229;&#21442;&#25968;&#21270;&#30340;ReLU&#32593;&#32476;&#20855;&#26377;&#26377;&#21033;&#30340;&#25439;&#22833;&#26223;&#35266;
&lt;/p&gt;
&lt;p&gt;
Mildly Overparameterized ReLU Networks Have a Favorable Loss Landscape. (arXiv:2305.19510v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19510
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#30053;&#24494;&#36229;&#21442;&#25968;&#21270;&#30340;ReLU&#32593;&#32476;&#22312;&#26377;&#38480;&#36755;&#20837;&#25968;&#25454;&#38598;&#19978;&#30340;&#25439;&#22833;&#26223;&#35266;&#65292;&#35777;&#26126;&#20102;&#22823;&#22810;&#25968;&#28608;&#27963;&#27169;&#24335;&#23545;&#24212;&#30340;&#21442;&#25968;&#21306;&#22495;&#27809;&#26377;&#22351;&#30340;&#21487;&#24494;&#23616;&#37096;&#26497;&#23567;&#20540;&#65292;&#23545;&#20110;&#19968;&#32500;&#36755;&#20837;&#25968;&#25454;&#65292;&#32593;&#32476;&#21487;&#20197;&#36890;&#36807;&#22823;&#22810;&#25968;&#28608;&#27963;&#27169;&#24335;&#23454;&#29616;&#39640;&#32500;&#20840;&#23616;&#26497;&#23567;&#20540;&#38598;&#21512;&#32780;&#19981;&#20855;&#26377;&#22351;&#30340;&#23616;&#37096;&#26497;&#23567;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26377;&#38480;&#36755;&#20837;&#25968;&#25454;&#38598;&#19978;&#65292;&#20108;&#23618;&#30053;&#24494;&#36229;&#21442;&#25968;&#21270;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#25439;&#22833;&#26223;&#35266;&#65292;&#20351;&#29992;&#20102;&#21442;&#25968;&#26144;&#23556;&#30340;Jacobian&#30697;&#38453;&#30340;&#31209;&#26469;&#20272;&#35745;&#23616;&#37096;&#21644;&#20840;&#23616;&#26497;&#23567;&#20540;&#38598;&#30340;&#32500;&#24230;&#12290;&#20351;&#29992;&#38543;&#26426;&#20108;&#36827;&#21046;&#30697;&#38453;&#30340;&#32467;&#26524;&#65292;&#25105;&#20204;&#35777;&#26126;&#22823;&#22810;&#25968;&#28608;&#27963;&#27169;&#24335;&#23545;&#24212;&#30340;&#21442;&#25968;&#21306;&#22495;&#27809;&#26377;&#22351;&#30340;&#21487;&#24494;&#23616;&#37096;&#26497;&#23567;&#20540;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#19968;&#32500;&#36755;&#20837;&#25968;&#25454;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#32593;&#32476;&#21487;&#20197;&#36890;&#36807;&#22823;&#22810;&#25968;&#30340;&#28608;&#27963;&#27169;&#24335;&#23454;&#29616;&#39640;&#32500;&#20840;&#23616;&#26497;&#23567;&#20540;&#38598;&#21512;&#32780;&#19981;&#20855;&#26377;&#22351;&#30340;&#23616;&#37096;&#26497;&#23567;&#20540;&#12290;&#25105;&#20204;&#36890;&#36807;&#21457;&#29616;&#22823;&#22810;&#25968;&#21306;&#22495;&#20855;&#26377;&#23436;&#25972;&#30340;&#31209;&#25110;&#32570;&#20047;&#31209;&#65292;&#20197;&#23454;&#39564;&#30340;&#26041;&#24335;&#35777;&#23454;&#20102;&#36825;&#20123;&#32467;&#26524;&#65292;&#36825;&#21462;&#20915;&#20110;&#36229;&#21442;&#25968;&#30340;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the loss landscape of two-layer mildly overparameterized ReLU neural networks on a generic finite input dataset for the squared error loss. Our approach involves bounding the dimension of the sets of local and global minima using the rank of the Jacobian of the parameterization map. Using results on random binary matrices, we show most activation patterns correspond to parameter regions with no bad differentiable local minima. Furthermore, for one-dimensional input data, we show most activation regions realizable by the network contain a high dimensional set of global minima and no bad local minima. We experimentally confirm these results by finding a phase transition from most regions having full rank to many regions having deficient rank depending on the amount of overparameterization.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#23558;&#20998;&#26512;&#21644;&#25968;&#20540;&#25512;&#23548;&#32467;&#21512;&#65292;&#22312;&#22522;&#20110;&#24191;&#20041; Potts &#27169;&#22411;&#30340;&#25968;&#25454;&#19978;&#65292;&#23545;&#32463;&#36807;&#25913;&#36827;&#36866;&#24212;&#36825;&#31181;&#27169;&#22411;&#30340;self-attention&#26426;&#21046;&#36827;&#34892;&#35757;&#32451;&#65292;&#21457;&#29616;&#32463;&#36807;&#20462;&#25913;&#30340;self-attention&#26426;&#21046;&#21487;&#20197;&#22312;&#26497;&#38480;&#37319;&#26679;&#19979;&#20934;&#30830;&#23398;&#20064;Potts&#27169;&#22411;&#12290;&#36825;&#20010;&#8220;&#20998;&#35299;&#8221;&#27880;&#24847;&#21147;&#26426;&#21046;&#36890;&#36807;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#30456;&#20851;&#23646;&#24615;&#65292;&#21487;&#20197;&#25552;&#39640;Transformer&#30340;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.07235</link><description>&lt;p&gt;
&#21033;&#29992;&#20998;&#35299;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#21333;&#23618;Transformer&#23545;&#24191;&#20041;Potts&#27169;&#22411;&#36827;&#34892;&#26368;&#20248;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Optimal inference of a generalised Potts model by single-layer transformers with factored attention. (arXiv:2304.07235v1 [cond-mat.dis-nn])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07235
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;&#20998;&#26512;&#21644;&#25968;&#20540;&#25512;&#23548;&#32467;&#21512;&#65292;&#22312;&#22522;&#20110;&#24191;&#20041; Potts &#27169;&#22411;&#30340;&#25968;&#25454;&#19978;&#65292;&#23545;&#32463;&#36807;&#25913;&#36827;&#36866;&#24212;&#36825;&#31181;&#27169;&#22411;&#30340;self-attention&#26426;&#21046;&#36827;&#34892;&#35757;&#32451;&#65292;&#21457;&#29616;&#32463;&#36807;&#20462;&#25913;&#30340;self-attention&#26426;&#21046;&#21487;&#20197;&#22312;&#26497;&#38480;&#37319;&#26679;&#19979;&#20934;&#30830;&#23398;&#20064;Potts&#27169;&#22411;&#12290;&#36825;&#20010;&#8220;&#20998;&#35299;&#8221;&#27880;&#24847;&#21147;&#26426;&#21046;&#36890;&#36807;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#30456;&#20851;&#23646;&#24615;&#65292;&#21487;&#20197;&#25552;&#39640;Transformer&#30340;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer &#26159;&#19968;&#31181;&#38761;&#21629;&#24615;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#34507;&#30333;&#36136;&#31185;&#23398;&#26041;&#38754;&#21462;&#24471;&#20102;&#23454;&#36341;&#19978;&#30340;&#25104;&#21151;&#12290;&#23427;&#20204;&#30340;&#20851;&#38190;&#26500;&#24314;&#22359;&#26159;&#19968;&#20010;&#21483;&#20570;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26426;&#21046;&#65292;&#23427;&#34987;&#35757;&#32451;&#29992;&#20110;&#39044;&#27979;&#21477;&#23376;&#20013;&#32570;&#22833;&#30340;&#35789;&#12290;&#23613;&#31649;Transformer&#22312;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#23454;&#36341;&#19978;&#30340;&#25104;&#21151;&#65292;&#20294;&#26159;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#31350;&#31455;&#20174;&#25968;&#25454;&#20013;&#23398;&#21040;&#20102;&#20160;&#20040;&#20197;&#21450;&#23427;&#26159;&#24590;&#20040;&#20570;&#21040;&#30340;&#36824;&#19981;&#26159;&#24456;&#28165;&#26970;&#12290;&#26412;&#25991;&#38024;&#23545;&#20174;&#20855;&#26377;&#30456;&#20114;&#20316;&#29992;&#30340;&#20301;&#32622;&#21644; Potts &#39068;&#33394;&#20013;&#25552;&#21462;&#30340;&#25968;&#25454;&#22312;&#35757;&#32451;&#30340;Transformer&#19978;&#32473;&#20986;&#20102;&#31934;&#30830;&#30340;&#20998;&#26512;&#21644;&#25968;&#20540;&#21051;&#30011;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#34429;&#28982;&#19968;&#33324;&#30340;transformer&#38656;&#35201;&#22810;&#23618;&#23398;&#20064;&#25165;&#33021;&#20934;&#30830;&#23398;&#20064;&#36825;&#20010;&#20998;&#24067;&#65292;&#20294;&#26159;&#32463;&#36807;&#23567;&#25913;&#36827;&#30340;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#22312;&#26080;&#38480;&#37319;&#26679;&#30340;&#26497;&#38480;&#19979;&#21487;&#20197;&#23436;&#32654;&#22320;&#23398;&#20064;Potts&#27169;&#22411;&#12290;&#25105;&#20204;&#36824;&#35745;&#31639;&#20102;&#36825;&#20010;&#20462;&#25913;&#21518;&#30340;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#25152;&#35859;&#8220;&#20998;&#35299;&#8221;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#25968;&#20540;&#28436;&#31034;&#20102;&#25105;&#20204;&#30340;&#21457;&#29616;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20026;&#35299;&#37322;Transformer&#30340;&#20869;&#22312;&#24037;&#20316;&#21407;&#29702;&#20197;&#21450;&#25552;&#39640;&#20854;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#25552;&#20379;&#20102;&#26032;&#30340;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformers are the type of neural networks that has revolutionised natural language processing and protein science. Their key building block is a mechanism called self-attention which is trained to predict missing words in sentences. Despite the practical success of transformers in applications it remains unclear what self-attention learns from data, and how. Here, we give a precise analytical and numerical characterisation of transformers trained on data drawn from a generalised Potts model with interactions between sites and Potts colours. While an off-the-shelf transformer requires several layers to learn this distribution, we show analytically that a single layer of self-attention with a small modification can learn the Potts model exactly in the limit of infinite sampling. We show that this modified self-attention, that we call ``factored'', has the same functional form as the conditional probability of a Potts spin given the other spins, compute its generalisation error using t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#22810;&#20803;&#27010;&#29575;CRPS&#23398;&#20064;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#26085;&#21069;&#30005;&#20215;&#39044;&#27979;&#20013;&#65292;&#30456;&#27604;&#20110;&#32479;&#19968;&#32452;&#21512;&#22312;CRPS&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2303.10019</link><description>&lt;p&gt;
&#22810;&#20803;&#27010;&#29575;CRPS&#23398;&#20064;&#21450;&#20854;&#22312;&#26085;&#21069;&#30005;&#20215;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Multivariate Probabilistic CRPS Learning with an Application to Day-Ahead Electricity Prices. (arXiv:2303.10019v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10019
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#22810;&#20803;&#27010;&#29575;CRPS&#23398;&#20064;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#26085;&#21069;&#30005;&#20215;&#39044;&#27979;&#20013;&#65292;&#30456;&#27604;&#20110;&#32479;&#19968;&#32452;&#21512;&#22312;CRPS&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32771;&#34385;&#20998;&#20301;&#25968;&#21644;&#21327;&#21464;&#37327;&#20381;&#36182;&#20851;&#31995;&#30340;&#22810;&#20803;&#27010;&#29575;&#39044;&#27979;&#30340;&#32467;&#21512;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#24179;&#28369;&#36807;&#31243;&#20801;&#35768;&#22312;&#32447;&#23398;&#20064;&#12290;&#36890;&#36807;&#32500;&#25968;&#38477;&#20302;&#21644;&#32602;&#20989;&#25968;&#24179;&#28369;&#31561;&#20004;&#31181;&#24179;&#28369;&#26041;&#27861;&#26469;&#23558;&#26631;&#20934;CRPS&#23398;&#20064;&#26694;&#26550;&#25512;&#24191;&#21040;&#22810;&#20803;&#32500;&#24230;&#20013;&#12290;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#39044;&#27979;&#26085;&#21069;&#30005;&#20215;&#65292;&#30456;&#27604;&#20110;&#32479;&#19968;&#32452;&#21512;&#65292;&#22312;CRPS&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a new method for combining (or aggregating or ensembling) multivariate probabilistic forecasts, taking into account dependencies between quantiles and covariates through a smoothing procedure that allows for online learning. Two smoothing methods are discussed: dimensionality reduction using Basis matrices and penalized smoothing. The new online learning algorithm generalizes the standard CRPS learning framework into multivariate dimensions. It is based on Bernstein Online Aggregation (BOA) and yields optimal asymptotic learning properties. We provide an in-depth discussion on possible extensions of the algorithm and several nested cases related to the existing literature on online forecast combination. The methodology is applied to forecasting day-ahead electricity prices, which are 24-dimensional distributional forecasts. The proposed method yields significant improvements over uniform combination in terms of continuous ranked probability score (CRPS). We discuss 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20998;&#25968;&#30340;&#26465;&#20214;&#27169;&#22411;&#20013;&#23398;&#20064;&#34920;&#31034;&#30340;&#32467;&#26500;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#25968;&#23398;&#24418;&#24335;&#21270;&#34920;&#36798;&#27010;&#24565;&#34987;&#32534;&#30721;&#20026;&#34920;&#31034;&#31354;&#38388;&#23376;&#31354;&#38388;&#30340;&#24605;&#24819;&#12290;&#21033;&#29992;&#36825;&#20010;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#32473;&#23450;&#27010;&#24565;&#23545;&#24212;&#30340;&#34920;&#31034;&#37096;&#20998;&#65292;&#24182;&#36890;&#36807;&#20195;&#25968;&#25805;&#20316;&#25805;&#32437;&#27169;&#22411;&#25152;&#34920;&#36798;&#30340;&#27010;&#24565;&#12290;</title><link>http://arxiv.org/abs/2302.03693</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#25968;&#30340;&#26465;&#20214;&#27169;&#22411;&#30340;&#27010;&#24565;&#20195;&#25968;
&lt;/p&gt;
&lt;p&gt;
Concept Algebra for Score-Based Conditional Models. (arXiv:2302.03693v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03693
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20998;&#25968;&#30340;&#26465;&#20214;&#27169;&#22411;&#20013;&#23398;&#20064;&#34920;&#31034;&#30340;&#32467;&#26500;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#25968;&#23398;&#24418;&#24335;&#21270;&#34920;&#36798;&#27010;&#24565;&#34987;&#32534;&#30721;&#20026;&#34920;&#31034;&#31354;&#38388;&#23376;&#31354;&#38388;&#30340;&#24605;&#24819;&#12290;&#21033;&#29992;&#36825;&#20010;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#32473;&#23450;&#27010;&#24565;&#23545;&#24212;&#30340;&#34920;&#31034;&#37096;&#20998;&#65292;&#24182;&#36890;&#36807;&#20195;&#25968;&#25805;&#20316;&#25805;&#32437;&#27169;&#22411;&#25152;&#34920;&#36798;&#30340;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25991;&#26412;&#24341;&#23548;&#29983;&#25104;&#27169;&#22411;&#20013;&#23398;&#20064;&#34920;&#31034;&#30340;&#32467;&#26500;&#65292;&#37325;&#28857;&#20851;&#27880;&#22522;&#20110;&#20998;&#25968;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#32858;&#28966;&#20110;&#27010;&#24565;&#34987;&#32534;&#30721;&#20026;&#26576;&#31181;&#34920;&#31034;&#31354;&#38388;&#30340;&#23376;&#31354;&#38388;&#65288;&#25110;&#26041;&#21521;&#65289;&#30340;&#24605;&#24819;&#65292;&#24182;&#24320;&#21457;&#20102;&#36825;&#20010;&#24605;&#24819;&#30340;&#25968;&#23398;&#24418;&#24335;&#21270;&#12290;&#21033;&#29992;&#36825;&#20010;&#24418;&#24335;&#21270;&#26041;&#27861;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26377;&#19968;&#20010;&#33258;&#28982;&#30340;&#34920;&#31034;&#36873;&#25321;&#20855;&#26377;&#36825;&#31181;&#24615;&#36136;&#65292;&#24182;&#19988;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#19982;&#32473;&#23450;&#27010;&#24565;&#23545;&#24212;&#30340;&#34920;&#31034;&#37096;&#20998;&#12290;&#29305;&#21035;&#26159;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#23545;&#34920;&#31034;&#30340;&#20195;&#25968;&#25805;&#20316;&#26469;&#25805;&#32437;&#27169;&#22411;&#25152;&#34920;&#36798;&#30340;&#27010;&#24565;&#12290;&#25105;&#20204;&#20351;&#29992;&#31283;&#23450;&#25193;&#25955;&#22312;&#25991;&#26412;&#24341;&#23548;&#22270;&#20687;&#29983;&#25104;&#30340;&#31034;&#20363;&#20013;&#28436;&#31034;&#20102;&#36825;&#20010;&#24605;&#24819;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper concerns the structure of learned representations in text-guided generative models, focusing on score-based models. Here, we focus on the idea that concepts are encoded as subspaces (or directions) of some representation space. We develop a mathematical formalization of this idea.Using this formalism, we show there's a natural choice of representation with this property, and we develop a simple method for identifying the part of the representation corresponding to a given concept. In particular, this allows us to manipulate the concepts expressed by the model through algebraic manipulation of the representation. We demonstrate the idea with examples text-guided image generation, using Stable Diffusion.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36136;&#30097;&#20102;&#36882;&#24402;&#21010;&#20998;&#22312;&#20915;&#31574;&#26641;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#36890;&#36807;&#35777;&#26126;&#23427;&#20204;&#21487;&#33021;&#26080;&#27861;&#23454;&#29616;&#19968;&#33268;&#33539;&#25968;&#30340;&#22810;&#39033;&#24335;&#25910;&#25947;&#36895;&#29575;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#38543;&#26426;&#26862;&#26519;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#23558;&#20302;&#24615;&#33021;&#30340;&#26641;&#36716;&#21270;&#20026;&#20960;&#20046;&#26368;&#20248;&#30340;&#36807;&#31243;&#65292;&#20294;&#20195;&#20215;&#26159;&#22833;&#21435;&#20102;&#35299;&#37322;&#24615;&#65292;&#24182;&#24341;&#20837;&#20102;&#20004;&#20010;&#39069;&#22806;&#30340;&#35843;&#25972;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/2211.10805</link><description>&lt;p&gt;
&#20851;&#20110;&#36882;&#24402;&#21010;&#20998;&#30340;&#36880;&#28857;&#34892;&#20026;&#21450;&#20854;&#23545;&#24322;&#36136;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
On the Pointwise Behavior of Recursive Partitioning and Its Implications for Heterogeneous Causal Effect Estimation. (arXiv:2211.10805v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.10805
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36136;&#30097;&#20102;&#36882;&#24402;&#21010;&#20998;&#22312;&#20915;&#31574;&#26641;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#36890;&#36807;&#35777;&#26126;&#23427;&#20204;&#21487;&#33021;&#26080;&#27861;&#23454;&#29616;&#19968;&#33268;&#33539;&#25968;&#30340;&#22810;&#39033;&#24335;&#25910;&#25947;&#36895;&#29575;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#38543;&#26426;&#26862;&#26519;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#23558;&#20302;&#24615;&#33021;&#30340;&#26641;&#36716;&#21270;&#20026;&#20960;&#20046;&#26368;&#20248;&#30340;&#36807;&#31243;&#65292;&#20294;&#20195;&#20215;&#26159;&#22833;&#21435;&#20102;&#35299;&#37322;&#24615;&#65292;&#24182;&#24341;&#20837;&#20102;&#20004;&#20010;&#39069;&#22806;&#30340;&#35843;&#25972;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20915;&#31574;&#26641;&#23398;&#20064;&#22312;&#36880;&#28857;&#25512;&#26029;&#20013;&#30340;&#24212;&#29992;&#26085;&#30410;&#22686;&#22810;&#12290;&#37325;&#35201;&#30340;&#24212;&#29992;&#21253;&#25324;&#24322;&#36136;&#22240;&#26524;&#27835;&#30103;&#25928;&#24212;&#21644;&#21160;&#24577;&#25919;&#31574;&#20915;&#31574;&#65292;&#20197;&#21450;&#26465;&#20214;&#20998;&#20301;&#25968;&#22238;&#24402;&#21644;&#23454;&#39564;&#35774;&#35745;&#65292;&#22312;&#36825;&#20123;&#24212;&#29992;&#20013;&#65292;&#26641;&#30340;&#20272;&#35745;&#21644;&#25512;&#26029;&#26159;&#22312;&#29305;&#23450;&#30340;&#21327;&#21464;&#37327;&#20540;&#19978;&#36827;&#34892;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23545;&#20351;&#29992;&#20915;&#31574;&#26641;&#65288;&#36890;&#36807;&#33258;&#36866;&#24212;&#36882;&#24402;&#21010;&#20998;&#35757;&#32451;&#65289;&#36827;&#34892;&#27492;&#31867;&#30446;&#30340;&#25552;&#20986;&#20102;&#36136;&#30097;&#65292;&#36890;&#36807;&#35777;&#26126;&#23427;&#20204;&#29978;&#33267;&#21487;&#20197;&#22312;&#20462;&#21098;&#30340;&#24773;&#20917;&#19979;&#26080;&#27861;&#23454;&#29616;&#19968;&#33268;&#33539;&#25968;&#30340;&#22810;&#39033;&#24335;&#25910;&#25947;&#36895;&#29575;&#12290;&#30456;&#21453;&#65292;&#25910;&#25947;&#36895;&#24230;&#21487;&#33021;&#26159;&#22810;&#39033;&#24335;&#23545;&#25968;&#32423;&#21035;&#30340;&#65292;&#25110;&#32773;&#22312;&#19968;&#20123;&#37325;&#35201;&#30340;&#29305;&#27530;&#24773;&#20917;&#19979;&#65292;&#20363;&#22914;&#35802;&#23454;&#22238;&#24402;&#26641;&#65292;&#23436;&#20840;&#22833;&#36133;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#38543;&#26426;&#26862;&#26519;&#21487;&#20197;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#23558;&#20302;&#24615;&#33021;&#30340;&#26641;&#36716;&#21270;&#20026;&#20960;&#20046;&#26368;&#20248;&#30340;&#36807;&#31243;&#65292;&#20294;&#20195;&#20215;&#26159;&#22833;&#21435;&#20102;&#35299;&#37322;&#24615;&#65292;&#24182;&#24341;&#20837;&#20102;&#20004;&#20010;&#39069;&#22806;&#30340;&#35843;&#25972;&#21442;&#25968;&#12290;&#38543;&#26426;&#26862;&#26519;&#30340;&#20004;&#20010;&#26631;&#24535;&#24615;&#29305;&#24449;&#26159;&#23376;&#37319;&#26679;&#21644;&#38543;&#26426;&#29305;&#24449;&#36873;&#25321;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Decision tree learning is increasingly being used for pointwise inference. Important applications include causal heterogenous treatment effects and dynamic policy decisions, as well as conditional quantile regression and design of experiments, where tree estimation and inference is conducted at specific values of the covariates. In this paper, we call into question the use of decision trees (trained by adaptive recursive partitioning) for such purposes by demonstrating that they can fail to achieve polynomial rates of convergence in uniform norm, even with pruning. Instead, the convergence may be poly-logarithmic or, in some important special cases, such as honest regression trees, fail completely. We show that random forests can remedy the situation, turning poor performing trees into nearly optimal procedures, at the cost of losing interpretability and introducing two additional tuning parameters. The two hallmarks of random forests, subsampling and the random feature selection mecha
&lt;/p&gt;</description></item></channel></rss>