<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#20855;&#26377;&#20219;&#24847;&#31867;&#22411;&#26410;&#30693;&#36229;&#21442;&#25968;&#30340;&#24773;&#20917;&#65292;&#24182;&#20855;&#26377;&#26080;&#36951;&#25022;&#29305;&#24615;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01632</link><description>&lt;p&gt;
&#36229;&#36234;&#23610;&#24230;&#65306;&#20855;&#26377;&#20219;&#24847;&#31867;&#22411;&#26410;&#30693;&#36229;&#21442;&#25968;&#30340;&#26080;&#36951;&#25022;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Beyond Lengthscales: No-regret Bayesian Optimisation With Unknown Hyperparameters Of Any Type
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01632
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#20855;&#26377;&#20219;&#24847;&#31867;&#22411;&#26410;&#30693;&#36229;&#21442;&#25968;&#30340;&#24773;&#20917;&#65292;&#24182;&#20855;&#26377;&#26080;&#36951;&#25022;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#38656;&#35201;&#25311;&#21512;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#32780;&#25311;&#21512;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#38656;&#35201;&#25351;&#23450;&#36229;&#21442;&#25968; - &#22823;&#37096;&#20998;&#29702;&#35770;&#25991;&#29486;&#20551;&#35774;&#36825;&#20123;&#36229;&#21442;&#25968;&#26159;&#24050;&#30693;&#30340;&#12290;&#20043;&#21069;&#30340;&#29702;&#35770;&#30740;&#31350;&#36890;&#24120;&#20551;&#35774;&#25968;&#25454;&#22312;&#31354;&#38388;&#20013;&#22343;&#21248;&#22635;&#20805;&#65292;&#32780;&#24120;&#29992;&#30340;&#39640;&#26031;&#36807;&#31243;&#36229;&#21442;&#25968;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#21482;&#26377;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#25165;&#26159;&#19968;&#33268;&#30340;&#12290;&#28982;&#32780;&#65292;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#65292;&#25968;&#25454;&#19981;&#19968;&#23450;&#28385;&#36275;&#36825;&#31181;&#22343;&#21248;&#22635;&#20805;&#30340;&#26465;&#20214;&#12290;&#30001;&#20110;&#26080;&#27861;&#20445;&#35777;&#36229;&#21442;&#25968;&#20272;&#35745;&#30340;&#27491;&#30830;&#24615;&#65292;&#24182;&#19988;&#36825;&#20123;&#36229;&#21442;&#25968;&#21487;&#20197;&#26174;&#33879;&#24433;&#21709;&#39640;&#26031;&#36807;&#31243;&#25311;&#21512;&#65292;&#22240;&#27492;&#23545;&#20855;&#26377;&#26410;&#30693;&#36229;&#21442;&#25968;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20043;&#21069;&#25552;&#20986;&#30340;&#20855;&#26377;&#26080;&#36951;&#25022;&#29305;&#24615;&#30340;&#31639;&#27861;&#20165;&#33021;&#22788;&#29702;&#29305;&#27530;&#24773;&#20917;&#19979;&#30340;&#26410;&#30693;&#38271;&#24230;&#23610;&#24230;&#12289;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#33539;&#25968;&#65292;&#24182;&#19988;&#20165;&#36866;&#29992;&#20110;&#39057;&#29575;&#27966;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#21629;&#21517;&#20026;HE-GP-UCB&#65292;&#23427;&#26159;&#31532;&#19968;&#20010;&#20855;&#26377;&#26080;&#36951;&#25022;&#29305;&#24615;&#30340;&#31639;&#27861;&#65292;&#22312;&#20855;&#26377;&#26410;&#30693;&#36229;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#36125;&#21494;&#26031;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimisation requires fitting a Gaussian process model, which in turn requires specifying hyperparameters - most of the theoretical literature assumes those hyperparameters are known. The commonly used maximum likelihood estimator for hyperparameters of the Gaussian process is consistent only if the data fills the space uniformly, which does not have to be the case in Bayesian optimisation. Since no guarantees exist regarding the correctness of hyperparameter estimation, and those hyperparameters can significantly affect the Gaussian process fit, theoretical analysis of Bayesian optimisation with unknown hyperparameters is very challenging. Previously proposed algorithms with the no-regret property were only able to handle the special case of unknown lengthscales, reproducing kernel Hilbert space norm and applied only to the frequentist case. We propose a novel algorithm, HE-GP-UCB, which is the first algorithm enjoying the no-regret property in the case of unknown hyperparame
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#20351;&#29992;&#20855;&#26377;&#21487;&#35777;&#26126;&#24615;&#33021;&#20445;&#35777;&#30340;&#24369;&#30417;&#30563;AI&#38169;&#35823;&#20462;&#27491;&#22120;&#26469;&#22788;&#29702;AI&#38169;&#35823;&#12290;&#20462;&#27491;&#22120;&#36890;&#36807;&#25209;&#20934;&#25110;&#25298;&#32477;&#24213;&#23618;&#20998;&#31867;&#22120;&#30340;&#20915;&#31574;&#26469;&#25552;&#21319;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#27010;&#29575;&#30028;&#38480;&#20445;&#35777;&#20854;&#24615;&#33021;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#35757;&#32451;&#25968;&#25454;&#31232;&#32570;&#30340;&#30495;&#23454;&#19990;&#30028;&#20219;&#21153;&#20013;&#25552;&#21319;&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#12290;</title><link>https://rss.arxiv.org/abs/2402.00899</link><description>&lt;p&gt;
&#24369;&#30417;&#30563;&#23398;&#20064;&#22120;&#23454;&#29616;&#20855;&#26377;&#21487;&#35777;&#26126;&#24615;&#33021;&#20445;&#35777;&#30340;AI&#38169;&#35823;&#20462;&#27491;
&lt;/p&gt;
&lt;p&gt;
Weakly Supervised Learners for Correction of AI Errors with Provable Performance Guarantees
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.00899
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#20351;&#29992;&#20855;&#26377;&#21487;&#35777;&#26126;&#24615;&#33021;&#20445;&#35777;&#30340;&#24369;&#30417;&#30563;AI&#38169;&#35823;&#20462;&#27491;&#22120;&#26469;&#22788;&#29702;AI&#38169;&#35823;&#12290;&#20462;&#27491;&#22120;&#36890;&#36807;&#25209;&#20934;&#25110;&#25298;&#32477;&#24213;&#23618;&#20998;&#31867;&#22120;&#30340;&#20915;&#31574;&#26469;&#25552;&#21319;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#27010;&#29575;&#30028;&#38480;&#20445;&#35777;&#20854;&#24615;&#33021;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#35757;&#32451;&#25968;&#25454;&#31232;&#32570;&#30340;&#30495;&#23454;&#19990;&#30028;&#20219;&#21153;&#20013;&#25552;&#21319;&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;AI&#38169;&#35823;&#65292;&#36890;&#36807;&#24341;&#20837;&#20855;&#26377;&#20808;&#39564;&#24615;&#33021;&#20445;&#35777;&#30340;&#24369;&#30417;&#30563;AI&#38169;&#35823;&#20462;&#27491;&#22120;&#12290;&#36825;&#20123;AI&#20462;&#27491;&#22120;&#26159;&#36741;&#21161;&#26144;&#23556;&#65292;&#20854;&#20316;&#29992;&#26159;&#36890;&#36807;&#25209;&#20934;&#25110;&#25298;&#32477;&#20197;&#35843;&#33410;&#20043;&#21069;&#26500;&#24314;&#30340;&#24213;&#23618;&#20998;&#31867;&#22120;&#30340;&#20915;&#31574;&#12290;&#25298;&#32477;&#19968;&#20010;&#20915;&#31574;&#21487;&#20197;&#29992;&#20316;&#24314;&#35758;&#25918;&#24323;&#20570;&#20986;&#20915;&#31574;&#30340;&#20449;&#21495;&#12290;&#35813;&#24037;&#20316;&#30340;&#19968;&#20010;&#20851;&#38190;&#25216;&#26415;&#37325;&#28857;&#26159;&#36890;&#36807;&#23545;&#38169;&#35823;&#20915;&#31574;&#30340;&#27010;&#29575;&#30028;&#38480;&#25552;&#20379;&#36825;&#20123;&#26032;&#30340;AI&#20462;&#27491;&#22120;&#30340;&#24615;&#33021;&#20445;&#35777;&#12290;&#36825;&#20123;&#30028;&#38480;&#26159;&#20998;&#24067;&#19981;&#21487;&#30693;&#30340;&#65292;&#24182;&#19988;&#19981;&#20381;&#36182;&#20110;&#23545;&#25968;&#25454;&#32500;&#24230;&#30340;&#20551;&#35774;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#31034;&#20363;&#35828;&#26126;&#20102;&#35813;&#26694;&#26550;&#22914;&#20309;&#24212;&#29992;&#20110;&#25913;&#21892;&#22312;&#35757;&#32451;&#25968;&#25454;&#31232;&#32570;&#30340;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#30495;&#23454;&#19990;&#30028;&#20219;&#21153;&#20013;&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a new methodology for handling AI errors by introducing weakly supervised AI error correctors with a priori performance guarantees. These AI correctors are auxiliary maps whose role is to moderate the decisions of some previously constructed underlying classifier by either approving or rejecting its decisions. The rejection of a decision can be used as a signal to suggest abstaining from making a decision. A key technical focus of the work is in providing performance guarantees for these new AI correctors through bounds on the probabilities of incorrect decisions. These bounds are distribution agnostic and do not rely on assumptions on the data dimension. Our empirical example illustrates how the framework can be applied to improve the performance of an image classifier in a challenging real-world task where training data are scarce.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#30446;&#26631;&#20998;&#25968;&#21305;&#37197;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#22238;&#24402;&#25439;&#22833;&#26469;&#20272;&#35745;&#30446;&#26631;&#20998;&#24067;&#30340;&#22122;&#22768;&#29256;&#26412;&#30340;&#20998;&#25968;&#12290;&#19982;&#20256;&#32479;&#30340;&#22122;&#22768;&#20998;&#25968;&#21305;&#37197;&#26041;&#27861;&#19981;&#21516;&#65292;&#35813;&#26041;&#27861;&#22312;&#20302;&#22122;&#22768;&#27700;&#24179;&#19979;&#33021;&#22815;&#33719;&#24471;&#26356;&#20934;&#30830;&#30340;&#20998;&#25968;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2402.08667</link><description>&lt;p&gt;
&#30446;&#26631;&#20998;&#25968;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Target Score Matching
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08667
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#30446;&#26631;&#20998;&#25968;&#21305;&#37197;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#22238;&#24402;&#25439;&#22833;&#26469;&#20272;&#35745;&#30446;&#26631;&#20998;&#24067;&#30340;&#22122;&#22768;&#29256;&#26412;&#30340;&#20998;&#25968;&#12290;&#19982;&#20256;&#32479;&#30340;&#22122;&#22768;&#20998;&#25968;&#21305;&#37197;&#26041;&#27861;&#19981;&#21516;&#65292;&#35813;&#26041;&#27861;&#22312;&#20302;&#22122;&#22768;&#27700;&#24179;&#19979;&#33021;&#22815;&#33719;&#24471;&#26356;&#20934;&#30830;&#30340;&#20998;&#25968;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22122;&#22768;&#20998;&#25968;&#21305;&#37197;&#36890;&#36807;&#26368;&#23567;&#21270;&#22238;&#24402;&#25439;&#22833;&#26469;&#20272;&#35745;&#30446;&#26631;&#20998;&#24067;&#30340;&#22122;&#22768;&#29256;&#26412;&#30340;&#20998;&#25968;&#65292;&#24182;&#24191;&#27867;&#29992;&#20110;&#35757;&#32451;&#27969;&#34892;&#30340;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#20247;&#25152;&#21608;&#30693;&#65292;&#22122;&#22768;&#20998;&#25968;&#21305;&#37197;&#30340;&#19968;&#20010;&#23616;&#38480;&#24615;&#26159;&#22312;&#20302;&#22122;&#22768;&#27700;&#24179;&#19979;&#20250;&#20135;&#29983;&#36739;&#24046;&#30340;&#20998;&#25968;&#20272;&#35745;&#12290;&#36825;&#20010;&#38382;&#39064;&#22312;&#29289;&#29702;&#31185;&#23398;&#21644;&#23545;&#20110;&#24050;&#30693;&#24178;&#20928;&#30340;&#21407;&#22987;&#30446;&#26631;&#20998;&#25968;&#30340;&#33945;&#29305;&#21345;&#27931;&#25277;&#26679;&#20219;&#21153;&#20013;&#29305;&#21035;&#19981;&#21033;&#12290;&#30452;&#35266;&#22320;&#35828;&#65292;&#22312;&#36825;&#20123;&#24773;&#20917;&#19979;&#65292;&#20272;&#35745;&#30446;&#26631;&#31245;&#26377;&#22122;&#22768;&#29256;&#26412;&#30340;&#20998;&#25968;&#24212;&#35813;&#26159;&#19968;&#20010;&#31616;&#21333;&#30340;&#20219;&#21153;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#36825;&#20010;&#32570;&#28857;&#65292;&#24182;&#23637;&#31034;&#20102;&#21033;&#29992;&#30446;&#26631;&#20998;&#25968;&#30340;&#30693;&#35782;&#30830;&#23454;&#21487;&#20197;&#23454;&#29616;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#30446;&#26631;&#20998;&#25968;&#36523;&#20221;&#21644;&#30456;&#24212;&#30340;&#30446;&#26631;&#20998;&#25968;&#21305;&#37197;&#22238;&#24402;&#25439;&#22833;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#22312;&#20302;&#22122;&#22768;&#27700;&#24179;&#19979;&#33719;&#24471;&#20855;&#26377;&#26377;&#21033;&#23646;&#24615;&#30340;&#20998;&#25968;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Denoising Score Matching estimates the score of a noised version of a target distribution by minimizing a regression loss and is widely used to train the popular class of Denoising Diffusion Models. A well known limitation of Denoising Score Matching, however, is that it yields poor estimates of the score at low noise levels. This issue is particularly unfavourable for problems in the physical sciences and for Monte Carlo sampling tasks for which the score of the clean original target is known. Intuitively, estimating the score of a slightly noised version of the target should be a simple task in such cases. In this paper, we address this shortcoming and show that it is indeed possible to leverage knowledge of the target score. We present a Target Score Identity and corresponding Target Score Matching regression loss which allows us to obtain score estimates admitting favourable properties at low noise levels.
&lt;/p&gt;</description></item><item><title>&#36825;&#26159;&#19968;&#31687;&#20851;&#20110;&#22312;&#32447;&#20984;&#20248;&#21270;&#30340;&#35770;&#25991;&#65292;&#20316;&#32773;&#20998;&#26512;&#20102;&#19981;&#21516;&#29615;&#22659;&#19979;&#30340;&#38382;&#39064;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#36716;&#21270;&#20026;&#30456;&#24212;&#30340;&#32447;&#24615;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#21487;&#20197;&#22312;&#38754;&#23545;&#19981;&#21516;&#31867;&#22411;&#23545;&#25163;&#26102;&#33719;&#24471;&#21487;&#27604;&#36739;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.08621</link><description>&lt;p&gt;
&#19968;&#31181;&#24191;&#20041;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Generalized Approach to Online Convex Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08621
&lt;/p&gt;
&lt;p&gt;
&#36825;&#26159;&#19968;&#31687;&#20851;&#20110;&#22312;&#32447;&#20984;&#20248;&#21270;&#30340;&#35770;&#25991;&#65292;&#20316;&#32773;&#20998;&#26512;&#20102;&#19981;&#21516;&#29615;&#22659;&#19979;&#30340;&#38382;&#39064;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#36716;&#21270;&#20026;&#30456;&#24212;&#30340;&#32447;&#24615;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#21487;&#20197;&#22312;&#38754;&#23545;&#19981;&#21516;&#31867;&#22411;&#23545;&#25163;&#26102;&#33719;&#24471;&#21487;&#27604;&#36739;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#19981;&#21516;&#29615;&#22659;&#19979;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20219;&#20309;&#29992;&#20110;&#20855;&#26377;&#23436;&#20840;&#33258;&#36866;&#24212;&#23545;&#25163;&#30340;&#22312;&#32447;&#32447;&#24615;&#20248;&#21270;&#30340;&#31639;&#27861;&#37117;&#26159;&#29992;&#20110;&#22312;&#32447;&#20984;&#20248;&#21270;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#20219;&#20309;&#38656;&#35201;&#20840;&#20449;&#24687;&#21453;&#39304;&#30340;&#31639;&#27861;&#37117;&#21487;&#20197;&#36716;&#21270;&#20026;&#20855;&#26377;&#21487;&#27604;&#36739;&#30340;&#36951;&#25022;&#30028;&#38480;&#30340;&#21322;&#21305;&#37197;&#21453;&#39304;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#20351;&#29992;&#30830;&#23450;&#24615;&#21322;&#21305;&#37197;&#21453;&#39304;&#30340;&#20840;&#33258;&#36866;&#24212;&#23545;&#25163;&#35774;&#35745;&#30340;&#31639;&#27861;&#22312;&#38754;&#23545;&#26080;&#30693;&#23545;&#25163;&#26102;&#21487;&#20197;&#20351;&#29992;&#21482;&#26377;&#38543;&#26426;&#21322;&#21305;&#37197;&#21453;&#39304;&#30340;&#31639;&#27861;&#33719;&#24471;&#30456;&#20284;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#19968;&#32467;&#26524;&#25551;&#36848;&#20102;&#23558;&#19968;&#38454;&#31639;&#27861;&#36716;&#21270;&#20026;&#38646;&#38454;&#31639;&#27861;&#30340;&#36890;&#29992;&#20803;&#31639;&#27861;&#65292;&#36825;&#20123;&#31639;&#27861;&#20855;&#26377;&#21487;&#27604;&#36739;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#20351;&#25105;&#20204;&#33021;&#22815;&#20998;&#26512;&#21508;&#31181;&#35774;&#32622;&#20013;&#30340;&#22312;&#32447;&#20248;&#21270;&#38382;&#39064;&#65292;&#21253;&#25324;&#20840;&#20449;&#24687;&#21453;&#39304;&#12289;&#21322;&#21305;&#37197;&#21453;&#39304;&#12289;&#38543;&#26426;&#36951;&#25022;&#12289;&#23545;&#25239;&#36951;&#25022;&#21644;&#21508;&#31181;&#24418;&#24335;&#30340;&#38750;&#24179;&#31283;&#36951;&#25022;&#12290;&#21033;&#29992;&#25105;&#20204;&#30340;&#20998;&#26512;&#32467;&#26524;&#65292;
&lt;/p&gt;
&lt;p&gt;
In this paper, we analyze the problem of online convex optimization in different settings. We show that any algorithm for online linear optimization with fully adaptive adversaries is an algorithm for online convex optimization. We also show that any such algorithm that requires full-information feedback may be transformed to an algorithm with semi-bandit feedback with comparable regret bound. We further show that algorithms that are designed for fully adaptive adversaries using deterministic semi-bandit feedback can obtain similar bounds using only stochastic semi-bandit feedback when facing oblivious adversaries. We use this to describe general meta-algorithms to convert first order algorithms to zeroth order algorithms with comparable regret bounds. Our framework allows us to analyze online optimization in various settings, such full-information feedback, bandit feedback, stochastic regret, adversarial regret and various forms of non-stationary regret. Using our analysis, we provide
&lt;/p&gt;</description></item><item><title>gadjid&#36719;&#20214;&#21253;&#25552;&#20379;&#20102;&#19968;&#31181;&#29992;&#20110;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#30340;&#35843;&#25972;&#35782;&#21035;&#36317;&#31163;&#65292;&#36890;&#36807;&#24341;&#20837;&#26694;&#26550;&#26469;&#35745;&#31639;&#22240;&#26524;&#36317;&#31163;&#65292;&#36825;&#20123;&#36317;&#31163;&#33021;&#22815;&#39640;&#25928;&#35780;&#20272;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#23398;&#20064;&#30340;&#22270;&#24418;&#65292;&#24182;&#19988;&#22312;&#22788;&#29702;&#22823;&#35268;&#27169;&#22270;&#24418;&#26102;&#20855;&#26377;&#36739;&#39640;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.08616</link><description>&lt;p&gt;
Adjustment Identification Distance: &#19968;&#31181;&#29992;&#20110;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#30340;&#35843;&#25972;&#35782;&#21035;&#36317;&#31163;
&lt;/p&gt;
&lt;p&gt;
Adjustment Identification Distance: A gadjid for Causal Structure Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08616
&lt;/p&gt;
&lt;p&gt;
gadjid&#36719;&#20214;&#21253;&#25552;&#20379;&#20102;&#19968;&#31181;&#29992;&#20110;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#30340;&#35843;&#25972;&#35782;&#21035;&#36317;&#31163;&#65292;&#36890;&#36807;&#24341;&#20837;&#26694;&#26550;&#26469;&#35745;&#31639;&#22240;&#26524;&#36317;&#31163;&#65292;&#36825;&#20123;&#36317;&#31163;&#33021;&#22815;&#39640;&#25928;&#35780;&#20272;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#23398;&#20064;&#30340;&#22270;&#24418;&#65292;&#24182;&#19988;&#22312;&#22788;&#29702;&#22823;&#35268;&#27169;&#22270;&#24418;&#26102;&#20855;&#26377;&#36739;&#39640;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#23398;&#20064;&#30340;&#22270;&#24418;&#30340;&#35780;&#20272;&#26159;&#22256;&#38590;&#30340;&#65306;&#20004;&#20010;&#22270;&#24418;&#20043;&#38388;&#19981;&#21516;&#30340;&#36793;&#30340;&#25968;&#37327;&#19981;&#33021;&#21453;&#26144;&#20986;&#23427;&#20204;&#22312;&#24314;&#35758;&#22240;&#26524;&#25928;&#24212;&#30340;&#35782;&#21035;&#20844;&#24335;&#26041;&#38754;&#26377;&#20309;&#19981;&#21516;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#24320;&#21457;&#22270;&#24418;&#20043;&#38388;&#30340;&#22240;&#26524;&#36317;&#31163;&#65292;&#20854;&#20013;&#21253;&#25324;&#26377;&#21521;&#26080;&#29615;&#22270;&#30340;&#32467;&#26500;&#24178;&#39044;&#36317;&#31163;&#20316;&#20026;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20010;&#26694;&#26550;&#24320;&#21457;&#20102;&#25913;&#36827;&#30340;&#22522;&#20110;&#35843;&#25972;&#30340;&#36317;&#31163;&#65292;&#20197;&#21450;&#23545;&#23436;&#25104;&#30340;&#37096;&#20998;&#26377;&#21521;&#26080;&#29615;&#22270;&#21644;&#22240;&#26524;&#24207;&#21015;&#30340;&#25193;&#23637;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#22810;&#39033;&#24335;&#26102;&#38388;&#21487;&#36798;&#24615;&#31639;&#27861;&#26469;&#39640;&#25928;&#35745;&#31639;&#36317;&#31163;&#12290;&#22312;&#25105;&#20204;&#30340;gadjid&#36719;&#20214;&#21253;&#20013;&#65288;&#22312;https://github.com/CausalDisco/gadjid&#19978;&#24320;&#28304;&#65289;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#25105;&#20204;&#30340;&#36317;&#31163;&#23454;&#29616;&#65307;&#23427;&#20204;&#30340;&#36816;&#34892;&#36895;&#24230;&#27604;&#32467;&#26500;&#24178;&#39044;&#36317;&#31163;&#24555;&#20960;&#20010;&#25968;&#37327;&#32423;&#65292;&#20174;&#32780;&#20026;&#20197;&#21069;&#26080;&#27861;&#25193;&#23637;&#30340;&#22270;&#24418;&#23610;&#23544;&#25552;&#20379;&#20102;&#19968;&#20010;&#22240;&#26524;&#21457;&#29616;&#30340;&#25104;&#21151;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
Evaluating graphs learned by causal discovery algorithms is difficult: The number of edges that differ between two graphs does not reflect how the graphs differ with respect to the identifying formulas they suggest for causal effects. We introduce a framework for developing causal distances between graphs which includes the structural intervention distance for directed acyclic graphs as a special case. We use this framework to develop improved adjustment-based distances as well as extensions to completed partially directed acyclic graphs and causal orders. We develop polynomial-time reachability algorithms to compute the distances efficiently. In our package gadjid (open source at https://github.com/CausalDisco/gadjid), we provide implementations of our distances; they are orders of magnitude faster than the structural intervention distance and thereby provide a success metric for causal discovery that scales to graph sizes that were previously prohibitive.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#20840;&#23616;&#20248;&#21270;&#30340;&#36138;&#23146;&#23454;&#39564;&#36873;&#25321;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#20027;&#21160;&#39034;&#24207;&#20272;&#35745;&#38382;&#39064;&#20013;&#30340;&#22810;&#32500;&#24773;&#20917;&#12290;&#36825;&#31181;&#26041;&#27861;&#20855;&#26377;&#35745;&#31639;&#26041;&#20415;&#12289;&#36866;&#24212;&#19978;&#19979;&#25991;&#21464;&#21270;&#21644;&#24191;&#27867;&#36866;&#29992;&#24615;&#30340;&#29305;&#28857;&#12290;</title><link>https://arxiv.org/abs/2402.08602</link><description>&lt;p&gt;
&#20840;&#23616;&#20248;&#21270;&#30340;&#36138;&#23146;&#23454;&#39564;&#36873;&#25321;&#26041;&#27861;&#29992;&#20110;&#20027;&#21160;&#39034;&#24207;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Globally-Optimal Greedy Experiment Selection for Active Sequential Estimation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08602
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#20840;&#23616;&#20248;&#21270;&#30340;&#36138;&#23146;&#23454;&#39564;&#36873;&#25321;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#20027;&#21160;&#39034;&#24207;&#20272;&#35745;&#38382;&#39064;&#20013;&#30340;&#22810;&#32500;&#24773;&#20917;&#12290;&#36825;&#31181;&#26041;&#27861;&#20855;&#26377;&#35745;&#31639;&#26041;&#20415;&#12289;&#36866;&#24212;&#19978;&#19979;&#25991;&#21464;&#21270;&#21644;&#24191;&#27867;&#36866;&#29992;&#24615;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35745;&#31639;&#26426;&#33258;&#36866;&#24212;&#27979;&#35797;&#12289;&#39034;&#24207;&#25490;&#21517;&#32858;&#21512;&#21644;&#24322;&#26500;&#25968;&#25454;&#28304;&#36873;&#25321;&#31561;&#29616;&#20195;&#24212;&#29992;&#30340;&#25512;&#21160;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20027;&#21160;&#39034;&#24207;&#20272;&#35745;&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#28041;&#21450;&#36880;&#27493;&#36873;&#25321;&#23454;&#39564;&#26469;&#37319;&#38598;&#25968;&#25454;&#12290;&#30446;&#26631;&#26159;&#35774;&#35745;&#23454;&#39564;&#36873;&#25321;&#35268;&#21017;&#20197;&#33719;&#24471;&#26356;&#20934;&#30830;&#30340;&#27169;&#22411;&#20272;&#35745;&#12290;&#30001;&#20110;&#35745;&#31639;&#26041;&#20415;&#12289;&#33021;&#22815;&#36866;&#24212;&#19978;&#19979;&#25991;&#25110;&#20219;&#21153;&#21464;&#21270;&#24182;&#20855;&#26377;&#24191;&#27867;&#36866;&#29992;&#24615;&#65292;&#22522;&#20110;&#20449;&#24687;&#22686;&#30410;&#30340;&#36138;&#23146;&#23454;&#39564;&#36873;&#25321;&#26041;&#27861;&#24050;&#22312;&#23454;&#36341;&#20013;&#34987;&#37319;&#29992;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#38382;&#39064;&#30340;&#32452;&#21512;&#24615;&#36136;&#21644;&#36138;&#23146;&#31639;&#27861;&#30340;&#34920;&#38754;&#19978;&#26377;&#38480;&#30340;&#33021;&#21147;&#65292;&#32479;&#35745;&#20998;&#26512;&#20165;&#38480;&#20110;&#19968;&#32500;&#24773;&#20917;&#65292;&#20351;&#24471;&#22810;&#32500;&#38382;&#39064;&#20173;&#28982;&#26410;&#35299;&#20915;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#22810;&#32500;&#38382;&#39064;&#30340;&#24046;&#36317;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#37319;&#29992;&#19968;&#31867;&#36138;&#23146;&#23454;&#39564;&#36873;&#25321;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#32479;&#35745;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by modern applications such as computerized adaptive testing, sequential rank aggregation, and heterogeneous data source selection, we study the problem of active sequential estimation, which involves adaptively selecting experiments for sequentially collected data. The goal is to design experiment selection rules for more accurate model estimation. Greedy information-based experiment selection methods, optimizing the information gain for one-step ahead, have been employed in practice thanks to their computational convenience, flexibility to context or task changes, and broad applicability. However, statistical analysis is restricted to one-dimensional cases due to the problem's combinatorial nature and the seemingly limited capacity of greedy algorithms, leaving the multidimensional problem open.   In this study, we close the gap for multidimensional problems. In particular, we propose adopting a class of greedy experiment selection methods and provide statistical analysis f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#39640;&#32500;&#29615;&#22659;&#19979;&#65292;&#38024;&#23545;&#38750;&#21487;&#24494;&#24809;&#32602;&#39033;&#65288;&#22914;&#25512;&#24191;&#30340;LASSO&#21644;&#26680;&#33539;&#25968;&#65289;&#65292;&#36890;&#36807;&#30740;&#31350;LOOCV&#22312;&#20272;&#35745;&#22806;&#26679;&#26412;&#39118;&#38505;&#26102;&#30340;&#26377;&#38480;&#26679;&#26412;&#19978;&#30028;&#65292;&#35299;&#20915;&#20102;&#36825;&#20010;&#29702;&#35770;&#32570;&#22833;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.08543</link><description>&lt;p&gt;
&#22312;&#39640;&#32500;&#29615;&#22659;&#19979;&#65292;&#20851;&#20110;&#38750;&#21487;&#24494;&#24809;&#32602;&#39033;&#30340;LOOCV&#30340;&#29702;&#35770;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Theoretical Analysis of Leave-one-out Cross Validation for Non-differentiable Penalties under High-dimensional Settings
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08543
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#39640;&#32500;&#29615;&#22659;&#19979;&#65292;&#38024;&#23545;&#38750;&#21487;&#24494;&#24809;&#32602;&#39033;&#65288;&#22914;&#25512;&#24191;&#30340;LASSO&#21644;&#26680;&#33539;&#25968;&#65289;&#65292;&#36890;&#36807;&#30740;&#31350;LOOCV&#22312;&#20272;&#35745;&#22806;&#26679;&#26412;&#39118;&#38505;&#26102;&#30340;&#26377;&#38480;&#26679;&#26412;&#19978;&#30028;&#65292;&#35299;&#20915;&#20102;&#36825;&#20010;&#29702;&#35770;&#32570;&#22833;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#20851;&#20110;&#27491;&#21017;&#21270;&#27169;&#22411;&#30340;&#38750;&#26679;&#26465;&#24809;&#32602;&#39033;&#65288;&#22914;&#25512;&#24191;&#30340;LASSO&#21644;&#26680;&#33539;&#25968;&#65289;&#30340;&#22806;&#26679;&#26412;&#39118;&#38505;&#20272;&#35745;&#26377;&#22823;&#37327;&#30340;&#37325;&#35201;&#24037;&#20316;&#65292;&#20294;&#23545;&#20110;&#36825;&#20010;&#38382;&#39064;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#32570;&#22833;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#36825;&#20010;&#25361;&#25112;&#12290;&#25105;&#20204;&#22312;&#27604;&#20363;&#39640;&#32500;&#24773;&#20917;&#19979;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#20854;&#20013;&#26679;&#26412;&#37327;n&#21644;&#29305;&#24449;&#25968;p&#37117;&#24456;&#22823;&#65292;&#19988;n/p&#21644;&#20449;&#22122;&#27604;&#65288;&#27599;&#20010;&#35266;&#27979;&#65289;&#20445;&#25345;&#26377;&#38480;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;LOOCV&#22312;&#20272;&#35745;&#22806;&#26679;&#26412;&#39118;&#38505;&#26102;&#30340;&#26377;&#38480;&#26679;&#26412;&#19978;&#30028;&#12290;&#26412;&#25991;&#25552;&#20986;&#30340;&#29702;&#35770;&#26694;&#26550;&#20026;&#38416;&#26126;LOOCV&#30340;&#20934;&#30830;&#24615;&#25552;&#20379;&#20102;&#22362;&#23454;&#30340;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite a large and significant body of recent work focused on estimating the out-of-sample risk of regularized models in the high dimensional regime, a theoretical understanding of this problem for non-differentiable penalties such as generalized LASSO and nuclear norm is missing. In this paper we resolve this challenge. We study this problem in the proportional high dimensional regime where both the sample size n and number of features p are large, and n/p and the signal-to-noise ratio (per observation) remain finite. We provide finite sample upper bounds on the expected squared error of leave-one-out cross-validation (LO) in estimating the out-of-sample risk. The theoretical framework presented here provides a solid foundation for elucidating empirical findings that show the accuracy of LO.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#20998;&#31163;&#36716;&#25442;&#32467;&#26500;&#21644;&#22870;&#21169;&#65292;&#24341;&#20837;&#20102;&#20998;&#24067;&#24335;&#21518;&#32487;&#24230;&#37327;&#26469;&#25551;&#36848;&#34892;&#20026;&#30340;&#20998;&#24067;&#24335;&#21518;&#26524;&#12290;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#38646;&#26679;&#26412;&#39118;&#38505;&#25935;&#24863;&#31574;&#30053;&#35780;&#20272;&#26041;&#38754;&#12290;</title><link>https://arxiv.org/abs/2402.08530</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#21518;&#32493;&#34920;&#31034;&#30340;&#20998;&#24067;&#24335;&#31867;&#27604;
&lt;/p&gt;
&lt;p&gt;
A Distributional Analogue to the Successor Representation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08530
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#20998;&#31163;&#36716;&#25442;&#32467;&#26500;&#21644;&#22870;&#21169;&#65292;&#24341;&#20837;&#20102;&#20998;&#24067;&#24335;&#21518;&#32487;&#24230;&#37327;&#26469;&#25551;&#36848;&#34892;&#20026;&#30340;&#20998;&#24067;&#24335;&#21518;&#26524;&#12290;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#38646;&#26679;&#26412;&#39118;&#38505;&#25935;&#24863;&#31574;&#30053;&#35780;&#20272;&#26041;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#23427;&#23558;&#36716;&#25442;&#32467;&#26500;&#21644;&#22870;&#21169;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#36827;&#34892;&#20102;&#26126;&#30830;&#30340;&#20998;&#31163;&#12290;&#19982;&#21518;&#32493;&#34920;&#31034;&#65288;SR&#65289;&#25551;&#36848;&#25353;&#29031;&#32473;&#23450;&#31574;&#30053;&#34892;&#20026;&#30340;&#26399;&#26395;&#21518;&#26524;&#31867;&#20284;&#65292;&#25105;&#20204;&#30340;&#20998;&#24067;&#24335;&#21518;&#32487;&#24230;&#37327;&#65288;SM&#65289;&#25551;&#36848;&#20102;&#36825;&#31181;&#34892;&#20026;&#30340;&#20998;&#24067;&#24335;&#32467;&#26524;&#12290;&#25105;&#20204;&#23558;&#20998;&#24067;&#24335;SM&#26500;&#24314;&#20026;&#19968;&#20010;&#20998;&#24067;&#30340;&#20998;&#24067;&#65292;&#24182;&#25552;&#20379;&#20102;&#19982;&#20998;&#24067;&#24335;&#21644;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#30456;&#20851;&#30340;&#29702;&#35770;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#20998;&#24067;&#24335;SM&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#20004;&#20010;&#23618;&#27425;&#30340;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#26469;&#23454;&#29616;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#20851;&#38190;&#26159;&#19968;&#20123;&#29420;&#31435;&#26377;&#20215;&#20540;&#30340;&#23398;&#20064;&#29366;&#24577;&#29983;&#25104;&#27169;&#22411;&#30340;&#31639;&#27861;&#25216;&#26415;&#12290;&#20316;&#20026;&#20998;&#24067;&#24335;SM&#26377;&#29992;&#24615;&#30340;&#20363;&#35777;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23427;&#20351;&#24471;&#38646;&#26679;&#26412;&#39118;&#38505;&#25935;&#24863;&#31574;&#30053;&#35780;&#20272;&#25104;&#20026;&#21487;&#33021;&#65292;&#36825;&#22312;&#20197;&#21069;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper contributes a new approach for distributional reinforcement learning which elucidates a clean separation of transition structure and reward in the learning process. Analogous to how the successor representation (SR) describes the expected consequences of behaving according to a given policy, our distributional successor measure (SM) describes the distributional consequences of this behaviour. We formulate the distributional SM as a distribution over distributions and provide theory connecting it with distributional and model-based reinforcement learning. Moreover, we propose an algorithm that learns the distributional SM from data by minimizing a two-level maximum mean discrepancy. Key to our method are a number of algorithmic techniques that are independently valuable for learning generative models of state. As an illustration of the usefulness of the distributional SM, we show that it enables zero-shot risk-sensitive policy evaluation in a way that was not previously possi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#32467;&#21512;&#20102;PAC-Bayes&#24037;&#20855;&#31665;&#21644;Poincar&#233;&#19982;Log-Sobolev&#19981;&#31561;&#24335;&#65292;&#25552;&#20379;&#20102;&#26032;&#30340;&#26799;&#24230;&#39033;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#31361;&#20986;&#20102;&#24179;&#22374;&#26368;&#23567;&#20540;&#23545;&#27867;&#21270;&#24615;&#33021;&#30340;&#31215;&#26497;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.08508</link><description>&lt;p&gt;
&#24191;&#20041;&#21644;&#24179;&#22343;&#23481;&#37327;&#20043;&#38388;&#30340;PAC-Bayes&#32852;&#32467;
&lt;/p&gt;
&lt;p&gt;
A PAC-Bayesian Link Between Generalisation and Flat Minima
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08508
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#32467;&#21512;&#20102;PAC-Bayes&#24037;&#20855;&#31665;&#21644;Poincar&#233;&#19982;Log-Sobolev&#19981;&#31561;&#24335;&#65292;&#25552;&#20379;&#20102;&#26032;&#30340;&#26799;&#24230;&#39033;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#31361;&#20986;&#20102;&#24179;&#22374;&#26368;&#23567;&#20540;&#23545;&#27867;&#21270;&#24615;&#33021;&#30340;&#31215;&#26497;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#36890;&#24120;&#20351;&#29992;&#36229;&#21442;&#25968;&#35774;&#32622;&#65288;&#35757;&#32451;&#21442;&#25968;&#25968;&#37327;&#22823;&#20110;&#25968;&#25454;&#38598;&#22823;&#23567;&#65289;&#20013;&#30340;&#39044;&#27979;&#22120;&#65292;&#23427;&#20204;&#30340;&#35757;&#32451;&#19981;&#20165;&#20135;&#29983;&#33391;&#22909;&#30340;&#35757;&#32451;&#25968;&#25454;&#24615;&#33021;&#65292;&#32780;&#19988;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#36825;&#19968;&#29616;&#35937;&#25361;&#25112;&#20102;&#35768;&#22810;&#29702;&#35770;&#32467;&#26524;&#65292;&#24182;&#19988;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;&#36825;&#19968;&#29616;&#35937;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#28041;&#21450;&#26799;&#24230;&#39033;&#30340;&#26032;&#22411;&#27867;&#21270;&#30028;&#38480;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#23558;PAC-Bayes&#24037;&#20855;&#31665;&#19982;Poincar&#233;&#21644;Log-Sobolev&#19981;&#31561;&#24335;&#30456;&#32467;&#21512;&#65292;&#36991;&#20813;&#20102;&#23545;&#39044;&#27979;&#22120;&#31354;&#38388;&#32500;&#25968;&#30340;&#26174;&#24335;&#20381;&#36182;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#31361;&#20986;&#20102;&#8220;&#24179;&#22374;&#26368;&#23567;&#20540;&#8221;&#65288;&#20960;&#20046;&#33021;&#22815;&#26368;&#23567;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#37051;&#36817;&#26368;&#23567;&#20540;&#65289;&#23545;&#27867;&#21270;&#24615;&#33021;&#30340;&#31215;&#26497;&#24433;&#21709;&#65292;&#30452;&#25509;&#28041;&#21450;&#21040;&#20248;&#21270;&#38454;&#27573;&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern machine learning usually involves predictors in the overparametrised setting (number of trained parameters greater than dataset size), and their training yield not only good performances on training data, but also good generalisation capacity. This phenomenon challenges many theoretical results, and remains an open problem. To reach a better understanding, we provide novel generalisation bounds involving gradient terms. To do so, we combine the PAC-Bayes toolbox with Poincar\'e and Log-Sobolev inequalities, avoiding an explicit dependency on dimension of the predictor space. Our results highlight the positive influence of \emph{flat minima} (being minima with a neighbourhood nearly minimising the learning problem as well) on generalisation performances, involving directly the benefits of the optimisation phase.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#31616;&#27905;&#30340;&#31232;&#30095;&#20998;&#32452;k&#26368;&#22823;&#35268;&#21017;&#21270;&#26041;&#27861;&#65292;&#21487;&#20197;&#21516;&#26102;&#22686;&#24378;&#20998;&#32452;&#20869;&#21644;&#20998;&#32452;&#38388;&#30340;&#31232;&#30095;&#24615;&#65292;&#26356;&#25509;&#36817;l0&#33539;&#25968;&#12290;</title><link>https://arxiv.org/abs/2402.08493</link><description>&lt;p&gt;
&#36890;&#36807;&#31232;&#30095;&#20998;&#32452;k&#26368;&#22823;&#35268;&#21017;&#21270;&#23454;&#29616;&#31232;&#30095;&#24615;
&lt;/p&gt;
&lt;p&gt;
Sparsity via Sparse Group $k$-max Regularization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08493
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#31616;&#27905;&#30340;&#31232;&#30095;&#20998;&#32452;k&#26368;&#22823;&#35268;&#21017;&#21270;&#26041;&#27861;&#65292;&#21487;&#20197;&#21516;&#26102;&#22686;&#24378;&#20998;&#32452;&#20869;&#21644;&#20998;&#32452;&#38388;&#30340;&#31232;&#30095;&#24615;&#65292;&#26356;&#25509;&#36817;l0&#33539;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#20855;&#26377;&#31232;&#30095;&#32422;&#26463;&#30340;&#32447;&#24615;&#36870;&#38382;&#39064;&#65292;l0&#27491;&#21017;&#21270;&#38382;&#39064;&#26159;NP&#22256;&#38590;&#30340;&#65292;&#29616;&#26377;&#26041;&#27861;&#35201;&#20040;&#21033;&#29992;&#36138;&#23146;&#31639;&#27861;&#25214;&#21040;&#36817;&#20284;&#26368;&#20248;&#35299;&#65292;&#35201;&#20040;&#29992;&#20984;&#26144;&#23556;&#26469;&#36924;&#36817;l0&#27491;&#21017;&#21270;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#31616;&#27905;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#21363;&#31232;&#30095;&#20998;&#32452;k&#26368;&#22823;&#35268;&#21017;&#21270;&#65292;&#20854;&#19981;&#20165;&#21487;&#20197;&#21516;&#26102;&#22686;&#24378;&#20998;&#32452;&#20869;&#21644;&#20998;&#32452;&#38388;&#30340;&#31232;&#30095;&#24615;&#65292;&#32780;&#19988;&#23545;&#27599;&#20010;&#20998;&#32452;&#20013;&#30340;&#21464;&#37327;&#30340;&#22823;&#23567;&#27809;&#26377;&#39069;&#22806;&#30340;&#38480;&#21046;&#65292;&#36825;&#23545;&#20110;&#19981;&#21516;&#23610;&#24230;&#30340;&#21464;&#37327;&#23588;&#20026;&#37325;&#35201;&#65292;&#20197;&#26356;&#25509;&#36817;l0&#33539;&#25968;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26377;&#23616;&#37096;&#26368;&#20248;&#24615;&#26465;&#20214;&#21644;&#22797;&#26434;&#24615;&#20998;&#26512;&#30340;&#36845;&#20195;&#36719;&#38408;&#20540;&#31639;&#27861;&#12290;&#36890;&#36807;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
For the linear inverse problem with sparsity constraints, the $l_0$ regularized problem is NP-hard, and existing approaches either utilize greedy algorithms to find almost-optimal solutions or to approximate the $l_0$ regularization with its convex counterparts. In this paper, we propose a novel and concise regularization, namely the sparse group $k$-max regularization, which can not only simultaneously enhance the group-wise and in-group sparsity, but also casts no additional restraints on the magnitude of variables in each group, which is especially important for variables at different scales, so that it approximate the $l_0$ norm more closely. We also establish an iterative soft thresholding algorithm with local optimality conditions and complexity analysis provided. Through numerical experiments on both synthetic and real-world datasets, we verify the effectiveness and flexibility of the proposed method.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#29109;&#20256;&#36755;&#26680;&#20174;&#25209;&#27425;&#30340;&#26410;&#37197;&#23545;&#28857;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;$X$&#21644;$Y$&#30340;&#32852;&#21512;&#27010;&#29575;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#20854;&#25910;&#25947;&#24615;&#36136;&#12290;</title><link>https://arxiv.org/abs/2402.08425</link><description>&lt;p&gt;
&#36890;&#36807;&#29109;&#20256;&#36755;&#26680;&#23558;&#26410;&#37197;&#23545;&#28857;&#30340;&#25209;&#27425;&#36716;&#31227;&#31639;&#23376;&#36827;&#34892;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Transfer Operators from Batches of Unpaired Points via Entropic Transport Kernels
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08425
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#29109;&#20256;&#36755;&#26680;&#20174;&#25209;&#27425;&#30340;&#26410;&#37197;&#23545;&#28857;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;$X$&#21644;$Y$&#30340;&#32852;&#21512;&#27010;&#29575;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#20854;&#25910;&#25947;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#20110;&#36890;&#36807;$N$&#20010;&#29420;&#31435;&#35266;&#27979;&#22359;$(\boldsymbol{x}^i,\boldsymbol{y}^i)$&#65288;$i=1,\ldots,N$&#65289;&#26469;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;$X$&#21644;$Y$&#30340;&#32852;&#21512;&#27010;&#29575;&#65292;&#27599;&#20010;&#35266;&#27979;&#22359;&#21253;&#21547;$M$&#20010;&#26679;&#26412;$(\boldsymbol{x}^i,\boldsymbol{y}^i) = \bigl((x^i_j, y^i_{\sigma^i(j)}) \bigr)_{j=1}^M$&#65292;&#20854;&#20013;$\sigma^i$&#34920;&#31034;&#19968;&#20010;&#26410;&#30693;&#30340;&#25490;&#21015;&#65292;&#29992;&#20110;&#23545;$i.i.d.$&#37319;&#26679;&#30340;&#23545;$(x^i_j,y_j^i)$&#36827;&#34892;&#37325;&#26032;&#25490;&#24207;&#65292;$j=1,\ldots,M$&#12290;&#36825;&#24847;&#21619;&#30528;&#35266;&#27979;&#22359;&#20869;&#37096;&#26679;&#26412;&#30340;&#39034;&#24207;&#26159;&#26410;&#30693;&#30340;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#20010;&#26368;&#22823;&#20284;&#28982;&#25512;&#26029;&#20989;&#25968;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#35745;&#31639;&#30340;&#36817;&#20284;&#26041;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#23427;&#20204;&#30340;&#24615;&#36136;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;$\Gamma$-&#25910;&#25947;&#32467;&#26524;&#65292;&#35828;&#26126;&#25105;&#20204;&#21487;&#20197;&#22312;&#22359;&#25968;$N$&#36235;&#21521;&#20110;&#26080;&#31351;&#22823;&#26102;&#65292;&#20174;&#32463;&#39564;&#36817;&#20284;&#20013;&#24674;&#22797;&#20986;&#30495;&#23454;&#30340;&#23494;&#24230;&#12290;&#20351;&#29992;&#29109;&#26368;&#20248;&#20256;&#36755;&#26680;&#65292;&#25105;&#20204;&#23545;&#19968;&#31867;&#20551;&#35774;&#31354;&#38388;&#24314;&#27169;&#65292;&#35813;&#31354;&#38388;&#30340;&#23494;&#24230;&#20989;&#25968;&#21487;&#20197;&#26368;&#23567;&#21270;&#25512;&#26029;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we are concerned with estimating the joint probability of random variables $X$ and $Y$, given $N$ independent observation blocks $(\boldsymbol{x}^i,\boldsymbol{y}^i)$, $i=1,\ldots,N$, each of $M$ samples $(\boldsymbol{x}^i,\boldsymbol{y}^i) = \bigl((x^i_j, y^i_{\sigma^i(j)}) \bigr)_{j=1}^M$, where $\sigma^i$ denotes an unknown permutation of i.i.d. sampled pairs $(x^i_j,y_j^i)$, $j=1,\ldots,M$. This means that the internal ordering of the $M$ samples within an observation block is not known. We derive a maximum-likelihood inference functional, propose a computationally tractable approximation and analyze their properties. In particular, we prove a $\Gamma$-convergence result showing that we can recover the true density from empirical approximations as the number $N$ of blocks goes to infinity. Using entropic optimal transport kernels, we model a class of hypothesis spaces of density functions over which the inference functional can be minimized. This hypothesis class is 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32593;&#32476;&#19978;&#24314;&#27169;&#22810;&#26234;&#20307;&#31995;&#32479;&#30340;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#32852;&#21512;&#25512;&#26029;&#32593;&#32476;&#30340;&#26435;&#37325;&#30697;&#38453;&#21644;&#30456;&#20114;&#20316;&#29992;&#26680;&#30340;&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;&#35299;&#20915;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#24182;&#20351;&#29992;&#20132;&#26367;&#26368;&#23567;&#20108;&#20056;&#65288;ALS&#65289;&#31639;&#27861;&#21644;&#20132;&#26367;&#26368;&#23567;&#20108;&#20056;&#31639;&#23376;&#22238;&#24402;&#65288;ORALS&#65289;&#31639;&#27861;&#36827;&#34892;&#27714;&#35299;&#12290;&#22312;&#20445;&#35777;&#21487;&#35782;&#21035;&#24615;&#21644;&#33391;&#23450;&#20041;&#24615;&#30340;&#26465;&#20214;&#19979;&#65292;ALS&#31639;&#27861;&#34920;&#29616;&#20986;&#32479;&#35745;&#25928;&#29575;&#21644;&#40065;&#26834;&#24615;&#65292;&#32780;ORALS&#31639;&#27861;&#26159;&#19968;&#33268;&#30340;&#65292;&#24182;&#19988;&#22312;&#28176;&#36817;&#24773;&#20917;&#19979;&#20855;&#26377;&#27491;&#24577;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.08412</link><description>&lt;p&gt;
&#22312;&#32593;&#32476;&#19978;&#30456;&#20114;&#20316;&#29992;&#30340;&#31890;&#23376;&#31995;&#32479;: &#32593;&#32476;&#21644;&#30456;&#20114;&#20316;&#29992;&#26680;&#30340;&#32852;&#21512;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Interacting Particle Systems on Networks: joint inference of the network and the interaction kernel
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08412
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32593;&#32476;&#19978;&#24314;&#27169;&#22810;&#26234;&#20307;&#31995;&#32479;&#30340;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#32852;&#21512;&#25512;&#26029;&#32593;&#32476;&#30340;&#26435;&#37325;&#30697;&#38453;&#21644;&#30456;&#20114;&#20316;&#29992;&#26680;&#30340;&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;&#35299;&#20915;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#24182;&#20351;&#29992;&#20132;&#26367;&#26368;&#23567;&#20108;&#20056;&#65288;ALS&#65289;&#31639;&#27861;&#21644;&#20132;&#26367;&#26368;&#23567;&#20108;&#20056;&#31639;&#23376;&#22238;&#24402;&#65288;ORALS&#65289;&#31639;&#27861;&#36827;&#34892;&#27714;&#35299;&#12290;&#22312;&#20445;&#35777;&#21487;&#35782;&#21035;&#24615;&#21644;&#33391;&#23450;&#20041;&#24615;&#30340;&#26465;&#20214;&#19979;&#65292;ALS&#31639;&#27861;&#34920;&#29616;&#20986;&#32479;&#35745;&#25928;&#29575;&#21644;&#40065;&#26834;&#24615;&#65292;&#32780;ORALS&#31639;&#27861;&#26159;&#19968;&#33268;&#30340;&#65292;&#24182;&#19988;&#22312;&#28176;&#36817;&#24773;&#20917;&#19979;&#20855;&#26377;&#27491;&#24577;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#31181;&#23398;&#31185;&#20013;&#65292;&#23545;&#32593;&#32476;&#19978;&#30340;&#22810;&#26234;&#20307;&#31995;&#32479;&#36827;&#34892;&#24314;&#27169;&#26159;&#19968;&#20010;&#22522;&#26412;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#20174;&#30001;&#22810;&#26465;&#36712;&#36857;&#32452;&#25104;&#30340;&#25968;&#25454;&#20013;&#32852;&#21512;&#25512;&#26029;&#32593;&#32476;&#30340;&#26435;&#37325;&#30697;&#38453;&#21644;&#30456;&#20114;&#20316;&#29992;&#26680;&#65292;&#20998;&#21035;&#30830;&#23450;&#21738;&#20123;&#26234;&#20307;&#19982;&#21738;&#20123;&#20854;&#20182;&#26234;&#20307;&#30456;&#20114;&#20316;&#29992;&#20197;&#21450;&#36825;&#31181;&#30456;&#20114;&#20316;&#29992;&#30340;&#35268;&#21017;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#33258;&#28982;&#22320;&#23548;&#33268;&#19968;&#20010;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#30740;&#31350;&#20102;&#20004;&#31181;&#35299;&#20915;&#26041;&#26696;&#65306;&#19968;&#31181;&#22522;&#20110;&#20132;&#26367;&#26368;&#23567;&#20108;&#20056;&#65288;ALS&#65289;&#31639;&#27861;&#65292;&#21478;&#19968;&#31181;&#22522;&#20110;&#19968;&#31181;&#21517;&#20026;&#20132;&#26367;&#26368;&#23567;&#20108;&#20056;&#30340;&#31639;&#23376;&#22238;&#24402;&#65288;ORALS&#65289;&#30340;&#26032;&#31639;&#27861;&#12290;&#36825;&#20004;&#31181;&#31639;&#27861;&#37117;&#21487;&#25193;&#23637;&#21040;&#22823;&#37327;&#25968;&#25454;&#36712;&#36857;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#20445;&#35777;&#21487;&#35782;&#21035;&#24615;&#21644;&#33391;&#23450;&#20041;&#24615;&#30340;&#24378;&#21046;&#24615;&#26465;&#20214;&#12290;&#23613;&#31649;ALS&#31639;&#27861;&#22312;&#23567;&#25968;&#25454;&#24773;&#20917;&#19979;&#32570;&#20047;&#24615;&#33021;&#21644;&#25910;&#25947;&#24615;&#20445;&#35777;&#65292;&#20294;&#34920;&#29616;&#20986;&#32479;&#35745;&#25928;&#29575;&#21644;&#40065;&#26834;&#24615;&#12290;&#22312;&#24378;&#21046;&#24615;&#26465;&#20214;&#19979;&#65292;ORALS&#20272;&#35745;&#22120;&#26159;&#19968;&#33268;&#30340;&#65292;&#24182;&#19988;&#22312;&#28176;&#36817;&#24773;&#20917;&#19979;&#20855;&#26377;&#27491;&#24577;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modeling multi-agent systems on networks is a fundamental challenge in a wide variety of disciplines. We jointly infer the weight matrix of the network and the interaction kernel, which determine respectively which agents interact with which others and the rules of such interactions from data consisting of multiple trajectories. The estimator we propose leads naturally to a non-convex optimization problem, and we investigate two approaches for its solution: one is based on the alternating least squares (ALS) algorithm; another is based on a new algorithm named operator regression with alternating least squares (ORALS). Both algorithms are scalable to large ensembles of data trajectories. We establish coercivity conditions guaranteeing identifiability and well-posedness. The ALS algorithm appears statistically efficient and robust even in the small data regime but lacks performance and convergence guarantees. The ORALS estimator is consistent and asymptotically normal under a coercivity
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20351;&#29992;&#24102;&#26377;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#30340;Noisy-SGD&#26041;&#27861;&#65292;&#25105;&#20204;&#21457;&#29616;&#38543;&#26426;&#24615;&#32780;&#38750;&#21098;&#35009;&#26799;&#24230;&#26159;&#23548;&#33268;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#38544;&#24335;&#20559;&#24046;&#30340;&#21407;&#22240;&#65292;&#24182;&#19988;&#36825;&#31181;&#20559;&#24046;&#20250;&#34987;&#21152;&#21095;&#65292;&#36825;&#23545;&#20110;&#20351;&#29992;&#24040;&#22823;&#25209;&#37327;&#25968;&#25454;&#30340;&#24378;&#24046;&#20998;&#38544;&#31169;&#20445;&#35777;&#26500;&#25104;&#37325;&#35201;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.08344</link><description>&lt;p&gt;
&#22312;&#24102;&#26377;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#30340;Noisy-SGD&#20013;&#30340;&#38544;&#24335;&#20559;&#24046;&#65306;&#21450;&#20854;&#22312;&#35757;&#32451;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Implicit Bias in Noisy-SGD: With Applications to Differentially Private Training
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08344
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#24102;&#26377;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#30340;Noisy-SGD&#26041;&#27861;&#65292;&#25105;&#20204;&#21457;&#29616;&#38543;&#26426;&#24615;&#32780;&#38750;&#21098;&#35009;&#26799;&#24230;&#26159;&#23548;&#33268;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#38544;&#24335;&#20559;&#24046;&#30340;&#21407;&#22240;&#65292;&#24182;&#19988;&#36825;&#31181;&#20559;&#24046;&#20250;&#34987;&#21152;&#21095;&#65292;&#36825;&#23545;&#20110;&#20351;&#29992;&#24040;&#22823;&#25209;&#37327;&#25968;&#25454;&#30340;&#24378;&#24046;&#20998;&#38544;&#31169;&#20445;&#35777;&#26500;&#25104;&#37325;&#35201;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;(SGD)&#20197;&#23567;&#25209;&#37327;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNN)&#30456;&#36739;&#20110;&#22823;&#25209;&#37327;&#35757;&#32451;&#33021;&#22815;&#33719;&#24471;&#26356;&#22909;&#30340;&#27979;&#35797;&#24615;&#33021;&#12290;SGD&#29305;&#23450;&#30340;&#22122;&#22768;&#32467;&#26500;&#34987;&#35748;&#20026;&#26159;&#23548;&#33268;&#36825;&#31181;&#38544;&#24335;&#20559;&#24046;&#30340;&#21407;&#22240;&#12290;&#29992;&#20110;&#30830;&#20445;DNN&#35757;&#32451;&#20013;&#30340;&#24046;&#24322;&#38544;&#31169;(DP)&#30340;DP-SGD&#20250;&#32473;&#21098;&#35009;&#26799;&#24230;&#28155;&#21152;&#39640;&#26031;&#22122;&#22768;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#22823;&#25209;&#37327;&#35757;&#32451;&#20173;&#28982;&#20250;&#23548;&#33268;&#26174;&#33879;&#30340;&#24615;&#33021;&#19979;&#38477;&#65292;&#36825;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#25361;&#25112;&#65292;&#22240;&#20026;&#24378;DP&#20445;&#35777;&#38656;&#35201;&#20351;&#29992;&#22823;&#25209;&#37327;&#25968;&#25454;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#29616;&#35937;&#22312;Noisy-SGD&#65288;&#27809;&#26377;&#21098;&#35009;&#30340;DP-SGD&#65289;&#20013;&#30340;&#23384;&#22312;&#65292;&#36825;&#34920;&#26126;&#38543;&#26426;&#24615;&#65288;&#32780;&#19981;&#26159;&#21098;&#35009;&#65289;&#26159;&#36825;&#31181;&#38544;&#24335;&#20559;&#24046;&#30340;&#21407;&#22240;&#65292;&#21363;&#20351;&#21152;&#20837;&#20102;&#39069;&#22806;&#30340;&#21508;&#21521;&#21516;&#24615;&#39640;&#26031;&#22122;&#22768;&#12290;&#25105;&#20204;&#22312;&#32447;&#24615;&#26368;&#23567;&#20108;&#20056;&#21644;&#23545;&#35282;&#32447;&#32447;&#24615;&#32593;&#32476;&#35774;&#32622;&#19978;&#23545;&#20351;&#29992;&#36830;&#32493;&#29256;&#26412;&#30340;Noisy-SGD&#33719;&#24471;&#30340;&#35299;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#24182;&#25581;&#31034;&#20102;&#38544;&#24335;&#20559;&#24046;&#30830;&#23454;&#34987;&#21152;&#21095;&#20102;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training Deep Neural Networks (DNNs) with small batches using Stochastic Gradient Descent (SGD) yields superior test performance compared to larger batches. The specific noise structure inherent to SGD is known to be responsible for this implicit bias. DP-SGD, used to ensure differential privacy (DP) in DNNs' training, adds Gaussian noise to the clipped gradients. Surprisingly, large-batch training still results in a significant decrease in performance, which poses an important challenge because strong DP guarantees necessitate the use of massive batches. We first show that the phenomenon extends to Noisy-SGD (DP-SGD without clipping), suggesting that the stochasticity (and not the clipping) is the cause of this implicit bias, even with additional isotropic Gaussian noise. We theoretically analyse the solutions obtained with continuous versions of Noisy-SGD for the Linear Least Square and Diagonal Linear Network settings, and reveal that the implicit bias is indeed amplified by the add
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#37096;&#20998;&#30417;&#27979;&#38382;&#39064;&#20013;&#25506;&#32034;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#28151;&#21512;&#27491;&#21017;&#21270;&#22120;&#21487;&#20197;&#25552;&#39640;&#22312;&#38543;&#26426;&#21644;&#23545;&#25239;&#29615;&#22659;&#20013;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.08321</link><description>&lt;p&gt;
&#20351;&#29992;&#28151;&#21512;&#27491;&#21017;&#21270;&#22120;&#30340;&#20248;&#21270;&#25506;&#32034;&#65306;&#22312;&#37096;&#20998;&#30417;&#27979;&#20013;&#20855;&#26377;&#23545;&#25239;&#40065;&#26834;&#24615;&#30340;&#23545;&#25968;&#36951;&#25022;
&lt;/p&gt;
&lt;p&gt;
Exploration by Optimization with Hybrid Regularizers: Logarithmic Regret with Adversarial Robustness in Partial Monitoring
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08321
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#37096;&#20998;&#30417;&#27979;&#38382;&#39064;&#20013;&#25506;&#32034;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#28151;&#21512;&#27491;&#21017;&#21270;&#22120;&#21487;&#20197;&#25552;&#39640;&#22312;&#38543;&#26426;&#21644;&#23545;&#25239;&#29615;&#22659;&#20013;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37096;&#20998;&#30417;&#27979;&#26159;&#19968;&#31181;&#20855;&#26377;&#26377;&#38480;&#35266;&#27979;&#30340;&#22312;&#32447;&#20915;&#31574;&#38382;&#39064;&#30340;&#36890;&#29992;&#26694;&#26550;&#12290;&#20026;&#20102;&#20174;&#36825;&#31181;&#26377;&#38480;&#35266;&#27979;&#20013;&#20570;&#20986;&#20915;&#31574;&#65292;&#38656;&#35201;&#25214;&#21040;&#19968;&#20010;&#36866;&#24403;&#30340;&#25506;&#32034;&#20998;&#24067;&#12290;&#26368;&#36817;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#27492;&#30446;&#30340;&#30340;&#24378;&#22823;&#26041;&#27861;&#65292;&#21363;&#36890;&#36807;&#20248;&#21270;&#36827;&#34892;&#25506;&#32034;&#65288;ExO&#65289;&#65292;&#23427;&#21033;&#29992;&#36861;&#36394;&#27491;&#21017;&#21270;&#26368;&#20248;&#26041;&#27861;&#65292;&#22312;&#24191;&#27867;&#30340;&#22312;&#32447;&#20915;&#31574;&#38382;&#39064;&#20013;&#23454;&#29616;&#23545;&#25239;&#29615;&#22659;&#19979;&#30340;&#26368;&#20248;&#30028;&#38480;&#12290;&#28982;&#32780;&#65292;&#22312;&#38543;&#26426;&#29615;&#22659;&#20013;&#32431;&#31929;&#24212;&#29992;ExO&#20250;&#26174;&#33879;&#38477;&#20302;&#36951;&#25022;&#30028;&#38480;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#23616;&#37096;&#21487;&#35266;&#27979;&#28216;&#25103;&#20013;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#39318;&#20808;&#24314;&#31435;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;ExO&#19982;&#28151;&#21512;&#27491;&#21017;&#21270;&#22120;&#30340;&#26694;&#26550;&#21644;&#20998;&#26512;&#12290;&#36825;&#20010;&#21457;&#23637;&#20351;&#25105;&#20204;&#33021;&#22815;&#26174;&#33879;&#25913;&#36827;&#26368;&#20339;&#21452;&#36194;&#31639;&#27861;&#65288;BOBW&#65289;&#30340;&#29616;&#26377;&#36951;&#25022;&#30028;&#38480;&#65292;&#22312;&#38543;&#26426;&#21644;&#23545;&#25239;&#29615;&#22659;&#20013;&#37117;&#23454;&#29616;&#20102;&#20960;&#20046;&#26368;&#20248;&#30340;&#30028;&#38480;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#24471;&#20986;&#20102;&#19968;&#20010;&#38543;&#26426;&#36951;&#25022;&#30028;&#38480;&#20026;$O(\sum_{a \neq a^*} k^2 m^2$
&lt;/p&gt;
&lt;p&gt;
Partial monitoring is a generic framework of online decision-making problems with limited observations. To make decisions from such limited observations, it is necessary to find an appropriate distribution for exploration. Recently, a powerful approach for this purpose, exploration by optimization (ExO), was proposed, which achieves the optimal bounds in adversarial environments with follow-the-regularized-leader for a wide range of online decision-making problems. However, a naive application of ExO in stochastic environments significantly degrades regret bounds. To resolve this problem in locally observable games, we first establish a novel framework and analysis for ExO with a hybrid regularizer. This development allows us to significantly improve the existing regret bounds of best-of-both-worlds (BOBW) algorithms, which achieves nearly optimal bounds both in stochastic and adversarial environments. In particular, we derive a stochastic regret bound of $O(\sum_{a \neq a^*} k^2 m^2 \
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20840;&#23616;&#21644;&#23616;&#37096;&#39532;&#27663;&#36317;&#31163;&#30340;&#20998;&#31867;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#26925;&#22278;&#24418;&#20998;&#24067;&#30340;&#31454;&#20105;&#31867;&#21035;&#65292;&#35813;&#26041;&#27861;&#30456;&#27604;&#27969;&#34892;&#30340;&#21442;&#25968;&#21270;&#21644;&#38750;&#21442;&#25968;&#21270;&#20998;&#31867;&#22120;&#20855;&#26377;&#26356;&#22909;&#30340;&#28789;&#27963;&#24615;&#21644;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.08283</link><description>&lt;p&gt;
&#20351;&#29992;&#20840;&#23616;&#21644;&#23616;&#37096;&#39532;&#27663;&#36317;&#31163;&#30340;&#20998;&#31867;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Classification Using Global and Local Mahalanobis Distances
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08283
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20840;&#23616;&#21644;&#23616;&#37096;&#39532;&#27663;&#36317;&#31163;&#30340;&#20998;&#31867;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#26925;&#22278;&#24418;&#20998;&#24067;&#30340;&#31454;&#20105;&#31867;&#21035;&#65292;&#35813;&#26041;&#27861;&#30456;&#27604;&#27969;&#34892;&#30340;&#21442;&#25968;&#21270;&#21644;&#38750;&#21442;&#25968;&#21270;&#20998;&#31867;&#22120;&#20855;&#26377;&#26356;&#22909;&#30340;&#28789;&#27963;&#24615;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26469;&#33258;&#19981;&#21516;&#31867;&#21035;&#30340;&#35266;&#23519;&#20540;&#30340;&#39532;&#27663;&#36317;&#31163;&#30340;&#26032;&#22411;&#21322;&#21442;&#25968;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#30340;&#24037;&#20855;&#26159;&#19968;&#20010;&#20855;&#26377;&#36923;&#36753;&#38142;&#25509;&#20989;&#25968;&#30340;&#24191;&#20041;&#21152;&#24615;&#27169;&#22411;&#65292;&#23427;&#20351;&#29992;&#36825;&#20123;&#36317;&#31163;&#20316;&#20026;&#29305;&#24449;&#26469;&#20272;&#35745;&#19981;&#21516;&#31867;&#21035;&#30340;&#21518;&#39564;&#27010;&#29575;&#12290;&#23613;&#31649;&#27969;&#34892;&#30340;&#21442;&#25968;&#21270;&#20998;&#31867;&#22120;&#22914;&#32447;&#24615;&#21644;&#20108;&#27425;&#21028;&#21035;&#20998;&#26512;&#20027;&#35201;&#22522;&#20110;&#22522;&#30784;&#20998;&#24067;&#30340;&#27491;&#24577;&#24615;&#65292;&#20294;&#25152;&#25552;&#20986;&#30340;&#20998;&#31867;&#22120;&#26356;&#21152;&#28789;&#27963;&#65292;&#19981;&#21463;&#27492;&#31867;&#21442;&#25968;&#21270;&#20551;&#35774;&#30340;&#38480;&#21046;&#12290;&#30001;&#20110;&#26925;&#22278;&#20998;&#24067;&#30340;&#23494;&#24230;&#26159;&#39532;&#27663;&#36317;&#31163;&#30340;&#20989;&#25968;&#65292;&#24403;&#31454;&#20105;&#31867;&#21035;&#26159;&#65288;&#20960;&#20046;&#65289;&#26925;&#22278;&#24418;&#26102;&#65292;&#35813;&#20998;&#31867;&#22120;&#30340;&#25928;&#26524;&#24456;&#22909;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#23427;&#32463;&#24120;&#32988;&#36807;&#27969;&#34892;&#30340;&#38750;&#21442;&#25968;&#21270;&#20998;&#31867;&#22120;&#65292;&#29305;&#21035;&#26159;&#24403;&#26679;&#26412;&#37327;&#30456;&#23545;&#20110;&#25968;&#25454;&#32500;&#25968;&#36739;&#23567;&#26102;&#12290;&#20026;&#20102;&#24212;&#23545;&#38750;&#26925;&#22278;&#21644;&#21487;&#33021;&#22810;&#23792;&#30340;&#20998;&#24067;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#39532;&#27663;&#36317;&#31163;&#30340;&#23616;&#37096;&#29256;&#26412;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;
&lt;/p&gt;
&lt;p&gt;
We propose a novel semi-parametric classifier based on Mahalanobis distances of an observation from the competing classes. Our tool is a generalized additive model with the logistic link function that uses these distances as features to estimate the posterior probabilities of the different classes. While popular parametric classifiers like linear and quadratic discriminant analyses are mainly motivated by the normality of the underlying distributions, the proposed classifier is more flexible and free from such parametric assumptions. Since the densities of elliptic distributions are functions of Mahalanobis distances, this classifier works well when the competing classes are (nearly) elliptic. In such cases, it often outperforms popular nonparametric classifiers, especially when the sample size is small compared to the dimension of the data. To cope with non-elliptic and possibly multimodal distributions, we propose a local version of the Mahalanobis distance. Subsequently, we propose 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#30446;&#26631;&#24178;&#39044;&#19979;&#30340;&#22240;&#26524;&#21457;&#29616;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#38543;&#26426;&#24178;&#39044;&#27169;&#22411;&#26469;&#23613;&#37327;&#20943;&#23569;&#24178;&#39044;&#27425;&#25968;&#12290;&#36890;&#36807;&#39564;&#35777;&#21644;&#25628;&#32034;&#20004;&#20010;&#22522;&#26412;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#22810;&#23545;&#25968;&#22797;&#26434;&#24230;&#30340;&#36817;&#20284;&#31639;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.08229</link><description>&lt;p&gt;
&#38750;&#30446;&#26631;&#24178;&#39044;&#19979;&#30340;&#22240;&#26524;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Causal Discovery under Off-Target Interventions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08229
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#30446;&#26631;&#24178;&#39044;&#19979;&#30340;&#22240;&#26524;&#21457;&#29616;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#38543;&#26426;&#24178;&#39044;&#27169;&#22411;&#26469;&#23613;&#37327;&#20943;&#23569;&#24178;&#39044;&#27425;&#25968;&#12290;&#36890;&#36807;&#39564;&#35777;&#21644;&#25628;&#32034;&#20004;&#20010;&#22522;&#26412;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#22810;&#23545;&#25968;&#22797;&#26434;&#24230;&#30340;&#36817;&#20284;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#22270;&#21457;&#29616;&#26159;&#19968;&#20010;&#22312;&#21508;&#20010;&#23398;&#31185;&#20013;&#20855;&#26377;&#37325;&#35201;&#24212;&#29992;&#30340;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#20165;&#20973;&#35266;&#23519;&#25968;&#25454;&#65292;&#21482;&#33021;&#24674;&#22797;&#21040;&#20854;&#39532;&#23572;&#21487;&#22827;&#31561;&#20215;&#31867;&#30340;&#28508;&#22312;&#22240;&#26524;&#22270;&#65292;&#24182;&#19988;&#38656;&#35201;&#36827;&#19968;&#27493;&#30340;&#20551;&#35774;&#25110;&#24178;&#39044;&#26469;&#32553;&#23567;&#30495;&#23454;&#22270;&#30340;&#33539;&#22260;&#12290;&#26412;&#30740;&#31350;&#35299;&#20915;&#20102;&#22312;&#38543;&#26426;&#24178;&#39044;&#35774;&#32622;&#19979;&#30340;&#22240;&#26524;&#21457;&#29616;&#38382;&#39064;&#65292;&#30446;&#26631;&#26159;&#23613;&#37327;&#20943;&#23569;&#24178;&#39044;&#27425;&#25968;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20197;&#19979;&#38543;&#26426;&#24178;&#39044;&#27169;&#22411;&#65292;&#23427;&#21253;&#21547;&#20102;&#29616;&#26377;&#25991;&#29486;&#20013;&#30340;&#33258;&#36866;&#24212;&#26080;&#22122;&#22768;&#24178;&#39044;&#65292;&#24182;&#33021;&#25429;&#25417;&#21040;&#33026;&#32938;&#25163;&#24178;&#39044;&#21644;CRISPR&#22522;&#22240;&#25970;&#38500;&#31561;&#24773;&#20917;&#65306;&#20219;&#20309;&#24178;&#39044;&#23581;&#35797;&#37117;&#20250;&#23548;&#33268;&#23545;&#19968;&#20010;&#38543;&#26426;&#39030;&#28857;&#23376;&#38598;&#30340;&#23454;&#38469;&#24178;&#39044;&#65292;&#36825;&#20010;&#23376;&#38598;&#30340;&#36873;&#25321;&#26159;&#20381;&#36182;&#20110;&#23581;&#35797;&#30340;&#21160;&#20316;&#30340;&#20998;&#24067;&#12290;&#22312;&#36825;&#20010;&#27169;&#22411;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22240;&#26524;&#21457;&#29616;&#20013;&#30340;&#39564;&#35777;&#21644;&#25628;&#32034;&#20004;&#20010;&#22522;&#26412;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#20855;&#26377;&#22810;&#23545;&#25968;&#22797;&#26434;&#24230;&#30340;&#36817;&#20284;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal graph discovery is a significant problem with applications across various disciplines. However, with observational data alone, the underlying causal graph can only be recovered up to its Markov equivalence class, and further assumptions or interventions are necessary to narrow down the true graph. This work addresses the causal discovery problem under the setting of stochastic interventions with the natural goal of minimizing the number of interventions performed. We propose the following stochastic intervention model which subsumes existing adaptive noiseless interventions in the literature while capturing scenarios such as fat-hand interventions and CRISPR gene knockouts: any intervention attempt results in an actual intervention on a random subset of vertices, drawn from a distribution dependent on attempted action. Under this model, we study the two fundamental problems in causal discovery of verification and search and provide approximation algorithms with polylogarithmic c
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24369;&#20998;&#24067;&#37325;&#21472;&#19979;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#25130;&#26029;&#21452;&#37325;&#31283;&#20581;&#65288;TDR&#65289;&#20272;&#35745;&#22120;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>https://arxiv.org/abs/2402.08201</link><description>&lt;p&gt;
&#24369;&#20998;&#24067;&#37325;&#21472;&#19979;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Off-Policy Evaluation in Markov Decision Processes under Weak Distributional Overlap
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08201
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24369;&#20998;&#24067;&#37325;&#21472;&#19979;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#25130;&#26029;&#21452;&#37325;&#31283;&#20581;&#65288;TDR&#65289;&#20272;&#35745;&#22120;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#20013;&#65292;&#21452;&#37325;&#31283;&#20581;&#26041;&#27861;&#22312;&#24207;&#21015;&#21487;&#24573;&#30053;&#24615;&#19979;&#23545;&#31163;&#31574;&#30053;&#35780;&#20272;&#20855;&#26377;&#24456;&#22823;&#30340;&#28508;&#21147;&#65306;&#23427;&#20204;&#24050;&#32463;&#35777;&#26126;&#20102;&#38543;&#30528;&#26102;&#38271;T&#30340;&#25910;&#25947;&#36895;&#24230;&#20026;$1/\sqrt{T}$&#65292;&#22312;&#22823;&#26679;&#26412;&#20013;&#20855;&#26377;&#32479;&#35745;&#25928;&#29575;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#26631;&#20934;&#24378;&#21270;&#23398;&#20064;&#25216;&#26415;&#25191;&#34892;&#39044;&#20272;&#20219;&#21153;&#65292;&#20855;&#26377;&#27169;&#22359;&#21270;&#23454;&#29616;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#32467;&#26524;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20351;&#29992;&#20102;&#24378;&#20998;&#24067;&#37325;&#21472;&#20551;&#35774;&#65292;&#21363;&#30446;&#26631;&#25919;&#31574;&#21644;&#25968;&#25454;&#25910;&#38598;&#25919;&#31574;&#30340;&#31283;&#24577;&#20998;&#24067;&#30456;&#24046;&#22312;&#26377;&#38480;&#22240;&#23376;&#20869;&#65292;&#32780;&#36825;&#20010;&#20551;&#35774;&#36890;&#24120;&#21482;&#22312;MDP&#30340;&#29366;&#24577;&#31354;&#38388;&#26377;&#30028;&#26102;&#25165;&#21487;&#20449;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#22312;&#24369;&#20998;&#24067;&#37325;&#21472;&#27010;&#24565;&#19979;&#30340;MDP&#31163;&#31574;&#30053;&#35780;&#20272;&#20219;&#21153;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31867;&#25130;&#26029;&#21452;&#37325;&#31283;&#20581;&#65288;TDR&#65289;&#20272;&#35745;&#22120;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#34920;&#29616;&#33391;&#22909;&#12290;&#24403;&#30446;&#26631;&#21644;&#25968;&#25454;&#25910;&#38598;&#30340;&#20998;&#24067;&#27604;&#29575;&#26377;&#30028;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;&#20272;&#35745;&#22120;&#30340;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Doubly robust methods hold considerable promise for off-policy evaluation in Markov decision processes (MDPs) under sequential ignorability: They have been shown to converge as $1/\sqrt{T}$ with the horizon $T$, to be statistically efficient in large samples, and to allow for modular implementation where preliminary estimation tasks can be executed using standard reinforcement learning techniques. Existing results, however, make heavy use of a strong distributional overlap assumption whereby the stationary distributions of the target policy and the data-collection policy are within a bounded factor of each other -- and this assumption is typically only credible when the state space of the MDP is bounded. In this paper, we re-visit the task of off-policy evaluation in MDPs under a weaker notion of distributional overlap, and introduce a class of truncated doubly robust (TDR) estimators which we find to perform well in this setting. When the distribution ratio of the target and data-coll
&lt;/p&gt;</description></item><item><title>&#39640;&#26031;&#27169;&#22411;&#38598;&#25104;&#32622;&#20449;&#20256;&#25773;&#31639;&#27861;&#65288;GEnBP&#65289;&#26159;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#31995;&#32479;&#20013;&#39640;&#25928;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#38598;&#25104;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#21644;&#39640;&#26031;&#32622;&#20449;&#20256;&#25773;&#31561;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#33021;&#26377;&#25928;&#22788;&#29702;&#39640;&#32500;&#29366;&#24577;&#12289;&#21442;&#25968;&#21644;&#22797;&#26434;&#30340;&#20381;&#36182;&#32467;&#26500;&#12290;</title><link>https://arxiv.org/abs/2402.08193</link><description>&lt;p&gt;
&#39640;&#26031;&#27169;&#22411;&#38598;&#25104;&#32622;&#20449;&#20256;&#25773;&#29992;&#20110;&#39640;&#32500;&#31995;&#32479;&#20013;&#30340;&#39640;&#25928;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Gaussian Ensemble Belief Propagation for Efficient Inference in High-Dimensional Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08193
&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#27169;&#22411;&#38598;&#25104;&#32622;&#20449;&#20256;&#25773;&#31639;&#27861;&#65288;GEnBP&#65289;&#26159;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#31995;&#32479;&#20013;&#39640;&#25928;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#38598;&#25104;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#21644;&#39640;&#26031;&#32622;&#20449;&#20256;&#25773;&#31561;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#33021;&#26377;&#25928;&#22788;&#29702;&#39640;&#32500;&#29366;&#24577;&#12289;&#21442;&#25968;&#21644;&#22797;&#26434;&#30340;&#20381;&#36182;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#27169;&#22411;&#20013;&#30340;&#39640;&#25928;&#25512;&#26029;&#20173;&#28982;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#25361;&#25112;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#39640;&#26031;&#27169;&#22411;&#38598;&#25104;&#32622;&#20449;&#20256;&#25773;&#65288;GEnBP&#65289;&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26159;&#38598;&#25104;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#21644;&#39640;&#26031;&#32622;&#20449;&#20256;&#25773;&#65288;GaBP&#65289;&#26041;&#27861;&#30340;&#32467;&#21512;&#12290;GEnBP&#36890;&#36807;&#22312;&#22270;&#27169;&#22411;&#32467;&#26500;&#20013;&#20256;&#36882;&#20302;&#31209;&#26412;&#22320;&#20449;&#24687;&#26469;&#26356;&#26032;&#38598;&#25104;&#27169;&#22411;&#12290;&#36825;&#31181;&#32452;&#21512;&#32487;&#25215;&#20102;&#27599;&#31181;&#26041;&#27861;&#30340;&#26377;&#21033;&#29305;&#24615;&#12290;&#38598;&#25104;&#25216;&#26415;&#20351;&#24471;GEnBP&#33021;&#22815;&#22788;&#29702;&#39640;&#32500;&#29366;&#24577;&#12289;&#21442;&#25968;&#21644;&#22797;&#26434;&#30340;&#12289;&#22024;&#26434;&#30340;&#40657;&#31665;&#29983;&#25104;&#36807;&#31243;&#12290;&#22312;&#22270;&#27169;&#22411;&#32467;&#26500;&#20013;&#20351;&#29992;&#26412;&#22320;&#20449;&#24687;&#30830;&#20445;&#20102;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#20998;&#24067;&#24335;&#35745;&#31639;&#65292;&#24182;&#33021;&#39640;&#25928;&#22320;&#22788;&#29702;&#22797;&#26434;&#30340;&#20381;&#36182;&#32467;&#26500;&#12290;&#24403;&#38598;&#25104;&#22823;&#23567;&#36828;&#23567;&#20110;&#25512;&#26029;&#32500;&#24230;&#26102;&#65292;GEnBP&#29305;&#21035;&#26377;&#20248;&#21183;&#12290;&#36825;&#31181;&#24773;&#20917;&#22312;&#31354;&#26102;&#24314;&#27169;&#12289;&#22270;&#20687;&#22788;&#29702;&#21644;&#29289;&#29702;&#27169;&#22411;&#21453;&#28436;&#31561;&#39046;&#22495;&#32463;&#24120;&#20986;&#29616;&#12290;GEnBP&#21487;&#20197;&#24212;&#29992;&#20110;&#19968;&#33324;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Efficient inference in high-dimensional models remains a central challenge in machine learning. This paper introduces the Gaussian Ensemble Belief Propagation (GEnBP) algorithm, a fusion of the Ensemble Kalman filter and Gaussian belief propagation (GaBP) methods. GEnBP updates ensembles by passing low-rank local messages in a graphical model structure. This combination inherits favourable qualities from each method. Ensemble techniques allow GEnBP to handle high-dimensional states, parameters and intricate, noisy, black-box generation processes. The use of local messages in a graphical model structure ensures that the approach is suited to distributed computing and can efficiently handle complex dependence structures. GEnBP is particularly advantageous when the ensemble size is considerably smaller than the inference dimension. This scenario often arises in fields such as spatiotemporal modelling, image processing and physical model inversion. GEnBP can be applied to general problem s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;VCoTTA&#65292;&#19968;&#31181;&#21464;&#20998;&#36125;&#21494;&#26031;&#26041;&#27861;&#29992;&#20110;&#27979;&#37327;&#36830;&#32493;&#27979;&#35797;&#26102;&#36866;&#24212;&#24615;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#37319;&#29992;&#21464;&#20998;&#39044;&#28909;&#31574;&#30053;&#23558;&#39044;&#35757;&#32451;&#30340;&#27169;&#22411;&#36716;&#20026;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65292;&#22312;&#27979;&#35797;&#26102;&#36890;&#36807;&#22343;&#20540;&#25945;&#24072;&#26356;&#26032;&#31574;&#30053;&#26469;&#26356;&#26032;&#23398;&#29983;&#27169;&#22411;&#65292;&#32467;&#21512;&#28304;&#27169;&#22411;&#21644;&#25945;&#24072;&#27169;&#22411;&#30340;&#20808;&#39564;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#20943;&#36731;&#20808;&#39564;&#20559;&#31227;&#26041;&#38754;&#26377;&#25928;&#12290;</title><link>https://arxiv.org/abs/2402.08182</link><description>&lt;p&gt;
&#21464;&#20998;&#36830;&#32493;&#27979;&#35797;&#26102;&#36866;&#24212;&#24615;
&lt;/p&gt;
&lt;p&gt;
Variational Continual Test-Time Adaptation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08182
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;VCoTTA&#65292;&#19968;&#31181;&#21464;&#20998;&#36125;&#21494;&#26031;&#26041;&#27861;&#29992;&#20110;&#27979;&#37327;&#36830;&#32493;&#27979;&#35797;&#26102;&#36866;&#24212;&#24615;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#37319;&#29992;&#21464;&#20998;&#39044;&#28909;&#31574;&#30053;&#23558;&#39044;&#35757;&#32451;&#30340;&#27169;&#22411;&#36716;&#20026;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65292;&#22312;&#27979;&#35797;&#26102;&#36890;&#36807;&#22343;&#20540;&#25945;&#24072;&#26356;&#26032;&#31574;&#30053;&#26469;&#26356;&#26032;&#23398;&#29983;&#27169;&#22411;&#65292;&#32467;&#21512;&#28304;&#27169;&#22411;&#21644;&#25945;&#24072;&#27169;&#22411;&#30340;&#20808;&#39564;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#20943;&#36731;&#20808;&#39564;&#20559;&#31227;&#26041;&#38754;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#39564;&#20559;&#31227;&#22312;&#21482;&#20351;&#29992;&#26080;&#26631;&#31614;&#27979;&#35797;&#25968;&#25454;&#30340;&#36830;&#32493;&#27979;&#35797;&#26102;&#36866;&#24212;&#24615;&#65288;CTTA&#65289;&#26041;&#27861;&#20013;&#33267;&#20851;&#37325;&#35201;&#65292;&#22240;&#20026;&#23427;&#21487;&#33021;&#23548;&#33268;&#20005;&#37325;&#30340;&#35823;&#24046;&#20256;&#25773;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;VCoTTA&#65292;&#19968;&#31181;&#29992;&#20110;&#27979;&#37327;CTTA&#20013;&#19981;&#30830;&#23450;&#24615;&#30340;&#21464;&#20998;&#36125;&#21494;&#26031;&#26041;&#27861;&#12290;&#22312;&#28304;&#38454;&#27573;&#65292;&#25105;&#20204;&#36890;&#36807;&#21464;&#20998;&#39044;&#28909;&#31574;&#30053;&#23558;&#39044;&#35757;&#32451;&#30340;&#30830;&#23450;&#24615;&#27169;&#22411;&#36716;&#21270;&#20026;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNN&#65289;&#65292;&#23558;&#19981;&#30830;&#23450;&#24615;&#27880;&#20837;&#27169;&#22411;&#20013;&#12290;&#22312;&#27979;&#35797;&#26102;&#65292;&#25105;&#20204;&#37319;&#29992;&#21464;&#20998;&#25512;&#26029;&#30340;&#22343;&#20540;&#25945;&#24072;&#26356;&#26032;&#31574;&#30053;&#65292;&#23558;&#23398;&#29983;&#27169;&#22411;&#21644;&#25351;&#25968;&#31227;&#21160;&#24179;&#22343;&#27861;&#29992;&#20110;&#25945;&#24072;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26032;&#26041;&#27861;&#36890;&#36807;&#32467;&#21512;&#28304;&#27169;&#22411;&#21644;&#25945;&#24072;&#27169;&#22411;&#30340;&#20808;&#39564;&#26469;&#26356;&#26032;&#23398;&#29983;&#27169;&#22411;&#12290;&#35777;&#25454;&#19979;&#30028;&#34987;&#21046;&#23450;&#20026;&#23398;&#29983;&#27169;&#22411;&#21644;&#25945;&#24072;&#27169;&#22411;&#20043;&#38388;&#30340;&#20132;&#21449;&#29109;&#65292;&#20197;&#21450;&#20808;&#39564;&#28151;&#21512;&#30340;Kullback-Leibler&#65288;KL&#65289;&#25955;&#24230;&#12290;&#22312;&#19977;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#20943;&#36731;&#22312;CTTA&#20013;&#30340;&#20808;&#39564;&#20559;&#31227;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The prior drift is crucial in Continual Test-Time Adaptation (CTTA) methods that only use unlabeled test data, as it can cause significant error propagation. In this paper, we introduce VCoTTA, a variational Bayesian approach to measure uncertainties in CTTA. At the source stage, we transform a pre-trained deterministic model into a Bayesian Neural Network (BNN) via a variational warm-up strategy, injecting uncertainties into the model. During the testing time, we employ a mean-teacher update strategy using variational inference for the student model and exponential moving average for the teacher model. Our novel approach updates the student model by combining priors from both the source and teacher models. The evidence lower bound is formulated as the cross-entropy between the student and teacher models, along with the Kullback-Leibler (KL) divergence of the prior mixture. Experimental results on three datasets demonstrate the method's effectiveness in mitigating prior drift within th
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#36890;&#20449;&#22797;&#26434;&#24615;&#35777;&#26126;&#20102;Transformer&#23618;&#22312;&#22788;&#29702;&#20989;&#25968;&#32452;&#21512;&#20219;&#21153;&#26102;&#30340;&#23616;&#38480;&#24615;&#65292;&#25351;&#20986;&#23545;&#20110;&#22823;&#22411;&#23450;&#20041;&#22495;&#21644;&#26576;&#20123;&#25968;&#23398;&#20219;&#21153;&#65292;Transformers&#21487;&#33021;&#26080;&#27861;&#35299;&#20915;&#12290;</title><link>https://arxiv.org/abs/2402.08164</link><description>&lt;p&gt;
&#20851;&#20110;Transformer&#26550;&#26500;&#30340;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
On Limitations of the Transformer Architecture
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08164
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#36890;&#20449;&#22797;&#26434;&#24615;&#35777;&#26126;&#20102;Transformer&#23618;&#22312;&#22788;&#29702;&#20989;&#25968;&#32452;&#21512;&#20219;&#21153;&#26102;&#30340;&#23616;&#38480;&#24615;&#65292;&#25351;&#20986;&#23545;&#20110;&#22823;&#22411;&#23450;&#20041;&#22495;&#21644;&#26576;&#20123;&#25968;&#23398;&#20219;&#21153;&#65292;Transformers&#21487;&#33021;&#26080;&#27861;&#35299;&#20915;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20013;&#24187;&#35273;&#30340;&#26681;&#26412;&#21407;&#22240;&#26159;&#20160;&#20040;&#65311;&#25105;&#20204;&#20351;&#29992;&#36890;&#20449;&#22797;&#26434;&#24615;&#26469;&#35777;&#26126;&#65292;&#22914;&#26524;&#20989;&#25968;&#30340;&#23450;&#20041;&#22495;&#36275;&#22815;&#22823;&#65292;Transformer&#23618;&#26080;&#27861;&#32452;&#21512;&#20989;&#25968;&#65288;&#20363;&#22914;&#65292;&#22312;&#23478;&#35889;&#20013;&#26597;&#25214;&#19968;&#20010;&#20154;&#30340;&#31062;&#29238;&#65289;&#65307;&#25105;&#20204;&#36890;&#36807;&#31034;&#20363;&#26174;&#31034;&#65292;&#24403;&#23450;&#20041;&#22495;&#30456;&#24403;&#23567;&#30340;&#26102;&#20505;&#65292;&#36825;&#31181;&#33021;&#21147;&#30340;&#32570;&#20047;&#24050;&#32463;&#22312;&#32463;&#39564;&#19978;&#23384;&#22312;&#12290;&#25105;&#20204;&#36824;&#25351;&#20986;&#65292;&#35768;&#22810;&#22312;&#25152;&#35859;&#30340;&#32452;&#21512;&#20219;&#21153;&#20013;&#30340;&#25968;&#23398;&#20219;&#21153;&#65292;&#35748;&#20026;&#23427;&#20204;&#23545;LLMs&#26469;&#35828;&#24456;&#38590;&#35299;&#20915;&#65292;&#23545;&#20110;&#36275;&#22815;&#22823;&#30340;&#23454;&#20363;&#26469;&#35828;&#65292;&#19988;&#20551;&#35774;&#35745;&#31639;&#22797;&#26434;&#24615;&#39046;&#22495;&#30340;&#26576;&#20123;&#34987;&#24191;&#27867;&#25509;&#21463;&#30340;&#29468;&#24819;&#26159;&#27491;&#30830;&#30340;&#65292;Transformers&#20063;&#19981;&#22826;&#21487;&#33021;&#35299;&#20915;&#12290;
&lt;/p&gt;
&lt;p&gt;
What are the root causes of hallucinations in large language models (LLMs)? We use Communication Complexity to prove that the Transformer layer is incapable of composing functions (e.g., identify a grandparent of a person in a genealogy) if the domains of the functions are large enough; we show through examples that this inability is already empirically present when the domains are quite small. We also point out that several mathematical tasks that are at the core of the so-called compositional tasks thought to be hard for LLMs are unlikely to be solvable by Transformers, for large enough instances and assuming that certain well accepted conjectures in the field of Computational Complexity are true.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;Laplacian&#32422;&#26463;&#19979;&#23398;&#20064;&#31515;&#21345;&#23572;&#20056;&#31215;&#22270;&#30340;&#38382;&#39064;&#65292;&#24314;&#31435;&#20102;&#31515;&#21345;&#23572;&#20056;&#31215;Laplacian&#30340;&#32479;&#35745;&#19968;&#33268;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#31639;&#27861;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.08105</link><description>&lt;p&gt;
&#23398;&#20064;&#20855;&#26377;Laplacian&#32422;&#26463;&#30340;&#31515;&#21345;&#23572;&#20056;&#31215;&#22270;
&lt;/p&gt;
&lt;p&gt;
Learning Cartesian Product Graphs with Laplacian Constraints
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08105
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;Laplacian&#32422;&#26463;&#19979;&#23398;&#20064;&#31515;&#21345;&#23572;&#20056;&#31215;&#22270;&#30340;&#38382;&#39064;&#65292;&#24314;&#31435;&#20102;&#31515;&#21345;&#23572;&#20056;&#31215;Laplacian&#30340;&#32479;&#35745;&#19968;&#33268;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#31639;&#27861;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;Laplacian&#23398;&#20064;&#65292;&#20063;&#34987;&#31216;&#20026;&#32593;&#32476;&#25299;&#25169;&#25512;&#26029;&#65292;&#26159;&#19968;&#20010;&#21560;&#24341;&#22810;&#20010;&#39046;&#22495;&#20852;&#36259;&#30340;&#38382;&#39064;&#12290;&#22312;&#39640;&#26031;&#22270;&#27169;&#22411;&#65288;GM&#65289;&#20013;&#65292;&#22270;&#23398;&#20064;&#31561;&#20215;&#20110;&#21521;&#21327;&#26041;&#24046;&#36873;&#25321;&#28155;&#21152;Laplacian&#32467;&#26500;&#12290;&#22312;&#22270;&#20449;&#21495;&#22788;&#29702;&#65288;GSP&#65289;&#20013;&#65292;&#20174;&#36807;&#28388;&#31995;&#32479;&#30340;&#36755;&#20986;&#20013;&#25512;&#26029;&#26410;&#35266;&#23519;&#21040;&#30340;&#22270;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;Laplacian&#32422;&#26463;&#19979;&#23398;&#20064;&#31515;&#21345;&#23572;&#20056;&#31215;&#22270;&#30340;&#38382;&#39064;&#12290;&#31515;&#21345;&#23572;&#22270;&#20056;&#31215;&#26159;&#24314;&#27169;&#39640;&#38454;&#26465;&#20214;&#20381;&#36182;&#30340;&#19968;&#31181;&#33258;&#28982;&#26041;&#27861;&#65292;&#20063;&#26159;&#23558;GSP&#25512;&#24191;&#21040;&#22810;&#36335;&#24352;&#37327;&#30340;&#20851;&#38190;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#31515;&#21345;&#23572;&#20056;&#31215;Laplacian&#30340;&#24809;&#32602;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65288;MLE&#65289;&#30340;&#32479;&#35745;&#19968;&#33268;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#36824;&#25193;&#23637;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#20197;&#22312;&#23384;&#22312;&#32467;&#26500;&#24615;&#32570;&#22833;&#20540;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#39640;&#25928;&#30340;&#32852;&#21512;&#22270;&#23398;&#20064;&#21644;&#25554;&#34917;&#12290;&#23545;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Laplacian learning, also known as network topology inference, is a problem of great interest to multiple communities. In Gaussian graphical models (GM), graph learning amounts to endowing covariance selection with the Laplacian structure. In graph signal processing (GSP), it is essential to infer the unobserved graph from the outputs of a filtering system. In this paper, we study the problem of learning Cartesian product graphs under Laplacian constraints. The Cartesian graph product is a natural way for modeling higher-order conditional dependencies and is also the key for generalizing GSP to multi-way tensors. We establish statistical consistency for the penalized maximum likelihood estimation (MLE) of a Cartesian product Laplacian, and propose an efficient algorithm to solve the problem. We also extend our method for efficient joint graph learning and imputation in the presence of structural missing values. Experiments on synthetic and real-world datasets demonstrate that our 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#36895;&#26799;&#24230;&#26041;&#27861;&#26469;&#35299;&#20915;&#20855;&#26377;&#20984;&#19979;&#23618;&#38382;&#39064;&#30340;&#31616;&#21333;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#23616;&#37096;&#36924;&#36817;&#19979;&#23618;&#38382;&#39064;&#30340;&#35299;&#38598;&#21644;&#21152;&#36895;&#26799;&#24230;&#26356;&#26032;&#26041;&#27861;&#65292;&#22312;&#26377;&#38480;&#27425;&#36845;&#20195;&#20869;&#25214;&#21040;&#19968;&#20010;&#20855;&#26377;&#19968;&#23450;&#31934;&#24230;&#30340;&#26368;&#20248;&#35299;&#12290;</title><link>https://arxiv.org/abs/2402.08097</link><description>&lt;p&gt;
&#19968;&#31181;&#21152;&#36895;&#26799;&#24230;&#26041;&#27861;&#27714;&#35299;&#20855;&#26377;&#20984;&#19979;&#23618;&#38382;&#39064;&#30340;&#31616;&#21333;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
An Accelerated Gradient Method for Simple Bilevel Optimization with Convex Lower-level Problem
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08097
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#36895;&#26799;&#24230;&#26041;&#27861;&#26469;&#35299;&#20915;&#20855;&#26377;&#20984;&#19979;&#23618;&#38382;&#39064;&#30340;&#31616;&#21333;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#23616;&#37096;&#36924;&#36817;&#19979;&#23618;&#38382;&#39064;&#30340;&#35299;&#38598;&#21644;&#21152;&#36895;&#26799;&#24230;&#26356;&#26032;&#26041;&#27861;&#65292;&#22312;&#26377;&#38480;&#27425;&#36845;&#20195;&#20869;&#25214;&#21040;&#19968;&#20010;&#20855;&#26377;&#19968;&#23450;&#31934;&#24230;&#30340;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#31616;&#21333;&#30340;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#21363;&#22312;&#21478;&#19968;&#20010;&#20984;&#20809;&#28369;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#30340;&#26368;&#20248;&#35299;&#38598;&#19978;&#26368;&#23567;&#21270;&#19968;&#20010;&#20984;&#20809;&#28369;&#30446;&#26631;&#20989;&#25968;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21452;&#23618;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#20999;&#24179;&#38754;&#26041;&#27861;&#23616;&#37096;&#36924;&#36817;&#19979;&#23618;&#38382;&#39064;&#30340;&#35299;&#38598;&#65292;&#24182;&#37319;&#29992;&#21152;&#36895;&#26799;&#24230;&#26356;&#26032;&#26041;&#27861;&#38477;&#20302;&#36817;&#20284;&#35299;&#38598;&#19978;&#30340;&#19978;&#23618;&#30446;&#26631;&#20989;&#25968;&#12290;&#25105;&#20204;&#36890;&#36807;&#23376;&#26368;&#20248;&#35299;&#21644;&#19981;&#21487;&#34892;&#35823;&#24046;&#24230;&#37327;&#25105;&#20204;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#20004;&#20010;&#35823;&#24046;&#26631;&#20934;&#30340;&#38750;&#28176;&#36827;&#25910;&#25947;&#24615;&#20445;&#35777;&#12290;&#29305;&#21035;&#22320;&#65292;&#24403;&#21487;&#34892;&#38598;&#26159;&#32039;&#33268;&#30340;&#26102;&#20505;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#26368;&#22810;&#38656;&#35201;$\mathcal{O}(\max\{1/\sqrt{\epsilon_{f}}, 1/\epsilon_g\})$&#27425;&#36845;&#20195;&#25165;&#33021;&#25214;&#21040;&#19968;&#20010;$\epsilon_f$-&#23376;&#26368;&#20248;&#19988;$\epsilon_g$-&#19981;&#21487;&#34892;&#30340;&#35299;&#12290;&#27492;&#22806;&#65292;&#22312;&#39069;&#22806;&#20551;&#35774;&#19979;&#65292;&#19979;&#23618;&#30446;&#26631;&#28385;&#36275;$r$&#38454;H\"olderian&#35823;&#24046;&#26102;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#35299;&#30340;&#25910;&#25947;&#36895;&#24230;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we focus on simple bilevel optimization problems, where we minimize a convex smooth objective function over the optimal solution set of another convex smooth constrained optimization problem. We present a novel bilevel optimization method that locally approximates the solution set of the lower-level problem using a cutting plane approach and employs an accelerated gradient-based update to reduce the upper-level objective function over the approximated solution set. We measure the performance of our method in terms of suboptimality and infeasibility errors and provide non-asymptotic convergence guarantees for both error criteria. Specifically, when the feasible set is compact, we show that our method requires at most $\mathcal{O}(\max\{1/\sqrt{\epsilon_{f}}, 1/\epsilon_g\})$ iterations to find a solution that is $\epsilon_f$-suboptimal and $\epsilon_g$-infeasible. Moreover, under the additional assumption that the lower-level objective satisfies the $r$-th H\"olderian err
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#22343;&#21248;&#21270;&#30340;&#26041;&#24335;&#30830;&#20999;&#23454;&#29616;&#20102;&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;&#65292;&#30740;&#31350;&#20102;&#20854;&#29702;&#35770;&#24615;&#36136;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#37319;&#26679;&#30340;&#24635;&#21464;&#24046;&#36317;&#31163;&#21644;KL&#25955;&#24230;&#20445;&#35777;&#12290;&#36825;&#19968;&#26041;&#27861;&#22312;&#24314;&#27169;&#31163;&#25955;&#25968;&#25454;&#26041;&#38754;&#20855;&#26377;&#37325;&#35201;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>https://arxiv.org/abs/2402.08095</link><description>&lt;p&gt;
&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;&#30340;&#25910;&#25947;&#20998;&#26512;&#65306;&#36890;&#36807;&#22343;&#21248;&#21270;&#30340;&#30830;&#20999;&#23454;&#29616;
&lt;/p&gt;
&lt;p&gt;
Convergence Analysis of Discrete Diffusion Model: Exact Implementation through Uniformization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08095
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#22343;&#21248;&#21270;&#30340;&#26041;&#24335;&#30830;&#20999;&#23454;&#29616;&#20102;&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;&#65292;&#30740;&#31350;&#20102;&#20854;&#29702;&#35770;&#24615;&#36136;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#37319;&#26679;&#30340;&#24635;&#21464;&#24046;&#36317;&#31163;&#21644;KL&#25955;&#24230;&#20445;&#35777;&#12290;&#36825;&#19968;&#26041;&#27861;&#22312;&#24314;&#27169;&#31163;&#25955;&#25968;&#25454;&#26041;&#38754;&#20855;&#26377;&#37325;&#35201;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#22312;&#25968;&#25454;&#29983;&#25104;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#32463;&#39564;&#25104;&#21151;&#12290;&#26368;&#36817;&#65292;&#19968;&#20123;&#21162;&#21147;&#24050;&#32463;&#34987;&#20570;&#20986;&#26469;&#65292;&#23558;&#25193;&#25955;&#27169;&#22411;&#30340;&#26694;&#26550;&#36866;&#24212;&#21040;&#31163;&#25955;&#29366;&#24577;&#31354;&#38388;&#65292;&#20026;&#24314;&#27169;&#26412;&#36136;&#19978;&#26159;&#31163;&#25955;&#25968;&#25454;&#65288;&#22914;&#35821;&#35328;&#21644;&#22270;&#24418;&#65289;&#25552;&#20379;&#20102;&#19968;&#31181;&#26356;&#33258;&#28982;&#30340;&#26041;&#27861;&#12290;&#36825;&#36890;&#36807;&#23558;&#21069;&#21521;&#22122;&#22768;&#36807;&#31243;&#21644;&#30456;&#24212;&#30340;&#36870;&#36807;&#31243;&#37117;&#26500;&#24314;&#20026;&#36830;&#32493;&#26102;&#38388;&#39532;&#23572;&#21487;&#22827;&#38142;&#65288;CTMC&#65289;&#26469;&#23454;&#29616;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;&#30340;&#29702;&#35770;&#24615;&#36136;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#36830;&#32493;&#39532;&#23572;&#21487;&#22827;&#38142;&#22343;&#21248;&#21270;&#30340;&#31639;&#27861;&#65292;&#22312;&#38543;&#26426;&#26102;&#38388;&#28857;&#19978;&#23454;&#29616;&#36716;&#31227;&#12290;&#22312;&#20851;&#20110;&#31163;&#25955;&#24471;&#20998;&#20989;&#25968;&#23398;&#20064;&#30340;&#21512;&#29702;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#20174;&#36229;&#31435;&#26041;&#20307;&#19978;&#30340;&#20219;&#20309;&#20998;&#24067;&#36827;&#34892;&#37319;&#26679;&#25152;&#38656;&#30340;&#24635;&#21464;&#24046;&#36317;&#31163;&#21644;KL&#25955;&#24230;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#19982;&#22312;$\mathbb{R}^d$&#20013;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#26368;&#26032;&#25104;&#23601;&#30456;&#19968;&#33268;&#65292;&#24182;&#36827;&#19968;&#27493;&#24378;&#35843;&#20102;d&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models have achieved huge empirical success in data generation tasks. Recently, some efforts have been made to adapt the framework of diffusion models to discrete state space, providing a more natural approach for modeling intrinsically discrete data, such as language and graphs. This is achieved by formulating both the forward noising process and the corresponding reversed process as Continuous Time Markov Chains (CTMCs). In this paper, we investigate the theoretical properties of the discrete diffusion model. Specifically, we introduce an algorithm leveraging the uniformization of continuous Markov chains, implementing transitions on random time points. Under reasonable assumptions on the learning of the discrete score function, we derive Total Variation distance and KL divergence guarantees for sampling from any distribution on a hypercube. Our results align with state-of-the-art achievements for diffusion models in $\mathbb{R}^d$ and further underscore the advantages of d
&lt;/p&gt;</description></item><item><title>&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#23398;&#20064;&#19968;&#20010;&#23376;&#39640;&#26031;&#27010;&#29575;&#20998;&#24067;&#26063;&#20013;&#31361;&#30772;&#20102;&#32500;&#25968;&#28798;&#38590;&#65292;&#36890;&#36807;&#20998;&#25968;&#21305;&#37197;&#29983;&#25104;&#30340;&#20998;&#24067;&#20197;&#32500;&#24230;&#26080;&#20851;&#30340;&#36895;&#29575;&#36924;&#36817;&#30446;&#26631;&#20998;&#24067;&#30340;&#24635;&#21464;&#24046;&#12290;</title><link>https://arxiv.org/abs/2402.08082</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#23398;&#20064;&#19968;&#20010;&#23376;&#39640;&#26031;&#27010;&#29575;&#20998;&#24067;&#26063;&#20013;&#31361;&#30772;&#20102;&#32500;&#25968;&#28798;&#38590;
&lt;/p&gt;
&lt;p&gt;
Score-based generative models break the curse of dimensionality in learning a family of sub-Gaussian probability distributions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08082
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#23398;&#20064;&#19968;&#20010;&#23376;&#39640;&#26031;&#27010;&#29575;&#20998;&#24067;&#26063;&#20013;&#31361;&#30772;&#20102;&#32500;&#25968;&#28798;&#38590;&#65292;&#36890;&#36807;&#20998;&#25968;&#21305;&#37197;&#29983;&#25104;&#30340;&#20998;&#24067;&#20197;&#32500;&#24230;&#26080;&#20851;&#30340;&#36895;&#29575;&#36924;&#36817;&#30446;&#26631;&#20998;&#24067;&#30340;&#24635;&#21464;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;SGMs&#65289;&#22312;&#24040;&#22823;&#30340;&#22270;&#20687;&#29983;&#25104;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#65292;&#20294;&#23427;&#20204;&#30340;&#25968;&#23398;&#22522;&#30784;&#20173;&#28982;&#26377;&#38480;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;SGMs&#22312;&#23398;&#20064;&#19968;&#20010;&#23376;&#39640;&#26031;&#27010;&#29575;&#20998;&#24067;&#26063;&#20013;&#30340;&#36817;&#20284;&#21644;&#27867;&#21270;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#20851;&#20110;&#27010;&#29575;&#20998;&#24067;&#22797;&#26434;&#24615;&#30340;&#27010;&#24565;&#65292;&#21363;&#30456;&#23545;&#23494;&#24230;&#19982;&#26631;&#20934;&#39640;&#26031;&#27979;&#24230;&#30340;&#30456;&#23545;&#23494;&#24230;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22914;&#26524;&#23545;&#25968;&#30456;&#23545;&#23494;&#24230;&#21487;&#20197;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#23616;&#37096;&#36924;&#36817;&#65292;&#24182;&#19988;&#32593;&#32476;&#21442;&#25968;&#21487;&#20197;&#36866;&#24403;&#22320;&#21463;&#38480;&#65292;&#37027;&#20040;&#36890;&#36807;&#32463;&#39564;&#20998;&#25968;&#21305;&#37197;&#29983;&#25104;&#30340;&#20998;&#24067;&#20197;&#32500;&#24230;&#26080;&#20851;&#30340;&#36895;&#29575;&#36924;&#36817;&#30446;&#26631;&#20998;&#24067;&#30340;&#24635;&#21464;&#24046;&#12290;&#25105;&#20204;&#36890;&#36807;&#31034;&#20363;&#35828;&#26126;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#20854;&#20013;&#21253;&#25324;&#26576;&#20123;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#12290;&#25105;&#20204;&#35777;&#26126;&#30340;&#19968;&#20010;&#20851;&#38190;&#28857;&#26159;&#25512;&#23548;&#20986;&#19982;&#27491;&#21521;&#36807;&#31243;&#30456;&#20851;&#30340;&#30495;&#23454;&#24471;&#20998;&#20989;&#25968;&#30340;&#32500;&#24230;&#26080;&#20851;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
While score-based generative models (SGMs) have achieved remarkable success in enormous image generation tasks, their mathematical foundations are still limited. In this paper, we analyze the approximation and generalization of SGMs in learning a family of sub-Gaussian probability distributions. We introduce a notion of complexity for probability distributions in terms of their relative density with respect to the standard Gaussian measure. We prove that if the log-relative density can be locally approximated by a neural network whose parameters can be suitably bounded, then the distribution generated by empirical score matching approximates the target distribution in total variation with a dimension-independent rate. We illustrate our theory through examples, which include certain mixtures of Gaussians. An essential ingredient of our proof is to derive a dimension-free deep neural network approximation rate for the true score function associated with the forward process, which is inte
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;&#26680;&#20989;&#25968;&#36827;&#34892;&#21516;&#32986;&#24230;&#37327;&#21305;&#37197;&#30340;&#26041;&#27861;&#65292;&#22312;&#29983;&#25104;&#24314;&#27169;&#20013;&#23454;&#29616;&#20102;&#27010;&#29575;&#27979;&#24230;&#30340;&#20256;&#36755;&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#25968;&#20540;&#23454;&#39564;&#65292;&#26412;&#25991;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#24615;&#33021;&#21644;&#36866;&#29992;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.08077</link><description>&lt;p&gt;
&#20351;&#29992;&#26680;&#20989;&#25968;&#30340;&#21516;&#32986;&#24230;&#37327;&#21305;&#37197;&#22312;&#29983;&#25104;&#24314;&#27169;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Diffeomorphic Measure Matching with Kernels for Generative Modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08077
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;&#26680;&#20989;&#25968;&#36827;&#34892;&#21516;&#32986;&#24230;&#37327;&#21305;&#37197;&#30340;&#26041;&#27861;&#65292;&#22312;&#29983;&#25104;&#24314;&#27169;&#20013;&#23454;&#29616;&#20102;&#27010;&#29575;&#27979;&#24230;&#30340;&#20256;&#36755;&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#25968;&#20540;&#23454;&#39564;&#65292;&#26412;&#25991;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#24615;&#33021;&#21644;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#36890;&#36807;&#26222;&#36890;&#24494;&#20998;&#26041;&#31243;(ODEs)&#21644;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;(RKHSs)&#23454;&#29616;&#27010;&#29575;&#27979;&#24230;&#30340;&#20256;&#36755;&#65292;&#20197;&#36798;&#21040;&#26368;&#23567;&#24046;&#24322;&#30340;&#29983;&#25104;&#24314;&#27169;&#21644;&#37319;&#26679;&#12290;&#35813;&#26694;&#26550;&#21463;&#21516;&#32986;&#21305;&#37197;&#21644;&#22270;&#20687;&#37197;&#20934;&#24605;&#24819;&#30340;&#21551;&#21457;&#12290;&#25991;&#20013;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#65292;&#32473;&#20986;&#20102;&#35813;&#26041;&#27861;&#30340;&#20808;&#39564;&#35823;&#24046;&#30028;&#38480;&#65292;&#35813;&#30028;&#38480;&#19982;&#27169;&#22411;&#30340;&#22797;&#26434;&#24615;&#12289;&#35757;&#32451;&#38598;&#20013;&#26679;&#26412;&#30340;&#25968;&#37327;&#21644;&#27169;&#22411;&#35268;&#33539;&#24615;&#26377;&#20851;&#12290;&#36890;&#36807;&#22823;&#37327;&#30340;&#25968;&#20540;&#23454;&#39564;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#29305;&#24615;&#12289;&#20248;&#21183;&#21644;&#24369;&#28857;&#65292;&#24182;&#25193;&#23637;&#20102;&#20854;&#22312;&#26465;&#20214;&#27169;&#25311;&#21644;&#25512;&#26029;&#31561;&#20854;&#20182;&#20219;&#21153;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article presents a general framework for the transport of probability measures towards minimum divergence generative modeling and sampling using ordinary differential equations (ODEs) and Reproducing Kernel Hilbert Spaces (RKHSs), inspired by ideas from diffeomorphic matching and image registration. A theoretical analysis of the proposed method is presented, giving a priori error bounds in terms of the complexity of the model, the number of samples in the training set, and model misspecification. An extensive suite of numerical experiments further highlights the properties, strengths, and weaknesses of the method and extends its applicability to other tasks, such as conditional simulation and inference.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26368;&#36817;&#37051;&#35780;&#20998;&#20989;&#25968;&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;&#21033;&#29992;&#35757;&#32451;&#38598;&#20013;&#30340;&#22810;&#20010;&#26679;&#26412;&#22823;&#22823;&#38477;&#20302;&#20102;&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#65292;&#21487;&#29992;&#20110;&#35757;&#32451;&#19968;&#33268;&#24615;&#27169;&#22411;&#21644;&#25193;&#25955;&#27169;&#22411;&#65292;&#25552;&#39640;&#25910;&#25947;&#36895;&#24230;&#12289;&#26679;&#26412;&#36136;&#37327;&#65292;&#24182;&#20026;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.08018</link><description>&lt;p&gt;
&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#30340;&#26368;&#36817;&#37051;&#35780;&#20998;&#20272;&#35745;&#22120;
&lt;/p&gt;
&lt;p&gt;
Nearest Neighbour Score Estimators for Diffusion Generative Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08018
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26368;&#36817;&#37051;&#35780;&#20998;&#20989;&#25968;&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;&#21033;&#29992;&#35757;&#32451;&#38598;&#20013;&#30340;&#22810;&#20010;&#26679;&#26412;&#22823;&#22823;&#38477;&#20302;&#20102;&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#65292;&#21487;&#29992;&#20110;&#35757;&#32451;&#19968;&#33268;&#24615;&#27169;&#22411;&#21644;&#25193;&#25955;&#27169;&#22411;&#65292;&#25552;&#39640;&#25910;&#25947;&#36895;&#24230;&#12289;&#26679;&#26412;&#36136;&#37327;&#65292;&#24182;&#20026;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20998;&#20989;&#25968;&#20272;&#35745;&#26159;&#35757;&#32451;&#21644;&#37319;&#26679;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#30340;&#22522;&#30784;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#26368;&#24120;&#29992;&#30340;&#20272;&#35745;&#22120;&#35201;&#20040;&#26159;&#26377;&#20559;&#30340;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#65292;&#35201;&#20040;&#26159;&#22522;&#20110;&#26465;&#20214;&#35780;&#20998;&#30340;&#39640;&#26041;&#24046;&#33945;&#29305;&#21345;&#27931;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#26368;&#36817;&#37051;&#35780;&#20998;&#20989;&#25968;&#20272;&#35745;&#22120;&#65292;&#21033;&#29992;&#35757;&#32451;&#38598;&#20013;&#30340;&#22810;&#20010;&#26679;&#26412;&#22823;&#22823;&#38477;&#20302;&#20102;&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#24341;&#20154;&#27880;&#30446;&#30340;&#24212;&#29992;&#20013;&#21033;&#29992;&#20102;&#20302;&#26041;&#24046;&#20272;&#35745;&#22120;&#12290;&#22312;&#20351;&#29992;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#36827;&#34892;&#35757;&#32451;&#19968;&#33268;&#24615;&#27169;&#22411;&#26102;&#65292;&#25105;&#20204;&#25253;&#21578;&#20102;&#25910;&#25947;&#36895;&#24230;&#21644;&#26679;&#26412;&#36136;&#37327;&#26174;&#33879;&#25552;&#39640;&#12290;&#22312;&#25193;&#25955;&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#21487;&#20197;&#26367;&#20195;&#23398;&#20064;&#32593;&#32476;&#36827;&#34892;&#27010;&#29575;&#27969;ODE&#31215;&#20998;&#65292;&#20026;&#26410;&#26469;&#30740;&#31350;&#24320;&#36767;&#20102;&#26377;&#21069;&#26223;&#30340;&#26032;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score function estimation is the cornerstone of both training and sampling from diffusion generative models. Despite this fact, the most commonly used estimators are either biased neural network approximations or high variance Monte Carlo estimators based on the conditional score. We introduce a novel nearest neighbour score function estimator which utilizes multiple samples from the training set to dramatically decrease estimator variance. We leverage our low variance estimator in two compelling applications. Training consistency models with our estimator, we report a significant increase in both convergence speed and sample quality. In diffusion models, we show that our estimator can replace a learned network for probability-flow ODE integration, opening promising new avenues of future research.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25551;&#36848;&#20102;CNN&#20013;&#21367;&#31215;&#29942;&#39048;&#65288;CBN&#65289;&#32467;&#26500;&#30340;&#20986;&#29616;&#65292;&#32593;&#32476;&#22312;&#21069;&#20960;&#23618;&#23558;&#36755;&#20837;&#34920;&#31034;&#36716;&#25442;&#20026;&#22312;&#23569;&#25968;&#39057;&#29575;&#21644;&#36890;&#36947;&#19978;&#21463;&#25903;&#25345;&#30340;&#34920;&#31034;&#65292;&#28982;&#21518;&#36890;&#36807;&#26368;&#21518;&#20960;&#23618;&#26144;&#23556;&#22238;&#36755;&#20986;&#12290;CBN&#31209;&#23450;&#20041;&#20102;&#20445;&#30041;&#22312;&#29942;&#39048;&#20013;&#30340;&#39057;&#29575;&#30340;&#25968;&#37327;&#21644;&#31867;&#22411;&#65292;&#24182;&#37096;&#20998;&#35777;&#26126;&#20102;&#21442;&#25968;&#33539;&#25968;&#19982;&#28145;&#24230;&#21644;CBN&#31209;&#30340;&#27604;&#20363;&#25104;&#27491;&#27604;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#32593;&#32476;&#30340;&#21442;&#25968;&#33539;&#25968;&#20381;&#36182;&#20110;&#20989;&#25968;&#30340;&#35268;&#21017;&#24615;&#12290;&#25105;&#20204;&#21457;&#29616;&#20219;&#20309;&#20855;&#26377;&#25509;&#36817;&#26368;&#20248;&#21442;&#25968;&#33539;&#25968;&#30340;&#32593;&#32476;&#37117;&#20250;&#23637;&#31034;&#20986;CBN&#32467;&#26500;&#65292;&#36825;&#35299;&#37322;&#20102;&#19979;&#37319;&#26679;&#30340;&#24120;&#35265;&#23454;&#36341;&#65307;&#25105;&#20204;&#36824;&#39564;&#35777;&#20102;CBN&#32467;&#26500;&#22312;&#19979;&#37319;&#26679;&#19979;&#20173;&#28982;&#25104;&#31435;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;CBN&#32467;&#26500;&#26469;&#35299;&#37322;...&#65288;&#25688;&#35201;&#23436;&#25972;&#20869;&#23481;&#35831;&#35265;&#27491;&#25991;&#65289;</title><link>https://arxiv.org/abs/2402.08010</link><description>&lt;p&gt;
CNN&#38656;&#35201;&#21738;&#20123;&#39057;&#29575;&#65311;&#29305;&#24449;&#23398;&#20064;&#20013;&#30340;&#32039;&#24613;&#29942;&#39048;&#32467;&#26500;&#30340;&#20986;&#29616;
&lt;/p&gt;
&lt;p&gt;
Which Frequencies do CNNs Need? Emergent Bottleneck Structure in Feature Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08010
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25551;&#36848;&#20102;CNN&#20013;&#21367;&#31215;&#29942;&#39048;&#65288;CBN&#65289;&#32467;&#26500;&#30340;&#20986;&#29616;&#65292;&#32593;&#32476;&#22312;&#21069;&#20960;&#23618;&#23558;&#36755;&#20837;&#34920;&#31034;&#36716;&#25442;&#20026;&#22312;&#23569;&#25968;&#39057;&#29575;&#21644;&#36890;&#36947;&#19978;&#21463;&#25903;&#25345;&#30340;&#34920;&#31034;&#65292;&#28982;&#21518;&#36890;&#36807;&#26368;&#21518;&#20960;&#23618;&#26144;&#23556;&#22238;&#36755;&#20986;&#12290;CBN&#31209;&#23450;&#20041;&#20102;&#20445;&#30041;&#22312;&#29942;&#39048;&#20013;&#30340;&#39057;&#29575;&#30340;&#25968;&#37327;&#21644;&#31867;&#22411;&#65292;&#24182;&#37096;&#20998;&#35777;&#26126;&#20102;&#21442;&#25968;&#33539;&#25968;&#19982;&#28145;&#24230;&#21644;CBN&#31209;&#30340;&#27604;&#20363;&#25104;&#27491;&#27604;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#32593;&#32476;&#30340;&#21442;&#25968;&#33539;&#25968;&#20381;&#36182;&#20110;&#20989;&#25968;&#30340;&#35268;&#21017;&#24615;&#12290;&#25105;&#20204;&#21457;&#29616;&#20219;&#20309;&#20855;&#26377;&#25509;&#36817;&#26368;&#20248;&#21442;&#25968;&#33539;&#25968;&#30340;&#32593;&#32476;&#37117;&#20250;&#23637;&#31034;&#20986;CBN&#32467;&#26500;&#65292;&#36825;&#35299;&#37322;&#20102;&#19979;&#37319;&#26679;&#30340;&#24120;&#35265;&#23454;&#36341;&#65307;&#25105;&#20204;&#36824;&#39564;&#35777;&#20102;CBN&#32467;&#26500;&#22312;&#19979;&#37319;&#26679;&#19979;&#20173;&#28982;&#25104;&#31435;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;CBN&#32467;&#26500;&#26469;&#35299;&#37322;...&#65288;&#25688;&#35201;&#23436;&#25972;&#20869;&#23481;&#35831;&#35265;&#27491;&#25991;&#65289;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25551;&#36848;&#20102;CNN&#20013;&#21367;&#31215;&#29942;&#39048;&#65288;CBN&#65289;&#32467;&#26500;&#30340;&#20986;&#29616;&#65292;&#32593;&#32476;&#20351;&#29992;&#20854;&#21069;&#20960;&#23618;&#23558;&#36755;&#20837;&#34920;&#31034;&#36716;&#25442;&#20026;&#20165;&#22312;&#20960;&#20010;&#39057;&#29575;&#21644;&#36890;&#36947;&#19978;&#21463;&#25903;&#25345;&#30340;&#34920;&#31034;&#65292;&#28982;&#21518;&#20351;&#29992;&#26368;&#21518;&#20960;&#23618;&#23558;&#20854;&#26144;&#23556;&#22238;&#36755;&#20986;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;CBN&#31209;&#65292;&#25551;&#36848;&#20102;&#20445;&#30041;&#22312;&#29942;&#39048;&#20869;&#30340;&#39057;&#29575;&#30340;&#25968;&#37327;&#21644;&#31867;&#22411;&#65292;&#24182;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#35777;&#26126;&#20102;&#34920;&#31034;&#20989;&#25968;$f$&#25152;&#38656;&#30340;&#21442;&#25968;&#33539;&#25968;&#25353;&#28145;&#24230;&#20056;&#20197;CBN&#31209;$f$&#30340;&#27604;&#20363;&#32553;&#25918;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#21442;&#25968;&#33539;&#25968;&#22312;&#19979;&#19968;&#38454;&#20013;&#20381;&#36182;&#20110;$f$&#30340;&#27491;&#21017;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20219;&#20309;&#20855;&#26377;&#36817;&#20046;&#26368;&#20248;&#21442;&#25968;&#33539;&#25968;&#30340;&#32593;&#32476;&#37117;&#20250;&#22312;&#26435;&#37325;&#21644;&#65288;&#22312;&#32593;&#32476;&#23545;&#22823;&#23398;&#20064;&#29575;&#31283;&#23450;&#30340;&#20551;&#35774;&#19979;&#65289;&#28608;&#27963;&#20013;&#34920;&#29616;&#20986;CBN&#32467;&#26500;&#65292;&#36825;&#20419;&#20351;&#20102;&#19979;&#37319;&#26679;&#30340;&#24120;&#35265;&#20570;&#27861;&#65307;&#24182;&#19988;&#25105;&#20204;&#39564;&#35777;&#20102;CBN&#32467;&#26500;&#22312;&#19979;&#37319;&#26679;&#19979;&#20173;&#28982;&#25104;&#31435;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;CBN&#32467;&#26500;&#26469;&#35299;&#37322;...
&lt;/p&gt;
&lt;p&gt;
We describe the emergence of a Convolution Bottleneck (CBN) structure in CNNs, where the network uses its first few layers to transform the input representation into a representation that is supported only along a few frequencies and channels, before using the last few layers to map back to the outputs. We define the CBN rank, which describes the number and type of frequencies that are kept inside the bottleneck, and partially prove that the parameter norm required to represent a function $f$ scales as depth times the CBN rank $f$. We also show that the parameter norm depends at next order on the regularity of $f$. We show that any network with almost optimal parameter norm will exhibit a CBN structure in both the weights and - under the assumption that the network is stable under large learning rate - the activations, which motivates the common practice of down-sampling; and we verify that the CBN results still hold with down-sampling. Finally we use the CBN structure to interpret the
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;BAM&#36827;&#34892;&#22270;&#32467;&#26500;&#25512;&#26029;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#36890;&#36807;&#21464;&#24418;&#30340;&#32806;&#21512;&#27169;&#25311;&#36755;&#20837;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#65292;&#20165;&#38656;&#36890;&#36807;&#19968;&#27425;&#21069;&#21521;&#20256;&#36882;&#21363;&#21487;&#36827;&#34892;&#25512;&#26029;&#12290;&#36890;&#36807;&#21033;&#29992;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#21644;&#38543;&#26426;&#29983;&#25104;&#30340;&#22810;&#21464;&#37327;&#20999;&#27604;&#38634;&#22827;&#22810;&#39033;&#24335;&#26469;&#27169;&#25311;&#35757;&#32451;&#25968;&#25454;&#65292;&#26041;&#27861;&#33021;&#22815;&#27867;&#21270;&#21040;&#32447;&#24615;&#21644;&#21508;&#31181;&#38750;&#32447;&#24615;&#20381;&#36182;&#20851;&#31995;&#12290;&#24341;&#20837;&#20102;&#21452;&#32447;&#24615;&#27880;&#24847;&#26426;&#21046;&#65288;BAM&#65289;&#26469;&#22788;&#29702;&#20381;&#36182;&#20851;&#31995;&#65292;&#35813;&#26426;&#21046;&#22312;&#36716;&#25442;&#25968;&#25454;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#27700;&#24179;&#19978;&#36816;&#34892;&#65292;&#24182;&#23562;&#37325;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#27969;&#24418;&#30340;&#20960;&#20309;&#29305;&#24615;&#12290;&#23454;&#35777;&#35780;&#20272;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.07735</link><description>&lt;p&gt;
&#29992;BAM&#36827;&#34892;&#22270;&#32467;&#26500;&#25512;&#26029;&#65306;&#24341;&#20837;&#21452;&#32447;&#24615;&#27880;&#24847;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Graph Structure Inference with BAM: Introducing the Bilinear Attention Mechanism
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07735
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;BAM&#36827;&#34892;&#22270;&#32467;&#26500;&#25512;&#26029;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#36890;&#36807;&#21464;&#24418;&#30340;&#32806;&#21512;&#27169;&#25311;&#36755;&#20837;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#65292;&#20165;&#38656;&#36890;&#36807;&#19968;&#27425;&#21069;&#21521;&#20256;&#36882;&#21363;&#21487;&#36827;&#34892;&#25512;&#26029;&#12290;&#36890;&#36807;&#21033;&#29992;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#21644;&#38543;&#26426;&#29983;&#25104;&#30340;&#22810;&#21464;&#37327;&#20999;&#27604;&#38634;&#22827;&#22810;&#39033;&#24335;&#26469;&#27169;&#25311;&#35757;&#32451;&#25968;&#25454;&#65292;&#26041;&#27861;&#33021;&#22815;&#27867;&#21270;&#21040;&#32447;&#24615;&#21644;&#21508;&#31181;&#38750;&#32447;&#24615;&#20381;&#36182;&#20851;&#31995;&#12290;&#24341;&#20837;&#20102;&#21452;&#32447;&#24615;&#27880;&#24847;&#26426;&#21046;&#65288;BAM&#65289;&#26469;&#22788;&#29702;&#20381;&#36182;&#20851;&#31995;&#65292;&#35813;&#26426;&#21046;&#22312;&#36716;&#25442;&#25968;&#25454;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#27700;&#24179;&#19978;&#36816;&#34892;&#65292;&#24182;&#23562;&#37325;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#27969;&#24418;&#30340;&#20960;&#20309;&#29305;&#24615;&#12290;&#23454;&#35777;&#35780;&#20272;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#26816;&#27979;&#25968;&#25454;&#38598;&#20013;&#30340;&#20381;&#36182;&#20851;&#31995;&#26159;&#19968;&#20010;&#26680;&#24515;&#25361;&#25112;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#29992;&#20110;&#30417;&#30563;&#22270;&#32467;&#26500;&#23398;&#20064;&#65292;&#21363;&#23398;&#20064;&#35266;&#27979;&#25968;&#25454;&#21644;&#23427;&#20204;&#30340;&#22522;&#26412;&#20381;&#36182;&#32467;&#26500;&#20043;&#38388;&#30340;&#26144;&#23556;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#21464;&#24418;&#30340;&#32806;&#21512;&#27169;&#25311;&#36755;&#20837;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#65292;&#24182;&#19988;&#20165;&#38656;&#36890;&#36807;&#35757;&#32451;&#32593;&#32476;&#36827;&#34892;&#19968;&#27425;&#21069;&#21521;&#20256;&#36882;&#21363;&#21487;&#36827;&#34892;&#25512;&#26029;&#12290;&#36890;&#36807;&#21033;&#29992;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#38543;&#26426;&#29983;&#25104;&#30340;&#22810;&#21464;&#37327;&#20999;&#27604;&#38634;&#22827;&#22810;&#39033;&#24335;&#26469;&#27169;&#25311;&#35757;&#32451;&#25968;&#25454;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23637;&#31034;&#20102;&#22312;&#32447;&#24615;&#21644;&#21508;&#31181;&#38750;&#32447;&#24615;&#20381;&#36182;&#20851;&#31995;&#20043;&#38388;&#30340;&#24378;&#22823;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#21452;&#32447;&#24615;&#27880;&#24847;&#26426;&#21046;&#65288;BAM&#65289;&#65292;&#29992;&#20110;&#26174;&#24335;&#22788;&#29702;&#20381;&#36182;&#20449;&#24687;&#65292;&#35813;&#26426;&#21046;&#22312;&#36716;&#25442;&#25968;&#25454;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#27700;&#24179;&#19978;&#36816;&#34892;&#65292;&#24182;&#23562;&#37325;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#27969;&#24418;&#30340;&#20960;&#20309;&#29305;&#24615;&#12290;&#23454;&#35777;&#35780;&#20272;&#23637;&#31034;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In statistics and machine learning, detecting dependencies in datasets is a central challenge. We propose a novel neural network model for supervised graph structure learning, i.e., the process of learning a mapping between observational data and their underlying dependence structure. The model is trained with variably shaped and coupled simulated input data and requires only a single forward pass through the trained network for inference. By leveraging structural equation models and employing randomly generated multivariate Chebyshev polynomials for the simulation of training data, our method demonstrates robust generalizability across both linear and various types of non-linear dependencies. We introduce a novel bilinear attention mechanism (BAM) for explicit processing of dependency information, which operates on the level of covariance matrices of transformed data and respects the geometry of the manifold of symmetric positive definite matrices. Empirical evaluation demonstrates th
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#12289;&#19982;&#27169;&#22411;&#26080;&#20851;&#30340;&#26041;&#27861;&#26063;&#65292;&#29992;&#20110;&#26657;&#20934;&#20855;&#26377;&#23616;&#37096;&#35206;&#30422;&#20445;&#35777;&#30340;&#22238;&#24402;&#38382;&#39064;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;&#36825;&#31181;&#26041;&#27861;&#21033;&#29992;&#22238;&#24402;&#26641;&#21644;&#38543;&#26426;&#26862;&#26519;&#35757;&#32451;&#26469;&#21019;&#24314;&#26368;&#31895;&#31961;&#30340;&#29305;&#24449;&#31354;&#38388;&#21010;&#20998;&#65292;&#20197;&#36817;&#20284;&#26465;&#20214;&#35206;&#30422;&#65292;&#25552;&#20379;&#20102;&#20934;&#30830;&#12289;&#24555;&#36895;&#21644;&#33258;&#36866;&#24212;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;</title><link>https://arxiv.org/abs/2402.07357</link><description>&lt;p&gt;
&#22238;&#24402;&#26641;&#29992;&#20110;&#24555;&#36895;&#21644;&#33258;&#36866;&#24212;&#30340;&#39044;&#27979;&#21306;&#38388;
&lt;/p&gt;
&lt;p&gt;
Regression Trees for Fast and Adaptive Prediction Intervals
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07357
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#12289;&#19982;&#27169;&#22411;&#26080;&#20851;&#30340;&#26041;&#27861;&#26063;&#65292;&#29992;&#20110;&#26657;&#20934;&#20855;&#26377;&#23616;&#37096;&#35206;&#30422;&#20445;&#35777;&#30340;&#22238;&#24402;&#38382;&#39064;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;&#36825;&#31181;&#26041;&#27861;&#21033;&#29992;&#22238;&#24402;&#26641;&#21644;&#38543;&#26426;&#26862;&#26519;&#35757;&#32451;&#26469;&#21019;&#24314;&#26368;&#31895;&#31961;&#30340;&#29305;&#24449;&#31354;&#38388;&#21010;&#20998;&#65292;&#20197;&#36817;&#20284;&#26465;&#20214;&#35206;&#30422;&#65292;&#25552;&#20379;&#20102;&#20934;&#30830;&#12289;&#24555;&#36895;&#21644;&#33258;&#36866;&#24212;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#27169;&#22411;&#20250;&#29359;&#38169;&#65292;&#22240;&#27492;&#38656;&#35201;&#37327;&#21270;&#19982;&#20854;&#39044;&#27979;&#30456;&#20851;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#31526;&#21512;&#24615;&#25512;&#26029;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#24378;&#22823;&#30340;&#24037;&#20855;&#65292;&#21487;&#20197;&#22312;&#28857;&#39044;&#27979;&#21608;&#22260;&#21019;&#24314;&#32479;&#35745;&#19978;&#26377;&#25928;&#30340;&#39044;&#27979;&#21306;&#22495;&#65292;&#20294;&#26159;&#23427;&#22312;&#22238;&#24402;&#38382;&#39064;&#19978;&#30340;&#26420;&#32032;&#24212;&#29992;&#20250;&#20135;&#29983;&#38750;&#33258;&#36866;&#24212;&#30340;&#21306;&#22495;&#12290;&#26032;&#30340;&#31526;&#21512;&#24615;&#24471;&#20998;&#65292;&#36890;&#24120;&#20381;&#36182;&#20110;&#20998;&#20301;&#25968;&#22238;&#24402;&#22120;&#25110;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#22120;&#65292;&#26088;&#22312;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#12290;&#34429;&#28982;&#23427;&#20204;&#22312;&#21019;&#24314;&#39044;&#27979;&#24102;&#26041;&#38754;&#24456;&#26377;&#29992;&#65292;&#20294;&#36825;&#20123;&#24471;&#20998;&#19982;&#37327;&#21270;&#20219;&#24847;&#39044;&#27979;&#27169;&#22411;&#21608;&#22260;&#30340;&#19981;&#30830;&#23450;&#24615;&#30340;&#21407;&#22987;&#30446;&#26631;&#33073;&#33410;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#12289;&#19982;&#27169;&#22411;&#26080;&#20851;&#30340;&#26041;&#27861;&#26063;&#65292;&#29992;&#20110;&#26657;&#20934;&#20855;&#26377;&#23616;&#37096;&#35206;&#30422;&#20445;&#35777;&#30340;&#22238;&#24402;&#38382;&#39064;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#22522;&#20110;&#36861;&#27714;&#26368;&#31895;&#31961;&#30340;&#29305;&#24449;&#31354;&#38388;&#21010;&#20998;&#26469;&#36817;&#20284;&#26465;&#20214;&#35206;&#30422;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#31526;&#21512;&#24615;&#24471;&#20998;&#36827;&#34892;&#22238;&#24402;&#26641;&#21644;&#38543;&#26426;&#26862;&#26519;&#30340;&#35757;&#32451;&#26469;&#21019;&#24314;&#36825;&#20010;&#21010;&#20998;&#12290;&#25105;&#20204;&#30340;&#25552;&#35758;&#23558;&#22238;&#24402;&#26641;&#21644;&#38543;&#26426;&#26862;&#26519;&#24212;&#29992;&#20110;&#31526;&#21512;&#24615;&#25512;&#26029;&#30340;&#26032;&#39046;&#22495;&#65292;&#20197;&#25552;&#20379;&#20934;&#30830;&#12289;&#24555;&#36895;&#21644;&#33258;&#36866;&#24212;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
Predictive models make mistakes. Hence, there is a need to quantify the uncertainty associated with their predictions. Conformal inference has emerged as a powerful tool to create statistically valid prediction regions around point predictions, but its naive application to regression problems yields non-adaptive regions. New conformal scores, often relying upon quantile regressors or conditional density estimators, aim to address this limitation. Although they are useful for creating prediction bands, these scores are detached from the original goal of quantifying the uncertainty around an arbitrary predictive model. This paper presents a new, model-agnostic family of methods to calibrate prediction intervals for regression problems with local coverage guarantees. Our approach is based on pursuing the coarsest partition of the feature space that approximates conditional coverage. We create this partition by training regression trees and Random Forests on conformity scores. Our proposal
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#22343;&#22330;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243; (SDE) &#30340;&#31283;&#24577;&#20998;&#24067;&#20013;&#37319;&#26679;&#30340;&#22797;&#26434;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#32806;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#22312;&#22810;&#31181;&#24773;&#20917;&#19979;&#25552;&#20379;&#25913;&#36827;&#30340;&#20445;&#35777;&#65292;&#21253;&#25324;&#22312;&#22343;&#22330;&#21306;&#22495;&#20248;&#21270;&#26576;&#20123;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26356;&#22909;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2402.07355</link><description>&lt;p&gt;
&#20174;&#22343;&#22330;&#31283;&#24577;&#20998;&#24067;&#20013;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Sampling from the Mean-Field Stationary Distribution
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07355
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#22343;&#22330;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243; (SDE) &#30340;&#31283;&#24577;&#20998;&#24067;&#20013;&#37319;&#26679;&#30340;&#22797;&#26434;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#32806;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#22312;&#22810;&#31181;&#24773;&#20917;&#19979;&#25552;&#20379;&#25913;&#36827;&#30340;&#20445;&#35777;&#65292;&#21253;&#25324;&#22312;&#22343;&#22330;&#21306;&#22495;&#20248;&#21270;&#26576;&#20123;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26356;&#22909;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20174;&#22343;&#22330;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243; (SDE) &#30340;&#31283;&#24577;&#20998;&#24067;&#20013;&#37319;&#26679;&#30340;&#22797;&#26434;&#24615;&#65292;&#25110;&#32773;&#31561;&#20215;&#22320;&#65292;&#21363;&#21253;&#21547;&#20132;&#20114;&#39033;&#30340;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#19978;&#30340;&#26368;&#23567;&#21270;&#20989;&#25968;&#30340;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#27934;&#23519;&#26159;&#23558;&#36825;&#20010;&#38382;&#39064;&#30340;&#20004;&#20010;&#20851;&#38190;&#26041;&#38754;&#35299;&#32806;&#65306;(1) &#36890;&#36807;&#26377;&#38480;&#31890;&#23376;&#31995;&#32479;&#36924;&#36817;&#22343;&#22330;SDE&#65292;&#36890;&#36807;&#26102;&#38388;&#22343;&#21248;&#20256;&#25773;&#28151;&#27788;&#65292;&#21644;(2) &#36890;&#36807;&#26631;&#20934;&#23545;&#25968;&#20985;&#25277;&#26679;&#22120;&#20174;&#26377;&#38480;&#31890;&#23376;&#31283;&#24577;&#20998;&#24067;&#20013;&#37319;&#26679;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#27010;&#24565;&#19978;&#26356;&#31616;&#21333;&#65292;&#20854;&#28789;&#27963;&#24615;&#20801;&#35768;&#32467;&#21512;&#29992;&#20110;&#31639;&#27861;&#21644;&#29702;&#35770;&#30340;&#26368;&#26032;&#25216;&#26415;&#12290;&#36825;&#23548;&#33268;&#22312;&#35768;&#22810;&#35774;&#32622;&#20013;&#25552;&#20379;&#20102;&#25913;&#36827;&#30340;&#20445;&#35777;&#65292;&#21253;&#25324;&#22312;&#22343;&#22330;&#21306;&#22495;&#20248;&#21270;&#26576;&#20123;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26356;&#22909;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the complexity of sampling from the stationary distribution of a mean-field SDE, or equivalently, the complexity of minimizing a functional over the space of probability measures which includes an interaction term.   Our main insight is to decouple the two key aspects of this problem: (1) approximation of the mean-field SDE via a finite-particle system, via uniform-in-time propagation of chaos, and (2) sampling from the finite-particle stationary distribution, via standard log-concave samplers. Our approach is conceptually simpler and its flexibility allows for incorporating the state-of-the-art for both algorithms and theory. This leads to improved guarantees in numerous settings, including better guarantees for optimizing certain two-layer neural networks in the mean-field regime.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;HyperBERT&#27169;&#22411;&#65292;&#36890;&#36807;&#22312;&#39044;&#35757;&#32451;&#30340;BERT&#27169;&#22411;&#20013;&#24341;&#20837;&#36229;&#22270;&#24863;&#30693;&#23618;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#26041;&#27861;&#22312;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#19978;&#38590;&#20197;&#25429;&#25417;&#36229;&#22270;&#32467;&#26500;&#20449;&#24687;&#21644;&#25991;&#26412;&#23646;&#24615;&#30340;&#23616;&#38480;&#24615;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#25928;&#26524;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.07309</link><description>&lt;p&gt;
HyperBERT:&#23558;&#28151;&#21512;&#36229;&#22270;&#24863;&#30693;&#23618;&#19982;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#25991;&#26412;&#23646;&#24615;&#36229;&#22270;&#19978;&#30340;&#33410;&#28857;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
HyperBERT: Mixing Hypergraph-Aware Layers with Language Models for Node Classification on Text-Attributed Hypergraphs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07309
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;HyperBERT&#27169;&#22411;&#65292;&#36890;&#36807;&#22312;&#39044;&#35757;&#32451;&#30340;BERT&#27169;&#22411;&#20013;&#24341;&#20837;&#36229;&#22270;&#24863;&#30693;&#23618;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#26041;&#27861;&#22312;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#19978;&#38590;&#20197;&#25429;&#25417;&#36229;&#22270;&#32467;&#26500;&#20449;&#24687;&#21644;&#25991;&#26412;&#23646;&#24615;&#30340;&#23616;&#38480;&#24615;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#25928;&#26524;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36229;&#22270;&#36890;&#36807;&#22797;&#26434;&#30340;&#25299;&#25169;&#32467;&#26500;&#26631;&#35760;&#65292;&#34920;&#36798;&#22810;&#20010;&#23454;&#20307;&#20043;&#38388;&#30340;&#39640;&#38454;&#30456;&#20114;&#20316;&#29992;&#65292;&#20854;&#20013;&#36229;&#36793;&#25198;&#28436;&#37325;&#35201;&#35282;&#33394;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#36229;&#22270;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#22312;&#23398;&#20064;&#25991;&#26412;&#23646;&#24615;&#36229;&#22270;&#19978;&#30340;&#33410;&#28857;&#20998;&#31867;&#38382;&#39064;&#20013;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#30740;&#31350;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#24448;&#24448;&#38590;&#20197;&#21516;&#26102;&#25429;&#25417;&#36229;&#22270;&#32467;&#26500;&#20449;&#24687;&#30340;&#20840;&#37096;&#20869;&#23481;&#21644;&#33410;&#28857;&#23646;&#24615;&#20013;&#30340;&#20016;&#23500;&#35821;&#35328;&#23646;&#24615;&#65292;&#36825;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#24433;&#21709;&#20102;&#23427;&#20204;&#30340;&#25928;&#26524;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#22914;&#20309;&#36890;&#36807;&#20026;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#36827;&#19968;&#27493;&#22686;&#24378;&#39044;&#35757;&#32451;&#30340;BERT&#27169;&#22411;&#65292;&#24341;&#20837;&#19987;&#38376;&#30340;&#36229;&#22270;&#24863;&#30693;&#23618;&#12290;&#36825;&#20123;&#23618;&#23558;&#39640;&#38454;&#32467;&#26500;&#24402;&#32435;&#20559;&#24046;&#24341;&#20837;&#35821;&#35328;&#27169;&#22411;&#20013;&#65292;&#20174;&#32780;&#25552;&#39640;&#27169;&#22411;&#21033;&#29992;&#36229;&#22270;&#32467;&#26500;&#20013;&#30340;&#39640;&#38454;&#19978;&#19979;&#25991;&#20449;&#24687;&#21644;&#25991;&#26412;&#20013;&#30340;&#35821;&#20041;&#20449;&#24687;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hypergraphs are marked by complex topology, expressing higher-order interactions among multiple entities with hyperedges. Lately, hypergraph-based deep learning methods to learn informative data representations for the problem of node classification on text-attributed hypergraphs have garnered increasing research attention. However, existing methods struggle to simultaneously capture the full extent of hypergraph structural information and the rich linguistic attributes inherent in the nodes attributes, which largely hampers their effectiveness and generalizability. To overcome these challenges, we explore ways to further augment a pretrained BERT model with specialized hypergraph-aware layers for the task of node classification. Such layers introduce higher-order structural inductive bias into the language model, thus improving the model's capacity to harness both higher-order context information from the hypergraph structure and semantic information present in text. In this paper, we
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#20013;&#36827;&#34892;&#24555;&#36895;&#38543;&#26426;&#37319;&#26679;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#20998;&#35010;&#31215;&#20998;&#22120;&#36827;&#34892;&#21407;&#21017;&#24615;&#20462;&#25913;&#65292;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#37319;&#26679;&#25928;&#29575;&#12290;&#22312;CIFAR-10&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;100&#27425;&#32593;&#32476;&#20989;&#25968;&#35780;&#20272;&#19979;&#30340;FID&#20998;&#25968;&#20026;2.36&#12290;</title><link>https://arxiv.org/abs/2402.07211</link><description>&lt;p&gt;
&#38754;&#21521;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#30340;&#24555;&#36895;&#38543;&#26426;&#37319;&#26679;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Towards Fast Stochastic Sampling in Diffusion Generative Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07211
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#20013;&#36827;&#34892;&#24555;&#36895;&#38543;&#26426;&#37319;&#26679;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#20998;&#35010;&#31215;&#20998;&#22120;&#36827;&#34892;&#21407;&#21017;&#24615;&#20462;&#25913;&#65292;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#37319;&#26679;&#25928;&#29575;&#12290;&#22312;CIFAR-10&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;100&#27425;&#32593;&#32476;&#20989;&#25968;&#35780;&#20272;&#19979;&#30340;FID&#20998;&#25968;&#20026;2.36&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#22312;&#25512;&#29702;&#26102;&#29983;&#25104;&#26679;&#26412;&#30340;&#36895;&#24230;&#36739;&#24930;&#12290;&#23613;&#31649;&#26368;&#36817;&#26377;&#19968;&#20123;&#21162;&#21147;&#22312;&#25913;&#21892;&#25193;&#25955;&#27169;&#22411;&#30340;&#38543;&#26426;&#37319;&#26679;&#25928;&#29575;&#65292;&#20294;&#20173;&#28982;&#26377;&#24453;&#25913;&#36827;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#20998;&#35010;&#31215;&#20998;&#22120;&#30340;&#39044;&#35757;&#32451;&#25193;&#25955;&#27169;&#22411;&#30340;&#24555;&#36895;&#38543;&#26426;&#37319;&#26679;&#26041;&#27861;&#12290;&#20998;&#35010;&#31215;&#20998;&#22120;&#36890;&#24120;&#22312;&#20998;&#23376;&#21160;&#21147;&#23398;&#20013;&#20351;&#29992;&#65292;&#36890;&#36807;&#24039;&#22937;&#22320;&#22312;&#28041;&#21450;&#25968;&#25454;&#12289;&#36741;&#21161;&#25110;&#22122;&#22768;&#21464;&#37327;&#30340;&#25968;&#20540;&#26356;&#26032;&#20043;&#38388;&#20132;&#26367;&#26469;&#25552;&#39640;&#37319;&#26679;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#23545;&#20110;&#24555;&#36895;&#37319;&#26679;&#65292;&#31616;&#21333;&#24212;&#29992;&#20998;&#35010;&#31215;&#20998;&#22120;&#26159;&#27425;&#20248;&#30340;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#31181;&#21407;&#21017;&#19978;&#20462;&#25913;&#20102;&#31616;&#21333;&#20998;&#35010;&#37319;&#26679;&#22120;&#20197;&#25552;&#39640;&#37319;&#26679;&#25928;&#29575;&#30340;&#26041;&#27861;&#65292;&#24182;&#23558;&#24471;&#21040;&#30340;&#37319;&#26679;&#22120;&#31216;&#20026;&#20943;&#23567;&#20998;&#35010;&#31215;&#20998;&#22120;&#12290;&#22312;CIFAR-10&#25968;&#25454;&#38598;&#19978;&#20351;&#29992;&#30456;&#31354;&#38388;&#26391;&#20043;&#19975;&#25193;&#25955; (PSLD) [Pandey \&amp; Mandt, 2023] &#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#30340;&#38543;&#26426;&#37319;&#26679;&#22120;&#22312;&#20165;&#36827;&#34892;100&#27425;&#32593;&#32476;&#20989;&#25968;&#35780;&#20272;&#21518;&#65292;&#23454;&#29616;&#20102;2.36&#30340;FID&#20998;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models suffer from slow sample generation at inference time. Despite recent efforts, improving the sampling efficiency of stochastic samplers for diffusion models remains a promising direction. We propose Splitting Integrators for fast stochastic sampling in pre-trained diffusion models in augmented spaces. Commonly used in molecular dynamics, splitting-based integrators attempt to improve sampling efficiency by cleverly alternating between numerical updates involving the data, auxiliary, or noise variables. However, we show that a naive application of splitting integrators is sub-optimal for fast sampling. Consequently, we propose several principled modifications to naive splitting samplers for improving sampling efficiency and denote the resulting samplers as Reduced Splitting Integrators. In the context of Phase Space Langevin Diffusion (PSLD) [Pandey \&amp; Mandt, 2023] on CIFAR-10, our stochastic sampler achieves an FID score of 2.36 in only 100 network function evaluations 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#35757;&#32451;&#25193;&#25955;&#27169;&#22411;&#20197;&#20174;&#32473;&#23450;&#20998;&#24067;&#20013;&#37319;&#26679;&#30340;&#38382;&#39064;&#65292;&#24182;&#38024;&#23545;&#38543;&#26426;&#25511;&#21046;&#21644;&#37319;&#26679;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25506;&#32034;&#31574;&#30053;&#65292;&#36890;&#36807;&#22522;&#20934;&#27979;&#35797;&#27604;&#36739;&#20102;&#19981;&#21516;&#25512;&#26029;&#26041;&#27861;&#30340;&#30456;&#23545;&#20248;&#21155;&#65292;&#24182;&#23545;&#36807;&#21435;&#30340;&#24037;&#20316;&#25552;&#20986;&#20102;&#36136;&#30097;&#12290;</title><link>https://arxiv.org/abs/2402.05098</link><description>&lt;p&gt;
&#20851;&#20110;&#20998;&#25955;&#25512;&#26029;&#27169;&#22411;&#30340;&#25193;&#25955;&#27169;&#22411;&#65306;&#22522;&#20934;&#27979;&#35797;&#21644;&#25913;&#36827;&#38543;&#26426;&#25511;&#21046;&#21644;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
On diffusion models for amortized inference: Benchmarking and improving stochastic control and sampling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05098
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#35757;&#32451;&#25193;&#25955;&#27169;&#22411;&#20197;&#20174;&#32473;&#23450;&#20998;&#24067;&#20013;&#37319;&#26679;&#30340;&#38382;&#39064;&#65292;&#24182;&#38024;&#23545;&#38543;&#26426;&#25511;&#21046;&#21644;&#37319;&#26679;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25506;&#32034;&#31574;&#30053;&#65292;&#36890;&#36807;&#22522;&#20934;&#27979;&#35797;&#27604;&#36739;&#20102;&#19981;&#21516;&#25512;&#26029;&#26041;&#27861;&#30340;&#30456;&#23545;&#20248;&#21155;&#65292;&#24182;&#23545;&#36807;&#21435;&#30340;&#24037;&#20316;&#25552;&#20986;&#20102;&#36136;&#30097;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#35757;&#32451;&#25193;&#25955;&#27169;&#22411;&#20197;&#20174;&#32473;&#23450;&#30340;&#38750;&#26631;&#20934;&#21270;&#23494;&#24230;&#25110;&#33021;&#37327;&#20989;&#25968;&#20998;&#24067;&#20013;&#37319;&#26679;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#23545;&#20960;&#31181;&#25193;&#25955;&#32467;&#26500;&#25512;&#26029;&#26041;&#27861;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#65292;&#21253;&#25324;&#22522;&#20110;&#27169;&#25311;&#30340;&#21464;&#20998;&#26041;&#27861;&#21644;&#31163;&#31574;&#30053;&#26041;&#27861;&#65288;&#36830;&#32493;&#29983;&#25104;&#27969;&#32593;&#32476;&#65289;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25581;&#31034;&#20102;&#29616;&#26377;&#31639;&#27861;&#30340;&#30456;&#23545;&#20248;&#21183;&#65292;&#21516;&#26102;&#23545;&#36807;&#21435;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20123;&#36136;&#30097;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31163;&#31574;&#30053;&#26041;&#27861;&#25506;&#32034;&#31574;&#30053;&#65292;&#22522;&#20110;&#30446;&#26631;&#31354;&#38388;&#20013;&#30340;&#23616;&#37096;&#25628;&#32034;&#21644;&#22238;&#25918;&#32531;&#20914;&#21306;&#30340;&#20351;&#29992;&#65292;&#24182;&#35777;&#26126;&#23427;&#21487;&#20197;&#25913;&#21892;&#21508;&#31181;&#30446;&#26631;&#20998;&#24067;&#19978;&#30340;&#26679;&#26412;&#36136;&#37327;&#12290;&#25105;&#20204;&#30740;&#31350;&#30340;&#37319;&#26679;&#26041;&#27861;&#21644;&#22522;&#20934;&#27979;&#35797;&#30340;&#20195;&#30721;&#24050;&#20844;&#24320;&#22312;https://github.com/GFNOrg/gfn-diffusion&#65292;&#20316;&#20026;&#26410;&#26469;&#22312;&#20998;&#25955;&#25512;&#26029;&#27169;&#22411;&#19978;&#24037;&#20316;&#30340;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of training diffusion models to sample from a distribution with a given unnormalized density or energy function. We benchmark several diffusion-structured inference methods, including simulation-based variational approaches and off-policy methods (continuous generative flow networks). Our results shed light on the relative advantages of existing algorithms while bringing into question some claims from past work. We also propose a novel exploration strategy for off-policy methods, based on local search in the target space with the use of a replay buffer, and show that it improves the quality of samples on a variety of target distributions. Our code for the sampling methods and benchmarks studied is made public at https://github.com/GFNOrg/gfn-diffusion as a base for future work on diffusion models for amortized inference.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22312;&#19968;&#33324;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#23398;&#20064;&#31639;&#23376;&#65292;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#30446;&#26631;&#31639;&#23376;&#30340;&#35268;&#21017;&#26465;&#20214;&#65292;&#24182;&#24314;&#31435;&#20102;SGD&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#19978;&#30028;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#23545;&#20110;&#38750;&#32447;&#24615;&#31639;&#23376;&#23398;&#20064;&#30340;&#26377;&#25928;&#24615;&#21450;&#32447;&#24615;&#36817;&#20284;&#25910;&#25947;&#29305;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.04691</link><description>&lt;p&gt;
&#22312;&#19968;&#33324;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#31639;&#23376;
&lt;/p&gt;
&lt;p&gt;
Learning Operators with Stochastic Gradient Descent in General Hilbert Spaces
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04691
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#19968;&#33324;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#23398;&#20064;&#31639;&#23376;&#65292;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#30446;&#26631;&#31639;&#23376;&#30340;&#35268;&#21017;&#26465;&#20214;&#65292;&#24182;&#24314;&#31435;&#20102;SGD&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#19978;&#30028;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#23545;&#20110;&#38750;&#32447;&#24615;&#31639;&#23376;&#23398;&#20064;&#30340;&#26377;&#25928;&#24615;&#21450;&#32447;&#24615;&#36817;&#20284;&#25910;&#25947;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#21033;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#22312;&#19968;&#33324;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#23398;&#20064;&#31639;&#23376;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#38024;&#23545;&#30446;&#26631;&#31639;&#23376;&#30340;&#24369;&#21644;&#24378;&#35268;&#21017;&#26465;&#20214;&#65292;&#20197;&#25551;&#36848;&#20854;&#20869;&#22312;&#32467;&#26500;&#21644;&#22797;&#26434;&#24615;&#12290;&#22312;&#36825;&#20123;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;SGD&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#30340;&#19978;&#30028;&#65292;&#24182;&#36827;&#34892;&#20102;&#26497;&#23567;&#20540;&#19979;&#30028;&#20998;&#26512;&#65292;&#36827;&#19968;&#27493;&#35828;&#26126;&#25105;&#20204;&#30340;&#25910;&#25947;&#20998;&#26512;&#21644;&#35268;&#21017;&#26465;&#20214;&#23450;&#37327;&#22320;&#21051;&#30011;&#20102;&#20351;&#29992;SGD&#31639;&#27861;&#35299;&#20915;&#31639;&#23376;&#23398;&#20064;&#38382;&#39064;&#30340;&#21487;&#34892;&#24615;&#12290;&#20540;&#24471;&#24378;&#35843;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#25910;&#25947;&#20998;&#26512;&#23545;&#20110;&#38750;&#32447;&#24615;&#31639;&#23376;&#23398;&#20064;&#20173;&#28982;&#26377;&#25928;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;SGD&#20272;&#35745;&#22120;&#23558;&#25910;&#25947;&#20110;&#38750;&#32447;&#24615;&#30446;&#26631;&#31639;&#23376;&#30340;&#26368;&#20339;&#32447;&#24615;&#36817;&#20284;&#12290;&#27492;&#22806;&#65292;&#23558;&#25105;&#20204;&#30340;&#20998;&#26512;&#24212;&#29992;&#20110;&#22522;&#20110;&#30690;&#37327;&#20540;&#21644;&#23454;&#20540;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;&#31639;&#23376;&#23398;&#20064;&#38382;&#39064;&#65292;&#20135;&#29983;&#20102;&#26032;&#30340;&#25910;&#25947;&#32467;&#26524;&#65292;&#20174;&#32780;&#23436;&#21892;&#20102;&#29616;&#26377;&#25991;&#29486;&#30340;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study investigates leveraging stochastic gradient descent (SGD) to learn operators between general Hilbert spaces. We propose weak and strong regularity conditions for the target operator to depict its intrinsic structure and complexity. Under these conditions, we establish upper bounds for convergence rates of the SGD algorithm and conduct a minimax lower bound analysis, further illustrating that our convergence analysis and regularity conditions quantitatively characterize the tractability of solving operator learning problems using the SGD algorithm. It is crucial to highlight that our convergence analysis is still valid for nonlinear operator learning. We show that the SGD estimator will converge to the best linear approximation of the nonlinear target operator. Moreover, applying our analysis to operator learning problems based on vector-valued and real-valued reproducing kernel Hilbert spaces yields new convergence results, thereby refining the conclusions of existing litera
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#35757;&#32451;&#21152;&#24615;&#27169;&#22411;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#20869;&#23384;&#23384;&#20648;&#21644;&#35745;&#31639;&#35201;&#27714;&#12290;&#22312;&#35268;&#33539;&#24456;&#22909;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#20180;&#32454;&#36873;&#25321;&#23398;&#20064;&#29575;&#65292;&#21487;&#20197;&#23454;&#29616;&#26368;&#23567;&#21644;&#26368;&#20248;&#30340;&#39118;&#38505;&#12290;</title><link>https://arxiv.org/abs/2401.00691</link><description>&lt;p&gt;
&#28155;&#21152;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;
&lt;/p&gt;
&lt;p&gt;
Stochastic Gradient Descent for Additive Nonparametric Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.00691
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#35757;&#32451;&#21152;&#24615;&#27169;&#22411;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#20869;&#23384;&#23384;&#20648;&#21644;&#35745;&#31639;&#35201;&#27714;&#12290;&#22312;&#35268;&#33539;&#24456;&#22909;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#20180;&#32454;&#36873;&#25321;&#23398;&#20064;&#29575;&#65292;&#21487;&#20197;&#23454;&#29616;&#26368;&#23567;&#21644;&#26368;&#20248;&#30340;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#35757;&#32451;&#21152;&#24615;&#27169;&#22411;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20855;&#26377;&#33391;&#22909;&#30340;&#20869;&#23384;&#23384;&#20648;&#21644;&#35745;&#31639;&#35201;&#27714;&#12290;&#35813;&#31639;&#27861;&#21487;&#20197;&#30475;&#20316;&#26159;&#23545;&#32452;&#20214;&#20989;&#25968;&#30340;&#25130;&#26029;&#22522;&#25193;&#23637;&#30340;&#31995;&#25968;&#24212;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#20989;&#25968;&#23545;&#24212;&#29289;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#24471;&#21040;&#30340;&#20272;&#35745;&#37327;&#28385;&#36275;&#19968;&#20010;&#22885;&#25289;&#20811;&#19981;&#31561;&#24335;&#65292;&#20801;&#35768;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#12290;&#22312;&#35268;&#33539;&#24456;&#22909;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#22312;&#35757;&#32451;&#30340;&#19977;&#20010;&#19981;&#21516;&#38454;&#27573;&#20180;&#32454;&#36873;&#25321;&#23398;&#20064;&#29575;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20854;&#39118;&#38505;&#22312;&#25968;&#25454;&#32500;&#24230;&#21644;&#35757;&#32451;&#26679;&#26412;&#22823;&#23567;&#30340;&#20381;&#36182;&#26041;&#38754;&#26159;&#26368;&#23567;&#21644;&#26368;&#20248;&#30340;&#12290;&#36890;&#36807;&#22312;&#20004;&#20010;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#23558;&#35813;&#26041;&#27861;&#19982;&#20256;&#32479;&#30340;&#21453;&#21521;&#25311;&#21512;&#36827;&#34892;&#27604;&#36739;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35828;&#26126;&#20102;&#35745;&#31639;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces an iterative algorithm for training additive models that enjoys favorable memory storage and computational requirements. The algorithm can be viewed as the functional counterpart of stochastic gradient descent, applied to the coefficients of a truncated basis expansion of the component functions. We show that the resulting estimator satisfies an oracle inequality that allows for model mis-specification. In the well-specified setting, by choosing the learning rate carefully across three distinct stages of training, we demonstrate that its risk is minimax optimal in terms of the dependence on the dimensionality of the data and the size of the training sample. We further illustrate the computational benefits by comparing the approach with traditional backfitting on two real-world datasets.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20379;&#20102;&#39318;&#20010;&#38024;&#23545;&#39044;&#35757;&#32451;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#38750;&#24179;&#20961;&#27867;&#21270;&#30028;&#38480;&#65292;&#34920;&#26126;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#21457;&#29616;&#36866;&#29992;&#20110;&#26410;&#35265;&#25968;&#25454;&#30340;&#35268;&#24459;&#24615;&#12290;&#24314;&#31435;&#20102;&#26377;&#25928;&#30340;&#21387;&#32553;&#30028;&#38480;&#65292;&#35777;&#26126;&#36739;&#22823;&#30340;&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#27867;&#21270;&#30028;&#38480;&#24182;&#26356;&#26131;&#21387;&#32553;&#12290;</title><link>https://arxiv.org/abs/2312.17173</link><description>&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#38750;&#24179;&#20961;&#27867;&#21270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Non-Vacuous Generalization Bounds for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.17173
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20379;&#20102;&#39318;&#20010;&#38024;&#23545;&#39044;&#35757;&#32451;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#38750;&#24179;&#20961;&#27867;&#21270;&#30028;&#38480;&#65292;&#34920;&#26126;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#21457;&#29616;&#36866;&#29992;&#20110;&#26410;&#35265;&#25968;&#25454;&#30340;&#35268;&#24459;&#24615;&#12290;&#24314;&#31435;&#20102;&#26377;&#25928;&#30340;&#21387;&#32553;&#30028;&#38480;&#65292;&#35777;&#26126;&#36739;&#22823;&#30340;&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#27867;&#21270;&#30028;&#38480;&#24182;&#26356;&#26131;&#21387;&#32553;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#21253;&#21547;&#25968;&#21313;&#20159;&#20010;&#21442;&#25968;&#65292;&#36825;&#24341;&#21457;&#20102;&#19968;&#20010;&#38382;&#39064;&#65292;&#23427;&#20204;&#26159;&#21542;&#21487;&#20197;&#22312;&#35757;&#32451;&#25968;&#25454;&#20043;&#22806;&#36827;&#34892;&#27867;&#21270;&#65292;&#25110;&#32773;&#21482;&#26159;&#37325;&#22797;&#23427;&#20204;&#30340;&#35757;&#32451;&#35821;&#26009;&#24211;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#39318;&#20010;&#38024;&#23545;&#39044;&#35757;&#32451;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#38750;&#24179;&#20961;&#27867;&#21270;&#30028;&#38480;&#65292;&#34920;&#26126;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#21457;&#29616;&#36866;&#29992;&#20110;&#26410;&#35265;&#25968;&#25454;&#30340;&#35268;&#24459;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20351;&#29992;&#39044;&#27979;&#24179;&#28369;&#23548;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#26080;&#30028;&#23545;&#25968;&#20284;&#28982;&#25439;&#22833;&#30340;&#21387;&#32553;&#30028;&#38480;&#65292;&#24182;&#19988;&#25105;&#20204;&#25193;&#23637;&#20102;&#35813;&#30028;&#38480;&#20197;&#22788;&#29702;&#23376;&#37319;&#26679;&#65292;&#21152;&#36895;&#23545;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#30340;&#30028;&#38480;&#35745;&#31639;&#12290;&#20026;&#20102;&#23454;&#29616;&#38750;&#24179;&#20961;&#27867;&#21270;&#30028;&#38480;&#25152;&#38656;&#30340;&#26497;&#31471;&#21387;&#32553;&#31243;&#24230;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;SubLoRA&#65292;&#36825;&#26159;&#19968;&#31181;&#20302;&#32500;&#38750;&#32447;&#24615;&#21442;&#25968;&#21270;&#26041;&#27861;&#12290;&#20351;&#29992;&#36825;&#31181;&#26041;&#27861;&#65292;&#25105;&#20204;&#21457;&#29616;&#36739;&#22823;&#30340;&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#19988;&#27604;&#36739;&#23567;&#30340;&#27169;&#22411;&#26356;&#26131;&#21387;&#32553;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern language models can contain billions of parameters, raising the question of whether they can generalize beyond the training data or simply regurgitate their training corpora. We provide the first non-vacuous generalization bounds for pretrained large language models (LLMs), indicating that language models are capable of discovering regularities that generalize to unseen data. In particular, we derive a compression bound that is valid for the unbounded log-likelihood loss using prediction smoothing, and we extend the bound to handle subsampling, accelerating bound computation on massive datasets. To achieve the extreme level of compression required for non-vacuous generalization bounds, we devise SubLoRA, a low-dimensional non-linear parameterization. Using this approach, we find that larger models have better generalization bounds and are more compressible than smaller models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Bagged Regularized $k$-Distances for Anomaly Detection (BRDAD)&#30340;&#22522;&#20110;&#36317;&#31163;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#23558;&#38750;&#30417;&#30563;&#24322;&#24120;&#26816;&#27979;&#38382;&#39064;&#36716;&#21270;&#20026;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#25104;&#21151;&#35299;&#20915;&#20102;&#22522;&#20110;&#36317;&#31163;&#31639;&#27861;&#20013;&#36229;&#21442;&#25968;&#36873;&#25321;&#30340;&#25935;&#24863;&#24615;&#25361;&#25112;&#65292;&#24182;&#36890;&#36807;&#21253;&#38598;&#25104;&#26041;&#27861;&#35299;&#20915;&#20102;&#22788;&#29702;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#26102;&#30340;&#25928;&#29575;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2312.01046</link><description>&lt;p&gt;
Bagged Regularized $k$-Distances&#29992;&#20110;&#24322;&#24120;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Bagged Regularized $k$-Distances for Anomaly Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.01046
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Bagged Regularized $k$-Distances for Anomaly Detection (BRDAD)&#30340;&#22522;&#20110;&#36317;&#31163;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#23558;&#38750;&#30417;&#30563;&#24322;&#24120;&#26816;&#27979;&#38382;&#39064;&#36716;&#21270;&#20026;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#25104;&#21151;&#35299;&#20915;&#20102;&#22522;&#20110;&#36317;&#31163;&#31639;&#27861;&#20013;&#36229;&#21442;&#25968;&#36873;&#25321;&#30340;&#25935;&#24863;&#24615;&#25361;&#25112;&#65292;&#24182;&#36890;&#36807;&#21253;&#38598;&#25104;&#26041;&#27861;&#35299;&#20915;&#20102;&#22788;&#29702;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#26102;&#30340;&#25928;&#29575;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#38750;&#30417;&#30563;&#24322;&#24120;&#26816;&#27979;&#30340;&#33539;&#24335;&#65292;&#21363;&#22312;&#27809;&#26377;&#26631;&#35760;&#30340;&#24773;&#20917;&#19979;&#35782;&#21035;&#25968;&#25454;&#38598;&#20013;&#30340;&#24322;&#24120;&#20540;&#12290;&#23613;&#31649;&#22522;&#20110;&#36317;&#31163;&#30340;&#26041;&#27861;&#23545;&#20110;&#38750;&#30417;&#30563;&#24322;&#24120;&#26816;&#27979;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#65292;&#20294;&#23427;&#20204;&#23545;&#26368;&#36817;&#37051;&#25968;&#37327;&#30340;&#36873;&#25321;&#38750;&#24120;&#25935;&#24863;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#36317;&#31163;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;Bagged Regularized $k$-Distances for Anomaly Detection (BRDAD)&#65292;&#23558;&#38750;&#30417;&#30563;&#24322;&#24120;&#26816;&#27979;&#38382;&#39064;&#36716;&#21270;&#20026;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;BRDAD&#31639;&#27861;&#36890;&#36807;&#26368;&#23567;&#21270;&#26367;&#20195;&#39118;&#38505;&#65288;&#21363;&#32463;&#39564;&#39118;&#38505;&#30340;&#26377;&#38480;&#26679;&#26412;&#19978;&#30028;&#65289;&#26469;&#36873;&#25321;&#26435;&#37325;&#65292;&#20197;&#29992;&#20110;&#23494;&#24230;&#20272;&#35745;&#30340;&#24102;&#26435;&#37325;&#30340;$k$-distances&#12290;&#36825;&#31181;&#26041;&#27861;&#25104;&#21151;&#35299;&#20915;&#20102;&#22522;&#20110;&#36317;&#31163;&#31639;&#27861;&#20013;&#36229;&#21442;&#25968;&#36873;&#25321;&#30340;&#25935;&#24863;&#24615;&#25361;&#25112;&#12290;&#27492;&#22806;&#65292;&#22312;&#22788;&#29702;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#26102;&#65292;&#25105;&#20204;&#36824;&#21487;&#20197;&#36890;&#36807;&#21253;&#38598;&#25104;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#25928;&#29575;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the paradigm of unsupervised anomaly detection, which involves the identification of anomalies within a dataset in the absence of labeled examples. Though distance-based methods are top-performing for unsupervised anomaly detection, they suffer heavily from the sensitivity to the choice of the number of the nearest neighbors. In this paper, we propose a new distance-based algorithm called bagged regularized $k$-distances for anomaly detection (BRDAD) converting the unsupervised anomaly detection problem into a convex optimization problem. Our BRDAD algorithm selects the weights by minimizing the surrogate risk, i.e., the finite sample bound of the empirical risk of the bagged weighted $k$-distances for density estimation (BWDDE). This approach enables us to successfully address the sensitivity challenge of the hyperparameter choice in distance-based algorithms. Moreover, when dealing with large-scale datasets, the efficiency issues can be addressed by the incorporated baggi
&lt;/p&gt;</description></item><item><title>MFAI&#26159;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#36125;&#21494;&#26031;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#36741;&#21161;&#20449;&#24687;&#26469;&#20811;&#26381;&#30001;&#20110;&#25968;&#25454;&#36136;&#37327;&#24046;&#23548;&#33268;&#30340;&#25361;&#25112;&#65292;&#20855;&#26377;&#28789;&#27963;&#24314;&#27169;&#38750;&#32447;&#24615;&#20851;&#31995;&#21644;&#23545;&#36741;&#21161;&#20449;&#24687;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>https://arxiv.org/abs/2303.02566</link><description>&lt;p&gt;
MFAI:&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#36125;&#21494;&#26031;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#26469;&#21033;&#29992;&#36741;&#21161;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
MFAI: A Scalable Bayesian Matrix Factorization Approach to Leveraging Auxiliary Information
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2303.02566
&lt;/p&gt;
&lt;p&gt;
MFAI&#26159;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#36125;&#21494;&#26031;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#36741;&#21161;&#20449;&#24687;&#26469;&#20811;&#26381;&#30001;&#20110;&#25968;&#25454;&#36136;&#37327;&#24046;&#23548;&#33268;&#30340;&#25361;&#25112;&#65292;&#20855;&#26377;&#28789;&#27963;&#24314;&#27169;&#38750;&#32447;&#24615;&#20851;&#31995;&#21644;&#23545;&#36741;&#21161;&#20449;&#24687;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#31181;&#23454;&#38469;&#24773;&#20917;&#19979;&#65292;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#22312;&#25968;&#25454;&#36136;&#37327;&#24046;&#30340;&#24773;&#20917;&#19979;&#24448;&#24448;&#34920;&#29616;&#19981;&#20339;&#65292;&#20363;&#22914;&#25968;&#25454;&#31232;&#30095;&#24615;&#39640;&#21644;&#20449;&#22122;&#27604;&#20302;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#32771;&#34385;&#21033;&#29992;&#36741;&#21161;&#20449;&#24687;&#30340;&#30697;&#38453;&#20998;&#35299;&#38382;&#39064;&#65292;&#36741;&#21161;&#20449;&#24687;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#26159;&#22823;&#37327;&#21487;&#29992;&#30340;&#65292;&#20197;&#20811;&#26381;&#30001;&#20110;&#25968;&#25454;&#36136;&#37327;&#24046;&#24341;&#36215;&#30340;&#25361;&#25112;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#20027;&#35201;&#20381;&#36182;&#20110;&#31616;&#21333;&#32447;&#24615;&#27169;&#22411;&#23558;&#36741;&#21161;&#20449;&#24687;&#19982;&#20027;&#25968;&#25454;&#30697;&#38453;&#32467;&#21512;&#19981;&#21516;&#65292;&#25105;&#20204;&#25552;&#20986;&#23558;&#26799;&#24230;&#22686;&#24378;&#26641;&#38598;&#25104;&#21040;&#27010;&#29575;&#30697;&#38453;&#20998;&#35299;&#26694;&#26550;&#20013;&#20197;&#26377;&#25928;&#22320;&#21033;&#29992;&#36741;&#21161;&#20449;&#24687;(MFAI)&#12290;&#22240;&#27492;&#65292;MFAI&#33258;&#28982;&#22320;&#32487;&#25215;&#20102;&#26799;&#24230;&#22686;&#24378;&#26641;&#30340;&#20960;&#20010;&#26174;&#33879;&#29305;&#28857;&#65292;&#22914;&#28789;&#27963;&#24314;&#27169;&#38750;&#32447;&#24615;&#20851;&#31995;&#12289;&#23545;&#36741;&#21161;&#20449;&#24687;&#20013;&#30340;&#19981;&#30456;&#20851;&#29305;&#24449;&#21644;&#32570;&#22833;&#20540;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;MFAI&#20013;&#30340;&#21442;&#25968;&#21487;&#20197;&#22312;&#32463;&#39564;&#36125;&#21494;&#26031;&#26694;&#26550;&#19979;&#33258;&#21160;&#30830;&#23450;&#65292;&#20351;&#20854;&#36866;&#24212;&#20110;&#21033;&#29992;&#36741;&#21161;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
In various practical situations, matrix factorization methods suffer from poor data quality, such as high data sparsity and low signal-to-noise ratio (SNR). Here, we consider a matrix factorization problem by utilizing auxiliary information, which is massively available in real-world applications, to overcome the challenges caused by poor data quality. Unlike existing methods that mainly rely on simple linear models to combine auxiliary information with the main data matrix, we propose to integrate gradient boosted trees in the probabilistic matrix factorization framework to effectively leverage auxiliary information (MFAI). Thus, MFAI naturally inherits several salient features of gradient boosted trees, such as the capability of flexibly modeling nonlinear relationships and robustness to irrelevant features and missing values in auxiliary information. The parameters in MFAI can be automatically determined under the empirical Bayes framework, making it adaptive to the utilization of a
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25919;&#31574;&#20248;&#21270;&#26694;&#26550;&#65292;&#36890;&#36807;&#38236;&#38754;&#19979;&#38477;&#33258;&#28982;&#22320;&#36866;&#24212;&#36890;&#29992;&#21442;&#25968;&#21270;&#65292;&#24182;&#33719;&#24471;&#20102;&#24212;&#29992;&#20110;&#36890;&#29992;&#21442;&#25968;&#21270;&#30340;&#22522;&#20110;&#25919;&#31574;&#26799;&#24230;&#30340;&#26041;&#27861;&#30340;&#32447;&#24615;&#25910;&#25947;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2301.13139</link><description>&lt;p&gt;
&#19968;&#31181;&#20855;&#26377;&#36890;&#29992;&#21442;&#25968;&#21270;&#21644;&#32447;&#24615;&#25910;&#25947;&#30340;&#25919;&#31574;&#38236;&#38754;&#19979;&#38477;&#26032;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Novel Framework for Policy Mirror Descent with General Parameterization and Linear Convergence
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2301.13139
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25919;&#31574;&#20248;&#21270;&#26694;&#26550;&#65292;&#36890;&#36807;&#38236;&#38754;&#19979;&#38477;&#33258;&#28982;&#22320;&#36866;&#24212;&#36890;&#29992;&#21442;&#25968;&#21270;&#65292;&#24182;&#33719;&#24471;&#20102;&#24212;&#29992;&#20110;&#36890;&#29992;&#21442;&#25968;&#21270;&#30340;&#22522;&#20110;&#25919;&#31574;&#26799;&#24230;&#30340;&#26041;&#27861;&#30340;&#32447;&#24615;&#25910;&#25947;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20013;&#29616;&#20195;&#25919;&#31574;&#20248;&#21270;&#26041;&#27861;&#65288;&#22914;TRPO&#21644;PPO&#65289;&#30340;&#25104;&#21151;&#24402;&#21151;&#20110;&#21442;&#25968;&#21270;&#25919;&#31574;&#30340;&#20351;&#29992;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#24050;&#32463;&#20026;&#36825;&#31867;&#31639;&#27861;&#22312;&#26631;&#31614;&#35774;&#32622;&#20013;&#24314;&#31435;&#20102;&#29702;&#35770;&#20445;&#35777;&#65292;&#20294;&#23545;&#20110;&#36890;&#29992;&#21442;&#25968;&#21270;&#26041;&#26696;&#30340;&#20351;&#29992;&#20173;&#28982;&#27809;&#26377;&#24471;&#21040;&#20805;&#20998;&#35777;&#26126;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#38236;&#38754;&#19979;&#38477;&#30340;&#25919;&#31574;&#20248;&#21270;&#26032;&#26694;&#26550;&#65292;&#21487;&#20197;&#33258;&#28982;&#22320;&#36866;&#24212;&#36890;&#29992;&#21442;&#25968;&#21270;&#12290;&#25105;&#20204;&#26041;&#26696;&#25152;&#20135;&#29983;&#30340;&#25919;&#31574;&#31867;&#21487;&#20197;&#24674;&#22797;&#24050;&#30693;&#30340;&#31867;&#65292;&#22914;softmax&#65292;&#24182;&#26681;&#25454;&#38236;&#38754;&#26144;&#23556;&#30340;&#36873;&#25321;&#29983;&#25104;&#26032;&#31867;&#12290;&#20351;&#29992;&#25105;&#20204;&#30340;&#26694;&#26550;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#20851;&#20110;&#28041;&#21450;&#36890;&#29992;&#21442;&#25968;&#21270;&#30340;&#22522;&#20110;&#25919;&#31574;&#26799;&#24230;&#30340;&#26041;&#27861;&#30340;&#32447;&#24615;&#25910;&#25947;&#30340;&#39318;&#20010;&#32467;&#26524;&#12290;&#20026;&#20102;&#23637;&#31034;&#25105;&#20204;&#30340;&#26694;&#26550;&#36866;&#24212;&#36890;&#29992;&#21442;&#25968;&#21270;&#26041;&#26696;&#30340;&#33021;&#21147;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20351;&#29992;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#26102;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#65292;&#24182;&#23637;&#31034;&#23427;&#30456;&#23545;&#20110;&#20808;&#21069;&#26041;&#27861;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern policy optimization methods in reinforcement learning, such as TRPO and PPO, owe their success to the use of parameterized policies. However, while theoretical guarantees have been established for this class of algorithms, especially in the tabular setting, the use of general parameterization schemes remains mostly unjustified. In this work, we introduce a novel framework for policy optimization based on mirror descent that naturally accommodates general parameterizations. The policy class induced by our scheme recovers known classes, e.g., softmax, and generates new ones depending on the choice of mirror map. Using our framework, we obtain the first result that guarantees linear convergence for a policy-gradient-based method involving general parameterization. To demonstrate the ability of our framework to accommodate general parameterization schemes, we provide its sample complexity when using shallow neural networks, show that it represents an improvement upon the previous be
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#23398;&#20064;&#22240;&#26524;DAG&#30340;&#23376;&#38598;&#20851;&#31995;&#26102;&#65292;&#35782;&#21035;&#25152;&#38656;&#26368;&#23567;&#24178;&#39044;&#38598;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#26377;&#25928;&#31639;&#27861;&#36827;&#34892;&#35299;&#20915;&#12290;&#22312;&#23376;&#38598;&#39564;&#35777;&#38382;&#39064;&#19978;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#35745;&#31639;&#26368;&#23567;&#24178;&#39044;&#38598;&#30340;&#39640;&#25928;&#31639;&#27861;&#12290;&#22312;&#23376;&#38598;&#25628;&#32034;&#38382;&#39064;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#35299;&#20915;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2301.03180</link><description>&lt;p&gt;
&#22240;&#26524;DAG&#30340;&#23376;&#38598;&#39564;&#35777;&#21644;&#25628;&#32034;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Subset verification and search algorithms for causal DAGs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2301.03180
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#23398;&#20064;&#22240;&#26524;DAG&#30340;&#23376;&#38598;&#20851;&#31995;&#26102;&#65292;&#35782;&#21035;&#25152;&#38656;&#26368;&#23567;&#24178;&#39044;&#38598;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#26377;&#25928;&#31639;&#27861;&#36827;&#34892;&#35299;&#20915;&#12290;&#22312;&#23376;&#38598;&#39564;&#35777;&#38382;&#39064;&#19978;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#35745;&#31639;&#26368;&#23567;&#24178;&#39044;&#38598;&#30340;&#39640;&#25928;&#31639;&#27861;&#12290;&#22312;&#23376;&#38598;&#25628;&#32034;&#38382;&#39064;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#35299;&#20915;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#21464;&#37327;&#20043;&#38388;&#30340;&#22240;&#26524;&#20851;&#31995;&#26159;&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#19968;&#39033;&#22522;&#26412;&#20219;&#21153;&#65292;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAGs&#65289;&#26159;&#34920;&#31034;&#22240;&#26524;&#20851;&#31995;&#30340;&#24120;&#35265;&#36873;&#25321;&#12290;&#30001;&#20110;&#25105;&#20204;&#21482;&#33021;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#24674;&#22797;&#22240;&#26524;&#22270;&#30340; Markov &#31561;&#20215;&#31867;&#65292;&#22240;&#27492;&#36890;&#24120;&#38656;&#35201;&#20351;&#29992;&#24178;&#39044;&#26469;&#36827;&#34892;&#24674;&#22797;&#20219;&#21153;&#12290;&#24178;&#39044;&#36890;&#24120;&#26159;&#26114;&#36149;&#30340;&#65292;&#22240;&#27492;&#35774;&#35745;&#33021;&#22815;&#26368;&#23567;&#21270;&#24178;&#39044;&#27425;&#25968;&#30340;&#31639;&#27861;&#38750;&#24120;&#37325;&#35201;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#23398;&#20064;&#19968;&#32452;&#36793;&#32536;&#65288;&#30446;&#26631;&#36793;&#32536;&#65289;&#20043;&#38388;&#30340;&#22240;&#26524;&#20851;&#31995;&#26102;&#65292;&#35782;&#21035;&#25152;&#38656;&#26368;&#23567;&#24178;&#39044;&#38598;&#30340;&#38382;&#39064;&#12290;&#22312;&#20551;&#35774;&#24544;&#23454;&#24615;&#12289;&#22240;&#26524;&#20805;&#20998;&#24615;&#21644;&#29702;&#24819;&#24178;&#39044;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#22312;&#20004;&#20010;&#35774;&#32622;&#19979;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#65306;&#24403;&#24213;&#23618;&#30495;&#23454;&#22240;&#26524;&#22270;&#24050;&#30693;&#26102;&#65288;&#23376;&#38598;&#39564;&#35777;&#65289;&#65292;&#20197;&#21450;&#24403;&#20854;&#26410;&#30693;&#26102;&#65288;&#23376;&#38598;&#25628;&#32034;&#65289;&#12290;&#23545;&#20110;&#23376;&#38598;&#39564;&#35777;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#31639;&#27861;&#26469;&#35745;&#31639;&#26368;&#23567;&#24178;&#39044;&#38598;&#65307;&#25105;&#20204;&#36827;&#19968;&#27493;&#35299;&#20915;&#20102;&#23376;&#38598;&#25628;&#32034;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#31639;&#27861;&#36827;&#34892;&#35299;&#20915;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning causal relationships between variables is a fundamental task in causal inference and directed acyclic graphs (DAGs) are a popular choice to represent the causal relationships. As one can recover a causal graph only up to its Markov equivalence class from observations, interventions are often used for the recovery task. Interventions are costly in general and it is important to design algorithms that minimize the number of interventions performed. In this work, we study the problem of identifying the smallest set of interventions required to learn the causal relationships between a subset of edges (target edges). Under the assumptions of faithfulness, causal sufficiency, and ideal interventions, we study this problem in two settings: when the underlying ground truth causal graph is known (subset verification) and when it is unknown (subset search). For the subset verification problem, we provide an efficient algorithm to compute a minimum sized interventional set; we further ex
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#27010;&#29575;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#39044;&#27979;&#24207;&#21015;&#25171;&#20998;&#35268;&#21017;&#36827;&#34892;&#35757;&#32451;&#65292;&#36991;&#20813;&#20102;&#32321;&#29712;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#21644;&#19981;&#31283;&#23450;&#30340;&#23545;&#25239;&#35757;&#32451;&#65292;&#20174;&#32780;&#22312;&#27010;&#29575;&#39044;&#27979;&#20013;&#21487;&#38752;&#22320;&#20351;&#29992;&#29983;&#25104;&#32593;&#32476;&#12290;</title><link>https://arxiv.org/abs/2112.08217</link><description>&lt;p&gt;
&#36890;&#36807;&#25171;&#20998;&#35268;&#21017;&#26368;&#23567;&#21270;&#23454;&#29616;&#29983;&#25104;&#32593;&#32476;&#30340;&#27010;&#29575;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Forecasting with Generative Networks via Scoring Rule Minimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2112.08217
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#27010;&#29575;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#39044;&#27979;&#24207;&#21015;&#25171;&#20998;&#35268;&#21017;&#36827;&#34892;&#35757;&#32451;&#65292;&#36991;&#20813;&#20102;&#32321;&#29712;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#21644;&#19981;&#31283;&#23450;&#30340;&#23545;&#25239;&#35757;&#32451;&#65292;&#20174;&#32780;&#22312;&#27010;&#29575;&#39044;&#27979;&#20013;&#21487;&#38752;&#22320;&#20351;&#29992;&#29983;&#25104;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27010;&#29575;&#39044;&#27979;&#20381;&#36182;&#20110;&#36807;&#21435;&#30340;&#35266;&#23519;&#32467;&#26524;&#65292;&#20197;&#25552;&#20379;&#26410;&#26469;&#32467;&#26524;&#30340;&#27010;&#29575;&#20998;&#24067;&#65292;&#24182;&#36890;&#36807;&#25171;&#20998;&#35268;&#21017;&#19982;&#23454;&#38469;&#32467;&#26524;&#36827;&#34892;&#35780;&#20272;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20351;&#29992;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#27010;&#29575;&#39044;&#27979;&#65292;&#36890;&#36807;&#36716;&#25442;&#28508;&#22312;&#21464;&#37327;&#30340;&#25277;&#26679;&#26469;&#21442;&#25968;&#21270;&#39640;&#32500;&#31354;&#38388;&#19978;&#30340;&#20998;&#24067;&#12290;&#29983;&#25104;&#32593;&#32476;&#36890;&#24120;&#22312;&#23545;&#25239;&#24615;&#26694;&#26550;&#20013;&#36827;&#34892;&#35757;&#32451;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#39044;&#27979;&#24207;&#21015;&#25171;&#20998;&#35268;&#21017;&#22312;&#35760;&#24405;&#30340;&#26102;&#38388;&#24207;&#21015;&#20013;&#35757;&#32451;&#29983;&#25104;&#32593;&#32476;&#65292;&#36825;&#31181;&#26041;&#27861;&#19982;&#24120;&#35268;&#35780;&#20272;&#39044;&#27979;&#31995;&#32479;&#30340;&#26041;&#24335;&#30456;&#19968;&#33268;&#12290;&#23545;&#20110;&#26576;&#20123;&#25171;&#20998;&#35268;&#21017;&#65292;&#21487;&#20197;&#23454;&#29616;&#26080;&#23545;&#25239;&#30340;&#26368;&#23567;&#21270;&#65307;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#36991;&#20813;&#20102;&#32321;&#29712;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#21644;&#30001;&#20110;&#19981;&#31283;&#23450;&#30340;&#23545;&#25239;&#35757;&#32451;&#32780;&#23548;&#33268;&#30340;&#19981;&#30830;&#23450;&#24615;&#20302;&#20272;&#65292;&#20174;&#32780;&#22312;&#27010;&#29575;&#39044;&#27979;&#20013;&#21487;&#38752;&#22320;&#20351;&#29992;&#29983;&#25104;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
Probabilistic forecasting relies on past observations to provide a probability distribution for a future outcome, which is often evaluated against the realization using a scoring rule. Here, we perform probabilistic forecasting with generative neural networks, which parametrize distributions on high-dimensional spaces by transforming draws from a latent variable. Generative networks are typically trained in an adversarial framework. In contrast, we propose to train generative networks to minimize a predictive-sequential (or prequential) scoring rule on a recorded temporal sequence of the phenomenon of interest, which is appealing as it corresponds to the way forecasting systems are routinely evaluated. Adversarial-free minimization is possible for some scoring rules; hence, our framework avoids the cumbersome hyperparameter tuning and uncertainty underestimation due to unstable adversarial training, thus unlocking reliable use of generative networks in probabilistic forecasting. Furthe
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#22810;&#32500;&#24230;&#22312;&#32447;&#20915;&#31574;&#30340;&#38543;&#26426;&#20302;&#31209;&#24352;&#37327;&#36172;&#21338;&#31639;&#27861;&#12290;&#36890;&#36807;&#32771;&#34385;&#26377;&#19978;&#19979;&#25991;&#21644;&#27809;&#26377;&#19978;&#19979;&#25991;&#30340;&#24773;&#20917;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#25512;&#23548;&#20102;&#26377;&#38480;&#26102;&#38388;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2007.15788</link><description>&lt;p&gt;
&#38754;&#21521;&#22810;&#32500;&#24230;&#22312;&#32447;&#20915;&#31574;&#30340;&#38543;&#26426;&#20302;&#31209;&#24352;&#37327;&#36172;&#21338;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Stochastic Low-rank Tensor Bandits for Multi-dimensional Online Decision Making
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2007.15788
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#22810;&#32500;&#24230;&#22312;&#32447;&#20915;&#31574;&#30340;&#38543;&#26426;&#20302;&#31209;&#24352;&#37327;&#36172;&#21338;&#31639;&#27861;&#12290;&#36890;&#36807;&#32771;&#34385;&#26377;&#19978;&#19979;&#25991;&#21644;&#27809;&#26377;&#19978;&#19979;&#25991;&#30340;&#24773;&#20917;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#25512;&#23548;&#20102;&#26377;&#38480;&#26102;&#38388;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#32500;&#24230;&#22312;&#32447;&#20915;&#31574;&#22312;&#22312;&#32447;&#25512;&#33616;&#21644;&#25968;&#23383;&#33829;&#38144;&#31561;&#23454;&#38469;&#24212;&#29992;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#22312;&#36825;&#20123;&#38382;&#39064;&#20013;&#65292;&#27599;&#20010;&#26102;&#38388;&#28857;&#30340;&#20915;&#31574;&#26159;&#26469;&#33258;&#19981;&#21516;&#31867;&#22411;&#23454;&#20307;&#30340;&#36873;&#25321;&#30340;&#32452;&#21512;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#38543;&#26426;&#20302;&#31209;&#24352;&#37327;&#36172;&#21338;&#31639;&#27861;&#65292;&#19968;&#31867;&#20854;&#22343;&#20540;&#25910;&#30410;&#21487;&#34920;&#31034;&#20026;&#20302;&#31209;&#24352;&#37327;&#30340;&#36172;&#21338;&#31639;&#27861;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#20004;&#31181;&#24773;&#20917;&#65292;&#21363;&#27809;&#26377;&#19978;&#19979;&#25991;&#30340;&#24352;&#37327;&#36172;&#21338;&#21644;&#26377;&#19978;&#19979;&#25991;&#30340;&#24352;&#37327;&#36172;&#21338;&#12290;&#22312;&#31532;&#19968;&#31181;&#24773;&#20917;&#20013;&#65292;&#24179;&#21488;&#26088;&#22312;&#25214;&#21040;&#20855;&#26377;&#26368;&#39640;&#26399;&#26395;&#22238;&#25253;&#30340;&#26368;&#20339;&#20915;&#31574;&#65292;&#21363;&#30495;&#23454;&#22238;&#25253;&#24352;&#37327;&#30340;&#26368;&#22823;&#26465;&#30446;&#12290;&#22312;&#31532;&#20108;&#31181;&#24773;&#20917;&#20013;&#65292;&#24352;&#37327;&#30340;&#26576;&#20123;&#27169;&#24335;&#26159;&#19978;&#19979;&#25991;&#65292;&#20854;&#20313;&#27169;&#24335;&#26159;&#20915;&#31574;&#65292;&#30446;&#26631;&#26159;&#22312;&#32473;&#23450;&#19978;&#19979;&#25991;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#25214;&#21040;&#26368;&#20339;&#20915;&#31574;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#23398;&#20064;&#31639;&#27861;&#65306;&#24352;&#37327;&#28040;&#38500;&#21644;&#24352;&#37327;&#26102;&#20195;&#36138;&#23146;&#31639;&#27861;&#65292;&#29992;&#20110;&#27809;&#26377;&#19978;&#19979;&#25991;&#30340;&#24352;&#37327;&#36172;&#21338;&#65292;&#24182;&#20026;&#23427;&#20204;&#25512;&#23548;&#20102;&#26377;&#38480;&#26102;&#38388;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;&#19982;&#29616;&#26377;&#30340;&#31454;&#20105;&#31639;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-dimensional online decision making plays a crucial role in many real applications such as online recommendation and digital marketing. In these problems, a decision at each time is a combination of choices from different types of entities. To solve it, we introduce stochastic low-rank tensor bandits, a class of bandits whose mean rewards can be represented as a low-rank tensor. We consider two settings, tensor bandits without context and tensor bandits with context. In the first setting, the platform aims to find the optimal decision with the highest expected reward, a.k.a, the largest entry of true reward tensor. In the second setting, some modes of the tensor are contexts and the rest modes are decisions, and the goal is to find the optimal decision given the contextual information. We propose two learning algorithms tensor elimination and tensor epoch-greedy for tensor bandits without context, and derive finite-time regret bounds for them. Comparing with existing competitive m
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20302;&#36136;&#37327;&#25968;&#25454;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24180;&#40836;&#32467;&#26500;&#20272;&#35745; COVID-19 ICU &#30340;&#38656;&#27714;&#37327;&#65292;&#24182;&#20351;&#29992;&#37325;&#30151;&#30417;&#25252;&#30149;&#25151;&#21344;&#29992;&#25968;&#25454;&#21644;&#36890;&#25253;&#22240;&#23376;&#36827;&#34892;&#26657;&#27491;&#65292;&#39044;&#27979;&#26410;&#26469; ICU &#24202;&#20301;&#30340;&#38656;&#27714;&#24773;&#20917;&#12290;</title><link>https://arxiv.org/abs/2006.06530</link><description>&lt;p&gt;
COVID-19 ICU&#38656;&#27714;&#30340;&#24180;&#40836;&#32467;&#26500;&#20272;&#35745;&#65306;&#22522;&#20110;&#20302;&#36136;&#37327;&#25968;&#25454;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Age-structured estimation of COVID-19 ICU demand from low quality data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2006.06530
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20302;&#36136;&#37327;&#25968;&#25454;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24180;&#40836;&#32467;&#26500;&#20272;&#35745; COVID-19 ICU &#30340;&#38656;&#27714;&#37327;&#65292;&#24182;&#20351;&#29992;&#37325;&#30151;&#30417;&#25252;&#30149;&#25151;&#21344;&#29992;&#25968;&#25454;&#21644;&#36890;&#25253;&#22240;&#23376;&#36827;&#34892;&#26657;&#27491;&#65292;&#39044;&#27979;&#26410;&#26469; ICU &#24202;&#20301;&#30340;&#38656;&#27714;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#23545;&#30830;&#35786;&#30149;&#20363;&#36827;&#34892;&#24180;&#40836;&#32467;&#26500;&#27010;&#29575;&#25277;&#26679;&#65292;&#20351;&#29992;&#37325;&#30151;&#30417;&#25252;&#30149;&#25151;&#21344;&#29992;&#25968;&#25454;&#26469;&#30830;&#23450;&#19968;&#20010;&#26410;&#36890;&#25253;&#22240;&#23376;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#26469;&#33258;&#36798;&#21040;&#24179;&#21488;&#38454;&#27573;&#30340;&#22320;&#21306;&#30340;&#24773;&#26223;&#65292;&#37319;&#29992; logistic &#25311;&#21512;&#26469;&#39044;&#27979; COVID-19 &#30123;&#24773;&#30340;&#36827;&#23637;&#12290;&#26368;&#21518;&#65292;&#36890;&#36807;&#26410;&#36890;&#25253;&#22240;&#23376;&#65292;&#23545;&#25214;&#21040;&#30340;&#36923;&#36753;&#26354;&#32447;&#36827;&#34892;&#26657;&#27491;&#65292;&#24182;&#23545;&#26410;&#26469; ICU &#24202;&#20301;&#38656;&#27714;&#36827;&#34892;&#25277;&#26679;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
We sample aggravated cases following age-structured probabilities from confirmed cases and use ICU occupation data to find a subnotification factor. A logistic fit is then employed to project the progression of the COVID-19 epidemic with plateau scenarios taken from locations that have reached this stage. Finally, the logistic curve found is corrected by the subnotification factor and sampled to project the future demand for ICU beds.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#36816;&#34892;&#26102;&#26412;&#22320;&#40065;&#26834;&#24615;&#39564;&#35777;&#26469;&#39564;&#35777;&#31070;&#32463;&#32593;&#32476;&#36755;&#20837;&#30340;&#26041;&#27861;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#20445;&#25252;&#31070;&#32463;&#32593;&#32476;&#20813;&#21463;&#23545;&#25239;&#24615;&#26679;&#26412;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#39640;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2002.03339</link><description>&lt;p&gt;
&#36890;&#36807;&#36816;&#34892;&#26102;&#26412;&#22320;&#40065;&#26834;&#24615;&#39564;&#35777;&#36827;&#34892;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20837;&#39564;&#35777;
&lt;/p&gt;
&lt;p&gt;
Input Validation for Neural Networks via Runtime Local Robustness Verification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2002.03339
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#36816;&#34892;&#26102;&#26412;&#22320;&#40065;&#26834;&#24615;&#39564;&#35777;&#26469;&#39564;&#35777;&#31070;&#32463;&#32593;&#32476;&#36755;&#20837;&#30340;&#26041;&#27861;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#20445;&#25252;&#31070;&#32463;&#32593;&#32476;&#20813;&#21463;&#23545;&#25239;&#24615;&#26679;&#26412;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#39640;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#22320;&#40065;&#26834;&#24615;&#39564;&#35777;&#21487;&#20197;&#39564;&#35777;&#31070;&#32463;&#32593;&#32476;&#23545;&#29305;&#23450;&#36755;&#20837;&#30340;&#25200;&#21160;&#22312;&#19968;&#23450;&#36317;&#31163;&#20869;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#36317;&#31163;&#31216;&#20026;&#40065;&#26834;&#24615;&#21322;&#24452;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#27491;&#30830;&#20998;&#31867;&#30340;&#36755;&#20837;&#30340;&#40065;&#26834;&#24615;&#21322;&#24452;&#35201;&#27604;&#38169;&#35823;&#20998;&#31867;&#30340;&#36755;&#20837;&#65288;&#21253;&#25324;&#23545;&#25239;&#24615;&#26679;&#26412;&#65292;&#29305;&#21035;&#26159;&#26469;&#33258;&#24378;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#26679;&#26412;&#65289;&#35201;&#22823;&#24471;&#22810;&#12290;&#21478;&#19968;&#20010;&#35266;&#23519;&#26159;&#65292;&#27491;&#30830;&#20998;&#31867;&#30340;&#36755;&#20837;&#30340;&#40065;&#26834;&#24615;&#21322;&#24452;&#36890;&#24120;&#31526;&#21512;&#27491;&#24577;&#20998;&#24067;&#12290;&#22522;&#20110;&#36825;&#20004;&#20010;&#35266;&#23519;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#36816;&#34892;&#26102;&#26412;&#22320;&#40065;&#26834;&#24615;&#39564;&#35777;&#26469;&#39564;&#35777;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20837;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20445;&#25252;&#31070;&#32463;&#32593;&#32476;&#20813;&#21463;&#23545;&#25239;&#24615;&#26679;&#26412;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#39640;&#20854;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Local robustness verification can verify that a neural network is robust wrt. any perturbation to a specific input within a certain distance. We call this distance Robustness Radius. We observe that the robustness radii of correctly classified inputs are much larger than that of misclassified inputs which include adversarial examples, especially those from strong adversarial attacks. Another observation is that the robustness radii of correctly classified inputs often follow a normal distribution. Based on these two observations, we propose to validate inputs for neural networks via runtime local robustness verification. Experiments show that our approach can protect neural networks from adversarial examples and improve their accuracies.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#32858;&#31867;&#20013;&#30340;&#30446;&#26631;&#20989;&#25968;&#19981;&#21305;&#37197;&#65288;OFM&#65289;&#38382;&#39064;&#65292;&#24182;&#21457;&#29616;&#22522;&#20110;&#33258;&#32534;&#30721;&#22120;&#30340;&#26041;&#27861;&#23481;&#26131;&#23548;&#33268;&#38477;&#20302;&#32858;&#31867;&#24615;&#33021;&#21644;&#37325;&#26500;&#19982;&#32858;&#31867;&#30446;&#26631;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36741;&#21161;&#30446;&#26631;&#26041;&#27861;&#65292;&#31216;&#20026;&#26080;&#30417;&#30563;&#20276;&#38543;&#23545;&#35937;&#65288;UCO&#65289;&#65292;&#36890;&#36807;&#26680;&#20989;&#25968;&#22312;&#32593;&#32476;&#30340;&#20013;&#38388;&#34920;&#31034;&#19978;&#21046;&#23450;&#32858;&#31867;&#30446;&#26631;&#12290;</title><link>https://arxiv.org/abs/2001.07026</link><description>&lt;p&gt;
&#21033;&#29992;&#24352;&#37327;&#26680;&#20943;&#23569;&#28145;&#24230;&#32858;&#31867;&#20013;&#30340;&#30446;&#26631;&#20989;&#25968;&#19981;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Leveraging tensor kernels to reduce objective function mismatch in deep clustering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2001.07026
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#32858;&#31867;&#20013;&#30340;&#30446;&#26631;&#20989;&#25968;&#19981;&#21305;&#37197;&#65288;OFM&#65289;&#38382;&#39064;&#65292;&#24182;&#21457;&#29616;&#22522;&#20110;&#33258;&#32534;&#30721;&#22120;&#30340;&#26041;&#27861;&#23481;&#26131;&#23548;&#33268;&#38477;&#20302;&#32858;&#31867;&#24615;&#33021;&#21644;&#37325;&#26500;&#19982;&#32858;&#31867;&#30446;&#26631;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36741;&#21161;&#30446;&#26631;&#26041;&#27861;&#65292;&#31216;&#20026;&#26080;&#30417;&#30563;&#20276;&#38543;&#23545;&#35937;&#65288;UCO&#65289;&#65292;&#36890;&#36807;&#26680;&#20989;&#25968;&#22312;&#32593;&#32476;&#30340;&#20013;&#38388;&#34920;&#31034;&#19978;&#21046;&#23450;&#32858;&#31867;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#26631;&#20989;&#25968;&#19981;&#21305;&#37197;&#65288;OFM&#65289;&#25351;&#30340;&#26159;&#19968;&#20010;&#30446;&#26631;&#30340;&#20248;&#21270;&#23545;&#21478;&#19968;&#20010;&#30446;&#26631;&#30340;&#20248;&#21270;&#20135;&#29983;&#36127;&#38754;&#24433;&#21709;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#28145;&#24230;&#32858;&#31867;&#20013;&#30340;OFM&#65292;&#24182;&#21457;&#29616;&#27969;&#34892;&#30340;&#22522;&#20110;&#33258;&#32534;&#30721;&#22120;&#30340;&#28145;&#24230;&#32858;&#31867;&#26041;&#27861;&#26082;&#20250;&#38477;&#20302;&#32858;&#31867;&#24615;&#33021;&#65292;&#21448;&#20250;&#23548;&#33268;&#37325;&#26500;&#30446;&#26631;&#21644;&#32858;&#31867;&#30446;&#26631;&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#30340;OFM&#12290;&#20026;&#20102;&#20943;&#23569;&#19981;&#21305;&#37197;&#65292;&#21516;&#26102;&#20445;&#25345;&#36741;&#21161;&#30446;&#26631;&#30340;&#32467;&#26500;&#20445;&#25345;&#29305;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#32452;&#26032;&#30340;&#29992;&#20110;&#28145;&#24230;&#32858;&#31867;&#30340;&#36741;&#21161;&#30446;&#26631;&#65292;&#31216;&#20026;&#26080;&#30417;&#30563;&#20276;&#38543;&#23545;&#35937;&#65288;UCO&#65289;&#12290;UCOs&#20381;&#36182;&#20110;&#26680;&#20989;&#25968;&#65292;&#22312;&#32593;&#32476;&#30340;&#20013;&#38388;&#34920;&#31034;&#19978;&#21046;&#23450;&#32858;&#31867;&#30446;&#26631;&#12290;&#19968;&#33324;&#32780;&#35328;&#65292;&#20013;&#38388;&#34920;&#31034;&#21487;&#20197;&#21253;&#25324;&#38500;&#29305;&#24449;&#32500;&#24230;&#20043;&#22806;&#30340;&#20854;&#20182;&#32500;&#24230;&#65292;&#20363;&#22914;&#31354;&#38388;&#25110;&#26102;&#38388;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#35748;&#20026;&#31616;&#21333;&#22320;&#23558;&#20854;&#21521;&#37327;&#21270;&#24182;&#24212;&#29992;&#21521;&#37327;&#26680;&#23545;&#27492;&#31867;&#38382;&#39064;&#24182;&#19981;&#29702;&#24819;&#12290;
&lt;/p&gt;
&lt;p&gt;
Objective Function Mismatch (OFM) occurs when the optimization of one objective has a negative impact on the optimization of another objective. In this work we study OFM in deep clustering, and find that the popular autoencoder-based approach to deep clustering can lead to both reduced clustering performance, and a significant amount of OFM between the reconstruction and clustering objectives. To reduce the mismatch, while maintaining the structure-preserving property of an auxiliary objective, we propose a set of new auxiliary objectives for deep clustering, referred to as the Unsupervised Companion Objectives (UCOs). The UCOs rely on a kernel function to formulate a clustering objective on intermediate representations in the network. Generally, intermediate representations can include other dimensions, for instance spatial or temporal, in addition to the feature dimension. We therefore argue that the na\"ive approach of vectorizing and applying a vector kernel is suboptimal for such 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#33258;&#25105;&#23545;&#24369;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#32454;&#35843;&#65288;SPIN&#65289;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27169;&#22411;&#33258;&#25105;&#23545;&#24328;&#29983;&#25104;&#35757;&#32451;&#25968;&#25454;&#65292;&#24182;&#20174;&#20013;&#20248;&#21270;&#27169;&#22411;&#31574;&#30053;&#65292;&#20174;&#32780;&#23558;&#24369;&#35821;&#35328;&#27169;&#22411;&#36716;&#21270;&#20026;&#24378;&#35821;&#35328;&#27169;&#22411;&#65292;&#26080;&#38656;&#39069;&#22806;&#30340;&#20154;&#31867;&#26631;&#27880;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2401.01335</link><description>&lt;p&gt;
&#33258;&#25105;&#23545;&#24369;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#32454;&#35843;&#21487;&#20197;&#23558;&#20854;&#36716;&#21270;&#20026;&#24378;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models. (arXiv:2401.01335v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01335
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#33258;&#25105;&#23545;&#24369;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#32454;&#35843;&#65288;SPIN&#65289;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27169;&#22411;&#33258;&#25105;&#23545;&#24328;&#29983;&#25104;&#35757;&#32451;&#25968;&#25454;&#65292;&#24182;&#20174;&#20013;&#20248;&#21270;&#27169;&#22411;&#31574;&#30053;&#65292;&#20174;&#32780;&#23558;&#24369;&#35821;&#35328;&#27169;&#22411;&#36716;&#21270;&#20026;&#24378;&#35821;&#35328;&#27169;&#22411;&#65292;&#26080;&#38656;&#39069;&#22806;&#30340;&#20154;&#31867;&#26631;&#27880;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30417;&#30563;&#32454;&#35843;&#65288;SFT&#65289;&#21033;&#29992;&#20154;&#31867;&#26631;&#27880;&#25968;&#25454;&#30340;&#21147;&#37327;&#23545;&#20110;&#25512;&#36827;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#19981;&#38656;&#35201;&#33719;&#21462;&#39069;&#22806;&#20154;&#31867;&#26631;&#27880;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#23558;&#24369;&#35821;&#35328;&#27169;&#22411;&#21457;&#23637;&#25104;&#20026;&#24378;&#35821;&#35328;&#27169;&#22411;&#30340;&#21487;&#33021;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#33258;&#25105;&#23545;&#24369;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#32454;&#35843;&#65288;SPIN&#65289;&#30340;&#26032;&#30340;&#32454;&#35843;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20174;&#19968;&#20010;&#32463;&#36807;&#30417;&#30563;&#32454;&#35843;&#30340;&#27169;&#22411;&#24320;&#22987;&#12290;SPIN&#30340;&#26680;&#24515;&#26159;&#33258;&#25105;&#23545;&#24369;&#35821;&#35328;&#27169;&#22411;&#30340;&#26426;&#21046;&#65292;&#20854;&#20013;&#24369;&#35821;&#35328;&#27169;&#22411;&#36890;&#36807;&#19982;&#33258;&#36523;&#30340;&#23454;&#20363;&#23545;&#24328;&#26469;&#25552;&#21319;&#33258;&#24049;&#30340;&#33021;&#21147;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#24369;&#35821;&#35328;&#27169;&#22411;&#36890;&#36807;&#29983;&#25104;&#33258;&#24049;&#30340;&#35757;&#32451;&#25968;&#25454;&#26469;&#20248;&#21270;&#33258;&#36523;&#31574;&#30053;&#65292;&#36890;&#36807;&#21306;&#20998;&#33258;&#25105;&#29983;&#25104;&#30340;&#22238;&#24212;&#19982;&#26469;&#33258;&#20154;&#31867;&#26631;&#27880;&#25968;&#25454;&#30340;&#22238;&#24212;&#26469;&#25913;&#36827;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36880;&#27493;&#23558;&#24369;&#35821;&#35328;&#27169;&#22411;&#25552;&#21319;&#20026;&#24378;&#22823;&#30340;&#27169;&#22411;&#65292;&#20805;&#20998;&#21457;&#25496;&#20154;&#31867;&#26631;&#27880;&#31034;&#33539;&#25968;&#25454;&#22312;SFT&#20013;&#30340;&#28508;&#21147;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#35757;&#32451;&#30446;&#26631;&#20989;&#25968;&#30340;&#20840;&#23616;&#26368;&#20248;&#35299;&#26159;&#21487;&#20197;&#36798;&#21040;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Harnessing the power of human-annotated data through Supervised Fine-Tuning (SFT) is pivotal for advancing Large Language Models (LLMs). In this paper, we delve into the prospect of growing a strong LLM out of a weak one without the need for acquiring additional human-annotated data. We propose a new fine-tuning method called Self-Play fIne-tuNing (SPIN), which starts from a supervised fine-tuned model. At the heart of SPIN lies a self-play mechanism, where the LLM refines its capability by playing against instances of itself. More specifically, the LLM generates its own training data from its previous iterations, refining its policy by discerning these self-generated responses from those obtained from human-annotated data. Our method progressively elevates the LLM from a nascent model to a formidable one, unlocking the full potential of human-annotated demonstration data for SFT. Theoretically, we prove that the global optimum to the training objective function of our method is achiev
&lt;/p&gt;</description></item><item><title>&#22312;&#26377;&#38480;&#20808;&#39564;&#30693;&#35782;&#19979;&#65292;&#36890;&#36807;&#23616;&#37096;&#20998;&#21306;&#21457;&#29616;&#31639;&#27861;&#65288;LDP&#65289;&#65292;&#35813;&#30740;&#31350;&#35299;&#20915;&#20102;&#33258;&#21160;&#21464;&#37327;&#36873;&#25321;&#30340;&#38382;&#39064;&#12290;LDP&#26681;&#25454;&#19982;&#26333;&#20809;-&#32467;&#26524;&#23545;{X,Y}&#30456;&#20851;&#30340;&#23376;&#38598;&#23558;&#21464;&#37327;&#38598;&#21512;Z&#36827;&#34892;&#20998;&#21306;&#65292;&#24182;&#21306;&#20998;&#28151;&#28102;&#22240;&#32032;&#21644;&#20854;&#20182;&#21464;&#37327;&#31867;&#22411;&#12290;&#35813;&#31639;&#27861;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#22312;&#23454;&#36341;&#20013;&#35266;&#23519;&#21040;&#27425;&#20108;&#27425;&#30340;&#36816;&#34892;&#26102;&#38388;&#12290;</title><link>http://arxiv.org/abs/2310.17816</link><description>&lt;p&gt;
Local Discovery by Partitioning: &#22312;&#26377;&#38480;&#20808;&#39564;&#30693;&#35782;&#19979;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Local Discovery by Partitioning: Polynomial-Time Causal Discovery Around Exposure-Outcome Pairs. (arXiv:2310.17816v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17816
&lt;/p&gt;
&lt;p&gt;
&#22312;&#26377;&#38480;&#20808;&#39564;&#30693;&#35782;&#19979;&#65292;&#36890;&#36807;&#23616;&#37096;&#20998;&#21306;&#21457;&#29616;&#31639;&#27861;&#65288;LDP&#65289;&#65292;&#35813;&#30740;&#31350;&#35299;&#20915;&#20102;&#33258;&#21160;&#21464;&#37327;&#36873;&#25321;&#30340;&#38382;&#39064;&#12290;LDP&#26681;&#25454;&#19982;&#26333;&#20809;-&#32467;&#26524;&#23545;{X,Y}&#30456;&#20851;&#30340;&#23376;&#38598;&#23558;&#21464;&#37327;&#38598;&#21512;Z&#36827;&#34892;&#20998;&#21306;&#65292;&#24182;&#21306;&#20998;&#28151;&#28102;&#22240;&#32032;&#21644;&#20854;&#20182;&#21464;&#37327;&#31867;&#22411;&#12290;&#35813;&#31639;&#27861;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#22312;&#23454;&#36341;&#20013;&#35266;&#23519;&#21040;&#27425;&#20108;&#27425;&#30340;&#36816;&#34892;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#35299;&#20915;&#20102;&#22312;&#26377;&#38480;&#20808;&#39564;&#30693;&#35782;&#19979;&#33258;&#21160;&#21464;&#37327;&#36873;&#25321;&#30340;&#38382;&#39064;&#12290;&#32473;&#23450;&#19968;&#20010;{X,Y}&#30340;&#26333;&#20809;-&#32467;&#26524;&#23545;&#21644;&#19968;&#20010;&#26410;&#30693;&#22240;&#26524;&#32467;&#26500;&#30340;&#21464;&#37327;&#38598;&#21512;Z&#65292;&#23616;&#37096;&#20998;&#21306;&#21457;&#29616;&#65288;LDP&#65289;&#31639;&#27861;&#23558;Z&#21010;&#20998;&#25104;&#19982;{X,Y}&#30456;&#20851;&#30340;&#23376;&#38598;&#12290;&#25105;&#20204;&#21015;&#20030;&#20102;&#20219;&#24847;Z&#30340;8&#20010;&#31351;&#20030;&#19988;&#20114;&#19981;&#37325;&#22797;&#30340;&#20998;&#21306;&#65292;&#24182;&#21033;&#29992;&#36825;&#20010;&#20998;&#31867;&#27861;&#21306;&#20998;&#28151;&#28102;&#22240;&#32032;&#21644;&#20854;&#20182;&#21464;&#37327;&#31867;&#22411;&#12290;LDP&#30340;&#21160;&#26426;&#26159;&#26377;&#25928;&#30340;&#35843;&#25972;&#38598;&#35782;&#21035;&#65292;&#20294;&#36991;&#20813;&#20102;&#33258;&#21160;&#21464;&#37327;&#36873;&#25321;&#26041;&#27861;&#20013;&#24120;&#35265;&#30340;&#39044;&#22788;&#29702;&#20551;&#35774;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#65292;LDP&#23545;&#20110;&#28385;&#36275;&#36275;&#22815;&#22270;&#24418;&#26465;&#20214;&#30340;&#20219;&#20309;Z&#37117;&#36820;&#22238;&#19968;&#20010;&#26377;&#25928;&#30340;&#35843;&#25972;&#38598;&#12290;&#22312;&#26356;&#24378;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20998;&#21306;&#26631;&#31614;&#30340;&#28176;&#36817;&#27491;&#30830;&#24615;&#12290;&#24635;&#29420;&#31435;&#24615;&#27979;&#35797;&#22312;|Z|&#30340;&#26368;&#22351;&#24773;&#20917;&#19979;&#26159;&#20108;&#27425;&#30340;&#65292;&#32463;&#39564;&#19978;&#35266;&#23519;&#21040;&#27425;&#20108;&#27425;&#30340;&#36816;&#34892;&#26102;&#38388;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#23545;&#29702;&#35770;&#20445;&#35777;&#36827;&#34892;&#20102;&#25968;&#20540;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work addresses the problem of automated covariate selection under limited prior knowledge. Given an exposure-outcome pair {X,Y} and a variable set Z of unknown causal structure, the Local Discovery by Partitioning (LDP) algorithm partitions Z into subsets defined by their relation to {X,Y}. We enumerate eight exhaustive and mutually exclusive partitions of any arbitrary Z and leverage this taxonomy to differentiate confounders from other variable types. LDP is motivated by valid adjustment set identification, but avoids the pretreatment assumption commonly made by automated covariate selection methods. We provide theoretical guarantees that LDP returns a valid adjustment set for any Z that meets sufficient graphical conditions. Under stronger conditions, we prove that partition labels are asymptotically correct. Total independence tests is worst-case quadratic in |Z|, with sub-quadratic runtimes observed empirically. We numerically validate our theoretical guarantees on synthetic 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32452;&#21512;&#28145;&#24230;&#27010;&#29575;&#27169;&#22411;DEL-Compose&#65292;&#29992;&#20110;&#23545;DNA&#32534;&#30721;&#24211;&#30340;&#25968;&#25454;&#36827;&#34892;&#24314;&#27169;&#21644;&#20998;&#26512;&#65292;&#20197;&#21457;&#29616;&#28508;&#22312;&#30340;&#32467;&#26500;&#21644;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#25913;&#36827;&#35266;&#23519;&#27169;&#22411;&#26469;&#26356;&#22909;&#22320;&#22788;&#29702;&#25968;&#25454;&#22122;&#22768;&#12290;</title><link>http://arxiv.org/abs/2310.13769</link><description>&lt;p&gt;
DNA&#32534;&#30721;&#24211;&#30340;&#32452;&#21512;&#28145;&#24230;&#27010;&#29575;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Compositional Deep Probabilistic Models of DNA Encoded Libraries. (arXiv:2310.13769v1 [q-bio.QM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13769
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32452;&#21512;&#28145;&#24230;&#27010;&#29575;&#27169;&#22411;DEL-Compose&#65292;&#29992;&#20110;&#23545;DNA&#32534;&#30721;&#24211;&#30340;&#25968;&#25454;&#36827;&#34892;&#24314;&#27169;&#21644;&#20998;&#26512;&#65292;&#20197;&#21457;&#29616;&#28508;&#22312;&#30340;&#32467;&#26500;&#21644;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#25913;&#36827;&#35266;&#23519;&#27169;&#22411;&#26469;&#26356;&#22909;&#22320;&#22788;&#29702;&#25968;&#25454;&#22122;&#22768;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
DNA&#32534;&#30721;&#24211;&#65288;DEL&#65289;&#24050;&#34987;&#35777;&#26126;&#26159;&#19968;&#31181;&#21033;&#29992;&#32452;&#21512;&#26500;&#24314;&#30340;&#23567;&#20998;&#23376;&#36827;&#34892;&#39640;&#25928;&#31579;&#36873;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#36825;&#20123;&#36873;&#25321;&#23454;&#39564;&#28041;&#21450;&#22810;&#20010;&#38454;&#27573;&#30340;&#27927;&#28068;&#12289;&#27927;&#33073;&#65292;&#24182;&#36890;&#36807;&#21807;&#19968;&#30340;DNA&#26465;&#24418;&#30721;&#37492;&#23450;&#20986;&#24378;&#25928;&#32467;&#21512;&#29289;&#36136;&#65292;&#24448;&#24448;&#20135;&#29983;&#22797;&#26434;&#30340;&#25968;&#25454;&#12290;&#36825;&#31181;&#22797;&#26434;&#24615;&#21487;&#33021;&#25513;&#30422;&#20102;&#28508;&#22312;&#30340;&#20449;&#21495;&#65292;&#22240;&#27492;&#38656;&#35201;&#24212;&#29992;&#26426;&#22120;&#23398;&#20064;&#31561;&#35745;&#31639;&#24037;&#20855;&#26469;&#21457;&#29616;&#26377;&#20215;&#20540;&#30340;&#35265;&#35299;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;DEL&#25968;&#25454;&#30340;&#32452;&#21512;&#28145;&#24230;&#27010;&#29575;&#27169;&#22411;DEL-Compose&#65292;&#23427;&#23558;&#20998;&#23376;&#34920;&#31034;&#20998;&#35299;&#20026;&#23427;&#20204;&#30340;&#21333;&#21512;&#23376;&#12289;&#20108;&#21512;&#23376;&#21644;&#19977;&#21512;&#23376;&#26500;&#24314;&#22359;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#23884;&#20837;&#21512;&#25104;&#29289;&#20043;&#38388;&#30340;&#28508;&#22312;&#21453;&#24212;&#26469;&#21033;&#29992;&#36825;&#20123;&#20998;&#23376;&#30340;&#20869;&#22312;&#20998;&#23618;&#32467;&#26500;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#25913;&#36827;DEL&#35745;&#25968;&#25968;&#25454;&#30340;&#35266;&#23519;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#22914;&#25972;&#21512;&#21327;&#21464;&#22240;&#23376;&#20197;&#26356;&#26377;&#25928;&#22320;&#35299;&#37322;&#25968;&#25454;&#22122;&#22768;&#12290;
&lt;/p&gt;
&lt;p&gt;
DNA-Encoded Library (DEL) has proven to be a powerful tool that utilizes combinatorially constructed small molecules to facilitate highly-efficient screening assays. These selection experiments, involving multiple stages of washing, elution, and identification of potent binders via unique DNA barcodes, often generate complex data. This complexity can potentially mask the underlying signals, necessitating the application of computational tools such as machine learning to uncover valuable insights. We introduce a compositional deep probabilistic model of DEL data, DEL-Compose, which decomposes molecular representations into their mono-synthon, di-synthon, and tri-synthon building blocks and capitalizes on the inherent hierarchical structure of these molecules by modeling latent reactions between embedded synthons. Additionally, we investigate methods to improve the observation models for DEL count data such as integrating covariate factors to more effectively account for data noise. Acro
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35299;&#20915;&#20102;&#23545;&#20110;&#22343;&#21248;&#25910;&#25947;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#38271;&#26399;&#24179;&#22343;&#22870;&#21169;&#26368;&#22823;&#21270;&#31574;&#30053;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#38382;&#39064;&#65292;&#24182;&#24314;&#31435;&#20102;&#19968;&#20010;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\widetilde O(|S||A|t_{\text{mix}}\epsilon^{-2})$&#30340;&#20248;&#21270;&#31574;&#30053;&#20272;&#35745;&#22120;&#12290;</title><link>http://arxiv.org/abs/2310.08833</link><description>&lt;p&gt;
&#24179;&#22343;&#22870;&#21169;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
Optimal Sample Complexity for Average Reward Markov Decision Processes. (arXiv:2310.08833v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08833
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35299;&#20915;&#20102;&#23545;&#20110;&#22343;&#21248;&#25910;&#25947;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#38271;&#26399;&#24179;&#22343;&#22870;&#21169;&#26368;&#22823;&#21270;&#31574;&#30053;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#38382;&#39064;&#65292;&#24182;&#24314;&#31435;&#20102;&#19968;&#20010;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\widetilde O(|S||A|t_{\text{mix}}\epsilon^{-2})$&#30340;&#20248;&#21270;&#31574;&#30053;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#20551;&#35774;&#26377;&#19968;&#20010;&#29983;&#25104;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#35299;&#20915;&#20102;&#19982;&#22343;&#21248;&#25910;&#25947;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30456;&#20851;&#30340;&#38271;&#26399;&#24179;&#22343;&#22870;&#21169;&#30340;&#31574;&#30053;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#38382;&#39064;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#29616;&#26377;&#30340;&#25991;&#29486;&#25552;&#20379;&#20102;&#19968;&#20010;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#19978;&#30028;&#65292;$ \widetilde O(|S||A|t_{\text{mix}}^2 \epsilon^{-2})$&#65292;&#21644;&#19968;&#20010;&#19979;&#30028;&#65292;$\Omega(|S||A|t_{\text{mix}} \epsilon^{-2})$&#12290;&#22312;&#36825;&#20123;&#34920;&#36798;&#24335;&#20013;&#65292;$|S|$&#21644;$|A|$&#20998;&#21035;&#34920;&#31034;&#29366;&#24577;&#31354;&#38388;&#21644;&#21160;&#20316;&#31354;&#38388;&#30340;&#21183;&#65292;$t_{\text{mix}}$&#20316;&#20026;&#24635;&#21464;&#24322;&#28151;&#21512;&#26102;&#38388;&#30340;&#32479;&#19968;&#19978;&#38480;&#65292;$\epsilon$&#34920;&#31034;&#35823;&#24046;&#23481;&#24525;&#24230;&#12290;&#22240;&#27492;&#65292;$t_{\text{mix}}$&#20173;&#28982;&#23384;&#22312;&#19968;&#20010;&#26174;&#30528;&#30340;&#24046;&#36317;&#38656;&#35201;&#22635;&#34917;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#24314;&#31435;&#19968;&#20010;&#20248;&#21270;&#31574;&#30053;&#30340;&#20272;&#35745;&#22120;&#65292;&#20854;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\widetilde O(|S||A|t_{\text{mix}}\epsilon^{-2})$&#65292;&#26377;&#25928;&#22320;&#36798;&#21040;&#20102;&#25991;&#29486;&#20013;&#30340;&#19979;&#30028;&#12290;&#36825;&#26159;&#36890;&#36807;&#32467;&#21512;&#31639;&#27861;&#24605;&#24819;&#23454;&#29616;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We settle the sample complexity of policy learning for the maximization of the long run average reward associated with a uniformly ergodic Markov decision process (MDP), assuming a generative model. In this context, the existing literature provides a sample complexity upper bound of $\widetilde O(|S||A|t_{\text{mix}}^2 \epsilon^{-2})$ and a lower bound of $\Omega(|S||A|t_{\text{mix}} \epsilon^{-2})$. In these expressions, $|S|$ and $|A|$ denote the cardinalities of the state and action spaces respectively, $t_{\text{mix}}$ serves as a uniform upper limit for the total variation mixing times, and $\epsilon$ signifies the error tolerance. Therefore, a notable gap of $t_{\text{mix}}$ still remains to be bridged. Our primary contribution is to establish an estimator for the optimal policy of average reward MDPs with a sample complexity of $\widetilde O(|S||A|t_{\text{mix}}\epsilon^{-2})$, effectively reaching the lower bound in the literature. This is achieved by combining algorithmic idea
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#24179;&#22343;&#20809;&#28369;&#24230;&#30340;&#26080;&#21442;&#22238;&#24402;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#26080;&#20998;&#24067;&#38480;&#21046;&#19979;&#30340;&#32479;&#19968;&#25910;&#25947;&#30028;&#38480;&#21644;&#39640;&#25928;&#26080;&#20559;&#23398;&#20064;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.17016</link><description>&lt;p&gt;
&#20855;&#26377;&#24179;&#22343;&#20809;&#28369;&#24230;&#30340;&#39640;&#25928;&#26080;&#20559;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Efficient Agnostic Learning with Average Smoothness. (arXiv:2309.17016v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.17016
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#24179;&#22343;&#20809;&#28369;&#24230;&#30340;&#26080;&#21442;&#22238;&#24402;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#26080;&#20998;&#24067;&#38480;&#21046;&#19979;&#30340;&#32479;&#19968;&#25910;&#25947;&#30028;&#38480;&#21644;&#39640;&#25928;&#26080;&#20559;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#38750;&#21442;&#25968;&#22238;&#24402;&#20013;&#26080;&#20998;&#24067;&#38480;&#21046;&#30340;&#24179;&#22343;&#20809;&#28369;&#24230;&#27010;&#24565;&#65292;&#35813;&#27010;&#24565;&#30001;Ashlagi&#31561;&#20154;&#65288;2021&#65289;&#25552;&#20986;&#65292;&#29992;&#20110;&#34913;&#37327;&#20989;&#25968;&#30456;&#23545;&#20110;&#20219;&#24847;&#26410;&#30693;&#28508;&#22312;&#20998;&#24067;&#30340;"&#26377;&#25928;"&#20809;&#28369;&#24230;&#12290;&#26368;&#36817;&#30340;Hanneke&#31561;&#20154;&#65288;2023&#65289;&#30340;&#30740;&#31350;&#22312;&#21487;&#23454;&#29616;&#24773;&#20917;&#19979;&#24314;&#31435;&#20102;&#24179;&#22343;&#20809;&#28369;&#20989;&#25968;&#30340;&#32039;&#23494;&#19968;&#33268;&#25910;&#25947;&#30028;&#38480;&#65292;&#24182;&#25552;&#20379;&#20102;&#20855;&#26377;&#39640;&#25928;&#21487;&#23454;&#29616;&#24615;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#20294;&#36825;&#20123;&#32467;&#26524;&#30446;&#21069;&#22312;&#26222;&#36941;&#26080;&#20559;&#65288;&#21363;&#26377;&#22122;&#22768;&#65289;&#24773;&#20917;&#19979;&#23578;&#32570;&#20047;&#31867;&#20284;&#32467;&#26524;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23436;&#20840;&#22635;&#34917;&#20102;&#36825;&#20123;&#24046;&#36317;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#20026;&#26080;&#20559;&#35774;&#32622;&#20013;&#30340;&#24179;&#22343;&#20809;&#28369;&#31867;&#25552;&#20379;&#20102;&#19968;&#20010;&#26080;&#20998;&#24067;&#19968;&#33268;&#25910;&#25947;&#30028;&#38480;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#23558;&#25152;&#24471;&#21040;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#19982;&#19968;&#20010;&#20855;&#26377;&#39640;&#25928;&#26080;&#20559;&#23398;&#20064;&#31639;&#27861;&#30456;&#21305;&#37197;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20197;&#25968;&#25454;&#30340;&#20869;&#22312;&#20960;&#20309;&#24418;&#29366;&#20026;&#22522;&#30784;&#65292;&#36866;&#29992;&#20110;&#20219;&#20309;&#20840;&#26377;&#30028;&#24230;&#37327;&#31354;&#38388;&#65292;&#24182;&#23637;&#31034;&#20102;&#26368;&#36817;&#22312;&#21487;&#23454;&#29616;&#24773;&#20917;&#19979;&#33719;&#24471;&#30340;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study distribution-free nonparametric regression following a notion of average smoothness initiated by Ashlagi et al. (2021), which measures the "effective" smoothness of a function with respect to an arbitrary unknown underlying distribution. While the recent work of Hanneke et al. (2023) established tight uniform convergence bounds for average-smooth functions in the realizable case and provided a computationally efficient realizable learning algorithm, both of these results currently lack analogs in the general agnostic (i.e. noisy) case.  In this work, we fully close these gaps. First, we provide a distribution-free uniform convergence bound for average-smoothness classes in the agnostic setting. Second, we match the derived sample complexity with a computationally efficient agnostic learning algorithm. Our results, which are stated in terms of the intrinsic geometry of the data and hold over any totally bounded metric space, show that the guarantees recently obtained for realiz
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20027;&#35201;&#20197;&#26080;&#31351;&#23485;&#24230;&#21644;&#22823;&#23485;&#24230;&#33539;&#22260;&#20869;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20026;&#30740;&#31350;&#23545;&#35937;&#65292;&#35752;&#35770;&#20102;&#36825;&#20123;&#32593;&#32476;&#30340;&#21508;&#31181;&#32479;&#35745;&#21644;&#21160;&#21147;&#23398;&#29305;&#24615;&#65292;&#21253;&#25324;&#38543;&#26426;&#32593;&#32476;&#30340;&#24615;&#36136;&#12289;&#35757;&#32451;&#21518;&#30340;&#32593;&#32476;&#19982;&#32447;&#24615;&#27169;&#22411;&#12289;&#26680;&#20989;&#25968;&#21644;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#20197;&#21450;&#23545;&#22823;&#20294;&#26377;&#38480;&#23485;&#24230;&#32593;&#32476;&#22312;&#21021;&#22987;&#21270;&#21644;&#35757;&#32451;&#21518;&#30340;&#25668;&#21160;&#21644;&#38750;&#25668;&#21160;&#22788;&#29702;&#12290;</title><link>http://arxiv.org/abs/2309.01592</link><description>&lt;p&gt;
&#22823;&#23610;&#24230;&#21644;&#26080;&#31351;&#23485;&#24230;&#19979;&#30340;&#28145;&#24230;&#23398;&#20064;&#21202;&#35753;&#28436;&#35762;
&lt;/p&gt;
&lt;p&gt;
Les Houches Lectures on Deep Learning at Large &amp; Infinite Width. (arXiv:2309.01592v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01592
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20027;&#35201;&#20197;&#26080;&#31351;&#23485;&#24230;&#21644;&#22823;&#23485;&#24230;&#33539;&#22260;&#20869;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20026;&#30740;&#31350;&#23545;&#35937;&#65292;&#35752;&#35770;&#20102;&#36825;&#20123;&#32593;&#32476;&#30340;&#21508;&#31181;&#32479;&#35745;&#21644;&#21160;&#21147;&#23398;&#29305;&#24615;&#65292;&#21253;&#25324;&#38543;&#26426;&#32593;&#32476;&#30340;&#24615;&#36136;&#12289;&#35757;&#32451;&#21518;&#30340;&#32593;&#32476;&#19982;&#32447;&#24615;&#27169;&#22411;&#12289;&#26680;&#20989;&#25968;&#21644;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#20197;&#21450;&#23545;&#22823;&#20294;&#26377;&#38480;&#23485;&#24230;&#32593;&#32476;&#22312;&#21021;&#22987;&#21270;&#21644;&#35757;&#32451;&#21518;&#30340;&#25668;&#21160;&#21644;&#38750;&#25668;&#21160;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#20123;&#28436;&#35762;&#26159;&#22312;2022&#24180;&#21202;&#35753;&#22799;&#23395;&#23398;&#26657;&#32479;&#35745;&#29289;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#35838;&#31243;&#19978;&#23637;&#31034;&#30340;&#65292;&#30528;&#37325;&#25506;&#35752;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#26080;&#38480;&#23485;&#24230;&#21644;&#22823;&#23485;&#24230;&#33539;&#22260;&#20869;&#30340;&#24773;&#20917;&#12290;&#28085;&#30422;&#30340;&#20027;&#39064;&#21253;&#25324;&#36825;&#20123;&#32593;&#32476;&#30340;&#21508;&#31181;&#32479;&#35745;&#21644;&#21160;&#21147;&#23398;&#29305;&#24615;&#12290;&#29305;&#21035;&#26159;&#65292;&#35762;&#24072;&#20204;&#35752;&#35770;&#20102;&#38543;&#26426;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#29305;&#24615;&#65307;&#35757;&#32451;&#36807;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#32447;&#24615;&#27169;&#22411;&#65292;&#26680;&#20989;&#25968;&#21644;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#36825;&#20123;&#32852;&#31995;&#22312;&#26080;&#31351;&#23485;&#24230;&#30340;&#26497;&#38480;&#19979;&#20986;&#29616;&#65307;&#20197;&#21450;&#22312;&#21021;&#22987;&#21270;&#21644;&#35757;&#32451;&#21518;&#23545;&#22823;&#20294;&#26377;&#38480;&#23485;&#24230;&#32593;&#32476;&#30340;&#25668;&#21160;&#21644;&#38750;&#25668;&#21160;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
These lectures, presented at the 2022 Les Houches Summer School on Statistical Physics and Machine Learning, focus on the infinite-width limit and large-width regime of deep neural networks. Topics covered include various statistical and dynamical properties of these networks. In particular, the lecturers discuss properties of random deep neural networks; connections between trained deep neural networks, linear models, kernels, and Gaussian processes that arise in the infinite-width limit; and perturbative and non-perturbative treatments of large but finite-width networks, at initialization and after training.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#26399;&#21464;&#20998;&#25512;&#26029;&#20316;&#20026;&#36817;&#20284;&#21518;&#39564;&#25512;&#26029;&#30340;&#19968;&#31181;&#36890;&#29992;&#26367;&#20195;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#20309;&#26102;&#33021;&#22815;&#36798;&#21040;&#19982;&#20256;&#32479;&#30340;&#22240;&#23376;&#21270;&#21464;&#20998;&#25512;&#26029;&#30456;&#21516;&#30340;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2307.11018</link><description>&lt;p&gt;
&#20998;&#26399;&#21464;&#20998;&#25512;&#26029;&#65306;&#20309;&#26102;&#20197;&#21450;&#20026;&#20160;&#20040;&#20351;&#29992;&#65311;
&lt;/p&gt;
&lt;p&gt;
Amortized Variational Inference: When and Why?. (arXiv:2307.11018v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11018
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#26399;&#21464;&#20998;&#25512;&#26029;&#20316;&#20026;&#36817;&#20284;&#21518;&#39564;&#25512;&#26029;&#30340;&#19968;&#31181;&#36890;&#29992;&#26367;&#20195;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#20309;&#26102;&#33021;&#22815;&#36798;&#21040;&#19982;&#20256;&#32479;&#30340;&#22240;&#23376;&#21270;&#21464;&#20998;&#25512;&#26029;&#30456;&#21516;&#30340;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#26399;&#21464;&#20998;&#25512;&#26029;&#65288;A-VI&#65289;&#26159;&#19968;&#31181;&#36817;&#20284;&#22788;&#29702;&#27010;&#29575;&#27169;&#22411;&#20013;&#30340;&#38590;&#20197;&#35745;&#31639;&#30340;&#21518;&#39564;&#20998;&#24067;&#30340;&#26041;&#27861;&#12290;A-VI&#30340;&#23450;&#20041;&#29305;&#28857;&#26159;&#23398;&#20064;&#19968;&#20010;&#20840;&#23616;&#25512;&#26029;&#20989;&#25968;&#65292;&#23558;&#27599;&#20010;&#35266;&#23519;&#26144;&#23556;&#21040;&#20854;&#23616;&#37096;&#28508;&#21464;&#37327;&#30340;&#36817;&#20284;&#21518;&#39564;&#20998;&#24067;&#12290;&#36825;&#19982;&#26356;&#20256;&#32479;&#30340;&#20998;&#35299;&#65288;&#25110;&#22343;&#22330;&#65289;&#21464;&#20998;&#25512;&#26029;&#65288;F-VI&#65289;&#24418;&#25104;&#23545;&#27604;&#65292;&#21518;&#32773;&#30452;&#25509;&#23398;&#20064;&#27599;&#20010;&#28508;&#21464;&#37327;&#30340;&#36817;&#20284;&#20998;&#24067;&#30340;&#21442;&#25968;&#12290;&#22312;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#20013;&#65292;A-VI&#29992;&#20316;&#21152;&#36895;&#23616;&#37096;&#28508;&#21464;&#37327;&#25512;&#26029;&#30340;&#35745;&#31639;&#25216;&#24039;&#12290;&#26412;&#25991;&#30740;&#31350;A-VI&#20316;&#20026;&#36817;&#20284;&#21518;&#39564;&#25512;&#26029;&#30340;&#19968;&#31181;&#36890;&#29992;&#26367;&#20195;&#26041;&#27861;&#12290;&#30001;&#20110;&#20998;&#26399;&#23478;&#26063;&#26159;&#20998;&#35299;&#23478;&#26063;&#30340;&#23376;&#38598;&#65292;A-VI&#26080;&#27861;&#20135;&#29983;&#27604;F-VI&#26368;&#20248;&#35299;&#26356;&#20302;&#30340;Kullback-Leibler&#25955;&#24230;&#30340;&#36817;&#20284;&#20540;&#12290;&#22240;&#27492;&#65292;&#19968;&#20010;&#26680;&#24515;&#30340;&#29702;&#35770;&#38382;&#39064;&#26159;&#21051;&#30011;A-VI&#20309;&#26102;&#20173;&#28982;&#36798;&#21040;F-VI&#30340;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Amortized variational inference (A-VI) is a method for approximating the intractable posterior distributions that arise in probabilistic models. The defining feature of A-VI is that it learns a global inference function that maps each observation to its local latent variable's approximate posterior. This stands in contrast to the more classical factorized (or mean-field) variational inference (F-VI), which directly learns the parameters of the approximating distribution for each latent variable. In deep generative models, A-VI is used as a computational trick to speed up inference for local latent variables. In this paper, we study A-VI as a general alternative to F-VI for approximate posterior inference. A-VI cannot produce an approximation with a lower Kullback-Leibler divergence than F-VI's optimal solution, because the amortized family is a subset of the factorized family. Thus a central theoretical problem is to characterize when A-VI still attains F-VI's optimal solution. We deri
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#20989;&#25968;&#35299;&#37322;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#22120;&#12290;&#37319;&#26679;&#22120;&#34920;&#29616;&#20986;&#20102;&#26368;&#20808;&#36827;&#30340;FID&#24471;&#20998;&#65292;&#24182;&#33021;&#22815;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#12290;</title><link>http://arxiv.org/abs/2306.04848</link><description>&lt;p&gt;
&#21033;&#29992;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#20989;&#25968;&#35299;&#37322;&#21644;&#25913;&#36827;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Interpreting and Improving Diffusion Models Using the Euclidean Distance Function. (arXiv:2306.04848v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04848
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#20989;&#25968;&#35299;&#37322;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#22120;&#12290;&#37319;&#26679;&#22120;&#34920;&#29616;&#20986;&#20102;&#26368;&#20808;&#36827;&#30340;FID&#24471;&#20998;&#65292;&#24182;&#33021;&#22815;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21435;&#22122;&#30452;&#35273;&#19978;&#19982;&#25237;&#24433;&#26377;&#20851;&#12290;&#20107;&#23454;&#19978;&#65292;&#22312;&#27969;&#24418;&#20551;&#35774;&#19979;&#65292;&#28155;&#21152;&#38543;&#26426;&#22122;&#22768;&#36817;&#20284;&#31561;&#20215;&#20110;&#27491;&#20132;&#25200;&#21160;&#12290;&#22240;&#27492;&#65292;&#23398;&#20064;&#21435;&#22122;&#36817;&#20284;&#20110;&#23398;&#20064;&#25237;&#24433;&#12290;&#26412;&#25991;&#21033;&#29992;&#36825;&#19968;&#35266;&#23519;&#32467;&#26524;&#65292;&#23558;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#35299;&#37322;&#20026;&#24212;&#29992;&#20110;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#20989;&#25968;&#30340;&#36817;&#20284;&#26799;&#24230;&#19979;&#38477;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#22522;&#20110;&#23545;&#21435;&#22122;&#22120;&#25237;&#24433;&#35823;&#24046;&#30340;&#31616;&#21333;&#20551;&#35774;&#65292;&#25552;&#20379;DDIM&#65288;Denoising Diffusion Implicit Models&#65289;&#37319;&#26679;&#22120;&#30340;&#31616;&#21333;&#25910;&#25947;&#20998;&#26512;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22522;&#20110;&#29702;&#35770;&#32467;&#26524;&#30340;&#27934;&#35265;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#23545;DDIM&#30340;&#20004;&#20010;&#31616;&#21333;&#20462;&#25913;&#30340;&#26032;&#37319;&#26679;&#22120;&#12290;&#20165;&#38656;&#35201;5-10&#20010;&#20989;&#25968;&#35780;&#20272;&#65292;&#25105;&#20204;&#30340;&#37319;&#26679;&#22120;&#23601;&#33021;&#22312;&#39044;&#35757;&#32451;&#30340;CIFAR-10&#21644;CelebA&#27169;&#22411;&#19978;&#36798;&#21040;&#26368;&#20808;&#36827;&#30340;FID&#24471;&#20998;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#19978;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Denoising is intuitively related to projection. Indeed, under the manifold hypothesis, adding random noise is approximately equivalent to orthogonal perturbation. Hence, learning to denoise is approximately learning to project. In this paper, we use this observation to reinterpret denoising diffusion models as approximate gradient descent applied to the Euclidean distance function. We then provide straight-forward convergence analysis of the DDIM sampler under simple assumptions on the projection-error of the denoiser. Finally, we propose a new sampler based on two simple modifications to DDIM using insights from our theoretical results. In as few as 5-10 function evaluations, our sampler achieves state-of-the-art FID scores on pretrained CIFAR-10 and CelebA models and can generate high quality samples on latent diffusion models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#27979;&#37327;&#33410;&#28857;&#20043;&#38388;&#25104;&#23545;&#20132;&#20114;&#30340;&#27700;&#24179;&#65292;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#20998;&#26512;&#65292;&#20197;&#30830;&#23450;&#20855;&#26377;&#19968;&#23450;&#23481;&#37327;&#30340;MPNN&#21487;&#20197;&#23398;&#20064;&#21738;&#20123;&#33410;&#28857;&#29305;&#24449;&#30340;&#20989;&#25968;&#31867;&#21035;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#20026;&#20102;&#20445;&#35777;&#33410;&#28857;&#23545;&#20043;&#38388;&#30340;&#20805;&#20998;&#36890;&#20449;&#65292;MPNN&#30340;&#23481;&#37327;&#24517;&#39035;&#26159;...</title><link>http://arxiv.org/abs/2306.03589</link><description>&lt;p&gt;
&#36807;&#24230;&#21387;&#32553;&#22914;&#20309;&#24433;&#21709;GNN&#30340;&#33021;&#21147;&#65311;
&lt;/p&gt;
&lt;p&gt;
How does over-squashing affect the power of GNNs?. (arXiv:2306.03589v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03589
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#27979;&#37327;&#33410;&#28857;&#20043;&#38388;&#25104;&#23545;&#20132;&#20114;&#30340;&#27700;&#24179;&#65292;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#20998;&#26512;&#65292;&#20197;&#30830;&#23450;&#20855;&#26377;&#19968;&#23450;&#23481;&#37327;&#30340;MPNN&#21487;&#20197;&#23398;&#20064;&#21738;&#20123;&#33410;&#28857;&#29305;&#24449;&#30340;&#20989;&#25968;&#31867;&#21035;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#20026;&#20102;&#20445;&#35777;&#33410;&#28857;&#23545;&#20043;&#38388;&#30340;&#20805;&#20998;&#36890;&#20449;&#65292;MPNN&#30340;&#23481;&#37327;&#24517;&#39035;&#26159;...
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#26159;&#22788;&#29702;&#22270;&#32467;&#26500;&#25968;&#25454;&#30340;&#26426;&#22120;&#23398;&#20064;&#30340;&#26368;&#20808;&#36827;&#27169;&#22411;&#12290;&#26368;&#27969;&#34892;&#30340;GNN&#31867;&#21035;&#26159;&#36890;&#36807;&#30456;&#37051;&#33410;&#28857;&#38388;&#30340;&#20449;&#24687;&#20132;&#25442;&#26469;&#25805;&#20316;&#30340;&#65292;&#31216;&#20026;&#28040;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#65288;MPNN&#65289;&#12290;&#37492;&#20110;&#23427;&#20204;&#30340;&#24191;&#27867;&#24212;&#29992;&#65292;&#20102;&#35299;MPNN&#30340;&#34920;&#36798;&#33021;&#21147;&#26159;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#32467;&#26524;&#36890;&#24120;&#32771;&#34385;&#20855;&#26377;&#26080;&#20449;&#24687;&#33410;&#28857;&#29305;&#24449;&#30340;&#29615;&#22659;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#20005;&#26684;&#30340;&#20998;&#26512;&#26041;&#27861;&#65292;&#20197;&#30830;&#23450;&#20855;&#26377;&#19968;&#23450;&#23481;&#37327;&#30340;MPNN&#21487;&#20197;&#23398;&#20064;&#21738;&#20123;&#33410;&#28857;&#29305;&#24449;&#30340;&#20989;&#25968;&#31867;&#21035;&#12290;&#25105;&#20204;&#36890;&#36807;&#27979;&#37327;MPNN&#20801;&#35768;&#30340;&#33410;&#28857;&#20043;&#38388;&#30340;&#25104;&#23545;&#20132;&#20114;&#27700;&#24179;&#26469;&#23454;&#29616;&#27492;&#30446;&#30340;&#12290;&#35813;&#27979;&#37327;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#37327;&#21270;&#29305;&#24615;&#65292;&#21363;&#25152;&#35859;&#30340;&#36807;&#24230;&#21387;&#32553;&#25928;&#24212;&#65292;&#35813;&#25928;&#24212;&#34987;&#35266;&#23519;&#21040;&#26159;&#24403;&#22823;&#37327;&#30340;&#20449;&#24687;&#32858;&#21512;&#25104;&#22266;&#23450;&#22823;&#23567;&#30340;&#21521;&#37327;&#26102;&#21457;&#29983;&#30340;&#12290;&#20351;&#29992;&#25105;&#20204;&#30340;&#27979;&#37327;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#20026;&#20102;&#20445;&#35777;&#33410;&#28857;&#23545;&#20043;&#38388;&#30340;&#20805;&#20998;&#36890;&#20449;&#65292;MPNN&#30340;&#23481;&#37327;&#24517;&#39035;&#26159;...
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) are the state-of-the-art model for machine learning on graph-structured data. The most popular class of GNNs operate by exchanging information between adjacent nodes, and are known as Message Passing Neural Networks (MPNNs). Given their widespread use, understanding the expressive power of MPNNs is a key question. However, existing results typically consider settings with uninformative node features. In this paper, we provide a rigorous analysis to determine which function classes of node features can be learned by an MPNN of a given capacity. We do so by measuring the level of pairwise interactions between nodes that MPNNs allow for. This measure provides a novel quantitative characterization of the so-called over-squashing effect, which is observed to occur when a large volume of messages is aggregated into fixed-size vectors. Using our measure, we prove that, to guarantee sufficient communication between pairs of nodes, the capacity of the MPNN must be l
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#31283;&#23450;&#24615;&#24809;&#32602;&#33258;&#36866;&#24212;&#65288;SPA&#65289;&#23398;&#20064;&#29575;&#65292;&#35813;&#23398;&#20064;&#29575;&#20351;FTRL&#20855;&#26377;&#31232;&#30095;&#24615;&#12289;&#28216;&#25103;&#20381;&#36182;&#24615;&#21644;&#26368;&#20339;&#19990;&#30028;&#65288;BOBW&#65289;&#19977;&#31181;&#36866;&#24212;&#24615;&#31867;&#22411;&#65292;&#20854;&#20013;SPA-sparse&#31639;&#27861;&#21487;&#36866;&#24212;&#20110;&#26410;&#30693;&#30340;&#31232;&#30095;&#32423;&#21035;&#65292;SPA-game-dependency&#31639;&#27861;&#21487;&#26681;&#25454;&#25152;&#29609;&#30340;&#28216;&#25103;&#33258;&#36866;&#24212;&#22320;&#25913;&#21464;&#20854;&#34892;&#20026;&#65292;BOBW&#31639;&#27861;&#21017;&#26159;&#26082;&#20855;&#26377;&#31232;&#30095;&#24615;&#21448;&#20855;&#26377;&#28216;&#25103;&#20381;&#36182;&#24615;&#30340;&#36866;&#24212;&#24615;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.17301</link><description>&lt;p&gt;
&#31283;&#23450;&#24615;&#24809;&#32602;&#33258;&#36866;&#24212;&#36319;&#38543;&#27491;&#21017;&#21270;&#39046;&#34966;&#65306;&#31232;&#30095;&#24615;&#12289;&#28216;&#25103;&#20381;&#36182;&#24615;&#21644;&#26368;&#20339;&#19990;&#30028;&#30340;&#24182;&#23384;
&lt;/p&gt;
&lt;p&gt;
Stability-penalty-adaptive Follow-the-regularized-leader: Sparsity, Game-dependency, and Best-of-both-worlds. (arXiv:2305.17301v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17301
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#31283;&#23450;&#24615;&#24809;&#32602;&#33258;&#36866;&#24212;&#65288;SPA&#65289;&#23398;&#20064;&#29575;&#65292;&#35813;&#23398;&#20064;&#29575;&#20351;FTRL&#20855;&#26377;&#31232;&#30095;&#24615;&#12289;&#28216;&#25103;&#20381;&#36182;&#24615;&#21644;&#26368;&#20339;&#19990;&#30028;&#65288;BOBW&#65289;&#19977;&#31181;&#36866;&#24212;&#24615;&#31867;&#22411;&#65292;&#20854;&#20013;SPA-sparse&#31639;&#27861;&#21487;&#36866;&#24212;&#20110;&#26410;&#30693;&#30340;&#31232;&#30095;&#32423;&#21035;&#65292;SPA-game-dependency&#31639;&#27861;&#21487;&#26681;&#25454;&#25152;&#29609;&#30340;&#28216;&#25103;&#33258;&#36866;&#24212;&#22320;&#25913;&#21464;&#20854;&#34892;&#20026;&#65292;BOBW&#31639;&#27861;&#21017;&#26159;&#26082;&#20855;&#26377;&#31232;&#30095;&#24615;&#21448;&#20855;&#26377;&#28216;&#25103;&#20381;&#36182;&#24615;&#30340;&#36866;&#24212;&#24615;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39034;&#24207;&#20915;&#31574;&#38382;&#39064;&#20013;&#65292;&#36866;&#24212;&#38382;&#39064;&#30340;&#22256;&#38590;&#31243;&#24230;&#26159;&#25193;&#23637;&#31639;&#27861;&#36866;&#29992;&#24615;&#30340;&#20851;&#38190;&#23646;&#24615;&#12290;&#36319;&#38543;&#27491;&#21017;&#21270;&#39046;&#34966;&#36817;&#24180;&#26469;&#25104;&#20026;&#33719;&#21462;&#28120;&#27760;&#27861;&#20013;&#21508;&#31181;&#31867;&#22411;&#36866;&#24212;&#24615;&#30340;&#26368;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#20043;&#19968;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#25512;&#24191;&#36825;&#31181;&#36866;&#24212;&#24615;&#65292;&#25105;&#20204;&#20026;FTRL&#24320;&#21457;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#65292;&#31216;&#20026;&#31283;&#23450;&#24615;&#24809;&#32602;&#33258;&#36866;&#24212;&#65288;SPA&#65289;&#23398;&#20064;&#29575;&#12290;&#35813;&#23398;&#20064;&#29575;&#20135;&#29983;&#30340;&#36951;&#25022;&#30028;&#20849;&#21516;&#21462;&#20915;&#20110;&#31639;&#27861;&#30340;&#31283;&#23450;&#24615;&#21644;&#24809;&#32602;&#65292;&#20854;&#20013;FTRL&#30340;&#36951;&#25022;&#36890;&#24120;&#34987;&#20998;&#35299;&#12290;&#20973;&#20511;&#36825;&#20010;&#32467;&#26524;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#20960;&#20010;&#20855;&#26377;&#19977;&#31181;&#36866;&#24212;&#24615;&#31867;&#22411;&#30340;&#31639;&#27861;&#65306;&#31232;&#30095;&#24615;&#12289;&#28216;&#25103;&#20381;&#36182;&#24615;&#21644;&#26368;&#20339;&#19990;&#30028;&#65288;BOBW&#65289;&#12290;&#31232;&#30095;&#24615;&#32463;&#24120;&#20986;&#29616;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#38382;&#39064;&#20013;&#65292;&#20294;&#26159;&#65292;&#29616;&#26377;&#30340;&#31232;&#30095;&#22810;&#33218;&#36172;&#21338;&#31639;&#27861;$k$-arms&#20551;&#23450;&#20107;&#20808;&#24050;&#30693;&#31232;&#30095;&#32423;&#21035;$s \leq k$&#65292;&#32780;&#36825;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#24773;&#20917;&#19979;&#36890;&#24120;&#19981;&#26159;&#24773;&#20917;&#12290;&#20026;&#20102;&#36866;&#24212;&#26410;&#30693;&#30340;&#31232;&#30095;&#32423;&#21035;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;SPA-sparse&#65292;&#35813;&#31639;&#27861;&#26174;&#31034;&#27604;&#29616;&#26377;&#31232;&#30095;&#31639;&#27861;&#30340;&#24615;&#33021;&#25552;&#39640;&#20102;&#12290;&#28216;&#25103;&#20381;&#36182;&#24615;&#26159;&#21478;&#19968;&#31181;&#36866;&#24212;&#24615;&#31867;&#22411;&#65292;&#24403;&#29992;&#20110;&#29983;&#25104;&#25968;&#25454;&#30340;&#28216;&#25103;&#21457;&#29983;&#21464;&#21270;&#26102;&#65292;&#21363;&#24517;&#38656;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;SPA-game-dependency&#65292;&#35813;&#31639;&#27861;&#26681;&#25454;&#25152;&#29609;&#30340;&#28216;&#25103;&#33258;&#36866;&#24212;&#22320;&#25913;&#21464;&#20854;&#34892;&#20026;&#65292;&#24182;&#34920;&#26126;&#23427;&#27604;&#38750;&#33258;&#36866;&#24212;&#31639;&#27861;&#30340;&#24615;&#33021;&#26356;&#22909;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26082;&#20855;&#26377;&#31232;&#30095;&#24615;&#21448;&#20855;&#26377;&#28216;&#25103;&#20381;&#36182;&#24615;&#36866;&#24212;&#24615;&#30340;BOBW&#31639;&#27861;&#65292;&#24182;&#26174;&#31034;&#23427;&#27604;&#20165;&#38598;&#20013;&#20110;&#19968;&#31181;&#36866;&#24212;&#24615;&#31867;&#22411;&#30340;&#31639;&#27861;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adaptivity to the difficulties of a problem is a key property in sequential decision-making problems to broaden the applicability of algorithms. Follow-the-Regularized-Leader (FTRL) has recently emerged as one of the most promising approaches for obtaining various types of adaptivity in bandit problems. Aiming to further generalize this adaptivity, we develop a generic adaptive learning rate, called Stability-Penalty-Adaptive (SPA) learning rate for FTRL. This learning rate yields a regret bound jointly depending on stability and penalty of the algorithm, into which the regret of FTRL is typically decomposed. With this result, we establish several algorithms with three types of adaptivity: sparsity, game-dependency, and Best-of-Both-Worlds (BOBW). Sparsity frequently appears in real-world problems. However, existing sparse multi-armed bandit algorithms with $k$-arms assume that the sparsity level $s \leq k$ is known in advance, which is often not the case in real-world scenarios. To ad
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20195;&#20215;&#24863;&#30693;&#30340;&#27169;&#22411;&#36873;&#25321;BO&#26041;&#27861;SADCBO&#65292;&#36890;&#36807;&#23545;&#21518;&#39564;&#20195;&#29702;&#27169;&#22411;&#30340;&#25935;&#24863;&#24615;&#20998;&#26512;&#26469;&#23398;&#20064;&#20851;&#20110;&#29615;&#22659;&#30340;&#30456;&#20851;&#24773;&#22659;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#24179;&#22343;&#27169;&#22411;&#39044;&#27979;&#26469;&#26368;&#23567;&#21270;&#20248;&#21270;&#20195;&#20215;&#65292;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.14120</link><description>&lt;p&gt;
&#22522;&#20110;&#20195;&#20215;&#24863;&#30693;&#30340;&#24773;&#22659;&#21464;&#37327;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Cost-aware learning of relevant contextual variables within Bayesian optimization. (arXiv:2305.14120v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14120
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20195;&#20215;&#24863;&#30693;&#30340;&#27169;&#22411;&#36873;&#25321;BO&#26041;&#27861;SADCBO&#65292;&#36890;&#36807;&#23545;&#21518;&#39564;&#20195;&#29702;&#27169;&#22411;&#30340;&#25935;&#24863;&#24615;&#20998;&#26512;&#26469;&#23398;&#20064;&#20851;&#20110;&#29615;&#22659;&#30340;&#30456;&#20851;&#24773;&#22659;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#24179;&#22343;&#27169;&#22411;&#39044;&#27979;&#26469;&#26368;&#23567;&#21270;&#20248;&#21270;&#20195;&#20215;&#65292;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24773;&#22659;&#36125;&#21494;&#26031;&#20248;&#21270;(CBO)&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#26694;&#26550;&#65292;&#21487;&#38024;&#23545;&#35774;&#35745;&#21464;&#37327;&#20248;&#21270;&#40657;&#30418;&#26114;&#36149;&#30340;&#35780;&#20272;&#20989;&#25968;&#65292;&#24182;&#21516;&#26102;&#26377;&#25928;&#22320;&#25972;&#21512;&#20851;&#20110;&#29615;&#22659;&#30340;&#30456;&#20851;&#24773;&#22659;&#20449;&#24687;&#65292;&#22914;&#23454;&#39564;&#26465;&#20214;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#23454;&#38469;&#22330;&#26223;&#20013;&#65292;&#24773;&#22659;&#21464;&#37327;&#30340;&#30456;&#20851;&#24615;&#19981;&#19968;&#23450;&#26159;&#39044;&#20808;&#24050;&#30693;&#30340;&#12290;&#27492;&#22806;&#65292;&#26377;&#26102;&#36824;&#21487;&#20197;&#26368;&#20248;&#21270;&#24773;&#22659;&#21464;&#37327;&#26412;&#36523;&#65292;&#36825;&#26159;&#24403;&#21069;CBO&#31639;&#27861;&#26410;&#32771;&#34385;&#30340;&#35774;&#32622;&#12290;&#20248;&#21270;&#24773;&#22659;&#21464;&#37327;&#21487;&#33021;&#26159;&#26114;&#36149;&#30340;&#65292;&#36825;&#24341;&#20986;&#20102;&#30830;&#23450;&#19968;&#20010;&#26368;&#23567;&#30456;&#20851;&#23376;&#38598;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#38382;&#39064;&#20316;&#20026;&#19968;&#20010;&#20195;&#20215;&#24863;&#30693;&#30340;&#27169;&#22411;&#36873;&#25321;BO&#20219;&#21153;&#26469;&#26500;&#26550;&#65292;&#37319;&#29992;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21363;&#22522;&#20110;&#25935;&#24863;&#24615;&#20998;&#26512;&#30340;&#24773;&#22659;BO (SADCBO) &#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#29305;&#23450;&#36755;&#20837;&#28857;&#21518;&#39564;&#20195;&#29702;&#27169;&#22411;&#30340;&#25935;&#24863;&#24615;&#20998;&#26512;&#26469;&#23398;&#20064;&#24773;&#22659;&#21464;&#37327;&#30340;&#30456;&#20851;&#24615;&#65292;&#21516;&#26102;&#36890;&#36807;&#24179;&#22343;&#27169;&#22411;&#39044;&#27979;&#26469;&#26368;&#23567;&#21270;&#20248;&#21270;&#30340;&#20195;&#20215;&#12290;SADCBO&#22312;&#22810;&#20010;&#21512;&#25104;&#21644;&#30495;&#23454;&#22522;&#20934;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#65292;&#26174;&#31034;&#20986;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Contextual Bayesian Optimization (CBO) is a powerful framework for optimizing black-box, expensive-to-evaluate functions with respect to design variables, while simultaneously efficiently integrating relevant contextual information regarding the environment, such as experimental conditions. However, in many practical scenarios, the relevance of contextual variables is not necessarily known beforehand. Moreover, the contextual variables can sometimes be optimized themselves, a setting that current CBO algorithms do not take into account. Optimizing contextual variables may be costly, which raises the question of determining a minimal relevant subset. In this paper, we frame this problem as a cost-aware model selection BO task and address it using a novel method, Sensitivity-Analysis-Driven Contextual BO (SADCBO). We learn the relevance of context variables by sensitivity analysis of the posterior surrogate model at specific input points, whilst minimizing the cost of optimization by lev
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#30456;&#20851;&#32858;&#31867;&#20013;&#25104;&#23545;&#30456;&#20284;&#24615;&#19981;&#20107;&#20808;&#32473;&#20986;&#30340;&#24773;&#20917;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#20027;&#21160;&#23398;&#20064;&#26694;&#26550;&#65292;&#36866;&#24212;&#21508;&#31181;&#30456;&#20851;&#32858;&#31867;&#31639;&#27861;&#21644;&#26597;&#35810;&#31574;&#30053;&#65292;&#21516;&#26102;&#20855;&#26377;&#36866;&#24212;&#24615;&#28789;&#27963;&#12289;&#22122;&#22768;&#40065;&#26834;&#24615;&#31561;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2302.10295</link><description>&lt;p&gt;
&#20351;&#29992;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#30340;&#30456;&#20851;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Correlation Clustering with Active Learning of Pairwise Similarities. (arXiv:2302.10295v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10295
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#30456;&#20851;&#32858;&#31867;&#20013;&#25104;&#23545;&#30456;&#20284;&#24615;&#19981;&#20107;&#20808;&#32473;&#20986;&#30340;&#24773;&#20917;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#20027;&#21160;&#23398;&#20064;&#26694;&#26550;&#65292;&#36866;&#24212;&#21508;&#31181;&#30456;&#20851;&#32858;&#31867;&#31639;&#27861;&#21644;&#26597;&#35810;&#31574;&#30053;&#65292;&#21516;&#26102;&#20855;&#26377;&#36866;&#24212;&#24615;&#28789;&#27963;&#12289;&#22122;&#22768;&#40065;&#26834;&#24615;&#31561;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30456;&#20851;&#32858;&#31867;&#26159;&#19968;&#20010;&#20247;&#25152;&#21608;&#30693;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#35774;&#32622;&#65292;&#22788;&#29702;&#27491;&#36127;&#30456;&#20284;&#24615;&#23545;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#24773;&#20917;&#65292;&#21363;&#25104;&#23545;&#30456;&#20284;&#24615;&#19981;&#20107;&#20808;&#32473;&#20986;&#65292;&#24517;&#39035;&#20197;&#39640;&#25928;&#30340;&#26041;&#24335;&#26597;&#35810;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#20027;&#21160;&#23398;&#20064;&#26694;&#26550;&#65292;&#38024;&#23545;&#36825;&#20010;&#20219;&#21153;&#20855;&#26377;&#22810;&#31181;&#20248;&#21183;&#65292;&#20363;&#22914;&#65292;&#29992;&#25143;/&#27880;&#37322;&#32773;&#21487;&#20197;&#25552;&#20379;&#21508;&#31181;&#21453;&#39304;&#31867;&#22411;&#12289;&#36866;&#24212;&#20219;&#20309;&#30456;&#20851;&#32858;&#31867;&#31639;&#27861;&#21644;&#26597;&#35810;&#31574;&#30053;&#20197;&#21450;&#23545;&#22122;&#22768;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#21644;&#20998;&#26512;&#20102;&#19968;&#20123;&#36866;&#21512;&#36825;&#31181;&#35774;&#32622;&#30340;&#26032;&#30340;&#26597;&#35810;&#31574;&#30053;&#12290;&#36890;&#36807;&#20960;&#20010;&#23454;&#39564;&#30740;&#31350;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#26694;&#26550;&#21644;&#25152;&#25552;&#20986;&#30340;&#26597;&#35810;&#31574;&#30053;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Correlation clustering is a well-known unsupervised learning setting that deals with positive and negative pairwise similarities. In this paper, we study the case where the pairwise similarities are not given in advance and must be queried in a cost-efficient way. Thereby, we develop a generic active learning framework for this task that benefits from several advantages, e.g., flexibility in the type of feedback that a user/annotator can provide, adaptation to any correlation clustering algorithm and query strategy, and robustness to noise. In addition, we propose and analyze a number of novel query strategies suited to this setting. We demonstrate the effectiveness of our framework and the proposed query strategies via several experimental studies.
&lt;/p&gt;</description></item></channel></rss>