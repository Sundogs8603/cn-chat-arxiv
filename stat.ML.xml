<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#35774;&#35745;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27700;&#21360;&#30340;&#32479;&#35745;&#25928;&#29575;&#21644;&#26816;&#27979;&#35268;&#21017;&#65292;&#36890;&#36807;&#20851;&#38190;&#32479;&#35745;&#37327;&#21644;&#31192;&#23494;&#23494;&#38053;&#25511;&#21046;&#35823;&#25253;&#29575;&#65292;&#21516;&#26102;&#35780;&#20272;&#27700;&#21360;&#26816;&#27979;&#35268;&#21017;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2404.01245</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27700;&#21360;&#30340;&#32479;&#35745;&#26694;&#26550;: &#26530;&#36724;&#12289;&#26816;&#27979;&#25928;&#29575;&#21644;&#26368;&#20248;&#35268;&#21017;
&lt;/p&gt;
&lt;p&gt;
A Statistical Framework of Watermarks for Large Language Models: Pivot, Detection Efficiency and Optimal Rules
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01245
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#35774;&#35745;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27700;&#21360;&#30340;&#32479;&#35745;&#25928;&#29575;&#21644;&#26816;&#27979;&#35268;&#21017;&#65292;&#36890;&#36807;&#20851;&#38190;&#32479;&#35745;&#37327;&#21644;&#31192;&#23494;&#23494;&#38053;&#25511;&#21046;&#35823;&#25253;&#29575;&#65292;&#21516;&#26102;&#35780;&#20272;&#27700;&#21360;&#26816;&#27979;&#35268;&#21017;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;ChatGPT&#20110;2022&#24180;11&#26376;&#25512;&#20986;&#20197;&#26469;&#65292;&#23558;&#20960;&#20046;&#19981;&#21487;&#23519;&#35273;&#30340;&#32479;&#35745;&#20449;&#21495;&#23884;&#20837;&#21040;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#29983;&#25104;&#30340;&#25991;&#26412;&#20013;&#65292;&#20063;&#34987;&#31216;&#20026;&#27700;&#21360;&#65292;&#24050;&#34987;&#29992;&#20316;&#20174;&#20854;&#20154;&#31867;&#25776;&#20889;&#23545;&#24212;&#29289;&#19978;&#21487;&#35777;&#26816;&#27979;LLM&#29983;&#25104;&#25991;&#26412;&#30340;&#21407;&#21017;&#24615;&#26041;&#27861;&#12290; &#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#36890;&#29992;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#25512;&#29702;&#27700;&#21360;&#30340;&#32479;&#35745;&#25928;&#29575;&#24182;&#35774;&#35745;&#24378;&#22823;&#30340;&#26816;&#27979;&#35268;&#21017;&#12290;&#21463;&#27700;&#21360;&#26816;&#27979;&#30340;&#20551;&#35774;&#26816;&#39564;&#20844;&#24335;&#21551;&#21457;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#39318;&#20808;&#36873;&#25321;&#25991;&#26412;&#30340;&#26530;&#36724;&#32479;&#35745;&#37327;&#21644;&#30001;LLM&#25552;&#20379;&#32473;&#39564;&#35777;&#22120;&#30340;&#31192;&#23494;&#23494;&#38053;&#65292;&#20197;&#23454;&#29616;&#25511;&#21046;&#35823;&#25253;&#29575;&#65288;&#23558;&#20154;&#31867;&#25776;&#20889;&#30340;&#25991;&#26412;&#38169;&#35823;&#22320;&#26816;&#27979;&#20026;LLM&#29983;&#25104;&#30340;&#38169;&#35823;&#65289;&#12290; &#25509;&#19979;&#26469;&#65292;&#35813;&#26694;&#26550;&#20801;&#35768;&#36890;&#36807;&#33719;&#21462;&#28176;&#36817;&#38169;&#35823;&#36127;&#29575;&#65288;&#23558;LLM&#29983;&#25104;&#25991;&#26412;&#38169;&#35823;&#22320;&#26816;&#27979;&#20026;&#20154;&#31867;&#25776;&#20889;&#30340;&#38169;&#35823;&#65289;&#30340;&#23553;&#38381;&#24418;&#24335;&#34920;&#36798;&#24335;&#26469;&#35780;&#20272;&#27700;&#21360;&#26816;&#27979;&#35268;&#21017;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01245v1 Announce Type: cross  Abstract: Since ChatGPT was introduced in November 2022, embedding (nearly) unnoticeable statistical signals into text generated by large language models (LLMs), also known as watermarking, has been used as a principled approach to provable detection of LLM-generated text from its human-written counterpart. In this paper, we introduce a general and flexible framework for reasoning about the statistical efficiency of watermarks and designing powerful detection rules. Inspired by the hypothesis testing formulation of watermark detection, our framework starts by selecting a pivotal statistic of the text and a secret key -- provided by the LLM to the verifier -- to enable controlling the false positive rate (the error of mistakenly detecting human-written text as LLM-generated). Next, this framework allows one to evaluate the power of watermark detection rules by obtaining a closed-form expression of the asymptotic false negative rate (the error of 
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#38024;&#23545;&#20998;&#24067;&#22806;&#39044;&#27979;&#30340;&#26368;&#20248;&#23725;&#22238;&#24402;&#27491;&#21017;&#21270;&#19979;&#30340;&#34892;&#20026;&#65292;&#24182;&#24314;&#31435;&#20102;&#30830;&#23450;&#26368;&#20248;&#27491;&#21017;&#21270;&#27700;&#24179;&#30340;&#19968;&#33324;&#26465;&#20214;&#65292;&#25581;&#31034;&#20102;&#19982;&#20998;&#24067;&#20869;&#35774;&#32622;&#30340;&#40092;&#26126;&#24046;&#24322;&#12290;</title><link>https://arxiv.org/abs/2404.01233</link><description>&lt;p&gt;
&#38024;&#23545;&#20998;&#24067;&#22806;&#39044;&#27979;&#30340;&#26368;&#20248;&#23725;&#22238;&#24402;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Optimal Ridge Regularization for Out-of-Distribution Prediction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01233
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#38024;&#23545;&#20998;&#24067;&#22806;&#39044;&#27979;&#30340;&#26368;&#20248;&#23725;&#22238;&#24402;&#27491;&#21017;&#21270;&#19979;&#30340;&#34892;&#20026;&#65292;&#24182;&#24314;&#31435;&#20102;&#30830;&#23450;&#26368;&#20248;&#27491;&#21017;&#21270;&#27700;&#24179;&#30340;&#19968;&#33324;&#26465;&#20214;&#65292;&#25581;&#31034;&#20102;&#19982;&#20998;&#24067;&#20869;&#35774;&#32622;&#30340;&#40092;&#26126;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#38024;&#23545;&#20998;&#24067;&#22806;&#39044;&#27979;&#30340;&#26368;&#20248;&#23725;&#22238;&#24402;&#27491;&#21017;&#21270;&#21644;&#26368;&#20248;&#23725;&#39118;&#38505;&#30340;&#34892;&#20026;&#65292;&#20854;&#20013;&#27979;&#35797;&#20998;&#24067;&#19982;&#35757;&#32451;&#20998;&#24067;&#20219;&#24847;&#20559;&#31163;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#30830;&#23450;&#22312;&#21327;&#21464;&#37327;&#21644;&#22238;&#24402;&#20559;&#31227;&#19979;&#26368;&#20248;&#27491;&#21017;&#21270;&#27700;&#24179;&#31526;&#21495;&#30340;&#19968;&#33324;&#26465;&#20214;&#12290;&#36825;&#20123;&#26465;&#20214;&#25429;&#25417;&#20102;&#35757;&#32451;&#25968;&#25454;&#21644;&#27979;&#35797;&#25968;&#25454;&#20043;&#38388;&#21327;&#26041;&#24046;&#21644;&#20449;&#21495;&#32467;&#26500;&#20043;&#38388;&#30340;&#23545;&#40784;&#65292;&#24182;&#25581;&#31034;&#20102;&#19982;&#22312;&#20998;&#24067;&#20869;&#35774;&#32622;&#30456;&#27604;&#30340;&#40092;&#26126;&#24046;&#24322;&#12290;&#20363;&#22914;&#65292;&#22312;&#21327;&#21464;&#37327;&#20559;&#31227;&#25110;&#22238;&#24402;&#20559;&#31227;&#19979;&#65292;&#21363;&#20351;&#35757;&#32451;&#29305;&#24449;&#26159;&#21508;&#21521;&#21516;&#24615;&#30340;&#25110;&#35774;&#35745;&#26159;&#27424;&#21442;&#25968;&#21270;&#30340;&#65292;&#36127;&#27491;&#21017;&#21270;&#27700;&#24179;&#20063;&#21487;&#33021;&#26159;&#26368;&#20248;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#25968;&#25454;&#32437;&#27178;&#27604;&#20013;&#65292;&#29978;&#33267;&#22312;&#26368;&#20248;&#21270;&#36127;&#27491;&#21017;&#21270;&#27700;&#24179;&#26102;&#65292;&#26368;&#20248;&#35843;&#25972;&#30340;&#39118;&#38505;&#26159;&#21333;&#35843;&#30340;&#65292;&#21363;&#22312;&#20998;&#24067;&#22806;&#35774;&#32622;&#20013;&#20063;&#26159;&#22914;&#27492;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#23545;&#35757;&#32451;&#25968;&#25454;&#27809;&#26377;&#20570;&#20986;&#20219;&#20309;&#24314;&#27169;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01233v1 Announce Type: cross  Abstract: We study the behavior of optimal ridge regularization and optimal ridge risk for out-of-distribution prediction, where the test distribution deviates arbitrarily from the train distribution. We establish general conditions that determine the sign of the optimal regularization level under covariate and regression shifts. These conditions capture the alignment between the covariance and signal structures in the train and test data and reveal stark differences compared to the in-distribution setting. For example, a negative regularization level can be optimal under covariate shift or regression shift, even when the training features are isotropic or the design is underparameterized. Furthermore, we prove that the optimally-tuned risk is monotonic in the data aspect ratio, even in the out-of-distribution setting and when optimizing over negative regularization levels. In general, our results do not make any modeling assumptions for the tra
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861; RECO-SLIP&#65292;&#29992;&#20110;&#22312;&#23646;&#24615;&#22270;&#20013;&#26816;&#27979;&#23646;&#20110;&#26032;&#31867;&#21035;&#30340;&#33410;&#28857;&#65292;&#33021;&#22815;&#26377;&#25928;&#35299;&#20915;&#23376;&#32676;&#20307;&#36716;&#31227;&#19979;&#30340;&#33410;&#28857;&#26816;&#27979;&#38382;&#39064;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#24615;&#33021;&#20248;&#36234;&#12290;</title><link>https://arxiv.org/abs/2404.01216</link><description>&lt;p&gt;
&#22312;&#23376;&#32676;&#20307;&#36716;&#31227;&#19979;&#30340;&#26032;&#39062;&#33410;&#28857;&#31867;&#21035;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Novel Node Category Detection Under Subpopulation Shift
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01216
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861; RECO-SLIP&#65292;&#29992;&#20110;&#22312;&#23646;&#24615;&#22270;&#20013;&#26816;&#27979;&#23646;&#20110;&#26032;&#31867;&#21035;&#30340;&#33410;&#28857;&#65292;&#33021;&#22815;&#26377;&#25928;&#35299;&#20915;&#23376;&#32676;&#20307;&#36716;&#31227;&#19979;&#30340;&#33410;&#28857;&#26816;&#27979;&#38382;&#39064;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#24615;&#33021;&#20248;&#36234;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#22270;&#25968;&#25454;&#20013;&#65292;&#20998;&#24067;&#36716;&#31227;&#21487;&#20197;&#36890;&#36807;&#21508;&#31181;&#26041;&#24335;&#34920;&#29616;&#65292;&#20363;&#22914;&#26032;&#31867;&#21035;&#30340;&#20986;&#29616;&#21644;&#29616;&#26377;&#31867;&#21035;&#30456;&#23545;&#27604;&#20363;&#30340;&#21464;&#21270;&#12290;&#22312;&#36825;&#31181;&#20998;&#24067;&#36716;&#31227;&#19979;&#65292;&#26816;&#27979;&#23646;&#20110;&#26032;&#31867;&#21035;&#30340;&#33410;&#28857;&#23545;&#20110;&#23433;&#20840;&#25110;&#27934;&#23519;&#21457;&#29616;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#31216;&#20026;&#20855;&#26377;&#36873;&#25321;&#24615;&#38142;&#36335;&#39044;&#27979;&#30340;&#21484;&#22238;&#32422;&#26463;&#20248;&#21270;&#65288;RECO-SLIP&#65289;&#65292;&#29992;&#20110;&#22312;&#23376;&#32676;&#20307;&#36716;&#31227;&#19979;&#26816;&#27979;&#23646;&#24615;&#22270;&#20013;&#23646;&#20110;&#26032;&#31867;&#21035;&#30340;&#33410;&#28857;&#12290;&#36890;&#36807;&#23558;&#21484;&#22238;&#32422;&#26463;&#23398;&#20064;&#26694;&#26550;&#19982;&#39640;&#25928;&#26679;&#26412;&#39044;&#27979;&#26426;&#21046;&#30456;&#32467;&#21512;&#65292;RECO-SLIP&#35299;&#20915;&#20102;&#25269;&#25239;&#23376;&#32676;&#20307;&#36716;&#31227;&#21644;&#26377;&#25928;&#21033;&#29992;&#22270;&#32467;&#26500;&#30340;&#21452;&#37325;&#25361;&#25112;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#22270;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#35777;&#35780;&#20272;&#65292;&#32467;&#26524;&#34920;&#26126;RECO-SLIP&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#20855;&#26377;&#26356;&#20248;&#24322;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01216v1 Announce Type: new  Abstract: In real-world graph data, distribution shifts can manifest in various ways, such as the emergence of new categories and changes in the relative proportions of existing categories. It is often important to detect nodes of novel categories under such distribution shifts for safety or insight discovery purposes. We introduce a new approach, Recall-Constrained Optimization with Selective Link Prediction (RECO-SLIP), to detect nodes belonging to novel categories in attributed graphs under subpopulation shifts. By integrating a recall-constrained learning framework with a sample-efficient link prediction mechanism, RECO-SLIP addresses the dual challenges of resilience against subpopulation shifts and the effective exploitation of graph structure. Our extensive empirical evaluation across multiple graph datasets demonstrates the superior performance of RECO-SLIP over existing methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#29992;&#20110;&#38750;&#20984;&#32422;&#26463;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30340;&#38543;&#26426;&#31639;&#27861;&#65292;&#20854;&#35745;&#31639;&#22797;&#26434;&#24230;&#19982;&#25972;&#20307;&#25968;&#25454;&#38598;&#22823;&#23567;&#26080;&#20851;&#65292;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2404.01200</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#38750;&#20984;&#38543;&#26426;&#32422;&#26463;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Large-Scale Non-convex Stochastic Constrained Distributionally Robust Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01200
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#29992;&#20110;&#38750;&#20984;&#32422;&#26463;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30340;&#38543;&#26426;&#31639;&#27861;&#65292;&#20854;&#35745;&#31639;&#22797;&#26434;&#24230;&#19982;&#25972;&#20307;&#25968;&#25454;&#38598;&#22823;&#23567;&#26080;&#20851;&#65292;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;DRO&#65289;&#26159;&#38024;&#23545;&#25968;&#25454;&#20998;&#24067;&#21464;&#21270;&#35757;&#32451;&#20581;&#22766;&#27169;&#22411;&#30340;&#24378;&#22823;&#26694;&#26550;&#12290;&#26412;&#25991;&#20851;&#27880;&#20855;&#26377;&#40065;&#26834;&#24615;&#27700;&#24179;&#26126;&#30830;&#29305;&#24449;&#30340;&#32422;&#26463;DRO&#12290;&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#20855;&#26377;&#20984;&#25439;&#22833;&#20989;&#25968;&#30340;&#32422;&#26463;DRO&#19978;&#65292;&#24182;&#25490;&#38500;&#20102;&#20855;&#26377;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#65288;&#22914;&#31070;&#32463;&#32593;&#32476;&#65289;&#30340;&#23454;&#36341;&#21644;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24773;&#20917;&#12290;&#26412;&#25991;&#20026;&#38750;&#20984;&#32422;&#26463;DRO&#24320;&#21457;&#20102;&#19968;&#31181;&#38543;&#26426;&#31639;&#27861;&#21450;&#20854;&#24615;&#33021;&#20998;&#26512;&#12290;&#25105;&#20204;&#30340;&#38543;&#26426;&#31639;&#27861;&#22312;&#27599;&#27425;&#36845;&#20195;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#19982;&#25972;&#20307;&#25968;&#25454;&#38598;&#22823;&#23567;&#29420;&#31435;&#26080;&#20851;&#65292;&#22240;&#27492;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#24212;&#29992;&#12290;&#25105;&#20204;&#20391;&#37325;&#20110;&#23558;Cressie-Read&#23478;&#26063;&#25955;&#24230;&#23450;&#20041;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#25104;&#20013;&#21253;&#21547;$\chi^2$-&#25955;&#24230;&#20316;&#20026;&#29305;&#20363;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#35745;&#31639;&#22797;&#26434;&#24230;&#20026;$\mathcal O(\epsilon^{-3k_*-5})$&#30340;&#24773;&#20917;&#19979;&#25214;&#21040;&#20102;&#19968;&#20010;$\epsilon$-&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01200v1 Announce Type: cross  Abstract: Distributionally robust optimization (DRO) is a powerful framework for training robust models against data distribution shifts. This paper focuses on constrained DRO, which has an explicit characterization of the robustness level. Existing studies on constrained DRO mostly focus on convex loss function, and exclude the practical and challenging case with non-convex loss function, e.g., neural network. This paper develops a stochastic algorithm and its performance analysis for non-convex constrained DRO. The computational complexity of our stochastic algorithm at each iteration is independent of the overall dataset size, and thus is suitable for large-scale applications. We focus on the general Cressie-Read family divergence defined uncertainty set which includes $\chi^2$-divergences as a special case. We prove that our algorithm finds an $\epsilon$-stationary point with a computational complexity of $\mathcal O(\epsilon^{-3k_*-5})$, wh
&lt;/p&gt;</description></item><item><title>&#23545;&#25913;&#36827;&#30340;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#20010;&#38543;&#26426;&#22312;&#32447;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#20102;&#35299;&#26368;&#20248;&#33218;&#26368;&#22823;&#22870;&#21169;&#30340;&#24773;&#20917;&#19979;&#65292;&#20197;$O(\sqrt{k} \log k)$&#30340;&#36924;&#36817;&#30456;&#23545;&#20110;&#26368;&#20248;&#12290;</title><link>https://arxiv.org/abs/2404.01198</link><description>&lt;p&gt;
&#23545;&#25913;&#36827;&#30340;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#30340;&#36817;&#20046;&#26368;&#32039;&#23494;&#30340;&#36924;&#36817;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Nearly-tight Approximation Guarantees for the Improving Multi-Armed Bandits Problem
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01198
&lt;/p&gt;
&lt;p&gt;
&#23545;&#25913;&#36827;&#30340;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#20010;&#38543;&#26426;&#22312;&#32447;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#20102;&#35299;&#26368;&#20248;&#33218;&#26368;&#22823;&#22870;&#21169;&#30340;&#24773;&#20917;&#19979;&#65292;&#20197;$O(\sqrt{k} \log k)$&#30340;&#36924;&#36817;&#30456;&#23545;&#20110;&#26368;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20026;&#25913;&#36827;&#30340;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#25552;&#20379;&#20102;&#36817;&#20046;&#26368;&#32039;&#23494;&#30340;&#19978;&#30028;&#21644;&#19979;&#30028;&#12290;&#36825;&#20010;&#38382;&#39064;&#30340;&#19968;&#20010;&#23454;&#20363;&#26377;$k$&#20010;&#33218;&#65292;&#27599;&#20010;&#33218;&#30340;&#22870;&#21169;&#20989;&#25968;&#37117;&#26159;&#19968;&#20010;&#20985;&#20989;&#25968;&#65292;&#24182;&#19988;&#26159;&#19968;&#20010;&#19982;&#21040;&#30446;&#21069;&#20026;&#27490;&#25289;&#21160;&#35813;&#33218;&#30340;&#27425;&#25968;&#25104;&#22686;&#20989;&#25968;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#20219;&#20309;&#38543;&#26426;&#22312;&#32447;&#31639;&#27861;&#65292;&#37117;&#23384;&#22312;&#19968;&#20010;&#23454;&#20363;&#65292;&#20351;&#20854;&#30456;&#23545;&#20110;&#26368;&#20248;&#22870;&#21169;&#24517;&#39035;&#33267;&#23569;&#25215;&#21463;&#19968;&#20010;$\Omega(\sqrt{k})$&#30340;&#36817;&#20284;&#22240;&#23376;&#12290;&#28982;&#21518;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#38543;&#26426;&#22312;&#32447;&#31639;&#27861;&#65292;&#22914;&#26524;&#20107;&#20808;&#21578;&#30693;&#26368;&#20248;&#33218;&#21487;&#23454;&#29616;&#30340;&#26368;&#22823;&#22870;&#21169;&#65292;&#23601;&#21487;&#20197;&#20445;&#35777;&#19968;&#20010;$O(\sqrt{k})$&#30340;&#36817;&#20284;&#22240;&#23376;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#39069;&#22806;&#20184;&#20986;$O(\log k)$&#30340;&#36817;&#20284;&#22240;&#23376;&#30340;&#20195;&#20215;&#19979;&#65292;&#28040;&#38500;&#36825;&#20010;&#20551;&#35774;&#65292;&#23454;&#29616;&#30456;&#23545;&#20110;&#26368;&#20248;&#30340;&#24635;&#20307;$O(\sqrt{k} \log k)$&#30340;&#36924;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01198v1 Announce Type: new  Abstract: We give nearly-tight upper and lower bounds for the improving multi-armed bandits problem. An instance of this problem has $k$ arms, each of whose reward function is a concave and increasing function of the number of times that arm has been pulled so far. We show that for any randomized online algorithm, there exists an instance on which it must suffer at least an $\Omega(\sqrt{k})$ approximation factor relative to the optimal reward. We then provide a randomized online algorithm that guarantees an $O(\sqrt{k})$ approximation factor, if it is told the maximum reward achievable by the optimal arm in advance. We then show how to remove this assumption at the cost of an extra $O(\log k)$ approximation factor, achieving an overall $O(\sqrt{k} \log k)$ approximation relative to optimal.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#34701;&#21512;&#27491;&#21017;&#21270;&#22120;&#30340;&#20004;&#27493;&#27861;&#26041;&#27861;&#65292;&#26377;&#25928;&#22788;&#29702;&#39640;&#32500;&#22238;&#24402;&#20013;&#30340;&#27169;&#22411;&#20559;&#31227;&#21644;&#21327;&#21464;&#37327;&#36716;&#31227;&#65292;&#25552;&#39640;&#20102;&#30446;&#26631;&#20219;&#21153;&#30340;&#23398;&#20064;&#24615;&#33021;&#65292;&#20855;&#26377;&#31283;&#20581;&#24615;&#24182;&#28385;&#36275;&#26368;&#23567;-&#26368;&#22823;&#26368;&#20248;&#26465;&#20214;&#12290;</title><link>https://arxiv.org/abs/2404.01153</link><description>&lt;p&gt;
TransFusion&#65306;&#29992;&#20110;&#39640;&#32500;&#22238;&#24402;&#30340;&#25239;&#21327;&#21464;&#37327;&#36716;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
TransFusion: Covariate-Shift Robust Transfer Learning for High-Dimensional Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01153
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#34701;&#21512;&#27491;&#21017;&#21270;&#22120;&#30340;&#20004;&#27493;&#27861;&#26041;&#27861;&#65292;&#26377;&#25928;&#22788;&#29702;&#39640;&#32500;&#22238;&#24402;&#20013;&#30340;&#27169;&#22411;&#20559;&#31227;&#21644;&#21327;&#21464;&#37327;&#36716;&#31227;&#65292;&#25552;&#39640;&#20102;&#30446;&#26631;&#20219;&#21153;&#30340;&#23398;&#20064;&#24615;&#33021;&#65292;&#20855;&#26377;&#31283;&#20581;&#24615;&#24182;&#28385;&#36275;&#26368;&#23567;-&#26368;&#22823;&#26368;&#20248;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30417;&#30563;&#23398;&#20064;&#19982;&#36716;&#31227;&#23398;&#20064;&#30340;&#20027;&#35201;&#25361;&#25112;&#22312;&#20110;&#20998;&#24067;&#20559;&#31227;&#65292;&#20307;&#29616;&#20026;&#28304;&#27169;&#22411;&#21644;&#30446;&#26631;&#27169;&#22411;&#20043;&#38388;&#30340;&#20559;&#31227;&#20197;&#21450;&#36793;&#38469;&#21327;&#21464;&#37327;&#20998;&#24067;&#20043;&#38388;&#30340;&#20559;&#31227;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#22312;&#39640;&#32500;&#22238;&#24402;&#35774;&#32622;&#20013;&#22788;&#29702;&#23384;&#22312;&#21327;&#21464;&#37327;&#21464;&#21270;&#30340;&#27169;&#22411;&#21464;&#21270;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#27493;&#27861;&#26041;&#27861;&#65292;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#34701;&#21512;&#27491;&#21017;&#21270;&#22120;&#65292;&#26377;&#25928;&#21033;&#29992;&#26469;&#33258;&#28304;&#20219;&#21153;&#30340;&#26679;&#26412;&#26469;&#25552;&#39640;&#22312;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#30340;&#30446;&#26631;&#20219;&#21153;&#19978;&#30340;&#23398;&#20064;&#24615;&#33021;&#12290;&#25552;&#20379;&#20102;&#30446;&#26631;&#27169;&#22411;&#20272;&#35745;&#35823;&#24046;&#30340;&#38750;&#28176;&#36817;&#30028;&#38480;&#65292;&#26174;&#31034;&#20102;&#25152;&#25552;&#26041;&#27861;&#23545;&#21327;&#21464;&#37327;&#36716;&#31227;&#30340;&#31283;&#20581;&#24615;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#30830;&#23450;&#20102;&#20272;&#35745;&#22120;&#26159;&#26368;&#23567;-&#26368;&#22823;&#26368;&#20248;&#30340;&#26465;&#20214;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#35813;&#26041;&#27861;&#25193;&#23637;&#21040;&#20998;&#24067;&#24335;&#35774;&#32622;&#65292;&#20801;&#35768;&#36827;&#34892;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#31574;&#30053;&#65292;&#20165;&#38656;&#19968;&#36718;&#36890;&#20449;&#21363;&#21487;&#20445;&#30041;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01153v1 Announce Type: cross  Abstract: The main challenge that sets transfer learning apart from traditional supervised learning is the distribution shift, reflected as the shift between the source and target models and that between the marginal covariate distributions. In this work, we tackle model shifts in the presence of covariate shifts in the high-dimensional regression setting. Specifically, we propose a two-step method with a novel fused-regularizer that effectively leverages samples from source tasks to improve the learning performance on a target task with limited samples. Nonasymptotic bound is provided for the estimation error of the target model, showing the robustness of the proposed method to covariate shifts. We further establish conditions under which the estimator is minimax-optimal. Additionally, we extend the method to a distributed setting, allowing for a pretraining-finetuning strategy, requiring just one round of communication while retaining the esti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#39640;&#32500;&#25968;&#25454;&#20013;&#24046;&#20998;&#31169;&#26377;&#32447;&#24615;&#27169;&#22411;&#30340;&#20248;&#21270;&#26041;&#27861;&#36827;&#34892;&#20840;&#38754;&#23457;&#26597;&#65292;&#21457;&#29616;&#40065;&#26834;&#21644;&#20248;&#21270;&#30340;&#22352;&#26631;&#31639;&#27861;&#25928;&#26524;&#26368;&#22909;&#65292;&#21487;&#20026;&#26410;&#26469;&#30740;&#31350;&#25552;&#20379;&#21442;&#32771;&#12290;</title><link>https://arxiv.org/abs/2404.01141</link><description>&lt;p&gt;
SoK: &#39640;&#32500;&#25968;&#25454;&#20013;&#24046;&#20998;&#31169;&#26377;&#32447;&#24615;&#27169;&#22411;&#30340;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
SoK: A Review of Differentially Private Linear Models For High-Dimensional Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01141
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#39640;&#32500;&#25968;&#25454;&#20013;&#24046;&#20998;&#31169;&#26377;&#32447;&#24615;&#27169;&#22411;&#30340;&#20248;&#21270;&#26041;&#27861;&#36827;&#34892;&#20840;&#38754;&#23457;&#26597;&#65292;&#21457;&#29616;&#40065;&#26834;&#21644;&#20248;&#21270;&#30340;&#22352;&#26631;&#31639;&#27861;&#25928;&#26524;&#26368;&#22909;&#65292;&#21487;&#20026;&#26410;&#26469;&#30740;&#31350;&#25552;&#20379;&#21442;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32447;&#24615;&#27169;&#22411;&#22312;&#25968;&#25454;&#31185;&#23398;&#20013;&#38543;&#22788;&#21487;&#35265;&#65292;&#20294;&#22312;&#39640;&#32500;&#24230;&#20013;&#29305;&#21035;&#23481;&#26131;&#20986;&#29616;&#36807;&#25311;&#21512;&#21644;&#25968;&#25454;&#35760;&#24518;&#12290;&#20026;&#20102;&#20445;&#35777;&#35757;&#32451;&#25968;&#25454;&#30340;&#38544;&#31169;&#24615;&#65292;&#21487;&#20197;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#12290;&#35768;&#22810;&#35770;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#39640;&#32500;&#24230;&#24046;&#20998;&#31169;&#26377;&#32447;&#24615;&#27169;&#22411;&#30340;&#20248;&#21270;&#25216;&#26415;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#20043;&#38388;&#32570;&#20047;&#31995;&#32479;&#27604;&#36739;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#31169;&#26377;&#39640;&#32500;&#32447;&#24615;&#27169;&#22411;&#30340;&#20248;&#21270;&#26041;&#27861;&#36827;&#34892;&#20840;&#38754;&#23457;&#26597;&#26469;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#23545;&#25152;&#26377;&#26041;&#27861;&#36827;&#34892;&#30340;&#23454;&#35777;&#27979;&#35797;&#34920;&#26126;&#65292;&#40065;&#26834;&#21644;&#20248;&#21270;&#30340;&#22352;&#26631;&#31639;&#27861;&#34920;&#29616;&#26368;&#20339;&#65292;&#36825;&#21487;&#20026;&#26410;&#26469;&#30740;&#31350;&#25552;&#20379;&#21442;&#32771;&#12290;&#22312;&#32447;&#21457;&#24067;&#20102;&#25152;&#26377;&#26041;&#27861;&#30340;&#23454;&#29616;&#20195;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01141v1 Announce Type: new  Abstract: Linear models are ubiquitous in data science, but are particularly prone to overfitting and data memorization in high dimensions. To guarantee the privacy of training data, differential privacy can be used. Many papers have proposed optimization techniques for high-dimensional differentially private linear models, but a systematic comparison between these methods does not exist. We close this gap by providing a comprehensive review of optimization methods for private high-dimensional linear models. Empirical tests on all methods demonstrate robust and coordinate-optimized algorithms perform best, which can inform future research. Code for implementing all methods is released online.
&lt;/p&gt;</description></item><item><title>&#31169;&#26377;&#38543;&#26426;&#24615;&#22312;&#22270;&#20687;&#21387;&#32553;&#20013;&#30340;&#20316;&#29992;&#22312;&#20004;&#31181;&#36924;&#30495;&#24230;&#32422;&#26463;&#26465;&#20214;&#19979;&#24471;&#21040;&#38416;&#26126;&#65292;&#20197;&#23454;&#29616;&#24863;&#30693;&#36136;&#37327;&#21644;&#22833;&#30495;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;</title><link>https://arxiv.org/abs/2404.01111</link><description>&lt;p&gt;
&#36895;&#29575;-&#22833;&#30495;-&#24863;&#30693;&#26435;&#34913;&#65306;&#31169;&#26377;&#38543;&#26426;&#24615;&#30340;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
The Rate-Distortion-Perception Trade-off: The Role of Private Randomness
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01111
&lt;/p&gt;
&lt;p&gt;
&#31169;&#26377;&#38543;&#26426;&#24615;&#22312;&#22270;&#20687;&#21387;&#32553;&#20013;&#30340;&#20316;&#29992;&#22312;&#20004;&#31181;&#36924;&#30495;&#24230;&#32422;&#26463;&#26465;&#20214;&#19979;&#24471;&#21040;&#38416;&#26126;&#65292;&#20197;&#23454;&#29616;&#24863;&#30693;&#36136;&#37327;&#21644;&#22833;&#30495;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22270;&#20687;&#21387;&#32553;&#20013;&#65292;&#38543;&#30528;&#29983;&#25104;&#24314;&#27169;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#25581;&#31034;&#20102;&#36895;&#29575;&#21644;&#24863;&#30693;&#36136;&#37327;&#65288;&#36924;&#30495;&#24230;&#65289;&#20043;&#38388;&#23384;&#22312;&#19968;&#31181;&#26435;&#34913;&#65292;&#20854;&#20013;&#36924;&#30495;&#24230;&#36890;&#36807;&#36755;&#20986;&#20998;&#24067;&#19982;&#28304;&#20998;&#24067;&#30340;&#25509;&#36817;&#31243;&#24230;&#26469;&#34913;&#37327;&#12290;&#24050;&#32463;&#34920;&#26126;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#32534;&#30721;&#21487;&#20197;&#26356;&#22909;&#12290;&#29305;&#21035;&#26159;&#65292;&#20849;&#21516;&#38543;&#26426;&#24615;&#30340;&#20316;&#29992;&#24050;&#34987;&#24191;&#27867;&#30740;&#31350;&#12290;&#25105;&#20204;&#38416;&#26126;&#20102;&#22312;&#20004;&#31181;&#36924;&#30495;&#24230;&#32422;&#26463;&#26465;&#20214;&#19979;&#31169;&#26377;&#38543;&#26426;&#24615;&#22312;&#35760;&#24518;&#28304;$X^n=(X_1,...,X_n)$&#21387;&#32553;&#20013;&#30340;&#20316;&#29992;&#12290;&#25509;&#36817;&#23436;&#32654;&#36924;&#30495;&#24230;&#32422;&#26463;&#35201;&#27714;&#36755;&#20986;&#31526;&#21495;$(Y_1,...,Y_n)$&#30340;&#32852;&#21512;&#20998;&#24067;&#19982;&#28304;&#20998;&#24067;&#22312;&#24635;&#21464;&#24046;&#36317;&#31163;&#65288;TVD&#65289;&#19978;&#20219;&#24847;&#25509;&#36817;&#12290;&#27599;&#20010;&#31526;&#21495;&#30340;&#36817;&#20046;&#23436;&#32654;&#36924;&#30495;&#24230;&#32422;&#26463;&#35201;&#27714;&#36755;&#20986;&#31526;&#21495;$Y_t$&#30340;&#20998;&#24067;&#19982;&#28304;&#20998;&#24067;&#20043;&#38388;&#30340;TVD&#22312;&#20219;&#24847;&#23567;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#19968;&#31181;&#24863;&#30693;&#36136;&#37327;&#21644;&#22833;&#30495;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01111v1 Announce Type: cross  Abstract: In image compression, with recent advances in generative modeling, the existence of a trade-off between the rate and the perceptual quality (realism) has been brought to light, where the realism is measured by the closeness of the output distribution to the source. It has been shown that randomized codes can be strictly better under a number of formulations. In particular, the role of common randomness has been well studied. We elucidate the role of private randomness in the compression of a memoryless source $X^n=(X_1,...,X_n)$ under two kinds of realism constraints. The near-perfect realism constraint requires the joint distribution of output symbols $(Y_1,...,Y_n)$ to be arbitrarily close the distribution of the source in total variation distance (TVD). The per-symbol near-perfect realism constraint requires that the TVD between the distribution of output symbol $Y_t$ and the source distribution be arbitrarily small, uniformly in th
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26377;&#38480;&#26679;&#26412;&#24773;&#20917;&#19979;&#36827;&#34892;&#38750;&#21442;&#25968;&#39057;&#22495;&#31995;&#32479;&#35782;&#21035;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;Empirical Transfer Function Estimate&#65288;ETFE&#65289;&#22312;&#29305;&#23450;&#39057;&#29575;&#22788;&#20934;&#30830;&#20272;&#35745;&#39057;&#29575;&#21709;&#24212;&#65292;&#24182;&#35777;&#26126;&#22312;&#27425;&#39640;&#26031;&#24425;&#33394;&#22122;&#22768;&#21644;&#31283;&#23450;&#24615;&#20551;&#35774;&#19979;&#65292;ETFE&#20272;&#35745;&#20540;&#20934;&#30830;&#21487;&#38752;&#12290;</title><link>https://arxiv.org/abs/2404.01100</link><description>&lt;p&gt;
&#26377;&#38480;&#26679;&#26412;&#39057;&#22495;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Finite Sample Frequency Domain Identification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01100
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26377;&#38480;&#26679;&#26412;&#24773;&#20917;&#19979;&#36827;&#34892;&#38750;&#21442;&#25968;&#39057;&#22495;&#31995;&#32479;&#35782;&#21035;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;Empirical Transfer Function Estimate&#65288;ETFE&#65289;&#22312;&#29305;&#23450;&#39057;&#29575;&#22788;&#20934;&#30830;&#20272;&#35745;&#39057;&#29575;&#21709;&#24212;&#65292;&#24182;&#35777;&#26126;&#22312;&#27425;&#39640;&#26031;&#24425;&#33394;&#22122;&#22768;&#21644;&#31283;&#23450;&#24615;&#20551;&#35774;&#19979;&#65292;ETFE&#20272;&#35745;&#20540;&#20934;&#30830;&#21487;&#38752;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20174;&#26377;&#38480;&#26679;&#26412;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#38750;&#21442;&#25968;&#39057;&#22495;&#31995;&#32479;&#35782;&#21035;&#12290;&#25105;&#20204;&#20551;&#35774;&#22312;&#24320;&#29615;&#24773;&#20917;&#19979;&#65292;&#28608;&#21169;&#36755;&#20837;&#26159;&#21608;&#26399;&#24615;&#30340;&#65292;&#24182;&#32771;&#34385;&#32463;&#39564;&#20256;&#36882;&#20989;&#25968;&#20272;&#35745;&#65288;ETFE&#65289;&#65292;&#20854;&#20013;&#30446;&#26631;&#26159;&#22312;&#32473;&#23450;&#36755;&#20837;-&#36755;&#20986;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#22312;&#26576;&#20123;&#25152;&#38656;&#65288;&#22343;&#21248;&#38388;&#38548;&#30340;&#65289;&#39057;&#29575;&#22788;&#20272;&#35745;&#39057;&#29575;&#21709;&#24212;&#12290;&#25105;&#20204;&#34920;&#26126;&#22312;&#27425;&#39640;&#26031;&#24425;&#33394;&#22122;&#22768;&#65288;&#22312;&#26102;&#22495;&#65289;&#21644;&#31283;&#23450;&#24615;&#20551;&#35774;&#19979;&#65292;ETFE&#20272;&#35745;&#20540;&#38598;&#20013;&#22312;&#30495;&#23454;&#20540;&#21608;&#22260;&#12290;&#35823;&#24046;&#29575;&#20026;$\mathcal{O}((d_{\mathrm{u}}+\sqrt{d_{\mathrm{u}}d_{\mathrm{y}}})\sqrt{M/N_{\mathrm{tot}}})$&#65292;&#20854;&#20013;$N_{\mathrm{tot}}$&#26159;&#26679;&#26412;&#30340;&#24635;&#25968;&#65292;$M$&#26159;&#25152;&#38656;&#39057;&#29575;&#30340;&#25968;&#37327;&#65292;$d_{\mathrm{u}},\,d_{\mathrm{y}}$&#20998;&#21035;&#20026;&#36755;&#20837;&#21644;&#36755;&#20986;&#20449;&#21495;&#30340;&#32500;&#25968;&#12290;&#36825;&#20010;&#36895;&#29575;&#23545;&#20110;&#19968;&#33324;&#30340;&#38750;&#29702;&#24615;&#20256;&#36882;&#20989;&#25968;&#20173;&#28982;&#26377;&#25928;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#26377;&#38480;&#38454;&#30340;&#29366;&#24577;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01100v1 Announce Type: cross  Abstract: We study non-parametric frequency-domain system identification from a finite-sample perspective. We assume an open loop scenario where the excitation input is periodic and consider the Empirical Transfer Function Estimate (ETFE), where the goal is to estimate the frequency response at certain desired (evenly-spaced) frequencies, given input-output samples. We show that under sub-Gaussian colored noise (in time-domain) and stability assumptions, the ETFE estimates are concentrated around the true values. The error rate is of the order of $\mathcal{O}((d_{\mathrm{u}}+\sqrt{d_{\mathrm{u}}d_{\mathrm{y}}})\sqrt{M/N_{\mathrm{tot}}})$, where $N_{\mathrm{tot}}$ is the total number of samples, $M$ is the number of desired frequencies, and $d_{\mathrm{u}},\,d_{\mathrm{y}}$ are the dimensions of the input and output signals respectively. This rate remains valid for general irrational transfer functions and does not require a finite order state-sp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#38543;&#26426;&#33609;&#22270;&#25110;&#25237;&#24433;&#26469;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#30340;&#32479;&#19968;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#26368;&#23567;&#20108;&#20056;&#21644;PCA&#38382;&#39064;&#65292;&#38024;&#23545;&#24191;&#27867;&#33539;&#22260;&#30340;&#33609;&#22270;&#20998;&#24067;&#25552;&#20986;&#20102;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#65292;&#23637;&#31034;&#20102;&#26576;&#20123;&#20108;&#27425;&#24418;&#24335;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;</title><link>https://arxiv.org/abs/2404.00912</link><description>&lt;p&gt;
&#36890;&#36807;&#20108;&#27425;&#24418;&#24335;&#30340;&#27491;&#24577;&#24615;&#36827;&#34892;&#38543;&#26426;&#26368;&#23567;&#20108;&#20056;&#21644;PCA&#30340;&#25512;&#35770;
&lt;/p&gt;
&lt;p&gt;
Inference in Randomized Least Squares and PCA via Normality of Quadratic Forms
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00912
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#38543;&#26426;&#33609;&#22270;&#25110;&#25237;&#24433;&#26469;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#30340;&#32479;&#19968;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#26368;&#23567;&#20108;&#20056;&#21644;PCA&#38382;&#39064;&#65292;&#38024;&#23545;&#24191;&#27867;&#33539;&#22260;&#30340;&#33609;&#22270;&#20998;&#24067;&#25552;&#20986;&#20102;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#65292;&#23637;&#31034;&#20102;&#26576;&#20123;&#20108;&#27425;&#24418;&#24335;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#31639;&#27861;&#21487;&#20197;&#29992;&#26469;&#21152;&#36895;&#22823;&#22411;&#25968;&#25454;&#38598;&#30340;&#20998;&#26512;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#38024;&#23545;&#22810;&#20803;&#32479;&#35745;&#20998;&#26512;&#20013;&#20004;&#20010;&#26368;&#22522;&#26412;&#30340;&#38382;&#39064;&#65306;&#26368;&#23567;&#20108;&#20056;&#21644;&#20027;&#25104;&#20998;&#20998;&#26512;(PCA)&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#32479;&#35745;&#25512;&#26029;&#30340;&#32479;&#19968;&#26041;&#27861;&#65292;&#36890;&#36807;&#38543;&#26426;&#33609;&#22270;&#25110;&#25237;&#24433;&#26469;&#36827;&#34892;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#22266;&#23450;&#25968;&#25454;&#38598; -- &#21363;&#25968;&#25454;&#26465;&#20214;&#24615; -- &#21807;&#19968;&#30340;&#38543;&#26426;&#24615;&#28304;&#20110;&#38543;&#26426;&#31639;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#24191;&#27867;&#33539;&#22260;&#30340;&#33609;&#22270;&#20998;&#24067;&#30340;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#65292;&#20363;&#22914;&#23376;&#37319;&#26679;&#38543;&#26426;&#21704;&#36798;&#29595;&#21464;&#25442;(SRHT)&#65292;&#31232;&#30095;&#31526;&#21495;&#23884;&#20837;(SSE)&#21644;CountSketch&#65292;&#20855;&#26377;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#26465;&#30446;&#30340;&#33609;&#22270;&#30697;&#38453;&#20197;&#21450;&#22343;&#21248;&#23376;&#37319;&#26679;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#30446;&#21069;&#23578;&#26080;&#21487;&#27604;&#36739;&#30340;&#26041;&#27861;&#36866;&#29992;&#20110;PCA&#20013;&#30340;SSE&#21644;SRHT&#12290;&#25105;&#20204;&#30340;&#26032;&#39062;&#29702;&#35770;&#26041;&#27861;&#22522;&#20110;&#23637;&#31034;&#26576;&#20123;&#20108;&#27425;&#24418;&#24335;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;&#20316;&#20026;&#26356;&#24191;&#27867;&#20852;&#36259;&#30340;&#36129;&#29486;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20851;&#20110;&#20108;&#27425;&#24418;&#24335;&#30340;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00912v1 Announce Type: cross  Abstract: Randomized algorithms can be used to speed up the analysis of large datasets. In this paper, we develop a unified methodology for statistical inference via randomized sketching or projections in two of the most fundamental problems in multivariate statistical analysis: least squares and PCA. The methodology applies to fixed datasets -- i.e., is data-conditional -- and the only randomness is due to the randomized algorithm. We propose statistical inference methods for a broad range of sketching distributions, such as the subsampled randomized Hadamard transform (SRHT), Sparse Sign Embeddings (SSE) and CountSketch, sketching matrices with i.i.d. entries, and uniform subsampling. To our knowledge, no comparable methods are available for SSE and for SRHT in PCA. Our novel theoretical approach rests on showing the asymptotic normality of certain quadratic forms. As a contribution of broader interest, we show central limit theorems for quadr
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#22823;&#37327;&#21512;&#25104;&#32593;&#32476;&#25968;&#25454;&#19978;&#35757;&#32451;&#20998;&#31867;&#22120;&#65292;&#35774;&#35745;&#20986;&#26131;&#20110;&#35745;&#31639;&#12289;&#35299;&#26512;&#21487;&#22788;&#29702;&#19988;&#20855;&#26377;&#35299;&#37322;&#24615;&#30340;&#21160;&#24577;&#29305;&#24449;&#31867;&#22411;&#65292;&#23454;&#29616;&#20102;&#20960;&#20046;&#23436;&#32654;&#30340;&#32593;&#32476;&#20998;&#31867;&#65292;&#36229;&#36807;&#20102;&#30446;&#21069;&#25216;&#26415;&#27700;&#24179;&#12290;</title><link>https://arxiv.org/abs/2404.00793</link><description>&lt;p&gt;
&#23398;&#20064;&#32593;&#32476;&#22686;&#38271;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Learning the mechanisms of network growth
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00793
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#22823;&#37327;&#21512;&#25104;&#32593;&#32476;&#25968;&#25454;&#19978;&#35757;&#32451;&#20998;&#31867;&#22120;&#65292;&#35774;&#35745;&#20986;&#26131;&#20110;&#35745;&#31639;&#12289;&#35299;&#26512;&#21487;&#22788;&#29702;&#19988;&#20855;&#26377;&#35299;&#37322;&#24615;&#30340;&#21160;&#24577;&#29305;&#24449;&#31867;&#22411;&#65292;&#23454;&#29616;&#20102;&#20960;&#20046;&#23436;&#32654;&#30340;&#32593;&#32476;&#20998;&#31867;&#65292;&#36229;&#36807;&#20102;&#30446;&#21069;&#25216;&#26415;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#21160;&#24577;&#30495;&#23454;&#32593;&#32476;&#30340;&#26032;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#22312;&#22823;&#37327;&#21512;&#25104;&#32593;&#32476;&#25968;&#25454;&#19978;&#35757;&#32451;&#20998;&#31867;&#22120;&#12290;&#25968;&#25454;&#26159;&#36890;&#36807;&#27169;&#25311;&#21160;&#24577;&#32593;&#32476;&#30340;&#20061;&#31181;&#26368;&#20808;&#36827;&#30340;&#38543;&#26426;&#22270;&#27169;&#22411;&#29983;&#25104;&#30340;&#65292;&#36873;&#23450;&#21442;&#25968;&#33539;&#22260;&#20197;&#30830;&#20445;&#32593;&#32476;&#35268;&#27169;&#38543;&#26102;&#38388;&#21576;&#25351;&#25968;&#22686;&#38271;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#27010;&#24565;&#19978;&#26032;&#39062;&#30340;&#21160;&#24577;&#29305;&#24449;&#31867;&#22411;&#65292;&#23427;&#35745;&#31639;&#22312;&#29305;&#23450;&#26102;&#38388;&#38388;&#38548;&#20869;&#19968;&#32452;&#39030;&#28857;&#25910;&#21040;&#30340;&#26032;&#38142;&#25509;&#25968;&#12290;&#25152;&#25552;&#20986;&#30340;&#29305;&#24449;&#26131;&#20110;&#35745;&#31639;&#65292;&#35299;&#26512;&#19978;&#21487;&#22788;&#29702;&#65292;&#24182;&#20855;&#26377;&#35299;&#37322;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23454;&#29616;&#20102;&#23545;&#21512;&#25104;&#32593;&#32476;&#30340;&#20960;&#20046;&#23436;&#32654;&#20998;&#31867;&#65292;&#36229;&#36807;&#24403;&#21069;&#25216;&#26415;&#27700;&#24179;&#12290;&#23558;&#25105;&#20204;&#30340;&#20998;&#31867;&#26041;&#27861;&#24212;&#29992;&#20110;&#30495;&#23454;&#19990;&#30028;&#30340;&#24341;&#25991;&#32593;&#32476;&#65292;&#23545;&#25991;&#29486;&#20013;&#22768;&#31216;&#30340;&#20855;&#26377;&#20248;&#20808;&#38468;&#30528;&#12289;&#36866;&#24212;&#24615;&#21644;&#32769;&#21270;&#30340;&#27169;&#22411;&#26368;&#22909;&#22320;&#36866;&#24212;&#30495;&#23454;&#19990;&#30028;&#30340;&#24341;&#25991;&#32593;&#32476;&#30340;&#35828;&#27861;&#20855;&#26377;&#21487;&#38752;&#24615;&#65292;&#23613;&#31649;&#26377;&#26102;&#65292;&#39044;&#27979;&#21487;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00793v1 Announce Type: cross  Abstract: We propose a novel model-selection method for dynamic real-life networks. Our approach involves training a classifier on a large body of synthetic network data. The data is generated by simulating nine state-of-the-art random graph models for dynamic networks, with parameter range chosen to ensure exponential growth of the network size in time. We design a conceptually novel type of dynamic features that count new links received by a group of vertices in a particular time interval. The proposed features are easy to compute, analytically tractable, and interpretable. Our approach achieves a near-perfect classification of synthetic networks, exceeding the state-of-the-art by a large margin. Applying our classification method to real-world citation networks gives credibility to the claims in the literature that models with preferential attachment, fitness and aging fit real-world citation networks best, although sometimes, the predicted m
&lt;/p&gt;</description></item><item><title>PyTorch Frame&#26159;&#19968;&#20010;&#29992;&#20110;&#22788;&#29702;&#22810;&#27169;&#24577;&#34920;&#26684;&#25968;&#25454;&#30340;PyTorch&#26694;&#26550;&#65292;&#36890;&#36807;&#25552;&#20379;&#25968;&#25454;&#32467;&#26500;&#12289;&#27169;&#22411;&#25277;&#35937;&#21644;&#22806;&#37096;&#22522;&#30784;&#27169;&#22411;&#25972;&#21512;&#31561;&#21151;&#33021;&#65292;&#23454;&#29616;&#20102;&#27169;&#22359;&#21270;&#30340;&#34920;&#26684;&#27169;&#22411;&#23454;&#29616;&#65292;&#24182;&#25104;&#21151;&#23558;&#36825;&#20123;&#27169;&#22411;&#24212;&#29992;&#20110;&#22797;&#26434;&#30340;&#25968;&#25454;&#38598;&#12290;</title><link>https://arxiv.org/abs/2404.00776</link><description>&lt;p&gt;
PyTorch Frame: &#19968;&#20010;&#29992;&#20110;&#22810;&#27169;&#24577;&#34920;&#26684;&#23398;&#20064;&#30340;&#27169;&#22359;&#21270;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
PyTorch Frame: A Modular Framework for Multi-Modal Tabular Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00776
&lt;/p&gt;
&lt;p&gt;
PyTorch Frame&#26159;&#19968;&#20010;&#29992;&#20110;&#22788;&#29702;&#22810;&#27169;&#24577;&#34920;&#26684;&#25968;&#25454;&#30340;PyTorch&#26694;&#26550;&#65292;&#36890;&#36807;&#25552;&#20379;&#25968;&#25454;&#32467;&#26500;&#12289;&#27169;&#22411;&#25277;&#35937;&#21644;&#22806;&#37096;&#22522;&#30784;&#27169;&#22411;&#25972;&#21512;&#31561;&#21151;&#33021;&#65292;&#23454;&#29616;&#20102;&#27169;&#22359;&#21270;&#30340;&#34920;&#26684;&#27169;&#22411;&#23454;&#29616;&#65292;&#24182;&#25104;&#21151;&#23558;&#36825;&#20123;&#27169;&#22411;&#24212;&#29992;&#20110;&#22797;&#26434;&#30340;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;PyTorch Frame&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;PyTorch&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22788;&#29702;&#22810;&#27169;&#24577;&#34920;&#26684;&#25968;&#25454;&#30340;&#28145;&#24230;&#23398;&#20064;&#12290;PyTorch Frame&#36890;&#36807;&#25552;&#20379;&#22522;&#20110;PyTorch&#30340;&#25968;&#25454;&#32467;&#26500;&#26469;&#22788;&#29702;&#22797;&#26434;&#30340;&#34920;&#26684;&#25968;&#25454;&#65292;&#24341;&#20837;&#27169;&#22411;&#25277;&#35937;&#20197;&#23454;&#29616;&#34920;&#26684;&#27169;&#22411;&#30340;&#27169;&#22359;&#21270;&#23454;&#29616;&#65292;&#24182;&#20801;&#35768;&#25972;&#21512;&#22806;&#37096;&#22522;&#30784;&#27169;&#22411;&#26469;&#22788;&#29702;&#22797;&#26434;&#21015;&#65288;&#20363;&#22914;&#65292;&#29992;&#20110;&#25991;&#26412;&#21015;&#30340;LLMs&#65289;&#12290;&#25105;&#20204;&#36890;&#36807;&#20197;&#27169;&#22359;&#21270;&#26041;&#24335;&#23454;&#29616;&#22810;&#26679;&#30340;&#34920;&#26684;&#27169;&#22411;&#65292;&#25104;&#21151;&#23558;&#36825;&#20123;&#27169;&#22411;&#24212;&#29992;&#20110;&#22797;&#26434;&#30340;&#22810;&#27169;&#24577;&#34920;&#26684;&#25968;&#25454;&#65292;&#24182;&#23558;&#25105;&#20204;&#30340;&#26694;&#26550;&#19982;PyTorch Geometric&#38598;&#25104;&#65292;PyTorch Geometric&#26159;&#19968;&#20010;&#29992;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#30340;PyTorch&#24211;&#65292;&#20197;&#23454;&#29616;&#23545;&#20851;&#31995;&#25968;&#25454;&#24211;&#30340;&#31471;&#21040;&#31471;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00776v1 Announce Type: new  Abstract: We present PyTorch Frame, a PyTorch-based framework for deep learning over multi-modal tabular data. PyTorch Frame makes tabular deep learning easy by providing a PyTorch-based data structure to handle complex tabular data, introducing a model abstraction to enable modular implementation of tabular models, and allowing external foundation models to be incorporated to handle complex columns (e.g., LLMs for text columns). We demonstrate the usefulness of PyTorch Frame by implementing diverse tabular models in a modular way, successfully applying these models to complex multi-modal tabular data, and integrating our framework with PyTorch Geometric, a PyTorch library for Graph Neural Networks (GNNs), to perform end-to-end learning over relational databases.
&lt;/p&gt;</description></item><item><title>&#30830;&#35748;&#20102;&#19968;&#20010;&#27665;&#38388;&#20449;&#24565;&#65292;&#21363;&#24694;&#24847;&#23545;&#25163;&#21487;&#20197;&#30772;&#22351;&#29305;&#23450;&#21494;&#23376;&#33410;&#28857;&#20351;&#24471;&#25512;&#26029;&#21464;&#24471;&#19981;&#21487;&#33021;&#65292;&#20294;&#26159;&#21487;&#20197;&#23454;&#29616;&#23545;&#26681;&#33410;&#28857;&#30340;&#20934;&#30830;&#21518;&#39564;&#25512;&#26029;</title><link>https://arxiv.org/abs/2404.00768</link><description>&lt;p&gt;
&#36890;&#36807;&#20449;&#24565;&#20256;&#25773;&#22312;&#26641;&#19978;&#23454;&#29616;&#23545;&#25239;&#24615;&#31283;&#20581;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Adversarially-Robust Inference on Trees via Belief Propagation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00768
&lt;/p&gt;
&lt;p&gt;
&#30830;&#35748;&#20102;&#19968;&#20010;&#27665;&#38388;&#20449;&#24565;&#65292;&#21363;&#24694;&#24847;&#23545;&#25163;&#21487;&#20197;&#30772;&#22351;&#29305;&#23450;&#21494;&#23376;&#33410;&#28857;&#20351;&#24471;&#25512;&#26029;&#21464;&#24471;&#19981;&#21487;&#33021;&#65292;&#20294;&#26159;&#21487;&#20197;&#23454;&#29616;&#23545;&#26681;&#33410;&#28857;&#30340;&#20934;&#30830;&#21518;&#39564;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#24182;&#30740;&#31350;&#20102;&#22312;&#26641;&#24418;&#22270;&#27169;&#22411;&#19978;&#36827;&#34892;&#21518;&#39564;&#25512;&#26029;&#30340;&#38382;&#39064;&#65292;&#23384;&#22312;&#19968;&#20010;&#24694;&#24847;&#23545;&#25163;&#21487;&#20197;&#30772;&#22351;&#19968;&#20123;&#35266;&#23519;&#33410;&#28857;&#12290;&#22312;&#24191;&#27867;&#30740;&#31350;&#30340;&#26641;&#27169;&#22411;&#20013;&#65292;&#24403;&#33258;&#28982;&#20449;&#22122;&#27604;&#36229;&#36807;1&#26102;&#65292;&#26681;&#25454;&#21494;&#23376;&#33410;&#28857;&#30340;&#21518;&#39564;&#20998;&#24067;&#19982;Ber(1/2)&#26377;&#26174;&#33879;&#24046;&#24322;&#65292;&#24182;&#19988;&#25658;&#24102;&#19982;&#26681;&#31526;&#21495;&#26377;&#20851;&#30340;&#37325;&#35201;&#20449;&#24687;&#12290;&#25105;&#20204;&#30830;&#35748;&#20102;&#19968;&#20010;&#27665;&#38388;&#20449;&#24565;&#65292;&#21363;&#19968;&#20010;&#21487;&#20197;&#30772;&#22351;&#33258;&#24049;&#36873;&#25321;&#30340;&#36870;&#22810;&#39033;&#24335;&#20998;&#25968;&#21494;&#23376;&#33410;&#28857;&#30340;&#24694;&#24847;&#23545;&#25163;&#20250;&#35753;&#36825;&#31181;&#25512;&#26029;&#21464;&#24471;&#19981;&#21487;&#33021;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#20934;&#30830;&#22320;&#26681;&#25454;&#21494;&#23376;&#33410;&#28857;&#23545;&#26681;&#33410;&#28857;&#36827;&#34892;&#21518;&#39564;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00768v1 Announce Type: cross  Abstract: We introduce and study the problem of posterior inference on tree-structured graphical models in the presence of a malicious adversary who can corrupt some observed nodes. In the well-studied broadcasting on trees model, corresponding to the ferromagnetic Ising model on a $d$-regular tree with zero external field, when a natural signal-to-noise ratio exceeds one (the celebrated Kesten-Stigum threshold), the posterior distribution of the root given the leaves is bounded away from $\mathrm{Ber}(1/2)$, and carries nontrivial information about the sign of the root. This posterior distribution can be computed exactly via dynamic programming, also known as belief propagation.   We first confirm a folklore belief that a malicious adversary who can corrupt an inverse-polynomial fraction of the leaves of their choosing makes this inference impossible. Our main result is that accurate posterior inference about the root vertex given the leaves is
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;C-XGBoost&#30340;&#26641;&#25552;&#21319;&#27169;&#22411;&#65292;&#21487;&#29992;&#20110;&#39044;&#27979;&#28508;&#22312;&#32467;&#26524;&#65292;&#32467;&#21512;&#20102;&#22522;&#20110;&#26641;&#30340;&#27169;&#22411;&#21644;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#22240;&#26524;&#25512;&#26029;&#27169;&#22411;&#30340;&#20248;&#21183;&#65292;&#21516;&#26102;&#32487;&#25215;&#20102;XGBoost&#27169;&#22411;&#30340;&#39640;&#25928;&#22788;&#29702;&#32570;&#22833;&#20540;&#29305;&#24449;&#30340;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2404.00751</link><description>&lt;p&gt;
C-XGBoost&#65306;&#19968;&#31181;&#29992;&#20110;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#30340;&#26641;&#25552;&#21319;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
C-XGBoost: A tree boosting model for causal effect estimation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00751
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;C-XGBoost&#30340;&#26641;&#25552;&#21319;&#27169;&#22411;&#65292;&#21487;&#29992;&#20110;&#39044;&#27979;&#28508;&#22312;&#32467;&#26524;&#65292;&#32467;&#21512;&#20102;&#22522;&#20110;&#26641;&#30340;&#27169;&#22411;&#21644;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#22240;&#26524;&#25512;&#26029;&#27169;&#22411;&#30340;&#20248;&#21183;&#65292;&#21516;&#26102;&#32487;&#25215;&#20102;XGBoost&#27169;&#22411;&#30340;&#39640;&#25928;&#22788;&#29702;&#32570;&#22833;&#20540;&#29305;&#24449;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#26088;&#22312;&#20272;&#35745;&#22788;&#29702;&#23545;&#32467;&#26524;&#30340;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20197;&#21450;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65292;&#36825;&#20123;&#30693;&#35782;&#22312;&#35768;&#22810;&#23433;&#20840;&#20851;&#38190;&#39046;&#22495;&#20013;&#33267;&#20851;&#37325;&#35201;&#65292;&#36890;&#24120;&#38656;&#35201;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#25552;&#21462;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#25512;&#26029;&#27169;&#22411;&#65292;&#21517;&#20026;C-XGBoost&#65292;&#29992;&#20110;&#39044;&#27979;&#28508;&#22312;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21160;&#26426;&#22312;&#20110;&#21033;&#29992;&#22522;&#20110;&#26641;&#30340;&#27169;&#22411;&#22788;&#29702;&#34920;&#26684;&#25968;&#25454;&#30340;&#20248;&#36234;&#24615;&#65292;&#20197;&#21450;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#22240;&#26524;&#25512;&#26029;&#27169;&#22411;&#23398;&#20064;&#26377;&#29992;&#20110;&#20272;&#35745;&#22788;&#29702;&#21644;&#38750;&#22788;&#29702;&#26696;&#20363;&#30340;&#32467;&#26524;&#30340;&#34920;&#31034;&#30340;&#26174;&#33879;&#29305;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#36824;&#32487;&#25215;&#20102;XGBoost&#27169;&#22411;&#30340;&#26174;&#33879;&#20248;&#21183;&#65292;&#22914;&#39640;&#25928;&#22788;&#29702;&#20855;&#26377;&#32570;&#22833;&#20540;&#29305;&#24449;&#30340;&#29305;&#24615;&#65292;&#38656;&#35201;&#26368;&#23569;&#30340;&#39044;&#22788;&#29702;&#24037;&#20316;&#65292;&#21516;&#26102;&#20855;&#22791;&#27491;&#21017;&#21270;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00751v1 Announce Type: cross  Abstract: Causal effect estimation aims at estimating the Average Treatment Effect as well as the Conditional Average Treatment Effect of a treatment to an outcome from the available data. This knowledge is important in many safety-critical domains, where it often needs to be extracted from observational data. In this work, we propose a new causal inference model, named C-XGBoost, for the prediction of potential outcomes. The motivation of our approach is to exploit the superiority of tree-based models for handling tabular data together with the notable property of causal inference neural network-based models to learn representations that are useful for estimating the outcome for both the treatment and non-treatment cases. The proposed model also inherits the considerable advantages of XGBoost model such as efficiently handling features with missing values requiring minimum preprocessing effort, as well as it is equipped with regularization tech
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20004;&#38454;&#27573;&#20272;&#35745;&#31574;&#30053;&#65292;&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#22240;&#26524;&#20013;&#20171;&#20998;&#26512;&#20013;&#24178;&#25200;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#26681;&#25454;&#20854;&#22312;&#20559;&#24046;&#32467;&#26500;&#20013;&#30340;&#20316;&#29992;&#26469;&#20272;&#35745;&#24178;&#25200;&#20989;&#25968;&#12290;</title><link>https://arxiv.org/abs/2404.00735</link><description>&lt;p&gt;
&#22240;&#26524;&#20013;&#20171;&#20998;&#26512;&#30340;&#20004;&#38454;&#27573;&#24178;&#25200;&#20989;&#25968;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Two-Stage Nuisance Function Estimation for Causal Mediation Analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00735
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20004;&#38454;&#27573;&#20272;&#35745;&#31574;&#30053;&#65292;&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#22240;&#26524;&#20013;&#20171;&#20998;&#26512;&#20013;&#24178;&#25200;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#26681;&#25454;&#20854;&#22312;&#20559;&#24046;&#32467;&#26500;&#20013;&#30340;&#20316;&#29992;&#26469;&#20272;&#35745;&#24178;&#25200;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20351;&#29992;&#22522;&#20110;&#24433;&#21709;&#20989;&#25968;&#30340;&#20013;&#20171;&#21151;&#33021;&#20272;&#35745;&#22120;&#20272;&#35745;&#30452;&#25509;&#21644;&#38388;&#25509;&#22240;&#26524;&#25928;&#24212;&#26102;&#65292;&#20102;&#35299;&#24212;&#35813;&#20851;&#27880;&#27835;&#30103;&#12289;&#20013;&#20171;&#21644;&#32467;&#26524;&#30340;&#21738;&#20123;&#26041;&#38754;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#23558;&#23427;&#20204;&#35270;&#20026;&#24178;&#25200;&#20989;&#25968;&#65292;&#24182;&#35797;&#22270;&#23613;&#21487;&#33021;&#20934;&#30830;&#22320;&#25311;&#21512;&#36825;&#20123;&#24178;&#25200;&#20989;&#25968;&#24182;&#19981;&#19968;&#23450;&#26159;&#26368;&#22909;&#30340;&#26041;&#27861;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#24178;&#25200;&#20989;&#25968;&#30340;&#20004;&#38454;&#27573;&#20272;&#35745;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#26681;&#25454;&#24178;&#25200;&#20989;&#25968;&#22312;&#24433;&#21709;&#20989;&#25968;&#30340;&#20013;&#20171;&#21151;&#33021;&#20272;&#35745;&#22120;&#30340;&#20559;&#24046;&#32467;&#26500;&#20013;&#21457;&#25381;&#30340;&#20316;&#29992;&#26469;&#20272;&#35745;&#24178;&#25200;&#20989;&#25968;&#12290;&#25105;&#20204;&#23545;&#25152;&#25552;&#20986;&#26041;&#27861;&#36827;&#34892;&#20102;&#31283;&#20581;&#24615;&#20998;&#26512;&#65292;&#20197;&#21450;&#21442;&#25968;&#20272;&#35745;&#22120;&#30340;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00735v1 Announce Type: cross  Abstract: When estimating the direct and indirect causal effects using the influence function-based estimator of the mediation functional, it is crucial to understand what aspects of the treatment, the mediator, and the outcome mean mechanisms should be focused on. Specifically, considering them as nuisance functions and attempting to fit these nuisance functions as accurate as possible is not necessarily the best approach to take. In this work, we propose a two-stage estimation strategy for the nuisance functions that estimates the nuisance functions based on the role they play in the structure of the bias of the influence function-based estimator of the mediation functional. We provide robustness analysis of the proposed method, as well as sufficient conditions for consistency and asymptotic normality of the estimator of the parameter of interest.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#21033;&#29992;&#20302;&#32500;&#20223;&#23556;&#23376;&#31354;&#38388;&#38598;&#20013;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20004;&#31181;&#31574;&#30053;&#35299;&#20915;&#20102;&#22312;&#22810;&#20010;&#29615;&#22659;&#38543;&#26426;&#33218;&#19978;&#20219;&#21153;&#20013;&#20943;&#23569;&#39044;&#26399;&#36951;&#25022;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2404.00688</link><description>&lt;p&gt;
&#20849;&#20139;&#20223;&#23556;&#23376;&#31354;&#38388;&#20013;&#30340;&#33218;&#19978;&#20803;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Meta Learning in Bandits within Shared Affine Subspaces
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00688
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#21033;&#29992;&#20302;&#32500;&#20223;&#23556;&#23376;&#31354;&#38388;&#38598;&#20013;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20004;&#31181;&#31574;&#30053;&#35299;&#20915;&#20102;&#22312;&#22810;&#20010;&#29615;&#22659;&#38543;&#26426;&#33218;&#19978;&#20219;&#21153;&#20013;&#20943;&#23569;&#39044;&#26399;&#36951;&#25022;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#36890;&#36807;&#21033;&#29992;&#22810;&#20010;&#29615;&#22659;&#38543;&#26426;&#33218;&#19978;&#20219;&#21153;&#22312;&#20302;&#32500;&#20223;&#23556;&#23376;&#31354;&#38388;&#21608;&#22260;&#30340;&#38598;&#20013;&#24615;&#65292;&#36890;&#36807;&#22312;&#32447;&#20027;&#25104;&#20998;&#20998;&#26512;&#26469;&#20943;&#23569;&#22312;&#36935;&#21040;&#30340;&#33218;&#19978;&#20219;&#21153;&#20013;&#30340;&#39044;&#26399;&#36951;&#25022;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#24182;&#29702;&#35770;&#20998;&#26512;&#20102;&#20004;&#31181;&#35299;&#20915;&#35813;&#38382;&#39064;&#30340;&#31574;&#30053;&#65306;&#19968;&#31181;&#22522;&#20110;&#38754;&#23545;&#19981;&#30830;&#23450;&#24615;&#26102;&#30340;&#20048;&#35266;&#21407;&#21017;&#65292;&#21478;&#19968;&#31181;&#36890;&#36807;&#27748;&#26222;&#26862;&#21462;&#26679;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#26159;&#36890;&#29992;&#30340;&#65292;&#24182;&#21253;&#25324;&#20808;&#21069;&#25552;&#20986;&#30340;&#26041;&#27861;&#20316;&#20026;&#29305;&#20363;&#12290;&#27492;&#22806;&#65292;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#26174;&#33879;&#20943;&#23569;&#20102;&#20960;&#20010;&#33218;&#19978;&#20219;&#21153;&#30340;&#36951;&#25022;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00688v1 Announce Type: new  Abstract: We study the problem of meta-learning several contextual stochastic bandits tasks by leveraging their concentration around a low-dimensional affine subspace, which we learn via online principal component analysis to reduce the expected regret over the encountered bandits. We propose and theoretically analyze two strategies that solve the problem: One based on the principle of optimism in the face of uncertainty and the other via Thompson sampling. Our framework is generic and includes previously proposed approaches as special cases. Besides, the empirical results show that our methods significantly reduce the regret on several bandit tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#32447;&#24615;&#25554;&#20540;&#30340;CNFs&#22312;&#20174;&#26377;&#38480;&#38543;&#26426;&#26679;&#26412;&#20013;&#23398;&#20064;&#27010;&#29575;&#20998;&#24067;&#26102;&#30340;&#29702;&#35770;&#24615;&#36136;&#65292;&#24314;&#31435;&#20102;&#38750;&#28176;&#36817;&#35823;&#24046;&#30028;&#65292;&#24182;&#25552;&#20379;&#20102;&#25910;&#25947;&#20998;&#26512;&#26694;&#26550;&#12290;</title><link>https://arxiv.org/abs/2404.00551</link><description>&lt;p&gt;
&#36830;&#32493;&#27491;&#35268;&#21270;&#27969;&#22312;&#23398;&#20064;&#27010;&#29575;&#20998;&#24067;&#20013;&#30340;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Convergence of Continuous Normalizing Flows for Learning Probability Distributions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00551
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#32447;&#24615;&#25554;&#20540;&#30340;CNFs&#22312;&#20174;&#26377;&#38480;&#38543;&#26426;&#26679;&#26412;&#20013;&#23398;&#20064;&#27010;&#29575;&#20998;&#24067;&#26102;&#30340;&#29702;&#35770;&#24615;&#36136;&#65292;&#24314;&#31435;&#20102;&#38750;&#28176;&#36817;&#35823;&#24046;&#30028;&#65292;&#24182;&#25552;&#20379;&#20102;&#25910;&#25947;&#20998;&#26512;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36830;&#32493;&#27491;&#35268;&#21270;&#27969;&#65288;CNFs&#65289;&#26159;&#19968;&#31181;&#22522;&#20110;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#23398;&#20064;&#27010;&#29575;&#20998;&#24067;&#30340;&#29983;&#25104;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#32463;&#39564;&#25104;&#21151;&#65292;&#21253;&#25324;&#22823;&#35268;&#27169;&#22270;&#20687;&#21512;&#25104;&#12289;&#34507;&#30333;&#36136;&#32467;&#26500;&#39044;&#27979;&#21644;&#20998;&#23376;&#29983;&#25104;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#32447;&#24615;&#25554;&#20540;&#30340;CNFs&#22312;&#20174;&#26377;&#38480;&#38543;&#26426;&#26679;&#26412;&#20013;&#23398;&#20064;&#27010;&#29575;&#20998;&#24067;&#26102;&#30340;&#29702;&#35770;&#24615;&#36136;&#65292;&#20351;&#29992;&#20102;&#27969;&#21305;&#37197;&#30446;&#26631;&#20989;&#25968;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#22522;&#20110;CNFs&#30340;&#20998;&#24067;&#20272;&#35745;&#22120;&#30340;&#38750;&#28176;&#36817;&#35823;&#24046;&#30028;&#65292;&#20197;Wasserstein-2&#36317;&#31163;&#34920;&#31034;&#12290;&#25105;&#20204;&#20998;&#26512;&#30340;&#20851;&#38190;&#20551;&#35774;&#26159;&#30446;&#26631;&#20998;&#24067;&#28385;&#36275;&#20197;&#19979;&#19977;&#20010;&#26465;&#20214;&#20043;&#19968;&#65306;&#35201;&#20040;&#20855;&#26377;&#26377;&#30028;&#25903;&#25345;&#65292;&#35201;&#20040;&#26159;&#24378;&#23545;&#25968;&#20985;&#30340;&#65292;&#35201;&#20040;&#26159;&#26377;&#38480;&#25110;&#26080;&#38480;&#28151;&#21512;&#30340;&#39640;&#26031;&#20998;&#24067;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21253;&#21547;&#20102;&#35823;&#24046;&#25910;&#25947;&#20998;&#26512;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00551v1 Announce Type: cross  Abstract: Continuous normalizing flows (CNFs) are a generative method for learning probability distributions, which is based on ordinary differential equations. This method has shown remarkable empirical success across various applications, including large-scale image synthesis, protein structure prediction, and molecule generation. In this work, we study the theoretical properties of CNFs with linear interpolation in learning probability distributions from a finite random sample, using a flow matching objective function. We establish non-asymptotic error bounds for the distribution estimator based on CNFs, in terms of the Wasserstein-2 distance. The key assumption in our analysis is that the target distribution satisfies one of the following three conditions: it either has a bounded support, is strongly log-concave, or is a finite or infinite mixture of Gaussian distributions. We present a convergence analysis framework that encompasses the err
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#39318;&#27425;&#35777;&#26126;&#20102;&#22312;&#36716;&#31227;&#23398;&#20064;&#35774;&#32622;&#19979;&#65292;&#33391;&#24615;&#36807;&#25311;&#21512;&#32447;&#24615;&#25554;&#20540;&#22120;&#30340;&#38750;&#28176;&#36817;&#36229;&#39069;&#39118;&#38505;&#30028;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#31867;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2404.00522</link><description>&lt;p&gt;
&#26368;&#23567;&#33539;&#25968;&#25554;&#20540;&#22312;&#21327;&#21464;&#37327;&#36716;&#31227;&#19979;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Minimum-Norm Interpolation Under Covariate Shift
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00522
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#39318;&#27425;&#35777;&#26126;&#20102;&#22312;&#36716;&#31227;&#23398;&#20064;&#35774;&#32622;&#19979;&#65292;&#33391;&#24615;&#36807;&#25311;&#21512;&#32447;&#24615;&#25554;&#20540;&#22120;&#30340;&#38750;&#28176;&#36817;&#36229;&#39069;&#39118;&#38505;&#30028;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#31867;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36716;&#31227;&#23398;&#20064;&#26159;&#29616;&#23454;&#19990;&#30028;&#26426;&#22120;&#23398;&#20064;&#37096;&#32626;&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#65292;&#24182;&#22312;&#36807;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#23454;&#39564;&#30740;&#31350;&#20013;&#24471;&#21040;&#24191;&#27867;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#21363;&#20351;&#22312;&#32447;&#24615;&#22238;&#24402;&#30340;&#26368;&#31616;&#21333;&#35774;&#32622;&#20013;&#65292;&#22312;&#23545;&#36716;&#31227;&#23398;&#20064;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#23384;&#22312;&#26174;&#33879;&#24046;&#36317;&#12290;&#22312;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#30340;&#20998;&#24067;&#30740;&#31350;&#20013;&#65292;&#24050;&#32463;&#21457;&#29616;&#20102;&#19968;&#31181;&#34987;&#31216;&#20026;&#8220;&#33391;&#24615;&#36807;&#25311;&#21512;&#8221;&#29616;&#35937;&#30340;&#29616;&#35937;&#65292;&#21363;&#32447;&#24615;&#25554;&#20540;&#22120;&#20250;&#23545;&#22122;&#22768;&#35757;&#32451;&#26631;&#31614;&#36807;&#25311;&#21512;&#65292;&#20294;&#20173;&#28982;&#33021;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;&#36825;&#31181;&#34892;&#20026;&#21457;&#29983;&#22312;&#28304;&#21327;&#26041;&#24046;&#30697;&#38453;&#21644;&#36755;&#20837;&#25968;&#25454;&#32500;&#24230;&#19978;&#30340;&#29305;&#23450;&#26465;&#20214;&#19979;&#12290;&#22240;&#27492;&#65292;&#33258;&#28982;&#32780;&#28982;&#22320;&#24819;&#30693;&#36947;&#36825;&#26679;&#30340;&#39640;&#32500;&#32447;&#24615;&#27169;&#22411;&#22312;&#36716;&#31227;&#23398;&#20064;&#19979;&#22914;&#20309;&#34892;&#20026;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#36716;&#31227;&#23398;&#20064;&#35774;&#32622;&#20013;&#33391;&#24615;&#36807;&#25311;&#21512;&#32447;&#24615;&#25554;&#20540;&#22120;&#30340;&#31532;&#19968;&#20010;&#38750;&#28176;&#36817;&#36229;&#39069;&#39118;&#38505;&#30028;&#12290;&#36890;&#36807;&#25105;&#20204;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23545;&#36716;&#31227;&#23398;&#20064;&#20013;&#30340;\textit {b&#36827;&#34892;&#20998;&#31867;}}&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00522v1 Announce Type: new  Abstract: Transfer learning is a critical part of real-world machine learning deployments and has been extensively studied in experimental works with overparameterized neural networks. However, even in the simplest setting of linear regression a notable gap still exists in the theoretical understanding of transfer learning. In-distribution research on high-dimensional linear regression has led to the identification of a phenomenon known as \textit{benign overfitting}, in which linear interpolators overfit to noisy training labels and yet still generalize well. This behavior occurs under specific conditions on the source covariance matrix and input data dimension. Therefore, it is natural to wonder how such high-dimensional linear models behave under transfer learning. We prove the first non-asymptotic excess risk bounds for benignly-overfit linear interpolators in the transfer learning setting. From our analysis, we propose a taxonomy of \textit{b
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#39069;&#22806;&#30340;&#37325;&#24314;&#38454;&#27573;&#21644;&#37325;&#24314;&#25439;&#22833;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20849;&#20139;&#27169;&#22411;&#21442;&#25968;&#21644;&#29305;&#24449;&#34920;&#31034;&#30340;&#27169;&#22411;&#35757;&#32451;&#26041;&#27861;&#65292;&#24314;&#31435;&#20102;&#20849;&#21516;&#20449;&#24687;&#30340;&#27010;&#24565;&#65292;&#29992;&#20110;&#35299;&#20915;&#30456;&#20851;&#20219;&#21153;&#12290;</title><link>https://arxiv.org/abs/2404.00505</link><description>&lt;p&gt;
&#20855;&#26377;&#37325;&#24314;&#25439;&#22833;&#30340;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Transfer Learning with Reconstruction Loss
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00505
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#39069;&#22806;&#30340;&#37325;&#24314;&#38454;&#27573;&#21644;&#37325;&#24314;&#25439;&#22833;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20849;&#20139;&#27169;&#22411;&#21442;&#25968;&#21644;&#29305;&#24449;&#34920;&#31034;&#30340;&#27169;&#22411;&#35757;&#32451;&#26041;&#27861;&#65292;&#24314;&#31435;&#20102;&#20849;&#21516;&#20449;&#24687;&#30340;&#27010;&#24565;&#65292;&#29992;&#20110;&#35299;&#20915;&#30456;&#20851;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#22810;&#25968;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#25968;&#23398;&#20248;&#21270;&#30340;&#24212;&#29992;&#20013;&#65292;&#36890;&#24120;&#20026;&#27599;&#20010;&#29305;&#23450;&#20248;&#21270;&#30446;&#26631;&#35757;&#32451;&#19968;&#20010;&#19987;&#29992;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#22330;&#26223;&#20013;&#65292;&#21516;&#19968;&#32452;&#38382;&#39064;&#36755;&#20837;&#19978;&#32463;&#24120;&#38656;&#35201;&#20248;&#21270;&#20960;&#20010;&#19981;&#21516;&#20294;&#30456;&#20851;&#30340;&#30446;&#26631;&#25110;&#20219;&#21153;&#12290;&#19982;&#20026;&#27599;&#20010;&#38382;&#39064;&#21333;&#29420;&#35757;&#32451;&#19981;&#21516;&#30340;&#31070;&#32463;&#32593;&#32476;&#30456;&#27604;&#65292;&#26356;&#26377;&#25928;&#30340;&#26041;&#27861;&#26159;&#21033;&#29992;&#36825;&#20123;&#30446;&#26631;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#20351;&#29992;&#20849;&#20139;&#27169;&#22411;&#21442;&#25968;&#21644;&#29305;&#24449;&#34920;&#31034;&#35757;&#32451;&#22810;&#20010;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#12290;&#20026;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#26412;&#25991;&#39318;&#20808;&#24314;&#31435;&#20102;&#20849;&#21516;&#20449;&#24687;&#30340;&#27010;&#24565;&#65306;&#35299;&#20915;&#30456;&#20851;&#20219;&#21153;&#25152;&#38656;&#30340;&#20849;&#20139;&#30693;&#35782;&#65292;&#28982;&#21518;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#27169;&#22411;&#20013;&#28155;&#21152;&#19968;&#20010;&#39069;&#22806;&#30340;&#37325;&#24314;&#38454;&#27573;&#20197;&#21450;&#30456;&#20851;&#30340;&#26032;&#37325;&#24314;&#25439;&#22833;&#12290;&#35813;&#25439;&#22833;&#29992;&#20110;&#20174;&#36873;&#25321;&#30340;&#38544;&#34255;&#29366;&#24577;&#24320;&#22987;&#37325;&#26032;&#26500;&#24314;&#20849;&#21516;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00505v1 Announce Type: cross  Abstract: In most applications of utilizing neural networks for mathematical optimization, a dedicated model is trained for each specific optimization objective. However, in many scenarios, several distinct yet correlated objectives or tasks often need to be optimized on the same set of problem inputs. Instead of independently training a different neural network for each problem separately, it would be more efficient to exploit the correlations between these objectives and to train multiple neural network models with shared model parameters and feature representations. To achieve this, this paper first establishes the concept of common information: the shared knowledge required for solving the correlated tasks, then proposes a novel approach for model training by adding into the model an additional reconstruction stage associated with a new reconstruction loss. This loss is for reconstructing the common information starting from a selected hidde
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#19981;&#31561;&#26465;&#20214;&#30340;&#39069;&#22806;&#20107;&#20214;&#65292;&#23558;&#26465;&#20214;&#27010;&#29575;&#36716;&#21270;&#20026;&#29305;&#27530;&#31215;&#20998;&#24418;&#24335;&#65292;&#25512;&#24191;&#20026;&#21367;&#31215;&#24418;&#24335;&#30340;&#26032;&#28388;&#27874;&#26694;&#26550;&#65292;&#31216;&#20026;&#21367;&#31215;&#36125;&#21494;&#26031;&#28388;&#27874;&#12290;</title><link>https://arxiv.org/abs/2404.00481</link><description>&lt;p&gt;
&#21367;&#31215;&#36125;&#21494;&#26031;&#28388;&#27874;
&lt;/p&gt;
&lt;p&gt;
Convolutional Bayesian Filtering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00481
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#19981;&#31561;&#26465;&#20214;&#30340;&#39069;&#22806;&#20107;&#20214;&#65292;&#23558;&#26465;&#20214;&#27010;&#29575;&#36716;&#21270;&#20026;&#29305;&#27530;&#31215;&#20998;&#24418;&#24335;&#65292;&#25512;&#24191;&#20026;&#21367;&#31215;&#24418;&#24335;&#30340;&#26032;&#28388;&#27874;&#26694;&#26550;&#65292;&#31216;&#20026;&#21367;&#31215;&#36125;&#21494;&#26031;&#28388;&#27874;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#28388;&#27874;&#26159;&#21160;&#24577;&#31995;&#32479;&#29366;&#24577;&#20272;&#35745;&#30340;&#20027;&#35201;&#26694;&#26550;&#12290;&#26631;&#20934;&#29256;&#26412;&#21033;&#29992;&#20840;&#27010;&#29575;&#35268;&#21017;&#21644;&#36125;&#21494;&#26031;&#23450;&#29702;&#20132;&#26367;&#20351;&#29992;&#65292;&#32780;&#23450;&#20041;&#21644;&#35745;&#31639;&#26465;&#20214;&#27010;&#29575;&#30340;&#26041;&#24335;&#23545;&#29366;&#24577;&#20998;&#24067;&#25512;&#26029;&#33267;&#20851;&#37325;&#35201;&#12290;&#20197;&#21069;&#65292;&#26465;&#20214;&#27010;&#29575;&#34987;&#20551;&#23450;&#20026;&#31934;&#30830;&#24050;&#30693;&#65292;&#20195;&#34920;&#19968;&#20010;&#20107;&#20214;&#21457;&#29983;&#27010;&#29575;&#32473;&#23450;&#31532;&#20108;&#20010;&#20107;&#20214;&#30340;&#24230;&#37327;&#12290;&#26412;&#25991;&#21457;&#29616;&#36890;&#36807;&#28155;&#21152;&#19968;&#20010;&#35268;&#23450;&#19981;&#31561;&#26465;&#20214;&#30340;&#39069;&#22806;&#20107;&#20214;&#65292;&#21487;&#20197;&#23558;&#26465;&#20214;&#27010;&#29575;&#36716;&#21270;&#20026;&#31867;&#20284;&#20110;&#21367;&#31215;&#30340;&#29305;&#27530;&#31215;&#20998;&#24418;&#24335;&#12290;&#22522;&#20110;&#36825;&#19968;&#36716;&#21270;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36807;&#28193;&#27010;&#29575;&#21644;&#36755;&#20986;&#27010;&#29575;&#22343;&#21487;&#20197;&#25512;&#24191;&#20026;&#21367;&#31215;&#24418;&#24335;&#65292;&#20174;&#32780;&#24471;&#21040;&#19968;&#20010;&#26356;&#19968;&#33324;&#30340;&#28388;&#27874;&#26694;&#26550;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#21367;&#31215;&#36125;&#21494;&#26031;&#28388;&#27874;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00481v1 Announce Type: cross  Abstract: Bayesian filtering serves as the mainstream framework of state estimation in dynamic systems. Its standard version utilizes total probability rule and Bayes' law alternatively, where how to define and compute conditional probability is critical to state distribution inference. Previously, the conditional probability is assumed to be exactly known, which represents a measure of the occurrence probability of one event, given the second event. In this paper, we find that by adding an additional event that stipulates an inequality condition, we can transform the conditional probability into a special integration that is analogous to convolution. Based on this transformation, we show that both transition probability and output probability can be generalized to convolutional forms, resulting in a more general filtering framework that we call convolutional Bayesian filtering. This new framework encompasses standard Bayesian filtering as a spe
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#30340;&#25991;&#26412;&#29983;&#25104;&#26469;&#23454;&#29616;&#35821;&#35328;&#26657;&#20934;&#65292;&#21487;&#20197;&#20351;&#29992;&#25143;&#20570;&#20986;&#26657;&#20934;&#27010;&#29575;&#39044;&#27979;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2404.00474</link><description>&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#30340;&#35821;&#35328;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Linguistic Calibration of Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00474
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#30340;&#25991;&#26412;&#29983;&#25104;&#26469;&#23454;&#29616;&#35821;&#35328;&#26657;&#20934;&#65292;&#21487;&#20197;&#20351;&#29992;&#25143;&#20570;&#20986;&#26657;&#20934;&#27010;&#29575;&#39044;&#27979;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#21487;&#33021;&#20250;&#22312;&#33258;&#20449;&#24187;&#35273;&#26102;&#23548;&#33268;&#29992;&#25143;&#20570;&#20986;&#27425;&#20248;&#21270;&#30340;&#19979;&#28216;&#20915;&#31574;&#12290;&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#21475;&#22836;&#20256;&#36798;&#20854;&#20027;&#24352;&#27491;&#30830;&#27010;&#29575;&#21487;&#20197;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#29616;&#26377;&#27169;&#22411;&#26080;&#27861;&#29983;&#25104;&#20855;&#26377;&#26657;&#20934;&#32622;&#20449;&#24230;&#22768;&#26126;&#30340;&#25991;&#26412;&#12290;&#25105;&#20204;&#36890;&#36807;&#20915;&#31574;&#35282;&#24230;&#65292;&#20026;&#38271;&#31687;&#29983;&#25104;&#24418;&#24335;&#30340;&#35821;&#35328;&#26657;&#20934;&#24418;&#24335;&#21270;&#23450;&#20041;&#65306;&#22914;&#26524;&#35821;&#35328;&#27169;&#22411;&#30340;&#29983;&#25104;&#20351;&#20854;&#29992;&#25143;&#33021;&#22815;&#20570;&#20986;&#26657;&#20934;&#27010;&#29575;&#39044;&#27979;&#65292;&#21017;&#35813;&#27169;&#22411;&#26159;&#35821;&#35328;&#19978;&#26657;&#20934;&#30340;&#12290;&#36825;&#20010;&#23450;&#20041;&#20351;&#24471;&#19968;&#20010;&#35757;&#32451;&#26694;&#26550;&#25104;&#20026;&#21487;&#33021;&#65292;&#20854;&#20013;&#19968;&#20010;&#30417;&#30563;&#24494;&#35843;&#27493;&#39588;&#24341;&#23548;&#19968;&#20010;&#35821;&#35328;&#27169;&#22411;&#21457;&#20986;&#24102;&#26377;&#32622;&#20449;&#24230;&#22768;&#26126;&#30340;&#38271;&#31687;&#29983;&#25104;&#65292;&#35832;&#22914;&#8220;&#25105;&#20272;&#35745;&#26377;30%&#30340;&#26426;&#20250;&#8230;&#8221;&#25110;&#8220;&#25105;&#30830;&#20449;&#8230;&#8221;&#65292;&#28982;&#21518;&#26159;&#19968;&#20010;&#24378;&#21270;&#23398;&#20064;&#27493;&#39588;&#65292;&#22870;&#21169;&#20351;&#29992;&#25143;&#33021;&#22815;&#23545;&#30456;&#20851;&#38382;&#39064;&#25552;&#20379;&#26657;&#20934;&#31572;&#26696;&#30340;&#29983;&#25104;&#12290;&#25105;&#20204;&#23545;Llama 2 7B &#36827;&#34892;&#35821;&#35328;&#26657;&#20934;&#65292;&#24182;&#21457;&#29616;&#22312;&#33258;&#21160;&#21270;&#21644;&#20154;&#31867;&#27979;&#35797;&#20013;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00474v1 Announce Type: cross  Abstract: Language models (LMs) may lead their users to make suboptimal downstream decisions when they confidently hallucinate. This issue can be mitigated by having the LM verbally convey the probability that its claims are correct, but existing models cannot produce text with calibrated confidence statements. Through the lens of decision-making, we formalize linguistic calibration for long-form generations: an LM is linguistically calibrated if its generations enable its users to make calibrated probabilistic predictions. This definition enables a training framework where a supervised finetuning step bootstraps an LM to emit long-form generations with confidence statements such as "I estimate a 30% chance of..." or "I am certain that...", followed by a reinforcement learning step which rewards generations that enable a user to provide calibrated answers to related questions. We linguistically calibrate Llama 2 7B and find in automated and huma
&lt;/p&gt;</description></item><item><title>&#20998;&#24067;&#24335;&#29422;&#23376;&#26159;&#23545; Lion &#36827;&#34892;&#20102;&#21019;&#26032;&#24615;&#25913;&#36827;&#65292;&#21033;&#29992;&#31526;&#21495;&#25805;&#20316;&#31526;&#38477;&#20302;&#20102;&#36890;&#20449;&#25104;&#26412;&#65292;&#22312;&#20998;&#24067;&#24335;&#35757;&#32451;&#20013;&#21462;&#24471;&#20102;&#19982;&#26631;&#20934; Lion &#25110; AdamW &#20248;&#21270;&#22120;&#30456;&#24403;&#30340;&#24615;&#33021;&#65292;&#24182;&#26174;&#33879;&#20943;&#23569;&#20102;&#36890;&#20449;&#24102;&#23485;&#12290;</title><link>https://arxiv.org/abs/2404.00438</link><description>&lt;p&gt;
&#20351;&#29992;&#20998;&#24067;&#24335;&#29422;&#23376;&#36827;&#34892;&#39640;&#25928;&#36890;&#20449;&#30340;&#20998;&#24067;&#24335;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Communication Efficient Distributed Training with Distributed Lion
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00438
&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#24335;&#29422;&#23376;&#26159;&#23545; Lion &#36827;&#34892;&#20102;&#21019;&#26032;&#24615;&#25913;&#36827;&#65292;&#21033;&#29992;&#31526;&#21495;&#25805;&#20316;&#31526;&#38477;&#20302;&#20102;&#36890;&#20449;&#25104;&#26412;&#65292;&#22312;&#20998;&#24067;&#24335;&#35757;&#32451;&#20013;&#21462;&#24471;&#20102;&#19982;&#26631;&#20934; Lion &#25110; AdamW &#20248;&#21270;&#22120;&#30456;&#24403;&#30340;&#24615;&#33021;&#65292;&#24182;&#26174;&#33879;&#20943;&#23569;&#20102;&#36890;&#20449;&#24102;&#23485;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Lion&#20248;&#21270;&#22120;&#22312;&#35757;&#32451;&#22823;&#22411;AI&#27169;&#22411;&#26041;&#38754;&#19982;AdamW&#26377;&#19968;&#23450;&#31454;&#20105;&#21147;&#65292;&#20855;&#26377;&#22312;&#20869;&#23384;&#12289;&#35745;&#31639;&#21644;&#26679;&#26412;&#25928;&#29575;&#19978;&#30340;&#20248;&#21183;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#20998;&#24067;&#24335;&#29422;&#23376;&#65292;&#36825;&#26159;&#29422;&#23376;&#22312;&#20998;&#24067;&#24335;&#35757;&#32451;&#29615;&#22659;&#20013;&#30340;&#21019;&#26032;&#24615;&#25913;&#36827;&#12290;&#21033;&#29992;&#29422;&#23376;&#20013;&#30340;&#31526;&#21495;&#25805;&#20316;&#31526;&#65292;&#25105;&#20204;&#30340;&#20998;&#24067;&#24335;&#29422;&#23376;&#21482;&#38656;&#35201;&#22312;&#24037;&#20316;&#33410;&#28857;&#21644;&#20013;&#24515;&#26381;&#21153;&#22120;&#20043;&#38388;&#20256;&#36882;&#20108;&#36827;&#21046;&#25110;&#20302;&#31934;&#24230;&#21521;&#37327;&#65292;&#26174;&#33879;&#38477;&#20302;&#20102;&#36890;&#20449;&#25104;&#26412;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#35777;&#23454;&#20102;&#20998;&#24067;&#24335;&#29422;&#23376;&#30340;&#25910;&#25947;&#24615;&#36136;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#23427;&#22312;&#22810;&#31181;&#20219;&#21153;&#12289;&#24037;&#20316;&#32773;&#25968;&#37327;&#21644;&#25209;&#37327;&#22823;&#23567;&#19978;&#34920;&#29616;&#31283;&#20581;&#65292;&#22312;&#35270;&#35273;&#21644;&#35821;&#35328;&#38382;&#39064;&#19978;&#34920;&#29616;&#20986;&#33394;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#20998;&#24067;&#24335;&#29422;&#23376;&#22312;&#32858;&#21512;&#26799;&#24230;&#19978;&#36798;&#21040;&#20102;&#19982;&#26631;&#20934;&#29422;&#23376;&#25110;AdamW&#20248;&#21270;&#22120;&#30456;&#24403;&#30340;&#24615;&#33021;&#65292;&#20294;&#36890;&#20449;&#24102;&#23485;&#26174;&#33879;&#20943;&#23569;&#12290;&#36825;&#20010;&#29305;&#24615;&#23545;&#20110;&#35757;&#32451;&#22823;&#22411;&#27169;&#22411;&#23588;&#20026;&#26377;&#21033;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00438v1 Announce Type: cross  Abstract: The Lion optimizer has been a promising competitor with the AdamW for training large AI models, with advantages on memory, computation, and sample efficiency. In this paper, we introduce Distributed Lion, an innovative adaptation of Lion for distributed training environments. Leveraging the sign operator in Lion, our Distributed Lion only requires communicating binary or lower-precision vectors between workers to the center server, significantly reducing the communication cost. Our theoretical analysis confirms Distributed Lion's convergence properties. Empirical results demonstrate its robustness across a range of tasks, worker counts, and batch sizes, on both vision and language problems. Notably, Distributed Lion attains comparable performance to standard Lion or AdamW optimizers applied on aggregated gradients, but with significantly reduced communication bandwidth. This feature is particularly advantageous for training large model
&lt;/p&gt;</description></item><item><title>&#23398;&#20064;&#21033;&#29992;&#35266;&#27979;&#25968;&#25454;&#25552;&#20986;&#20102;&#19968;&#31181;&#36880;&#27493;&#21452;&#37325;&#24378;&#20581;&#26041;&#27861;&#65292;&#36890;&#36807;&#21521;&#21518;&#24402;&#32435;&#35299;&#20915;&#20102;&#26368;&#20339;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#30340;&#38382;&#39064;</title><link>https://arxiv.org/abs/2404.00221</link><description>&lt;p&gt;
&#21033;&#29992;&#35266;&#27979;&#25968;&#25454;&#36827;&#34892;&#24378;&#20581;&#23398;&#20064;&#20197;&#33719;&#24471;&#26368;&#20339;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Robust Learning for Optimal Dynamic Treatment Regimes with Observational Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00221
&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#21033;&#29992;&#35266;&#27979;&#25968;&#25454;&#25552;&#20986;&#20102;&#19968;&#31181;&#36880;&#27493;&#21452;&#37325;&#24378;&#20581;&#26041;&#27861;&#65292;&#36890;&#36807;&#21521;&#21518;&#24402;&#32435;&#35299;&#20915;&#20102;&#26368;&#20339;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#30340;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#20844;&#20849;&#25919;&#31574;&#21644;&#21307;&#30103;&#24178;&#39044;&#28041;&#21450;&#20854;&#27835;&#30103;&#20998;&#37197;&#20013;&#30340;&#21160;&#24577;&#24615;&#65292;&#27835;&#30103;&#36890;&#24120;&#20381;&#25454;&#20808;&#21069;&#27835;&#30103;&#30340;&#21382;&#21490;&#21644;&#30456;&#20851;&#29305;&#24449;&#23545;&#27599;&#20010;&#38454;&#27573;&#30340;&#25928;&#26524;&#20855;&#26377;&#24322;&#36136;&#24615;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#32479;&#35745;&#23398;&#20064;&#26368;&#20339;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;(DTR)&#65292;&#26681;&#25454;&#20010;&#20307;&#30340;&#21382;&#21490;&#25351;&#23548;&#27599;&#20010;&#38454;&#27573;&#30340;&#26368;&#20339;&#27835;&#30103;&#20998;&#37197;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35266;&#27979;&#25968;&#25454;&#30340;&#36880;&#27493;&#21452;&#37325;&#24378;&#20581;&#26041;&#27861;&#65292;&#22312;&#39034;&#24207;&#21487;&#24573;&#30053;&#24615;&#20551;&#35774;&#19979;&#23398;&#20064;&#26368;&#20339;DTR&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#21521;&#21518;&#24402;&#32435;&#35299;&#20915;&#20102;&#39034;&#24207;&#27835;&#30103;&#20998;&#37197;&#38382;&#39064;&#65292;&#22312;&#27599;&#19968;&#27493;&#20013;&#65292;&#25105;&#20204;&#32467;&#21512;&#20542;&#21521;&#35780;&#20998;&#21644;&#34892;&#21160;&#20540;&#20989;&#25968;(Q&#20989;&#25968;)&#30340;&#20272;&#35745;&#37327;&#65292;&#26500;&#24314;&#20102;&#25919;&#31574;&#20215;&#20540;&#30340;&#22686;&#24378;&#21453;&#21521;&#27010;&#29575;&#21152;&#26435;&#20272;&#35745;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00221v1 Announce Type: cross  Abstract: Many public policies and medical interventions involve dynamics in their treatment assignments, where treatments are sequentially assigned to the same individuals across multiple stages, and the effect of treatment at each stage is usually heterogeneous with respect to the history of prior treatments and associated characteristics. We study statistical learning of optimal dynamic treatment regimes (DTRs) that guide the optimal treatment assignment for each individual at each stage based on the individual's history. We propose a step-wise doubly-robust approach to learn the optimal DTR using observational data under the assumption of sequential ignorability. The approach solves the sequential treatment assignment problem through backward induction, where, at each step, we combine estimators of propensity scores and action-value functions (Q-functions) to construct augmented inverse probability weighting estimators of values of policies 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#21487;&#37096;&#20998;&#35266;&#27979;&#22810;&#20256;&#24863;&#22120;&#24207;&#36143;&#21464;&#28857;&#26816;&#27979;&#30340;&#33258;&#36866;&#24212;&#19978;&#32622;&#20449;&#21306;&#38388;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65288;AUCRSS&#65289;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#37319;&#26679;&#31574;&#30053;&#23454;&#29616;&#39640;&#25928;&#30340;&#21464;&#28857;&#26816;&#27979;&#21644;&#23450;&#20301;&#12290;</title><link>https://arxiv.org/abs/2404.00220</link><description>&lt;p&gt;
&#21487;&#37096;&#20998;&#35266;&#27979;&#24207;&#36143;&#33258;&#30456;&#20851;&#25968;&#25454;&#30340;&#21464;&#28857;&#26816;&#27979;&#65306;&#19978;&#32622;&#20449;&#21306;&#38388;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Partially-Observable Sequential Change-Point Detection for Autocorrelated Data via Upper Confidence Region
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00220
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#21487;&#37096;&#20998;&#35266;&#27979;&#22810;&#20256;&#24863;&#22120;&#24207;&#36143;&#21464;&#28857;&#26816;&#27979;&#30340;&#33258;&#36866;&#24212;&#19978;&#32622;&#20449;&#21306;&#38388;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65288;AUCRSS&#65289;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#37319;&#26679;&#31574;&#30053;&#23454;&#29616;&#39640;&#25928;&#30340;&#21464;&#28857;&#26816;&#27979;&#21644;&#23450;&#20301;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00220v1 &#20844;&#21578;&#31867;&#22411;: &#20132;&#21449;&#25688;&#35201;: &#22810;&#21464;&#37327;&#33258;&#30456;&#20851;&#25968;&#25454;&#30340;&#24207;&#36143;&#21464;&#28857;&#26816;&#27979;&#26159;&#23454;&#36341;&#20013;&#19968;&#20010;&#38750;&#24120;&#24120;&#35265;&#30340;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#24403;&#24863;&#30693;&#36164;&#28304;&#26377;&#38480;&#26102;&#65292;&#27599;&#27425;&#24863;&#30693;&#26102;&#38388;&#28857;&#21482;&#33021;&#35266;&#27979;&#22810;&#21464;&#37327;&#31995;&#32479;&#30340;&#19968;&#20010;&#23376;&#38598;&#12290;&#36825;&#23601;&#25552;&#20986;&#20102;&#21487;&#37096;&#20998;&#35266;&#27979;&#22810;&#20256;&#24863;&#22120;&#24207;&#36143;&#21464;&#28857;&#26816;&#27979;&#30340;&#38382;&#39064;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#33258;&#36866;&#24212;&#19978;&#32622;&#20449;&#21306;&#38388;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;(AUCRSS)&#30340;&#26816;&#27979;&#26041;&#26696;&#12290;&#23427;&#36890;&#36807;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;(SSM)&#23545;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#21033;&#29992;&#33258;&#36866;&#24212;&#37319;&#26679;&#31574;&#30053;&#36827;&#34892;&#39640;&#25928;&#30340;&#21464;&#28857;&#26816;&#27979;&#21644;&#23450;&#20301;&#12290;&#23545;&#22312;&#32447;&#25512;&#26029;SSM&#30340;&#37096;&#20998;&#21487;&#35266;&#27979;&#21345;&#23572;&#26364;&#28388;&#27874;&#31639;&#27861;&#36827;&#34892;&#24320;&#21457;&#65292;&#24182;&#30456;&#24212;&#22320;&#65292;&#22522;&#20110;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#30340;&#21464;&#28857;&#26816;&#27979;&#26041;&#26696;&#34987;&#24320;&#21457;&#12290;&#20998;&#26512;&#20102;&#20854;&#26816;&#27979;&#33021;&#21147;&#19982;&#33258;&#36866;&#24212;&#37319;&#26679;&#31574;&#30053;&#30340;&#20851;&#31995;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#23558;&#26816;&#27979;&#33021;&#21147;&#35270;&#20026;&#19968;&#31181;&#20877;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00220v1 Announce Type: cross  Abstract: Sequential change point detection for multivariate autocorrelated data is a very common problem in practice. However, when the sensing resources are limited, only a subset of variables from the multivariate system can be observed at each sensing time point. This raises the problem of partially observable multi-sensor sequential change point detection. For it, we propose a detection scheme called adaptive upper confidence region with state space model (AUCRSS). It models multivariate time series via a state space model (SSM), and uses an adaptive sampling policy for efficient change point detection and localization. A partially-observable Kalman filter algorithm is developed for online inference of SSM, and accordingly, a change point detection scheme based on a generalized likelihood ratio test is developed. How its detection power relates to the adaptive sampling strategy is analyzed. Meanwhile, by treating the detection power as a re
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21151;&#33021;&#36793;&#32536;&#32593;&#32476;&#27169;&#22411;&#65292;&#36890;&#36807;&#23558;&#36793;&#35270;&#20026;&#21151;&#33021;&#25968;&#25454;&#65292;&#24182;&#24341;&#20837;&#39069;&#22806;&#32500;&#24230;&#26469;&#34920;&#31034;&#20989;&#25968;&#65292;&#20351;&#29992;Tucker&#21151;&#33021;&#20998;&#35299;&#22788;&#29702;&#21151;&#33021;&#37051;&#25509;&#24352;&#37327;&#65292;&#36827;&#34892;&#27169;&#22411;&#25512;&#26029;&#20197;&#35299;&#20915;&#19981;&#35268;&#21017;&#35266;&#27979;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#27491;&#21017;&#21270;&#20351;&#22522;&#30784;&#30697;&#38453;&#23545;&#31216;&#21270;&#65292;&#26368;&#32456;&#23637;&#31034;&#20102;&#27169;&#22411;&#30340;&#29702;&#24819;&#23646;&#24615;&#12290;</title><link>https://arxiv.org/abs/2404.00218</link><description>&lt;p&gt;
&#21151;&#33021;&#36793;&#32536;&#32593;&#32476;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Functional-Edged Network Modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00218
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21151;&#33021;&#36793;&#32536;&#32593;&#32476;&#27169;&#22411;&#65292;&#36890;&#36807;&#23558;&#36793;&#35270;&#20026;&#21151;&#33021;&#25968;&#25454;&#65292;&#24182;&#24341;&#20837;&#39069;&#22806;&#32500;&#24230;&#26469;&#34920;&#31034;&#20989;&#25968;&#65292;&#20351;&#29992;Tucker&#21151;&#33021;&#20998;&#35299;&#22788;&#29702;&#21151;&#33021;&#37051;&#25509;&#24352;&#37327;&#65292;&#36827;&#34892;&#27169;&#22411;&#25512;&#26029;&#20197;&#35299;&#20915;&#19981;&#35268;&#21017;&#35266;&#27979;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#27491;&#21017;&#21270;&#20351;&#22522;&#30784;&#30697;&#38453;&#23545;&#31216;&#21270;&#65292;&#26368;&#32456;&#23637;&#31034;&#20102;&#27169;&#22411;&#30340;&#29702;&#24819;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19982;&#29616;&#26377;&#20316;&#21697;&#24418;&#25104;&#23545;&#27604;&#65292;&#29616;&#26377;&#20316;&#21697;&#37117;&#23558;&#33410;&#28857;&#35270;&#20026;&#20989;&#25968;&#65292;&#24182;&#20351;&#29992;&#36793;&#26469;&#34920;&#31034;&#19981;&#21516;&#20989;&#25968;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#32593;&#32476;&#24314;&#27169;&#65292;&#20854;&#20013;&#36793;&#26159;&#21151;&#33021;&#25968;&#25454;&#65292;&#24182;&#23558;&#37051;&#25509;&#30697;&#38453;&#36716;&#25442;&#20026;&#21151;&#33021;&#37051;&#25509;&#24352;&#37327;&#65292;&#24341;&#20837;&#19968;&#20010;&#39069;&#22806;&#30340;&#32500;&#24230;&#19987;&#38376;&#29992;&#20110;&#20989;&#25968;&#34920;&#31034;&#12290;&#25105;&#20204;&#20351;&#29992;Tucker&#21151;&#33021;&#20998;&#35299;&#26469;&#22788;&#29702;&#21151;&#33021;&#37051;&#25509;&#24352;&#37327;&#65292;&#20026;&#36827;&#19968;&#27493;&#32771;&#34385;&#33410;&#28857;&#20043;&#38388;&#30340;&#31038;&#21306;&#65292;&#23545;&#22522;&#30784;&#30697;&#38453;&#36827;&#34892;&#27491;&#21017;&#21270;&#20351;&#20854;&#23545;&#31216;&#21270;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#22788;&#29702;&#21151;&#33021;&#36793;&#30340;&#19981;&#35268;&#21017;&#35266;&#27979;&#65292;&#25105;&#20204;&#36827;&#34892;&#27169;&#22411;&#25512;&#26029;&#20197;&#35299;&#20915;&#24352;&#37327;&#23436;&#25104;&#38382;&#39064;&#65292;&#36890;&#36807;Riemann&#20849;&#36717;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#36827;&#34892;&#20248;&#21270;&#12290;&#38500;&#27492;&#20043;&#22806;&#65292;&#25105;&#20204;&#36824;&#25512;&#23548;&#20986;&#20960;&#20010;&#23450;&#29702;&#26469;&#23637;&#31034;&#21151;&#33021;&#36793;&#32536;&#32593;&#32476;&#27169;&#22411;&#30340;&#29702;&#24819;&#23646;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#27169;&#25311;&#25968;&#25454;&#21644;&#30495;&#23454;&#22320;&#38081;&#31995;&#32479;&#25968;&#25454;&#35780;&#20272;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00218v1 Announce Type: cross  Abstract: Contrasts with existing works which all consider nodes as functions and use edges to represent the relationships between different functions. We target at network modeling whose edges are functional data and transform the adjacency matrix into a functional adjacency tensor, introducing an additional dimension dedicated to function representation. Tucker functional decomposition is used for the functional adjacency tensor, and to further consider the community between nodes, we regularize the basis matrices to be symmetrical. Furthermore, to deal with irregular observations of the functional edges, we conduct model inference to solve a tensor completion problem. It is optimized by a Riemann conjugate gradient descent method. Besides these, we also derive several theorems to show the desirable properties of the functional edged network model. Finally, we evaluate the efficacy of our proposed model using simulation data and real metro sys
&lt;/p&gt;</description></item><item><title>&#22312;&#27491;-&#26080;&#30417;&#30563;&#23398;&#20064;&#20013;&#65292;&#30740;&#31350;&#20102;&#39564;&#35777;&#23436;&#20840;&#38543;&#26426;&#36873;&#25321;&#20551;&#35774;&#65288;SCAR&#65289;&#21644;&#26356;&#20026;&#29616;&#23454;&#30340;&#38543;&#26426;&#36873;&#25321;&#20551;&#35774;&#65288;SAR&#65289;&#23545;&#31639;&#27861;&#22797;&#26434;&#24615;&#21644;&#36895;&#24230;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2404.00145</link><description>&lt;p&gt;
&#22312;&#27491;-&#26080;&#30417;&#30563;&#23398;&#20064;&#20013;&#39564;&#35777;&#23436;&#20840;&#38543;&#26426;&#36873;&#25321;&#20551;&#35774;
&lt;/p&gt;
&lt;p&gt;
Verifying the Selected Completely at Random Assumption in Positive-Unlabeled Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00145
&lt;/p&gt;
&lt;p&gt;
&#22312;&#27491;-&#26080;&#30417;&#30563;&#23398;&#20064;&#20013;&#65292;&#30740;&#31350;&#20102;&#39564;&#35777;&#23436;&#20840;&#38543;&#26426;&#36873;&#25321;&#20551;&#35774;&#65288;SCAR&#65289;&#21644;&#26356;&#20026;&#29616;&#23454;&#30340;&#38543;&#26426;&#36873;&#25321;&#20551;&#35774;&#65288;SAR&#65289;&#23545;&#31639;&#27861;&#22797;&#26434;&#24615;&#21644;&#36895;&#24230;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27491;-&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#30446;&#26631;&#26159;&#22312;&#21253;&#21547;&#27491;&#20363;&#21644;&#26410;&#26631;&#35760;&#23454;&#20363;&#30340;&#35757;&#32451;&#25968;&#25454;&#22522;&#30784;&#19978;&#35757;&#32451;&#20108;&#20803;&#20998;&#31867;&#22120;&#65292;&#20854;&#20013;&#26410;&#26631;&#35760;&#35266;&#27979;&#21487;&#20197;&#23646;&#20110;&#27491;&#31867;&#25110;&#36127;&#31867;&#12290;&#24314;&#27169;&#27491;-&#26080;&#30417;&#30563;&#25968;&#25454;&#38656;&#35201;&#20851;&#20110;&#26631;&#31614;&#26426;&#21046;&#30340;&#19968;&#20123;&#20551;&#35774;&#65292;&#25551;&#36848;&#21738;&#20123;&#27491;&#20363;&#34987;&#20998;&#37197;&#26631;&#31614;&#12290;&#26089;&#26399;&#30740;&#31350;&#20013;&#32771;&#34385;&#30340;&#26368;&#31616;&#21333;&#20551;&#35774;&#26159;SCAR&#65288;&#23436;&#20840;&#38543;&#26426;&#36873;&#25321;&#20551;&#35774;&#65289;&#65292;&#20854;&#27010;&#29575;&#20998;&#25968;&#20989;&#25968;&#23450;&#20041;&#20026;&#32473;&#27491;&#20363;&#20998;&#37197;&#26631;&#31614;&#30340;&#27010;&#29575;&#26159;&#24120;&#25968;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#19968;&#20010;&#26356;&#20026;&#29616;&#23454;&#30340;&#20551;&#35774;&#26159;SAR&#65288;&#38543;&#26426;&#36873;&#25321;&#65289;&#65292;&#23427;&#34920;&#26126;&#27010;&#29575;&#20989;&#25968;&#20165;&#20381;&#36182;&#20110;&#35266;&#23519;&#21040;&#30340;&#29305;&#24449;&#21521;&#37327;&#12290;&#22522;&#20110;SCAR&#30340;&#31639;&#27861;&#27604;&#22522;&#20110;SAR&#30340;&#31639;&#27861;&#31616;&#21333;&#24471;&#22810;&#65292;&#24182;&#19988;&#22312;&#35745;&#31639;&#19978;&#26356;&#24555;&#65292;&#21518;&#32773;&#36890;&#24120;&#38656;&#35201;&#25361;&#25112;&#24615;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00145v1 Announce Type: cross  Abstract: The goal of positive-unlabeled (PU) learning is to train a binary classifier on the basis of training data containing positive and unlabeled instances, where unlabeled observations can belong either to the positive class or to the negative class. Modeling PU data requires certain assumptions on the labeling mechanism that describes which positive observations are assigned a label. The simplest assumption, considered in early works, is SCAR (Selected Completely at Random Assumption), according to which the propensity score function, defined as the probability of assigning a label to a positive observation, is constant. On the other hand, a much more realistic assumption is SAR (Selected at Random), which states that the propensity function solely depends on the observed feature vector. SCAR-based algorithms are much simpler and computationally much faster compared to SAR-based algorithms, which usually require challenging estimation of 
&lt;/p&gt;</description></item><item><title>&#22312;&#23545;&#25239;&#24615;&#29615;&#22659;&#20013;&#65292;&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20462;&#25913;&#36716;&#31227;&#26680;&#23494;&#24230;&#30340;&#25200;&#21160;&#27169;&#22411;&#65292;&#25299;&#23637;&#20102;&#20256;&#32479;&#30340;&#36793;&#32536;&#25935;&#24863;&#24615;&#27169;&#22411;&#65292;&#23545;&#26080;&#38480;&#26102;&#38388;RL&#20013;&#31574;&#30053;&#20215;&#20540;&#36827;&#34892;&#20102;&#23574;&#38160;&#36793;&#30028;&#30340;&#21051;&#30011;&#21644;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2404.00099</link><description>&lt;p&gt;
&#22312;&#24378;&#20581;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#39640;&#25928;&#32780;&#23574;&#38160;&#30340;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Efficient and Sharp Off-Policy Evaluation in Robust Markov Decision Processes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00099
&lt;/p&gt;
&lt;p&gt;
&#22312;&#23545;&#25239;&#24615;&#29615;&#22659;&#20013;&#65292;&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20462;&#25913;&#36716;&#31227;&#26680;&#23494;&#24230;&#30340;&#25200;&#21160;&#27169;&#22411;&#65292;&#25299;&#23637;&#20102;&#20256;&#32479;&#30340;&#36793;&#32536;&#25935;&#24863;&#24615;&#27169;&#22411;&#65292;&#23545;&#26080;&#38480;&#26102;&#38388;RL&#20013;&#31574;&#30053;&#20215;&#20540;&#36827;&#34892;&#20102;&#23574;&#38160;&#36793;&#30028;&#30340;&#21051;&#30011;&#21644;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#20013;&#32473;&#23450;&#26469;&#33258;&#21407;&#22987;MDP&#30340;&#36716;&#31227;&#35266;&#23519;&#26102;&#65292;&#22312;&#26368;&#20339;&#21644;&#26368;&#22351;&#24773;&#20917;&#19979;&#35780;&#20272;&#31574;&#30053;&#65292;&#26080;&#35770;&#26159;&#22312;&#30456;&#21516;&#31574;&#30053;&#36824;&#26159;&#19981;&#21516;&#31574;&#30053;&#19979;&#12290;&#24403;&#23384;&#22312;&#21382;&#21490;&#21644;&#26410;&#26469;&#29615;&#22659;&#20043;&#38388;&#21487;&#33021;&#21457;&#29983;&#36716;&#21464;&#30340;&#21487;&#33021;&#24615;&#26102;&#65292;&#27604;&#22914;&#30001;&#20110;&#26410;&#27979;&#37327;&#30340;&#28151;&#26434;&#12289;&#20998;&#24067;&#36716;&#31227;&#25110;&#23545;&#25239;&#24615;&#29615;&#22659;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25200;&#21160;&#27169;&#22411;&#65292;&#21487;&#20197;&#23558;&#36716;&#31227;&#26680;&#23494;&#24230;&#20462;&#25913;&#33267;&#32473;&#23450;&#20056;&#27861;&#22240;&#23376;&#25110;&#20854;&#20498;&#25968;&#65292;&#36825;&#23558;&#32463;&#20856;&#30340;&#36793;&#38469;&#25935;&#24863;&#24615;&#27169;&#22411;&#65288;MSM&#65289;&#25193;&#23637;&#21040;&#26080;&#38480;&#26102;&#38388; RL&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#22312;&#36825;&#20010;&#27169;&#22411;&#19979;&#30340;&#31574;&#30053;&#20215;&#20540;&#30340;&#23574;&#38160;&#36793;&#30028;&#65292;&#21363;&#22312;&#32473;&#23450;&#26469;&#33258;&#21407;&#22987;MDP&#30340;&#36716;&#31227;&#35266;&#27979;&#26102;&#21487;&#33021;&#30340;&#26368;&#20005;&#26684;&#36793;&#30028;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20174;&#36825;&#20123;&#36716;&#31227;&#35266;&#23519;&#20013;&#20272;&#35745;&#36825;&#20123;&#36793;&#30028;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#20272;&#35745;&#22120;&#65292;&#20855;&#26377;&#20960;&#20010;&#21560;&#24341;&#20154;&#30340;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00099v1 Announce Type: new  Abstract: We study evaluating a policy under best- and worst-case perturbations to a Markov decision process (MDP), given transition observations from the original MDP, whether under the same or different policy. This is an important problem when there is the possibility of a shift between historical and future environments, due to e.g. unmeasured confounding, distributional shift, or an adversarial environment. We propose a perturbation model that can modify transition kernel densities up to a given multiplicative factor or its reciprocal, which extends the classic marginal sensitivity model (MSM) for single time step decision making to infinite-horizon RL. We characterize the sharp bounds on policy value under this model, that is, the tightest possible bounds given by the transition observations from the original MDP, and we study the estimation of these bounds from such transition observations. We develop an estimator with several appealing gua
&lt;/p&gt;</description></item><item><title>&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#27169;&#22411;&#20026;&#32479;&#35745;&#27169;&#22411;&#36873;&#25321;&#25552;&#20379;&#20102;&#28789;&#27963;&#32780;&#24378;&#22823;&#30340;&#26694;&#26550;&#65292;&#25581;&#31034;&#20102;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#30340;&#22810;&#25165;&#22810;&#33402;&#21644;&#39640;&#25928;&#24615;&#65292;&#20026;&#22312;&#21508;&#20010;&#23398;&#31185;&#39046;&#22495;&#20013;&#24212;&#23545;&#22797;&#26434;&#25361;&#25112;&#25552;&#20379;&#20102;&#21019;&#26032;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2404.00085</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#65306;&#28145;&#24230;&#23398;&#20064;&#30340;&#26367;&#20195;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Bayesian Nonparametrics: An Alternative to Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00085
&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#27169;&#22411;&#20026;&#32479;&#35745;&#27169;&#22411;&#36873;&#25321;&#25552;&#20379;&#20102;&#28789;&#27963;&#32780;&#24378;&#22823;&#30340;&#26694;&#26550;&#65292;&#25581;&#31034;&#20102;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#30340;&#22810;&#25165;&#22810;&#33402;&#21644;&#39640;&#25928;&#24615;&#65292;&#20026;&#22312;&#21508;&#20010;&#23398;&#31185;&#39046;&#22495;&#20013;&#24212;&#23545;&#22797;&#26434;&#25361;&#25112;&#25552;&#20379;&#20102;&#21019;&#26032;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#27169;&#22411;&#20026;&#32479;&#35745;&#27169;&#22411;&#36873;&#25321;&#25552;&#20379;&#20102;&#28789;&#27963;&#32780;&#24378;&#22823;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#20351;&#27169;&#22411;&#22797;&#26434;&#24230;&#36866;&#24212;&#21508;&#31181;&#25968;&#25454;&#38598;&#30340;&#22797;&#26434;&#24615;&#12290;&#26412;&#35843;&#26597;&#26088;&#22312;&#28145;&#20837;&#25506;&#35752;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#30340;&#37325;&#35201;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#35299;&#20915;&#32479;&#35745;&#23398;&#12289;&#35745;&#31639;&#26426;&#31185;&#23398;&#21644;&#30005;&#27668;&#24037;&#31243;&#31561;&#21508;&#20010;&#39046;&#22495;&#30340;&#22797;&#26434;&#25361;&#25112;&#26041;&#38754;&#12290;&#36890;&#36807;&#38416;&#26126;&#36825;&#20123;&#38750;&#21442;&#25968;&#27169;&#22411;&#30340;&#22522;&#26412;&#29305;&#24615;&#21644;&#29702;&#35770;&#22522;&#30784;&#65292;&#26412;&#35843;&#26597;&#26088;&#22312;&#25552;&#20379;&#23545;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#21450;&#20854;&#22312;&#35299;&#20915;&#22797;&#26434;&#38382;&#39064;&#26041;&#38754;&#30340;&#30456;&#20851;&#24615;&#30340;&#20840;&#38754;&#29702;&#35299;&#65292;&#29305;&#21035;&#26159;&#22312;&#22810;&#30446;&#26631;&#36319;&#36394;&#39046;&#22495;&#12290;&#36890;&#36807;&#36825;&#31181;&#25506;&#32034;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#30340;&#22810;&#25165;&#22810;&#33402;&#21644;&#39640;&#25928;&#24615;&#65292;&#20026;&#22312;&#21508;&#20010;&#23398;&#31185;&#39046;&#22495;&#20013;&#24212;&#23545;&#22797;&#26434;&#25361;&#25112;&#25552;&#20379;&#20102;&#21019;&#26032;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00085v1 Announce Type: new  Abstract: Bayesian nonparametric models offer a flexible and powerful framework for statistical model selection, enabling the adaptation of model complexity to the intricacies of diverse datasets. This survey intends to delve into the significance of Bayesian nonparametrics, particularly in addressing complex challenges across various domains such as statistics, computer science, and electrical engineering. By elucidating the basic properties and theoretical foundations of these nonparametric models, this survey aims to provide a comprehensive understanding of Bayesian nonparametrics and their relevance in addressing complex problems, particularly in the domain of multi-object tracking. Through this exploration, we uncover the versatility and efficacy of Bayesian nonparametric methodologies, paving the way for innovative solutions to intricate challenges across diverse disciplines.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20984;&#32422;&#26463;&#30340;&#38543;&#26426;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#28176;&#36817;&#20445;&#35777;&#30340;VRPG&#31639;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#24615;&#33021;&#21463;&#21040;&#35299;&#20197;&#21450;&#24102;&#20984;&#32422;&#26463;&#35299;&#20915;&#30340;&#38382;&#39064;&#30340;&#32553;&#25918;&#36317;&#31163;&#25511;&#21046;&#12290;</title><link>https://arxiv.org/abs/2404.00042</link><description>&lt;p&gt;
&#20855;&#26377;&#32422;&#26463;&#30340;&#38543;&#26426;&#20248;&#21270;&#65306;&#38750;&#28176;&#36817;&#23454;&#20363;&#30456;&#20851;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Stochastic Optimization with Constraints: A Non-asymptotic Instance-Dependent Analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00042
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20984;&#32422;&#26463;&#30340;&#38543;&#26426;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#28176;&#36817;&#20445;&#35777;&#30340;VRPG&#31639;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#24615;&#33021;&#21463;&#21040;&#35299;&#20197;&#21450;&#24102;&#20984;&#32422;&#26463;&#35299;&#20915;&#30340;&#38382;&#39064;&#30340;&#32553;&#25918;&#36317;&#31163;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#38543;&#26426;&#20984;&#20248;&#21270;&#22312;&#20984;&#32422;&#26463;&#19979;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#36825;&#20010;&#38382;&#39064;&#30340;&#33258;&#28982;&#26041;&#24046;&#20943;&#23569;&#30340;&#36817;&#31471;&#26799;&#24230;&#65288;VRPG&#65289;&#31639;&#27861;&#30340;&#34892;&#20026;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;VRPG&#31639;&#27861;&#30340;&#38750;&#28176;&#36817;&#20445;&#35777;&#12290;&#19982;&#26497;&#23567;&#20540;&#26368;&#22351;&#24773;&#20917;&#20445;&#35777;&#30456;&#21453;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#26159;&#22522;&#20110;&#23454;&#20363;&#30340;&#12290;&#36825;&#24847;&#21619;&#30528;&#25105;&#20204;&#30340;&#20445;&#35777;&#25429;&#25417;&#20102;&#25439;&#22833;&#20989;&#25968;&#30340;&#22797;&#26434;&#24615;&#65292;&#22122;&#22768;&#30340;&#21464;&#24322;&#24615;&#21644;&#32422;&#26463;&#38598;&#30340;&#20960;&#20309;&#24615;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;VRPG&#31639;&#27861;&#30340;&#38750;&#28176;&#36817;&#24615;&#33021;&#21463;&#32473;&#23450;&#38382;&#39064;&#30340;&#35299;&#21644;&#32473;&#23450;&#20984;&#32422;&#26463;&#19979;&#35299;&#20915;&#30340;&#29305;&#23450;&#23567;&#25200;&#21160;&#38382;&#39064;&#30340;&#35299;&#20043;&#38388;&#30340;&#32553;&#25918;&#36317;&#31163;&#65288;&#30001;$\sqrt{N}$&#32553;&#25918;&#65289;&#30340;&#25511;&#21046;&#65292;&#36825;&#37324;&#65292;$N$&#34920;&#31034;&#26679;&#26412;&#25968;&#12290;&#21033;&#29992;&#23616;&#37096;&#26497;&#23567;&#20540;&#19979;&#30028;&#21644;&#25200;&#21160;&#38382;&#39064;&#35299;&#20043;&#38388;&#30340;&#19968;&#31181;&#25104;&#29087;&#32852;&#31995;&#65292;&#25105;&#20204;&#34920;&#26126;&#24403;$N \rightarrow +\infty$&#26102;&#65292;&#26497;&#23567;&#20540;&#23384;&#22312;&#24182;&#19988;&#21463;&#25351;&#23450;&#20984;&#32422;&#26463;&#30340;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00042v1 Announce Type: cross  Abstract: We consider the problem of stochastic convex optimization under convex constraints. We analyze the behavior of a natural variance reduced proximal gradient (VRPG) algorithm for this problem. Our main result is a non-asymptotic guarantee for VRPG algorithm. Contrary to minimax worst case guarantees, our result is instance-dependent in nature. This means that our guarantee captures the complexity of the loss function, the variability of the noise, and the geometry of the constraint set. We show that the non-asymptotic performance of the VRPG algorithm is governed by the scaled distance (scaled by $\sqrt{N}$) between the solutions of the given problem and that of a certain small perturbation of the given problem -- both solved under the given convex constraints; here, $N$ denotes the number of samples. Leveraging a well-established connection between local minimax lower bounds and solutions to perturbed problems, we show that as $N \right
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Systemic Quantum Score (SQS)&#30340;&#26032;&#26041;&#27861;&#65292;&#23637;&#31034;&#22312;&#37329;&#34701;&#39046;&#22495;&#29983;&#20135;&#32423;&#24212;&#29992;&#26696;&#20363;&#20013;&#30456;&#27604;&#32431;&#32463;&#20856;&#27169;&#22411;&#26356;&#26377;&#20248;&#21183;&#65292;&#33021;&#22815;&#20174;&#36739;&#23569;&#25968;&#25454;&#28857;&#20013;&#25552;&#21462;&#27169;&#24335;&#24182;&#34920;&#29616;&#20986;&#26356;&#22909;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2404.00015</link><description>&lt;p&gt;
&#21033;&#29992;&#37327;&#23376;&#22686;&#24378;&#26426;&#22120;&#23398;&#20064;&#36171;&#33021;&#20449;&#29992;&#35780;&#20998;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Empowering Credit Scoring Systems with Quantum-Enhanced Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00015
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Systemic Quantum Score (SQS)&#30340;&#26032;&#26041;&#27861;&#65292;&#23637;&#31034;&#22312;&#37329;&#34701;&#39046;&#22495;&#29983;&#20135;&#32423;&#24212;&#29992;&#26696;&#20363;&#20013;&#30456;&#27604;&#32431;&#32463;&#20856;&#27169;&#22411;&#26356;&#26377;&#20248;&#21183;&#65292;&#33021;&#22815;&#20174;&#36739;&#23569;&#25968;&#25454;&#28857;&#20013;&#25552;&#21462;&#27169;&#24335;&#24182;&#34920;&#29616;&#20986;&#26356;&#22909;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Quantum Kernels&#34987;&#35748;&#20026;&#22312;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#30340;&#26089;&#26399;&#38454;&#27573;&#25552;&#20379;&#20102;&#26377;&#29992;&#24615;&#12290;&#28982;&#32780;&#65292;&#22312;&#21033;&#29992;&#24222;&#22823;&#25968;&#25454;&#38598;&#26102;&#65292;&#39640;&#24230;&#22797;&#26434;&#30340;&#32463;&#20856;&#27169;&#22411;&#24456;&#38590;&#36229;&#36234;&#65292;&#29305;&#21035;&#26159;&#22312;&#29702;&#35299;&#21147;&#26041;&#38754;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#19968;&#26086;&#25968;&#25454;&#31232;&#32570;&#19988;&#20542;&#26012;&#65292;&#32463;&#20856;&#27169;&#22411;&#23601;&#20250;&#36935;&#21040;&#22256;&#38590;&#12290;&#37327;&#23376;&#29305;&#24449;&#31354;&#38388;&#34987;&#39044;&#35745;&#22312;&#36825;&#26679;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24773;&#26223;&#20013;&#33021;&#22815;&#25214;&#21040;&#26356;&#22909;&#30340;&#25968;&#25454;&#29305;&#24449;&#21644;&#30446;&#26631;&#31867;&#21035;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#26368;&#37325;&#35201;&#30340;&#26159;&#22686;&#24378;&#20102;&#27867;&#21270;&#33021;&#21147;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Systemic Quantum Score (SQS)&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#21021;&#27493;&#32467;&#26524;&#65292;&#34920;&#26126;&#22312;&#37329;&#34701;&#34892;&#19994;&#29983;&#20135;&#32423;&#24212;&#29992;&#26696;&#20363;&#20013;&#65292;SQS&#21487;&#33021;&#27604;&#32431;&#32463;&#20856;&#27169;&#22411;&#20855;&#26377;&#20248;&#21183;&#12290;&#25105;&#20204;&#30340;&#20855;&#20307;&#30740;&#31350;&#34920;&#26126;&#65292;SQS&#33021;&#22815;&#20174;&#36739;&#23569;&#30340;&#25968;&#25454;&#28857;&#20013;&#25552;&#21462;&#20986;&#27169;&#24335;&#65292;&#24182;&#19988;&#22312;&#25968;&#25454;&#38656;&#27714;&#37327;&#22823;&#30340;&#31639;&#27861;&#65288;&#22914;XGBoost&#65289;&#19978;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#24102;&#26469;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00015v1 Announce Type: cross  Abstract: Quantum Kernels are projected to provide early-stage usefulness for quantum machine learning. However, highly sophisticated classical models are hard to surpass without losing interpretability, particularly when vast datasets can be exploited. Nonetheless, classical models struggle once data is scarce and skewed. Quantum feature spaces are projected to find better links between data features and the target class to be predicted even in such challenging scenarios and most importantly, enhanced generalization capabilities. In this work, we propose a novel approach called Systemic Quantum Score (SQS) and provide preliminary results indicating potential advantage over purely classical models in a production grade use case for the Finance sector. SQS shows in our specific study an increased capacity to extract patterns out of fewer data points as well as improved performance over data-hungry algorithms such as XGBoost, providing advantage i
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26680;&#21253;&#25216;&#26415;&#35777;&#26126;&#21453;&#21521;&#25311;&#21512;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;&#26680;&#22810;&#37325;&#32593;&#26684;&#31639;&#27861;&#65292;&#36890;&#36807;&#31232;&#30095;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#22686;&#24378;&#21453;&#21521;&#25311;&#21512;&#65292;&#36866;&#29992;&#20110;&#32467;&#26500;&#21270;&#21644;&#20998;&#25955;&#25968;&#25454;&#30340;&#21152;&#24615;GPs&#12290;</title><link>https://arxiv.org/abs/2403.13300</link><description>&lt;p&gt;
&#26680;&#22810;&#37325;&#32593;&#26684;&#65306;&#36890;&#36807;&#31232;&#30095;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#21152;&#36895;&#21453;&#21521;&#25311;&#21512;
&lt;/p&gt;
&lt;p&gt;
Kernel Multigrid: Accelerate Back-fitting via Sparse Gaussian Process Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13300
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26680;&#21253;&#25216;&#26415;&#35777;&#26126;&#21453;&#21521;&#25311;&#21512;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;&#26680;&#22810;&#37325;&#32593;&#26684;&#31639;&#27861;&#65292;&#36890;&#36807;&#31232;&#30095;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#22686;&#24378;&#21453;&#21521;&#25311;&#21512;&#65292;&#36866;&#29992;&#20110;&#32467;&#26500;&#21270;&#21644;&#20998;&#25955;&#25968;&#25454;&#30340;&#21152;&#24615;GPs&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28155;&#21152;&#39640;&#26031;&#36807;&#31243;(GPs)&#26159;&#38750;&#21442;&#25968;&#29305;&#24449;&#36873;&#25321;&#30340;&#27969;&#34892;&#26041;&#27861;&#12290;&#23545;&#20110;&#36825;&#20123;&#27169;&#22411;&#30340;&#24120;&#35265;&#35757;&#32451;&#26041;&#27861;&#26159;&#36125;&#21494;&#26031;&#21453;&#21521;&#25311;&#21512;&#12290;&#28982;&#32780;&#65292;&#22312;&#35757;&#32451;&#21152;&#24615;GPs&#26102;&#65292;&#21453;&#21521;&#25311;&#21512;&#30340;&#25910;&#25947;&#36895;&#24230;&#20173;&#28982;&#26159;&#19968;&#20010;&#24748;&#32780;&#26410;&#20915;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#21033;&#29992;&#19968;&#31181;&#31216;&#20026;&#26680;&#21253;(KP)&#30340;&#25216;&#26415;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21453;&#21521;&#25311;&#21512;&#30340;&#25910;&#25947;&#36895;&#24230;&#19981;&#20250;&#27604;$(1-\mathcal{O}(\frac{1}{n}))^t$&#26356;&#24555;&#65292;&#20854;&#20013;$n$&#21644;$t$&#20998;&#21035;&#34920;&#31034;&#25968;&#25454;&#22823;&#23567;&#21644;&#36845;&#20195;&#27425;&#25968;&#12290;&#22240;&#27492;&#65292;&#21453;&#21521;&#25311;&#21512;&#38656;&#35201;&#26368;&#23569;$\mathcal{O}(n\log n)$&#27425;&#36845;&#20195;&#25165;&#33021;&#23454;&#29616;&#25910;&#25947;&#12290;&#22522;&#20110;KP&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#26680;&#22810;&#37325;&#32593;&#26684;(KMG)&#30340;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#23558;&#31232;&#30095;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;(GPR)&#32435;&#20837;&#27599;&#20010;&#21453;&#21521;&#25311;&#21512;&#36845;&#20195;&#20043;&#21518;&#22788;&#29702;&#27531;&#24046;&#26469;&#22686;&#24378;&#21453;&#21521;&#25311;&#21512;&#12290;&#23427;&#36866;&#29992;&#20110;&#20855;&#26377;&#32467;&#26500;&#21270;&#21644;&#20998;&#25955;&#25968;&#25454;&#30340;&#21152;&#24615;GPs&#12290;&#20174;&#29702;&#35770;&#19978;&#35762;&#65292;&#25105;&#20204;&#35777;&#26126;K
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13300v1 Announce Type: cross  Abstract: Additive Gaussian Processes (GPs) are popular approaches for nonparametric feature selection. The common training method for these models is Bayesian Back-fitting. However, the convergence rate of Back-fitting in training additive GPs is still an open problem. By utilizing a technique called Kernel Packets (KP), we prove that the convergence rate of Back-fitting is no faster than $(1-\mathcal{O}(\frac{1}{n}))^t$, where $n$ and $t$ denote the data size and the iteration number, respectively. Consequently, Back-fitting requires a minimum of $\mathcal{O}(n\log n)$ iterations to achieve convergence. Based on KPs, we further propose an algorithm called Kernel Multigrid (KMG). This algorithm enhances Back-fitting by incorporating a sparse Gaussian Process Regression (GPR) to process the residuals subsequent to each Back-fitting iteration. It is applicable to additive GPs with both structured and scattered data. Theoretically, we prove that K
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36923;&#36753;&#22238;&#24402;&#38382;&#39064;&#30340;&#31616;&#21333;&#38543;&#26426;&#25277;&#26679;&#31639;&#27861;&#65292;&#36890;&#36807;&#38543;&#26426;&#30697;&#38453;&#20056;&#27861;&#23454;&#29616;&#39640;&#36136;&#37327;&#36924;&#36817;&#20272;&#35745;&#27010;&#29575;&#21644;&#27169;&#22411;&#25972;&#20307;&#24046;&#24322;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.16326</link><description>&lt;p&gt;
&#36923;&#36753;&#22238;&#24402;&#30340;&#21487;&#35777;&#23454;&#20934;&#30830;&#24615;&#38543;&#26426;&#25277;&#26679;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Provably Accurate Randomized Sampling Algorithm for Logistic Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16326
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36923;&#36753;&#22238;&#24402;&#38382;&#39064;&#30340;&#31616;&#21333;&#38543;&#26426;&#25277;&#26679;&#31639;&#27861;&#65292;&#36890;&#36807;&#38543;&#26426;&#30697;&#38453;&#20056;&#27861;&#23454;&#29616;&#39640;&#36136;&#37327;&#36924;&#36817;&#20272;&#35745;&#27010;&#29575;&#21644;&#27169;&#22411;&#25972;&#20307;&#24046;&#24322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#36923;&#36753;&#22238;&#24402;&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#20110;&#20108;&#20998;&#31867;&#20219;&#21153;&#30340;&#30417;&#30563;&#23398;&#20064;&#25216;&#26415;&#12290;&#24403;&#35266;&#27979;&#25968;&#37327;&#36828;&#36828;&#36229;&#36807;&#39044;&#27979;&#21464;&#37327;&#25968;&#37327;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#22522;&#20110;&#38543;&#26426;&#25277;&#26679;&#30340;&#36923;&#36753;&#22238;&#24402;&#38382;&#39064;&#31639;&#27861;&#65292;&#20445;&#35777;&#39640;&#36136;&#37327;&#36924;&#36817;&#20272;&#35745;&#27010;&#29575;&#21644;&#27169;&#22411;&#25972;&#20307;&#24046;&#24322;&#24615;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#24314;&#31435;&#22312;&#20004;&#20010;&#31616;&#21333;&#30340;&#32467;&#26500;&#26465;&#20214;&#22522;&#30784;&#19978;&#65292;&#36825;&#20004;&#20010;&#26465;&#20214;&#21487;&#24402;&#32467;&#20026;&#38543;&#26426;&#30697;&#38453;&#20056;&#27861;&#65292;&#26159;&#38543;&#26426;&#21270;&#25968;&#20540;&#32447;&#24615;&#20195;&#25968;&#30340;&#22522;&#26412;&#19988;&#28145;&#20837;&#29702;&#35299;&#30340;&#22522;&#20803;&#12290;&#24403;&#21033;&#29992;&#26464;&#26438;&#20998;&#25968;&#23545;&#35266;&#27979;&#36827;&#34892;&#25277;&#26679;&#26102;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#36923;&#36753;&#22238;&#24402;&#30340;&#20272;&#35745;&#27010;&#29575;&#23646;&#24615;&#65292;&#24182;&#35777;&#26126;&#20934;&#30830;&#36924;&#36817;&#21487;&#20197;&#36890;&#36807;&#36828;&#23567;&#20110;&#24635;&#35266;&#27979;&#25968;&#30340;&#26679;&#26412;&#23454;&#29616;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#39564;&#35777;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16326v1 Announce Type: cross  Abstract: In statistics and machine learning, logistic regression is a widely-used supervised learning technique primarily employed for binary classification tasks. When the number of observations greatly exceeds the number of predictor variables, we present a simple, randomized sampling-based algorithm for logistic regression problem that guarantees high-quality approximations to both the estimated probabilities and the overall discrepancy of the model. Our analysis builds upon two simple structural conditions that boil down to randomized matrix multiplication, a fundamental and well-understood primitive of randomized numerical linear algebra. We analyze the properties of estimated probabilities of logistic regression when leverage scores are used to sample observations, and prove that accurate approximations can be achieved with a sample whose size is much smaller than the total number of observations. To further validate our theoretical findi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#21160;&#24577;&#31995;&#32479;&#20013;&#30340;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#38382;&#39064;&#65292;&#21033;&#29992;&#23884;&#22871;&#31890;&#23376;&#28388;&#27874;&#22120;&#21644;&#31435;&#20307;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#26469;&#36827;&#34892;&#22522;&#20110;&#26799;&#24230;&#30340;&#31574;&#30053;&#20248;&#21270;&#65292;&#30456;&#27604;&#20110;&#20854;&#20182;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.07868</link><description>&lt;p&gt;
&#21160;&#24577;&#31995;&#32479;&#20013;&#30340;&#23454;&#39564;&#35774;&#35745;&#30340;&#23884;&#22871;&#31890;&#23376;&#28388;&#27874;&#22120;
&lt;/p&gt;
&lt;p&gt;
Nesting Particle Filters for Experimental Design in Dynamical Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07868
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#21160;&#24577;&#31995;&#32479;&#20013;&#30340;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#38382;&#39064;&#65292;&#21033;&#29992;&#23884;&#22871;&#31890;&#23376;&#28388;&#27874;&#22120;&#21644;&#31435;&#20307;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#26469;&#36827;&#34892;&#22522;&#20110;&#26799;&#24230;&#30340;&#31574;&#30053;&#20248;&#21270;&#65292;&#30456;&#27604;&#20110;&#20854;&#20182;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#38750;&#20132;&#25442;&#25968;&#25454;&#65292;&#24182;&#23558;&#20854;&#24418;&#24335;&#21270;&#20026;&#39118;&#38505;&#25935;&#24863;&#30340;&#31574;&#30053;&#20248;&#21270;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#20869;&#22806;SMC^2&#31639;&#27861;&#65292;&#20351;&#29992;&#23884;&#22871;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#65288;SMC&#65289;&#20272;&#35745;&#22120;&#26469;&#39044;&#27979;&#26399;&#26395;&#30340;&#20449;&#24687;&#22686;&#30410;&#65292;&#24182;&#23558;&#20854;&#23884;&#20837;&#21040;&#31890;&#23376;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#65288;pMCMC&#65289;&#26694;&#26550;&#20013;&#36827;&#34892;&#22522;&#20110;&#26799;&#24230;&#30340;&#31574;&#30053;&#20248;&#21270;&#12290;&#19982;&#26368;&#36817;&#20381;&#36182;&#20110;&#20559;&#20272;&#35745;&#22120;&#26469;&#25674;&#38144;&#20808;&#21069;&#23398;&#20064;&#35774;&#35745;&#31574;&#30053;&#30340;&#25104;&#26412;&#30340;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#22312;&#19968;&#32452;&#21160;&#24577;&#31995;&#32479;&#30340;&#25968;&#20540;&#39564;&#35777;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a novel approach to Bayesian Experimental Design (BED) for non-exchangeable data that formulates it as risk-sensitive policy optimization. We develop the Inside-Out SMC^2 algorithm that uses a nested sequential Monte Carlo (SMC) estimator of the expected information gain and embeds it into a particle Markov chain Monte Carlo (pMCMC) framework to perform gradient-based policy optimization. This is in contrast to recent approaches that rely on biased estimators of the expected information gain (EIG) to amortize the cost of experiments by learning a design policy in advance. Numerical validation on a set of dynamical systems showcases the efficacy of our method in comparison to other state-of-the-art strategies.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#22806;&#28304;&#21464;&#37327;&#30340;&#20998;&#24067;&#65292;&#25552;&#39640;&#20102;&#32467;&#26500;&#21270;&#22240;&#26524;&#27169;&#22411;&#30340;&#36817;&#20284;&#31934;&#24230;&#65292;&#24182;&#23558;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#25193;&#23637;&#21040;&#26356;&#19968;&#33324;&#30340;&#22240;&#26524;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2402.02277</link><description>&lt;p&gt;
&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#36890;&#36807;&#22806;&#28304;&#20998;&#24067;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Causal Bayesian Optimization via Exogenous Distribution Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02277
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#22806;&#28304;&#21464;&#37327;&#30340;&#20998;&#24067;&#65292;&#25552;&#39640;&#20102;&#32467;&#26500;&#21270;&#22240;&#26524;&#27169;&#22411;&#30340;&#36817;&#20284;&#31934;&#24230;&#65292;&#24182;&#23558;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#25193;&#23637;&#21040;&#26356;&#19968;&#33324;&#30340;&#22240;&#26524;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32467;&#26500;&#21270;&#22240;&#26524;&#27169;&#22411;&#20013;&#65292;&#23558;&#30446;&#26631;&#21464;&#37327;&#26368;&#22823;&#21270;&#20316;&#20026;&#25805;&#20316;&#30446;&#26631;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#38382;&#39064;&#12290;&#29616;&#26377;&#30340;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;CBO&#65289;&#26041;&#27861;&#35201;&#20040;&#20381;&#36182;&#20110;&#25913;&#21464;&#22240;&#26524;&#32467;&#26500;&#20197;&#26368;&#22823;&#21270;&#22870;&#21169;&#30340;&#30828;&#24178;&#39044;&#65292;&#35201;&#20040;&#24341;&#20837;&#21160;&#20316;&#33410;&#28857;&#21040;&#20869;&#29983;&#21464;&#37327;&#20013;&#65292;&#20197;&#35843;&#25972;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#20197;&#23454;&#29616;&#30446;&#26631;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#22806;&#28304;&#21464;&#37327;&#30340;&#20998;&#24067;&#65292;&#36825;&#22312;&#29616;&#26377;&#26041;&#27861;&#20013;&#36890;&#24120;&#34987;&#24573;&#30053;&#25110;&#36890;&#36807;&#26399;&#26395;&#36827;&#34892;&#36793;&#32536;&#21270;&#12290;&#22806;&#28304;&#20998;&#24067;&#23398;&#20064;&#25552;&#39640;&#20102;&#36890;&#24120;&#36890;&#36807;&#26377;&#38480;&#35266;&#27979;&#25968;&#25454;&#35757;&#32451;&#30340;&#20195;&#29702;&#27169;&#22411;&#20013;&#30340;&#32467;&#26500;&#21270;&#22240;&#26524;&#27169;&#22411;&#30340;&#36817;&#20284;&#31934;&#24230;&#12290;&#27492;&#22806;&#65292;&#23398;&#20064;&#21040;&#30340;&#22806;&#28304;&#20998;&#24067;&#23558;&#29616;&#26377;&#30340;CBO&#25193;&#23637;&#21040;&#36229;&#20986;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#65288;ANM&#65289;&#30340;&#19968;&#33324;&#22240;&#26524;&#26041;&#26696;&#12290;&#24674;&#22797;&#22806;&#28304;&#21464;&#37327;&#20351;&#25105;&#20204;&#33021;&#22815;&#20026;&#22122;&#22768;&#25110;&#26410;&#35266;&#27979;&#21040;&#30340;&#38544;&#34255;&#21464;&#37327;&#20351;&#29992;&#26356;&#28789;&#27963;&#30340;&#20808;&#39564;&#12290;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;CBO&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Maximizing a target variable as an operational objective in a structured causal model is an important problem. Existing Causal Bayesian Optimization (CBO) methods either rely on hard interventions that alter the causal structure to maximize the reward; or introduce action nodes to endogenous variables so that the data generation mechanisms are adjusted to achieve the objective. In this paper, a novel method is introduced to learn the distribution of exogenous variables, which is typically ignored or marginalized through expectation by existing methods.   Exogenous distribution learning improves the approximation accuracy of structured causal models in a surrogate model that is usually trained with limited observational data. Moreover, the learned exogenous distribution extends existing CBO to general causal schemes beyond Additive Noise Models (ANM). The recovery of exogenous variables allows us to use a more flexible prior for noise or unobserved hidden variables. A new CBO method is 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#20855;&#26377;&#21487;&#23398;&#20064;&#24352;&#37327;&#26680;&#33539;&#25968;&#30340;&#26032;&#22411;&#24352;&#37327;&#24674;&#22797;&#27169;&#22411;&#65292;&#24341;&#20837;&#20132;&#26367;&#36817;&#31471;&#20056;&#23376;&#26041;&#27861;&#65288;APMM&#65289;&#20248;&#21270;&#31639;&#27861;&#65292;&#35299;&#20915;&#22788;&#29702;&#38750;&#20809;&#28369;&#21464;&#21270;&#30340;&#24352;&#37327;&#25968;&#25454;&#25361;&#25112;</title><link>https://arxiv.org/abs/2311.13958</link><description>&lt;p&gt;
&#22788;&#29702;&#24352;&#37327;&#22855;&#24322;&#20540;&#20998;&#35299;&#20013;&#30340;&#38750;&#20809;&#28369;&#25361;&#25112;&#65306;&#22810;&#30446;&#26631;&#24352;&#37327;&#24674;&#22797;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Handling The Non-Smooth Challenge in Tensor SVD: A Multi-Objective Tensor Recovery Framework
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.13958
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#20855;&#26377;&#21487;&#23398;&#20064;&#24352;&#37327;&#26680;&#33539;&#25968;&#30340;&#26032;&#22411;&#24352;&#37327;&#24674;&#22797;&#27169;&#22411;&#65292;&#24341;&#20837;&#20132;&#26367;&#36817;&#31471;&#20056;&#23376;&#26041;&#27861;&#65288;APMM&#65289;&#20248;&#21270;&#31639;&#27861;&#65292;&#35299;&#20915;&#22788;&#29702;&#38750;&#20809;&#28369;&#21464;&#21270;&#30340;&#24352;&#37327;&#25968;&#25454;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#35768;&#22810;&#22522;&#20110;&#24352;&#37327;&#22855;&#24322;&#20540;&#20998;&#35299;&#65288;t-SVD&#65289;&#30340;&#24352;&#37327;&#24674;&#22797;&#26041;&#27861;&#22312;&#22788;&#29702;&#35270;&#35273;&#25968;&#25454;&#65288;&#22914;&#24425;&#33394;&#22270;&#20687;&#21644;&#35270;&#39057;&#65289;&#26041;&#38754;&#34920;&#29616;&#20986;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#24403;&#38754;&#23545;&#26174;&#31034;&#20986;&#38750;&#20809;&#28369;&#21464;&#21270;&#30340;&#24352;&#37327;&#25968;&#25454;&#26102;&#65292;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#20250;&#36973;&#21463;&#20005;&#37325;&#30340;&#24615;&#33021;&#36864;&#21270;&#12290;&#34429;&#28982;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#32463;&#24120;&#35266;&#23519;&#21040;&#36825;&#31181;&#24773;&#20917;&#65292;&#20294;&#20256;&#32479;&#30340;&#22522;&#20110;t-SVD&#30340;&#26041;&#27861;&#21364;&#24573;&#35270;&#20102;&#36825;&#19968;&#28857;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24352;&#37327;&#24674;&#22797;&#27169;&#22411;&#65292;&#20854;&#20013;&#21253;&#25324;&#21487;&#23398;&#20064;&#30340;&#24352;&#37327;&#26680;&#33539;&#25968;&#65292;&#20197;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#21517;&#20026;&#20132;&#26367;&#36817;&#31471;&#20056;&#23376;&#26041;&#27861;&#65288;APMM&#65289;&#30340;&#26032;&#20248;&#21270;&#31639;&#27861;&#65292;&#20197;&#36845;&#20195;&#22320;&#35299;&#20915;&#25552;&#20986;&#30340;&#24352;&#37327;&#34917;&#20840;&#27169;&#22411;&#12290;&#29702;&#35770;&#20998;&#26512;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;APMM&#25910;&#25947;&#21040;&#20248;&#21270;&#38382;&#39064;&#30340;Karush-Kuhn-Tucker&#65288;KKT&#65289;&#28857;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22522;&#20110;APMM&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#30446;&#26631;&#24352;&#37327;&#24674;&#22797;&#26694;&#26550;&#65292;&#20197;&#26377;&#25928;&#25506;&#32034;&#21327;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.13958v2 Announce Type: replace-cross  Abstract: Recently, numerous tensor singular value decomposition (t-SVD)-based tensor recovery methods have shown promise in processing visual data, such as color images and videos. However, these methods often suffer from severe performance degradation when confronted with tensor data exhibiting non-smooth changes. It has been commonly observed in real-world scenarios but ignored by the traditional t-SVD-based methods. In this work, we introduce a novel tensor recovery model with a learnable tensor nuclear norm to address such a challenge. We develop a new optimization algorithm named the Alternating Proximal Multiplier Method (APMM) to iteratively solve the proposed tensor completion model. Theoretical analysis demonstrates the convergence of the proposed APMM to the Karush-Kuhn-Tucker (KKT) point of the optimization problem. In addition, we propose a multi-objective tensor recovery framework based on APMM to efficiently explore the co
&lt;/p&gt;</description></item><item><title>&#40654;&#26364;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#30340;&#26032;&#26041;&#27861;&#21033;&#29992;Fisher&#24230;&#37327;&#25552;&#20379;&#26356;&#20016;&#23500;&#30340;&#36924;&#36817;&#26063;&#65292;&#35299;&#20915;&#20102;&#22312;&#26080;&#38480;&#25968;&#25454;&#26497;&#38480;&#19979;&#20808;&#21069;&#26041;&#27861;&#24230;&#37327;&#36873;&#25321;&#19981;&#24403;&#23548;&#33268;&#36924;&#36817;&#36807;&#20110;&#29421;&#31364;&#21644;&#26377;&#20559;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2311.02766</link><description>&lt;p&gt;
&#20855;&#26377;Fisher&#24230;&#37327;&#30340;&#40654;&#26364;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Riemannian Laplace Approximation with the Fisher Metric
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.02766
&lt;/p&gt;
&lt;p&gt;
&#40654;&#26364;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#30340;&#26032;&#26041;&#27861;&#21033;&#29992;Fisher&#24230;&#37327;&#25552;&#20379;&#26356;&#20016;&#23500;&#30340;&#36924;&#36817;&#26063;&#65292;&#35299;&#20915;&#20102;&#22312;&#26080;&#38480;&#25968;&#25454;&#26497;&#38480;&#19979;&#20808;&#21069;&#26041;&#27861;&#24230;&#37327;&#36873;&#25321;&#19981;&#24403;&#23548;&#33268;&#36924;&#36817;&#36807;&#20110;&#29421;&#31364;&#21644;&#26377;&#20559;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Laplace&#26041;&#27861;&#29992;&#39640;&#26031;&#20998;&#24067;&#22312;&#20854;&#27169;&#24335;&#22788;&#23545;&#30446;&#26631;&#23494;&#24230;&#36827;&#34892;&#36817;&#20284;&#12290;&#22522;&#20110;Bernstein-von Mises&#23450;&#29702;&#65292;&#23427;&#22312;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#26159;&#35745;&#31639;&#25928;&#29575;&#39640;&#19988;&#28176;&#36817;&#20934;&#30830;&#30340;&#65292;&#20294;&#23545;&#20110;&#22797;&#26434;&#30340;&#30446;&#26631;&#21644;&#26377;&#38480;&#25968;&#25454;&#21518;&#39564;&#65292;&#23427;&#24448;&#24448;&#26159;&#19968;&#31181;&#36807;&#20110;&#31895;&#31961;&#30340;&#36817;&#20284;&#12290;&#26368;&#36817;&#23545;Laplace&#36924;&#36817;&#30340;&#19968;&#33324;&#21270;&#26159;&#26681;&#25454;&#36873;&#25321;&#30340;&#40654;&#26364;&#20960;&#20309;&#23545;&#39640;&#26031;&#36817;&#20284;&#36827;&#34892;&#36716;&#25442;&#65292;&#25552;&#20379;&#20102;&#26356;&#20016;&#23500;&#30340;&#36817;&#20284;&#26063;&#65292;&#21516;&#26102;&#20445;&#25345;&#35745;&#31639;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#27491;&#22914;&#26412;&#25991;&#25152;&#31034;&#65292;&#20854;&#24615;&#36136;&#20005;&#37325;&#20381;&#36182;&#20110;&#25152;&#36873;&#25321;&#30340;&#24230;&#37327;&#65292;&#23454;&#38469;&#19978;&#65292;&#22312;&#20808;&#21069;&#30740;&#31350;&#20013;&#37319;&#29992;&#30340;&#24230;&#37327;&#23548;&#33268;&#30340;&#36924;&#36817;&#21363;&#20351;&#22312;&#26080;&#38480;&#25968;&#25454;&#37327;&#30340;&#26497;&#38480;&#19979;&#20063;&#36807;&#20110;&#29421;&#31364;&#19988;&#23384;&#22312;&#20559;&#24046;&#12290;&#25105;&#20204;&#36890;&#36807;&#36827;&#19968;&#27493;&#21457;&#23637;&#36924;&#36817;&#26063;&#65292;&#25512;&#23548;&#20986;&#20004;&#31181;&#22312;&#26080;&#38480;&#25968;&#25454;&#26497;&#38480;&#19979;&#31934;&#30830;&#30340;&#26367;&#20195;&#21464;&#31181;&#65292;&#25193;&#23637;&#20102;&#29702;&#35770;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.02766v3 Announce Type: replace  Abstract: Laplace's method approximates a target density with a Gaussian distribution at its mode. It is computationally efficient and asymptotically exact for Bayesian inference due to the Bernstein-von Mises theorem, but for complex targets and finite-data posteriors it is often too crude an approximation. A recent generalization of the Laplace Approximation transforms the Gaussian approximation according to a chosen Riemannian geometry providing a richer approximation family, while still retaining computational efficiency. However, as shown here, its properties depend heavily on the chosen metric, indeed the metric adopted in previous work results in approximations that are overly narrow as well as being biased even at the limit of infinite data. We correct this shortcoming by developing the approximation family further, deriving two alternative variants that are exact at the limit of infinite data, extending the theoretical analysis of the
&lt;/p&gt;</description></item><item><title>&#30456;&#20284;&#24615;&#12289;&#21387;&#32553;&#21644;&#23616;&#37096;&#26356;&#26032;&#26159;&#26412;&#25991;&#25552;&#20986;&#30340;&#19977;&#22823;&#25216;&#26415;&#65292;&#29992;&#20110;&#20943;&#23569;&#20998;&#24067;&#24335;&#21464;&#20998;&#19981;&#31561;&#24335;&#38382;&#39064;&#20013;&#36890;&#20449;&#36718;&#27425;&#21644;&#25104;&#26412;&#65292;&#23454;&#29616;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#19977;&#37325;&#21327;&#21516;&#20316;&#29992;&#12290;</title><link>https://arxiv.org/abs/2302.07615</link><description>&lt;p&gt;
&#30456;&#20284;&#24615;&#12289;&#21387;&#32553;&#21644;&#23616;&#37096;&#27493;&#39588;&#65306;&#20998;&#24067;&#24335;&#21464;&#20998;&#19981;&#31561;&#24335;&#39640;&#25928;&#36890;&#20449;&#30340;&#19977;&#22823;&#25903;&#26609;
&lt;/p&gt;
&lt;p&gt;
Similarity, Compression and Local Steps: Three Pillars of Efficient Communications for Distributed Variational Inequalities
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2302.07615
&lt;/p&gt;
&lt;p&gt;
&#30456;&#20284;&#24615;&#12289;&#21387;&#32553;&#21644;&#23616;&#37096;&#26356;&#26032;&#26159;&#26412;&#25991;&#25552;&#20986;&#30340;&#19977;&#22823;&#25216;&#26415;&#65292;&#29992;&#20110;&#20943;&#23569;&#20998;&#24067;&#24335;&#21464;&#20998;&#19981;&#31561;&#24335;&#38382;&#39064;&#20013;&#36890;&#20449;&#36718;&#27425;&#21644;&#25104;&#26412;&#65292;&#23454;&#29616;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#19977;&#37325;&#21327;&#21516;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#19981;&#31561;&#24335;&#26159;&#19968;&#20010;&#24191;&#27867;&#32780;&#28789;&#27963;&#30340;&#38382;&#39064;&#31867;&#65292;&#21253;&#25324;&#26368;&#23567;&#21270;&#12289;&#38797;&#28857;&#21644;&#19981;&#21160;&#28857;&#38382;&#39064;&#20316;&#20026;&#29305;&#20363;&#12290;&#22240;&#27492;&#65292;&#21464;&#20998;&#19981;&#31561;&#24335;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#34987;&#20351;&#29992;&#65292;&#20174;&#22343;&#34913;&#25628;&#32034;&#21040;&#23545;&#25239;&#23398;&#20064;&#37117;&#26377;&#28041;&#21450;&#12290;&#38543;&#30528;&#25968;&#25454;&#21644;&#27169;&#22411;&#35268;&#27169;&#30340;&#22686;&#21152;&#65292;&#24403;&#20170;&#30340;&#23454;&#20363;&#38656;&#35201;&#24182;&#34892;&#21644;&#20998;&#24067;&#24335;&#35745;&#31639;&#26469;&#35299;&#20915;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#65292;&#20854;&#20013;&#22823;&#37096;&#20998;&#21487;&#20197;&#34920;&#31034;&#20026;&#21464;&#20998;&#19981;&#31561;&#24335;&#12290;&#21516;&#26102;&#65292;&#22823;&#22810;&#25968;&#20998;&#24067;&#24335;&#26041;&#27861;&#23384;&#22312;&#19968;&#20010;&#37325;&#22823;&#29942;&#39048; - &#36890;&#20449;&#25104;&#26412;&#12290;&#20943;&#23569;&#36890;&#20449;&#36718;&#27425;&#30340;&#24635;&#25968;&#21644;&#27599;&#36718;&#25104;&#26412;&#30340;&#19977;&#31181;&#20027;&#35201;&#25216;&#26415;&#26159;&#26412;&#22320;&#20989;&#25968;&#30340;&#30456;&#20284;&#24615;&#12289;&#20256;&#36755;&#20449;&#24687;&#30340;&#21387;&#32553;&#21644;&#23616;&#37096;&#26356;&#26032;&#12290;&#26412;&#25991;&#32467;&#21512;&#20102;&#25152;&#26377;&#36825;&#20123;&#26041;&#27861;&#12290;&#23545;&#20110;&#21464;&#20998;&#19981;&#31561;&#24335;&#21644;&#38797;&#28857;&#38382;&#39064;&#26469;&#35828;&#65292;&#36825;&#26679;&#30340;&#19977;&#37325;&#21327;&#21516;&#20316;&#29992;&#20197;&#21069;&#24182;&#19981;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2302.07615v2 Announce Type: replace-cross  Abstract: Variational inequalities are a broad and flexible class of problems that includes minimization, saddle point, and fixed point problems as special cases. Therefore, variational inequalities are used in various applications ranging from equilibrium search to adversarial learning. With the increasing size of data and models, today's instances demand parallel and distributed computing for real-world machine learning problems, most of which can be represented as variational inequalities. Meanwhile, most distributed approaches have a significant bottleneck - the cost of communications. The three main techniques to reduce the total number of communication rounds and the cost of one such round are the similarity of local functions, compression of transmitted information, and local updates. In this paper, we combine all these approaches. Such a triple synergy did not exist before for variational inequalities and saddle problems, nor eve
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38544;&#21547;&#21327;&#21464;&#37327;&#36716;&#31227;&#65288;LCS&#65289;&#33539;&#24335;&#65292;&#22686;&#21152;&#20102;&#39046;&#22495;&#38388;&#30340;&#21487;&#21464;&#24615;&#21644;&#36866;&#24212;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#24674;&#22797;&#26631;&#31614;&#21464;&#37327;&#28508;&#22312;&#21407;&#22240;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2208.14161</link><description>&lt;p&gt;
&#21487;&#35782;&#21035;&#30340;&#28508;&#22312;&#22240;&#26524;&#20869;&#23481;&#29992;&#20110;&#38544;&#21547;&#21327;&#21464;&#37327;&#36716;&#31227;&#19979;&#30340;&#39046;&#22495;&#33258;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
Identifiable Latent Causal Content for Domain Adaptation under Latent Covariate Shift
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2208.14161
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38544;&#21547;&#21327;&#21464;&#37327;&#36716;&#31227;&#65288;LCS&#65289;&#33539;&#24335;&#65292;&#22686;&#21152;&#20102;&#39046;&#22495;&#38388;&#30340;&#21487;&#21464;&#24615;&#21644;&#36866;&#24212;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#24674;&#22797;&#26631;&#31614;&#21464;&#37327;&#28508;&#22312;&#21407;&#22240;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#28304;&#39046;&#22495;&#33258;&#36866;&#24212;&#65288;MSDA&#65289;&#35299;&#20915;&#20102;&#21033;&#29992;&#26469;&#33258;&#22810;&#20010;&#28304;&#22495;&#30340;&#26631;&#35760;&#25968;&#25454;&#21644;&#26469;&#33258;&#30446;&#26631;&#22495;&#30340;&#26410;&#26631;&#35760;&#25968;&#25454;&#26469;&#23398;&#20064;&#38024;&#23545;&#26410;&#26631;&#35760;&#30446;&#26631;&#39046;&#22495;&#30340;&#26631;&#31614;&#39044;&#27979;&#20989;&#25968;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#28508;&#22312;&#21327;&#21464;&#37327;&#36716;&#31227;&#65288;LCS&#65289;&#30340;&#26032;&#33539;&#24335;&#65292;&#23427;&#24341;&#20837;&#20102;&#26356;&#22823;&#30340;&#39046;&#22495;&#38388;&#21487;&#21464;&#24615;&#21644;&#36866;&#24212;&#24615;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#23427;&#20026;&#24674;&#22797;&#26631;&#31614;&#21464;&#37327;&#30340;&#28508;&#22312;&#21407;&#22240;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2208.14161v3 Announce Type: replace  Abstract: Multi-source domain adaptation (MSDA) addresses the challenge of learning a label prediction function for an unlabeled target domain by leveraging both the labeled data from multiple source domains and the unlabeled data from the target domain. Conventional MSDA approaches often rely on covariate shift or conditional shift paradigms, which assume a consistent label distribution across domains. However, this assumption proves limiting in practical scenarios where label distributions do vary across domains, diminishing its applicability in real-world settings. For example, animals from different regions exhibit diverse characteristics due to varying diets and genetics.   Motivated by this, we propose a novel paradigm called latent covariate shift (LCS), which introduces significantly greater variability and adaptability across domains. Notably, it provides a theoretical assurance for recovering the latent cause of the label variable, w
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Embed to Control&#65288;ETC&#65289;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#20004;&#20010;&#32423;&#21035;&#23398;&#20064;&#34920;&#31034;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#37096;&#20998;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#38382;&#39064;&#65292;&#20197;&#23454;&#29616;&#26679;&#26412;&#39640;&#25928;&#21033;&#29992;&#12290;</title><link>https://arxiv.org/abs/2205.13476</link><description>&lt;p&gt;
&#23884;&#20837;&#25511;&#21046;&#37096;&#20998;&#35266;&#23519;&#31995;&#32479;&#65306;&#20855;&#26377;&#21487;&#35777;&#26126;&#26679;&#26412;&#25928;&#29575;&#30340;&#34920;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Embed to Control Partially Observed Systems: Representation Learning with Provable Sample Efficiency
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2205.13476
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Embed to Control&#65288;ETC&#65289;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#20004;&#20010;&#32423;&#21035;&#23398;&#20064;&#34920;&#31034;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#37096;&#20998;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#38382;&#39064;&#65292;&#20197;&#23454;&#29616;&#26679;&#26412;&#39640;&#25928;&#21033;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#22312;&#37096;&#20998;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;POMDPs&#65289;&#20013;&#38754;&#20020;&#20004;&#20010;&#25361;&#25112;&#12290;&#19968;&#26159;&#36890;&#24120;&#38656;&#35201;&#20840;&#37096;&#21382;&#21490;&#35760;&#24405;&#26469;&#39044;&#27979;&#26410;&#26469;&#65292;&#36825;&#23548;&#33268;&#26679;&#26412;&#22797;&#26434;&#24230;&#38543;&#30528;&#26102;&#38388;&#36328;&#24230;&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#12290;&#20108;&#26159;&#35266;&#27979;&#21644;&#29366;&#24577;&#31354;&#38388;&#36890;&#24120;&#26159;&#36830;&#32493;&#30340;&#65292;&#36825;&#23548;&#33268;&#26679;&#26412;&#22797;&#26434;&#24230;&#38543;&#22806;&#22312;&#32500;&#25968;&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#38656;&#35201;&#36890;&#36807;&#21033;&#29992;POMDP&#30340;&#32467;&#26500;&#23398;&#20064;&#35266;&#27979;&#21644;&#29366;&#24577;&#21382;&#21490;&#30340;&#26368;&#23567;&#20294;&#36275;&#22815;&#30340;&#34920;&#31034;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Embed to Control (ETC)&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#20248;&#21270;&#31574;&#30053;&#30340;&#21516;&#26102;&#23398;&#20064;&#20004;&#20010;&#32423;&#21035;&#30340;&#34920;&#31034;&#12290;(i)&#22312;&#27599;&#19968;&#27493;&#65292;ETC&#23398;&#20064;&#29992;&#20302;&#32500;&#29305;&#24449;&#34920;&#31034;&#29366;&#24577;&#65292;&#36825;&#23545;&#36716;&#31227;&#26680;&#36827;&#34892;&#22240;&#23376;&#20998;&#35299;&#12290;(ii)&#22312;&#22810;&#20010;&#27493;&#39588;&#20013;&#65292;ETC&#23398;&#20064;&#29992;&#20302;&#32500;&#34920;&#31034;&#23436;&#25972;&#21382;&#21490;&#35760;&#24405;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2205.13476v2 Announce Type: replace-cross  Abstract: Reinforcement learning in partially observed Markov decision processes (POMDPs) faces two challenges. (i) It often takes the full history to predict the future, which induces a sample complexity that scales exponentially with the horizon. (ii) The observation and state spaces are often continuous, which induces a sample complexity that scales exponentially with the extrinsic dimension. Addressing such challenges requires learning a minimal but sufficient representation of the observation and state histories by exploiting the structure of the POMDP.   To this end, we propose a reinforcement learning algorithm named Embed to Control (ETC), which learns the representation at two levels while optimizing the policy.~(i) For each step, ETC learns to represent the state with a low-dimensional feature, which factorizes the transition kernel. (ii) Across multiple steps, ETC learns to represent the full history with a low-dimensional emb
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#40657;&#30418;&#30693;&#35782;&#33976;&#39311;&#26041;&#27861;MEKD&#65292;&#36890;&#36807;&#23558;&#25945;&#24072;&#21644;&#23398;&#29983;&#27169;&#22411;&#30340;&#20302;&#32500;&#24230;&#23545;&#25968;&#23545;&#40784;&#65292;&#23454;&#29616;&#23558;&#19968;&#20010;&#32321;&#29712;&#27169;&#22411;&#21387;&#32553;&#25104;&#36731;&#37327;&#32423;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2205.10490</link><description>&lt;p&gt;
&#23558;&#29983;&#25104;&#30340;&#23545;&#25968;&#36827;&#34892;&#20934;&#21017;&#23545;&#40784;&#30340;&#40657;&#30418;&#30693;&#35782;&#33976;&#39311;
&lt;/p&gt;
&lt;p&gt;
Aligning Logits Generatively for Principled Black-Box Knowledge Distillation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2205.10490
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#40657;&#30418;&#30693;&#35782;&#33976;&#39311;&#26041;&#27861;MEKD&#65292;&#36890;&#36807;&#23558;&#25945;&#24072;&#21644;&#23398;&#29983;&#27169;&#22411;&#30340;&#20302;&#32500;&#24230;&#23545;&#25968;&#23545;&#40784;&#65292;&#23454;&#29616;&#23558;&#19968;&#20010;&#32321;&#29712;&#27169;&#22411;&#21387;&#32553;&#25104;&#36731;&#37327;&#32423;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#40657;&#30418;&#30693;&#35782;&#33976;&#39311;&#65288;B2KD&#65289;&#26159;&#19968;&#20010;&#22788;&#29702;&#20113;&#31471;&#21040;&#36793;&#32536;&#27169;&#22411;&#21387;&#32553;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#25968;&#25454;&#21644;&#27169;&#22411;&#25176;&#31649;&#22312;&#26381;&#21153;&#22120;&#19978;&#19988;&#26080;&#27861;&#30475;&#35265;&#12290;B2KD&#38754;&#20020;&#30340;&#25361;&#25112;&#21253;&#25324;&#20114;&#32852;&#32593;&#20132;&#25442;&#21463;&#38480;&#21644;&#25968;&#25454;&#20998;&#24067;&#22312;&#36793;&#32536;&#21644;&#20113;&#31471;&#20043;&#38388;&#30340;&#19981;&#19968;&#33268;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21253;&#25324;&#21435;&#38544;&#21435;&#21644;&#33976;&#39311;&#20004;&#27493;&#24037;&#20316;&#27969;&#31243;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#25552;&#20379;&#20102;&#19968;&#20010;&#20174;&#23545;&#25968;&#21040;&#21333;&#20803;&#36793;&#30028;&#30340;&#26032;&#20248;&#21270;&#26041;&#21521;&#65292;&#19981;&#21516;&#20110;&#30452;&#25509;&#23545;&#25968;&#23545;&#40784;&#12290;&#22312;&#20854;&#25351;&#23548;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;Mapping-Emulation KD&#65288;MEKD&#65289;&#65292;&#23558;&#19968;&#20010;&#40657;&#30418;&#32321;&#29712;&#27169;&#22411;&#33976;&#39311;&#25104;&#19968;&#20010;&#36731;&#37327;&#32423;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#21306;&#20998;&#36719;&#25110;&#30828;&#21709;&#24212;&#22788;&#29702;&#65292;&#24182;&#21253;&#25324;&#65306;1&#65289;&#21435;&#38544;&#21435;&#65306;&#36890;&#36807;&#29983;&#25104;&#22120;&#27169;&#25311;&#25945;&#24072;&#20989;&#25968;&#30340;&#36870;&#26144;&#23556;&#65292;&#21644;2&#65289;&#33976;&#39311;&#65306;&#36890;&#36807;&#20943;&#23567;&#39640;&#32500;&#22270;&#20687;&#28857;&#20043;&#38388;&#30340;&#36317;&#31163;&#26469;&#23545;&#40784;&#25945;&#24072;&#27169;&#22411;&#21644;&#23398;&#29983;&#27169;&#22411;&#30340;&#20302;&#32500;&#24230;&#23545;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2205.10490v2 Announce Type: replace-cross  Abstract: Black-Box Knowledge Distillation (B2KD) is a formulated problem for cloud-to-edge model compression with invisible data and models hosted on the server. B2KD faces challenges such as limited Internet exchange and edge-cloud disparity of data distributions. In this paper, we formalize a two-step workflow consisting of deprivatization and distillation, and theoretically provide a new optimization direction from logits to cell boundary different from direct logits alignment. With its guidance, we propose a new method Mapping-Emulation KD (MEKD) that distills a black-box cumbersome model into a lightweight one. Our method does not differentiate between treating soft or hard responses, and consists of: 1) deprivatization: emulating the inverse mapping of the teacher function with a generator, and 2) distillation: aligning low-dimensional logits of the teacher and student models by reducing the distance of high-dimensional image poin
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;&#37096;&#20998;&#35266;&#27979;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65288;OP-TENET&#65289;&#65292;&#22312;&#26377;&#38480;&#30340;&#24773;&#33410;&#25968;&#20869;&#23454;&#29616;&#20102;$\epsilon$-&#26368;&#20248;&#31574;&#30053;&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#19982;&#32447;&#24615;&#32467;&#26500;&#30340;&#26412;&#24449;&#32500;&#24230;&#22810;&#39033;&#24335;&#32553;&#25918;&#65292;&#19982;&#35266;&#27979;&#21644;&#29366;&#24577;&#31354;&#38388;&#30340;&#22823;&#23567;&#26080;&#20851;&#12290;</title><link>https://arxiv.org/abs/2204.09787</link><description>&lt;p&gt;
&#22522;&#20110;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;&#37096;&#20998;&#35266;&#27979;&#24378;&#21270;&#23398;&#20064;&#21450;&#20854;&#21487;&#35777;&#26126;&#30340;&#26679;&#26412;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning from Partial Observation: Linear Function Approximation with Provable Sample Efficiency
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2204.09787
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;&#37096;&#20998;&#35266;&#27979;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65288;OP-TENET&#65289;&#65292;&#22312;&#26377;&#38480;&#30340;&#24773;&#33410;&#25968;&#20869;&#23454;&#29616;&#20102;$\epsilon$-&#26368;&#20248;&#31574;&#30053;&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#19982;&#32447;&#24615;&#32467;&#26500;&#30340;&#26412;&#24449;&#32500;&#24230;&#22810;&#39033;&#24335;&#32553;&#25918;&#65292;&#19982;&#35266;&#27979;&#21644;&#29366;&#24577;&#31354;&#38388;&#30340;&#22823;&#23567;&#26080;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20855;&#26377;&#26080;&#38480;&#35266;&#27979;&#21644;&#29366;&#24577;&#31354;&#38388;&#30340;&#37096;&#20998;&#35266;&#27979;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;POMDP&#65289;&#30340;&#24378;&#21270;&#23398;&#20064;&#65292;&#22312;&#29702;&#35770;&#19978;&#20173;&#28982;&#21463;&#21040;&#36739;&#23569;&#30340;&#30740;&#31350;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#39318;&#27425;&#23581;&#35797;&#23558;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#19982;&#20855;&#26377;&#32447;&#24615;&#32467;&#26500;&#30340;&#19968;&#31867;POMDP&#30340;&#20989;&#25968;&#36924;&#36817;&#32852;&#31995;&#36215;&#26469;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65288;&#20048;&#35266;&#25506;&#32034;&#36890;&#36807;&#23545;&#25239;&#31215;&#20998;&#26041;&#31243;&#25110;OP-TENET&#65289;&#65292;&#22312;$ O&#65288;1 / \ epsilon ^ 2&#65289;$&#20010;&#24773;&#33410;&#20869;&#23454;&#29616;&#20102;$\ epsilon $-&#26368;&#20248;&#31574;&#30053;&#12290;&#29305;&#21035;&#22320;&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#22312;&#32447;&#24615;&#32467;&#26500;&#30340;&#26412;&#24449;&#32500;&#24230;&#22810;&#39033;&#24335;&#22320;&#32553;&#25918;&#65292;&#24182;&#19988;&#19982;&#35266;&#27979;&#21644;&#29366;&#24577;&#31354;&#38388;&#30340;&#22823;&#23567;&#26080;&#20851;&#12290;OP-TENET&#30340;&#26679;&#26412;&#25928;&#29575;&#30001;&#19968;&#31995;&#21015;&#22240;&#32032;&#23454;&#29616;&#65306;&#65288;i&#65289;&#20855;&#26377;&#26377;&#38480;&#35760;&#24518;&#30340;Bellman&#31639;&#23376;&#65292;&#20197;&#36882;&#24402;&#26041;&#24335;&#34920;&#31034;&#20540;&#20989;&#25968;&#65292;&#65288;ii&#65289;&#35782;&#21035;&#21644;&#20272;&#35745;&#36825;&#26679;&#19968;&#20010;&#31639;&#23376;
&lt;/p&gt;
&lt;p&gt;
arXiv:2204.09787v3 Announce Type: replace  Abstract: We study reinforcement learning for partially observed Markov decision processes (POMDPs) with infinite observation and state spaces, which remains less investigated theoretically. To this end, we make the first attempt at bridging partial observability and function approximation for a class of POMDPs with a linear structure. In detail, we propose a reinforcement learning algorithm (Optimistic Exploration via Adversarial Integral Equation or OP-TENET) that attains an $\epsilon$-optimal policy within $O(1/\epsilon^2)$ episodes. In particular, the sample complexity scales polynomially in the intrinsic dimension of the linear structure and is independent of the size of the observation and state spaces.   The sample efficiency of OP-TENET is enabled by a sequence of ingredients: (i) a Bellman operator with finite memory, which represents the value function in a recursive manner, (ii) the identification and estimation of such an operator 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#40065;&#26834;&#23494;&#24230;&#24863;&#30693;&#36317;&#31163;&#65288;RDAD&#65289;&#36807;&#28388;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#22312;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#20013;&#20934;&#30830;&#21306;&#20998;&#34987;&#39640;&#23494;&#24230;&#21306;&#22495;&#21253;&#22260;&#30340;&#23567;&#23380;&#65292;&#23545;&#22122;&#22768;&#21644;&#24322;&#24120;&#20540;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;</title><link>https://arxiv.org/abs/2204.07821</link><description>&lt;p&gt;
&#36890;&#36807;&#26631;&#24230;&#19981;&#21464;&#30340;&#40065;&#26834;&#23494;&#24230;&#24863;&#30693;&#36317;&#31163;&#65288;RDAD&#65289;&#36807;&#28388;&#26816;&#27979;&#23567;&#23380;
&lt;/p&gt;
&lt;p&gt;
Detection of Small Holes by the Scale-Invariant Robust Density-Aware Distance (RDAD) Filtration
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2204.07821
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#40065;&#26834;&#23494;&#24230;&#24863;&#30693;&#36317;&#31163;&#65288;RDAD&#65289;&#36807;&#28388;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#22312;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#20013;&#20934;&#30830;&#21306;&#20998;&#34987;&#39640;&#23494;&#24230;&#21306;&#22495;&#21253;&#22260;&#30340;&#23567;&#23380;&#65292;&#23545;&#22122;&#22768;&#21644;&#24322;&#24120;&#20540;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#65288;TDA&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#21306;&#20998;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#20013;&#34987;&#39640;&#23494;&#24230;&#21306;&#22495;&#21253;&#22260;&#30340;&#23567;&#23380;&#19982;&#22122;&#22768;&#12290;&#35813;&#26041;&#27861;&#23545;&#38468;&#21152;&#22122;&#22768;&#21644;&#24322;&#24120;&#20540;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#20256;&#32479;&#30340;TDA&#24037;&#20855;&#65292;&#22914;&#22522;&#20110;&#36317;&#31163;&#36807;&#28388;&#30340;&#24037;&#20855;&#65292;&#36890;&#24120;&#38590;&#20197;&#21306;&#20998;&#23567;&#29305;&#24449;&#21644;&#22122;&#22768;&#65292;&#22240;&#20026;&#20004;&#32773;&#30340;&#25345;&#32493;&#26102;&#38388;&#36739;&#30701;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#40065;&#26834;&#23494;&#24230;&#24863;&#30693;&#36317;&#31163;&#65288;RDAD&#65289;&#36807;&#28388;&#30340;&#22791;&#29992;&#36807;&#28388;&#65292;&#29992;&#20110;&#24310;&#38271;&#39640;&#23494;&#24230;&#21306;&#22495;&#30340;&#23567;&#23380;&#30340;&#25345;&#32493;&#26102;&#38388;&#12290;&#36825;&#26159;&#36890;&#36807;&#26681;&#25454;Bell&#31561;&#20154;&#30340;&#35266;&#28857;&#23558;&#36317;&#31163;&#20989;&#25968;&#21152;&#26435;&#23494;&#24230;&#23454;&#29616;&#30340;&#12290;&#24341;&#20837;&#20102;&#36317;&#31163;-&#27979;&#24230;&#30340;&#27010;&#24565;&#20197;&#22686;&#24378;&#31283;&#23450;&#24615;&#21644;&#20943;&#23569;&#22122;&#22768;&#12290;&#25552;&#20986;&#36807;&#28388;&#30340;&#25345;&#32493;&#26102;&#38388;&#24310;&#38271;&#24615;&#21644;&#40065;&#26834;&#24615;&#24471;&#21040;&#20102;&#20005;&#26684;&#35770;&#35777;&#65292;&#24182;&#25552;&#20379;&#20102;&#25968;&#20540;&#23454;&#39564;&#20197;&#35777;&#26126;&#25152;&#25552;&#36807;&#28388;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2204.07821v3 Announce Type: replace-cross  Abstract: A novel topological-data-analytical (TDA) method is proposed to distinguish, from noise, small holes surrounded by high-density regions of a probability density function. The proposed method is robust against additive noise and outliers. Traditional TDA tools, like those based on the distance filtration, often struggle to distinguish small features from noise, because both have short persistences. An alternative filtration, called the Robust Density-Aware Distance (RDAD) filtration, is proposed to prolong the persistences of small holes of high-density regions. This is achieved by weighting the distance function by the density in the sense of Bell et al. The concept of distance-to-measure is incorporated to enhance stability and mitigate noise. The persistence-prolonging property and robustness of the proposed filtration are rigorously established, and numerical experiments are presented to demonstrate the proposed filtration's
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#22343;&#22330;&#20998;&#26512;&#30740;&#31350;&#20102;&#22522;&#20110;&#29305;&#24449;&#30340;&#31070;&#32463;AC&#30340;&#28436;&#21270;&#21644;&#25910;&#25947;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#20351;&#29992;&#20004;&#20010;&#23398;&#20064;&#29575;&#26356;&#26032;&#30340;AC&#29256;&#26412;&#65292;&#20854;&#20013;&#35780;&#35770;&#23478;&#36890;&#36807;&#22823;&#27493;&#38271;&#36827;&#34892;TD&#23398;&#20064;&#26356;&#26032;&#65292;&#28436;&#21592;&#36890;&#36807;&#23567;&#27493;&#38271;&#36827;&#34892;PPO&#26356;&#26032;&#12290;</title><link>https://arxiv.org/abs/2112.13530</link><description>&lt;p&gt;
Wasserstein Flow&#36935;&#35265;&#22797;&#21046;&#21160;&#21147;&#23398;&#65306;Actor-Critic&#20013;&#20195;&#34920;&#23398;&#20064;&#30340;&#22343;&#22330;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Wasserstein Flow Meets Replicator Dynamics: A Mean-Field Analysis of Representation Learning in Actor-Critic
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2112.13530
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#22343;&#22330;&#20998;&#26512;&#30740;&#31350;&#20102;&#22522;&#20110;&#29305;&#24449;&#30340;&#31070;&#32463;AC&#30340;&#28436;&#21270;&#21644;&#25910;&#25947;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#20351;&#29992;&#20004;&#20010;&#23398;&#20064;&#29575;&#26356;&#26032;&#30340;AC&#29256;&#26412;&#65292;&#20854;&#20013;&#35780;&#35770;&#23478;&#36890;&#36807;&#22823;&#27493;&#38271;&#36827;&#34892;TD&#23398;&#20064;&#26356;&#26032;&#65292;&#28436;&#21592;&#36890;&#36807;&#23567;&#27493;&#38271;&#36827;&#34892;PPO&#26356;&#26032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Actor-critic (AC)&#31639;&#27861;&#20511;&#21161;&#31070;&#32463;&#32593;&#32476;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#32463;&#39564;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#22823;&#37096;&#20998;&#20851;&#20110;AC&#31639;&#27861;&#30340;&#29702;&#35770;&#25903;&#25345;&#38598;&#20013;&#22312;&#20855;&#26377;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#25110;&#32447;&#24615;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#24773;&#20917;&#19979;&#65292;&#20854;&#20013;&#29305;&#24449;&#34920;&#31034;&#22312;&#25972;&#20010;&#35757;&#32451;&#36807;&#31243;&#20013;&#20445;&#25345;&#19981;&#21464;&#12290;&#36825;&#31181;&#38480;&#21046;&#26410;&#33021;&#25429;&#25417;&#31070;&#32463;AC&#20013;&#20195;&#34920;&#23398;&#20064;&#30340;&#20851;&#38190;&#26041;&#38754;&#65292;&#22312;&#23454;&#38469;&#38382;&#39064;&#20013;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#20174;&#22343;&#22330;&#30340;&#35282;&#24230;&#23545;&#22522;&#20110;&#29305;&#24449;&#30340;&#31070;&#32463;AC&#30340;&#28436;&#21270;&#21644;&#25910;&#25947;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;AC&#30340;&#29256;&#26412;&#65292;&#20854;&#20013;&#28436;&#21592;&#21644;&#35780;&#35770;&#23478;&#30001;&#36229;&#21442;&#25968;&#21270;&#30340;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#34920;&#31034;&#65292;&#24182;&#20351;&#29992;&#20004;&#20010;&#26102;&#38388;&#23610;&#24230;&#30340;&#23398;&#20064;&#29575;&#36827;&#34892;&#26356;&#26032;&#12290;&#35780;&#35770;&#23478;&#36890;&#36807;&#36739;&#22823;&#30340;&#27493;&#38271;&#36827;&#34892;&#26102;&#24046;&#65288;TD&#65289;&#23398;&#20064;&#26356;&#26032;&#65292;&#32780;&#28436;&#21592;&#36890;&#36807;&#36739;&#23567;&#27493;&#38271;&#36827;&#34892;&#37051;&#22495;&#31574;&#30053;&#20248;&#21270;&#65288;PPO&#65289;&#26356;&#26032;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2112.13530v2 Announce Type: replace  Abstract: Actor-critic (AC) algorithms, empowered by neural networks, have had significant empirical success in recent years. However, most of the existing theoretical support for AC algorithms focuses on the case of linear function approximations, or linearized neural networks, where the feature representation is fixed throughout training. Such a limitation fails to capture the key aspect of representation learning in neural AC, which is pivotal in practical problems. In this work, we take a mean-field perspective on the evolution and convergence of feature-based neural AC. Specifically, we consider a version of AC where the actor and critic are represented by overparameterized two-layer neural networks and are updated with two-timescale learning rates. The critic is updated by temporal-difference (TD) learning with a larger stepsize while the actor is updated via proximal policy optimization (PPO) with a smaller stepsize. In the continuous-t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22238;&#39038;&#20102;&#22238;&#24402;&#38382;&#39064;&#20013;&#22235;&#31867;&#39044;&#27979;&#21306;&#38388;&#20272;&#35745;&#26041;&#27861;&#65292;&#24182;&#25351;&#20986;&#20102;&#19968;&#20123;&#26041;&#27861;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#24615;&#33021;&#27874;&#21160;&#22823;&#30340;&#21407;&#22240;&#12290;</title><link>https://arxiv.org/abs/2107.00363</link><description>&lt;p&gt;
&#22238;&#24402;&#38382;&#39064;&#30340;&#26377;&#25928;&#39044;&#27979;&#21306;&#38388;
&lt;/p&gt;
&lt;p&gt;
Valid prediction intervals for regression problems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2107.00363
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22238;&#39038;&#20102;&#22238;&#24402;&#38382;&#39064;&#20013;&#22235;&#31867;&#39044;&#27979;&#21306;&#38388;&#20272;&#35745;&#26041;&#27861;&#65292;&#24182;&#25351;&#20986;&#20102;&#19968;&#20123;&#26041;&#27861;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#24615;&#33021;&#27874;&#21160;&#22823;&#30340;&#21407;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#20960;&#21313;&#24180;&#20013;&#65292;&#38024;&#23545;&#22238;&#24402;&#35774;&#32622;&#25552;&#20986;&#20102;&#21508;&#31181;&#26041;&#27861;&#26469;&#20272;&#35745;&#39044;&#27979;&#21306;&#38388;&#65292;&#21253;&#25324;&#36125;&#21494;&#26031;&#26041;&#27861;&#12289;&#38598;&#25104;&#26041;&#27861;&#12289;&#30452;&#25509;&#21306;&#38388;&#20272;&#35745;&#26041;&#27861;&#21644;&#31526;&#21512;&#39044;&#27979;&#26041;&#27861;&#12290;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#26159;&#36825;&#20123;&#26041;&#27861;&#30340;&#26657;&#20934;&#65306;&#29983;&#25104;&#30340;&#39044;&#27979;&#21306;&#38388;&#24212;&#35813;&#20855;&#26377;&#39044;&#23450;&#20041;&#30340;&#35206;&#30422;&#27700;&#24179;&#65292;&#32780;&#19981;&#24212;&#35813;&#36807;&#20110;&#20445;&#23432;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20174;&#27010;&#24565;&#21644;&#23454;&#39564;&#35282;&#24230;&#22238;&#39038;&#20102;&#19978;&#36848;&#22235;&#31867;&#26041;&#27861;&#12290;&#26469;&#33258;&#21508;&#20010;&#39046;&#22495;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#30340;&#32467;&#26524;&#31361;&#26174;&#20986;&#22312;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;&#24615;&#33021;&#26377;&#24456;&#22823;&#27874;&#21160;&#12290;&#36825;&#20123;&#35266;&#23519;&#32467;&#26524;&#21487;&#24402;&#22240;&#20110;&#26576;&#20123;&#31867;&#26041;&#27861;&#22266;&#26377;&#20551;&#35774;&#30340;&#36829;&#32972;&#12290;&#25105;&#20204;&#38416;&#36848;&#20102;&#22914;&#20309;&#23558;&#31526;&#21512;&#39044;&#27979;&#29992;&#20316;&#27809;&#26377;&#26657;&#20934;&#27493;&#39588;&#20250;&#20135;&#29983;&#24046;&#32467;&#26524;&#30340;&#26041;&#27861;&#30340;&#36890;&#29992;&#26657;&#20934;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2107.00363v4 Announce Type: replace-cross  Abstract: Over the last few decades, various methods have been proposed for estimating prediction intervals in regression settings, including Bayesian methods, ensemble methods, direct interval estimation methods and conformal prediction methods. An important issue is the calibration of these methods: the generated prediction intervals should have a predefined coverage level, without being overly conservative. In this work, we review the above four classes of methods from a conceptual and experimental point of view. Results on benchmark data sets from various domains highlight large fluctuations in performance from one data set to another. These observations can be attributed to the violation of certain assumptions that are inherent to some classes of methods. We illustrate how conformal prediction can be used as a general calibration procedure for methods that deliver poor results without a calibration step.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#31890;&#23376;&#30340;&#31639;&#27861;&#65292;&#21517;&#20026;&#21464;&#20998;&#20256;&#36755;&#65292;&#36890;&#36807;&#36845;&#20195;&#22320;&#25512;&#21160;&#19968;&#32452;&#31890;&#23376;&#65292;&#22312;&#27010;&#29575;&#20998;&#24067;&#27969;&#24418;&#19978;&#36817;&#20284;&#25191;&#34892;&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#19979;&#38477;&#12290;</title><link>https://arxiv.org/abs/2012.11554</link><description>&lt;p&gt;
&#21464;&#20998;&#20256;&#36755;&#65306;&#19968;&#31181;&#29992;&#20110;&#20998;&#24067;&#20248;&#21270;&#30340;&#25910;&#25947;&#31890;&#23376;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Variational Transport: A Convergent Particle-BasedAlgorithm for Distributional Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2012.11554
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#31890;&#23376;&#30340;&#31639;&#27861;&#65292;&#21517;&#20026;&#21464;&#20998;&#20256;&#36755;&#65292;&#36890;&#36807;&#36845;&#20195;&#22320;&#25512;&#21160;&#19968;&#32452;&#31890;&#23376;&#65292;&#22312;&#27010;&#29575;&#20998;&#24067;&#27969;&#24418;&#19978;&#36817;&#20284;&#25191;&#34892;&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#19979;&#38477;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#26368;&#23567;&#21270;&#19968;&#20010;&#22312;&#27010;&#29575;&#20998;&#24067;&#26063;&#19978;&#23450;&#20041;&#30340;&#20989;&#25968;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#20551;&#23450;&#30446;&#26631;&#20989;&#25968;&#20855;&#26377;&#21464;&#20998;&#24418;&#24335;&#12290;&#36825;&#31181;&#20998;&#24067;&#20248;&#21270;&#38382;&#39064;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#23398;&#20013;&#24191;&#27867;&#23384;&#22312;&#65292;&#33945;&#29305;&#21345;&#27931;&#25277;&#26679;&#12289;&#21464;&#20998;&#25512;&#26029;&#12289;&#31574;&#30053;&#20248;&#21270;&#21644;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#26159;&#20854;&#20013;&#30340;&#20363;&#23376;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#31890;&#23376;&#30340;&#31639;&#27861;&#65292;&#21517;&#20026;&#21464;&#20998;&#20256;&#36755;&#65292;&#36890;&#36807;&#36845;&#20195;&#22320;&#25512;&#21160;&#19968;&#32452;&#31890;&#23376;&#65292;&#22312;&#27010;&#29575;&#20998;&#24067;&#27969;&#24418;&#19978;&#36817;&#20284;&#25191;&#34892;&#27779;&#29791;&#26031;&#22374;&#26799;&#24230;&#19979;&#38477;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35777;&#26126;&#27839;&#30528;&#20989;&#25968;&#26799;&#24230;&#30340;&#27979;&#22320;&#32447;&#26041;&#21521;&#31227;&#21160;&#65292;&#19982;&#23545;&#27010;&#29575;&#20998;&#24067;&#26045;&#21152;&#19968;&#20010;&#25512;&#21069;&#26144;&#23556;&#31561;&#20215;&#20110;&#36890;&#36807;&#25512;&#21160;&#19968;&#32452;&#31890;&#23376;&#26469;&#20934;&#30830;&#36817;&#20284;&#23454;&#26045;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2012.11554v2 Announce Type: replace  Abstract: We consider the optimization problem of minimizing a functional defined over a family of probability distributions, where the objective functional is assumed to possess a variational form. Such a distributional optimization problem arises widely in machine learning and statistics, with Monte-Carlo sampling, variational inference, policy optimization, and generative adversarial network as examples. For this problem, we propose a novel particle-based algorithm, dubbed as variational transport, which approximately performs Wasserstein gradient descent over the manifold of probability distributions via iteratively pushing a set of particles. Specifically, we prove that moving along the geodesic in the direction of functional gradient with respect to the second-order Wasserstein distance is equivalent to applying a pushforward mapping to a probability distribution, which can be approximated accurately by pushing a set of particles. Specif
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25506;&#35752;&#31163;&#25955;&#26102;&#38388;&#24046;&#20998;&#23398;&#20064;&#21644;Q&#23398;&#20064;&#22312;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#29305;&#24449;&#34920;&#31034;&#28436;&#21464;&#65292;&#35777;&#26126;&#21033;&#29992;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#36825;&#31181;&#28436;&#21464;&#65292;&#24182;&#20851;&#27880;&#29305;&#24449;&#34920;&#31034;&#23545;&#20110;&#31639;&#27861;&#25910;&#25947;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>https://arxiv.org/abs/2006.04761</link><description>&lt;p&gt;
&#31163;&#25955;&#26102;&#38388;&#24046;&#20998;&#21644;Q&#23398;&#20064;&#33021;&#23398;&#24471;&#29305;&#24449;&#34920;&#31034;&#21527;&#65311;&#19968;&#31181;&#24179;&#22343;&#22330;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Can Temporal-Difference and Q-Learning Learn Representation? A Mean-Field Theory
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2006.04761
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25506;&#35752;&#31163;&#25955;&#26102;&#38388;&#24046;&#20998;&#23398;&#20064;&#21644;Q&#23398;&#20064;&#22312;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#29305;&#24449;&#34920;&#31034;&#28436;&#21464;&#65292;&#35777;&#26126;&#21033;&#29992;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#36825;&#31181;&#28436;&#21464;&#65292;&#24182;&#20851;&#27880;&#29305;&#24449;&#34920;&#31034;&#23545;&#20110;&#31639;&#27861;&#25910;&#25947;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#25955;&#26102;&#38388;&#24046;&#20998;&#21644;Q&#23398;&#20064;&#22312;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#21457;&#25381;&#20851;&#38190;&#20316;&#29992;&#65292;&#23427;&#20204;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#31561;&#34920;&#36798;&#21147;&#38750;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#22120;&#12290;&#23427;&#20204;&#30340;&#23454;&#35777;&#25104;&#21151;&#30340;&#26680;&#24515;&#26159;&#23398;&#24471;&#30340;&#29305;&#24449;&#34920;&#31034;&#65292;&#23558;&#20016;&#23500;&#30340;&#35266;&#27979;&#65292;&#22914;&#22270;&#20687;&#21644;&#25991;&#26412;&#65292;&#23884;&#20837;&#21040;&#32534;&#30721;&#35821;&#20041;&#32467;&#26500;&#30340;&#28508;&#22312;&#31354;&#38388;&#20013;&#12290;&#21516;&#26102;&#65292;&#36825;&#31181;&#29305;&#24449;&#34920;&#31034;&#30340;&#28436;&#21464;&#23545;&#31163;&#25955;&#26102;&#38388;&#24046;&#20998;&#23398;&#20064;&#21644;Q&#23398;&#20064;&#30340;&#25910;&#25947;&#33267;&#20851;&#37325;&#35201;&#12290;&#29305;&#21035;&#22320;&#65292;&#24403;&#20989;&#25968;&#36924;&#36817;&#22120;&#22312;&#29305;&#24449;&#34920;&#31034;&#20013;&#26159;&#32447;&#24615;&#30340;&#19988;&#22312;&#25972;&#20010;&#23398;&#20064;&#36807;&#31243;&#20013;&#20445;&#25345;&#19981;&#21464;&#26102;&#65292;&#31163;&#25955;&#26102;&#38388;&#24046;&#20998;&#23398;&#20064;&#20250;&#25910;&#25947;&#65292;&#21542;&#21017;&#21487;&#33021;&#21457;&#25955;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#22238;&#31572;&#20197;&#19979;&#38382;&#39064;&#65306;&#24403;&#20989;&#25968;&#36924;&#36817;&#22120;&#26159;&#31070;&#32463;&#32593;&#32476;&#26102;&#65292;&#30456;&#20851;&#30340;&#29305;&#24449;&#34920;&#31034;&#22914;&#20309;&#28436;&#36827;&#65311;&#22914;&#26524;&#23427;&#25910;&#25947;&#65292;&#23427;&#26159;&#21542;&#25910;&#25947;&#33267;&#26368;&#20248;&#30340;&#29305;&#24449;&#34920;&#31034;&#65311;
&lt;/p&gt;
&lt;p&gt;
arXiv:2006.04761v2 Announce Type: replace  Abstract: Temporal-difference and Q-learning play a key role in deep reinforcement learning, where they are empowered by expressive nonlinear function approximators such as neural networks. At the core of their empirical successes is the learned feature representation, which embeds rich observations, e.g., images and texts, into the latent space that encodes semantic structures. Meanwhile, the evolution of such a feature representation is crucial to the convergence of temporal-difference and Q-learning.   In particular, temporal-difference learning converges when the function approximator is linear in a feature representation, which is fixed throughout learning, and possibly diverges otherwise. We aim to answer the following questions: When the function approximator is a neural network, how does the associated feature representation evolve? If it converges, does it converge to the optimal one?   We prove that, utilizing an overparameterized tw
&lt;/p&gt;</description></item><item><title>OPPO&#26159;&#31532;&#19968;&#20010;&#22312;&#25506;&#32034;&#20013;&#39640;&#25928;&#30340;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#65292;&#22312;&#22788;&#29702;&#20855;&#26377;&#32447;&#24615;&#20989;&#25968;&#36817;&#20284;&#12289;&#26410;&#30693;&#36716;&#31227;&#21644;&#23545;&#25239;&#24615;&#22870;&#21169;&#30340;&#38382;&#39064;&#20013;&#21462;&#24471;&#20102; $\tilde{O}(\sqrt{d^2 H^3 T} )$ &#30340;&#36951;&#25022;&#12290;</title><link>https://arxiv.org/abs/1912.05830</link><description>&lt;p&gt;
&#22312;&#31574;&#30053;&#20248;&#21270;&#20013;&#23454;&#29616;&#21487;&#35777;&#26126;&#39640;&#25928;&#30340;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Provably Efficient Exploration in Policy Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/1912.05830
&lt;/p&gt;
&lt;p&gt;
OPPO&#26159;&#31532;&#19968;&#20010;&#22312;&#25506;&#32034;&#20013;&#39640;&#25928;&#30340;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#65292;&#22312;&#22788;&#29702;&#20855;&#26377;&#32447;&#24615;&#20989;&#25968;&#36817;&#20284;&#12289;&#26410;&#30693;&#36716;&#31227;&#21644;&#23545;&#25239;&#24615;&#22870;&#21169;&#30340;&#38382;&#39064;&#20013;&#21462;&#24471;&#20102; $\tilde{O}(\sqrt{d^2 H^3 T} )$ &#30340;&#36951;&#25022;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#22522;&#20110;&#31574;&#30053;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#22312;&#23454;&#36341;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#65292;&#20294;&#22312;&#29702;&#35770;&#19978;&#21364;&#36828;&#19981;&#22914;&#22522;&#20110;&#20540;&#20989;&#25968;&#30340;RL&#34987;&#29702;&#35299;&#30340;&#20805;&#20998;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#22914;&#20309;&#35774;&#35745;&#19968;&#20010;&#22312;&#25506;&#32034;&#20013;&#32508;&#21512;&#39640;&#25928;&#30340;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#20173;&#28982;&#26159;&#27169;&#31946;&#30340;&#12290;&#20026;&#24357;&#21512;&#36825;&#19968;&#24046;&#36317;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;Proximal Policy Optimization&#31639;&#27861;&#30340;"&#20048;&#35266;&#21464;&#20307;"&#65288;OPPO&#65289;&#65292;&#20854;&#36981;&#24490;&#8220;&#31574;&#30053;&#26799;&#24230;&#26041;&#21521;&#8221;&#30340;&#8220;&#20048;&#35266;&#29256;&#26412;&#8221;&#12290;&#26412;&#25991;&#35777;&#26126;&#65292;&#23545;&#20110;&#20855;&#26377;&#32447;&#24615;&#20989;&#25968;&#36817;&#20284;&#12289;&#26410;&#30693;&#36716;&#31227;&#21644;&#20855;&#26377;&#23436;&#20840;&#20449;&#24687;&#21453;&#39304;&#30340;&#23545;&#25239;&#24615;&#22870;&#21169;&#30340;&#22522;&#20110;&#24773;&#33410;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#38382;&#39064;&#65292;OPPO&#23454;&#29616;&#20102; $\tilde{O}(\sqrt{d^2 H^3 T} )$ &#30340;&#36951;&#25022;&#12290;&#20854;&#20013;&#65292;$d$ &#26159;&#29305;&#24449;&#32500;&#24230;&#65292;$H$ &#26159;&#24773;&#33410;&#38271;&#24230;&#65292;$T$ &#26159;&#24635;&#27493;&#25968;&#12290;&#23601;&#25105;&#20204;&#25152;&#30693;&#65292;OPPO&#26159;&#31532;&#19968;&#20010;&#21487;&#35777;&#26126;&#39640;&#25928;&#30340;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:1912.05830v4 Announce Type: replace  Abstract: While policy-based reinforcement learning (RL) achieves tremendous successes in practice, it is significantly less understood in theory, especially compared with value-based RL. In particular, it remains elusive how to design a provably efficient policy optimization algorithm that incorporates exploration. To bridge such a gap, this paper proposes an Optimistic variant of the Proximal Policy Optimization algorithm (OPPO), which follows an ``optimistic version'' of the policy gradient direction. This paper proves that, in the problem of episodic Markov decision process with linear function approximation, unknown transition, and adversarial reward with full-information feedback, OPPO achieves $\tilde{O}(\sqrt{d^2 H^3 T} )$ regret. Here $d$ is the feature dimension, $H$ is the episode horizon, and $T$ is the total number of steps. To the best of our knowledge, OPPO is the first provably efficient policy optimization algorithm that explo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30340;&#20840;&#38754;&#22238;&#39038;&#65292;&#28085;&#30422;&#20102;&#22312;NISQ&#25216;&#26415;&#21644;&#23481;&#38169;&#37327;&#23376;&#35745;&#31639;&#30828;&#20214;&#19978;&#20351;&#29992;&#30340;&#25216;&#26415;&#21644;&#31639;&#27861;&#65292;&#24182;&#28145;&#20837;&#35752;&#35770;&#20102;&#19982;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#30456;&#20851;&#30340;&#22522;&#26412;&#27010;&#24565;&#21644;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#12290;</title><link>http://arxiv.org/abs/2401.11351</link><description>&lt;p&gt;
&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#65306;&#20174;NISQ&#21040;&#23481;&#38169;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantum Machine Learning: from NISQ to Fault Tolerance. (arXiv:2401.11351v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11351
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30340;&#20840;&#38754;&#22238;&#39038;&#65292;&#28085;&#30422;&#20102;&#22312;NISQ&#25216;&#26415;&#21644;&#23481;&#38169;&#37327;&#23376;&#35745;&#31639;&#30828;&#20214;&#19978;&#20351;&#29992;&#30340;&#25216;&#26415;&#21644;&#31639;&#27861;&#65292;&#24182;&#28145;&#20837;&#35752;&#35770;&#20102;&#19982;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#30456;&#20851;&#30340;&#22522;&#26412;&#27010;&#24565;&#21644;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#26159;&#22312;&#37327;&#23376;&#35774;&#22791;&#19978;&#36816;&#34892;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#36807;&#31243;&#65292;&#22312;&#23398;&#26415;&#30028;&#21644;&#21830;&#19994;&#30028;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#26412;&#25991;&#23545;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#28044;&#29616;&#30340;&#21508;&#31181;&#27010;&#24565;&#36827;&#34892;&#20102;&#20840;&#38754;&#32780;&#20844;&#27491;&#30340;&#22238;&#39038;&#12290;&#36825;&#21253;&#25324;&#22312;&#22122;&#22768;&#20013;&#38388;&#23610;&#24230;&#37327;&#23376;&#65288;NISQ&#65289;&#25216;&#26415;&#20013;&#20351;&#29992;&#30340;&#25216;&#26415;&#65292;&#20197;&#21450;&#19982;&#23481;&#38169;&#37327;&#23376;&#35745;&#31639;&#30828;&#20214;&#20860;&#23481;&#30340;&#31639;&#27861;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#22238;&#39038;&#28085;&#30422;&#20102;&#19982;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#30456;&#20851;&#30340;&#22522;&#26412;&#27010;&#24565;&#12289;&#31639;&#27861;&#21644;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantum machine learning, which involves running machine learning algorithms on quantum devices, has garnered significant attention in both academic and business circles. In this paper, we offer a comprehensive and unbiased review of the various concepts that have emerged in the field of quantum machine learning. This includes techniques used in Noisy Intermediate-Scale Quantum (NISQ) technologies and approaches for algorithms compatible with fault-tolerant quantum computing hardware. Our review covers fundamental concepts, algorithms, and the statistical learning theory pertinent to quantum machine learning.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#30340;PCA&#21644;&#20854;&#21464;&#31181;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#22522;&#20110;&#32447;&#24615;&#23376;&#31354;&#38388;&#26071;&#24092;&#65292;&#24182;&#24341;&#20837;&#20102;&#23545;&#24322;&#24120;&#20540;&#21644;&#25968;&#25454;&#27969;&#24418;&#30340;&#32771;&#34385;&#12290;&#36890;&#36807;&#22312;&#26071;&#24092;&#27969;&#24418;&#19978;&#36827;&#34892;&#20248;&#21270;&#38382;&#39064;&#30340;&#27714;&#35299;&#65292;&#32467;&#21512;&#20027;&#27979;&#22320;&#32447;&#36817;&#20284;&#65292;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#26032;&#30340;&#38477;&#32500;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.04071</link><description>&lt;p&gt;
&#26071;&#24092;&#28216;&#25103;&#65306;&#36890;&#36807;&#26071;&#24092;&#27969;&#24418;&#26469;&#33719;&#24471;&#40065;&#26834;&#30340;&#20027;&#26041;&#21521;
&lt;/p&gt;
&lt;p&gt;
Fun with Flags: Robust Principal Directions via Flag Manifolds. (arXiv:2401.04071v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04071
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#30340;PCA&#21644;&#20854;&#21464;&#31181;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#22522;&#20110;&#32447;&#24615;&#23376;&#31354;&#38388;&#26071;&#24092;&#65292;&#24182;&#24341;&#20837;&#20102;&#23545;&#24322;&#24120;&#20540;&#21644;&#25968;&#25454;&#27969;&#24418;&#30340;&#32771;&#34385;&#12290;&#36890;&#36807;&#22312;&#26071;&#24092;&#27969;&#24418;&#19978;&#36827;&#34892;&#20248;&#21270;&#38382;&#39064;&#30340;&#27714;&#35299;&#65292;&#32467;&#21512;&#20027;&#27979;&#22320;&#32447;&#36817;&#20284;&#65292;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#26032;&#30340;&#38477;&#32500;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#21450;&#20854;&#23545;&#27969;&#24418;&#21644;&#24322;&#24120;&#25968;&#25454;&#30340;&#25193;&#23637;&#65292;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#26159;&#19981;&#21487;&#25110;&#32570;&#30340;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;PCA&#21450;&#20854;&#21464;&#31181;&#30340;&#32479;&#19968;&#24418;&#24335;&#65292;&#24341;&#20837;&#20102;&#22522;&#20110;&#32447;&#24615;&#23376;&#31354;&#38388;&#26071;&#24092;&#30340;&#26694;&#26550;&#65292;&#21363;&#36880;&#28176;&#22686;&#21152;&#32500;&#24230;&#30340;&#23884;&#22871;&#32447;&#24615;&#23376;&#31354;&#38388;&#30340;&#23618;&#27425;&#32467;&#26500;&#65292;&#19981;&#20165;&#20801;&#35768;&#20849;&#21516;&#23454;&#29616;&#65292;&#36824;&#20135;&#29983;&#20102;&#26032;&#30340;&#26410;&#26366;&#25506;&#32034;&#30340;&#21464;&#31181;&#12290;&#25105;&#20204;&#20174;&#24191;&#20041;&#21270;&#20256;&#32479;&#30340;PCA&#26041;&#27861;&#24320;&#22987;&#65292;&#36825;&#20123;&#26041;&#27861;&#35201;&#20040;&#26368;&#22823;&#21270;&#26041;&#24046;&#65292;&#35201;&#20040;&#26368;&#23567;&#21270;&#37325;&#26500;&#35823;&#24046;&#12290;&#25105;&#20204;&#25193;&#23637;&#36825;&#20123;&#35299;&#37322;&#65292;&#36890;&#36807;&#32771;&#34385;&#24322;&#24120;&#20540;&#21644;&#25968;&#25454;&#27969;&#24418;&#65292;&#24320;&#21457;&#20986;&#20102;&#22823;&#37327;&#26032;&#30340;&#38477;&#32500;&#31639;&#27861;&#12290;&#20026;&#20102;&#35774;&#35745;&#19968;&#31181;&#36890;&#29992;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#25105;&#20204;&#23558;&#40065;&#26834;&#21644;&#23545;&#20598;&#24418;&#24335;&#30340;PCA&#37325;&#26032;&#26500;&#24314;&#20026;&#22312;&#26071;&#24092;&#27969;&#24418;&#19978;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#20027;&#27979;&#22320;&#32447;&#36817;&#20284;&#65288;&#20999;&#32447;PCA&#65289;&#25972;&#21512;&#21040;&#36825;&#20010;&#22522;&#20110;&#26071;&#24092;&#30340;&#26694;&#26550;&#20013;&#65292;&#21019;&#36896;&#20986;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Principal component analysis (PCA), along with its extensions to manifolds and outlier contaminated data, have been indispensable in computer vision and machine learning. In this work, we present a unifying formalism for PCA and its variants, and introduce a framework based on the flags of linear subspaces, \ie a hierarchy of nested linear subspaces of increasing dimension, which not only allows for a common implementation but also yields novel variants, not explored previously. We begin by generalizing traditional PCA methods that either maximize variance or minimize reconstruction error. We expand these interpretations to develop a wide array of new dimensionality reduction algorithms by accounting for outliers and the data manifold. To devise a common computational approach, we recast robust and dual forms of PCA as optimization problems on flag manifolds. We then integrate tangent space approximations of principal geodesic analysis (tangent-PCA) into this flag-based framework, crea
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#22312;&#27969;&#24418;&#19978;&#22788;&#29702;&#30690;&#37327;&#20540;&#20449;&#21495;&#30340;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#20855;&#26377;&#20869;&#22312;&#23450;&#20041;&#21644;&#32771;&#34385;&#31354;&#38388;&#20960;&#20309;&#30340;&#29305;&#28857;&#65292;&#24182;&#20026;&#37096;&#32626;&#22312;&#20108;&#32500;&#29699;&#38754;&#21644;&#36229;&#26354;&#38754;&#19978;&#30340;Hodge-Mat\'ern&#39640;&#26031;&#21521;&#37327;&#22330;&#25552;&#20379;&#20102;&#35745;&#31639;&#22522;&#20803;&#12290;</title><link>http://arxiv.org/abs/2310.18824</link><description>&lt;p&gt;
&#29699;&#38754;&#19978;&#30340;&#20869;&#22312;&#39640;&#26031;&#21521;&#37327;&#22330;
&lt;/p&gt;
&lt;p&gt;
Intrinsic Gaussian Vector Fields on Manifolds. (arXiv:2310.18824v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18824
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#22312;&#27969;&#24418;&#19978;&#22788;&#29702;&#30690;&#37327;&#20540;&#20449;&#21495;&#30340;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#20855;&#26377;&#20869;&#22312;&#23450;&#20041;&#21644;&#32771;&#34385;&#31354;&#38388;&#20960;&#20309;&#30340;&#29305;&#28857;&#65292;&#24182;&#20026;&#37096;&#32626;&#22312;&#20108;&#32500;&#29699;&#38754;&#21644;&#36229;&#26354;&#38754;&#19978;&#30340;Hodge-Mat\'ern&#39640;&#26031;&#21521;&#37327;&#22330;&#25552;&#20379;&#20102;&#35745;&#31639;&#22522;&#20803;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#26426;&#22120;&#20154;&#25216;&#26415;&#21040;&#27668;&#20505;&#31185;&#23398;&#31561;&#21508;&#31181;&#24212;&#29992;&#37117;&#38656;&#35201;&#23545;&#38750;&#27431;&#20960;&#37324;&#24471;&#22495;&#65288;&#22914;&#29699;&#38754;&#65289;&#19978;&#30340;&#20449;&#21495;&#36827;&#34892;&#24314;&#27169;&#12290;&#26368;&#36817;&#65292;&#22312;&#27969;&#34892;&#24230;&#37327;&#31354;&#38388;&#19978;&#25552;&#20986;&#20102;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#23588;&#20854;&#26159;&#22312;&#38656;&#35201;&#36827;&#34892;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#20219;&#21153;&#20013;&#12290;&#22312;&#27969;&#24418;&#35774;&#32622;&#20013;&#65292;&#19982;&#26631;&#37327;&#20540;&#20449;&#21495;&#30456;&#27604;&#65292;&#30690;&#37327;&#20540;&#20449;&#21495;&#21487;&#33021;&#34920;&#29616;&#20986;&#25130;&#28982;&#19981;&#21516;&#30340;&#34892;&#20026;&#65292;&#36804;&#20170;&#20026;&#27490;&#30340;&#22823;&#37096;&#20998;&#36827;&#23637;&#37117;&#38598;&#20013;&#22312;&#23545;&#21069;&#32773;&#36827;&#34892;&#24314;&#27169;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#35768;&#22810;&#24212;&#29992;&#65292;&#22914;&#23545;&#26410;&#30693;&#21160;&#21147;&#31995;&#32479;&#30340;&#39118;&#36895;&#25110;&#21147;&#22330;&#36827;&#34892;&#24314;&#27169;&#65292;&#21518;&#32773;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27969;&#24418;&#19978;&#20026;&#30690;&#37327;&#20540;&#20449;&#21495;&#25552;&#20379;&#20869;&#22312;&#23450;&#20041;&#24182;&#32771;&#34385;&#31354;&#38388;&#20960;&#20309;&#30340;&#26032;&#22411;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#37096;&#32626;&#25152;&#24471;&#21040;&#30340;Hodge-Mat\'ern&#39640;&#26031;&#21521;&#37327;&#22330;&#22312;&#20108;&#32500;&#29699;&#38754;&#21644;&#36229;&#26354;&#38754;&#19978;&#25152;&#38656;&#30340;&#35745;&#31639;&#22522;&#20803;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24378;&#35843;&#20102;&#20004;&#20010;&#25512;&#24191;&#26041;&#21521;&#65306;&#31163;&#25955;&#30340;&#20108;&#32500;&#32593;&#26684;&#21644;&#8221;ide&#8220;&#65288;&#26242;&#19988;&#35793;&#20026;&#65306;&#24819;&#27861;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Various applications ranging from robotics to climate science require modeling signals on non-Euclidean domains, such as the sphere. Gaussian process models on manifolds have recently been proposed for such tasks, in particular when uncertainty quantification is needed. In the manifold setting, vector-valued signals can behave very differently from scalar-valued ones, with much of the progress so far focused on modeling the latter. The former, however, are crucial for many applications, such as modeling wind speeds or force fields of unknown dynamical systems. In this paper, we propose novel Gaussian process models for vector-valued signals on manifolds that are intrinsically defined and account for the geometry of the space in consideration. We provide computational primitives needed to deploy the resulting Hodge-Mat\'ern Gaussian vector fields on the two-dimensional sphere and the hypertori. Further, we highlight two generalization directions: discrete two-dimensional meshes and "ide
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#30340;ROAM&#21644;ROOM&#31639;&#27861;&#26694;&#26550;&#36890;&#36807;&#23558;&#20013;&#20301;&#25968;&#27861;&#19982;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#30456;&#32467;&#21512;&#65292;&#25552;&#20379;&#20102;&#23545;&#37325;&#23614;&#22870;&#21169;&#30340;&#30452;&#25509;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#20174;&#32780;&#22686;&#24378;&#20102;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#22312;&#29616;&#23454;&#24212;&#29992;&#20013;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.18715</link><description>&lt;p&gt;
&#20855;&#26377;&#37325;&#23614;&#22870;&#21169;&#30340;&#24378;&#21270;&#23398;&#20064;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#21644;&#20248;&#21270;&#30340;&#40065;&#26834;&#24615;&#25552;&#21319;
&lt;/p&gt;
&lt;p&gt;
Robust Offline Policy Evaluation and Optimization with Heavy-Tailed Rewards. (arXiv:2310.18715v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18715
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#30340;ROAM&#21644;ROOM&#31639;&#27861;&#26694;&#26550;&#36890;&#36807;&#23558;&#20013;&#20301;&#25968;&#27861;&#19982;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#30456;&#32467;&#21512;&#65292;&#25552;&#20379;&#20102;&#23545;&#37325;&#23614;&#22870;&#21169;&#30340;&#30452;&#25509;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#20174;&#32780;&#22686;&#24378;&#20102;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#22312;&#29616;&#23454;&#24212;&#29992;&#20013;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#22686;&#24378;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#22312;&#29616;&#23454;&#19990;&#30028;&#24212;&#29992;&#20013;&#26222;&#36941;&#23384;&#22312;&#30340;&#37325;&#23614;&#22870;&#21169;&#24773;&#20917;&#19979;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#31639;&#27861;&#26694;&#26550;&#65292;ROAM&#21644;ROOM&#65292;&#29992;&#20110;&#40065;&#26834;&#30340;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#21644;&#31163;&#32447;&#31574;&#30053;&#20248;&#21270;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#30340;&#26680;&#24515;&#26159;&#23558;&#20013;&#20301;&#25968;&#27861;&#19982;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#30456;&#32467;&#21512;&#65292;&#33021;&#22815;&#23545;&#20540;&#20989;&#25968;&#20272;&#35745;&#22120;&#36827;&#34892;&#30452;&#25509;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#36825;&#19981;&#20165;&#31526;&#21512;&#31163;&#32447;&#31574;&#30053;&#20248;&#21270;&#20013;&#30340;&#20445;&#23432;&#20027;&#20041;&#21407;&#21017;&#65292;&#32780;&#19988;&#28789;&#27963;&#22788;&#29702;&#37325;&#23614;&#22870;&#21169;&#12290;&#29702;&#35770;&#32467;&#26524;&#21644;&#24191;&#27867;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#20004;&#20010;&#26694;&#26550;&#22312;&#35760;&#24405;&#30340;&#25968;&#25454;&#38598;&#20013;&#23637;&#31034;&#20102;&#20855;&#26377;&#37325;&#23614;&#22870;&#21169;&#20998;&#24067;&#26102;&#36229;&#36234;&#29616;&#26377;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper endeavors to augment the robustness of offline reinforcement learning (RL) in scenarios laden with heavy-tailed rewards, a prevalent circumstance in real-world applications. We propose two algorithmic frameworks, ROAM and ROOM, for robust off-policy evaluation (OPE) and offline policy optimization (OPO), respectively. Central to our frameworks is the strategic incorporation of the median-of-means method with offline RL, enabling straightforward uncertainty estimation for the value function estimator. This not only adheres to the principle of pessimism in OPO but also adeptly manages heavy-tailed rewards. Theoretical results and extensive experiments demonstrate that our two frameworks outperform existing methods on the logged dataset exhibits heavy-tailed reward distributions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21457;&#29616;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;grokking&#29616;&#35937;&#19981;&#20165;&#23616;&#38480;&#20110;&#31070;&#32463;&#32593;&#32476;&#65292;&#36824;&#20986;&#29616;&#22312;&#20854;&#20182;&#31639;&#27861;&#21644;&#27169;&#22411;&#20013;&#12290;&#36890;&#36807;&#22312;&#25968;&#25454;&#38598;&#20013;&#28155;&#21152;&#34394;&#20551;&#20449;&#24687;&#30340;&#32500;&#24230;&#65292;&#21487;&#20197;&#35825;&#21457;grokking&#29616;&#35937;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;grokking&#29616;&#35937;&#22312;&#35299;&#20915;&#26041;&#26696;&#25628;&#32034;&#21463;&#22797;&#26434;&#24615;&#21644;&#38169;&#35823;&#25351;&#23548;&#30340;&#20219;&#20309;&#24773;&#20917;&#19979;&#21487;&#33021;&#21457;&#29983;&#12290;&#36825;&#23545;&#29702;&#35299;grokking&#29616;&#35937;&#25552;&#20379;&#20102;&#26356;&#24191;&#27867;&#30340;&#29702;&#35770;&#25903;&#25345;&#12290;</title><link>http://arxiv.org/abs/2310.17247</link><description>&lt;p&gt;
&#36229;&#36234;&#31070;&#32463;&#32593;&#32476;&#65306;&#27169;&#22411;&#22797;&#26434;&#24615;&#30340;&#32463;&#39564;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Grokking Beyond Neural Networks: An Empirical Exploration with Model Complexity. (arXiv:2310.17247v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17247
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21457;&#29616;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;grokking&#29616;&#35937;&#19981;&#20165;&#23616;&#38480;&#20110;&#31070;&#32463;&#32593;&#32476;&#65292;&#36824;&#20986;&#29616;&#22312;&#20854;&#20182;&#31639;&#27861;&#21644;&#27169;&#22411;&#20013;&#12290;&#36890;&#36807;&#22312;&#25968;&#25454;&#38598;&#20013;&#28155;&#21152;&#34394;&#20551;&#20449;&#24687;&#30340;&#32500;&#24230;&#65292;&#21487;&#20197;&#35825;&#21457;grokking&#29616;&#35937;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;grokking&#29616;&#35937;&#22312;&#35299;&#20915;&#26041;&#26696;&#25628;&#32034;&#21463;&#22797;&#26434;&#24615;&#21644;&#38169;&#35823;&#25351;&#23548;&#30340;&#20219;&#20309;&#24773;&#20917;&#19979;&#21487;&#33021;&#21457;&#29983;&#12290;&#36825;&#23545;&#29702;&#35299;grokking&#29616;&#35937;&#25552;&#20379;&#20102;&#26356;&#24191;&#27867;&#30340;&#29702;&#35770;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#31070;&#32463;&#32593;&#32476;&#23637;&#29616;&#20986;&#19968;&#31181;&#31216;&#20026;&#8220;grokking&#8221;&#30340;&#29616;&#35937;&#65292;&#21363;&#23427;&#20204;&#22312;&#39564;&#35777;&#38598;&#19978;&#23454;&#29616;&#23436;&#32654;&#25110;&#25509;&#36817;&#23436;&#32654;&#30340;&#20934;&#30830;&#24230;&#65292;&#32780;&#22312;&#35757;&#32451;&#38598;&#19978;&#21017;&#26089;&#24050;&#36798;&#21040;&#30456;&#21516;&#30340;&#24615;&#33021;&#12290;&#26412;&#25991;&#21457;&#29616;&#65292;grokking&#19981;&#20165;&#38480;&#20110;&#31070;&#32463;&#32593;&#32476;&#65292;&#36824;&#20986;&#29616;&#22312;&#20854;&#20182;&#35774;&#32622;&#20013;&#65292;&#20363;&#22914;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#20998;&#31867;&#12289;GP&#22238;&#24402;&#21644;&#32447;&#24615;&#22238;&#24402;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#20102;&#19968;&#31181;&#36890;&#36807;&#28155;&#21152;&#21253;&#21547;&#34394;&#20551;&#20449;&#24687;&#30340;&#32500;&#24230;&#26469;&#35825;&#21457;&#22522;&#20110;&#31639;&#27861;&#30340;&#25968;&#25454;&#38598;&#20013;&#30340;grokking&#29616;&#35937;&#30340;&#26426;&#21046;&#12290;&#38750;&#31070;&#32463;&#32467;&#26500;&#20013;&#30340;&#36825;&#31181;&#29616;&#35937;&#30340;&#23384;&#22312;&#35777;&#26126;&#20102;grokking&#19981;&#23616;&#38480;&#20110;SGD&#25110;&#26435;&#37325;&#33539;&#25968;&#27491;&#21017;&#21270;&#12290;&#30456;&#21453;&#65292;grokking&#21487;&#33021;&#21457;&#29983;&#22312;&#20219;&#20309;&#30001;&#22797;&#26434;&#24615;&#21644;&#38169;&#35823;&#25351;&#23548;&#35299;&#20915;&#26041;&#26696;&#25628;&#32034;&#30340;&#24773;&#20917;&#20013;&#12290;&#22522;&#20110;&#36825;&#19968;&#27934;&#23519;&#21644;&#25105;&#20204;&#22312;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNN&#65289;&#21644;GP&#22238;&#24402;&#27169;&#22411;&#30340;&#35757;&#32451;&#36712;&#36857;&#20013;&#35266;&#23519;&#21040;&#30340;&#36827;&#19968;&#27493;&#36235;&#21183;&#65292;&#25105;&#20204;&#22312;grokking&#30340;&#26356;&#19968;&#33324;&#30340;&#29702;&#35770;&#26041;&#38754;&#21462;&#24471;&#20102;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
In some settings neural networks exhibit a phenomenon known as grokking, where they achieve perfect or near-perfect accuracy on the validation set long after the same performance has been achieved on the training set. In this paper, we discover that grokking is not limited to neural networks but occurs in other settings such as Gaussian process (GP) classification, GP regression and linear regression. We also uncover a mechanism by which to induce grokking on algorithmic datasets via the addition of dimensions containing spurious information. The presence of the phenomenon in non-neural architectures provides evidence that grokking is not specific to SGD or weight norm regularisation. Instead, grokking may be possible in any setting where solution search is guided by complexity and error. Based on this insight and further trends we see in the training trajectories of a Bayesian neural network (BNN) and GP regression model, we make progress towards a more general theory of grokking. Spe
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#30740;&#31350;&#20102;&#22810;&#20010;&#19987;&#23478;&#23398;&#20064;&#25512;&#36831;&#38382;&#39064;&#30340;&#20195;&#29702;&#25439;&#22833;&#21644;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20123;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#20855;&#26377;&#24378;H&#19968;&#33268;&#24615;&#30028;&#38480;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20960;&#20010;&#23454;&#38469;&#24212;&#29992;&#30340;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#65292;&#24182;&#35774;&#35745;&#20102;&#22522;&#20110;&#26368;&#23567;&#21270;&#36825;&#20123;&#25439;&#22833;&#20989;&#25968;&#30340;&#26032;&#30340;&#23398;&#20064;&#25512;&#36831;&#31639;&#27861;&#12290;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#22312;SVHN&#21644;CIFAR-10&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#12290;</title><link>http://arxiv.org/abs/2310.14774</link><description>&lt;p&gt;
&#22810;&#20010;&#19987;&#23478;&#23398;&#20064;&#25512;&#36831;&#30340;&#21407;&#21017;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Principled Approaches for Learning to Defer with Multiple Experts. (arXiv:2310.14774v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14774
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22810;&#20010;&#19987;&#23478;&#23398;&#20064;&#25512;&#36831;&#38382;&#39064;&#30340;&#20195;&#29702;&#25439;&#22833;&#21644;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20123;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#20855;&#26377;&#24378;H&#19968;&#33268;&#24615;&#30028;&#38480;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20960;&#20010;&#23454;&#38469;&#24212;&#29992;&#30340;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#65292;&#24182;&#35774;&#35745;&#20102;&#22522;&#20110;&#26368;&#23567;&#21270;&#36825;&#20123;&#25439;&#22833;&#20989;&#25968;&#30340;&#26032;&#30340;&#23398;&#20064;&#25512;&#36831;&#31639;&#27861;&#12290;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#22312;SVHN&#21644;CIFAR-10&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#39033;&#20851;&#20110;&#20351;&#29992;&#22810;&#20010;&#19987;&#23478;&#23398;&#20064;&#25512;&#36831;&#38382;&#39064;&#30340;&#20195;&#29702;&#25439;&#22833;&#21644;&#31639;&#27861;&#30340;&#30740;&#31350;&#12290;&#25105;&#20204;&#39318;&#20808;&#24341;&#20837;&#20102;&#19968;&#31867;&#19987;&#38376;&#38024;&#23545;&#22810;&#19987;&#23478;&#35774;&#32622;&#30340;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#65292;&#20854;&#20013;&#39044;&#27979;&#21644;&#25512;&#36831;&#20989;&#25968;&#21516;&#26102;&#23398;&#20064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#21463;&#30410;&#20110;&#24378;H&#19968;&#33268;&#24615;&#30028;&#38480;&#12290;&#25105;&#20204;&#36890;&#36807;&#20960;&#20010;&#23454;&#38469;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#30340;&#31034;&#20363;&#23637;&#31034;&#20102;&#25105;&#20204;&#20998;&#26512;&#30340;&#24212;&#29992;&#65292;&#24182;&#32473;&#20986;&#20102;&#26126;&#30830;&#30340;&#20445;&#35777;&#12290;&#36825;&#20123;&#25439;&#22833;&#20989;&#25968;&#30452;&#25509;&#23548;&#33268;&#20102;&#22522;&#20110;&#23427;&#20204;&#26368;&#23567;&#21270;&#30340;&#26032;&#30340;&#23398;&#20064;&#25512;&#36831;&#31639;&#27861;&#30340;&#35774;&#35745;&#12290;&#34429;&#28982;&#26412;&#24037;&#20316;&#30340;&#20027;&#35201;&#37325;&#28857;&#26159;&#29702;&#35770;&#20998;&#26512;&#65292;&#20294;&#25105;&#20204;&#36824;&#25253;&#21578;&#20102;&#22312;SVHN&#21644;CIFAR-10&#25968;&#25454;&#38598;&#19978;&#30340;&#22810;&#20010;&#23454;&#39564;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a study of surrogate losses and algorithms for the general problem of learning to defer with multiple experts. We first introduce a new family of surrogate losses specifically tailored for the multiple-expert setting, where the prediction and deferral functions are learned simultaneously. We then prove that these surrogate losses benefit from strong $H$-consistency bounds. We illustrate the application of our analysis through several examples of practical surrogate losses, for which we give explicit guarantees. These loss functions readily lead to the design of new learning to defer algorithms based on their minimization. While the main focus of this work is a theoretical analysis, we also report the results of several experiments on SVHN and CIFAR-10 datasets.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#30740;&#31350;&#20102;&#22810;&#31867;&#21035;&#20998;&#31867;&#35774;&#32622;&#20013;&#30340;&#23398;&#20064;&#19982;&#25918;&#24323;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#26032;&#30340;&#29702;&#35770;&#21644;&#31639;&#27861;&#32467;&#26524;&#65292;&#35299;&#20915;&#20102;&#20004;&#20010;&#29616;&#23384;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;&#36825;&#20123;&#20445;&#35777;&#20026;&#22522;&#20110;&#26368;&#23567;&#21270;&#25918;&#24323;&#25439;&#22833;&#30340;&#26032;&#30340;&#22810;&#31867;&#21035;&#25918;&#24323;&#31639;&#27861;&#25552;&#20379;&#20102;&#21551;&#31034;&#12290;</title><link>http://arxiv.org/abs/2310.14772</link><description>&lt;p&gt;
&#39044;&#27979;-&#25298;&#32477;&#22810;&#31867;&#25918;&#24323;&#65306;&#29702;&#35770;&#20998;&#26512;&#21644;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Predictor-Rejector Multi-Class Abstention: Theoretical Analysis and Algorithms. (arXiv:2310.14772v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14772
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22810;&#31867;&#21035;&#20998;&#31867;&#35774;&#32622;&#20013;&#30340;&#23398;&#20064;&#19982;&#25918;&#24323;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#26032;&#30340;&#29702;&#35770;&#21644;&#31639;&#27861;&#32467;&#26524;&#65292;&#35299;&#20915;&#20102;&#20004;&#20010;&#29616;&#23384;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;&#36825;&#20123;&#20445;&#35777;&#20026;&#22522;&#20110;&#26368;&#23567;&#21270;&#25918;&#24323;&#25439;&#22833;&#30340;&#26032;&#30340;&#22810;&#31867;&#21035;&#25918;&#24323;&#31639;&#27861;&#25552;&#20379;&#20102;&#21551;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22810;&#31867;&#21035;&#20998;&#31867;&#35774;&#32622;&#20013;&#30340;&#23398;&#20064;&#19982;&#25918;&#24323;&#26694;&#26550;&#12290;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#65292;&#23398;&#20064;&#32773;&#21487;&#20197;&#36873;&#25321;&#20197;&#19968;&#23450;&#30340;&#39044;&#23450;&#20041;&#25104;&#26412;&#25918;&#24323;&#36827;&#34892;&#39044;&#27979;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#26032;&#30340;&#29702;&#35770;&#21644;&#31639;&#27861;&#32467;&#26524;&#65292;&#35299;&#20915;&#20102;&#39044;&#27979;-&#25298;&#32477;&#26694;&#26550;&#19979;&#30340;&#23398;&#20064;&#38382;&#39064;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#20960;&#20010;&#26032;&#30340;&#26367;&#20195;&#25439;&#22833;&#20989;&#25968;&#23478;&#26063;&#65292;&#35777;&#26126;&#20102;&#24378;&#38750;&#28176;&#36827;&#21644;&#20551;&#35774;&#38598;&#29305;&#23450;&#30340;&#19968;&#33268;&#24615;&#20445;&#35777;&#65292;&#20174;&#32780;&#31215;&#26497;&#22320;&#35299;&#20915;&#20102;&#20004;&#20010;&#29616;&#23384;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;&#36825;&#20123;&#20445;&#35777;&#25552;&#20379;&#20102;&#25918;&#24323;&#25439;&#22833;&#20989;&#25968;&#30340;&#20272;&#35745;&#35823;&#24046;&#30340;&#19978;&#30028;&#65292;&#19982;&#26367;&#20195;&#25439;&#22833;&#30340;&#35823;&#24046;&#30456;&#20851;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#21516;&#26102;&#23398;&#20064;&#39044;&#27979;&#22120;&#21644;&#25298;&#32477;&#22120;&#30340;&#21333;&#38454;&#27573;&#35774;&#32622;&#65292;&#20197;&#21450;&#22312;&#24212;&#29992;&#20013;&#33267;&#20851;&#37325;&#35201;&#30340;&#20004;&#38454;&#27573;&#35774;&#32622;&#65292;&#22312;&#31532;&#19968;&#38454;&#27573;&#20351;&#29992;&#26631;&#20934;&#26367;&#20195;&#25439;&#22833;&#20989;&#25968;&#22914;&#20132;&#21449;&#29109;&#26469;&#23398;&#20064;&#39044;&#27979;&#22120;&#12290;&#36825;&#20123;&#20445;&#35777;&#20026;&#22522;&#20110;&#26368;&#23567;&#21270;&#25918;&#24323;&#25439;&#22833;&#30340;&#26032;&#30340;&#22810;&#31867;&#21035;&#25918;&#24323;&#31639;&#27861;&#25552;&#20379;&#20102;&#21551;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the key framework of learning with abstention in the multi-class classification setting. In this setting, the learner can choose to abstain from making a prediction with some pre-defined cost. We present a series of new theoretical and algorithmic results for this learning problem in the predictor-rejector framework. We introduce several new families of surrogate losses for which we prove strong non-asymptotic and hypothesis set-specific consistency guarantees, thereby resolving positively two existing open questions. These guarantees provide upper bounds on the estimation error of the abstention loss function in terms of that of the surrogate loss. We analyze both a single-stage setting where the predictor and rejector are learned simultaneously and a two-stage setting crucial in applications, where the predictor is learned in a first stage using a standard surrogate loss such as cross-entropy. These guarantees suggest new multi-class abstention algorithms based on minimizing
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#20998;&#25968;&#30340;&#22810;&#31867;&#25918;&#24323;&#30340;&#29702;&#35770;&#22522;&#30784;&#25439;&#22833;&#20989;&#25968;&#21644;&#31639;&#27861;&#65292;&#21253;&#25324;&#24341;&#20837;&#20102;&#26032;&#30340;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#26063;&#32676;&#20197;&#21450;&#35777;&#26126;&#20102;&#36825;&#20123;&#20195;&#29702;&#25439;&#22833;&#30340;&#19968;&#33268;&#24615;&#20445;&#35777;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#31639;&#27861;&#30340;&#23454;&#38469;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2310.14770</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#25968;&#30340;&#22810;&#31867;&#25918;&#24323;&#30340;&#29702;&#35770;&#22522;&#30784;&#25439;&#22833;&#20989;&#25968;&#21644;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Theoretically Grounded Loss Functions and Algorithms for Score-Based Multi-Class Abstention. (arXiv:2310.14770v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14770
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#20998;&#25968;&#30340;&#22810;&#31867;&#25918;&#24323;&#30340;&#29702;&#35770;&#22522;&#30784;&#25439;&#22833;&#20989;&#25968;&#21644;&#31639;&#27861;&#65292;&#21253;&#25324;&#24341;&#20837;&#20102;&#26032;&#30340;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#26063;&#32676;&#20197;&#21450;&#35777;&#26126;&#20102;&#36825;&#20123;&#20195;&#29702;&#25439;&#22833;&#30340;&#19968;&#33268;&#24615;&#20445;&#35777;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#31639;&#27861;&#30340;&#23454;&#38469;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#20013;&#30340;&#25918;&#24323;&#26159;&#19968;&#31181;&#37325;&#35201;&#30340;&#22330;&#26223;&#65292;&#23398;&#20064;&#32773;&#21487;&#20197;&#36873;&#25321;&#22312;&#26576;&#20010;&#20195;&#20215;&#19979;&#25918;&#24323;&#36827;&#34892;&#39044;&#27979;&#12290;&#26412;&#25991;&#22312;&#22810;&#31867;&#21035;&#20998;&#31867;&#30340;&#35774;&#32622;&#19979;&#20998;&#26512;&#20102;&#22522;&#20110;&#20998;&#25968;&#30340;&#23398;&#20064;&#20013;&#30340;&#25918;&#24323;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#25918;&#24323;&#25439;&#22833;&#20989;&#25968;&#30340;&#26032;&#20195;&#29702;&#25439;&#22833;&#26063;&#32676;&#65292;&#20854;&#20013;&#21253;&#25324;&#21333;&#38454;&#27573;&#35774;&#32622;&#20013;&#26368;&#20808;&#36827;&#30340;&#20195;&#29702;&#25439;&#22833;&#20197;&#21450;&#20108;&#38454;&#27573;&#35774;&#32622;&#20013;&#30340;&#26032;&#22411;&#25439;&#22833;&#20989;&#25968;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;&#20195;&#29702;&#25439;&#22833;&#30340;&#24378;&#38750;&#28176;&#36817;&#21644;&#20551;&#35774;&#38598;&#29305;&#23450;&#30340;&#19968;&#33268;&#24615;&#20445;&#35777;&#65292;&#36825;&#20123;&#20445;&#35777;&#19978;&#30028;&#20102;&#25918;&#24323;&#25439;&#22833;&#20989;&#25968;&#30340;&#20272;&#35745;&#35823;&#24046;&#65292;&#19982;&#20195;&#29702;&#25439;&#22833;&#30340;&#20272;&#35745;&#35823;&#24046;&#30456;&#20851;&#12290;&#25105;&#20204;&#30340;&#19978;&#30028;&#21487;&#20197;&#24110;&#21161;&#27604;&#36739;&#19981;&#21516;&#30340;&#22522;&#20110;&#20998;&#25968;&#30340;&#20195;&#29702;&#25439;&#22833;&#65292;&#25351;&#23548;&#36890;&#36807;&#26368;&#23567;&#21270;&#25552;&#20986;&#30340;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#26469;&#35774;&#35745;&#26032;&#30340;&#25918;&#24323;&#31639;&#27861;&#12290;&#25105;&#20204;&#22312;CIFAR-10&#12289;CIFAR-100&#21644;SVHN&#25968;&#25454;&#38598;&#19978;&#23545;&#25105;&#20204;&#30340;&#26032;&#31639;&#27861;&#36827;&#34892;&#20102;&#23454;&#39564;&#35780;&#20272;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26032;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#30340;&#23454;&#38469;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning with abstention is a key scenario where the learner can abstain from making a prediction at some cost. In this paper, we analyze the score-based formulation of learning with abstention in the multi-class classification setting. We introduce new families of surrogate losses for the abstention loss function, which include the state-of-the-art surrogate losses in the single-stage setting and a novel family of loss functions in the two-stage setting. We prove strong non-asymptotic and hypothesis set-specific consistency guarantees for these surrogate losses, which upper-bound the estimation error of the abstention loss function in terms of the estimation error of the surrogate loss. Our bounds can help compare different score-based surrogates and guide the design of novel abstention algorithms by minimizing the proposed surrogate losses. We experimentally evaluate our new algorithms on CIFAR-10, CIFAR-100, and SVHN datasets and the practical significance of our new surrogate losse
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#24191;&#27867;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#21363;Ito&#38142;&#30340;Ito&#25193;&#25955;&#36924;&#36817;&#12290;&#19982;&#22823;&#22810;&#25968;&#30456;&#20851;&#35770;&#25991;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#38142;&#20855;&#26377;&#21508;&#21521;&#21516;&#24615;&#21644;&#29366;&#24577;&#30456;&#20851;&#30340;&#22122;&#22768;&#65292;&#24182;&#21487;&#20197;&#36866;&#29992;&#20110;&#22810;&#31181;&#24212;&#29992;&#22330;&#26223;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;Ito&#38142;&#19982;&#23545;&#24212;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20043;&#38388;&#30340;W2-&#36317;&#31163;&#30340;&#19978;&#30028;&#12290;&#36825;&#20123;&#32467;&#26524;&#25913;&#36827;&#20102;&#24050;&#26377;&#30340;&#20272;&#35745;&#26041;&#27861;&#65292;&#24182;&#22312;&#26576;&#20123;&#29305;&#27530;&#24773;&#20917;&#19979;&#25552;&#20379;&#20102;&#39318;&#27425;&#30340;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2310.06081</link><description>&lt;p&gt;
&#29992;&#20110;&#37319;&#26679;&#12289;&#20248;&#21270;&#21644;&#25552;&#21319;&#30340;&#36890;&#29992;Ito&#38142;&#30340;Ito&#25193;&#25955;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Ito Diffusion Approximation of Universal Ito Chains for Sampling, Optimization and Boosting. (arXiv:2310.06081v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06081
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#24191;&#27867;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#21363;Ito&#38142;&#30340;Ito&#25193;&#25955;&#36924;&#36817;&#12290;&#19982;&#22823;&#22810;&#25968;&#30456;&#20851;&#35770;&#25991;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#38142;&#20855;&#26377;&#21508;&#21521;&#21516;&#24615;&#21644;&#29366;&#24577;&#30456;&#20851;&#30340;&#22122;&#22768;&#65292;&#24182;&#21487;&#20197;&#36866;&#29992;&#20110;&#22810;&#31181;&#24212;&#29992;&#22330;&#26223;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;Ito&#38142;&#19982;&#23545;&#24212;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20043;&#38388;&#30340;W2-&#36317;&#31163;&#30340;&#19978;&#30028;&#12290;&#36825;&#20123;&#32467;&#26524;&#25913;&#36827;&#20102;&#24050;&#26377;&#30340;&#20272;&#35745;&#26041;&#27861;&#65292;&#24182;&#22312;&#26576;&#20123;&#29305;&#27530;&#24773;&#20917;&#19979;&#25552;&#20379;&#20102;&#39318;&#27425;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#31867;&#30456;&#24403;&#19968;&#33324;&#21644;&#24191;&#27867;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#21363;Ito&#38142;&#65292;&#20854;&#31867;&#20284;&#20110;&#26576;&#20123;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;Euler-Maruyama&#31163;&#25955;&#21270;&#12290;&#25105;&#20204;&#30740;&#31350;&#30340;&#38142;&#26159;&#19968;&#20010;&#32479;&#19968;&#30340;&#29702;&#35770;&#20998;&#26512;&#26694;&#26550;&#12290;&#19982;&#22823;&#22810;&#25968;&#30456;&#20851;&#35770;&#25991;&#20013;&#30340;&#27491;&#24577;&#21644;&#29366;&#24577;&#29420;&#31435;&#22122;&#22768;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#38142;&#20855;&#26377;&#20960;&#20046;&#20219;&#24847;&#21508;&#21521;&#21516;&#24615;&#21644;&#29366;&#24577;&#30456;&#20851;&#22122;&#22768;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#38142;&#30340;&#28418;&#31227;&#21644;&#25193;&#25955;&#31995;&#25968;&#21487;&#20197;&#26159;&#31934;&#30830;&#30340;&#65292;&#20197;&#28085;&#30422;&#35832;&#22914;&#38543;&#26426;&#26799;&#24230;Langevin&#21160;&#21147;&#23398;&#12289;&#37319;&#26679;&#12289;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#25110;&#38543;&#26426;&#26799;&#24230;&#25552;&#21319;&#31561;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;Ito&#38142;&#19982;&#23545;&#24212;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20043;&#38388;&#30340;W2-&#36317;&#31163;&#30340;&#19968;&#20010;&#19978;&#30028;&#12290;&#36825;&#20123;&#32467;&#26524;&#25913;&#36827;&#25110;&#35206;&#30422;&#20102;&#22823;&#37096;&#20998;&#24050;&#30693;&#30340;&#20272;&#35745;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#26576;&#20123;&#29305;&#27530;&#24773;&#20917;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#26159;&#31532;&#19968;&#20010;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work considers a rather general and broad class of Markov chains, Ito chains that look like Euler-Maryama discretization of some Stochastic Differential Equation. The chain we study is a unified framework for theoretical analysis. It comes with almost arbitrary isotropic and state-dependent noise instead of normal and state-independent one, as in most related papers. Moreover, our chain's drift and diffusion coefficient can be inexact to cover a wide range of applications such as Stochastic Gradient Langevin Dynamics, sampling, Stochastic Gradient Descent, or Stochastic Gradient Boosting. We prove an upper bound for $W_{2}$-distance between laws of the Ito chain and the corresponding Stochastic Differential Equation. These results improve or cover most of the known estimates. Moreover, for some particular cases, our analysis is the first.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#19968;&#33268;&#24615;&#36712;&#36857;&#27169;&#22411;&#65288;CTM&#65289;&#65292;&#23427;&#21487;&#20197;&#21152;&#36895;&#25193;&#25955;&#27169;&#22411;&#30340;&#37319;&#26679;&#65292;&#21516;&#26102;&#36890;&#36807;&#23545;&#25239;&#35757;&#32451;&#21644;&#21435;&#22122;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#30340;&#32452;&#21512;&#26469;&#25552;&#39640;&#24615;&#33021;&#65292;&#24182;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#37319;&#26679;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2310.02279</link><description>&lt;p&gt;
&#19968;&#33268;&#24615;&#36712;&#36857;&#27169;&#22411;&#65306;&#23398;&#20064;&#25193;&#25955;&#30340;&#27010;&#29575;&#27969;ODE&#36712;&#36857;
&lt;/p&gt;
&lt;p&gt;
Consistency Trajectory Models: Learning Probability Flow ODE Trajectory of Diffusion. (arXiv:2310.02279v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02279
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#19968;&#33268;&#24615;&#36712;&#36857;&#27169;&#22411;&#65288;CTM&#65289;&#65292;&#23427;&#21487;&#20197;&#21152;&#36895;&#25193;&#25955;&#27169;&#22411;&#30340;&#37319;&#26679;&#65292;&#21516;&#26102;&#36890;&#36807;&#23545;&#25239;&#35757;&#32451;&#21644;&#21435;&#22122;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#30340;&#32452;&#21512;&#26469;&#25552;&#39640;&#24615;&#33021;&#65292;&#24182;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#37319;&#26679;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#33268;&#24615;&#27169;&#22411;&#65288;CM&#65289;&#21152;&#36895;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#37319;&#26679;&#65292;&#20294;&#20197;&#29306;&#29298;&#26679;&#26412;&#36136;&#37327;&#20026;&#20195;&#20215;&#65292;&#32570;&#20047;&#19968;&#31181;&#33258;&#28982;&#30340;&#26041;&#27861;&#26469;&#26435;&#34913;&#36895;&#24230;&#21644;&#36136;&#37327;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#33268;&#24615;&#36712;&#36857;&#27169;&#22411;&#65288;CTM&#65289;&#65292;&#23427;&#26159;&#21253;&#25324;CM&#21644;&#22522;&#20110;&#24471;&#20998;&#27169;&#22411;&#22312;&#20869;&#30340;&#27867;&#21270;&#27169;&#22411;&#12290;CTM&#35757;&#32451;&#19968;&#20010;&#21333;&#19968;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#20197;&#22312;&#21333;&#27425;&#21069;&#21521;&#20256;&#36882;&#20013;&#36755;&#20986;&#24471;&#20998;&#65288;&#21363;&#23545;&#25968;&#23494;&#24230;&#30340;&#26799;&#24230;&#65289;&#65292;&#24182;&#20801;&#35768;&#22312;&#25193;&#25955;&#36807;&#31243;&#20013;&#20219;&#24847;&#21021;&#22987;&#21644;&#26368;&#32456;&#26102;&#38388;&#20043;&#38388;&#36827;&#34892;&#19981;&#21463;&#38480;&#21046;&#30340;&#36941;&#21382;&#27010;&#29575;&#27969;&#26222;&#36890;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#12290;CTM&#21033;&#29992;&#23545;&#25239;&#35757;&#32451;&#21644;&#21435;&#22122;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#30340;&#26377;&#25928;&#32452;&#21512;&#26469;&#25552;&#39640;&#24615;&#33021;&#65292;&#24182;&#22312;CIFAR-10&#65288;FID 1.73&#65289;&#21644;64X64&#20998;&#36776;&#29575;&#30340;ImageNet&#19978;&#23454;&#29616;&#26032;&#30340;&#26368;&#20808;&#36827;FID&#12290;CTM&#36824;&#23454;&#29616;&#20102;&#19968;&#31995;&#21015;&#26032;&#30340;&#37319;&#26679;&#26041;&#26696;&#65292;&#21253;&#25324;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#30340;ODE&#35299;&#20013;&#30340;&#38271;&#36339;&#36291;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consistency Models (CM) (Song et al., 2023) accelerate score-based diffusion model sampling at the cost of sample quality but lack a natural way to trade-off quality for speed. To address this limitation, we propose Consistency Trajectory Model (CTM), a generalization encompassing CM and score-based models as special cases. CTM trains a single neural network that can -- in a single forward pass -- output scores (i.e., gradients of log-density) and enables unrestricted traversal between any initial and final time along the Probability Flow Ordinary Differential Equation (ODE) in a diffusion process. CTM enables the efficient combination of adversarial training and denoising score matching loss to enhance performance and achieves new state-of-the-art FIDs for single-step diffusion model sampling on CIFAR-10 (FID 1.73) and ImageNet at 64X64 resolution (FID 2.06). CTM also enables a new family of sampling schemes, both deterministic and stochastic, involving long jumps along the ODE soluti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#21160;&#24577;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DDAG&#65289;&#30340;&#20449;&#24687;&#29702;&#35770;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35266;&#27979;&#26102;&#38388;&#24207;&#21015;&#30340;&#21151;&#29575;&#35889;&#23494;&#24230;&#30697;&#38453;&#30340;&#24230;&#37327;&#21644;&#31639;&#27861;&#26469;&#37325;&#24314;DDAG&#12290;</title><link>http://arxiv.org/abs/2308.16859</link><description>&lt;p&gt;
&#23398;&#20064;&#21160;&#24577;&#26377;&#21521;&#26080;&#29615;&#22270;&#30340;&#20449;&#24687;&#29702;&#35770;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
Information Theoretically Optimal Sample Complexity of Learning Dynamical Directed Acyclic Graphs. (arXiv:2308.16859v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16859
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#21160;&#24577;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DDAG&#65289;&#30340;&#20449;&#24687;&#29702;&#35770;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35266;&#27979;&#26102;&#38388;&#24207;&#21015;&#30340;&#21151;&#29575;&#35889;&#23494;&#24230;&#30697;&#38453;&#30340;&#24230;&#37327;&#21644;&#31639;&#27861;&#26469;&#37325;&#24314;DDAG&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#65288;LDS&#65289;&#22312;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#19978;&#30340;&#24213;&#23618;&#30456;&#20114;&#20316;&#29992;/&#20381;&#36182;&#20851;&#31995;&#30340;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#23398;&#20064;DAG&#32467;&#26500;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#22312;&#38745;&#24577;&#31995;&#32479;&#20013;&#24050;&#32463;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#30740;&#31350;&#65292;&#20854;&#20013;&#33410;&#28857;&#29366;&#24577;&#30340;&#26679;&#26412;&#26159;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#65288;i.i.d.&#65289;&#12290;&#28982;&#32780;&#65292;&#22312;&#20855;&#26377;&#21160;&#24577;&#31995;&#32479;&#30340;DAG&#20013;&#65292;&#36825;&#26679;&#30340;&#30740;&#31350;&#36739;&#23569;&#12290;&#25105;&#20204;&#23558;&#36825;&#26679;&#30340;DAG&#31216;&#20026;\emph{&#21160;&#24577;}DAG&#65288;DDAG&#65289;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;DDAG&#65292;&#20854;&#20013;&#33410;&#28857;&#21160;&#21147;&#23398;&#30001;&#26410;&#35266;&#27979;&#30340;&#22806;&#29983;&#22122;&#22768;&#28304;&#39537;&#21160;&#65292;&#36825;&#20123;&#22122;&#22768;&#28304;&#22312;&#26102;&#38388;&#19978;&#26159;&#23485;&#24133;&#24179;&#31283;&#30340;&#65288;WSS&#65289;&#65292;&#20294;&#24444;&#27492;&#20043;&#38388;&#26159;&#19981;&#30456;&#20851;&#30340;&#65292;&#24182;&#19988;&#20855;&#26377;&#30456;&#21516;&#30340;&#21151;&#29575;&#35889;&#23494;&#24230;&#65288;PSD&#65289;&#12290;&#21463;&#38745;&#24577;&#35774;&#32622;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35266;&#27979;&#26102;&#38388;&#24207;&#21015;&#30340;PSD&#30697;&#38453;&#30340;&#24230;&#37327;&#21644;&#31639;&#27861;&#26469;&#37325;&#24314;DDAG&#12290;&#22122;&#22768;PSD&#30456;&#31561;&#30340;&#20551;&#35774;&#21487;&#20197;&#25918;&#23485;&#65292;&#20197;&#20351;&#20854;&#21487;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this article, the optimal sample complexity of learning the underlying interaction/dependencies of a Linear Dynamical System (LDS) over a Directed Acyclic Graph (DAG) is studied. The sample complexity of learning a DAG's structure is well-studied for static systems, where the samples of nodal states are independent and identically distributed (i.i.d.). However, such a study is less explored for DAGs with dynamical systems, where the nodal states are temporally correlated. We call such a DAG underlying an LDS as \emph{dynamical} DAG (DDAG). In particular, we consider a DDAG where the nodal dynamics are driven by unobserved exogenous noise sources that are wide-sense stationary (WSS) in time but are mutually uncorrelated, and have the same {power spectral density (PSD)}. Inspired by the static settings, a metric and an algorithm based on the PSD matrix of the observed time series are proposed to reconstruct the DDAG. The equal noise PSD assumption can be relaxed such that identifiabil
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35814;&#32454;&#30740;&#31350;&#20102;PCA&#26041;&#27861;&#20013;&#25968;&#25454;&#23621;&#20013;&#21270;&#27493;&#39588;&#30340;&#24433;&#21709;&#65292;&#20998;&#26512;&#20102;&#24102;&#23621;&#20013;&#21270;&#21644;&#19981;&#24102;&#23621;&#20013;&#21270;&#30340;&#20004;&#20010;PCA&#23884;&#20837;&#20043;&#38388;&#30340;&#23545;&#40784;&#24615;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#19982;&#22855;&#24322;&#21521;&#37327;&#20197;&#21450;&#22343;&#20540;&#26041;&#21521;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2307.15213</link><description>&lt;p&gt;
PCA&#12289;SVD&#21644;&#25968;&#25454;&#23621;&#20013;&#21270;
&lt;/p&gt;
&lt;p&gt;
PCA, SVD, and Centering of Data. (arXiv:2307.15213v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15213
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35814;&#32454;&#30740;&#31350;&#20102;PCA&#26041;&#27861;&#20013;&#25968;&#25454;&#23621;&#20013;&#21270;&#27493;&#39588;&#30340;&#24433;&#21709;&#65292;&#20998;&#26512;&#20102;&#24102;&#23621;&#20013;&#21270;&#21644;&#19981;&#24102;&#23621;&#20013;&#21270;&#30340;&#20004;&#20010;PCA&#23884;&#20837;&#20043;&#38388;&#30340;&#23545;&#40784;&#24615;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#19982;&#22855;&#24322;&#21521;&#37327;&#20197;&#21450;&#22343;&#20540;&#26041;&#21521;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35814;&#32454;&#30740;&#31350;&#20102;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#65292;&#36825;&#26159;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#24120;&#29992;&#30340;&#38477;&#32500;&#26041;&#27861;&#12290;&#22855;&#24322;&#20540;&#20998;&#35299;&#65288;SVD&#65289;&#36890;&#24120;&#34987;&#29992;&#20316;&#35745;&#31639;PCA&#30340;&#20027;&#35201;&#26041;&#27861;&#65292;&#36825;&#20010;&#36807;&#31243;&#20013;&#24517;&#19981;&#21487;&#23569;&#22320;&#21253;&#21547;&#20102;&#25968;&#25454;&#23621;&#20013;&#21270;&#30340;&#27493;&#39588;&#65292;&#21363;&#20174;&#25968;&#25454;&#38598;&#20013;&#20943;&#21435;&#22343;&#20540;&#20301;&#32622;&#12290;&#22312;&#25105;&#20204;&#30340;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#28145;&#20837;&#25506;&#35752;&#20102;&#36825;&#20010;&#20851;&#38190;&#20294;&#24120;&#24120;&#34987;&#24573;&#35270;&#25110;&#36731;&#35270;&#30340;&#25968;&#25454;&#23621;&#20013;&#21270;&#27493;&#39588;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#31934;&#32454;&#22320;&#30740;&#31350;&#20102;&#22312;&#20160;&#20040;&#26465;&#20214;&#19979;&#65292;&#20174;&#24102;&#26377;&#23621;&#20013;&#21270;&#30340;SVD&#21644;&#19981;&#24102;&#23621;&#20013;&#21270;&#30340;SVD&#24471;&#21040;&#30340;&#20004;&#20010;PCA&#23884;&#20837;&#21487;&#20197;&#30475;&#20316;&#26159;&#23545;&#40784;&#30340;&#12290;&#20316;&#20026;&#36825;&#20010;&#25506;&#32034;&#30340;&#19968;&#37096;&#20998;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#31532;&#19968;&#20010;&#22855;&#24322;&#21521;&#37327;&#21644;&#22343;&#20540;&#26041;&#21521;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#38543;&#21518;&#23558;&#36825;&#19968;&#35266;&#23519;&#32467;&#26524;&#19982;&#20013;&#24515;&#21270;&#21644;&#38750;&#20013;&#24515;&#21270;&#30697;&#38453;&#30340;&#20004;&#20010;SVD&#20043;&#38388;&#30340;&#19968;&#33268;&#24615;&#32852;&#31995;&#36215;&#26469;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#21487;&#33021;&#20135;&#29983;&#30340;&#30456;&#20851;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
The research detailed in this paper scrutinizes Principal Component Analysis (PCA), a seminal method employed in statistics and machine learning for the purpose of reducing data dimensionality. Singular Value Decomposition (SVD) is often employed as the primary means for computing PCA, a process that indispensably includes the step of centering - the subtraction of the mean location from the data set. In our study, we delve into a detailed exploration of the influence of this critical yet often ignored or downplayed data centering step. Our research meticulously investigates the conditions under which two PCA embeddings, one derived from SVD with centering and the other without, can be viewed as aligned. As part of this exploration, we analyze the relationship between the first singular vector and the mean direction, subsequently linking this observation to the congruity between two SVDs of centered and uncentered matrices. Furthermore, we explore the potential implications arising fro
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#28041;&#21450;&#39532;&#23572;&#31185;&#22827;&#22122;&#22768;&#30340;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#20984;&#21644;&#24378;&#20984;&#26368;&#23567;&#21270;&#38382;&#39064;&#30340;&#19968;&#38454;&#26799;&#24230;&#26041;&#27861;&#65292;&#20351;&#29992;&#22522;&#20110;&#22810;&#23618;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#30340;&#38543;&#26426;&#25209;&#22788;&#29702;&#26041;&#26696;&#20197;&#33719;&#24471;&#26368;&#20248;&#32447;&#24615;&#20851;&#31995;&#65292;&#24182;&#28040;&#38500;&#20102;&#20197;&#21069;&#30740;&#31350;&#20013;&#30340;&#38480;&#21046;&#26465;&#20214;&#12290;&#22312;&#39532;&#23572;&#21487;&#22827;&#22122;&#22768;&#19979;&#23545;&#21464;&#20998;&#19981;&#31561;&#24335;&#30340;&#25193;&#23637;&#26159;&#21407;&#21019;&#24615;&#30340;&#12290;</title><link>http://arxiv.org/abs/2305.15938</link><description>&lt;p&gt;
&#20855;&#26377;&#39532;&#23572;&#21487;&#22827;&#22122;&#22768;&#30340;&#19968;&#38454;&#26041;&#27861;&#65306;&#20174;&#21152;&#36895;&#21040;&#21464;&#20998;&#19981;&#31561;&#24335;
&lt;/p&gt;
&lt;p&gt;
First Order Methods with Markovian Noise: from Acceleration to Variational Inequalities. (arXiv:2305.15938v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15938
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#28041;&#21450;&#39532;&#23572;&#31185;&#22827;&#22122;&#22768;&#30340;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#20984;&#21644;&#24378;&#20984;&#26368;&#23567;&#21270;&#38382;&#39064;&#30340;&#19968;&#38454;&#26799;&#24230;&#26041;&#27861;&#65292;&#20351;&#29992;&#22522;&#20110;&#22810;&#23618;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#30340;&#38543;&#26426;&#25209;&#22788;&#29702;&#26041;&#26696;&#20197;&#33719;&#24471;&#26368;&#20248;&#32447;&#24615;&#20851;&#31995;&#65292;&#24182;&#28040;&#38500;&#20102;&#20197;&#21069;&#30740;&#31350;&#20013;&#30340;&#38480;&#21046;&#26465;&#20214;&#12290;&#22312;&#39532;&#23572;&#21487;&#22827;&#22122;&#22768;&#19979;&#23545;&#21464;&#20998;&#19981;&#31561;&#24335;&#30340;&#25193;&#23637;&#26159;&#21407;&#21019;&#24615;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#28041;&#21450;&#39532;&#23572;&#21487;&#22827;&#22122;&#22768;&#30340;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26041;&#27861;&#26469;&#29702;&#35770;&#20998;&#26512;&#19968;&#38454;&#26799;&#24230;&#26041;&#27861;&#29992;&#20110;&#35299;&#20915;&#38543;&#26426;&#20248;&#21270;&#21644;&#21464;&#20998;&#19981;&#31561;&#24335;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28085;&#30422;&#20102;&#38750;&#20984;&#21644;&#24378;&#20984;&#26368;&#23567;&#21270;&#38382;&#39064;&#30340;&#24773;&#20917;&#12290;&#20026;&#20102;&#23454;&#29616;&#19968;&#20010;&#20381;&#36182;&#20110;&#24213;&#23618;&#22122;&#22768;&#24207;&#21015;&#28151;&#21512;&#26102;&#38388;&#30340;&#26368;&#20248;(&#32447;&#24615;)&#20851;&#31995;&#65292;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#22810;&#23618;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#30340;&#38543;&#26426;&#25209;&#22788;&#29702;&#26041;&#26696;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#25216;&#26415;&#20801;&#35768;&#25105;&#20204;&#28040;&#38500;&#20197;&#21069;&#20851;&#20110;&#39532;&#23572;&#21487;&#22827;&#22122;&#22768;&#30340;&#30740;&#31350;&#20013;&#30340;&#38480;&#21046;&#26465;&#20214;&#65292;&#20363;&#22914;&#38656;&#35201;&#26377;&#30028;&#22495;&#21644;&#22343;&#21248;&#26377;&#30028;&#38543;&#26426;&#26799;&#24230;&#12290;&#25105;&#20204;&#22312;&#39532;&#23572;&#21487;&#22827;&#22122;&#22768;&#19979;&#23545;&#21464;&#20998;&#19981;&#31561;&#24335;&#30340;&#25193;&#23637;&#26159;&#21407;&#21019;&#24615;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#21305;&#37197;&#24378;&#20984;&#20248;&#21270;&#38382;&#39064;&#30340;&#29702;&#35770;&#26368;&#20248;&#35299;&#30340;&#19979;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper delves into stochastic optimization problems that involve Markovian noise. We present a unified approach for the theoretical analysis of first-order gradient methods for stochastic optimization and variational inequalities. Our approach covers scenarios for both non-convex and strongly convex minimization problems. To achieve an optimal (linear) dependence on the mixing time of the underlying noise sequence, we use the randomized batching scheme, which is based on the multilevel Monte Carlo method. Moreover, our technique allows us to eliminate the limiting assumptions of previous research on Markov noise, such as the need for a bounded domain and uniformly bounded stochastic gradients. Our extension to variational inequalities under Markovian noise is original. Additionally, we provide lower bounds that match the oracle complexity of our method in the case of strongly convex optimization problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#26694;&#26550;&#65292;&#21487;&#20197;&#22788;&#29702;&#20915;&#31574;&#21382;&#21490;&#30340;&#38271;&#26399;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#20171;&#32461;&#20102;&#29992;&#20110;&#37327;&#21270;&#20381;&#36182;&#31243;&#24230;&#30340;$p$-&#26377;&#25928;&#20869;&#23384;&#23481;&#37327;&#30340;&#27010;&#24565;&#12290;</title><link>http://arxiv.org/abs/2210.09903</link><description>&lt;p&gt;
&#20855;&#26377;&#26080;&#38480;&#21046;&#20869;&#23384;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Online Convex Optimization with Unbounded Memory. (arXiv:2210.09903v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.09903
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#26694;&#26550;&#65292;&#21487;&#20197;&#22788;&#29702;&#20915;&#31574;&#21382;&#21490;&#30340;&#38271;&#26399;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#20171;&#32461;&#20102;&#29992;&#20110;&#37327;&#21270;&#20381;&#36182;&#31243;&#24230;&#30340;$p$-&#26377;&#25928;&#20869;&#23384;&#23481;&#37327;&#30340;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#20984;&#20248;&#21270;&#65288;OCO&#65289;&#26159;&#22312;&#32447;&#23398;&#20064;&#20013;&#24191;&#27867;&#20351;&#29992;&#30340;&#26694;&#26550;&#12290;&#28982;&#32780;&#65292;&#22312;&#24456;&#22810;&#24212;&#29992;&#20013;&#65292;&#23398;&#20064;&#32773;&#30340;&#25439;&#22833;&#19981;&#20165;&#21462;&#20915;&#20110;&#24403;&#21069;&#30340;&#20915;&#31574;&#65292;&#36824;&#21462;&#20915;&#20110;&#30452;&#21040;&#37027;&#20010;&#26102;&#38388;&#28857;&#30340;&#25152;&#26377;&#20915;&#31574;&#21382;&#21490;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;OCO&#30340;&#25193;&#23637;&#26694;&#26550;&#65292;&#8220;&#20855;&#26377;&#26080;&#38480;&#21046;&#20869;&#23384;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#8221;&#65292;&#26469;&#25429;&#25417;&#23545;&#36807;&#21435;&#20915;&#31574;&#30340;&#38271;&#26399;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#20171;&#32461;&#20102;$p$-&#26377;&#25928;&#20869;&#23384;&#23481;&#37327;&#30340;&#27010;&#24565;&#65292;$H_p$&#65292;&#23427;&#37327;&#21270;&#20102;$p$&#38454;&#24433;&#21709;&#30340;&#26368;&#22823;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online convex optimization (OCO) is a widely used framework in online learning. In each round, the learner chooses a decision in a convex set and an adversary chooses a convex loss function, and then the learner suffers the loss associated with their current decision. However, in many applications the learner's loss depends not only on the current decision but on the entire history of decisions until that point. The OCO framework and its existing generalizations do not capture this, and they can only be applied to many settings of interest after a long series of approximation arguments. They also leave open the question of whether the dependence on memory is tight because there are no non-trivial lower bounds. In this work we introduce a generalization of the OCO framework, ``Online Convex Optimization with Unbounded Memory'', that captures long-term dependence on past decisions. We introduce the notion of $p$-effective memory capacity, $H_p$, that quantifies the maximum influence of p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#21464;&#37327;&#25968;&#37327;&#36828;&#22823;&#20110;&#26679;&#26412;&#22823;&#23567;&#30340;&#24773;&#20917;&#19979;&#65292;&#20934;&#30830;&#22320;&#20272;&#35745;&#22823;&#35268;&#27169;&#22240;&#26524;&#22810;&#26641;&#32467;&#26500;&#65292;&#32780;&#20960;&#20046;&#19981;&#38656;&#35201;&#20219;&#20309;&#20998;&#24067;&#25110;&#24314;&#27169;&#30340;&#20551;&#35774;&#12290;</title><link>http://arxiv.org/abs/2209.07028</link><description>&lt;p&gt;
&#20174;&#23567;&#26679;&#26412;&#20013;&#20272;&#35745;&#22823;&#30340;&#22240;&#26524;&#22810;&#26641;
&lt;/p&gt;
&lt;p&gt;
Estimating large causal polytrees from small samples. (arXiv:2209.07028v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.07028
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#21464;&#37327;&#25968;&#37327;&#36828;&#22823;&#20110;&#26679;&#26412;&#22823;&#23567;&#30340;&#24773;&#20917;&#19979;&#65292;&#20934;&#30830;&#22320;&#20272;&#35745;&#22823;&#35268;&#27169;&#22240;&#26524;&#22810;&#26641;&#32467;&#26500;&#65292;&#32780;&#20960;&#20046;&#19981;&#38656;&#35201;&#20219;&#20309;&#20998;&#24067;&#25110;&#24314;&#27169;&#30340;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20174;&#30456;&#23545;&#36739;&#23567;&#30340;&#29420;&#31435;&#21516;&#20998;&#24067;&#26679;&#26412;&#20013;&#20272;&#35745;&#22823;&#30340;&#22240;&#26524;&#22810;&#26641;&#30340;&#38382;&#39064;&#12290;&#36825;&#26159;&#22312;&#21464;&#37327;&#25968;&#37327;&#19982;&#26679;&#26412;&#22823;&#23567;&#30456;&#27604;&#38750;&#24120;&#22823;&#30340;&#24773;&#20917;&#19979;&#30830;&#23450;&#22240;&#26524;&#32467;&#26500;&#30340;&#38382;&#39064;&#65292;&#20363;&#22914;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20197;&#39640;&#20934;&#30830;&#24230;&#24674;&#22797;&#26641;&#24418;&#32467;&#26500;&#12290;&#35813;&#31639;&#27861;&#38500;&#20102;&#19968;&#20123;&#28201;&#21644;&#30340;&#38750;&#36864;&#21270;&#26465;&#20214;&#22806;&#65292;&#22522;&#26412;&#19981;&#38656;&#35201;&#20998;&#24067;&#25110;&#24314;&#27169;&#30340;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of estimating a large causal polytree from a relatively small i.i.d. sample. This is motivated by the problem of determining causal structure when the number of variables is very large compared to the sample size, such as in gene regulatory networks. We give an algorithm that recovers the tree with high accuracy in such settings. The algorithm works under essentially no distributional or modeling assumptions other than some mild non-degeneracy conditions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20195;&#29702;&#21464;&#37327;&#24754;&#35266;&#31574;&#30053;&#20248;&#21270; (P3O) &#31639;&#27861;&#65292;&#23427;&#36890;&#36807;&#36817;&#31471;&#22240;&#26524;&#25512;&#26029;&#26500;&#24314;&#24754;&#35266;&#32622;&#20449;&#21306;&#38388;&#32806;&#21512;&#24207;&#21015;&#35299;&#20915;&#20102;&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#28151;&#28102;&#20559;&#24046;&#21644;&#26368;&#20248;&#31574;&#30053;&#19982;&#34892;&#20026;&#31574;&#30053;&#20043;&#38388;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2205.13589</link><description>&lt;p&gt;
&#38754;&#23545;&#28151;&#28102;&#22240;&#32032;&#30340;&#24754;&#35266;&#24773;&#32490;&#65306;&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#35777;&#26126;&#26377;&#25928;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Pessimism in the Face of Confounders: Provably Efficient Offline Reinforcement Learning in Partially Observable Markov Decision Processes. (arXiv:2205.13589v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.13589
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20195;&#29702;&#21464;&#37327;&#24754;&#35266;&#31574;&#30053;&#20248;&#21270; (P3O) &#31639;&#27861;&#65292;&#23427;&#36890;&#36807;&#36817;&#31471;&#22240;&#26524;&#25512;&#26029;&#26500;&#24314;&#24754;&#35266;&#32622;&#20449;&#21306;&#38388;&#32806;&#21512;&#24207;&#21015;&#35299;&#20915;&#20102;&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#28151;&#28102;&#20559;&#24046;&#21644;&#26368;&#20248;&#31574;&#30053;&#19982;&#34892;&#20026;&#31574;&#30053;&#20043;&#38388;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#37096;&#20998;&#21487;&#35266;&#27979;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#26088;&#22312;&#20174;&#30001;&#34892;&#20026;&#31574;&#30053;&#25910;&#38598;&#30340;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#26368;&#20248;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#21487;&#33021;&#21462;&#20915;&#20110;&#28508;&#22312;&#29366;&#24577;&#12290;&#36825;&#26679;&#30340;&#25968;&#25454;&#38598;&#22312;&#28151;&#28102;&#24847;&#20041;&#19978;&#21516;&#26102;&#24433;&#21709;&#34892;&#21160;&#21644;&#35266;&#27979;&#20540;&#65292;&#36825;&#23545;&#20110;&#29616;&#26377;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#26469;&#35828;&#26159;&#31105;&#27490;&#30340;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36890;&#36807;&#36817;&#31471;&#22240;&#26524;&#25512;&#26029;&#26500;&#24314;&#30340;&#24754;&#35266;&#32622;&#20449;&#21306;&#38388;&#32806;&#21512;&#24207;&#21015;&#30340;&#20195;&#29702;&#21464;&#37327;&#24754;&#35266;&#31574;&#30053;&#20248;&#21270;&#65288;P3O&#65289;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#24191;&#20041;&#20989;&#25968;&#36924;&#36817;&#30340;&#19978;&#19979;&#25991;&#20013;&#35299;&#20915;&#20102;&#28151;&#28102;&#20559;&#24046;&#21644;&#26368;&#20248;&#31574;&#30053;&#19982;&#34892;&#20026;&#31574;&#30053;&#20043;&#38388;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#28151;&#28102;&#25968;&#25454;&#38598;&#30340;&#37096;&#20998;&#35206;&#30422;&#20551;&#35774;&#19979;&#65292;P3O&#21487;&#20197;&#23454;&#29616;n^{-1/2}&#30340;&#25910;&#25947;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study offline reinforcement learning (RL) in partially observable Markov decision processes. In particular, we aim to learn an optimal policy from a dataset collected by a behavior policy which possibly depends on the latent state. Such a dataset is confounded in the sense that the latent state simultaneously affects the action and the observation, which is prohibitive for existing offline RL algorithms. To this end, we propose the \underline{P}roxy variable \underline{P}essimistic \underline{P}olicy \underline{O}ptimization (\texttt{P3O}) algorithm, which addresses the confounding bias and the distributional shift between the optimal and behavior policies in the context of general function approximation. At the core of \texttt{P3O} is a coupled sequence of pessimistic confidence regions constructed via proximal causal inference, which is formulated as minimax estimation. Under a partial coverage assumption on the confounded dataset, we prove that \texttt{P3O} achieves a $n^{-1/2}$-
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22810;&#20219;&#21153;&#23398;&#20064;&#20197;&#21450;Bandits&#26041;&#27861;&#30340;&#20581;&#22766;&#32479;&#35745;&#23398;&#23454;&#29616;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20004;&#38454;&#27573;&#22810;&#20219;&#21153;&#23398;&#20064;&#20272;&#35745;&#22120;&#65292;&#35813;&#20272;&#35745;&#22120;&#20197;&#19968;&#31181;&#26679;&#26412;&#39640;&#25928;&#30340;&#26041;&#24335;&#21033;&#29992;&#20849;&#20139;&#20840;&#23616;&#21442;&#25968;&#21644;&#31232;&#30095;&#23454;&#20363;&#29305;&#23450;&#26415;&#35821;&#30340;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2112.14233</link><description>&lt;p&gt;
&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;Bandits&#36890;&#36807;&#20581;&#22766;&#32479;&#35745;&#23398;
&lt;/p&gt;
&lt;p&gt;
Multitask Learning and Bandits via Robust Statistics. (arXiv:2112.14233v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.14233
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22810;&#20219;&#21153;&#23398;&#20064;&#20197;&#21450;Bandits&#26041;&#27861;&#30340;&#20581;&#22766;&#32479;&#35745;&#23398;&#23454;&#29616;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20004;&#38454;&#27573;&#22810;&#20219;&#21153;&#23398;&#20064;&#20272;&#35745;&#22120;&#65292;&#35813;&#20272;&#35745;&#22120;&#20197;&#19968;&#31181;&#26679;&#26412;&#39640;&#25928;&#30340;&#26041;&#24335;&#21033;&#29992;&#20849;&#20139;&#20840;&#23616;&#21442;&#25968;&#21644;&#31232;&#30095;&#23454;&#20363;&#29305;&#23450;&#26415;&#35821;&#30340;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20915;&#31574;&#32773;&#32463;&#24120;&#21516;&#26102;&#38754;&#23545;&#35768;&#22810;&#30456;&#20851;&#20294;&#24322;&#36136;&#30340;&#23398;&#20064;&#38382;&#39064;&#12290;&#22312;&#27492;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#33258;&#28982;&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;&#27599;&#20010;&#23398;&#20064;&#23454;&#20363;&#20013;&#30340;&#26410;&#30693;&#21442;&#25968;&#21487;&#20197;&#20998;&#35299;&#20026;&#20849;&#20139;&#20840;&#23616;&#21442;&#25968;&#21152;&#19978;&#31232;&#30095;&#30340;&#23454;&#20363;&#29305;&#23450;&#26415;&#35821;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20004;&#38454;&#27573;&#22810;&#20219;&#21153;&#23398;&#20064;&#20272;&#35745;&#22120;&#65292;&#20197;&#19968;&#31181;&#26679;&#26412;&#39640;&#25928;&#30340;&#26041;&#24335;&#21033;&#29992;&#36825;&#31181;&#32467;&#26500;&#65292;&#20351;&#29992;&#20581;&#22766;&#32479;&#35745;&#23398;&#65288;&#22312;&#30456;&#20284;&#23454;&#20363;&#19978;&#23398;&#20064;&#65289;&#21644;LASSO&#22238;&#24402;&#65288;&#21435;&#20559;&#24046;&#32467;&#26524;&#65289;&#30340;&#29420;&#29305;&#32452;&#21512;&#12290;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#25552;&#20379;&#20102;&#25913;&#36827;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Decision-makers often simultaneously face many related but heterogeneous learning problems. For instance, a large retailer may wish to learn product demand at different stores to solve pricing or inventory problems, making it desirable to learn jointly for stores serving similar customers; alternatively, a hospital network may wish to learn patient risk at different providers to allocate personalized interventions, making it desirable to learn jointly for hospitals serving similar patient populations. Motivated by real datasets, we study a natural setting where the unknown parameter in each learning instance can be decomposed into a shared global parameter plus a sparse instance-specific term. We propose a novel two-stage multitask learning estimator that exploits this structure in a sample-efficient way, using a unique combination of robust statistics (to learn across similar instances) and LASSO regression (to debias the results). Our estimator yields improved sample complexity bound
&lt;/p&gt;</description></item></channel></rss>