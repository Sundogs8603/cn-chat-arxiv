<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36923;&#36753;&#22686;&#24378;&#30340;&#22522;&#30784;&#27169;&#22411;&#65288;LEFT&#65289;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#19968;&#20010;&#21487;&#24494;&#20998;&#12289;&#19982;&#39046;&#22495;&#26080;&#20851;&#30340;&#19968;&#38454;&#36923;&#36753;&#31243;&#24207;&#25191;&#34892;&#22120;&#65292;&#22312;&#19981;&#21516;&#39046;&#22495;&#20013;&#23545;&#27010;&#24565;&#36827;&#34892;&#36171;&#26435;&#21644;&#25512;&#29702;&#12290;</title><link>http://arxiv.org/abs/2310.16035</link><description>&lt;p&gt;
&#12298;&#21097;&#19979;&#20160;&#20040;&#65311;&#36923;&#36753;&#22686;&#24378;&#30340;&#22522;&#30784;&#27169;&#22411;&#29992;&#20110;&#27010;&#24565;&#36171;&#26435;&#12299;
&lt;/p&gt;
&lt;p&gt;
What's Left? Concept Grounding with Logic-Enhanced Foundation Models. (arXiv:2310.16035v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16035
&lt;/p&gt;
&lt;p&gt;
&#36923;&#36753;&#22686;&#24378;&#30340;&#22522;&#30784;&#27169;&#22411;&#65288;LEFT&#65289;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#19968;&#20010;&#21487;&#24494;&#20998;&#12289;&#19982;&#39046;&#22495;&#26080;&#20851;&#30340;&#19968;&#38454;&#36923;&#36753;&#31243;&#24207;&#25191;&#34892;&#22120;&#65292;&#22312;&#19981;&#21516;&#39046;&#22495;&#20013;&#23545;&#27010;&#24565;&#36827;&#34892;&#36171;&#26435;&#21644;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#65292;&#22914;VisProg&#21644;ViperGPT&#65292;&#24039;&#22937;&#22320;&#32467;&#21512;&#20102;&#22522;&#30784;&#27169;&#22411;&#19982;&#35270;&#35273;&#25512;&#29702;-&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#29983;&#25104;&#21487;&#20197;&#30001;&#39044;&#35757;&#32451;&#30340;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#25191;&#34892;&#30340;&#31243;&#24207;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#21482;&#22312;&#26377;&#38480;&#30340;&#39046;&#22495;&#20013;&#25805;&#20316;&#65292;&#27604;&#22914;2D&#22270;&#20687;&#65292;&#27809;&#26377;&#20805;&#20998;&#21033;&#29992;&#35821;&#35328;&#30340;&#27010;&#25324;&#24615;&#65306;&#25277;&#35937;&#27010;&#24565;&#22914;&#8220;&#24038;&#8221;&#20063;&#21487;&#20197;&#36890;&#36807;3D&#12289;&#26102;&#38388;&#21644;&#21160;&#20316;&#25968;&#25454;&#36827;&#34892;&#36171;&#26435;&#65292;&#20363;&#22914;&#21521;&#24038;&#31227;&#21160;&#12290;&#36825;&#31181;&#26377;&#38480;&#30340;&#27010;&#25324;&#24615;&#28304;&#20110;&#36825;&#20123;&#20165;&#25512;&#29702;&#30340;&#26041;&#27861;&#26080;&#27861;&#22312;&#26032;&#39046;&#22495;&#20013;&#23398;&#20064;&#25110;&#35843;&#25972;&#39044;&#35757;&#32451;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#36923;&#36753;&#22686;&#24378;&#30340;&#22522;&#30784;&#27169;&#22411;&#65288;LEFT&#65289;&#65292;&#23427;&#26159;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#19968;&#20010;&#21487;&#24494;&#20998;&#12289;&#19982;&#39046;&#22495;&#26080;&#20851;&#30340;&#19968;&#38454;&#36923;&#36753;&#31243;&#24207;&#25191;&#34892;&#22120;&#65292;&#23398;&#20064;&#22312;&#19981;&#21516;&#39046;&#22495;&#20013;&#23545;&#27010;&#24565;&#36827;&#34892;&#36171;&#26435;&#21644;&#25512;&#29702;&#12290;LEFT&#20855;&#26377;&#19968;&#20010;LLM&#35299;&#37322;&#22120;&#65292;&#36755;&#20986;&#29992;&#19968;&#31181;&#36890;&#29992;&#30340;&#22522;&#20110;&#36923;&#36753;&#25512;&#29702;&#30340;&#25512;&#29702;&#35821;&#35328;&#34920;&#31034;&#30340;&#31243;&#24207;&#65292;&#35813;&#31243;&#24207;&#22312;&#25152;&#26377;&#39046;&#22495;&#21644;&#20219;&#21153;&#20043;&#38388;&#20849;&#20139;&#12290;LEFT&#30340;&#25512;&#29702;&#22120;&#28982;&#21518;&#25191;&#34892;&#35813;&#31243;&#24207;&#65292;
&lt;/p&gt;
&lt;p&gt;
Recent works such as VisProg and ViperGPT have smartly composed foundation models for visual reasoning-using large language models (LLMs) to produce programs that can be executed by pre-trained vision-language models. However, they operate in limited domains, such as 2D images, not fully exploiting the generalization of language: abstract concepts like "left" can also be grounded in 3D, temporal, and action data, as in moving to your left. This limited generalization stems from these inference-only methods' inability to learn or adapt pre-trained models to a new domain. We propose the Logic-Enhanced Foundation Model (LEFT), a unified framework that learns to ground and reason with concepts across domains with a differentiable, domain-independent, first-order logic-based program executor. LEFT has an LLM interpreter that outputs a program represented in a general, logic-based reasoning language, which is shared across all domains and tasks. LEFT's executor then executes the program with
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;RASP&#32534;&#31243;&#35821;&#35328;&#21644;RASP&#27867;&#21270;&#29468;&#24819;&#65292;&#23545;Transformer&#27169;&#22411;&#22312;&#31639;&#27861;&#20219;&#21153;&#30340;&#38271;&#24230;&#27867;&#21270;&#33021;&#21147;&#36827;&#34892;&#30740;&#31350;&#65292;&#24182;&#21487;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.16028</link><description>&lt;p&gt;
Transformers&#21487;&#20197;&#23398;&#20064;&#21738;&#20123;&#31639;&#27861;&#65311;&#23545;&#38271;&#24230;&#27867;&#21270;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
What Algorithms can Transformers Learn? A Study in Length Generalization. (arXiv:2310.16028v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16028
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;RASP&#32534;&#31243;&#35821;&#35328;&#21644;RASP&#27867;&#21270;&#29468;&#24819;&#65292;&#23545;Transformer&#27169;&#22411;&#22312;&#31639;&#27861;&#20219;&#21153;&#30340;&#38271;&#24230;&#27867;&#21270;&#33021;&#21147;&#36827;&#34892;&#30740;&#31350;&#65292;&#24182;&#21487;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23637;&#29616;&#20986;&#20196;&#20154;&#24778;&#35766;&#30340;&#32039;&#24613;&#27867;&#21270;&#29305;&#24615;&#65292;&#20294;&#22312;&#35768;&#22810;&#31616;&#21333;&#30340;&#25512;&#29702;&#20219;&#21153;&#19978;&#22914;&#31639;&#26415;&#21644;&#22855;&#20598;&#21028;&#26029;&#19978;&#21364;&#24456;&#38590;&#12290;&#36825;&#24341;&#21457;&#20102;&#19968;&#20010;&#38382;&#39064;&#65292;&#21363;Transformer&#27169;&#22411;&#26159;&#21542;&#21487;&#20197;&#23398;&#20064;&#35299;&#20915;&#20219;&#21153;&#30340;&#30495;&#27491;&#31639;&#27861;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;Transformer&#27169;&#22411;&#22312;&#31639;&#27861;&#20219;&#21153;&#30340;&#38271;&#24230;&#27867;&#21270;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#26469;&#29702;&#35299;Transformer&#22312;&#32473;&#23450;&#20219;&#21153;&#19978;&#22914;&#20309;&#23637;&#29616;&#20986;&#24378;&#22823;&#30340;&#38271;&#24230;&#27867;&#21270;&#33021;&#21147;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#21033;&#29992;RASP&#65288;Weiss&#31561;&#20154;&#65292;2021&#65289;- &#29992;&#20110;Transformer&#30340;&#35745;&#31639;&#27169;&#22411;&#30340;&#32534;&#31243;&#35821;&#35328;&#65292;&#24182;&#24341;&#20837;&#20102;RASP&#27867;&#21270;&#29468;&#24819;&#65306;&#22914;&#26524;&#20219;&#21153;&#21487;&#20197;&#30001;&#36866;&#29992;&#20110;&#25152;&#26377;&#36755;&#20837;&#38271;&#24230;&#30340;&#30701;RASP&#31243;&#24207;&#35299;&#20915;&#65292;&#37027;&#20040;Transformer&#20542;&#21521;&#20110;&#22312;&#35813;&#20219;&#21153;&#19978;&#36827;&#34892;&#38271;&#24230;&#27867;&#21270;&#12290;&#36825;&#20010;&#31616;&#21333;&#30340;&#29468;&#24819;&#26174;&#33879;&#25429;&#25417;&#20102;&#22823;&#22810;&#25968;&#24050;&#30693;&#30340;&#31639;&#27861;&#20219;&#21153;&#30340;&#38271;&#24230;&#27867;&#21270;&#23454;&#20363;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21033;&#29992;&#25105;&#20204;&#30340;&#27934;&#23519;&#21147;&#65292;&#22823;&#24133;&#25552;&#39640;&#20102;&#38271;&#24230;&#27867;&#21270;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models exhibit surprising emergent generalization properties, yet also struggle on many simple reasoning tasks such as arithmetic and parity. This raises the question of if and when Transformer models can learn the true algorithm for solving a task. We study the scope of Transformers' abilities in the specific setting of length generalization on algorithmic tasks. Here, we propose a unifying framework to understand when and how Transformers can exhibit strong length generalization on a given task. Specifically, we leverage RASP (Weiss et al., 2021) -- a programming language designed for the computational model of a Transformer -- and introduce the RASP-Generalization Conjecture: Transformers tend to length generalize on a task if the task can be solved by a short RASP program which works for all input lengths. This simple conjecture remarkably captures most known instances of length generalization on algorithmic tasks. Moreover, we leverage our insights to drastically im
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#35777;&#26126;signSGD&#31639;&#27861;&#22312;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#20013;&#30340;&#38543;&#26426;&#37325;&#25490;&#65288;SignRR&#65289;&#30340;&#25910;&#25947;&#24615;&#65292;&#24357;&#34917;&#20102;&#29616;&#26377;&#20998;&#26512;&#20013;&#30340;&#32570;&#38519;&#65292;&#25552;&#20986;&#20102;SignRVR&#21644;SignRVM&#31639;&#27861;&#65292;&#24182;&#19988;&#37117;&#20197;&#36739;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2310.15976</link><description>&lt;p&gt;
&#38750;&#20984;&#20248;&#21270;&#30340;&#22522;&#20110;&#31526;&#21495;&#38543;&#26426;&#37325;&#25490;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Convergence of Sign-based Random Reshuffling Algorithms for Nonconvex Optimization. (arXiv:2310.15976v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15976
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#35777;&#26126;signSGD&#31639;&#27861;&#22312;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#20013;&#30340;&#38543;&#26426;&#37325;&#25490;&#65288;SignRR&#65289;&#30340;&#25910;&#25947;&#24615;&#65292;&#24357;&#34917;&#20102;&#29616;&#26377;&#20998;&#26512;&#20013;&#30340;&#32570;&#38519;&#65292;&#25552;&#20986;&#20102;SignRVR&#21644;SignRVM&#31639;&#27861;&#65292;&#24182;&#19988;&#37117;&#20197;&#36739;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20854;&#36890;&#20449;&#25928;&#29575;&#36739;&#39640;&#65292;signSGD&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#24456;&#21463;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#23545;signSGD&#30340;&#20998;&#26512;&#22522;&#20110;&#20551;&#35774;&#27599;&#27425;&#36845;&#20195;&#20013;&#30340;&#25968;&#25454;&#37117;&#26159;&#26377;&#25918;&#22238;&#37319;&#26679;&#30340;&#65292;&#36825;&#19982;&#23454;&#38469;&#23454;&#29616;&#20013;&#25968;&#25454;&#30340;&#38543;&#26426;&#37325;&#25490;&#21644;&#39034;&#24207;&#39304;&#36865;&#36827;&#31639;&#27861;&#30340;&#24773;&#20917;&#30456;&#30683;&#30462;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;signSGD&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#38543;&#26426;&#37325;&#25490;&#65288;SignRR&#65289;&#30340;&#39318;&#20010;&#25910;&#25947;&#32467;&#26524;&#12290;&#32473;&#23450;&#25968;&#25454;&#38598;&#22823;&#23567;$n$&#65292;&#25968;&#25454;&#36845;&#20195;&#27425;&#25968;$T$&#65292;&#21644;&#38543;&#26426;&#26799;&#24230;&#30340;&#26041;&#24046;&#38480;&#21046;$\sigma^2$&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;SignRR&#30340;&#25910;&#25947;&#36895;&#24230;&#19982;signSGD&#30456;&#21516;&#65292;&#20026;$O(\log(nT)/\sqrt{nT} + \|\sigma\|_1)$ \citep{bernstein2018signsgd}&#12290;&#25509;&#30528;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102; SignRVR &#21644; SignRVM&#65292;&#20998;&#21035;&#21033;&#29992;&#20102;&#26041;&#24046;&#32422;&#20943;&#26799;&#24230;&#21644;&#21160;&#37327;&#26356;&#26032;&#65292;&#37117;&#20197;$O(\log(nT)/\sqrt{nT})$&#30340;&#36895;&#24230;&#25910;&#25947;&#12290;&#19982;signSGD&#30340;&#20998;&#26512;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#19981;&#38656;&#35201;&#27599;&#27425;&#36845;&#20195;&#20013;&#26497;&#22823;&#30340;&#25209;&#27425;&#22823;&#23567;&#19982;&#21516;&#31561;&#25968;&#37327;&#30340;&#26799;&#24230;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
signSGD is popular in nonconvex optimization due to its communication efficiency. Yet, existing analyses of signSGD rely on assuming that data are sampled with replacement in each iteration, contradicting the practical implementation where data are randomly reshuffled and sequentially fed into the algorithm. We bridge this gap by proving the first convergence result of signSGD with random reshuffling (SignRR) for nonconvex optimization. Given the dataset size $n$, the number of epochs of data passes $T$, and the variance bound of a stochastic gradient $\sigma^2$, we show that SignRR has the same convergence rate $O(\log(nT)/\sqrt{nT} + \|\sigma\|_1)$ as signSGD \citep{bernstein2018signsgd}. We then present SignRVR and SignRVM, which leverage variance-reduced gradients and momentum updates respectively, both converging at $O(\log(nT)/\sqrt{nT})$. In contrast with the analysis of signSGD, our results do not require an extremely large batch size in each iteration to be of the same order a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22686;&#37327;&#26368;&#23567;&#21270;&#39118;&#38505;&#20998;&#31867;&#22120;&#65288;IMRCs&#65289;&#65292;&#33021;&#22815;&#26377;&#25928;&#21033;&#29992;&#21069;&#21521;&#21644;&#21518;&#21521;&#23398;&#20064;&#65292;&#24182;&#32771;&#34385;&#20219;&#21153;&#30340;&#28436;&#21464;&#12290;&#23454;&#39564;&#35780;&#20272;&#34920;&#26126;&#65292;IMRCs&#21487;&#20197;&#25552;&#39640;&#20998;&#31867;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.15974</link><description>&lt;p&gt;
&#26368;&#23567;&#21270;&#27491;&#21453;&#21521;&#23398;&#20064;&#30340;&#20219;&#21153;&#19982;&#24615;&#33021;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Minimax Forward and Backward Learning of Evolving Tasks with Performance Guarantees. (arXiv:2310.15974v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15974
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22686;&#37327;&#26368;&#23567;&#21270;&#39118;&#38505;&#20998;&#31867;&#22120;&#65288;IMRCs&#65289;&#65292;&#33021;&#22815;&#26377;&#25928;&#21033;&#29992;&#21069;&#21521;&#21644;&#21518;&#21521;&#23398;&#20064;&#65292;&#24182;&#32771;&#34385;&#20219;&#21153;&#30340;&#28436;&#21464;&#12290;&#23454;&#39564;&#35780;&#20272;&#34920;&#26126;&#65292;IMRCs&#21487;&#20197;&#25552;&#39640;&#20998;&#31867;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#38543;&#26102;&#38388;&#25512;&#31227;&#30340;&#20998;&#31867;&#20219;&#21153;&#24207;&#21015;&#65292;&#24448;&#24448;&#23384;&#22312;&#20219;&#21153;&#30340;&#28436;&#21464;&#65292;&#22312;&#36825;&#20010;&#24847;&#20041;&#19978;&#65292;&#36830;&#32493;&#30340;&#20219;&#21153;&#32463;&#24120;&#20855;&#26377;&#26356;&#39640;&#30340;&#30456;&#20284;&#24615;&#12290;&#36890;&#36807;&#21033;&#29992;&#24207;&#21015;&#20013;&#25152;&#26377;&#20219;&#21153;&#30340;&#20449;&#24687;&#65288;&#21069;&#21521;&#21644;&#21518;&#21521;&#23398;&#20064;&#65289;&#65292;&#22686;&#37327;&#23398;&#20064;&#26085;&#30410;&#22686;&#38271;&#30340;&#20219;&#21153;&#24207;&#21015;&#26377;&#26395;&#23454;&#29616;&#21363;&#20351;&#27599;&#20010;&#20219;&#21153;&#21482;&#26377;&#24456;&#23569;&#26679;&#26412;&#20063;&#33021;&#36827;&#34892;&#20934;&#30830;&#20998;&#31867;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#25345;&#32493;&#23398;&#20064;&#21644;&#27010;&#24565;&#28418;&#31227;&#36866;&#24212;&#25216;&#26415;&#35201;&#20040;&#26159;&#38024;&#23545;&#20855;&#26377;&#26102;&#38388;&#26080;&#20851;&#30456;&#20284;&#24615;&#30340;&#20219;&#21153;&#35774;&#35745;&#30340;&#65292;&#35201;&#20040;&#21482;&#38024;&#23545;&#23398;&#20064;&#24207;&#21015;&#20013;&#30340;&#26368;&#21518;&#19968;&#20010;&#20219;&#21153;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26377;&#25928;&#21033;&#29992;&#21069;&#21521;&#21644;&#21518;&#21521;&#23398;&#20064;&#24182;&#32771;&#34385;&#20219;&#21153;&#28436;&#21464;&#30340;&#22686;&#37327;&#26368;&#23567;&#21270;&#39118;&#38505;&#20998;&#31867;&#22120;&#65288;IMRCs&#65289;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20174;&#20219;&#21153;&#30340;&#39044;&#26399;&#20108;&#27425;&#21464;&#21270;&#21644;&#20219;&#21153;&#25968;&#37327;&#30340;&#35282;&#24230;&#20998;&#26512;&#20102;&#21069;&#21521;&#21644;&#21518;&#21521;&#23398;&#20064;&#25152;&#25552;&#20379;&#30340;&#24615;&#33021;&#25913;&#36827;&#12290;&#23454;&#39564;&#35780;&#20272;&#34920;&#26126;&#65292;IMRCs&#21487;&#20197;&#23548;&#33268;&#24615;&#33021;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
For a sequence of classification tasks that arrive over time, it is common that tasks are evolving in the sense that consecutive tasks often have a higher similarity. The incremental learning of a growing sequence of tasks holds promise to enable accurate classification even with few samples per task by leveraging information from all the tasks in the sequence (forward and backward learning). However, existing techniques developed for continual learning and concept drift adaptation are either designed for tasks with time-independent similarities or only aim to learn the last task in the sequence. This paper presents incremental minimax risk classifiers (IMRCs) that effectively exploit forward and backward learning and account for evolving tasks. In addition, we analytically characterize the performance improvement provided by forward and backward learning in terms of the tasks' expected quadratic change and the number of tasks. The experimental evaluation shows that IMRCs can result in
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#36890;&#36807;&#23398;&#20064;&#21010;&#20998;&#20107;&#20214;&#26102;&#38388;&#31354;&#38388;&#30340;&#26041;&#27861;&#26469;&#25913;&#21892;&#20107;&#20214;&#26102;&#38388;&#39044;&#27979;&#65292;&#36991;&#20813;&#20102;&#23545;&#20107;&#20214;&#23494;&#24230;&#36827;&#34892;&#24378;&#21442;&#25968;&#20551;&#35774;&#65292;&#33021;&#22815;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#22312;&#21487;&#29992;&#25968;&#25454;&#26377;&#38480;&#30340;&#20020;&#24202;&#29615;&#22659;&#20013;&#12290;&#36890;&#36807;&#22312;&#27169;&#25311;&#25968;&#25454;&#38598;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.15853</link><description>&lt;p&gt;
&#36890;&#36807;&#23398;&#20064;&#21010;&#20998;&#20107;&#20214;&#26102;&#38388;&#31354;&#38388;&#26469;&#25913;&#36827;&#20107;&#20214;&#26102;&#38388;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Improving Event Time Prediction by Learning to Partition the Event Time Space. (arXiv:2310.15853v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15853
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#36890;&#36807;&#23398;&#20064;&#21010;&#20998;&#20107;&#20214;&#26102;&#38388;&#31354;&#38388;&#30340;&#26041;&#27861;&#26469;&#25913;&#21892;&#20107;&#20214;&#26102;&#38388;&#39044;&#27979;&#65292;&#36991;&#20813;&#20102;&#23545;&#20107;&#20214;&#23494;&#24230;&#36827;&#34892;&#24378;&#21442;&#25968;&#20551;&#35774;&#65292;&#33021;&#22815;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#22312;&#21487;&#29992;&#25968;&#25454;&#26377;&#38480;&#30340;&#20020;&#24202;&#29615;&#22659;&#20013;&#12290;&#36890;&#36807;&#22312;&#27169;&#25311;&#25968;&#25454;&#38598;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#21457;&#23637;&#36215;&#26469;&#30340;&#29983;&#23384;&#20998;&#26512;&#26041;&#27861;&#36890;&#36807;&#39044;&#27979;&#22312;&#19968;&#20123;&#39044;&#20808;&#25351;&#23450;&#30340;&#65288;&#31163;&#25955;&#30340;&#65289;&#26102;&#38388;&#38388;&#38548;&#20869;&#20107;&#20214;&#21457;&#29983;&#30340;&#27010;&#29575;&#26469;&#25913;&#36827;&#29616;&#26377;&#26041;&#27861;&#12290;&#36890;&#36807;&#36991;&#20813;&#23545;&#20107;&#20214;&#23494;&#24230;&#26045;&#21152;&#24378;&#28872;&#30340;&#21442;&#25968;&#20551;&#35774;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#25968;&#25454;&#20016;&#23500;&#30340;&#24773;&#20917;&#19979;&#24448;&#24448;&#33021;&#22815;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#22312;&#20020;&#24202;&#29615;&#22659;&#20013;&#65292;&#30001;&#20110;&#21487;&#29992;&#25968;&#25454;&#26377;&#38480;&#65292;&#36890;&#24120;&#26356;&#21916;&#27426;&#23558;&#20107;&#20214;&#26102;&#38388;&#31354;&#38388;&#21010;&#20998;&#20026;&#23569;&#37327;&#36866;&#21512;&#25163;&#22836;&#39044;&#27979;&#20219;&#21153;&#30340;&#26102;&#38388;&#38388;&#38548;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#21010;&#20998;&#23450;&#20041;&#30340;&#20999;&#28857;&#38598;&#21512;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#22312;&#20004;&#20010;&#27169;&#25311;&#25968;&#25454;&#38598;&#20013;&#65292;&#25105;&#20204;&#33021;&#22815;&#24674;&#22797;&#19982;&#22522;&#30784;&#29983;&#25104;&#27169;&#22411;&#30456;&#21305;&#37197;&#30340;&#26102;&#38388;&#38388;&#38548;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#22312;&#19977;&#20010;&#30495;&#23454;&#30340;&#35266;&#23519;&#24615;&#25968;&#25454;&#38598;&#20013;&#23637;&#31034;&#20102;&#25913;&#36827;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#20854;&#20013;&#21253;&#25324;&#19968;&#20010;&#22823;&#22411;&#30340;&#12289;&#26032;&#35843;&#21644;&#30340;&#20013;&#39118;&#39118;&#38505;&#39044;&#27979;&#25968;&#25454;&#38598;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35748;&#20026;&#25105;&#20204;&#30340;&#26041;&#27861;&#26377;&#21161;&#20110;&#20020;&#24202;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently developed survival analysis methods improve upon existing approaches by predicting the probability of event occurrence in each of a number pre-specified (discrete) time intervals. By avoiding placing strong parametric assumptions on the event density, this approach tends to improve prediction performance, particularly when data are plentiful. However, in clinical settings with limited available data, it is often preferable to judiciously partition the event time space into a limited number of intervals well suited to the prediction task at hand. In this work, we develop a method to learn from data a set of cut points defining such a partition. We show that in two simulated datasets, we are able to recover intervals that match the underlying generative model. We then demonstrate improved prediction performance on three real-world observational datasets, including a large, newly harmonized stroke risk prediction dataset. Finally, we argue that our approach facilitates clinical d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#21028;&#21035;&#22120;&#24341;&#23548;&#65292;&#29992;&#20110;&#33258;&#22238;&#24402;&#25193;&#25955;&#27169;&#22411;&#30340;&#35757;&#32451;&#65292;&#36890;&#36807;&#20351;&#29992;&#26368;&#20248;&#21028;&#21035;&#22120;&#26469;&#32416;&#27491;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#31639;&#27861;&#26469;&#24212;&#23545;&#20351;&#29992;&#27425;&#20248;&#21028;&#21035;&#22120;&#30340;&#24773;&#20917;&#12290;&#22312;&#29983;&#25104;&#20998;&#23376;&#22270;&#30340;&#20219;&#21153;&#20013;&#65292;&#21028;&#21035;&#22120;&#24341;&#23548;&#26377;&#21161;&#20110;&#25552;&#39640;&#29983;&#25104;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.15817</link><description>&lt;p&gt;
&#21028;&#21035;&#22120;&#24341;&#23548;&#19979;&#30340;&#33258;&#22238;&#24402;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Discriminator Guidance for Autoregressive Diffusion Models. (arXiv:2310.15817v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15817
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#21028;&#21035;&#22120;&#24341;&#23548;&#65292;&#29992;&#20110;&#33258;&#22238;&#24402;&#25193;&#25955;&#27169;&#22411;&#30340;&#35757;&#32451;&#65292;&#36890;&#36807;&#20351;&#29992;&#26368;&#20248;&#21028;&#21035;&#22120;&#26469;&#32416;&#27491;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#31639;&#27861;&#26469;&#24212;&#23545;&#20351;&#29992;&#27425;&#20248;&#21028;&#21035;&#22120;&#30340;&#24773;&#20917;&#12290;&#22312;&#29983;&#25104;&#20998;&#23376;&#22270;&#30340;&#20219;&#21153;&#20013;&#65292;&#21028;&#21035;&#22120;&#24341;&#23548;&#26377;&#21161;&#20110;&#25552;&#39640;&#29983;&#25104;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#33258;&#22238;&#24402;&#25193;&#25955;&#27169;&#22411;&#20013;&#24341;&#20837;&#20102;&#21028;&#21035;&#22120;&#24341;&#23548;&#12290;&#22312;&#36830;&#32493;&#25193;&#25955;&#27169;&#22411;&#20013;&#65292;&#20351;&#29992;&#21028;&#21035;&#22120;&#24341;&#23548;&#25193;&#25955;&#36807;&#31243;&#30340;&#26041;&#27861;&#24050;&#32463;&#34987;&#20351;&#29992;&#36807;&#65292;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#22312;&#31163;&#25955;&#24773;&#20917;&#19979;&#20351;&#29992;&#21028;&#21035;&#22120;&#21644;&#39044;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35777;&#26126;&#20351;&#29992;&#26368;&#20248;&#21028;&#21035;&#22120;&#23558;&#32416;&#27491;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#24182;&#33021;&#22815;&#20174;&#24213;&#23618;&#25968;&#25454;&#20998;&#24067;&#20013;&#31934;&#30830;&#37319;&#26679;&#12290;&#20854;&#27425;&#65292;&#20026;&#20102;&#24212;&#23545;&#20351;&#29992;&#27425;&#20248;&#21028;&#21035;&#22120;&#30340;&#23454;&#38469;&#24773;&#20917;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#20010;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#29983;&#25104;&#36807;&#31243;&#20013;&#36845;&#20195;&#22320;&#23558;&#21028;&#21035;&#22120;&#30340;&#39044;&#27979;&#32435;&#20837;&#32771;&#34385;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#26041;&#27861;&#24212;&#29992;&#20110;&#29983;&#25104;&#20998;&#23376;&#22270;&#30340;&#20219;&#21153;&#65292;&#24182;&#23637;&#31034;&#20102;&#21028;&#21035;&#22120;&#30456;&#36739;&#20110;&#20165;&#20351;&#29992;&#39044;&#35757;&#32451;&#27169;&#22411;&#26102;&#30340;&#29983;&#25104;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce discriminator guidance in the setting of Autoregressive Diffusion Models. The use of a discriminator to guide a diffusion process has previously been used for continuous diffusion models, and in this work we derive ways of using a discriminator together with a pretrained generative model in the discrete case. First, we show that using an optimal discriminator will correct the pretrained model and enable exact sampling from the underlying data distribution. Second, to account for the realistic scenario of using a sub-optimal discriminator, we derive a sequential Monte Carlo algorithm which iteratively takes the predictions from the discrimiator into account during the generation process. We test these approaches on the task of generating molecular graphs and show how the discriminator improves the generative performance over using only the pretrained model.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#26377;&#25928;&#30340;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;Thompson&#37319;&#26679;&#20174;GP Pareto&#21069;&#27839;&#20013;&#36873;&#25321;&#26032;&#30340;&#20505;&#36873;&#32773;&#65292;&#36991;&#20813;&#20102;&#32321;&#26434;&#30340;&#33719;&#21462;&#20989;&#25968;&#20248;&#21270;&#27493;&#39588;&#12290;</title><link>http://arxiv.org/abs/2310.15788</link><description>&lt;p&gt;
qPOTS: &#39640;&#25928;&#30340;&#25209;&#37327;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
qPOTS: Efficient batch multiobjective Bayesian optimization via Pareto optimal Thompson sampling. (arXiv:2310.15788v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15788
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#26377;&#25928;&#30340;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;Thompson&#37319;&#26679;&#20174;GP Pareto&#21069;&#27839;&#20013;&#36873;&#25321;&#26032;&#30340;&#20505;&#36873;&#32773;&#65292;&#36991;&#20813;&#20102;&#32321;&#26434;&#30340;&#33719;&#21462;&#20989;&#25968;&#20248;&#21270;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#36827;&#21270;&#26041;&#27861;&#22312;&#22810;&#30446;&#26631;&#20248;&#21270;&#20013;&#38750;&#24120;&#26377;&#25928;&#65292;&#20294;&#23545;&#30446;&#26631;&#36827;&#34892;&#22823;&#37327;&#26597;&#35810;&#21487;&#33021;&#19981;&#21033;&#20110;&#30446;&#26631;&#33457;&#36153;&#24456;&#22810;&#25110;&#32773;&#35745;&#31639;&#37327;&#24456;&#22823;&#30340;&#26102;&#20505;&#12290;&#29992;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#26367;&#20195;&#29289;&#21644;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#26469;&#35299;&#20915;&#22810;&#30446;&#26631;&#20248;&#21270;&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;&#26041;&#27861;&#12290;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;(MOBO)&#28041;&#21450;&#26500;&#24314;&#19968;&#20010;&#34987;&#20248;&#21270;&#29992;&#26469;&#33719;&#24471;&#26032;&#35266;&#23519;&#20505;&#36873;&#30340;&#33719;&#21462;&#20989;&#25968;&#12290;&#36825;&#20010;&#8220;&#20869;&#37096;&#8221;&#20248;&#21270;&#21487;&#33021;&#24456;&#22256;&#38590;&#65292;&#22240;&#20026;&#33719;&#21462;&#20989;&#25968;&#26159;&#38750;&#20984;&#30340;&#65292;&#19981;&#21487;&#24494;&#30340;&#21644;/&#25110;&#32773;&#19981;&#20986;&#27874;&#65292;MOBO&#30340;&#25104;&#21151;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20381;&#36182;&#20110;&#36825;&#20010;&#20869;&#37096;&#20248;&#21270;&#12290;&#25105;&#20204;&#25682;&#24323;&#36825;&#20010;&#22256;&#38590;&#30340;&#33719;&#21462;&#20989;&#25968;&#20248;&#21270;&#27493;&#39588;&#65292;&#25552;&#20986;&#19968;&#31181;&#31616;&#21333;&#20294;&#26377;&#25928;&#30340;&#22522;&#20110;Thompson&#37319;&#26679;&#30340;&#26041;&#27861;($q\texttt{POTS}$)&#65292;&#20854;&#20013;&#26032;&#30340;&#20505;&#36873;&#32773;&#26159;&#20174;&#36890;&#36807;&#27714;&#35299;&#19968;&#20010;&#26356;&#20415;&#23452;&#30340;&#22810;&#20010;&#21518;&#39564;&#26679;&#26412;&#36335;&#24452;&#30340;GP Pareto&#21069;&#27839;&#20013;&#36873;&#25321;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Classical evolutionary approaches for multiobjective optimization are quite effective but incur a lot of queries to the objectives; this can be prohibitive when objectives are expensive oracles. A sample-efficient approach to solving multiobjective optimization is via Gaussian process (GP) surrogates and Bayesian optimization (BO). Multiobjective Bayesian optimization (MOBO) involves the construction of an acquisition function which is optimized to acquire new observation candidates. This ``inner'' optimization can be hard due to various reasons: acquisition functions being nonconvex, nondifferentiable and/or unavailable in analytical form; the success of MOBO heavily relies on this inner optimization. We do away with this hard acquisition function optimization step and propose a simple, but effective, Thompson sampling based approach ($q\texttt{POTS}$) where new candidate(s) are chosen from the Pareto frontier of random GP posterior sample paths obtained by solving a much cheaper mult
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#36827;&#34892;&#23567;&#35268;&#27169;&#27010;&#29575;&#20803;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#35825;&#23548;&#36755;&#20837;&#26367;&#25442;&#20026;&#23454;&#38469;&#25968;&#25454;&#65292;&#36890;&#36807;&#35757;&#32451;&#25512;&#29702;&#32593;&#32476;&#26469;&#23454;&#29616;&#23545;&#20219;&#21153;&#29305;&#23450;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;&#20803;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2310.15786</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20998;&#25674;&#25512;&#29702;&#29992;&#20110;&#23567;&#35268;&#27169;&#27010;&#29575;&#20803;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Amortised Inference in Neural Networks for Small-Scale Probabilistic Meta-Learning. (arXiv:2310.15786v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15786
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#36827;&#34892;&#23567;&#35268;&#27169;&#27010;&#29575;&#20803;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#35825;&#23548;&#36755;&#20837;&#26367;&#25442;&#20026;&#23454;&#38469;&#25968;&#25454;&#65292;&#36890;&#36807;&#35757;&#32451;&#25512;&#29702;&#32593;&#32476;&#26469;&#23454;&#29616;&#23545;&#20219;&#21153;&#29305;&#23450;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;&#20803;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20840;&#23616;&#35825;&#23548;&#28857;&#30340;&#21464;&#20998;&#36924;&#36817;&#26159;&#22522;&#20110;&#20351;&#29992;&#19968;&#32452;&#35825;&#23548;&#36755;&#20837;&#26469;&#26500;&#24314;&#19968;&#31995;&#21015;&#26465;&#20214;&#20998;&#24067;&#65292;&#20174;&#32780;&#20934;&#30830;&#22320;&#36924;&#36817;&#30495;&#23454;&#21518;&#39564;&#20998;&#24067;&#30340;&#26465;&#20214;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#27934;&#23519;&#21147;&#26159;&#36825;&#20123;&#35825;&#23548;&#36755;&#20837;&#21487;&#20197;&#34987;&#23454;&#38469;&#25968;&#25454;&#26367;&#20195;&#65292;&#20351;&#24471;&#21464;&#20998;&#20998;&#24067;&#30001;&#27599;&#20010;&#25968;&#25454;&#28857;&#30340;&#19968;&#32452;&#36817;&#20284;&#20284;&#28982;&#32452;&#25104;&#12290;&#36825;&#31181;&#32467;&#26500;&#36866;&#21512;&#20110;&#20998;&#25674;&#25512;&#29702;&#65292;&#20854;&#20013;&#27599;&#20010;&#36817;&#20284;&#20284;&#28982;&#30340;&#21442;&#25968;&#26159;&#36890;&#36807;&#23558;&#27599;&#20010;&#25968;&#25454;&#28857;&#36890;&#36807;&#31216;&#20026;&#25512;&#29702;&#32593;&#32476;&#30340;&#20803;&#27169;&#22411;&#36890;&#36807;&#33719;&#24471;&#30340;&#12290;&#36890;&#36807;&#22312;&#30456;&#20851;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#36825;&#20010;&#25512;&#29702;&#32593;&#32476;&#65292;&#25105;&#20204;&#21487;&#20197;&#20803;&#23398;&#20064;&#20219;&#21153;&#29305;&#23450;BNN&#19978;&#30340;&#36125;&#21494;&#26031;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
The global inducing point variational approximation for BNNs is based on using a set of inducing inputs to construct a series of conditional distributions that accurately approximate the conditionals of the true posterior distribution. Our key insight is that these inducing inputs can be replaced by the actual data, such that the variational distribution consists of a set of approximate likelihoods for each datapoint. This structure lends itself to amortised inference, in which the parameters of each approximate likelihood are obtained by passing each datapoint through a meta-model known as the inference network. By training this inference network across related datasets, we can meta-learn Bayesian inference over task-specific BNNs.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#25345;&#20037;&#24615;&#25299;&#25169;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#65292;&#21363;TNMF&#21644;rTNMF&#65292;&#29992;&#20110;&#20998;&#26512;&#21333;&#32454;&#32990;RNA&#27979;&#24207;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;TNMF&#21644;rTNMF&#26174;&#33879;&#20248;&#20110;&#20854;&#20182;NMF&#26041;&#27861;&#65292;&#24182;&#19988;&#21487;&#20197;&#29992;&#20110;&#21487;&#35270;&#21270;UMAP&#21644;t-SNE&#12290;</title><link>http://arxiv.org/abs/2310.15744</link><description>&lt;p&gt;
&#20351;&#29992;&#25299;&#25169;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#20998;&#26512;&#21333;&#32454;&#32990;RNA&#27979;&#24207;
&lt;/p&gt;
&lt;p&gt;
Analyzing Single Cell RNA Sequencing with Topological Nonnegative Matrix Factorization. (arXiv:2310.15744v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15744
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#25345;&#20037;&#24615;&#25299;&#25169;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#65292;&#21363;TNMF&#21644;rTNMF&#65292;&#29992;&#20110;&#20998;&#26512;&#21333;&#32454;&#32990;RNA&#27979;&#24207;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;TNMF&#21644;rTNMF&#26174;&#33879;&#20248;&#20110;&#20854;&#20182;NMF&#26041;&#27861;&#65292;&#24182;&#19988;&#21487;&#20197;&#29992;&#20110;&#21487;&#35270;&#21270;UMAP&#21644;t-SNE&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21333;&#32454;&#32990;RNA&#27979;&#24207;(scRNA-seq)&#26159;&#19968;&#39033;&#30456;&#23545;&#36739;&#26032;&#30340;&#25216;&#26415;&#65292;&#30001;&#20110;&#20854;&#39640;&#32500;&#24230;&#12289;&#22797;&#26434;&#24615;&#21644;&#22823;&#35268;&#27169;&#24615;&#65292;&#24341;&#36215;&#20102;&#32479;&#35745;&#23398;&#12289;&#25968;&#25454;&#31185;&#23398;&#21644;&#35745;&#31639;&#29983;&#29289;&#23398;&#39046;&#22495;&#30340;&#24040;&#22823;&#20852;&#36259;&#12290;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;(NMF)&#22240;&#20854;&#23545;&#32467;&#26524;&#20302;&#32500;&#24230;&#20998;&#37327;&#30340;&#20803;&#22522;&#22240;&#35299;&#37322;&#32780;&#25552;&#20379;&#20102;&#19968;&#31181;&#29420;&#29305;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;NMF&#26041;&#27861;&#22312;&#32570;&#20047;&#22810;&#23610;&#24230;&#20998;&#26512;&#26041;&#38754;&#23384;&#22312;&#38382;&#39064;&#12290;&#35813;&#30740;&#31350;&#24341;&#20837;&#20102;&#20004;&#31181;&#25345;&#20037;&#24615;&#25289;&#26222;&#25289;&#26031;&#27491;&#21017;&#21270;NMF&#26041;&#27861;&#65292;&#21363;&#25299;&#25169;NMF(TNMF)&#21644;&#40065;&#26834;&#25299;&#25169;NMF(rTNMF)&#12290;&#36890;&#36807;&#20351;&#29992;&#20849;&#35745;12&#20010;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;TNMF&#21644;rTNMF&#26174;&#33879;&#20248;&#20110;&#25152;&#26377;&#20854;&#20182;NMF&#26041;&#27861;&#12290;&#25105;&#20204;&#36824;&#21033;&#29992;TNMF&#21644;rTNMF&#23545;&#27969;&#34892;&#30340;UMAP(Uniform Manifold Approximation and Projection)&#21644;t-SNE(t-distributed stochastic neighbor embedding)&#36827;&#34892;&#20102;&#21487;&#35270;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Single-cell RNA sequencing (scRNA-seq) is a relatively new technology that has stimulated enormous interest in statistics, data science, and computational biology due to the high dimensionality, complexity, and large scale associated with scRNA-seq data. Nonnegative matrix factorization (NMF) offers a unique approach due to its meta-gene interpretation of resulting low-dimensional components. However, NMF approaches suffer from the lack of multiscale analysis. This work introduces two persistent Laplacian regularized NMF methods, namely, topological NMF (TNMF) and robust topological NMF (rTNMF). By employing a total of 12 datasets, we demonstrate that the proposed TNMF and rTNMF significantly outperform all other NMF-based methods. We have also utilized TNMF and rTNMF for the visualization of popular Uniform Manifold Approximation and Projection (UMAP) and t-distributed stochastic neighbor embedding (t-SNE).
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#65288;CRL&#65289;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35266;&#27979;&#21464;&#37327;&#20998;&#32452;&#30340;&#26032;&#22411;&#24369;&#32422;&#26463;&#30340;&#21487;&#36776;&#35782;&#24615;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#19981;&#20381;&#36182;&#20110;&#26102;&#38388;&#32467;&#26500;&#12289;&#24178;&#39044;&#25110;&#30417;&#30563;&#65292;&#20855;&#26377;&#23454;&#38469;&#24212;&#29992;&#30340;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2310.15709</link><description>&lt;p&gt;
&#36890;&#36807;&#35266;&#27979;&#21464;&#37327;&#30340;&#20998;&#32452;&#20351;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#21487;&#36776;&#35782;&#21270;
&lt;/p&gt;
&lt;p&gt;
Causal Representation Learning Made Identifiable by Grouping of Observational Variables. (arXiv:2310.15709v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15709
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#65288;CRL&#65289;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35266;&#27979;&#21464;&#37327;&#20998;&#32452;&#30340;&#26032;&#22411;&#24369;&#32422;&#26463;&#30340;&#21487;&#36776;&#35782;&#24615;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#19981;&#20381;&#36182;&#20110;&#26102;&#38388;&#32467;&#26500;&#12289;&#24178;&#39044;&#25110;&#30417;&#30563;&#65292;&#20855;&#26377;&#23454;&#38469;&#24212;&#29992;&#30340;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20170;&#24456;&#26377;&#24847;&#20041;&#30340;&#35805;&#39064;&#26159;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#65288;Causal Representation Learning&#65292;&#31616;&#31216;CRL&#65289;&#65292;&#20854;&#30446;&#26631;&#26159;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#23398;&#20064;&#38544;&#34255;&#29305;&#24449;&#30340;&#22240;&#26524;&#27169;&#22411;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;CRL&#23384;&#22312;&#20005;&#37325;&#30340;&#19981;&#36866;&#38382;&#39064;&#65292;&#22240;&#20026;&#23427;&#32467;&#21512;&#20102;&#34920;&#31034;&#23398;&#20064;&#21644;&#22240;&#26524;&#21457;&#29616;&#36825;&#20004;&#20010;&#23481;&#26131;&#19981;&#36866;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#35201;&#25214;&#21040;&#33021;&#20445;&#35777;&#21807;&#19968;&#35299;&#30340;&#23454;&#38469;&#21487;&#35782;&#21035;&#24615;&#26465;&#20214;&#23545;&#20110;&#20854;&#23454;&#38469;&#24212;&#29992;&#38750;&#24120;&#37325;&#35201;&#12290;&#30446;&#21069;&#22823;&#22810;&#25968;&#26041;&#27861;&#37117;&#22522;&#20110;&#23545;&#28508;&#22312;&#22240;&#26524;&#26426;&#21046;&#30340;&#20551;&#35774;&#65292;&#27604;&#22914;&#26102;&#38388;&#22240;&#26524;&#24615;&#12289;&#30417;&#30563;&#25110;&#24178;&#39044;&#30340;&#23384;&#22312;&#65307;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#36825;&#20123;&#20551;&#35774;&#21487;&#33021;&#36807;&#20110;&#38480;&#21046;&#24615;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#36890;&#36807;&#23545;&#35266;&#27979;&#28151;&#21512;&#34920;&#29616;&#20986;&#21512;&#36866;&#30340;&#21464;&#37327;&#20998;&#32452;&#30340;&#26032;&#22411;&#24369;&#32422;&#26463;&#65292;&#23637;&#31034;&#20102;&#21487;&#36776;&#35782;&#24615;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#19982;&#27169;&#22411;&#19968;&#33268;&#30340;&#26032;&#22411;&#33258;&#25105;&#30417;&#30563;&#20272;&#35745;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
A topic of great current interest is Causal Representation Learning (CRL), whose goal is to learn a causal model for hidden features in a data-driven manner. Unfortunately, CRL is severely ill-posed since it is a combination of the two notoriously ill-posed problems of representation learning and causal discovery. Yet, finding practical identifiability conditions that guarantee a unique solution is crucial for its practical applicability. Most approaches so far have been based on assumptions on the latent causal mechanisms, such as temporal causality, or existence of supervision or interventions; these can be too restrictive in actual applications. Here, we show identifiability based on novel, weak constraints, which requires no temporal structure, intervention, nor weak supervision. The approach is based assuming the observational mixing exhibits a suitable grouping of the observational variables. We also propose a novel self-supervised estimation framework consistent with the model, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#22270;&#36827;&#34892;&#27450;&#39575;&#24615;&#20844;&#24179;&#25915;&#20987;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20803;&#23398;&#20064;&#30340;&#26694;&#26550;FATE&#65292;&#22312;&#20445;&#25345;&#19979;&#28216;&#20219;&#21153;&#25928;&#29992;&#30340;&#21069;&#25552;&#19979;&#65292;&#33021;&#22815;&#25918;&#22823;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#20559;&#35265;&#65292;&#26080;&#35770;&#26159;&#21542;&#32771;&#34385;&#20844;&#24179;&#24615;&#12290;&#35813;&#30740;&#31350;&#21487;&#20197;&#20026;&#35774;&#35745;&#40065;&#26834;&#21644;&#20844;&#24179;&#30340;&#22270;&#23398;&#20064;&#27169;&#22411;&#25552;&#20379;&#21551;&#31034;&#12290;</title><link>http://arxiv.org/abs/2310.15653</link><description>&lt;p&gt;
&#36890;&#36807;&#20803;&#23398;&#20064;&#23545;&#22270;&#36827;&#34892;&#27450;&#39575;&#24615;&#20844;&#24179;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Deceptive Fairness Attacks on Graphs via Meta Learning. (arXiv:2310.15653v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15653
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#22270;&#36827;&#34892;&#27450;&#39575;&#24615;&#20844;&#24179;&#25915;&#20987;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20803;&#23398;&#20064;&#30340;&#26694;&#26550;FATE&#65292;&#22312;&#20445;&#25345;&#19979;&#28216;&#20219;&#21153;&#25928;&#29992;&#30340;&#21069;&#25552;&#19979;&#65292;&#33021;&#22815;&#25918;&#22823;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#20559;&#35265;&#65292;&#26080;&#35770;&#26159;&#21542;&#32771;&#34385;&#20844;&#24179;&#24615;&#12290;&#35813;&#30740;&#31350;&#21487;&#20197;&#20026;&#35774;&#35745;&#40065;&#26834;&#21644;&#20844;&#24179;&#30340;&#22270;&#23398;&#20064;&#27169;&#22411;&#25552;&#20379;&#21551;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#23545;&#22270;&#36827;&#34892;&#27450;&#39575;&#24615;&#20844;&#24179;&#25915;&#20987;&#65292;&#20197;&#22238;&#31572;&#20197;&#19979;&#38382;&#39064;&#65306;&#22914;&#20309;&#36890;&#36807;&#27745;&#26579;&#25915;&#20987;&#22270;&#23398;&#20064;&#27169;&#22411;&#26469;&#27450;&#39575;&#24615;&#22320;&#21152;&#21095;&#20559;&#35265;&#65311;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#22238;&#31572;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#20803;&#23398;&#20064;&#30340;&#26694;&#26550;FATE&#12290;FATE&#24191;&#27867;&#36866;&#29992;&#20110;&#21508;&#31181;&#20844;&#24179;&#23450;&#20041;&#21644;&#22270;&#23398;&#20064;&#27169;&#22411;&#65292;&#20197;&#21450;&#20219;&#24847;&#36873;&#25321;&#30340;&#25805;&#20316;&#26041;&#27861;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;FATE&#23454;&#20363;&#21270;&#20026;&#25915;&#20987;&#22270;&#31070;&#32463;&#32593;&#32476;&#19978;&#30340;&#32479;&#35745;&#24179;&#34913;&#21644;&#20010;&#20307;&#20844;&#24179;&#12290;&#25105;&#20204;&#22312;&#21322;&#30417;&#30563;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#30340;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#35780;&#20272;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;FATE&#33021;&#22815;&#22312;&#32500;&#25345;&#19979;&#28216;&#20219;&#21153;&#30340;&#25928;&#29992;&#30340;&#21516;&#26102;&#25918;&#22823;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#20559;&#35265;&#65292;&#26080;&#35770;&#26159;&#21542;&#32771;&#34385;&#20844;&#24179;&#24615;&#12290;&#25105;&#20204;&#24076;&#26395;&#26412;&#25991;&#33021;&#22815;&#23545;&#20844;&#24179;&#22270;&#23398;&#20064;&#30340;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#25552;&#20379;&#19968;&#20123;&#35265;&#35299;&#65292;&#24182;&#33021;&#20026;&#35774;&#35745;&#40065;&#26834;&#21644;&#20844;&#24179;&#30340;&#22270;&#23398;&#20064;&#27169;&#22411;&#25552;&#20379;&#21551;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study deceptive fairness attacks on graphs to answer the following question: How can we achieve poisoning attacks on a graph learning model to exacerbate the bias deceptively? We answer this question via a bi-level optimization problem and propose a meta learning-based framework named FATE. FATE is broadly applicable with respect to various fairness definitions and graph learning models, as well as arbitrary choices of manipulation operations. We further instantiate FATE to attack statistical parity and individual fairness on graph neural networks. We conduct extensive experimental evaluations on real-world datasets in the task of semi-supervised node classification. The experimental results demonstrate that FATE could amplify the bias of graph neural networks with or without fairness consideration while maintaining the utility on the downstream task. We hope this paper provides insights into the adversarial robustness of fair graph learning and can shed light on designing robust an
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19978;&#19979;&#25991;&#23450;&#21521;&#26080;&#29615;&#22270;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#23558;&#19978;&#19979;&#25991;&#29305;&#24449;&#26144;&#23556;&#21040;DAG&#65292;&#21033;&#29992;&#31232;&#30095;&#30340;&#21152;&#26435;&#37051;&#25509;&#30697;&#38453;&#34920;&#31034;&#22270;&#32467;&#26500;&#65292;&#24182;&#36890;&#36807;&#26032;&#39062;&#30340;&#25237;&#24433;&#23618;&#28385;&#36275;&#26080;&#29615;&#24615;&#30340;&#29305;&#28857;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#33021;&#22815;&#25104;&#21151;&#24674;&#22797;&#20986;&#30495;&#23454;&#30340;&#19978;&#19979;&#25991;&#29305;&#23450;&#22270;&#12290;</title><link>http://arxiv.org/abs/2310.15627</link><description>&lt;p&gt;
&#19978;&#19979;&#25991;&#23450;&#21521;&#26080;&#29615;&#22270;
&lt;/p&gt;
&lt;p&gt;
Contextual directed acyclic graphs. (arXiv:2310.15627v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15627
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19978;&#19979;&#25991;&#23450;&#21521;&#26080;&#29615;&#22270;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#23558;&#19978;&#19979;&#25991;&#29305;&#24449;&#26144;&#23556;&#21040;DAG&#65292;&#21033;&#29992;&#31232;&#30095;&#30340;&#21152;&#26435;&#37051;&#25509;&#30697;&#38453;&#34920;&#31034;&#22270;&#32467;&#26500;&#65292;&#24182;&#36890;&#36807;&#26032;&#39062;&#30340;&#25237;&#24433;&#23618;&#28385;&#36275;&#26080;&#29615;&#24615;&#30340;&#29305;&#28857;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#33021;&#22815;&#25104;&#21151;&#24674;&#22797;&#20986;&#30495;&#23454;&#30340;&#19978;&#19979;&#25991;&#29305;&#23450;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#20272;&#35745;&#23450;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#30340;&#32467;&#26500;&#20173;&#28982;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#12290;&#36825;&#20010;&#39046;&#22495;&#30340;&#22823;&#37096;&#20998;&#30740;&#31350;&#38598;&#20013;&#22312;&#20026;&#25972;&#20010;&#20154;&#21475;&#23398;&#20064;&#21333;&#20010;DAG&#19978;&#12290;&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#20010;&#26367;&#20195;&#24615;&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;&#22270;&#32467;&#26500;&#22522;&#20110;&#21487;&#29992;&#30340;&#8220;&#19978;&#19979;&#25991;&#8221;&#29305;&#24449;&#32780;&#22240;&#20154;&#32780;&#24322;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#23558;&#19978;&#19979;&#25991;&#29305;&#24449;&#26144;&#23556;&#21040;DAG&#30340;&#31070;&#32463;&#32593;&#32476;&#26469;&#35299;&#20915;&#36825;&#20010;&#19978;&#19979;&#25991;DAG&#38382;&#39064;&#65292;DAG&#20197;&#21152;&#26435;&#37051;&#25509;&#30697;&#38453;&#34920;&#31034;&#12290;&#31070;&#32463;&#32593;&#32476;&#37197;&#22791;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#25237;&#24433;&#23618;&#65292;&#30830;&#20445;&#36755;&#20986;&#30697;&#38453;&#26159;&#31232;&#30095;&#30340;&#65292;&#24182;&#28385;&#36275;&#26368;&#36817;&#21457;&#23637;&#30340;&#26080;&#29615;&#24615;&#30340;&#29305;&#28857;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#35745;&#31639;&#26694;&#26550;&#26469;&#23398;&#20064;&#19978;&#19979;&#25991;DAG&#65292;&#24182;&#25552;&#20379;&#20102;&#25910;&#25947;&#20445;&#35777;&#21644;&#36890;&#36807;&#25237;&#24433;&#23618;&#21453;&#21521;&#20256;&#25773;&#30340;&#20998;&#26512;&#26799;&#24230;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#31181;&#26032;&#26041;&#27861;&#21487;&#20197;&#24674;&#22797;&#20986;&#30495;&#23454;&#30340;&#19978;&#19979;&#25991;&#29305;&#23450;&#22270;&#65292;&#32780;&#29616;&#26377;&#26041;&#27861;&#21017;&#22833;&#36133;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating the structure of directed acyclic graphs (DAGs) from observational data remains a significant challenge in machine learning. Most research in this area concentrates on learning a single DAG for the entire population. This paper considers an alternative setting where the graph structure varies across individuals based on available "contextual" features. We tackle this contextual DAG problem via a neural network that maps the contextual features to a DAG, represented as a weighted adjacency matrix. The neural network is equipped with a novel projection layer that ensures the output matrices are sparse and satisfy a recently developed characterization of acyclicity. We devise a scalable computational framework for learning contextual DAGs and provide a convergence guarantee and an analytical gradient for backpropagating through the projection layer. Our experiments suggest that the new approach can recover the true context-specific graph where existing approaches fail.
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#33258;&#21160;&#32534;&#30721;&#22120;&#21644;&#25193;&#25955;&#27169;&#22411;&#32467;&#21512;&#30340;AutoDiff&#27169;&#22411;&#21487;&#20197;&#26377;&#25928;&#22320;&#29983;&#25104;&#21512;&#25104;&#30340;&#34920;&#26684;&#25968;&#25454;&#65292;&#20811;&#26381;&#20102;&#34920;&#26684;&#25968;&#25454;&#20013;&#30340;&#24322;&#26500;&#29305;&#24449;&#21644;&#29305;&#24449;&#38388;&#30456;&#20851;&#24615;&#30340;&#25361;&#25112;&#65292;&#29983;&#25104;&#30340;&#25968;&#25454;&#19982;&#30495;&#23454;&#25968;&#25454;&#22312;&#32479;&#35745;&#19978;&#38750;&#24120;&#30456;&#20284;&#65292;&#24182;&#22312;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>http://arxiv.org/abs/2310.15479</link><description>&lt;p&gt;
AutoDiff:&#32467;&#21512;&#33258;&#21160;&#32534;&#30721;&#22120;&#21644;&#25193;&#25955;&#27169;&#22411;&#29992;&#20110;&#34920;&#26684;&#25968;&#25454;&#21512;&#25104;
&lt;/p&gt;
&lt;p&gt;
AutoDiff: combining Auto-encoder and Diffusion model for tabular data synthesizing. (arXiv:2310.15479v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15479
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#33258;&#21160;&#32534;&#30721;&#22120;&#21644;&#25193;&#25955;&#27169;&#22411;&#32467;&#21512;&#30340;AutoDiff&#27169;&#22411;&#21487;&#20197;&#26377;&#25928;&#22320;&#29983;&#25104;&#21512;&#25104;&#30340;&#34920;&#26684;&#25968;&#25454;&#65292;&#20811;&#26381;&#20102;&#34920;&#26684;&#25968;&#25454;&#20013;&#30340;&#24322;&#26500;&#29305;&#24449;&#21644;&#29305;&#24449;&#38388;&#30456;&#20851;&#24615;&#30340;&#25361;&#25112;&#65292;&#29983;&#25104;&#30340;&#25968;&#25454;&#19982;&#30495;&#23454;&#25968;&#25454;&#22312;&#32479;&#35745;&#19978;&#38750;&#24120;&#30456;&#20284;&#65292;&#24182;&#22312;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#24050;&#25104;&#20026;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#35768;&#22810;&#23376;&#39046;&#22495;&#20013;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#30340;&#20027;&#35201;&#33539;&#24335;&#65292;&#21253;&#25324;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#35821;&#35328;&#27169;&#22411;&#25110;&#35821;&#38899;&#21512;&#25104;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#25193;&#25955;&#27169;&#22411;&#30340;&#21147;&#37327;&#26469;&#29983;&#25104;&#21512;&#25104;&#30340;&#34920;&#26684;&#25968;&#25454;&#12290;&#34920;&#26684;&#25968;&#25454;&#20013;&#30340;&#24322;&#26500;&#29305;&#24449;&#19968;&#30452;&#26159;&#34920;&#26684;&#25968;&#25454;&#21512;&#25104;&#30340;&#20027;&#35201;&#38556;&#30861;&#65292;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#26550;&#26500;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#19982;&#26368;&#20808;&#36827;&#30340;&#34920;&#26684;&#21512;&#25104;&#22120;&#30456;&#27604;&#65292;&#25105;&#20204;&#27169;&#22411;&#29983;&#25104;&#30340;&#21512;&#25104;&#34920;&#26684;&#22312;&#32479;&#35745;&#19978;&#19982;&#30495;&#23454;&#25968;&#25454;&#38750;&#24120;&#30456;&#20284;&#65292;&#24182;&#22312;&#26426;&#22120;&#23398;&#20064;&#24037;&#20855;&#30340;&#19979;&#28216;&#20219;&#21153;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;&#25105;&#20204;&#22312;15&#20010;&#20844;&#24320;&#21487;&#29992;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#28789;&#27963;&#22320;&#25429;&#25417;&#20102;&#29305;&#24449;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#36825;&#26159;&#34920;&#26684;&#25968;&#25454;&#21512;&#25104;&#20013;&#38271;&#26399;&#23384;&#22312;&#30340;&#25361;&#25112;&#12290;&#22914;&#33509;&#25509;&#32435;&#20102;&#35770;&#25991;&#65292;&#25105;&#20204;&#30340;&#20195;&#30721;&#23558;&#26681;&#25454;&#35201;&#27714;&#25552;&#20379;&#65292;&#24182;&#19988;&#23558;&#20844;&#24320;&#21457;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion model has become a main paradigm for synthetic data generation in many subfields of modern machine learning, including computer vision, language model, or speech synthesis. In this paper, we leverage the power of diffusion model for generating synthetic tabular data. The heterogeneous features in tabular data have been main obstacles in tabular data synthesis, and we tackle this problem by employing the auto-encoder architecture. When compared with the state-of-the-art tabular synthesizers, the resulting synthetic tables from our model show nice statistical fidelities to the real data, and perform well in downstream tasks for machine learning utilities. We conducted the experiments over 15 publicly available datasets. Notably, our model adeptly captures the correlations among features, which has been a long-standing challenge in tabular data synthesis. Our code is available upon request and will be publicly released if paper is accepted.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#12289;&#21487;&#35299;&#37322;&#30340;&#29983;&#23384;&#20998;&#26512;&#27969;&#31243;&#65292;&#21033;&#29992;&#25913;&#36827;&#30340;&#29983;&#23384;&#22534;&#21472;&#25216;&#26415;&#23558;&#29983;&#23384;&#20998;&#26512;&#38382;&#39064;&#36716;&#21270;&#20026;&#20998;&#31867;&#38382;&#39064;&#65292;&#24182;&#21033;&#29992;&#21487;&#35299;&#37322;&#24615;&#24378;&#30340;&#22686;&#24378;&#26426;&#22120;&#36827;&#34892;&#24515;&#34928;&#39118;&#38505;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2310.15472</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#24515;&#34928;&#39118;&#38505;&#39044;&#27979;&#30340;&#29983;&#23384;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Interpretable Survival Analysis for Heart Failure Risk Prediction. (arXiv:2310.15472v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15472
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#12289;&#21487;&#35299;&#37322;&#30340;&#29983;&#23384;&#20998;&#26512;&#27969;&#31243;&#65292;&#21033;&#29992;&#25913;&#36827;&#30340;&#29983;&#23384;&#22534;&#21472;&#25216;&#26415;&#23558;&#29983;&#23384;&#20998;&#26512;&#38382;&#39064;&#36716;&#21270;&#20026;&#20998;&#31867;&#38382;&#39064;&#65292;&#24182;&#21033;&#29992;&#21487;&#35299;&#37322;&#24615;&#24378;&#30340;&#22686;&#24378;&#26426;&#22120;&#36827;&#34892;&#24515;&#34928;&#39118;&#38505;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#23384;&#20998;&#26512;&#65292;&#25110;&#26102;&#38388;&#20107;&#20214;&#20998;&#26512;&#65292;&#22312;&#21307;&#30103;&#30740;&#31350;&#20013;&#26159;&#19968;&#20010;&#37325;&#35201;&#19988;&#24191;&#27867;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;&#21307;&#30103;&#30740;&#31350;&#20256;&#32479;&#19978;&#20381;&#36182;&#20110;Cox&#27169;&#22411;&#36827;&#34892;&#29983;&#23384;&#20998;&#26512;&#65292;&#22240;&#20026;&#20854;&#31616;&#21333;&#19988;&#21487;&#35299;&#37322;&#24615;&#24378;&#12290;Cox&#27169;&#22411;&#20551;&#35774;&#19968;&#20010;&#23545;&#25968;&#32447;&#24615;&#39118;&#38505;&#20989;&#25968;&#20197;&#21450;&#26102;&#38388;&#19978;&#30340;&#27604;&#20363;&#39118;&#38505;&#65292;&#24403;&#36825;&#20123;&#20551;&#35774;&#22833;&#36133;&#26102;&#21487;&#33021;&#34920;&#29616;&#19981;&#20339;&#12290;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26032;&#22411;&#29983;&#23384;&#27169;&#22411;&#36991;&#20813;&#20102;&#36825;&#20123;&#20551;&#35774;&#65292;&#24182;&#25552;&#20379;&#20102;&#26356;&#39640;&#30340;&#20934;&#30830;&#24615;&#65292;&#20294;&#26377;&#26102;&#20197;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#20026;&#20195;&#20215;&#65292;&#32780;&#36825;&#23545;&#20110;&#20020;&#24202;&#20351;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29983;&#23384;&#20998;&#26512;&#27969;&#31243;&#65292;&#26082;&#21487;&#35299;&#37322;&#24615;&#24378;&#65292;&#21448;&#33021;&#19982;&#26368;&#20808;&#36827;&#30340;&#29983;&#23384;&#27169;&#22411;&#31454;&#20105;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#20351;&#29992;&#25913;&#36827;&#30340;&#29983;&#23384;&#22534;&#21472;&#25216;&#26415;&#23558;&#29983;&#23384;&#20998;&#26512;&#38382;&#39064;&#36716;&#21270;&#20026;&#19968;&#20010;&#20998;&#31867;&#38382;&#39064;&#65292;&#20351;&#29992;ControlBurn&#36827;&#34892;&#29305;&#24449;&#36873;&#25321;&#65292;&#24182;&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;&#22686;&#24378;&#26426;&#22120;&#29983;&#25104;&#21487;&#35299;&#37322;&#30340;&#39044;&#27979;&#12290;&#20026;&#20102;&#35780;&#20272;&#25105;&#20204;&#30340;&#27969;&#31243;&#65292;&#25105;&#20204;&#39044;&#27979;&#24515;&#34928;&#30340;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;
Survival analysis, or time-to-event analysis, is an important and widespread problem in healthcare research. Medical research has traditionally relied on Cox models for survival analysis, due to their simplicity and interpretability. Cox models assume a log-linear hazard function as well as proportional hazards over time, and can perform poorly when these assumptions fail. Newer survival models based on machine learning avoid these assumptions and offer improved accuracy, yet sometimes at the expense of model interpretability, which is vital for clinical use. We propose a novel survival analysis pipeline that is both interpretable and competitive with state-of-the-art survival models. Specifically, we use an improved version of survival stacking to transform a survival analysis problem to a classification problem, ControlBurn to perform feature selection, and Explainable Boosting Machines to generate interpretable predictions. To evaluate our pipeline, we predict risk of heart failure 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#20855;&#26377;&#31169;&#26377;&#21644;&#20844;&#20849;&#29305;&#24449;&#30340;&#20010;&#20154;&#21270;&#23398;&#20064;&#38382;&#39064;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#21482;&#20445;&#25252;&#29305;&#23450;&#30340;&#32479;&#35745;&#37327;&#26469;&#25552;&#39640;&#23454;&#29992;&#24615;&#65292;&#22312;&#20004;&#20010;&#26631;&#20934;&#31169;&#26377;&#25512;&#33616;&#22522;&#20934;&#27979;&#35797;&#20013;&#36798;&#21040;&#20102;&#26368;&#26032;&#30340;&#25104;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.15454</link><description>&lt;p&gt;
&#20855;&#26377;&#20844;&#20849;&#29305;&#24449;&#30340;&#20010;&#20154;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Private Learning with Public Features. (arXiv:2310.15454v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15454
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#20855;&#26377;&#31169;&#26377;&#21644;&#20844;&#20849;&#29305;&#24449;&#30340;&#20010;&#20154;&#21270;&#23398;&#20064;&#38382;&#39064;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#21482;&#20445;&#25252;&#29305;&#23450;&#30340;&#32479;&#35745;&#37327;&#26469;&#25552;&#39640;&#23454;&#29992;&#24615;&#65292;&#22312;&#20004;&#20010;&#26631;&#20934;&#31169;&#26377;&#25512;&#33616;&#22522;&#20934;&#27979;&#35797;&#20013;&#36798;&#21040;&#20102;&#26368;&#26032;&#30340;&#25104;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31867;&#31169;&#26377;&#23398;&#20064;&#38382;&#39064;&#65292;&#20854;&#20013;&#25968;&#25454;&#26159;&#31169;&#26377;&#29305;&#24449;&#21644;&#20844;&#20849;&#29305;&#24449;&#30340;&#32852;&#32467;&#12290;&#36825;&#22312;&#31169;&#20154;&#20010;&#24615;&#21270;&#20219;&#21153;&#20013;&#32463;&#24120;&#20986;&#29616;&#65292;&#20363;&#22914;&#25512;&#33616;&#25110;&#24191;&#21578;&#39044;&#27979;&#65292;&#22312;&#36825;&#20123;&#20219;&#21153;&#20013;&#65292;&#19982;&#20010;&#20154;&#30456;&#20851;&#30340;&#29305;&#24449;&#26159;&#25935;&#24863;&#30340;&#65292;&#32780;&#19982;&#29289;&#21697;&#30456;&#20851;&#30340;&#29305;&#24449;&#65288;&#22914;&#25512;&#33616;&#30340;&#30005;&#24433;&#25110;&#27468;&#26354;&#65292;&#25110;&#32773;&#21521;&#29992;&#25143;&#23637;&#31034;&#30340;&#24191;&#21578;&#65289;&#26159;&#20844;&#24320;&#21487;&#29992;&#30340;&#24182;&#19988;&#19981;&#38656;&#35201;&#20445;&#25252;&#12290;&#19968;&#20010;&#33258;&#28982;&#30340;&#38382;&#39064;&#26159;&#65292;&#22312;&#20844;&#20849;&#29305;&#24449;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#31169;&#26377;&#31639;&#27861;&#26159;&#21542;&#33021;&#22815;&#23454;&#29616;&#26356;&#39640;&#30340;&#23454;&#29992;&#24615;&#12290;&#25105;&#20204;&#23545;&#22810;&#32534;&#30721;&#22120;&#27169;&#22411;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#20854;&#20013;&#19968;&#20010;&#32534;&#30721;&#22120;&#22788;&#29702;&#20844;&#20849;&#29305;&#24449;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#26032;&#30340;&#31639;&#27861;&#65292;&#21033;&#29992;&#36825;&#31181;&#20998;&#31163;&#21482;&#20445;&#25252;&#26576;&#20123;&#20805;&#20998;&#32479;&#35745;&#37327;&#65288;&#32780;&#19981;&#26159;&#21521;&#26799;&#24230;&#28155;&#21152;&#22122;&#38899;&#65289;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#32447;&#24615;&#22238;&#24402;&#20013;&#20445;&#35777;&#20102;&#23454;&#29992;&#24615;&#25913;&#36827;&#65292;&#24182;&#19988;&#22312;&#20004;&#20010;&#26631;&#20934;&#31169;&#26377;&#25512;&#33616;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;&#26368;&#26032;&#30340;&#25104;&#26524;&#65292;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a class of private learning problems in which the data is a join of private and public features. This is often the case in private personalization tasks such as recommendation or ad prediction, in which features related to individuals are sensitive, while features related to items (the movies or songs to be recommended, or the ads to be shown to users) are publicly available and do not require protection. A natural question is whether private algorithms can achieve higher utility in the presence of public features. We give a positive answer for multi-encoder models where one of the encoders operates on public features. We develop new algorithms that take advantage of this separation by only protecting certain sufficient statistics (instead of adding noise to the gradient). This method has a guaranteed utility improvement for linear regression, and importantly, achieves the state of the art on two standard private recommendation benchmarks, demonstrating the importance of metho
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#36890;&#29992;&#38750;&#21442;&#25968;&#22240;&#26524;&#28508;&#21464;&#37327;&#27169;&#22411;&#21644;&#36890;&#29992;&#36716;&#25442;&#27169;&#22411;&#19979;&#65292;&#36890;&#36807;&#38750;&#32806;&#21512;&#24178;&#39044;&#24314;&#31435;&#20102;&#22240;&#26524;&#34920;&#36798;&#23398;&#20064;&#30340;&#21487;&#35782;&#21035;&#24615;&#21644;&#21487;&#23454;&#29616;&#24615;&#32467;&#26524;&#12290;&#22312;&#19981;&#30693;&#36947;&#20855;&#20307;&#24178;&#39044;&#23545;&#24212;&#30340;&#33410;&#28857;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#20123;&#32467;&#26524;&#20445;&#35777;&#20102;&#28508;&#22312;&#30340;&#22240;&#26524;&#27169;&#22411;&#21644;&#21464;&#37327;&#30340;&#23436;&#32654;&#24674;&#22797;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#31639;&#27861;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#12290;</title><link>http://arxiv.org/abs/2310.15450</link><description>&lt;p&gt;
&#36890;&#29992;&#22240;&#26524;&#34920;&#36798;&#23398;&#20064;&#30340;&#21487;&#35782;&#21035;&#24615;&#21644;&#21487;&#23454;&#29616;&#24615;
&lt;/p&gt;
&lt;p&gt;
General Identifiability and Achievability for Causal Representation Learning. (arXiv:2310.15450v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15450
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#36890;&#29992;&#38750;&#21442;&#25968;&#22240;&#26524;&#28508;&#21464;&#37327;&#27169;&#22411;&#21644;&#36890;&#29992;&#36716;&#25442;&#27169;&#22411;&#19979;&#65292;&#36890;&#36807;&#38750;&#32806;&#21512;&#24178;&#39044;&#24314;&#31435;&#20102;&#22240;&#26524;&#34920;&#36798;&#23398;&#20064;&#30340;&#21487;&#35782;&#21035;&#24615;&#21644;&#21487;&#23454;&#29616;&#24615;&#32467;&#26524;&#12290;&#22312;&#19981;&#30693;&#36947;&#20855;&#20307;&#24178;&#39044;&#23545;&#24212;&#30340;&#33410;&#28857;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#20123;&#32467;&#26524;&#20445;&#35777;&#20102;&#28508;&#22312;&#30340;&#22240;&#26524;&#27169;&#22411;&#21644;&#21464;&#37327;&#30340;&#23436;&#32654;&#24674;&#22797;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#31639;&#27861;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#36890;&#29992;&#38750;&#21442;&#25968;&#22240;&#26524;&#28508;&#21464;&#37327;&#27169;&#22411;&#21644;&#23558;&#28508;&#21464;&#37327;&#25968;&#25454;&#26144;&#23556;&#21040;&#35266;&#27979;&#25968;&#25454;&#30340;&#36890;&#29992;&#36716;&#25442;&#27169;&#22411;&#19979;&#30340;&#22240;&#26524;&#34920;&#36798;&#23398;&#20064;&#12290;&#36890;&#36807;&#22312;&#28508;&#22312;&#22240;&#26524;&#22270;&#20013;&#27599;&#20010;&#33410;&#28857;&#36827;&#34892;&#20004;&#20010;&#30828;&#24615;&#38750;&#32806;&#21512;&#24178;&#39044;&#26469;&#24314;&#31435;&#21487;&#35782;&#21035;&#24615;&#21644;&#21487;&#23454;&#29616;&#24615;&#32467;&#26524;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#20154;&#20204;&#19981;&#30693;&#36947;&#21738;&#20010;&#24178;&#39044;&#29615;&#22659;&#23545;&#24212;&#30340;&#33410;&#28857;&#26159;&#30456;&#21516;&#30340;&#65288;&#22240;&#27492;&#26159;&#38750;&#32806;&#21512;&#29615;&#22659;&#65289;&#12290;&#22312;&#21487;&#35782;&#21035;&#24615;&#26041;&#38754;&#65292;&#26412;&#25991;&#30830;&#20445;&#22312;&#38750;&#32806;&#21512;&#24178;&#39044;&#19979;&#33021;&#22815;&#23436;&#32654;&#24674;&#22797;&#28508;&#22312;&#30340;&#22240;&#26524;&#27169;&#22411;&#21644;&#21464;&#37327;&#12290;&#22312;&#21487;&#23454;&#29616;&#24615;&#26041;&#38754;&#65292;&#35774;&#35745;&#20102;&#19968;&#20010;&#31639;&#27861;&#65292;&#21033;&#29992;&#35266;&#27979;&#21644;&#24178;&#39044;&#25968;&#25454;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#35813;&#31639;&#27861;&#30340;&#21487;&#39564;&#35777;&#30340;&#20445;&#35777;&#65292;&#20197;&#24674;&#22797;&#28508;&#22312;&#30340;&#22240;&#26524;&#27169;&#22411;&#21644;&#21464;&#37327;&#12290;&#35813;&#31639;&#27861;&#21033;&#29992;&#19981;&#21516;&#29615;&#22659;&#20013;&#30340;&#24471;&#20998;&#21464;&#21270;&#26469;&#20272;&#35745;&#36716;&#25442;&#22120;&#30340;&#36870;&#21644;&#38543;&#21518;&#30340;&#28508;&#21464;&#37327;&#12290;&#35813;&#20998;&#26512;&#36824;...
&lt;/p&gt;
&lt;p&gt;
This paper focuses on causal representation learning (CRL) under a general nonparametric causal latent model and a general transformation model that maps the latent data to the observational data. It establishes \textbf{identifiability} and \textbf{achievability} results using two hard \textbf{uncoupled} interventions per node in the latent causal graph. Notably, one does not know which pair of intervention environments have the same node intervened (hence, uncoupled environments). For identifiability, the paper establishes that perfect recovery of the latent causal model and variables is guaranteed under uncoupled interventions. For achievability, an algorithm is designed that uses observational and interventional data and recovers the latent causal model and variables with provable guarantees for the algorithm. This algorithm leverages score variations across different environments to estimate the inverse of the transformer and, subsequently, the latent variables. The analysis, addit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#36895;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#38543;&#26426;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#36845;&#20195;&#22797;&#26434;&#24230;&#36798;&#21040;&#20102;&#26368;&#20339;&#24050;&#30693;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2310.15448</link><description>&lt;p&gt;
&#19968;&#31181;&#21152;&#36895;&#30340;&#19968;&#38454;&#27491;&#21017;&#21160;&#37327;&#19979;&#38477;&#31639;&#27861;&#29992;&#20110;&#38543;&#26426;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
An accelerated first-order regularized momentum descent ascent algorithm for stochastic nonconvex-concave minimax problems. (arXiv:2310.15448v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15448
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#36895;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#38543;&#26426;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#36845;&#20195;&#22797;&#26434;&#24230;&#36798;&#21040;&#20102;&#26368;&#20339;&#24050;&#30693;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#36817;&#24180;&#26469;&#22312;&#26426;&#22120;&#23398;&#20064;&#12289;&#20449;&#21495;&#22788;&#29702;&#31561;&#39046;&#22495;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#36895;&#30340;&#19968;&#38454;&#27491;&#21017;&#21160;&#37327;&#19979;&#38477;&#31639;&#27861;&#65288;FORMDA&#65289;&#29992;&#20110;&#35299;&#20915;&#38543;&#26426;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#12290;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#20026;$\tilde{\mathcal{O}}(\varepsilon ^{-6.5})$&#20197;&#36798;&#21040;$\varepsilon$-&#31283;&#23450;&#28857;&#65292;&#36825;&#22312;&#30446;&#26631;&#20989;&#25968;&#31283;&#23450;&#24615;&#19979;&#23454;&#29616;&#20102;&#35299;&#20915;&#38543;&#26426;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#26368;&#20339;&#24050;&#30693;&#22797;&#26434;&#24230;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic nonconvex minimax problems have attracted wide attention in machine learning, signal processing and many other fields in recent years. In this paper, we propose an accelerated first-order regularized momentum descent ascent algorithm (FORMDA) for solving stochastic nonconvex-concave minimax problems. The iteration complexity of the algorithm is proved to be $\tilde{\mathcal{O}}(\varepsilon ^{-6.5})$ to obtain an $\varepsilon$-stationary point, which achieves the best-known complexity bound for single-loop algorithms to solve the stochastic nonconvex-concave minimax problems under the stationarity of the objective function.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#23545;&#32447;&#24615;VAE&#20013;&#30340;&#23398;&#20064;&#21160;&#24577;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#22312;&#22823;&#36755;&#20837;&#32500;&#24230;&#30340;&#38480;&#21046;&#19979;&#65292;&#23398;&#20064;&#21160;&#24577;&#25910;&#25947;&#20026;&#30830;&#23450;&#24615;&#36807;&#31243;&#65292;&#24182;&#25552;&#20986;&#20102;&#21518;&#39564;&#23849;&#22604;&#38408;&#20540;&#21644;KL&#36864;&#28779;&#21152;&#36895;&#31574;&#30053;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;VAE&#26368;&#21021;&#23398;&#20064;&#21040;&#32416;&#32544;&#34920;&#31034;&#65292;&#24182;&#36880;&#28176;&#33719;&#24471;&#19981;&#32416;&#32544;&#30340;&#34920;&#31034;&#12290;&#22312;&#30830;&#23450;&#24615;&#36807;&#31243;&#20013;&#65292;&#36229;fluous&#28508;&#22312;&#31354;&#38388;&#26159;&#19968;&#20010;&#28508;&#22312;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.15440</link><description>&lt;p&gt;
Learning Dynamics in Linear VAE: Posterior Collapse Threshold, Superfluous Latent Space Pitfalls, and Speedup with KL Annealing. (arXiv:2310.15440v1 [stat.ML])&#30340;&#23398;&#20064;&#21160;&#24577;&#65306;&#21518;&#39564;&#23849;&#22604;&#38408;&#20540;&#65292;&#22810;&#20313;&#30340;&#28508;&#22312;&#31354;&#38388;&#38519;&#38449;&#20197;&#21450;KL&#36864;&#28779;&#30340;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning Dynamics in Linear VAE: Posterior Collapse Threshold, Superfluous Latent Space Pitfalls, and Speedup with KL Annealing. (arXiv:2310.15440v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15440
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#23545;&#32447;&#24615;VAE&#20013;&#30340;&#23398;&#20064;&#21160;&#24577;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#22312;&#22823;&#36755;&#20837;&#32500;&#24230;&#30340;&#38480;&#21046;&#19979;&#65292;&#23398;&#20064;&#21160;&#24577;&#25910;&#25947;&#20026;&#30830;&#23450;&#24615;&#36807;&#31243;&#65292;&#24182;&#25552;&#20986;&#20102;&#21518;&#39564;&#23849;&#22604;&#38408;&#20540;&#21644;KL&#36864;&#28779;&#21152;&#36895;&#31574;&#30053;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;VAE&#26368;&#21021;&#23398;&#20064;&#21040;&#32416;&#32544;&#34920;&#31034;&#65292;&#24182;&#36880;&#28176;&#33719;&#24471;&#19981;&#32416;&#32544;&#30340;&#34920;&#31034;&#12290;&#22312;&#30830;&#23450;&#24615;&#36807;&#31243;&#20013;&#65292;&#36229;fluous&#28508;&#22312;&#31354;&#38388;&#26159;&#19968;&#20010;&#28508;&#22312;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAEs&#65289;&#23384;&#22312;&#19968;&#20010;&#33261;&#21517;&#26157;&#33879;&#30340;&#38382;&#39064;&#65292;&#21363;&#21464;&#20998;&#21518;&#39564;&#36890;&#24120;&#19982;&#20808;&#39564;&#38750;&#24120;&#25509;&#36817;&#65292;&#36825;&#31181;&#29616;&#35937;&#31216;&#20026;&#21518;&#39564;&#23849;&#22604;&#65292;&#23427;&#38459;&#30861;&#20102;&#34920;&#31034;&#23398;&#20064;&#30340;&#36136;&#37327;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#35843;&#30340;&#36229;&#21442;&#25968;&#946;&#20197;&#21450;&#19968;&#31181;&#31216;&#20026;KL&#36864;&#28779;&#30340;&#31574;&#30053;&#26469;&#35843;&#25972;&#35813;&#21442;&#25968;&#12290;&#26412;&#30740;&#31350;&#22312;&#19968;&#20010;&#31616;&#21270;&#30340;VAE&#20013;&#23545;&#23398;&#20064;&#21160;&#24577;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#12290;&#32463;&#36807;&#20005;&#26684;&#35777;&#26126;&#65292;&#22312;&#36755;&#20837;&#32500;&#24230;&#36235;&#20110;&#26080;&#31351;&#22823;&#30340;&#26497;&#38480;&#19979;&#65292;&#21160;&#24577;&#25910;&#25947;&#20026;&#30830;&#23450;&#24615;&#36807;&#31243;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23545;&#27867;&#21270;&#35823;&#24046;&#30340;&#35814;&#32454;&#21160;&#24577;&#20998;&#26512;&#12290;&#27492;&#22806;&#65292;&#20998;&#26512;&#36824;&#34920;&#26126;&#65292;VAE&#26368;&#21021;&#23398;&#20064;&#21040;&#32416;&#32544;&#34920;&#31034;&#65292;&#24182;&#36880;&#28176;&#33719;&#24471;&#19981;&#32416;&#32544;&#30340;&#34920;&#31034;&#12290;&#23545;&#30830;&#23450;&#24615;&#36807;&#31243;&#30340;&#22266;&#23450;&#28857;&#20998;&#26512;&#25581;&#31034;&#65292;&#24403;&#946;&#36229;&#36807;&#19968;&#23450;&#38408;&#20540;&#26102;&#65292;&#26080;&#35770;&#23398;&#20064;&#21608;&#26399;&#22810;&#38271;&#65292;&#21518;&#39564;&#23849;&#22604;&#37117;&#26159;&#19981;&#21487;&#36991;&#20813;&#30340;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#25506;&#35752;&#20102;&#36229;fluous&#28508;&#22312;&#31354;&#38388;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational autoencoders (VAEs) face a notorious problem wherein the variational posterior often aligns closely with the prior, a phenomenon known as posterior collapse, which hinders the quality of representation learning. To mitigate this problem, an adjustable hyperparameter $\beta$ and a strategy for annealing this parameter, called KL annealing, are proposed. This study presents a theoretical analysis of the learning dynamics in a minimal VAE. It is rigorously proved that the dynamics converge to a deterministic process within the limit of large input dimensions, thereby enabling a detailed dynamical analysis of the generalization error. Furthermore, the analysis shows that the VAE initially learns entangled representations and gradually acquires disentangled representations. A fixed-point analysis of the deterministic process reveals that when $\beta$ exceeds a certain threshold, posterior collapse becomes inevitable regardless of the learning period. Additionally, the superfluou
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32467;&#26500;&#21270;&#26080;&#26631;&#31614;&#25968;&#25454;&#20998;&#24067;&#19979;&#65292;&#23545;&#20110;&#20855;&#26377;Tsybakov&#22122;&#22768;&#30340;$d$&#32500;&#21322;&#31354;&#38388;&#65292;&#35745;&#31639;&#21644;&#26631;&#31614;&#30340;&#39640;&#25928;PAC&#20027;&#21160;&#23398;&#20064;&#38382;&#39064;&#12290;&#36890;&#36807;&#35774;&#35745;&#19968;&#31181;&#22522;&#20110;&#38750;&#20984;&#20248;&#21270;&#30340;&#31639;&#27861;&#65292;&#23427;&#33021;&#22815;&#22312;&#19968;&#23450;&#30340;&#22122;&#22768;&#21442;&#25968;&#33539;&#22260;&#20869;&#36798;&#21040;&#36739;&#20302;&#30340;&#26631;&#31614;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.15411</link><description>&lt;p&gt;
&#39640;&#25928;&#30340;&#24102;&#26377;Tsybakov&#22122;&#22768;&#30340;&#21322;&#31354;&#38388;&#20027;&#21160;&#23398;&#20064;&#65306;&#19968;&#31181;&#38750;&#20984;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient Active Learning Halfspaces with Tsybakov Noise: A Non-convex Optimization Approach. (arXiv:2310.15411v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15411
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32467;&#26500;&#21270;&#26080;&#26631;&#31614;&#25968;&#25454;&#20998;&#24067;&#19979;&#65292;&#23545;&#20110;&#20855;&#26377;Tsybakov&#22122;&#22768;&#30340;$d$&#32500;&#21322;&#31354;&#38388;&#65292;&#35745;&#31639;&#21644;&#26631;&#31614;&#30340;&#39640;&#25928;PAC&#20027;&#21160;&#23398;&#20064;&#38382;&#39064;&#12290;&#36890;&#36807;&#35774;&#35745;&#19968;&#31181;&#22522;&#20110;&#38750;&#20984;&#20248;&#21270;&#30340;&#31639;&#27861;&#65292;&#23427;&#33021;&#22815;&#22312;&#19968;&#23450;&#30340;&#22122;&#22768;&#21442;&#25968;&#33539;&#22260;&#20869;&#36798;&#21040;&#36739;&#20302;&#30340;&#26631;&#31614;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32467;&#26500;&#21270;&#26080;&#26631;&#31614;&#25968;&#25454;&#20998;&#24067;&#19979;&#65292;&#23545;&#20110;&#20855;&#26377;Tsybakov&#22122;&#22768;&#30340;$d$&#32500;&#21322;&#31354;&#38388;&#65292;&#35745;&#31639;&#21644;&#26631;&#31614;&#30340;&#39640;&#25928;PAC&#20027;&#21160;&#23398;&#20064;&#38382;&#39064;&#12290;&#21463;&#21040;\cite{diakonikolas2020learning}&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24179;&#28369;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#30340;&#20219;&#20309;&#36817;&#20284;&#19968;&#38454;&#31283;&#23450;&#28857;&#37117;&#20250;&#20135;&#29983;&#19968;&#20010;&#20855;&#26377;&#20302;&#36807;&#37327;&#35823;&#24046;&#20445;&#35777;&#30340;&#21322;&#31354;&#38388;&#12290;&#26681;&#25454;&#19978;&#36848;&#32467;&#26500;&#24615;&#32467;&#26524;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#22522;&#20110;&#38750;&#20984;&#20248;&#21270;&#30340;&#31639;&#27861;&#65292;&#20854;&#26631;&#31614;&#22797;&#26434;&#24230;&#20026;$\tilde{O}(d (\frac{1}{\epsilon})^{\frac{8-6\alpha}{3\alpha-1}})$&#65292;&#22312;Tsybakov&#22122;&#22768;&#21442;&#25968;$\alpha \in (\frac13, 1]$&#30340;&#20551;&#35774;&#19979;&#65292;&#36825;&#32553;&#23567;&#20102;&#20808;&#21069;&#24050;&#30693;&#30340;&#39640;&#25928;&#34987;&#21160;&#25110;&#20027;&#21160;&#31639;&#27861;&#30340;&#26631;&#31614;&#22797;&#26434;&#24230;&#38388;&#38548;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of computationally and label efficient PAC active learning $d$-dimensional halfspaces with Tsybakov Noise~\citep{tsybakov2004optimal} under structured unlabeled data distributions. Inspired by~\cite{diakonikolas2020learning}, we prove that any approximate first-order stationary point of a smooth nonconvex loss function yields a halfspace with a low excess error guarantee. In light of the above structural result, we design a nonconvex optimization-based algorithm with a label complexity of $\tilde{O}(d (\frac{1}{\epsilon})^{\frac{8-6\alpha}{3\alpha-1}})$\footnote{In the main body of this work, we use $\tilde{O}(\cdot), \tilde{\Theta}(\cdot)$ to hide factors of the form $\polylog(d, \frac{1}{\epsilon}, \frac{1}{\delta})$}, under the assumption that the Tsybakov noise parameter $\alpha \in (\frac13, 1]$, which narrows down the gap between the label complexities of the previously known efficient passive or active algorithms~\citep{diakonikolas2020polynomial,zhang2021im
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#21033;&#29992;Talagrand&#19981;&#31561;&#24335;&#21644;Borel-Cantelli&#24341;&#29702;&#65292;&#24314;&#31435;&#20102;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#30340;&#35823;&#24046;&#32039;&#33268;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#25552;&#20379;&#20102;&#25913;&#36827;&#30340;&#25910;&#25947;&#36895;&#24230;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.15387</link><description>&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;&#35823;&#24046;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Error analysis of generative adversarial network. (arXiv:2310.15387v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15387
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#21033;&#29992;Talagrand&#19981;&#31561;&#24335;&#21644;Borel-Cantelli&#24341;&#29702;&#65292;&#24314;&#31435;&#20102;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#30340;&#35823;&#24046;&#32039;&#33268;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#25552;&#20379;&#20102;&#25913;&#36827;&#30340;&#25910;&#25947;&#36895;&#24230;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#26159;&#36817;&#24180;&#26469;&#29992;&#20110;&#39640;&#32500;&#20998;&#24067;&#23398;&#20064;&#30340;&#37325;&#35201;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#24613;&#38656;&#19968;&#31181;&#20840;&#38754;&#30340;&#26041;&#27861;&#26469;&#29702;&#35299;&#20854;&#35823;&#24046;&#25910;&#25947;&#36895;&#24230;&#12290;&#26412;&#30740;&#31350;&#30528;&#37325;&#30740;&#31350;&#22522;&#20110;&#37492;&#21035;&#22120;&#21644;&#29983;&#25104;&#22120;&#31070;&#32463;&#32593;&#32476;&#30340;&#20989;&#25968;&#31867;&#21035;&#26500;&#24314;&#30340;GAN&#27169;&#22411;&#30340;&#35823;&#24046;&#25910;&#25947;&#36895;&#24230;&#12290;&#22312;&#25105;&#20204;&#30340;&#20551;&#35774;&#19979;&#65292;&#36825;&#20123;&#20989;&#25968;&#23646;&#20110;VC&#31867;&#22411;&#65292;&#24182;&#20855;&#26377;&#26377;&#30028;&#20449;&#23553;&#20989;&#25968;&#65292;&#21487;&#20197;&#24212;&#29992;Talagrand&#19981;&#31561;&#24335;&#12290;&#36890;&#36807;&#36816;&#29992;Talagrand&#19981;&#31561;&#24335;&#21644;Borel-Cantelli&#24341;&#29702;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;GAN&#35823;&#24046;&#30340;&#32039;&#33268;&#25910;&#25947;&#36895;&#24230;&#12290;&#35813;&#26041;&#27861;&#36824;&#21487;&#20197;&#24212;&#29992;&#20110;&#29616;&#26377;&#30340;GAN&#35823;&#24046;&#20272;&#35745;&#65292;&#24182;&#33719;&#24471;&#25913;&#36827;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#29305;&#21035;&#26159;&#65292;&#22312;&#25105;&#20204;&#30340;&#23450;&#20041;&#20013;&#65292;&#29992;&#31070;&#32463;&#32593;&#32476;&#36317;&#31163;&#23450;&#20041;&#30340;&#35823;&#24046;&#26159;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
The generative adversarial network (GAN) is an important model developed for high-dimensional distribution learning in recent years. However, there is a pressing need for a comprehensive method to understand its error convergence rate. In this research, we focus on studying the error convergence rate of the GAN model that is based on a class of functions encompassing the discriminator and generator neural networks. These functions are VC type with bounded envelope function under our assumptions, enabling the application of the Talagrand inequality. By employing the Talagrand inequality and Borel-Cantelli lemma, we establish a tight convergence rate for the error of GAN. This method can also be applied on existing error estimations of GAN and yields improved convergence rates. In particular, the error defined with the neural network distance is a special case error in our definition.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20855;&#26377;&#39640;&#27010;&#29575;&#20844;&#24179;&#24615;&#20445;&#35777;&#30340;&#20844;&#24179;&#34920;&#31034;&#23398;&#20064;&#26694;&#26550;&#65288;FRG&#65289;&#65292;&#36890;&#36807;&#29992;&#25143;&#23450;&#20041;&#30340;&#19978;&#30028;&#38480;&#21046;&#65292;&#22312;&#25152;&#26377;&#19979;&#28216;&#27169;&#22411;&#21644;&#20219;&#21153;&#20013;&#20943;&#23569;&#19981;&#20844;&#24179;&#24615;&#12290;&#23454;&#35777;&#35780;&#20272;&#32467;&#26524;&#35777;&#26126;&#20102;FRG&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.15358</link><description>&lt;p&gt;
&#23398;&#20064;&#20855;&#26377;&#39640;&#32622;&#20449;&#24230;&#20445;&#35777;&#30340;&#20844;&#24179;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Learning Fair Representations with High-Confidence Guarantees. (arXiv:2310.15358v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15358
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20855;&#26377;&#39640;&#27010;&#29575;&#20844;&#24179;&#24615;&#20445;&#35777;&#30340;&#20844;&#24179;&#34920;&#31034;&#23398;&#20064;&#26694;&#26550;&#65288;FRG&#65289;&#65292;&#36890;&#36807;&#29992;&#25143;&#23450;&#20041;&#30340;&#19978;&#30028;&#38480;&#21046;&#65292;&#22312;&#25152;&#26377;&#19979;&#28216;&#27169;&#22411;&#21644;&#20219;&#21153;&#20013;&#20943;&#23569;&#19981;&#20844;&#24179;&#24615;&#12290;&#23454;&#35777;&#35780;&#20272;&#32467;&#26524;&#35777;&#26126;&#20102;FRG&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36234;&#26469;&#36234;&#22810;&#22320;&#20351;&#29992;&#34920;&#31034;&#23398;&#20064;&#29983;&#25104;&#36328;&#22810;&#20010;&#19979;&#28216;&#20219;&#21153;&#20855;&#26377;&#39044;&#27979;&#24615;&#30340;&#34920;&#31034;&#12290;&#22240;&#27492;&#65292;&#24320;&#21457;&#33021;&#25552;&#20379;&#24378;&#26377;&#21147;&#20844;&#24179;&#20445;&#35777;&#30340;&#34920;&#31034;&#23398;&#20064;&#31639;&#27861;&#38750;&#24120;&#37325;&#35201;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#38450;&#27490;&#23545;&#24369;&#21183;&#32676;&#20307;&#22312;&#25152;&#26377;&#19979;&#28216;&#39044;&#27979;&#20219;&#21153;&#20013;&#30340;&#19981;&#20844;&#24179;&#24453;&#36935;&#12290;&#20026;&#20102;&#38450;&#27490;&#22312;&#25152;&#26377;&#19979;&#28216;&#20219;&#21153;&#20013;&#23545;&#24369;&#21183;&#32676;&#20307;&#30340;&#19981;&#20844;&#24179;&#24453;&#36935;&#65292;&#25552;&#20379;&#25552;&#20379;&#20844;&#24179;&#20445;&#35777;&#30340;&#34920;&#31034;&#23398;&#20064;&#31639;&#27861;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#24418;&#24335;&#21270;&#23450;&#20041;&#20102;&#23398;&#20064;&#20855;&#26377;&#39640;&#32622;&#20449;&#24230;&#30340;&#20844;&#24179;&#34920;&#31034;&#30340;&#38382;&#39064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#20855;&#26377;&#39640;&#32622;&#20449;&#24230;&#20445;&#35777;&#30340;&#20844;&#24179;&#34920;&#31034;&#23398;&#20064;&#65288;FRG&#65289;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#20197;&#29992;&#25143;&#23450;&#20041;&#30340;&#19978;&#30028;&#20026;&#38480;&#21046;&#65292;&#22312;&#25152;&#26377;&#19979;&#28216;&#27169;&#22411;&#21644;&#20219;&#21153;&#20013;&#38477;&#20302;&#19981;&#20844;&#24179;&#24615;&#65292;&#24182;&#35777;&#26126;FRG&#33021;&#20197;&#39640;&#27010;&#29575;&#20445;&#35777;&#25152;&#26377;&#19979;&#28216;&#27169;&#22411;&#21644;&#20219;&#21153;&#30340;&#20844;&#24179;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#65292;&#35777;&#26126;&#20102;FRG&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Representation learning is increasingly employed to generate representations that are predictive across multiple downstream tasks. The development of representation learning algorithms that provide strong fairness guarantees is thus important because it can prevent unfairness towards disadvantaged groups for all downstream prediction tasks. To prevent unfairness towards disadvantaged groups in all downstream tasks, it is crucial to provide representation learning algorithms that provide fairness guarantees. In this paper, we formally define the problem of learning representations that are fair with high confidence. We then introduce the Fair Representation learning with high-confidence Guarantees (FRG) framework, which provides high-confidence guarantees for limiting unfairness across all downstream models and tasks, with user-defined upper bounds. After proving that FRG ensures fairness for all downstream models and tasks with high probability, we present empirical evaluations that de
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#20351;&#29992;&#38543;&#26426;&#25506;&#32034;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#33021;&#22815;&#23454;&#29616;&#26368;&#20339;&#30340;&#35823;&#24046;&#29575;&#21644;&#26368;&#20248;&#36951;&#25022;&#20445;&#35777;&#12290;&#21516;&#26102;&#65292;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#36890;&#36807;&#38543;&#26426;&#25506;&#32034;&#36991;&#20813;&#20102;&#27599;&#27425;&#36845;&#20195;&#20013;&#38750;&#20984;&#33719;&#21462;&#20989;&#25968;&#30340;&#26114;&#36149;&#20248;&#21270;&#65292;&#20855;&#26377;&#35745;&#31639;&#19978;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2310.15351</link><description>&lt;p&gt;
&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#38543;&#26426;&#25506;&#32034;&#65306;&#26368;&#20339;&#36951;&#25022;&#21644;&#35745;&#31639;&#25928;&#29575;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Random Exploration in Bayesian Optimization: Order-Optimal Regret and Computational Efficiency. (arXiv:2310.15351v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15351
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#20351;&#29992;&#38543;&#26426;&#25506;&#32034;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#33021;&#22815;&#23454;&#29616;&#26368;&#20339;&#30340;&#35823;&#24046;&#29575;&#21644;&#26368;&#20248;&#36951;&#25022;&#20445;&#35777;&#12290;&#21516;&#26102;&#65292;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#36890;&#36807;&#38543;&#26426;&#25506;&#32034;&#36991;&#20813;&#20102;&#27599;&#27425;&#36845;&#20195;&#20013;&#38750;&#20984;&#33719;&#21462;&#20989;&#25968;&#30340;&#26114;&#36149;&#20248;&#21270;&#65292;&#20855;&#26377;&#35745;&#31639;&#19978;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#20063;&#31216;&#20026;&#22522;&#20110;&#26680;&#30340;&#36172;&#21338;&#20248;&#21270;&#12290;&#25105;&#20204;&#30740;&#31350;&#20351;&#29992;&#20174;&#20998;&#24067;&#20013;&#38543;&#26426;&#25277;&#26679;&#26469;&#25506;&#32034;&#39046;&#22495;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#38543;&#26426;&#25506;&#32034;&#26041;&#27861;&#33021;&#22815;&#23454;&#29616;&#26368;&#20339;&#30340;&#35823;&#24046;&#29575;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#22522;&#20110;&#22312;&#26412;&#30740;&#31350;&#20013;&#24314;&#31435;&#30340;&#26080;&#38480;&#32500;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#26032;&#22411;&#38598;&#20013;&#36793;&#30028;&#65292;&#36825;&#21487;&#33021;&#20855;&#26377;&#29420;&#31435;&#30340;&#24847;&#20041;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#25506;&#32034;&#21644;&#39046;&#22495;&#32553;&#23567;&#30340;&#31639;&#27861;&#65292;&#24182;&#22312;&#26080;&#22122;&#22768;&#21644;&#26377;&#22122;&#22768;&#29615;&#22659;&#19979;&#24314;&#31435;&#20854;&#26368;&#20339;&#36951;&#25022;&#20445;&#35777;&#12290;&#22312;&#26080;&#22122;&#22768;&#29615;&#22659;&#20013;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#22635;&#34917;&#20102;&#22312;&#36951;&#25022;&#24615;&#33021;&#26041;&#38754;&#23384;&#22312;&#30340;&#24046;&#36317;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;COLT&#20013;&#30340;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#12290;&#30001;&#20110;&#38543;&#26426;&#25506;&#32034;&#28040;&#38500;&#20102;&#27599;&#27425;&#36845;&#20195;&#20013;&#36873;&#25321;&#26597;&#35810;&#28857;&#30340;&#38750;&#20984;&#33719;&#21462;&#20989;&#25968;&#30340;&#26114;&#36149;&#20248;&#21270;&#65292;&#25152;&#20197;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#20063;&#20855;&#26377;&#35745;&#31639;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider Bayesian optimization using Gaussian Process models, also referred to as kernel-based bandit optimization. We study the methodology of exploring the domain using random samples drawn from a distribution. We show that this random exploration approach achieves the optimal error rates. Our analysis is based on novel concentration bounds in an infinite dimensional Hilbert space established in this work, which may be of independent interest. We further develop an algorithm based on random exploration with domain shrinking and establish its order-optimal regret guarantees under both noise-free and noisy settings. In the noise-free setting, our analysis closes the existing gap in regret performance and thereby resolves a COLT open problem. The proposed algorithm also enjoys a computational advantage over prevailing methods due to the random exploration that obviates the expensive optimization of a non-convex acquisition function for choosing the query points at each iteration.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#24102;&#26377;&#24322;&#26500;&#28151;&#21512;&#27604;&#20363;&#30340;&#28151;&#21512;&#27169;&#22411;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#26032;&#22411;&#32852;&#37030;&#26799;&#24230;EM&#31639;&#27861;&#65292;&#22312;&#36866;&#29992;&#20110;&#26222;&#36890;&#28151;&#21512;&#27169;&#22411;&#30340;&#20840;&#38754;&#26377;&#38480;&#26679;&#26412;&#29702;&#35770;&#22522;&#30784;&#19978;&#65292;&#23545;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65288;GMM&#65289;&#21644;&#28151;&#21512;&#22238;&#24402;&#65288;MoRs&#65289;&#36827;&#34892;&#20102;&#20855;&#20307;&#30340;&#20272;&#35745;&#35823;&#24046;&#20998;&#26512;&#12290;&#35813;&#31639;&#27861;&#20855;&#26377;&#36866;&#24212;&#26410;&#30693;&#20219;&#21153;&#30456;&#20284;&#24615;&#12289;&#25269;&#25239;&#23545;&#23569;&#37096;&#20998;&#25968;&#25454;&#28304;&#30340;&#23545;&#25239;&#25915;&#20987;&#12289;&#20445;&#25252;&#26412;&#22320;&#25968;&#25454;&#38544;&#31169;&#20197;&#21450;&#35745;&#31639;&#21644;&#36890;&#20449;&#25928;&#29575;&#31561;&#20851;&#38190;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2310.15330</link><description>&lt;p&gt;
&#26080;&#30417;&#30563;&#32852;&#37030;&#23398;&#20064;&#65306;&#20855;&#26377;&#23545;&#25239;&#25915;&#20987;&#40065;&#26834;&#24615;&#30340;&#24322;&#26500;&#28151;&#21512;&#27169;&#22411;&#30340;&#32852;&#37030;&#26799;&#24230;EM&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Unsupervised Federated Learning: A Federated Gradient EM Algorithm for Heterogeneous Mixture Models with Robustness against Adversarial Attacks. (arXiv:2310.15330v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15330
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#24102;&#26377;&#24322;&#26500;&#28151;&#21512;&#27604;&#20363;&#30340;&#28151;&#21512;&#27169;&#22411;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#26032;&#22411;&#32852;&#37030;&#26799;&#24230;EM&#31639;&#27861;&#65292;&#22312;&#36866;&#29992;&#20110;&#26222;&#36890;&#28151;&#21512;&#27169;&#22411;&#30340;&#20840;&#38754;&#26377;&#38480;&#26679;&#26412;&#29702;&#35770;&#22522;&#30784;&#19978;&#65292;&#23545;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65288;GMM&#65289;&#21644;&#28151;&#21512;&#22238;&#24402;&#65288;MoRs&#65289;&#36827;&#34892;&#20102;&#20855;&#20307;&#30340;&#20272;&#35745;&#35823;&#24046;&#20998;&#26512;&#12290;&#35813;&#31639;&#27861;&#20855;&#26377;&#36866;&#24212;&#26410;&#30693;&#20219;&#21153;&#30456;&#20284;&#24615;&#12289;&#25269;&#25239;&#23545;&#23569;&#37096;&#20998;&#25968;&#25454;&#28304;&#30340;&#23545;&#25239;&#25915;&#20987;&#12289;&#20445;&#25252;&#26412;&#22320;&#25968;&#25454;&#38544;&#31169;&#20197;&#21450;&#35745;&#31639;&#21644;&#36890;&#20449;&#25928;&#29575;&#31561;&#20851;&#38190;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#26377;&#30417;&#30563;&#30340;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#65292;&#20294;&#26080;&#30417;&#30563;&#30340;&#32852;&#37030;&#23398;&#20064;&#39046;&#22495;&#30456;&#23545;&#36739;&#23569;&#25506;&#32034;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#24102;&#26377;&#24322;&#26500;&#28151;&#21512;&#27604;&#20363;&#30340;&#28151;&#21512;&#27169;&#22411;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#26032;&#22411;&#32852;&#37030;&#26799;&#24230;EM&#31639;&#27861;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#26222;&#36890;&#28151;&#21512;&#27169;&#22411;&#30340;&#20840;&#38754;&#26377;&#38480;&#26679;&#26412;&#29702;&#35770;&#65292;&#28982;&#21518;&#23558;&#36825;&#19968;&#36890;&#29992;&#29702;&#35770;&#24212;&#29992;&#20110;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65288;GMM&#65289;&#21644;&#28151;&#21512;&#22238;&#24402;&#65288;MoRs&#65289;&#20197;&#25551;&#36848;&#27169;&#22411;&#21442;&#25968;&#21644;&#28151;&#21512;&#27604;&#20363;&#30340;&#26174;&#24335;&#20272;&#35745;&#35823;&#24046;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#32852;&#37030;&#26799;&#24230;EM&#31639;&#27861;&#20855;&#26377;&#20197;&#19979;&#20960;&#20010;&#20851;&#38190;&#20248;&#21183;&#65306;&#36866;&#24212;&#26410;&#30693;&#20219;&#21153;&#30456;&#20284;&#24615;&#12289;&#23545;&#23569;&#37096;&#20998;&#25968;&#25454;&#28304;&#30340;&#23545;&#25239;&#25915;&#20987;&#20855;&#26377;&#24377;&#24615;&#12289;&#20445;&#25252;&#26412;&#22320;&#25968;&#25454;&#38544;&#31169;&#20197;&#21450;&#35745;&#31639;&#21644;&#36890;&#20449;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
While supervised federated learning approaches have enjoyed significant success, the domain of unsupervised federated learning remains relatively underexplored. In this paper, we introduce a novel federated gradient EM algorithm designed for the unsupervised learning of mixture models with heterogeneous mixture proportions across tasks. We begin with a comprehensive finite-sample theory that holds for general mixture models, then apply this general theory on Gaussian Mixture Models (GMMs) and Mixture of Regressions (MoRs) to characterize the explicit estimation error of model parameters and mixture proportions. Our proposed federated gradient EM algorithm demonstrates several key advantages: adaptability to unknown task similarity, resilience against adversarial attacks on a small fraction of data sources, protection of local data privacy, and computational and communication efficiency.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36951;&#25022;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#31232;&#30095;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#32467;&#21512;&#21452;&#37325;&#31283;&#20581;&#26041;&#27861;&#21644;&#26032;&#39062;&#30340;&#20998;&#26512;&#25216;&#26415;&#65292;&#20811;&#26381;&#20102;&#20043;&#21069;&#31639;&#27861;&#23545;&#31232;&#30095;&#21442;&#25968;&#21644;&#26410;&#30693;&#31574;&#30053;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2310.15286</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#31232;&#30095;&#24378;&#21270;&#23398;&#20064;&#30340;&#21452;&#37325;&#31283;&#20581;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Doubly Robust Approach to Sparse Reinforcement Learning. (arXiv:2310.15286v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15286
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36951;&#25022;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#31232;&#30095;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#32467;&#21512;&#21452;&#37325;&#31283;&#20581;&#26041;&#27861;&#21644;&#26032;&#39062;&#30340;&#20998;&#26512;&#25216;&#26415;&#65292;&#20811;&#26381;&#20102;&#20043;&#21069;&#31639;&#27861;&#23545;&#31232;&#30095;&#21442;&#25968;&#21644;&#26410;&#30693;&#31574;&#30053;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36951;&#25022;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#29366;&#24577;-&#36716;&#31227;&#20998;&#24067;&#20026;&#35266;&#27979;&#29305;&#24449;&#30340;&#32447;&#24615;&#20989;&#25968;&#30340;&#21608;&#26399;&#24615;&#31232;&#30095;&#32447;&#24615;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;SMDP&#65289;&#12290;&#20043;&#21069;&#24050;&#30693;&#30340;SMDP&#31639;&#27861;&#38656;&#35201;&#30693;&#36947;&#31232;&#30095;&#21442;&#25968;&#24182;&#33021;&#22815;&#35775;&#38382;&#26410;&#30693;&#31574;&#30053;&#30340;oracle&#12290;&#25105;&#20204;&#36890;&#36807;&#32467;&#21512;&#21452;&#37325;&#31283;&#20581;&#26041;&#27861;&#20801;&#35768;&#20351;&#29992;\emph{&#25152;&#26377;}&#21160;&#20316;&#30340;&#29305;&#24449;&#21521;&#37327;&#21644;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#26512;&#25216;&#26415;&#26469;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#12290;&#35813;&#31639;&#27861;&#30340;&#36951;&#25022;&#26159;$\tilde{O}(\sigma^{-1}_{\min} s_{\star} H \sqrt{N})$&#65292;&#20854;&#20013;$\sigma_{\min}$&#34920;&#31034;&#29305;&#24449;&#21521;&#37327;&#30340;&#24179;&#22343;Gram&#30697;&#38453;&#30340;&#26368;&#23567;&#29305;&#24449;&#20540;&#65292;$s_\star$&#26159;&#31232;&#30095;&#21442;&#25968;&#65292;$H$&#26159;&#19968;&#20010;&#21608;&#26399;&#30340;&#38271;&#24230;&#65292;$N$&#26159;&#22238;&#21512;&#25968;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#21305;&#37197;&#19978;&#30028;&#30340;&#36951;&#25022;&#19979;&#30028;&#65292;&#36866;&#29992;&#20110;&#26032;&#35782;&#21035;&#20986;&#30340;SMDP&#23376;&#31867;&#65292;&#23545;&#25968;&#22240;&#23376;&#38500;&#22806;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new regret minimization algorithm for episodic sparse linear Markov decision process (SMDP) where the state-transition distribution is a linear function of observed features. The only previously known algorithm for SMDP requires the knowledge of the sparsity parameter and oracle access to an unknown policy. We overcome these limitations by combining the doubly robust method that allows one to use feature vectors of \emph{all} actions with a novel analysis technique that enables the algorithm to use data from all periods in all episodes. The regret of the proposed algorithm is $\tilde{O}(\sigma^{-1}_{\min} s_{\star} H \sqrt{N})$, where $\sigma_{\min}$ denotes the restrictive the minimum eigenvalue of the average Gram matrix of feature vectors, $s_\star$ is the sparsity parameter, $H$ is the length of an episode, and $N$ is the number of rounds. We provide a lower regret bound that matches the upper bound up to logarithmic factors on a newly identified subclass of SMDPs. Our
&lt;/p&gt;</description></item><item><title>UncertaintyPlayground&#26159;&#19968;&#27454;&#22522;&#20110;PyTorch&#21644;GPyTorch&#30340;Python&#24211;&#65292;&#21487;&#20197;&#24555;&#36895;&#36827;&#34892;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#21644;&#21487;&#35270;&#21270;&#39044;&#27979;&#21306;&#38388;&#65292;&#24182;&#25552;&#20379;&#20102;&#22810;&#31181;&#36895;&#24230;&#20248;&#21270;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2310.15281</link><description>&lt;p&gt;
UncertaintyPlayground: &#19968;&#27454;&#24555;&#36895;&#31616;&#21270;&#30340;&#29992;&#20110;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;Python&#24211;
&lt;/p&gt;
&lt;p&gt;
UncertaintyPlayground: A Fast and Simplified Python Library for Uncertainty Estimation. (arXiv:2310.15281v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15281
&lt;/p&gt;
&lt;p&gt;
UncertaintyPlayground&#26159;&#19968;&#27454;&#22522;&#20110;PyTorch&#21644;GPyTorch&#30340;Python&#24211;&#65292;&#21487;&#20197;&#24555;&#36895;&#36827;&#34892;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#21644;&#21487;&#35270;&#21270;&#39044;&#27979;&#21306;&#38388;&#65292;&#24182;&#25552;&#20379;&#20102;&#22810;&#31181;&#36895;&#24230;&#20248;&#21270;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;UncertaintyPlayground&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;PyTorch&#21644;GPyTorch&#26500;&#24314;&#30340;Python&#24211;&#65292;&#29992;&#20110;&#22312;&#30417;&#30563;&#23398;&#20064;&#20219;&#21153;&#20013;&#36827;&#34892;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#35813;&#24211;&#36890;&#36807;&#31232;&#30095;&#21644;&#21464;&#20998;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#65288;SVGPR&#65289;&#29992;&#20110;&#27491;&#24577;&#20998;&#24067;&#32467;&#26524;&#21644;&#28151;&#21512;&#23494;&#24230;&#32593;&#32476;&#65288;MDN&#65289;&#29992;&#20110;&#28151;&#21512;&#20998;&#24067;&#65292;&#25552;&#20379;&#20102;&#39640;&#26031;&#21644;&#22810;&#27169;&#24577;&#32467;&#26524;&#20998;&#24067;&#30340;&#24555;&#36895;&#35757;&#32451;&#12290;&#38500;&#20102;&#20351;&#29992;&#19981;&#21516;&#36229;&#21442;&#25968;&#36827;&#34892;&#27169;&#22411;&#35757;&#32451;&#22806;&#65292;UncertaintyPlayground&#36824;&#21487;&#20197;&#21487;&#35270;&#21270;&#19968;&#20010;&#25110;&#22810;&#20010;&#23454;&#20363;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;&#30001;&#20110;&#20351;&#29992;&#20102;&#24352;&#37327;&#25805;&#20316;&#65292;&#35813;&#24211;&#21487;&#20197;&#22312;CPU&#21644;GPU&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#24182;&#25552;&#20379;&#21508;&#31181;PyTorch&#29305;&#23450;&#30340;&#36895;&#24230;&#20248;&#21270;&#25216;&#26415;&#12290;&#35813;&#24211;&#21253;&#21547;&#27599;&#20010;&#27169;&#22359;&#30340;&#21333;&#20803;&#27979;&#35797;&#65292;&#24182;&#36890;&#36807;GitHub Workflows&#65288;&#22312;&#32447;&#38598;&#25104;&#65289;&#21644;Tox&#65288;&#26412;&#22320;&#38598;&#25104;&#65289;&#30830;&#20445;&#22810;&#24179;&#21488;&#25345;&#32493;&#38598;&#25104;&#12290;&#26368;&#21518;&#65292;&#20195;&#30721;&#20351;&#29992;&#20102;Google&#39118;&#26684;&#30340;&#25991;&#26723;&#23383;&#31526;&#20018;&#65292;&#24182;&#25552;&#20379;&#20102;&#20351;&#29992;MkDocs&#21644;MkDocStrings&#21019;&#24314;&#30340;&#25991;&#26723;&#32593;&#31449;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces UncertaintyPlayground, a Python library built on PyTorch and GPyTorch for uncertainty estimation in supervised learning tasks. The library offers fast training for Gaussian and multi-modal outcome distributions through Sparse and Variational Gaussian Process Regressions (SVGPRs) for normally distributed outcomes and Mixed Density Networks (MDN) for mixed distributions. In addition to model training with various hyperparameters, UncertaintyPlayground can visualize the prediction intervals of one or more instances. Due to using tensor operations, the library can be trained both on CPU and GPU and offers various PyTorch-specific techniques for speed optimization. The library contains unit tests for each module and ensures multi-platform continuous integration with GitHub Workflows (online integration) and Tox (local integration). Finally, the code is documented with Google-style docstrings and offers a documentation website created with MkDocs and MkDocStrings.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#35757;&#32451;&#39640;&#36136;&#37327;AI&#21161;&#25163;&#30340;&#25216;&#26415;&#65292;&#21457;&#29616;&#36825;&#31181;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#22312;&#22238;&#31572;&#38382;&#39064;&#26102;&#36807;&#20110;&#35844;&#23194;&#65292;&#32780;&#19981;&#26159;&#22374;&#35802;&#65292;&#36890;&#36807;&#20998;&#26512;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#24471;&#20986;&#20102;&#36825;&#19968;&#32467;&#35770;&#12290;</title><link>http://arxiv.org/abs/2310.13548</link><description>&lt;p&gt;
&#25506;&#32034;&#35821;&#35328;&#27169;&#22411;&#20013;&#35844;&#23194;&#34892;&#20026;&#30340;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Towards Understanding Sycophancy in Language Models. (arXiv:2310.13548v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13548
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#35757;&#32451;&#39640;&#36136;&#37327;AI&#21161;&#25163;&#30340;&#25216;&#26415;&#65292;&#21457;&#29616;&#36825;&#31181;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#22312;&#22238;&#31572;&#38382;&#39064;&#26102;&#36807;&#20110;&#35844;&#23194;&#65292;&#32780;&#19981;&#26159;&#22374;&#35802;&#65292;&#36890;&#36807;&#20998;&#26512;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#24471;&#20986;&#20102;&#36825;&#19968;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#12300;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#36827;&#34892;&#24378;&#21270;&#23398;&#20064;&#65288;RLHF&#65289;&#12301;&#26159;&#35757;&#32451;&#39640;&#36136;&#37327;AI&#21161;&#25163;&#30340;&#19968;&#31181;&#27969;&#34892;&#25216;&#26415;&#12290;&#28982;&#32780;&#65292;RLHF&#21487;&#33021;&#20250;&#40723;&#21169;&#27169;&#22411;&#36890;&#36807;&#19982;&#29992;&#25143;&#20449;&#24565;&#30456;&#31526;&#30340;&#22238;&#31572;&#26469;&#20195;&#26367;&#30495;&#23454;&#22238;&#31572;&#65292;&#36825;&#31181;&#34892;&#20026;&#34987;&#31216;&#20026;&#35844;&#23194;&#34892;&#20026;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;RLHF&#35757;&#32451;&#27169;&#22411;&#20013;&#35844;&#23194;&#34892;&#20026;&#30340;&#26222;&#36941;&#24615;&#20197;&#21450;&#20154;&#31867;&#20559;&#22909;&#21028;&#26029;&#26159;&#21542;&#36215;&#21040;&#20102;&#20316;&#29992;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20116;&#20010;&#26368;&#20808;&#36827;&#30340;AI&#21161;&#25163;&#22312;&#22235;&#20010;&#19981;&#21516;&#30340;&#33258;&#30001;&#25991;&#26412;&#29983;&#25104;&#20219;&#21153;&#20013;&#19968;&#36143;&#34920;&#29616;&#20986;&#35844;&#23194;&#34892;&#20026;&#12290;&#20026;&#20102;&#29702;&#35299;&#20154;&#31867;&#20559;&#22909;&#26159;&#21542;&#39537;&#21160;&#20102;RLHF&#27169;&#22411;&#30340;&#36825;&#31181;&#24191;&#27867;&#34892;&#20026;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#29616;&#26377;&#30340;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#24403;&#22238;&#31572;&#19982;&#29992;&#25143;&#30340;&#35266;&#28857;&#30456;&#31526;&#26102;&#65292;&#23427;&#26356;&#26377;&#21487;&#33021;&#34987;&#36873;&#20013;&#12290;&#27492;&#22806;&#65292;&#20154;&#31867;&#21644;&#20559;&#22909;&#27169;&#22411;&#65288;PMs&#65289;&#23558;&#26377;&#35828;&#26381;&#21147;&#30340;&#35844;&#23194;&#22238;&#31572;&#19982;&#27491;&#30830;&#22238;&#31572;&#30456;&#27604;&#65292;&#26377;&#26102;&#20960;&#20046;&#21487;&#20197;&#24573;&#30053;&#19981;&#35745;&#22320;&#36873;&#25321;&#20102;&#35844;&#23194;&#22238;&#31572;&#12290;&#20248;&#21270;&#27169;&#22411;&#36755;&#20986;&#20197;&#28385;&#36275;PMs&#26377;&#26102;&#20063;&#20250;&#22312;&#30495;&#23454;&#24615;&#21644;&#35844;&#23194;&#34892;&#20026;&#20043;&#38388;&#20570;&#20986;&#21462;&#33293;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning from human feedback (RLHF) is a popular technique for training high-quality AI assistants. However, RLHF may also encourage model responses that match user beliefs over truthful responses, a behavior known as sycophancy. We investigate the prevalence of sycophancy in RLHF-trained models and whether human preference judgements are responsible. We first demonstrate that five state-of-the-art AI assistants consistently exhibit sycophantic behavior across four varied free-form text-generation tasks. To understand if human preferences drive this broadly observed behavior of RLHF models, we analyze existing human preference data. We find that when a response matches a user's views, it is more likely to be preferred. Moreover, both humans and preference models (PMs) prefer convincingly-written sycophantic responses over correct ones a negligible fraction of the time. Optimizing model outputs against PMs also sometimes sacrifices truthfulness in favor of sycophancy. Over
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;&#20013;&#65292;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#20026;&#22522;&#30784;&#30340;&#20195;&#29702;&#27169;&#22411;&#65292;&#20197;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#21644;&#22788;&#29702;&#25968;&#20540;&#25361;&#25112;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.12046</link><description>&lt;p&gt;
&#20197;&#26426;&#22120;&#23398;&#20064;&#20026;&#22522;&#30784;&#30340;&#20195;&#29702;&#27169;&#22411;&#22312;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;&#26041;&#27861;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Applications of ML-Based Surrogates in Bayesian Approaches to Inverse Problems. (arXiv:2310.12046v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12046
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;&#20013;&#65292;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#20026;&#22522;&#30784;&#30340;&#20195;&#29702;&#27169;&#22411;&#65292;&#20197;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#21644;&#22788;&#29702;&#25968;&#20540;&#25361;&#25112;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#24050;&#25104;&#20026;&#19968;&#31181;&#24378;&#22823;&#30340;&#24037;&#20855;&#65292;&#20316;&#20026;&#20195;&#29702;&#27169;&#22411;&#65292;&#22312;&#22686;&#21152;&#35745;&#31639;&#25928;&#29575;&#30340;&#21516;&#26102;&#20026;&#31185;&#23398;&#38382;&#39064;&#25552;&#20379;&#25968;&#20540;&#35299;&#12290;&#36825;&#31181;&#25928;&#29575;&#22312;&#26102;&#38388;&#33267;&#20851;&#37325;&#35201;&#30340;&#25968;&#20540;&#25361;&#25112;&#38382;&#39064;&#25110;&#38656;&#35201;&#35780;&#20272;&#35768;&#22810;&#31867;&#20284;&#20998;&#26512;&#26041;&#26696;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#20248;&#21183;&#12290;&#19968;&#20010;&#29305;&#23450;&#30340;&#31185;&#23398;&#20852;&#36259;&#39046;&#22495;&#26159;&#36870;&#38382;&#39064;&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;&#25105;&#20204;&#30693;&#36947;&#31995;&#32479;&#30340;&#27491;&#21521;&#21160;&#24577;&#30001;&#20559;&#24494;&#20998;&#26041;&#31243;&#25551;&#36848;&#65292;&#20219;&#21153;&#26159;&#26681;&#25454;&#36825;&#20123;&#21160;&#24577;&#30340;&#65288;&#28508;&#22312;&#26377;&#22122;&#22768;&#30340;&#65289;&#35266;&#27979;&#26469;&#25512;&#26029;&#31995;&#32479;&#30340;&#24615;&#36136;&#12290;&#25105;&#20204;&#32771;&#34385;&#25512;&#26029;&#32473;&#23450;2D&#22768;&#27874;&#26041;&#31243;&#30340;&#22024;&#26434;&#35299;&#30340;&#26041;&#22359;&#22495;&#20013;&#27874;&#28304;&#30340;&#20301;&#32622;&#30340;&#36870;&#38382;&#39064;&#12290;&#22312;&#20551;&#35774;&#20026;&#39640;&#26031;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#26500;&#36896;&#28304;&#20301;&#32622;&#30340;&#20284;&#28982;&#20989;&#25968;&#65292;&#27599;&#20010;&#35780;&#20272;&#37117;&#38656;&#35201;&#23545;&#31995;&#32479;&#36827;&#34892;&#19968;&#27425;&#27491;&#21521;&#27169;&#25311;&#12290;&#20351;&#29992;&#26631;&#20934;&#30340;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#20195;&#29702;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Neural networks have become a powerful tool as surrogate models to provide numerical solutions for scientific problems with increased computational efficiency. This efficiency can be advantageous for numerically challenging problems where time to solution is important or when evaluation of many similar analysis scenarios is required. One particular area of scientific interest is the setting of inverse problems, where one knows the forward dynamics of a system are described by a partial differential equation and the task is to infer properties of the system given (potentially noisy) observations of these dynamics. We consider the inverse problem of inferring the location of a wave source on a square domain, given a noisy solution to the 2-D acoustic wave equation. Under the assumption of Gaussian noise, a likelihood function for source location can be formulated, which requires one forward simulation of the system per evaluation. Using a standard neural network as a surrogate model make
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#32452;&#32553;&#25918;&#26041;&#27861;&#65288;BVS&#65289;&#30340;&#20960;&#31181;&#25913;&#36827;&#26041;&#27861;&#65292;&#25506;&#32034;&#20102;&#20351;&#29992;&#26367;&#20195;&#25439;&#22833;&#20989;&#25968;&#21644;&#22522;&#20110;&#36755;&#20837;&#29305;&#24449;&#30340;&#20998;&#32452;&#26041;&#26696;&#26469;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#19968;&#33268;&#24615;&#21644;&#36866;&#24212;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.11978</link><description>&lt;p&gt;
&#21487;&#20197;&#36890;&#36807;&#20998;&#32452;&#32553;&#25918;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#19968;&#33268;&#24615;&#21644;&#36866;&#24212;&#24615;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can bin-wise scaling improve consistency and adaptivity of prediction uncertainty for machine learning regression ?. (arXiv:2310.11978v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11978
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#32452;&#32553;&#25918;&#26041;&#27861;&#65288;BVS&#65289;&#30340;&#20960;&#31181;&#25913;&#36827;&#26041;&#27861;&#65292;&#25506;&#32034;&#20102;&#20351;&#29992;&#26367;&#20195;&#25439;&#22833;&#20989;&#25968;&#21644;&#22522;&#20110;&#36755;&#20837;&#29305;&#24449;&#30340;&#20998;&#32452;&#26041;&#26696;&#26469;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#19968;&#33268;&#24615;&#21644;&#36866;&#24212;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#20998;&#32452;&#26041;&#24046;&#32553;&#25918;&#65288;BVS&#65289;&#34987;&#25552;&#20986;&#20316;&#20026;&#19968;&#31181;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#38382;&#39064;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#20107;&#21518;&#26657;&#20934;&#26041;&#27861;&#65292;&#33021;&#22815;&#27604;&#32479;&#19968;&#26041;&#24046;&#65288;&#25110;&#28201;&#24230;&#65289;&#32553;&#25918;&#26356;&#26377;&#25928;&#22320;&#36827;&#34892;&#26657;&#27491;&#12290;&#21407;&#22987;&#29256;&#26412;&#30340;BVS&#20351;&#29992;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#20998;&#32452;&#65292;&#26088;&#22312;&#25552;&#39640;&#26465;&#20214;&#19978;&#30340;&#26657;&#20934;&#24615;&#65292;&#21363;&#19968;&#33268;&#24615;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;BVS&#30340;&#20960;&#31181;&#25913;&#36827;&#26041;&#27861;&#65292;&#29305;&#21035;&#26159;&#22312;&#25439;&#22833;&#20989;&#25968;&#21644;&#22522;&#20110;&#36755;&#20837;&#29305;&#24449;&#65288;X&#65289;&#30340;&#20998;&#32452;&#26041;&#26696;&#19978;&#36827;&#34892;&#25913;&#36827;&#65292;&#20197;&#25552;&#39640;&#36866;&#24212;&#24615;&#65292;&#21363;&#22312;&#32473;&#23450;X&#30340;&#26465;&#20214;&#19979;&#36827;&#34892;&#26657;&#20934;&#24615;&#12290;&#23558;BVS&#21450;&#20854;&#25913;&#36827;&#26041;&#26696;&#22312;&#39044;&#27979;&#21407;&#23376;&#21270;&#33021;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24615;&#33021;&#27979;&#35797;&#65292;&#24182;&#19982;&#20445;&#24207;&#22238;&#24402;&#30340;&#32467;&#26524;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Binwise Variance Scaling (BVS) has recently been proposed as a post hoc recalibration method for prediction uncertainties of machine learning regression problems that is able of more efficient corrections than uniform variance (or temperature) scaling. The original version of BVS uses uncertainty-based binning, which is aimed to improve calibration conditionally on uncertainty, i.e. consistency. I explore here several adaptations of BVS, in particular with alternative loss functions and a binning scheme based on an input-feature (X) in order to improve adaptivity, i.e. calibration conditional on X. The performances of BVS and its proposed variants are tested on a benchmark dataset for the prediction of atomization energies and compared to the results of isotonic regression.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25506;&#35752;&#20102;&#23558;&#28201;&#24230;&#21442;&#25968;&#32435;&#20837;&#36125;&#21494;&#26031;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#19968;&#33268;&#39044;&#27979;&#20013;&#30340;&#20248;&#21183;&#65292;&#20197;&#25552;&#20379;&#26377;&#25928;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;</title><link>http://arxiv.org/abs/2310.11479</link><description>&lt;p&gt;
&#20851;&#20110;&#36125;&#21494;&#26031;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#19968;&#33268;&#39044;&#27979;&#20013;&#30340;&#28201;&#24230;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
On the Temperature of Bayesian Graph Neural Networks for Conformal Prediction. (arXiv:2310.11479v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11479
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25506;&#35752;&#20102;&#23558;&#28201;&#24230;&#21442;&#25968;&#32435;&#20837;&#36125;&#21494;&#26031;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#19968;&#33268;&#39044;&#27979;&#20013;&#30340;&#20248;&#21183;&#65292;&#20197;&#25552;&#20379;&#26377;&#25928;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20934;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#23545;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;(GNNs)&#33267;&#20851;&#37325;&#35201;&#65292;&#29305;&#21035;&#26159;&#22312;&#39640;&#39118;&#38505;&#39046;&#22495;&#20013;&#32463;&#24120;&#20351;&#29992;GNNs&#30340;&#24773;&#20917;&#19979;&#12290;&#19968;&#33268;&#39044;&#27979;(CP)&#20026;&#20219;&#20309;&#40657;&#30418;&#27169;&#22411;&#25552;&#20379;&#20102;&#19968;&#20010;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#30340;&#26377;&#21069;&#36884;&#30340;&#26694;&#26550;&#12290;CP&#20445;&#35777;&#20102;&#19968;&#20010;&#39044;&#27979;&#38598;&#20197;&#25152;&#38656;&#30340;&#27010;&#29575;&#21253;&#21547;&#30495;&#23454;&#26631;&#31614;&#30340;&#24418;&#24335;&#30340;&#23448;&#26041;&#27010;&#29575;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#39044;&#27979;&#38598;&#30340;&#22823;&#23567;&#65292;&#21363;"&#20302;&#25928;&#29575;"&#65292;&#21463;&#21040;&#24213;&#23618;&#27169;&#22411;&#21644;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#24433;&#21709;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#36125;&#21494;&#26031;&#23398;&#20064;&#36824;&#22522;&#20110;&#20272;&#35745;&#30340;&#21518;&#39564;&#20998;&#24067;&#25552;&#20379;&#19968;&#20010;&#21487;&#20449;&#21306;&#22495;&#65292;&#20294;&#21482;&#26377;&#22312;&#27169;&#22411;&#27491;&#30830;&#25351;&#23450;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#20010;&#21306;&#22495;&#25165;&#26159;"&#33391;&#22909;&#26657;&#20934;"&#30340;&#12290;&#22312;&#19968;&#20010;&#26368;&#36817;&#30340;&#24037;&#20316;&#30340;&#22522;&#30784;&#19978;&#65292;&#35813;&#24037;&#20316;&#24341;&#20837;&#20102;&#19968;&#20010;&#32553;&#25918;&#21442;&#25968;&#65292;&#29992;&#20110;&#20174;&#21518;&#39564;&#20272;&#35745;&#20013;&#26500;&#24314;&#26377;&#25928;&#30340;&#21487;&#20449;&#21306;&#22495;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;CP&#26694;&#26550;&#20013;&#23558;&#19968;&#20010;&#28201;&#24230;&#21442;&#25968;&#32435;&#20837;&#36125;&#21494;&#26031;GNNs&#20013;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Accurate uncertainty quantification in graph neural networks (GNNs) is essential, especially in high-stakes domains where GNNs are frequently employed. Conformal prediction (CP) offers a promising framework for quantifying uncertainty by providing $\textit{valid}$ prediction sets for any black-box model. CP ensures formal probabilistic guarantees that a prediction set contains a true label with a desired probability. However, the size of prediction sets, known as $\textit{inefficiency}$, is influenced by the underlying model and data generating process. On the other hand, Bayesian learning also provides a credible region based on the estimated posterior distribution, but this region is $\textit{well-calibrated}$ only when the model is correctly specified. Building on a recent work that introduced a scaling parameter for constructing valid credible regions from posterior estimate, our study explores the advantages of incorporating a temperature parameter into Bayesian GNNs within CP fra
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#39640;&#33021;&#30005;&#23376;-&#27491;&#30005;&#23376;&#30896;&#25758;&#20013;&#30340;&#31890;&#23376;&#27969;&#37325;&#24314;&#65292;&#20351;&#29992;&#21487;&#25193;&#23637;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#36229;&#21442;&#25968;&#35843;&#20248;&#21644;&#30828;&#20214;&#22788;&#29702;&#22120;&#30340;&#39640;&#24230;&#21487;&#31227;&#26893;&#24615;&#65292;&#21462;&#24471;&#20102;&#30495;&#23454;&#19988;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#29289;&#29702;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.06782</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#21644;&#21315;&#20806;&#32423;&#25968;&#25454;&#38598;&#29992;&#20110;&#31890;&#23376;&#27969;&#37325;&#24314;
&lt;/p&gt;
&lt;p&gt;
Scalable neural network models and terascale datasets for particle-flow reconstruction. (arXiv:2309.06782v1 [physics.data-an])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06782
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#39640;&#33021;&#30005;&#23376;-&#27491;&#30005;&#23376;&#30896;&#25758;&#20013;&#30340;&#31890;&#23376;&#27969;&#37325;&#24314;&#65292;&#20351;&#29992;&#21487;&#25193;&#23637;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#36229;&#21442;&#25968;&#35843;&#20248;&#21644;&#30828;&#20214;&#22788;&#29702;&#22120;&#30340;&#39640;&#24230;&#21487;&#31227;&#26893;&#24615;&#65292;&#21462;&#24471;&#20102;&#30495;&#23454;&#19988;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#29289;&#29702;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#39640;&#33021;&#30005;&#23376;-&#27491;&#30005;&#23376;&#30896;&#25758;&#20013;&#22522;&#20110;&#39640;&#24230;&#31890;&#24230;&#25506;&#27979;&#22120;&#27169;&#25311;&#30340;&#23436;&#25972;&#20107;&#20214;&#37325;&#24314;&#65292;&#30740;&#31350;&#20102;&#21487;&#25193;&#23637;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;&#31890;&#23376;&#27969;&#65288;PF&#65289;&#37325;&#24314;&#21487;&#36890;&#36807;&#36319;&#36394;&#21644;&#37327;&#33021;&#22120;&#22242;&#31751;&#25110;&#20987;&#20013;&#26469;&#26500;&#24314;&#30417;&#30563;&#23398;&#20064;&#20219;&#21153;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#21644;&#22522;&#20110;&#20869;&#26680;&#30340;&#21464;&#25442;&#22120;&#65292;&#24182;&#35777;&#26126;&#20004;&#32773;&#37117;&#36991;&#20813;&#20102;&#20108;&#27425;&#20869;&#23384;&#20998;&#37197;&#21644;&#35745;&#31639;&#25104;&#26412;&#65292;&#21516;&#26102;&#23454;&#29616;&#20102;&#30495;&#23454;&#30340;&#31890;&#23376;&#27969;&#37325;&#24314;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#36229;&#32423;&#35745;&#31639;&#26426;&#19978;&#36827;&#34892;&#30340;&#36229;&#21442;&#25968;&#35843;&#20248;&#26174;&#33879;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#29289;&#29702;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#25152;&#24471;&#27169;&#22411;&#22312;&#30828;&#20214;&#22788;&#29702;&#22120;&#19978;&#20855;&#26377;&#39640;&#24230;&#21487;&#31227;&#26893;&#24615;&#65292;&#25903;&#25345;NVIDIA, AMD&#21644;&#33521;&#29305;&#23572; Habana&#21345;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#27169;&#22411;&#21487;&#20197;&#22312;&#30001;&#36319;&#36394;&#21644;&#37327;&#33021;&#22120;&#20987;&#20013;&#32452;&#25104;&#30340;&#39640;&#31890;&#24230;&#36755;&#20837;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#20174;&#32780;&#33719;&#24471;&#19982;&#22522;&#20934;&#30456;&#31454;&#20105;&#30340;&#29289;&#29702;&#24615;&#33021;&#12290;&#26377;&#20851;&#22797;&#29616;&#30740;&#31350;&#30340;&#25968;&#25454;&#38598;&#21644;&#36719;&#20214;&#24050;&#21457;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study scalable machine learning models for full event reconstruction in high-energy electron-positron collisions based on a highly granular detector simulation. Particle-flow (PF) reconstruction can be formulated as a supervised learning task using tracks and calorimeter clusters or hits. We compare a graph neural network and kernel-based transformer and demonstrate that both avoid quadratic memory allocation and computational cost while achieving realistic PF reconstruction. We show that hyperparameter tuning on a supercomputer significantly improves the physics performance of the models. We also demonstrate that the resulting model is highly portable across hardware processors, supporting Nvidia, AMD, and Intel Habana cards. Finally, we demonstrate that the model can be trained on highly granular inputs consisting of tracks and calorimeter hits, resulting in a competitive physics performance with the baseline. Datasets and software to reproduce the studies are published following 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#24191;&#20041;&#27748;&#26222;&#26862;&#25277;&#26679;&#25506;&#32034;&#31639;&#27861;&#65292;&#33021;&#22815;&#35299;&#20915;&#22810;&#33218;&#32769;&#34382;&#26426;&#23454;&#20540;&#32452;&#21512;&#32431;&#25506;&#32034;&#38382;&#39064;&#20013;&#21160;&#20316;&#38598;&#21512;&#22823;&#23567;&#20026;&#25351;&#25968;&#32423;&#21035;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2308.10238</link><description>&lt;p&gt;
Thompson Sampling&#29992;&#20110;&#22810;&#33218;&#32769;&#34382;&#26426;&#30340;&#23454;&#20540;&#32452;&#21512;&#32431;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Thompson Sampling for Real-Valued Combinatorial Pure Exploration of Multi-Armed Bandit. (arXiv:2308.10238v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10238
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#24191;&#20041;&#27748;&#26222;&#26862;&#25277;&#26679;&#25506;&#32034;&#31639;&#27861;&#65292;&#33021;&#22815;&#35299;&#20915;&#22810;&#33218;&#32769;&#34382;&#26426;&#23454;&#20540;&#32452;&#21512;&#32431;&#25506;&#32034;&#38382;&#39064;&#20013;&#21160;&#20316;&#38598;&#21512;&#22823;&#23567;&#20026;&#25351;&#25968;&#32423;&#21035;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22810;&#33218;&#32769;&#34382;&#26426;&#30340;&#23454;&#20540;&#32452;&#21512;&#32431;&#25506;&#32034;&#65288;R-CPE-MAB&#65289;&#38382;&#39064;&#12290;&#22312;R-CPE-MAB&#20013;&#65292;&#29609;&#23478;&#20174;&#32473;&#23450;&#30340;d&#20010;&#38543;&#26426;&#33218;&#20013;&#36873;&#25321;&#19968;&#20010;&#65292;&#27599;&#20010;&#33218;s&#30340;&#22870;&#21169;&#36981;&#24490;&#26410;&#30693;&#20998;&#24067;&#65292;&#20854;&#24179;&#22343;&#20540;&#20026;&#956;s&#12290;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#20013;&#65292;&#29609;&#23478;&#25289;&#21160;&#19968;&#20010;&#33218;&#24182;&#35266;&#23519;&#20854;&#22870;&#21169;&#12290;&#29609;&#23478;&#30340;&#30446;&#26631;&#26159;&#20197;&#23613;&#21487;&#33021;&#23569;&#30340;&#33218;&#25289;&#21160;&#27425;&#25968;&#26469;&#30830;&#23450;&#26368;&#20248;&#21160;&#20316;&#960;* = argmax&#960;&#8712;A &#956;T&#960;&#65292;&#20854;&#20013;A&#26159;&#26377;&#38480;&#22823;&#23567;&#30340;&#23454;&#20540;&#21160;&#20316;&#38598;&#21512;&#12290;&#20043;&#21069;&#30340;&#26041;&#27861;&#20551;&#35774;&#21160;&#20316;&#38598;&#21512;A&#30340;&#22823;&#23567;&#22312;d&#30340;&#22810;&#39033;&#24335;&#32423;&#21035;&#19978;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;&#24191;&#20041;&#27748;&#26222;&#26862;&#25277;&#26679;&#25506;&#32034;&#65288;GenTS-Explore&#65289;&#31639;&#27861;&#65292;&#23427;&#26159;&#31532;&#19968;&#20010;&#21487;&#20197;&#35299;&#20915;&#21160;&#20316;&#38598;&#21512;&#22823;&#23567;&#22312;d&#30340;&#25351;&#25968;&#32423;&#21035;&#19978;&#30340;&#31639;&#27861;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#38382;&#39064;&#30456;&#20851;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the real-valued combinatorial pure exploration of the multi-armed bandit (R-CPE-MAB) problem. In R-CPE-MAB, a player is given $d$ stochastic arms, and the reward of each arm $s\in\{1, \ldots, d\}$ follows an unknown distribution with mean $\mu_s$. In each time step, a player pulls a single arm and observes its reward. The player's goal is to identify the optimal \emph{action} $\boldsymbol{\pi}^{*} = \argmax_{\boldsymbol{\pi} \in \mathcal{A}} \boldsymbol{\mu}^{\top}\boldsymbol{\pi}$ from a finite-sized real-valued \emph{action set} $\mathcal{A}\subset \mathbb{R}^{d}$ with as few arm pulls as possible. Previous methods in the R-CPE-MAB assume that the size of the action set $\mathcal{A}$ is polynomial in $d$. We introduce an algorithm named the Generalized Thompson Sampling Explore (GenTS-Explore) algorithm, which is the first algorithm that can work even when the size of the action set is exponentially large in $d$. We also introduce a novel problem-dependent sample complexity 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20197;&#30315;&#30187;&#39044;&#27979;&#20026;&#30446;&#26631;&#65292;&#36890;&#36807;&#33258;&#21160;&#21457;&#29616;&#21644;&#37327;&#21270;&#24739;&#32773;&#29305;&#23450;&#30340;&#32479;&#35745;&#29305;&#24449;&#65292;&#29305;&#21035;&#26159;&#26368;&#26032;&#30340;&#36335;&#24452;&#31614;&#21517;&#31639;&#27861;&#65292;&#25506;&#32034;&#20854;&#22312;&#30315;&#30187;&#39044;&#27979;&#20013;&#30340;&#24615;&#33021;&#65292;&#20026;&#20010;&#24615;&#21270;&#30340;&#30315;&#30187;&#39044;&#27979;&#35299;&#20915;&#26041;&#26696;&#25552;&#20379;&#20102;&#21442;&#32771;&#12290;</title><link>http://arxiv.org/abs/2308.09312</link><description>&lt;p&gt;
&#30315;&#30187;&#39044;&#27979;&#20013;&#30340;&#36335;&#24452;&#31614;&#21517;
&lt;/p&gt;
&lt;p&gt;
Path Signatures for Seizure Forecasting. (arXiv:2308.09312v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09312
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20197;&#30315;&#30187;&#39044;&#27979;&#20026;&#30446;&#26631;&#65292;&#36890;&#36807;&#33258;&#21160;&#21457;&#29616;&#21644;&#37327;&#21270;&#24739;&#32773;&#29305;&#23450;&#30340;&#32479;&#35745;&#29305;&#24449;&#65292;&#29305;&#21035;&#26159;&#26368;&#26032;&#30340;&#36335;&#24452;&#31614;&#21517;&#31639;&#27861;&#65292;&#25506;&#32034;&#20854;&#22312;&#30315;&#30187;&#39044;&#27979;&#20013;&#30340;&#24615;&#33021;&#65292;&#20026;&#20010;&#24615;&#21270;&#30340;&#30315;&#30187;&#39044;&#27979;&#35299;&#20915;&#26041;&#26696;&#25552;&#20379;&#20102;&#21442;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#27979;&#21040;&#30340;&#26102;&#38388;&#24207;&#21015;&#20013;&#39044;&#27979;&#31995;&#32479;&#29366;&#24577;&#26159;&#35768;&#22810;&#39046;&#22495;&#65288;&#22914;&#35745;&#31639;&#31070;&#32463;&#31185;&#23398;&#65289;&#30340;&#30740;&#31350;&#35838;&#39064;&#12290;&#22312;&#36825;&#37324;&#65292;&#20174;&#22823;&#33041;&#27979;&#37327;&#20013;&#39044;&#27979;&#30315;&#30187;&#21457;&#20316;&#26159;&#19968;&#20010;&#23578;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#26082;&#27809;&#26377;&#23436;&#25972;&#30340;&#25551;&#36848;&#24213;&#23618;&#22823;&#33041;&#21160;&#24577;&#30340;&#27169;&#22411;&#65292;&#20063;&#27809;&#26377;&#21333;&#20010;&#24739;&#32773;&#34920;&#29616;&#20986;&#21333;&#19968;&#30340;&#30315;&#30187;&#21457;&#20316;&#27169;&#24335;&#65292;&#36825;&#20351;&#24471;&#24320;&#21457;&#8220;&#19968;&#20992;&#20999;&#8221;&#30340;&#35299;&#20915;&#26041;&#26696;&#21464;&#24471;&#22797;&#26434;&#12290;&#22522;&#20110;&#32437;&#21521;&#24739;&#32773;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#33258;&#21160;&#21457;&#29616;&#21644;&#37327;&#21270;&#21487;&#29992;&#20110;&#20197;&#24739;&#32773;&#20026;&#20013;&#24515;&#30340;&#30315;&#30187;&#39044;&#27979;&#30340;&#32479;&#35745;&#29305;&#24449;&#65288;&#29983;&#29289;&#26631;&#24535;&#29289;&#65289;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#29616;&#26377;&#21644;&#26032;&#39062;&#30340;&#29305;&#24449;&#25552;&#21462;&#31639;&#27861;&#65292;&#23588;&#20854;&#26159;&#36335;&#24452;&#31614;&#21517;&#65292;&#21363;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#30340;&#26368;&#26032;&#21457;&#23637;&#12290;&#29305;&#21035;&#20540;&#24471;&#20851;&#27880;&#30340;&#26159;&#65292;&#19982;&#31616;&#21333;&#30340;&#32447;&#24615;&#29305;&#24449;&#30456;&#27604;&#65292;&#36825;&#32452;&#22797;&#26434;&#30340;&#38750;&#32447;&#24615;&#29305;&#24449;&#22312;&#36825;&#20010;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#22914;&#20309;&#12290;&#25105;&#20204;&#30340;&#25512;&#26029;&#22522;&#20110;&#32479;&#35745;&#20998;&#31867;&#31639;&#27861;&#65292;&#24182;&#24102;&#26377;&#20869;&#32622;&#30340;&#23376;&#38598;&#36873;&#25321;&#21151;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Forecasting the state of a system from an observed time series is the subject of research in many domains, such as computational neuroscience. Here, the prediction of epileptic seizures from brain measurements is an unresolved problem. There are neither complete models describing underlying brain dynamics, nor do individual patients exhibit a single seizure onset pattern, which complicates the development of a `one-size-fits-all' solution. Based on a longitudinal patient data set, we address the automated discovery and quantification of statistical features (biomarkers) that can be used to forecast seizures in a patient-specific way. We use existing and novel feature extraction algorithms, in particular the path signature, a recent development in time series analysis. Of particular interest is how this set of complex, nonlinear features performs compared to simpler, linear features on this task. Our inference is based on statistical classification algorithms with in-built subset select
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#24102;&#26377;&#25511;&#21046;&#21464;&#37327;&#30340;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#22312;&#23436;&#32654;&#21464;&#20998;&#26063;&#35268;&#33539;&#19979;&#20197;&#20960;&#20309;&#36895;&#24230;&#25910;&#25947;&#65292;&#20026;BBVI&#25552;&#20379;&#20102;&#25910;&#25947;&#24615;&#20445;&#35777;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#23545;&#29109;&#26799;&#24230;&#20272;&#35745;&#22120;&#30340;&#25913;&#36827;&#65292;&#23545;&#27604;&#20102;STL&#20272;&#35745;&#22120;&#65292;&#24182;&#32473;&#20986;&#20102;&#26126;&#30830;&#30340;&#38750;&#28176;&#36817;&#22797;&#26434;&#24230;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2307.14642</link><description>&lt;p&gt;
&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#30340;&#32447;&#24615;&#25910;&#25947;&#24615;&#65306;&#25105;&#20204;&#24212;&#35813;&#22362;&#25345;&#21040;&#24213;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Linear Convergence of Black-Box Variational Inference: Should We Stick the Landing?. (arXiv:2307.14642v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14642
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#24102;&#26377;&#25511;&#21046;&#21464;&#37327;&#30340;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#22312;&#23436;&#32654;&#21464;&#20998;&#26063;&#35268;&#33539;&#19979;&#20197;&#20960;&#20309;&#36895;&#24230;&#25910;&#25947;&#65292;&#20026;BBVI&#25552;&#20379;&#20102;&#25910;&#25947;&#24615;&#20445;&#35777;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#23545;&#29109;&#26799;&#24230;&#20272;&#35745;&#22120;&#30340;&#25913;&#36827;&#65292;&#23545;&#27604;&#20102;STL&#20272;&#35745;&#22120;&#65292;&#24182;&#32473;&#20986;&#20102;&#26126;&#30830;&#30340;&#38750;&#28176;&#36817;&#22797;&#26434;&#24230;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;&#24102;&#26377;&#25511;&#21046;&#21464;&#37327;&#30340;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#65288;BBVI&#65289;&#65292;&#29305;&#21035;&#26159;&#30528;&#38470;&#31283;&#23450;&#65288;STL&#65289;&#20272;&#35745;&#22120;&#65292;&#22312;&#23436;&#32654;&#21464;&#20998;&#26063;&#35268;&#33539;&#19979;&#25910;&#25947;&#20110;&#20960;&#20309;&#65288;&#20256;&#32479;&#19978;&#31216;&#20026;&#8220;&#32447;&#24615;&#8221;&#65289;&#36895;&#24230;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;STL&#20272;&#35745;&#22120;&#30340;&#26799;&#24230;&#26041;&#24046;&#30340;&#20108;&#27425;&#30028;&#38480;&#65292;&#35813;&#30028;&#38480;&#21253;&#25324;&#20102;&#35823;&#25351;&#23450;&#30340;&#21464;&#20998;&#26063;&#12290;&#32467;&#21512;&#20808;&#21069;&#20851;&#20110;&#20108;&#27425;&#26041;&#24046;&#26465;&#20214;&#30340;&#24037;&#20316;&#65292;&#36825;&#30452;&#25509;&#26263;&#31034;&#20102;&#22312;&#20351;&#29992;&#25237;&#24433;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#24773;&#20917;&#19979;BBVI&#30340;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#36824;&#25913;&#36827;&#20102;&#29616;&#26377;&#23545;&#20110;&#27491;&#24120;&#23553;&#38381;&#24418;&#24335;&#29109;&#26799;&#24230;&#20272;&#35745;&#22120;&#30340;&#20998;&#26512;&#65292;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#23558;&#20854;&#19982;STL&#20272;&#35745;&#22120;&#36827;&#34892;&#27604;&#36739;&#65292;&#24182;&#20026;&#20004;&#32773;&#25552;&#20379;&#26126;&#30830;&#30340;&#38750;&#28176;&#36827;&#22797;&#26434;&#24230;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We prove that black-box variational inference (BBVI) with control variates, particularly the sticking-the-landing (STL) estimator, converges at a geometric (traditionally called "linear") rate under perfect variational family specification. In particular, we prove a quadratic bound on the gradient variance of the STL estimator, one which encompasses misspecified variational families. Combined with previous works on the quadratic variance condition, this directly implies convergence of BBVI with the use of projected stochastic gradient descent. We also improve existing analysis on the regular closed-form entropy gradient estimators, which enables comparison against the STL estimator and provides explicit non-asymptotic complexity guarantees for both.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#30740;&#31350;&#20102;&#22312;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#20013;&#27169;&#20223;&#22797;&#26434;&#19987;&#23478;&#28436;&#31034;&#30340;&#34892;&#20026;&#12290;&#36890;&#36807;&#31283;&#23450;&#27169;&#20223;&#31574;&#30053;&#24182;&#30830;&#20445;&#20934;&#30830;&#20272;&#35745;&#28436;&#31034;&#32773;&#20998;&#24067;&#65292;&#21487;&#20197;&#20351;&#27169;&#20223;&#32773;&#19982;&#28436;&#31034;&#32773;&#30340;&#36712;&#36857;&#20998;&#24067;&#30456;&#36817;&#12290;</title><link>http://arxiv.org/abs/2307.14619</link><description>&lt;p&gt;
&#27169;&#20223;&#22797;&#26434;&#36712;&#36857;&#65306;&#26725;&#25509;&#20302;&#23618;&#31283;&#23450;&#24615;&#19982;&#39640;&#23618;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Imitating Complex Trajectories: Bridging Low-Level Stability and High-Level Behavior. (arXiv:2307.14619v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14619
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#30740;&#31350;&#20102;&#22312;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#20013;&#27169;&#20223;&#22797;&#26434;&#19987;&#23478;&#28436;&#31034;&#30340;&#34892;&#20026;&#12290;&#36890;&#36807;&#31283;&#23450;&#27169;&#20223;&#31574;&#30053;&#24182;&#30830;&#20445;&#20934;&#30830;&#20272;&#35745;&#28436;&#31034;&#32773;&#20998;&#24067;&#65292;&#21487;&#20197;&#20351;&#27169;&#20223;&#32773;&#19982;&#28436;&#31034;&#32773;&#30340;&#36712;&#36857;&#20998;&#24067;&#30456;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#30740;&#31350;&#22312;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#20013;&#27169;&#20223;&#38543;&#26426;&#12289;&#38750;&#39532;&#23572;&#21487;&#22827;&#12289;&#28508;&#22312;&#22810;&#27169;&#24577;&#65288;&#21363;&#8220;&#22797;&#26434;&#8221;&#65289;&#19987;&#23478;&#28436;&#31034;&#30340;&#34892;&#20026;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#20351;&#29992;&#20302;&#23618;&#25511;&#21046;&#22120;&#65288;&#26080;&#35770;&#26159;&#23398;&#20064;&#30340;&#36824;&#26159;&#38544;&#21547;&#30340;&#65289;&#26469;&#31283;&#23450;&#22260;&#32469;&#19987;&#23478;&#28436;&#31034;&#30340;&#27169;&#20223;&#31574;&#30053;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#65288;a&#65289;&#21512;&#36866;&#30340;&#20302;&#23618;&#31283;&#23450;&#24615;&#20445;&#35777;&#21644;&#65288;b&#65289;&#23398;&#20064;&#31574;&#30053;&#30340;&#38543;&#26426;&#36830;&#32493;&#24615;&#23646;&#24615;&#65288;&#25105;&#20204;&#31216;&#20043;&#20026;&#8220;&#24635;&#21464;&#24046;&#36830;&#32493;&#24615;&#8221;&#65289;&#65288;TVC&#65289;&#30340;&#24773;&#20917;&#19979;&#65292;&#19968;&#20010;&#31934;&#30830;&#20272;&#35745;&#28436;&#31034;&#32773;&#29366;&#24577;&#20998;&#24067;&#19978;&#30340;&#34892;&#21160;&#30340;&#27169;&#20223;&#32773;&#20250;&#19982;&#28436;&#31034;&#32773;&#23545;&#25972;&#20010;&#36712;&#36857;&#30340;&#20998;&#24067;&#30456;&#36817;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#21487;&#20197;&#36890;&#36807;&#23558;&#27969;&#34892;&#30340;&#25968;&#25454;&#22686;&#24378;&#35268;&#21017;&#19982;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#25216;&#24039;&#30456;&#32467;&#21512;&#65288;&#21363;&#22312;&#25191;&#34892;&#26102;&#28155;&#21152;&#22686;&#24378;&#22122;&#22768;&#65289;&#26469;&#30830;&#20445;TVC&#24182;&#19988;&#26368;&#23567;&#31243;&#24230;&#19978;&#38477;&#20302;&#31934;&#24230;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#20445;&#35777;&#23454;&#20363;&#21270;&#20026;&#30001;&#25193;&#25955;&#27169;&#22411;&#21442;&#25968;&#21270;&#30340;&#31574;&#30053;&#65292;&#24182;&#35777;&#26126;&#22914;&#26524;&#23398;&#20064;&#32773;&#20934;&#30830;&#22320;&#20272;&#35745;&#20102;&#28436;&#31034;&#32773;&#30340;&#20998;&#24067;&#65292;&#21017;&#26368;&#32456;&#23436;&#25104;&#36825;&#31181;&#23454;&#20363;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a theoretical framework for studying the imitation of stochastic, non-Markovian, potentially multi-modal (i.e. "complex" ) expert demonstrations in nonlinear dynamical systems. Our framework invokes low-level controllers either learned or implicit in position-command control - to stabilize imitation policies around expert demonstrations. We show that with (a) a suitable low-level stability guarantee and (b) a stochastic continuity property of the learned policy we call "total variation continuity" (TVC), an imitator that accurately estimates actions on the demonstrator's state distribution closely matches the demonstrator's distribution over entire trajectories. We then show that TVC can be ensured with minimal degradation of accuracy by combining a popular data-augmentation regimen with a novel algorithmic trick: adding augmentation noise at execution time. We instantiate our guarantees for policies parameterized by diffusion models and prove that if the learner accuratel
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#39318;&#27425;&#20174;&#29702;&#35770;&#19978;&#29702;&#35299;&#20102;&#20851;&#31995;&#30693;&#35782;&#33976;&#39311;&#65292;&#36890;&#36807;&#31181;&#32676;&#19978;&#30340;&#35889;&#32858;&#31867;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20851;&#31995;&#30693;&#35782;&#33976;&#39311;&#33021;&#22815;&#23548;&#33268;&#20302;&#32858;&#31867;&#35823;&#24046;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22312;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#26631;&#31614;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2307.11030</link><description>&lt;p&gt;
&#38598;&#32676;&#24863;&#30693;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#65306;&#20851;&#31995;&#30693;&#35782;&#33976;&#39311;&#21487;&#35777;&#26126;&#30340;&#23398;&#20064;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Cluster-aware Semi-supervised Learning: Relational Knowledge Distillation Provably Learns Clustering. (arXiv:2307.11030v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11030
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#39318;&#27425;&#20174;&#29702;&#35770;&#19978;&#29702;&#35299;&#20102;&#20851;&#31995;&#30693;&#35782;&#33976;&#39311;&#65292;&#36890;&#36807;&#31181;&#32676;&#19978;&#30340;&#35889;&#32858;&#31867;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20851;&#31995;&#30693;&#35782;&#33976;&#39311;&#33021;&#22815;&#23548;&#33268;&#20302;&#32858;&#31867;&#35823;&#24046;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22312;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#26631;&#31614;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22522;&#20110;&#20851;&#31995;&#30340;&#30693;&#35782;&#33976;&#39311;&#22312;&#21305;&#37197;&#25945;&#24072;&#21644;&#23398;&#29983;&#27169;&#22411;&#20043;&#38388;&#30340;&#29305;&#24449;&#20851;&#31995;&#26041;&#38754;&#21462;&#24471;&#20102;&#23454;&#35777;&#25104;&#21151;&#21644;&#23454;&#38469;&#24847;&#20041;&#65292;&#20294;&#23545;&#20110;&#21508;&#31181;&#30693;&#35782;&#33976;&#39311;&#33539;&#24335;&#65292;&#20854;&#30456;&#24212;&#30340;&#29702;&#35770;&#35299;&#37322;&#20173;&#28982;&#26377;&#38480;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#20174;&#29702;&#35770;&#19978;&#29702;&#35299;&#20851;&#31995;&#30693;&#35782;&#33976;&#39311;&#65288;RKD&#65289;&#65292;&#24182;&#37325;&#28857;&#20851;&#27880;&#21322;&#30417;&#30563;&#20998;&#31867;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#23558;RKD&#35270;&#20026;&#25945;&#24072;&#27169;&#22411;&#25581;&#31034;&#30340;&#30001;&#31181;&#32676;&#20135;&#29983;&#30340;&#22270;&#19978;&#30340;&#35889;&#32858;&#31867;&#12290;&#36890;&#36807;&#34913;&#37327;&#39044;&#27979;&#21644;&#22522;&#26412;&#20107;&#23454;&#32858;&#31867;&#20043;&#38388;&#24046;&#24322;&#30340;&#32858;&#31867;&#35823;&#24046;&#27010;&#24565;&#65292;&#25105;&#20204;&#35828;&#26126;&#20102;&#31181;&#32676;&#19978;&#30340;RKD&#21487;&#35777;&#26126;&#22320;&#23548;&#33268;&#20302;&#32858;&#31867;&#35823;&#24046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#20110;&#26377;&#38480;&#26080;&#26631;&#31614;&#26679;&#26412;&#30340;RKD&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#12290;&#23545;&#20110;&#21322;&#30417;&#30563;&#23398;&#20064;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#36890;&#36807;&#38598;&#32676;&#24863;&#30693;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#26694;&#26550;&#23637;&#31034;&#20102;RKD&#30340;&#26631;&#31614;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the empirical success and practical significance of (relational) knowledge distillation that matches (the relations of) features between teacher and student models, the corresponding theoretical interpretations remain limited for various knowledge distillation paradigms. In this work, we take an initial step toward a theoretical understanding of relational knowledge distillation (RKD), with a focus on semi-supervised classification problems. We start by casting RKD as spectral clustering on a population-induced graph unveiled by a teacher model. Via a notion of clustering error that quantifies the discrepancy between the predicted and ground truth clusterings, we illustrate that RKD over the population provably leads to low clustering error. Moreover, we provide a sample complexity bound for RKD with limited unlabeled samples. For semi-supervised learning, we further demonstrate the label efficiency of RKD through a general framework of cluster-aware semi-supervised learning th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#21547;&#26377;&#27169;&#31946;&#22320;&#38754;&#30495;&#30456;&#30340;&#31526;&#21512;&#39044;&#27979;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#22312;&#32570;&#20047;&#26126;&#30830;&#22320;&#38754;&#30495;&#30456;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#20302;&#20272;&#19981;&#30830;&#23450;&#24615;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.09302</link><description>&lt;p&gt;
&#21547;&#26377;&#19981;&#30830;&#23450;&#22320;&#38754;&#30495;&#30456;&#30340;&#31526;&#21512;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Conformal prediction under ambiguous ground truth. (arXiv:2307.09302v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09302
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#21547;&#26377;&#27169;&#31946;&#22320;&#38754;&#30495;&#30456;&#30340;&#31526;&#21512;&#39044;&#27979;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#22312;&#32570;&#20047;&#26126;&#30830;&#22320;&#38754;&#30495;&#30456;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#20302;&#20272;&#19981;&#30830;&#23450;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23433;&#20840;&#20851;&#38190;&#30340;&#20998;&#31867;&#20219;&#21153;&#20013;&#65292;&#31526;&#21512;&#39044;&#27979;&#21487;&#20197;&#36890;&#36807;&#25552;&#20379;&#32622;&#20449;&#21306;&#38388;&#26469;&#36827;&#34892;&#20005;&#26684;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#20854;&#20013;&#21253;&#25324;&#30495;&#27491;&#31867;&#21035;&#30340;&#29992;&#25143;&#25351;&#23450;&#30340;&#27010;&#29575;&#12290;&#36825;&#36890;&#24120;&#20551;&#35774;&#26377;&#19968;&#20010;&#29420;&#31435;&#30340;&#26657;&#20934;&#38598;&#21512;&#65292;&#24182;&#19988;&#33021;&#22815;&#35775;&#38382;&#22320;&#38754;&#30495;&#30456;&#26631;&#31614;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#22312;&#35768;&#22810;&#39046;&#22495;&#20013;&#65292;&#36825;&#20123;&#26631;&#31614;&#24456;&#38590;&#33719;&#24471;&#65292;&#24182;&#19988;&#36890;&#24120;&#36890;&#36807;&#32858;&#21512;&#19987;&#23478;&#24847;&#35265;&#26469;&#36817;&#20284;&#12290;&#20107;&#23454;&#19978;&#65292;&#36825;&#36866;&#29992;&#20110;&#20960;&#20046;&#25152;&#26377;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#30693;&#21517;&#30340;&#25968;&#25454;&#38598;&#22914;CIFAR&#21644;ImageNet&#12290;&#20351;&#29992;&#36825;&#26679;&#30340;&#26631;&#31614;&#24212;&#29992;&#31526;&#21512;&#39044;&#27979;&#20250;&#20302;&#20272;&#19981;&#30830;&#23450;&#24615;&#12290;&#20107;&#23454;&#19978;&#65292;&#24403;&#19987;&#23478;&#24847;&#35265;&#26080;&#27861;&#35299;&#20915;&#26102;&#65292;&#26631;&#31614;&#20013;&#23384;&#22312;&#22266;&#26377;&#30340;&#27169;&#31946;&#24615;&#12290;&#20063;&#23601;&#26159;&#35828;&#65292;&#25105;&#20204;&#27809;&#26377;&#8220;&#28165;&#26224;&#8221;&#12289;&#26126;&#30830;&#30340;&#22320;&#38754;&#30495;&#30456;&#26631;&#31614;&#65292;&#32780;&#22312;&#26657;&#20934;&#36807;&#31243;&#20013;&#24212;&#35813;&#32771;&#34385;&#36825;&#31181;&#19981;&#30830;&#23450;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#38024;&#23545;&#36825;&#31181;&#27169;&#31946;&#22320;&#38754;&#30495;&#30456;&#24773;&#26223;&#24320;&#21457;&#20102;&#19968;&#20010;&#31526;&#21512;&#39044;&#27979;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#20381;&#36182;&#20110;&#23545;&#28508;&#22312;&#27169;&#31946;&#24615;&#30340;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;
In safety-critical classification tasks, conformal prediction allows to perform rigorous uncertainty quantification by providing confidence sets including the true class with a user-specified probability. This generally assumes the availability of a held-out calibration set with access to ground truth labels. Unfortunately, in many domains, such labels are difficult to obtain and usually approximated by aggregating expert opinions. In fact, this holds true for almost all datasets, including well-known ones such as CIFAR and ImageNet. Applying conformal prediction using such labels underestimates uncertainty. Indeed, when expert opinions are not resolvable, there is inherent ambiguity present in the labels. That is, we do not have ``crisp'', definitive ground truth labels and this uncertainty should be taken into account during calibration. In this paper, we develop a conformal prediction framework for such ambiguous ground truth settings which relies on an approximation of the underlyi
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#23545;&#25239;&#27169;&#22411;&#65288;QUAM&#65289;&#26469;&#26356;&#22909;&#22320;&#20272;&#35745;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#12290;QUAM&#35782;&#21035;&#25972;&#20010;&#31215;&#20998;&#19979;&#20056;&#31215;&#36739;&#22823;&#30340;&#21306;&#22495;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#21518;&#39564;&#12290;&#19982;&#20808;&#21069;&#30340;&#26041;&#27861;&#30456;&#27604;&#65292;QUAM&#23545;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#30340;&#36817;&#20284;&#35823;&#24046;&#26356;&#23567;&#12290;</title><link>http://arxiv.org/abs/2307.03217</link><description>&lt;p&gt;
&#20351;&#29992;&#23545;&#25239;&#27169;&#22411;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Quantification of Uncertainty with Adversarial Models. (arXiv:2307.03217v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03217
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#23545;&#25239;&#27169;&#22411;&#65288;QUAM&#65289;&#26469;&#26356;&#22909;&#22320;&#20272;&#35745;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#12290;QUAM&#35782;&#21035;&#25972;&#20010;&#31215;&#20998;&#19979;&#20056;&#31215;&#36739;&#22823;&#30340;&#21306;&#22495;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#21518;&#39564;&#12290;&#19982;&#20808;&#21069;&#30340;&#26041;&#27861;&#30456;&#27604;&#65292;QUAM&#23545;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#30340;&#36817;&#20284;&#35823;&#24046;&#26356;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#23545;&#20110;&#21487;&#25805;&#20316;&#30340;&#39044;&#27979;&#38750;&#24120;&#37325;&#35201;&#12290;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#20851;&#38190;&#22312;&#20110;&#20272;&#35745;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#65292;&#23427;&#34987;&#23450;&#20041;&#20026;&#19968;&#20010;&#25955;&#24230;&#20989;&#25968;&#21644;&#21518;&#39564;&#30340;&#20056;&#31215;&#30340;&#31215;&#20998;&#12290;&#24403;&#21069;&#30340;&#26041;&#27861;&#22914;Deep Ensembles&#25110;MC dropout&#22312;&#20272;&#35745;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#26041;&#38754;&#34920;&#29616;&#19981;&#20339;&#65292;&#22240;&#20026;&#23427;&#20204;&#20027;&#35201;&#32771;&#34385;&#21518;&#39564;&#22312;&#37319;&#26679;&#27169;&#22411;&#26102;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20351;&#29992;&#23545;&#25239;&#27169;&#22411;&#65288;QUAM&#65289;&#26469;&#26356;&#22909;&#22320;&#20272;&#35745;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#12290;QUAM&#35782;&#21035;&#25972;&#20010;&#31215;&#20998;&#19979;&#20056;&#31215;&#36739;&#22823;&#30340;&#21306;&#22495;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#21518;&#39564;&#12290;&#22240;&#27492;&#65292;&#19982;&#20808;&#21069;&#30340;&#26041;&#27861;&#30456;&#27604;&#65292;QUAM&#23545;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#30340;&#36817;&#20284;&#35823;&#24046;&#26356;&#23567;&#12290;&#20056;&#31215;&#36739;&#22823;&#30340;&#27169;&#22411;&#23545;&#24212;&#20110;&#23545;&#25239;&#27169;&#22411;&#65288;&#19981;&#26159;&#23545;&#25239;&#24615;&#31034;&#20363;&#65281;&#65289;&#12290;&#23545;&#25239;&#27169;&#22411;&#26082;&#26377;&#36739;&#39640;&#30340;&#21518;&#39564;&#65292;&#20063;&#26377;&#20854;&#39044;&#27979;&#19982;&#20854;&#20182;&#27169;&#22411;&#20043;&#38388;&#30340;&#36739;&#39640;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantifying uncertainty is important for actionable predictions in real-world applications. A crucial part of predictive uncertainty quantification is the estimation of epistemic uncertainty, which is defined as an integral of the product between a divergence function and the posterior. Current methods such as Deep Ensembles or MC dropout underperform at estimating the epistemic uncertainty, since they primarily consider the posterior when sampling models. We suggest Quantification of Uncertainty with Adversarial Models (QUAM) to better estimate the epistemic uncertainty. QUAM identifies regions where the whole product under the integral is large, not just the posterior. Consequently, QUAM has lower approximation error of the epistemic uncertainty compared to previous methods. Models for which the product is large correspond to adversarial models (not adversarial examples!). Adversarial models have both a high posterior as well as a high divergence between their predictions and that of
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#21019;&#26032;&#30340;&#25628;&#32034;&#31639;&#27861;&#65292;&#22312;&#39640;&#32500;&#22270;&#32467;&#26500;&#23398;&#20064;&#20013;&#20351;&#29992;&#36793;&#38469;&#20266;&#20284;&#28982;&#20989;&#25968;&#35299;&#20915;&#35745;&#31639;&#22797;&#26434;&#24615;&#38382;&#39064;&#65292;&#24182;&#19988;&#33021;&#22815;&#22312;&#30701;&#26102;&#38388;&#20869;&#29983;&#25104;&#21487;&#38752;&#30340;&#20272;&#35745;&#12290;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;R&#36719;&#20214;&#21253;BDgraph&#30340;&#20195;&#30721;&#23454;&#29616;&#12290;</title><link>http://arxiv.org/abs/2307.00127</link><description>&lt;p&gt;
&#39640;&#32500;&#36125;&#21494;&#26031;&#39640;&#26031;&#22270;&#27169;&#22411;&#20013;&#30340;&#32467;&#26500;&#23398;&#20064;&#26041;&#27861;&#8212;&#8212;&#21033;&#29992;&#36793;&#38469;&#20266;&#20284;&#28982;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
High-Dimensional Bayesian Structure Learning in Gaussian Graphical Models using Marginal Pseudo-Likelihood. (arXiv:2307.00127v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00127
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#21019;&#26032;&#30340;&#25628;&#32034;&#31639;&#27861;&#65292;&#22312;&#39640;&#32500;&#22270;&#32467;&#26500;&#23398;&#20064;&#20013;&#20351;&#29992;&#36793;&#38469;&#20266;&#20284;&#28982;&#20989;&#25968;&#35299;&#20915;&#35745;&#31639;&#22797;&#26434;&#24615;&#38382;&#39064;&#65292;&#24182;&#19988;&#33021;&#22815;&#22312;&#30701;&#26102;&#38388;&#20869;&#29983;&#25104;&#21487;&#38752;&#30340;&#20272;&#35745;&#12290;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;R&#36719;&#20214;&#21253;BDgraph&#30340;&#20195;&#30721;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#22270;&#27169;&#22411;&#20197;&#22270;&#24418;&#24418;&#24335;&#25551;&#32472;&#20102;&#22810;&#20803;&#27491;&#24577;&#20998;&#24067;&#20013;&#21464;&#37327;&#20043;&#38388;&#30340;&#26465;&#20214;&#20381;&#36182;&#20851;&#31995;&#12290;&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#21019;&#26032;&#30340;&#25628;&#32034;&#31639;&#27861;&#65292;&#21033;&#29992;&#36793;&#38469;&#20266;&#20284;&#28982;&#20989;&#25968;&#26469;&#24212;&#23545;&#39640;&#32500;&#22270;&#32467;&#26500;&#23398;&#20064;&#20013;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#38382;&#39064;&#12290;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#22312;&#26631;&#20934;&#35745;&#31639;&#26426;&#19978;&#22312;&#20960;&#20998;&#38047;&#20869;&#24555;&#36895;&#29983;&#25104;&#23545;&#21253;&#21547;1000&#20010;&#21464;&#37327;&#30340;&#38382;&#39064;&#30340;&#21487;&#38752;&#20272;&#35745;&#12290;&#23545;&#20110;&#23545;&#23454;&#38469;&#24212;&#29992;&#24863;&#20852;&#36259;&#30340;&#20154;&#65292;&#25903;&#25345;&#36825;&#31181;&#26032;&#26041;&#27861;&#30340;&#20195;&#30721;&#36890;&#36807;R&#36719;&#20214;&#21253;BDgraph&#25552;&#20379;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian graphical models depict the conditional dependencies between variables within a multivariate normal distribution in a graphical format. The identification of these graph structures is an area known as structure learning. However, when utilizing Bayesian methodologies in structure learning, computational complexities can arise, especially with high-dimensional graphs surpassing 250 nodes. This paper introduces two innovative search algorithms that employ marginal pseudo-likelihood to address this computational challenge. These methods can swiftly generate reliable estimations for problems encompassing 1000 variables in just a few minutes on standard computers. For those interested in practical applications, the code supporting this new approach is made available through the R package BDgraph.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#20010;&#24046;&#20998;&#38544;&#31169;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#36866;&#29992;&#20110;Z&#20026;&#36830;&#32493;&#20540;&#30340;&#19968;&#33324;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2306.06721</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Conditional Independence Testing. (arXiv:2306.06721v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06721
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#20010;&#24046;&#20998;&#38544;&#31169;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#36866;&#29992;&#20110;Z&#20026;&#36830;&#32493;&#20540;&#30340;&#19968;&#33324;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26465;&#20214;&#29420;&#31435;&#24615;&#65288;CI&#65289;&#26816;&#39564;&#22312;&#32479;&#35745;&#25968;&#25454;&#20998;&#26512;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20363;&#22914;&#65292;&#23427;&#20204;&#26159;&#35768;&#22810;&#22240;&#26524;&#22270;&#21457;&#29616;&#31639;&#27861;&#30340;&#26500;&#24314;&#22359;&#12290;CI&#27979;&#35797;&#26088;&#22312;&#25509;&#21463;&#25110;&#25298;&#32477;$X \perp \!\!\! \perp Y \mid Z$&#30340;&#38646;&#20551;&#35774;&#65292;&#20854;&#20013;$X \in \mathbb{R}&#65292;Y \in \mathbb{R}&#65292;Z \in \mathbb{R}^d$&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#19979;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#22522;&#20110;Shah&#21644;Peters&#65288;2020&#65289;&#30340;&#19968;&#33324;&#21270;&#21327;&#26041;&#24046;&#27979;&#37327;&#21644;&#22522;&#20110;Cand\`es&#31561;&#20154;&#30340;&#26465;&#20214;&#38543;&#26426;&#21270;&#26816;&#39564;&#30340;&#20004;&#31181;&#31169;&#20154;CI&#27979;&#35797;&#36807;&#31243;&#65288;&#22312;&#27169;&#22411;-X&#20551;&#35774;&#19979;&#65289;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#25105;&#20204;&#27979;&#35797;&#24615;&#33021;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#22312;&#23454;&#35777;&#19978;&#39564;&#35777;&#23427;&#20204;&#12290;&#36825;&#20123;&#26159;&#31532;&#19968;&#20010;&#36866;&#29992;&#20110;Z&#20026;&#36830;&#32493;&#30340;&#19968;&#33324;&#24773;&#20917;&#30340;&#31169;&#20154;CI&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conditional independence (CI) tests are widely used in statistical data analysis, e.g., they are the building block of many algorithms for causal graph discovery. The goal of a CI test is to accept or reject the null hypothesis that $X \perp \!\!\! \perp Y \mid Z$, where $X \in \mathbb{R}, Y \in \mathbb{R}, Z \in \mathbb{R}^d$. In this work, we investigate conditional independence testing under the constraint of differential privacy. We design two private CI testing procedures: one based on the generalized covariance measure of Shah and Peters (2020) and another based on the conditional randomization test of Cand\`es et al. (2016) (under the model-X assumption). We provide theoretical guarantees on the performance of our tests and validate them empirically. These are the first private CI tests that work for the general case when $Z$ is continuous.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#20301;&#25968;&#22238;&#24402;&#30340;&#26032;&#22411;&#32852;&#37030;&#21512;&#35268;&#24615;&#39044;&#27979;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#37325;&#35201;&#24615;&#21152;&#26435;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#20195;&#29702;&#20043;&#38388;&#30340;&#26631;&#31614;&#28418;&#31227;&#38382;&#39064;&#65292;&#24182;&#20026;&#39044;&#27979;&#38598;&#30340;&#26377;&#25928;&#35206;&#30422;&#21644;&#24046;&#20998;&#38544;&#31169;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;&#24191;&#27867;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#30446;&#21069;&#30340;&#31454;&#20105;&#23545;&#25163;&#12290;</title><link>http://arxiv.org/abs/2306.05131</link><description>&lt;p&gt;
&#38754;&#21521;&#26631;&#31614;&#28418;&#31227;&#30340;&#32852;&#37030;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#21512;&#35268;&#24615;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Conformal Prediction for Federated Uncertainty Quantification Under Label Shift. (arXiv:2306.05131v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05131
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#20301;&#25968;&#22238;&#24402;&#30340;&#26032;&#22411;&#32852;&#37030;&#21512;&#35268;&#24615;&#39044;&#27979;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#37325;&#35201;&#24615;&#21152;&#26435;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#20195;&#29702;&#20043;&#38388;&#30340;&#26631;&#31614;&#28418;&#31227;&#38382;&#39064;&#65292;&#24182;&#20026;&#39044;&#27979;&#38598;&#30340;&#26377;&#25928;&#35206;&#30422;&#21644;&#24046;&#20998;&#38544;&#31169;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;&#24191;&#27867;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#30446;&#21069;&#30340;&#31454;&#20105;&#23545;&#25163;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#26159;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#35768;&#22810;&#23458;&#25143;&#31471;&#21327;&#20316;&#35757;&#32451;&#27169;&#22411;&#65292;&#21516;&#26102;&#20445;&#25345;&#35757;&#32451;&#25968;&#25454;&#20998;&#25955;&#12290;&#23613;&#31649;&#36817;&#24180;&#26469;&#22312;FL&#26041;&#38754;&#21462;&#24471;&#20102;&#36827;&#23637;&#65292;&#20294;&#26410;&#23545;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#20027;&#39064;&#65288;UQ&#65289;&#36827;&#34892;&#37096;&#20998;&#22788;&#29702;&#12290;&#22312;UQ&#26041;&#27861;&#20013;&#65292;&#21512;&#35268;&#24615;&#39044;&#27979;&#65288;CP&#65289;&#26041;&#27861;&#22312;&#26368;&#23567;&#20551;&#35774;&#19979;&#25552;&#20379;&#26080;&#20998;&#24067;&#20445;&#35777;&#12290;&#25105;&#20204;&#22522;&#20110;&#20998;&#20301;&#25968;&#22238;&#24402;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#32852;&#37030;&#21512;&#35268;&#24615;&#39044;&#27979;&#26041;&#27861;&#65292;&#24182;&#32771;&#34385;&#20102;&#38544;&#31169;&#32422;&#26463;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#37325;&#35201;&#24615;&#21152;&#26435;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#20195;&#29702;&#20043;&#38388;&#30340;&#26631;&#31614;&#28418;&#31227;&#38382;&#39064;&#65292;&#24182;&#20026;&#39044;&#27979;&#38598;&#30340;&#26377;&#25928;&#35206;&#30422;&#21644;&#24046;&#20998;&#38544;&#31169;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;&#24191;&#27867;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#30446;&#21069;&#30340;&#31454;&#20105;&#23545;&#25163;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated Learning (FL) is a machine learning framework where many clients collaboratively train models while keeping the training data decentralized. Despite recent advances in FL, the uncertainty quantification topic (UQ) remains partially addressed. Among UQ methods, conformal prediction (CP) approaches provides distribution-free guarantees under minimal assumptions. We develop a new federated conformal prediction method based on quantile regression and take into account privacy constraints. This method takes advantage of importance weighting to effectively address the label shift between agents and provides theoretical guarantees for both valid coverage of the prediction sets and differential privacy. Extensive experimental studies demonstrate that this method outperforms current competitors.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20302;&#31209;&#32467;&#26500;&#20294;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#30340;&#24773;&#20917;&#65292;&#22312;&#20998;&#31163;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#30340;&#20551;&#35774;&#19979;&#65292;&#35299;&#20915;&#20102;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#20998;&#24067;&#20559;&#31227;&#30340;&#24773;&#20917;&#19979;&#65292;&#26412;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;&#27867;&#21270;&#35823;&#24046;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.17297</link><description>&lt;p&gt;
&#26080;&#29420;&#31435;&#24615;&#30340;&#27867;&#21270;&#35823;&#24046;&#65306;&#21435;&#22122;&#12289;&#32447;&#24615;&#22238;&#24402;&#21644;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Generalization Error without Independence: Denoising, Linear Regression, and Transfer Learning. (arXiv:2305.17297v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17297
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20302;&#31209;&#32467;&#26500;&#20294;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#30340;&#24773;&#20917;&#65292;&#22312;&#20998;&#31163;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#30340;&#20551;&#35774;&#19979;&#65292;&#35299;&#20915;&#20102;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#20998;&#24067;&#20559;&#31227;&#30340;&#24773;&#20917;&#19979;&#65292;&#26412;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;&#27867;&#21270;&#35823;&#24046;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#32447;&#24615;&#27169;&#22411;&#22312;&#30495;&#23454;&#25968;&#25454;&#20013;&#30340;&#27867;&#21270;&#33021;&#21147;&#26159;&#32479;&#35745;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#12290;&#20808;&#21069;&#30340;&#19968;&#20123;&#37325;&#35201;&#24037;&#20316;&#39564;&#35777;&#20102;&#29702;&#35770;&#24037;&#20316;&#19982;&#30495;&#23454;&#25968;&#25454;&#30340;&#30456;&#20851;&#24615;&#65292;&#20294;&#36825;&#20123;&#24037;&#20316;&#30001;&#20110;&#25216;&#26415;&#20551;&#35774;&#23384;&#22312;&#38480;&#21046;&#65292;&#36825;&#20123;&#20551;&#35774;&#21253;&#25324;&#20855;&#26377;&#33391;&#22909;&#26465;&#20214;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#20197;&#21450;&#20855;&#26377;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#65292;&#36825;&#20123;&#20551;&#35774;&#22312;&#30495;&#23454;&#25968;&#25454;&#20013;&#24182;&#19981;&#19968;&#23450;&#25104;&#31435;&#12290;&#27492;&#22806;&#65292;&#20197;&#21069;&#30340;&#19968;&#20123;&#20851;&#20110;&#20998;&#24067;&#20559;&#31227;&#30340;&#24037;&#20316;&#36890;&#24120;&#23545;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#30340;&#32852;&#21512;&#20998;&#24067;&#36827;&#34892;&#25216;&#26415;&#20551;&#35774;&#65292;&#24182;&#19988;&#19981;&#22312;&#30495;&#23454;&#25968;&#25454;&#19978;&#36827;&#34892;&#27979;&#35797;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#24182;&#26356;&#22909;&#22320;&#23545;&#30495;&#23454;&#25968;&#25454;&#36827;&#34892;&#24314;&#27169;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#20302;&#31209;&#32467;&#26500;&#20294;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#30340;&#24773;&#20917;&#65292;&#21516;&#26102;&#36890;&#36807;&#20998;&#31163;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#30340;&#20551;&#35774;&#26469;&#35299;&#20915;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;&#25105;&#20204;&#36824;&#22312;&#36825;&#20123;&#26494;&#24347;&#30340;&#20551;&#35774;&#19979;&#65292;&#30740;&#31350;&#20102;&#21435;&#22122;&#38382;&#39064;&#12289;&#32447;&#24615;&#22238;&#24402;&#21644;&#36801;&#31227;&#23398;&#20064;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#30456;&#27604;&#20197;&#21069;&#30340;&#26041;&#27861;&#65292;&#22312;&#20998;&#24067;&#20559;&#31227;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;&#27867;&#21270;&#35823;&#24046;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Studying the generalization abilities of linear models with real data is a central question in statistical learning. While there exist a limited number of prior important works (Loureiro et al. (2021A, 2021B), Wei et al. 2022) that do validate theoretical work with real data, these works have limitations due to technical assumptions. These assumptions include having a well-conditioned covariance matrix and having independent and identically distributed data. These assumptions are not necessarily valid for real data. Additionally, prior works that do address distributional shifts usually make technical assumptions on the joint distribution of the train and test data (Tripuraneni et al. 2021, Wu and Xu 2020), and do not test on real data.  In an attempt to address these issues and better model real data, we look at data that is not I.I.D. but has a low-rank structure. Further, we address distributional shift by decoupling assumptions on the training and test distribution. We provide anal
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#22343;&#22330;&#21338;&#24328;&#20316;&#20026;&#23454;&#39564;&#23460;&#23545;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#35774;&#35745;&#21644;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#36825;&#31181;&#26041;&#27861;&#19982;&#20027;&#35201;&#27969;&#21160;&#21644;&#25193;&#25955;&#22411;&#29983;&#25104;&#27169;&#22411;&#20043;&#38388;&#30340;&#20851;&#32852;&#12290;&#36890;&#36807;&#30740;&#31350;&#27599;&#20010;&#29983;&#25104;&#27169;&#22411;&#19982;&#23427;&#20204;&#30456;&#20851;&#30340; MFG &#30340;&#26368;&#20248;&#26465;&#20214;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#21452;&#20154; MFG &#30340;&#26032;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;&#25552;&#39640;&#26679;&#26412;&#22810;&#26679;&#24615;&#21644;&#36924;&#30495;&#24230;&#30340;&#21516;&#26102;&#25913;&#21892;&#20102;&#35299;&#32544;&#32467;&#21644;&#20844;&#24179;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.13534</link><description>&lt;p&gt;
&#29992;&#22343;&#22330;&#21338;&#24328;&#20026;&#29983;&#25104;&#27169;&#22411;&#25645;&#24314;&#23454;&#39564;&#23460;
&lt;/p&gt;
&lt;p&gt;
A mean-field games laboratory for generative modeling. (arXiv:2304.13534v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13534
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#22343;&#22330;&#21338;&#24328;&#20316;&#20026;&#23454;&#39564;&#23460;&#23545;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#35774;&#35745;&#21644;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#36825;&#31181;&#26041;&#27861;&#19982;&#20027;&#35201;&#27969;&#21160;&#21644;&#25193;&#25955;&#22411;&#29983;&#25104;&#27169;&#22411;&#20043;&#38388;&#30340;&#20851;&#32852;&#12290;&#36890;&#36807;&#30740;&#31350;&#27599;&#20010;&#29983;&#25104;&#27169;&#22411;&#19982;&#23427;&#20204;&#30456;&#20851;&#30340; MFG &#30340;&#26368;&#20248;&#26465;&#20214;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#21452;&#20154; MFG &#30340;&#26032;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;&#25552;&#39640;&#26679;&#26412;&#22810;&#26679;&#24615;&#21644;&#36924;&#30495;&#24230;&#30340;&#21516;&#26102;&#25913;&#21892;&#20102;&#35299;&#32544;&#32467;&#21644;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#20102;&#22343;&#22330;&#21338;&#24328; (MFGs) &#20316;&#20026;&#19968;&#31181;&#25968;&#23398;&#26694;&#26550;&#29992;&#20110;&#35299;&#37322;&#12289;&#22686;&#24378;&#21644;&#35774;&#35745;&#29983;&#25104;&#27169;&#22411;&#30340;&#22810;&#21151;&#33021;&#24615;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102; MFGs &#19982;&#20027;&#35201;&#27969;&#21160;&#21644;&#25193;&#25955;&#22411;&#29983;&#25104;&#27169;&#22411;&#20043;&#38388;&#20851;&#32852;&#65292;&#24182;&#36890;&#36807;&#19981;&#21516;&#30340;&#31890;&#23376;&#21160;&#21147;&#23398;&#21644;&#20195;&#20215;&#20989;&#25968;&#25512;&#23548;&#20102;&#36825;&#19977;&#20010;&#31867;&#21035;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#30740;&#31350;&#23427;&#20204;&#30456;&#20851;&#30340; MFG &#30340;&#26368;&#20248;&#26465;&#20214;&#8212;&#8212;&#19968;&#32452;&#32806;&#21512;&#30340;&#38750;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#65292;&#26469;&#30740;&#31350;&#27599;&#20010;&#29983;&#25104;&#27169;&#22411;&#30340;&#25968;&#23398;&#32467;&#26500;&#21644;&#29305;&#24615;&#12290;&#26412;&#25991;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20110;&#21452;&#20154; MFG &#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#20854;&#20013;&#19968;&#20010;&#20195;&#29702;&#21512;&#25104;&#26679;&#26412;&#65292;&#21478;&#19968;&#20010;&#20195;&#29702;&#23545;&#26679;&#26412;&#36827;&#34892;&#35782;&#21035;&#65292;&#29702;&#35770;&#21644;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#27169;&#22411;&#29983;&#25104;&#30340;&#26679;&#26412;&#22810;&#26679;&#19988;&#36924;&#30495;&#65292;&#21516;&#26102;&#19982;&#22522;&#20934;&#27169;&#22411;&#30456;&#27604;&#65292;&#25913;&#21892;&#20102;&#35299;&#32544;&#32467;&#21644;&#20844;&#24179;&#24615;&#12290;&#24635;&#20043;&#65292;&#26412;&#25991;&#31361;&#26174;&#20102; MFGs &#20316;&#20026;&#35774;&#35745;&#21644;&#20998;&#26512;&#29983;&#25104;&#27169;&#22411;&#30340;&#23454;&#39564;&#23460;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we demonstrate the versatility of mean-field games (MFGs) as a mathematical framework for explaining, enhancing, and designing generative models. There is a pervasive sense in the generative modeling community that the various flow and diffusion-based generative models have some foundational common structure and interrelationships. We establish connections between MFGs and major classes of flow and diffusion-based generative models including continuous-time normalizing flows, score-based models, and Wasserstein gradient flows. We derive these three classes of generative models through different choices of particle dynamics and cost functions. Furthermore, we study the mathematical structure and properties of each generative model by studying their associated MFG's optimality condition, which is a set of coupled nonlinear partial differential equations (PDEs). The theory of MFGs, therefore, enables the study of generative models through the theory of nonlinear PDEs. Throu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#29992;&#29305;&#24449;&#25193;&#25955;&#30697;&#38453;&#30340;&#26368;&#22823;&#22855;&#24322;&#20540;&#26469;&#32553;&#25918;&#27867;&#21270;&#30028;&#38480;&#30340;&#26041;&#27861;&#65292;&#24182;&#29992;Hessians&#26469;&#34913;&#37327;&#22270;&#31070;&#32463;&#32593;&#32476;&#23545;&#22122;&#22768;&#25200;&#21160;&#30340;&#31283;&#23450;&#24615;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#20943;&#23567;&#27867;&#21270;&#30028;&#38480;&#65292;&#26356;&#22909;&#22320;&#35299;&#20915;&#20102;&#23454;&#38469;&#22270;&#24418;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2302.04451</link><description>&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#27867;&#21270;&#65306;&#22522;&#20110;&#22270;&#25193;&#25955;&#30340;&#25913;&#36827;PAC-Bayesian&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generalization in Graph Neural Networks: Improved PAC-Bayesian Bounds on Graph Diffusion. (arXiv:2302.04451v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04451
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#29992;&#29305;&#24449;&#25193;&#25955;&#30697;&#38453;&#30340;&#26368;&#22823;&#22855;&#24322;&#20540;&#26469;&#32553;&#25918;&#27867;&#21270;&#30028;&#38480;&#30340;&#26041;&#27861;&#65292;&#24182;&#29992;Hessians&#26469;&#34913;&#37327;&#22270;&#31070;&#32463;&#32593;&#32476;&#23545;&#22122;&#22768;&#25200;&#21160;&#30340;&#31283;&#23450;&#24615;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#20943;&#23567;&#27867;&#21270;&#30028;&#38480;&#65292;&#26356;&#22909;&#22320;&#35299;&#20915;&#20102;&#23454;&#38469;&#22270;&#24418;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#26159;&#22270;&#39044;&#27979;&#20219;&#21153;&#20013;&#24191;&#27867;&#20351;&#29992;&#30340;&#24037;&#20855;&#12290;&#30001;&#20854;&#23454;&#35777;&#34920;&#29616;&#25152;&#39537;&#21160;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#24320;&#21457;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#23427;&#20204;&#26681;&#25454;&#26368;&#22823;&#24230;&#25968;&#22312;&#22270;&#32467;&#26500;&#26041;&#38754;&#36827;&#34892;&#32553;&#25918;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#27867;&#21270;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#26681;&#25454;&#22270;&#31070;&#32463;&#32593;&#32476;&#29305;&#24449;&#25193;&#25955;&#30697;&#38453;&#30340;&#26368;&#22823;&#22855;&#24322;&#20540;&#36827;&#34892;&#32553;&#25918;&#12290;&#23545;&#20110;&#23454;&#38469;&#22270;&#24418;&#65292;&#36825;&#20123;&#30028;&#38480;&#30340;&#25968;&#20540;&#35201;&#27604;&#20808;&#21069;&#30340;&#30028;&#38480;&#23567;&#24471;&#22810;&#12290;&#25105;&#20204;&#36824;&#26500;&#24314;&#20102;&#19968;&#20010;&#30456;&#31526;&#30340;&#27867;&#21270;&#24046;&#36317;&#19979;&#38480;&#65292;&#20854;&#28176;&#36817;&#22320;&#21305;&#37197;&#20102;&#25105;&#20204;&#30340;&#19978;&#38480;&#30028;&#38480;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20123;&#32467;&#26524;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#27169;&#22411;&#65292;&#20854;&#20013;&#21253;&#25324;&#20808;&#21069;&#30340;&#35774;&#32622;&#65288;&#21363;&#21367;&#31215;&#21644;&#28040;&#24687;&#20256;&#36882;&#32593;&#32476;&#65289;&#21644;&#26032;&#30340;&#35774;&#32622;&#65288;&#21363;&#22270;&#21516;&#26500;&#32593;&#32476;&#65289;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#24605;&#24819;&#26159;&#21033;&#29992;Hessians&#26469;&#34913;&#37327;&#22270;&#31070;&#32463;&#32593;&#32476;&#23545;&#20110;&#22122;&#22768;&#25200;&#21160;&#30340;&#31283;&#23450;&#24615;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22522;&#20110;Hessian&#30340;&#27979;&#37327;&#19982;&#35266;&#23519;&#21040;&#30340;&#27867;&#21270;&#24046;&#36317;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks are widely used tools for graph prediction tasks. Motivated by their empirical performance, prior works have developed generalization bounds for graph neural networks, which scale with graph structures in terms of the maximum degree. In this paper, we present generalization bounds that instead scale with the largest singular value of the graph neural network's feature diffusion matrix. These bounds are numerically much smaller than prior bounds for real-world graphs. We also construct a lower bound of the generalization gap that matches our upper bound asymptotically. To achieve these results, we analyze a unified model that includes prior works' settings (i.e., convolutional and message-passing networks) and new settings (i.e., graph isomorphism networks). Our key idea is to measure the stability of graph neural networks against noise perturbations using Hessians. Empirically, we find that Hessian-based measurements correlate with the observed generalization gaps
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#22312;&#36817;&#22240;&#26524;&#25512;&#26029;&#26694;&#26550;&#30340;&#22522;&#30784;&#19978;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20248;&#21270;&#20010;&#20307;&#21270;&#27835;&#30103;&#26041;&#26696;&#65292;&#21033;&#29992;&#20195;&#29702;&#21464;&#37327;&#26469;&#35782;&#21035;&#22240;&#26524;&#25928;&#24212;&#65292;&#23637;&#31034;&#20102;&#35813;&#26041;&#26696;&#30340;&#20215;&#20540;&#20989;&#25968;&#20248;&#20110;&#29616;&#26377;&#26041;&#26696;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2212.09494</link><description>&lt;p&gt;
&#36817;&#22240;&#26524;&#23398;&#20064;&#30340;&#26368;&#20248;&#27835;&#30103;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Optimal Treatment Regimes for Proximal Causal Learning. (arXiv:2212.09494v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.09494
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#22312;&#36817;&#22240;&#26524;&#25512;&#26029;&#26694;&#26550;&#30340;&#22522;&#30784;&#19978;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20248;&#21270;&#20010;&#20307;&#21270;&#27835;&#30103;&#26041;&#26696;&#65292;&#21033;&#29992;&#20195;&#29702;&#21464;&#37327;&#26469;&#35782;&#21035;&#22240;&#26524;&#25928;&#24212;&#65292;&#23637;&#31034;&#20102;&#35813;&#26041;&#26696;&#30340;&#20215;&#20540;&#20989;&#25968;&#20248;&#20110;&#29616;&#26377;&#26041;&#26696;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20915;&#31574;&#32773;&#22522;&#20110;&#35266;&#27979;&#25968;&#25454;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#24182;&#20570;&#20986;&#20915;&#31574;&#26102;&#65292;&#19968;&#20010;&#24120;&#35265;&#30340;&#20851;&#27880;&#28857;&#26159;&#27979;&#37327;&#21040;&#30340;&#21327;&#21464;&#37327;&#19981;&#36275;&#20197;&#35299;&#37322;&#25152;&#26377;&#28151;&#28102;&#22240;&#32032;&#65292;&#21363;&#26631;&#20934;&#30340;&#26080;&#28151;&#28102;&#24615;&#20551;&#35774;&#19981;&#25104;&#31435;&#12290;&#26368;&#36817;&#25552;&#20986;&#30340;&#36817;&#22240;&#26524;&#25512;&#26029;&#26694;&#26550;&#26174;&#31034;&#65292;&#22312;&#29616;&#23454;&#22330;&#26223;&#20013;&#20016;&#23500;&#23384;&#22312;&#30340;&#20195;&#29702;&#21464;&#37327;&#21487;&#20197;&#34987;&#21033;&#29992;&#26469;&#35782;&#21035;&#22240;&#26524;&#25928;&#24212;&#65292;&#20174;&#32780;&#20419;&#36827;&#20915;&#31574;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#32467;&#26524;&#21644;&#27835;&#30103;&#28151;&#28102;&#26725;&#26753;&#30340;&#26368;&#20248;&#20010;&#20307;&#21270;&#27835;&#30103;&#26041;&#26696;&#12290;&#28982;&#21518;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20010;&#26032;&#30340;&#26368;&#20248;&#27835;&#30103;&#26041;&#26696;&#30340;&#20215;&#20540;&#20989;&#25968;&#20248;&#20110;&#29616;&#26377;&#25991;&#29486;&#20013;&#30340;&#20854;&#20182;&#26041;&#26696;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#21253;&#25324;&#35782;&#21035;&#12289;&#20248;&#36234;&#24615;&#12289;&#36807;&#21097;&#20215;&#20540;&#19978;&#30028;&#21644;&#20272;&#35745;&#26041;&#26696;&#30340;&#19968;&#33268;&#24615;&#22312;&#20869;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#21644;&#30495;&#23454;&#25968;&#25454;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26368;&#20248;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
A common concern when a policymaker draws causal inferences from and makes decisions based on observational data is that the measured covariates are insufficiently rich to account for all sources of confounding, i.e., the standard no confoundedness assumption fails to hold. The recently proposed proximal causal inference framework shows that proxy variables that abound in real-life scenarios can be leveraged to identify causal effects and therefore facilitate decision-making. Building upon this line of work, we propose a novel optimal individualized treatment regime based on so-called outcome and treatment confounding bridges. We then show that the value function of this new optimal treatment regime is superior to that of existing ones in the literature. Theoretical guarantees, including identification, superiority, excess value bound, and consistency of the estimated regime, are established. Furthermore, we demonstrate the proposed optimal regime via numerical experiments and a real d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20013;&#26368;&#22823;&#27744;&#21270;&#29305;&#24449;&#22270;&#30340;&#20301;&#31227;&#19981;&#21464;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#22797;&#25968;&#27169;&#30340;&#26465;&#20214;&#65292;&#23454;&#29616;&#20102;&#20301;&#31227;&#31283;&#23450;&#24615;&#12290;&#23454;&#39564;&#35777;&#23454;&#20102;&#29702;&#35770;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2209.11740</link><description>&lt;p&gt;
&#20851;&#20110;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20013;&#26368;&#22823;&#27744;&#21270;&#29305;&#24449;&#22270;&#30340;&#20301;&#31227;&#19981;&#21464;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Shift Invariance of Max Pooling Feature Maps in Convolutional Neural Networks. (arXiv:2209.11740v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.11740
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20013;&#26368;&#22823;&#27744;&#21270;&#29305;&#24449;&#22270;&#30340;&#20301;&#31227;&#19981;&#21464;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#22797;&#25968;&#27169;&#30340;&#26465;&#20214;&#65292;&#23454;&#29616;&#20102;&#20301;&#31227;&#31283;&#23450;&#24615;&#12290;&#23454;&#39564;&#35777;&#23454;&#20102;&#29702;&#35770;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#33268;&#21147;&#20110;&#25913;&#21892;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#22312;&#22270;&#20687;&#20998;&#31867;&#39046;&#22495;&#20013;&#30340;&#25968;&#23398;&#21487;&#35299;&#37322;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#22312;&#20854;&#31532;&#19968;&#23618;&#20013;&#20986;&#29616;&#30340;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;&#24403;&#22312;&#20687;ImageNet&#36825;&#26679;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;&#20854;&#31532;&#19968;&#23618;&#24448;&#24448;&#23398;&#20064;&#21040;&#19982;&#26041;&#21521;&#36793;&#36890;&#28388;&#27874;&#22120;&#38750;&#24120;&#30456;&#20284;&#30340;&#21442;&#25968;&#12290;&#20351;&#29992;&#36825;&#26679;&#30340;Gabor&#28388;&#27874;&#22120;&#36827;&#34892;&#23376;&#37319;&#26679;&#21367;&#31215;&#23481;&#26131;&#20986;&#29616;&#28151;&#21472;&#38382;&#39064;&#65292;&#23548;&#33268;&#23545;&#36755;&#20837;&#30340;&#23567;&#20559;&#31227;&#25935;&#24863;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#26368;&#22823;&#27744;&#21270;&#31639;&#23376;&#36817;&#20284;&#22797;&#25968;&#27169;&#30340;&#26465;&#20214;&#65292;&#20351;&#20854;&#20960;&#20046;&#20855;&#26377;&#20301;&#31227;&#19981;&#21464;&#24615;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#23376;&#37319;&#26679;&#21367;&#31215;&#21518;&#26368;&#22823;&#27744;&#21270;&#30340;&#20301;&#31227;&#31283;&#23450;&#24615;&#24230;&#37327;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;&#28388;&#27874;&#22120;&#30340;&#39057;&#29575;&#21644;&#26041;&#21521;&#22312;&#23454;&#29616;&#31283;&#23450;&#24615;&#26041;&#38754;&#30340;&#20851;&#38190;&#20316;&#29992;&#12290;&#36890;&#36807;&#32771;&#34385;&#22522;&#20110;&#21452;&#26641;&#22797;&#23567;&#27874;&#21253;&#21464;&#25442;&#30340;&#30830;&#23450;&#24615;&#29305;&#24449;&#25552;&#21462;&#22120;&#65292;&#21363;&#31163;&#25955;Gabor&#30340;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper focuses on improving the mathematical interpretability of convolutional neural networks (CNNs) in the context of image classification. Specifically, we tackle the instability issue arising in their first layer, which tends to learn parameters that closely resemble oriented band-pass filters when trained on datasets like ImageNet. Subsampled convolutions with such Gabor-like filters are prone to aliasing, causing sensitivity to small input shifts. In this context, we establish conditions under which the max pooling operator approximates a complex modulus, which is nearly shift invariant. We then derive a measure of shift invariance for subsampled convolutions followed by max pooling. In particular, we highlight the crucial role played by the filter's frequency and orientation in achieving stability. We experimentally validate our theory by considering a deterministic feature extractor based on the dual-tree complex wavelet packet transform, a particular case of discrete Gabor
&lt;/p&gt;</description></item><item><title>&#20998;&#26399;&#21464;&#20998;&#25512;&#26029;&#65288;Amortized Variational Inference&#65289;&#26159;&#19968;&#31181;&#39640;&#25928;&#19988;&#21487;&#25193;&#23637;&#30340;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21442;&#25968;&#21270;&#20989;&#25968;&#23398;&#20064;&#36817;&#20284;&#21518;&#39564;&#27010;&#29575;&#23494;&#24230;&#21442;&#25968;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;VI&#31639;&#27861;&#22312;&#22788;&#29702;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#21644;&#25512;&#26029;&#20986;&#30028;&#25968;&#25454;&#28857;&#26041;&#38754;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2209.10888</link><description>&lt;p&gt;
&#20998;&#26399;&#21464;&#20998;&#25512;&#26029;&#65306;&#19968;&#39033;&#31995;&#32479;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Amortized Variational Inference: A Systematic Review. (arXiv:2209.10888v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.10888
&lt;/p&gt;
&lt;p&gt;
&#20998;&#26399;&#21464;&#20998;&#25512;&#26029;&#65288;Amortized Variational Inference&#65289;&#26159;&#19968;&#31181;&#39640;&#25928;&#19988;&#21487;&#25193;&#23637;&#30340;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21442;&#25968;&#21270;&#20989;&#25968;&#23398;&#20064;&#36817;&#20284;&#21518;&#39564;&#27010;&#29575;&#23494;&#24230;&#21442;&#25968;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;VI&#31639;&#27861;&#22312;&#22788;&#29702;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#21644;&#25512;&#26029;&#20986;&#30028;&#25968;&#25454;&#28857;&#26041;&#38754;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#25512;&#26029;&#65288;VI&#65289;&#30340;&#26680;&#24515;&#21407;&#21017;&#26159;&#23558;&#35745;&#31639;&#22797;&#26434;&#21518;&#39564;&#27010;&#29575;&#23494;&#24230;&#30340;&#32479;&#35745;&#25512;&#26029;&#38382;&#39064;&#36716;&#21270;&#20026;&#21487;&#22788;&#29702;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#36825;&#20010;&#29305;&#24615;&#20351;&#24471;VI&#27604;&#20960;&#31181;&#22522;&#20110;&#37319;&#26679;&#30340;&#25216;&#26415;&#26356;&#24555;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;VI&#31639;&#27861;&#22312;&#22788;&#29702;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#26102;&#19981;&#20855;&#26377;&#21487;&#25193;&#23637;&#24615;&#65292;&#24182;&#19988;&#26080;&#27861;&#30452;&#25509;&#25512;&#26029;&#20986;&#30028;&#25968;&#25454;&#28857;&#32780;&#19981;&#37325;&#26032;&#36816;&#34892;&#20248;&#21270;&#36807;&#31243;&#12290;&#36817;&#24180;&#26469;&#65292;&#22914;&#38543;&#26426;&#12289;&#40657;&#30418;&#21644;&#20998;&#26399;VI&#31561;&#39046;&#22495;&#30340;&#21457;&#23637;&#24050;&#32463;&#24110;&#21161;&#35299;&#20915;&#20102;&#36825;&#20123;&#38382;&#39064;&#12290;&#29616;&#22312;&#65292;&#29983;&#25104;&#24314;&#27169;&#20219;&#21153;&#24191;&#27867;&#20351;&#29992;&#20998;&#26399;VI&#65292;&#22240;&#20026;&#23427;&#21033;&#29992;&#21442;&#25968;&#21270;&#20989;&#25968;&#26469;&#23398;&#20064;&#36817;&#20284;&#21518;&#39564;&#27010;&#29575;&#23494;&#24230;&#21442;&#25968;&#65292;&#20855;&#26377;&#39640;&#25928;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22238;&#39038;&#20102;&#21508;&#31181;VI&#25216;&#26415;&#30340;&#25968;&#23398;&#22522;&#30784;&#65292;&#20026;&#29702;&#35299;&#20998;&#26399;VI&#25552;&#20379;&#20102;&#22522;&#30784;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#27010;&#36848;&#20102;&#35299;&#20915;&#20998;&#26399;VI&#33509;&#24178;&#38382;&#39064;&#30340;&#26368;&#26032;&#36235;&#21183;&#65292;&#22914;
&lt;/p&gt;
&lt;p&gt;
The core principle of Variational Inference (VI) is to convert the statistical inference problem of computing complex posterior probability densities into a tractable optimization problem. This property enables VI to be faster than several sampling-based techniques. However, the traditional VI algorithm is not scalable to large data sets and is unable to readily infer out-of-bounds data points without re-running the optimization process. Recent developments in the field, like stochastic-, black box-, and amortized-VI, have helped address these issues. Generative modeling tasks nowadays widely make use of amortized VI for its efficiency and scalability, as it utilizes a parameterized function to learn the approximate posterior density parameters. In this paper, we review the mathematical foundations of various VI techniques to form the basis for understanding amortized VI. Additionally, we provide an overview of the recent trends that address several issues of amortized VI, such as the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#24515;&#33039;&#36229;&#22768;&#35270;&#39057;&#30340;&#26032;&#39062;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#65292;&#21033;&#29992;&#24515;&#33039;&#21608;&#26399;&#24615;&#29305;&#24615;&#65292;&#22312;&#23156;&#20799;&#24515;&#33039;&#36229;&#22768;&#35270;&#39057;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#20102;&#19977;&#31181;&#21464;&#20998;&#28508;&#22312;&#36712;&#36857;&#27169;&#22411;&#65292;&#21487;&#21487;&#38752;&#22320;&#35782;&#21035;&#20005;&#37325;&#30340;&#20808;&#22825;&#24615;&#24515;&#33039;&#32570;&#38519;&#65292;&#24182;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2206.15316</link><description>&lt;p&gt;
&#21160;&#24577;&#21464;&#20998;&#36712;&#36857;&#27169;&#22411;&#20013;&#30340;&#24515;&#33039;&#36229;&#22768;&#24322;&#24120;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Anomaly Detection in Echocardiograms with Dynamic Variational Trajectory Models. (arXiv:2206.15316v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.15316
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#24515;&#33039;&#36229;&#22768;&#35270;&#39057;&#30340;&#26032;&#39062;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#65292;&#21033;&#29992;&#24515;&#33039;&#21608;&#26399;&#24615;&#29305;&#24615;&#65292;&#22312;&#23156;&#20799;&#24515;&#33039;&#36229;&#22768;&#35270;&#39057;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#20102;&#19977;&#31181;&#21464;&#20998;&#28508;&#22312;&#36712;&#36857;&#27169;&#22411;&#65292;&#21487;&#21487;&#38752;&#22320;&#35782;&#21035;&#20005;&#37325;&#30340;&#20808;&#22825;&#24615;&#24515;&#33039;&#32570;&#38519;&#65292;&#24182;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#24515;&#33039;&#36229;&#22768;&#35270;&#39057;&#30340;&#26032;&#39062;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#24515;&#33039;&#21608;&#26399;&#24615;&#30340;&#29305;&#24615;&#65292;&#23398;&#20064;&#19977;&#31181;&#21464;&#20998;&#28508;&#22312;&#36712;&#36857;&#27169;&#22411;&#65288;TVAE&#65289;&#30340;&#21464;&#20307;&#12290;&#20854;&#20013;&#21069;&#20004;&#31181;&#21464;&#20307;&#65288;TVAE-C&#21644;TVAE-R&#65289;&#27169;&#25311;&#24515;&#33039;&#30340;&#20005;&#26684;&#21608;&#26399;&#24615;&#36816;&#21160;&#65292;&#32780;&#31532;&#19977;&#31181;&#21464;&#20307;&#65288;TVAE-S&#65289;&#26356;&#20026;&#36890;&#29992;&#65292;&#20801;&#35768;&#35270;&#39057;&#20013;&#31354;&#38388;&#34920;&#31034;&#30340;&#31227;&#20301;&#12290;&#25152;&#26377;&#27169;&#22411;&#37117;&#22312;&#19968;&#20010;&#26032;&#30340;&#20869;&#37096;&#23156;&#20799;&#24515;&#33039;&#36229;&#22768;&#35270;&#39057;&#25968;&#25454;&#38598;&#30340;&#20581;&#24247;&#26679;&#26412;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#20197;&#23398;&#20064;&#20581;&#24247;&#20154;&#32676;&#30340;&#35268;&#33539;&#20808;&#39564;&#30693;&#35782;&#12290;&#22312;&#25512;&#26029;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#26368;&#22823;&#21518;&#39564;&#27010;&#29575;&#65288;MAP&#65289;&#30340;&#24322;&#24120;&#26816;&#27979;&#26469;&#26816;&#27979;&#25968;&#25454;&#38598;&#20013;&#30340;&#31163;&#32676;&#26679;&#26412;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#21487;&#38752;&#22320;&#35782;&#21035;&#20005;&#37325;&#30340;&#20808;&#22825;&#24615;&#24515;&#33039;&#32570;&#38519;&#65292;&#22914;&#22467;&#26222;&#26031;&#22374;&#24322;&#24120;&#25110;Shone&#32508;&#21512;&#24449;&#12290;&#27492;&#22806;&#65292;&#30456;&#27604;&#20110;&#22522;&#20110;&#26631;&#20934;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;MAP-based&#24322;&#24120;&#26816;&#27979;&#65292;&#23427;&#23454;&#29616;&#20102;&#26356;&#20248;&#24322;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel anomaly detection method for echocardiogram videos. The introduced method takes advantage of the periodic nature of the heart cycle to learn three variants of a variational latent trajectory model (TVAE). While the first two variants (TVAE-C and TVAE-R) model strict periodic movements of the heart, the third (TVAE-S) is more general and allows shifts in the spatial representation throughout the video. All models are trained on the healthy samples of a novel in-house dataset of infant echocardiogram videos consisting of multiple chamber views to learn a normative prior of the healthy population. During inference, maximum a posteriori (MAP) based anomaly detection is performed to detect out-of-distribution samples in our dataset. The proposed method reliably identifies severe congenital heart defects, such as Ebstein's Anomaly or Shone-complex. Moreover, it achieves superior performance over MAP-based anomaly detection with standard variational autoencoders when detect
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#23436;&#20840;&#33258;&#36866;&#24212;&#24046;&#20998;&#38544;&#31169;&#32452;&#21512;&#30340;&#27010;&#24565;&#65292;&#36890;&#36807;&#24341;&#20837;&#38544;&#31169;&#36807;&#28388;&#22120;&#21644;&#38544;&#31169;&#37324;&#31243;&#34920;&#26469;&#35299;&#20915;&#29616;&#26377;&#32452;&#21512;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#12290;</title><link>http://arxiv.org/abs/2203.05481</link><description>&lt;p&gt;
&#23436;&#20840;&#33258;&#36866;&#24212;&#24046;&#20998;&#38544;&#31169;&#32452;&#21512;
&lt;/p&gt;
&lt;p&gt;
Fully Adaptive Composition in Differential Privacy. (arXiv:2203.05481v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.05481
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#23436;&#20840;&#33258;&#36866;&#24212;&#24046;&#20998;&#38544;&#31169;&#32452;&#21512;&#30340;&#27010;&#24565;&#65292;&#36890;&#36807;&#24341;&#20837;&#38544;&#31169;&#36807;&#28388;&#22120;&#21644;&#38544;&#31169;&#37324;&#31243;&#34920;&#26469;&#35299;&#20915;&#29616;&#26377;&#32452;&#21512;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32452;&#21512;&#26159;&#24046;&#20998;&#38544;&#31169;&#30340;&#19968;&#20010;&#37325;&#35201;&#29305;&#24615;&#12290;&#33879;&#21517;&#30340;&#39640;&#32423;&#32452;&#21512;&#23450;&#29702;&#20801;&#35768;&#22312;&#22522;&#26412;&#38544;&#31169;&#32452;&#21512;&#20801;&#35768;&#30340;&#24773;&#20917;&#19979;&#65292;&#26597;&#35810;&#31169;&#26377;&#25968;&#25454;&#24211;&#30340;&#27425;&#25968;&#22686;&#21152;&#21040;&#21407;&#26469;&#30340;&#24179;&#26041;&#20493;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#32467;&#26524;&#35201;&#27714;&#22312;&#19982;&#25968;&#25454;&#20132;&#20114;&#20043;&#21069;&#22266;&#23450;&#25152;&#26377;&#31639;&#27861;&#30340;&#38544;&#31169;&#21442;&#25968;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;Rogers&#31561;&#20154;&#24341;&#20837;&#20102;&#23436;&#20840;&#33258;&#36866;&#24212;&#32452;&#21512;&#65292;&#20854;&#20013;&#31639;&#27861;&#21644;&#20854;&#38544;&#31169;&#21442;&#25968;&#21487;&#20197;&#33258;&#36866;&#24212;&#36873;&#25321;&#12290;&#20182;&#20204;&#23450;&#20041;&#20102;&#20004;&#20010;&#27010;&#29575;&#23545;&#35937;&#26469;&#34913;&#37327;&#33258;&#36866;&#24212;&#32452;&#21512;&#20013;&#30340;&#38544;&#31169;&#65306;&#38544;&#31169;&#36807;&#28388;&#22120;&#65288;privacy filters&#65289;&#65292;&#29992;&#20110;&#25552;&#20379;&#32452;&#21512;&#20132;&#20114;&#30340;&#24046;&#20998;&#38544;&#31169;&#20445;&#35777;&#65292;&#20197;&#21450;&#38544;&#31169;&#37324;&#31243;&#34920;&#65288;privacy odometers&#65289;&#65292;&#23545;&#38544;&#31169;&#25439;&#22833;&#30340;&#26102;&#38388;&#22343;&#21248;&#30028;&#38480;&#12290;&#39640;&#32423;&#32452;&#21512;&#21644;&#29616;&#26377;&#30340;&#36807;&#28388;&#22120;&#21644;&#37324;&#31243;&#34920;&#20043;&#38388;&#23384;&#22312;&#23454;&#36136;&#24615;&#24046;&#36317;&#12290;&#39318;&#20808;&#65292;&#29616;&#26377;&#30340;&#36807;&#28388;&#22120;&#23545;&#34987;&#32452;&#21512;&#30340;&#31639;&#27861;&#25552;&#20986;&#20102;&#26356;&#24378;&#30340;&#20551;&#35774;&#12290;&#20854;&#27425;&#65292;&#36825;&#20123;&#37324;&#31243;&#34920;&#21644;&#36807;&#28388;&#22120;&#23384;&#22312;&#36739;&#22823;&#30340;&#24120;&#25968;&#65292;&#20351;&#24471;&#23427;&#20204;&#19981;&#23454;&#29992;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#33021;&#22815;&#22312;&#23436;&#20840;&#33258;&#36866;&#24212;&#32452;&#21512;&#20013;&#20351;&#29992;&#30340;&#36807;&#28388;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Composition is a key feature of differential privacy. Well-known advanced composition theorems allow one to query a private database quadratically more times than basic privacy composition would permit. However, these results require that the privacy parameters of all algorithms be fixed before interacting with the data. To address this, Rogers et al. introduced fully adaptive composition, wherein both algorithms and their privacy parameters can be selected adaptively. They defined two probabilistic objects to measure privacy in adaptive composition: privacy filters, which provide differential privacy guarantees for composed interactions, and privacy odometers, time-uniform bounds on privacy loss. There are substantial gaps between advanced composition and existing filters and odometers. First, existing filters place stronger assumptions on the algorithms being composed. Second, these odometers and filters suffer from large constants, making them impractical. We construct filters that 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;Bellman&#19968;&#33268;&#30340;&#24754;&#35266;&#35770;&#36848;&#30340;&#27010;&#24565;&#65292;&#29992;&#20110;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20989;&#25968;&#36924;&#36817;&#65292;&#36890;&#36807;&#22312;&#19982;Bellman&#26041;&#31243;&#19968;&#33268;&#30340;&#20989;&#25968;&#38598;&#21512;&#19978;&#23454;&#26045;&#21021;&#22987;&#29366;&#24577;&#30340;&#24754;&#35266;&#20027;&#20041;&#65292;&#25913;&#21892;&#20102;&#22522;&#20110;&#22870;&#21169;&#30340;&#24754;&#35266;&#20027;&#20041;&#26041;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;</title><link>http://arxiv.org/abs/2106.06926</link><description>&lt;p&gt;
Bellman&#19968;&#33268;&#30340;&#24754;&#35266;&#35770;&#36848;&#29992;&#20110;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Bellman-consistent Pessimism for Offline Reinforcement Learning. (arXiv:2106.06926v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.06926
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;Bellman&#19968;&#33268;&#30340;&#24754;&#35266;&#35770;&#36848;&#30340;&#27010;&#24565;&#65292;&#29992;&#20110;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20989;&#25968;&#36924;&#36817;&#65292;&#36890;&#36807;&#22312;&#19982;Bellman&#26041;&#31243;&#19968;&#33268;&#30340;&#20989;&#25968;&#38598;&#21512;&#19978;&#23454;&#26045;&#21021;&#22987;&#29366;&#24577;&#30340;&#24754;&#35266;&#20027;&#20041;&#65292;&#25913;&#21892;&#20102;&#22522;&#20110;&#22870;&#21169;&#30340;&#24754;&#35266;&#20027;&#20041;&#26041;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22312;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#24403;&#25512;&#29702;&#25968;&#25454;&#38598;&#32570;&#20047;&#35814;&#23613;&#25506;&#32034;&#26102;&#65292;&#20351;&#29992;&#24754;&#35266;&#20027;&#20041;&#33719;&#24471;&#20102;&#26174;&#33879;&#30340;&#37325;&#35201;&#24615;&#12290;&#23613;&#31649;&#24754;&#35266;&#20027;&#20041;&#22686;&#21152;&#20102;&#31639;&#27861;&#30340;&#40065;&#26834;&#24615;&#65292;&#20294;&#36807;&#24230;&#24754;&#35266;&#30340;&#25512;&#29702;&#21516;&#26679;&#20250;&#38459;&#30861;&#21457;&#29616;&#33391;&#22909;&#31574;&#30053;&#65292;&#36825;&#23545;&#20110;&#27969;&#34892;&#30340;&#22522;&#20110;&#22870;&#21169;&#30340;&#24754;&#35266;&#20027;&#20041;&#26159;&#19968;&#20010;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;Bellman&#19968;&#33268;&#30340;&#24754;&#35266;&#20027;&#20041;&#30340;&#27010;&#24565;&#65292;&#29992;&#20110;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#65306;&#25105;&#20204;&#19981;&#26159;&#35745;&#31639;&#20540;&#20989;&#25968;&#30340;&#36880;&#28857;&#19979;&#30028;&#65292;&#32780;&#26159;&#22312;&#19982;Bellman&#26041;&#31243;&#19968;&#33268;&#30340;&#20989;&#25968;&#38598;&#21512;&#19978;&#23454;&#26045;&#21021;&#22987;&#29366;&#24577;&#19978;&#30340;&#24754;&#35266;&#20027;&#20041;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20445;&#35777;&#20165;&#38656;&#35201;&#26631;&#20934;&#30340;Bellman&#23553;&#38381;&#24615;&#20316;&#20026;&#25506;&#32034;&#24615;&#35774;&#32622;&#20013;&#30340;&#35201;&#27714;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#22522;&#20110;&#22870;&#21169;&#30340;&#24754;&#35266;&#20027;&#20041;&#26080;&#27861;&#25552;&#20379;&#20445;&#35777;&#12290;&#21363;&#20351;&#22312;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;&#29305;&#27530;&#24773;&#20917;&#19979;&#65292;&#26356;&#24378;&#30340;&#34920;&#29616;&#21147;&#20551;&#35774;&#25104;&#31435;&#26102;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#22312;&#26679;&#26412;&#22797;&#26434;&#24615;&#19978;&#20248;&#20110;&#26368;&#36817;&#30340;&#22522;&#20110;&#22870;&#21169;&#30340;&#26041;&#27861;&#65292;&#22797;&#26434;&#24615;&#25913;&#21892;&#20102;&#927;(d)&#12290;
&lt;/p&gt;
&lt;p&gt;
The use of pessimism, when reasoning about datasets lacking exhaustive exploration has recently gained prominence in offline reinforcement learning. Despite the robustness it adds to the algorithm, overly pessimistic reasoning can be equally damaging in precluding the discovery of good policies, which is an issue for the popular bonus-based pessimism. In this paper, we introduce the notion of Bellman-consistent pessimism for general function approximation: instead of calculating a point-wise lower bound for the value function, we implement pessimism at the initial state over the set of functions consistent with the Bellman equations. Our theoretical guarantees only require Bellman closedness as standard in the exploratory setting, in which case bonus-based pessimism fails to provide guarantees. Even in the special case of linear function approximation where stronger expressivity assumptions hold, our result improves upon a recent bonus-based approach by $\mathcal{O}(d)$ in its sample c
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#38543;&#26426;&#19978;&#19979;&#25991;&#25512;&#26029;&#35774;&#32622;&#20013;&#65292;&#38024;&#23545;&#32047;&#35745;&#36951;&#25022;&#26368;&#23567;&#21270;&#30340;&#26368;&#20248;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#36890;&#36807;&#24341;&#20837;&#28176;&#22686;&#31867;&#21035;&#22797;&#26434;&#24615;&#21644;&#36882;&#20943;&#36793;&#38469;&#25910;&#30410;&#26465;&#20214;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26032;&#39062;&#35823;&#37197;&#27979;&#35797;&#30340;&#31639;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#27169;&#22411;&#36873;&#25321;&#22312;&#22870;&#21169;&#20272;&#35745;&#20013;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2106.06483</link><description>&lt;p&gt;
&#22312;&#20855;&#26377;&#35768;&#22810;&#31867;&#21035;&#30340;&#19978;&#19979;&#25991;&#25512;&#26029;&#20013;&#36890;&#36807;&#31163;&#32447;&#31070;&#35861;&#36827;&#34892;&#26368;&#20248;&#27169;&#22411;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Optimal Model Selection in Contextual Bandits with Many Classes via Offline Oracles. (arXiv:2106.06483v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.06483
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#38543;&#26426;&#19978;&#19979;&#25991;&#25512;&#26029;&#35774;&#32622;&#20013;&#65292;&#38024;&#23545;&#32047;&#35745;&#36951;&#25022;&#26368;&#23567;&#21270;&#30340;&#26368;&#20248;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#36890;&#36807;&#24341;&#20837;&#28176;&#22686;&#31867;&#21035;&#22797;&#26434;&#24615;&#21644;&#36882;&#20943;&#36793;&#38469;&#25910;&#30410;&#26465;&#20214;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26032;&#39062;&#35823;&#37197;&#27979;&#35797;&#30340;&#31639;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#27169;&#22411;&#36873;&#25321;&#22312;&#22870;&#21169;&#20272;&#35745;&#20013;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30417;&#30563;&#23398;&#20064;&#20013;&#65292;&#27169;&#22411;&#36873;&#25321;&#25552;&#20379;&#20102;&#19968;&#31181;&#26080;&#25104;&#26412;&#30340;&#20445;&#35777;&#65292;&#23601;&#22909;&#20687;&#26368;&#20248;&#24179;&#34913;&#20559;&#24046;&#21644;&#26041;&#24046;&#30340;&#27169;&#22411;&#26159;&#20808;&#39564;&#24050;&#30693;&#30340;&#19968;&#26679;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#38543;&#26426;&#19978;&#19979;&#25991;&#25512;&#26029;&#35774;&#32622;&#20013;&#23454;&#29616;&#31867;&#20284;&#20445;&#35777;&#30340;&#21487;&#34892;&#24615;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350; [Marinov and Zimmert, 2021] &#37492;&#21035;&#20986;&#27809;&#26377;&#31639;&#27861;&#33021;&#22815;&#20445;&#35777;&#26080;&#25104;&#26412;&#30340;&#36951;&#25022;&#30028;&#38480;&#30340;&#24773;&#20917;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#28176;&#22686;&#31867;&#21035;&#22797;&#26434;&#24615;&#21644;&#38543;&#30528;&#31867;&#21035;&#22797;&#26434;&#24615;&#22686;&#21152;&#26368;&#20339;&#31574;&#30053;&#20215;&#20540;&#36793;&#38469;&#25910;&#30410;&#36882;&#20943;&#30340;&#28201;&#21644;&#26465;&#20214;&#19979;&#65292;&#26080;&#25104;&#26412;&#27169;&#22411;&#36873;&#25321;&#26159;&#21487;&#34892;&#30340;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22522;&#20110;&#19968;&#31181;&#26032;&#39062;&#30340;&#35823;&#37197;&#27979;&#35797;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#23637;&#31034;&#20102;&#27169;&#22411;&#36873;&#25321;&#22312;&#22870;&#21169;&#20272;&#35745;&#20013;&#30340;&#20248;&#21183;&#12290;&#19982;&#20808;&#21069;&#20851;&#20110;&#19978;&#19979;&#25991;&#25512;&#26029;&#20013;&#27169;&#22411;&#36873;&#25321;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#25910;&#38598;&#26356;&#22810;&#25968;&#25454;&#26102;&#20250;&#20180;&#32454;&#22320;&#36866;&#24212;&#36880;&#28176;&#28436;&#21464;&#30340;&#20559;&#24046;-&#26041;&#24046;&#26435;&#34913;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#21644;&#20998;&#26512;&#36229;&#36234;&#20102;&#36866;&#24212;&#26102;&#38388;&#22797;&#26434;&#24615;&#30340;&#33539;&#30068;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model selection in supervised learning provides costless guarantees as if the model that best balances bias and variance was known a priori. We study the feasibility of similar guarantees for cumulative regret minimization in the stochastic contextual bandit setting. Recent work [Marinov and Zimmert, 2021] identifies instances where no algorithm can guarantee costless regret bounds. Nevertheless, we identify benign conditions where costless model selection is feasible: gradually increasing class complexity, and diminishing marginal returns for best-in-class policy value with increasing class complexity. Our algorithm is based on a novel misspecification test, and our analysis demonstrates the benefits of using model selection for reward estimation. Unlike prior work on model selection in contextual bandits, our algorithm carefully adapts to the evolving bias-variance trade-off as more data is collected. In particular, our algorithm and analysis go beyond adapting to the complexity of t
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38754;&#21521;&#24930;-&#24555;&#38543;&#26426;&#31995;&#32479;&#30340;&#38750;&#32447;&#24615;&#27169;&#22411;&#31616;&#21270;&#25216;&#26415;&#65292;&#21487;&#20197;&#36890;&#36807;&#40657;&#30418;&#27169;&#25311;&#22120;&#20272;&#35745;&#19981;&#21464;&#27969;&#24418;&#24182;&#35745;&#31639;&#26377;&#25928;&#30340;&#38543;&#26426;&#21160;&#21147;&#23398;&#36807;&#31243;&#65292;&#23454;&#29616;&#39640;&#25928;&#30340;&#29366;&#24577;&#31354;&#38388;&#25506;&#32034;&#12290;</title><link>http://arxiv.org/abs/2104.02120</link><description>&lt;p&gt;
&#38754;&#21521;&#26410;&#30693;&#19981;&#21464;&#27969;&#24418;&#30340;&#24930;-&#24555;&#38543;&#26426;&#31995;&#32479;&#30340;&#38750;&#32447;&#24615;&#27169;&#22411;&#31616;&#21270;
&lt;/p&gt;
&lt;p&gt;
Nonlinear model reduction for slow-fast stochastic systems near unknown invariant manifolds. (arXiv:2104.02120v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2104.02120
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38754;&#21521;&#24930;-&#24555;&#38543;&#26426;&#31995;&#32479;&#30340;&#38750;&#32447;&#24615;&#27169;&#22411;&#31616;&#21270;&#25216;&#26415;&#65292;&#21487;&#20197;&#36890;&#36807;&#40657;&#30418;&#27169;&#25311;&#22120;&#20272;&#35745;&#19981;&#21464;&#27969;&#24418;&#24182;&#35745;&#31639;&#26377;&#25928;&#30340;&#38543;&#26426;&#21160;&#21147;&#23398;&#36807;&#31243;&#65292;&#23454;&#29616;&#39640;&#25928;&#30340;&#29366;&#24577;&#31354;&#38388;&#25506;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#38750;&#32447;&#24615;&#38543;&#26426;&#27169;&#22411;&#31616;&#21270;&#25216;&#26415;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#20302;&#32500;&#19981;&#21464;&#26377;&#25928;&#27969;&#24418;&#21644;&#39640;&#32500;&#22823;&#24555;&#27169;&#30340;&#39640;&#32500;&#38543;&#26426;&#21160;&#21147;&#31995;&#32479;&#12290;&#36890;&#36807;&#20165;&#35775;&#38382;&#33021;&#22815;&#33719;&#24471;&#30701;&#26102;&#38388;&#27169;&#25311;&#30340;&#40657;&#30418;&#27169;&#25311;&#22120;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#36755;&#20986;&#19981;&#21464;&#27969;&#24418;&#30340;&#20272;&#35745;&#12289;&#22312;&#20854;&#19978;&#30340;&#26377;&#25928;&#38543;&#26426;&#21160;&#21147;&#36807;&#31243;&#65288;&#24179;&#22343;&#25481;&#20102;&#24555;&#27169;&#65289;&#65292;&#20197;&#21450;&#23545;&#24212;&#30340;&#27169;&#25311;&#22120;&#12290;&#36825;&#20010;&#27169;&#25311;&#22120;&#26159;&#39640;&#25928;&#30340;&#65292;&#22240;&#20026;&#23427;&#21033;&#29992;&#20102;&#19981;&#21464;&#27969;&#24418;&#30340;&#20302;&#32500;&#29305;&#24615;&#65292;&#24182;&#19988;&#37319;&#29992;&#30340;&#26102;&#38388;&#27493;&#38271;&#22823;&#23567;&#21462;&#20915;&#20110;&#26377;&#25928;&#36807;&#31243;&#30340;&#27491;&#21017;&#24615;&#65292;&#22240;&#27492;&#36890;&#24120;&#27604;&#21407;&#27169;&#25311;&#22120;&#30340;&#26102;&#38388;&#27493;&#38271;&#22823;&#24471;&#22810;&#65292;&#21407;&#27169;&#25311;&#22120;&#38656;&#35201;&#35299;&#20915;&#24555;&#27169;&#12290;&#31639;&#27861;&#21644;&#20272;&#35745;&#21487;&#20197;&#23454;&#26102;&#36827;&#34892;&#65292;&#20197;&#26377;&#25928;&#22320;&#25506;&#32034;&#26377;&#25928;&#29366;&#24577;&#31354;&#38388;&#65292;&#32780;&#19981;&#20250;&#22833;&#21435;&#19982;&#22522;&#30784;&#21160;&#21147;&#23398;&#30340;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a nonlinear stochastic model reduction technique for high-dimensional stochastic dynamical systems that have a low-dimensional invariant effective manifold with slow dynamics, and high-dimensional, large fast modes. Given only access to a black box simulator from which short bursts of simulation can be obtained, we design an algorithm that outputs an estimate of the invariant manifold, a process of the effective stochastic dynamics on it, which has averaged out the fast modes, and a simulator thereof. This simulator is efficient in that it exploits of the low dimension of the invariant manifold, and takes time steps of size dependent on the regularity of the effective process, and therefore typically much larger than that of the original simulator, which had to resolve the fast modes. The algorithm and the estimation can be performed on-the-fly, leading to efficient exploration of the effective state space, without losing consistency with the underlying dynamics. This cons
&lt;/p&gt;</description></item><item><title>ProtoryNet&#26159;&#19968;&#31181;&#22522;&#20110;&#21407;&#22411;&#36712;&#36857;&#30340;&#21487;&#35299;&#37322;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#23427;&#36890;&#36807;&#25429;&#25417;&#26102;&#38388;&#27169;&#24335;&#21644;&#21407;&#22411;&#30340;&#36817;&#20284;&#31243;&#24230;&#26469;&#36827;&#34892;&#25991;&#26412;&#20998;&#31867;&#65292;&#24182;&#23454;&#29616;&#20102;&#30452;&#35266;&#21644;&#32454;&#33268;&#30340;&#25512;&#29702;&#36807;&#31243;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2007.01777</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#24207;&#21015;&#20998;&#31867;&#36890;&#36807;&#21407;&#22411;&#36712;&#36857;
&lt;/p&gt;
&lt;p&gt;
Interpretable Sequence Classification Via Prototype Trajectory. (arXiv:2007.01777v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2007.01777
&lt;/p&gt;
&lt;p&gt;
ProtoryNet&#26159;&#19968;&#31181;&#22522;&#20110;&#21407;&#22411;&#36712;&#36857;&#30340;&#21487;&#35299;&#37322;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#23427;&#36890;&#36807;&#25429;&#25417;&#26102;&#38388;&#27169;&#24335;&#21644;&#21407;&#22411;&#30340;&#36817;&#20284;&#31243;&#24230;&#26469;&#36827;&#34892;&#25991;&#26412;&#20998;&#31867;&#65292;&#24182;&#23454;&#29616;&#20102;&#30452;&#35266;&#21644;&#32454;&#33268;&#30340;&#25512;&#29702;&#36807;&#31243;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29992;&#20110;&#25991;&#26412;&#20998;&#31867;&#30340;&#21487;&#35299;&#37322;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#31216;&#20026;ProtoryNet&#65292;&#23427;&#22522;&#20110;&#21407;&#22411;&#36712;&#36857;&#30340;&#26032;&#27010;&#24565;&#12290;&#21463;&#29616;&#20195;&#35821;&#35328;&#23398;&#20013;&#30340;&#21407;&#22411;&#29702;&#35770;&#30340;&#21551;&#21457;&#65292;ProtoryNet&#36890;&#36807;&#20026;&#25991;&#26412;&#24207;&#21015;&#20013;&#30340;&#27599;&#20010;&#21477;&#23376;&#25214;&#21040;&#26368;&#30456;&#20284;&#30340;&#21407;&#22411;&#65292;&#24182;&#23558;&#27599;&#20010;&#21477;&#23376;&#19982;&#30456;&#24212;&#30340;&#27963;&#21160;&#21407;&#22411;&#30340;&#25509;&#36817;&#31243;&#24230;&#36755;&#20837;&#21040;RNN&#20027;&#24178;&#20013;&#36827;&#34892;&#39044;&#27979;&#12290;&#28982;&#21518;&#65292;RNN&#20027;&#24178;&#25429;&#25417;&#21040;&#21407;&#22411;&#30340;&#26102;&#38388;&#27169;&#24335;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#21407;&#22411;&#36712;&#36857;&#12290;&#21407;&#22411;&#36712;&#36857;&#33021;&#22815;&#30452;&#35266;&#32780;&#32454;&#33268;&#22320;&#35299;&#37322;RNN&#27169;&#22411;&#30340;&#25512;&#29702;&#36807;&#31243;&#65292;&#31867;&#20284;&#20110;&#20154;&#31867;&#20998;&#26512;&#25991;&#26412;&#30340;&#26041;&#24335;&#12290;&#25105;&#20204;&#36824;&#35774;&#35745;&#20102;&#21407;&#22411;&#20462;&#21098;&#36807;&#31243;&#65292;&#20197;&#20943;&#23569;&#27169;&#22411;&#20351;&#29992;&#30340;&#21407;&#22411;&#24635;&#25968;&#65292;&#20197;&#25552;&#39640;&#35299;&#37322;&#24615;&#12290;&#22312;&#22810;&#20010;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;ProtoryNet&#27604;&#22522;&#32447;&#30340;&#22522;&#20110;&#21407;&#22411;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26356;&#20934;&#30830;&#65292;&#24182;&#20943;&#23569;&#20102;&#19982;&#29616;&#26377;&#27169;&#22411;&#30456;&#27604;&#30340;&#24615;&#33021;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel interpretable deep neural network for text classification, called ProtoryNet, based on a new concept of prototype trajectories. Motivated by the prototype theory in modern linguistics, ProtoryNet makes a prediction by finding the most similar prototype for each sentence in a text sequence and feeding an RNN backbone with the proximity of each sentence to the corresponding active prototype. The RNN backbone then captures the temporal pattern of the prototypes, which we refer to as prototype trajectories. Prototype trajectories enable intuitive and fine-grained interpretation of the reasoning process of the RNN model, in resemblance to how humans analyze texts. We also design a prototype pruning procedure to reduce the total number of prototypes used by the model for better interpretability. Experiments on multiple public data sets show that ProtoryNet is more accurate than the baseline prototype-based deep neural net and reduces the performance gap compared to state-o
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#20840;&#21487;&#24494;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#31232;&#30095;&#21270;&#26041;&#27861;&#65292;&#33021;&#22815;&#36890;&#36807;&#20248;&#21270;&#30446;&#26631;&#20989;&#25968;&#30452;&#25509;&#23398;&#20064;&#32593;&#32476;&#30340;&#31232;&#30095;&#32467;&#26500;&#21644;&#26435;&#37325;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#26377;&#25928;&#26550;&#26500;&#30830;&#23450;&#21644;&#32593;&#32476;&#23610;&#23544;&#32553;&#23567;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/1910.03201</link><description>&lt;p&gt;
&#21487;&#24494;&#31232;&#30095;&#21270;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Differentiable Sparsification for Deep Neural Networks. (arXiv:1910.03201v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1910.03201
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#20840;&#21487;&#24494;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#31232;&#30095;&#21270;&#26041;&#27861;&#65292;&#33021;&#22815;&#36890;&#36807;&#20248;&#21270;&#30446;&#26631;&#20989;&#25968;&#30452;&#25509;&#23398;&#20064;&#32593;&#32476;&#30340;&#31232;&#30095;&#32467;&#26500;&#21644;&#26435;&#37325;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#26377;&#25928;&#26550;&#26500;&#30830;&#23450;&#21644;&#32593;&#32476;&#23610;&#23544;&#32553;&#23567;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26497;&#22823;&#22320;&#20943;&#36731;&#20102;&#29305;&#24449;&#24037;&#31243;&#30340;&#36127;&#25285;&#65292;&#20294;&#23545;&#20110;&#36825;&#20123;&#32593;&#32476;&#30340;&#26377;&#25928;&#26550;&#26500;&#30340;&#30830;&#23450;&#20063;&#38656;&#35201;&#30456;&#24403;&#22823;&#30340;&#21162;&#21147;&#12290;&#27492;&#22806;&#65292;&#38543;&#30528;&#32593;&#32476;&#35268;&#27169;&#21464;&#24471;&#36807;&#20110;&#24222;&#22823;&#65292;&#22823;&#37327;&#36164;&#28304;&#34987;&#25237;&#20837;&#21040;&#32553;&#23567;&#23427;&#20204;&#30340;&#22823;&#23567;&#12290;&#36825;&#20123;&#25361;&#25112;&#21487;&#20197;&#36890;&#36807;&#23545;&#36807;&#23436;&#22791;&#27169;&#22411;&#36827;&#34892;&#31232;&#30095;&#21270;&#26469;&#26377;&#25928;&#35299;&#20915;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#20840;&#21487;&#24494;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#31232;&#30095;&#21270;&#26041;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#30452;&#25509;&#20248;&#21270;&#24102;&#26377;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#27491;&#21017;&#21270;&#30446;&#26631;&#20989;&#25968;&#23558;&#26080;&#20851;&#32039;&#35201;&#30340;&#21442;&#25968;&#32622;&#38646;&#12290;&#22240;&#27492;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#31471;&#21040;&#31471;&#22320;&#23398;&#20064;&#32593;&#32476;&#30340;&#31232;&#30095;&#32467;&#26500;&#21644;&#26435;&#37325;&#12290;&#23427;&#21487;&#20197;&#30452;&#25509;&#24212;&#29992;&#20110;&#21508;&#31181;&#29616;&#20195;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#23545;&#35757;&#32451;&#36807;&#31243;&#30340;&#20462;&#25913;&#35201;&#27714;&#24456;&#23567;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#23436;&#20840;&#21487;&#24494;&#30340;&#31232;&#30095;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks have significantly alleviated the burden of feature engineering, but comparable efforts are now required to determine effective architectures for these networks. Furthermore, as network sizes have become excessively large, a substantial amount of resources is invested in reducing their sizes. These challenges can be effectively addressed through the sparsification of over-complete models. In this study, we propose a fully differentiable sparsification method for deep neural networks, which can zero out unimportant parameters by directly optimizing a regularized objective function with stochastic gradient descent. Consequently, the proposed method can learn both the sparsified structure and weights of a network in an end-to-end manner. It can be directly applied to various modern deep neural networks and requires minimal modification to the training process. To the best of our knowledge, this is the first fully differentiable sparsification method.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#38543;&#26426;&#23454;&#39564;&#20013;&#20272;&#31639;&#21644;&#25512;&#26029;&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#24212;&#30340;&#20851;&#38190;&#29305;&#24449;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#21360;&#24230;&#20813;&#30123;&#35745;&#21010;&#30340;&#25968;&#25454;&#20013;&#65292;&#33719;&#24471;&#26377;&#25928;&#25512;&#26029;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/1712.04802</link><description>&lt;p&gt;
Fischer-Schultz &#35762;&#24231;&#65306;&#38543;&#26426;&#23454;&#39564;&#20013;&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#24212;&#30340;&#36890;&#29992;&#26426;&#22120;&#23398;&#20064;&#25512;&#26029;&#65292;&#20197;&#21360;&#24230;&#20813;&#30123;&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
Fischer-Schultz Lecture: Generic Machine Learning Inference on Heterogenous Treatment Effects in Randomized Experiments, with an Application to Immunization in India. (arXiv:1712.04802v7 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1712.04802
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#38543;&#26426;&#23454;&#39564;&#20013;&#20272;&#31639;&#21644;&#25512;&#26029;&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#24212;&#30340;&#20851;&#38190;&#29305;&#24449;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#21360;&#24230;&#20813;&#30123;&#35745;&#21010;&#30340;&#25968;&#25454;&#20013;&#65292;&#33719;&#24471;&#26377;&#25928;&#25512;&#26029;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31574;&#30053;&#65292;&#29992;&#20110;&#22312;&#38543;&#26426;&#23454;&#39564;&#20013;&#20272;&#31639;&#21644;&#25512;&#26029;&#24322;&#36136;&#24615;&#25928;&#24212;&#30340;&#20851;&#38190;&#29305;&#24449;&#12290;&#36825;&#20123;&#20851;&#38190;&#29305;&#24449;&#21253;&#25324;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#20195;&#29702;&#30340;&#25928;&#24212;&#30340;&#26368;&#20339;&#32447;&#24615;&#39044;&#27979;&#22120;&#65292;&#25353;&#24433;&#21709;&#32452;&#25490;&#24207;&#30340;&#24179;&#22343;&#25928;&#24212;&#20197;&#21450;&#26368;&#21463;&#24433;&#21709;&#21333;&#20301;&#30340;&#24179;&#22343;&#29305;&#24449;&#21644;&#26368;&#19981;&#21463;&#24433;&#21709;&#30340;&#21333;&#20301;&#12290;&#35813;&#26041;&#27861;&#22312;&#39640;&#32500;&#35774;&#32622;&#20013;&#26377;&#25928;&#65292;&#20854;&#20013;&#25928;&#24212;&#30001;&#39044;&#27979;&#21644;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#20195;&#29702;&#65288;&#20294;&#19981;&#19968;&#23450;&#26159;&#19968;&#33268;&#20272;&#35745;&#30340;&#65289;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#20195;&#29702;&#21518;&#22788;&#29702;&#25104;&#20851;&#38190;&#29305;&#24449;&#30340;&#20272;&#35745;&#20540;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#36890;&#29992;&#30340;&#65292;&#21487;&#20197;&#19982;&#26377;&#24809;&#32602;&#30340;&#26041;&#27861;&#65292;&#31070;&#32463;&#32593;&#32476;&#65292;&#38543;&#26426;&#26862;&#26519;&#65292;&#25552;&#21319;&#26641;&#21644;&#38598;&#25104;&#26041;&#27861;&#19968;&#36215;&#20351;&#29992;&#65292;&#26082;&#21487;&#20197;&#36827;&#34892;&#39044;&#27979;&#20063;&#21487;&#20197;&#36827;&#34892;&#22240;&#26524;&#20998;&#26512;&#12290;&#20272;&#35745;&#21644;&#25512;&#26029;&#22522;&#20110;&#37325;&#22797;&#25968;&#25454;&#20998;&#21106;&#65292;&#20197;&#36991;&#20813;&#36807;&#24230;&#25311;&#21512;&#24182;&#23454;&#29616;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#32467;&#26524;&#30340;&#20998;&#20301;&#32858;&#21512;&#26469;&#33258;&#35768;&#22810;&#28508;&#22312;&#30340;&#20998;&#21106;&#65292;&#29305;&#21035;&#26159;&#21462;p&#20540;&#30340;&#20013;&#20301;&#25968;&#21644;&#32622;&#20449;&#21306;&#38388;&#30340;&#20013;&#20301;&#25968;&#21644;&#20854;&#20182;&#20998;&#20301;&#25968;&#12290;&#25105;&#20204;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#21360;&#24230;&#19968;&#39033;&#22823;&#22411;&#20813;&#30123;&#35745;&#21010;&#30340;&#25968;&#25454;&#20013;&#65292;&#20272;&#35745;&#20813;&#30123;&#23545;&#20799;&#31461;&#21457;&#30149;&#29575;&#21644;&#27515;&#20129;&#29575;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#39640;&#32500;&#24230;&#65292;&#24322;&#36136;&#24615;&#22788;&#29702;&#35774;&#32622;&#20013;&#20135;&#29983;&#26377;&#25928;&#30340;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose strategies to estimate and make inference on key features of heterogeneous effects in randomized experiments. These key features include best linear predictors of the effects using machine learning proxies, average effects sorted by impact groups, and average characteristics of most and least impacted units. The approach is valid in high dimensional settings, where the effects are proxied (but not necessarily consistently estimated) by predictive and causal machine learning methods. We post-process these proxies into estimates of the key features. Our approach is generic, it can be used in conjunction with penalized methods, neural networks, random forests, boosted trees, and ensemble methods, both predictive and causal. Estimation and inference are based on repeated data splitting to avoid overfitting and achieve validity. We use quantile aggregation of the results across many potential splits, in particular taking medians of p-values and medians and other quantiles of conf
&lt;/p&gt;</description></item></channel></rss>