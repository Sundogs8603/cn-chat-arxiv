<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#35752;&#35770;&#22312;&#35266;&#27979;&#25968;&#25454;&#19979;&#65292;&#36890;&#36807;&#26500;&#36896;&#20004;&#20010;&#26377;&#21521;&#26080;&#29615;&#22270;&#65292;&#24182;&#20849;&#20139;&#20844;&#20849;&#21442;&#25968;&#26469;&#23545;&#20004;&#32452;&#30340;&#20108;&#20803;&#21709;&#24212;&#21464;&#37327;&#21644;&#21327;&#21464;&#37327;&#36827;&#34892;&#24314;&#27169;&#12290;&#21452;&#39640;&#26031;DAG-probit&#27169;&#22411;&#26159;&#22312;&#27492;&#22522;&#30784;&#19978;&#25552;&#20986;&#30340;&#65292;&#22312;&#27169;&#22411;&#20013;&#25105;&#20204;&#21487;&#20197;&#20272;&#35745;&#27599;&#20010;&#33410;&#28857;&#30340;&#25928;&#24212;&#22823;&#23567;&#12290;</title><link>http://arxiv.org/abs/2304.05976</link><description>&lt;p&gt;
&#21452;&#39640;&#26031;DAG-probit&#27169;&#22411;&#20013;&#30340;&#36125;&#21494;&#26031;&#22240;&#26524;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Bayesian Causal Inference in Doubly Gaussian DAG-probit Models. (arXiv:2304.05976v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05976
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#22312;&#35266;&#27979;&#25968;&#25454;&#19979;&#65292;&#36890;&#36807;&#26500;&#36896;&#20004;&#20010;&#26377;&#21521;&#26080;&#29615;&#22270;&#65292;&#24182;&#20849;&#20139;&#20844;&#20849;&#21442;&#25968;&#26469;&#23545;&#20004;&#32452;&#30340;&#20108;&#20803;&#21709;&#24212;&#21464;&#37327;&#21644;&#21327;&#21464;&#37327;&#36827;&#34892;&#24314;&#27169;&#12290;&#21452;&#39640;&#26031;DAG-probit&#27169;&#22411;&#26159;&#22312;&#27492;&#22522;&#30784;&#19978;&#25552;&#20986;&#30340;&#65292;&#22312;&#27169;&#22411;&#20013;&#25105;&#20204;&#21487;&#20197;&#20272;&#35745;&#27599;&#20010;&#33410;&#28857;&#30340;&#25928;&#24212;&#22823;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#35266;&#23519;&#25968;&#25454;&#19979;&#65292;&#23545;&#20004;&#20010;&#32452;&#30340;&#20108;&#20803;&#21709;&#24212;&#21464;&#37327;&#20197;&#21450;&#19968;&#32452;&#21327;&#21464;&#37327;&#36827;&#34892;&#24314;&#27169;&#12290;&#20998;&#32452;&#21464;&#37327;&#21487;&#20197;&#26159;&#28151;&#28102;&#21464;&#37327;&#65288;&#27835;&#30103;&#21644;&#32467;&#26524;&#30340;&#20849;&#21516;&#21407;&#22240;&#65289;&#65292;&#24615;&#21035;&#65292;&#30149;&#20363;/&#23545;&#29031;&#32452;&#65292;&#31181;&#26063;&#31561;&#12290;&#32473;&#23450;&#21327;&#21464;&#37327;&#21644;&#19968;&#20010;&#20108;&#20803;&#28508;&#21464;&#37327;&#65292;&#30446;&#26631;&#26159;&#26500;&#36896;&#20004;&#20010;&#26377;&#21521;&#26080;&#29615;&#22270;(DAGs),&#21516;&#26102;&#20849;&#20139;&#19968;&#20123;&#20844;&#20849;&#21442;&#25968;&#12290;&#34920;&#31034;&#21464;&#37327;&#30340;&#33410;&#28857;&#38598;&#23545;&#20110;&#20004;&#32452;&#26159;&#30456;&#21516;&#30340;&#65292;&#20294;&#34920;&#31034;&#21464;&#37327;&#20043;&#38388;&#22240;&#26524;&#20851;&#31995;&#30340;&#26377;&#21521;&#36793;&#21487;&#20197;&#26377;&#28508;&#22312;&#30340;&#21306;&#21035;&#12290;&#23545;&#20110;&#27599;&#20010;&#32452;&#65292;&#25105;&#20204;&#36824;&#20272;&#35745;&#20102;&#27599;&#20010;&#33410;&#28857;&#30340;&#25928;&#24212;&#22823;&#23567;&#12290;&#25105;&#20204;&#20551;&#35774;&#27599;&#20010;&#32452;&#22312;&#20854;DAG&#19979;&#31526;&#21512;&#39640;&#26031;&#20998;&#24067;&#12290;&#30001;&#20110;DAG&#30340;&#39532;&#23572;&#31185;&#22827;&#24615;&#36136;&#65292;&#32473;&#23450;&#29238;&#33410;&#28857;&#21518;&#65292;DAG&#30340;&#32852;&#21512;&#20998;&#24067;&#26159;&#26465;&#20214;&#29420;&#31435;&#30340;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#32452;&#19979;&#24341;&#20837;&#20102;&#39640;&#26031;DAG-probit&#27169;&#22411;&#30340;&#27010;&#24565;&#65292;&#22240;&#27492;&#26159;&#21452;&#39640;&#26031;DAG-probit&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider modeling a binary response variable together with a set of covariates for two groups under observational data. The grouping variable can be the confounding variable (the common cause of treatment and outcome), gender, case/control, ethnicity, etc. Given the covariates and a binary latent variable, the goal is to construct two directed acyclic graphs (DAGs), while sharing some common parameters. The set of nodes, which represent the variables, are the same for both groups but the directed edges between nodes, which represent the causal relationships between the variables, can be potentially different. For each group, we also estimate the effect size for each node. We assume that each group follows a Gaussian distribution under its DAG. Given the parent nodes, the joint distribution of DAG is conditionally independent due to the Markov property of DAGs. We introduce the concept of Gaussian DAG-probit model under two groups and hence doubly Gaussian DAG-probit model. To estima
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#8220;&#30830;&#23450;&#24615;ADVI&#8221;&#65288;DADVI&#65289;&#65292;&#23427;&#29992;&#19968;&#31181;&#22266;&#23450;&#30340;&#33945;&#29305;&#21345;&#32599;&#36817;&#20284;&#26367;&#25442;&#20102;&#22343;&#20540;&#22330;&#21464;&#20998;&#36125;&#21494;&#26031;&#65288;MFVB&#65289;&#30340;&#19981;&#21487;&#35299;&#30446;&#26631;&#65292;&#21487;&#20197;&#20351;&#29992;&#29616;&#25104;&#30340;&#20108;&#38454;&#20248;&#21270;&#65292;&#36866;&#29992;&#20110;&#26356;&#20934;&#30830;&#30340;&#21518;&#39564;&#32447;&#24615;&#21709;&#24212;&#65288;LR&#65289;&#21327;&#26041;&#24046;&#20272;&#35745;&#65292;&#22312;&#26576;&#20123;&#24120;&#35265;&#30340;&#32479;&#35745;&#38382;&#39064;&#31867;&#21035;&#19978;&#25928;&#26524;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2304.05527</link><description>&lt;p&gt;
&#19968;&#31181;&#20351;&#29992;&#30830;&#23450;&#24615;&#30446;&#26631;&#30340;&#40657;&#21283;&#23376;&#21464;&#20998;&#25512;&#26029;&#65306;&#26356;&#24555;&#65292;&#26356;&#31934;&#30830;&#65292;&#26356;&#40657;&#12290;
&lt;/p&gt;
&lt;p&gt;
Black Box Variational Inference with a Deterministic Objective: Faster, More Accurate, and Even More Black Box. (arXiv:2304.05527v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05527
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#8220;&#30830;&#23450;&#24615;ADVI&#8221;&#65288;DADVI&#65289;&#65292;&#23427;&#29992;&#19968;&#31181;&#22266;&#23450;&#30340;&#33945;&#29305;&#21345;&#32599;&#36817;&#20284;&#26367;&#25442;&#20102;&#22343;&#20540;&#22330;&#21464;&#20998;&#36125;&#21494;&#26031;&#65288;MFVB&#65289;&#30340;&#19981;&#21487;&#35299;&#30446;&#26631;&#65292;&#21487;&#20197;&#20351;&#29992;&#29616;&#25104;&#30340;&#20108;&#38454;&#20248;&#21270;&#65292;&#36866;&#29992;&#20110;&#26356;&#20934;&#30830;&#30340;&#21518;&#39564;&#32447;&#24615;&#21709;&#24212;&#65288;LR&#65289;&#21327;&#26041;&#24046;&#20272;&#35745;&#65292;&#22312;&#26576;&#20123;&#24120;&#35265;&#30340;&#32479;&#35745;&#38382;&#39064;&#31867;&#21035;&#19978;&#25928;&#26524;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#24494;&#20998;&#21464;&#20998;&#25512;&#26029;&#65288;ADVI&#65289;&#25552;&#20379;&#20102;&#22810;&#31181;&#29616;&#20195;&#27010;&#29575;&#32534;&#31243;&#35821;&#35328;&#20013;&#24555;&#36895;&#26131;&#29992;&#30340;&#21518;&#39564;&#36817;&#20284;&#26041;&#27861;&#12290;&#28982;&#32780;&#23427;&#30340;&#38543;&#26426;&#20248;&#21270;&#22120;&#32570;&#20047;&#26126;&#30830;&#30340;&#25910;&#25947;&#26631;&#20934;&#65292;&#24182;&#19988;&#38656;&#35201;&#35843;&#25972;&#21442;&#25968;&#12290;&#27492;&#22806;&#65292;ADVI&#32487;&#25215;&#20102;&#22343;&#20540;&#22330;&#21464;&#20998;&#36125;&#21494;&#26031;&#65288;MFVB&#65289;&#30340;&#36739;&#24046;&#21518;&#39564;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#8220;&#30830;&#23450;&#24615;ADVI&#8221;&#65288;DADVI&#65289;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;DADVI&#29992;&#22266;&#23450;&#30340;&#33945;&#29305;&#21345;&#32599;&#36817;&#20284;&#26367;&#25442;&#20102;MFVB&#30340;&#19981;&#21487;&#35299;&#30446;&#26631;&#65292;&#36825;&#19968;&#25216;&#26415;&#22312;&#38543;&#26426;&#20248;&#21270;&#25991;&#29486;&#20013;&#34987;&#31216;&#20026;&#8220;&#26679;&#26412;&#24179;&#22343;&#36817;&#20284;&#8221;&#65288;SAA&#65289;&#12290;&#36890;&#36807;&#20248;&#21270;&#36817;&#20284;&#20294;&#30830;&#23450;&#30340;&#30446;&#26631;&#65292;DADVI&#21487;&#20197;&#20351;&#29992;&#29616;&#25104;&#30340;&#20108;&#38454;&#20248;&#21270;&#65292;&#32780;&#19988;&#19982;&#26631;&#20934;&#22343;&#20540;&#22330;ADVI&#19981;&#21516;&#30340;&#26159;&#65292;&#21487;&#20197;&#36866;&#29992;&#20110;&#26356;&#20934;&#30830;&#30340;&#21518;&#39564;&#32447;&#24615;&#21709;&#24212;&#65288;LR&#65289;&#21327;&#26041;&#24046;&#20272;&#35745;&#12290;&#19982;&#29616;&#26377;&#30340;&#26368;&#22351;&#24773;&#20917;&#29702;&#35770;&#30456;&#21453;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312;&#26576;&#20123;&#24120;&#35265;&#30340;&#32479;&#35745;&#38382;&#39064;&#31867;&#21035;&#19978;&#65292;DADVI&#21644;SAA&#21487;&#20197;&#34920;&#29616;&#24471;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Automatic differentiation variational inference (ADVI) offers fast and easy-to-use posterior approximation in multiple modern probabilistic programming languages. However, its stochastic optimizer lacks clear convergence criteria and requires tuning parameters. Moreover, ADVI inherits the poor posterior uncertainty estimates of mean-field variational Bayes (MFVB). We introduce ``deterministic ADVI'' (DADVI) to address these issues. DADVI replaces the intractable MFVB objective with a fixed Monte Carlo approximation, a technique known in the stochastic optimization literature as the ``sample average approximation'' (SAA). By optimizing an approximate but deterministic objective, DADVI can use off-the-shelf second-order optimization, and, unlike standard mean-field ADVI, is amenable to more accurate posterior linear response (LR) covariance estimates. In contrast to existing worst-case theory, we show that, on certain classes of common statistical problems, DADVI and the SAA can perform 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;ChemCrow&#65292;&#19968;&#31181;LLM&#21270;&#23398;&#20195;&#29702;&#65292;&#36890;&#36807;&#25972;&#21512;13&#20010;&#19987;&#23478;&#35774;&#35745;&#30340;&#24037;&#20855;&#20174;&#32780;&#22686;&#24378;LLM&#22312;&#21270;&#23398;&#39046;&#22495;&#30340;&#24615;&#33021;&#65292;&#22312;&#21270;&#23398;&#20219;&#21153;&#20013;&#23454;&#29616;&#33258;&#21160;&#21270;&#65292;&#25552;&#39640;&#20102;&#25928;&#29575;&#21644;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.05376</link><description>&lt;p&gt;
ChemCrow:&#29992;&#21270;&#23398;&#24037;&#20855;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
ChemCrow: Augmenting large-language models with chemistry tools. (arXiv:2304.05376v1 [physics.chem-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05376
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;ChemCrow&#65292;&#19968;&#31181;LLM&#21270;&#23398;&#20195;&#29702;&#65292;&#36890;&#36807;&#25972;&#21512;13&#20010;&#19987;&#23478;&#35774;&#35745;&#30340;&#24037;&#20855;&#20174;&#32780;&#22686;&#24378;LLM&#22312;&#21270;&#23398;&#39046;&#22495;&#30340;&#24615;&#33021;&#65292;&#22312;&#21270;&#23398;&#20219;&#21153;&#20013;&#23454;&#29616;&#33258;&#21160;&#21270;&#65292;&#25552;&#39640;&#20102;&#25928;&#29575;&#21644;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#36328;&#39046;&#22495;&#30340;&#20219;&#21153;&#34920;&#29616;&#20986;&#19968;&#23450;&#30340;&#20248;&#21183;&#65292;&#20294;&#22312;&#21270;&#23398;&#30456;&#20851;&#38382;&#39064;&#19978;&#21364;&#34920;&#29616;&#19981;&#20339;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#27169;&#22411;&#32570;&#20047;&#35775;&#38382;&#22806;&#37096;&#30693;&#35782;&#28304;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#31185;&#23398;&#24212;&#29992;&#20013;&#30340;&#26377;&#29992;&#24615;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;ChemCrow&#65292;&#19968;&#31181;LLM&#21270;&#23398;&#20195;&#29702;&#65292;&#26088;&#22312;&#23436;&#25104;&#26377;&#26426;&#21512;&#25104;&#12289;&#33647;&#29289;&#21457;&#29616;&#21644;&#26448;&#26009;&#35774;&#35745;&#31561;&#20219;&#21153;&#12290;&#36890;&#36807;&#25972;&#21512;13&#20010;&#19987;&#23478;&#35774;&#35745;&#30340;&#24037;&#20855;&#65292;ChemCrow&#25552;&#39640;&#20102;LLM&#22312;&#21270;&#23398;&#20013;&#30340;&#24615;&#33021;&#65292;&#24182;&#20135;&#29983;&#20102;&#26032;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#65292;&#21253;&#25324;LLM&#21644;&#20154;&#31867;&#19987;&#23478;&#35780;&#20272;&#65292;&#35777;&#26126;&#20102;ChemCrow&#22312;&#33258;&#21160;&#21270;&#21508;&#31181;&#21270;&#23398;&#20219;&#21153;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;GPT-4&#20316;&#20026;&#35780;&#20272;&#22120;&#26080;&#27861;&#21306;&#20998;&#26126;&#26174;&#38169;&#35823;&#30340;GPT-4&#23436;&#25104;&#21644;GPT-4 + ChemCrow&#24615;&#33021;&#12290;&#36825;&#31181;&#24037;&#20855;&#30340;&#28389;&#29992;&#26377;&#24456;&#22823;&#30340;&#39118;&#38505;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#23427;&#20204;&#30340;&#28508;&#22312;&#21361;&#23475;&#12290;&#22312;&#36127;&#36131;&#20219;&#30340;&#24773;&#20917;&#19979;&#65292;ChemCrow&#19981;&#20165;&#21487;&#20197;&#24110;&#21161;&#19987;&#19994;&#21270;&#23398;&#23478;&#24182;&#38477;&#20302;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large-language models (LLMs) have recently shown strong performance in tasks across domains, but struggle with chemistry-related problems. Moreover, these models lack access to external knowledge sources, limiting their usefulness in scientific applications. In this study, we introduce ChemCrow, an LLM chemistry agent designed to accomplish tasks across organic synthesis, drug discovery, and materials design. By integrating 13 expert-designed tools, ChemCrow augments the LLM performance in chemistry, and new capabilities emerge. Our evaluation, including both LLM and expert human assessments, demonstrates ChemCrow's effectiveness in automating a diverse set of chemical tasks. Surprisingly, we find that GPT-4 as an evaluator cannot distinguish between clearly wrong GPT-4 completions and GPT-4 + ChemCrow performance. There is a significant risk of misuse of tools like ChemCrow and we discuss their potential harms. Employed responsibly, ChemCrow not only aids expert chemists and lowers ba
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#25968;&#25454;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#21516;&#26102;&#22788;&#29702;&#19968;&#32452;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#65292;&#29983;&#25104;&#19968;&#20010;&#21333;&#19968;&#30340;&#22240;&#26524;&#39537;&#21160;&#38598;&#65292;&#24182;&#19988;&#21487;&#20197;&#36807;&#28388;&#25481;&#22240;&#26524;&#34394;&#20551;&#38142;&#25509;&#65292;&#26368;&#32456;&#36755;&#20837;&#21040;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#39044;&#27979;&#30446;&#26631;&#12290;</title><link>http://arxiv.org/abs/2304.05294</link><description>&lt;p&gt;
&#20351;&#29992;&#22810;&#25968;&#25454;&#22240;&#26524;&#25512;&#26029;&#36873;&#25321;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#30340;&#24378;&#20581;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Selecting Robust Features for Machine Learning Applications using Multidata Causal Discovery. (arXiv:2304.05294v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05294
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#25968;&#25454;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#21516;&#26102;&#22788;&#29702;&#19968;&#32452;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#65292;&#29983;&#25104;&#19968;&#20010;&#21333;&#19968;&#30340;&#22240;&#26524;&#39537;&#21160;&#38598;&#65292;&#24182;&#19988;&#21487;&#20197;&#36807;&#28388;&#25481;&#22240;&#26524;&#34394;&#20551;&#38142;&#25509;&#65292;&#26368;&#32456;&#36755;&#20837;&#21040;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#39044;&#27979;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#20581;&#30340;&#29305;&#24449;&#36873;&#25321;&#23545;&#20110;&#21019;&#24314;&#21487;&#38752;&#21644;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#27169;&#22411;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#39046;&#22495;&#30693;&#35782;&#26377;&#38480;&#12289;&#28508;&#22312;&#20132;&#20114;&#26410;&#30693;&#30340;&#24773;&#20917;&#19979;&#35774;&#35745;&#32479;&#35745;&#39044;&#27979;&#27169;&#22411;&#26102;&#65292;&#36873;&#25321;&#26368;&#20248;&#29305;&#24449;&#38598;&#36890;&#24120;&#24456;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22810;&#25968;&#25454;&#65288;M&#65289;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#23427;&#21516;&#26102;&#22788;&#29702;&#19968;&#32452;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#65292;&#24182;&#29983;&#25104;&#19968;&#20010;&#21333;&#19968;&#30340;&#22240;&#26524;&#39537;&#21160;&#38598;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;Tigramite Python&#21253;&#20013;&#23454;&#29616;&#30340;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;PC1&#25110;PCMCI&#12290;&#36825;&#20123;&#31639;&#27861;&#21033;&#29992;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#25512;&#26029;&#22240;&#26524;&#22270;&#30340;&#37096;&#20998;&#12290;&#25105;&#20204;&#30340;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#22312;&#23558;&#21097;&#20313;&#22240;&#26524;&#29305;&#24449;&#20316;&#20026;&#36755;&#20837;&#20256;&#36882;&#32473;ML&#27169;&#22411;&#65288;&#22810;&#20803;&#32447;&#24615;&#22238;&#24402;&#65292;&#38543;&#26426;&#26862;&#26519;&#65289;&#39044;&#27979;&#30446;&#26631;&#20043;&#21069;&#65292;&#36807;&#28388;&#25481;&#22240;&#26524;&#34394;&#20551;&#38142;&#25509;&#12290;&#25105;&#20204;&#23558;&#35813;&#26694;&#26550;&#24212;&#29992;&#20110;&#39044;&#27979;&#35199;&#22826;&#24179;&#27915;&#28909;&#24102;&#22320;&#21306;&#30340;&#22320;&#38663;&#24378;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Robust feature selection is vital for creating reliable and interpretable Machine Learning (ML) models. When designing statistical prediction models in cases where domain knowledge is limited and underlying interactions are unknown, choosing the optimal set of features is often difficult. To mitigate this issue, we introduce a Multidata (M) causal feature selection approach that simultaneously processes an ensemble of time series datasets and produces a single set of causal drivers. This approach uses the causal discovery algorithms PC1 or PCMCI that are implemented in the Tigramite Python package. These algorithms utilize conditional independence tests to infer parts of the causal graph. Our causal feature selection approach filters out causally-spurious links before passing the remaining causal features as inputs to ML models (Multiple linear regression, Random Forest) that predict the targets. We apply our framework to the statistical intensity prediction of Western Pacific Tropical
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#28151;&#27788;&#36793;&#32536;&#21021;&#22987;&#21270;&#26102;&#30340;&#35757;&#32451;&#33021;&#21147;&#65292;&#21457;&#29616;&#39281;&#21644;&#30340;&#28608;&#27963;&#20989;&#25968;&#20250;&#22952;&#30861;&#35757;&#32451;&#25928;&#29575;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#27839;&#28151;&#27788;&#36793;&#32536;&#21021;&#22987;&#21270;&#21482;&#26159;&#33719;&#24471;&#26368;&#20339;&#21487;&#35757;&#32451;&#24615;&#25152;&#24517;&#38656;&#20294;&#19981;&#20805;&#20998;&#30340;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2304.04784</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20020;&#30028;&#24615;&#19982;&#22343;&#21248;&#24615;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Criticality versus uniformity in deep neural networks. (arXiv:2304.04784v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04784
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#28151;&#27788;&#36793;&#32536;&#21021;&#22987;&#21270;&#26102;&#30340;&#35757;&#32451;&#33021;&#21147;&#65292;&#21457;&#29616;&#39281;&#21644;&#30340;&#28608;&#27963;&#20989;&#25968;&#20250;&#22952;&#30861;&#35757;&#32451;&#25928;&#29575;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#27839;&#28151;&#27788;&#36793;&#32536;&#21021;&#22987;&#21270;&#21482;&#26159;&#33719;&#24471;&#26368;&#20339;&#21487;&#35757;&#32451;&#24615;&#25152;&#24517;&#38656;&#20294;&#19981;&#20805;&#20998;&#30340;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27839;&#30528;&#28151;&#27788;&#36793;&#32536;&#21021;&#22987;&#21270;&#30340;&#28145;&#23618;&#21069;&#39304;&#32593;&#32476;&#34920;&#29616;&#20986;&#25351;&#25968;&#32423;&#20248;&#36234;&#30340;&#35757;&#32451;&#33021;&#21147;&#65292;&#20854;&#26368;&#22823;&#21487;&#35757;&#32451;&#28145;&#24230;&#21487;&#20197;&#37327;&#21270;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#27839;&#28151;&#27788;&#36793;&#32536;&#39281;&#21644;tanh&#28608;&#27963;&#20989;&#25968;&#30340;&#24433;&#21709;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#30456;&#31354;&#38388;&#20013;&#26368;&#22823;&#29109;&#30340;&#21518;&#28608;&#27963;&#20998;&#24067;&#30340;&#22343;&#21248;&#24615;&#32447;&#12290;&#35813;&#32447;&#20132;&#21449;&#20110;&#28151;&#27788;&#36793;&#32536;&#65292;&#24182;&#25351;&#31034;&#20102;&#36229;&#36807;&#28608;&#27963;&#20989;&#25968;&#39281;&#21644;&#24320;&#22987;&#22952;&#30861;&#35757;&#32451;&#25928;&#29575;&#30340;&#21306;&#22495;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#27839;&#28151;&#27788;&#36793;&#32536;&#21021;&#22987;&#21270;&#26159;&#33719;&#24471;&#26368;&#20339;&#21487;&#35757;&#32451;&#24615;&#25152;&#24517;&#38656;&#20294;&#19981;&#20805;&#20998;&#30340;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep feedforward networks initialized along the edge of chaos exhibit exponentially superior training ability as quantified by maximum trainable depth. In this work, we explore the effect of saturation of the tanh activation function along the edge of chaos. In particular, we determine the line of uniformity in phase space along which the post-activation distribution has maximum entropy. This line intersects the edge of chaos, and indicates the regime beyond which saturation of the activation function begins to impede training efficiency. Our results suggest that initialization along the edge of chaos is a necessary but not sufficient condition for optimal trainability.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#21487;&#22797;&#21046;&#24615;&#21644;&#20840;&#23616;&#31283;&#23450;&#24615;&#65292;&#24182;&#35777;&#26126;&#35768;&#22810;&#23398;&#20064;&#20219;&#21153;&#21482;&#33021;&#24369;&#21270;&#22320;&#23454;&#29616;&#20840;&#23616;&#31283;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.03757</link><description>&lt;p&gt;
&#23398;&#20064;&#20013;&#30340;&#21487;&#22797;&#21046;&#24615;&#21644;&#31283;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Replicability and stability in learning. (arXiv:2304.03757v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03757
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#21487;&#22797;&#21046;&#24615;&#21644;&#20840;&#23616;&#31283;&#23450;&#24615;&#65292;&#24182;&#35777;&#26126;&#35768;&#22810;&#23398;&#20064;&#20219;&#21153;&#21482;&#33021;&#24369;&#21270;&#22320;&#23454;&#29616;&#20840;&#23616;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#22797;&#21046;&#24615;&#26159;&#31185;&#23398;&#20013;&#30340;&#20851;&#38190;&#65292;&#22240;&#20026;&#23427;&#20351;&#25105;&#20204;&#33021;&#22815;&#39564;&#35777;&#21644;&#39564;&#35777;&#30740;&#31350;&#32467;&#26524;&#12290;Impagliazzo&#12289;Lei&#12289;Pitassi&#21644;Sorrell&#65288;'22&#65289;&#26368;&#36817;&#24320;&#22987;&#30740;&#31350;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#21487;&#22797;&#21046;&#24615;&#12290;&#22914;&#26524;&#21516;&#19968;&#31639;&#27861;&#22312;&#20004;&#20010;&#29420;&#31435;&#21516;&#20998;&#24067;&#36755;&#20837;&#19978;&#20351;&#29992;&#30456;&#21516;&#30340;&#20869;&#37096;&#38543;&#26426;&#24615;&#26102;&#36890;&#24120;&#20135;&#29983;&#30456;&#21516;&#30340;&#36755;&#20986;&#65292;&#21017;&#23398;&#20064;&#31639;&#27861;&#26159;&#21487;&#22797;&#21046;&#30340;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#19981;&#28041;&#21450;&#22266;&#23450;&#38543;&#26426;&#24615;&#30340;&#21487;&#22797;&#21046;&#24615;&#21464;&#20307;&#12290;&#22914;&#26524;&#19968;&#20010;&#31639;&#27861;&#22312;&#20004;&#20010;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#36755;&#20837;&#19978;&#65288;&#19981;&#22266;&#23450;&#20869;&#37096;&#38543;&#26426;&#24615;&#65289;&#24212;&#29992;&#26102;&#36890;&#24120;&#20135;&#29983;&#30456;&#21516;&#30340;&#36755;&#20986;&#65292;&#21017;&#31639;&#27861;&#28385;&#36275;&#36825;&#31181;&#24418;&#24335;&#30340;&#21487;&#22797;&#21046;&#24615;&#12290;&#36825;&#20010;&#21464;&#31181;&#34987;&#31216;&#20026;&#20840;&#23616;&#31283;&#23450;&#24615;&#65292;&#24182;&#22312;&#24046;&#20998;&#38544;&#31169;&#30340;&#19978;&#19979;&#25991;&#20013;&#30001;Bun&#12289;Livni&#21644;Moran&#65288;'20&#65289;&#20171;&#32461;&#12290; Impagliazzo&#31561;&#20154;&#23637;&#31034;&#20102;&#22914;&#20309;&#25552;&#39640;&#20219;&#20309;&#21487;&#22797;&#21046;&#31639;&#27861;&#30340;&#25928;&#26524;&#65292;&#20197;&#20351;&#20854;&#20135;&#29983;&#30340;&#36755;&#20986;&#27010;&#29575;&#26080;&#38480;&#25509;&#36817;&#20110;1&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#35768;&#22810;&#23398;&#20064;&#20219;&#21153;&#65292;&#21482;&#33021;&#24369;&#21270;&#22320;&#23454;&#29616;&#20840;&#23616;&#31283;&#23450;&#24615;&#65292;&#36825;&#37324;&#36755;&#20986;&#21482;&#26377;&#30456;&#21516;&#30340;&#37096;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
Replicability is essential in science as it allows us to validate and verify research findings. Impagliazzo, Lei, Pitassi and Sorrell (`22) recently initiated the study of replicability in machine learning. A learning algorithm is replicable if it typically produces the same output when applied on two i.i.d. inputs using the same internal randomness. We study a variant of replicability that does not involve fixing the randomness. An algorithm satisfies this form of replicability if it typically produces the same output when applied on two i.i.d. inputs (without fixing the internal randomness). This variant is called global stability and was introduced by Bun, Livni and Moran (`20) in the context of differential privacy.  Impagliazzo et al. showed how to boost any replicable algorithm so that it produces the same output with probability arbitrarily close to 1. In contrast, we demonstrate that for numerous learning tasks, global stability can only be accomplished weakly, where the same o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#30340;&#33258;&#36866;&#24212;&#23398;&#29983;t&#20998;&#24067;&#26041;&#27861;&#65292;&#22522;&#20110;&#26041;&#27861;&#30340;&#19968;&#33324;&#33258;&#36866;&#24212;&#30697;&#21487;&#20197;&#20351;&#29992;&#24265;&#20215;&#30340;&#25351;&#25968;&#31227;&#21160;&#24179;&#22343;&#20540;&#65288;EMA&#65289;&#26469;&#20272;&#35745;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/2304.03069</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#23398;&#29983;t&#20998;&#24067;&#19982;&#26041;&#27861;&#30697;&#31227;&#21160;&#20272;&#35745;&#22120;&#29992;&#20110;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;
&lt;/p&gt;
&lt;p&gt;
Adaptive Student's t-distribution with method of moments moving estimator for nonstationary time series. (arXiv:2304.03069v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03069
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#30340;&#33258;&#36866;&#24212;&#23398;&#29983;t&#20998;&#24067;&#26041;&#27861;&#65292;&#22522;&#20110;&#26041;&#27861;&#30340;&#19968;&#33324;&#33258;&#36866;&#24212;&#30697;&#21487;&#20197;&#20351;&#29992;&#24265;&#20215;&#30340;&#25351;&#25968;&#31227;&#21160;&#24179;&#22343;&#20540;&#65288;EMA&#65289;&#26469;&#20272;&#35745;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30495;&#23454;&#30340;&#26102;&#38388;&#24207;&#21015;&#36890;&#24120;&#26159;&#38750;&#24179;&#31283;&#30340;&#65292;&#36825;&#24102;&#26469;&#20102;&#27169;&#22411;&#36866;&#24212;&#30340;&#38590;&#39064;&#12290;&#20256;&#32479;&#26041;&#27861;&#22914;GARCH&#20551;&#23450;&#20219;&#24847;&#31867;&#22411;&#30340;&#20381;&#36182;&#24615;&#12290;&#20026;&#20102;&#36991;&#20813;&#36825;&#31181;&#20559;&#24046;&#65292;&#25105;&#20204;&#23558;&#30528;&#30524;&#20110;&#26368;&#36817;&#25552;&#20986;&#30340;&#19981;&#21487;&#30693;&#30340;&#31227;&#21160;&#20272;&#35745;&#22120;&#21746;&#23398;&#65306;&#22312;&#26102;&#38388;$t$&#25214;&#21040;&#20248;&#21270;$F_t=\sum_{\tau&lt;t} (1-\eta)^{t-\tau} \ln(\rho_\theta (x_\tau))$&#31227;&#21160;&#23545;&#25968;&#20284;&#28982;&#30340;&#21442;&#25968;&#65292;&#38543;&#26102;&#38388;&#28436;&#21270;&#12290;&#20363;&#22914;&#65292;&#23427;&#20801;&#35768;&#20351;&#29992;&#24265;&#20215;&#30340;&#25351;&#25968;&#31227;&#21160;&#24179;&#22343;&#20540;&#65288;EMA&#65289;&#26469;&#20272;&#35745;&#21442;&#25968;&#65292;&#20363;&#22914;&#32477;&#23545;&#20013;&#24515;&#30697;$E[|x-\mu|^p]$&#38543;$p\in\mathbb{R}^+$&#30340;&#21464;&#21270;&#32780;&#28436;&#21270;$m_{p,t+1} = m_{p,t} + \eta (|x_t-\mu_t|^p-m_{p,t})$&#12290;&#36825;&#31181;&#22522;&#20110;&#26041;&#27861;&#30340;&#19968;&#33324;&#33258;&#36866;&#24212;&#30697;&#30340;&#24212;&#29992;&#23558;&#21576;&#29616;&#22312;&#23398;&#29983;t&#20998;&#24067;&#19978;&#65292;&#23588;&#20854;&#26159;&#22312;&#32463;&#27982;&#24212;&#29992;&#20013;&#27969;&#34892;&#65292;&#36825;&#37324;&#24212;&#29992;&#20110;DJIA&#20844;&#21496;&#30340;&#23545;&#25968;&#25910;&#30410;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
The real life time series are usually nonstationary, bringing a difficult question of model adaptation. Classical approaches like GARCH assume arbitrary type of dependence. To prevent such bias, we will focus on recently proposed agnostic philosophy of moving estimator: in time $t$ finding parameters optimizing e.g. $F_t=\sum_{\tau&lt;t} (1-\eta)^{t-\tau} \ln(\rho_\theta (x_\tau))$ moving log-likelihood, evolving in time. It allows for example to estimate parameters using inexpensive exponential moving averages (EMA), like absolute central moments $E[|x-\mu|^p]$ evolving with $m_{p,t+1} = m_{p,t} + \eta (|x_t-\mu_t|^p-m_{p,t})$ for one or multiple powers $p\in\mathbb{R}^+$. Application of such general adaptive methods of moments will be presented on Student's t-distribution, popular especially in economical applications, here applied to log-returns of DJIA companies.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#25991;&#26412;&#24341;&#23548;&#22270;&#20687;&#39118;&#26684;&#36801;&#31227;&#20013;&#30340;&#38646;&#26679;&#26412;&#23545;&#27604;&#25439;&#22833;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#38656;&#35201;&#39069;&#22806;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#29983;&#25104;&#20855;&#26377;&#30456;&#21516;&#35821;&#20041;&#20869;&#23481;&#30340;&#22270;&#20687;&#12290;</title><link>http://arxiv.org/abs/2303.08622</link><description>&lt;p&gt;
&#38646;&#26679;&#26412;&#23545;&#27604;&#25439;&#22833;&#29992;&#20110;&#25991;&#26412;&#24341;&#23548;&#25193;&#25955;&#22270;&#20687;&#39118;&#26684;&#36801;&#31227;
&lt;/p&gt;
&lt;p&gt;
Zero-Shot Contrastive Loss for Text-Guided Diffusion Image Style Transfer. (arXiv:2303.08622v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08622
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#25991;&#26412;&#24341;&#23548;&#22270;&#20687;&#39118;&#26684;&#36801;&#31227;&#20013;&#30340;&#38646;&#26679;&#26412;&#23545;&#27604;&#25439;&#22833;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#38656;&#35201;&#39069;&#22806;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#29983;&#25104;&#20855;&#26377;&#30456;&#21516;&#35821;&#20041;&#20869;&#23481;&#30340;&#22270;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#22312;&#25991;&#26412;&#24341;&#23548;&#22270;&#20687;&#39118;&#26684;&#36801;&#31227;&#20013;&#34920;&#29616;&#20986;&#26497;&#22823;&#30340;&#28508;&#21147;&#65292;&#20294;&#30001;&#20110;&#20854;&#38543;&#26426;&#24615;&#32780;&#23384;&#22312;&#39118;&#26684;&#36716;&#25442;&#21644;&#20869;&#23481;&#20445;&#25252;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#29616;&#26377;&#26041;&#27861;&#38656;&#35201;&#35745;&#31639;&#23494;&#38598;&#30340;&#25193;&#25955;&#27169;&#22411;&#24494;&#35843;&#25110;&#38468;&#21152;&#31070;&#32463;&#32593;&#32476;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#22312;&#25193;&#25955;&#27169;&#22411;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#26679;&#26412;&#23545;&#27604;&#25439;&#22833;&#65292;&#23427;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#24494;&#35843;&#25110;&#36741;&#21161;&#32593;&#32476;&#12290;&#36890;&#36807;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#20013;&#29983;&#25104;&#26679;&#26412;&#21644;&#21407;&#22987;&#22270;&#20687;&#23884;&#20837;&#20043;&#38388;&#30340;&#22270;&#22359;&#23545;&#27604;&#25439;&#22833;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20197;&#38646;&#26679;&#26412;&#30340;&#26041;&#24335;&#29983;&#25104;&#20855;&#26377;&#19982;&#28304;&#22270;&#20687;&#30456;&#21516;&#35821;&#20041;&#20869;&#23481;&#30340;&#22270;&#20687;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20445;&#30041;&#20869;&#23481;&#19988;&#19981;&#38656;&#35201;&#39069;&#22806;&#35757;&#32451;&#30340;&#21516;&#26102;&#65292;&#22312;&#22270;&#20687;&#39118;&#26684;&#36801;&#31227;&#12289;&#22270;&#20687;&#21040;&#22270;&#20687;&#30340;&#36716;&#25442;&#21644;&#25805;&#20316;&#20013;&#22343;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#35777;&#23454;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models have shown great promise in text-guided image style transfer, but there is a trade-off between style transformation and content preservation due to their stochastic nature. Existing methods require computationally expensive fine-tuning of diffusion models or additional neural network. To address this, here we propose a zero-shot contrastive loss for diffusion models that doesn't require additional fine-tuning or auxiliary networks. By leveraging patch-wise contrastive loss between generated samples and original image embeddings in the pre-trained diffusion model, our method can generate images with the same semantic content as the source image in a zero-shot manner. Our approach outperforms existing methods while preserving content and requiring no additional training, not only for image style transfer but also for image-to-image translation and manipulation. Our experimental results validate the effectiveness of our proposed method.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20351;&#29992;&#20284;&#28982;&#27604;&#26816;&#39564;&#20026;&#22522;&#20934;&#27979;&#35797;TSC&#31639;&#27861;&#22312;&#21306;&#20998;&#25193;&#25955;&#36807;&#31243;&#20013;&#30340;&#26368;&#20248;&#24615;&#12290;&#38543;&#26426;&#26862;&#26519;&#12289;ResNet&#21644;ROCKET&#31639;&#27861;&#22312;&#21333;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#21644;&#22810;&#20803;&#39640;&#26031;&#36807;&#31243;&#20013;&#21487;&#20197;&#23454;&#29616;LRT&#26368;&#20248;&#24615;&#65292;&#20294;&#22312;&#20998;&#31867;&#39640;&#32500;&#38750;&#32447;&#24615;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#26102;&#26159;&#27425;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2301.13112</link><description>&lt;p&gt;
&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#26041;&#27861;&#22312;&#20998;&#36776;&#25193;&#25955;&#36807;&#31243;&#20013;&#30340;&#26368;&#20248;&#24615;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Benchmarking optimality of time series classification methods in distinguishing diffusions. (arXiv:2301.13112v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13112
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20351;&#29992;&#20284;&#28982;&#27604;&#26816;&#39564;&#20026;&#22522;&#20934;&#27979;&#35797;TSC&#31639;&#27861;&#22312;&#21306;&#20998;&#25193;&#25955;&#36807;&#31243;&#20013;&#30340;&#26368;&#20248;&#24615;&#12290;&#38543;&#26426;&#26862;&#26519;&#12289;ResNet&#21644;ROCKET&#31639;&#27861;&#22312;&#21333;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#21644;&#22810;&#20803;&#39640;&#26031;&#36807;&#31243;&#20013;&#21487;&#20197;&#23454;&#29616;LRT&#26368;&#20248;&#24615;&#65292;&#20294;&#22312;&#20998;&#31867;&#39640;&#32500;&#38750;&#32447;&#24615;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#26102;&#26159;&#27425;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32479;&#35745;&#26368;&#20248;&#24615;&#22522;&#20934;&#27979;&#35797;&#23545;&#20110;&#20998;&#26512;&#21644;&#35774;&#35745;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#65288;TSC&#65289;&#31639;&#27861;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20351;&#29992;&#20284;&#28982;&#27604;&#26816;&#39564;&#65288;LRT&#65289;&#22522;&#20934;&#27979;&#35797;TSC&#31639;&#27861;&#22312;&#21306;&#20998;&#25193;&#25955;&#36807;&#31243;&#20013;&#30340;&#26368;&#20248;&#24615;&#12290;LRT&#26159;&#26681;&#25454;Neyman-Pearson&#24341;&#29702;&#24471;&#20986;&#30340;&#26368;&#20248;&#20998;&#31867;&#22120;&#12290;LRT&#22522;&#20934;&#27979;&#35797;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#22240;&#20026;LRT&#19981;&#38656;&#35201;&#35757;&#32451;&#65292;&#24182;&#19988;&#25193;&#25955;&#36807;&#31243;&#21487;&#20197;&#36827;&#34892;&#39640;&#25928;&#27169;&#25311;&#65292;&#21487;&#20197;&#28789;&#27963;&#21453;&#26144;&#20986;&#30495;&#23454;&#19990;&#30028;&#24212;&#29992;&#30340;&#29305;&#23450;&#29305;&#24449;&#12290;&#25105;&#20204;&#20351;&#29992;&#19977;&#31181;&#24120;&#29992;&#30340;TSC&#31639;&#27861;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#65306;&#38543;&#26426;&#26862;&#26519;&#12289;ResNet&#21644;ROCKET&#12290;&#36825;&#20123;&#31639;&#27861;&#21487;&#20197;&#23454;&#29616;&#21333;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#21644;&#22810;&#20803;&#39640;&#26031;&#36807;&#31243;&#30340;LRT&#26368;&#20248;&#24615;&#12290;&#20294;&#26159;&#65292;&#36825;&#20123;&#27169;&#22411;&#26080;&#20851;&#30340;&#31639;&#27861;&#22312;&#20998;&#31867;&#39640;&#32500;&#38750;&#32447;&#24615;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#26102;&#26159;&#27425;&#20248;&#30340;&#12290;&#27492;&#22806;&#65292;LRT&#22522;&#20934;&#27979;&#35797;&#25552;&#20379;&#20102;&#24037;&#20855;&#26469;&#20998;&#26512;&#20998;&#31867;&#20934;&#30830;&#24615;&#19982;&#26102;&#38388;&#20381;&#36182;&#24615;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Statistical optimality benchmarking is crucial for analyzing and designing time series classification (TSC) algorithms. This study proposes to benchmark the optimality of TSC algorithms in distinguishing diffusion processes by the likelihood ratio test (LRT). The LRT is an optimal classifier by the Neyman-Pearson lemma. The LRT benchmarks are computationally efficient because the LRT does not need training, and the diffusion processes can be efficiently simulated and are flexible to reflect the specific features of real-world applications. We demonstrate the benchmarking with three widely-used TSC algorithms: random forest, ResNet, and ROCKET. These algorithms can achieve the LRT optimality for univariate time series and multivariate Gaussian processes. However, these model-agnostic algorithms are suboptimal in classifying high-dimensional nonlinear multivariate time series. Additionally, the LRT benchmark provides tools to analyze the dependence of classification accuracy on the time 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25193;&#23637;&#20102;&#20449;&#24687;&#22330;&#29702;&#35770;(IFT)&#21040;&#29289;&#29702;&#20449;&#24687;&#22330;&#29702;&#35770;(PIFT)&#65292;&#23558;&#25551;&#36848;&#22330;&#30340;&#29289;&#29702;&#23450;&#24459;&#30340;&#20449;&#24687;&#32534;&#30721;&#20026;&#20989;&#25968;&#20808;&#39564;&#12290;&#20174;&#36825;&#20010;PIFT&#24471;&#20986;&#30340;&#21518;&#39564;&#19982;&#20219;&#20309;&#25968;&#20540;&#26041;&#26696;&#26080;&#20851;&#65292;&#24182;&#19988;&#21487;&#20197;&#25429;&#25417;&#22810;&#31181;&#27169;&#24335;&#12290;</title><link>http://arxiv.org/abs/2301.07609</link><description>&lt;p&gt;
&#29289;&#29702;&#23398;&#30693;&#35782;&#20316;&#20026;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#27169;&#22411;&#30340;&#20449;&#24687;&#22330;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Physics-informed Information Field Theory for Modeling Physical Systems with Uncertainty Quantification. (arXiv:2301.07609v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.07609
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25193;&#23637;&#20102;&#20449;&#24687;&#22330;&#29702;&#35770;(IFT)&#21040;&#29289;&#29702;&#20449;&#24687;&#22330;&#29702;&#35770;(PIFT)&#65292;&#23558;&#25551;&#36848;&#22330;&#30340;&#29289;&#29702;&#23450;&#24459;&#30340;&#20449;&#24687;&#32534;&#30721;&#20026;&#20989;&#25968;&#20808;&#39564;&#12290;&#20174;&#36825;&#20010;PIFT&#24471;&#20986;&#30340;&#21518;&#39564;&#19982;&#20219;&#20309;&#25968;&#20540;&#26041;&#26696;&#26080;&#20851;&#65292;&#24182;&#19988;&#21487;&#20197;&#25429;&#25417;&#22810;&#31181;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#32467;&#21512;&#29289;&#29702;&#23398;&#30693;&#35782;&#26159;&#24314;&#27169;&#31995;&#32479;&#30340;&#24378;&#26377;&#21147;&#25216;&#26415;&#12290;&#27492;&#31867;&#27169;&#22411;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#23558;&#27979;&#37327;&#32467;&#26524;&#19982;&#24050;&#30693;&#29289;&#29702;&#23450;&#24459;&#30456;&#32467;&#21512;&#65292;&#39640;&#25928;&#22320;&#27714;&#35299;&#22522;&#26412;&#22330;&#12290;&#30001;&#20110;&#35768;&#22810;&#31995;&#32479;&#21253;&#21547;&#26410;&#30693;&#20803;&#32032;&#65292;&#22914;&#32570;&#22833;&#21442;&#25968;&#12289;&#22024;&#26434;&#25968;&#25454;&#25110;&#19981;&#23436;&#25972;&#30340;&#29289;&#29702;&#23450;&#24459;&#65292;&#22240;&#27492;&#36825;&#36890;&#24120;&#34987;&#35270;&#20026;&#19968;&#31181;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#38382;&#39064;&#12290;&#22788;&#29702;&#25152;&#26377;&#21464;&#37327;&#30340;&#24120;&#35265;&#25216;&#26415;&#36890;&#24120;&#21462;&#20915;&#20110;&#29992;&#20110;&#36817;&#20284;&#21518;&#39564;&#30340;&#25968;&#20540;&#26041;&#26696;&#65292;&#24182;&#19988;&#24076;&#26395;&#26377;&#19968;&#31181;&#19981;&#20381;&#36182;&#20110;&#20219;&#20309;&#31163;&#25955;&#21270;&#30340;&#26041;&#27861;&#12290;&#20449;&#24687;&#22330;&#29702;&#35770;&#65288;IFT&#65289;&#25552;&#20379;&#20102;&#23545;&#19981;&#19968;&#23450;&#26159;&#39640;&#26031;&#22330;&#30340;&#22330;&#36827;&#34892;&#32479;&#35745;&#23398;&#30340;&#24037;&#20855;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#25551;&#36848;&#22330;&#30340;&#29289;&#29702;&#23450;&#24459;&#30340;&#20449;&#24687;&#32534;&#30721;&#20026;&#20989;&#25968;&#20808;&#39564;&#26469;&#25193;&#23637;IFT&#21040;&#29289;&#29702;&#20449;&#24687;&#22330;&#29702;&#35770;&#65288;PIFT&#65289;&#12290;&#20174;&#36825;&#20010;PIFT&#24471;&#20986;&#30340;&#21518;&#39564;&#19982;&#20219;&#20309;&#25968;&#20540;&#26041;&#26696;&#26080;&#20851;&#65292;&#24182;&#19988;&#21487;&#20197;&#25429;&#25417;&#22810;&#31181;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data-driven approaches coupled with physical knowledge are powerful techniques to model systems. The goal of such models is to efficiently solve for the underlying field by combining measurements with known physical laws. As many systems contain unknown elements, such as missing parameters, noisy data, or incomplete physical laws, this is widely approached as an uncertainty quantification problem. The common techniques to handle all the variables typically depend on the numerical scheme used to approximate the posterior, and it is desirable to have a method which is independent of any such discretization. Information field theory (IFT) provides the tools necessary to perform statistics over fields that are not necessarily Gaussian. We extend IFT to physics-informed IFT (PIFT) by encoding the functional priors with information about the physical laws which describe the field. The posteriors derived from this PIFT remain independent of any numerical scheme and can capture multiple modes,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#33258;&#25105;&#38598;&#25104;&#20445;&#25252;&#25216;&#26415;&#65292;&#36890;&#36807;&#23545;&#35757;&#32451;&#25968;&#25454;&#28155;&#21152;&#19981;&#21487;&#24863;&#30693;&#30340;&#25200;&#21160;&#65292;&#36890;&#36807;&#27169;&#22411;&#26816;&#26597;&#28857;&#30340;&#26799;&#24230;&#21457;&#29616;&#36825;&#20123;&#26679;&#26412;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#38450;&#27490;&#31454;&#20105;&#23545;&#25163;&#22312;&#25968;&#25454;&#19978;&#35757;&#32451;&#39640;&#24615;&#33021;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2211.12005</link><description>&lt;p&gt;
&#33258;&#25105;&#38598;&#25104;&#20445;&#25252;&#65306;&#35757;&#32451;&#26816;&#26597;&#28857;&#26159;&#33391;&#22909;&#30340;&#25968;&#25454;&#20445;&#25252;&#32773;
&lt;/p&gt;
&lt;p&gt;
Self-Ensemble Protection: Training Checkpoints Are Good Data Protectors. (arXiv:2211.12005v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.12005
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#33258;&#25105;&#38598;&#25104;&#20445;&#25252;&#25216;&#26415;&#65292;&#36890;&#36807;&#23545;&#35757;&#32451;&#25968;&#25454;&#28155;&#21152;&#19981;&#21487;&#24863;&#30693;&#30340;&#25200;&#21160;&#65292;&#36890;&#36807;&#27169;&#22411;&#26816;&#26597;&#28857;&#30340;&#26799;&#24230;&#21457;&#29616;&#36825;&#20123;&#26679;&#26412;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#38450;&#27490;&#31454;&#20105;&#23545;&#25163;&#22312;&#25968;&#25454;&#19978;&#35757;&#32451;&#39640;&#24615;&#33021;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#25968;&#25454;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#65292;&#20844;&#21496;&#22312;&#21457;&#24067;&#25968;&#25454;&#26102;&#36890;&#24120;&#20250;&#38750;&#24120;&#35880;&#24910;&#65292;&#22240;&#20026;&#31454;&#20105;&#23545;&#25163;&#21487;&#20197;&#20351;&#29992;&#23427;&#26469;&#35757;&#32451;&#39640;&#24615;&#33021;&#27169;&#22411;&#65292;&#20174;&#32780;&#23545;&#20844;&#21496;&#30340;&#21830;&#19994;&#31454;&#20105;&#21147;&#36896;&#25104;&#24040;&#22823;&#23041;&#32961;&#12290;&#20026;&#20102;&#38450;&#27490;&#22312;&#25968;&#25454;&#19978;&#35757;&#32451;&#33391;&#22909;&#30340;&#27169;&#22411;&#65292;&#25105;&#20204;&#21487;&#20197;&#23545;&#20854;&#28155;&#21152;&#19981;&#21487;&#24863;&#30693;&#30340;&#25200;&#21160;&#12290;&#30001;&#20110;&#36825;&#26679;&#30340;&#25200;&#21160;&#26088;&#22312;&#20260;&#23475;&#25972;&#20010;&#35757;&#32451;&#36807;&#31243;&#65292;&#22240;&#27492;&#23427;&#20204;&#24212;&#35813;&#21453;&#26144;DNN&#35757;&#32451;&#30340;&#33030;&#24369;&#24615;&#65292;&#32780;&#19981;&#26159;&#21333;&#20010;&#27169;&#22411;&#30340;&#33030;&#24369;&#24615;&#12290;&#22522;&#20110;&#36825;&#20010;&#26032;&#24819;&#27861;&#65292;&#25105;&#20204;&#23547;&#25214;&#22312;&#35757;&#32451;&#20013;&#22987;&#32456;&#26080;&#27861;&#35782;&#21035;&#65288;&#20174;&#26410;&#34987;&#27491;&#30830;&#20998;&#31867;&#65289;&#30340;&#25200;&#21160;&#26679;&#26412;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#27169;&#22411;&#26816;&#26597;&#28857;&#30340;&#26799;&#24230;&#21457;&#29616;&#36825;&#20123;&#26679;&#26412;&#65292;&#24418;&#25104;&#25152;&#25552;&#20986;&#30340;&#33258;&#25105;&#38598;&#25104;&#20445;&#25252;&#65288;SEP&#65289;&#12290;&#35813;&#26041;&#27861;&#38750;&#24120;&#26377;&#25928;&#65292;&#22240;&#20026;&#65288;1&#65289;&#22312;&#27491;&#24120;&#35757;&#32451;&#36807;&#31243;&#20013;&#24573;&#30053;&#30340;&#31034;&#20363;&#19978;&#36827;&#34892;&#23398;&#20064;&#24448;&#24448;&#20250;&#20135;&#29983;&#19981;&#24573;&#30053;&#27491;&#24120;&#31034;&#20363;&#30340;DNN&#65307;&#65288;2&#65289;&#26816;&#26597;&#28857;&#20043;&#38388;&#36328;&#27169;&#22411;&#30340;&#26799;&#24230;&#19982;&#27491;&#20132;&#25509;&#36817;&#65292;&#34920;&#31034;&#23427;&#20204;&#19982;&#20855;&#26377;&#19981;&#21516;&#20307;&#31995;&#32467;&#26500;&#30340;DNN&#19968;&#26679;&#22810;&#26679;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
As data becomes increasingly vital, a company would be very cautious about releasing data, because the competitors could use it to train high-performance models, thereby posing a tremendous threat to the company's commercial competence. To prevent training good models on the data, we could add imperceptible perturbations to it. Since such perturbations aim at hurting the entire training process, they should reflect the vulnerability of DNN training, rather than that of a single model. Based on this new idea, we seek perturbed examples that are always unrecognized (never correctly classified) in training. In this paper, we uncover them by model checkpoints' gradients, forming the proposed self-ensemble protection (SEP), which is very effective because (1) learning on examples ignored during normal training tends to yield DNNs ignoring normal examples; (2) checkpoints' cross-model gradients are close to orthogonal, meaning that they are as diverse as DNNs with different architectures. Th
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#35757;&#32451;&#35823;&#24046;&#30340;&#26799;&#24230;&#19979;&#38477;&#21160;&#24577;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#20998;&#26512;&#20844;&#24335;&#65292;&#21487;&#20197;&#25429;&#25417;&#21040;&#23485;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#25439;&#22833;&#20989;&#25968;&#30340;&#24179;&#22343;&#34892;&#20026;&#12290;&#25105;&#20204;&#39044;&#27979;&#24182;&#34920;&#24449;&#20102;&#38543;&#26426;&#37327;&#23376;&#30005;&#36335;&#27531;&#20313;&#35757;&#32451;&#35823;&#24046;&#20316;&#20026;&#31995;&#32479;&#21442;&#25968;&#30340;&#25351;&#25968;&#34928;&#20943;&#12290;</title><link>http://arxiv.org/abs/2203.16711</link><description>&lt;p&gt;
&#23485;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#21160;&#21147;&#23398;&#30340;&#20998;&#26512;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Analytic theory for the dynamics of wide quantum neural networks. (arXiv:2203.16711v3 [quant-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.16711
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#35757;&#32451;&#35823;&#24046;&#30340;&#26799;&#24230;&#19979;&#38477;&#21160;&#24577;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#20998;&#26512;&#20844;&#24335;&#65292;&#21487;&#20197;&#25429;&#25417;&#21040;&#23485;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#25439;&#22833;&#20989;&#25968;&#30340;&#24179;&#22343;&#34892;&#20026;&#12290;&#25105;&#20204;&#39044;&#27979;&#24182;&#34920;&#24449;&#20102;&#38543;&#26426;&#37327;&#23376;&#30005;&#36335;&#27531;&#20313;&#35757;&#32451;&#35823;&#24046;&#20316;&#20026;&#31995;&#32479;&#21442;&#25968;&#30340;&#25351;&#25968;&#34928;&#20943;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21442;&#25968;&#37327;&#23376;&#30005;&#36335;&#21487;&#29992;&#20316;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#26377;&#28508;&#21147;&#22312;&#35299;&#20915;&#23398;&#20064;&#38382;&#39064;&#26102;&#20248;&#20110;&#23427;&#20204;&#30340;&#32463;&#20856;&#23545;&#24212;&#29289;&#12290;&#36804;&#20170;&#20026;&#27490;&#65292;&#22823;&#37096;&#20998;&#20851;&#20110;&#23427;&#20204;&#22312;&#23454;&#38469;&#38382;&#39064;&#19978;&#34920;&#29616;&#30340;&#32467;&#26524;&#26159;&#21551;&#21457;&#24335;&#30340;&#12290;&#29305;&#21035;&#26159;&#65292;&#23545;&#20110;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#25910;&#25947;&#29575;&#36824;&#27809;&#26377;&#23436;&#20840;&#29702;&#35299;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20998;&#26512;&#26799;&#24230;&#19979;&#38477;&#30340;&#21160;&#24577;&#65292;&#30740;&#31350;&#19968;&#31867;&#21487;&#21464;&#37327;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#35757;&#32451;&#35823;&#24046;&#12290;&#25105;&#20204;&#23558;&#23485;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#23450;&#20041;&#20026;&#24102;&#26377;&#22823;&#37327;&#37327;&#23376;&#20301;&#21644;&#21487;&#21464;&#21442;&#25968;&#30340;&#21442;&#25968;&#21270;&#37327;&#23376;&#30005;&#36335;&#26497;&#38480;&#12290;&#25105;&#20204;&#28982;&#21518;&#21457;&#29616;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#20998;&#26512;&#20844;&#24335;&#65292;&#21487;&#20197;&#25429;&#25417;&#21040;&#23427;&#20204;&#25439;&#22833;&#20989;&#25968;&#30340;&#24179;&#22343;&#34892;&#20026;&#65292;&#24182;&#35752;&#35770;&#20102;&#25105;&#20204;&#30740;&#31350;&#30340;&#32467;&#26524;&#30340;&#21518;&#26524;&#12290;&#20363;&#22914;&#65292;&#23545;&#20110;&#38543;&#26426;&#37327;&#23376;&#30005;&#36335;&#65292;&#25105;&#20204;&#39044;&#27979;&#24182;&#34920;&#24449;&#20102;&#27531;&#20313;&#35757;&#32451;&#35823;&#24046;&#20316;&#20026;&#31995;&#32479;&#21442;&#25968;&#30340;&#25351;&#25968;&#34928;&#20943;&#12290;&#25105;&#20204;&#26368;&#32456;&#36890;&#36807;&#21508;&#31181;&#37327;&#23376;&#30005;&#36335;&#30340;&#25968;&#20540;&#27169;&#25311;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#20998;&#26512;&#29702;&#35770;&#65292;&#24182;&#23637;&#31034;&#20102;&#19982;&#25105;&#20204;&#30340;&#39044;&#27979;&#19968;&#33268;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Parameterized quantum circuits can be used as quantum neural networks and have the potential to outperform their classical counterparts when trained for addressing learning problems. To date, much of the results on their performance on practical problems are heuristic in nature. In particular, the convergence rate for the training of quantum neural networks is not fully understood. Here, we analyze the dynamics of gradient descent for the training error of a class of variational quantum machine learning models. We define wide quantum neural networks as parameterized quantum circuits in the limit of a large number of qubits and variational parameters. We then find a simple analytic formula that captures the average behavior of their loss function and discuss the consequences of our findings. For example, for random quantum circuits, we predict and characterize an exponential decay of the residual training error as a function of the parameters of the system. We finally validate our analy
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#19987;&#23478;&#22686;&#24378;&#8221;&#30340;&#28151;&#21512;&#25968;&#25454;&#22686;&#24378;&#31574;&#30053;&#65292;&#21487;&#20197;&#23558;&#20854;&#32435;&#20837;&#28151;&#21512;&#31995;&#32479;&#20197;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#20811;&#26381;&#28151;&#21512;&#27169;&#22411;&#24615;&#33021;&#20165;&#38480;&#20110;&#35757;&#32451;&#20998;&#24067;&#30340;&#38480;&#21046;&#12290;&#20316;&#32773;&#22312;&#19977;&#20010;&#25511;&#21046;&#23454;&#39564;&#20013;&#20174;&#24120;&#24494;&#20998;&#26041;&#31243;&#21644;&#20559;&#24494;&#20998;&#26041;&#31243;&#24314;&#27169;&#21160;&#24577;&#31995;&#32479;&#65292;&#24182;&#22312;&#30495;&#23454;&#21452;&#25670;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#35813;&#26041;&#27861;&#30340;&#28508;&#22312;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2202.03881</link><description>&lt;p&gt;
&#24378;&#38887;&#30340;&#28151;&#21512;&#23398;&#20064;&#65306;&#19987;&#23478;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
Robust Hybrid Learning With Expert Augmentation. (arXiv:2202.03881v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.03881
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#19987;&#23478;&#22686;&#24378;&#8221;&#30340;&#28151;&#21512;&#25968;&#25454;&#22686;&#24378;&#31574;&#30053;&#65292;&#21487;&#20197;&#23558;&#20854;&#32435;&#20837;&#28151;&#21512;&#31995;&#32479;&#20197;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#20811;&#26381;&#28151;&#21512;&#27169;&#22411;&#24615;&#33021;&#20165;&#38480;&#20110;&#35757;&#32451;&#20998;&#24067;&#30340;&#38480;&#21046;&#12290;&#20316;&#32773;&#22312;&#19977;&#20010;&#25511;&#21046;&#23454;&#39564;&#20013;&#20174;&#24120;&#24494;&#20998;&#26041;&#31243;&#21644;&#20559;&#24494;&#20998;&#26041;&#31243;&#24314;&#27169;&#21160;&#24577;&#31995;&#32479;&#65292;&#24182;&#22312;&#30495;&#23454;&#21452;&#25670;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#35813;&#26041;&#27861;&#30340;&#28508;&#22312;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28151;&#21512;&#24314;&#27169;&#36890;&#36807;&#23558;&#19987;&#23478;&#27169;&#22411;&#19982;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#32452;&#20214;&#30456;&#32467;&#21512;&#65292;&#20943;&#23569;&#20102;&#19987;&#23478;&#27169;&#22411;&#30340;&#38169;&#35823;&#24314;&#27169;&#12290;&#19982;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#31867;&#20284;&#65292;&#28151;&#21512;&#27169;&#22411;&#30340;&#24615;&#33021;&#20445;&#35777;&#20165;&#38480;&#20110;&#35757;&#32451;&#20998;&#24067;&#12290;&#21033;&#29992;&#19987;&#23478;&#27169;&#22411;&#36890;&#24120;&#22312;&#35757;&#32451;&#22495;&#22806;&#20063;&#36866;&#29992;&#30340;&#35265;&#35299;&#65292;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#21517;&#20026;&#19987;&#23478;&#22686;&#24378;&#30340;&#28151;&#21512;&#25968;&#25454;&#22686;&#24378;&#31574;&#30053;&#20811;&#26381;&#20102;&#36825;&#20010;&#38480;&#21046;&#12290;&#22522;&#20110;&#28151;&#21512;&#24314;&#27169;&#30340;&#27010;&#29575;&#24418;&#24335;&#21270;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21487;&#20197;&#23558;&#19987;&#23478;&#22686;&#24378;&#32435;&#20837;&#29616;&#26377;&#30340;&#28151;&#21512;&#31995;&#32479;&#20197;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#22312;&#19977;&#20010;&#25511;&#21046;&#23454;&#39564;&#20013;&#20174;&#24120;&#24494;&#20998;&#26041;&#31243;&#21644;&#20559;&#24494;&#20998;&#26041;&#31243;&#24314;&#27169;&#21160;&#24577;&#31995;&#32479;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#19987;&#23478;&#22686;&#24378;&#22312;&#30495;&#23454;&#21452;&#25670;&#25968;&#25454;&#38598;&#19978;&#30340;&#28508;&#22312;&#29616;&#23454;&#19990;&#30028;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hybrid modelling reduces the misspecification of expert models by combining them with machine learning (ML) components learned from data. Similarly to many ML algorithms, hybrid model performance guarantees are limited to the training distribution. Leveraging the insight that the expert model is usually valid even outside the training domain, we overcome this limitation by introducing a hybrid data augmentation strategy termed \textit{expert augmentation}. Based on a probabilistic formalization of hybrid modelling, we demonstrate that expert augmentation, which can be incorporated into existing hybrid systems, improves generalization. We empirically validate the expert augmentation on three controlled experiments modelling dynamical systems with ordinary and partial differential equations. Finally, we assess the potential real-world applicability of expert augmentation on a dataset of a real double pendulum.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#25130;&#26029;&#27850;&#26494;&#22238;&#24402;&#26041;&#27861;&#26469;&#22788;&#29702;&#34987;&#20551;&#38646;&#20540;&#27745;&#26579;&#30340;&#22810;&#32500;&#35745;&#25968;&#25968;&#25454;&#65292;&#26080;&#38656;&#21306;&#20998;&#30495;&#23454;&#21644;&#20551;&#30340;&#38646;&#35745;&#25968;&#65292;&#21363;&#21487;&#20934;&#30830;&#20272;&#35745;&#38750;&#36127;&#21442;&#25968;&#24352;&#37327;&#31354;&#38388;&#65292;&#22788;&#29702;&#25928;&#29575;&#39640;&#12290;</title><link>http://arxiv.org/abs/2201.10014</link><description>&lt;p&gt;
&#38024;&#23545;&#31232;&#30095;&#22810;&#32500;&#35745;&#25968;&#25968;&#25454;&#20013;&#30340;&#20551;&#38646;&#20540;&#30340;&#38646;&#25130;&#26029;&#27850;&#26494;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Zero-Truncated Poisson Regression for Sparse Multiway Count Data Corrupted by False Zeros. (arXiv:2201.10014v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.10014
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#25130;&#26029;&#27850;&#26494;&#22238;&#24402;&#26041;&#27861;&#26469;&#22788;&#29702;&#34987;&#20551;&#38646;&#20540;&#27745;&#26579;&#30340;&#22810;&#32500;&#35745;&#25968;&#25968;&#25454;&#65292;&#26080;&#38656;&#21306;&#20998;&#30495;&#23454;&#21644;&#20551;&#30340;&#38646;&#35745;&#25968;&#65292;&#21363;&#21487;&#20934;&#30830;&#20272;&#35745;&#38750;&#36127;&#21442;&#25968;&#24352;&#37327;&#31354;&#38388;&#65292;&#22788;&#29702;&#25928;&#29575;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#34987;&#20551;&#38646;&#20540;&#27745;&#26579;&#30340;&#22810;&#32500;&#35745;&#25968;&#25968;&#25454;&#65292;&#36825;&#20123;&#20551;&#38646;&#20540;&#21644;&#30495;&#23454;&#30340;&#38646;&#35745;&#25968;&#26080;&#27861;&#21306;&#20998;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21253;&#25324;&#23558;&#27850;&#26494;&#20998;&#24067;&#36827;&#34892;&#38646;&#25130;&#26029;&#65292;&#20197;&#28040;&#38500;&#25152;&#26377;&#38646;&#20540;&#12290;&#36825;&#31181;&#31616;&#21333;&#30340;&#25130;&#26029;&#26041;&#27861;&#36991;&#20813;&#20102;&#21306;&#20998;&#30495;&#23454;&#38646;&#35745;&#25968;&#21644;&#20551;&#38646;&#35745;&#25968;&#30340;&#38656;&#27714;&#65292;&#24182;&#20943;&#23569;&#20102;&#38656;&#35201;&#22788;&#29702;&#30340;&#25968;&#25454;&#37327;&#12290;&#25512;&#26029;&#26159;&#36890;&#36807;&#22312;&#27850;&#26494;&#21442;&#25968;&#31354;&#38388;&#19978;&#26045;&#21152;&#20302;&#31209;&#24352;&#37327;&#32467;&#26500;&#30340;&#24352;&#37327;&#23436;&#25104;&#30340;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#34920;&#26126;&#65292;&#21487;&#20197;&#26681;&#25454;&#38750;&#36127;&#26631;&#20934;&#20998;&#35299;&#20013;&#30340;&#20174;&#32422;IR^2log_2^2(I)&#20010;&#36817;&#20284;&#38750;&#38646;&#35745;&#25968;&#30340;N&#37325;&#31209;&#20026;R&#30340;&#21442;&#25968;&#24352;&#37327;M&#21487;&#20197;&#36890;&#36807;&#38646;&#25130;&#26029;&#27850;&#26494;&#22238;&#24402;&#36827;&#34892;&#20934;&#30830;&#20272;&#35745;&#12290;&#24403;&#21442;&#25968;&#20174;&#19979;&#38754;&#32479;&#19968;&#32422;&#26463;&#26102;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#20063;&#37327;&#21270;&#20102;&#38646;&#25130;&#26029;&#27850;&#26494;&#20998;&#24067;&#30340;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel statistical inference methodology for multiway count data that is corrupted by false zeros that are indistinguishable from true zero counts. Our approach consists of zero-truncating the Poisson distribution to neglect all zero values. This simple truncated approach dispenses with the need to distinguish between true and false zero counts and reduces the amount of data to be processed. Inference is accomplished via tensor completion that imposes low-rank tensor structure on the Poisson parameter space.  Our main result shows that an $N$-way rank-$R$ parametric tensor $\boldsymbol{\mathscr{M}}\in(0,\infty)^{I\times \cdots\times I}$ generating Poisson observations can be accurately estimated by zero-truncated Poisson regression from approximately $IR^2\log_2^2(I)$ non-zero counts under the nonnegative canonical polyadic decomposition. Our result also quantifies the error made by zero-truncating the Poisson distribution when the parameter is uniformly bounded from below.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28151;&#21512;&#27169;&#22411;&#30340;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#35299;&#20915;&#28151;&#21512;&#38382;&#39064;&#21644;&#24674;&#22797;&#27010;&#29575;&#20998;&#24067;&#65292;&#21487;&#20197;&#30830;&#23450;&#21407;&#26412;&#26080;&#27861;&#30830;&#23450;&#30340;&#22240;&#26524;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2112.11602</link><description>&lt;p&gt;
&#36890;&#36807;&#28151;&#21512;&#27169;&#22411;&#36827;&#34892;&#26377;&#38480;&#20840;&#23616;&#28151;&#28102;&#30340;&#22240;&#26524;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Causal Inference Despite Limited Global Confounding via Mixture Models. (arXiv:2112.11602v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.11602
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28151;&#21512;&#27169;&#22411;&#30340;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#35299;&#20915;&#28151;&#21512;&#38382;&#39064;&#21644;&#24674;&#22797;&#27010;&#29575;&#20998;&#24067;&#65292;&#21487;&#20197;&#30830;&#23450;&#21407;&#26412;&#26080;&#27861;&#30830;&#23450;&#30340;&#22240;&#26524;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#32593;&#32476;&#26159;&#19968;&#32452;$n$&#20010;&#38543;&#26426;&#21464;&#37327;&#65288;&#22270;&#30340;&#39030;&#28857;&#65289;&#19978;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;; &#36125;&#21494;&#26031;&#32593;&#32476;&#20998;&#24067;&#65288;BND&#65289;&#26159;&#22312;&#22270;&#19978;&#39532;&#23572;&#21487;&#22827;&#30340;&#38543;&#26426;&#21464;&#37327;&#30340;&#27010;&#29575;&#20998;&#24067;&#12290;&#36825;&#31181;&#27169;&#22411;&#30340;&#26377;&#38480;$k$-&#28151;&#21512;&#30001;&#19968;&#20010;&#26356;&#22823;&#30340;&#22270;&#24418;&#24335;&#21270;&#34920;&#31034;&#65292;&#35813;&#22270;&#20855;&#26377;&#19968;&#20010;&#39069;&#22806;&#30340;&#8220;&#38544;&#34255;&#8221;&#65288;&#25110;&#8220;&#28508;&#22312;&#8221;&#65289;&#38543;&#26426;&#21464;&#37327;$U$&#65292;&#20854;&#33539;&#22260;&#20026;$\{1,\ldots,k\}$&#65292;&#24182;&#19988;$U$&#21040;&#27599;&#20010;&#20854;&#20182;&#39030;&#28857;&#37117;&#26377;&#19968;&#20010;&#26377;&#21521;&#36793;&#12290;&#36825;&#31181;&#31867;&#22411;&#30340;&#27169;&#22411;&#22312;&#22240;&#26524;&#25512;&#26029;&#20013;&#26159;&#22522;&#26412;&#30340;&#65292;&#20854;&#20013;$U$&#27169;&#25311;&#20102;&#22810;&#20010;&#32676;&#20307;&#30340;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#25928;&#24212;&#65292;&#20351;&#24471;&#21487;&#35266;&#23519;&#30340;DAG&#20013;&#30340;&#22240;&#26524;&#20851;&#31995;&#21464;&#24471;&#27169;&#31946;&#19981;&#28165;&#12290;&#36890;&#36807;&#35299;&#20915;&#28151;&#21512;&#38382;&#39064;&#24182;&#24674;&#22797;$U$&#19978;&#30340;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#65292;&#20256;&#32479;&#19978;&#26080;&#27861;&#30830;&#23450;&#30340;&#22240;&#26524;&#20851;&#31995;&#21464;&#24471;&#21487;&#30830;&#23450;&#12290;&#36890;&#36807;&#23558;&#20854;&#32422;&#21270;&#20026;&#26356;&#20026;&#30740;&#31350;&#30340;&#8220;&#31354;&#8221;&#22270;&#20013;&#30340;&#8220;&#20056;&#31215;&#8221;&#24773;&#20917;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#23398;&#20064;&#38750;&#31354;DAG&#30340;&#28151;&#21512;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Bayesian Network is a directed acyclic graph (DAG) on a set of $n$ random variables (the vertices); a Bayesian Network Distribution (BND) is a probability distribution on the random variables that is Markovian on the graph. A finite $k$-mixture of such models is graphically represented by a larger graph which has an additional "hidden" (or "latent") random variable $U$, ranging in $\{1,\ldots,k\}$, and a directed edge from $U$ to every other vertex. Models of this type are fundamental to causal inference, where $U$ models an unobserved confounding effect of multiple populations, obscuring the causal relationships in the observable DAG. By solving the mixture problem and recovering the joint probability distribution on $U$, traditionally unidentifiable causal relationships become identifiable. Using a reduction to the more well-studied "product" case on empty graphs, we give the first algorithm to learn mixtures of non-empty DAGs.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#24773;&#20917;&#19979;&#36817;&#20284;MCMC&#26041;&#27861;&#30340;&#28176;&#36817;&#20559;&#24046;&#23545;&#19981;&#31934;&#30830;MCMC&#26041;&#27861;&#30340;&#19981;&#21464;&#27010;&#29575;&#27979;&#24230;&#21644;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#21644;&#23545;&#20110;&#26377;&#38480;&#30456;&#20114;&#20316;&#29992;&#30340;&#27169;&#22411;&#65292;&#28176;&#36817;&#20559;&#24046;&#26377;&#31867;&#20284;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2108.00682</link><description>&lt;p&gt;
&#39640;&#32500;&#24773;&#20917;&#19979;&#36817;&#20284;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#30340;&#28176;&#36817;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Asymptotic bias of inexact Markov Chain Monte Carlo methods in high dimension. (arXiv:2108.00682v2 [math.PR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.00682
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#24773;&#20917;&#19979;&#36817;&#20284;MCMC&#26041;&#27861;&#30340;&#28176;&#36817;&#20559;&#24046;&#23545;&#19981;&#31934;&#30830;MCMC&#26041;&#27861;&#30340;&#19981;&#21464;&#27010;&#29575;&#27979;&#24230;&#21644;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#21644;&#23545;&#20110;&#26377;&#38480;&#30456;&#20114;&#20316;&#29992;&#30340;&#27169;&#22411;&#65292;&#28176;&#36817;&#20559;&#24046;&#26377;&#31867;&#20284;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#20284;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;(MCMC)&#26041;&#27861;&#20381;&#36182;&#20110;&#19981;&#23436;&#20840;&#20445;&#30041;&#30446;&#26631;&#20998;&#24067;&#30340;&#39532;&#23572;&#31185;&#22827;&#38142;&#65292;&#20363;&#22914;&#26410;&#35843;&#25972;&#30340;Langevin&#31639;&#27861;(ULA)&#21644;&#26410;&#35843;&#25972;&#30340;Hamilton&#33945;&#29305;&#21345;&#32599;(uHMC)&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32500;&#24230;&#21644;&#31163;&#25955;&#27493;&#38271;&#20004;&#20010;&#26041;&#38754;&#28145;&#20837;&#20102;&#35299;&#20102;&#36825;&#31181;&#28176;&#36817;&#20559;&#24046;&#23545;&#19981;&#31934;&#30830;MCMC&#26041;&#27861;&#30340;&#19981;&#21464;&#27010;&#29575;&#27979;&#24230;&#21644;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#20551;&#35774;&#31934;&#30830;&#25110;&#36817;&#20284;&#21160;&#21147;&#23398;&#30340;&#25910;&#25947;&#24615;&#21040;&#24179;&#34913;&#30340;Wasserstein&#36793;&#30028;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;ULA&#21644;uHMC&#65292;&#28176;&#36817;&#20559;&#24046;&#21462;&#20915;&#20110;&#19982;&#26041;&#26696;&#30340;&#30446;&#26631;&#20998;&#24067;&#25110;&#31283;&#24577;&#27010;&#29575;&#27979;&#24230;&#26377;&#20851;&#30340;&#20851;&#38190;&#37327;&#12290;&#20316;&#20026;&#19968;&#20010;&#25512;&#35770;&#65292;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65292;&#23545;&#20110;&#20855;&#26377;&#26377;&#38480;&#30456;&#20114;&#20316;&#29992;&#30340;&#27169;&#22411;&#65292;&#20363;&#22914;&#22343;&#22330;&#27169;&#22411;&#12289;&#26377;&#38480;&#33539;&#22260;&#22270;&#27169;&#22411;&#21644;&#20854;&#25200;&#21160;&#27169;&#22411;&#65292;&#28176;&#36817;&#20559;&#24046;&#23545;&#36825;&#20123;&#27169;&#22411;&#26377;&#31867;&#20284;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inexact Markov Chain Monte Carlo methods rely on Markov chains that do not exactly preserve the target distribution. Examples include the unadjusted Langevin algorithm (ULA) and unadjusted Hamiltonian Monte Carlo (uHMC). This paper establishes bounds on Wasserstein distances between the invariant probability measures of inexact MCMC methods and their target distributions with a focus on understanding the precise dependence of this asymptotic bias on both dimension and discretization step size. Assuming Wasserstein bounds on the convergence to equilibrium of either the exact or the approximate dynamics, we show that for both ULA and uHMC, the asymptotic bias depends on key quantities related to the target distribution or the stationary probability measure of the scheme. As a corollary, we conclude that for models with a limited amount of interactions such as mean-field models, finite range graphical models, and perturbations thereof, the asymptotic bias has a similar dependence on the s
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#31227;&#21160;&#35774;&#22791;&#21644;&#20998;&#24067;&#24335;&#32593;&#32476;&#20013;&#23454;&#29616;&#20998;&#24067;&#24335;&#35757;&#32451;&#21644;&#25512;&#26029;&#30340;&#31639;&#27861;&#21644;&#26550;&#26500;&#65292;&#24182;&#23454;&#29616;&#20102;&#25512;&#26029;&#30340;&#20256;&#25773;&#21644;&#34701;&#21512;&#12290;&#19982;&#29616;&#26377;&#25216;&#26415;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2107.03433</link><description>&lt;p&gt;
&#32593;&#32476;&#20869;&#23398;&#20064;&#65306;&#20998;&#24067;&#24335;&#35757;&#32451;&#21644;&#32593;&#32476;&#20013;&#30340;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
In-Network Learning: Distributed Training and Inference in Networks. (arXiv:2107.03433v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.03433
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#31227;&#21160;&#35774;&#22791;&#21644;&#20998;&#24067;&#24335;&#32593;&#32476;&#20013;&#23454;&#29616;&#20998;&#24067;&#24335;&#35757;&#32451;&#21644;&#25512;&#26029;&#30340;&#31639;&#27861;&#21644;&#26550;&#26500;&#65292;&#24182;&#23454;&#29616;&#20102;&#25512;&#26029;&#30340;&#20256;&#25773;&#21644;&#34701;&#21512;&#12290;&#19982;&#29616;&#26377;&#25216;&#26415;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#30340;&#25104;&#21151;&#20351;&#24471;&#31227;&#21160;&#35774;&#22791;&#21644;&#26080;&#32447;&#32593;&#32476;&#33021;&#22815;&#23454;&#29616;&#37325;&#35201;&#30340;&#26032;&#26381;&#21153;&#65292;&#28982;&#32780;&#65292;&#30001;&#20110;&#25968;&#25454;&#21644;&#22788;&#29702;&#33021;&#21147;&#22312;&#26080;&#32447;&#32593;&#32476;&#20013;&#39640;&#24230;&#20998;&#24067;&#65292;&#36825;&#20063;&#24102;&#26469;&#20102;&#37325;&#22823;&#25361;&#25112;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#31639;&#27861;&#21644;&#26550;&#26500;&#65292;&#21033;&#29992;&#22810;&#20010;&#25968;&#25454;&#27969;&#21644;&#22788;&#29702;&#21333;&#20803;&#65292;&#19981;&#20165;&#22312;&#35757;&#32451;&#38454;&#27573;&#32780;&#19988;&#22312;&#25512;&#26029;&#38454;&#27573;&#36827;&#34892;&#25512;&#26029;&#20256;&#25773;&#21644;&#34701;&#21512;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#25552;&#20986;&#26041;&#27861;&#30340;&#35774;&#35745;&#20934;&#21017;&#21450;&#20854;&#23545;&#24102;&#23485;&#30340;&#35201;&#27714;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#22312;&#20856;&#22411;&#30340;&#26080;&#32447;&#30005;&#25509;&#20837;&#20013;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#23454;&#29616;&#26041;&#38754;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#39564;&#35777;&#26126;&#20102;&#26412;&#26041;&#27861;&#30456;&#27604;&#29616;&#26377;&#25216;&#26415;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is widely perceived that leveraging the success of modern machine learning techniques to mobile devices and wireless networks has the potential of enabling important new services. This, however, poses significant challenges, essentially due to that both data and processing power are highly distributed in a wireless network. In this paper, we develop a learning algorithm and an architecture that make use of multiple data streams and processing units, not only during the training phase but also during the inference phase. In particular, the analysis reveals how inference propagates and fuses across a network. We study the design criterion of our proposed method and its bandwidth requirements. Also, we discuss implementation aspects using neural networks in typical wireless radio access; and provide experiments that illustrate benefits over state-of-the-art techniques.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#21518;&#39564;&#20849;&#35782;&#20998;&#24067;&#30340;&#25554;&#34917;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#25511;&#21046;&#26041;&#24046;&#21644;&#21069;&#30651;&#24615;&#20559;&#24046;&#26435;&#34913;&#30340;&#21516;&#26102;&#36827;&#34892;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#65292;&#36866;&#29992;&#20110;&#37329;&#34701;&#31561;&#39046;&#22495;&#12290;</title><link>http://arxiv.org/abs/2102.12736</link><description>&lt;p&gt;
&#29992;Wasserstein&#25554;&#20540;&#36827;&#34892;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#20197;&#36798;&#21040;&#26368;&#20339;&#36828;&#26399;&#20559;&#24046;&#21644;&#26041;&#24046;&#24179;&#34913;
&lt;/p&gt;
&lt;p&gt;
Time-Series Imputation with Wasserstein Interpolation for Optimal Look-Ahead-Bias and Variance Tradeoff. (arXiv:2102.12736v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.12736
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#21518;&#39564;&#20849;&#35782;&#20998;&#24067;&#30340;&#25554;&#34917;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#25511;&#21046;&#26041;&#24046;&#21644;&#21069;&#30651;&#24615;&#20559;&#24046;&#26435;&#34913;&#30340;&#21516;&#26102;&#36827;&#34892;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#65292;&#36866;&#29992;&#20110;&#37329;&#34701;&#31561;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32570;&#22833;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#26159;&#19968;&#20010;&#26222;&#36941;&#23384;&#22312;&#30340;&#23454;&#38469;&#38382;&#39064;&#12290;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#30340;&#25554;&#34917;&#26041;&#27861;&#36890;&#24120;&#34987;&#24212;&#29992;&#20110;&#23436;&#25972;&#30340;&#38754;&#26495;&#25968;&#25454;&#65292;&#30446;&#30340;&#26159;&#20026;&#20102;&#35757;&#32451;&#19968;&#20010;&#29992;&#20110;&#19979;&#28216;&#26679;&#26412;&#22806;&#20219;&#21153;&#30340;&#27169;&#22411;&#12290;&#20363;&#22914;&#65292;&#22312;&#37329;&#34701;&#20013;&#65292;&#32570;&#22833;&#25910;&#30410;&#30340;&#25554;&#34917;&#21487;&#33021;&#34987;&#24212;&#29992;&#20110;&#22312;&#35757;&#32451;&#32452;&#21512;&#20248;&#21270;&#27169;&#22411;&#20043;&#21069;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#20570;&#27861;&#21487;&#33021;&#20250;&#23548;&#33268;&#26410;&#26469;&#24615;&#33021;&#19978;&#30340;&#21069;&#30651;&#24615;&#20559;&#24046;&#12290;&#20351;&#29992;&#23436;&#25972;&#25968;&#25454;&#38598;&#36827;&#34892;&#25554;&#34917;&#23384;&#22312;&#20351;&#29992;&#21482;&#35757;&#32451;&#25968;&#25454;&#30340;&#25554;&#34917;&#20013;&#36739;&#22823;&#30340;&#26041;&#24046;&#20043;&#38388;&#30340;&#22266;&#26377;&#26435;&#34913;&#12290;&#36890;&#36807;&#36830;&#25509;&#26102;&#38388;&#20013;&#26174;&#31034;&#30340;&#20449;&#24687;&#23618;&#27425;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36125;&#21494;&#26031;&#21518;&#39564;&#20849;&#35782;&#20998;&#24067;&#65292;&#23427;&#22312;&#25554;&#34917;&#20013;&#26368;&#20248;&#22320;&#25511;&#21046;&#20102;&#26041;&#24046;&#21644;&#21069;&#30651;&#24615;&#20559;&#24046;&#30340;&#26435;&#34913;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#37329;&#34701;&#25968;&#25454;&#20013;&#30340;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Missing time-series data is a prevalent practical problem. Imputation methods in time-series data often are applied to the full panel data with the purpose of training a model for a downstream out-of-sample task. For example, in finance, imputation of missing returns may be applied prior to training a portfolio optimization model. Unfortunately, this practice may result in a look-ahead-bias in the future performance on the downstream task. There is an inherent trade-off between the look-ahead-bias of using the full data set for imputation and the larger variance in the imputation from using only the training data. By connecting layers of information revealed in time, we propose a Bayesian posterior consensus distribution which optimally controls the variance and look-ahead-bias trade-off in the imputation. We demonstrate the benefit of our methodology both in synthetic and real financial data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#31995;&#32479;&#22320;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#35748;&#35777;&#40065;&#26834;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#20840;&#38754;&#30340;&#22522;&#20934;&#27979;&#35797;&#12290;&#35770;&#25991;&#24635;&#32467;&#20102;&#20851;&#20110;&#20984;&#26494;&#24347;&#12289;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#21644;&#38543;&#26426;&#24179;&#28369;&#31561;&#26041;&#27861;&#30340;&#26368;&#26032;&#30740;&#31350;&#36827;&#23637;&#65292;&#24182;&#35752;&#35770;&#20102;&#20854;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#21644;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2009.04131</link><description>&lt;p&gt;
SoK: &#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#35748;&#35777;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
SoK: Certified Robustness for Deep Neural Networks. (arXiv:2009.04131v9 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2009.04131
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#31995;&#32479;&#22320;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#35748;&#35777;&#40065;&#26834;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#20840;&#38754;&#30340;&#22522;&#20934;&#27979;&#35797;&#12290;&#35770;&#25991;&#24635;&#32467;&#20102;&#20851;&#20110;&#20984;&#26494;&#24347;&#12289;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#21644;&#38543;&#26426;&#24179;&#28369;&#31561;&#26041;&#27861;&#30340;&#26368;&#26032;&#30740;&#31350;&#36827;&#23637;&#65292;&#24182;&#35752;&#35770;&#20102;&#20854;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#21644;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#20294;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#25915;&#20987;&#65292;&#36825;&#22312;&#23558;&#36825;&#20123;&#27169;&#22411;&#37096;&#32626;&#21040;&#33258;&#21160;&#39550;&#39542;&#31561;&#23433;&#20840;&#20851;&#38190;&#22411;&#24212;&#29992;&#26102;&#24341;&#36215;&#20102;&#37325;&#22823;&#20851;&#27880;&#12290;&#19981;&#21516;&#30340;&#38450;&#24481;&#26041;&#27861;&#24050;&#34987;&#25552;&#20986;&#26469;&#23545;&#25239;&#23545;&#25239;&#25915;&#20987;&#65292;&#21253;&#25324;&#32463;&#39564;&#24615;&#38450;&#24481;&#21644;&#35748;&#35777;&#40065;&#26834;&#24615;&#38450;&#24481;&#12290;&#26412;&#25991;&#31995;&#32479;&#21270;&#30740;&#31350;&#20102;&#35748;&#35777;&#40065;&#26834;&#24615;&#38450;&#24481;&#26041;&#27861;&#21450;&#30456;&#20851;&#30340;&#23454;&#38469;&#21644;&#29702;&#35770;&#24847;&#20041;&#21644;&#21457;&#29616;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#39318;&#27425;&#23545;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#30340;&#29616;&#26377;&#40065;&#26834;&#24615;&#35748;&#35777;&#21644;&#35757;&#32451;&#26041;&#27861;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#22522;&#20934;&#27979;&#35797;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#20851;&#27880;&#22522;&#20110;&#20984;&#26494;&#24347;&#12289;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#21644;&#38543;&#26426;&#24179;&#28369;&#30340;&#35748;&#35777;&#40065;&#26834;&#24615;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24635;&#32467;&#20102;&#23545;&#26356;&#20808;&#36827;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#22914;&#22270;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;GCNN&#65289;&#21644;&#29983;&#25104;&#27169;&#22411;&#30340;&#35748;&#35777;&#40065;&#26834;&#24615;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#21644;&#35748;&#35777;&#40065;&#26834;&#24615;DNN&#30340;&#28508;&#22312;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Great advances in deep neural networks (DNNs) have led to state-of-the-art performance on a wide range of tasks. However, recent studies have shown that DNNs are vulnerable to adversarial attacks, which have brought great concerns when deploying these models to safety-critical applications such as autonomous driving. Different defense approaches have been proposed against adversarial attacks, including: a) empirical defenses, which can usually be adaptively attacked again without providing robustness certification; and b) certifiably robust approaches, which consist of robustness verification providing the lower bound of robust accuracy against any attacks under certain conditions and corresponding robust training approaches. In this paper, we systematize certifiably robust approaches and related practical and theoretical implications and findings. We also provide the first comprehensive benchmark on existing robustness verification and training approaches on different datasets. In par
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20351;&#29992;&#38454;&#20056;&#24130;&#20316;&#20026;&#26032;&#30340;&#21442;&#25968;&#35774;&#32622;&#24037;&#20855;&#65292;&#21487;&#20197;&#31616;&#21270;&#25110;&#25552;&#39640;&#21160;&#37327;&#27861;&#21644;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2006.01244</link><description>&lt;p&gt;
&#38454;&#20056;&#24130;&#30340;&#23041;&#21147;: (&#38543;&#26426;) &#20248;&#21270;&#30340;&#26032;&#21442;&#25968;&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Power of Factorial Powers: New Parameter settings for (Stochastic) Optimization. (arXiv:2006.01244v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.01244
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20351;&#29992;&#38454;&#20056;&#24130;&#20316;&#20026;&#26032;&#30340;&#21442;&#25968;&#35774;&#32622;&#24037;&#20855;&#65292;&#21487;&#20197;&#31616;&#21270;&#25110;&#25552;&#39640;&#21160;&#37327;&#27861;&#21644;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20984;&#20248;&#21270;&#21644;&#38750;&#20984;&#20248;&#21270;&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#21462;&#20915;&#20110;&#35768;&#22810;&#24120;&#25968;&#30340;&#36873;&#25321;&#65292;&#21253;&#25324;&#27493;&#38271;&#12289;Lyapunov&#20989;&#25968;&#24120;&#25968;&#21644;&#21160;&#37327;&#24120;&#25968;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#38454;&#20056;&#24130;&#20316;&#20026;&#23450;&#20041;&#20986;&#29616;&#22312;&#25910;&#25947;&#35777;&#26126;&#20013;&#30340;&#24120;&#25968;&#30340;&#28789;&#27963;&#24037;&#20855;&#12290;&#25105;&#20204;&#21015;&#20030;&#20102;&#36825;&#20123;&#25968;&#21015;&#20855;&#26377;&#30340;&#19968;&#20123;&#26174;&#33879;&#24615;&#36136;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#23427;&#20204;&#24212;&#29992;&#20110;&#21152;&#36895;&#26799;&#24230;&#26041;&#27861;&#12289;&#21160;&#37327;&#27861;&#21644;&#38543;&#26426;&#26041;&#24046;&#32553;&#20943;&#26041;&#27861;&#65288;SVRG&#65289;&#30340;&#25910;&#25947;&#35777;&#26126;&#20013;&#65292;&#20197;&#31616;&#21270;&#25110;&#25913;&#36827;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
The convergence rates for convex and non-convex optimization methods depend on the choice of a host of constants, including step sizes, Lyapunov function constants and momentum constants. In this work we propose the use of factorial powers as a flexible tool for defining constants that appear in convergence proofs. We list a number of remarkable properties that these sequences enjoy, and show how they can be applied to convergence proofs to simplify or improve the convergence rates of the momentum method, accelerated gradient and the stochastic variance reduced method (SVRG).
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23558;&#32479;&#35745; ML &#27169;&#22411;&#19982;&#36923;&#36753;&#25512;&#29702;&#32452;&#20214;&#38598;&#25104;&#65292;&#25552;&#20986;&#20102;&#26041;&#27861;&#26469;&#36827;&#19968;&#27493;&#25552;&#39640; ML &#27169;&#22411;&#30340;&#35748;&#35777;&#40065;&#26834;&#24615;&#65292;&#21516;&#26102;&#32473;&#20986;&#20102;&#39318;&#20010;&#36866;&#29992;&#20110;&#39532;&#23572;&#21487;&#22827;&#36923;&#36753;&#32593;&#32476;&#30340;&#40065;&#26834;&#24615;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2003.00120</link><description>&lt;p&gt;
&#36890;&#36807;&#36923;&#36753;&#25512;&#29702;&#19982;&#32479;&#35745;&#23398;&#20064;&#25552;&#39640;&#35748;&#35777;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Improving Certified Robustness via Statistical Learning with Logical Reasoning. (arXiv:2003.00120v9 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2003.00120
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23558;&#32479;&#35745; ML &#27169;&#22411;&#19982;&#36923;&#36753;&#25512;&#29702;&#32452;&#20214;&#38598;&#25104;&#65292;&#25552;&#20986;&#20102;&#26041;&#27861;&#26469;&#36827;&#19968;&#27493;&#25552;&#39640; ML &#27169;&#22411;&#30340;&#35748;&#35777;&#40065;&#26834;&#24615;&#65292;&#21516;&#26102;&#32473;&#20986;&#20102;&#39318;&#20010;&#36866;&#29992;&#20110;&#39532;&#23572;&#21487;&#22827;&#36923;&#36753;&#32593;&#32476;&#30340;&#40065;&#26834;&#24615;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#38024;&#23545;&#22797;&#26434; ML &#27169;&#22411;&#30340;&#35748;&#35777;&#40065;&#26834;&#24615;&#24555;&#36895;&#25552;&#39640;&#38656;&#35201;&#36827;&#34892;&#23494;&#38598;&#30340;&#31639;&#27861;&#24037;&#20316;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#40065;&#26834;&#24615;&#35748;&#35777;&#26041;&#27861;&#21482;&#33021;&#22312;&#26377;&#38480;&#30340;&#25200;&#21160;&#21322;&#24452;&#20869;&#36827;&#34892;&#35748;&#35777;&#12290;&#32771;&#34385;&#21040;&#29616;&#26377;&#30340;&#32431;&#25968;&#25454;&#39537;&#21160;&#30340;&#32479;&#35745;&#26041;&#27861;&#24050;&#32463;&#36798;&#21040;&#29942;&#39048;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#39532;&#23572;&#21487;&#22827;&#36923;&#36753;&#32593;&#32476;&#65288;MLN&#65289;&#23558;&#32479;&#35745; ML &#27169;&#22411;&#19982;&#30693;&#35782;&#65288;&#36890;&#36807;&#36923;&#36753;&#35268;&#21017;&#34920;&#31034;&#65289;&#20316;&#20026;&#25512;&#29702;&#32452;&#20214;&#36827;&#34892;&#38598;&#25104;&#65292;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#25972;&#20307;&#30340;&#35748;&#35777;&#40065;&#26834;&#24615;&#12290;&#36825;&#24341;&#21457;&#20102;&#20851;&#20110;&#35748;&#35777;&#36825;&#31181;&#33539;&#24335;&#65288;&#29305;&#21035;&#26159;&#25512;&#29702;&#32452;&#20214;&#65292;&#22914; MLN&#65289;&#40065;&#26834;&#24615;&#30340;&#26032;&#30340;&#30740;&#31350;&#38382;&#39064;&#12290;&#20316;&#20026;&#29702;&#35299;&#36825;&#20123;&#38382;&#39064;&#30340;&#31532;&#19968;&#27493;&#65292;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#35777;&#26126; MLN &#40065;&#26834;&#24615;&#35745;&#31639;&#22797;&#26434;&#24230;&#26159; #P-&#38590;&#30340;&#12290;&#22312;&#36825;&#20010;&#38590;&#24230;&#32467;&#26524;&#30340;&#25351;&#23548;&#19979;&#65292;&#25105;&#20204;&#36890;&#36807;&#20180;&#32454;&#20998;&#26512;&#19981;&#21516;&#30340;&#27169;&#22411;&#35268;&#21017;&#65292;&#25512;&#23548;&#20986;&#20102; MLN &#30340;&#31532;&#19968;&#20010;&#35748;&#35777;&#30340;&#40065;&#26834;&#24615;&#30028;&#38480;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22312;&#20004;&#20010;&#24191;&#27867;&#20351;&#29992;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Intensive algorithmic efforts have been made to enable the rapid improvements of certificated robustness for complex ML models recently. However, current robustness certification methods are only able to certify under a limited perturbation radius. Given that existing pure data-driven statistical approaches have reached a bottleneck, in this paper, we propose to integrate statistical ML models with knowledge (expressed as logical rules) as a reasoning component using Markov logic networks (MLN, so as to further improve the overall certified robustness. This opens new research questions about certifying the robustness of such a paradigm, especially the reasoning component (e.g., MLN). As the first step towards understanding these questions, we first prove that the computational complexity of certifying the robustness of MLN is #P-hard. Guided by this hardness result, we then derive the first certified robustness bound for MLN by carefully analyzing different model regimes. Finally, we c
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20272;&#35745;&#22320;&#38663;&#26029;&#23618;&#19981;&#30830;&#23450;&#24615;&#65292;&#36890;&#36807;&#35299;&#20915;&#25968;&#25454;&#19981;&#36275;&#38382;&#39064;&#21644;&#30830;&#23450;&#23548;&#33268;&#26029;&#23618;&#30340;&#21442;&#25968;&#32452;&#21512;&#65292;&#24182;&#20351;&#29992;&#20004;&#21315;&#27425;&#30340;&#26029;&#23618;&#27169;&#25311;&#26469;&#35757;&#32451;&#21644;&#27979;&#35797;&#27169;&#22411;&#65292;&#26368;&#32456;&#24471;&#20998;0.83&#12290;</title><link>http://arxiv.org/abs/1911.09660</link><description>&lt;p&gt;
&#20351;&#29992;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20272;&#35745;&#22320;&#38663;&#26029;&#23618;&#30340;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Estimating uncertainty of earthquake rupture using Bayesian neural network. (arXiv:1911.09660v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1911.09660
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20272;&#35745;&#22320;&#38663;&#26029;&#23618;&#19981;&#30830;&#23450;&#24615;&#65292;&#36890;&#36807;&#35299;&#20915;&#25968;&#25454;&#19981;&#36275;&#38382;&#39064;&#21644;&#30830;&#23450;&#23548;&#33268;&#26029;&#23618;&#30340;&#21442;&#25968;&#32452;&#21512;&#65292;&#24182;&#20351;&#29992;&#20004;&#21315;&#27425;&#30340;&#26029;&#23618;&#27169;&#25311;&#26469;&#35757;&#32451;&#21644;&#27979;&#35797;&#27169;&#22411;&#65292;&#26368;&#32456;&#24471;&#20998;0.83&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNN&#65289;&#26159;&#19968;&#31181;&#32467;&#21512;&#20102;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#21644;&#38543;&#26426;&#36807;&#31243;&#20248;&#21183;&#30340;&#27010;&#29575;&#27169;&#22411;&#12290;&#22240;&#27492;&#65292;BNN&#21487;&#20197;&#35299;&#20915;&#36807;&#24230;&#25311;&#21512;&#38382;&#39064;&#65292;&#24182;&#22312;&#25968;&#25454;&#26377;&#38480;&#30340;&#24212;&#29992;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;&#22320;&#38663;&#26029;&#23618;&#30740;&#31350;&#23601;&#26159;&#36825;&#26679;&#19968;&#20010;&#25968;&#25454;&#19981;&#36275;&#30340;&#38382;&#39064;&#65292;&#31185;&#23398;&#23478;&#24517;&#39035;&#20381;&#38752;&#35768;&#22810;&#35797;&#39564;&#21644;&#38169;&#35823;&#30340;&#25968;&#20540;&#25110;&#29289;&#29702;&#27169;&#22411;&#26469;&#36827;&#34892;&#30740;&#31350;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#20351;&#29992;BNN&#65292;&#65288;1&#65289;&#35299;&#20915;&#25968;&#25454;&#38382;&#39064;&#65292;&#65288;2&#65289;&#25214;&#20986;&#23548;&#33268;&#22320;&#38663;&#26029;&#35010;&#30340;&#21442;&#25968;&#32452;&#21512;&#65292;&#65288;3&#65289;&#20272;&#35745;&#22320;&#38663;&#26029;&#23618;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#20351;&#29992;&#20102;&#20004;&#21315;&#27425;&#30340;&#26029;&#23618;&#27169;&#25311;&#26469;&#35757;&#32451;&#21644;&#27979;&#35797;&#27169;&#22411;&#65292;&#22312;&#27599;&#20010;&#27169;&#25311;&#20013;&#65292;&#19968;&#20010;&#31616;&#21333;&#30340;2D&#26029;&#23618;&#32467;&#26500;&#34987;&#32771;&#34385;&#65292;&#22312;&#20013;&#24515;&#22788;&#20855;&#26377;&#39640;&#26031;&#20960;&#20309;&#24322;&#36136;&#24615;&#65292;8&#20010;&#21442;&#25968;&#22312;&#27599;&#27425;&#27169;&#25311;&#20013;&#21464;&#21270;&#12290;BNN&#30340;&#27979;&#35797;F1&#24471;&#20998;&#20026;0.83&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian neural networks (BNN) are the probabilistic model that combines the strengths of both neural network (NN) and stochastic processes. As a result, BNN can combat overfitting and perform well in applications where data is limited. Earthquake rupture study is such a problem where data is insufficient, and scientists have to rely on many trial and error numerical or physical models. Lack of resources and computational expenses, often, it becomes hard to determine the reasons behind the earthquake rupture. In this work, a BNN has been used (1) to combat the small data problem and (2) to find out the parameter combinations responsible for earthquake rupture and (3) to estimate the uncertainty associated with earthquake rupture. Two thousand rupture simulations are used to train and test the model. A simple 2D rupture geometry is considered where the fault has a Gaussian geometric heterogeneity at the center, and eight parameters vary in each simulation. The test F1-score of BNN (0.83
&lt;/p&gt;</description></item></channel></rss>