<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36890;&#36807;&#38750;&#20984;&#35268;&#21010;&#25216;&#26415;&#65292;&#21033;&#29992;&#32858;&#31867;&#21644;&#20998;&#20301;&#25968;&#20272;&#35745;&#30340;&#26041;&#27861;&#35299;&#20915;&#20102;&#38543;&#26426;&#24191;&#20041;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292;&#24182;&#22312;&#21508;&#31181;&#25351;&#26631;&#19978;&#34920;&#29616;&#20248;&#20110;&#20256;&#32479;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2401.08488</link><description>&lt;p&gt;
&#36890;&#36807;&#38750;&#20984;&#35268;&#21010;&#35299;&#20915;&#38543;&#26426;&#24191;&#20041;&#32447;&#24615;&#22238;&#24402;&#30340;&#26032;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Novel Approach in Solving Stochastic Generalized Linear Regression via Nonconvex Programming. (arXiv:2401.08488v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08488
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#38750;&#20984;&#35268;&#21010;&#25216;&#26415;&#65292;&#21033;&#29992;&#32858;&#31867;&#21644;&#20998;&#20301;&#25968;&#20272;&#35745;&#30340;&#26041;&#27861;&#35299;&#20915;&#20102;&#38543;&#26426;&#24191;&#20041;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292;&#24182;&#22312;&#21508;&#31181;&#25351;&#26631;&#19978;&#34920;&#29616;&#20248;&#20110;&#20256;&#32479;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24191;&#20041;&#32447;&#24615;&#22238;&#24402;(&#22914;&#36923;&#36753;&#22238;&#24402;&#25110;&#27850;&#26494;&#22238;&#24402;)&#26159;&#38271;&#26399;&#30740;&#31350;&#30340;&#22238;&#24402;&#20998;&#26512;&#26041;&#27861;&#65292;&#22312;&#21508;&#31181;&#20998;&#31867;&#38382;&#39064;&#20013;&#24191;&#27867;&#24212;&#29992;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#23558;&#38543;&#26426;&#24191;&#20041;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#35270;&#20026;&#24102;&#26377;&#26426;&#20250;&#32422;&#26463;&#30340;&#38543;&#26426;&#38382;&#39064;&#65292;&#24182;&#20351;&#29992;&#38750;&#20984;&#35268;&#21010;&#25216;&#26415;&#35299;&#20915;&#23427;&#12290;&#21516;&#26102;&#36816;&#29992;&#32858;&#31867;&#25216;&#26415;&#21644;&#20998;&#20301;&#25968;&#20272;&#35745;&#26469;&#20272;&#35745;&#38543;&#26426;&#25968;&#25454;&#30340;&#22343;&#20540;&#21644;&#26041;&#24046;-&#21327;&#26041;&#24046;&#30697;&#38453;&#12290;&#20351;&#29992;F1&#24471;&#20998;&#12289;&#31934;&#30830;&#24230;&#24471;&#20998;&#21644;&#21484;&#22238;&#29575;&#24471;&#20998;&#31561;&#25351;&#26631;&#26469;&#35780;&#20272;&#36923;&#36753;&#22238;&#24402;&#27169;&#22411;&#30340;&#25928;&#26524;&#12290;&#22312;&#30456;&#21516;&#25968;&#25454;&#38598;&#19978;&#65292;&#25152;&#25552;&#31639;&#27861;&#30340;&#32467;&#26524;&#27604;&#26222;&#36890;&#36923;&#36753;&#22238;&#24402;&#27169;&#22411;&#22312;&#20197;&#19978;&#35780;&#20272;&#26631;&#20934;&#19978;&#25552;&#39640;&#20102;1-2&#20010;&#30334;&#20998;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generalized linear regressions, such as logistic regressions or Poisson regressions, are long-studied regression analysis approaches, and their applications are widely employed in various classification problems. Our study considers a stochastic generalized linear regression model as a stochastic problem with chance constraints and tackles it using nonconvex programming techniques. Clustering techniques and quantile estimation are also used to estimate random data's mean and variance-covariance matrix. Metrics for measuring the performance of logistic regression are used to assess the model's efficacy, including the F1 score, precision score, and recall score. The results of the proposed algorithm were over 1 to 2 percent better than the ordinary logistic regression model on the same dataset with the above assessment criteria.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#24314;&#31435;&#26497;&#22823;&#20284;&#28982;&#20272;&#35745;&#37327;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#32467;&#26524;&#65292;&#22635;&#34917;&#20102;&#37197;&#23545;&#27604;&#36739;&#27169;&#22411;&#20013;&#32479;&#35745;&#25512;&#26029;&#30340;&#31354;&#30333;&#65292;&#20026;&#21508;&#31181;&#37197;&#23545;&#27604;&#36739;&#27169;&#22411;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#26041;&#27861;&#65292;&#36229;&#36234;&#20102;Bradley-Terry&#27169;&#22411;&#65292;&#20026;&#23454;&#36341;&#32773;&#25552;&#20379;&#20102;&#22362;&#23454;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2401.08463</link><description>&lt;p&gt;
&#23545;&#20110;&#37197;&#23545;&#27604;&#36739;&#27169;&#22411;&#30340;&#32479;&#35745;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Statistical inference for pairwise comparison models. (arXiv:2401.08463v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08463
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#24314;&#31435;&#26497;&#22823;&#20284;&#28982;&#20272;&#35745;&#37327;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#32467;&#26524;&#65292;&#22635;&#34917;&#20102;&#37197;&#23545;&#27604;&#36739;&#27169;&#22411;&#20013;&#32479;&#35745;&#25512;&#26029;&#30340;&#31354;&#30333;&#65292;&#20026;&#21508;&#31181;&#37197;&#23545;&#27604;&#36739;&#27169;&#22411;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#26041;&#27861;&#65292;&#36229;&#36234;&#20102;Bradley-Terry&#27169;&#22411;&#65292;&#20026;&#23454;&#36341;&#32773;&#25552;&#20379;&#20102;&#22362;&#23454;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37197;&#23545;&#27604;&#36739;&#27169;&#22411;&#34987;&#29992;&#20110;&#21508;&#20010;&#39046;&#22495;&#30340;&#23454;&#29992;&#24615;&#21644;&#25490;&#21517;&#35780;&#20272;&#12290;&#29616;&#20195;&#38382;&#39064;&#35268;&#27169;&#30340;&#22686;&#21152;&#24378;&#35843;&#20102;&#23545;&#20110;&#24403;&#34987;&#27604;&#36739;&#23545;&#35937;&#25968;&#37327;&#26080;&#38480;&#22686;&#21152;&#26102;&#65292;&#23545;&#20110;&#36825;&#20123;&#27169;&#22411;&#20013;&#30340;&#32479;&#35745;&#25512;&#26029;&#30340;&#29702;&#35299;&#30340;&#38656;&#27714;&#12290;&#30446;&#21069;&#65292;&#25991;&#29486;&#20013;&#23545;&#20110;&#36825;&#20123;&#27169;&#22411;&#20013;&#30340;&#32479;&#35745;&#25512;&#26029;&#30340;&#29702;&#35299;&#36824;&#30456;&#24403;&#26377;&#38480;&#65292;&#38500;&#38750;&#21482;&#26159;&#22312;&#23569;&#25968;&#29305;&#27530;&#23454;&#20363;&#20013;&#12290;&#26412;&#25991;&#36890;&#36807;&#22312;&#24191;&#27867;&#30340;&#37197;&#23545;&#27604;&#36739;&#27169;&#22411;&#20013;&#24314;&#31435;&#26497;&#22823;&#20284;&#28982;&#20272;&#35745;&#37327;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#32467;&#26524;&#26469;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#20851;&#38190;&#24605;&#24819;&#22312;&#20110;&#23558;&#36153;&#33293;&#23572;&#20449;&#24687;&#30697;&#38453;&#35782;&#21035;&#20026;&#21152;&#26435;&#22270;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#65292;&#36890;&#36807;&#19968;&#31181;&#32454;&#33268;&#20837;&#24494;&#30340;&#35889;&#20998;&#26512;&#26041;&#27861;&#26469;&#36827;&#34892;&#30740;&#31350;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#20026;&#22312;&#21508;&#31181;&#37197;&#23545;&#27604;&#36739;&#27169;&#22411;&#20013;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#32479;&#19968;&#30340;&#26041;&#27861;&#65292;&#36229;&#36234;&#20102;Bradley-Terry&#27169;&#22411;&#65292;&#20026;&#23454;&#36341;&#32773;&#25552;&#20379;&#20102;&#22362;&#23454;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#36890;&#36807;&#21033;&#29992;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#30340;&#27169;&#25311;&#39564;&#35777;&#36825;&#19968;&#28176;&#36817;&#27491;&#24577;&#24615;&#32467;&#26524;&#65292;&#28982;&#21518;&#36827;&#34892;&#20102;
&lt;/p&gt;
&lt;p&gt;
Pairwise comparison models are used for quantitatively evaluating utility and ranking in various fields. The increasing scale of modern problems underscores the need to understand statistical inference in these models when the number of subjects diverges, which is currently lacking in the literature except in a few special instances. This paper addresses this gap by establishing an asymptotic normality result for the maximum likelihood estimator in a broad class of pairwise comparison models. The key idea lies in identifying the Fisher information matrix as a weighted graph Laplacian matrix which can be studied via a meticulous spectral analysis. Our findings provide the first unified theory for performing statistical inference in a wide range of pairwise comparison models beyond the Bradley--Terry model, benefiting practitioners with a solid theoretical guarantee for their use. Simulations utilizing synthetic data are conducted to validate the asymptotic normality result, followed by 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21487;&#25511;&#30340;&#35823;&#21457;&#29616;&#29575;&#65288;FDR&#65289;&#39537;&#21160;&#30340;&#31232;&#30095;PCA&#26041;&#27861;&#65292;&#22312;&#19981;&#38656;&#35201;&#35843;&#25972;&#31232;&#30095;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#23454;&#29616;&#20102;&#23545;&#21152;&#36733;&#21521;&#37327;&#30340;&#33258;&#21160;&#36873;&#25321;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#20256;&#32479;&#31232;&#30095;PCA&#26041;&#27861;&#23481;&#26131;&#36873;&#25321;&#19981;&#30456;&#20851;&#21464;&#37327;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.08375</link><description>&lt;p&gt;
&#36890;&#36807;&#21487;&#25511;&#30340;&#35823;&#21457;&#29616;&#29575;&#36873;&#25321;&#30340;&#31232;&#30095;PCA
&lt;/p&gt;
&lt;p&gt;
Sparse PCA with False Discovery Rate Controlled Variable Selection. (arXiv:2401.08375v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08375
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21487;&#25511;&#30340;&#35823;&#21457;&#29616;&#29575;&#65288;FDR&#65289;&#39537;&#21160;&#30340;&#31232;&#30095;PCA&#26041;&#27861;&#65292;&#22312;&#19981;&#38656;&#35201;&#35843;&#25972;&#31232;&#30095;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#23454;&#29616;&#20102;&#23545;&#21152;&#36733;&#21521;&#37327;&#30340;&#33258;&#21160;&#36873;&#25321;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#20256;&#32479;&#31232;&#30095;PCA&#26041;&#27861;&#23481;&#26131;&#36873;&#25321;&#19981;&#30456;&#20851;&#21464;&#37327;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#26088;&#22312;&#23558;&#39640;&#32500;&#25968;&#25454;&#26144;&#23556;&#21040;&#36739;&#20302;&#32500;&#30340;&#32447;&#24615;&#23376;&#31354;&#38388;&#12290;&#36890;&#36807;&#20351;&#21152;&#36733;&#21521;&#37327;&#31232;&#30095;&#65292;&#23427;&#26082;&#21487;&#20197;&#23454;&#29616;&#38477;&#32500;&#21448;&#21487;&#20197;&#36827;&#34892;&#21464;&#37327;&#36873;&#25321;&#12290;&#31232;&#30095;PCA&#31639;&#27861;&#36890;&#24120;&#26159;&#22312;&#35299;&#37322;&#26041;&#24046;&#21644;&#21152;&#36733;&#21521;&#37327;&#31232;&#30095;&#24615;&#20043;&#38388;&#26435;&#34913;&#65292;&#21152;&#36733;&#21521;&#37327;&#30340;&#31232;&#30095;&#24615;&#21363;&#36873;&#25321;&#30340;&#21464;&#37327;&#25968;&#37327;&#12290;&#30001;&#20110;&#39640;&#35299;&#37322;&#26041;&#24046;&#19981;&#19968;&#23450;&#20195;&#34920;&#30456;&#20851;&#20449;&#24687;&#65292;&#36825;&#20123;&#26041;&#27861;&#23481;&#26131;&#36873;&#25321;&#19981;&#30456;&#20851;&#30340;&#21464;&#37327;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20197;&#35823;&#21457;&#29616;&#29575;&#65288;FDR&#65289;&#20026;&#39537;&#21160;&#30340;&#31232;&#30095;PCA&#30340;&#26367;&#20195;&#24418;&#24335;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#32456;&#27490;&#38543;&#26426;&#23454;&#39564;&#65288;T-Rex&#65289;&#36873;&#25321;&#22120;&#33258;&#21160;&#30830;&#23450;&#21152;&#36733;&#21521;&#37327;&#30340;FDR&#25511;&#21046;&#25903;&#25745;&#12290;&#24471;&#21040;&#30340;T-Rex PCA&#30340;&#19968;&#22823;&#20248;&#21183;&#26159;&#19981;&#38656;&#35201;&#35843;&#25972;&#31232;&#30095;&#21442;&#25968;&#12290;&#25968;&#20540;&#23454;&#39564;&#21644;&#32929;&#31080;&#24066;&#22330;&#25968;&#25454;&#31034;&#20363;&#35777;&#26126;&#20102;&#24615;&#33021;&#30340;&#26174;&#33879;&#25913;&#21892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse principal component analysis (PCA) aims at mapping large dimensional data to a linear subspace of lower dimension. By imposing loading vectors to be sparse, it performs the double duty of dimension reduction and variable selection. Sparse PCA algorithms are usually expressed as a trade-off between explained variance and sparsity of the loading vectors (i.e., number of selected variables). As a high explained variance is not necessarily synonymous with relevant information, these methods are prone to select irrelevant variables. To overcome this issue, we propose an alternative formulation of sparse PCA driven by the false discovery rate (FDR). We then leverage the Terminating-Random Experiments (T-Rex) selector to automatically determine an FDR-controlled support of the loading vectors. A major advantage of the resulting T-Rex PCA is that no sparsity parameter tuning is required. Numerical experiments and a stock market data example demonstrate a significant performance improvem
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21442;&#25968;&#65292;&#24179;&#34913;&#32676;&#20307;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;BGATE&#65289;&#65292;&#29992;&#20110;&#35299;&#37322;&#22788;&#29702;&#22312;&#32676;&#20307;&#38388;&#30340;&#25928;&#24212;&#24046;&#24322;&#65292;&#35813;&#21442;&#25968;&#22522;&#20110;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#23545;&#31163;&#25955;&#22788;&#29702;&#36827;&#34892;&#20272;&#35745;&#12290;&#36890;&#36807;&#27604;&#36739;&#20004;&#20010;BGATE&#30340;&#24046;&#24322;&#65292;&#33021;&#26356;&#22909;&#22320;&#20998;&#26512;&#22788;&#29702;&#30340;&#24322;&#36136;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.08290</link><description>&lt;p&gt;
&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#29992;&#20110;&#20013;&#20171;&#25928;&#24212;&#12290; (arXiv:2401.08290v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
Causal Machine Learning for Moderation Effects. (arXiv:2401.08290v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08290
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21442;&#25968;&#65292;&#24179;&#34913;&#32676;&#20307;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;BGATE&#65289;&#65292;&#29992;&#20110;&#35299;&#37322;&#22788;&#29702;&#22312;&#32676;&#20307;&#38388;&#30340;&#25928;&#24212;&#24046;&#24322;&#65292;&#35813;&#21442;&#25968;&#22522;&#20110;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#23545;&#31163;&#25955;&#22788;&#29702;&#36827;&#34892;&#20272;&#35745;&#12290;&#36890;&#36807;&#27604;&#36739;&#20004;&#20010;BGATE&#30340;&#24046;&#24322;&#65292;&#33021;&#26356;&#22909;&#22320;&#20998;&#26512;&#22788;&#29702;&#30340;&#24322;&#36136;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#20219;&#20309;&#20915;&#31574;&#32773;&#26469;&#35828;&#65292;&#20102;&#35299;&#20915;&#31574;&#65288;&#22788;&#29702;&#65289;&#23545;&#25972;&#20307;&#21644;&#23376;&#32676;&#30340;&#24433;&#21709;&#26159;&#38750;&#24120;&#26377;&#20215;&#20540;&#30340;&#12290;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#26368;&#36817;&#25552;&#20379;&#20102;&#29992;&#20110;&#20272;&#35745;&#32676;&#20307;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;GATE&#65289;&#30340;&#24037;&#20855;&#65292;&#20197;&#26356;&#22909;&#22320;&#29702;&#35299;&#22788;&#29702;&#30340;&#24322;&#36136;&#24615;&#12290;&#26412;&#25991;&#35299;&#20915;&#20102;&#22312;&#32771;&#34385;&#20854;&#20182;&#21327;&#21464;&#37327;&#21464;&#21270;&#30340;&#24773;&#20917;&#19979;&#35299;&#37322;&#32676;&#20307;&#38388;&#22788;&#29702;&#25928;&#24212;&#24046;&#24322;&#30340;&#38590;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#21442;&#25968;&#65292;&#21363;&#24179;&#34913;&#32676;&#20307;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;BGATE&#65289;&#65292;&#23427;&#34913;&#37327;&#20102;&#20855;&#26377;&#29305;&#23450;&#20998;&#24067;&#30340;&#20808;&#39564;&#30830;&#23450;&#21327;&#21464;&#37327;&#30340;GATE&#12290;&#36890;&#36807;&#27604;&#36739;&#20004;&#20010;BGATE&#30340;&#24046;&#24322;&#65292;&#25105;&#20204;&#21487;&#20197;&#26356;&#26377;&#24847;&#20041;&#22320;&#20998;&#26512;&#24322;&#36136;&#24615;&#65292;&#32780;&#19981;&#20165;&#20165;&#27604;&#36739;&#20004;&#20010;GATE&#12290;&#36825;&#20010;&#21442;&#25968;&#30340;&#20272;&#35745;&#31574;&#30053;&#26159;&#22522;&#20110;&#26080;&#28151;&#28102;&#35774;&#32622;&#20013;&#31163;&#25955;&#22788;&#29702;&#30340;&#21452;&#37325;/&#21435;&#20559;&#26426;&#22120;&#23398;&#20064;&#65292;&#35813;&#20272;&#35745;&#37327;&#22312;&#26631;&#20934;&#26465;&#20214;&#19979;&#34920;&#29616;&#20026;$\sqrt{N}$&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;&#28155;&#21152;&#39069;&#22806;&#30340;&#26631;&#35782;
&lt;/p&gt;
&lt;p&gt;
It is valuable for any decision maker to know the impact of decisions (treatments) on average and for subgroups. The causal machine learning literature has recently provided tools for estimating group average treatment effects (GATE) to understand treatment heterogeneity better. This paper addresses the challenge of interpreting such differences in treatment effects between groups while accounting for variations in other covariates. We propose a new parameter, the balanced group average treatment effect (BGATE), which measures a GATE with a specific distribution of a priori-determined covariates. By taking the difference of two BGATEs, we can analyse heterogeneity more meaningfully than by comparing two GATEs. The estimation strategy for this parameter is based on double/debiased machine learning for discrete treatments in an unconfoundedness setting, and the estimator is shown to be $\sqrt{N}$-consistent and asymptotically normal under standard conditions. Adding additional identifyin
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;Vision Transformer&#20013;&#27880;&#24847;&#21147;&#22270;&#30340;&#32479;&#35745;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#27880;&#24847;&#21147;&#20316;&#20026;&#21487;&#38752;&#30340;&#23450;&#37327;&#35777;&#25454;&#25351;&#26631;&#29992;&#20110;&#20915;&#31574;&#65292;&#24182;&#36890;&#36807;p&#20540;&#36827;&#34892;&#32479;&#35745;&#26174;&#33879;&#24615;&#37327;&#21270;&#12290;</title><link>http://arxiv.org/abs/2401.08169</link><description>&lt;p&gt;
Vision Transformer&#20013;&#30340;&#27880;&#24847;&#21147;&#22270;&#32479;&#35745;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Statistical Test for Attention Map in Vision Transformer. (arXiv:2401.08169v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08169
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;Vision Transformer&#20013;&#27880;&#24847;&#21147;&#22270;&#30340;&#32479;&#35745;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#27880;&#24847;&#21147;&#20316;&#20026;&#21487;&#38752;&#30340;&#23450;&#37327;&#35777;&#25454;&#25351;&#26631;&#29992;&#20110;&#20915;&#31574;&#65292;&#24182;&#36890;&#36807;p&#20540;&#36827;&#34892;&#32479;&#35745;&#26174;&#33879;&#24615;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Vision Transformer&#65288;ViT&#65289;&#22312;&#21508;&#31181;&#35745;&#31639;&#26426;&#35270;&#35273;&#20219;&#21153;&#20013;&#23637;&#31034;&#20986;&#20102;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;&#27880;&#24847;&#21147;&#23545;&#20110;ViT&#25429;&#25417;&#22270;&#20687;&#34917;&#19969;&#20043;&#38388;&#22797;&#26434;&#24191;&#27867;&#30340;&#20851;&#31995;&#38750;&#24120;&#37325;&#35201;&#65292;&#20351;&#24471;&#27169;&#22411;&#21487;&#20197;&#26435;&#34913;&#22270;&#20687;&#34917;&#19969;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#24110;&#21161;&#25105;&#20204;&#29702;&#35299;&#20915;&#31574;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#24403;&#23558;ViT&#30340;&#27880;&#24847;&#21147;&#29992;&#20316;&#39640;&#39118;&#38505;&#20915;&#31574;&#20219;&#21153;&#65288;&#22914;&#21307;&#23398;&#35786;&#26029;&#65289;&#20013;&#30340;&#35777;&#25454;&#26102;&#65292;&#38754;&#20020;&#19968;&#20010;&#25361;&#25112;&#65292;&#21363;&#27880;&#24847;&#26426;&#21046;&#21487;&#33021;&#38169;&#35823;&#22320;&#20851;&#27880;&#26080;&#20851;&#30340;&#21306;&#22495;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;ViT&#27880;&#24847;&#21147;&#30340;&#32479;&#35745;&#26816;&#39564;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;&#27880;&#24847;&#21147;&#20316;&#20026;&#21487;&#38752;&#30340;&#23450;&#37327;&#35777;&#25454;&#25351;&#26631;&#29992;&#20110;ViT&#30340;&#20915;&#31574;&#65292;&#24182;&#20005;&#26684;&#25511;&#21046;&#35823;&#24046;&#29575;&#12290;&#20351;&#29992;&#36873;&#25321;&#24615;&#25512;&#29702;&#26694;&#26550;&#65292;&#25105;&#20204;&#20197;p&#20540;&#30340;&#24418;&#24335;&#37327;&#21270;&#27880;&#24847;&#21147;&#30340;&#32479;&#35745;&#26174;&#33879;&#24615;&#65292;&#20174;&#32780;&#33021;&#22815;&#29702;&#35770;&#19978;&#22522;&#20110;&#20551;&#38451;&#24615;&#26816;&#27979;&#27010;&#29575;&#37327;&#21270;&#27880;&#24847;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Vision Transformer (ViT) demonstrates exceptional performance in various computer vision tasks. Attention is crucial for ViT to capture complex wide-ranging relationships among image patches, allowing the model to weigh the importance of image patches and aiding our understanding of the decision-making process. However, when utilizing the attention of ViT as evidence in high-stakes decision-making tasks such as medical diagnostics, a challenge arises due to the potential of attention mechanisms erroneously focusing on irrelevant regions. In this study, we propose a statistical test for ViT's attentions, enabling us to use the attentions as reliable quantitative evidence indicators for ViT's decision-making with a rigorously controlled error rate. Using the framework called selective inference, we quantify the statistical significance of attentions in the form of p-values, which enables the theoretically grounded quantification of the false positive detection probability of attentio
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#32479;&#19968;&#30340;&#29702;&#35770;&#26694;&#26550;&#30740;&#31350;&#20102;&#22810;&#35270;&#35282;&#25968;&#25454;&#20013;&#30340;&#31038;&#21306;&#26816;&#27979;&#38382;&#39064;&#65292;&#24182;&#25552;&#21462;&#20986;&#20102;&#22312;&#19981;&#21516;&#27169;&#22411;&#19979;&#31038;&#21306;&#24674;&#22797;&#30340;&#22522;&#26412;&#38408;&#20540;&#12290;</title><link>http://arxiv.org/abs/2401.08167</link><description>&lt;p&gt;
&#22810;&#35270;&#35282;&#25968;&#25454;&#30340;&#31038;&#21306;&#26816;&#27979;&#30340;&#22522;&#26412;&#38480;&#21046;&#65306;&#22810;&#23618;&#12289;&#21160;&#24577;&#21644;&#37096;&#20998;&#26631;&#35760;&#30340;&#22359;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Fundamental limits of community detection from multi-view data: multi-layer, dynamic and partially labeled block models. (arXiv:2401.08167v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08167
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#32479;&#19968;&#30340;&#29702;&#35770;&#26694;&#26550;&#30740;&#31350;&#20102;&#22810;&#35270;&#35282;&#25968;&#25454;&#20013;&#30340;&#31038;&#21306;&#26816;&#27979;&#38382;&#39064;&#65292;&#24182;&#25552;&#21462;&#20986;&#20102;&#22312;&#19981;&#21516;&#27169;&#22411;&#19979;&#31038;&#21306;&#24674;&#22797;&#30340;&#22522;&#26412;&#38408;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#35270;&#35282;&#25968;&#25454;&#22312;&#29616;&#20195;&#32593;&#32476;&#20998;&#26512;&#20013;&#32463;&#24120;&#20986;&#29616;&#65292;&#20363;&#22914;&#31038;&#20132;&#32593;&#32476;&#20998;&#26512;&#20013;&#20010;&#20307;&#20043;&#38388;&#30340;&#22810;&#31181;&#31867;&#22411;&#20851;&#31995;&#12289;&#35266;&#27979;&#21333;&#20301;&#20043;&#38388;&#30340;&#38271;&#26399;&#20114;&#21160;&#27979;&#37327;&#20197;&#21450;&#24102;&#26377;&#22122;&#22768;&#37096;&#20998;&#26631;&#35760;&#39030;&#28857;&#30340;&#27880;&#37322;&#32593;&#32476;&#31561;&#12290;&#25105;&#20204;&#36890;&#36807;&#32479;&#19968;&#30340;&#29702;&#35770;&#26694;&#26550;&#30740;&#31350;&#20102;&#36825;&#20123;&#19981;&#21516;&#35774;&#32622;&#19979;&#30340;&#31038;&#21306;&#26816;&#27979;&#65292;&#24182;&#30740;&#31350;&#20102;&#31038;&#21306;&#24674;&#22797;&#30340;&#22522;&#26412;&#38408;&#20540;&#12290;&#25105;&#20204;&#22312;&#24230;&#25968;&#36275;&#22815;&#22823;&#30340;&#24773;&#20917;&#19979;&#34920;&#24449;&#20102;&#25968;&#25454;&#21644;&#28508;&#22312;&#21442;&#25968;&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#12290;&#22522;&#20110;&#36825;&#20010;&#36890;&#29992;&#32467;&#26524;&#65292;(i)&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#22312;&#38750;&#22343;&#21248;&#22810;&#23618;&#22359;&#27169;&#22411;&#20013;&#36827;&#34892;&#31038;&#21306;&#26816;&#27979;&#30340;&#23574;&#38160;&#38408;&#20540;&#65292;(ii)&#34920;&#24449;&#20102;&#21160;&#24577;&#38543;&#26426;&#22359;&#27169;&#22411;&#20013;&#24369;&#24674;&#22797;&#30340;&#23574;&#38160;&#38408;&#20540;&#65292;(iii)&#30830;&#23450;&#20102;&#19981;&#24179;&#34913;&#37096;&#20998;&#26631;&#35760;&#22359;&#27169;&#22411;&#20013;&#30340;&#20114;&#20449;&#24687;&#26497;&#38480;&#12290;&#25105;&#20204;&#30340;&#21069;&#20004;&#20010;&#32467;&#26524;&#26159;&#22312;&#22352;&#26631;&#19978;&#20445;&#20984;&#30340;&#26465;&#20214;&#19979;&#25512;&#23548;&#20986;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-view data arises frequently in modern network analysis e.g. relations of multiple types among individuals in social network analysis, longitudinal measurements of interactions among observational units, annotated networks with noisy partial labeling of vertices etc. We study community detection in these disparate settings via a unified theoretical framework, and investigate the fundamental thresholds for community recovery. We characterize the mutual information between the data and the latent parameters, provided the degrees are sufficiently large. Based on this general result, (i) we derive a sharp threshold for community detection in an inhomogeneous multilayer block model \citep{chen2022global}, (ii) characterize a sharp threshold for weak recovery in a dynamic stochastic block model \citep{matias2017statistical}, and (iii) identify the limiting mutual information in an unbalanced partially labeled block model. Our first two results are derived modulo coordinate-wise convexit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#20805;&#36275;&#32500;&#24230;&#20943;&#23569;&#20013;&#30340;&#38544;&#31169;&#38382;&#39064;&#30340;&#26368;&#20339;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#65292;&#24182;&#22312;&#20302;&#32500;&#21644;&#39640;&#32500;&#35774;&#32622;&#19979;&#24314;&#31435;&#20102;&#19981;&#21516;ially private &#20999;&#29255;&#36870;&#22238;&#24402;&#30340;&#19979;&#30028;&#12290;&#36890;&#36807;&#20223;&#30495;&#21644;&#30495;&#23454;&#25968;&#25454;&#20998;&#26512;&#39564;&#35777;&#20102;&#36825;&#20123;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.08150</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#20999;&#29255;&#36870;&#22238;&#24402;: &#26497;&#23567;&#26497;&#22823;&#24615;&#21644;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Sliced Inverse Regression: Minimax Optimality and Algorithm. (arXiv:2401.08150v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08150
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#20805;&#36275;&#32500;&#24230;&#20943;&#23569;&#20013;&#30340;&#38544;&#31169;&#38382;&#39064;&#30340;&#26368;&#20339;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#65292;&#24182;&#22312;&#20302;&#32500;&#21644;&#39640;&#32500;&#35774;&#32622;&#19979;&#24314;&#31435;&#20102;&#19981;&#21516;ially private &#20999;&#29255;&#36870;&#22238;&#24402;&#30340;&#19979;&#30028;&#12290;&#36890;&#36807;&#20223;&#30495;&#21644;&#30495;&#23454;&#25968;&#25454;&#20998;&#26512;&#39564;&#35777;&#20102;&#36825;&#20123;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#25968;&#25454;&#39537;&#21160;&#24212;&#29992;&#30340;&#26222;&#21450;&#65292;&#38544;&#31169;&#20445;&#25252;&#24050;&#25104;&#20026;&#39640;&#32500;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#12290;&#20999;&#29255;&#36870;&#22238;&#24402;&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#30340;&#32479;&#35745;&#25216;&#26415;&#65292;&#36890;&#36807;&#38477;&#20302;&#21327;&#21464;&#37327;&#30340;&#32500;&#24230;&#65292;&#21516;&#26102;&#20445;&#25345;&#36275;&#22815;&#30340;&#32479;&#35745;&#20449;&#24687;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#20805;&#36275;&#32500;&#24230;&#20943;&#23569;&#20013;&#30340;&#38544;&#31169;&#38382;&#39064;&#30340;&#26368;&#20339;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#12290;&#25105;&#20204;&#22312;&#20302;&#32500;&#21644;&#39640;&#32500;&#35774;&#32622;&#19979;&#24314;&#31435;&#20102;&#19981;&#21516;ially private &#20999;&#29255;&#36870;&#22238;&#24402;&#30340;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#26497;&#23567;&#26497;&#22823;&#19979;&#30028;&#30340;&#35201;&#27714;&#65292;&#24182;&#22312;&#38477;&#32500;&#31354;&#38388;&#20013;&#21516;&#26102;&#20445;&#25252;&#38544;&#31169;&#21644;&#20445;&#23384;&#37325;&#35201;&#20449;&#24687;&#30340;&#26377;&#25928;&#24615;&#12290;&#36890;&#36807;&#19968;&#31995;&#21015;&#30340;&#20223;&#30495;&#23454;&#39564;&#21644;&#30495;&#23454;&#25968;&#25454;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Privacy preservation has become a critical concern in high-dimensional data analysis due to the growing prevalence of data-driven applications. Proposed by Li (1991), sliced inverse regression has emerged as a widely utilized statistical technique for reducing covariate dimensionality while maintaining sufficient statistical information. In this paper, we propose optimally differentially private algorithms specifically designed to address privacy concerns in the context of sufficient dimension reduction. We proceed to establish lower bounds for differentially private sliced inverse regression in both the low and high-dimensional settings. Moreover, we develop differentially private algorithms that achieve the minimax lower bounds up to logarithmic factors. Through a combination of simulations and real data analysis, we illustrate the efficacy of these differentially private algorithms in safeguarding privacy while preserving vital information within the reduced dimension space. As a na
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20855;&#26377;&#38454;&#27573;&#32422;&#26463;&#30340;&#19978;&#19979;&#25991;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#19978;&#38480;&#32622;&#20449;&#21306;&#38388;&#30340;&#31639;&#27861;&#21644;&#30456;&#24212;&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;&#36890;&#36807;&#20351;&#29992;&#19981;&#21516;&#30340;&#32553;&#25918;&#22240;&#23376;&#26469;&#24179;&#34913;&#25506;&#32034;&#21644;&#32422;&#26463;&#28385;&#36275;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#20197;&#36866;&#24212;&#39640;&#27010;&#29575;&#21644;&#26399;&#26395;&#35774;&#32622;&#65292;&#24182;&#22312;&#22810;&#20010;&#32422;&#26463;&#24773;&#20917;&#19979;&#24471;&#21040;&#20102;&#25193;&#23637;&#12290;</title><link>http://arxiv.org/abs/2401.08016</link><description>&lt;p&gt;
&#20855;&#26377;&#38454;&#27573;&#32422;&#26463;&#30340;&#19978;&#19979;&#25991;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
Contextual Bandits with Stage-wise Constraints. (arXiv:2401.08016v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08016
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20855;&#26377;&#38454;&#27573;&#32422;&#26463;&#30340;&#19978;&#19979;&#25991;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#19978;&#38480;&#32622;&#20449;&#21306;&#38388;&#30340;&#31639;&#27861;&#21644;&#30456;&#24212;&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;&#36890;&#36807;&#20351;&#29992;&#19981;&#21516;&#30340;&#32553;&#25918;&#22240;&#23376;&#26469;&#24179;&#34913;&#25506;&#32034;&#21644;&#32422;&#26463;&#28385;&#36275;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#20197;&#36866;&#24212;&#39640;&#27010;&#29575;&#21644;&#26399;&#26395;&#35774;&#32622;&#65292;&#24182;&#22312;&#22810;&#20010;&#32422;&#26463;&#24773;&#20917;&#19979;&#24471;&#21040;&#20102;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#32422;&#26463;&#38382;&#39064;&#24517;&#39035;&#28385;&#36275;&#39640;&#27010;&#29575;&#21644;&#26399;&#26395;&#26102;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19978;&#19979;&#25991;&#36172;&#21338;&#26426;&#22312;&#38454;&#27573;&#32422;&#26463;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#30340;&#34920;&#29616;&#12290;&#26174;&#28982;&#65292;&#26399;&#26395;&#32422;&#26463;&#30340;&#35774;&#23450;&#26159;&#23545;&#39640;&#27010;&#29575;&#32422;&#26463;&#30340;&#25918;&#23485;&#12290;&#25105;&#20204;&#39318;&#20808;&#20174;&#32447;&#24615;&#24773;&#20917;&#24320;&#22987;&#65292;&#20854;&#20013;&#19978;&#19979;&#25991;&#36172;&#21338;&#26426;&#38382;&#39064;&#65288;&#22870;&#21169;&#20989;&#25968;&#65289;&#21644;&#38454;&#27573;&#32422;&#26463;&#65288;&#25104;&#26412;&#20989;&#25968;&#65289;&#37117;&#26159;&#32447;&#24615;&#30340;&#12290;&#22312;&#39640;&#27010;&#29575;&#21644;&#26399;&#26395;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#19978;&#38480;&#32622;&#20449;&#21306;&#38388;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#27492;&#38382;&#39064;&#30340;T&#36718;&#36951;&#25022;&#19978;&#30028;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20351;&#29992;&#19968;&#31181;&#26032;&#30340;&#24605;&#24819;&#26469;&#24179;&#34913;&#25506;&#32034;&#21644;&#32422;&#26463;&#28385;&#36275;&#65292;&#36890;&#36807;&#19981;&#21516;&#30340;&#32553;&#25918;&#22240;&#23376;&#32553;&#25918;&#22870;&#21169;&#21644;&#25104;&#26412;&#32622;&#20449;&#21306;&#38388;&#30340;&#21322;&#24452;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#35813;&#32422;&#26463;&#38382;&#39064;&#30340;&#19979;&#30028;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#21644;&#20998;&#26512;&#22914;&#20309;&#25193;&#23637;&#21040;&#22810;&#20010;&#32422;&#26463;&#65292;&#24182;&#25552;&#20379;&#20102;&#27169;&#25311;&#23454;&#39564;&#26469;&#39564;&#35777;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study contextual bandits in the presence of a stage-wise constraint (a constraint at each round), when the constraint must be satisfied both with high probability and in expectation. Obviously the setting where the constraint is in expectation is a relaxation of the one with high probability. We start with the linear case where both the contextual bandit problem (reward function) and the stage-wise constraint (cost function) are linear. In each of the high probability and in expectation settings, we propose an upper-confidence bound algorithm for the problem and prove a $T$-round regret bound for it. Our algorithms balance exploration and constraint satisfaction using a novel idea that scales the radii of the reward and cost confidence sets with different scaling factors. We also prove a lower-bound for this constrained problem, show how our algorithms and analyses can be extended to multiple constraints, and provide simulations to validate our theoretical results. In the high proba
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#23558;&#27010;&#29575;Lambert&#38382;&#39064;&#19982;&#26368;&#20248;&#36136;&#37327;&#20256;&#36755;&#12289;Schr\"odinger&#26725;&#21644;&#21453;&#24212;-&#25193;&#25955;&#20559;&#24494;&#20998;&#26041;&#31243;&#31561;&#39046;&#22495;&#36830;&#25509;&#36215;&#26469;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#27010;&#29575;Lambert&#38382;&#39064;&#30340;&#35299;&#30340;&#23384;&#22312;&#21644;&#21807;&#19968;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#25968;&#20540;&#27714;&#35299;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.07961</link><description>&lt;p&gt;
&#27010;&#29575;Lambert&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#26696;&#65306;&#19982;&#26368;&#20248;&#36136;&#37327;&#20256;&#36755;&#12289;Schr\"odinger&#26725;&#21644;&#21453;&#24212;-&#25193;&#25955;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#36830;&#25509;
&lt;/p&gt;
&lt;p&gt;
Solution of the Probabilistic Lambert Problem: Connections with Optimal Mass Transport, Schr\"odinger Bridge and Reaction-Diffusion PDEs. (arXiv:2401.07961v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.07961
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#23558;&#27010;&#29575;Lambert&#38382;&#39064;&#19982;&#26368;&#20248;&#36136;&#37327;&#20256;&#36755;&#12289;Schr\"odinger&#26725;&#21644;&#21453;&#24212;-&#25193;&#25955;&#20559;&#24494;&#20998;&#26041;&#31243;&#31561;&#39046;&#22495;&#36830;&#25509;&#36215;&#26469;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#27010;&#29575;Lambert&#38382;&#39064;&#30340;&#35299;&#30340;&#23384;&#22312;&#21644;&#21807;&#19968;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#25968;&#20540;&#27714;&#35299;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Lambert&#38382;&#39064;&#28041;&#21450;&#36890;&#36807;&#36895;&#24230;&#25511;&#21046;&#22312;&#35268;&#23450;&#30340;&#39134;&#34892;&#26102;&#38388;&#20869;&#23558;&#33322;&#22825;&#22120;&#20174;&#32473;&#23450;&#30340;&#21021;&#22987;&#20301;&#32622;&#36716;&#31227;&#21040;&#32473;&#23450;&#30340;&#32456;&#31471;&#20301;&#32622;&#65292;&#21463;&#21040;&#37325;&#21147;&#21147;&#22330;&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;Lambert&#38382;&#39064;&#30340;&#27010;&#29575;&#21464;&#31181;&#65292;&#20854;&#20013;&#20301;&#32622;&#21521;&#37327;&#30340;&#31471;&#28857;&#32422;&#26463;&#30340;&#30693;&#35782;&#34987;&#23427;&#20204;&#21508;&#33258;&#30340;&#32852;&#21512;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#25152;&#26367;&#20195;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20855;&#26377;&#31471;&#28857;&#32852;&#21512;&#27010;&#29575;&#23494;&#24230;&#32422;&#26463;&#30340;Lambert&#38382;&#39064;&#26159;&#19968;&#20010;&#24191;&#20041;&#30340;&#26368;&#20248;&#36136;&#37327;&#20256;&#36755;&#65288;OMT&#65289;&#38382;&#39064;&#65292;&#20174;&#32780;&#23558;&#36825;&#20010;&#32463;&#20856;&#30340;&#22825;&#20307;&#21160;&#21147;&#23398;&#38382;&#39064;&#19982;&#29616;&#20195;&#38543;&#26426;&#25511;&#21046;&#21644;&#38543;&#26426;&#26426;&#22120;&#23398;&#20064;&#30340;&#26032;&#20852;&#30740;&#31350;&#39046;&#22495;&#32852;&#31995;&#36215;&#26469;&#12290;&#36825;&#20010;&#26032;&#21457;&#29616;&#30340;&#36830;&#25509;&#20351;&#25105;&#20204;&#33021;&#22815;&#20005;&#26684;&#24314;&#31435;&#27010;&#29575;Lambert&#38382;&#39064;&#30340;&#35299;&#30340;&#23384;&#22312;&#24615;&#21644;&#21807;&#19968;&#24615;&#12290;&#21516;&#26679;&#30340;&#36830;&#25509;&#36824;&#24110;&#21161;&#36890;&#36807;&#25193;&#25955;&#27491;&#35268;&#21270;&#25968;&#20540;&#27714;&#35299;&#27010;&#29575;Lambert&#38382;&#39064;&#65292;&#21363;&#36890;&#36807;&#36827;&#19968;&#27493;&#30340;&#36830;&#25509;&#26469;&#21033;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Lambert's problem concerns with transferring a spacecraft from a given initial to a given terminal position within prescribed flight time via velocity control subject to a gravitational force field. We consider a probabilistic variant of the Lambert problem where the knowledge of the endpoint constraints in position vectors are replaced by the knowledge of their respective joint probability density functions. We show that the Lambert problem with endpoint joint probability density constraints is a generalized optimal mass transport (OMT) problem, thereby connecting this classical astrodynamics problem with a burgeoning area of research in modern stochastic control and stochastic machine learning. This newfound connection allows us to rigorously establish the existence and uniqueness of solution for the probabilistic Lambert problem. The same connection also helps to numerically solve the probabilistic Lambert problem via diffusion regularization, i.e., by leveraging further connection 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#26500;&#24314;&#36866;&#24212;&#24615;&#20132;&#21449;&#22343;&#21248;&#39044;&#27979;&#21306;&#38388;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#20808;&#39564;&#36866;&#21512;&#24230;&#19981;&#24688;&#24403;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#25152;&#24471;&#21040;&#30340;&#39044;&#27979;&#21306;&#38388;&#20855;&#26377;&#36125;&#21494;&#26031;&#21487;&#20449;&#24230;&#38598;&#30340;&#33258;&#36866;&#24212;&#24615;&#21644;&#19982;&#20195;&#29702;&#27169;&#22411;&#30340;&#23616;&#37096;&#36924;&#36817;&#35823;&#24046;&#30340;&#30456;&#20851;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.07733</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#26367;&#20195;&#35780;&#20272;&#30340;&#36866;&#24212;&#24615;&#22343;&#21248;&#39044;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Conformal Approach To Gaussian Process Surrogate Evaluation With Coverage Guarantees. (arXiv:2401.07733v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.07733
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#26500;&#24314;&#36866;&#24212;&#24615;&#20132;&#21449;&#22343;&#21248;&#39044;&#27979;&#21306;&#38388;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#20808;&#39564;&#36866;&#21512;&#24230;&#19981;&#24688;&#24403;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#25152;&#24471;&#21040;&#30340;&#39044;&#27979;&#21306;&#38388;&#20855;&#26377;&#36125;&#21494;&#26031;&#21487;&#20449;&#24230;&#38598;&#30340;&#33258;&#36866;&#24212;&#24615;&#21644;&#19982;&#20195;&#29702;&#27169;&#22411;&#30340;&#23616;&#37096;&#36924;&#36817;&#35823;&#24046;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#24191;&#27867;&#24212;&#29992;&#20110;&#26500;&#24314;&#24037;&#19994;&#24212;&#29992;&#20013;&#35745;&#31639;&#26426;&#27169;&#25311;&#20195;&#30721;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#20195;&#29702;&#27169;&#22411;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36866;&#24212;&#24615;&#20132;&#21449;&#22343;&#21248;&#39044;&#27979;&#21306;&#38388;&#26500;&#24314;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#38750;&#19968;&#33268;&#24615;&#24471;&#20998;&#19982;&#39640;&#26031;&#36807;&#31243;&#30340;&#21518;&#39564;&#26631;&#20934;&#24046;&#21152;&#26435;&#65292;&#35299;&#20915;&#20102;&#20808;&#39564;&#36866;&#21512;&#24230;&#19981;&#24688;&#24403;&#30340;&#38382;&#39064;&#12290;&#24471;&#21040;&#30340;&#22343;&#21248;&#39044;&#27979;&#21306;&#38388;&#34920;&#29616;&#20986;&#31867;&#20284;&#20110;&#36125;&#21494;&#26031;&#21487;&#20449;&#24230;&#38598;&#30340;&#33258;&#36866;&#24212;&#27700;&#24179;&#65292;&#24182;&#19988;&#19982;&#20195;&#29702;&#27169;&#22411;&#30340;&#23616;&#37096;&#36924;&#36817;&#35823;&#24046;&#20855;&#26377;&#26174;&#33879;&#30456;&#20851;&#24615;&#65292;&#21516;&#26102;&#19981;&#21463;&#20248;&#21270;&#38382;&#39064;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian processes (GPs) are a Bayesian machine learning approach widely used to construct surrogate models for the uncertainty quantification of computer simulation codes in industrial applications. It provides both a mean predictor and an estimate of the posterior prediction variance, the latter being used to produce Bayesian credibility intervals. Interpreting these intervals relies on the Gaussianity of the simulation model as well as the well-specification of the priors which are not always appropriate. We propose to address this issue with the help of conformal prediction. In the present work, a method for building adaptive cross-conformal prediction intervals is proposed by weighting the non-conformity score with the posterior standard deviation of the GP. The resulting conformal prediction intervals exhibit a level of adaptivity akin to Bayesian credibility sets and display a significant correlation with the surrogate model local approximation error, while being free from the u
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102; ENTED&#65292;&#19968;&#20010;&#36866;&#29992;&#20110;&#20108;&#20803;&#21644;&#35745;&#25968;&#24352;&#37327;&#30340;&#39640;&#25928;&#38750;&#21442;&#25968;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#38750;&#21442;&#25968;&#39640;&#26031;&#36807;&#31243;&#26469;&#26367;&#20195;&#20256;&#32479;&#30340;&#22810;&#32447;&#24615;&#32467;&#26500;&#65292;&#24182;&#21033;&#29992;&#22686;&#24378;&#25216;&#26415;&#24314;&#31435;&#20849;&#36717;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#22788;&#29702;&#22797;&#26434;&#23454;&#38469;&#25968;&#25454;&#38598;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.07711</link><description>&lt;p&gt;
&#36866;&#29992;&#20110;&#20108;&#20803;&#21644;&#35745;&#25968;&#25968;&#25454;&#30340;&#39640;&#25928;&#38750;&#21442;&#25968;&#24352;&#37327;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
Efficient Nonparametric Tensor Decomposition for Binary and Count Data. (arXiv:2401.07711v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.07711
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102; ENTED&#65292;&#19968;&#20010;&#36866;&#29992;&#20110;&#20108;&#20803;&#21644;&#35745;&#25968;&#24352;&#37327;&#30340;&#39640;&#25928;&#38750;&#21442;&#25968;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#38750;&#21442;&#25968;&#39640;&#26031;&#36807;&#31243;&#26469;&#26367;&#20195;&#20256;&#32479;&#30340;&#22810;&#32447;&#24615;&#32467;&#26500;&#65292;&#24182;&#21033;&#29992;&#22686;&#24378;&#25216;&#26415;&#24314;&#31435;&#20849;&#36717;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#22788;&#29702;&#22797;&#26434;&#23454;&#38469;&#25968;&#25454;&#38598;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#35266;&#23519;&#21644;&#23384;&#20648;&#20108;&#20803;&#21453;&#24212;&#25110;&#20107;&#20214;&#35745;&#25968;&#30340;&#25968;&#25454;&#20197;&#21450;&#39640;&#38454;&#24352;&#37327;&#12290;&#24352;&#37327;&#20998;&#35299;&#65288;TD&#65289;&#26159;&#22788;&#29702;&#36825;&#31181;&#39640;&#32500;&#31232;&#30095;&#25968;&#25454;&#30340;&#24378;&#21147;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#20256;&#32479;&#30340;TD&#37117;&#26159;&#22522;&#20110;&#39640;&#26031;&#20998;&#24067;&#26126;&#30830;&#25110;&#38544;&#24335;&#35774;&#35745;&#30340;&#65292;&#23545;&#20110;&#31163;&#25955;&#25968;&#25454;&#26159;&#19981;&#21512;&#36866;&#30340;&#12290;&#27492;&#22806;&#65292;&#22823;&#22810;&#25968;TD&#20381;&#36182;&#20110;&#39044;&#23450;&#20041;&#30340;&#22810;&#32447;&#24615;&#32467;&#26500;&#65292;&#22914;CP&#21644;Tucker&#26684;&#24335;&#12290;&#22240;&#27492;&#65292;&#23427;&#20204;&#21487;&#33021;&#19981;&#36275;&#20197;&#22788;&#29702;&#22797;&#26434;&#30340;&#29616;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;ENTED&#65292;&#19968;&#20010;&#36866;&#29992;&#20110;&#20108;&#20803;&#21644;&#35745;&#25968;&#24352;&#37327;&#30340;\textbf{&#39640;&#25928;&#38750;&#21442;&#25968;&#24352;&#37327;&#20998;&#35299;}&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#37319;&#29992;&#20102;&#38750;&#21442;&#25968;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#26469;&#26367;&#20195;&#20256;&#32479;&#30340;&#22810;&#32447;&#24615;&#32467;&#26500;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#21033;&#29992;&#20102;\pg&#22686;&#24378;&#65292;&#20026;&#20108;&#20803;&#21644;&#35745;&#25968;&#20998;&#24067;&#24314;&#31435;&#20849;&#36717;&#27169;&#22411;&#25552;&#20379;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#12290;&#26368;&#21518;&#65292;&#20026;&#20102;&#35299;&#20915;&#35745;&#31639;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
In numerous applications, binary reactions or event counts are observed and stored within high-order tensors. Tensor decompositions (TDs) serve as a powerful tool to handle such high-dimensional and sparse data. However, many traditional TDs are explicitly or implicitly designed based on the Gaussian distribution, which is unsuitable for discrete data. Moreover, most TDs rely on predefined multi-linear structures, such as CP and Tucker formats. Therefore, they may not be effective enough to handle complex real-world datasets. To address these issues, we propose ENTED, an \underline{E}fficient \underline{N}onparametric \underline{TE}nsor \underline{D}ecomposition for binary and count tensors. Specifically, we first employ a nonparametric Gaussian process (GP) to replace traditional multi-linear structures. Next, we utilize the \pg augmentation which provides a unified framework to establish conjugate models for binary and count distributions. Finally, to address the computational issue 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#38750;&#20984;&#12289;&#21487;&#33021;&#19981;&#20809;&#28369;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#22312;&#19968;&#33324;&#30340;&#32463;&#24120;&#24615;&#25277;&#26679;&#26041;&#26696;&#19979;&#65292;&#21487;&#20197;&#20197;&#26368;&#20339;&#36895;&#29575;&#25910;&#25947;&#65307;&#21516;&#26102;&#25351;&#20986;&#20102;&#25910;&#25947;&#36895;&#24230;&#19982;"&#32463;&#24120;&#24615;&#30340;&#36895;&#24230;"&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2401.07694</link><description>&lt;p&gt;
&#20855;&#26377;&#20219;&#24847;&#32463;&#24120;&#24615;&#25968;&#25454;&#25277;&#26679;&#30340;&#38543;&#26426;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Stochastic optimization with arbitrary recurrent data sampling. (arXiv:2401.07694v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.07694
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#38750;&#20984;&#12289;&#21487;&#33021;&#19981;&#20809;&#28369;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#22312;&#19968;&#33324;&#30340;&#32463;&#24120;&#24615;&#25277;&#26679;&#26041;&#26696;&#19979;&#65292;&#21487;&#20197;&#20197;&#26368;&#20339;&#36895;&#29575;&#25910;&#25947;&#65307;&#21516;&#26102;&#25351;&#20986;&#20102;&#25910;&#25947;&#36895;&#24230;&#19982;"&#32463;&#24120;&#24615;&#30340;&#36895;&#24230;"&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#33719;&#24471;&#38543;&#26426;&#20248;&#21270;&#30340;&#26368;&#20339;&#19968;&#38454;&#25910;&#25947;&#20445;&#35777;&#65292;&#38656;&#35201;&#20351;&#29992;&#19968;&#20010;&#32463;&#24120;&#24615;&#25968;&#25454;&#25277;&#26679;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20197;&#36275;&#22815;&#30340;&#39057;&#29575;&#23545;&#27599;&#20010;&#25968;&#25454;&#28857;&#36827;&#34892;&#25277;&#26679;&#12290;&#22823;&#22810;&#25968;&#24120;&#29992;&#30340;&#25968;&#25454;&#25277;&#26679;&#31639;&#27861;&#65288;&#22914;i.i.d.&#65292;MCMC&#65292;&#38543;&#26426;&#37325;&#25490;&#65289;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#30830;&#23454;&#26159;&#32463;&#24120;&#24615;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#34920;&#26126;&#23545;&#20110;&#19968;&#31867;&#29305;&#27530;&#30340;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#25105;&#20204;&#26080;&#38656;&#38500;&#20102;&#25968;&#25454;&#25277;&#26679;&#31639;&#27861;&#20013;&#30340;&#32463;&#24120;&#24615;&#20043;&#22806;&#30340;&#20219;&#20309;&#20854;&#20182;&#23646;&#24615;&#65288;&#22914;&#29420;&#31435;&#24615;&#65292;&#25351;&#25968;&#28151;&#21512;&#21644;&#37325;&#25490;&#65289;&#26469;&#20445;&#35777;&#26368;&#20339;&#30340;&#19968;&#38454;&#25910;&#25947;&#36895;&#29575;&#12290;&#20063;&#23601;&#26159;&#35828;&#65292;&#20351;&#29992;Minimization by Incremental Surrogate Optimization (MISO)&#30340;&#27491;&#21017;&#21270;&#29256;&#26412;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#38750;&#20984;&#30340;&#12289;&#21487;&#33021;&#19981;&#20809;&#28369;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#26399;&#26395;&#30340;&#26368;&#20248;&#24615;&#24046;&#24322;&#22312;&#19968;&#33324;&#30340;&#32463;&#24120;&#24615;&#25277;&#26679;&#26041;&#26696;&#19979;&#25910;&#25947;&#20110;&#26368;&#20339;&#36895;&#29575;$O(n^{-1/2})$&#12290;&#27492;&#22806;&#65292;&#26263;&#31034;&#30340;&#24120;&#25968;&#26126;&#30830;&#21462;&#20915;&#20110;"&#32463;&#24120;&#24615;&#30340;&#36895;&#24230;"&#65292;&#30001;&#25351;&#25968;&#27979;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
For obtaining optimal first-order convergence guarantee for stochastic optimization, it is necessary to use a recurrent data sampling algorithm that samples every data point with sufficient frequency. Most commonly used data sampling algorithms (e.g., i.i.d., MCMC, random reshuffling) are indeed recurrent under mild assumptions. In this work, we show that for a particular class of stochastic optimization algorithms, we do not need any other property (e.g., independence, exponential mixing, and reshuffling) than recurrence in data sampling algorithms to guarantee the optimal rate of first-order convergence. Namely, using regularized versions of Minimization by Incremental Surrogate Optimization (MISO), we show that for non-convex and possibly non-smooth objective functions, the expected optimality gap converges at an optimal rate $O(n^{-1/2})$ under general recurrent sampling schemes. Furthermore, the implied constant depends explicitly on the `speed of recurrence', measured by the expe
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#25903;&#25345;&#21521;&#37327;&#26426;&#30340;&#25104;&#26412;&#25935;&#24863;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#25152;&#36873;&#29305;&#24449;&#30340;&#25968;&#37327;&#26469;&#36866;&#24212;&#35823;&#20998;&#31867;&#25104;&#26412;&#30340;&#19981;&#23545;&#31216;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.07627</link><description>&lt;p&gt;
&#38024;&#23545;&#25903;&#25345;&#21521;&#37327;&#26426;&#30340;&#25104;&#26412;&#25935;&#24863;&#29305;&#24449;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Cost-sensitive Feature Selection for Support Vector Machines. (arXiv:2401.07627v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.07627
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#25903;&#25345;&#21521;&#37327;&#26426;&#30340;&#25104;&#26412;&#25935;&#24863;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#25152;&#36873;&#29305;&#24449;&#30340;&#25968;&#37327;&#26469;&#36866;&#24212;&#35823;&#20998;&#31867;&#25104;&#26412;&#30340;&#19981;&#23545;&#31216;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#36873;&#25321;&#26159;&#25968;&#25454;&#31185;&#23398;&#20219;&#21153;&#65288;&#22914;&#20998;&#31867;&#65289;&#20013;&#30340;&#20851;&#38190;&#27493;&#39588;&#65292;&#23427;&#21487;&#20197;&#35782;&#21035;&#30456;&#20851;&#21464;&#37327;&#65292;&#20351;&#20998;&#31867;&#36807;&#31243;&#26356;&#20855;&#35299;&#37322;&#24615;&#65292;&#26356;&#30465;&#25104;&#26412;&#65288;&#27979;&#37327;&#26041;&#38754;&#65289;&#65292;&#36890;&#36807;&#20943;&#23569;&#22122;&#22768;&#21644;&#25968;&#25454;&#36807;&#25311;&#21512;&#32780;&#26356;&#26377;&#25928;&#12290;&#29305;&#24449;&#22312;&#20998;&#31867;&#36807;&#31243;&#20013;&#30340;&#30456;&#20851;&#24615;&#19982;&#35823;&#20998;&#31867;&#25104;&#26412;&#30340;&#19981;&#23545;&#31216;&#24615;&#26377;&#20851;&#65292;&#22240;&#20026;&#20551;&#38451;&#24615;&#21644;&#20551;&#38452;&#24615;&#24773;&#20917;&#21487;&#33021;&#20855;&#26377;&#38750;&#24120;&#19981;&#21516;&#30340;&#21518;&#26524;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#24456;&#23569;&#32771;&#34385;&#21040;&#36825;&#31181;&#35823;&#24046;&#30340;&#25104;&#26412;&#25935;&#24863;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#23398;&#20248;&#21270;&#30340;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#23884;&#20837;&#21040;&#20854;&#20013;&#19968;&#20010;&#26368;&#24120;&#29992;&#30340;&#20998;&#31867;&#26041;&#27861;&#8212;&#8212;&#25903;&#25345;&#21521;&#37327;&#26426;&#20013;&#65292;&#20197;&#36866;&#24212;&#35823;&#20998;&#31867;&#25104;&#26412;&#30340;&#19981;&#23545;&#31216;&#24615;&#12290;&#20854;&#20851;&#38190;&#24605;&#24819;&#26159;&#36890;&#36807;&#26368;&#23567;&#21270;&#25152;&#36873;&#29305;&#24449;&#30340;&#25968;&#37327;&#26469;&#21462;&#20195;&#20256;&#32479;&#30340;&#36793;&#30028;&#26368;&#22823;&#21270;&#65292;&#24182;&#23545;&#20551;&#38451;&#24615;&#35774;&#32622;&#19978;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Feature Selection is a crucial procedure in Data Science tasks such as Classification, since it identifies the relevant variables, making thus the classification procedures more interpretable, cheaper in terms of measurement and more effective by reducing noise and data overfit. The relevance of features in a classification procedure is linked to the fact that misclassifications costs are frequently asymmetric, since false positive and false negative cases may have very different consequences. However, off-the-shelf Feature Selection procedures seldom take into account such cost-sensitivity of errors.  In this paper we propose a mathematical-optimization-based Feature Selection procedure embedded in one of the most popular classification procedures, namely, Support Vector Machines, accommodating asymmetric misclassification costs. The key idea is to replace the traditional margin maximization by minimizing the number of features selected, but imposing upper bounds on the false positive
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;RedEx&#30340;&#26032;&#26550;&#26500;&#65292;&#36890;&#36807;&#20984;&#20248;&#21270;&#26041;&#27861;&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#26080;&#27861;&#23398;&#20064;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#20855;&#26377;&#20248;&#21270;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2401.07606</link><description>&lt;p&gt;
RedEx: &#36890;&#36807;&#20984;&#20248;&#21270;&#26041;&#27861;&#36229;&#36234;&#22266;&#23450;&#34920;&#31034;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
RedEx: Beyond Fixed Representation Methods via Convex Optimization. (arXiv:2401.07606v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.07606
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;RedEx&#30340;&#26032;&#26550;&#26500;&#65292;&#36890;&#36807;&#20984;&#20248;&#21270;&#26041;&#27861;&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#26080;&#27861;&#23398;&#20064;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#20855;&#26377;&#20248;&#21270;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20248;&#21270;&#31070;&#32463;&#32593;&#32476;&#26159;&#19968;&#20010;&#38590;&#20197;&#29702;&#35299;&#30340;&#22256;&#38590;&#20219;&#21153;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#22266;&#23450;&#34920;&#31034;&#26041;&#27861;&#22914;&#26680;&#20989;&#25968;&#21644;&#38543;&#26426;&#29305;&#24449;&#20855;&#26377;&#21487;&#35777;&#26126;&#30340;&#20248;&#21270;&#20445;&#35777;&#65292;&#20294;&#30001;&#20110;&#20854;&#22266;&#26377;&#30340;&#26080;&#27861;&#23398;&#20064;&#34920;&#31034;&#30340;&#33021;&#21147;&#32780;&#34920;&#29616;&#36739;&#24046;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#26550;&#26500;RedEx&#65288;Reduced Expander Extractor&#65289;&#65292;&#26469;&#24357;&#21512;&#36825;&#19968;&#24046;&#36317;&#12290;RedEx&#20855;&#26377;&#19982;&#31070;&#32463;&#32593;&#32476;&#19968;&#26679;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#19968;&#20010;&#24102;&#26377;&#21322;&#27491;&#23450;&#32422;&#26463;&#21644;&#20248;&#21270;&#20445;&#35777;&#30340;&#20984;&#31243;&#24207;&#25353;&#23618;&#27425;&#36827;&#34892;&#35757;&#32451;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;RedEx&#21487;&#20197;&#26377;&#25928;&#22320;&#23398;&#20064;&#22266;&#23450;&#34920;&#31034;&#26041;&#27861;&#26080;&#27861;&#23398;&#20064;&#30340;&#19968;&#31867;&#30446;&#26631;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Optimizing Neural networks is a difficult task which is still not well understood. On the other hand, fixed representation methods such as kernels and random features have provable optimization guarantees but inferior performance due to their inherent inability to learn the representations. In this paper, we aim at bridging this gap by presenting a novel architecture called RedEx (Reduced Expander Extractor) that is as expressive as neural networks and can also be trained in a layer-wise fashion via a convex program with semi-definite constraints and optimization guarantees. We also show that RedEx provably surpasses fixed representation methods, in the sense that it can efficiently learn a family of target functions which fixed representation methods cannot.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#26694;&#26550;&#26469;&#35299;&#20915;&#24191;&#20041;&#20302;&#31209;&#30697;&#38453;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#65292;&#22312;&#35745;&#31639;&#21644;&#29702;&#35770;&#19978;&#20811;&#26381;&#20102;&#29616;&#26377;&#31639;&#27861;&#30340;&#38480;&#21046;&#65292;&#36890;&#36807;&#20351;&#29992;Stein&#30340;&#26041;&#27861;&#21644;&#27491;&#21017;&#21270;&#24605;&#24819;&#23545;&#23376;&#31354;&#38388;&#36827;&#34892;&#20272;&#35745;&#65292;&#20197;&#21450;&#36890;&#36807;&#19968;&#31181;&#26032;&#30340;&#25490;&#38500;&#24605;&#24819;&#36827;&#19968;&#27493;&#25552;&#39640;&#20102;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2401.07298</link><description>&lt;p&gt;
&#24191;&#20041;&#20302;&#31209;&#30697;&#38453;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#30340;&#39640;&#25928;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Efficient Frameworks for Generalized Low-Rank Matrix Bandit Problems. (arXiv:2401.07298v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.07298
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#26694;&#26550;&#26469;&#35299;&#20915;&#24191;&#20041;&#20302;&#31209;&#30697;&#38453;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#65292;&#22312;&#35745;&#31639;&#21644;&#29702;&#35770;&#19978;&#20811;&#26381;&#20102;&#29616;&#26377;&#31639;&#27861;&#30340;&#38480;&#21046;&#65292;&#36890;&#36807;&#20351;&#29992;Stein&#30340;&#26041;&#27861;&#21644;&#27491;&#21017;&#21270;&#24605;&#24819;&#23545;&#23376;&#31354;&#38388;&#36827;&#34892;&#20272;&#35745;&#65292;&#20197;&#21450;&#36890;&#36807;&#19968;&#31181;&#26032;&#30340;&#25490;&#38500;&#24605;&#24819;&#36827;&#19968;&#27493;&#25552;&#39640;&#20102;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#38543;&#26426;&#32972;&#26223;&#19979;&#30340;&#20302;&#31209;&#30697;&#38453;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#20013;&#65292;&#19968;&#20010;&#21160;&#20316;&#30340;&#26399;&#26395;&#22238;&#25253;&#30001;&#35813;&#21160;&#20316;&#30340;&#29305;&#24449;&#30697;&#38453;&#19982;&#26576;&#20010;&#22266;&#23450;&#20294;&#26368;&#21021;&#26410;&#30693;&#30340;$d_1 \times d_2$&#31209;&#20026;$r \ll \{d_1, d_2\}$&#30340;&#30697;&#38453;$\Theta^*$&#30340;&#20869;&#31215;&#32473;&#20986;&#65292;&#20195;&#29702;&#26681;&#25454;&#36807;&#21435;&#30340;&#32463;&#39564;&#39034;&#24207;&#37319;&#21462;&#21160;&#20316;&#20197;&#26368;&#22823;&#21270;&#32047;&#31215;&#22238;&#25253;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#36817;&#22312;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65288;GLM&#65289;&#26694;&#26550;&#19979;&#25552;&#20986;&#30340;&#24191;&#20041;&#20302;&#31209;&#30697;&#38453;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#12290;&#20026;&#20102;&#20811;&#26381;&#29616;&#26377;&#31639;&#27861;&#22312;&#35813;&#38382;&#39064;&#19978;&#30340;&#35745;&#31639;&#19981;&#21487;&#34892;&#24615;&#21644;&#29702;&#35770;&#38480;&#21046;&#65292;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;G-ESTT&#26694;&#26550;&#65292;&#36890;&#36807;&#22312;&#23376;&#31354;&#38388;&#20272;&#35745;&#19978;&#20351;&#29992;Stein&#30340;&#26041;&#27861;&#24182;&#36890;&#36807;&#27491;&#21017;&#21270;&#24605;&#24819;&#21033;&#29992;&#20272;&#35745;&#30340;&#23376;&#31354;&#38388;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#20272;&#35745;&#30340;&#23376;&#31354;&#38388;&#19978;&#20351;&#29992;&#19968;&#31181;&#26032;&#30340;&#25490;&#38500;&#24605;&#24819;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;G-ESTT&#30340;&#25928;&#29575;&#65292;&#24182;&#25552;&#20986;&#20102;...
&lt;/p&gt;
&lt;p&gt;
In the stochastic contextual low-rank matrix bandit problem, the expected reward of an action is given by the inner product between the action's feature matrix and some fixed, but initially unknown $d_1$ by $d_2$ matrix $\Theta^*$ with rank $r \ll \{d_1, d_2\}$, and an agent sequentially takes actions based on past experience to maximize the cumulative reward. In this paper, we study the generalized low-rank matrix bandit problem, which has been recently proposed in \cite{lu2021low} under the Generalized Linear Model (GLM) framework. To overcome the computational infeasibility and theoretical restrain of existing algorithms on this problem, we first propose the G-ESTT framework that modifies the idea from \cite{jun2019bilinear} by using Stein's method on the subspace estimation and then leverage the estimated subspaces via a regularization idea. Furthermore, we remarkably improve the efficiency of G-ESTT by using a novel exclusion idea on the estimated subspace instead, and propose the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#29992;&#20110;&#20855;&#26377;&#26410;&#35266;&#27979;&#21464;&#37327;&#30340;&#22240;&#26524;&#21487;&#21152;&#27169;&#22411;&#65288;CAM-UV&#65289;&#30340;&#26041;&#27861;&#65292;&#24182;&#25193;&#23637;&#20102;&#36825;&#20123;&#26041;&#27861;&#20197;&#24212;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#12290;&#36825;&#20123;&#26041;&#27861;&#21033;&#29992;&#20808;&#39564;&#30693;&#35782;&#36827;&#34892;&#39640;&#25928;&#22240;&#26524;&#21457;&#29616;&#65292;&#24182;&#20855;&#26377;&#23545;&#22240;&#26524;&#20851;&#31995;&#39034;&#24207;&#30340;&#29305;&#27530;&#22788;&#29702;&#12290;</title><link>http://arxiv.org/abs/2401.07231</link><description>&lt;p&gt;
&#21033;&#29992;&#20808;&#39564;&#30693;&#35782;&#21457;&#29616;&#20855;&#26377;&#26410;&#35266;&#27979;&#21464;&#37327;&#30340;&#22240;&#26524;&#21487;&#21152;&#27169;&#22411;&#21450;&#20854;&#22312;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Use of Prior Knowledge to Discover Causal Additive Models with Unobserved Variables and its Application to Time Series Data. (arXiv:2401.07231v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.07231
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#29992;&#20110;&#20855;&#26377;&#26410;&#35266;&#27979;&#21464;&#37327;&#30340;&#22240;&#26524;&#21487;&#21152;&#27169;&#22411;&#65288;CAM-UV&#65289;&#30340;&#26041;&#27861;&#65292;&#24182;&#25193;&#23637;&#20102;&#36825;&#20123;&#26041;&#27861;&#20197;&#24212;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#12290;&#36825;&#20123;&#26041;&#27861;&#21033;&#29992;&#20808;&#39564;&#30693;&#35782;&#36827;&#34892;&#39640;&#25928;&#22240;&#26524;&#21457;&#29616;&#65292;&#24182;&#20855;&#26377;&#23545;&#22240;&#26524;&#20851;&#31995;&#39034;&#24207;&#30340;&#29305;&#27530;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#29992;&#20110;&#20855;&#26377;&#26410;&#35266;&#27979;&#21464;&#37327;&#30340;&#22240;&#26524;&#21487;&#21152;&#27169;&#22411;&#65288;CAM-UV&#65289;&#30340;&#26041;&#27861;&#12290;CAM-UV&#20551;&#35774;&#22240;&#26524;&#20989;&#25968;&#37319;&#29992;&#24191;&#20041;&#21487;&#21152;&#27169;&#22411;&#30340;&#24418;&#24335;&#65292;&#24182;&#23384;&#22312;&#28508;&#22312;&#30340;&#28151;&#28102;&#21464;&#37327;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#20808;&#39564;&#30693;&#35782;&#36827;&#34892;&#39640;&#25928;&#22240;&#26524;&#21457;&#29616;&#30340;&#26041;&#27861;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#36825;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#25512;&#26029;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#22240;&#26524;&#20851;&#31995;&#12290;&#19982;&#20854;&#20182;&#29616;&#26377;&#30340;&#22240;&#26524;&#20989;&#25968;&#27169;&#22411;&#19981;&#21516;&#65292;&#21407;&#22987;&#30340;CAM-UV&#31639;&#27861;&#19981;&#23547;&#27714;&#35266;&#27979;&#21464;&#37327;&#20043;&#38388;&#30340;&#22240;&#26524;&#39034;&#24207;&#65292;&#32780;&#26159;&#26088;&#22312;&#30830;&#23450;&#27599;&#20010;&#35266;&#27979;&#21464;&#37327;&#30340;&#21407;&#22240;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#20013;&#25552;&#20986;&#30340;&#31532;&#19968;&#31181;&#26041;&#27861;&#21033;&#29992;&#20808;&#39564;&#30693;&#35782;&#65292;&#20363;&#22914;&#29702;&#35299;&#26576;&#20123;&#21464;&#37327;&#19981;&#33021;&#25104;&#20026;&#29305;&#23450;&#21464;&#37327;&#30340;&#21407;&#22240;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#34701;&#20837;&#22240;&#26524;&#22312;&#26102;&#38388;&#19978;&#30340;&#20808;&#39564;&#30693;&#35782;&#65292;&#25105;&#20204;&#23558;&#31532;&#19968;&#20010;&#31639;&#27861;&#25193;&#23637;&#20026;&#31532;&#20108;&#31181;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#30340;&#22240;&#26524;&#21457;&#29616;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#39564;&#35777;&#20102;&#31532;&#19968;&#20010;&#25552;&#20986;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes two methods for causal additive models with unobserved variables (CAM-UV). CAM-UV assumes that the causal functions take the form of generalized additive models and that latent confounders are present. First, we propose a method that leverages prior knowledge for efficient causal discovery. Then, we propose an extension of this method for inferring causality in time series data. The original CAM-UV algorithm differs from other existing causal function models in that it does not seek the causal order between observed variables, but rather aims to identify the causes for each observed variable. Therefore, the first proposed method in this paper utilizes prior knowledge, such as understanding that certain variables cannot be causes of specific others. Moreover, by incorporating the prior knowledge that causes precedes their effects in time, we extend the first algorithm to the second method for causal discovery in time series data. We validate the first proposed method
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27010;&#29575;&#38477;&#32500;&#21521;&#37327;&#33258;&#22238;&#24402;&#65288;PredVAR&#65289;&#27169;&#22411;&#65292;&#36890;&#36807;&#26012;&#25237;&#24433;&#26041;&#27861;&#20174;&#39640;&#32500;&#22122;&#22768;&#25968;&#25454;&#20013;&#25552;&#21462;&#20302;&#32500;&#21160;&#24577;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#36845;&#20195;&#30340;&#31639;&#27861;&#26356;&#26032;&#28508;&#22312;&#21160;&#24577;&#21644;&#26368;&#20339;&#26012;&#25237;&#24433;&#30340;&#20272;&#35745;&#65292;&#24471;&#21040;&#20855;&#26377;&#25490;&#24207;&#39044;&#27979;&#33021;&#21147;&#30340;&#21160;&#24577;&#28508;&#21464;&#37327;&#21644;&#19982;&#22806;&#37096;&#25237;&#24433;&#27169;&#22411;&#19968;&#33268;&#30340;&#26174;&#24335;&#28508;&#22312;VAR&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2401.07206</link><description>&lt;p&gt;
&#27010;&#29575;&#38477;&#32500;&#21521;&#37327;&#33258;&#22238;&#24402;&#27169;&#22411;&#21450;&#20854;&#26012;&#25237;&#24433;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Reduced-Dimensional Vector Autoregressive Modeling with Oblique Projections. (arXiv:2401.07206v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.07206
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27010;&#29575;&#38477;&#32500;&#21521;&#37327;&#33258;&#22238;&#24402;&#65288;PredVAR&#65289;&#27169;&#22411;&#65292;&#36890;&#36807;&#26012;&#25237;&#24433;&#26041;&#27861;&#20174;&#39640;&#32500;&#22122;&#22768;&#25968;&#25454;&#20013;&#25552;&#21462;&#20302;&#32500;&#21160;&#24577;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#36845;&#20195;&#30340;&#31639;&#27861;&#26356;&#26032;&#28508;&#22312;&#21160;&#24577;&#21644;&#26368;&#20339;&#26012;&#25237;&#24433;&#30340;&#20272;&#35745;&#65292;&#24471;&#21040;&#20855;&#26377;&#25490;&#24207;&#39044;&#27979;&#33021;&#21147;&#30340;&#21160;&#24577;&#28508;&#21464;&#37327;&#21644;&#19982;&#22806;&#37096;&#25237;&#24433;&#27169;&#22411;&#19968;&#33268;&#30340;&#26174;&#24335;&#28508;&#22312;VAR&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27010;&#29575;&#38477;&#32500;&#21521;&#37327;&#33258;&#22238;&#24402;&#65288;PredVAR&#65289;&#27169;&#22411;&#65292;&#29992;&#20110;&#20174;&#39640;&#32500;&#22122;&#22768;&#25968;&#25454;&#20013;&#25552;&#21462;&#20302;&#32500;&#21160;&#24577;&#20449;&#24687;&#12290;&#35813;&#27169;&#22411;&#37319;&#29992;&#26012;&#25237;&#24433;&#23558;&#27979;&#37327;&#31354;&#38388;&#21010;&#20998;&#20026;&#36866;&#24212;&#38477;&#32500;&#21160;&#24577;&#30340;&#23376;&#31354;&#38388;&#21644;&#34917;&#20805;&#30340;&#38745;&#24577;&#23376;&#31354;&#38388;&#12290;&#36890;&#36807;&#26368;&#20339;&#26012;&#20998;&#35299;&#65292;&#23454;&#29616;&#20102;&#20851;&#20110;&#39044;&#27979;&#35823;&#24046;&#21327;&#26041;&#24046;&#30340;&#26368;&#20339;&#39044;&#27979;&#33021;&#21147;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36845;&#20195;&#30340;PredVAR&#31639;&#27861;&#65292;&#21033;&#29992;&#26368;&#22823;&#20284;&#28982;&#21644;&#26399;&#26395;&#26368;&#22823;&#21270;&#65288;EM&#65289;&#26694;&#26550;&#20132;&#26367;&#26356;&#26032;&#28508;&#22312;&#21160;&#24577;&#21644;&#26368;&#20339;&#26012;&#25237;&#24433;&#30340;&#20272;&#35745;&#65292;&#24471;&#21040;&#20855;&#26377;&#25490;&#24207;&#39044;&#27979;&#33021;&#21147;&#30340;&#21160;&#24577;&#28508;&#21464;&#37327;&#21644;&#19982;&#22806;&#37096;&#25237;&#24433;&#27169;&#22411;&#19968;&#33268;&#30340;&#26174;&#24335;&#28508;&#22312;VAR&#27169;&#22411;&#12290;&#36890;&#36807;&#20351;&#29992;&#21512;&#25104;Lorenz&#31995;&#32479;&#21644;&#24037;&#19994;&#25968;&#25454;&#38598;&#65292;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#21331;&#36234;&#24615;&#33021;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a probabilistic reduced-dimensional vector autoregressive (PredVAR) model to extract low-dimensional dynamics from high-dimensional noisy data. The model utilizes an oblique projection to partition the measurement space into a subspace that accommodates the reduced-dimensional dynamics and a complementary static subspace. An optimal oblique decomposition is derived for the best predictability regarding prediction error covariance. Building on this, we develop an iterative PredVAR algorithm using maximum likelihood and the expectation-maximization (EM) framework. This algorithm alternately updates the estimates of the latent dynamics and optimal oblique projection, yielding dynamic latent variables with rank-ordered predictability and an explicit latent VAR model that is consistent with the outer projection model. The superior performance and efficiency of the proposed approach are demonstrated using data sets from a synthesized Lorenz system and an industrial 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#32508;&#36848;&#20102;&#28145;&#24230;&#23398;&#20064;&#30340;&#32479;&#35745;&#29702;&#35770;&#65292;&#21253;&#25324;&#36817;&#20284;&#26041;&#27861;&#12289;&#35757;&#32451;&#21160;&#24577;&#21644;&#29983;&#25104;&#27169;&#22411;&#12290;&#22312;&#38750;&#21442;&#25968;&#26694;&#26550;&#20013;&#65292;&#32467;&#26524;&#25581;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#36807;&#24230;&#39118;&#38505;&#30340;&#24555;&#36895;&#25910;&#25947;&#36895;&#29575;&#65292;&#20197;&#21450;&#22914;&#20309;&#36890;&#36807;&#26799;&#24230;&#26041;&#27861;&#35757;&#32451;&#32593;&#32476;&#20197;&#25214;&#21040;&#33391;&#22909;&#30340;&#27867;&#21270;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2401.07187</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#32479;&#35745;&#29702;&#35770;&#32508;&#36848;&#65306;&#36817;&#20284;&#65292;&#35757;&#32451;&#21160;&#24577;&#21644;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Survey on Statistical Theory of Deep Learning: Approximation, Training Dynamics, and Generative Models. (arXiv:2401.07187v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.07187
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#32508;&#36848;&#20102;&#28145;&#24230;&#23398;&#20064;&#30340;&#32479;&#35745;&#29702;&#35770;&#65292;&#21253;&#25324;&#36817;&#20284;&#26041;&#27861;&#12289;&#35757;&#32451;&#21160;&#24577;&#21644;&#29983;&#25104;&#27169;&#22411;&#12290;&#22312;&#38750;&#21442;&#25968;&#26694;&#26550;&#20013;&#65292;&#32467;&#26524;&#25581;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#36807;&#24230;&#39118;&#38505;&#30340;&#24555;&#36895;&#25910;&#25947;&#36895;&#29575;&#65292;&#20197;&#21450;&#22914;&#20309;&#36890;&#36807;&#26799;&#24230;&#26041;&#27861;&#35757;&#32451;&#32593;&#32476;&#20197;&#25214;&#21040;&#33391;&#22909;&#30340;&#27867;&#21270;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#25991;&#31456;&#20013;&#65292;&#25105;&#20204;&#20174;&#19977;&#20010;&#35282;&#24230;&#22238;&#39038;&#20102;&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#32479;&#35745;&#29702;&#35770;&#30340;&#25991;&#29486;&#12290;&#31532;&#19968;&#37096;&#20998;&#22238;&#39038;&#20102;&#22312;&#22238;&#24402;&#25110;&#20998;&#31867;&#30340;&#38750;&#21442;&#25968;&#26694;&#26550;&#19979;&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#36807;&#24230;&#39118;&#38505;&#30340;&#32467;&#26524;&#12290;&#36825;&#20123;&#32467;&#26524;&#20381;&#36182;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26174;&#24335;&#26500;&#36896;&#65292;&#20197;&#21450;&#37319;&#29992;&#20102;&#36817;&#20284;&#29702;&#35770;&#30340;&#24037;&#20855;&#65292;&#23548;&#33268;&#36807;&#24230;&#39118;&#38505;&#30340;&#24555;&#36895;&#25910;&#25947;&#36895;&#29575;&#12290;&#36890;&#36807;&#36825;&#20123;&#26500;&#36896;&#65292;&#21487;&#20197;&#29992;&#26679;&#26412;&#22823;&#23567;&#12289;&#25968;&#25454;&#32500;&#24230;&#21644;&#20989;&#25968;&#24179;&#28369;&#24615;&#26469;&#34920;&#36798;&#32593;&#32476;&#30340;&#23485;&#24230;&#21644;&#28145;&#24230;&#12290;&#28982;&#32780;&#65292;&#20182;&#20204;&#30340;&#22522;&#26412;&#20998;&#26512;&#20165;&#36866;&#29992;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#39640;&#24230;&#38750;&#20984;&#30340;&#20840;&#23616;&#26497;&#23567;&#20540;&#28857;&#12290;&#36825;&#20419;&#20351;&#25105;&#20204;&#22312;&#31532;&#20108;&#37096;&#20998;&#22238;&#39038;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22238;&#39038;&#20102;&#37027;&#20123;&#35797;&#22270;&#22238;&#31572;&#8220;&#22522;&#20110;&#26799;&#24230;&#26041;&#27861;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#22914;&#20309;&#25214;&#21040;&#33021;&#22815;&#22312;&#26410;&#35265;&#25968;&#25454;&#19978;&#26377;&#33391;&#22909;&#27867;&#21270;&#24615;&#33021;&#30340;&#35299;&#8221;&#30340;&#35770;&#25991;&#12290;&#23588;&#20854;&#26159;&#20004;&#20010;&#30693;&#21517;&#30340;
&lt;/p&gt;
&lt;p&gt;
In this article, we review the literature on statistical theories of neural networks from three perspectives. In the first part, results on excess risks for neural networks are reviewed in the nonparametric framework of regression or classification. These results rely on explicit constructions of neural networks, leading to fast convergence rates of excess risks, in that tools from the approximation theory are adopted. Through these constructions, the width and depth of the networks can be expressed in terms of sample size, data dimension, and function smoothness. Nonetheless, their underlying analysis only applies to the global minimizer in the highly non-convex landscape of deep neural networks. This motivates us to review the training dynamics of neural networks in the second part. Specifically, we review papers that attempt to answer ``how the neural network trained via gradient-based methods finds the solution that can generalize well on unseen data.'' In particular, two well-know
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#30740;&#31350;&#20102;&#26368;&#20248;&#32479;&#35745;&#24179;&#31561;&#35299;&#21644;&#20010;&#20307;&#20844;&#24179;&#20043;&#38388;&#30340;&#20860;&#23481;&#24615;&#65292;&#25552;&#20986;&#20102;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#20998;&#26512;&#20102;&#35299;&#20915;&#20914;&#31361;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.07174</link><description>&lt;p&gt;
&#20851;&#20110;&#32676;&#20307;&#20844;&#24179;&#21644;&#20010;&#20307;&#20844;&#24179;&#20043;&#38388;&#30340;&#65288;&#19981;&#65289;&#20860;&#23481;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the (In)Compatibility between Group Fairness and Individual Fairness. (arXiv:2401.07174v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.07174
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#30740;&#31350;&#20102;&#26368;&#20248;&#32479;&#35745;&#24179;&#31561;&#35299;&#21644;&#20010;&#20307;&#20844;&#24179;&#20043;&#38388;&#30340;&#20860;&#23481;&#24615;&#65292;&#25552;&#20986;&#20102;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#20998;&#26512;&#20102;&#35299;&#20915;&#20914;&#31361;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#26368;&#20248;&#32479;&#35745;&#24179;&#31561;&#35299;&#21644;&#20010;&#20307;&#20844;&#24179;&#20043;&#38388;&#30340;&#20860;&#23481;&#24615;&#12290;&#34429;&#28982;&#20010;&#20307;&#20844;&#24179;&#26088;&#22312;&#23545;&#24453;&#31867;&#20284;&#30340;&#20010;&#20307;&#65292;&#26368;&#20248;&#32479;&#35745;&#24179;&#31561;&#21017;&#26088;&#22312;&#20026;&#22312;&#21508;&#33258;&#25935;&#24863;&#32676;&#20307;&#20869;&#20849;&#20139;&#30456;&#23545;&#30456;&#20284;&#24615;&#30340;&#20010;&#20307;&#25552;&#20379;&#31867;&#20284;&#30340;&#24453;&#36935;&#12290;&#36825;&#20004;&#31181;&#20844;&#24179;&#35266;&#28857;&#34429;&#28982;&#37117;&#26159;&#20844;&#24179;&#30340;&#35282;&#24230;&#26469;&#30475;&#37117;&#26159;&#21487;&#21462;&#30340;&#65292;&#20294;&#22312;&#24212;&#29992;&#20013;&#24448;&#24448;&#20250;&#21457;&#29983;&#20914;&#31361;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20998;&#26512;&#36825;&#31181;&#20914;&#31361;&#30340;&#23384;&#22312;&#21450;&#20854;&#28508;&#22312;&#35299;&#20915;&#26041;&#26696;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#20805;&#20998;&#65288;&#23574;&#38160;&#65289;&#30340;&#26465;&#20214;&#65292;&#20351;&#26368;&#20248;&#65288;&#21518;&#22788;&#29702;&#65289;&#32479;&#35745;&#24179;&#31561; $L^2$ &#23398;&#20064;&#19982;&#65288;$K$-Lipschitz &#25110; $(\epsilon,\delta)$&#65289;&#20010;&#20307;&#20844;&#24179;&#35201;&#27714;&#20043;&#38388;&#20860;&#23481;&#12290;&#27492;&#22806;&#65292;&#22312;&#20004;&#32773;&#20043;&#38388;&#23384;&#22312;&#20914;&#31361;&#26102;&#65292;&#25105;&#20204;&#39318;&#20808;&#23558;&#21069;&#32773;&#25918;&#26494;&#20026; Pareto &#21069;&#27839;&#65288;&#25110;&#31561;&#25928;&#22320;&#35828;&#26159; $L^2$ &#35823;&#24046;&#21644;&#32479;&#35745;&#20559;&#31163;&#20043;&#38388;&#30340;&#26368;&#20248;&#26435;&#34913;&#65289;&#65292;&#28982;&#21518;&#20998;&#26512;&#20860;&#23481;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the compatibility between the optimal statistical parity solutions and individual fairness. While individual fairness seeks to treat similar individuals similarly, optimal statistical parity aims to provide similar treatment to individuals who share relative similarity within their respective sensitive groups. The two fairness perspectives, while both desirable from a fairness perspective, often come into conflict in applications. Our goal in this work is to analyze the existence of this conflict and its potential solution. In particular, we establish sufficient (sharp) conditions for the compatibility between the optimal (post-processing) statistical parity $L^2$ learning and the ($K$-Lipschitz or $(\epsilon,\delta)$) individual fairness requirements. Furthermore, when there exists a conflict between the two, we first relax the former to the Pareto frontier (or equivalently the optimal trade-off) between $L^2$ error and statistical disparity, and then analyze the compatibilit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#31532;&#19968;&#21407;&#29702;&#20013;&#24471;&#21040;&#20102;&#36203;&#24067;&#23398;&#20064;&#30340;&#26126;&#30830;&#34920;&#36798;&#24335;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20123;&#23398;&#20064;&#35268;&#21017;&#22312;&#22823;&#25968;&#25454;&#26497;&#38480;&#19979;&#25910;&#25947;&#21040;&#21407;&#22987;&#30340;&#23384;&#20648;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2401.07110</link><description>&lt;p&gt;
&#20174;&#31532;&#19968;&#21407;&#29702;&#20013;&#30340;&#36203;&#24067;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Hebbian Learning from First Principles. (arXiv:2401.07110v1 [cond-mat.dis-nn])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.07110
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#31532;&#19968;&#21407;&#29702;&#20013;&#24471;&#21040;&#20102;&#36203;&#24067;&#23398;&#20064;&#30340;&#26126;&#30830;&#34920;&#36798;&#24335;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20123;&#23398;&#20064;&#35268;&#21017;&#22312;&#22823;&#25968;&#25454;&#26497;&#38480;&#19979;&#25910;&#25947;&#21040;&#21407;&#22987;&#30340;&#23384;&#20648;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#38024;&#23545;&#31070;&#32463;&#32593;&#32476;&#30340;Hopfield&#27169;&#22411;&#21450;&#20854;&#23494;&#38598;&#27010;&#21270;&#24418;&#24335;&#30340;&#21407;&#22987;&#23384;&#20648;&#26041;&#26696;&#24050;&#36890;&#36807;&#20551;&#35774;&#20854;&#21704;&#23494;&#39039;&#37327;&#30340;&#34920;&#36798;&#24335;&#20026;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#21327;&#35758;&#65292;&#25104;&#20026;&#30495;&#27491;&#30340;&#36203;&#24067;&#23398;&#20064;&#35268;&#21017;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#20381;&#38752;Jaynes&#30340;&#26368;&#22823;&#29109;&#26497;&#20540;&#27861;&#24471;&#21040;&#20102;&#36825;&#20123;&#26126;&#30830;&#30340;&#34920;&#36798;&#24335;&#12290;&#38500;&#20102;&#24418;&#24335;&#19978;&#25512;&#23548;&#20986;&#36825;&#20123;&#36203;&#24067;&#23398;&#20064;&#30340;&#35268;&#21017;&#65292;&#36825;&#20010;&#26500;&#24314;&#36824;&#31361;&#26174;&#20102;&#29109;&#26497;&#20540;&#20013;&#30340;&#26391;&#26684;&#26391;&#26085;&#32422;&#26463;&#22914;&#20309;&#24378;&#21046;&#32593;&#32476;&#32467;&#26524;&#19978;&#30340;&#31070;&#32463;&#30456;&#20851;&#24615;&#65306;&#36825;&#20123;&#23581;&#35797;&#27169;&#20223;&#25552;&#20379;&#32473;&#32593;&#32476;&#36827;&#34892;&#35757;&#32451;&#30340;&#25968;&#25454;&#38598;&#20013;&#38544;&#34255;&#30340;&#32463;&#39564;&#25903;&#25345;&#65292;&#32780;&#19988;&#32593;&#32476;&#36234;&#23494;&#38598;&#65292;&#33021;&#22815;&#25429;&#25417;&#21040;&#30340;&#30456;&#20851;&#24615;&#26102;&#38388;&#36234;&#38271;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#22823;&#25968;&#25454;&#26497;&#38480;&#19979;&#65292;&#26080;&#35770;&#26159;&#21542;&#23384;&#22312;&#25945;&#24072;&#65292;&#36825;&#20123;&#36203;&#24067;&#23398;&#20064;&#35268;&#21017;&#37117;&#20250;&#25910;&#25947;&#21040;&#21407;&#22987;&#30340;&#23384;&#20648;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, the original storage prescription for the Hopfield model of neural networks -- as well as for its dense generalizations -- has been turned into a genuine Hebbian learning rule by postulating the expression of its Hamiltonian for both the supervised and unsupervised protocols. In these notes, first, we obtain these explicit expressions by relying upon maximum entropy extremization \`a la Jaynes. Beyond providing a formal derivation of these recipes for Hebbian learning, this construction also highlights how Lagrangian constraints within entropy extremization force network's outcomes on neural correlations: these try to mimic the empirical counterparts hidden in the datasets provided to the network for its training and, the denser the network, the longer the correlations that it is able to capture. Next, we prove that, in the big data limit, whatever the presence of a teacher (or its lacking), not only these Hebbian learning rules converge to the original storage prescription o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;ADRC&#34701;&#20837;&#21040;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#20013;&#30340;&#28508;&#22312;&#22240;&#23376;&#20998;&#26512;&#26041;&#27861;&#65292;&#36890;&#36807;&#25913;&#36827;&#23398;&#20064;&#35823;&#24046;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.07012</link><description>&lt;p&gt;
&#19968;&#31181;&#23558;ADRC&#34701;&#20837;&#21040;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#20013;&#30340;&#28508;&#22312;&#22240;&#23376;&#20998;&#26512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
An ADRC-Incorporated Stochastic Gradient Descent Algorithm for Latent Factor Analysis. (arXiv:2401.07012v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.07012
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;ADRC&#34701;&#20837;&#21040;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#20013;&#30340;&#28508;&#22312;&#22240;&#23376;&#20998;&#26512;&#26041;&#27861;&#65292;&#36890;&#36807;&#25913;&#36827;&#23398;&#20064;&#35823;&#24046;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#21644;&#19981;&#23436;&#25972;&#30340;&#30697;&#38453;&#21253;&#21547;&#30528;&#35768;&#22810;&#22797;&#26434;&#30340;&#33410;&#28857;&#38388;&#30456;&#20114;&#20316;&#29992;&#12290;&#22522;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#28508;&#22312;&#22240;&#23376;&#20998;&#26512;&#65288;LFA&#65289;&#27169;&#22411;&#22312;&#20174;&#39640;&#32500;&#19981;&#23436;&#25972;&#30340;&#30697;&#38453;&#20013;&#25552;&#21462;&#26377;&#20215;&#20540;&#20449;&#24687;&#26041;&#38754;&#38750;&#24120;&#26377;&#25928;&#12290;&#28982;&#32780;&#65292;&#36825;&#26679;&#30340;&#27169;&#22411;&#36890;&#24120;&#20250;&#36935;&#21040;&#25910;&#25947;&#36895;&#24230;&#24930;&#30340;&#38382;&#39064;&#65292;&#22240;&#20026;&#26631;&#20934;&#30340;SGD&#31639;&#27861;&#21482;&#32771;&#34385;&#24403;&#21069;&#30340;&#23398;&#20064;&#35823;&#24046;&#26469;&#35745;&#31639;&#38543;&#26426;&#26799;&#24230;&#65292;&#32780;&#19981;&#32771;&#34385;&#23398;&#20064;&#35823;&#24046;&#30340;&#21382;&#21490;&#21644;&#26410;&#26469;&#29366;&#24577;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#20851;&#38190;&#38382;&#39064;&#65292;&#26412;&#25991;&#21019;&#26032;&#24615;&#22320;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;ADRC&#34701;&#20837;&#21040;SGD&#31639;&#27861;&#20013;&#30340;ADS&#65288;ADRC-incorporated SGD&#65289;&#31639;&#27861;&#65292;&#36890;&#36807;&#32771;&#34385;&#23398;&#20064;&#35823;&#24046;&#30340;&#21382;&#21490;&#21644;&#26410;&#26469;&#29366;&#24577;&#26469;&#25913;&#36827;&#23454;&#20363;&#30340;&#23398;&#20064;&#35823;&#24046;&#65292;&#36981;&#24490;ADRC&#25511;&#21046;&#22120;&#30340;&#21407;&#21017;&#12290;&#22522;&#20110;&#27492;&#65292;&#36827;&#19968;&#27493;&#23454;&#29616;&#20102;&#19968;&#31181;&#22522;&#20110;ADS&#30340;LFA&#27169;&#22411;&#65292;&#29992;&#20110;&#22312;&#39640;&#32500;&#19981;&#23436;&#25972;&#30340;&#30697;&#38453;&#19978;&#36827;&#34892;&#24555;&#36895;&#20934;&#30830;&#30340;&#28508;&#22312;&#22240;&#23376;&#20998;&#26512;&#12290;&#23545;&#20004;&#20010;&#39640;&#32500;&#19981;&#23436;&#25972;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#22312;&#25216;&#26415;&#24615;&#33021;&#19978;&#20248;&#20110;&#29616;&#26377;&#30340;LFA&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
High-dimensional and incomplete (HDI) matrix contains many complex interactions between numerous nodes. A stochastic gradient descent (SGD)-based latent factor analysis (LFA) model is remarkably effective in extracting valuable information from an HDI matrix. However, such a model commonly encounters the problem of slow convergence because a standard SGD algorithm only considers the current learning error to compute the stochastic gradient without considering the historical and future state of the learning error. To address this critical issue, this paper innovatively proposes an ADRC-incorporated SGD (ADS) algorithm by refining the instance learning error by considering the historical and future state by following the principle of an ADRC controller. With it, an ADS-based LFA model is further achieved for fast and accurate latent factor analysis on an HDI matrix. Empirical studies on two HDI datasets demonstrate that the proposed model outperforms the state-of-the-art LFA models in te
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#20013;&#23545;&#28508;&#22312;&#36873;&#25321;&#36827;&#34892;&#24314;&#27169;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22914;&#20309;&#24110;&#21161;&#36827;&#34892;&#22240;&#26524;&#25512;&#29702;&#20219;&#21153;&#65292;&#21253;&#25324;&#22788;&#29702;&#36873;&#25321;&#20559;&#24046;&#12290;</title><link>http://arxiv.org/abs/2401.06925</link><description>&lt;p&gt;
&#29992;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#23545;&#28508;&#22312;&#36873;&#25321;&#36827;&#34892;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Modeling Latent Selection with Structural Causal Models. (arXiv:2401.06925v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06925
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#20013;&#23545;&#28508;&#22312;&#36873;&#25321;&#36827;&#34892;&#24314;&#27169;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22914;&#20309;&#24110;&#21161;&#36827;&#34892;&#22240;&#26524;&#25512;&#29702;&#20219;&#21153;&#65292;&#21253;&#25324;&#22788;&#29702;&#36873;&#25321;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36873;&#25321;&#20559;&#20506;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#20013;&#26159;&#26222;&#36941;&#23384;&#22312;&#30340;&#65292;&#22914;&#26524;&#19981;&#27491;&#30830;&#22788;&#29702;&#21487;&#33021;&#23548;&#33268;&#35823;&#23548;&#24615;&#32467;&#26524;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#23545;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#65288;SCMs&#65289;&#36827;&#34892;&#26465;&#20214;&#25805;&#20316;&#30340;&#26041;&#27861;&#65292;&#20197;&#20174;&#22240;&#26524;&#30340;&#35282;&#24230;&#23545;&#28508;&#22312;&#36873;&#25321;&#36827;&#34892;&#24314;&#27169;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26465;&#20214;&#25805;&#20316;&#23558;&#20855;&#26377;&#26126;&#30830;&#28508;&#22312;&#36873;&#25321;&#26426;&#21046;&#30340;SCM&#36716;&#25442;&#20026;&#27809;&#26377;&#27492;&#31867;&#36873;&#25321;&#26426;&#21046;&#30340;SCM&#65292;&#36825;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#32534;&#30721;&#20102;&#26681;&#25454;&#21407;&#22987;SCM&#36873;&#25321;&#30340;&#20122;&#24635;&#20307;&#30340;&#22240;&#26524;&#35821;&#20041;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#35813;&#26465;&#20214;&#25805;&#20316;&#20445;&#25345;SCMs&#30340;&#31616;&#27905;&#24615;&#65292;&#26080;&#29615;&#24615;&#21644;&#32447;&#24615;&#24615;&#65292;&#24182;&#19982;&#36793;&#38469;&#21270;&#25805;&#20316;&#30456;&#31526;&#21512;&#12290;&#30001;&#20110;&#36825;&#20123;&#29305;&#24615;&#19982;&#36793;&#38469;&#21270;&#21644;&#24178;&#39044;&#32467;&#21512;&#36215;&#26469;&#65292;&#26465;&#20214;&#25805;&#20316;&#20026;&#22312;&#28508;&#22312;&#32454;&#33410;&#24050;&#32463;&#21435;&#38500;&#30340;&#22240;&#26524;&#27169;&#22411;&#20013;&#36827;&#34892;&#22240;&#26524;&#25512;&#29702;&#20219;&#21153;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#20215;&#20540;&#30340;&#24037;&#20855;&#12290;&#25105;&#20204;&#36890;&#36807;&#20363;&#23376;&#28436;&#31034;&#20102;&#22914;&#20309;&#23558;&#22240;&#26524;&#25512;&#26029;&#30340;&#32463;&#20856;&#32467;&#26524;&#25512;&#24191;&#20197;&#21253;&#25324;&#36873;&#25321;&#20559;&#20506;&#12290;
&lt;/p&gt;
&lt;p&gt;
Selection bias is ubiquitous in real-world data, and can lead to misleading results if not dealt with properly. We introduce a conditioning operation on Structural Causal Models (SCMs) to model latent selection from a causal perspective. We show that the conditioning operation transforms an SCM with the presence of an explicit latent selection mechanism into an SCM without such selection mechanism, which partially encodes the causal semantics of the selected subpopulation according to the original SCM. Furthermore, we show that this conditioning operation preserves the simplicity, acyclicity, and linearity of SCMs, and commutes with marginalization. Thanks to these properties, combined with marginalization and intervention, the conditioning operation offers a valuable tool for conducting causal reasoning tasks within causal models where latent details have been abstracted away. We demonstrate by example how classical results of causal inference can be generalized to include selection b
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#36827;&#34892;Open RAN LSTM&#27969;&#37327;&#39044;&#27979;&#21644;&#20999;&#29255;&#31649;&#29702;&#30340;&#26041;&#27861;&#65292;&#22312;&#20445;&#25345;&#26381;&#21153;&#36136;&#37327;&#30340;&#21069;&#25552;&#19979;&#65292;&#36890;&#36807;&#21033;&#29992;&#20998;&#24067;&#24335;&#21333;&#20803;&#30340;&#24322;&#26500;&#32463;&#39564;&#21644;&#39044;&#27979;&#27169;&#22411;&#30340;&#36741;&#21161;&#20449;&#24687;&#65292;&#26174;&#33879;&#25913;&#21892;&#20102;&#32593;&#32476;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.06922</link><description>&lt;p&gt;
&#20351;&#29992;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#36827;&#34892;Open RAN LSTM&#27969;&#37327;&#39044;&#27979;&#21644;&#20999;&#29255;&#31649;&#29702;
&lt;/p&gt;
&lt;p&gt;
Open RAN LSTM Traffic Prediction and Slice Management using Deep Reinforcement Learning. (arXiv:2401.06922v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06922
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#36827;&#34892;Open RAN LSTM&#27969;&#37327;&#39044;&#27979;&#21644;&#20999;&#29255;&#31649;&#29702;&#30340;&#26041;&#27861;&#65292;&#22312;&#20445;&#25345;&#26381;&#21153;&#36136;&#37327;&#30340;&#21069;&#25552;&#19979;&#65292;&#36890;&#36807;&#21033;&#29992;&#20998;&#24067;&#24335;&#21333;&#20803;&#30340;&#24322;&#26500;&#32463;&#39564;&#21644;&#39044;&#27979;&#27169;&#22411;&#30340;&#36741;&#21161;&#20449;&#24687;&#65292;&#26174;&#33879;&#25913;&#21892;&#20102;&#32593;&#32476;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#33258;&#21160;&#39550;&#39542;&#12289;&#26234;&#24935;&#22478;&#24066;&#21644;&#26234;&#33021;&#24037;&#21378;&#31561;&#26032;&#20852;&#24212;&#29992;&#30340;&#20986;&#29616;&#65292;&#32593;&#32476;&#20999;&#29255;&#25104;&#20026;5G&#21450;&#20197;&#19978;&#32593;&#32476;&#20013;&#28385;&#36275;&#38754;&#21521;&#26381;&#21153;&#30340;&#32593;&#32476;&#38656;&#27714;&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#12290;&#28982;&#32780;&#65292;&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#31649;&#29702;&#19981;&#21516;&#30340;&#32593;&#32476;&#20999;&#29255;&#24182;&#20445;&#25345;&#26381;&#21153;&#36136;&#37327;(QoS)&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#21033;&#29992;ORAN&#31995;&#32479;&#20013;&#20998;&#24067;&#24335;&#21333;&#20803;(DUs)&#30340;&#24322;&#26500;&#32463;&#39564;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#20351;&#29992;&#20998;&#24067;&#24335;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;(DDRL)&#30340;ORAN&#20999;&#29255;xApp&#30340;&#26032;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#25552;&#39640;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#30340;&#20915;&#31574;&#24615;&#33021;&#65292;&#36824;&#24341;&#20837;&#20102;&#22522;&#20110;&#38271;&#30701;&#26399;&#35760;&#24518;(LSTM)&#30340;&#39044;&#27979;rApp&#65292;&#20174;&#21160;&#24577;&#29615;&#22659;&#20013;&#25552;&#20379;&#39069;&#22806;&#20449;&#24687;&#32473;xApp&#12290;&#27169;&#25311;&#32467;&#26524;&#34920;&#26126;&#32593;&#32476;&#24615;&#33021;&#26377;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#65292;&#23588;&#20854;&#22312;&#38477;&#20302;QoS&#36829;&#35268;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;&#36825;&#20984;&#26174;&#20102;&#20351;&#29992;&#39044;&#27979;rApp&#21644;&#20998;&#24067;&#24335;actor&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
With emerging applications such as autonomous driving, smart cities, and smart factories, network slicing has become an essential component of 5G and beyond networks as a means of catering to a service-aware network. However, managing different network slices while maintaining quality of services (QoS) is a challenge in a dynamic environment. To address this issue, this paper leverages the heterogeneous experiences of distributed units (DUs) in ORAN systems and introduces a novel approach to ORAN slicing xApp using distributed deep reinforcement learning (DDRL). Additionally, to enhance the decision-making performance of the RL agent, a prediction rApp based on long short-term memory (LSTM) is incorporated to provide additional information from the dynamic environment to the xApp. Simulation results demonstrate significant improvements in network performance, particularly in reducing QoS violations. This emphasizes the importance of using the prediction rApp and distributed actors' inf
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26469;&#23545;&#22240;&#26524;&#22270;&#36827;&#34892;&#23454;&#35777;&#35780;&#20272;&#30340;&#26032;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#31216;&#20026;&#22240;&#26524;&#22270;&#26631;&#20934;&#21270;&#27969;(cGNFs)&#65292;&#36890;&#36807;&#20351;&#29992;DAGs&#34920;&#31034;&#29702;&#35770;&#65292;&#24182;&#36991;&#20813;&#21151;&#33021;&#24418;&#24335;&#30340;&#20551;&#35774;&#65292;&#26469;&#26356;&#20934;&#30830;&#22320;&#25429;&#25417;&#22240;&#26524;&#31995;&#32479;&#30340;&#22797;&#26434;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.06864</link><description>&lt;p&gt;
&#20351;&#29992;DAGs&#30340;&#28145;&#24230;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Deep Learning With DAGs. (arXiv:2401.06864v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06864
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26469;&#23545;&#22240;&#26524;&#22270;&#36827;&#34892;&#23454;&#35777;&#35780;&#20272;&#30340;&#26032;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#31216;&#20026;&#22240;&#26524;&#22270;&#26631;&#20934;&#21270;&#27969;(cGNFs)&#65292;&#36890;&#36807;&#20351;&#29992;DAGs&#34920;&#31034;&#29702;&#35770;&#65292;&#24182;&#36991;&#20813;&#21151;&#33021;&#24418;&#24335;&#30340;&#20551;&#35774;&#65292;&#26469;&#26356;&#20934;&#30830;&#22320;&#25429;&#25417;&#22240;&#26524;&#31995;&#32479;&#30340;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20250;&#31185;&#23398;&#29702;&#35770;&#32463;&#24120;&#20551;&#35774;&#19968;&#32452;&#21464;&#37327;&#25110;&#20107;&#20214;&#20043;&#38388;&#23384;&#22312;&#22240;&#26524;&#20851;&#31995;&#12290;&#23613;&#31649;&#26377;&#21521;&#26080;&#29615;&#22270;(DAGs)&#36234;&#26469;&#36234;&#22810;&#22320;&#34987;&#29992;&#26469;&#34920;&#31034;&#36825;&#20123;&#29702;&#35770;&#65292;&#20294;&#23427;&#20204;&#22312;&#23454;&#36341;&#20013;&#30340;&#20840;&#37096;&#28508;&#21147;&#23578;&#26410;&#24471;&#21040;&#23454;&#29616;&#12290;&#20316;&#20026;&#38750;&#21442;&#25968;&#22240;&#26524;&#27169;&#22411;&#65292;DAGs&#19981;&#38656;&#35201;&#20851;&#20110;&#20551;&#35774;&#20851;&#31995;&#30340;&#21151;&#33021;&#24418;&#24335;&#30340;&#20219;&#20309;&#20551;&#35774;&#12290;&#28982;&#32780;&#65292;&#20026;&#20102;&#31616;&#21270;&#23454;&#35777;&#35780;&#20272;&#30340;&#20219;&#21153;&#65292;&#30740;&#31350;&#20154;&#21592;&#20542;&#21521;&#20110;&#26080;&#35770;&#22914;&#20309;&#28608;&#27963;&#36825;&#20123;&#20551;&#35774;&#65292;&#23613;&#31649;&#23427;&#20204;&#36890;&#24120;&#26159;&#20219;&#24847;&#30340;&#65292;&#19981;&#21453;&#26144;&#20219;&#20309;&#29702;&#35770;&#20869;&#23481;&#25110;&#20808;&#21069;&#30693;&#35782;&#12290;&#27492;&#22806;&#65292;&#21151;&#33021;&#24418;&#24335;&#30340;&#20551;&#35774;&#21487;&#33021;&#23548;&#33268;&#20559;&#35265;&#65292;&#22240;&#20026;&#23427;&#20204;&#26410;&#33021;&#20934;&#30830;&#25429;&#25417;&#30740;&#31350;&#20013;&#22240;&#26524;&#31995;&#32479;&#30340;&#22797;&#26434;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#22240;&#26524;&#22270;&#26631;&#20934;&#21270;&#27969;(cGNFs)&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26469;&#23545;&#34920;&#31034;&#20026;DAGs&#30340;&#29702;&#35770;&#36827;&#34892;&#23454;&#35777;&#35780;&#20272;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#65292;cGNFs&#27169;&#25311;&#20102;&#20840;&#32852;&#21512;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Social science theories often postulate causal relationships among a set of variables or events. Although directed acyclic graphs (DAGs) are increasingly used to represent these theories, their full potential has not yet been realized in practice. As non-parametric causal models, DAGs require no assumptions about the functional form of the hypothesized relationships. Nevertheless, to simplify the task of empirical evaluation, researchers tend to invoke such assumptions anyway, even though they are typically arbitrary and do not reflect any theoretical content or prior knowledge. Moreover, functional form assumptions can engender bias, whenever they fail to accurately capture the complexity of the causal system under investigation. In this article, we introduce causal-graphical normalizing flows (cGNFs), a novel approach to causal inference that leverages deep neural networks to empirically evaluate theories represented as DAGs. Unlike conventional approaches, cGNFs model the full joint
&lt;/p&gt;</description></item><item><title>&#36825;&#20221;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#23450;&#20215;&#36339;&#36291;&#25193;&#25955;&#27169;&#22411;&#19979;&#27431;&#24335;&#31726;&#24335;&#26399;&#26435;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#37319;&#29992;&#20102;&#38544;&#24335;-&#26174;&#24335;&#26368;&#23567;&#31227;&#21160;&#26041;&#27861;&#20197;&#21450;&#27531;&#24046;&#22411;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#65292;&#24182;&#36890;&#36807;&#31232;&#30095;&#32593;&#26684;&#39640;&#26031;-&#22467;&#23572;&#31859;&#29305;&#36924;&#36817;&#21644;&#22522;&#20110;ANN&#30340;&#39640;&#32500;&#19987;&#29992;&#27714;&#31215;&#35268;&#21017;&#26469;&#31163;&#25955;&#21270;&#31215;&#20998;&#36816;&#31639;&#31526;&#12290;</title><link>http://arxiv.org/abs/2401.06740</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#36339;&#36291;&#25193;&#25955;&#27169;&#22411;&#26399;&#26435;&#23450;&#20215;&#30340;&#28145;&#24230;&#38544;&#24335;-&#26174;&#24335;&#26368;&#23567;&#31227;&#21160;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A deep implicit-explicit minimizing movement method for option pricing in jump-diffusion models. (arXiv:2401.06740v1 [q-fin.CP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06740
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20221;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#23450;&#20215;&#36339;&#36291;&#25193;&#25955;&#27169;&#22411;&#19979;&#27431;&#24335;&#31726;&#24335;&#26399;&#26435;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#37319;&#29992;&#20102;&#38544;&#24335;-&#26174;&#24335;&#26368;&#23567;&#31227;&#21160;&#26041;&#27861;&#20197;&#21450;&#27531;&#24046;&#22411;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#65292;&#24182;&#36890;&#36807;&#31232;&#30095;&#32593;&#26684;&#39640;&#26031;-&#22467;&#23572;&#31859;&#29305;&#36924;&#36817;&#21644;&#22522;&#20110;ANN&#30340;&#39640;&#32500;&#19987;&#29992;&#27714;&#31215;&#35268;&#21017;&#26469;&#31163;&#25955;&#21270;&#31215;&#20998;&#36816;&#31639;&#31526;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#23450;&#20215;&#36339;&#36291;&#25193;&#25955;&#21160;&#24577;&#19979;&#30340;&#27431;&#24335;&#31726;&#24335;&#26399;&#26435;&#12290;&#23558;&#26399;&#26435;&#23450;&#20215;&#38382;&#39064;&#34920;&#36848;&#20026;&#19968;&#20010;&#20559;&#31215;&#20998;&#24494;&#20998;&#26041;&#31243;&#65292;&#24182;&#36890;&#36807;&#19968;&#31181;&#26032;&#30340;&#38544;&#24335;-&#26174;&#24335;&#26368;&#23567;&#31227;&#21160;&#26102;&#38388;&#27493;&#27861;&#36827;&#34892;&#36817;&#20284;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#28145;&#24230;&#27531;&#24046;&#22411;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#65288;ANNs&#65289;&#36880;&#27493;&#36924;&#36817;&#12290;&#31215;&#20998;&#36816;&#31639;&#31526;&#36890;&#36807;&#20004;&#31181;&#19981;&#21516;&#30340;&#26041;&#27861;&#31163;&#25955;&#21270;&#65306;a&#65289;&#36890;&#36807;&#31232;&#30095;&#32593;&#26684;&#39640;&#26031;-&#22467;&#23572;&#31859;&#29305;&#36924;&#36817;&#65292;&#37319;&#29992;&#22855;&#24322;&#20540;&#20998;&#35299;&#20135;&#29983;&#30340;&#23616;&#37096;&#22352;&#26631;&#36724;&#65292;&#24182;&#19988;b&#65289;&#36890;&#36807;&#22522;&#20110;ANN&#30340;&#39640;&#32500;&#19987;&#29992;&#27714;&#31215;&#35268;&#21017;&#12290;&#20851;&#38190;&#26159;&#65292;&#25152;&#25552;&#20986;&#30340;ANN&#30340;&#26500;&#36896;&#30830;&#20445;&#20102;&#35299;&#20915;&#26041;&#26696;&#22312;&#26631;&#30340;&#36164;&#20135;&#36739;&#22823;&#20540;&#26102;&#30340;&#28176;&#36817;&#34892;&#20026;&#65292;&#24182;&#19988;&#19982;&#35299;&#20915;&#26041;&#26696;&#20808;&#39564;&#24050;&#30693;&#30340;&#23450;&#24615;&#29305;&#24615;&#30456;&#19968;&#33268;&#36755;&#20986;&#12290;&#23545;&#26041;&#27861;&#32500;&#24230;&#30340;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a novel deep learning approach for pricing European basket options written on assets that follow jump-diffusion dynamics. The option pricing problem is formulated as a partial integro-differential equation, which is approximated via a new implicit-explicit minimizing movement time-stepping approach, involving approximation by deep, residual-type Artificial Neural Networks (ANNs) for each time step. The integral operator is discretized via two different approaches: a) a sparse-grid Gauss--Hermite approximation following localised coordinate axes arising from singular value decompositions, and b) an ANN-based high-dimensional special-purpose quadrature rule. Crucially, the proposed ANN is constructed to ensure the asymptotic behavior of the solution for large values of the underlyings and also leads to consistent outputs with respect to a priori known qualitative properties of the solution. The performance and robustness with respect to the dimension of the methods are assesse
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#20855;&#26377;&#31934;&#30830;&#35268;&#33539;&#19981;&#21464;&#24615;&#30340;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#25214;&#21040;&#20102;&#22235;&#32500;SU&#65288;3&#65289;&#35268;&#33539;&#29702;&#35770;&#30340;&#20248;&#31168;&#22266;&#23450;&#28857;&#20316;&#29992;&#30340;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#20026;&#26410;&#26469;&#30340;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#25171;&#19979;&#20102;&#24517;&#35201;&#30340;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2401.06481</link><description>&lt;p&gt;
&#20351;&#29992;&#20855;&#26377;&#35268;&#33539;&#31561;&#21464;&#24615;&#30340;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#26426;&#22120;&#23398;&#20064;SU&#65288;3&#65289;&#35268;&#33539;&#29702;&#35770;&#30340;&#22266;&#23450;&#28857;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Machine learning a fixed point action for SU(3) gauge theory with a gauge equivariant convolutional neural network. (arXiv:2401.06481v1 [hep-lat] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06481
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#20855;&#26377;&#31934;&#30830;&#35268;&#33539;&#19981;&#21464;&#24615;&#30340;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#25214;&#21040;&#20102;&#22235;&#32500;SU&#65288;3&#65289;&#35268;&#33539;&#29702;&#35770;&#30340;&#20248;&#31168;&#22266;&#23450;&#28857;&#20316;&#29992;&#30340;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#20026;&#26410;&#26469;&#30340;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#25171;&#19979;&#20102;&#24517;&#35201;&#30340;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22266;&#23450;&#28857;&#30340;&#26684;&#23376;&#20316;&#29992;&#34987;&#35774;&#35745;&#25104;&#20855;&#26377;&#19981;&#21463;&#31163;&#25955;&#21270;&#25928;&#24212;&#24433;&#21709;&#30340;&#36830;&#32493;&#32463;&#20856;&#24615;&#36136;&#65292;&#24182;&#22312;&#37327;&#23376;&#23618;&#38754;&#19978;&#20943;&#23569;&#26684;&#23376;&#25928;&#24212;&#12290;&#23427;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#29992;&#36739;&#31895;&#30340;&#26684;&#23376;&#26469;&#25552;&#21462;&#36830;&#32493;&#29289;&#29702;&#30340;&#21487;&#33021;&#26041;&#27861;&#65292;&#20174;&#32780;&#32469;&#36807;&#19982;&#36830;&#32493;&#26497;&#38480;&#30456;&#20851;&#30340;&#20020;&#30028;&#20943;&#24930;&#21644;&#25299;&#25169;&#20923;&#32467;&#38382;&#39064;&#12290;&#23454;&#38469;&#24212;&#29992;&#30340;&#20851;&#38190;&#26159;&#25214;&#21040;&#19968;&#20010;&#31934;&#30830;&#19988;&#32039;&#20945;&#30340;&#22266;&#23450;&#28857;&#20316;&#29992;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#22240;&#20026;&#20854;&#35768;&#22810;&#24615;&#36136;&#21482;&#26159;&#38544;&#21547;&#23450;&#20041;&#30340;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#37325;&#26032;&#24605;&#32771;&#20102;&#22914;&#20309;&#21442;&#25968;&#21270;&#22266;&#23450;&#28857;&#20316;&#29992;&#30340;&#38382;&#39064;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#20351;&#29992;&#20855;&#26377;&#31934;&#30830;&#35268;&#33539;&#19981;&#21464;&#24615;&#30340;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#33719;&#24471;&#22235;&#32500;SU&#65288;3&#65289;&#35268;&#33539;&#29702;&#35770;&#30340;&#22266;&#23450;&#28857;&#20316;&#29992;&#12290;&#22823;&#30340;&#31639;&#23376;&#31354;&#38388;&#20351;&#25105;&#20204;&#33021;&#22815;&#25214;&#21040;&#27604;&#20043;&#21069;&#30740;&#31350;&#26356;&#22909;&#30340;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#36825;&#26159;&#26410;&#26469;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#30340;&#24517;&#35201;&#31532;&#19968;&#27493;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fixed point lattice actions are designed to have continuum classical properties unaffected by discretization effects and reduced lattice artifacts at the quantum level. They provide a possible way to extract continuum physics with coarser lattices, thereby allowing to circumvent problems with critical slowing down and topological freezing toward the continuum limit. A crucial ingredient for practical applications is to find an accurate and compact parametrization of a fixed point action, since many of its properties are only implicitly defined. Here we use machine learning methods to revisit the question of how to parametrize fixed point actions. In particular, we obtain a fixed point action for four-dimensional SU(3) gauge theory using convolutional neural networks with exact gauge invariance. The large operator space allows us to find superior parametrizations compared to previous studies, a necessary first step for future Monte Carlo simulations.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26641;&#30340;&#21487;&#21464;&#31995;&#25968;&#27169;&#22411;&#65292;&#20351;&#29992;&#24490;&#29615;&#26799;&#24230;&#25552;&#21319;&#26426;&#36827;&#34892;&#24314;&#27169;&#65292;&#23454;&#29616;&#20102;&#36880;&#32500;&#26089;&#20572;&#21644;&#29305;&#24449;&#37325;&#35201;&#24615;&#35780;&#20998;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#20135;&#29983;&#19982;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;VCM&#30456;&#24403;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.05982</link><description>&lt;p&gt;
&#22522;&#20110;&#26641;&#30340;&#21487;&#21464;&#31995;&#25968;&#27169;&#22411;&#20171;&#32461;
&lt;/p&gt;
&lt;p&gt;
A tree-based varying coefficient model. (arXiv:2401.05982v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05982
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26641;&#30340;&#21487;&#21464;&#31995;&#25968;&#27169;&#22411;&#65292;&#20351;&#29992;&#24490;&#29615;&#26799;&#24230;&#25552;&#21319;&#26426;&#36827;&#34892;&#24314;&#27169;&#65292;&#23454;&#29616;&#20102;&#36880;&#32500;&#26089;&#20572;&#21644;&#29305;&#24449;&#37325;&#35201;&#24615;&#35780;&#20998;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#20135;&#29983;&#19982;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;VCM&#30456;&#24403;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26641;&#30340;&#21487;&#21464;&#31995;&#25968;&#27169;&#22411;(VCM)&#65292;&#20854;&#20013;&#21487;&#21464;&#31995;&#25968;&#20351;&#29992;Delong&#31561;&#20154;(2023)&#30340;&#24490;&#29615;&#26799;&#24230;&#25552;&#21319;&#26426;(CGBM)&#36827;&#34892;&#24314;&#27169;&#12290;&#20351;&#29992;CGBM&#23545;&#31995;&#25968;&#20989;&#25968;&#36827;&#34892;&#24314;&#27169;&#65292;&#21487;&#20197;&#36827;&#34892;&#36880;&#32500;&#26089;&#20572;&#21644;&#29305;&#24449;&#37325;&#35201;&#24615;&#35780;&#20998;&#12290;&#36880;&#32500;&#26089;&#20572;&#19981;&#20165;&#21487;&#20197;&#20943;&#23569;&#32500;&#24230;&#29305;&#23450;&#30340;&#36807;&#25311;&#21512;&#39118;&#38505;&#65292;&#36824;&#21487;&#20197;&#25581;&#31034;&#32500;&#24230;&#20043;&#38388;&#27169;&#22411;&#22797;&#26434;&#24615;&#30340;&#24046;&#24322;&#12290;&#20351;&#29992;&#29305;&#24449;&#37325;&#35201;&#24615;&#35780;&#20998;&#21487;&#20197;&#36827;&#34892;&#31616;&#21333;&#30340;&#29305;&#24449;&#36873;&#25321;&#21644;&#26131;&#20110;&#35299;&#37322;&#30340;&#27169;&#22411;&#35299;&#37322;&#12290;&#35813;&#27169;&#22411;&#22312;Richman&#21644;W&#252;thrich&#65288;2023&#65289;&#20351;&#29992;&#30340;&#30456;&#21516;&#30340;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#31034;&#20363;&#19978;&#36827;&#34892;&#35780;&#20272;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;&#23427;&#22312;&#26679;&#26412;&#22806;&#25439;&#22833;&#26041;&#38754;&#20135;&#29983;&#20102;&#19982;&#20182;&#20204;&#30340;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;VCM LocalGLMnet&#30456;&#24403;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
The paper introduces a tree-based varying coefficient model (VCM) where the varying coefficients are modelled using the cyclic gradient boosting machine (CGBM) from Delong et al. (2023). Modelling the coefficient functions using a CGBM allows for dimension-wise early stopping and feature importance scores. The dimension-wise early stopping not only reduces the risk of dimension-specific overfitting, but also reveals differences in model complexity across dimensions. The use of feature importance scores allows for simple feature selection and easy model interpretation. The model is evaluated on the same simulated and real data examples as those used in Richman and W\"uthrich (2023), and the results show that it produces results in terms of out of sample loss that are comparable to those of their neural network-based VCM called LocalGLMnet.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#36845;&#20195;&#27491;&#21017;&#21270;&#31639;&#27861;IRKSN&#65292;&#23427;&#36890;&#36807;&#20351;&#29992;$k$&#25903;&#25745;&#33539;&#25968;&#27491;&#21017;&#21270;&#23454;&#29616;&#31232;&#30095;&#24674;&#22797;&#65292;&#24182;&#25552;&#20379;&#20102;&#26465;&#20214;&#12290;&#36825;&#26159;&#23545;&#22522;&#20110;$\ell_1$&#33539;&#25968;&#30340;&#36845;&#20195;&#26041;&#27861;&#30340;&#19968;&#31181;&#37325;&#35201;&#34917;&#20805;&#12290;</title><link>http://arxiv.org/abs/2401.05394</link><description>&lt;p&gt;
&#36845;&#20195;&#27491;&#21017;&#21270;&#19982;k&#25903;&#25745;&#33539;&#25968;&#65306;&#31232;&#30095;&#24674;&#22797;&#30340;&#37325;&#35201;&#34917;&#20805;
&lt;/p&gt;
&lt;p&gt;
Iterative Regularization with k-Support Norm: an Important Complement to Sparse Recovery. (arXiv:2401.05394v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05394
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#36845;&#20195;&#27491;&#21017;&#21270;&#31639;&#27861;IRKSN&#65292;&#23427;&#36890;&#36807;&#20351;&#29992;$k$&#25903;&#25745;&#33539;&#25968;&#27491;&#21017;&#21270;&#23454;&#29616;&#31232;&#30095;&#24674;&#22797;&#65292;&#24182;&#25552;&#20379;&#20102;&#26465;&#20214;&#12290;&#36825;&#26159;&#23545;&#22522;&#20110;$\ell_1$&#33539;&#25968;&#30340;&#36845;&#20195;&#26041;&#27861;&#30340;&#19968;&#31181;&#37325;&#35201;&#34917;&#20805;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#24674;&#22797;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#20449;&#21495;&#22788;&#29702;&#20013;&#26080;&#22788;&#19981;&#22312;&#12290;&#30001;&#20110;&#31232;&#30095;&#24674;&#22797;&#30340;NP&#22256;&#38590;&#24615;&#36136;&#65292;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#35201;&#20040;&#21463;&#38480;&#20110;&#36866;&#29992;&#26465;&#20214;&#65288;&#29978;&#33267;&#26410;&#30693;&#65289;&#65292;&#35201;&#20040;&#35745;&#31639;&#25104;&#26412;&#39640;&#12290;&#26368;&#36817;&#65292;&#36845;&#20195;&#27491;&#21017;&#21270;&#26041;&#27861;&#20316;&#20026;&#19968;&#31181;&#24555;&#36895;&#26041;&#27861;&#20986;&#29616;&#65292;&#22240;&#20026;&#23427;&#20204;&#21487;&#20197;&#36890;&#36807;&#25552;&#21069;&#20572;&#27490;&#19968;&#27425;&#36890;&#36807;&#26469;&#23454;&#29616;&#31232;&#30095;&#24674;&#22797;&#65292;&#32780;&#19981;&#26159;&#20256;&#32479;&#26041;&#27861;&#20013;&#32321;&#29712;&#30340;&#32593;&#26684;&#25628;&#32034;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#36825;&#20123;&#36845;&#20195;&#26041;&#27861;&#37117;&#22522;&#20110;$\ell_1$&#33539;&#25968;&#65292;&#38656;&#35201;&#21463;&#38480;&#30340;&#36866;&#29992;&#26465;&#20214;&#65292;&#24182;&#19988;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#21487;&#33021;&#20250;&#22833;&#36133;&#12290;&#22240;&#27492;&#65292;&#36845;&#20195;&#27491;&#21017;&#21270;&#26041;&#27861;&#22312;&#26356;&#24191;&#27867;&#30340;&#26465;&#20214;&#19979;&#23454;&#29616;&#31232;&#30095;&#24674;&#22797;&#20173;&#38656;&#36827;&#19968;&#27493;&#25506;&#32034;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36845;&#20195;&#27491;&#21017;&#21270;&#31639;&#27861;IRKSN&#65292;&#23427;&#22522;&#20110;$k$&#25903;&#25745;&#33539;&#25968;&#27491;&#21017;&#21270;&#32780;&#19981;&#26159;$\ell_1$&#33539;&#25968;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20351;&#29992;IRKSN&#36827;&#34892;&#31232;&#30095;&#24674;&#22797;&#30340;&#26465;&#20214;&#65292;&#24182;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse recovery is ubiquitous in machine learning and signal processing. Due to the NP-hard nature of sparse recovery, existing methods are known to suffer either from restrictive (or even unknown) applicability conditions, or high computational cost. Recently, iterative regularization methods have emerged as a promising fast approach because they can achieve sparse recovery in one pass through early stopping, rather than the tedious grid-search used in the traditional methods. However, most of those iterative methods are based on the $\ell_1$ norm which requires restrictive applicability conditions and could fail in many cases. Therefore, achieving sparse recovery with iterative regularization methods under a wider range of conditions has yet to be further explored. To address this issue, we propose a novel iterative regularization algorithm, IRKSN, based on the $k$-support norm regularizer rather than the $\ell_1$ norm. We provide conditions for sparse recovery with IRKSN, and compar
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#31639;&#23376;&#27969;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#36817;&#20284;&#26102;&#38388;&#30456;&#20851;&#31639;&#23376;&#65292;&#23454;&#29616;&#20102;&#22312;&#37327;&#23376;&#22330;&#35770;&#20013;&#20174;&#24213;&#23618;&#33258;&#30001;&#29702;&#35770;&#21040;&#30446;&#26631;&#29702;&#35770;&#30340;&#31163;&#25955;-&#36830;&#32493;&#24402;&#19968;&#21270;&#27969;&#12290;</title><link>http://arxiv.org/abs/2401.00828</link><description>&lt;p&gt;
&#22522;&#20110;&#31070;&#32463;&#31639;&#23376;&#27969;&#30340;&#37327;&#23376;&#22330;&#35770;&#22810;&#26684;&#37319;&#26679;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Multi-Lattice Sampling of Quantum Field Theories via Neural Operator-based Flows. (arXiv:2401.00828v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.00828
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#31639;&#23376;&#27969;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#36817;&#20284;&#26102;&#38388;&#30456;&#20851;&#31639;&#23376;&#65292;&#23454;&#29616;&#20102;&#22312;&#37327;&#23376;&#22330;&#35770;&#20013;&#20174;&#24213;&#23618;&#33258;&#30001;&#29702;&#35770;&#21040;&#30446;&#26631;&#29702;&#35770;&#30340;&#31163;&#25955;-&#36830;&#32493;&#24402;&#19968;&#21270;&#27969;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20174;&#29627;&#23572;&#20857;&#26364;&#20998;&#24067;&#20013;&#37319;&#26679;&#31163;&#25955;&#22330;&#37197;&#32622;$\phi$&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;$S$&#26159;&#26576;&#20010;&#37327;&#23376;&#22330;&#35770;&#36830;&#32493;&#27431;&#20960;&#37324;&#24471;&#20316;&#29992;$\mathcal S$&#30340;&#26684;&#28857;&#31163;&#25955;&#21270;&#12290;&#25105;&#20204;&#23558;&#35813;&#23494;&#24230;&#36817;&#20284;&#35270;&#20026;&#24213;&#23618;&#20989;&#25968;&#23494;&#24230;$[\mathcal D\phi(x)]\mathcal Z^{-1}e^{-\mathcal S[\phi(x)]}$&#30340;&#23398;&#20064;&#31639;&#23376;&#23454;&#20363;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36817;&#20284;&#26102;&#38388;&#30456;&#20851;&#31639;&#23376;$\mathcal V_t$&#30340;&#26041;&#27861;&#65292;&#20854;&#26102;&#38388;&#31215;&#20998;&#25552;&#20379;&#20102;&#33258;&#30001;&#29702;&#35770;$[\mathcal D\phi(x)]\mathcal Z_0^{-1}e^{-\mathcal S_{0}[\phi(x)]}$&#30340;&#20989;&#25968;&#20998;&#24067;&#19982;&#30446;&#26631;&#29702;&#35770;$[\mathcal D\phi(x)]\mathcal Z^{-1}e^{-\mathcal S[\phi(x)]}$&#20043;&#38388;&#30340;&#26144;&#23556;&#12290;&#24403;&#36873;&#25321;&#29305;&#23450;&#30340;&#26684;&#28857;&#26102;&#65292;&#31639;&#23376;$\mathcal V_t$&#21487;&#20197;&#31163;&#25955;&#21270;&#20026;&#26377;&#38480;&#32500;&#30340;&#26102;&#38388;&#30456;&#20851;&#30690;&#37327;&#22330;$V_t$&#65292;&#20174;&#32780;&#22312;&#31163;&#25955;&#26684;&#28857;&#19978;&#23454;&#29616;&#20102;&#36830;&#32493;&#30340;&#24402;&#19968;&#21270;&#27969;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of sampling discrete field configurations $\phi$ from the Boltzmann distribution $[d\phi] Z^{-1} e^{-S[\phi]}$, where $S$ is the lattice-discretization of the continuous Euclidean action $\mathcal S$ of some quantum field theory. Since such densities arise as the approximation of the underlying functional density $[\mathcal D\phi(x)] \mathcal Z^{-1} e^{-\mathcal S[\phi(x)]}$, we frame the task as an instance of operator learning. In particular, we propose to approximate a time-dependent operator $\mathcal V_t$ whose time integral provides a mapping between the functional distributions of the free theory $[\mathcal D\phi(x)] \mathcal Z_0^{-1} e^{-\mathcal S_{0}[\phi(x)]}$ and of the target theory $[\mathcal D\phi(x)]\mathcal Z^{-1}e^{-\mathcal S[\phi(x)]}$. Whenever a particular lattice is chosen, the operator $\mathcal V_t$ can be discretized to a finite dimensional, time-dependent vector field $V_t$ which in turn induces a continuous normalizing flow between fi
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#23376;&#31354;&#38388;&#21644;&#23376;&#25277;&#26679;&#38598;&#21512;&#30340;Dirichlet&#36807;&#31243;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#26080;&#30417;&#30563;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#65292;&#25552;&#39640;&#20102;&#35745;&#31639;&#25928;&#29575;&#21644;&#26816;&#27979;&#22120;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.00773</link><description>&lt;p&gt;
&#20351;&#29992;&#38543;&#26426;&#23376;&#31354;&#38388;&#21644;Dirichlet&#36807;&#31243;&#28151;&#21512;&#27169;&#22411;&#30340;&#23376;&#25277;&#26679;&#38598;&#21512;&#36827;&#34892;&#26080;&#30417;&#30563;&#24322;&#24120;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Unsupervised Outlier Detection using Random Subspace and Subsampling Ensembles of Dirichlet Process Mixtures. (arXiv:2401.00773v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.00773
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#23376;&#31354;&#38388;&#21644;&#23376;&#25277;&#26679;&#38598;&#21512;&#30340;Dirichlet&#36807;&#31243;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#26080;&#30417;&#30563;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#65292;&#25552;&#39640;&#20102;&#35745;&#31639;&#25928;&#29575;&#21644;&#26816;&#27979;&#22120;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27010;&#29575;&#28151;&#21512;&#27169;&#22411;&#34987;&#35748;&#20026;&#26159;&#19968;&#31181;&#26377;&#20215;&#20540;&#30340;&#24037;&#20855;&#65292;&#29992;&#20110;&#26080;&#30417;&#30563;&#24322;&#24120;&#26816;&#27979;&#65292;&#22240;&#20026;&#23427;&#20204;&#20855;&#26377;&#35299;&#37322;&#24615;&#65292;&#24182;&#19988;&#22312;&#32479;&#35745;&#21407;&#29702;&#19978;&#26377;&#30452;&#35266;&#22522;&#30784;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#20869;&#65292;Dirichlet&#36807;&#31243;&#28151;&#21512;&#27169;&#22411;&#20316;&#20026;&#20256;&#32479;&#26377;&#38480;&#28151;&#21512;&#27169;&#22411;&#22312;&#32858;&#31867;&#21644;&#24322;&#24120;&#26816;&#27979;&#20219;&#21153;&#20013;&#30340;&#19968;&#20010;&#24341;&#20154;&#27880;&#30446;&#30340;&#26367;&#20195;&#36873;&#25321;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#23427;&#20204;&#26126;&#26174;&#20855;&#26377;&#20248;&#21183;&#65292;&#20294;&#22312;&#26080;&#30417;&#30563;&#24322;&#24120;&#26816;&#27979;&#20013;&#24191;&#27867;&#37319;&#29992;Dirichlet&#36807;&#31243;&#28151;&#21512;&#27169;&#22411;&#21463;&#21040;&#19982;&#26500;&#24314;&#26816;&#27979;&#22120;&#36807;&#31243;&#20013;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#23545;&#24322;&#24120;&#20540;&#30340;&#25935;&#24863;&#24615;&#26377;&#20851;&#30340;&#25361;&#25112;&#30340;&#38459;&#30861;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Dirichlet&#36807;&#31243;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#38598;&#21512;&#30340;&#26032;&#22411;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#26159;&#19968;&#31181;&#23436;&#20840;&#26080;&#30417;&#30563;&#30340;&#31639;&#27861;&#65292;&#21033;&#29992;&#20102;&#38543;&#26426;&#23376;&#31354;&#38388;&#21644;&#23376;&#25277;&#26679;&#38598;&#21512;&#65292;&#19981;&#20165;&#30830;&#20445;&#20102;&#39640;&#25928;&#35745;&#31639;&#65292;&#36824;&#22686;&#24378;&#20102;&#32467;&#26524;&#24322;&#24120;&#26816;&#27979;&#22120;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Probabilistic mixture models are acknowledged as a valuable tool for unsupervised outlier detection owing to their interpretability and intuitive grounding in statistical principles. Within this framework, Dirichlet process mixture models emerge as a compelling alternative to conventional finite mixture models for both clustering and outlier detection tasks. However, despite their evident advantages, the widespread adoption of Dirichlet process mixture models in unsupervised outlier detection has been hampered by challenges related to computational inefficiency and sensitivity to outliers during the construction of detectors. To tackle these challenges, we propose a novel outlier detection method based on ensembles of Dirichlet process Gaussian mixtures. The proposed method is a fully unsupervised algorithm that capitalizes on random subspace and subsampling ensembles, not only ensuring efficient computation but also enhancing the robustness of the resulting outlier detector. Moreover,
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25506;&#35752;&#20102;&#22914;&#20309;&#21033;&#29992;&#20844;&#20849;&#25968;&#25454;&#26469;&#25913;&#36827;&#31169;&#26377;&#23398;&#20064;&#30340;&#38382;&#39064;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#36890;&#36807;&#23398;&#20064;&#20844;&#20849;&#25968;&#25454;&#20013;&#30340;&#20849;&#20139;&#34920;&#31034;&#65292;&#21487;&#20197;&#22312;&#20004;&#31181;&#36801;&#31227;&#23398;&#20064;&#22330;&#26223;&#20013;&#23454;&#29616;&#26368;&#20248;&#30340;&#23398;&#20064;&#25928;&#26524;&#12290;&#22312;&#21333;&#20219;&#21153;&#36801;&#31227;&#22330;&#26223;&#20013;&#65292;&#31639;&#27861;&#22312;&#32473;&#23450;&#23376;&#31354;&#38388;&#33539;&#22260;&#20869;&#25628;&#32034;&#32447;&#24615;&#27169;&#22411;&#65292;&#24182;&#23454;&#29616;&#20102;&#26368;&#20248;&#36229;&#39069;&#39118;&#38505;&#12290;&#22312;&#22810;&#20219;&#21153;&#20010;&#24615;&#21270;&#22330;&#26223;&#20013;&#65292;&#36275;&#22815;&#30340;&#20844;&#20849;&#25968;&#25454;&#21487;&#20197;&#28040;&#38500;&#31169;&#26377;&#21327;&#35843;&#38656;&#27714;&#65292;&#24182;&#36890;&#36807;&#32431;&#23616;&#37096;&#23398;&#20064;&#36798;&#21040;&#30456;&#21516;&#30340;&#25928;&#29992;&#12290;</title><link>http://arxiv.org/abs/2312.15551</link><description>&lt;p&gt;
&#21033;&#29992;&#20844;&#20849;&#34920;&#31034;&#26469;&#36827;&#34892;&#31169;&#26377;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Leveraging Public Representations for Private Transfer Learning. (arXiv:2312.15551v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.15551
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25506;&#35752;&#20102;&#22914;&#20309;&#21033;&#29992;&#20844;&#20849;&#25968;&#25454;&#26469;&#25913;&#36827;&#31169;&#26377;&#23398;&#20064;&#30340;&#38382;&#39064;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#36890;&#36807;&#23398;&#20064;&#20844;&#20849;&#25968;&#25454;&#20013;&#30340;&#20849;&#20139;&#34920;&#31034;&#65292;&#21487;&#20197;&#22312;&#20004;&#31181;&#36801;&#31227;&#23398;&#20064;&#22330;&#26223;&#20013;&#23454;&#29616;&#26368;&#20248;&#30340;&#23398;&#20064;&#25928;&#26524;&#12290;&#22312;&#21333;&#20219;&#21153;&#36801;&#31227;&#22330;&#26223;&#20013;&#65292;&#31639;&#27861;&#22312;&#32473;&#23450;&#23376;&#31354;&#38388;&#33539;&#22260;&#20869;&#25628;&#32034;&#32447;&#24615;&#27169;&#22411;&#65292;&#24182;&#23454;&#29616;&#20102;&#26368;&#20248;&#36229;&#39069;&#39118;&#38505;&#12290;&#22312;&#22810;&#20219;&#21153;&#20010;&#24615;&#21270;&#22330;&#26223;&#20013;&#65292;&#36275;&#22815;&#30340;&#20844;&#20849;&#25968;&#25454;&#21487;&#20197;&#28040;&#38500;&#31169;&#26377;&#21327;&#35843;&#38656;&#27714;&#65292;&#24182;&#36890;&#36807;&#32431;&#23616;&#37096;&#23398;&#20064;&#36798;&#21040;&#30456;&#21516;&#30340;&#25928;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#21040;&#23558;&#20844;&#20849;&#25968;&#25454;&#32435;&#20837;&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;&#30340;&#26368;&#26032;&#23454;&#35777;&#25104;&#21151;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;&#20174;&#20844;&#20849;&#25968;&#25454;&#20013;&#23398;&#21040;&#30340;&#20849;&#20139;&#34920;&#31034;&#22914;&#20309;&#25913;&#36827;&#31169;&#26377;&#23398;&#20064;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#32447;&#24615;&#22238;&#24402;&#30340;&#20004;&#31181;&#24120;&#35265;&#36801;&#31227;&#23398;&#20064;&#22330;&#26223;&#65292;&#20004;&#32773;&#37117;&#20551;&#35774;&#20844;&#20849;&#20219;&#21153;&#21644;&#31169;&#26377;&#20219;&#21153;&#65288;&#22238;&#24402;&#21521;&#37327;&#65289;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#20849;&#20139;&#19968;&#20010;&#20302;&#31209;&#23376;&#31354;&#38388;&#12290;&#22312;&#31532;&#19968;&#31181;&#21333;&#20219;&#21153;&#36801;&#31227;&#22330;&#26223;&#20013;&#65292;&#30446;&#26631;&#26159;&#23398;&#20064;&#19968;&#20010;&#22312;&#25152;&#26377;&#29992;&#25143;&#20043;&#38388;&#20849;&#20139;&#30340;&#21333;&#19968;&#27169;&#22411;&#65292;&#27599;&#20010;&#29992;&#25143;&#23545;&#24212;&#25968;&#25454;&#38598;&#20013;&#30340;&#19968;&#34892;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#21305;&#37197;&#30340;&#19978;&#19979;&#30028;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#32473;&#23450;&#23376;&#31354;&#38388;&#20272;&#35745;&#33539;&#22260;&#20869;&#25628;&#32034;&#32447;&#24615;&#27169;&#22411;&#30340;&#31639;&#27861;&#31867;&#20013;&#23454;&#29616;&#20102;&#26368;&#20248;&#36229;&#39069;&#39118;&#38505;&#12290;&#22312;&#22810;&#20219;&#21153;&#27169;&#22411;&#20010;&#24615;&#21270;&#30340;&#31532;&#20108;&#31181;&#24773;&#26223;&#20013;&#65292;&#25105;&#20204;&#34920;&#26126;&#22312;&#26377;&#36275;&#22815;&#30340;&#20844;&#20849;&#25968;&#25454;&#24773;&#20917;&#19979;&#65292;&#29992;&#25143;&#21487;&#20197;&#36991;&#20813;&#31169;&#26377;&#21327;&#35843;&#65292;&#22240;&#20026;&#22312;&#32473;&#23450;&#23376;&#31354;&#38388;&#20869;&#32431;&#31929;&#30340;&#23616;&#37096;&#23398;&#20064;&#21487;&#20197;&#36798;&#21040;&#30456;&#21516;&#30340;&#25928;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by the recent empirical success of incorporating public data into differentially private learning, we theoretically investigate how a shared representation learned from public data can improve private learning. We explore two common scenarios of transfer learning for linear regression, both of which assume the public and private tasks (regression vectors) share a low-rank subspace in a high-dimensional space. In the first single-task transfer scenario, the goal is to learn a single model shared across all users, each corresponding to a row in a dataset. We provide matching upper and lower bounds showing that our algorithm achieves the optimal excess risk within a natural class of algorithms that search for the linear model within the given subspace estimate. In the second scenario of multitask model personalization, we show that with sufficient public data, users can avoid private coordination, as purely local learning within the given subspace achieves the same utility. Take
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21160;&#24577;&#27491;&#21017;&#21270;&#27969;&#30340;&#21464;&#31181;&#65292;&#21363;&#26102;&#38388;&#21464;&#25442;&#27491;&#21017;&#21270;&#27969;(TCNF)&#65292;&#36890;&#36807;&#26102;&#38388;&#21464;&#24418;&#30340;&#26041;&#27861;&#33021;&#26377;&#25928;&#22320;&#24314;&#27169;&#19968;&#20123;&#26080;&#27861;&#29992;&#20854;&#20182;&#26041;&#27861;&#24314;&#27169;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;(SDEs)&#65292;&#21253;&#25324;&#33879;&#21517;&#30340;&#22885;&#24681;&#26031;&#22374;-&#20044;&#20262;&#36125;&#20811;&#36807;&#31243;&#65292;&#24182;&#27867;&#21270;&#20102;&#20808;&#21069;&#30340;&#26041;&#27861;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#32467;&#26524;&#30340;&#20934;&#30830;&#24230;&#21644;&#25512;&#26029;&#21644;&#39044;&#27979;&#30340;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2312.14698</link><description>&lt;p&gt;
&#20934;&#30830;&#24314;&#27169;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#26102;&#38388;&#21464;&#25442;&#27491;&#21017;&#21270;&#27969;
&lt;/p&gt;
&lt;p&gt;
Time-changed normalizing flows for accurate SDE modeling. (arXiv:2312.14698v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.14698
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21160;&#24577;&#27491;&#21017;&#21270;&#27969;&#30340;&#21464;&#31181;&#65292;&#21363;&#26102;&#38388;&#21464;&#25442;&#27491;&#21017;&#21270;&#27969;(TCNF)&#65292;&#36890;&#36807;&#26102;&#38388;&#21464;&#24418;&#30340;&#26041;&#27861;&#33021;&#26377;&#25928;&#22320;&#24314;&#27169;&#19968;&#20123;&#26080;&#27861;&#29992;&#20854;&#20182;&#26041;&#27861;&#24314;&#27169;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;(SDEs)&#65292;&#21253;&#25324;&#33879;&#21517;&#30340;&#22885;&#24681;&#26031;&#22374;-&#20044;&#20262;&#36125;&#20811;&#36807;&#31243;&#65292;&#24182;&#27867;&#21270;&#20102;&#20808;&#21069;&#30340;&#26041;&#27861;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#32467;&#26524;&#30340;&#20934;&#30830;&#24230;&#21644;&#25512;&#26029;&#21644;&#39044;&#27979;&#30340;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#33539;&#24335;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20013;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#20854;&#20013;&#27969;&#34892;&#30340;&#29983;&#25104;&#27169;&#22411;&#20043;&#19968;&#26159;&#27491;&#21017;&#21270;&#27969;&#65292;&#36890;&#36807;&#24494;&#20998;&#21516;&#32986;&#21464;&#25442;&#23558;&#22522;&#26412;&#20998;&#24067;&#36716;&#21464;&#20026;&#20934;&#30830;&#20272;&#35745;&#30340;&#20284;&#28982;&#20989;&#25968;&#12290;&#23558;&#27491;&#21017;&#21270;&#27969;&#26694;&#26550;&#25193;&#23637;&#21040;&#22788;&#29702;&#26102;&#38388;&#32034;&#24341;&#27969;&#20135;&#29983;&#21160;&#24577;&#27491;&#21017;&#21270;&#27969;&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#27169;&#25311;&#26102;&#38388;&#24207;&#21015;&#12289;&#38543;&#26426;&#36807;&#31243;&#21644;&#31070;&#32463;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;(SDEs)&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21160;&#24577;&#27491;&#21017;&#21270;&#27969;&#21464;&#20307;&#65292;&#21363;&#26102;&#38388;&#21464;&#25442;&#27491;&#21017;&#21270;&#27969;(TCNF)&#65292;&#23427;&#22522;&#20110;&#24067;&#26391;&#36816;&#21160;&#30340;&#26102;&#38388;&#21464;&#24418;&#65292;&#26500;&#25104;&#20102;&#19968;&#26063;&#22810;&#25165;&#22810;&#33402;&#30340;&#39640;&#26031;&#36807;&#31243;&#12290;&#36825;&#31181;&#26041;&#27861;&#20351;&#25105;&#20204;&#33021;&#22815;&#26377;&#25928;&#22320;&#27169;&#25311;&#19968;&#20123;&#26080;&#27861;&#20351;&#29992;&#20854;&#20182;&#26041;&#27861;&#24314;&#27169;&#30340;SDEs&#65292;&#21253;&#25324;&#33879;&#21517;&#30340;&#22885;&#24681;&#26031;&#22374;-&#20044;&#20262;&#36125;&#20811;&#36807;&#31243;&#20197;&#21450;&#27867;&#21270;&#20102;&#20808;&#21069;&#30340;&#26041;&#27861;&#65292;&#20174;&#32780;&#25552;&#20379;&#20102;&#25913;&#36827;&#30340;&#32467;&#26524;&#21644;&#26356;&#22909;&#30340;&#25512;&#26029;&#21644;&#39044;&#27979;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
The generative paradigm has become increasingly important in machine learning and deep learning models. Among popular generative models are normalizing flows, which enable exact likelihood estimation by transforming a base distribution through diffeomorphic transformations. Extending the normalizing flow framework to handle time-indexed flows gave dynamic normalizing flows, a powerful tool to model time series, stochastic processes, and neural stochastic differential equations (SDEs). In this work, we propose a novel variant of dynamic normalizing flows, a Time Changed Normalizing Flow (TCNF), based on time deformation of a Brownian motion which constitutes a versatile and extensive family of Gaussian processes. This approach enables us to effectively model some SDEs, that cannot be modeled otherwise, including standard ones such as the well-known Ornstein-Uhlenbeck process, and generalizes prior methodologies, leading to improved results and better inference and prediction capability.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#38598;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#24341;&#20837;&#21464;&#20998;&#25512;&#29702;&#26694;&#26550;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#39640;&#26031;&#36807;&#31243;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#24182;&#19988;&#26377;&#25928;&#22320;&#21033;&#29992;&#20102;&#28508;&#22312;&#29366;&#24577;&#21644;&#21160;&#21147;&#23398;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#20943;&#23569;&#20102;&#21464;&#20998;&#21442;&#25968;&#30340;&#25968;&#37327;&#12290;</title><link>http://arxiv.org/abs/2312.05910</link><description>&lt;p&gt;
&#38598;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#19982;&#39640;&#26031;&#36807;&#31243;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#22312;&#38750;&#22343;&#22330;&#21644;&#22312;&#32447;&#25512;&#29702;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Ensemble Kalman Filtering Meets Gaussian Process SSM for Non-Mean-Field and Online Inference. (arXiv:2312.05910v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.05910
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#38598;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#24341;&#20837;&#21464;&#20998;&#25512;&#29702;&#26694;&#26550;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#39640;&#26031;&#36807;&#31243;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#24182;&#19988;&#26377;&#25928;&#22320;&#21033;&#29992;&#20102;&#28508;&#22312;&#29366;&#24577;&#21644;&#21160;&#21147;&#23398;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#20943;&#23569;&#20102;&#21464;&#20998;&#21442;&#25968;&#30340;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65288;GPSSMs&#65289;&#26159;&#19968;&#31181;&#22810;&#21151;&#33021;&#21644;&#21407;&#21017;&#24615;&#30340;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;GPSSMs&#21464;&#20998;&#23398;&#20064;&#21644;&#25512;&#29702;&#26041;&#27861;&#36890;&#24120;&#38656;&#35201;&#20248;&#21270;&#22823;&#37327;&#21464;&#20998;&#21442;&#25968;&#65292;&#23548;&#33268;&#24615;&#33021;&#21644;&#25928;&#29575;&#19981;&#36275;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#23558;&#38598;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#65288;EnKF&#65289;&#65292;&#19968;&#31181;&#25104;&#29087;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#28388;&#27874;&#25216;&#26415;&#65292;&#32435;&#20837;&#21464;&#20998;&#25512;&#29702;&#26694;&#26550;&#20013;&#65292;&#20197;&#36817;&#20284;&#28508;&#22312;&#29366;&#24577;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#36825;&#31181;&#21033;&#29992;EnKF&#30340;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#22320;&#21033;&#29992;&#28508;&#22312;&#29366;&#24577;&#21644;GP&#21160;&#21147;&#23398;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#21516;&#26102;&#28040;&#38500;&#20102;&#23545;&#21464;&#20998;&#20998;&#24067;&#36827;&#34892;&#21442;&#25968;&#21270;&#30340;&#38656;&#27714;&#65292;&#20174;&#32780;&#26174;&#33879;&#20943;&#23569;&#20102;&#21464;&#20998;&#21442;&#25968;&#30340;&#25968;&#37327;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#21487;&#20197;&#36890;&#36807;&#31616;&#21333;&#22320;&#23545;&#22810;&#20010;&#39033;&#36827;&#34892;&#27714;&#21644;&#26469;&#30452;&#25509;&#35780;&#20272;&#21464;&#20998;&#25512;&#29702;&#20013;&#30340;&#36817;&#20284;&#35777;&#25454;&#19979;&#30028;&#65288;ELBO&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian process state-space models (GPSSMs) are a versatile and principled family of nonlinear dynamical system models. However, existing variational learning and inference methods for GPSSMs often necessitate optimizing a substantial number of variational parameters, leading to inadequate performance and efficiency. To overcome this issue, we propose incorporating the ensemble Kalman filter (EnKF), a well-established model-based filtering technique, into the variational inference framework to approximate the posterior distribution of latent states. This utilization of EnKF can effectively exploit the dependencies between latent states and GP dynamics, while eliminating the need for parameterizing the variational distribution, thereby significantly reducing the number of variational parameters. Moreover, we show that our proposed algorithm allows straightforward evaluation of an approximated evidence lower bound (ELBO) in variational inference via simply summating multiple terms with 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32771;&#34385;&#20219;&#21153;&#23545;&#31216;&#24615;&#30340;&#21487;&#35777;&#26126;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#27010;&#24565;&#65292;&#24182;&#36890;&#36807;&#36873;&#25321;&#21512;&#36866;&#30340;&#27169;&#22411;&#21644;&#35748;&#35777;&#26041;&#27861;&#26469;&#23454;&#29616;&#40065;&#26834;&#24615;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#24320;&#21457;&#20445;&#25345;&#23545;&#31216;&#24615;&#30340;&#38543;&#26426;&#24179;&#28369;&#30340;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#23545;&#20110;&#20855;&#26377;&#36830;&#32493;&#23545;&#31216;&#24615;&#30340;&#27169;&#22411;&#30340;&#35748;&#35777;&#26041;&#27861;&#19981;&#21487;&#29992;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2312.02708</link><description>&lt;p&gt;
&#21487;&#35777;&#26126;&#30340;&#23545;&#31216;&#20219;&#21153;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#65306;&#22270;&#24418;&#12289;&#28857;&#20113;&#12289;&#20998;&#23376;&#31561;
&lt;/p&gt;
&lt;p&gt;
Provable Adversarial Robustness for Group Equivariant Tasks: Graphs, Point Clouds, Molecules, and More. (arXiv:2312.02708v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.02708
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32771;&#34385;&#20219;&#21153;&#23545;&#31216;&#24615;&#30340;&#21487;&#35777;&#26126;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#27010;&#24565;&#65292;&#24182;&#36890;&#36807;&#36873;&#25321;&#21512;&#36866;&#30340;&#27169;&#22411;&#21644;&#35748;&#35777;&#26041;&#27861;&#26469;&#23454;&#29616;&#40065;&#26834;&#24615;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#24320;&#21457;&#20445;&#25345;&#23545;&#31216;&#24615;&#30340;&#38543;&#26426;&#24179;&#28369;&#30340;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#23545;&#20110;&#20855;&#26377;&#36830;&#32493;&#23545;&#31216;&#24615;&#30340;&#27169;&#22411;&#30340;&#35748;&#35777;&#26041;&#27861;&#19981;&#21487;&#29992;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#19978;&#65292;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#34987;&#35748;&#20026;&#22312;&#36755;&#20837;&#25200;&#21160;&#30340;&#24773;&#20917;&#19979;&#20445;&#25345;&#65288;&#20960;&#20046;&#65289;&#24658;&#23450;&#30340;&#39044;&#27979;&#26159;&#20581;&#22766;&#30340;&#12290;&#28982;&#32780;&#65292;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#20219;&#21153;&#65292;&#22914;&#20998;&#23376;&#24615;&#36136;&#39044;&#27979;&#25110;&#28857;&#20113;&#20998;&#21106;&#65292;&#20855;&#26377;&#22266;&#26377;&#30340;&#23545;&#31216;&#24615;&#65292;&#22914;&#26059;&#36716;&#25110;&#32622;&#25442;&#23545;&#31216;&#24615;&#12290;&#22312;&#36825;&#20123;&#20219;&#21153;&#20013;&#65292;&#21363;&#20351;&#26159;&#20855;&#26377;&#22823;&#33539;&#25968;&#30340;&#25200;&#21160;&#20063;&#19981;&#19968;&#23450;&#20250;&#25913;&#21464;&#36755;&#20837;&#30340;&#35821;&#20041;&#20869;&#23481;&#12290;&#27492;&#22806;&#65292;&#26377;&#20123;&#25200;&#21160;&#38656;&#35201;&#26126;&#30830;&#25913;&#21464;&#27169;&#22411;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#39318;&#27425;&#25552;&#20986;&#20102;&#19968;&#31181;&#32771;&#34385;&#20219;&#21153;&#23545;&#31216;&#24615;&#30340;&#21487;&#38752;&#23545;&#25239;&#40065;&#26834;&#24615;&#27010;&#24565;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21487;&#20197;&#36890;&#36807;&#36873;&#25321;&#19982;&#20219;&#21153;&#23545;&#31216;&#24615;&#30456;&#21305;&#37197;&#30340;&#27169;&#22411;&#21644;&#35748;&#35777;&#20256;&#32479;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#26469;&#23454;&#29616;&#21487;&#35777;&#26126;&#30340;&#40065;&#26834;&#24615;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#35768;&#22810;&#20855;&#26377;&#36830;&#32493;&#23545;&#31216;&#24615;&#30340;&#27169;&#22411;&#65292;&#35748;&#35777;&#26041;&#27861;&#19981;&#21487;&#29992;&#12290;&#36890;&#36807;&#24320;&#21457;&#20445;&#25345;&#23545;&#31216;&#24615;&#30340;&#38543;&#26426;&#24179;&#28369;&#30340;&#26694;&#26550;&#65292;&#25105;&#20204;&#22635;&#34917;&#20102;&#36825;&#20010;&#31354;&#30333;&#12290;
&lt;/p&gt;
&lt;p&gt;
A machine learning model is traditionally considered robust if its prediction remains (almost) constant under input perturbations with small norm. However, real-world tasks like molecular property prediction or point cloud segmentation have inherent equivariances, such as rotation or permutation equivariance. In such tasks, even perturbations with large norm do not necessarily change an input's semantic content. Furthermore, there are perturbations for which a model's prediction explicitly needs to change. For the first time, we propose a sound notion of adversarial robustness that accounts for task equivariance. We then demonstrate that provable robustness can be achieved by (1) choosing a model that matches the task's equivariances (2) certifying traditional adversarial robustness. Certification methods are, however, unavailable for many models, such as those with continuous equivariances. We close this gap by developing the framework of equivariance-preserving randomized smoothing, 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#32452;&#22810;&#20803;&#20989;&#25968;&#22238;&#24402;&#27169;&#22411;&#65292;&#20854;&#20013;&#37319;&#29992;&#20102;&#19968;&#31181;&#26032;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#26469;&#35299;&#20915;&#19981;&#21516;&#20989;&#25968;&#21327;&#21464;&#37327;&#30340;&#28508;&#22312;&#21516;&#36136;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2312.01925</link><description>&lt;p&gt;
&#22312;&#22810;&#20803;&#20989;&#25968;&#22238;&#24402;&#20013;&#30340;&#31995;&#25968;&#24418;&#29366;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Coefficient Shape Alignment in Multivariate Functional Regression. (arXiv:2312.01925v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.01925
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#32452;&#22810;&#20803;&#20989;&#25968;&#22238;&#24402;&#27169;&#22411;&#65292;&#20854;&#20013;&#37319;&#29992;&#20102;&#19968;&#31181;&#26032;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#26469;&#35299;&#20915;&#19981;&#21516;&#20989;&#25968;&#21327;&#21464;&#37327;&#30340;&#28508;&#22312;&#21516;&#36136;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#20803;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#20013;&#65292;&#19981;&#21516;&#30340;&#20989;&#25968;&#21327;&#21464;&#37327;&#21487;&#33021;&#20855;&#26377;&#21516;&#36136;&#24615;&#12290;&#38544;&#34255;&#30340;&#21516;&#36136;&#24615;&#32467;&#26500;&#23545;&#20110;&#19981;&#21516;&#21327;&#21464;&#37327;&#30340;&#36830;&#25509;&#25110;&#20851;&#32852;&#20855;&#26377;&#20449;&#24687;&#20215;&#20540;&#12290;&#20855;&#26377;&#26126;&#26174;&#21516;&#36136;&#24615;&#30340;&#21327;&#21464;&#37327;&#21487;&#20197;&#22312;&#21516;&#19968;&#32676;&#32452;&#20013;&#36827;&#34892;&#32852;&#21512;&#20998;&#26512;&#65292;&#20174;&#32780;&#20135;&#29983;&#19968;&#31181;&#31616;&#21270;&#24314;&#27169;&#22810;&#20803;&#20989;&#25968;&#25968;&#25454;&#30340;&#26041;&#27861;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#32452;&#22810;&#20803;&#20989;&#25968;&#22238;&#24402;&#27169;&#22411;&#65292;&#37319;&#29992;&#31216;&#20026;&#8220;&#31995;&#25968;&#24418;&#29366;&#23545;&#40784;&#8221;&#30340;&#26032;&#27491;&#21017;&#21270;&#26041;&#27861;&#26469;&#35299;&#20915;&#19981;&#21516;&#20989;&#25968;&#21327;&#21464;&#37327;&#30340;&#28508;&#22312;&#21516;&#36136;&#24615;&#38382;&#39064;&#12290;&#24314;&#27169;&#36807;&#31243;&#21253;&#25324;&#20004;&#20010;&#20027;&#35201;&#27493;&#39588;&#65306;&#39318;&#20808;&#65292;&#20351;&#29992;&#26032;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#26816;&#27979;&#26410;&#30693;&#20998;&#32452;&#32467;&#26500;&#65292;&#23558;&#21327;&#21464;&#37327;&#32858;&#21512;&#21040;&#19981;&#30456;&#20132;&#30340;&#32676;&#32452;&#20013;&#65307;&#28982;&#21518;&#65292;&#22522;&#20110;&#26816;&#27979;&#21040;&#30340;&#20998;&#32452;&#32467;&#26500;&#24314;&#31435;&#20998;&#32452;&#22810;&#20803;&#20989;&#25968;&#22238;&#24402;&#27169;&#22411;&#12290;&#22312;&#36825;&#20010;&#26032;&#30340;&#20998;&#32452;&#27169;&#22411;&#20013;&#65292;&#21516;&#19968;&#21516;&#36136;&#32676;&#32452;&#20013;&#30340;&#31995;&#25968;&#20989;&#25968;&#24212;&#23545;&#40784;&#12290;
&lt;/p&gt;
&lt;p&gt;
In multivariate functional data analysis, different functional covariates can be homogeneous. The hidden homogeneity structure is informative about the connectivity or association of different covariates. The covariates with pronounced homogeneity can be analyzed jointly within the same group, which gives rise to a way of parsimoniously modeling multivariate functional data. In this paper, a novel grouped multivariate functional regression model with a new regularization approach termed "coefficient shape alignment" is developed to tackle the potential homogeneity of different functional covariates. The modeling procedure includes two main steps: first detect the unknown grouping structure with the new regularization approach to aggregate covariates into disjoint groups; and then the grouped multivariate functional regression model is established based on the detected grouping structure. In this new grouped model, the coefficient functions of covariates in the same homogeneous group sh
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#36125;&#21494;&#26031;&#32593;&#32476;&#20013;Shannon&#29109;&#21644;Kullback-Leibler&#25955;&#24230;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#19968;&#31995;&#21015;&#25968;&#20540;&#31034;&#20363;&#36827;&#34892;&#20102;&#28436;&#31034;&#12290;&#27492;&#22806;&#65292;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#39640;&#26031;&#36125;&#21494;&#26031;&#32593;&#32476;&#20013;KL&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#20174;&#31435;&#26041;&#38477;&#20302;&#21040;&#20108;&#27425;&#12290;</title><link>http://arxiv.org/abs/2312.01520</link><description>&lt;p&gt;
Bayesian&#32593;&#32476;&#30340;&#29109;&#21644;Kullback-Leibler&#25955;&#24230;&#65306;&#35745;&#31639;&#22797;&#26434;&#24230;&#21644;&#39640;&#25928;&#23454;&#29616;
&lt;/p&gt;
&lt;p&gt;
Entropy and the Kullback-Leibler Divergence for Bayesian Networks: Computational Complexity and Efficient Implementation. (arXiv:2312.01520v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.01520
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#36125;&#21494;&#26031;&#32593;&#32476;&#20013;Shannon&#29109;&#21644;Kullback-Leibler&#25955;&#24230;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#19968;&#31995;&#21015;&#25968;&#20540;&#31034;&#20363;&#36827;&#34892;&#20102;&#28436;&#31034;&#12290;&#27492;&#22806;&#65292;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#39640;&#26031;&#36125;&#21494;&#26031;&#32593;&#32476;&#20013;KL&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#20174;&#31435;&#26041;&#38477;&#20302;&#21040;&#20108;&#27425;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#32593;&#32476;&#65288;BNs&#65289;&#26159;&#26426;&#22120;&#23398;&#20064;&#21644;&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#22522;&#30784;&#27169;&#22411;&#12290;&#23427;&#20204;&#30340;&#22270;&#32467;&#26500;&#21487;&#20197;&#22788;&#29702;&#39640;&#32500;&#38382;&#39064;&#65292;&#24182;&#23558;&#20854;&#20998;&#20026;&#31232;&#30095;&#30340;&#19968;&#31995;&#21015;&#36739;&#23567;&#38382;&#39064;&#65292;&#36825;&#26159;Judea Pearl&#30340;&#22240;&#26524;&#24615;&#30340;&#22522;&#30784;&#65292;&#20063;&#20915;&#23450;&#20102;&#23427;&#20204;&#30340;&#21487;&#35299;&#37322;&#24615;&#21644;&#21487;&#29702;&#35299;&#24615;&#12290;&#23613;&#31649;&#23427;&#20204;&#24456;&#21463;&#27426;&#36814;&#65292;&#20294;&#22312;&#25991;&#29486;&#20013;&#20960;&#20046;&#27809;&#26377;&#20851;&#20110;&#22914;&#20309;&#22312;&#26368;&#24120;&#35265;&#30340;&#20998;&#24067;&#20551;&#35774;&#19979;&#35745;&#31639;BNs&#30340;Shannon&#29109;&#21644;Kullback-Leibler&#65288;KL&#65289;&#25955;&#24230;&#30340;&#36164;&#28304;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;BNs&#30340;&#22270;&#32467;&#26500;&#25552;&#20379;&#20102;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#31639;&#27861;&#65292;&#24182;&#29992;&#19968;&#25972;&#22871;&#25968;&#20540;&#31034;&#20363;&#35828;&#26126;&#20102;&#23427;&#20204;&#12290;&#22312;&#27492;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#23558;&#39640;&#26031;BNs&#30340;KL&#35745;&#31639;&#22797;&#26434;&#24230;&#20174;&#31435;&#26041;&#38477;&#20302;&#21040;&#20108;&#27425;&#30340;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian networks (BNs) are a foundational model in machine learning and causal inference. Their graphical structure can handle high-dimensional problems, divide them into a sparse collection of smaller ones, underlies Judea Pearl's causality, and determines their explainability and interpretability. Despite their popularity, there are almost no resources in the literature on how to compute Shannon's entropy and the Kullback-Leibler (KL) divergence for BNs under their most common distributional assumptions. In this paper, we provide computationally efficient algorithms for both by leveraging BNs' graphical structure, and we illustrate them with a complete set of numerical examples. In the process, we show it is possible to reduce the computational complexity of KL from cubic to quadratic for Gaussian BNs.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#31561;&#21464;&#37327;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#65288;EQNN&#65289;&#21644;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#65288;QNN&#65289;&#19982;&#32463;&#20856;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#20840;&#38754;&#27604;&#36739;&#20998;&#26512;&#65292;&#32467;&#26524;&#34920;&#26126;&#12298;$\mathbb{Z}_2\times \mathbb{Z}_2$&#12299;EQNN&#21644;QNN&#22312;&#36739;&#23567;&#30340;&#21442;&#25968;&#38598;&#21644;&#36866;&#20013;&#30340;&#35757;&#32451;&#25968;&#25454;&#26679;&#26412;&#19978;&#34920;&#29616;&#20248;&#36234;&#12290;</title><link>http://arxiv.org/abs/2311.18744</link><description>&lt;p&gt;
&#12298;$\mathbb{Z}_2\times \mathbb{Z}_2$&#12299;&#31561;&#21464;&#37327;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#65306;&#19982;&#32463;&#20856;&#31070;&#32463;&#32593;&#32476;&#30340;&#22522;&#20934;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
$\mathbb{Z}_2\times \mathbb{Z}_2$ Equivariant Quantum Neural Networks: Benchmarking against Classical Neural Networks. (arXiv:2311.18744v2 [quant-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.18744
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#31561;&#21464;&#37327;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#65288;EQNN&#65289;&#21644;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#65288;QNN&#65289;&#19982;&#32463;&#20856;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#20840;&#38754;&#27604;&#36739;&#20998;&#26512;&#65292;&#32467;&#26524;&#34920;&#26126;&#12298;$\mathbb{Z}_2\times \mathbb{Z}_2$&#12299;EQNN&#21644;QNN&#22312;&#36739;&#23567;&#30340;&#21442;&#25968;&#38598;&#21644;&#36866;&#20013;&#30340;&#35757;&#32451;&#25968;&#25454;&#26679;&#26412;&#19978;&#34920;&#29616;&#20248;&#36234;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#31561;&#21464;&#37327;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#65288;EQNN&#65289;&#21644;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#65288;QNN&#65289;&#19982;&#23427;&#20204;&#30340;&#32463;&#20856;&#23545;&#24212;&#29289;&#65306;&#31561;&#21464;&#37327;&#31070;&#32463;&#32593;&#32476;&#65288;ENN&#65289;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#20840;&#38754;&#27604;&#36739;&#20998;&#26512;&#12290;&#25105;&#20204;&#36890;&#36807;&#20004;&#20010;&#20108;&#20803;&#20998;&#31867;&#20219;&#21153;&#30340;&#29609;&#20855;&#31034;&#20363;&#35780;&#20272;&#27599;&#20010;&#32593;&#32476;&#30340;&#24615;&#33021;&#65292;&#20851;&#27880;&#27169;&#22411;&#22797;&#26434;&#24230;&#65288;&#30001;&#21442;&#25968;&#25968;&#37327;&#27979;&#37327;&#65289;&#21644;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;&#65292;&#12298;$\mathbb{Z}_2\times \mathbb{Z}_2$&#12299;EQNN&#21644;QNN&#22312;&#36739;&#23567;&#30340;&#21442;&#25968;&#38598;&#21644;&#36866;&#20013;&#30340;&#35757;&#32451;&#25968;&#25454;&#26679;&#26412;&#19978;&#25552;&#20379;&#20102;&#26356;&#20248;&#31168;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a comprehensive comparative analysis of the performance of Equivariant Quantum Neural Networks (EQNN) and Quantum Neural Networks (QNN), juxtaposed against their classical counterparts: Equivariant Neural Networks (ENN) and Deep Neural Networks (DNN). We evaluate the performance of each network with two toy examples for a binary classification task, focusing on model complexity (measured by the number of parameters) and the size of the training data set. Our results show that the $\mathbb{Z}_2\times \mathbb{Z}_2$ EQNN and the QNN provide superior performance for smaller parameter sets and modest training data samples.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#26230;&#26684;&#35268;&#33539;&#31561;&#21464;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;L-CNN&#65289;&#25551;&#36848;&#20102;&#22522;&#20110;&#37325;&#25972;&#21270;&#32676;&#21464;&#25442;&#30340;&#22266;&#23450;&#28857;&#20316;&#29992;&#65288;FP&#65289;&#65292;&#36825;&#31181;&#26041;&#27861;&#26356;&#20934;&#30830;&#22320;&#21442;&#25968;&#21270;FP&#20316;&#29992;&#65292;&#21487;&#20197;&#35268;&#36991;&#20020;&#30028;&#20943;&#36895;&#21644;&#25299;&#25169;&#20923;&#32467;&#38382;&#39064;&#65292;&#24182;&#22312;&#31895;&#26230;&#26684;&#19978;&#20135;&#29983;&#20855;&#26377;&#38750;&#24120;&#23567;&#26230;&#26684;&#25928;&#24212;&#30340;&#29289;&#29702;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2311.17816</link><description>&lt;p&gt;
&#20174;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20013;&#33719;&#24471;&#30340;&#22266;&#23450;&#28857;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Fixed point actions from convolutional neural networks. (arXiv:2311.17816v1 [hep-lat] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.17816
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#26230;&#26684;&#35268;&#33539;&#31561;&#21464;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;L-CNN&#65289;&#25551;&#36848;&#20102;&#22522;&#20110;&#37325;&#25972;&#21270;&#32676;&#21464;&#25442;&#30340;&#22266;&#23450;&#28857;&#20316;&#29992;&#65288;FP&#65289;&#65292;&#36825;&#31181;&#26041;&#27861;&#26356;&#20934;&#30830;&#22320;&#21442;&#25968;&#21270;FP&#20316;&#29992;&#65292;&#21487;&#20197;&#35268;&#36991;&#20020;&#30028;&#20943;&#36895;&#21644;&#25299;&#25169;&#20923;&#32467;&#38382;&#39064;&#65292;&#24182;&#22312;&#31895;&#26230;&#26684;&#19978;&#20135;&#29983;&#20855;&#26377;&#38750;&#24120;&#23567;&#26230;&#26684;&#25928;&#24212;&#30340;&#29289;&#29702;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26230;&#26684;&#35268;&#33539;&#31561;&#21464;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;L-CNN&#65289;&#21487;&#29992;&#20110;&#24418;&#25104;&#20219;&#24847;&#24418;&#29366;&#30340;Wilson&#29615;&#65292;&#24182;&#19988;&#21487;&#20197;&#36817;&#20284;&#26230;&#26684;&#19978;&#30340;&#20219;&#20309;&#35268;&#33539;&#20381;&#21464;&#25110;&#35268;&#33539;&#19981;&#21464;&#20989;&#25968;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20351;&#29992;L-CNN&#26469;&#25551;&#36848;&#22522;&#20110;&#37325;&#25972;&#21270;&#32676;&#21464;&#25442;&#30340;&#22266;&#23450;&#28857;&#65288;FP&#65289;&#20316;&#29992;&#12290;FP&#20316;&#29992;&#22312;&#32463;&#20856;&#35268;&#33539;&#22330;&#28385;&#36275;&#36816;&#21160;&#26041;&#31243;&#30340;&#24773;&#20917;&#19979;&#26159;&#32463;&#20856;&#23436;&#32654;&#30340;&#65292;&#21363;&#23427;&#20204;&#27809;&#26377;&#26230;&#26684;&#25928;&#24212;&#65292;&#24182;&#19988;&#20855;&#26377;&#23610;&#24230;&#19981;&#21464;&#30340;&#30636;&#23376;&#35299;&#12290;FP&#20316;&#29992;&#22312;&#26230;&#26684;&#38388;&#36317;&#30340;&#25152;&#26377;&#38454;&#23618;&#20013;&#37117;&#26159;&#26641;&#32423;Symanzik&#25913;&#36827;&#30340;&#65292;&#21363;&#20351;&#22312;&#31895;&#26230;&#26684;&#19978;&#20063;&#33021;&#20135;&#29983;&#20855;&#26377;&#38750;&#24120;&#23567;&#26230;&#26684;&#25928;&#24212;&#30340;&#29289;&#29702;&#39044;&#27979;&#12290;&#25105;&#20204;&#21457;&#29616;&#19982;&#36739;&#26087;&#30340;&#26041;&#27861;&#30456;&#27604;&#65292;L-CNN&#22312;&#21442;&#25968;&#21270;FP&#20316;&#29992;&#26041;&#38754;&#26356;&#20934;&#30830;&#12290;&#22240;&#27492;&#65292;&#23427;&#20204;&#21487;&#33021;&#25552;&#20379;&#19968;&#31181;&#35268;&#36991;&#20020;&#30028;&#20943;&#36895;&#21644;&#25299;&#25169;&#20923;&#32467;&#20197;&#25509;&#36817;&#36830;&#32493;&#26497;&#38480;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Lattice gauge-equivariant convolutional neural networks (L-CNNs) can be used to form arbitrarily shaped Wilson loops and can approximate any gauge-covariant or gauge-invariant function on the lattice. Here we use L-CNNs to describe fixed point (FP) actions which are based on renormalization group transformations. FP actions are classically perfect, i.e., they have no lattice artifacts on classical gauge-field configurations satisfying the equations of motion, and therefore possess scale invariant instanton solutions. FP actions are tree-level Symanzik-improved to all orders in the lattice spacing and can produce physical predictions with very small lattice artifacts even on coarse lattices. We find that L-CNNs are much more accurate at parametrizing the FP action compared to older approaches. They may therefore provide a way to circumvent critical slowing down and topological freezing towards the continuum limit.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#26368;&#23567;&#33539;&#25968;&#27973;&#23618;&#21435;&#22122;&#22120;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#30340;&#34920;&#29616;&#65292;&#25512;&#23548;&#20986;&#19968;&#20803;&#25968;&#25454;&#21644;&#22810;&#20803;&#25968;&#25454;&#19978;&#30340;&#38381;&#21512;&#24418;&#24335;&#65292;&#24182;&#21457;&#29616;&#20854;&#20855;&#26377;&#25910;&#32553;&#24615;&#21644;&#36739;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2311.06748</link><description>&lt;p&gt;
&#26368;&#23567;&#33539;&#25968;&#27973;&#23618;&#21435;&#22122;&#22120;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#30340;&#34920;&#29616;&#22914;&#20309;&#65311;
&lt;/p&gt;
&lt;p&gt;
How do Minimum-Norm Shallow Denoisers Look in Function Space?. (arXiv:2311.06748v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.06748
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#26368;&#23567;&#33539;&#25968;&#27973;&#23618;&#21435;&#22122;&#22120;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#30340;&#34920;&#29616;&#65292;&#25512;&#23548;&#20986;&#19968;&#20803;&#25968;&#25454;&#21644;&#22810;&#20803;&#25968;&#25454;&#19978;&#30340;&#38381;&#21512;&#24418;&#24335;&#65292;&#24182;&#21457;&#29616;&#20854;&#20855;&#26377;&#25910;&#32553;&#24615;&#21644;&#36739;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#21435;&#22122;&#22120;&#65288;NN&#21435;&#22122;&#22120;&#65289;&#26159;&#35768;&#22810;&#24120;&#35265;&#20219;&#21153;&#20013;&#30340;&#22522;&#26412;&#26500;&#24314;&#22359;&#65292;&#20174;&#22270;&#20687;&#37325;&#24314;&#21040;&#22270;&#20687;&#29983;&#25104;&#12290;&#28982;&#32780;&#65292;&#20174;&#29702;&#35770;&#35282;&#24230;&#26469;&#30475;&#65292;&#36825;&#20123;&#27169;&#22411;&#30340;&#25104;&#21151;&#23578;&#19981;&#26126;&#30830;&#12290;&#26412;&#25991;&#26088;&#22312;&#25551;&#36848;&#27973;&#23618;ReLU NN&#21435;&#22122;&#22120;&#23454;&#29616;&#30340;&#20989;&#25968;&#29305;&#24615;--&#22312;&#25554;&#20540;&#30340;&#24120;&#35265;&#29702;&#35770;&#35774;&#32622;&#19979;&#65288;&#21363;&#38646;&#35757;&#32451;&#25439;&#22833;&#65289;&#20197;&#21450;&#26368;&#23567;&#34920;&#31034;&#25104;&#26412;&#65288;&#21363;&#26368;&#23567;&#30340;l^2&#33539;&#25968;&#26435;&#37325;&#65289;&#12290;&#39318;&#20808;&#65292;&#23545;&#20110;&#19968;&#20803;&#25968;&#25454;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;NN&#21435;&#22122;&#22120;&#20989;&#25968;&#30340;&#38381;&#21512;&#24418;&#24335;&#65292;&#21457;&#29616;&#23427;&#23545;&#24178;&#20928;&#25968;&#25454;&#28857;&#20855;&#26377;&#25910;&#32553;&#24615;&#65292;&#24182;&#35777;&#26126;&#22312;&#20302;&#22122;&#22768;&#27700;&#24179;&#19979;&#23427;&#27604;&#32463;&#39564;MMSE&#20272;&#35745;&#22120;&#26356;&#22909;&#22320;&#27867;&#21270;&#12290;&#25509;&#19979;&#26469;&#65292;&#23545;&#20110;&#22810;&#20803;&#25968;&#25454;&#65292;&#25105;&#20204;&#22312;&#22810;&#31181;&#20960;&#20309;&#20551;&#35774;&#19979;&#25214;&#21040;&#20102;&#38381;&#21512;&#24418;&#24335;&#30340;NN&#21435;&#22122;&#22120;&#20989;&#25968;&#65306;&#25968;&#25454;&#21253;&#21547;&#22312;&#20302;&#32500;&#23376;&#31354;&#38388;&#20013;&#65292;&#25968;&#25454;&#21253;&#21547;&#22312;&#21333;&#21521;&#23556;&#32447;&#30340;&#24182;&#38598;&#20013;&#65292;&#25110;&#32773;&#22810;&#31181;&#31867;&#22411;&#30340;&#31616;&#21333;&#24418;&#29366;&#12290;&#36825;&#20123;&#20989;&#25968;&#20998;&#35299;&#20026;&#19968;&#20010;&#21644;&#30340;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural network (NN) denoisers are an essential building block in many common tasks, ranging from image reconstruction to image generation. However, the success of these models is not well understood from a theoretical perspective. In this paper, we aim to characterize the functions realized by shallow ReLU NN denoisers -- in the common theoretical setting of interpolation (i.e., zero training loss) with a minimal representation cost (i.e., minimal $\ell^2$ norm weights). First, for univariate data, we derive a closed form for the NN denoiser function, find it is contractive toward the clean data points, and prove it generalizes better than the empirical MMSE estimator at a low noise level. Next, for multivariate data, we find the NN denoiser functions in a closed form under various geometric assumptions on the training data: data contained in a low-dimensional subspace, data contained in a union of one-sided rays, or several types of simplexes. These functions decompose into a sum of s
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31232;&#30095;&#28155;&#21152;&#26426;&#21046;&#31227;&#20301;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;SAMS-VAE&#65289;&#65292;&#29992;&#20110;&#24314;&#27169;&#32454;&#32990;&#30340;&#25200;&#21160;&#24773;&#20917;&#65292;&#24182;&#32467;&#21512;&#22797;&#21512;&#24615;&#12289;&#35299;&#32544;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;&#36890;&#36807;&#31232;&#30095;&#21270;&#22788;&#29702;&#20840;&#23616;&#28508;&#21464;&#37327;&#65292;SAMS-VAE&#33021;&#22815;&#35782;&#21035;&#20986;&#29305;&#23450;&#20110;&#24178;&#25200;&#30340;&#28508;&#22312;&#23376;&#31354;&#38388;&#65292;&#24182;&#22312;&#22810;&#20010;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#23450;&#37327;&#21644;&#23450;&#24615;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2311.02794</link><description>&lt;p&gt;
&#29992;&#31232;&#30095;&#28155;&#21152;&#26426;&#21046;&#31227;&#20301;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#23545;&#32454;&#32990;&#25200;&#21160;&#36827;&#34892;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Modelling Cellular Perturbations with the Sparse Additive Mechanism Shift Variational Autoencoder. (arXiv:2311.02794v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.02794
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31232;&#30095;&#28155;&#21152;&#26426;&#21046;&#31227;&#20301;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;SAMS-VAE&#65289;&#65292;&#29992;&#20110;&#24314;&#27169;&#32454;&#32990;&#30340;&#25200;&#21160;&#24773;&#20917;&#65292;&#24182;&#32467;&#21512;&#22797;&#21512;&#24615;&#12289;&#35299;&#32544;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;&#36890;&#36807;&#31232;&#30095;&#21270;&#22788;&#29702;&#20840;&#23616;&#28508;&#21464;&#37327;&#65292;SAMS-VAE&#33021;&#22815;&#35782;&#21035;&#20986;&#29305;&#23450;&#20110;&#24178;&#25200;&#30340;&#28508;&#22312;&#23376;&#31354;&#38388;&#65292;&#24182;&#22312;&#22810;&#20010;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#23450;&#37327;&#21644;&#23450;&#24615;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#38024;&#23545;&#24178;&#39044;&#19979;&#35266;&#27979;&#25968;&#25454;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#31185;&#23398;&#39046;&#22495;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#20363;&#22914;&#65292;&#22312;&#33647;&#29289;&#21457;&#29616;&#20013;&#65292;&#38656;&#35201;&#23545;&#32454;&#32990;&#30340;&#22810;&#31181;&#24178;&#39044;&#25928;&#24212;&#36827;&#34892;&#24314;&#27169;&#65292;&#20197;&#25581;&#31034;&#26410;&#30693;&#30340;&#29983;&#29289;&#20316;&#29992;&#26426;&#21046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#31232;&#30095;&#28155;&#21152;&#26426;&#21046;&#31227;&#20301;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;SAMS-VAE&#65289;&#65292;&#20197;&#32452;&#21512;&#22797;&#21512;&#24615;&#12289;&#35299;&#32544;&#21644;&#21487;&#35299;&#37322;&#24615;&#36827;&#34892;&#25200;&#21160;&#27169;&#22411;&#12290;SAMS-VAE&#23558;&#25200;&#21160;&#26679;&#26412;&#30340;&#28508;&#22312;&#29366;&#24577;&#24314;&#27169;&#20026;&#19968;&#20010;&#23616;&#37096;&#28508;&#22312;&#21464;&#37327;&#21644;&#31232;&#30095;&#20840;&#23616;&#21464;&#37327;&#20043;&#21644;&#65292;&#29992;&#20110;&#25429;&#25417;&#26679;&#26412;&#29305;&#23450;&#30340;&#21464;&#21270;&#21644;&#28508;&#22312;&#24178;&#39044;&#25928;&#24212;&#12290;&#20851;&#38190;&#26159;&#65292;SAMS-VAE&#36890;&#36807;&#23545;&#21508;&#20010;&#24178;&#39044;&#30340;&#20840;&#23616;&#28508;&#21464;&#37327;&#36827;&#34892;&#31232;&#30095;&#21270;&#22788;&#29702;&#65292;&#20174;&#32780;&#35782;&#21035;&#20986;&#35299;&#32544;&#30340;&#12289;&#24178;&#25200;&#29305;&#23450;&#30340;&#28508;&#22312;&#23376;&#31354;&#38388;&#65292;&#36825;&#20123;&#23376;&#31354;&#38388;&#20855;&#26377;&#28789;&#27963;&#30340;&#32452;&#21512;&#24615;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#27969;&#34892;&#30340;&#21333;&#32454;&#32990;&#27979;&#24207;&#25968;&#25454;&#38598;&#19978;&#23450;&#37327;&#21644;&#23450;&#24615;&#35780;&#20272;&#20102;SAMS-VAE&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative models of observations under interventions have been a vibrant topic of interest across machine learning and the sciences in recent years. For example, in drug discovery, there is a need to model the effects of diverse interventions on cells in order to characterize unknown biological mechanisms of action. We propose the Sparse Additive Mechanism Shift Variational Autoencoder, SAMS-VAE, to combine compositionality, disentanglement, and interpretability for perturbation models. SAMS-VAE models the latent state of a perturbed sample as the sum of a local latent variable capturing sample-specific variation and sparse global variables of latent intervention effects. Crucially, SAMS-VAE sparsifies these global latent variables for individual perturbations to identify disentangled, perturbation-specific latent subspaces that are flexibly composable. We evaluate SAMS-VAE both quantitatively and qualitatively on a range of tasks using two popular single cell sequencing datasets. In 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#27424;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#65292;&#23398;&#29983;&#32593;&#32476;&#26159;&#21542;&#24212;&#35813;&#22797;&#21046;&#25945;&#24072;&#31070;&#32463;&#20803;&#25110;&#24179;&#22343;&#19968;&#32452;&#25945;&#24072;&#31070;&#32463;&#20803;&#30340;&#26435;&#37325;&#12290;&#30740;&#31350;&#21457;&#29616;&#23545;&#20110;&#29305;&#23450;&#30340;&#32593;&#32476;&#32467;&#26500;&#21644;&#36755;&#20837;&#20998;&#24067;&#65292;&#24403;&#25945;&#24072;&#32593;&#32476;&#30340;&#36755;&#20837;&#21521;&#37327;&#27491;&#20132;&#19988;&#36755;&#20986;&#26435;&#37325;&#20026;&#37193;&#26102;&#65292;&#22797;&#21046;-&#24179;&#22343;&#37197;&#32622;&#23558;&#36798;&#21040;&#20248;&#21270;&#32467;&#26524;&#65292;&#20854;&#20013;&#22823;&#37096;&#20998;&#23398;&#29983;&#31070;&#32463;&#20803;&#22797;&#21046;&#19968;&#20010;&#25945;&#24072;&#31070;&#32463;&#20803;&#65292;&#26368;&#21518;&#19968;&#20010;&#23398;&#29983;&#31070;&#32463;&#20803;&#23545;&#25152;&#26377;&#25945;&#24072;&#31070;&#32463;&#20803;&#21462;&#24179;&#22343;&#20540;&#12290;</title><link>http://arxiv.org/abs/2311.01644</link><description>&lt;p&gt;
&#23398;&#29983;&#32593;&#32476;&#26159;&#21542;&#24212;&#35813;&#22797;&#21046;&#25110;&#24179;&#22343;&#25945;&#24072;&#26435;&#37325;&#65311;
&lt;/p&gt;
&lt;p&gt;
Should Under-parameterized Student Networks Copy or Average Teacher Weights?. (arXiv:2311.01644v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01644
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#27424;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#65292;&#23398;&#29983;&#32593;&#32476;&#26159;&#21542;&#24212;&#35813;&#22797;&#21046;&#25945;&#24072;&#31070;&#32463;&#20803;&#25110;&#24179;&#22343;&#19968;&#32452;&#25945;&#24072;&#31070;&#32463;&#20803;&#30340;&#26435;&#37325;&#12290;&#30740;&#31350;&#21457;&#29616;&#23545;&#20110;&#29305;&#23450;&#30340;&#32593;&#32476;&#32467;&#26500;&#21644;&#36755;&#20837;&#20998;&#24067;&#65292;&#24403;&#25945;&#24072;&#32593;&#32476;&#30340;&#36755;&#20837;&#21521;&#37327;&#27491;&#20132;&#19988;&#36755;&#20986;&#26435;&#37325;&#20026;&#37193;&#26102;&#65292;&#22797;&#21046;-&#24179;&#22343;&#37197;&#32622;&#23558;&#36798;&#21040;&#20248;&#21270;&#32467;&#26524;&#65292;&#20854;&#20013;&#22823;&#37096;&#20998;&#23398;&#29983;&#31070;&#32463;&#20803;&#22797;&#21046;&#19968;&#20010;&#25945;&#24072;&#31070;&#32463;&#20803;&#65292;&#26368;&#21518;&#19968;&#20010;&#23398;&#29983;&#31070;&#32463;&#20803;&#23545;&#25152;&#26377;&#25945;&#24072;&#31070;&#32463;&#20803;&#21462;&#24179;&#22343;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20219;&#20309;&#36830;&#32493;&#20989;&#25968; $f^*$ &#37117;&#21487;&#20197;&#29992;&#36275;&#22815;&#22810;&#30340;&#31070;&#32463;&#20803; $k$&#26469;&#36817;&#20284;&#12290;&#25105;&#20204;&#32771;&#34385; $f^*$ &#26412;&#36523;&#26159;&#19968;&#20010;&#20855;&#26377;&#19968;&#20010;&#38544;&#34255;&#23618;&#21644; $k$ &#20010;&#31070;&#32463;&#20803;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#24773;&#20917;&#12290;&#29992;&#20855;&#26377; $n&lt;k$ &#20010;&#31070;&#32463;&#20803;&#30340;&#31070;&#32463;&#32593;&#32476;&#26469;&#36924;&#36817; $f^*$ &#21487;&#20197;&#30475;&#20316;&#26159;&#23558;&#19968;&#20010;&#27424;&#21442;&#25968;&#21270;&#30340;&#8220;&#23398;&#29983;&#8221;&#32593;&#32476;&#19982; $k$ &#20010;&#31070;&#32463;&#20803;&#30340;&#8220;&#25945;&#24072;&#8221;&#32593;&#32476;&#36827;&#34892;&#25311;&#21512;&#12290;&#30001;&#20110;&#23398;&#29983;&#20855;&#26377;&#36739;&#23569;&#30340;&#31070;&#32463;&#20803;&#65292;&#25152;&#20197;&#19981;&#28165;&#26970;&#27599;&#20010; $n$ &#20010;&#23398;&#29983;&#31070;&#32463;&#20803;&#24212;&#35813;&#22797;&#21046;&#19968;&#20010;&#25945;&#24072;&#31070;&#32463;&#20803;&#36824;&#26159;&#24179;&#22343;&#19968;&#32452;&#25945;&#24072;&#31070;&#32463;&#20803;&#12290;&#23545;&#20110;&#20855;&#26377; erf &#28608;&#27963;&#20989;&#25968;&#21644;&#26631;&#20934;&#39640;&#26031;&#36755;&#20837;&#20998;&#24067;&#30340;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#25945;&#24072;&#30340;&#36755;&#20837;&#21521;&#37327;&#26159;&#27491;&#20132;&#30340;&#24182;&#19988;&#36755;&#20986;&#26435;&#37325;&#26159;&#37193;&#30340;&#26102;&#20505;&#65292;&#8220;&#22797;&#21046;-&#24179;&#22343;&#8221;&#37197;&#32622;&#26159;&#20020;&#30028;&#28857;&#12290;&#27492;&#22806;&#65292;&#22312;&#36825;&#26679;&#30340;&#37197;&#32622;&#20013;&#65292;&#20248;&#21270;&#32467;&#26524;&#26159;&#24403; $n-1$ &#20010;&#23398;&#29983;&#31070;&#32463;&#20803;&#20998;&#21035;&#22797;&#21046;&#19968;&#20010;&#25945;&#24072;&#31070;&#32463;&#20803;&#65292;&#24182;&#19988;&#31532; $n$ &#20010;&#23398;&#29983;&#31070;&#32463;&#20803;&#26159;&#25152;&#26377;&#25945;&#24072;&#31070;&#32463;&#20803;&#30340;&#24179;&#22343;&#12290;
&lt;/p&gt;
&lt;p&gt;
Any continuous function $f^*$ can be approximated arbitrarily well by a neural network with sufficiently many neurons $k$. We consider the case when $f^*$ itself is a neural network with one hidden layer and $k$ neurons. Approximating $f^*$ with a neural network with $n&lt; k$ neurons can thus be seen as fitting an under-parameterized "student" network with $n$ neurons to a "teacher" network with $k$ neurons. As the student has fewer neurons than the teacher, it is unclear, whether each of the $n$ student neurons should copy one of the teacher neurons or rather average a group of teacher neurons. For shallow neural networks with erf activation function and for the standard Gaussian input distribution, we prove that "copy-average" configurations are critical points if the teacher's incoming vectors are orthonormal and its outgoing weights are unitary. Moreover, the optimum among such configurations is reached when $n-1$ student neurons each copy one teacher neuron and the $n$-th student ne
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;&#35760;&#24518;&#25200;&#21160;&#26041;&#31243;&#65288;MPE&#65289;&#65292;&#35813;&#26041;&#31243;&#36890;&#36807;&#24212;&#29992;&#36125;&#21494;&#26031;&#21407;&#29702;&#23558;&#27169;&#22411;&#30340;&#25935;&#24863;&#24615;&#19982;&#35757;&#32451;&#25968;&#25454;&#30340;&#25200;&#21160;&#32852;&#31995;&#36215;&#26469;&#65292;&#24182;&#19988;&#33021;&#22815;&#20934;&#30830;&#39044;&#27979;&#27169;&#22411;&#22312;&#26410;&#35265;&#27979;&#35797;&#25968;&#25454;&#19978;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.19273</link><description>&lt;p&gt;
The Memory Perturbation Equation: Understanding Model's Sensitivity to Data&#65288;&#29702;&#35299;&#27169;&#22411;&#23545;&#25968;&#25454;&#30340;&#25935;&#24863;&#24615;&#30340;&#35760;&#24518;&#25200;&#21160;&#26041;&#31243;&#65289;
&lt;/p&gt;
&lt;p&gt;
The Memory Perturbation Equation: Understanding Model's Sensitivity to Data. (arXiv:2310.19273v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19273
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;&#35760;&#24518;&#25200;&#21160;&#26041;&#31243;&#65288;MPE&#65289;&#65292;&#35813;&#26041;&#31243;&#36890;&#36807;&#24212;&#29992;&#36125;&#21494;&#26031;&#21407;&#29702;&#23558;&#27169;&#22411;&#30340;&#25935;&#24863;&#24615;&#19982;&#35757;&#32451;&#25968;&#25454;&#30340;&#25200;&#21160;&#32852;&#31995;&#36215;&#26469;&#65292;&#24182;&#19988;&#33021;&#22815;&#20934;&#30830;&#39044;&#27979;&#27169;&#22411;&#22312;&#26410;&#35265;&#27979;&#35797;&#25968;&#25454;&#19978;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#27169;&#22411;&#23545;&#20854;&#35757;&#32451;&#25968;&#25454;&#30340;&#25935;&#24863;&#24615;&#23545;&#20110;&#35757;&#32451;&#36807;&#31243;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#20063;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#21644;&#25104;&#26412;&#39640;&#26114;&#12290;&#20026;&#20102;&#31616;&#21270;&#36825;&#31867;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35760;&#24518;&#25200;&#21160;&#26041;&#31243;&#65288;MPE&#65289;&#65292;&#23427;&#23558;&#27169;&#22411;&#30340;&#25935;&#24863;&#24615;&#19982;&#20854;&#35757;&#32451;&#25968;&#25454;&#30340;&#25200;&#21160;&#32852;&#31995;&#36215;&#26469;&#12290;&#20351;&#29992;&#36125;&#21494;&#26031;&#21407;&#29702;&#23548;&#20986;&#30340;MPE&#23558;&#29616;&#26377;&#30340;&#25935;&#24863;&#24615;&#24230;&#37327;&#32479;&#19968;&#36215;&#26469;&#65292;&#27867;&#21270;&#21040;&#21508;&#31181;&#27169;&#22411;&#21644;&#31639;&#27861;&#65292;&#24182;&#25581;&#31034;&#20102;&#26377;&#20851;&#25935;&#24863;&#24615;&#30340;&#26377;&#29992;&#24615;&#36136;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#35757;&#32451;&#36807;&#31243;&#20013;&#33719;&#24471;&#30340;&#25935;&#24863;&#24615;&#20272;&#35745;&#21487;&#20197;&#20934;&#30830;&#39044;&#27979;&#22312;&#26410;&#35265;&#27979;&#35797;&#25968;&#25454;&#19978;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#35813;&#25552;&#20986;&#30340;&#26041;&#31243;&#39044;&#35745;&#23558;&#23545;&#26410;&#26469;&#30340;&#40065;&#26834;&#21644;&#33258;&#36866;&#24212;&#23398;&#20064;&#30740;&#31350;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding model's sensitivity to its training data is crucial but can also be challenging and costly, especially during training. To simplify such issues, we present the Memory-Perturbation Equation (MPE) which relates model's sensitivity to perturbation in its training data. Derived using Bayesian principles, the MPE unifies existing sensitivity measures, generalizes them to a wide-variety of models and algorithms, and unravels useful properties regarding sensitivities. Our empirical results show that sensitivity estimates obtained during training can be used to faithfully predict generalization on unseen test data. The proposed equation is expected to be useful for future research on robust and adaptive learning.
&lt;/p&gt;</description></item><item><title>&#20998;&#23618;&#38543;&#26426;&#24179;&#28369;&#26159;&#19968;&#31181;&#22312;&#22797;&#26434;&#25968;&#25454;&#19978;&#36827;&#34892;&#40065;&#26834;&#24615;&#35748;&#35777;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#21482;&#22312;&#19968;&#20010;&#23545;&#35937;&#30340;&#23376;&#38598;&#19978;&#28155;&#21152;&#38543;&#26426;&#22122;&#22768;&#65292;&#20197;&#26356;&#26377;&#38024;&#23545;&#24615;&#30340;&#26041;&#24335;&#25552;&#20379;&#20102;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#20445;&#35777;&#21644;&#39640;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.16221</link><description>&lt;p&gt;
&#20998;&#23618;&#38543;&#26426;&#24179;&#28369;
&lt;/p&gt;
&lt;p&gt;
Hierarchical Randomized Smoothing. (arXiv:2310.16221v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16221
&lt;/p&gt;
&lt;p&gt;
&#20998;&#23618;&#38543;&#26426;&#24179;&#28369;&#26159;&#19968;&#31181;&#22312;&#22797;&#26434;&#25968;&#25454;&#19978;&#36827;&#34892;&#40065;&#26834;&#24615;&#35748;&#35777;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#21482;&#22312;&#19968;&#20010;&#23545;&#35937;&#30340;&#23376;&#38598;&#19978;&#28155;&#21152;&#38543;&#26426;&#22122;&#22768;&#65292;&#20197;&#26356;&#26377;&#38024;&#23545;&#24615;&#30340;&#26041;&#24335;&#25552;&#20379;&#20102;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#20445;&#35777;&#21644;&#39640;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#26159;&#22797;&#26434;&#30340;&#65292;&#36890;&#24120;&#30001;&#21487;&#20998;&#35299;&#20026;&#22810;&#20010;&#23454;&#20307;&#30340;&#23545;&#35937;&#32452;&#25104;&#65288;&#20363;&#22914;&#65292;&#23558;&#22270;&#20687;&#20998;&#35299;&#20026;&#20687;&#32032;&#65292;&#23558;&#22270;&#24418;&#20998;&#35299;&#20026;&#30456;&#20114;&#36830;&#25509;&#30340;&#33410;&#28857;&#65289;&#12290;&#38543;&#26426;&#24179;&#28369;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#20351;&#27169;&#22411;&#22312;&#20854;&#36755;&#20837;&#30340;&#24494;&#23567;&#21464;&#21270;&#19978;&#20855;&#26377;&#35777;&#26126;&#30340;&#40065;&#26834;&#24615;-&#36890;&#36807;&#22312;&#20998;&#31867;&#20043;&#21069;&#38543;&#26426;&#28155;&#21152;&#22122;&#22768;&#26469;&#20445;&#35777;&#22810;&#25968;&#25237;&#31080;&#30340;&#40065;&#26834;&#24615;&#12290;&#28982;&#32780;&#65292;&#24403;&#23545;&#25163;&#19981;&#26159;&#20219;&#24847;&#24178;&#25200;&#25972;&#20010;&#23545;&#35937;&#65288;&#20363;&#22914;&#22270;&#20687;&#65289;&#65292;&#32780;&#26159;&#23545;&#35937;&#30340;&#26576;&#20010;&#23454;&#20307;&#30340;&#23376;&#38598;&#65288;&#20363;&#22914;&#20687;&#32032;&#65289;&#26102;&#65292;&#36890;&#36807;&#38543;&#26426;&#24179;&#28369;&#23545;&#36825;&#31181;&#22797;&#26434;&#25968;&#25454;&#36827;&#34892;&#40065;&#26834;&#24615;&#35748;&#35777;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#20316;&#20026;&#35299;&#20915;&#26041;&#26696;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20998;&#23618;&#38543;&#26426;&#24179;&#28369;&#65306;&#25105;&#20204;&#36890;&#36807;&#20165;&#22312;&#38543;&#26426;&#36873;&#25321;&#30340;&#23454;&#20307;&#23376;&#38598;&#19978;&#28155;&#21152;&#38543;&#26426;&#22122;&#22768;&#26469;&#37096;&#20998;&#24179;&#28369;&#23545;&#35937;&#12290;&#36890;&#36807;&#20197;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#26377;&#38024;&#23545;&#24615;&#30340;&#26041;&#24335;&#28155;&#21152;&#22122;&#22768;&#65292;&#25105;&#20204;&#33719;&#24471;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#20445;&#35777;&#65292;&#21516;&#26102;&#20445;&#25345;&#39640;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#19981;&#21516;&#30340;&#22122;&#22768;&#20998;&#24067;&#21021;&#22987;&#21270;&#20998;&#23618;&#24179;&#28369;&#65292;&#24471;&#21040;&#20102;&#26032;&#30340;&#40065;&#26834;&#24615;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Real-world data is complex and often consists of objects that can be decomposed into multiple entities (e.g. images into pixels, graphs into interconnected nodes). Randomized smoothing is a powerful framework for making models provably robust against small changes to their inputs - by guaranteeing robustness of the majority vote when randomly adding noise before classification. Yet, certifying robustness on such complex data via randomized smoothing is challenging when adversaries do not arbitrarily perturb entire objects (e.g. images) but only a subset of their entities (e.g. pixels). As a solution, we introduce hierarchical randomized smoothing: We partially smooth objects by adding random noise only on a randomly selected subset of their entities. By adding noise in a more targeted manner than existing methods we obtain stronger robustness guarantees while maintaining high accuracy. We initialize hierarchical smoothing using different noising distributions, yielding novel robustness
&lt;/p&gt;</description></item><item><title>DeepFDR&#26159;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#34394;&#35686;&#25511;&#21046;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#26080;&#30417;&#30563;&#30340;&#22270;&#20687;&#20998;&#21106;&#25216;&#26415;&#35299;&#20915;&#31070;&#32463;&#24433;&#20687;&#25968;&#25454;&#20013;&#30340;&#22810;&#37325;&#26816;&#39564;&#38382;&#39064;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#20854;&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#20855;&#26377;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.13349</link><description>&lt;p&gt;
DeepFDR&#65306;&#19968;&#31181;&#29992;&#20110;&#31070;&#32463;&#24433;&#20687;&#25968;&#25454;&#30340;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#34394;&#35686;&#25511;&#21046;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
DeepFDR: A Deep Learning-based False Discovery Rate Control Method for Neuroimaging Data. (arXiv:2310.13349v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13349
&lt;/p&gt;
&lt;p&gt;
DeepFDR&#26159;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#34394;&#35686;&#25511;&#21046;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#26080;&#30417;&#30563;&#30340;&#22270;&#20687;&#20998;&#21106;&#25216;&#26415;&#35299;&#20915;&#31070;&#32463;&#24433;&#20687;&#25968;&#25454;&#20013;&#30340;&#22810;&#37325;&#26816;&#39564;&#38382;&#39064;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#20854;&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#20855;&#26377;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20307;&#32032;&#30340;&#22810;&#37325;&#26816;&#39564;&#22312;&#31070;&#32463;&#24433;&#20687;&#25968;&#25454;&#20998;&#26512;&#20013;&#24191;&#27867;&#24212;&#29992;&#12290;&#20256;&#32479;&#30340;&#34394;&#35686;&#25511;&#21046;&#26041;&#27861;&#24120;&#24120;&#24573;&#35270;&#22522;&#20110;&#20307;&#32032;&#30340;&#26816;&#39564;&#20043;&#38388;&#30340;&#31354;&#38388;&#30456;&#20851;&#24615;&#65292;&#20174;&#32780;&#23548;&#33268;&#27979;&#35797;&#33021;&#21147;&#30340;&#22823;&#24133;&#25439;&#22833;&#12290;&#34429;&#28982;&#26368;&#36817;&#20986;&#29616;&#20102;&#19968;&#20123;&#31354;&#38388;&#34394;&#35686;&#25511;&#21046;&#26041;&#27861;&#65292;&#20294;&#26159;&#24403;&#22788;&#29702;&#22797;&#26434;&#30340;&#33041;&#31354;&#38388;&#20381;&#36182;&#20851;&#31995;&#26102;&#65292;&#23427;&#20204;&#30340;&#26377;&#25928;&#24615;&#21644;&#26368;&#20248;&#24615;&#20173;&#23384;&#22312;&#30097;&#38382;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#24050;&#32463;&#22312;&#22270;&#20687;&#20998;&#21106;&#26041;&#38754;&#21462;&#24471;&#20102;&#38761;&#21629;&#24615;&#30340;&#36827;&#23637;&#65292;&#32780;&#22270;&#20687;&#20998;&#21106;&#19982;&#22522;&#20110;&#20307;&#32032;&#30340;&#22810;&#37325;&#26816;&#39564;&#23494;&#20999;&#30456;&#20851;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DeepFDR&#30340;&#26032;&#22411;&#31354;&#38388;&#34394;&#35686;&#25511;&#21046;&#26041;&#27861;&#65292;&#21033;&#29992;&#26080;&#30417;&#30563;&#30340;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#22270;&#20687;&#20998;&#21106;&#26469;&#35299;&#20915;&#22522;&#20110;&#20307;&#32032;&#30340;&#22810;&#37325;&#26816;&#39564;&#38382;&#39064;&#12290;&#21253;&#25324;&#20840;&#38754;&#30340;&#27169;&#25311;&#21644;&#38463;&#23572;&#33576;&#28023;&#40664;&#30149;FDG-PET&#24433;&#20687;&#20998;&#26512;&#22312;&#20869;&#30340;&#25968;&#20540;&#30740;&#31350;&#34920;&#26126;DeepFDR&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#20855;&#26377;&#20248;&#21183;&#12290;DeepFDR&#19981;&#20165;&#22312;&#34394;&#35686;&#25511;&#21046;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#36824;&#26377;&#25928;&#38477;&#20302;&#20102;&#34394;&#20551;&#30340;&#38750;&#21457;&#29616;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Voxel-based multiple testing is widely used in neuroimaging data analysis. Traditional false discovery rate (FDR) control methods often ignore the spatial dependence among the voxel-based tests and thus suffer from substantial loss of testing power. While recent spatial FDR control methods have emerged, their validity and optimality remain questionable when handling the complex spatial dependencies of the brain. Concurrently, deep learning methods have revolutionized image segmentation, a task closely related to voxel-based multiple testing. In this paper, we propose DeepFDR, a novel spatial FDR control method that leverages unsupervised deep learning-based image segmentation to address the voxel-based multiple testing problem. Numerical studies, including comprehensive simulations and Alzheimer's disease FDG-PET image analysis, demonstrate DeepFDR's superiority over existing methods. DeepFDR not only excels in FDR control and effectively diminishes the false nondiscovery rate, but als
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#20248;&#20256;&#36755;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#38750;&#21442;&#25968;&#21270;&#30340;&#20998;&#24067;&#32422;&#26463;&#26435;&#37325;&#65292;&#24182;&#21033;&#29992;&#26368;&#22823;&#29109;&#21407;&#29702;&#21644;&#26368;&#20248;&#20256;&#36755;&#24037;&#20855;&#35774;&#35745;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#20197;&#23454;&#29616;&#23545;&#35266;&#27979;&#25968;&#25454;&#30340;&#26368;&#20248;&#26435;&#37325;&#35843;&#25972;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#19981;&#21516;&#30340;&#24212;&#29992;&#22330;&#26223;&#20013;&#23637;&#29616;&#20102;&#28789;&#27963;&#24615;&#21644;&#22810;&#21151;&#33021;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.12447</link><description>&lt;p&gt;
&#32422;&#26463;&#37325;&#21152;&#26435;&#20998;&#24067;&#65306;&#19968;&#31181;&#26368;&#20248;&#20256;&#36755;&#26041;&#27861;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Constrained Reweighting of Distributions: an Optimal Transport Approach. (arXiv:2310.12447v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12447
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#20248;&#20256;&#36755;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#38750;&#21442;&#25968;&#21270;&#30340;&#20998;&#24067;&#32422;&#26463;&#26435;&#37325;&#65292;&#24182;&#21033;&#29992;&#26368;&#22823;&#29109;&#21407;&#29702;&#21644;&#26368;&#20248;&#20256;&#36755;&#24037;&#20855;&#35774;&#35745;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#20197;&#23454;&#29616;&#23545;&#35266;&#27979;&#25968;&#25454;&#30340;&#26368;&#20248;&#26435;&#37325;&#35843;&#25972;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#19981;&#21516;&#30340;&#24212;&#29992;&#22330;&#26223;&#20013;&#23637;&#29616;&#20102;&#28789;&#27963;&#24615;&#21644;&#22810;&#21151;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32463;&#24120;&#36935;&#21040;&#30340;&#38382;&#39064;&#26159;&#35201;&#35782;&#21035;&#20986;&#31526;&#21512;&#39044;&#23450;&#20041;&#30340;&#26435;&#37325;&#32422;&#26463;&#26465;&#20214;&#30340;&#35266;&#27979;&#25968;&#25454;&#30340;&#32463;&#39564;&#20998;&#24067;&#30340;&#26368;&#20248;&#35843;&#25972;&#29256;&#26412;&#12290;&#36825;&#20123;&#32422;&#26463;&#36890;&#24120;&#34920;&#29616;&#20026;&#23545;&#26435;&#37325;&#30340;&#30697;&#12289;&#23614;&#37096;&#34892;&#20026;&#12289;&#24418;&#29366;&#12289;&#27169;&#24335;&#25968;&#37327;&#31561;&#30340;&#38480;&#21046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#38750;&#21442;&#25968;&#21270;&#30340;&#20998;&#24067;&#32422;&#26463;&#26435;&#37325;&#24182;&#21033;&#29992;&#26368;&#22823;&#29109;&#21407;&#29702;&#21644;&#26368;&#20248;&#20256;&#36755;&#24037;&#20855;&#24320;&#21457;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#20174;&#32780;&#22823;&#22823;&#25552;&#39640;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#28789;&#27963;&#24615;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#30830;&#20445;&#35266;&#27979;&#25968;&#25454;&#30340;&#26368;&#22823;&#29109;&#26435;&#37325;&#35843;&#25972;&#32463;&#39564;&#20998;&#24067;&#19982;&#39044;&#23450;&#30340;&#27010;&#29575;&#20998;&#24067;&#22312;&#26368;&#20248;&#20256;&#36755;&#24230;&#37327;&#19979;&#25509;&#36817;&#65292;&#24182;&#20801;&#35768;&#32454;&#24494;&#30340;&#20559;&#24046;&#12290;&#35813;&#26694;&#26550;&#30340;&#22810;&#21151;&#33021;&#24615;&#22312;&#19977;&#20010;&#19981;&#21516;&#30340;&#24212;&#29992;&#22330;&#26223;&#20013;&#24471;&#21040;&#20102;&#35777;&#26126;&#65292;&#20854;&#20013;&#25968;&#25454;&#37325;&#21152;&#26435;&#26159;&#21512;&#29702;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We commonly encounter the problem of identifying an optimally weight adjusted version of the empirical distribution of observed data, adhering to predefined constraints on the weights. Such constraints often manifest as restrictions on the moments, tail behaviour, shapes, number of modes, etc., of the resulting weight adjusted empirical distribution. In this article, we substantially enhance the flexibility of such methodology by introducing a nonparametrically imbued distributional constraints on the weights, and developing a general framework leveraging the maximum entropy principle and tools from optimal transport. The key idea is to ensure that the maximum entropy weight adjusted empirical distribution of the observed data is close to a pre-specified probability distribution in terms of the optimal transport metric while allowing for subtle departures. The versatility of the framework is demonstrated in the context of three disparate applications where data re-weighting is warrante
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SFAVEL&#30340;&#26080;&#30417;&#30563;&#26694;&#26550;&#65292;&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#33976;&#39311;&#23558;&#33258;&#30417;&#30563;&#29305;&#24449;&#36716;&#21270;&#20026;&#39640;&#36136;&#37327;&#30340;&#20027;&#24352;-&#20107;&#23454;&#23545;&#40784;&#65292;&#23454;&#29616;&#26080;&#30417;&#30563;&#20107;&#23454;&#39564;&#35777;&#12290;&#36825;&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#23545;&#27604;&#25439;&#22833;&#20989;&#25968;&#23454;&#29616;&#65292;&#21516;&#26102;&#20445;&#30041;&#35821;&#26009;&#24211;&#38388;&#30340;&#35821;&#20041;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2309.16540</link><description>&lt;p&gt;
&#26080;&#30417;&#30563;&#35821;&#35328;&#27169;&#22411;&#33976;&#39311;&#30340;&#20107;&#23454;&#39564;&#35777;
&lt;/p&gt;
&lt;p&gt;
Unsupervised Fact Verification by Language Model Distillation. (arXiv:2309.16540v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16540
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SFAVEL&#30340;&#26080;&#30417;&#30563;&#26694;&#26550;&#65292;&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#33976;&#39311;&#23558;&#33258;&#30417;&#30563;&#29305;&#24449;&#36716;&#21270;&#20026;&#39640;&#36136;&#37327;&#30340;&#20027;&#24352;-&#20107;&#23454;&#23545;&#40784;&#65292;&#23454;&#29616;&#26080;&#30417;&#30563;&#20107;&#23454;&#39564;&#35777;&#12290;&#36825;&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#23545;&#27604;&#25439;&#22833;&#20989;&#25968;&#23454;&#29616;&#65292;&#21516;&#26102;&#20445;&#30041;&#35821;&#26009;&#24211;&#38388;&#30340;&#35821;&#20041;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#20107;&#23454;&#39564;&#35777;&#26088;&#22312;&#36890;&#36807;&#21487;&#38752;&#30693;&#35782;&#24211;&#20013;&#30340;&#35777;&#25454;&#26469;&#39564;&#35777;&#20027;&#24352;&#65292;&#32780;&#26080;&#38656;&#20219;&#20309;&#24418;&#24335;&#30340;&#25968;&#25454;&#27880;&#37322;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#31639;&#27861;&#24517;&#39035;&#20026;&#27599;&#20010;&#20027;&#24352;&#29983;&#25104;&#26082;&#35821;&#20041;&#26126;&#30830;&#21448;&#32039;&#20945;&#30340;&#29305;&#24449;&#65292;&#20197;&#20415;&#19982;&#28304;&#20449;&#24687;&#36827;&#34892;&#35821;&#20041;&#23545;&#40784;&#12290;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#21069;&#32773;&#36890;&#36807;&#23398;&#20064;&#21253;&#21547;&#20027;&#24352;&#21450;&#20854;&#30456;&#24212;&#26631;&#31614;&#30340;&#27880;&#37322;&#35821;&#26009;&#24211;&#26469;&#35299;&#20915;&#23545;&#40784;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;SFAVEL&#65288;&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#33976;&#39311;&#30340;&#33258;&#30417;&#30563;&#20107;&#23454;&#39564;&#35777;&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#39062;&#30340;&#26080;&#30417;&#30563;&#26694;&#26550;&#65292;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#23558;&#33258;&#30417;&#30563;&#29305;&#24449;&#33976;&#39311;&#20026;&#39640;&#36136;&#37327;&#30340;&#20027;&#24352;-&#20107;&#23454;&#23545;&#40784;&#65292;&#32780;&#26080;&#38656;&#27880;&#37322;&#12290;&#36825;&#26159;&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#23545;&#27604;&#25439;&#22833;&#20989;&#25968;&#23454;&#29616;&#30340;&#65292;&#35813;&#20989;&#25968;&#40723;&#21169;&#29305;&#24449;&#22312;&#20445;&#25345;&#35821;&#26009;&#24211;&#38388;&#30340;&#35821;&#20041;&#20851;&#31995;&#30340;&#21516;&#26102;&#23454;&#29616;&#39640;&#36136;&#37327;&#30340;&#20027;&#24352;&#21644;&#35777;&#25454;&#23545;&#40784;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36798;&#21040;&#26032;&#39062;&#30340;&#29366;&#24577;&#19968;.
&lt;/p&gt;
&lt;p&gt;
Unsupervised fact verification aims to verify a claim using evidence from a trustworthy knowledge base without any kind of data annotation. To address this challenge, algorithms must produce features for every claim that are both semantically meaningful, and compact enough to find a semantic alignment with the source information. In contrast to previous work, which tackled the alignment problem by learning over annotated corpora of claims and their corresponding labels, we propose SFAVEL (Self-supervised Fact Verification via Language Model Distillation), a novel unsupervised framework that leverages pre-trained language models to distil self-supervised features into high-quality claim-fact alignments without the need for annotations. This is enabled by a novel contrastive loss function that encourages features to attain high-quality claim and evidence alignments whilst preserving the semantic relationships across the corpora. Notably, we present results that achieve a new state-of-the
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#31070;&#32463;&#31574;&#30053;&#38236;&#20687;&#26799;&#24230;&#31639;&#27861;&#22312;&#20302;&#32500;&#27969;&#24418;&#19978;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#30740;&#31350;&#21457;&#29616;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#65292;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#24456;&#22909;&#22320;&#36924;&#36817;&#20215;&#20540;&#20989;&#25968;&#21644;&#31574;&#30053;&#65292;&#19988;&#36924;&#36817;&#35823;&#24046;&#21463;&#32593;&#32476;&#22823;&#23567;&#30340;&#24433;&#21709;&#65292;&#24182;&#19988;&#21487;&#20197;&#32487;&#25215;&#20043;&#21069;&#32593;&#32476;&#30340;&#24179;&#28369;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.13915</link><description>&lt;p&gt;
&#31070;&#32463;&#31574;&#30053;&#38236;&#20687;&#26799;&#24230;&#22312;&#20302;&#32500;&#27969;&#24418;&#19978;&#30340;&#31574;&#30053;&#20248;&#21270;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Sample Complexity of Neural Policy Mirror Descent for Policy Optimization on Low-Dimensional Manifolds. (arXiv:2309.13915v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13915
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#31070;&#32463;&#31574;&#30053;&#38236;&#20687;&#26799;&#24230;&#31639;&#27861;&#22312;&#20302;&#32500;&#27969;&#24418;&#19978;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#30740;&#31350;&#21457;&#29616;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#65292;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#24456;&#22909;&#22320;&#36924;&#36817;&#20215;&#20540;&#20989;&#25968;&#21644;&#31574;&#30053;&#65292;&#19988;&#36924;&#36817;&#35823;&#24046;&#21463;&#32593;&#32476;&#22823;&#23567;&#30340;&#24433;&#21709;&#65292;&#24182;&#19988;&#21487;&#20197;&#32487;&#25215;&#20043;&#21069;&#32593;&#32476;&#30340;&#24179;&#28369;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#37197;&#22791;&#26377;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#22312;&#35299;&#20915;&#39640;&#32500;&#24230;&#30340;&#38382;&#39064;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#30340;&#20998;&#26512;&#26080;&#27861;&#35299;&#37322;&#23427;&#20204;&#20026;&#20309;&#33021;&#25269;&#25239;&#32500;&#24230;&#35781;&#21650;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#20989;&#25968;&#36924;&#36817;&#22120;&#30340;&#31070;&#32463;&#31574;&#30053;&#38236;&#20687;&#26799;&#24230;&#65288;NPMD&#65289;&#31639;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#21463;&#21040;&#35768;&#22810;&#39640;&#32500;&#29615;&#22659;&#20855;&#26377;&#20302;&#32500;&#32467;&#26500;&#30340;&#32463;&#39564;&#35266;&#23519;&#30340;&#21551;&#21457;&#65292;&#20363;&#22914;&#23558;&#22270;&#20687;&#20316;&#20026;&#29366;&#24577;&#65292;&#25105;&#20204;&#23558;&#29366;&#24577;&#31354;&#38388;&#35270;&#20026;&#23884;&#20837;&#22312;$D$&#32500;&#27431;&#27663;&#31354;&#38388;&#20013;&#30340;$d$&#32500;&#27969;&#24418;&#65292;&#20854;&#20013;$d\ll D$&#26159;&#20869;&#22312;&#32500;&#24230;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;NPMD&#30340;&#27599;&#27425;&#36845;&#20195;&#20013;&#65292;&#20215;&#20540;&#20989;&#25968;&#21644;&#31574;&#30053;&#37117;&#21487;&#20197;&#24456;&#22909;&#22320;&#30001;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#36924;&#36817;&#12290;&#36924;&#36817;&#35823;&#24046;&#30001;&#32593;&#32476;&#30340;&#22823;&#23567;&#25511;&#21046;&#65292;&#24182;&#19988;&#21069;&#19968;&#20010;&#32593;&#32476;&#30340;&#24179;&#28369;&#24615;&#21487;&#20197;&#20445;&#30041;&#12290;
&lt;/p&gt;
&lt;p&gt;
Policy-based algorithms equipped with deep neural networks have achieved great success in solving high-dimensional policy optimization problems in reinforcement learning. However, current analyses cannot explain why they are resistant to the curse of dimensionality. In this work, we study the sample complexity of the neural policy mirror descent (NPMD) algorithm with convolutional neural networks (CNN) as function approximators. Motivated by the empirical observation that many high-dimensional environments have state spaces possessing low-dimensional structures, such as those taking images as states, we consider the state space to be a $d$-dimensional manifold embedded in the $D$-dimensional Euclidean space with intrinsic dimension $d\ll D$. We show that in each iteration of NPMD, both the value function and the policy can be well approximated by CNNs. The approximation errors are controlled by the size of the networks, and the smoothness of the previous networks can be inherited. As a
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25913;&#36827;&#30340;&#26041;&#24046;&#26368;&#23567;&#21270;&#30340;&#20998;&#22359;&#37327;&#21270;&#31574;&#30053;&#65292;&#29992;&#20110;&#21387;&#32553;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#28608;&#27963;&#65292;&#23454;&#29616;&#20869;&#23384;&#28040;&#32791;&#30340;&#38477;&#20302;&#21644;&#36816;&#34892;&#26102;&#30340;&#21152;&#36895;&#12290;</title><link>http://arxiv.org/abs/2309.11856</link><description>&lt;p&gt;
&#20351;&#29992;&#25913;&#36827;&#30340;&#26041;&#24046;&#26368;&#23567;&#21270;&#30340;&#20998;&#22359;&#37327;&#21270;&#23545;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#28608;&#27963;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
Activation Compression of Graph Neural Networks using Block-wise Quantization with Improved Variance Minimization. (arXiv:2309.11856v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11856
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25913;&#36827;&#30340;&#26041;&#24046;&#26368;&#23567;&#21270;&#30340;&#20998;&#22359;&#37327;&#21270;&#31574;&#30053;&#65292;&#29992;&#20110;&#21387;&#32553;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#28608;&#27963;&#65292;&#23454;&#29616;&#20869;&#23384;&#28040;&#32791;&#30340;&#38477;&#20302;&#21644;&#36816;&#34892;&#26102;&#30340;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24050;&#32463;&#30740;&#31350;&#20102;&#22823;&#35268;&#27169;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#30340;&#39640;&#25928;&#35757;&#32451;&#65292;&#37325;&#28857;&#26159;&#20943;&#23569;&#20854;&#20869;&#23384;&#28040;&#32791;&#12290;Liu&#31561;&#20154;&#65288;2022&#24180;&#65289;&#25552;&#20986;&#20102;&#26497;&#38480;&#28608;&#27963;&#21387;&#32553;&#65288;EXACT&#65289;&#65292;&#36890;&#36807;&#23558;&#20013;&#38388;&#28608;&#27963;&#22270;&#30340;&#37327;&#21270;&#38477;&#33267;INT2&#31934;&#24230;&#65292;&#23454;&#29616;&#20102;&#20869;&#23384;&#28040;&#32791;&#30340;&#21095;&#28872;&#20943;&#23569;&#12290;&#20182;&#20204;&#22312;&#23454;&#29616;&#22823;&#24133;&#20943;&#23569;GPU&#20869;&#23384;&#28040;&#32791;&#30340;&#21516;&#26102;&#65292;&#34920;&#29616;&#20960;&#20046;&#27809;&#26377;&#38477;&#20302;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#20013;&#38388;&#28608;&#27963;&#22270;&#30340;&#20998;&#22359;&#37327;&#21270;&#65292;&#23545;EXACT&#31574;&#30053;&#36827;&#34892;&#20102;&#25913;&#36827;&#12290;&#25105;&#20204;&#23454;&#39564;&#20998;&#26512;&#20102;&#19981;&#21516;&#30340;&#22359;&#22823;&#23567;&#65292;&#24182;&#23637;&#31034;&#20102;&#36827;&#19968;&#27493;&#30340;&#20869;&#23384;&#28040;&#32791;&#38477;&#20302;&#65288;&gt;15%&#65289;&#21644;&#27599;&#20010;epoch&#30340;&#36816;&#34892;&#26102;&#21152;&#36895;&#65288;&#32422;5%&#65289;&#65292;&#21363;&#20351;&#36827;&#34892;&#20102;&#26497;&#20854;&#22823;&#30340;&#37327;&#21270;&#31243;&#24230;&#65292;&#20063;&#33021;&#33719;&#24471;&#19982;&#21407;&#22987;EXACT&#30456;&#20284;&#30340;&#24615;&#33021;&#26435;&#34913;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;EXACT&#20013;&#20851;&#20110;&#20013;&#38388;&#28608;&#27963;&#22270;&#20998;&#24067;&#30340;&#20551;&#35774;&#36827;&#34892;&#20102;&#32416;&#27491;&#65288;&#20551;&#35774;&#20026;u
&lt;/p&gt;
&lt;p&gt;
Efficient training of large-scale graph neural networks (GNNs) has been studied with a specific focus on reducing their memory consumption. Work by Liu et al. (2022) proposed extreme activation compression (EXACT) which demonstrated drastic reduction in memory consumption by performing quantization of the intermediate activation maps down to using INT2 precision. They showed little to no reduction in performance while achieving large reductions in GPU memory consumption. In this work, we present an improvement to the EXACT strategy by using block-wise quantization of the intermediate activation maps. We experimentally analyze different block sizes and show further reduction in memory consumption (&gt;15%), and runtime speedup per epoch (about 5%) even when performing extreme extents of quantization with similar performance trade-offs as with the original EXACT. Further, we present a correction to the assumptions on the distribution of intermediate activation maps in EXACT (assumed to be u
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#39034;&#24207;&#26694;&#26550;&#26469;&#36880;&#27493;&#23454;&#29616;&#23545;&#22810;&#20010;&#25935;&#24863;&#29305;&#24449;&#30340;&#20844;&#24179;&#24615;&#65292;&#36890;&#36807;&#21033;&#29992;&#22810;&#36793;&#38469;Wasserstein&#37325;&#24515;&#25193;&#23637;&#20102;&#26631;&#20934;&#30340;&#24378;&#20154;&#21475;&#24179;&#31561;&#27010;&#24565;&#65292;&#24182;&#25552;&#20379;&#20102;&#38381;&#24335;&#35299;&#26469;&#35299;&#37322;&#25935;&#24863;&#29305;&#24449;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.06627</link><description>&lt;p&gt;
&#22810;&#20010;&#25935;&#24863;&#23646;&#24615;&#30340;&#39034;&#24207;&#20844;&#24179;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
A Sequentially Fair Mechanism for Multiple Sensitive Attributes. (arXiv:2309.06627v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06627
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#39034;&#24207;&#26694;&#26550;&#26469;&#36880;&#27493;&#23454;&#29616;&#23545;&#22810;&#20010;&#25935;&#24863;&#29305;&#24449;&#30340;&#20844;&#24179;&#24615;&#65292;&#36890;&#36807;&#21033;&#29992;&#22810;&#36793;&#38469;Wasserstein&#37325;&#24515;&#25193;&#23637;&#20102;&#26631;&#20934;&#30340;&#24378;&#20154;&#21475;&#24179;&#31561;&#27010;&#24565;&#65292;&#24182;&#25552;&#20379;&#20102;&#38381;&#24335;&#35299;&#26469;&#35299;&#37322;&#25935;&#24863;&#29305;&#24449;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31639;&#27861;&#20844;&#24179;&#24615;&#30340;&#26631;&#20934;&#29992;&#20363;&#20013;&#65292;&#30446;&#26631;&#26159;&#28040;&#38500;&#25935;&#24863;&#21464;&#37327;&#21644;&#30456;&#24212;&#20998;&#25968;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#28982;&#32780;&#65292;&#22312;&#22810;&#20010;&#25935;&#24863;&#23646;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#20123;&#24037;&#20855;&#21644;&#23450;&#20041;&#30340;&#36866;&#29992;&#24615;&#21644;&#26377;&#25928;&#24615;&#21464;&#24471;&#26356;&#21152;&#22797;&#26434;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#39034;&#24207;&#26694;&#26550;&#65292;&#21487;&#20197;&#36880;&#27493;&#23454;&#29616;&#23545;&#19968;&#32452;&#25935;&#24863;&#29305;&#24449;&#30340;&#20844;&#24179;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#21033;&#29992;&#22810;&#36793;&#38469;Wasserstein&#37325;&#24515;&#26469;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#23558;&#26631;&#20934;&#30340;&#24378;&#20154;&#21475;&#24179;&#31561;&#27010;&#24565;&#25193;&#23637;&#21040;&#20855;&#26377;&#22810;&#20010;&#25935;&#24863;&#29305;&#24449;&#30340;&#24773;&#20917;&#12290;&#36825;&#31181;&#26041;&#27861;&#36824;&#20026;&#26368;&#20248;&#30340;&#39034;&#24207;&#20844;&#24179;&#39044;&#27979;&#22120;&#25552;&#20379;&#20102;&#38381;&#24335;&#35299;&#65292;&#21487;&#20197;&#28165;&#26970;&#22320;&#35299;&#37322;&#25935;&#24863;&#29305;&#24449;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20063;&#21487;&#20197;&#26080;&#32541;&#25193;&#23637;&#21040;&#36817;&#20284;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the standard use case of Algorithmic Fairness, the goal is to eliminate the relationship between a sensitive variable and a corresponding score. Throughout recent years, the scientific community has developed a host of definitions and tools to solve this task, which work well in many practical applications. However, the applicability and effectivity of these tools and definitions becomes less straightfoward in the case of multiple sensitive attributes. To tackle this issue, we propose a sequential framework, which allows to progressively achieve fairness across a set of sensitive features. We accomplish this by leveraging multi-marginal Wasserstein barycenters, which extends the standard notion of Strong Demographic Parity to the case with multiple sensitive characteristics. This method also provides a closed-form solution for the optimal, sequentially fair predictor, permitting a clear interpretation of inter-sensitive feature correlations. Our approach seamlessly extends to approx
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#36895;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#20984;&#20960;&#20309;&#30340;&#25104;&#20687;&#36870;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#38543;&#26426;&#24347;&#32531;&#32437;&#22352;&#26631;&#36845;&#20195;&#23454;&#29616;&#65292;&#23545;&#20110;&#39640;&#26031;&#30446;&#26631;&#26159;&#28176;&#36817;&#26080;&#20559;&#30340;&#65292;&#24182;&#19988;&#23545;&#20110;$\kappa$-&#24378;&#23545;&#25968;&#20985;&#30340;&#20219;&#20309;&#30446;&#26631;&#37117;&#33021;&#20197;&#21152;&#36895;&#26041;&#24335;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2308.09460</link><description>&lt;p&gt;
&#21152;&#36895;&#36125;&#21494;&#26031;&#25104;&#20687;&#30340;&#24347;&#32531;&#32437;&#22352;&#26631;&#20848;&#27663;&#25277;&#26679;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Accelerated Bayesian imaging by relaxed proximal-point Langevin sampling. (arXiv:2308.09460v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09460
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#36895;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#20984;&#20960;&#20309;&#30340;&#25104;&#20687;&#36870;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#38543;&#26426;&#24347;&#32531;&#32437;&#22352;&#26631;&#36845;&#20195;&#23454;&#29616;&#65292;&#23545;&#20110;&#39640;&#26031;&#30446;&#26631;&#26159;&#28176;&#36817;&#26080;&#20559;&#30340;&#65292;&#24182;&#19988;&#23545;&#20110;$\kappa$-&#24378;&#23545;&#25968;&#20985;&#30340;&#20219;&#20309;&#30446;&#26631;&#37117;&#33021;&#20197;&#21152;&#36895;&#26041;&#24335;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21152;&#36895;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20855;&#26377;&#20984;&#20960;&#20309;&#30340;&#25104;&#20687;&#36870;&#38382;&#39064;&#20013;&#36827;&#34892;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;&#25152;&#25552;&#20986;&#30340;&#31574;&#30053;&#37319;&#29992;&#38543;&#26426;&#24347;&#32531;&#32437;&#22352;&#26631;&#36845;&#20195;&#30340;&#24418;&#24335;&#65292;&#20855;&#26377;&#20004;&#31181;&#20114;&#34917;&#30340;&#35299;&#37322;&#26041;&#24335;&#12290;&#23545;&#20110;&#36890;&#36807;Moreau-Yosida&#24179;&#28369;&#36827;&#34892;&#24179;&#28369;&#25110;&#27491;&#21017;&#21270;&#30340;&#27169;&#22411;&#65292;&#35813;&#31639;&#27861;&#31561;&#20215;&#20110;&#30446;&#26631;&#21518;&#39564;&#20998;&#24067;&#19978;&#30340;&#38544;&#24335;&#20013;&#28857;&#31163;&#25955;&#21270;&#36807;&#28857;&#20848;&#27663;&#25193;&#25955;&#65292;&#23545;&#20110;&#39640;&#26031;&#30446;&#26631;&#26159;&#28176;&#36817;&#26080;&#20559;&#30340;&#65292;&#24182;&#19988;&#23545;&#20110;$\kappa$-&#24378;&#23545;&#25968;&#20985;&#65288;&#21363;&#38656;&#35201;&#22823;&#32422;$\sqrt{\kappa}$&#27425;&#36845;&#20195;&#26469;&#25910;&#25947;&#65292;&#31867;&#20284;&#20110;&#21152;&#36895;&#20248;&#21270;&#26041;&#26696;&#65289;&#30340;&#20219;&#20309;&#30446;&#26631;&#37117;&#25910;&#25947;&#21152;&#36895;&#65292;&#19982;[M. Pereyra, L. Vargas Mieles, K.C. Zygalakis, SIAM J. Imaging Sciences, 13, 2 (2020), pp. 905-935]&#30456;&#27604;&#65292;&#22312;&#39640;&#26031;&#30446;&#26631;&#19978;&#21482;&#33021;&#35777;&#26126;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a new accelerated proximal Markov chain Monte Carlo methodology to perform Bayesian inference in imaging inverse problems with an underlying convex geometry. The proposed strategy takes the form of a stochastic relaxed proximal-point iteration that admits two complementary interpretations. For models that are smooth or regularised by Moreau-Yosida smoothing, the algorithm is equivalent to an implicit midpoint discretisation of an overdamped Langevin diffusion targeting the posterior distribution of interest. This discretisation is asymptotically unbiased for Gaussian targets and shown to converge in an accelerated manner for any target that is $\kappa$-strongly log-concave (i.e., requiring in the order of $\sqrt{\kappa}$ iterations to converge, similarly to accelerated optimisation schemes), comparing favorably to [M. Pereyra, L. Vargas Mieles, K.C. Zygalakis, SIAM J. Imaging Sciences, 13, 2 (2020), pp. 905-935] which is only provably accelerated for Gaussian target
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#21644;&#23618;&#27425;&#32858;&#31867;&#24212;&#29992;&#20110;&#36125;&#21494;&#26031;&#32593;&#32476;&#23398;&#20064;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#20892;&#23398;&#30740;&#31350;&#20013;&#24191;&#27867;&#24212;&#29992;&#12290;&#36890;&#36807;&#25972;&#21512;&#38543;&#26426;&#25928;&#24212;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#32467;&#26500;&#23398;&#20064;&#33021;&#21147;&#65292;&#23454;&#29616;&#22240;&#26524;&#20851;&#31995;&#32593;&#32476;&#30340;&#21457;&#29616;&#12290;</title><link>http://arxiv.org/abs/2308.06399</link><description>&lt;p&gt;
&#36890;&#36807;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#21644;&#23618;&#27425;&#32858;&#31867;&#23398;&#20064;&#20855;&#26377;&#24322;&#26500;&#20892;&#19994;&#25968;&#25454;&#38598;&#30340;&#36125;&#21494;&#26031;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Learning Bayesian Networks with Heterogeneous Agronomic Data Sets via Mixed-Effect Models and Hierarchical Clustering. (arXiv:2308.06399v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06399
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#21644;&#23618;&#27425;&#32858;&#31867;&#24212;&#29992;&#20110;&#36125;&#21494;&#26031;&#32593;&#32476;&#23398;&#20064;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#20892;&#23398;&#30740;&#31350;&#20013;&#24191;&#27867;&#24212;&#29992;&#12290;&#36890;&#36807;&#25972;&#21512;&#38543;&#26426;&#25928;&#24212;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#32467;&#26500;&#23398;&#20064;&#33021;&#21147;&#65292;&#23454;&#29616;&#22240;&#26524;&#20851;&#31995;&#32593;&#32476;&#30340;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28041;&#21450;&#22810;&#26679;&#20294;&#30456;&#20851;&#25968;&#25454;&#38598;&#30340;&#30740;&#31350;&#20013;&#65292;&#20854;&#20013;&#21327;&#21464;&#37327;&#19982;&#32467;&#26524;&#20043;&#38388;&#30340;&#20851;&#32852;&#21487;&#33021;&#20250;&#26377;&#25152;&#19981;&#21516;&#65292;&#22312;&#21253;&#25324;&#20892;&#23398;&#30740;&#31350;&#22312;&#20869;&#30340;&#21508;&#20010;&#39046;&#22495;&#37117;&#24456;&#26222;&#36941;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#24120;&#24120;&#20351;&#29992;&#23618;&#27425;&#27169;&#22411;&#65292;&#20063;&#34987;&#31216;&#20026;&#22810;&#23618;&#27169;&#22411;&#65292;&#26469;&#34701;&#21512;&#26469;&#33258;&#19981;&#21516;&#25968;&#25454;&#38598;&#30340;&#20449;&#24687;&#65292;&#24182;&#36866;&#24212;&#23427;&#20204;&#30340;&#19981;&#21516;&#29305;&#28857;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#32467;&#26500;&#36229;&#20986;&#20102;&#31616;&#21333;&#30340;&#24322;&#36136;&#24615;&#65292;&#22240;&#20026;&#21464;&#37327;&#36890;&#24120;&#24418;&#25104;&#22797;&#26434;&#30340;&#22240;&#26524;&#20851;&#31995;&#32593;&#32476;&#12290;&#36125;&#21494;&#26031;&#32593;&#32476;&#65288;BNs&#65289;&#20351;&#29992;&#26377;&#21521;&#26080;&#29615;&#22270;&#26469;&#27169;&#25311;&#36825;&#31181;&#20851;&#31995;&#30340;&#24378;&#22823;&#26694;&#26550;&#12290;&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#38543;&#26426;&#25928;&#24212;&#25972;&#21512;&#21040;BN&#23398;&#20064;&#20013;&#30340;&#26032;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#22522;&#20110;&#32447;&#24615;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#22788;&#29702;&#23618;&#27425;&#25968;&#25454;&#12290;&#26469;&#33258;&#30495;&#23454;&#20892;&#23398;&#35797;&#39564;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#37319;&#29992;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#22686;&#24378;&#32467;&#26500;&#23398;&#20064;&#65292;&#20174;&#32780;&#23454;&#29616;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Research involving diverse but related data sets, where associations between covariates and outcomes may vary, is prevalent in various fields including agronomic studies. In these scenarios, hierarchical models, also known as multilevel models, are frequently employed to assimilate information from different data sets while accommodating their distinct characteristics. However, their structure extend beyond simple heterogeneity, as variables often form complex networks of causal relationships.  Bayesian networks (BNs) provide a powerful framework for modelling such relationships using directed acyclic graphs to illustrate the connections between variables. This study introduces a novel approach that integrates random effects into BN learning. Rooted in linear mixed-effects models, this approach is particularly well-suited for handling hierarchical data. Results from a real-world agronomic trial suggest that employing this approach enhances structural learning, leading to the discovery 
&lt;/p&gt;</description></item><item><title>CardiGraphormer&#26159;&#19968;&#31181;&#38761;&#21629;&#24615;&#30340;&#26041;&#27861;&#65292;&#32467;&#21512;&#20102;&#33258;&#30417;&#30563;&#23398;&#20064;&#12289;&#22270;&#31070;&#32463;&#32593;&#32476;&#21644;&#20445;&#25345;&#22522;&#25968;&#27880;&#24847;&#21147;&#65292;&#39072;&#35206;&#20102;&#33647;&#29289;&#21457;&#29616;&#30340;&#26041;&#24335;&#12290;&#23427;&#21033;&#29992;&#33258;&#30417;&#30563;&#23398;&#20064;&#23398;&#20064;&#20998;&#23376;&#34920;&#31034;&#24182;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#25552;&#21462;&#20998;&#23376;&#25351;&#32441;&#65292;&#25552;&#39640;&#20102;&#39044;&#27979;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#21516;&#26102;&#20943;&#23569;&#20102;&#35745;&#31639;&#26102;&#38388;&#65292;&#24182;&#22312;&#22788;&#29702;&#22797;&#26434;&#25968;&#25454;&#21644;&#25191;&#34892;&#21508;&#31181;&#19982;&#22270;&#32467;&#26500;&#30456;&#20851;&#30340;&#20219;&#21153;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>http://arxiv.org/abs/2307.00859</link><description>&lt;p&gt;
CardiGraphormer: &#25581;&#31034;&#33258;&#30417;&#30563;&#23398;&#20064;&#22312;&#39072;&#35206;&#33647;&#29289;&#21457;&#29616;&#20013;&#30340;&#21147;&#37327;
&lt;/p&gt;
&lt;p&gt;
CardiGraphormer: Unveiling the Power of Self-Supervised Learning in Revolutionizing Drug Discovery. (arXiv:2307.00859v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00859
&lt;/p&gt;
&lt;p&gt;
CardiGraphormer&#26159;&#19968;&#31181;&#38761;&#21629;&#24615;&#30340;&#26041;&#27861;&#65292;&#32467;&#21512;&#20102;&#33258;&#30417;&#30563;&#23398;&#20064;&#12289;&#22270;&#31070;&#32463;&#32593;&#32476;&#21644;&#20445;&#25345;&#22522;&#25968;&#27880;&#24847;&#21147;&#65292;&#39072;&#35206;&#20102;&#33647;&#29289;&#21457;&#29616;&#30340;&#26041;&#24335;&#12290;&#23427;&#21033;&#29992;&#33258;&#30417;&#30563;&#23398;&#20064;&#23398;&#20064;&#20998;&#23376;&#34920;&#31034;&#24182;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#25552;&#21462;&#20998;&#23376;&#25351;&#32441;&#65292;&#25552;&#39640;&#20102;&#39044;&#27979;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#21516;&#26102;&#20943;&#23569;&#20102;&#35745;&#31639;&#26102;&#38388;&#65292;&#24182;&#22312;&#22788;&#29702;&#22797;&#26434;&#25968;&#25454;&#21644;&#25191;&#34892;&#21508;&#31181;&#19982;&#22270;&#32467;&#26500;&#30456;&#20851;&#30340;&#20219;&#21153;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24191;&#38420;&#30340;&#33647;&#29289;&#21457;&#29616;&#39046;&#22495;&#20013;&#65292;&#24050;&#30693;&#33647;&#29289;&#32422;&#26377;15,000&#31181;&#65292;&#20294;&#21482;&#26377;&#22823;&#32422;4,200&#31181;&#24471;&#21040;&#20102;&#25209;&#20934;&#65292;&#21270;&#23398;&#31354;&#38388;&#30340;&#32452;&#21512;&#24615;&#36136;&#25552;&#20379;&#20102;&#19968;&#39033;&#33392;&#24040;&#30340;&#25361;&#25112;&#12290;&#23613;&#31649;&#20154;&#24037;&#26234;&#33021;&#25104;&#20026;&#20102;&#26377;&#21147;&#30340;&#20249;&#20276;&#65292;&#20256;&#32479;&#30340;&#20154;&#24037;&#26234;&#33021;&#26694;&#26550;&#20173;&#38754;&#20020;&#37325;&#22823;&#38556;&#30861;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;CardiGraphormer&#65292;&#36825;&#26159;&#19968;&#31181;&#21010;&#26102;&#20195;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#12289;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#21644;&#20445;&#25345;&#22522;&#25968;&#27880;&#24847;&#21147;&#65292;&#20174;&#32780;&#39072;&#35206;&#33647;&#29289;&#21457;&#29616;&#12290;CardiGraphormer&#26159;Graphormer&#21644;&#20445;&#25345;&#22522;&#25968;&#27880;&#24847;&#21147;&#30340;&#26032;&#39062;&#32452;&#21512;&#65292;&#21033;&#29992;SSL&#23398;&#20064;&#26377;&#25928;&#30340;&#20998;&#23376;&#34920;&#31034;&#65292;&#24182;&#21033;&#29992;GNN&#25552;&#21462;&#20998;&#23376;&#25351;&#32441;&#65292;&#25552;&#39640;&#20102;&#39044;&#27979;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#20943;&#23569;&#20102;&#35745;&#31639;&#26102;&#38388;&#12290;&#23427;&#22312;&#22788;&#29702;&#20998;&#23376;&#32467;&#26500;&#31561;&#22797;&#26434;&#25968;&#25454;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#24182;&#33021;&#25191;&#34892;&#19982;&#33410;&#28857;&#12289;&#33410;&#28857;&#23545;&#12289;&#23376;&#22270;&#25110;&#25972;&#20010;&#22270;&#32467;&#26500;&#30456;&#20851;&#30340;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the expansive realm of drug discovery, with approximately 15,000 known drugs and only around 4,200 approved, the combinatorial nature of the chemical space presents a formidable challenge. While Artificial Intelligence (AI) has emerged as a powerful ally, traditional AI frameworks face significant hurdles. This manuscript introduces CardiGraphormer, a groundbreaking approach that synergizes self-supervised learning (SSL), Graph Neural Networks (GNNs), and Cardinality Preserving Attention to revolutionize drug discovery. CardiGraphormer, a novel combination of Graphormer and Cardinality Preserving Attention, leverages SSL to learn potent molecular representations and employs GNNs to extract molecular fingerprints, enhancing predictive performance and interpretability while reducing computation time. It excels in handling complex data like molecular structures and performs tasks associated with nodes, pairs of nodes, subgraphs, or entire graph structures. CardiGraphormer's potential a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35782;&#21035;&#38750;&#32447;&#24615;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#20013;&#22240;&#26524;&#26426;&#21046;&#36716;&#21464;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#19987;&#27880;&#20110;&#22312;&#30456;&#20851;&#30340;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#20013;&#35782;&#21035;&#21151;&#33021;&#26426;&#21046;&#30340;&#21464;&#21270;&#65292;&#32780;&#19981;&#38656;&#35201;&#20272;&#35745;&#25972;&#20010;&#26377;&#21521;&#26080;&#29615;&#22270;(DAG)&#30340;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2306.17361</link><description>&lt;p&gt;
iSCAN&#65306;&#35782;&#21035;&#38750;&#32447;&#24615;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#20013;&#30340;&#22240;&#26524;&#26426;&#21046;&#36716;&#21464;
&lt;/p&gt;
&lt;p&gt;
iSCAN: Identifying Causal Mechanism Shifts among Nonlinear Additive Noise Models. (arXiv:2306.17361v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17361
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35782;&#21035;&#38750;&#32447;&#24615;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#20013;&#22240;&#26524;&#26426;&#21046;&#36716;&#21464;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#19987;&#27880;&#20110;&#22312;&#30456;&#20851;&#30340;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#20013;&#35782;&#21035;&#21151;&#33021;&#26426;&#21046;&#30340;&#21464;&#21270;&#65292;&#32780;&#19981;&#38656;&#35201;&#20272;&#35745;&#25972;&#20010;&#26377;&#21521;&#26080;&#29615;&#22270;(DAG)&#30340;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;(SCM)&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#21508;&#20010;&#39046;&#22495;&#65292;&#20197;&#34920;&#31034;&#22797;&#26434;&#31995;&#32479;&#20013;&#21464;&#37327;&#20043;&#38388;&#30340;&#22240;&#26524;&#20851;&#31995;&#12290;&#28982;&#32780;&#65292;&#30495;&#27491;&#30340;&#24213;&#23618;&#26377;&#21521;&#26080;&#29615;&#22270;(DAG)&#32467;&#26500;&#36890;&#24120;&#26159;&#26410;&#30693;&#30340;&#65292;&#24182;&#19988;&#20174;&#35266;&#27979;&#25968;&#25454;&#25110;&#24178;&#39044;&#25968;&#25454;&#20013;&#30830;&#23450;&#23427;&#20173;&#28982;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#30446;&#26631;&#26159;&#35782;&#21035;&#30456;&#20851;SCM&#20043;&#38388;&#30340;&#22240;&#26524;&#26426;&#21046;&#30340;&#21464;&#21270;(&#36716;&#21464;)&#32780;&#19981;&#26159;&#24674;&#22797;&#25972;&#20010;&#24213;&#23618;DAG&#32467;&#26500;&#12290;&#20363;&#23376;&#21253;&#25324;&#20998;&#26512;&#20581;&#24247;&#21644;&#30284;&#30151;&#24739;&#32773;&#20043;&#38388;&#30340;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#32467;&#26500;&#21464;&#21270;&#65292;&#25110;&#32773;&#22312;&#19981;&#21516;&#32454;&#32990;&#29615;&#22659;&#19979;&#29702;&#35299;&#29983;&#29289;&#36884;&#24452;&#30340;&#21464;&#21270;&#12290;&#26412;&#25991;&#37325;&#28857;&#30740;&#31350;&#20102;&#22312;&#30456;&#21516;&#30340;&#21464;&#37327;&#38598;&#19978;&#35782;&#21035;&#20004;&#20010;&#25110;&#22810;&#20010;&#30456;&#20851;SCM&#20013;&#30340;$\textit{&#21151;&#33021;}$&#26426;&#21046;&#36716;&#21464;&#65292;&#32780;&#19981;&#38656;&#35201;&#20272;&#35745;&#27599;&#20010;SCM&#30340;&#25972;&#20010;DAG&#32467;&#26500;&#12290;&#22312;&#36825;&#31181;&#35774;&#32622;&#19979;&#65292;&#20808;&#21069;&#30340;&#24037;&#20316;&#20551;&#35774;&#20351;&#29992;&#20102;&#20855;&#26377;&#39640;&#26031;&#22122;&#22768;&#30340;&#32447;&#24615;&#27169;&#22411;&#65307;&#32780;&#26412;&#25991;&#20013;&#25105;&#20204;&#21017;&#32771;&#34385;&#20102;&#38750;&#32447;&#24615;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Structural causal models (SCMs) are widely used in various disciplines to represent causal relationships among variables in complex systems. Unfortunately, the true underlying directed acyclic graph (DAG) structure is often unknown, and determining it from observational or interventional data remains a challenging task. However, in many situations, the end goal is to identify changes (shifts) in causal mechanisms between related SCMs rather than recovering the entire underlying DAG structure. Examples include analyzing gene regulatory network structure changes between healthy and cancerous individuals or understanding variations in biological pathways under different cellular contexts. This paper focuses on identifying $\textit{functional}$ mechanism shifts in two or more related SCMs over the same set of variables -$\textit{without estimating the entire DAG structure of each SCM}$. Prior work under this setting assumed linear models with Gaussian noises; instead, in this work we ass
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#32034;&#20102;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#20174;&#39640;&#26031;&#36807;&#31243;&#21518;&#39564;&#20013;&#37319;&#26679;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#35745;&#31639;&#39640;&#25928;&#19988;&#33021;&#22312;&#36275;&#22815;&#35206;&#30422;&#25968;&#25454;&#30340;&#21306;&#22495;&#21644;&#36275;&#22815;&#36828;&#31163;&#25968;&#25454;&#30340;&#21306;&#22495;&#20013;&#20135;&#29983;&#25509;&#36817;&#30495;&#23454;&#21518;&#39564;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2306.11589</link><description>&lt;p&gt;
&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20174;&#39640;&#26031;&#36807;&#31243;&#21518;&#39564;&#20013;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Sampling from Gaussian Process Posteriors using Stochastic Gradient Descent. (arXiv:2306.11589v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11589
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#20174;&#39640;&#26031;&#36807;&#31243;&#21518;&#39564;&#20013;&#37319;&#26679;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#35745;&#31639;&#39640;&#25928;&#19988;&#33021;&#22312;&#36275;&#22815;&#35206;&#30422;&#25968;&#25454;&#30340;&#21306;&#22495;&#21644;&#36275;&#22815;&#36828;&#31163;&#25968;&#25454;&#30340;&#21306;&#22495;&#20013;&#20135;&#29983;&#25509;&#36817;&#30495;&#23454;&#21518;&#39564;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#26159;&#29992;&#20110;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#21644;&#39034;&#24207;&#20915;&#31574;&#30340;&#24378;&#22823;&#26694;&#26550;&#65292;&#20294;&#20854;&#38656;&#35201;&#27714;&#35299;&#32447;&#24615;&#31995;&#32479;&#65292;&#27599;&#24403;&#25968;&#25454;&#38598;&#22823;&#23567;&#22686;&#21152;&#26102;&#20195;&#20215;&#26159;&#31435;&#26041;&#32423;&#21035;&#30340;&#19988;&#23545;&#26465;&#20214;&#25935;&#24863;&#12290;&#26412;&#25991;&#25506;&#32034;&#20102;&#38543;&#26426;&#26799;&#24230;&#31639;&#27861;&#20316;&#20026;&#19968;&#31181;&#35745;&#31639;&#39640;&#25928;&#30340;&#26041;&#27861;&#26469;&#36817;&#20284;&#35299;&#20915;&#36825;&#20123;&#32447;&#24615;&#31995;&#32479;&#65306;&#25105;&#20204;&#24320;&#21457;&#20102;&#20302;&#26041;&#24046;&#30340;&#26368;&#20248;&#21270;&#30446;&#26631;&#20197;&#20174;&#21518;&#39564;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#24182;&#23558;&#20854;&#25193;&#23637;&#21040;&#24341;&#20837;&#28857;&#12290;&#20196;&#20154;&#24847;&#24819;&#19981;&#21040;&#30340;&#26159;&#65292;&#21363;&#20351;&#22312;&#19981;&#24555;&#36895;&#25910;&#25947;&#21040;&#26368;&#20248;&#35299;&#30340;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#36890;&#24120;&#20063;&#20250;&#20135;&#29983;&#20934;&#30830;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#36890;&#36807;&#38750;&#25910;&#25947;&#30340;&#38544;&#24335;&#20559;&#32622;&#30340;&#35889;&#29305;&#24449;&#26469;&#35299;&#37322;&#36825;&#19968;&#28857;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20250;&#22312;&#36275;&#22815;&#35206;&#30422;&#25968;&#25454;&#30340;&#21306;&#22495;&#21644;&#36275;&#22815;&#36828;&#31163;&#25968;&#25454;&#30340;&#21306;&#22495;&#20013;&#20135;&#29983;&#25509;&#36817;&#30495;&#23454;&#21518;&#39564;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#23454;&#29616;&#20102;
&lt;/p&gt;
&lt;p&gt;
Gaussian processes are a powerful framework for quantifying uncertainty and for sequential decision-making but are limited by the requirement of solving linear systems. In general, this has a cubic cost in dataset size and is sensitive to conditioning. We explore stochastic gradient algorithms as a computationally efficient method of approximately solving these linear systems: we develop low-variance optimization objectives for sampling from the posterior and extend these to inducing points. Counterintuitively, stochastic gradient descent often produces accurate predictions, even in cases where it does not converge quickly to the optimum. We explain this through a spectral characterization of the implicit bias from non-convergence. We show that stochastic gradient descent produces predictive distributions close to the true posterior both in regions with sufficient data coverage, and in regions sufficiently far away from the data. Experimentally, stochastic gradient descent achieves sta
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36755;&#20986;&#36827;&#34892;&#19979;&#28216;&#32479;&#35745;&#20998;&#26512;&#65292;&#20197;&#23454;&#29616;&#26377;&#25928;&#30340;&#19979;&#28216;&#32479;&#35745;&#25512;&#26029;&#65292;&#24182;&#38477;&#20302;&#26631;&#31614;&#33719;&#21462;&#30340;&#30740;&#31350;&#25104;&#26412;80&#65285;&#65292;&#21516;&#26102;&#20445;&#35777;CSS&#30740;&#31350;&#30340;&#32479;&#35745;&#23646;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.04746</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27880;&#37322;&#36827;&#34892;&#31038;&#20250;&#31185;&#23398;&#20013;&#30340;&#26377;&#25928;&#19979;&#28216;&#32479;&#35745;&#25512;&#26029;: &#22522;&#20110;&#35774;&#35745;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Using Large Language Model Annotations for Valid Downstream Statistical Inference in Social Science: Design-Based Semi-Supervised Learning. (arXiv:2306.04746v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04746
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36755;&#20986;&#36827;&#34892;&#19979;&#28216;&#32479;&#35745;&#20998;&#26512;&#65292;&#20197;&#23454;&#29616;&#26377;&#25928;&#30340;&#19979;&#28216;&#32479;&#35745;&#25512;&#26029;&#65292;&#24182;&#38477;&#20302;&#26631;&#31614;&#33719;&#21462;&#30340;&#30740;&#31350;&#25104;&#26412;80&#65285;&#65292;&#21516;&#26102;&#20445;&#35777;CSS&#30740;&#31350;&#30340;&#32479;&#35745;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35745;&#31639;&#31038;&#20250;&#31185;&#23398;&#65288;CSS&#65289;&#20013;&#65292;&#30740;&#31350;&#20154;&#21592;&#36890;&#36807;&#20998;&#26512;&#25991;&#26723;&#26469;&#35299;&#37322;&#31038;&#20250;&#21644;&#25919;&#27835;&#29616;&#35937;&#12290;&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#65292;CSS&#30740;&#31350;&#20154;&#21592;&#39318;&#20808;&#33719;&#21462;&#25991;&#26723;&#30340;&#26631;&#31614;&#65292;&#28982;&#21518;&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;&#22238;&#24402;&#20998;&#26512;&#26469;&#35299;&#37322;&#26631;&#31614;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#26368;&#36817;&#36827;&#23637;&#21487;&#20197;&#36890;&#36807;&#22312;&#35268;&#27169;&#19978;&#20415;&#23452;&#22320;&#27880;&#37322;&#25991;&#26723;&#26469;&#38477;&#20302;CSS&#30740;&#31350;&#25104;&#26412;&#65292;&#20294;&#36825;&#20123;&#26367;&#20195;&#26631;&#31614;&#36890;&#24120;&#26159;&#19981;&#23436;&#32654;&#21644;&#26377;&#20559;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#29992;&#20110;&#20351;&#29992;LLMs&#30340;&#36755;&#20986;&#36827;&#34892;&#19979;&#28216;&#32479;&#35745;&#20998;&#26512;&#65292;&#21516;&#26102;&#20445;&#35777;&#19982;CSS&#30740;&#31350;&#22522;&#26412;&#30456;&#20851;&#30340;&#32479;&#35745;&#23646;&#24615;-&#22914;&#28176;&#36817;&#26080;&#20559;&#24615;&#21644;&#27491;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#30452;&#25509;&#22312;&#19979;&#28216;&#32479;&#35745;&#20998;&#26512;&#20013;&#20351;&#29992;LLM&#39044;&#27979;&#30340;&#26367;&#20195;&#26631;&#31614;&#20250;&#23548;&#33268;&#23454;&#36136;&#24615;&#20559;&#24046;&#21644;&#26080;&#25928;&#32622;&#20449;&#21306;&#38388;&#65292;&#21363;&#20351;&#26367;&#20195;&#20934;&#30830;&#24615;&#39640;&#36798;80-90&#65285;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#22522;&#20110;&#26080;&#20559;&#26426;&#22120;&#23398;&#20064;&#25552;&#20986;&#20102;&#22522;&#20110;&#35774;&#35745;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#65288;D-SSL&#65289;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#23558;LLM&#27880;&#37322;&#19982;&#26377;&#38024;&#23545;&#24615;&#30340;&#37319;&#26679;&#30456;&#32467;&#21512;&#65292;&#20197;&#23454;&#29616;&#26377;&#25928;&#30340;&#19979;&#28216;&#32479;&#35745;&#25512;&#26029;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#23558;&#26631;&#31614;&#33719;&#21462;&#30340;CSS&#30740;&#31350;&#25104;&#26412;&#38477;&#20302;80&#65285;&#65292;&#32780;&#19981;&#24433;&#21709;&#32479;&#35745;&#20998;&#26512;&#30340;&#26377;&#25928;&#24615;&#12290;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#25968;&#25454;&#31034;&#20363;&#34920;&#26126;&#65292;&#19982;&#30452;&#25509;&#20351;&#29992;LLM&#39044;&#27979;&#26631;&#31614;&#30456;&#27604;&#65292;D-SSL&#21487;&#20197;&#23558;&#22238;&#24402;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#25552;&#39640;&#22810;&#36798;40&#65285;&#12290;
&lt;/p&gt;
&lt;p&gt;
In computational social science (CSS), researchers analyze documents to explain social and political phenomena. In most scenarios, CSS researchers first obtain labels for documents and then explain labels using interpretable regression analyses in the second step. The recent advancements in large language models (LLMs) can lower costs for CSS research by annotating documents cheaply at scale, but such surrogate labels are often imperfect and biased. We present a new algorithm for using outputs from LLMs for downstream statistical analyses while guaranteeing statistical properties -- like asymptotic unbiasedness and proper uncertainty quantification -- which are fundamental to CSS research. We show that direct use of LLM-predicted surrogate labels in downstream statistical analyses leads to substantial bias and invalid confidence intervals, even with high surrogate accuracy of 80--90\%. To address this, we build on debiased machine learning to propose the design-based semi-supervised le
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;$(k, t)$-FWL&#21644;$k$-FWL+&#20004;&#31181;&#26041;&#27861;&#65292;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#23427;&#20204;&#21487;&#20197;&#22312;$O(n^2)$&#30340;&#31354;&#38388;&#22797;&#26434;&#24230;&#19979;&#65292;&#35299;&#20915;&#22270;&#21516;&#26500;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.03266</link><description>&lt;p&gt;
&#36890;&#36807;&#37325;&#26032;&#24605;&#32771;&#27665;&#38388;&#23041;&#26031;&#36153;&#21202;-&#33713;&#26364;&#31639;&#27861;&#65292;&#23454;&#29616;$O(n^2)$&#31354;&#38388;&#20869;&#20219;&#24847;&#34920;&#36798;&#33021;&#21147;&#30340;GNNs
&lt;/p&gt;
&lt;p&gt;
Towards Arbitrarily Expressive GNNs in $O(n^2)$ Space by Rethinking Folklore Weisfeiler-Lehman. (arXiv:2306.03266v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03266
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;$(k, t)$-FWL&#21644;$k$-FWL+&#20004;&#31181;&#26041;&#27861;&#65292;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#23427;&#20204;&#21487;&#20197;&#22312;$O(n^2)$&#30340;&#31354;&#38388;&#22797;&#26434;&#24230;&#19979;&#65292;&#35299;&#20915;&#22270;&#21516;&#26500;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#28040;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#65288;MPNNs&#65289;&#24050;&#25104;&#20026;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#20013;&#26368;&#21463;&#27426;&#36814;&#30340;&#26694;&#26550;&#12290;&#28982;&#32780;&#65292;&#20854;&#34920;&#36798;&#33021;&#21147;&#21463;&#21040;&#19968;&#32500;&#23041;&#26031;&#36153;&#21202;-&#33713;&#26364;&#65288;1-WL&#65289;&#27979;&#35797;&#30340;&#38480;&#21046;&#12290;&#19968;&#20123;&#30740;&#31350;&#21463;&#21040;$k$-WL/FWL&#65288;&#27665;&#38388;WL&#65289;&#30340;&#21551;&#21457;&#24182;&#35774;&#35745;&#20854;&#30456;&#24212;&#30340;&#31070;&#32463;&#29256;&#26412;&#12290;&#23613;&#31649;&#20855;&#26377;&#24456;&#39640;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#20294;&#36825;&#19968;&#30740;&#31350;&#26041;&#21521;&#23384;&#22312;&#20005;&#37325;&#23616;&#38480;&#24615;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;$(k, t)$-FWL&#21644;$k$-FWL+&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Message passing neural networks (MPNNs) have emerged as the most popular framework of graph neural networks (GNNs) in recent years. However, their expressive power is limited by the 1-dimensional Weisfeiler-Lehman (1-WL) test. Some works are inspired by $k$-WL/FWL (Folklore WL) and design the corresponding neural versions. Despite the high expressive power, there are serious limitations in this line of research. In particular, (1) $k$-WL/FWL requires at least $O(n^k)$ space complexity, which is impractical for large graphs even when $k=3$; (2) The design space of $k$-WL/FWL is rigid, with the only adjustable hyper-parameter being $k$. To tackle the first limitation, we propose an extension, $(k, t)$-FWL. We theoretically prove that even if we fix the space complexity to $O(n^2)$ in $(k, t)$-FWL, we can construct an expressiveness hierarchy up to solving the graph isomorphism problem. To tackle the second problem, we propose $k$-FWL+, which considers any equivariant set as neighbors ins
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#26694;&#26550;&#65292;&#23558;&#20219;&#20309;&#21333;&#33218;&#31574;&#30053;&#36716;&#21270;&#20026;&#21407;&#22987;&#30340;$N$&#33218;&#38382;&#39064;&#30340;&#31574;&#30053;&#65292;&#35299;&#20915;&#20102;&#20381;&#36182;&#20110;&#22797;&#26434;UGAP&#20551;&#35774;&#30340;&#38382;&#39064;&#65292;&#24182;&#23454;&#29616;&#20102;&#20855;&#26377;$O(1/\sqrt{N})$&#26368;&#20248;&#24615;&#24046;&#36317;&#30340;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2306.00196</link><description>&lt;p&gt;
&#20855;&#26377;&#24179;&#22343;&#22870;&#21169;&#30340;&#19981;&#23433;&#23450;&#36172;&#24466;&#38382;&#39064;&#65306;&#25171;&#30772;&#32479;&#19968;&#20840;&#23616;&#24341;&#23376;&#20551;&#35774;
&lt;/p&gt;
&lt;p&gt;
Restless Bandits with Average Reward: Breaking the Uniform Global Attractor Assumption. (arXiv:2306.00196v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00196
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#26694;&#26550;&#65292;&#23558;&#20219;&#20309;&#21333;&#33218;&#31574;&#30053;&#36716;&#21270;&#20026;&#21407;&#22987;&#30340;$N$&#33218;&#38382;&#39064;&#30340;&#31574;&#30053;&#65292;&#35299;&#20915;&#20102;&#20381;&#36182;&#20110;&#22797;&#26434;UGAP&#20551;&#35774;&#30340;&#38382;&#39064;&#65292;&#24182;&#23454;&#29616;&#20102;&#20855;&#26377;$O(1/\sqrt{N})$&#26368;&#20248;&#24615;&#24046;&#36317;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#24179;&#22343;&#22870;&#21169;&#26631;&#20934;&#19979;&#30340;&#26080;&#38480;&#26102;&#19981;&#23433;&#23450;&#36172;&#24466;&#38382;&#39064;&#65292;&#21253;&#25324;&#31163;&#25955;&#26102;&#38388;&#21644;&#36830;&#32493;&#26102;&#38388;&#35774;&#32622;&#12290;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#26159;&#22914;&#20309;&#35774;&#35745;&#35745;&#31639;&#26377;&#25928;&#30340;&#31574;&#30053;&#65292;&#20351;&#24471;&#20248;&#21270;&#24046;&#36317;&#38543;&#30528;&#33218;&#30340;&#25968;&#37327;$N$&#30340;&#22686;&#21152;&#32780;&#20943;&#23567;&#12290;&#29616;&#26377;&#30340;&#28176;&#36817;&#26368;&#20248;&#24615;&#32467;&#26524;&#37117;&#20381;&#36182;&#20110;&#32479;&#19968;&#20840;&#23616;&#24341;&#23376;&#24615;&#36136;(UGAP)&#65292;&#36825;&#26159;&#19968;&#20010;&#22797;&#26434;&#19988;&#38590;&#20197;&#39564;&#35777;&#30340;&#20551;&#35774;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#12289;&#22522;&#20110;&#27169;&#25311;&#30340;&#26694;&#26550;&#65292;&#23558;&#20219;&#20309;&#21333;&#33218;&#31574;&#30053;&#36716;&#21270;&#20026;&#21407;&#22987;&#30340;$N$&#33218;&#38382;&#39064;&#30340;&#31574;&#30053;&#12290;&#36825;&#26159;&#36890;&#36807;&#22312;&#27599;&#20010;&#33218;&#19978;&#27169;&#25311;&#21333;&#33218;&#31574;&#30053;&#65292;&#24182;&#20180;&#32454;&#22320;&#23558;&#30495;&#23454;&#29366;&#24577;&#24341;&#23548;&#21521;&#27169;&#25311;&#29366;&#24577;&#26469;&#23454;&#29616;&#30340;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#23454;&#20363;&#21270;&#65292;&#20135;&#29983;&#19968;&#20010;&#20855;&#26377;$O(1/\sqrt{N})$&#30340;&#26368;&#20248;&#35299;&#24046;&#36317;&#30340;&#31574;&#30053;&#12290;&#22312;&#31163;&#25955;&#26102;&#38388;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#22312;&#26356;&#31616;&#21333;&#30340;&#21516;&#27493;&#20551;&#35774;&#19979;&#25104;&#31435;&#65292;&#28085;&#30422;&#20102;&#19968;&#20123;&#19981;&#28385;&#36275;UGAP&#30340;&#38382;&#39064;&#23454;&#20363;&#12290;&#26356;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#22788;&#29702;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#22823;&#30340;&#38382;&#39064;&#31867;&#65292;&#32780;&#19981;&#38656;&#23545;&#38382;&#39064;&#23454;&#20363;&#20570;&#20219;&#20309;&#29305;&#23450;&#30340;&#32467;&#26500;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the infinite-horizon restless bandit problem with the average reward criterion, under both discrete-time and continuous-time settings. A fundamental question is how to design computationally efficient policies that achieve a diminishing optimality gap as the number of arms, $N$, grows large. Existing results on asymptotical optimality all rely on the uniform global attractor property (UGAP), a complex and challenging-to-verify assumption. In this paper, we propose a general, simulation-based framework that converts any single-armed policy into a policy for the original $N$-armed problem. This is accomplished by simulating the single-armed policy on each arm and carefully steering the real state towards the simulated state. Our framework can be instantiated to produce a policy with an $O(1/\sqrt{N})$ optimality gap. In the discrete-time setting, our result holds under a simpler synchronization assumption, which covers some problem instances that do not satisfy UGAP. More notabl
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#21442;&#25968;&#21270;&#34920;&#31034;&#21518;&#39564;&#20998;&#24067;&#30340;&#25674;&#38144;&#21464;&#20998;&#25512;&#29702;&#26041;&#27861;&#65292;&#20197;&#23454;&#29616;&#23454;&#26102;&#25512;&#29702;&#30340;&#30446;&#30340;&#65292;&#21487;&#24212;&#29992;&#20110;&#27969;&#20307;&#21147;&#23398;&#20013;&#30340;&#21442;&#25968;&#20272;&#35745;&#21644;&#27969;&#22330;&#37325;&#26500;&#31561;&#39046;&#22495;&#12290;</title><link>http://arxiv.org/abs/2305.20004</link><description>&lt;p&gt;
&#23398;&#20064;&#35299;&#20915;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;&#65306;&#19968;&#31181;&#25674;&#38144;&#21464;&#20998;&#25512;&#29702;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Learning to solve Bayesian inverse problems: An amortized variational inference approach. (arXiv:2305.20004v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.20004
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#21442;&#25968;&#21270;&#34920;&#31034;&#21518;&#39564;&#20998;&#24067;&#30340;&#25674;&#38144;&#21464;&#20998;&#25512;&#29702;&#26041;&#27861;&#65292;&#20197;&#23454;&#29616;&#23454;&#26102;&#25512;&#29702;&#30340;&#30446;&#30340;&#65292;&#21487;&#24212;&#29992;&#20110;&#27969;&#20307;&#21147;&#23398;&#20013;&#30340;&#21442;&#25968;&#20272;&#35745;&#21644;&#27969;&#22330;&#37325;&#26500;&#31561;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36870;&#38382;&#39064;&#65292;&#21363;&#20174;&#23454;&#39564;&#25968;&#25454;&#20013;&#20272;&#35745;&#29289;&#29702;&#27169;&#22411;&#30340;&#21442;&#25968;&#65292;&#22312;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#26222;&#36941;&#23384;&#22312;&#12290;&#36125;&#21494;&#26031;&#20844;&#24335;&#26159;&#40644;&#37329;&#26631;&#20934;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#32531;&#35299;&#30149;&#24577;&#24615;&#38382;&#39064;&#24182;&#37327;&#21270;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#35299;&#26512;&#21518;&#39564;&#19981;&#36890;&#24120;&#21487;&#29992;&#65292;&#20154;&#20204;&#37319;&#29992;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#37319;&#26679;&#25110;&#36817;&#20284;&#21464;&#20998;&#25512;&#29702;&#12290;&#20294;&#26159;&#65292;&#38656;&#35201;&#37325;&#26032;&#20174;&#22836;&#24320;&#22987;&#36827;&#34892;&#25512;&#29702;&#20197;&#36866;&#24212;&#27599;&#32452;&#26032;&#25968;&#25454;&#12290;&#36825;&#31181;&#32570;&#28857;&#38480;&#21046;&#20102;&#36125;&#21494;&#26031;&#20844;&#24335;&#22312;&#23454;&#26102;&#35774;&#32622;&#65292;&#20363;&#22914;&#24037;&#31243;&#31995;&#32479;&#30340;&#20581;&#24247;&#30417;&#27979;&#21644;&#21307;&#30103;&#35786;&#26029;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;&#26412;&#25991;&#30340;&#30446;&#26631;&#26159;&#24320;&#21457;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#20174;&#25968;&#25454;&#21040;&#21518;&#39564;&#30340;&#36125;&#21494;&#26031;&#36870;&#26144;&#23556;&#65292;&#21363;&#20174;&#25968;&#25454;&#21040;&#21518;&#39564;&#30340;&#26144;&#23556;&#65292;&#23454;&#29616;&#23454;&#26102;&#25512;&#29702;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22914;&#19979;&#12290;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#21442;&#25968;&#21270;&#34920;&#31034;&#21518;&#39564;&#20998;&#24067;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#36890;&#36807;&#25674;&#38144;&#21464;&#20998;&#25512;&#29702;&#23398;&#20064;&#32593;&#32476;&#21442;&#25968;&#65292;&#20854;&#20013;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#20197;&#39044;&#27979;&#20174;&#25968;&#25454;&#20013;&#39044;&#27979;&#21518;&#39564;&#20998;&#24067;&#65292;&#20174;&#32780;&#23454;&#29616;&#24555;&#36895;&#20934;&#30830;&#30340;&#25512;&#29702;&#12290;&#25105;&#20204;&#22312;&#27969;&#20307;&#21147;&#23398;&#20013;&#30340;&#19968;&#20123;&#36870;&#38382;&#39064;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#20854;&#20013;&#21253;&#25324;&#21442;&#25968;&#20272;&#35745;&#21644;&#27969;&#22330;&#37325;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inverse problems, i.e., estimating parameters of physical models from experimental data, are ubiquitous in science and engineering. The Bayesian formulation is the gold standard because it alleviates ill-posedness issues and quantifies epistemic uncertainty. Since analytical posteriors are not typically available, one resorts to Markov chain Monte Carlo sampling or approximate variational inference. However, inference needs to be rerun from scratch for each new set of data. This drawback limits the applicability of the Bayesian formulation to real-time settings, e.g., health monitoring of engineered systems, and medical diagnosis. The objective of this paper is to develop a methodology that enables real-time inference by learning the Bayesian inverse map, i.e., the map from data to posteriors. Our approach is as follows. We represent the posterior distribution using a parameterization based on deep neural networks. Next, we learn the network parameters by amortized variational inferenc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DoWG&#30340;&#26080;&#21442;&#25968;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#23427;&#26159;&#31532;&#19968;&#20010;&#26082;&#39640;&#25928;&#21448;&#36890;&#29992;&#30340;&#31639;&#27861;&#65292;&#33021;&#22815;&#33258;&#36866;&#24212;&#20110;&#24179;&#31283;&#21644;&#38750;&#24179;&#31283;&#38382;&#39064;&#65292;&#24182;&#19988;&#26080;&#38656;&#22238;&#28335;&#25628;&#32034;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2305.16284</link><description>&lt;p&gt;
DoWG&#23637;&#31034;&#65306;&#19968;&#31181;&#39640;&#25928;&#30340;&#36890;&#29992;&#26080;&#21442;&#25968;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
DoWG Unleashed: An Efficient Universal Parameter-Free Gradient Descent Method. (arXiv:2305.16284v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16284
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DoWG&#30340;&#26080;&#21442;&#25968;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#23427;&#26159;&#31532;&#19968;&#20010;&#26082;&#39640;&#25928;&#21448;&#36890;&#29992;&#30340;&#31639;&#27861;&#65292;&#33021;&#22815;&#33258;&#36866;&#24212;&#20110;&#24179;&#31283;&#21644;&#38750;&#24179;&#31283;&#38382;&#39064;&#65292;&#24182;&#19988;&#26080;&#38656;&#22238;&#28335;&#25628;&#32034;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26131;&#20110;&#23454;&#29616;&#30340;&#26080;&#21442;&#25968;&#26799;&#24230;&#20248;&#21270;&#22120;&#65306;DoWG&#65288;Weighted Gradients&#30340;&#36317;&#31163;&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#26159;&#39640;&#25928;&#30340;&#8212;&#8212;&#22312;&#19981;&#35843;&#25972;&#20219;&#20309;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#21305;&#37197;&#20248;&#21270;&#20984;&#20248;&#21270;&#20013;&#26368;&#20248;&#35843;&#30340;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#30452;&#21040;&#23545;&#25968;&#22240;&#23376;&#65292;&#24182;&#19988;&#26159;&#36890;&#29992;&#30340;&#8212;&#8212;&#33258;&#21160;&#36866;&#24212;&#24179;&#28369;&#21644;&#38750;&#24179;&#28369;&#38382;&#39064;&#12290;&#19982;AdaGrad&#65292;Adam&#25110;DoG&#31561;&#27969;&#34892;&#31639;&#27861;&#35745;&#31639;&#24179;&#26041;&#26799;&#24230;&#30340;&#36816;&#34892;&#24179;&#22343;&#20540;&#19981;&#21516;&#65292;DoWG&#20445;&#25345;&#36816;&#34892;&#24179;&#22343;&#20540;&#30340;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#36317;&#31163;&#30340;&#21152;&#26435;&#29256;&#26412;&#65292;&#36825;&#23545;&#20110;&#23454;&#29616;&#25152;&#38656;&#30340;&#24615;&#36136;&#33267;&#20851;&#37325;&#35201;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;DoWG&#26159;&#31532;&#19968;&#20010;&#19981;&#38656;&#35201;&#22238;&#28335;&#25628;&#32034;&#36807;&#31243;&#30340;&#26080;&#21442;&#25968;&#65292;&#39640;&#25928;&#21644;&#36890;&#29992;&#31639;&#27861;&#12290;&#23427;&#36824;&#26159;&#31532;&#19968;&#20010;&#36866;&#24212;&#20110;&#24179;&#31283;&#20248;&#21270;&#30340;&#26080;&#21442;&#25968;AdaGrad&#26679;&#24335;&#31639;&#27861;&#12290;&#20026;&#20102;&#34917;&#20805;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#25105;&#20204;&#36824;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;DoWG&#22312;&#31283;&#23450;&#30340;&#36793;&#32536;&#35757;&#32451;&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;&#23454;&#36341;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a new easy-to-implement parameter-free gradient-based optimizer: DoWG (Distance over Weighted Gradients). We prove that DoWG is efficient -- matching the convergence rate of optimally tuned gradient descent in convex optimization up to a logarithmic factor without tuning any parameters, and universal -- automatically adapting to both smooth and nonsmooth problems. While popular algorithms such as AdaGrad, Adam, or DoG compute a running average of the squared gradients, DoWG maintains a new distance-based weighted version of the running average, which is crucial to achieve the desired properties. To our best knowledge, DoWG is the first parameter-free, efficient, and universal algorithm that does not require backtracking search procedures. It is also the first parameter-free AdaGrad style algorithm that adapts to smooth optimization. To complement our theory, we also show empirically that DoWG trains at the edge of stability, and validate its effectiveness on practic
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Koopman&#26680;&#30340;&#22238;&#24402;&#26041;&#27861;&#65292;&#29992;&#20110;&#39044;&#27979;&#38750;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#30340;&#26102;&#38388;&#28436;&#21464;&#12290;&#35813;&#26041;&#27861;&#22312;&#26426;&#22120;&#20154;&#25805;&#20316;&#65292;&#35270;&#39057;&#39044;&#27979;&#21644;&#20132;&#36890;&#39044;&#27979;&#31561;&#21508;&#31181;&#24212;&#29992;&#20013;&#22343;&#26377;&#20248;&#24322;&#34920;&#29616;&#65292;&#24182;&#20855;&#26377;&#21487;&#35777;&#26126;&#30340;&#23398;&#20064;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2305.16215</link><description>&lt;p&gt;
Koopman&#26680;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Koopman Kernel Regression. (arXiv:2305.16215v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16215
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Koopman&#26680;&#30340;&#22238;&#24402;&#26041;&#27861;&#65292;&#29992;&#20110;&#39044;&#27979;&#38750;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#30340;&#26102;&#38388;&#28436;&#21464;&#12290;&#35813;&#26041;&#27861;&#22312;&#26426;&#22120;&#20154;&#25805;&#20316;&#65292;&#35270;&#39057;&#39044;&#27979;&#21644;&#20132;&#36890;&#39044;&#27979;&#31561;&#21508;&#31181;&#24212;&#29992;&#20013;&#22343;&#26377;&#20248;&#24322;&#34920;&#29616;&#65292;&#24182;&#20855;&#26377;&#21487;&#35777;&#26126;&#30340;&#23398;&#20064;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#20915;&#31574;&#21046;&#23450;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#22914;&#24378;&#21270;&#23398;&#20064;&#65292;&#20381;&#36182;&#20110;&#27169;&#25311;&#22120;&#25110;&#39044;&#27979;&#27169;&#22411;&#26469;&#39044;&#27979;&#24863;&#20852;&#36259;&#30340;&#37327;&#30340;&#26102;&#38388;&#28436;&#21464;&#65292;&#20363;&#22914;&#26234;&#33021;&#20307;&#30340;&#29366;&#24577;&#25110;&#31574;&#30053;&#30340;&#22870;&#21169;&#12290;&#36825;&#20123;&#22797;&#26434;&#29616;&#35937;&#30340;&#39044;&#27979;&#36890;&#24120;&#30001;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#21160;&#21147;&#31995;&#32479;&#25551;&#36848;&#65292;&#20351;&#24471;&#23427;&#20204;&#22312;&#22522;&#20110;&#20248;&#21270;&#30340;&#20915;&#31574;&#21046;&#23450;&#20013;&#30340;&#20351;&#29992;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;Koopman&#31639;&#23376;&#29702;&#35770;&#36890;&#36807;&#36890;&#36807;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#25551;&#36848;&#39044;&#27979;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#36825;&#20351;&#24471;&#31995;&#32479;&#20998;&#26512;&#21644;&#38271;&#26399;&#39044;&#27979;&#21464;&#24471;&#31616;&#21333;--&#21482;&#28041;&#21450;&#30697;&#38453;&#20056;&#27861;&#12290;&#28982;&#32780;&#65292;&#23558;&#20854;&#36716;&#21270;&#20026;&#32447;&#24615;&#31995;&#32479;&#36890;&#24120;&#26159;&#38750;&#24179;&#20961;&#30340;&#21644;&#26410;&#30693;&#30340;&#65292;&#38656;&#35201;&#22522;&#20110;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;&#34429;&#28982;&#23384;&#22312;&#21508;&#31181;&#26041;&#27861;&#65292;&#20294;&#23427;&#20204;&#36890;&#24120;&#32570;&#20047;&#20851;&#38190;&#30340;&#23398;&#20064;&#29702;&#35770;&#20445;&#35777;&#65292;&#22240;&#27492;&#25152;&#33719;&#24471;&#30340;&#27169;&#22411;&#22312;&#25968;&#25454;&#21644;&#32500;&#24230;&#22686;&#21152;&#26102;&#30340;&#34892;&#20026;&#36890;&#24120;&#19981;&#28165;&#26970;&#12290;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;Koopman&#26680;&#30340;&#22238;&#24402;&#26041;&#27861;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#19978;&#36848;&#25361;&#25112;&#65292;&#35813;&#26041;&#27861;&#30452;&#25509;&#20174;&#21382;&#21490;&#35266;&#23519;&#20013;&#23398;&#20064;&#21040;&#26410;&#26469;&#39044;&#27979;&#22312;Koopman&#31639;&#23376;&#31354;&#38388;&#20013;&#30340;&#26144;&#23556;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20139;&#26377;&#21487;&#35777;&#26126;&#30340;&#23398;&#20064;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#22312;&#24191;&#27867;&#30340;&#24212;&#29992;&#20013;&#19982;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#21305;&#37197;&#65288;&#25110;&#20248;&#20110;&#65289;&#65292;&#21253;&#25324;&#26426;&#22120;&#20154;&#25805;&#20316;&#65292;&#35270;&#39057;&#39044;&#27979;&#21644;&#20132;&#36890;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many machine learning approaches for decision making, such as reinforcement learning, rely on simulators or predictive models to forecast the time-evolution of quantities of interest, e.g., the state of an agent or the reward of a policy. Forecasts of such complex phenomena are commonly described by highly nonlinear dynamical systems, making their use in optimization-based decision-making challenging. Koopman operator theory offers a beneficial paradigm for addressing this problem by characterizing forecasts via linear dynamical systems. This makes system analysis and long-term predictions simple -- involving only matrix multiplications. However, the transformation to a linear system is generally non-trivial and unknown, requiring learning-based approaches. While there exists a variety of approaches, they usually lack crucial learning-theoretic guarantees, such that the behavior of the obtained models with increasing data and dimensionality is often unclear. We address the aforemention
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30740;&#31350;&#20102;&#35299;&#26512;&#24230;&#20989;&#25968;&#20026;&#38750;&#20984;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#35777;&#26126;&#20102;&#24403;&#26426;&#22120;&#23398;&#20064;&#22122;&#22768;&#30340;&#23610;&#24230;&#19982;&#30446;&#26631;&#20989;&#25968;&#30456;&#31561;&#26102;&#65292;&#22312;&#23616;&#37096;&#21306;&#22495;&#20869;&#21021;&#22987;&#21270;&#21518;&#65292;&#20197;&#27491;&#30340;&#27010;&#29575;&#33021;&#22815;&#25910;&#25947;&#21040;&#35813;&#21306;&#22495;&#20869;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#12290;</title><link>http://arxiv.org/abs/2304.09221</link><description>&lt;p&gt;
&#22522;&#20110;&#23616;&#37096;Lajasiewicz&#26465;&#20214;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#25910;&#25947;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Convergence of stochastic gradient descent under a local Lajasiewicz condition for deep neural networks. (arXiv:2304.09221v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09221
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30740;&#31350;&#20102;&#35299;&#26512;&#24230;&#20989;&#25968;&#20026;&#38750;&#20984;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#35777;&#26126;&#20102;&#24403;&#26426;&#22120;&#23398;&#20064;&#22122;&#22768;&#30340;&#23610;&#24230;&#19982;&#30446;&#26631;&#20989;&#25968;&#30456;&#31561;&#26102;&#65292;&#22312;&#23616;&#37096;&#21306;&#22495;&#20869;&#21021;&#22987;&#21270;&#21518;&#65292;&#20197;&#27491;&#30340;&#27010;&#29575;&#33021;&#22815;&#25910;&#25947;&#21040;&#35813;&#21306;&#22495;&#20869;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#35299;&#26512;&#24230;&#20989;&#25968;&#20026;&#38750;&#20984;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#23545;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#22312;&#26377;&#38480;&#23485;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#36890;&#36807;&#21152;&#20837;&#26368;&#23567;&#30340;&#39069;&#22806;&#20551;&#35774;&#24182;&#20445;&#35777;&#26426;&#22120;&#23398;&#20064;&#22122;&#22768;&#30340;&#23610;&#24230;&#19982;&#30446;&#26631;&#20989;&#25968;&#30456;&#31561;&#65292;&#35777;&#26126;&#20102;&#22312;&#23616;&#37096;&#21306;&#22495;&#20869;&#21021;&#22987;&#21270;&#26102;&#65292;&#20197;&#27491;&#30340;&#27010;&#29575;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#36845;&#20195;&#25910;&#25947;&#21040;&#35813;&#21306;&#22495;&#20869;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#12290;&#26412;&#25991;&#30340;&#20851;&#38190;&#26159;&#30830;&#20445;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#25972;&#20010;&#36712;&#36857;&#20197;&#27491;&#30340;&#27010;&#29575;&#20445;&#30041;&#22312;&#23616;&#37096;&#21306;&#22495;&#20869;&#12290;&#25991;&#31456;&#25552;&#20379;&#20102;&#36127;&#38754;&#20998;&#26512;&#65292;&#34920;&#26126;&#20351;&#29992;Robbins-Monro&#31867;&#22411;&#30340;&#27493;&#38271;&#20043;&#38388;&#20855;&#26377;&#26377;&#30028;&#22122;&#22768;&#30340;&#20551;&#35774;&#19981;&#36275;&#20197;&#20445;&#25345;&#35813;&#20851;&#38190;&#37096;&#20998;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We extend the global convergence result of Chatterjee \cite{chatterjee2022convergence} by considering the stochastic gradient descent (SGD) for non-convex objective functions. With minimal additional assumptions that can be realized by finitely wide neural networks, we prove that if we initialize inside a local region where the \L{}ajasiewicz condition holds, with a positive probability, the stochastic gradient iterates converge to a global minimum inside this region. A key component of our proof is to ensure that the whole trajectories of SGD stay inside the local region with a positive probability. For that, we assume the SGD noise scales with the objective function, which is called machine learning noise and achievable in many real examples. Furthermore, we provide a negative argument to show why using the boundedness of noise with Robbins-Monro type step sizes is not enough to keep the key component valid.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36845;&#20195;&#38543;&#26426;&#20989;&#25968;&#29983;&#25104;&#30340;&#36807;&#31243;&#30340;&#24378;&#31283;&#23450;&#24615;&#65292;&#35777;&#26126;&#20102;&#36866;&#29992;&#20110;&#36882;&#24402;&#26144;&#23556;&#30340;&#28201;&#21644;&#26465;&#20214;&#19979;&#30340;&#24378;&#31283;&#23450;&#24615;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#22810;&#20010;&#24212;&#29992;&#21450;&#30456;&#20851;&#39046;&#22495;&#30340;&#26032;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.04657</link><description>&lt;p&gt;
&#35770;&#38543;&#26426;&#36941;&#21382;&#30340;&#24378;&#31283;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the strong stability of ergodic iterations. (arXiv:2304.04657v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04657
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36845;&#20195;&#38543;&#26426;&#20989;&#25968;&#29983;&#25104;&#30340;&#36807;&#31243;&#30340;&#24378;&#31283;&#23450;&#24615;&#65292;&#35777;&#26126;&#20102;&#36866;&#29992;&#20110;&#36882;&#24402;&#26144;&#23556;&#30340;&#28201;&#21644;&#26465;&#20214;&#19979;&#30340;&#24378;&#31283;&#23450;&#24615;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#22810;&#20010;&#24212;&#29992;&#21450;&#30456;&#20851;&#39046;&#22495;&#30340;&#26032;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#30001;&#38543;&#26426;&#20989;&#25968;&#36845;&#20195;&#29983;&#25104;&#30340;&#36807;&#31243;&#65292;&#36825;&#20123;&#20989;&#25968;&#30001;&#19968;&#20010;&#24179;&#31283;&#19988;&#31526;&#21512;&#36941;&#21382;&#26465;&#20214;&#30340;&#24207;&#21015;&#39537;&#21160;&#12290;&#22914;&#26524;&#23384;&#22312;&#19968;&#20010;&#38543;&#26426;&#21021;&#22987;&#21270;&#20351;&#24471;&#35813;&#36807;&#31243;&#26159;&#31283;&#23450;&#21644;&#36941;&#21382;&#30340;&#65292;&#24182;&#19988;&#23545;&#20110;&#20219;&#20309;&#20854;&#20182;&#21021;&#22987;&#21270;&#65292;&#20004;&#20010;&#36807;&#31243;&#20043;&#38388;&#30340;&#24046;&#24322;&#20960;&#20046;&#32943;&#23450;&#25910;&#25947;&#20110;&#38646;&#65292;&#37027;&#20040;&#36825;&#26679;&#30340;&#36807;&#31243;&#34987;&#31216;&#20026;&#24378;&#31283;&#23450;&#12290;&#22312;&#23545;&#24212;&#36882;&#24402;&#26144;&#23556;&#19978;&#26045;&#21152;&#19968;&#20123;&#28201;&#21644;&#30340;&#26465;&#20214;&#65292;&#32780;&#19981;&#22312;&#39537;&#21160;&#24207;&#21015;&#19978;&#26045;&#21152;&#20219;&#20309;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36845;&#20195;&#30340;&#24378;&#31283;&#23450;&#24615;&#12290;&#22810;&#20010;&#24212;&#29992;&#34987;&#30740;&#31350;&#65292;&#22914;&#38543;&#26426;&#36924;&#36817;&#21644;&#25490;&#38431;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#20855;&#26377;&#20381;&#36182;&#22122;&#22768;&#30340; Langevin &#22411;&#36845;&#20195;&#21644;&#22810;&#22411;&#20998;&#25903;&#36807;&#31243;&#30340;&#26032;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We revisit processes generated by iterated random functions driven by a stationary and ergodic sequence. Such a process is called strongly stable if a random initialization exists, for which the process is stationary and ergodic, and for any other initialization, the difference of the two processes converges to zero almost surely. Under some mild conditions on the corresponding recursive map, without any condition on the driving sequence, we show the strong stability of iterations. Several applications are surveyed such as stochastic approximation and queuing. Furthermore, new results are deduced for Langevin-type iterations with dependent noise and for multitype branching processes.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32452;&#21512;&#24178;&#39044;&#19979;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#26045;&#21152;&#28508;&#22312;&#32467;&#26500;&#36328;&#36234;&#21333;&#20301;&#21644;&#32452;&#21512;&#65292;&#22312;&#38477;&#20302;&#23454;&#39564;&#25968;&#37327;&#21644;&#22788;&#29702;&#28151;&#26434;&#38382;&#39064;&#26041;&#38754;&#26377;&#30528;&#33391;&#22909;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2303.14226</link><description>&lt;p&gt;
&#32452;&#21512;&#24178;&#39044;&#30340;&#22240;&#26524;&#25512;&#26029;&#26694;&#26550;:&#21512;&#25104;&#32452;&#21512;
&lt;/p&gt;
&lt;p&gt;
Synthetic Combinations: A Causal Inference Framework for Combinatorial Interventions. (arXiv:2303.14226v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14226
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32452;&#21512;&#24178;&#39044;&#19979;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#26045;&#21152;&#28508;&#22312;&#32467;&#26500;&#36328;&#36234;&#21333;&#20301;&#21644;&#32452;&#21512;&#65292;&#22312;&#38477;&#20302;&#23454;&#39564;&#25968;&#37327;&#21644;&#22788;&#29702;&#28151;&#26434;&#38382;&#39064;&#26041;&#38754;&#26377;&#30528;&#33391;&#22909;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#19968;&#20010;&#21253;&#21547;N&#20010;&#24322;&#36136;&#21333;&#20301;&#21644;p&#20010;&#24178;&#39044;&#30340;&#35774;&#32622;&#12290; &#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#23398;&#20064;&#20219;&#24847;&#32452;&#21512;&#30340;&#21333;&#20301;&#29305;&#23450;&#28508;&#22312;&#32467;&#26524;&#65292;&#21363;N&#215;2 ^ p&#20010;&#22240;&#26524;&#21442;&#25968;&#12290;&#22312;&#35768;&#22810;&#24212;&#29992;&#31243;&#24207;&#20013;&#33258;&#28982;&#20986;&#29616;&#20102;&#36873;&#25321;&#24178;&#39044;&#32452;&#21512;&#30340;&#38382;&#39064;&#65292;&#20363;&#22914;&#22240;&#23376;&#35774;&#35745;&#35797;&#39564;&#65292;&#25512;&#33616;&#24341;&#25806;(&#20363;&#22914;&#65292;&#20026;&#29992;&#25143;&#26174;&#31034;&#26368;&#22823;&#31243;&#24230;&#30340;&#21442;&#19982;&#24230;&#30340;&#19968;&#32452;&#30005;&#24433;)&#65292;&#21307;&#23398;&#20013;&#30340;&#32452;&#21512;&#30103;&#27861;&#65292;&#36873;&#25321;ML&#27169;&#22411;&#30340;&#37325;&#35201;&#29305;&#24449;&#31561;&#31561;&#12290;&#24403;N&#21644;p&#22686;&#38271;&#26102;&#65292;&#36827;&#34892;N&#215;2 ^ p&#20010;&#23454;&#39564;&#26469;&#20272;&#35745;&#21508;&#31181;&#21442;&#25968;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#32780;&#19988;&#65292;&#35266;&#27979;&#25968;&#25454;&#24456;&#21487;&#33021;&#23384;&#22312;&#28151;&#26434;&#65292;&#21363;&#21333;&#20301;&#26159;&#21542;&#22312;&#32452;&#21512;&#19979;&#20986;&#29616;&#19982;&#20854;&#22312;&#35813;&#32452;&#21512;&#19979;&#30340;&#28508;&#22312;&#32467;&#26524;&#30456;&#20851;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;&#65292;&#23427;&#22312;&#21333;&#20301;&#21644;&#32452;&#21512;&#20043;&#38388;&#37117;&#26045;&#21152;&#20102;&#28508;&#22312;&#32467;&#26500;&#12290;&#25105;&#20204;&#20551;&#35774;&#21333;&#20301;&#20043;&#38388;&#23384;&#22312;&#28508;&#22312;&#30340;&#30456;&#20284;&#24615;(&#21363;&#31867;&#20284;&#21333;&#20301;&#30340;&#28508;&#22312;&#32467;&#26524;&#26159;&#30456;&#20284;&#30340;)&#65292;&#24182;&#19988;&#32452;&#21512;&#20043;&#38388;&#20063;&#23384;&#22312;&#28508;&#22312;&#30340;&#30456;&#20284;&#24615;(&#21363;&#31867;&#20284;&#32452;&#21512;&#30340;&#25928;&#26524;&#26159;&#30456;&#20284;&#30340;)&#12290;&#25105;&#20204;&#20351;&#29992;&#23618;&#27425;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#27169;&#22411;&#26469;&#24418;&#24335;&#21270;&#36825;&#19968;&#28857;&#65292;&#35813;&#27169;&#22411;&#32852;&#21512;&#32858;&#31867;&#21333;&#20803;&#21644;&#32452;&#21512;&#65292;&#24182;&#19988;&#36275;&#22815;&#28789;&#27963;&#65292;&#21487;&#20197;&#27169;&#25311;&#36830;&#32493;&#25110;&#31163;&#25955;&#32467;&#26524;&#12290;&#25105;&#20204;&#22312;&#27169;&#25311;&#21644;&#23454;&#38469;&#25968;&#25454;&#19978;&#28436;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#24182;&#34920;&#26126;&#23427;&#21487;&#20197;&#26174;&#30528;&#20943;&#23569;&#23398;&#20064;&#22240;&#26524;&#21442;&#25968;&#25152;&#38656;&#30340;&#23454;&#39564;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a setting with $N$ heterogeneous units and $p$ interventions. Our goal is to learn unit-specific potential outcomes for any combination of these $p$ interventions, i.e., $N \times 2^p$ causal parameters. Choosing combinations of interventions is a problem that naturally arises in many applications such as factorial design experiments, recommendation engines (e.g., showing a set of movies that maximizes engagement for users), combination therapies in medicine, selecting important features for ML models, etc. Running $N \times 2^p$ experiments to estimate the various parameters is infeasible as $N$ and $p$ grow. Further, with observational data there is likely confounding, i.e., whether or not a unit is seen under a combination is correlated with its potential outcome under that combination. To address these challenges, we propose a novel model that imposes latent structure across both units and combinations. We assume latent similarity across units (i.e., the potential outco
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#36801;&#31227;&#23398;&#20064;&#20013;&#20351;&#29992;&#21333;&#20010;&#39044;&#35757;&#32451;&#26816;&#26597;&#28857;&#24494;&#35843;&#30340;&#27169;&#22411;&#38598;&#21512;&#65292;&#21457;&#29616;&#36890;&#36807;&#26356;&#22909;&#22320;&#25506;&#32034;&#39044;&#35757;&#32451;&#22522;&#22495;&#21487;&#20197;&#25913;&#36827;&#38598;&#25104;&#27169;&#22411;&#65292;&#20294;&#31163;&#24320;&#22522;&#22495;&#20250;&#23548;&#33268;&#22833;&#21435;&#36801;&#31227;&#23398;&#20064;&#30340;&#22909;&#22788;&#65292;&#24182;&#19988;&#38477;&#20302;&#38598;&#25104;&#36136;&#37327;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#26377;&#25928;&#30340;&#20462;&#25913;&#26041;&#27861;StarSSE&#65292;&#21487;&#20197;&#20135;&#29983;&#26356;&#24378;&#30340;&#38598;&#25104;&#27169;&#22411;&#21644;&#22343;&#21248;&#30340;&#27169;&#22411;&#28151;&#21512;&#12290;</title><link>http://arxiv.org/abs/2303.03374</link><description>&lt;p&gt;
&#20572;&#30041;&#36824;&#26159;&#31163;&#24320;&#39044;&#35757;&#32451;&#22522;&#22495;&#65306;&#20851;&#20110;&#38598;&#25104;&#23398;&#20064;&#22312;&#36801;&#31227;&#23398;&#20064;&#20013;&#30340;&#27934;&#35265;
&lt;/p&gt;
&lt;p&gt;
To Stay or Not to Stay in the Pre-train Basin: Insights on Ensembling in Transfer Learning. (arXiv:2303.03374v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.03374
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#36801;&#31227;&#23398;&#20064;&#20013;&#20351;&#29992;&#21333;&#20010;&#39044;&#35757;&#32451;&#26816;&#26597;&#28857;&#24494;&#35843;&#30340;&#27169;&#22411;&#38598;&#21512;&#65292;&#21457;&#29616;&#36890;&#36807;&#26356;&#22909;&#22320;&#25506;&#32034;&#39044;&#35757;&#32451;&#22522;&#22495;&#21487;&#20197;&#25913;&#36827;&#38598;&#25104;&#27169;&#22411;&#65292;&#20294;&#31163;&#24320;&#22522;&#22495;&#20250;&#23548;&#33268;&#22833;&#21435;&#36801;&#31227;&#23398;&#20064;&#30340;&#22909;&#22788;&#65292;&#24182;&#19988;&#38477;&#20302;&#38598;&#25104;&#36136;&#37327;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#26377;&#25928;&#30340;&#20462;&#25913;&#26041;&#27861;StarSSE&#65292;&#21487;&#20197;&#20135;&#29983;&#26356;&#24378;&#30340;&#38598;&#25104;&#27169;&#22411;&#21644;&#22343;&#21248;&#30340;&#27169;&#22411;&#28151;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36801;&#31227;&#23398;&#20064;&#21644;&#38598;&#25104;&#23398;&#20064;&#26159;&#25913;&#21892;&#31070;&#32463;&#32593;&#32476;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#30340;&#20004;&#31181;&#28909;&#38376;&#25216;&#26415;&#12290;&#30001;&#20110;&#39044;&#35757;&#32451;&#25104;&#26412;&#39640;&#26114;&#65292;&#36890;&#24120;&#23454;&#36341;&#20013;&#20351;&#29992;&#20174;&#21333;&#20010;&#39044;&#35757;&#32451;&#26816;&#26597;&#28857;&#24494;&#35843;&#30340;&#27169;&#22411;&#38598;&#21512;&#12290;&#36825;&#20123;&#27169;&#22411;&#26368;&#32456;&#20250;&#36827;&#20837;&#25439;&#22833;&#20989;&#25968;&#26799;&#24230;&#19979;&#38477;&#31354;&#38388;&#30340;&#30456;&#21516;&#21306;&#22495;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#39044;&#35757;&#32451;&#22522;&#22495;&#65292;&#22240;&#27492;&#20855;&#26377;&#26377;&#38480;&#30340;&#22810;&#26679;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20174;&#21333;&#20010;&#39044;&#35757;&#32451;&#26816;&#26597;&#28857;&#35757;&#32451;&#30340;&#38598;&#25104;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#26356;&#22909;&#22320;&#25506;&#32034;&#39044;&#35757;&#32451;&#22522;&#22495;&#26469;&#25913;&#36827;&#65292;&#28982;&#32780;&#65292;&#31163;&#24320;&#22522;&#22495;&#20250;&#23548;&#33268;&#22833;&#21435;&#36801;&#31227;&#23398;&#20064;&#30340;&#22909;&#22788;&#24182;&#23548;&#33268;&#38598;&#25104;&#36136;&#37327;&#30340;&#19979;&#38477;&#12290;&#22522;&#20110;&#23545;&#29616;&#26377;&#25506;&#32034;&#26041;&#27861;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#26377;&#25928;&#30340;&#20462;&#25913;Transfer Learning Setup&#20013;&#30340;Snapshot Ensembles&#65288;SSE&#65289;&#26041;&#27861;&#65292;&#21517;&#20026;StarSSE&#65292;&#23427;&#33021;&#20135;&#29983;&#26356;&#24378;&#30340;&#38598;&#25104;&#27169;&#22411;&#21644;&#22343;&#21248;&#30340;&#27169;&#22411;&#28151;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transfer learning and ensembling are two popular techniques for improving the performance and robustness of neural networks. Due to the high cost of pre-training, ensembles of models fine-tuned from a single pre-trained checkpoint are often used in practice. Such models end up in the same basin of the loss landscape, which we call the pre-train basin, and thus have limited diversity. In this work, we show that ensembles trained from a single pre-trained checkpoint may be improved by better exploring the pre-train basin, however, leaving the basin results in losing the benefits of transfer learning and in degradation of the ensemble quality. Based on the analysis of existing exploration methods, we propose a more effective modification of the Snapshot Ensembles (SSE) for transfer learning setup, StarSSE, which results in stronger ensembles and uniform model soups.
&lt;/p&gt;</description></item><item><title>CAMEL&#26159;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#25299;&#25169;&#24230;&#37327;&#21644;&#29420;&#29305;&#30340;&#40654;&#26364;&#24230;&#37327;&#36827;&#34892;&#39640;&#32500;&#25968;&#25454;&#20998;&#31867;&#12289;&#38477;&#32500;&#21644;&#21487;&#35270;&#21270;&#12290;&#23427;&#36890;&#36807;&#24179;&#28369;&#20998;&#21306;&#32479;&#19968;&#31639;&#23376;&#23558;&#23616;&#37096;&#27491;&#20132;&#25237;&#24433;&#36716;&#25442;&#20026;&#20840;&#23616;&#23884;&#20837;&#65292;&#24182;&#25552;&#20379;&#20102;&#32858;&#31867;&#26174;&#33879;&#29305;&#24449;&#30340;&#29289;&#29702;&#35299;&#37322;&#12290;CAMEL&#22312;&#21508;&#31181;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#39640;&#32500;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2303.02561</link><description>&lt;p&gt;
CAMEL: &#26354;&#29575;&#22686;&#24378;&#30340;&#27969;&#24418;&#23884;&#20837;&#19982;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
CAMEL: Curvature-Augmented Manifold Embedding and Learning. (arXiv:2303.02561v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.02561
&lt;/p&gt;
&lt;p&gt;
CAMEL&#26159;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#25299;&#25169;&#24230;&#37327;&#21644;&#29420;&#29305;&#30340;&#40654;&#26364;&#24230;&#37327;&#36827;&#34892;&#39640;&#32500;&#25968;&#25454;&#20998;&#31867;&#12289;&#38477;&#32500;&#21644;&#21487;&#35270;&#21270;&#12290;&#23427;&#36890;&#36807;&#24179;&#28369;&#20998;&#21306;&#32479;&#19968;&#31639;&#23376;&#23558;&#23616;&#37096;&#27491;&#20132;&#25237;&#24433;&#36716;&#25442;&#20026;&#20840;&#23616;&#23884;&#20837;&#65292;&#24182;&#25552;&#20379;&#20102;&#32858;&#31867;&#26174;&#33879;&#29305;&#24449;&#30340;&#29289;&#29702;&#35299;&#37322;&#12290;CAMEL&#22312;&#21508;&#31181;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#39640;&#32500;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Curvature-Augmented Manifold Embedding and Learning (CAMEL)&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#20998;&#31867;&#12289;&#38477;&#32500;&#21644;&#21487;&#35270;&#21270;&#12290;CAMEL&#21033;&#29992;&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#23450;&#20041;&#30340;&#25299;&#25169;&#24230;&#37327;&#20197;&#21450;&#29992;&#20110;&#36317;&#31163;&#21644;&#26354;&#29575;&#30340;&#29420;&#29305;&#40654;&#26364;&#24230;&#37327;&#26469;&#22686;&#24378;&#20854;&#34920;&#36798;&#33021;&#21147;&#12290;&#35813;&#26041;&#27861;&#36824;&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#20351;&#29992;&#24179;&#28369;&#20998;&#21306;&#32479;&#19968;&#31639;&#23376;&#65292;&#23558;&#23616;&#37096;&#27491;&#20132;&#25237;&#24433;&#36716;&#25442;&#20026;&#20840;&#23616;&#23884;&#20837;&#65292;&#21516;&#26102;&#25429;&#25417;&#25972;&#20307;&#25299;&#25169;&#32467;&#26500;&#21644;&#23616;&#37096;&#30456;&#20284;&#24615;&#12290;&#23616;&#37096;&#27491;&#20132;&#21521;&#37327;&#25552;&#20379;&#20102;&#32858;&#31867;&#30340;&#26174;&#33879;&#29305;&#24449;&#30340;&#29289;&#29702;&#35299;&#37322;&#12290;&#22240;&#27492;&#65292;CAMEL&#19981;&#20165;&#25552;&#20379;&#20102;&#20302;&#32500;&#23884;&#20837;&#65292;&#36824;&#35299;&#37322;&#20102;&#27492;&#23884;&#20837;&#32972;&#21518;&#30340;&#29289;&#29702;&#24773;&#20917;&#12290;CAMEL&#24050;&#22312;&#21508;&#31181;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#24182;&#26174;&#31034;&#20986;&#20248;&#20110;&#20854;&#20182;&#26368;&#20808;&#36827;&#26041;&#27861;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#39640;&#32500;&#25968;&#25454;&#38598;&#12290;&#35813;&#26041;&#27861;&#30340;&#26174;&#33879;&#20248;&#21183;&#26159;&#12290;
&lt;/p&gt;
&lt;p&gt;
A novel method, named Curvature-Augmented Manifold Embedding and Learning (CAMEL), is proposed for high dimensional data classification, dimension reduction, and visualization. CAMEL utilizes a topology metric defined on the Riemannian manifold, and a unique Riemannian metric for both distance and curvature to enhance its expressibility. The method also employs a smooth partition of unity operator on the Riemannian manifold to convert localized orthogonal projection to global embedding, which captures both the overall topological structure and local similarity simultaneously. The local orthogonal vectors provide a physical interpretation of the significant characteristics of clusters. Therefore, CAMEL not only provides a low-dimensional embedding but also interprets the physics behind this embedding. CAMEL has been evaluated on various benchmark datasets and has shown to outperform state-of-the-art methods, especially for high-dimensional datasets. The method's distinct benefits are it
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#27604;&#36739;&#32806;&#21512;&#27969;&#21644;&#33258;&#22238;&#24402;&#27969;&#30340;&#19981;&#21516;&#26550;&#26500;&#21644;&#22810;&#26679;&#30446;&#26631;&#20998;&#24067;&#65292;&#21033;&#29992;&#21508;&#31181;&#27979;&#35797;&#32479;&#35745;&#37327;&#36827;&#34892;&#24615;&#33021;&#27604;&#36739;&#65292;&#20026;&#27491;&#35268;&#21270;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#25552;&#20379;&#20102;&#28145;&#20837;&#30340;&#30740;&#31350;&#21644;&#23454;&#35777;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2302.12024</link><description>&lt;p&gt;
&#27604;&#36739;&#32806;&#21512;&#27969;&#21644;&#33258;&#22238;&#24402;&#27969;&#30340;&#40065;&#26834;&#32479;&#35745;&#26816;&#39564;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Comparative Study of Coupling and Autoregressive Flows through Robust Statistical Tests. (arXiv:2302.12024v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.12024
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#27604;&#36739;&#32806;&#21512;&#27969;&#21644;&#33258;&#22238;&#24402;&#27969;&#30340;&#19981;&#21516;&#26550;&#26500;&#21644;&#22810;&#26679;&#30446;&#26631;&#20998;&#24067;&#65292;&#21033;&#29992;&#21508;&#31181;&#27979;&#35797;&#32479;&#35745;&#37327;&#36827;&#34892;&#24615;&#33021;&#27604;&#36739;&#65292;&#20026;&#27491;&#35268;&#21270;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#25552;&#20379;&#20102;&#28145;&#20837;&#30340;&#30740;&#31350;&#21644;&#23454;&#35777;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27491;&#35268;&#21270;&#27969;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#24378;&#22823;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#22240;&#20026;&#23427;&#20204;&#19981;&#20165;&#33021;&#22815;&#26377;&#25928;&#22320;&#23545;&#22797;&#26434;&#30446;&#26631;&#20998;&#24067;&#36827;&#34892;&#37319;&#26679;&#65292;&#32780;&#19988;&#36824;&#36890;&#36807;&#26500;&#36896;&#25552;&#20379;&#23494;&#24230;&#20272;&#35745;&#12290;&#25105;&#20204;&#22312;&#36825;&#37324;&#25552;&#20986;&#20102;&#23545;&#32806;&#21512;&#27969;&#21644;&#33258;&#22238;&#24402;&#27969;&#36827;&#34892;&#28145;&#20837;&#27604;&#36739;&#30340;&#30740;&#31350;&#65292;&#21253;&#25324;&#20223;&#23556;&#21644;&#26377;&#29702;&#20108;&#27425;&#26679;&#26465;&#31867;&#22411;&#30340;&#22235;&#31181;&#19981;&#21516;&#26550;&#26500;&#65306;&#23454;&#20540;&#38750;&#20307;&#31215;&#20445;&#25345;&#65288;RealNVP&#65289;&#12289;&#25513;&#34109;&#33258;&#22238;&#24402;&#27969;&#65288;MAF&#65289;&#12289;&#32806;&#21512;&#26377;&#29702;&#20108;&#27425;&#26679;&#26465;&#65288;C-RQS&#65289;&#21644;&#33258;&#22238;&#24402;&#26377;&#29702;&#20108;&#27425;&#26679;&#26465;&#65288;A-RQS&#65289;&#12290;&#25105;&#20204;&#20851;&#27880;&#19968;&#32452;&#20174;4&#32500;&#21040;400&#32500;&#36882;&#22686;&#30340;&#22810;&#27169;&#24577;&#30446;&#26631;&#20998;&#24067;&#12290;&#36890;&#36807;&#20351;&#29992;&#19981;&#21516;&#30340;&#20004;&#26679;&#26412;&#27979;&#35797;&#30340;&#27979;&#35797;&#32479;&#35745;&#37327;&#36827;&#34892;&#27604;&#36739;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#24050;&#30693;&#36317;&#31163;&#24230;&#37327;&#30340;&#27979;&#35797;&#32479;&#35745;&#37327;&#65306;&#20999;&#29255;Wasserstein&#36317;&#31163;&#12289;&#32500;&#24230;&#24179;&#22343;&#19968;&#32500;Kolmogorov-Smirnov&#26816;&#39564;&#21644;&#30456;&#20851;&#30697;&#38453;&#20043;&#24046;&#30340;Frobenius&#33539;&#25968;&#12290;&#21478;&#22806;&#65292;&#25105;&#20204;&#36824;&#21253;&#25324;&#20102;&#20197;&#19979;&#20272;&#35745;&#65306;
&lt;/p&gt;
&lt;p&gt;
Normalizing Flows have emerged as a powerful brand of generative models, as they not only allow for efficient sampling of complicated target distributions, but also deliver density estimation by construction. We propose here an in-depth comparison of coupling and autoregressive flows, both of the affine and rational quadratic spline type, considering four different architectures: Real-valued Non-Volume Preserving (RealNVP), Masked Autoregressive Flow (MAF), Coupling Rational Quadratic Spline (C-RQS), and Autoregressive Rational Quadratic Spline (A-RQS). We focus on a set of multimodal target distributions of increasing dimensionality ranging from 4 to 400. The performances are compared by means of different test-statistics for two-sample tests, built from known distance measures: the sliced Wasserstein distance, the dimension-averaged one-dimensional Kolmogorov-Smirnov test, and the Frobenius norm of the difference between correlation matrices. Furthermore, we include estimations of th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38543;&#26426;&#20984;&#20248;&#21270;&#20013;&#65292;&#36755;&#20986;&#27169;&#22411;&#21644;&#32463;&#39564;&#26679;&#26412;&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#19982;&#31639;&#27861;&#27867;&#21270;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#29616;&#26377;&#30340;&#20449;&#24687;&#29702;&#35770;&#27867;&#21270;&#30028;&#38480;&#19981;&#36275;&#20197;&#25429;&#25417;&#21040;&#20687;SGD&#21644;&#27491;&#21017;&#21270;ERM&#36825;&#26679;&#20855;&#26377;&#32500;&#24230;&#26080;&#20851;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#31639;&#27861;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2302.04925</link><description>&lt;p&gt;
&#20449;&#24687;&#29702;&#35770;&#19978;&#30028;&#23545;&#20449;&#24687;&#29702;&#35770;&#19979;&#30028;&#30340;&#36129;&#29486;
&lt;/p&gt;
&lt;p&gt;
Information Theoretic Lower Bounds for Information Theoretic Upper Bounds. (arXiv:2302.04925v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04925
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38543;&#26426;&#20984;&#20248;&#21270;&#20013;&#65292;&#36755;&#20986;&#27169;&#22411;&#21644;&#32463;&#39564;&#26679;&#26412;&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#19982;&#31639;&#27861;&#27867;&#21270;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#29616;&#26377;&#30340;&#20449;&#24687;&#29702;&#35770;&#27867;&#21270;&#30028;&#38480;&#19981;&#36275;&#20197;&#25429;&#25417;&#21040;&#20687;SGD&#21644;&#27491;&#21017;&#21270;ERM&#36825;&#26679;&#20855;&#26377;&#32500;&#24230;&#26080;&#20851;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#31639;&#27861;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#38543;&#26426;&#20984;&#20248;&#21270;&#30340;&#32972;&#26223;&#19979;&#30740;&#31350;&#20102;&#36755;&#20986;&#27169;&#22411;&#21644;&#32463;&#39564;&#26679;&#26412;&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#19982;&#31639;&#27861;&#30340;&#27867;&#21270;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#23613;&#31649;&#23545;&#20449;&#24687;&#29702;&#35770;&#27867;&#21270;&#30028;&#38480;&#30340;&#20852;&#36259;&#26085;&#30410;&#22686;&#21152;&#65292;&#20294;&#36825;&#20123;&#30028;&#38480;&#33021;&#21542;&#25581;&#31034;&#21508;&#31181;&#23398;&#20064;&#31639;&#27861;&#30340;&#21331;&#36234;&#24615;&#33021;&#36824;&#19981;&#30830;&#23450;&#12290;&#25105;&#20204;&#23545;&#38543;&#26426;&#20984;&#20248;&#21270;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23545;&#20110;&#30495;&#27491;&#30340;&#39118;&#38505;&#26368;&#23567;&#21270;&#65292;&#20381;&#36182;&#20110;&#32500;&#24230;&#30340;&#20114;&#20449;&#24687;&#26159;&#24517;&#35201;&#30340;&#12290;&#36825;&#34920;&#26126;&#29616;&#26377;&#30340;&#20449;&#24687;&#29702;&#35770;&#27867;&#21270;&#30028;&#38480;&#19981;&#33021;&#23436;&#20840;&#25429;&#25417;&#21040;&#20687;SGD&#21644;&#27491;&#21017;&#21270;ERM&#36825;&#26679;&#20855;&#26377;&#32500;&#24230;&#26080;&#20851;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#31639;&#27861;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We examine the relationship between the mutual information between the output model and the empirical sample and the generalization of the algorithm in the context of stochastic convex optimization. Despite increasing interest in information-theoretic generalization bounds, it is uncertain if these bounds can provide insight into the exceptional performance of various learning algorithms. Our study of stochastic convex optimization reveals that, for true risk minimization, dimension-dependent mutual information is necessary. This indicates that existing information-theoretic generalization bounds fall short in capturing the generalization capabilities of algorithms like SGD and regularized ERM, which have dimension-independent sample complexity.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20998;&#26512;&#20102;&#22312;&#24378;&#21270;&#23398;&#20064;&#21644;&#26368;&#20248;&#25511;&#21046;&#20013;&#35266;&#27979;&#26102;&#38388;&#20197;&#31163;&#25955;&#26102;&#38388;&#28857;&#22266;&#23450;&#21608;&#26399;&#21040;&#36798;&#30340;&#40664;&#35748;&#20551;&#35774;&#19982;&#23454;&#38469;&#24773;&#20917;&#19979;&#30340;&#36830;&#32493;&#26102;&#38388;&#31995;&#32479;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#24182;&#22312;LQR&#31995;&#32479;&#20013;&#25581;&#31034;&#20102;&#36817;&#20284;&#35823;&#24046;&#21644;&#32479;&#35745;&#35823;&#24046;&#20043;&#38388;&#30340;&#22522;&#26412;&#26435;&#34913;&#12290;&#22312;&#26377;&#38480;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#31649;&#29702;&#26102;&#38388;&#20998;&#36776;&#29575;&#21487;&#20197;&#26174;&#33879;&#25913;&#21892;&#31574;&#30053;&#35780;&#20272;&#30340;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2212.08949</link><description>&lt;p&gt;
&#22312;&#36830;&#32493;&#20540;&#20272;&#35745;&#20013;&#31649;&#29702;&#26102;&#38388;&#20998;&#36776;&#29575;: &#19968;&#39033;&#22522;&#26412;&#26435;&#34913;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Managing Temporal Resolution in Continuous Value Estimation: A Fundamental Trade-off. (arXiv:2212.08949v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.08949
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20998;&#26512;&#20102;&#22312;&#24378;&#21270;&#23398;&#20064;&#21644;&#26368;&#20248;&#25511;&#21046;&#20013;&#35266;&#27979;&#26102;&#38388;&#20197;&#31163;&#25955;&#26102;&#38388;&#28857;&#22266;&#23450;&#21608;&#26399;&#21040;&#36798;&#30340;&#40664;&#35748;&#20551;&#35774;&#19982;&#23454;&#38469;&#24773;&#20917;&#19979;&#30340;&#36830;&#32493;&#26102;&#38388;&#31995;&#32479;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#24182;&#22312;LQR&#31995;&#32479;&#20013;&#25581;&#31034;&#20102;&#36817;&#20284;&#35823;&#24046;&#21644;&#32479;&#35745;&#35823;&#24046;&#20043;&#38388;&#30340;&#22522;&#26412;&#26435;&#34913;&#12290;&#22312;&#26377;&#38480;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#31649;&#29702;&#26102;&#38388;&#20998;&#36776;&#29575;&#21487;&#20197;&#26174;&#33879;&#25913;&#21892;&#31574;&#30053;&#35780;&#20272;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#21644;&#26368;&#20248;&#25511;&#21046;&#20013;&#30340;&#40664;&#35748;&#20551;&#35774;&#26159;&#35266;&#27979;&#20197;&#22266;&#23450;&#30340;&#26102;&#38047;&#21608;&#26399;&#22312;&#31163;&#25955;&#30340;&#26102;&#38388;&#28857;&#21040;&#36798;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#24212;&#29992;&#28041;&#21450;&#36830;&#32493;&#26102;&#38388;&#31995;&#32479;&#65292;&#29702;&#35770;&#19978;&#21487;&#20197;&#23545;&#26102;&#38388;&#31163;&#25955;&#21270;&#36827;&#34892;&#31649;&#29702;&#12290;&#26102;&#38388;&#31163;&#25955;&#21270;&#23545;RL&#26041;&#27861;&#30340;&#24433;&#21709;&#23578;&#26410;&#22312;&#29616;&#26377;&#29702;&#35770;&#20013;&#23436;&#20840;&#34920;&#24449;&#65292;&#20294;&#23545;&#20854;&#24433;&#21709;&#36827;&#34892;&#26356;&#35814;&#32454;&#30340;&#20998;&#26512;&#21487;&#33021;&#25581;&#31034;&#25552;&#39640;&#25968;&#25454;&#25928;&#29575;&#30340;&#26426;&#20250;&#12290;&#25105;&#20204;&#36890;&#36807;&#20998;&#26512;LQR&#31995;&#32479;&#30340;Monte-Carlo&#31574;&#30053;&#35780;&#20272;&#26469;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#24182;&#21457;&#29616;&#20102;&#20272;&#20540;&#36807;&#31243;&#20013;&#36817;&#20284;&#35823;&#24046;&#21644;&#32479;&#35745;&#35823;&#24046;&#20043;&#38388;&#30340;&#22522;&#26412;&#26435;&#34913;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#36825;&#20004;&#31181;&#38169;&#35823;&#23545;&#26102;&#38388;&#31163;&#25955;&#21270;&#30340;&#34920;&#29616;&#19981;&#21516;&#65292;&#36825;&#23548;&#33268;&#20102;&#23545;&#20110;&#32473;&#23450;&#25968;&#25454;&#39044;&#31639;&#30340;&#26102;&#38388;&#20998;&#36776;&#29575;&#30340;&#26368;&#20339;&#36873;&#25321;&#12290;&#36825;&#20123;&#21457;&#29616;&#34920;&#26126;&#65292;&#22312;&#20855;&#26377;&#26377;&#38480;&#25968;&#25454;&#30340;LQR&#31995;&#32479;&#20013;&#65292;&#31649;&#29702;&#26102;&#38388;&#20998;&#36776;&#29575;&#21487;&#20197;&#25913;&#21892;&#31574;&#30053;&#35780;&#20272;&#30340;&#25928;&#29575;&#12290;&#20174;&#23454;&#35777;&#35282;&#24230;&#26469;&#30475;&#65292;&#25105;&#20204;&#22312;&#25968;&#20540;&#27169;&#25311;&#20013;&#23637;&#31034;&#20102;&#36825;&#31181;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
A default assumption in reinforcement learning (RL) and optimal control is that observations arrive at discrete time points on a fixed clock cycle. Yet, many applications involve continuous-time systems where the time discretization, in principle, can be managed. The impact of time discretization on RL methods has not been fully characterized in existing theory, but a more detailed analysis of its effect could reveal opportunities for improving data-efficiency. We address this gap by analyzing Monte-Carlo policy evaluation for LQR systems and uncover a fundamental trade-off between approximation and statistical error in value estimation. Importantly, these two errors behave differently to time discretization, leading to an optimal choice of temporal resolution for a given data budget. These findings show that managing the temporal resolution can provably improve policy evaluation efficiency in LQR systems with finite data. Empirically, we demonstrate the trade-off in numerical simulati
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#39044;&#27979;&#22238;&#24402;&#20013;LASSO&#30340;&#24212;&#29992;&#65292;&#25552;&#20986;&#20102;LASSO&#30340;&#25910;&#25947;&#36895;&#24230;&#19982;&#27178;&#26029;&#38754;&#24773;&#20917;&#19981;&#21516;&#30340;&#26032;&#30340;&#27010;&#29575;&#30028;&#38480;&#65292;&#24182;&#23637;&#31034;&#20102;LASSO&#22312;&#39044;&#27979;&#22833;&#19994;&#29575;&#26041;&#38754;&#30340;&#24378;&#22823;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2212.07052</link><description>&lt;p&gt;
&#39640;&#32500;&#39044;&#27979;&#22238;&#24402;&#20013;LASSO&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On LASSO for High Dimensional Predictive Regression. (arXiv:2212.07052v2 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.07052
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#39044;&#27979;&#22238;&#24402;&#20013;LASSO&#30340;&#24212;&#29992;&#65292;&#25552;&#20986;&#20102;LASSO&#30340;&#25910;&#25947;&#36895;&#24230;&#19982;&#27178;&#26029;&#38754;&#24773;&#20917;&#19981;&#21516;&#30340;&#26032;&#30340;&#27010;&#29575;&#30028;&#38480;&#65292;&#24182;&#23637;&#31034;&#20102;LASSO&#22312;&#39044;&#27979;&#22833;&#19994;&#29575;&#26041;&#38754;&#30340;&#24378;&#22823;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;LASSO&#22312;&#39640;&#32500;&#32447;&#24615;&#39044;&#27979;&#22238;&#24402;&#20013;&#30340;&#24212;&#29992;&#65292;&#29305;&#21035;&#26159;&#22312;&#28508;&#22312;&#39044;&#27979;&#21464;&#37327;&#25968;&#37327;&#36229;&#36807;&#26679;&#26412;&#37327;&#19988;&#23384;&#22312;&#22823;&#37327;&#21333;&#20301;&#26681;&#22238;&#24402;&#22120;&#30340;&#24773;&#20917;&#19979;&#12290;LASSO&#30340;&#19968;&#33268;&#24615;&#21462;&#20915;&#20110;&#20004;&#20010;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#65306;&#22238;&#24402;&#22120;&#21644;&#35823;&#24046;&#39033;&#30340;&#20132;&#21449;&#20056;&#31215;&#30340;&#20559;&#24046;&#30028;&#38480;&#20197;&#21450;Gram&#30697;&#38453;&#30340;&#21463;&#38480;&#29305;&#24449;&#20540;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#36825;&#20123;&#32452;&#25104;&#37096;&#20998;&#30340;&#26032;&#30340;&#27010;&#29575;&#30028;&#38480;&#65292;&#34920;&#26126;LASSO&#30340;&#25910;&#25947;&#36895;&#24230;&#19982;&#20856;&#22411;&#30340;&#27178;&#26029;&#38754;&#24773;&#20917;&#19981;&#21516;&#12290;&#24403;&#24212;&#29992;&#20110;&#28151;&#21512;&#30340;&#24179;&#31283;&#12289;&#38750;&#24179;&#31283;&#21644;&#21327;&#25972;&#39044;&#27979;&#22120;&#26102;&#65292;&#22914;&#26524;&#39044;&#27979;&#22120;&#36827;&#34892;&#20102;&#26631;&#24230;&#26631;&#20934;&#21270;&#65292;LASSO&#20173;&#28982;&#20445;&#25345;&#20854;&#28176;&#36817;&#20445;&#35777;&#12290;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#21644;&#23439;&#35266;&#32463;&#27982;&#39046;&#22495;&#30340;&#19987;&#19994;&#30693;&#35782;&#65292;LASSO&#22312;&#39044;&#27979;&#22833;&#19994;&#29575;&#26041;&#38754;&#34920;&#29616;&#20986;&#24378;&#22823;&#30340;&#24615;&#33021;&#65292;&#36825;&#19968;&#28857;&#22312;&#20854;&#24212;&#29992;&#20110;FRED-MD&#25968;&#25454;&#24211;&#20013;&#24471;&#21040;&#20102;&#35777;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper examines LASSO, a widely-used $L_{1}$-penalized regression method, in high dimensional linear predictive regressions, particularly when the number of potential predictors exceeds the sample size and numerous unit root regressors are present. The consistency of LASSO is contingent upon two key components: the deviation bound of the cross product of the regressors and the error term, and the restricted eigenvalue of the Gram matrix. We present new probabilistic bounds for these components, suggesting that LASSO's rates of convergence are different from those typically observed in cross-sectional cases. When applied to a mixture of stationary, nonstationary, and cointegrated predictors, LASSO maintains its asymptotic guarantee if predictors are scale-standardized. Leveraging machine learning and macroeconomic domain expertise, LASSO demonstrates strong performance in forecasting the unemployment rate, as evidenced by its application to the FRED-MD database.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#31163;&#32447;&#27169;&#22411;&#20248;&#21270;&#20013;&#30340;&#39564;&#35777;&#25351;&#26631;&#12290;&#22312;&#31163;&#32447;&#27169;&#22411;&#20248;&#21270;&#20013;&#65292;&#25105;&#20204;&#24076;&#26395;&#22312;&#27809;&#26377;&#35775;&#38382;&#30495;&#20540;&#39044;&#35328;&#26426;&#30340;&#24773;&#20917;&#19979;&#35774;&#35745;&#20505;&#36873;&#26041;&#26696;&#12290;&#29616;&#26377;&#30340;&#39564;&#35777;&#25351;&#26631;&#26159;&#23545;&#39044;&#35328;&#26426;&#30340;&#36817;&#20284;&#65292;&#25105;&#20204;&#24076;&#26395;&#25214;&#21040;&#19982;&#30495;&#20540;&#39044;&#35328;&#26426;&#26368;&#30456;&#20851;&#30340;&#39564;&#35777;&#25351;&#26631;&#12290;</title><link>http://arxiv.org/abs/2211.10747</link><description>&lt;p&gt;
&#25506;&#32034;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#31163;&#32447;&#27169;&#22411;&#20248;&#21270;&#30340;&#39564;&#35777;&#25351;&#26631;
&lt;/p&gt;
&lt;p&gt;
Exploring validation metrics for offline model-based optimisation with diffusion models. (arXiv:2211.10747v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.10747
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#31163;&#32447;&#27169;&#22411;&#20248;&#21270;&#20013;&#30340;&#39564;&#35777;&#25351;&#26631;&#12290;&#22312;&#31163;&#32447;&#27169;&#22411;&#20248;&#21270;&#20013;&#65292;&#25105;&#20204;&#24076;&#26395;&#22312;&#27809;&#26377;&#35775;&#38382;&#30495;&#20540;&#39044;&#35328;&#26426;&#30340;&#24773;&#20917;&#19979;&#35774;&#35745;&#20505;&#36873;&#26041;&#26696;&#12290;&#29616;&#26377;&#30340;&#39564;&#35777;&#25351;&#26631;&#26159;&#23545;&#39044;&#35328;&#26426;&#30340;&#36817;&#20284;&#65292;&#25105;&#20204;&#24076;&#26395;&#25214;&#21040;&#19982;&#30495;&#20540;&#39044;&#35328;&#26426;&#26368;&#30456;&#20851;&#30340;&#39564;&#35777;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#20110;&#27169;&#22411;&#30340;&#20248;&#21270;&#20013;&#65292;&#25105;&#20204;&#24076;&#26395;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#35774;&#35745;&#20505;&#36873;&#26041;&#26696;&#65292;&#20197;&#26368;&#22823;&#21270;&#23545;&#20110;&#19968;&#20010;&#31216;&#20026;&#65288;&#22320;&#38754;&#30495;&#20540;&#65289;&#39044;&#35328;&#26426;&#30340;&#40657;&#30418;&#20989;&#25968;&#30340;&#26576;&#31181;&#22870;&#21169;&#24230;&#37327;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#28041;&#21450;&#21040;&#25191;&#34892;&#30495;&#23454;&#19990;&#30028;&#36807;&#31243;&#65292;&#35745;&#31639;&#39044;&#35328;&#26426;&#26159;&#26114;&#36149;&#30340;&#12290;&#22312;&#31163;&#32447;&#27169;&#22411;&#20248;&#21270;&#20013;&#65292;&#25105;&#20204;&#24076;&#26395;&#22312;&#35757;&#32451;&#25110;&#39564;&#35777;&#36807;&#31243;&#20013;&#19981;&#20551;&#35774;&#23545;&#39044;&#35328;&#26426;&#26377;&#35775;&#38382;&#26435;&#38480;&#65292;&#36825;&#20351;&#24471;&#35780;&#20272;&#21464;&#24471;&#22797;&#26434;&#12290;&#34429;&#28982;&#21487;&#20197;&#35757;&#32451;&#19968;&#20010;&#39044;&#35328;&#26426;&#30340;&#36817;&#20284;&#27169;&#22411;&#24182;&#22312;&#27169;&#22411;&#39564;&#35777;&#36807;&#31243;&#20013;&#20351;&#29992;&#23427;&#20195;&#26367;&#30495;&#20540;&#39044;&#35328;&#26426;&#26469;&#27979;&#37327;&#29983;&#25104;&#20505;&#36873;&#26041;&#26696;&#30340;&#24179;&#22343;&#22870;&#21169;&#65292;&#20294;&#36825;&#31181;&#35780;&#20272;&#26159;&#36817;&#20284;&#30340;&#19988;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#24615;&#26679;&#26412;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#36817;&#20284;&#19979;&#29983;&#25104;&#20505;&#36873;&#26041;&#26696;&#30340;&#24179;&#22343;&#22870;&#21169;&#20316;&#20026;&#19968;&#31181;&#8220;&#39564;&#35777;&#25351;&#26631;&#8221;&#65292;&#32780;&#25105;&#20204;&#26356;&#20851;&#24515;&#30340;&#26159;&#19968;&#20010;&#26356;&#22522;&#26412;&#30340;&#38382;&#39064;&#65292;&#21363;&#25214;&#21040;&#19982;&#30495;&#20540;&#39044;&#35328;&#26426;&#26368;&#30456;&#20851;&#30340;&#39564;&#35777;&#25351;&#26631;&#12290;&#36825;&#28041;&#21450;&#21040;&#25552;&#20986;&#39564;&#35777;&#25351;&#26631;&#24182;&#23545;&#35768;&#22810;&#25968;&#25454;&#38598;&#36827;&#34892;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In model-based optimisation (MBO) we are interested in using machine learning to design candidates that maximise some measure of reward with respect to a black box function called the (ground truth) oracle, which is expensive to compute since it involves executing a real world process. In offline MBO we wish to do so without assuming access to such an oracle during training or validation, with makes evaluation non-straightforward. While an approximation to the ground oracle can be trained and used in place of it during model validation to measure the mean reward over generated candidates, the evaluation is approximate and vulnerable to adversarial examples. Measuring the mean reward of generated candidates over this approximation is one such `validation metric', whereas we are interested in a more fundamental question which is finding which validation metrics correlate the most with the ground truth. This involves proposing validation metrics and quantifying them over many datasets for
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#25968;&#20540;&#31283;&#23450;&#24615;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#36890;&#36807;&#24863;&#20852;&#36259;&#28857;&#30340;&#36873;&#25321;&#21644;&#35745;&#31639;&#65292;&#25552;&#20379;&#20102;&#31283;&#23450;&#21487;&#38752;&#30340;&#31232;&#30095;&#36924;&#36817;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2210.07893</link><description>&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;Cover Trees&#30340;&#26368;&#23567;&#38388;&#38548;&#23454;&#29616;&#25968;&#20540;&#31283;&#23450;&#30340;&#31232;&#30095;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Numerically Stable Sparse Gaussian Processes via Minimum Separation using Cover Trees. (arXiv:2210.07893v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.07893
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#25968;&#20540;&#31283;&#23450;&#24615;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#36890;&#36807;&#24863;&#20852;&#36259;&#28857;&#30340;&#36873;&#25321;&#21644;&#35745;&#31639;&#65292;&#25552;&#20379;&#20102;&#31283;&#23450;&#21487;&#38752;&#30340;&#31232;&#30095;&#36924;&#36817;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#24120;&#29992;&#20110;&#36739;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#21644;&#20915;&#31574;&#31995;&#32479;&#20013;&#65292;&#20363;&#22914;&#22320;&#29702;&#31354;&#38388;&#24314;&#27169;&#12289;&#36125;&#21494;&#26031;&#20248;&#21270;&#25110;&#28508;&#22312;&#39640;&#26031;&#27169;&#22411;&#20013;&#12290;&#22312;&#19968;&#20010;&#31995;&#32479;&#20013;&#65292;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#38656;&#35201;&#20197;&#31283;&#23450;&#21487;&#38752;&#30340;&#26041;&#24335;&#36816;&#34892;&#65292;&#20197;&#30830;&#20445;&#19982;&#31995;&#32479;&#30340;&#20854;&#20182;&#37096;&#20998;&#27491;&#30830;&#20132;&#20114;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#24863;&#20852;&#36259;&#28857;&#30340;&#21487;&#25193;&#23637;&#31232;&#30095;&#36924;&#36817;&#30340;&#25968;&#20540;&#31283;&#23450;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#39318;&#20808;&#22238;&#39038;&#20102;&#25968;&#20540;&#31283;&#23450;&#24615;&#65292;&#24182;&#38416;&#36848;&#20102;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#21487;&#33021;&#19981;&#31283;&#23450;&#30340;&#20856;&#22411;&#24773;&#20917;&#12290;&#22312;&#25554;&#20540;&#25991;&#29486;&#20013;&#21407;&#22987;&#24320;&#21457;&#30340;&#31283;&#23450;&#24615;&#29702;&#35770;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;&#23545;&#24863;&#20852;&#36259;&#28857;&#36827;&#34892;&#35745;&#31639;&#30340;&#25968;&#20540;&#31283;&#23450;&#24615;&#30340;&#20805;&#20998;&#26465;&#20214;&#21644;&#26576;&#20123;&#24773;&#20917;&#19979;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;&#23545;&#20110;&#22320;&#29702;&#31354;&#38388;&#24314;&#27169;&#31561;&#20302;&#32500;&#20219;&#21153;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#35745;&#31639;&#28385;&#36275;&#36825;&#20123;&#26465;&#20214;&#30340;&#24863;&#20852;&#36259;&#28857;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian processes are frequently deployed as part of larger machine learning and decision-making systems, for instance in geospatial modeling, Bayesian optimization, or in latent Gaussian models. Within a system, the Gaussian process model needs to perform in a stable and reliable manner to ensure it interacts correctly with other parts of the system. In this work, we study the numerical stability of scalable sparse approximations based on inducing points. To do so, we first review numerical stability, and illustrate typical situations in which Gaussian process models can be unstable. Building on stability theory originally developed in the interpolation literature, we derive sufficient and in certain cases necessary conditions on the inducing points for the computations performed to be numerically stable. For low-dimensional tasks such as geospatial modeling, we propose an automated method for computing inducing points satisfying these conditions. This is done via a modification of t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#23545;&#31216;&#30340;&#22806;&#37096;&#32858;&#31867;&#26377;&#25928;&#24230;&#37327;&#26041;&#27861;&#65292;&#26088;&#22312;&#21306;&#20998;&#19981;&#21516;&#20219;&#21153;&#31867;&#22411;&#19978;&#34920;&#29616;&#33391;&#22909;&#21644;&#31995;&#32479;&#24615;&#34920;&#29616;&#19981;&#20339;&#30340;&#32858;&#31867;&#31639;&#27861;&#12290;&#19982;&#20256;&#32479;&#30340;&#20869;&#37096;&#24230;&#37327;&#19981;&#21516;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#21442;&#32771;&#30495;&#23454;&#20998;&#32452;&#36827;&#34892;&#35780;&#20272;&#65292;&#24182;&#24357;&#34917;&#20102;&#29616;&#26377;&#26041;&#27861;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2209.02935</link><description>&lt;p&gt;
&#35268;&#33539;&#21270;&#32858;&#31867;&#20934;&#30830;&#24230;&#65306;&#19968;&#31181;&#38750;&#23545;&#31216;&#30340;&#22806;&#37096;&#32858;&#31867;&#26377;&#25928;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
Normalised clustering accuracy: An asymmetric external cluster validity measure. (arXiv:2209.02935v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.02935
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#23545;&#31216;&#30340;&#22806;&#37096;&#32858;&#31867;&#26377;&#25928;&#24230;&#37327;&#26041;&#27861;&#65292;&#26088;&#22312;&#21306;&#20998;&#19981;&#21516;&#20219;&#21153;&#31867;&#22411;&#19978;&#34920;&#29616;&#33391;&#22909;&#21644;&#31995;&#32479;&#24615;&#34920;&#29616;&#19981;&#20339;&#30340;&#32858;&#31867;&#31639;&#27861;&#12290;&#19982;&#20256;&#32479;&#30340;&#20869;&#37096;&#24230;&#37327;&#19981;&#21516;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#21442;&#32771;&#30495;&#23454;&#20998;&#32452;&#36827;&#34892;&#35780;&#20272;&#65292;&#24182;&#24357;&#34917;&#20102;&#29616;&#26377;&#26041;&#27861;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27809;&#26377;&#19968;&#20010;&#26368;&#22909;&#30340;&#32858;&#31867;&#31639;&#27861;&#65292;&#25105;&#20204;&#20173;&#28982;&#24076;&#26395;&#33021;&#22815;&#21306;&#20998;&#20986;&#22312;&#26576;&#20123;&#20219;&#21153;&#31867;&#22411;&#19978;&#34920;&#29616;&#33391;&#22909;&#21644;&#31995;&#32479;&#24615;&#34920;&#29616;&#19981;&#20339;&#30340;&#26041;&#27861;&#12290;&#20256;&#32479;&#19978;&#65292;&#32858;&#31867;&#31639;&#27861;&#20351;&#29992;&#20869;&#37096;&#25110;&#22806;&#37096;&#26377;&#25928;&#24230;&#37327;&#36827;&#34892;&#35780;&#20272;&#12290;&#20869;&#37096;&#24230;&#37327;&#37327;&#21270;&#25152;&#24471;&#20998;&#21306;&#30340;&#19981;&#21516;&#26041;&#38754;&#65292;&#20363;&#22914;&#65292;&#31751;&#32039;&#23494;&#24230;&#30340;&#24179;&#22343;&#31243;&#24230;&#25110;&#28857;&#30340;&#21487;&#20998;&#31163;&#24615;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#26377;&#25928;&#24615;&#26159;&#26377;&#38382;&#39064;&#30340;&#65292;&#22240;&#20026;&#23427;&#20204;&#20419;&#20351;&#30340;&#32858;&#31867;&#26377;&#26102;&#21487;&#33021;&#26159;&#26080;&#24847;&#20041;&#30340;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#22806;&#37096;&#24230;&#37327;&#23558;&#31639;&#27861;&#30340;&#36755;&#20986;&#19982;&#30001;&#19987;&#23478;&#25552;&#20379;&#30340;&#21442;&#32771;&#30495;&#23454;&#20998;&#32452;&#36827;&#34892;&#27604;&#36739;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35748;&#20026;&#24120;&#29992;&#30340;&#32463;&#20856;&#20998;&#21306;&#30456;&#20284;&#24615;&#35780;&#20998;&#65292;&#20363;&#22914;&#35268;&#33539;&#21270;&#20114;&#20449;&#24687;&#12289;Fowlkes-Mallows&#25110;&#35843;&#25972;&#20848;&#24503;&#25351;&#25968;&#65292;&#32570;&#23569;&#19968;&#20123;&#21487;&#21462;&#30340;&#23646;&#24615;&#65292;&#20363;&#22914;&#65292;&#23427;&#20204;&#19981;&#33021;&#27491;&#30830;&#35782;&#21035;&#26368;&#22351;&#24773;&#20917;&#65292;&#20063;&#19981;&#26131;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is no, nor will there ever be, single best clustering algorithm, but we would still like to be able to distinguish between methods which work well on certain task types and those that systematically underperform. Clustering algorithms are traditionally evaluated using either internal or external validity measures. Internal measures quantify different aspects of the obtained partitions, e.g., the average degree of cluster compactness or point separability. Yet, their validity is questionable, because the clusterings they promote can sometimes be meaningless. External measures, on the other hand, compare the algorithms' outputs to the reference, ground truth groupings that are provided by experts. In this paper, we argue that the commonly-used classical partition similarity scores, such as the normalised mutual information, Fowlkes-Mallows, or adjusted Rand index, miss some desirable properties, e.g., they do not identify worst-case scenarios correctly or are not easily interpretab
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#20351;&#29992;&#27491;&#21017;&#21270;&#31232;&#30095;&#33258;&#32534;&#30721;&#22120;&#39044;&#27979;&#33391;&#22909;&#30340;&#21453;&#24212;&#22352;&#26631;&#20197;&#21450;MD&#36712;&#36857;&#30340;&#28436;&#21270;&#24773;&#20917;&#65292;&#24182;&#23637;&#31034;&#20102;&#27491;&#21017;&#21270;&#32422;&#26463;&#23545;&#20110;&#36873;&#25321;&#37325;&#35201;&#21453;&#24212;&#22352;&#26631;&#30340;&#24110;&#21161;&#12290;</title><link>http://arxiv.org/abs/2208.10962</link><description>&lt;p&gt;
&#20351;&#29992;&#27491;&#21017;&#21270;&#31232;&#30095;&#33258;&#32534;&#30721;&#22120;&#39044;&#27979;&#33391;&#22909;&#21453;&#24212;&#22352;&#26631;&#21644;MD&#36712;&#36857;&#30340;&#26410;&#26469;&#28436;&#21270;&#65306;&#19968;&#31181;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Prediction of good reaction coordinates and future evolution of MD trajectories using Regularized Sparse Autoencoders: A novel deep learning approach. (arXiv:2208.10962v2 [physics.chem-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.10962
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#20351;&#29992;&#27491;&#21017;&#21270;&#31232;&#30095;&#33258;&#32534;&#30721;&#22120;&#39044;&#27979;&#33391;&#22909;&#30340;&#21453;&#24212;&#22352;&#26631;&#20197;&#21450;MD&#36712;&#36857;&#30340;&#28436;&#21270;&#24773;&#20917;&#65292;&#24182;&#23637;&#31034;&#20102;&#27491;&#21017;&#21270;&#32422;&#26463;&#23545;&#20110;&#36873;&#25321;&#37325;&#35201;&#21453;&#24212;&#22352;&#26631;&#30340;&#24110;&#21161;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#23450;&#21453;&#24212;&#22352;&#26631;(RCs)&#26159;&#19968;&#20010;&#27963;&#36291;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#22240;&#20026;RCs&#22312;&#30830;&#23450;&#21270;&#23398;&#21453;&#24212;&#30340;&#36827;&#23637;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#36873;&#25321;&#21453;&#24212;&#22352;&#26631;&#36890;&#24120;&#22522;&#20110;&#21551;&#21457;&#24335;&#30693;&#35782;&#12290;&#28982;&#32780;&#65292;&#36873;&#25321;&#30340;&#26631;&#20934;&#20043;&#19968;&#26159;&#35813;&#22352;&#26631;&#24212;&#28165;&#26224;&#22320;&#25429;&#33719;&#21453;&#24212;&#29289;&#21644;&#29983;&#25104;&#29289;&#29366;&#24577;&#12290;&#27492;&#22806;&#65292;&#22352;&#26631;&#24212;&#35813;&#26159;&#26368;&#24930;&#30340;&#65292;&#20351;&#24471;&#25152;&#26377;&#20854;&#20182;&#33258;&#30001;&#24230;&#21487;&#20197;&#27839;&#30528;&#21453;&#24212;&#22352;&#26631;&#36731;&#26494;&#36798;&#21040;&#24179;&#34913;&#12290;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#31181;&#27491;&#21017;&#21270;&#31232;&#30095;&#33258;&#32534;&#30721;&#22120;&#65292;&#21363;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#65292;&#26469;&#21457;&#29616;&#19968;&#32452;&#20851;&#38190;&#30340;&#21453;&#24212;&#22352;&#26631;&#12290;&#38500;&#20102;&#21457;&#29616;&#21453;&#24212;&#22352;&#26631;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#36824;&#21487;&#20197;&#39044;&#27979;&#20998;&#23376;&#21160;&#21147;&#23398;(MD)&#36712;&#36857;&#30340;&#28436;&#21270;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#21253;&#25324;&#31232;&#30095;&#32422;&#26463;&#27491;&#21017;&#21270;&#26377;&#21161;&#20110;&#36873;&#25321;&#19968;&#20010;&#23567;&#20294;&#37325;&#35201;&#30340;&#19968;&#32452;&#21453;&#24212;&#22352;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
Identifying reaction coordinates(RCs) is an active area of research, given the crucial role RCs play in determining the progress of a chemical reaction. The choice of the reaction coordinate is often based on heuristic knowledge. However, an essential criterion for the choice is that the coordinate should capture both the reactant and product states unequivocally. Also, the coordinate should be the slowest one so that all the other degrees of freedom can easily equilibrate along the reaction coordinate. Also, the coordinate should be the slowest one so that all the other degrees of freedom can easily equilibrate along the reaction coordinate. We used a regularised sparse autoencoder, an energy-based model, to discover a crucial set of reaction coordinates. Along with discovering reaction coordinates, our model also predicts the evolution of a molecular dynamics(MD) trajectory. We showcased that including sparsity enforcing regularisation helps in choosing a small but important set of r
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#38024;&#23545;ElasticNet&#30340;&#26032;&#39062;&#32467;&#26500;&#32467;&#26524;&#65292;&#29992;&#20197;&#35777;&#26126;&#22312;&#22810;&#20010;&#38382;&#39064;&#23454;&#20363;&#20013;&#35843;&#25972;&#27491;&#35268;&#21270;&#21442;&#25968;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#32479;&#35745;&#21644;&#22312;&#32447;&#23398;&#20064;&#24773;&#26223;&#19979;&#30340;&#27867;&#21270;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2207.10199</link><description>&lt;p&gt;
&#21487;&#35777;&#26126;&#22320;&#35843;&#25972;ElasticNet&#22312;&#22810;&#20010;&#23454;&#20363;&#38388;&#30340;&#21442;&#25968;
&lt;/p&gt;
&lt;p&gt;
Provably tuning the ElasticNet across instances. (arXiv:2207.10199v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.10199
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#38024;&#23545;ElasticNet&#30340;&#26032;&#39062;&#32467;&#26500;&#32467;&#26524;&#65292;&#29992;&#20197;&#35777;&#26126;&#22312;&#22810;&#20010;&#38382;&#39064;&#23454;&#20363;&#20013;&#35843;&#25972;&#27491;&#35268;&#21270;&#21442;&#25968;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#32479;&#35745;&#21644;&#22312;&#32447;&#23398;&#20064;&#24773;&#26223;&#19979;&#30340;&#27867;&#21270;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27491;&#35268;&#21270;&#29702;&#35770;&#20013;&#19968;&#20010;&#37325;&#35201;&#26410;&#35299;&#20915;&#30340;&#25361;&#25112;&#26159;&#22914;&#20309;&#35774;&#32622;&#24120;&#29992;&#25216;&#26415;&#65288;&#22914;ElasticNet&#65289;&#30340;&#27491;&#35268;&#21270;&#31995;&#25968;&#65292;&#24182;&#25552;&#20379;&#19968;&#33324;&#21487;&#35777;&#26126;&#30340;&#20445;&#35777;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#22312;&#22810;&#20010;&#38382;&#39064;&#23454;&#20363;&#20013;&#35843;&#25972;Ridge&#22238;&#24402;&#12289;LASSO&#21644;ElasticNet&#30340;&#27491;&#35268;&#21270;&#21442;&#25968;&#30340;&#38382;&#39064;&#65292;&#36825;&#31181;&#35774;&#32622;&#21253;&#25324;&#20102;&#20132;&#21449;&#39564;&#35777;&#21644;&#22810;&#20219;&#21153;&#36229;&#21442;&#25968;&#20248;&#21270;&#12290;&#25105;&#20204;&#33719;&#24471;&#20102;&#38024;&#23545;ElasticNet&#30340;&#26032;&#39062;&#32467;&#26500;&#32467;&#26524;&#65292;&#23558;&#25439;&#22833;&#20989;&#25968;&#34920;&#36798;&#20026;&#20197;&#35843;&#25972;&#21442;&#25968;&#20026;&#20989;&#25968;&#30340;&#20998;&#27573;&#26377;&#29702;&#20989;&#25968;&#65292;&#20854;&#20013;&#21253;&#21547;&#20195;&#25968;&#36793;&#30028;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#19968;&#32467;&#26524;&#23545;&#27491;&#35268;&#21270;&#25439;&#22833;&#20989;&#25968;&#30340;&#32467;&#26500;&#22797;&#26434;&#24615;&#36827;&#34892;&#20102;&#30028;&#23450;&#65292;&#24182;&#22312;&#32479;&#35745;&#24773;&#26223;&#19979;&#23637;&#31034;&#20102;&#35843;&#25972;ElasticNet&#22238;&#24402;&#31995;&#25968;&#30340;&#27867;&#21270;&#20445;&#35777;&#12290;&#25105;&#20204;&#36824;&#32771;&#34385;&#20102;&#26356;&#20855;&#25361;&#25112;&#24615;&#30340;&#22312;&#32447;&#23398;&#20064;&#24773;&#26223;&#65292;&#23637;&#31034;&#20102;&#19982;&#26368;&#20248;&#21442;&#25968;&#23545;&#30456;&#23545;&#32780;&#35328;&#65292;&#28040;&#22833;&#30340;&#24179;&#22343;&#39044;&#26399;&#36951;&#25022;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;&#25105;&#20204;&#30340;&#32467;&#26524;&#25193;&#23637;&#21040;&#35843;&#25972;&#20998;&#31867;&#38382;&#39064;&#30340;&#24773;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
An important unresolved challenge in the theory of regularization is to set the regularization coefficients of popular techniques like the ElasticNet with general provable guarantees. We consider the problem of tuning the regularization parameters of Ridge regression, LASSO, and the ElasticNet across multiple problem instances, a setting that encompasses both cross-validation and multi-task hyperparameter optimization. We obtain a novel structural result for the ElasticNet which characterizes the loss as a function of the tuning parameters as a piecewise-rational function with algebraic boundaries. We use this to bound the structural complexity of the regularized loss functions and show generalization guarantees for tuning the ElasticNet regression coefficients in the statistical setting. We also consider the more challenging online learning setting, where we show vanishing average expected regret relative to the optimal parameter pair. We further extend our results to tuning classific
&lt;/p&gt;</description></item><item><title>&#24352;&#37327;&#23545;&#24352;&#37327;&#22238;&#24402;&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#40654;&#26364;&#20248;&#21270;&#26041;&#27861;&#21644;&#31209;&#36807;&#21442;&#25968;&#21270;&#30340;&#30740;&#31350;&#65292;&#24182;&#23637;&#31034;&#20102;&#40654;&#26364;&#20248;&#21270;&#26041;&#27861;&#30340;&#32447;&#24615;&#21644;&#20108;&#27425;&#25910;&#25947;&#24615;&#20197;&#21450;&#36866;&#24212;&#36807;&#21442;&#25968;&#21270;&#30340;&#33021;&#21147;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#26631;&#37327;&#23545;&#24352;&#37327;&#22238;&#24402;&#20013;&#30340;&#32479;&#35745;&#35745;&#31639;&#24046;&#24322;&#12290;</title><link>http://arxiv.org/abs/2206.08756</link><description>&lt;p&gt;
&#24352;&#37327;&#23545;&#24352;&#37327;&#22238;&#24402;: &#40654;&#26364;&#20248;&#21270;&#65292;&#36807;&#21442;&#25968;&#21270;&#65292;&#32479;&#35745;&#35745;&#31639;&#24046;&#24322;&#21450;&#20854;&#30456;&#20114;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Tensor-on-Tensor Regression: Riemannian Optimization, Over-parameterization, Statistical-computational Gap, and Their Interplay. (arXiv:2206.08756v3 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.08756
&lt;/p&gt;
&lt;p&gt;
&#24352;&#37327;&#23545;&#24352;&#37327;&#22238;&#24402;&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#40654;&#26364;&#20248;&#21270;&#26041;&#27861;&#21644;&#31209;&#36807;&#21442;&#25968;&#21270;&#30340;&#30740;&#31350;&#65292;&#24182;&#23637;&#31034;&#20102;&#40654;&#26364;&#20248;&#21270;&#26041;&#27861;&#30340;&#32447;&#24615;&#21644;&#20108;&#27425;&#25910;&#25947;&#24615;&#20197;&#21450;&#36866;&#24212;&#36807;&#21442;&#25968;&#21270;&#30340;&#33021;&#21147;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#26631;&#37327;&#23545;&#24352;&#37327;&#22238;&#24402;&#20013;&#30340;&#32479;&#35745;&#35745;&#31639;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#24352;&#37327;&#23545;&#24352;&#37327;&#22238;&#24402;&#38382;&#39064;&#65292;&#20854;&#30446;&#26631;&#26159;&#22312;&#19981;&#30693;&#36947;&#20854;&#20869;&#22312;&#31209;&#30340;&#24773;&#20917;&#19979;&#65292;&#23558;&#24352;&#37327;&#21709;&#24212;&#19982;&#24352;&#37327;&#21327;&#21464;&#37327;&#30456;&#36830;&#25509;&#65292;&#36890;&#36807;&#20302;Tucker&#31209;&#21442;&#25968;&#24352;&#37327;/&#30697;&#38453;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#40654;&#26364;&#26799;&#24230;&#19979;&#38477;&#65288;RGD&#65289;&#21644;&#40654;&#26364;&#39640;&#26031;&#29275;&#39039;&#65288;RGN&#65289;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#30740;&#31350;&#31209;&#36807;&#21442;&#25968;&#21270;&#30340;&#24433;&#21709;&#26469;&#24212;&#23545;&#26410;&#30693;&#31209;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#39318;&#27425;&#25552;&#20379;&#20102;&#20851;&#20110;&#19968;&#33324;&#24352;&#37327;&#23545;&#24352;&#37327;&#22238;&#24402;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;&#65292;&#34920;&#26126;RGD&#21644;RGN&#20998;&#21035;&#22312;&#27491;&#30830;&#21442;&#25968;&#21270;&#21644;&#36807;&#21442;&#25968;&#21270;&#35774;&#32622;&#19979;&#32447;&#24615;&#21644;&#20108;&#27425;&#25910;&#25947;&#21040;&#32479;&#35745;&#19978;&#30340;&#26368;&#20248;&#20272;&#35745;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#25581;&#31034;&#20102;&#19968;&#20010;&#26377;&#36259;&#30340;&#29616;&#35937;&#65306;&#40654;&#26364;&#20248;&#21270;&#26041;&#27861;&#22312;&#19981;&#20462;&#25913;&#23454;&#29616;&#26041;&#24335;&#30340;&#24773;&#20917;&#19979;&#33258;&#28982;&#22320;&#36866;&#24212;&#36807;&#21442;&#25968;&#21270;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#30452;&#25509;&#30340;&#20302;&#27425;&#22810;&#39033;&#24335;&#35770;&#35777;&#35777;&#26126;&#20102;&#26631;&#37327;&#23545;&#24352;&#37327;&#22238;&#24402;&#20013;&#30340;&#32479;&#35745;&#35745;&#31639;&#24046;&#24322;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#35777;&#26126;&#20102;&#32479;&#35745;&#23398;&#30340;&#31119;&#38899;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the tensor-on-tensor regression, where the goal is to connect tensor responses to tensor covariates with a low Tucker rank parameter tensor/matrix without the prior knowledge of its intrinsic rank. We propose the Riemannian gradient descent (RGD) and Riemannian Gauss-Newton (RGN) methods and cope with the challenge of unknown rank by studying the effect of rank over-parameterization. We provide the first convergence guarantee for the general tensor-on-tensor regression by showing that RGD and RGN respectively converge linearly and quadratically to a statistically optimal estimate in both rank correctly-parameterized and over-parameterized settings. Our theory reveals an intriguing phenomenon: Riemannian optimization methods naturally adapt to over-parameterization without modifications to their implementation. We also prove the statistical-computational gap in scalar-on-tensor regression by a direct low-degree polynomial argument. Our theory demonstrates a "blessing of statist
&lt;/p&gt;</description></item><item><title>CoDA Nets&#26159;&#19968;&#31181;&#24615;&#33021;&#33391;&#22909;&#30340;&#20998;&#31867;&#22120;&#65292;&#20855;&#26377;&#39640;&#24230;&#20869;&#22312;&#21487;&#35299;&#37322;&#24615;&#12290;&#23427;&#20204;&#36890;&#36807;&#21160;&#24577;&#23545;&#40784;&#21333;&#20803;&#23454;&#29616;&#36755;&#20837;&#20381;&#36182;&#30340;&#32447;&#24615;&#21464;&#25442;&#65292;&#24182;&#23558;&#36755;&#20986;&#32447;&#24615;&#20998;&#35299;&#20026;&#21508;&#20010;&#36755;&#20837;&#30340;&#36129;&#29486;&#12290;&#36825;&#20123;&#27169;&#22411;&#22312;&#35270;&#35273;&#36136;&#37327;&#21644;&#20998;&#31867;&#20934;&#30830;&#24230;&#19978;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;CIFAR-10&#21644;TinyImagenet&#31561;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#19982;ResNet&#21644;VGG&#27169;&#22411;&#30456;&#23218;&#32654;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2109.13004</link><description>&lt;p&gt;
&#20248;&#21270;&#21487;&#35299;&#37322;&#24615;&#65306;&#21367;&#31215;&#21160;&#24577;&#23545;&#40784;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Optimising for Interpretability: Convolutional Dynamic Alignment Networks. (arXiv:2109.13004v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.13004
&lt;/p&gt;
&lt;p&gt;
CoDA Nets&#26159;&#19968;&#31181;&#24615;&#33021;&#33391;&#22909;&#30340;&#20998;&#31867;&#22120;&#65292;&#20855;&#26377;&#39640;&#24230;&#20869;&#22312;&#21487;&#35299;&#37322;&#24615;&#12290;&#23427;&#20204;&#36890;&#36807;&#21160;&#24577;&#23545;&#40784;&#21333;&#20803;&#23454;&#29616;&#36755;&#20837;&#20381;&#36182;&#30340;&#32447;&#24615;&#21464;&#25442;&#65292;&#24182;&#23558;&#36755;&#20986;&#32447;&#24615;&#20998;&#35299;&#20026;&#21508;&#20010;&#36755;&#20837;&#30340;&#36129;&#29486;&#12290;&#36825;&#20123;&#27169;&#22411;&#22312;&#35270;&#35273;&#36136;&#37327;&#21644;&#20998;&#31867;&#20934;&#30830;&#24230;&#19978;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;CIFAR-10&#21644;TinyImagenet&#31561;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#19982;ResNet&#21644;VGG&#27169;&#22411;&#30456;&#23218;&#32654;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#31216;&#20026;&#21367;&#31215;&#21160;&#24577;&#23545;&#40784;&#32593;&#32476;&#65288;CoDA Nets&#65289;&#65292;&#23427;&#26159;&#19968;&#31181;&#20855;&#26377;&#39640;&#24230;&#20869;&#22312;&#21487;&#35299;&#37322;&#24615;&#30340;&#24615;&#33021;&#20998;&#31867;&#22120;&#12290;&#23427;&#20204;&#30340;&#26680;&#24515;&#26500;&#24314;&#27169;&#22359;&#26159;&#21160;&#24577;&#23545;&#40784;&#21333;&#20803;&#65288;DAUs&#65289;&#65292;&#20854;&#32463;&#36807;&#20248;&#21270;&#21518;&#33021;&#22815;&#36890;&#36807;&#21160;&#24577;&#35745;&#31639;&#30340;&#26435;&#37325;&#21521;&#37327;&#23558;&#20854;&#36755;&#20837;&#36716;&#25442;&#20026;&#19982;&#20219;&#21153;&#30456;&#20851;&#27169;&#24335;&#23545;&#40784;&#30340;&#24418;&#24335;&#12290;&#22240;&#27492;&#65292;CoDA Nets&#36890;&#36807;&#19968;&#31995;&#21015;&#20381;&#36182;&#20110;&#36755;&#20837;&#30340;&#32447;&#24615;&#21464;&#25442;&#26469;&#27169;&#25311;&#20998;&#31867;&#39044;&#27979;&#65292;&#20801;&#35768;&#23558;&#36755;&#20986;&#32447;&#24615;&#20998;&#35299;&#20026;&#21508;&#20010;&#36755;&#20837;&#30340;&#36129;&#29486;&#12290;&#26681;&#25454;DAUs&#30340;&#23545;&#40784;&#24773;&#20917;&#65292;&#24471;&#21040;&#30340;&#36129;&#29486;&#26144;&#23556;&#19982;&#37492;&#21035;&#24615;&#36755;&#20837;&#27169;&#24335;&#30456;&#19968;&#33268;&#12290;&#36825;&#20123;&#27169;&#22411;&#22266;&#26377;&#30340;&#20998;&#35299;&#20855;&#26377;&#24456;&#39640;&#30340;&#35270;&#35273;&#36136;&#37327;&#65292;&#22312;&#23450;&#37327;&#25351;&#26631;&#19979;&#20248;&#20110;&#29616;&#26377;&#30340;&#24402;&#22240;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;CoDA Nets&#26159;&#24615;&#33021;&#20986;&#33394;&#30340;&#20998;&#31867;&#22120;&#65292;&#22312;CIFAR-10&#21644;TinyImagenet&#31561;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#19982;ResNet&#21644;VGG&#27169;&#22411;&#30456;&#23218;&#32654;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new family of neural network models called Convolutional Dynamic Alignment Networks (CoDA Nets), which are performant classifiers with a high degree of inherent interpretability. Their core building blocks are Dynamic Alignment Units (DAUs), which are optimised to transform their inputs with dynamically computed weight vectors that align with task-relevant patterns. As a result, CoDA Nets model the classification prediction through a series of input-dependent linear transformations, allowing for linear decomposition of the output into individual input contributions. Given the alignment of the DAUs, the resulting contribution maps align with discriminative input patterns. These model-inherent decompositions are of high visual quality and outperform existing attribution methods under quantitative metrics. Further, CoDA Nets constitute performant classifiers, achieving on par results to ResNet and VGG models on e.g. CIFAR-10 and TinyImagenet. Lastly, CoDA Nets can be combin
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;SubseasonalClimateUSA&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#35757;&#32451;&#21644;&#22522;&#20934;&#27979;&#35797;&#32654;&#22269;&#30340;&#20122;&#23395;&#33410;&#39044;&#27979;&#27169;&#22411;&#30340;&#25968;&#25454;&#38598;&#12290;&#20316;&#32773;&#20351;&#29992;&#35813;&#25968;&#25454;&#38598;&#23545;&#22810;&#31181;&#27169;&#22411;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#12290;</title><link>http://arxiv.org/abs/2109.10399</link><description>&lt;p&gt;
SubseasonalClimateUSA: &#29992;&#20110;&#20122;&#23395;&#33410;&#39044;&#27979;&#21644;&#22522;&#20934;&#27979;&#35797;&#30340;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
SubseasonalClimateUSA: A Dataset for Subseasonal Forecasting and Benchmarking. (arXiv:2109.10399v3 [physics.ao-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.10399
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;SubseasonalClimateUSA&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#35757;&#32451;&#21644;&#22522;&#20934;&#27979;&#35797;&#32654;&#22269;&#30340;&#20122;&#23395;&#33410;&#39044;&#27979;&#27169;&#22411;&#30340;&#25968;&#25454;&#38598;&#12290;&#20316;&#32773;&#20351;&#29992;&#35813;&#25968;&#25454;&#38598;&#23545;&#22810;&#31181;&#27169;&#22411;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22825;&#27668;&#30340;&#20122;&#23395;&#33410;&#39044;&#27979;&#23545;&#36164;&#28304;&#37197;&#32622;&#21644;&#27668;&#20505;&#36866;&#24212;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#23545;&#39044;&#27979;&#31038;&#21306;&#25552;&#20986;&#20102;&#35768;&#22810;&#25361;&#25112;&#12290;&#22312;&#36825;&#20010;&#39044;&#27979;&#26102;&#38388;&#33539;&#22260;&#20869;&#65292;&#22522;&#20110;&#29289;&#29702;&#30340;&#21160;&#21147;&#23398;&#27169;&#22411;&#30340;&#25216;&#33021;&#26377;&#38480;&#65292;&#24182;&#19988;&#39044;&#27979;&#30446;&#26631;&#20197;&#19968;&#31181;&#22797;&#26434;&#30340;&#26041;&#24335;&#20381;&#36182;&#20110;&#26412;&#22320;&#22825;&#27668;&#21644;&#20840;&#29699;&#27668;&#20505;&#21464;&#37327;&#12290;&#26368;&#36817;&#65292;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#26174;&#31034;&#20986;&#25512;&#36827;&#25216;&#26415;&#30340;&#28508;&#21147;&#65292;&#20294;&#38656;&#35201;&#22797;&#26434;&#30340;&#25968;&#25454;&#25972;&#29702;&#65292;&#23558;&#19987;&#23478;&#30693;&#35782;&#19982;&#22810;&#20010;&#30456;&#20851;&#25968;&#25454;&#26469;&#28304;&#12289;&#25991;&#20214;&#26684;&#24335;&#21644;&#26102;&#38388;&#31354;&#38388;&#20998;&#36776;&#29575;&#30340;&#32858;&#21512;&#36827;&#34892;&#25972;&#21512;&#12290;&#20026;&#20102;&#31616;&#21270;&#36825;&#20010;&#36807;&#31243;&#24182;&#21152;&#36895;&#26410;&#26469;&#30340;&#21457;&#23637;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;SubseasonalClimateUSA&#65292;&#36825;&#26159;&#19968;&#20010;&#32463;&#36807;&#31574;&#21010;&#30340;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#35757;&#32451;&#21644;&#22522;&#20934;&#27979;&#35797;&#32654;&#22269;&#30340;&#20122;&#23395;&#33410;&#39044;&#27979;&#27169;&#22411;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#20010;&#25968;&#25454;&#38598;&#26469;&#23545;&#21508;&#31181;&#19981;&#21516;&#30340;&#20122;&#23395;&#33410;&#27169;&#22411;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#65292;&#21253;&#25324;&#25805;&#20316;&#24615;&#21160;&#21147;&#23398;&#27169;&#22411;&#12289;&#21476;&#20856;&#30340;&#27668;&#35937;&#22522;&#32447;&#20197;&#21450;&#21313;&#20010;&#32479;&#35745;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Subseasonal forecasting of the weather two to six weeks in advance is critical for resource allocation and climate adaptation but poses many challenges for the forecasting community. At this forecast horizon, physics-based dynamical models have limited skill, and the targets for prediction depend in a complex manner on both local weather and global climate variables. Recently, machine learning methods have shown promise in advancing the state of the art but only at the cost of complex data curation, integrating expert knowledge with aggregation across multiple relevant data sources, file formats, and temporal and spatial resolutions. To streamline this process and accelerate future development, we introduce SubseasonalClimateUSA, a curated dataset for training and benchmarking subseasonal forecasting models in the United States. We use this dataset to benchmark a diverse suite of subseasonal models, including operational dynamical models, classical meteorological baselines, and ten sta
&lt;/p&gt;</description></item><item><title>&#24191;&#20041;&#27491;&#20132;Procrustes&#38382;&#39064;&#22312;&#22810;&#20010;&#31185;&#23398;&#39046;&#22495;&#20013;&#36215;&#21040;&#22522;&#30784;&#24615;&#20316;&#29992;&#12290;SDR&#21487;&#20197;&#31934;&#30830;&#24674;&#22797;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#65292;&#32780;&#36866;&#24403;&#21021;&#22987;&#21270;&#19979;&#30340;&#24191;&#20041;&#21151;&#29575;&#26041;&#27861;&#20197;&#32447;&#24615;&#26041;&#24335;&#25910;&#25947;&#20110;SDR&#30340;&#20840;&#23616;&#26368;&#23567;&#21270;&#22120;&#12290;</title><link>http://arxiv.org/abs/2106.15493</link><description>&lt;p&gt;
&#20219;&#24847;&#23545;&#25163;&#19979;&#30340;&#24191;&#20041;&#27491;&#20132;Procrustes&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Generalized Orthogonal Procrustes Problem under Arbitrary Adversaries. (arXiv:2106.15493v2 [cs.IT] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.15493
&lt;/p&gt;
&lt;p&gt;
&#24191;&#20041;&#27491;&#20132;Procrustes&#38382;&#39064;&#22312;&#22810;&#20010;&#31185;&#23398;&#39046;&#22495;&#20013;&#36215;&#21040;&#22522;&#30784;&#24615;&#20316;&#29992;&#12290;SDR&#21487;&#20197;&#31934;&#30830;&#24674;&#22797;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#65292;&#32780;&#36866;&#24403;&#21021;&#22987;&#21270;&#19979;&#30340;&#24191;&#20041;&#21151;&#29575;&#26041;&#27861;&#20197;&#32447;&#24615;&#26041;&#24335;&#25910;&#25947;&#20110;SDR&#30340;&#20840;&#23616;&#26368;&#23567;&#21270;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24191;&#20041;&#27491;&#20132;Procrustes&#38382;&#39064;&#65288;Generalized Orthogonal Procrustes Problem&#65292;GOPP&#65289;&#22312;&#32479;&#35745;&#23398;&#12289;&#25104;&#20687;&#31185;&#23398;&#21644;&#35745;&#31639;&#26426;&#35270;&#35273;&#31561;&#22810;&#20010;&#31185;&#23398;&#39046;&#22495;&#20013;&#37117;&#20855;&#26377;&#22522;&#30784;&#24615;&#20316;&#29992;&#12290;&#23613;&#31649;&#20854;&#22312;&#23454;&#38469;&#20013;&#20855;&#26377;&#24040;&#22823;&#30340;&#37325;&#35201;&#24615;&#65292;&#20294;&#36890;&#24120;&#24456;&#38590;&#25214;&#21040;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#30340; NP-hard &#38382;&#39064;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#21322;&#23450;&#26494;&#24347;&#65288;Semidefinite Relaxation&#65292;SDR&#65289;&#21644;&#19968;&#31181;&#21517;&#20026;&#24191;&#20041;&#21151;&#29575;&#26041;&#27861;&#65288;Generalized Power Method&#65292;GPM&#65289;&#30340;&#36845;&#20195;&#26041;&#27861;&#65292;&#20197;&#23547;&#25214;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#65292;&#24182;&#30740;&#31350;&#20102;&#22312;&#20449;&#21495;&#21152;&#22122;&#22768;&#27169;&#22411;&#19979;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;SDR&#21487;&#20197;&#31934;&#30830;&#24674;&#22797;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#65292;&#24182;&#19988;&#22312;&#36866;&#24403;&#30340;&#21021;&#22987;&#21270;&#19979;&#65292;&#24191;&#20041;&#21151;&#29575;&#26041;&#27861;&#20197;&#32447;&#24615;&#26041;&#24335;&#25910;&#25947;&#20110;SDR&#30340;&#20840;&#23616;&#26368;&#23567;&#21270;&#22120;&#65292;&#21069;&#25552;&#26159;&#20449;&#22122;&#27604;&#36739;&#22823;&#12290;&#20027;&#35201;&#25216;&#26415;&#22522;&#20110;&#23637;&#31034;GPM&#20013;&#28041;&#21450;&#30340;&#38750;&#32447;&#24615;&#26144;&#23556;&#26412;&#36136;&#19978;&#26159;&#23616;&#37096;&#25910;&#32553;&#26144;&#23556;&#65292;&#28982;&#21518;&#24212;&#29992;&#33879;&#21517;&#30340;Banach&#19981;&#21160;&#28857;&#23450;&#29702;&#23436;&#25104;&#35777;&#26126;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#20998;&#26512;&#20102;&#20302;&#31209;&#20998;&#35299;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The generalized orthogonal Procrustes problem (GOPP) plays a fundamental role in several scientific disciplines including statistics, imaging science and computer vision. Despite its tremendous practical importance, it is generally an NP-hard problem to find the least squares estimator. We study the semidefinite relaxation (SDR) and an iterative method named generalized power method (GPM) to find the least squares estimator, and investigate the performance under a signal-plus-noise model. We show that the SDR recovers the least squares estimator exactly and moreover the generalized power method with a proper initialization converges linearly to the global minimizer to the SDR, provided that the signal-to-noise ratio is large. The main technique follows from showing the nonlinear mapping involved in the GPM is essentially a local contraction mapping and then applying the well-known Banach fixed-point theorem finishes the proof. In addition, we analyze the low-rank factorization algorith
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25932;&#23545;&#26694;&#26550;&#65292;&#20351;&#29992;&#36890;&#29992;&#20989;&#25968;&#31354;&#38388;&#26469;&#20272;&#35745;Riesz Representer&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#38750;&#28176;&#36817;&#22343;&#26041;&#36895;&#29575;&#20197;&#21450;&#28176;&#36817;&#27491;&#24577;&#24615;&#30340;&#26465;&#20214;&#12290;&#36825;&#20010;&#26465;&#20214;&#20351;&#24471;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#36827;&#34892;&#25512;&#26029;&#26102;&#26080;&#38656;&#26679;&#26412;&#20998;&#21106;&#65292;&#24182;&#19988;&#33021;&#22815;&#25552;&#39640;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2101.00009</link><description>&lt;p&gt;
&#23545;Riesz Representer&#30340;&#25932;&#23545;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Adversarial Estimation of Riesz Representers. (arXiv:2101.00009v2 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2101.00009
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25932;&#23545;&#26694;&#26550;&#65292;&#20351;&#29992;&#36890;&#29992;&#20989;&#25968;&#31354;&#38388;&#26469;&#20272;&#35745;Riesz Representer&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#38750;&#28176;&#36817;&#22343;&#26041;&#36895;&#29575;&#20197;&#21450;&#28176;&#36817;&#27491;&#24577;&#24615;&#30340;&#26465;&#20214;&#12290;&#36825;&#20010;&#26465;&#20214;&#20351;&#24471;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#36827;&#34892;&#25512;&#26029;&#26102;&#26080;&#38656;&#26679;&#26412;&#20998;&#21106;&#65292;&#24182;&#19988;&#33021;&#22815;&#25552;&#39640;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#22240;&#26524;&#21644;&#32467;&#26500;&#21442;&#25968;&#26159;&#22522;&#20110;&#24213;&#23618;&#22238;&#24402;&#30340;&#32447;&#24615;&#27867;&#20989;&#12290;Riesz Representer&#26159;&#21322;&#21442;&#25968;&#32447;&#24615;&#27867;&#20989;&#28176;&#36817;&#26041;&#24046;&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25932;&#23545;&#26694;&#26550;&#65292;&#20351;&#29992;&#36890;&#29992;&#20989;&#25968;&#31354;&#38388;&#26469;&#20272;&#35745;Riesz Representer&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#38750;&#28176;&#36817;&#22343;&#26041;&#36895;&#29575;&#65292;&#20854;&#20013;&#28041;&#21450;&#19968;&#20010;&#31216;&#20026;&#20020;&#30028;&#21322;&#24452;&#30340;&#25277;&#35937;&#37327;&#65292;&#28982;&#21518;&#23558;&#20854;&#19987;&#38376;&#24212;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#12289;&#38543;&#26426;&#26862;&#26519;&#21644;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20316;&#20026;&#20027;&#35201;&#26696;&#20363;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;&#20020;&#30028;&#21322;&#24452;&#29702;&#35770;&#26469;&#35777;&#26126;&#20102;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#32780;&#19981;&#38656;&#35201;&#26679;&#26412;&#20998;&#21106;&#65292;&#25581;&#31034;&#20102;&#19968;&#31181;&#8220;&#22797;&#26434;&#24230;-&#36895;&#29575;&#40065;&#26834;&#24615;&#8221;&#26465;&#20214;&#12290;&#36825;&#20010;&#26465;&#20214;&#20855;&#26377;&#23454;&#38469;&#21518;&#26524;&#65306;&#22312;&#20960;&#20010;&#26426;&#22120;&#23398;&#20064;&#35774;&#32622;&#20013;&#65292;&#21487;&#20197;&#23454;&#29616;&#26080;&#38656;&#26679;&#26412;&#20998;&#21106;&#30340;&#25512;&#26029;&#65292;&#36825;&#21487;&#33021;&#20250;&#25552;&#39640;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#22312;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#27169;&#25311;&#20013;&#23454;&#29616;&#20102;&#21517;&#20041;&#35206;&#30422;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many causal and structural parameters are linear functionals of an underlying regression. The Riesz representer is a key component in the asymptotic variance of a semiparametrically estimated linear functional. We propose an adversarial framework to estimate the Riesz representer using general function spaces. We prove a nonasymptotic mean square rate in terms of an abstract quantity called the critical radius, then specialize it for neural networks, random forests, and reproducing kernel Hilbert spaces as leading cases. Furthermore, we use critical radius theory -- in place of Donsker theory -- to prove asymptotic normality without sample splitting, uncovering a ``complexity-rate robustness'' condition. This condition has practical consequences: inference without sample splitting is possible in several machine learning settings, which may improve finite sample performance compared to sample splitting. Our estimators achieve nominal coverage in highly nonlinear simulations where previo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#29983;&#25104;&#22411;&#38543;&#26426;&#20613;&#31435;&#21494;&#29305;&#24449;&#36827;&#34892;&#31471;&#21040;&#31471;&#20869;&#26680;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#23558;&#20869;&#26680;&#23398;&#20064;&#21644;&#32447;&#24615;&#23398;&#20064;&#22120;&#34701;&#21512;&#20026;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#65292;&#36890;&#36807;&#29983;&#25104;&#32593;&#32476;&#21644;&#32447;&#24615;&#20998;&#31867;&#22120;&#32852;&#21512;&#35757;&#32451;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2009.04614</link><description>&lt;p&gt;
&#36890;&#36807;&#29983;&#25104;&#22411;&#38543;&#26426;&#20613;&#31435;&#21494;&#29305;&#24449;&#36827;&#34892;&#31471;&#21040;&#31471;&#20869;&#26680;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
End-to-end Kernel Learning via Generative Random Fourier Features. (arXiv:2009.04614v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2009.04614
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#29983;&#25104;&#22411;&#38543;&#26426;&#20613;&#31435;&#21494;&#29305;&#24449;&#36827;&#34892;&#31471;&#21040;&#31471;&#20869;&#26680;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#23558;&#20869;&#26680;&#23398;&#20064;&#21644;&#32447;&#24615;&#23398;&#20064;&#22120;&#34701;&#21512;&#20026;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#65292;&#36890;&#36807;&#29983;&#25104;&#32593;&#32476;&#21644;&#32447;&#24615;&#20998;&#31867;&#22120;&#32852;&#21512;&#35757;&#32451;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#20613;&#31435;&#21494;&#29305;&#24449;&#65288;RFFs&#65289;&#20026;&#35889;&#20869;&#26680;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#26041;&#27861;&#12290;&#30446;&#21069;&#22522;&#20110;RFFs&#30340;&#20869;&#26680;&#23398;&#20064;&#26041;&#27861;&#36890;&#24120;&#20197;&#20004;&#38454;&#27573;&#26041;&#24335;&#24037;&#20316;&#12290;&#22312;&#31532;&#19968;&#38454;&#27573;&#36807;&#31243;&#20013;&#65292;&#23398;&#20064;&#26368;&#20248;&#29305;&#24449;&#26144;&#23556;&#36890;&#24120;&#34987;&#34920;&#36848;&#20026;&#30446;&#26631;&#23545;&#40784;&#38382;&#39064;&#65292;&#20854;&#30446;&#26631;&#26159;&#23558;&#23398;&#20064;&#21040;&#30340;&#20869;&#26680;&#19982;&#39044;&#23450;&#20041;&#30340;&#30446;&#26631;&#20869;&#26680;&#65288;&#36890;&#24120;&#26159;&#29702;&#24819;&#20869;&#26680;&#65289;&#23545;&#40784;&#12290;&#22312;&#31532;&#20108;&#38454;&#27573;&#36807;&#31243;&#20013;&#65292;&#32447;&#24615;&#23398;&#20064;&#22120;&#38024;&#23545;&#26144;&#23556;&#30340;&#38543;&#26426;&#29305;&#24449;&#36827;&#34892;&#35757;&#32451;&#12290;&#28982;&#32780;&#65292;&#30446;&#26631;&#23545;&#40784;&#20013;&#30340;&#39044;&#23450;&#20041;&#20869;&#26680;&#19981;&#19968;&#23450;&#23545;&#20110;&#32447;&#24615;&#23398;&#20064;&#22120;&#30340;&#27867;&#21270;&#26159;&#26368;&#20248;&#30340;&#12290;&#30456;&#21453;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#23558;&#20869;&#26680;&#23398;&#20064;&#21644;&#32447;&#24615;&#23398;&#20064;&#22120;&#34701;&#21512;&#20026;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#30340;&#19968;&#38454;&#27573;&#36807;&#31243;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#36890;&#36807;RFFs&#38544;&#24335;&#23398;&#20064;&#20869;&#26680;&#30340;&#29983;&#25104;&#32593;&#32476;&#65292;&#25509;&#30528;&#20351;&#29992;&#19968;&#20010;&#20840;&#36830;&#25509;&#23618;&#21442;&#25968;&#21270;&#30340;&#32447;&#24615;&#20998;&#31867;&#22120;&#12290;&#28982;&#21518;&#65292;&#36890;&#36807;&#27714;&#35299;&#20248;&#21270;&#38382;&#39064;&#65292;&#32852;&#21512;&#35757;&#32451;&#29983;&#25104;&#32593;&#32476;&#21644;&#20998;&#31867;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Random Fourier features (RFFs) provide a promising way for kernel learning in a spectral case. Current RFFs-based kernel learning methods usually work in a two-stage way. In the first-stage process, learning the optimal feature map is often formulated as a target alignment problem, which aims to align the learned kernel with the pre-defined target kernel (usually the ideal kernel). In the second-stage process, a linear learner is conducted with respect to the mapped random features. Nevertheless, the pre-defined kernel in target alignment is not necessarily optimal for the generalization of the linear learner. Instead, in this paper, we consider a one-stage process that incorporates the kernel learning and linear learner into a unifying framework. To be specific, a generative network via RFFs is devised to implicitly learn the kernel, followed by a linear classifier parameterized as a full-connected layer. Then the generative network and the classifier are jointly trained by solving th
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23558;&#30417;&#30563;&#23398;&#20064;&#21644;VAEs&#32479;&#19968;&#20110;&#22522;&#20110;&#27491;&#24577;&#27969;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20013;&#65292;&#23545;&#22825;&#25991;&#31890;&#23376;&#37325;&#24314;&#36827;&#34892;&#20102;&#35206;&#30422;&#12289;&#31995;&#32479;&#24615;&#21644;&#25311;&#21512;&#22909;&#22351;&#30340;&#30740;&#31350;&#65292;&#24182;&#36890;&#36807;KL&#25955;&#24230;&#30446;&#26631;&#23454;&#29616;&#20102;&#30417;&#30563;&#23398;&#20064;&#21644;VAEs&#30340;&#32479;&#19968;&#12290;&#21033;&#29992;&#26465;&#20214;&#27491;&#24577;&#21270;&#27969;&#30340;&#26041;&#27861;&#21487;&#20197;&#35745;&#31639;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#25311;&#21512;&#20248;&#24230;p&#20540;&#12290;</title><link>http://arxiv.org/abs/2008.05825</link><description>&lt;p&gt;
&#23558;&#30417;&#30563;&#23398;&#20064;&#21644;VAEs&#32479;&#19968;&#22312;&#22522;&#20110;&#27491;&#24577;&#27969;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20013;&#23545;&#22825;&#25991;&#31890;&#23376;&#37325;&#24314;&#36827;&#34892;&#35206;&#30422;&#12289;&#31995;&#32479;&#24615;&#21644;&#25311;&#21512;&#22909;&#22351;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Unifying supervised learning and VAEs -- coverage, systematics and goodness-of-fit in normalizing-flow based neural network models for astro-particle reconstructions. (arXiv:2008.05825v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2008.05825
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#30417;&#30563;&#23398;&#20064;&#21644;VAEs&#32479;&#19968;&#20110;&#22522;&#20110;&#27491;&#24577;&#27969;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20013;&#65292;&#23545;&#22825;&#25991;&#31890;&#23376;&#37325;&#24314;&#36827;&#34892;&#20102;&#35206;&#30422;&#12289;&#31995;&#32479;&#24615;&#21644;&#25311;&#21512;&#22909;&#22351;&#30340;&#30740;&#31350;&#65292;&#24182;&#36890;&#36807;KL&#25955;&#24230;&#30446;&#26631;&#23454;&#29616;&#20102;&#30417;&#30563;&#23398;&#20064;&#21644;VAEs&#30340;&#32479;&#19968;&#12290;&#21033;&#29992;&#26465;&#20214;&#27491;&#24577;&#21270;&#27969;&#30340;&#26041;&#27861;&#21487;&#20197;&#35745;&#31639;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#25311;&#21512;&#20248;&#24230;p&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22825;&#25991;&#31890;&#23376;&#29289;&#29702;&#23398;&#20013;&#65292;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#20107;&#20214;&#23646;&#24615;&#39044;&#27979;&#21464;&#24471;&#36234;&#26469;&#36234;&#24120;&#35265;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#32467;&#26524;&#21482;&#34987;&#29992;&#20316;&#28857;&#39044;&#27979;&#12290;&#32479;&#35745;&#19981;&#30830;&#23450;&#24615;&#21644;&#35206;&#30422;&#29575;(1)&#65292;&#31995;&#32479;&#19981;&#30830;&#23450;&#24615;(2)&#25110;&#25311;&#21512;&#20248;&#24230;&#24230;&#37327;(3)&#32463;&#24120;&#27809;&#26377;&#34987;&#35745;&#31639;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#31181;&#29305;&#23450;&#30340;&#35757;&#32451;&#21644;&#32593;&#32476;&#26550;&#26500;&#36873;&#25321;&#65292;&#21487;&#20197;&#23558;&#25152;&#26377;&#36825;&#20123;&#23646;&#24615;&#34701;&#20837;&#21040;&#19968;&#20010;&#21333;&#19968;&#30340;&#32593;&#32476;&#27169;&#22411;&#20013;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25968;&#25454;&#21644;&#26631;&#31614;&#32852;&#21512;&#20998;&#24067;&#30340;KL&#25955;&#24230;&#30446;&#26631;&#20351;&#24471;&#22312;&#38543;&#26426;&#21464;&#20998;&#25512;&#29702;&#30340;&#19968;&#31181;&#32479;&#19968;&#19979;&#23558;&#30417;&#30563;&#23398;&#20064;&#21644;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;(VAEs)&#32479;&#19968;&#36215;&#26469;&#12290;&#36825;&#31181;&#32479;&#19968;&#24615;&#28608;&#21457;&#20102;&#19968;&#31181;&#25193;&#23637;&#30340;&#30417;&#30563;&#23398;&#20064;&#26041;&#26696;&#65292;&#21487;&#20197;&#35745;&#31639;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#25311;&#21512;&#20248;&#24230;p&#20540;&#12290;&#22312;&#36825;&#31181;&#24314;&#35774;&#20013;&#65292;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#30340;&#26465;&#20214;&#27491;&#24577;&#21270;&#27969;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#23427;&#20204;&#22914;&#20309;&#20026;&#24050;&#23450;&#20041;&#30340;&#21518;&#39564;&#20998;&#24067;&#20005;&#26684;&#23450;&#20041;&#35206;&#30422;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural-network based predictions of event properties in astro-particle physics are getting more and more common. However, in many cases the result is just utilized as a point prediction. Statistical uncertainties and coverage (1), systematic uncertainties (2) or a goodness-of-fit measure (3) are often not calculated. Here we describe a certain choice of training and network architecture that allows to incorporate all these properties into a single network model. We show that a KL-divergence objective of the joint distribution of data and labels allows to unify supervised learning and variational autoencoders (VAEs) under one umbrella of stochastic variational inference. The unification motivates an extended supervised learning scheme which allows to calculate a goodness-of-fit p-value for the neural network model. Conditional normalizing flows amortized with a neural network are crucial in this construction. We discuss how they allow to rigorously define coverage for posteriors defined
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#20559;&#21387;&#21387;&#32553;&#22312;&#20998;&#24067;&#24335;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#39318;&#27425;&#35777;&#26126;&#20102;&#20559;&#21387;&#21387;&#32553;&#22120;&#21487;&#20197;&#22312;&#21333;&#33410;&#28857;&#21644;&#20998;&#24067;&#24335;&#29615;&#22659;&#20013;&#23454;&#29616;&#32447;&#24615;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2002.12410</link><description>&lt;p&gt;
&#20851;&#20110;&#20559;&#21387;&#21387;&#32553;&#22312;&#20998;&#24067;&#24335;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
On Biased Compression for Distributed Learning. (arXiv:2002.12410v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2002.12410
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#20559;&#21387;&#21387;&#32553;&#22312;&#20998;&#24067;&#24335;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#39318;&#27425;&#35777;&#26126;&#20102;&#20559;&#21387;&#21387;&#32553;&#22120;&#21487;&#20197;&#22312;&#21333;&#33410;&#28857;&#21644;&#20998;&#24067;&#24335;&#29615;&#22659;&#20013;&#23454;&#29616;&#32447;&#24615;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#21508;&#31181;&#36890;&#20449;&#21387;&#32553;&#25216;&#26415;&#20316;&#20026;&#20998;&#24067;&#24335;&#23398;&#20064;&#20013;&#32531;&#35299;&#36890;&#20449;&#29942;&#39048;&#30340;&#24517;&#19981;&#21487;&#23569;&#30340;&#24037;&#20855;&#32780;&#20986;&#29616;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#20559;&#21387;&#21387;&#32553;&#22120;&#22312;&#23454;&#36341;&#20013;&#24448;&#24448;&#34920;&#29616;&#20986;&#27604;&#34987;&#24191;&#27867;&#30740;&#31350;&#21644;&#29702;&#35299;&#30340;&#26080;&#20559;&#21387;&#21387;&#32553;&#22120;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#20294;&#23545;&#23427;&#20204;&#30340;&#20102;&#35299;&#38750;&#24120;&#26377;&#38480;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19977;&#31867;&#20559;&#21387;&#21387;&#32553;&#31639;&#23376;&#65292;&#20854;&#20013;&#20004;&#31867;&#26159;&#26032;&#30340;&#65292;&#24182;&#30740;&#31350;&#20102;&#23427;&#20204;&#22312;&#65288;&#38543;&#26426;&#65289;&#26799;&#24230;&#19979;&#38477;&#21644;&#20998;&#24067;&#24335;&#65288;&#38543;&#26426;&#65289;&#26799;&#24230;&#19979;&#38477;&#20013;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#39318;&#27425;&#35777;&#26126;&#20102;&#20559;&#21387;&#21387;&#32553;&#22120;&#21487;&#20197;&#22312;&#21333;&#33410;&#28857;&#21644;&#20998;&#24067;&#24335;&#29615;&#22659;&#20013;&#23454;&#29616;&#32447;&#24615;&#25910;&#25947;&#36895;&#29575;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#32463;&#36807;&#38169;&#35823;&#21453;&#39304;&#26426;&#21046;&#22788;&#29702;&#30340;&#20998;&#24067;&#24335;&#21387;&#32553;&#30340;SGD&#26041;&#27861;&#20855;&#26377;&#36951;&#20256;&#36895;&#29575;$O\left( \delta L \exp \left[-\frac{\mu K}{\delta L}\right] + \frac{(C + \delta D)}{K\mu}\right)$&#65292;&#20854;&#20013;$\delta\ge 1$&#26159;&#19968;&#20010;&#36880;&#28176;&#22686;&#38271;&#30340;&#21387;&#32553;&#21442;&#25968;&#65292;m&#26410;&#23436;&#24453;&#32493;
&lt;/p&gt;
&lt;p&gt;
In the last few years, various communication compression techniques have emerged as an indispensable tool helping to alleviate the communication bottleneck in distributed learning. However, despite the fact biased compressors often show superior performance in practice when compared to the much more studied and understood unbiased compressors, very little is known about them. In this work we study three classes of biased compression operators, two of which are new, and their performance when applied to (stochastic) gradient descent and distributed (stochastic) gradient descent. We show for the first time that biased compressors can lead to linear convergence rates both in the single node and distributed settings. We prove that distributed compressed SGD method, employed with error feedback mechanism, enjoys the ergodic rate $O\left( \delta L \exp \left[-\frac{\mu K}{\delta L}\right] + \frac{(C + \delta D)}{K\mu}\right)$, where $\delta\ge 1$ is a compression parameter which grows when m
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#24102;&#21160;&#37327;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#20998;&#26512;&#19981;&#21516;&#30340;&#25439;&#22833;&#20989;&#25968;&#24418;&#24335;&#21644;&#21160;&#37327;&#33539;&#22260;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#22312;&#22810;&#20010;&#21608;&#26399;&#20869;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#24182;&#20445;&#35777;&#27867;&#21270;&#24615;&#33021;&#30340;&#20462;&#25913;&#21518;&#30340;&#21160;&#37327;&#26356;&#26032;&#35268;&#21017;&#12290;&#23545;&#20110;&#29305;&#27530;&#24773;&#20917;&#19979;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#26631;&#20934;&#30340;&#24102;&#21160;&#37327;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#20063;&#33021;&#22815;&#20855;&#26377;&#27867;&#21270;&#24615;&#33021;&#12290;&#35813;&#35770;&#25991;&#36824;&#32473;&#20986;&#20102;&#23545;&#20110;&#26399;&#26395;&#30495;&#23454;&#39118;&#38505;&#30340;&#19978;&#30028;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/1809.04564</link><description>&lt;p&gt;
&#20851;&#20110;&#24102;&#21160;&#37327;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Generalization of Stochastic Gradient Descent with Momentum. (arXiv:1809.04564v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1809.04564
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#24102;&#21160;&#37327;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#20998;&#26512;&#19981;&#21516;&#30340;&#25439;&#22833;&#20989;&#25968;&#24418;&#24335;&#21644;&#21160;&#37327;&#33539;&#22260;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#22312;&#22810;&#20010;&#21608;&#26399;&#20869;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#24182;&#20445;&#35777;&#27867;&#21270;&#24615;&#33021;&#30340;&#20462;&#25913;&#21518;&#30340;&#21160;&#37327;&#26356;&#26032;&#35268;&#21017;&#12290;&#23545;&#20110;&#29305;&#27530;&#24773;&#20917;&#19979;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#26631;&#20934;&#30340;&#24102;&#21160;&#37327;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#20063;&#33021;&#22815;&#20855;&#26377;&#27867;&#21270;&#24615;&#33021;&#12290;&#35813;&#35770;&#25991;&#36824;&#32473;&#20986;&#20102;&#23545;&#20110;&#26399;&#26395;&#30495;&#23454;&#39118;&#38505;&#30340;&#19978;&#30028;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22312;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26102;&#65292;&#22522;&#20110;&#21160;&#37327;&#30340;&#21152;&#36895;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#21464;&#31181;&#24191;&#27867;&#24212;&#29992;&#65292;&#20294;&#23545;&#20110;&#36825;&#20123;&#26041;&#27861;&#30340;&#27867;&#21270;&#35823;&#24046;&#20960;&#20046;&#27809;&#26377;&#29702;&#35770;&#19978;&#30340;&#29702;&#35299;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#23384;&#22312;&#19968;&#31181;&#20984;&#25439;&#22833;&#20989;&#25968;&#65292;&#23545;&#20110;&#22810;&#20010;&#21608;&#26399;&#30340;&#26631;&#20934;&#37325;&#29699;&#21160;&#37327;&#65288;SGDM&#65289;SGD&#65292;&#20854;&#31283;&#23450;&#38388;&#38553;&#21464;&#24471;&#26080;&#38480;&#22823;&#12290;&#28982;&#21518;&#65292;&#23545;&#20110;&#24179;&#28369;Lipschitz&#25439;&#22833;&#20989;&#25968;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#19968;&#31181;&#20462;&#25913;&#21518;&#30340;&#22522;&#20110;&#21160;&#37327;&#30340;&#26356;&#26032;&#35268;&#21017;&#65292;&#21363;SGD&#25552;&#21069;&#21160;&#37327;&#65288;SGDEM&#65289;&#65292;&#22312;&#24191;&#27867;&#30340;&#27493;&#38271;&#33539;&#22260;&#20869;&#65292;&#23427;&#21487;&#20197;&#22312;&#22810;&#20010;&#21608;&#26399;&#20869;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#24182;&#20445;&#35777;&#27867;&#21270;&#24615;&#33021;&#12290;&#26368;&#21518;&#65292;&#23545;&#20110;&#24378;&#20984;&#25439;&#22833;&#20989;&#25968;&#30340;&#29305;&#27530;&#24773;&#20917;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#19968;&#31181;&#21160;&#37327;&#33539;&#22260;&#65292;&#20351;&#24471;&#22810;&#20010;&#21608;&#26399;&#30340;&#26631;&#20934;SGDM&#65292;&#20316;&#20026;SGDEM&#30340;&#29305;&#27530;&#24418;&#24335;&#65292;&#20063;&#20855;&#26377;&#27867;&#21270;&#24615;&#33021;&#12290;&#22312;&#27867;&#21270;&#24615;&#33021;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#36824;&#23545;&#26399;&#26395;&#30495;&#23454;&#39118;&#38505;&#36827;&#34892;&#20102;&#19968;&#20010;&#19978;&#30028;&#65292;&#19982;&#35757;&#32451;&#27493;&#39588;&#25968;&#37327;&#26377;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
While momentum-based accelerated variants of stochastic gradient descent (SGD) are widely used when training machine learning models, there is little theoretical understanding on the generalization error of such methods. In this work, we first show that there exists a convex loss function for which the stability gap for multiple epochs of SGD with standard heavy-ball momentum (SGDM) becomes unbounded. Then, for smooth Lipschitz loss functions, we analyze a modified momentum-based update rule, i.e., SGD with early momentum (SGDEM) under a broad range of step-sizes, and show that it can train machine learning models for multiple epochs with a guarantee for generalization. Finally, for the special case of strongly convex loss functions, we find a range of momentum such that multiple epochs of standard SGDM, as a special form of SGDEM, also generalizes. Extending our results on generalization, we also develop an upper bound on the expected true risk, in terms of the number of training step
&lt;/p&gt;</description></item></channel></rss>