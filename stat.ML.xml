<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>otsfeatures&#26159;&#19968;&#20010;R&#21253;&#65292;&#25552;&#20379;&#20102;&#19968;&#32452;&#20989;&#25968;&#29992;&#20110;&#20998;&#26512;&#24207;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#20854;&#20013;&#21253;&#21547;&#25552;&#21462;&#32479;&#35745;&#29305;&#24449;&#21644;&#25191;&#34892;&#25512;&#26029;&#20219;&#21153;&#65292;&#20197;&#21450;&#32858;&#31867;&#12289;&#20998;&#31867;&#25110;&#24322;&#24120;&#26816;&#27979;&#31561;&#24120;&#35268;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#12290;&#27492;&#22806;&#65292;&#35813;&#36719;&#20214;&#21253;&#36824;&#21253;&#21547;&#20004;&#20010;&#37329;&#34701;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#21644;&#19977;&#20010;&#21512;&#25104;&#25968;&#25454;&#24211;&#12290;</title><link>http://arxiv.org/abs/2304.12251</link><description>&lt;p&gt;
R&#21253;otsfeatures&#20013;&#30340;&#24207;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Ordinal time series analysis with the R package otsfeatures. (arXiv:2304.12251v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12251
&lt;/p&gt;
&lt;p&gt;
otsfeatures&#26159;&#19968;&#20010;R&#21253;&#65292;&#25552;&#20379;&#20102;&#19968;&#32452;&#20989;&#25968;&#29992;&#20110;&#20998;&#26512;&#24207;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#20854;&#20013;&#21253;&#21547;&#25552;&#21462;&#32479;&#35745;&#29305;&#24449;&#21644;&#25191;&#34892;&#25512;&#26029;&#20219;&#21153;&#65292;&#20197;&#21450;&#32858;&#31867;&#12289;&#20998;&#31867;&#25110;&#24322;&#24120;&#26816;&#27979;&#31561;&#24120;&#35268;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#12290;&#27492;&#22806;&#65292;&#35813;&#36719;&#20214;&#21253;&#36824;&#21253;&#21547;&#20004;&#20010;&#37329;&#34701;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#21644;&#19977;&#20010;&#21512;&#25104;&#25968;&#25454;&#24211;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
21&#19990;&#32426;&#35265;&#35777;&#20102;&#23545;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20998;&#26512;&#30340;&#19981;&#26029;&#20852;&#36259;&#12290;&#34429;&#28982;&#22823;&#37096;&#20998;&#25991;&#29486;&#37117;&#22788;&#29702;&#20102;&#23454;&#20540;&#26102;&#38388;&#24207;&#21015;&#30340;&#38382;&#39064;&#65292;&#20294;&#24207;&#26102;&#38388;&#24207;&#21015;&#36890;&#24120;&#21463;&#21040;&#30340;&#20851;&#27880;&#36739;&#23569;&#12290;&#28982;&#32780;&#65292;&#23545;&#21518;&#32773;&#30340;&#29305;&#23450;&#20998;&#26512;&#24037;&#20855;&#30340;&#21457;&#23637;&#36817;&#24180;&#26469;&#24050;&#32463;&#26174;&#33879;&#22686;&#21152;&#12290; R&#21253;otsfeatures&#26088;&#22312;&#25552;&#20379;&#19968;&#32452;&#31616;&#21333;&#30340;&#20989;&#25968;&#65292;&#29992;&#20110;&#20998;&#26512;&#24207;&#26102;&#38388;&#24207;&#21015;&#12290;&#29305;&#21035;&#22320;&#65292;&#25552;&#20379;&#20102;&#20960;&#20010;&#21629;&#20196;&#65292;&#20801;&#35768;&#29992;&#25143;&#25552;&#21462;&#19968;&#20123;&#24050;&#30693;&#30340;&#32479;&#35745;&#29305;&#24449;&#21644;&#25191;&#34892;&#25512;&#26029;&#20219;&#21153;&#12290;&#20960;&#20010;&#20989;&#25968;&#30340;&#36755;&#20986;&#21487;&#20197;&#29992;&#20110;&#25191;&#34892;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#21253;&#25324;&#32858;&#31867;&#65292;&#20998;&#31867;&#25110;&#24322;&#24120;&#26816;&#27979;&#12290;otsfeatures&#36824;&#21253;&#21547;&#20102;&#20004;&#20010;&#37329;&#34701;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#65292;&#36825;&#20123;&#25968;&#25454;&#38598;&#22312;&#25991;&#29486;&#20013;&#29992;&#20110;&#32858;&#31867;&#30446;&#30340;&#65292;&#20197;&#21450;&#19977;&#20010;&#26377;&#36259;&#30340;&#21512;&#25104;&#25968;&#25454;&#24211;&#12290;&#25551;&#36848;&#20102;&#35813;&#36719;&#20214;&#21253;&#30340;&#20027;&#35201;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The 21st century has witnessed a growing interest in the analysis of time series data. Whereas most of the literature on the topic deals with real-valued time series, ordinal time series have typically received much less attention. However, the development of specific analytical tools for the latter objects has substantially increased in recent years. The R package otsfeatures attempts to provide a set of simple functions for analyzing ordinal time series. In particular, several commands allowing the extraction of well-known statistical features and the execution of inferential tasks are available for the user. The output of several functions can be employed to perform traditional machine learning tasks including clustering, classification or outlier detection. otsfeatures also incorporates two datasets of financial time series which were used in the literature for clustering purposes, as well as three interesting synthetic databases. The main properties of the package are described an
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#25955;&#21709;&#24212;&#30340;&#24207;&#21015;&#27169;&#31946;&#32858;&#31867;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#36317;&#31163;&#24230;&#37327;&#65292;&#20854;&#20013;&#30340;&#31639;&#27861;&#20855;&#26377;&#39640;&#25928;&#24615;&#21644;&#20934;&#30830;&#24615;&#65292;&#24182;&#21487;&#22312;&#32463;&#27982;&#23398;&#39046;&#22495;&#33719;&#24471;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2304.12249</link><description>&lt;p&gt;
&#22522;&#20110;&#20004;&#20010;&#26032;&#36317;&#31163;&#30340;&#24207;&#21015;&#27169;&#31946;&#32858;&#31867;&#21450;&#20854;&#22312;&#32463;&#27982;&#23398;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Fuzzy clustering of ordinal time series based on two novel distances with economic applications. (arXiv:2304.12249v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12249
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#25955;&#21709;&#24212;&#30340;&#24207;&#21015;&#27169;&#31946;&#32858;&#31867;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#36317;&#31163;&#24230;&#37327;&#65292;&#20854;&#20013;&#30340;&#31639;&#27861;&#20855;&#26377;&#39640;&#25928;&#24615;&#21644;&#20934;&#30830;&#24615;&#65292;&#24182;&#21487;&#22312;&#32463;&#27982;&#23398;&#39046;&#22495;&#33719;&#24471;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#24207;&#21015;&#32858;&#31867;&#26159;&#19968;&#39033;&#26377;&#24191;&#27867;&#24212;&#29992;&#30340;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#12290;&#28982;&#32780;&#32477;&#22823;&#37096;&#20998;&#26041;&#27861;&#32858;&#28966;&#20110;&#36830;&#32493;&#22411;&#26102;&#38388;&#24207;&#21015;&#65292;&#21482;&#26377;&#26497;&#23569;&#25968;&#30740;&#31350;&#31163;&#25955;&#21709;&#24212;&#30340;&#24207;&#21015;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#24207;&#21015;&#27169;&#31946;&#32858;&#31867;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;&#20004;&#20010;&#26032;&#30340;&#24207;&#21015;&#36317;&#31163;&#24230;&#37327;&#65292;&#24182;&#29992;&#20854;&#26500;&#24314;&#27169;&#31946;&#32858;&#31867;&#31639;&#27861;&#12290;&#36825;&#20004;&#20010;&#36317;&#31163;&#24230;&#37327;&#22343;&#26159;&#20272;&#31639;&#30340;&#32047;&#31215;&#27010;&#29575;&#20989;&#25968;&#65292;&#20174;&#32780;&#33258;&#21160;&#21033;&#29992;&#20102;&#24207;&#21015;&#33539;&#22260;&#30340;&#25490;&#24207;&#20248;&#21183;&#12290;&#31639;&#27861;&#20855;&#26377;&#39640;&#25928;&#24615;&#65292;&#24182;&#33021;&#22815;&#20934;&#30830;&#23558;&#26469;&#33258;&#21508;&#31181;&#27169;&#22411;&#30340;&#30456;&#20284;&#38543;&#26426;&#36807;&#31243;&#24207;&#21015;&#20998;&#32452;&#12290;&#30001;&#20110;&#24207;&#21015;&#21160;&#24577;&#21487;&#33021;&#38543;&#26102;&#38388;&#21464;&#21270;&#65292;&#26412;&#25991;&#37319;&#29992;&#20102;&#27169;&#31946;&#26041;&#27861;&#65292;&#20351;&#24471;&#31639;&#27861;&#21487;&#20197;&#22312;&#19981;&#21516;&#25104;&#21592;&#24230;&#25968;&#30340;&#20960;&#20010;&#31867;&#21035;&#20013;&#23450;&#20301;&#27599;&#20010;&#24207;&#21015;&#12290;&#26412;&#25991;&#36824;&#25552;&#20379;&#20102;&#22823;&#37327;&#30340;&#20223;&#30495;&#23454;&#39564;&#20197;&#21450;&#22312;&#32463;&#27982;&#23398;&#20013;&#36816;&#29992;&#30340;&#26696;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
Time series clustering is a central machine learning task with applications in many fields. While the majority of the methods focus on real-valued time series, very few works consider series with discrete response. In this paper, the problem of clustering ordinal time series is addressed. To this aim, two novel distances between ordinal time series are introduced and used to construct fuzzy clustering procedures. Both metrics are functions of the estimated cumulative probabilities, thus automatically taking advantage of the ordering inherent to the series' range. The resulting clustering algorithms are computationally efficient and able to group series generated from similar stochastic processes, reaching accurate results even though the series come from a wide variety of models. Since the dynamic of the series may vary over the time, we adopt a fuzzy approach, thus enabling the procedures to locate each series into several clusters with different membership degrees. An extensive simul
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20351;&#29992;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#36890;&#29992;&#36924;&#36817;&#22120;&#20026;&#26500;&#24314;&#22359;&#65292;&#26500;&#24314;&#20102;&#22312;&#20219;&#24847;&#27874;&#20848;&#24230;&#37327;&#31354;&#38388; $\mathcal{X}$ &#21644; $\mathcal{Y}$ &#20043;&#38388;&#30340;&#36890;&#29992;&#36924;&#36817;&#22120;&#65292;&#24182;&#36890;&#36807;&#38543;&#26426;&#21270;&#36755;&#20986;&#31163;&#25955;&#27010;&#29575;&#27979;&#24230;&#26469;&#20811;&#26381;&#26576;&#20123;&#38480;&#21046;&#12290;&#22312;&#36866;&#24403;&#30340;&#32467;&#26500;&#19979;&#25552;&#20379;&#20102;&#27010;&#29575;&#21644;&#23450;&#37327;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2304.12231</link><description>&lt;p&gt;
&#19968;&#31181;&#36716;&#31227;&#21407;&#29702;&#65306;&#20174;&#27431;&#20960;&#37324;&#24471;&#36890;&#29992;&#36924;&#36817;&#22120;&#21040;&#24230;&#37327;&#31354;&#38388;&#20043;&#38388;&#30340;&#36890;&#29992;&#36924;&#36817;&#22120;
&lt;/p&gt;
&lt;p&gt;
A Transfer Principle: Universal Approximators Between Metric Spaces From Euclidean Universal Approximators. (arXiv:2304.12231v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12231
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20351;&#29992;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#36890;&#29992;&#36924;&#36817;&#22120;&#20026;&#26500;&#24314;&#22359;&#65292;&#26500;&#24314;&#20102;&#22312;&#20219;&#24847;&#27874;&#20848;&#24230;&#37327;&#31354;&#38388; $\mathcal{X}$ &#21644; $\mathcal{Y}$ &#20043;&#38388;&#30340;&#36890;&#29992;&#36924;&#36817;&#22120;&#65292;&#24182;&#36890;&#36807;&#38543;&#26426;&#21270;&#36755;&#20986;&#31163;&#25955;&#27010;&#29575;&#27979;&#24230;&#26469;&#20811;&#26381;&#26576;&#20123;&#38480;&#21046;&#12290;&#22312;&#36866;&#24403;&#30340;&#32467;&#26500;&#19979;&#25552;&#20379;&#20102;&#27010;&#29575;&#21644;&#23450;&#37327;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20351;&#29992;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#36890;&#29992;&#36924;&#36817;&#22120;&#20316;&#20026;&#26500;&#24314;&#22359;&#65292;&#26500;&#24314;&#20102;&#36830;&#32493;&#26144;&#23556;&#30340;&#24230;&#37327;&#31354;&#38388;&#20043;&#38388;&#30340;&#36890;&#29992;&#36924;&#36817;&#22120;&#12290;&#26089;&#26399;&#32467;&#26524;&#20551;&#23450;&#36755;&#20986;&#31354;&#38388; $\mathcal{Y}$ &#26159;&#25299;&#25169;&#21521;&#37327;&#31354;&#38388;&#12290;&#25105;&#20204;&#36890;&#36807;&#8220;&#38543;&#26426;&#21270;&#8221;&#26469;&#20811;&#26381;&#36825;&#31181;&#38480;&#21046;&#65306;&#25105;&#20204;&#30340;&#36924;&#36817;&#22120;&#36755;&#20986; $\mathcal{Y}$ &#19978;&#30340;&#31163;&#25955;&#27010;&#29575;&#27979;&#24230;&#12290;&#24403; $\mathcal{X}$ &#21644; $\mathcal{Y}$ &#27809;&#26377;&#38468;&#21152;&#32467;&#26500;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#38750;&#24120;&#36890;&#29992;&#30340;&#23450;&#24615;&#20445;&#35777;&#65307;&#24403;&#23427;&#20204;&#20855;&#26377;&#36866;&#24403;&#30340;&#32452;&#21512;&#32467;&#26500;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102; H\"older &#31867;&#26144;&#23556;&#30340;&#23450;&#37327;&#20445;&#35777;&#65292;&#21253;&#25324;&#26377;&#38480;&#22270;&#20043;&#38388;&#30340;&#26144;&#23556;&#65292;&#22312;&#26576;&#20123; Carnot &#32676;&#20043;&#38388;&#30340;&#31895;&#24494;&#20998;&#26041;&#31243;&#30340;&#35299;&#31639;&#23376;&#20197;&#21450;&#21453;&#38382;&#39064;&#20013;&#20986;&#29616;&#30340; Banach &#31354;&#38388;&#20043;&#38388;&#30340;&#36830;&#32493;&#38750;&#32447;&#24615;&#31639;&#23376;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#38656;&#30340; Dirac &#27979;&#24230;&#25968;&#37327;&#30001; $\mathcal{X}$ &#21644; $\mathcal{Y}$ &#30340;&#32452;&#21512;&#32467;&#26500;&#20915;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
We build universal approximators of continuous maps between arbitrary Polish metric spaces $\mathcal{X}$ and $\mathcal{Y}$ using universal approximators between Euclidean spaces as building blocks. Earlier results assume that the output space $\mathcal{Y}$ is a topological vector space. We overcome this limitation by "randomization": our approximators output discrete probability measures over $\mathcal{Y}$. When $\mathcal{X}$ and $\mathcal{Y}$ are Polish without additional structure, we prove very general qualitative guarantees; when they have suitable combinatorial structure, we prove quantitative guarantees for H\"older-like maps, including maps between finite graphs, solution operators to rough differential equations between certain Carnot groups, and continuous non-linear operators between Banach spaces arising in inverse problems. In particular, we show that the required number of Dirac measures is determined by the combinatorial structure of $\mathcal{X}$ and $\mathcal{Y}$. For b
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#30740;&#31350;&#20102;&#32852;&#37030;&#23398;&#20064;&#29615;&#22659;&#19979;&#30340;&#32479;&#35745;&#23398;&#20064;&#27169;&#22411;&#27867;&#21270;&#35823;&#24046;&#65292;&#34920;&#26126;&#26356;&#39057;&#32321;&#22320;&#19982;&#21442;&#25968;&#26381;&#21153;&#22120;&#36890;&#20449;&#20250;&#36127;&#38754;&#24433;&#21709;&#27492;&#31867;&#23398;&#20064;&#31639;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.12216</link><description>&lt;p&gt;
&#26356;&#22810;&#36890;&#20449;&#19981;&#20250;&#20351;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#27867;&#21270;&#35823;&#24046;&#21464;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
More Communication Does Not Result in Smaller Generalization Error in Federated Learning. (arXiv:2304.12216v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12216
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#32852;&#37030;&#23398;&#20064;&#29615;&#22659;&#19979;&#30340;&#32479;&#35745;&#23398;&#20064;&#27169;&#22411;&#27867;&#21270;&#35823;&#24046;&#65292;&#34920;&#26126;&#26356;&#39057;&#32321;&#22320;&#19982;&#21442;&#25968;&#26381;&#21153;&#22120;&#36890;&#20449;&#20250;&#36127;&#38754;&#24433;&#21709;&#27492;&#31867;&#23398;&#20064;&#31639;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#29615;&#22659;&#19979;&#32479;&#35745;&#23398;&#20064;&#27169;&#22411;&#30340;&#27867;&#21270;&#35823;&#24046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#26377;$K$&#20010;&#35774;&#22791;&#25110;&#23458;&#25143;&#31471;&#65292;&#27599;&#20010;&#35774;&#22791;&#25345;&#26377;&#19968;&#20010;&#22823;&#23567;&#20026;$n$&#30340;&#29420;&#31435;&#25968;&#25454;&#38598;&#12290;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26412;&#22320;&#23398;&#20064;&#30340;&#20010;&#20307;&#27169;&#22411;&#36890;&#36807;&#19968;&#20010;&#20013;&#22830;&#26381;&#21153;&#22120;&#36827;&#34892;&#32858;&#21512;&#65288;&#24179;&#22343;&#65289;&#65292;&#28982;&#21518;&#21457;&#36865;&#22238;&#35774;&#22791;&#12290;&#25105;&#20204;&#32771;&#34385;&#22810;&#27425;&#65288;&#27604;&#22914;&#35828;$R\in \mathbb{N}^*$&#65289;&#27169;&#22411;&#32858;&#21512;&#24182;&#30740;&#31350;$R$&#23545;&#26368;&#32456;&#32858;&#21512;&#27169;&#22411;&#30340;&#27867;&#21270;&#35823;&#24046;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#19978;&#30028;&#65292;&#26126;&#30830;&#32771;&#34385;&#20102;$R$&#65288;&#38500;&#20102;&#21442;&#19982;&#35774;&#22791;&#30340;&#25968;&#37327;$K$&#21644;&#25968;&#25454;&#38598;&#22823;&#23567;$n$&#65289;&#30340;&#24433;&#21709;&#12290;&#35266;&#23519;&#21040;&#23545;&#20110;&#22266;&#23450;&#30340;$(n,K)$&#65292;&#19978;&#30028;&#38543;$R$&#30340;&#22686;&#21152;&#32780;&#22686;&#21152;&#65292;&#36825;&#34920;&#26126;&#26356;&#39057;&#32321;&#22320;&#19982;&#21442;&#25968;&#26381;&#21153;&#22120;&#36890;&#20449;&#20250;&#36127;&#38754;&#24433;&#21709;&#27492;&#31867;&#23398;&#20064;&#31639;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#30001;&#20110;&#32463;&#39564;&#39118;&#38505;&#36890;&#24120;&#21482;&#38543;&#30528;$n$&#30340;&#22686;&#21152;&#32780;&#20943;&#23569;&#65292;&#22240;&#27492;&#25105;&#20204;&#30340;&#29702;&#35770;&#35777;&#26126;&#20102;&#20026;&#20102;&#22312;FL&#20013;&#23454;&#29616;&#33391;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#38656;&#35201;&#26435;&#34913;&#26412;&#22320;&#23398;&#20064;&#21644;&#20840;&#23616;&#32858;&#21512;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the generalization error of statistical learning models in a Federated Learning (FL) setting. Specifically, there are $K$ devices or clients, each holding an independent own dataset of size $n$. Individual models, learned locally via Stochastic Gradient Descent, are aggregated (averaged) by a central server into a global model and then sent back to the devices. We consider multiple (say $R \in \mathbb N^*$) rounds of model aggregation and study the effect of $R$ on the generalization error of the final aggregated model. We establish an upper bound on the generalization error that accounts explicitly for the effect of $R$ (in addition to the number of participating devices $K$ and dataset size $n$). It is observed that, for fixed $(n, K)$, the bound increases with $R$, suggesting that the generalization of such learning algorithms is negatively affected by more frequent communication with the parameter server. Combined with the fact that the empirical risk, however, generally d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#23545;&#26465;&#20214;&#25968;&#25454;&#20998;&#24067;&#36827;&#34892;&#24314;&#27169;&#30340;&#21464;&#20998;&#25193;&#25955;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#65292;&#23427;&#36991;&#20813;&#20102;&#23545;&#21442;&#25968;&#24418;&#24335;&#20570;&#20986;&#24378;&#28872;&#20551;&#35774;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#29983;&#25104;&#22270;&#20687;&#30340;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2304.12141</link><description>&lt;p&gt;
&#21464;&#20998;&#25193;&#25955;&#33258;&#32534;&#30721;&#22120;&#65306;&#20855;&#26377;&#26080;&#26465;&#20214;&#25193;&#25955;&#20808;&#39564;&#30340;&#28145;&#23618;&#28508;&#21464;&#37327;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Variational Diffusion Auto-encoder: Deep Latent Variable Model with Unconditional Diffusion Prior. (arXiv:2304.12141v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12141
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#23545;&#26465;&#20214;&#25968;&#25454;&#20998;&#24067;&#36827;&#34892;&#24314;&#27169;&#30340;&#21464;&#20998;&#25193;&#25955;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#65292;&#23427;&#36991;&#20813;&#20102;&#23545;&#21442;&#25968;&#24418;&#24335;&#20570;&#20986;&#24378;&#28872;&#20551;&#35774;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#29983;&#25104;&#22270;&#20687;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#26159;&#28145;&#24230;&#29983;&#25104;&#24314;&#27169;&#30340;&#19968;&#31181;&#26368;&#27969;&#34892;&#30340;&#26041;&#27861;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#22240;&#20026;&#39640;&#24230;&#19981;&#29616;&#23454;&#30340;&#24314;&#27169;&#20551;&#35774;&#65292;&#21363;&#26465;&#20214;&#25968;&#25454;&#20998;&#24067;p(x|z)&#21487;&#20197;&#36817;&#20284;&#20026;&#21508;&#21521;&#21516;&#24615;&#39640;&#26031;&#20998;&#24067;&#65292;&#25152;&#20197;&#30001;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#29983;&#25104;&#30340;&#22270;&#20687;&#26159;&#27169;&#31946;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#23545;&#26465;&#20214;&#25968;&#25454;&#20998;&#24067;p(x|z)&#36827;&#34892;&#24314;&#27169;&#30340;&#21407;&#21017;&#24615;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#21487;&#20197;&#21019;&#24314;&#31867;&#20284;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#28145;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#32780;&#26080;&#38656;&#23545;p(x|z)&#20570;&#39640;&#26031;&#20551;&#35774;&#65292;&#29978;&#33267;&#19981;&#38656;&#35201;&#35757;&#32451;&#35299;&#30721;&#22120;&#32593;&#32476;&#12290;&#36890;&#36807;Bayes'&#35268;&#21017;&#65292;&#21487;&#20197;&#23558;&#32463;&#36807;&#35757;&#32451;&#30340;&#32534;&#30721;&#22120;&#21644;&#26080;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#32452;&#21512;&#21040;&#19968;&#36215;&#65292;&#20197;&#33719;&#24471;&#19968;&#20010;&#34920;&#36798;&#20016;&#23500;&#30340;p(x|z)&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36991;&#20813;&#20102;&#23545;&#21442;&#25968;&#24418;&#24335;p(x|z)&#20570;&#20986;&#24378;&#28872;&#20551;&#35774;&#65292;&#22240;&#27492;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#29983;&#25104;&#22270;&#20687;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational auto-encoders (VAEs) are one of the most popular approaches to deep generative modeling. Despite their success, images generated by VAEs are known to suffer from blurriness, due to a highly unrealistic modeling assumption that the conditional data distribution $ p(\textbf{x} | \textbf{z})$ can be approximated as an isotropic Gaussian. In this work we introduce a principled approach to modeling the conditional data distribution $p(\textbf{x} | \textbf{z})$ by incorporating a diffusion model. We show that it is possible to create a VAE-like deep latent variable model without making the Gaussian assumption on $ p(\textbf{x} | \textbf{z}) $ or even training a decoder network. A trained encoder and an unconditional diffusion model can be combined via Bayes' rule for score functions to obtain an expressive model for $ p(\textbf{x} | \textbf{z}) $. Our approach avoids making strong assumptions on the parametric form of $ p(\textbf{x} | \textbf{z}) $, and thus allows to significant
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22312;&#19981;&#38656;&#35201;&#26356;&#24378;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#65292;&#21363;&#20351;&#22312;&#21327;&#21464;&#37327;&#26469;&#33258; $L$-&#20122;&#25351;&#25968;&#38543;&#26426;&#21521;&#37327;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;$\ell_1$ -&#24085;&#20271;&#22238;&#24402;&#36827;&#34892;&#32447;&#24615;&#22238;&#24402;&#65292;&#21487;&#20197;&#24471;&#21040;&#19982;&#39640;&#26031;&#38543;&#26426;&#21521;&#37327;&#30456;&#21516;&#65288;&#22312;&#24120;&#25968;&#22240;&#23376;&#19979;&#65289;&#30340;&#35823;&#24046;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2304.11958</link><description>&lt;p&gt;
&#22312; $L$-&#20122;&#25351;&#25968;&#21327;&#21464;&#37327;&#19979;&#30340;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#31995;&#25968;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Estimation of sparse linear regression coefficients under $L$-subexponential covariates. (arXiv:2304.11958v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11958
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22312;&#19981;&#38656;&#35201;&#26356;&#24378;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#65292;&#21363;&#20351;&#22312;&#21327;&#21464;&#37327;&#26469;&#33258; $L$-&#20122;&#25351;&#25968;&#38543;&#26426;&#21521;&#37327;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;$\ell_1$ -&#24085;&#20271;&#22238;&#24402;&#36827;&#34892;&#32447;&#24615;&#22238;&#24402;&#65292;&#21487;&#20197;&#24471;&#21040;&#19982;&#39640;&#26031;&#38543;&#26426;&#21521;&#37327;&#30456;&#21516;&#65288;&#22312;&#24120;&#25968;&#22240;&#23376;&#19979;&#65289;&#30340;&#35823;&#24046;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21327;&#21464;&#37327;&#26469;&#33258; $L$-&#20122;&#25351;&#25968;&#38543;&#26426;&#21521;&#37327;&#26102;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#22312;&#32447;&#24615;&#22238;&#24402;&#20013;&#20272;&#35745;&#31232;&#30095;&#31995;&#25968;&#30340;&#20219;&#21153;&#65292;&#35813;&#38543;&#26426;&#21521;&#37327;&#23646;&#20110;&#19968;&#31867;&#20855;&#26377;&#27604;&#39640;&#26031;&#38543;&#26426;&#21521;&#37327;&#26356;&#37325;&#30340;&#23614;&#24052;&#30340;&#20998;&#24067;&#12290;&#20197;&#21069;&#30340;&#24037;&#20316;&#36890;&#36807;&#20551;&#35774;&#21327;&#21464;&#37327;&#26469;&#33258; $L$-&#20122;&#25351;&#25968;&#38543;&#26426;&#21521;&#37327;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#24314;&#31435;&#20102;&#31867;&#20284;&#20110;&#23545;&#39640;&#26031;&#38543;&#26426;&#21521;&#37327;&#23548;&#20986;&#30340;&#35823;&#24046;&#30028;&#38480;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#20197;&#21069;&#30340;&#26041;&#27861;&#35201;&#27714;&#26356;&#24378;&#30340;&#26465;&#20214;&#65292;&#20197;&#23548;&#20986;&#19982;&#39640;&#26031;&#38543;&#26426;&#21521;&#37327;&#30456;&#21516;&#30340;&#35823;&#24046;&#30028;&#38480;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22312;&#19981;&#38656;&#35201;&#26356;&#24378;&#30340;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#25552;&#20986;&#20102;&#19982;&#39640;&#26031;&#38543;&#26426;&#21521;&#37327;&#30456;&#21516;&#65288;&#22312;&#24120;&#25968;&#22240;&#23376;&#19979;&#65289;&#65292;&#29978;&#33267;&#24403;&#21327;&#21464;&#37327;&#26469;&#33258; $L$-&#20122;&#25351;&#25968;&#38543;&#26426;&#21521;&#37327;&#26102;&#30340;&#35823;&#24046;&#30028;&#38480;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#21033;&#29992;&#20102; $\ell_1$-&#24085;&#20271;&#22238;&#24402;&#65292;&#35813;&#22238;&#24402;&#22240;&#20854;&#23545;&#37325;&#23614;&#38543;&#26426;&#22122;&#22768;&#30340;&#40065;&#26834;&#24615;&#32780;&#34987;&#35748;&#20026;&#26159;&#37325;&#35201;&#30340;&#65292;&#32780;&#19981;&#26159;&#21327;&#21464;&#37327;&#12290;&#25105;&#20204;&#30456;&#20449;...
&lt;/p&gt;
&lt;p&gt;
We address a task of estimating sparse coefficients in linear regression when the covariates are drawn from an $L$-subexponential random vector, which belongs to a class of distributions having heavier tails than a Gaussian random vector. Prior works have tackled this issue by assuming that the covariates are drawn from an $L$-subexponential random vector and have established error bounds that resemble those derived for Gaussian random vectors. However, these previous methods require stronger conditions to derive error bounds than those employed for Gaussian random vectors. In the present paper, we present an error bound identical to that obtained for Gaussian random vectors, up to constant factors, without requiring stronger conditions, even when the covariates are drawn from an $L$-subexponential random vector. Somewhat interestingly, we utilize an $\ell_1$-penalized Huber regression, that is recognized for its robustness to heavy-tailed random noises, not covariates. We believe that
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#23545;&#39640;&#39057;&#37329;&#34701;&#25968;&#25454;&#30340;Hawkes&#27169;&#22411;&#21442;&#25968;&#36827;&#34892;&#20272;&#35745;&#65292;&#24182;&#36890;&#36807;&#23454;&#26102;&#27874;&#21160;&#29575;&#27979;&#37327;&#36827;&#34892;&#24212;&#29992;&#12290;&#30456;&#36739;&#20110;&#20256;&#32479;&#26041;&#27861;&#65292;&#26412;&#26041;&#27861;&#20855;&#26377;&#26356;&#24555;&#30340;&#35745;&#31639;&#24615;&#33021;&#21644;&#21487;&#27604;&#36739;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.11883</link><description>&lt;p&gt;
&#22522;&#20110;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#30340;&#39640;&#39057;&#37329;&#34701;&#25968;&#25454;Hawkes&#27169;&#22411;&#21442;&#25968;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Recurrent neural network based parameter estimation of Hawkes model on high-frequency financial data. (arXiv:2304.11883v1 [q-fin.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11883
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#23545;&#39640;&#39057;&#37329;&#34701;&#25968;&#25454;&#30340;Hawkes&#27169;&#22411;&#21442;&#25968;&#36827;&#34892;&#20272;&#35745;&#65292;&#24182;&#36890;&#36807;&#23454;&#26102;&#27874;&#21160;&#29575;&#27979;&#37327;&#36827;&#34892;&#24212;&#29992;&#12290;&#30456;&#36739;&#20110;&#20256;&#32479;&#26041;&#27861;&#65292;&#26412;&#26041;&#27861;&#20855;&#26377;&#26356;&#24555;&#30340;&#35745;&#31639;&#24615;&#33021;&#21644;&#21487;&#27604;&#36739;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#21033;&#29992;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#23545;&#22522;&#20110;&#39640;&#39057;&#37329;&#34701;&#25968;&#25454;&#30340;Hawkes&#27169;&#22411;&#21442;&#25968;&#36827;&#34892;&#20272;&#35745;&#65292;&#24182;&#36890;&#36807;&#35745;&#31639;&#27874;&#21160;&#24615;&#26469;&#36827;&#34892;&#20998;&#26512;&#12290;&#31070;&#32463;&#32593;&#32476;&#22312;&#21508;&#20010;&#39046;&#22495;&#37117;&#23637;&#29616;&#20986;&#20102;&#33391;&#22909;&#30340;&#25928;&#26524;&#65292;&#22312;&#37329;&#34701;&#39046;&#22495;&#20013;&#30340;&#24212;&#29992;&#20063;&#27491;&#22312;&#22686;&#38271;&#12290;&#19982;&#20256;&#32479;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#27169;&#25311;&#21644;&#23454;&#35777;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#20102;&#21487;&#27604;&#36739;&#30340;&#20934;&#30830;&#24615;&#65292;&#21516;&#26102;&#20855;&#26377;&#26174;&#30528;&#26356;&#24555;&#30340;&#35745;&#31639;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#28436;&#31034;&#20102;&#35813;&#26041;&#27861;&#22312;&#23454;&#26102;&#27874;&#21160;&#29575;&#27979;&#37327;&#20013;&#30340;&#24212;&#29992;&#65292;&#21487;&#20197;&#25345;&#32493;&#22320;&#20272;&#35745;&#37329;&#34701;&#27874;&#21160;&#24615;&#65292;&#38543;&#30528;&#24066;&#22330;&#19978;&#20986;&#29616;&#26032;&#30340;&#20215;&#26684;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study examines the use of a recurrent neural network for estimating the parameters of a Hawkes model based on high-frequency financial data, and subsequently, for computing volatility. Neural networks have shown promising results in various fields, and interest in finance is also growing. Our approach demonstrates significantly faster computational performance compared to traditional maximum likelihood estimation methods while yielding comparable accuracy in both simulation and empirical studies. Furthermore, we demonstrate the application of this method for real-time volatility measurement, enabling the continuous estimation of financial volatility as new price data keeps coming from the market.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25506;&#31350;&#20102;&#23458;&#25143;&#22312;&#32852;&#31995;&#20013;&#24515;&#26080;&#22768;&#25918;&#24323;&#30340;&#29616;&#35937;&#65292;&#36890;&#36807;&#19981;&#30830;&#23450;&#25968;&#25454;&#20272;&#35745;&#23458;&#25143;&#31561;&#24453;&#30340;&#32784;&#24515;&#65292;&#25581;&#31034;&#20102;&#36825;&#31181;&#29616;&#35937;&#23545;&#20195;&#29702;&#20154;&#26102;&#38388;&#21644;&#33021;&#21147;&#30340;&#28010;&#36153;&#12290;</title><link>http://arxiv.org/abs/2304.11754</link><description>&lt;p&gt;
&#26080;&#22768;&#25918;&#24323;&#65306;&#22914;&#20309;&#20174;&#19981;&#30830;&#23450;&#25968;&#25454;&#20013;&#20272;&#35745;&#23458;&#25143;&#31561;&#24453;&#30340;&#32784;&#24515;
&lt;/p&gt;
&lt;p&gt;
Silent Abandonment in Contact Centers: Estimating Customer Patience from Uncertain Data. (arXiv:2304.11754v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11754
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25506;&#31350;&#20102;&#23458;&#25143;&#22312;&#32852;&#31995;&#20013;&#24515;&#26080;&#22768;&#25918;&#24323;&#30340;&#29616;&#35937;&#65292;&#36890;&#36807;&#19981;&#30830;&#23450;&#25968;&#25454;&#20272;&#35745;&#23458;&#25143;&#31561;&#24453;&#30340;&#32784;&#24515;&#65292;&#25581;&#31034;&#20102;&#36825;&#31181;&#29616;&#35937;&#23545;&#20195;&#29702;&#20154;&#26102;&#38388;&#21644;&#33021;&#21147;&#30340;&#28010;&#36153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#25552;&#39640;&#26381;&#21153;&#36136;&#37327;&#65292;&#20844;&#21496;&#20026;&#23458;&#25143;&#25552;&#20379;&#19982;&#20195;&#29702;&#20154;&#36827;&#34892;&#20132;&#20114;&#30340;&#26426;&#20250;&#65292;&#20854;&#20013;&#22823;&#37096;&#20998;&#20132;&#27969;&#26159;&#22522;&#20110;&#25991;&#26412;&#30340;&#12290;&#36825;&#24050;&#25104;&#20026;&#36817;&#24180;&#26469;&#23458;&#25143;&#19982;&#20844;&#21496;&#20132;&#27969;&#30340;&#26368;&#21463;&#27426;&#36814;&#30340;&#28192;&#36947;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#32852;&#31995;&#20013;&#24515;&#38754;&#20020;&#36816;&#33829;&#25361;&#25112;&#65292;&#22240;&#20026;&#23458;&#25143;&#20307;&#39564;&#30340;&#24120;&#35265;&#20195;&#29702;&#65292;&#20363;&#22914;&#26159;&#21542;&#30693;&#36947;&#23458;&#25143;&#24050;&#25918;&#24323;&#25490;&#38431;&#21644;&#20182;&#20204;&#31561;&#24453;&#26381;&#21153;&#30340;&#24847;&#24895;&#65288;&#32784;&#24515;&#65289;&#65292;&#21463;&#21040;&#20449;&#24687;&#19981;&#30830;&#23450;&#24615;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32858;&#28966;&#20110;&#20027;&#35201;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#30340;&#24433;&#21709;&#65306;&#23458;&#25143;&#30340;&#26080;&#22768;&#25918;&#24323;&#12290;&#36825;&#20123;&#23458;&#25143;&#22312;&#31561;&#24453;&#22238;&#31572;&#20182;&#20204;&#30340;&#26597;&#35810;&#26102;&#31163;&#24320;&#31995;&#32479;&#65292;&#20294;&#27809;&#26377;&#32473;&#20986;&#20219;&#20309;&#25351;&#31034;&#65292;&#20363;&#22914;&#20851;&#38381;&#20114;&#21160;&#30340;&#31227;&#21160;&#24212;&#29992;&#31243;&#24207;&#12290;&#22240;&#27492;&#65292;&#31995;&#32479;&#19981;&#30693;&#36947;&#20182;&#20204;&#24050;&#32463;&#31163;&#24320;&#65292;&#24182;&#28010;&#36153;&#20195;&#29702;&#20154;&#30340;&#26102;&#38388;&#21644;&#33021;&#21147;&#65292;&#30452;&#21040;&#24847;&#35782;&#21040;&#36825;&#19968;&#20107;&#23454;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#25918;&#24323;&#23458;&#25143;&#20013;&#30340;30&#65285;-67&#65285;&#25918;&#24323;&#26102;&#20250;&#37319;&#21462;&#26080;&#22768;&#25918;&#24323;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the quest to improve services, companies offer customers the opportunity to interact with agents through contact centers, where the communication is mainly text-based. This has become one of the favorite channels of communication with companies in recent years. However, contact centers face operational challenges, since the measurement of common proxies for customer experience, such as knowledge of whether customers have abandoned the queue and their willingness to wait for service (patience), are subject to information uncertainty. We focus this research on the impact of a main source of such uncertainty: silent abandonment by customers. These customers leave the system while waiting for a reply to their inquiry, but give no indication of doing so, such as closing the mobile app of the interaction. As a result, the system is unaware that they have left and waste agent time and capacity until this fact is realized. In this paper, we show that 30%-67% of the abandoning customers aban
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#24046;&#20998;&#38544;&#31169;&#21644;&#23545;&#25239;&#24615;&#24378;&#20581;&#24615;&#26465;&#20214;&#19979;&#30340;&#38543;&#26426;&#32447;&#24615;&#36172;&#21338;&#26426;&#31639;&#27861;&#65292;&#26159;&#39318;&#27425;&#25552;&#20379;&#36825;&#20004;&#20010;&#20445;&#25252;&#26465;&#20214;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.11741</link><description>&lt;p&gt;
&#24378;&#20581;&#19988;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#20445;&#25252;&#30340;&#38543;&#26426;&#32447;&#24615;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
Robust and differentially private stochastic linear bandits. (arXiv:2304.11741v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11741
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#24046;&#20998;&#38544;&#31169;&#21644;&#23545;&#25239;&#24615;&#24378;&#20581;&#24615;&#26465;&#20214;&#19979;&#30340;&#38543;&#26426;&#32447;&#24615;&#36172;&#21338;&#26426;&#31639;&#27861;&#65292;&#26159;&#39318;&#27425;&#25552;&#20379;&#36825;&#20004;&#20010;&#20445;&#25252;&#26465;&#20214;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#24046;&#20998;&#38544;&#31169;&#12289;&#24378;&#20581;&#24615;&#21644;&#25209;&#37327;&#35266;&#23519;&#36825;&#20123;&#38468;&#21152;&#26465;&#20214;&#19979;&#30340;&#38543;&#26426;&#32447;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#20551;&#35774;&#22312;&#27599;&#20010;&#25209;&#27425;&#20013;&#65292;&#23545;&#20110;&#35266;&#27979;&#21040;&#30340;&#22870;&#21169;&#65292;&#23545;&#25163;&#20250;&#38543;&#26426;&#36873;&#25321;&#20854;&#20013;&#30340;&#19968;&#20010;&#22266;&#23450;&#37096;&#20998;&#65292;&#24182;&#29992;&#20219;&#24847;&#25968;&#23383;&#26367;&#25442;&#12290;&#25105;&#20204;&#20197;&#23545;&#25968;&#25209;&#37327;&#26597;&#35810;&#20026;&#22522;&#30784;&#65292;&#20998;&#21035;&#22312;&#20004;&#31181;&#38544;&#31169;&#27169;&#22411;&#19979;&#25552;&#20986;&#20102;&#26377;&#24046;&#20998;&#38544;&#31169;&#20445;&#25252;&#21644;&#24378;&#20581;&#30340;&#33218;&#28040;&#38500;&#31639;&#27861;&#21464;&#20307;&#65292;&#24182;&#22312;&#20004;&#31181;&#24773;&#20917;&#19979;&#25552;&#20379;&#20102;&#36951;&#25022;&#30028;&#12290;&#22312;&#31532;&#19968;&#20010;&#27169;&#22411;&#20013;&#65292;&#27599;&#19968;&#36718;&#20013;&#30340;&#27599;&#20010;&#22870;&#21169;&#37117;&#30001;&#21487;&#33021;&#19981;&#21516;&#30340;&#23458;&#25143;&#25253;&#21578;&#65292;&#36825;&#24402;&#32467;&#20026;&#26631;&#20934;&#30340;&#26412;&#22320;&#24046;&#20998;&#38544;&#31169;&#12290;&#22312;&#31532;&#20108;&#20010;&#27169;&#22411;&#20013;&#65292;&#27599;&#20010;&#21160;&#20316;&#30001;&#19981;&#21516;&#30340;&#23458;&#25143;&#8220;&#25317;&#26377;&#8221;&#65292;&#36825;&#20123;&#23458;&#25143;&#21487;&#33021;&#20250;&#27719;&#24635;&#22810;&#20010;&#26597;&#35810;&#30340;&#22870;&#21169;&#65292;&#24182;&#23558;&#32858;&#21512;&#21709;&#24212;&#31169;&#26377;&#21270;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#26159;&#22312;&#38543;&#26426;&#32447;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#65292;&#39318;&#27425;&#21516;&#26102;&#25552;&#20379;&#24046;&#20998;&#38544;&#31169;&#21644;&#23545;&#25239;&#24615;&#24378;&#20581;&#24615;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the stochastic linear bandit problem under the additional requirements of differential privacy, robustness and batched observations. In particular, we assume an adversary randomly chooses a constant fraction of the observed rewards in each batch, replacing them with arbitrary numbers. We present differentially private and robust variants of the arm elimination algorithm using logarithmic batch queries under two privacy models and provide regret bounds in both settings. In the first model, every reward in each round is reported by a potentially different client, which reduces to standard local differential privacy (LDP). In the second model, every action is "owned" by a different client, who may aggregate the rewards over multiple queries and privatize the aggregate response instead. To the best of our knowledge, our algorithms are the first simultaneously providing differential privacy and adversarial robustness in the stochastic linear bandits problem.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#26032;&#30340;&#38543;&#26426;FW&#26377;&#38480;&#21644;&#26368;&#23567;&#21270;&#31639;&#27861;&#21464;&#20307;&#65292;&#36866;&#29992;&#20110;&#20984;&#20989;&#25968;&#21644;&#38750;&#20984;&#20989;&#25968;&#65292;&#19988;&#20855;&#26377;&#26368;&#20339;&#25910;&#25947;&#20445;&#35777;&#12290;&#21516;&#26102;&#20004;&#31181;&#26041;&#27861;&#19981;&#38656;&#35201;&#27704;&#20037;&#25910;&#38598;&#22823;&#25209;&#25968;&#25454;&#21644;&#20840;&#30830;&#23450;&#24615;&#26799;&#24230;&#12290;</title><link>http://arxiv.org/abs/2304.11737</link><description>&lt;p&gt;
Sarah Frank-Wolfe&#65306;&#20855;&#26377;&#26368;&#20339;&#36895;&#29575;&#21644;&#23454;&#29992;&#29305;&#28857;&#30340;&#32422;&#26463;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sarah Frank-Wolfe: Methods for Constrained Optimization with Best Rates and Practical Features. (arXiv:2304.11737v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11737
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#26032;&#30340;&#38543;&#26426;FW&#26377;&#38480;&#21644;&#26368;&#23567;&#21270;&#31639;&#27861;&#21464;&#20307;&#65292;&#36866;&#29992;&#20110;&#20984;&#20989;&#25968;&#21644;&#38750;&#20984;&#20989;&#25968;&#65292;&#19988;&#20855;&#26377;&#26368;&#20339;&#25910;&#25947;&#20445;&#35777;&#12290;&#21516;&#26102;&#20004;&#31181;&#26041;&#27861;&#19981;&#38656;&#35201;&#27704;&#20037;&#25910;&#38598;&#22823;&#25209;&#25968;&#25454;&#21644;&#20840;&#30830;&#23450;&#24615;&#26799;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Frank-Wolfe&#65288;FW&#65289;&#26041;&#27861;&#26159;&#35299;&#20915;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#20986;&#29616;&#30340;&#32467;&#26500;&#21270;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#30340;&#27969;&#34892;&#26041;&#27861;&#12290;&#36817;&#24180;&#26469;&#65292;&#21463;&#21040;&#22823;&#25968;&#25454;&#38598;&#30340;&#21551;&#21457;&#65292;FW&#30340;&#38543;&#26426;&#29256;&#26412;&#21464;&#24471;&#26356;&#21152;&#27969;&#34892;&#65292;&#22240;&#20026;&#35745;&#31639;&#20840;&#26799;&#24230;&#20195;&#20215;&#36807;&#39640;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#26032;&#30340;FW&#38543;&#26426;&#26377;&#38480;&#21644;&#26368;&#23567;&#21270;&#31639;&#27861;&#21464;&#20307;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#26082;&#36866;&#29992;&#20110;&#20984;&#20989;&#25968;&#21448;&#36866;&#29992;&#20110;&#38750;&#20984;&#20989;&#25968;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#23384;&#22312;&#27704;&#20037;&#25910;&#38598;&#22823;&#25209;&#25968;&#25454;&#30340;&#38382;&#39064;&#65292;&#36825;&#26159;&#35768;&#22810;&#25237;&#24433;&#26080;&#32422;&#26463;&#38543;&#26426;&#26041;&#27861;&#30340;&#20849;&#21516;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#31532;&#20108;&#31181;&#26041;&#27861;&#26082;&#19981;&#38656;&#35201;&#22823;&#25209;&#37327;&#30340;&#25968;&#25454;&#20063;&#19981;&#38656;&#35201;&#20840;&#30830;&#23450;&#24615;&#26799;&#24230;&#65292;&#36825;&#26159;&#35768;&#22810;&#26377;&#38480;&#21644;&#38382;&#39064;&#25216;&#26415;&#30340;&#20856;&#22411;&#24369;&#28857;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#26356;&#24555;&#25910;&#25947;&#36895;&#24230;&#22312;&#23454;&#36341;&#20013;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Frank-Wolfe (FW) method is a popular approach for solving optimization problems with structured constraints that arise in machine learning applications. In recent years, stochastic versions of FW have gained popularity, motivated by large datasets for which the computation of the full gradient is prohibitively expensive. In this paper, we present two new variants of the FW algorithms for stochastic finite-sum minimization. Our algorithms have the best convergence guarantees of existing stochastic FW approaches for both convex and non-convex objective functions. Our methods do not have the issue of permanently collecting large batches, which is common to many stochastic projection-free approaches. Moreover, our second approach does not require either large batches or full deterministic gradients, which is a typical weakness of many techniques for finite-sum problems. The faster theoretical rates of our approaches are confirmed experimentally.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;QXGBoost&#65292;&#23427;&#26159;&#23545;&#26497;&#31471;&#26799;&#24230;&#25552;&#21319;&#65288;XGBoost&#65289;&#30340;&#22686;&#24378;&#65292;&#37319;&#29992;&#20462;&#25913;&#21518;&#30340;&#20998;&#20301;&#25968;&#22238;&#24402;&#26041;&#27861;&#20272;&#35745;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.11732</link><description>&lt;p&gt;
&#20998;&#20301;&#25968;&#26497;&#31471;&#26799;&#24230;&#25552;&#21319;&#29992;&#20110;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Quantile Extreme Gradient Boosting for Uncertainty Quantification. (arXiv:2304.11732v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11732
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;QXGBoost&#65292;&#23427;&#26159;&#23545;&#26497;&#31471;&#26799;&#24230;&#25552;&#21319;&#65288;XGBoost&#65289;&#30340;&#22686;&#24378;&#65292;&#37319;&#29992;&#20462;&#25913;&#21518;&#30340;&#20998;&#20301;&#25968;&#22238;&#24402;&#26041;&#27861;&#20272;&#35745;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#38543;&#30528;&#25968;&#25454;&#30340;&#21487;&#29992;&#24615;&#12289;&#35268;&#27169;&#21644;&#22797;&#26434;&#24615;&#30340;&#22686;&#21152;&#65292;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#25216;&#26415;&#24050;&#32463;&#25104;&#20026;&#24314;&#27169;&#30340;&#28909;&#38376;&#26041;&#27861;&#12290;&#23558;ML&#27169;&#22411;&#24212;&#29992;&#20110;&#39044;&#27979;&#30340;&#32467;&#26524;&#32463;&#24120;&#34987;&#29992;&#20110;&#25512;&#29702;&#12289;&#20915;&#31574;&#21644;&#19979;&#28216;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;ML&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26159;&#19968;&#20010;&#33267;&#20851;&#37325;&#35201;&#20294;&#24120;&#24120;&#34987;&#24573;&#35270;&#30340;&#26041;&#38754;&#65292;&#23427;&#33021;&#22815;&#26174;&#33879;&#24433;&#21709;&#27169;&#22411;&#39044;&#27979;&#30340;&#20351;&#29992;&#21644;&#35299;&#37322;&#12290;&#26497;&#31471;&#26799;&#24230;&#25552;&#21319;&#65288;XGBoost&#65289;&#26159;&#26368;&#21463;&#27426;&#36814;&#30340;ML&#26041;&#27861;&#20043;&#19968;&#65292;&#22240;&#20026;&#23427;&#30340;&#23454;&#29616;&#31616;&#21333;&#12289;&#35745;&#31639;&#36895;&#24230;&#24555;&#12289;&#24207;&#21015;&#23398;&#20064;&#31561;&#21407;&#22240;&#65292;&#20854;&#39044;&#27979;&#30456;&#23545;&#20110;&#20854;&#20182;&#26041;&#27861;&#26469;&#35828;&#26356;&#20026;&#20934;&#30830;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#22914;XGBoost&#36825;&#26679;&#30340;ML&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#30830;&#23450;&#25216;&#26415;&#65292;&#20854;&#22312;&#19981;&#21516;&#24212;&#29992;&#22330;&#26223;&#20013;&#20173;&#28982;&#23384;&#22312;&#20105;&#35758;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;XGBoost&#30340;&#22686;&#24378;&#25514;&#26045;&#65292;&#37319;&#29992;&#20462;&#25913;&#21518;&#30340;&#20998;&#20301;&#25968;&#22238;&#24402;&#20316;&#20026;&#30446;&#26631;&#20989;&#25968;&#26469;&#20272;&#35745;&#19981;&#30830;&#23450;&#24615;&#65288;QXGBoost&#65289;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22312;&#20998;&#20301;&#25968;&#22238;&#24402;&#20013;&#24341;&#20837;&#20102;Huber&#33539;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
As the availability, size and complexity of data have increased in recent years, machine learning (ML) techniques have become popular for modeling. Predictions resulting from applying ML models are often used for inference, decision-making, and downstream applications. A crucial yet often overlooked aspect of ML is uncertainty quantification, which can significantly impact how predictions from models are used and interpreted.  Extreme Gradient Boosting (XGBoost) is one of the most popular ML methods given its simple implementation, fast computation, and sequential learning, which make its predictions highly accurate compared to other methods. However, techniques for uncertainty determination in ML models such as XGBoost have not yet been universally agreed among its varying applications. We propose enhancements to XGBoost whereby a modified quantile regression is used as the objective function to estimate uncertainty (QXGBoost). Specifically, we included the Huber norm in the quantile 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#20132;&#36890;&#32593;&#32476;&#30340;&#38543;&#26426;&#21333;&#20803;&#20256;&#36755;&#27169;&#22411;&#65292;&#36890;&#36807;&#20559;&#22909;&#20989;&#25968;&#21644;&#21487;&#25509;&#21463;&#35774;&#35745;&#26469;&#35780;&#20272;&#20132;&#36890;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;&#25968;&#20540;&#23454;&#29616;&#32467;&#21512;&#20102;&#27169;&#25311;&#12289;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#21644;&#38543;&#26426;&#25506;&#32034;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2304.11654</link><description>&lt;p&gt;
&#20132;&#36890;&#32593;&#32476;&#30340;&#38543;&#26426;&#21333;&#20803;&#20256;&#36755;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Stochastic Cell Transmission Models of Traffic Networks. (arXiv:2304.11654v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11654
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#20132;&#36890;&#32593;&#32476;&#30340;&#38543;&#26426;&#21333;&#20803;&#20256;&#36755;&#27169;&#22411;&#65292;&#36890;&#36807;&#20559;&#22909;&#20989;&#25968;&#21644;&#21487;&#25509;&#21463;&#35774;&#35745;&#26469;&#35780;&#20272;&#20132;&#36890;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;&#25968;&#20540;&#23454;&#29616;&#32467;&#21512;&#20102;&#27169;&#25311;&#12289;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#21644;&#38543;&#26426;&#25506;&#32034;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20026;&#19968;&#33324;&#20132;&#36890;&#32593;&#32476;&#24341;&#20837;&#20102;&#38543;&#26426;&#21333;&#20803;&#20256;&#36755;&#27169;&#22411;&#30340;&#20005;&#26684;&#26694;&#26550;&#12290;&#36890;&#36807;&#20559;&#22909;&#20989;&#25968;&#21644;&#21487;&#25509;&#21463;&#35774;&#35745;&#35780;&#20272;&#20132;&#36890;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;&#25968;&#20540;&#23454;&#29616;&#32467;&#21512;&#20102;&#27169;&#25311;&#12289;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#21644;&#38543;&#26426;&#25506;&#32034;&#36807;&#31243;&#12290;&#35813;&#26041;&#27861;&#22312;&#20004;&#20010;&#26696;&#20363;&#30740;&#31350;&#20013;&#24471;&#21040;&#20102;&#35828;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a rigorous framework for stochastic cell transmission models for general traffic networks. The performance of traffic systems is evaluated based on preference functionals and acceptable designs. The numerical implementation combines simulation, Gaussian process regression, and a stochastic exploration procedure. The approach is illustrated in two case studies.
&lt;/p&gt;</description></item><item><title>&#32858;&#21512;&#21464;&#37327;&#19978;&#30340;&#22240;&#26524;&#24615;&#19981;&#30830;&#23450;&#24615;&#21487;&#33021;&#20250;&#20351;&#24471;&#21407;&#26412;&#19981;&#28151;&#28102;&#30340;&#22240;&#26524;&#20851;&#31995;&#21464;&#24471;&#28151;&#28102;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#38656;&#35201;&#25509;&#21463;&#23439;&#35266;&#22240;&#26524;&#20851;&#31995;&#36890;&#24120;&#21482;&#19982;&#24494;&#35266;&#29366;&#24577;&#30456;&#20851;&#30340;&#20107;&#23454;&#12290;</title><link>http://arxiv.org/abs/2304.11625</link><description>&lt;p&gt;
&#26377;&#24847;&#20041;&#30340;&#22240;&#26524;&#32858;&#21512;&#21644;&#24726;&#35770;&#24615;&#28151;&#28102;
&lt;/p&gt;
&lt;p&gt;
Meaningful Causal Aggregation and Paradoxical Confounding. (arXiv:2304.11625v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11625
&lt;/p&gt;
&lt;p&gt;
&#32858;&#21512;&#21464;&#37327;&#19978;&#30340;&#22240;&#26524;&#24615;&#19981;&#30830;&#23450;&#24615;&#21487;&#33021;&#20250;&#20351;&#24471;&#21407;&#26412;&#19981;&#28151;&#28102;&#30340;&#22240;&#26524;&#20851;&#31995;&#21464;&#24471;&#28151;&#28102;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#38656;&#35201;&#25509;&#21463;&#23439;&#35266;&#22240;&#26524;&#20851;&#31995;&#36890;&#24120;&#21482;&#19982;&#24494;&#35266;&#29366;&#24577;&#30456;&#20851;&#30340;&#20107;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32858;&#21512;&#21464;&#37327;&#20013;&#65292;&#24178;&#39044;&#30340;&#24433;&#21709;&#36890;&#24120;&#26159;&#19981;&#30830;&#23450;&#30340;&#65292;&#22240;&#20026;&#30456;&#21516;&#30340;&#23439;&#35266;&#24178;&#39044;&#30340;&#19981;&#21516;&#24494;&#35266;&#23454;&#29616;&#21487;&#33021;&#20250;&#23548;&#33268;&#19979;&#28216;&#23439;&#35266;&#21464;&#37327;&#30340;&#19981;&#21516;&#21464;&#21270;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#23545;&#20110;&#32858;&#21512;&#21464;&#37327;&#65292;&#22240;&#26524;&#24615;&#30340;&#19981;&#30830;&#23450;&#24615;&#21487;&#20197;&#20351;&#24471;&#21407;&#26412;&#19981;&#28151;&#28102;&#30340;&#22240;&#26524;&#20851;&#31995;&#21464;&#24471;&#28151;&#28102;&#65292;&#24182;&#19988;&#21453;&#20043;&#20134;&#28982;&#65292;&#36825;&#19968;&#28857;&#21462;&#20915;&#20110;&#30456;&#24212;&#30340;&#24494;&#35266;&#23454;&#29616;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#21482;&#26377;&#22312;&#32858;&#21512;&#22240;&#26524;&#31995;&#32479;&#27809;&#26377;&#36825;&#31181;&#19981;&#30830;&#23450;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25165;&#21487;&#20197;&#23454;&#38469;&#24212;&#29992;&#36825;&#31181;&#26041;&#27861;&#12290;&#21542;&#21017;&#65292;&#25105;&#20204;&#38656;&#35201;&#25509;&#21463;&#19968;&#28857;&#65292;&#23601;&#26159;&#23439;&#35266;&#22240;&#26524;&#20851;&#31995;&#36890;&#24120;&#21482;&#19982;&#24494;&#35266;&#29366;&#24577;&#30456;&#20851;&#12290;&#22312;&#31215;&#26497;&#26041;&#38754;&#65292;&#25105;&#20204;&#34920;&#26126;&#24403;&#23439;&#35266;&#24178;&#39044;&#30340;&#20998;&#24067;&#19982;&#35266;&#27979;&#20998;&#24067;&#20013;&#24494;&#35266;&#29366;&#24577;&#30340;&#20998;&#24067;&#30456;&#21516;&#26102;&#65292;&#22240;&#26524;&#20851;&#31995;&#21487;&#20197;&#36827;&#34892;&#32858;&#21512;&#65292;&#24182;&#35752;&#35770;&#20102;&#27492;&#35266;&#23519;&#30340;&#27010;&#25324;&#12290;
&lt;/p&gt;
&lt;p&gt;
In aggregated variables the impact of interventions is typically ill-defined because different micro-realizations of the same macro-intervention can result in different changes of downstream macro-variables. We show that this ill-definedness of causality on aggregated variables can turn unconfounded causal relations into confounded ones and vice versa, depending on the respective micro-realization. We argue that it is practically infeasible to only use aggregated causal systems when we are free from this ill-definedness. Instead, we need to accept that macro causal relations are typically defined only with reference to the micro states. On the positive side, we show that cause-effect relations can be aggregated when the macro interventions are such that the distribution of micro states is the same as in the observational distribution and also discuss generalizations of this observation.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;BAxUS&#65292;&#36890;&#36807;&#21033;&#29992;&#23884;&#22871;&#23376;&#31354;&#38388;&#26469;&#36991;&#20813;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#39118;&#38505;&#24182;&#30830;&#20445;&#39640;&#24615;&#33021;&#65292;&#30456;&#23545;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#22312;&#24191;&#27867;&#24212;&#29992;&#20013;&#21462;&#24471;&#26356;&#22909;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.11468</link><description>&lt;p&gt;
&#23398;&#20064;&#26102;&#25193;&#22823;&#33539;&#22260;&#65306;&#23884;&#22871;&#23376;&#31354;&#38388;&#20013;&#30340;&#33258;&#36866;&#24212;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Increasing the Scope as You Learn: Adaptive Bayesian Optimization in Nested Subspaces. (arXiv:2304.11468v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11468
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;BAxUS&#65292;&#36890;&#36807;&#21033;&#29992;&#23884;&#22871;&#23376;&#31354;&#38388;&#26469;&#36991;&#20813;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#39118;&#38505;&#24182;&#30830;&#20445;&#39640;&#24615;&#33021;&#65292;&#30456;&#23545;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#22312;&#24191;&#27867;&#24212;&#29992;&#20013;&#21462;&#24471;&#26356;&#22909;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#36827;&#23637;&#23558;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#30340;&#33539;&#22260;&#25193;&#23637;&#21040;&#20102;&#20855;&#26377;&#20960;&#21313;&#20010;&#32500;&#24230;&#30340;&#26114;&#36149;&#40657;&#30418;&#20989;&#25968;&#65292;&#24182;&#28212;&#26395;&#22312;&#29983;&#21629;&#31185;&#23398;&#12289;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#21644;&#26426;&#22120;&#20154;&#31561;&#39046;&#22495;&#23454;&#29616;&#37325;&#22823;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#23545;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;HDBO&#65289;&#30340;&#29616;&#26377;&#26041;&#27861;&#30340;&#26356;&#28145;&#20837;&#30740;&#31350;&#34920;&#26126;&#65292;&#38543;&#30528;&#32500;&#24230;&#25968;&#37327;&#30340;&#22686;&#21152;&#65292;&#24615;&#33021;&#20250;&#38477;&#20302;&#65292;&#29978;&#33267;&#26377;&#22833;&#36133;&#39118;&#38505;&#65292;&#22914;&#26524;&#19981;&#28385;&#36275;&#26576;&#20123;&#26080;&#27861;&#39564;&#35777;&#30340;&#20551;&#35774;&#12290;&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;BAxUS&#65292;&#23427;&#21033;&#29992;&#19968;&#26063;&#26032;&#39062;&#30340;&#23884;&#22871;&#38543;&#26426;&#23376;&#31354;&#38388;&#26469;&#20351;&#20854;&#20248;&#21270;&#30340;&#31354;&#38388;&#36866;&#24212;&#38382;&#39064;&#12290;&#36825;&#30830;&#20445;&#20102;&#39640;&#24615;&#33021;&#65292;&#21516;&#26102;&#36890;&#36807;&#29702;&#35770;&#20445;&#35777;&#28040;&#38500;&#20102;&#22833;&#36133;&#30340;&#39118;&#38505;&#12290;&#20840;&#38754;&#35780;&#20272;&#34920;&#26126;&#65292;&#23545;&#20110;&#24191;&#27867;&#30340;&#24212;&#29992;&#65292;BAxUS&#27604;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advances have extended the scope of Bayesian optimization (BO) to expensive-to-evaluate black-box functions with dozens of dimensions, aspiring to unlock impactful applications, for example, in the life sciences, neural architecture search, and robotics. However, a closer examination reveals that the state-of-the-art methods for high-dimensional Bayesian optimization (HDBO) suffer from degrading performance as the number of dimensions increases or even risk failure if certain unverifiable assumptions are not met. This paper proposes BAxUS that leverages a novel family of nested random subspaces to adapt the space it optimizes over to the problem. This ensures high performance while removing the risk of failure, which we assert via theoretical guarantees. A comprehensive evaluation demonstrates that BAxUS achieves better results than the state-of-the-art methods for a broad set of applications.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#21457;&#29616;&#65292;ERM&#26412;&#36136;&#19978;&#21516;&#26102;&#23398;&#20064;&#20102;&#20855;&#26377;&#35823;&#23548;&#24615;&#30340;&#29305;&#24449;&#21644;&#19981;&#21464;&#29305;&#24449;&#65292;&#22312;ERM&#39044;&#35757;&#32451;&#26399;&#38388;&#23398;&#20064;&#21040;&#30340;&#29305;&#24449;&#36136;&#37327;&#24433;&#21709;&#20102;&#26368;&#32456;&#30340;OOD&#24615;&#33021;&#65292;&#26410;&#33021;&#25429;&#33719;&#25152;&#26377;&#28508;&#22312;&#30340;&#26377;&#29992;&#29305;&#24449;&#23558;&#38480;&#21046;&#26368;&#32456;&#30340;OOD&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.11327</link><description>&lt;p&gt;
&#25506;&#32034;&#22806;&#37096;&#20998;&#24067;&#24191;&#20041;&#21270;&#20013;&#30340;&#29305;&#24449;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Towards Understanding Feature Learning in Out-of-Distribution Generalization. (arXiv:2304.11327v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11327
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#65292;ERM&#26412;&#36136;&#19978;&#21516;&#26102;&#23398;&#20064;&#20102;&#20855;&#26377;&#35823;&#23548;&#24615;&#30340;&#29305;&#24449;&#21644;&#19981;&#21464;&#29305;&#24449;&#65292;&#22312;ERM&#39044;&#35757;&#32451;&#26399;&#38388;&#23398;&#20064;&#21040;&#30340;&#29305;&#24449;&#36136;&#37327;&#24433;&#21709;&#20102;&#26368;&#32456;&#30340;OOD&#24615;&#33021;&#65292;&#26410;&#33021;&#25429;&#33719;&#25152;&#26377;&#28508;&#22312;&#30340;&#26377;&#29992;&#29305;&#24449;&#23558;&#38480;&#21046;&#26368;&#32456;&#30340;OOD&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#22806;&#37096;&#20998;&#24067;&#65288;OOD&#65289;&#24191;&#20041;&#21270;&#30340;&#22833;&#36133;&#65292;&#24120;&#35265;&#30340;&#35299;&#37322;&#26159;&#20351;&#29992;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;ERM&#65289;&#27169;&#22411;&#23398;&#20064;&#21040;&#20855;&#26377;&#35823;&#23548;&#24615;&#30340;&#29305;&#24449;&#32780;&#19981;&#26159;&#26399;&#26395;&#30340;&#19981;&#21464;&#29305;&#24449;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#20960;&#39033;&#30740;&#31350;&#25361;&#25112;&#20102;&#36825;&#31181;&#35299;&#37322;&#65292;&#21457;&#29616;&#28145;&#24230;&#32593;&#32476;&#21487;&#33021;&#24050;&#32463;&#23398;&#21040;&#20102;&#36275;&#22815;&#22909;&#30340;&#29305;&#24449;&#36827;&#34892;OOD&#24191;&#20041;&#21270;&#12290;&#36825;&#22330;&#36777;&#35770;&#25193;&#23637;&#21040;&#20102;&#35768;&#22810;OOD&#24191;&#20041;&#21270;&#20219;&#21153;&#30340;&#35757;&#32451;&#25110;&#24494;&#35843;&#31070;&#32463;&#32593;&#32476;&#30340;&#20869;&#37096;&#32452;&#32455;&#21644;OOD&#24615;&#33021;&#30456;&#20851;&#24615;&#20013;&#12290;&#20026;&#20102;&#29702;&#35299;&#36825;&#20123;&#20284;&#20046;&#30456;&#20114;&#30683;&#30462;&#30340;&#29616;&#35937;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#29702;&#35770;&#30740;&#31350;&#65292;&#21457;&#29616;ERM&#26412;&#36136;&#19978;&#21516;&#26102;&#23398;&#20064;&#20102;&#20855;&#26377;&#35823;&#23548;&#24615;&#30340;&#29305;&#24449;&#21644;&#19981;&#21464;&#29305;&#24449;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#22312;ERM&#39044;&#35757;&#32451;&#26399;&#38388;&#23398;&#20064;&#21040;&#30340;&#29305;&#24449;&#36136;&#37327;&#26174;&#33879;&#24433;&#21709;&#20102;&#26368;&#32456;&#30340;OOD&#24615;&#33021;&#65292;&#22240;&#20026;OOD&#23545;&#35937;&#24456;&#23569;&#23398;&#20064;&#21040;&#26032;&#21151;&#33021;&#12290;&#26410;&#33021;&#22312;&#39044;&#35757;&#32451;&#26399;&#38388;&#25429;&#33719;&#25152;&#26377;&#28508;&#22312;&#30340;&#26377;&#29992;&#29305;&#24449;&#23558;&#36827;&#19968;&#27493;&#38480;&#21046;&#26368;&#32456;&#30340;OOD&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
A common explanation for the failure of out-of-distribution (OOD) generalization is that the model trained with empirical risk minimization (ERM) learns spurious features instead of the desired invariant features. However, several recent studies challenged this explanation and found that deep networks may have already learned sufficiently good features for OOD generalization. The debate extends to the in-distribution and OOD performance correlations along with training or fine-tuning neural nets across a variety of OOD generalization tasks. To understand these seemingly contradicting phenomena, we conduct a theoretical investigation and find that ERM essentially learns both spurious features and invariant features. On the other hand, the quality of learned features during ERM pre-training significantly affects the final OOD performance, as OOD objectives rarely learn new features. Failing to capture all the underlying useful features during pre-training will further limit the final OOD
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#30340;&#24605;&#24819;&#26469;&#25913;&#36827;&#36125;&#21494;&#26031;&#35745;&#31639;&#30340;&#28508;&#21147;&#65292;&#24182;&#25506;&#35752;&#20102;&#20960;&#20010;&#20855;&#20307;&#30340;&#26410;&#26469;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2304.11251</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#19982;&#36125;&#21494;&#26031;&#35745;&#31639;&#30340;&#26410;&#26469;
&lt;/p&gt;
&lt;p&gt;
Machine Learning and the Future of Bayesian Computation. (arXiv:2304.11251v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11251
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#30340;&#24605;&#24819;&#26469;&#25913;&#36827;&#36125;&#21494;&#26031;&#35745;&#31639;&#30340;&#28508;&#21147;&#65292;&#24182;&#25506;&#35752;&#20102;&#20960;&#20010;&#20855;&#20307;&#30340;&#26410;&#26469;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#27169;&#22411;&#26159;&#30740;&#31350;&#22797;&#26434;&#25968;&#25454;&#30340;&#24378;&#22823;&#24037;&#20855;&#65292;&#20801;&#35768;&#20998;&#26512;&#20154;&#21592;&#32534;&#30721;&#20016;&#23500;&#30340;&#23618;&#27425;&#20381;&#36182;&#20851;&#31995;&#24182;&#21033;&#29992;&#20808;&#39564;&#20449;&#24687;&#12290;&#26368;&#37325;&#35201;&#30340;&#26159;&#65292;&#23427;&#20204;&#36890;&#36807;&#21518;&#39564;&#20998;&#24067;&#20419;&#36827;&#20102;&#23545;&#19981;&#30830;&#23450;&#24615;&#30340;&#23436;&#25972;&#34920;&#24449;&#12290;&#23454;&#29992;&#30340;&#21518;&#39564;&#35745;&#31639;&#36890;&#24120;&#36890;&#36807;MCMC&#36827;&#34892;&#65292;&#20294;&#23545;&#20110;&#20855;&#26377;&#35768;&#22810;&#35266;&#27979;&#20540;&#30340;&#39640;&#32500;&#27169;&#22411;&#32780;&#35328;&#65292;&#36825;&#21487;&#33021;&#35745;&#31639;&#19978;&#19981;&#21487;&#34892;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35752;&#35770;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#24605;&#24819;&#26469;&#25913;&#36827;&#21518;&#39564;&#35745;&#31639;&#30340;&#28508;&#21147;&#12290;&#20855;&#20307;&#30340;&#26410;&#26469;&#26041;&#21521;&#22312;&#27491;&#24577;&#27969;&#12289;&#36125;&#21494;&#26031;&#26680;&#24515;&#38598;&#12289;&#20998;&#24067;&#24335;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#21464;&#20998;&#25512;&#26029;&#30340;vignettes&#20013;&#24471;&#21040;&#25506;&#35752;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian models are a powerful tool for studying complex data, allowing the analyst to encode rich hierarchical dependencies and leverage prior information. Most importantly, they facilitate a complete characterization of uncertainty through the posterior distribution. Practical posterior computation is commonly performed via MCMC, which can be computationally infeasible for high dimensional models with many observations. In this article we discuss the potential to improve posterior computation using ideas from machine learning. Concrete future directions are explored in vignettes on normalizing flows, Bayesian coresets, distributed Bayesian inference, and variational inference.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#36890;&#29992;&#31639;&#27861;&#65292;&#21033;&#29992;&#23610;&#24230;&#25935;&#24863;&#30340;Vapnik&#32500;&#24230;&#26469;&#23398;&#20064;$[0,1]$&#20540;&#20989;&#25968;&#31867;&#65292;&#24182;&#33719;&#24471;&#20102;&#20851;&#20110;&#26399;&#26395;&#32477;&#23545;&#35823;&#24046;&#30340;&#19968;&#33324;&#19978;&#38480;&#12290;&#25991;&#20013;&#35777;&#26126;&#35813;&#19978;&#38480;&#19981;&#33021;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#36827;&#19968;&#27493;&#25913;&#21892;&#19968;&#20010;&#24120;&#25968;&#22240;&#23376;&#12290;&#36825;&#31687;&#35770;&#25991;&#23545;&#26080;&#20559;&#23398;&#20064;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#25552;&#39640;&#20855;&#26377;&#37325;&#35201;&#30340;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2304.11059</link><description>&lt;p&gt;
&#39044;&#27979;&#12289;&#23398;&#20064;&#12289;&#19968;&#33268;&#25910;&#25947;&#21644;&#23610;&#24230;&#25935;&#24863;&#32500;&#24230;
&lt;/p&gt;
&lt;p&gt;
Prediction, Learning, Uniform Convergence, and Scale-sensitive Dimensions. (arXiv:2304.11059v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11059
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#36890;&#29992;&#31639;&#27861;&#65292;&#21033;&#29992;&#23610;&#24230;&#25935;&#24863;&#30340;Vapnik&#32500;&#24230;&#26469;&#23398;&#20064;$[0,1]$&#20540;&#20989;&#25968;&#31867;&#65292;&#24182;&#33719;&#24471;&#20102;&#20851;&#20110;&#26399;&#26395;&#32477;&#23545;&#35823;&#24046;&#30340;&#19968;&#33324;&#19978;&#38480;&#12290;&#25991;&#20013;&#35777;&#26126;&#35813;&#19978;&#38480;&#19981;&#33021;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#36827;&#19968;&#27493;&#25913;&#21892;&#19968;&#20010;&#24120;&#25968;&#22240;&#23376;&#12290;&#36825;&#31687;&#35770;&#25991;&#23545;&#26080;&#20559;&#23398;&#20064;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#25552;&#39640;&#20855;&#26377;&#37325;&#35201;&#30340;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36890;&#29992;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#39044;&#27979;&#27169;&#22411;&#30340;&#25512;&#24191;&#20013;&#23398;&#20064;$[0,1]$&#20540;&#20989;&#25968;&#31867;&#65292;&#24182;&#35777;&#26126;&#20102;&#19968;&#33324;&#24615;&#30340;&#19978;&#38480;&#65292;&#35813;&#19978;&#38480;&#21453;&#26144;&#20102;&#30001;Alon&#12289;Ben-David&#12289;Cesa-Bianchi&#21644;Haussler&#25552;&#20986;&#30340;&#23610;&#24230;&#25935;&#24863;&#30340;Vapnik&#32500;&#24230;&#30340;&#25512;&#24191;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#19979;&#38480;&#65292;&#36825;&#34920;&#26126;&#25105;&#20204;&#30340;&#19978;&#38480;&#19981;&#33021;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#36827;&#19968;&#27493;&#25913;&#21892;&#19968;&#20010;&#24120;&#25968;&#22240;&#23376;&#12290;&#25105;&#20204;&#24212;&#29992;&#27492;&#32467;&#26524;&#21644;Haussler&#20197;&#21450;Benedek&#21644;Itai&#30340;&#25216;&#26415;&#65292;&#20197;&#21033;&#29992;&#36825;&#31181;&#23610;&#24230;&#25935;&#24863;&#30340;&#32500;&#24230;&#27010;&#24565;&#33719;&#24471;&#26032;&#30340;&#22635;&#20805;&#25968;&#19978;&#38480;&#12290;&#25105;&#20204;&#21033;&#29992;&#19981;&#21516;&#30340;&#25216;&#26415;&#65292;&#21033;&#29992;Kearns&#21644;Schapire&#30340;fat-shattering&#20989;&#25968;&#24471;&#21040;&#20102;&#26032;&#30340;&#22635;&#20805;&#25968;&#19978;&#38480;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#24212;&#29992;&#36825;&#20004;&#31181;&#22635;&#20805;&#19978;&#38480;&#26469;&#33719;&#24471;&#23545;&#26080;&#20559;&#23398;&#20064;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#25913;&#36827;&#19968;&#33324;&#24615;&#19978;&#38480;&#12290;&#23545;&#20110;&#27599;&#20010;$\epsilon &gt; 0$&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#31867;&#30340;&#36275;&#22815;&#26465;&#20214;&#21644;&#24517;&#35201;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a new general-purpose algorithm for learning classes of $[0,1]$-valued functions in a generalization of the prediction model, and prove a general upper bound on the expected absolute error of this algorithm in terms of a scale-sensitive generalization of the Vapnik dimension proposed by Alon, Ben-David, Cesa-Bianchi and Haussler. We give lower bounds implying that our upper bounds cannot be improved by more than a constant factor in general. We apply this result, together with techniques due to Haussler and to Benedek and Itai, to obtain new upper bounds on packing numbers in terms of this scale-sensitive notion of dimension. Using a different technique, we obtain new bounds on packing numbers in terms of Kearns and Schapire's fat-shattering function. We show how to apply both packing bounds to obtain improved general bounds on the sample complexity of agnostic learning. For each $\epsilon &gt; 0$, we establish weaker sufficient and stronger necessary conditions for a class of 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#37325;&#22797;&#37319;&#26679;&#30340;&#25919;&#31574;&#35780;&#20272;&#26041;&#27861;&#65292;&#20197;&#35780;&#20272;&#22312;&#32447; RL &#31639;&#27861;&#23454;&#29616;&#30340;&#20010;&#24615;&#21270;&#31243;&#24230;&#12290;&#35813;&#26041;&#27861;&#21487;&#29992;&#20110;&#20248;&#21270;&#25968;&#23383;&#20581;&#24247;&#30340;&#20010;&#24615;&#21270;&#24178;&#39044;&#12290;</title><link>http://arxiv.org/abs/2304.05365</link><description>&lt;p&gt;
&#25105;&#20204;&#23454;&#29616;&#20102;&#20010;&#24615;&#21270;&#27835;&#30103;&#21527;&#65311;&#20351;&#29992;&#37325;&#22797;&#37319;&#26679;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#20010;&#24615;&#21270;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Did we personalize? Assessing personalization by an online reinforcement learning algorithm using resampling. (arXiv:2304.05365v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05365
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#37325;&#22797;&#37319;&#26679;&#30340;&#25919;&#31574;&#35780;&#20272;&#26041;&#27861;&#65292;&#20197;&#35780;&#20272;&#22312;&#32447; RL &#31639;&#27861;&#23454;&#29616;&#30340;&#20010;&#24615;&#21270;&#31243;&#24230;&#12290;&#35813;&#26041;&#27861;&#21487;&#29992;&#20110;&#20248;&#21270;&#25968;&#23383;&#20581;&#24247;&#30340;&#20010;&#24615;&#21270;&#24178;&#39044;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#23383;&#20581;&#24247;&#20013;&#65292;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20010;&#24615;&#21270;&#27835;&#30103;&#24207;&#21015;&#20197;&#25903;&#25345;&#29992;&#25143;&#37319;&#21462;&#26356;&#20581;&#24247;&#30340;&#34892;&#20026;&#36234;&#26469;&#36234;&#21463;&#21040;&#20851;&#27880;&#12290;&#36825;&#31181;&#36830;&#32493;&#20915;&#31574;&#38382;&#39064;&#28041;&#21450;&#21040;&#22522;&#20110;&#29992;&#25143;&#30340;&#19978;&#19979;&#25991;&#65288;&#20363;&#22914;&#65292;&#20808;&#21069;&#30340;&#27963;&#21160;&#27700;&#24179;&#12289;&#20301;&#32622;&#31561;&#65289;&#22312;&#20309;&#26102;&#27835;&#30103;&#20197;&#21450;&#22914;&#20309;&#27835;&#30103;&#30340;&#20915;&#23450;&#12290;&#22312;&#32447;RL&#31639;&#27861;&#26159;&#36825;&#20010;&#38382;&#39064;&#30340;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#65292;&#22240;&#20026;&#23427;&#22522;&#20110;&#27599;&#20010;&#29992;&#25143;&#30340;&#21382;&#21490;&#21453;&#39304;&#36827;&#34892;&#23398;&#20064;&#65292;&#24182;&#21033;&#29992;&#36825;&#20123;&#30693;&#35782;&#20010;&#24615;&#21270;&#36825;&#20123;&#20915;&#31574;&#12290;&#28982;&#32780;&#65292;&#35201;&#20915;&#23450;&#26159;&#21542;&#24212;&#22312;&#23454;&#38469;&#37096;&#32626;&#30340;&#8220;&#20248;&#21270;&#8221;&#24178;&#39044;&#20013;&#21253;&#21547;RL&#31639;&#27861;&#65292;&#25105;&#20204;&#24517;&#39035;&#35780;&#20272;&#25968;&#25454;&#35777;&#25454;&#65292;&#34920;&#26126;RL&#31639;&#27861;&#23454;&#38469;&#19978;&#27491;&#22312;&#23558;&#27835;&#30103;&#20010;&#24615;&#21270;&#36866;&#24212;&#20854;&#29992;&#25143;&#12290;&#30001;&#20110;RL&#31639;&#27861;&#20013;&#30340;&#38543;&#26426;&#24615;&#65292;&#20154;&#20204;&#21487;&#33021;&#20250;&#23545;&#20854;&#22312;&#26576;&#20123;&#29366;&#24577;&#19979;&#30340;&#23398;&#20064;&#24182;&#20351;&#29992;&#27492;&#23398;&#20064;&#26469;&#25552;&#20379;&#29305;&#23450;&#27835;&#30103;&#30340;&#33021;&#21147;&#20135;&#29983;&#35823;&#35299;&#12290;&#25105;&#20204;&#20351;&#29992;&#24037;&#20316;&#23450;&#20041;&#30340;&#20010;&#24615;&#21270;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#31181;&#37325;&#22797;&#37319;&#26679;&#25919;&#31574;&#35780;&#20272;&#26041;&#27861;&#26469;&#35780;&#20272;&#22312;&#32447;RL&#31639;&#27861;&#23454;&#29616;&#30340;&#20010;&#24615;&#21270;&#27700;&#24179;&#12290;&#25105;&#20204;&#20351;&#29992;&#27169;&#25311;&#35780;&#20272;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20934;&#30830;&#22320;&#35782;&#21035;&#20010;&#24615;&#21270;&#30340;&#31574;&#30053;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#20248;&#21270;&#25968;&#23383;&#20581;&#24247;&#30340;&#20010;&#24615;&#21270;&#24178;&#39044;&#26041;&#38754;&#20855;&#26377;&#28508;&#22312;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is a growing interest in using reinforcement learning (RL) to personalize sequences of treatments in digital health to support users in adopting healthier behaviors. Such sequential decision-making problems involve decisions about when to treat and how to treat based on the user's context (e.g., prior activity level, location, etc.). Online RL is a promising data-driven approach for this problem as it learns based on each user's historical responses and uses that knowledge to personalize these decisions. However, to decide whether the RL algorithm should be included in an ``optimized'' intervention for real-world deployment, we must assess the data evidence indicating that the RL algorithm is actually personalizing the treatments to its users. Due to the stochasticity in the RL algorithm, one may get a false impression that it is learning in certain states and using this learning to provide specific treatments. We use a working definition of personalization and introduce a resamp
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#23436;&#22791;&#24615;&#30340;&#37096;&#20998;&#35782;&#21035;&#26041;&#27861;&#65292;&#23427;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#32452;&#30028;&#38480;&#65292;&#29992;&#20110;&#22312;&#26410;&#33021;&#25511;&#21046;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#24418;&#19979;&#65292;&#35780;&#20272;&#27835;&#30103;&#23545;&#32467;&#26524;&#21464;&#37327;&#22240;&#26524;&#25928;&#24212;&#12290;</title><link>http://arxiv.org/abs/2304.04374</link><description>&lt;p&gt;
&#21033;&#29992;&#20195;&#29702;&#21464;&#37327;&#36827;&#34892;&#22240;&#26524;&#25928;&#24212;&#37096;&#20998;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Partial Identification of Causal Effects Using Proxy Variables. (arXiv:2304.04374v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04374
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#23436;&#22791;&#24615;&#30340;&#37096;&#20998;&#35782;&#21035;&#26041;&#27861;&#65292;&#23427;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#32452;&#30028;&#38480;&#65292;&#29992;&#20110;&#22312;&#26410;&#33021;&#25511;&#21046;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#24418;&#19979;&#65292;&#35780;&#20272;&#27835;&#30103;&#23545;&#32467;&#26524;&#21464;&#37327;&#22240;&#26524;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#36817;&#31471;&#22240;&#26524;&#25512;&#26029;&#34987;&#25552;&#20986;&#20026;&#19968;&#31181;&#22312;&#26410;&#33021;&#25511;&#21046;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#24418;&#19979;&#35780;&#20272;&#27835;&#30103;&#23545;&#32467;&#26524;&#21464;&#37327;&#22240;&#26524;&#25928;&#24212;&#30340;&#26694;&#26550;&#12290;&#20854;&#20013;&#21033;&#29992;&#26410;&#34987;&#35266;&#27979;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#20195;&#29702;&#21464;&#37327;&#36827;&#34892;&#28857;&#20272;&#35745;&#65292;&#21069;&#25552;&#26159;&#36825;&#26679;&#30340;&#20195;&#29702;&#21464;&#37327;&#23545;&#28151;&#28102;&#22240;&#32032;&#30456;&#24403;&#26377;&#20851;&#65292;&#28982;&#32780;&#36825;&#31181;&#23436;&#22791;&#24615;&#21364;&#26159;&#32463;&#39564;&#19981;&#21487;&#26816;&#39564;&#30340;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19981;&#35201;&#27714;&#23436;&#22791;&#24615;&#30340;&#37096;&#20998;&#35782;&#21035;&#26041;&#27861;&#65292;&#24182;&#20026;&#24863;&#20852;&#36259;&#30340;&#22240;&#26524;&#25928;&#24212;&#25552;&#20379;&#20102;&#19968;&#32452;&#30028;&#38480;&#12290;&#35813;&#26041;&#27861;&#24314;&#31435;&#22312;&#25935;&#24863;&#24615;&#20998;&#26512;&#30340;&#22522;&#30784;&#19978;&#65292;&#24182;&#19988;&#27604;&#29616;&#26377;&#30340;&#22522;&#20110;&#20195;&#29702;&#21464;&#37327;&#30340;&#26041;&#27861;&#35201;&#27714;&#26356;&#24369;&#12290;&#36825;&#39033;&#24037;&#20316;&#22312;&#27169;&#25311;&#25968;&#25454;&#21644;&#29616;&#23454;&#25968;&#25454;&#19978;&#36827;&#34892;&#20102;&#23637;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Proximal causal inference is a recently proposed framework for evaluating the causal effect of a treatment on an outcome variable in the presence of unmeasured confounding (Miao et al., 2018a; Tchetgen Tchetgen et al., 2020). For nonparametric point identification, the framework leverages proxy variables of unobserved confounders, provided that such proxies are sufficiently relevant for the latter, a requirement that has previously been formalized as a completeness condition. Completeness is key to connecting the observed proxy data to hidden factors via a so-called confounding bridge function, identification of which is an important step towards proxy-based point identification of causal effects. However, completeness is well-known not to be empirically testable, therefore potentially restricting the application of the proximal causal framework. In this paper, we propose partial identification methods that do not require completeness and obviate the need for identification of a bridge
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21457;&#23637;&#20102;PCA-Net&#30340;&#36817;&#20284;&#29702;&#35770;&#65292;&#24471;&#20986;&#20102;&#36890;&#29992;&#36924;&#36817;&#32467;&#26524;&#65292;&#24182;&#35782;&#21035;&#20986;&#20102;&#20351;&#29992;PCA-Net&#36827;&#34892;&#39640;&#25928;&#25805;&#20316;&#23398;&#20064;&#30340;&#28508;&#22312;&#38556;&#30861;&#65306;&#36755;&#20986;&#20998;&#24067;&#30340;&#22797;&#26434;&#24615;&#21644;&#31639;&#23376;&#31354;&#38388;&#30340;&#20869;&#22312;&#22797;&#26434;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.16317</link><description>&lt;p&gt;
PCA-Net&#65306;&#25805;&#20316;&#23398;&#20064;&#30340;&#22797;&#26434;&#24615;&#19978;&#19979;&#30028;
&lt;/p&gt;
&lt;p&gt;
Operator learning with PCA-Net: upper and lower complexity bounds. (arXiv:2303.16317v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16317
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21457;&#23637;&#20102;PCA-Net&#30340;&#36817;&#20284;&#29702;&#35770;&#65292;&#24471;&#20986;&#20102;&#36890;&#29992;&#36924;&#36817;&#32467;&#26524;&#65292;&#24182;&#35782;&#21035;&#20986;&#20102;&#20351;&#29992;PCA-Net&#36827;&#34892;&#39640;&#25928;&#25805;&#20316;&#23398;&#20064;&#30340;&#28508;&#22312;&#38556;&#30861;&#65306;&#36755;&#20986;&#20998;&#24067;&#30340;&#22797;&#26434;&#24615;&#21644;&#31639;&#23376;&#31354;&#38388;&#30340;&#20869;&#22312;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#31639;&#23376;&#22312;&#35745;&#31639;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#22791;&#21463;&#20851;&#27880;&#12290;PCA-Net&#26159;&#19968;&#31181;&#26368;&#36817;&#25552;&#20986;&#30340;&#31070;&#32463;&#31639;&#23376;&#26550;&#26500;&#65292;&#23427;&#23558;&#20027;&#25104;&#20998;&#20998;&#26512;(PCA)&#19982;&#31070;&#32463;&#32593;&#32476;&#30456;&#32467;&#21512;&#65292;&#20197;&#36924;&#36817;&#28508;&#22312;&#30340;&#31639;&#23376;&#12290;&#26412;&#25991;&#23545;&#36825;&#31181;&#26041;&#27861;&#36827;&#34892;&#20102;&#36817;&#20284;&#29702;&#35770;&#30340;&#21457;&#23637;&#65292;&#25913;&#36827;&#24182;&#26174;&#30528;&#25193;&#23637;&#20102;&#27492;&#26041;&#21521;&#30340;&#20197;&#21069;&#30340;&#24037;&#20316;&#12290;&#22312;&#23450;&#24615;&#30028;&#38480;&#26041;&#38754;&#65292;&#26412;&#25991;&#24471;&#20986;&#20102;&#26032;&#39062;&#30340;&#36890;&#29992;&#36924;&#36817;&#32467;&#26524;&#65292;&#22312;&#23545;&#28508;&#22312;&#31639;&#23376;&#21644;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#30340;&#26368;&#23567;&#20551;&#35774;&#30340;&#21069;&#25552;&#19979;&#12290;&#22312;&#23450;&#37327;&#38480;&#21046;&#26041;&#38754;&#65292;&#26412;&#25991;&#35782;&#21035;&#20102;&#20351;&#29992;PCA-Net&#36827;&#34892;&#39640;&#25928;&#25805;&#20316;&#23398;&#20064;&#30340;&#20004;&#20010;&#28508;&#22312;&#38556;&#30861;&#65292;&#36890;&#36807;&#23548;&#20986;&#19979;&#30028;&#36827;&#34892;&#20102;&#20005;&#26684;&#35777;&#26126;&#65292;&#31532;&#19968;&#20010;&#38556;&#30861;&#19982;&#36755;&#20986;&#20998;&#24067;&#30340;&#22797;&#26434;&#24615;&#26377;&#20851;&#65292;&#30001;PCA&#29305;&#24449;&#20540;&#30340;&#32531;&#24930;&#34928;&#20943;&#26469;&#34913;&#37327;&#65307;&#21478;&#19968;&#20010;&#38556;&#30861;&#28041;&#21450;&#26080;&#38480;&#32500;&#36755;&#20837;&#21644;&#36755;&#20986;&#31354;&#38388;&#20043;&#38388;&#30340;&#31639;&#23376;&#31354;&#38388;&#30340;&#20869;&#22312;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural operators are gaining attention in computational science and engineering. PCA-Net is a recently proposed neural operator architecture which combines principal component analysis (PCA) with neural networks to approximate an underlying operator. The present work develops approximation theory for this approach, improving and significantly extending previous work in this direction. In terms of qualitative bounds, this paper derives a novel universal approximation result, under minimal assumptions on the underlying operator and the data-generating distribution. In terms of quantitative bounds, two potential obstacles to efficient operator learning with PCA-Net are identified, and made rigorous through the derivation of lower complexity bounds; the first relates to the complexity of the output distribution, measured by a slow decay of the PCA eigenvalues. The other obstacle relates the inherent complexity of the space of operators between infinite-dimensional input and output spaces, 
&lt;/p&gt;</description></item><item><title>FuNVol&#26159;&#19968;&#20010;&#22810;&#36164;&#20135;&#38544;&#21547;&#27874;&#21160;&#29575;&#24066;&#22330;&#27169;&#25311;&#22120;&#65292;&#20351;&#29992;&#20989;&#25968;&#20027;&#25104;&#20998;&#21644;&#31070;&#32463;SDE&#29983;&#25104;&#30495;&#23454;&#21382;&#21490;&#20215;&#26684;&#30340;IV&#34920;&#38754;&#24207;&#21015;&#65292;&#24182;&#22312;&#26080;&#38745;&#24577;&#22871;&#21033;&#30340;&#34920;&#38754;&#27425;&#27969;&#24418;&#20869;&#20135;&#29983;&#19968;&#33268;&#30340;&#24066;&#22330;&#24773;&#26223;&#12290;&#21516;&#26102;&#65292;&#20351;&#29992;&#27169;&#25311;&#34920;&#38754;&#36827;&#34892;&#23545;&#20914;&#21487;&#20197;&#29983;&#25104;&#19982;&#23454;&#29616;P&#65286;L&#19968;&#33268;&#30340;&#25439;&#30410;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2303.00859</link><description>&lt;p&gt;
FuNVol&#65306;&#20351;&#29992;&#20989;&#25968;&#20027;&#25104;&#20998;&#21644;&#31070;&#32463;SDE&#30340;&#22810;&#36164;&#20135;&#38544;&#21547;&#27874;&#21160;&#29575;&#24066;&#22330;&#27169;&#25311;&#22120;
&lt;/p&gt;
&lt;p&gt;
FuNVol: A Multi-Asset Implied Volatility Market Simulator using Functional Principal Components and Neural SDEs. (arXiv:2303.00859v2 [q-fin.CP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.00859
&lt;/p&gt;
&lt;p&gt;
FuNVol&#26159;&#19968;&#20010;&#22810;&#36164;&#20135;&#38544;&#21547;&#27874;&#21160;&#29575;&#24066;&#22330;&#27169;&#25311;&#22120;&#65292;&#20351;&#29992;&#20989;&#25968;&#20027;&#25104;&#20998;&#21644;&#31070;&#32463;SDE&#29983;&#25104;&#30495;&#23454;&#21382;&#21490;&#20215;&#26684;&#30340;IV&#34920;&#38754;&#24207;&#21015;&#65292;&#24182;&#22312;&#26080;&#38745;&#24577;&#22871;&#21033;&#30340;&#34920;&#38754;&#27425;&#27969;&#24418;&#20869;&#20135;&#29983;&#19968;&#33268;&#30340;&#24066;&#22330;&#24773;&#26223;&#12290;&#21516;&#26102;&#65292;&#20351;&#29992;&#27169;&#25311;&#34920;&#38754;&#36827;&#34892;&#23545;&#20914;&#21487;&#20197;&#29983;&#25104;&#19982;&#23454;&#29616;P&#65286;L&#19968;&#33268;&#30340;&#25439;&#30410;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#21644;&#31070;&#32463;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65292;&#32467;&#21512;&#27010;&#29575;&#31215;&#20998;&#21464;&#25442;&#24809;&#32602;&#26469;&#29983;&#25104;&#22810;&#20010;&#36164;&#20135;&#30340;&#38544;&#21547;&#27874;&#21160;&#29575;&#34920;&#38754;&#24207;&#21015;&#65292;&#35813;&#26041;&#27861;&#24544;&#23454;&#20110;&#21382;&#21490;&#20215;&#26684;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23398;&#20064;IV&#34920;&#38754;&#21644;&#20215;&#26684;&#30340;&#32852;&#21512;&#21160;&#24577;&#20135;&#29983;&#30340;&#24066;&#22330;&#24773;&#26223;&#19982;&#21382;&#21490;&#29305;&#24449;&#19968;&#33268;&#65292;&#24182;&#19988;&#22312;&#27809;&#26377;&#38745;&#24577;&#22871;&#21033;&#30340;&#34920;&#38754;&#27425;&#27969;&#24418;&#20869;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20351;&#29992;&#27169;&#25311;&#34920;&#38754;&#36827;&#34892;&#23545;&#20914;&#20250;&#29983;&#25104;&#19982;&#23454;&#29616;P&#65286;L&#19968;&#33268;&#30340;&#25439;&#30410;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
Here, we introduce a new approach for generating sequences of implied volatility (IV) surfaces across multiple assets that is faithful to historical prices. We do so using a combination of functional data analysis and neural stochastic differential equations (SDEs) combined with a probability integral transform penalty to reduce model misspecification. We demonstrate that learning the joint dynamics of IV surfaces and prices produces market scenarios that are consistent with historical features and lie within the sub-manifold of surfaces that are essentially free of static arbitrage. Finally, we demonstrate that delta hedging using the simulated surfaces generates profit and loss (P&amp;L) distributions that are consistent with realised P&amp;Ls.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;Bagging&#25216;&#26415;&#21487;&#25552;&#20379;&#26080;&#20559;&#24046;&#31283;&#23450;&#24615;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#25968;&#25454;&#20998;&#24067;&#21644;&#31639;&#27861;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#23454;&#35777;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2301.12600</link><description>&lt;p&gt;
Bagging&#25552;&#20379;&#26080;&#20559;&#24046;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bagging Provides Assumption-free Stability. (arXiv:2301.12600v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12600
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;Bagging&#25216;&#26415;&#21487;&#25552;&#20379;&#26080;&#20559;&#24046;&#31283;&#23450;&#24615;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#25968;&#25454;&#20998;&#24067;&#21644;&#31639;&#27861;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#23454;&#35777;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Bagging&#26159;&#31283;&#23450;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#19968;&#20010;&#37325;&#35201;&#25216;&#26415;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#38024;&#23545;&#20219;&#20309;&#27169;&#22411;&#30340;&#31283;&#23450;&#24615;&#25512;&#23548;&#20102;&#19968;&#20010;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#19981;&#23545;&#25968;&#25454;&#20998;&#24067;&#12289;&#22522;&#26412;&#31639;&#27861;&#30340;&#23646;&#24615;&#25110;&#21327;&#21464;&#37327;&#30340;&#32500;&#25968;&#36827;&#34892;&#20219;&#20309;&#20551;&#35774;&#12290;&#25105;&#20204;&#30340;&#20445;&#35777;&#36866;&#29992;&#20110;&#22810;&#31181;&#21464;&#20307;&#30340;Bagging&#65292;&#24182;&#19988;&#26159;&#26368;&#20248;&#30340;&#24120;&#25968;&#12290;&#23454;&#35777;&#32467;&#26524;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#21457;&#29616;&#65292;&#34920;&#26126;Bagging&#25104;&#21151;&#31283;&#23450;&#20102;&#21363;&#20351;&#26159;&#39640;&#24230;&#19981;&#31283;&#23450;&#30340;&#22522;&#26412;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bagging is an important technique for stabilizing machine learning models. In this paper, we derive a finite-sample guarantee on the stability of bagging for any model. Our result places no assumptions on the distribution of the data, on the properties of the base algorithm, or on the dimensionality of the covariates. Our guarantee applies to many variants of bagging and is optimal up to a constant. Empirical results validate our findings, showing that bagging successfully stabilizes even highly unstable base algorithms.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32479;&#35745;&#26816;&#39564;&#30340; MMD-B-Fair &#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#20844;&#24179;&#30340;&#25968;&#25454;&#34920;&#31034;&#65292;&#24182;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2211.07907</link><description>&lt;p&gt;
&#22522;&#20110;&#32479;&#35745;&#26816;&#39564;&#30340;MMD-B-Fair&#65306;&#23398;&#20064;&#20844;&#24179;&#30340;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
MMD-B-Fair: Learning Fair Representations with Statistical Testing. (arXiv:2211.07907v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.07907
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32479;&#35745;&#26816;&#39564;&#30340; MMD-B-Fair &#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#20844;&#24179;&#30340;&#25968;&#25454;&#34920;&#31034;&#65292;&#24182;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26680;&#21452;&#26679;&#26412;&#27979;&#35797;&#23398;&#20064;&#25968;&#25454;&#20844;&#24179;&#34920;&#31034;&#30340;&#26041;&#27861;MMD-B-Fair&#12290;&#25105;&#20204;&#25214;&#21040;&#20102;&#25968;&#25454;&#30340;&#31070;&#32463;&#29305;&#24449;&#65292;&#20854;&#20013;&#26368;&#22823;&#24179;&#22343;&#20559;&#24046;&#65288;MMD&#65289;&#27979;&#35797;&#26080;&#27861;&#21306;&#20998;&#19981;&#21516;&#25935;&#24863;&#32452;&#30340;&#34920;&#31034;&#65292;&#21516;&#26102;&#20445;&#30041;&#26377;&#20851;&#30446;&#26631;&#23646;&#24615;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#22359;&#27979;&#35797;&#26041;&#26696;&#30340;&#31616;&#21333;&#28176;&#36817;&#24615;&#33021;&#22815;&#26377;&#25928;&#22320;&#25214;&#21040;&#20844;&#24179;&#34920;&#31034;&#65292;&#32780;&#19981;&#38656;&#35201;&#20351;&#29992;&#29616;&#26377;&#20844;&#24179;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#20013;&#24191;&#27867;&#20351;&#29992;&#30340;&#22797;&#26434;&#23545;&#25239;&#24615;&#20248;&#21270;&#25110;&#29983;&#25104;&#24314;&#27169;&#26041;&#26696;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#26174;&#31034;&#20854;&#33021;&#22815;&#8220;&#38544;&#34255;&#8221;&#26377;&#20851;&#25935;&#24863;&#23646;&#24615;&#30340;&#20449;&#24687;&#65292;&#24182;&#22312;&#19979;&#28216;&#20256;&#36755;&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a method, MMD-B-Fair, to learn fair representations of data via kernel two-sample testing. We find neural features of our data where a maximum mean discrepancy (MMD) test cannot distinguish between representations of different sensitive groups, while preserving information about the target attributes. Minimizing the power of an MMD test is more difficult than maximizing it (as done in previous work), because the test threshold's complex behavior cannot be simply ignored. Our method exploits the simple asymptotics of block testing schemes to efficiently find fair representations without requiring complex adversarial optimization or generative modelling schemes widely used by existing work on fair representation learning. We evaluate our approach on various datasets, showing its ability to ``hide'' information about sensitive attributes, and its effectiveness in downstream transfer tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20026;&#37325;&#23614;&#25439;&#22833;&#24773;&#20917;&#19979;&#30340;PAC-Bayes&#25552;&#20379;&#20102;&#27867;&#21270;&#30028;&#65292;&#25193;&#23637;&#20102;&#20808;&#21069;&#30340;&#30740;&#31350;&#65292;&#24182;&#36890;&#36807;&#39532;&#23572;&#31185;&#22827;&#19981;&#31561;&#24335;&#30340;&#25193;&#23637;&#20026;&#19981;&#21516;&#30340;PAC-Bayesian&#26694;&#26550;&#25552;&#20379;&#20102;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2210.00928</link><description>&lt;p&gt;
&#36890;&#36807;&#36229;&#39532;&#27663;&#36807;&#31243;&#25512;&#23548;&#37325;&#23614;&#25439;&#22833;&#30340;PAC-Bayes&#27867;&#21270;&#30028;
&lt;/p&gt;
&lt;p&gt;
PAC-Bayes Generalisation Bounds for Heavy-Tailed Losses through Supermartingales. (arXiv:2210.00928v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.00928
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20026;&#37325;&#23614;&#25439;&#22833;&#24773;&#20917;&#19979;&#30340;PAC-Bayes&#25552;&#20379;&#20102;&#27867;&#21270;&#30028;&#65292;&#25193;&#23637;&#20102;&#20808;&#21069;&#30340;&#30740;&#31350;&#65292;&#24182;&#36890;&#36807;&#39532;&#23572;&#31185;&#22827;&#19981;&#31561;&#24335;&#30340;&#25193;&#23637;&#20026;&#19981;&#21516;&#30340;PAC-Bayesian&#26694;&#26550;&#25552;&#20379;&#20102;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;PAC-Bayes&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#29992;&#20110;&#36731;&#23614;&#25439;&#22833;&#65288;&#20363;&#22914;&#20122;&#39640;&#26031;&#25110;&#20122;&#25351;&#25968;&#65289;&#30340;&#23398;&#20064;&#26694;&#26550;&#65292;&#20294;&#20854;&#22312;&#37325;&#23614;&#25439;&#22833;&#24773;&#20917;&#19979;&#30340;&#25512;&#24191;&#20173;&#28982;&#26410;&#24471;&#21040;&#24191;&#27867;&#30740;&#31350;&#65292;&#36817;&#24180;&#26469;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#26412;&#25991;&#22312;&#20551;&#23450;&#25439;&#22833;&#20989;&#25968;&#26377;&#30028;&#26041;&#24046;&#30340;&#24773;&#20917;&#19979;&#65292;&#20026;&#37325;&#23614;&#25439;&#22833;&#25552;&#20379;&#20102;PAC-Bayes&#27867;&#21270;&#30028;&#12290;&#22312;&#35813;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;\citet{kuzborskij2019efron}&#30340;&#20808;&#21069;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#25216;&#26415;&#36129;&#29486;&#22312;&#20110;&#21033;&#29992;&#36229;&#39532;&#27663;&#36807;&#31243;&#30340;&#39532;&#23572;&#31185;&#22827;&#19981;&#31561;&#24335;&#30340;&#25193;&#23637;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#25216;&#26415;&#36890;&#36807;&#20026;&#26080;&#30028;&#38789;&#25552;&#20379;&#30028;&#38480;&#65292;&#20197;&#21450;&#20026;&#37325;&#23614;&#25439;&#22833;&#30340;&#25209;&#22788;&#29702;&#21644;&#22312;&#32447;&#23398;&#20064;&#25552;&#20379;&#30028;&#38480;&#65292;&#32479;&#19968;&#21644;&#25193;&#23637;&#20102;&#19981;&#21516;&#30340;PAC-Bayesian&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
While PAC-Bayes is now an established learning framework for light-tailed losses (\emph{e.g.}, subgaussian or subexponential), its extension to the case of heavy-tailed losses remains largely uncharted and has attracted a growing interest in recent years. We contribute PAC-Bayes generalisation bounds for heavy-tailed losses under the sole assumption of bounded variance of the loss function. Under that assumption, we extend previous results from \citet{kuzborskij2019efron}. Our key technical contribution is exploiting an extention of Markov's inequality for supermartingales. Our proof technique unifies and extends different PAC-Bayesian frameworks by providing bounds for unbounded martingales as well as bounds for batch and online learning with heavy-tailed losses.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24314;&#31435;&#20102;&#19968;&#20123;&#20989;&#25968;&#31867;&#30340;Natarajan&#32500;&#24230;&#19978;&#30028;&#65292;&#36825;&#20123;&#32467;&#26524;&#21487;&#20197;&#29992;&#20110;&#25551;&#36848;&#26576;&#20123;&#22810;&#31867;&#23398;&#20064;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2209.07015</link><description>&lt;p&gt;
&#26576;&#20123;&#20989;&#25968;&#31867;&#30340;Natarajan&#32500;&#25968;&#30340;&#19978;&#30028;
&lt;/p&gt;
&lt;p&gt;
Upper bounds on the Natarajan dimensions of some function classes. (arXiv:2209.07015v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.07015
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24314;&#31435;&#20102;&#19968;&#20123;&#20989;&#25968;&#31867;&#30340;Natarajan&#32500;&#24230;&#19978;&#30028;&#65292;&#36825;&#20123;&#32467;&#26524;&#21487;&#20197;&#29992;&#20110;&#25551;&#36848;&#26576;&#20123;&#22810;&#31867;&#23398;&#20064;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Natarajan&#32500;&#24230;&#26159;&#34920;&#24449;&#22810;&#31867;PAC&#21487;&#23398;&#20064;&#24615;&#30340;&#22522;&#26412;&#24037;&#20855;&#65292;&#23558;Vapnik-Chervonenkis&#65288;VC&#65289;&#32500;&#20174;&#20108;&#36827;&#21046;&#20998;&#31867;&#38382;&#39064;&#25512;&#24191;&#21040;&#22810;&#31867;&#20998;&#31867;&#38382;&#39064;&#12290;&#26412;&#30740;&#31350;&#24314;&#31435;&#20102;&#19968;&#20123;&#20989;&#25968;&#31867;&#30340;Natarajan&#32500;&#24230;&#19978;&#30028;&#65292;&#21253;&#25324;&#65288;i&#65289;&#22810;&#31867;&#20915;&#31574;&#26641;&#21644;&#38543;&#26426;&#26862;&#26519;&#65292;&#20197;&#21450;&#65288;ii&#65289;&#20108;&#36827;&#21046;&#12289;&#32447;&#24615;&#21644;ReLU&#28608;&#27963;&#30340;&#22810;&#31867;&#31070;&#32463;&#32593;&#32476;&#12290;&#36825;&#20123;&#32467;&#26524;&#21487;&#33021;&#23545;&#25551;&#36848;&#26576;&#20123;&#22810;&#31867;&#23398;&#20064;&#31639;&#27861;&#30340;&#24615;&#33021;&#26377;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Natarajan dimension is a fundamental tool for characterizing multi-class PAC learnability, generalizing the Vapnik-Chervonenkis (VC) dimension from binary to multi-class classification problems. This work establishes upper bounds on Natarajan dimensions for certain function classes, including (i) multi-class decision tree and random forests, and (ii) multi-class neural networks with binary, linear and ReLU activations. These results may be relevant for describing the performance of certain multi-class learning algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24555;&#36895;&#12289;&#26080;&#38656;&#20284;&#28982;&#20989;&#25968;&#12289;&#26131;&#20110;&#36827;&#34892;&#22522;&#20110;&#33258;&#20030;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#25512;&#26029;&#24037;&#20855;&#8212;&#8212;&#31070;&#32463;&#28857;&#20272;&#35745;&#22120;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#26696;&#20363;&#20998;&#26512;&#35777;&#26126;&#20854;&#21487;&#20197;&#22312;&#24369;&#35782;&#21035;&#21644;&#39640;&#21442;&#25968;&#21270;&#27169;&#22411;&#20013;&#36827;&#34892;&#24555;&#36895;&#19988;&#26368;&#20248;&#30340;&#21442;&#25968;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2208.12942</link><description>&lt;p&gt;
&#24555;&#36895;&#26368;&#20248;&#26080;&#20284;&#28982;&#25512;&#26029;&#30340;&#31070;&#32463;&#28857;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Neural Point Estimation for Fast Optimal Likelihood-Free Inference. (arXiv:2208.12942v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.12942
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24555;&#36895;&#12289;&#26080;&#38656;&#20284;&#28982;&#20989;&#25968;&#12289;&#26131;&#20110;&#36827;&#34892;&#22522;&#20110;&#33258;&#20030;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#25512;&#26029;&#24037;&#20855;&#8212;&#8212;&#31070;&#32463;&#28857;&#20272;&#35745;&#22120;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#26696;&#20363;&#20998;&#26512;&#35777;&#26126;&#20854;&#21487;&#20197;&#22312;&#24369;&#35782;&#21035;&#21644;&#39640;&#21442;&#25968;&#21270;&#27169;&#22411;&#20013;&#36827;&#34892;&#24555;&#36895;&#19988;&#26368;&#20248;&#30340;&#21442;&#25968;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#28857;&#20272;&#35745;&#22120;&#26159;&#19968;&#31181;&#23558;&#25968;&#25454;&#26144;&#23556;&#21040;&#21442;&#25968;&#28857;&#20272;&#35745;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#23427;&#20204;&#24555;&#36895;&#12289;&#26080;&#38656;&#20284;&#28982;&#20989;&#25968;&#65292;&#24182;&#19988;&#30001;&#20110;&#23427;&#20204;&#30340;&#24179;&#22343;&#29305;&#24615;&#65292;&#26131;&#20110;&#36827;&#34892;&#22522;&#20110;&#33258;&#20030;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#26412;&#25991;&#26088;&#22312;&#25552;&#39640;&#32479;&#35745;&#23398;&#23478;&#23545;&#20110;&#36825;&#31181;&#30456;&#23545;&#36739;&#26032;&#30340;&#25512;&#26029;&#24037;&#20855;&#30340;&#35748;&#35782;&#65292;&#24182;&#36890;&#36807;&#25552;&#20379;&#29992;&#25143;&#21451;&#22909;&#30340;&#24320;&#28304;&#36719;&#20214;&#26469;&#20419;&#36827;&#20854;&#37319;&#29992;&#12290;&#25105;&#20204;&#36824;&#20851;&#27880;&#20102;&#20174;&#37325;&#22797;&#25968;&#25454;&#36827;&#34892;&#25512;&#26029;&#30340;&#24191;&#27867;&#38382;&#39064;&#65292;&#22312;&#31070;&#32463;&#35774;&#32622;&#20013;&#20351;&#29992;&#25490;&#21015;&#19981;&#21464;&#31070;&#32463;&#32593;&#32476;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#27169;&#25311;&#30740;&#31350;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#31070;&#32463;&#28857;&#20272;&#35745;&#22120;&#21487;&#20197;&#24555;&#36895;&#19988;&#26368;&#20248;&#22320;&#65288;&#20174;&#36125;&#21494;&#26031;&#24847;&#20041;&#19978;&#65289;&#22312;&#24369;&#35782;&#21035;&#21644;&#39640;&#21442;&#25968;&#21270;&#27169;&#22411;&#20013;&#36827;&#34892;&#20272;&#35745;&#65292;&#24182;&#19988;&#30456;&#23545;&#23481;&#26131;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#32418;&#28023;&#26497;&#31471;&#28023;&#34920;&#28201;&#24230;&#20998;&#26512;&#26469;&#35777;&#26126;&#23427;&#20204;&#30340;&#36866;&#29992;&#24615;&#65292;&#22312;&#35757;&#32451;&#20043;&#21518;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#21442;&#25968;&#20272;&#35745;&#21644;&#22522;&#20110;&#33258;&#20030;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural point estimators are neural networks that map data to parameter point estimates. They are fast, likelihood free and, due to their amortised nature, amenable to fast bootstrap-based uncertainty quantification. In this paper, we aim to increase the awareness of statisticians to this relatively new inferential tool, and to facilitate its adoption by providing user-friendly open-source software. We also give attention to the ubiquitous problem of making inference from replicated data, which we address in the neural setting using permutation-invariant neural networks. Through extensive simulation studies we show that these neural point estimators can quickly and optimally (in a Bayes sense) estimate parameters in weakly-identified and highly-parameterised models with relative ease. We demonstrate their applicability through an analysis of extreme sea-surface temperature in the Red Sea where, after training, we obtain parameter estimates and bootstrap-based confidence intervals from h
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31526;&#21512;&#20445;&#24207;&#30340;&#39118;&#38505;&#25511;&#21046;&#26041;&#27861;&#65292;&#21487;&#20197;&#25511;&#21046;&#20219;&#20309;&#21333;&#35843;&#25439;&#22833;&#20989;&#25968;&#30340;&#26399;&#26395;&#20540;&#65292;&#31034;&#20363;&#35777;&#26126;&#20854;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#20855;&#26377;&#25511;&#21046;&#35823;&#25253;&#29575;&#12289;&#22270;&#24418;&#36317;&#31163;&#21644;&#20196;&#29260;&#32423;F1&#24471;&#20998;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2208.02814</link><description>&lt;p&gt;
&#19968;&#31181;&#31526;&#21512;&#20445;&#24207;&#30340;&#39118;&#38505;&#25511;&#21046;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Conformal Risk Control. (arXiv:2208.02814v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.02814
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31526;&#21512;&#20445;&#24207;&#30340;&#39118;&#38505;&#25511;&#21046;&#26041;&#27861;&#65292;&#21487;&#20197;&#25511;&#21046;&#20219;&#20309;&#21333;&#35843;&#25439;&#22833;&#20989;&#25968;&#30340;&#26399;&#26395;&#20540;&#65292;&#31034;&#20363;&#35777;&#26126;&#20854;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#20855;&#26377;&#25511;&#21046;&#35823;&#25253;&#29575;&#12289;&#22270;&#24418;&#36317;&#31163;&#21644;&#20196;&#29260;&#32423;F1&#24471;&#20998;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;&#31526;&#21512;&#24615;&#39044;&#27979;&#25512;&#24191;&#33267;&#25511;&#21046;&#20219;&#20309;&#21333;&#35843;&#25439;&#22833;&#20989;&#25968;&#30340;&#26399;&#26395;&#20540;&#12290;&#35813;&#31639;&#27861;&#23558;&#20998;&#35010;&#31526;&#21512;&#24615;&#39044;&#27979;&#21450;&#20854;&#35206;&#30422;&#20445;&#35777;&#36827;&#34892;&#20102;&#27867;&#21270;&#12290;&#31867;&#20284;&#20110;&#31526;&#21512;&#24615;&#39044;&#27979;&#65292;&#31526;&#21512;&#20445;&#24207;&#30340;&#39118;&#38505;&#25511;&#21046;&#26041;&#27861;&#22312;$\mathcal{O}(1/n)$&#22240;&#23376;&#20869;&#20445;&#25345;&#32039;&#23494;&#24615;&#12290;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#31034;&#20363;&#35777;&#26126;&#20102;&#25105;&#20204;&#31639;&#27861;&#22312;&#25511;&#21046;&#35823;&#25253;&#29575;&#12289;&#22270;&#24418;&#36317;&#31163;&#21644;&#20196;&#29260;&#32423;F1&#24471;&#20998;&#26041;&#38754;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We extend conformal prediction to control the expected value of any monotone loss function. The algorithm generalizes split conformal prediction together with its coverage guarantee. Like conformal prediction, the conformal risk control procedure is tight up to an $\mathcal{O}(1/n)$ factor. Worked examples from computer vision and natural language processing demonstrate the usage of our algorithm to bound the false negative rate, graph distance, and token-level F1-score.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#25968;&#25454;&#20462;&#21098;&#31639;&#27861;&#31361;&#30772;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#38598;&#22823;&#23567;&#19982;&#27169;&#22411;&#35823;&#24046;&#24130;&#24459;&#30340;&#23610;&#24230;&#30028;&#38480;&#65292;&#24182;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;&#26377;&#25928;&#24615;&#65292;&#21516;&#26102;&#36827;&#34892;&#20102;&#39318;&#27425;&#22823;&#35268;&#27169;&#25968;&#25454;&#20462;&#21098;&#31639;&#27861;&#22522;&#20934;&#27979;&#35797;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2206.14486</link><description>&lt;p&gt;
&#36229;&#36234;&#31070;&#32463;&#23610;&#24230;&#23450;&#24459;&#65306;&#36890;&#36807;&#25968;&#25454;&#20462;&#21098;&#25171;&#36133;&#24130;&#24459;&#23610;&#24230;
&lt;/p&gt;
&lt;p&gt;
Beyond neural scaling laws: beating power law scaling via data pruning. (arXiv:2206.14486v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.14486
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#25968;&#25454;&#20462;&#21098;&#31639;&#27861;&#31361;&#30772;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#38598;&#22823;&#23567;&#19982;&#27169;&#22411;&#35823;&#24046;&#24130;&#24459;&#30340;&#23610;&#24230;&#30028;&#38480;&#65292;&#24182;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;&#26377;&#25928;&#24615;&#65292;&#21516;&#26102;&#36827;&#34892;&#20102;&#39318;&#27425;&#22823;&#35268;&#27169;&#25968;&#25454;&#20462;&#21098;&#31639;&#27861;&#22522;&#20934;&#27979;&#35797;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26222;&#36941;&#23384;&#22312;&#30340;&#31070;&#32463;&#23610;&#24230;&#23450;&#24459;&#20197;&#35757;&#32451;&#38598;&#22823;&#23567;&#12289;&#27169;&#22411;&#35268;&#27169;&#25110;&#20004;&#32773;&#30340;&#24130;&#20026;&#27169;&#22411;&#35823;&#24046;&#19979;&#38477;&#30340;&#39537;&#21160;&#21147;&#65292;&#20026;&#28145;&#24230;&#23398;&#20064;&#24102;&#26469;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;&#20294;&#26159;&#65292;&#20165;&#36890;&#36807;&#23610;&#24230;&#26469;&#23454;&#29616;&#36825;&#20123;&#25913;&#36827;&#38656;&#35201;&#24040;&#22823;&#30340;&#35745;&#31639;&#21644;&#33021;&#28304;&#25104;&#26412;&#12290;&#26412;&#25991;&#30528;&#37325;&#30740;&#31350;&#25968;&#25454;&#38598;&#22823;&#23567;&#19982;&#35823;&#24046;&#27604;&#20363;&#30340;&#23610;&#24230;&#65292;&#24182;&#23637;&#31034;&#29702;&#35770;&#19978;&#25105;&#20204;&#22914;&#20309;&#31361;&#30772;&#24130;&#24459;&#23610;&#24230;&#65292;&#24182;&#22312;pruning&#31639;&#27861;&#26465;&#20214;&#19979;&#28508;&#22312;&#22320;&#29978;&#33267;&#33021;&#23558;&#20854;&#38477;&#33267;&#25351;&#25968;&#23610;&#24230;&#12290;&#25105;&#20204;&#25509;&#30528;&#22312;CIFAR-10&#12289;SVHN&#21644;ImageNet&#30340;ResNet&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#39564;&#35777;&#65292;&#24182;&#35266;&#23519;&#21040;&#23454;&#36341;&#20013;&#20248;&#20110;&#24130;&#24459;&#23610;&#24230;&#30340;&#34920;&#29616;&#12290;&#27492;&#22806;&#65292;&#37492;&#20110;&#23547;&#25214;&#20248;&#36136;pruning&#31639;&#27861;&#30340;&#37325;&#35201;&#24615;&#65292;&#25105;&#20204;&#23545;ImageNet&#19978;&#30340;&#21313;&#31181;&#19981;&#21516;&#30340;&#25968;&#25454;&#20462;&#21098;&#31639;&#27861;&#36827;&#34892;&#20102;&#39318;&#27425;&#22823;&#35268;&#27169;&#22522;&#20934;&#27979;&#35797;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Widely observed neural scaling laws, in which error falls off as a power of the training set size, model size, or both, have driven substantial performance improvements in deep learning. However, these improvements through scaling alone require considerable costs in compute and energy. Here we focus on the scaling of error with dataset size and show how in theory we can break beyond power law scaling and potentially even reduce it to exponential scaling instead if we have access to a high-quality data pruning metric that ranks the order in which training examples should be discarded to achieve any pruned dataset size. We then test this improved scaling prediction with pruned dataset size empirically, and indeed observe better than power law scaling in practice on ResNets trained on CIFAR-10, SVHN, and ImageNet. Next, given the importance of finding high-quality pruning metrics, we perform the first large-scale benchmarking study of ten different data pruning metrics on ImageNet. We fin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21452;&#23618;&#20248;&#21270;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23616;&#37096;&#36924;&#36817;&#19979;&#23618;&#38382;&#39064;&#30340;&#35299;&#38598;&#65292;&#28982;&#21518;&#36816;&#34892;&#26465;&#20214;&#26799;&#24230;&#26356;&#26032;&#26469;&#20943;&#23569;&#19978;&#23618;&#30446;&#26631;&#20989;&#25968;&#65292;&#24182;&#19988;&#25910;&#25947;&#24615;&#20445;&#35777;&#36739;&#22909;&#12290;</title><link>http://arxiv.org/abs/2206.08868</link><description>&lt;p&gt;
&#24102;&#32422;&#26463;&#19979;&#20984;&#19979;&#23618;&#38382;&#39064;&#30340;&#31616;&#21333;&#21452;&#23618;&#20248;&#21270;&#26465;&#20214;&#26799;&#24230;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Conditional Gradient-based Method for Simple Bilevel Optimization with Convex Lower-level Problem. (arXiv:2206.08868v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.08868
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21452;&#23618;&#20248;&#21270;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23616;&#37096;&#36924;&#36817;&#19979;&#23618;&#38382;&#39064;&#30340;&#35299;&#38598;&#65292;&#28982;&#21518;&#36816;&#34892;&#26465;&#20214;&#26799;&#24230;&#26356;&#26032;&#26469;&#20943;&#23569;&#19978;&#23618;&#30446;&#26631;&#20989;&#25968;&#65292;&#24182;&#19988;&#25910;&#25947;&#24615;&#20445;&#35777;&#36739;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#19968;&#31867;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#8212;&#8212;&#31616;&#21333;&#21452;&#23618;&#20248;&#21270;&#65292;&#20854;&#20013;&#25105;&#20204;&#22312;&#21478;&#19968;&#20010;&#20984;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#30340;&#26368;&#20248;&#35299;&#38598;&#19978;&#26368;&#23567;&#21270;&#24179;&#28369;&#30340;&#30446;&#26631;&#20989;&#25968;&#12290;&#24050;&#32463;&#21457;&#23637;&#20986;&#20102;&#20960;&#31181;&#36845;&#20195;&#26041;&#27861;&#26469;&#22788;&#29702;&#36825;&#31867;&#38382;&#39064;&#65292;&#20294;&#23427;&#20204;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;&#35201;&#20040;&#26159;&#19978;&#23618;&#30446;&#26631;&#30340;&#28176;&#36817;&#24615;&#65292;&#35201;&#20040;&#26159;&#25910;&#25947;&#36895;&#29575;&#32531;&#24930;&#19988;&#20122;&#20248;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21452;&#23618;&#20248;&#21270;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#20999;&#21106;&#24179;&#38754;&#23616;&#37096;&#36924;&#36817;&#19979;&#23618;&#38382;&#39064;&#30340;&#35299;&#38598;&#65292;&#28982;&#21518;&#36816;&#34892;&#26465;&#20214;&#26799;&#24230;&#26356;&#26032;&#26469;&#20943;&#23569;&#19978;&#23618;&#30446;&#26631;&#20989;&#25968;&#12290;&#24403;&#19978;&#23618;&#30446;&#26631;&#20989;&#25968;&#20026;&#20984;&#20989;&#25968;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#38656;&#35201;${\mathcal{O}}(\max\{1/\epsilon_f,1/\epsilon_g\})$&#27425;&#36845;&#20195;&#25165;&#33021;&#25214;&#21040;&#19968;&#20010;&#23545;&#20110;&#19978;&#23618; &#21644;&#19979;&#23618;&#30446;&#26631;&#20989;&#25968;&#21516;&#26102;$\epsilon_f$&#21644;$\epsilon_g$&#26368;&#20248;&#30340;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study a class of bilevel optimization problems, also known as simple bilevel optimization, where we minimize a smooth objective function over the optimal solution set of another convex constrained optimization problem. Several iterative methods have been developed for tackling this class of problems. Alas, their convergence guarantees are either asymptotic for the upper-level objective, or the convergence rates are slow and sub-optimal. To address this issue, in this paper, we introduce a novel bilevel optimization method that locally approximates the solution set of the lower-level problem via a cutting plane, and then runs a conditional gradient update to decrease the upper-level objective. When the upper-level objective is convex, we show that our method requires ${\mathcal{O}}(\max\{1/\epsilon_f,1/\epsilon_g\})$ iterations to find a solution that is $\epsilon_f$-optimal for the upper-level objective and $\epsilon_g$-optimal for the lower-level objective. Moreover,
&lt;/p&gt;</description></item><item><title>&#23545;&#20110;&#23384;&#22312;&#27169;&#22411;&#35268;&#26684;&#19981;&#20934;&#30830;&#21644;&#24322;&#24120;&#20540;&#24773;&#20917;&#19979;&#30340;&#38598;&#25104;&#23398;&#20064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#40065;&#26834;&#33258;&#30001;&#33021;&#37327;&#20934;&#21017;&#65292;&#36890;&#36807;&#23558;&#24191;&#20041;&#23545;&#25968;&#24471;&#20998;&#20989;&#25968;&#19982;PAC$^m$&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2203.01859</link><description>&lt;p&gt;
&#40065;&#26834;PAC$^m$: &#22312;&#27169;&#22411;&#35268;&#26684;&#19981;&#20934;&#30830;&#21644;&#23384;&#22312;&#24322;&#24120;&#20540;&#24773;&#20917;&#19979;&#35757;&#32451;&#38598;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Robust PAC$^m$: Training Ensemble Models Under Model Misspecification and Outliers. (arXiv:2203.01859v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.01859
&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#23384;&#22312;&#27169;&#22411;&#35268;&#26684;&#19981;&#20934;&#30830;&#21644;&#24322;&#24120;&#20540;&#24773;&#20917;&#19979;&#30340;&#38598;&#25104;&#23398;&#20064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#40065;&#26834;&#33258;&#30001;&#33021;&#37327;&#20934;&#21017;&#65292;&#36890;&#36807;&#23558;&#24191;&#20041;&#23545;&#25968;&#24471;&#20998;&#20989;&#25968;&#19982;PAC$^m$&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#36125;&#21494;&#26031;&#23398;&#20064;&#22312;&#27169;&#22411;&#35268;&#26684;&#19981;&#20934;&#30830;&#21644;&#23384;&#22312;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#24050;&#30693;&#23384;&#22312;&#27867;&#21270;&#33021;&#21147;&#30340;&#19981;&#36275;&#12290;PAC-Bayes&#29702;&#35770;&#35777;&#26126;&#20102;&#36125;&#21494;&#26031;&#23398;&#20064;&#25152;&#26368;&#23567;&#21270;&#30340;&#33258;&#30001;&#33021;&#37327;&#20934;&#21017;&#26159;&#22312;&#20551;&#35774;&#26410;&#34987;&#24322;&#24120;&#20540;&#27745;&#26579;&#30340;&#37319;&#26679;&#20998;&#24067;&#19979;&#65292;&#23545;Gibbs&#39044;&#27979;&#22120;&#65288;&#21363;&#20174;&#21518;&#39564;&#38543;&#26426;&#25277;&#21462;&#30340;&#21333;&#20010;&#27169;&#22411;&#65289;&#30340;&#27867;&#21270;&#35823;&#24046;&#30340;&#19968;&#20010;&#19978;&#30028;&#12290;&#35813;&#35266;&#28857;&#25552;&#20379;&#20102;&#36125;&#21494;&#26031;&#23398;&#20064;&#22312;&#27169;&#22411;&#35268;&#26684;&#19981;&#20934;&#30830;&#19988;&#38656;&#35201;&#38598;&#25104;&#65292;&#20197;&#21450;&#25968;&#25454;&#21463;&#21040;&#24322;&#24120;&#20540;&#24433;&#21709;&#26102;&#30340;&#23616;&#38480;&#24615;&#30340;&#35777;&#26126;&#12290;&#26368;&#36817;&#30340;&#24037;&#20316;&#20013;&#65292;&#25512;&#23548;&#20986;&#20102;PAC-Bayes&#19978;&#30028; - &#31216;&#20026;PAC$^m$ - &#24341;&#20837;&#20102;&#33258;&#30001;&#33021;&#37327;&#24230;&#37327;&#65292;&#21487;&#32771;&#34385;&#38598;&#21512;&#39044;&#27979;&#22120;&#30340;&#24615;&#33021;&#65292;&#20174;&#32780;&#33719;&#24471;&#22312;&#27169;&#22411;&#19981;&#20934;&#30830;&#30340;&#24773;&#20917;&#19979;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#40065;&#26834;&#33258;&#30001;&#33021;&#37327;&#20934;&#21017;&#65292;&#23558;&#24191;&#20041;&#23545;&#25968;&#24471;&#20998;&#20989;&#25968;&#19982;PAC$^m$&#38598;&#25104;&#19978;&#30028;&#30456;&#32467;&#21512;&#12290;&#24314;&#35758;&#30340;&#33258;&#30001;&#33021;&#37327;&#35757;&#32451;...&#65288;&#25688;&#35201;&#26410;&#23436;&#65292;&#35814;&#24773;&#35831;&#26597;&#30475;&#21407;&#25991;&#65289;
&lt;/p&gt;
&lt;p&gt;
Standard Bayesian learning is known to have suboptimal generalization capabilities under model misspecification and in the presence of outliers. PAC-Bayes theory demonstrates that the free energy criterion minimized by Bayesian learning is a bound on the generalization error for Gibbs predictors (i.e., for single models drawn at random from the posterior) under the assumption of sampling distributions uncontaminated by outliers. This viewpoint provides a justification for the limitations of Bayesian learning when the model is misspecified, requiring ensembling, and when data is affected by outliers. In recent work, PAC-Bayes bounds - referred to as PAC$^m$ - were derived to introduce free energy metrics that account for the performance of ensemble predictors, obtaining enhanced performance under misspecification. This work presents a novel robust free energy criterion that combines the generalized logarithm score function with PAC$^m$ ensemble bounds. The proposed free energy training 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#27969;&#25968;&#25454;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#36895;&#24230;&#65292;&#21253;&#25324;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#12289;&#23567;&#25209;&#37327;SG&#21644;&#26102;&#38388;&#21464;&#21270;&#30340;&#23567;&#25209;&#37327;SG&#31639;&#27861;&#20197;&#21450;&#23427;&#20204;&#30340;&#36845;&#20195;&#24179;&#22343;&#20540;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#21152;&#36895;&#25910;&#25947;&#30340;&#26041;&#27861;&#21644;&#21516;&#26102;&#25552;&#20379;&#26041;&#24046;&#20943;&#23569;&#21644;&#21152;&#36895;&#25910;&#25947;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2109.07117</link><description>&lt;p&gt;
&#27969;&#25968;&#25454;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#30340;&#38750;&#28176;&#36827;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Non-Asymptotic Analysis of Stochastic Approximation Algorithms for Streaming Data. (arXiv:2109.07117v7 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.07117
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#27969;&#25968;&#25454;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#36895;&#24230;&#65292;&#21253;&#25324;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#12289;&#23567;&#25209;&#37327;SG&#21644;&#26102;&#38388;&#21464;&#21270;&#30340;&#23567;&#25209;&#37327;SG&#31639;&#27861;&#20197;&#21450;&#23427;&#20204;&#30340;&#36845;&#20195;&#24179;&#22343;&#20540;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#21152;&#36895;&#25910;&#25947;&#30340;&#26041;&#27861;&#21644;&#21516;&#26102;&#25552;&#20379;&#26041;&#24046;&#20943;&#23569;&#21644;&#21152;&#36895;&#25910;&#25947;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#27969;&#24335;&#26694;&#26550;&#26469;&#20998;&#26512;&#38543;&#26426;&#36924;&#36817;/&#20248;&#21270;&#38382;&#39064;&#12290;&#36825;&#20010;&#27969;&#24335;&#26694;&#26550;&#31867;&#20284;&#20110;&#20351;&#29992;&#36880;&#27493;&#21040;&#36798;&#30340;&#26102;&#38388;&#21464;&#21270;&#30340;&#23567;&#25209;&#27425;&#26469;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#21508;&#31181;&#22522;&#20110;&#26799;&#24230;&#30340;&#31639;&#27861;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#36895;&#24230;&#65307;&#36825;&#21253;&#25324;&#33879;&#21517;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SG&#65289;&#31639;&#27861;&#65288;&#20063;&#31216;&#20026;Robbins-Monro&#31639;&#27861;&#65289;&#65292;&#23567;&#25209;&#37327;SG&#21644;&#26102;&#38388;&#21464;&#21270;&#30340;&#23567;&#25209;&#37327;SG&#31639;&#27861;&#65292;&#20197;&#21450;&#23427;&#20204;&#30340;&#36845;&#20195;&#24179;&#22343;&#20540;&#65288;&#20063;&#31216;&#20026;Polyak-Ruppert&#24179;&#22343;&#65289;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#65306;i&#65289;&#22914;&#20309;&#36890;&#36807;&#26681;&#25454;&#26102;&#38388;&#21464;&#21270;&#30340;&#23567;&#25209;&#27425;&#26469;&#36873;&#25321;&#23398;&#20064;&#36895;&#29575;&#26469;&#21152;&#36895;&#25910;&#25947;&#65307;ii&#65289;Polyak-Ruppert&#24179;&#22343;&#20540;&#22312;&#36798;&#21040;Cramer-Rao&#19979;&#30028;&#26041;&#38754;&#23454;&#29616;&#20102;&#26368;&#20248;&#25910;&#25947;&#65307;iii&#65289;&#26102;&#38388;&#21464;&#21270;&#30340;&#23567;&#25209;&#27425;&#19982;Polyak-Ruppert&#24179;&#22343;&#20540;&#32467;&#21512;&#20351;&#29992;&#21487;&#20197;&#21516;&#26102;&#25552;&#20379;&#26041;&#24046;&#20943;&#23569;&#21644;&#21152;&#36895;&#25910;&#25947;&#65292;&#36825;&#23545;&#20110;&#35768;&#22810;&#23398;&#20064;&#38382;&#39064;&#65288;&#22914;&#22312;&#32447;&#65292;&#39034;&#24207;&#21644;&#22823;&#35268;&#27169;&#65289;&#37117;&#26159;&#26377;&#21033;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a streaming framework for analyzing stochastic approximation/optimization problems. This streaming framework is analogous to solving optimization problems using time-varying mini-batches that arrive sequentially. We provide non-asymptotic convergence rates of various gradient-based algorithms; this includes the famous Stochastic Gradient (SG) descent (a.k.a. Robbins-Monro algorithm), mini-batch SG and time-varying mini-batch SG algorithms, as well as their iterated averages (a.k.a. Polyak-Ruppert averaging). We show i) how to accelerate convergence by choosing the learning rate according to the time-varying mini-batches, ii) that Polyak-Ruppert averaging achieves optimal convergence in terms of attaining the Cramer-Rao lower bound, and iii) how time-varying mini-batches together with Polyak-Ruppert averaging can provide variance reduction and accelerate convergence simultaneously, which is advantageous for many learning problems, such as online, sequential, and large-scale
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26080;&#38480;&#23485;&#24230;&#38480;&#21046;&#8212;&#8212;&#36125;&#21494;&#26031;&#34920;&#31034;&#23398;&#20064;&#38480;&#21046;&#65292;&#26088;&#22312;&#35299;&#20915;&#26631;&#20934;&#26080;&#38480;&#23485;&#24230;&#38480;&#21046;&#28040;&#38500;&#34920;&#31034;&#23398;&#20064;&#30340;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#31867;&#20284;&#20110;&#26377;&#38480;&#23485;&#24230;&#27169;&#22411;&#20013;&#30340;&#34920;&#31034;&#23398;&#20064;&#25928;&#26524;&#65292;&#24182;&#20445;&#30041;&#26631;&#20934;&#26080;&#38480;&#23485;&#24230;&#38480;&#21046;&#30340;&#31616;&#21333;&#24615;&#12290;</title><link>http://arxiv.org/abs/2108.13097</link><description>&lt;p&gt;
&#19968;&#31181;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#34920;&#31034;&#23398;&#20064;&#30340;&#29702;&#35770;&#32473;&#20986;&#20102;&#26680;&#26041;&#27861;&#30340;&#28145;&#24230;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
A theory of representation learning in deep neural networks gives a deep generalisation of kernel methods. (arXiv:2108.13097v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.13097
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26080;&#38480;&#23485;&#24230;&#38480;&#21046;&#8212;&#8212;&#36125;&#21494;&#26031;&#34920;&#31034;&#23398;&#20064;&#38480;&#21046;&#65292;&#26088;&#22312;&#35299;&#20915;&#26631;&#20934;&#26080;&#38480;&#23485;&#24230;&#38480;&#21046;&#28040;&#38500;&#34920;&#31034;&#23398;&#20064;&#30340;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#31867;&#20284;&#20110;&#26377;&#38480;&#23485;&#24230;&#27169;&#22411;&#20013;&#30340;&#34920;&#31034;&#23398;&#20064;&#25928;&#26524;&#65292;&#24182;&#20445;&#30041;&#26631;&#20934;&#26080;&#38480;&#23485;&#24230;&#38480;&#21046;&#30340;&#31616;&#21333;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#28145;&#24230;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#25104;&#21151;&#22522;&#20110;&#23427;&#20204;&#36328;&#22810;&#20010;&#23618;&#27425;&#23545;&#36755;&#20837;&#36827;&#34892;&#21464;&#25442;&#20197;&#24314;&#31435;&#33391;&#22909;&#30340;&#39640;&#32423;&#34920;&#31034;&#33021;&#21147;&#12290;&#22240;&#27492;&#65292;&#29702;&#35299;&#36825;&#31181;&#34920;&#31034;&#23398;&#20064;&#36807;&#31243;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#24120;&#35268;&#30340;&#29702;&#35770;&#26041;&#27861;&#65288;&#27491;&#24335;&#20026;NNGPs&#65289;&#28041;&#21450;&#26080;&#38480;&#23485;&#38480;&#21046;&#28040;&#38500;&#20102;&#34920;&#31034;&#23398;&#20064;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#26080;&#38480;&#23485;&#38480;&#21046;&#8212;&#8212;&#36125;&#21494;&#26031;&#34920;&#31034;&#23398;&#20064;&#38480;&#21046;&#65292;&#23427;&#23637;&#29616;&#20102;&#22312;&#26377;&#38480;&#23485;&#24230;&#27169;&#22411;&#20013;&#38236;&#20687;&#34920;&#31034;&#23398;&#20064;&#30340;&#25928;&#26524;&#65292;&#21516;&#26102;&#20445;&#30041;&#20102;&#19968;&#20123;&#26631;&#20934;&#26080;&#38480;&#23485;&#24230;&#38480;&#21046;&#30340;&#31616;&#21333;&#24615;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#34920;&#26126;&#22312;&#36125;&#21494;&#26031;&#34920;&#31034;&#23398;&#20064;&#26497;&#38480;&#19979;&#30340;&#28145;&#23618;&#39640;&#26031;&#36807;&#31243;&#65288;DGPs&#65289;&#20855;&#26377;&#30830;&#20999;&#30340;&#22810;&#20803;&#39640;&#26031;&#21518;&#39564;&#20998;&#24067;&#65292;&#21518;&#39564;&#21327;&#26041;&#24046;&#21487;&#20197;&#36890;&#36807;&#20248;&#21270;&#19968;&#31181;&#21487;&#35299;&#37322;&#30446;&#26631;&#24471;&#21040;&#65292;&#35813;&#30446;&#26631;&#32467;&#21512;&#20102;&#22686;&#24378;&#24615;&#33021;&#30340;&#23545;&#25968;&#20284;&#28982;&#21644;&#19968;&#31995;&#21015;&#30340;KL-&#25955;&#24230;&#65292;&#20351;&#24471;&#21518;&#39564;&#20998;&#24067;&#25509;&#36817;&#20808;&#39564;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
The successes of modern deep machine learning methods are founded on their ability to transform inputs across multiple layers to build good high-level representations. It is therefore critical to understand this process of representation learning. However, standard theoretical approaches (formally NNGPs) involving infinite width limits eliminate representation learning. We therefore develop a new infinite width limit, the Bayesian representation learning limit, that exhibits representation learning mirroring that in finite-width models, yet at the same time, retains some of the simplicity of standard infinite-width limits. In particular, we show that Deep Gaussian processes (DGPs) in the Bayesian representation learning limit have exactly multivariate Gaussian posteriors, and the posterior covariances can be obtained by optimizing an interpretable objective combining a log-likelihood to improve performance with a series of KL-divergences which keep the posteriors close to the prior. We
&lt;/p&gt;</description></item><item><title>MRCpy&#26159;&#19968;&#31181;&#29992;&#20110;&#23454;&#29616;&#26368;&#23567;&#21270;&#39118;&#38505;&#20998;&#31867;&#22120;&#30340;Python&#24211;&#65292;&#23427;&#22522;&#20110;&#40065;&#26834;&#39118;&#38505;&#26368;&#23567;&#21270;&#25216;&#26415;&#65292;&#21487;&#20197;&#21033;&#29992;0-1&#25439;&#22833;&#24182;&#25552;&#20379;&#20102;&#22810;&#31181;&#20998;&#31867;&#26041;&#27861;&#65292;&#20854;&#20013;&#19968;&#20123;&#25552;&#20379;&#20102;&#32039;&#23494;&#30340;&#26399;&#26395;&#25439;&#22833;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2108.01952</link><description>&lt;p&gt;
MRCpy&#65306;&#19968;&#31181;&#29992;&#20110;&#26368;&#23567;&#21270;&#39118;&#38505;&#20998;&#31867;&#22120;&#30340;&#24211;
&lt;/p&gt;
&lt;p&gt;
MRCpy: A Library for Minimax Risk Classifiers. (arXiv:2108.01952v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.01952
&lt;/p&gt;
&lt;p&gt;
MRCpy&#26159;&#19968;&#31181;&#29992;&#20110;&#23454;&#29616;&#26368;&#23567;&#21270;&#39118;&#38505;&#20998;&#31867;&#22120;&#30340;Python&#24211;&#65292;&#23427;&#22522;&#20110;&#40065;&#26834;&#39118;&#38505;&#26368;&#23567;&#21270;&#25216;&#26415;&#65292;&#21487;&#20197;&#21033;&#29992;0-1&#25439;&#22833;&#24182;&#25552;&#20379;&#20102;&#22810;&#31181;&#20998;&#31867;&#26041;&#27861;&#65292;&#20854;&#20013;&#19968;&#20123;&#25552;&#20379;&#20102;&#32039;&#23494;&#30340;&#26399;&#26395;&#25439;&#22833;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#29616;&#26377;&#30340;&#30417;&#30563;&#20998;&#31867;&#24211;&#37117;&#26159;&#22522;&#20110;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#21644;&#20351;&#29992;&#20195;&#29702;&#25439;&#22833;&#25216;&#26415;&#30340;&#12290;&#26412;&#25991;&#20171;&#32461;MRCpy&#24211;&#65292;&#35813;&#24211;&#23454;&#29616;&#20102;&#22522;&#20110;&#40065;&#26834;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#26368;&#23567;&#21270;&#39118;&#38505;&#20998;&#31867;&#22120;&#65288;MRC&#65289;&#65292;&#24182;&#21487;&#21033;&#29992;0-1&#25439;&#22833;&#12290;&#36825;&#31181;&#25216;&#26415;&#20135;&#29983;&#20102;&#35768;&#22810;&#20998;&#31867;&#26041;&#27861;&#65292;&#21487;&#20197;&#25552;&#20379;&#32039;&#23494;&#30340;&#26399;&#26395;&#25439;&#22833;&#30028;&#38480;&#12290;MRCpy&#20026;&#19981;&#21516;&#21464;&#37327;&#30340;MRC&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#25509;&#21475;&#65292;&#24182;&#36981;&#24490;&#27969;&#34892;Python&#24211;&#30340;&#26631;&#20934;&#12290;&#27492;&#22806;&#65292;MRCpy&#36824;&#25552;&#20379;&#20102;&#23454;&#29616;&#19968;&#20123;&#27969;&#34892;&#25216;&#26415;&#30340;&#21151;&#33021;&#65292;&#36825;&#20123;&#25216;&#26415;&#21487;&#20197;&#30475;&#20316;&#26159;MRC&#65292;&#20363;&#22914;L1&#27491;&#21017;&#21270;&#36923;&#36753;&#22238;&#24402;&#65292;0-1&#23545;&#25239;&#24615;&#21644;&#26368;&#22823;&#29109;&#26426;&#12290;&#27492;&#22806;&#65292;MRCpy&#36824;&#23454;&#29616;&#20102;&#26368;&#36817;&#30340;&#29305;&#24449;&#26144;&#23556;&#65292;&#22914;&#20613;&#37324;&#21494;&#65292;ReLU&#21644;&#38408;&#20540;&#29305;&#24449;&#12290;&#35813;&#24211;&#37319;&#29992;&#38754;&#21521;&#23545;&#35937;&#30340;&#26041;&#27861;&#35774;&#35745;&#65292;&#26041;&#20415;&#21327;&#20316;&#32773;&#21644;&#29992;&#25143;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing libraries for supervised classification implement techniques that are based on empirical risk minimization and utilize surrogate losses. We present MRCpy library that implements minimax risk classifiers (MRCs) that are based on robust risk minimization and can utilize 0-1-loss. Such techniques give rise to a manifold of classification methods that can provide tight bounds on the expected loss. MRCpy provides a unified interface for different variants of MRCs and follows the standards of popular Python libraries. The presented library also provides implementation for popular techniques that can be seen as MRCs such as L1-regularized logistic regression, zero-one adversarial, and maximum entropy machines. In addition, MRCpy implements recent feature mappings such as Fourier, ReLU, and threshold features. The library is designed with an object-oriented approach that facilitates collaborators and users.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20803;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65288;GMMs&#65289;&#40065;&#26834;&#27169;&#22411;&#36873;&#25321;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#40065;&#26834;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#23545;&#25239;&#24615;&#25200;&#21160;&#19979;&#36817;&#20284;&#27491;&#30830;&#22320;&#23398;&#20064;GMMs&#65292;&#23454;&#29616;&#20102;&#26368;&#20339;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#33021;&#22815;&#36817;&#20284;&#30830;&#23450;&#25311;&#21512;&#20998;&#24067;&#25152;&#38656;&#30340;&#26368;&#23569;&#32452;&#20214;&#25968;&#12290;</title><link>http://arxiv.org/abs/2106.02774</link><description>&lt;p&gt;
GMM&#30340;&#40065;&#26834;&#27169;&#22411;&#36873;&#25321;&#21644;&#36817;&#20284;&#27491;&#30830;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Robust Model Selection and Nearly-Proper Learning for GMMs. (arXiv:2106.02774v2 [cs.DS] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.02774
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20803;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65288;GMMs&#65289;&#40065;&#26834;&#27169;&#22411;&#36873;&#25321;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#40065;&#26834;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#23545;&#25239;&#24615;&#25200;&#21160;&#19979;&#36817;&#20284;&#27491;&#30830;&#22320;&#23398;&#20064;GMMs&#65292;&#23454;&#29616;&#20102;&#26368;&#20339;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#33021;&#22815;&#36817;&#20284;&#30830;&#23450;&#25311;&#21512;&#20998;&#24067;&#25152;&#38656;&#30340;&#26368;&#23569;&#32452;&#20214;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23398;&#20064;&#29702;&#35770;&#20013;&#65292;&#36890;&#24120;&#20551;&#23450;&#25968;&#25454;&#26159;&#20174;&#26377;&#38480;&#28151;&#21512;&#27169;&#22411;&#29983;&#25104;&#30340;&#12290;&#20294;&#26159;&#22914;&#26524;&#20107;&#20808;&#19981;&#30693;&#36947;&#32452;&#20998;&#25968;&#20250;&#21457;&#29983;&#20160;&#20040;&#21602;&#65311;&#20272;&#35745;&#32452;&#20998;&#25968;&#30340;&#38382;&#39064;&#65292;&#22312;&#26412;&#36523;&#19978;&#26159;&#24456;&#37325;&#35201;&#30340;&#65292;&#20294;&#23454;&#38469;&#19978;&#23601;&#31639;&#26159;&#27809;&#26377;&#26377;&#25928;&#31639;&#27861;&#65292;&#26356;&#19981;&#29992;&#35828;&#33021;&#23481;&#24525;&#23545;&#25239;&#24615;&#25200;&#21160;&#20102;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20803;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65288;GMMs&#65289;&#40065;&#26834;&#27169;&#22411;&#36873;&#25321;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#20250;&#20174;&#19968;&#20010;&#19982;$k$&#20010;&#32452;&#20998;&#30340;GMM $\epsilon$ -close&#30340;&#20998;&#24067;&#20013;&#20135;&#29983;$\textsf{poly}(k / \epsilon)$&#20010;&#26679;&#26412;&#65292;&#29992;$\textsf{poly}(k / \epsilon)$&#26102;&#38388;&#26500;&#24314;&#19968;&#20010;&#26377;$\widetilde{O}(k)$&#20010;&#32452;&#20214;&#30340;GMM&#65292;&#21487;&#22312;$\widetilde {O} (\epsilon)$&#20869;&#36817;&#20284;&#34920;&#31034;&#20998;&#24067;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#33021;&#22815;&#36817;&#20284;&#30830;&#23450;&#25311;&#21512;&#20998;&#24067;&#25152;&#38656;&#30340;&#26368;&#23569;&#32452;&#20214;&#25968;&#12290;&#22312;&#26412;&#30740;&#31350;&#20043;&#21069;&#65292;&#21807;&#19968;&#24050;&#30693;&#30340;&#26377;&#25928;&#31639;&#27861;&#38656;&#35201;&#33267;&#23569; $O(k \log \log n)$ &#20010;&#32452;&#20214;&#25165;&#33021;&#23436;&#25104;&#27492;&#20219;&#21153;&#65292;&#36825;&#24050;&#36817;&#20046;&#36798;&#21040;&#20102;&#26497;&#38480;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#20960;&#20046;&#26159;&#27491;&#30830;&#30340;&#65292;&#21363;&#65292;&#20854;&#20855;&#26377;&#26368;&#20248;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#20165;&#20855;&#26377;&#23545;&#25968;&#22240;&#23376;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#32467;&#26524;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#22312;&#23545;&#25239;&#25200;&#21160;&#19979;&#40065;&#26834;&#22320;&#23398;&#20064;GMMs&#12290;
&lt;/p&gt;
&lt;p&gt;
In learning theory, a standard assumption is that the data is generated from a finite mixture model. But what happens when the number of components is not known in advance? The problem of estimating the number of components, also called model selection, is important in its own right but there are essentially no known efficient algorithms with provable guarantees let alone ones that can tolerate adversarial corruptions. In this work, we study the problem of robust model selection for univariate Gaussian mixture models (GMMs). Given $\textsf{poly}(k/\epsilon)$ samples from a distribution that is $\epsilon$-close in TV distance to a GMM with $k$ components, we can construct a GMM with $\widetilde{O}(k)$ components that approximates the distribution to within $\widetilde{O}(\epsilon)$ in $\textsf{poly}(k/\epsilon)$ time. Thus we are able to approximately determine the minimum number of components needed to fit the distribution within a logarithmic factor. Prior to our work, the only known 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25311;&#21512;&#39044;&#27979;&#24605;&#24819;&#30340;&#25512;&#35770;&#26041;&#27861;&#65292;&#21487;&#20197;&#20135;&#29983;&#26657;&#20934;&#12289;&#22522;&#20110;&#21327;&#21464;&#37327;&#30340;&#29983;&#23384;&#26102;&#38388;&#30340;&#19979;&#30028;&#39044;&#27979;&#65292;&#19981;&#20381;&#36182;&#24378;&#22823;&#30340;&#24314;&#27169;&#20551;&#35774;&#65292;&#21487;&#26377;&#25928;&#36991;&#20813;&#27169;&#22411;&#38169;&#35823;&#12290;</title><link>http://arxiv.org/abs/2103.09763</link><description>&lt;p&gt;
&#25311;&#21512;&#30340;&#29983;&#23384;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Conformalized Survival Analysis. (arXiv:2103.09763v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2103.09763
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25311;&#21512;&#39044;&#27979;&#24605;&#24819;&#30340;&#25512;&#35770;&#26041;&#27861;&#65292;&#21487;&#20197;&#20135;&#29983;&#26657;&#20934;&#12289;&#22522;&#20110;&#21327;&#21464;&#37327;&#30340;&#29983;&#23384;&#26102;&#38388;&#30340;&#19979;&#30028;&#39044;&#27979;&#65292;&#19981;&#20381;&#36182;&#24378;&#22823;&#30340;&#24314;&#27169;&#20551;&#35774;&#65292;&#21487;&#26377;&#25928;&#36991;&#20813;&#27169;&#22411;&#38169;&#35823;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#29983;&#23384;&#20998;&#26512;&#25216;&#26415;&#24448;&#24448;&#20381;&#36182;&#20110;&#24378;&#22823;&#30340;&#24314;&#27169;&#20551;&#35774;&#65292;&#22240;&#27492;&#23481;&#26131;&#20986;&#29616;&#27169;&#22411;&#38169;&#35823;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25311;&#21512;&#39044;&#27979;&#24605;&#24819;&#30340;&#25512;&#35770;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#21253;&#35065;&#20219;&#20309;&#29983;&#23384;&#39044;&#27979;&#31639;&#27861;&#65292;&#20135;&#29983;&#26657;&#20934;&#12289;&#22522;&#20110;&#21327;&#21464;&#37327;&#30340;&#29983;&#23384;&#26102;&#38388;&#30340;&#19979;&#30028;&#39044;&#27979;&#12290;&#22312;&#31867;&#22411;I&#21491;&#25130;&#23614;&#35774;&#23450;&#19979;&#65292;&#24403;&#21098;&#38500;&#26102;&#38388;&#26159;&#23436;&#20840;&#22806;&#29983;&#30340;&#26102;&#65292;&#36825;&#20123;&#19979;&#30028;&#39044;&#27979;&#22312;&#26377;&#38480;&#26679;&#26412;&#20013;&#20855;&#26377;&#20445;&#35777;&#30340;&#35206;&#30422;&#29575;&#65292;&#38500;&#20102;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#25968;&#25454;&#28857;&#36825;&#19968;&#20551;&#35774;&#22806;&#65292;&#26080;&#38656;&#20219;&#20309;&#20854;&#20182;&#20551;&#35774;&#12290;&#22312;&#26356;&#19968;&#33324;&#30340;&#26465;&#20214;&#29420;&#31435;&#21098;&#38500;&#20551;&#35774;&#19979;&#65292;&#22914;&#26524;&#21098;&#38500;&#26426;&#21046;&#25110;&#26465;&#20214;&#29983;&#23384;&#20989;&#25968;&#20272;&#35745;&#33391;&#22909;&#65292;&#21017;&#36793;&#38469;&#35206;&#30422;&#29575;&#23558;&#36817;&#20046;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#24403;&#29983;&#23384;&#39044;&#27979;&#31639;&#27861;&#34987;&#38169;&#35823;&#22320;&#35268;&#23450;&#26102;&#65292;&#36825;&#20123;&#19979;&#30028;&#39044;&#27979;&#20173;&#28982;&#26377;&#25928;&#19988;&#20449;&#24687;&#20016;&#23500;&#12290;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#21644;&#21307;&#23398;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing survival analysis techniques heavily rely on strong modelling assumptions and are, therefore, prone to model misspecification errors. In this paper, we develop an inferential method based on ideas from conformal prediction, which can wrap around any survival prediction algorithm to produce calibrated, covariate-dependent lower predictive bounds on survival times. In the Type I right-censoring setting, when the censoring times are completely exogenous, the lower predictive bounds have guaranteed coverage in finite samples without any assumptions other than that of operating on independent and identically distributed data points. Under a more general conditionally independent censoring assumption, the bounds satisfy a doubly robust property which states the following: marginal coverage is approximately guaranteed if either the censoring mechanism or the conditional survival function is estimated well. Further, we demonstrate that the lower predictive bounds remain valid and info
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;IMAE&#27169;&#22411;&#29992;&#20110;&#30072;&#24418;&#35757;&#32451;&#25968;&#25454;&#30340;&#40065;&#26834;&#28145;&#24230;&#23398;&#20064;&#65292;&#36890;&#36807;&#23454;&#36341;&#35777;&#23454;&#24179;&#22343;&#32477;&#23545;&#35823;&#24046;&#65288;MAE&#65289;&#22312;&#22788;&#29702;&#31034;&#20363;&#26102;&#23384;&#22312;&#27424;&#25311;&#21512;&#38382;&#39064;&#65292;&#21033;&#29992;&#21152;&#26435;&#26041;&#24046;&#35843;&#25972;&#25552;&#39640;&#20102;&#25311;&#21512;&#33021;&#21147;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/1903.12141</link><description>&lt;p&gt;
IMAE&#29992;&#20110;&#22122;&#22768;&#40065;&#26834;&#23398;&#20064;&#65306;&#32477;&#23545;&#20540;&#35823;&#24046;&#19981;&#24179;&#31561;&#23545;&#24453;&#31034;&#20363;&#65292;&#26799;&#24230;&#22823;&#23567;&#30340;&#26041;&#24046;&#24456;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
IMAE for Noise-Robust Learning: Mean Absolute Error Does Not Treat Examples Equally and Gradient Magnitude's Variance Matters. (arXiv:1903.12141v10 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1903.12141
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;IMAE&#27169;&#22411;&#29992;&#20110;&#30072;&#24418;&#35757;&#32451;&#25968;&#25454;&#30340;&#40065;&#26834;&#28145;&#24230;&#23398;&#20064;&#65292;&#36890;&#36807;&#23454;&#36341;&#35777;&#23454;&#24179;&#22343;&#32477;&#23545;&#35823;&#24046;&#65288;MAE&#65289;&#22312;&#22788;&#29702;&#31034;&#20363;&#26102;&#23384;&#22312;&#27424;&#25311;&#21512;&#38382;&#39064;&#65292;&#21033;&#29992;&#21152;&#26435;&#26041;&#24046;&#35843;&#25972;&#25552;&#39640;&#20102;&#25311;&#21512;&#33021;&#21147;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#31034;&#20363;&#21152;&#26435;&#35282;&#24230;&#65292;&#21363;&#19982;&#23545;&#25968;&#30340;&#26799;&#24230;&#22823;&#23567;&#26469;&#30475;&#24453;&#30072;&#24418;&#35757;&#32451;&#25968;&#25454;&#30340;&#40065;&#26834;&#28145;&#24230;&#23398;&#20064;&#12290;&#25105;&#20204;&#26377;&#20004;&#20010;&#20851;&#38190;&#21457;&#29616;&#65306;&#65288;1&#65289;&#24179;&#22343;&#32477;&#23545;&#35823;&#24046;&#65288;MAE&#65289;&#19981;&#24179;&#31561;&#22320;&#22788;&#29702;&#31034;&#20363;&#12290;&#25105;&#20204;&#38024;&#23545;MAE&#36827;&#34892;&#20102;&#26032;&#30340;&#35266;&#23519;&#21644;&#28145;&#20837;&#20998;&#26512;&#65292;&#29702;&#35770;&#35777;&#26126;&#20854;&#40065;&#26834;&#24615;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#20854;&#22312;&#23454;&#36341;&#20013;&#30340;&#27424;&#25311;&#21512;&#38382;&#39064;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;MAE&#30340;&#40065;&#26834;&#24615;&#26159;&#36890;&#36807;&#24378;&#35843;&#19981;&#30830;&#23450;&#31034;&#20363;&#32780;&#19981;&#26159;&#20687;&#21069;&#20154;&#30740;&#31350;&#20013;&#25152;&#22768;&#31216;&#30340;&#37027;&#26679;&#23545;&#24453;&#35757;&#32451;&#26679;&#26412;&#26469;&#23454;&#29616;&#30340;&#12290;&#65288;2&#65289;&#26799;&#24230;&#22823;&#23567;&#30340;&#26041;&#24046;&#24456;&#37325;&#35201;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#32780;&#31616;&#21333;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20197;&#22686;&#24378;MAE&#30340;&#25311;&#21512;&#33021;&#21147;&#65292;&#21516;&#26102;&#20445;&#25345;&#20854;&#40065;&#26834;&#24615;&#12290;&#22312;&#19981;&#25913;&#21464;MAE&#30340;&#25972;&#20307;&#21152;&#26435;&#26041;&#26696;&#65288;&#21363;&#21738;&#20123;&#31034;&#20363;&#33719;&#24471;&#26356;&#39640;&#30340;&#26435;&#37325;&#65289;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#20165;&#36890;&#36807;&#38750;&#32447;&#24615;&#22320;&#25913;&#21464;&#20854;&#21152;&#26435;&#26041;&#24046;&#26469;&#23454;&#29616;&#36825;&#19968;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we study robust deep learning against abnormal training data from the perspective of example weighting built in empirical loss functions, i.e., gradient magnitude with respect to logits, an angle that is not thoroughly studied so far. Consequently, we have two key findings: (1) Mean Absolute Error (MAE) Does Not Treat Examples Equally. We present new observations and insightful analysis about MAE, which is theoretically proved to be noise-robust. First, we reveal its underfitting problem in practice. Second, we analyse that MAE's noise-robustness is from emphasising on uncertain examples instead of treating training samples equally, as claimed in prior work. (2) The Variance of Gradient Magnitude Matters. We propose an effective and simple solution to enhance MAE's fitting ability while preserving its noise-robustness. Without changing MAE's overall weighting scheme, i.e., what examples get higher weights, we simply change its weighting variance non-linearly so that the i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#24555;&#36895;&#36817;&#20284;&#35745;&#31639;&#21516;&#36136; Ising &#27169;&#22411;&#20013;&#37325;&#35201;&#37327;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#30340;&#34920;&#29616;&#22312;&#27169;&#25311;&#30740;&#31350;&#20013;&#34920;&#29616;&#33391;&#22909;&#65292;&#21487;&#29992;&#20110;&#22330;&#26223;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/1712.02195</link><description>&lt;p&gt;
&#29992;&#20110;&#22330;&#26223;&#20998;&#26512;&#30340;&#21516;&#36136; Ising &#27169;&#22411;&#30340;&#24555;&#36895;&#36817;&#20284;&#35745;&#31639;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Fast approximations in the homogeneous Ising model for use in scene analysis. (arXiv:1712.02195v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1712.02195
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#24555;&#36895;&#36817;&#20284;&#35745;&#31639;&#21516;&#36136; Ising &#27169;&#22411;&#20013;&#37325;&#35201;&#37327;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#30340;&#34920;&#29616;&#22312;&#27169;&#25311;&#30740;&#31350;&#20013;&#34920;&#29616;&#33391;&#22909;&#65292;&#21487;&#29992;&#20110;&#22330;&#26223;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Ising &#27169;&#22411;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#37117;&#24456;&#37325;&#35201;&#65292;&#20294;&#20854;&#24402;&#19968;&#21270;&#24120;&#25968;&#12289;&#27963;&#21160;&#39030;&#28857;&#25968;&#30340;&#24179;&#22343;&#20540;&#21644;&#33258;&#26059;&#30456;&#20114;&#20316;&#29992;&#30340;&#22343;&#20540;&#38590;&#20197;&#35745;&#31639;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20934;&#30830;&#30340;&#36817;&#20284;&#20540;&#65292;&#20351;&#24471;&#22312;&#21516;&#36136;&#24773;&#20917;&#19979;&#21487;&#20197;&#25968;&#20540;&#35745;&#31639;&#36825;&#20123;&#37327;&#12290;&#27169;&#25311;&#30740;&#31350;&#34920;&#26126;&#65292;&#19982;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24615;&#33021;&#33391;&#22909;&#65292;&#19988;&#25152;&#38656;&#26102;&#38388;&#21482;&#26159;&#37027;&#20123;&#38543;&#26426;&#26041;&#27861;&#30340;&#19968;&#23567;&#37096;&#20998;&#12290;&#25105;&#20204;&#30340;&#36817;&#20284;&#20540;&#22312;&#25191;&#34892;&#21151;&#33021;&#30913;&#20849;&#25391;&#28608;&#27963;&#26816;&#27979;&#23454;&#39564;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#20197;&#21450;&#26893;&#29289;&#29983;&#20135;&#20013;&#24180;&#22686;&#37327;&#31354;&#38388;&#22270;&#26696;&#30340;&#21508;&#21521;&#24322;&#24615;&#30340;&#20284;&#28982;&#27604;&#26816;&#39564;&#20013;&#24471;&#21040;&#20102;&#20307;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Ising model is important in statistical modeling and inference in many applications, however its normalizing constant, mean number of active vertices and mean spin interaction are intractable to compute. We provide accurate approximations that make it possible to numerically calculate these quantities in the homogeneous case. Simulation studies indicate good performance when compared to Markov Chain Monte Carlo methods and at a tiny fraction of the time taken by those stochastic approaches. The value of our approximations is illustrated in performing Bayesian inference in a functional Magnetic Resonance Imaging activation detection experiment, and also in likelihood ratio testing for anisotropy in the spatial patterns of yearly increases in pistachio tree yields.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#21517;&#20026;&#27169;&#25311;&#22120;&#30340;&#26032;&#25216;&#26415;&#29992;&#20110;&#20998;&#26512;&#33258;&#36866;&#24212;&#37319;&#26679;&#12290;&#23558;&#37325;&#28857;&#25918;&#22312;&#20102;&#21306;&#20998;&#22909;&#30340;&#37319;&#26679;&#31574;&#30053;&#21644;&#22351;&#37319;&#26679;&#31574;&#30053;&#30340;&#38590;&#24230;&#19978;&#12290;&#22312;&#32431;&#25506;&#32034;&#22330;&#26223;&#30340;&#32467;&#26500;&#21270;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#20013;&#24212;&#29992;&#20102;&#35813;&#25216;&#26415;&#65292;&#23637;&#31034;&#20102;&#26377;&#20013;&#31561;&#32622;&#20449;&#24230;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#21644;&#25991;&#29486;&#20013;&#22312; $\delta \to 0$ &#26102;&#24471;&#21040;&#30340;&#28176;&#36817;&#22797;&#26434;&#24230;&#20043;&#38388;&#23384;&#22312;&#30528;&#23454;&#36136;&#24615;&#24046;&#24322;&#65292;&#24182;&#19988;&#36824;&#35777;&#26126;&#20102;&#20316;&#20026;&#39030;&#37096;-k&#38382;&#39064;&#30340;&#31532;&#19968;&#20010;&#22522;&#20110;&#23454;&#20363;&#30340;&#19979;&#30028;&#12290;</title><link>http://arxiv.org/abs/1702.05186</link><description>&lt;p&gt;
&#27169;&#25311;&#22120;&#65306;&#29702;&#35299;&#22312;&#20013;&#31561;&#32622;&#20449;&#24230;&#26465;&#20214;&#19979;&#30340;&#33258;&#36866;&#24212;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
The Simulator: Understanding Adaptive Sampling in the Moderate-Confidence Regime. (arXiv:1702.05186v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1702.05186
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#21517;&#20026;&#27169;&#25311;&#22120;&#30340;&#26032;&#25216;&#26415;&#29992;&#20110;&#20998;&#26512;&#33258;&#36866;&#24212;&#37319;&#26679;&#12290;&#23558;&#37325;&#28857;&#25918;&#22312;&#20102;&#21306;&#20998;&#22909;&#30340;&#37319;&#26679;&#31574;&#30053;&#21644;&#22351;&#37319;&#26679;&#31574;&#30053;&#30340;&#38590;&#24230;&#19978;&#12290;&#22312;&#32431;&#25506;&#32034;&#22330;&#26223;&#30340;&#32467;&#26500;&#21270;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#20013;&#24212;&#29992;&#20102;&#35813;&#25216;&#26415;&#65292;&#23637;&#31034;&#20102;&#26377;&#20013;&#31561;&#32622;&#20449;&#24230;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#21644;&#25991;&#29486;&#20013;&#22312; $\delta \to 0$ &#26102;&#24471;&#21040;&#30340;&#28176;&#36817;&#22797;&#26434;&#24230;&#20043;&#38388;&#23384;&#22312;&#30528;&#23454;&#36136;&#24615;&#24046;&#24322;&#65292;&#24182;&#19988;&#36824;&#35777;&#26126;&#20102;&#20316;&#20026;&#39030;&#37096;-k&#38382;&#39064;&#30340;&#31532;&#19968;&#20010;&#22522;&#20110;&#23454;&#20363;&#30340;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25216;&#26415;&#65292;&#31216;&#20026;&#8220;&#27169;&#25311;&#22120;&#8221;&#65292;&#29992;&#20110;&#20998;&#26512;&#33258;&#36866;&#24212;&#37319;&#26679;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#65292;&#23427;&#19981;&#32771;&#34385;&#20219;&#20309;&#22266;&#23450;&#37319;&#26679;&#31574;&#30053;&#21487;&#20197;&#25910;&#38598;&#22810;&#23569;&#20449;&#24687;&#65292;&#32780;&#26159;&#32771;&#34385;&#22312;&#32473;&#23450;&#30340;&#26377;&#38480;&#25968;&#25454;&#25910;&#38598;&#26102;&#38388;&#20869;&#65292;&#21306;&#20998;&#22909;&#30340;&#37319;&#26679;&#31574;&#30053;&#21644;&#22351;&#30340;&#37319;&#26679;&#31574;&#30053;&#26377;&#22810;&#38590;&#12290;&#36825;&#31181;&#35270;&#35282;&#30340;&#25913;&#21464;&#20351;&#25105;&#20204;&#33021;&#22815;&#21305;&#37197;Fano&#21644;&#21464;&#37327;&#27979;&#37327;&#25216;&#26415;&#30340;&#20248;&#28857;&#65292;&#32780;&#19981;&#20250;&#38519;&#20837;&#20219;&#20309;&#19968;&#31181;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#20013;&#12290;&#20026;&#20102;&#20855;&#20307;&#35828;&#26126;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#25216;&#26415;&#24212;&#29992;&#21040;&#20102;&#19968;&#20010;&#22266;&#23450;&#32622;&#20449;&#27700;&#24179;&#30340;&#32431;&#25506;&#32034;&#22330;&#26223;&#20013;&#30340;&#32467;&#26500;&#21270;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#22343;&#20540;&#38480;&#21046;&#19979;&#65292;&#26377;&#20013;&#31561;&#32622;&#20449;&#24230;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#21644;&#25991;&#29486;&#20013;&#22312; $\delta \to 0$ &#26102;&#24471;&#21040;&#30340;&#28176;&#36817;&#22797;&#26434;&#24230;&#20043;&#38388;&#23384;&#22312;&#30528;&#23454;&#36136;&#24615;&#24046;&#24322;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#20316;&#20026;&#39030;&#37096;-k&#38382;&#39064;&#30340;&#31532;&#19968;&#20010;&#22522;&#20110;&#23454;&#20363;&#30340;&#19979;&#30028;&#65292;&#20854;&#21253;&#25324;&#36866;&#24403;&#30340;&#23545;&#25968;&#22240;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel technique for analyzing adaptive sampling called the {\em Simulator}. Our approach differs from the existing methods by considering not how much information could be gathered by any fixed sampling strategy, but how difficult it is to distinguish a good sampling strategy from a bad one given the limited amount of data collected up to any given time. This change of perspective allows us to match the strength of both Fano and change-of-measure techniques, without succumbing to the limitations of either method. For concreteness, we apply our techniques to a structured multi-arm bandit problem in the fixed-confidence pure exploration setting, where we show that the constraints on the means imply a substantial gap between the moderate-confidence sample complexity, and the asymptotic sample complexity as $\delta \to 0$ found in the literature. We also prove the first instance-based lower bounds for the top-k problem which incorporate the appropriate log-factors. Moreover, o
&lt;/p&gt;</description></item></channel></rss>