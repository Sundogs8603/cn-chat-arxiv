<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>SciRE-Solver&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;&#37319;&#26679;&#22120;&#65292;&#36890;&#36807;&#24341;&#20837;&#24471;&#20998;&#31215;&#20998;&#27714;&#35299;&#22120;&#21644;&#36882;&#24402;&#23548;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#23427;&#35299;&#20915;&#20102;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#37319;&#26679;&#36807;&#31243;&#32531;&#24930;&#30340;&#25361;&#25112;&#65292;&#24182;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#37319;&#26679;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.07896</link><description>&lt;p&gt;
SciRE-Solver: &#29992;&#24471;&#20998;&#31215;&#20998;&#27714;&#35299;&#22120;&#21644;&#36882;&#24402;&#23548;&#25968;&#20272;&#35745;&#24555;&#36895;&#37319;&#26679;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
SciRE-Solver: Efficient Sampling of Diffusion Probabilistic Models by Score-integrand Solver with Recursive Derivative Estimation. (arXiv:2308.07896v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07896
&lt;/p&gt;
&lt;p&gt;
SciRE-Solver&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;&#37319;&#26679;&#22120;&#65292;&#36890;&#36807;&#24341;&#20837;&#24471;&#20998;&#31215;&#20998;&#27714;&#35299;&#22120;&#21644;&#36882;&#24402;&#23548;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#23427;&#35299;&#20915;&#20102;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#37319;&#26679;&#36807;&#31243;&#32531;&#24930;&#30340;&#25361;&#25112;&#65292;&#24182;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#37319;&#26679;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;(DPMs)&#26159;&#19968;&#31867;&#24378;&#22823;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#20197;&#20854;&#29983;&#25104;&#39640;&#20445;&#30495;&#22270;&#20687;&#26679;&#26412;&#30340;&#33021;&#21147;&#32780;&#38395;&#21517;&#12290;DPMs&#30340;&#23454;&#29616;&#38754;&#20020;&#30340;&#20027;&#35201;&#25361;&#25112;&#26159;&#37319;&#26679;&#36807;&#31243;&#32531;&#24930;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;DPMs&#37319;&#26679;&#22120;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#38024;&#23545;&#19982;DPMs&#37319;&#26679;&#36807;&#31243;&#23545;&#24212;&#30340;&#25193;&#25955;ODE&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#24471;&#20998;&#30340;&#31934;&#30830;&#35299;&#20915;&#26041;&#26696;&#33539;&#24335;&#65292;&#35813;&#33539;&#24335;&#20026;&#27714;&#35299;&#25193;&#25955;ODE&#30340;&#25968;&#20540;&#31639;&#27861;&#24320;&#21457;&#25552;&#20379;&#20102;&#26032;&#30340;&#35270;&#35282;&#12290;&#20026;&#20102;&#23454;&#29616;&#39640;&#25928;&#30340;&#37319;&#26679;&#22120;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36882;&#24402;&#23548;&#25968;&#20272;&#35745;(RDE)&#26041;&#27861;&#26469;&#20943;&#23567;&#20272;&#35745;&#35823;&#24046;&#12290;&#36890;&#36807;&#25105;&#20204;&#25552;&#20986;&#30340;&#35299;&#20915;&#26041;&#26696;&#33539;&#24335;&#21644;RDE&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20855;&#26377;&#25910;&#25947;&#39034;&#24207;&#20445;&#35777;&#30340;&#24471;&#20998;&#31215;&#20998;&#27714;&#35299;&#22120;(SciRE-Solver)&#26469;&#35299;&#20915;&#25193;&#25955;ODEs&#12290;SciRE-Solver&#22312;&#31163;&#25955;&#26102;&#38388;&#21644;&#36830;&#32493;&#26102;&#38388;DPMs&#19978;&#33719;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#37319;&#26679;&#24615;&#33021;&#65292;&#24182;&#19988;&#20165;&#38656;&#26377;&#38480;&#25968;&#37327;&#30340;&#24471;&#20998;&#20989;&#25968;&#35780;&#20272;(NFE)&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion probabilistic models (DPMs) are a powerful class of generative models known for their ability to generate high-fidelity image samples. A major challenge in the implementation of DPMs is the slow sampling process. In this work, we bring a high-efficiency sampler for DPMs. Specifically, we propose a score-based exact solution paradigm for the diffusion ODEs corresponding to the sampling process of DPMs, which introduces a new perspective on developing numerical algorithms for solving diffusion ODEs. To achieve an efficient sampler, we propose a recursive derivative estimation (RDE) method to reduce the estimation error. With our proposed solution paradigm and RDE method, we propose the score-integrand solver with the convergence order guarantee as efficient solver (SciRE-Solver) for solving diffusion ODEs. The SciRE-Solver attains state-of-the-art (SOTA) sampling performance with a limited number of score function evaluations (NFE) on both discrete-time and continuous-time DPMs
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#20272;&#35745;Radon-Nikodym&#23548;&#25968;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#27491;&#21017;&#21270;&#26041;&#26696;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;&#36890;&#36807;&#32771;&#34385;&#23548;&#25968;&#30340;&#24179;&#28369;&#24230;&#21644;&#20272;&#35745;&#31354;&#38388;&#30340;&#23481;&#37327;&#65292;&#24314;&#31435;&#20102;&#30456;&#24212;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#25968;&#20540;&#27169;&#25311;&#36827;&#19968;&#27493;&#39564;&#35777;&#20102;&#29702;&#35770;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.07887</link><description>&lt;p&gt;
&#20851;&#20110;&#27491;&#21017;&#21270;&#30340;Radon-Nikodym&#23548;&#25968;
&lt;/p&gt;
&lt;p&gt;
On regularized Radon-Nikodym differentiation. (arXiv:2308.07887v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07887
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#20272;&#35745;Radon-Nikodym&#23548;&#25968;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#27491;&#21017;&#21270;&#26041;&#26696;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;&#36890;&#36807;&#32771;&#34385;&#23548;&#25968;&#30340;&#24179;&#28369;&#24230;&#21644;&#20272;&#35745;&#31354;&#38388;&#30340;&#23481;&#37327;&#65292;&#24314;&#31435;&#20102;&#30456;&#24212;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#25968;&#20540;&#27169;&#25311;&#36827;&#19968;&#27493;&#39564;&#35777;&#20102;&#29702;&#35770;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#20272;&#35745;Radon-Nikodym&#23548;&#25968;&#30340;&#38382;&#39064;&#12290;&#36825;&#20010;&#38382;&#39064;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#20986;&#29616;&#65292;&#27604;&#22914;&#21327;&#21464;&#37327;&#20559;&#31227;&#36866;&#24212;&#12289;&#20284;&#28982;&#27604;&#26816;&#39564;&#12289;&#20114;&#20449;&#24687;&#20272;&#35745;&#21644;&#26465;&#20214;&#27010;&#29575;&#20272;&#35745;&#12290;&#20026;&#20102;&#35299;&#20915;&#19978;&#36848;&#38382;&#39064;&#65292;&#25105;&#20204;&#37319;&#29992;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#19968;&#33324;&#27491;&#21017;&#21270;&#26041;&#26696;&#12290;&#36890;&#36807;&#32771;&#34385;&#23548;&#25968;&#30340;&#24179;&#28369;&#24230;&#21644;&#20272;&#35745;&#23427;&#30340;&#31354;&#38388;&#30340;&#23481;&#37327;&#65292;&#24314;&#31435;&#20102;&#30456;&#24212;&#27491;&#21017;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#36825;&#26159;&#20197;&#19968;&#33324;&#28304;&#26465;&#20214;&#21644;&#27491;&#21017;&#21270;&#30340;Christoffel&#20989;&#25968;&#20026;&#22522;&#30784;&#30340;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#65292;&#22312;&#20219;&#20309;&#29305;&#23450;&#28857;&#19978;&#37325;&#24314;Radon-Nikodym&#23548;&#25968;&#21487;&#20197;&#20855;&#26377;&#39640;&#31934;&#24230;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#36890;&#36807;&#25968;&#20540;&#27169;&#25311;&#36827;&#34892;&#20102;&#35828;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
We discuss the problem of estimating Radon-Nikodym derivatives. This problem appears in various applications, such as covariate shift adaptation, likelihood-ratio testing, mutual information estimation, and conditional probability estimation. To address the above problem, we employ the general regularization scheme in reproducing kernel Hilbert spaces. The convergence rate of the corresponding regularized algorithm is established by taking into account both the smoothness of the derivative and the capacity of the space in which it is estimated. This is done in terms of general source conditions and the regularized Christoffel functions. We also find that the reconstruction of Radon-Nikodym derivatives at any particular point can be done with high order of accuracy. Our theoretical results are illustrated by numerical simulations.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#31216;&#20026;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#29992;&#20110;&#26681;&#25454;&#19978;&#19979;&#25991;&#22240;&#32032;&#21644;&#30446;&#26631;&#20154;&#19982;&#20854;&#29031;&#39038;&#20276;&#20387;&#30340;&#36807;&#21435;&#21453;&#39304;&#65292;&#20010;&#24615;&#21270;&#22320;&#25552;&#20379;&#24178;&#39044;&#25514;&#26045;&#12290;&#35813;&#31639;&#27861;&#26159;&#36125;&#21494;&#26031;&#21644;&#23618;&#27425;&#30340;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#23637;&#31034;&#20102;&#33391;&#22909;&#30340;&#23454;&#35777;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.07843</link><description>&lt;p&gt;
Dyadic Reinforcement Learning. (arXiv:2308.07843v1 [cs.LG]) &#35813;&#35770;&#25991;&#26631;&#39064;&#24050;&#32763;&#35793;&#65306;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dyadic Reinforcement Learning. (arXiv:2308.07843v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07843
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#31216;&#20026;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#29992;&#20110;&#26681;&#25454;&#19978;&#19979;&#25991;&#22240;&#32032;&#21644;&#30446;&#26631;&#20154;&#19982;&#20854;&#29031;&#39038;&#20276;&#20387;&#30340;&#36807;&#21435;&#21453;&#39304;&#65292;&#20010;&#24615;&#21270;&#22320;&#25552;&#20379;&#24178;&#39044;&#25514;&#26045;&#12290;&#35813;&#31639;&#27861;&#26159;&#36125;&#21494;&#26031;&#21644;&#23618;&#27425;&#30340;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#23637;&#31034;&#20102;&#33391;&#22909;&#30340;&#23454;&#35777;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31227;&#21160;&#21307;&#30103;&#26088;&#22312;&#36890;&#36807;&#22312;&#20010;&#20154;&#26085;&#24120;&#29983;&#27963;&#20013;&#25552;&#20379;&#24178;&#39044;&#26469;&#25552;&#39640;&#20581;&#24247;&#32467;&#26524;&#12290;&#29031;&#39038;&#20276;&#20387;&#21644;&#31038;&#20250;&#25903;&#25345;&#32593;&#32476;&#30340;&#21442;&#19982;&#32463;&#24120;&#22312;&#24110;&#21161;&#20010;&#20154;&#31649;&#29702;&#32321;&#37325;&#30340;&#21307;&#30103;&#26465;&#20214;&#26041;&#38754;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#36825;&#20026;&#31227;&#21160;&#21307;&#30103;&#25552;&#20379;&#20102;&#26426;&#20250;&#65292;&#35774;&#35745;&#38024;&#23545;&#20108;&#20803;&#20851;&#31995;&#8212;&#8212;&#30446;&#26631;&#20154;&#21644;&#20854;&#29031;&#39038;&#20276;&#20387;&#20043;&#38388;&#20851;&#31995;&#8212;&#8212;&#20197;&#25552;&#39640;&#31038;&#20250;&#25903;&#25345;&#30340;&#24178;&#39044;&#25514;&#26045;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#65288;Dyadic RL&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#29615;&#22659;&#22240;&#32032;&#21644;&#30446;&#26631;&#20154;&#21450;&#20854;&#29031;&#39038;&#20276;&#20387;&#30340;&#36807;&#21435;&#21453;&#39304;&#20010;&#24615;&#21270;&#24178;&#39044;&#25514;&#26045;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#12290;&#22312;&#36825;&#37324;&#65292;&#22810;&#32452;&#24178;&#39044;&#25514;&#26045;&#24433;&#21709;&#30528;&#20108;&#20803;&#20851;&#31995;&#22312;&#22810;&#20010;&#26102;&#38388;&#38388;&#38548;&#20869;&#12290;&#24320;&#21457;&#30340;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#26159;&#36125;&#21494;&#26031;&#21644;&#23618;&#27425;&#30340;&#12290;&#25105;&#20204;&#27491;&#24335;&#20171;&#32461;&#20102;&#38382;&#39064;&#35774;&#23450;&#65292;&#24320;&#21457;&#20102;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#24182;&#30830;&#23450;&#20102;&#36951;&#25022;&#36793;&#30028;&#12290;&#36890;&#36807;&#27169;&#25311;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#30340;&#23454;&#35777;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mobile health aims to enhance health outcomes by delivering interventions to individuals as they go about their daily life. The involvement of care partners and social support networks often proves crucial in helping individuals managing burdensome medical conditions. This presents opportunities in mobile health to design interventions that target the dyadic relationship -- the relationship between a target person and their care partner -- with the aim of enhancing social support. In this paper, we develop dyadic RL, an online reinforcement learning algorithm designed to personalize intervention delivery based on contextual factors and past responses of a target person and their care partner. Here, multiple sets of interventions impact the dyad across multiple time intervals. The developed dyadic RL is Bayesian and hierarchical. We formally introduce the problem setup, develop dyadic RL and establish a regret bound. We demonstrate dyadic RL's empirical performance through simulation st
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#32508;&#36848;&#30740;&#31350;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#38754;&#20020;&#30340;&#23545;&#25239;&#24615;&#25915;&#20987;&#65292;&#25506;&#35752;&#20102;&#25915;&#20987;&#31867;&#22411;&#12289;&#25915;&#20987;&#32773;&#30446;&#30340;&#20197;&#21450;&#40657;&#30333;&#30418;&#25915;&#20987;&#30340;&#21306;&#21035;&#65292;&#24182;&#24378;&#35843;&#20102;&#23545;&#25239;&#26679;&#26412;&#30340;&#20256;&#36882;&#24615;&#21644;&#29616;&#23454;&#24212;&#29992;&#30340;&#21487;&#34892;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.07673</link><description>&lt;p&gt;
&#35745;&#31639;&#26426;&#35270;&#35273;&#20013;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Review of Adversarial Attacks in Computer Vision. (arXiv:2308.07673v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07673
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#32508;&#36848;&#30740;&#31350;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#38754;&#20020;&#30340;&#23545;&#25239;&#24615;&#25915;&#20987;&#65292;&#25506;&#35752;&#20102;&#25915;&#20987;&#31867;&#22411;&#12289;&#25915;&#20987;&#32773;&#30446;&#30340;&#20197;&#21450;&#40657;&#30333;&#30418;&#25915;&#20987;&#30340;&#21306;&#21035;&#65292;&#24182;&#24378;&#35843;&#20102;&#23545;&#25239;&#26679;&#26412;&#30340;&#20256;&#36882;&#24615;&#21644;&#29616;&#23454;&#24212;&#29992;&#30340;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#20013;&#34987;&#24191;&#27867;&#24212;&#29992;&#65292;&#29305;&#21035;&#26159;&#22312;&#20687;&#33258;&#21160;&#39550;&#39542;&#36825;&#26679;&#30340;&#23433;&#20840;&#20851;&#38190;&#22330;&#26223;&#20013;&#65292;&#20294;&#28145;&#24230;&#32593;&#32476;&#32463;&#24120;&#21463;&#21040;&#23545;&#25239;&#26679;&#26412;&#30340;&#23041;&#32961;&#12290;&#36825;&#31181;&#23545;&#25239;&#24615;&#25915;&#20987;&#23545;&#20154;&#30524;&#26469;&#35828;&#26159;&#30475;&#19981;&#35265;&#30340;&#65292;&#20294;&#21364;&#20250;&#23548;&#33268;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#35823;&#20998;&#31867;&#65292;&#24182;&#19988;&#22312;&#28145;&#24230;&#23398;&#20064;&#21644;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20197;&#21450;&#29616;&#23454;&#29615;&#22659;&#20013;&#20855;&#26377;&#20256;&#36882;&#24615;&#12290;&#23545;&#25239;&#24615;&#25915;&#20987;&#21487;&#20197;&#20998;&#20026;&#30333;&#30418;&#25915;&#20987;&#65292;&#25915;&#20987;&#32773;&#30693;&#36947;&#27169;&#22411;&#30340;&#21442;&#25968;&#21644;&#26799;&#24230;&#65307;&#20197;&#21450;&#40657;&#30418;&#25915;&#20987;&#65292;&#25915;&#20987;&#32773;&#21482;&#33021;&#33719;&#21462;&#27169;&#22411;&#30340;&#36755;&#20837;&#21644;&#36755;&#20986;&#12290;&#26681;&#25454;&#25915;&#20987;&#32773;&#30340;&#30446;&#30340;&#65292;&#21487;&#20197;&#20998;&#20026;&#26377;&#30446;&#26631;&#25915;&#20987;&#21644;&#38750;&#30446;&#26631;&#25915;&#20987;&#65292;&#21069;&#32773;&#26159;&#25351;&#25915;&#20987;&#32773;&#24076;&#26395;&#27169;&#22411;&#23558;&#21407;&#22987;&#26679;&#26412;&#38169;&#35823;&#20998;&#31867;&#20026;&#25351;&#23450;&#30340;&#31867;&#65292;&#36825;&#26356;&#23454;&#38469;&#65307;&#32780;&#38750;&#30446;&#26631;&#25915;&#20987;&#21482;&#38656;&#35753;&#27169;&#22411;&#23558;&#26679;&#26412;&#38169;&#35823;&#20998;&#31867;&#21363;&#21487;&#12290;&#40657;&#30418;&#35774;&#32622;&#26159;&#19968;&#31181;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks have been widely used in various downstream tasks, especially those safety-critical scenario such as autonomous driving, but deep networks are often threatened by adversarial samples. Such adversarial attacks can be invisible to human eyes, but can lead to DNN misclassification, and often exhibits transferability between deep learning and machine learning models and real-world achievability. Adversarial attacks can be divided into white-box attacks, for which the attacker knows the parameters and gradient of the model, and black-box attacks, for the latter, the attacker can only obtain the input and output of the model. In terms of the attacker's purpose, it can be divided into targeted attacks and non-targeted attacks, which means that the attacker wants the model to misclassify the original sample into the specified class, which is more practical, while the non-targeted attack just needs to make the model misclassify the sample. The black box setting is a scenari
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#38543;&#26426;&#31616;&#21333;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26080;&#25237;&#24433;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#38543;&#26426;&#21106;&#24179;&#38754;&#36817;&#20284;&#35299;&#20915;&#26041;&#26696;&#38598;&#65292;&#28982;&#21518;&#20351;&#29992;&#26041;&#24046;&#32553;&#20943;&#25216;&#26415;&#36827;&#34892;&#26465;&#20214;&#26799;&#24230;&#26356;&#26032;&#26469;&#25511;&#21046;&#35823;&#24046;&#12290;&#22312;&#19978;&#23618;&#20026;&#20984;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#22312;$\tilde{\mathcal{O}}(\max\{1/\epsilon_f^{2},1/\epsilon_g^{2}\})$&#20010;&#26597;&#35810;&#20013;&#33719;&#24471;$\epsilon_f$-&#26368;&#20248;&#30340;&#19978;&#23618;&#35299;&#21644;$\epsilon_g$-&#26368;&#20248;&#30340;&#19979;&#23618;&#35299;&#65292;&#36825;&#19968;&#20445;&#35777;&#25913;&#36827;&#20102;&#20808;&#21069;&#24050;&#30693;&#30340;&#22797;&#26434;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.07536</link><description>&lt;p&gt;
&#26080;&#25237;&#24433;&#26041;&#27861;&#27714;&#35299;&#20855;&#26377;&#20984;&#19979;&#23618;&#38382;&#39064;&#30340;&#38543;&#26426;&#31616;&#21333;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Projection-Free Methods for Stochastic Simple Bilevel Optimization with Convex Lower-level Problem. (arXiv:2308.07536v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07536
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#38543;&#26426;&#31616;&#21333;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26080;&#25237;&#24433;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#38543;&#26426;&#21106;&#24179;&#38754;&#36817;&#20284;&#35299;&#20915;&#26041;&#26696;&#38598;&#65292;&#28982;&#21518;&#20351;&#29992;&#26041;&#24046;&#32553;&#20943;&#25216;&#26415;&#36827;&#34892;&#26465;&#20214;&#26799;&#24230;&#26356;&#26032;&#26469;&#25511;&#21046;&#35823;&#24046;&#12290;&#22312;&#19978;&#23618;&#20026;&#20984;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#22312;$\tilde{\mathcal{O}}(\max\{1/\epsilon_f^{2},1/\epsilon_g^{2}\})$&#20010;&#26597;&#35810;&#20013;&#33719;&#24471;$\epsilon_f$-&#26368;&#20248;&#30340;&#19978;&#23618;&#35299;&#21644;$\epsilon_g$-&#26368;&#20248;&#30340;&#19979;&#23618;&#35299;&#65292;&#36825;&#19968;&#20445;&#35777;&#25913;&#36827;&#20102;&#20808;&#21069;&#24050;&#30693;&#30340;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#38543;&#26426;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#20063;&#31216;&#20026;&#38543;&#26426;&#31616;&#21333;&#21452;&#23618;&#20248;&#21270;&#65292;&#22312;&#36825;&#31867;&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#26368;&#23567;&#21270;&#21478;&#19968;&#20010;&#38543;&#26426;&#20984;&#20248;&#21270;&#38382;&#39064;&#30340;&#26368;&#20248;&#35299;&#38598;&#19978;&#30340;&#19968;&#20010;&#20809;&#28369;&#38543;&#26426;&#30446;&#26631;&#20989;&#25968;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38543;&#26426;&#21452;&#23618;&#20248;&#21270;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#38543;&#26426;&#21106;&#24179;&#38754;&#23616;&#37096;&#36817;&#20284;&#19979;&#23618;&#38382;&#39064;&#30340;&#35299;&#38598;&#65292;&#24182;&#20351;&#29992;&#26041;&#24046;&#32553;&#20943;&#25216;&#26415;&#36827;&#34892;&#26465;&#20214;&#26799;&#24230;&#26356;&#26032;&#20197;&#25511;&#21046;&#30001;&#20110;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#32780;&#24341;&#20837;&#30340;&#35823;&#24046;&#12290;&#24403;&#19978;&#23618;&#20989;&#25968;&#20026;&#20984;&#20989;&#25968;&#26102;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#38656;&#35201;$\tilde{\mathcal{O}}(\max\{1/\epsilon_f^{2},1/\epsilon_g^{2}\})$&#20010;&#38543;&#26426;&#39044;&#35328;&#26426;&#26597;&#35810;&#25165;&#33021;&#33719;&#24471;&#19978;&#23618;&#20026;$\epsilon_f$&#26368;&#20248;&#65292;&#19979;&#23618;&#20026;$\epsilon_g$&#26368;&#20248;&#30340;&#35299;&#12290;&#36825;&#20010;&#20445;&#35777;&#25913;&#36827;&#20102;&#20808;&#21069;&#26368;&#22909;&#24050;&#30693;&#22797;&#26434;&#24615;$\mathcal{O}(\max\{1/\epsilon_f^{4},1/\epsilon_g^{4}\})$&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#19978;&#23618;&#20026;&#20984;&#20989;&#25968;&#30340;&#24773;&#20917;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20013;&#30340;&#35770;&#25991;&#20855;&#26377;&#22810;&#20010;&#21019;&#26032;&#21644;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study a class of stochastic bilevel optimization problems, also known as stochastic simple bilevel optimization, where we minimize a smooth stochastic objective function over the optimal solution set of another stochastic convex optimization problem. We introduce novel stochastic bilevel optimization methods that locally approximate the solution set of the lower-level problem via a stochastic cutting plane, and then run a conditional gradient update with variance reduction techniques to control the error induced by using stochastic gradients. For the case that the upper-level function is convex, our method requires $\tilde{\mathcal{O}}(\max\{1/\epsilon_f^{2},1/\epsilon_g^{2}\}) $ stochastic oracle queries to obtain a solution that is $\epsilon_f$-optimal for the upper-level and $\epsilon_g$-optimal for the lower-level. This guarantee improves the previous best-known complexity of $\mathcal{O}(\max\{1/\epsilon_f^{4},1/\epsilon_g^{4}\})$. Moreover, for the case that the
&lt;/p&gt;</description></item><item><title>&#28145;&#23618;&#25805;&#20316;&#31526;&#32593;&#32476;&#65288;DeepONet&#65289;&#20316;&#20026;&#19968;&#31181;&#24378;&#22823;&#30340;&#26367;&#20195;&#24314;&#27169;&#26041;&#27861;&#65292;&#22312;&#26680;&#31995;&#32479;&#25968;&#23383;&#23402;&#29983;&#25216;&#26415;&#20013;&#23637;&#31034;&#20986;&#20102;&#26174;&#33879;&#30340;&#39044;&#27979;&#31934;&#24230;&#21644;&#35745;&#31639;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#25361;&#25112;&#20173;&#28982;&#23384;&#22312;&#65292;&#21253;&#25324;&#26368;&#20339;&#20256;&#24863;&#22120;&#25918;&#32622;&#21644;&#27169;&#22411;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2308.07523</link><description>&lt;p&gt;
&#28145;&#23618;&#25805;&#20316;&#31526;&#32593;&#32476;&#22312;&#26680;&#31995;&#32479;&#25968;&#23383;&#23402;&#29983;&#25216;&#26415;&#20013;&#30340;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;
Potential of Deep Operator Networks in Digital Twin-enabling Technology for Nuclear System. (arXiv:2308.07523v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07523
&lt;/p&gt;
&lt;p&gt;
&#28145;&#23618;&#25805;&#20316;&#31526;&#32593;&#32476;&#65288;DeepONet&#65289;&#20316;&#20026;&#19968;&#31181;&#24378;&#22823;&#30340;&#26367;&#20195;&#24314;&#27169;&#26041;&#27861;&#65292;&#22312;&#26680;&#31995;&#32479;&#25968;&#23383;&#23402;&#29983;&#25216;&#26415;&#20013;&#23637;&#31034;&#20986;&#20102;&#26174;&#33879;&#30340;&#39044;&#27979;&#31934;&#24230;&#21644;&#35745;&#31639;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#25361;&#25112;&#20173;&#28982;&#23384;&#22312;&#65292;&#21253;&#25324;&#26368;&#20339;&#20256;&#24863;&#22120;&#25918;&#32622;&#21644;&#27169;&#22411;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#26680;&#24037;&#31243;&#30340;&#25968;&#23383;&#23402;&#29983;&#31995;&#32479;&#20013;&#24341;&#20837;&#20102;&#28145;&#23618;&#25805;&#20316;&#31526;&#32593;&#32476;&#65288;DeepONet&#65289;&#20316;&#20026;&#19968;&#31181;&#24378;&#22823;&#30340;&#26367;&#20195;&#24314;&#27169;&#26041;&#27861;&#12290;&#38543;&#30528;&#26680;&#33021;&#20316;&#20026;&#19968;&#31181;&#30899;&#20013;&#21644;&#35299;&#20915;&#26041;&#26696;&#30340;&#37325;&#35201;&#24615;&#19981;&#26029;&#22686;&#21152;&#65292;&#37319;&#29992;&#25968;&#23383;&#23402;&#29983;&#25216;&#26415;&#23545;&#20110;&#25552;&#39640;&#26680;&#24037;&#31243;&#24212;&#29992;&#20013;&#30340;&#36816;&#33829;&#25928;&#29575;&#12289;&#23433;&#20840;&#24615;&#21644;&#39044;&#27979;&#33021;&#21147;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;DeepONet&#20855;&#26377;&#26174;&#33879;&#30340;&#39044;&#27979;&#31934;&#24230;&#65292;&#20248;&#20110;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#22522;&#20934;&#27979;&#35797;&#21644;&#35780;&#20272;&#65292;&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;DeepONet&#22312;&#35299;&#20915;&#22797;&#26434;&#31890;&#23376;&#20256;&#36755;&#38382;&#39064;&#20013;&#30340;&#21487;&#25193;&#23637;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#12290;&#36890;&#36807;&#23558;&#20989;&#25968;&#20316;&#20026;&#36755;&#20837;&#25968;&#25454;&#24182;&#20351;&#29992;&#35757;&#32451;&#25968;&#25454;&#26500;&#24314;&#25805;&#20316;&#31526;G&#65292;DeepONet&#33021;&#22815;&#26377;&#25928;&#22788;&#29702;&#22810;&#26679;&#21270;&#21644;&#22797;&#26434;&#30340;&#22330;&#26223;&#12290;&#28982;&#32780;&#65292;DeepONet&#30340;&#24212;&#29992;&#20063;&#25581;&#31034;&#20102;&#19982;&#26368;&#20339;&#20256;&#24863;&#22120;&#25918;&#32622;&#21644;&#27169;&#22411;&#35780;&#20272;&#30456;&#20851;&#30340;&#25361;&#25112;&#65292;&#36825;&#26159;&#23454;&#38469;&#23454;&#26045;&#20013;&#30340;&#20851;&#38190;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This research introduces the Deep Operator Network (DeepONet) as a robust surrogate modeling method within the context of digital twin (DT) systems for nuclear engineering. With the increasing importance of nuclear energy as a carbon-neutral solution, adopting DT technology has become crucial to enhancing operational efficiencies, safety, and predictive capabilities in nuclear engineering applications. DeepONet exhibits remarkable prediction accuracy, outperforming traditional ML methods. Through extensive benchmarking and evaluation, this study showcases the scalability and computational efficiency of DeepONet in solving a challenging particle transport problem. By taking functions as input data and constructing the operator $G$ from training data, DeepONet can handle diverse and complex scenarios effectively. However, the application of DeepONet also reveals challenges related to optimal sensor placement and model evaluation, critical aspects of real-world implementation. Addressing 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#38750;&#32447;&#24615;&#12289;&#21453;&#39304;&#21644;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#20013;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#24369;&#20110;&#24378;&#21487;&#38752;&#24615;&#30340;k-Triangle Faithfulness&#30340;&#26367;&#20195;&#23450;&#20041;&#12290;</title><link>http://arxiv.org/abs/2308.07520</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#12289;&#21453;&#39304;&#21644;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#20013;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Nonlinearity, Feedback and Uniform Consistency in Causal Structural Learning. (arXiv:2308.07520v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07520
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#38750;&#32447;&#24615;&#12289;&#21453;&#39304;&#21644;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#20013;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#24369;&#20110;&#24378;&#21487;&#38752;&#24615;&#30340;k-Triangle Faithfulness&#30340;&#26367;&#20195;&#23450;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#21457;&#29616;&#30340;&#30446;&#26631;&#26159;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#25214;&#21040;&#23398;&#20064;&#22240;&#26524;&#32467;&#26500;&#30340;&#33258;&#21160;&#21270;&#25628;&#32034;&#26041;&#27861;&#12290;&#26377;&#20123;&#24773;&#20917;&#19979;&#65292;&#24863;&#20852;&#36259;&#30340;&#22240;&#26524;&#26426;&#21046;&#30340;&#25152;&#26377;&#21464;&#37327;&#37117;&#24050;&#32463;&#34987;&#27979;&#37327;&#65292;&#20219;&#21153;&#26159;&#39044;&#27979;&#19968;&#20010;&#21464;&#37327;&#23545;&#21478;&#19968;&#20010;&#21464;&#37327;&#30340;&#24433;&#21709;&#12290;&#30456;&#21453;&#65292;&#26377;&#26102;&#20027;&#35201;&#20851;&#27880;&#30340;&#21464;&#37327;&#24182;&#38750;&#30452;&#25509;&#21487;&#35266;&#23519;&#65292;&#32780;&#26159;&#36890;&#36807;&#23427;&#20204;&#22312;&#25968;&#25454;&#20013;&#30340;&#34920;&#29616;&#26469;&#25512;&#29702;&#20986;&#26469;&#30340;&#12290;&#36825;&#20123;&#34987;&#31216;&#20026;&#28508;&#22312;&#21464;&#37327;&#12290;&#19968;&#20010;&#24191;&#27867;&#34987;&#30693;&#36947;&#30340;&#20363;&#23376;&#26159;&#24515;&#29702;&#26500;&#36896;&#30340;&#26234;&#21830;&#65292;&#22240;&#20026;&#26080;&#27861;&#30452;&#25509;&#27979;&#37327;&#65292;&#25152;&#20197;&#30740;&#31350;&#20154;&#21592;&#23581;&#35797;&#36890;&#36807;&#21508;&#31181;&#25351;&#26631;&#22914;&#26234;&#21830;&#27979;&#35797;&#26469;&#35780;&#20272;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#21487;&#20197;&#25581;&#31034;&#28508;&#22312;&#21464;&#37327;&#20043;&#38388;&#21644;&#28508;&#22312;&#21464;&#37327;&#19982;&#35266;&#23519;&#21464;&#37327;&#20043;&#38388;&#30340;&#22240;&#26524;&#36830;&#25509;&#65292;&#20174;&#32780;&#21457;&#29616;&#28508;&#22312;&#30340;&#27169;&#24335;&#21644;&#32467;&#26500;&#12290;&#36825;&#31687;&#35770;&#25991;&#20027;&#35201;&#30740;&#31350;&#22240;&#26524;&#21457;&#29616;&#20013;&#30340;&#20004;&#20010;&#38382;&#39064;&#65306;&#25552;&#20379;&#20102;&#19968;&#20010;&#24369;&#20110;&#24378;&#21487;&#38752;&#24615;&#30340;k-Triangle Faithfulness&#30340;&#26367;&#20195;&#23450;&#20041;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;&#32479;&#35745;&#19968;&#33268;&#24615;&#30340;&#26032;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
The goal of Causal Discovery is to find automated search methods for learning causal structures from observational data. In some cases all variables of the interested causal mechanism are measured, and the task is to predict the effects one measured variable has on another. In contrast, sometimes the variables of primary interest are not directly observable but instead inferred from their manifestations in the data. These are referred to as latent variables. One commonly known example is the psychological construct of intelligence, which cannot directly measured so researchers try to assess through various indicators such as IQ tests. In this case, casual discovery algorithms can uncover underlying patterns and structures to reveal the causal connections between the latent variables and between the latent and observed variables. This thesis focuses on two questions in causal discovery: providing an alternative definition of k-Triangle Faithfulness that (i) is weaker than strong faithfu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;ExTRA&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;&#36890;&#36807;&#30830;&#23450;&#28304;&#25968;&#25454;&#19978;&#30340;&#37325;&#35201;&#24615;&#26435;&#37325;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26368;&#23567;&#21270;&#21152;&#26435;&#28304;&#25968;&#25454;&#21644;&#30446;&#26631;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;KL&#25955;&#24230;&#12290;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#65292;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.07424</link><description>&lt;p&gt;
&#36890;&#36807;&#25351;&#25968;&#20542;&#26012;&#35299;&#20915;RTB&#24066;&#22330;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Addressing Distribution Shift in RTB Markets via Exponential Tilting. (arXiv:2308.07424v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07424
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;ExTRA&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;&#36890;&#36807;&#30830;&#23450;&#28304;&#25968;&#25454;&#19978;&#30340;&#37325;&#35201;&#24615;&#26435;&#37325;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26368;&#23567;&#21270;&#21152;&#26435;&#28304;&#25968;&#25454;&#21644;&#30446;&#26631;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;KL&#25955;&#24230;&#12290;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#65292;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#21487;&#33021;&#26159;&#24615;&#33021;&#19979;&#38477;&#30340;&#20027;&#35201;&#21407;&#22240;&#12290;&#26412;&#25991;&#28145;&#20837;&#25506;&#35752;&#20102;&#36825;&#20123;&#20559;&#31227;&#30340;&#29305;&#24615;&#65292;&#20027;&#35201;&#38024;&#23545;&#23454;&#26102;&#31454;&#20215;&#65288;RTB&#65289;&#24066;&#22330;&#27169;&#22411;&#30340;&#29305;&#28857;&#12290;&#25105;&#20204;&#24378;&#35843;&#20102;&#31867;&#21035;&#19981;&#24179;&#34913;&#21644;&#26679;&#26412;&#36873;&#25321;&#20559;&#24046;&#25152;&#24102;&#26469;&#30340;&#25361;&#25112;&#65292;&#36825;&#20004;&#32773;&#22343;&#26159;&#20998;&#24067;&#20559;&#31227;&#30340;&#24378;&#26377;&#21147;&#35825;&#22240;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;ExTRA&#65288;Exponential Tilt Reweighting Alignment&#65289;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#30001;Marty&#31561;&#20154;&#65288;2023&#65289;&#25552;&#20986;&#65292;&#29992;&#20110;&#35299;&#20915;&#25968;&#25454;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;ExTRA&#26041;&#27861;&#26088;&#22312;&#30830;&#23450;&#28304;&#25968;&#25454;&#19978;&#30340;&#37325;&#35201;&#24615;&#26435;&#37325;&#65292;&#20197;&#26368;&#23567;&#21270;&#21152;&#26435;&#28304;&#25968;&#25454;&#21644;&#30446;&#26631;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;KL&#25955;&#24230;&#12290;&#35813;&#26041;&#27861;&#30340;&#19968;&#20010;&#26174;&#33879;&#20248;&#28857;&#26159;&#23427;&#33021;&#22815;&#20351;&#29992;&#26377;&#26631;&#31614;&#30340;&#28304;&#25968;&#25454;&#21644;&#26080;&#26631;&#31614;&#30340;&#30446;&#26631;&#25968;&#25454;&#36827;&#34892;&#25805;&#20316;&#12290;&#36890;&#36807;&#27169;&#25311;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20998;&#24067;&#20559;&#31227;&#30340;&#24615;&#36136;&#65292;&#24182;&#35780;&#20272;&#20102;&#25152;&#25552;&#20986;&#27169;&#22411;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distribution shift in machine learning models can be a primary cause of performance degradation. This paper delves into the characteristics of these shifts, primarily motivated by Real-Time Bidding (RTB) market models. We emphasize the challenges posed by class imbalance and sample selection bias, both potent instigators of distribution shifts. This paper introduces the Exponential Tilt Reweighting Alignment (ExTRA) algorithm, as proposed by Marty et al. (2023), to address distribution shifts in data. The ExTRA method is designed to determine the importance weights on the source data, aiming to minimize the KL divergence between the weighted source and target datasets. A notable advantage of this method is its ability to operate using labeled source data and unlabeled target data. Through simulated real-world data, we investigate the nature of distribution shift and evaluate the applicacy of the proposed model.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26412;&#22320;&#33258;&#36866;&#24212;&#21487;&#24494;&#22238;&#24402;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#23616;&#37096;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#21152;&#26435;&#24179;&#22343;&#65292;&#22312;&#19981;&#21516;&#26412;&#22320;&#21306;&#22495;&#22788;&#29702;&#25968;&#25454;&#26102;&#20855;&#26377;&#31454;&#20105;&#21147;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#23454;&#29616;&#26356;&#24555;&#30340;&#32479;&#35745;&#25910;&#25947;&#20197;&#21450;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#25913;&#21892;&#20102;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.07418</link><description>&lt;p&gt;
&#26412;&#22320;&#33258;&#36866;&#24212;&#21487;&#24494;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Locally Adaptive and Differentiable Regression. (arXiv:2308.07418v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07418
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26412;&#22320;&#33258;&#36866;&#24212;&#21487;&#24494;&#22238;&#24402;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#23616;&#37096;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#21152;&#26435;&#24179;&#22343;&#65292;&#22312;&#19981;&#21516;&#26412;&#22320;&#21306;&#22495;&#22788;&#29702;&#25968;&#25454;&#26102;&#20855;&#26377;&#31454;&#20105;&#21147;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#23454;&#29616;&#26356;&#24555;&#30340;&#32479;&#35745;&#25910;&#25947;&#20197;&#21450;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#25913;&#21892;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#24230;&#21442;&#25968;&#21270;&#27169;&#22411;&#65292;&#22914;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#38543;&#26426;&#26862;&#26519;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#21464;&#24471;&#38750;&#24120;&#21463;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#22312;&#29616;&#20195;&#36229;&#21442;&#25968;&#21270;&#30340;&#26412;&#22320;&#33258;&#36866;&#24212;&#27169;&#22411;&#20013;&#65292;&#24120;&#35265;&#30340;&#36830;&#32493;&#24615;&#21644;&#21487;&#24494;&#24615;&#30446;&#26631;&#24448;&#24448;&#34987;&#24573;&#35270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#36890;&#36807;&#22312;&#23545;&#24212;&#30340;&#26412;&#22320;&#21306;&#22495;&#20013;&#23545;&#23616;&#37096;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#21152;&#26435;&#24179;&#22343;&#26469;&#26500;&#24314;&#20840;&#23616;&#36830;&#32493;&#21487;&#24494;&#27169;&#22411;&#12290;&#35813;&#27169;&#22411;&#22312;&#22788;&#29702;&#20855;&#26377;&#19981;&#21516;&#23494;&#24230;&#25110;&#19981;&#21516;&#26412;&#22320;&#21306;&#22495;&#20013;&#30340;&#20989;&#25968;&#20540;&#23610;&#24230;&#30340;&#25968;&#25454;&#26102;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#24403;&#25105;&#20204;&#22312;&#26412;&#22320;&#27169;&#22411;&#20013;&#28151;&#21512;&#20351;&#29992;&#26680;&#23725;&#21644;&#22810;&#39033;&#24335;&#22238;&#24402;&#39033;&#65292;&#24182;&#23545;&#23427;&#20204;&#36827;&#34892;&#36830;&#32493;&#25340;&#25509;&#26102;&#65292;&#22312;&#29702;&#35770;&#19978;&#23454;&#29616;&#26356;&#24555;&#30340;&#32479;&#35745;&#25910;&#25947;&#65292;&#24182;&#22312;&#21508;&#31181;&#23454;&#38469;&#29615;&#22659;&#20013;&#23454;&#29616;&#25913;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Over-parameterized models like deep nets and random forests have become very popular in machine learning. However, the natural goals of continuity and differentiability, common in regression models, are now often ignored in modern overparametrized, locally-adaptive models. We propose a general framework to construct a global continuous and differentiable model based on a weighted average of locally learned models in corresponding local regions. This model is competitive in dealing with data with different densities or scales of function values in different local regions. We demonstrate that when we mix kernel ridge and polynomial regression terms in the local models, and stitch them together continuously, we achieve faster statistical convergence in theory and improved performance in various practical settings.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#36319;&#36394;&#28436;&#21464;&#27169;&#24335;&#30340;&#26102;&#31354;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;tPARAFAC2&#65292;&#36890;&#36807;&#26102;&#38388;&#27491;&#21017;&#21270;&#22120;&#20174;&#26102;&#38388;&#25968;&#25454;&#20013;&#25552;&#21462;&#36880;&#28176;&#28436;&#21464;&#30340;&#27169;&#24335;&#12290;</title><link>http://arxiv.org/abs/2308.07126</link><description>&lt;p&gt;
&#19968;&#31181;&#36866;&#29992;&#20110;&#36319;&#36394;&#28436;&#21464;&#27169;&#24335;&#30340;&#26102;&#31354;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Time-aware tensor decomposition for tracking evolving patterns. (arXiv:2308.07126v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07126
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#36319;&#36394;&#28436;&#21464;&#27169;&#24335;&#30340;&#26102;&#31354;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;tPARAFAC2&#65292;&#36890;&#36807;&#26102;&#38388;&#27491;&#21017;&#21270;&#22120;&#20174;&#26102;&#38388;&#25968;&#25454;&#20013;&#25552;&#21462;&#36880;&#28176;&#28436;&#21464;&#30340;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#28436;&#21464;&#30340;&#25968;&#25454;&#38598;&#36890;&#24120;&#21487;&#20197;&#32452;&#32455;&#25104;&#19968;&#20010;&#39640;&#38454;&#24352;&#37327;&#65292;&#20854;&#20013;&#30340;&#19968;&#20010;&#27169;&#24335;&#26159;&#26102;&#38388;&#27169;&#24335;&#12290;&#34429;&#28982;&#24352;&#37327;&#20998;&#35299;&#24050;&#32463;&#25104;&#21151;&#22320;&#29992;&#20110;&#25429;&#25417;&#36825;&#31867;&#39640;&#38454;&#25968;&#25454;&#38598;&#20013;&#30340;&#28508;&#22312;&#27169;&#24335;&#65292;&#20294;&#24448;&#24448;&#24573;&#30053;&#20102;&#26102;&#38388;&#30340;&#22240;&#32032;&#65292;&#20801;&#35768;&#26102;&#38388;&#28857;&#30340;&#37325;&#26032;&#25490;&#24207;&#12290;&#22312;&#26368;&#36817;&#30340;&#30740;&#31350;&#20013;&#65292;&#24341;&#20837;&#20102;&#26102;&#38388;&#27491;&#21017;&#21270;&#22120;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#20173;&#28982;&#19981;&#20801;&#35768;&#28508;&#22312;&#27169;&#24335;&#22312;&#26102;&#38388;&#19978;&#21457;&#29983;&#21464;&#21270;&#65288;&#20363;&#22914;&#65292;&#22823;&#33041;&#20013;&#30340;&#31354;&#38388;&#21464;&#21270;&#65292;&#20027;&#39064;&#20013;&#30340;&#19978;&#19979;&#25991;&#21464;&#21270;&#65289;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;PARAFAC2&#30340;&#26102;&#31354;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;tPARAFAC2&#65292;&#36890;&#36807;&#26102;&#38388;&#27491;&#21017;&#21270;&#22120;&#20174;&#26102;&#38388;&#25968;&#25454;&#20013;&#25552;&#21462;&#36880;&#28176;&#28436;&#21464;&#30340;&#27169;&#24335;&#12290;&#36890;&#36807;&#23545;&#21512;&#25104;&#25968;&#25454;&#30340;&#22823;&#37327;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;tPARAFAC2&#33021;&#22815;&#20934;&#30830;&#22320;&#25429;&#25417;&#21040;&#28436;&#21464;&#20013;&#30340;&#28508;&#22312;&#27169;&#24335;&#65292;&#34920;&#29616;&#20248;&#20110;PARAFAC2&#21644;&#24102;&#26377;&#26102;&#38388;&#24179;&#28369;&#27491;&#21017;&#21270;&#30340;&#32806;&#21512;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Time-evolving data sets can often be arranged as a higher-order tensor with one of the modes being the time mode. While tensor factorizations have been successfully used to capture the underlying patterns in such higher-order data sets, the temporal aspect is often ignored, allowing for the reordering of time points. In recent studies, temporal regularizers are incorporated in the time mode to tackle this issue. Nevertheless, existing approaches still do not allow underlying patterns to change in time (e.g., spatial changes in the brain, contextual changes in topics). In this paper, we propose temporal PARAFAC2 (tPARAFAC2): a PARAFAC2-based tensor factorization method with temporal regularization to extract gradually evolving patterns from temporal data. Through extensive experiments on synthetic data, we demonstrate that tPARAFAC2 can capture the underlying evolving patterns accurately performing better than PARAFAC2 and coupled matrix factorization with temporal smoothness regulariza
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Frechet&#32479;&#35745;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22810;&#21464;&#37327;Hawkes&#36807;&#31243;&#20013;&#26816;&#27979;&#21464;&#28857;&#12290;&#36890;&#36807;&#23558;&#28857;&#36807;&#31243;&#20998;&#25104;&#31383;&#21475;&#65292;&#24182;&#21033;&#29992;&#26680;&#30697;&#38453;&#26469;&#37325;&#26500;&#26377;&#31526;&#21495;&#30340;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#20934;&#30830;&#22320;&#26816;&#27979;&#21644;&#25551;&#36848;&#22810;&#21464;&#37327;Hawkes&#36807;&#31243;&#22240;&#26524;&#32467;&#26500;&#20013;&#30340;&#21464;&#21270;&#65292;&#20855;&#26377;&#28508;&#22312;&#30340;&#37329;&#34701;&#21644;&#31070;&#32463;&#31185;&#23398;&#31561;&#39046;&#22495;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2308.06769</link><description>&lt;p&gt;
&#22522;&#20110;Frechet&#32479;&#35745;&#30340;&#22810;&#21464;&#37327;Hawkes&#36807;&#31243;&#20013;&#30340;&#21464;&#28857;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Fr\'echet Statistics Based Change Point Detection in Multivariate Hawkes Process. (arXiv:2308.06769v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06769
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Frechet&#32479;&#35745;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22810;&#21464;&#37327;Hawkes&#36807;&#31243;&#20013;&#26816;&#27979;&#21464;&#28857;&#12290;&#36890;&#36807;&#23558;&#28857;&#36807;&#31243;&#20998;&#25104;&#31383;&#21475;&#65292;&#24182;&#21033;&#29992;&#26680;&#30697;&#38453;&#26469;&#37325;&#26500;&#26377;&#31526;&#21495;&#30340;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#20934;&#30830;&#22320;&#26816;&#27979;&#21644;&#25551;&#36848;&#22810;&#21464;&#37327;Hawkes&#36807;&#31243;&#22240;&#26524;&#32467;&#26500;&#20013;&#30340;&#21464;&#21270;&#65292;&#20855;&#26377;&#28508;&#22312;&#30340;&#37329;&#34701;&#21644;&#31070;&#32463;&#31185;&#23398;&#31561;&#39046;&#22495;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Frechet&#32479;&#35745;&#26041;&#27861;&#23545;&#22810;&#21464;&#37327;Hawkes&#36807;&#31243;&#20013;&#30340;&#22240;&#26524;&#32593;&#32476;&#36827;&#34892;&#21464;&#28857;&#26816;&#27979;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#28857;&#36807;&#31243;&#20998;&#25104;&#37325;&#21472;&#30340;&#31383;&#21475;&#65292;&#22312;&#27599;&#20010;&#31383;&#21475;&#20013;&#20272;&#35745;&#26680;&#30697;&#38453;&#65292;&#24182;&#36890;&#36807;&#23558;&#26680;&#30697;&#38453;&#35270;&#20026;&#22240;&#26524;&#32593;&#32476;&#30340;&#37051;&#25509;&#30697;&#38453;&#26469;&#37325;&#26500;&#26377;&#31526;&#21495;&#30340;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#12290;&#36890;&#36807;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#21152;&#23494;&#36135;&#24065;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#20934;&#30830;&#22320;&#26816;&#27979;&#21644;&#25551;&#36848;&#22810;&#21464;&#37327;Hawkes&#36807;&#31243;&#22240;&#26524;&#32467;&#26500;&#20013;&#30340;&#21464;&#21270;&#65292;&#24182;&#22312;&#37329;&#34701;&#21644;&#31070;&#32463;&#31185;&#23398;&#31561;&#39046;&#22495;&#20855;&#26377;&#28508;&#22312;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#26159;&#23545;&#28857;&#36807;&#31243;&#35774;&#32622;&#20013;Frechet&#32479;&#35745;&#20043;&#21069;&#24037;&#20316;&#30340;&#25193;&#23637;&#65292;&#24182;&#23545;&#22810;&#21464;&#37327;&#28857;&#36807;&#31243;&#30340;&#21464;&#28857;&#26816;&#27979;&#39046;&#22495;&#20570;&#20986;&#20102;&#37325;&#35201;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a new approach for change point detection in causal networks of multivariate Hawkes processes using Frechet statistics. Our method splits the point process into overlapping windows, estimates kernel matrices in each window, and reconstructs the signed Laplacians by treating the kernel matrices as the adjacency matrices of the causal network. We demonstrate the effectiveness of our method through experiments on both simulated and real-world cryptocurrency datasets. Our results show that our method is capable of accurately detecting and characterizing changes in the causal structure of multivariate Hawkes processes, and may have potential applications in fields such as finance and neuroscience. The proposed method is an extension of previous work on Frechet statistics in point process settings and represents an important contribution to the field of change point detection in multivariate point processes.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#20855;&#26377;&#20844;&#20849;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#30340;&#31169;&#26377;&#20998;&#24067;&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#21387;&#32553;&#26679;&#26412;&#21644;&#21015;&#34920;&#23398;&#20064;&#30340;&#26041;&#24335;&#65292;&#25105;&#20204;&#23545;&#39640;&#26031;&#20998;&#24067;&#20197;&#21450;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#36827;&#34892;&#20102;&#23398;&#20064;&#19978;&#38480;&#30340;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;&#19981;&#21487;&#30693;&#23398;&#20064;&#21644;&#20998;&#24067;&#21464;&#21270;&#25269;&#25239;&#23398;&#20064;&#30340;&#26032;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.06239</link><description>&lt;p&gt;
&#20855;&#26377;&#20844;&#20849;&#25968;&#25454;&#30340;&#31169;&#26377;&#20998;&#24067;&#23398;&#20064;&#65306;&#22522;&#20110;&#26679;&#26412;&#21387;&#32553;&#30340;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Private Distribution Learning with Public Data: The View from Sample Compression. (arXiv:2308.06239v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06239
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#20855;&#26377;&#20844;&#20849;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#30340;&#31169;&#26377;&#20998;&#24067;&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#21387;&#32553;&#26679;&#26412;&#21644;&#21015;&#34920;&#23398;&#20064;&#30340;&#26041;&#24335;&#65292;&#25105;&#20204;&#23545;&#39640;&#26031;&#20998;&#24067;&#20197;&#21450;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#36827;&#34892;&#20102;&#23398;&#20064;&#19978;&#38480;&#30340;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;&#19981;&#21487;&#30693;&#23398;&#20064;&#21644;&#20998;&#24067;&#21464;&#21270;&#25269;&#25239;&#23398;&#20064;&#30340;&#26032;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#21487;&#20197;&#35775;&#38382;&#20844;&#20849;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#30340;&#31169;&#26377;&#20998;&#24067;&#23398;&#20064;&#38382;&#39064;&#12290;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#20844;&#31169;&#23398;&#20064;&#65292;&#23398;&#20064;&#22120;&#34987;&#32473;&#20104;&#26469;&#33258;&#26410;&#30693;&#20998;&#24067;p&#30340;&#23646;&#20110;&#31867;$\mathcal Q$&#30340;&#20844;&#20849;&#26679;&#26412;&#21644;&#31169;&#26377;&#26679;&#26412;&#65292;&#30446;&#26631;&#26159;&#36755;&#20986;&#19968;&#20010;&#23545;p&#30340;&#20272;&#35745;&#65292;&#21516;&#26102;&#36981;&#23432;&#19982;&#31169;&#26377;&#26679;&#26412;&#30456;&#20851;&#30340;&#38544;&#31169;&#32422;&#26463;&#65288;&#36825;&#37324;&#26159;&#32431;&#24046;&#20998;&#38544;&#31169;&#65289;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#31867;$\mathcal Q$&#30340;&#20844;&#31169;&#21487;&#23398;&#20064;&#24615;&#19982;$\mathcal Q$&#30340;&#26679;&#26412;&#21387;&#32553;&#26041;&#26696;&#20197;&#21450;&#20013;&#38388;&#27010;&#24565;&#8212;&#8212;&#21015;&#34920;&#23398;&#20064;&#30340;&#23384;&#22312;&#24615;&#26377;&#20851;&#12290;&#21033;&#29992;&#36825;&#20010;&#32852;&#31995;&#65306;&#65288;1&#65289;&#36817;&#20284;&#24674;&#22797;&#20102;&#20851;&#20110;$\mathbb R^d$&#19978;&#39640;&#26031;&#20998;&#24067;&#30340;&#20808;&#21069;&#32467;&#26524;&#65307;&#65288;2&#65289;&#24471;&#20986;&#20102;&#26032;&#30340;&#32467;&#26524;&#65292;&#21253;&#25324;&#23545;&#20219;&#24847;$k$-&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#22312;$\mathbb R^d$&#19978;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#19978;&#30028;&#65292;&#20197;&#21450;&#23545;&#19981;&#21487;&#30693;&#21644;&#20998;&#24067;&#21464;&#21270;&#25269;&#25239;&#23398;&#20064;&#22120;&#30340;&#32467;&#26524;&#65292;&#20197;&#21450;&#20844;&#31169;&#21487;&#23398;&#20064;&#24615;&#30340;&#38381;&#21253;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of private distribution learning with access to public data. In this setup, which we refer to as public-private learning, the learner is given public and private samples drawn from an unknown distribution $p$ belonging to a class $\mathcal Q$, with the goal of outputting an estimate of $p$ while adhering to privacy constraints (here, pure differential privacy) only with respect to the private samples.  We show that the public-private learnability of a class $\mathcal Q$ is connected to the existence of a sample compression scheme for $\mathcal Q$, as well as to an intermediate notion we refer to as list learning. Leveraging this connection: (1) approximately recovers previous results on Gaussians over $\mathbb R^d$; and (2) leads to new ones, including sample complexity upper bounds for arbitrary $k$-mixtures of Gaussians over $\mathbb R^d$, results for agnostic and distribution-shift resistant learners, as well as closure properties for public-private learnability
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25193;&#23637;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#20351;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;BDCM&#65292;&#21487;&#20197;&#22312;&#23384;&#22312;&#26080;&#27861;&#27979;&#37327;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#26356;&#20934;&#30830;&#22320;&#22238;&#31572;&#22240;&#26524;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.03669</link><description>&lt;p&gt;
&#26080;&#27861;&#27979;&#37327;&#28151;&#28102;&#22240;&#32032;&#19979;&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Diffusion Model in Causal Inference with Unmeasured Confounders. (arXiv:2308.03669v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03669
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25193;&#23637;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#20351;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;BDCM&#65292;&#21487;&#20197;&#22312;&#23384;&#22312;&#26080;&#27861;&#27979;&#37327;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#26356;&#20934;&#30830;&#22320;&#22238;&#31572;&#22240;&#26524;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22914;&#20309;&#22312;&#26080;&#27861;&#27979;&#37327;&#30340;&#28151;&#28102;&#22240;&#32032;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#25193;&#23637;&#25193;&#25955;&#27169;&#22411;&#30340;&#20351;&#29992;&#65292;&#20197;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#22238;&#31572;&#22240;&#26524;&#38382;&#39064;&#12290;&#22312;Pearl&#30340;&#20351;&#29992;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#25429;&#25417;&#22240;&#26524;&#24178;&#39044;&#30340;&#26694;&#26550;&#20013;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#22240;&#26524;&#27169;&#22411;&#65288;DCM&#65289;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#22238;&#31572;&#22240;&#26524;&#38382;&#39064;&#65292;&#20551;&#35774;&#25152;&#26377;&#28151;&#28102;&#22240;&#32032;&#37117;&#26159;&#21487;&#20197;&#35266;&#23519;&#21040;&#30340;&#12290;&#28982;&#32780;&#65292;&#23454;&#38469;&#20013;&#23384;&#22312;&#26080;&#27861;&#27979;&#37327;&#30340;&#28151;&#28102;&#22240;&#32032;&#65292;&#36825;&#20351;&#24471;DCM&#26080;&#27861;&#24212;&#29992;&#12290;&#20026;&#20102;&#32531;&#35299;DCM&#30340;&#36825;&#19968;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25193;&#23637;&#27169;&#22411;&#65292;&#31216;&#20026;&#22522;&#20110;&#21453;&#38376;&#20934;&#21017;&#30340;DCM&#65288;BDCM&#65289;&#65292;&#20854;&#24605;&#24819;&#26681;&#26893;&#20110;&#22312;DAG&#20013;&#25214;&#21040;&#35201;&#21253;&#25324;&#22312;&#25193;&#25955;&#27169;&#22411;&#35299;&#30721;&#36807;&#31243;&#20013;&#30340;&#21464;&#37327;&#30340;&#21453;&#38376;&#20934;&#21017;&#65292;&#36825;&#26679;&#25105;&#20204;&#21487;&#20197;&#23558;DCM&#25193;&#23637;&#21040;&#23384;&#22312;&#26080;&#27861;&#27979;&#37327;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#12290;&#21512;&#25104;&#25968;&#25454;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#27169;&#22411;&#22312;&#26080;&#27861;&#27979;&#37327;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#26356;&#31934;&#30830;&#22320;&#25429;&#25417;&#21040;&#20102;&#21453;&#20107;&#23454;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study how to extend the use of the diffusion model to answer the causal question from the observational data under the existence of unmeasured confounders. In Pearl's framework of using a Directed Acyclic Graph (DAG) to capture the causal intervention, a Diffusion-based Causal Model (DCM) was proposed incorporating the diffusion model to answer the causal questions more accurately, assuming that all of the confounders are observed. However, unmeasured confounders in practice exist, which hinders DCM from being applicable. To alleviate this limitation of DCM, we propose an extended model called Backdoor Criterion based DCM (BDCM), whose idea is rooted in the Backdoor criterion to find the variables in DAG to be included in the decoding process of the diffusion model so that we can extend DCM to the case with unmeasured confounders. Synthetic data experiment demonstrates that our proposed model captures the counterfactual distribution more precisely than DCM under the unmeasured confo
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21463;&#38480;&#29627;&#23572;&#20857;&#26364;&#26426;&#65288;RBMs&#65289;&#30340;&#20108;&#20540;&#22270;&#20687;&#21435;&#22122;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#20351;&#29992;&#20108;&#27425;&#26080;&#32422;&#26463;&#20108;&#20540;&#20248;&#21270;&#65288;QUBO&#65289;&#24418;&#24335;&#30340;&#21435;&#22122;&#30446;&#26631;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#37327;&#23376;&#36864;&#28779;&#12290;&#36890;&#36807;&#24179;&#34913;&#35757;&#32451;&#30340;RBMs&#23398;&#20064;&#21040;&#30340;&#20998;&#24067;&#21644;&#22122;&#22768;&#22270;&#20687;&#20559;&#31163;&#30340;&#24809;&#32602;&#39033;&#65292;&#23454;&#29616;&#20102;&#21435;&#22122;&#30446;&#26631;&#12290;&#36890;&#36807;&#36827;&#34892;&#23454;&#39564;&#65292;&#30740;&#31350;&#21457;&#29616;&#35813;&#26041;&#27861;&#24471;&#21040;&#30340;&#21435;&#22122;&#22270;&#20687;&#22312;&#26399;&#26395;&#24847;&#20041;&#19979;&#26126;&#26174;&#27604;&#22122;&#22768;&#22270;&#20687;&#26356;&#25509;&#36817;&#26080;&#22122;&#22768;&#22270;&#20687;&#12290;</title><link>http://arxiv.org/abs/2307.06542</link><description>&lt;p&gt;
&#37327;&#23376;&#36864;&#28779;&#20013;&#36866;&#21512;&#30340;&#22270;&#20687;&#21435;&#22122;&#26694;&#26550;&#65306;QUBO&#21644;&#21463;&#38480;&#29627;&#23572;&#20857;&#26364;&#26426;
&lt;/p&gt;
&lt;p&gt;
An Image-Denoising Framework Fit for Quantum Annealing via QUBO and Restricted Boltzmann Machines. (arXiv:2307.06542v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06542
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21463;&#38480;&#29627;&#23572;&#20857;&#26364;&#26426;&#65288;RBMs&#65289;&#30340;&#20108;&#20540;&#22270;&#20687;&#21435;&#22122;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#20351;&#29992;&#20108;&#27425;&#26080;&#32422;&#26463;&#20108;&#20540;&#20248;&#21270;&#65288;QUBO&#65289;&#24418;&#24335;&#30340;&#21435;&#22122;&#30446;&#26631;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#37327;&#23376;&#36864;&#28779;&#12290;&#36890;&#36807;&#24179;&#34913;&#35757;&#32451;&#30340;RBMs&#23398;&#20064;&#21040;&#30340;&#20998;&#24067;&#21644;&#22122;&#22768;&#22270;&#20687;&#20559;&#31163;&#30340;&#24809;&#32602;&#39033;&#65292;&#23454;&#29616;&#20102;&#21435;&#22122;&#30446;&#26631;&#12290;&#36890;&#36807;&#36827;&#34892;&#23454;&#39564;&#65292;&#30740;&#31350;&#21457;&#29616;&#35813;&#26041;&#27861;&#24471;&#21040;&#30340;&#21435;&#22122;&#22270;&#20687;&#22312;&#26399;&#26395;&#24847;&#20041;&#19979;&#26126;&#26174;&#27604;&#22122;&#22768;&#22270;&#20687;&#26356;&#25509;&#36817;&#26080;&#22122;&#22768;&#22270;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#36890;&#36807;&#21463;&#38480;&#29627;&#23572;&#20857;&#26364;&#26426;&#65288;RBMs&#65289;&#23454;&#29616;&#30340;&#20108;&#20540;&#22270;&#20687;&#21435;&#22122;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#24341;&#20837;&#20102;&#19968;&#20010;&#20108;&#27425;&#26080;&#32422;&#26463;&#20108;&#20540;&#20248;&#21270;&#65288;QUBO&#65289;&#24418;&#24335;&#30340;&#21435;&#22122;&#30446;&#26631;&#65292;&#24182;&#19988;&#38750;&#24120;&#36866;&#21512;&#37327;&#23376;&#36864;&#28779;&#12290;&#36890;&#36807;&#22312;&#35757;&#32451;&#30340;RBMs&#19978;&#23398;&#20064;&#21040;&#30340;&#20998;&#24067;&#19982;&#22122;&#22768;&#22270;&#20687;&#20559;&#31163;&#30340;&#24809;&#32602;&#39033;&#30340;&#24179;&#34913;&#65292;&#23454;&#29616;&#20102;&#21435;&#22122;&#30446;&#26631;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#22312;&#30446;&#26631;&#20998;&#24067;&#34987;&#33391;&#22909;&#36817;&#20284;&#30340;&#24773;&#20917;&#19979;&#65292;&#24809;&#32602;&#21442;&#25968;&#30340;&#32479;&#35745;&#26368;&#20248;&#36873;&#25321;&#65292;&#24182;&#36827;&#19968;&#27493;&#24314;&#35758;&#20102;&#19968;&#31181;&#32463;&#36807;&#32463;&#39564;&#35777;&#25903;&#25345;&#30340;&#20462;&#25913;&#26041;&#27861;&#65292;&#20351;&#35813;&#26041;&#27861;&#23545;&#20110;&#29702;&#24819;&#21270;&#20551;&#35774;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#36824;&#22312;&#39069;&#22806;&#30340;&#20551;&#35774;&#19979;&#23637;&#31034;&#20102;&#65292;&#25105;&#20204;&#26041;&#27861;&#24471;&#21040;&#30340;&#21435;&#22122;&#22270;&#20687;&#22312;&#26399;&#26395;&#24847;&#20041;&#19979;&#26126;&#26174;&#27604;&#22122;&#22768;&#22270;&#20687;&#26356;&#25509;&#36817;&#26080;&#22122;&#22768;&#22270;&#20687;&#12290;&#34429;&#28982;&#25105;&#20204;&#23558;&#35813;&#27169;&#22411;&#26500;&#24314;&#20026;&#22270;&#20687;&#21435;&#22122;&#27169;&#22411;&#65292;&#20294;&#23427;&#21487;&#20197;&#24212;&#29992;&#20110;&#20219;&#20309;&#20108;&#20540;&#25968;&#25454;&#12290;&#30001;&#20110;QUBO&#20844;&#24335;&#38750;&#24120;&#36866;&#21512;&#22312;&#37327;&#23376;&#36864;&#28779;&#22120;&#19978;&#23454;&#29616;&#65292;&#25105;&#20204;&#22312;&#19968;&#20010;&#25968;&#25454;&#38598;&#19978;&#23545;&#35813;&#27169;&#22411;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate a framework for binary image denoising via restricted Boltzmann machines (RBMs) that introduces a denoising objective in quadratic unconstrained binary optimization (QUBO) form and is well-suited for quantum annealing. The denoising objective is attained by balancing the distribution learned by a trained RBM with a penalty term for derivations from the noisy image. We derive the statistically optimal choice of the penalty parameter assuming the target distribution has been well-approximated, and further suggest an empirically supported modification to make the method robust to that idealistic assumption. We also show under additional assumptions that the denoised images attained by our method are, in expectation, strictly closer to the noise-free images than the noisy images are. While we frame the model as an image denoising model, it can be applied to any binary data. As the QUBO formulation is well-suited for implementation on quantum annealers, we test the model on a
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26080;&#20284;&#28982;&#36125;&#21494;&#26031;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#26500;&#24314;&#39640;&#25928;&#30340;&#25130;&#23614;&#36229;&#38408;&#20540;&#27169;&#22411;&#20272;&#35745;&#22120;&#12290;&#35813;&#26041;&#27861;&#25361;&#25112;&#20102;&#20256;&#32479;&#30340;&#22522;&#20110;&#25130;&#23614;&#20284;&#28982;&#30340;&#31354;&#38388;&#26497;&#20540;&#25512;&#29702;&#65292;&#24182;&#22312;&#35745;&#31639;&#21644;&#32479;&#35745;&#25928;&#29575;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2306.15642</link><description>&lt;p&gt;
&#26080;&#20284;&#28982;&#31070;&#32463;&#36125;&#21494;&#26031;&#20272;&#35745;&#30340;&#25130;&#23614;&#36229;&#38408;&#20540;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Likelihood-free neural Bayes estimators for censored peaks-over-threshold models. (arXiv:2306.15642v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15642
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26080;&#20284;&#28982;&#36125;&#21494;&#26031;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#26500;&#24314;&#39640;&#25928;&#30340;&#25130;&#23614;&#36229;&#38408;&#20540;&#27169;&#22411;&#20272;&#35745;&#22120;&#12290;&#35813;&#26041;&#27861;&#25361;&#25112;&#20102;&#20256;&#32479;&#30340;&#22522;&#20110;&#25130;&#23614;&#20284;&#28982;&#30340;&#31354;&#38388;&#26497;&#20540;&#25512;&#29702;&#65292;&#24182;&#22312;&#35745;&#31639;&#21644;&#32479;&#35745;&#25928;&#29575;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#24230;&#19979;&#65292;&#23545;&#20110;&#31354;&#38388;&#26497;&#20540;&#20381;&#36182;&#27169;&#22411;&#30340;&#25512;&#29702;&#24448;&#24448;&#22240;&#20854;&#20381;&#36182;&#20110;&#38590;&#20197;&#22788;&#29702;&#30340;&#25110;&#25130;&#23614;&#30340;&#20284;&#28982;&#20989;&#25968;&#32780;&#36896;&#25104;&#35745;&#31639;&#36127;&#25285;&#12290;&#21033;&#29992;&#26368;&#36817;&#22312;&#26080;&#20284;&#28982;&#25512;&#29702;&#26041;&#38754;&#30340;&#36827;&#23637;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#20013;&#32534;&#30721;&#25130;&#23614;&#20449;&#24687;&#65292;&#20026;&#25130;&#23614;&#36229;&#38408;&#20540;&#27169;&#22411;&#26500;&#24314;&#20102;&#39640;&#25928;&#30340;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#30340;&#26032;&#26041;&#27861;&#23545;&#20110;&#20256;&#32479;&#30340;&#22522;&#20110;&#25130;&#23614;&#20284;&#28982;&#30340;&#31354;&#38388;&#26497;&#20540;&#25512;&#29702;&#25552;&#20986;&#20102;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#27169;&#25311;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#25512;&#26029;&#27969;&#34892;&#30340;&#26497;&#20540;&#20381;&#36182;&#27169;&#22411;&#65288;&#22914;&#26368;&#22823;&#31283;&#23450;&#27169;&#22411;&#12289;r-&#24085;&#32047;&#25176;&#27169;&#22411;&#21644;&#38543;&#26426;&#27604;&#20363;&#28151;&#21512;&#36807;&#31243;&#65289;&#26102;&#65292;&#30456;&#23545;&#20110;&#31454;&#20105;&#30340;&#22522;&#20110;&#20284;&#28982;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26032;&#20272;&#35745;&#22120;&#22312;&#35745;&#31639;&#21644;&#32479;&#35745;&#25928;&#29575;&#26041;&#38754;&#25552;&#20379;&#20102;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inference for spatial extremal dependence models can be computationally burdensome in moderate-to-high dimensions due to their reliance on intractable and/or censored likelihoods. Exploiting recent advances in likelihood-free inference with neural Bayes estimators (that is, neural estimators that target Bayes estimators), we develop a novel approach to construct highly efficient estimators for censored peaks-over-threshold models by encoding censoring information in the neural network architecture. Our new method provides a paradigm shift that challenges traditional censored likelihood-based inference for spatial extremes. Our simulation studies highlight significant gains in both computational and statistical efficiency, relative to competing likelihood-based approaches, when applying our novel estimators for inference of popular extremal dependence models, such as max-stable, $r$-Pareto, and random scale mixture processes. We also illustrate that it is possible to train a single esti
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;VHGM&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#22522;&#20110;&#25513;&#30721;&#24314;&#27169;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#20581;&#24247;&#23646;&#24615;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20154;&#26684;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#36890;&#36807;&#20351;&#29992;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#38598;&#65292;VHGM&#26377;&#25928;&#22320;&#23398;&#20064;&#20102;&#36229;&#36807;1,800&#20010;&#23646;&#24615;&#12290;&#35813;&#27169;&#22411;&#20855;&#26377;&#28508;&#22312;&#30340;&#24212;&#29992;&#21069;&#26223;&#65292;&#20363;&#22914;&#29992;&#20110;&#21307;&#30103;&#23646;&#24615;&#30340;&#34394;&#25311;&#27979;&#37327;&#21644;&#29983;&#27963;&#26041;&#24335;&#30340;&#20551;&#35774;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.10656</link><description>&lt;p&gt;
&#34394;&#25311;&#20154;&#31867;&#29983;&#25104;&#27169;&#22411;&#65306;&#22522;&#20110;&#25513;&#30721;&#24314;&#27169;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#20154;&#31867;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Virtual Human Generative Model: Masked Modeling Approach for Learning Human Characteristics. (arXiv:2306.10656v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10656
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;VHGM&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#22522;&#20110;&#25513;&#30721;&#24314;&#27169;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#20581;&#24247;&#23646;&#24615;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20154;&#26684;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#36890;&#36807;&#20351;&#29992;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#38598;&#65292;VHGM&#26377;&#25928;&#22320;&#23398;&#20064;&#20102;&#36229;&#36807;1,800&#20010;&#23646;&#24615;&#12290;&#35813;&#27169;&#22411;&#20855;&#26377;&#28508;&#22312;&#30340;&#24212;&#29992;&#21069;&#26223;&#65292;&#20363;&#22914;&#29992;&#20110;&#21307;&#30103;&#23646;&#24615;&#30340;&#34394;&#25311;&#27979;&#37327;&#21644;&#29983;&#27963;&#26041;&#24335;&#30340;&#20551;&#35774;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35782;&#21035;&#21307;&#30103;&#23646;&#24615;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20154;&#26684;&#20043;&#38388;&#30340;&#20851;&#31995;&#23545;&#20110;&#29702;&#35299;&#21644;&#25913;&#21892;&#36523;&#20307;&#21644;&#31934;&#31070;&#29366;&#20917;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#34394;&#25311;&#20154;&#31867;&#29983;&#25104;&#27169;&#22411;&#65288;VHGM&#65289;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#29992;&#20110;&#20272;&#35745;&#26377;&#20851;&#21307;&#30103;&#20445;&#20581;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20010;&#24615;&#30340;&#23646;&#24615;&#12290;VHGM&#26159;&#19968;&#20010;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#20351;&#29992;&#25513;&#30721;&#24314;&#27169;&#35757;&#32451;&#65292;&#22312;&#24050;&#30693;&#23646;&#24615;&#30340;&#26465;&#20214;&#19979;&#23398;&#20064;&#23646;&#24615;&#30340;&#32852;&#21512;&#20998;&#24067;&#12290;&#21033;&#29992;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#38598;&#65292;VHGM&#39640;&#25928;&#22320;&#23398;&#20064;&#20102;&#36229;&#36807;1,800&#20010;&#23646;&#24615;&#12290;&#25105;&#20204;&#25968;&#20540;&#35780;&#20272;&#20102;VHGM&#21450;&#20854;&#35757;&#32451;&#25216;&#26415;&#30340;&#24615;&#33021;&#12290;&#20316;&#20026;VHGM&#30340;&#27010;&#24565;&#39564;&#35777;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#20010;&#24212;&#29992;&#31243;&#24207;&#65292;&#28436;&#31034;&#20102;&#29992;&#25143;&#24773;&#22659;&#65292;&#20363;&#22914;&#21307;&#30103;&#23646;&#24615;&#30340;&#34394;&#25311;&#27979;&#37327;&#21644;&#29983;&#27963;&#26041;&#24335;&#30340;&#20551;&#35774;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Identifying the relationship between healthcare attributes, lifestyles, and personality is vital for understanding and improving physical and mental conditions. Machine learning approaches are promising for modeling their relationships and offering actionable suggestions. In this paper, we propose Virtual Human Generative Model (VHGM), a machine learning model for estimating attributes about healthcare, lifestyles, and personalities. VHGM is a deep generative model trained with masked modeling to learn the joint distribution of attributes conditioned on known ones. Using heterogeneous tabular datasets, VHGM learns more than 1,800 attributes efficiently. We numerically evaluate the performance of VHGM and its training techniques. As a proof-of-concept of VHGM, we present several applications demonstrating user scenarios, such as virtual measurements of healthcare attributes and hypothesis verifications of lifestyles.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#969;-UCB&#30340;&#26032;&#19978;&#32622;&#20449;&#21306;&#38388;&#25277;&#26679;&#31574;&#30053;&#65292;&#20351;&#29992;&#19981;&#23545;&#31216;&#32622;&#20449;&#21306;&#38388;&#20197;&#26356;&#20934;&#30830;&#12289;&#26356;&#32039;&#23494;&#22320;&#20272;&#35745;&#22870;&#21169;&#25104;&#26412;&#27604;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#39044;&#31639;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#31574;&#30053;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#29615;&#22659;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>http://arxiv.org/abs/2306.07071</link><description>&lt;p&gt;
&#20855;&#26377;&#19981;&#23545;&#31216;&#32622;&#20449;&#21306;&#38388;&#30340;&#26377;&#38480;&#39044;&#31639;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Budgeted Multi-Armed Bandits with Asymmetric Confidence Intervals. (arXiv:2306.07071v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07071
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#969;-UCB&#30340;&#26032;&#19978;&#32622;&#20449;&#21306;&#38388;&#25277;&#26679;&#31574;&#30053;&#65292;&#20351;&#29992;&#19981;&#23545;&#31216;&#32622;&#20449;&#21306;&#38388;&#20197;&#26356;&#20934;&#30830;&#12289;&#26356;&#32039;&#23494;&#22320;&#20272;&#35745;&#22870;&#21169;&#25104;&#26412;&#27604;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#39044;&#31639;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#31574;&#30053;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#29615;&#22659;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#38543;&#26426;&#39044;&#31639;&#22810;&#33218;&#32769;&#34382;&#26426;&#65288;MAB&#65289;&#38382;&#39064;&#65292;&#20854;&#20013;&#29609;&#23478;&#36873;&#25321;&#20855;&#26377;&#26410;&#30693;&#26399;&#26395;&#22870;&#21169;&#21644;&#25104;&#26412;&#30340;K&#20010;&#33218;&#12290;&#30446;&#26631;&#26159;&#22312;&#39044;&#31639;&#32422;&#26463;&#19979;&#26368;&#22823;&#21270;&#24635;&#22870;&#21169;&#12290;&#22240;&#27492;&#65292;&#29609;&#23478;&#35797;&#22270;&#23613;&#21487;&#33021;&#32463;&#24120;&#22320;&#36873;&#25321;&#20855;&#26377;&#26368;&#39640;&#22870;&#21169;&#25104;&#26412;&#27604;&#30340;&#33218;&#12290;&#24403;&#21069;&#38024;&#23545;&#27492;&#38382;&#39064;&#30340;&#26368;&#20808;&#36827;&#31574;&#30053;&#23384;&#22312;&#19968;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#20104;&#20197;&#35828;&#26126;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19978;&#32622;&#20449;&#21306;&#38388;&#65288;UCB&#65289;&#25277;&#26679;&#31574;&#30053;&#65292;&#31216;&#20026;&#969;-UCB&#65292;&#24182;&#20351;&#29992;&#19981;&#23545;&#31216;&#32622;&#20449;&#21306;&#38388;&#12290;&#36825;&#20123;&#21306;&#38388;&#23610;&#24230;&#38543;&#30528;&#26679;&#26412;&#22343;&#20540;&#21644;&#38543;&#26426;&#21464;&#37327;&#36793;&#30028;&#20043;&#38388;&#30340;&#36317;&#31163;&#32780;&#21464;&#21270;&#65292;&#30456;&#23545;&#20110;&#25105;&#20204;&#30340;&#31454;&#20105;&#23545;&#25163;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#12289;&#26356;&#32039;&#23494;&#22320;&#20272;&#35745;&#22870;&#21169;&#25104;&#26412;&#27604;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#23545;&#25968;&#21518;&#24724;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#29615;&#22659;&#20013;&#22987;&#32456;&#20248;&#20110;&#29616;&#26377;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the stochastic Budgeted Multi-Armed Bandit (MAB) problem, where a player chooses from $K$ arms with unknown expected rewards and costs. The goal is to maximize the total reward under a budget constraint. A player thus seeks to choose the arm with the highest reward-cost ratio as often as possible. Current state-of-the-art policies for this problem have several issues, which we illustrate. To overcome them, we propose a new upper confidence bound (UCB) sampling policy, $\omega$-UCB, that uses asymmetric confidence intervals. These intervals scale with the distance between the sample mean and the bounds of a random variable, yielding a more accurate and tight estimation of the reward-cost ratio compared to our competitors. We show that our approach has logarithmic regret and consistently outperforms existing policies in synthetic and real settings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#28508;&#22312;&#37327;&#21270;&#30340;&#26041;&#24335;&#23454;&#29616;&#20102;&#35299;&#32544;&#34920;&#31034;&#23398;&#20064;&#65292;&#24182;&#36890;&#36807;&#20005;&#26684;&#30340;&#20132;&#27969;&#29942;&#39048;&#21644;&#24378;&#22823;&#30340;&#27169;&#22411;&#35268;&#33539;&#21270;&#25104;&#21151;&#23558;&#25968;&#25454;&#36827;&#34892;&#20102;&#32452;&#21512;&#32534;&#30721;&#21644;&#35299;&#30721;&#65292;&#26368;&#32456;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#35299;&#32544;&#24615;&#33021;&#65292;&#24182;&#25552;&#39640;&#20102;&#26631;&#20934;VAE&#27169;&#22411;&#23398;&#20064;&#34920;&#24449;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.18378</link><description>&lt;p&gt;
&#36890;&#36807;&#28508;&#22312;&#37327;&#21270;&#36827;&#34892;&#35299;&#32544;
&lt;/p&gt;
&lt;p&gt;
Disentanglement via Latent Quantization. (arXiv:2305.18378v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18378
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#28508;&#22312;&#37327;&#21270;&#30340;&#26041;&#24335;&#23454;&#29616;&#20102;&#35299;&#32544;&#34920;&#31034;&#23398;&#20064;&#65292;&#24182;&#36890;&#36807;&#20005;&#26684;&#30340;&#20132;&#27969;&#29942;&#39048;&#21644;&#24378;&#22823;&#30340;&#27169;&#22411;&#35268;&#33539;&#21270;&#25104;&#21151;&#23558;&#25968;&#25454;&#36827;&#34892;&#20102;&#32452;&#21512;&#32534;&#30721;&#21644;&#35299;&#30721;&#65292;&#26368;&#32456;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#35299;&#32544;&#24615;&#33021;&#65292;&#24182;&#25552;&#39640;&#20102;&#26631;&#20934;VAE&#27169;&#22411;&#23398;&#20064;&#34920;&#24449;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35299;&#32544;&#34920;&#31034;&#23398;&#20064;&#20013;&#65292;&#27169;&#22411;&#38656;&#35201;&#23558;&#25968;&#25454;&#38598;&#30340;&#22522;&#30784;&#21464;&#21270;&#22240;&#32032;&#20998;&#24320;&#24182;&#29420;&#31435;&#22320;&#34920;&#31034;&#20986;&#26469;&#65292;&#32780;&#27169;&#22411;&#24182;&#27809;&#26377;&#25552;&#20379;&#26377;&#20851;&#36825;&#20123;&#22240;&#32032;&#30340;&#30495;&#23454;&#20449;&#24687;&#65292;&#24402;&#32435;&#20559;&#35265;&#22312;&#23454;&#29616;&#35299;&#32544;&#26041;&#38754;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#26045;&#21152;&#20005;&#26684;&#30340;&#20132;&#27969;&#29942;&#39048;&#21644;&#24378;&#22823;&#30340;&#27169;&#22411;&#35268;&#33539;&#21270;&#65292;&#26500;&#24314;&#20102;&#19968;&#31181;&#26397;&#30528;&#32452;&#21512;&#32534;&#30721;&#21644;&#35299;&#30721;&#25968;&#25454;&#30340;&#24402;&#32435;&#20559;&#35265;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#23545;&#28508;&#22312;&#32500;&#24230;&#36827;&#34892;&#21487;&#23398;&#20064;&#30340;&#31163;&#25955;&#32534;&#30721;&#65292;&#24182;&#20026;&#27599;&#20010;&#32500;&#24230;&#24212;&#29992;&#19968;&#20010;&#21333;&#29420;&#30340;&#26631;&#37327;&#30721;&#20070;&#12290;&#28508;&#22312;&#37327;&#21270;&#36843;&#20351;&#32534;&#30721;&#22120;&#22312;&#35768;&#22810;&#25968;&#25454;&#28857;&#19978;&#20351;&#29992;&#23569;&#37327;&#28508;&#22312;&#20540;&#65292;&#20174;&#32780;&#20351;&#35299;&#30721;&#22120;&#33021;&#22815;&#20026;&#27599;&#20010;&#20540;&#20998;&#37197;&#19968;&#33268;&#30340;&#21547;&#20041;&#12290;&#35268;&#33539;&#21270;&#26377;&#21161;&#20110;&#23558;&#27169;&#22411;&#24341;&#21521;&#36825;&#31181;&#31616;&#26126;&#31574;&#30053;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#24191;&#27867;&#24212;&#29992;&#24615;&#65292;&#24182;&#19988;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;&#19968;&#31995;&#21015;&#26631;&#20934;VAE&#27169;&#22411;&#23398;&#20064;&#30340;&#34920;&#24449;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In disentangled representation learning, a model is asked to tease apart a dataset's underlying sources of variation and represent them independently of one another. Since the model is provided with no ground truth information about these sources, inductive biases take a paramount role in enabling disentanglement. In this work, we construct an inductive bias towards compositionally encoding and decoding data by enforcing a harsh communication bottleneck. Concretely, we do this by (i) quantizing the latent space into learnable discrete codes with a separate scalar codebook per dimension and (ii) applying strong model regularization via an unusually high weight decay. Intuitively, the quantization forces the encoder to use a small number of latent values across many datapoints, which in turn enables the decoder to assign a consistent meaning to each value. Regularization then serves to drive the model towards this parsimonious strategy. We demonstrate the broad applicability of this appr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36817;&#20284;&#28040;&#24687;&#20256;&#36882;&#31639;&#27861;&#26469;&#35299;&#20915;&#22312;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;&#22238;&#24402;&#38382;&#39064;&#65292;&#35813;&#31639;&#27861;&#36866;&#29992;&#20110;&#28151;&#21512;&#32447;&#24615;&#22238;&#24402;&#12289;&#26368;&#22823;&#20223;&#23556;&#22238;&#24402;&#21644;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#31561;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2304.02229</link><description>&lt;p&gt;
&#36890;&#36807;&#36817;&#20284;&#28040;&#24687;&#20256;&#36882;&#30340;&#28151;&#21512;&#22238;&#24402;&#65288;Mixed Regression via Approximate Message Passing&#65289;
&lt;/p&gt;
&lt;p&gt;
Mixed Regression via Approximate Message Passing. (arXiv:2304.02229v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02229
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36817;&#20284;&#28040;&#24687;&#20256;&#36882;&#31639;&#27861;&#26469;&#35299;&#20915;&#22312;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;&#22238;&#24402;&#38382;&#39064;&#65292;&#35813;&#31639;&#27861;&#36866;&#29992;&#20110;&#28151;&#21512;&#32447;&#24615;&#22238;&#24402;&#12289;&#26368;&#22823;&#20223;&#23556;&#22238;&#24402;&#21644;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#31561;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65288;GLM&#65289;&#20013;&#20855;&#26377;&#22810;&#20010;&#20449;&#21495;&#21644;&#28508;&#21464;&#37327;&#30340;&#22238;&#24402;&#38382;&#39064;&#12290;&#35813;&#27169;&#22411;&#34987;&#31216;&#20026;&#30697;&#38453;GLM&#65292;&#28085;&#30422;&#20102;&#35768;&#22810;&#22312;&#32479;&#35745;&#23398;&#20064;&#20013;&#24191;&#27867;&#30740;&#31350;&#30340;&#38382;&#39064;&#65292;&#21253;&#25324;&#28151;&#21512;&#32447;&#24615;&#22238;&#24402;&#12289;&#26368;&#22823;&#20223;&#23556;&#22238;&#24402;&#21644;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#31561;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36817;&#20284;&#28040;&#24687;&#20256;&#36882;&#65288;AMP&#65289;&#31639;&#27861;&#26469;&#20272;&#35745;&#30697;&#38453;GLM&#20013;&#30340;&#20449;&#21495;&#21644;&#28508;&#21464;&#37327;&#65292;&#24182;&#22312;&#39640;&#32500;&#26497;&#38480;&#20013;&#23545;&#20854;&#24615;&#33021;&#36827;&#34892;&#20102;&#20005;&#26684;&#30340;&#34920;&#24449;&#12290;&#35813;&#34920;&#24449;&#26159;&#36890;&#36807;&#29366;&#24577;&#28436;&#21270;&#36882;&#24402;&#26469;&#35745;&#31639;&#30340;&#65292;&#20174;&#32780;&#21487;&#20197;&#31934;&#30830;&#35745;&#31639;&#28176;&#36817;&#24615;&#33021;&#24230;&#37327;&#65292;&#20363;&#22914;&#20449;&#22122;&#27604;&#19979;&#38477;&#38408;&#20540;&#65288;threshold&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of regression in a generalized linear model (GLM) with multiple signals and latent variables. This model, which we call a matrix GLM, covers many widely studied problems in statistical learning, including mixed linear regression, max-affine regression, and mixture-of-experts. In mixed linear regression, each observation comes from one of $L$ signal vectors (regressors), but we do not know which one; in max-affine regression, each observation comes from the maximum of $L$ affine functions, each defined via a different signal vector. The goal in all these problems is to estimate the signals, and possibly some of the latent variables, from the observations. We propose a novel approximate message passing (AMP) algorithm for estimation in a matrix GLM and rigorously characterize its performance in the high-dimensional limit. This characterization is in terms of a state evolution recursion, which allows us to precisely compute performance measures such as the asymptotic 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36125;&#21494;&#26031;&#31639;&#27861;&#30340;&#33258;&#36866;&#24212;&#23454;&#39564;&#26694;&#26550;&#65292;&#21487;&#28789;&#27963;&#22788;&#29702;&#20219;&#20309;&#25209;&#22788;&#29702;&#22823;&#23567;&#12290;&#36890;&#36807;&#27491;&#24577;&#36817;&#20284;&#25351;&#23548;&#21487;&#25193;&#23637;&#33258;&#36866;&#24212;&#35774;&#35745;&#65292;&#37319;&#29992;&#27531;&#20313;&#26102;&#38480;&#20248;&#21270;&#36873;&#25321;&#37319;&#26679;&#20998;&#37197;&#65292;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2303.11582</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#36866;&#24212;&#24615;&#23454;&#39564;&#65306;&#28789;&#27963;&#25209;&#22788;&#29702;&#30340;&#36125;&#21494;&#26031;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Adaptive Experimentation at Scale: Bayesian Algorithms for Flexible Batches. (arXiv:2303.11582v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11582
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36125;&#21494;&#26031;&#31639;&#27861;&#30340;&#33258;&#36866;&#24212;&#23454;&#39564;&#26694;&#26550;&#65292;&#21487;&#28789;&#27963;&#22788;&#29702;&#20219;&#20309;&#25209;&#22788;&#29702;&#22823;&#23567;&#12290;&#36890;&#36807;&#27491;&#24577;&#36817;&#20284;&#25351;&#23548;&#21487;&#25193;&#23637;&#33258;&#36866;&#24212;&#35774;&#35745;&#65292;&#37319;&#29992;&#27531;&#20313;&#26102;&#38480;&#20248;&#21270;&#36873;&#25321;&#37319;&#26679;&#20998;&#37197;&#65292;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934;&#30340;&#36125;&#21494;&#26031;&#31639;&#27861;&#20551;&#23450;&#25345;&#32493;&#37325;&#26032;&#20998;&#37197;&#27979;&#37327;&#24037;&#20316;&#65292;&#36825;&#22312;&#23454;&#29616;&#36807;&#31243;&#20013;&#23384;&#22312;&#24310;&#36831;&#21453;&#39304;&#21644;&#22522;&#30784;&#35774;&#26045;/&#32452;&#32455;&#38590;&#39064;&#31561;&#25361;&#25112;&#12290;&#26412;&#25991;&#38024;&#23545;&#20165;&#26377;&#23569;&#25968;&#37325;&#26032;&#20998;&#37197;&#38454;&#27573;&#30340;&#23454;&#38469;&#24773;&#20917;&#65292;&#20854;&#20013;&#27979;&#37327;&#32467;&#26524;&#26159;&#20197;&#25209;&#22788;&#29702;&#24418;&#24335;&#27979;&#37327;&#30340;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36866;&#24212;&#24615;&#23454;&#39564;&#26694;&#26550;&#65292;&#21487;&#28789;&#27963;&#22788;&#29702;&#20219;&#20309;&#25209;&#22788;&#29702;&#22823;&#23567;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#35266;&#23519;&#26159;&#65292;&#22312;&#32479;&#35745;&#25512;&#26029;&#20013;&#26222;&#36941;&#20351;&#29992;&#30340;&#27491;&#24577;&#36817;&#20284;&#20063;&#21487;&#20197;&#25351;&#23548;&#21487;&#25193;&#23637;&#33258;&#36866;&#24212;&#35774;&#35745;&#12290;&#36890;&#36807;&#25512;&#23548;&#28176;&#36827;&#39034;&#24207;&#23454;&#39564;&#65292;&#25105;&#20204;&#21046;&#23450;&#20102;&#19968;&#31181;&#21160;&#24577;&#35268;&#21010;&#65292;&#21487;&#20197;&#21033;&#29992;&#24179;&#22343;&#22238;&#25253;&#30340;&#20808;&#39564;&#20449;&#24687;&#12290;&#21160;&#24577;&#35268;&#21010;&#30340;&#29366;&#24577;&#36716;&#31227;&#30456;&#23545;&#20110;&#37319;&#26679;&#20998;&#37197;&#26159;&#21487;&#24494;&#30340;&#65292;&#20801;&#35768;&#20351;&#29992;&#22522;&#20110;&#26799;&#24230;&#30340;&#26041;&#27861;&#36827;&#34892;&#35268;&#21010;&#21644;&#31574;&#30053;&#20248;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#36845;&#20195;&#35268;&#21010;&#26041;&#27861;&#65292;&#21363;&#27531;&#20313;&#26102;&#38480;&#20248;&#21270;&#65292;&#36890;&#36807;&#20248;&#21270;&#24179;&#34913;&#25506;&#32034;&#21644;&#21033;&#29992;&#30340;&#35268;&#21010;&#30446;&#26631;&#26469;&#36873;&#25321;&#37319;&#26679;&#20998;&#37197;&#12290;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#22522;&#20934;&#27979;&#35797;&#38382;&#39064;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#20855;&#26377;&#27169;&#22359;&#21270;&#21644;&#26131;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Standard bandit algorithms that assume continual reallocation of measurement effort are challenging to implement due to delayed feedback and infrastructural/organizational difficulties. Motivated by practical instances involving a handful of reallocation epochs in which outcomes are measured in batches, we develop a new adaptive experimentation framework that can flexibly handle any batch size. Our main observation is that normal approximations universal in statistical inference can also guide the design of scalable adaptive designs. By deriving an asymptotic sequential experiment, we formulate a dynamic program that can leverage prior information on average rewards. State transitions of the dynamic program are differentiable with respect to the sampling allocations, allowing the use of gradient-based methods for planning and policy optimization. We propose a simple iterative planning method, Residual Horizon Optimization, which selects sampling allocations by optimizing a planning obj
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#34892;&#20026;&#33391;&#22909;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;&#22797;&#26434;&#21160;&#21147;&#23398;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#24517;&#35201;&#30340;&#20559;&#32622;&#21644;&#36866;&#24403;&#30340;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#65292;&#24182;&#25552;&#20986;&#20102;&#35780;&#20272;&#27867;&#21270;&#33021;&#21147;&#21644;&#25512;&#26029;&#26102;&#39044;&#27979;&#32622;&#20449;&#24230;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2301.04900</link><description>&lt;p&gt;
&#19968;&#31181;&#34892;&#20026;&#33391;&#22909;&#30340;&#22270;&#31070;&#32463;&#36817;&#20284;&#22797;&#26434;&#21160;&#21147;&#23398;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Recipe for Well-behaved Graph Neural Approximations of Complex Dynamics. (arXiv:2301.04900v2 [cond-mat.stat-mech] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.04900
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#34892;&#20026;&#33391;&#22909;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;&#22797;&#26434;&#21160;&#21147;&#23398;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#24517;&#35201;&#30340;&#20559;&#32622;&#21644;&#36866;&#24403;&#30340;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#65292;&#24182;&#25552;&#20986;&#20102;&#35780;&#20272;&#27867;&#21270;&#33021;&#21147;&#21644;&#25512;&#26029;&#26102;&#39044;&#27979;&#32622;&#20449;&#24230;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#39537;&#21160;&#30340;&#24120;&#24494;&#20998;&#26041;&#31243;&#36817;&#20284;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#26041;&#27861;&#26469;&#21457;&#29616;&#21160;&#21147;&#31995;&#32479;&#27169;&#22411;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#32570;&#20047;&#26126;&#30830;&#21407;&#29702;&#30340;&#22797;&#26434;&#31995;&#32479;&#12290;&#26412;&#25991;&#30528;&#37325;&#30740;&#31350;&#20102;&#19968;&#31867;&#30001;&#32593;&#32476;&#37051;&#25509;&#30697;&#38453;&#32806;&#21512;&#30340;&#24120;&#24494;&#20998;&#26041;&#31243;&#31995;&#32479;&#25551;&#36848;&#30340;&#22797;&#26434;&#31995;&#32479;&#12290;&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#31995;&#32479;&#65292;&#21253;&#25324;&#37329;&#34701;&#12289;&#31038;&#20132;&#21644;&#31070;&#32463;&#31995;&#32479;&#65292;&#23646;&#20110;&#36825;&#31867;&#21160;&#21147;&#23398;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;&#36825;&#31181;&#21160;&#21147;&#31995;&#32479;&#30340;&#20851;&#38190;&#35201;&#32032;&#65292;&#21253;&#25324;&#24517;&#35201;&#30340;&#20559;&#32622;&#21644;&#36866;&#24403;&#30340;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#12290;&#24378;&#35843;&#19982;&#38745;&#24577;&#30417;&#30563;&#23398;&#20064;&#30340;&#21306;&#21035;&#65292;&#25105;&#20204;&#25552;&#20513;&#22312;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#30340;&#32463;&#20856;&#20551;&#35774;&#20043;&#22806;&#35780;&#20272;&#27867;&#21270;&#33021;&#21147;&#12290;&#20026;&#20102;&#22312;&#25512;&#26029;&#26102;&#20272;&#35745;&#39044;&#27979;&#30340;&#32622;&#20449;&#24230;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#19987;&#29992;&#30340;&#31354;&#27169;&#22411;&#12290;&#36890;&#36807;&#30740;&#31350;&#21508;&#31181;&#22797;&#26434;&#32593;&#32476;&#21160;&#21147;&#23398;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data-driven approximations of ordinary differential equations offer a promising alternative to classical methods in discovering a dynamical system model, particularly in complex systems lacking explicit first principles. This paper focuses on a complex system whose dynamics is described with a system of ordinary differential equations, coupled via a network adjacency matrix. Numerous real-world systems, including financial, social, and neural systems, belong to this class of dynamical models. We propose essential elements for approximating such dynamical systems using neural networks, including necessary biases and an appropriate neural architecture. Emphasizing the differences from static supervised learning, we advocate for evaluating generalization beyond classical assumptions of statistical learning theory. To estimate confidence in prediction during inference time, we introduce a dedicated null model. By studying various complex network dynamics, we demonstrate the neural network'
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#36830;&#32493;&#30340;&#20986;&#29983;&#27515;&#20129;&#21160;&#24577;&#65292;&#24182;&#25552;&#20986;&#20102;&#24369;&#20551;&#35774;&#12290;&#36890;&#36807;&#36825;&#31181;&#21160;&#24577;&#25511;&#21046;&#30340;&#27010;&#29575;&#23494;&#24230;&#25351;&#25968;&#32423;&#22320;&#24555;&#36895;&#25910;&#25947;&#21040;&#21513;&#24067;&#26031;&#24179;&#34913;&#27979;&#24230;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;&#22522;&#20110;&#32431;&#20986;&#29983;&#27515;&#20129;&#21160;&#24577;&#30340;&#25968;&#20540;&#37319;&#26679;&#22120;&#65292;&#24182;&#23545;&#20854;&#36924;&#36817;&#21697;&#36136;&#36827;&#34892;&#20102;&#23450;&#37327;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2211.00450</link><description>&lt;p&gt;
&#37319;&#26679;&#30340;&#20986;&#29983;&#27515;&#20129;&#21160;&#24577;&#65306;&#20840;&#23616;&#25910;&#25947;&#65292;&#36924;&#36817;&#21450;&#20854;&#28176;&#36817;&#24615;&#36136;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Birth-death dynamics for sampling: Global convergence, approximations and their asymptotics. (arXiv:2211.00450v2 [math.AP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.00450
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#36830;&#32493;&#30340;&#20986;&#29983;&#27515;&#20129;&#21160;&#24577;&#65292;&#24182;&#25552;&#20986;&#20102;&#24369;&#20551;&#35774;&#12290;&#36890;&#36807;&#36825;&#31181;&#21160;&#24577;&#25511;&#21046;&#30340;&#27010;&#29575;&#23494;&#24230;&#25351;&#25968;&#32423;&#22320;&#24555;&#36895;&#25910;&#25947;&#21040;&#21513;&#24067;&#26031;&#24179;&#34913;&#27979;&#24230;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;&#22522;&#20110;&#32431;&#20986;&#29983;&#27515;&#20129;&#21160;&#24577;&#30340;&#25968;&#20540;&#37319;&#26679;&#22120;&#65292;&#24182;&#23545;&#20854;&#36924;&#36817;&#21697;&#36136;&#36827;&#34892;&#20102;&#23450;&#37327;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20197;&#37319;&#26679;&#38750;&#20984;&#20301;&#21183;&#21513;&#24067;&#26031;&#27979;&#24230;&#20026;&#25361;&#25112;&#65292;&#30740;&#31350;&#20102;&#19968;&#31181;&#36830;&#32493;&#20986;&#29983;&#27515;&#20129;&#21160;&#24577;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24369;&#20551;&#35774;&#65292;&#25913;&#36827;&#20102;&#20808;&#21069;[51,57]&#30340;&#32467;&#26524;&#65292;&#35777;&#26126;&#20102;&#30001;Kullback-Leibler&#25955;&#24230;&#25110;$\chi^2$&#25955;&#24230;&#25511;&#21046;&#30340;&#20986;&#29983;&#27515;&#20129;&#27010;&#29575;&#23494;&#24230;&#20250;&#25351;&#25968;&#32423;&#24555;&#36895;&#22320;&#25910;&#25947;&#21040;&#21513;&#24067;&#26031;&#24179;&#34913;&#27979;&#24230;&#65292;&#20854;&#26222;&#36866;&#36895;&#29575;&#29420;&#31435;&#20110;&#21183;&#22418;&#12290;&#20026;&#20102;&#26500;&#24314;&#22522;&#20110;&#32431;&#20986;&#29983;&#27515;&#20129;&#21160;&#24577;&#30340;&#23454;&#29992;&#25968;&#20540;&#37319;&#26679;&#22120;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#20132;&#20114;&#31890;&#23376;&#31995;&#32479;&#65292;&#23427;&#28789;&#24863;&#26469;&#33258;&#20110;&#26799;&#24230;&#27969;&#32467;&#26500;&#21644;&#32463;&#20856;&#30340;Fokker-Planck&#26041;&#31243;&#65292;&#24182;&#20381;&#36182;&#20110;&#27979;&#37327;&#30340;&#22522;&#20110;&#26680;&#30340;&#36924;&#36817;&#12290;&#36890;&#36807;&#26799;&#24230;&#27969;&#30340;$\Gamma$-&#25910;&#25947;&#25216;&#26415;&#65292;&#35777;&#26126;&#22312;&#29615;&#19978;&#65292;&#26680;&#21270;&#21160;&#24577;&#30340;&#20809;&#28369;&#26377;&#30028;&#27491;&#35299;&#22312;&#26377;&#38480;&#26102;&#38388;&#38388;&#38548;&#20869;&#65292;&#24403;&#26680;&#24102;&#23485;&#25910;&#32553;&#21040;&#38646;&#26102;&#65292;&#25910;&#25947;&#20110;&#32431;&#20986;&#29983;&#27515;&#20129;&#21160;&#24577;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#20285;&#39532;&#25910;&#25947;&#30340;&#25216;&#26415;&#23545;&#32431;&#20986;&#29983;&#27515;&#20129;&#36807;&#31243;&#30340;&#36924;&#36817;&#21697;&#36136;&#36827;&#34892;&#20102;&#23450;&#37327;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by the challenge of sampling Gibbs measures with nonconvex potentials, we study a continuum birth-death dynamics. We improve results in previous works [51,57] and provide weaker hypotheses under which the probability density of the birth-death governed by Kullback-Leibler divergence or by $\chi^2$ divergence converge exponentially fast to the Gibbs equilibrium measure, with a universal rate that is independent of the potential barrier. To build a practical numerical sampler based on the pure birth-death dynamics, we consider an interacting particle system, which is inspired by the gradient flow structure and the classical Fokker-Planck equation and relies on kernel-based approximations of the measure. Using the technique of $\Gamma$-convergence of gradient flows, we show that on the torus, smooth and bounded positive solutions of the kernelized dynamics converge on finite time intervals, to the pure birth-death dynamics as the kernel bandwidth shrinks to zero. Moreover we pro
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19968;&#38454;&#20248;&#21270;&#31639;&#27861;AG-OG&#65292;&#29992;&#20110;&#21487;&#20998;&#31163;&#30340;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#38382;&#39064;&#12290;&#36890;&#36807;&#31934;&#32454;&#22320;&#21033;&#29992;&#38382;&#39064;&#32467;&#26500;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#65292;&#21487;&#20197;&#36866;&#29992;&#20110;&#22810;&#31181;&#35774;&#32622;&#65292;&#21253;&#25324;&#21452;&#32447;&#24615;&#32806;&#21512;&#30340;&#24378;&#20984;-&#24378;&#20985;&#12289;&#20984;-&#24378;&#20985;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#21644;&#21452;&#32447;&#24615;&#21338;&#24328;&#12290;&#35813;&#31639;&#27861;&#36824;&#22312;&#38543;&#26426;&#35774;&#32622;&#19979;&#36798;&#21040;&#20102;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#21452;&#32447;&#24615;&#32806;&#21512;&#30340;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#38382;&#39064;&#20013;&#22312;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#35774;&#32622;&#19979;&#37117;&#20855;&#26377;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#30340;&#21333;&#27425;&#35843;&#29992;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2210.17550</link><description>&lt;p&gt;
Nesterov&#36935;&#35265;&#20048;&#35266;&#20027;&#20041;&#65306;&#36895;&#29575;&#26368;&#20248;&#30340;&#21487;&#20998;&#31163;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Nesterov Meets Optimism: Rate-Optimal Separable Minimax Optimization. (arXiv:2210.17550v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.17550
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19968;&#38454;&#20248;&#21270;&#31639;&#27861;AG-OG&#65292;&#29992;&#20110;&#21487;&#20998;&#31163;&#30340;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#38382;&#39064;&#12290;&#36890;&#36807;&#31934;&#32454;&#22320;&#21033;&#29992;&#38382;&#39064;&#32467;&#26500;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#65292;&#21487;&#20197;&#36866;&#29992;&#20110;&#22810;&#31181;&#35774;&#32622;&#65292;&#21253;&#25324;&#21452;&#32447;&#24615;&#32806;&#21512;&#30340;&#24378;&#20984;-&#24378;&#20985;&#12289;&#20984;-&#24378;&#20985;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#21644;&#21452;&#32447;&#24615;&#21338;&#24328;&#12290;&#35813;&#31639;&#27861;&#36824;&#22312;&#38543;&#26426;&#35774;&#32622;&#19979;&#36798;&#21040;&#20102;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#21452;&#32447;&#24615;&#32806;&#21512;&#30340;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#38382;&#39064;&#20013;&#22312;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#35774;&#32622;&#19979;&#37117;&#20855;&#26377;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#30340;&#21333;&#27425;&#35843;&#29992;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19968;&#38454;&#20248;&#21270;&#31639;&#27861; - &#21152;&#36895;&#26799;&#24230;-&#20048;&#35266;&#26799;&#24230;&#65288;AG-OG&#65289;&#19979;&#38477;&#19978;&#21319;&#27861;&#65292;&#29992;&#20110;&#21487;&#20998;&#31163;&#30340;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#31639;&#27861;&#30340;&#20027;&#35201;&#24605;&#24819;&#26159;&#31934;&#32454;&#22320;&#21033;&#29992;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#32467;&#26500;&#65292;&#22312;&#20010;&#20307;&#32452;&#20214;&#19978;&#36827;&#34892;Nesterov&#21152;&#36895;&#65292;&#24182;&#22312;&#32806;&#21512;&#32452;&#20214;&#19978;&#36827;&#34892;&#20048;&#35266;&#26799;&#24230;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;AG-OG&#22312;&#21508;&#31181;&#35774;&#32622;&#19979;&#65288;&#21253;&#25324;&#21452;&#32447;&#24615;&#32806;&#21512;&#30340;&#24378;&#20984;-&#24378;&#20985;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#65292;&#21452;&#32447;&#24615;&#32806;&#21512;&#30340;&#20984;-&#24378;&#20985;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#21644;&#21452;&#32447;&#24615;&#21338;&#24328;&#65289;&#23454;&#29616;&#20102;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#65288;&#24120;&#25968;&#22240;&#23376;&#20043;&#20869;&#65289;&#12290;&#25105;&#20204;&#36824;&#23558;&#25105;&#20204;&#30340;&#31639;&#27861;&#25193;&#23637;&#21040;&#38543;&#26426;&#35774;&#32622;&#65292;&#24182;&#22312;&#21452;&#32447;&#24615;&#32806;&#21512;&#30340;&#24378;&#20984;-&#24378;&#20985;&#21644;&#20984;-&#24378;&#20985;&#35774;&#32622;&#19979;&#36798;&#21040;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;AG-OG&#26159;&#31532;&#19968;&#20010;&#22312;&#21452;&#32447;&#24615;&#32806;&#21512;&#30340;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#38382;&#39064;&#30340;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#35774;&#32622;&#19979;&#37117;&#20855;&#26377;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#30340;&#21333;&#27425;&#35843;&#29992;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new first-order optimization algorithm -AcceleratedGradient-OptimisticGradient (AG-OG) Descent Ascent -- for separable convex-concave minimax optimization. The main idea of our algorithm is to carefully leverage the structure of the minimax problem, performing Nesterov acceleration on the individual component and optimistic gradient on the coupling component. Equipped with proper restarting, we show that AG-OG achieves the optimal convergence rate (up to a constant) for a variety of settings, including bilinearly coupled strongly convex-strongly concave minimax optimization (bi-SC-SC), bilinearly coupled convex-strongly concave minimax optimization (bi-C-SC), and bilinear games. We also extend our algorithm to the stochastic setting and achieve the optimal convergence rate in both bi-SC-SC and bi-C-SC settings. AG-OG is the first single-call algorithm with optimal convergence rates in both deterministic and stochastic settings for bilinearly coupled minimax optimization 
&lt;/p&gt;</description></item><item><title>&#36825;&#26159;&#19968;&#31687;&#20851;&#20110;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#21452;&#26354;&#22810;&#32500;&#26631;&#24230;&#26041;&#27861;&#30340;&#35770;&#25991;&#65292;&#36890;&#36807;&#22312;&#21452;&#26354;&#31354;&#38388;&#20013;&#34920;&#31034;&#20302;&#32500;&#22270;&#24418;&#26469;&#22788;&#29702;&#39640;&#32500;&#30456;&#20851;&#25968;&#25454;&#65292;&#20174;&#32780;&#36866;&#29992;&#20110;&#20855;&#26377;&#26641;&#29366;&#32467;&#26500;&#30340;&#25968;&#25454;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#26377;&#25928;&#30340;&#21518;&#39564;&#37319;&#26679;&#26041;&#27861;&#65292;&#38477;&#20302;&#20102;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;</title><link>http://arxiv.org/abs/2210.15081</link><description>&lt;p&gt;
Bayesian&#21452;&#26354;&#22810;&#32500;&#26631;&#24230;
&lt;/p&gt;
&lt;p&gt;
Bayesian Hyperbolic Multidimensional Scaling. (arXiv:2210.15081v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.15081
&lt;/p&gt;
&lt;p&gt;
&#36825;&#26159;&#19968;&#31687;&#20851;&#20110;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#21452;&#26354;&#22810;&#32500;&#26631;&#24230;&#26041;&#27861;&#30340;&#35770;&#25991;&#65292;&#36890;&#36807;&#22312;&#21452;&#26354;&#31354;&#38388;&#20013;&#34920;&#31034;&#20302;&#32500;&#22270;&#24418;&#26469;&#22788;&#29702;&#39640;&#32500;&#30456;&#20851;&#25968;&#25454;&#65292;&#20174;&#32780;&#36866;&#29992;&#20110;&#20855;&#26377;&#26641;&#29366;&#32467;&#26500;&#30340;&#25968;&#25454;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#26377;&#25928;&#30340;&#21518;&#39564;&#37319;&#26679;&#26041;&#27861;&#65292;&#38477;&#20302;&#20102;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#32500;&#26631;&#24230;&#65288;MDS&#65289;&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#20110;&#34920;&#31034;&#39640;&#32500;&#12289;&#30456;&#20851;&#25968;&#25454;&#30340;&#26041;&#27861;&#12290;MDS&#36890;&#36807;&#20026;&#27599;&#20010;&#35266;&#27979;&#20998;&#37197;&#19968;&#20010;&#20302;&#32500;&#20960;&#20309;&#22270;&#24418;&#19978;&#30340;&#20301;&#32622;&#26469;&#24037;&#20316;&#65292;&#22270;&#24418;&#19978;&#30340;&#36317;&#31163;&#34920;&#31034;&#30456;&#20284;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#26041;&#27861;&#26469;&#22788;&#29702;&#20302;&#32500;&#22270;&#24418;&#20026;&#21452;&#26354;&#32447;&#30340;&#22810;&#32500;&#26631;&#24230;&#12290;&#20351;&#29992;&#21452;&#26354;&#31354;&#38388;&#26377;&#21161;&#20110;&#34920;&#31034;&#35768;&#22810;&#22330;&#26223;&#20013;&#24120;&#35265;&#30340;&#26641;&#29366;&#32467;&#26500;&#65288;&#20363;&#22914;&#20855;&#26377;&#23618;&#27425;&#32467;&#26500;&#30340;&#25991;&#26412;&#25110;&#36951;&#20256;&#25968;&#25454;&#65289;&#12290;&#36125;&#21494;&#26031;&#26041;&#27861;&#25552;&#20379;&#20102;&#23545;&#35266;&#27979;&#25968;&#25454;&#20013;&#27979;&#37327;&#35823;&#24046;&#30340;&#26368;&#23567;&#21270;&#24433;&#21709;&#21644;&#19981;&#30830;&#23450;&#24615;&#35780;&#20272;&#30340;&#27491;&#21017;&#21270;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#24773;&#20917;&#23545;&#29031;&#20284;&#28982;&#20272;&#35745;&#36817;&#20284;&#20540;&#65292;&#20801;&#35768;&#22312;&#26356;&#22823;&#30340;&#25968;&#25454;&#35774;&#32622;&#20013;&#20174;&#21518;&#39564;&#20998;&#24067;&#20013;&#39640;&#25928;&#37319;&#26679;&#65292;&#23558;&#35745;&#31639;&#22797;&#26434;&#24615;&#20174;&#36817;&#20284;$O(n^2)$&#38477;&#20302;&#21040;$O(n)$&#12290;&#25105;&#20204;&#20351;&#29992;&#27169;&#25311;&#12289;&#32463;&#20856;&#21442;&#32771;&#25968;&#25454;&#38598;&#12289;&#21360;&#24230;vil&#36827;&#34892;&#20102;&#23545;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#19982;&#19994;&#30028;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Multidimensional scaling (MDS) is a widely used approach to representing high-dimensional, dependent data. MDS works by assigning each observation a location on a low-dimensional geometric manifold, with distance on the manifold representing similarity. We propose a Bayesian approach to multidimensional scaling when the low-dimensional manifold is hyperbolic. Using hyperbolic space facilitates representing tree-like structures common in many settings (e.g. text or genetic data with hierarchical structure). A Bayesian approach provides regularization that minimizes the impact of measurement error in the observed data and assesses uncertainty. We also propose a case-control likelihood approximation that allows for efficient sampling from the posterior distribution in larger data settings, reducing computational complexity from approximately $O(n^2)$ to $O(n)$. We evaluate the proposed method against state-of-the-art alternatives using simulations, canonical reference datasets, Indian vil
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#35777;&#26126;&#30340;&#38381;&#24335;&#26041;&#31243;&#65292;&#25551;&#36848;&#20102;&#19968;&#31867;&#22522;&#20110;&#26799;&#24230;&#30340;&#26041;&#27861;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#30340;&#31934;&#30830;&#28176;&#36827;&#24615;&#33021;&#65292;&#20026;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31561;&#31639;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#25903;&#25345;&#65292;&#24182;&#25552;&#20379;&#20102;&#25968;&#20540;&#23454;&#29616;&#12290;</title><link>http://arxiv.org/abs/2210.06591</link><description>&lt;p&gt;
&#20005;&#26684;&#30340;&#21160;&#21147;&#23398;&#22343;&#22330;&#29702;&#35770;&#29992;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Rigorous dynamical mean field theory for stochastic gradient descent methods. (arXiv:2210.06591v2 [math-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.06591
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#35777;&#26126;&#30340;&#38381;&#24335;&#26041;&#31243;&#65292;&#25551;&#36848;&#20102;&#19968;&#31867;&#22522;&#20110;&#26799;&#24230;&#30340;&#26041;&#27861;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#30340;&#31934;&#30830;&#28176;&#36827;&#24615;&#33021;&#65292;&#20026;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31561;&#31639;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#25903;&#25345;&#65292;&#24182;&#25552;&#20379;&#20102;&#25968;&#20540;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#31867;&#22522;&#20110;&#26799;&#24230;&#30340;&#26041;&#27861;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#30340;&#31934;&#30830;&#28176;&#36827;&#24615;&#33021;&#38381;&#24335;&#26041;&#31243;&#65292;&#35813;&#26041;&#27861;&#20174;&#39640;&#26031;&#25968;&#25454;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#23398;&#20064;&#20272;&#35745;&#22120;&#65288;&#20363;&#22914;M-&#20272;&#35745;&#22120;&#65292;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;...&#65289;&#12290;&#36825;&#21253;&#25324;&#20102;&#24191;&#27867;&#20351;&#29992;&#30340;&#31639;&#27861;&#65292;&#22914;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#25110;Nesterov&#21152;&#36895;&#12290;&#24471;&#21040;&#30340;&#26041;&#31243;&#19982;&#23558;&#21160;&#21147;&#23398;&#22343;&#22330;&#29702;&#35770;&#65288;DMFT&#65289;&#26041;&#31243;&#31163;&#25955;&#21270;&#21518;&#24212;&#29992;&#20110;&#26799;&#24230;&#27969;&#26102;&#20135;&#29983;&#30340;&#26041;&#31243;&#30456;&#21305;&#37197;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#26041;&#27861;&#20801;&#35768;&#25105;&#20204;&#26126;&#30830;&#25551;&#36848;&#35760;&#24518;&#26680;&#22312;&#26377;&#25928;&#21160;&#21147;&#23398;&#20013;&#22914;&#20309;&#26500;&#24314;&#65292;&#24182;&#19988;&#21253;&#25324;&#38750;&#21487;&#20998;&#31163;&#30340;&#26356;&#26032;&#20989;&#25968;&#65292;&#20801;&#35768;&#20855;&#26377;&#38750;&#21333;&#20301;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#25968;&#25454;&#38598;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20855;&#26377;&#36890;&#29992;&#25209;&#22788;&#29702;&#22823;&#23567;&#21644;&#24658;&#23450;&#23398;&#20064;&#29575;&#30340;SGD&#26041;&#31243;&#30340;&#25968;&#20540;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We prove closed-form equations for the exact high-dimensional asymptotics of a family of first order gradient-based methods, learning an estimator (e.g. M-estimator, shallow neural network, ...) from observations on Gaussian data with empirical risk minimization. This includes widely used algorithms such as stochastic gradient descent (SGD) or Nesterov acceleration. The obtained equations match those resulting from the discretization of dynamical mean-field theory (DMFT) equations from statistical physics when applied to gradient flow. Our proof method allows us to give an explicit description of how memory kernels build up in the effective dynamics, and to include non-separable update functions, allowing datasets with non-identity covariance matrices. Finally, we provide numerical implementations of the equations for SGD with generic extensive batch-size and with constant learning rates.
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#20998;&#31867;&#22120;&#30340;&#26032;&#39062;&#22810;&#21464;&#37327;&#38750;&#21442;&#25968;&#22810;&#21464;&#28857;&#26816;&#27979;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20197;&#38543;&#26426;&#26862;&#26519;&#20026;&#26680;&#24515;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#32463;&#39564;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2205.04997</link><description>&lt;p&gt;
&#38543;&#26426;&#26862;&#26519;&#29992;&#20110;&#21464;&#28857;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Random Forests for Change Point Detection. (arXiv:2205.04997v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.04997
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#20998;&#31867;&#22120;&#30340;&#26032;&#39062;&#22810;&#21464;&#37327;&#38750;&#21442;&#25968;&#22810;&#21464;&#28857;&#26816;&#27979;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20197;&#38543;&#26426;&#26862;&#26519;&#20026;&#26680;&#24515;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#32463;&#39564;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#21464;&#37327;&#38750;&#21442;&#25968;&#22810;&#21464;&#28857;&#26816;&#27979;&#26041;&#27861;&#65292;&#20351;&#29992;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#20998;&#31867;&#22120;&#23545;&#25968;&#20284;&#28982;&#27604;&#65292;&#21033;&#29992;&#31867;&#27010;&#29575;&#39044;&#27979;&#26469;&#27604;&#36739;&#19981;&#21516;&#30340;&#21464;&#28857;&#37197;&#32622;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#21487;&#34892;&#30340;&#25628;&#32034;&#26041;&#27861;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#38543;&#26426;&#26862;&#26519;&#65292;&#31216;&#20026;changeforest&#12290;&#28982;&#32780;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#19982;&#20219;&#20309;&#20135;&#29983;&#31867;&#27010;&#29575;&#39044;&#27979;&#30340;&#20998;&#31867;&#22120;&#37197;&#23545;&#20351;&#29992;&#65292;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;k&#26368;&#36817;&#37051;&#20998;&#31867;&#22120;&#26469;&#35828;&#26126;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#19982;&#19968;&#33268;&#30340;&#20998;&#31867;&#22120;&#37197;&#23545;&#26102;&#65292;&#22312;&#21333;&#21464;&#28857;&#35774;&#32622;&#20013;&#65292;&#23427;&#33021;&#22815;&#19968;&#33268;&#22320;&#23450;&#20301;&#21464;&#28857;&#12290;&#22312;&#24191;&#27867;&#30340;&#27169;&#25311;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;changeforest&#30456;&#36739;&#20110;&#29616;&#26377;&#30340;&#22810;&#21464;&#37327;&#38750;&#21442;&#25968;&#21464;&#28857;&#26816;&#27979;&#26041;&#27861;&#23454;&#29616;&#20102;&#25913;&#36827;&#30340;&#32463;&#39564;&#24615;&#33021;&#12290;&#25105;&#20204;&#20026;R&#65292;Python&#21644;Rust&#29992;&#25143;&#25552;&#20379;&#20102;changeforest&#36719;&#20214;&#21253;&#30340;&#39640;&#25928;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel multivariate nonparametric multiple change point detection method using classifiers. We construct a classifier log-likelihood ratio that uses class probability predictions to compare different change point configurations. We propose a computationally feasible search method that is particularly well suited for random forests, denoted by changeforest. However, the method can be paired with any classifier that yields class probability predictions, which we illustrate by also using a k-nearest neighbor classifier. We prove that it consistently locates change points in single change point settings when paired with a consistent classifier. Our proposed method changeforest achieves improved empirical performance in an extensive simulation study compared to existing multivariate nonparametric change point detection methods. An efficient implementation of our method is made available for R, Python, and Rust users in the changeforest software package.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#36328;&#20219;&#21153;&#20849;&#20139;&#20302;&#32500;&#32447;&#24615;&#34920;&#31034;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36857;&#33539;&#25968;&#27491;&#21017;&#21270;&#30340;&#39640;&#25928;&#36138;&#23146;&#31574;&#30053;&#65292;&#22312;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#23398;&#20064;&#20302;&#32500;&#34920;&#31034;&#65292;&#26080;&#38656;&#30693;&#36947;&#28508;&#22312;&#30697;&#38453;&#30340;&#31209;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#31574;&#30053;&#30456;&#27604;&#22522;&#32447;&#22312;&#22810;&#20219;&#21153;&#36951;&#25022;&#19978;&#26377;&#26126;&#26174;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2202.10066</link><description>&lt;p&gt;
&#22810;&#20219;&#21153;&#34920;&#31034;&#23398;&#20064;&#19982;&#38543;&#26426;&#32447;&#24615;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
Multi-task Representation Learning with Stochastic Linear Bandits. (arXiv:2202.10066v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.10066
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#36328;&#20219;&#21153;&#20849;&#20139;&#20302;&#32500;&#32447;&#24615;&#34920;&#31034;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36857;&#33539;&#25968;&#27491;&#21017;&#21270;&#30340;&#39640;&#25928;&#36138;&#23146;&#31574;&#30053;&#65292;&#22312;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#23398;&#20064;&#20302;&#32500;&#34920;&#31034;&#65292;&#26080;&#38656;&#30693;&#36947;&#28508;&#22312;&#30697;&#38453;&#30340;&#31209;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#31574;&#30053;&#30456;&#27604;&#22522;&#32447;&#22312;&#22810;&#20219;&#21153;&#36951;&#25022;&#19978;&#26377;&#26126;&#26174;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#38543;&#26426;&#32447;&#24615;&#36172;&#21338;&#26426;&#20219;&#21153;&#20013;&#30340;&#36801;&#31227;&#23398;&#20064;&#38382;&#39064;&#12290;&#25105;&#20204;&#32771;&#34385;&#36328;&#20219;&#21153;&#20849;&#20139;&#20302;&#32500;&#32447;&#24615;&#34920;&#31034;&#65292;&#24182;&#30740;&#31350;&#22312;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#23398;&#20064;&#36825;&#31181;&#34920;&#31034;&#30340;&#30410;&#22788;&#12290;&#26681;&#25454;&#26368;&#26032;&#30340;&#38543;&#26426;&#36172;&#21338;&#26426;&#31574;&#30053;&#35774;&#35745;&#32467;&#26524;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36857;&#33539;&#25968;&#27491;&#21017;&#21270;&#30340;&#39640;&#25928;&#36138;&#23146;&#31574;&#30053;&#12290;&#23427;&#36890;&#36807;&#40723;&#21169;&#20219;&#21153;&#22238;&#24402;&#21521;&#37327;&#24418;&#25104;&#30340;&#30697;&#38453;&#20855;&#26377;&#20302;&#31209;&#26469;&#38544;&#24335;&#22320;&#23398;&#20064;&#20302;&#32500;&#34920;&#31034;&#12290;&#19982;&#25991;&#29486;&#20013;&#30340;&#20808;&#21069;&#24037;&#20316;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#31574;&#30053;&#19981;&#38656;&#35201;&#30693;&#36947;&#28508;&#22312;&#30697;&#38453;&#30340;&#31209;&#12290;&#25105;&#20204;&#23548;&#20986;&#20102;&#25105;&#20204;&#31574;&#30053;&#30340;&#22810;&#20219;&#21153;&#36951;&#25022;&#30340;&#19978;&#30028;&#65292;&#35813;&#19978;&#30028;&#22312;&#23545;&#25968;&#22240;&#23376;&#19978;&#26159;$O(\sqrt{NdT(T+d)r})$&#65292;&#20854;&#20013;$T$&#26159;&#20219;&#21153;&#25968;&#65292;$r$&#26159;&#31209;&#65292;$d$&#26159;&#21464;&#37327;&#25968;&#65292;$N$&#26159;&#27599;&#20010;&#20219;&#21153;&#30340;&#22238;&#21512;&#25968;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19982;&#22522;&#32447;$Td\sqrt{N}$&#30456;&#27604;&#65292;&#25105;&#20204;&#31574;&#30053;&#30340;&#30410;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of transfer-learning in the setting of stochastic linear bandit tasks. We consider that a low dimensional linear representation is shared across the tasks, and study the benefit of learning this representation in the multi-task learning setting. Following recent results to design stochastic bandit policies, we propose an efficient greedy policy based on trace norm regularization. It implicitly learns a low dimensional representation by encouraging the matrix formed by the task regression vectors to be of low rank. Unlike previous work in the literature, our policy does not need to know the rank of the underlying matrix. We derive an upper bound on the multi-task regret of our policy, which is, up to logarithmic factors, of order $\sqrt{NdT(T+d)r}$, where $T$ is the number of tasks, $r$ the rank, $d$ the number of variables and $N$ the number of rounds per task. We show the benefit of our strategy compared to the baseline $Td\sqrt{N}$ obtained by solving each task i
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21464;&#20998;&#21513;&#24067;&#26031;&#25512;&#26029;&#65288;VGI&#65289;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20351;&#29992;&#19981;&#23436;&#20840;&#25968;&#25454;&#36827;&#34892;&#32479;&#35745;&#27169;&#22411;&#20272;&#35745;&#26102;&#30340;&#25361;&#25112;&#12290;&#19982;&#26631;&#20934;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#19981;&#21516;&#65292;VGI&#33021;&#22815;&#22788;&#29702;&#20272;&#35745;&#25351;&#25968;&#22810;&#20010;&#32570;&#22833;&#21464;&#37327;&#30340;&#26465;&#20214;&#20998;&#24067;&#65292;&#20174;&#32780;&#20026;&#23454;&#38469;&#30340;&#25968;&#25454;&#38598;&#25552;&#20379;&#20102;&#26356;&#20934;&#30830;&#30340;&#27169;&#22411;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2111.13180</link><description>&lt;p&gt;
&#19981;&#23436;&#20840;&#25968;&#25454;&#32479;&#35745;&#27169;&#22411;&#20272;&#35745;&#30340;&#21464;&#20998;&#21513;&#24067;&#26031;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Variational Gibbs Inference for Statistical Model Estimation from Incomplete Data. (arXiv:2111.13180v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.13180
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21464;&#20998;&#21513;&#24067;&#26031;&#25512;&#26029;&#65288;VGI&#65289;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20351;&#29992;&#19981;&#23436;&#20840;&#25968;&#25454;&#36827;&#34892;&#32479;&#35745;&#27169;&#22411;&#20272;&#35745;&#26102;&#30340;&#25361;&#25112;&#12290;&#19982;&#26631;&#20934;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#19981;&#21516;&#65292;VGI&#33021;&#22815;&#22788;&#29702;&#20272;&#35745;&#25351;&#25968;&#22810;&#20010;&#32570;&#22833;&#21464;&#37327;&#30340;&#26465;&#20214;&#20998;&#24067;&#65292;&#20174;&#32780;&#20026;&#23454;&#38469;&#30340;&#25968;&#25454;&#38598;&#25552;&#20379;&#20102;&#26356;&#20934;&#30830;&#30340;&#27169;&#22411;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32479;&#35745;&#27169;&#22411;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#20855;&#26377;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#65292;&#21487;&#29992;&#20110;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#12290;&#36825;&#20123;&#27169;&#22411;&#30001;&#33258;&#30001;&#21442;&#25968;&#25511;&#21046;&#65292;&#36890;&#24120;&#36890;&#36807;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#25110;&#20854;&#36817;&#20284;&#26041;&#27861;&#20174;&#25968;&#25454;&#20013;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#24403;&#38754;&#23545;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#26102;&#65292;&#35768;&#22810;&#27169;&#22411;&#37117;&#20250;&#36935;&#21040;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#65306;&#23427;&#20204;&#26159;&#20197;&#23436;&#20840;&#35266;&#27979;&#30340;&#25968;&#25454;&#20026;&#22522;&#30784;&#30340;&#65292;&#32780;&#23454;&#38469;&#19978;&#25968;&#25454;&#38598;&#20013;&#23384;&#22312;&#32570;&#22833;&#25968;&#25454;&#12290;&#20174;&#19981;&#23436;&#20840;&#25968;&#25454;&#20013;&#36827;&#34892;&#32479;&#35745;&#27169;&#22411;&#20272;&#35745;&#30340;&#29702;&#35770;&#22312;&#27010;&#24565;&#19978;&#31867;&#20284;&#20110;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#20272;&#35745;&#65292;&#20854;&#20013;&#23384;&#22312;&#35832;&#22914;&#21464;&#20998;&#25512;&#26029;&#65288;VI&#65289;&#20043;&#31867;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#19982;&#26631;&#20934;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#19981;&#21516;&#65292;&#20351;&#29992;&#19981;&#23436;&#20840;&#25968;&#25454;&#30340;&#21442;&#25968;&#20272;&#35745;&#36890;&#24120;&#38656;&#35201;&#20272;&#35745;&#25351;&#25968;&#22810;&#20010;&#32570;&#22833;&#21464;&#37327;&#30340;&#26465;&#20214;&#20998;&#24067;&#65292;&#22240;&#27492;&#20351;&#24471;&#26631;&#20934;&#30340;VI&#26041;&#27861;&#38590;&#20197;&#22788;&#29702;&#12290;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#21464;&#20998;&#21513;&#24067;&#26031;&#25512;&#26029;&#65288;VGI&#65289;&#65292;&#19968;&#31181;&#26032;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#26469;&#22635;&#34917;&#36825;&#19968;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
Statistical models are central to machine learning with broad applicability across a range of downstream tasks. The models are controlled by free parameters that are typically estimated from data by maximum-likelihood estimation or approximations thereof. However, when faced with real-world data sets many of the models run into a critical issue: they are formulated in terms of fully-observed data, whereas in practice the data sets are plagued with missing data. The theory of statistical model estimation from incomplete data is conceptually similar to the estimation of latent-variable models, where powerful tools such as variational inference (VI) exist. However, in contrast to standard latent-variable models, parameter estimation with incomplete data often requires estimating exponentially-many conditional distributions of the missing variables, hence making standard VI methods intractable. We address this gap by introducing variational Gibbs inference (VGI), a new general-purpose meth
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32858;&#31867;&#26041;&#27861;&#65292;&#36890;&#36807;&#23450;&#20041;&#36807;&#28193;&#32858;&#31867;&#24182;&#24212;&#29992;&#23436;&#22791;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#31616;&#21270;&#22240;&#26524;&#22270;&#20013;&#30340;&#21464;&#37327;&#20851;&#31995;&#65292;&#24182;&#20445;&#30041;&#22240;&#26524;&#25928;&#24212;&#30340;&#21487;&#36776;&#35782;&#24615;&#23646;&#24615;&#12290;</title><link>http://arxiv.org/abs/2111.04513</link><description>&lt;p&gt;
&#32858;&#31867;&#21644;&#22240;&#26524;&#22270;&#20013;&#30340;&#32467;&#26500;&#31283;&#20581;&#24615;
&lt;/p&gt;
&lt;p&gt;
Clustering and Structural Robustness in Causal Diagrams. (arXiv:2111.04513v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.04513
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32858;&#31867;&#26041;&#27861;&#65292;&#36890;&#36807;&#23450;&#20041;&#36807;&#28193;&#32858;&#31867;&#24182;&#24212;&#29992;&#23436;&#22791;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#31616;&#21270;&#22240;&#26524;&#22270;&#20013;&#30340;&#21464;&#37327;&#20851;&#31995;&#65292;&#24182;&#20445;&#30041;&#22240;&#26524;&#25928;&#24212;&#30340;&#21487;&#36776;&#35782;&#24615;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#34920;&#24120;&#29992;&#20110;&#34920;&#31034;&#21644;&#21487;&#35270;&#21270;&#22240;&#26524;&#20851;&#31995;&#12290;&#23545;&#20110;&#23569;&#37327;&#21464;&#37327;&#65292;&#36825;&#31181;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#27905;&#28165;&#26224;&#30340;&#22330;&#26223;&#35270;&#22270;&#12290;&#20294;&#26159;&#38543;&#30528;&#30740;&#31350;&#21464;&#37327;&#25968;&#37327;&#30340;&#22686;&#21152;&#65292;&#22270;&#34920;&#26041;&#27861;&#21487;&#33021;&#21464;&#24471;&#19981;&#21487;&#34892;&#65292;&#24182;&#19988;&#34920;&#31034;&#30340;&#28165;&#26224;&#24230;&#20007;&#22833;&#12290;&#21464;&#37327;&#32858;&#31867;&#26159;&#20943;&#23567;&#22240;&#26524;&#22270;&#22823;&#23567;&#30340;&#19968;&#31181;&#33258;&#28982;&#26041;&#24335;&#65292;&#20294;&#22914;&#26524;&#38543;&#24847;&#23454;&#26045;&#65292;&#21487;&#33021;&#20250;&#38169;&#35823;&#22320;&#25913;&#21464;&#22240;&#26524;&#20851;&#31995;&#30340;&#37325;&#35201;&#23646;&#24615;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#19968;&#31181;&#29305;&#23450;&#31867;&#22411;&#30340;&#32858;&#31867;&#65292;&#31216;&#20026;&#36807;&#28193;&#32858;&#31867;&#65292;&#22312;&#26576;&#20123;&#26465;&#20214;&#19979;&#20445;&#35777;&#20445;&#30041;&#22240;&#26524;&#25928;&#24212;&#30340;&#21487;&#36776;&#35782;&#24615;&#23646;&#24615;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#23436;&#22791;&#30340;&#31639;&#27861;&#26469;&#23547;&#25214;&#32473;&#23450;&#22270;&#34920;&#20013;&#30340;&#25152;&#26377;&#36807;&#28193;&#32858;&#31867;&#65292;&#24182;&#23637;&#31034;&#20102;&#32858;&#31867;&#22914;&#20309;&#31616;&#21270;&#22240;&#26524;&#25928;&#24212;&#30340;&#35782;&#21035;&#12290;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#21453;&#21521;&#38382;&#39064;&#65292;&#21363;&#25105;&#20204;&#20174;&#19968;&#20010;&#32858;&#31867;&#22270;&#34920;&#24320;&#22987;&#65292;&#23547;&#25214;&#28385;&#36275;&#22240;&#26524;&#25928;&#24212;&#21487;&#36776;&#35782;&#24615;&#23646;&#24615;&#30340;&#25193;&#23637;&#22270;&#34920;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graphs are commonly used to represent and visualize causal relations. For a small number of variables, this approach provides a succinct and clear view of the scenario at hand. As the number of variables under study increases, the graphical approach may become impractical, and the clarity of the representation is lost. Clustering of variables is a natural way to reduce the size of the causal diagram, but it may erroneously change the essential properties of the causal relations if implemented arbitrarily. We define a specific type of cluster, called transit cluster, that is guaranteed to preserve the identifiability properties of causal effects under certain conditions. We provide a sound and complete algorithm for finding all transit clusters in a given graph and demonstrate how clustering can simplify the identification of causal effects. We also study the inverse problem, where one starts with a clustered graph and looks for extended graphs where the identifiability properties of ca
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#35760;&#24518;&#30340;&#38750;&#24179;&#31283;&#22312;&#32447;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;&#21160;&#24577;&#31574;&#30053;&#36951;&#25022;&#20316;&#20026;&#24615;&#33021;&#24230;&#37327;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#36890;&#36807;&#26032;&#39062;&#30340;&#20999;&#25442;&#25104;&#26412;&#24863;&#30693;&#22312;&#32447;&#21512;&#22863;&#26041;&#27861;&#35299;&#20915;&#20102;&#20999;&#25442;&#25104;&#26412;&#30340;&#20851;&#38190;&#25216;&#26415;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2102.03758</link><description>&lt;p&gt;
&#38750;&#24179;&#31283;&#22312;&#32447;&#23398;&#20064;&#20013;&#30340;&#35760;&#24518;&#19982;&#38750;&#38543;&#26426;&#25511;&#21046;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Non-stationary Online Learning with Memory and Non-stochastic Control. (arXiv:2102.03758v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.03758
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#35760;&#24518;&#30340;&#38750;&#24179;&#31283;&#22312;&#32447;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;&#21160;&#24577;&#31574;&#30053;&#36951;&#25022;&#20316;&#20026;&#24615;&#33021;&#24230;&#37327;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#36890;&#36807;&#26032;&#39062;&#30340;&#20999;&#25442;&#25104;&#26412;&#24863;&#30693;&#22312;&#32447;&#21512;&#22863;&#26041;&#27861;&#35299;&#20915;&#20102;&#20999;&#25442;&#25104;&#26412;&#30340;&#20851;&#38190;&#25216;&#26415;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#35760;&#24518;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#38382;&#39064;&#65288;OCO&#65289;&#65292;&#20854;&#20013;&#25439;&#22833;&#20989;&#25968;&#21487;&#20197;&#20381;&#36182;&#20110;&#36807;&#21435;&#30340;&#20915;&#31574;&#65292;&#20174;&#32780;&#25429;&#25417;&#21040;&#23398;&#20064;&#38382;&#39064;&#30340;&#26102;&#38388;&#25928;&#24212;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#21160;&#24577;&#31574;&#30053;&#36951;&#25022;&#20316;&#20026;&#24615;&#33021;&#24230;&#37327;&#65292;&#20197;&#35774;&#35745;&#22312;&#38750;&#24179;&#31283;&#29615;&#22659;&#19979;&#40065;&#26834;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#23558;&#31639;&#27861;&#30340;&#20915;&#31574;&#19982;&#19968;&#31995;&#21015;&#21464;&#21270;&#30340;&#27604;&#36739;&#22120;&#36827;&#34892;&#31454;&#20105;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;OCO&#35760;&#24518;&#31639;&#27861;&#65292;&#23427;&#22312;&#26102;&#38388;&#36328;&#24230;&#12289;&#38750;&#24179;&#31283;&#24230;&#37327;&#21644;&#35760;&#24518;&#38271;&#24230;&#26041;&#38754;&#20445;&#35777;&#20102;&#26368;&#20339;&#30340;&#21160;&#24577;&#31574;&#30053;&#36951;&#25022;&#12290;&#20851;&#38190;&#25216;&#26415;&#25361;&#25112;&#26159;&#22914;&#20309;&#25511;&#21046;&#20999;&#25442;&#25104;&#26412;&#65292;&#21363;&#21442;&#19982;&#32773;&#20915;&#31574;&#30340;&#32047;&#31215;&#31227;&#21160;&#37327;&#65292;&#36825;&#20010;&#38382;&#39064;&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#20999;&#25442;&#25104;&#26412;&#24863;&#30693;&#22312;&#32447;&#21512;&#22863;&#26041;&#27861;&#24471;&#21040;&#20102;&#24039;&#22937;&#35299;&#20915;&#65292;&#35813;&#26041;&#27861;&#37319;&#29992;&#20102;&#21160;&#24577;&#31574;&#30053;&#36951;&#25022;&#30340;&#26032;&#30340;&#20803;&#22522;&#20998;&#35299;&#21644;&#19968;&#20010;&#31934;&#24515;&#35774;&#35745;&#30340;&#20803;&#23398;&#20064;&#22120;&#21644;&#22522;&#23398;&#20064;&#22120;&#65292;&#20197;&#26174;&#24335;&#22320;&#35268;&#33539;&#21270;&#20999;&#25442;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of Online Convex Optimization (OCO) with memory, which allows loss functions to depend on past decisions and thus captures temporal effects of learning problems. In this paper, we introduce dynamic policy regret as the performance measure to design algorithms robust to non-stationary environments, which competes algorithms' decisions with a sequence of changing comparators. We propose a novel algorithm for OCO with memory that provably enjoys an optimal dynamic policy regret in terms of time horizon, non-stationarity measure, and memory length. The key technical challenge is how to control the switching cost, the cumulative movements of player's decisions, which is neatly addressed by a novel switching-cost-aware online ensemble approach equipped with a new meta-base decomposition of dynamic policy regret and a careful design of meta-learner and base-learner that explicitly regularizes the switching cost. The results are further applied to tackle non-stationarity i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#22686;&#24378;&#31639;&#27861;&#26469;&#23454;&#29616;&#20844;&#24179;&#23494;&#24230;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23398;&#20064;&#25351;&#25968;&#26063;&#30340;&#20805;&#20998;&#32479;&#35745;&#37327;&#65292;&#20197;&#25913;&#21892;&#25968;&#25454;&#25311;&#21512;&#65292;&#24182;&#30830;&#20445;&#26368;&#23567;&#30340;&#20844;&#24179;&#24615;&#20445;&#35777;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#30495;&#23454;&#25968;&#25454;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2012.00188</link><description>&lt;p&gt;
&#36890;&#36807;&#22686;&#24378;&#25351;&#25968;&#26063;&#30340;&#20805;&#20998;&#32479;&#35745;&#37327;&#26469;&#23454;&#29616;&#20844;&#24179;&#23494;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fair Densities via Boosting the Sufficient Statistics of Exponential Families. (arXiv:2012.00188v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2012.00188
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#22686;&#24378;&#31639;&#27861;&#26469;&#23454;&#29616;&#20844;&#24179;&#23494;&#24230;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23398;&#20064;&#25351;&#25968;&#26063;&#30340;&#20805;&#20998;&#32479;&#35745;&#37327;&#65292;&#20197;&#25913;&#21892;&#25968;&#25454;&#25311;&#21512;&#65292;&#24182;&#30830;&#20445;&#26368;&#23567;&#30340;&#20844;&#24179;&#24615;&#20445;&#35777;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#30495;&#23454;&#25968;&#25454;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#22686;&#24378;&#31639;&#27861;&#23545;&#25968;&#25454;&#36827;&#34892;&#20844;&#24179;&#39044;&#22788;&#29702;&#30340;&#26041;&#27861;&#12290;&#20174;&#19968;&#20010;&#21021;&#22987;&#30340;&#20844;&#24179;&#20294;&#19981;&#20934;&#30830;&#30340;&#20998;&#24067;&#24320;&#22987;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#30830;&#20445;&#26368;&#23567;&#20844;&#24179;&#24615;&#20445;&#35777;&#30340;&#21516;&#26102;&#26397;&#30528;&#26356;&#22909;&#30340;&#25968;&#25454;&#25311;&#21512;&#26041;&#21521;&#36827;&#34892;&#36716;&#31227;&#12290;&#20026;&#27492;&#65292;&#23427;&#23398;&#20064;&#20102;&#19968;&#20010;&#20855;&#26377;&#22686;&#24378;&#25910;&#25947;&#24615;&#30340;&#25351;&#25968;&#26063;&#30340;&#20805;&#20998;&#32479;&#35745;&#37327;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#33021;&#22815;&#20174;&#29702;&#35770;&#19978;&#35777;&#26126;&#23398;&#20064;&#30340;&#20998;&#24067;&#23558;&#20855;&#26377;&#34920;&#31034;&#29575;&#21644;&#32479;&#35745;&#29575;&#30340;&#25968;&#25454;&#20844;&#24179;&#24615;&#20445;&#35777;&#12290;&#19982;&#26368;&#36817;&#30340;&#22522;&#20110;&#20248;&#21270;&#30340;&#39044;&#22788;&#29702;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#36731;&#26494;&#36866;&#24212;&#36830;&#32493;&#22495;&#29305;&#24449;&#12290;&#27492;&#22806;&#65292;&#24403;&#24369;&#23398;&#20064;&#32773;&#34987;&#25351;&#23450;&#20026;&#20915;&#31574;&#26641;&#26102;&#65292;&#21487;&#20197;&#26816;&#26597;&#23398;&#20064;&#20998;&#24067;&#30340;&#20805;&#20998;&#32479;&#35745;&#37327;&#65292;&#20197;&#25552;&#20379;&#65288;&#19981;&#65289;&#20844;&#24179;&#24615;&#30340;&#26469;&#28304;&#32447;&#32034;&#12290;&#36890;&#36807;&#23454;&#35777;&#32467;&#26524;&#23637;&#31034;&#20102;&#22312;&#30495;&#23454;&#25968;&#25454;&#19978;&#30340;&#32467;&#26524;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a boosting algorithm to pre-process data for fairness. Starting from an initial fair but inaccurate distribution, our approach shifts towards better data fitting while still ensuring a minimal fairness guarantee. To do so, it learns the sufficient statistics of an exponential family with boosting-compliant convergence. Importantly, we are able to theoretically prove that the learned distribution will have a representation rate and statistical rate data fairness guarantee. Unlike recent optimization based pre-processing methods, our approach can be easily adapted for continuous domain features. Furthermore, when the weak learners are specified to be decision trees, the sufficient statistics of the learned distribution can be examined to provide clues on sources of (un)fairness. Empirical results are present to display the quality of result on real-world data.
&lt;/p&gt;</description></item></channel></rss>