<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#33258;&#21160;&#20998;&#31867;&#21644;&#27169;&#25311;&#32676;&#20307;&#32769;&#40736;&#34892;&#20026;&#30340;&#24037;&#20855;&#65292;&#36890;&#36807;&#21333;&#19968;&#27169;&#22411;&#36328;&#31548;&#20351;&#29992;&#32622;&#25442;&#30697;&#38453;&#21305;&#37197;&#32769;&#40736;&#36523;&#20221;&#65292;&#22312;&#23478;&#40736;&#29615;&#22659;&#19979;&#30740;&#31350;&#32769;&#40736;&#21487;&#20197;&#25429;&#25417;&#21040;&#20010;&#20307;&#34892;&#20026;&#30340;&#26102;&#38388;&#22240;&#32032;&#65292;&#32780;&#19988;&#26080;&#38656;&#20154;&#20026;&#24178;&#39044;&#12290;</title><link>http://arxiv.org/abs/2306.03066</link><description>&lt;p&gt;
&#12298;&#40736;&#31867;&#19982;&#37197;&#20598;&#65306;&#21333;&#19968;&#27169;&#22411;&#33258;&#21160;&#23545;&#32676;&#20307;&#20013;&#30340;&#32769;&#40736;&#34892;&#20026;&#36827;&#34892;&#20998;&#31867;&#21644;&#24314;&#27169;&#36328;&#31548;&#12299;
&lt;/p&gt;
&lt;p&gt;
Of Mice and Mates: Automated Classification and Modelling of Mouse Behaviour in Groups using a Single Model across Cages. (arXiv:2306.03066v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03066
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#33258;&#21160;&#20998;&#31867;&#21644;&#27169;&#25311;&#32676;&#20307;&#32769;&#40736;&#34892;&#20026;&#30340;&#24037;&#20855;&#65292;&#36890;&#36807;&#21333;&#19968;&#27169;&#22411;&#36328;&#31548;&#20351;&#29992;&#32622;&#25442;&#30697;&#38453;&#21305;&#37197;&#32769;&#40736;&#36523;&#20221;&#65292;&#22312;&#23478;&#40736;&#29615;&#22659;&#19979;&#30740;&#31350;&#32769;&#40736;&#21487;&#20197;&#25429;&#25417;&#21040;&#20010;&#20307;&#34892;&#20026;&#30340;&#26102;&#38388;&#22240;&#32032;&#65292;&#32780;&#19988;&#26080;&#38656;&#20154;&#20026;&#24178;&#39044;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34892;&#20026;&#23454;&#39564;&#36890;&#24120;&#22312;&#19987;&#38376;&#30340;&#31454;&#25216;&#22330;&#20013;&#36827;&#34892;&#65292;&#20294;&#36825;&#21487;&#33021;&#20250;&#28151;&#28102;&#20998;&#26512;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#24037;&#20855;&#26469;&#30740;&#31350;&#23478;&#40736;&#29615;&#22659;&#20013;&#30340;&#32769;&#40736;&#65292;&#20026;&#29983;&#29289;&#23398;&#23478;&#25552;&#20379;&#20102;&#25429;&#25417;&#20010;&#20307;&#34892;&#20026;&#30340;&#26102;&#38388;&#22240;&#32032;&#21644;&#27169;&#25311;&#26368;&#23567;&#20154;&#20026;&#24178;&#39044;&#19979;&#31548;&#21451;&#20043;&#38388;&#20114;&#21160;&#21644;&#30456;&#20114;&#20381;&#36182;&#30340;&#21487;&#33021;&#24615;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#8220;&#27963;&#21160;&#26631;&#31614;&#27169;&#22359;&#8221;&#65288;ALM&#65289;&#26469;&#33258;&#21160;&#23545;&#32769;&#40736;&#34892;&#20026;&#36827;&#34892;&#20998;&#31867;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#8220;&#32676;&#20307;&#34892;&#20026;&#27169;&#22411;&#8221;&#65288;GBM&#65289;&#26469;&#27010;&#25324;&#20182;&#20204;&#22312;&#31548;&#23376;&#20013;&#30340;&#32852;&#21512;&#34892;&#20026;&#65292;&#20351;&#29992;&#32622;&#25442;&#30697;&#38453;&#23558;&#27599;&#20010;&#31548;&#23376;&#20013;&#30340;&#32769;&#40736;&#36523;&#20221;&#19982;&#27169;&#22411;&#21305;&#37197;&#12290;&#25105;&#20204;&#36824;&#21457;&#24067;&#20102;&#20004;&#20010;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#35757;&#32451;&#34892;&#20026;&#20998;&#31867;&#22120;&#65288;ABODe&#65289;&#21644;&#34892;&#20026;&#24314;&#27169;&#65288;IMADGE&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Behavioural experiments often happen in specialised arenas, but this may confound the analysis. To address this issue, we provide tools to study mice in the homecage environment, equipping biologists with the possibility to capture the temporal aspect of the individual's behaviour and model the interaction and interdependence between cage-mates with minimal human intervention. We develop the Activity Labelling Module (ALM) to automatically classify mouse behaviour from video, and a novel Group Behaviour Model (GBM) for summarising their joint behaviour across cages, using a permutation matrix to match the mouse identities in each cage to the model. We also release two datasets, ABODe for training behaviour classifiers and IMADGE for modelling behaviour.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;LibAUC&#30340;&#28145;&#24230;&#23398;&#20064;&#24211;&#65292;&#29992;&#20110;&#35299;&#20915;X-risk&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#20248;&#24322;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.03065</link><description>&lt;p&gt;
LibAUC: &#29992;&#20110;X-Risk&#20248;&#21270;&#30340;&#28145;&#24230;&#23398;&#20064;&#24211;
&lt;/p&gt;
&lt;p&gt;
LibAUC: A Deep Learning Library for X-Risk Optimization. (arXiv:2306.03065v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03065
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;LibAUC&#30340;&#28145;&#24230;&#23398;&#20064;&#24211;&#65292;&#29992;&#20110;&#35299;&#20915;X-risk&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#20248;&#24322;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;LibAUC&#30340;&#28145;&#24230;&#23398;&#20064;&#24211;&#65292;&#21487;&#20197;&#23454;&#29616;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#20197;&#20248;&#21270;&#19968;&#31867;&#39118;&#38505;&#20989;&#25968;&#65292;&#31216;&#20026;X-risk&#12290; X-risk&#26159;&#19968;&#31867;&#32452;&#21512;&#20989;&#25968;&#65292;&#20854;&#20013;&#27599;&#20010;&#25968;&#25454;&#28857;&#30340;&#25439;&#22833;&#20989;&#25968;&#20197;&#19982;&#22823;&#37327;&#20854;&#20182;&#25968;&#25454;&#28857;&#36827;&#34892;&#23545;&#27604;&#30340;&#26041;&#24335;&#23450;&#20041;&#12290;&#23427;&#20204;&#22312;AI&#20013;&#20855;&#26377;&#24191;&#27867;&#24212;&#29992;&#65292;&#21487;&#35299;&#20915;&#32463;&#20856;&#21644;&#26032;&#20852;&#38382;&#39064;&#65292;&#21253;&#25324;&#20294;&#19981;&#38480;&#20110;&#19981;&#22343;&#34913;&#25968;&#25454;&#30340;&#20998;&#31867;&#65288;CID&#65289;&#65292;&#25490;&#21517;&#23398;&#20064;&#65288;LTR&#65289;&#21644;&#34920;&#31034;&#30340;&#23545;&#27604;&#23398;&#20064;&#65288;CLR&#65289;&#12290; LibAUC&#30340;&#24320;&#21457;&#21160;&#26426;&#26159;&#35299;&#20915;&#29616;&#26377;&#24211;&#22312;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#26102;&#30340;&#25910;&#25947;&#38382;&#39064;&#12290;&#29305;&#21035;&#22320;&#65292;&#29616;&#26377;&#24211;&#21487;&#33021;&#19981;&#20250;&#25910;&#25947;&#25110;&#38656;&#35201;&#38750;&#24120;&#22823;&#30340;mini-batch&#22823;&#23567;&#25165;&#33021;&#33719;&#24471;&#33391;&#22909;&#30340;&#24615;&#33021;&#65292;&#22240;&#20026;&#22312;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;ERM&#65289;&#26694;&#26550;&#20013;&#20351;&#29992;&#20102;&#26631;&#20934;&#30340;mini-batch&#25216;&#26415;&#12290;&#25105;&#20204;&#30340;&#24211;&#26159;&#29992;&#20110;&#28145;&#24230;X-risk&#20248;&#21270;&#30340;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#23427;&#22312;&#27979;&#35797;&#20934;&#30830;&#24615;&#21644;&#25910;&#25947;&#36895;&#24230;&#26041;&#38754;&#26174;&#30528;&#20248;&#20110;&#29616;&#26377;&#24211;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces the award-winning deep learning (DL) library called LibAUC for implementing state-of-the-art algorithms towards optimizing a family of risk functions named X-risks. X-risks refer to a family of compositional functions in which the loss function of each data point is defined in a way that contrasts the data point with a large number of others. They have broad applications in AI for solving classical and emerging problems, including but not limited to classification for imbalanced data (CID), learning to rank (LTR), and contrastive learning of representations (CLR). The motivation of developing LibAUC is to address the convergence issues of existing libraries for solving these problems. In particular, existing libraries may not converge or require very large mini-batch sizes in order to attain good performance for these problems, due to the usage of the standard mini-batch technique in the empirical risk minimization (ERM) framework. Our library is for deep X-risk o
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23558;&#20154;&#31867;&#29983;&#21629;&#34920;&#31034;&#25104;&#20107;&#20214;&#24207;&#21015;&#65292;&#21033;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#21019;&#26032;&#26041;&#27861;&#65292;&#20998;&#26512;&#20102;&#25972;&#20010;&#22269;&#23478;&#30340;&#36229;&#36807;&#20845;&#30334;&#19975;&#20154;&#30340;&#22810;&#24180;&#27880;&#20876;&#25968;&#25454;&#65292;&#26088;&#22312;&#20174;&#20013;&#39044;&#27979;&#20154;&#31867;&#29983;&#21629;&#30340;&#28436;&#21464;&#21644;&#21487;&#39044;&#27979;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.03009</link><description>&lt;p&gt;
&#21033;&#29992;&#29983;&#27963;&#20107;&#20214;&#24207;&#21015;&#39044;&#27979;&#20154;&#31867;&#29983;&#21629;
&lt;/p&gt;
&lt;p&gt;
Using Sequences of Life-events to Predict Human Lives. (arXiv:2306.03009v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03009
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23558;&#20154;&#31867;&#29983;&#21629;&#34920;&#31034;&#25104;&#20107;&#20214;&#24207;&#21015;&#65292;&#21033;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#21019;&#26032;&#26041;&#27861;&#65292;&#20998;&#26512;&#20102;&#25972;&#20010;&#22269;&#23478;&#30340;&#36229;&#36807;&#20845;&#30334;&#19975;&#20154;&#30340;&#22810;&#24180;&#27880;&#20876;&#25968;&#25454;&#65292;&#26088;&#22312;&#20174;&#20013;&#39044;&#27979;&#20154;&#31867;&#29983;&#21629;&#30340;&#28436;&#21464;&#21644;&#21487;&#39044;&#27979;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#20013;&#65292;&#26426;&#22120;&#23398;&#20064;&#36890;&#36807;&#28789;&#27963;&#30340;&#35745;&#31639;&#27169;&#22411;&#65292;&#24443;&#24213;&#25913;&#21464;&#20102;&#35745;&#31639;&#26426;&#20998;&#26512;&#25991;&#26412;&#30340;&#33021;&#21147;&#12290;&#30001;&#20110;&#20854;&#19982;&#20070;&#38754;&#35821;&#35328;&#30340;&#32467;&#26500;&#30456;&#20284;&#24615;&#65292;&#22522;&#20110;&#36716;&#25442;&#22120;&#30340;&#20307;&#31995;&#32467;&#26500;&#20063;&#26174;&#31034;&#20986;&#25104;&#20026;&#33539;&#22260;&#20174;&#34507;&#30333;&#36136;&#32467;&#26500;&#12289;&#38899;&#20048;&#12289;&#30005;&#23376;&#21307;&#30103;&#35760;&#24405;&#21040;&#22825;&#27668;&#39044;&#25253;&#31561;&#22810;&#21464;&#37327;&#24207;&#21015;&#30340;&#24037;&#20855;&#30340;&#21069;&#26223;&#12290;&#25105;&#20204;&#36824;&#21487;&#20197;&#20197;&#19968;&#31181;&#19982;&#35821;&#35328;&#20855;&#26377;&#32467;&#26500;&#30456;&#20284;&#24615;&#30340;&#26041;&#24335;&#26469;&#34920;&#31034;&#20154;&#31867;&#29983;&#21629;&#12290;&#20174;&#19968;&#20010;&#35282;&#24230;&#26469;&#30475;&#65292;&#29983;&#21629;&#21482;&#26159;&#19968;&#31995;&#21015;&#20107;&#20214;&#30340;&#24207;&#21015;&#65306;&#20154;&#20204;&#20986;&#29983;&#65292;&#21435;&#30475;&#23567;&#20799;&#31185;&#21307;&#29983;&#65292;&#24320;&#22987;&#19978;&#23398;&#65292;&#25644;&#21040;&#26032;&#22320;&#26041;&#65292;&#32467;&#23130;&#31561;&#31561;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#31181;&#30456;&#20284;&#24615;&#65292;&#37319;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#21019;&#26032;&#26469;&#30740;&#31350;&#21644;&#39044;&#27979;&#20154;&#31867;&#29983;&#21629;&#30340;&#28436;&#21464;&#21644;&#21487;&#39044;&#27979;&#24615;&#65292;&#22522;&#20110;&#25972;&#20010;&#22269;&#23478;&#30340;&#20845;&#30334;&#22810;&#19975;&#20154;&#25968;&#21313;&#24180;&#38388;&#21487;&#29992;&#30340;&#21487;&#33021;&#26159;&#26368;&#20840;&#38754;&#30340;&#27880;&#20876;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Over the past decade, machine learning has revolutionized computers' ability to analyze text through flexible computational models. Due to their structural similarity to written language, transformer-based architectures have also shown promise as tools to make sense of a range of multi-variate sequences from protein-structures, music, electronic health records to weather-forecasts. We can also represent human lives in a way that shares this structural similarity to language. From one perspective, lives are simply sequences of events: People are born, visit the pediatrician, start school, move to a new location, get married, and so on. Here, we exploit this similarity to adapt innovations from natural language processing to examine the evolution and predictability of human lives based on detailed event sequences. We do this by drawing on arguably the most comprehensive registry data in existence, available for an entire nation of more than six million individuals across decades. Our dat
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#31163;&#25955;&#25193;&#25955;&#26680;&#22914;&#20309;&#24433;&#21709;&#22270;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#32467;&#26524;&#34920;&#26126;&#36873;&#25321;&#27491;&#30830;&#30340;&#25910;&#25947;&#20808;&#39564;&#23545;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#29983;&#25104;&#24615;&#33021;&#33267;&#20851;&#37325;&#35201;&#12290;</title><link>http://arxiv.org/abs/2306.02957</link><description>&lt;p&gt;
&#31163;&#25955;&#22270;&#25193;&#25955;&#20013;&#19981;&#21516;&#25910;&#25947;&#20808;&#39564;&#30340;&#22797;&#26434;&#20559;&#22909;
&lt;/p&gt;
&lt;p&gt;
Complex Preferences for Different Convergent Priors in Discrete Graph Diffusion. (arXiv:2306.02957v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02957
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#31163;&#25955;&#25193;&#25955;&#26680;&#22914;&#20309;&#24433;&#21709;&#22270;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#32467;&#26524;&#34920;&#26126;&#36873;&#25321;&#27491;&#30830;&#30340;&#25910;&#25947;&#20808;&#39564;&#23545;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#29983;&#25104;&#24615;&#33021;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#24050;&#32463;&#21462;&#24471;&#20102;&#22312;&#29983;&#25104;&#35768;&#22810;&#19981;&#21516;&#31867;&#22411;&#30340;&#25968;&#25454;&#65292;&#21253;&#25324;&#22270;&#20687;&#12289;&#25991;&#26412;&#21644;&#35270;&#39057;&#26041;&#38754;&#30340;&#26368;&#20808;&#36827;&#34920;&#29616;&#12290;&#23613;&#31649;&#23427;&#20204;&#24456;&#25104;&#21151;&#65292;&#20294;&#23545;&#20110;&#22522;&#30784;&#25193;&#25955;&#36807;&#31243;&#21644;&#26368;&#32456;&#25910;&#25947;&#20808;&#39564;&#22914;&#20309;&#24433;&#21709;&#29983;&#25104;&#30340;&#24615;&#33021;&#36827;&#34892;&#30340;&#30740;&#31350;&#26377;&#38480;&#65307;&#27492;&#30740;&#31350;&#20063;&#20165;&#38480;&#20110;&#36830;&#32493;&#25968;&#25454;&#31867;&#22411;&#21644;&#22522;&#20110;&#20998;&#25968;&#30340;&#25193;&#25955;&#26694;&#26550;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#19981;&#21516;&#31163;&#25955;&#25193;&#25955;&#26680;&#65288;&#25910;&#25947;&#21040;&#19981;&#21516;&#30340;&#20808;&#39564;&#20998;&#24067;&#65289;&#22914;&#20309;&#24433;&#21709;&#22270;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#31163;&#25955;&#25193;&#25955;&#26680;&#31995;&#21015;&#20844;&#24335;&#65292;&#21487;&#20197;&#36731;&#26494;&#35843;&#25972;&#20197;&#25910;&#25947;&#21040;&#19981;&#21516;&#30340;&#20271;&#21162;&#21033;&#20808;&#39564;&#65292;&#24182;&#30740;&#31350;&#36825;&#20123;&#19981;&#21516;&#30340;&#26680;&#23545;&#29983;&#25104;&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#29983;&#25104;&#30340;&#22270;&#30340;&#36136;&#37327;&#23545;&#20351;&#29992;&#30340;&#20808;&#39564;&#24456;&#25935;&#24863;&#65292;&#26368;&#20248;&#36873;&#25321;&#19981;&#33021;&#29992;&#26126;&#26174;&#30340;&#32479;&#35745;&#25968;&#25454;&#25110;&#25351;&#26631;&#26469;&#35299;&#37322;&#65292;&#36825;&#25361;&#25112;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#30452;&#35273;&#20551;&#35774;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#31163;&#25955;&#25968;&#25454;&#19978;&#65292;&#36873;&#25321;&#27491;&#30830;&#30340;&#25910;&#25947;&#20808;&#39564;&#23545;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#29983;&#25104;&#24615;&#33021;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models have achieved state-of-the-art performance in generating many different kinds of data, including images, text, and videos. Despite their success, there has been limited research on how the underlying diffusion process and the final convergent prior can affect generative performance; this research has also been limited to continuous data types and a score-based diffusion framework. To fill this gap, we explore how different discrete diffusion kernels (which converge to different prior distributions) affect the performance of diffusion models for graphs. To this end, we developed a novel formulation of a family of discrete diffusion kernels which are easily adjustable to converge to different Bernoulli priors, and we study the effect of these different kernels on generative performance. We show that the quality of generated graphs is sensitive to the prior used, and that the optimal choice cannot be explained by obvious statistics or metrics, which challenges the intuiti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38590;&#27665;&#23433;&#32622;&#20013;&#30340;&#38543;&#26426;&#20998;&#24067;&#36716;&#31227;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#24182;&#27604;&#36739;&#20102;&#19977;&#31181;&#24314;&#27169;&#31574;&#30053;&#65292;&#26368;&#32456;&#21457;&#29616;&#28151;&#21512;&#26041;&#27861;&#20855;&#26377;&#36739;&#24378;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.02948</link><description>&lt;p&gt;
&#38590;&#27665;&#23433;&#32622;&#20013;&#30340;&#38543;&#26426;&#20998;&#24067;&#36716;&#31227;: &#24314;&#31435;&#20581;&#22766;&#27169;&#22411;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Random Distribution Shift in Refugee Placement: Strategies for Building Robust Models. (arXiv:2306.02948v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02948
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38590;&#27665;&#23433;&#32622;&#20013;&#30340;&#38543;&#26426;&#20998;&#24067;&#36716;&#31227;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#24182;&#27604;&#36739;&#20102;&#19977;&#31181;&#24314;&#27169;&#31574;&#30053;&#65292;&#26368;&#32456;&#21457;&#29616;&#28151;&#21512;&#26041;&#27861;&#20855;&#26377;&#36739;&#24378;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#31639;&#27861;&#20998;&#37197;&#38590;&#27665;&#21644;&#23547;&#27714;&#24199;&#25252;&#32773;&#21040;&#20027;&#26426;&#22269;&#23478;&#30340;&#22320;&#28857;&#24050;&#32463;&#24341;&#36215;&#20102;&#20851;&#27880;&#65292;&#22312;&#32654;&#22269;&#21644;&#29790;&#22763;&#23454;&#26045;&#12290;&#36825;&#20123;&#26041;&#27861;&#20351;&#29992;&#36807;&#21435;&#25269;&#36798;&#30340;&#25968;&#25454;&#29983;&#25104;&#21487;&#20197;&#29992;&#20110;&#21305;&#37197;&#23478;&#24237;&#21040;&#20301;&#32622;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65288;&#19982;&#20998;&#37197;&#31639;&#27861;&#19968;&#36215;&#20351;&#29992;&#65289;&#65292;&#30446;&#26631;&#26159;&#26368;&#22823;&#21270;&#25919;&#31574;&#30456;&#20851;&#30340;&#25972;&#21512;&#32467;&#26524;&#65292;&#22914;&#22312;&#19968;&#23450;&#26102;&#38388;&#21518;&#30340;&#23601;&#19994;&#29366;&#24577;&#12290;&#29616;&#26377;&#30340;&#23454;&#29616;&#21644;&#30740;&#31350;&#36890;&#36807;&#30452;&#25509;&#39044;&#27979;&#25919;&#31574;&#32467;&#26524;&#26469;&#35757;&#32451;&#27169;&#22411;&#65292;&#24182;&#23558;&#36825;&#20123;&#39044;&#27979;&#29992;&#20110;&#20998;&#37197;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#30340;&#20248;&#28857;&#65292;&#29305;&#21035;&#26159;&#22312;&#38750;&#31283;&#24577;&#29615;&#22659;&#19979;&#65292;&#23578;&#26410;&#34987;&#20808;&#21069;&#25506;&#35752;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#24182;&#27604;&#36739;&#20102;&#19977;&#31181;&#19981;&#21516;&#30340;&#24314;&#27169;&#31574;&#30053;&#65306;&#19978;&#36848;&#30340;&#26631;&#20934;&#26041;&#27861;&#12289;&#20351;&#29992;&#26356;&#26032;&#25968;&#25454;&#21644;&#20195;&#29702;&#32467;&#26524;&#30340;&#26041;&#27861;&#20197;&#21450;&#28151;&#21512;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#28151;&#21512;&#26041;&#27861;&#22312;&#20998;&#24067;&#36716;&#31227;&#21644;&#24369;&#20195;&#29702;&#20851;&#31995;&#26041;&#38754;&#20855;&#26377;&#40065;&#26834;&#24615;-
&lt;/p&gt;
&lt;p&gt;
Algorithmic assignment of refugees and asylum seekers to locations within host countries has gained attention in recent years, with implementations in the US and Switzerland. These approaches use data on past arrivals to generate machine learning models that can be used (along with assignment algorithms) to match families to locations, with the goal of maximizing a policy-relevant integration outcome such as employment status after a certain duration. Existing implementations and research train models to predict the policy outcome directly, and use these predictions in the assignment procedure. However, the merits of this approach, particularly in non-stationary settings, has not been previously explored. This study proposes and compares three different modeling strategies: the standard approach described above, an approach that uses newer data and proxy outcomes, and a hybrid approach. We show that the hybrid approach is robust to both distribution shift and weak proxy relationships -
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#26032;&#30340;&#31639;&#27861;&#31283;&#23450;&#24615;&#29702;&#35770;&#26469;&#25913;&#36827;&#20998;&#24067;&#24335;SGD&#31639;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#20998;&#26512;&#65292;&#25512;&#32763;&#20102;&#29616;&#26377;&#25216;&#26415;&#23545;&#36890;&#20449;&#22270;&#36127;&#38754;&#24433;&#21709;&#30340;&#35266;&#28857;&#65292;&#24182;&#23637;&#31034;&#20102;D-SGD&#22312;&#20984;&#35774;&#32622;&#20013;&#19982;&#32463;&#20856;SGD&#31639;&#27861;&#27867;&#21270;&#30028;&#30456;&#21516;&#12290;</title><link>http://arxiv.org/abs/2306.02939</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;SGD&#31639;&#27861;&#30340;&#31283;&#23450;&#24615;&#19982;&#27867;&#21270;&#20998;&#26512;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
Improved Stability and Generalization Analysis of the Decentralized SGD Algorithm. (arXiv:2306.02939v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02939
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#26032;&#30340;&#31639;&#27861;&#31283;&#23450;&#24615;&#29702;&#35770;&#26469;&#25913;&#36827;&#20998;&#24067;&#24335;SGD&#31639;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#20998;&#26512;&#65292;&#25512;&#32763;&#20102;&#29616;&#26377;&#25216;&#26415;&#23545;&#36890;&#20449;&#22270;&#36127;&#38754;&#24433;&#21709;&#30340;&#35266;&#28857;&#65292;&#24182;&#23637;&#31034;&#20102;D-SGD&#22312;&#20984;&#35774;&#32622;&#20013;&#19982;&#32463;&#20856;SGD&#31639;&#27861;&#27867;&#21270;&#30028;&#30456;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22522;&#20110;&#31639;&#27861;&#31283;&#23450;&#24615;&#65292;&#25552;&#20986;&#20102;&#20998;&#24067;&#24335;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;(D-SGD)&#31639;&#27861;&#30340;&#26032;&#30340;&#27867;&#21270;&#35823;&#24046;&#20998;&#26512;&#26041;&#27861;&#12290;&#24471;&#21040;&#30340;&#32467;&#26524;&#22823;&#22823;&#25913;&#36827;&#20102;&#29616;&#26377;&#25216;&#26415;&#65292;&#24182;&#25512;&#32763;&#20102;&#23427;&#20204;&#20851;&#20110;&#36890;&#20449;&#22270;&#23545;&#27867;&#21270;&#30340;&#36127;&#38754;&#24433;&#21709;&#30340;&#35266;&#28857;&#12290;&#20363;&#22914;&#65292;&#22312;&#20984;&#35774;&#32622;&#20013;&#65292;&#26080;&#35770;&#22270;&#30340;&#36873;&#25321;&#22914;&#20309;&#65292;D-SGD&#20855;&#26377;&#19982;&#32463;&#20856;SGD&#31639;&#27861;&#30456;&#21516;&#30340;&#27867;&#21270;&#30028;&#12290;&#25105;&#20204;&#21457;&#29616;&#36825;&#31181;&#21453;&#30452;&#35273;&#30340;&#32467;&#26524;&#26469;&#33258;&#20110;&#32771;&#34385;&#26412;&#22320;&#21442;&#25968;&#30340;&#24179;&#22343;&#20540;&#65292;&#36825;&#20250;&#38544;&#34255;&#19968;&#20010;&#19982;&#20998;&#24067;&#24335;&#22330;&#26223;&#19981;&#20860;&#23481;&#30340;&#26368;&#32456;&#20840;&#23616;&#24179;&#22343;&#21270;&#27493;&#39588;&#12290;&#32771;&#34385;&#21040;&#36825;&#19968;&#35266;&#23519;&#32467;&#26524;&#65292;&#25105;&#20204;&#20513;&#23548;&#20998;&#26512;&#26412;&#22320;&#21442;&#25968;&#30340;&#19978;&#30830;&#30028;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#22270;&#30830;&#23454;&#23545;&#27867;&#21270;&#20135;&#29983;&#24433;&#21709;&#12290;&#19982;&#20043;&#21069;&#30340;&#32467;&#26524;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#21363;&#20351;&#23545;&#20110;&#38750;&#36830;&#25509;&#22270;&#20063;&#33021;&#20135;&#29983;&#38750;&#24179;&#20961;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a new generalization error analysis for the Decentralized Stochastic Gradient Descent (D-SGD) algorithm based on algorithmic stability. The obtained results largely improve upon state-of-the-art results, and even invalidate their claims that the communication graph has a detrimental effect on generalization. For instance, we show that in convex settings, D-SGD has the same generalization bounds as the classical SGD algorithm, no matter the choice of graph. We exhibit that this counter-intuitive result comes from considering the average of local parameters, which hides a final global averaging step incompatible with the decentralized scenario. In light of this observation, we advocate to analyze the supremum over local parameters and show that in this case, the graph does have an impact on the generalization. Unlike prior results, our analysis yields non-vacuous bounds even for non-connected graphs.
&lt;/p&gt;</description></item><item><title>&#23545;&#20110;&#20855;&#26377;&#29616;&#23454;&#20551;&#35774;&#30340;&#25968;&#25454;&#38598;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#20351;&#24471;&#30830;&#23450;&#22240;&#26524;&#26041;&#21521;&#21464;&#25104;&#20102;&#19968;&#20010;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#20351;&#29992;&#23454;&#38469;&#25968;&#25454;&#38598;&#39564;&#35777;&#20102;&#26412;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.02931</link><description>&lt;p&gt;
&#20351;&#29992;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Causal Discovery using Bayesian Model Selection. (arXiv:2306.02931v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02931
&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#20855;&#26377;&#29616;&#23454;&#20551;&#35774;&#30340;&#25968;&#25454;&#38598;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#20351;&#24471;&#30830;&#23450;&#22240;&#26524;&#26041;&#21521;&#21464;&#25104;&#20102;&#19968;&#20010;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#20351;&#29992;&#23454;&#38469;&#25968;&#25454;&#38598;&#39564;&#35777;&#20102;&#26412;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21482;&#26377;&#20004;&#20010;&#21464;&#37327;&#30340;&#35266;&#27979;&#25968;&#25454;&#19988;&#27809;&#26377;&#20854;&#20182;&#20551;&#35774;&#65292;&#26080;&#27861;&#25512;&#26029;&#21738;&#20010;&#21464;&#37327;&#26159;&#24341;&#36215;&#21478;&#19968;&#20010;&#21464;&#37327;&#30340;&#21407;&#22240;&#12290;&#22823;&#37096;&#20998;&#22240;&#26524;&#25991;&#29486;&#32858;&#28966;&#20110;&#38024;&#23545;&#24378;&#20551;&#35774;&#30340;&#25968;&#25454;&#38598;(&#22914;&#21152;&#24615;&#22122;&#22768;&#25110;&#21442;&#25968;&#35745;&#25968;&#38480;&#21046;)&#20445;&#35777;&#22240;&#26524;&#26041;&#21521;&#30340;&#21487;&#35782;&#21035;&#24615;&#12290;&#28982;&#32780;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#34987;&#27979;&#35797;&#20110;&#36829;&#21453;&#20551;&#35774;&#30340;&#29616;&#23454;&#25968;&#25454;&#38598;&#19978;&#12290;&#26412;&#25991;&#22312;&#27492;&#22522;&#30784;&#19978;&#25552;&#20986;&#22914;&#20309;&#22312;&#36125;&#21494;&#26031;&#26694;&#26550;&#20869;&#20351;&#29992;&#22240;&#26524;&#20551;&#35774;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#21046;&#23450;&#20855;&#26377;&#29616;&#23454;&#20551;&#35774;&#30340;&#27169;&#22411;&#65292;&#21516;&#26102;&#32534;&#30721;&#29420;&#31435;&#30340;&#22240;&#26524;&#26426;&#21046;&#65292;&#23548;&#33268;&#22240;&#26524;&#26041;&#21521;&#20043;&#38388;&#30340;&#38750;&#23545;&#31216;&#24615;&#12290;&#22240;&#27492;&#65292;&#30830;&#23450;&#22240;&#26524;&#26041;&#21521;&#25104;&#20026;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#20026;&#20309;&#22312;&#24050;&#30693;&#21487;&#35782;&#21035;&#30340;&#24773;&#20917;&#21644;&#28789;&#27963;&#30340;&#27169;&#22411;&#31867;&#19978;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
With only observational data on two variables, and without other assumptions, it is not possible to infer which one causes the other. Much of the causal literature has focused on guaranteeing identifiability of causal direction in statistical models for datasets where strong assumptions hold, such as additive noise or restrictions on parameter count. These methods are then subsequently tested on realistic datasets, most of which violate their assumptions. Building on previous attempts, we show how to use causal assumptions within the Bayesian framework. This allows us to specify models with realistic assumptions, while also encoding independent causal mechanisms, leading to an asymmetry between the causal directions. Identifying causal direction then becomes a Bayesian model selection problem. We analyse why Bayesian model selection works for known identifiable cases and flexible model classes, while also providing correctness guarantees about its behaviour. To demonstrate our approach
&lt;/p&gt;</description></item><item><title>&#20998;&#25955;SGD&#21644;&#24179;&#22343;&#26041;&#21521;SAM&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#26159;&#31561;&#20215;&#30340;&#65292;D-SGD&#34920;&#29616;&#20986;&#26799;&#24230;&#24179;&#28369;&#25928;&#24212;&#21644;&#38160;&#24230;&#27491;&#21017;&#21270;&#25928;&#24212;&#65292;&#32780;&#19988;&#21487;&#20197;&#25552;&#39640;&#21518;&#39564;&#35780;&#20272;&#65292;&#24182;&#35777;&#26126;&#20102;&#28508;&#22312;&#30340;&#27867;&#21270;&#33021;&#21147;</title><link>http://arxiv.org/abs/2306.02913</link><description>&lt;p&gt;
&#20998;&#25955;&#21270;SGD&#21644;&#24179;&#22343;&#26041;&#21521;SAM&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#26159;&#31561;&#20215;&#30340;
&lt;/p&gt;
&lt;p&gt;
Decentralized SGD and Average-direction SAM are Asymptotically Equivalent. (arXiv:2306.02913v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02913
&lt;/p&gt;
&lt;p&gt;
&#20998;&#25955;SGD&#21644;&#24179;&#22343;&#26041;&#21521;SAM&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#26159;&#31561;&#20215;&#30340;&#65292;D-SGD&#34920;&#29616;&#20986;&#26799;&#24230;&#24179;&#28369;&#25928;&#24212;&#21644;&#38160;&#24230;&#27491;&#21017;&#21270;&#25928;&#24212;&#65292;&#32780;&#19988;&#21487;&#20197;&#25552;&#39640;&#21518;&#39564;&#35780;&#20272;&#65292;&#24182;&#35777;&#26126;&#20102;&#28508;&#22312;&#30340;&#27867;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#25955;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;D-SGD&#65289;&#20801;&#35768;&#22312;&#27809;&#26377;&#20013;&#22830;&#26381;&#21153;&#22120;&#30340;&#25511;&#21046;&#19979;&#65292;&#22823;&#37327;&#35774;&#22791;&#21516;&#26102;&#36827;&#34892;&#21327;&#20316;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#29702;&#35770;&#35748;&#20026;&#65292;&#20998;&#25955;&#21270;&#19981;&#21487;&#36991;&#20813;&#22320;&#21066;&#24369;&#20102;&#27867;&#21270;&#33021;&#21147;&#12290;&#26412;&#25991;&#25361;&#25112;&#20256;&#32479;&#20449;&#24565;&#65292;&#25552;&#20986;&#20102;&#23436;&#20840;&#26032;&#30340;&#35282;&#24230;&#26469;&#29702;&#35299;&#20998;&#25955;&#23398;&#20064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19968;&#33324;&#38750;&#20984;&#38750;-$\beta$-&#24179;&#28369;&#35774;&#32622;&#19979;&#65292;D-SGD&#38544;&#24335;&#22320;&#26368;&#23567;&#21270;&#20102;&#24179;&#22343;&#26041;&#21521;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#65288;SAM&#65289;&#31639;&#27861;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;&#36825;&#31181;&#24778;&#20154;&#30340;&#28176;&#36817;&#31561;&#20215;&#25581;&#31034;&#20102;&#20869;&#22312;&#30340;&#27491;&#21017;&#21270;-&#20248;&#21270;&#26435;&#34913;&#20197;&#21450;&#20998;&#25955;&#21270;&#30340;&#19977;&#20010;&#20248;&#28857;&#65306;&#65288;1&#65289;D-SGD&#20013;&#23384;&#22312;&#19968;&#20010;&#33258;&#30001;&#30340;&#19981;&#30830;&#23450;&#24615;&#35780;&#20272;&#26426;&#21046;&#65292;&#21487;&#20197;&#25552;&#39640;&#21518;&#39564;&#20272;&#35745;&#65307;&#65288;2&#65289;D-SGD&#34920;&#29616;&#20986;&#26799;&#24230;&#24179;&#28369;&#25928;&#24212;&#65307;&#65288;3&#65289;D-SGD&#30340;&#38160;&#24230;&#27491;&#21017;&#21270;&#25928;&#24212;&#19981;&#20250;&#38543;&#30528;&#24635;&#25209;&#22788;&#29702;&#22823;&#23567;&#30340;&#22686;&#21152;&#32780;&#20943;&#23569;&#65292;&#36825;&#35777;&#26126;&#20102;&#28508;&#22312;&#30340;&#27867;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Decentralized stochastic gradient descent (D-SGD) allows collaborative learning on massive devices simultaneously without the control of a central server. However, existing theories claim that decentralization invariably undermines generalization. In this paper, we challenge the conventional belief and present a completely new perspective for understanding decentralized learning. We prove that D-SGD implicitly minimizes the loss function of an average-direction Sharpness-aware minimization (SAM) algorithm under general non-convex non-$\beta$-smooth settings. This surprising asymptotic equivalence reveals an intrinsic regularization-optimization trade-off and three advantages of decentralization: (1) there exists a free uncertainty evaluation mechanism in D-SGD to improve posterior estimation; (2) D-SGD exhibits a gradient smoothing effect; and (3) the sharpness regularization effect of D-SGD does not decrease as total batch size increases, which justifies the potential generalization b
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#20855;&#26377;&#26410;&#30693;&#24178;&#39044;&#30340;&#38750;&#21442;&#25968;&#28508;&#22312;&#22240;&#26524;&#22270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24314;&#31435;&#26465;&#20214;&#30830;&#23450;&#38750;&#21442;&#25968;&#28508;&#22312;&#22240;&#26524;&#22270;&#24182;&#20174;&#20013;&#37325;&#26500;&#12290;&#36825;&#31181;&#26041;&#27861;&#19981;&#38656;&#35201;&#21442;&#25968;&#20551;&#35774;&#65292;&#21487;&#29992;&#20110;&#35782;&#21035;&#27979;&#37327;&#27169;&#22411;&#20013;&#28508;&#22312;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2306.02899</link><description>&lt;p&gt;
&#23398;&#20064;&#20855;&#26377;&#26410;&#30693;&#24178;&#39044;&#30340;&#38750;&#21442;&#25968;&#28508;&#22312;&#22240;&#26524;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning nonparametric latent causal graphs with unknown interventions. (arXiv:2306.02899v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02899
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#20855;&#26377;&#26410;&#30693;&#24178;&#39044;&#30340;&#38750;&#21442;&#25968;&#28508;&#22312;&#22240;&#26524;&#22270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24314;&#31435;&#26465;&#20214;&#30830;&#23450;&#38750;&#21442;&#25968;&#28508;&#22312;&#22240;&#26524;&#22270;&#24182;&#20174;&#20013;&#37325;&#26500;&#12290;&#36825;&#31181;&#26041;&#27861;&#19981;&#38656;&#35201;&#21442;&#25968;&#20551;&#35774;&#65292;&#21487;&#29992;&#20110;&#35782;&#21035;&#27979;&#37327;&#27169;&#22411;&#20013;&#28508;&#22312;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#26410;&#30693;&#24178;&#39044;&#30340;&#28508;&#22312;&#31354;&#38388;&#24314;&#31435;&#26465;&#20214;&#65292;&#20197;&#30830;&#23450;&#38750;&#21442;&#25968;&#28508;&#22312;&#22240;&#26524;&#22270;&#24182;&#20174;&#20013;&#37325;&#26500;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#37325;&#28857;&#26159;&#27979;&#37327;&#27169;&#22411;&#20013;&#28508;&#22312;&#32467;&#26500;&#30340;&#35782;&#21035;&#65292;&#21363;&#22240;&#26524;&#22270;&#27169;&#22411;&#65292;&#22312;&#20854;&#20013;&#35266;&#23519;&#21464;&#37327;&#20043;&#38388;&#30340;&#20381;&#36182;&#24615;&#19982;&#28508;&#22312;&#34920;&#31034;&#20043;&#38388;&#30340;&#20381;&#36182;&#24615;&#30456;&#27604;&#65292;&#24182;&#19981;&#20570;&#20986;&#21442;&#25968;&#20551;&#35774;&#65292;&#22914;&#32447;&#24615;&#25110;&#39640;&#26031;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#19981;&#20551;&#35774;&#38544;&#34255;&#21464;&#37327;&#30340;&#25968;&#37327;&#24050;&#30693;&#65292;&#24182;&#19988;&#25105;&#20204;&#34920;&#26126;&#27599;&#20010;&#38544;&#34255;&#21464;&#37327;&#26368;&#22810;&#21482;&#38656;&#35201;&#19968;&#20010;&#26410;&#30693;&#30340;&#24178;&#39044;&#12290;&#36825;&#25193;&#23637;&#20102;&#26368;&#36817;&#20851;&#20110;&#20174;&#35266;&#27979;&#21644;&#24178;&#39044;&#20013;&#23398;&#20064;&#22240;&#26524;&#34920;&#31034;&#30340;&#24037;&#20316;&#12290;&#35777;&#26126;&#26159;&#24314;&#35774;&#24615;&#30340;&#65292;&#24182;&#24341;&#20837;&#20102;&#20004;&#20010;&#26032;&#30340;&#22270;&#24418;&#27010;&#24565;&#8212;&#8212;&#24819;&#35937;&#23376;&#38598;&#21644;&#23396;&#31435;&#36793;&#8212;&#8212;&#23427;&#20204;&#26412;&#36523;&#21487;&#33021;&#26159;&#26377;&#29992;&#30340;&#12290;&#20316;&#20026;&#19968;&#20010;&#29420;&#31435;&#30340;&#24863;&#20852;&#36259;&#30340;&#38382;&#39064;&#65292;&#35777;&#26126;&#36824;&#28041;&#21450;&#23545;&#36793;&#32536;&#23450;&#21521;&#38480;&#21046;&#30340;&#26032;&#30340;&#29305;&#24449;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We establish conditions under which latent causal graphs are nonparametrically identifiable and can be reconstructed from unknown interventions in the latent space. Our primary focus is the identification of the latent structure in a measurement model, i.e. causal graphical models where dependence between observed variables is insignificant compared to dependence between latent representations, without making parametric assumptions such as linearity or Gaussianity. Moreover, we do not assume the number of hidden variables is known, and we show that at most one unknown intervention per hidden variable is needed. This extends a recent line of work on learning causal representations from observations and interventions. The proofs are constructive and introduce two new graphical concepts -- imaginary subsets and isolated edges -- that may be useful in their own right. As a matter of independent interest, the proofs also involve a novel characterization of the limits of edge orientations wi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;transformer&#30340;&#34920;&#31034;&#33021;&#21147;&#65292;&#27491;&#38754;&#35828;&#26126;&#20102;transformer&#22312;&#31232;&#30095;&#24179;&#22343;&#20219;&#21153;&#20013;&#30340;&#25928;&#29575;&#27604;&#24490;&#29615;&#32593;&#32476;&#21644;&#21069;&#39304;&#32593;&#32476;&#26356;&#39640;&#65292;&#24182;&#23637;&#31034;&#20102;&#22823;&#23884;&#20837;&#32500;&#24230;&#22312;transformer&#20013;&#30340;&#24517;&#35201;&#24615;&#21644;&#20316;&#29992;&#65307;&#36127;&#38754;&#35828;&#26126;&#20102;&#27880;&#24847;&#21147;&#23618;&#30340;&#22797;&#26434;&#24230;&#38543;&#36755;&#20837;&#22823;&#23567;&#32447;&#24615;&#32553;&#25918;&#65292;&#20294;&#36825;&#31181;&#24773;&#20917;&#22312;&#23454;&#36341;&#20013;&#24456;&#23569;&#21457;&#29983;&#65292;&#21487;&#20197;&#20351;&#29992;&#26367;&#20195;&#30340;&#21464;&#20307;&#12290;</title><link>http://arxiv.org/abs/2306.02896</link><description>&lt;p&gt;
Transformer&#30340;&#20195;&#34920;&#24615;&#20248;&#21183;&#21644;&#23616;&#38480;&#24615;
&lt;/p&gt;
&lt;p&gt;
Representational Strengths and Limitations of Transformers. (arXiv:2306.02896v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02896
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;transformer&#30340;&#34920;&#31034;&#33021;&#21147;&#65292;&#27491;&#38754;&#35828;&#26126;&#20102;transformer&#22312;&#31232;&#30095;&#24179;&#22343;&#20219;&#21153;&#20013;&#30340;&#25928;&#29575;&#27604;&#24490;&#29615;&#32593;&#32476;&#21644;&#21069;&#39304;&#32593;&#32476;&#26356;&#39640;&#65292;&#24182;&#23637;&#31034;&#20102;&#22823;&#23884;&#20837;&#32500;&#24230;&#22312;transformer&#20013;&#30340;&#24517;&#35201;&#24615;&#21644;&#20316;&#29992;&#65307;&#36127;&#38754;&#35828;&#26126;&#20102;&#27880;&#24847;&#21147;&#23618;&#30340;&#22797;&#26434;&#24230;&#38543;&#36755;&#20837;&#22823;&#23567;&#32447;&#24615;&#32553;&#25918;&#65292;&#20294;&#36825;&#31181;&#24773;&#20917;&#22312;&#23454;&#36341;&#20013;&#24456;&#23569;&#21457;&#29983;&#65292;&#21487;&#20197;&#20351;&#29992;&#26367;&#20195;&#30340;&#21464;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27880;&#24847;&#21147;&#23618;&#24120;&#29992;&#20110;transformer&#20013;&#65292;&#26159;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#30340;&#25903;&#26609;&#20043;&#19968;&#65292;&#20294;&#19982;&#20854;&#20182;&#32593;&#32476;&#32467;&#26500;&#30456;&#27604;&#65292;&#23427;&#20204;&#30340;&#22909;&#22788;&#21644;&#32570;&#38519;&#27809;&#26377;&#25968;&#23398;&#25551;&#36848;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23545;&#27880;&#24847;&#21147;&#23618;&#30340;&#34920;&#31034;&#33021;&#21147;&#36827;&#34892;&#20102;&#27491;&#38754;&#21644;&#36127;&#38754;&#30340;&#30740;&#31350;&#65292;&#24182;&#32858;&#28966;&#20110;&#20869;&#22312;&#22797;&#26434;&#24230;&#21442;&#25968;&#65292;&#22914;&#23485;&#24230;&#12289;&#28145;&#24230;&#21644;&#23884;&#20837;&#32500;&#24230;&#12290;&#22312;&#27491;&#38754;&#26041;&#38754;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#39033;&#31232;&#30095;&#24179;&#22343;&#20219;&#21153;&#65292;&#20854;&#20013;&#24490;&#29615;&#32593;&#32476;&#21644;&#21069;&#39304;&#32593;&#32476;&#30340;&#22797;&#26434;&#24230;&#37117;&#38543;&#36755;&#20837;&#22823;&#23567;&#21576;&#22810;&#39033;&#24335;&#32553;&#25918;&#65292;&#32780;transformer&#20165;&#21576;&#23545;&#25968;&#32553;&#25918;&#65307;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;&#30456;&#21516;&#30340;&#26500;&#36896;&#26469;&#23637;&#31034;transformer&#20013;&#22823;&#23884;&#20837;&#32500;&#24230;&#30340;&#24517;&#35201;&#24615;&#21644;&#20316;&#29992;&#12290;&#22312;&#36127;&#38754;&#26041;&#38754;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#19977;&#20803;&#26816;&#27979;&#20219;&#21153;&#65292;&#20854;&#20013;&#27880;&#24847;&#21147;&#23618;&#30340;&#22797;&#26434;&#24230;&#38543;&#36755;&#20837;&#22823;&#23567;&#21576;&#32447;&#24615;&#32553;&#25918;&#65307;&#30001;&#20110;&#36825;&#31181;&#24773;&#20917;&#22312;&#23454;&#36341;&#20013;&#20284;&#20046;&#24456;&#23569;&#21457;&#29983;&#65292;&#22240;&#27492;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#21487;&#20197;&#26367;&#20195;&#30340;&#21464;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;
Attention layers, as commonly used in transformers, form the backbone of modern deep learning, yet there is no mathematical description of their benefits and deficiencies as compared with other architectures. In this work we establish both positive and negative results on the representation power of attention layers, with a focus on intrinsic complexity parameters such as width, depth, and embedding dimension. On the positive side, we present a sparse averaging task, where recurrent networks and feedforward networks all have complexity scaling polynomially in the input size, whereas transformers scale merely logarithmically in the input size; furthermore, we use the same construction to show the necessity and role of a large embedding dimension in a transformer. On the negative side, we present a triple detection task, where attention layers in turn have complexity scaling linearly in the input size; as this scenario seems rare in practice, we also present natural variants that can be 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23454;&#38469;&#20195;&#20215;&#30340;&#40657;&#30418;&#25915;&#20987;&#65292;&#36890;&#36807;&#35774;&#35745;&#26032;&#30340;&#25915;&#20987;&#26041;&#24335;&#65292;&#25104;&#21151;&#20943;&#23569;&#20102;&#8220;&#26377;&#23475;&#8221;&#26597;&#35810;&#30340;&#25968;&#37327;&#65292;&#25552;&#39640;&#20102;&#40657;&#30418;&#25915;&#20987;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.02895</link><description>&lt;p&gt;
&#19981;&#30772;&#22351;&#40657;&#30418;&#20998;&#31867;&#22120;&#30340;&#24773;&#20917;&#19979;&#35268;&#36991;&#23427;&#30340;&#20998;&#31867;&#8212;&#8212;&#22522;&#20110;&#23454;&#38469;&#20195;&#20215;&#30340;&#40657;&#30418;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Evading Black-box Classifiers Without Breaking Eggs. (arXiv:2306.02895v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02895
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23454;&#38469;&#20195;&#20215;&#30340;&#40657;&#30418;&#25915;&#20987;&#65292;&#36890;&#36807;&#35774;&#35745;&#26032;&#30340;&#25915;&#20987;&#26041;&#24335;&#65292;&#25104;&#21151;&#20943;&#23569;&#20102;&#8220;&#26377;&#23475;&#8221;&#26597;&#35810;&#30340;&#25968;&#37327;&#65292;&#25552;&#39640;&#20102;&#40657;&#30418;&#25915;&#20987;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20915;&#31574;&#30340;&#35268;&#36991;&#25915;&#20987;&#26159;&#36890;&#36807;&#19981;&#26029;&#26597;&#35810;&#40657;&#30418;&#20998;&#31867;&#22120;&#26469;&#29983;&#25104;&#23545;&#25239;&#24615;&#26679;&#26412;&#12290;&#26412;&#25991;&#35748;&#20026;&#29616;&#26377;&#30340;&#25915;&#20987;&#26041;&#24335;&#22312;&#22788;&#29702;&#23545;&#23433;&#20840;&#24615;&#25935;&#24863;&#30340;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#26102;&#26377;&#32570;&#38519;&#12290;&#22240;&#20026;&#36825;&#20123;&#31995;&#32479;&#20027;&#35201;&#30446;&#30340;&#26159;&#36807;&#28388;&#20986;&#26377;&#23475;&#25968;&#25454;&#65288;&#20363;&#22914;&#24694;&#24847;&#36719;&#20214;&#12289;&#26377;&#23475;&#20869;&#23481;&#31561;&#65289;&#65292;&#25152;&#20197;&#26597;&#35810;&#30340;&#20195;&#20215;&#26159;&#19981;&#23545;&#31561;&#30340;&#65292;&#19968;&#26086;&#26597;&#35810;&#34987;&#26816;&#27979;&#20986;&#26159;&#26377;&#23475;&#30340;&#65292;&#23601;&#20250;&#35302;&#21457;&#39069;&#22806;&#30340;&#23433;&#20840;&#36807;&#28388;&#65292;&#20363;&#22914;&#20351;&#29992;&#38480;&#21046;&#25110;&#36134;&#25143;&#26242;&#20572;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22522;&#20110;&#20915;&#31574;&#30340;&#25915;&#20987;&#20135;&#29983;&#20102;&#22823;&#37327;&#30340;&#8220;&#26377;&#23475;&#8221;&#26597;&#35810;&#65292;&#23548;&#33268;&#23427;&#20204;&#24456;&#21487;&#33021;&#23545;&#23433;&#20840;&#20851;&#38190;&#31995;&#32479;&#26080;&#25928;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#26032;&#30340;&#25915;&#20987;&#26041;&#24335;&#65292;&#36890;&#36807;&#20943;&#23569;&#8220;&#26377;&#23475;&#8221;&#26597;&#35810;&#30340;&#25968;&#37327;&#65288;&#26368;&#22810;&#21487;&#20197;&#20943;&#23569; $1.5$ &#20493;&#21040; $7.3$ &#20493;&#65289;&#65292;&#20197;&#23454;&#29616;&#26356;&#21152;&#26377;&#25928;&#30340;&#40657;&#30418;&#25915;&#20987;&#12290;&#20294;&#36825;&#20123;&#25915;&#20987;&#30340;&#27491;&#24120;&#26597;&#35810;&#25968;&#37327;&#22823;&#22823;&#22686;&#21152;&#65292;&#22240;&#27492;&#25552;&#20986;&#20102;&#22312;&#23454;&#38469;&#20195;&#20215;&#24230;&#37327;&#19979;&#26500;&#24314;&#26356;&#26377;&#25928;&#30340;&#40657;&#30418;&#25915;&#20987;&#30340;&#24320;&#25918;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Decision-based evasion attacks repeatedly query a black-box classifier to generate adversarial examples. Prior work measures the cost of such attacks by the total number of queries made to the classifier. We argue this metric is flawed. Most security-critical machine learning systems aim to weed out "bad" data (e.g., malware, harmful content, etc). Queries to such systems carry a fundamentally asymmetric cost: queries detected as "bad" come at a higher cost because they trigger additional security filters, e.g., usage throttling or account suspension. Yet, we find that existing decision-based attacks issue a large number of "bad" queries, which likely renders them ineffective against security-critical systems. We then design new attacks that reduce the number of bad queries by $1.5$-$7.3\times$, but often at a significant increase in total (non-bad) queries. We thus pose it as an open problem to build black-box attacks that are more effective under realistic cost metrics.
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#35752;&#35770;&#22312;&#20855;&#26377;&#36172;&#21338;&#21453;&#39304;&#30340;&#38543;&#26426;&#29615;&#22659;&#20013;&#36827;&#34892;&#36873;&#25321;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#25968;&#25454;&#30340;&#27169;&#22411;&#36873;&#25321;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#20445;&#35777;&#12290;&#36890;&#36807;&#21033;&#29992;&#23454;&#38469;&#36951;&#25022;&#65292;&#36825;&#20123;&#31639;&#27861;&#22312;&#23454;&#38469;&#20013;&#21462;&#24471;&#20102;&#22909;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.02869</link><description>&lt;p&gt;
&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#36951;&#25022;&#24179;&#34913;&#22312;&#32447;&#27169;&#22411;&#36873;&#25321;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Data-Driven Regret Balancing for Online Model Selection in Bandits. (arXiv:2306.02869v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02869
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#35752;&#35770;&#22312;&#20855;&#26377;&#36172;&#21338;&#21453;&#39304;&#30340;&#38543;&#26426;&#29615;&#22659;&#20013;&#36827;&#34892;&#36873;&#25321;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#25968;&#25454;&#30340;&#27169;&#22411;&#36873;&#25321;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#20445;&#35777;&#12290;&#36890;&#36807;&#21033;&#29992;&#23454;&#38469;&#36951;&#25022;&#65292;&#36825;&#20123;&#31639;&#27861;&#22312;&#23454;&#38469;&#20013;&#21462;&#24471;&#20102;&#22909;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#20855;&#26377;&#36172;&#21338;&#21453;&#39304;&#30340;&#38543;&#26426;&#29615;&#22659;&#20013;&#36827;&#34892;&#39034;&#24207;&#20915;&#31574;&#27169;&#22411;&#36873;&#25321;&#65292;&#20854;&#20013;&#20803;&#23398;&#20064;&#22120;&#21487;&#20197;&#20351;&#29992;&#19968;&#32452;&#22522;&#26412;&#23398;&#20064;&#22120;&#65292;&#24182;&#26681;&#25454;&#27599;&#20010;&#22522;&#26412;&#23398;&#20064;&#22120;&#25512;&#33616;&#30340;&#31574;&#30053;&#21160;&#24577;&#20915;&#31574;&#12290;&#25105;&#20204;&#36890;&#36807;&#36951;&#25022;&#24179;&#34913;&#26469;&#25191;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#20294;&#19982;&#27492;&#30456;&#20851;&#30340;&#26368;&#36817;&#25991;&#29486;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#27809;&#26377;&#20551;&#35774;&#20219;&#20309;&#20851;&#20110;&#22522;&#26412;&#23398;&#20064;&#22120;&#30340;&#20808;&#39564;&#30693;&#35782;&#65292;&#22914;&#20505;&#36873;&#36951;&#25022;&#20445;&#35777;&#65307;&#30456;&#21453;&#65292;&#25105;&#20204;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#25581;&#31034;&#36825;&#20123;&#25968;&#37327;&#12290;&#22240;&#27492;&#65292;&#20803;&#23398;&#20064;&#22120;&#33021;&#22815;&#21033;&#29992;&#27599;&#20010;&#22522;&#26412;&#23398;&#20064;&#22120;&#22312;&#32473;&#23450;&#30340;&#23398;&#20064;&#29615;&#22659;&#20013;&#20135;&#29983;&#30340;&#23454;&#38469;&#36951;&#25022;&#65288;&#32780;&#19981;&#26159;&#26399;&#26395;&#36951;&#25022;&#65289;&#65292;&#24182;&#25361;&#36873;&#20986;&#26368;&#20339;&#30340;&#36951;&#25022;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#20010;&#27169;&#22411;&#36873;&#25321;&#31639;&#27861;&#65292;&#25805;&#20316;&#26356;&#20026;&#38596;&#24515;&#21187;&#21187;&#30340;&#36951;&#25022;&#27010;&#24565;&#65292;&#24182;&#19988;&#38500;&#20102;&#36890;&#36807;&#36951;&#25022;&#24179;&#34913;&#35777;&#26126;&#27169;&#22411;&#36873;&#25321;&#20445;&#35777;&#22806;&#65292;&#25105;&#20204;&#36824;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#22788;&#29702;&#23454;&#38469;&#36951;&#25022;&#30340;&#20196;&#20154;&#20449;&#26381;&#30340;&#23454;&#38469;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider model selection for sequential decision making in stochastic environments with bandit feedback, where a meta-learner has at its disposal a pool of base learners, and decides on the fly which action to take based on the policies recommended by each base learner. Model selection is performed by regret balancing but, unlike the recent literature on this subject, we do not assume any prior knowledge about the base learners like candidate regret guarantees; instead, we uncover these quantities in a data-driven manner. The meta-learner is therefore able to leverage the realized regret incurred by each base learner for the learning environment at hand (as opposed to the expected regret), and single out the best such regret. We design two model selection algorithms operating with this more ambitious notion of regret and, besides proving model selection guarantees via regret balancing, we experimentally demonstrate the compelling practical benefits of dealing with actual regrets ins
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;$L^\infty$&#33539;&#25968;&#19979;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;&#21487;&#23398;&#20064;&#24615;&#65292;&#24314;&#31435;&#20102;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#19979;&#30028;&#21644;&#19978;&#30028;&#65292;&#24182;&#30830;&#23450;&#20102;&#22312;&#28385;&#36275;&#26465;&#20214;&#26102;&#21487;&#20197;&#22810;&#39033;&#24335;&#26679;&#26412;&#19979;&#23454;&#29616;$L^\infty$&#23398;&#20064;&#30340;&#39057;&#35889;&#34928;&#20943;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2306.02833</link><description>&lt;p&gt;
&#24102;&#26377;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;$L^\infty$&#21487;&#23398;&#20064;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
The $L^\infty$ Learnability of Reproducing Kernel Hilbert Spaces. (arXiv:2306.02833v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02833
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;$L^\infty$&#33539;&#25968;&#19979;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;&#21487;&#23398;&#20064;&#24615;&#65292;&#24314;&#31435;&#20102;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#19979;&#30028;&#21644;&#19978;&#30028;&#65292;&#24182;&#30830;&#23450;&#20102;&#22312;&#28385;&#36275;&#26465;&#20214;&#26102;&#21487;&#20197;&#22810;&#39033;&#24335;&#26679;&#26412;&#19979;&#23454;&#29616;$L^\infty$&#23398;&#20064;&#30340;&#39057;&#35889;&#34928;&#20943;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;$L^\infty$&#33539;&#25968;&#19979;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#30340;&#21487;&#23398;&#20064;&#24615;&#65292;&#36825;&#23545;&#20110;&#29702;&#35299;&#26680;&#26041;&#27861;&#21644;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#22312;&#23433;&#20840;&#21644;&#23433;&#20840;&#20851;&#38190;&#24212;&#29992;&#20013;&#30340;&#24615;&#33021;&#33267;&#20851;&#37325;&#35201;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#23558;RKHS&#30340;$L^\infty$&#21487;&#23398;&#20064;&#24615;&#19982;&#20851;&#32852;&#26680;&#30340;&#39057;&#35889;&#34928;&#20943;&#30456;&#20851;&#32852;&#65292;&#24182;&#24314;&#31435;&#20102;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#19979;&#30028;&#21644;&#19978;&#30028;&#12290;&#29305;&#21035;&#22320;&#65292;&#23545;&#20110;&#29699;&#19978;&#30340;&#28857;&#31215;&#26680;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#22312;&#22810;&#39033;&#24335;&#26679;&#26412;&#19979;&#21487;&#20197;&#23454;&#29616;$L^\infty$&#23398;&#20064;&#30340;&#26465;&#20214;&#12290;&#20551;&#35774;&#36755;&#20837;&#32500;&#25968;&#20026;$d$&#65292;&#19988;&#26680;&#39057;&#35889;&#22823;&#33268;&#34928;&#20943;&#20026;$\lambda_k\sim k^{-1-\beta}$&#65292;&#20854;&#20013;$\beta&gt;0$&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22914;&#26524;$\beta$&#29420;&#31435;&#20110;&#36755;&#20837;&#32500;&#25968;$d$&#65292;&#37027;&#20040;RKHS&#20013;&#30340;&#20989;&#25968;&#21487;&#20197;&#22312;$L^\infty$&#33539;&#25968;&#19979;&#26377;&#25928;&#22320;&#23398;&#20064;&#65292;&#21363;&#26679;&#26412;&#22797;&#26434;&#24230;&#22810;&#39033;&#24335;&#22320;&#20381;&#36182;&#20110;$d$&#12290;&#30456;&#21453;&#65292;&#22914;&#26524;$\beta=1/\mathrm{poly}(d)$&#65292;&#21017;$L^\infty$&#23398;&#20064;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we analyze the learnability of reproducing kernel Hilbert spaces (RKHS) under the $L^\infty$ norm, which is critical for understanding the performance of kernel methods and random feature models in safety- and security-critical applications. Specifically, we relate the $L^\infty$ learnability of a RKHS to the spectrum decay of the associate kernel and both lower bounds and upper bounds of the sample complexity are established. In particular, for dot-product kernels on the sphere, we identify conditions when the $L^\infty$ learning can be achieved with polynomial samples. Let $d$ denote the input dimension and assume the kernel spectrum roughly decays as $\lambda_k\sim k^{-1-\beta}$ with $\beta&gt;0$. We prove that if $\beta$ is independent of the input dimension $d$, then functions in the RKHS can be learned efficiently under the $L^\infty$ norm, i.e., the sample complexity depends polynomially on $d$. In contrast, if $\beta=1/\mathrm{poly}(d)$, then the $L^\infty$ learning 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#20219;&#21153;&#12289;&#22810;&#27169;&#24577;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;MM-DAG&#65289;&#23398;&#20064;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#20132;&#36890;&#25317;&#22581;&#20998;&#26512;&#65292;&#20197;&#26368;&#22823;&#21270;&#22270;&#30340;&#19968;&#33268;&#24615;&#21644;&#19968;&#33268;&#24615;&#65292;&#36890;&#36807;&#22810;&#27169;&#24577;&#22238;&#24402;&#23545;&#19981;&#21516;&#21464;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#36827;&#34892;&#32447;&#24615;&#22240;&#26524;&#20851;&#31995;&#25551;&#36848;&#12290;</title><link>http://arxiv.org/abs/2306.02831</link><description>&lt;p&gt;
MM-DAG: &#22810;&#27169;&#24577;&#25968;&#25454;&#30340;&#22810;&#20219;&#21153;&#26377;&#21521;&#26080;&#29615;&#22270;&#23398;&#20064;&#21450;&#20854;&#22312;&#20132;&#36890;&#25317;&#22581;&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
MM-DAG: Multi-task DAG Learning for Multi-modal Data -- with Application for Traffic Congestion Analysis. (arXiv:2306.02831v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02831
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#20219;&#21153;&#12289;&#22810;&#27169;&#24577;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;MM-DAG&#65289;&#23398;&#20064;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#20132;&#36890;&#25317;&#22581;&#20998;&#26512;&#65292;&#20197;&#26368;&#22823;&#21270;&#22270;&#30340;&#19968;&#33268;&#24615;&#21644;&#19968;&#33268;&#24615;&#65292;&#36890;&#36807;&#22810;&#27169;&#24577;&#22238;&#24402;&#23545;&#19981;&#21516;&#21464;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#36827;&#34892;&#32447;&#24615;&#22240;&#26524;&#20851;&#31995;&#25551;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#23398;&#20064;&#22810;&#20219;&#21153;&#12289;&#22810;&#27169;&#24577;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;MM-DAG&#65289;&#65292;&#36825;&#31181;&#22270;&#24120;&#35265;&#20110;&#22797;&#26434;&#31995;&#32479;&#65292;&#22914;&#20132;&#36890;&#12289;&#21046;&#36896;&#21644;&#22825;&#27668;&#31995;&#32479;&#65292;&#21464;&#37327;&#26159;&#26631;&#37327;&#12289;&#21521;&#37327;&#21644;&#20989;&#25968;&#30340;&#28151;&#21512;&#12290;&#26412;&#25991;&#20197;&#20132;&#36890;&#25317;&#22581;&#20998;&#26512;&#20026;&#20855;&#20307;&#26696;&#20363;&#65292;&#20854;&#20013;&#19968;&#20010;&#20132;&#36890;&#36335;&#21475;&#36890;&#24120;&#34987;&#35748;&#20026;&#26159;&#19968;&#20010; DAG&#12290;&#22312;&#22810;&#20010;&#20132;&#21449;&#21475;&#32452;&#25104;&#30340;&#20132;&#36890;&#32593;&#32476;&#20013;&#65292;&#19981;&#21516;&#30340;&#20132;&#21449;&#21475;&#21482;&#33021;&#35266;&#23519;&#21040;&#19968;&#20123;&#37325;&#21472;&#21644;&#19981;&#21516;&#30340;&#21464;&#37327;&#12290;&#20363;&#22914;&#65292;&#19968;&#20010;&#20449;&#21495;ized&#30340;&#36335;&#21475;&#26377;&#20851;&#20110;&#20132;&#36890;&#28783;&#30340;&#21464;&#37327;&#65292;&#32780;&#38750;&#20449;&#21495;ized&#30340;&#36335;&#21475;&#21017;&#27809;&#26377;&#12290;&#36825;&#20419;&#36827;&#20102;&#22810;&#20219;&#21153;&#35774;&#35745;&#65306;&#23558;&#27599;&#20010;DAG&#20316;&#20026;&#19968;&#20010;&#20219;&#21153;&#65292;MM-DAG&#35797;&#22270;&#20849;&#21516;&#23398;&#20064;&#22810;&#20010;DAG&#65292;&#20197;&#26368;&#22823;&#21270;&#23427;&#20204;&#30340;&#19968;&#33268;&#24615;&#21644;&#19968;&#33268;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#21019;&#26032;&#24615;&#22320;&#25552;&#20986;&#20102;&#22810;&#27169;&#24577;&#22238;&#24402;&#65292;&#29992;&#20110;&#32447;&#24615;&#22240;&#26524;&#20851;&#31995;&#25551;&#36848;&#19981;&#21516;&#21464;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#24615;&#24046;&#24322;&#65288;CD&#65289;&#24230;&#37327;&#21450;&#20854;&#30340;&#24046;&#20998;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes to learn Multi-task, Multi-modal Direct Acyclic Graphs (MM-DAGs), which are commonly observed in complex systems, e.g., traffic, manufacturing, and weather systems, whose variables are multi-modal with scalars, vectors, and functions. This paper takes the traffic congestion analysis as a concrete case, where a traffic intersection is usually regarded as a DAG. In a road network of multiple intersections, different intersections can only have some overlapping and distinct variables observed. For example, a signalized intersection has traffic light-related variables, whereas unsignalized ones do not. This encourages the multi-task design: with each DAG as a task, the MM-DAG tries to learn the multiple DAGs jointly so that their consensus and consistency are maximized. To this end, we innovatively propose a multi-modal regression for linear causal relationship description of different variables. Then we develop a novel Causality Difference (CD) measure and its differen
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#37327;&#23376;&#26680;&#24515;&#38598;&#26500;&#36896;&#30340;&#36817;&#26368;&#20248;&#32858;&#31867;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;$\tilde{O}(\sqrt{nk}d^{3/2})$&#30340;&#26597;&#35810;&#22797;&#26434;&#24230;&#19979;&#32553;&#23567;&#20102;&#36755;&#20837;&#22823;&#23567;&#65292;&#24182;&#20026;&#21508;&#31181;$k$-&#32858;&#31867;&#36817;&#20284;&#31639;&#27861;&#25552;&#20379;&#20102;&#20108;&#27425;&#21152;&#36895;&#12290;</title><link>http://arxiv.org/abs/2306.02826</link><description>&lt;p&gt;
&#22522;&#20110;&#37327;&#23376;&#26680;&#24515;&#38598;&#26500;&#36896;&#30340;&#36817;&#26368;&#20248;&#32858;&#31867;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Near-Optimal Quantum Coreset Construction Algorithms for Clustering. (arXiv:2306.02826v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02826
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#37327;&#23376;&#26680;&#24515;&#38598;&#26500;&#36896;&#30340;&#36817;&#26368;&#20248;&#32858;&#31867;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;$\tilde{O}(\sqrt{nk}d^{3/2})$&#30340;&#26597;&#35810;&#22797;&#26434;&#24230;&#19979;&#32553;&#23567;&#20102;&#36755;&#20837;&#22823;&#23567;&#65292;&#24182;&#20026;&#21508;&#31181;$k$-&#32858;&#31867;&#36817;&#20284;&#31639;&#27861;&#25552;&#20379;&#20102;&#20108;&#27425;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;$\mathbb{R}^d$&#20013;$k$-&#32858;&#31867;&#65288;&#20363;&#22914;$k$-&#20013;&#20301;&#25968;&#21644;$k$-&#22343;&#20540;&#65289;&#26159;&#19968;&#31181;&#22522;&#26412;&#30340;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#12290;&#23613;&#31649;&#24050;&#30693;&#22312;&#32463;&#20856;&#35774;&#32622;&#19979;&#23545;&#20110;&#20855;&#26377;&#22522;&#25968;$n$&#30340;&#25968;&#25454;&#38598;&#30340;&#36817;&#32447;&#24615;&#26102;&#38388;&#36817;&#20284;&#31639;&#27861;&#65292;&#20294;&#23545;&#20110;&#23376;&#32447;&#24615;&#26102;&#38388;&#37327;&#23376;&#31639;&#27861;&#20173;&#28982;&#26159;&#26410;&#30693;&#30340;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#22312;$\mathbb{R}^d$&#20013;&#26597;&#25214;$k$-&#32858;&#31867;&#26680;&#24515;&#38598;&#30340;&#37327;&#23376;&#31639;&#27861;&#65292;&#20854;&#26597;&#35810;&#22797;&#26434;&#24230;&#20026;$\tilde{O}(\sqrt{nk}d^{3/2})$&#12290;&#25105;&#20204;&#30340;&#26680;&#24515;&#38598;&#23558;&#36755;&#20837;&#22823;&#23567;&#20174;$n$&#20943;&#23569;&#21040;$\mathrm{poly}(k\epsilon^{-1}d)$&#65292;&#20174;&#32780;&#29616;&#26377;&#30340;&#32858;&#31867;$\alpha$-&#36817;&#20284;&#31639;&#27861;&#21487;&#20197;&#22312;&#20854;&#19978;&#36816;&#34892;&#24182;&#20135;&#29983;$(1+\epsilon)\alpha$-&#36817;&#20284;&#12290;&#36825;&#26368;&#32456;&#20026;&#21508;&#31181;$k$-&#32858;&#31867;&#36817;&#20284;&#31639;&#27861;&#25552;&#20379;&#20102;&#20108;&#27425;&#21152;&#36895;&#12290;&#25105;&#20204;&#34917;&#20805;&#20102;&#36817;&#20046;&#21305;&#37197;&#30340;&#19979;&#30028;&#65292;&#21363;&#20219;&#20309;&#37327;&#23376;&#31639;&#27861;&#24517;&#39035;&#36827;&#34892;$\Omega(\sqrt{nk})$&#27425;&#26597;&#35810;&#25165;&#33021;&#23454;&#29616;&#29978;&#33267;&#20110;$k$-&#32858;&#31867;&#30340;$O(1)$-&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;
$k$-Clustering in $\mathbb{R}^d$ (e.g., $k$-median and $k$-means) is a fundamental machine learning problem. While near-linear time approximation algorithms were known in the classical setting for a dataset with cardinality $n$, it remains open to find sublinear-time quantum algorithms. We give quantum algorithms that find coresets for $k$-clustering in $\mathbb{R}^d$ with $\tilde{O}(\sqrt{nk}d^{3/2})$ query complexity. Our coreset reduces the input size from $n$ to $\mathrm{poly}(k\epsilon^{-1}d)$, so that existing $\alpha$-approximation algorithms for clustering can run on top of it and yield $(1 + \epsilon)\alpha$-approximation. This eventually yields a quadratic speedup for various $k$-clustering approximation algorithms. We complement our algorithm with a nearly matching lower bound, that any quantum algorithm must make $\Omega(\sqrt{nk})$ queries in order to achieve even $O(1)$-approximation for $k$-clustering.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22522;&#20110;&#36923;&#36753;&#22238;&#24402;&#26041;&#27861;&#30340;&#26420;&#32032;&#20998;&#31867;&#22120;&#24182;&#20248;&#21270;&#36873;&#25321;&#20998;&#31867;&#22120;&#30340;&#25130;&#36317;&#65292;&#21363;&#20351;&#25311;&#21512;&#30340;PU&#25968;&#25454;&#24182;&#19981;&#31526;&#21512;&#35813;&#27169;&#22411;&#65292;&#20063;&#33021;&#33719;&#24471;&#19982;&#31454;&#20105;&#23545;&#25163;&#30456;&#24403;&#25110;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.02798</link><description>&lt;p&gt;
&#22522;&#20110;&#36923;&#36753;&#22238;&#24402;&#26041;&#27861;&#22686;&#24378;&#27491;&#26080;&#26631;&#35760;&#25968;&#25454;&#30340;&#26420;&#32032;&#20998;&#31867;&#22120;
&lt;/p&gt;
&lt;p&gt;
Enhancing naive classifier for positive unlabeled data based on logistic regression approach. (arXiv:2306.02798v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02798
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22522;&#20110;&#36923;&#36753;&#22238;&#24402;&#26041;&#27861;&#30340;&#26420;&#32032;&#20998;&#31867;&#22120;&#24182;&#20248;&#21270;&#36873;&#25321;&#20998;&#31867;&#22120;&#30340;&#25130;&#36317;&#65292;&#21363;&#20351;&#25311;&#21512;&#30340;PU&#25968;&#25454;&#24182;&#19981;&#31526;&#21512;&#35813;&#27169;&#22411;&#65292;&#20063;&#33021;&#33719;&#24471;&#19982;&#31454;&#20105;&#23545;&#25163;&#30456;&#24403;&#25110;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35748;&#20026;&#65292;&#22312;&#36873;&#25321;&#23436;&#20840;&#38543;&#26426;&#65288;SCAR&#65289;&#20551;&#35774;&#19979;&#20998;&#26512;&#27491;&#26080;&#26631;&#35760;&#65288;PU&#65289;&#25968;&#25454;&#26102;&#65292;&#23558;&#38382;&#39064;&#35270;&#20026;&#23545;&#25968;&#25454;&#25311;&#21512;&#38169;&#35823;&#35268;&#33539;&#27169;&#22411;&#23558;&#26159;&#26377;&#30410;&#30340;&#12290;&#25442;&#21477;&#35805;&#35828;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#25311;&#21512;&#36923;&#36753;&#22238;&#24402;&#27169;&#22411;&#26102;&#65292;&#21363;&#20351;&#25311;&#21512;&#30340;PU&#25968;&#25454;&#24182;&#19981;&#31526;&#21512;&#35813;&#27169;&#22411;&#65292;&#25311;&#21512;&#32467;&#26524;&#20063;&#24847;&#21619;&#30528;&#24471;&#21040;&#30340;&#21442;&#25968;&#21521;&#37327;&#19982;&#30495;&#23454;&#21442;&#25968;&#21521;&#37327;&#36817;&#20284;&#20849;&#32447;&#12290;&#36825;&#19968;&#35266;&#23519;&#32467;&#26524;&#19982;&#22522;&#20110;&#31867;&#20284;&#20110;F1&#24230;&#37327;&#30340;&#20248;&#21270;&#36873;&#25321;&#20998;&#31867;&#22120;&#30340;&#25130;&#36317;&#30456;&#32467;&#21512;&#65292;&#21487;&#22312;&#20960;&#20010;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#33719;&#24471;&#19982;&#31454;&#20105;&#23545;&#25163;&#30456;&#24403;&#25110;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We argue that for analysis of Positive Unlabeled (PU) data under Selected Completely At Random (SCAR) assumption it is fruitful to view the problem as fitting of misspecified model to the data. Namely, we show that the results on misspecified fit imply that in the case when posterior probability of the response is modelled by logistic regression, fitting the logistic regression to the observable PU data which {\it does not} follow this model, still yields the vector of estimated parameters approximately colinear with the true vector of parameters. This observation together with choosing the intercept of the classifier based on optimisation of analogue of F1 measure yields a classifier which performs on par or better than its competitors on several real data sets considered.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#38454;&#26021;&#21147;&#28145;&#24230;&#38598;&#25104; (FoRDE) &#31639;&#27861;&#65292;&#23427;&#20351;&#29992;&#36755;&#20837;&#26799;&#24230;&#26469;&#22686;&#24378;&#22810;&#26679;&#24615;&#20197;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.02775</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#38598;&#21512;&#30340;&#36755;&#20837;&#26799;&#24230;&#22810;&#26679;&#24615;
&lt;/p&gt;
&lt;p&gt;
Input gradient diversity for neural network ensembles. (arXiv:2306.02775v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02775
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#38454;&#26021;&#21147;&#28145;&#24230;&#38598;&#25104; (FoRDE) &#31639;&#27861;&#65292;&#23427;&#20351;&#29992;&#36755;&#20837;&#26799;&#24230;&#26469;&#22686;&#24378;&#22810;&#26679;&#24615;&#20197;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#38598;&#25104; (DE) &#36890;&#36807;&#23427;&#20204;&#30340;&#21151;&#33021;&#22810;&#26679;&#24615;&#22312;&#20934;&#30830;&#24615;&#12289;&#26657;&#20934;&#24615;&#21644;&#25269;&#25239;&#24178;&#25200;&#26041;&#38754;&#34920;&#29616;&#20986;&#27604;&#21333;&#20010;&#31070;&#32463;&#32593;&#32476;&#26356;&#22909;&#30340;&#34920;&#29616;&#12290;&#22522;&#20110;&#31890;&#23376;&#30340;&#21464;&#20998;&#25512;&#26029; (ParVI) &#26041;&#27861;&#36890;&#36807;&#22522;&#20110;&#32593;&#32476;&#30456;&#20284;&#24615;&#20869;&#26680;&#30340;&#25490;&#26021;&#39033;&#26469;&#22686;&#24378;&#22810;&#26679;&#24615;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#36807;&#24230;&#21442;&#25968;&#21270;&#65292;&#26435;&#37325;&#31354;&#38388;&#25490;&#26021;&#26159;&#20302;&#25928;&#30340;&#65292;&#32780;&#30452;&#25509;&#21151;&#33021;&#31354;&#38388;&#25490;&#26021;&#34987;&#21457;&#29616;&#23545; DE &#30340;&#25913;&#36827;&#24456;&#23567;&#12290;&#20026;&#20102;&#36991;&#20813;&#36825;&#20123;&#22256;&#38590;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110; ParVI &#30340;&#19968;&#38454;&#26021;&#21147;&#28145;&#24230;&#38598;&#25104; (FoRDE)&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#36755;&#20837;&#26799;&#24230;&#30340;&#38598;&#25104;&#23398;&#20064;&#26041;&#27861;&#12290;&#30001;&#20110;&#36755;&#20837;&#26799;&#24230;&#21807;&#19968;&#22320;&#30830;&#23450;&#20102;&#19968;&#20010;&#20989;&#25968;&#24182;&#19988;&#27604;&#26435;&#37325;&#23567;&#24471;&#22810;&#65292;&#25152;&#20197;&#36825;&#31181;&#26041;&#27861;&#20445;&#35777;&#20102;&#38598;&#21512;&#25104;&#21592;&#22312;&#21151;&#33021;&#19978;&#26159;&#19981;&#21516;&#30340;&#12290;&#30452;&#35266;&#22320;&#35828;&#65292;&#22810;&#26679;&#21270;&#36755;&#20837;&#26799;&#24230;&#40723;&#21169;&#27599;&#20010;&#32593;&#32476;&#23398;&#20064;&#19981;&#21516;&#30340;&#29305;&#24449;&#65292;&#36825;&#26377;&#26395;&#25913;&#21892;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Ensembles (DEs) demonstrate improved accuracy, calibration and robustness to perturbations over single neural networks partly due to their functional diversity. Particle-based variational inference (ParVI) methods enhance diversity by formalizing a repulsion term based on a network similarity kernel. However, weight-space repulsion is inefficient due to over-parameterization, while direct function-space repulsion has been found to produce little improvement over DEs. To sidestep these difficulties, we propose First-order Repulsive Deep Ensemble (FoRDE), an ensemble learning method based on ParVI, which performs repulsion in the space of first-order input gradients. As input gradients uniquely characterize a function up to translation and are much smaller in dimension than the weights, this method guarantees that ensemble members are functionally different. Intuitively, diversifying the input gradients encourages each network to learn different features, which is expected to improv
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#35299;&#20915;&#24191;&#20041;&#33258;&#30001;&#33021;&#65288;FE&#65289;&#30446;&#26631;&#30340;&#21512;&#25104;&#20027;&#21160;&#25512;&#29702;&#20195;&#29702;&#30340;&#21464;&#20998;&#20449;&#24687;&#26356;&#26032;&#21644;&#28040;&#24687;&#20256;&#36882;&#31639;&#27861;&#65292;&#36890;&#36807;&#23545;T&#24418;&#36855;&#23467;&#23548;&#33322;&#20219;&#21153;&#30340;&#27169;&#25311;&#27604;&#36739;&#65292;&#34920;&#26126;AIF&#21487;&#24341;&#36215;&#35748;&#30693;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2306.02733</link><description>&lt;p&gt;
&#23454;&#29616;&#21512;&#25104;&#20027;&#21160;&#25512;&#29702;&#20195;&#29702;&#65292;&#31532;&#20108;&#37096;&#20998;&#65306;&#21464;&#20998;&#20449;&#24687;&#26356;&#26032;
&lt;/p&gt;
&lt;p&gt;
Realising Synthetic Active Inference Agents, Part II: Variational Message Updates. (arXiv:2306.02733v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02733
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#35299;&#20915;&#24191;&#20041;&#33258;&#30001;&#33021;&#65288;FE&#65289;&#30446;&#26631;&#30340;&#21512;&#25104;&#20027;&#21160;&#25512;&#29702;&#20195;&#29702;&#30340;&#21464;&#20998;&#20449;&#24687;&#26356;&#26032;&#21644;&#28040;&#24687;&#20256;&#36882;&#31639;&#27861;&#65292;&#36890;&#36807;&#23545;T&#24418;&#36855;&#23467;&#23548;&#33322;&#20219;&#21153;&#30340;&#27169;&#25311;&#27604;&#36739;&#65292;&#34920;&#26126;AIF&#21487;&#24341;&#36215;&#35748;&#30693;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#30001;&#33021;&#21407;&#29702;&#65288;FEP&#65289;&#25551;&#36848;&#29983;&#29289;&#20195;&#29702;&#36890;&#36807;&#30456;&#24212;&#29615;&#22659;&#30340;&#29983;&#25104;&#27169;&#22411;&#26368;&#23567;&#21270;&#21464;&#20998;&#33258;&#30001;&#33021;&#65288;FE&#65289;&#12290;&#20027;&#21160;&#25512;&#29702;&#65288;AIF&#65289;&#26159;FEP&#30340;&#25512;&#35770;&#65292;&#25551;&#36848;&#20102;&#20195;&#29702;&#20154;&#36890;&#36807;&#26368;&#23567;&#21270;&#26399;&#26395;&#30340;FE&#30446;&#26631;&#26469;&#25506;&#32034;&#21644;&#21033;&#29992;&#20854;&#29615;&#22659;&#12290;&#22312;&#20004;&#31687;&#30456;&#20851;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#33258;&#30001;&#24418;&#24335;Forney-style&#22240;&#23376;&#22270;&#65288;FFG&#65289;&#19978;&#30340;&#28040;&#24687;&#20256;&#36882;&#65292;&#25551;&#36848;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#21512;&#25104;AIF&#20195;&#29702;&#30340;&#35748;&#30693;&#26041;&#27861;&#12290;&#26412;&#25991;&#65288;&#31532;&#20108;&#37096;&#20998;&#65289;&#26681;&#25454;&#21464;&#20998;&#28436;&#31639;&#27861;&#65292;&#23548;&#20986;&#20102;&#26368;&#23567;&#21270;CFFG&#19978;&#65288;&#24191;&#20041;&#65289;FE&#30446;&#26631;&#30340;&#28040;&#24687;&#20256;&#36882;&#31639;&#27861;&#12290;&#27604;&#36739;&#20102;&#27169;&#25311;Bethe&#21644;&#24191;&#20041;FE&#20195;&#29702;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#35828;&#26126;&#20102;&#21512;&#25104;AIF&#22914;&#20309;&#22312;T&#24418;&#36855;&#23467;&#23548;&#33322;&#20219;&#21153;&#19978;&#24341;&#36215;&#35748;&#30693;&#34892;&#20026;&#12290;&#36890;&#36807;&#23545;&#21512;&#25104;AIF&#20195;&#29702;&#30340;&#23436;&#25972;&#28040;&#24687;&#20256;&#36882;&#25551;&#36848;&#65292;&#21487;&#20197;&#25512;&#23548;&#21644;&#37325;&#29992;&#35813;&#20195;&#29702;&#22312;&#19981;&#21516;&#29615;&#22659;&#19979;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Free Energy Principle (FEP) describes (biological) agents as minimising a variational Free Energy (FE) with respect to a generative model of their environment. Active Inference (AIF) is a corollary of the FEP that describes how agents explore and exploit their environment by minimising an expected FE objective. In two related papers, we describe a scalable, epistemic approach to synthetic AIF agents, by message passing on free-form Forney-style Factor Graphs (FFGs). A companion paper (part I) introduces a Constrained FFG (CFFG) notation that visually represents (generalised) FE objectives for AIF. The current paper (part II) derives message passing algorithms that minimise (generalised) FE objectives on a CFFG by variational calculus. A comparison between simulated Bethe and generalised FE agents illustrates how synthetic AIF induces epistemic behaviour on a T-maze navigation task. With a full message passing account of synthetic AIF agents, it becomes possible to derive and reuse 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#21327;&#21464;&#37327;&#20013;&#23384;&#22312;&#32570;&#22833;&#20540;&#30340;&#19968;&#33268;&#24615;&#39044;&#27979;&#65292;&#25552;&#20986;&#20102;&#32570;&#22833;&#25968;&#25454;&#25193;&#20805;&#30340;&#24191;&#20041;&#19968;&#33268;&#21270;&#20998;&#20301;&#25968;&#22238;&#24402;&#26694;&#26550;&#65292;&#21487;&#20197;&#24471;&#20986;&#26465;&#20214;&#20110;&#32570;&#22833;&#20540;&#27169;&#24335;&#30340;&#26377;&#25928;&#39044;&#27979;&#38388;&#38548;&#12290;</title><link>http://arxiv.org/abs/2306.02732</link><description>&lt;p&gt;
&#32570;&#22833;&#20540;&#19979;&#30340;&#19968;&#33268;&#24615;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Conformal Prediction with Missing Values. (arXiv:2306.02732v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02732
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#21327;&#21464;&#37327;&#20013;&#23384;&#22312;&#32570;&#22833;&#20540;&#30340;&#19968;&#33268;&#24615;&#39044;&#27979;&#65292;&#25552;&#20986;&#20102;&#32570;&#22833;&#25968;&#25454;&#25193;&#20805;&#30340;&#24191;&#20041;&#19968;&#33268;&#21270;&#20998;&#20301;&#25968;&#22238;&#24402;&#26694;&#26550;&#65292;&#21487;&#20197;&#24471;&#20986;&#26465;&#20214;&#20110;&#32570;&#22833;&#20540;&#27169;&#24335;&#30340;&#26377;&#25928;&#39044;&#27979;&#38388;&#38548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#33268;&#24615;&#39044;&#27979;&#26159;&#19968;&#31181;&#26500;&#24314;&#39044;&#27979;&#38388;&#38548;&#30340;&#29702;&#35770;&#22522;&#30784;&#26694;&#26550;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#21327;&#21464;&#37327;&#20013;&#23384;&#22312;&#32570;&#22833;&#20540;&#30340;&#19968;&#33268;&#24615;&#39044;&#27979;&#65292;&#36825;&#31181;&#24773;&#20917;&#32473;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#23545;&#20110;&#20219;&#20309;&#32570;&#22833;&#25968;&#25454;&#20998;&#24067;&#21644;&#20960;&#20046;&#25152;&#26377;&#30340;&#25554;&#34917;&#20989;&#25968;&#65292;&#19968;&#33268;&#24615;&#39044;&#27979;&#30340;&#36793;&#32536;&#35206;&#30422;&#20445;&#35777;&#22312;&#25554;&#34917;&#25968;&#25454;&#19978;&#25104;&#31435;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#24378;&#35843;&#24179;&#22343;&#35206;&#30422;&#24230;&#21462;&#20915;&#20110;&#32570;&#22833;&#20540;&#30340;&#27169;&#24335;&#65306;&#22312;&#26576;&#20123;&#32570;&#22833;&#27169;&#24335;&#19979;&#65292;&#19968;&#33268;&#24615;&#26041;&#27861;&#20542;&#21521;&#20110;&#26500;&#24314;&#20302;&#20272;&#21709;&#24212;&#30340;&#39044;&#27979;&#38388;&#38548;&#12290;&#36825;&#28608;&#21457;&#20102;&#25105;&#20204;&#30340;&#26032;&#22411;&#24191;&#20041;&#19968;&#33268;&#21270;&#20998;&#20301;&#25968;&#22238;&#24402;&#26694;&#26550;&#65292;&#32570;&#22833;&#25968;&#25454;&#25193;&#20805;&#65292;&#23427;&#21487;&#20197;&#24471;&#20986;&#26465;&#20214;&#20110;&#32570;&#22833;&#20540;&#27169;&#24335;&#30340;&#26377;&#25928;&#39044;&#27979;&#38388;&#38548;&#65292;&#23613;&#31649;&#23384;&#22312;&#25351;&#25968;&#25968;&#37327;&#30340;&#32570;&#22833;&#27169;&#24335;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#25554;&#34917;&#25968;&#25454;&#19978;&#35757;&#32451;&#30340;&#26222;&#36941;&#19968;&#33268;&#20998;&#20301;&#25968;&#22238;&#24402;&#31639;&#27861;&#26159;&#26399;&#26395;&#25439;&#22833;&#26368;&#23567;&#30340;&#26368;&#20248;&#36125;&#21494;&#26031;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conformal prediction is a theoretically grounded framework for constructing predictive intervals. We study conformal prediction with missing values in the covariates -- a setting that brings new challenges to uncertainty quantification. We first show that the marginal coverage guarantee of conformal prediction holds on imputed data for any missingness distribution and almost all imputation functions. However, we emphasize that the average coverage varies depending on the pattern of missing values: conformal methods tend to construct prediction intervals that under-cover the response conditionally to some missing patterns. This motivates our novel generalized conformalized quantile regression framework, missing data augmentation, which yields prediction intervals that are valid conditionally to the patterns of missing values, despite their exponential number. We then show that a universally consistent quantile regression algorithm trained on the imputed data is Bayes optimal for the pin
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28155;&#21152;&#22122;&#22768;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;Gibbs&#37319;&#26679;&#22120;&#20174;&#21518;&#39564;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#35813;&#26041;&#27861;&#22312;&#30495;&#23454;&#25968;&#25454;&#21644;&#21512;&#25104;&#25968;&#25454;&#20013;&#33021;&#22815;&#36798;&#21040;&#31867;&#20284;&#20110;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.02729</link><description>&lt;p&gt;
Gibbs&#37319;&#26679;&#31070;&#32463;&#32593;&#32476;&#30340;&#21518;&#39564;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Gibbs Sampling the Posterior of Neural Networks. (arXiv:2306.02729v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02729
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28155;&#21152;&#22122;&#22768;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;Gibbs&#37319;&#26679;&#22120;&#20174;&#21518;&#39564;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#35813;&#26041;&#27861;&#22312;&#30495;&#23454;&#25968;&#25454;&#21644;&#21512;&#25104;&#25968;&#25454;&#20013;&#33021;&#22815;&#36798;&#21040;&#31867;&#20284;&#20110;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#31070;&#32463;&#32593;&#32476;&#30340;&#21518;&#39564;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;&#32593;&#32476;&#30340;&#27599;&#20010;&#39044;&#28608;&#27963;&#21644;&#21518;&#28608;&#27963;&#20013;&#28155;&#21152;&#22122;&#22768;&#65292;&#24182;&#35748;&#20026;&#20351;&#29992;&#26377;&#25928;&#30340;Gibbs&#37319;&#26679;&#22120;&#21487;&#20197;&#37319;&#26679;&#24471;&#21040;&#25152;&#24471;&#21040;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#22312;&#30495;&#23454;&#25968;&#25454;&#21644;&#21512;&#25104;&#25968;&#25454;&#19978;&#65292;Gibbs&#37319;&#26679;&#22120;&#33021;&#22815;&#36798;&#21040;&#31867;&#20284;&#20110;&#29366;&#24577;-of-the-art&#30340;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#65288;&#22914;&#21704;&#23494;&#39039;&#33945;&#29305;&#21345;&#27931;&#25110;Metropolis&#35843;&#25972;Langevin&#31639;&#27861;&#65289;&#30340;&#24615;&#33021;&#12290;&#36890;&#36807;&#22312;&#24072;&#29983;&#35774;&#32622;&#20013;&#36827;&#34892;&#20998;&#26512;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#28909;&#21270;&#20934;&#21017;&#65292;&#35813;&#20934;&#21017;&#20801;&#35768;&#25105;&#20204;&#26816;&#27979;&#31639;&#27861;&#22312;&#20351;&#29992;&#21512;&#25104;&#26631;&#31614;&#30340;&#25968;&#25454;&#19978;&#36816;&#34892;&#26102;&#26159;&#21542;&#26080;&#27861;&#20174;&#21518;&#39564;&#20998;&#24067;&#20013;&#37319;&#26679;&#12290;&#35813;&#20934;&#21017;&#22522;&#20110;&#24072;&#29983;&#35774;&#32622;&#20013;&#30340;&#20107;&#23454;&#65292;&#25105;&#20204;&#21487;&#20197;&#30452;&#25509;&#22312;&#24179;&#34913;&#28857;&#22788;&#21021;&#22987;&#21270;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study sampling from a posterior derived from a neural network. We propose a new probabilistic model consisting of adding noise at every pre- and post-activation in the network, arguing that the resulting posterior can be sampled using an efficient Gibbs sampler. The Gibbs sampler attains similar performances as the state-of-the-art Monte Carlo Markov chain methods, such as the Hamiltonian Monte Carlo or the Metropolis adjusted Langevin algorithm, both on real and synthetic data. By framing our analysis in the teacher-student setting, we introduce a thermalization criterion that allows us to detect when an algorithm, when run on data with synthetic labels, fails to sample from the posterior. The criterion is based on the fact that in the teacher-student setting we can initialize an algorithm directly at equilibrium.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#27604;&#36739;&#20102;&#19981;&#21516;&#31867;&#22411;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#22312;&#28082;&#21387;&#29366;&#24577;&#30417;&#27979;&#31995;&#32479;&#20013;&#29992;&#20110;&#24322;&#24120;&#26816;&#27979;&#12290;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#34920;&#29616;&#26368;&#22909;&#65292;&#32780;&#38598;&#25104;&#27169;&#22411;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#26816;&#27979;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.02709</link><description>&lt;p&gt;
&#29992;&#20110;&#28082;&#21387;&#29366;&#24577;&#30417;&#27979;&#31995;&#32479;&#24322;&#24120;&#26816;&#27979;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#27604;&#36739;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Comparative Study on Semi-supervised Learning Applied for Anomaly Detection in Hydraulic Condition Monitoring System. (arXiv:2306.02709v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02709
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#27604;&#36739;&#20102;&#19981;&#21516;&#31867;&#22411;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#22312;&#28082;&#21387;&#29366;&#24577;&#30417;&#27979;&#31995;&#32479;&#20013;&#29992;&#20110;&#24322;&#24120;&#26816;&#27979;&#12290;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#34920;&#29616;&#26368;&#22909;&#65292;&#32780;&#38598;&#25104;&#27169;&#22411;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#26816;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#29366;&#24577;&#30340;&#32500;&#25252;&#22312;&#28082;&#21387;&#31995;&#32479;&#20013;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31995;&#32479;&#30340;&#24322;&#24120;&#26816;&#27979;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#29305;&#21035;&#26159;&#30001;&#20110;&#24322;&#24120;&#25968;&#25454;&#24456;&#23569;&#65292;&#26631;&#35760;&#36825;&#20123;&#25968;&#25454;&#26159;&#36153;&#26102;&#36153;&#21147;&#29978;&#33267;&#21361;&#38505;&#30340;&#12290;&#22240;&#27492;&#65292;&#24314;&#35758;&#20351;&#29992;&#26080;&#30417;&#30563;&#25110;&#21322;&#30417;&#30563;&#26041;&#27861;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#21482;&#26377;&#23569;&#37327;&#26631;&#31614;&#21487;&#29992;&#30340;&#24773;&#20917;&#19979;&#21033;&#29992;&#26080;&#30417;&#30563;&#23398;&#20064;&#20316;&#20026;&#29305;&#24449;&#25552;&#21462;&#26426;&#21046;&#26469;&#36741;&#21161;&#30417;&#30563;&#23398;&#20064;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#12290;&#26412;&#30740;&#31350;&#31995;&#32479;&#22320;&#27604;&#36739;&#20102;&#22312;&#28082;&#21387;&#29366;&#24577;&#30417;&#27979;&#31995;&#32479;&#20013;&#24212;&#29992;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#29992;&#20110;&#24322;&#24120;&#26816;&#27979;&#12290;&#39318;&#20808;&#65292;&#36827;&#34892;&#20102;&#28145;&#20837;&#30340;&#25968;&#25454;&#20998;&#26512;&#21644;&#29305;&#24449;&#23398;&#20064;&#65292;&#20197;&#20102;&#35299;&#24320;&#28304;&#30340;&#28082;&#21387;&#29366;&#24577;&#30417;&#27979;&#25968;&#25454;&#38598;&#12290;&#28982;&#21518;&#65292;&#23454;&#26045;&#21644;&#35780;&#20272;&#20102;&#21508;&#31181;&#26041;&#27861;&#65292;&#21253;&#25324;&#20256;&#32479;&#30340;&#29420;&#31435;&#21322;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#65288;&#20363;&#22914;&#65292;&#19968;&#31867;&#25903;&#25345;&#21521;&#37327;&#26426;&#12289;&#40065;&#26834;&#21327;&#26041;&#24046;&#65289;&#12289;&#38598;&#25104;&#27169;&#22411;&#65288;&#20363;&#22914;&#65292;&#23396;&#31435;&#26862;&#26519;&#65289;&#21644;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#27169;&#22411;&#65288;&#20363;&#22914;&#65292;&#33258;&#21160;&#32534;&#30721;&#22120;&#12289;&#22270;&#21367;&#31215;&#32593;&#32476;&#65289;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20248;&#20110;&#20256;&#32479;&#27169;&#22411;&#65292;&#32780;&#38598;&#25104;&#27169;&#22411;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#26816;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Condition-based maintenance is becoming increasingly important in hydraulic systems. However, anomaly detection for these systems remains challenging, especially since that anomalous data is scarce and labeling such data is tedious and even dangerous. Therefore, it is advisable to make use of unsupervised or semi-supervised methods, especially for semi-supervised learning which utilizes unsupervised learning as a feature extraction mechanism to aid the supervised part when only a small number of labels are available. This study systematically compares semi-supervised learning methods applied for anomaly detection in hydraulic condition monitoring systems. Firstly, thorough data analysis and feature learning were carried out to understand the open-sourced hydraulic condition monitoring dataset. Then, various methods were implemented and evaluated including traditional stand-alone semi-supervised learning models (e.g., one-class SVM, Robust Covariance), ensemble models (e.g., Isolation F
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;Equity-Transformer&#26469;&#35299;&#20915;&#22823;&#35268;&#27169;&#30340;&#26368;&#23567;&#26368;&#22823;&#36335;&#24452;&#38382;&#39064;&#12290;&#35813;&#27169;&#22411;&#21033;&#29992;&#21487;&#25193;&#23637;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#39034;&#24207;&#20915;&#31574;&#65292;&#24182;&#29983;&#25104;&#32771;&#34385;&#20844;&#24179;&#24037;&#20316;&#36127;&#36733;&#30340;&#39034;&#24207;&#21160;&#20316;&#12290;&#30740;&#31350;&#26174;&#31034;&#65292;Equity-Transformer&#22312;&#20004;&#20010;&#20195;&#34920;&#24615;&#26368;&#23567;&#26368;&#22823;&#36335;&#24452;&#38382;&#39064;&#20013;&#20855;&#26377;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.02689</link><description>&lt;p&gt;
&#23558;NP&#22256;&#38590;&#30340;&#26368;&#23567;&#26368;&#22823;&#36335;&#24452;&#38382;&#39064;&#20316;&#20026;&#20855;&#26377;&#20844;&#24179;&#32972;&#26223;&#30340;&#39034;&#24207;&#29983;&#25104;&#26469;&#35299;&#20915;
&lt;/p&gt;
&lt;p&gt;
Solving NP-hard Min-max Routing Problems as Sequential Generation with Equity Context. (arXiv:2306.02689v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02689
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;Equity-Transformer&#26469;&#35299;&#20915;&#22823;&#35268;&#27169;&#30340;&#26368;&#23567;&#26368;&#22823;&#36335;&#24452;&#38382;&#39064;&#12290;&#35813;&#27169;&#22411;&#21033;&#29992;&#21487;&#25193;&#23637;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#39034;&#24207;&#20915;&#31574;&#65292;&#24182;&#29983;&#25104;&#32771;&#34385;&#20844;&#24179;&#24037;&#20316;&#36127;&#36733;&#30340;&#39034;&#24207;&#21160;&#20316;&#12290;&#30740;&#31350;&#26174;&#31034;&#65292;Equity-Transformer&#22312;&#20004;&#20010;&#20195;&#34920;&#24615;&#26368;&#23567;&#26368;&#22823;&#36335;&#24452;&#38382;&#39064;&#20013;&#20855;&#26377;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#23567;&#26368;&#22823;&#36335;&#24452;&#38382;&#39064;&#26088;&#22312;&#26368;&#23567;&#21270;&#25152;&#26377;&#20195;&#29702;&#21830;&#21327;&#21516;&#35775;&#38382;&#25152;&#26377;&#22478;&#24066;&#30340;&#26368;&#22823;&#26053;&#28216;&#38271;&#24230;&#65292;&#21363;&#23436;&#25104;&#26102;&#38388;&#12290;&#36825;&#20123;&#38382;&#39064;&#21253;&#25324;&#26377;&#24433;&#21709;&#21147;&#30340;&#23454;&#38469;&#24212;&#29992;&#65292;&#20294;&#34987;&#35748;&#20026;&#26159;NP&#22256;&#38590;&#30340;&#12290;&#29616;&#26377;&#26041;&#27861;&#38754;&#20020;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#22312;&#38656;&#35201;&#21327;&#35843;&#20247;&#22810;&#20195;&#29702;&#21830;&#35206;&#30422;&#25968;&#21315;&#20010;&#22478;&#24066;&#30340;&#22823;&#35268;&#27169;&#38382;&#39064;&#20013;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#26469;&#35299;&#20915;&#22823;&#35268;&#27169;&#30340;&#26368;&#23567;&#26368;&#22823;&#36335;&#24452;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#22810;&#20010;&#20195;&#29702;&#21830;&#30340;&#21516;&#26102;&#20915;&#31574;&#24314;&#27169;&#20026;&#39034;&#24207;&#29983;&#25104;&#36807;&#31243;&#65292;&#20801;&#35768;&#21033;&#29992;&#21487;&#25193;&#23637;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#39034;&#24207;&#20915;&#31574;&#12290;&#22312;&#39034;&#24207;&#36817;&#20284;&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#19978;&#19979;&#25991;Transformer&#27169;&#22411;Equity-Transformer&#65292;&#23427;&#29983;&#25104;&#32771;&#34385;&#20854;&#20182;&#20195;&#29702;&#21830;&#20043;&#38388;&#20844;&#24179;&#24037;&#20316;&#36127;&#36733;&#30340;&#39034;&#24207;&#21160;&#20316;&#12290;Equity-Transformer&#30340;&#26377;&#25928;&#24615;&#36890;&#36807;&#20854;&#22312;&#20004;&#20010;&#20195;&#34920;&#24615;&#26368;&#23567;&#26368;&#22823;&#36335;&#24452;&#38382;&#39064;&#20013;&#20855;&#26377;&#21331;&#36234;&#30340;&#24615;&#33021;&#24471;&#21040;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Min-max routing problems aim to minimize the maximum tour length among agents as they collaboratively visit all cities, i.e., the completion time. These problems include impactful real-world applications but are known as NP-hard. Existing methods are facing challenges, particularly in large-scale problems that require the coordination of numerous agents to cover thousands of cities. This paper proposes a new deep-learning framework to solve large-scale min-max routing problems. We model the simultaneous decision-making of multiple agents as a sequential generation process, allowing the utilization of scalable deep-learning models for sequential decision-making. In the sequentially approximated problem, we propose a scalable contextual Transformer model, Equity-Transformer, which generates sequential actions considering an equitable workload among other agents. The effectiveness of Equity-Transformer is demonstrated through its superior performance in two representative min-max routing 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Meta-SAGE&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#32452;&#21512;&#20248;&#21270;&#20219;&#21153;&#20013;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#21487;&#25193;&#23637;&#24615;&#30340;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#27604;&#20363;&#20803;&#23398;&#20064;&#21644;&#26102;&#38388;&#34920;&#35843;&#25972;&#26469;&#36866;&#24212;&#27169;&#22411;&#65292;&#24182;&#30495;&#23454;&#22320;&#20248;&#21270;&#20102;&#30456;&#20851;&#20219;&#21153;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.02688</link><description>&lt;p&gt;
Meta-SAGE&#65306;&#29992;&#24341;&#23548;&#25506;&#32034;&#30340;&#35268;&#21010;&#26041;&#27861;&#21644;&#27604;&#20363;&#19968;&#20803;&#23398;&#20064;&#36827;&#34892;&#21327;&#21516;&#20248;&#21270;&#35268;&#27169;&#20559;&#31227;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Meta-SAGE: Scale Meta-Learning Scheduled Adaptation with Guided Exploration for Mitigating Scale Shift on Combinatorial Optimization. (arXiv:2306.02688v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02688
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Meta-SAGE&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#32452;&#21512;&#20248;&#21270;&#20219;&#21153;&#20013;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#21487;&#25193;&#23637;&#24615;&#30340;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#27604;&#20363;&#20803;&#23398;&#20064;&#21644;&#26102;&#38388;&#34920;&#35843;&#25972;&#26469;&#36866;&#24212;&#27169;&#22411;&#65292;&#24182;&#30495;&#23454;&#22320;&#20248;&#21270;&#20102;&#30456;&#20851;&#20219;&#21153;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20043;&#20026;Meta-SAGE&#30340;&#26032;&#26041;&#27861;&#65292;&#26088;&#22312;&#25913;&#21892;&#32452;&#21512;&#20248;&#21270;&#65288;CO&#65289;&#20219;&#21153;&#30340;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;&#26412;&#26041;&#27861;&#36890;&#36807;&#24314;&#35758;&#20004;&#20010;&#32452;&#20214;&#26469;&#22312;&#27979;&#35797;&#26102;&#38388;&#36866;&#24212;&#39044;&#35757;&#32451;&#27169;&#22411;&#20197;&#35299;&#20915;&#35268;&#27169;&#38382;&#39064;&#65306;&#19968;&#20010;&#26159;&#27604;&#20363;&#20803;&#23398;&#20064;&#22120;&#65288;SML&#65289;&#65292;&#21478;&#19968;&#20010;&#26159;&#20855;&#26377;&#24341;&#23548;&#25506;&#32034;&#21644;&#26102;&#38388;&#34920;&#35843;&#25972;&#21151;&#33021;&#30340;scheduled adaptation with guided exploration&#65288;SAGE&#65289;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;Meta-SAGE&#20248;&#20110;&#20197;&#21069;&#30340;&#36866;&#24212;&#26041;&#27861;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#20102;&#20195;&#34920;&#24615;CO&#20219;&#21153;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes Meta-SAGE, a novel approach for improving the scalability of deep reinforcement learning models for combinatorial optimization (CO) tasks. Our method adapts pre-trained models to larger-scale problems in test time by suggesting two components: a scale meta-learner (SML) and scheduled adaptation with guided exploration (SAGE). First, SML transforms the context embedding for subsequent adaptation of SAGE based on scale information. Then, SAGE adjusts the model parameters dedicated to the context embedding for a specific instance. SAGE introduces locality bias, which encourages selecting nearby locations to determine the next location. The locality bias gradually decays as the model is adapted to the target instance. Results show that Meta-SAGE outperforms previous adaptation methods and significantly improves scalability in representative CO tasks. Our source code is available at https://github.com/kaist-silab/meta-sage
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#24182;&#34892;&#35780;&#20998;&#21305;&#37197;&#30340;&#25193;&#25955;&#27169;&#22411;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#19981;&#21516;&#26102;&#38388;&#28857;&#30340;&#20219;&#21153;&#29420;&#31435;&#24615;&#65292;&#37319;&#29992;&#29420;&#31435;&#32593;&#32476;&#24314;&#27169;&#20998;&#25968;&#28436;&#21464;&#65292;&#25552;&#39640;&#20102;&#23494;&#24230;&#20272;&#35745;&#24615;&#33021;&#65292;&#21152;&#36895;&#20102;&#35757;&#32451;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2306.02658</link><description>&lt;p&gt;
&#22522;&#20110;&#24182;&#34892;&#35780;&#20998;&#21305;&#37197;&#30340;&#25193;&#25955;&#27169;&#22411;&#26356;&#24555;&#30340;&#35757;&#32451;&#21644;&#25913;&#36827;&#23494;&#24230;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Faster Training of Diffusion Models and Improved Density Estimation via Parallel Score Matching. (arXiv:2306.02658v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02658
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#24182;&#34892;&#35780;&#20998;&#21305;&#37197;&#30340;&#25193;&#25955;&#27169;&#22411;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#19981;&#21516;&#26102;&#38388;&#28857;&#30340;&#20219;&#21153;&#29420;&#31435;&#24615;&#65292;&#37319;&#29992;&#29420;&#31435;&#32593;&#32476;&#24314;&#27169;&#20998;&#25968;&#28436;&#21464;&#65292;&#25552;&#39640;&#20102;&#23494;&#24230;&#20272;&#35745;&#24615;&#33021;&#65292;&#21152;&#36895;&#20102;&#35757;&#32451;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;(DPMs)&#20013;&#65292;&#21333;&#20010;&#26102;&#38388;&#20381;&#36182;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#35780;&#20998;&#28436;&#21464;&#30340;&#20219;&#21153;&#38656;&#35201;&#38271;&#26102;&#38388;&#30340;&#35757;&#32451;&#65292;&#21487;&#33021;&#20250;&#38459;&#30861;&#24314;&#27169;&#30340;&#28789;&#27963;&#24615;&#21644;&#33021;&#21147;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#21033;&#29992; DPMs &#22266;&#26377;&#30340;&#19981;&#21516;&#26102;&#38388;&#28857;&#23398;&#20064;&#20219;&#21153;&#30340;&#29420;&#31435;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#29420;&#31435;&#30340;&#32593;&#32476;&#23558;&#23398;&#20064;&#20219;&#21153;&#36827;&#34892;&#21010;&#20998;&#65292;&#27599;&#20010;&#32593;&#32476;&#19987;&#38376;&#23398;&#20064;&#29305;&#23450;&#26102;&#38388;&#23376;&#38388;&#38548;&#20869;&#30340;&#20998;&#25968;&#28436;&#21464;&#12290;&#21463;&#27531;&#24046;&#27969;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#23558;&#27492;&#31574;&#30053;&#25193;&#23637;&#21040;&#20854;&#36923;&#36753;&#32467;&#35770;&#65292;&#37319;&#29992;&#21333;&#29420;&#30340;&#32593;&#32476;&#29420;&#31435;&#24314;&#27169;&#27599;&#20010;&#26102;&#38388;&#28857;&#30340;&#20998;&#25968;&#12290;&#36890;&#36807;&#23545;&#21512;&#25104;&#21644;&#22270;&#20687;&#25968;&#25454;&#38598;&#30340;&#23454;&#35777;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#20165;&#36890;&#36807;&#22312;&#25968;&#25454;&#24182;&#34892;&#21270;&#20043;&#19978;&#24341;&#20837;&#39069;&#22806;&#30340;&#24182;&#34892;&#21270;&#23618;&#26174;&#33879;&#21152;&#36895;&#20102;&#35757;&#32451;&#36807;&#31243;&#65292;&#32780;&#19988;&#22312;&#19982;&#29616;&#26377;&#26041;&#27861;&#27604;&#36739;&#26102;&#65292;&#25552;&#39640;&#20102;&#23494;&#24230;&#20272;&#35745;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In Diffusion Probabilistic Models (DPMs), the task of modeling the score evolution via a single time-dependent neural network necessitates extended training periods and may potentially impede modeling flexibility and capacity. To counteract these challenges, we propose leveraging the independence of learning tasks at different time points inherent to DPMs. More specifically, we partition the learning task by utilizing independent networks, each dedicated to learning the evolution of scores within a specific time sub-interval. Further, inspired by residual flows, we extend this strategy to its logical conclusion by employing separate networks to independently model the score at each individual time point. As empirically demonstrated on synthetic and image datasets, our approach not only significantly accelerates the training process by introducing an additional layer of parallelization atop data parallelization, but it also enhances density estimation performance when compared to the co
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;Early-Exit&#32593;&#32476;&#20013;&#23454;&#29616;&#26465;&#20214;&#21333;&#35843;&#24615;&#30340;&#26041;&#27861;&#65292;&#23558;&#28145;&#24230;&#27169;&#22411;&#36716;&#21270;&#20026;&#30495;&#27491;&#30340;&#38543;&#26102;&#20998;&#31867;&#22120;&#12290;</title><link>http://arxiv.org/abs/2306.02652</link><description>&lt;p&gt;
&#36890;&#36807;&#24378;&#21046;&#26465;&#20214;&#21333;&#35843;&#24615;&#22312;Early-Exit&#32467;&#26500;&#20013;&#23454;&#29616;&#38543;&#26102;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Towards Anytime Classification in Early-Exit Architectures by Enforcing Conditional Monotonicity. (arXiv:2306.02652v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02652
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;Early-Exit&#32593;&#32476;&#20013;&#23454;&#29616;&#26465;&#20214;&#21333;&#35843;&#24615;&#30340;&#26041;&#27861;&#65292;&#23558;&#28145;&#24230;&#27169;&#22411;&#36716;&#21270;&#20026;&#30495;&#27491;&#30340;&#38543;&#26102;&#20998;&#31867;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#39044;&#27979;&#27169;&#22411;&#36890;&#24120;&#37096;&#32626;&#22312;&#35745;&#31639;&#39044;&#31639;&#21160;&#24577;&#30340;&#29615;&#22659;&#20013;&#12290;&#38543;&#26102;&#31639;&#27861;&#38750;&#24120;&#36866;&#29992;&#20110;&#36825;&#31181;&#29615;&#22659;&#65292;&#22240;&#20026;&#23427;&#20204;&#22312;&#35745;&#31639;&#30340;&#20219;&#20309;&#26102;&#20505;&#37117;&#21487;&#20197;&#36755;&#20986;&#39044;&#27979;&#20540;&#65292;&#20854;&#36136;&#37327;&#26159;&#35745;&#31639;&#26102;&#38388;&#30340;&#20989;&#25968;&#12290;&#30001;&#20110;&#20854;&#33021;&#22815;&#22312;&#32593;&#32476;&#21508;&#20010;&#38454;&#27573;&#25552;&#20379;&#20013;&#38388;&#39044;&#27979;&#32467;&#26524;&#30340;&#33021;&#21147;&#65292;Early-Exit&#31070;&#32463;&#32593;&#32476;&#22312;&#38543;&#26102;&#35745;&#31639;&#30340;&#32972;&#26223;&#19979;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35777;&#26126;&#24403;&#21069;&#30340;Early-Exit&#32593;&#32476;&#24182;&#19981;&#30452;&#25509;&#36866;&#29992;&#20110;&#20219;&#20309;&#26102;&#20505;&#30340;&#35774;&#32622;&#65292;&#22240;&#20026;&#21333;&#20010;&#25968;&#25454;&#28857;&#30340;&#39044;&#27979;&#36136;&#37327;&#19981;&#33021;&#20445;&#35777;&#38543;&#30528;&#35745;&#31639;&#26102;&#38388;&#30340;&#22686;&#21152;&#32780;&#25552;&#39640;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#32570;&#38519;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20248;&#38597;&#30340;&#20107;&#21518;&#20462;&#25913;&#65292;&#22522;&#20110;&#19987;&#23478;&#20056;&#31215;&#65292;&#40723;&#21169;Early-Exit&#32593;&#32476;&#36880;&#28176;&#21464;&#24471;&#33258;&#20449;&#12290;&#36825;&#36171;&#20104;&#20102;&#25105;&#20204;&#30340;&#28145;&#24230;&#27169;&#22411;&#26465;&#20214;&#21333;&#35843;&#24615;&#30340;&#29305;&#24615;&#8212;&#8212;&#36825;&#26159;&#23454;&#29616;&#30495;&#27491;&#38543;&#26102;&#20998;&#31867;&#30340;&#37325;&#35201;&#22522;&#30707;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern predictive models are often deployed to environments in which computational budgets are dynamic. Anytime algorithms are well-suited to such environments as, at any point during computation, they can output a prediction whose quality is a function of computation time. Early-exit neural networks have garnered attention in the context of anytime computation due to their capability to provide intermediate predictions at various stages throughout the network. However, we demonstrate that current early-exit networks are not directly applicable to anytime settings, as the quality of predictions for individual data points is not guaranteed to improve with longer computation. To address this shortcoming, we propose an elegant post-hoc modification, based on the Product-of-Experts, that encourages an early-exit network to become gradually confident. This gives our deep models the property of conditional monotonicity in the prediction quality -- an essential stepping stone towards truly an
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21327;&#26041;&#24046;&#33258;&#36866;&#24212;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#30456;&#36739;&#20110;&#29420;&#31435;&#33218;&#20998;&#24067;&#20551;&#35774;&#19979;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#33021;&#26356;&#26377;&#25928;&#22320;&#35782;&#21035;&#20986;&#39640;&#24179;&#22343;&#22870;&#21169;&#30340;&#33218;&#65292;&#36866;&#29992;&#20110;&#20020;&#24202;&#35797;&#39564;&#31561;&#22330;&#26223;&#12290;</title><link>http://arxiv.org/abs/2306.02630</link><description>&lt;p&gt;
&#21327;&#26041;&#24046;&#33258;&#36866;&#24212;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Covariance Adaptive Best Arm Identification. (arXiv:2306.02630v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02630
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21327;&#26041;&#24046;&#33258;&#36866;&#24212;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#30456;&#36739;&#20110;&#29420;&#31435;&#33218;&#20998;&#24067;&#20551;&#35774;&#19979;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#33021;&#26356;&#26377;&#25928;&#22320;&#35782;&#21035;&#20986;&#39640;&#24179;&#22343;&#22870;&#21169;&#30340;&#33218;&#65292;&#36866;&#29992;&#20110;&#20020;&#24202;&#35797;&#39564;&#31561;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22810;&#33218;&#32769;&#34382;&#26426;&#27169;&#22411;&#19979;&#65292;&#22522;&#20110;&#22266;&#23450;&#32622;&#20449;&#24230;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#22312;&#32473;&#23450;&#32622;&#20449;&#24230; $\delta$ &#30340;&#24773;&#20917;&#19979;&#65292;&#26088;&#22312;&#20197;&#33267;&#23569; 1 - $\delta$ &#30340;&#27010;&#29575;&#35782;&#21035;&#20986;&#20855;&#26377;&#26368;&#39640;&#24179;&#22343;&#22870;&#21169;&#30340;&#33218;&#65292;&#21516;&#26102;&#26368;&#23567;&#21270;&#33218;&#30340;&#25289;&#21160;&#27425;&#25968;&#12290;&#34429;&#28982;&#25991;&#29486;&#25552;&#20379;&#20102;&#38024;&#23545;&#29420;&#31435;&#33218;&#20998;&#24067;&#20551;&#35774;&#19979;&#35813;&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26356;&#21152;&#28789;&#27963;&#30340;&#24773;&#24418;&#65292;&#20854;&#20013;&#33218;&#21487;&#20197;&#26159;&#30456;&#20851;&#30340;&#65292;&#24182;&#19988;&#25910;&#30410;&#21487;&#20197;&#21516;&#26102;&#36827;&#34892;&#37319;&#26679;&#12290;&#35813;&#26694;&#26550;&#20801;&#35768;&#23398;&#20064;&#32773;&#20272;&#35745;&#33218;&#20043;&#38388;&#20998;&#24067;&#30340;&#21327;&#26041;&#24046;&#65292;&#20174;&#32780;&#26356;&#26377;&#25928;&#22320;&#35782;&#21035;&#26368;&#20339;&#33218;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#36866;&#24212;&#33218;&#21327;&#26041;&#24046;&#30340;&#26032;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#20445;&#35777;&#35777;&#26126;&#20854;&#20855;&#26377;&#23454;&#36136;&#24615;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of best arm identification in the multi-armed bandit model, under fixed confidence. Given a confidence input $\delta$, the goal is to identify the arm with the highest mean reward with a probability of at least 1 -- $\delta$, while minimizing the number of arm pulls. While the literature provides solutions to this problem under the assumption of independent arms distributions, we propose a more flexible scenario where arms can be dependent and rewards can be sampled simultaneously. This framework allows the learner to estimate the covariance among the arms distributions, enabling a more efficient identification of the best arm. The relaxed setting we propose is relevant in various applications, such as clinical trials, where similarities between patients or drugs suggest underlying correlations in the outcomes. We introduce new algorithms that adapt to the unknown covariance of the arms and demonstrate through theoretical guarantees that substantial improvement 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#22810;&#20010;&#20219;&#21153;&#34920;&#29616;&#30340;&#19987;&#23478;&#31215;&#26497;&#25490;&#21517;&#38382;&#39064;&#21450;&#22788;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#21333;&#35843;&#24615;&#20551;&#35774;&#21450;&#25991;&#31456;&#25552;&#20379;&#30340;&#31574;&#30053;&#22312;&#20445;&#35777;&#32622;&#20449;&#24230;&#30340;&#24773;&#20917;&#19979;&#65292;&#23454;&#29616;&#20102;&#19987;&#23478;&#27491;&#30830;&#25490;&#21517;&#65292;&#19988;&#35813;&#31574;&#30053;&#20855;&#26377;&#33258;&#36866;&#24212;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.02628</link><description>&lt;p&gt;
&#22522;&#20110;&#22810;&#20010;&#20219;&#21153;&#34920;&#29616;&#30340;&#19987;&#23478;&#31215;&#26497;&#25490;&#21517;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Active Ranking of Experts Based on their Performances in Many Tasks. (arXiv:2306.02628v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02628
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#22810;&#20010;&#20219;&#21153;&#34920;&#29616;&#30340;&#19987;&#23478;&#31215;&#26497;&#25490;&#21517;&#38382;&#39064;&#21450;&#22788;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#21333;&#35843;&#24615;&#20551;&#35774;&#21450;&#25991;&#31456;&#25552;&#20379;&#30340;&#31574;&#30053;&#22312;&#20445;&#35777;&#32622;&#20449;&#24230;&#30340;&#24773;&#20917;&#19979;&#65292;&#23454;&#29616;&#20102;&#19987;&#23478;&#27491;&#30830;&#25490;&#21517;&#65292;&#19988;&#35813;&#31574;&#30053;&#20855;&#26377;&#33258;&#36866;&#24212;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22522;&#20110;d&#20010;&#20219;&#21153;&#30340;n&#20010;&#19987;&#23478;&#30340;&#34920;&#29616;&#26469;&#25490;&#21517;&#19987;&#23478;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21333;&#35843;&#24615;&#20551;&#35774;&#65292;&#21363;&#23545;&#20110;&#27599;&#23545;&#19987;&#23478;&#65292;&#20854;&#20013;&#19968;&#20010;&#22312;&#25152;&#26377;&#20219;&#21153;&#19978;&#34920;&#29616;&#20248;&#20110;&#21478;&#19968;&#20010;&#12290;&#25105;&#20204;&#32771;&#34385;&#25353;&#39034;&#24207;&#36827;&#34892;&#30340;&#24773;&#20917;&#65292;&#22312;&#27599;&#19968;&#36718;&#20013;&#65292;&#23398;&#20064;&#32773;&#37117;&#21487;&#20197;&#35775;&#38382;&#26377;&#22122;&#22768;&#30340;&#35780;&#20272;&#65292;&#24182;&#36873;&#25321;&#19968;&#23545;&#19987;&#23478;&#20219;&#21153;&#65292;&#32473;&#20986;&#21040;&#23454;&#38469;&#36718;&#27425;&#20026;&#27490;&#21487;&#29992;&#30340;&#20449;&#24687;&#12290;&#32473;&#23450;&#32622;&#20449;&#24230;&#21442;&#25968;$\delta$ $\in$ (0,1)&#65292;&#25105;&#20204;&#25552;&#20379;&#31574;&#30053;&#65292;&#20801;&#35768;&#24674;&#22797;&#19987;&#23478;&#30340;&#27491;&#30830;&#25490;&#21517;&#65292;&#24182;&#24320;&#21457;&#20986;&#19968;&#20010;&#31639;&#27861;&#22312;&#27010;&#29575;&#33267;&#23569;&#20026;1-$\delta$&#19979;&#20445;&#25345;&#30340;&#26597;&#35810;&#24635;&#25968;&#19978;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#34920;&#26126;&#25105;&#20204;&#30340;&#31574;&#30053;&#23545;&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#26159;&#33258;&#36866;&#24212;&#30340;(&#25105;&#20204;&#30340;&#38480;&#21046;&#26159;&#23454;&#20363;&#30456;&#20851;&#30340;)&#65292;&#24182;&#24320;&#21457;&#20986;&#19982;&#29702;&#35770;&#19979;&#38480;&#30456;&#21305;&#37197;&#30340;&#32467;&#26524;(&#22810;&#23545;&#25968;&#30340;&#22240;&#23376;)&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#31574;&#30053;&#36866;&#24212;&#21040;&#26368;&#20339;&#19987;&#23478;&#35782;&#21035;&#30340;&#38382;&#39064;&#19978;&#65292;&#24182;&#25552;&#20379;&#19982;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#19968;&#33268;&#30340;&#25968;&#20540;&#27169;&#25311;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of ranking n experts based on their performances on d tasks. We make a monotonicity assumption stating that for each pair of experts, one outperforms the other on all tasks. We consider the sequential setting where in each round, the learner has access to noisy evaluations of actively chosen pair of expert-task, given the information available up to the actual round. Given a confidence parameter $\delta$ $\in$ (0, 1), we provide strategies allowing to recover the correct ranking of experts and develop a bound on the total number of queries made by our algorithm that hold with probability at least 1 -- $\delta$. We show that our strategy is adaptive to the complexity of the problem (our bounds are instance dependent), and develop matching lower bounds up to a poly-logarithmic factor. Finally, we adapt our strategy to the relaxed problem of best expert identification and provide numerical simulation consistent with our theoretical results.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#25554;&#20540;&#21306;&#22495;&#20869;&#30340;&#27491;&#21017;&#26465;&#20214;&#65292;&#23545;&#20110;&#36807;&#21442;&#25968;&#21270;&#38382;&#39064;&#37319;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#33021;&#22815;&#36798;&#21040;&#21644;&#30830;&#23450;&#24615;&#26799;&#24230;&#19979;&#38477;&#30456;&#21516;&#30340;&#26368;&#22351;&#24773;&#20917;&#22797;&#26434;&#24230;&#65292;&#24182;&#20855;&#26377;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.02601</link><description>&lt;p&gt;
&#26397;&#21521;&#26368;&#23567;&#21270;&#22120;&#65306;&#36807;&#21442;&#25968;&#21270;&#38382;&#39064;&#20013;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#24555;&#36895;&#25910;&#25947;
&lt;/p&gt;
&lt;p&gt;
Aiming towards the minimizers: fast convergence of SGD for overparametrized problems. (arXiv:2306.02601v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02601
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#25554;&#20540;&#21306;&#22495;&#20869;&#30340;&#27491;&#21017;&#26465;&#20214;&#65292;&#23545;&#20110;&#36807;&#21442;&#25968;&#21270;&#38382;&#39064;&#37319;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#33021;&#22815;&#36798;&#21040;&#21644;&#30830;&#23450;&#24615;&#26799;&#24230;&#19979;&#38477;&#30456;&#21516;&#30340;&#26368;&#22351;&#24773;&#20917;&#22797;&#26434;&#24230;&#65292;&#24182;&#20855;&#26377;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#33539;&#24335;&#65292;&#22914;&#28145;&#24230;&#23398;&#20064;&#65292;&#20986;&#29616;&#22312;&#25554;&#20540;&#21306;&#22495;&#20869;&#25110;&#25509;&#36817;&#25554;&#20540;&#21306;&#22495;&#65292;&#20854;&#20013;&#27169;&#22411;&#21442;&#25968;&#30340;&#25968;&#37327;&#36828;&#22823;&#20110;&#25968;&#25454;&#26679;&#26412;&#30340;&#25968;&#37327;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#25554;&#20540;&#21306;&#22495;&#20869;&#30340;&#19968;&#31181;&#27491;&#21017;&#26465;&#20214;&#65292;&#36171;&#20104;&#38543;&#26426;&#26799;&#24230;&#26041;&#27861;&#19982;&#30830;&#23450;&#24615;&#26799;&#24230;&#26041;&#27861;&#30456;&#21516;&#30340;&#26368;&#22351;&#36845;&#20195;&#22797;&#26434;&#24230;&#65292;&#32780;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#20165;&#20351;&#29992;&#21333;&#20010;&#25277;&#26679;&#30340;&#26799;&#24230;&#65288;&#25110;&#23567;&#25209;&#37327;&#65289;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#25152;&#26377;&#29616;&#26377;&#30340;&#20445;&#35777;&#37117;&#35201;&#27714;&#38543;&#26426;&#26799;&#24230;&#26041;&#27861;&#37319;&#21462;&#23567;&#27493;&#38271;&#65292;&#20174;&#32780;&#23548;&#33268;&#25910;&#25947;&#36895;&#29575;&#26126;&#26174;&#20943;&#24930;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#35757;&#32451;&#20855;&#26377;&#32447;&#24615;&#36755;&#20986;&#23618;&#30340;&#36275;&#22815;&#23485;&#30340;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#26102;&#65292;&#25105;&#20204;&#30340;&#26465;&#20214;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern machine learning paradigms, such as deep learning, occur in or close to the interpolation regime, wherein the number of model parameters is much larger than the number of data samples. In this work, we propose a regularity condition within the interpolation regime which endows the stochastic gradient method with the same worst-case iteration complexity as the deterministic gradient method, while using only a single sampled gradient (or a minibatch) in each iteration. In contrast, all existing guarantees require the stochastic gradient method to take small steps, thereby resulting in a much slower linear rate of convergence. Finally, we demonstrate that our condition holds when training sufficiently wide feedforward neural networks with a linear output layer.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#36890;&#36807;&#21033;&#29992;&#27169;&#22411;&#24211;&#20013;&#22810;&#26679;&#21270;&#30340;&#30693;&#35782;&#26469;&#25552;&#39640;&#39046;&#22495;&#27867;&#21270;&#33021;&#21147;&#30340;&#26041;&#27861;&#65292;&#24378;&#35843;&#35748;&#20026;&#24369;&#27169;&#22411;&#20013;&#25152;&#21253;&#21547;&#30340;&#30693;&#35782;&#20855;&#26377;&#20215;&#20540;&#12290;&#36890;&#36807;&#27604;&#36739;&#21508;&#31181;&#24050;&#39044;&#35757;&#32451;&#22909;&#30340;&#27169;&#22411;&#22312;&#19981;&#21516;&#39046;&#22495;&#19979;&#30340;&#34920;&#29616;&#65292;&#21051;&#30011;&#23427;&#20204;&#22312;&#32534;&#30721;&#34920;&#31034;&#19978;&#30340;&#22810;&#26679;&#24615;&#20559;&#31227;&#21644;&#30456;&#20851;&#24615;&#20559;&#31227;&#31561;&#29305;&#24449;&#20197;&#25552;&#39640;&#39046;&#22495;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2306.02595</link><description>&lt;p&gt;
&#25506;&#32034;&#21644;&#21033;&#29992;&#27169;&#22411;&#24211;&#20013;&#22810;&#26679;&#21270;&#30340;&#30693;&#35782;&#20197;&#23454;&#29616;&#39046;&#22495;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Explore and Exploit the Diverse Knowledge in Model Zoo for Domain Generalization. (arXiv:2306.02595v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02595
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#36890;&#36807;&#21033;&#29992;&#27169;&#22411;&#24211;&#20013;&#22810;&#26679;&#21270;&#30340;&#30693;&#35782;&#26469;&#25552;&#39640;&#39046;&#22495;&#27867;&#21270;&#33021;&#21147;&#30340;&#26041;&#27861;&#65292;&#24378;&#35843;&#35748;&#20026;&#24369;&#27169;&#22411;&#20013;&#25152;&#21253;&#21547;&#30340;&#30693;&#35782;&#20855;&#26377;&#20215;&#20540;&#12290;&#36890;&#36807;&#27604;&#36739;&#21508;&#31181;&#24050;&#39044;&#35757;&#32451;&#22909;&#30340;&#27169;&#22411;&#22312;&#19981;&#21516;&#39046;&#22495;&#19979;&#30340;&#34920;&#29616;&#65292;&#21051;&#30011;&#23427;&#20204;&#22312;&#32534;&#30721;&#34920;&#31034;&#19978;&#30340;&#22810;&#26679;&#24615;&#20559;&#31227;&#21644;&#30456;&#20851;&#24615;&#20559;&#31227;&#31561;&#29305;&#24449;&#20197;&#25552;&#39640;&#39046;&#22495;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#24191;&#27867;&#24212;&#29992;&#24050;&#32463;&#23548;&#33268;&#20102;&#22823;&#37327;&#20844;&#20849;&#21487;&#29992;&#27169;&#22411;&#30340;&#20986;&#29616;&#12290;&#26377;&#25928;&#22320;&#21033;&#29992;&#36825;&#20123;&#36164;&#28304;&#65292;&#20197;&#33719;&#24471;&#22312;&#19979;&#28216;&#20219;&#21153;&#20013;&#20855;&#26377;&#24378;&#38887;&#24615;&#30340;&#27169;&#22411;&#65292;&#24050;&#25104;&#20026;&#19968;&#20010;&#33267;&#20851;&#37325;&#35201;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#35782;&#21035;&#27169;&#22411;&#24211;&#20013;&#26368;&#24378;&#22823;&#30340;&#27169;&#22411;&#19978;&#65292;&#32780;&#24573;&#35270;&#20102;&#20854;&#20013;&#21253;&#21547;&#30340;&#22810;&#26679;&#30340;&#24402;&#32435;&#20559;&#24046;&#12290;&#26412;&#25991;&#35748;&#20026;&#24369;&#27169;&#22411;&#20013;&#25152;&#21253;&#21547;&#30340;&#30693;&#35782;&#20855;&#26377;&#20215;&#20540;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27169;&#22411;&#24211;&#20013;&#22810;&#26679;&#24615;&#20197;&#25552;&#39640;&#39046;&#22495;&#27867;&#21270;&#33021;&#21147;&#30340;&#26041;&#27861;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#36890;&#36807;&#23558;&#32534;&#30721;&#34920;&#31034;&#30340;&#21464;&#21270;&#21051;&#30011;&#20026;&#22810;&#20803;&#30340;&#8220;&#22810;&#26679;&#24615;&#20559;&#31227;&#8221;&#21644;&#8220;&#30456;&#20851;&#24615;&#20559;&#31227;&#8221;&#65292;&#26469;&#30740;&#31350;&#19981;&#21516;&#39046;&#22495;&#19979;&#30340;&#22810;&#31181;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
The proliferation of pretrained models, as a result of advancements in pretraining techniques, has led to the emergence of a vast zoo of publicly available models. Effectively utilizing these resources to obtain models with robust out-of-distribution generalization capabilities for downstream tasks has become a crucial area of research. Previous research has primarily focused on identifying the most powerful models within the model zoo, neglecting to fully leverage the diverse inductive biases contained within. This paper argues that the knowledge contained in weaker models is valuable and presents a method for leveraging the diversity within the model zoo to improve out-of-distribution generalization capabilities. Specifically, we investigate the behaviors of various pretrained models across different domains of downstream tasks by characterizing the variations in their encoded representations in terms of two dimensions: diversity shift and correlation shift. This characterization ena
&lt;/p&gt;</description></item><item><title>&#29992;&#33021;&#37327;&#27169;&#22411;&#21644;&#28508;&#21464;&#37327;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#23618;&#27425;&#32852;&#21512;&#23884;&#20837;&#39044;&#27979;&#26550;&#26500;&#65288;H-JEPA&#65289;&#65292;&#26159; Yann LeCun&#25552;&#20986;&#30340;&#23454;&#29616;&#26410;&#26469;&#33258;&#20027;&#26234;&#33021;&#30340;&#20851;&#38190;&#12290;</title><link>http://arxiv.org/abs/2306.02572</link><description>&lt;p&gt;
&#28508;&#21464;&#37327;&#33021;&#37327;&#27169;&#22411;&#31616;&#20171;&#65306;&#23454;&#29616;&#33258;&#20027;&#26426;&#22120;&#26234;&#33021;&#36335;&#24452;
&lt;/p&gt;
&lt;p&gt;
Introduction to Latent Variable Energy-Based Models: A Path Towards Autonomous Machine Intelligence. (arXiv:2306.02572v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02572
&lt;/p&gt;
&lt;p&gt;
&#29992;&#33021;&#37327;&#27169;&#22411;&#21644;&#28508;&#21464;&#37327;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#23618;&#27425;&#32852;&#21512;&#23884;&#20837;&#39044;&#27979;&#26550;&#26500;&#65288;H-JEPA&#65289;&#65292;&#26159; Yann LeCun&#25552;&#20986;&#30340;&#23454;&#29616;&#26410;&#26469;&#33258;&#20027;&#26234;&#33021;&#30340;&#20851;&#38190;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#33258;&#21160;&#21270;&#31995;&#32479;&#23384;&#22312;&#20851;&#38190;&#38480;&#21046;&#38656;&#35201;&#35299;&#20915;&#65292;&#25165;&#33021;&#36798;&#21040;&#20154;&#31867;&#27700;&#24179;&#30340;&#20154;&#24037;&#26234;&#33021;&#65292;&#24182;&#24341;&#39046;&#26032;&#30340;&#25216;&#26415;&#38761;&#21629;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#24635;&#32467;&#20102;Yann LeCun&#25552;&#20986;&#30340;&#38754;&#21521;&#26410;&#26469;&#33258;&#20027;&#26234;&#33021;&#26550;&#26500;&#30340;&#20027;&#35201;&#24605;&#24819;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#33021;&#37327;&#27169;&#22411;&#21644;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#24182;&#23558;&#23427;&#20204;&#30340;&#20248;&#28857;&#32467;&#21512;&#36215;&#26469;&#65292;&#26500;&#24314;LeCun&#25552;&#20986;&#30340;&#23618;&#27425;&#32852;&#21512;&#23884;&#20837;&#39044;&#27979;&#26550;&#26500;&#65288;H-JEPA&#65289;&#30340;&#22522;&#26412;&#27169;&#22359;&#12290;
&lt;/p&gt;
&lt;p&gt;
Current automated systems have crucial limitations that need to be addressed before artificial intelligence can reach human-like levels and bring new technological revolutions. Among others, our societies still lack Level 5 self-driving cars, domestic robots, and virtual assistants that learn reliable world models, reason, and plan complex action sequences. In these notes, we summarize the main ideas behind the architecture of autonomous intelligence of the future proposed by Yann LeCun. In particular, we introduce energy-based and latent variable models and combine their advantages in the building block of LeCun's proposal, that is, in the hierarchical joint embedding predictive architecture (H-JEPA).
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20351;&#29992;&#21160;&#24577;&#35268;&#21010;&#21644;Gumbel&#20256;&#25773;&#22312;VAE&#30340;&#28508;&#22312;&#31354;&#38388;&#20013;&#33719;&#24471;&#32467;&#26500;&#21270;&#31232;&#30095;&#26368;&#20248;&#36335;&#24452;&#65292;&#20174;&#32780;&#20351;&#24471;&#27169;&#22411;&#21487;&#20197;&#20381;&#36182;&#20110;&#26410;&#35266;&#23519;&#21040;&#30340;&#32467;&#26500;&#29305;&#24449;&#20449;&#24687;&#65292;&#24182;&#25104;&#21151;&#23454;&#29616;&#20102;&#25991;&#26412;&#36716;&#35821;&#38899;&#21644;&#27468;&#22768;&#21512;&#25104;&#12290;</title><link>http://arxiv.org/abs/2306.02568</link><description>&lt;p&gt;
Gumbel&#20256;&#25773;&#19979;&#30340;&#28508;&#22312;&#26368;&#20248;&#36335;&#24452;&#21464;&#20998;&#36125;&#21494;&#26031;&#21160;&#24577;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
Latent Optimal Paths by Gumbel Propagation for Variational Bayesian Dynamic Programming. (arXiv:2306.02568v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02568
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20351;&#29992;&#21160;&#24577;&#35268;&#21010;&#21644;Gumbel&#20256;&#25773;&#22312;VAE&#30340;&#28508;&#22312;&#31354;&#38388;&#20013;&#33719;&#24471;&#32467;&#26500;&#21270;&#31232;&#30095;&#26368;&#20248;&#36335;&#24452;&#65292;&#20174;&#32780;&#20351;&#24471;&#27169;&#22411;&#21487;&#20197;&#20381;&#36182;&#20110;&#26410;&#35266;&#23519;&#21040;&#30340;&#32467;&#26500;&#29305;&#24449;&#20449;&#24687;&#65292;&#24182;&#25104;&#21151;&#23454;&#29616;&#20102;&#25991;&#26412;&#36716;&#35821;&#38899;&#21644;&#27468;&#22768;&#21512;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#26041;&#27861;&#65292;&#20351;&#29992;&#21160;&#24577;&#35268;&#21010;&#21644;Gumbel&#20256;&#25773;&#22312;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#30340;&#28508;&#22312;&#31354;&#38388;&#20013;&#33719;&#21462;&#32467;&#26500;&#21270;&#31232;&#30095;&#26368;&#20248;&#36335;&#24452;&#12290;&#25105;&#20204;&#36890;&#36807;&#27010;&#29575;&#36719;&#21270;&#35299;&#65292;&#21363;&#38543;&#26426;&#26368;&#20248;&#36335;&#24452;&#65292;&#26469;&#35299;&#20915;&#32463;&#20856;&#26368;&#20248;&#36335;&#24452;&#38382;&#39064;&#65292;&#24182;&#23558;&#24191;&#27867;&#30340;DP&#38382;&#39064;&#36716;&#21270;&#20026;&#26377;&#21521;&#26080;&#29615;&#22270;&#65292;&#20854;&#20013;&#25152;&#26377;&#21487;&#33021;&#30340;&#36335;&#24452;&#36981;&#24490;Gibbs&#20998;&#24067;&#12290;&#25105;&#20204;&#36890;&#36807;Gumbel&#20998;&#24067;&#30340;&#23646;&#24615;&#26174;&#31034;Gibbs&#20998;&#24067;&#19982;&#28040;&#24687;&#20256;&#36882;&#31639;&#27861;&#30340;&#31561;&#20215;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#21464;&#20998;&#36125;&#21494;&#26031;&#25512;&#29702;&#25152;&#38656;&#30340;&#25152;&#26377;&#35201;&#32032;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#33719;&#21462;&#20102;&#28508;&#22312;&#26368;&#20248;&#36335;&#24452;&#65292;&#20351;&#29983;&#25104;&#20219;&#21153;&#30340;&#31471;&#21040;&#31471;&#35757;&#32451;&#25104;&#20026;&#21487;&#33021;&#65292;&#20854;&#20013;&#27169;&#22411;&#20381;&#36182;&#20110;&#26410;&#35266;&#23519;&#21040;&#30340;&#32467;&#26500;&#29305;&#24449;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#39564;&#35777;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#34892;&#20026;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#20004;&#20010;&#30495;&#23454;&#19990;&#30028;&#24212;&#29992;&#20013;&#30340;&#36866;&#29992;&#24615;&#65306;&#25991;&#26412;&#36716;&#35821;&#38899;&#21644;&#27468;&#22768;&#21512;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a unified approach to obtain structured sparse optimal paths in the latent space of a variational autoencoder (VAE) using dynamic programming and Gumbel propagation. We solve the classical optimal path problem by a probability softening solution, called the stochastic optimal path, and transform a wide range of DP problems into directed acyclic graphs in which all possible paths follow a Gibbs distribution. We show the equivalence of the Gibbs distribution to a message-passing algorithm by the properties of the Gumbel distribution and give all the ingredients required for variational Bayesian inference. Our approach obtaining latent optimal paths enables end-to-end training for generative tasks in which models rely on the information of unobserved structural features. We validate the behavior of our approach and showcase its applicability in two real-world applications: text-to-speech and singing voice synthesis.
&lt;/p&gt;</description></item><item><title>C-VAE&#36890;&#36807;&#23558;VAE&#38382;&#39064;&#21046;&#23450;&#20026;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#24182;&#22312;&#20808;&#39564;&#21644;&#25968;&#25454;&#20998;&#24067;&#20043;&#38388;&#24378;&#21046;&#32806;&#21512;&#65292;&#23454;&#29616;&#20102;&#23545;&#20808;&#39564;&#30340;&#26356;&#22823;&#28789;&#27963;&#24615;&#12289;&#35299;&#20915;&#20102;&#20808;&#39564;&#23384;&#22312;&#30340;&#31354;&#27934;&#38382;&#39064;&#65292;&#24182;&#22312;&#20445;&#30495;&#24230;&#12289;&#28508;&#22312;&#34920;&#31034;&#30340;&#36136;&#37327;&#21644;&#29983;&#25104;&#26679;&#26412;&#30340;&#36136;&#37327;&#31561;&#26041;&#38754;&#20248;&#20110;VAE&#12289;WAE&#21644;InfoVAE&#31561;&#26367;&#20195;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2306.02565</link><description>&lt;p&gt;
&#32852;&#21512;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Coupled Variational Autoencoder. (arXiv:2306.02565v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02565
&lt;/p&gt;
&lt;p&gt;
C-VAE&#36890;&#36807;&#23558;VAE&#38382;&#39064;&#21046;&#23450;&#20026;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#24182;&#22312;&#20808;&#39564;&#21644;&#25968;&#25454;&#20998;&#24067;&#20043;&#38388;&#24378;&#21046;&#32806;&#21512;&#65292;&#23454;&#29616;&#20102;&#23545;&#20808;&#39564;&#30340;&#26356;&#22823;&#28789;&#27963;&#24615;&#12289;&#35299;&#20915;&#20102;&#20808;&#39564;&#23384;&#22312;&#30340;&#31354;&#27934;&#38382;&#39064;&#65292;&#24182;&#22312;&#20445;&#30495;&#24230;&#12289;&#28508;&#22312;&#34920;&#31034;&#30340;&#36136;&#37327;&#21644;&#29983;&#25104;&#26679;&#26412;&#30340;&#36136;&#37327;&#31561;&#26041;&#38754;&#20248;&#20110;VAE&#12289;WAE&#21644;InfoVAE&#31561;&#26367;&#20195;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#22312;&#29983;&#25104;&#20219;&#21153;&#20013;&#26159;&#24378;&#22823;&#30340;&#27010;&#29575;&#27169;&#22411;&#65292;&#20294;&#20250;&#20135;&#29983;&#20302;&#36136;&#37327;&#30340;&#26679;&#26412;&#65292;&#36825;&#26159;&#30001;&#20110;&#20808;&#39564;&#20013;&#23384;&#22312;&#31354;&#27934;&#25152;&#23548;&#33268;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#32852;&#21512;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;(C-VAE)&#65292;&#23558;VAE&#38382;&#39064;&#21046;&#23450;&#20026;&#20808;&#39564;&#21644;&#25968;&#25454;&#20998;&#24067;&#20043;&#38388;&#30340;&#26368;&#20248;&#36755;&#36816;(OT)&#38382;&#39064;&#12290;C-VAE&#36890;&#36807;&#22312;&#20808;&#39564;&#21644;&#25968;&#25454;&#20998;&#24067;&#20043;&#38388;&#24378;&#21046;&#32806;&#21512;&#65292;&#23454;&#29616;&#20102;&#23545;&#20808;&#39564;&#30340;&#26356;&#22823;&#28789;&#27963;&#24615;&#21644;&#33258;&#28982;&#22320;&#35299;&#20915;&#20102;&#20808;&#39564;&#23384;&#22312;&#30340;&#31354;&#27934;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#29109;OT&#30340;&#21407;&#22987;&#12289;&#23545;&#20598;&#21644;&#21322;&#23545;&#20598;&#24418;&#24335;&#23454;&#29616;&#20102;&#28789;&#27963;&#30340;&#20248;&#21270;&#12290;&#23545;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#30340;&#27169;&#25311;&#34920;&#26126;&#65292;C-VAE&#22312;&#25968;&#25454;&#30340;&#20445;&#30495;&#24230;&#12289;&#28508;&#22312;&#34920;&#31034;&#30340;&#36136;&#37327;&#21644;&#29983;&#25104;&#26679;&#26412;&#30340;&#36136;&#37327;&#31561;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#26367;&#20195;&#26041;&#26696;&#65292;&#21253;&#25324;VAE&#12289;WAE&#21644;InfoVAE&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational auto-encoders are powerful probabilistic models in generative tasks but suffer from generating low-quality samples which are caused by the holes in the prior. We propose the Coupled Variational Auto-Encoder (C-VAE), which formulates the VAE problem as one of Optimal Transport (OT) between the prior and data distributions. The C-VAE allows greater flexibility in priors and natural resolution of the prior hole problem by enforcing coupling between the prior and the data distribution and enables flexible optimization through the primal, dual, and semi-dual formulations of entropic OT. Simulations on synthetic and real data show that the C-VAE outperforms alternatives including VAE, WAE, and InfoVAE in fidelity to the data, quality of the latent representation, and in quality of generated samples.
&lt;/p&gt;</description></item><item><title>&#24403;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#28155;&#21152;&#38543;&#26426;&#26631;&#31614;&#22122;&#22768;&#26102;&#65292;&#31070;&#32463;&#32593;&#32476;&#20250;&#20808;&#23398;&#20064;&#24178;&#20928;&#25968;&#25454;&#20877;&#23398;&#20064;&#22122;&#22768;&#65292;&#23548;&#33268;&#39044;&#27979;&#35823;&#24046;&#21576;&#29616;U&#24418;&#26354;&#32447;&#12290;&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#36825;&#31181;&#28165;&#27905;&#20248;&#20808;&#23398;&#20064;&#30340;&#23398;&#20064;&#21160;&#24577;&#65292;&#24182;&#25552;&#20986;&#20102;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#23545;&#26631;&#31614;&#22122;&#22768;&#40065;&#26834;&#24615;&#30340;&#28508;&#22312;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2306.02533</link><description>&lt;p&gt;
&#26089;&#26399;&#20572;&#27490;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#28165;&#27905;&#20248;&#20808;&#23398;&#20064;&#29616;&#35937;&#30340;&#20986;&#29616;
&lt;/p&gt;
&lt;p&gt;
On Emergence of Clean-Priority Learning in Early Stopped Neural Networks. (arXiv:2306.02533v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02533
&lt;/p&gt;
&lt;p&gt;
&#24403;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#28155;&#21152;&#38543;&#26426;&#26631;&#31614;&#22122;&#22768;&#26102;&#65292;&#31070;&#32463;&#32593;&#32476;&#20250;&#20808;&#23398;&#20064;&#24178;&#20928;&#25968;&#25454;&#20877;&#23398;&#20064;&#22122;&#22768;&#65292;&#23548;&#33268;&#39044;&#27979;&#35823;&#24046;&#21576;&#29616;U&#24418;&#26354;&#32447;&#12290;&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#36825;&#31181;&#28165;&#27905;&#20248;&#20808;&#23398;&#20064;&#30340;&#23398;&#20064;&#21160;&#24577;&#65292;&#24182;&#25552;&#20986;&#20102;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#23545;&#26631;&#31614;&#22122;&#22768;&#40065;&#26834;&#24615;&#30340;&#28508;&#22312;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#28155;&#21152;&#38543;&#26426;&#26631;&#31614;&#22122;&#22768;&#26102;&#65292;&#31070;&#32463;&#32593;&#32476;&#22312;&#27809;&#26377;&#22122;&#22768;&#30340;&#27979;&#35797;&#25968;&#25454;&#38598;&#19978;&#30340;&#39044;&#27979;&#35823;&#24046;&#22312;&#26089;&#26399;&#35757;&#32451;&#36807;&#31243;&#20013;&#20250;&#20808;&#25913;&#21892;&#21518;&#24694;&#21270;&#65292;&#21576;&#29616;&#20986;&#19968;&#20010;U&#24418;&#30340;&#20381;&#36182;&#20110;&#35757;&#32451;&#26102;&#38388;&#30340;&#26354;&#32447;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#36825;&#31181;&#34892;&#20026;&#26159;&#31070;&#32463;&#32593;&#32476;&#22312;&#35757;&#32451;&#20013;&#20808;&#23398;&#20064;&#24178;&#20928;&#25968;&#25454;&#30340;&#27169;&#24335;&#65292;&#28982;&#21518;&#20877;&#36880;&#28176;&#25311;&#21512;&#22122;&#22768;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#31216;&#20043;&#20026;&#28165;&#27905;&#20248;&#20808;&#23398;&#20064;&#29616;&#35937;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#25506;&#32034;&#35813;&#29616;&#35937;&#32972;&#21518;&#30340;&#23398;&#20064;&#21160;&#24577;&#12290;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#65292;&#22312;&#35757;&#32451;&#30340;&#26089;&#26399;&#38454;&#27573;&#65292;&#26799;&#24230;&#19979;&#38477;&#30340;&#26356;&#26032;&#26041;&#21521;&#30001;&#35757;&#32451;&#25968;&#25454;&#30340;&#24178;&#20928;&#23376;&#38598;&#20915;&#23450;&#65292;&#22122;&#22768;&#23376;&#38598;&#30340;&#24433;&#21709;&#26159;&#26368;&#23567;&#30340;&#25110;&#27809;&#26377;&#30340;&#65292;&#23548;&#33268;&#20102;&#20248;&#20808;&#36827;&#34892;&#24178;&#20928;&#25968;&#25454;&#30340;&#23398;&#20064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#29702;&#35770;&#19978;&#21644;&#23454;&#39564;&#19978;&#37117;&#26174;&#31034;&#65292;&#22312;&#36827;&#34892;&#28165;&#27905;&#20248;&#20808;&#23398;&#20064;&#30340;&#36807;&#31243;&#20013;&#65292;&#28165;&#27905;&#26679;&#26412;&#30340;&#26799;&#24230;&#22312;&#22024;&#26434;&#26679;&#26412;&#30340;&#26799;&#24230;&#20043;&#19978;&#30340;&#20248;&#21183;&#36880;&#28176;&#20943;&#23567;&#65292;&#26368;&#32456;&#24418;&#25104;&#20102;&#39044;&#27979;&#35823;&#24046;&#30340;U&#24418;&#26354;&#32447;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#20026;&#28165;&#27905;&#20248;&#20808;&#23398;&#20064;&#29616;&#35937;&#30340;&#20986;&#29616;&#25552;&#20379;&#20102;&#28145;&#20837;&#30340;&#27934;&#23519;&#65292;&#24182;&#25552;&#20986;&#20102;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#23545;&#26631;&#31614;&#22122;&#22768;&#30340;&#40065;&#26834;&#24615;&#30340;&#28508;&#22312;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
When random label noise is added to a training dataset, the prediction error of a neural network on a label-noise-free test dataset initially improves during early training but eventually deteriorates, following a U-shaped dependence on training time. This behaviour is believed to be a result of neural networks learning the pattern of clean data first and fitting the noise later in the training, a phenomenon that we refer to as clean-priority learning. In this study, we aim to explore the learning dynamics underlying this phenomenon. We theoretically demonstrate that, in the early stage of training, the update direction of gradient descent is determined by the clean subset of training data, leaving the noisy subset has minimal to no impact, resulting in a prioritization of clean learning. Moreover, we show both theoretically and experimentally, as the clean-priority learning goes on, the dominance of the gradients of clean samples over those of noisy samples diminishes, and finally res
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29992;&#20110;&#27604;&#36739;&#22270;&#19978;&#20449;&#21495;&#30340;&#26041;&#27861;&#8212;&#8212;&#22270;&#20613;&#37324;&#21494;&#31227;&#21160;&#36317;&#31163;&#65288;GFMMD&#65289;&#65292;&#23427;&#26159;&#36890;&#36807;&#19968;&#20010;&#26368;&#20248;&#30340;&#35265;&#35777;&#20989;&#25968;&#36827;&#34892;&#23450;&#20041;&#65292;&#24182;&#19988;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#34920;&#26126;&#23427;&#20248;&#20110;&#29616;&#26377;&#30340;&#27604;&#36739;&#22270;&#20449;&#21495;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.02508</link><description>&lt;p&gt;
&#22270;&#20613;&#37324;&#21494;&#31227;&#21160;&#36317;&#31163;&#29992;&#20110;&#22270;&#20449;&#21495;
&lt;/p&gt;
&lt;p&gt;
Graph Fourier MMD for Signals on Graphs. (arXiv:2306.02508v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02508
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29992;&#20110;&#27604;&#36739;&#22270;&#19978;&#20449;&#21495;&#30340;&#26041;&#27861;&#8212;&#8212;&#22270;&#20613;&#37324;&#21494;&#31227;&#21160;&#36317;&#31163;&#65288;GFMMD&#65289;&#65292;&#23427;&#26159;&#36890;&#36807;&#19968;&#20010;&#26368;&#20248;&#30340;&#35265;&#35777;&#20989;&#25968;&#36827;&#34892;&#23450;&#20041;&#65292;&#24182;&#19988;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#34920;&#26126;&#23427;&#20248;&#20110;&#29616;&#26377;&#30340;&#27604;&#36739;&#22270;&#20449;&#21495;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#26041;&#27861;&#26469;&#35745;&#31639;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#27010;&#29575;&#20998;&#24067;&#20043;&#38388;&#30340;&#36317;&#31163;&#65292;&#20294;&#26159;&#30456;&#23545;&#20110;&#35745;&#31639;&#36825;&#26679;&#30340;&#36317;&#31163;&#22312;&#22270;&#19978;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#21364;&#32473;&#20104;&#20102;&#30456;&#23545;&#36739;&#23569;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#22312;&#29983;&#29289;&#21307;&#23398;&#31185;&#23398;&#39046;&#22495;&#65292;&#26080;&#35770;&#26159;&#20301;&#20110;&#22270;&#19978;&#65288;&#22914;&#34507;&#30333;&#36136;&#30456;&#20114;&#20316;&#29992;&#32593;&#32476;&#65289;&#36824;&#26159;&#21487;&#34987;&#24314;&#27169;&#20026;&#22270;&#30340;&#25968;&#25454;&#65288;&#21333;&#32454;&#32990;&#25968;&#25454;&#65289;&#37117;&#26377;&#26174;&#33879;&#22686;&#21152;&#12290;&#22240;&#27492;&#65292;&#37325;&#35201;&#30340;&#26159;&#35201;&#25214;&#21040;&#27604;&#36739;&#23450;&#20041;&#22312;&#36825;&#31181;&#22270;&#19978;&#30340;&#20449;&#21495;&#30340;&#26041;&#27861;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#24067;&#21644;&#22270;&#19978;&#20449;&#21495;&#20043;&#38388;&#30340;&#36317;&#31163;&#65292;&#31216;&#20026;&#22270;&#20613;&#37324;&#21494;&#31227;&#21160;&#36317;&#31163;&#65288;GFMMD&#65289;&#12290;GFMMD&#36890;&#36807;&#19968;&#20010;&#26368;&#20248;&#30340;&#35265;&#35777;&#20989;&#25968;&#36827;&#34892;&#23450;&#20041;&#65292;&#36825;&#20010;&#20989;&#25968;&#26082;&#22312;&#22270;&#19978;&#24179;&#28369;&#65292;&#21448;&#26368;&#22823;&#21270;&#20102;&#22312;&#22270;&#19978;&#30340;&#20004;&#20010;&#20998;&#24067;&#20043;&#38388;&#30340;&#26399;&#26395;&#24046;&#24322;&#12290;&#25105;&#20204;&#21457;&#29616;&#20102;&#36825;&#20010;&#20248;&#21270;&#38382;&#39064;&#30340;&#19968;&#20010;&#35299;&#26512;&#35299;&#20197;&#21450;&#30001;&#35813;&#26041;&#27861;&#20135;&#29983;&#30340;&#20998;&#24067;&#23884;&#20837;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20960;&#20010;&#24615;&#36136;&#65292;&#21253;&#25324;&#23610;&#24230;&#19981;&#21464;&#24615;&#21644;&#36866;&#29992;&#20110;&#19968;&#33324;&#22270;&#24418;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#23545;GFMMD&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#65292;&#24182;&#26174;&#31034;&#23427;&#20248;&#20110;&#29616;&#26377;&#27604;&#36739;&#22270;&#20449;&#21495;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
While numerous methods have been proposed for computing distances between probability distributions in Euclidean space, relatively little attention has been given to computing such distances for distributions on graphs. However, there has been a marked increase in data that either lies on graph (such as protein interaction networks) or can be modeled as a graph (single cell data), particularly in the biomedical sciences. Thus, it becomes important to find ways to compare signals defined on such graphs. Here, we propose Graph Fourier MMD (GFMMD), a novel distance between distributions and signals on graphs. GFMMD is defined via an optimal witness function that is both smooth on the graph and maximizes difference in expectation between the pair of distributions on the graph. We find an analytical solution to this optimization problem as well as an embedding of distributions that results from this method. We also prove several properties of this method including scale invariance and appli
&lt;/p&gt;</description></item><item><title>SALE&#26159;&#19968;&#31181;&#22522;&#20110;&#29366;&#24577;-&#21160;&#20316;&#34920;&#31034;&#23398;&#20064;&#30340;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#20174;&#20302;&#32423;&#29366;&#24577;&#20013;&#23454;&#29616;&#34920;&#31034;&#23398;&#20064;&#65292;TD7&#31639;&#27861;&#24341;&#20837;&#20102;&#35813;&#26041;&#27861;&#24182;&#22312;&#36830;&#32493;&#25511;&#21046;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2306.02451</link><description>&lt;p&gt;
&#24453;&#21806;&#65306;&#22522;&#20110;&#29366;&#24577;-&#21160;&#20316;&#34920;&#31034;&#23398;&#20064;&#30340;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
For SALE: State-Action Representation Learning for Deep Reinforcement Learning. (arXiv:2306.02451v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02451
&lt;/p&gt;
&lt;p&gt;
SALE&#26159;&#19968;&#31181;&#22522;&#20110;&#29366;&#24577;-&#21160;&#20316;&#34920;&#31034;&#23398;&#20064;&#30340;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#20174;&#20302;&#32423;&#29366;&#24577;&#20013;&#23454;&#29616;&#34920;&#31034;&#23398;&#20064;&#65292;TD7&#31639;&#27861;&#24341;&#20837;&#20102;&#35813;&#26041;&#27861;&#24182;&#22312;&#36830;&#32493;&#25511;&#21046;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#20013;&#65292;&#34920;&#31034;&#23398;&#20064;&#26159;&#22788;&#29702;&#22797;&#26434;&#22522;&#20110;&#22270;&#20687;&#20219;&#21153;&#30340;&#26377;&#25928;&#24037;&#20855;&#65292;&#20294;&#36890;&#24120;&#34987;&#24573;&#30053;&#20102;&#20302;&#32423;&#29366;&#24577;&#65288;&#20363;&#22914;&#29289;&#29702;&#25511;&#21046;&#38382;&#39064;&#65289;&#30340;&#29615;&#22659;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;SALE&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#23398;&#20064;&#23884;&#20837;&#26469;&#24314;&#27169;&#29366;&#24577;&#21644;&#21160;&#20316;&#20043;&#38388;&#24494;&#22937;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#20174;&#20302;&#32423;&#29366;&#24577;&#20013;&#23454;&#29616;&#26377;&#25928;&#30340;&#34920;&#31034;&#23398;&#20064;&#12290;&#25105;&#20204;&#24191;&#27867;&#30740;&#31350;&#20102;&#36825;&#20123;&#23884;&#20837;&#30340;&#35774;&#35745;&#31354;&#38388;&#65292;&#24182;&#24378;&#35843;&#20102;&#37325;&#35201;&#30340;&#35774;&#35745;&#32771;&#34385;&#22240;&#32032;&#12290;&#25105;&#20204;&#23558;SALE&#21644;RL&#30340;&#26816;&#26597;&#28857;&#33258;&#36866;&#24212;&#26041;&#27861;&#25972;&#21512;&#21040;TD3&#20013;&#65292;&#24418;&#25104;TD7&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#36830;&#32493;&#25511;&#21046;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;&#22312;OpenAI gym&#22522;&#20934;&#20219;&#21153;&#20013;&#65292;TD7&#22312;300k&#21644;5M&#26102;&#38388;&#27493;&#39588;&#19979;&#30340;&#24179;&#22343;&#24615;&#33021;&#22686;&#30410;&#20998;&#21035;&#20026;276.7&#65285;&#21644;50.7&#65285;&#65292;&#21487;&#20197;&#22312;&#22312;&#32447;&#21644;&#31163;&#32447;&#35774;&#32622;&#20013;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the field of reinforcement learning (RL), representation learning is a proven tool for complex image-based tasks, but is often overlooked for environments with low-level states, such as physical control problems. This paper introduces SALE, a novel approach for learning embeddings that model the nuanced interaction between state and action, enabling effective representation learning from low-level states. We extensively study the design space of these embeddings and highlight important design considerations. We integrate SALE and an adaptation of checkpoints for RL into TD3 to form the TD7 algorithm, which significantly outperforms existing continuous control algorithms. On OpenAI gym benchmark tasks, TD7 has an average performance gain of 276.7% and 50.7% over TD3 at 300k and 5M time steps, respectively, and works in both the online and offline settings.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#8220;&#25239;&#24178;&#25200;&#32422;&#26463;&#23398;&#20064;&#8221;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#22312;&#37096;&#32626;&#26426;&#22120;&#23398;&#20064;&#35299;&#20915;&#26041;&#26696;&#26102;&#38656;&#35201;&#28385;&#36275;&#38500;&#20102;&#20934;&#30830;&#24615;&#20197;&#22806;&#30340;&#22810;&#20010;&#35201;&#27714;&#65292;&#24182;&#20197;&#24179;&#34913;&#20174;&#25918;&#23485;&#20013;&#33719;&#24471;&#30340;&#24615;&#33021;&#22686;&#30410;&#19982;&#29992;&#25143;&#23450;&#20041;&#30340;&#25918;&#23485;&#25104;&#26412;&#20043;&#38388;&#30340;&#20851;&#31995;&#30340;&#26041;&#24335;&#25918;&#26494;&#23398;&#20064;&#32422;&#26463;&#12290;</title><link>http://arxiv.org/abs/2306.02426</link><description>&lt;p&gt;
&#25239;&#24178;&#25200;&#32422;&#26463;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Resilient Constrained Learning. (arXiv:2306.02426v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02426
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#8220;&#25239;&#24178;&#25200;&#32422;&#26463;&#23398;&#20064;&#8221;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#22312;&#37096;&#32626;&#26426;&#22120;&#23398;&#20064;&#35299;&#20915;&#26041;&#26696;&#26102;&#38656;&#35201;&#28385;&#36275;&#38500;&#20102;&#20934;&#30830;&#24615;&#20197;&#22806;&#30340;&#22810;&#20010;&#35201;&#27714;&#65292;&#24182;&#20197;&#24179;&#34913;&#20174;&#25918;&#23485;&#20013;&#33719;&#24471;&#30340;&#24615;&#33021;&#22686;&#30410;&#19982;&#29992;&#25143;&#23450;&#20041;&#30340;&#25918;&#23485;&#25104;&#26412;&#20043;&#38388;&#30340;&#20851;&#31995;&#30340;&#26041;&#24335;&#25918;&#26494;&#23398;&#20064;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#37096;&#32626;&#26426;&#22120;&#23398;&#20064;&#35299;&#20915;&#26041;&#26696;&#26102;&#65292;&#38500;&#20102;&#20934;&#30830;&#24615;&#20043;&#22806;&#65292;&#23427;&#20204;&#24517;&#39035;&#28385;&#36275;&#22810;&#20010;&#35201;&#27714;&#65292;&#22914;&#20844;&#24179;&#24615;&#12289;&#40065;&#26834;&#24615;&#25110;&#23433;&#20840;&#24615;&#12290;&#36825;&#20123;&#35201;&#27714;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#24809;&#32602;&#26469;&#38544;&#24335;&#22320;&#26045;&#21152;&#65292;&#25110;&#32773;&#36890;&#36807;&#22522;&#20110;Lagrangian&#23545;&#20598;&#30340;&#32422;&#26463;&#20248;&#21270;&#26041;&#27861;&#26469;&#26174;&#24335;&#22320;&#26045;&#21152;&#12290;&#26080;&#35770;&#21738;&#31181;&#26041;&#24335;&#65292;&#25351;&#23450;&#35201;&#27714;&#37117;&#21463;&#21040;&#22949;&#21327;&#21644;&#26377;&#38480;&#30340;&#26377;&#20851;&#25968;&#25454;&#30340;&#20808;&#21069;&#30693;&#35782;&#30340;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;&#23427;&#20204;&#23545;&#24615;&#33021;&#30340;&#24433;&#21709;&#36890;&#24120;&#21482;&#33021;&#36890;&#36807;&#23454;&#38469;&#35299;&#20915;&#23398;&#20064;&#38382;&#39064;&#26469;&#35780;&#20272;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32422;&#26463;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#21516;&#26102;&#35299;&#20915;&#23398;&#20064;&#20219;&#21153;&#30340;&#21516;&#26102;&#35843;&#25972;&#35201;&#27714;&#12290;&#20026;&#27492;&#65292;&#23427;&#20197;&#24179;&#34913;&#20174;&#25918;&#23485;&#20013;&#33719;&#24471;&#30340;&#24615;&#33021;&#22686;&#30410;&#19982;&#29992;&#25143;&#23450;&#20041;&#30340;&#25918;&#23485;&#25104;&#26412;&#20043;&#38388;&#30340;&#20851;&#31995;&#30340;&#26041;&#24335;&#25918;&#26494;&#20102;&#23398;&#20064;&#32422;&#26463;&#12290;&#25105;&#20204;&#23558;&#27492;&#26041;&#27861;&#31216;&#20026;&#20855;&#26377;&#24377;&#24615;&#30340;&#32422;&#26463;&#23398;&#20064;&#65292;&#36825;&#26159;&#23545;&#29992;&#20110;&#25551;&#36848;&#29983;&#24577;&#31995;&#32479;&#30340;&#26415;&#35821;&#30340;&#19968;&#31181;&#20511;&#37492;&#12290;
&lt;/p&gt;
&lt;p&gt;
When deploying machine learning solutions, they must satisfy multiple requirements beyond accuracy, such as fairness, robustness, or safety. These requirements are imposed during training either implicitly, using penalties, or explicitly, using constrained optimization methods based on Lagrangian duality. Either way, specifying requirements is hindered by the presence of compromises and limited prior knowledge about the data. Furthermore, their impact on performance can often only be evaluated by actually solving the learning problem. This paper presents a constrained learning approach that adapts the requirements while simultaneously solving the learning task. To do so, it relaxes the learning constraints in a way that contemplates how much they affect the task at hand by balancing the performance gains obtained from the relaxation against a user-defined cost of that relaxation. We call this approach resilient constrained learning after the term used to describe ecological systems tha
&lt;/p&gt;</description></item><item><title>ContraBAR&#26159;&#19968;&#31181;&#20351;&#29992;&#23545;&#27604;&#36125;&#21494;&#26031;&#33258;&#36866;&#24212;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#20803;RL&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#22522;&#20110;&#29366;&#24577;&#35266;&#23519;&#30340;&#39046;&#22495;&#20013;&#23454;&#29616;&#19982;&#26368;&#20808;&#36827;&#26041;&#27861;&#21487;&#27604;&#36739;&#30340;&#24615;&#33021;&#65292;&#24182;&#35268;&#36991;&#20102;&#26410;&#26469;&#35266;&#23519;&#37325;&#24314;&#30340;&#35745;&#31639;&#20195;&#20215;&#65292;&#20174;&#32780;&#22312;&#22522;&#20110;&#22270;&#20687;&#30340;&#35266;&#23519;&#30340;&#39046;&#22495;&#20013;&#36827;&#34892;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2306.02418</link><description>&lt;p&gt;
ContraBAR: &#23545;&#27604;&#36125;&#21494;&#26031;&#33258;&#36866;&#24212;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
ContraBAR: Contrastive Bayes-Adaptive Deep RL. (arXiv:2306.02418v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02418
&lt;/p&gt;
&lt;p&gt;
ContraBAR&#26159;&#19968;&#31181;&#20351;&#29992;&#23545;&#27604;&#36125;&#21494;&#26031;&#33258;&#36866;&#24212;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#20803;RL&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#22522;&#20110;&#29366;&#24577;&#35266;&#23519;&#30340;&#39046;&#22495;&#20013;&#23454;&#29616;&#19982;&#26368;&#20808;&#36827;&#26041;&#27861;&#21487;&#27604;&#36739;&#30340;&#24615;&#33021;&#65292;&#24182;&#35268;&#36991;&#20102;&#26410;&#26469;&#35266;&#23519;&#37325;&#24314;&#30340;&#35745;&#31639;&#20195;&#20215;&#65292;&#20174;&#32780;&#22312;&#22522;&#20110;&#22270;&#20687;&#30340;&#35266;&#23519;&#30340;&#39046;&#22495;&#20013;&#36827;&#34892;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20803;&#24378;&#21270;&#23398;&#20064;&#65288;meta RL&#65289;&#20013;&#65292;&#26234;&#33021;&#20307;&#23547;&#27714;&#36125;&#21494;&#26031;&#26368;&#20248;&#31574;&#30053;&#8212;&#8212;&#38754;&#23545;&#20174;&#26576;&#20123;&#24050;&#30693;&#20219;&#21153;&#20998;&#24067;&#20013;&#37319;&#26679;&#30340;&#26410;&#30693;&#20219;&#21153;&#26102;&#30340;&#26368;&#20248;&#31574;&#30053;&#12290;&#20197;&#21069;&#30340;&#26041;&#27861;&#36890;&#36807;&#25512;&#26029;&#20219;&#21153;&#21442;&#25968;&#19978;&#30340;&#20449;&#24565;&#65292;&#20351;&#29992;&#21464;&#20998;&#25512;&#29702;&#26041;&#27861;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#21463;&#24378;&#21270;&#23398;&#20064;&#20013;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#30340;&#26368;&#36817;&#25104;&#21151;&#21551;&#21457;&#65292;&#20363;&#22914;&#23545;&#27604;&#39044;&#27979;&#32534;&#30721;&#65288;CPC&#65289;&#65292;&#25105;&#20204;&#35843;&#26597;&#23545;&#27604;&#26041;&#27861;&#26159;&#21542;&#21487;&#29992;&#20110;&#23398;&#20064;&#36125;&#21494;&#26031;&#26368;&#20248;&#34892;&#20026;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;CPC&#23398;&#20064;&#21040;&#30340;&#34920;&#31034;&#36275;&#20197;&#36827;&#34892;&#36125;&#21494;&#26031;&#26368;&#20248;&#21270;&#12290;&#22522;&#20110;&#36825;&#20010;&#35266;&#23519;&#32467;&#26524;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#20803;RL&#31639;&#27861;&#8212;&#8212;ContraBAR&#65292;&#23427;&#20351;&#29992;CPC&#20195;&#26367;&#21464;&#20998;&#20449;&#24565;&#25512;&#26029;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22522;&#20110;&#29366;&#24577;&#35266;&#23519;&#30340;&#22495;&#20013;&#23454;&#29616;&#20102;&#19982;&#26368;&#20808;&#36827;&#26041;&#27861;&#21487;&#27604;&#36739;&#30340;&#24615;&#33021;&#65292;&#24182;&#35268;&#36991;&#20102;&#26410;&#26469;&#35266;&#23519;&#37325;&#24314;&#30340;&#35745;&#31639;&#20195;&#20215;&#65292;&#20174;&#32780;&#22312;&#22522;&#20110;&#22270;&#20687;&#30340;&#35266;&#23519;&#30340;&#39046;&#22495;&#20013;&#36827;&#34892;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
In meta reinforcement learning (meta RL), an agent seeks a Bayes-optimal policy -- the optimal policy when facing an unknown task that is sampled from some known task distribution. Previous approaches tackled this problem by inferring a belief over task parameters, using variational inference methods. Motivated by recent successes of contrastive learning approaches in RL, such as contrastive predictive coding (CPC), we investigate whether contrastive methods can be used for learning Bayes-optimal behavior. We begin by proving that representations learned by CPC are indeed sufficient for Bayes optimality. Based on this observation, we propose a simple meta RL algorithm that uses CPC in lieu of variational belief inference. Our method, ContraBAR, achieves comparable performance to state-of-the-art in domains with state-based observation and circumvents the computational toll of future observation reconstruction, enabling learning in domains with image-based observations. It can also be c
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#23436;&#32654;&#24863;&#30693;&#36136;&#37327;&#32422;&#26463;&#19979;&#30340;&#22312;&#32447;&#29366;&#24577;&#20272;&#35745;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#24863;&#30693;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;PKF&#65289;&#36825;&#19968;&#26368;&#20248;&#20272;&#35745;&#22120;&#65292;&#24182;&#25552;&#20379;&#20102;&#20854;&#22312;&#32447;&#23454;&#29616;&#30340;&#23454;&#38469;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#23454;&#26102;&#25805;&#20316;&#12290;&#23454;&#39564;&#35777;&#26126;PKF&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#20272;&#35745;&#20449;&#21495;&#30340;&#24863;&#30693;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2306.02400</link><description>&lt;p&gt;
&#24863;&#30693;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65306;&#22312;&#23436;&#32654;&#24863;&#30693;&#36136;&#37327;&#32422;&#26463;&#19979;&#30340;&#22312;&#32447;&#29366;&#24577;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Perceptual Kalman Filters: Online State Estimation under a Perfect Perceptual-Quality Constraint. (arXiv:2306.02400v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02400
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#23436;&#32654;&#24863;&#30693;&#36136;&#37327;&#32422;&#26463;&#19979;&#30340;&#22312;&#32447;&#29366;&#24577;&#20272;&#35745;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#24863;&#30693;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;PKF&#65289;&#36825;&#19968;&#26368;&#20248;&#20272;&#35745;&#22120;&#65292;&#24182;&#25552;&#20379;&#20102;&#20854;&#22312;&#32447;&#23454;&#29616;&#30340;&#23454;&#38469;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#23454;&#26102;&#25805;&#20316;&#12290;&#23454;&#39564;&#35777;&#26126;PKF&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#20272;&#35745;&#20449;&#21495;&#30340;&#24863;&#30693;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#38656;&#35201;&#20174;&#21463;&#25439;&#25110;&#32570;&#22833;&#25968;&#25454;&#20013;&#37325;&#24314;&#26102;&#38388;&#20449;&#21495;&#12290;&#32463;&#20856;&#30340;&#20363;&#23376;&#21253;&#25324;&#35299;&#30721;&#12289;&#36319;&#36394;&#12289;&#20449;&#21495;&#22686;&#24378;&#21644;&#21435;&#22122;&#12290;&#30001;&#20110;&#26368;&#32456;&#37325;&#24314;&#20449;&#21495;&#26159;&#30001;&#20154;&#31867;&#35266;&#30475;&#30340;&#65292;&#22240;&#27492;&#24076;&#26395;&#23454;&#29616;&#20196;&#20154;&#24841;&#24742;&#30340;&#37325;&#24314;&#25928;&#26524;&#12290;&#22312;&#25968;&#23398;&#19978;&#65292;&#36890;&#36807;&#24674;&#22797;&#20449;&#21495;&#20998;&#24067;&#19982;&#33258;&#28982;&#20449;&#21495;&#30340;&#20998;&#24067;&#30456;&#21516;&#26469;&#23454;&#29616;&#23436;&#32654;&#24863;&#30693;&#36136;&#37327;&#65292;&#36825;&#26159;&#38745;&#24577;&#20272;&#35745;&#35774;&#32622;&#65288;&#21363;&#19968;&#27425;&#22788;&#29702;&#25972;&#20010;&#20449;&#21495;&#65289;&#20013;&#24050;&#32463;&#36827;&#34892;&#20102;&#22823;&#37327;&#30740;&#31350;&#30340;&#35201;&#27714;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#23436;&#32654;&#24863;&#30693;&#36136;&#37327;&#32422;&#26463;&#26465;&#20214;&#19979;&#30340;&#26368;&#20248;&#22240;&#26524;&#28388;&#27874;&#38382;&#39064;&#65292;&#36825;&#26159;&#19968;&#31181;&#26681;&#26412;&#19981;&#21516;&#30340;&#20219;&#21153;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#36890;&#36807;&#32447;&#24615;&#22122;&#22768;&#21464;&#25442;&#35266;&#23519;&#30340;&#39640;&#26031;&#39532;&#23572;&#21487;&#22827;&#20449;&#21495;&#12290;&#22312;&#27809;&#26377;&#24863;&#30693;&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#65292;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#34987;&#35748;&#20026;&#26159;&#35813;&#35774;&#32622;&#20013;MSE&#33539;&#22260;&#20869;&#30340;&#26368;&#20248;&#20272;&#35745;&#22120;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21152;&#20837;&#23436;&#32654;&#24863;&#30693;&#36136;&#37327;&#32422;&#26463;&#20250;&#20135;&#29983;&#19968;&#31181;&#26032;&#30340;&#20272;&#35745;&#22120;&#65292;&#31216;&#20026;&#24863;&#30693;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;PKF&#65289;&#65292;&#23427;&#26159;&#22312;&#27492;&#32422;&#26463;&#26465;&#20214;&#19979;&#30340;&#26368;&#20248;&#20272;&#35745;&#22120;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20854;&#22312;&#32447;&#23454;&#29616;&#30340;&#23454;&#38469;&#31639;&#27861;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23454;&#26102;&#25805;&#20316;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;PKF&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#20272;&#35745;&#20449;&#21495;&#30340;&#24863;&#30693;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many practical settings call for the reconstruction of temporal signals from corrupted or missing data. Classic examples include decoding, tracking, signal enhancement and denoising. Since the reconstructed signals are ultimately viewed by humans, it is desirable to achieve reconstructions that are pleasing to human perception. Mathematically, perfect perceptual-quality is achieved when the distribution of restored signals is the same as that of natural signals, a requirement which has been heavily researched in static estimation settings (i.e. when a whole signal is processed at once). Here, we study the problem of optimal causal filtering under a perfect perceptual-quality constraint, which is a task of fundamentally different nature. Specifically, we analyze a Gaussian Markov signal observed through a linear noisy transformation. In the absence of perceptual constraints, the Kalman filter is known to be optimal in the MSE sense for this setting. Here, we show that adding the perfect
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21033;&#26222;&#24076;&#33576;&#21160;&#24577;&#39118;&#38505;&#24230;&#37327;&#30340;&#39118;&#38505;&#25935;&#24863;&#24378;&#21270;&#23398;&#20064;&#65292;&#24182;&#24314;&#31435;&#20102;&#36951;&#25022;&#19978;&#38480;&#21644;&#19979;&#38480;&#65292;&#19978;&#38480;&#34920;&#26126;&#20102;&#26368;&#20339;&#20381;&#36182;&#20851;&#31995;&#21644;&#39118;&#38505;&#25935;&#24863;&#24615;&#19982;&#26679;&#26412;&#22797;&#26434;&#24615;&#20043;&#38388;&#30340;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2306.02399</link><description>&lt;p&gt;
&#21033;&#26222;&#24076;&#33576;&#21160;&#24577;&#39118;&#38505;&#24230;&#37327;&#30340;&#39118;&#38505;&#25935;&#24863;&#24378;&#21270;&#23398;&#20064;&#30340;&#36951;&#25022;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Regret Bounds for Risk-sensitive Reinforcement Learning with Lipschitz Dynamic Risk Measures. (arXiv:2306.02399v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02399
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21033;&#26222;&#24076;&#33576;&#21160;&#24577;&#39118;&#38505;&#24230;&#37327;&#30340;&#39118;&#38505;&#25935;&#24863;&#24378;&#21270;&#23398;&#20064;&#65292;&#24182;&#24314;&#31435;&#20102;&#36951;&#25022;&#19978;&#38480;&#21644;&#19979;&#38480;&#65292;&#19978;&#38480;&#34920;&#26126;&#20102;&#26368;&#20339;&#20381;&#36182;&#20851;&#31995;&#21644;&#39118;&#38505;&#25935;&#24863;&#24615;&#19982;&#26679;&#26412;&#22797;&#26434;&#24615;&#20043;&#38388;&#30340;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21253;&#21547;&#21160;&#24577;&#39118;&#38505;&#24230;&#37327;&#30340;&#26377;&#38480;&#24773;&#33410;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65292;&#20197;&#25429;&#25417;&#39118;&#38505;&#25935;&#24863;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#24212;&#29992;&#20110;&#21033;&#26222;&#24076;&#33576;&#21160;&#24577;&#39118;&#38505;&#24230;&#37327;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#31639;&#27861;&#65292;&#21033;&#26222;&#24076;&#33576;&#21160;&#24577;&#39118;&#38505;&#24230;&#37327;&#26159;&#19968;&#31181;&#24191;&#27867;&#30340;&#39118;&#38505;&#24230;&#37327;&#65292;&#21253;&#25324;&#35889;&#39118;&#38505;&#24230;&#37327;&#12289;&#20248;&#21270;&#30830;&#23450;&#31561;&#20215;&#12289;&#22833;&#30495;&#39118;&#38505;&#24230;&#37327;&#31561;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#36951;&#25022;&#19978;&#38480;&#21644;&#19979;&#38480;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#19978;&#38480;&#34920;&#26126;&#20102;&#21160;&#20316;&#25968;&#37327;&#21644;&#24773;&#33410;&#25968;&#37327;&#30340;&#26368;&#20339;&#20381;&#36182;&#20851;&#31995;&#65292;&#21516;&#26102;&#21453;&#26144;&#20102;&#39118;&#38505;&#25935;&#24863;&#24615;&#21644;&#26679;&#26412;&#22797;&#26434;&#24615;&#20043;&#38388;&#22266;&#26377;&#30340;&#24179;&#34913;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study finite episodic Markov decision processes incorporating dynamic risk measures to capture risk sensitivity. To this end, we present two model-based algorithms applied to \emph{Lipschitz} dynamic risk measures, a wide range of risk measures that subsumes spectral risk measure, optimized certainty equivalent, distortion risk measures among others. We establish both regret upper bounds and lower bounds. Notably, our upper bounds demonstrate optimal dependencies on the number of actions and episodes, while reflecting the inherent trade-off between risk sensitivity and sample complexity. Additionally, we substantiate our theoretical results through numerical experiments.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24314;&#31435;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#20219;&#20309;&#30830;&#23450;&#24615;&#21462;&#26679;&#26041;&#26696;&#30340;&#31934;&#30830;&#21644;&#36817;&#20284;&#20302;&#31209;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#30340;&#29702;&#35770;&#20445;&#35777;&#26041;&#27861;&#65292;&#24182;&#19988;&#29702;&#35770;&#26174;&#33879;&#25913;&#36827;&#20102;&#24050;&#26377;&#24037;&#20316;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.02283</link><description>&lt;p&gt;
&#20174;&#19968;&#33324;&#30340;&#30830;&#23450;&#24615;&#21462;&#26679;&#27169;&#24335;&#20013;&#36827;&#34892;&#30697;&#38453;&#34917;&#20840;
&lt;/p&gt;
&lt;p&gt;
Matrix Completion from General Deterministic Sampling Patterns. (arXiv:2306.02283v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02283
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24314;&#31435;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#20219;&#20309;&#30830;&#23450;&#24615;&#21462;&#26679;&#26041;&#26696;&#30340;&#31934;&#30830;&#21644;&#36817;&#20284;&#20302;&#31209;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#30340;&#29702;&#35770;&#20445;&#35777;&#26041;&#27861;&#65292;&#24182;&#19988;&#29702;&#35770;&#26174;&#33879;&#25913;&#36827;&#20102;&#24050;&#26377;&#24037;&#20316;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#22823;&#22810;&#25968;&#20302;&#31209;&#30697;&#38453;&#34917;&#20840;&#31639;&#27861;&#30340;&#21487;&#35777;&#20445;&#35777;&#37117;&#20381;&#36182;&#20110;&#19968;&#20123;&#19981;&#20999;&#23454;&#38469;&#30340;&#20551;&#35774;&#65292;&#20363;&#22914;&#30697;&#38453;&#26465;&#30446;&#26159;&#38543;&#26426;&#37319;&#26679;&#30340;&#65292;&#25110;&#32773;&#37319;&#26679;&#27169;&#24335;&#20855;&#26377;&#29305;&#23450;&#30340;&#32467;&#26500;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#29702;&#35770;&#20445;&#35777;&#65292;&#36866;&#29992;&#20110;&#20219;&#20309;&#30830;&#23450;&#24615;&#21462;&#26679;&#26041;&#26696;&#30340;&#31934;&#30830;&#21644;&#36817;&#20284;&#20302;&#31209;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#19968;&#20010;&#22270;&#24418;&#65292;&#20854;&#20013;&#35266;&#23519;&#21040;&#30340;&#26465;&#30446;&#20316;&#20026;&#20854;&#36793;&#30028;&#65292;&#24182;&#30740;&#31350;&#20102;&#23427;&#30340;&#22270;&#24418;&#23646;&#24615;&#65292;&#21253;&#25324;&#26631;&#20934;&#32422;&#26463;&#26680;&#33539;&#25968;&#26368;&#23567;&#21270;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#20174;&#29702;&#35770;&#21644;&#23454;&#39564;&#19978;&#35777;&#26126;&#65292;&#24403;&#35266;&#23519;&#22270;&#24418;&#36830;&#25509;&#33391;&#22909;&#24182;&#19988;&#20855;&#26377;&#31867;&#20284;&#30340;&#33410;&#28857;&#24230;&#26102;&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#25104;&#21151;&#36816;&#34892;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#21487;&#20197;&#30475;&#20316;&#26159; Bhojanapalli &#21644; Jain [2014] &#20197;&#21450; Burnwal &#21644; Vidyasagar [2020] &#30340;&#24037;&#20316;&#30340;&#25193;&#23637;&#65292;&#22312;&#20854;&#20013;&#35266;&#23519;&#22270;&#30340;&#33410;&#28857;&#24230;&#34987;&#20551;&#23450;&#20026;&#30456;&#21516;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30340;&#29702;&#35770;&#26174;&#33879;&#25913;&#36827;&#20102;&#36825;&#20123;&#24037;&#20316;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most of the existing works on provable guarantees for low-rank matrix completion algorithms rely on some unrealistic assumptions such that matrix entries are sampled randomly or the sampling pattern has a specific structure. In this work, we establish theoretical guarantee for the exact and approximate low-rank matrix completion problems which can be applied to any deterministic sampling schemes. For this, we introduce a graph having observed entries as its edge set, and investigate its graph properties involving the performance of the standard constrained nuclear norm minimization algorithm. We theoretically and experimentally show that the algorithm can be successful as the observation graph is well-connected and has similar node degrees. Our result can be viewed as an extension of the works by Bhojanapalli and Jain [2014] and Burnwal and Vidyasagar [2020], in which the node degrees of the observation graph were assumed to be the same. In particular, our theory significantly improves
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#20808;&#21069;&#24037;&#20316;&#24369;&#19968;&#31867;&#38382;&#39064;&#36827;&#34892;&#25512;&#24191;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;&#38750;&#32447;&#24615;&#28151;&#21512;&#19979;&#30340;&#24178;&#39044;&#20013;&#23398;&#20064;&#32447;&#24615;&#22240;&#26524;&#34920;&#31034;&#30340;&#24378;&#21487;&#35782;&#21035;&#24615;&#31639;&#27861;&#65292;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#22312;&#23454;&#36341;&#20013;&#35782;&#21035;&#28508;&#22312;&#21464;&#37327;&#30340;&#23545;&#27604;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.02235</link><description>&lt;p&gt;
&#20174;&#38750;&#32447;&#24615;&#28151;&#21512;&#19979;&#30340;&#24178;&#39044;&#20013;&#23398;&#20064;&#32447;&#24615;&#22240;&#26524;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Learning Linear Causal Representations from Interventions under General Nonlinear Mixing. (arXiv:2306.02235v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02235
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#20808;&#21069;&#24037;&#20316;&#24369;&#19968;&#31867;&#38382;&#39064;&#36827;&#34892;&#25512;&#24191;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;&#38750;&#32447;&#24615;&#28151;&#21512;&#19979;&#30340;&#24178;&#39044;&#20013;&#23398;&#20064;&#32447;&#24615;&#22240;&#26524;&#34920;&#31034;&#30340;&#24378;&#21487;&#35782;&#21035;&#24615;&#31639;&#27861;&#65292;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#22312;&#23454;&#36341;&#20013;&#35782;&#21035;&#28508;&#22312;&#21464;&#37327;&#30340;&#23545;&#27604;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#28151;&#21512;&#20989;&#25968;&#23436;&#20840;&#36890;&#29992;&#30340;&#19968;&#33324;&#35774;&#32622;&#19979;&#65292;&#20174;&#26410;&#30693;&#30340;&#28508;&#22312;&#24178;&#39044;&#20013;&#23398;&#20064;&#22240;&#26524;&#34920;&#31034;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#28508;&#22312;&#20998;&#24067;&#26159;&#39640;&#26031;&#20998;&#24067;&#12290; &#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#21333;&#33410;&#28857;&#26410;&#30693;&#24178;&#39044;&#65288;&#21363;&#27809;&#26377;&#24178;&#39044;&#30446;&#26631;&#30340;&#24773;&#20917;&#19979;&#65289;&#32473;&#20986;&#24378;&#21487;&#35782;&#21035;&#24615;&#32467;&#26524;&#12290;&#36825;&#25512;&#24191;&#20102;&#20808;&#21069;&#30340;&#24037;&#20316;&#65292;&#20808;&#21069;&#30340;&#24037;&#20316;&#30528;&#37325;&#20110;&#26356;&#24369;&#30340;&#31867;&#21035;&#65292;&#20363;&#22914;&#32447;&#24615;&#26144;&#23556;&#25110;&#25104;&#23545;&#30340;&#21453;&#20107;&#23454;&#25968;&#25454;&#12290;&#36825;&#20063;&#26159;&#39318;&#27425;&#20174;&#38750;&#37197;&#23545;&#24178;&#39044;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23884;&#20837;&#20013;&#33719;&#24471;&#22240;&#26524;&#21487;&#35782;&#21035;&#24615;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#20381;&#36182;&#20110;&#20180;&#32454;&#25581;&#31034;&#32463;&#36807;&#38750;&#32447;&#24615;&#23494;&#24230;&#36716;&#25442;&#21518;&#25968;&#25454;&#20998;&#24067;&#20013;&#23384;&#22312;&#30340;&#39640;&#32500;&#20960;&#20309;&#32467;&#26500;&#65292;&#25105;&#20204;&#36890;&#36807;&#20998;&#26512;&#28508;&#22312;&#20998;&#24067;&#30340;&#31934;&#24230;&#30697;&#38453;&#30340;&#20108;&#27425;&#24418;&#24335;&#26469;&#25429;&#25417;&#36825;&#31181;&#32467;&#26500;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#27604;&#31639;&#27861;&#26469;&#23454;&#38469;&#35782;&#21035;&#28508;&#22312;&#21464;&#37327;&#65292;&#24182;&#35780;&#20272;&#20854;&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of learning causal representations from unknown, latent interventions in a general setting, where the latent distribution is Gaussian but the mixing function is completely general. We prove strong identifiability results given unknown single-node interventions, i.e., without having access to the intervention targets. This generalizes prior works which have focused on weaker classes, such as linear maps or paired counterfactual data. This is also the first instance of causal identifiability from non-paired interventions for deep neural network embeddings. Our proof relies on carefully uncovering the high-dimensional geometric structure present in the data distribution after a non-linear density transformation, which we capture by analyzing quadratic forms of precision matrices of the latent distributions. Finally, we propose a contrastive algorithm to identify the latent variables in practice and evaluate its performance on various tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#36895;&#25311;&#29275;&#39039;&#36817;&#31471;&#22806;&#25512;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#26080;&#32422;&#26463;&#24179;&#28369;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#22312;$k = {O}(d)$&#26102;&#36798;&#21040;&#26368;&#20248;&#36895;&#29575;&#65292;&#24182;&#22312;$k = \Omega(d \log d)$&#26102;&#20197;&#26356;&#24555;&#30340;&#36895;&#29575;&#25910;&#25947;&#12290;&#36825;&#26159;&#22312;&#20984;&#35774;&#32622;&#20013;&#65292;&#39318;&#20010;&#35777;&#26126;&#25311;&#29275;&#39039;&#31867;&#22411;&#26041;&#27861;&#27604;NAG&#26377;&#21487;&#35777;&#26126;&#20248;&#21183;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.02212</link><description>&lt;p&gt;
&#21152;&#36895;&#25311;&#29275;&#39039;&#36817;&#31471;&#22806;&#25512;&#27861;&#65306;&#24179;&#28369;&#20984;&#20248;&#21270;&#26356;&#24555;&#30340;&#25910;&#25947;&#29575;
&lt;/p&gt;
&lt;p&gt;
Accelerated Quasi-Newton Proximal Extragradient: Faster Rate for Smooth Convex Optimization. (arXiv:2306.02212v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02212
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#36895;&#25311;&#29275;&#39039;&#36817;&#31471;&#22806;&#25512;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#26080;&#32422;&#26463;&#24179;&#28369;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#22312;$k = {O}(d)$&#26102;&#36798;&#21040;&#26368;&#20248;&#36895;&#29575;&#65292;&#24182;&#22312;$k = \Omega(d \log d)$&#26102;&#20197;&#26356;&#24555;&#30340;&#36895;&#29575;&#25910;&#25947;&#12290;&#36825;&#26159;&#22312;&#20984;&#35774;&#32622;&#20013;&#65292;&#39318;&#20010;&#35777;&#26126;&#25311;&#29275;&#39039;&#31867;&#22411;&#26041;&#27861;&#27604;NAG&#26377;&#21487;&#35777;&#26126;&#20248;&#21183;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#36895;&#25311;&#29275;&#39039;&#36817;&#31471;&#22806;&#25512;&#65288;A-QPNE&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#26080;&#32422;&#26463;&#24179;&#28369;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#20165;&#21033;&#29992;&#30446;&#26631;&#20989;&#25968;&#30340;&#26799;&#24230;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#36798;&#21040;&#25910;&#25947;&#36895;&#29575;${O}\bigl(\min\{\frac{1}{k^2}, \frac{\sqrt{d\log k}}{k^{2.5}}\}\bigr)$&#65292;&#20854;&#20013;$d$&#26159;&#38382;&#39064;&#32500;&#24230;&#65292;$k$&#26159;&#36845;&#20195;&#27425;&#25968;&#12290;&#29305;&#21035;&#22320;&#65292;&#22312;$k = {O}(d)$&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;Nesterov&#21152;&#36895;&#26799;&#24230;&#65288;NAG&#65289;&#36798;&#21040;&#20102;$O(\frac{1}{k^2})$&#30340;&#26368;&#20248;&#36895;&#29575;&#12290;&#27492;&#22806;&#65292;&#22312;$k = \Omega(d \log d)$&#30340;&#21306;&#22495;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;NAG&#65292;&#24182;&#20197;&#26356;&#24555;&#30340;&#36895;&#29575;${O}\bigl(\frac{\sqrt{d\log k}}{k^{2.5}}\bigr)$&#25910;&#25947;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#39318;&#20010;&#22312;&#20984;&#35774;&#32622;&#20013;&#35777;&#26126;&#25311;&#29275;&#39039;&#31867;&#22411;&#26041;&#27861;&#27604;NAG&#26377;&#21487;&#35777;&#26126;&#20248;&#21183;&#30340;&#32467;&#26524;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#26679;&#30340;&#32467;&#26524;&#65292;&#25105;&#20204;&#22522;&#20110;Monteiro-Svaiter&#21152;&#36895;&#26694;&#26550;&#30340;&#26368;&#26032;&#21464;&#20307;&#26500;&#24314;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#24182;&#37319;&#29992;&#20102;&#22312;&#32447;&#26799;&#24230;&#20272;&#35745;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose an accelerated quasi-Newton proximal extragradient (A-QPNE) method for solving unconstrained smooth convex optimization problems. With access only to the gradients of the objective, we prove that our method can achieve a convergence rate of ${O}\bigl(\min\{\frac{1}{k^2}, \frac{\sqrt{d\log k}}{k^{2.5}}\}\bigr)$, where $d$ is the problem dimension and $k$ is the number of iterations. In particular, in the regime where $k = {O}(d)$, our method matches the optimal rate of ${O}(\frac{1}{k^2})$ by Nesterov's accelerated gradient (NAG). Moreover, in the the regime where $k = \Omega(d \log d)$, it outperforms NAG and converges at a faster rate of ${O}\bigl(\frac{\sqrt{d\log k}}{k^{2.5}}\bigr)$. To the best of our knowledge, this result is the first to demonstrate a provable gain of a quasi-Newton-type method over NAG in the convex setting. To achieve such results, we build our method on a recent variant of the Monteiro-Svaiter acceleration framework and adopt an onlin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22238;&#31572;&#20102;&#21333;&#36941;&#27969;&#24335;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#36951;&#25022;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#19968;&#20010;&#36951;&#25022;&#19978;&#30028;&#20026;$O(K^{1/3} T^{2/3})$ &#30340;&#31639;&#27861;&#65292;&#35828;&#26126;&#22343;&#21248;&#25506;&#32034;&#26159;&#26368;&#20248;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.02208</link><description>&lt;p&gt;
&#21333;&#36941;&#27969;&#24335;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#32039;&#20945;&#36951;&#25022;&#30028;
&lt;/p&gt;
&lt;p&gt;
Tight Regret Bounds for Single-pass Streaming Multi-armed Bandits. (arXiv:2306.02208v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02208
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22238;&#31572;&#20102;&#21333;&#36941;&#27969;&#24335;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#36951;&#25022;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#19968;&#20010;&#36951;&#25022;&#19978;&#30028;&#20026;$O(K^{1/3} T^{2/3})$ &#30340;&#31639;&#27861;&#65292;&#35828;&#26126;&#22343;&#21248;&#25506;&#32034;&#26159;&#26368;&#20248;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#27969;&#24335;&#22810;&#33218;&#36172;&#21338;&#26426;(MABs) &#30340;&#36951;&#25022;&#26368;&#23567;&#21270;&#24471;&#21040;&#20102;&#24191;&#27867;&#30340;&#30740;&#31350;&#12290;&#22312; $K$ &#33218;&#21644; $T$ &#27425;&#35797;&#39564;&#30340;&#21333;&#36941;&#35774;&#32622;&#20013;&#65292;&#24050;&#32463;&#35777;&#26126;&#20102;&#20219;&#20309;&#20855;&#26377; $o(K)$ &#20869;&#23384;&#30340;&#31639;&#27861;&#30340;&#36951;&#25022;&#19979;&#38480;&#20026; $\Omega(T^{2/3})$ (Maiti&#31561;&#20154; [NeurIPS'21]; Agarwal&#31561;&#20154; [COLT'22])&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#20043;&#21069;&#26368;&#22909;&#30340;&#36951;&#25022;&#19978;&#38480;&#20173;&#28982;&#26159; $O(K^{1/3} T^{2/3}\log^{1/3}(T))$&#65292;&#36825;&#26159;&#36890;&#36807;&#31616;&#21333;&#22343;&#21248;&#25506;&#32034;&#30340;&#27969;&#24335;&#23454;&#29616;&#23454;&#29616;&#30340;&#12290;$O(K^{1/3}\log^{1/3}(T))$ &#30340;&#24046;&#36317;&#30041;&#19979;&#20102;&#21333;&#36941; MABs &#30340;&#26368;&#32039;&#20945;&#30340;&#36951;&#25022;&#30028;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22238;&#31572;&#20102;&#36825;&#20010;&#24320;&#25918;&#24615;&#38382;&#39064;&#65292;&#24182;&#23436;&#25104;&#20102;&#21333;&#36941;&#27969;&#24335; MABs &#30340;&#36951;&#25022;&#26368;&#23567;&#21270;&#22270;&#26223;&#12290;&#25105;&#20204;&#39318;&#20808;&#23558;&#20855;&#26377; $o(K)$ &#20869;&#23384;&#30340;&#31639;&#27861;&#30340;&#36951;&#25022;&#19979;&#38480;&#25913;&#36827;&#20026; $\Omega(K^{1/3}T^{2/3})$&#65292;&#36825;&#19982; $T$ &#30340;&#23545;&#25968;&#22240;&#23376;&#21305;&#37197;&#22343;&#21248;&#25506;&#32034;&#30340;&#36951;&#25022;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102; $\log^{1/3}(T)$ &#22240;&#23376;&#26159;&#19981;&#24517;&#35201;&#30340;&#65292;&#24182;&#20026;&#20219;&#20309; $T$ &#20540;&#25552;&#20379;&#20102;&#36951;&#25022;&#19978;&#30028;&#20026; $O(K^{1/3} T^{2/3})$ &#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#24847;&#21619;&#30528;&#22312;&#25152;&#26377;&#20855;&#26377;&#27425;&#32447;&#24615;&#20869;&#23384;&#30340;&#31639;&#27861;&#20013;&#65292;&#22343;&#21248;&#25506;&#32034;&#26159;&#26412;&#36136;&#19978;&#26368;&#20248;&#31168;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Regret minimization in streaming multi-armed bandits (MABs) has been studied extensively in recent years. In the single-pass setting with $K$ arms and $T$ trials, a regret lower bound of $\Omega(T^{2/3})$ has been proved for any algorithm with $o(K)$ memory (Maiti et al. [NeurIPS'21]; Agarwal at al. [COLT'22]). On the other hand, however, the previous best regret upper bound is still $O(K^{1/3} T^{2/3}\log^{1/3}(T))$, which is achieved by the streaming implementation of the simple uniform exploration. The $O(K^{1/3}\log^{1/3}(T))$ gap leaves the open question of the tight regret bound in the single-pass MABs with sublinear arm memory.  In this paper, we answer this open problem and complete the picture of regret minimization in single-pass streaming MABs. We first improve the regret lower bound to $\Omega(K^{1/3}T^{2/3})$ for algorithms with $o(K)$ memory, which matches the uniform exploration regret up to a logarithm factor in $T$. We then show that the $\log^{1/3}(T)$ factor is not n
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#22411;&#22312;&#32447;&#25512;&#26029;&#31243;&#24207;&#65292;&#23558;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#27861;&#21644;&#20056;&#25968;&#33258;&#20030;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#29992;&#20110;&#38750;&#20984;&#30446;&#26631;&#20989;&#25968;&#30340;&#25512;&#26029;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#36825;&#20123;&#31243;&#24207;&#30340;&#38169;&#35823;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#39564;&#35777;&#20102;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.02205</link><description>&lt;p&gt;
&#38750;&#20984;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20272;&#35745;&#30340;&#22312;&#32447;&#33258;&#20030;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Online Bootstrap Inference with Nonconvex Stochastic Gradient Descent Estimator. (arXiv:2306.02205v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02205
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#22411;&#22312;&#32447;&#25512;&#26029;&#31243;&#24207;&#65292;&#23558;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#27861;&#21644;&#20056;&#25968;&#33258;&#20030;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#29992;&#20110;&#38750;&#20984;&#30446;&#26631;&#20989;&#25968;&#30340;&#25512;&#26029;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#36825;&#20123;&#31243;&#24207;&#30340;&#38169;&#35823;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#39564;&#35777;&#20102;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#27861;&#65288;SGD&#65289;&#22312;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#20013;&#30340;&#32479;&#35745;&#25512;&#26029;&#29702;&#35770;&#29305;&#24615;&#12290;&#30456;&#23545;&#20110;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#36825;&#37096;&#20998;&#20869;&#23481;&#36824;&#27604;&#36739;&#26410;&#34987;&#25506;&#32034;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#26159;&#31532;&#19968;&#31687;&#38024;&#23545;&#21253;&#21547;&#22810;&#20010;&#23616;&#37096;&#26368;&#23567;&#20540;&#21487;&#33021;&#30340;&#36890;&#29992;&#38750;&#20984;&#30446;&#26631;&#20989;&#25968;&#65292;&#20351;&#29992;SGD&#20272;&#35745;&#22120;&#24314;&#31435;&#21487;&#35777;&#26126;&#25512;&#26029;&#31243;&#24207;&#30340;&#35770;&#25991;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#22411;&#22312;&#32447;&#25512;&#26029;&#31243;&#24207;&#65292;&#23558;SGD&#21644;&#20056;&#25968;&#33258;&#20030;&#25216;&#26415;&#30456;&#32467;&#21512;&#12290;&#31532;&#19968;&#31181;&#31243;&#24207;&#20351;&#29992;&#19968;&#33268;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#22120;&#65292;&#24182;&#19988;&#25105;&#20204;&#24314;&#31435;&#20102;&#20854;&#35823;&#24046;&#25910;&#25947;&#36895;&#29575;&#12290;&#31532;&#20108;&#31181;&#31243;&#24207;&#20351;&#29992;&#33258;&#20030;SGD&#20272;&#35745;&#22120;&#26469;&#36924;&#36817;&#26497;&#38480;&#20998;&#24067;&#65292;&#20135;&#29983;&#28176;&#36827;&#26377;&#25928;&#30340;&#33258;&#20030;&#32622;&#20449;&#21306;&#38388;&#12290;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#20004;&#31181;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#36824;&#20135;&#29983;&#20102;&#19968;&#20010;&#20013;&#38388;&#32467;&#26524;&#65306;&#21407;&#22987;SGD&#20272;&#35745;&#22120;&#30340;&#26399;&#26395;&#35823;&#24046;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we investigate the theoretical properties of stochastic gradient descent (SGD) for statistical inference in the context of nonconvex optimization problems, which have been relatively unexplored compared to convex settings. Our study is the first to establish provable inferential procedures using the SGD estimator for general nonconvex objective functions, which may contain multiple local minima.  We propose two novel online inferential procedures that combine SGD and the multiplier bootstrap technique. The first procedure employs a consistent covariance matrix estimator, and we establish its error convergence rate. The second procedure approximates the limit distribution using bootstrap SGD estimators, yielding asymptotically valid bootstrap confidence intervals. We validate the effectiveness of both approaches through numerical experiments.  Furthermore, our analysis yields an intermediate result: the in-expectation error convergence rate for the original SGD estimator 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#38598;&#25104;&#26041;&#27861;&#25581;&#31034;&#35757;&#32451;&#25968;&#25454;&#23545;&#25193;&#25955;&#27169;&#22411;&#36755;&#20986;&#24433;&#21709;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#27169;&#22411;&#38598;&#21512;&#21487;&#20197;&#26377;&#25928;&#20943;&#24369;&#35757;&#32451;&#25968;&#25454;&#30340;&#24433;&#21709;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#35780;&#20272;&#35757;&#32451;&#25968;&#25454;&#23545;&#27169;&#22411;&#36755;&#20986;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2306.02174</link><description>&lt;p&gt;
&#31070;&#32463;&#25193;&#25955;&#27169;&#22411;&#30340;&#35757;&#32451;&#25968;&#25454;&#24402;&#22240;
&lt;/p&gt;
&lt;p&gt;
Training Data Attribution for Diffusion Models. (arXiv:2306.02174v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02174
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#38598;&#25104;&#26041;&#27861;&#25581;&#31034;&#35757;&#32451;&#25968;&#25454;&#23545;&#25193;&#25955;&#27169;&#22411;&#36755;&#20986;&#24433;&#21709;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#27169;&#22411;&#38598;&#21512;&#21487;&#20197;&#26377;&#25928;&#20943;&#24369;&#35757;&#32451;&#25968;&#25454;&#30340;&#24433;&#21709;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#35780;&#20272;&#35757;&#32451;&#25968;&#25454;&#23545;&#27169;&#22411;&#36755;&#20986;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#31070;&#32463;&#25193;&#25955;&#27169;&#22411;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#65292;&#29992;&#20110;&#21512;&#25104;&#39640;&#36136;&#37327;&#26679;&#26412;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#22823;&#23567;&#20063;&#19981;&#26029;&#22686;&#21152;&#65292;&#35780;&#20272;&#35757;&#32451;&#25968;&#25454;&#23545;&#35757;&#32451;&#21518;&#30340;&#27169;&#22411;&#29983;&#25104;&#26679;&#26412;&#30340;&#24433;&#21709;&#21464;&#24471;&#22256;&#38590;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#38598;&#25104;&#26041;&#27861;&#25581;&#31034;&#35757;&#32451;&#25968;&#25454;&#23545;&#25193;&#25955;&#27169;&#22411;&#36755;&#20986;&#30340;&#24433;&#21709;&#30340;&#26032;&#26041;&#27861;&#12290;&#22312;&#36825;&#31181;&#26041;&#27861;&#20013;&#65292;&#23545;&#25972;&#20010;&#35757;&#32451;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#31934;&#24515;&#35774;&#35745;&#30340;&#20998;&#35010;&#65292;&#24182;&#22312;&#32534;&#30721;&#38598;&#21512;&#20013;&#35757;&#32451;&#21333;&#20010;&#27169;&#22411;&#65292;&#20197;&#20801;&#35768;&#35782;&#21035;&#26377;&#24433;&#21709;&#21147;&#30340;&#35757;&#32451;&#31034;&#20363;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#27169;&#22411;&#38598;&#21512;&#21487;&#20197;&#26377;&#25928;&#20943;&#24369;&#35757;&#32451;&#25968;&#25454;&#30340;&#24433;&#21709;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#35780;&#20272;&#35757;&#32451;&#25968;&#25454;&#23545;&#27169;&#22411;&#36755;&#20986;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;&#38598;&#21512;&#20316;&#20026;&#29983;&#25104;&#27169;&#22411;&#30340;&#21487;&#34892;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models have become increasingly popular for synthesizing high-quality samples based on training datasets. However, given the oftentimes enormous sizes of the training datasets, it is difficult to assess how training data impact the samples produced by a trained diffusion model. The difficulty of relating diffusion model inputs and outputs poses significant challenges to model explainability and training data attribution. Here we propose a novel solution that reveals how training data influence the output of diffusion models through the use of ensembles. In our approach individual models in an encoded ensemble are trained on carefully engineered splits of the overall training data to permit the identification of influential training examples. The resulting model ensembles enable efficient ablation of training data influence, allowing us to assess the impact of training data on model outputs. We demonstrate the viability of these ensembles as generative models and the validity 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#38646;&#38454;&#22024;&#26434;&#27491;&#21017;&#20449;&#24687;&#30340;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#38024;&#23545;&#39640;&#20809;&#28369;&#20989;&#25968;&#31867;&#25512;&#23548;&#20102;&#20004;&#31181;&#38646;&#38454;&#25237;&#24433;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.02159</link><description>&lt;p&gt;
&#39640;&#20809;&#28369;&#20989;&#25968;&#30340;&#26080;&#26799;&#24230;&#20248;&#21270;&#65306;&#25913;&#36827;&#20998;&#26512;&#19982;&#26032;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Gradient-free optimization of highly smooth functions: improved analysis and a new algorithm. (arXiv:2306.02159v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02159
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#38646;&#38454;&#22024;&#26434;&#27491;&#21017;&#20449;&#24687;&#30340;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#38024;&#23545;&#39640;&#20809;&#28369;&#20989;&#25968;&#31867;&#25512;&#23548;&#20102;&#20004;&#31181;&#38646;&#38454;&#25237;&#24433;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20855;&#26377;&#38646;&#38454;&#22024;&#26434;&#27491;&#21017;&#20449;&#24687;&#30340;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#20551;&#35774;&#30446;&#26631;&#20989;&#25968;&#39640;&#24230;&#20809;&#28369;&#19988;&#21487;&#33021;&#28385;&#36275;&#38468;&#21152;&#23646;&#24615;&#12290;&#25105;&#20204;&#32771;&#34385;&#20004;&#31181;&#38646;&#38454;&#25237;&#24433;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#20854;&#26799;&#24230;&#20272;&#35745;&#22120;&#24418;&#24335;&#19981;&#21516;&#12290;&#31532;&#19968;&#20010;&#31639;&#27861;&#20351;&#29992;&#22522;&#20110;Bach&#21644;Perchet&#65288;2016&#65289;&#30340;L2&#29699;&#19978;&#38543;&#26426;&#21270;&#30340;&#26799;&#24230;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#22312;&#20808;&#21069;&#24037;&#20316;&#20013;&#30740;&#31350;&#30340;&#39640;&#20809;&#28369;&#21644;&#24378;&#20984;&#20989;&#25968;&#31867;&#19978;&#21576;&#29616;&#20102;&#35813;&#31639;&#27861;&#30340;&#25913;&#36827;&#20998;&#26512;&#65292;&#24182;&#38024;&#23545;&#20004;&#20010;&#26356;&#19968;&#33324;&#30340;&#38750;&#20984;&#20989;&#25968;&#31867;&#25512;&#23548;&#20102;&#25910;&#25947;&#36895;&#29575;&#12290;&#21363;&#65292;&#25105;&#20204;&#32771;&#34385;&#28385;&#36275;Polyak-Lojasiewicz&#26465;&#20214;&#30340;&#39640;&#20809;&#28369;&#20989;&#25968;&#21644;&#27809;&#26377;&#38468;&#21152;&#23646;&#24615;&#30340;&#39640;&#20809;&#28369;&#20989;&#25968;&#31867;&#12290;&#31532;&#20108;&#20010;&#31639;&#27861;&#22522;&#20110;L1&#29699;&#19978;&#30340;&#38543;&#26426;&#21270;&#65292;&#24182;&#23558;&#26368;&#36817;&#20026;Lipschitz&#20989;&#25968;&#25552;&#20986;&#30340;&#31639;&#27861;&#25193;&#23637;&#21040;&#39640;&#20809;&#28369;&#35774;&#32622;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work studies minimization problems with zero-order noisy oracle information under the assumption that the objective function is highly smooth and possibly satisfies additional properties. We consider two kinds of zero-order projected gradient descent algorithms, which differ in the form of the gradient estimator. The first algorithm uses a gradient estimator based on randomization over the $\ell_2$ sphere due to Bach and Perchet (2016). We present an improved analysis of this algorithm on the class of highly smooth and strongly convex functions studied in the prior work, and we derive rates of convergence for two more general classes of non-convex functions. Namely, we consider highly smooth functions satisfying the Polyak-{\L}ojasiewicz condition and the class of highly smooth functions with no additional property. The second algorithm is based on randomization over the $\ell_1$ sphere, and it extends to the highly smooth setting the algorithm that was recently proposed for Lipsc
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;DU-Shapley&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26356;&#26377;&#25928;&#22320;&#35745;&#31639;Shapley&#20540;&#65292;&#20197;&#23454;&#29616;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#25968;&#25454;&#38598;&#20215;&#20540;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2306.02071</link><description>&lt;p&gt;
DU-Shapley: &#19968;&#31181;&#26377;&#25928;&#30340;&#25968;&#25454;&#38598;&#20215;&#20540;&#35780;&#20272;&#30340;Shapley&#20540;&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
DU-Shapley: A Shapley Value Proxy for Efficient Dataset Valuation. (arXiv:2306.02071v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02071
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;DU-Shapley&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26356;&#26377;&#25928;&#22320;&#35745;&#31639;Shapley&#20540;&#65292;&#20197;&#23454;&#29616;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#25968;&#25454;&#38598;&#20215;&#20540;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#38656;&#35201;&#36827;&#34892;&#25968;&#25454;&#38598;&#35780;&#20272;&#65292;&#21363;&#37327;&#21270;&#23558;&#19968;&#20010;&#21333;&#29420;&#30340;&#25968;&#25454;&#38598;&#19982;&#20854;&#20182;&#25968;&#25454;&#38598;&#32858;&#21512;&#30340;&#22686;&#37327;&#25910;&#30410;&#65292;&#20197;&#26576;&#20123;&#30456;&#20851;&#39044;&#23450;&#20041;&#20844;&#29992;&#20107;&#19994;&#20026;&#22522;&#30784;&#12290;&#26368;&#36817;&#65292;Shapley&#20540;&#34987;&#25552;&#20986;&#20316;&#20026;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#30340;&#19968;&#31181;&#22522;&#26412;&#24037;&#20855;&#65292;&#22240;&#20026;&#23427;&#20855;&#26377;&#24418;&#24335;&#20844;&#29702;&#35777;&#26126;&#12290;&#30001;&#20110;&#20854;&#35745;&#31639;&#36890;&#24120;&#38656;&#35201;&#25351;&#25968;&#26102;&#38388;&#65292;&#22240;&#27492;&#32771;&#34385;&#22522;&#20110;Monte Carlo&#31215;&#20998;&#30340;&#26631;&#20934;&#36817;&#20284;&#31574;&#30053;&#12290;&#28982;&#32780;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#36825;&#31181;&#36890;&#29992;&#36817;&#20284;&#26041;&#27861;&#20173;&#28982;&#26114;&#36149;&#12290;&#26412;&#25991;&#21033;&#29992;&#25968;&#25454;&#38598;&#35780;&#20272;&#38382;&#39064;&#30340;&#32467;&#26500;&#30693;&#35782;&#65292;&#35774;&#35745;&#20102;&#26356;&#26377;&#25928;&#30340;Shapley&#20540;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;Shapley&#20540;&#36817;&#20284;&#65292;&#31216;&#20026;&#31163;&#25955;&#22343;&#21248;Shapley (DU-Shapley)&#65292;&#20854;&#34920;&#36798;&#20026;&#26399;&#26395;&#20540;
&lt;/p&gt;
&lt;p&gt;
Many machine learning problems require performing dataset valuation, i.e. to quantify the incremental gain, to some relevant pre-defined utility, of aggregating an individual dataset to others. As seminal examples, dataset valuation has been leveraged in collaborative and federated learning to create incentives for data sharing across several data owners. The Shapley value has recently been proposed as a principled tool to achieve this goal due to formal axiomatic justification. Since its computation often requires exponential time, standard approximation strategies based on Monte Carlo integration have been considered. Such generic approximation methods, however, remain expensive in some cases. In this paper, we exploit the knowledge about the structure of the dataset valuation problem to devise more efficient Shapley value estimators. We propose a novel approximation of the Shapley value, referred to as discrete uniform Shapley (DU-Shapley) which is expressed as an expectation under 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#39640;&#26031;&#21464;&#20998;&#36807;&#31243;&#21442;&#25968;&#21270;&#26041;&#27861;&#26469;&#26356;&#22909;&#22320;&#23398;&#20064;&#20855;&#26377;&#38750;&#32447;&#24615;&#25193;&#25955;&#36807;&#31243;&#30340;&#28508;&#22312;&#36807;&#31243;&#65292;&#27492;&#26041;&#27861;&#37319;&#29992;&#20855;&#26377;&#36830;&#32493;&#25351;&#25968;&#26063;&#25551;&#36848;&#30340;&#31639;&#27861;&#23454;&#29616;&#20984;&#20248;&#21270;&#65292;&#21487;&#20197;&#20195;&#26367;&#32531;&#24930;&#30340;&#20855;&#26377;&#22266;&#23450;&#28857;&#36845;&#20195;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.02066</link><description>&lt;p&gt;
&#21464;&#20998;&#39640;&#26031;&#36807;&#31243;&#25193;&#25955;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Variational Gaussian Process Diffusion Processes. (arXiv:2306.02066v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02066
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#39640;&#26031;&#21464;&#20998;&#36807;&#31243;&#21442;&#25968;&#21270;&#26041;&#27861;&#26469;&#26356;&#22909;&#22320;&#23398;&#20064;&#20855;&#26377;&#38750;&#32447;&#24615;&#25193;&#25955;&#36807;&#31243;&#30340;&#28508;&#22312;&#36807;&#31243;&#65292;&#27492;&#26041;&#27861;&#37319;&#29992;&#20855;&#26377;&#36830;&#32493;&#25351;&#25968;&#26063;&#25551;&#36848;&#30340;&#31639;&#27861;&#23454;&#29616;&#20984;&#20248;&#21270;&#65292;&#21487;&#20197;&#20195;&#26367;&#32531;&#24930;&#30340;&#20855;&#26377;&#22266;&#23450;&#28857;&#36845;&#20195;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#36807;&#31243;&#26159;&#19968;&#31867;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65292;&#25552;&#20379;&#20102;&#19968;&#31995;&#21015;&#34920;&#29616;&#20016;&#23500;&#30340;&#27169;&#22411;&#65292;&#33258;&#28982;&#22320;&#20986;&#29616;&#22312;&#21160;&#24577;&#24314;&#27169;&#20219;&#21153;&#20013;&#12290;&#27010;&#29575;&#25512;&#29702;&#21644;&#29983;&#25104;&#27169;&#22411;&#19979;&#20855;&#26377;&#38750;&#32447;&#24615;&#25193;&#25955;&#36807;&#31243;&#30340;&#28508;&#22312;&#36807;&#31243;&#30340;&#23398;&#20064;&#37117;&#26159;&#26840;&#25163;&#30340;&#38382;&#39064;&#12290;&#26412;&#25991;&#22312;&#21464;&#20998;&#25512;&#29702;&#30340;&#22522;&#30784;&#19978;&#26500;&#24314;&#39640;&#26031;&#36807;&#31243;&#25193;&#25955;&#36807;&#31243;&#30340;&#21442;&#25968;&#21270;&#65292;&#25351;&#20986;&#26041;&#27861;&#20013;&#30340;&#30149;&#24577;&#65292;&#24182;&#25552;&#20986;&#19968;&#31181;&#20351;&#29992;&#36830;&#32493;&#25351;&#25968;&#26063;&#25551;&#36848;&#30340;&#39640;&#26031;&#21464;&#20998;&#36807;&#31243;&#30340;&#26367;&#20195;&#21442;&#25968;&#21270;&#26041;&#27861;&#12290;&#36825;&#20351;&#25105;&#20204;&#21487;&#20197;&#29992;&#20984;&#20248;&#21270;&#30340;&#24555;&#36895;&#31639;&#27861;&#20195;&#26367;&#20855;&#26377;&#22266;&#23450;&#28857;&#36845;&#20195;&#30340;&#32531;&#24930;&#31639;&#27861;&#65292;&#36825;&#31181;&#31639;&#27861;&#31867;&#20284;&#20110;&#33258;&#28982;&#26799;&#24230;&#19979;&#38477;&#65292;&#21516;&#26102;&#25552;&#20379;&#26356;&#22909;&#30340;&#30446;&#26631;&#26469;&#23398;&#20064;&#27169;&#22411;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion processes are a class of stochastic differential equations (SDEs) providing a rich family of expressive models that arise naturally in dynamic modelling tasks. Probabilistic inference and learning under generative models with latent processes endowed with a non-linear diffusion process prior are intractable problems. We build upon work within variational inference approximating the posterior process as a linear diffusion process, point out pathologies in the approach, and propose an alternative parameterization of the Gaussian variational process using a continuous exponential family description. This allows us to trade a slow inference algorithm with fixed-point iterations for a fast algorithm for convex optimization akin to natural gradient descent, which also provides a better objective for the learning of model parameters.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#26368;&#20248;&#32531;&#23384;&#19982;&#27169;&#22411;&#22797;&#29992;&#20004;&#31181;&#26041;&#27861;&#26469;&#32531;&#35299;&#22823;&#22411;&#27169;&#22411;&#25512;&#29702;&#20013;&#36164;&#28304;&#28040;&#32791;&#21644;&#24310;&#36831;&#25361;&#25112;&#65292;&#32463;&#36807;&#23454;&#35777;&#27169;&#25311;&#21457;&#29616;&#36825;&#31181;&#32452;&#21512;&#22823;&#22823;&#25552;&#39640;&#20102;&#20256;&#32479;&#27169;&#22411;&#25512;&#29702;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.02003</link><description>&lt;p&gt;
&#20851;&#20110;&#22823;&#22411;&#27169;&#22411;&#25512;&#29702;&#20013;&#30340;&#26368;&#20248;&#32531;&#23384;&#19982;&#27169;&#22411;&#22797;&#29992;
&lt;/p&gt;
&lt;p&gt;
On Optimal Caching and Model Multiplexing for Large Model Inference. (arXiv:2306.02003v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02003
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#26368;&#20248;&#32531;&#23384;&#19982;&#27169;&#22411;&#22797;&#29992;&#20004;&#31181;&#26041;&#27861;&#26469;&#32531;&#35299;&#22823;&#22411;&#27169;&#22411;&#25512;&#29702;&#20013;&#36164;&#28304;&#28040;&#32791;&#21644;&#24310;&#36831;&#25361;&#25112;&#65292;&#32463;&#36807;&#23454;&#35777;&#27169;&#25311;&#21457;&#29616;&#36825;&#31181;&#32452;&#21512;&#22823;&#22823;&#25552;&#39640;&#20102;&#20256;&#32479;&#27169;&#22411;&#25512;&#29702;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#20854;&#20182;&#22823;&#22411;&#22522;&#30784;&#27169;&#22411;&#24050;&#32463;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#65292;&#20294;&#20854;&#23610;&#23544;&#21152;&#21095;&#20102;&#29616;&#26377;&#30340;&#36164;&#28304;&#28040;&#32791;&#21644;&#24310;&#36831;&#25361;&#25112;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#32531;&#35299;&#36825;&#20123;&#25361;&#25112;&#65306;&#21033;&#29992;&#32531;&#23384;&#23384;&#20648;&#20808;&#21069;&#30340;&#26597;&#35810;&#21644;&#23398;&#20064;&#27169;&#22411;&#22797;&#29992;&#22120;&#26469;&#36873;&#25321;&#29992;&#20110;&#26597;&#35810;&#22788;&#29702;&#30340;&#27169;&#22411;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26368;&#20248;&#31639;&#27861;&#26469;&#32852;&#21512;&#20248;&#21270;&#36825;&#20004;&#31181;&#26041;&#27861;&#65292;&#20174;&#32780;&#20943;&#23569;&#31163;&#32447;&#21644;&#22312;&#32447;&#21046;&#34920;&#29615;&#22659;&#20013;&#30340;&#25512;&#29702;&#25104;&#26412;&#12290;&#36890;&#36807;&#23558;&#32531;&#23384;&#31639;&#27861;&#21644;&#27169;&#22411;&#22797;&#29992;&#22120;&#30456;&#32467;&#21512;&#65292;&#25105;&#20204;&#22312;&#31163;&#32447;&#21644;&#22312;&#32447;&#35774;&#32622;&#19979;&#37117;&#23454;&#29616;&#20102;&#26368;&#20248;&#24615;&#33021;&#12290;&#23454;&#35777;&#27169;&#25311;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#32531;&#23384;&#21644;&#27169;&#22411;&#22797;&#29992;&#31639;&#27861;&#30340;&#32452;&#21512;&#22823;&#22823;&#25552;&#39640;&#20102;&#20256;&#32479;&#27169;&#22411;&#25512;&#29702;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) and other large foundation models have achieved noteworthy success, but their size exacerbates existing resource consumption and latency challenges. In particular, the large-scale deployment of these models is hindered by the significant resource requirements during inference. In this paper, we study two approaches for mitigating these challenges: employing a cache to store previous queries and learning a model multiplexer to choose from an ensemble of models for query processing.  Theoretically, we provide an optimal algorithm for jointly optimizing both approaches to reduce the inference cost in both offline and online tabular settings. By combining a caching algorithm, namely Greedy Dual Size with Frequency (GDSF) or Least Expected Cost (LEC), with a model multiplexer, we achieve optimal rates in both offline and online settings. Empirically, simulations show that the combination of our caching and model multiplexing algorithms greatly improves over the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#26410;&#30693;&#20998;&#24067;&#20013;&#29983;&#25104;&#30340;&#26080;&#38480;&#22810;&#33218;&#32769;&#34382;&#26426;&#30340;&#32431;&#25506;&#32034;&#38382;&#39064;&#65292;&#26088;&#22312;&#26377;&#25928;&#22320;&#36873;&#25321;&#21333;&#20010;&#39640;&#36136;&#37327;&#33218;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#22266;&#23450;&#32622;&#20449;&#24230;&#21644;&#22266;&#23450;&#39044;&#31639;&#24773;&#20917;&#19979;&#31639;&#27861;&#30340;&#26399;&#26395;&#25110;&#28176;&#36827;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#20197;&#21450;&#26368;&#20248;&#22833;&#25928;&#27010;&#29575;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2306.01995</link><description>&lt;p&gt;
&#26080;&#38480;&#33218;&#32769;&#34382;&#26426;&#30340;&#28176;&#36827;&#26368;&#20248;&#32431;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Asymptotically Optimal Pure Exploration for Infinite-Armed Bandits. (arXiv:2306.01995v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01995
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#26410;&#30693;&#20998;&#24067;&#20013;&#29983;&#25104;&#30340;&#26080;&#38480;&#22810;&#33218;&#32769;&#34382;&#26426;&#30340;&#32431;&#25506;&#32034;&#38382;&#39064;&#65292;&#26088;&#22312;&#26377;&#25928;&#22320;&#36873;&#25321;&#21333;&#20010;&#39640;&#36136;&#37327;&#33218;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#22266;&#23450;&#32622;&#20449;&#24230;&#21644;&#22266;&#23450;&#39044;&#31639;&#24773;&#20917;&#19979;&#31639;&#27861;&#30340;&#26399;&#26395;&#25110;&#28176;&#36827;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#20197;&#21450;&#26368;&#20248;&#22833;&#25928;&#27010;&#29575;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20174;&#26410;&#30693;&#20998;&#24067;&#20013;&#29983;&#25104;&#30340;&#26080;&#38480;&#22810;&#32769;&#34382;&#26426;&#33218;&#30340;&#32431;&#25506;&#32034;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#26377;&#25928;&#22320;&#36873;&#25321;&#21333;&#20010;&#39640;&#36136;&#37327;&#33218;&#65292;&#20854;&#24179;&#22343;&#22870;&#21169;&#22312;&#27010;&#29575;&#20026;$1-\delta$&#30340;&#24773;&#20917;&#19979;&#19982;&#21069;$\eta$&#31561;&#20998;&#30340;&#33218;&#20013;&#65292;&#30456;&#24046;&#19981;&#36229;&#36807;$\varepsilon$&#65307;&#36825;&#26159;&#23545;&#26080;&#38480;&#34892;&#21160;&#38598;&#30340;&#32463;&#20856;&#23454;&#29616;&#21487;&#33021;&#24615;&#20445;&#35777;&#30340;&#33258;&#28982;&#35843;&#25972;&#12290;&#25105;&#20204;&#32771;&#34385;&#22266;&#23450;&#32622;&#20449;&#24230;&#21644;&#22266;&#23450;&#39044;&#31639;&#20004;&#31181;&#24773;&#20917;&#65292;&#20998;&#21035;&#26088;&#22312;&#23454;&#29616;&#26368;&#23567;&#26399;&#26395;&#21644;&#22266;&#23450;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#23545;&#20110;&#22266;&#23450;&#32622;&#20449;&#24230;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#20854;&#26399;&#26395;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$O\left(\frac{\log (1/\eta)\log (1/\delta)}{\eta\varepsilon^2}\right)$&#12290;&#36825;&#26159;&#38500;&#20102;$\log (1/\eta)$&#22240;&#23376;&#20197;&#22806;&#30340;&#26368;&#20248;&#35299;&#65292;&#24182;&#19988;$\delta$&#30340;&#20381;&#36182;&#20851;&#31995;&#22635;&#34917;&#20102;&#25991;&#29486;&#20013;&#20108;&#27425;&#24046;&#36317;&#12290;&#23545;&#20110;&#22266;&#23450;&#39044;&#31639;&#65292;&#25105;&#20204;&#21457;&#29616;&#24403;$\delta\to 0$&#26102;&#65292;&#28176;&#36827;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#26159;$c^{-1}\log(1/\delta)\big(\log\log(1/\delta)\big)^2$&#12290;&#31561;&#20215;&#30340;&#65292;&#32473;&#23450;&#31934;&#30830;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#26102;&#65292;&#26368;&#20248;&#22833;&#25928;&#27010;&#29575;&#26159;&#19968;&#20010;$\log(1/\delta)$&#38454;&#30340;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study pure exploration with infinitely many bandit arms generated i.i.d. from an unknown distribution. Our goal is to efficiently select a single high quality arm whose average reward is, with probability $1-\delta$, within $\varepsilon$ of being among the top $\eta$-fraction of arms; this is a natural adaptation of the classical PAC guarantee for infinite action sets. We consider both the fixed confidence and fixed budget settings, aiming respectively for minimal expected and fixed sample complexity.  For fixed confidence, we give an algorithm with expected sample complexity $O\left(\frac{\log (1/\eta)\log (1/\delta)}{\eta\varepsilon^2}\right)$. This is optimal except for the $\log (1/\eta)$ factor, and the $\delta$-dependence closes a quadratic gap in the literature. For fixed budget, we show the asymptotically optimal sample complexity as $\delta\to 0$ is $c^{-1}\log(1/\delta)\big(\log\log(1/\delta)\big)^2$ to leading order. Equivalently, the optimal failure probability given exa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32473;&#20986;&#20102;&#20851;&#20110;&#20998;&#25968;&#21305;&#37197;&#30340;&#31532;&#19968;&#20010;&#21487;&#35777;&#26126;&#30340;&#25351;&#25968;&#26063;&#30340;&#20363;&#23376;&#65292;&#23637;&#31034;&#20102;&#23427;&#30456;&#23545;&#20110;&#26368;&#22823;&#20284;&#28982;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#32479;&#35745;&#25928;&#29575;&#30340;&#20248;&#36234;&#24615;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#22312;&#19968;&#23450;&#24773;&#20917;&#19979;&#65292;&#26368;&#22823;&#20284;&#28982;&#30340;&#25439;&#22833;&#20989;&#25968;&#26159;&#38590;&#20197;&#20351;&#29992;&#26799;&#24230;&#26041;&#27861;&#26469;&#36827;&#34892;&#20248;&#21270;&#30340;&#12290;</title><link>http://arxiv.org/abs/2306.01993</link><description>&lt;p&gt;
&#20998;&#25968;&#21305;&#37197;&#30340;&#21487;&#35777;&#26126;&#22909;&#22788;
&lt;/p&gt;
&lt;p&gt;
Provable benefits of score matching. (arXiv:2306.01993v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01993
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32473;&#20986;&#20102;&#20851;&#20110;&#20998;&#25968;&#21305;&#37197;&#30340;&#31532;&#19968;&#20010;&#21487;&#35777;&#26126;&#30340;&#25351;&#25968;&#26063;&#30340;&#20363;&#23376;&#65292;&#23637;&#31034;&#20102;&#23427;&#30456;&#23545;&#20110;&#26368;&#22823;&#20284;&#28982;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#32479;&#35745;&#25928;&#29575;&#30340;&#20248;&#36234;&#24615;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#22312;&#19968;&#23450;&#24773;&#20917;&#19979;&#65292;&#26368;&#22823;&#20284;&#28982;&#30340;&#25439;&#22833;&#20989;&#25968;&#26159;&#38590;&#20197;&#20351;&#29992;&#26799;&#24230;&#26041;&#27861;&#26469;&#36827;&#34892;&#20248;&#21270;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#25968;&#21305;&#37197;&#26159;&#20272;&#35745;&#21442;&#25968;&#21270;&#21040;&#27604;&#20363;&#24120;&#25968;&#30340;&#27010;&#29575;&#20998;&#24067;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#36890;&#36807;&#25311;&#21512;&#20998;&#24067;&#30340;&#8220;&#20998;&#25968;&#8221;&#65292;&#23427;&#36991;&#24320;&#20102;&#35745;&#31639;&#27604;&#20363;&#24120;&#25968;&#30340;&#38656;&#27714;&#65288;&#36825;&#36890;&#24120;&#26159;&#26840;&#25163;&#30340;&#65289;&#12290;&#34429;&#28982;&#20998;&#25968;&#21305;&#37197;&#21450;&#20854;&#21464;&#20307;&#22312;&#23454;&#36341;&#20013;&#24456;&#21463;&#27426;&#36814;&#65292;&#20294;&#23545;&#20110;&#19982;&#26368;&#22823;&#20284;&#28982;&#65288;ML&#65289;&#30340;&#22909;&#22788;&#21644;&#26435;&#34913;&#65292;&#26080;&#35770;&#26159;&#35745;&#31639;&#36824;&#26159;&#32479;&#35745;&#65292;&#37117;&#27809;&#26377;&#31934;&#30830;&#30340;&#29702;&#35770;&#29702;&#35299;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#32473;&#20986;&#20102;&#19968;&#20010;&#33258;&#28982;&#25351;&#25968;&#20998;&#24067;&#26063;&#30340;&#20363;&#23376;&#65292;&#20351;&#24471;&#20998;&#25968;&#21305;&#37197;&#25439;&#22833;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#32479;&#35745;&#25928;&#29575;&#19982;ML&#30456;&#24403;&#65292;&#32780;&#20351;&#29992;&#22522;&#20110;&#26799;&#24230;&#30340;&#26041;&#27861;&#20248;&#21270;ML&#25439;&#22833;&#26159;&#26840;&#25163;&#30340;&#12290;&#35813;&#23478;&#26063;&#30001;&#22266;&#23450;&#27425;&#25968;&#30340;&#22810;&#39033;&#24335;&#30340;&#25351;&#25968;&#32452;&#25104;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#21487;&#20197;&#35270;&#20026;&#31163;&#25955;&#24773;&#20917;&#19979;&#26368;&#36817;&#21457;&#23637;&#30340;&#36830;&#32493;&#27169;&#25311;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#65306;&#65288;1&#65289;
&lt;/p&gt;
&lt;p&gt;
Score matching is an alternative to maximum likelihood (ML) for estimating a probability distribution parametrized up to a constant of proportionality. By fitting the ''score'' of the distribution, it sidesteps the need to compute this constant of proportionality (which is often intractable). While score matching and variants thereof are popular in practice, precise theoretical understanding of the benefits and tradeoffs with maximum likelihood -- both computational and statistical -- are not well understood. In this work, we give the first example of a natural exponential family of distributions such that the score matching loss is computationally efficient to optimize, and has a comparable statistical efficiency to ML, while the ML loss is intractable to optimize using a gradient-based method. The family consists of exponentials of polynomials of fixed degree, and our result can be viewed as a continuous analogue of recent developments in the discrete setting. Precisely, we show: (1)
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#32473;&#20986;&#20102;&#19968;&#20010;&#29616;&#26377;&#26041;&#27861;&#31934;&#32454;&#21270;&#30340;&#32467;&#26524;&#65292;&#23454;&#29616;&#20102;&#26080;&#28145;&#24230;&#20381;&#36182;&#24615;&#30340;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2306.01992</link><description>&lt;p&gt;
&#20851;&#20110;ReLU&#32593;&#32476;&#30340;&#22823;&#23567;&#26080;&#20851;&#26679;&#26412;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
On Size-Independent Sample Complexity of ReLU Networks. (arXiv:2306.01992v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01992
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#32473;&#20986;&#20102;&#19968;&#20010;&#29616;&#26377;&#26041;&#27861;&#31934;&#32454;&#21270;&#30340;&#32467;&#26524;&#65292;&#23454;&#29616;&#20102;&#26080;&#28145;&#24230;&#20381;&#36182;&#24615;&#30340;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20174;&#27867;&#21270;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#23398;&#20064;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#22312;&#26435;&#37325;&#30697;&#38453;&#19978;&#32473;&#23450;&#33539;&#25968;&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#65292;&#19968;&#20010;&#24120;&#35265;&#30340;&#26041;&#27861;&#26159;&#20272;&#35745;&#30456;&#20851;&#20989;&#25968;&#31867;&#30340;Rademacher&#22797;&#26434;&#24230;&#12290;&#20043;&#21069;Golowich-Rakhlin-Shamir (2020)&#33719;&#24471;&#20102;&#19968;&#20010;&#19981;&#20381;&#36182;&#20110;&#32593;&#32476;&#22823;&#23567;&#30340;&#65288;&#19982;Frobenius&#33539;&#25968;&#30340;&#20056;&#31215;&#25104;&#27604;&#20363;&#65289;&#19978;&#30028;&#65292;&#38500;&#20102;&#19968;&#20010;&#24179;&#26041;&#26681;&#28145;&#24230;&#30340;&#22240;&#23376;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#20010;&#31934;&#32454;&#21270;&#30340;&#32467;&#26524;&#65292;&#36890;&#24120;&#26681;&#26412;&#27809;&#26377;&#26126;&#26174;&#30340;&#28145;&#24230;&#20381;&#36182;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the sample complexity of learning ReLU neural networks from the point of view of generalization. Given norm constraints on the weight matrices, a common approach is to estimate the Rademacher complexity of the associated function class. Previously Golowich-Rakhlin-Shamir (2020) obtained a bound independent of the network size (scaling with a product of Frobenius norms) except for a factor of the square-root depth. We give a refinement which often has no explicit depth-dependence at all.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#20854;&#32467;&#21512;&#20102;&#25968;&#25454;&#20013;&#32534;&#30721;&#30340;&#26102;&#38388;&#21160;&#24577;&#65292;&#33258;&#28982;&#22320;&#32534;&#30721;&#20102;&#22810;&#27493;&#21644;&#38271;&#31243;&#39044;&#27979;&#33021;&#21147;&#65292;&#20855;&#26377;&#28789;&#27963;&#30340;&#37319;&#26679;&#36712;&#36857;&#21644;&#25240;&#34935;&#24615;&#33021;&#19982;&#21152;&#36895;&#37319;&#26679;&#30340;&#33021;&#21147;&#65292;&#21516;&#26102;&#25552;&#39640;&#20102;&#35745;&#31639;&#25928;&#29575;&#65292;&#21487;&#22312;&#26102;&#31354;&#39044;&#27979;&#26041;&#38754;&#21462;&#24471;&#31454;&#20105;&#24615;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.01984</link><description>&lt;p&gt;
DYffusion&#65306;&#38754;&#21521;&#26102;&#31354;&#39044;&#27979;&#30340;&#21160;&#24577;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
DYffusion: A Dynamics-informed Diffusion Model for Spatiotemporal Forecasting. (arXiv:2306.01984v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01984
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#20854;&#32467;&#21512;&#20102;&#25968;&#25454;&#20013;&#32534;&#30721;&#30340;&#26102;&#38388;&#21160;&#24577;&#65292;&#33258;&#28982;&#22320;&#32534;&#30721;&#20102;&#22810;&#27493;&#21644;&#38271;&#31243;&#39044;&#27979;&#33021;&#21147;&#65292;&#20855;&#26377;&#28789;&#27963;&#30340;&#37319;&#26679;&#36712;&#36857;&#21644;&#25240;&#34935;&#24615;&#33021;&#19982;&#21152;&#36895;&#37319;&#26679;&#30340;&#33021;&#21147;&#65292;&#21516;&#26102;&#25552;&#39640;&#20102;&#35745;&#31639;&#25928;&#29575;&#65292;&#21487;&#22312;&#26102;&#31354;&#39044;&#27979;&#26041;&#38754;&#21462;&#24471;&#31454;&#20105;&#24615;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#25193;&#25955;&#27169;&#22411;&#21487;&#20197;&#25104;&#21151;&#22320;&#29983;&#25104;&#25968;&#25454;&#21644;&#20570;&#20986;&#39044;&#27979;&#65292;&#20294;&#23427;&#20204;&#20027;&#35201;&#26159;&#20026;&#38745;&#24577;&#22270;&#20687;&#35774;&#35745;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#35757;&#32451;&#29992;&#20110;&#21160;&#24577;&#39044;&#27979;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#21033;&#29992;&#32534;&#30721;&#22312;&#25968;&#25454;&#20013;&#30340;&#26102;&#38388;&#21160;&#24577;&#65292;&#30452;&#25509;&#23558;&#20854;&#19982;&#32593;&#32476;&#20013;&#30340;&#25193;&#25955;&#27493;&#39588;&#32806;&#21512;&#12290;&#25105;&#20204;&#35757;&#32451;&#20102;&#19968;&#20010;&#38543;&#26426;&#30340;&#12289;&#26102;&#38388;&#26465;&#20214;&#30340;&#25554;&#20540;&#22120;&#21644;&#19968;&#20010;&#39592;&#24178;&#39044;&#27979;&#32593;&#32476;&#65292;&#20998;&#21035;&#27169;&#20223;&#20256;&#32479;&#25193;&#25955;&#27169;&#22411;&#30340;&#21069;&#21521;&#21644;&#21518;&#21521;&#36807;&#31243;&#12290;&#36825;&#31181;&#35774;&#35745;&#36873;&#25321;&#33258;&#28982;&#22320;&#32534;&#30721;&#20102;&#22810;&#27493;&#21644;&#38271;&#31243;&#39044;&#27979;&#33021;&#21147;&#65292;&#20801;&#35768;&#39640;&#24230;&#28789;&#27963;&#30340;&#36830;&#32493;&#26102;&#38388;&#37319;&#26679;&#36712;&#36857;&#65292;&#24182;&#22312;&#25512;&#29702;&#26102;&#33021;&#22815;&#25240;&#34935;&#24615;&#33021;&#19982;&#21152;&#36895;&#37319;&#26679;&#30340;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#38754;&#21521;&#21160;&#24577;&#30340;&#25193;&#25955;&#36807;&#31243;&#24378;&#21152;&#20102;&#24378;&#30340;&#24402;&#32435;&#20559;&#24046;&#65292;&#30456;&#27604;&#20256;&#32479;&#22522;&#20110;&#39640;&#26031;&#22122;&#22768;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#21487;&#20197;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#27010;&#29575;&#28369;&#38634;&#39044;&#27979;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
While diffusion models can successfully generate data and make predictions, they are predominantly designed for static images. We propose an approach for training diffusion models for dynamics forecasting that leverages the temporal dynamics encoded in the data, directly coupling it with the diffusion steps in the network. We train a stochastic, time-conditioned interpolator and a backbone forecaster network that mimic the forward and reverse processes of conventional diffusion models, respectively. This design choice naturally encodes multi-step and long-range forecasting capabilities, allowing for highly flexible, continuous-time sampling trajectories and the ability to trade-off performance with accelerated sampling at inference time. In addition, the dynamics-informed diffusion process imposes a strong inductive bias, allowing for improved computational efficiency compared to traditional Gaussian noise-based diffusion models. Our approach performs competitively on probabilistic ski
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25581;&#31034;&#20102;&#23618;&#38388;&#21453;&#39304;&#23545;&#40784;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20445;&#23432;&#24615;&#65292;&#24182;&#21457;&#29616;FA&#19982;GD&#20043;&#38388;&#23384;&#22312;&#38544;&#24335;&#20559;&#24046;&#30340;&#30456;&#20284;&#20043;&#22788;&#65292;&#21516;&#26102;&#38416;&#26126;&#20102;ReLU&#32593;&#32476;&#20013;&#19982;&#21453;&#39304;&#30697;&#38453;&#23545;&#40784;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2306.01870</link><description>&lt;p&gt;
&#23618;&#38388;&#21453;&#39304;&#23545;&#40784;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20445;&#23432;&#24615;
&lt;/p&gt;
&lt;p&gt;
Layer-Wise Feedback Alignment is Conserved in Deep Neural Networks. (arXiv:2306.01870v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01870
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25581;&#31034;&#20102;&#23618;&#38388;&#21453;&#39304;&#23545;&#40784;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20445;&#23432;&#24615;&#65292;&#24182;&#21457;&#29616;FA&#19982;GD&#20043;&#38388;&#23384;&#22312;&#38544;&#24335;&#20559;&#24046;&#30340;&#30456;&#20284;&#20043;&#22788;&#65292;&#21516;&#26102;&#38416;&#26126;&#20102;ReLU&#32593;&#32476;&#20013;&#19982;&#21453;&#39304;&#30697;&#38453;&#23545;&#40784;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#25552;&#39640;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#25928;&#29575;&#21644;&#29983;&#29289;&#21487;&#22609;&#24615;&#65292;&#21453;&#39304;&#23545;&#40784;&#65288;FA&#65289;&#20316;&#20026;&#20256;&#32479;&#21453;&#21521;&#20256;&#25773;&#30340;&#26367;&#20195;&#26041;&#27861;&#24212;&#36816;&#32780;&#29983;&#65292;&#23427;&#23558;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#21453;&#21521;&#20256;&#36755;&#26435;&#37325;&#26367;&#25442;&#20026;&#38543;&#26426;&#30697;&#38453;&#12290;&#34429;&#28982;FA&#30340;&#21560;&#24341;&#21147;&#22312;&#20110;&#23427;&#33021;&#22815;&#32469;&#36807;&#35745;&#31639;&#25361;&#25112;&#21644;&#20854;&#21487;&#20449;&#30340;&#29983;&#29289;&#23545;&#40784;&#24615;&#65292;&#20294;&#23545;&#20110;&#36825;&#31181;&#23398;&#20064;&#35268;&#21017;&#30340;&#29702;&#35299;&#36824;&#26159;&#26377;&#25152;&#27424;&#32570;&#30340;&#12290;&#26412;&#25991;&#25581;&#31034;&#20102;&#25903;&#25745;FA&#23398;&#20064;&#21160;&#24577;&#30340;&#19968;&#32452;&#23432;&#24658;&#23450;&#24459;&#65292;&#25581;&#31034;&#20102;FA&#21644;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#20043;&#38388;&#30340;&#26377;&#36259;&#30456;&#20284;&#20043;&#22788;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;FA&#20855;&#26377;&#19982;GD&#34920;&#29616;&#20986;&#30340;&#38544;&#24335;&#20559;&#24046;&#30456;&#20284;&#30340;&#38544;&#24335;&#20559;&#24046;&#65292;&#25361;&#25112;&#20102;&#29616;&#26377;&#30340;&#36825;&#20123;&#23398;&#20064;&#31639;&#27861;&#20043;&#38388;&#26681;&#26412;&#19981;&#21516;&#30340;&#27969;&#34892;&#35828;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#36825;&#20123;&#23432;&#24658;&#23450;&#24459;&#38416;&#26126;&#20102;ReLU&#32593;&#32476;&#20013;&#19982;&#21453;&#39304;&#30697;&#38453;&#23545;&#40784;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#65292;&#36825;&#24847;&#21619;&#30528;&#36807;&#21442;&#25968;&#21270;&#30340;&#21452;&#32447;&#24615;&#32593;&#32476;&#20013;&#21487;&#20197;&#23454;&#29616;&#32447;&#24615;&#22320;&#20195;&#26367;&#21518;&#21521;&#26435;&#37325;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the quest to enhance the efficiency and bio-plausibility of training deep neural networks, Feedback Alignment (FA), which replaces the backward pass weights with random matrices in the training process, has emerged as an alternative to traditional backpropagation. While the appeal of FA lies in its circumvention of computational challenges and its plausible biological alignment, the theoretical understanding of this learning rule remains partial. This paper uncovers a set of conservation laws underpinning the learning dynamics of FA, revealing intriguing parallels between FA and Gradient Descent (GD). Our analysis reveals that FA harbors implicit biases akin to those exhibited by GD, challenging the prevailing narrative that these learning algorithms are fundamentally different. Moreover, we demonstrate that these conservation laws elucidate sufficient conditions for layer-wise alignment with feedback matrices in ReLU networks. We further show that this implies over-parameterized tw
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;cvHM&#65292;&#19968;&#31181;&#20351;&#29992;Hida-Mat'ern&#26680;&#21644;&#20849;&#36717;&#35745;&#31639;&#21464;&#20998;&#25512;&#29702;&#65288;CVI&#65289;&#30340;&#28508;&#22312;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#36890;&#29992;&#25512;&#29702;&#26694;&#26550;&#65292;&#33021;&#22815;&#20197;&#32447;&#24615;&#26102;&#38388;&#22797;&#26434;&#24230;&#25191;&#34892;&#28508;&#22312;&#31070;&#32463;&#36712;&#36857;&#30340;&#21464;&#20998;&#25512;&#26029;&#65292;&#20197;&#36866;&#24212;&#20219;&#24847;&#30340;&#20284;&#28982;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2306.01802</link><description>&lt;p&gt;
&#32447;&#24615;&#26102;&#38388;&#39640;&#26031;&#36807;&#31243;&#25512;&#26029;&#31070;&#32463;&#33033;&#20914;&#24207;&#21015;&#20013;&#30340;&#28508;&#22312;&#36712;&#36857;
&lt;/p&gt;
&lt;p&gt;
Linear Time GPs for Inferring Latent Trajectories from Neural Spike Trains. (arXiv:2306.01802v1 [q-bio.NC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01802
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;cvHM&#65292;&#19968;&#31181;&#20351;&#29992;Hida-Mat'ern&#26680;&#21644;&#20849;&#36717;&#35745;&#31639;&#21464;&#20998;&#25512;&#29702;&#65288;CVI&#65289;&#30340;&#28508;&#22312;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#36890;&#29992;&#25512;&#29702;&#26694;&#26550;&#65292;&#33021;&#22815;&#20197;&#32447;&#24615;&#26102;&#38388;&#22797;&#26434;&#24230;&#25191;&#34892;&#28508;&#22312;&#31070;&#32463;&#36712;&#36857;&#30340;&#21464;&#20998;&#25512;&#26029;&#65292;&#20197;&#36866;&#24212;&#20219;&#24847;&#30340;&#20284;&#28982;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28508;&#22312;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#31070;&#32463;&#31185;&#23398;&#20013;&#65292;&#20197;&#20174;&#39034;&#24207;&#35266;&#27979;&#20013;&#25581;&#31034;&#38544;&#34255;&#29366;&#24577;&#30340;&#28436;&#21270;&#65292;&#20027;&#35201;&#29992;&#20110;&#31070;&#32463;&#27963;&#21160;&#35760;&#24405;&#12290;&#34429;&#28982;&#28508;&#22312;GP&#27169;&#22411;&#22312;&#29702;&#35770;&#19978;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#21407;&#21017;&#21644;&#26377;&#21147;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#22312;&#38750;&#20849;&#36717;&#35774;&#32622;&#20013;&#30340;&#19981;&#21487;&#34892;&#21518;&#39564;&#38656;&#35201;&#36817;&#20284;&#25512;&#26029;&#26041;&#26696;&#65292;&#36825;&#20123;&#26041;&#26696;&#21487;&#33021;&#32570;&#20047;&#21487;&#25193;&#23637;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;cvHM&#65292;&#19968;&#31181;&#20351;&#29992;Hida-Mat'ern&#26680;&#21644;&#20849;&#36717;&#35745;&#31639;&#21464;&#20998;&#25512;&#29702;&#65288;CVI&#65289;&#30340;&#28508;&#22312;GP&#27169;&#22411;&#30340;&#36890;&#29992;&#25512;&#29702;&#26694;&#26550;&#12290;&#20351;&#29992;cvHM&#65292;&#25105;&#20204;&#33021;&#22815;&#20197;&#32447;&#24615;&#26102;&#38388;&#22797;&#26434;&#24230;&#25191;&#34892;&#28508;&#22312;&#31070;&#32463;&#36712;&#36857;&#30340;&#21464;&#20998;&#25512;&#26029;&#65292;&#20197;&#36866;&#24212;&#20219;&#24847;&#30340;&#20284;&#28982;&#20989;&#25968;&#12290;&#20351;&#29992;Hida-Mat'ern GPs&#23545;&#24179;&#31283;&#26680;&#36827;&#34892;&#37325;&#26032;&#21442;&#25968;&#21270;&#65292;&#24110;&#21161;&#25105;&#20204;&#23558;&#32534;&#30721;&#20808;&#21069;&#20551;&#35774;&#30340;&#28508;&#22312;&#21464;&#37327;&#27169;&#22411;&#19982;&#32534;&#30721;&#36712;&#36857;&#20551;&#35774;&#30340;GP&#36830;&#25509;&#36215;&#26469;&#65292;&#36890;&#36807;&#21160;&#21147;&#31995;&#32479;&#12290;&#19982;&#20197;&#21069;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#25105;&#20204;&#20351;&#29992;&#21452;&#21521;&#20449;&#24687;&#36807;&#28388;&#65292;&#23548;&#33268;&#27169;&#22411;&#25512;&#26029;&#26356;&#28165;&#26224;&#65292;&#20272;&#35745;&#26356;&#20934;&#30830;&#12290;
&lt;/p&gt;
&lt;p&gt;
Latent Gaussian process (GP) models are widely used in neuroscience to uncover hidden state evolutions from sequential observations, mainly in neural activity recordings. While latent GP models provide a principled and powerful solution in theory, the intractable posterior in non-conjugate settings necessitates approximate inference schemes, which may lack scalability. In this work, we propose cvHM, a general inference framework for latent GP models leveraging Hida-Mat\'ern kernels and conjugate computation variational inference (CVI). With cvHM, we are able to perform variational inference of latent neural trajectories with linear time complexity for arbitrary likelihoods. The reparameterization of stationary kernels using Hida-Mat\'ern GPs helps us connect the latent variable models that encode prior assumptions through dynamical systems to those that encode trajectory assumptions through GPs. In contrast to previous work, we use bidirectional information filtering, leading to a more
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#65292;&#20854;&#20013;iDP-SignRP&#31639;&#27861;&#22312;&#20010;&#20307;&#24046;&#20998;&#38544;&#31169;&#35774;&#32622;&#19979;&#25928;&#26524;&#26174;&#33879;&#65292;DP-SignOPORP&#31639;&#27861;&#25913;&#36827;&#20102;&#29616;&#26377;&#31639;&#27861;&#65292;DP-OPORP&#31639;&#27861;&#34920;&#29616;&#26368;&#20248;&#65292;iDP&#25552;&#20379;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#29305;&#23450;&#25968;&#25454;&#38598;&#30340;&#38544;&#31169;&#20445;&#25252;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2306.01751</link><description>&lt;p&gt;
&#38543;&#26426;&#25237;&#24433;&#21644;&#31526;&#21495;&#38543;&#26426;&#25237;&#24433;&#30340;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Differential Privacy with Random Projections and Sign Random Projections. (arXiv:2306.01751v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01751
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#65292;&#20854;&#20013;iDP-SignRP&#31639;&#27861;&#22312;&#20010;&#20307;&#24046;&#20998;&#38544;&#31169;&#35774;&#32622;&#19979;&#25928;&#26524;&#26174;&#33879;&#65292;DP-SignOPORP&#31639;&#27861;&#25913;&#36827;&#20102;&#29616;&#26377;&#31639;&#27861;&#65292;DP-OPORP&#31639;&#27861;&#34920;&#29616;&#26368;&#20248;&#65292;iDP&#25552;&#20379;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#29305;&#23450;&#25968;&#25454;&#38598;&#30340;&#38544;&#31169;&#20445;&#25252;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#22522;&#20110;&#38543;&#26426;&#25237;&#24433;&#65288;RP&#65289;&#30340;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#31639;&#27861;&#65292;&#36866;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#12289;&#25968;&#25454;&#25366;&#25496;&#21644;&#20449;&#24687;&#26816;&#32034;&#31561;&#21508;&#31181;&#24212;&#29992;&#12290;&#20854;&#20013;&#65292;&#22522;&#20110;&#31526;&#21495;&#38543;&#26426;&#25237;&#24433;&#65288;SignRP&#65289;&#30340;iDP-SignRP&#31639;&#27861;&#22312;&#20010;&#20307;&#24046;&#20998;&#38544;&#31169;&#65288;iDP&#65289;&#35774;&#32622;&#19979;&#38750;&#24120;&#26377;&#25928;&#65292;&#32780;DP-SignOPORP&#31639;&#27861;&#22312;&#26631;&#20934;DP&#35774;&#32622;&#19979;&#21033;&#29992;&#8220;&#19968;&#27425;&#25490;&#21015;+&#19968;&#27425;&#38543;&#26426;&#25237;&#24433;&#8221;&#65288;OPORP&#65289;&#26497;&#22823;&#22320;&#25913;&#36827;&#20102;&#25991;&#29486;&#20013;&#29616;&#26377;&#30340;&#31639;&#27861;&#12290;&#38500;&#19981;&#32771;&#34385;&#31526;&#21495;&#20043;&#22806;&#65292;&#22312;DP-RP&#23478;&#26063;&#20013;&#65292;DP-OPORP&#31639;&#27861;&#34920;&#29616;&#26368;&#20339;&#12290;iDP&#65288;&#20010;&#20307;&#24046;&#20998;&#38544;&#31169;&#65289;&#30340;&#27010;&#24565;&#20165;&#36866;&#29992;&#20110;&#29305;&#23450;&#30340;&#25968;&#25454;&#38598;&#12290;&#34429;&#28982;iDP&#19981;&#26159;&#20005;&#26684;&#30340;DP&#65292;&#20294;&#22312;&#26576;&#20123;&#24212;&#29992;&#20013;&#65288;&#22914;&#21521;&#23567;&#32452;&#29992;&#25143;&#21457;&#24067;&#21253;&#25324;&#23884;&#20837;&#20449;&#24687;&#25110;&#20010;&#24615;&#21270;&#25512;&#33616;&#31561;&#20869;&#23481;&#30340;&#25968;&#25454;&#38598;&#65292;&#32780;&#19981;&#27844;&#38706;&#19981;&#23646;&#20110;&#35813;&#32452;&#30340;&#20010;&#20154;&#30340;&#20219;&#20309;&#31169;&#20154;&#20449;&#24687;&#65289;&#21487;&#33021;&#24456;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we develop a series of differential privacy (DP) algorithms from a family of random projections (RP), for general applications in machine learning, data mining, and information retrieval. Among the presented algorithms, \textbf{iDP-SignRP} is remarkably effective under the setting of ``individual differential privacy'' (iDP), based on sign random projections (SignRP). Also, \textbf{DP-SignOPORP} considerably improves existing algorithms in the literature under the standard DP setting, using ``one permutation + one random projection'' (OPORP), where OPORP is a variant of the celebrated count-sketch method with fixed-length binning and normalization. Without taking signs, among the DP-RP family, \textbf{DP-OPORP} achieves the best performance.  The concept of iDP (individual differential privacy) is defined only on a particular dataset of interest. While iDP is not strictly DP, iDP might be useful in certain applications, such as releasing a dataset (including sharing embe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#28789;&#27963;&#30340;PFN&#20316;&#20026;BO&#20195;&#29702;&#24314;&#27169;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#20801;&#35768;&#36827;&#19968;&#27493;&#20449;&#24687;&#32435;&#20837;&#20197;&#36827;&#34892;&#38750;&#36828;&#35270;BO&#12290;&#22312;&#19977;&#31181;&#19981;&#21516;&#30340;&#38382;&#39064;&#19978;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.17535</link><description>&lt;p&gt;
PFN&#26159;&#36866;&#29992;&#20110;&#23454;&#38469;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#28789;&#27963;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
PFNs Are Flexible Models for Real-World Bayesian Optimization. (arXiv:2305.17535v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17535
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#28789;&#27963;&#30340;PFN&#20316;&#20026;BO&#20195;&#29702;&#24314;&#27169;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#20801;&#35768;&#36827;&#19968;&#27493;&#20449;&#24687;&#32435;&#20837;&#20197;&#36827;&#34892;&#38750;&#36828;&#35270;BO&#12290;&#22312;&#19977;&#31181;&#19981;&#21516;&#30340;&#38382;&#39064;&#19978;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#20808;&#39564;&#25968;&#25454;&#25311;&#21512;&#32593;&#32476;(PFNs)&#20316;&#20026;&#36125;&#21494;&#26031;&#20248;&#21270;(BO)&#30340;&#28789;&#27963;&#20195;&#29702;&#12290;PFN&#26159;&#19968;&#31181;&#31070;&#32463;&#36807;&#31243;&#65292;&#34987;&#35757;&#32451;&#29992;&#20110;&#36817;&#20284;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;(PPD)&#65292;&#36866;&#29992;&#20110;&#20219;&#20309;&#21487;&#26377;&#25928;&#37319;&#26679;&#30340;&#20808;&#39564;&#20998;&#24067;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#22914;&#20309;&#21033;&#29992;&#36825;&#31181;&#28789;&#27963;&#24615;&#26469;&#36827;&#34892;BO&#30340;&#20195;&#29702;&#24314;&#27169;&#12290;&#25105;&#20204;&#20351;&#29992;PFN&#26469;&#27169;&#25311;&#19968;&#20010;&#26420;&#32032;&#39640;&#26031;&#36807;&#31243;(GP)&#65292;&#19968;&#20010;&#20808;&#36827;&#30340;GP&#21644;&#19968;&#20010;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;(BNN)&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#36827;&#19968;&#27493;&#30340;&#20449;&#24687;&#32435;&#20837;&#20808;&#39564;&#65292;&#20363;&#22914;&#20801;&#35768;&#26377;&#20851;&#26368;&#20248;&#20301;&#32622;&#30340;&#25552;&#31034;(&#29992;&#25143;&#20808;&#39564;)&#65292;&#24573;&#30053;&#19981;&#30456;&#20851;&#30340;&#32500;&#24230;&#65292;&#24182;&#36890;&#36807;&#23398;&#20064;&#33719;&#21462;&#20989;&#25968;&#26469;&#25191;&#34892;&#38750;&#36828;&#35270;BO&#12290;&#36825;&#20123;&#25193;&#23637;&#30340;&#28789;&#27963;&#24615;&#20026;&#20351;&#29992;PFN&#36827;&#34892;BO&#24320;&#36767;&#20102;&#24191;&#38420;&#30340;&#21487;&#33021;&#24615;&#12290;&#25105;&#20204;&#22312;&#20154;&#24037;&#39640;&#26031;&#36807;&#31243;&#26679;&#26412;&#21644;&#19977;&#20010;&#19981;&#21516;&#30340;&#36229;&#21442;&#25968;&#20248;&#21270;&#27979;&#35797;&#24179;&#21488;&#19978;&#23637;&#31034;&#20102;PFN&#23545;BO&#30340;&#26377;&#29992;&#24615;&#65306;HPO-B&#12289;Bayesmark&#21644;PD1&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we use Prior-data Fitted Networks (PFNs) as a flexible surrogate for Bayesian Optimization (BO). PFNs are neural processes that are trained to approximate the posterior predictive distribution (PPD) for any prior distribution that can be efficiently sampled from. We describe how this flexibility can be exploited for surrogate modeling in BO. We use PFNs to mimic a naive Gaussian process (GP), an advanced GP, and a Bayesian Neural Network (BNN). In addition, we show how to incorporate further information into the prior, such as allowing hints about the position of optima (user priors), ignoring irrelevant dimensions, and performing non-myopic BO by learning the acquisition function. The flexibility underlying these extensions opens up vast possibilities for using PFNs for BO. We demonstrate the usefulness of PFNs for BO in a large-scale evaluation on artificial GP samples and three different hyperparameter optimization testbeds: HPO-B, Bayesmark, and PD1. We publish code 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#19981;&#21487;&#30693;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32771;&#34385;&#21508;&#31181;&#19981;&#30830;&#23450;&#24615;&#65292;&#21487;&#20197;&#21033;&#29992;&#20219;&#20309;&#22238;&#24402;&#22120;&#26816;&#27979;&#25968;&#20540;&#25968;&#25454;&#20013;&#30340;&#24322;&#24120;&#20540;&#19982;&#33258;&#28982;&#25968;&#25454;&#27874;&#21160;&#65292;&#33021;&#22815;&#26377;&#25928;&#21306;&#20998;&#30495;&#27491;&#30340;&#24322;&#24120;&#21644;&#33258;&#28982;&#25968;&#25454;&#27874;&#21160;&#12290;</title><link>http://arxiv.org/abs/2305.16583</link><description>&lt;p&gt;
&#36890;&#36807;&#20219;&#24847;&#22238;&#24402;&#27169;&#22411;&#26816;&#27979;&#25968;&#20540;&#25968;&#25454;&#20013;&#30340;&#38169;&#35823;&#12290;
&lt;/p&gt;
&lt;p&gt;
Detecting Errors in Numerical Data via any Regression Model. (arXiv:2305.16583v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16583
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#19981;&#21487;&#30693;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32771;&#34385;&#21508;&#31181;&#19981;&#30830;&#23450;&#24615;&#65292;&#21487;&#20197;&#21033;&#29992;&#20219;&#20309;&#22238;&#24402;&#22120;&#26816;&#27979;&#25968;&#20540;&#25968;&#25454;&#20013;&#30340;&#24322;&#24120;&#20540;&#19982;&#33258;&#28982;&#25968;&#25454;&#27874;&#21160;&#65292;&#33021;&#22815;&#26377;&#25928;&#21306;&#20998;&#30495;&#27491;&#30340;&#24322;&#24120;&#21644;&#33258;&#28982;&#25968;&#25454;&#27874;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22122;&#22768;&#22256;&#25200;&#30528;&#35768;&#22810;&#25968;&#20540;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#25968;&#25454;&#35760;&#24405;&#30340;&#20540;&#21487;&#33021;&#30001;&#20110;&#38169;&#35823;&#30340;&#20256;&#24863;&#22120;&#12289;&#25968;&#25454;&#36755;&#20837;/&#22788;&#29702;&#38169;&#35823;&#25110;&#19981;&#23436;&#32654;&#30340;&#20154;&#31867;&#20272;&#35745;&#31561;&#21407;&#22240;&#32780;&#26080;&#27861;&#21305;&#37197;&#30495;&#23454;&#30340;&#24213;&#23618;&#20540;&#12290;&#25105;&#20204;&#32771;&#34385;&#20272;&#35745;&#27839;&#25968;&#20540;&#21015;&#21738;&#20123;&#25968;&#25454;&#20540;&#26159;&#19981;&#27491;&#30830;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#19981;&#21487;&#30693;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#21033;&#29992;&#20219;&#20309;&#22238;&#24402;&#22120;&#65288;&#21363;&#22522;&#20110;&#25968;&#25454;&#38598;&#20013;&#30340;&#20854;&#20182;&#21464;&#37327;&#26469;&#39044;&#27979;&#35813;&#21015;&#20540;&#30340;&#32479;&#35745;&#23398;&#25110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65289;&#26469;&#35299;&#20915;&#38382;&#39064;&#12290;&#36890;&#36807;&#32771;&#34385;&#21508;&#31181;&#19981;&#30830;&#23450;&#24615;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21306;&#20998;&#20102;&#30495;&#27491;&#30340;&#24322;&#24120;&#21644;&#33258;&#28982;&#25968;&#25454;&#27874;&#21160;&#65292;&#26465;&#20214;&#26159;&#26377;&#21487;&#29992;&#30340;&#25968;&#25454;&#38598;&#20449;&#24687;&#12290;&#25105;&#20204;&#20026;&#25105;&#20204;&#30340;&#26041;&#27861;&#24314;&#31435;&#20102;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#34920;&#26126;&#20854;&#20182;&#26041;&#27861;&#65288;&#22914;&#31526;&#21512;&#24615;&#25512;&#26029;&#65289;&#38590;&#20197;&#26816;&#27979;&#38169;&#35823;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#35823;&#24046;&#26816;&#27979;&#22522;&#20934;&#65292;&#28041;&#21450; 5 &#20010;&#20855;&#26377;&#30495;&#23454;&#19990;&#30028;&#25968;&#23383;&#38169;&#35823;&#30340;&#22238;&#24402;&#25968;&#25454;&#38598;&#65288;&#23545;&#20110;&#20854;&#20013;&#30340;&#30495;&#23454;&#20540;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Noise plagues many numerical datasets, where the recorded values in the data may fail to match the true underlying values due to reasons including: erroneous sensors, data entry/processing mistakes, or imperfect human estimates. Here we consider estimating \emph{which} data values are incorrect along a numerical column. We present a model-agnostic approach that can utilize \emph{any} regressor (i.e.\ statistical or machine learning model) which was fit to predict values in this column based on the other variables in the dataset. By accounting for various uncertainties, our approach distinguishes between genuine anomalies and natural data fluctuations, conditioned on the available information in the dataset. We establish theoretical guarantees for our method and show that other approaches like conformal inference struggle to detect errors. We also contribute a new error detection benchmark involving 5 regression datasets with real-world numerical errors (for which the true values are al
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#32447;&#23398;&#20064;&#20013;&#26368;&#23567;&#21270;&#39118;&#38505;&#30340;&#20498;&#25968;&#20542;&#21521;&#35780;&#20998;(IPS)&#30340;&#24179;&#28369;&#27491;&#21017;&#21270;&#65292;&#25512;&#23548;&#20986;&#20102;&#21487;&#22788;&#29702;&#12289;&#21487;&#25193;&#23637;&#12289;&#21487;&#35299;&#37322;&#30340;&#23398;&#20064;&#35777;&#26126;&#65292;&#24182;&#30830;&#23450;&#20102;&#22312;&#20309;&#31181;&#24773;&#20917;&#19979;&#19981;&#38656;&#35201;&#27491;&#21017;&#21270;IPS&#12290;</title><link>http://arxiv.org/abs/2305.15877</link><description>&lt;p&gt;
&#25351;&#25968;&#24179;&#28369;&#29992;&#20110;&#31163;&#32447;&#31574;&#30053;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Exponential Smoothing for Off-Policy Learning. (arXiv:2305.15877v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15877
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#32447;&#23398;&#20064;&#20013;&#26368;&#23567;&#21270;&#39118;&#38505;&#30340;&#20498;&#25968;&#20542;&#21521;&#35780;&#20998;(IPS)&#30340;&#24179;&#28369;&#27491;&#21017;&#21270;&#65292;&#25512;&#23548;&#20986;&#20102;&#21487;&#22788;&#29702;&#12289;&#21487;&#25193;&#23637;&#12289;&#21487;&#35299;&#37322;&#30340;&#23398;&#20064;&#35777;&#26126;&#65292;&#24182;&#30830;&#23450;&#20102;&#22312;&#20309;&#31181;&#24773;&#20917;&#19979;&#19981;&#38656;&#35201;&#27491;&#21017;&#21270;IPS&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#31574;&#30053;&#23398;&#20064;&#26088;&#22312;&#36890;&#36807;&#26368;&#23567;&#21270;&#39118;&#38505;&#30340;&#20498;&#25968;&#20542;&#21521;&#35780;&#20998;&#65288;IPS&#65289;&#26469;&#23547;&#25214;&#25913;&#36827;&#30340;&#31574;&#30053;&#65292;&#36890;&#24120;&#20351;&#29992;&#35760;&#24405;&#30340;&#36172;&#21338;&#25968;&#25454;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;IPS&#30340;&#24179;&#28369;&#27491;&#21017;&#21270;&#65292;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#21452;&#21521;PAC-Bayes&#27867;&#21270;&#30028;&#38480;&#12290;&#35813;&#30028;&#38480;&#26159;&#21487;&#22788;&#29702;&#30340;&#12289;&#21487;&#25193;&#23637;&#30340;&#12289;&#21487;&#35299;&#37322;&#30340;&#24182;&#25552;&#20379;&#20102;&#23398;&#20064;&#35777;&#26126;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#31995;&#21015;&#23398;&#20064;&#20219;&#21153;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#30456;&#20851;&#24615;&#21644;&#26377;&#21033;&#30340;&#24615;&#33021;&#12290;&#30001;&#20110;&#25105;&#20204;&#30340;&#30028;&#38480;&#36866;&#29992;&#20110;&#26631;&#20934;IPS&#65292;&#22240;&#27492;&#25105;&#20204;&#33021;&#22815;&#25552;&#20379;&#20851;&#20110;&#20309;&#26102;&#27491;&#21017;&#21270;IPS&#26377;&#29992;&#30340;&#35265;&#35299;&#12290;&#21363;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#19981;&#38656;&#35201;&#27491;&#21017;&#21270;&#30340;&#24773;&#20917;&#12290;&#36825;&#19982;&#22312;&#23454;&#36341;&#20013;&#65292;&#21098;&#36753;IPS&#24120;&#24120;&#27604;OPL&#20013;&#30340;&#26631;&#20934;IPS&#34920;&#29616;&#26356;&#22909;&#30340;&#20449;&#24565;&#30456;&#21453;&#12290;
&lt;/p&gt;
&lt;p&gt;
Off-policy learning (OPL) aims at finding improved policies from logged bandit data, often by minimizing the inverse propensity scoring (IPS) estimator of the risk. In this work, we investigate a smooth regularization for IPS, for which we derive a two-sided PAC-Bayes generalization bound. The bound is tractable, scalable, interpretable and provides learning certificates. In particular, it is also valid for standard IPS without making the assumption that the importance weights are bounded. We demonstrate the relevance of our approach and its favorable performance through a set of learning tasks. Since our bound holds for standard IPS, we are able to provide insight into when regularizing IPS is useful. Namely, we identify cases where regularization might not be needed. This goes against the belief that, in practice, clipped IPS often enjoys favorable performance than standard IPS in OPL.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#31216;&#20026;OffCEM&#30340;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#23545;&#22823;&#31163;&#25955;&#21160;&#20316;&#31354;&#38388;&#19979;&#19978;&#19979;&#25991;&#21305;&#37197;&#31574;&#30053;&#36827;&#34892;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#12290;&#35813;&#20272;&#35745;&#22120;&#36890;&#36807;&#22522;&#20110;&#27169;&#22411;&#30340;&#22870;&#21169;&#20272;&#35745;&#26469;&#22788;&#29702;&#27531;&#20313;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#22312;&#26032;&#30340;&#26412;&#22320;&#27491;&#30830;&#24615;&#26465;&#20214;&#19979;&#20445;&#25345;&#26080;&#20559;&#24615;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;OffCEM&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#22823;&#21160;&#20316;&#31354;&#38388;&#25968;&#25454;&#38598;&#19978;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.08062</link><description>&lt;p&gt;
&#22522;&#20110;&#36830;&#35789;&#25928;&#24212;&#24314;&#27169;&#30340;&#22823;&#21160;&#20316;&#31354;&#38388;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Off-Policy Evaluation for Large Action Spaces via Conjunct Effect Modeling. (arXiv:2305.08062v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08062
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#31216;&#20026;OffCEM&#30340;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#23545;&#22823;&#31163;&#25955;&#21160;&#20316;&#31354;&#38388;&#19979;&#19978;&#19979;&#25991;&#21305;&#37197;&#31574;&#30053;&#36827;&#34892;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#12290;&#35813;&#20272;&#35745;&#22120;&#36890;&#36807;&#22522;&#20110;&#27169;&#22411;&#30340;&#22870;&#21169;&#20272;&#35745;&#26469;&#22788;&#29702;&#27531;&#20313;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#22312;&#26032;&#30340;&#26412;&#22320;&#27491;&#30830;&#24615;&#26465;&#20214;&#19979;&#20445;&#25345;&#26080;&#20559;&#24615;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;OffCEM&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#22823;&#21160;&#20316;&#31354;&#38388;&#25968;&#25454;&#38598;&#19978;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#23545;&#20110;&#20256;&#32479;&#37325;&#35201;&#24615;&#21152;&#26435;&#26041;&#27861;&#26041;&#24040;&#30340;&#22823;&#31163;&#25955;&#21160;&#20316;&#31354;&#38388;&#19979;&#30340;&#19978;&#19979;&#25991;&#21305;&#37197;&#31574;&#30053;&#30340;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#65288;OPE&#65289;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#26041;&#24040;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20272;&#35745;&#22120;OffCEM&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#36830;&#35789;&#25928;&#24212;&#27169;&#22411;&#65288;CEM&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#25928;&#24212;&#20998;&#35299;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#25928;&#24212;&#20998;&#20026;&#32676;&#38598;&#25928;&#24212;&#21644;&#27531;&#24046;&#25928;&#24212;&#12290;OffCEM&#20165;&#23545;&#34892;&#21160;&#32676;&#38598;&#24212;&#29992;&#37325;&#35201;&#24615;&#21152;&#26435;&#65292;&#36890;&#36807;&#22522;&#20110;&#27169;&#22411;&#30340;&#22870;&#21169;&#20272;&#35745;&#26469;&#22788;&#29702;&#27531;&#20313;&#22240;&#26524;&#25928;&#24212;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312;&#26032;&#30340;&#26412;&#22320;&#27491;&#30830;&#24615;&#26465;&#20214;&#19979;&#65292;&#35813;&#20272;&#35745;&#22120;&#26159;&#26080;&#20559;&#30340;&#65292;&#35813;&#26465;&#20214;&#20165;&#35201;&#27714;&#27531;&#24046;&#25928;&#24212;&#27169;&#22411;&#20445;&#30041;&#27599;&#20010;&#32676;&#38598;&#20013;&#34892;&#21160;&#30340;&#30456;&#23545;&#26399;&#26395;&#22870;&#21169;&#24046;&#24322;&#12290;&#20026;&#20102;&#20805;&#20998;&#21033;&#29992;CEM&#21644;&#26412;&#22320;&#27491;&#30830;&#24615;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20004;&#27493;&#36807;&#31243;&#65292;&#29992;&#20110;&#25191;&#34892;&#22522;&#20110;&#27169;&#22411;&#30340;&#20272;&#35745;&#65292;&#31532;&#19968;&#27493;&#26368;&#23567;&#21270;&#20559;&#24046;&#65292;&#31532;&#20108;&#27493;&#26368;&#23567;&#21270;&#26041;&#24046;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#25152;&#24471;&#21040;&#30340;OPE&#20272;&#35745;&#22120;OffCEM&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#22823;&#21160;&#20316;&#31354;&#38388;&#25968;&#25454;&#38598;&#19978;&#37117;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study off-policy evaluation (OPE) of contextual bandit policies for large discrete action spaces where conventional importance-weighting approaches suffer from excessive variance. To circumvent this variance issue, we propose a new estimator, called OffCEM, that is based on the conjunct effect model (CEM), a novel decomposition of the causal effect into a cluster effect and a residual effect. OffCEM applies importance weighting only to action clusters and addresses the residual causal effect through model-based reward estimation. We show that the proposed estimator is unbiased under a new condition, called local correctness, which only requires that the residual-effect model preserves the relative expected reward differences of the actions within each cluster. To best leverage the CEM and local correctness, we also propose a new two-step procedure for performing model-based estimation that minimizes bias in the first step and variance in the second step. We find that the resulting O
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23558;&#38464;&#34746;&#30690;&#37327;&#31354;&#38388;&#20013;&#30340;&#19968;&#20123;&#27010;&#24565;&#25512;&#24191;&#21040;SPD&#21644;Grassmann&#27969;&#24418;&#65292;&#25552;&#20986;&#20102;&#22312;&#36825;&#20123;&#27969;&#24418;&#19978;&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#27169;&#22411;&#21644;&#26032;&#23618;&#65292;&#24182;&#22312;&#20154;&#31867;&#21160;&#20316;&#35782;&#21035;&#21644;&#30693;&#35782;&#22270;&#35889;&#23436;&#25104;&#20004;&#20010;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.04560</link><description>&lt;p&gt;
&#22522;&#20110;&#30697;&#38453;&#27969;&#24418;&#30340;&#31070;&#32463;&#32593;&#32476;&#26500;&#24314;&#65306;&#38464;&#34746;&#30690;&#37327;&#31354;&#38388;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Building Neural Networks on Matrix Manifolds: A Gyrovector Space Approach. (arXiv:2305.04560v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04560
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23558;&#38464;&#34746;&#30690;&#37327;&#31354;&#38388;&#20013;&#30340;&#19968;&#20123;&#27010;&#24565;&#25512;&#24191;&#21040;SPD&#21644;Grassmann&#27969;&#24418;&#65292;&#25552;&#20986;&#20102;&#22312;&#36825;&#20123;&#27969;&#24418;&#19978;&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#27169;&#22411;&#21644;&#26032;&#23618;&#65292;&#24182;&#22312;&#20154;&#31867;&#21160;&#20316;&#35782;&#21035;&#21644;&#30693;&#35782;&#22270;&#35889;&#23436;&#25104;&#20004;&#20010;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30697;&#38453;&#27969;&#24418;&#65292;&#22914;&#23545;&#31216;&#27491;&#23450;&#65288;SPD&#65289;&#30697;&#38453;&#21644;Grassmann&#27969;&#24418;&#65292;&#20986;&#29616;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#12290;&#26368;&#36817;&#65292;&#36890;&#36807;&#24212;&#29992;&#38464;&#34746;&#32676;&#21644;&#38464;&#34746;&#30690;&#37327;&#31354;&#38388;&#30340;&#29702;&#35770;&#8212;&#8212;&#36825;&#26159;&#19968;&#20010;&#30740;&#31350;&#21452;&#26354;&#20960;&#20309;&#30340;&#24378;&#22823;&#26694;&#26550;&#8212;&#8212;&#19968;&#20123;&#24037;&#20316;&#23581;&#35797;&#22312;&#30697;&#38453;&#27969;&#24418;&#19978;&#26500;&#24314;&#27431;&#20960;&#37324;&#24503;&#31070;&#32463;&#32593;&#32476;&#30340;&#21407;&#21017;&#24615;&#25512;&#24191;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#32570;&#20047;&#32771;&#34385;&#27969;&#24418;&#30340;&#20869;&#31215;&#21644;&#38464;&#34746;&#35282;&#31561;&#27010;&#24565;&#30340;&#38464;&#34746;&#30690;&#37327;&#31354;&#38388;&#65292;&#30456;&#27604;&#20110;&#29992;&#20110;&#30740;&#31350;&#21452;&#26354;&#20960;&#20309;&#30340;&#37027;&#20123;&#27010;&#24565;&#65292;&#36825;&#20123;&#24037;&#20316;&#25552;&#20379;&#30340;&#25216;&#26415;&#21644;&#25968;&#23398;&#24037;&#20855;&#20173;&#28982;&#26377;&#38480;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#38464;&#34746;&#30690;&#37327;&#31354;&#38388;&#20013;&#30340;&#19968;&#20123;&#27010;&#24565;&#25512;&#24191;&#21040;SPD&#21644;Grassmann&#27969;&#24418;&#65292;&#24182;&#25552;&#20986;&#20102;&#22312;&#36825;&#20123;&#27969;&#24418;&#19978;&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#27169;&#22411;&#21644;&#26032;&#23618;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20154;&#31867;&#21160;&#20316;&#35782;&#21035;&#21644;&#30693;&#35782;&#22270;&#35889;&#23436;&#25104;&#20004;&#20010;&#24212;&#29992;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Matrix manifolds, such as manifolds of Symmetric Positive Definite (SPD) matrices and Grassmann manifolds, appear in many applications. Recently, by applying the theory of gyrogroups and gyrovector spaces that is a powerful framework for studying hyperbolic geometry, some works have attempted to build principled generalizations of Euclidean neural networks on matrix manifolds. However, due to the lack of many concepts in gyrovector spaces for the considered manifolds, e.g., the inner product and gyroangles, techniques and mathematical tools provided by these works are still limited compared to those developed for studying hyperbolic geometry. In this paper, we generalize some notions in gyrovector spaces for SPD and Grassmann manifolds, and propose new models and layers for building neural networks on these manifolds. We show the effectiveness of our approach in two applications, i.e., human action recognition and knowledge graph completion.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#26080;&#29305;&#23450;&#27169;&#22411;&#30340;&#12289;&#37327;&#21270;&#26426;&#22120;&#23398;&#20064;&#27979;&#35797;&#27867;&#21270;&#38590;&#24230;&#30340;&#26041;&#27861;&#8212;&#8212;&#24402;&#32435;&#20559;&#24046;&#22797;&#26434;&#24230;&#24230;&#37327;&#12290;&#35813;&#26041;&#27861;&#37327;&#21270;&#20102;&#22312;&#20219;&#21153;&#19978;&#33391;&#22909;&#27867;&#21270;&#25152;&#38656;&#30340;&#24635;&#20449;&#24687;&#37327;&#19982;&#25968;&#25454;&#25552;&#20379;&#30340;&#20449;&#24687;&#37327;&#20043;&#24046;&#65292;&#36890;&#24120;&#38656;&#35201;&#22312;&#35768;&#22810;&#32500;&#24230;&#19978;&#27867;&#21270;&#30340;&#20219;&#21153;&#27604;&#28041;&#21450;&#26356;&#23569;&#32500;&#24230;&#20294;&#35201;&#27714;&#26356;&#22810;&#32454;&#33410;&#30340;&#20219;&#21153;&#35201;&#22256;&#38590;&#24471;&#22810;&#12290;</title><link>http://arxiv.org/abs/2305.01034</link><description>&lt;p&gt;
&#26080;&#29305;&#23450;&#27169;&#22411;&#27867;&#21270;&#38590;&#24230;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
Model-agnostic Measure of Generalization Difficulty. (arXiv:2305.01034v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01034
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#26080;&#29305;&#23450;&#27169;&#22411;&#30340;&#12289;&#37327;&#21270;&#26426;&#22120;&#23398;&#20064;&#27979;&#35797;&#27867;&#21270;&#38590;&#24230;&#30340;&#26041;&#27861;&#8212;&#8212;&#24402;&#32435;&#20559;&#24046;&#22797;&#26434;&#24230;&#24230;&#37327;&#12290;&#35813;&#26041;&#27861;&#37327;&#21270;&#20102;&#22312;&#20219;&#21153;&#19978;&#33391;&#22909;&#27867;&#21270;&#25152;&#38656;&#30340;&#24635;&#20449;&#24687;&#37327;&#19982;&#25968;&#25454;&#25552;&#20379;&#30340;&#20449;&#24687;&#37327;&#20043;&#24046;&#65292;&#36890;&#24120;&#38656;&#35201;&#22312;&#35768;&#22810;&#32500;&#24230;&#19978;&#27867;&#21270;&#30340;&#20219;&#21153;&#27604;&#28041;&#21450;&#26356;&#23569;&#32500;&#24230;&#20294;&#35201;&#27714;&#26356;&#22810;&#32454;&#33410;&#30340;&#20219;&#21153;&#35201;&#22256;&#38590;&#24471;&#22810;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#24230;&#37327;&#26159;&#20854;&#21487;&#20197;&#25191;&#34892;&#30340;&#20219;&#21153;&#38590;&#24230;&#65292;&#36275;&#22815;&#22256;&#38590;&#30340;&#20219;&#21153;&#26159;&#24378;&#22823;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20851;&#38190;&#39537;&#21160;&#22240;&#32032;&#12290;&#28982;&#32780;&#65292;&#37327;&#21270;&#26426;&#22120;&#23398;&#20064;&#27979;&#35797;&#30340;&#27867;&#21270;&#38590;&#24230;&#19968;&#30452;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#25454;&#25105;&#20204;&#25152;&#30693;&#30340;&#31532;&#19968;&#20010;&#23545;&#20219;&#21153;&#22266;&#26377;&#27867;&#21270;&#38590;&#24230;&#30340;&#26080;&#29305;&#23450;&#27169;&#22411;&#30340;&#24230;&#37327;&#12290;&#25105;&#20204;&#30340;&#24402;&#32435;&#20559;&#24046;&#22797;&#26434;&#24230;&#24230;&#37327;&#37327;&#21270;&#20102;&#22312;&#20219;&#21153;&#19978;&#33391;&#22909;&#27867;&#21270;&#25152;&#38656;&#30340;&#24635;&#20449;&#24687;&#37327;&#19982;&#25968;&#25454;&#25552;&#20379;&#30340;&#20449;&#24687;&#37327;&#20043;&#24046;&#12290;&#36890;&#36807;&#27979;&#37327;&#36866;&#21512;&#35757;&#32451;&#25968;&#25454;&#30340;&#20551;&#35774;&#22312;&#20219;&#21153;&#20013;&#27867;&#21270;&#30340;&#20998;&#25968;&#21344;&#25454;&#30340;&#23481;&#31215;&#65292;&#26469;&#23454;&#29616;&#36825;&#19968;&#28857;&#12290;&#23427;&#19982;&#27169;&#22411;&#24517;&#39035;&#27867;&#21270;&#30340;&#31354;&#38388;&#30340;&#20869;&#22312;&#32500;&#25968;&#25104;&#25351;&#25968;&#27604;&#20363;&#65292;&#20294;&#20165;&#22312;&#27599;&#20010;&#32500;&#24230;&#30340;&#20998;&#36776;&#29575;&#19978;&#21576;&#22810;&#39033;&#24335;&#27604;&#20363;&#65292;&#34920;&#26126;&#38656;&#35201;&#22312;&#35768;&#22810;&#32500;&#24230;&#19978;&#27867;&#21270;&#30340;&#20219;&#21153;&#27604;&#28041;&#21450;&#26356;&#23569;&#32500;&#24230;&#30340;&#26356;&#22810;&#32454;&#33410;&#30340;&#20219;&#21153;&#35201;&#22256;&#38590;&#24471;&#22810;&#12290;
&lt;/p&gt;
&lt;p&gt;
The measure of a machine learning algorithm is the difficulty of the tasks it can perform, and sufficiently difficult tasks are critical drivers of strong machine learning models. However, quantifying the generalization difficulty of machine learning benchmarks has remained challenging. We propose what is to our knowledge the first model-agnostic measure of the inherent generalization difficulty of tasks. Our inductive bias complexity measure quantifies the total information required to generalize well on a task minus the information provided by the data. It does so by measuring the fractional volume occupied by hypotheses that generalize on a task given that they fit the training data. It scales exponentially with the intrinsic dimensionality of the space over which the model must generalize but only polynomially in resolution per dimension, showing that tasks which require generalizing over many dimensions are drastically more difficult than tasks involving more detail in fewer dimen
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22312;&#26679;&#26412;&#20013;&#24341;&#20837;&#25200;&#21160;&#65292;&#25913;&#36827;&#22522;&#20110;&#26680;&#21270;&#26031;&#22374;&#36317;&#30340;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;&#26041;&#27861;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#22312;&#21516;&#36136;&#20294;&#28151;&#21512;&#27604;&#20363;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#20302;&#21151;&#29575;&#30340;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#23454;&#39564;&#35777;&#25454;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#21151;&#25928;&#12290;</title><link>http://arxiv.org/abs/2304.14762</link><description>&lt;p&gt;
&#21033;&#29992;&#25200;&#21160;&#26469;&#25913;&#21892;&#22522;&#20110;&#26680;&#21270;&#26031;&#22374;&#36317;&#30340;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Using Perturbation to Improve Goodness-of-Fit Tests based on Kernelized Stein Discrepancy. (arXiv:2304.14762v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14762
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22312;&#26679;&#26412;&#20013;&#24341;&#20837;&#25200;&#21160;&#65292;&#25913;&#36827;&#22522;&#20110;&#26680;&#21270;&#26031;&#22374;&#36317;&#30340;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;&#26041;&#27861;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#22312;&#21516;&#36136;&#20294;&#28151;&#21512;&#27604;&#20363;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#20302;&#21151;&#29575;&#30340;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#23454;&#39564;&#35777;&#25454;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#21151;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#21270;&#26031;&#22374;&#36317;&#65288;KSD&#65289;&#26159;&#19968;&#31181;&#24191;&#27867;&#29992;&#20110;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;&#30340;&#22522;&#20110;&#24471;&#20998;&#30340;&#24046;&#24322;&#24230;&#37327;&#12290;&#21363;&#20351;&#30446;&#26631;&#20998;&#24067;&#20855;&#26377;&#26410;&#30693;&#30340;&#26631;&#20934;&#21270;&#22240;&#23376;&#65292;&#20363;&#22914;&#22312;&#36125;&#21494;&#26031;&#20998;&#26512;&#20013;&#65292;&#20063;&#21487;&#20197;&#24212;&#29992;&#23427;&#12290;&#25105;&#20204;&#29702;&#35770;&#19978;&#21644;&#23454;&#39564;&#35777;&#26126;&#65292;&#24403;&#30446;&#26631;&#20998;&#24067;&#21644;&#26367;&#20195;&#20998;&#24067;&#20855;&#26377;&#30456;&#21516;&#19988;&#30456;&#36317;&#36739;&#36828;&#30340;&#27169;&#24335;&#20294;&#22312;&#28151;&#21512;&#27604;&#20363;&#19978;&#26377;&#25152;&#19981;&#21516;&#26102;&#65292;KSD&#26816;&#39564;&#21487;&#33021;&#20250;&#20986;&#29616;&#20302;&#21151;&#29575;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#39532;&#23572;&#31185;&#22827;&#36716;&#31227;&#26680;&#23545;&#35266;&#27979;&#26679;&#26412;&#36827;&#34892;&#25200;&#21160;&#65292;&#20351;&#20854;&#30456;&#23545;&#20110;&#30446;&#26631;&#20998;&#24067;&#19981;&#21464;&#12290;&#36825;&#20351;&#25105;&#20204;&#21487;&#20197;&#22312;&#25200;&#21160;&#26679;&#26412;&#19978;&#20351;&#29992;KSD&#26816;&#39564;&#12290;&#25105;&#20204;&#25552;&#20379;&#30340;&#25968;&#20540;&#35777;&#25454;&#34920;&#26126;&#65292;&#20351;&#29992;&#36866;&#24403;&#36873;&#25321;&#30340;&#26680;&#26102;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#27604;KSD&#26816;&#39564;&#20855;&#26377;&#26356;&#39640;&#30340;&#21151;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernelized Stein discrepancy (KSD) is a score-based discrepancy widely used in goodness-of-fit tests. It can be applied even when the target distribution has an unknown normalising factor, such as in Bayesian analysis. We show theoretically and empirically that the KSD test can suffer from low power when the target and the alternative distribution have the same well-separated modes but differ in mixing proportions. We propose to perturb the observed sample via Markov transition kernels, with respect to which the target distribution is invariant. This allows us to then employ the KSD test on the perturbed sample. We provide numerical evidence that with suitably chosen kernels the proposed approach can lead to a substantially higher power than the KSD test.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;Adam&#31639;&#27861;&#20570;&#20102;&#26032;&#30340;&#20551;&#35774;&#24182;&#36827;&#34892;&#20102;&#35777;&#26126;&#65292;&#35777;&#26126;&#20102;&#22312;&#26356;&#21152;&#29616;&#23454;&#30340;&#26465;&#20214;&#19979;&#65292;Adam&#33021;&#22815;&#20197;&#36739;&#23567;&#30340;&#26799;&#24230;&#22797;&#26434;&#24230;&#36798;&#21040;&#31283;&#23450;&#28857;&#12290;</title><link>http://arxiv.org/abs/2304.13972</link><description>&lt;p&gt;
&#26494;&#24347;&#20551;&#35774;&#19979;Adam&#25910;&#25947;&#24615;&#30340;&#35777;&#26126;
&lt;/p&gt;
&lt;p&gt;
Convergence of Adam Under Relaxed Assumptions. (arXiv:2304.13972v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13972
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;Adam&#31639;&#27861;&#20570;&#20102;&#26032;&#30340;&#20551;&#35774;&#24182;&#36827;&#34892;&#20102;&#35777;&#26126;&#65292;&#35777;&#26126;&#20102;&#22312;&#26356;&#21152;&#29616;&#23454;&#30340;&#26465;&#20214;&#19979;&#65292;Adam&#33021;&#22815;&#20197;&#36739;&#23567;&#30340;&#26799;&#24230;&#22797;&#26434;&#24230;&#36798;&#21040;&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#19968;&#31867;&#24191;&#27867;&#30340;&#20248;&#21270;&#30446;&#26631;&#65292;&#23545;&#33258;&#36866;&#24212;&#30697;&#20272;&#35745;&#65288;Adam&#65289;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#36827;&#34892;&#20102;&#20005;&#26684;&#35777;&#26126;&#12290;&#34429;&#28982;Adam&#31639;&#27861;&#22312;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#27969;&#34892;&#24230;&#21644;&#25928;&#29575;&#24456;&#39640;&#65292;&#20294;&#20854;&#29702;&#35770;&#24615;&#36136;&#23578;&#26410;&#23436;&#20840;&#29702;&#35299;&#65292;&#29616;&#26377;&#30340;&#25910;&#25947;&#24615;&#35777;&#26126;&#38656;&#35201;&#36807;&#20110;&#24378;&#30340;&#20551;&#35774;&#65292;&#22914;&#20840;&#23616;&#26799;&#24230;&#26377;&#30028;&#65292;&#20197;&#35777;&#26126;&#25910;&#25947;&#21040;&#31283;&#23450;&#28857;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;&#22312;&#26356;&#20026;&#29616;&#23454;&#30340;&#26465;&#20214;&#19979;&#65292;Adam&#33021;&#20197;$\mathcal{O}(\epsilon^{-4})$&#26799;&#24230;&#22797;&#26434;&#24230;&#25910;&#25947;&#21040;$\epsilon$-&#31283;&#23450;&#28857;&#12290;&#25105;&#20204;&#20998;&#26512;&#30340;&#20851;&#38190;&#26159;&#26681;&#25454;&#19968;&#31181;&#24191;&#20041;&#20809;&#28369;&#24615;&#20551;&#35774;&#32473;&#20986;&#30340;&#65292;&#27839;&#30528;&#20248;&#21270;&#36712;&#36857;&#30340;&#26799;&#24230;&#26377;&#30028;&#30340;&#26032;&#35777;&#26126;&#12290;&#26681;&#25454;&#35813;&#20551;&#35774;&#65292;&#23616;&#37096;&#20809;&#28369;&#24615;(&#21363;&#23384;&#22312;&#26102;&#30340;Hessian norm)&#21463;&#26799;&#24230;&#33539;&#25968;&#30340;&#27425;&#24179;&#26041;&#20989;&#25968;&#38480;&#21046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#24046;&#32422;&#20943;&#29256;&#26412;&#30340;Adam&#19982;&#21152;&#36895;Gradient&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we provide a rigorous proof of convergence of the Adaptive Moment Estimate (Adam) algorithm for a wide class of optimization objectives. Despite the popularity and efficiency of the Adam algorithm in training deep neural networks, its theoretical properties are not yet fully understood, and existing convergence proofs require unrealistically strong assumptions, such as globally bounded gradients, to show the convergence to stationary points. In this paper, we show that Adam provably converges to $\epsilon$-stationary points with $\mathcal{O}(\epsilon^{-4})$ gradient complexity under far more realistic conditions. The key to our analysis is a new proof of boundedness of gradients along the optimization trajectory, under a generalized smoothness assumption according to which the local smoothness (i.e., Hessian norm when it exists) is bounded by a sub-quadratic function of the gradient norm. Moreover, we propose a variance-reduced version of Adam with an accelerated gradien
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#19981;&#31934;&#30830;&#30340;&#36845;&#20195;&#32447;&#24615;&#20195;&#25968;&#26041;&#27861;&#65292;&#29992;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#35889;&#20272;&#35745;&#21644;&#20174;&#30701;&#36712;&#36857;&#25968;&#25454;&#38598;&#20013;&#36827;&#34892;&#31232;&#26377;&#20107;&#20214;&#30340;&#39044;&#27979;&#65292;&#36825;&#23545;&#20110;&#29702;&#35299;&#22797;&#26434;&#31995;&#32479;&#30340;&#21160;&#24577;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#24182;&#35752;&#35770;&#20102;&#35813;&#26041;&#27861;&#23545;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#39044;&#27979;&#38382;&#39064;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2303.12534</link><description>&lt;p&gt;
&#19981;&#31934;&#30830;&#30340;&#36845;&#20195;&#25968;&#20540;&#32447;&#24615;&#20195;&#25968;&#29992;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#35889;&#20272;&#35745;&#21644;&#31232;&#26377;&#20107;&#20214;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Inexact iterative numerical linear algebra for neural network-based spectral estimation and rare-event prediction. (arXiv:2303.12534v1 [physics.comp-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12534
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#19981;&#31934;&#30830;&#30340;&#36845;&#20195;&#32447;&#24615;&#20195;&#25968;&#26041;&#27861;&#65292;&#29992;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#35889;&#20272;&#35745;&#21644;&#20174;&#30701;&#36712;&#36857;&#25968;&#25454;&#38598;&#20013;&#36827;&#34892;&#31232;&#26377;&#20107;&#20214;&#30340;&#39044;&#27979;&#65292;&#36825;&#23545;&#20110;&#29702;&#35299;&#22797;&#26434;&#31995;&#32479;&#30340;&#21160;&#24577;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#24182;&#35752;&#35770;&#20102;&#35813;&#26041;&#27861;&#23545;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#39044;&#27979;&#38382;&#39064;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#22797;&#26434;&#31995;&#32479;&#23384;&#22312;&#22823;&#37327;&#33258;&#30001;&#24230;&#65292;&#20854;&#20013;&#26368;&#37325;&#35201;&#30340;&#24230;&#37327;&#36890;&#24120;&#24182;&#19981;&#26126;&#26174;&#65292;&#22240;&#27492;&#29702;&#35299;&#20854;&#21160;&#24577;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#36716;&#31227;&#31639;&#31526;&#30340;&#20027;&#35201;&#29305;&#24449;&#20989;&#25968;&#23545;&#20110;&#21487;&#35270;&#21270;&#24456;&#26377;&#29992;&#65292;&#23427;&#20204;&#21487;&#20197;&#20026;&#35745;&#31639;&#32479;&#35745;&#37327;&#65288;&#20363;&#22914;&#20107;&#20214;&#30340;&#21487;&#33021;&#24615;&#21644;&#24179;&#22343;&#26102;&#38388;&#65289;&#25552;&#20379;&#39640;&#25928;&#30340;&#22522;&#30784;&#65288;&#39044;&#27979;&#65289;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19981;&#31934;&#30830;&#30340;&#36845;&#20195;&#32447;&#24615;&#20195;&#25968;&#26041;&#27861;&#26469;&#35745;&#31639;&#36825;&#20123;&#29305;&#24449;&#20989;&#25968;&#65288;&#35889;&#20272;&#35745;&#65289;&#24182;&#20174;&#30701;&#36712;&#36857;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#39044;&#27979;&#12290;&#25105;&#20204;&#22312;&#20415;&#20110;&#21487;&#35270;&#21270;&#30340;&#20302;&#32500;&#27169;&#22411;&#21644;&#29983;&#29289;&#20998;&#23376;&#31995;&#32479;&#30340;&#39640;&#32500;&#27169;&#22411;&#19978;&#28436;&#31034;&#20102;&#35813;&#26041;&#27861;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#36825;&#20123;&#26041;&#27861;&#23545;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#39044;&#27979;&#38382;&#39064;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding dynamics in complex systems is challenging because there are many degrees of freedom, and those that are most important for describing events of interest are often not obvious. The leading eigenfunctions of the transition operator are useful for visualization, and they can provide an efficient basis for computing statistics such as the likelihood and average time of events (predictions). Here we develop inexact iterative linear algebra methods for computing these eigenfunctions (spectral estimation) and making predictions from a data set of short trajectories sampled at finite intervals. We demonstrate the methods on a low-dimensional model that facilitates visualization and a high-dimensional model of a biomolecular system. Implications for the prediction problem in reinforcement learning are discussed.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#20013;&#30740;&#31350;&#20102;&#22522;&#20110;Group Lasso&#27491;&#21017;&#21270;&#22120;&#30340;&#36138;&#23146;&#21098;&#26525;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#20462;&#21098;&#20302;$\ell_2$&#33539;&#25968;&#21015;&#30340;&#35299;&#21487;&#20197;&#27867;&#21270;&#21040;&#26032;&#26679;&#26412;&#19978;&#12290;</title><link>http://arxiv.org/abs/2303.11453</link><description>&lt;p&gt;
&#22522;&#20110;Group Lasso&#30340;&#36138;&#23146;&#21098;&#26525;&#22312;&#30697;&#38453;&#24863;&#30693;&#21644;&#20108;&#27425;&#28608;&#27963;&#31070;&#32463;&#32593;&#32476;&#19978;&#21487;&#35777;&#22320;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Greedy Pruning with Group Lasso Provably Generalizes for Matrix Sensing and Neural Networks with Quadratic Activations. (arXiv:2303.11453v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11453
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#20013;&#30740;&#31350;&#20102;&#22522;&#20110;Group Lasso&#27491;&#21017;&#21270;&#22120;&#30340;&#36138;&#23146;&#21098;&#26525;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#20462;&#21098;&#20302;$\ell_2$&#33539;&#25968;&#21015;&#30340;&#35299;&#21487;&#20197;&#27867;&#21270;&#21040;&#26032;&#26679;&#26412;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21098;&#26525;&#26041;&#26696;&#24191;&#27867;&#29992;&#20110;&#38477;&#20302;&#20855;&#26377;&#22823;&#37327;&#21442;&#25968;&#30340;&#27169;&#22411;&#30340;&#22797;&#26434;&#24615;&#12290;&#23454;&#36341;&#30740;&#31350;&#34920;&#26126;&#65292;&#20462;&#21098;&#36807;&#24230;&#21442;&#25968;&#21270;&#27169;&#22411;&#24182;&#24494;&#35843;&#21487;&#24456;&#22909;&#22320;&#27867;&#21270;&#21040;&#26032;&#26679;&#26412;&#19978;&#12290;&#34429;&#28982;&#20197;&#19978;&#34987;&#31216;&#20026;&#21098;&#26525;+&#24494;&#35843;&#30340;&#27969;&#31243;&#22312;&#38477;&#20302;&#35757;&#32451;&#27169;&#22411;&#30340;&#22797;&#26434;&#24615;&#26041;&#38754;&#38750;&#24120;&#25104;&#21151;&#65292;&#20294;&#20854;&#32972;&#21518;&#30340;&#29702;&#35770;&#20173;&#28982;&#19981;&#29978;&#20102;&#35299;&#12290;&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#36229;&#21442;&#25968;&#21270;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#19978;&#30340;&#21098;&#26525;+&#24494;&#35843;&#26694;&#26550;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20854;&#20013;&#30495;&#23454;&#32467;&#26524;&#34920;&#31034;&#20026;$U_\star \in \mathbb{R}^{d \times r}$&#65292;&#32780;&#36229;&#21442;&#25968;&#21270;&#27169;&#22411;&#34920;&#31034;&#20026;$U \in \mathbb{R}^{d \times k}$&#65292;&#20854;&#20013;$k \gg r$&#12290;&#25105;&#20204;&#30740;&#31350;&#21152;&#19978;Group Lasso&#27491;&#21017;&#21270;&#22120;&#30340;&#24179;&#28369;&#29256;&#26412;$\sum_{i=1}^k \| U e_i \|_2$&#30340;&#24179;&#22343;&#35823;&#24046;&#30340;&#36817;&#20284;&#23616;&#37096;&#26497;&#23567;&#20540;&#65292;&#35777;&#26126;&#20462;&#21098;&#20302;$\ell_2$&#33539;&#25968;&#21015;&#30340;&#35299;$U_{
&lt;/p&gt;
&lt;p&gt;
Pruning schemes have been widely used in practice to reduce the complexity of trained models with a massive number of parameters. Several practical studies have shown that pruning an overparameterized model and fine-tuning generalizes well to new samples. Although the above pipeline, which we refer to as pruning + fine-tuning, has been extremely successful in lowering the complexity of trained models, there is very little known about the theory behind this success. In this paper we address this issue by investigating the pruning + fine-tuning framework on the overparameterized matrix sensing problem, with the ground truth denoted $U_\star \in \mathbb{R}^{d \times r}$ and the overparameterized model $U \in \mathbb{R}^{d \times k}$ with $k \gg r$. We study the approximate local minima of the empirical mean square error, augmented with a smooth version of a group Lasso regularizer, $\sum_{i=1}^k \| U e_i \|_2$ and show that pruning the low $\ell_2$-norm columns results in a solution $U_{\
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#34920;&#26126;&#40657;&#30418;&#21464;&#20998;&#25512;&#29702;&#65288;BBVI&#65289;&#28385;&#36275;SGD&#25991;&#29486;&#20013;&#30340;ABC&#26465;&#20214;&#65292;&#35813;&#32467;&#26524;&#36866;&#29992;&#20110;&#24179;&#28369;&#21644;&#20108;&#27425;&#22686;&#38271;&#30340;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#65292;&#21516;&#26102;&#25105;&#20204;&#30340;&#32467;&#26524;&#25512;&#24191;&#21040;&#24191;&#27867;&#24212;&#29992;&#20110;BBVI&#23454;&#36341;&#20013;&#30340;&#38750;&#32447;&#24615;&#21327;&#26041;&#24046;&#21442;&#25968;&#21270;&#12290;</title><link>http://arxiv.org/abs/2303.10472</link><description>&lt;p&gt;
&#40657;&#30418;&#21464;&#20998;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;&#23454;&#29992;&#21305;&#37197;&#26799;&#24230;&#26041;&#24046;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Practical and Matching Gradient Variance Bounds for Black-Box Variational Bayesian Inference. (arXiv:2303.10472v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10472
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#34920;&#26126;&#40657;&#30418;&#21464;&#20998;&#25512;&#29702;&#65288;BBVI&#65289;&#28385;&#36275;SGD&#25991;&#29486;&#20013;&#30340;ABC&#26465;&#20214;&#65292;&#35813;&#32467;&#26524;&#36866;&#29992;&#20110;&#24179;&#28369;&#21644;&#20108;&#27425;&#22686;&#38271;&#30340;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#65292;&#21516;&#26102;&#25105;&#20204;&#30340;&#32467;&#26524;&#25512;&#24191;&#21040;&#24191;&#27867;&#24212;&#29992;&#20110;BBVI&#23454;&#36341;&#20013;&#30340;&#38750;&#32447;&#24615;&#21327;&#26041;&#24046;&#21442;&#25968;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#40657;&#30418;&#21464;&#20998;&#25512;&#29702;&#65288;BBVI&#65289;&#30340;&#26799;&#24230;&#26041;&#24046;&#26159;&#24314;&#31435;&#20854;&#25910;&#25947;&#24615;&#21644;&#31639;&#27861;&#25913;&#36827;&#30340;&#20851;&#38190;&#19968;&#27493;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30740;&#31350;&#23578;&#26410;&#34920;&#26126;BBVI&#30340;&#26799;&#24230;&#26041;&#24046;&#28385;&#36275;&#29992;&#20110;&#30740;&#31350;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#25910;&#25947;&#30340;&#26465;&#20214;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#24212;&#29992;&#20110;&#24179;&#28369;&#21644;&#20108;&#27425;&#22686;&#38271;&#30340;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#26102;&#65292;BBVI&#28385;&#36275;&#19982;SGD&#25991;&#29486;&#20013;&#20351;&#29992;&#30340;ABC&#26465;&#20214;&#30456;&#21305;&#37197;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25512;&#24191;&#21040;&#24191;&#27867;&#24212;&#29992;&#20110;BBVI&#23454;&#36341;&#20013;&#30340;&#38750;&#32447;&#24615;&#21327;&#26041;&#24046;&#21442;&#25968;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#24179;&#22343;&#22330;&#21442;&#25968;&#21270;&#30340;&#26041;&#24046;&#20855;&#26377;&#32463;&#36807;&#39564;&#35777;&#30340;&#20248;&#36234;&#32500;&#24230;&#20381;&#36182;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding the gradient variance of black-box variational inference (BBVI) is a crucial step for establishing its convergence and developing algorithmic improvements. However, existing studies have yet to show that the gradient variance of BBVI satisfies the conditions used to study the convergence of stochastic gradient descent (SGD), the workhorse of BBVI. In this work, we show that BBVI satisfies a matching bound corresponding to the $ABC$ condition used in the SGD literature when applied to smooth and quadratically-growing log-likelihoods. Our results generalize to nonlinear covariance parameterizations widely used in the practice of BBVI. Furthermore, we show that the variance of the mean-field parameterization has provably superior dimensional dependence.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#26041;&#24046;&#32553;&#20943;&#35009;&#21098;&#26041;&#27861;SPIDER&#65292;&#21487;&#20197;&#23454;&#29616;&#22312;&#36739;&#23569;&#30340;&#38543;&#26426;&#26799;&#24230;&#35745;&#31639;&#27425;&#25968;&#19979;&#25214;&#21040;&#19968;&#20010;&#36739;&#31283;&#23450;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2303.00883</link><description>&lt;p&gt;
&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#26041;&#24046;&#32553;&#20943;&#35009;&#21098;
&lt;/p&gt;
&lt;p&gt;
Variance-reduced Clipping for Non-convex Optimization. (arXiv:2303.00883v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.00883
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#26041;&#24046;&#32553;&#20943;&#35009;&#21098;&#26041;&#27861;SPIDER&#65292;&#21487;&#20197;&#23454;&#29616;&#22312;&#36739;&#23569;&#30340;&#38543;&#26426;&#26799;&#24230;&#35745;&#31639;&#27425;&#25968;&#19979;&#25214;&#21040;&#19968;&#20010;&#36739;&#31283;&#23450;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26799;&#24230;&#35009;&#21098;&#26159;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#20013;&#30340;&#26631;&#20934;&#35757;&#32451;&#25216;&#26415;&#65292;&#29992;&#20110;&#20943;&#36731;&#26799;&#24230;&#29190;&#28856;&#31561;&#38382;&#39064;&#65292;&#26368;&#36817;&#30340;&#23454;&#39564;&#30740;&#31350;&#34920;&#26126;&#65292;&#24403;&#20351;&#29992;&#26799;&#24230;&#35009;&#21098;&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;&#35757;&#32451;&#30446;&#26631;&#27839;&#30528;&#20854;&#36712;&#36857;&#30340;&#24179;&#28369;&#24615;&#20855;&#26377;&#19968;&#31181;&#29305;&#27530;&#30340;&#34892;&#20026;&#65292;&#21363;&#24179;&#28369;&#24615;&#38543;&#30528;&#26799;&#24230;&#33539;&#25968;&#22686;&#38271;&#32780;&#22686;&#38271;&#12290;&#36825;&#19982;&#27665;&#38388;&#38750;&#20984;&#20248;&#21270;&#20013;&#24191;&#27867;&#27969;&#20256;&#30340;$L$-&#24179;&#28369;&#20551;&#35774;&#24418;&#25104;&#26126;&#26174;&#23545;&#27604;&#65292;&#21363;&#20840;&#23616;&#24179;&#28369;&#24615;&#34987;&#20551;&#23450;&#20026;&#30001;&#24120;&#25968;$L$&#19978;&#30028;&#12290;&#26368;&#36817;&#24341;&#20837;&#30340;$(L_0,L_1)$-&#24179;&#28369;&#24230;&#26159;&#19968;&#20010;&#26356;&#25918;&#26494;&#30340;&#27010;&#24565;&#65292;&#23427;&#25429;&#25417;&#21040;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#36825;&#31181;&#29305;&#24449;&#12290;&#29305;&#21035;&#26159;&#65292;&#22312;&#36825;&#31181;&#25918;&#26494;&#30340;&#24179;&#28369;&#24615;&#20551;&#35774;&#19979;&#65292;&#22312;SGD&#35009;&#21098;&#30340;&#24773;&#20917;&#19979;&#38656;&#35201;$O(\epsilon^{-4})$&#38543;&#26426;&#26799;&#24230;&#35745;&#31639;&#25165;&#33021;&#25214;&#21040;&#19968;&#20010;$\epsilon$-&#31283;&#23450;&#35299;&#12290;&#26412;&#25991;&#37319;&#29992;&#26041;&#24046;&#32553;&#20943;&#25216;&#26415;SPIDER&#65292;&#24182;&#28436;&#31034;&#22914;&#20309;&#22312;&#29702;&#35770;&#19978;&#20998;&#26512;&#35813;&#26041;&#27861;&#30340;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gradient clipping is a standard training technique used in deep learning applications such as large-scale language modeling to mitigate exploding gradients. Recent experimental studies have demonstrated a fairly special behavior in the smoothness of the training objective along its trajectory when trained with gradient clipping. That is, the smoothness grows with the gradient norm. This is in clear contrast to the well-established assumption in folklore non-convex optimization, a.k.a. $L$--smoothness, where the smoothness is assumed to be bounded by a constant $L$ globally. The recently introduced $(L_0,L_1)$--smoothness is a more relaxed notion that captures such behavior in non-convex optimization. In particular, it has been shown that under this relaxed smoothness assumption, SGD with clipping requires $O(\epsilon^{-4})$ stochastic gradient computations to find an $\epsilon$--stationary solution. In this paper, we employ a variance reduction technique, namely SPIDER, and demonstrate
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#8220;&#23433;&#20840;&#21093;&#31163;&#8221;&#26041;&#27861;&#21152;&#36895;&#35299;&#20915;L0&#27491;&#21017;&#21270;&#26368;&#23567;&#20108;&#20056;&#38382;&#39064;&#65292;&#36890;&#36807;&#25910;&#32553;&#26494;&#24347;&#24230;&#20801;&#35768;&#26356;&#28608;&#36827;&#30340;&#21098;&#26525;&#65292;&#26174;&#33879;&#38477;&#20302;&#27714;&#35299;&#26102;&#38388;&#12290;</title><link>http://arxiv.org/abs/2302.14471</link><description>&lt;p&gt;
&#23433;&#20840;&#21093;&#31163;L0&#27491;&#21017;&#21270;&#26368;&#23567;&#20108;&#20056;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Safe Peeling for L0-Regularized Least-Squares with supplementary material. (arXiv:2302.14471v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.14471
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#8220;&#23433;&#20840;&#21093;&#31163;&#8221;&#26041;&#27861;&#21152;&#36895;&#35299;&#20915;L0&#27491;&#21017;&#21270;&#26368;&#23567;&#20108;&#20056;&#38382;&#39064;&#65292;&#36890;&#36807;&#25910;&#32553;&#26494;&#24347;&#24230;&#20801;&#35768;&#26356;&#28608;&#36827;&#30340;&#21098;&#26525;&#65292;&#26174;&#33879;&#38477;&#20302;&#27714;&#35299;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;&#8220;&#23433;&#20840;&#21093;&#31163;&#8221;&#65292;&#36890;&#36807;&#20998;&#25903;&#23450;&#30028;&#31639;&#27861;&#21152;&#36895;&#35299;&#20915;L0&#27491;&#21017;&#21270;&#26368;&#23567;&#20108;&#20056;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#31243;&#24207;&#20351;&#24471;&#22312;BnB&#20915;&#31574;&#26641;&#30340;&#27599;&#20010;&#33410;&#28857;&#22788;&#32771;&#34385;&#21040;&#25910;&#32553;&#26494;&#24347;&#24230;&#65292;&#22240;&#27492;&#21487;&#33021;&#20801;&#35768;&#26356;&#21152;&#28608;&#36827;&#30340;&#21098;&#26525;&#12290;&#25968;&#20540;&#27169;&#25311;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#25506;&#32034;&#33410;&#28857;&#25968;&#37327;&#21644;&#25972;&#20307;&#27714;&#35299;&#26102;&#38388;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new methodology dubbed ``safe peeling'' to accelerate the resolution of L0-regularized least-squares problems via a Branch-and-Bound (BnB) algorithm. Our procedure enables to tighten the convex relaxation considered at each node of the BnB decision tree and therefore potentially allows for more aggressive pruning. Numerical simulations show that our proposed methodology leads to significant gains in terms of number of nodes explored and overall solving time.s show that our proposed methodology leads to significant gains in terms of number of nodes explored and overall solving time.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#32467;&#26500;&#30340;&#22810;&#26679;&#21270;&#20998;&#24067;&#36716;&#25442;&#30340;&#26041;&#27861;&#65292;&#24182;&#19988;&#38024;&#23545;&#24615;&#22320;&#35774;&#35745;&#20102;&#25968;&#25454;&#38598;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#36825;&#20123;&#20998;&#24067;&#36716;&#25442;&#23545;&#20110;&#29616;&#26377;&#30340;&#22270;&#27169;&#22411;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.13875</link><description>&lt;p&gt;
&#22312;&#32467;&#26500;&#20998;&#24067;&#20559;&#31227;&#26465;&#20214;&#19979;&#35780;&#20272;&#22270;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Evaluating Robustness and Uncertainty of Graph Models Under Structural Distributional Shifts. (arXiv:2302.13875v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.13875
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#32467;&#26500;&#30340;&#22810;&#26679;&#21270;&#20998;&#24067;&#36716;&#25442;&#30340;&#26041;&#27861;&#65292;&#24182;&#19988;&#38024;&#23545;&#24615;&#22320;&#35774;&#35745;&#20102;&#25968;&#25454;&#38598;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#36825;&#20123;&#20998;&#24067;&#36716;&#25442;&#23545;&#20110;&#29616;&#26377;&#30340;&#22270;&#27169;&#22411;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#21487;&#38752;&#20915;&#31574;&#31995;&#32479;&#20013;&#65292;&#27169;&#22411;&#24517;&#39035;&#23545;&#20998;&#24067;&#20559;&#31227;&#20855;&#26377;&#40065;&#26834;&#24615;&#25110;&#25552;&#20379;&#20854;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#22312;&#22270;&#23398;&#20064;&#30340;&#33410;&#28857;&#32423;&#38382;&#39064;&#20013;&#65292;&#20998;&#24067;&#20559;&#31227;&#21487;&#33021;&#23588;&#20026;&#22797;&#26434;&#65292;&#22240;&#20026;&#26679;&#26412;&#26159;&#30456;&#20114;&#20381;&#36182;&#30340;&#12290;&#20026;&#20102;&#35780;&#20272;&#22270;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#37325;&#35201;&#30340;&#26159;&#22312;&#21508;&#31181;&#26377;&#24847;&#20041;&#30340;&#20998;&#24067;&#20559;&#31227;&#19979;&#23545;&#23427;&#20204;&#36827;&#34892;&#27979;&#35797;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#32771;&#34385;&#33410;&#28857;&#32423;&#20998;&#24067;&#20559;&#31227;&#30340;&#22270;&#22522;&#20934;&#20027;&#35201;&#20851;&#27880;&#33410;&#28857;&#29305;&#24449;&#65292;&#32780;&#32467;&#26500;&#23646;&#24615;&#23545;&#22270;&#38382;&#39064;&#20063;&#24456;&#37325;&#35201;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#32467;&#26500;&#24341;&#20986;&#22810;&#26679;&#21270;&#20998;&#24067;&#20559;&#31227;&#30340;&#36890;&#29992;&#26041;&#27861;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#31181;&#26041;&#27861;&#26681;&#25454;&#20960;&#20010;&#33410;&#28857;&#30340;&#32467;&#26500;&#23646;&#24615;&#65306;&#27969;&#34892;&#24230;&#12289;&#23616;&#37096;&#24615;&#21644;&#23494;&#24230;&#26469;&#21019;&#24314;&#25968;&#25454;&#20998;&#21106;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#20840;&#38754;&#35780;&#20272;&#20102;&#25152;&#25552;&#20986;&#30340;&#20998;&#24067;&#20559;&#31227;&#65292;&#24182;&#34920;&#26126;&#23427;&#20204;&#23545;&#20110;&#29616;&#26377;&#30340;&#22270;&#27169;&#22411;&#21487;&#33021;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#25105;&#20204;&#36824;&#20462;&#35746;&#20102;&#19968;&#20123;&#20851;&#20110;&#22522;&#20934;&#27979;&#35797;&#22270;&#27169;&#22411;&#30340;&#20808;&#21069;&#24037;&#20316;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#32452;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#32771;&#34385;&#20102;&#32467;&#26500;&#20998;&#24067;&#20559;&#31227;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
In reliable decision-making systems based on machine learning, models have to be robust to distributional shifts or provide the uncertainty of their predictions. In node-level problems of graph learning, distributional shifts can be especially complex since the samples are interdependent. To evaluate the performance of graph models, it is important to test them on diverse and meaningful distributional shifts. However, most graph benchmarks considering distributional shifts for node-level problems focus mainly on node features, while structural properties are also essential for graph problems. In this work, we propose a general approach for inducing diverse distributional shifts based on graph structure. We use this approach to create data splits according to several structural node properties: popularity, locality, and density. In our experiments, we thoroughly evaluate the proposed distributional shifts and show that they can be quite challenging for existing graph models. We also rev
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33021;&#37327;&#25193;&#25955;&#27169;&#22411;&#21644;MCMC&#30340;&#32452;&#21512;&#29983;&#25104;&#26041;&#27861;&#65292;&#26088;&#22312;&#35299;&#20915;&#29616;&#26377;&#25216;&#26415;&#22312;&#32452;&#21512;&#29983;&#25104;&#20013;&#30340;&#22833;&#36133;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#25104;&#21151;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2302.11552</link><description>&lt;p&gt;
&#20943;&#23569;&#12289;&#37325;&#22797;&#21033;&#29992;&#12289;&#22238;&#25910;&#65306;&#22522;&#20110;&#33021;&#37327;&#25193;&#25955;&#27169;&#22411;&#21644;MCMC&#30340;&#32452;&#21512;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Reduce, Reuse, Recycle: Compositional Generation with Energy-Based Diffusion Models and MCMC. (arXiv:2302.11552v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.11552
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33021;&#37327;&#25193;&#25955;&#27169;&#22411;&#21644;MCMC&#30340;&#32452;&#21512;&#29983;&#25104;&#26041;&#27861;&#65292;&#26088;&#22312;&#35299;&#20915;&#29616;&#26377;&#25216;&#26415;&#22312;&#32452;&#21512;&#29983;&#25104;&#20013;&#30340;&#22833;&#36133;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#25104;&#21151;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#20174;&#25193;&#25955;&#27169;&#22411;&#38382;&#19990;&#20197;&#26469;&#65292;&#23427;&#22312;&#35768;&#22810;&#39046;&#22495;&#20013;&#24050;&#32463;&#36805;&#36895;&#25104;&#20026;&#29983;&#25104;&#27169;&#22411;&#30340;&#20027;&#35201;&#26041;&#27861;&#12290;&#23427;&#20204;&#21487;&#20197;&#34987;&#35299;&#37322;&#20026;&#23398;&#20064;&#19968;&#31995;&#21015;&#26102;&#21464;&#30340;&#23545;&#25968;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#30340;&#26799;&#24230;&#12290;&#36825;&#31181;&#35299;&#37322;&#24050;&#32463;&#28608;&#21457;&#20102;&#22522;&#20110;&#20998;&#31867;&#22120;&#21644;&#26080;&#20998;&#31867;&#22120;&#25351;&#23548;&#30340;&#24605;&#24819;&#25104;&#20026;&#21518;&#32493;&#25511;&#21046;&#25193;&#25955;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#22312;&#36825;&#20123;&#24819;&#27861;&#30340;&#22522;&#30784;&#19978;&#65292;&#21033;&#29992;&#25193;&#25955;&#27169;&#22411;&#30340;&#20998;&#25968;-based&#35299;&#37322;&#65292;&#25506;&#32034;&#20102;&#29992;&#20110;&#28041;&#21450;&#32452;&#21512;&#29983;&#25104;&#21644;&#25351;&#23548;&#30340;&#26465;&#20214;&#12289;&#20462;&#25913;&#21644;&#37325;&#22797;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#20026;&#20160;&#20040;&#26576;&#20123;&#31867;&#22411;&#30340;&#32452;&#21512;&#20351;&#29992;&#24403;&#21069;&#25216;&#26415;&#22833;&#36133;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#20123;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65292;&#37319;&#26679;&#32773;(&#32780;&#19981;&#26159;&#27169;&#22411;)&#23545;&#27492;&#22833;&#36133;&#36127;&#26377;&#36131;&#20219;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#37319;&#26679;&#22120;&#65292;&#21463;MCMC&#30340;&#21551;&#21457;&#65292;&#20351;&#32452;&#21512;&#29983;&#25104;&#25104;&#21151;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33021;&#37327;&#30340;&#25193;&#25955;&#27169;&#22411;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#23427;&#20351;&#24471;&#36924;&#36817;&#30446;&#26631;&#20998;&#24067;&#26356;&#21152;&#23481;&#26131;&#12290;
&lt;/p&gt;
&lt;p&gt;
Since their introduction, diffusion models have quickly become the prevailing approach to generative modeling in many domains. They can be interpreted as learning the gradients of a time-varying sequence of log-probability density functions. This interpretation has motivated classifier-based and classifier-free guidance as methods for post-hoc control of diffusion models. In this work, we build upon these ideas using the score-based interpretation of diffusion models, and explore alternative ways to condition, modify, and reuse diffusion models for tasks involving compositional generation and guidance. In particular, we investigate why certain types of composition fail using current techniques and present a number of solutions. We conclude that the sampler (not the model) is responsible for this failure and propose new samplers, inspired by MCMC, which enable successful compositional generation. Further, we propose an energy-based parameterization of diffusion models which enables the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#22312;&#22270;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#29702;&#35770;&#35752;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#25345;&#32493;&#21516;&#35843;&#25216;&#26415;&#22312;&#25429;&#25417;&#20855;&#26377;&#26174;&#33879;&#25299;&#25169;&#32467;&#26500;&#30340;&#25968;&#25454;&#38598;&#20013;&#30340;&#38271;&#31243;&#22270;&#24615;&#36136;&#26041;&#38754;&#34920;&#29616;&#20986;&#30340;&#39640;&#34920;&#36798;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.09826</link><description>&lt;p&gt;
&#25345;&#32493;&#21516;&#35843;&#22312;&#22270;&#23398;&#20064;&#20013;&#30340;&#34920;&#36798;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Expressivity of Persistent Homology in Graph Learning. (arXiv:2302.09826v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09826
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#22312;&#22270;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#29702;&#35770;&#35752;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#25345;&#32493;&#21516;&#35843;&#25216;&#26415;&#22312;&#25429;&#25417;&#20855;&#26377;&#26174;&#33879;&#25299;&#25169;&#32467;&#26500;&#30340;&#25968;&#25454;&#38598;&#20013;&#30340;&#38271;&#31243;&#22270;&#24615;&#36136;&#26041;&#38754;&#34920;&#29616;&#20986;&#30340;&#39640;&#34920;&#36798;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26469;&#65292;&#35745;&#31639;&#25299;&#25169;&#23398;&#20013;&#30340;&#19968;&#39033;&#25216;&#26415;&#65292;&#25345;&#32493;&#21516;&#35843;&#23637;&#29616;&#20986;&#22312;&#22270;&#20998;&#31867;&#26041;&#38754;&#24378;&#22823;&#30340;&#23454;&#35777;&#24615;&#33021;&#12290;&#23427;&#33021;&#22815;&#36890;&#36807;&#39640;&#38454;&#25299;&#25169;&#29305;&#24449;&#8212;&#8212;&#22914;&#20219;&#24847;&#38271;&#24230;&#30340;&#29615;&#8212;&#8212;&#20197;&#21450;&#22810;&#23610;&#24230;&#25299;&#25169;&#25551;&#36848;&#31526;&#25429;&#25417;&#38271;&#31243;&#22270;&#24615;&#36136;&#65292;&#20174;&#32780;&#25552;&#39640;&#23545;&#20855;&#26377;&#26174;&#33879;&#25299;&#25169;&#32467;&#26500;&#30340;&#25968;&#25454;&#38598;&#8212;&#8212;&#22914;&#20998;&#23376;&#8212;&#8212;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#25345;&#32493;&#21516;&#35843;&#30340;&#29702;&#35770;&#24615;&#36136;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#23578;&#26410;&#24471;&#21040;&#27491;&#24335;&#35780;&#20272;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#25552;&#20379;&#25345;&#32493;&#21516;&#35843;&#22312;&#22270;&#20013;&#30340;&#31616;&#35201;&#20171;&#32461;&#20197;&#21450;&#23545;&#20854;&#22312;&#22270;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#34920;&#36798;&#24615;&#36827;&#34892;&#29702;&#35770;&#35752;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#65292;&#24357;&#21512;&#35745;&#31639;&#25299;&#25169;&#23398;&#21644;&#22270;&#26426;&#22120;&#23398;&#20064;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
Persistent homology, a technique from computational topology, has recently shown strong empirical performance in the context of graph classification. Being able to capture long range graph properties via higher-order topological features, such as cycles of arbitrary length, in combination with multi-scale topological descriptors, has improved predictive performance for data sets with prominent topological structures, such as molecules. At the same time, the theoretical properties of persistent homology have not been formally assessed in this context. This paper intends to bridge the gap between computational topology and graph machine learning by providing a brief introduction to persistent homology in the context of graphs, as well as a theoretical discussion and empirical analysis of its expressivity for graph learning tasks.
&lt;/p&gt;</description></item><item><title>GFlowNet-EM&#37319;&#29992;GFlowNets&#31639;&#27861;&#20316;&#20026;&#24314;&#27169;&#28508;&#21464;&#37327;&#21518;&#39564;&#27010;&#29575;&#30340;E&#27493;&#39588;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23545;&#20855;&#26377;&#31163;&#25955;&#32452;&#21512;&#28508;&#21464;&#37327;&#30340;&#34920;&#29616;&#21147;&#24378;&#30340;LVM&#36827;&#34892;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2302.06576</link><description>&lt;p&gt;
GFlowNet-EM&#29992;&#20110;&#23398;&#20064;&#32452;&#21512;&#38544;&#21464;&#37327;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
GFlowNet-EM for learning compositional latent variable models. (arXiv:2302.06576v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06576
&lt;/p&gt;
&lt;p&gt;
GFlowNet-EM&#37319;&#29992;GFlowNets&#31639;&#27861;&#20316;&#20026;&#24314;&#27169;&#28508;&#21464;&#37327;&#21518;&#39564;&#27010;&#29575;&#30340;E&#27493;&#39588;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23545;&#20855;&#26377;&#31163;&#25955;&#32452;&#21512;&#28508;&#21464;&#37327;&#30340;&#34920;&#29616;&#21147;&#24378;&#30340;LVM&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20855;&#26377;&#31163;&#25955;&#32452;&#21512;&#28508;&#21464;&#37327;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#65288;LVM&#65289;&#26159;&#19968;&#20010;&#37325;&#35201;&#20294;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#39046;&#22495;&#65292;&#30001;&#20110;&#28508;&#21464;&#37327;&#30340;&#21487;&#33021;&#32452;&#21512;&#25968;&#37327;&#32452;&#21512;&#24456;&#22823;&#12290;&#22312;&#24314;&#27169;&#28508;&#21464;&#37327;&#30340;&#21518;&#39564;&#27010;&#29575;&#26102;&#65292;&#34920;&#29616;&#21644;&#21487;&#36319;&#36394;&#30340;&#20248;&#21270;&#20043;&#38388;&#20855;&#26377;&#20851;&#38190;&#30340;&#26435;&#34913;&#12290;&#23545;&#20110;&#22522;&#20110;&#26399;&#26395;&#26368;&#22823;&#21270;&#65288;EM&#65289;&#30340;&#31639;&#27861;&#65292;E-&#27493;&#39588;&#24448;&#24448;&#22312;&#27809;&#26377;&#23545;&#21518;&#39564;&#36827;&#34892;&#38480;&#21046;&#30340;&#36817;&#20284;&#30340;&#24773;&#20917;&#19979;&#26159;&#19981;&#21487;&#36319;&#36394;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;GFlowNets&#65292;&#19968;&#31181;&#23398;&#20064;&#20174;&#26410;&#35268;&#33539;&#21270;&#30340;&#23494;&#24230;&#20013;&#37319;&#26679;&#30340;&#38543;&#26426;&#31574;&#30053;&#20197;&#36827;&#34892;&#39034;&#24207;&#26679;&#26412;&#26500;&#24314;&#30340;&#31639;&#27861;&#65292;&#26469;&#22788;&#29702;&#36825;&#20010;&#19981;&#21487;&#36319;&#36394;&#30340;E-&#27493;&#39588;&#12290;&#36890;&#36807;&#35757;&#32451;GFlowNets&#20174;&#28508;&#21464;&#37327;&#21518;&#39564;&#20013;&#37319;&#26679;&#65292;&#25105;&#20204;&#21033;&#29992;&#20102;&#23427;&#20204;&#20316;&#20026;&#31163;&#25955;&#32467;&#26500;&#22797;&#26434;&#20998;&#24067;&#30340;&#21464;&#20998;&#25512;&#29702;&#31639;&#27861;&#30340;&#20248;&#21183;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;GFlowNet-EM&#65292;&#21487;&#20197;&#23454;&#29616;&#23545;&#20855;&#26377;&#31163;&#25955;&#32452;&#21512;&#28508;&#21464;&#37327;&#30340;&#34920;&#29616;&#21147;&#24378;&#30340;LVM&#36827;&#34892;&#35757;&#32451;&#65292;&#22914;&#22312;&#38750;&#19978;&#19979;&#25991;&#26080;&#20851;&#25991;&#27861;&#24402;&#32435;&#21644;&#22270;&#20687;&#32763;&#35793;&#23454;&#39564;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Latent variable models (LVMs) with discrete compositional latents are an important but challenging setting due to a combinatorially large number of possible configurations of the latents. A key tradeoff in modeling the posteriors over latents is between expressivity and tractable optimization. For algorithms based on expectation-maximization (EM), the E-step is often intractable without restrictive approximations to the posterior. We propose the use of GFlowNets, algorithms for sampling from an unnormalized density by learning a stochastic policy for sequential construction of samples, for this intractable E-step. By training GFlowNets to sample from the posterior over latents, we take advantage of their strengths as amortized variational inference algorithms for complex distributions over discrete structures. Our approach, GFlowNet-EM, enables the training of expressive LVMs with discrete compositional latents, as shown by experiments on non-context-free grammar induction and on image
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; DIFF2 &#30340;&#26032;&#22411;&#24046;&#20998;&#38544;&#31169;&#20248;&#21270;&#26694;&#26550;&#65292;&#20854;&#20197;&#26799;&#24230;&#24046;&#24322;&#20026;&#22522;&#30784;&#26500;&#36896;&#20102;&#19968;&#20010;&#20855;&#26377;&#23567;&#26041;&#24046;&#30340;&#20840;&#23616;&#26799;&#24230;&#20272;&#35745;&#22120;&#65292;&#30456;&#27604;&#20110;&#20043;&#21069;&#30340;&#31639;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#38750;&#20984;&#24179;&#28369;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#20013;&#33021;&#22815;&#26356;&#22909;&#22320;&#20943;&#23567;&#35823;&#24046;&#19979;&#30028;&#65292;&#25552;&#39640;&#25928;&#29992;&#12290;</title><link>http://arxiv.org/abs/2302.03884</link><description>&lt;p&gt;
DIFF2: &#22522;&#20110;&#26799;&#24230;&#24046;&#24322;&#30340;&#24046;&#20998;&#38544;&#31169;&#20248;&#21270;&#26041;&#27861;&#29992;&#20110;&#38750;&#20984;&#20998;&#24067;&#24335;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
DIFF2: Differential Private Optimization via Gradient Differences for Nonconvex Distributed Learning. (arXiv:2302.03884v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03884
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; DIFF2 &#30340;&#26032;&#22411;&#24046;&#20998;&#38544;&#31169;&#20248;&#21270;&#26694;&#26550;&#65292;&#20854;&#20197;&#26799;&#24230;&#24046;&#24322;&#20026;&#22522;&#30784;&#26500;&#36896;&#20102;&#19968;&#20010;&#20855;&#26377;&#23567;&#26041;&#24046;&#30340;&#20840;&#23616;&#26799;&#24230;&#20272;&#35745;&#22120;&#65292;&#30456;&#27604;&#20110;&#20043;&#21069;&#30340;&#31639;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#38750;&#20984;&#24179;&#28369;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#20013;&#33021;&#22815;&#26356;&#22909;&#22320;&#20943;&#23567;&#35823;&#24046;&#19979;&#30028;&#65292;&#25552;&#39640;&#25928;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#38750;&#20984;&#24179;&#28369;&#30446;&#26631;&#30340;&#24046;&#20998;&#38544;&#31169;&#20248;&#21270;&#38382;&#39064;&#12290;&#22312;&#20197;&#24448;&#30340;&#24037;&#20316;&#20013;&#65292;&#22522;&#20110;&#20840;&#26799;&#24230;&#33539;&#25968;&#30340;&#26368;&#20339;&#25928;&#29992;&#36793;&#30028;&#24050;&#30693;&#20026; $\widetilde O(\sqrt{d}/(n\varepsilon_\mathrm{DP}))$&#65292;&#20854;&#20013; $n$ &#20026;&#26679;&#26412;&#22823;&#23567;&#65292;$d$ &#20026;&#38382;&#39064;&#32500;&#24230;&#65292;$\varepsilon_\mathrm{DP}$ &#20026;&#24046;&#20998;&#38544;&#31169;&#21442;&#25968;&#65292;DP-GD &#26159;&#23454;&#29616;&#35813;&#36793;&#30028;&#30340;&#19968;&#31181;&#31639;&#27861;&#12290;&#20026;&#20102;&#25552;&#39640;&#24050;&#30693;&#30340;&#25928;&#29992;&#36793;&#30028;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24046;&#20998;&#38544;&#31169;&#20248;&#21270;&#26694;&#26550; DIFF2&#65288;DIFFerential private optimization via gradient DIFFerences&#65289;&#65292;&#23427;&#26500;&#36896;&#20102;&#19968;&#20010;&#24046;&#20998;&#38544;&#31169;&#20840;&#23616;&#26799;&#24230;&#20272;&#35745;&#22120;&#65292;&#35813;&#20272;&#35745;&#22120;&#20855;&#26377;&#21487;&#33021;&#38750;&#24120;&#23567;&#30340;&#26041;&#24046;&#65292;&#22522;&#20110;&#36890;&#20449;&#30340;&#8220;&#26799;&#24230;&#24046;&#24322;&#8221;&#65292;&#32780;&#19981;&#26159;&#26799;&#24230;&#26412;&#36523;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#23376;&#20363;&#31243;&#30340; DIFF2 &#23454;&#29616;&#30340;&#25928;&#29992;&#20026; $\widetilde O(d^{2/3}/(n\varepsilon_\mathrm{DP})^{4/3})$&#65292;&#27604;&#20808;&#21069;&#30340;&#26041;&#27861;&#26174;&#33879;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differential private optimization for nonconvex smooth objective is considered. In the previous work, the best known utility bound is $\widetilde O(\sqrt{d}/(n\varepsilon_\mathrm{DP}))$ in terms of the squared full gradient norm, which is achieved by Differential Private Gradient Descent (DP-GD) as an instance, where $n$ is the sample size, $d$ is the problem dimensionality and $\varepsilon_\mathrm{DP}$ is the differential privacy parameter. To improve the best known utility bound, we propose a new differential private optimization framework called \emph{DIFF2 (DIFFerential private optimization via gradient DIFFerences)} that constructs a differential private global gradient estimator with possibly quite small variance based on communicated \emph{gradient differences} rather than gradients themselves. It is shown that DIFF2 with a gradient descent subroutine achieves the utility of $\widetilde O(d^{2/3}/(n\varepsilon_\mathrm{DP})^{4/3})$, which can be significantly better than the prev
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#8220;&#38543;&#26426;&#28857;&#31934;&#24230;&#27979;&#35797;&#8221;&#65288;TARP&#65289;&#35206;&#30422;&#27979;&#35797;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#29983;&#25104;&#21518;&#39564;&#20272;&#35745;&#22120;&#35206;&#30422;&#27010;&#29575;&#12290;&#35813;&#26041;&#27861;&#26159;&#19968;&#31181;&#20272;&#35745;&#29983;&#25104;&#27169;&#22411;&#20013;&#32534;&#30721;&#21518;&#39564;&#31934;&#24230;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;&#35813;&#26041;&#27861;&#21487;&#29992;&#20110;&#27979;&#35797;&#39640;&#32500;&#31354;&#38388;&#20013;&#21518;&#39564;&#25512;&#26029;&#20998;&#26512;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2302.03026</link><description>&lt;p&gt;
&#22522;&#20110;&#37319;&#26679;&#30340;&#36890;&#29992;&#25512;&#26029;&#21518;&#39564;&#20272;&#35745;&#31934;&#24230;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Sampling-Based Accuracy Testing of Posterior Estimators for General Inference. (arXiv:2302.03026v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03026
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#8220;&#38543;&#26426;&#28857;&#31934;&#24230;&#27979;&#35797;&#8221;&#65288;TARP&#65289;&#35206;&#30422;&#27979;&#35797;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#29983;&#25104;&#21518;&#39564;&#20272;&#35745;&#22120;&#35206;&#30422;&#27010;&#29575;&#12290;&#35813;&#26041;&#27861;&#26159;&#19968;&#31181;&#20272;&#35745;&#29983;&#25104;&#27169;&#22411;&#20013;&#32534;&#30721;&#21518;&#39564;&#31934;&#24230;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;&#35813;&#26041;&#27861;&#21487;&#29992;&#20110;&#27979;&#35797;&#39640;&#32500;&#31354;&#38388;&#20013;&#21518;&#39564;&#25512;&#26029;&#20998;&#26512;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21442;&#25968;&#25512;&#26029;&#26159;&#35768;&#22810;&#31185;&#23398;&#23398;&#31185;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#65292;&#21363;&#22312;&#32473;&#23450;&#19968;&#20123;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#25512;&#26029;&#32479;&#35745;&#27169;&#22411;&#21442;&#25968;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#29983;&#25104;&#27169;&#22411;&#21487;&#29992;&#20316;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#29992;&#20110;&#36827;&#34892;&#22522;&#20110;&#20284;&#28982;&#21644;&#22522;&#20110;&#27169;&#25311;&#30340;&#21518;&#39564;&#25512;&#26029;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#20013;&#32534;&#30721;&#30340;&#21518;&#39564;&#31934;&#24230;&#24182;&#19981;&#31616;&#21333;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#8220;&#38543;&#26426;&#28857;&#31934;&#24230;&#27979;&#35797;&#8221;&#65288;TARP&#65289;&#35206;&#30422;&#27979;&#35797;&#20316;&#20026;&#19968;&#31181;&#20272;&#35745;&#29983;&#25104;&#21518;&#39564;&#20272;&#35745;&#22120;&#35206;&#30422;&#27010;&#29575;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#21516;&#20110;&#20197;&#21069;&#23384;&#22312;&#30340;&#38656;&#35201;&#21518;&#39564;&#35780;&#20272;&#30340;&#22522;&#20110;&#35206;&#30422;&#29575;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#30830;&#23450;&#21518;&#39564;&#20272;&#35745;&#22120;&#20934;&#30830;&#24615;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#21512;&#25104;&#31034;&#20363;&#19978;&#28436;&#31034;&#20102;&#35813;&#26041;&#27861;&#65292;&#24182;&#34920;&#26126;TARP&#21487;&#29992;&#20110;&#27979;&#35797;&#39640;&#32500;&#31354;&#38388;&#20013;&#21518;&#39564;&#25512;&#26029;&#20998;&#26512;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Parameter inference, i.e. inferring the posterior distribution of the parameters of a statistical model given some data, is a central problem to many scientific disciplines. Generative models can be used as an alternative to Markov Chain Monte Carlo methods for conducting posterior inference, both in likelihood-based and simulation-based problems. However, assessing the accuracy of posteriors encoded in generative models is not straightforward. In this paper, we introduce `Tests of Accuracy with Random Points' (TARP) coverage testing as a method to estimate coverage probabilities of generative posterior estimators. Our method differs from previously-existing coverage-based methods, which require posterior evaluations. We prove that our approach is necessary and sufficient to show that a posterior estimator is accurate. We demonstrate the method on a variety of synthetic examples, and show that TARP can be used to test the results of posterior inference analyses in high-dimensional spac
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102; RLSbench&#65292;&#23427;&#26159;&#19968;&#20010;&#22823;&#35268;&#27169;&#22522;&#20934;&#65292;&#29992;&#20110;&#23485;&#26494;&#26631;&#31614;&#20559;&#31227;&#12290;&#19982;&#29616;&#26377;&#22522;&#20934;&#19981;&#21516;&#65292;&#23427;&#26088;&#22312;&#35780;&#20272;&#39046;&#22495;&#33258;&#36866;&#24212;&#26041;&#27861;&#22312;&#26631;&#31614;&#36793;&#38469;&#20559;&#31227;&#19979;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2302.03020</link><description>&lt;p&gt;
RLSbench: &#23485;&#26494;&#26631;&#31614;&#20559;&#31227;&#19979;&#30340;&#39046;&#22495;&#33258;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
RLSbench: Domain Adaptation Under Relaxed Label Shift. (arXiv:2302.03020v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03020
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102; RLSbench&#65292;&#23427;&#26159;&#19968;&#20010;&#22823;&#35268;&#27169;&#22522;&#20934;&#65292;&#29992;&#20110;&#23485;&#26494;&#26631;&#31614;&#20559;&#31227;&#12290;&#19982;&#29616;&#26377;&#22522;&#20934;&#19981;&#21516;&#65292;&#23427;&#26088;&#22312;&#35780;&#20272;&#39046;&#22495;&#33258;&#36866;&#24212;&#26041;&#27861;&#22312;&#26631;&#31614;&#36793;&#38469;&#20559;&#31227;&#19979;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#20986;&#29616;&#20102;&#35299;&#20915;&#26631;&#31614;&#20559;&#31227;&#19979;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#21407;&#21017;&#24615;&#26041;&#27861;&#65292;&#20294;&#23545;&#20110;&#31867;&#26465;&#20214;&#20998;&#24067;&#30340;&#20559;&#31227;&#25935;&#24863;&#24615;&#21364;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#32034;&#12290;&#21516;&#26102;&#65292;&#27969;&#34892;&#30340;&#28145;&#24230;&#39046;&#22495;&#33258;&#36866;&#24212;&#21551;&#21457;&#24335;&#26041;&#27861;&#22312;&#38754;&#23545;&#26631;&#31614;&#27604;&#20363;&#20559;&#31227;&#26102;&#24448;&#24448;&#30130;&#36719;&#12290;&#34429;&#28982;&#26377;&#20960;&#31687;&#35770;&#25991;&#25913;&#36827;&#20102;&#36825;&#20123;&#21551;&#21457;&#26041;&#27861;&#20197;&#23581;&#35797;&#22788;&#29702;&#26631;&#31614;&#27604;&#20363;&#20559;&#31227;&#65292;&#20294;&#35780;&#20272;&#26631;&#20934;&#12289;&#25968;&#25454;&#38598;&#21644;&#22522;&#32447;&#30340;&#19981;&#19968;&#33268;&#20351;&#24471;&#35780;&#20272;&#24403;&#21069;&#26368;&#20339;&#23454;&#36341;&#21464;&#24471;&#22256;&#38590;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837; RLSbench&#65292;&#19968;&#20010;&#22823;&#35268;&#27169;&#30340;&#23485;&#26494;&#26631;&#31614;&#20559;&#31227;&#22522;&#20934;&#65292;&#28085;&#30422;500&#22810;&#20010;&#20998;&#24067;&#20559;&#31227;&#23545;&#65292;&#36328;&#35270;&#35273;&#12289;&#34920;&#26684;&#21644;&#35821;&#35328;&#27169;&#24335;&#65292;&#20855;&#26377;&#19981;&#21516;&#30340;&#26631;&#31614;&#27604;&#20363;&#12290;&#19982;&#29616;&#26377;&#22522;&#20934;&#20027;&#35201;&#20851;&#27880;&#31867;&#26465;&#20214;$p(x|y)$&#20559;&#31227;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#22522;&#20934;&#36824;&#20851;&#27880;&#26631;&#31614;&#36793;&#38469;&#20559;&#31227;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;13&#31181;&#27969;&#34892;&#30340;&#39046;&#22495;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#35777;&#26126;&#22312;&#26631;&#31614;&#27604;&#20363;&#20559;&#31227;&#19979;&#26356;&#26222;&#36941;&#22320;&#22833;&#36133;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the emergence of principled methods for domain adaptation under label shift, their sensitivity to shifts in class conditional distributions is precariously under explored. Meanwhile, popular deep domain adaptation heuristics tend to falter when faced with label proportions shifts. While several papers modify these heuristics in attempts to handle label proportions shifts, inconsistencies in evaluation standards, datasets, and baselines make it difficult to gauge the current best practices. In this paper, we introduce RLSbench, a large-scale benchmark for relaxed label shift, consisting of $&gt;$500 distribution shift pairs spanning vision, tabular, and language modalities, with varying label proportions. Unlike existing benchmarks, which primarily focus on shifts in class-conditional $p(x|y)$, our benchmark also focuses on label marginal shifts. First, we assess 13 popular domain adaptation methods, demonstrating more widespread failures under label proportion shifts than were pre
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21487;&#24494;&#20998;&#21644;&#31232;&#30095;&#30340;Top-k&#36816;&#31639;&#31526;&#65292;&#23558;&#20854;&#35270;&#20026;&#25490;&#21015;&#20984;&#21253;&#19978;&#30340;&#32447;&#24615;&#35268;&#21010;&#65292;&#24182;&#24341;&#20837;p-&#33539;&#25968;&#27491;&#21017;&#21270;&#39033;&#20197;&#24179;&#28369;&#36816;&#31639;&#31526;&#12290;&#31639;&#27861;&#26041;&#38754;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36817;&#31471;&#31639;&#23376;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#36827;&#34892;Top-k&#36816;&#31639;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#22810;&#20010;&#20219;&#21153;&#20013;&#37117;&#24456;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2302.01425</link><description>&lt;p&gt;
&#24555;&#36895;&#65292;&#21487;&#24494;&#20998;&#21644;&#31232;&#30095;&#30340;Top-k: &#20984;&#20998;&#26512;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Fast, Differentiable and Sparse Top-k: a Convex Analysis Perspective. (arXiv:2302.01425v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.01425
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21487;&#24494;&#20998;&#21644;&#31232;&#30095;&#30340;Top-k&#36816;&#31639;&#31526;&#65292;&#23558;&#20854;&#35270;&#20026;&#25490;&#21015;&#20984;&#21253;&#19978;&#30340;&#32447;&#24615;&#35268;&#21010;&#65292;&#24182;&#24341;&#20837;p-&#33539;&#25968;&#27491;&#21017;&#21270;&#39033;&#20197;&#24179;&#28369;&#36816;&#31639;&#31526;&#12290;&#31639;&#27861;&#26041;&#38754;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36817;&#31471;&#31639;&#23376;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#36827;&#34892;Top-k&#36816;&#31639;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#22810;&#20010;&#20219;&#21153;&#20013;&#37117;&#24456;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Top-k&#36816;&#31639;&#31526;&#36820;&#22238;&#19968;&#20010;&#31232;&#30095;&#21521;&#37327;&#65292;&#20854;&#20013;&#38750;&#38646;&#20540;&#23545;&#24212;&#20110;&#36755;&#20837;k&#20010;&#26368;&#22823;&#20540;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23427;&#26159;&#19968;&#20010;&#19981;&#36830;&#32493;&#30340;&#20989;&#25968;&#65292;&#25152;&#20197;&#24456;&#38590;&#23558;&#20854;&#32435;&#20837;&#20351;&#29992;&#21453;&#21521;&#20256;&#25773;&#36827;&#34892;&#31471;&#21040;&#31471;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#12290;&#26412;&#25991;&#25552;&#20986;&#26032;&#30340;&#21487;&#24494;&#20998;&#21644;&#31232;&#30095;&#30340;Top-k&#36816;&#31639;&#31526;&#12290;&#25105;&#20204;&#23558;Top-k&#36816;&#31639;&#31526;&#35270;&#20026;&#25490;&#21015;&#20984;&#21253;&#19978;&#30340;&#32447;&#24615;&#35268;&#21010;&#65292;&#24182;&#24341;&#20837;p-&#33539;&#25968;&#27491;&#21017;&#21270;&#39033;&#20197;&#24179;&#28369;&#36816;&#31639;&#31526;&#65292;&#35777;&#26126;&#20854;&#35745;&#31639;&#21487;&#20197;&#20943;&#23569;&#21040;&#21516;&#21521;&#20248;&#21270;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#26694;&#26550;&#26174;&#33879;&#27604;&#29616;&#26377;&#26694;&#26550;&#26356;&#36890;&#29992;&#65292;&#21487;&#20197;&#34920;&#31034;&#36873;&#25321;&#22823;&#23567;&#20540;&#30340;Top-k&#36816;&#31639;&#31526;&#12290;&#22312;&#31639;&#27861;&#26041;&#38754;&#65292;&#38500;&#20102;&#27744;&#30456;&#37051;&#36829;&#35268;&#31639;&#27861;&#65288;PAV&#65289;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36817;&#31471;&#31639;&#23376;&#65292;&#20801;&#35768;&#26377;&#25928;&#30340;Top-k&#36816;&#31639;&#65292;&#24182;&#21487;&#36731;&#26494;&#38598;&#25104;&#21040;&#31070;&#32463;&#32593;&#32476;&#20013;&#12290;&#22312;&#22270;&#20687;&#20998;&#31867;&#21644;&#24207;&#21015;&#26631;&#35760;&#31561;&#22810;&#20010;&#20219;&#21153;&#19978;&#30340;&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The top-k operator returns a sparse vector, where the non-zero values correspond to the k largest values of the input. Unfortunately, because it is a discontinuous function, it is difficult to incorporate in neural networks trained end-to-end with backpropagation. Recent works have considered differentiable relaxations, based either on regularization or perturbation techniques. However, to date, no approach is fully differentiable and sparse. In this paper, we propose new differentiable and sparse top-k operators. We view the top-k operator as a linear program over the permutahedron, the convex hull of permutations. We then introduce a p-norm regularization term to smooth out the operator, and show that its computation can be reduced to isotonic optimization. Our framework is significantly more general than the existing one and allows for example to express top-k operators that select values in magnitude. On the algorithmic side, in addition to pool adjacent violator (PAV) algorithms, 
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#25552;&#20986;&#23569;&#26679;&#26412;&#23398;&#20064;&#30340;&#34920;&#29616;&#19982;&#20154;&#31867;&#34920;&#24449;&#30340;&#19968;&#33268;&#24615;&#23384;&#22312;U&#24418;&#20851;&#31995;&#65292;&#24182;&#36890;&#36807;&#35745;&#31639;&#26426;&#35270;&#35273;&#27169;&#22411;&#30340;&#23454;&#39564;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;&#39640;&#24230;&#23545;&#40784;&#30340;&#27169;&#22411;&#26356;&#21152;&#40065;&#26834;&#65292;&#23545;&#25968;&#25454;&#30340;&#21033;&#29992;&#26356;&#21152;&#26377;&#25928;&#65292;&#20294;&#19982;&#20154;&#31867;&#23545;&#40784;&#24182;&#38750;&#24517;&#35201;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2301.11990</link><description>&lt;p&gt;
&#19982;&#20154;&#31867;&#34920;&#24449;&#30340;&#19968;&#33268;&#24615;&#25903;&#25345;&#40065;&#26834;&#30340;&#23569;&#26679;&#26412;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Alignment with human representations supports robust few-shot learning. (arXiv:2301.11990v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11990
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25552;&#20986;&#23569;&#26679;&#26412;&#23398;&#20064;&#30340;&#34920;&#29616;&#19982;&#20154;&#31867;&#34920;&#24449;&#30340;&#19968;&#33268;&#24615;&#23384;&#22312;U&#24418;&#20851;&#31995;&#65292;&#24182;&#36890;&#36807;&#35745;&#31639;&#26426;&#35270;&#35273;&#27169;&#22411;&#30340;&#23454;&#39564;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;&#39640;&#24230;&#23545;&#40784;&#30340;&#27169;&#22411;&#26356;&#21152;&#40065;&#26834;&#65292;&#23545;&#25968;&#25454;&#30340;&#21033;&#29992;&#26356;&#21152;&#26377;&#25928;&#65292;&#20294;&#19982;&#20154;&#31867;&#23545;&#40784;&#24182;&#38750;&#24517;&#35201;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#26159;&#21542;&#24212;&#35813;&#20851;&#24515;AI&#31995;&#32479;&#26159;&#21542;&#20855;&#26377;&#19982;&#20154;&#31867;&#30456;&#20284;&#30340;&#19990;&#30028;&#34920;&#24449;&#65311;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#20449;&#24687;&#35770;&#20998;&#26512;&#65292;&#24314;&#35758;&#22312;&#23569;&#26679;&#26412;&#23398;&#20064;&#20219;&#21153;&#30340;&#34920;&#29616;&#24230;&#19982;&#20154;&#31867;&#34920;&#24449;&#30340;&#19968;&#33268;&#24615;&#20043;&#38388;&#24212;&#35813;&#23384;&#22312;&#19968;&#20010;U&#24418;&#20851;&#31995;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;491&#20010;&#35745;&#31639;&#26426;&#35270;&#35273;&#27169;&#22411;&#30340;&#24615;&#33021;&#20998;&#26512;&#39564;&#35777;&#20102;&#36825;&#20010;&#39044;&#27979;&#30340;&#21487;&#34892;&#24615;&#65292;&#24182;&#19988;&#34920;&#26126;&#39640;&#24230;&#23545;&#40784;&#30340;&#27169;&#22411;&#26356;&#21152;&#40065;&#26834;&#20110;&#23545;&#25239;&#25915;&#20987;&#21644;&#22495;&#20559;&#31227;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#20154;&#31867;&#23545;&#40784;&#24448;&#24448;&#26159;&#27169;&#22411;&#26377;&#25928;&#21033;&#29992;&#26377;&#38480;&#25968;&#25454;&#12289;&#40065;&#26834;&#24615; &#20197;&#21450;&#27867;&#21270;&#33021;&#21147;&#30340;&#20805;&#20998;&#20294;&#19981;&#24517;&#35201;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
Should we care whether AI systems have representations of the world that are similar to those of humans? We provide an information-theoretic analysis that suggests that there should be a U-shaped relationship between the degree of representational alignment with humans and performance on few-shot learning tasks. We confirm this prediction empirically, finding such a relationship in an analysis of the performance of 491 computer vision models. We also show that highly-aligned models are more robust to both adversarial attacks and domain shifts. Our results suggest that human-alignment is often a sufficient, but not necessary, condition for models to make effective use of limited data, be robust, and generalize well.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20960;&#20309;&#29256;&#26412;&#30340;Weisfeiler-Leman&#27979;&#35797;(GWL)&#65292;&#21487;&#20197;&#21306;&#20998;&#20960;&#20309;&#22270;&#24418;&#65292;&#25581;&#31034;&#20102;&#20851;&#38190;&#35774;&#35745;&#36873;&#25321;&#22914;&#20309;&#24433;&#21709;&#20960;&#20309;GNN&#30340;&#34920;&#29616;&#21147;</title><link>http://arxiv.org/abs/2301.09308</link><description>&lt;p&gt;
&#35770;&#20960;&#20309;&#22270;&#31070;&#32463;&#32593;&#32476;&#34920;&#29616;&#21147;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Expressive Power of Geometric Graph Neural Networks. (arXiv:2301.09308v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.09308
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20960;&#20309;&#29256;&#26412;&#30340;Weisfeiler-Leman&#27979;&#35797;(GWL)&#65292;&#21487;&#20197;&#21306;&#20998;&#20960;&#20309;&#22270;&#24418;&#65292;&#25581;&#31034;&#20102;&#20851;&#38190;&#35774;&#35745;&#36873;&#25321;&#22914;&#20309;&#24433;&#21709;&#20960;&#20309;GNN&#30340;&#34920;&#29616;&#21147;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807; Weisfeiler-Leman (WL) &#22270;&#21516;&#26500;&#27979;&#35797;&#65292;&#24050;&#32463;&#24191;&#27867;&#30740;&#31350;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476; (GNNs) &#30340;&#34920;&#29616;&#21147;&#12290;&#28982;&#32780;&#65292;&#26631;&#20934;&#30340; GNNs &#21644; WL &#26694;&#26550;&#19981;&#36866;&#29992;&#20110;&#23884;&#20837;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#30340;&#20960;&#20309;&#22270;&#24418;&#65292;&#20363;&#22914;&#29983;&#29289;&#20998;&#23376;&#12289;&#26448;&#26009;&#21644;&#20854;&#20182;&#29289;&#29702;&#31995;&#32479;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102; WL &#27979;&#35797;&#30340;&#20960;&#20309;&#29256;&#26412; (GWL)&#65292;&#20197;&#21306;&#20998;&#20960;&#20309;&#22270;&#24418;&#65292;&#21516;&#26102;&#23562;&#37325;&#24213;&#23618;&#29289;&#29702;&#23545;&#31216;&#24615;&#65306;&#25490;&#21015;&#12289;&#26059;&#36716;&#12289;&#21453;&#23556;&#21644;&#24179;&#31227;&#12290;&#25105;&#20204;&#20351;&#29992; GWL &#26469;&#34920;&#24449;&#20855;&#26377;&#19981;&#21464;&#25110;&#31561;&#21464;&#20110;&#29289;&#29702;&#23545;&#31216;&#24615;&#30340;&#20960;&#20309; GNN &#30340;&#34920;&#29616;&#21147;&#65292;&#20197;&#21306;&#20998;&#20960;&#20309;&#22270;&#24418;&#12290;GWL &#25581;&#31034;&#20102;&#20851;&#38190;&#35774;&#35745;&#36873;&#25321;&#22914;&#20309;&#24433;&#21709;&#20960;&#20309; GNN &#30340;&#34920;&#29616;&#21147;&#65306;(1) &#19981;&#21464;&#23618;&#34920;&#29616;&#21147;&#26377;&#38480;&#65292;&#22240;&#20026;&#23427;&#20204;&#26080;&#27861;&#21306;&#20998;&#19968;&#36339;&#30456;&#21516;&#30340;&#20960;&#20309;&#22270;&#24418;&#65307;(2) &#31561;&#21464;&#23618;&#36890;&#36807;&#20256;&#25773;&#23616;&#37096;&#37051;&#22495;&#20043;&#22806;&#30340;&#20960;&#20309;&#20449;&#24687;&#65292;&#21306;&#20998;&#26356;&#22823;&#31867;&#21035;&#30340;&#22270;&#24418;&#65307;(3)
&lt;/p&gt;
&lt;p&gt;
The expressive power of Graph Neural Networks (GNNs) has been studied extensively through the Weisfeiler-Leman (WL) graph isomorphism test. However, standard GNNs and the WL framework are inapplicable for geometric graphs embedded in Euclidean space, such as biomolecules, materials, and other physical systems. In this work, we propose a geometric version of the WL test (GWL) for discriminating geometric graphs while respecting the underlying physical symmetries: permutations, rotation, reflection, and translation. We use GWL to characterise the expressive power of geometric GNNs that are invariant or equivariant to physical symmetries in terms of distinguishing geometric graphs. GWL unpacks how key design choices influence geometric GNN expressivity: (1) Invariant layers have limited expressivity as they cannot distinguish one-hop identical geometric graphs; (2) Equivariant layers distinguish a larger class of graphs by propagating geometric information beyond local neighbourhoods; (3)
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#32479;&#35745;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#20998;&#26512;&#20102;&#27431;&#27954;&#21644;&#22320;&#20013;&#28023;&#30406;&#22320;2001&#24180;&#33267;2020&#24180;&#22240;&#37326;&#28779;&#32780;&#28903;&#27585;&#30340;&#26376;&#24230;&#38754;&#31215;&#65292;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#27668;&#28201;&#12289;&#38477;&#27700;&#21644;&#39118;&#36895;&#26159;&#26497;&#31471;&#37326;&#28779;&#30340;&#20027;&#35201;&#39537;&#21160;&#22240;&#32032;&#65292;&#26681;&#25454;&#23395;&#33410;&#21644;&#22320;&#28857;&#26377;&#19981;&#21516;&#30340;&#24433;&#21709;&#12290;&#38463;&#23572;&#21450;&#21033;&#20122;&#30340;&#37326;&#28779;&#27963;&#21160;&#27491;&#22312;&#22686;&#21152;&#65292;&#33889;&#33796;&#29273;&#30340;&#36235;&#21183;&#27491;&#22312;&#19979;&#38477;&#65292;&#32780;&#24847;&#22823;&#21033;&#30340;&#36235;&#21183;&#26159;&#38750;&#32447;&#24615;&#30340;&#12290;</title><link>http://arxiv.org/abs/2212.01796</link><description>&lt;p&gt;
&#29992;&#32479;&#35745;&#28145;&#24230;&#23398;&#20064;&#25581;&#31034;&#22320;&#20013;&#28023;&#22320;&#21306;&#26497;&#31471;&#37326;&#28779;&#30340;&#39537;&#21160;&#22240;&#32032;&#21644;&#26102;&#31354;&#36235;&#21183;
&lt;/p&gt;
&lt;p&gt;
Insights into the drivers and spatio-temporal trends of extreme Mediterranean wildfires with statistical deep-learning. (arXiv:2212.01796v3 [stat.AP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.01796
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#32479;&#35745;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#20998;&#26512;&#20102;&#27431;&#27954;&#21644;&#22320;&#20013;&#28023;&#30406;&#22320;2001&#24180;&#33267;2020&#24180;&#22240;&#37326;&#28779;&#32780;&#28903;&#27585;&#30340;&#26376;&#24230;&#38754;&#31215;&#65292;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#27668;&#28201;&#12289;&#38477;&#27700;&#21644;&#39118;&#36895;&#26159;&#26497;&#31471;&#37326;&#28779;&#30340;&#20027;&#35201;&#39537;&#21160;&#22240;&#32032;&#65292;&#26681;&#25454;&#23395;&#33410;&#21644;&#22320;&#28857;&#26377;&#19981;&#21516;&#30340;&#24433;&#21709;&#12290;&#38463;&#23572;&#21450;&#21033;&#20122;&#30340;&#37326;&#28779;&#27963;&#21160;&#27491;&#22312;&#22686;&#21152;&#65292;&#33889;&#33796;&#29273;&#30340;&#36235;&#21183;&#27491;&#22312;&#19979;&#38477;&#65292;&#32780;&#24847;&#22823;&#21033;&#30340;&#36235;&#21183;&#26159;&#38750;&#32447;&#24615;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26497;&#31471;&#37326;&#28779;&#26159;&#22320;&#20013;&#28023;&#30406;&#22320;&#22269;&#23478;&#20013;&#20154;&#31867;&#27515;&#20129;&#21644;&#29983;&#29289;&#22810;&#26679;&#24615;&#30772;&#22351;&#30340;&#37325;&#35201;&#21407;&#22240;&#12290;&#26368;&#36817;&#37326;&#28779;&#27963;&#21160;&#65288;&#21363;&#21457;&#29983;&#21644;&#34067;&#24310;&#65289;&#30340;&#36235;&#21183;&#20196;&#20154;&#25285;&#24551;&#65292;&#34920;&#26126;&#37326;&#28779;&#21487;&#33021;&#21463;&#21040;&#27668;&#20505;&#21464;&#21270;&#30340;&#39640;&#24230;&#24433;&#21709;&#12290;&#20026;&#20102;&#20419;&#36827;&#36866;&#24403;&#30340;&#39118;&#38505;&#32531;&#35299;&#65292;&#25105;&#20204;&#24517;&#39035;&#30830;&#23450;&#26497;&#31471;&#37326;&#28779;&#30340;&#20027;&#35201;&#39537;&#21160;&#22240;&#32032;&#65292;&#24182;&#35780;&#20272;&#23427;&#20204;&#30340;&#26102;&#31354;&#36235;&#21183;&#65292;&#20197;&#20415;&#20102;&#35299;&#20840;&#29699;&#21464;&#26262;&#23545;&#28779;&#28798;&#27963;&#21160;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#27431;&#27954;&#21644;&#22320;&#20013;&#28023;&#30406;&#22320;&#22823;&#37096;&#20998;&#22320;&#21306;&#20174;2001&#24180;&#21040;2020&#24180;&#22240;&#37326;&#28779;&#32780;&#28903;&#27585;&#30340;&#26376;&#24230;&#38754;&#31215;&#65292;&#24182;&#30830;&#23450;&#38463;&#23572;&#21450;&#21033;&#20122;&#12289;&#24847;&#22823;&#21033;&#21644;&#33889;&#33796;&#29273;&#22312;&#36825;&#26399;&#38388;&#23384;&#22312;&#39640;&#21457;&#30340;&#37326;&#28779;&#27963;&#21160;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#39640;&#32500;&#39044;&#27979;&#22120;&#38598;&#25551;&#36848;&#27668;&#35937;&#26465;&#20214;&#12289;&#22303;&#22320;&#35206;&#30422;&#21033;&#29992;&#21644;&#23665;&#21183;&#30340;&#26497;&#31471;&#20998;&#20301;&#25968;&#22238;&#24402;&#27169;&#22411;&#12290;&#20026;&#20102;&#27169;&#25311;&#39044;&#27979;&#21464;&#37327;&#21644;&#37326;&#28779;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#20010;&#28151;&#21512;&#32479;&#35745;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#27668;&#28201;&#12289;&#38477;&#27700;&#21644;&#39118;&#36895;&#26159;&#26497;&#31471;&#37326;&#28779;&#30340;&#20027;&#35201;&#39537;&#21160;&#22240;&#32032;&#65292;&#26681;&#25454;&#23395;&#33410;&#21644;&#22320;&#28857;&#26377;&#19981;&#21516;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#26174;&#33879;&#30340;&#26102;&#31354;&#36235;&#21183;&#65292;&#38463;&#23572;&#21450;&#21033;&#20122;&#30340;&#37326;&#28779;&#27963;&#21160;&#27491;&#22312;&#22686;&#21152;&#65292;&#33889;&#33796;&#29273;&#30340;&#36235;&#21183;&#27491;&#22312;&#19979;&#38477;&#65292;&#32780;&#24847;&#22823;&#21033;&#30340;&#36235;&#21183;&#26159;&#38750;&#32447;&#24615;&#30340;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#20026;&#20102;&#35299;&#27668;&#20505;&#21464;&#21270;&#23545;&#22320;&#20013;&#28023;&#30406;&#22320;&#26497;&#31471;&#37326;&#28779;&#24403;&#21069;&#21644;&#28508;&#22312;&#30340;&#24433;&#21709;&#25552;&#20379;&#20102;&#37325;&#35201;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Extreme wildfires are a significant cause of human death and biodiversity destruction within countries that encompass the Mediterranean Basin. Recent worrying trends in wildfire activity (i.e., occurrence and spread) suggest that wildfires are likely to be highly impacted by climate change. In order to facilitate appropriate risk mitigation, we must identify the main drivers of extreme wildfires and assess their spatio-temporal trends, with a view to understanding the impacts of global warming on fire activity. We analyse the monthly burnt area due to wildfires over a region encompassing most of Europe and the Mediterranean Basin from 2001 to 2020, and identify high fire activity during this period in Algeria, Italy and Portugal. We build an extreme quantile regression model with a high-dimensional predictor set describing meteorological conditions, land cover usage, and orography. To model the complex relationships between the predictor variables and wildfires, we use a hybrid statist
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#24322;&#24120;&#26816;&#27979;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#8212;&#8212;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#38750;&#23545;&#31216;&#25554;&#20540;&#30340;&#26041;&#27861;&#26469;&#22686;&#24378;&#36755;&#20837;&#24182;&#20943;&#36731;&#36807;&#24230;&#33258;&#20449;&#30340;&#38382;&#39064;&#65292;&#20174;&#32780;&#25552;&#39640;&#21028;&#21035;&#22120;&#27169;&#22411;&#22312;&#24322;&#24120;&#26816;&#27979;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2211.11255</link><description>&lt;p&gt;
&#22522;&#20110;&#25193;&#25955;&#21435;&#22122;&#36807;&#31243;&#30340;&#24863;&#30693;&#22120;&#20559;&#32622;&#22312;&#24322;&#24120;&#26816;&#27979;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Diffusion Denoising Process for Perceptron Bias in Out-of-distribution Detection. (arXiv:2211.11255v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.11255
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#24322;&#24120;&#26816;&#27979;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#8212;&#8212;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#38750;&#23545;&#31216;&#25554;&#20540;&#30340;&#26041;&#27861;&#26469;&#22686;&#24378;&#36755;&#20837;&#24182;&#20943;&#36731;&#36807;&#24230;&#33258;&#20449;&#30340;&#38382;&#39064;&#65292;&#20174;&#32780;&#25552;&#39640;&#21028;&#21035;&#22120;&#27169;&#22411;&#22312;&#24322;&#24120;&#26816;&#27979;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24322;&#24120;&#26816;&#27979;&#23545;&#20110;&#20445;&#35777;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#21487;&#38752;&#24615;&#21644;&#23433;&#20840;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#30446;&#21069;&#65292;&#21028;&#21035;&#22120;&#27169;&#22411;&#22312;&#36825;&#26041;&#38754;&#30340;&#34920;&#29616;&#36229;&#36807;&#20854;&#20182;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#21028;&#21035;&#22120;&#27169;&#22411;&#20351;&#29992;&#30340;&#29305;&#24449;&#25552;&#21462;&#36807;&#31243;&#23481;&#26131;&#20002;&#22833;&#20851;&#38190;&#20449;&#24687;&#65292;&#30041;&#19979;&#19981;&#33391;&#24773;&#20917;&#21644;&#24694;&#24847;&#25915;&#20987;&#30340;&#31354;&#38388;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#24863;&#30693;&#22120;&#20559;&#32622;&#20551;&#35774;&#65292;&#23427;&#34920;&#26126;&#21028;&#21035;&#22120;&#27169;&#22411;&#23545;&#36755;&#20837;&#30340;&#26576;&#20123;&#29305;&#24449;&#26356;&#20026;&#25935;&#24863;&#65292;&#23548;&#33268;&#36807;&#24230;&#33258;&#20449;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#23427;&#32467;&#21512;&#20102;&#21028;&#21035;&#22120;&#21644;&#29983;&#25104;&#27169;&#22411;&#65292;&#24182;&#23558;&#25193;&#25955;&#27169;&#22411;(DMs)&#38598;&#25104;&#21040;OOD&#26816;&#27979;&#20013;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25193;&#25955;&#21435;&#22122;&#36807;&#31243;(DDP)&#20316;&#20026;&#19968;&#31181;&#26032;&#24418;&#24335;&#30340;&#38750;&#23545;&#31216;&#25554;&#20540;&#65292;&#24456;&#36866;&#21512;&#22686;&#24378;&#36755;&#20837;&#24182;&#20943;&#36731;&#36807;&#24230;&#33258;&#20449;&#30340;&#38382;&#39064;&#12290;&#22312;DDP&#19979;&#65292;OOD&#25968;&#25454;&#30340;&#21028;&#21035;&#22120;&#27169;&#22411;&#29305;&#24449;&#34920;&#29616;&#20026;&#23574;&#38160;&#30340;&#21464;&#21270;&#65292;&#25105;&#20204;&#21033;&#29992;&#33539;&#25968;...
&lt;/p&gt;
&lt;p&gt;
Out-of-distribution (OOD) detection is a crucial task for ensuring the reliability and safety of deep learning. Currently, discriminator models outperform other methods in this regard. However, the feature extraction process used by discriminator models suffers from the loss of critical information, leaving room for bad cases and malicious attacks. In this paper, we introduce a new perceptron bias assumption that suggests discriminator models are more sensitive to certain features of the input, leading to the overconfidence problem. To address this issue, we propose a novel framework that combines discriminator and generation models and integrates diffusion models (DMs) into OOD detection. We demonstrate that the diffusion denoising process (DDP) of DMs serves as a novel form of asymmetric interpolation, which is well-suited to enhance the input and mitigate the overconfidence problem. The discriminator model features of OOD data exhibit sharp changes under DDP, and we utilize the norm
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22522;&#20110;&#26080;&#19978;&#19979;&#25991;&#25991;&#27861;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#25628;&#32034;&#31354;&#38388;&#35774;&#35745;&#26694;&#26550;&#65292;&#21487;&#20197;&#29983;&#25104;&#34920;&#36798;&#21147;&#24378;&#22823;&#30340;&#20998;&#23618;&#25628;&#32034;&#31354;&#38388;&#65292;&#23454;&#29616;&#20102;&#23545;&#25972;&#20010;&#20307;&#31995;&#32467;&#26500;&#30340;&#25628;&#32034;&#24182;&#20419;&#36827;&#32467;&#26500;&#30340;&#35268;&#24459;&#24615;&#12290;</title><link>http://arxiv.org/abs/2211.01842</link><description>&lt;p&gt;
&#22522;&#20110;&#26080;&#19978;&#19979;&#25991;&#25991;&#27861;&#30340;&#20998;&#23618;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#31354;&#38388;&#26500;&#24314;
&lt;/p&gt;
&lt;p&gt;
Construction of Hierarchical Neural Architecture Search Spaces based on Context-free Grammars. (arXiv:2211.01842v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.01842
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22522;&#20110;&#26080;&#19978;&#19979;&#25991;&#25991;&#27861;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#25628;&#32034;&#31354;&#38388;&#35774;&#35745;&#26694;&#26550;&#65292;&#21487;&#20197;&#29983;&#25104;&#34920;&#36798;&#21147;&#24378;&#22823;&#30340;&#20998;&#23618;&#25628;&#32034;&#31354;&#38388;&#65292;&#23454;&#29616;&#20102;&#23545;&#25972;&#20010;&#20307;&#31995;&#32467;&#26500;&#30340;&#25628;&#32034;&#24182;&#20419;&#36827;&#32467;&#26500;&#30340;&#35268;&#24459;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#31616;&#21333;&#30340;&#26500;&#24314;&#22359;&#20013;&#21457;&#29616;&#31070;&#32463;&#32467;&#26500;&#26159;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;(NAS)&#30340;&#19968;&#20010;&#38271;&#26399;&#30446;&#26631;&#12290;&#20998;&#23618;&#25628;&#32034;&#31354;&#38388;&#26159;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#30340;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#27493;&#39588;&#65292;&#20294;&#32570;&#20047;&#32479;&#19968;&#30340;&#25628;&#32034;&#31354;&#38388;&#35774;&#35745;&#26694;&#26550;&#65292;&#24182;&#19988;&#36890;&#24120;&#20165;&#25628;&#32034;&#19968;&#20123;&#38480;&#23450;&#26041;&#38754;&#30340;&#26550;&#26500;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#22522;&#20110;&#26080;&#19978;&#19979;&#25991;&#25991;&#27861;&#30340;&#32479;&#19968;&#25628;&#32034;&#31354;&#38388;&#35774;&#35745;&#26694;&#26550;&#65292;&#23427;&#21487;&#20197;&#33258;&#28982;&#32780;&#32039;&#20945;&#22320;&#29983;&#25104;&#34920;&#36798;&#21147;&#24378;&#22823;&#30340;&#20998;&#23618;&#25628;&#32034;&#31354;&#38388;&#65292;&#27604;&#25991;&#29486;&#20013;&#24120;&#35265;&#30340;&#31354;&#38388;&#22823;&#20960;&#20010;&#25968;&#37327;&#32423;&#12290;&#36890;&#36807;&#22686;&#24378;&#21644;&#21033;&#29992;&#23427;&#20204;&#30340;&#23646;&#24615;&#65292;&#25105;&#20204;&#26377;&#25928;&#22320;&#23454;&#29616;&#20102;&#23545;&#25972;&#20010;&#20307;&#31995;&#32467;&#26500;&#30340;&#25628;&#32034;&#65292;&#24182;&#20419;&#36827;&#20102;&#32467;&#26500;&#30340;&#35268;&#24459;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20998;&#23618;&#26680;&#35774;&#35745;&#29992;&#20110;&#36125;&#21494;&#26031;&#20248;&#21270;&#25628;&#32034;&#31574;&#30053;&#65292;&#20197;&#39640;&#25928;&#25628;&#32034;&#22914;&#27492;&#24222;&#22823;&#30340;&#31354;&#38388;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#25628;&#32034;&#31354;&#38388;&#35774;&#35745;&#26694;&#26550;&#30340;&#22810;&#26679;&#24615;&#65292;&#24182;&#34920;&#26126;&#25105;&#20204;&#30340;&#25628;&#32034;&#31574;&#30053;&#21487;&#20197;&#20248;&#20110;&#29616;&#26377;&#30340;NAS&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The discovery of neural architectures from simple building blocks is a long-standing goal of Neural Architecture Search (NAS). Hierarchical search spaces are a promising step towards this goal but lack a unifying search space design framework and typically only search over some limited aspect of architectures. In this work, we introduce a unifying search space design framework based on context-free grammars that can naturally and compactly generate expressive hierarchical search spaces that are 100s of orders of magnitude larger than common spaces from the literature. By enhancing and using their properties, we effectively enable search over the complete architecture and can foster regularity. Further, we propose an efficient hierarchical kernel design for a Bayesian Optimization search strategy to efficiently search over such huge spaces. We demonstrate the versatility of our search space design framework and show that our search strategy can be superior to existing NAS approaches. Co
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21518;&#22788;&#29702;&#31639;&#27861;&#65292;&#36890;&#36807;&#35780;&#20998;&#20989;&#25968;&#25512;&#23548;&#20844;&#24179;&#20998;&#31867;&#22120;&#65292;&#36798;&#21040;&#20844;&#24179;&#23545;&#24453;&#19981;&#21516;&#32676;&#20307;&#30340;&#30446;&#30340;&#12290;</title><link>http://arxiv.org/abs/2211.01528</link><description>&lt;p&gt;
&#36890;&#36807;&#21518;&#22788;&#29702;&#23454;&#29616;&#20844;&#24179;&#21644;&#26368;&#20248;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Fair and Optimal Classification via Post-Processing. (arXiv:2211.01528v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.01528
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21518;&#22788;&#29702;&#31639;&#27861;&#65292;&#36890;&#36807;&#35780;&#20998;&#20989;&#25968;&#25512;&#23548;&#20844;&#24179;&#20998;&#31867;&#22120;&#65292;&#36798;&#21040;&#20844;&#24179;&#23545;&#24453;&#19981;&#21516;&#32676;&#20307;&#30340;&#30446;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#20943;&#36731;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#25152;&#21576;&#29616;&#30340;&#20559;&#35265;&#65292;&#20844;&#24179;&#24615;&#26631;&#20934;&#21487;&#20197;&#25972;&#21512;&#21040;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#20197;&#30830;&#20445;&#22312;&#25152;&#26377;&#20154;&#21475;&#32479;&#35745;&#23398;&#20013;&#23454;&#29616;&#20844;&#24179;&#23545;&#24453;&#65292;&#28982;&#32780;&#36825;&#24448;&#24448;&#26159;&#20197;&#27169;&#22411;&#34920;&#29616;&#20026;&#20195;&#20215;&#30340;&#12290;&#22240;&#27492;&#65292;&#20102;&#35299;&#36825;&#31181;&#26435;&#34913;&#26159;&#20844;&#24179;&#31639;&#27861;&#35774;&#35745;&#30340;&#22522;&#30784;&#12290;&#26412;&#25991;&#22312;&#26368;&#26222;&#36941;&#30340;&#22810;&#32452;&#12289;&#22810;&#31867;&#21035;&#21644;&#22024;&#26434;&#35774;&#32622;&#19979;&#65292;&#23436;&#25972;&#22320;&#34920;&#24449;&#20102;&#20844;&#24179;&#12289;&#36798;&#25705;&#23572;&#24179;&#31561;&#22312;&#20998;&#31867;&#38382;&#39064;&#20013;&#30340;&#20869;&#22312;&#26435;&#34913;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#36890;&#36807;&#38543;&#26426;&#21270;&#21644;&#23646;&#24615;&#24863;&#30693;&#20844;&#24179;&#20998;&#31867;&#22120;&#23454;&#29616;&#30340;&#26368;&#23567;&#38169;&#35823;&#29575;&#26159;&#30001;&#27779;&#29791;&#26031;&#22374;&#37325;&#24515;&#38382;&#39064;&#30340;&#26368;&#20248;&#20540;&#32473;&#20986;&#30340;&#12290;&#22312;&#23454;&#36341;&#26041;&#38754;&#65292;&#25105;&#20204;&#30340;&#21457;&#29616;&#21487;&#20197;&#20135;&#29983;&#19968;&#20010;&#31616;&#21333;&#30340;&#21518;&#22788;&#29702;&#31639;&#27861;&#65292;&#20174;&#35780;&#20998;&#20989;&#25968;&#20013;&#25512;&#23548;&#20986;&#20844;&#24179;&#20998;&#31867;&#22120;&#65292;&#24182;&#22312;&#35780;&#20998;&#20026;&#36125;&#21494;&#26031;&#26368;&#20248;&#26102;&#24471;&#21040;&#26368;&#20248;&#20844;&#24179;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#20026;&#25105;&#20204;&#30340;&#31639;&#27861;&#25552;&#20379;&#20102;&#27425;&#20248;&#24615;&#20998;&#26512;&#21644;&#26679;&#26412;&#22797;&#26434;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
To mitigate the bias exhibited by machine learning models, fairness criteria can be integrated into the training process to ensure fair treatment across all demographics, but it often comes at the expense of model performance. Understanding such tradeoffs, therefore, underlies the design of fair algorithms. To this end, this paper provides a complete characterization of the inherent tradeoff of demographic parity on classification problems, under the most general multi-group, multi-class, and noisy setting. Specifically, we show that the minimum error rate achievable by randomized and attribute-aware fair classifiers is given by the optimal value of a Wasserstein-barycenter problem. On the practical side, our findings lead to a simple post-processing algorithm that derives fair classifiers from score functions, which yields the optimal fair classifier when the score is Bayes optimal. We provide suboptimality analysis and sample complexity for our algorithm, and demonstrate its effectiv
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#33324;&#29702;&#35770;&#26469;&#38480;&#23450;POMDP&#19982;&#20854;&#30456;&#24212;&#30340;&#26377;&#38480;&#26679;&#26412;&#31890;&#23376;&#20449;&#24565;MDP(PB-MDP)&#36924;&#36817;&#20043;&#38388;&#30340;&#35823;&#24046;&#65292;&#24182;&#23558;&#20219;&#20309;&#37319;&#26679;MDP&#31639;&#27861;&#36866;&#24212;&#21040;POMDP&#20013;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#35299;&#20915;&#20855;&#26377;&#22823;&#30340;&#25110;&#36830;&#32493;&#29366;&#24577;&#31354;&#38388;&#30340;POMDP&#30340;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2210.05015</link><description>&lt;p&gt;
&#31890;&#23376;&#20449;&#24565;&#36817;&#20284;POMDP&#30340;&#26368;&#20248;&#24615;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Optimality Guarantees for Particle Belief Approximation of POMDPs. (arXiv:2210.05015v3 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.05015
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#33324;&#29702;&#35770;&#26469;&#38480;&#23450;POMDP&#19982;&#20854;&#30456;&#24212;&#30340;&#26377;&#38480;&#26679;&#26412;&#31890;&#23376;&#20449;&#24565;MDP(PB-MDP)&#36924;&#36817;&#20043;&#38388;&#30340;&#35823;&#24046;&#65292;&#24182;&#23558;&#20219;&#20309;&#37319;&#26679;MDP&#31639;&#27861;&#36866;&#24212;&#21040;POMDP&#20013;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#35299;&#20915;&#20855;&#26377;&#22823;&#30340;&#25110;&#36830;&#32493;&#29366;&#24577;&#31354;&#38388;&#30340;POMDP&#30340;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;(POMDP)&#25552;&#20379;&#20102;&#29616;&#23454;&#20915;&#31574;&#21644;&#25511;&#21046;&#38382;&#39064;&#30340;&#28789;&#27963;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;POMDP&#30340;&#27714;&#35299;&#38750;&#24120;&#22256;&#38590;&#65292;&#29305;&#21035;&#26159;&#24403;&#29366;&#24577;&#21644;&#35266;&#27979;&#31354;&#38388;&#26159;&#36830;&#32493;&#25110;&#28151;&#21512;&#30340;&#26102;&#20505;&#65292;&#36825;&#22312;&#29289;&#29702;&#31995;&#32479;&#20013;&#32463;&#24120;&#21457;&#29983;&#12290;&#23613;&#31649;&#26368;&#36817;&#20351;&#29992;&#35266;&#27979;&#20284;&#28982;&#26435;&#37325;&#31574;&#21010;&#30340;&#22312;&#32447;&#37319;&#26679;POMDP&#31639;&#27861;&#34920;&#29616;&#20986;&#20102;&#23454;&#29992;&#30340;&#26377;&#25928;&#24615;&#65292;&#20294;&#20808;&#21069;&#24182;&#27809;&#26377;&#25552;&#20986;&#19968;&#33324;&#29702;&#35770;&#26469;&#21051;&#30011;&#36825;&#20123;&#31639;&#27861;&#20351;&#29992;&#30340;&#31890;&#23376;&#28388;&#27874;&#25216;&#26415;&#30340;&#36924;&#36817;&#35823;&#24046;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#38480;&#23450;&#20219;&#20309;POMDP&#19982;&#20854;&#30456;&#24212;&#30340;&#26377;&#38480;&#26679;&#26412;&#31890;&#23376;&#20449;&#24565;MDP(PB-MDP)&#36924;&#36817;&#20043;&#38388;&#30340;&#35823;&#24046;&#12290;&#36825;&#31181;PB-MDP&#21644;POMDP&#20043;&#38388;&#30340;&#22522;&#30784;&#26725;&#26753;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#35299;&#20915;&#30456;&#24212;&#30340;&#31890;&#23376;&#20449;&#24565;MDP&#23558;&#20219;&#20309;&#37319;&#26679;MDP&#31639;&#27861;&#36866;&#24212;&#21040;POMDP&#20013;&#65292;&#20174;&#32780;&#23558;MDP&#31639;&#27861;&#30340;&#25910;&#25947;&#20445;&#35777;&#25193;&#23637;&#21040;POMDP&#20013;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#36825;&#21487;&#20197;&#25552;&#39640;&#22312;&#35299;&#20915;&#20855;&#26377;&#22823;&#30340;&#25110;&#36830;&#32493;&#29366;&#24577;&#31354;&#38388;&#30340;POMDP&#26102;&#30340;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Partially observable Markov decision processes (POMDPs) provide a flexible representation for real-world decision and control problems. However, POMDPs are notoriously difficult to solve, especially when the state and observation spaces are continuous or hybrid, which is often the case for physical systems. While recent online sampling-based POMDP algorithms that plan with observation likelihood weighting have shown practical effectiveness, a general theory characterizing the approximation error of the particle filtering techniques that these algorithms use has not previously been proposed. Our main contribution is bounding the error between any POMDP and its corresponding finite sample particle belief MDP (PB-MDP) approximation. This fundamental bridge between PB-MDPs and POMDPs allows us to adapt any sampling-based MDP algorithm to a POMDP by solving the corresponding particle belief MDP, thereby extending the convergence guarantees of the MDP algorithm to the POMDP. Practically, thi
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21152;&#26435;&#19981;&#23545;&#31216;&#25439;&#22833;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#29983;&#25104;&#21487;&#38752;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#36866;&#29992;&#20110;&#22797;&#26434;&#30340;&#26426;&#22120;&#23398;&#20064;&#24773;&#22659;&#65292;&#21487;&#25193;&#23637;&#20026;&#21442;&#25968;&#21270;&#20989;&#25968;&#30340;PI&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2210.04318</link><description>&lt;p&gt;
&#20351;&#29992;&#21152;&#26435;&#19981;&#23545;&#31216;&#25439;&#22833;&#20989;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#39044;&#27979;&#21306;&#38388;
&lt;/p&gt;
&lt;p&gt;
Prediction intervals for neural network models using weighted asymmetric loss functions. (arXiv:2210.04318v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.04318
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21152;&#26435;&#19981;&#23545;&#31216;&#25439;&#22833;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#29983;&#25104;&#21487;&#38752;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#36866;&#29992;&#20110;&#22797;&#26434;&#30340;&#26426;&#22120;&#23398;&#20064;&#24773;&#22659;&#65292;&#21487;&#25193;&#23637;&#20026;&#21442;&#25968;&#21270;&#20989;&#25968;&#30340;PI&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#29983;&#25104;&#36817;&#20284;&#21644;&#39044;&#27979;&#36235;&#21183;&#30340;&#39044;&#27979;&#21306;&#38388;&#65288;PIs&#65289;&#12290;&#25105;&#20204;&#21033;&#29992;&#21152;&#26435;&#19981;&#23545;&#31216;&#25439;&#22833;&#20989;&#25968;&#26469;&#20272;&#35745;PI&#30340;&#19979;&#38480;&#21644;&#19978;&#38480;&#65292;&#26435;&#37325;&#30001;&#21306;&#38388;&#23485;&#24230;&#30830;&#23450;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#35813;&#26041;&#27861;&#30340;&#31616;&#27905;&#25968;&#23398;&#35777;&#26126;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#20854;&#25193;&#23637;&#21040;&#20026;&#21442;&#25968;&#21270;&#20989;&#25968;&#25512;&#23548;PI&#65292;&#24182;&#35770;&#35777;&#20102;&#35813;&#26041;&#27861;&#20026;&#39044;&#27979;&#30456;&#20851;&#21464;&#37327;&#30340;PI&#32780;&#26377;&#25928;&#30340;&#21407;&#22240;&#12290;&#25105;&#20204;&#22312;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#27169;&#22411;&#30340;&#30495;&#23454;&#19990;&#30028;&#39044;&#27979;&#20219;&#21153;&#19978;&#23545;&#35813;&#26041;&#27861;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#32467;&#26524;&#34920;&#26126;&#23427;&#22312;&#22797;&#26434;&#30340;&#26426;&#22120;&#23398;&#20064;&#24773;&#22659;&#19979;&#21487;&#20197;&#20135;&#29983;&#21487;&#38752;&#30340;PI&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a simple and efficient approach to generate prediction intervals (PIs) for approximated and forecasted trends. Our method leverages a weighted asymmetric loss function to estimate the lower and upper bounds of the PIs, with the weights determined by the interval width. We provide a concise mathematical proof of the method, show how it can be extended to derive PIs for parametrised functions and argue why the method works for predicting PIs of dependent variables. The presented tests of the method on a real-world forecasting task using a neural network-based model show that it can produce reliable PIs in complex machine learning scenarios.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26410;&#26631;&#35760;&#26679;&#26412;&#30340;&#20998;&#24067;&#28418;&#31227;&#19979;&#27979;&#35797;&#26102;&#38388;&#26657;&#20934;&#32622;&#20449;&#24230;&#39044;&#27979;&#22120;&#12290;&#36890;&#36807;&#20351;&#29992;&#23494;&#24230;&#27604;&#20272;&#35745;&#25216;&#26415;&#26469;&#39044;&#27979;&#26032;&#20998;&#24067;&#30340;&#25130;&#27490;&#38408;&#20540;&#65292;&#25105;&#20204;&#22312;&#20960;&#20010;&#26631;&#20934;&#22270;&#20687;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#20248;&#20110;&#26368;&#26032;&#30340;&#20998;&#24067;&#28418;&#31227;&#19979;&#30340;&#27979;&#35797;&#26102;&#38388;&#26657;&#20934;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2210.04166</link><description>&lt;p&gt;
&#22522;&#20110;&#26410;&#26631;&#35760;&#30340;&#26679;&#26412;&#30340;&#20998;&#24067;&#28418;&#31227;&#19979;&#27979;&#35797;&#26102;&#38388;&#26657;&#20934;&#32622;&#20449;&#24230;&#39044;&#27979;&#22120;
&lt;/p&gt;
&lt;p&gt;
Test-time Recalibration of Conformal Predictors Under Distribution Shift Based on Unlabeled Examples. (arXiv:2210.04166v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.04166
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26410;&#26631;&#35760;&#26679;&#26412;&#30340;&#20998;&#24067;&#28418;&#31227;&#19979;&#27979;&#35797;&#26102;&#38388;&#26657;&#20934;&#32622;&#20449;&#24230;&#39044;&#27979;&#22120;&#12290;&#36890;&#36807;&#20351;&#29992;&#23494;&#24230;&#27604;&#20272;&#35745;&#25216;&#26415;&#26469;&#39044;&#27979;&#26032;&#20998;&#24067;&#30340;&#25130;&#27490;&#38408;&#20540;&#65292;&#25105;&#20204;&#22312;&#20960;&#20010;&#26631;&#20934;&#22270;&#20687;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#20248;&#20110;&#26368;&#26032;&#30340;&#20998;&#24067;&#28418;&#31227;&#19979;&#30340;&#27979;&#35797;&#26102;&#38388;&#26657;&#20934;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#22270;&#20687;&#20998;&#31867;&#22120;&#38750;&#24120;&#20934;&#30830;&#65292;&#20294;&#39044;&#27979;&#27809;&#26377;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#22522;&#20110;&#20998;&#31867;&#22120;&#30340;&#27010;&#29575;&#20272;&#35745;&#65292;&#22522;&#26412;&#32622;&#20449;&#24230;&#39044;&#27979;&#22120;&#36890;&#36807;&#35745;&#31639;&#19968;&#32452;&#21253;&#21547;&#20855;&#26377;&#29992;&#25143;&#25351;&#23450;&#27010;&#29575;&#30340;&#27491;&#30830;&#31867;&#30340;&#31867;&#26469;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#20026;&#20102;&#25552;&#20379;&#36825;&#26679;&#30340;&#38598;&#21512;&#65292;&#32622;&#20449;&#24230;&#39044;&#27979;&#22120;&#24120;&#24120;&#22522;&#20110;&#26657;&#20934;&#38598;&#21512;&#20272;&#35745;&#27010;&#29575;&#20272;&#35745;&#30340;&#25130;&#26029;&#38408;&#20540;&#12290;&#32622;&#20449;&#24230;&#39044;&#27979;&#22120;&#20165;&#22312;&#26657;&#20934;&#38598;&#21512;&#19982;&#27979;&#35797;&#38598;&#30456;&#21516;&#26102;&#20445;&#35777;&#21487;&#38752;&#24615;&#12290;&#22240;&#27492;&#65292;&#32622;&#20449;&#24230;&#39044;&#27979;&#22120;&#38656;&#35201;&#20026;&#26032;&#20998;&#24067;&#37325;&#26032;&#26657;&#20934;&#12290;&#20294;&#22312;&#23454;&#36341;&#20013;&#65292;&#24456;&#23569;&#26377;&#26469;&#33258;&#26032;&#20998;&#24067;&#30340;&#26631;&#35760;&#25968;&#25454;&#65292;&#20351;&#26657;&#20934;&#25104;&#20026;&#19981;&#21487;&#34892;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#22522;&#20110;&#26410;&#26631;&#35760;&#26679;&#26412;&#39044;&#27979;&#26032;&#20998;&#24067;&#25130;&#27490;&#38408;&#20540;&#30340;&#38382;&#39064;&#12290;&#34429;&#28982;&#19968;&#33324;&#24773;&#20917;&#19979;&#19981;&#33021;&#20445;&#35777;&#22522;&#20110;&#26410;&#26631;&#35760;&#26679;&#26412;&#36827;&#34892;&#26657;&#20934;&#26102;&#30340;&#21487;&#38752;&#24615;&#65292;&#20294;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#27604;&#20272;&#35745;&#25216;&#26415;&#30340;&#26041;&#27861;&#26469;&#39044;&#27979;&#26032;&#20998;&#24067;&#30340;&#25130;&#27490;&#38408;&#20540;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#26631;&#20934;&#22270;&#20687;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#24182;&#26174;&#31034;&#20986;&#22312;&#20998;&#24067;&#28418;&#31227;&#19979;&#36827;&#34892;&#27979;&#35797;&#26102;&#38388;&#26657;&#20934;&#30340;&#26368;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern image classifiers are very accurate, but the predictions come without uncertainty estimates. Conformal predictors provide uncertainty estimates by computing a set of classes containing the correct class with a user-specified probability based on the classifier's probability estimates. To provide such sets, conformal predictors often estimate a cutoff threshold for the probability estimates based on a calibration set. Conformal predictors guarantee reliability only when the calibration set is from the same distribution as the test set. Therefore, conformal predictors need to be recalibrated for new distributions. However, in practice, labeled data from new distributions is rarely available, making calibration infeasible. In this work, we consider the problem of predicting the cutoff threshold for a new distribution based on unlabeled examples. While it is impossible in general to guarantee reliability when calibrating based on unlabeled examples, we propose a method that provides
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20887;&#20313;&#37325;&#21442;&#25968;&#21270;&#21644;&#31616;&#21333;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26469;&#26368;&#23567;&#21270;&#24102;&#26377;$L_1$&#24809;&#32602;&#30340;&#36890;&#29992;&#21487;&#24494;&#25439;&#22833;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;\textit{spred}&#65292;&#26159;$L_1$&#30340;&#31934;&#30830;&#27714;&#35299;&#22120;&#65292;&#21487;&#29992;&#20110;&#35757;&#32451;&#31232;&#30095;&#31070;&#32463;&#32593;&#32476;&#20197;&#25191;&#34892;&#22522;&#22240;&#36873;&#25321;&#20219;&#21153;&#21644;&#31070;&#32463;&#32593;&#32476;&#21387;&#32553;&#20219;&#21153;&#65292;&#24357;&#21512;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#31232;&#30095;&#24615;&#21644;&#20256;&#32479;&#32479;&#35745;&#23398;&#20064;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2210.01212</link><description>&lt;p&gt;
&#36890;&#36807;&#20887;&#20313;&#24615;&#23454;&#29616;&#31232;&#30095;&#24615;&#65306;&#29992;SGD&#27714;&#35299;$L_1$
&lt;/p&gt;
&lt;p&gt;
Sparsity by Redundancy: Solving $L_1$ with SGD. (arXiv:2210.01212v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.01212
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20887;&#20313;&#37325;&#21442;&#25968;&#21270;&#21644;&#31616;&#21333;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26469;&#26368;&#23567;&#21270;&#24102;&#26377;$L_1$&#24809;&#32602;&#30340;&#36890;&#29992;&#21487;&#24494;&#25439;&#22833;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;\textit{spred}&#65292;&#26159;$L_1$&#30340;&#31934;&#30830;&#27714;&#35299;&#22120;&#65292;&#21487;&#29992;&#20110;&#35757;&#32451;&#31232;&#30095;&#31070;&#32463;&#32593;&#32476;&#20197;&#25191;&#34892;&#22522;&#22240;&#36873;&#25321;&#20219;&#21153;&#21644;&#31070;&#32463;&#32593;&#32476;&#21387;&#32553;&#20219;&#21153;&#65292;&#24357;&#21512;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#31232;&#30095;&#24615;&#21644;&#20256;&#32479;&#32479;&#35745;&#23398;&#20064;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a method called "spred" to minimize a generic differentiable loss function with $L_1$ penalty using redundant reparametrization and straightforward stochastic gradient descent. It is an exact solver of $L_1$ and can be used to train sparse neural networks for gene selection tasks and neural network compression tasks, bridging the gap between sparsity in deep learning and conventional statistical learning.
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20887;&#20313;&#37325;&#21442;&#25968;&#21270;&#21644;&#31616;&#21333;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26469;&#26368;&#23567;&#21270;&#24102;&#26377;$L_1$&#24809;&#32602;&#30340;&#36890;&#29992;&#21487;&#24494;&#25439;&#22833;&#20989;&#25968;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#25552;&#35758;&#26159;$L_1$&#24809;&#32602;&#31561;&#20215;&#20110;&#24102;&#26377;&#26435;&#37325;&#34928;&#20943;&#30340;&#21487;&#24494;&#37325;&#21442;&#25968;&#21270;&#30340;&#30452;&#25509;&#25512;&#24191;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#21363;\textit{spred}&#65292;&#26159;$L_1$&#30340;&#31934;&#30830;&#27714;&#35299;&#22120;&#65292;&#24182;&#19988;&#23545;&#20110;&#36890;&#29992;&#30340;&#38750;&#20984;&#20989;&#25968;&#65292;&#37325;&#21442;&#25968;&#21270;&#25216;&#24039;&#26159;&#23436;&#20840;&#8220;&#33391;&#24615;&#8221;&#30340;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#65292;&#21253;&#25324;(1)&#35757;&#32451;&#31232;&#30095;&#31070;&#32463;&#32593;&#32476;&#20197;&#25191;&#34892;&#22522;&#22240;&#36873;&#25321;&#20219;&#21153;&#65292;&#20854;&#20013;&#28041;&#21450;&#22312;&#38750;&#24120;&#39640;&#32500;&#31354;&#38388;&#20013;&#25214;&#21040;&#30456;&#20851;&#29305;&#24449;&#65292;&#20197;&#21450;(2)&#31070;&#32463;&#32593;&#32476;&#21387;&#32553;&#20219;&#21153;&#65292;&#20808;&#21069;&#23581;&#35797;&#24212;&#29992;$L_1$&#24809;&#32602;&#30340;&#26041;&#27861;&#22343;&#26410;&#25104;&#21151;&#12290;&#20174;&#27010;&#24565;&#19978;&#35762;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#24357;&#21512;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#31232;&#30095;&#24615;&#21644;&#20256;&#32479;&#32479;&#35745;&#23398;&#20064;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose to minimize a generic differentiable loss function with $L_1$ penalty with a redundant reparametrization and straightforward stochastic gradient descent. Our proposal is the direct generalization of a series of previous ideas that the $L_1$ penalty may be equivalent to a differentiable reparametrization with weight decay. We prove that the proposed method, \textit{spred}, is an exact solver of $L_1$ and that the reparametrization trick is completely ``benign" for a generic nonconvex function. Practically, we demonstrate the usefulness of the method in (1) training sparse neural networks to perform gene selection tasks, which involves finding relevant features in a very high dimensional space, and (2) neural network compression task, to which previous attempts at applying the $L_1$-penalty have been unsuccessful. Conceptually, our result bridges the gap between the sparsity in deep learning and conventional statistical learning.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181; GFlowNets &#35757;&#32451;&#30446;&#26631;&#8212;&#8212;&#23376;&#36712;&#36857;&#24179;&#34913;(SubTB($\lambda$))&#65292;&#20174;&#37096;&#20998; episode &#23398;&#20064;&#30340;&#26041;&#24335;&#21487;&#20197;&#21152;&#36895;&#37319;&#26679;&#22120;&#22312;&#29615;&#22659;&#20013;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#20351;&#24471;&#22312;&#20043;&#21069;&#38590;&#20197;&#35757;&#32451;&#30340;&#38271;&#21160;&#20316;&#24207;&#21015;&#21644;&#22870;&#21169;&#31232;&#30095;&#30340;&#29615;&#22659;&#20013;&#20063;&#33021;&#22815;&#35757;&#32451; GFlowNets&#12290;</title><link>http://arxiv.org/abs/2209.12782</link><description>&lt;p&gt;
&#20174;&#37096;&#20998; episode &#20013;&#23398;&#20064; GFlowNets &#20197;&#25913;&#21892;&#25910;&#25947;&#24615;&#21644;&#31283;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Learning GFlowNets from partial episodes for improved convergence and stability. (arXiv:2209.12782v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.12782
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181; GFlowNets &#35757;&#32451;&#30446;&#26631;&#8212;&#8212;&#23376;&#36712;&#36857;&#24179;&#34913;(SubTB($\lambda$))&#65292;&#20174;&#37096;&#20998; episode &#23398;&#20064;&#30340;&#26041;&#24335;&#21487;&#20197;&#21152;&#36895;&#37319;&#26679;&#22120;&#22312;&#29615;&#22659;&#20013;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#20351;&#24471;&#22312;&#20043;&#21069;&#38590;&#20197;&#35757;&#32451;&#30340;&#38271;&#21160;&#20316;&#24207;&#21015;&#21644;&#22870;&#21169;&#31232;&#30095;&#30340;&#29615;&#22659;&#20013;&#20063;&#33021;&#22815;&#35757;&#32451; GFlowNets&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27969;&#32593;&#32476;(GFlowNets)&#26159;&#19968;&#31867;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#26410;&#24402;&#19968;&#21270;&#30340;&#30446;&#26631;&#23494;&#24230;&#19979;&#23545;&#31163;&#25955;&#23545;&#35937;&#36827;&#34892;&#39034;&#24207;&#37319;&#26679;&#35757;&#32451;&#65292;&#24182;&#24050;&#25104;&#21151;&#24212;&#29992;&#20110;&#21508;&#31181;&#27010;&#29575;&#24314;&#27169;&#20219;&#21153;&#20013;&#12290;&#29616;&#26377;&#30340;GFlowNets&#35757;&#32451;&#30446;&#26631;&#26082;&#21487;&#20197;&#23616;&#37096;&#20851;&#27880;&#29366;&#24577;&#25110;&#36716;&#25442;&#65292;&#20063;&#21487;&#20197;&#22312;&#25972;&#20010;&#37319;&#26679;&#36712;&#36857;&#19978;&#20256;&#25773;&#22870;&#21169;&#20449;&#21495;&#12290;&#25105;&#20204;&#35748;&#20026;&#36825;&#20123;&#26367;&#20195;&#26041;&#26696;&#20195;&#34920;&#20102;&#26799;&#24230;&#20559;&#24046;&#8212;&#26041;&#24046;&#24179;&#34913;&#30340;&#20004;&#31471;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#36825;&#31181;&#24179;&#34913;&#26469;&#20943;&#36731;&#20854;&#26377;&#23475;&#24433;&#21709;&#30340;&#26041;&#27861;&#12290;&#21463;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340; TD($\lambda$)&#31639;&#27861;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#23376;&#36712;&#36857;&#24179;&#34913;(SubTB($\lambda$))&#65292;&#19968;&#31181; GFlowNets &#35757;&#32451;&#30446;&#26631;&#65292;&#21487;&#20197;&#20174;&#19981;&#21516;&#38271;&#24230;&#30340;&#37096;&#20998;&#21160;&#20316;&#23376;&#24207;&#21015;&#20013;&#23398;&#20064;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102; SubTB($\lambda$) &#21152;&#36895;&#20102;&#22312;&#20808;&#21069;&#30740;&#31350;&#36807;&#30340;&#21644;&#26032;&#30340;&#29615;&#22659;&#20013;&#30340;&#37319;&#26679;&#22120;&#25910;&#25947;&#65292;&#24182;&#20351;&#24471;&#22312;&#21160;&#20316;&#24207;&#21015;&#26356;&#38271;&#12289;&#22870;&#21169;&#26356;&#31232;&#30095;&#30340;&#29615;&#22659;&#20013;&#35757;&#32451; GFlowNets &#25104;&#20026;&#20102;&#21487;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative flow networks (GFlowNets) are a family of algorithms for training a sequential sampler of discrete objects under an unnormalized target density and have been successfully used for various probabilistic modeling tasks. Existing training objectives for GFlowNets are either local to states or transitions, or propagate a reward signal over an entire sampling trajectory. We argue that these alternatives represent opposite ends of a gradient bias-variance tradeoff and propose a way to exploit this tradeoff to mitigate its harmful effects. Inspired by the TD($\lambda$) algorithm in reinforcement learning, we introduce subtrajectory balance or SubTB($\lambda$), a GFlowNet training objective that can learn from partial action subsequences of varying lengths. We show that SubTB($\lambda$) accelerates sampler convergence in previously studied and new environments and enables training GFlowNets in environments with longer action sequences and sparser reward landscapes than what was poss
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23884;&#20837;&#22270;&#24418;&#21040;&#21521;&#37327;&#31354;&#38388;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#24352;&#37327;&#31215;&#20197;&#21450;&#29699;&#24418;&#30721;&#23454;&#29616;&#39640;&#25928;&#21387;&#32553;&#21644;&#34920;&#24449;&#65292;&#22312;&#31232;&#30095;&#22270;&#34920;&#31034;&#21644;&#20854;&#20182;&#24212;&#29992;&#20013;&#20855;&#26377;&#28508;&#22312;&#25216;&#26415;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2208.10917</link><description>&lt;p&gt;
&#24352;&#37327;&#31215;&#19982;&#36817;&#20284;&#27491;&#20132;&#30721;&#30340;&#22270;&#23884;&#20837;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Graph Embeddings via Tensor Products and Approximately Orthonormal Codes. (arXiv:2208.10917v4 [cs.SI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.10917
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23884;&#20837;&#22270;&#24418;&#21040;&#21521;&#37327;&#31354;&#38388;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#24352;&#37327;&#31215;&#20197;&#21450;&#29699;&#24418;&#30721;&#23454;&#29616;&#39640;&#25928;&#21387;&#32553;&#21644;&#34920;&#24449;&#65292;&#22312;&#31232;&#30095;&#22270;&#34920;&#31034;&#21644;&#20854;&#20182;&#24212;&#29992;&#20013;&#20855;&#26377;&#28508;&#22312;&#25216;&#26415;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20998;&#26512;&#20102;&#19968;&#31181;&#20197;&#20445;&#25345;&#32467;&#26500;&#26041;&#24335;&#26469;&#23884;&#20837;&#22270;&#24418;&#30340;&#26041;&#27861;&#65292;&#23637;&#31034;&#20102;&#20854;&#20016;&#23500;&#30340;&#34920;&#24449;&#33021;&#21147;&#24182;&#24314;&#31435;&#20102;&#19968;&#20123;&#29702;&#35770;&#24615;&#36136;&#12290;&#25105;&#20204;&#30340;&#36807;&#31243;&#23646;&#20110;&#32465;&#23450;&#21644;&#27714;&#21644;&#26041;&#27861;&#65292;&#24182;&#19988;&#25105;&#20204;&#26174;&#31034;&#20102;&#24352;&#37327;&#31215;&#26159;&#23562;&#37325;&#21472;&#21152;&#21407;&#29702;&#30340;&#26368;&#19968;&#33324;&#30340;&#32465;&#23450;&#25805;&#20316;&#12290;&#25105;&#20204;&#36824;&#24314;&#31435;&#20102;&#19968;&#20123;&#31934;&#30830;&#30340;&#32467;&#26524;&#23545;&#25105;&#20204;&#26041;&#27861;&#30340;&#34892;&#20026;&#36827;&#34892;&#20102;&#34920;&#24449;&#65292;&#24182;&#19988;&#25105;&#20204;&#35777;&#26126;&#25105;&#20204;&#20351;&#29992;&#30340;&#29699;&#24418;&#30721;&#23454;&#29616;&#20102;&#19968;&#20010;&#35013;&#31665;&#19978;&#38480;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19982;&#37051;&#25509;&#30697;&#38453;&#30340;&#32852;&#31995;&#65292;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26576;&#31181;&#24847;&#20041;&#19978;&#26159;&#19968;&#31181;&#37051;&#25509;&#30697;&#38453;&#30340;&#21387;&#32553;&#65292;&#20855;&#26377;&#31232;&#30095;&#22270;&#34920;&#31034;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyze a method for embedding graphs as vectors in a structure-preserving manner, showcasing its rich representational capacity and establishing some of its theoretical properties. Our procedure falls under the bind-and-sum approach, and we show that the tensor product is the most general binding operation that respects the superposition principle. We also establish some precise results characterizing the behavior of our method, and we show that our use of spherical codes achieves a packing upper bound. We establish a link to adjacency matrices, showing that our method is, in some sense, a compression of adjacency matrices with applications towards sparse graph representations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#20351;&#29992;&#20102;&#26426;&#22120;&#23398;&#20064;&#21644;&#33258;&#36866;&#24212;&#23454;&#39564;&#25216;&#26415;&#65292;&#29992;&#20110;&#33258;&#36866;&#24212;&#24615;&#20020;&#24202;&#35797;&#39564;&#20013;&#21463;&#30410;&#20110;&#32473;&#23450;&#27835;&#30103;&#30340;&#24739;&#32773;&#20122;&#32676;&#30340;&#35782;&#21035;&#12290;&#26412;&#25991;&#36890;&#36807;&#23454;&#39564;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#24322;&#34920;&#29616;&#65292;&#24182;&#35299;&#20915;&#20102;&#36825;&#19968;&#38382;&#39064;&#30340;&#29420;&#29305;&#25361;&#25112;&#65292;&#20135;&#29983;&#20102;&#26377;&#25928;&#21644;&#26377;&#29992;&#30340;&#21457;&#29616;&#12290;</title><link>http://arxiv.org/abs/2208.05844</link><description>&lt;p&gt;
&#20020;&#24202;&#35797;&#39564;&#20013;&#21463;&#30410;&#20154;&#32676;&#30340;&#33258;&#36866;&#24212;&#35782;&#21035;&#65306;&#26426;&#22120;&#23398;&#20064;&#25361;&#25112;&#19982;&#35299;&#20915;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Adaptive Identification of Populations with Treatment Benefit in Clinical Trials: Machine Learning Challenges and Solutions. (arXiv:2208.05844v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.05844
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#20351;&#29992;&#20102;&#26426;&#22120;&#23398;&#20064;&#21644;&#33258;&#36866;&#24212;&#23454;&#39564;&#25216;&#26415;&#65292;&#29992;&#20110;&#33258;&#36866;&#24212;&#24615;&#20020;&#24202;&#35797;&#39564;&#20013;&#21463;&#30410;&#20110;&#32473;&#23450;&#27835;&#30103;&#30340;&#24739;&#32773;&#20122;&#32676;&#30340;&#35782;&#21035;&#12290;&#26412;&#25991;&#36890;&#36807;&#23454;&#39564;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#24322;&#34920;&#29616;&#65292;&#24182;&#35299;&#20915;&#20102;&#36825;&#19968;&#38382;&#39064;&#30340;&#29420;&#29305;&#25361;&#25112;&#65292;&#20135;&#29983;&#20102;&#26377;&#25928;&#21644;&#26377;&#29992;&#30340;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#30830;&#35748;&#24615;&#20020;&#24202;&#35797;&#39564;&#20013;&#33258;&#36866;&#24212;&#24615;&#22320;&#35782;&#21035;&#21463;&#30410;&#20110;&#32473;&#23450;&#27835;&#30103;&#30340;&#24739;&#32773;&#20122;&#32676;&#30340;&#38382;&#39064;&#12290;&#36825;&#31181;&#33258;&#36866;&#24212;&#24615;&#20020;&#24202;&#35797;&#39564;&#24050;&#32463;&#22312;&#29983;&#29289;&#32479;&#35745;&#23398;&#20013;&#24471;&#21040;&#20102;&#28145;&#20837;&#30740;&#31350;&#65292;&#20294;&#30446;&#21069;&#20165;&#20801;&#35768;&#26377;&#38480;&#30340;&#33258;&#36866;&#24212;&#24615;&#12290;&#26412;&#25991;&#26088;&#22312;&#25918;&#23485;&#36825;&#26679;&#30340;&#35774;&#35745;&#30340;&#32463;&#20856;&#38480;&#21046;&#65292;&#24182;&#30740;&#31350;&#22914;&#20309;&#34701;&#21512;&#26368;&#36817;&#26426;&#22120;&#23398;&#20064;&#25991;&#29486;&#20013;&#30340;&#33258;&#36866;&#24212;&#21644;&#22312;&#32447;&#23454;&#39564;&#30340;&#24605;&#24819;&#65292;&#20351;&#35797;&#39564;&#26356;&#21152;&#28789;&#27963;&#21644;&#39640;&#25928;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#20122;&#32676;&#36873;&#25321;&#38382;&#39064;&#30340;&#29420;&#29305;&#29305;&#24449;&#8212;&#8212;&#26368;&#37325;&#35201;&#30340;&#26159;&#65292;&#65288;i&#65289;&#36890;&#24120;&#24863;&#20852;&#36259;&#30340;&#26159;&#22312;&#26377;&#38480;&#30340;&#39044;&#31639;&#19979;&#25214;&#21040;&#20219;&#20309;&#21463;&#30410;&#20110;&#27835;&#30103;&#30340;&#20122;&#32676;&#65288;&#32780;&#19981;&#19968;&#23450;&#26159;&#21333;&#20010;&#25928;&#26524;&#26368;&#22823;&#30340;&#20122;&#32452;&#65289;&#65292;&#20197;&#21450;&#65288;ii&#65289;&#21482;&#38656;&#22312;&#24179;&#22343;&#27700;&#24179;&#19978;&#35777;&#26126;&#26377;&#25928;&#24615;&#8212;&#8212;&#20652;&#29983;&#20102;&#26377;&#36259;&#30340;&#25361;&#25112;&#21644;&#35774;&#35745;&#31639;&#27861;&#35299;&#20915;&#26041;&#26696;&#30340;&#26032;&#35201;&#27714;&#12290;&#22522;&#20110;&#36825;&#20123;&#21457;&#29616;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#30340;&#23376;&#32676;&#20307;&#35782;&#21035;&#26041;&#27861;&#65292;&#21516;&#26102;&#20351;&#29992;&#20102;&#26426;&#22120;&#23398;&#20064;&#21644;&#33258;&#36866;&#24212;&#23454;&#39564;&#25216;&#26415;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#22823;&#37327;&#30340;&#27169;&#25311;&#21644;&#23454;&#38469;&#25968;&#25454;&#20998;&#26512;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#19981;&#20165;&#34920;&#29616;&#20248;&#24322;&#65292;&#32780;&#19988;&#35299;&#20915;&#20102;&#36825;&#19968;&#38382;&#39064;&#30340;&#29420;&#29305;&#25361;&#25112;&#65292;&#20135;&#29983;&#20102;&#26377;&#25928;&#21644;&#26377;&#29992;&#30340;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of adaptively identifying patient subpopulations that benefit from a given treatment during a confirmatory clinical trial. This type of adaptive clinical trial has been thoroughly studied in biostatistics, but has been allowed only limited adaptivity so far. Here, we aim to relax classical restrictions on such designs and investigate how to incorporate ideas from the recent machine learning literature on adaptive and online experimentation to make trials more flexible and efficient. We find that the unique characteristics of the subpopulation selection problem -- most importantly that (i) one is usually interested in finding subpopulations with any treatment benefit (and not necessarily the single subgroup with largest effect) given a limited budget and that (ii) effectiveness only has to be demonstrated across the subpopulation on average -- give rise to interesting challenges and new desiderata when designing algorithmic solutions. Building on these findings, we 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30417;&#30563;&#24352;&#37327;&#38477;&#32500;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#33021;&#22788;&#29702;&#19981;&#23436;&#25972;&#30340;&#25104;&#20687;&#25968;&#25454;&#65292;&#21033;&#29992;&#22833;&#25928;&#26102;&#38388;&#30417;&#30563;&#25552;&#21462;&#20302;&#32500;&#29305;&#24449;&#65292;&#25552;&#39640;&#20102;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2207.11353</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#30417;&#30563;&#24352;&#37327;&#38477;&#32500;&#30340;&#19981;&#23436;&#25972;&#25104;&#20687;&#25968;&#25454;&#30340;&#39044;&#27979;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Supervised Tensor Dimension Reduction-Based Prognostics Model for Applications with Incomplete Imaging Data. (arXiv:2207.11353v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.11353
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30417;&#30563;&#24352;&#37327;&#38477;&#32500;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#33021;&#22788;&#29702;&#19981;&#23436;&#25972;&#30340;&#25104;&#20687;&#25968;&#25454;&#65292;&#21033;&#29992;&#22833;&#25928;&#26102;&#38388;&#30417;&#30563;&#25552;&#21462;&#20302;&#32500;&#29305;&#24449;&#65292;&#25552;&#39640;&#20102;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#24352;&#37327;&#25968;&#25454;&#30340;&#30417;&#30563;&#38477;&#32500;&#26041;&#27861;&#65292;&#19982;&#22823;&#22810;&#25968;&#22522;&#20110;&#22270;&#20687;&#30340;&#39044;&#27979;&#27169;&#22411;&#30456;&#27604;&#20855;&#26377;&#20004;&#20010;&#20248;&#21183;&#12290;&#39318;&#20808;&#65292;&#35813;&#27169;&#22411;&#19981;&#35201;&#27714;&#24352;&#37327;&#25968;&#25454;&#23436;&#25972;&#65292;&#20174;&#32780;&#25193;&#23637;&#20102;&#20854;&#24212;&#29992;&#33539;&#22260;&#65307;&#20854;&#27425;&#65292;&#21033;&#29992;&#22833;&#25928;&#26102;&#38388;&#65288;TTF&#65289;&#26469;&#30417;&#30563;&#25552;&#21462;&#20302;&#32500;&#29305;&#24449;&#65292;&#20351;&#25552;&#21462;&#30340;&#29305;&#24449;&#26356;&#26377;&#25928;&#22320;&#29992;&#20110;&#21518;&#32493;&#39044;&#27979;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#20026;&#21442;&#25968;&#20272;&#35745;&#25552;&#20986;&#20102;&#19968;&#31181;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#22312;&#29305;&#23450;&#20998;&#24067;&#19979;&#25512;&#23548;&#20986;&#20102;&#38381;&#24335;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a supervised dimension reduction methodology for tensor data which has two advantages over most image-based prognostic models. First, the model does not require tensor data to be complete which expands its application to incomplete data. Second, it utilizes time-to-failure (TTF) to supervise the extraction of low-dimensional features which makes the extracted features more effective for the subsequent prognostic. Besides, an optimization algorithm is proposed for parameter estimation and closed-form solutions are derived under certain distributions.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20613;&#37324;&#21494;&#20998;&#26512;&#25216;&#26415;&#65292;&#29992;&#20110;&#20174;$\mathscr{L}_2(\mathbb{R})$&#30340;&#27491;&#20132;&#22522;&#20013;&#26500;&#24314;&#24179;&#31227;&#19981;&#21464;&#26680;&#20989;&#25968;&#30340;&#27491;&#20132;&#22522;&#23637;&#24320;&#65292;&#23454;&#29616;&#20102;&#39532;&#29305;&#23572;&#26680;&#20989;&#25968;&#12289;&#26607;&#35199;&#26680;&#20989;&#25968;&#21644;&#39640;&#26031;&#26680;&#20989;&#25968;&#30340;&#26126;&#30830;&#23637;&#24320;&#34920;&#36798;&#24335;&#12290;</title><link>http://arxiv.org/abs/2206.08648</link><description>&lt;p&gt;
&#24179;&#31227;&#19981;&#21464;&#26680;&#20989;&#25968;&#30340;&#27491;&#20132;&#23637;&#24320;
&lt;/p&gt;
&lt;p&gt;
Orthonormal Expansions for Translation-Invariant Kernels. (arXiv:2206.08648v3 [math.CA] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.08648
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20613;&#37324;&#21494;&#20998;&#26512;&#25216;&#26415;&#65292;&#29992;&#20110;&#20174;$\mathscr{L}_2(\mathbb{R})$&#30340;&#27491;&#20132;&#22522;&#20013;&#26500;&#24314;&#24179;&#31227;&#19981;&#21464;&#26680;&#20989;&#25968;&#30340;&#27491;&#20132;&#22522;&#23637;&#24320;&#65292;&#23454;&#29616;&#20102;&#39532;&#29305;&#23572;&#26680;&#20989;&#25968;&#12289;&#26607;&#35199;&#26680;&#20989;&#25968;&#21644;&#39640;&#26031;&#26680;&#20989;&#25968;&#30340;&#26126;&#30830;&#23637;&#24320;&#34920;&#36798;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26500;&#24314;&#24179;&#31227;&#19981;&#21464;&#26680;&#20989;&#25968;&#30340;&#27491;&#20132;&#22522;&#23637;&#24320;&#30340;&#20613;&#37324;&#21494;&#20998;&#26512;&#25216;&#26415;&#65292;&#35813;&#25216;&#26415;&#21033;&#29992;$\mathscr{L}_2(\mathbb{R})$&#19978;&#30340;&#27491;&#20132;&#22522;&#65292;&#24471;&#21040;&#20102;&#23454;&#36724;&#19978;&#25152;&#26377;&#21322;&#25972;&#25968;&#38454;&#39532;&#29305;&#23572;&#26680;&#20989;&#25968;&#12289;&#26607;&#35199;&#26680;&#20989;&#25968;&#20197;&#21450;&#39640;&#26031;&#26680;&#20989;&#25968;&#30340;&#26126;&#30830;&#23637;&#24320;&#34920;&#36798;&#24335;&#65292;&#20998;&#21035;&#30001;&#30456;&#20851;&#30340;&#25289;&#30422;&#23572;&#20989;&#25968;&#12289;&#26377;&#29702;&#20989;&#25968;&#21644;&#21380;&#31859;&#20989;&#25968;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a general Fourier analytic technique for constructing orthonormal basis expansions of translation-invariant kernels from orthonormal bases of $\mathscr{L}_2(\mathbb{R})$. This allows us to derive explicit expansions on the real line for (i) Mat\'ern kernels of all half-integer orders in terms of associated Laguerre functions, (ii) the Cauchy kernel in terms of rational functions, and (iii) the Gaussian kernel in terms of Hermite functions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#36807;&#21435;&#38382;&#39064;&#30340;&#30693;&#35782;&#21644;&#20449;&#24687;&#26469;&#36805;&#36895;&#39044;&#27979;&#21644;&#35299;&#20915;&#26032;&#38382;&#39064;&#65292;&#37325;&#22797;&#22320;&#35299;&#20915;&#19981;&#21516;&#24230;&#37327;&#20043;&#38388;&#30340;&#31867;&#20284;OT&#38382;&#39064;&#65292;&#20174;&#32780;&#25913;&#21892;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#30340;&#35745;&#31639;&#26102;&#38388;&#12290;</title><link>http://arxiv.org/abs/2206.05262</link><description>&lt;p&gt;
&#20803;&#26368;&#20248;&#36755;&#36816;
&lt;/p&gt;
&lt;p&gt;
Meta Optimal Transport. (arXiv:2206.05262v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.05262
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#36807;&#21435;&#38382;&#39064;&#30340;&#30693;&#35782;&#21644;&#20449;&#24687;&#26469;&#36805;&#36895;&#39044;&#27979;&#21644;&#35299;&#20915;&#26032;&#38382;&#39064;&#65292;&#37325;&#22797;&#22320;&#35299;&#20915;&#19981;&#21516;&#24230;&#37327;&#20043;&#38388;&#30340;&#31867;&#20284;OT&#38382;&#39064;&#65292;&#20174;&#32780;&#25913;&#21892;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#30340;&#35745;&#31639;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;&#20998;&#25674;&#20248;&#21270;&#26469;&#39044;&#27979;&#26368;&#20248;&#36755;&#36816;&#65288;OT&#65289;&#22320;&#22270;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#20803;OT&#12290;&#36825;&#26377;&#21161;&#20110;&#36890;&#36807;&#21033;&#29992;&#36807;&#21435;&#38382;&#39064;&#30340;&#30693;&#35782;&#21644;&#20449;&#24687;&#26469;&#36805;&#36895;&#39044;&#27979;&#21644;&#35299;&#20915;&#26032;&#38382;&#39064;&#65292;&#20174;&#32780;&#37325;&#22797;&#22320;&#35299;&#20915;&#19981;&#21516;&#24230;&#37327;&#20043;&#38388;&#30340;&#31867;&#20284;OT&#38382;&#39064;&#12290;&#21542;&#21017;&#65292;&#26631;&#20934;&#26041;&#27861;&#20250;&#24573;&#30053;&#36807;&#21435;&#35299;&#20915;&#26041;&#26696;&#30340;&#30693;&#35782;&#65292;&#20174;&#22836;&#24320;&#22987;&#27425;&#20248;&#22320;&#37325;&#26032;&#35299;&#20915;&#27599;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#22312;&#28784;&#24230;&#22270;&#20687;&#12289;&#29699;&#24418;&#25968;&#25454;&#12289;&#20998;&#31867;&#26631;&#31614;&#21644;&#39068;&#33394;&#35843;&#33394;&#26495;&#20043;&#38388;&#23454;&#20363;&#21270;&#20803;OT&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;&#23427;&#20204;&#26469;&#25913;&#21892;&#26631;&#20934;OT&#27714;&#35299;&#22120;&#30340;&#35745;&#31639;&#26102;&#38388;&#12290;&#25105;&#20204;&#30340;&#28304;&#20195;&#30721;&#21487;&#22312;&#27492;http URL&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the use of amortized optimization to predict optimal transport (OT) maps from the input measures, which we call Meta OT. This helps repeatedly solve similar OT problems between different measures by leveraging the knowledge and information present from past problems to rapidly predict and solve new problems. Otherwise, standard methods ignore the knowledge of the past solutions and suboptimally re-solve each problem from scratch. We instantiate Meta OT models in discrete and continuous settings between grayscale images, spherical data, classification labels, and color palettes and use them to improve the computational time of standard OT solvers. Our source code is available at this http URL
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32454;&#33268;&#30740;&#31350;&#20102;&#28857;&#31215;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#65292;&#38024;&#23545; $m\propto d^r$ &#39640;&#38454;&#26631;&#24230;&#20851;&#31995;&#25552;&#20986;&#20102;&#31934;&#30830;&#30340;&#27979;&#35797;&#35823;&#24046;&#12289;&#20559;&#24046;&#21644;&#26041;&#24046;&#20844;&#24335;&#12290;</title><link>http://arxiv.org/abs/2205.14846</link><description>&lt;p&gt;
&#28857;&#31215;&#26680;&#22238;&#24402;&#30340;&#31934;&#30830;&#23398;&#20064;&#26354;&#32447;&#21644;&#39640;&#38454;&#26631;&#24230;&#26497;&#38480;
&lt;/p&gt;
&lt;p&gt;
Precise Learning Curves and Higher-Order Scaling Limits for Dot Product Kernel Regression. (arXiv:2205.14846v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.14846
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32454;&#33268;&#30740;&#31350;&#20102;&#28857;&#31215;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#65292;&#38024;&#23545; $m\propto d^r$ &#39640;&#38454;&#26631;&#24230;&#20851;&#31995;&#25552;&#20986;&#20102;&#31934;&#30830;&#30340;&#27979;&#35797;&#35823;&#24046;&#12289;&#20559;&#24046;&#21644;&#26041;&#24046;&#20844;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19981;&#26029;&#25512;&#36827;&#35745;&#31639;&#21069;&#27839;&#65292;&#24320;&#21457;&#23545;&#19981;&#21516;&#27169;&#22411;&#21644;&#25968;&#25454;&#32553;&#25918;&#26041;&#26696;&#19979;&#39044;&#26399;&#24615;&#33021;&#25552;&#39640;&#30340;&#31934;&#30830;&#20272;&#35745;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#30446;&#21069;&#65292;&#20851;&#20110;&#25551;&#36848;&#39044;&#27979;&#35823;&#24046;&#22914;&#20309;&#38543;&#30528;&#26679;&#26412;&#25968;&#37327;&#32780;&#21464;&#21270;&#30340;&#23398;&#20064;&#26354;&#32447;&#30340;&#29702;&#35770;&#29702;&#35299;&#21463;&#38480;&#20110;&#22823;&#26679;&#26412;&#28176;&#36817;&#24615; ($m\to\infty$) &#25110;&#23545;&#20110;&#26576;&#20123;&#31616;&#21333;&#25968;&#25454;&#20998;&#24067;&#30340;&#39640;&#32500;&#28176;&#36817;&#24615;&#65292;&#20854;&#20013;&#26679;&#26412;&#25968;&#37327;&#19982;&#32500;&#25968;&#25104;&#32447;&#24615;&#27604;&#20363; ($m\propto d$)&#12290;&#36825;&#20004;&#20010;&#33539;&#30068;&#20043;&#38388;&#23384;&#22312;&#24456;&#22823;&#24046;&#36317;&#65292;&#21253;&#25324;&#25152;&#26377;&#39640;&#38454;&#26631;&#24230;&#20851;&#31995; $m\propto d^r$&#65292;&#36825;&#26159;&#26412;&#25991;&#30340;&#30740;&#31350;&#23545;&#35937;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#28857;&#31215;&#26680;&#23725;&#22238;&#24402;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#22312; $m/d\rightarrow2r$ &#30340; $r$ &#38454;&#28176;&#36817;&#26631;&#24230;&#19979;&#65288;&#20854;&#20013; $m\to\infty$&#65289;&#65292;&#23545;&#20110;&#20174;&#29699;&#38754;&#19978;&#22343;&#21248;&#25277;&#21462;&#30340;&#25968;&#25454;&#65292;&#27979;&#35797;&#35823;&#24046;&#12289;&#20559;&#24046;&#21644;&#26041;&#24046;&#30340;&#31934;&#30830;&#20844;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
As modern machine learning models continue to advance the computational frontier, it has become increasingly important to develop precise estimates for expected performance improvements under different model and data scaling regimes. Currently, theoretical understanding of the learning curves that characterize how the prediction error depends on the number of samples is restricted to either large-sample asymptotics ($m\to\infty$) or, for certain simple data distributions, to the high-dimensional asymptotics in which the number of samples scales linearly with the dimension ($m\propto d$). There is a wide gulf between these two regimes, including all higher-order scaling relations $m\propto d^r$, which are the subject of the present paper. We focus on the problem of kernel ridge regression for dot-product kernels and present precise formulas for the test error, bias, and variance, for data drawn uniformly from the sphere in the $r$th-order asymptotic scaling regime $m\to\infty$ with $m/d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#21033;&#29992;&#20803;&#23398;&#20064;&#22120;&#20272;&#35745;&#22810;&#20540;&#22788;&#29702;&#24322;&#36136;&#25928;&#24212;&#30340;&#38382;&#39064;&#65292;&#21457;&#29616;&#26420;&#32032;&#25193;&#23637;&#24182;&#19981;&#24635;&#26159;&#21487;&#34892;&#65292;&#25552;&#20986;&#24182;&#35752;&#35770;&#20102;&#19968;&#20123;&#34920;&#29616;&#33391;&#22909;&#30340;&#20803;&#23398;&#20064;&#22120;&#12290;</title><link>http://arxiv.org/abs/2205.14714</link><description>&lt;p&gt;
&#20803;&#23398;&#20064;&#22120;&#29992;&#20110;&#22810;&#20540;&#22788;&#29702;&#24322;&#36136;&#20316;&#29992;&#20272;&#35745;&#30340;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Comparison of meta-learners for estimating multi-valued treatment heterogeneous effects. (arXiv:2205.14714v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.14714
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#21033;&#29992;&#20803;&#23398;&#20064;&#22120;&#20272;&#35745;&#22810;&#20540;&#22788;&#29702;&#24322;&#36136;&#25928;&#24212;&#30340;&#38382;&#39064;&#65292;&#21457;&#29616;&#26420;&#32032;&#25193;&#23637;&#24182;&#19981;&#24635;&#26159;&#21487;&#34892;&#65292;&#25552;&#20986;&#24182;&#35752;&#35770;&#20102;&#19968;&#20123;&#34920;&#29616;&#33391;&#22909;&#30340;&#20803;&#23398;&#20064;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21033;&#29992;&#35266;&#23519;&#25968;&#25454;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#26102;&#65292;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;CATE&#65289;&#20272;&#35745;&#26159;&#20027;&#35201;&#25361;&#25112;&#20043;&#19968;&#12290;&#38500;&#20102;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27169;&#22411;&#22806;&#65292;&#36824;&#24320;&#21457;&#20986;&#20102;&#31216;&#20026;&#20803;&#23398;&#20064;&#22120;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;&#22120;&#20197;&#20272;&#35745;CATE&#65292;&#20854;&#20027;&#35201;&#20248;&#28857;&#26159;&#19981;&#23616;&#38480;&#20110;&#29305;&#23450;&#30340;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#24403;&#22788;&#29702;&#19981;&#26159;&#20108;&#36827;&#21046;&#30340;&#26102;&#65292;&#19968;&#20123;&#26420;&#32032;&#25193;&#23637;&#30340;&#38480;&#21046;&#20250;&#20986;&#29616;&#65292;&#36825;&#26679;&#30340;&#20219;&#21153;&#23601;&#21464;&#24471;&#26356;&#21152;&#22797;&#26434;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20803;&#23398;&#20064;&#22120;&#29992;&#20110;&#20272;&#35745;&#22810;&#20540;&#22788;&#29702;&#24322;&#36136;&#25928;&#24212;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19981;&#21516;&#30340;&#20803;&#23398;&#20064;&#22120;&#65292;&#29702;&#35770;&#20998;&#26512;&#20102;&#23427;&#20204;&#30340;&#35823;&#24046;&#19978;&#30028;&#20316;&#20026;&#37325;&#35201;&#21442;&#25968;&#30340;&#20989;&#25968;&#65292;&#20363;&#22914;&#22788;&#29702;&#27700;&#24179;&#30340;&#25968;&#37327;&#65292;&#32467;&#26524;&#26174;&#31034;&#65292;&#26420;&#32032;&#25193;&#23637;&#24182;&#19981;&#24635;&#26159;&#25552;&#20379;&#28385;&#24847;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#24341;&#20837;&#21644;&#35752;&#35770;&#20102;&#19968;&#20123;&#20803;&#23398;&#20064;&#22120;&#65292;&#23427;&#20204;&#22312;&#22788;&#29702;&#25968;&#37327;&#22686;&#22810;&#26102;&#34920;&#29616;&#33391;&#22909;&#12290;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#21644;&#19968;&#39033;&#20057;&#32925;&#27835;&#30103;&#30740;&#31350;&#30340;&#30495;&#23454;&#25968;&#25454;&#31034;&#20363;&#65292;&#25105;&#20204;&#35777;&#23454;&#20102;&#20803;&#23398;&#20064;&#22120;&#30340;&#20248;&#32570;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conditional Average Treatment Effects (CATE) estimation is one of the main challenges in causal inference with observational data. In addition to Machine Learning based-models, nonparametric estimators called meta-learners have been developed to estimate the CATE with the main advantage of not restraining the estimation to a specific supervised learning method. This task becomes, however, more complicated when the treatment is not binary as some limitations of the naive extensions emerge. This paper looks into meta-learners for estimating the heterogeneous effects of multi-valued treatments. We consider different meta-learners, and we carry out a theoretical analysis of their error upper bounds as functions of important parameters such as the number of treatment levels, showing that the naive extensions do not always provide satisfactory results. We introduce and discuss meta-learners that perform well as the number of treatments increases. We empirically confirm the strengths and weak
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#21033;&#29992;&#40654;&#26364;&#20960;&#20309;&#21644;&#21494;&#38754;&#29702;&#35770;&#21019;&#26032;&#24212;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#40065;&#26834;&#24615;&#30340;&#26032;&#35270;&#35282;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#25968;&#25454;&#31354;&#38388;&#30340;&#20197;&#26354;&#29575;&#20026;&#32771;&#37327;&#22240;&#32032;&#30340; two-step spectral &#23545;&#25239;&#25915;&#20987;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2203.00922</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#30340;&#35268;&#33539;&#21494;&#38754;&#65306;&#40065;&#26834;&#24615;&#24212;&#29992;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Canonical foliations of neural networks: application to robustness. (arXiv:2203.00922v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.00922
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#21033;&#29992;&#40654;&#26364;&#20960;&#20309;&#21644;&#21494;&#38754;&#29702;&#35770;&#21019;&#26032;&#24212;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#40065;&#26834;&#24615;&#30340;&#26032;&#35270;&#35282;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#25968;&#25454;&#31354;&#38388;&#30340;&#20197;&#26354;&#29575;&#20026;&#32771;&#37327;&#22240;&#32032;&#30340; two-step spectral &#23545;&#25239;&#25915;&#20987;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#26131;&#21463;&#21040;&#23545;&#25239;&#25915;&#20987;&#12290;&#32780;&#23545;&#25239;&#23398;&#20064;&#27491;&#22312;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#40065;&#26834;&#24615;&#35270;&#35282;&#65292;&#37319;&#29992;&#40654;&#26364;&#20960;&#20309;&#21644;&#21494;&#38754;&#29702;&#35770;&#12290;&#36890;&#36807;&#21019;&#24314;&#32771;&#34385;&#25968;&#25454;&#31354;&#38388;&#26354;&#29575;&#30340;&#26032;&#23545;&#25239;&#25915;&#20987;&#65292;&#21363; two-step spectral attack&#65292;&#26469;&#35828;&#26126;&#36825;&#20010;&#24819;&#27861;&#12290;&#25968;&#25454;&#31354;&#38388;&#34987;&#35270;&#20026;&#19968;&#20010;&#37197;&#22791;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340; Fisher &#20449;&#24687;&#24230;&#37327;&#65288;FIM&#65289;&#25289;&#22238;&#30340;&#65288;&#36864;&#21270;&#30340;&#65289;&#40654;&#26364;&#27969;&#24418;&#12290;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#65292;&#35813;&#24230;&#37327;&#20165;&#20026;&#21322;&#27491;&#23450;&#65292;&#20854;&#20869;&#26680;&#25104;&#20026;&#30740;&#31350;&#30340;&#26680;&#24515;&#23545;&#35937;&#12290;&#20174;&#35813;&#26680;&#20013;&#23548;&#20986;&#19968;&#20010;&#35268;&#33539;&#21494;&#38754;&#12290;&#27178;&#21521;&#21494;&#30340;&#26354;&#29575;&#32473;&#20986;&#20102;&#36866;&#24403;&#30340;&#20462;&#27491;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#20004;&#27493;&#36817;&#20284;&#30340;&#27979;&#22320;&#32447;&#21644;&#19968;&#31181;&#26032;&#30340;&#39640;&#25928;&#23545;&#25239;&#25915;&#20987;&#12290;&#35813;&#26041;&#27861;&#39318;&#20808;&#22312;&#19968;&#20010; 2D &#29609;&#20855;&#31034;&#20363;&#20013;&#36827;&#34892;&#28436;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning models are known to be vulnerable to adversarial attacks. Adversarial learning is therefore becoming a crucial task. We propose a new vision on neural network robustness using Riemannian geometry and foliation theory. The idea is illustrated by creating a new adversarial attack that takes into account the curvature of the data space. This new adversarial attack called the two-step spectral attack is a piece-wise linear approximation of a geodesic in the data space. The data space is treated as a (degenerate) Riemannian manifold equipped with the pullback of the Fisher Information Metric (FIM) of the neural network. In most cases, this metric is only semi-definite and its kernel becomes a central object to study. A canonical foliation is derived from this kernel. The curvature of transverse leaves gives the appropriate correction to get a two-step approximation of the geodesic and hence a new efficient adversarial attack. The method is first illustrated on a 2D toy example
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#31163;&#25955;&#28508;&#21464;&#37327;&#22238;&#24402;&#27169;&#22411;&#30340;&#26368;&#22823;&#30456;&#20114;&#20449;&#24687;&#36755;&#20837;&#36873;&#25321;&#12290;&#36890;&#36807;&#23545;&#32447;&#24615;&#22238;&#24402;&#28151;&#21512;&#29289;&#27169;&#22411;&#30340;Fisher&#20449;&#24687;&#20998;&#26512;&#65292;&#35777;&#26126;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20027;&#21160;&#23398;&#20064;&#21487;&#20197;&#21462;&#24471;&#24040;&#22823;&#30340;&#25910;&#30410;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31867;&#24378;&#22823;&#30340;&#26102;&#38388;&#32467;&#26500;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#25105;&#20204;&#30340;&#26694;&#26550;&#35843;&#25972;&#20026;&#22312;&#36873;&#25321;&#36807;&#31243;&#20013;&#34701;&#20837;&#26102;&#24577;&#20381;&#36182;&#24615;&#12290;</title><link>http://arxiv.org/abs/2202.13426</link><description>&lt;p&gt;
&#31163;&#25955;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#20027;&#21160;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Bayesian Active Learning for Discrete Latent Variable Models. (arXiv:2202.13426v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.13426
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#31163;&#25955;&#28508;&#21464;&#37327;&#22238;&#24402;&#27169;&#22411;&#30340;&#26368;&#22823;&#30456;&#20114;&#20449;&#24687;&#36755;&#20837;&#36873;&#25321;&#12290;&#36890;&#36807;&#23545;&#32447;&#24615;&#22238;&#24402;&#28151;&#21512;&#29289;&#27169;&#22411;&#30340;Fisher&#20449;&#24687;&#20998;&#26512;&#65292;&#35777;&#26126;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20027;&#21160;&#23398;&#20064;&#21487;&#20197;&#21462;&#24471;&#24040;&#22823;&#30340;&#25910;&#30410;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31867;&#24378;&#22823;&#30340;&#26102;&#38388;&#32467;&#26500;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#25105;&#20204;&#30340;&#26694;&#26550;&#35843;&#25972;&#20026;&#22312;&#36873;&#25321;&#36807;&#31243;&#20013;&#34701;&#20837;&#26102;&#24577;&#20381;&#36182;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#21160;&#23398;&#20064;&#26088;&#22312;&#20943;&#23569;&#25311;&#21512;&#27169;&#22411;&#21442;&#25968;&#25152;&#38656;&#30340;&#25968;&#25454;&#37327;&#65292;&#22240;&#27492;&#25104;&#20026;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#37325;&#35201;&#25216;&#26415;&#31867;&#21035;&#12290;&#28982;&#32780;&#65292;&#36807;&#21435;&#30340;&#20027;&#21160;&#23398;&#20064;&#30740;&#31350;&#24448;&#24448;&#24573;&#35270;&#20102;&#22312;&#31070;&#32463;&#31185;&#23398;&#12289;&#24515;&#29702;&#23398;&#21644;&#21508;&#31181;&#24037;&#31243;&#21644;&#31185;&#23398;&#23398;&#31185;&#20013;&#21457;&#25381;&#20851;&#38190;&#20316;&#29992;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#31163;&#25955;&#28508;&#21464;&#37327;&#22238;&#24402;&#27169;&#22411;&#30340;&#26368;&#22823;&#30456;&#20114;&#20449;&#24687;&#36755;&#20837;&#36873;&#25321;&#12290;&#25105;&#20204;&#39318;&#20808;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#19968;&#31867;&#31216;&#20026;&#8220;&#32447;&#24615;&#22238;&#24402;&#28151;&#21512;&#29289;&#8221;&#30340;&#27169;&#22411;&#12290;&#34429;&#28982;&#24050;&#30693;&#23545;&#20110;&#32447;&#24615;&#39640;&#26031;&#22238;&#24402;&#27169;&#22411;&#65292;&#20027;&#21160;&#23398;&#20064;&#24182;&#19981;&#20855;&#26377;&#20248;&#21183;&#65292;&#20294;&#25105;&#20204;&#20351;&#29992;Fisher&#20449;&#24687;&#36827;&#34892;&#20998;&#26512;&#65292;&#34920;&#26126;&#21363;&#20351;&#23545;&#20110;&#36825;&#31181;&#28151;&#21512;&#27169;&#22411;&#65292;&#20027;&#21160;&#23398;&#20064;&#20173;&#28982;&#21487;&#20197;&#21462;&#24471;&#24040;&#22823;&#30340;&#25910;&#30410;&#65292;&#24182;&#20351;&#29992;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#23545;&#27492;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31867;&#24378;&#22823;&#30340;&#26102;&#38388;&#32467;&#26500;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#25105;&#20204;&#30340;&#26694;&#26550;&#35843;&#25972;&#20026;&#22312;&#36873;&#25321;&#36807;&#31243;&#20013;&#34701;&#20837;&#26102;&#24577;&#20381;&#36182;&#24615;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#23637;&#31034;&#20102;&#20027;&#21160;&#23398;&#20064;&#22312;&#19968;&#20010;&#26032;&#39046;&#22495;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#26694;&#26550;&#65292;&#21487;&#24212;&#29992;&#20110;&#24191;&#27867;&#30340;&#31163;&#25955;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#21482;&#38656;&#36827;&#34892;&#36739;&#23569;&#30340;&#20462;&#25913;&#12290;
&lt;/p&gt;
&lt;p&gt;
Active learning seeks to reduce the amount of data required to fit the parameters of a model, thus forming an important class of techniques in modern machine learning. However, past work on active learning has largely overlooked latent variable models, which play a vital role in neuroscience, psychology, and a variety of other engineering and scientific disciplines. Here we address this gap by proposing a novel framework for maximum-mutual-information input selection for discrete latent variable regression models. We first apply our method to a class of models known as "mixtures of linear regressions" (MLR). While it is well known that active learning confers no advantage for linear-Gaussian regression models, we use Fisher information to show analytically that active learning can nevertheless achieve large gains for mixtures of such models, and we validate this improvement using both simulations and real-world data. We then consider a powerful class of temporally structured latent var
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25506;&#32034;&#24615;&#30340;&#38544;&#39532;&#23572;&#21487;&#22827;&#22240;&#23376;&#27169;&#22411;&#20197;&#21033;&#29992;&#38271;&#26399;&#31227;&#21160;&#35774;&#22791;&#25968;&#25454;&#65292;&#30830;&#23450; APNS &#29366;&#24577;&#24182;&#30740;&#31350;&#20854;&#36716;&#25442;&#21644;&#28508;&#22312;&#39118;&#38505;&#22240;&#32032;&#65292;&#20026;&#29702;&#35299;&#21644;&#24178;&#39044; APNS &#25552;&#20379;&#20102;&#26356;&#20840;&#38754;&#21644;&#23458;&#35266;&#30340;&#36884;&#24452;&#12290;</title><link>http://arxiv.org/abs/2202.12819</link><description>&lt;p&gt;
&#25506;&#32034;&#24615;&#30340;&#38544;&#39532;&#23572;&#21487;&#22827;&#22240;&#23376;&#27169;&#22411;&#29992;&#20110;&#32437;&#21521;&#31227;&#21160;&#20581;&#24247;&#25968;&#25454;&#65306;&#20197;&#19981;&#33391;&#21019;&#20260;&#21518;&#31070;&#32463;&#31934;&#31070;&#21518;&#36951;&#30151;&#20026;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
Exploratory Hidden Markov Factor Models for Longitudinal Mobile Health Data: Application to Adverse Posttraumatic Neuropsychiatric Sequelae. (arXiv:2202.12819v2 [stat.AP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.12819
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25506;&#32034;&#24615;&#30340;&#38544;&#39532;&#23572;&#21487;&#22827;&#22240;&#23376;&#27169;&#22411;&#20197;&#21033;&#29992;&#38271;&#26399;&#31227;&#21160;&#35774;&#22791;&#25968;&#25454;&#65292;&#30830;&#23450; APNS &#29366;&#24577;&#24182;&#30740;&#31350;&#20854;&#36716;&#25442;&#21644;&#28508;&#22312;&#39118;&#38505;&#22240;&#32032;&#65292;&#20026;&#29702;&#35299;&#21644;&#24178;&#39044; APNS &#25552;&#20379;&#20102;&#26356;&#20840;&#38754;&#21644;&#23458;&#35266;&#30340;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#33391;&#30340;&#21019;&#20260;&#21518;&#31070;&#32463;&#31934;&#31070;&#21518;&#36951;&#30151;&#65288;APNS&#65289;&#22312;&#36864;&#24441;&#20891;&#20154;&#21644;&#25968;&#30334;&#19975;&#32654;&#22269;&#20154;&#20013;&#24456;&#24120;&#35265;&#65292;&#32473;&#21019;&#20260;&#24184;&#23384;&#32773;&#21644;&#31038;&#20250;&#24102;&#26469;&#20102;&#24040;&#22823;&#37325;&#36127;&#12290;&#23613;&#31649;&#36807;&#21435;&#20960;&#21313;&#24180;&#23545;APNS&#36827;&#34892;&#20102;Numerous&#30340;&#30740;&#31350;&#65292;&#20294;&#30001;&#20110;&#20960;&#20010;&#29420;&#29305;&#30340;&#25361;&#25112;&#65292;&#29702;&#35299;&#20854;&#28508;&#22312;&#31070;&#32463;&#29983;&#29289;&#26426;&#21046;&#30340;&#36827;&#23637;&#26377;&#38480;&#12290;&#20854;&#20013;&#19968;&#20010;&#25361;&#25112;&#26159;&#20381;&#36182;&#20110;&#20027;&#35266;&#30340;&#33258;&#25105;&#25253;&#21578;&#27979;&#37327;APNS&#65292;&#36825;&#23481;&#26131;&#23548;&#33268;&#27979;&#37327;&#35823;&#24046;&#21644;&#20559;&#24046;&#65288;&#20363;&#22914;&#22238;&#24518;&#20559;&#20506;&#65289;&#12290;&#20026;&#20102;&#20943;&#36731;&#36825;&#20010;&#38382;&#39064;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#21033;&#29992;&#23458;&#35266;&#32437;&#21521;&#31227;&#21160;&#35774;&#22791;&#25968;&#25454;&#20197;&#35782;&#21035;&#21516;&#36136;APNS&#29366;&#24577;&#24182;&#30740;&#31350;&#21019;&#20260;&#26292;&#38706;&#21518;APNS&#30340;&#21160;&#24577;&#36716;&#25442;&#21644;&#28508;&#22312;&#39118;&#38505;&#22240;&#32032;&#30340;&#28508;&#21147;&#12290;&#20026;&#20102;&#22788;&#29702;&#32437;&#21521;&#31227;&#21160;&#35774;&#22791;&#25968;&#25454;&#25152;&#38754;&#20020;&#30340;&#29305;&#23450;&#25361;&#25112;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#25506;&#32034;&#24615;&#30340;&#38544;&#39532;&#23572;&#21487;&#22827;&#22240;&#23376;&#27169;&#22411;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#31283;&#23450;&#30340;&#26399;&#26395;&#26368;&#22823;&#21270;&#31639;&#27861;&#26469;&#23398;&#20064;&#27169;&#22411;&#21442;&#25968;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20351;&#29992;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#36825;&#20123;&#25968;&#25454;&#26469;&#33258;&#22823;&#37327;&#36973;&#21463;&#21019;&#20260;&#30340;&#36864;&#24441;&#20891;&#20154;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#33021;&#22815;&#25104;&#21151;&#22320;&#35782;&#21035;&#21516;&#36136;APNS&#29366;&#24577;&#65292;&#25429;&#33719;&#36825;&#20123;&#29366;&#24577;&#20043;&#38388;&#30340;&#21160;&#24577;&#36716;&#25442;&#65292;&#24182;&#25581;&#31034;&#19982;&#36825;&#20123;&#36716;&#25442;&#30456;&#20851;&#30340;&#39118;&#38505;&#22240;&#32032;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#26377;&#28508;&#21147;&#25552;&#20379;&#26356;&#23458;&#35266;&#21644;&#20840;&#38754;&#30340;&#29702;&#35299;APNS&#28508;&#22312;&#31070;&#32463;&#24418;&#25104;&#26426;&#21046;&#65292;&#24182;&#20026;&#21019;&#20260;&#24184;&#23384;&#32773;&#30340;&#26377;&#38024;&#23545;&#24615;&#30340;&#24178;&#39044;&#30340;&#24320;&#21457;&#25552;&#20379;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adverse posttraumatic neuropsychiatric sequelae (APNS) are common among veterans and millions of Americans after traumatic exposures, resulting in substantial burdens for trauma survivors and society. Despite numerous studies conducted on APNS over the past decades, there has been limited progress in understanding the underlying neurobiological mechanisms due to several unique challenges. One of these challenges is the reliance on subjective self-report measures to assess APNS, which can easily result in measurement errors and biases (e.g., recall bias). To mitigate this issue, in this paper, we investigate the potential of leveraging the objective longitudinal mobile device data to identify homogeneous APNS states and study the dynamic transitions and potential risk factors of APNS after trauma exposure. To handle specific challenges posed by longitudinal mobile device data, we developed exploratory hidden Markov factor models and designed a Stabilized Expectation-Maximization algorit
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;Eigenlearning&#26694;&#26550;&#65292;&#36890;&#36807;&#38480;&#21046;&#26680;&#22238;&#24402;&#22312;&#23398;&#20064;&#27491;&#20132;&#22522;&#20989;&#25968;&#26041;&#38754;&#30340;&#33021;&#21147;&#24182;&#21033;&#29992;&#23432;&#24658;&#23450;&#24459;&#26469;&#35299;&#37322;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#21516;&#26102;&#36824;&#20026;Nakkiran&#31561;&#20154;&#30340;&#8220;&#28145;&#24230;&#24341;&#23548;&#8221;&#29616;&#35937;&#65292;&#32463;&#20856;&#22855;&#20598;&#38382;&#39064;&#38590;&#24230;&#21644;&#23545;&#25239;&#40065;&#26834;&#24615;&#25552;&#20379;&#20102;&#29702;&#35770;&#25903;&#25345;&#65292;&#24182;&#19982;&#32479;&#35745;&#29289;&#29702;&#23398;&#20013;&#30340;&#19968;&#20010;&#31995;&#32479;&#36827;&#34892;&#20102;&#31867;&#27604;&#12290;</title><link>http://arxiv.org/abs/2110.03922</link><description>&lt;p&gt;
Eigenlearning&#26694;&#26550;&#65306;&#26680;&#22238;&#24402;&#21644;&#23485;&#31070;&#32463;&#32593;&#32476;&#30340;&#23432;&#24658;&#23450;&#24459;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
The Eigenlearning Framework: A Conservation Law Perspective on Kernel Regression and Wide Neural Networks. (arXiv:2110.03922v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.03922
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;Eigenlearning&#26694;&#26550;&#65292;&#36890;&#36807;&#38480;&#21046;&#26680;&#22238;&#24402;&#22312;&#23398;&#20064;&#27491;&#20132;&#22522;&#20989;&#25968;&#26041;&#38754;&#30340;&#33021;&#21147;&#24182;&#21033;&#29992;&#23432;&#24658;&#23450;&#24459;&#26469;&#35299;&#37322;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#21516;&#26102;&#36824;&#20026;Nakkiran&#31561;&#20154;&#30340;&#8220;&#28145;&#24230;&#24341;&#23548;&#8221;&#29616;&#35937;&#65292;&#32463;&#20856;&#22855;&#20598;&#38382;&#39064;&#38590;&#24230;&#21644;&#23545;&#25239;&#40065;&#26834;&#24615;&#25552;&#20379;&#20102;&#29702;&#35770;&#25903;&#25345;&#65292;&#24182;&#19982;&#32479;&#35745;&#29289;&#29702;&#23398;&#20013;&#30340;&#19968;&#20010;&#31995;&#32479;&#36827;&#34892;&#20102;&#31867;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#38024;&#23545;&#26680;&#23725;&#22238;&#24402;&#65288;KRR&#65289;&#30340;&#27979;&#35797;&#39118;&#38505;&#21644;&#20854;&#20182;&#27867;&#21270;&#25351;&#26631;&#23548;&#20986;&#20102;&#31616;&#21333;&#30340;&#38381;&#24335;&#20272;&#35745;&#12290;&#30456;&#23545;&#20110;&#20197;&#21069;&#30340;&#24037;&#20316;&#65292;&#25105;&#20204;&#30340;&#25512;&#23548;&#22823;&#22823;&#31616;&#21270;&#65292;&#26368;&#32456;&#34920;&#36798;&#24335;&#26356;&#26131;&#20110;&#35299;&#37322;&#12290;&#36825;&#20123;&#25913;&#36827;&#24471;&#30410;&#20110;&#25105;&#20204;&#35782;&#21035;&#20986;&#30340;&#19968;&#20010;&#23574;&#38160;&#30340;&#23432;&#24658;&#23450;&#24459;&#65292;&#23427;&#38480;&#21046;&#20102;KRR&#23398;&#20064;&#20219;&#20309;&#27491;&#20132;&#22522;&#20989;&#25968;&#30340;&#33021;&#21147;&#12290;&#27979;&#35797;&#39118;&#38505;&#21644;&#20854;&#20182;&#24863;&#20852;&#36259;&#30340;&#23545;&#35937;&#21487;&#20197;&#36879;&#26126;&#22320;&#29992;&#20110;&#25105;&#20204;&#22312;&#26680;&#29305;&#24449;&#22522;&#20013;&#35780;&#20272;&#30340;&#23432;&#24658;&#37327;&#26469;&#34920;&#31034;&#12290;&#25105;&#20204;&#20351;&#29992;&#25913;&#36827;&#30340;&#26694;&#26550;&#26469;&#65306;i&#65289;&#20026;Nakkiran&#31561;&#20154;&#65288;2020&#65289;&#30340;&#8220;&#28145;&#24230;&#24341;&#23548;&#8221;&#25552;&#20379;&#29702;&#35770;&#35299;&#37322;&#65292;ii&#65289;&#25512;&#24191;&#20808;&#21069;&#20851;&#20110;&#32463;&#20856;&#22855;&#20598;&#38382;&#39064;&#38590;&#24230;&#30340;&#32467;&#26524;&#65292;iii&#65289;&#20026;&#23545;&#25239;&#40065;&#26834;&#24615;&#30340;&#30740;&#31350;&#25552;&#20379;&#29702;&#35770;&#24037;&#20855;&#65292;&#24182;iv&#65289;&#22312;&#32479;&#35745;&#29289;&#29702;&#23398;&#20013;&#30740;&#31350;&#26680;&#23725;&#22238;&#24402;&#21644;&#29087;&#30693;&#31995;&#32479;&#20043;&#38388;&#30340;&#20005;&#23494;&#31867;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
We derive simple closed-form estimates for the test risk and other generalization metrics of kernel ridge regression (KRR). Relative to prior work, our derivations are greatly simplified and our final expressions are more readily interpreted. These improvements are enabled by our identification of a sharp conservation law which limits the ability of KRR to learn any orthonormal basis of functions. Test risk and other objects of interest are expressed transparently in terms of our conserved quantity evaluated in the kernel eigenbasis. We use our improved framework to: i) provide a theoretical explanation for the "deep bootstrap" of Nakkiran et al (2020), ii) generalize a previous result regarding the hardness of the classic parity problem, iii) fashion a theoretical tool for the study of adversarial robustness, and iv) draw a tight analogy between KRR and a well-studied system in statistical physics.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;Sinkhorn&#36317;&#31163;&#36827;&#34892;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65292;&#25512;&#23548;&#20986;&#26356;&#23481;&#26131;&#22788;&#29702;&#19988;&#22312;&#23454;&#38469;&#20013;&#26356;&#21512;&#29702;&#30340;&#26368;&#22351;&#24773;&#20917;&#20998;&#24067;&#65292;&#25552;&#20986;&#20102;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2109.11926</link><description>&lt;p&gt;
Sinkhorn&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Sinkhorn Distributionally Robust Optimization. (arXiv:2109.11926v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.11926
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;Sinkhorn&#36317;&#31163;&#36827;&#34892;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65292;&#25512;&#23548;&#20986;&#26356;&#23481;&#26131;&#22788;&#29702;&#19988;&#22312;&#23454;&#38469;&#20013;&#26356;&#21512;&#29702;&#30340;&#26368;&#22351;&#24773;&#20917;&#20998;&#24067;&#65292;&#25552;&#20986;&#20102;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;Sinkhorn&#36317;&#31163; -&#19968;&#31181;&#22522;&#20110;&#29109;&#27491;&#21017;&#21270;&#30340;Wasserstein&#36317;&#31163;&#21464;&#20307;- &#30340;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;DRO&#65289;&#12290;&#25105;&#20204;&#20026;&#19968;&#33324;&#21517;&#20041;&#20998;&#24067;&#25512;&#23548;&#20102;&#20984;&#35268;&#21010;&#23545;&#20598;&#37325;&#26500;&#12290;&#30456;&#27604;&#20110;Wasserstein DRO&#65292;&#23545;&#20110;&#26356;&#22823;&#31867;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#23427;&#22312;&#35745;&#31639;&#19978;&#26356;&#23481;&#26131;&#22788;&#29702;&#65292;&#23427;&#30340;&#26368;&#22351;&#24773;&#20917;&#20998;&#24067;&#23545;&#23454;&#38469;&#24212;&#29992;&#26356;&#21512;&#29702;&#12290;&#20026;&#20102;&#35299;&#20915;&#23545;&#20598;&#37325;&#26500;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#20351;&#29992;&#26377;&#20559;&#26799;&#24230;&#31070;&#32463;&#20803;&#30340;&#38543;&#26426;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#20854;&#25910;&#25947;&#36895;&#24230;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20351;&#29992;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#30340;&#25968;&#20540;&#23454;&#20363;&#65292;&#20197;&#35777;&#26126;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study distributionally robust optimization (DRO) with Sinkhorn distance -a variant of Wasserstein distance based on entropic regularization. We derive convex programming dual reformulation for a general nominal distribution. Compared with Wasserstein DRO, it is computationally tractable for a larger class of loss functions, and its worst-case distribution is more reasonable for practical applications. To solve the dual reformulation, we develop a stochastic mirror descent algorithm using biased gradient oracles and analyze its convergence rate. Finally, we provide numerical examples using synthetic and real data to demonstrate its superior performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#20132;&#20114;&#24335;&#31070;&#32463;&#36807;&#31243;(INP)&#30340;&#28145;&#24230;&#36125;&#21494;&#26031;&#20027;&#21160;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#23398;&#20064;&#28145;&#24230;&#20195;&#29702;&#27169;&#22411;&#20197;&#21152;&#36895;&#38543;&#26426;&#27169;&#25311;&#36807;&#31243;&#65292;&#20854;&#20013;&#36890;&#36807;&#20351;&#29992;&#31354;&#38388;&#26102;&#38388;&#31070;&#32463;&#36807;&#31243;(STNP)&#23454;&#29616;&#27169;&#25311;&#22120;&#21160;&#24577;&#30340;&#27169;&#25311;&#65292;&#20197;&#21450;&#21033;&#29992;&#28508;&#22312;&#20449;&#24687;&#22686;&#30410;(LIG)&#30340;&#20027;&#21160;&#23398;&#20064;&#26041;&#24335;&#26469;&#20943;&#23569;&#26679;&#26412;&#30340;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2106.02770</link><description>&lt;p&gt;
&#28145;&#24230;&#36125;&#21494;&#26031;&#20027;&#21160;&#23398;&#20064;&#29992;&#20110;&#21152;&#36895;&#38543;&#26426;&#27169;&#25311;
&lt;/p&gt;
&lt;p&gt;
Deep Bayesian Active Learning for Accelerating Stochastic Simulation. (arXiv:2106.02770v7 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.02770
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#20132;&#20114;&#24335;&#31070;&#32463;&#36807;&#31243;(INP)&#30340;&#28145;&#24230;&#36125;&#21494;&#26031;&#20027;&#21160;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#23398;&#20064;&#28145;&#24230;&#20195;&#29702;&#27169;&#22411;&#20197;&#21152;&#36895;&#38543;&#26426;&#27169;&#25311;&#36807;&#31243;&#65292;&#20854;&#20013;&#36890;&#36807;&#20351;&#29992;&#31354;&#38388;&#26102;&#38388;&#31070;&#32463;&#36807;&#31243;(STNP)&#23454;&#29616;&#27169;&#25311;&#22120;&#21160;&#24577;&#30340;&#27169;&#25311;&#65292;&#20197;&#21450;&#21033;&#29992;&#28508;&#22312;&#20449;&#24687;&#22686;&#30410;(LIG)&#30340;&#20027;&#21160;&#23398;&#20064;&#26041;&#24335;&#26469;&#20943;&#23569;&#26679;&#26412;&#30340;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#23454;&#29616;&#31934;&#32454;&#31890;&#24230;&#19979;&#30340;&#22823;&#35268;&#27169;&#31354;&#38388;&#26102;&#38388;&#24180;&#40836;&#32467;&#26500;&#27969;&#34892;&#30149;&#27169;&#22411;&#31561;&#38543;&#26426;&#27169;&#25311;&#26041;&#27861;&#30340;&#39640;&#35745;&#31639;&#20195;&#20215;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#20132;&#20114;&#24335;&#31070;&#32463;&#36807;&#31243;(INP)&#30340;&#28145;&#24230;&#36125;&#21494;&#26031;&#20027;&#21160;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#23398;&#20064;&#28145;&#24230;&#20195;&#29702;&#27169;&#22411;&#20197;&#21152;&#36895;&#38543;&#26426;&#27169;&#25311;&#36807;&#31243;&#12290;&#35813;&#26694;&#26550;&#30001;&#20004;&#20010;&#37096;&#20998;&#32452;&#25104;&#65292;&#21363;&#24314;&#31435;&#22312;&#31070;&#32463;&#36807;&#31243;(NP)&#23478;&#26063;&#22522;&#30784;&#20043;&#19978;&#30340;&#31354;&#38388;&#26102;&#38388;&#20195;&#29702;&#27169;&#22411;&#21644;&#19968;&#20010;&#29992;&#20110;&#20027;&#21160;&#23398;&#20064;&#30340;&#25910;&#36141;&#20989;&#25968;&#12290;&#20854;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31354;&#38388;&#26102;&#38388;&#31070;&#32463;&#36807;&#31243;(STNP)&#26469;&#27169;&#25311;&#27169;&#25311;&#22120;&#21160;&#24577;&#65292;&#21516;&#26102;&#22312;NP&#27169;&#22411;&#30340;&#28508;&#31354;&#38388;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25910;&#33719;&#20989;&#25968;&#8212;&#8212;&#28508;&#22312;&#20449;&#24687;&#22686;&#30410;(LIG)&#12290;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#36341;&#35777;&#26126;&#65292;LIG&#30456;&#23545;&#20110;&#39640;&#32500;&#38543;&#26426;&#25277;&#26679;&#21487;&#20197;&#38477;&#20302;&#27169;&#25311;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic simulations such as large-scale, spatiotemporal, age-structured epidemic models are computationally expensive at fine-grained resolution. While deep surrogate models can speed up the simulations, doing so for stochastic simulations and with active learning approaches is an underexplored area. We propose Interactive Neural Process (INP), a deep Bayesian active learning framework for learning deep surrogate models to accelerate stochastic simulations. INP consists of two components, a spatiotemporal surrogate model built upon Neural Process (NP) family and an acquisition function for active learning. For surrogate modeling, we develop Spatiotemporal Neural Process (STNP) to mimic the simulator dynamics. For active learning, we propose a novel acquisition function, Latent Information Gain (LIG), calculated in the latent space of NP based models. We perform a theoretical analysis and demonstrate that LIG reduces sample complexity compared with random sampling in high dimensions.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#24067;&#24335;&#33258;&#36866;&#24212;NN&#20998;&#31867;&#22120;&#65292;&#36890;&#36807;&#38543;&#26426;&#36873;&#25321;&#25968;&#25454;&#39537;&#21160;&#20934;&#21017;&#26469;&#35843;&#20248;&#26368;&#36817;&#37051;&#25968;&#65292;&#25552;&#20986;&#20102;&#26089;&#26399;&#20572;&#27490;&#35268;&#21017;&#65292;&#23454;&#29616;&#20102;&#21152;&#36895;&#35745;&#31639;&#21644;&#25913;&#21892;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#12290;&#36890;&#36807;&#30740;&#31350;&#35777;&#26126;&#65292;&#24403;&#23376;&#26679;&#26412;&#22823;&#23567;&#36275;&#22815;&#22823;&#26102;&#65292;&#20998;&#31867;&#22120;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#26377;&#25928;&#24615;&#24050;&#36890;&#36807;&#27169;&#25311;&#21644;&#23454;&#35777;&#24212;&#29992;&#24471;&#21040;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2105.09788</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#33258;&#36866;&#24212;&#26368;&#36817;&#37051;&#20998;&#31867;&#22120;&#65306;&#31639;&#27861;&#21644;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Distributed Adaptive Nearest Neighbor Classifier: Algorithm and Theory. (arXiv:2105.09788v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.09788
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#24067;&#24335;&#33258;&#36866;&#24212;NN&#20998;&#31867;&#22120;&#65292;&#36890;&#36807;&#38543;&#26426;&#36873;&#25321;&#25968;&#25454;&#39537;&#21160;&#20934;&#21017;&#26469;&#35843;&#20248;&#26368;&#36817;&#37051;&#25968;&#65292;&#25552;&#20986;&#20102;&#26089;&#26399;&#20572;&#27490;&#35268;&#21017;&#65292;&#23454;&#29616;&#20102;&#21152;&#36895;&#35745;&#31639;&#21644;&#25913;&#21892;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#12290;&#36890;&#36807;&#30740;&#31350;&#35777;&#26126;&#65292;&#24403;&#23376;&#26679;&#26412;&#22823;&#23567;&#36275;&#22815;&#22823;&#26102;&#65292;&#20998;&#31867;&#22120;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#26377;&#25928;&#24615;&#24050;&#36890;&#36807;&#27169;&#25311;&#21644;&#23454;&#35777;&#24212;&#29992;&#24471;&#21040;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#25968;&#25454;&#35268;&#27169;&#24322;&#24120;&#24222;&#22823;&#25110;&#20998;&#24067;&#22312;&#19981;&#21516;&#30340;&#20301;&#32622;&#19978;&#26102;&#65292;&#20998;&#24067;&#24335;&#26368;&#36817;&#37051;&#65288;NN&#65289;&#20998;&#31867;&#22120;&#26159;&#19968;&#31181;&#21560;&#24341;&#20154;&#30340;&#20998;&#31867;&#24037;&#20855;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#24067;&#24335;&#33258;&#36866;&#24212;NN&#20998;&#31867;&#22120;&#65292;&#20854;&#20013;&#26368;&#36817;&#37051;&#25968;&#26159;&#30001;&#25968;&#25454;&#39537;&#21160;&#20934;&#21017;&#38543;&#26426;&#36873;&#25321;&#30340;&#35843;&#20248;&#21442;&#25968;&#12290;&#22312;&#23547;&#25214;&#26368;&#20248;&#35843;&#20248;&#21442;&#25968;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#26089;&#26399;&#20572;&#27490;&#35268;&#21017;&#65292;&#36825;&#19981;&#20165;&#21152;&#24555;&#20102;&#35745;&#31639;&#36895;&#24230;&#65292;&#36824;&#25913;&#21892;&#20102;&#25152;&#25552;&#31639;&#27861;&#30340;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#12290;&#22312;&#21508;&#31181;&#23376;&#26679;&#26412;&#22823;&#23567;&#32452;&#21512;&#19979;&#65292;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#33258;&#36866;&#24212;NN&#20998;&#31867;&#22120;&#30340;&#36229;&#39069;&#39118;&#38505;&#25910;&#25947;&#36895;&#24230;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#23376;&#26679;&#26412;&#22823;&#23567;&#36275;&#22815;&#22823;&#26102;&#65292;&#25152;&#25552;&#20998;&#31867;&#22120;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#21644;&#23545;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#30340;&#23454;&#35777;&#24212;&#29992;&#65292;&#35777;&#26126;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
When data is of an extraordinarily large size or physically stored in different locations, the distributed nearest neighbor (NN) classifier is an attractive tool for classification. We propose a novel distributed adaptive NN classifier for which the number of nearest neighbors is a tuning parameter stochastically chosen by a data-driven criterion. An early stopping rule is proposed when searching for the optimal tuning parameter, which not only speeds up the computation but also improves the finite sample performance of the proposed Algorithm. Convergence rate of excess risk of the distributed adaptive NN classifier is investigated under various sub-sample size compositions. In particular, we show that when the sub-sample sizes are sufficiently large, the proposed classifier achieves the nearly optimal convergence rate. Effectiveness of the proposed approach is demonstrated through simulation studies as well as an empirical application to a real-world dataset.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#35745;&#31639;&#39640;&#26031;&#36807;&#31243;&#22810;&#25240;&#20132;&#21449;&#39564;&#35777;&#27531;&#24046;&#21450;&#20854;&#21327;&#26041;&#24046;&#30340;&#26041;&#27861;&#65292;&#22312;&#27169;&#22411;&#35786;&#26029;&#21644;&#27604;&#20363;&#23610;&#21442;&#25968;&#20272;&#35745;&#26041;&#38754;&#26377;&#19968;&#23450;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2101.03108</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#22810;&#25240;&#20132;&#21449;&#39564;&#35777;&#27531;&#24046;&#21450;&#20854;&#21327;&#26041;&#24046;&#30340;&#24555;&#36895;&#35745;&#31639;
&lt;/p&gt;
&lt;p&gt;
Fast calculation of Gaussian Process multiple-fold cross-validation residuals and their covariances. (arXiv:2101.03108v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2101.03108
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#35745;&#31639;&#39640;&#26031;&#36807;&#31243;&#22810;&#25240;&#20132;&#21449;&#39564;&#35777;&#27531;&#24046;&#21450;&#20854;&#21327;&#26041;&#24046;&#30340;&#26041;&#27861;&#65292;&#22312;&#27169;&#22411;&#35786;&#26029;&#21644;&#27604;&#20363;&#23610;&#21442;&#25968;&#20272;&#35745;&#26041;&#38754;&#26377;&#19968;&#23450;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;&#24555;&#36895;&#39640;&#26031;&#36807;&#31243;&#30041;&#19968;&#27861;&#21017;&#25512;&#24191;&#21040;&#22810;&#25240;&#20132;&#21449;&#39564;&#35777;&#65292;&#37325;&#28857;&#20171;&#32461;&#20102;&#31616;&#21333;&#21644;&#36890;&#29992;Kriging&#26694;&#26550;&#19979;&#20132;&#21449;&#39564;&#35777;&#27531;&#24046;&#30340;&#21327;&#26041;&#24046;&#32467;&#26500;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#32467;&#26524;&#21327;&#26041;&#24046;&#22914;&#20309;&#24433;&#21709;&#27169;&#22411;&#35786;&#26029;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#22312;&#26080;&#22122;&#22768;&#35266;&#27979;&#20540;&#30340;&#24773;&#20917;&#19979;&#35777;&#26126;&#65292;&#22312;&#20132;&#21449;&#39564;&#35777;&#20272;&#35745;&#27604;&#20363;&#23610;&#21442;&#25968;&#26102;&#65292;&#32416;&#27491;&#27531;&#24046;&#20043;&#38388;&#30340;&#21327;&#26041;&#24046;&#21487;&#23548;&#22238;MLE&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20063;&#24378;&#35843;&#20102;&#22312;&#26356;&#24191;&#27867;&#30340;&#24773;&#20917;&#19979;&#65292;&#20266;&#20284;&#28982;&#21644;&#20284;&#28982;&#26041;&#27861;&#20043;&#38388;&#30340;&#24046;&#24322;&#24402;&#32467;&#20026;&#26159;&#21542;&#32771;&#34385;&#27531;&#24046;&#21327;&#26041;&#24046;&#12290;&#25152;&#25552;&#35758;&#30340;&#24555;&#36895;&#35745;&#31639;&#20132;&#21449;&#39564;&#35777;&#27531;&#24046;&#24050;&#24471;&#21040;&#23454;&#29616;&#21644;&#22522;&#20934;&#27979;&#35797;&#65292;&#25968;&#20540;&#23454;&#39564;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#25152;&#20855;&#26377;&#30340;&#31934;&#24230;&#21644;&#23454;&#29616;&#22823;&#24133;&#25552;&#36895;&#30340;&#20248;&#21183;&#12290;&#28982;&#32780;&#65292;&#26681;&#25454;&#35745;&#31639;&#25104;&#26412;&#20027;&#35201;&#39537;&#21160;&#22240;&#32032;&#30340;&#35752;&#35770;&#21644;&#25968;&#23383;&#22522;&#20934;&#27979;&#35797;&#30340;&#25903;&#25345;&#65292;&#25105;&#20204;&#21457;&#29616;&#38543;&#30528;&#25240;&#25968;&#30340;&#22686;&#21152;&#65292;&#36895;&#24230;&#25552;&#21319;&#39588;&#20943;&#12290;
&lt;/p&gt;
&lt;p&gt;
We generalize fast Gaussian process leave-one-out formulae to multiple-fold cross-validation, highlighting in turn the covariance structure of cross-validation residuals in both Simple and Universal Kriging frameworks. We illustrate how resulting covariances affect model diagnostics. We further establish in the case of noiseless observations that correcting for covariances between residuals in cross-validation-based estimation of the scale parameter leads back to MLE. Also, we highlight in broader settings how differences between pseudo-likelihood and likelihood methods boil down to accounting or not for residual covariances. The proposed fast calculation of cross-validation residuals is implemented and benchmarked against a naive implementation. Numerical experiments highlight the accuracy and substantial speed-ups that our approach enables. However, as supported by a discussion on main drivers of computational costs and by a numerical benchmark, speed-ups steeply decline as the numbe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#27010;&#29575;&#20998;&#37197;&#33719;&#24471;&#32452;&#25104;&#21592;&#36523;&#20221;&#30340;&#19981;&#23436;&#32654;&#30693;&#35782;&#30340;&#20844;&#24179;&#32858;&#31867;&#31639;&#27861;&#65292;&#24182;&#22312;&#36825;&#31181;&#26356;&#19968;&#33324;&#30340;&#35774;&#32622;&#20013;&#32473;&#20986;&#20102;&#36924;&#36817;&#27604;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2006.10916</link><description>&lt;p&gt;
&#27010;&#29575;&#20844;&#24179;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Fair Clustering. (arXiv:2006.10916v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.10916
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#27010;&#29575;&#20998;&#37197;&#33719;&#24471;&#32452;&#25104;&#21592;&#36523;&#20221;&#30340;&#19981;&#23436;&#32654;&#30693;&#35782;&#30340;&#20844;&#24179;&#32858;&#31867;&#31639;&#27861;&#65292;&#24182;&#22312;&#36825;&#31181;&#26356;&#19968;&#33324;&#30340;&#35774;&#32622;&#20013;&#32473;&#20986;&#20102;&#36924;&#36817;&#27604;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32858;&#31867;&#38382;&#39064;&#20013;&#65292;&#19968;&#20010;&#20013;&#22830;&#20915;&#31574;&#32773;&#34987;&#36171;&#20104;&#20102;&#19968;&#20010;&#39030;&#28857;&#30340;&#23436;&#25972;&#24230;&#37327;&#22270;&#65292;&#24182;&#19988;&#24517;&#39035;&#25552;&#20379;&#39030;&#28857;&#30340;&#32858;&#31867;&#65292;&#20197;&#26368;&#23567;&#21270;&#26576;&#20123;&#23458;&#35266;&#20989;&#25968;&#12290;&#22312;&#20844;&#24179;&#32858;&#31867;&#38382;&#39064;&#20013;&#65292;&#39030;&#28857;&#34987;&#36171;&#20104;&#20102;&#39068;&#33394;&#65288;&#20363;&#22914;&#65292;&#23646;&#20110;&#19968;&#20010;&#32452;&#30340;&#25104;&#21592;&#36164;&#26684;&#65289;&#65292;&#26377;&#25928;&#32858;&#31867;&#30340;&#29305;&#24449;&#20063;&#21487;&#33021;&#21253;&#25324;&#39068;&#33394;&#22312;&#35813;&#32858;&#31867;&#20013;&#30340;&#34920;&#31034;&#12290;&#20043;&#21069;&#30340;&#20844;&#24179;&#32858;&#31867;&#24037;&#20316;&#20551;&#35774;&#23436;&#20840;&#30693;&#36947;&#32452;&#25104;&#21592;&#36523;&#20221;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#20551;&#35774;&#36890;&#36807;&#27010;&#29575;&#20998;&#37197;&#26469;&#33719;&#24471;&#32452;&#25104;&#21592;&#36523;&#20221;&#30340;&#19981;&#23436;&#32654;&#30693;&#35782;&#65292;&#23545;&#20197;&#21069;&#30340;&#24037;&#20316;&#36827;&#34892;&#20102;&#25512;&#24191;&#12290;&#25105;&#20204;&#22312;&#36825;&#31181;&#26356;&#19968;&#33324;&#30340;&#35774;&#32622;&#20013;&#25552;&#20986;&#20102;&#32858;&#31867;&#31639;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#36924;&#36817;&#27604;&#25285;&#20445;&#12290;&#25105;&#20204;&#36824;&#35299;&#20915;&#20102;&#8220;&#24230;&#37327;&#25104;&#21592;&#36523;&#20221;&#8221;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#19981;&#21516;&#30340;&#32452;&#20855;&#26377;&#39034;&#24207;&#21644;&#36317;&#31163;&#30340;&#27010;&#24565;&#12290;&#20351;&#29992;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#20197;&#21450;&#22522;&#32447;&#36827;&#34892;&#23454;&#39564;&#65292;&#20197;&#39564;&#35777;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#19981;&#30830;&#23450;&#22320;&#30693;&#36947;&#32452;&#25104;&#21592;&#36523;&#20221;&#26102;&#25581;&#31034;&#24494;&#22937;&#30340;&#25285;&#24551;&#12290;
&lt;/p&gt;
&lt;p&gt;
In clustering problems, a central decision-maker is given a complete metric graph over vertices and must provide a clustering of vertices that minimizes some objective function. In fair clustering problems, vertices are endowed with a color (e.g., membership in a group), and the features of a valid clustering might also include the representation of colors in that clustering. Prior work in fair clustering assumes complete knowledge of group membership. In this paper, we generalize prior work by assuming imperfect knowledge of group membership through probabilistic assignments. We present clustering algorithms in this more general setting with approximation ratio guarantees. We also address the problem of "metric membership", where different groups have a notion of order and distance. Experiments are conducted using our proposed algorithms as well as baselines to validate our approach and also surface nuanced concerns when group membership is not known deterministically.
&lt;/p&gt;</description></item><item><title>PReNet&#26159;&#19968;&#31181;&#28145;&#24230;&#24369;&#30417;&#30563;&#26041;&#27861;&#65292;&#21487;&#20197;&#26816;&#27979;&#26082;&#26377;&#24050;&#30693;&#21448;&#26377;&#26410;&#30693;&#30340;&#24322;&#24120;&#24773;&#20917;&#65292;&#36890;&#36807;&#23398;&#20064;&#25104;&#23545;&#30340;&#20851;&#31995;&#29305;&#24449;&#21644;&#24322;&#24120;&#20998;&#25968;&#65292;&#23454;&#29616;&#20102;&#24322;&#24120;-&#24322;&#24120;&#12289;&#24322;&#24120;-&#27491;&#24120;&#21644;&#27491;&#24120;-&#27491;&#24120;&#30340;&#32852;&#21512;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/1910.13601</link><description>&lt;p&gt;
&#28145;&#24230;&#24369;&#30417;&#30563;&#24322;&#24120;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Deep Weakly-supervised Anomaly Detection. (arXiv:1910.13601v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1910.13601
&lt;/p&gt;
&lt;p&gt;
PReNet&#26159;&#19968;&#31181;&#28145;&#24230;&#24369;&#30417;&#30563;&#26041;&#27861;&#65292;&#21487;&#20197;&#26816;&#27979;&#26082;&#26377;&#24050;&#30693;&#21448;&#26377;&#26410;&#30693;&#30340;&#24322;&#24120;&#24773;&#20917;&#65292;&#36890;&#36807;&#23398;&#20064;&#25104;&#23545;&#30340;&#20851;&#31995;&#29305;&#24449;&#21644;&#24322;&#24120;&#20998;&#25968;&#65292;&#23454;&#29616;&#20102;&#24322;&#24120;-&#24322;&#24120;&#12289;&#24322;&#24120;-&#27491;&#24120;&#21644;&#27491;&#24120;-&#27491;&#24120;&#30340;&#32852;&#21512;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#21322;&#30417;&#30563;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#20351;&#29992;&#36739;&#23569;&#30340;&#26631;&#35760;&#24322;&#24120;&#26679;&#26412;&#21644;&#22823;&#37327;&#30340;&#26410;&#26631;&#35760;&#25968;&#25454;&#65288;&#22823;&#22810;&#25968;&#20026;&#27491;&#24120;&#25968;&#25454;&#65289;&#36827;&#34892;&#35757;&#32451;&#65292;&#24050;&#32463;&#26174;&#31034;&#22312;&#19982;&#26080;&#30417;&#30563;&#26041;&#27861;&#30456;&#27604;&#21487;&#20197;&#22823;&#24133;&#25552;&#39640;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#21482;&#20250;&#20851;&#27880;&#19982;&#32473;&#23450;&#24322;&#24120;&#26679;&#26412;&#23545;&#24212;&#30340;&#24322;&#24120;&#24773;&#20917;&#65292;&#22240;&#27492;&#26080;&#27861;&#27867;&#21270;&#21040;&#19981;&#23646;&#20110;&#27492;&#31867;&#24773;&#20917;&#30340;&#26032;&#31867;&#22411;/&#31867;&#21035;&#30340;&#24322;&#24120;&#24773;&#20917;&#12290;&#20026;&#20102;&#26816;&#27979;&#26082;&#26377;&#24050;&#30693;&#21448;&#26377;&#26410;&#30693;&#30340;&#24322;&#24120;&#24773;&#20917;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28145;&#24230;&#24369;&#30417;&#30563;&#26041;&#27861;&#65292;&#31216;&#20026;Pairwise Relation Prediction Network (PReNet)&#65292;&#36890;&#36807;&#39044;&#27979;&#20219;&#24847;&#20004;&#20010;&#38543;&#26426;&#25277;&#21462;&#30340;&#35757;&#32451;&#23454;&#20363;&#20043;&#38388;&#30340;&#20851;&#31995;&#26469;&#23398;&#20064;&#25104;&#23545;&#30340;&#20851;&#31995;&#29305;&#24449;&#21644;&#24322;&#24120;&#20998;&#25968;&#65292;&#20854;&#20013;&#25104;&#23545;&#30340;&#20851;&#31995;&#21487;&#20197;&#26159;&#24322;&#24120;-&#24322;&#24120;&#65292;&#24322;&#24120;-&#26410;&#26631;&#35760;&#25110;&#26410;&#26631;&#35760;-&#26410;&#26631;&#35760;&#12290;&#30001;&#20110;&#26410;&#26631;&#35760;&#30340;&#23454;&#20363;&#22823;&#22810;&#26159;&#27491;&#24120;&#30340;&#65292;&#36825;&#31181;&#20851;&#31995;&#39044;&#27979;&#24378;&#21046;&#36827;&#34892;&#24322;&#24120;-&#24322;&#24120;&#12289;&#24322;&#24120;-&#27491;&#24120;&#21644;&#27491;&#24120;-&#27491;&#24120;&#30340;&#32852;&#21512;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent semi-supervised anomaly detection methods that are trained using small labeled anomaly examples and large unlabeled data (mostly normal data) have shown largely improved performance over unsupervised methods. However, these methods often focus on fitting abnormalities illustrated by the given anomaly examples only (i.e.,, seen anomalies), and consequently they fail to generalize to those that are not, i.e., new types/classes of anomaly unseen during training. To detect both seen and unseen anomalies, we introduce a novel deep weakly-supervised approach, namely Pairwise Relation prediction Network (PReNet), that learns pairwise relation features and anomaly scores by predicting the relation of any two randomly sampled training instances, in which the pairwise relation can be anomaly-anomaly, anomaly-unlabeled, or unlabeled-unlabeled. Since unlabeled instances are mostly normal, the relation prediction enforces a joint learning of anomaly-anomaly, anomaly-normal, and normal-normal
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#65292;&#37319;&#29992;K&#22343;&#20540;&#21644;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#31561;&#26041;&#27861;&#65292;&#39044;&#27979;&#32593;&#32422;&#36710;&#21483;&#36710;&#31995;&#32479;&#20013;&#20056;&#23458;&#34892;&#31243;&#30340;&#36215;&#28857;&#21644;&#32456;&#28857;&#65292;&#30456;&#36739;&#20110;&#29616;&#26377;&#27169;&#22411;&#65292;&#20855;&#26377;&#26356;&#39640;&#30340;&#39044;&#27979;&#20934;&#30830;&#24230;&#12290;</title><link>http://arxiv.org/abs/1910.08145</link><description>&lt;p&gt;
&#22312;&#32593;&#32422;&#36710;&#21483;&#36710;&#31995;&#32479;&#20013;&#39044;&#27979;&#20056;&#23458;&#36215;&#32456;&#28857;&#30340;&#27169;&#22411;&#25552;&#20986;
&lt;/p&gt;
&lt;p&gt;
Proposing a Model for Predicting Passenger Origin-Destination in Online Taxi-Hailing Systems. (arXiv:1910.08145v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1910.08145
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#65292;&#37319;&#29992;K&#22343;&#20540;&#21644;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#31561;&#26041;&#27861;&#65292;&#39044;&#27979;&#32593;&#32422;&#36710;&#21483;&#36710;&#31995;&#32479;&#20013;&#20056;&#23458;&#34892;&#31243;&#30340;&#36215;&#28857;&#21644;&#32456;&#28857;&#65292;&#30456;&#36739;&#20110;&#29616;&#26377;&#27169;&#22411;&#65292;&#20855;&#26377;&#26356;&#39640;&#30340;&#39044;&#27979;&#20934;&#30830;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#20056;&#23458;&#30340;&#36215;&#32456;&#28857;&#23545;&#26234;&#33021;&#20132;&#36890;&#31649;&#29702;&#20013;&#30340;&#20132;&#36890;&#35268;&#21010;&#12289;&#20132;&#36890;&#31649;&#29702;&#21644;&#35843;&#24230;&#20248;&#21270;&#26377;&#30528;&#37325;&#35201;&#30340;&#24847;&#20041;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#65292;&#29992;&#20110;&#22312;&#32473;&#23450;&#26102;&#38388;&#31383;&#21475;&#20869;&#39044;&#27979;&#34892;&#31243;&#30340;&#36215;&#28857;&#21644;&#32456;&#28857;&#12290;&#25105;&#20204;&#37319;&#29992;K&#22343;&#20540;&#32858;&#31867;&#22312;&#22235;&#32500;&#31354;&#38388;&#20013;&#36827;&#34892;&#32858;&#31867;&#65292;&#24182;&#35774;&#32622;&#20102;&#36215;&#28857;&#21644;&#32456;&#28857;&#21306;&#22495;&#30340;&#26368;&#22823;&#32858;&#31867;&#22823;&#23567;&#32422;&#26463;&#26469;&#30830;&#23450;&#26377;&#25928;&#30340;&#20986;&#34892;&#27969;&#12290;&#30001;&#20110;&#38598;&#32676;&#25968;&#37327;&#24222;&#22823;&#65292;&#25105;&#20204;&#37319;&#29992;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#38477;&#20302;&#20986;&#34892;&#38598;&#32676;&#30340;&#25968;&#37327;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23454;&#29616;&#20102;&#19968;&#31181;&#22534;&#21472;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#29992;&#20110;&#39044;&#27979;&#27599;&#20010;&#38598;&#32676;&#20013;&#30340;&#20986;&#34892;&#27425;&#25968;&#12290;&#19982;&#29616;&#26377;&#27169;&#22411;&#30340;&#32467;&#26524;&#27604;&#36739;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;1&#23567;&#26102;&#21644;30&#20998;&#38047;&#30340;&#26102;&#38388;&#31383;&#21475;&#20869;&#23454;&#29616;&#20102;5-7\%&#21644;14\%&#30340;&#36739;&#20302;&#22343;&#26041;&#32477;&#23545;&#35823;&#24046;&#65288;MAPE&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Due to the significance of transportation planning, traffic management, and dispatch optimization, predicting passenger origin-destination has emerged as a crucial requirement for intelligent transportation systems management. In this study, we present a model designed to forecast the origin and destination of travels within a specified time window. To derive meaningful travel flows, we employ K-means clustering in a four-dimensional space with a maximum cluster size constraint for origin and destination zones. Given the large number of clusters, we utilize non-negative matrix factorization to reduce the number of travel clusters. Furthermore, we implement a stacked recurrent neural network model to predict the travel count in each cluster. A comparison of our results with existing models reveals that our proposed model achieves a 5-7\% lower mean absolute percentage error (MAPE) for 1-hour time windows and a 14\% lower MAPE for 30-minute time windows.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;&#19968;&#31181;&#22522;&#20110;&#37319;&#26679;&#30340;&#31639;&#27861;&#65292;&#37096;&#20998;&#21487;&#35266;&#23519;&#21152;&#26435;&#31232;&#30095;&#37319;&#26679;&#65288;POWSS&#65289;&#65292;&#21487;&#20197;&#22312;&#20855;&#26377;&#36830;&#32493;&#35266;&#27979;&#31354;&#38388;&#30340;POMDPs&#20013;&#20934;&#30830;&#20272;&#35745;Q&#20540;&#65292;&#24182;&#36890;&#36807;&#22686;&#21152;&#35745;&#31639;&#33021;&#21147;&#26469;&#23454;&#29616;&#25509;&#36817;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/1910.04332</link><description>&lt;p&gt;
&#20855;&#26377;&#36830;&#32493;&#35266;&#27979;&#31354;&#38388;&#30340;POMDPs&#20013;&#30340;&#31232;&#30095;&#26641;&#25628;&#32034;&#26368;&#20248;&#24615;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Sparse tree search optimality guarantees in POMDPs with continuous observation spaces. (arXiv:1910.04332v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1910.04332
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;&#19968;&#31181;&#22522;&#20110;&#37319;&#26679;&#30340;&#31639;&#27861;&#65292;&#37096;&#20998;&#21487;&#35266;&#23519;&#21152;&#26435;&#31232;&#30095;&#37319;&#26679;&#65288;POWSS&#65289;&#65292;&#21487;&#20197;&#22312;&#20855;&#26377;&#36830;&#32493;&#35266;&#27979;&#31354;&#38388;&#30340;POMDPs&#20013;&#20934;&#30830;&#20272;&#35745;Q&#20540;&#65292;&#24182;&#36890;&#36807;&#22686;&#21152;&#35745;&#31639;&#33021;&#21147;&#26469;&#23454;&#29616;&#25509;&#36817;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20855;&#26377;&#36830;&#32493;&#29366;&#24577;&#21644;&#35266;&#27979;&#31354;&#38388;&#30340;&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;POMDPs&#65289;&#20855;&#26377;&#34920;&#31034;&#23454;&#38469;&#20915;&#31574;&#21644;&#25511;&#21046;&#38382;&#39064;&#30340;&#24378;&#22823;&#28789;&#27963;&#24615;&#65292;&#20294;&#35299;&#20915;&#36215;&#26469;&#38750;&#24120;&#22256;&#38590;&#12290;&#26368;&#36817;&#65292;&#20351;&#29992;&#35266;&#27979;&#26435;&#37325;&#30340;&#22312;&#32447;&#22522;&#20110;&#37319;&#26679;&#30340;&#31639;&#27861;&#22312;&#20855;&#26377;&#36830;&#32493;&#35266;&#27979;&#31354;&#38388;&#30340;&#39046;&#22495;&#20013;&#23637;&#29616;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#26377;&#25928;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#25216;&#26415;&#23578;&#26410;&#26377;&#27491;&#24335;&#30340;&#29702;&#35770;&#35777;&#26126;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#36825;&#26679;&#30340;&#35777;&#26126;&#65292;&#35777;&#26126;&#19968;&#31181;&#31616;&#21270;&#26041;&#27861;&#65292;&#37096;&#20998;&#21487;&#35266;&#23519;&#21152;&#26435;&#31232;&#30095;&#37319;&#26679;&#65288;POWSS&#65289;&#65292;&#23558;&#27491;&#30830;&#22320;&#20272;&#35745;Q&#20540;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#22686;&#21152;&#35745;&#31639;&#33021;&#21147;&#26469;&#20351;&#20854;&#25509;&#36817;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Partially observable Markov decision processes (POMDPs) with continuous state and observation spaces have powerful flexibility for representing real-world decision and control problems but are notoriously difficult to solve. Recent online sampling-based algorithms that use observation likelihood weighting have shown unprecedented effectiveness in domains with continuous observation spaces. However there has been no formal theoretical justification for this technique. This work offers such a justification, proving that a simplified algorithm, partially observable weighted sparse sampling (POWSS), will estimate Q-values accurately with high probability and can be made to perform arbitrarily near the optimal solution by increasing computational power.
&lt;/p&gt;</description></item></channel></rss>