<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;NetHack&#28216;&#25103;&#20013;&#30340;&#27169;&#20223;&#23398;&#20064;&#65292;&#21457;&#29616;&#36890;&#36807;&#25193;&#22823;&#27169;&#22411;&#21644;&#25968;&#25454;&#35268;&#27169;&#21487;&#20197;&#25913;&#36827;&#27169;&#20223;&#23398;&#20064;&#30340;&#25928;&#26524;&#65292;&#24182;&#24314;&#31435;&#20102;&#35757;&#32451;&#35745;&#31639;&#26368;&#20248;IL&#20195;&#29702;&#20154;&#30340;&#24130;&#24459;&#12290;</title><link>http://arxiv.org/abs/2307.09423</link><description>&lt;p&gt;
&#22312;NetHack&#20013;&#30340;&#27169;&#20223;&#23398;&#20064;&#30340;&#35268;&#27169;&#24459;
&lt;/p&gt;
&lt;p&gt;
Scaling Laws for Imitation Learning in NetHack. (arXiv:2307.09423v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09423
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;NetHack&#28216;&#25103;&#20013;&#30340;&#27169;&#20223;&#23398;&#20064;&#65292;&#21457;&#29616;&#36890;&#36807;&#25193;&#22823;&#27169;&#22411;&#21644;&#25968;&#25454;&#35268;&#27169;&#21487;&#20197;&#25913;&#36827;&#27169;&#20223;&#23398;&#20064;&#30340;&#25928;&#26524;&#65292;&#24182;&#24314;&#31435;&#20102;&#35757;&#32451;&#35745;&#31639;&#26368;&#20248;IL&#20195;&#29702;&#20154;&#30340;&#24130;&#24459;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#20223;&#23398;&#20064; (IL) &#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#24120;&#29992;&#30340;&#26041;&#27861;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#34429;&#28982;&#24378;&#22823;&#65292;&#20294;&#35768;&#22810;&#30740;&#31350;&#21457;&#29616;&#23427;&#24448;&#24448;&#19981;&#33021;&#23436;&#20840;&#24674;&#22797;&#20986;&#28508;&#22312;&#30340;&#19987;&#23478;&#34892;&#20026;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30740;&#31350;&#27809;&#26377;&#28145;&#20837;&#25506;&#31350;&#27169;&#22411;&#21644;&#25968;&#25454;&#35268;&#27169;&#30340;&#25193;&#22823;&#22312;&#20854;&#20013;&#30340;&#20316;&#29992;&#12290;&#21463;&#26368;&#36817;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702; (NLP) &#39046;&#22495;&#30340;&#24037;&#20316;&#30340;&#21551;&#21457;&#65292;&#22312;&#37027;&#37324;&#8220;&#25193;&#22823;&#35268;&#27169;&#8221;&#24050;&#32463;&#23548;&#33268;&#20102;&#36234;&#26469;&#36234;&#26377;&#33021;&#21147;&#30340;&#39046;&#22495;&#29305;&#23450;&#35821;&#35328;&#27169;&#22411; (LLMs)&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20180;&#32454;&#25193;&#22823;&#27169;&#22411;&#21644;&#25968;&#25454;&#35268;&#27169;&#26159;&#21542;&#21487;&#20197;&#22312;&#27169;&#20223;&#23398;&#20064;&#30340;&#35774;&#32622;&#20013;&#24102;&#26469;&#31867;&#20284;&#30340;&#25913;&#36827;&#12290;&#20026;&#20102;&#23637;&#31034;&#25105;&#20204;&#30340;&#21457;&#29616;&#65292;&#25105;&#20204;&#23558;&#37325;&#28857;&#25918;&#22312; NetHack &#28216;&#25103;&#19978;&#65292;&#36825;&#26159;&#19968;&#20010;&#20855;&#26377;&#31243;&#24207;&#29983;&#25104;&#12289;&#38543;&#26426;&#24615;&#12289;&#38271;&#26399;&#20381;&#36182;&#24615;&#21644;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#30340;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#29615;&#22659;&#12290;&#25105;&#20204;&#21457;&#29616; IL &#30340;&#25439;&#22833;&#21644;&#24179;&#22343;&#22238;&#25253;&#38543;&#30528;&#35745;&#31639;&#39044;&#31639;&#30340;&#21464;&#21270;&#32780;&#24179;&#28369;&#21464;&#21270;&#19988;&#24378;&#30456;&#20851;&#65292;&#20174;&#32780;&#22312;&#27169;&#22411;&#22823;&#23567;&#21644;&#26679;&#26412;&#25968;&#37327;&#26041;&#38754;&#20026;&#35757;&#32451;&#35745;&#31639;&#26368;&#20248;&#30340; IL &#20195;&#29702;&#20154;&#30340;&#35745;&#31639;&#39044;&#31639;&#24314;&#31435;&#20102;&#24130;&#24459;&#12290;&#25105;&#20204;&#39044;&#27979;&#24182;&#35757;&#32451;&#20102;&#20960;&#20010;&#20855;&#26377; IL &#30340;NetHack&#20195;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Imitation Learning (IL) is one of the most widely used methods in machine learning. Yet, while powerful, many works find it is often not able to fully recover the underlying expert behavior. However, none of these works deeply investigate the role of scaling up the model and data size. Inspired by recent work in Natural Language Processing (NLP) where "scaling up" has resulted in increasingly more capable LLMs, we investigate whether carefully scaling up model and data size can bring similar improvements in the imitation learning setting. To demonstrate our findings, we focus on the game of NetHack, a challenging environment featuring procedural generation, stochasticity, long-term dependencies, and partial observability. We find IL loss and mean return scale smoothly with the compute budget and are strongly correlated, resulting in power laws for training compute-optimal IL agents with respect to model size and number of samples. We forecast and train several NetHack agents with IL an
&lt;/p&gt;</description></item><item><title>&#25209;&#37327;&#39044;&#27979;&#22120;&#25552;&#20379;&#20102;&#25351;&#25968;&#32423;&#26356;&#24378;&#30340;&#27867;&#21270;&#20445;&#35777;&#65292;&#21487;&#24212;&#29992;&#20110;&#31163;&#32447;&#27979;&#35797;&#21069;&#21270;&#21512;&#29289;&#36136;&#37327;&#30340;&#39044;&#27979;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2307.09379</link><description>&lt;p&gt;
&#25209;&#37327;&#39044;&#27979;&#22120;&#22312;&#20998;&#24067;&#20869;&#20855;&#26377;&#24191;&#20041;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Batched Predictors Generalize within Distribution. (arXiv:2307.09379v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09379
&lt;/p&gt;
&lt;p&gt;
&#25209;&#37327;&#39044;&#27979;&#22120;&#25552;&#20379;&#20102;&#25351;&#25968;&#32423;&#26356;&#24378;&#30340;&#27867;&#21270;&#20445;&#35777;&#65292;&#21487;&#24212;&#29992;&#20110;&#31163;&#32447;&#27979;&#35797;&#21069;&#21270;&#21512;&#29289;&#36136;&#37327;&#30340;&#39044;&#27979;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#25209;&#37327;&#39044;&#27979;&#22120;&#30340;&#24191;&#20041;&#24615;&#36136;&#65292;&#21363;&#20219;&#21153;&#26159;&#39044;&#27979;&#19968;&#23567;&#32452;&#65288;&#25110;&#25209;&#37327;&#65289;&#31034;&#20363;&#30340;&#22343;&#20540;&#26631;&#31614;&#30340;&#27169;&#22411;&#12290;&#25209;&#37327;&#39044;&#27979;&#33539;&#24335;&#23545;&#20110;&#37096;&#32626;&#22312;&#31163;&#32447;&#27979;&#35797;&#21069;&#30830;&#23450;&#19968;&#32452;&#21270;&#21512;&#29289;&#30340;&#36136;&#37327;&#30340;&#27169;&#22411;&#23588;&#20026;&#30456;&#20851;&#12290;&#36890;&#36807;&#21033;&#29992;&#36866;&#24403;&#30340;Rademacher&#22797;&#26434;&#24615;&#30340;&#24191;&#20041;&#21270;&#65292;&#25105;&#20204;&#35777;&#26126;&#25209;&#37327;&#39044;&#27979;&#22120;&#20855;&#26377;&#25351;&#25968;&#32423;&#26356;&#24378;&#30340;&#27867;&#21270;&#20445;&#35777;&#65292;&#19982;&#26631;&#20934;&#30340;&#36880;&#20010;&#26679;&#26412;&#26041;&#27861;&#30456;&#27604;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#35813;&#25552;&#35758;&#30340;&#19978;&#30028;&#29420;&#31435;&#20110;&#36807;&#21442;&#25968;&#21270;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#27934;&#23519;&#21147;&#22312;&#21508;&#31181;&#20219;&#21153;&#12289;&#26550;&#26500;&#21644;&#24212;&#29992;&#20013;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the generalization properties of batched predictors, i.e., models tasked with predicting the mean label of a small set (or batch) of examples. The batched prediction paradigm is particularly relevant for models deployed to determine the quality of a group of compounds in preparation for offline testing. By utilizing a suitable generalization of the Rademacher complexity, we prove that batched predictors come with exponentially stronger generalization guarantees as compared to the standard per-sample approach. Surprisingly, the proposed bound holds independently of overparametrization. Our theoretical insights are validated experimentally for various tasks, architectures, and applications.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#31163;&#25955;&#20248;&#21270;&#30340;&#31232;&#30095;&#39640;&#26031;&#22270;&#27169;&#22411;&#23398;&#20064;&#38382;&#39064;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#22823;&#35268;&#27169;&#27714;&#35299;&#22120;&#26469;&#33719;&#21462;&#33391;&#22909;&#30340;&#21407;&#22987;&#35299;&#12290;</title><link>http://arxiv.org/abs/2307.09366</link><description>&lt;p&gt;
&#31232;&#30095;&#39640;&#26031;&#22270;&#27169;&#22411;&#30340;&#31163;&#25955;&#20248;&#21270;&#65306;&#35745;&#31639;&#21644;&#32479;&#35745;&#35282;&#24230;
&lt;/p&gt;
&lt;p&gt;
Sparse Gaussian Graphical Models with Discrete Optimization: Computational and Statistical Perspectives. (arXiv:2307.09366v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09366
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#31163;&#25955;&#20248;&#21270;&#30340;&#31232;&#30095;&#39640;&#26031;&#22270;&#27169;&#22411;&#23398;&#20064;&#38382;&#39064;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#22823;&#35268;&#27169;&#27714;&#35299;&#22120;&#26469;&#33719;&#21462;&#33391;&#22909;&#30340;&#21407;&#22987;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#23398;&#20064;&#22522;&#20110;&#26080;&#21521;&#39640;&#26031;&#22270;&#27169;&#22411;&#30340;&#31232;&#30095;&#22270;&#30340;&#38382;&#39064;&#65292;&#36825;&#26159;&#32479;&#35745;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#12290;&#32473;&#23450;&#26469;&#33258;&#20855;&#26377;p&#20010;&#21464;&#37327;&#30340;&#22810;&#20803;&#39640;&#26031;&#20998;&#24067;&#30340;n&#20010;&#26679;&#26412;&#65292;&#30446;&#26631;&#26159;&#20272;&#35745;p&#215;p&#30340;&#36870;&#21327;&#26041;&#24046;&#30697;&#38453;&#65288;&#20063;&#31216;&#20026;&#31934;&#24230;&#30697;&#38453;&#65289;&#65292;&#20551;&#35774;&#23427;&#26159;&#31232;&#30095;&#30340;&#65288;&#21363;&#20855;&#26377;&#23569;&#25968;&#38750;&#38646;&#26465;&#30446;&#65289;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;GraphL0BnB&#36825;&#19968;&#26032;&#30340;&#20272;&#35745;&#26041;&#27861;&#65292;&#23427;&#22522;&#20110;&#20266;&#20284;&#28982;&#20989;&#25968;&#30340;l0&#24809;&#32602;&#29256;&#26412;&#65292;&#32780;&#22823;&#22810;&#25968;&#26089;&#26399;&#26041;&#27861;&#37117;&#26159;&#22522;&#20110;l1&#26494;&#24347;&#12290;&#25105;&#20204;&#30340;&#20272;&#35745;&#26041;&#27861;&#21487;&#20197;&#34987;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#20984;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#65288;MIP&#65289;&#65292;&#20351;&#29992;&#29616;&#25104;&#30340;&#21830;&#29992;&#27714;&#35299;&#22120;&#22312;&#22823;&#35268;&#27169;&#35745;&#31639;&#26102;&#21487;&#33021;&#24456;&#38590;&#35745;&#31639;&#12290;&#20026;&#20102;&#35299;&#20915;MIP&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23450;&#21046;&#30340;&#38750;&#32447;&#24615;&#20998;&#25903;&#23450;&#30028;&#65288;BnB&#65289;&#26694;&#26550;&#65292;&#29992;&#20110;&#20351;&#29992;&#23450;&#21046;&#30340;&#19968;&#38454;&#26041;&#27861;&#26469;&#35299;&#20915;&#33410;&#28857;&#25918;&#26494;&#38382;&#39064;&#12290;&#20316;&#20026;&#25105;&#20204;BnB&#26694;&#26550;&#30340;&#21103;&#20135;&#21697;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#29992;&#20110;&#33719;&#24471;&#29420;&#31435;&#20852;&#36259;&#30340;&#33391;&#22909;&#21407;&#22987;&#35299;&#30340;&#22823;&#35268;&#27169;&#27714;&#35299;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning a sparse graph underlying an undirected Gaussian graphical model, a key problem in statistical machine learning. Given $n$ samples from a multivariate Gaussian distribution with $p$ variables, the goal is to estimate the $p \times p$ inverse covariance matrix (aka precision matrix), assuming it is sparse (i.e., has a few nonzero entries). We propose GraphL0BnB, a new estimator based on an $\ell_0$-penalized version of the pseudolikelihood function, while most earlier approaches are based on the $\ell_1$-relaxation. Our estimator can be formulated as a convex mixed integer program (MIP) which can be difficult to compute at scale using off-the-shelf commercial solvers. To solve the MIP, we propose a custom nonlinear branch-and-bound (BnB) framework that solves node relaxations with tailored first-order methods. As a by-product of our BnB framework, we propose large-scale solvers for obtaining good primal solutions that are of independent interest. We d
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#33258;&#36866;&#24212;&#20248;&#21270;&#24037;&#20855;&#30340;&#33258;&#36866;&#24212;&#37325;&#35201;&#24615;&#37319;&#26679;&#22120;&#65292;&#31216;&#20026;AdaOAIS&#12290;&#36890;&#36807;&#20351;&#29992;&#33258;&#36866;&#24212;&#20248;&#21270;&#22120;&#25913;&#21892;&#20102;&#20248;&#21270;&#33258;&#36866;&#24212;&#37325;&#35201;&#24615;&#37319;&#26679;&#22120;&#30340;&#31283;&#23450;&#24615;&#65292;&#24182;&#22312;&#23454;&#20363;&#20013;&#23637;&#31034;&#20102;&#20854;&#31283;&#23450;&#30340;&#37325;&#35201;&#24615;&#37319;&#26679;&#20272;&#35745;&#22120;&#12290;</title><link>http://arxiv.org/abs/2307.09341</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#20248;&#21270;&#30340;&#33258;&#36866;&#24212;&#37325;&#35201;&#24615;&#37319;&#26679;&#22120;
&lt;/p&gt;
&lt;p&gt;
Adaptively Optimised Adaptive Importance Samplers. (arXiv:2307.09341v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09341
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#33258;&#36866;&#24212;&#20248;&#21270;&#24037;&#20855;&#30340;&#33258;&#36866;&#24212;&#37325;&#35201;&#24615;&#37319;&#26679;&#22120;&#65292;&#31216;&#20026;AdaOAIS&#12290;&#36890;&#36807;&#20351;&#29992;&#33258;&#36866;&#24212;&#20248;&#21270;&#22120;&#25913;&#21892;&#20102;&#20248;&#21270;&#33258;&#36866;&#24212;&#37325;&#35201;&#24615;&#37319;&#26679;&#22120;&#30340;&#31283;&#23450;&#24615;&#65292;&#24182;&#22312;&#23454;&#20363;&#20013;&#23637;&#31034;&#20102;&#20854;&#31283;&#23450;&#30340;&#37325;&#35201;&#24615;&#37319;&#26679;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#36866;&#24212;&#37325;&#35201;&#24615;&#37319;&#26679;&#22120;&#31867;&#21035;&#65292;&#20511;&#21161;&#33258;&#36866;&#24212;&#20248;&#21270;&#24037;&#20855;&#65292;&#31216;&#20043;&#20026;AdaOAIS&#12290;&#25105;&#20204;&#20511;&#37492;&#20102;&#20248;&#21270;&#33258;&#36866;&#24212;&#37325;&#35201;&#24615;&#37319;&#26679;&#22120;&#65288;OAIS&#65289;&#30340;&#25216;&#26415;&#65292;&#35813;&#25216;&#26415;&#36890;&#36807;&#21442;&#25968;&#21270;&#25552;&#35758;&#24182;&#20248;&#21270;&#30446;&#26631;&#19982;&#25552;&#35758;&#20043;&#38388;&#30340;$\chi^2$-&#25955;&#24230;&#65292;&#26469;&#25913;&#21892;&#37325;&#35201;&#24615;&#37319;&#26679;&#20272;&#35745;&#37327;&#30340;&#22343;&#26041;&#35823;&#24046;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23613;&#31649;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#27861;&#20445;&#35777;&#25910;&#25947;&#65292;&#20294;OAIS&#30340;&#26420;&#32032;&#23454;&#29616;&#21487;&#33021;&#23548;&#33268;&#19981;&#31283;&#23450;&#30340;&#20272;&#35745;&#22120;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#32570;&#28857;&#65292;&#25105;&#20204;&#25552;&#20986;&#25913;&#29992;&#33258;&#36866;&#24212;&#20248;&#21270;&#22120;&#65288;&#22914;AdaGrad&#21644;Adam&#65289;&#26469;&#25552;&#39640;OAIS&#30340;&#31283;&#23450;&#24615;&#12290;&#25105;&#20204;&#20197;&#31867;&#20284;&#20110;OAIS&#30340;&#26041;&#24335;&#25552;&#20379;&#20102;AdaOAIS&#30340;&#25910;&#25947;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#22312;&#21508;&#31181;&#31034;&#20363;&#19978;&#36827;&#34892;&#20102;&#23454;&#35777;&#28436;&#31034;&#65292;&#24182;&#34920;&#26126;AdaOAIS&#22312;&#23454;&#36341;&#20013;&#21487;&#20197;&#20135;&#29983;&#31283;&#23450;&#30340;&#37325;&#35201;&#24615;&#37319;&#26679;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new class of adaptive importance samplers leveraging adaptive optimisation tools, which we term AdaOAIS. We build on Optimised Adaptive Importance Samplers (OAIS), a class of techniques that adapt proposals to improve the mean-squared error of the importance sampling estimators by parameterising the proposal and optimising the $\chi^2$-divergence between the target and the proposal. We show that a naive implementation of OAIS using stochastic gradient descent may lead to unstable estimators despite its convergence guarantees. To remedy this shortcoming, we instead propose to use adaptive optimisers (such as AdaGrad and Adam) to improve the stability of the OAIS. We provide convergence results for AdaOAIS in a similar manner to OAIS. We also provide empirical demonstration on a variety of examples and show that AdaOAIS lead to stable importance sampling estimators in practice.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#21547;&#26377;&#27169;&#31946;&#22320;&#38754;&#30495;&#30456;&#30340;&#31526;&#21512;&#39044;&#27979;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#22312;&#32570;&#20047;&#26126;&#30830;&#22320;&#38754;&#30495;&#30456;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#20302;&#20272;&#19981;&#30830;&#23450;&#24615;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.09302</link><description>&lt;p&gt;
&#21547;&#26377;&#19981;&#30830;&#23450;&#22320;&#38754;&#30495;&#30456;&#30340;&#31526;&#21512;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Conformal prediction under ambiguous ground truth. (arXiv:2307.09302v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09302
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#21547;&#26377;&#27169;&#31946;&#22320;&#38754;&#30495;&#30456;&#30340;&#31526;&#21512;&#39044;&#27979;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#22312;&#32570;&#20047;&#26126;&#30830;&#22320;&#38754;&#30495;&#30456;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#20302;&#20272;&#19981;&#30830;&#23450;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23433;&#20840;&#20851;&#38190;&#30340;&#20998;&#31867;&#20219;&#21153;&#20013;&#65292;&#31526;&#21512;&#39044;&#27979;&#21487;&#20197;&#36890;&#36807;&#25552;&#20379;&#32622;&#20449;&#21306;&#38388;&#26469;&#36827;&#34892;&#20005;&#26684;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#20854;&#20013;&#21253;&#25324;&#30495;&#27491;&#31867;&#21035;&#30340;&#29992;&#25143;&#25351;&#23450;&#30340;&#27010;&#29575;&#12290;&#36825;&#36890;&#24120;&#20551;&#35774;&#26377;&#19968;&#20010;&#29420;&#31435;&#30340;&#26657;&#20934;&#38598;&#21512;&#65292;&#24182;&#19988;&#33021;&#22815;&#35775;&#38382;&#22320;&#38754;&#30495;&#30456;&#26631;&#31614;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#22312;&#35768;&#22810;&#39046;&#22495;&#20013;&#65292;&#36825;&#20123;&#26631;&#31614;&#24456;&#38590;&#33719;&#24471;&#65292;&#24182;&#19988;&#36890;&#24120;&#36890;&#36807;&#32858;&#21512;&#19987;&#23478;&#24847;&#35265;&#26469;&#36817;&#20284;&#12290;&#20107;&#23454;&#19978;&#65292;&#36825;&#36866;&#29992;&#20110;&#20960;&#20046;&#25152;&#26377;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#30693;&#21517;&#30340;&#25968;&#25454;&#38598;&#22914;CIFAR&#21644;ImageNet&#12290;&#20351;&#29992;&#36825;&#26679;&#30340;&#26631;&#31614;&#24212;&#29992;&#31526;&#21512;&#39044;&#27979;&#20250;&#20302;&#20272;&#19981;&#30830;&#23450;&#24615;&#12290;&#20107;&#23454;&#19978;&#65292;&#24403;&#19987;&#23478;&#24847;&#35265;&#26080;&#27861;&#35299;&#20915;&#26102;&#65292;&#26631;&#31614;&#20013;&#23384;&#22312;&#22266;&#26377;&#30340;&#27169;&#31946;&#24615;&#12290;&#20063;&#23601;&#26159;&#35828;&#65292;&#25105;&#20204;&#27809;&#26377;&#8220;&#28165;&#26224;&#8221;&#12289;&#26126;&#30830;&#30340;&#22320;&#38754;&#30495;&#30456;&#26631;&#31614;&#65292;&#32780;&#22312;&#26657;&#20934;&#36807;&#31243;&#20013;&#24212;&#35813;&#32771;&#34385;&#36825;&#31181;&#19981;&#30830;&#23450;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#38024;&#23545;&#36825;&#31181;&#27169;&#31946;&#22320;&#38754;&#30495;&#30456;&#24773;&#26223;&#24320;&#21457;&#20102;&#19968;&#20010;&#31526;&#21512;&#39044;&#27979;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#20381;&#36182;&#20110;&#23545;&#28508;&#22312;&#27169;&#31946;&#24615;&#30340;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;
In safety-critical classification tasks, conformal prediction allows to perform rigorous uncertainty quantification by providing confidence sets including the true class with a user-specified probability. This generally assumes the availability of a held-out calibration set with access to ground truth labels. Unfortunately, in many domains, such labels are difficult to obtain and usually approximated by aggregating expert opinions. In fact, this holds true for almost all datasets, including well-known ones such as CIFAR and ImageNet. Applying conformal prediction using such labels underestimates uncertainty. Indeed, when expert opinions are not resolvable, there is inherent ambiguity present in the labels. That is, we do not have ``crisp'', definitive ground truth labels and this uncertainty should be taken into account during calibration. In this paper, we develop a conformal prediction framework for such ambiguous ground truth settings which relies on an approximation of the underlyi
&lt;/p&gt;</description></item><item><title>&#23884;&#22871;&#28040;&#38500;&#26159;&#19968;&#31181;&#31616;&#21333;&#26131;&#23454;&#29616;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21019;&#26032;&#30340;&#28040;&#38500;&#20934;&#21017;&#21644;&#23884;&#22871;&#32467;&#26500;&#65292;&#33021;&#22815;&#20197;&#26368;&#23569;&#30340;&#26679;&#26412;&#25968;&#37327;&#21644;&#39640;&#32622;&#20449;&#27700;&#24179;&#35782;&#21035;&#20986;&#26368;&#21463;&#27426;&#36814;&#30340;&#39033;&#30446;&#12290;</title><link>http://arxiv.org/abs/2307.09295</link><description>&lt;p&gt;
&#23884;&#22871;&#28040;&#38500;&#65306;&#19968;&#31181;&#20174;&#22522;&#20110;&#36873;&#25321;&#30340;&#21453;&#39304;&#20013;&#35782;&#21035;&#26368;&#20339;&#39033;&#30446;&#30340;&#31616;&#21333;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Nested Elimination: A Simple Algorithm for Best-Item Identification from Choice-Based Feedback. (arXiv:2307.09295v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09295
&lt;/p&gt;
&lt;p&gt;
&#23884;&#22871;&#28040;&#38500;&#26159;&#19968;&#31181;&#31616;&#21333;&#26131;&#23454;&#29616;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21019;&#26032;&#30340;&#28040;&#38500;&#20934;&#21017;&#21644;&#23884;&#22871;&#32467;&#26500;&#65292;&#33021;&#22815;&#20197;&#26368;&#23569;&#30340;&#26679;&#26412;&#25968;&#37327;&#21644;&#39640;&#32622;&#20449;&#27700;&#24179;&#35782;&#21035;&#20986;&#26368;&#21463;&#27426;&#36814;&#30340;&#39033;&#30446;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;&#36873;&#25321;&#30340;&#21453;&#39304;&#20013;&#35782;&#21035;&#26368;&#20339;&#39033;&#30446;&#30340;&#38382;&#39064;&#12290;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#20844;&#21496;&#20381;&#27425;&#21521;&#19968;&#32676;&#39038;&#23458;&#23637;&#31034;&#26174;&#31034;&#38598;&#65292;&#24182;&#25910;&#38598;&#20182;&#20204;&#30340;&#36873;&#25321;&#12290;&#30446;&#26631;&#26159;&#20197;&#26368;&#23569;&#30340;&#26679;&#26412;&#25968;&#37327;&#21644;&#39640;&#32622;&#20449;&#27700;&#24179;&#35782;&#21035;&#20986;&#26368;&#21463;&#27426;&#36814;&#30340;&#39033;&#30446;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28040;&#38500;&#30340;&#31639;&#27861;&#65292;&#21363;&#23884;&#22871;&#28040;&#38500;(Nested Elimination&#65292;NE)&#65292;&#23427;&#21463;&#21040;&#20449;&#24687;&#29702;&#35770;&#19979;&#30028;&#25152;&#26263;&#31034;&#30340;&#23884;&#22871;&#32467;&#26500;&#30340;&#21551;&#21457;&#12290;NE&#30340;&#32467;&#26500;&#31616;&#21333;&#65292;&#26131;&#20110;&#23454;&#26045;&#65292;&#20855;&#26377;&#23545;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#24378;&#22823;&#29702;&#35770;&#20445;&#35777;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;NE&#21033;&#29992;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#28040;&#38500;&#20934;&#21017;&#65292;&#24182;&#36991;&#20813;&#20102;&#35299;&#20915;&#20219;&#20309;&#22797;&#26434;&#30340;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#30340;&#38656;&#35201;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;NE&#30340;&#29305;&#23450;&#23454;&#20363;&#21644;&#38750;&#28176;&#36817;&#24615;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#19978;&#30028;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;NE&#23454;&#29616;&#20102;&#39640;&#38454;&#26368;&#22351;&#24773;&#20917;&#28176;&#36817;&#26368;&#20248;&#24615;&#12290;&#26368;&#21518;&#65292;&#26469;&#33258;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#30340;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of best-item identification from choice-based feedback. In this problem, a company sequentially and adaptively shows display sets to a population of customers and collects their choices. The objective is to identify the most preferred item with the least number of samples and at a high confidence level. We propose an elimination-based algorithm, namely Nested Elimination (NE), which is inspired by the nested structure implied by the information-theoretic lower bound. NE is simple in structure, easy to implement, and has a strong theoretical guarantee for sample complexity. Specifically, NE utilizes an innovative elimination criterion and circumvents the need to solve any complex combinatorial optimization problem. We provide an instance-specific and non-asymptotic bound on the expected sample complexity of NE. We also show NE achieves high-order worst-case asymptotic optimality. Finally, numerical experiments from both synthetic and real data corroborate our theore
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#37327;&#21270;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;PAC&#31070;&#32463;&#39044;&#27979;&#38598;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#22810;&#31181;&#35821;&#35328;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#30456;&#27604;&#20110;&#26631;&#20934;&#22522;&#20934;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24179;&#22343;&#25552;&#39640;&#20102;63&#65285;&#30340;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.09254</link><description>&lt;p&gt;
&#29992;&#20110;&#37327;&#21270;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;PAC&#31070;&#32463;&#39044;&#27979;&#38598;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
PAC Neural Prediction Set Learning to Quantify the Uncertainty of Generative Language Models. (arXiv:2307.09254v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09254
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#37327;&#21270;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;PAC&#31070;&#32463;&#39044;&#27979;&#38598;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#22810;&#31181;&#35821;&#35328;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#30456;&#27604;&#20110;&#26631;&#20934;&#22522;&#20934;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24179;&#22343;&#25552;&#39640;&#20102;63&#65285;&#30340;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#21644;&#37327;&#21270;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#26159;&#22686;&#24378;&#27169;&#22411;&#21487;&#20449;&#24230;&#30340;&#20851;&#38190;&#20219;&#21153;&#12290;&#30001;&#20110;&#23545;&#29983;&#25104;&#34394;&#26500;&#20107;&#23454;&#30340;&#25285;&#24551;&#65292;&#26368;&#36817;&#20852;&#36215;&#30340;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#65288;GLM&#65289;&#29305;&#21035;&#24378;&#35843;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#38656;&#27714;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#31070;&#32463;&#39044;&#27979;&#38598;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#20197;&#21487;&#33021;&#36817;&#20284;&#27491;&#30830;&#65288;PAC&#65289;&#30340;&#26041;&#24335;&#37327;&#21270;GLM&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#19982;&#29616;&#26377;&#30340;&#39044;&#27979;&#38598;&#27169;&#22411;&#36890;&#36807;&#26631;&#37327;&#20540;&#21442;&#25968;&#21270;&#19981;&#21516;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#39044;&#27979;&#38598;&#65292;&#23454;&#29616;&#26356;&#31934;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#20294;&#20173;&#28385;&#36275;PAC&#20445;&#35777;&#12290;&#36890;&#36807;&#22312;&#22235;&#31181;&#31867;&#22411;&#30340;&#35821;&#35328;&#25968;&#25454;&#38598;&#21644;&#20845;&#31181;&#31867;&#22411;&#30340;&#27169;&#22411;&#19978;&#23637;&#31034;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#30456;&#27604;&#26631;&#20934;&#22522;&#20934;&#26041;&#27861;&#24179;&#22343;&#25552;&#39640;&#20102;63&#65285;&#30340;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty learning and quantification of models are crucial tasks to enhance the trustworthiness of the models. Importantly, the recent surge of generative language models (GLMs) emphasizes the need for reliable uncertainty quantification due to the concerns on generating hallucinated facts. In this paper, we propose to learn neural prediction set models that comes with the probably approximately correct (PAC) guarantee for quantifying the uncertainty of GLMs. Unlike existing prediction set models, which are parameterized by a scalar value, we propose to parameterize prediction sets via neural networks, which achieves more precise uncertainty quantification but still satisfies the PAC guarantee. We demonstrate the efficacy of our method on four types of language datasets and six types of models by showing that our method improves the quantified uncertainty by $63\%$ on average, compared to a standard baseline method.
&lt;/p&gt;</description></item><item><title>&#23884;&#22871;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;NSBM&#65289;&#33021;&#22815;&#21516;&#26102;&#23545;&#32593;&#32476;&#21644;&#33410;&#28857;&#36827;&#34892;&#32858;&#31867;&#65292;&#20855;&#26377;&#22788;&#29702;&#26080;&#26631;&#31614;&#32593;&#32476;&#12289;&#24314;&#27169;&#24322;&#36136;&#31038;&#32676;&#20197;&#21450;&#33258;&#21160;&#36873;&#25321;&#32858;&#31867;&#25968;&#37327;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.09210</link><description>&lt;p&gt;
&#23884;&#22871;&#38543;&#26426;&#22359;&#27169;&#22411;&#29992;&#20110;&#21516;&#26102;&#23545;&#32593;&#32476;&#21644;&#33410;&#28857;&#36827;&#34892;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Nested stochastic block model for simultaneously clustering networks and nodes. (arXiv:2307.09210v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09210
&lt;/p&gt;
&lt;p&gt;
&#23884;&#22871;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;NSBM&#65289;&#33021;&#22815;&#21516;&#26102;&#23545;&#32593;&#32476;&#21644;&#33410;&#28857;&#36827;&#34892;&#32858;&#31867;&#65292;&#20855;&#26377;&#22788;&#29702;&#26080;&#26631;&#31614;&#32593;&#32476;&#12289;&#24314;&#27169;&#24322;&#36136;&#31038;&#32676;&#20197;&#21450;&#33258;&#21160;&#36873;&#25321;&#32858;&#31867;&#25968;&#37327;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#23884;&#22871;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;NSBM&#65289;&#65292;&#29992;&#20110;&#23545;&#19968;&#32452;&#32593;&#32476;&#36827;&#34892;&#32858;&#31867;&#65292;&#21516;&#26102;&#26816;&#27979;&#27599;&#20010;&#32593;&#32476;&#20013;&#30340;&#31038;&#32676;&#12290;NSBM&#20855;&#26377;&#20960;&#20010;&#21560;&#24341;&#20154;&#30340;&#29305;&#28857;&#65292;&#21253;&#25324;&#33021;&#22815;&#22788;&#29702;&#20855;&#26377;&#28508;&#22312;&#19981;&#21516;&#33410;&#28857;&#38598;&#30340;&#26080;&#26631;&#31614;&#32593;&#32476;&#65292;&#28789;&#27963;&#22320;&#24314;&#27169;&#24322;&#36136;&#31038;&#32676;&#65292;&#20197;&#21450;&#33258;&#21160;&#36873;&#25321;&#32593;&#32476;&#31867;&#21035;&#21644;&#27599;&#20010;&#32593;&#32476;&#20869;&#31038;&#32676;&#25968;&#37327;&#30340;&#33021;&#21147;&#12290;&#36890;&#36807;&#36125;&#21494;&#26031;&#27169;&#22411;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#24182;&#23558;&#23884;&#22871;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#65288;NDP&#65289;&#20316;&#20026;&#20808;&#39564;&#65292;&#20197;&#32852;&#21512;&#24314;&#27169;&#32593;&#32476;&#38388;&#21644;&#32593;&#32476;&#20869;&#30340;&#32858;&#31867;&#12290;&#32593;&#32476;&#25968;&#25454;&#24341;&#20837;&#30340;&#20381;&#36182;&#24615;&#32473;NDP&#24102;&#26469;&#20102;&#38750;&#24179;&#20961;&#30340;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#22312;&#24320;&#21457;&#39640;&#25928;&#30340;&#37319;&#26679;&#22120;&#26041;&#38754;&#12290;&#23545;&#20110;&#21518;&#39564;&#25512;&#26029;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#31181;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#31639;&#27861;&#65292;&#21253;&#25324;&#26631;&#20934;&#30340;Gibbs&#37319;&#26679;&#22120;&#65292;&#31616;&#21270;Gibbs&#37319;&#26679;&#22120;&#21644;&#20004;&#31181;&#29992;&#20110;&#36820;&#22238;&#20004;&#20010;&#32423;&#21035;&#32858;&#31867;&#32467;&#26524;&#30340;&#38459;&#22622;Gibbs&#37319;&#26679;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce the nested stochastic block model (NSBM) to cluster a collection of networks while simultaneously detecting communities within each network. NSBM has several appealing features including the ability to work on unlabeled networks with potentially different node sets, the flexibility to model heterogeneous communities, and the means to automatically select the number of classes for the networks and the number of communities within each network. This is accomplished via a Bayesian model, with a novel application of the nested Dirichlet process (NDP) as a prior to jointly model the between-network and within-network clusters. The dependency introduced by the network data creates nontrivial challenges for the NDP, especially in the development of efficient samplers. For posterior inference, we propose several Markov chain Monte Carlo algorithms including a standard Gibbs sampler, a collapsed Gibbs sampler, and two blocked Gibbs samplers that ultimately return two levels of clus
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#20855;&#26377;&#32467;&#26500;&#20381;&#36182;&#20851;&#31995;&#30340;&#32452;&#21512;&#21322;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#24310;&#36831;&#30340;&#21453;&#39304;&#20013;&#23398;&#20064;&#22240;&#26524;&#20851;&#31995;&#24182;&#20570;&#20986;&#20915;&#31574;&#30340;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2307.09093</link><description>&lt;p&gt;
&#38750;&#24179;&#31283;&#24310;&#36831;&#32452;&#21512;&#21322;&#24378;&#21270;&#23398;&#20064;&#22312;&#22240;&#26524;&#30456;&#20851;&#22238;&#25253;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Non-stationary Delayed Combinatorial Semi-Bandit with Causally Related Rewards. (arXiv:2307.09093v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09093
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#20855;&#26377;&#32467;&#26500;&#20381;&#36182;&#20851;&#31995;&#30340;&#32452;&#21512;&#21322;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#24310;&#36831;&#30340;&#21453;&#39304;&#20013;&#23398;&#20064;&#22240;&#26524;&#20851;&#31995;&#24182;&#20570;&#20986;&#20915;&#31574;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19981;&#30830;&#23450;&#24615;&#19979;&#30340;&#39034;&#24207;&#20915;&#31574;&#20013;&#65292;&#24120;&#24120;&#23384;&#22312;&#38271;&#26102;&#38388;&#30340;&#21453;&#39304;&#24310;&#36831;&#12290;&#36825;&#31181;&#24310;&#36831;&#20250;&#38477;&#20302;&#23398;&#20064;&#20195;&#29702;&#22312;&#38271;&#26399;&#20013;&#35782;&#21035;&#20986;&#19968;&#32452;&#20855;&#26377;&#26368;&#20248;&#24635;&#22238;&#25253;&#30340;&#33218;&#30340;&#24615;&#33021;&#12290;&#22312;&#20855;&#26377;&#32467;&#26500;&#20381;&#36182;&#30340;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#65292;&#36825;&#20010;&#38382;&#39064;&#21464;&#24471;&#26497;&#20855;&#25361;&#25112;&#24615;&#12290;&#22240;&#27492;&#65292;&#38500;&#20102;&#36866;&#24212;&#24310;&#36831;&#21644;&#29615;&#22659;&#21464;&#21270;&#22806;&#65292;&#23398;&#20064;&#22240;&#26524;&#20851;&#31995;&#21487;&#20197;&#20943;&#36731;&#21453;&#39304;&#24310;&#36831;&#23545;&#20915;&#31574;&#36807;&#31243;&#30340;&#19981;&#21033;&#24433;&#21709;&#12290;&#25105;&#20204;&#23558;&#25152;&#25551;&#36848;&#30340;&#24773;&#26223;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#20855;&#26377;&#22240;&#26524;&#30456;&#20851;&#22238;&#25253;&#30340;&#38750;&#24179;&#31283;&#21644;&#24310;&#36831;&#30340;&#32452;&#21512;&#21322;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#23450;&#21521;&#22270;&#22312;&#19968;&#20010;&#22266;&#23450;&#30340;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#20013;&#24314;&#27169;&#22240;&#26524;&#20851;&#31995;&#12290;&#23398;&#20064;&#20195;&#29702;&#26368;&#22823;&#21270;&#38271;&#26399;&#24179;&#22343;&#22238;&#25253;&#65292;&#35813;&#22238;&#25253;&#23450;&#20041;&#20026;&#22522;&#30784;&#33218;&#30340;&#22238;&#25253;&#30340;&#32447;&#24615;&#20989;&#25968;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#20174;&#24310;&#36831;&#30340;&#21453;&#39304;&#20013;&#23398;&#20064;&#32467;&#26500;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#21033;&#29992;&#36825;&#20123;&#20449;&#24687;&#36827;&#34892;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential decision-making under uncertainty is often associated with long feedback delays. Such delays degrade the performance of the learning agent in identifying a subset of arms with the optimal collective reward in the long run. This problem becomes significantly challenging in a non-stationary environment with structural dependencies amongst the reward distributions associated with the arms. Therefore, besides adapting to delays and environmental changes, learning the causal relations alleviates the adverse effects of feedback delay on the decision-making process. We formalize the described setting as a non-stationary and delayed combinatorial semi-bandit problem with causally related rewards. We model the causal relations by a directed graph in a stationary structural equation model. The agent maximizes the long-term average payoff, defined as a linear function of the base arms' rewards. We develop a policy that learns the structural dependencies from delayed feedback and utiliz
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#39057;&#20132;&#26131;&#20107;&#20214;&#21040;&#36798;&#30340;&#28857;&#36807;&#31243;&#65292;&#20854;&#20013;&#24378;&#24230;&#26159;Hawkes&#36807;&#31243;&#21644;&#22996;&#25176;&#31807;&#27966;&#29983;&#30340;&#39640;&#32500;&#21327;&#21464;&#37327;&#20989;&#25968;&#30340;&#20056;&#31215;&#12290;&#31639;&#27861;&#21487;&#20197;&#22312;&#23384;&#22312;&#25968;&#21313;&#20159;&#25968;&#25454;&#28857;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20272;&#35745;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#25910;&#25947;&#24615;&#21644;&#19968;&#33268;&#24615;&#12290;&#26679;&#26412;&#22806;&#27979;&#35797;&#32467;&#26524;&#26174;&#31034;&#65292;&#25429;&#25417;&#22996;&#25176;&#31807;&#20449;&#24687;&#30340;&#38750;&#32447;&#24615;&#29305;&#24449;&#23545;&#20110;&#39640;&#39057;&#20132;&#26131;&#30340;&#33258;&#28608;&#24615;&#29305;&#24449;&#26377;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2307.09077</link><description>&lt;p&gt;
&#12298;&#22823;&#25968;&#25454;&#38598;&#19978;&#22522;&#20110;&#22996;&#25176;&#31807;&#30456;&#20851;Hawkes&#36807;&#31243;&#30340;&#20272;&#35745;&#12299;
&lt;/p&gt;
&lt;p&gt;
Estimation of an Order Book Dependent Hawkes Process for Large Datasets. (arXiv:2307.09077v1 [q-fin.TR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09077
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#39057;&#20132;&#26131;&#20107;&#20214;&#21040;&#36798;&#30340;&#28857;&#36807;&#31243;&#65292;&#20854;&#20013;&#24378;&#24230;&#26159;Hawkes&#36807;&#31243;&#21644;&#22996;&#25176;&#31807;&#27966;&#29983;&#30340;&#39640;&#32500;&#21327;&#21464;&#37327;&#20989;&#25968;&#30340;&#20056;&#31215;&#12290;&#31639;&#27861;&#21487;&#20197;&#22312;&#23384;&#22312;&#25968;&#21313;&#20159;&#25968;&#25454;&#28857;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20272;&#35745;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#25910;&#25947;&#24615;&#21644;&#19968;&#33268;&#24615;&#12290;&#26679;&#26412;&#22806;&#27979;&#35797;&#32467;&#26524;&#26174;&#31034;&#65292;&#25429;&#25417;&#22996;&#25176;&#31807;&#20449;&#24687;&#30340;&#38750;&#32447;&#24615;&#29305;&#24449;&#23545;&#20110;&#39640;&#39057;&#20132;&#26131;&#30340;&#33258;&#28608;&#24615;&#29305;&#24449;&#26377;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#39057;&#20132;&#26131;&#20107;&#20214;&#21040;&#36798;&#30340;&#28857;&#36807;&#31243;&#12290;&#24378;&#24230;&#26159;Hawkes&#36807;&#31243;&#21644;&#22996;&#25176;&#31807;&#27966;&#29983;&#30340;&#39640;&#32500;&#21327;&#21464;&#37327;&#20989;&#25968;&#30340;&#20056;&#31215;&#12290;&#35752;&#35770;&#20102;&#35813;&#36807;&#31243;&#31283;&#23450;&#24615;&#30340;&#26465;&#20214;&#12290;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21363;&#20351;&#22312;&#23384;&#22312;&#25968;&#21313;&#20159;&#25968;&#25454;&#28857;&#30340;&#24773;&#20917;&#19979;&#65292;&#20063;&#21487;&#20197;&#36827;&#34892;&#27169;&#22411;&#20272;&#35745;&#65292;&#21487;&#33021;&#38656;&#35201;&#23558;&#21327;&#21464;&#37327;&#26144;&#23556;&#21040;&#39640;&#32500;&#31354;&#38388;&#12290;&#22823;&#26679;&#26412;&#37327;&#26159;&#24120;&#35265;&#20110;&#20351;&#29992;&#22810;&#20010;&#27969;&#21160;&#24037;&#20855;&#30340;&#39640;&#39057;&#25968;&#25454;&#24212;&#29992;&#20013;&#30340;&#24773;&#20917;&#12290;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#65292;&#24314;&#31435;&#20102;&#22312;&#24369;&#26465;&#20214;&#19979;&#30340;&#19968;&#33268;&#24615;&#32467;&#26524;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#27979;&#35797;&#32479;&#35745;&#37327;&#26469;&#35780;&#20272;&#19981;&#21516;&#27169;&#22411;&#35268;&#33539;&#30340;&#26679;&#26412;&#22806;&#34920;&#29616;&#12290;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#32445;&#32422;&#35777;&#21048;&#20132;&#26131;&#25152;&#65288;NYSE&#65289;&#19978;&#20132;&#26131;&#30340;&#22235;&#21482;&#32929;&#31080;&#30340;&#30740;&#31350;&#20013;&#12290;&#26679;&#26412;&#22806;&#27979;&#35797;&#36807;&#31243;&#34920;&#26126;&#65292;&#25429;&#25417;&#22996;&#25176;&#31807;&#20449;&#24687;&#30340;&#38750;&#32447;&#24615;&#29305;&#24449;&#23545;&#20110;&#39640;&#39057;&#20132;&#26131;&#30340;&#33258;&#28608;&#24615;&#29305;&#24449;&#26377;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
A point process for event arrivals in high frequency trading is presented. The intensity is the product of a Hawkes process and high dimensional functions of covariates derived from the order book. Conditions for stationarity of the process are stated. An algorithm is presented to estimate the model even in the presence of billions of data points, possibly mapping covariates into a high dimensional space. The large sample size can be common for high frequency data applications using multiple liquid instruments. Convergence of the algorithm is shown, consistency results under weak conditions is established, and a test statistic to assess out of sample performance of different model specifications is suggested. The methodology is applied to the study of four stocks that trade on the New York Stock Exchange (NYSE). The out of sample testing procedure suggests that capturing the nonlinearity of the order book information adds value to the self exciting nature of high frequency trading even
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#29992;&#20110;&#22312;&#20302;&#32500;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#35745;&#31639;&#20004;&#32452;&#28857;&#20043;&#38388;Gromov-Wasserstein&#38382;&#39064;&#30340;&#26694;&#26550;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#23558;&#38382;&#39064;&#37325;&#26032;&#34920;&#36848;&#20026;&#19968;&#20010;&#20302;&#32500;&#20248;&#21270;&#38382;&#39064;&#26469;&#35299;&#20915;&#35745;&#31639;&#22256;&#38590;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#24182;&#33021;&#22815;&#22312;&#22823;&#35268;&#27169;&#38382;&#39064;&#20013;&#25214;&#21040;&#20840;&#23616;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2307.09057</link><description>&lt;p&gt;
&#22312;&#20302;&#32500;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#20840;&#23616;&#27714;&#35299;&#28857;&#20113;&#30340;Gromov-Wasserstein&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Globally solving the Gromov-Wasserstein problem for point clouds in low dimensional Euclidean spaces. (arXiv:2307.09057v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09057
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#29992;&#20110;&#22312;&#20302;&#32500;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#35745;&#31639;&#20004;&#32452;&#28857;&#20043;&#38388;Gromov-Wasserstein&#38382;&#39064;&#30340;&#26694;&#26550;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#23558;&#38382;&#39064;&#37325;&#26032;&#34920;&#36848;&#20026;&#19968;&#20010;&#20302;&#32500;&#20248;&#21270;&#38382;&#39064;&#26469;&#35299;&#20915;&#35745;&#31639;&#22256;&#38590;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#24182;&#33021;&#22815;&#22312;&#22823;&#35268;&#27169;&#38382;&#39064;&#20013;&#25214;&#21040;&#20840;&#23616;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#20302;&#32500;&#31354;&#38388;&#20013;&#35745;&#31639;&#20004;&#32452;&#28857;&#20043;&#38388;Gromov-Wasserstein&#38382;&#39064;&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;&#24046;&#24322;&#26159;&#27431;&#20960;&#37324;&#24471;&#33539;&#25968;&#30340;&#24179;&#26041;&#12290;Gromov-Wasserstein&#38382;&#39064;&#26159;&#20248;&#21270;&#36816;&#36755;&#38382;&#39064;&#30340;&#19968;&#31181;&#25512;&#24191;&#65292;&#23427;&#23547;&#25214;&#20445;&#25345;&#23613;&#21487;&#33021;&#22810;&#30340;&#25104;&#23545;&#36317;&#31163;&#30340;&#20004;&#32452;&#28857;&#20043;&#38388;&#30340;&#23545;&#24212;&#20851;&#31995;&#12290;&#36825;&#21487;&#20197;&#29992;&#20110;&#37327;&#21270;AI&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#20004;&#20010;&#24418;&#24577;&#25110;&#24418;&#29366;&#30340;&#30456;&#20284;&#24615;&#65292;&#36825;&#26159;&#19968;&#20010;&#24120;&#35265;&#30340;&#38382;&#39064;&#12290;&#38382;&#39064;&#21487;&#20197;&#34987;&#24314;&#27169;&#20026;&#19968;&#20010;Quadratic Assignment Problem&#65288;QAP&#65289;&#65292;&#21363;&#20351;&#23545;&#20110;&#23567;&#38382;&#39064;&#26469;&#35828;&#65292;QAP&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#20063;&#26159;&#38590;&#20197;&#35745;&#31639;&#30340;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#36890;&#36807;&#23558;QAP&#37325;&#26032;&#34920;&#36848;&#20026;&#19968;&#20010;&#22312;&#20302;&#32500;&#22495;&#19978;&#30340;&#20248;&#21270;&#38382;&#39064;&#26469;&#24212;&#23545;&#36825;&#20010;&#25361;&#25112;&#65292;&#21033;&#29992;&#20102;&#38382;&#39064;&#21487;&#20197;&#34920;&#31034;&#20026;&#20302;&#31209;&#30340;&#20985;&#20108;&#27425;&#20248;&#21270;&#38382;&#39064;&#30340;&#20107;&#23454;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#28857;&#30340;&#25968;&#37327;&#26041;&#38754;&#20855;&#26377;&#33391;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#24182;&#19988;&#21487;&#20197;&#29992;&#20110;&#22312;&#25104;&#21315;&#19978;&#19975;&#30340;&#22823;&#35268;&#27169;&#38382;&#39064;&#20013;&#25214;&#21040;&#20840;&#23616;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a framework for computing the Gromov-Wasserstein problem between two sets of points in low dimensional spaces, where the discrepancy is the squared Euclidean norm. The Gromov-Wasserstein problem is a generalization of the optimal transport problem that finds the assignment between two sets preserving pairwise distances as much as possible. This can be used to quantify the similarity between two formations or shapes, a common problem in AI and machine learning. The problem can be formulated as a Quadratic Assignment Problem (QAP), which is in general computationally intractable even for small problems. Our framework addresses this challenge by reformulating the QAP as an optimization problem with a low-dimensional domain, leveraging the fact that the problem can be expressed as a concave quadratic optimization problem with low rank. The method scales well with the number of points, and it can be used to find the global solution for large-scale problems with thousands
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24322;&#24120;&#40065;&#26834;&#24352;&#37327;&#20302;&#31209;&#34920;&#31034;&#26041;&#27861;&#65292;&#29992;&#20110;&#21516;&#26102;&#26816;&#27979;&#24322;&#24120;&#20540;&#21644;&#36827;&#34892;&#25968;&#25454;&#32858;&#31867;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#24352;&#37327;&#22855;&#24322;&#20540;&#20998;&#35299;&#65288;t-SVD&#65289;&#20195;&#25968;&#26694;&#26550;&#65292;&#24182;&#22312;&#36739;&#24369;&#26465;&#20214;&#19979;&#20855;&#26377;&#24674;&#22797;&#24178;&#20928;&#25968;&#25454;&#30340;&#34892;&#31354;&#38388;&#21644;&#26816;&#27979;&#24322;&#24120;&#20540;&#30340;&#21487;&#35777;&#26126;&#24615;&#33021;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;&#25193;&#23637;&#26041;&#27861;&#20197;&#22788;&#29702;&#25968;&#25454;&#37096;&#20998;&#32570;&#22833;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2307.09055</link><description>&lt;p&gt;
&#24322;&#24120;&#40065;&#26834;&#24352;&#37327;&#20302;&#31209;&#34920;&#31034;&#29992;&#20110;&#25968;&#25454;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Outlier-Robust Tensor Low-Rank Representation for Data Clustering. (arXiv:2307.09055v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09055
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24322;&#24120;&#40065;&#26834;&#24352;&#37327;&#20302;&#31209;&#34920;&#31034;&#26041;&#27861;&#65292;&#29992;&#20110;&#21516;&#26102;&#26816;&#27979;&#24322;&#24120;&#20540;&#21644;&#36827;&#34892;&#25968;&#25454;&#32858;&#31867;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#24352;&#37327;&#22855;&#24322;&#20540;&#20998;&#35299;&#65288;t-SVD&#65289;&#20195;&#25968;&#26694;&#26550;&#65292;&#24182;&#22312;&#36739;&#24369;&#26465;&#20214;&#19979;&#20855;&#26377;&#24674;&#22797;&#24178;&#20928;&#25968;&#25454;&#30340;&#34892;&#31354;&#38388;&#21644;&#26816;&#27979;&#24322;&#24120;&#20540;&#30340;&#21487;&#35777;&#26126;&#24615;&#33021;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;&#25193;&#23637;&#26041;&#27861;&#20197;&#22788;&#29702;&#25968;&#25454;&#37096;&#20998;&#32570;&#22833;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#31209;&#24352;&#37327;&#20998;&#26512;&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#24352;&#37327;&#25968;&#25454;&#32463;&#24120;&#21463;&#21040;&#24322;&#24120;&#20540;&#25110;&#26679;&#26412;&#29305;&#23450;&#30340;&#27745;&#26579;&#12290;&#22914;&#20309;&#24674;&#22797;&#34987;&#24322;&#24120;&#20540;&#25439;&#22351;&#30340;&#24352;&#37327;&#25968;&#25454;&#24182;&#36827;&#34892;&#25968;&#25454;&#32858;&#31867;&#20173;&#28982;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;&#26412;&#25991;&#22522;&#20110;&#24352;&#37327;&#22855;&#24322;&#20540;&#20998;&#35299;&#65288;t-SVD&#65289;&#20195;&#25968;&#26694;&#26550;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#21516;&#26102;&#26816;&#27979;&#24322;&#24120;&#20540;&#21644;&#24352;&#37327;&#25968;&#25454;&#32858;&#31867;&#30340;&#24322;&#24120;&#40065;&#26834;&#24352;&#37327;&#20302;&#31209;&#34920;&#31034;&#65288;OR-TLRR&#65289;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21463;&#21040;&#26368;&#36817;&#25552;&#20986;&#30340;&#28385;&#36275;&#19968;&#23450;&#26465;&#20214;&#30340;&#21487;&#36870;&#32447;&#24615;&#21464;&#25442;&#24341;&#36215;&#30340;&#24352;&#37327;&#24352;&#37327;&#31215;&#30340;&#21551;&#21457;&#12290;&#23545;&#20110;&#24102;&#26377;&#20219;&#24847;&#24322;&#24120;&#20540;&#27745;&#26579;&#30340;&#24352;&#37327;&#35266;&#27979;&#65292;OR-TLRR&#22312;&#36739;&#24369;&#26465;&#20214;&#19979;&#33021;&#22815;&#30830;&#20999;&#24674;&#22797;&#24178;&#20928;&#25968;&#25454;&#30340;&#34892;&#31354;&#38388;&#24182;&#26816;&#27979;&#24322;&#24120;&#20540;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;OR-TLRR&#30340;&#25193;&#23637;&#26469;&#22788;&#29702;&#25968;&#25454;&#37096;&#20998;&#32570;&#22833;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Low-rank tensor analysis has received widespread attention with many practical applications. However, the tensor data are often contaminated by outliers or sample-specific corruptions. How to recover the tensor data that are corrupted by outliers and perform data clustering remains a challenging problem. This paper develops an outlier-robust tensor low-rank representation (OR-TLRR) method for simultaneous outlier detection and tensor data clustering based on the tensor singular value decomposition (t-SVD) algebraic framework. It is motivated by the recently proposed tensor-tensor product induced by invertible linear transforms that satisfy certain conditions. For tensor observations with arbitrary outlier corruptions, OR-TLRR has provable performance guarantee for exactly recovering the row space of clean data and detecting outliers under mild conditions. Moreover, an extension of OR-TLRR is also proposed to handle the case when parts of the data are missing. Finally, extensive experim
&lt;/p&gt;</description></item><item><title>qecGPT&#26159;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#29992;&#29983;&#25104;&#27169;&#22411;&#35299;&#30721;&#37327;&#23376;&#32416;&#38169;&#30721;&#12290;&#35813;&#27169;&#22411;&#21033;&#29992;Transformers&#23398;&#20064;&#36923;&#36753;&#36816;&#31639;&#31526;&#21644;&#32508;&#21512;&#30340;&#32852;&#21512;&#27010;&#29575;&#65292;&#22312;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#21518;&#21487;&#20197;&#39640;&#25928;&#35745;&#31639;&#21644;&#29983;&#25104;&#26368;&#21487;&#33021;&#30340;&#36923;&#36753;&#36816;&#31639;&#31526;&#65292;&#27604;&#20256;&#32479;&#26041;&#27861;&#26356;&#24555;&#26356;&#20934;&#30830;&#12290;</title><link>http://arxiv.org/abs/2307.09025</link><description>&lt;p&gt;
qecGPT&#65306;&#20351;&#29992;&#29983;&#25104;&#24335;&#39044;&#35757;&#32451;&#36716;&#25442;&#22120;&#23545;&#37327;&#23376;&#32416;&#38169;&#30721;&#36827;&#34892;&#35299;&#30721;
&lt;/p&gt;
&lt;p&gt;
qecGPT: decoding Quantum Error-correcting Codes with Generative Pre-trained Transformers. (arXiv:2307.09025v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09025
&lt;/p&gt;
&lt;p&gt;
qecGPT&#26159;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#29992;&#29983;&#25104;&#27169;&#22411;&#35299;&#30721;&#37327;&#23376;&#32416;&#38169;&#30721;&#12290;&#35813;&#27169;&#22411;&#21033;&#29992;Transformers&#23398;&#20064;&#36923;&#36753;&#36816;&#31639;&#31526;&#21644;&#32508;&#21512;&#30340;&#32852;&#21512;&#27010;&#29575;&#65292;&#22312;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#21518;&#21487;&#20197;&#39640;&#25928;&#35745;&#31639;&#21644;&#29983;&#25104;&#26368;&#21487;&#33021;&#30340;&#36923;&#36753;&#36816;&#31639;&#31526;&#65292;&#27604;&#20256;&#32479;&#26041;&#27861;&#26356;&#24555;&#26356;&#20934;&#30830;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#29983;&#25104;&#24314;&#27169;&#35299;&#30721;&#37327;&#23376;&#32416;&#38169;&#30721;&#30340;&#36890;&#29992;&#26694;&#26550;&#12290;&#35813;&#27169;&#22411;&#21033;&#29992;&#33258;&#22238;&#24402;&#31070;&#32463;&#32593;&#32476;&#65292;&#29305;&#21035;&#26159;&#20351;&#29992;Transformer&#23398;&#20064;&#36923;&#36753;&#36816;&#31639;&#31526;&#21644;&#32508;&#21512;&#30340;&#32852;&#21512;&#27010;&#29575;&#12290;&#35813;&#35757;&#32451;&#26159;&#26080;&#30417;&#30563;&#30340;&#65292;&#19981;&#38656;&#35201;&#26631;&#27880;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#24182;&#19988;&#34987;&#31216;&#20026;&#39044;&#35757;&#32451;&#12290;&#22312;&#39044;&#35757;&#32451;&#20043;&#21518;&#65292;&#27169;&#22411;&#21487;&#20197;&#39640;&#25928;&#22320;&#35745;&#31639;&#32473;&#23450;&#32508;&#21512;&#30340;&#36923;&#36753;&#36816;&#31639;&#31526;&#30340;&#21487;&#33021;&#24615;&#65292;&#20351;&#29992;&#26368;&#22823;&#20284;&#28982;&#35299;&#30721;&#12290;&#23427;&#21487;&#20197;&#30452;&#25509;&#29983;&#25104;&#26368;&#21487;&#33021;&#30340;&#36923;&#36753;&#36816;&#31639;&#31526;&#65292;&#35745;&#31639;&#22797;&#26434;&#24230;&#20026;$\mathcal O(2k)$&#65292;&#20854;&#20013;$k$&#20026;&#36923;&#36753;&#37327;&#23376;&#27604;&#29305;&#30340;&#25968;&#37327;&#65292;&#36825;&#27604;&#24120;&#35268;&#30340;&#26368;&#22823;&#20284;&#28982;&#35299;&#30721;&#31639;&#27861;$\mathcal O(4^k)$&#26356;&#20248;&#12290;&#22522;&#20110;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#36890;&#36807;&#30452;&#25509;&#37319;&#26679;&#31283;&#23450;&#23376;&#31639;&#31526;&#26469;&#26356;&#20934;&#30830;&#22320;&#33719;&#24471;&#32473;&#23450;&#32508;&#21512;&#30340;&#36923;&#36753;&#36816;&#31639;&#31526;&#21487;&#33021;&#24615;&#30340;&#25913;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a general framework for decoding quantum error-correcting codes with generative modeling. The model utilizes autoregressive neural networks, specifically Transformers, to learn the joint probability of logical operators and syndromes. This training is in an unsupervised way, without the need for labeled training data, and is thus referred to as pre-training. After the pre-training, the model can efficiently compute the likelihood of logical operators for any given syndrome, using maximum likelihood decoding. It can directly generate the most-likely logical operators with computational complexity $\mathcal O(2k)$ in the number of logical qubits $k$, which is significantly better than the conventional maximum likelihood decoding algorithms that require $\mathcal O(4^k)$ computation. Based on the pre-trained model, we further propose refinement to achieve more accurately the likelihood of logical operators for a given syndrome by directly sampling the stabilizer operators. We p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#23545;&#25239;&#32972;&#26223;&#19979;&#30340;&#20840;&#38754;&#39044;&#27979;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22312;&#32447;&#22810;&#26657;&#20934;&#31639;&#27861;&#65292;&#21487;&#20197;&#36866;&#29992;&#20110;&#26080;&#38480;&#30340;&#22522;&#20934;&#20989;&#25968;&#31867;&#65292;&#24182;&#19988;&#26159;Oracle&#39640;&#25928;&#30340;&#12290;</title><link>http://arxiv.org/abs/2307.08999</link><description>&lt;p&gt;
Oracle&#39640;&#25928;&#30340;&#22312;&#32447;&#22810;&#26657;&#20934;&#21644;&#20840;&#38754;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Oracle Efficient Online Multicalibration and Omniprediction. (arXiv:2307.08999v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08999
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#23545;&#25239;&#32972;&#26223;&#19979;&#30340;&#20840;&#38754;&#39044;&#27979;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22312;&#32447;&#22810;&#26657;&#20934;&#31639;&#27861;&#65292;&#21487;&#20197;&#36866;&#29992;&#20110;&#26080;&#38480;&#30340;&#22522;&#20934;&#20989;&#25968;&#31867;&#65292;&#24182;&#19988;&#26159;Oracle&#39640;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#19968;&#31995;&#21015;&#30740;&#31350;&#34920;&#26126;&#65292;&#22810;&#26657;&#20934;&#65288;multicalibration&#65289;&#36825;&#19968;&#22810;&#32452;&#20844;&#24179;&#24615;&#27010;&#24565;&#19982;&#20840;&#38754;&#39044;&#27979;&#65288;omniprediction&#65289;&#36825;&#19968;&#20026;&#22823;&#37327;&#25439;&#22833;&#20989;&#25968;&#25552;&#20379;&#21516;&#26102;&#25439;&#22833;&#26368;&#23567;&#21270;&#20445;&#35777;&#30340;&#23398;&#20064;&#33539;&#24335;&#20043;&#38388;&#23384;&#22312;&#24847;&#24819;&#19981;&#21040;&#30340;&#32852;&#31995;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#25209;&#22788;&#29702;&#35774;&#32622;&#19979;&#30340;&#20840;&#38754;&#39044;&#27979;&#12290;&#25105;&#20204;&#39318;&#27425;&#22312;&#22312;&#32447;&#23545;&#25239;&#35774;&#32622;&#19979;&#30740;&#31350;&#20102;&#20840;&#38754;&#39044;&#27979;&#12290;&#23613;&#31649;&#24050;&#32463;&#23384;&#22312;&#29992;&#20110;&#22312;&#32447;&#23545;&#25239;&#35774;&#32622;&#19979;&#33719;&#21462;&#22810;&#26657;&#20934;&#27010;&#24565;&#30340;&#31639;&#27861;&#65292;&#20294;&#19982;&#25209;&#22788;&#29702;&#31639;&#27861;&#19981;&#21516;&#65292;&#23427;&#20204;&#21482;&#36866;&#29992;&#20110;&#26377;&#38480;&#30340;&#22522;&#20934;&#20989;&#25968;&#31867;$F$&#65292;&#22240;&#20026;&#23427;&#20204;&#35201;&#27714;&#27599;&#19968;&#36718;&#26522;&#20030;&#27599;&#20010;&#20989;&#25968;$f \in F$&#12290;&#30456;&#21453;&#65292;&#20840;&#38754;&#39044;&#27979;&#23545;&#20110;&#23398;&#20064;&#29702;&#35770;&#30340;&#20551;&#35774;&#31867;$F$&#26368;&#26377;&#36259;&#65292;&#32780;&#36825;&#20123;&#31867;&#36890;&#24120;&#26159;&#36830;&#32493;&#22823;&#30340;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#22312;&#32447;&#22810;&#26657;&#20934;&#31639;&#27861;&#65292;&#21487;&#20197;&#36866;&#29992;&#20110;&#26080;&#38480;&#30340;&#22522;&#20934;&#20989;&#25968;&#31867;$F$&#65292;&#24182;&#19988;&#26159;Oracle&#39640;&#25928;&#30340;&#65288;&#21363;&#23545;&#20110;&#20219;&#20309;&#31867;$F$&#65292;&#31639;&#27861;&#37117;&#21487;&#20197;&#36716;&#21270;&#20026;&#39640;&#25928;&#30340;&#32422;&#31616;&#24418;&#24335;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
A recent line of work has shown a surprising connection between multicalibration, a multi-group fairness notion, and omniprediction, a learning paradigm that provides simultaneous loss minimization guarantees for a large family of loss functions. Prior work studies omniprediction in the batch setting. We initiate the study of omniprediction in the online adversarial setting. Although there exist algorithms for obtaining notions of multicalibration in the online adversarial setting, unlike batch algorithms, they work only for small finite classes of benchmark functions $F$, because they require enumerating every function $f \in F$ at every round. In contrast, omniprediction is most interesting for learning theoretic hypothesis classes $F$, which are generally continuously large.  We develop a new online multicalibration algorithm that is well defined for infinite benchmark classes $F$, and is oracle efficient (i.e. for any class $F$, the algorithm has the form of an efficient reduction 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20048;&#35266;&#20272;&#35745;&#26041;&#27861;&#65292;&#30740;&#31350;&#25581;&#31034;&#20102;&#38750;&#32447;&#24615;&#27169;&#22411;&#22312;&#25311;&#21512;&#30446;&#26631;&#20989;&#25968;&#26102;&#30340;&#28508;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;DNN&#30340;&#26550;&#26500;&#35774;&#35745;&#21407;&#21017;&#12290;</title><link>http://arxiv.org/abs/2307.08921</link><description>&lt;p&gt;
&#20048;&#35266;&#20272;&#35745;&#25581;&#31034;&#20102;&#38750;&#32447;&#24615;&#27169;&#22411;&#30340;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;
Optimistic Estimate Uncovers the Potential of Nonlinear Models. (arXiv:2307.08921v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08921
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20048;&#35266;&#20272;&#35745;&#26041;&#27861;&#65292;&#30740;&#31350;&#25581;&#31034;&#20102;&#38750;&#32447;&#24615;&#27169;&#22411;&#22312;&#25311;&#21512;&#30446;&#26631;&#20989;&#25968;&#26102;&#30340;&#28508;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;DNN&#30340;&#26550;&#26500;&#35774;&#35745;&#21407;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20048;&#35266;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#38750;&#32447;&#24615;&#27169;&#22411;&#30340;&#26368;&#20339;&#25311;&#21512;&#24615;&#33021;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#25105;&#20204;&#21487;&#20197;&#24471;&#21040;&#19968;&#20010;&#20048;&#35266;&#26679;&#26412;&#22823;&#23567;&#65292;&#29992;&#20110;&#30830;&#23450;&#20351;&#29992;&#38750;&#32447;&#24615;&#27169;&#22411;&#26469;&#25311;&#21512;&#25110;&#24674;&#22797;&#30446;&#26631;&#20989;&#25968;&#25152;&#38656;&#30340;&#26368;&#23567;&#26679;&#26412;&#22823;&#23567;&#12290;&#25105;&#20204;&#20272;&#35745;&#20102;&#30697;&#38453;&#22240;&#24335;&#20998;&#35299;&#27169;&#22411;&#12289;&#28145;&#24230;&#27169;&#22411;&#21644;&#20855;&#26377;&#20840;&#36830;&#25509;&#25110;&#21367;&#31215;&#32467;&#26500;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNN)&#30340;&#20048;&#35266;&#26679;&#26412;&#22823;&#23567;&#12290;&#23545;&#20110;&#27599;&#20010;&#38750;&#32447;&#24615;&#27169;&#22411;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#39044;&#27979;&#20102;&#21487;&#20197;&#22312;&#36807;&#24230;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#25311;&#21512;&#30340;&#29305;&#23450;&#30446;&#26631;&#23376;&#38598;&#65292;&#36825;&#24471;&#21040;&#20102;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#23454;&#12290;&#25105;&#20204;&#30340;&#20048;&#35266;&#20272;&#35745;&#25581;&#31034;&#20102;DNN&#27169;&#22411;&#30340;&#20004;&#20010;&#29305;&#27530;&#23646;&#24615;--&#23485;&#24230;&#19978;&#30340;&#33258;&#30001;&#34920;&#36798;&#21644;&#36830;&#25509;&#19978;&#30340;&#26114;&#36149;&#34920;&#36798;&#12290;&#36825;&#20123;&#23646;&#24615;&#25552;&#31034;&#20102;DNN&#30340;&#20197;&#19979;&#26550;&#26500;&#35774;&#35745;&#21407;&#21017;&#65306;(i)&#38543;&#24847;&#22686;&#21152;&#31070;&#32463;&#20803;/&#26680;&#65307;(ii)&#36991;&#20813;&#36830;&#25509;&#31070;&#32463;&#20803;&#12290;&#24635;&#20307;&#19978;&#65292;&#25105;&#20204;&#30340;&#20048;&#35266;&#20272;&#35745;&#22312;&#29702;&#35770;&#19978;&#25581;&#31034;&#20102;&#38750;&#32447;&#24615;&#27169;&#22411;&#22312;&#36807;&#24230;&#21442;&#25968;&#21270;&#25311;&#21512;&#20013;&#30340;&#24040;&#22823;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose an optimistic estimate to evaluate the best possible fitting performance of nonlinear models. It yields an optimistic sample size that quantifies the smallest possible sample size to fit/recover a target function using a nonlinear model. We estimate the optimistic sample sizes for matrix factorization models, deep models, and deep neural networks (DNNs) with fully-connected or convolutional architecture. For each nonlinear model, our estimates predict a specific subset of targets that can be fitted at overparameterization, which are confirmed by our experiments. Our optimistic estimate reveals two special properties of the DNN models -- free expressiveness in width and costly expressiveness in connection. These properties suggest the following architecture design principles of DNNs: (i) feel free to add neurons/kernels; (ii) restrain from connecting neurons. Overall, our optimistic estimate theoretically unveils the vast potential of nonlinear models in fitting at overparame
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35780;&#20272;&#20102;&#26080;&#30417;&#30563;&#20998;&#31163;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#22312;&#22522;&#22240;&#25506;&#32034;&#21644;&#30142;&#30149;&#39118;&#38505;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;&#65292;&#21457;&#29616;&#20351;&#29992;FactorVAE&#25110;beta-VAE&#30456;&#27604;&#26631;&#20934;VAE&#25110;&#38750;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#21487;&#20197;&#26174;&#33879;&#25913;&#21892;&#21742;&#21912;&#21644;&#24930;&#24615;&#38459;&#22622;&#24615;&#32954;&#30142;&#30149;&#30340;&#20840;&#22522;&#22240;&#32452;&#26174;&#33879;&#20301;&#28857;&#25968;&#37327;&#12289;&#36951;&#20256;&#21147;&#21644;&#22810;&#22522;&#22240;&#39118;&#38505;&#35780;&#20998;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.08893</link><description>&lt;p&gt;
&#35780;&#20272;&#26080;&#30417;&#30563;&#20998;&#31163;&#34920;&#31034;&#23398;&#20064;&#22312;&#22522;&#22240;&#25506;&#32034;&#21644;&#30142;&#30149;&#39118;&#38505;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Evaluating unsupervised disentangled representation learning for genomic discovery and disease risk prediction. (arXiv:2307.08893v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08893
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35780;&#20272;&#20102;&#26080;&#30417;&#30563;&#20998;&#31163;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#22312;&#22522;&#22240;&#25506;&#32034;&#21644;&#30142;&#30149;&#39118;&#38505;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;&#65292;&#21457;&#29616;&#20351;&#29992;FactorVAE&#25110;beta-VAE&#30456;&#27604;&#26631;&#20934;VAE&#25110;&#38750;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#21487;&#20197;&#26174;&#33879;&#25913;&#21892;&#21742;&#21912;&#21644;&#24930;&#24615;&#38459;&#22622;&#24615;&#32954;&#30142;&#30149;&#30340;&#20840;&#22522;&#22240;&#32452;&#26174;&#33879;&#20301;&#28857;&#25968;&#37327;&#12289;&#36951;&#20256;&#21147;&#21644;&#22810;&#22522;&#22240;&#39118;&#38505;&#35780;&#20998;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#20020;&#24202;&#25968;&#25454;&#30001;&#20110;&#20854;&#22312;&#29983;&#29289;&#24211;&#35268;&#27169;&#25968;&#25454;&#38598;&#20013;&#30340;&#21487;&#35775;&#38382;&#24615;&#21644;&#39640;&#24615;&#33021;&#24314;&#27169;&#25216;&#26415;&#65288;&#23588;&#20854;&#26159;&#28145;&#24230;&#23398;&#20064;&#65289;&#30340;&#21457;&#23637;&#65292;&#24050;&#32463;&#25104;&#20026;&#36951;&#20256;&#30740;&#31350;&#20013;&#23453;&#36149;&#30340;&#36164;&#28304;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#30001;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#23398;&#20064;&#30340;&#36825;&#20123;&#20020;&#24202;&#25968;&#25454;&#30340;&#20302;&#32500;&#23884;&#20837;&#21487;&#20197;&#29992;&#20110;&#20840;&#22522;&#22240;&#32452;&#20851;&#32852;&#30740;&#31350;&#21644;&#22810;&#22522;&#22240;&#39118;&#38505;&#39044;&#27979;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#22810;&#31181;&#26080;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#36951;&#20256;&#30456;&#20851;&#30740;&#31350;&#20013;&#23398;&#20064;&#20998;&#31163;&#34920;&#31034;&#65292;&#21253;&#25324;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;autoencoders&#65289;&#12289;VAE&#12289;beta-VAE&#21644;FactorVAE&#12290;&#20197;&#33521;&#22269;&#29983;&#29289;&#24211;&#30340;&#25903;&#27668;&#31649;&#22270;&#35889;&#20026;&#20363;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#20351;&#29992;FactorVAE&#25110;beta-VAE&#30456;&#27604;&#26631;&#20934;VAE&#25110;&#38750;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#21487;&#20197;&#25913;&#21892;&#21742;&#21912;&#21644;&#24930;&#24615;&#38459;&#22622;&#24615;&#32954;&#30142;&#30149;&#30340;&#20840;&#22522;&#22240;&#32452;&#26174;&#33879;&#20301;&#28857;&#25968;&#37327;&#12289;&#36951;&#20256;&#21147;&#21644;&#22810;&#22522;&#22240;&#39118;&#38505;&#35780;&#20998;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
High-dimensional clinical data have become invaluable resources for genetic studies, due to their accessibility in biobank-scale datasets and the development of high performance modeling techniques especially using deep learning. Recent work has shown that low dimensional embeddings of these clinical data learned by variational autoencoders (VAE) can be used for genome-wide association studies and polygenic risk prediction. In this work, we consider multiple unsupervised learning methods for learning disentangled representations, namely autoencoders, VAE, beta-VAE, and FactorVAE, in the context of genetic association studies. Using spirograms from UK Biobank as a running example, we observed improvements in the number of genome-wide significant loci, heritability, and performance of polygenic risk scores for asthma and chronic obstructive pulmonary disease by using FactorVAE or beta-VAE, compared to standard VAE or non-variational autoencoders. FactorVAEs performed effectively across m
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#23545;&#31070;&#32463;&#31639;&#27861;&#25512;&#29702;&#22120;&#20013;&#25191;&#34892;&#31639;&#27861;&#26102;&#20135;&#29983;&#30340;&#28508;&#22312;&#31354;&#38388;&#32467;&#26500;&#36827;&#34892;&#20102;&#35814;&#32454;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#20102;&#35299;&#20915;&#20004;&#31181;&#25925;&#38556;&#27169;&#24335;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;softmax&#32858;&#21512;&#22120;&#35299;&#20915;&#20998;&#36776;&#29575;&#20007;&#22833;&#38382;&#39064;&#65292;&#20197;&#21450;&#34928;&#20943;&#28508;&#22312;&#31354;&#38388;&#26469;&#22788;&#29702;&#36229;&#20986;&#33539;&#22260;&#30340;&#20540;&#65292;&#36825;&#20123;&#25913;&#21464;&#22312;&#26631;&#20934;CLRS-30&#22522;&#20934;&#27979;&#35797;&#20013;&#22823;&#22810;&#25968;&#31639;&#27861;&#19978;&#23454;&#29616;&#20102;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2307.08874</link><description>&lt;p&gt;
&#31070;&#32463;&#31639;&#27861;&#25512;&#29702;&#22120;&#30340;&#28508;&#22312;&#31354;&#38388;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Latent Space Representations of Neural Algorithmic Reasoners. (arXiv:2307.08874v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08874
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#23545;&#31070;&#32463;&#31639;&#27861;&#25512;&#29702;&#22120;&#20013;&#25191;&#34892;&#31639;&#27861;&#26102;&#20135;&#29983;&#30340;&#28508;&#22312;&#31354;&#38388;&#32467;&#26500;&#36827;&#34892;&#20102;&#35814;&#32454;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#20102;&#35299;&#20915;&#20004;&#31181;&#25925;&#38556;&#27169;&#24335;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;softmax&#32858;&#21512;&#22120;&#35299;&#20915;&#20998;&#36776;&#29575;&#20007;&#22833;&#38382;&#39064;&#65292;&#20197;&#21450;&#34928;&#20943;&#28508;&#22312;&#31354;&#38388;&#26469;&#22788;&#29702;&#36229;&#20986;&#33539;&#22260;&#30340;&#20540;&#65292;&#36825;&#20123;&#25913;&#21464;&#22312;&#26631;&#20934;CLRS-30&#22522;&#20934;&#27979;&#35797;&#20013;&#22823;&#22810;&#25968;&#31639;&#27861;&#19978;&#23454;&#29616;&#20102;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#31639;&#27861;&#25512;&#29702;&#65288;NAR&#65289;&#26159;&#19968;&#20010;&#30740;&#31350;&#39046;&#22495;&#65292;&#19987;&#27880;&#20110;&#35774;&#35745;&#33021;&#22815;&#21487;&#38752;&#22320;&#25429;&#25417;&#32463;&#20856;&#35745;&#31639;&#30340;&#31070;&#32463;&#26550;&#26500;&#65292;&#36890;&#24120;&#36890;&#36807;&#23398;&#20064;&#25191;&#34892;&#31639;&#27861;&#26469;&#23454;&#29616;&#12290;&#20856;&#22411;&#30340;&#26041;&#27861;&#26159;&#20381;&#36182;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#26550;&#26500;&#65292;&#23427;&#20204;&#23558;&#36755;&#20837;&#32534;&#30721;&#20026;&#39640;&#32500;&#28508;&#22312;&#31354;&#38388;&#65292;&#22312;&#31639;&#27861;&#25191;&#34892;&#26399;&#38388;&#21453;&#22797;&#36716;&#25442;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23545;GNN&#22312;&#25191;&#34892;&#31639;&#27861;&#26102;&#23548;&#33268;&#30340;&#28508;&#22312;&#31354;&#38388;&#32467;&#26500;&#36827;&#34892;&#20102;&#35814;&#32454;&#20998;&#26512;&#12290;&#25105;&#20204;&#21457;&#29616;&#20102;&#20004;&#31181;&#21487;&#33021;&#30340;&#25925;&#38556;&#27169;&#24335;&#65306;&#65288;i&#65289;&#20998;&#36776;&#29575;&#20007;&#22833;&#65292;&#20351;&#24471;&#38590;&#20197;&#21306;&#20998;&#30456;&#20284;&#30340;&#20540;&#65307;&#65288;ii&#65289;&#26080;&#27861;&#22788;&#29702;&#35757;&#32451;&#26399;&#38388;&#26410;&#35266;&#23519;&#21040;&#30340;&#20540;&#33539;&#22260;&#20043;&#22806;&#30340;&#20540;&#12290;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#20381;&#36182;softmax&#32858;&#21512;&#22120;&#26469;&#35299;&#20915;&#31532;&#19968;&#20010;&#38382;&#39064;&#65292;&#24182;&#24314;&#35758;&#34928;&#20943;&#28508;&#22312;&#31354;&#38388;&#20197;&#22788;&#29702;&#36229;&#20986;&#33539;&#22260;&#30340;&#20540;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#21464;&#21270;&#22312;&#20351;&#29992;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#26102;&#65292;&#22312;&#26631;&#20934;CLRS-30&#22522;&#20934;&#27979;&#35797;&#20013;&#22823;&#22810;&#25968;&#31639;&#27861;&#19978;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural Algorithmic Reasoning (NAR) is a research area focused on designing neural architectures that can reliably capture classical computation, usually by learning to execute algorithms. A typical approach is to rely on Graph Neural Network (GNN) architectures, which encode inputs in high-dimensional latent spaces that are repeatedly transformed during the execution of the algorithm. In this work we perform a detailed analysis of the structure of the latent space induced by the GNN when executing algorithms. We identify two possible failure modes: (i) loss of resolution, making it hard to distinguish similar values; (ii) inability to deal with values outside the range observed during training. We propose to solve the first issue by relying on a softmax aggregator, and propose to decay the latent space in order to deal with out-of-range values. We show that these changes lead to improvements on the majority of algorithms in the standard CLRS-30 benchmark when using the state-of-the-art
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32771;&#34385;&#21327;&#21464;&#37327;&#30340;&#21516;&#36136;&#24615;&#27979;&#35797;&#26041;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#24207;&#25968;&#35780;&#20998;&#30740;&#31350;&#20013;&#35780;&#20998;&#21592;&#20934;&#30830;&#24615;&#30340;&#24046;&#24322;&#65292;&#24182;&#24212;&#29992;&#20110;&#20154;&#33080;&#35782;&#21035;&#30740;&#31350;&#20013;&#65292;&#21457;&#29616;&#20102;&#20116;&#20010;&#21442;&#19982;&#32773;&#32452;&#20043;&#38388;&#30340;&#32479;&#35745;&#26174;&#33879;&#24046;&#24322;&#12290;</title><link>http://arxiv.org/abs/2307.08846</link><description>&lt;p&gt;
&#32771;&#34385;&#21327;&#21464;&#37327;&#30340;&#21516;&#36136;&#24615;&#27979;&#35797;&#21450;&#20854;&#22312;&#20154;&#33080;&#35782;&#21035;&#20934;&#30830;&#24615;&#35780;&#20272;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
A Covariate-Adjusted Homogeneity Test with Application to Facial Recognition Accuracy Assessment. (arXiv:2307.08846v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08846
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32771;&#34385;&#21327;&#21464;&#37327;&#30340;&#21516;&#36136;&#24615;&#27979;&#35797;&#26041;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#24207;&#25968;&#35780;&#20998;&#30740;&#31350;&#20013;&#35780;&#20998;&#21592;&#20934;&#30830;&#24615;&#30340;&#24046;&#24322;&#65292;&#24182;&#24212;&#29992;&#20110;&#20154;&#33080;&#35782;&#21035;&#30740;&#31350;&#20013;&#65292;&#21457;&#29616;&#20102;&#20116;&#20010;&#21442;&#19982;&#32773;&#32452;&#20043;&#38388;&#30340;&#32479;&#35745;&#26174;&#33879;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21307;&#23398;&#24433;&#20687;&#30740;&#31350;&#21644;&#40657;&#30418;&#37492;&#23450;&#30740;&#31350;&#20013;&#65292;&#24120;&#24120;&#20986;&#29616;&#24207;&#25968;&#35780;&#20998;&#12290;&#20026;&#20102;&#35780;&#20272;&#30740;&#31350;&#20013;&#30340;&#35780;&#20998;&#21592;&#20934;&#30830;&#24615;&#65292;&#38656;&#35201;&#22312;&#20272;&#35745;&#25509;&#25910;&#22120;&#25805;&#20316;&#29305;&#24449;&#26354;&#32447;&#65288;ROC&#26354;&#32447;&#65289;&#26102;&#32771;&#34385;&#35780;&#20998;&#21592;&#30340;&#21327;&#21464;&#37327;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32771;&#34385;&#21327;&#21464;&#37327;&#30340;&#21516;&#36136;&#24615;&#27979;&#35797;&#26041;&#27861;&#65292;&#29992;&#20110;&#30830;&#23450;&#22810;&#20010;&#35780;&#20998;&#21592;&#32452;&#38388;&#20934;&#30830;&#24615;&#30340;&#24046;&#24322;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#25152;&#25552;&#20986;&#27979;&#35797;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#24182;&#36827;&#34892;&#20102;&#22823;&#37327;&#27169;&#25311;&#30740;&#31350;&#65292;&#35780;&#20272;&#20102;&#25152;&#25552;&#20986;&#27979;&#35797;&#30340;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#12290;&#25105;&#20204;&#23558;&#25152;&#25552;&#20986;&#30340;&#27979;&#35797;&#24212;&#29992;&#20110;&#19968;&#20010;&#20154;&#33080;&#35782;&#21035;&#30740;&#31350;&#65292;&#20197;&#30830;&#23450;&#20116;&#20010;&#21442;&#19982;&#32773;&#32452;&#20043;&#38388;&#30340;&#32479;&#35745;&#26174;&#33879;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ordinal scores occur commonly in medical imaging studies and in black-box forensic studies \citep{Phillips:2018}. To assess the accuracy of raters in the studies, one needs to estimate the receiver operating characteristic (ROC) curve while accounting for covariates of raters. In this paper, we propose a covariate-adjusted homogeneity test to determine differences in accuracy among multiple rater groups. We derived the theoretical results of the proposed test and conducted extensive simulation studies to evaluate the finite sample performance of the proposed test. Our proposed test is applied to a face recognition study to identify statistically significant differences among five participant groups.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#32034;&#20102;&#19968;&#31181;&#21152;&#26435;&#24179;&#22343;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#26041;&#26696;&#65292;&#24182;&#24314;&#31435;&#20102;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#25552;&#20379;&#20102;&#28176;&#36817;&#26377;&#25928;&#30340;&#22312;&#32447;&#25512;&#29702;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#24179;&#22343;&#26041;&#26696;&#65292;&#20855;&#26377;&#26368;&#20248;&#30340;&#32479;&#35745;&#36895;&#24230;&#21644;&#26377;&#21033;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.06915</link><description>&lt;p&gt;
&#21152;&#26435;&#24179;&#22343;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;: &#28176;&#36817;&#27491;&#24577;&#24615;&#21644;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
Weighted Averaged Stochastic Gradient Descent: Asymptotic Normality and Optimality. (arXiv:2307.06915v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06915
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#19968;&#31181;&#21152;&#26435;&#24179;&#22343;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#26041;&#26696;&#65292;&#24182;&#24314;&#31435;&#20102;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#25552;&#20379;&#20102;&#28176;&#36817;&#26377;&#25928;&#30340;&#22312;&#32447;&#25512;&#29702;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#24179;&#22343;&#26041;&#26696;&#65292;&#20855;&#26377;&#26368;&#20248;&#30340;&#32479;&#35745;&#36895;&#24230;&#21644;&#26377;&#21033;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#26159;&#29616;&#20195;&#32479;&#35745;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#31616;&#21333;&#21644;&#26368;&#27969;&#34892;&#30340;&#31639;&#27861;&#20043;&#19968;&#65292;&#30001;&#20110;&#20854;&#35745;&#31639;&#21644;&#20869;&#23384;&#25928;&#29575;&#32780;&#21463;&#21040;&#38738;&#30544;&#12290;&#22312;&#19981;&#21516;&#30340;&#24773;&#22659;&#19979;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;&#24179;&#22343;&#26041;&#26696;&#26469;&#21152;&#36895;SGD&#30340;&#25910;&#25947;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#19968;&#31181;&#29992;&#20110;SGD&#30340;&#36890;&#29992;&#24179;&#22343;&#26041;&#26696;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#31867;&#21152;&#26435;&#24179;&#22343;SGD&#35299;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#28176;&#36817;&#26377;&#25928;&#30340;&#22312;&#32447;&#25512;&#29702;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#24179;&#22343;&#26041;&#26696;&#65292;&#23637;&#29616;&#20986;&#26368;&#20248;&#30340;&#32479;&#35745;&#36895;&#24230;&#21644;&#26377;&#21033;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#24615;&#65292;&#20511;&#37492;&#20102;&#32447;&#24615;&#27169;&#22411;&#30340;&#38750;&#28176;&#36817;&#22343;&#26041;&#35823;&#24046;&#65288;MSE&#65289;&#30340;&#26368;&#20248;&#26435;&#37325;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic Gradient Descent (SGD) is one of the simplest and most popular algorithms in modern statistical and machine learning due to its computational and memory efficiency. Various averaging schemes have been proposed to accelerate the convergence of SGD in different settings. In this paper, we explore a general averaging scheme for SGD. Specifically, we establish the asymptotic normality of a broad range of weighted averaged SGD solutions and provide asymptotically valid online inference approaches. Furthermore, we propose an adaptive averaging scheme that exhibits both optimal statistical rate and favorable non-asymptotic convergence, drawing insights from the optimal weight for the linear model in terms of non-asymptotic mean squared error (MSE).
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#35780;&#20272;&#23884;&#20837;&#36136;&#37327;&#30340;&#19981;&#21516;&#26041;&#27861;&#65292;&#20851;&#27880;&#22914;&#20309;&#20197;&#31283;&#23450;&#30340;&#26041;&#24335;&#36827;&#34892;&#32447;&#24615;&#20998;&#31163;&#12290;&#20174;&#35843;&#26597;&#30340;&#25991;&#29486;&#21644;&#24341;&#20837;&#30340;&#26032;&#26041;&#27861;&#20013;&#65292;&#25105;&#20204;&#21487;&#20197;&#35780;&#20272;&#23884;&#20837;&#30340;&#36136;&#37327;&#65292;&#20174;&#32780;&#25552;&#39640;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#34920;&#29616;&#12290;(This work proposes new methods to evaluate the quality of embeddings, focusing on stable linear separation. From the surveyed literature and introduced novel methods, we can evaluate the quality of embeddings and improve the performance of unsupervised learning.)</title><link>http://arxiv.org/abs/2305.16562</link><description>&lt;p&gt;
&#26080;&#30417;&#30563;&#23884;&#20837;&#36136;&#37327;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Unsupervised Embedding Quality Evaluation. (arXiv:2305.16562v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16562
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#35780;&#20272;&#23884;&#20837;&#36136;&#37327;&#30340;&#19981;&#21516;&#26041;&#27861;&#65292;&#20851;&#27880;&#22914;&#20309;&#20197;&#31283;&#23450;&#30340;&#26041;&#24335;&#36827;&#34892;&#32447;&#24615;&#20998;&#31163;&#12290;&#20174;&#35843;&#26597;&#30340;&#25991;&#29486;&#21644;&#24341;&#20837;&#30340;&#26032;&#26041;&#27861;&#20013;&#65292;&#25105;&#20204;&#21487;&#20197;&#35780;&#20272;&#23884;&#20837;&#30340;&#36136;&#37327;&#65292;&#20174;&#32780;&#25552;&#39640;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#34920;&#29616;&#12290;(This work proposes new methods to evaluate the quality of embeddings, focusing on stable linear separation. From the surveyed literature and introduced novel methods, we can evaluate the quality of embeddings and improve the performance of unsupervised learning.)
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#23398;&#20064;&#65292;&#23588;&#20854;&#26159;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#26368;&#36817;&#22312;&#23398;&#26415;&#30028;&#24471;&#21040;&#20102;&#26174;&#33879;&#30340;&#21457;&#23637;&#12290;&#34429;&#28982;&#22312;&#21508;&#31181;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;&#25509;&#36817;&#30417;&#30563;&#23398;&#20064;&#27700;&#24179;&#30340;&#25104;&#26524;&#65292;&#20294;&#30001;&#20110;&#26080;&#30417;&#30563;&#38382;&#39064;&#30340;&#26412;&#36136;&#65292;&#23454;&#36341;&#20013;&#35757;&#32451;&#21644;&#35780;&#20272; SSL &#27169;&#22411;&#20173;&#28982;&#24456;&#22256;&#38590;&#12290;&#21363;&#20351;&#26159;&#20197;&#26377;&#30417;&#30563;&#30340;&#26041;&#24335;&#35757;&#32451;&#30340;&#32593;&#32476;&#65292;&#22312;&#36716;&#31227;&#21040;&#21478;&#19968;&#20010;&#39046;&#22495;&#26102;&#26159;&#21542;&#33021;&#22815;&#33391;&#22909;&#22320;&#34920;&#29616;&#65292;&#20063;&#24448;&#24448;&#19981;&#28165;&#26970;&#12290;&#36807;&#21435;&#30340;&#24037;&#20316;&#36890;&#24120;&#20165;&#38480;&#20110;&#35780;&#20272;&#23884;&#20837;&#20013;&#21253;&#21547;&#30340;&#20449;&#24687;&#37327;&#65292;&#36825;&#23545;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#33258;&#25105;&#30417;&#30563;&#23398;&#20064;&#26368;&#20026;&#30456;&#20851;&#12290;&#28982;&#32780;&#65292;&#36825;&#39033;&#24037;&#20316;&#36873;&#25321;&#20102;&#19981;&#21516;&#30340;&#26041;&#27861;&#65306;&#25105;&#20204;&#33021;&#21542;&#37327;&#21270;&#25968;&#25454;&#20013;&#22914;&#20309;&#20197;&#31283;&#23450;&#30340;&#26041;&#24335;&#36827;&#34892;&#32447;&#24615;&#20998;&#31163;&#65311;&#25105;&#20204;&#35843;&#26597;&#20102;&#30456;&#20851;&#30340;&#25991;&#29486;&#65292;&#24182;&#21457;&#29616;&#19977;&#31181;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#35780;&#20272;&#23884;&#20837;&#30340;&#36136;&#37327;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#36817;&#26399;&#23545;&#39640;&#32500;&#31354;&#38388;&#29702;&#35299;&#30340;&#26368;&#26032;&#36827;&#23637;&#30340;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unsupervised learning has recently significantly gained in popularity, especially with deep learning-based approaches. Despite numerous successes and approaching supervised-level performance on a variety of academic benchmarks, it is still hard to train and evaluate SSL models in practice due to the unsupervised nature of the problem. Even with networks trained in a supervised fashion, it is often unclear whether they will perform well when transferred to another domain.  Past works are generally limited to assessing the amount of information contained in embeddings, which is most relevant for self-supervised learning of deep neural networks. This works chooses to follow a different approach: can we quantify how easy it is to linearly separate the data in a stable way? We survey the literature and uncover three methods that could be potentially used for evaluating quality of representations. We also introduce one novel method based on recent advances in understanding the high-dimension
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#23376;&#39640;&#26031;&#28151;&#21512;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#29992;&#20110;&#22810;&#23610;&#24230;&#32858;&#31867;&#21644;&#28304;&#20998;&#31163;&#65292;&#36890;&#36807;&#21033;&#29992;&#23567;&#27874;&#25955;&#23556;&#21327;&#26041;&#24046;&#26469;&#25552;&#20379;&#38543;&#26426;&#36807;&#31243;&#30340;&#20302;&#32500;&#34920;&#31034;&#65292;&#33021;&#22815;&#21306;&#20998;&#19981;&#21516;&#30340;&#38750;&#39640;&#26031;&#38543;&#26426;&#36807;&#31243;&#65292;&#24182;&#22312;MRO&#25968;&#25454;&#38598;&#19978;&#23637;&#29616;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.16189</link><description>&lt;p&gt;
&#28779;&#26143;&#26102;&#38388;&#24207;&#21015;&#20998;&#35299;&#65306;&#19968;&#31181;&#22810;&#23610;&#24230;&#23884;&#22871;&#26041;&#27861;&#20013;&#30340;&#22240;&#23376;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Martian time-series unraveled: A multi-scale nested approach with factorial variational autoencoders. (arXiv:2305.16189v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16189
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#23376;&#39640;&#26031;&#28151;&#21512;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#29992;&#20110;&#22810;&#23610;&#24230;&#32858;&#31867;&#21644;&#28304;&#20998;&#31163;&#65292;&#36890;&#36807;&#21033;&#29992;&#23567;&#27874;&#25955;&#23556;&#21327;&#26041;&#24046;&#26469;&#25552;&#20379;&#38543;&#26426;&#36807;&#31243;&#30340;&#20302;&#32500;&#34920;&#31034;&#65292;&#33021;&#22815;&#21306;&#20998;&#19981;&#21516;&#30340;&#38750;&#39640;&#26031;&#38543;&#26426;&#36807;&#31243;&#65292;&#24182;&#22312;MRO&#25968;&#25454;&#38598;&#19978;&#23637;&#29616;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#30340;&#28304;&#20998;&#31163;&#28041;&#21450;&#36890;&#36807;&#28151;&#21512;&#25805;&#20316;&#35760;&#24405;&#30340;&#26410;&#30693;&#28304;&#20449;&#21495;&#30340;&#20998;&#35299;&#65292;&#20854;&#20013;&#23545;&#28304;&#30340;&#20808;&#39564;&#30693;&#35782;&#26377;&#38480;&#65292;&#20165;&#21487;&#20197;&#35775;&#38382;&#20449;&#21495;&#28151;&#21512;&#25968;&#25454;&#38598;&#12290;&#36825;&#20010;&#38382;&#39064;&#26412;&#36136;&#19978;&#26159;&#19981;&#36866;&#29992;&#30340;&#65292;&#24182;&#19988;&#36827;&#19968;&#27493;&#21463;&#21040;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#28304;&#23637;&#29616;&#20986;&#30340;&#22810;&#31181;&#26102;&#38388;&#23610;&#24230;&#30340;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#30340;&#22810;&#23610;&#24230;&#32858;&#31867;&#21644;&#28304;&#20998;&#31163;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#23567;&#27874;&#25955;&#23556;&#21327;&#26041;&#24046;&#26469;&#25552;&#20379;&#38543;&#26426;&#36807;&#31243;&#30340;&#20302;&#32500;&#34920;&#31034;&#65292;&#33021;&#22815;&#21306;&#20998;&#19981;&#21516;&#30340;&#38750;&#39640;&#26031;&#38543;&#26426;&#36807;&#31243;&#12290;&#22312;&#36825;&#20010;&#34920;&#31034;&#31354;&#38388;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#22240;&#23376;&#39640;&#26031;&#28151;&#21512;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#23427;&#34987;&#35757;&#32451;&#29992;&#20110;(1)&#27010;&#29575;&#22320;&#23545;&#19981;&#21516;&#26102;&#38388;&#23610;&#24230;&#19978;&#30340;&#28304;&#36827;&#34892;&#32858;&#31867;&#21644;&#36880;&#23618;&#38750;&#30417;&#30563;&#28304;&#20998;&#31163;&#65292;(2)&#22312;&#27599;&#20010;&#26102;&#38388;&#23610;&#24230;&#19978;&#25552;&#21462;&#20302;&#32500;&#34920;&#31034;&#65292;(3)&#23398;&#20064;&#28304;&#20449;&#21495;&#30340;&#22240;&#23376;&#34920;&#31034;&#65292;(4)&#22312;&#34920;&#31034;&#31354;&#38388;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#20197;&#29983;&#25104;&#26410;&#30693;&#28304;&#20449;&#21495;&#12290;&#25105;&#20204;&#22312;MRO&#19978;&#30340;&#19977;&#20010;&#39057;&#36947;&#30340;&#21487;&#35265;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#32467;&#26524;&#34920;&#26126;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#27604;&#30446;&#21069;&#26368;&#20808;&#36827;&#30340;&#25216;&#26415;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unsupervised source separation involves unraveling an unknown set of source signals recorded through a mixing operator, with limited prior knowledge about the sources, and only access to a dataset of signal mixtures. This problem is inherently ill-posed and is further challenged by the variety of time-scales exhibited by sources in time series data. Existing methods typically rely on a preselected window size that limits their capacity to handle multi-scale sources. To address this issue, instead of operating in the time domain, we propose an unsupervised multi-scale clustering and source separation framework by leveraging wavelet scattering covariances that provide a low-dimensional representation of stochastic processes, capable of distinguishing between different non-Gaussian stochastic processes. Nested within this representation space, we develop a factorial Gaussian-mixture variational autoencoder that is trained to (1) probabilistically cluster sources at different time-scales a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#38752;&#30340;&#31070;&#32463;&#32593;&#32476;&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#38024;&#23545;&#33258;&#28982;&#21457;&#29983;&#30340;&#27169;&#22411;&#21464;&#21270;&#25552;&#20379;&#39640;&#27010;&#29575;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.11997</link><description>&lt;p&gt;
&#20855;&#26377;&#27010;&#29575;&#20445;&#35777;&#30340;&#31070;&#32463;&#32593;&#32476;&#40065;&#26834;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Robust Counterfactual Explanations for Neural Networks With Probabilistic Guarantees. (arXiv:2305.11997v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11997
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#38752;&#30340;&#31070;&#32463;&#32593;&#32476;&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#38024;&#23545;&#33258;&#28982;&#21457;&#29983;&#30340;&#27169;&#22411;&#21464;&#21270;&#25552;&#20379;&#39640;&#27010;&#29575;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#31070;&#32463;&#32593;&#32476;&#21457;&#29616;&#20559;&#31227;&#65292;&#36890;&#36807;&#20351;&#29992;&#31283;&#23450;&#24615;&#24230;&#37327;&#26469;&#37327;&#21270;&#21453;&#20107;&#23454;&#35299;&#37322;&#23545;&#21487;&#33021;&#30340;&#27169;&#22411;&#21464;&#21270;&#30340;&#40065;&#26834;&#24615;&#12290;&#36890;&#36807;&#22312;&#21453;&#20107;&#23454;&#35299;&#37322;&#20248;&#21270;&#20013;&#24341;&#20837;&#27491;&#21017;&#21270;&#39033;&#26469;&#23558;&#29983;&#25104;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#38752;&#36817;&#25968;&#25454;&#27969;&#24418;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23545;&#33258;&#28982;&#21457;&#29983;&#30340;&#27169;&#22411;&#21464;&#21270;&#30340;&#39640;&#27010;&#29575;&#40065;&#26834;&#24615;&#12290;&#26032;&#30340;&#31639;&#27861;&#22312;&#21512;&#25104;&#21644;&#29616;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is an emerging interest in generating robust counterfactual explanations that would remain valid if the model is updated or changed even slightly. Towards finding robust counterfactuals, existing literature often assumes that the original model $m$ and the new model $M$ are bounded in the parameter space, i.e., $\|\text{Params}(M){-}\text{Params}(m)\|{&lt;}\Delta$. However, models can often change significantly in the parameter space with little to no change in their predictions or accuracy on the given dataset. In this work, we introduce a mathematical abstraction termed \emph{naturally-occurring} model change, which allows for arbitrary changes in the parameter space such that the change in predictions on points that lie on the data manifold is limited. Next, we propose a measure -- that we call \emph{Stability} -- to quantify the robustness of counterfactuals to potential model changes for differentiable models, e.g., neural networks. Our main contribution is to show that counter
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#21644;&#25439;&#22833;&#20989;&#25968;&#65292;&#33021;&#22815;&#26377;&#25928;&#23398;&#20064;&#22914;&#20309;&#35299;&#20915;NP-hard&#25512;&#29702;&#38382;&#39064;&#65292;&#24182;&#22312;&#31163;&#25955;&#22270;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#39564;&#35777;&#12290;&#21516;&#26102;&#21487;&#20197;&#25552;&#39640;&#25968;&#25454;&#25928;&#29575;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#20855;&#26377;&#23545;&#39044;&#27979;&#30340;&#25511;&#21046;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2305.07617</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#19982;&#36923;&#36753;&#25512;&#29702;&#30340;&#21487;&#25193;&#23637;&#32806;&#21512;
&lt;/p&gt;
&lt;p&gt;
Scalable Coupling of Deep Learning with Logical Reasoning. (arXiv:2305.07617v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07617
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#21644;&#25439;&#22833;&#20989;&#25968;&#65292;&#33021;&#22815;&#26377;&#25928;&#23398;&#20064;&#22914;&#20309;&#35299;&#20915;NP-hard&#25512;&#29702;&#38382;&#39064;&#65292;&#24182;&#22312;&#31163;&#25955;&#22270;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#39564;&#35777;&#12290;&#21516;&#26102;&#21487;&#20197;&#25552;&#39640;&#25968;&#25454;&#25928;&#29575;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#20855;&#26377;&#23545;&#39044;&#27979;&#30340;&#25511;&#21046;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23558;&#31163;&#25955;&#25512;&#29702;&#19982;&#31070;&#32463;&#32593;&#32476;&#28151;&#21512;&#30340;&#19981;&#26029;&#25506;&#32034;&#20013;&#65292;&#20986;&#29616;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#23545;&#31070;&#32463;&#32467;&#26500;&#20855;&#22791;&#20174;&#33258;&#28982;&#36755;&#20837;&#20013;&#23398;&#20064;&#22914;&#20309;&#35299;&#20915;&#31163;&#25955;&#25512;&#29702;&#25110;&#20248;&#21270;&#38382;&#39064;&#30340;&#20852;&#36259;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#31070;&#32463;&#32467;&#26500;&#20197;&#21450;&#19987;&#38376;&#29992;&#20110;&#23398;&#20064;&#34987;&#34920;&#31034;&#20026;&#31163;&#25955;&#22270;&#27169;&#22411;&#30340; NP-hard &#25512;&#29702;&#38382;&#39064;&#30340;&#32422;&#26463;&#21644;&#26631;&#20934;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;&#25105;&#20204;&#30340;&#25439;&#22833;&#20989;&#25968;&#35299;&#20915;&#20102; Besag &#30340;&#20266;&#23545;&#25968;&#20284;&#28982;&#30340;&#20027;&#35201;&#38480;&#21046;&#20043;&#19968;&#65292;&#33021;&#22815;&#23398;&#20064;&#39640;&#33021;&#37327;&#20989;&#25968;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#23427;&#33021;&#22815;&#26377;&#25928;&#22320;&#20174;&#33258;&#28982;&#36755;&#20837;&#20013;&#23398;&#20064;&#22914;&#20309;&#35299;&#20915; NP-hard &#25512;&#29702;&#38382;&#39064;&#65292;&#22914;&#31526;&#21495;&#12289;&#35270;&#35273;&#25110;&#22810;&#35299;&#25968;&#25968;&#29420;&#38382;&#39064;&#65292;&#20197;&#21450;&#34507;&#30333;&#36136;&#35774;&#35745;&#38382;&#39064;&#30340;&#33021;&#37327;&#20248;&#21270;&#24418;&#24335;&#65292;&#25552;&#39640;&#20102;&#25968;&#25454;&#25928;&#29575;&#12289;&#21487;&#35299;&#37322;&#24615;&#20197;&#21450;&#23545;&#39044;&#27979;&#30340; \textit{a posteriori} &#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the ongoing quest for hybridizing discrete reasoning with neural nets, there is an increasing interest in neural architectures that can learn how to solve discrete reasoning or optimization problems from natural inputs. In this paper, we introduce a scalable neural architecture and loss function dedicated to learning the constraints and criteria of NP-hard reasoning problems expressed as discrete Graphical Models. Our loss function solves one of the main limitations of Besag's pseudo-loglikelihood, enabling learning of high energies. We empirically show it is able to efficiently learn how to solve NP-hard reasoning problems from natural inputs as the symbolic, visual or many-solutions Sudoku problems as well as the energy optimization formulation of the protein design problem, providing data efficiency, interpretability, and \textit{a posteriori} control over predictions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35780;&#20998;&#24046;&#24322;&#27969;&#27169;&#22411;(SD flow)&#65292;&#23427;&#21487;&#20197;&#26368;&#20248;&#22320;&#20943;&#23569;&#20004;&#20010;&#20998;&#24067;&#20043;&#38388;&#30340;&#25955;&#24230;&#65292;&#21516;&#26102;&#35299;&#20915;Schr&#8203;&#8203;&#246;dinger&#26725;&#38382;&#39064;&#12290;&#19982;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#19981;&#21516;&#65292;&#23427;&#27809;&#26377;&#23545;&#20808;&#39564;&#20998;&#24067;&#26045;&#21152;&#20219;&#20309;&#38480;&#21046;&#65292;&#22312;&#19968;&#20123;&#22522;&#20934;&#25968;&#25454;&#38598;&#20013;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.12906</link><description>&lt;p&gt;
&#35780;&#20998;&#24046;&#20540;&#27969;&#27169;&#22411;&#29992;&#20110;&#38544;&#24335;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
The Score-Difference Flow for Implicit Generative Modeling. (arXiv:2304.12906v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12906
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35780;&#20998;&#24046;&#24322;&#27969;&#27169;&#22411;(SD flow)&#65292;&#23427;&#21487;&#20197;&#26368;&#20248;&#22320;&#20943;&#23569;&#20004;&#20010;&#20998;&#24067;&#20043;&#38388;&#30340;&#25955;&#24230;&#65292;&#21516;&#26102;&#35299;&#20915;Schr&#8203;&#8203;&#246;dinger&#26725;&#38382;&#39064;&#12290;&#19982;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#19981;&#21516;&#65292;&#23427;&#27809;&#26377;&#23545;&#20808;&#39564;&#20998;&#24067;&#26045;&#21152;&#20219;&#20309;&#38480;&#21046;&#65292;&#22312;&#19968;&#20123;&#22522;&#20934;&#25968;&#25454;&#38598;&#20013;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38544;&#24335;&#29983;&#25104;&#24314;&#27169;(IGM)&#26088;&#22312;&#29983;&#25104;&#31526;&#21512;&#30446;&#26631;&#25968;&#25454;&#20998;&#24067;&#29305;&#24449;&#30340;&#21512;&#25104;&#25968;&#25454;&#26679;&#26412;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;(&#20363;&#22914;&#35780;&#20998;&#21305;&#37197;&#32593;&#32476;&#12289;&#25193;&#25955;&#27169;&#22411;)&#20174;&#36890;&#36807;&#29615;&#22659;&#31354;&#38388;&#20013;&#30340;&#21160;&#24577;&#25200;&#21160;&#25110;&#27969;&#23558;&#21512;&#25104;&#28304;&#25968;&#25454;&#25512;&#21521;&#30446;&#26631;&#20998;&#24067;&#30340;&#35282;&#24230;&#35299;&#20915;&#20102;IGM&#38382;&#39064;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#20219;&#24847;&#30446;&#26631;&#21644;&#28304;&#20998;&#24067;&#20043;&#38388;&#30340;&#35780;&#20998;&#24046;&#24322;(SD)&#20316;&#20026;&#27969;&#65292;&#23427;&#21487;&#20197;&#26368;&#20248;&#22320;&#20943;&#23569;&#23427;&#20204;&#20043;&#38388;&#30340;Kullback-Leibler&#25955;&#24230;&#65292;&#21516;&#26102;&#35299;&#20915;Schr&#8203;&#8203;&#246;dinger&#26725;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;SD&#27969;&#24212;&#29992;&#20110;&#26041;&#20415;&#30340;&#20195;&#29702;&#20998;&#24067;&#65292;&#24403;&#19988;&#20165;&#24403;&#21407;&#22987;&#20998;&#24067;&#23545;&#40784;&#26102;&#65292;&#23427;&#20204;&#26159;&#23545;&#40784;&#30340;&#12290;&#25105;&#20204;&#22312;&#26576;&#20123;&#26465;&#20214;&#19979;&#23637;&#31034;&#20102;&#36825;&#31181;&#20844;&#24335;&#19982;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#30340;&#24418;&#24335;&#19968;&#33268;&#24615;&#12290;&#28982;&#32780;&#65292;&#19982;&#25193;&#25955;&#27169;&#22411;&#19981;&#21516;&#65292;SD&#27969;&#27809;&#26377;&#23545;&#20808;&#39564;&#20998;&#24067;&#26045;&#21152;&#20219;&#20309;&#38480;&#21046;&#12290;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#22312;&#26080;&#38480;&#36776;&#21035;&#22120;&#33021;&#21147;&#30340;&#26497;&#38480;&#19979;&#65292;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;&#35757;&#32451;&#21253;&#21547;SD&#27969;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;SD&#27969;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#20248;&#20110;&#20808;&#21069;&#30340;&#26368;&#26032;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Implicit generative modeling (IGM) aims to produce samples of synthetic data matching the characteristics of a target data distribution. Recent work (e.g. score-matching networks, diffusion models) has approached the IGM problem from the perspective of pushing synthetic source data toward the target distribution via dynamical perturbations or flows in the ambient space. We introduce the score difference (SD) between arbitrary target and source distributions as a flow that optimally reduces the Kullback-Leibler divergence between them while also solving the Schr\"odinger bridge problem. We apply the SD flow to convenient proxy distributions, which are aligned if and only if the original distributions are aligned. We demonstrate the formal equivalence of this formulation to denoising diffusion models under certain conditions. However, unlike diffusion models, SD flow places no restrictions on the prior distribution. We also show that the training of generative adversarial networks includ
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Follow-the-regularized-leader&#31639;&#27861;&#30340;&#19977;&#37325;&#19990;&#30028;&#20998;&#26512;&#65292;&#24182;&#35777;&#26126;&#35813;&#31639;&#27861;&#20351;&#29992;&#36127;&#29109;&#27491;&#21017;&#21270;&#22120;&#21487;&#20197;&#22312;&#32447;&#24615;bandit&#38382;&#39064;&#20013;&#33719;&#24471;&#26368;&#20339;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2303.06825</link><description>&lt;p&gt;
&#20351;&#29992;Follow-the-regularized-leader&#31639;&#27861;&#30340;&#32447;&#24615;bandits&#38382;&#39064;&#30340;&#19977;&#37325;&#19990;&#30028;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Best-of-three-worlds Analysis for Linear Bandits with Follow-the-regularized-leader Algorithm. (arXiv:2303.06825v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06825
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Follow-the-regularized-leader&#31639;&#27861;&#30340;&#19977;&#37325;&#19990;&#30028;&#20998;&#26512;&#65292;&#24182;&#35777;&#26126;&#35813;&#31639;&#27861;&#20351;&#29992;&#36127;&#29109;&#27491;&#21017;&#21270;&#22120;&#21487;&#20197;&#22312;&#32447;&#24615;bandit&#38382;&#39064;&#20013;&#33719;&#24471;&#26368;&#20339;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32447;&#24615;bandit&#38382;&#39064;&#22312;&#38543;&#26426;&#21644;&#23545;&#25239;&#29615;&#22659;&#20013;&#24050;&#32463;&#30740;&#31350;&#20102;&#24456;&#22810;&#24180;&#12290;&#35774;&#35745;&#19968;&#20010;&#21487;&#20197;&#22312;&#19981;&#30693;&#36947;&#25439;&#22833;&#31867;&#22411;&#30340;&#24773;&#20917;&#19979;&#20248;&#21270;&#29615;&#22659;&#30340;&#31639;&#27861;&#65292;&#24341;&#36215;&#20102;&#24456;&#22810;&#20852;&#36259;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#36890;&#36807;&#20027;&#21160;&#26816;&#27979;&#25439;&#22833;&#31867;&#22411;&#65292;&#28982;&#21518;&#22312;&#38024;&#23545;&#29305;&#23450;&#29615;&#22659;&#35774;&#35745;&#30340;&#19981;&#21516;&#31639;&#27861;&#20043;&#38388;&#20999;&#25442;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#38656;&#35201;&#31934;&#24515;&#35774;&#35745;&#20197;&#22312;&#25152;&#26377;&#29615;&#22659;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;Follow-the-regularized-leader&#65288;FTRL&#65289;&#26159;&#21478;&#19968;&#31181;&#27969;&#34892;&#30340;&#31639;&#27861;&#31867;&#22411;&#65292;&#21487;&#20197;&#36866;&#24212;&#19981;&#21516;&#30340;&#29615;&#22659;&#12290;&#19982;&#26816;&#27979;&#24182;&#20999;&#25442;&#31867;&#22411;&#30456;&#27604;&#65292;&#35813;&#31639;&#27861;&#35774;&#35745;&#31616;&#21333;&#65292;&#36951;&#25022;&#30028;&#38480;&#22312;&#20256;&#32479;&#30340;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#20013;&#34987;&#35777;&#26126;&#26159;&#26368;&#20248;&#30340;&#12290;&#20026;&#32447;&#24615;bandit&#35774;&#35745;&#19968;&#31181;FTRL&#31867;&#22411;&#30340;&#31639;&#27861;&#26159;&#19968;&#20010;&#38271;&#26399;&#23384;&#22312;&#30340;&#37325;&#35201;&#38382;&#39064;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;&#20351;&#29992;&#36127;&#29109;&#27491;&#21017;&#21270;&#22120;&#30340;FTRL&#31639;&#27861;&#21487;&#20197;&#23454;&#29616;&#32447;&#24615;bandit&#38382;&#39064;&#30340;&#26368;&#20339;&#19977;&#37325;&#19990;&#30028;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
The linear bandit problem has been studied for many years in both stochastic and adversarial settings. Designing an algorithm that can optimize the environment without knowing the loss type attracts lots of interest. \citet{LeeLWZ021} propose an algorithm that actively detects the loss type and then switches between different algorithms specially designed for specific settings. However, such an approach requires meticulous designs to perform well in all environments. Follow-the-regularized-leader (FTRL) is another type of popular algorithm that can adapt to different environments. This algorithm is of simple design and the regret bounds are shown to be optimal in traditional multi-armed bandit problems compared with the detect-switch type. Designing an FTRL-type algorithm for linear bandits is an important question that has been open for a long time. In this paper, we prove that the FTRL algorithm with a negative entropy regularizer can achieve the best-of-three-world results for the l
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#29992;&#20110;&#40065;&#26834;&#30340;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#65292;&#24182;&#22312;&#21463;&#27745;&#26579;&#30340;&#25968;&#25454;&#27969;&#20013;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#34920;&#29616;&#20248;&#24322;&#65292;&#21516;&#26102;&#30830;&#20445;&#20102;&#31283;&#23450;&#24615;&#24182;&#20943;&#23569;&#24322;&#24120;&#20540;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2302.00422</link><description>&lt;p&gt;
&#40065;&#26834;&#30340;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Robust online active learning. (arXiv:2302.00422v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00422
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#29992;&#20110;&#40065;&#26834;&#30340;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#65292;&#24182;&#22312;&#21463;&#27745;&#26579;&#30340;&#25968;&#25454;&#27969;&#20013;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#34920;&#29616;&#20248;&#24322;&#65292;&#21516;&#26102;&#30830;&#20445;&#20102;&#31283;&#23450;&#24615;&#24182;&#20943;&#23569;&#24322;&#24120;&#20540;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24037;&#19994;&#24212;&#29992;&#20013;&#65292;&#33719;&#24471;&#26631;&#35760;&#30340;&#35266;&#27979;&#25968;&#25454;&#24182;&#19981;&#31616;&#21333;&#65292;&#36890;&#24120;&#38656;&#35201;&#20154;&#24037;&#19987;&#23478;&#24178;&#39044;&#25110;&#20351;&#29992;&#26114;&#36149;&#30340;&#27979;&#35797;&#35774;&#22791;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20027;&#21160;&#23398;&#20064;&#21487;&#20197;&#22823;&#22823;&#25552;&#39640;&#25311;&#21512;&#27169;&#22411;&#26102;&#26368;&#20449;&#24687;&#25968;&#25454;&#28857;&#30340;&#24314;&#35758;&#12290;&#20943;&#23569;&#27169;&#22411;&#24320;&#21457;&#25152;&#38656;&#30340;&#35266;&#27979;&#25968;&#25454;&#25968;&#37327;&#21487;&#20197;&#20943;&#36731;&#35757;&#32451;&#25152;&#38656;&#30340;&#35745;&#31639;&#36127;&#25285;&#21644;&#26631;&#35760;&#30456;&#20851;&#30340;&#25805;&#20316;&#25903;&#20986;&#12290;&#29305;&#21035;&#26159;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#65292;&#22312;&#38656;&#35201;&#22312;&#26497;&#30701;&#26102;&#38388;&#20869;&#20915;&#23450;&#26159;&#21542;&#33719;&#21462;&#25968;&#25454;&#28857;&#26631;&#35760;&#30340;&#39640;&#23481;&#37327;&#29983;&#20135;&#36807;&#31243;&#20013;&#38750;&#24120;&#26377;&#29992;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#26368;&#36817;&#33268;&#21147;&#20110;&#24320;&#21457;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#31574;&#30053;&#65292;&#20294;&#22312;&#23384;&#22312;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#36825;&#20123;&#26041;&#27861;&#30340;&#34892;&#20026;&#20173;&#26410;&#24471;&#21040;&#24443;&#24213;&#30740;&#31350;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#22312;&#32447;&#20027;&#21160;&#32447;&#24615;&#22238;&#24402;&#22312;&#21463;&#27745;&#26579;&#30340;&#25968;&#25454;&#27969;&#20013;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#29992;&#20110;&#40065;&#26834;&#30340;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#65292;&#21516;&#26102;&#20445;&#35777;&#31283;&#23450;&#24615;&#24182;&#20943;&#23569;&#24322;&#24120;&#20540;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many industrial applications, obtaining labeled observations is not straightforward as it often requires the intervention of human experts or the use of expensive testing equipment. In these circumstances, active learning can be highly beneficial in suggesting the most informative data points to be used when fitting a model. Reducing the number of observations needed for model development alleviates both the computational burden required for training and the operational expenses related to labeling. Online active learning, in particular, is useful in high-volume production processes where the decision about the acquisition of the label for a data point needs to be taken within an extremely short time frame. However, despite the recent efforts to develop online active learning strategies, the behavior of these methods in the presence of outliers has not been thoroughly examined. In this work, we investigate the performance of online active linear regression in contaminated data strea
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#32771;&#34385;&#22810;&#31181;&#20449;&#24687;&#35770;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#22312;&#38543;&#26426;&#20984;&#20248;&#21270;&#39046;&#22495;&#20013;&#65292;&#27809;&#26377;&#19968;&#20010;"&#20449;&#24687;&#35770;"&#26694;&#26550;&#33021;&#22815;&#24314;&#31435;&#26799;&#24230;&#19979;&#38477;&#30340;&#26368;&#23567;&#26368;&#22823;&#36895;&#29575;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#20998;&#26512;&#19968;&#31181;&#24120;&#35265;&#30340;&#31574;&#30053;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#39640;&#26031;&#22122;&#22768;&#30772;&#22351;&#36845;&#20195;&#30340;&#26041;&#27861;&#20063;&#26080;&#27861;&#24314;&#31435;&#26368;&#23567;&#26368;&#22823;&#36895;&#29575;&#12290;&#36825;&#20123;&#32467;&#26524;&#34920;&#26126;&#65292;&#38656;&#35201;&#26032;&#30340;&#24605;&#36335;&#26469;&#20998;&#26512;&#20351;&#29992;&#20449;&#24687;&#35770;&#25216;&#26415;&#30340;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2212.13556</link><description>&lt;p&gt;
&#12298;&#38543;&#26426;&#20984;&#20248;&#21270;&#20013;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#30340;&#20449;&#24687;&#35770;&#27867;&#21270;&#30028;&#38480;&#30340;&#23616;&#38480;&#24615;&#12299;
&lt;/p&gt;
&lt;p&gt;
Limitations of Information-Theoretic Generalization Bounds for Gradient Descent Methods in Stochastic Convex Optimization. (arXiv:2212.13556v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.13556
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#32771;&#34385;&#22810;&#31181;&#20449;&#24687;&#35770;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#22312;&#38543;&#26426;&#20984;&#20248;&#21270;&#39046;&#22495;&#20013;&#65292;&#27809;&#26377;&#19968;&#20010;"&#20449;&#24687;&#35770;"&#26694;&#26550;&#33021;&#22815;&#24314;&#31435;&#26799;&#24230;&#19979;&#38477;&#30340;&#26368;&#23567;&#26368;&#22823;&#36895;&#29575;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#20998;&#26512;&#19968;&#31181;&#24120;&#35265;&#30340;&#31574;&#30053;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#39640;&#26031;&#22122;&#22768;&#30772;&#22351;&#36845;&#20195;&#30340;&#26041;&#27861;&#20063;&#26080;&#27861;&#24314;&#31435;&#26368;&#23567;&#26368;&#22823;&#36895;&#29575;&#12290;&#36825;&#20123;&#32467;&#26524;&#34920;&#26126;&#65292;&#38656;&#35201;&#26032;&#30340;&#24605;&#36335;&#26469;&#20998;&#26512;&#20351;&#29992;&#20449;&#24687;&#35770;&#25216;&#26415;&#30340;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33267;&#20170;&#20026;&#27490;&#65292;&#22312;&#38543;&#26426;&#20984;&#20248;&#21270;&#35774;&#32622;&#20013;&#65292;&#27809;&#26377;&#35777;&#26126;&#8220;&#20449;&#24687;&#35770;&#8221;&#26694;&#26550;&#33021;&#22815;&#24314;&#31435;&#26799;&#24230;&#19979;&#38477;&#30340;&#26368;&#23567;&#26368;&#22823;&#36895;&#29575;&#20197;&#25512;&#26029;&#27867;&#21270;&#35823;&#24046;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#36890;&#36807;&#20960;&#31181;&#29616;&#26377;&#30340;&#20449;&#24687;&#35770;&#26694;&#26550;&#26469;&#24314;&#31435;&#36825;&#26679;&#30340;&#36895;&#29575;&#65306;&#36755;&#20837;-&#36755;&#20986;&#20114;&#20449;&#24687;&#30028;&#38480;&#12289;&#26465;&#20214;&#20114;&#20449;&#24687;&#30028;&#38480;&#21450;&#20854;&#21464;&#20307;&#12289;PAC-Bayes&#30028;&#38480;&#21644;&#26368;&#36817;&#30340;&#26465;&#20214;&#21464;&#20307;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;&#30028;&#38480;&#22343;&#26080;&#27861;&#24314;&#31435;&#26368;&#23567;&#26368;&#22823;&#36895;&#29575;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#22312;&#30740;&#31350;&#26799;&#24230;&#26041;&#27861;&#20013;&#24120;&#29992;&#30340;&#19968;&#31181;&#31574;&#30053;&#65292;&#21363;&#36890;&#36807;&#39640;&#26031;&#22122;&#22768;&#30772;&#22351;&#26368;&#32456;&#30340;&#36845;&#20195;&#65292;&#20174;&#32780;&#20135;&#29983;&#22122;&#22768;&#30340;&#8220;&#20195;&#29702;&#8221;&#31639;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#26080;&#27861;&#36890;&#36807;&#23545;&#36825;&#20123;&#20195;&#29702;&#31639;&#27861;&#30340;&#20998;&#26512;&#24314;&#31435;&#26368;&#23567;&#26368;&#22823;&#36895;&#29575;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#38656;&#35201;&#26032;&#30340;&#24605;&#36335;&#26469;&#20998;&#26512;&#20351;&#29992;&#20449;&#24687;&#35770;&#25216;&#26415;&#30340;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
To date, no "information-theoretic" frameworks for reasoning about generalization error have been shown to establish minimax rates for gradient descent in the setting of stochastic convex optimization. In this work, we consider the prospect of establishing such rates via several existing information-theoretic frameworks: input-output mutual information bounds, conditional mutual information bounds and variants, PAC-Bayes bounds, and recent conditional variants thereof. We prove that none of these bounds are able to establish minimax rates. We then consider a common tactic employed in studying gradient methods, whereby the final iterate is corrupted by Gaussian noise, producing a noisy "surrogate" algorithm. We prove that minimax rates cannot be established via the analysis of such surrogates. Our results suggest that new ideas are required to analyze gradient descent using information-theoretic techniques.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#28145;&#24230;&#40654;&#26364;&#32593;&#32476;&#23545;EEG&#30340;&#24212;&#29992;&#65292;&#25506;&#35752;&#20102;&#32593;&#32476;&#22823;&#23567;&#12289;&#31471;&#21040;&#31471;&#33021;&#21147;&#12289;&#27169;&#22411;&#35757;&#32451;&#23545;&#27169;&#22411;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#27604;&#36739;&#20102;&#20854;&#19982;&#22522;&#20110;&#40654;&#26364;&#20960;&#20309;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2212.10426</link><description>&lt;p&gt;
EEG&#35299;&#30721;&#30340;&#28145;&#24230;&#40654;&#26364;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Deep Riemannian Networks for EEG Decoding. (arXiv:2212.10426v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.10426
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#28145;&#24230;&#40654;&#26364;&#32593;&#32476;&#23545;EEG&#30340;&#24212;&#29992;&#65292;&#25506;&#35752;&#20102;&#32593;&#32476;&#22823;&#23567;&#12289;&#31471;&#21040;&#31471;&#33021;&#21147;&#12289;&#27169;&#22411;&#35757;&#32451;&#23545;&#27169;&#22411;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#27604;&#36739;&#20102;&#20854;&#19982;&#22522;&#20110;&#40654;&#26364;&#20960;&#20309;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#22312;&#30005;&#33041;&#33041;&#30005;&#22270;&#65288;EEG&#65289;&#35299;&#30721;&#20219;&#21153;&#20013;&#65292;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#36890;&#24120;&#26159;&#30001;&#28145;&#24230;&#23398;&#20064;&#25110;&#22522;&#20110;&#40654;&#26364;&#20960;&#20309;&#30340;&#35299;&#30721;&#22120;&#23454;&#29616;&#30340;&#12290;&#26368;&#36817;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#20154;&#23545;&#28145;&#24230;&#40654;&#26364;&#32593;&#32476;&#65288;DRNs&#65289;&#20135;&#29983;&#20102;&#20852;&#36259;&#65292;&#21487;&#33021;&#32467;&#21512;&#20102;&#20043;&#21069;&#20004;&#31867;&#26041;&#27861;&#30340;&#20248;&#28857;&#12290;&#28982;&#32780;&#65292;&#36824;&#26377;&#19968;&#31995;&#21015;&#38382;&#39064;&#38656;&#35201;&#36827;&#19968;&#27493;&#27934;&#23519;&#65292;&#20197;&#38138;&#24179;DRNs&#22312;EEG&#20013;&#26356;&#24191;&#27867;&#24212;&#29992;&#30340;&#36947;&#36335;&#12290;&#36825;&#20123;&#38382;&#39064;&#21253;&#25324;&#26550;&#26500;&#35774;&#35745;&#38382;&#39064;&#65292;&#22914;&#32593;&#32476;&#22823;&#23567;&#21644;&#31471;&#21040;&#31471;&#33021;&#21147;&#65292;&#20197;&#21450;&#27169;&#22411;&#35757;&#32451;&#38382;&#39064;&#12290;&#36825;&#20123;&#22240;&#32032;&#22914;&#20309;&#24433;&#21709;&#27169;&#22411;&#24615;&#33021;&#23578;&#26410;&#34987;&#25506;&#32034;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#32593;&#32476;&#20013;&#30340;&#25968;&#25454;&#22914;&#20309;&#36716;&#25442;&#65292;&#20197;&#21450;&#26159;&#21542;&#19982;&#20256;&#32479;&#30340;EEG&#35299;&#30721;&#30456;&#20851;&#20063;&#19981;&#28165;&#26970;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#20998;&#26512;&#20855;&#26377;&#24191;&#27867;&#36229;&#21442;&#25968;&#30340;DRNs&#26469;&#22880;&#23450;&#36825;&#20123;&#20027;&#39064;&#39046;&#22495;&#30340;&#22522;&#30784;&#12290;&#20351;&#29992;&#20004;&#20010;&#20844;&#20849;EEG&#25968;&#25454;&#38598;&#27979;&#35797;&#20102;&#32593;&#32476;&#65292;&#24182;&#19982;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;&#40654;&#26364;&#20960;&#20309;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
State-of-the-art performance in electroencephalography (EEG) decoding tasks is currently often achieved with either Deep-Learning or Riemannian-Geometry-based decoders. Recently, there is growing interest in Deep Riemannian Networks (DRNs) possibly combining the advantages of both previous classes of methods. However, there are still a range of topics where additional insight is needed to pave the way for a more widespread application of DRNs in EEG. These include architecture design questions such as network size and end-to-end ability as well as model training questions. How these factors affect model performance has not been explored. Additionally, it is not clear how the data within these networks is transformed, and whether this would correlate with traditional EEG decoding. Our study aims to lay the groundwork in the area of these topics through the analysis of DRNs for EEG with a wide range of hyperparameters. Networks were tested on two public EEG datasets and compared with sta
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#31232;&#26377;&#20107;&#20214;&#30340;&#26032;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#65292;&#22522;&#20110;&#25910;&#38598;&#21040;&#30340;&#26102;&#38388;&#19981;&#21464;&#21160;&#24577;&#31995;&#32479;&#30340;&#25968;&#25454;&#65292;&#26500;&#24314;&#20102;&#21472;&#21152;&#25968;&#25454;&#38598;&#21644;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#25581;&#31034;&#22312;&#21464;&#37327;&#31532;&#19968;&#27425;&#32463;&#21382;&#20302;&#27010;&#29575;&#23454;&#29616;&#26102;&#25165;&#20250;&#26174;&#29616;&#30340;&#22240;&#26524;&#20851;&#31995;&#65292;&#20855;&#26377;&#24456;&#22909;&#30340;&#21487;&#34892;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;</title><link>http://arxiv.org/abs/2211.16596</link><description>&lt;p&gt;
&#38754;&#21521;&#31232;&#26377;&#20107;&#20214;&#30340;&#21160;&#24577;&#22240;&#26524;&#21457;&#29616;&#65306;&#19968;&#31181;&#38750;&#21442;&#25968;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Towards Dynamic Causal Discovery with Rare Events: A Nonparametric Conditional Independence Test. (arXiv:2211.16596v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.16596
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#31232;&#26377;&#20107;&#20214;&#30340;&#26032;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#65292;&#22522;&#20110;&#25910;&#38598;&#21040;&#30340;&#26102;&#38388;&#19981;&#21464;&#21160;&#24577;&#31995;&#32479;&#30340;&#25968;&#25454;&#65292;&#26500;&#24314;&#20102;&#21472;&#21152;&#25968;&#25454;&#38598;&#21644;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#25581;&#31034;&#22312;&#21464;&#37327;&#31532;&#19968;&#27425;&#32463;&#21382;&#20302;&#27010;&#29575;&#23454;&#29616;&#26102;&#25165;&#20250;&#26174;&#29616;&#30340;&#22240;&#26524;&#20851;&#31995;&#65292;&#20855;&#26377;&#24456;&#22909;&#30340;&#21487;&#34892;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19982;&#31232;&#26377;&#20107;&#20214;&#30456;&#20851;&#32852;&#30340;&#22240;&#26524;&#29616;&#35937;&#22312;&#35768;&#22810;&#24037;&#31243;&#38382;&#39064;&#20013;&#37117;&#23384;&#22312;&#65292;&#20363;&#22914;&#38024;&#23545;&#39118;&#38505;&#30340;&#23433;&#20840;&#20998;&#26512;&#12289;&#20107;&#25925;&#20998;&#26512;&#21644;&#39044;&#38450;&#20197;&#21450;&#26497;&#20540;&#29702;&#35770;&#31561;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#24448;&#24448;&#26080;&#27861;&#21457;&#29616;&#22312;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#30340;&#21407;&#22240;&#32852;&#31995;&#65292;&#29305;&#21035;&#26159;&#22312;&#21464;&#21160;&#29615;&#22659;&#19979;&#65292;&#20165;&#22312;&#21464;&#37327;&#31532;&#19968;&#27425;&#32463;&#21382;&#20302;&#27010;&#29575;&#23454;&#29616;&#26102;&#25165;&#20250;&#26174;&#29616;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#29420;&#31435;&#24615;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#21457;&#29983;&#31232;&#26377;&#20294;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#30340;&#26102;&#38388;&#19981;&#21464;&#21160;&#24577;&#31995;&#32479;&#25910;&#38598;&#30340;&#25968;&#25454;&#20013;&#36827;&#34892;&#22240;&#26524;&#25506;&#32034;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#21033;&#29992;&#24213;&#23618;&#25968;&#25454;&#30340;&#26102;&#38388;&#19981;&#21464;&#24615;&#26469;&#26500;&#24314;&#19968;&#20010;&#21472;&#21152;&#30340;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#25324;&#22312;&#19981;&#21516;&#26102;&#38388;&#27493;&#39588;&#20043;&#21069;&#31232;&#26377;&#20107;&#20214;&#21457;&#29983;&#21069;&#31995;&#32479;&#29366;&#24577;&#30340;&#25968;&#25454;&#12290;&#28982;&#21518;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#22312;&#37325;&#26032;&#32452;&#32455;&#30340;&#25968;&#25454;&#19978;&#36827;&#34892;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#25105;&#20204;&#26041;&#27861;&#19968;&#33268;&#24615;&#30340;&#38750;&#28176;&#36817;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#65292;&#24182;&#39564;&#35777;&#20102;&#23427;&#22312;&#21508;&#31181;&#27169;&#25311;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal phenomena associated with rare events occur across a wide range of engineering problems, such as risk-sensitive safety analysis, accident analysis and prevention, and extreme value theory. However, current methods for causal discovery are often unable to uncover causal links, between random variables in a dynamic setting, that manifest only when the variables first experience low-probability realizations. To address this issue, we introduce a novel statistical independence test on data collected from time-invariant dynamical systems in which rare but consequential events occur. In particular, we exploit the time-invariance of the underlying data to construct a superimposed dataset of the system state before rare events happen at different timesteps. We then design a conditional independence test on the reorganized data. We provide non-asymptotic sample complexity bounds for the consistency of our method, and validate its performance across various simulated and real-world datase
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Refoqus&#30340;&#36164;&#28304;&#33410;&#32422;&#30340;&#37327;&#23376;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20248;&#21270;&#22120;&#65292;&#36890;&#36807;&#21516;&#26102;&#38543;&#26426;&#37319;&#26679;&#25968;&#25454;&#38598;&#21644;&#27979;&#37327;&#25805;&#20316;&#65292;&#33021;&#22815;&#20445;&#23384;&#22823;&#37327;&#36164;&#28304;&#12290;</title><link>http://arxiv.org/abs/2211.04965</link><description>&lt;p&gt;
&#36164;&#28304;&#33410;&#32422;&#30340;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#20248;&#21270;&#22120;
&lt;/p&gt;
&lt;p&gt;
Resource frugal optimizer for quantum machine learning. (arXiv:2211.04965v2 [quant-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.04965
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Refoqus&#30340;&#36164;&#28304;&#33410;&#32422;&#30340;&#37327;&#23376;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20248;&#21270;&#22120;&#65292;&#36890;&#36807;&#21516;&#26102;&#38543;&#26426;&#37319;&#26679;&#25968;&#25454;&#38598;&#21644;&#27979;&#37327;&#25805;&#20316;&#65292;&#33021;&#22815;&#20445;&#23384;&#22823;&#37327;&#36164;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#22686;&#24378;&#30340;&#25968;&#25454;&#31185;&#23398;&#65292;&#20063;&#31216;&#20026;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#65288;QML&#65289;&#65292;&#20316;&#20026;&#36817;&#26399;&#37327;&#23376;&#35745;&#31639;&#26426;&#30340;&#24212;&#29992;&#36234;&#26469;&#36234;&#21463;&#20851;&#27880;&#12290;&#21464;&#20998;QML&#31639;&#27861;&#22312;&#28041;&#21450;&#37327;&#23376;&#25968;&#25454;&#26102;&#26377;&#33021;&#21147;&#35299;&#20915;&#23454;&#38469;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#35757;&#32451;&#36825;&#20123;&#31639;&#27861;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#24182;&#38656;&#35201;&#23450;&#21046;&#30340;&#20248;&#21270;&#31243;&#24207;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;QML&#24212;&#29992;&#21487;&#33021;&#38656;&#35201;&#22823;&#37327;&#30340;&#37319;&#26679;&#27425;&#25968;&#65292;&#22240;&#20026;&#28041;&#21450;&#22823;&#22411;&#25968;&#25454;&#38598;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20513;&#23545;&#25968;&#25454;&#38598;&#21644;&#23450;&#20041;&#25439;&#22833;&#20989;&#25968;&#30340;&#27979;&#37327;&#25805;&#20316;&#36827;&#34892;&#21516;&#26102;&#38543;&#26426;&#37319;&#26679;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#39640;&#24230;&#36890;&#29992;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#21253;&#25324;&#20102;&#35768;&#22810;QML&#24212;&#29992;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#26500;&#24314;&#20854;&#26799;&#24230;&#30340;&#26080;&#20559;&#20272;&#35745;&#22120;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#25552;&#20986;&#19968;&#31181;&#31216;&#20026;Refoqus&#65288;&#36164;&#28304;&#33410;&#32422;&#30340;&#37327;&#23376;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20248;&#21270;&#22120;&#65289;&#30340;&#33410;&#32422;&#37319;&#26679;&#26799;&#24230;&#19979;&#38477;&#20248;&#21270;&#22120;&#12290;&#25105;&#20204;&#30340;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#65292;Refoqus&#33021;&#22815;&#33410;&#30465;&#20960;&#20010;&#25968;&#37327;&#32423;&#30340;&#36164;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantum-enhanced data science, also known as quantum machine learning (QML), is of growing interest as an application of near-term quantum computers. Variational QML algorithms have the potential to solve practical problems on real hardware, particularly when involving quantum data. However, training these algorithms can be challenging and calls for tailored optimization procedures. Specifically, QML applications can require a large shot-count overhead due to the large datasets involved. In this work, we advocate for simultaneous random sampling over both the dataset as well as the measurement operators that define the loss function. We consider a highly general loss function that encompasses many QML applications, and we show how to construct an unbiased estimator of its gradient. This allows us to propose a shot-frugal gradient descent optimizer called Refoqus (REsource Frugal Optimizer for QUantum Stochastic gradient descent). Our numerics indicate that Refoqus can save several orde
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22810;&#30446;&#26631;GFlowNets (MOGFNs) &#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#20013;&#29983;&#25104;&#22810;&#26679;&#30340;Pareto&#26368;&#20248;&#35299;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;GFlowNets&#65292;&#24182;&#24341;&#20837;&#20102;&#20004;&#31181;&#21464;&#20307;&#65306;MOGFN-PC&#21644;MOGFN-AL&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;MOGFNs&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#37117;&#34920;&#29616;&#20986;&#20102;&#24456;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2210.12765</link><description>&lt;p&gt;
&#22810;&#30446;&#26631;GFlowNets
&lt;/p&gt;
&lt;p&gt;
Multi-Objective GFlowNets. (arXiv:2210.12765v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.12765
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22810;&#30446;&#26631;GFlowNets (MOGFNs) &#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#20013;&#29983;&#25104;&#22810;&#26679;&#30340;Pareto&#26368;&#20248;&#35299;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;GFlowNets&#65292;&#24182;&#24341;&#20837;&#20102;&#20004;&#31181;&#21464;&#20307;&#65306;MOGFN-PC&#21644;MOGFN-AL&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;MOGFNs&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#37117;&#34920;&#29616;&#20986;&#20102;&#24456;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#22810;&#30446;&#26631;&#20248;&#21270;&#30340;&#32972;&#26223;&#19979;&#29983;&#25104;&#22810;&#26679;&#20505;&#36873;&#35299;&#30340;&#38382;&#39064;&#12290;&#22312;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#65292;&#22914;&#33647;&#29289;&#21457;&#29616;&#21644;&#26448;&#26009;&#35774;&#35745;&#65292;&#30446;&#26631;&#26159;&#29983;&#25104;&#21516;&#26102;&#20248;&#21270;&#19968;&#32452;&#28508;&#22312;&#20914;&#31361;&#30446;&#26631;&#30340;&#20505;&#36873;&#35299;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#30446;&#26631;&#24448;&#24448;&#26159;&#23545;&#26576;&#20010;&#24863;&#20852;&#36259;&#23646;&#24615;&#30340;&#19981;&#23436;&#21892;&#35780;&#20272;&#65292;&#22240;&#27492;&#29983;&#25104;&#22810;&#26679;&#20505;&#36873;&#35299;&#23545;&#20110;&#36827;&#34892;&#26114;&#36149;&#30340;&#19979;&#28216;&#35780;&#20272;&#26469;&#35828;&#26159;&#37325;&#35201;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#31216;&#20026;&#22810;&#30446;&#26631;GFlowNets&#65288;MOGFNs&#65289;&#65292;&#29992;&#20110;&#29983;&#25104;&#22810;&#26679;&#30340;Pareto&#26368;&#20248;&#35299;&#65292;&#22522;&#20110;GFlowNets&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#20004;&#20010;MOGFNs&#30340;&#21464;&#20307;&#65306;MOGFN-PC&#65292;&#23427;&#36890;&#36807;&#29305;&#23450;&#26631;&#37327;&#21270;&#20989;&#25968;&#23450;&#20041;&#20102;&#19968;&#20010;&#29420;&#31435;&#23376;&#38382;&#39064;&#30340;&#31995;&#21015;&#65292;&#24182;&#20351;&#29992;&#22870;&#21169;&#26465;&#20214;&#30340;GFlowNets&#36827;&#34892;&#24314;&#27169;&#65307;&#20197;&#21450;MOGFN-AL&#65292;&#23427;&#22312;&#20027;&#21160;&#23398;&#20064;&#24490;&#29615;&#20013;&#35299;&#20915;&#20102;&#19968;&#31995;&#21015;&#30001;&#25910;&#36141;&#20989;&#25968;&#23450;&#20041;&#30340;&#23376;&#38382;&#39064;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#21512;&#25104;&#21644;&#22522;&#20934;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;MOGFNs&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of generating diverse candidates in the context of Multi-Objective Optimization. In many applications of machine learning such as drug discovery and material design, the goal is to generate candidates which simultaneously optimize a set of potentially conflicting objectives. Moreover, these objectives are often imperfect evaluations of some underlying property of interest, making it important to generate diverse candidates to have multiple options for expensive downstream evaluations. We propose Multi-Objective GFlowNets (MOGFNs), a novel method for generating diverse Pareto optimal solutions, based on GFlowNets. We introduce two variants of MOGFNs: MOGFN-PC, which models a family of independent sub-problems defined by a scalarization function, with reward-conditional GFlowNets, and MOGFN-AL, which solves a sequence of sub-problems defined by an acquisition function in an active learning loop. Our experiments on wide variety of synthetic and benchmark tasks demonst
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#20108;&#32500;&#20989;&#25968;&#26102;&#38388;&#24207;&#21015;&#30340;&#21512;&#35268;&#39044;&#27979;&#24102;&#26041;&#27861;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#39044;&#27979;&#30340;&#27010;&#29575;&#26694;&#26550;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#25216;&#26415;&#12290;&#23558;&#20989;&#25968;&#33258;&#22238;&#24402;&#36807;&#31243;&#25193;&#23637;&#21040;&#35813;&#35774;&#32622;&#65292;&#24182;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#35777;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2207.13656</link><description>&lt;p&gt;
&#20108;&#32500;&#20989;&#25968;&#26102;&#38388;&#24207;&#21015;&#30340;&#21512;&#35268;&#39044;&#27979;&#24102;
&lt;/p&gt;
&lt;p&gt;
Conformal Prediction Bands for Two-Dimensional Functional Time Series. (arXiv:2207.13656v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.13656
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#20108;&#32500;&#20989;&#25968;&#26102;&#38388;&#24207;&#21015;&#30340;&#21512;&#35268;&#39044;&#27979;&#24102;&#26041;&#27861;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#39044;&#27979;&#30340;&#27010;&#29575;&#26694;&#26550;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#25216;&#26415;&#12290;&#23558;&#20989;&#25968;&#33258;&#22238;&#24402;&#36807;&#31243;&#25193;&#23637;&#21040;&#35813;&#35774;&#32622;&#65292;&#24182;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#35777;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#28436;&#21270;&#30340;&#34920;&#38754;&#21487;&#20197;&#34987;&#24314;&#27169;&#20026;&#20108;&#32500;&#20989;&#25968;&#26102;&#38388;&#24207;&#21015;&#65292;&#21033;&#29992;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#30340;&#24037;&#20855;&#12290;&#26412;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#20010;&#38024;&#23545;&#36825;&#31181;&#22797;&#26434;&#25968;&#25454;&#30340;&#39044;&#27979;&#26694;&#26550;&#12290;&#20027;&#35201;&#20851;&#27880;&#28857;&#26159;&#21512;&#35268;&#39044;&#27979;&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#37327;&#21270;&#39044;&#27979;&#38382;&#39064;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#30340;&#22810;&#21151;&#33021;&#38750;&#21442;&#25968;&#33539;&#20363;&#12290;&#22312;&#26368;&#36817;&#30340;&#20108;&#32500;&#20989;&#25968;&#26102;&#38388;&#24207;&#21015;&#21512;&#35268;&#39044;&#27979;&#30340;&#21464;&#31181;&#22522;&#30784;&#19978;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#27010;&#29575;&#39044;&#27979;&#26041;&#26696;&#65292;&#24182;&#23545;&#19968;&#38454;&#20989;&#25968;&#33258;&#22238;&#24402;&#36807;&#31243;&#22312;&#35813;&#35774;&#32622;&#19979;&#30340;&#25193;&#23637;&#36827;&#34892;&#20102;&#24314;&#35758;&#12290;&#24341;&#20837;&#20102;&#21518;&#32773;&#30340;&#20272;&#35745;&#25216;&#26415;&#65292;&#24182;&#36890;&#36807;&#39044;&#27979;&#21306;&#22495;&#26469;&#27604;&#36739;&#23427;&#20204;&#30340;&#24615;&#33021;&#12290;&#26368;&#21518;&#65292;&#23558;&#25152;&#25552;&#20986;&#30340;&#39044;&#27979;&#31243;&#24207;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#25216;&#26415;&#24212;&#29992;&#20110;&#40657;&#28023;&#26085;&#24120;&#28023;&#24179;&#38754;&#24322;&#24120;&#35266;&#27979;&#30340;&#30495;&#23454;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Time evolving surfaces can be modeled as two-dimensional Functional time series, exploiting the tools of Functional data analysis. Leveraging this approach, a forecasting framework for such complex data is developed. The main focus revolves around Conformal Prediction, a versatile nonparametric paradigm used to quantify uncertainty in prediction problems. Building upon recent variations of Conformal Prediction for Functional time series, a probabilistic forecasting scheme for two-dimensional functional time series is presented, while providing an extension of Functional Autoregressive Processes of order one to this setting. Estimation techniques for the latter process are introduced and their performance are compared in terms of the resulting prediction regions. Finally, the proposed forecasting procedure and the uncertainty quantification technique are applied to a real dataset, collecting daily observations of Sea Level Anomalies of the Black Sea
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Cal-PIT&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#19968;&#20010;&#27010;&#29575;-&#27010;&#29575;&#26144;&#23556;&#65292;&#35299;&#20915;&#20102;&#39044;&#27979;&#20998;&#24067;&#30340;&#35786;&#26029;&#21644;&#26657;&#20934;&#38382;&#39064;&#65292;&#26469;&#23454;&#29616;&#26377;&#26465;&#20214;&#26657;&#20934;&#12290;</title><link>http://arxiv.org/abs/2205.14568</link><description>&lt;p&gt;
&#36890;&#36807;&#27010;&#29575;-&#27010;&#29575;&#26144;&#23556;&#23454;&#29616;&#26377;&#26465;&#20214;&#26657;&#20934;&#30340;&#39044;&#27979;&#20998;&#24067;&#65306;&#22312;&#38134;&#27827;&#32418;&#31227;&#20272;&#35745;&#21644;&#27010;&#29575;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Conditionally Calibrated Predictive Distributions by Probability-Probability Map: Application to Galaxy Redshift Estimation and Probabilistic Forecasting. (arXiv:2205.14568v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.14568
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Cal-PIT&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#19968;&#20010;&#27010;&#29575;-&#27010;&#29575;&#26144;&#23556;&#65292;&#35299;&#20915;&#20102;&#39044;&#27979;&#20998;&#24067;&#30340;&#35786;&#26029;&#21644;&#26657;&#20934;&#38382;&#39064;&#65292;&#26469;&#23454;&#29616;&#26377;&#26465;&#20214;&#26657;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#23545;&#20110;&#35780;&#20272;AI&#31639;&#27861;&#30340;&#39044;&#27979;&#33021;&#21147;&#33267;&#20851;&#37325;&#35201;&#12290;&#36807;&#21435;&#30340;&#30740;&#31350;&#33268;&#21147;&#20110;&#25551;&#36848;&#30446;&#26631;&#21464;&#37327;$y \in \mathbb{R}$&#22312;&#32473;&#23450;&#22797;&#26434;&#36755;&#20837;&#29305;&#24449;$\mathbf{x} \in \mathcal{X}$&#30340;&#26465;&#20214;&#19979;&#30340;&#39044;&#27979;&#20998;&#24067;$F(y|\mathbf{x})$&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#39044;&#27979;&#20998;&#24067;&#65288;&#20363;&#22914;&#65292;&#24402;&#19968;&#21270;&#27969;&#21644;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65289;&#24448;&#24448;&#32570;&#20047;&#26465;&#20214;&#26657;&#20934;&#65292;&#21363;&#32473;&#23450;&#36755;&#20837;$\mathbf{x}$&#30340;&#20107;&#20214;&#21457;&#29983;&#30340;&#27010;&#29575;&#19982;&#39044;&#27979;&#27010;&#29575;&#26174;&#33879;&#19981;&#21516;&#12290;&#24403;&#21069;&#30340;&#26657;&#20934;&#26041;&#27861;&#19981;&#33021;&#23436;&#20840;&#35780;&#20272;&#21644;&#23454;&#26045;&#26377;&#26465;&#20214;&#26657;&#20934;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Cal-PIT&#30340;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#20174;&#26657;&#20934;&#25968;&#25454;&#20013;&#23398;&#20064;&#19968;&#20010;&#27010;&#29575;-&#27010;&#29575;&#26144;&#23556;&#26469;&#21516;&#26102;&#35299;&#20915;&#39044;&#27979;&#20998;&#24067;&#30340;&#35786;&#26029;&#21644;&#26657;&#20934;&#38382;&#39064;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#23545;&#27010;&#29575;&#31215;&#20998;&#21464;&#25442;&#20998;&#25968;&#36827;&#34892;$\mathbf{x}$&#30340;&#22238;&#24402;&#12290;&#20272;&#35745;&#30340;&#22238;&#24402;&#25552;&#20379;&#20102;&#23545;&#29305;&#24449;&#31354;&#38388;&#20013;&#26465;&#20214;&#35206;&#30422;&#30340;&#21487;&#35299;&#37322;&#35786;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty quantification is crucial for assessing the predictive ability of AI algorithms. Much research has been devoted to describing the predictive distribution (PD) $F(y|\mathbf{x})$ of a target variable $y \in \mathbb{R}$ given complex input features $\mathbf{x} \in \mathcal{X}$. However, off-the-shelf PDs (from, e.g., normalizing flows and Bayesian neural networks) often lack conditional calibration with the probability of occurrence of an event given input $\mathbf{x}$ being significantly different from the predicted probability. Current calibration methods do not fully assess and enforce conditionally calibrated PDs. Here we propose \texttt{Cal-PIT}, a method that addresses both PD diagnostics and recalibration by learning a single probability-probability map from calibration data. The key idea is to regress probability integral transform scores against $\mathbf{x}$. The estimated regression provides interpretable diagnostics of conditional coverage across the feature space. 
&lt;/p&gt;</description></item></channel></rss>