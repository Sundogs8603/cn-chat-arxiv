<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>VITS&#26159;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#21464;&#20998;&#25512;&#29702;&#30340;&#26032;&#31639;&#27861;&#65292;&#29992;&#20110;&#24773;&#22659;&#32972;&#31163;&#38382;&#39064;&#30340;&#27748;&#26222;&#26862;&#25277;&#26679;&#12290;&#23427;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#21518;&#39564;&#36817;&#20284;&#65292;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#24182;&#19988;&#22312;&#32447;&#24615;&#24773;&#22659;&#32972;&#31163;&#38382;&#39064;&#20013;&#36798;&#21040;&#19982;&#20256;&#32479;TS&#30456;&#21516;&#38454;&#25968;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2307.10167</link><description>&lt;p&gt;
VITS: &#22522;&#20110;&#21464;&#20998;&#25512;&#29702;&#30340;&#27748;&#26222;&#26862;&#25277;&#26679;&#29992;&#20110;&#24773;&#22659;&#32972;&#31163;&#38382;&#39064;&#30340;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
VITS : Variational Inference Thomson Sampling for contextual bandits. (arXiv:2307.10167v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10167
&lt;/p&gt;
&lt;p&gt;
VITS&#26159;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#21464;&#20998;&#25512;&#29702;&#30340;&#26032;&#31639;&#27861;&#65292;&#29992;&#20110;&#24773;&#22659;&#32972;&#31163;&#38382;&#39064;&#30340;&#27748;&#26222;&#26862;&#25277;&#26679;&#12290;&#23427;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#21518;&#39564;&#36817;&#20284;&#65292;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#24182;&#19988;&#22312;&#32447;&#24615;&#24773;&#22659;&#32972;&#31163;&#38382;&#39064;&#20013;&#36798;&#21040;&#19982;&#20256;&#32479;TS&#30456;&#21516;&#38454;&#25968;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#24182;&#20998;&#26512;&#20102;&#19968;&#31181;&#29992;&#20110;&#24773;&#22659;&#32972;&#31163;&#38382;&#39064;&#30340;&#27748;&#26222;&#26862;&#25277;&#26679;&#65288;TS&#65289;&#31639;&#27861;&#30340;&#21464;&#20307;&#12290;&#20256;&#32479;&#30340;TS&#31639;&#27861;&#22312;&#27599;&#36718;&#38656;&#35201;&#20174;&#24403;&#21069;&#30340;&#21518;&#39564;&#20998;&#24067;&#20013;&#25277;&#26679;&#65292;&#32780;&#36825;&#36890;&#24120;&#26159;&#38590;&#20197;&#35745;&#31639;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#21487;&#20197;&#20351;&#29992;&#36817;&#20284;&#25512;&#29702;&#25216;&#26415;&#24182;&#25552;&#20379;&#25509;&#36817;&#21518;&#39564;&#20998;&#24067;&#30340;&#26679;&#26412;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#36817;&#20284;&#25216;&#26415;&#35201;&#20040;&#20272;&#35745;&#19981;&#20934;&#30830;&#65288;&#25289;&#26222;&#25289;&#26031;&#36817;&#20284;&#65289;&#65292;&#35201;&#20040;&#35745;&#31639;&#24320;&#38144;&#36739;&#22823;&#65288;MCMC&#26041;&#27861;&#65292;&#38598;&#25104;&#25277;&#26679;...&#65289;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#22522;&#20110;&#39640;&#26031;&#21464;&#20998;&#25512;&#29702;&#30340;&#21464;&#20998;&#25512;&#29702;&#27748;&#26222;&#26862;&#25277;&#26679;&#65288;VITS&#65289;&#12290;&#36825;&#31181;&#26041;&#27861;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#21518;&#39564;&#36817;&#20284;&#65292;&#24182;&#19988;&#23481;&#26131;&#20174;&#20013;&#25277;&#26679;&#65292;&#32780;&#19988;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#26159;TS&#30340;&#29702;&#24819;&#36873;&#25321;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#22312;&#32447;&#24615;&#24773;&#22659;&#32972;&#31163;&#38382;&#39064;&#20013;&#65292;VITS&#23454;&#29616;&#20102;&#19982;&#20256;&#32479;TS&#30456;&#21516;&#38454;&#25968;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#19978;&#30028;&#65292;&#19982;&#32500;&#24230;&#21644;&#22238;&#21512;&#25968;&#25104;&#27491;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce and analyze a variant of the Thompson sampling (TS) algorithm for contextual bandits. At each round, traditional TS requires samples from the current posterior distribution, which is usually intractable. To circumvent this issue, approximate inference techniques can be used and provide samples with distribution close to the posteriors. However, current approximate techniques yield to either poor estimation (Laplace approximation) or can be computationally expensive (MCMC methods, Ensemble sampling...). In this paper, we propose a new algorithm, Varational Inference Thompson sampling VITS, based on Gaussian Variational Inference. This scheme provides powerful posterior approximations which are easy to sample from, and is computationally efficient, making it an ideal choice for TS. In addition, we show that VITS achieves a sub-linear regret bound of the same order in the dimension and number of round as traditional TS for linear contextual bandit. Finally, we 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#37325;&#26032;&#24605;&#32771;&#20102;&#21518;&#38376;&#25915;&#20987;&#38382;&#39064;&#65292;&#21457;&#29616;&#22312;&#27809;&#26377;&#20851;&#20110;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#30340;&#32467;&#26500;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#65292;&#21518;&#38376;&#25915;&#20987;&#19982;&#25968;&#25454;&#20013;&#33258;&#28982;&#20135;&#29983;&#30340;&#29305;&#24449;&#26159;&#19981;&#21487;&#21306;&#20998;&#30340;&#65292;&#22240;&#27492;&#38590;&#20197;&#26816;&#27979;&#12290;&#20316;&#32773;&#36824;&#37325;&#26032;&#23457;&#35270;&#29616;&#26377;&#30340;&#25269;&#24481;&#21518;&#38376;&#25915;&#20987;&#30340;&#26041;&#27861;&#65292;&#24182;&#25506;&#32034;&#20102;&#19968;&#31181;&#20851;&#20110;&#21518;&#38376;&#25915;&#20987;&#30340;&#26367;&#20195;&#35270;&#35282;&#12290;</title><link>http://arxiv.org/abs/2307.10163</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#21518;&#38376;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Rethinking Backdoor Attacks. (arXiv:2307.10163v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10163
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#24605;&#32771;&#20102;&#21518;&#38376;&#25915;&#20987;&#38382;&#39064;&#65292;&#21457;&#29616;&#22312;&#27809;&#26377;&#20851;&#20110;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#30340;&#32467;&#26500;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#65292;&#21518;&#38376;&#25915;&#20987;&#19982;&#25968;&#25454;&#20013;&#33258;&#28982;&#20135;&#29983;&#30340;&#29305;&#24449;&#26159;&#19981;&#21487;&#21306;&#20998;&#30340;&#65292;&#22240;&#27492;&#38590;&#20197;&#26816;&#27979;&#12290;&#20316;&#32773;&#36824;&#37325;&#26032;&#23457;&#35270;&#29616;&#26377;&#30340;&#25269;&#24481;&#21518;&#38376;&#25915;&#20987;&#30340;&#26041;&#27861;&#65292;&#24182;&#25506;&#32034;&#20102;&#19968;&#31181;&#20851;&#20110;&#21518;&#38376;&#25915;&#20987;&#30340;&#26367;&#20195;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21518;&#38376;&#25915;&#20987;&#20013;&#65292;&#23545;&#25163;&#20250;&#23558;&#24694;&#24847;&#26500;&#36896;&#30340;&#21518;&#38376;&#31034;&#20363;&#25554;&#20837;&#35757;&#32451;&#38598;&#20013;&#65292;&#20351;&#24471;&#29983;&#25104;&#30340;&#27169;&#22411;&#23481;&#26131;&#21463;&#21040;&#25805;&#32437;&#12290;&#38450;&#24481;&#36825;&#31181;&#25915;&#20987;&#36890;&#24120;&#28041;&#21450;&#23558;&#36825;&#20123;&#25554;&#20837;&#30340;&#31034;&#20363;&#35270;&#20026;&#35757;&#32451;&#38598;&#20013;&#30340;&#24322;&#24120;&#20540;&#65292;&#24182;&#20351;&#29992;&#40065;&#26834;&#32479;&#35745;&#23398;&#30340;&#25216;&#26415;&#26469;&#26816;&#27979;&#21644;&#21024;&#38500;&#23427;&#20204;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#19981;&#21516;&#30340;&#35299;&#20915;&#21518;&#38376;&#25915;&#20987;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#27809;&#26377;&#20851;&#20110;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#30340;&#32467;&#26500;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#65292;&#21518;&#38376;&#25915;&#20987;&#19982;&#25968;&#25454;&#20013;&#33258;&#28982;&#20135;&#29983;&#30340;&#29305;&#24449;&#26159;&#19981;&#21487;&#21306;&#20998;&#30340;--&#22240;&#27492;&#26080;&#27861;&#22312;&#19968;&#33324;&#24847;&#20041;&#19978;&#8220;&#26816;&#27979;&#8221;&#23427;&#20204;&#12290;&#28982;&#21518;&#65292;&#26681;&#25454;&#36825;&#19968;&#35266;&#23519;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#29616;&#26377;&#30340;&#25269;&#24481;&#21518;&#38376;&#25915;&#20987;&#30340;&#26041;&#27861;&#65292;&#24182;&#34920;&#24449;&#23427;&#20204;&#25152;&#20570;&#20986;&#30340;&#65288;&#24120;&#24120;&#26159;&#28508;&#22312;&#30340;&#65289;&#20551;&#35774;&#20197;&#21450;&#23427;&#20204;&#20381;&#36182;&#30340;&#20551;&#35774;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#19968;&#31181;&#20851;&#20110;&#21518;&#38376;&#25915;&#20987;&#30340;&#26367;&#20195;&#35270;&#35282;&#65306;&#20551;&#35774;&#36825;&#20123;&#25915;&#20987;&#23545;&#24212;&#20110;&#35757;&#32451;&#25968;&#25454;&#20013;&#26368;&#24378;&#30340;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
In a backdoor attack, an adversary inserts maliciously constructed backdoor examples into a training set to make the resulting model vulnerable to manipulation. Defending against such attacks typically involves viewing these inserted examples as outliers in the training set and using techniques from robust statistics to detect and remove them.  In this work, we present a different approach to the backdoor attack problem. Specifically, we show that without structural information about the training data distribution, backdoor attacks are indistinguishable from naturally-occurring features in the data--and thus impossible to "detect" in a general sense. Then, guided by this observation, we revisit existing defenses against backdoor attacks and characterize the (often latent) assumptions they make and on which they depend. Finally, we explore an alternative perspective on backdoor attacks: one that assumes these attacks correspond to the strongest feature in the training data. Under this a
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24809;&#32602;&#21270;&#21644;&#38408;&#20540;&#21270;&#20272;&#35745;&#30340;&#27169;&#24335;&#24674;&#22797;&#26041;&#27861;&#65292;&#24182;&#23450;&#20041;&#20102;&#27169;&#24335;&#21644;&#24674;&#22797;&#26465;&#20214;&#12290;&#23545;&#20110;LASSO&#65292;&#26080;&#22122;&#22768;&#24674;&#22797;&#26465;&#20214;&#21644;&#20114;&#19981;&#34920;&#31034;&#26465;&#20214;&#36215;&#21040;&#20102;&#30456;&#21516;&#30340;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2307.10158</link><description>&lt;p&gt;
&#24809;&#32602;&#21270;&#21644;&#38408;&#20540;&#21270;&#20272;&#35745;&#20013;&#30340;&#27169;&#24335;&#24674;&#22797;&#21450;&#20854;&#20960;&#20309;
&lt;/p&gt;
&lt;p&gt;
Pattern Recovery in Penalized and Thresholded Estimation and its Geometry. (arXiv:2307.10158v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10158
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24809;&#32602;&#21270;&#21644;&#38408;&#20540;&#21270;&#20272;&#35745;&#30340;&#27169;&#24335;&#24674;&#22797;&#26041;&#27861;&#65292;&#24182;&#23450;&#20041;&#20102;&#27169;&#24335;&#21644;&#24674;&#22797;&#26465;&#20214;&#12290;&#23545;&#20110;LASSO&#65292;&#26080;&#22122;&#22768;&#24674;&#22797;&#26465;&#20214;&#21644;&#20114;&#19981;&#34920;&#31034;&#26465;&#20214;&#36215;&#21040;&#20102;&#30456;&#21516;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#24809;&#32602;&#20272;&#35745;&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;&#24809;&#32602;&#39033;&#30001;&#23454;&#20540;&#30340;&#22810;&#38754;&#20307;&#35268;&#33539;&#32473;&#20986;&#65292;&#20854;&#20013;&#21253;&#25324;&#35832;&#22914;LASSO&#65288;&#20197;&#21450;&#20854;&#35768;&#22810;&#21464;&#20307;&#22914;&#24191;&#20041;LASSO&#65289;&#12289;SLOPE&#12289;OSCAR&#12289;PACS&#31561;&#26041;&#27861;&#12290;&#27599;&#20010;&#20272;&#35745;&#22120;&#21487;&#20197;&#25581;&#31034;&#26410;&#30693;&#21442;&#25968;&#21521;&#37327;&#30340;&#19981;&#21516;&#32467;&#26500;&#25110;&#8220;&#27169;&#24335;&#8221;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#22522;&#20110;&#27425;&#24494;&#20998;&#30340;&#27169;&#24335;&#30340;&#19968;&#33324;&#27010;&#24565;&#65292;&#24182;&#24418;&#24335;&#21270;&#20102;&#19968;&#31181;&#34913;&#37327;&#20854;&#22797;&#26434;&#24615;&#30340;&#26041;&#27861;&#12290;&#23545;&#20110;&#27169;&#24335;&#24674;&#22797;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#29305;&#23450;&#27169;&#24335;&#20197;&#27491;&#27010;&#29575;&#34987;&#35813;&#36807;&#31243;&#26816;&#27979;&#21040;&#30340;&#26368;&#23567;&#26465;&#20214;&#65292;&#21363;&#25152;&#35859;&#30340;&#21487;&#36798;&#24615;&#26465;&#20214;&#12290;&#21033;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#26356;&#24378;&#30340;&#26080;&#22122;&#22768;&#24674;&#22797;&#26465;&#20214;&#12290;&#23545;&#20110;LASSO&#65292;&#20247;&#25152;&#21608;&#30693;&#65292;&#20114;&#19981;&#34920;&#31034;&#26465;&#20214;&#26159;&#20351;&#27169;&#24335;&#24674;&#22797;&#30340;&#27010;&#29575;&#22823;&#20110;1/2&#25152;&#24517;&#38656;&#30340;&#65292;&#24182;&#19988;&#25105;&#20204;&#23637;&#31034;&#20102;&#26080;&#22122;&#22768;&#24674;&#22797;&#36215;&#21040;&#20102;&#23436;&#20840;&#30456;&#21516;&#30340;&#20316;&#29992;&#65292;&#20174;&#32780;&#25193;&#23637;&#21644;&#32479;&#19968;&#20102;&#20114;&#19981;&#34920;&#31034;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the framework of penalized estimation where the penalty term is given by a real-valued polyhedral gauge, which encompasses methods such as LASSO (and many variants thereof such as the generalized LASSO), SLOPE, OSCAR, PACS and others. Each of these estimators can uncover a different structure or ``pattern'' of the unknown parameter vector. We define a general notion of patterns based on subdifferentials and formalize an approach to measure their complexity. For pattern recovery, we provide a minimal condition for a particular pattern to be detected by the procedure with positive probability, the so-called accessibility condition. Using our approach, we also introduce the stronger noiseless recovery condition. For the LASSO, it is well known that the irrepresentability condition is necessary for pattern recovery with probability larger than $1/2$ and we show that the noiseless recovery plays exactly the same role, thereby extending and unifying the irrepresentability conditi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#21033;&#29992;&#22270;&#30340;&#20960;&#20309;&#24615;&#36136;&#65292;&#23454;&#29616;&#20102;&#22522;&#20110;&#31163;&#25955;Ricci&#26354;&#29575;&#30340;&#32858;&#31867;&#31639;&#27861;&#65292;&#21487;&#20197;&#35782;&#21035;&#22270;&#32467;&#26500;&#20013;&#30340;&#23494;&#38598;&#36830;&#25509;&#23376;&#32467;&#26500;&#65292;&#21253;&#25324;&#21333;&#25104;&#21592;&#31038;&#21306;&#21644;&#28151;&#21512;&#25104;&#21592;&#31038;&#21306;&#65292;&#20197;&#21450;&#22312;&#32447;&#22270;&#19978;&#30340;&#31038;&#21306;&#26816;&#27979;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#39564;&#35777;&#25454;&#25903;&#25345;&#12290;</title><link>http://arxiv.org/abs/2307.10155</link><description>&lt;p&gt;
&#22522;&#20110;&#26354;&#29575;&#30340;&#22270;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Curvature-based Clustering on Graphs. (arXiv:2307.10155v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10155
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#21033;&#29992;&#22270;&#30340;&#20960;&#20309;&#24615;&#36136;&#65292;&#23454;&#29616;&#20102;&#22522;&#20110;&#31163;&#25955;Ricci&#26354;&#29575;&#30340;&#32858;&#31867;&#31639;&#27861;&#65292;&#21487;&#20197;&#35782;&#21035;&#22270;&#32467;&#26500;&#20013;&#30340;&#23494;&#38598;&#36830;&#25509;&#23376;&#32467;&#26500;&#65292;&#21253;&#25324;&#21333;&#25104;&#21592;&#31038;&#21306;&#21644;&#28151;&#21512;&#25104;&#21592;&#31038;&#21306;&#65292;&#20197;&#21450;&#22312;&#32447;&#22270;&#19978;&#30340;&#31038;&#21306;&#26816;&#27979;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#39564;&#35777;&#25454;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#33410;&#28857;&#32858;&#31867;&#65288;&#25110;&#31038;&#21306;&#26816;&#27979;&#65289;&#26159;&#32463;&#20856;&#30340;&#22270;&#23398;&#20064;&#20219;&#21153;&#12290;&#26412;&#25991;&#30740;&#31350;&#21033;&#29992;&#22270;&#30340;&#20960;&#20309;&#24615;&#36136;&#26469;&#35782;&#21035;&#23494;&#38598;&#36830;&#25509;&#30340;&#23376;&#32467;&#26500;&#20197;&#24418;&#25104;&#32858;&#31867;&#25110;&#31038;&#21306;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23454;&#29616;&#20102;&#31163;&#25955;Ricci&#26354;&#29575;&#21450;&#20854;&#30456;&#20851;&#30340;&#20960;&#20309;&#27969;&#65292;&#36890;&#36807;&#36825;&#20123;&#27969;&#65292;&#22270;&#30340;&#36793;&#26435;&#37325;&#28436;&#21270;&#20197;&#25581;&#31034;&#20854;&#31038;&#21306;&#32467;&#26500;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#20960;&#31181;&#31163;&#25955;&#26354;&#29575;&#27010;&#24565;&#65292;&#24182;&#20998;&#26512;&#20102;&#30456;&#24212;&#31639;&#27861;&#30340;&#23454;&#29992;&#24615;&#12290;&#19982;&#20043;&#21069;&#30340;&#25991;&#29486;&#30456;&#27604;&#65292;&#25105;&#20204;&#19981;&#20165;&#30740;&#31350;&#20102;&#21333;&#25104;&#21592;&#31038;&#21306;&#26816;&#27979;&#65292;&#21363;&#27599;&#20010;&#33410;&#28857;&#21482;&#23646;&#20110;&#19968;&#20010;&#31038;&#21306;&#65292;&#36824;&#30740;&#31350;&#20102;&#28151;&#21512;&#25104;&#21592;&#31038;&#21306;&#26816;&#27979;&#65292;&#21363;&#31038;&#21306;&#21487;&#33021;&#37325;&#21472;&#12290;&#23545;&#20110;&#21518;&#32773;&#65292;&#25105;&#20204;&#35748;&#20026;&#22312;&#32447;&#22270;&#19978;&#25191;&#34892;&#31038;&#21306;&#26816;&#27979;&#26377;&#30410;&#22788;&#65292;&#21363;&#22270;&#30340;&#23545;&#20598;&#22270;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#25105;&#20204;&#22522;&#20110;&#26354;&#29575;&#30340;&#32858;&#31867;&#31639;&#27861;&#30340;&#29702;&#35770;&#21644;&#23454;&#35777;&#35777;&#25454;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#20960;&#20010;&#37325;&#26032;&#23454;&#29616;&#21644;&#35780;&#20272;&#30340;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unsupervised node clustering (or community detection) is a classical graph learning task. In this paper, we study algorithms, which exploit the geometry of the graph to identify densely connected substructures, which form clusters or communities. Our method implements discrete Ricci curvatures and their associated geometric flows, under which the edge weights of the graph evolve to reveal its community structure. We consider several discrete curvature notions and analyze the utility of the resulting algorithms. In contrast to prior literature, we study not only single-membership community detection, where each node belongs to exactly one community, but also mixed-membership community detection, where communities may overlap. For the latter, we argue that it is beneficial to perform community detection on the line graph, i.e., the graph's dual. We provide both theoretical and empirical evidence for the utility of our curvature-based clustering algorithms. In addition, we give several re
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;Wasserstein&#36317;&#31163;&#19979;&#30340;&#36125;&#21494;&#26031;&#30452;&#26041;&#22270;&#30340;&#20869;&#23384;&#39640;&#25928;&#24615;&#21644;&#26368;&#23567;&#21270;&#20998;&#24067;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#24403;&#32500;&#24230;&#23567;&#20110;2v&#26102;&#65292;&#21482;&#38656;&#35201;&#20351;&#29992;n^{d/2v}&#20010;bins&#23601;&#21487;&#20197;&#36798;&#21040;&#26368;&#23567;&#21270;&#29575;&#26368;&#20248;&#24615;&#65292;&#30456;&#36739;&#20110;&#29616;&#26377;&#31639;&#27861;&#30340;&#20869;&#23384;&#21344;&#29992;&#21487;&#20197;&#20943;&#23569;&#22810;&#39033;&#24335;&#22240;&#23376;$n^{1 - d/2v}$&#65292;&#21516;&#26102;&#26500;&#24314;&#21518;&#39564;&#22343;&#20540;&#30452;&#26041;&#22270;&#21644;&#21518;&#39564;&#26412;&#36523;&#30340;&#22797;&#26434;&#24230;&#21487;&#20197;&#36229;&#32447;&#24615;&#22686;&#21152;&#12290;</title><link>http://arxiv.org/abs/2307.10099</link><description>&lt;p&gt;
&#20869;&#23384;&#39640;&#25928;&#21644;&#26368;&#23567;&#21270;&#20998;&#24067;&#20272;&#35745;&#19979;&#30340;Wasserstein&#36317;&#31163;&#20351;&#29992;&#36125;&#21494;&#26031;&#30452;&#26041;&#22270;
&lt;/p&gt;
&lt;p&gt;
Memory Efficient And Minimax Distribution Estimation Under Wasserstein Distance Using Bayesian Histograms. (arXiv:2307.10099v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10099
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;Wasserstein&#36317;&#31163;&#19979;&#30340;&#36125;&#21494;&#26031;&#30452;&#26041;&#22270;&#30340;&#20869;&#23384;&#39640;&#25928;&#24615;&#21644;&#26368;&#23567;&#21270;&#20998;&#24067;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#24403;&#32500;&#24230;&#23567;&#20110;2v&#26102;&#65292;&#21482;&#38656;&#35201;&#20351;&#29992;n^{d/2v}&#20010;bins&#23601;&#21487;&#20197;&#36798;&#21040;&#26368;&#23567;&#21270;&#29575;&#26368;&#20248;&#24615;&#65292;&#30456;&#36739;&#20110;&#29616;&#26377;&#31639;&#27861;&#30340;&#20869;&#23384;&#21344;&#29992;&#21487;&#20197;&#20943;&#23569;&#22810;&#39033;&#24335;&#22240;&#23376;$n^{1 - d/2v}$&#65292;&#21516;&#26102;&#26500;&#24314;&#21518;&#39564;&#22343;&#20540;&#30452;&#26041;&#22270;&#21644;&#21518;&#39564;&#26412;&#36523;&#30340;&#22797;&#26434;&#24230;&#21487;&#20197;&#36229;&#32447;&#24615;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;$[0,1]^d$&#19978;&#30340;Wasserstein $W_v, 1 \leq v &lt; \infty$&#36317;&#31163;&#19979;&#30340;&#36125;&#21494;&#26031;&#30452;&#26041;&#22270;&#20998;&#24067;&#20272;&#35745;&#12290;&#25105;&#20204;&#26032;&#30340;&#21457;&#29616;&#26159;&#65292;&#24403;$d &lt; 2v$&#26102;&#65292;&#30452;&#26041;&#22270;&#20855;&#26377;&#29305;&#27530;&#30340;"&#20869;&#23384;&#39640;&#25928;"&#23646;&#24615;&#65292;&#21363;&#22312;&#21442;&#32771;&#26679;&#26412;&#22823;&#23567;$n$&#30340;&#24773;&#20917;&#19979;&#65292;&#38656;&#35201;&#39034;&#24207;$n^{d/2v}$&#30340;bins&#26469;&#33719;&#24471;&#26368;&#23567;&#21270;&#29575;&#26368;&#20248;&#24615;&#12290;&#36825;&#20010;&#32467;&#26524;&#23545;&#20110;&#21518;&#39564;&#22343;&#20540;&#30452;&#26041;&#22270;&#21644;&#30456;&#23545;&#20110;&#21518;&#39564;&#25910;&#32553;&#26469;&#35828;&#26159;&#25104;&#31435;&#30340;&#65306;&#23545;&#20110;Borel&#27010;&#29575;&#27979;&#24230;&#21644;&#19968;&#20123;&#20809;&#28369;&#23494;&#24230;&#31867;&#21035;&#12290;&#25152;&#33719;&#24471;&#30340;&#20869;&#23384;&#21344;&#29992;&#20248;&#21183;&#27604;&#29616;&#26377;&#30340;&#26368;&#23567;&#21270;&#26368;&#20248;&#31639;&#27861;&#22810;&#20986;&#20102;$n$&#30340;&#22810;&#39033;&#24335;&#22240;&#23376;&#65307;&#20363;&#22914;&#65292;&#19982;Borel&#27010;&#29575;&#27979;&#24230;&#31867;&#21035;&#20013;&#30340;&#32463;&#39564;&#27979;&#24230;&#65288;&#26368;&#23567;&#21270;&#20272;&#35745;&#22120;&#65289;&#30456;&#27604;&#65292;&#20869;&#23384;&#21344;&#29992;&#21487;&#20197;&#20943;&#23569;$n^{1 - d/2v}$&#20493;&#12290;&#27492;&#22806;&#65292;&#26500;&#24314;&#21518;&#39564;&#22343;&#20540;&#30452;&#26041;&#22270;&#21644;&#21518;&#39564;&#26412;&#36523;&#21487;&#20197;&#36229;&#32447;&#24615;&#22320;&#36827;&#34892;$n$&#12290;
&lt;/p&gt;
&lt;p&gt;
We study Bayesian histograms for distribution estimation on $[0,1]^d$ under the Wasserstein $W_v, 1 \leq v &lt; \infty$ distance in the i.i.d sampling regime. We newly show that when $d &lt; 2v$, histograms possess a special \textit{memory efficiency} property, whereby in reference to the sample size $n$, order $n^{d/2v}$ bins are needed to obtain minimax rate optimality. This result holds for the posterior mean histogram and with respect to posterior contraction: under the class of Borel probability measures and some classes of smooth densities. The attained memory footprint overcomes existing minimax optimal procedures by a polynomial factor in $n$; for example an $n^{1 - d/2v}$ factor reduction in the footprint when compared to the empirical measure, a minimax estimator in the Borel probability measure class. Additionally constructing both the posterior mean histogram and the posterior itself can be done super--linearly in $n$. Due to the popularity of the $W_1,W_2$ metrics and the covera
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#30340;&#36317;&#31163;&#65292;&#22686;&#24378;&#30340;Gromov-Wasserstein&#65292;&#23427;&#22312;Gromov-Wasserstein&#36317;&#31163;&#30340;&#22522;&#30784;&#19978;&#24341;&#20837;&#20102;&#23545;&#21464;&#25442;&#21018;&#24230;&#30340;&#25511;&#21046;&#21644;&#29305;&#24449;&#23545;&#40784;&#65292;&#24182;&#24212;&#29992;&#20110;&#21333;&#32454;&#32990;&#22810;&#32452;&#23398;&#21644;&#36801;&#31227;&#23398;&#20064;&#20219;&#21153;&#20013;&#65292;&#23637;&#31034;&#20102;&#20854;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#23454;&#29992;&#24615;&#21644;&#25913;&#36827;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.10093</link><description>&lt;p&gt;
&#37325;&#26032;&#23457;&#35270;&#19981;&#21464;&#24615;&#24182;&#24341;&#20837;&#20808;&#39564;&#30693;&#35782;&#22312;Gromov-Wasserstein&#36317;&#31163;&#20013;
&lt;/p&gt;
&lt;p&gt;
Revisiting invariances and introducing priors in Gromov-Wasserstein distances. (arXiv:2307.10093v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10093
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#30340;&#36317;&#31163;&#65292;&#22686;&#24378;&#30340;Gromov-Wasserstein&#65292;&#23427;&#22312;Gromov-Wasserstein&#36317;&#31163;&#30340;&#22522;&#30784;&#19978;&#24341;&#20837;&#20102;&#23545;&#21464;&#25442;&#21018;&#24230;&#30340;&#25511;&#21046;&#21644;&#29305;&#24449;&#23545;&#40784;&#65292;&#24182;&#24212;&#29992;&#20110;&#21333;&#32454;&#32990;&#22810;&#32452;&#23398;&#21644;&#36801;&#31227;&#23398;&#20064;&#20219;&#21153;&#20013;&#65292;&#23637;&#31034;&#20102;&#20854;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#23454;&#29992;&#24615;&#21644;&#25913;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20854;&#33021;&#22815;&#27604;&#36739;&#24230;&#37327;&#31354;&#38388;&#20013;&#30340;&#27979;&#24230;&#24182;&#19988;&#23545;&#31561;&#24230;&#21464;&#25442;&#20855;&#26377;&#19981;&#21464;&#24615;&#65292;Gromov-Wasserstein&#36317;&#31163;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#26377;&#24456;&#22810;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#22312;&#26576;&#20123;&#24212;&#29992;&#20013;&#65292;&#36825;&#31181;&#19981;&#21464;&#24615;&#21487;&#33021;&#36807;&#20110;&#28789;&#27963;&#32780;&#19981;&#21487;&#21462;&#12290;&#27492;&#22806;&#65292;Gromov-Wasserstein&#36317;&#31163;&#20165;&#32771;&#34385;&#36755;&#20837;&#25968;&#25454;&#38598;&#20013;&#30340;&#25104;&#23545;&#26679;&#26412;&#30456;&#20284;&#24615;&#65292;&#32780;&#24573;&#30053;&#21407;&#22987;&#29305;&#24449;&#34920;&#31034;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#30340;&#36317;&#31163;&#65292;&#31216;&#20026;&#22686;&#24378;&#30340;Gromov-Wasserstein&#65292;&#23427;&#20801;&#35768;&#23545;&#21464;&#25442;&#30340;&#21018;&#24230;&#26377;&#19968;&#23450;&#25511;&#21046;&#12290;&#23427;&#36824;&#32467;&#21512;&#20102;&#29305;&#24449;&#23545;&#40784;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#26356;&#22909;&#22320;&#21033;&#29992;&#36755;&#20837;&#25968;&#25454;&#19978;&#30340;&#20808;&#39564;&#30693;&#35782;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#25152;&#25552;&#20986;&#30340;&#24230;&#37327;&#30340;&#29702;&#35770;&#27934;&#23519;&#21147;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23427;&#22312;&#21333;&#32454;&#32990;&#22810;&#32452;&#23398;&#23545;&#40784;&#20219;&#21153;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#36801;&#31227;&#23398;&#20064;&#22330;&#26223;&#20013;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gromov-Wasserstein distance has found many applications in machine learning due to its ability to compare measures across metric spaces and its invariance to isometric transformations. However, in certain applications, this invariance property can be too flexible, thus undesirable. Moreover, the Gromov-Wasserstein distance solely considers pairwise sample similarities in input datasets, disregarding the raw feature representations. We propose a new optimal transport-based distance, called Augmented Gromov-Wasserstein, that allows for some control over the level of rigidity to transformations. It also incorporates feature alignments, enabling us to better leverage prior knowledge on the input data for improved performance. We present theoretical insights into the proposed metric. We then demonstrate its usefulness for single-cell multi-omic alignment tasks and a transfer learning scenario in machine learning.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#27010;&#29575;&#20027;&#25104;&#20998;&#20998;&#26512;&#22312;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#21452;&#37325;&#34920;&#36848;&#26041;&#27861;&#65292;&#24182;&#21457;&#23637;&#20102;&#36866;&#29992;&#20110;&#26680;&#26041;&#27861;&#30340;&#29983;&#25104;&#26694;&#26550;&#12290;&#20316;&#32773;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#33021;&#20860;&#23481;&#26680;&#20027;&#25104;&#20998;&#20998;&#26512;&#65292;&#24182;&#22312;&#34394;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2307.10078</link><description>&lt;p&gt;
&#27010;&#29575;&#20027;&#25104;&#20998;&#20998;&#26512;&#30340;&#21452;&#37325;&#34920;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Dual Formulation for Probabilistic Principal Component Analysis. (arXiv:2307.10078v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10078
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#27010;&#29575;&#20027;&#25104;&#20998;&#20998;&#26512;&#22312;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#21452;&#37325;&#34920;&#36848;&#26041;&#27861;&#65292;&#24182;&#21457;&#23637;&#20102;&#36866;&#29992;&#20110;&#26680;&#26041;&#27861;&#30340;&#29983;&#25104;&#26694;&#26550;&#12290;&#20316;&#32773;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#33021;&#20860;&#23481;&#26680;&#20027;&#25104;&#20998;&#20998;&#26512;&#65292;&#24182;&#22312;&#34394;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22312;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#23545;&#27010;&#29575;&#20027;&#25104;&#20998;&#20998;&#26512;&#36827;&#34892;&#20102;&#34920;&#36848;&#65292;&#24182;&#23637;&#31034;&#20102;&#26368;&#20248;&#35299;&#22312;&#23545;&#20598;&#31354;&#38388;&#20013;&#30340;&#34920;&#31034;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#21457;&#23637;&#20986;&#19968;&#31181;&#36866;&#29992;&#20110;&#26680;&#26041;&#27861;&#30340;&#29983;&#25104;&#26694;&#26550;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23427;&#22914;&#20309;&#21560;&#32435;&#20102;&#26680;&#20027;&#25104;&#20998;&#20998;&#26512;&#65292;&#24182;&#22312;&#19968;&#20010;&#34394;&#25311;&#25968;&#25454;&#38598;&#21644;&#19968;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#28436;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we characterize Probabilistic Principal Component Analysis in Hilbert spaces and demonstrate how the optimal solution admits a representation in dual space. This allows us to develop a generative framework for kernel methods. Furthermore, we show how it englobes Kernel Principal Component Analysis and illustrate its working on a toy and a real dataset.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36125;&#21494;&#26031;&#32858;&#31867;&#37197;&#32622;&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;&#29109;&#27491;&#21017;&#21270;&#21518;&#22788;&#29702;&#36807;&#31243;&#65292;&#20943;&#23569;&#20102;&#31232;&#30095;&#22635;&#20805;&#31751;&#30340;&#25968;&#37327;&#24182;&#22686;&#24378;&#20102;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.10065</link><description>&lt;p&gt;
&#27010;&#29575;&#32858;&#31867;&#20013;&#30340;&#29109;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Entropy regularization in probabilistic clustering. (arXiv:2307.10065v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10065
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36125;&#21494;&#26031;&#32858;&#31867;&#37197;&#32622;&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;&#29109;&#27491;&#21017;&#21270;&#21518;&#22788;&#29702;&#36807;&#31243;&#65292;&#20943;&#23569;&#20102;&#31232;&#30095;&#22635;&#20805;&#31751;&#30340;&#25968;&#37327;&#24182;&#22686;&#24378;&#20102;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#28151;&#21512;&#27169;&#22411;&#34987;&#24191;&#27867;&#29992;&#20110;&#32858;&#31867;&#35266;&#27979;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#30340;&#19968;&#20010;&#20027;&#35201;&#32570;&#28857;&#26159;&#20272;&#35745;&#30340;&#20998;&#21306;&#32463;&#24120;&#21576;&#29616;&#19981;&#24179;&#34913;&#30340;&#31751;&#39057;&#29575;&#65292;&#20854;&#20013;&#21482;&#26377;&#23569;&#25968;&#20960;&#20010;&#31751;&#21344;&#20027;&#23548;&#22320;&#20301;&#65292;&#32780;&#22823;&#37327;&#31232;&#30095;&#22635;&#20805;&#30340;&#31751;&#23384;&#22312;&#12290;&#38500;&#38750;&#25105;&#20204;&#25509;&#21463;&#24573;&#30053;&#19968;&#20123;&#35266;&#27979;&#21644;&#31751;&#65292;&#21542;&#21017;&#36825;&#31181;&#29305;&#28857;&#20250;&#23548;&#33268;&#32467;&#26524;&#26080;&#27861;&#35299;&#37322;&#12290;&#23558;&#21518;&#39564;&#20998;&#24067;&#35299;&#37322;&#20026;&#24809;&#32602;&#20284;&#28982;&#24230;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19981;&#24179;&#34913;&#24615;&#21487;&#20197;&#35299;&#37322;&#20026;&#20272;&#35745;&#20998;&#21306;&#28041;&#21450;&#30340;&#20195;&#20215;&#20989;&#25968;&#30452;&#25509;&#21518;&#26524;&#12290;&#26681;&#25454;&#25105;&#20204;&#30340;&#21457;&#29616;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36125;&#21494;&#26031;&#32858;&#31867;&#37197;&#32622;&#20272;&#35745;&#22120;&#12290;&#35813;&#20272;&#35745;&#22120;&#31561;&#21516;&#20110;&#19968;&#31181;&#21518;&#22788;&#29702;&#36807;&#31243;&#65292;&#20943;&#23569;&#20102;&#31232;&#30095;&#22635;&#20805;&#31751;&#30340;&#25968;&#37327;&#24182;&#22686;&#24378;&#20102;&#21487;&#35299;&#37322;&#24615;&#12290;&#35813;&#36807;&#31243;&#37319;&#21462;&#20102;&#36125;&#21494;&#26031;&#20272;&#35745;&#30340;&#29109;&#27491;&#21017;&#21270;&#24418;&#24335;&#12290;&#34429;&#28982;&#22312;&#35745;&#31639;&#19978;&#24456;&#26041;&#20415;...
&lt;/p&gt;
&lt;p&gt;
Bayesian nonparametric mixture models are widely used to cluster observations. However, one major drawback of the approach is that the estimated partition often presents unbalanced clusters' frequencies with only a few dominating clusters and a large number of sparsely-populated ones. This feature translates into results that are often uninterpretable unless we accept to ignore a relevant number of observations and clusters. Interpreting the posterior distribution as penalized likelihood, we show how the unbalance can be explained as a direct consequence of the cost functions involved in estimating the partition. In light of our findings, we propose a novel Bayesian estimator of the clustering configuration. The proposed estimator is equivalent to a post-processing procedure that reduces the number of sparsely-populated clusters and enhances interpretability. The procedure takes the form of entropy-regularization of the Bayesian estimate. While being computationally convenient with res
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#24179;&#28369;&#38750;&#20984;&#20248;&#21270;&#20013;&#38543;&#26426;&#27425;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#36136;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#21333;&#26102;&#38388;&#23610;&#24230;&#21644;&#21452;&#26102;&#38388;&#23610;&#24230;&#24773;&#20917;&#19979;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#21253;&#25324;&#20102;&#22810;&#31181;&#24050;&#30693;&#30340;SGD&#31867;&#22411;&#26041;&#27861;&#12290;&#23545;&#20110;&#26377;&#38480;&#21644;&#24418;&#24335;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#35777;&#26126;&#20102;&#36825;&#20123;&#26041;&#27861;&#33021;&#22815;&#22312;&#38543;&#26426;&#36873;&#25321;&#30340;&#27493;&#38271;&#21644;&#21021;&#22987;&#28857;&#19978;&#25214;&#21040;Clarke&#31283;&#23450;&#28857;&#12290;</title><link>http://arxiv.org/abs/2307.10053</link><description>&lt;p&gt;
&#38750;&#24179;&#28369;&#38750;&#20984;&#20248;&#21270;&#20013;&#38543;&#26426;&#27425;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Convergence Guarantees for Stochastic Subgradient Methods in Nonsmooth Nonconvex Optimization. (arXiv:2307.10053v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10053
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#24179;&#28369;&#38750;&#20984;&#20248;&#21270;&#20013;&#38543;&#26426;&#27425;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#36136;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#21333;&#26102;&#38388;&#23610;&#24230;&#21644;&#21452;&#26102;&#38388;&#23610;&#24230;&#24773;&#20917;&#19979;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#21253;&#25324;&#20102;&#22810;&#31181;&#24050;&#30693;&#30340;SGD&#31867;&#22411;&#26041;&#27861;&#12290;&#23545;&#20110;&#26377;&#38480;&#21644;&#24418;&#24335;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#35777;&#26126;&#20102;&#36825;&#20123;&#26041;&#27861;&#33021;&#22815;&#22312;&#38543;&#26426;&#36873;&#25321;&#30340;&#27493;&#38271;&#21644;&#21021;&#22987;&#28857;&#19978;&#25214;&#21040;Clarke&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#26041;&#27861;&#21450;&#20854;&#21464;&#31181;&#22312;&#35757;&#32451;&#30001;&#38750;&#24179;&#28369;&#28608;&#27963;&#20989;&#25968;&#26500;&#24314;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#25910;&#25947;&#24615;&#36136;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#20026;&#26356;&#26032;&#21160;&#37327;&#39033;&#21644;&#21464;&#37327;&#30340;&#27493;&#38271;&#20998;&#37197;&#20102;&#19981;&#21516;&#30340;&#26102;&#38388;&#23610;&#24230;&#12290;&#22312;&#19968;&#20123;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#22312;&#21333;&#26102;&#38388;&#23610;&#24230;&#21644;&#21452;&#26102;&#38388;&#23610;&#24230;&#24773;&#20917;&#19979;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#21253;&#21547;&#20102;&#24456;&#22810;&#24050;&#30693;&#30340;SGD&#31867;&#22411;&#26041;&#27861;&#65292;&#21253;&#25324;heavy-ball SGD&#12289;SignSGD&#12289;Lion&#12289;normalized SGD&#21644;clipped SGD&#12290;&#27492;&#22806;&#65292;&#24403;&#30446;&#26631;&#20989;&#25968;&#37319;&#29992;&#26377;&#38480;&#21644;&#24418;&#24335;&#26102;&#65292;&#25105;&#20204;&#22522;&#20110;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#35777;&#26126;&#20102;&#36825;&#20123;SGD&#31867;&#22411;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#36136;&#12290;&#29305;&#21035;&#22320;&#65292;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;SGD&#31867;&#22411;&#26041;&#27861;&#22312;&#38543;&#26426;&#36873;&#25321;&#30340;&#27493;&#38271;&#21644;&#21021;&#22987;&#28857;&#19978;&#33021;&#22815;&#25214;&#21040;&#30446;&#26631;&#20989;&#25968;&#30340;Clarke&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we investigate the convergence properties of the stochastic gradient descent (SGD) method and its variants, especially in training neural networks built from nonsmooth activation functions. We develop a novel framework that assigns different timescales to stepsizes for updating the momentum terms and variables, respectively. Under mild conditions, we prove the global convergence of our proposed framework in both single-timescale and two-timescale cases. We show that our proposed framework encompasses a wide range of well-known SGD-type methods, including heavy-ball SGD, SignSGD, Lion, normalized SGD and clipped SGD. Furthermore, when the objective function adopts a finite-sum formulation, we prove the convergence properties for these SGD-type methods based on our proposed framework. In particular, we prove that these SGD-type methods find the Clarke stationary points of the objective function with randomly chosen stepsizes and initial points under mild assumptions. Preli
&lt;/p&gt;</description></item><item><title>FaIRGP&#26159;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#20195;&#29702;&#27169;&#22411;&#65292;&#23427;&#28385;&#36275;&#33021;&#37327;&#24179;&#34913;&#27169;&#22411;&#30340;&#29289;&#29702;&#28201;&#24230;&#21709;&#24212;&#26041;&#31243;&#65292;&#21516;&#26102;&#20855;&#22791;&#20102;&#20174;&#35266;&#27979;&#20013;&#23398;&#20064;&#21644;&#36827;&#34892;&#25512;&#26029;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.10052</link><description>&lt;p&gt;
FaIRGP:&#38754;&#21521;&#34920;&#38754;&#28201;&#24230;&#27169;&#25311;&#30340;&#36125;&#21494;&#26031;&#33021;&#37327;&#24179;&#34913;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
FaIRGP: A Bayesian Energy Balance Model for Surface Temperatures Emulation. (arXiv:2307.10052v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10052
&lt;/p&gt;
&lt;p&gt;
FaIRGP&#26159;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#20195;&#29702;&#27169;&#22411;&#65292;&#23427;&#28385;&#36275;&#33021;&#37327;&#24179;&#34913;&#27169;&#22411;&#30340;&#29289;&#29702;&#28201;&#24230;&#21709;&#24212;&#26041;&#31243;&#65292;&#21516;&#26102;&#20855;&#22791;&#20102;&#20174;&#35266;&#27979;&#20013;&#23398;&#20064;&#21644;&#36827;&#34892;&#25512;&#26029;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20195;&#29702;&#27169;&#22411;&#25110;&#31616;&#21270;&#22797;&#26434;&#27668;&#20505;&#27169;&#22411;&#26159;&#36890;&#36807;&#26368;&#23567;&#30340;&#35745;&#31639;&#36164;&#28304;&#29983;&#25104;&#20851;&#38190;&#27668;&#20505;&#37327;&#39044;&#27979;&#30340;&#22320;&#29699;&#31995;&#32479;&#27169;&#22411;&#12290;&#36890;&#36807;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#25110;&#26356;&#20808;&#36827;&#30340;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#65292;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#20195;&#29702;&#27169;&#22411;&#24050;&#25104;&#20026;&#19968;&#20010;&#26377;&#24076;&#26395;&#30340;&#30740;&#31350;&#26041;&#21521;&#65292;&#33021;&#22815;&#29983;&#25104;&#19982;&#26368;&#20808;&#36827;&#30340;&#22320;&#29699;&#31995;&#32479;&#27169;&#22411;&#22312;&#35270;&#35273;&#19978;&#38590;&#20197;&#21306;&#20998;&#30340;&#31354;&#38388;&#20998;&#36776;&#29575;&#27668;&#20505;&#21709;&#24212;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#32570;&#20047;&#29289;&#29702;&#19978;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#24191;&#27867;&#24212;&#29992;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#20195;&#29702;&#27169;&#22411;FaIRGP&#65292;&#23427;&#28385;&#36275;&#33021;&#37327;&#24179;&#34913;&#27169;&#22411;&#30340;&#29289;&#29702;&#28201;&#24230;&#21709;&#24212;&#26041;&#31243;&#12290;&#32467;&#26524;&#26159;&#19968;&#20010;&#26082;&#33021;&#22815;&#20174;&#35266;&#27979;&#20013;&#23398;&#20064;&#21448;&#20855;&#26377;&#22362;&#23454;&#29289;&#29702;&#22522;&#30784;&#30340;&#20195;&#29702;&#27169;&#22411;&#65292;&#21487;&#29992;&#20110;&#23545;&#27668;&#20505;&#31995;&#32479;&#36827;&#34892;&#25512;&#26029;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#21407;&#21017;&#19988;&#25968;&#23398;&#21487;&#34892;&#30340;&#26041;&#27861;&#26469;&#36827;&#34892;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
Emulators, or reduced complexity climate models, are surrogate Earth system models that produce projections of key climate quantities with minimal computational resources. Using time-series modeling or more advanced machine learning techniques, data-driven emulators have emerged as a promising avenue of research, producing spatially resolved climate responses that are visually indistinguishable from state-of-the-art Earth system models. Yet, their lack of physical interpretability limits their wider adoption. In this work, we introduce FaIRGP, a data-driven emulator that satisfies the physical temperature response equations of an energy balance model. The result is an emulator that (i) enjoys the flexibility of statistical machine learning models and can learn from observations, and (ii) has a robust physical grounding with interpretable parameters that can be used to make inference about the climate system. Further, our Bayesian approach allows a principled and mathematically tractabl
&lt;/p&gt;</description></item><item><title>&#36825;&#37324;&#26159;&#20013;&#25991;&#24635;&#32467;&#20986;&#30340;&#19968;&#21477;&#35805;&#35201;&#28857;&#65306;&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#25552;&#39640;&#29992;&#25143;&#38271;&#26399;&#28385;&#24847;&#24230;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#24320;&#21457;&#19968;&#20010;&#39044;&#27979;&#24310;&#36831;&#22870;&#21169;&#30340;&#27169;&#22411;&#21644;&#35774;&#35745;&#19968;&#20010;&#21033;&#29992;&#35813;&#27169;&#22411;&#30340;&#36172;&#21338;&#31639;&#27861;&#26469;&#35299;&#20915;&#20102;&#36890;&#36807;&#27979;&#37327;&#30701;&#26399;&#20195;&#29702;&#22870;&#21169;&#21453;&#26144;&#23454;&#38469;&#38271;&#26399;&#30446;&#26631;&#19981;&#23436;&#32654;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2307.09943</link><description>&lt;p&gt;
&#36825;&#37324;&#26159;&#32763;&#35793;&#36807;&#30340;&#35770;&#25991;&#26631;&#39064;: &#36807;&#21435;&#26366;&#32763;&#35793;&#12298;Impatient Bandits: Optimizing for the Long-Term Without Delay&#12299;
&lt;/p&gt;
&lt;p&gt;
Impatient Bandits: Optimizing for the Long-Term Without Delay. (arXiv:2307.09943v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09943
&lt;/p&gt;
&lt;p&gt;
&#36825;&#37324;&#26159;&#20013;&#25991;&#24635;&#32467;&#20986;&#30340;&#19968;&#21477;&#35805;&#35201;&#28857;&#65306;&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#25552;&#39640;&#29992;&#25143;&#38271;&#26399;&#28385;&#24847;&#24230;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#24320;&#21457;&#19968;&#20010;&#39044;&#27979;&#24310;&#36831;&#22870;&#21169;&#30340;&#27169;&#22411;&#21644;&#35774;&#35745;&#19968;&#20010;&#21033;&#29992;&#35813;&#27169;&#22411;&#30340;&#36172;&#21338;&#31639;&#27861;&#26469;&#35299;&#20915;&#20102;&#36890;&#36807;&#27979;&#37327;&#30701;&#26399;&#20195;&#29702;&#22870;&#21169;&#21453;&#26144;&#23454;&#38469;&#38271;&#26399;&#30446;&#26631;&#19981;&#23436;&#32654;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#37324;&#26159;&#32763;&#35793;&#36807;&#30340;&#35770;&#25991;&#25688;&#35201;&#65306;&#25512;&#33616;&#31995;&#32479;&#22312;&#22312;&#32447;&#24179;&#21488;&#19978;&#26159;&#19968;&#20010;&#26222;&#36941;&#23384;&#22312;&#30340;&#21151;&#33021;&#12290;&#36234;&#26469;&#36234;&#22810;&#30340;&#24773;&#20917;&#19979;&#65292;&#23427;&#20204;&#26126;&#30830;&#22320;&#34987;&#20219;&#21153;&#20026;&#25552;&#39640;&#29992;&#25143;&#30340;&#38271;&#26399;&#28385;&#24847;&#24230;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#20869;&#23481;&#25506;&#32034;&#20219;&#21153;&#65292;&#23558;&#20854;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#20855;&#26377;&#24310;&#36831;&#22870;&#21169;&#30340;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#22312;&#36873;&#25321;&#23398;&#20064;&#20449;&#21495;&#26102;&#23384;&#22312;&#26126;&#26174;&#30340;&#26435;&#34913;&#65306;&#31561;&#24453;&#23436;&#20840;&#30340;&#22870;&#21169;&#21487;&#33021;&#38656;&#35201;&#20960;&#21608;&#26102;&#38388;&#65292;&#36825;&#20250;&#24433;&#21709;&#23398;&#20064;&#21457;&#29983;&#30340;&#36895;&#24230;&#65292;&#32780;&#27979;&#37327;&#30701;&#26399;&#20195;&#29702;&#22870;&#21169;&#21017;&#19981;&#23436;&#32654;&#22320;&#21453;&#26144;&#20102;&#23454;&#38469;&#30340;&#38271;&#26399;&#30446;&#26631;&#12290;&#25105;&#20204;&#36890;&#36807;&#20004;&#20010;&#27493;&#39588;&#26469;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#39044;&#27979;&#24310;&#36831;&#22870;&#21169;&#30340;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#25972;&#21512;&#36804;&#20170;&#25152;&#33719;&#24471;&#30340;&#25152;&#26377;&#20449;&#24687;&#12290;&#36890;&#36807;&#36125;&#21494;&#26031;&#28388;&#27874;&#22120;&#32452;&#21512;&#23436;&#25972;&#30340;&#35266;&#23519;&#32467;&#26524;&#20197;&#21450;&#37096;&#20998;&#65288;&#30701;&#26399;&#25110;&#20013;&#26399;&#65289;&#30340;&#32467;&#26524;&#65292;&#20174;&#32780;&#24471;&#21040;&#27010;&#29575;&#20449;&#24565;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#21033;&#29992;&#36825;&#20010;&#26032;&#30340;&#39044;&#27979;&#27169;&#22411;&#30340;&#36172;&#21338;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#21487;&#20197;&#24555;&#36895;&#23398;&#20064;&#35782;&#21035;&#20869;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems are a ubiquitous feature of online platforms. Increasingly, they are explicitly tasked with increasing users' long-term satisfaction. In this context, we study a content exploration task, which we formalize as a multi-armed bandit problem with delayed rewards. We observe that there is an apparent trade-off in choosing the learning signal: Waiting for the full reward to become available might take several weeks, hurting the rate at which learning happens, whereas measuring short-term proxy rewards reflects the actual long-term goal only imperfectly. We address this challenge in two steps. First, we develop a predictive model of delayed rewards that incorporates all information obtained to date. Full observations as well as partial (short or medium-term) outcomes are combined through a Bayesian filter to obtain a probabilistic belief. Second, we devise a bandit algorithm that takes advantage of this new predictive model. The algorithm quickly learns to identify conten
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#29702;&#35770;&#35777;&#26126;&#21644;&#31639;&#27861;&#25552;&#20986;&#65292;&#23637;&#31034;&#20102;&#22312;&#27809;&#26377;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#22914;&#20309;&#21033;&#29992;&#19981;&#31283;&#23450;&#29305;&#24449;&#26469;&#25552;&#39640;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.09933</link><description>&lt;p&gt;
Spuriosity&#24182;&#27809;&#26377;&#23548;&#33268;&#20998;&#31867;&#22120;&#22833;&#36133;&#65306;&#21033;&#29992;&#19981;&#21464;&#30340;&#39044;&#27979;&#26469;&#21033;&#29992;&#34394;&#20551;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Spuriosity Didn't Kill the Classifier: Using Invariant Predictions to Harness Spurious Features. (arXiv:2307.09933v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09933
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#29702;&#35770;&#35777;&#26126;&#21644;&#31639;&#27861;&#25552;&#20986;&#65292;&#23637;&#31034;&#20102;&#22312;&#27809;&#26377;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#22914;&#20309;&#21033;&#29992;&#19981;&#31283;&#23450;&#29305;&#24449;&#26469;&#25552;&#39640;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#36991;&#20813;&#22312;&#22495;&#22806;&#25968;&#25454;&#19978;&#30340;&#22833;&#36133;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#35797;&#22270;&#25552;&#21462;&#20855;&#26377;&#19982;&#26631;&#31614;&#22312;&#19981;&#21516;&#22495;&#20043;&#38388;&#31283;&#23450;&#25110;&#19981;&#21464;&#20851;&#31995;&#30340;&#29305;&#24449;&#65292;&#33293;&#24323;&#19982;&#26631;&#31614;&#22312;&#19981;&#21516;&#22495;&#20043;&#38388;&#20851;&#31995;&#21464;&#21270;&#30340;"&#34394;&#20551;"&#25110;&#19981;&#31283;&#23450;&#29305;&#24449;&#12290;&#28982;&#32780;&#65292;&#19981;&#31283;&#23450;&#29305;&#24449;&#24120;&#24120;&#25658;&#24102;&#20851;&#20110;&#26631;&#31614;&#30340;&#34917;&#20805;&#20449;&#24687;&#65292;&#22914;&#26524;&#22312;&#27979;&#35797;&#22495;&#20013;&#27491;&#30830;&#20351;&#29992;&#65292;&#21487;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#26174;&#31034;&#22312;&#27809;&#26377;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#22914;&#20309;&#22312;&#27979;&#35797;&#22495;&#20013;&#20351;&#29992;&#36825;&#20123;&#19981;&#31283;&#23450;&#29305;&#24449;&#26159;&#21487;&#33021;&#30340;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#35777;&#26126;&#22522;&#20110;&#31283;&#23450;&#29305;&#24449;&#30340;&#20266;&#26631;&#31614;&#25552;&#20379;&#20102;&#36275;&#22815;&#30340;&#25351;&#23548;&#26469;&#20570;&#21040;&#36825;&#19968;&#28857;&#65292;&#21069;&#25552;&#26159;&#22312;&#32473;&#23450;&#26631;&#31614;&#30340;&#26465;&#20214;&#19979;&#65292;&#31283;&#23450;&#29305;&#24449;&#21644;&#19981;&#31283;&#23450;&#29305;&#24449;&#26159;&#26465;&#20214;&#29420;&#31435;&#30340;&#12290;&#22522;&#20110;&#36825;&#20010;&#29702;&#35770;&#27934;&#35265;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31283;&#23450;&#29305;&#24449;&#22686;&#24378;&#65288;SFB&#65289;&#31639;&#27861;&#65306;(i)&#23398;&#20064;&#19968;&#20010;&#33021;&#22815;&#20998;&#31163;&#31283;&#23450;&#29305;&#24449;&#21644;&#26465;&#20214;&#29420;&#31435;&#19981;&#31283;&#23450;&#29305;&#24449;&#30340;&#39044;&#27979;&#22120;&#65307;(ii)&#20351;&#29992;&#31283;&#23450;&#29305;&#24449;&#39044;&#27979;&#26469;&#36866;&#24212;&#27979;&#35797;&#22495;
&lt;/p&gt;
&lt;p&gt;
To avoid failures on out-of-distribution data, recent works have sought to extract features that have a stable or invariant relationship with the label across domains, discarding the "spurious" or unstable features whose relationship with the label changes across domains. However, unstable features often carry complementary information about the label that could boost performance if used correctly in the test domain. Our main contribution is to show that it is possible to learn how to use these unstable features in the test domain without labels. In particular, we prove that pseudo-labels based on stable features provide sufficient guidance for doing so, provided that stable and unstable features are conditionally independent given the label. Based on this theoretical insight, we propose Stable Feature Boosting (SFB), an algorithm for: (i) learning a predictor that separates stable and conditionally-independent unstable features; and (ii) using the stable-feature predictions to adapt t
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#31232;&#30095;&#27491;&#21017;&#26368;&#20248;&#20256;&#36755;&#36827;&#34892;&#27969;&#24418;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26500;&#24314;&#20102;&#19968;&#20010;&#31232;&#30095;&#33258;&#36866;&#24212;&#30340;&#20146;&#21644;&#30697;&#38453;&#65292;&#24182;&#22312;&#36830;&#32493;&#26497;&#38480;&#19979;&#19982;&#25289;&#26222;&#25289;&#26031;&#22411;&#31639;&#23376;&#19968;&#33268;&#12290;</title><link>http://arxiv.org/abs/2307.09816</link><description>&lt;p&gt;
&#29992;&#31232;&#30095;&#27491;&#21017;&#26368;&#20248;&#20256;&#36755;&#36827;&#34892;&#27969;&#24418;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Manifold Learning with Sparse Regularised Optimal Transport. (arXiv:2307.09816v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09816
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#31232;&#30095;&#27491;&#21017;&#26368;&#20248;&#20256;&#36755;&#36827;&#34892;&#27969;&#24418;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26500;&#24314;&#20102;&#19968;&#20010;&#31232;&#30095;&#33258;&#36866;&#24212;&#30340;&#20146;&#21644;&#30697;&#38453;&#65292;&#24182;&#22312;&#36830;&#32493;&#26497;&#38480;&#19979;&#19982;&#25289;&#26222;&#25289;&#26031;&#22411;&#31639;&#23376;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27969;&#24418;&#23398;&#20064;&#26159;&#29616;&#20195;&#32479;&#35745;&#23398;&#21644;&#25968;&#25454;&#31185;&#23398;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#20219;&#21153;&#12290;&#35768;&#22810;&#25968;&#25454;&#38598;&#65288;&#32454;&#32990;&#12289;&#25991;&#26723;&#12289;&#22270;&#20687;&#12289;&#20998;&#23376;&#65289;&#21487;&#20197;&#34987;&#34920;&#31034;&#20026;&#23884;&#20837;&#22312;&#39640;&#32500;&#29615;&#22659;&#31354;&#38388;&#20013;&#30340;&#28857;&#20113;&#65292;&#28982;&#32780;&#25968;&#25454;&#22266;&#26377;&#30340;&#33258;&#30001;&#24230;&#36890;&#24120;&#36828;&#36828;&#23569;&#20110;&#29615;&#22659;&#32500;&#24230;&#30340;&#25968;&#37327;&#12290;&#26816;&#27979;&#25968;&#25454;&#23884;&#20837;&#30340;&#28508;&#22312;&#27969;&#24418;&#26159;&#35768;&#22810;&#19979;&#28216;&#20998;&#26512;&#30340;&#20808;&#20915;&#26465;&#20214;&#12290;&#29616;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#32463;&#24120;&#21463;&#21040;&#22122;&#22768;&#35266;&#27979;&#21644;&#25277;&#26679;&#30340;&#24433;&#21709;&#65292;&#22240;&#27492;&#25552;&#21462;&#20851;&#20110;&#28508;&#22312;&#27969;&#24418;&#30340;&#20449;&#24687;&#26159;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#23545;&#31216;&#29256;&#26412;&#30340;&#26368;&#20248;&#20256;&#36755;&#21644;&#20108;&#27425;&#27491;&#21017;&#21270;&#30340;&#27969;&#24418;&#23398;&#20064;&#26041;&#27861;&#65292;&#23427;&#26500;&#24314;&#20102;&#19968;&#20010;&#31232;&#30095;&#33258;&#36866;&#24212;&#30340;&#20146;&#21644;&#30697;&#38453;&#65292;&#21487;&#20197;&#35299;&#37322;&#20026;&#21452;&#38543;&#26426;&#26680;&#24402;&#19968;&#21270;&#30340;&#25512;&#24191;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#36830;&#32493;&#26497;&#38480;&#19979;&#20135;&#29983;&#30340;&#26680;&#19982;&#25289;&#26222;&#25289;&#26031;&#22411;&#31639;&#23376;&#19968;&#33268;&#65292;&#24182;&#24314;&#31435;&#20102;&#35813;&#26041;&#27861;&#30340;&#20581;&#22766;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Manifold learning is a central task in modern statistics and data science. Many datasets (cells, documents, images, molecules) can be represented as point clouds embedded in a high dimensional ambient space, however the degrees of freedom intrinsic to the data are usually far fewer than the number of ambient dimensions. The task of detecting a latent manifold along which the data are embedded is a prerequisite for a wide family of downstream analyses. Real-world datasets are subject to noisy observations and sampling, so that distilling information about the underlying manifold is a major challenge. We propose a method for manifold learning that utilises a symmetric version of optimal transport with a quadratic regularisation that constructs a sparse and adaptive affinity matrix, that can be interpreted as a generalisation of the bistochastic kernel normalisation. We prove that the resulting kernel is consistent with a Laplace-type operator in the continuous limit, establish robustness
&lt;/p&gt;</description></item><item><title>R-Learning&#22312;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#26102;&#37319;&#29992;&#20102;&#36870;&#21464;&#25968;&#21152;&#26435;&#30340;&#24418;&#24335;&#26469;&#31283;&#23450;&#22238;&#24402;&#65292;&#24182;&#31616;&#21270;&#20102;&#20559;&#24046;&#39033;&#12290;</title><link>http://arxiv.org/abs/2307.09700</link><description>&lt;p&gt;
R-Learning&#19982;&#24322;&#36136;&#24615;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#20013;&#30340;&#36870;&#21464;&#25968;&#21152;&#26435;&#30340;&#36830;&#25509;
&lt;/p&gt;
&lt;p&gt;
The Connection Between R-Learning and Inverse-Variance Weighting for Estimation of Heterogeneous Treatment Effects. (arXiv:2307.09700v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09700
&lt;/p&gt;
&lt;p&gt;
R-Learning&#22312;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#26102;&#37319;&#29992;&#20102;&#36870;&#21464;&#25968;&#21152;&#26435;&#30340;&#24418;&#24335;&#26469;&#31283;&#23450;&#22238;&#24402;&#65292;&#24182;&#31616;&#21270;&#20102;&#20559;&#24046;&#39033;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30340;&#21160;&#26426;&#26159;&#20026;&#20102;&#25506;&#35752;&#24191;&#27867;&#27969;&#34892;&#30340;&#8220;R-Learner&#8221;&#30340;&#24615;&#33021;&#12290;&#20687;&#20854;&#20182;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#65288;CATEs&#65289;&#30340;&#26041;&#27861;&#19968;&#26679;&#65292;R-Learning&#21487;&#20197;&#34920;&#31034;&#20026;&#21152;&#26435;&#20266;&#32467;&#26524;&#22238;&#24402;&#65288;POR&#65289;&#12290;&#20808;&#21069;&#23545;POR&#25216;&#26415;&#30340;&#27604;&#36739;&#24050;&#32463;&#20180;&#32454;&#27880;&#24847;&#20102;&#20266;&#32467;&#26524;&#36716;&#25442;&#30340;&#36873;&#25321;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35748;&#20026;&#24615;&#33021;&#30340;&#20027;&#35201;&#39537;&#21160;&#22240;&#32032;&#23454;&#38469;&#19978;&#26159;&#26435;&#37325;&#30340;&#36873;&#25321;&#12290;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#35748;&#20026;R-Learning&#38544;&#24335;&#22320;&#25191;&#34892;&#20102;&#21152;&#26435;&#24418;&#24335;&#30340;POR&#65292;&#20854;&#20013;&#26435;&#37325;&#31283;&#23450;&#20102;&#22238;&#24402;&#65292;&#24182;&#20801;&#35768;&#23545;&#20559;&#24046;&#39033;&#36827;&#34892;&#26041;&#20415;&#30340;&#31616;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Our motivation is to shed light the performance of the widely popular "R-Learner." Like many other methods for estimating conditional average treatment effects (CATEs), R-Learning can be expressed as a weighted pseudo-outcome regression (POR). Previous comparisons of POR techniques have paid careful attention to the choice of pseudo-outcome transformation. However, we argue that the dominant driver of performance is actually the choice of weights. Specifically, we argue that R-Learning implicitly performs an inverse-variance weighted form of POR. These weights stabilize the regression and allow for convenient simplifications of bias terms.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#35270;&#35282;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#22810;&#21464;&#37327;&#36890;&#36947;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#20043;&#38388;&#36827;&#34892;&#36801;&#31227;&#23398;&#20064;&#12290;&#36890;&#36807;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#65292;&#32467;&#21512;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#21644;TS2Vec&#25439;&#22833;&#65292;&#35813;&#26041;&#27861;&#22312;&#22823;&#22810;&#25968;&#35774;&#32622;&#19979;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.09614</link><description>&lt;p&gt;
&#22810;&#35270;&#35282;&#33258;&#30417;&#30563;&#23398;&#20064;&#29992;&#20110;&#22810;&#21464;&#37327;&#36890;&#36947;&#26102;&#38388;&#24207;&#21015;
&lt;/p&gt;
&lt;p&gt;
Multi-view self-supervised learning for multivariate variable-channel time series. (arXiv:2307.09614v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09614
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#35270;&#35282;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#22810;&#21464;&#37327;&#36890;&#36947;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#20043;&#38388;&#36827;&#34892;&#36801;&#31227;&#23398;&#20064;&#12290;&#36890;&#36807;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#65292;&#32467;&#21512;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#21644;TS2Vec&#25439;&#22833;&#65292;&#35813;&#26041;&#27861;&#22312;&#22823;&#22810;&#25968;&#35774;&#32622;&#19979;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#22810;&#21464;&#37327;&#29983;&#29289;&#21307;&#23398;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#36827;&#34892;&#26631;&#27880;&#26159;&#19968;&#39033;&#32321;&#37325;&#21644;&#26114;&#36149;&#30340;&#20219;&#21153;&#12290;&#33258;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#36890;&#36807;&#23545;&#26410;&#26631;&#35760;&#25968;&#25454;&#36827;&#34892;&#39044;&#35757;&#32451;&#26469;&#20943;&#23569;&#23545;&#22823;&#22411;&#26631;&#35760;&#25968;&#25454;&#38598;&#30340;&#38656;&#27714;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#36755;&#20837;&#36890;&#36947;&#30340;&#38598;&#21512;&#22312;&#19981;&#21516;&#24212;&#29992;&#20043;&#38388;&#36890;&#24120;&#20250;&#26377;&#25152;&#21464;&#21270;&#65292;&#32780;&#22823;&#22810;&#25968;&#29616;&#26377;&#24037;&#20316;&#24182;&#19981;&#20801;&#35768;&#22312;&#20855;&#26377;&#19981;&#21516;&#36755;&#20837;&#36890;&#36947;&#38598;&#21512;&#30340;&#25968;&#25454;&#38598;&#20043;&#38388;&#36827;&#34892;&#36801;&#31227;&#23398;&#20064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#19968;&#31181;&#32534;&#30721;&#22120;&#26469;&#20998;&#21035;&#22788;&#29702;&#25152;&#26377;&#36755;&#20837;&#36890;&#36947;&#30340;&#26041;&#27861;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#22312;&#36890;&#36947;&#20043;&#38388;&#25552;&#21462;&#21333;&#19968;&#34920;&#31034;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#19968;&#20010;&#20855;&#26377;&#20845;&#20010;&#33041;&#30005;&#22270;&#36890;&#36947;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#65292;&#24182;&#22312;&#19968;&#20010;&#20855;&#26377;&#20004;&#20010;&#19981;&#21516;&#33041;&#30005;&#22270;&#36890;&#36947;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#24494;&#35843;&#26469;&#23637;&#31034;&#36825;&#31181;&#26041;&#27861;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#20855;&#26377;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#21644;&#19981;&#20855;&#26377;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#30340;&#32593;&#32476;&#22312;&#19981;&#21516;&#23545;&#27604;&#25439;&#22833;&#20989;&#25968;&#19979;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#21457;&#29616;&#25105;&#20204;&#30340;&#26041;&#27861;&#32467;&#21512;&#20102;TS2Vec&#25439;&#22833;&#22312;&#22823;&#22810;&#25968;&#35774;&#32622;&#20013;&#30340;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#25152;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Labeling of multivariate biomedical time series data is a laborious and expensive process. Self-supervised contrastive learning alleviates the need for large, labeled datasets through pretraining on unlabeled data. However, for multivariate time series data the set of input channels often varies between applications, and most existing work does not allow for transfer between datasets with different sets of input channels. We propose learning one encoder to operate on all input channels individually. We then use a message passing neural network to extract a single representation across channels. We demonstrate the potential of this method by pretraining our network on a dataset with six EEG channels and finetuning on a dataset with two different EEG channels. We compare networks with and without the message passing neural network across different contrastive loss functions. We show that our method combined with the TS2Vec loss outperforms all other methods in most settings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#33258;&#21160;&#21457;&#29616;&#22797;&#26434;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#20934;&#30830;&#27169;&#22411;&#12290;&#22312;&#23454;&#39564;&#20013;&#26174;&#31034;&#65292;&#35813;&#26041;&#27861;&#30456;&#23545;&#20110;&#20043;&#21069;&#30340;&#26041;&#27861;&#65292;&#20855;&#26377;&#36739;&#24555;&#30340;&#36816;&#34892;&#36895;&#24230;&#24182;&#33021;&#22815;&#21457;&#29616;&#21512;&#29702;&#30340;&#27169;&#22411;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2307.09607</link><description>&lt;p&gt;
&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#23398;&#20064;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#32467;&#26500;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Sequential Monte Carlo Learning for Time Series Structure Discovery. (arXiv:2307.09607v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09607
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#33258;&#21160;&#21457;&#29616;&#22797;&#26434;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#20934;&#30830;&#27169;&#22411;&#12290;&#22312;&#23454;&#39564;&#20013;&#26174;&#31034;&#65292;&#35813;&#26041;&#27861;&#30456;&#23545;&#20110;&#20043;&#21069;&#30340;&#26041;&#27861;&#65292;&#20855;&#26377;&#36739;&#24555;&#30340;&#36816;&#34892;&#36895;&#24230;&#24182;&#33021;&#22815;&#21457;&#29616;&#21512;&#29702;&#30340;&#27169;&#22411;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#21457;&#29616;&#22797;&#26434;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20934;&#30830;&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#12290;&#22312;&#39640;&#26031;&#36807;&#31243;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#30340;&#31526;&#21495;&#31354;&#38388;&#19978;&#24037;&#20316;&#30340;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#20808;&#39564;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38598;&#25104;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#65288;SMC&#65289;&#21644;&#26059;&#25442;MCMC&#30340;&#26032;&#22411;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#65292;&#20197;&#23454;&#29616;&#39640;&#25928;&#30340;&#21518;&#39564;&#25512;&#26029;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#22312;&#8220;&#22312;&#32447;&#8221;&#35774;&#32622;&#20013;&#20351;&#29992;&#65292;&#20854;&#20013;&#26032;&#25968;&#25454;&#39034;&#24207;&#22320;&#21512;&#24182;&#22312;&#26102;&#38388;&#20013;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#8220;&#31163;&#32447;&#8221;&#35774;&#32622;&#20013;&#20351;&#29992;&#65292;&#36890;&#36807;&#20351;&#29992;&#21382;&#21490;&#25968;&#25454;&#30340;&#23884;&#22871;&#23376;&#38598;&#23545;&#21518;&#39564;&#36827;&#34892;&#36864;&#28779;&#12290;&#23545;&#30495;&#23454;&#19990;&#30028;&#30340;&#26102;&#38388;&#24207;&#21015;&#36827;&#34892;&#30340;&#23454;&#39564;&#27979;&#37327;&#32467;&#26524;&#26174;&#31034;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#30456;&#27604;&#20043;&#21069;&#38024;&#23545;&#30456;&#21516;&#27169;&#22411;&#26063;&#30340;MCMC&#21644;&#36138;&#24515;&#25628;&#32034;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#25552;&#20379;10&#20493;&#33267;100&#20493;&#30340;&#36816;&#34892;&#26102;&#38388;&#21152;&#36895;&#12290;&#25105;&#20204;&#20351;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#23545;1,428&#20010;&#35745;&#37327;&#32463;&#27982;&#25968;&#25454;&#38598;&#30340;&#30693;&#21517;&#22522;&#20934;&#36827;&#34892;&#20102;&#39318;&#27425;&#22823;&#35268;&#27169;&#30340;&#39640;&#26031;&#36807;&#31243;&#26102;&#38388;&#24207;&#21015;&#32467;&#26500;&#23398;&#20064;&#35780;&#20272;&#12290;&#32467;&#26524;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#21457;&#29616;&#21512;&#29702;&#30340;&#27169;&#22411;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a new approach to automatically discovering accurate models of complex time series data. Working within a Bayesian nonparametric prior over a symbolic space of Gaussian process time series models, we present a novel structure learning algorithm that integrates sequential Monte Carlo (SMC) and involutive MCMC for highly effective posterior inference. Our method can be used both in "online" settings, where new data is incorporated sequentially in time, and in "offline" settings, by using nested subsets of historical data to anneal the posterior. Empirical measurements on real-world time series show that our method can deliver 10x--100x runtime speedups over previous MCMC and greedy-search structure learning algorithms targeting the same model family. We use our method to perform the first large-scale evaluation of Gaussian process time series structure learning on a prominent benchmark of 1,428 econometric datasets. The results show that our method discovers sensible 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27809;&#26377;&#22522;&#20934;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#35780;&#20272;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#19981;&#21516;&#21464;&#37327;&#23376;&#38598;&#19978;&#23398;&#20064;&#30340;&#22240;&#26524;&#22270;&#20043;&#38388;&#30340;&#20860;&#23481;&#24615;&#26816;&#27979;&#65292;&#26469;&#20266;&#35777;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#26029;&#27491;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.09552</link><description>&lt;p&gt;
&#33258;&#25105;&#20860;&#23481;&#24615;&#65306;&#22312;&#27809;&#26377;&#22522;&#20934;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#35780;&#20272;&#22240;&#26524;&#21457;&#29616;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-Compatibility: Evaluating Causal Discovery without Ground Truth. (arXiv:2307.09552v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09552
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27809;&#26377;&#22522;&#20934;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#35780;&#20272;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#19981;&#21516;&#21464;&#37327;&#23376;&#38598;&#19978;&#23398;&#20064;&#30340;&#22240;&#26524;&#22270;&#20043;&#38388;&#30340;&#20860;&#23481;&#24615;&#26816;&#27979;&#65292;&#26469;&#20266;&#35777;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#26029;&#27491;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#22240;&#26524;&#22522;&#26412;&#20107;&#23454;&#38750;&#24120;&#32597;&#35265;&#65292;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#36890;&#24120;&#21482;&#22312;&#27169;&#25311;&#25968;&#25454;&#19978;&#36827;&#34892;&#35780;&#20272;&#12290;&#36825;&#20196;&#20154;&#25285;&#24551;&#65292;&#22240;&#20026;&#27169;&#25311;&#21453;&#26144;&#20102;&#20851;&#20110;&#22122;&#22768;&#20998;&#24067;&#12289;&#27169;&#22411;&#31867;&#21035;&#31561;&#29983;&#25104;&#36807;&#31243;&#30340;&#24120;&#35265;&#20551;&#35774;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#27809;&#26377;&#22522;&#20934;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#23545;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#30340;&#36755;&#20986;&#36827;&#34892;&#20266;&#35777;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#35265;&#35299;&#26159;&#65292;&#23613;&#31649;&#32479;&#35745;&#23398;&#20064;&#23547;&#27714;&#25968;&#25454;&#28857;&#23376;&#38598;&#20043;&#38388;&#30340;&#31283;&#23450;&#24615;&#65292;&#20294;&#22240;&#26524;&#23398;&#20064;&#24212;&#35813;&#23547;&#27714;&#21464;&#37327;&#23376;&#38598;&#20043;&#38388;&#30340;&#31283;&#23450;&#24615;&#12290;&#22522;&#20110;&#36825;&#20010;&#35265;&#35299;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#22312;&#19981;&#21516;&#21464;&#37327;&#23376;&#38598;&#19978;&#23398;&#20064;&#30340;&#22240;&#26524;&#22270;&#20043;&#38388;&#30340;&#20860;&#23481;&#24615;&#27010;&#24565;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#26816;&#27979;&#19981;&#20860;&#23481;&#24615;&#21487;&#20197;&#20266;&#35777;&#22240;&#26524;&#20851;&#31995;&#34987;&#38169;&#35823;&#25512;&#26029;&#30340;&#21407;&#22240;&#65292;&#36825;&#26159;&#22240;&#20026;&#20551;&#35774;&#36829;&#21453;&#25110;&#26377;&#38480;&#26679;&#26412;&#25928;&#24212;&#24102;&#26469;&#30340;&#38169;&#35823;&#12290;&#34429;&#28982;&#36890;&#36807;&#36825;&#31181;&#20860;&#23481;&#24615;&#27979;&#35797;&#21482;&#26159;&#23545;&#33391;&#22909;&#24615;&#33021;&#30340;&#24517;&#35201;&#26465;&#20214;&#65292;&#20294;&#25105;&#20204;&#35748;&#20026;&#23427;&#25552;&#20379;&#20102;&#24378;&#26377;&#21147;&#30340;&#35777;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
As causal ground truth is incredibly rare, causal discovery algorithms are commonly only evaluated on simulated data. This is concerning, given that simulations reflect common preconceptions about generating processes regarding noise distributions, model classes, and more. In this work, we propose a novel method for falsifying the output of a causal discovery algorithm in the absence of ground truth. Our key insight is that while statistical learning seeks stability across subsets of data points, causal learning should seek stability across subsets of variables. Motivated by this insight, our method relies on a notion of compatibility between causal graphs learned on different subsets of variables. We prove that detecting incompatibilities can falsify wrongly inferred causal relations due to violation of assumptions or errors from finite sample effects. Although passing such compatibility tests is only a necessary criterion for good performance, we argue that it provides strong evidenc
&lt;/p&gt;</description></item><item><title>BOF-UCB&#26159;&#19968;&#31181;&#29992;&#20110;&#38750;&#24179;&#31283;&#29615;&#22659;&#19979;&#30340;&#32972;&#26223;&#32447;&#24615;&#36172;&#21338;&#26426;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#39057;&#29575;&#31639;&#27861;&#65292;&#20854;&#32467;&#21512;&#20102;&#36125;&#21494;&#26031;&#21644;&#39057;&#29575;&#23398;&#27966;&#21407;&#21017;&#65292;&#25552;&#39640;&#20102;&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#30340;&#24615;&#33021;&#12290;&#23427;&#21033;&#29992;&#36125;&#21494;&#26031;&#26356;&#26032;&#25512;&#26029;&#21518;&#39564;&#20998;&#24067;&#65292;&#24182;&#20351;&#29992;&#39057;&#29575;&#23398;&#27966;&#26041;&#27861;&#35745;&#31639;&#19978;&#30028;&#20449;&#24515;&#30028;&#20197;&#24179;&#34913;&#25506;&#32034;&#21644;&#24320;&#21457;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;BOF-UCB&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#26159;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#39034;&#24207;&#20915;&#31574;&#30340;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2307.03587</link><description>&lt;p&gt;
BOF-UCB: &#19968;&#31181;&#29992;&#20110;&#38750;&#24179;&#31283;&#29615;&#22659;&#19979;&#30340;&#19978;&#19979;&#30028;&#20449;&#24515;&#31639;&#27861;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#39057;&#29575;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
BOF-UCB: A Bayesian-Optimistic Frequentist Algorithm for Non-Stationary Contextual Bandits. (arXiv:2307.03587v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03587
&lt;/p&gt;
&lt;p&gt;
BOF-UCB&#26159;&#19968;&#31181;&#29992;&#20110;&#38750;&#24179;&#31283;&#29615;&#22659;&#19979;&#30340;&#32972;&#26223;&#32447;&#24615;&#36172;&#21338;&#26426;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#39057;&#29575;&#31639;&#27861;&#65292;&#20854;&#32467;&#21512;&#20102;&#36125;&#21494;&#26031;&#21644;&#39057;&#29575;&#23398;&#27966;&#21407;&#21017;&#65292;&#25552;&#39640;&#20102;&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#30340;&#24615;&#33021;&#12290;&#23427;&#21033;&#29992;&#36125;&#21494;&#26031;&#26356;&#26032;&#25512;&#26029;&#21518;&#39564;&#20998;&#24067;&#65292;&#24182;&#20351;&#29992;&#39057;&#29575;&#23398;&#27966;&#26041;&#27861;&#35745;&#31639;&#19978;&#30028;&#20449;&#24515;&#30028;&#20197;&#24179;&#34913;&#25506;&#32034;&#21644;&#24320;&#21457;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;BOF-UCB&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#26159;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#39034;&#24207;&#20915;&#31574;&#30340;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#39057;&#29575;&#19978;&#19979;&#30028;&#20449;&#24515;&#31639;&#27861;&#65288;BOF-UCB&#65289;&#65292;&#29992;&#20110;&#38750;&#24179;&#31283;&#29615;&#22659;&#19979;&#30340;&#38543;&#26426;&#32972;&#26223;&#32447;&#24615;&#36172;&#21338;&#26426;&#12290;&#36125;&#21494;&#26031;&#21644;&#39057;&#29575;&#23398;&#27966;&#21407;&#21017;&#30340;&#29420;&#29305;&#32467;&#21512;&#22686;&#24378;&#20102;&#31639;&#27861;&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#30340;&#36866;&#24212;&#24615;&#21644;&#24615;&#33021;&#12290;BOF-UCB&#31639;&#27861;&#21033;&#29992;&#39034;&#24207;&#36125;&#21494;&#26031;&#26356;&#26032;&#25512;&#26029;&#26410;&#30693;&#22238;&#24402;&#21442;&#25968;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#24182;&#38543;&#21518;&#37319;&#29992;&#39057;&#29575;&#23398;&#27966;&#26041;&#27861;&#36890;&#36807;&#26368;&#22823;&#21270;&#21518;&#39564;&#20998;&#24067;&#19978;&#30340;&#26399;&#26395;&#25910;&#30410;&#26469;&#35745;&#31639;&#19978;&#30028;&#20449;&#24515;&#30028;&#65288;UCB&#65289;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;BOF-UCB&#24615;&#33021;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#24378;&#21270;&#23398;&#20064;&#29615;&#22659;&#20013;&#30340;&#32463;&#20856;&#25511;&#21046;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;BOF-UCB&#20248;&#20110;&#29616;&#26377;&#30340;&#26041;&#27861;&#65292;&#22312;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#36827;&#34892;&#39034;&#24207;&#20915;&#31574;&#26159;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel Bayesian-Optimistic Frequentist Upper Confidence Bound (BOF-UCB) algorithm for stochastic contextual linear bandits in non-stationary environments. This unique combination of Bayesian and frequentist principles enhances adaptability and performance in dynamic settings. The BOF-UCB algorithm utilizes sequential Bayesian updates to infer the posterior distribution of the unknown regression parameter, and subsequently employs a frequentist approach to compute the Upper Confidence Bound (UCB) by maximizing the expected reward over the posterior distribution. We provide theoretical guarantees of BOF-UCB's performance and demonstrate its effectiveness in balancing exploration and exploitation on synthetic datasets and classical control tasks in a reinforcement learning setting. Our results show that BOF-UCB outperforms existing methods, making it a promising solution for sequential decision-making in non-stationary environments.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#35745;&#31639;&#26377;&#25928;$p$-&#38459;&#25239;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#22810;&#31867;&#22270;&#32858;&#31867;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#36890;&#36807;&#21442;&#25968;$p$&#20559;&#21521;&#20110;&#20855;&#26377;&#39640;&#20869;&#37096;&#36830;&#36890;&#24615;&#25110;&#32773;&#26356;&#23567;&#30340;&#31751;&#20869;&#39030;&#28857;&#20043;&#38388;&#30340;&#26368;&#30701;&#36335;&#24452;&#36317;&#31163;&#30340;&#32858;&#31867;&#12290;</title><link>http://arxiv.org/abs/2306.08617</link><description>&lt;p&gt;
&#22522;&#20110;&#36817;&#20284;&#26377;&#25928;&#30340;$p$-&#38459;&#25239;&#30340;&#22810;&#31867;&#22270;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Multi-class Graph Clustering via Approximated Effective $p$-Resistance. (arXiv:2306.08617v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08617
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#35745;&#31639;&#26377;&#25928;$p$-&#38459;&#25239;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#22810;&#31867;&#22270;&#32858;&#31867;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#36890;&#36807;&#21442;&#25968;$p$&#20559;&#21521;&#20110;&#20855;&#26377;&#39640;&#20869;&#37096;&#36830;&#36890;&#24615;&#25110;&#32773;&#26356;&#23567;&#30340;&#31751;&#20869;&#39030;&#28857;&#20043;&#38388;&#30340;&#26368;&#30701;&#36335;&#24452;&#36317;&#31163;&#30340;&#32858;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#35745;&#31639;&#26377;&#25928;$p$-&#38459;&#25239;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#22810;&#31867;&#32858;&#31867;&#12290;&#22522;&#20110;&#22270;&#25289;&#26222;&#25289;&#26031;&#21644;&#20854;$p$-&#25289;&#26222;&#25289;&#26031;&#25512;&#24191;&#30340;&#35889;&#26041;&#27861;&#19968;&#30452;&#26159;&#38750;&#27431;&#20960;&#37324;&#24471;&#32858;&#31867;&#25216;&#26415;&#30340;&#25903;&#26609;&#12290;$p$-&#25289;&#26222;&#25289;&#26031;&#30340;&#20248;&#28857;&#22312;&#20110;&#21442;&#25968;$p$&#23545;&#32858;&#31867;&#32467;&#26500;&#20855;&#26377;&#21487;&#25511;&#20559;&#20506;&#12290;$p$-&#25289;&#26222;&#25289;&#26031;&#29305;&#24449;&#21521;&#37327;&#27861;&#30340;&#32570;&#28857;&#22312;&#20110;&#38590;&#20197;&#35745;&#31639;&#31532;&#19977;&#21644;&#26356;&#39640;&#38454;&#29305;&#24449;&#21521;&#37327;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#21160;&#26426;&#22312;&#20110;&#20351;&#29992;&#30001;$p$-&#25289;&#26222;&#25289;&#26031;&#24341;&#23548;&#30340;$p$-&#38459;&#25239;&#36827;&#34892;&#32858;&#31867;&#12290;&#23545;&#20110;$p$-&#38459;&#25239;&#32780;&#35328;&#65292;&#23567;$p$&#20250;&#20559;&#21521;&#20110;&#20855;&#26377;&#39640;&#20869;&#37096;&#36830;&#36890;&#24615;&#30340;&#32858;&#31867;&#65292;&#32780;&#22823;$p$&#21017;&#20250;&#20559;&#21521;&#20110;&#22823;&#23567;&#8220;&#33539;&#22260;&#8221;&#30340;&#32858;&#31867;&#65292;&#21363;&#26356;&#23567;&#30340;&#31751;&#20869;&#39030;&#28857;&#20043;&#38388;&#30340;&#26368;&#30701;&#36335;&#24452;&#36317;&#31163;&#12290;&#28982;&#32780;&#65292;&#35745;&#31639;$p$-&#38459;&#25239;&#25104;&#26412;&#24456;&#39640;&#12290;&#25105;&#20204;&#36890;&#36807;&#24320;&#21457;$p$-&#38459;&#25239;&#30340;&#36817;&#20284;&#26041;&#27861;&#26469;&#20811;&#26381;&#36825;&#19968;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19978;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper develops an approximation to the (effective) $p$-resistance and applies it to multi-class clustering. Spectral methods based on the graph Laplacian and its generalization to the graph $p$-Laplacian have been a backbone of non-euclidean clustering techniques. The advantage of the $p$-Laplacian is that the parameter $p$ induces a controllable bias on cluster structure. The drawback of $p$-Laplacian eigenvector based methods is that the third and higher eigenvectors are difficult to compute. Thus, instead, we are motivated to use the $p$-resistance induced by the $p$-Laplacian for clustering. For $p$-resistance, small $p$ biases towards clusters with high internal connectivity while large $p$ biases towards clusters of small ``extent,'' that is a preference for smaller shortest-path distances between vertices in the cluster. However, the $p$-resistance is expensive to compute. We overcome this by developing an approximation to the $p$-resistance. We prove upper and lower bounds
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#36317;&#31163;&#27861;&#24322;&#24120;&#26816;&#27979;&#20998;&#25968;&#36716;&#21270;&#20026;&#21487;&#35299;&#37322;&#30340;&#27010;&#29575;&#20272;&#35745;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#19982;&#20854;&#20182;&#25968;&#25454;&#28857;&#30340;&#36317;&#31163;&#24314;&#27169;&#36317;&#31163;&#27010;&#29575;&#20998;&#24067;&#65292;&#23558;&#36317;&#31163;&#27861;&#24322;&#24120;&#26816;&#27979;&#20998;&#25968;&#36716;&#25442;&#20026;&#24322;&#24120;&#27010;&#29575;&#65292;&#25552;&#39640;&#20102;&#27491;&#24120;&#28857;&#21644;&#24322;&#24120;&#28857;&#20043;&#38388;&#30340;&#23545;&#27604;&#24230;&#65292;&#32780;&#19981;&#20250;&#24433;&#21709;&#26816;&#27979;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.09446</link><description>&lt;p&gt;
&#27010;&#29575;&#36317;&#31163;&#27861;&#24322;&#24120;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Distance-Based Outlier Detection. (arXiv:2305.09446v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09446
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#36317;&#31163;&#27861;&#24322;&#24120;&#26816;&#27979;&#20998;&#25968;&#36716;&#21270;&#20026;&#21487;&#35299;&#37322;&#30340;&#27010;&#29575;&#20272;&#35745;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#19982;&#20854;&#20182;&#25968;&#25454;&#28857;&#30340;&#36317;&#31163;&#24314;&#27169;&#36317;&#31163;&#27010;&#29575;&#20998;&#24067;&#65292;&#23558;&#36317;&#31163;&#27861;&#24322;&#24120;&#26816;&#27979;&#20998;&#25968;&#36716;&#25442;&#20026;&#24322;&#24120;&#27010;&#29575;&#65292;&#25552;&#39640;&#20102;&#27491;&#24120;&#28857;&#21644;&#24322;&#24120;&#28857;&#20043;&#38388;&#30340;&#23545;&#27604;&#24230;&#65292;&#32780;&#19981;&#20250;&#24433;&#21709;&#26816;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36317;&#31163;&#27861;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#30340;&#20998;&#25968;&#38590;&#20197;&#35299;&#37322;&#65292;&#22240;&#27492;&#22312;&#27809;&#26377;&#39069;&#22806;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#65292;&#24456;&#38590;&#30830;&#23450;&#27491;&#24120;&#28857;&#21644;&#24322;&#24120;&#28857;&#20043;&#38388;&#30340;&#25130;&#26029;&#38408;&#20540;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#23558;&#36317;&#31163;&#27861;&#24322;&#24120;&#26816;&#27979;&#20998;&#25968;&#36716;&#21270;&#20026;&#21487;&#35299;&#37322;&#30340;&#27010;&#29575;&#20272;&#35745;&#30340;&#36890;&#29992;&#26041;&#27861;&#12290;&#35813;&#36716;&#25442;&#26159;&#25490;&#21517;&#31283;&#23450;&#30340;&#65292;&#24182;&#22686;&#21152;&#20102;&#27491;&#24120;&#28857;&#21644;&#24322;&#24120;&#28857;&#20043;&#38388;&#30340;&#23545;&#27604;&#24230;&#12290;&#30830;&#23450;&#25968;&#25454;&#28857;&#20043;&#38388;&#30340;&#36317;&#31163;&#20851;&#31995;&#26159;&#35782;&#21035;&#25968;&#25454;&#20013;&#26368;&#36817;&#37051;&#20851;&#31995;&#25152;&#24517;&#38656;&#30340;&#65292;&#28982;&#32780;&#22823;&#22810;&#25968;&#35745;&#31639;&#20986;&#30340;&#36317;&#31163;&#36890;&#24120;&#34987;&#20002;&#24323;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#20351;&#29992;&#19982;&#20854;&#20182;&#25968;&#25454;&#28857;&#30340;&#36317;&#31163;&#26469;&#24314;&#27169;&#36317;&#31163;&#27010;&#29575;&#20998;&#24067;&#65292;&#24182;&#38543;&#21518;&#20351;&#29992;&#36825;&#20123;&#20998;&#24067;&#23558;&#36317;&#31163;&#27861;&#24322;&#24120;&#26816;&#27979;&#20998;&#25968;&#36716;&#25442;&#20026;&#24322;&#24120;&#27010;&#29575;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#27010;&#29575;&#36716;&#25442;&#19981;&#20250;&#24433;&#21709;&#20247;&#22810;&#34920;&#26684;&#21644;&#22270;&#20687;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#26816;&#27979;&#24615;&#33021;&#65292;&#20294;&#20250;&#20135;&#29983;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The scores of distance-based outlier detection methods are difficult to interpret, making it challenging to determine a cut-off threshold between normal and outlier data points without additional context. We describe a generic transformation of distance-based outlier scores into interpretable, probabilistic estimates. The transformation is ranking-stable and increases the contrast between normal and outlier data points. Determining distance relationships between data points is necessary to identify the nearest-neighbor relationships in the data, yet, most of the computed distances are typically discarded. We show that the distances to other data points can be used to model distance probability distributions and, subsequently, use the distributions to turn distance-based outlier scores into outlier probabilities. Our experiments show that the probabilistic transformation does not impact detection performance over numerous tabular and image benchmark datasets but results in interpretable
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#24067;&#38647;-&#29926;&#29791;&#26031;&#22374;&#36317;&#31163;&#35757;&#32451;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#28145;&#24230;&#30697;&#38453;&#20998;&#35299;&#27169;&#22411;&#65292;&#24182;&#22312;&#26377;&#38480;&#31209;&#30697;&#38453;&#31354;&#38388;&#20869;&#34920;&#24449;&#20851;&#38190;&#28857;&#21644;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#26368;&#32456;&#30830;&#23450;&#20102;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.03027</link><description>&lt;p&gt;
&#24067;&#38647;-&#29926;&#29791;&#26031;&#22374;&#36317;&#31163;&#35757;&#32451;&#19979;&#30340;&#29983;&#25104;&#24335;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#30340;&#20851;&#38190;&#28857;&#21644;&#25910;&#25947;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Critical Points and Convergence Analysis of Generative Deep Linear Networks Trained with Bures-Wasserstein Loss. (arXiv:2303.03027v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.03027
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#24067;&#38647;-&#29926;&#29791;&#26031;&#22374;&#36317;&#31163;&#35757;&#32451;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#28145;&#24230;&#30697;&#38453;&#20998;&#35299;&#27169;&#22411;&#65292;&#24182;&#22312;&#26377;&#38480;&#31209;&#30697;&#38453;&#31354;&#38388;&#20869;&#34920;&#24449;&#20851;&#38190;&#28857;&#21644;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#26368;&#32456;&#30830;&#23450;&#20102;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#19968;&#31181;&#20351;&#29992;&#24067;&#38647;-&#29926;&#29791;&#26031;&#22374;&#36317;&#31163;&#35757;&#32451;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#28145;&#24230;&#30697;&#38453;&#20998;&#35299;&#27169;&#22411;&#12290;&#30456;&#36739;&#20110;&#20197;&#24448;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#22312;&#25439;&#22833;&#20989;&#25968;&#21644;&#29983;&#25104;&#24335;&#35774;&#32622;&#19978;&#26377;&#25152;&#19981;&#21516;&#12290;&#25105;&#20204;&#22312;&#26377;&#38480;&#31209;&#30697;&#38453;&#31354;&#38388;&#20869;&#34920;&#24449;&#20102;&#35813;&#26041;&#27861;&#30340;&#20851;&#38190;&#28857;&#21644;&#26368;&#23567;&#21270;&#38382;&#39064;&#12290;&#38024;&#23545;&#20302;&#31209;&#30697;&#38453;&#32780;&#35328;&#65292;&#35813;&#26041;&#27861;&#30340;&#28023;&#26862;&#30697;&#38453;&#29702;&#35770;&#19978;&#21487;&#33021;&#20250;&#29190;&#28856;&#65292;&#36825;&#20026;&#20248;&#21270;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#24102;&#26469;&#20102;&#25361;&#25112;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#20013;&#20351;&#29992;&#25439;&#22833;&#30340;&#24179;&#28369;&#24494;&#25200;&#29256;&#26412;&#26102;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#22312;&#21021;&#22987;&#26435;&#37325;&#30340;&#19968;&#23450;&#20551;&#35774;&#26465;&#20214;&#19979;&#35777;&#26126;&#20102;&#26377;&#38480;&#27493;&#38271;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a deep matrix factorization model of covariance matrices trained with the Bures-Wasserstein distance. While recent works have made important advances in the study of the optimization problem for overparametrized low-rank matrix approximation, much emphasis has been placed on discriminative settings and the square loss. In contrast, our model considers another interesting type of loss and connects with the generative setting. We characterize the critical points and minimizers of the Bures-Wasserstein distance over the space of rank-bounded matrices. For low-rank matrices the Hessian of this loss can theoretically blow up, which creates challenges to analyze convergence of optimizaton methods. We establish convergence results for gradient flow using a smooth perturbative version of the loss and convergence results for finite step size gradient descent under certain assumptions on the initial weights.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26368;&#22823;&#27844;&#38706;&#20998;&#26512;&#22122;&#22768;&#36845;&#20195;&#31639;&#27861;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#65292;&#35777;&#26126;&#20102;&#22914;&#26524;&#26356;&#26032;&#20989;&#25968;&#22312;L2-&#33539;&#25968;&#19979;&#26377;&#30028;&#19988;&#21152;&#24615;&#22122;&#22768;&#20026;&#21508;&#21521;&#21516;&#24615;&#39640;&#26031;&#22122;&#22768;&#65292;&#21017;&#21487;&#20197;&#24471;&#21040;&#19968;&#20010;&#21322;&#23553;&#38381;&#24418;&#24335;&#19979;&#30340;&#26368;&#22823;&#27844;&#38706;&#19978;&#30028;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#26356;&#26032;&#20989;&#25968;&#30340;&#20551;&#35774;&#22914;&#20309;&#24433;&#21709;&#22122;&#22768;&#30340;&#26368;&#20248;&#36873;&#25321;&#12290;</title><link>http://arxiv.org/abs/2302.14518</link><description>&lt;p&gt;
&#36890;&#36807;&#26368;&#22823;&#27844;&#38706;&#20998;&#26512;&#22122;&#22768;&#36845;&#20195;&#31639;&#27861;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Generalization Error Bounds for Noisy, Iterative Algorithms via Maximal Leakage. (arXiv:2302.14518v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.14518
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26368;&#22823;&#27844;&#38706;&#20998;&#26512;&#22122;&#22768;&#36845;&#20195;&#31639;&#27861;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#65292;&#35777;&#26126;&#20102;&#22914;&#26524;&#26356;&#26032;&#20989;&#25968;&#22312;L2-&#33539;&#25968;&#19979;&#26377;&#30028;&#19988;&#21152;&#24615;&#22122;&#22768;&#20026;&#21508;&#21521;&#21516;&#24615;&#39640;&#26031;&#22122;&#22768;&#65292;&#21017;&#21487;&#20197;&#24471;&#21040;&#19968;&#20010;&#21322;&#23553;&#38381;&#24418;&#24335;&#19979;&#30340;&#26368;&#22823;&#27844;&#38706;&#19978;&#30028;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#26356;&#26032;&#20989;&#25968;&#30340;&#20551;&#35774;&#22914;&#20309;&#24433;&#21709;&#22122;&#22768;&#30340;&#26368;&#20248;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#37319;&#29992;&#20449;&#24687;&#35770;&#26694;&#26550;&#26469;&#20998;&#26512;&#19968;&#31867;&#36845;&#20195;&#24335;&#12289;&#24102;&#26377;&#22122;&#22768;&#30340;&#23398;&#20064;&#31639;&#27861;&#30340;&#27867;&#21270;&#34892;&#20026;&#12290;&#30001;&#20110;&#36825;&#31867;&#31639;&#27861;&#20855;&#26377;&#38543;&#26426;&#24615;&#65292;&#24182;&#19988;&#21253;&#21547;&#24120;&#29992;&#30340;&#31639;&#27861;&#65288;&#22914;&#38543;&#26426;&#26799;&#24230; Langevin &#21160;&#21147;&#23398;&#65289;&#65292;&#25152;&#20197;&#22312;&#20449;&#24687;&#35770;&#24230;&#37327;&#19979;&#30740;&#31350;&#23427;&#20204;&#23588;&#20026;&#21512;&#36866;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#26368;&#22823;&#27844;&#38706;&#65288;&#31561;&#20215;&#20110;&#26080;&#31351;&#38454; Sibson &#20114;&#20449;&#24687;&#65289;&#24230;&#37327;&#65292;&#22240;&#20854;&#26131;&#20110;&#20998;&#26512;&#19988;&#21487;&#20197;&#21516;&#26102;&#33719;&#24471;&#27867;&#21270;&#35823;&#24046;&#22823;&#27010;&#29575;&#19978;&#30028;&#21644;&#26399;&#26395;&#20540;&#19978;&#30028;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22914;&#26524;&#26356;&#26032;&#20989;&#25968;&#65288;&#22914;&#26799;&#24230;&#65289;&#22312;L2-&#33539;&#25968;&#19979;&#26377;&#30028;&#65292;&#19988;&#21152;&#24615;&#22122;&#22768;&#20026;&#21508;&#21521;&#21516;&#24615;&#39640;&#26031;&#22122;&#22768;&#65292;&#21017;&#21487;&#20197;&#24471;&#21040;&#19968;&#20010;&#21322;&#23553;&#38381;&#24418;&#24335;&#19979;&#30340;&#26368;&#22823;&#27844;&#38706;&#19978;&#30028;&#12290;&#21478;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#26356;&#26032;&#20989;&#25968;&#30340;&#20551;&#35774;&#22914;&#20309;&#24433;&#21709;&#22122;&#22768;&#30340;&#26368;&#20248;&#36873;&#25321;&#65288;&#21363;&#26368;&#23567;&#21270;&#20135;&#29983;&#30340;&#26368;&#22823;&#27844;&#38706;&#65289;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35745;&#31639;&#20102;...
&lt;/p&gt;
&lt;p&gt;
We adopt an information-theoretic framework to analyze the generalization behavior of the class of iterative, noisy learning algorithms. This class is particularly suitable for study under information-theoretic metrics as the algorithms are inherently randomized, and it includes commonly used algorithms such as Stochastic Gradient Langevin Dynamics (SGLD). Herein, we use the maximal leakage (equivalently, the Sibson mutual information of order infinity) metric, as it is simple to analyze, and it implies both bounds on the probability of having a large generalization error and on its expected value. We show that, if the update function (e.g., gradient) is bounded in $L_2$-norm and the additive noise is isotropic Gaussian noise, then one can obtain an upper-bound on maximal leakage in semi-closed form. Furthermore, we demonstrate how the assumptions on the update function affect the optimal (in the sense of minimizing the induced maximal leakage) choice of the noise. Finally, we compute 
&lt;/p&gt;</description></item><item><title>CO-BED&#26159;&#19968;&#20010;&#36890;&#29992;&#30340;&#12289;&#19982;&#27169;&#22411;&#26080;&#20851;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#36890;&#36807;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#30340;&#20449;&#24687;&#29702;&#35770;&#26469;&#36827;&#34892;&#19978;&#19979;&#25991;&#20248;&#21270;&#12290;&#23427;&#37319;&#29992;&#40657;&#31665;&#21464;&#20998;&#26041;&#27861;&#21516;&#26102;&#20272;&#35745;&#21644;&#20248;&#21270;&#35774;&#35745;&#65292;&#21487;&#20197;&#36866;&#24212;&#31163;&#25955;&#21160;&#20316;&#65292;&#24182;&#22312;&#22810;&#20010;&#23454;&#39564;&#20013;&#23637;&#31034;&#20986;&#31454;&#20105;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2302.14015</link><description>&lt;p&gt;
CO-BED&#65306;&#36890;&#36807;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#30340;&#20449;&#24687;&#29702;&#35770;&#19978;&#19979;&#25991;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
CO-BED: Information-Theoretic Contextual Optimization via Bayesian Experimental Design. (arXiv:2302.14015v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.14015
&lt;/p&gt;
&lt;p&gt;
CO-BED&#26159;&#19968;&#20010;&#36890;&#29992;&#30340;&#12289;&#19982;&#27169;&#22411;&#26080;&#20851;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#36890;&#36807;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#30340;&#20449;&#24687;&#29702;&#35770;&#26469;&#36827;&#34892;&#19978;&#19979;&#25991;&#20248;&#21270;&#12290;&#23427;&#37319;&#29992;&#40657;&#31665;&#21464;&#20998;&#26041;&#27861;&#21516;&#26102;&#20272;&#35745;&#21644;&#20248;&#21270;&#35774;&#35745;&#65292;&#21487;&#20197;&#36866;&#24212;&#31163;&#25955;&#21160;&#20316;&#65292;&#24182;&#22312;&#22810;&#20010;&#23454;&#39564;&#20013;&#23637;&#31034;&#20986;&#31454;&#20105;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#30340;&#35270;&#35282;&#23545;&#19978;&#19979;&#25991;&#20248;&#21270;&#38382;&#39064;&#36827;&#34892;&#20102;&#24418;&#24335;&#21270;&#65292;&#24182;&#25552;&#20986;&#20102;CO-BED - &#19968;&#20010;&#36890;&#29992;&#30340;&#12289;&#19982;&#27169;&#22411;&#26080;&#20851;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#20351;&#29992;&#20449;&#24687;&#29702;&#35770;&#21407;&#21017;&#35774;&#35745;&#19978;&#19979;&#25991;&#23454;&#39564;&#12290;&#22312;&#21046;&#23450;&#21512;&#36866;&#30340;&#22522;&#20110;&#20449;&#24687;&#30340;&#30446;&#26631;&#21518;&#65292;&#25105;&#20204;&#37319;&#29992;&#40657;&#31665;&#21464;&#20998;&#26041;&#27861;&#22312;&#21333;&#19968;&#38543;&#26426;&#26799;&#24230;&#26041;&#26696;&#20013;&#21516;&#26102;&#20272;&#35745;&#21644;&#20248;&#21270;&#35774;&#35745;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#36866;&#24212;&#25105;&#20204;&#26694;&#26550;&#20013;&#30340;&#31163;&#25955;&#21160;&#20316;&#65292;&#25105;&#20204;&#25552;&#35758;&#21033;&#29992;&#36830;&#32493;&#26494;&#24347;&#26041;&#26696;&#65292;&#36825;&#21487;&#20197;&#33258;&#28982;&#22320;&#38598;&#25104;&#21040;&#25105;&#20204;&#21464;&#20998;&#30446;&#26631;&#20013;&#12290;&#22240;&#27492;&#65292;CO-BED&#20026;&#21508;&#31181;&#19978;&#19979;&#25991;&#20248;&#21270;&#38382;&#39064;&#25552;&#20379;&#20102;&#36890;&#29992;&#30340;&#33258;&#21160;&#21270;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#22312;&#35768;&#22810;&#23454;&#39564;&#20013;&#28436;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#65292;&#21363;&#20351;&#19982;&#23450;&#21046;&#30340;&#12289;&#29305;&#23450;&#20110;&#27169;&#22411;&#30340;&#26367;&#20195;&#26041;&#27861;&#30456;&#27604;&#65292;CO-BED&#20063;&#34920;&#29616;&#20986;&#20102;&#31454;&#20105;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We formalize the problem of contextual optimization through the lens of Bayesian experimental design and propose CO-BED -- a general, model-agnostic framework for designing contextual experiments using information-theoretic principles. After formulating a suitable information-based objective, we employ black-box variational methods to simultaneously estimate it and optimize the designs in a single stochastic gradient scheme. In addition, to accommodate discrete actions within our framework, we propose leveraging continuous relaxation schemes, which can naturally be integrated into our variational objective. As a result, CO-BED provides a general and automated solution to a wide range of contextual optimization problems. We illustrate its effectiveness in a number of experiments, where CO-BED demonstrates competitive performance even when compared to bespoke, model-specific alternatives.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#39034;&#24207;&#26680;&#29420;&#31435;&#24615;&#27979;&#35797;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#20256;&#32479;&#25209;&#37327;&#27979;&#35797;&#22312;&#27969;&#25968;&#25454;&#19978;&#30340;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#26681;&#25454;&#20219;&#21153;&#22797;&#26434;&#24615;&#33258;&#36866;&#24212;&#35843;&#25972;&#26679;&#26412;&#22823;&#23567;&#65292;&#24182;&#22312;&#25910;&#38598;&#26032;&#25968;&#25454;&#21518;&#25345;&#32493;&#30417;&#27979;&#21644;&#25511;&#21046;&#35823;&#25253;&#29575;&#12290;</title><link>http://arxiv.org/abs/2212.07383</link><description>&lt;p&gt;
&#39034;&#24207;&#26680;&#29420;&#31435;&#24615;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Sequential Kernelized Independence Testing. (arXiv:2212.07383v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.07383
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#39034;&#24207;&#26680;&#29420;&#31435;&#24615;&#27979;&#35797;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#20256;&#32479;&#25209;&#37327;&#27979;&#35797;&#22312;&#27969;&#25968;&#25454;&#19978;&#30340;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#26681;&#25454;&#20219;&#21153;&#22797;&#26434;&#24615;&#33258;&#36866;&#24212;&#35843;&#25972;&#26679;&#26412;&#22823;&#23567;&#65292;&#24182;&#22312;&#25910;&#38598;&#26032;&#25968;&#25454;&#21518;&#25345;&#32493;&#30417;&#27979;&#21644;&#25511;&#21046;&#35823;&#25253;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29420;&#31435;&#24615;&#27979;&#35797;&#26159;&#19968;&#20010;&#32463;&#20856;&#30340;&#32479;&#35745;&#38382;&#39064;&#65292;&#22312;&#22266;&#23450;&#37319;&#38598;&#25968;&#25454;&#20043;&#21069;&#30340;&#25209;&#37327;&#35774;&#32622;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#23454;&#36341;&#32773;&#20204;&#24448;&#24448;&#26356;&#21916;&#27426;&#33021;&#22815;&#26681;&#25454;&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#36827;&#34892;&#33258;&#36866;&#24212;&#30340;&#31243;&#24207;&#65292;&#32780;&#19981;&#26159;&#20107;&#20808;&#35774;&#23450;&#26679;&#26412;&#22823;&#23567;&#12290;&#29702;&#24819;&#24773;&#20917;&#19979;&#65292;&#36825;&#26679;&#30340;&#31243;&#24207;&#24212;&#35813;&#65288;a&#65289;&#22312;&#31616;&#21333;&#20219;&#21153;&#19978;&#23613;&#26089;&#20572;&#27490;&#65288;&#22312;&#22256;&#38590;&#20219;&#21153;&#19978;&#31245;&#21518;&#20572;&#27490;&#65289;&#65292;&#22240;&#27492;&#26356;&#22909;&#22320;&#21033;&#29992;&#21487;&#29992;&#36164;&#28304;&#65292;&#20197;&#21450;&#65288;b&#65289;&#22312;&#25910;&#38598;&#26032;&#25968;&#25454;&#20043;&#21518;&#65292;&#25345;&#32493;&#30417;&#27979;&#25968;&#25454;&#24182;&#39640;&#25928;&#22320;&#25972;&#21512;&#32479;&#35745;&#35777;&#25454;&#65292;&#21516;&#26102;&#25511;&#21046;&#35823;&#25253;&#29575;&#12290;&#32463;&#20856;&#30340;&#25209;&#37327;&#27979;&#35797;&#19981;&#36866;&#29992;&#20110;&#27969;&#25968;&#25454;&#65306;&#22312;&#25968;&#25454;&#35266;&#23519;&#21518;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#38656;&#35201;&#23545;&#22810;&#37325;&#27979;&#35797;&#36827;&#34892;&#26657;&#27491;&#65292;&#36825;&#23548;&#33268;&#20102;&#20302;&#21151;&#29575;&#12290;&#36981;&#24490;&#36890;&#36807;&#25237;&#27880;&#36827;&#34892;&#27979;&#35797;&#30340;&#21407;&#21017;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#39034;&#24207;&#26680;&#29420;&#31435;&#24615;&#27979;&#35797;&#65292;&#20811;&#26381;&#20102;&#36825;&#20123;&#32570;&#28857;&#12290;&#25105;&#20204;&#36890;&#36807;&#37319;&#29992;&#30001;&#26680;&#30456;&#20851;&#24615;&#27979;&#24230;&#65288;&#22914;Hilbert-&#65289;&#21551;&#21457;&#30340;&#25237;&#27880;&#26469;&#35828;&#26126;&#25105;&#20204;&#30340;&#24191;&#27867;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Independence testing is a classical statistical problem that has been extensively studied in the batch setting when one fixes the sample size before collecting data. However, practitioners often prefer procedures that adapt to the complexity of a problem at hand instead of setting sample size in advance. Ideally, such procedures should (a) stop earlier on easy tasks (and later on harder tasks), hence making better use of available resources, and (b) continuously monitor the data and efficiently incorporate statistical evidence after collecting new data, while controlling the false alarm rate. Classical batch tests are not tailored for streaming data: valid inference after data peeking requires correcting for multiple testing which results in low power. Following the principle of testing by betting, we design sequential kernelized independence tests that overcome such shortcomings. We exemplify our broad framework using bets inspired by kernelized dependence measures, e.g., the Hilbert-
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;VR-IWAE&#19979;&#30028;&#65292;&#35813;&#19979;&#30028;&#26159;IWAE&#19979;&#30028;&#30340;&#25512;&#24191;&#65292;&#37319;&#29992;&#26080;&#20559;&#26799;&#24230;&#20272;&#35745;&#22120;&#33021;&#22815;&#23454;&#29616;&#19982;VR&#19979;&#30028;&#30456;&#21516;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#36807;&#31243;&#65292;&#23545;&#35813;&#19979;&#30028;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#25581;&#31034;&#20102;&#20854;&#20248;&#21183;&#21644;&#19981;&#36275;&#65292;&#24182;&#36890;&#36807;&#31034;&#20363;&#39564;&#35777;&#20102;&#29702;&#35770;&#35266;&#28857;&#12290;</title><link>http://arxiv.org/abs/2210.06226</link><description>&lt;p&gt;
Alpha-divergence&#21464;&#20998;&#25512;&#26029;&#19982;&#37325;&#35201;&#24615;&#21152;&#26435;&#33258;&#32534;&#30721;&#22120;&#30340;&#32467;&#21512;&#65306;&#26041;&#27861;&#21644;&#28176;&#36817;&#24615;
&lt;/p&gt;
&lt;p&gt;
Alpha-divergence Variational Inference Meets Importance Weighted Auto-Encoders: Methodology and Asymptotics. (arXiv:2210.06226v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.06226
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;VR-IWAE&#19979;&#30028;&#65292;&#35813;&#19979;&#30028;&#26159;IWAE&#19979;&#30028;&#30340;&#25512;&#24191;&#65292;&#37319;&#29992;&#26080;&#20559;&#26799;&#24230;&#20272;&#35745;&#22120;&#33021;&#22815;&#23454;&#29616;&#19982;VR&#19979;&#30028;&#30456;&#21516;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#36807;&#31243;&#65292;&#23545;&#35813;&#19979;&#30028;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#25581;&#31034;&#20102;&#20854;&#20248;&#21183;&#21644;&#19981;&#36275;&#65292;&#24182;&#36890;&#36807;&#31034;&#20363;&#39564;&#35777;&#20102;&#29702;&#35770;&#35266;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#30446;&#26631;&#21518;&#39564;&#20998;&#24067;&#21644;&#21464;&#20998;&#20998;&#24067;&#20043;&#38388;&#30340;alpha&#25955;&#24230;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#20960;&#20010;&#28041;&#21450;&#21464;&#20998;R&#233;nyi (VR)&#19979;&#30028;&#30340;&#31639;&#27861;&#12290;&#23613;&#31649;&#26377;&#20196;&#20154;&#28385;&#24847;&#30340;&#23454;&#35777;&#32467;&#26524;&#65292;&#20294;&#36825;&#20123;&#31639;&#27861;&#37117;&#37319;&#29992;&#20102;&#26377;&#20559;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#36807;&#31243;&#65292;&#22240;&#27492;&#32570;&#20047;&#29702;&#35770;&#20445;&#35777;&#12290;&#26412;&#25991;&#23545;VR-IWAE&#19979;&#30028;&#36827;&#34892;&#20102;&#27491;&#24335;&#21270;&#21644;&#30740;&#31350;&#65292;&#35813;&#19979;&#30028;&#26159;&#37325;&#35201;&#24615;&#21152;&#26435;&#33258;&#32534;&#30721;&#22120;(IWAE)&#19979;&#30028;&#30340;&#25512;&#24191;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;VR-IWAE&#19979;&#30028;&#20855;&#26377;&#20960;&#20010;&#21487;&#21462;&#30340;&#29305;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#37325;&#26032;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#19979;&#19982;VR&#19979;&#30028;&#23548;&#33268;&#30456;&#21516;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#36807;&#31243;&#65292;&#20294;&#36825;&#27425;&#26159;&#20381;&#38752;&#26080;&#20559;&#26799;&#24230;&#20272;&#35745;&#22120;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;VR-IWAE&#19979;&#30028;&#20197;&#21450;&#26631;&#20934;IWAE&#19979;&#30028;&#30340;&#20004;&#31181;&#20114;&#34917;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;&#36825;&#20123;&#20998;&#26512;&#25581;&#31034;&#20102;&#36825;&#20123;&#19979;&#30028;&#30340;&#22909;&#22788;&#21644;&#32570;&#28857;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#29609;&#20855;&#21644;&#30495;&#23454;&#25968;&#25454;&#31034;&#20363;&#26469;&#35828;&#26126;&#25105;&#20204;&#30340;&#29702;&#35770;&#35266;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several algorithms involving the Variational R\'enyi (VR) bound have been proposed to minimize an alpha-divergence between a target posterior distribution and a variational distribution. Despite promising empirical results, those algorithms resort to biased stochastic gradient descent procedures and thus lack theoretical guarantees. In this paper, we formalize and study the VR-IWAE bound, a generalization of the Importance Weighted Auto-Encoder (IWAE) bound. We show that the VR-IWAE bound enjoys several desirable properties and notably leads to the same stochastic gradient descent procedure as the VR bound in the reparameterized case, but this time by relying on unbiased gradient estimators. We then provide two complementary theoretical analyses of the VR-IWAE bound and thus of the standard IWAE bound. Those analyses shed light on the benefits or lack thereof of these bounds. Lastly, we illustrate our theoretical claims over toy and real-data examples.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21152;&#26435;&#19981;&#23545;&#31216;&#25439;&#22833;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#29983;&#25104;&#21487;&#38752;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#36866;&#29992;&#20110;&#22797;&#26434;&#30340;&#26426;&#22120;&#23398;&#20064;&#24773;&#22659;&#65292;&#21487;&#25193;&#23637;&#20026;&#21442;&#25968;&#21270;&#20989;&#25968;&#30340;PI&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2210.04318</link><description>&lt;p&gt;
&#20351;&#29992;&#21152;&#26435;&#19981;&#23545;&#31216;&#25439;&#22833;&#20989;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#39044;&#27979;&#21306;&#38388;
&lt;/p&gt;
&lt;p&gt;
Prediction intervals for neural network models using weighted asymmetric loss functions. (arXiv:2210.04318v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.04318
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21152;&#26435;&#19981;&#23545;&#31216;&#25439;&#22833;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#29983;&#25104;&#21487;&#38752;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#36866;&#29992;&#20110;&#22797;&#26434;&#30340;&#26426;&#22120;&#23398;&#20064;&#24773;&#22659;&#65292;&#21487;&#25193;&#23637;&#20026;&#21442;&#25968;&#21270;&#20989;&#25968;&#30340;PI&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#29983;&#25104;&#36817;&#20284;&#21644;&#39044;&#27979;&#36235;&#21183;&#30340;&#39044;&#27979;&#21306;&#38388;&#65288;PIs&#65289;&#12290;&#25105;&#20204;&#21033;&#29992;&#21152;&#26435;&#19981;&#23545;&#31216;&#25439;&#22833;&#20989;&#25968;&#26469;&#20272;&#35745;PI&#30340;&#19979;&#38480;&#21644;&#19978;&#38480;&#65292;&#26435;&#37325;&#30001;&#21306;&#38388;&#23485;&#24230;&#30830;&#23450;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#35813;&#26041;&#27861;&#30340;&#31616;&#27905;&#25968;&#23398;&#35777;&#26126;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#20854;&#25193;&#23637;&#21040;&#20026;&#21442;&#25968;&#21270;&#20989;&#25968;&#25512;&#23548;PI&#65292;&#24182;&#35770;&#35777;&#20102;&#35813;&#26041;&#27861;&#20026;&#39044;&#27979;&#30456;&#20851;&#21464;&#37327;&#30340;PI&#32780;&#26377;&#25928;&#30340;&#21407;&#22240;&#12290;&#25105;&#20204;&#22312;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#27169;&#22411;&#30340;&#30495;&#23454;&#19990;&#30028;&#39044;&#27979;&#20219;&#21153;&#19978;&#23545;&#35813;&#26041;&#27861;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#32467;&#26524;&#34920;&#26126;&#23427;&#22312;&#22797;&#26434;&#30340;&#26426;&#22120;&#23398;&#20064;&#24773;&#22659;&#19979;&#21487;&#20197;&#20135;&#29983;&#21487;&#38752;&#30340;PI&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a simple and efficient approach to generate prediction intervals (PIs) for approximated and forecasted trends. Our method leverages a weighted asymmetric loss function to estimate the lower and upper bounds of the PIs, with the weights determined by the interval width. We provide a concise mathematical proof of the method, show how it can be extended to derive PIs for parametrised functions and argue why the method works for predicting PIs of dependent variables. The presented tests of the method on a real-world forecasting task using a neural network-based model show that it can produce reliable PIs in complex machine learning scenarios.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#22312;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#20013;&#28155;&#21152;&#28151;&#21512;&#25104;&#20998;&#30340;&#22909;&#22788;&#65292;&#24182;&#35777;&#26126;&#20102;&#28151;&#21512;&#25104;&#20998;&#30340;&#22686;&#21152;&#33021;&#22815;&#25552;&#39640;&#20854;&#22312;&#22270;&#20687;&#21644;&#21333;&#32454;&#32990;&#25968;&#25454;&#38598;&#19978;&#30340;&#28508;&#22312;&#34920;&#31034;&#33021;&#21147;&#12290;&#36825;&#34920;&#26126;&#20351;&#29992;&#28151;&#21512;VAE&#26159;&#33719;&#21462;&#26356;&#28789;&#27963;&#21464;&#20998;&#36924;&#36817;&#30340;&#26631;&#20934;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2209.15514</link><description>&lt;p&gt;
&#22312;&#28508;&#22312;&#31354;&#38388;&#20013;&#30340;&#21512;&#20316;&#65306;&#22312;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#20013;&#28155;&#21152;&#28151;&#21512;&#25104;&#20998;&#30340;&#22909;&#22788;
&lt;/p&gt;
&lt;p&gt;
Cooperation in the Latent Space: The Benefits of Adding Mixture Components in Variational Autoencoders. (arXiv:2209.15514v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.15514
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#22312;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#20013;&#28155;&#21152;&#28151;&#21512;&#25104;&#20998;&#30340;&#22909;&#22788;&#65292;&#24182;&#35777;&#26126;&#20102;&#28151;&#21512;&#25104;&#20998;&#30340;&#22686;&#21152;&#33021;&#22815;&#25552;&#39640;&#20854;&#22312;&#22270;&#20687;&#21644;&#21333;&#32454;&#32990;&#25968;&#25454;&#38598;&#19978;&#30340;&#28508;&#22312;&#34920;&#31034;&#33021;&#21147;&#12290;&#36825;&#34920;&#26126;&#20351;&#29992;&#28151;&#21512;VAE&#26159;&#33719;&#21462;&#26356;&#28789;&#27963;&#21464;&#20998;&#36924;&#36817;&#30340;&#26631;&#20934;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#20102;&#28151;&#21512;&#25104;&#20998;&#22312;&#20849;&#21516;&#36866;&#24212;&#26368;&#22823;&#21270;ELBO&#26102;&#30340;&#21512;&#20316;&#26041;&#24335;&#12290;&#25105;&#20204;&#20511;&#37492;&#20102;&#26368;&#36817;&#22312;&#22810;&#20010;&#21644;&#33258;&#36866;&#24212;&#37325;&#35201;&#24615;&#37319;&#26679;&#25991;&#29486;&#20013;&#30340;&#36827;&#23637;&#12290;&#25105;&#20204;&#20351;&#29992;&#21333;&#29420;&#30340;&#32534;&#30721;&#22120;&#32593;&#32476;&#23545;&#28151;&#21512;&#25104;&#20998;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#22312;&#23454;&#35777;&#19978;&#35777;&#26126;ELBO&#38543;&#28151;&#21512;&#25104;&#20998;&#25968;&#37327;&#30340;&#22686;&#21152;&#26159;&#21333;&#35843;&#38750;&#20943;&#30340;&#12290;&#36825;&#20123;&#32467;&#26524;&#36866;&#29992;&#20110;MNIST&#12289;FashionMNIST&#21644;CIFAR-10&#25968;&#25454;&#38598;&#19978;&#30340;&#19981;&#21516;VAE&#26550;&#26500;&#12290;&#26412;&#24037;&#20316;&#36824;&#34920;&#26126;&#22686;&#21152;&#28151;&#21512;&#25104;&#20998;&#30340;&#25968;&#37327;&#33021;&#22815;&#25913;&#21892;VAE&#22312;&#22270;&#20687;&#21644;&#21333;&#32454;&#32990;&#25968;&#25454;&#38598;&#19978;&#30340;&#28508;&#22312;&#34920;&#31034;&#33021;&#21147;&#12290;&#36825;&#31181;&#21512;&#20316;&#34892;&#20026;&#34920;&#26126;&#65292;&#20351;&#29992;&#28151;&#21512;VAE&#24212;&#34987;&#35270;&#20026;&#33719;&#21462;&#26356;&#28789;&#27963;&#30340;&#21464;&#20998;&#36817;&#20284;&#30340;&#26631;&#20934;&#26041;&#27861;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#39318;&#27425;&#22312;&#22823;&#33539;&#22260;&#30340;&#28040;&#34701;&#23454;&#39564;&#20013;&#23558;&#28151;&#21512;VAE&#19982;&#24402;&#19968;&#21270;&#27969;&#12289;&#23618;&#27425;&#27169;&#22411;&#21644;/&#25110;VampPrior&#36827;&#34892;&#20102;&#27604;&#36739;&#21644;&#32467;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we show how the mixture components cooperate when they jointly adapt to maximize the ELBO. We build upon recent advances in the multiple and adaptive importance sampling literature. We then model the mixture components using separate encoder networks and show empirically that the ELBO is monotonically non-decreasing as a function of the number of mixture components. These results hold for a range of different VAE architectures on the MNIST, FashionMNIST, and CIFAR-10 datasets. In this work, we also demonstrate that increasing the number of mixture components improves the latent-representation capabilities of the VAE on both image and single-cell datasets. This cooperative behavior motivates that using Mixture VAEs should be considered a standard approach for obtaining more flexible variational approximations. Finally, Mixture VAEs are here, for the first time, compared and combined with normalizing flows, hierarchical models and/or the VampPrior in an extensive ablation 
&lt;/p&gt;</description></item><item><title>&#19981;&#21516;&#20998;&#24067;&#30340;&#25968;&#25454;&#21487;&#20197;&#23545;&#20219;&#21153;&#30340;&#27867;&#21270;&#35823;&#24046;&#20135;&#29983;&#38750;&#21333;&#35843;&#30340;&#24433;&#21709;&#65292;&#20351;&#29992;&#23569;&#37327;&#19981;&#21516;&#20998;&#24067;&#30340;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#26159;&#26377;&#20215;&#20540;&#30340;&#12290;</title><link>http://arxiv.org/abs/2208.10967</link><description>&lt;p&gt;
&#19981;&#21516;&#20998;&#24067;&#30340;&#25968;&#25454;&#20215;&#20540;
&lt;/p&gt;
&lt;p&gt;
The Value of Out-of-Distribution Data. (arXiv:2208.10967v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.10967
&lt;/p&gt;
&lt;p&gt;
&#19981;&#21516;&#20998;&#24067;&#30340;&#25968;&#25454;&#21487;&#20197;&#23545;&#20219;&#21153;&#30340;&#27867;&#21270;&#35823;&#24046;&#20135;&#29983;&#38750;&#21333;&#35843;&#30340;&#24433;&#21709;&#65292;&#20351;&#29992;&#23569;&#37327;&#19981;&#21516;&#20998;&#24067;&#30340;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#26159;&#26377;&#20215;&#20540;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#26399;&#26395;&#38543;&#30528;&#31867;&#20284;&#20219;&#21153;&#26679;&#26412;&#30340;&#22686;&#21152;&#65292;&#27867;&#21270;&#35823;&#24046;&#20250;&#20943;&#23567;&#65307;&#32780;&#38543;&#30528;&#26469;&#33258;&#19981;&#21516;&#20998;&#24067;&#65288;OOD&#65289;&#20219;&#21153;&#26679;&#26412;&#30340;&#22686;&#21152;&#65292;&#27867;&#21270;&#35823;&#24046;&#20250;&#22686;&#22823;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#21453;&#30452;&#35273;&#30340;&#29616;&#35937;&#65306;&#20219;&#21153;&#30340;&#27867;&#21270;&#35823;&#24046;&#21487;&#20197;&#26159;&#26679;&#26412;&#20174;OOD&#20219;&#21153;&#20013;&#30340;&#25968;&#37327;&#30340;&#38750;&#21333;&#35843;&#20989;&#25968;&#12290;&#38543;&#30528;OOD&#26679;&#26412;&#25968;&#37327;&#30340;&#22686;&#21152;&#65292;&#30446;&#26631;&#20219;&#21153;&#30340;&#27867;&#21270;&#35823;&#24046;&#22312;&#36229;&#36807;&#19968;&#20010;&#38408;&#20540;&#20043;&#21069;&#20250;&#20808;&#20943;&#23567;&#21518;&#22686;&#22823;&#12290;&#25442;&#21477;&#35805;&#35828;&#65292;&#20351;&#29992;&#23569;&#37327;OOD&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#26159;&#26377;&#20215;&#20540;&#30340;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#20351;&#29992;Fisher&#32447;&#24615;&#21028;&#21035;&#21644;&#35745;&#31639;&#26426;&#35270;&#35273;&#22522;&#20934;&#25968;&#25454;&#38598;&#65288;&#22914;MNIST&#12289;CIFAR-10&#12289;CINIC-10&#12289;PACS&#21644;DomainNet&#65289;&#19978;&#30340;&#28145;&#24230;&#32593;&#32476;&#26469;&#23637;&#31034;&#21644;&#20998;&#26512;&#36825;&#19968;&#29616;&#35937;&#12290;&#22312;&#25105;&#20204;&#30693;&#36947;&#21738;&#20123;&#26679;&#26412;&#23646;&#20110;OOD&#30340;&#29702;&#24819;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#21033;&#29992;&#30446;&#26631;&#21644;OOD&#32463;&#39564;&#39118;&#38505;&#30340;&#36866;&#24403;&#21152;&#26435;&#30446;&#26631;&#26469;&#21033;&#29992;&#36825;&#20123;&#38750;&#21333;&#35843;&#36235;&#21183;&#12290;&#23613;&#31649;&#23454;&#38469;&#24212;&#29992;&#26377;&#38480;&#65292;&#20294;&#36825;&#34920;&#26126;&#22914;&#26524;&#25105;&#20204;&#33021;&#22815;&#26816;&#27979;&#21040;OOD&#26679;&#26412;&#65292;&#36825;&#31181;&#26041;&#27861;&#21487;&#33021;&#26159;&#26377;&#20215;&#20540;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We expect the generalization error to improve with more samples from a similar task, and to deteriorate with more samples from an out-of-distribution (OOD) task. In this work, we show a counter-intuitive phenomenon: the generalization error of a task can be a non-monotonic function of the number of OOD samples. As the number of OOD samples increases, the generalization error on the target task improves before deteriorating beyond a threshold. In other words, there is value in training on small amounts of OOD data. We use Fisher's Linear Discriminant on synthetic datasets and deep networks on computer vision benchmarks such as MNIST, CIFAR-10, CINIC-10, PACS and DomainNet to demonstrate and analyze this phenomenon. In the idealistic setting where we know which samples are OOD, we show that these non-monotonic trends can be exploited using an appropriately weighted objective of the target and OOD empirical risk. While its practical utility is limited, this does suggest that if we can det
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22788;&#29702;&#26102;&#38388;&#30456;&#20851;&#30340;&#27969;&#24335;&#25968;&#25454;&#30340;&#22312;&#32447;&#38543;&#26426;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#38750;&#28176;&#36827;&#20998;&#26512;&#24314;&#31435;&#20102;&#26032;&#39062;&#30340;&#21551;&#21457;&#24335;&#31639;&#27861;&#65292;&#21152;&#36895;&#25910;&#25947;&#12290;&#23454;&#39564;&#35777;&#26126;&#26102;&#38388;&#21464;&#21270;&#30340;&#23567;&#25209;&#37327;SGD&#26041;&#27861;&#21487;&#20197;&#25171;&#30772;&#20381;&#36182;&#32467;&#26500;&#65292;&#26377;&#20559;&#20506;&#30340;SGD&#26041;&#27861;&#20855;&#26377;&#19982;&#26080;&#20559;&#20506;&#26041;&#27861;&#30456;&#24403;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#20351;&#29992;Polyak-Ruppert&#24179;&#22343;&#21270;&#26041;&#27861;&#33021;&#22815;&#21152;&#24555;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2205.12549</link><description>&lt;p&gt;
&#23398;&#20064;&#22788;&#29702;&#26102;&#38388;&#30456;&#20851;&#30340;&#27969;&#24335;&#25968;&#25454;&#30340;&#22312;&#32447;&#38543;&#26426;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Learning from time-dependent streaming data with online stochastic algorithms. (arXiv:2205.12549v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.12549
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22788;&#29702;&#26102;&#38388;&#30456;&#20851;&#30340;&#27969;&#24335;&#25968;&#25454;&#30340;&#22312;&#32447;&#38543;&#26426;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#38750;&#28176;&#36827;&#20998;&#26512;&#24314;&#31435;&#20102;&#26032;&#39062;&#30340;&#21551;&#21457;&#24335;&#31639;&#27861;&#65292;&#21152;&#36895;&#25910;&#25947;&#12290;&#23454;&#39564;&#35777;&#26126;&#26102;&#38388;&#21464;&#21270;&#30340;&#23567;&#25209;&#37327;SGD&#26041;&#27861;&#21487;&#20197;&#25171;&#30772;&#20381;&#36182;&#32467;&#26500;&#65292;&#26377;&#20559;&#20506;&#30340;SGD&#26041;&#27861;&#20855;&#26377;&#19982;&#26080;&#20559;&#20506;&#26041;&#27861;&#30456;&#24403;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#20351;&#29992;Polyak-Ruppert&#24179;&#22343;&#21270;&#26041;&#27861;&#33021;&#22815;&#21152;&#24555;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#26102;&#38388;&#30456;&#20851;&#19988;&#26377;&#20559;&#20506;&#26799;&#24230;&#20272;&#35745;&#19979;&#30340;&#27969;&#24335;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#19968;&#20123;&#19968;&#38454;&#26041;&#27861;&#65292;&#21253;&#25324;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#12289;&#23567;&#25209;&#37327;SGD&#21644;&#26102;&#38388;&#21464;&#21270;&#30340;&#23567;&#25209;&#37327;SGD&#65292;&#20197;&#21450;&#23427;&#20204;&#30340;Polyak-Ruppert&#24179;&#22343;&#20540;&#12290;&#25105;&#20204;&#30340;&#38750;&#28176;&#36827;&#20998;&#26512;&#24314;&#31435;&#20102;&#26032;&#39062;&#30340;&#21551;&#21457;&#24335;&#31639;&#27861;&#65292;&#23558;&#20381;&#36182;&#24615;&#12289;&#20559;&#20506;&#21644;&#20984;&#24615;&#27700;&#24179;&#32852;&#31995;&#36215;&#26469;&#65292;&#23454;&#29616;&#20102;&#21152;&#36895;&#25910;&#25947;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65306;&#65288;i&#65289;&#26102;&#38388;&#21464;&#21270;&#30340;&#23567;&#25209;&#37327;SGD&#26041;&#27861;&#33021;&#22815;&#25171;&#30772;&#38271;&#26399;&#21644;&#30701;&#26399;&#30340;&#20381;&#36182;&#32467;&#26500;&#65307;&#65288;ii&#65289;&#26377;&#20559;&#20506;&#30340;SGD&#26041;&#27861;&#21487;&#20197;&#36798;&#21040;&#19982;&#26080;&#20559;&#20506;&#26041;&#27861;&#30456;&#24403;&#30340;&#24615;&#33021;&#65307;&#65288;iii&#65289;&#20351;&#29992;Polyak-Ruppert&#24179;&#22343;&#21270;&#26041;&#27861;&#21487;&#20197;&#21152;&#36895;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#12290;&#20026;&#20102;&#39564;&#35777;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#65292;&#25105;&#20204;&#22312;&#27169;&#25311;&#21644;&#29616;&#23454;&#30340;&#26102;&#38388;&#30456;&#20851;&#25968;&#25454;&#19978;&#36827;&#34892;&#20102;&#19968;&#31995;&#21015;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper addresses stochastic optimization in a streaming setting with time-dependent and biased gradient estimates. We analyze several first-order methods, including Stochastic Gradient Descent (SGD), mini-batch SGD, and time-varying mini-batch SGD, along with their Polyak-Ruppert averages. Our non-asymptotic analysis establishes novel heuristics that link dependence, biases, and convexity levels, enabling accelerated convergence. Specifically, our findings demonstrate that (i) time-varying mini-batch SGD methods have the capability to break long- and short-range dependence structures, (ii) biased SGD methods can achieve comparable performance to their unbiased counterparts, and (iii) incorporating Polyak-Ruppert averaging can accelerate the convergence of the stochastic optimization algorithms. To validate our theoretical findings, we conduct a series of experiments using both simulated and real-life time-dependent data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#37096;&#20998;&#35266;&#23519;&#30340;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;POMDPs&#65289;&#19979;&#33258;&#28982;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26041;&#27861;&#30340;&#26377;&#38480;&#26102;&#38388;&#29305;&#24615;&#65292;&#24182;&#23545;&#20351;&#29992;&#26377;&#38480;&#29366;&#24577;&#25511;&#21046;&#22120;&#20135;&#29983;&#30340;&#38169;&#35823;&#36827;&#34892;&#20102;&#26126;&#30830;&#30340;&#34920;&#24449;&#12290;</title><link>http://arxiv.org/abs/2202.09753</link><description>&lt;p&gt;
&#37096;&#20998;&#35266;&#23519;&#30340;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;POMDPs&#65289;&#30340;&#33258;&#28982;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26041;&#27861;&#30340;&#26377;&#38480;&#26102;&#38388;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Finite-Time Analysis of Natural Actor-Critic for POMDPs. (arXiv:2202.09753v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.09753
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#37096;&#20998;&#35266;&#23519;&#30340;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;POMDPs&#65289;&#19979;&#33258;&#28982;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26041;&#27861;&#30340;&#26377;&#38480;&#26102;&#38388;&#29305;&#24615;&#65292;&#24182;&#23545;&#20351;&#29992;&#26377;&#38480;&#29366;&#24577;&#25511;&#21046;&#22120;&#20135;&#29983;&#30340;&#38169;&#35823;&#36827;&#34892;&#20102;&#26126;&#30830;&#30340;&#34920;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#26377;&#38480;&#25110;&#21487;&#25968;&#26080;&#38480;&#29366;&#24577;&#31354;&#38388;&#30340;&#37096;&#20998;&#35266;&#23519;&#30340;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;POMDPs&#65289;&#30340;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#20854;&#20013;&#25511;&#21046;&#22120;&#21482;&#33021;&#35775;&#38382;&#22522;&#30784;&#25511;&#21046;&#39532;&#23572;&#31185;&#22827;&#38142;&#30340;&#22122;&#22768;&#35266;&#27979;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31181;&#33258;&#28982;&#30340;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#37319;&#29992;&#26377;&#38480;&#30340;&#20869;&#37096;&#23384;&#20648;&#22120;&#36827;&#34892;&#31574;&#30053;&#21442;&#25968;&#21270;&#65292;&#24182;&#20351;&#29992;&#22810;&#27493;&#26102;&#24207;&#24046;&#24322;&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#31574;&#30053;&#35780;&#20272;&#12290;&#20973;&#20511;&#25105;&#20204;&#30340;&#30693;&#35782;&#65292;&#25105;&#20204;&#39318;&#27425;&#30830;&#31435;&#20102;&#37096;&#20998;&#35266;&#23519;&#31995;&#32479;&#19979;&#22522;&#20110;&#20989;&#25968;&#36924;&#36817;&#30340;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26041;&#27861;&#30340;&#38750;&#28176;&#36817;&#20840;&#23616;&#25910;&#25947;&#24615;&#12290;&#29305;&#21035;&#22320;&#65292;&#38500;&#20102;&#22312;MDPs&#20013;&#20986;&#29616;&#30340;&#20989;&#25968;&#36924;&#36817;&#21644;&#32479;&#35745;&#35823;&#24046;&#20043;&#22806;&#65292;&#25105;&#20204;&#36824;&#26126;&#30830;&#22320;&#34920;&#24449;&#20102;&#30001;&#20110;&#20351;&#29992;&#26377;&#38480;&#29366;&#24577;&#25511;&#21046;&#22120;&#32780;&#20135;&#29983;&#30340;&#38169;&#35823;&#12290;&#36825;&#31181;&#39069;&#22806;&#30340;&#38169;&#35823;&#26159;&#20197;&#20256;&#32479;&#30340;POMDPs&#20013;&#30340;&#20449;&#24515;&#29366;&#24577;&#21644;&#20351;&#29992;&#26377;&#38480;&#29366;&#24577;&#26102;&#30340;&#38544;&#34255;&#29366;&#24577;&#30340;&#21518;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#24635;&#21464;&#24046;&#36317;&#31163;&#26469;&#34920;&#31034;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the reinforcement learning problem for partially observed Markov decision processes (POMDPs) with large or even countably infinite state spaces, where the controller has access to only noisy observations of the underlying controlled Markov chain. We consider a natural actor-critic method that employs a finite internal memory for policy parameterization, and a multi-step temporal difference learning algorithm for policy evaluation. We establish, to the best of our knowledge, the first non-asymptotic global convergence of actor-critic methods for partially observed systems under function approximation. In particular, in addition to the function approximation and statistical errors that also arise in MDPs, we explicitly characterize the error due to the use of finite-state controllers. This additional error is stated in terms of the total variation distance between the traditional belief state in POMDPs and the posterior distribution of the hidden state when using a finite-sta
&lt;/p&gt;</description></item><item><title>Weisfeiler-Leman&#31639;&#27861;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#22788;&#29702;&#22270;&#21644;&#20851;&#31995;&#25968;&#25454;&#12290;&#26412;&#25991;&#20840;&#38754;&#20171;&#32461;&#20102;&#35813;&#31639;&#27861;&#22312;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#21253;&#25324;&#29702;&#35770;&#32972;&#26223;&#12289;&#25193;&#23637;&#12289;&#19982;&#31561;&#21464;&#31070;&#32463;&#32593;&#26684;&#30340;&#32852;&#31995;&#12289;&#24182;&#21015;&#20986;&#20102;&#24403;&#21069;&#24212;&#29992;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2112.09992</link><description>&lt;p&gt;
Weisfeiler&#21644;Leman&#26469;&#20570;&#26426;&#22120;&#23398;&#20064;&#20102;&#65306;&#30446;&#21069;&#30340;&#30740;&#31350;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Weisfeiler and Leman go Machine Learning: The Story so far. (arXiv:2112.09992v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.09992
&lt;/p&gt;
&lt;p&gt;
Weisfeiler-Leman&#31639;&#27861;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#22788;&#29702;&#22270;&#21644;&#20851;&#31995;&#25968;&#25454;&#12290;&#26412;&#25991;&#20840;&#38754;&#20171;&#32461;&#20102;&#35813;&#31639;&#27861;&#22312;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#21253;&#25324;&#29702;&#35770;&#32972;&#26223;&#12289;&#25193;&#23637;&#12289;&#19982;&#31561;&#21464;&#31070;&#32463;&#32593;&#26684;&#30340;&#32852;&#31995;&#12289;&#24182;&#21015;&#20986;&#20102;&#24403;&#21069;&#24212;&#29992;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22522;&#20110;Weisfeiler-Leman&#31639;&#27861;&#30340;&#31639;&#27861;&#21644;&#31070;&#32463;&#26550;&#26500;&#24050;&#25104;&#20026;&#22788;&#29702;&#22270;&#21644;&#20851;&#31995;&#25968;&#25454;&#30340;&#26426;&#22120;&#23398;&#20064;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#26412;&#25991;&#20840;&#38754;&#20171;&#32461;&#31639;&#27861;&#22312;&#26426;&#22120;&#23398;&#20064;&#29615;&#22659;&#20013;&#30340;&#20351;&#29992;&#24773;&#20917;&#65292;&#37325;&#28857;&#20851;&#27880;&#30417;&#30563;&#23398;&#20064;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#29702;&#35770;&#32972;&#26223;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#20854;&#29992;&#20110;&#30417;&#30563;&#22270;&#24418;&#21644;&#33410;&#28857;&#34920;&#31034;&#23398;&#20064;&#65292;&#35752;&#35770;&#20102;&#26368;&#36817;&#30340;&#25193;&#23637;&#65292;&#24182;&#27010;&#36848;&#20102;&#31639;&#27861;&#19982;&#65288;&#32622;&#25442;&#65289;&#31561;&#21464;&#31070;&#32463;&#32593;&#26684;&#30340;&#32852;&#31995;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#27010;&#36848;&#20102;&#24403;&#21069;&#30340;&#24212;&#29992;&#21644;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#20197;&#21050;&#28608;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, algorithms and neural architectures based on the Weisfeiler-Leman algorithm, a well-known heuristic for the graph isomorphism problem, have emerged as a powerful tool for machine learning with graphs and relational data. Here, we give a comprehensive overview of the algorithm's use in a machine-learning setting, focusing on the supervised regime. We discuss the theoretical background, show how to use it for supervised graph and node representation learning, discuss recent extensions, and outline the algorithm's connection to (permutation-)equivariant neural architectures. Moreover, we give an overview of current applications and future directions to stimulate further research.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MixPath&#30340;&#32479;&#19968;&#30340;&#19968;&#27425;&#24615;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#19968;&#27425;&#24615;&#30340;&#22810;&#36335;&#24452;&#36229;&#32593;&#32476;&#26469;&#20934;&#30830;&#35780;&#20272;&#20505;&#36873;&#26550;&#26500;&#12290;&#37319;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#26426;&#21046;&#31216;&#20026;Shadow Batch Normalization&#65288;SBN&#65289;&#26469;&#35299;&#20915;&#22810;&#36335;&#24452;&#32467;&#26500;&#30340;&#29305;&#24449;&#24046;&#24322;&#38382;&#39064;&#65292;&#31283;&#23450;&#20248;&#21270;&#24182;&#25552;&#39640;&#25490;&#21517;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2001.05887</link><description>&lt;p&gt;
MixPath: &#19968;&#31181;&#32479;&#19968;&#30340;&#19968;&#27425;&#24615;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
MixPath: A Unified Approach for One-shot Neural Architecture Search. (arXiv:2001.05887v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2001.05887
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MixPath&#30340;&#32479;&#19968;&#30340;&#19968;&#27425;&#24615;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#19968;&#27425;&#24615;&#30340;&#22810;&#36335;&#24452;&#36229;&#32593;&#32476;&#26469;&#20934;&#30830;&#35780;&#20272;&#20505;&#36873;&#26550;&#26500;&#12290;&#37319;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#26426;&#21046;&#31216;&#20026;Shadow Batch Normalization&#65288;SBN&#65289;&#26469;&#35299;&#20915;&#22810;&#36335;&#24452;&#32467;&#26500;&#30340;&#29305;&#24449;&#24046;&#24322;&#38382;&#39064;&#65292;&#31283;&#23450;&#20248;&#21270;&#24182;&#25552;&#39640;&#25490;&#21517;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31070;&#32463;&#26550;&#26500;&#35774;&#35745;&#20013;&#65292;&#28151;&#21512;&#22810;&#20010;&#21367;&#31215;&#26680;&#34987;&#35777;&#26126;&#26159;&#26377;&#20248;&#21183;&#30340;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#20004;&#38454;&#27573;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#26041;&#27861;&#20027;&#35201;&#23616;&#38480;&#20110;&#21333;&#36335;&#24452;&#25628;&#32034;&#31354;&#38388;&#12290;&#22914;&#20309;&#39640;&#25928;&#22320;&#25628;&#32034;&#22810;&#36335;&#24452;&#32467;&#26500;&#30340;&#27169;&#22411;&#20173;&#28982;&#26159;&#19968;&#20010;&#38590;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30340;&#21160;&#26426;&#26159;&#35757;&#32451;&#19968;&#20010;&#19968;&#27425;&#24615;&#30340;&#22810;&#36335;&#24452;&#36229;&#32593;&#32476;&#26469;&#20934;&#30830;&#35780;&#20272;&#20505;&#36873;&#26550;&#26500;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#25152;&#30740;&#31350;&#30340;&#25628;&#32034;&#31354;&#38388;&#20013;&#65292;&#20174;&#22810;&#20010;&#36335;&#24452;&#20013;&#27714;&#21644;&#30340;&#29305;&#24449;&#21521;&#37327;&#20960;&#20046;&#26159;&#21333;&#20010;&#36335;&#24452;&#30340;&#20493;&#25968;&#12290;&#36825;&#31181;&#24046;&#24322;&#25200;&#20081;&#20102;&#36229;&#32593;&#32476;&#30340;&#35757;&#32451;&#21644;&#25490;&#21517;&#33021;&#21147;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26426;&#21046;&#65292;&#31216;&#20026;Shadow Batch Normalization&#65288;SBN&#65289;&#65292;&#26469;&#35268;&#33539;&#24046;&#24322;&#30340;&#29305;&#24449;&#32479;&#35745;&#12290;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#65292;SBN&#33021;&#22815;&#31283;&#23450;&#20248;&#21270;&#21644;&#25552;&#39640;&#25490;&#21517;&#24615;&#33021;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#32479;&#19968;&#22810;&#36335;&#24452;&#19968;&#27425;&#24615;&#26041;&#27861;&#31216;&#20026;MixPath&#65292;&#21487;&#20197;&#29983;&#25104;&#19968;&#31995;&#21015;&#33021;&#36798;&#21040;&#26368;&#26032;&#25216;&#26415;&#27700;&#24179;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Blending multiple convolutional kernels is proved advantageous in neural architecture design. However, current two-stage neural architecture search methods are mainly limited to single-path search spaces. How to efficiently search models of multi-path structures remains a difficult problem. In this paper, we are motivated to train a one-shot multi-path supernet to accurately evaluate the candidate architectures. Specifically, we discover that in the studied search spaces, feature vectors summed from multiple paths are nearly multiples of those from a single path. Such disparity perturbs the supernet training and its ranking ability. Therefore, we propose a novel mechanism called Shadow Batch Normalization (SBN) to regularize the disparate feature statistics. Extensive experiments prove that SBNs are capable of stabilizing the optimization and improving ranking performance. We call our unified multi-path one-shot approach as MixPath, which generates a series of models that achieve state
&lt;/p&gt;</description></item></channel></rss>