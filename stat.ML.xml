<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>ASNR-MICCAI&#33041;&#32959;&#30244;&#20998;&#21106;&#25361;&#25112;2023&#23558;&#25552;&#20379;&#19968;&#20010;&#36866;&#29992;&#20110;&#33258;&#21160;&#35786;&#26029;&#39045;&#20869;&#33041;&#33180;&#30244;&#30340;&#26368;&#20808;&#36827;&#33258;&#21160;&#21270;&#39045;&#20869;&#33041;&#33180;&#30244;&#20998;&#21106;&#27169;&#22411;&#30340;&#22522;&#20934;&#12290;</title><link>http://arxiv.org/abs/2305.07642</link><description>&lt;p&gt;
ASNR-MICCAI&#33041;&#32959;&#30244;&#20998;&#21106;&#25361;&#25112;2023&#65306;&#39045;&#20869;&#33041;&#33180;&#30244;
&lt;/p&gt;
&lt;p&gt;
The ASNR-MICCAI Brain Tumor Segmentation (BraTS) Challenge 2023: Intracranial Meningioma. (arXiv:2305.07642v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07642
&lt;/p&gt;
&lt;p&gt;
ASNR-MICCAI&#33041;&#32959;&#30244;&#20998;&#21106;&#25361;&#25112;2023&#23558;&#25552;&#20379;&#19968;&#20010;&#36866;&#29992;&#20110;&#33258;&#21160;&#35786;&#26029;&#39045;&#20869;&#33041;&#33180;&#30244;&#30340;&#26368;&#20808;&#36827;&#33258;&#21160;&#21270;&#39045;&#20869;&#33041;&#33180;&#30244;&#20998;&#21106;&#27169;&#22411;&#30340;&#22522;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33041;&#33180;&#30244;&#26159;&#25104;&#20154;&#39045;&#20869;&#26368;&#24120;&#35265;&#30340;&#21407;&#21457;&#24615;&#32959;&#30244;&#65292;&#21487;&#33021;&#19982;&#37325;&#22823;&#30340;&#21457;&#30149;&#29575;&#21644;&#27515;&#20129;&#29575;&#26377;&#20851;&#12290;&#25918;&#23556;&#31185;&#21307;&#29983;&#12289;&#31070;&#32463;&#22806;&#31185;&#21307;&#29983;&#12289;&#31070;&#32463;&#32959;&#30244;&#23398;&#23478;&#21644;&#25918;&#23556;&#32959;&#30244;&#31185;&#21307;&#29983;&#20381;&#38752;&#22810;&#21442;&#25968;MRI&#65288;mpMRI&#65289;&#36827;&#34892;&#35786;&#26029;&#12289;&#27835;&#30103;&#35268;&#21010;&#21644;&#38271;&#26399;&#27835;&#30103;&#30417;&#27979;&#65307;&#28982;&#32780;&#65292;&#32570;&#20047;&#33258;&#21160;&#21270;&#12289;&#23458;&#35266;&#21270;&#21644;&#23450;&#37327;&#21270;&#30340;&#24037;&#20855;&#26469;&#23545;mpMRI&#20013;&#30340;&#33041;&#33180;&#30244;&#36827;&#34892;&#38750;&#20405;&#20837;&#24615;&#35780;&#20272;&#12290;BraTS&#33041;&#33180;&#30244;2023&#25361;&#25112;&#23558;&#25552;&#20379;&#19968;&#20010;&#31038;&#21306;&#26631;&#20934;&#21644;&#22522;&#20110;&#36804;&#20170;&#20026;&#27490;&#26368;&#22823;&#30340;&#19987;&#23478;&#27880;&#37322;&#30340;&#22810;&#26631;&#31614;&#33041;&#33180;&#30244;mpMRI&#25968;&#25454;&#38598;&#30340;&#26368;&#20808;&#36827;&#33258;&#21160;&#21270;&#39045;&#20869;&#33041;&#33180;&#30244;&#20998;&#21106;&#27169;&#22411;&#30340;&#22522;&#20934;&#12290;&#25361;&#25112;&#21442;&#36187;&#32773;&#23558;&#24320;&#21457;&#33258;&#21160;&#21270;&#20998;&#21106;&#27169;&#22411;&#65292;&#39044;&#27979;MRI&#19978;&#30340;&#19977;&#20010;&#19981;&#21516;&#30340;&#33041;&#33180;&#30244;&#20122;&#21306;&#22495;&#65292;&#21253;&#25324;&#22686;&#24378;&#32959;&#30244;&#12289;&#38750;&#22686;&#24378;&#32959;&#30244;&#26680;&#24515;&#21644;&#21608;&#22260;&#26080;&#22686;&#24378;T2/FLAIR&#39640;&#20449;&#21495;&#21306;&#12290;&#27169;&#22411;&#23558;&#20351;&#29992;&#26631;&#20934;&#21270;&#25351;&#26631;&#22312;&#21333;&#29420;&#30340;&#39564;&#35777;&#21644;&#20445;&#30041;&#27979;&#35797;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Meningiomas are the most common primary intracranial tumor in adults and can be associated with significant morbidity and mortality. Radiologists, neurosurgeons, neuro-oncologists, and radiation oncologists rely on multiparametric MRI (mpMRI) for diagnosis, treatment planning, and longitudinal treatment monitoring; yet automated, objective, and quantitative tools for non-invasive assessment of meningiomas on mpMRI are lacking. The BraTS meningioma 2023 challenge will provide a community standard and benchmark for state-of-the-art automated intracranial meningioma segmentation models based on the largest expert annotated multilabel meningioma mpMRI dataset to date. Challenge competitors will develop automated segmentation models to predict three distinct meningioma sub-regions on MRI including enhancing tumor, non-enhancing tumor core, and surrounding nonenhancing T2/FLAIR hyperintensity. Models will be evaluated on separate validation and held-out test datasets using standardized metri
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20302;&#31209;&#35889;&#26368;&#20248;&#21270;&#38382;&#39064;&#30340;&#37096;&#20998;&#20984;&#21270;&#30340;&#23454;&#21147;&#65292;&#25552;&#20986;&#20102;&#27966;&#29983;&#20219;&#20309;&#26497;&#31471;&#28857;&#30340;&#31209;&#30028;&#65292;&#24182;&#35777;&#26126;&#20102;&#23545;&#20110;&#19981;&#21516;&#30697;&#38453;&#31354;&#38388;&#30340;&#22495;&#38598;&#21512;&#30340;&#32039;&#33268;&#24615;&#65292;&#21516;&#26102;&#24320;&#21457;&#20102;&#19968;&#20010;&#21253;&#21547;&#30690;&#37327;&#20984;&#23450;&#20215;&#31070;&#35861;&#30340;&#21015;&#29983;&#25104;&#31639;&#27861;&#20197;&#26377;&#25928;&#35299;&#20915;&#27492;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.07638</link><description>&lt;p&gt;
&#20851;&#20110;&#20302;&#31209;&#35889;&#26368;&#20248;&#21270;&#30340;&#37096;&#20998;&#20984;&#21270;&#65306;&#31209;&#30028;&#19982;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
On the Partial Convexification for Low-Rank Spectral Optimization: Rank Bounds and Algorithms. (arXiv:2305.07638v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07638
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20302;&#31209;&#35889;&#26368;&#20248;&#21270;&#38382;&#39064;&#30340;&#37096;&#20998;&#20984;&#21270;&#30340;&#23454;&#21147;&#65292;&#25552;&#20986;&#20102;&#27966;&#29983;&#20219;&#20309;&#26497;&#31471;&#28857;&#30340;&#31209;&#30028;&#65292;&#24182;&#35777;&#26126;&#20102;&#23545;&#20110;&#19981;&#21516;&#30697;&#38453;&#31354;&#38388;&#30340;&#22495;&#38598;&#21512;&#30340;&#32039;&#33268;&#24615;&#65292;&#21516;&#26102;&#24320;&#21457;&#20102;&#19968;&#20010;&#21253;&#21547;&#30690;&#37327;&#20984;&#23450;&#20215;&#31070;&#35861;&#30340;&#21015;&#29983;&#25104;&#31639;&#27861;&#20197;&#26377;&#25928;&#35299;&#20915;&#27492;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#31209;&#35889;&#26368;&#20248;&#21270;&#38382;&#39064;&#65288;LSOP&#65289;&#30340;&#30446;&#26631;&#26159;&#22312;&#20302;&#31209;&#21644;&#35889;&#32422;&#26463;&#30340;&#21487;&#34892;&#22495;&#20869;&#65292;&#26368;&#23567;&#21270;&#19968;&#20010;&#32447;&#24615;&#30446;&#26631;&#65292;&#28385;&#36275;&#22810;&#20010;&#21452;&#38754;&#32447;&#24615;&#30697;&#38453;&#19981;&#31561;&#24335;&#30340;&#20132;&#38598;&#12290;&#34429;&#28982;&#35299;&#20915;LSOP&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#26159;NP&#38590;&#30340;&#65292;&#20294;&#23427;&#30340;&#37096;&#20998;&#20984;&#21270;&#65288;&#21363;&#29992;&#20984;&#22771;&#20195;&#26367;&#22495;&#38598;&#21512;&#65289;&#65292;&#31216;&#20026;&#8220;LSOP-R&#8221;&#65292;&#36890;&#24120;&#26159;&#21487;&#22788;&#29702;&#30340;&#24182;&#20135;&#29983;&#39640;&#36136;&#37327;&#30340;&#35299;&#12290;&#36825;&#28608;&#21169;&#25105;&#20204;&#30740;&#31350;LSOP-R&#30340;&#23454;&#21147;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20026;LSOP-R&#21487;&#34892;&#38598;&#30340;&#20219;&#20309;&#26497;&#31471;&#28857;&#27966;&#29983;&#31209;&#30028;&#65292;&#24182;&#35777;&#26126;&#23545;&#20110;&#19981;&#21516;&#30697;&#38453;&#31354;&#38388;&#30340;&#22495;&#38598;&#21512;&#65292;&#23427;&#20204;&#30340;&#32039;&#33268;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#31209;&#30028;&#20174;&#26032;&#30340;&#35282;&#24230;&#24674;&#22797;&#20102;&#25991;&#29486;&#20013;&#30340;&#20004;&#20010;&#20247;&#25152;&#21608;&#30693;&#30340;&#32467;&#26524;&#65292;&#24182;&#20801;&#35768;&#25105;&#20204;&#23548;&#20986;&#24403;&#26494;&#24347;LSOP-R&#31561;&#20215;&#20110;&#21407;&#22987;LSOP&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#20026;&#20102;&#26377;&#25928;&#22320;&#35299;&#20915;LSOP-R&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#21253;&#21547;&#30690;&#37327;&#20984;&#23450;&#20215;&#31070;&#35861;&#30340;&#21015;&#29983;&#25104;&#31639;&#27861;&#65292;&#37197;&#21512;&#19968;&#20010;&#31209;&#38477;&#31639;&#27861;&#65292;&#23427;&#30830;&#20445;&#36755;&#20986;&#19968;&#20010;LSOP-R&#30340;&#20934;&#30830;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Low-rank Spectral Optimization Problem (LSOP) minimizes a linear objective subject to multiple two-sided linear matrix inequalities intersected with a low-rank and spectral constrained domain set. Although solving LSOP is, in general, NP-hard, its partial convexification (i.e., replacing the domain set by its convex hull) termed "LSOP-R," is often tractable and yields a high-quality solution. This motivates us to study the strength of LSOP-R. Specifically, we derive rank bounds for any extreme point of the feasible set of LSOP-R and prove their tightness for the domain sets with different matrix spaces. The proposed rank bounds recover two well-known results in the literature from a fresh angle and also allow us to derive sufficient conditions under which the relaxation LSOP-R is equivalent to the original LSOP. To effectively solve LSOP-R, we develop a column generation algorithm with a vector-based convex pricing oracle, coupled with a rank-reduction algorithm, which ensures the ou
&lt;/p&gt;</description></item><item><title>Meta Omnium&#25552;&#20379;&#20102;&#19968;&#20010;&#25968;&#25454;&#38598;&#65292;&#21253;&#21547;&#22810;&#20010;&#35270;&#35273;&#20219;&#21153;&#65292;&#20351;&#24471;&#23398;&#26415;&#30028;&#21487;&#20197;&#35780;&#20272;&#27169;&#22411;&#23545;&#20110;&#22810;&#39033;&#20219;&#21153;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#23427;&#21516;&#26102;&#25552;&#20379;&#20102;&#19968;&#20010;&#19968;&#33268;&#30340;&#26694;&#26550;&#65292;&#26469;&#35780;&#20272;&#20803;&#23398;&#20064;&#32773;&#12290;</title><link>http://arxiv.org/abs/2305.07625</link><description>&lt;p&gt;
Meta Omnium: &#19968;&#39033;&#36890;&#29992;&#23398;&#20064;-&#23398;&#20064;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Meta Omnium: A Benchmark for General-Purpose Learning-to-Learn. (arXiv:2305.07625v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07625
&lt;/p&gt;
&lt;p&gt;
Meta Omnium&#25552;&#20379;&#20102;&#19968;&#20010;&#25968;&#25454;&#38598;&#65292;&#21253;&#21547;&#22810;&#20010;&#35270;&#35273;&#20219;&#21153;&#65292;&#20351;&#24471;&#23398;&#26415;&#30028;&#21487;&#20197;&#35780;&#20272;&#27169;&#22411;&#23545;&#20110;&#22810;&#39033;&#20219;&#21153;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#23427;&#21516;&#26102;&#25552;&#20379;&#20102;&#19968;&#20010;&#19968;&#33268;&#30340;&#26694;&#26550;&#65292;&#26469;&#35780;&#20272;&#20803;&#23398;&#20064;&#32773;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20803;&#23398;&#20064;&#20197;&#21450;&#20854;&#20182;&#23569;&#26679;&#26412;&#23398;&#20064;&#26041;&#27861;&#24050;&#24191;&#27867;&#24212;&#29992;&#20110;&#22270;&#20687;&#35782;&#21035;&#65292;&#21516;&#26102;&#20063;&#36234;&#26469;&#36234;&#24212;&#29992;&#20110;&#20854;&#20182;&#35270;&#35273;&#20219;&#21153;&#65292;&#22914;&#23039;&#24577;&#20272;&#35745;&#21644;&#23494;&#38598;&#39044;&#27979;&#12290;&#36825;&#33258;&#28982;&#24341;&#20986;&#20102;&#19968;&#20010;&#38382;&#39064;&#65306;&#26159;&#21542;&#23384;&#22312;&#19968;&#31181;&#23569;&#26679;&#26412;&#20803;&#23398;&#20064;&#31639;&#27861;&#65292;&#33021;&#22815;&#27867;&#21270;&#21040;&#36825;&#20123;&#22810;&#26679;&#21270;&#30340;&#20219;&#21153;&#31867;&#22411;&#20043;&#38388;&#65311;&#20026;&#20102;&#24110;&#21161;&#23398;&#26415;&#30028;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;Meta Omnium&#36825;&#20010;&#25968;&#25454;&#38598;&#65292;&#23427;&#28085;&#30422;&#20102;&#22810;&#20010;&#35270;&#35273;&#20219;&#21153;&#65292;&#21253;&#25324;&#35782;&#21035;&#12289;&#20851;&#38190;&#28857;&#23450;&#20301;&#12289;&#35821;&#20041;&#20998;&#21106;&#21644;&#22238;&#24402;&#12290;&#25105;&#20204;&#35797;&#39564;&#20102;&#21463;&#27426;&#36814;&#30340;&#23569;&#26679;&#26412;&#20803;&#23398;&#20064;&#22522;&#32447;&#65292;&#24182;&#20998;&#26512;&#20102;&#23427;&#20204;&#27867;&#21270;&#21040;&#19981;&#21516;&#20219;&#21153;&#31867;&#22411;&#30340;&#33021;&#21147;&#20197;&#21450;&#22312;&#23427;&#20204;&#20043;&#38388;&#20256;&#36882;&#30693;&#35782;&#30340;&#33021;&#21147;&#12290;Meta Omnium&#20351;&#24471;&#23398;&#26415;&#30028;&#33021;&#22815;&#35780;&#20272;&#27169;&#22411;&#23545;&#20110;&#22810;&#39033;&#20219;&#21153;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#36825;&#27604;&#20197;&#21069;&#26356;&#21152;&#24191;&#27867;&#65292;&#21516;&#26102;&#23427;&#25552;&#20379;&#20102;&#19968;&#20010;&#22312;&#19981;&#21516;&#35270;&#35273;&#24212;&#29992;&#20013;&#20197;&#19968;&#33268;&#30340;&#26041;&#24335;&#35780;&#20272;&#20803;&#23398;&#20064;&#32773;&#30340;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Meta-learning and other approaches to few-shot learning are widely studied for image recognition, and are increasingly applied to other vision tasks such as pose estimation and dense prediction. This naturally raises the question of whether there is any few-shot meta-learning algorithm capable of generalizing across these diverse task types? To support the community in answering this question, we introduce Meta Omnium, a dataset-of-datasets spanning multiple vision tasks including recognition, keypoint localization, semantic segmentation and regression. We experiment with popular few-shot meta-learning baselines and analyze their ability to generalize across tasks and to transfer knowledge between them. Meta Omnium enables meta-learning researchers to evaluate model generalization to a much wider array of tasks than previously possible, and provides a single framework for evaluating meta-learners across a wide suite of vision applications in a consistent manner.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#21644;&#25439;&#22833;&#20989;&#25968;&#65292;&#33021;&#22815;&#26377;&#25928;&#23398;&#20064;&#22914;&#20309;&#35299;&#20915;NP-hard&#25512;&#29702;&#38382;&#39064;&#65292;&#24182;&#22312;&#31163;&#25955;&#22270;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#39564;&#35777;&#12290;&#21516;&#26102;&#21487;&#20197;&#25552;&#39640;&#25968;&#25454;&#25928;&#29575;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#20855;&#26377;&#23545;&#39044;&#27979;&#30340;&#25511;&#21046;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2305.07617</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#19982;&#36923;&#36753;&#25512;&#29702;&#30340;&#21487;&#25193;&#23637;&#32806;&#21512;
&lt;/p&gt;
&lt;p&gt;
Scalable Coupling of Deep Learning with Logical Reasoning. (arXiv:2305.07617v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07617
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#21644;&#25439;&#22833;&#20989;&#25968;&#65292;&#33021;&#22815;&#26377;&#25928;&#23398;&#20064;&#22914;&#20309;&#35299;&#20915;NP-hard&#25512;&#29702;&#38382;&#39064;&#65292;&#24182;&#22312;&#31163;&#25955;&#22270;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#39564;&#35777;&#12290;&#21516;&#26102;&#21487;&#20197;&#25552;&#39640;&#25968;&#25454;&#25928;&#29575;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#20855;&#26377;&#23545;&#39044;&#27979;&#30340;&#25511;&#21046;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23558;&#31163;&#25955;&#25512;&#29702;&#19982;&#31070;&#32463;&#32593;&#32476;&#28151;&#21512;&#30340;&#19981;&#26029;&#25506;&#32034;&#20013;&#65292;&#20986;&#29616;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#23545;&#31070;&#32463;&#32467;&#26500;&#20855;&#22791;&#20174;&#33258;&#28982;&#36755;&#20837;&#20013;&#23398;&#20064;&#22914;&#20309;&#35299;&#20915;&#31163;&#25955;&#25512;&#29702;&#25110;&#20248;&#21270;&#38382;&#39064;&#30340;&#20852;&#36259;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#31070;&#32463;&#32467;&#26500;&#20197;&#21450;&#19987;&#38376;&#29992;&#20110;&#23398;&#20064;&#34987;&#34920;&#31034;&#20026;&#31163;&#25955;&#22270;&#27169;&#22411;&#30340; NP-hard &#25512;&#29702;&#38382;&#39064;&#30340;&#32422;&#26463;&#21644;&#26631;&#20934;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;&#25105;&#20204;&#30340;&#25439;&#22833;&#20989;&#25968;&#35299;&#20915;&#20102; Besag &#30340;&#20266;&#23545;&#25968;&#20284;&#28982;&#30340;&#20027;&#35201;&#38480;&#21046;&#20043;&#19968;&#65292;&#33021;&#22815;&#23398;&#20064;&#39640;&#33021;&#37327;&#20989;&#25968;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#23427;&#33021;&#22815;&#26377;&#25928;&#22320;&#20174;&#33258;&#28982;&#36755;&#20837;&#20013;&#23398;&#20064;&#22914;&#20309;&#35299;&#20915; NP-hard &#25512;&#29702;&#38382;&#39064;&#65292;&#22914;&#31526;&#21495;&#12289;&#35270;&#35273;&#25110;&#22810;&#35299;&#25968;&#25968;&#29420;&#38382;&#39064;&#65292;&#20197;&#21450;&#34507;&#30333;&#36136;&#35774;&#35745;&#38382;&#39064;&#30340;&#33021;&#37327;&#20248;&#21270;&#24418;&#24335;&#65292;&#25552;&#39640;&#20102;&#25968;&#25454;&#25928;&#29575;&#12289;&#21487;&#35299;&#37322;&#24615;&#20197;&#21450;&#23545;&#39044;&#27979;&#30340; \textit{a posteriori} &#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the ongoing quest for hybridizing discrete reasoning with neural nets, there is an increasing interest in neural architectures that can learn how to solve discrete reasoning or optimization problems from natural inputs. In this paper, we introduce a scalable neural architecture and loss function dedicated to learning the constraints and criteria of NP-hard reasoning problems expressed as discrete Graphical Models. Our loss function solves one of the main limitations of Besag's pseudo-loglikelihood, enabling learning of high energies. We empirically show it is able to efficiently learn how to solve NP-hard reasoning problems from natural inputs as the symbolic, visual or many-solutions Sudoku problems as well as the energy optimization formulation of the protein design problem, providing data efficiency, interpretability, and \textit{a posteriori} control over predictions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Spider GAN&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23547;&#25214;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;&#21451;&#22909;&#37051;&#23621;&#26469;&#25552;&#39640;GAN&#30340;&#35757;&#32451;&#25928;&#29575;&#65292;&#21152;&#36895;&#25910;&#25947;&#65292;&#21363;&#20351;&#26159;&#19981;&#30456;&#20851;&#30340;&#25968;&#25454;&#38598;&#20043;&#38388;&#20063;&#21487;&#20197;&#21457;&#29616;&#23545;&#24212;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2305.07613</link><description>&lt;p&gt;
Spider GAN:&#21033;&#29992;&#21451;&#22909;&#37051;&#23621;&#21152;&#36895;GAN&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Spider GAN: Leveraging Friendly Neighbors to Accelerate GAN Training. (arXiv:2305.07613v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07613
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Spider GAN&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23547;&#25214;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;&#21451;&#22909;&#37051;&#23621;&#26469;&#25552;&#39640;GAN&#30340;&#35757;&#32451;&#25928;&#29575;&#65292;&#21152;&#36895;&#25910;&#25947;&#65292;&#21363;&#20351;&#26159;&#19981;&#30456;&#20851;&#30340;&#25968;&#25454;&#38598;&#20043;&#38388;&#20063;&#21487;&#20197;&#21457;&#29616;&#23545;&#24212;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
GAN&#30340;&#35757;&#32451;&#26159;&#20010;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;Spider GAN&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#22270;&#20687;&#32467;&#26500;&#30340;&#29305;&#28857;&#20248;&#21270;&#29983;&#25104;&#22120;&#30340;&#36716;&#25442;&#65292;&#36890;&#36807;&#23450;&#20041;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26041;&#24335;&#65292;&#21363;&#26377;&#31526;&#21495;&#21551;&#21160;&#36317;&#31163;&#65288;SID&#65289;&#65292;&#20351;&#20854;&#26356;&#39640;&#25928;&#22320;&#23547;&#25214;&#21451;&#22909;&#37051;&#23621;&#65292;&#32467;&#26524;&#23548;&#33268;&#26356;&#24555;&#30340;&#25910;&#25947;&#65292;&#21363;&#20351;&#22312;&#30475;&#20284;&#19981;&#30456;&#20851;&#30340;&#25968;&#25454;&#38598;&#20043;&#38388;&#20063;&#21487;&#20197;&#25214;&#21040;&#23545;&#24212;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training Generative adversarial networks (GANs) stably is a challenging task. The generator in GANs transform noise vectors, typically Gaussian distributed, into realistic data such as images. In this paper, we propose a novel approach for training GANs with images as inputs, but without enforcing any pairwise constraints. The intuition is that images are more structured than noise, which the generator can leverage to learn a more robust transformation. The process can be made efficient by identifying closely related datasets, or a ``friendly neighborhood'' of the target distribution, inspiring the moniker, Spider GAN. To define friendly neighborhoods leveraging proximity between datasets, we propose a new measure called the signed inception distance (SID), inspired by the polyharmonic kernel. We show that the Spider GAN formulation results in faster convergence, as the generator can discover correspondence even between seemingly unrelated datasets, for instance, between Tiny-ImageNet 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#22270;&#33410;&#28857;&#23884;&#20837;&#26694;&#26550;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#29702;&#35299;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;GNN&#12290;</title><link>http://arxiv.org/abs/2305.07580</link><description>&lt;p&gt;
&#22522;&#20110;Fisher&#20449;&#24687;&#23884;&#20837;&#30340;&#33410;&#28857;&#21644;&#22270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Fisher Information Embedding for Node and Graph Learning. (arXiv:2305.07580v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07580
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#22270;&#33410;&#28857;&#23884;&#20837;&#26694;&#26550;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#29702;&#35299;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;GNN&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#65292;&#20363;&#22914;&#22270;&#27880;&#24847;&#21147;&#32593;&#32476;&#65288;GAT&#65289;&#65292;&#24050;&#25104;&#20026;&#22788;&#29702;&#22270;&#32467;&#26500;&#25968;&#25454;&#21644;&#23398;&#20064;&#33410;&#28857;&#23884;&#20837;&#30340;&#27969;&#34892;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#12290;&#23613;&#31649;&#36825;&#20123;&#27169;&#22411;&#22312;&#32463;&#39564;&#19978;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#23427;&#20204;&#20381;&#36182;&#20110;&#26631;&#27880;&#25968;&#25454;&#65292;&#19988;&#36825;&#20123;&#27169;&#22411;&#30340;&#29702;&#35770;&#23646;&#24615;&#23578;&#26410;&#23436;&#20840;&#29702;&#35299;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#22270;&#33410;&#28857;&#23884;&#20837;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#24314;&#31435;&#22312;&#19968;&#31181;&#22810;&#37325;&#38598;&#21512;&#20869;&#33410;&#28857;&#21608;&#22260;&#23376;&#22270;&#30340;&#20998;&#23618;&#26680;&#20043;&#19978;&#65288;&#20363;&#22914;&#65292;&#37051;&#22495;&#65289;&#65292;&#24182;&#19988;&#27599;&#20010;&#26680;&#21033;&#29992;&#24179;&#28369;&#32479;&#35745;&#27969;&#24418;&#30340;&#20960;&#20309;&#26469;&#27604;&#36739;&#22810;&#37325;&#38598;&#21512;&#30340;&#25104;&#23545;&#24046;&#24322;&#65292;&#36890;&#36807;&#23558;&#22810;&#37325;&#38598;&#21512;&#8220;&#26144;&#23556;&#8221;&#21040;&#27969;&#24418;&#19978;&#12290;&#36890;&#36807;&#26174;&#24335;&#35745;&#31639;&#39640;&#26031;&#28151;&#21512;&#29289;&#27969;&#24418;&#20013;&#30340;&#33410;&#28857;&#23884;&#20837;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24341;&#23548;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20851;&#27880;&#26426;&#21046;&#36827;&#34892;&#37051;&#22495;&#32858;&#21512;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#26377;&#20851;&#23884;&#20837;&#30340;&#27867;&#21270;&#21644;&#34920;&#36798;&#33021;&#21147;&#30340;&#29702;&#35770;&#35265;&#35299;&#65292;&#20026;&#26356;&#28145;&#20837;&#29702;&#35299;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;GNN&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
Attention-based graph neural networks (GNNs), such as graph attention networks (GATs), have become popular neural architectures for processing graph-structured data and learning node embeddings. Despite their empirical success, these models rely on labeled data and the theoretical properties of these models have yet to be fully understood. In this work, we propose a novel attention-based node embedding framework for graphs. Our framework builds upon a hierarchical kernel for multisets of subgraphs around nodes (e.g. neighborhoods) and each kernel leverages the geometry of a smooth statistical manifold to compare pairs of multisets, by "projecting" the multisets onto the manifold. By explicitly computing node embeddings with a manifold of Gaussian mixtures, our method leads to a new attention mechanism for neighborhood aggregation. We provide theoretical insights into genralizability and expressivity of our embeddings, contributing to a deeper understanding of attention-based GNNs. We p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#26032;&#39062;&#30340;Voronoi Loss&#20989;&#25968;&#26469;&#35299;&#20915;&#39640;&#26031;&#38376;&#25511;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#21442;&#25968;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#29575;&#38382;&#39064;&#65292;&#24182;&#22312;&#20004;&#31181;&#19981;&#21516;&#30340;&#38376;&#25511;&#32593;&#32476;&#19979;&#25552;&#20379;&#29702;&#35770;&#25910;&#25947;&#36895;&#29575;&#30340;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2305.07572</link><description>&lt;p&gt;
&#39640;&#26031;&#38376;&#25511;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#21442;&#25968;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#29575;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Towards Convergence Rates for Parameter Estimation in Gaussian-gated Mixture of Experts. (arXiv:2305.07572v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07572
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#26032;&#39062;&#30340;Voronoi Loss&#20989;&#25968;&#26469;&#35299;&#20915;&#39640;&#26031;&#38376;&#25511;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#21442;&#25968;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#29575;&#38382;&#39064;&#65292;&#24182;&#22312;&#20004;&#31181;&#19981;&#21516;&#30340;&#38376;&#25511;&#32593;&#32476;&#19979;&#25552;&#20379;&#29702;&#35770;&#25910;&#25947;&#36895;&#29575;&#30340;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#22240;&#20854;&#22312;&#38598;&#25104;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#32780;&#34987;&#24341;&#20837;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#36817;&#24180;&#26469;&#25104;&#20026;&#29616;&#20195;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#22788;&#29702;&#24322;&#26500;&#25968;&#25454;&#20998;&#26512;&#30340;&#22522;&#26412;&#26500;&#20214;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#39640;&#26031;&#38376;&#25511;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#21442;&#25968;&#20272;&#35745;&#30340;&#25910;&#25947;&#34892;&#20026;&#30340;&#29702;&#35299;&#36824;&#19981;&#20805;&#20998;&#12290;&#25105;&#20204;&#36890;&#36807;&#35774;&#35745;&#26032;&#39062;&#30340;Voronoi Loss&#20989;&#25968;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35770;&#25910;&#25947;&#36895;&#29575;&#30340;&#35777;&#26126;&#65292;&#25581;&#31034;&#20102;&#22312;&#20004;&#31181;&#20998;&#31163;&#30340;&#38376;&#25511;&#32593;&#32476;&#19979;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#30340;&#19981;&#21516;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
Originally introduced as a neural network for ensemble learning, mixture of experts (MoE) has recently become a fundamental building block of highly successful modern deep neural networks for heterogeneous data analysis in several applications, including those in machine learning, statistics, bioinformatics, economics, and medicine. Despite its popularity in practice, a satisfactory level of understanding of the convergence behavior of Gaussian-gated MoE parameter estimation is far from complete. The underlying reason for this challenge is the inclusion of covariates in the Gaussian gating and expert networks, which leads to their intrinsically complex interactions via partial differential equations with respect to their parameters. We address these issues by designing novel Voronoi loss functions to accurately capture heterogeneity in the maximum likelihood estimator (MLE) for resolving parameter estimation in these models. Our results reveal distinct behaviors of the MLE under two se
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#19987;&#23478;&#35780;&#20272;&#30340;&#21152;&#26435;&#22238;&#24402;&#27169;&#22411;&#65292;&#21487;&#29992;&#20110;&#22788;&#29702;&#20855;&#26377;&#19981;&#21516;&#35266;&#28857;&#30340;&#22024;&#26434;&#26631;&#31614;&#12290;&#35813;&#26041;&#27861;&#21253;&#25324;&#20004;&#20010;&#27493;&#39588;&#65306;&#20272;&#35745;&#27599;&#20010;&#19987;&#23478;&#30340;&#19987;&#19994;&#31243;&#24230;&#21644;&#32467;&#21512;&#20182;&#20204;&#30340;&#24847;&#35265;&#65292;&#28982;&#21518;&#23558;&#21152;&#26435;&#24179;&#22343;&#29992;&#20110;&#22238;&#24402;&#24314;&#27169;&#12290;&#26412;&#26041;&#27861;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#65292;&#20855;&#26377;&#31616;&#21333;&#12289;&#24555;&#36895;&#21644;&#26377;&#25928;&#30340;&#29305;&#28857;&#12290;</title><link>http://arxiv.org/abs/2305.07430</link><description>&lt;p&gt;
&#22522;&#20110;&#19987;&#23478;&#35780;&#20272;&#30340;&#21152;&#26435;&#22238;&#24402;&#27169;&#22411;&#22788;&#29702;&#22024;&#26434;&#26631;&#31614;
&lt;/p&gt;
&lt;p&gt;
Expertise-based Weighting for Regression Models with Noisy Labels. (arXiv:2305.07430v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07430
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#19987;&#23478;&#35780;&#20272;&#30340;&#21152;&#26435;&#22238;&#24402;&#27169;&#22411;&#65292;&#21487;&#29992;&#20110;&#22788;&#29702;&#20855;&#26377;&#19981;&#21516;&#35266;&#28857;&#30340;&#22024;&#26434;&#26631;&#31614;&#12290;&#35813;&#26041;&#27861;&#21253;&#25324;&#20004;&#20010;&#27493;&#39588;&#65306;&#20272;&#35745;&#27599;&#20010;&#19987;&#23478;&#30340;&#19987;&#19994;&#31243;&#24230;&#21644;&#32467;&#21512;&#20182;&#20204;&#30340;&#24847;&#35265;&#65292;&#28982;&#21518;&#23558;&#21152;&#26435;&#24179;&#22343;&#29992;&#20110;&#22238;&#24402;&#24314;&#27169;&#12290;&#26412;&#26041;&#27861;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#65292;&#20855;&#26377;&#31616;&#21333;&#12289;&#24555;&#36895;&#21644;&#26377;&#25928;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22238;&#24402;&#26041;&#27861;&#20551;&#35774;&#35757;&#32451;&#25968;&#25454;&#30340;&#26631;&#31614;&#26159;&#20934;&#30830;&#30340;&#65292;&#28982;&#32780;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#33719;&#21462;&#20934;&#30830;&#30340;&#26631;&#31614;&#24182;&#19981;&#21487;&#34892;&#65292;&#22240;&#27492;&#38656;&#35201;&#20381;&#36182;&#22810;&#20010;&#20855;&#26377;&#19981;&#21516;&#35266;&#28857;&#30340;&#19987;&#23478;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#12289;&#26356;&#28789;&#27963;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#22024;&#26434;&#26631;&#31614;&#12290;&#35813;&#26041;&#27861;&#21253;&#25324;&#20004;&#20010;&#27493;&#39588;&#65306;&#20808;&#20272;&#35745;&#27599;&#20010;&#19987;&#23478;&#30340;&#19987;&#19994;&#31243;&#24230;&#65292;&#28982;&#21518;&#20351;&#29992;&#23398;&#20064;&#21040;&#30340;&#26435;&#37325;&#32467;&#21512;&#20182;&#20204;&#30340;&#24847;&#35265;&#12290;&#25509;&#30528;&#65292;&#23558;&#21152;&#26435;&#24179;&#22343;&#29992;&#20110;&#22238;&#24402;&#24314;&#27169;&#12290;&#26412;&#25991;&#26041;&#27861;&#32463;&#36807;&#27491;&#24335;&#39564;&#35777;&#65292;&#35777;&#26126;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;&#27492;&#22806;&#65292;&#20854;&#28789;&#27963;&#24615;&#20351;&#24471;&#21487;&#20197;&#22312;&#20004;&#20010;&#27493;&#39588;&#20013;&#21033;&#29992;&#20219;&#20309;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#12290;&#24635;&#20043;&#65292;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#31616;&#21333;&#12289;&#24555;&#36895;&#21644;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#29992;&#20110;&#35757;&#32451;&#22238;&#24402;&#27169;&#22411;&#24182;&#22788;&#29702;&#33719;&#21462;&#33258;&#19981;&#21516;&#19987;&#19994;&#26469;&#28304;&#30340;&#22024;&#26434;&#26631;&#31614;&#12290;
&lt;/p&gt;
&lt;p&gt;
Regression methods assume that accurate labels are available for training. However, in certain scenarios, obtaining accurate labels may not be feasible, and relying on multiple specialists with differing opinions becomes necessary. Existing approaches addressing noisy labels often impose restrictive assumptions on the regression function. In contrast, this paper presents a novel, more flexible approach. Our method consists of two steps: estimating each labeler's expertise and combining their opinions using learned weights. We then regress the weighted average against the input features to build the prediction model. The proposed method is formally justified and empirically demonstrated to outperform existing techniques on simulated and real data. Furthermore, its flexibility enables the utilization of any machine learning technique in both steps. In summary, this method offers a simple, fast, and effective solution for training regression models with noisy labels derived from diverse e
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20989;&#25968;&#25968;&#25454;&#30340;&#20998;&#24067;&#24335;&#26799;&#24230;&#19979;&#38477;&#20989;&#25968;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26694;&#26550;&#19979;&#36890;&#36807;&#31215;&#20998;&#31639;&#23376;&#26041;&#27861;&#24471;&#21040;&#20102;&#35813;&#31639;&#27861;&#30340;&#29702;&#35770;&#29702;&#35299;&#65292;&#24182;&#21462;&#24471;&#20102;&#19981;&#39281;&#21644;&#36793;&#30028;&#30340;&#32622;&#20449;&#24230;&#26368;&#20248;&#23398;&#20064;&#29575;&#12290;</title><link>http://arxiv.org/abs/2305.07408</link><description>&lt;p&gt;
&#38754;&#21521;&#20989;&#25968;&#23398;&#20064;&#30340;&#20998;&#24067;&#24335;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Distributed Gradient Descent for Functional Learning. (arXiv:2305.07408v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07408
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20989;&#25968;&#25968;&#25454;&#30340;&#20998;&#24067;&#24335;&#26799;&#24230;&#19979;&#38477;&#20989;&#25968;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26694;&#26550;&#19979;&#36890;&#36807;&#31215;&#20998;&#31639;&#23376;&#26041;&#27861;&#24471;&#21040;&#20102;&#35813;&#31639;&#27861;&#30340;&#29702;&#35770;&#29702;&#35299;&#65292;&#24182;&#21462;&#24471;&#20102;&#19981;&#39281;&#21644;&#36793;&#30028;&#30340;&#32622;&#20449;&#24230;&#26368;&#20248;&#23398;&#20064;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#19981;&#21516;&#31867;&#22411;&#30340;&#20998;&#24067;&#24335;&#23398;&#20064;&#26041;&#26696;&#22240;&#20854;&#22312;&#22788;&#29702;&#22823;&#35268;&#27169;&#25968;&#25454;&#20449;&#24687;&#26041;&#38754;&#30340;&#24040;&#22823;&#20248;&#21183;&#32780;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#38024;&#23545;&#26368;&#36817;&#20174;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#20013;&#20135;&#29983;&#30340;&#22823;&#25968;&#25454;&#25361;&#25112;&#65292;&#25105;&#20204;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26694;&#26550;&#19979;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#24067;&#24335;&#26799;&#24230;&#19979;&#38477;&#20989;&#25968;&#23398;&#20064;&#65288;DGDFL&#65289;&#31639;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#26469;&#33258;&#20247;&#22810;&#26412;&#22320;&#26426;&#22120;&#65288;&#22788;&#29702;&#22120;&#65289;&#30340;&#20989;&#25968;&#25968;&#25454;&#12290;&#22522;&#20110;&#31215;&#20998;&#31639;&#23376;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;DGDFL&#31639;&#27861;&#22312;&#25991;&#29486;&#20013;&#30340;&#35768;&#22810;&#26041;&#38754;&#30340;&#31532;&#19968;&#20010;&#29702;&#35770;&#29702;&#35299;&#12290;&#22312;&#29702;&#35299;DGDFL&#30340;&#36807;&#31243;&#20013;&#65292;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#20840;&#38754;&#30740;&#31350;&#20102;&#22522;&#20110;&#25968;&#25454;&#30340;&#28176;&#36827;&#24335;&#19979;&#38477;&#20989;&#25968;&#23398;&#20064;&#65288;GDFL&#65289;&#31639;&#27861;&#19982;&#21333;&#26426;&#27169;&#22411;&#30456;&#20851;&#32852;&#12290;&#22312;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#65292;&#24471;&#21040;&#20102;DGDFL&#30340;&#32622;&#20449;&#24230;&#26368;&#20248;&#23398;&#20064;&#29575;&#65292;&#36991;&#20813;&#20102;&#20808;&#21069;&#22312;&#27491;&#21017;&#24615;&#32034;&#24341;&#19978;&#36973;&#21463;&#30340;&#39281;&#21644;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, different types of distributed learning schemes have received increasing attention for their strong advantages in handling large-scale data information. In the information era, to face the big data challenges which stem from functional data analysis very recently, we propose a novel distributed gradient descent functional learning (DGDFL) algorithm to tackle functional data across numerous local machines (processors) in the framework of reproducing kernel Hilbert space. Based on integral operator approaches, we provide the first theoretical understanding of the DGDFL algorithm in many different aspects in the literature. On the way of understanding DGDFL, firstly, a data-based gradient descent functional learning (GDFL) algorithm associated with a single-machine model is proposed and comprehensively studied. Under mild conditions, confidence-based optimal learning rates of DGDFL are obtained without the saturation boundary on the regularity index suffered in previous w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#27169;&#22411;&#32452;&#21512;&#24037;&#20855;&#65292;&#21487;&#20197;&#36890;&#36807;&#23545;&#25968;&#27744;&#21270;&#21644;&#36229;&#21472;&#21152;&#26469;&#32452;&#21512;&#21518;&#39564;&#23494;&#24230;&#65292;&#36991;&#20813;&#20102;&#26631;&#20934;&#21270;&#24120;&#25968;&#30340;&#36127;&#25285;&#65292;&#24182;&#22312;&#39044;&#27979;&#20934;&#30830;&#24615;&#26041;&#38754;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.07334</link><description>&lt;p&gt;
&#38145;&#23450;&#19982;&#21472;&#23618;&#65306;&#36890;&#36807;&#23545;&#25968;&#27744;&#21270;&#21644;&#36229;&#21472;&#21152;&#22534;&#21472;&#36125;&#21494;&#26031;&#27169;&#22411;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Locking and Quacking: Stacking Bayesian model predictions by log-pooling and superposition. (arXiv:2305.07334v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07334
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#27169;&#22411;&#32452;&#21512;&#24037;&#20855;&#65292;&#21487;&#20197;&#36890;&#36807;&#23545;&#25968;&#27744;&#21270;&#21644;&#36229;&#21472;&#21152;&#26469;&#32452;&#21512;&#21518;&#39564;&#23494;&#24230;&#65292;&#36991;&#20813;&#20102;&#26631;&#20934;&#21270;&#24120;&#25968;&#30340;&#36127;&#25285;&#65292;&#24182;&#22312;&#39044;&#27979;&#20934;&#30830;&#24615;&#26041;&#38754;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#26469;&#33258;&#19981;&#21516;&#27169;&#22411;&#30340;&#39044;&#27979;&#32467;&#21512;&#36215;&#26469;&#26159;&#36125;&#21494;&#26031;&#25512;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#12290;&#30446;&#21069;&#65292;&#36825;&#20123;&#39044;&#27979;&#20998;&#24067;&#20960;&#20046;&#20165;&#20351;&#29992;&#32447;&#24615;&#32452;&#21512;&#36827;&#34892;&#32452;&#21512;&#65292;&#20363;&#22914;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#12289;&#36125;&#21494;&#26031;&#22534;&#21472;&#21644;&#19987;&#23478;&#28151;&#21512;&#12290;&#36825;&#31181;&#32447;&#24615;&#28151;&#21512;&#21487;&#33021;&#23545;&#26576;&#20123;&#24212;&#29992;&#31243;&#24207;&#19981;&#21033;&#65292;&#20363;&#22914;&#22810;&#23792;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#27169;&#22411;&#32452;&#21512;&#24037;&#20855;&#12290;&#36825;&#20123;&#24037;&#20855;&#26159;&#27169;&#22411;&#22534;&#21472;&#30340;&#25512;&#24191;&#65292;&#20294;&#26159;&#36890;&#36807;&#23545;&#25968;&#32447;&#24615;&#27719;&#38598;&#65288;&#38145;&#23450;&#65289;&#21644;&#37327;&#23376;&#21472;&#21152;&#65288;quacking&#65289;&#26469;&#21512;&#24182;&#21518;&#39564;&#23494;&#24230;&#12290;&#20026;&#20102;&#20248;&#21270;&#27169;&#22411;&#26435;&#37325;&#32780;&#36991;&#20813;&#26631;&#20934;&#21270;&#24120;&#25968;&#30340;&#36127;&#25285;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#32452;&#21512;&#21518;&#39564;&#39044;&#27979;&#30340;Hyvarinen&#24471;&#20998;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#31034;&#20363;&#35828;&#26126;&#20102;&#38145;&#23450;&#65292;&#24182;&#23558;&#20004;&#31181;&#26041;&#27861;&#24212;&#29992;&#20110;&#26469;&#33258;&#19981;&#21516;&#36830;&#32493;&#23494;&#24230;&#30340;&#27169;&#25311;&#25968;&#25454;&#38598;&#65292;&#23558;&#23427;&#20204;&#19982;&#20256;&#32479;&#30340;&#27169;&#22411;&#32452;&#21512;&#24037;&#20855;&#36827;&#34892;&#27604;&#36739;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#22312;&#39044;&#27979;&#20934;&#30830;&#24615;&#26041;&#38754;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#65292;&#21516;&#26102;&#20855;&#26377;&#39640;&#25928;&#35745;&#31639;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Combining predictions from different models is a central problem in Bayesian inference and machine learning more broadly. Currently, these predictive distributions are almost exclusively combined using linear mixtures such as Bayesian model averaging, Bayesian stacking, and mixture of experts. Such linear mixtures impose idiosyncrasies that might be undesirable for some applications, such as multi-modality. While there exist alternative strategies (e.g. geometric bridge or superposition), optimising their parameters usually involves computing an intractable normalising constant repeatedly. We present two novel Bayesian model combination tools. These are generalisations of model stacking, but combine posterior densities by log-linear pooling (locking) and quantum superposition (quacking). To optimise model weights while avoiding the burden of normalising constants, we investigate the Hyvarinen score of the combined posterior predictions. We demonstrate locking with an illustrative examp
&lt;/p&gt;</description></item><item><title>HINT&#26159;&#19968;&#31181;&#29992;&#20110;&#27010;&#29575;&#39044;&#27979;&#30340;&#26032;&#22411;&#27169;&#22411;&#26063;&#65292;&#33021;&#22815;&#26377;&#25928;&#12289;&#20934;&#30830;&#22320;&#36827;&#34892;&#19968;&#33268;&#24615;&#39044;&#27979;&#65292;&#36890;&#36807;&#24341;&#20837;Bootstrap&#26041;&#27861;&#24182;&#20026;&#32593;&#32476;&#21152;&#20837;&#35268;&#33539;&#21270;&#29305;&#24449;&#25552;&#21462;&#21644;&#36755;&#20986;&#35268;&#33539;&#21270;&#26469;&#20445;&#35777;&#20854;&#24615;&#33021;&#65292;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#39044;&#27979;&#31934;&#24230;&#27604;&#29616;&#26377;&#25216;&#26415;&#26356;&#39640;&#12290;</title><link>http://arxiv.org/abs/2305.07089</link><description>&lt;p&gt;
HINT:&#23618;&#27425;&#28151;&#21512;&#32593;&#32476;&#29992;&#20110;&#19968;&#33268;&#27010;&#29575;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
HINT: Hierarchical Mixture Networks For Coherent Probabilistic Forecasting. (arXiv:2305.07089v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07089
&lt;/p&gt;
&lt;p&gt;
HINT&#26159;&#19968;&#31181;&#29992;&#20110;&#27010;&#29575;&#39044;&#27979;&#30340;&#26032;&#22411;&#27169;&#22411;&#26063;&#65292;&#33021;&#22815;&#26377;&#25928;&#12289;&#20934;&#30830;&#22320;&#36827;&#34892;&#19968;&#33268;&#24615;&#39044;&#27979;&#65292;&#36890;&#36807;&#24341;&#20837;Bootstrap&#26041;&#27861;&#24182;&#20026;&#32593;&#32476;&#21152;&#20837;&#35268;&#33539;&#21270;&#29305;&#24449;&#25552;&#21462;&#21644;&#36755;&#20986;&#35268;&#33539;&#21270;&#26469;&#20445;&#35777;&#20854;&#24615;&#33021;&#65292;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#39044;&#27979;&#31934;&#24230;&#27604;&#29616;&#26377;&#25216;&#26415;&#26356;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;"Hierarchical Mixture Networks"&#65288;HINT&#65289;&#30340;&#27169;&#22411;&#26063;&#65292;&#29992;&#20110;&#26377;&#25928;&#32780;&#20934;&#30830;&#30340;&#19968;&#33268;&#24615;&#39044;&#27979;&#12290;&#25105;&#20204;&#36890;&#36807;&#22810;&#20803;&#28151;&#21512;&#24182;&#20351;&#29992;&#22797;&#21512;&#20284;&#28982;&#20989;&#25968;&#36827;&#34892;&#20248;&#21270;&#26469;&#19987;&#38376;&#38024;&#23545;&#35813;&#20219;&#21153;&#36827;&#34892;&#32593;&#32476;&#29305;&#21270;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;Bootstrap&#26041;&#27861;&#21152;&#20197;&#21327;&#35843;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;&#32593;&#32476;&#20013;&#24341;&#20837;&#20102;&#35268;&#33539;&#21270;&#29305;&#24449;&#25552;&#21462;&#21644;&#36755;&#20986;&#35268;&#33539;&#21270;&#65292;&#20197;&#24212;&#23545;&#26102;&#38388;&#24207;&#21015;&#23610;&#24230;&#21464;&#21270;&#12290;&#19982;&#29616;&#26377;&#26368;&#20808;&#36827;&#25216;&#26415;&#30456;&#27604;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#20116;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;8&#65285; sCRPS&#22686;&#24378;&#31934;&#24230;&#12290;&#25105;&#20204;&#23545;&#27169;&#22411;&#37096;&#20214;&#36827;&#34892;&#20102;&#28040;&#34701;&#30740;&#31350;&#24182;&#24191;&#27867;&#30740;&#31350;&#20102;&#22810;&#20803;&#28151;&#21512;&#30340;&#29702;&#35770;&#24615;&#36136;&#12290; HINT&#30340;&#20195;&#30721;&#21487;&#20197;&#22312;https://github.com/Nixtla/neuralforecast&#19978;&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present the Hierarchical Mixture Networks (HINT), a model family for efficient and accurate coherent forecasting. We specialize the networks on the task via a multivariate mixture optimized with composite likelihood and made coherent via bootstrap reconciliation. Additionally, we robustify the networks to stark time series scale variations, incorporating normalized feature extraction and recomposition of output scales within their architecture. We demonstrate 8% sCRPS improved accuracy across five datasets compared to the existing state-of-the-art. We conduct ablation studies on our model's components and extensively investigate the theoretical properties of the multivariate mixture. HINT's code is available at this https://github.com/Nixtla/neuralforecast.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#24179;&#28369;&#27491;&#21017;&#21270;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#33258;&#36866;&#24212;&#22320;&#12289;&#26377;&#25928;&#22320;&#23398;&#20064;&#23646;&#20110;&#32463;&#20856;Sobolev&#31354;&#38388;&#33539;&#22260;&#20869;&#30340;&#21508;&#31181;&#30495;&#23454;&#20989;&#25968;&#65292;&#36890;&#36807;&#24341;&#20837;&#22122;&#22768;&#36991;&#20813;&#36807;&#25311;&#21512;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#36739;&#24555;&#30340;&#36895;&#24230;&#19979;&#23454;&#29616;&#26368;&#20248;&#25910;&#25947;&#29575;&#12290;</title><link>http://arxiv.org/abs/2305.03531</link><description>&lt;p&gt;
&#26680;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#20013;&#30340;&#38543;&#26426;&#24179;&#28369;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Random Smoothing Regularization in Kernel Gradient Descent Learning. (arXiv:2305.03531v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03531
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#24179;&#28369;&#27491;&#21017;&#21270;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#33258;&#36866;&#24212;&#22320;&#12289;&#26377;&#25928;&#22320;&#23398;&#20064;&#23646;&#20110;&#32463;&#20856;Sobolev&#31354;&#38388;&#33539;&#22260;&#20869;&#30340;&#21508;&#31181;&#30495;&#23454;&#20989;&#25968;&#65292;&#36890;&#36807;&#24341;&#20837;&#22122;&#22768;&#36991;&#20813;&#36807;&#25311;&#21512;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#36739;&#24555;&#30340;&#36895;&#24230;&#19979;&#23454;&#29616;&#26368;&#20248;&#25910;&#25947;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#24179;&#28369;&#25968;&#25454;&#22686;&#24378;&#26159;&#19968;&#31181;&#29420;&#29305;&#30340;&#27491;&#21017;&#21270;&#24418;&#24335;&#65292;&#21487;&#20197;&#36890;&#36807;&#21521;&#36755;&#20837;&#25968;&#25454;&#24341;&#20837;&#22122;&#22768;&#26469;&#38450;&#27490;&#36807;&#25311;&#21512;&#65292;&#40723;&#21169;&#27169;&#22411;&#23398;&#20064;&#26356;&#24191;&#27867;&#30340;&#29305;&#24449;&#12290;&#23613;&#31649;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#37117;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#38543;&#26426;&#24179;&#28369;&#30340;&#27491;&#21017;&#21270;&#33021;&#21147;&#32570;&#20047;&#31995;&#32479;&#30340;&#30740;&#31350;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#36890;&#36807;&#25552;&#20986;&#19968;&#20010;&#38543;&#26426;&#24179;&#28369;&#27491;&#21017;&#21270;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#33258;&#36866;&#24212;&#22320;&#12289;&#26377;&#25928;&#22320;&#23398;&#20064;&#23646;&#20110;&#32463;&#20856; Sobolev &#31354;&#38388;&#33539;&#22260;&#20869;&#30340;&#21508;&#31181;&#30495;&#23454;&#20989;&#25968;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#31181;&#22522;&#30784;&#30340;&#20989;&#25968;&#31354;&#38388;&#65306;&#20302;&#22266;&#26377;&#32500;&#24230;&#30340; Sobolev &#31354;&#38388;&#65292;&#20854;&#20013;&#21253;&#25324; $D$ &#32500;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#25110;&#20302;&#32500;&#23376;&#27969;&#24418;&#20316;&#20026;&#29305;&#20363;&#65292;&#20197;&#21450;&#20855;&#26377;&#24352;&#37327;&#32467;&#26500;&#30340;&#28151;&#21512;&#24179;&#28369; Sobolev &#31354;&#38388;&#12290;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#24179;&#28369;&#27491;&#21017;&#21270;&#20316;&#20026;&#26032;&#22411;&#21367;&#31215;&#24179;&#28369;&#26680;&#65292;&#25105;&#20204;&#21487;&#20197;&#22312;&#36825;&#20123;&#24773;&#20917;&#19979;&#23454;&#29616;&#26368;&#20248;&#25910;&#25947;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Random smoothing data augmentation is a unique form of regularization that can prevent overfitting by introducing noise to the input data, encouraging the model to learn more generalized features. Despite its success in various applications, there has been a lack of systematic study on the regularization ability of random smoothing. In this paper, we aim to bridge this gap by presenting a framework for random smoothing regularization that can adaptively and effectively learn a wide range of ground truth functions belonging to the classical Sobolev spaces. Specifically, we investigate two underlying function spaces: the Sobolev space of low intrinsic dimension, which includes the Sobolev space in $D$-dimensional Euclidean space or low-dimensional sub-manifolds as special cases, and the mixed smooth Sobolev space with a tensor structure. By using random smoothing regularization as novel convolution-based smoothing kernels, we can attain optimal convergence rates in these cases using a ke
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#24102;&#38543;&#26426;&#20808;&#39564;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#29992;&#20110;&#39640;&#32500;&#36755;&#20986;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#21487;&#26377;&#25928;&#22320;&#22788;&#29702;&#20840;&#23616;&#20248;&#21270;&#38382;&#39064;&#65292;&#21363;&#20351;&#22312;&#39640;&#32500;&#24230;&#21521;&#37327;&#31354;&#38388;&#25110;&#26080;&#38480;&#32500;&#20989;&#25968;&#31354;&#38388;&#20013;&#20063;&#33021;&#36817;&#20284;&#21151;&#33021;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2302.07260</link><description>&lt;p&gt;
&#22522;&#20110;&#38543;&#26426;&#20808;&#39564;&#32593;&#32476;&#30340;&#39640;&#32500;&#36755;&#20986;&#21487;&#25193;&#23637;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Scalable Bayesian optimization with high-dimensional outputs using randomized prior networks. (arXiv:2302.07260v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07260
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#24102;&#38543;&#26426;&#20808;&#39564;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#29992;&#20110;&#39640;&#32500;&#36755;&#20986;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#21487;&#26377;&#25928;&#22320;&#22788;&#29702;&#20840;&#23616;&#20248;&#21270;&#38382;&#39064;&#65292;&#21363;&#20351;&#22312;&#39640;&#32500;&#24230;&#21521;&#37327;&#31354;&#38388;&#25110;&#26080;&#38480;&#32500;&#20989;&#25968;&#31354;&#38388;&#20013;&#20063;&#33021;&#36817;&#20284;&#21151;&#33021;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#30340;&#19968;&#20123;&#22522;&#26412;&#38382;&#39064;&#28041;&#21450;&#21040;&#26410;&#30693;&#30340;&#39640;&#32500;&#24230;&#26144;&#23556;&#19968;&#32452;&#21487;&#25511;&#21464;&#37327;&#21040;&#26114;&#36149;&#23454;&#39564;&#32467;&#26524;&#30340;&#40657;&#30418;&#20989;&#25968;&#30340;&#20840;&#23616;&#20248;&#21270;&#20219;&#21153;&#12290;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#25216;&#26415;&#24050;&#34987;&#35777;&#26126;&#22312;&#20351;&#29992;&#30456;&#23545;&#36739;&#23569;&#30340;&#30446;&#26631;&#20989;&#25968;&#35780;&#20272;&#26102;&#22788;&#29702;&#20840;&#23616;&#20248;&#21270;&#38382;&#39064;&#26102;&#38750;&#24120;&#26377;&#25928;&#65292;&#20294;&#24403;&#22788;&#29702;&#39640;&#32500;&#36755;&#20986;&#26102;&#65292;&#20854;&#24615;&#33021;&#21463;&#21040;&#24433;&#21709;&#12290;&#20026;&#20811;&#26381;&#32500;&#24230;&#20027;&#35201;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#24102;&#38543;&#26426;&#20808;&#39564;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#33258;&#20030;&#38598;&#25104;&#30340;BO&#21644;&#24207;&#36143;&#20915;&#31574;&#21046;&#23450;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#12290;&#20351;&#29992;&#36866;&#24403;&#30340;&#20307;&#31995;&#32467;&#26500;&#36873;&#25321;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#21487;&#20197;&#36817;&#20284;&#35774;&#35745;&#21464;&#37327;&#21644;&#24863;&#20852;&#36259;&#37327;&#20043;&#38388;&#30340;&#21151;&#33021;&#20851;&#31995;&#65292;&#21363;&#20351;&#22312;&#21518;&#32773;&#21462;&#20540;&#20110;&#39640;&#32500;&#21521;&#37327;&#31354;&#38388;&#25110;&#29978;&#33267;&#26080;&#38480;&#32500;&#20989;&#25968;&#31354;&#38388;&#30340;&#24773;&#20917;&#19979;&#12290;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#32972;&#26223;&#19979;&#65292;&#35813;&#26041;&#27861;&#20801;&#35768;&#39640;&#25928;&#21644;&#21487;&#25193;&#23637;&#30340;&#22788;&#29702;&#39640;&#32500;&#24230;&#40657;&#30418;&#20989;&#25968;&#30340;&#20840;&#23616;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several fundamental problems in science and engineering consist of global optimization tasks involving unknown high-dimensional (black-box) functions that map a set of controllable variables to the outcomes of an expensive experiment. Bayesian Optimization (BO) techniques are known to be effective in tackling global optimization problems using a relatively small number objective function evaluations, but their performance suffers when dealing with high-dimensional outputs. To overcome the major challenge of dimensionality, here we propose a deep learning framework for BO and sequential decision making based on bootstrapped ensembles of neural architectures with randomized priors. Using appropriate architecture choices, we show that the proposed framework can approximate functional relationships between design variables and quantities of interest, even in cases where the latter take values in high-dimensional vector spaces or even infinite-dimensional function spaces. In the context of 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#26041;&#27861;&#65292;&#20855;&#26377;&#22362;&#22266;&#21644;&#21487;&#25193;&#23637;&#24615;&#65292;&#36890;&#36807;&#21033;&#29992;&#24191;&#20041;&#36125;&#21494;&#26031;&#35270;&#35282;&#25552;&#20379;&#20102;&#21487;&#35777;&#26126;&#30340;&#22362;&#22266;&#24615;&#65292;&#24182;&#36890;&#36807;&#25193;&#25955;&#24471;&#20998;&#21305;&#37197;&#35299;&#20915;&#20102;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#12290;&#25152;&#24471;&#31639;&#27861;&#26159;&#31934;&#30830;&#30340;&#65292;&#26356;&#26032;&#31616;&#21333;&#65292;&#36895;&#24230;&#36739;&#20043;&#21069;&#30340;&#31639;&#27861;&#24555;10&#20493;&#20197;&#19978;&#12290;</title><link>http://arxiv.org/abs/2302.04759</link><description>&lt;p&gt;
&#22362;&#22266;&#19988;&#21487;&#25193;&#23637;&#30340;&#36125;&#21494;&#26031;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Robust and Scalable Bayesian Online Changepoint Detection. (arXiv:2302.04759v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04759
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#26041;&#27861;&#65292;&#20855;&#26377;&#22362;&#22266;&#21644;&#21487;&#25193;&#23637;&#24615;&#65292;&#36890;&#36807;&#21033;&#29992;&#24191;&#20041;&#36125;&#21494;&#26031;&#35270;&#35282;&#25552;&#20379;&#20102;&#21487;&#35777;&#26126;&#30340;&#22362;&#22266;&#24615;&#65292;&#24182;&#36890;&#36807;&#25193;&#25955;&#24471;&#20998;&#21305;&#37197;&#35299;&#20915;&#20102;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#12290;&#25152;&#24471;&#31639;&#27861;&#26159;&#31934;&#30830;&#30340;&#65292;&#26356;&#26032;&#31616;&#21333;&#65292;&#36895;&#24230;&#36739;&#20043;&#21069;&#30340;&#31639;&#27861;&#24555;10&#20493;&#20197;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#12289;&#21487;&#35777;&#26126;&#22362;&#22266;&#19988;&#21487;&#25193;&#23637;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#29992;&#20110;&#21464;&#28857;&#26816;&#27979;&#12290;&#25152;&#24471;&#31639;&#27861;&#30456;&#23545;&#20110;&#20043;&#21069;&#30340;&#24037;&#20316;&#20855;&#26377;&#37325;&#35201;&#20248;&#21183;&#65306;&#36890;&#36807;&#21033;&#29992;&#24191;&#20041;&#36125;&#21494;&#26031;&#35270;&#35282;&#25552;&#20379;&#20102;&#21487;&#35777;&#26126;&#30340;&#22362;&#22266;&#24615;&#65292;&#24182;&#35299;&#20915;&#20102;&#20043;&#21069;&#23581;&#35797;&#20013;&#30340;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25152;&#25552;&#20986;&#30340;&#24191;&#20041;&#36125;&#21494;&#26031;&#24418;&#24335;&#20027;&#20041;&#36890;&#36807;&#21033;&#29992;&#25193;&#25955;&#24471;&#20998;&#21305;&#37197;&#23548;&#33268;&#20849;&#36717;&#21518;&#39564;&#30340;&#21442;&#25968;&#21487;&#20197;&#36890;&#36807;&#23553;&#38381;&#24418;&#24335;&#33719;&#24471;&#12290;&#25152;&#24471;&#31639;&#27861;&#26159;&#31934;&#30830;&#30340;&#65292;&#21487;&#20197;&#36890;&#36807;&#31616;&#21333;&#30340;&#20195;&#25968;&#26356;&#26032;&#65292;&#24182;&#19988;&#27604;&#20854;&#26368;&#25509;&#36817;&#30340;&#31454;&#20105;&#23545;&#25163;&#24555;10&#20493;&#20197;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes an online, provably robust, and scalable Bayesian approach for changepoint detection. The resulting algorithm has key advantages over previous work: it provides provable robustness by leveraging the generalised Bayesian perspective, and also addresses the scalability issues of previous attempts. Specifically, the proposed generalised Bayesian formalism leads to conjugate posteriors whose parameters are available in closed form by leveraging diffusion score matching. The resulting algorithm is exact, can be updated through simple algebra, and is more than 10 times faster than its closest competitor.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#35299;&#20915;&#39640;&#24230;&#31232;&#30095;&#24615;&#30340;&#32479;&#35745;&#23398;&#20064;&#31639;&#27861;&#65292;&#21363;&#21464;&#31995;&#25968;$\ell_1$&#24809;&#32602;&#30340;&#31232;&#30095;&#36125;&#21494;&#26031;Lasso&#65292;&#24182;&#36890;&#36807;&#23450;&#20041;&#21487;&#23398;&#20064;&#30340;&#24809;&#32602;&#26435;&#37325;$\lambda_p$&#21450;&#36229;&#20808;&#39564;&#30693;&#35782;&#26469;&#36798;&#21040;&#30446;&#30340;&#12290;</title><link>http://arxiv.org/abs/2211.05089</link><description>&lt;p&gt;
&#21464;&#31995;&#25968;$\ell_1$&#24809;&#32602;&#30340;&#31232;&#30095;&#36125;&#21494;&#26031;Lasso&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse Bayesian Lasso via a Variable-Coefficient $\ell_1$ Penalty. (arXiv:2211.05089v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.05089
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#35299;&#20915;&#39640;&#24230;&#31232;&#30095;&#24615;&#30340;&#32479;&#35745;&#23398;&#20064;&#31639;&#27861;&#65292;&#21363;&#21464;&#31995;&#25968;$\ell_1$&#24809;&#32602;&#30340;&#31232;&#30095;&#36125;&#21494;&#26031;Lasso&#65292;&#24182;&#36890;&#36807;&#23450;&#20041;&#21487;&#23398;&#20064;&#30340;&#24809;&#32602;&#26435;&#37325;$\lambda_p$&#21450;&#36229;&#20808;&#39564;&#30693;&#35782;&#26469;&#36798;&#21040;&#30446;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#32479;&#35745;&#23398;&#20064;&#31639;&#27861;&#20855;&#26377;&#24778;&#20154;&#30340;&#28789;&#27963;&#24615;&#65292;&#20294;&#35299;&#37322;&#24615;&#36739;&#24046;&#12290;&#31232;&#30095;&#24615;&#26159;&#19968;&#31181;&#21487;&#33021;&#30340;&#35299;&#20915;&#26041;&#26696;&#65306;&#36890;&#36807;&#20272;&#35745;&#35768;&#22810;&#21442;&#25968;&#20026;0&#65292;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#19981;&#20809;&#28369;&#30340;$\ell_1$&#24809;&#32602;&#26469;&#23454;&#29616;&#36825;&#19968;&#28857;&#12290;&#28982;&#32780;&#65292;&#24403;&#38656;&#35201;&#39640;&#24230;&#31232;&#30095;&#24615;&#26102;&#65292;$\ell_1$&#24809;&#32602;&#20250;&#24341;&#20837;&#26174;&#30528;&#30340;&#20559;&#24046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20445;&#30041;&#20102;$\ell_1$&#24809;&#32602;&#65292;&#20294;&#23450;&#20041;&#20102;&#21487;&#23398;&#20064;&#30340;&#24809;&#32602;&#26435;&#37325;$\lambda_p$&#24182;&#36171;&#20104;&#20102;&#36229;&#20808;&#39564;&#30693;&#35782;&#12290;&#25105;&#20204;&#39318;&#20808;&#30740;&#31350;&#20102;&#36825;&#20010;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#24320;&#21457;&#20102;&#19982;$\ell_1$&#33539;&#25968;&#30456;&#20851;&#30340;&#36817;&#31471;&#31639;&#23376;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#22312;&#24809;&#32602;&#20284;&#28982;&#30340;&#32972;&#26223;&#19979;&#30740;&#31350;&#20102;&#36825;&#20010;&#21464;&#31995;&#25968;$\ell_1$&#24809;&#32602;&#30340;&#29702;&#35770;&#24615;&#36136;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#23558;&#35813;&#24809;&#32602;&#24212;&#29992;&#20110;&#21464;&#20998;&#36125;&#21494;&#26031;&#30340;&#26041;&#27861;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#27169;&#22411;&#65292;&#31216;&#20026;&#31232;&#30095;&#36125;&#21494;&#26031;Lasso&#65292;&#20801;&#35768;&#34920;&#29616;&#20986;&#31867;&#20284;&#20110;Lasso&#22238;&#24402;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern statistical learning algorithms are capable of amazing flexibility, but struggle with interpretability. One possible solution is sparsity: making inference such that many of the parameters are estimated as being identically 0, which may be imposed through the use of nonsmooth penalties such as the $\ell_1$ penalty. However, the $\ell_1$ penalty introduces significant bias when high sparsity is desired. In this article, we retain the $\ell_1$ penalty, but define learnable penalty weights $\lambda_p$ endowed with hyperpriors. We start the article by investigating the optimization problem this poses, developing a proximal operator associated with the $\ell_1$ norm. We then study the theoretical properties of this variable-coefficient $\ell_1$ penalty in the context of penalized likelihood. Next, we investigate application of this penalty to Variational Bayes, developing a model we call the Sparse Bayesian Lasso which allows for behavior qualitatively like Lasso regression to be app
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36793;&#32536;&#20998;&#24067;&#30340;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#38750;&#21442;&#25968;&#28040;&#36153;&#32773;&#36873;&#25321;&#24314;&#27169;&#26041;&#27861;&#65292;&#22312;&#20219;&#20309;&#36873;&#25321;&#38598;&#21512;&#20013;&#20250;&#25226;&#36873;&#25321;&#27010;&#29575;&#30340;&#38598;&#21512;&#19968;&#33268;&#22320;&#25551;&#36848;&#20986;&#26469;&#12290;</title><link>http://arxiv.org/abs/2208.06115</link><description>&lt;p&gt;
&#22522;&#20110;&#36793;&#32536;&#20998;&#24067;&#30340;&#38750;&#21442;&#25968;&#28040;&#36153;&#32773;&#36873;&#25321;&#24314;&#27169;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Nonparametric Approach with Marginals for Modeling Consumer Choice. (arXiv:2208.06115v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.06115
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36793;&#32536;&#20998;&#24067;&#30340;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#38750;&#21442;&#25968;&#28040;&#36153;&#32773;&#36873;&#25321;&#24314;&#27169;&#26041;&#27861;&#65292;&#22312;&#20219;&#20309;&#36873;&#25321;&#38598;&#21512;&#20013;&#20250;&#25226;&#36873;&#25321;&#27010;&#29575;&#30340;&#38598;&#21512;&#19968;&#33268;&#22320;&#25551;&#36848;&#20986;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#28040;&#36153;&#32773;&#22312;&#19981;&#21516;&#36873;&#25321;&#38598;&#21512;&#20013;&#20316;&#20986;&#36873;&#25321;&#30340;&#25968;&#25454;&#65292;&#24320;&#21457;&#25551;&#36848;&#21644;&#39044;&#27979;&#28040;&#36153;&#32773;&#36873;&#25321;&#34892;&#20026;&#30340;&#31616;&#27905;&#27169;&#22411;&#26159;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#12290;&#20854;&#20013;&#19968;&#31181;&#36873;&#25321;&#27169;&#22411;&#26159;&#36793;&#32536;&#20998;&#24067;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20165;&#38656;&#35201;&#35268;&#23450;&#38543;&#26426;&#25928;&#29992;&#30340;&#36793;&#32536;&#20998;&#24067;&#21363;&#21487;&#35299;&#37322;&#36873;&#39033;&#25968;&#25454;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#31934;&#30830;&#30340;&#36873;&#25321;&#27010;&#29575;&#38598;&#21512;&#30340;&#29305;&#24449;&#21270;&#26041;&#27861;&#65292;&#35813;&#38598;&#21512;&#21487;&#20197;&#22312;&#20219;&#20309;&#38598;&#21512;&#20013;&#19968;&#33268;&#22320;&#36890;&#36807;&#36793;&#32536;&#20998;&#24067;&#27169;&#22411;&#26469;&#25551;&#36848;&#12290;&#20801;&#35768;&#26681;&#25454;&#20854;&#25928;&#29992;&#30340;&#36793;&#32536;&#20998;&#24067;&#23558;&#36873;&#25321;&#38598;&#21512;&#36827;&#34892;&#20998;&#32452;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;(a)&#39564;&#35777;&#36825;&#20010;&#27169;&#22411;&#19982;&#36873;&#25321;&#27010;&#29575;&#25968;&#25454;&#30340;&#19968;&#33268;&#24615;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#26159;&#21487;&#33021;&#30340;&#65292;(b)&#26368;&#25509;&#36817;&#25311;&#21512;&#30340;&#26041;&#27861;&#21487;&#20197;&#31616;&#21270;&#20026;&#35299;&#20915;&#28151;&#21512;&#25972;&#25968;&#20984;&#35268;&#21010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#22810;&#39033;&#24335;Logit&#27169;&#22411;&#21644;m&#30456;&#27604;&#65292;&#36793;&#32536;&#20998;&#24067;&#27169;&#22411;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#34920;&#29616;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given data on choices made by consumers for different assortments, a key challenge is to develop parsimonious models that describe and predict consumer choice behavior. One such choice model is the marginal distribution model which requires only the specification of the marginal distributions of the random utilities of the alternatives to explain choice data. In this paper, we develop an exact characterisation of the set of choice probabilities which are representable by the marginal distribution model consistently across any collection of assortments. Allowing for the possibility of alternatives to be grouped based on the marginal distribution of their utilities, we show (a) verifying consistency of choice probability data with this model is possible in polynomial time and (b) finding the closest fit reduces to solving a mixed integer convex program. Our results show that the marginal distribution model provides much better representational power as compared to multinomial logit and m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#23618;&#36125;&#21494;&#26031;&#24314;&#27169;&#26041;&#27861;&#65292;&#21033;&#29992;&#25805;&#20316;&#26426;&#32676;&#20013;&#30340;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#65292;&#22312;&#19981;&#21516;&#30340;&#23376;&#32676;&#20043;&#38388;&#33258;&#21160;&#22320;&#20849;&#20139;&#20449;&#24687;&#12290;&#35813;&#26041;&#27861;&#25104;&#21151;&#22320;&#35299;&#20915;&#20102;&#21345;&#36710;&#26426;&#32676;&#30340;&#29983;&#23384;&#20998;&#26512;&#21644;&#39118;&#30005;&#22330;&#30340;&#21151;&#29575;&#39044;&#27979;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2204.12404</link><description>&lt;p&gt;
&#20998;&#23618;&#36125;&#21494;&#26031;&#24314;&#27169;&#22312;&#24037;&#31243;&#26426;&#32676;&#38388;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#30340;&#30693;&#35782;&#36716;&#31227;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Hierarchical Bayesian Modelling for Knowledge Transfer Across Engineering Fleets via Multitask Learning. (arXiv:2204.12404v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.12404
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#23618;&#36125;&#21494;&#26031;&#24314;&#27169;&#26041;&#27861;&#65292;&#21033;&#29992;&#25805;&#20316;&#26426;&#32676;&#20013;&#30340;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#65292;&#22312;&#19981;&#21516;&#30340;&#23376;&#32676;&#20043;&#38388;&#33258;&#21160;&#22320;&#20849;&#20139;&#20449;&#24687;&#12290;&#35813;&#26041;&#27861;&#25104;&#21151;&#22320;&#35299;&#20915;&#20102;&#21345;&#36710;&#26426;&#32676;&#30340;&#29983;&#23384;&#20998;&#26512;&#21644;&#39118;&#30005;&#22330;&#30340;&#21151;&#29575;&#39044;&#27979;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32676;&#20307;&#32423;&#21035;&#20998;&#26512;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#24037;&#31243;&#22522;&#30784;&#35774;&#26045;&#39044;&#27979;&#24314;&#27169;&#20013;&#25968;&#25454;&#31232;&#30095;&#30340;&#38382;&#39064;&#12290;&#21033;&#29992;&#21487;&#35299;&#37322;&#30340;&#20998;&#23618;&#36125;&#21494;&#26031;&#26041;&#27861;&#21644;&#25805;&#20316;&#26426;&#32676;&#25968;&#25454;&#65292;&#33258;&#28982;&#22320;&#23558;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#32534;&#30721;&#65288;&#21644;&#36866;&#24403;&#20849;&#20139;&#65289;&#21040;&#19981;&#21516;&#23376;&#32676;&#20043;&#38388;&#65292;&#20998;&#21035;&#20195;&#34920;&#65288;i&#65289;&#20351;&#29992;&#31867;&#22411;&#65292;&#65288;ii&#65289;&#37096;&#20214;&#25110;&#65288;iii&#65289;&#36816;&#34892;&#26465;&#20214;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#36890;&#36807;&#20551;&#35774;&#65288;&#21644;&#20808;&#39564;&#20998;&#24067;&#65289;&#65292;&#21033;&#29992;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#26469;&#38480;&#21046;&#27169;&#22411;&#65292;&#20351;&#24471;&#26041;&#27861;&#33021;&#22815;&#33258;&#21160;&#22312;&#31867;&#20284;&#36164;&#20135;&#20043;&#38388;&#20849;&#20139;&#20449;&#24687;&#65292;&#20197;&#25913;&#21892;&#21345;&#36710;&#26426;&#32676;&#30340;&#29983;&#23384;&#20998;&#26512;&#21644;&#39118;&#30005;&#22330;&#30340;&#21151;&#29575;&#39044;&#27979;&#12290;&#22312;&#27599;&#20010;&#36164;&#20135;&#31649;&#29702;&#31034;&#20363;&#20013;&#65292;&#36890;&#36807;&#21512;&#24182;&#25512;&#29702;&#65292;&#22312;&#26426;&#32676;&#19978;&#23398;&#20064;&#19968;&#32452;&#30456;&#20851;&#20989;&#25968;&#65292;&#20197;&#23398;&#20064;&#32676;&#20307;&#27169;&#22411;&#12290;&#24403;&#23376;&#26426;&#32676;&#22312;&#23618;&#27425;&#32467;&#26500;&#30340;&#19981;&#21516;&#32423;&#21035;&#19978;&#20849;&#20139;&#30456;&#20851;&#20449;&#24687;&#26102;&#65292;&#21442;&#25968;&#20272;&#35745;&#24471;&#21040;&#25913;&#36827;&#12290;&#21453;&#36807;&#26469;&#65292;&#20855;&#26377;&#19981;&#23436;&#25972;&#25968;&#25454;&#30340;&#32676;&#20307;&#33258;&#21160;&#20511;&#29992;&#32479;&#35745;&#24378;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
A population-level analysis is proposed to address data sparsity when building predictive models for engineering infrastructure. Utilising an interpretable hierarchical Bayesian approach and operational fleet data, domain expertise is naturally encoded (and appropriately shared) between different sub-groups, representing (i) use-type, (ii) component, or (iii) operating condition. Specifically, domain expertise is exploited to constrain the model via assumptions (and prior distributions) allowing the methodology to automatically share information between similar assets, improving the survival analysis of a truck fleet and power prediction in a wind farm. In each asset management example, a set of correlated functions is learnt over the fleet, in a combined inference, to learn a population model. Parameter estimation is improved when sub-fleets share correlated information at different levels of the hierarchy. In turn, groups with incomplete data automatically borrow statistical strength
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;Transformer&#22312;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#20013;&#30340;&#24212;&#29992;&#36827;&#34892;&#20102;&#31995;&#32479;&#22238;&#39038;&#65292;&#24635;&#32467;&#20102;&#20854;&#20248;&#28857;&#21450;&#23616;&#38480;&#24615;&#65292;&#20174;&#32593;&#32476;&#32467;&#26500;&#21644;&#24212;&#29992;&#20004;&#20010;&#35282;&#24230;&#23457;&#35270;&#20102;&#20854;&#36866;&#24212;&#21644;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2202.07125</link><description>&lt;p&gt;
Transformer&#22312;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#24212;&#29992;&#27010;&#36848;
&lt;/p&gt;
&lt;p&gt;
Transformers in Time Series: A Survey. (arXiv:2202.07125v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.07125
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;Transformer&#22312;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#20013;&#30340;&#24212;&#29992;&#36827;&#34892;&#20102;&#31995;&#32479;&#22238;&#39038;&#65292;&#24635;&#32467;&#20102;&#20854;&#20248;&#28857;&#21450;&#23616;&#38480;&#24615;&#65292;&#20174;&#32593;&#32476;&#32467;&#26500;&#21644;&#24212;&#29992;&#20004;&#20010;&#35282;&#24230;&#23457;&#35270;&#20102;&#20854;&#36866;&#24212;&#21644;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#35745;&#31639;&#26426;&#35270;&#35273;&#20013;&#24050;&#32463;&#21462;&#24471;&#20102;&#20248;&#36234;&#30340;&#24615;&#33021;&#65292;&#20063;&#24341;&#36215;&#20102;&#26102;&#38388;&#24207;&#21015;&#31038;&#21306;&#30340;&#26497;&#22823;&#20852;&#36259;&#12290;Transformer&#30340;&#22810;&#20010;&#20248;&#21183;&#20043;&#19968;&#26159;&#33021;&#22815;&#25429;&#25417;&#38271;&#31243;&#20381;&#36182;&#21644;&#30456;&#20114;&#20316;&#29992;&#65292;&#29305;&#21035;&#36866;&#21512;&#20110;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#65292;&#26497;&#22823;&#22320;&#25512;&#21160;&#20102;&#26102;&#38388;&#24207;&#21015;&#24212;&#29992;&#30340;&#21457;&#23637;&#12290;&#26412;&#25991;&#31995;&#32479;&#22320;&#22238;&#39038;&#20102;Transformer&#22312;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#24378;&#35843;&#20102;&#20854;&#20248;&#28857;&#21450;&#23616;&#38480;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20174;&#32593;&#32476;&#32467;&#26500;&#21644;&#24212;&#29992;&#20004;&#20010;&#23618;&#38754;&#23457;&#35270;&#20102;Transformer&#22312;&#26102;&#38388;&#24207;&#21015;&#19978;&#30340;&#36866;&#24212;&#21644;&#25913;&#36827;&#12290;&#20174;&#32593;&#32476;&#32467;&#26500;&#30340;&#35282;&#24230;&#65292;&#25105;&#20204;&#24635;&#32467;&#20102;&#20026;&#20102;&#36866;&#24212;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#20013;&#30340;&#25361;&#25112;&#32780;&#20570;&#20986;&#30340;&#25913;&#21464;&#21644;&#35843;&#25972;&#12290;&#20174;&#24212;&#29992;&#30340;&#35282;&#24230;&#65292;&#25105;&#20204;&#26681;&#25454;&#24120;&#35265;&#20219;&#21153;&#65288;&#21253;&#25324;&#39044;&#27979;&#12289;&#24322;&#24120;&#26816;&#27979;&#21644;&#20998;&#31867;&#65289;&#23545;&#26102;&#38388;&#24207;&#21015;Transformer&#36827;&#34892;&#20102;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformers have achieved superior performances in many tasks in natural language processing and computer vision, which also triggered great interest in the time series community. Among multiple advantages of Transformers, the ability to capture long-range dependencies and interactions is especially attractive for time series modeling, leading to exciting progress in various time series applications. In this paper, we systematically review Transformer schemes for time series modeling by highlighting their strengths as well as limitations. In particular, we examine the development of time series Transformers in two perspectives. From the perspective of network structure, we summarize the adaptations and modifications that have been made to Transformers in order to accommodate the challenges in time series analysis. From the perspective of applications, we categorize time series Transformers based on common tasks including forecasting, anomaly detection, and classification. Empirically,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#28145;&#24230;&#21069;&#39304;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#21442;&#25968;&#21487;&#36776;&#35782;&#24615;&#65292;&#32473;&#20986;&#20102;&#19968;&#32452;&#21051;&#30011;&#26465;&#20214;&#24182;&#35777;&#26126;&#20102;&#22312;&#36825;&#20123;&#26465;&#20214;&#19979;&#65292;&#21487;&#20197;&#21807;&#19968;&#30830;&#23450;&#32593;&#32476;&#30340;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/2112.12982</link><description>&lt;p&gt;
&#28145;&#24230;&#21069;&#39304;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#21442;&#25968;&#21487;&#36776;&#35782;&#24615;
&lt;/p&gt;
&lt;p&gt;
Parameter identifiability of a deep feedforward ReLU neural network. (arXiv:2112.12982v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.12982
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#28145;&#24230;&#21069;&#39304;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#21442;&#25968;&#21487;&#36776;&#35782;&#24615;&#65292;&#32473;&#20986;&#20102;&#19968;&#32452;&#21051;&#30011;&#26465;&#20214;&#24182;&#35777;&#26126;&#20102;&#22312;&#36825;&#20123;&#26465;&#20214;&#19979;&#65292;&#21487;&#20197;&#21807;&#19968;&#30830;&#23450;&#32593;&#32476;&#30340;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19968;&#20123;&#24773;&#20917;&#19979;&#65292;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#22312;&#36755;&#20837;&#30340;&#19968;&#20010;&#23376;&#38598;&#19978;&#30340;&#20989;&#25968;&#20540;&#21487;&#20197;&#24674;&#22797;&#31070;&#32463;&#32593;&#32476;&#30340;&#21442;&#25968;&#26435;&#37325;&#21644;&#20559;&#32622;&#65292;&#36825;&#26082;&#21487;&#20197;&#26159;&#19968;&#20010;&#35781;&#21650;&#20063;&#21487;&#20197;&#26159;&#19968;&#20010;&#31119;&#38899;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#28145;&#24230;&#20840;&#36830;&#25509;&#21069;&#39304;ReLU&#31070;&#32463;&#32593;&#32476;&#65292;&#25552;&#20986;&#20102;&#19968;&#32452;&#26465;&#20214;&#26469;&#21051;&#30011;&#20854;&#21442;&#25968;&#21487;&#36776;&#35782;&#24615;&#30340;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#36825;&#20123;&#26465;&#20214;&#19979;&#65292;&#21487;&#20197;&#21807;&#19968;&#30830;&#23450;&#32593;&#32476;&#30340;&#21442;&#25968;-&#27169;&#38500;&#32622;&#25442;&#21644;&#27491;&#30340;&#32553;&#25918;&#12290;
&lt;/p&gt;
&lt;p&gt;
The possibility for one to recover the parameters-weights and biases-of a neural network thanks to the knowledge of its function on a subset of the input space can be, depending on the situation, a curse or a blessing. On one hand, recovering the parameters allows for better adversarial attacks and could also disclose sensitive information from the dataset used to construct the network. On the other hand, if the parameters of a network can be recovered, it guarantees the user that the features in the latent spaces can be interpreted. It also provides foundations to obtain formal guarantees on the performances of the network. It is therefore important to characterize the networks whose parameters can be identified and those whose parameters cannot. In this article, we provide a set of conditions on a deep fully-connected feedforward ReLU neural network under which the parameters of the network are uniquely identified-modulo permutation and positive rescaling-from the function it impleme
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#22312;&#26080;&#38480;&#19981;&#24179;&#34913;&#24773;&#20917;&#19979;&#30340;&#32447;&#24615;&#20998;&#31867;&#22120;&#65292;&#36890;&#36807;&#26435;&#37325;&#20989;&#25968;&#25351;&#23450;&#30340;&#32463;&#39564;&#25439;&#22833;&#26368;&#23567;&#21270;&#31995;&#25968;&#12290;&#25130;&#36317;&#21457;&#25955;&#20294;&#20854;&#20313;&#31995;&#25968;&#21521;&#37327;&#26377;&#19968;&#20010;&#26377;&#38480;&#30340;&#20960;&#20046;&#32943;&#23450;&#30340;&#26497;&#38480;&#65292;&#26497;&#38480;&#20381;&#36182;&#20110;&#26435;&#37325;&#20989;&#25968;&#30340;&#24038;&#23614;&#22686;&#38271;&#36895;&#29575;&#12290;&#26497;&#38480;&#31995;&#25968;&#21521;&#37327;&#21453;&#26144;&#31283;&#20581;&#24615;&#25110;&#20445;&#23432;&#24615;&#23646;&#24615;&#65292;&#32780;&#22312;&#20122;&#25351;&#25968;&#24773;&#20917;&#19979;&#65292;&#26497;&#38480;&#31561;&#20215;&#20110;&#23569;&#25968;&#31867;&#30340;&#19978;&#37319;&#26679;&#20998;&#24067;&#30340;&#38544;&#24335;&#36873;&#25321;&#12290;</title><link>http://arxiv.org/abs/2106.05797</link><description>&lt;p&gt;
&#26080;&#38480;&#19981;&#24179;&#34913;&#19979;&#30340;&#32447;&#24615;&#20998;&#31867;&#22120;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Linear Classifiers Under Infinite Imbalance. (arXiv:2106.05797v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.05797
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#22312;&#26080;&#38480;&#19981;&#24179;&#34913;&#24773;&#20917;&#19979;&#30340;&#32447;&#24615;&#20998;&#31867;&#22120;&#65292;&#36890;&#36807;&#26435;&#37325;&#20989;&#25968;&#25351;&#23450;&#30340;&#32463;&#39564;&#25439;&#22833;&#26368;&#23567;&#21270;&#31995;&#25968;&#12290;&#25130;&#36317;&#21457;&#25955;&#20294;&#20854;&#20313;&#31995;&#25968;&#21521;&#37327;&#26377;&#19968;&#20010;&#26377;&#38480;&#30340;&#20960;&#20046;&#32943;&#23450;&#30340;&#26497;&#38480;&#65292;&#26497;&#38480;&#20381;&#36182;&#20110;&#26435;&#37325;&#20989;&#25968;&#30340;&#24038;&#23614;&#22686;&#38271;&#36895;&#29575;&#12290;&#26497;&#38480;&#31995;&#25968;&#21521;&#37327;&#21453;&#26144;&#31283;&#20581;&#24615;&#25110;&#20445;&#23432;&#24615;&#23646;&#24615;&#65292;&#32780;&#22312;&#20122;&#25351;&#25968;&#24773;&#20917;&#19979;&#65292;&#26497;&#38480;&#31561;&#20215;&#20110;&#23569;&#25968;&#31867;&#30340;&#19978;&#37319;&#26679;&#20998;&#24067;&#30340;&#38544;&#24335;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#19968;&#20010;&#31867;&#21035;&#30340;&#26679;&#26412;&#25968;&#37327;&#22686;&#38271;&#21040;&#26080;&#31351;&#22823;&#32780;&#21478;&#19968;&#20010;&#31867;&#21035;&#30340;&#26679;&#26412;&#25968;&#37327;&#20445;&#25345;&#19981;&#21464;&#30340;&#24773;&#20917;&#19979;&#65292;&#20108;&#20803;&#20998;&#31867;&#20013;&#30340;&#32447;&#24615;&#21028;&#21035;&#20989;&#25968;&#30340;&#34892;&#20026;&#12290;&#20998;&#31867;&#22120;&#30340;&#31995;&#25968;&#36890;&#36807;&#19968;&#20010;&#26435;&#37325;&#20989;&#25968;&#25351;&#23450;&#30340;&#32463;&#39564;&#25439;&#22833;&#26368;&#23567;&#21270;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#65292;&#23545;&#20110;&#24191;&#27867;&#30340;&#26435;&#37325;&#20989;&#25968;&#31867;&#65292;&#25130;&#36317;&#21457;&#25955;&#20294;&#20854;&#20313;&#31995;&#25968;&#21521;&#37327;&#22312;&#26080;&#31351;&#19981;&#24179;&#34913;&#24773;&#20917;&#19979;&#20855;&#26377;&#19968;&#20010;&#26377;&#38480;&#30340;&#20960;&#20046;&#32943;&#23450;&#30340;&#26497;&#38480;&#65292;&#36825;&#25193;&#23637;&#20102;&#20043;&#21069;&#23545;&#36923;&#36753;&#22238;&#24402;&#30340;&#30740;&#31350;&#12290;&#26497;&#38480;&#20381;&#36182;&#20110;&#26435;&#37325;&#20989;&#25968;&#30340;&#24038;&#23614;&#22686;&#38271;&#36895;&#29575;&#65292;&#23545;&#27492;&#25105;&#20204;&#21306;&#20998;&#20102;&#20004;&#31181;&#24773;&#20917;&#65306;&#20122;&#25351;&#25968;&#21644;&#25351;&#25968;&#12290;&#26497;&#38480;&#31995;&#25968;&#21521;&#37327;&#21453;&#26144;&#20102;&#31283;&#20581;&#24615;&#25110;&#20445;&#23432;&#24615;&#23646;&#24615;&#65292;&#22240;&#20026;&#23427;&#20204;&#20248;&#21270;&#20102;&#26576;&#20123;&#26368;&#22351;&#24773;&#20917;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;&#22312;&#20122;&#25351;&#25968;&#24773;&#20917;&#19979;&#65292;&#26497;&#38480;&#31561;&#20215;&#20110;&#23569;&#25968;&#31867;&#30340;&#19978;&#37319;&#26679;&#20998;&#24067;&#30340;&#38544;&#24335;&#36873;&#25321;&#12290;&#25105;&#20204;&#22312;&#20449;&#29992;&#39118;&#38505;&#35774;&#32622;&#20013;&#24212;&#29992;&#20102;&#36825;&#20123;&#24605;&#24819;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the behavior of linear discriminant functions for binary classification in the infinite-imbalance limit, where the sample size of one class grows without bound while the sample size of the other remains fixed. The coefficients of the classifier minimize an empirical loss specified through a weight function. We show that for a broad class of weight functions, the intercept diverges but the rest of the coefficient vector has a finite almost sure limit under infinite imbalance, extending prior work on logistic regression. The limit depends on the left-tail growth rate of the weight function, for which we distinguish two cases: subexponential and exponential. The limiting coefficient vectors reflect robustness or conservatism properties in the sense that they optimize against certain worst-case alternatives. In the subexponential case, the limit is equivalent to an implicit choice of upsampling distribution for the minority class. We apply these ideas in a credit risk setting, wit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#28145;&#24230;&#22238;&#24402;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#21464;&#37327;&#35823;&#24046;&#27169;&#22411;&#32771;&#34385;&#25152;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20837;&#25152;&#20851;&#32852;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#23558;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#20998;&#35299;&#20026;&#38543;&#26426;&#21644;&#35748;&#35782;&#37096;&#20998;&#12290;&#30456;&#27604;&#20110;&#19981;&#20351;&#29992;&#35813;&#27169;&#22411;&#65292;&#20351;&#29992;&#38169;&#35823;&#21464;&#37327;&#27169;&#22411;&#33021;&#22815;&#25552;&#39640;&#23545;&#24050;&#30693;&#22238;&#24402;&#20989;&#25968;&#30340;&#35206;&#30422;&#29575;&#65292;&#19988;&#20445;&#25345;&#39044;&#27979;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2105.09095</link><description>&lt;p&gt;
&#28145;&#24230;&#22238;&#24402;&#20013;&#30340;&#21464;&#37327;&#35823;&#24046;&#27169;&#22411;&#30340;&#38543;&#26426;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Aleatoric uncertainty for Errors-in-Variables models in deep regression. (arXiv:2105.09095v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.09095
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#28145;&#24230;&#22238;&#24402;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#21464;&#37327;&#35823;&#24046;&#27169;&#22411;&#32771;&#34385;&#25152;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20837;&#25152;&#20851;&#32852;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#23558;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#20998;&#35299;&#20026;&#38543;&#26426;&#21644;&#35748;&#35782;&#37096;&#20998;&#12290;&#30456;&#27604;&#20110;&#19981;&#20351;&#29992;&#35813;&#27169;&#22411;&#65292;&#20351;&#29992;&#38169;&#35823;&#21464;&#37327;&#27169;&#22411;&#33021;&#22815;&#25552;&#39640;&#23545;&#24050;&#30693;&#22238;&#24402;&#20989;&#25968;&#30340;&#35206;&#30422;&#29575;&#65292;&#19988;&#20445;&#25345;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#36125;&#21494;&#26031;&#22788;&#29702;&#21487;&#20197;&#35745;&#31639;&#19982;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#30456;&#20851;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#36125;&#21494;&#26031;&#28145;&#24230;&#22238;&#24402;&#20013;&#20351;&#29992;&#21464;&#37327;&#35823;&#24046;&#30340;&#27010;&#24565;&#65292;&#20197;&#32771;&#34385;&#25152;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20837;&#25152;&#20851;&#32852;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21033;&#29992;&#20102;&#19968;&#20010;&#30456;&#20851;&#20294;&#36890;&#24120;&#34987;&#24573;&#35270;&#30340;&#19981;&#30830;&#23450;&#24615;&#28304;&#65292;&#24182;&#23558;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#20998;&#35299;&#20026;&#38543;&#26426;&#21644;&#35748;&#35782;&#37096;&#20998;&#65292;&#36825;&#22312;&#32479;&#35745;&#23398;&#35282;&#24230;&#26356;&#23436;&#25972;&#65292;&#32780;&#19988;&#22312;&#24456;&#22810;&#24773;&#20917;&#19979;&#26356;&#19968;&#33268;&#12290;&#25105;&#20204;&#36890;&#36807;&#21508;&#31181;&#27169;&#25311;&#21644;&#30495;&#23454;&#30340;&#20363;&#23376;&#35752;&#35770;&#20102;&#36825;&#31181;&#26041;&#27861;&#65292;&#24182;&#35266;&#23519;&#21040;&#20351;&#29992;&#21464;&#37327;&#35823;&#24046;&#27169;&#22411;&#20250;&#22686;&#21152;&#19981;&#30830;&#23450;&#24615;&#65292;&#21516;&#26102;&#20445;&#25345;&#19981;&#20351;&#29992;&#21464;&#37327;&#35823;&#24046;&#27169;&#22411;&#30340;&#27169;&#22411;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#23545;&#20110;&#24050;&#30693;&#22238;&#24402;&#20989;&#25968;&#30340;&#20363;&#23376;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#21464;&#37327;&#35823;&#24046;&#27169;&#22411;&#22823;&#22823;&#25552;&#39640;&#20102;&#23545;&#22522;&#30784;&#20107;&#23454;&#30340;&#35206;&#30422;&#65292;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#22238;&#24402;&#38382;&#39064;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Bayesian treatment of deep learning allows for the computation of uncertainties associated with the predictions of deep neural networks. We show how the concept of Errors-in-Variables can be used in Bayesian deep regression to also account for the uncertainty associated with the input of the employed neural network. The presented approach thereby exploits a relevant, but generally overlooked, source of uncertainty and yields a decomposition of the predictive uncertainty into an aleatoric and epistemic part that is more complete and, in many cases, more consistent from a statistical perspective. We discuss the approach along various simulated and real examples and observe that using an Errors-in-Variables model leads to an increase in the uncertainty while preserving the prediction performance of models without Errors-in-Variables. For examples with known regression function we observe that this ground truth is substantially better covered by the Errors-in-Variables model, indicating 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#19981;&#30830;&#23450;&#24615;&#23545;&#19981;&#21516;&#20154;&#32676;&#30340;&#24433;&#21709;&#26159;&#19981;&#24179;&#31561;&#30340;&#65292;&#34429;&#28982;&#23427;&#20250;&#22312;&#25152;&#26377;&#20154;&#21475;&#32676;&#20307;&#20013;&#20135;&#29983;&#35823;&#24046;&#65292;&#20294;&#35823;&#24046;&#30340;&#31867;&#22411;&#20250;&#26377;&#31995;&#32479;&#24615;&#30340;&#21464;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#24179;&#26435;&#20449;&#24687;&#30340;&#31574;&#30053;&#65292;&#21487;&#20197;&#28040;&#38500;&#36825;&#31181;&#24046;&#24322;&#24182;&#25193;&#22823;&#26426;&#20250;&#30340;&#33719;&#21462;&#65292;&#36825;&#21487;&#20197;&#20316;&#20026;&#24179;&#26435;&#34892;&#21160;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2102.10019</link><description>&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#30340;&#19981;&#24179;&#31561;&#24433;&#21709;&#65306;&#24179;&#26435;&#34892;&#21160;&#19982;&#24179;&#26435;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
The Disparate Impact of Uncertainty: Affirmative Action vs. Affirmative Information. (arXiv:2102.10019v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.10019
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#19981;&#30830;&#23450;&#24615;&#23545;&#19981;&#21516;&#20154;&#32676;&#30340;&#24433;&#21709;&#26159;&#19981;&#24179;&#31561;&#30340;&#65292;&#34429;&#28982;&#23427;&#20250;&#22312;&#25152;&#26377;&#20154;&#21475;&#32676;&#20307;&#20013;&#20135;&#29983;&#35823;&#24046;&#65292;&#20294;&#35823;&#24046;&#30340;&#31867;&#22411;&#20250;&#26377;&#31995;&#32479;&#24615;&#30340;&#21464;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#24179;&#26435;&#20449;&#24687;&#30340;&#31574;&#30053;&#65292;&#21487;&#20197;&#28040;&#38500;&#36825;&#31181;&#24046;&#24322;&#24182;&#25193;&#22823;&#26426;&#20250;&#30340;&#33719;&#21462;&#65292;&#36825;&#21487;&#20197;&#20316;&#20026;&#24179;&#26435;&#34892;&#21160;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proves that uncertainty has a disparate impact on different demographic groups, with varying types of errors. The proposed strategy, called Affirmative Information, can eliminate this disparity and broaden access to opportunity, serving as an alternative to Affirmative Action.
&lt;/p&gt;
&lt;p&gt;
&#20687;&#36151;&#27454;&#25209;&#20934;&#12289;&#21307;&#30103;&#24178;&#39044;&#21644;&#22823;&#23398;&#24405;&#21462;&#36825;&#26679;&#30340;&#20851;&#38190;&#20915;&#31574;&#26159;&#22312;&#23384;&#22312;&#19981;&#30830;&#23450;&#24615;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#39044;&#27979;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19981;&#30830;&#23450;&#24615;&#20855;&#26377;&#19981;&#24179;&#31561;&#30340;&#24433;&#21709;&#12290;&#34429;&#28982;&#23427;&#20250;&#22312;&#25152;&#26377;&#20154;&#21475;&#32676;&#20307;&#20013;&#20135;&#29983;&#35823;&#24046;&#65292;&#20294;&#35823;&#24046;&#30340;&#31867;&#22411;&#20250;&#26377;&#31995;&#32479;&#24615;&#30340;&#21464;&#21270;&#65306;&#24179;&#22343;&#32467;&#26524;&#36739;&#39640;&#30340;&#32676;&#20307;&#36890;&#24120;&#34987;&#20998;&#37197;&#26356;&#39640;&#30340;&#20551;&#38451;&#24615;&#29575;&#65292;&#32780;&#24179;&#22343;&#32467;&#26524;&#36739;&#20302;&#30340;&#32676;&#20307;&#21017;&#34987;&#20998;&#37197;&#26356;&#39640;&#30340;&#20551;&#38452;&#24615;&#29575;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#39069;&#22806;&#30340;&#25968;&#25454;&#33719;&#21462;&#21487;&#20197;&#28040;&#38500;&#36825;&#31181;&#24046;&#24322;&#24182;&#25193;&#22823;&#26426;&#20250;&#30340;&#33719;&#21462;&#12290;&#25105;&#20204;&#31216;&#20043;&#20026;&#24179;&#26435;&#20449;&#24687;&#30340;&#31574;&#30053;&#21487;&#20197;&#20316;&#20026;&#24179;&#26435;&#34892;&#21160;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Critical decisions like loan approvals, medical interventions, and college admissions are guided by predictions made in the presence of uncertainty. In this paper, we prove that uncertainty has a disparate impact. While it imparts errors across all demographic groups, the types of errors vary systematically: Groups with higher average outcomes are typically assigned higher false positive rates, while those with lower average outcomes are assigned higher false negative rates. We show that additional data acquisition can eliminate the disparity and broaden access to opportunity. The strategy, which we call Affirmative Information, could stand as an alternative to Affirmative Action.
&lt;/p&gt;</description></item></channel></rss>