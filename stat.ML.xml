<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#22312;&#21482;&#26377;&#24102;&#26631;&#31614;&#30340;&#21333;&#27169;&#24577;&#25968;&#25454;&#21644;&#33258;&#28982;&#20986;&#29616;&#30340;&#22810;&#27169;&#24577;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#22914;&#20309;&#37327;&#21270;&#22810;&#27169;&#24577;&#20132;&#20114;&#30340;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#19979;&#30028;&#21644;&#19968;&#20010;&#19978;&#30028;&#26469;&#37327;&#21270;&#22810;&#27169;&#24577;&#20132;&#20114;&#37327;&#12290;</title><link>http://arxiv.org/abs/2306.04539</link><description>&lt;p&gt;
&#26080;&#26631;&#35760;&#22810;&#27169;&#24577;&#25968;&#25454;&#30340;&#22810;&#27169;&#24577;&#23398;&#20064;&#65306;&#20445;&#35777;&#21644;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Multimodal Learning Without Labeled Multimodal Data: Guarantees and Applications. (arXiv:2306.04539v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04539
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22312;&#21482;&#26377;&#24102;&#26631;&#31614;&#30340;&#21333;&#27169;&#24577;&#25968;&#25454;&#21644;&#33258;&#28982;&#20986;&#29616;&#30340;&#22810;&#27169;&#24577;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#22914;&#20309;&#37327;&#21270;&#22810;&#27169;&#24577;&#20132;&#20114;&#30340;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#19979;&#30028;&#21644;&#19968;&#20010;&#19978;&#30028;&#26469;&#37327;&#21270;&#22810;&#27169;&#24577;&#20132;&#20114;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#20849;&#21516;&#23398;&#20064;&#22810;&#20010;&#27169;&#24577;&#30340;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#20013;&#65292;&#19968;&#20010;&#26680;&#24515;&#30340;&#30740;&#31350;&#38382;&#39064;&#26159;&#29702;&#35299;&#22810;&#27169;&#24577;&#20132;&#20114;&#30340;&#26412;&#36136;&#65306;&#22312;&#20174;&#20004;&#20010;&#37117;&#27809;&#26377;&#30340;&#27169;&#24577;&#23398;&#20064;&#26102;&#20986;&#29616;&#20102;&#26032;&#30340;&#20219;&#21153;&#30456;&#20851;&#20449;&#24687;&#12290;&#25105;&#20204;&#22312;&#21322;&#30417;&#30563;&#30340;&#24773;&#20917;&#19979;&#30740;&#31350;&#36825;&#19968;&#20132;&#20114;&#37327;&#21270;&#30340;&#25361;&#25112;&#65292;&#21482;&#20351;&#29992;&#24102;&#26631;&#31614;&#30340;&#21333;&#27169;&#24577;&#25968;&#25454;&#21644;&#33258;&#28982;&#20986;&#29616;&#30340;&#22810;&#27169;&#24577;&#25968;&#25454;&#65288;&#20363;&#22914;&#65292;&#26080;&#26631;&#31614;&#30340;&#22270;&#20687;&#21644;&#26631;&#39064;&#65292;&#35270;&#39057;&#21644;&#30456;&#24212;&#30340;&#38899;&#39057;&#65289;&#12290;&#21033;&#29992;&#31934;&#30830;&#30340;&#20449;&#24687;&#35770;&#20132;&#20114;&#23450;&#20041;&#65292;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#25512;&#23548;&#19979;&#30028;&#21644;&#19978;&#30028;&#65292;&#37327;&#21270;&#36825;&#31181;&#21322;&#30417;&#30563;&#35774;&#32622;&#19979;&#30340;&#22810;&#27169;&#24577;&#20132;&#20114;&#37327;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#27169;&#24577;&#20849;&#20139;&#20449;&#24687;&#37327;&#21644;&#21333;&#29420;&#35757;&#32451;&#30340;&#21333;&#27169;&#24577;&#20998;&#31867;&#22120;&#20043;&#38388;&#30340;&#19981;&#19968;&#33268;&#24615;&#30340;&#20004;&#20010;&#19979;&#30028;&#65292;&#24182;&#36890;&#36807;&#36830;&#25509;&#21040;&#36817;&#20284;&#31639;&#27861;&#26469;&#25512;&#23548;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many machine learning systems that jointly learn from multiple modalities, a core research question is to understand the nature of multimodal interactions: the emergence of new task-relevant information during learning from both modalities that was not present in either alone. We study this challenge of interaction quantification in a semi-supervised setting with only labeled unimodal data and naturally co-occurring multimodal data (e.g., unlabeled images and captions, video and corresponding audio) but when labeling them is time-consuming. Using a precise information-theoretic definition of interactions, our key contributions are the derivations of lower and upper bounds to quantify the amount of multimodal interactions in this semi-supervised setting. We propose two lower bounds based on the amount of shared information between modalities and the disagreement between separately trained unimodal classifiers, and derive an upper bound through connections to approximate algorithms fo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;&#38543;&#26426;&#25237;&#24433;&#25216;&#26415;&#20248;&#21270;&#20102;Koopman&#31639;&#23376;&#30340;&#20272;&#35745;&#22120;&#65292;&#21152;&#24555;&#20102;&#35745;&#31639;&#36895;&#24230;&#65292;&#24182;&#32473;&#20986;&#20102;&#31934;&#30830;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#25552;&#39640;&#20102;&#31639;&#27861;&#30340;&#21487;&#38752;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.04520</link><description>&lt;p&gt;
&#21033;&#29992;&#33609;&#22270;&#25216;&#26415;&#20272;&#35745;Koopman&#31639;&#23376;&#24182;&#21487;&#38752;&#22320;&#23398;&#20064;&#22823;&#35268;&#27169;&#21160;&#24577;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Estimating Koopman operators with sketching to provably learn large scale dynamical systems. (arXiv:2306.04520v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04520
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;&#38543;&#26426;&#25237;&#24433;&#25216;&#26415;&#20248;&#21270;&#20102;Koopman&#31639;&#23376;&#30340;&#20272;&#35745;&#22120;&#65292;&#21152;&#24555;&#20102;&#35745;&#31639;&#36895;&#24230;&#65292;&#24182;&#32473;&#20986;&#20102;&#31934;&#30830;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#25552;&#39640;&#20102;&#31639;&#27861;&#30340;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Koopman&#31639;&#23376;&#29702;&#35770;&#20801;&#35768;&#20351;&#29992;&#38750;&#21442;&#25968;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#26469;&#39044;&#27979;&#21644;&#20998;&#26512;&#22797;&#26434;&#30340;&#21160;&#24577;&#31995;&#32479;&#12290;&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;&#38543;&#26426;&#25237;&#24433;&#65288;&#33609;&#22270;&#25216;&#26415;&#65289;&#25552;&#39640;&#22522;&#20110;&#26680;&#30340;Koopman&#31639;&#23376;&#20272;&#35745;&#22120;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#22823;&#35268;&#27169;&#20998;&#23376;&#21160;&#21147;&#23398;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#23454;&#39564;&#65292;&#24182;&#24314;&#31435;&#20102;&#38750;&#28176;&#36827;&#35823;&#24046;&#30028;&#65292;&#32473;&#20986;&#20102;&#32479;&#35745;&#23398;&#20064;&#36895;&#29575;&#21644;&#35745;&#31639;&#25928;&#29575;&#20043;&#38388;&#30340;&#26435;&#34913;&#30340;&#31934;&#30830;&#21051;&#30011;&#12290;&#25105;&#20204;&#30340;&#32463;&#39564;&#21644;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#32463;&#36807;&#25913;&#36827;&#30340;&#20272;&#35745;&#22120;&#22312;&#20445;&#35777;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#22823;&#22823;&#25552;&#39640;&#20102;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
The theory of Koopman operators allows to deploy non-parametric machine learning algorithms to predict and analyze complex dynamical systems. Estimators such as principal component regression (PCR) or reduced rank regression (RRR) in kernel spaces can be shown to provably learn Koopman operators from finite empirical observations of the system's time evolution. Scaling these approaches to very long trajectories is a challenge and requires introducing suitable approximations to make computations feasible. In this paper, we boost the efficiency of different kernel-based Koopman operator estimators using random projections (sketching). We derive, implement and test the new "sketched" estimators with extensive experiments on synthetic and large-scale molecular dynamics datasets. Further, we establish non asymptotic error bounds giving a sharp characterization of the trade-offs between statistical learning rates and computational efficiency. Our empirical and theoretical analysis shows that
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ProjUnit&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#23454;&#29616;&#39640;&#25928;&#30340;&#26412;&#22320;&#38544;&#31169;&#22343;&#20540;&#20272;&#35745;&#65292;&#36890;&#36807;&#38543;&#26426;&#25237;&#24433;&#20302;&#32500;&#31354;&#38388;&#23454;&#29616;&#26368;&#20248;&#35299;&#65292;&#19988;&#20855;&#26377;&#20302;&#36890;&#20449;&#22797;&#26434;&#24230;&#21644;&#24555;&#36895;&#30340;&#26381;&#21153;&#22120;&#36816;&#34892;&#26102;&#38388;&#12290;</title><link>http://arxiv.org/abs/2306.04444</link><description>&lt;p&gt;
&#36890;&#36807;&#38543;&#26426;&#25237;&#24433;&#24555;&#36895;&#33719;&#24471;&#26368;&#20248;&#30340;&#26412;&#22320;&#38544;&#31169;&#22343;&#20540;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Fast Optimal Locally Private Mean Estimation via Random Projections. (arXiv:2306.04444v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04444
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ProjUnit&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#23454;&#29616;&#39640;&#25928;&#30340;&#26412;&#22320;&#38544;&#31169;&#22343;&#20540;&#20272;&#35745;&#65292;&#36890;&#36807;&#38543;&#26426;&#25237;&#24433;&#20302;&#32500;&#31354;&#38388;&#23454;&#29616;&#26368;&#20248;&#35299;&#65292;&#19988;&#20855;&#26377;&#20302;&#36890;&#20449;&#22797;&#26434;&#24230;&#21644;&#24555;&#36895;&#30340;&#26381;&#21153;&#22120;&#36816;&#34892;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#39640;&#32500;&#21521;&#37327;&#30340;&#26412;&#22320;&#38544;&#31169;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#12290;&#29616;&#26377;&#31639;&#27861;&#35201;&#20040;&#20135;&#29983;&#27425;&#20248;&#35823;&#24046;&#65292;&#35201;&#20040;&#20855;&#26377;&#39640;&#36890;&#20449;&#21644;/&#25110;&#36816;&#34892;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#26694;&#26550;ProjUnit&#65292;&#29992;&#20110;&#38544;&#31169;&#22343;&#20540;&#20272;&#35745;&#30340;&#31639;&#27861;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#39640;&#12289;&#36890;&#20449;&#22797;&#26434;&#24230;&#20302;&#19988;&#35823;&#24046;&#19982;&#26368;&#20248;&#35299;&#20043;&#38388;&#30340;&#24046;&#36317;&#26368;&#22823;&#20026;1 + o(1)&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#23454;&#29616;&#36215;&#26469;&#38750;&#24120;&#31616;&#21333;&#65306;&#27599;&#20010;&#38543;&#26426;&#21270;&#22120;&#23558;&#20854;&#36755;&#20837;&#25237;&#24433;&#21040;&#19968;&#20010;&#38543;&#26426;&#30340;&#20302;&#32500;&#23376;&#31354;&#38388;&#20013;&#65292;&#23545;&#32467;&#26524;&#36827;&#34892;&#24402;&#19968;&#21270;&#65292;&#28982;&#21518;&#22312;&#20302;&#32500;&#31354;&#38388;&#20013;&#36816;&#34892;&#19968;&#20010;&#26368;&#20248;&#31639;&#27861;&#65292;&#20363;&#22914;PrivUnitG&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#36866;&#24403;&#22320;&#21327;&#35843;&#35774;&#22791;&#20043;&#38388;&#30340;&#38543;&#26426;&#25237;&#24433;&#30697;&#38453;&#65292;&#21487;&#20197;&#23454;&#29616;&#24555;&#36895;&#30340;&#26381;&#21153;&#22120;&#36816;&#34892;&#26102;&#38388;&#12290;&#25105;&#20204;&#36890;&#36807;&#38543;&#26426;&#25237;&#24433;&#30340;&#24615;&#36136;&#20998;&#26512;&#20102;&#31639;&#27861;&#30340;&#35823;&#24046;&#65292;&#24182;&#30740;&#31350;&#20102;&#20004;&#31181;&#23454;&#20363;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;ProjUnit&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#20855;&#26377;&#26174;&#33879;&#30340;&#24615;&#33021;&#20248;&#21183;&#65292;&#29305;&#21035;&#26159;&#22312;&#39640;&#32500;&#39640;&#26031;&#28151;&#21512;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of locally private mean estimation of high-dimensional vectors in the Euclidean ball. Existing algorithms for this problem either incur sub-optimal error or have high communication and/or run-time complexity. We propose a new algorithmic framework, ProjUnit, for private mean estimation that yields algorithms that are computationally efficient, have low communication complexity, and incur optimal error up to a $1+o(1)$-factor. Our framework is deceptively simple: each randomizer projects its input to a random low-dimensional subspace, normalizes the result, and then runs an optimal algorithm such as PrivUnitG in the lower-dimensional space. In addition, we show that, by appropriately correlating the random projection matrices across devices, we can achieve fast server run-time. We mathematically analyze the error of the algorithm in terms of properties of the random projections, and study two instantiations. Lastly, our experiments for private mean estimation and pr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#38750;&#23545;&#31216;&#26799;&#24230;&#24341;&#23548;&#26469;&#25351;&#23548;&#25193;&#25955;&#37319;&#26679;&#30340;&#21453;&#21521;&#36807;&#31243;&#30340;&#26041;&#27861;&#65292;&#20197;&#25913;&#21892;&#25193;&#25955;&#22270;&#20687;&#32763;&#35793;&#30340;&#39118;&#26684;&#36716;&#25442;&#21644;&#20869;&#23481;&#20445;&#30041;&#20043;&#38388;&#30340;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2306.04396</link><description>&lt;p&gt;
&#20351;&#29992;&#38750;&#23545;&#31216;&#26799;&#24230;&#24341;&#23548;&#26469;&#25913;&#36827;&#25193;&#25955;&#22270;&#20687;&#32763;&#35793;
&lt;/p&gt;
&lt;p&gt;
Improving Diffusion-based Image Translation using Asymmetric Gradient Guidance. (arXiv:2306.04396v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04396
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#38750;&#23545;&#31216;&#26799;&#24230;&#24341;&#23548;&#26469;&#25351;&#23548;&#25193;&#25955;&#37319;&#26679;&#30340;&#21453;&#21521;&#36807;&#31243;&#30340;&#26041;&#27861;&#65292;&#20197;&#25913;&#21892;&#25193;&#25955;&#22270;&#20687;&#32763;&#35793;&#30340;&#39118;&#26684;&#36716;&#25442;&#21644;&#20869;&#23481;&#20445;&#30041;&#20043;&#38388;&#30340;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#25193;&#25955;&#27169;&#22411;&#22312;&#22270;&#20687;&#32763;&#35793;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#30528;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20854;&#38543;&#26426;&#24615;&#65292;&#36890;&#24120;&#23384;&#22312;&#30528;&#39118;&#26684;&#36716;&#25442;&#21644;&#20869;&#23481;&#20445;&#30041;&#20043;&#38388;&#30340;&#24179;&#34913;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#38750;&#23545;&#31216;&#26799;&#24230;&#24341;&#23548;&#26469;&#25351;&#23548;&#25193;&#25955;&#37319;&#26679;&#30340;&#21453;&#21521;&#36807;&#31243;&#30340;&#26041;&#27861;&#12290;&#36825;&#23548;&#33268;&#20102;&#26356;&#24555;&#21644;&#26356;&#31283;&#23450;&#30340;&#22270;&#20687;&#25805;&#20316;&#65292;&#36866;&#29992;&#20110;&#22522;&#20110;&#25991;&#26412;&#21644;&#22270;&#29255;&#30340;&#22270;&#20687;&#32763;&#35793;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models have shown significant progress in image translation tasks recently. However, due to their stochastic nature, there's often a trade-off between style transformation and content preservation. Current strategies aim to disentangle style and content, preserving the source image's structure while successfully transitioning from a source to a target domain under text or one-shot image conditions. Yet, these methods often require computationally intense fine-tuning of diffusion models or additional neural networks. To address these challenges, here we present an approach that guides the reverse process of diffusion sampling by applying asymmetric gradient guidance. This results in quicker and more stable image manipulation for both text-guided and image-guided image translation. Our model's adaptability allows it to be implemented with both image- and latent-diffusion models. Experiments show that our method outperforms various state-of-the-art models in image translation ta
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#21517;&#20026;DFM&#26694;&#26550;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#37327;&#21270;&#26631;&#31614;&#20559;&#31227;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#19978;&#38480;&#21644;&#40065;&#26834;&#24615;&#12290;&#20351;&#29992;&#22522;&#20110;&#26680;&#30340;DFM&#29256;&#26412;&#21487;&#20197;&#25552;&#39640;&#25928;&#29575;&#12289;&#21487;&#25193;&#23637;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.04376</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#24067;&#29305;&#24449;&#21305;&#37197;&#30340;&#26631;&#31614;&#20559;&#31227;&#37327;&#37327;&#21270;&#21450;&#20854;&#40065;&#26834;&#24615;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Label Shift Quantification with Robustness Guarantees via Distribution Feature Matching. (arXiv:2306.04376v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04376
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#21517;&#20026;DFM&#26694;&#26550;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#37327;&#21270;&#26631;&#31614;&#20559;&#31227;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#19978;&#38480;&#21644;&#40065;&#26834;&#24615;&#12290;&#20351;&#29992;&#22522;&#20110;&#26680;&#30340;DFM&#29256;&#26412;&#21487;&#20197;&#25552;&#39640;&#25928;&#29575;&#12289;&#21487;&#25193;&#23637;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#21270;&#23398;&#20064;&#22788;&#29702;&#22312;&#26631;&#31614;&#20559;&#31227;&#19979;&#20272;&#35745;&#30446;&#26631;&#26631;&#31614;&#20998;&#24067;&#30340;&#20219;&#21153;&#12290;&#26412;&#25991;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#20998;&#24067;&#29305;&#24449;&#21305;&#37197;&#65288;DFM&#65289;&#65292;&#23558;&#20808;&#21069;&#25991;&#29486;&#20013;&#24341;&#20837;&#30340;&#21508;&#31181;&#20272;&#35745;&#22120;&#24674;&#22797;&#20026;&#29305;&#23450;&#23454;&#20363;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;DFM&#31243;&#24207;&#30340;&#19968;&#33324;&#24615;&#33021;&#30028;&#65292;&#25913;&#36827;&#20102;&#20808;&#21069;&#22312;&#29305;&#23450;&#24773;&#20917;&#19979;&#25512;&#23548;&#30340;&#30028;&#38480;&#30340;&#33509;&#24178;&#20851;&#38190;&#26041;&#38754;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#36825;&#19968;&#20998;&#26512;&#25193;&#23637;&#21040;&#30740;&#31350;DFM&#31243;&#24207;&#22312;&#26410;&#31934;&#30830;&#20551;&#35774;&#26631;&#31614;&#20559;&#31227;&#37327;&#30340;&#24773;&#20917;&#19979;&#30340;&#40065;&#26834;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#30446;&#26631;&#21463;&#21040;&#26410;&#30693;&#20998;&#24067;&#27745;&#26579;&#30340;&#24773;&#20917;&#19979;&#12290;&#36825;&#20123;&#29702;&#35770;&#21457;&#29616;&#22312;&#27169;&#25311;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#20102;&#35814;&#32454;&#30340;&#25968;&#23383;&#30740;&#31350;&#30830;&#35748;&#12290;&#25105;&#20204;&#36824;&#20351;&#29992;&#38543;&#26426;&#20613;&#37324;&#21494;&#29305;&#24449;&#21407;&#29702;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#25928;&#65292;&#21487;&#25193;&#23637;&#19988;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#22522;&#20110;&#26680;&#30340;DFM&#29256;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantification learning deals with the task of estimating the target label distribution under label shift. In this paper, we first present a unifying framework, distribution feature matching (DFM), that recovers as particular instances various estimators introduced in previous literature. We derive a general performance bound for DFM procedures, improving in several key aspects upon previous bounds derived in particular cases. We then extend this analysis to study robustness of DFM procedures in the misspecified setting under departure from the exact label shift hypothesis, in particular in the case of contamination of the target by an unknown distribution. These theoretical findings are confirmed by a detailed numerical study on simulated and real-world datasets. We also introduce an efficient, scalable and robust version of kernel-based DFM using the Random Fourier Feature principle.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#22522;&#20110;Wasserstein&#36317;&#31163;&#30340;PAC-Bayesian&#27867;&#21270;&#30028;&#38480;&#30340;&#26032;&#39062;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#31639;&#27861;&#26694;&#26550;&#65292;&#35813;&#30028;&#38480;&#26174;&#33879;&#25193;&#23637;&#20102;PAC-Bayesian&#30028;&#38480;&#30340;&#33539;&#22260;&#65292;&#24182;&#22312;&#32463;&#20856;&#30340;&#23398;&#20064;&#38382;&#39064;&#20013;&#23637;&#29616;&#20102;&#25913;&#36827;&#30340;&#27867;&#21270;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2306.04375</link><description>&lt;p&gt;
&#22522;&#20110;Wasserstein&#30340;&#39640;&#27010;&#29575;&#27867;&#21270;&#30028;&#38480;&#19979;&#30340;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Learning via Wasserstein-Based High Probability Generalisation Bounds. (arXiv:2306.04375v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04375
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#22522;&#20110;Wasserstein&#36317;&#31163;&#30340;PAC-Bayesian&#27867;&#21270;&#30028;&#38480;&#30340;&#26032;&#39062;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#31639;&#27861;&#26694;&#26550;&#65292;&#35813;&#30028;&#38480;&#26174;&#33879;&#25193;&#23637;&#20102;PAC-Bayesian&#30028;&#38480;&#30340;&#33539;&#22260;&#65292;&#24182;&#22312;&#32463;&#20856;&#30340;&#23398;&#20064;&#38382;&#39064;&#20013;&#23637;&#29616;&#20102;&#25913;&#36827;&#30340;&#27867;&#21270;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32467;&#26500;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;SRM&#65289;&#20013;&#65292;&#26368;&#23567;&#21270;&#24635;&#20307;&#39118;&#38505;&#25110;&#27867;&#21270;&#24046;&#36317;&#19978;&#38480;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#36825;&#23588;&#20854;&#26159;PAC-Bayesian&#23398;&#20064;&#30340;&#26680;&#24515;&#12290;&#23613;&#31649;&#36817;&#24180;&#26469;&#20854;&#21462;&#24471;&#20102;&#25104;&#21151;&#24182;&#21560;&#24341;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#65292;&#20294;PAC-Bayesian&#26694;&#26550;&#30340;&#23616;&#38480;&#26159;&#22823;&#22810;&#25968;&#30028;&#38480;&#28041;&#21450;Kullback-Leibler&#65288;KL&#65289;&#25955;&#24230;&#39033;&#65288;&#25110;&#20854;&#21464;&#21270;&#65289;&#65292;&#36825;&#21487;&#33021;&#34920;&#29616;&#20986;&#19981;&#35268;&#21017;&#34892;&#20026;&#24182;&#26080;&#27861;&#25429;&#25417;&#23398;&#20064;&#38382;&#39064;&#30340;&#24213;&#23618;&#20960;&#20309;&#32467;&#26500;&#65292;&#22240;&#27492;&#38480;&#21046;&#20102;&#20854;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#20351;&#29992;&#12290;&#26368;&#36817;&#30340;&#19968;&#20123;&#30740;&#31350;&#20225;&#22270;&#29992;Wasserstein&#36317;&#31163;&#26367;&#25442;PAC-Bayesian&#30028;&#38480;&#20013;&#30340;KL&#25955;&#24230;&#12290;&#21363;&#20351;&#36825;&#20123;&#30028;&#38480;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#32531;&#35299;&#20102;&#19978;&#36848;&#38382;&#39064;&#65292;&#20294;&#23427;&#20204;&#35201;&#20040;&#20445;&#25345;&#26399;&#26395;&#65292;&#35201;&#20040;&#23545;&#26377;&#30028;&#25439;&#22833;&#26377;&#25928;&#65292;&#35201;&#20040;&#38590;&#20197;&#22312;SRM&#26694;&#26550;&#20013;&#26368;&#23567;&#21270;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20026;&#36825;&#19968;&#30740;&#31350;&#26041;&#21521;&#20570;&#20986;&#20102;&#36129;&#29486;&#65292;&#35777;&#26126;&#20102;&#22522;&#20110;Wasserstein&#36317;&#31163;&#30340;PAC-Bayesian&#27867;&#21270;&#30028;&#38480;&#30340;&#26032;&#39062;&#24615;&#65292;&#24182;&#19988;&#25105;&#20204;&#30340;&#30028;&#38480;&#20197;&#26174;&#33879;&#24615;&#22320;&#25193;&#23637;&#20102;PAC-Bayesian&#30028;&#38480;&#30340;&#33539;&#22260;&#65292;&#24182;&#22312;&#20960;&#31181;&#32463;&#20856;&#30340;&#23398;&#20064;&#38382;&#39064;&#20013;&#23637;&#29616;&#20102;&#25913;&#36827;&#30340;&#27867;&#21270;&#35823;&#24046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#23398;&#20064;&#26032;&#30340;&#30028;&#38480;&#65292;&#24182;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#26377;&#21069;&#36884;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Minimising upper bounds on the population risk or the generalisation gap has been widely used in structural risk minimisation (SRM) - this is in particular at the core of PAC-Bayesian learning. Despite its successes and unfailing surge of interest in recent years, a limitation of the PAC-Bayesian framework is that most bounds involve a Kullback-Leibler (KL) divergence term (or its variations), which might exhibit erratic behavior and fail to capture the underlying geometric structure of the learning problem - hence restricting its use in practical applications. As a remedy, recent studies have attempted to replace the KL divergence in the PAC-Bayesian bounds with the Wasserstein distance. Even though these bounds alleviated the aforementioned issues to a certain extent, they either hold in expectation, are for bounded losses, or are nontrivial to minimize in an SRM framework. In this work, we contribute to this line of research and prove novel Wasserstein distance-based PAC-Bayesian ge
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24635;&#32467;&#20102;&#26426;&#22120;&#23398;&#20064;&#26102;&#20195;&#23448;&#26041;&#32479;&#35745;&#23398;&#20013;&#65292;&#25968;&#25454;&#28304;&#21464;&#26356;&#25152;&#24102;&#26469;&#30340;&#39118;&#38505;&#12289;&#36131;&#20219;&#21644;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#25552;&#20379;&#19968;&#20221;&#28165;&#21333;&#21015;&#20986;&#39640;&#39057;&#30340;&#21464;&#26356;&#36215;&#22240;&#21644;&#21407;&#22240;&#12290;</title><link>http://arxiv.org/abs/2306.04338</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#26102;&#20195;&#32479;&#35745;&#23398;&#25968;&#25454;&#26469;&#28304;&#30340;&#21464;&#26356;
&lt;/p&gt;
&lt;p&gt;
Changing Data Sources in the Age of Machine Learning for Official Statistics. (arXiv:2306.04338v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04338
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24635;&#32467;&#20102;&#26426;&#22120;&#23398;&#20064;&#26102;&#20195;&#23448;&#26041;&#32479;&#35745;&#23398;&#20013;&#65292;&#25968;&#25454;&#28304;&#21464;&#26356;&#25152;&#24102;&#26469;&#30340;&#39118;&#38505;&#12289;&#36131;&#20219;&#21644;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#25552;&#20379;&#19968;&#20221;&#28165;&#21333;&#21015;&#20986;&#39640;&#39057;&#30340;&#21464;&#26356;&#36215;&#22240;&#21644;&#21407;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#31185;&#23398;&#22312;&#23448;&#26041;&#32479;&#35745;&#25968;&#25454;&#30340;&#29983;&#20135;&#20013;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#65292;&#22240;&#20026;&#23427;&#20351;&#22823;&#37327;&#25968;&#25454;&#30340;&#33258;&#21160;&#25910;&#38598;&#12289;&#22788;&#29702;&#21644;&#20998;&#26512;&#25104;&#20026;&#21487;&#33021;&#12290;&#38543;&#30528;&#36825;&#26679;&#30340;&#25968;&#25454;&#31185;&#23398;&#26041;&#27861;&#30340;&#24212;&#29992;&#65292;&#23427;&#20351;&#24471;&#25253;&#21578;&#21464;&#24471;&#26356;&#21450;&#26102;&#12289;&#26356;&#26377;&#28145;&#24230;&#21644;&#26356;&#20855;&#28789;&#27963;&#24615;&#12290;&#28982;&#32780;&#65292;&#25968;&#25454;&#31185;&#23398;&#39537;&#21160;&#30340;&#32479;&#35745;&#25968;&#25454;&#30340;&#36136;&#37327;&#21644;&#23436;&#25972;&#24615;&#21462;&#20915;&#20110;&#25968;&#25454;&#28304;&#21644;&#25903;&#25345;&#23427;&#20204;&#30340;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#30340;&#20934;&#30830;&#24615;&#21644;&#21487;&#38752;&#24615;&#12290;&#29305;&#21035;&#22320;&#65292;&#25968;&#25454;&#28304;&#30340;&#21464;&#26356;&#26159;&#19981;&#21487;&#36991;&#20813;&#30340;&#65292;&#23427;&#20204;&#20250;&#24341;&#21457;&#37325;&#22823;&#30340;&#39118;&#38505;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#39537;&#21160;&#30340;&#32479;&#35745;&#23398;&#20013;&#24517;&#39035;&#24471;&#21040;&#22949;&#21892;&#22788;&#29702;&#12290;&#26412;&#25991;&#27010;&#36848;&#20102;&#22312;&#23448;&#26041;&#32479;&#35745;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#19982;&#25968;&#25454;&#28304;&#21464;&#26356;&#30456;&#20851;&#30340;&#20027;&#35201;&#39118;&#38505;&#12289;&#36131;&#20219;&#21644;&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#28165;&#21333;&#65292;&#21015;&#20986;&#20102;&#25968;&#25454;&#28304;&#21464;&#26356;&#26368;&#24120;&#35265;&#30340;&#36215;&#22240;&#21644;&#21407;&#22240;&#65292;&#19981;&#20165;&#26159;&#22312;&#25216;&#26415;&#23618;&#38754;&#65292;&#32780;&#19988;&#28041;&#21450;&#25152;&#26377;&#26435;&#12289;&#20262;&#29702;&#21644;&#27861;&#35268;&#31561;&#26041;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data science has become increasingly essential for the production of official statistics, as it enables the automated collection, processing, and analysis of large amounts of data. With such data science practices in place, it enables more timely, more insightful and more flexible reporting. However, the quality and integrity of data-science-driven statistics rely on the accuracy and reliability of the data sources and the machine learning techniques that support them. In particular, changes in data sources are inevitable to occur and pose significant risks that are crucial to address in the context of machine learning for official statistics.  This paper gives an overview of the main risks, liabilities, and uncertainties associated with changing data sources in the context of machine learning for official statistics. We provide a checklist of the most prevalent origins and causes of changing data sources; not only on a technical level but also regarding ownership, ethics, regulation, 
&lt;/p&gt;</description></item><item><title>&#24403;&#21069;XAI&#30740;&#31350;&#20013;&#23384;&#22312;&#22522;&#26412;&#35823;&#35299;&#65292;&#20363;&#22914;&#26410;&#26126;&#30830;&#35299;&#37322;&#25216;&#26415;&#30340;&#30446;&#30340;&#65292;&#20381;&#36182;&#20110;&#20851;&#20110;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#25152;&#23398;&#8220;&#27010;&#24565;&#8221;&#30340;&#24378;&#28872;&#20551;&#35774;&#31561;&#12290;&#25105;&#20204;&#38656;&#35201;&#37319;&#21462;&#25514;&#26045;&#20351;XAI&#25104;&#20026;&#26356;&#23454;&#36136;&#24615;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;</title><link>http://arxiv.org/abs/2306.04292</link><description>&lt;p&gt;
&#20146;&#29233;&#30340;XAI&#31038;&#21306;&#65292;&#25105;&#20204;&#38656;&#35201;&#35848;&#35848;&#65281;&#20851;&#20110;&#24403;&#21069;XAI&#30740;&#31350;&#20013;&#23384;&#22312;&#30340;&#22522;&#26412;&#35823;&#35299;
&lt;/p&gt;
&lt;p&gt;
Dear XAI Community, We Need to Talk! Fundamental Misconceptions in Current XAI Research. (arXiv:2306.04292v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04292
&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;XAI&#30740;&#31350;&#20013;&#23384;&#22312;&#22522;&#26412;&#35823;&#35299;&#65292;&#20363;&#22914;&#26410;&#26126;&#30830;&#35299;&#37322;&#25216;&#26415;&#30340;&#30446;&#30340;&#65292;&#20381;&#36182;&#20110;&#20851;&#20110;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#25152;&#23398;&#8220;&#27010;&#24565;&#8221;&#30340;&#24378;&#28872;&#20551;&#35774;&#31561;&#12290;&#25105;&#20204;&#38656;&#35201;&#37319;&#21462;&#25514;&#26045;&#20351;XAI&#25104;&#20026;&#26356;&#23454;&#36136;&#24615;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#35813;&#39046;&#22495;&#24050;&#32463;&#21462;&#24471;&#20102;&#36827;&#23637;&#65292;&#20294;&#30446;&#21069;XAI&#30740;&#31350;&#30340;&#37325;&#35201;&#37096;&#20998;&#20173;&#26410;&#24314;&#31435;&#22312;&#22362;&#23454;&#30340;&#27010;&#24565;&#12289;&#20262;&#29702;&#25110;&#26041;&#27861;&#35770;&#22522;&#30784;&#19978;&#12290;&#20196;&#20154;&#36951;&#25022;&#30340;&#26159;&#65292;&#36825;&#20123;&#22522;&#30784;&#34180;&#24369;&#30340;&#37096;&#20998;&#24182;&#27809;&#26377;&#20943;&#23569;&#65292;&#32780;&#26159;&#19981;&#26029;&#22686;&#38271;&#12290;&#35768;&#22810;&#35299;&#37322;&#25216;&#26415;&#20173;&#28982;&#27809;&#26377;&#28548;&#28165;&#20854;&#30446;&#30340;&#65292;&#32780;&#26159;&#29992;&#36234;&#26469;&#36234;&#33457;&#21736;&#30340;&#28909;&#28857;&#22270;&#25110;&#30475;&#20284;&#30456;&#20851;&#30340;&#22522;&#20934;&#26469;&#23459;&#20256;&#12290;&#27492;&#22806;&#65292;&#35299;&#37322;&#25216;&#26415;&#30340;&#21160;&#26426;&#23384;&#22312;&#38382;&#39064;&#65292;&#20363;&#22914;&#24314;&#31435;&#20449;&#20219;&#65292;&#25110;&#20381;&#36182;&#20110;&#20851;&#20110;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#25152;&#23398;&#8220;&#27010;&#24565;&#8221;&#30340;&#24378;&#28872;&#20551;&#35774;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#31361;&#20986;&#24182;&#35752;&#35770;&#20102;&#24403;&#21069;XAI&#30740;&#31350;&#20013;&#30340;&#36825;&#20123;&#21644;&#20854;&#20182;&#35823;&#35299;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#20351;XAI&#25104;&#20026;&#26356;&#23454;&#36136;&#24615;&#30740;&#31350;&#39046;&#22495;&#30340;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite progress in the field, significant parts of current XAI research are still not on solid conceptual, ethical, or methodological grounds. Unfortunately, these unfounded parts are not on the decline but continue to grow. Many explanation techniques are still proposed without clarifying their purpose. Instead, they are advertised with ever more fancy-looking heatmaps or only seemingly relevant benchmarks. Moreover, explanation techniques are motivated with questionable goals, such as building trust, or rely on strong assumptions about the 'concepts' that deep learning algorithms learn. In this paper, we highlight and discuss these and other misconceptions in current XAI research. We also suggest steps to make XAI a more substantive area of research.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#23384;&#22312;&#20449;&#24687;&#25277;&#26679;&#30340;&#35266;&#27979;&#25968;&#25454;&#65292;&#25552;&#20986;&#19968;&#31181;&#36890;&#36807;&#36870;&#24378;&#24230;&#21152;&#26435;&#26469;&#23398;&#20064;&#27835;&#30103;&#25928;&#26524;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;TESAR-CDE&#12290;</title><link>http://arxiv.org/abs/2306.04255</link><description>&lt;p&gt;
&#24403;&#23398;&#20064;&#38543;&#26102;&#38388;&#39044;&#27979;&#27835;&#30103;&#25928;&#26524;&#26102;&#32771;&#34385;&#20449;&#24687;&#25277;&#26679;
&lt;/p&gt;
&lt;p&gt;
Accounting For Informative Sampling When Learning to Forecast Treatment Outcomes Over Time. (arXiv:2306.04255v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04255
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#23384;&#22312;&#20449;&#24687;&#25277;&#26679;&#30340;&#35266;&#27979;&#25968;&#25454;&#65292;&#25552;&#20986;&#19968;&#31181;&#36890;&#36807;&#36870;&#24378;&#24230;&#21152;&#26435;&#26469;&#23398;&#20064;&#27835;&#30103;&#25928;&#26524;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;TESAR-CDE&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#22312;&#20934;&#30830;&#39044;&#27979;&#27835;&#30103;&#25928;&#26524;&#38543;&#26102;&#38388;&#21464;&#21270;&#26041;&#38754;&#20855;&#26377;&#24040;&#22823;&#28508;&#21147;&#65292;&#36825;&#26368;&#32456;&#21487;&#20197;&#20351;&#26356;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#37319;&#29992;&#20010;&#24615;&#21270;&#27835;&#30103;&#31574;&#30053;&#25104;&#20026;&#21487;&#33021;&#12290;&#28982;&#32780;&#65292;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#22312;&#36825;&#20010;&#20027;&#39064;&#19978;&#34987;&#22823;&#37327;&#24573;&#35270;&#30340;&#19968;&#20010;&#37325;&#35201;&#25361;&#25112;&#26159;&#35266;&#27979;&#25968;&#25454;&#20013;&#23384;&#22312;&#20449;&#24687;&#25277;&#26679;&#12290;&#24403;&#23454;&#20363;&#22312;&#26102;&#38388;&#19978;&#19981;&#35268;&#21017;&#35266;&#27979;&#26102;&#65292;&#25277;&#26679;&#26102;&#38388;&#36890;&#24120;&#19981;&#26159;&#38543;&#26426;&#30340;&#65292;&#32780;&#26159;&#20855;&#26377;&#20449;&#24687;&#24615;&#30340; - &#21462;&#20915;&#20110;&#23454;&#20363;&#30340;&#29305;&#24449;&#12289;&#36807;&#21435;&#30340;&#32467;&#26524;&#21644;&#26045;&#29992;&#30340;&#27835;&#30103;&#26041;&#26696;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#20449;&#24687;&#25277;&#26679;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#21327;&#21464;&#25442;&#31227;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#22914;&#26524;&#19981;&#36866;&#24403;&#22320;&#32771;&#34385;&#23427;&#20250;&#38480;&#21046;&#27835;&#30103;&#25928;&#26524;&#30340;&#20934;&#30830;&#20272;&#35745;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#23384;&#22312;&#20449;&#24687;&#25277;&#26679;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#27835;&#30103;&#25928;&#26524;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;TESAR-CDE&#65292;&#26469;&#23454;&#29616;&#36825;&#20010;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning (ML) holds great potential for accurately forecasting treatment outcomes over time, which could ultimately enable the adoption of more individualized treatment strategies in many practical applications. However, a significant challenge that has been largely overlooked by the ML literature on this topic is the presence of informative sampling in observational data. When instances are observed irregularly over time, sampling times are typically not random, but rather informative -- depending on the instance's characteristics, past outcomes, and administered treatments. In this work, we formalize informative sampling as a covariate shift problem and show that it can prohibit accurate estimation of treatment outcomes if not properly accounted for. To overcome this challenge, we present a general framework for learning treatment outcomes in the presence of informative sampling using inverse intensity-weighting, and propose a novel method, TESAR-CDE, that instantiates this f
&lt;/p&gt;</description></item><item><title>SGD&#22312;&#35757;&#32451;&#36807;&#24230;&#34920;&#36798;&#30340;&#32593;&#32476;&#26102;&#65292;&#20250;&#38543;&#26426;&#22320;&#23558;&#21160;&#24577;&#21560;&#24341;&#21040;&#26356;&#31616;&#21333;&#30340;&#23376;&#32593;&#32476;&#65292;&#36825;&#31181;&#38543;&#26426;&#21560;&#24341;&#24615;&#33021;&#22815;&#25552;&#39640;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2306.04251</link><description>&lt;p&gt;
&#38543;&#26426;&#22349;&#32553;&#65306;&#22914;&#20309;&#21033;&#29992;&#26799;&#24230;&#22122;&#22768;&#20351;SGD&#21160;&#24577;&#36235;&#21521;&#26356;&#31616;&#21333;&#30340;&#23376;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Stochastic Collapse: How Gradient Noise Attracts SGD Dynamics Towards Simpler Subnetworks. (arXiv:2306.04251v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04251
&lt;/p&gt;
&lt;p&gt;
SGD&#22312;&#35757;&#32451;&#36807;&#24230;&#34920;&#36798;&#30340;&#32593;&#32476;&#26102;&#65292;&#20250;&#38543;&#26426;&#22320;&#23558;&#21160;&#24577;&#21560;&#24341;&#21040;&#26356;&#31616;&#21333;&#30340;&#23376;&#32593;&#32476;&#65292;&#36825;&#31181;&#38543;&#26426;&#21560;&#24341;&#24615;&#33021;&#22815;&#25552;&#39640;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25581;&#31034;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#19968;&#20010;&#24378;&#28872;&#38544;&#24335;&#20559;&#22909;&#65292;&#23427;&#23558;&#36807;&#24230;&#34920;&#36798;&#30340;&#32593;&#32476;&#39537;&#21160;&#21040;&#26356;&#31616;&#21333;&#30340;&#23376;&#32593;&#32476;&#65292;&#20174;&#32780;&#22823;&#22823;&#20943;&#23569;&#20102;&#29420;&#31435;&#21442;&#25968;&#30340;&#25968;&#37327;&#65292;&#24182;&#25552;&#39640;&#20102;&#27867;&#21270;&#33021;&#21147;&#12290;&#20026;&#20102;&#25581;&#31034;&#36825;&#20010;&#20559;&#22909;&#65292;&#25105;&#20204;&#35782;&#21035;&#20102;&#19981;&#21464;&#38598;&#65292;&#25110;&#32773;&#35828;&#26159;SGD&#26410;&#20462;&#25913;&#30340;&#21442;&#25968;&#31354;&#38388;&#30340;&#23376;&#38598;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#20004;&#31867;&#19981;&#21464;&#38598;&#65292;&#23427;&#20204;&#23545;&#24212;&#20110;&#29616;&#20195;&#26550;&#26500;&#20013;&#24120;&#35265;&#30340;&#26356;&#31616;&#21333;&#30340;&#23376;&#32593;&#32476;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;SGD&#22312;&#36825;&#20123;&#31616;&#21333;&#19981;&#21464;&#38598;&#26041;&#38754;&#20855;&#26377;&#38543;&#26426;&#21560;&#24341;&#24615;&#30340;&#29305;&#24615;&#12290;&#25105;&#20204;&#26681;&#25454;&#25439;&#22833;&#26223;&#35266;&#22312;&#19981;&#21464;&#38598;&#21608;&#22260;&#30340;&#26354;&#29575;&#21644;&#38543;&#26426;&#26799;&#24230;&#24341;&#20837;&#30340;&#22122;&#22768;&#20043;&#38388;&#30340;&#31454;&#20105;&#24314;&#31435;&#20102;&#19968;&#31181;&#38543;&#26426;&#21560;&#24341;&#24615;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#22686;&#21152;&#22122;&#22768;&#27700;&#24179;&#20250;&#22686;&#24378;&#21560;&#24341;&#21147;&#65292;&#23548;&#33268;&#19982;&#38797;&#28857;&#25110;&#35757;&#32451;&#25439;&#22833;&#30340;&#23616;&#37096;&#26497;&#22823;&#20540;&#30456;&#20851;&#30340;&#21560;&#24341;&#19981;&#21464;&#38598;&#30340;&#20986;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we reveal a strong implicit bias of stochastic gradient descent (SGD) that drives overly expressive networks to much simpler subnetworks, thereby dramatically reducing the number of independent parameters, and improving generalization. To reveal this bias, we identify invariant sets, or subsets of parameter space that remain unmodified by SGD. We focus on two classes of invariant sets that correspond to simpler subnetworks and commonly appear in modern architectures. Our analysis uncovers that SGD exhibits a property of stochastic attractivity towards these simpler invariant sets. We establish a sufficient condition for stochastic attractivity based on a competition between the loss landscape's curvature around the invariant set and the noise introduced by stochastic gradients. Remarkably, we find that an increased level of noise strengthens attractivity, leading to the emergence of attractive invariant sets associated with saddle-points or local maxima of the train loss.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#21452;&#37325;/&#26080;&#20559;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30740;&#31350;&#20102;&#20809;&#30005;&#21322;&#23548;&#20307;&#21046;&#36896;&#20013;&#30340;&#36820;&#24037;&#27493;&#39588;&#65292;&#20026;&#38646;&#20214;&#36820;&#24037;&#21046;&#23450;&#31574;&#30053;&#24182;&#20174;&#32463;&#39564;&#19978;&#20272;&#35745;&#23427;&#20204;&#30340;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2306.04223</link><description>&lt;p&gt;
&#23398;&#20064;&#21046;&#23450;&#26368;&#20339;&#36820;&#24037;&#31574;&#30053;&#30340;&#22240;&#26524;&#20851;&#31995;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Causally Learning an Optimal Rework Policy. (arXiv:2306.04223v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04223
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#21452;&#37325;/&#26080;&#20559;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30740;&#31350;&#20102;&#20809;&#30005;&#21322;&#23548;&#20307;&#21046;&#36896;&#20013;&#30340;&#36820;&#24037;&#27493;&#39588;&#65292;&#20026;&#38646;&#20214;&#36820;&#24037;&#21046;&#23450;&#31574;&#30053;&#24182;&#20174;&#32463;&#39564;&#19978;&#20272;&#35745;&#23427;&#20204;&#30340;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21046;&#36896;&#19994;&#20013;&#65292;&#36820;&#24037;&#26159;&#19968;&#31181;&#26088;&#22312;&#28040;&#38500;&#38169;&#35823;&#25110;&#32416;&#27491;&#19981;&#31526;&#21512;&#25152;&#38656;&#36136;&#37327;&#26631;&#20934;&#30340;&#20135;&#21697;&#30340;&#21487;&#36873;&#29983;&#20135;&#27493;&#39588;&#12290;&#37325;&#26032;&#21152;&#24037;&#29983;&#20135;&#25209;&#27425;&#28041;&#21450;&#37325;&#22797;&#20197;&#21069;&#30340;&#29983;&#20135;&#38454;&#27573;&#65292;&#24182;&#36827;&#34892;&#35843;&#25972;&#20197;&#30830;&#20445;&#26368;&#32456;&#20135;&#21697;&#31526;&#21512;&#25152;&#38656;&#35268;&#26684;&#12290;&#34429;&#28982;&#25552;&#20379;&#20102;&#25913;&#21892;&#20135;&#37327;&#20174;&#32780;&#22686;&#21152;&#29983;&#20135;&#25209;&#27425;&#25910;&#20837;&#30340;&#26426;&#20250;&#65292;&#20294;&#36820;&#24037;&#27493;&#39588;&#20063;&#20250;&#20135;&#29983;&#39069;&#22806;&#30340;&#25104;&#26412;&#12290;&#27492;&#22806;&#65292;&#37325;&#26032;&#21152;&#24037;&#24050;&#28385;&#36275;&#30446;&#26631;&#35268;&#26684;&#30340;&#38646;&#20214;&#21487;&#33021;&#20250;&#25439;&#22351;&#23427;&#20204;&#24182;&#38477;&#20302;&#20135;&#37327;&#12290;&#26412;&#25991;&#24212;&#29992;&#21452;&#37325;/&#26080;&#20559;&#26426;&#22120;&#23398;&#20064;&#65288;DML&#65289;&#26469;&#20272;&#35745;&#20809;&#30005;&#21322;&#23548;&#20307;&#21046;&#36896;&#20013;&#39068;&#33394;&#36716;&#25442;&#36807;&#31243;&#20013;&#19968;&#27425;&#36820;&#24037;&#27493;&#39588;&#23545;&#26368;&#32456;&#20135;&#21697;&#20135;&#37327;&#30340;&#26465;&#20214;&#22788;&#29702;&#25928;&#24212;&#12290; &#25105;&#20204;&#21033;&#29992;DoubleML&#23454;&#29616;&#21046;&#23450;&#38646;&#20214;&#36820;&#24037;&#31574;&#30053;&#24182;&#20174;&#32463;&#39564;&#19978;&#20272;&#35745;&#23427;&#20204;&#30340;&#20215;&#20540;&#12290;&#20174;&#25105;&#20204;&#30340;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#20998;&#26512;&#20013;
&lt;/p&gt;
&lt;p&gt;
In manufacturing, rework refers to an optional step of a production process which aims to eliminate errors or remedy products that do not meet the desired quality standards. Reworking a production lot involves repeating a previous production stage with adjustments to ensure that the final product meets the required specifications. While offering the chance to improve the yield and thus increase the revenue of a production lot, a rework step also incurs additional costs. Additionally, the rework of parts that already meet the target specifications may damage them and decrease the yield. In this paper, we apply double/debiased machine learning (DML) to estimate the conditional treatment effect of a rework step during the color conversion process in opto-electronic semiconductor manufacturing on the final product yield. We utilize the implementation DoubleML to develop policies for the rework of components and estimate their value empirically. From our causal machine learning analysis we 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25913;&#36827;&#20102;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#20013;&#30340;&#36229;&#21442;&#25968;&#23398;&#20064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#35757;&#32451;&#26041;&#27861;&#26469;&#20860;&#39038;&#21464;&#20998;&#25512;&#26029;&#21644;&#26399;&#26395;&#20256;&#25773;&#26041;&#27861;&#65292;&#20197;&#20248;&#21270;&#36229;&#21442;&#25968;&#30340;&#23398;&#20064;&#30446;&#26631;&#65292;&#35813;&#26041;&#27861;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.04201</link><description>&lt;p&gt;
&#22312;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#36817;&#20284;&#25512;&#26029;&#20013;&#25913;&#21892;&#36229;&#21442;&#25968;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Improving Hyperparameter Learning under Approximate Inference in Gaussian Process Models. (arXiv:2306.04201v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04201
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25913;&#36827;&#20102;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#20013;&#30340;&#36229;&#21442;&#25968;&#23398;&#20064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#35757;&#32451;&#26041;&#27861;&#26469;&#20860;&#39038;&#21464;&#20998;&#25512;&#26029;&#21644;&#26399;&#26395;&#20256;&#25773;&#26041;&#27861;&#65292;&#20197;&#20248;&#21270;&#36229;&#21442;&#25968;&#30340;&#23398;&#20064;&#30446;&#26631;&#65292;&#35813;&#26041;&#27861;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20855;&#26377;&#38750;&#20849;&#36717;&#20284;&#28982;&#20989;&#25968;&#30340;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#27169;&#22411;&#20013;&#65292;&#36817;&#20284;&#25512;&#26029;&#19982;&#27169;&#22411;&#36229;&#21442;&#25968;&#30340;&#23398;&#20064;&#32416;&#32544;&#22312;&#19968;&#36215;&#12290;&#25105;&#20204;&#25913;&#36827;&#20102; GP &#27169;&#22411;&#20013;&#30340;&#36229;&#21442;&#25968;&#23398;&#20064;&#65292;&#24182;&#20851;&#27880;&#21464;&#20998;&#25512;&#26029;&#65288;VI&#65289;&#19982;&#23398;&#20064;&#30446;&#26631;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#34429;&#28982; VI &#23545;&#36793;&#32536;&#20284;&#28982;&#20989;&#25968;&#30340;&#19979;&#30028;&#26159;&#25512;&#26029;&#36817;&#20284;&#21518;&#39564;&#30340;&#21512;&#36866;&#30446;&#26631;&#65292;&#20294;&#25105;&#20204;&#21457;&#29616;&#20687;&#26399;&#26395;&#20256;&#25773;&#65288;EP&#65289;&#20013;&#30452;&#25509;&#36924;&#36817;&#36793;&#32536;&#20284;&#28982;&#20989;&#25968;&#26159;&#26356;&#36866;&#21512;&#36229;&#21442;&#25968;&#20248;&#21270;&#30340;&#23398;&#20064;&#30446;&#26631;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#28151;&#21512;&#35757;&#32451;&#36807;&#31243;&#65292;&#23558;&#26368;&#20339;&#25928;&#26524;&#32467;&#21512;&#21040;&#19968;&#36215;&#65306;&#21033;&#29992;&#20849;&#36717;&#35745;&#31639; VI &#36827;&#34892;&#25512;&#26029;&#65292;&#24182;&#20351;&#29992;&#31867;&#20284;&#20110; EP &#30340;&#36793;&#32536;&#20284;&#28982;&#20989;&#25968;&#36924;&#36817;&#36827;&#34892;&#36229;&#21442;&#25968;&#23398;&#20064;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102; VI&#12289;EP&#12289;Laplace &#36817;&#20284;&#21644;&#25105;&#20204;&#25552;&#20986;&#30340;&#35757;&#32451;&#36807;&#31243;&#65292;&#24182;&#22312;&#24191;&#27867;&#30340;&#25968;&#25454;&#38598;&#19978;&#32463;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#25552;&#35758;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Approximate inference in Gaussian process (GP) models with non-conjugate likelihoods gets entangled with the learning of the model hyperparameters. We improve hyperparameter learning in GP models and focus on the interplay between variational inference (VI) and the learning target. While VI's lower bound to the marginal likelihood is a suitable objective for inferring the approximate posterior, we show that a direct approximation of the marginal likelihood as in Expectation Propagation (EP) is a better learning objective for hyperparameter optimization. We design a hybrid training procedure to bring the best of both worlds: it leverages conjugate-computation VI for inference and uses an EP-like marginal likelihood approximation for hyperparameter learning. We compare VI, EP, Laplace approximation, and our proposed training procedure and empirically demonstrate the effectiveness of our proposal across a wide range of data sets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#35270;&#35282;&#30340;&#38543;&#26426;&#20248;&#21270;&#31471;&#21040;&#31471;&#23398;&#20064;&#26041;&#27861;&#65292;&#20026;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#21644;&#20998;&#24067;&#24335;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#25552;&#20379;&#26032;&#30340;&#31471;&#21040;&#31471;&#23398;&#20064;&#31639;&#27861;&#65292;&#26041;&#24335;&#20027;&#35201;&#26159;&#35757;&#32451;&#20915;&#31574;&#26144;&#23556;&#12290;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#30340;newsvendor&#38382;&#39064;&#21644;&#32463;&#27982;&#20998;&#37197;&#38382;&#39064;&#19978;&#22343;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#25928;&#26524;&#65292;&#21516;&#26102;&#20063;&#21457;&#29616;&#20915;&#31574;&#26144;&#23556;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#23545;&#27979;&#35797;&#24615;&#33021;&#30340;&#24433;&#21709;&#24456;&#22823;&#12290;</title><link>http://arxiv.org/abs/2306.04174</link><description>&lt;p&gt;
&#22522;&#20110;&#36125;&#21494;&#26031;&#35270;&#35282;&#30340;&#38543;&#26426;&#20248;&#21270;&#31471;&#21040;&#31471;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
End-to-End Learning for Stochastic Optimization: A Bayesian Perspective. (arXiv:2306.04174v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04174
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#35270;&#35282;&#30340;&#38543;&#26426;&#20248;&#21270;&#31471;&#21040;&#31471;&#23398;&#20064;&#26041;&#27861;&#65292;&#20026;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#21644;&#20998;&#24067;&#24335;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#25552;&#20379;&#26032;&#30340;&#31471;&#21040;&#31471;&#23398;&#20064;&#31639;&#27861;&#65292;&#26041;&#24335;&#20027;&#35201;&#26159;&#35757;&#32451;&#20915;&#31574;&#26144;&#23556;&#12290;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#30340;newsvendor&#38382;&#39064;&#21644;&#32463;&#27982;&#20998;&#37197;&#38382;&#39064;&#19978;&#22343;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#25928;&#26524;&#65292;&#21516;&#26102;&#20063;&#21457;&#29616;&#20915;&#31574;&#26144;&#23556;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#23545;&#27979;&#35797;&#24615;&#33021;&#30340;&#24433;&#21709;&#24456;&#22823;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#35270;&#35282;&#30340;&#38543;&#26426;&#20248;&#21270;&#31471;&#21040;&#31471;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#37319;&#29992;&#20102;&#26631;&#20934;&#31471;&#21040;&#31471;&#23398;&#20064;&#31639;&#27861;&#30340;&#24605;&#24819;&#65292;&#35757;&#32451;&#20102;&#19968;&#20010;&#21518;&#39564;&#36125;&#21494;&#26031;&#34892;&#21160;&#26144;&#23556;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#20026;&#35299;&#20915;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#21644;&#20998;&#24067;&#24335;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#25552;&#20986;&#20102;&#26032;&#30340;&#31471;&#21040;&#31471;&#23398;&#20064;&#31639;&#27861;&#12290;&#36890;&#36807;&#21512;&#25104;&#30340;newsvendor&#38382;&#39064;&#21644;&#22522;&#20110;&#30495;&#23454;&#25968;&#25454;&#30340;&#32463;&#27982;&#20998;&#37197;&#38382;&#39064;&#30340;&#25968;&#20540;&#32467;&#26524;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19981;&#21516;&#35757;&#32451;&#26041;&#26696;&#20043;&#38388;&#30340;&#20851;&#38190;&#24046;&#24322;&#20197;&#21450;&#20915;&#31574;&#26144;&#23556;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#23545;&#27979;&#35797;&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a principled approach to end-to-end learning in stochastic optimization. First, we show that the standard end-to-end learning algorithm admits a Bayesian interpretation and trains a posterior Bayes action map. Building on the insights of this analysis, we then propose new end-to-end learning algorithms for training decision maps that output solutions of empirical risk minimization and distributionally robust optimization problems, two dominant modeling paradigms in optimization under uncertainty. Numerical results for a synthetic newsvendor problem illustrate the key differences between alternative training schemes. We also investigate an economic dispatch problem based on real data to showcase the impact of the neural network architecture of the decision maps on their test performance.
&lt;/p&gt;</description></item><item><title>MESSY&#20272;&#35745;&#26041;&#27861;&#26159;&#19968;&#31181;&#22522;&#20110;&#26368;&#22823;&#29109;&#30340;&#38543;&#26426;&#21644;&#31526;&#21495;&#23494;&#24230;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#22522;&#20110;&#26799;&#24230;&#30340;&#28418;&#31227;&#25193;&#25955;&#36807;&#31243;&#26469;&#39640;&#25928;&#22320;&#25214;&#21040;&#26368;&#22823;&#29109;&#20998;&#24067;&#30340;&#21442;&#25968;&#65292;&#25903;&#25345;&#39640;&#32500;&#38382;&#39064;&#65292;&#24182;&#20855;&#26377;&#20248;&#20110;&#29616;&#26377;&#26368;&#26032;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#26222;&#36866;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.04120</link><description>&lt;p&gt;
MESSY&#20272;&#35745;&#65306;&#22522;&#20110;&#26368;&#22823;&#29109;&#30340;&#38543;&#26426;&#21644;&#31526;&#21495;&#23494;&#24230;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
MESSY Estimation: Maximum-Entropy based Stochastic and Symbolic densitY Estimation. (arXiv:2306.04120v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04120
&lt;/p&gt;
&lt;p&gt;
MESSY&#20272;&#35745;&#26041;&#27861;&#26159;&#19968;&#31181;&#22522;&#20110;&#26368;&#22823;&#29109;&#30340;&#38543;&#26426;&#21644;&#31526;&#21495;&#23494;&#24230;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#22522;&#20110;&#26799;&#24230;&#30340;&#28418;&#31227;&#25193;&#25955;&#36807;&#31243;&#26469;&#39640;&#25928;&#22320;&#25214;&#21040;&#26368;&#22823;&#29109;&#20998;&#24067;&#30340;&#21442;&#25968;&#65292;&#25903;&#25345;&#39640;&#32500;&#38382;&#39064;&#65292;&#24182;&#20855;&#26377;&#20248;&#20110;&#29616;&#26377;&#26368;&#26032;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#26222;&#36866;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#26368;&#22823;&#29109;&#30340;&#38543;&#26426;&#21644;&#31526;&#21495;&#23494;&#24230;&#20272;&#35745;&#26041;&#27861;MESSY&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20351;&#29992;&#26799;&#24230;&#27969;&#30340;&#30697;&#23558;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#20174;&#26679;&#26412;&#20013;&#24674;&#22797;&#20026;&#31526;&#21495;&#34920;&#36798;&#24335;&#65292;&#24182;&#23558;ansatz&#20316;&#20026;&#39537;&#21160;&#21147;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#22522;&#20110;&#26799;&#24230;&#30340;&#28418;&#31227;&#25193;&#25955;&#36807;&#31243;&#65292;&#23558;&#26410;&#30693;&#20998;&#24067;&#20989;&#25968;&#30340;&#26679;&#26412;&#19982;&#29468;&#27979;&#30340;&#31526;&#21495;&#34920;&#36798;&#24335;&#30456;&#36830;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20986;&#24403;&#29468;&#27979;&#20998;&#24067;&#20855;&#26377;&#26368;&#22823;&#29109;&#24418;&#24335;&#26102;&#65292;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#25552;&#20379;&#30340;&#26679;&#26412;&#30340;&#30697;&#26500;&#24314;&#30340;&#32447;&#24615;&#26041;&#31243;&#32452;&#39640;&#25928;&#22320;&#25214;&#21040;&#35813;&#20998;&#24067;&#30340;&#21442;&#25968;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;&#31526;&#21495;&#22238;&#24402;&#26469;&#25506;&#32034;&#24179;&#28369;&#20989;&#25968;&#30340;&#31354;&#38388;&#65292;&#24182;&#25214;&#21040;&#23548;&#33268;&#26368;&#22823;&#29109;&#27867;&#20989;&#25351;&#25968;&#30340;&#26368;&#20248;&#22522;&#20989;&#25968;&#65292;&#20197;&#33719;&#24471;&#33391;&#22909;&#26465;&#20214;&#12290;&#35813;&#26041;&#27861;&#22312;&#38543;&#26426;&#25628;&#32034;&#30340;&#27599;&#27425;&#36845;&#20195;&#20013;&#30340;&#25104;&#26412;&#19982;&#26679;&#26412;&#25968;&#37327;&#21576;&#32447;&#24615;&#20851;&#31995;&#65292;&#19982;&#21464;&#37327;&#25968;&#37327;&#21576;&#20108;&#27425;&#20851;&#31995;&#65292;&#20351;&#20854;&#21487;&#25193;&#23637;&#21040;&#39640;&#32500;&#38382;&#39064;&#12290;&#25968;&#20540;&#23454;&#39564;&#26174;&#31034;&#20986;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#26222;&#36866;&#24615;&#65292;&#19982;&#29616;&#26377;&#30340;&#26368;&#26032;&#26041;&#27861;&#30456;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce MESSY estimation, a Maximum-Entropy based Stochastic and Symbolic densitY estimation method. The proposed approach recovers probability density functions symbolically from samples using moments of a Gradient flow in which the ansatz serves as the driving force. In particular, we construct a gradient-based drift-diffusion process that connects samples of the unknown distribution function to a guess symbolic expression. We then show that when the guess distribution has the maximum entropy form, the parameters of this distribution can be found efficiently by solving a linear system of equations constructed using the moments of the provided samples. Furthermore, we use Symbolic regression to explore the space of smooth functions and find optimal basis functions for the exponent of the maximum entropy functional leading to good conditioning. The cost of the proposed method in each iteration of the random search is linear with the number of samples and quadratic with the number 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21333;&#36793;&#30697;&#38453;&#23436;&#25104;&#38382;&#39064;&#65292;&#22312;&#27599;&#34892;&#21482;&#26377;&#20004;&#20010;&#35266;&#27979;&#20540;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#25554;&#20540;&#31639;&#27861;&#21487;&#20197;&#21487;&#38752;&#24674;&#22797;$X^TX$&#65292;&#36827;&#32780;&#24674;&#22797;$X$&#30340;&#21491;&#22855;&#24322;&#21521;&#37327;&#12290;</title><link>http://arxiv.org/abs/2306.04049</link><description>&lt;p&gt;
&#20174;&#27599;&#34892;&#20004;&#20010;&#35266;&#27979;&#26469;&#30475;&#30340;&#21333;&#36793;&#30697;&#38453;&#23436;&#25104;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
One-sided Matrix Completion from Two Observations Per Row. (arXiv:2306.04049v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04049
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21333;&#36793;&#30697;&#38453;&#23436;&#25104;&#38382;&#39064;&#65292;&#22312;&#27599;&#34892;&#21482;&#26377;&#20004;&#20010;&#35266;&#27979;&#20540;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#25554;&#20540;&#31639;&#27861;&#21487;&#20197;&#21487;&#38752;&#24674;&#22797;$X^TX$&#65292;&#36827;&#32780;&#24674;&#22797;$X$&#30340;&#21491;&#22855;&#24322;&#21521;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32473;&#23450;&#19968;&#20010;&#20302;&#31209;&#30697;&#38453;$X$&#30340;&#19968;&#20123;&#35266;&#27979;&#20540;&#65292;&#30697;&#38453;&#23436;&#25104;&#38382;&#39064;&#26159;&#25512;&#27979;&#32570;&#22833;&#20540;&#30340;&#38382;&#39064;&#65292;&#23427;&#26159;&#24418;&#24335;&#21270;&#25551;&#36848;&#19968;&#31995;&#21015;&#38656;&#35201;&#20272;&#35745;&#32570;&#22833;&#25968;&#25454;&#30340;&#29616;&#23454;&#19990;&#30028;&#35774;&#32622;&#12290;&#28982;&#32780;&#65292;&#24403;&#35266;&#27979;&#21040;&#30340;&#26465;&#30446;&#22826;&#23569;&#32780;&#26080;&#27861;&#23436;&#25104;&#30697;&#38453;&#26102;&#65292;&#21487;&#20197;&#21487;&#38752;&#24674;&#22797;&#22522;&#30784;&#30697;&#38453;&#30340;&#21738;&#20123;&#20854;&#20182;&#26041;&#38754;&#65311;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#36825;&#26679;&#30340;&#38382;&#39064;&#35774;&#32622;&#65292;&#21363;&#8220;&#21333;&#36793;&#8221;&#30697;&#38453;&#23436;&#25104;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#24674;&#22797;$X$&#30340;&#21491;&#22855;&#24322;&#21521;&#37327;&#65292;&#21363;&#20351;&#22312;&#26080;&#27861;&#24674;&#22797;&#24038;&#22855;&#24322;&#21521;&#37327;&#30340;&#24773;&#20917;&#19979;&#65292;&#21363;&#24403;&#34892;&#25968;&#22823;&#20110;&#21015;&#25968;&#19988;&#35266;&#27979;&#30340;&#24456;&#23569;&#26102;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#28982;&#31639;&#27861;&#65292;&#28041;&#21450;&#21040;&#30697;&#38453;$X^TX$&#20013;&#32570;&#22833;&#20540;&#30340;&#25554;&#20540;&#65292;&#24182;&#35777;&#26126;&#21363;&#20351;&#22312;&#27599;&#34892;&#21482;&#26377;&#20004;&#20010;&#35266;&#27979;&#20540;&#30340;&#24773;&#20917;&#19979;&#65292;&#21482;&#35201;&#25105;&#20204;&#26377;&#33267;&#23569;$\Omega(r^2 d \log d)$&#34892;&#65292;&#20854;&#20013;$r$&#20026;&#31209;&#65292;$d$&#20026;&#21015;&#25968;&#65292;&#25105;&#20204;&#23601;&#21487;&#20197;&#21487;&#38752;&#22320;&#24674;&#22797;$X^TX$&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#21333;&#36793;&#30697;&#38453;&#23436;&#25104;&#38382;&#39064;&#20197;&#21450;&#25512;&#33616;&#20219;&#21153;&#19978;&#30340;&#34920;&#29616;&#65292;&#24182;&#21457;&#29616;&#23427;&#22312;&#25152;&#32771;&#34385;&#30340;&#35774;&#32622;&#19979;&#20248;&#20110;&#29616;&#26377;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given only a few observed entries from a low-rank matrix $X$, matrix completion is the problem of imputing the missing entries, and it formalizes a wide range of real-world settings that involve estimating missing data. However, when there are too few observed entries to complete the matrix, what other aspects of the underlying matrix can be reliably recovered? We study one such problem setting, that of "one-sided" matrix completion, where our goal is to recover the right singular vectors of $X$, even in the regime where recovering the left singular vectors is impossible, which arises when there are more rows than columns and very few observations. We propose a natural algorithm that involves imputing the missing values of the matrix $X^TX$ and show that even with only two observations per row in $X$, we can provably recover $X^TX$ as long as we have at least $\Omega(r^2 d \log d)$ rows, where $r$ is the rank and $d$ is the number of columns. We evaluate our algorithm on one-sided reco
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22240;&#23376;&#22270;&#27169;&#22411;&#30340;&#8220;&#24178;&#39044;&#22240;&#23376;&#27169;&#22411;&#8221;(IFM)&#26041;&#27861;&#65292;&#20165;&#22522;&#20110;&#23545;&#25805;&#32437;&#31995;&#32479;&#20998;&#24067;&#30340;&#22240;&#23376;&#20998;&#35299;&#30340;&#26368;&#23567;&#20551;&#35774;&#65292;&#20197;&#23454;&#29616;&#20174;&#36807;&#21435;&#30340;&#23454;&#39564;&#21040;&#26032;&#30340;&#26465;&#20214;&#30340;&#36291;&#36801;&#12290;</title><link>http://arxiv.org/abs/2306.04027</link><description>&lt;p&gt;
&#22240;&#23376;&#22270;&#27169;&#22411;&#35270;&#35282;&#19979;&#30340;&#24178;&#39044;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Intervention Generalization: A View from Factor Graph Models. (arXiv:2306.04027v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04027
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22240;&#23376;&#22270;&#27169;&#22411;&#30340;&#8220;&#24178;&#39044;&#22240;&#23376;&#27169;&#22411;&#8221;(IFM)&#26041;&#27861;&#65292;&#20165;&#22522;&#20110;&#23545;&#25805;&#32437;&#31995;&#32479;&#20998;&#24067;&#30340;&#22240;&#23376;&#20998;&#35299;&#30340;&#26368;&#23567;&#20551;&#35774;&#65292;&#20197;&#23454;&#29616;&#20174;&#36807;&#21435;&#30340;&#23454;&#39564;&#21040;&#26032;&#30340;&#26465;&#20214;&#30340;&#36291;&#36801;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#25512;&#26029;&#30340;&#19968;&#20010;&#30446;&#26631;&#26159;&#20174;&#36807;&#21435;&#30340;&#23454;&#39564;&#21644;&#35266;&#23519;&#25968;&#25454;&#25512;&#24191;&#21040;&#26032;&#30340;&#26465;&#20214;&#12290;&#22312;&#35757;&#32451;&#25968;&#25454;&#20013;&#25552;&#20379;&#36275;&#22815;&#22810;&#30340;&#23454;&#39564;&#30340;&#24773;&#20917;&#19979;&#65292;&#29702;&#35770;&#19978;&#21487;&#33021;&#26368;&#32456;&#23398;&#20064;&#20174;&#26032;&#30340;&#23454;&#39564;&#26465;&#20214;&#21040;&#24863;&#20852;&#36259;&#30340;&#32467;&#26524;&#30340;&#26144;&#23556;&#65292;&#20294;&#26159;&#22788;&#29702;&#22823;&#37327;&#21487;&#33021;&#30340;&#24178;&#39044;&#32452;&#21512;&#31354;&#38388;&#24456;&#22256;&#38590;&#12290;&#22312;&#20856;&#22411;&#30340;&#31232;&#30095;&#23454;&#39564;&#35774;&#35745;&#19979;&#65292;&#22914;&#26524;&#19981;&#20381;&#36182;&#20110;&#37325;&#30340;&#35268;&#21017;&#21270;&#25110;&#20808;&#39564;&#20998;&#24067;&#65292;&#36825;&#31181;&#26144;&#23556;&#26159;&#19981;&#36866;&#24403;&#30340;&#12290;&#36825;&#26679;&#30340;&#20551;&#35774;&#21487;&#33021;&#26159;&#21487;&#38752;&#30340;&#65292;&#20063;&#21487;&#33021;&#26159;&#19981;&#21487;&#38752;&#30340;&#65292;&#24456;&#38590;&#36777;&#25252;&#25110;&#27979;&#35797;&#12290;&#26412;&#25991;&#20174;&#22240;&#23376;&#22270;&#27169;&#22411;&#30340;&#35821;&#35328;&#35282;&#24230;&#28145;&#20837;&#25506;&#35752;&#22914;&#20309;&#20445;&#35777;&#20174;&#36807;&#21435;&#30340;&#23454;&#39564;&#21040;&#26032;&#30340;&#26465;&#20214;&#30340;&#36291;&#36801;&#65292;&#20165;&#22522;&#20110;&#23545;&#25805;&#32437;&#31995;&#32479;&#20998;&#24067;&#30340;&#22240;&#23376;&#20998;&#35299;&#30340;&#26368;&#23567;&#20551;&#35774;&#12290;&#20551;&#35774;&#30340;&#8220;&#24178;&#39044;&#22240;&#23376;&#27169;&#22411;&#8221;&#21487;&#33021;&#24182;&#19981;&#24635;&#26159;&#26377;&#29992;&#30340;&#65292;&#20294;&#26159;&#23427;&#24456;&#26041;&#20415;&#22320;&#22788;&#29702;&#20102;&#22823;&#37327;&#21487;&#33021;&#30340;&#24178;&#39044;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
One of the goals of causal inference is to generalize from past experiments and observational data to novel conditions. While it is in principle possible to eventually learn a mapping from a novel experimental condition to an outcome of interest, provided a sufficient variety of experiments is available in the training data, coping with a large combinatorial space of possible interventions is hard. Under a typical sparse experimental design, this mapping is ill-posed without relying on heavy regularization or prior distributions. Such assumptions may or may not be reliable, and can be hard to defend or test. In this paper, we take a close look at how to warrant a leap from past experiments to novel conditions based on minimal assumptions about the factorization of the distribution of the manipulated system, communicated in the well-understood language of factor graph models. A postulated $\textit{interventional factor model}$ (IFM) may not always be informative, but it conveniently abs
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#32593;&#32476;&#23398;&#20064;&#30340;&#36816;&#31639;&#31526;&#26159;&#21542;&#26159;&#21333;&#23556;&#21644;&#28385;&#23556;&#30340;&#24773;&#20917;&#65292;&#24182;&#32473;&#20986;&#20102;&#31934;&#30830;&#26465;&#20214;&#12290;&#23427;&#20204;&#25552;&#20379;&#30340;&#21333;&#23556;&#31070;&#32463;&#36816;&#31639;&#31526;&#26159;&#36890;&#29992;&#36924;&#36817;&#22120;&#65292;&#24182;&#19988;&#20351;&#29992;&#26377;&#38480;&#31209;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#23427;&#20204;&#65292;&#20351;&#24471;&#32593;&#32476;&#20173;&#28982;&#21333;&#23556;&#12290;</title><link>http://arxiv.org/abs/2306.03982</link><description>&lt;p&gt;
&#20840;&#29699;&#21487;&#27979;&#21644;&#21487;&#36870;&#31070;&#32463;&#36816;&#31639;&#31526;
&lt;/p&gt;
&lt;p&gt;
Globally injective and bijective neural operators. (arXiv:2306.03982v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03982
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#32593;&#32476;&#23398;&#20064;&#30340;&#36816;&#31639;&#31526;&#26159;&#21542;&#26159;&#21333;&#23556;&#21644;&#28385;&#23556;&#30340;&#24773;&#20917;&#65292;&#24182;&#32473;&#20986;&#20102;&#31934;&#30830;&#26465;&#20214;&#12290;&#23427;&#20204;&#25552;&#20379;&#30340;&#21333;&#23556;&#31070;&#32463;&#36816;&#31639;&#31526;&#26159;&#36890;&#29992;&#36924;&#36817;&#22120;&#65292;&#24182;&#19988;&#20351;&#29992;&#26377;&#38480;&#31209;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#23427;&#20204;&#65292;&#20351;&#24471;&#32593;&#32476;&#20173;&#28982;&#21333;&#23556;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22312;&#36816;&#31639;&#23398;&#20064;&#39046;&#22495;&#65292;&#32593;&#32476;&#20174;&#22522;&#26412;&#19978;&#26080;&#38480;&#32500;&#24230;&#30340;&#35270;&#35282;&#23398;&#20064;&#20989;&#25968;&#31354;&#38388;&#20043;&#38388;&#30340;&#36816;&#31639;&#31526;&#65292;&#25105;&#20204;&#38024;&#23545;&#32593;&#32476;&#23398;&#20064;&#30340;&#36816;&#31639;&#31526;&#26159;&#21333;&#23556;&#21644;&#28385;&#23556;&#30340;&#24773;&#20917;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently there has been great interest in operator learning, where networks learn operators between function spaces from an essentially infinite-dimensional perspective. In this work we present results for when the operators learned by these networks are injective and surjective. As a warmup, we combine prior work in both the finite-dimensional ReLU and operator learning setting by giving sharp conditions under which ReLU layers with linear neural operators are injective. We then consider the case the case when the activation function is pointwise bijective and obtain sufficient conditions for the layer to be injective. We remark that this question, while trivial in the finite-rank case, is subtler in the infinite-rank case and is proved using tools from Fredholm theory. Next, we prove that our supplied injective neural operators are universal approximators and that their implementation, with finite-rank neural networks, are still injective. This ensures that injectivity is not `lost' 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#31070;&#32463;&#20999;&#21521;&#26680;&#30340;&#38543;&#26426;&#36793;&#38469;&#20284;&#28982;&#26799;&#24230;&#65292;&#21487;&#20197;&#21152;&#36895;&#22522;&#20110;&#26799;&#24230;&#30340;&#36229;&#21442;&#25968;&#20248;&#21270;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2306.03968</link><description>&lt;p&gt;
&#20351;&#29992;&#31070;&#32463;&#20999;&#21521;&#26680;&#30340;&#38543;&#26426;&#36793;&#38469;&#20284;&#28982;&#26799;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic Marginal Likelihood Gradients using Neural Tangent Kernels. (arXiv:2306.03968v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03968
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#31070;&#32463;&#20999;&#21521;&#26680;&#30340;&#38543;&#26426;&#36793;&#38469;&#20284;&#28982;&#26799;&#24230;&#65292;&#21487;&#20197;&#21152;&#36895;&#22522;&#20110;&#26799;&#24230;&#30340;&#36229;&#21442;&#25968;&#20248;&#21270;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36873;&#25321;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#36229;&#21442;&#25968;&#23545;&#20854;&#26377;&#25928;&#24615;&#26377;&#37325;&#22823;&#24433;&#21709;&#65292;&#20294;&#38656;&#35201;&#20154;&#24037;&#21162;&#21147;&#21644;&#19987;&#19994;&#30693;&#35782;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#20351;&#29992;&#25289;&#26222;&#25289;&#26031;&#36817;&#20284;&#30340;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#33021;&#22815;&#20687;&#20351;&#29992;&#26799;&#24230;&#20248;&#21270;&#26631;&#20934;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#19968;&#26679;&#20248;&#21270;&#36825;&#20123;&#36229;&#21442;&#25968;&#65292;&#24182;&#20351;&#29992;&#35757;&#32451;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#12290;&#28982;&#32780;&#65292;&#20272;&#35745;&#21333;&#20010;&#36229;&#21442;&#25968;&#26799;&#24230;&#38656;&#35201;&#36890;&#36807;&#25972;&#20010;&#25968;&#25454;&#38598;&#65292;&#38480;&#21046;&#20102;&#36825;&#20123;&#31639;&#27861;&#30340;&#21487;&#20280;&#32553;&#24615;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#32447;&#24615;&#21270;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#30340;&#19979;&#38480;&#26469;&#20811;&#26381;&#36825;&#20010;&#38382;&#39064;&#12290;&#19982;&#20197;&#21069;&#30340;&#20272;&#35745;&#22120;&#19981;&#21516;&#65292;&#36825;&#20123;&#19979;&#38480;&#36866;&#29992;&#20110;&#22522;&#20110;&#38543;&#26426;&#26799;&#24230;&#30340;&#20248;&#21270;&#65292;&#24182;&#20801;&#35768;&#22312;&#20272;&#35745;&#31934;&#24230;&#21644;&#35745;&#31639;&#22797;&#26434;&#24615;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#12290;&#25105;&#20204;&#20351;&#29992;&#32447;&#24615;&#21270;&#25289;&#26222;&#25289;&#26031;&#30340;&#20989;&#25968;&#31354;&#38388;&#24418;&#24335;&#23548;&#20986;&#20102;&#23427;&#20204;&#65292;&#36825;&#21487;&#20197;&#20351;&#29992;&#31070;&#32463;&#20999;&#21521;&#26680;&#36827;&#34892;&#20272;&#35745;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#20272;&#35745;&#22120;&#21487;&#20197;&#26174;&#33879;&#21152;&#36895;&#22522;&#20110;&#26799;&#24230;&#30340;&#36229;&#21442;&#25968;&#20248;&#21270;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Selecting hyperparameters in deep learning greatly impacts its effectiveness but requires manual effort and expertise. Recent works show that Bayesian model selection with Laplace approximations can allow to optimize such hyperparameters just like standard neural network parameters using gradients and on the training data. However, estimating a single hyperparameter gradient requires a pass through the entire dataset, limiting the scalability of such algorithms. In this work, we overcome this issue by introducing lower bounds to the linearized Laplace approximation of the marginal likelihood. In contrast to previous estimators, these bounds are amenable to stochastic-gradient-based optimization and allow to trade off estimation accuracy against computational complexity. We derive them using the function-space form of the linearized Laplace, which can be estimated using the neural tangent kernel. Experimentally, we show that the estimators can significantly accelerate gradient-based hyp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#31639;&#27861; PILLAR&#65292;&#21487;&#20197;&#22312;&#21322;&#30417;&#30563;&#21322;&#31169;&#26377;&#65288;SP&#65289;&#23398;&#20064;&#20013;&#26126;&#26174;&#38477;&#20302;&#31169;&#26377;&#26631;&#35760;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#21487;&#20197;&#22312;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#39640;&#25928;&#36816;&#34892;&#65292;&#21487;&#20197;&#21033;&#29992;&#22312;&#20844;&#20849;&#25968;&#25454;&#19978;&#39044;&#35757;&#32451;&#30340;&#32593;&#32476;&#25552;&#21462;&#30340;&#29305;&#24449;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#26174;&#33879;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.03962</link><description>&lt;p&gt;
PILLAR&#65306;&#22914;&#20309;&#20351;&#21322;&#31169;&#26377;&#23398;&#20064;&#26356;&#26377;&#25928;
&lt;/p&gt;
&lt;p&gt;
PILLAR: How to make semi-private learning more effective. (arXiv:2306.03962v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03962
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#31639;&#27861; PILLAR&#65292;&#21487;&#20197;&#22312;&#21322;&#30417;&#30563;&#21322;&#31169;&#26377;&#65288;SP&#65289;&#23398;&#20064;&#20013;&#26126;&#26174;&#38477;&#20302;&#31169;&#26377;&#26631;&#35760;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#21487;&#20197;&#22312;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#39640;&#25928;&#36816;&#34892;&#65292;&#21487;&#20197;&#21033;&#29992;&#22312;&#20844;&#20849;&#25968;&#25454;&#19978;&#39044;&#35757;&#32451;&#30340;&#32593;&#32476;&#25552;&#21462;&#30340;&#29305;&#24449;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#26174;&#33879;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21322;&#30417;&#30563;&#21322;&#31169;&#26377;&#65288;SP&#65289;&#23398;&#20064;&#20013;&#65292;&#23398;&#20064;&#32773;&#21487;&#20197;&#35775;&#38382;&#20844;&#20849;&#30340;&#26410;&#26631;&#35760;&#25968;&#25454;&#21644;&#31169;&#26377;&#30340;&#26631;&#35760;&#25968;&#25454;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#31639;&#27861;&#65292;&#20551;&#35774;&#25968;&#25454;&#31526;&#21512;&#19968;&#23450;&#26465;&#20214;&#65292;&#21487;&#20197;&#26126;&#26174;&#38477;&#20302;&#31169;&#26377;&#26631;&#35760;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#21487;&#20197;&#22312;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#39640;&#25928;&#36816;&#34892;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#21033;&#29992;&#22312;&#20844;&#20849;&#25968;&#25454;&#65288;&#26631;&#35760;&#25110;&#26410;&#26631;&#35760;&#65289;&#19978;&#39044;&#35757;&#32451;&#30340;&#32593;&#32476;&#25552;&#21462;&#30340;&#29305;&#24449;&#65292;&#36825;&#20123;&#29305;&#24449;&#30340;&#20998;&#24067;&#21487;&#33021;&#19982;&#36827;&#34892;SP&#23398;&#20064;&#30340;&#20998;&#24067;&#26174;&#33879;&#19981;&#21516;&#12290;&#20026;&#20102;&#39564;&#35777;&#20854;&#23454;&#35777;&#26377;&#25928;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22810;&#31181;&#22312;&#20005;&#26684;&#30340;&#38544;&#31169;&#32422;&#26463;&#65288;\(\epsilon=0.1\))&#21644;&#20302;&#25968;&#25454;&#37327;&#24773;&#20917;&#19979;&#30340;&#23454;&#39564;&#12290;&#22312;&#25152;&#26377;&#36825;&#20123;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#34920;&#29616;&#20986;&#26174;&#33879;&#20248;&#20110;&#20351;&#29992;&#31867;&#20284;&#25968;&#37327;&#30340;&#20844;&#20849;&#25968;&#25454;&#30340;&#29616;&#26377;&#22522;&#32447;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In Semi-Supervised Semi-Private (SP) learning, the learner has access to both public unlabelled and private labelled data. We propose a computationally efficient algorithm that, under mild assumptions on the data, provably achieves significantly lower private labelled sample complexity and can be efficiently run on real-world datasets. For this purpose, we leverage the features extracted by networks pre-trained on public (labelled or unlabelled) data, whose distribution can significantly differ from the one on which SP learning is performed. To validate its empirical effectiveness, we propose a wide variety of experiments under tight privacy constraints (\(\epsilon=0.1\)) and with a focus on low-data regimes. In all of these settings, our algorithm exhibits significantly improved performance over available baselines that use similar amounts of public data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20351;&#29992;&#38543;&#26426;&#36873;&#25321;&#32431;&#37327;&#20998;&#35299;&#31639;&#27861;&#30340;&#26680;&#27714;&#31215;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#36798;&#21040;&#21487;&#27604;&#30340;&#27714;&#31215;&#35823;&#24046;&#36798;&#21040;&#29575;&#30340;&#21516;&#26102;&#26174;&#33879;&#38477;&#20302;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#24182;&#21487;&#20197;&#24212;&#29992;&#20110;&#20219;&#24847;&#26680;&#30340;&#22797;&#26434;&#20960;&#20309;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2306.03955</link><description>&lt;p&gt;
&#38543;&#26426;&#36873;&#25321;&#32431;&#37327;&#20998;&#35299;&#30340;&#26680;&#27714;&#31215;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Kernel Quadrature with Randomly Pivoted Cholesky. (arXiv:2306.03955v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03955
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20351;&#29992;&#38543;&#26426;&#36873;&#25321;&#32431;&#37327;&#20998;&#35299;&#31639;&#27861;&#30340;&#26680;&#27714;&#31215;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#36798;&#21040;&#21487;&#27604;&#30340;&#27714;&#31215;&#35823;&#24046;&#36798;&#21040;&#29575;&#30340;&#21516;&#26102;&#26174;&#33879;&#38477;&#20302;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#24182;&#21487;&#20197;&#24212;&#29992;&#20110;&#20219;&#24847;&#26680;&#30340;&#22797;&#26434;&#20960;&#20309;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#38543;&#26426;&#36873;&#25321;&#32431;&#37327;&#20998;&#35299;&#30340;&#37319;&#26679;&#31639;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37325;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20989;&#25968;&#27714;&#31215;&#35268;&#21017;&#12290;&#25152;&#24471;&#30340;&#35745;&#31639;&#36807;&#31243;&#19982;&#26082;&#26377;&#30340;&#26680;&#27714;&#31215;&#26041;&#27861;&#30456;&#27604;&#65292;&#22312;&#31934;&#24230;&#21644;&#27714;&#35299;&#22797;&#26434;&#24230;&#26041;&#38754;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#29702;&#35770;&#21644;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#38543;&#26426;&#36873;&#25321;&#32431;&#37327;&#20998;&#35299;&#30340;&#26041;&#27861;&#24555;&#36895;&#19988;&#20855;&#26377;&#21487;&#27604;&#30340;&#27714;&#31215;&#35823;&#24046;&#36798;&#21040;&#29575;&#65292;&#19982;&#22522;&#20110;&#36830;&#32493;&#20307;&#31215;&#37319;&#26679;&#12289;&#31232;&#30095;&#21270;&#21644;&#37325;&#32452;&#30340;&#26356;&#20026;&#26114;&#36149;&#30340;&#27714;&#31215;&#26041;&#26696;&#30456;&#21305;&#37197;&#12290;&#38543;&#26426;&#36873;&#25321;&#32431;&#37327;&#20998;&#35299;&#26131;&#20110;&#36866;&#24212;&#20219;&#24847;&#26680;&#30340;&#22797;&#26434;&#20960;&#20309;&#32467;&#26500;&#65292;&#20026;&#26680;&#27714;&#31215;&#24320;&#36767;&#20102;&#26032;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents new quadrature rules for functions in a reproducing kernel Hilbert space using nodes drawn by a sampling algorithm known as randomly pivoted Cholesky. The resulting computational procedure compares favorably to previous kernel quadrature methods, which either achieve low accuracy or require solving a computationally challenging sampling problem. Theoretical and numerical results show that randomly pivoted Cholesky is fast and achieves comparable quadrature error rates to more computationally expensive quadrature schemes based on continuous volume sampling, thinning, and recombination. Randomly pivoted Cholesky is easily adapted to complicated geometries with arbitrary kernels, unlocking new potential for kernel quadrature.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#32467;&#26500;&#21270;&#39044;&#27979;&#20013;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#29983;&#25104;&#27169;&#22411;&#21644;&#20984;&#20248;&#21270;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#21487;&#35777;&#26126;&#20445;&#35777;&#30340;&#37096;&#20998;&#26631;&#31614;&#24674;&#22797;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.03949</link><description>&lt;p&gt;
&#32467;&#26500;&#21270;&#39044;&#27979;&#20013;&#30340;&#37096;&#20998;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Partial Inference in Structured Prediction. (arXiv:2306.03949v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03949
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32467;&#26500;&#21270;&#39044;&#27979;&#20013;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#29983;&#25104;&#27169;&#22411;&#21644;&#20984;&#20248;&#21270;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#21487;&#35777;&#26126;&#20445;&#35777;&#30340;&#37096;&#20998;&#26631;&#31614;&#24674;&#22797;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#32467;&#26500;&#21270;&#39044;&#27979;&#20013;&#37096;&#20998;&#25512;&#26029;&#30340;&#38382;&#39064;&#12290;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#26041;&#27861;&#65292;&#30740;&#31350;&#22312;&#26631;&#31614;&#22270;&#19978;&#26368;&#22823;&#21270;&#19968;&#31181;&#21253;&#21547;&#19968;&#20803;&#21644;&#20108;&#20803;&#22240;&#23376;&#30340;&#35780;&#20998;&#20989;&#25968;&#30340;&#20219;&#21153;&#12290;&#36890;&#36807;&#37319;&#29992;&#20004;&#38454;&#27573;&#20984;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#26631;&#31614;&#24674;&#22797;&#65292;&#20998;&#26512;&#20102;&#22823;&#22810;&#25968;&#26631;&#31614;&#21487;&#24674;&#22797;&#30340;&#26465;&#20214;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;Karush-Kuhn-Tucker&#65288;KKT&#65289;&#26465;&#20214;&#21644;&#21407;&#22987;&#23545;&#20598;&#26500;&#36896;&#30340;&#35266;&#28857;&#65292;&#24182;&#25552;&#20379;&#20102;&#20855;&#26377;&#21487;&#35777;&#26126;&#20445;&#35777;&#30340;&#37096;&#20998;&#24674;&#22797;&#30340;&#32479;&#35745;&#21644;&#25299;&#25169;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we examine the problem of partial inference in the context of structured prediction. Using a generative model approach, we consider the task of maximizing a score function with unary and pairwise potentials in the space of labels on graphs. Employing a two-stage convex optimization algorithm for label recovery, we analyze the conditions under which a majority of the labels can be recovered. We introduce a novel perspective on the Karush-Kuhn-Tucker (KKT) conditions and primal and dual construction, and provide statistical and topological requirements for partial recovery with provable guarantees.
&lt;/p&gt;</description></item><item><title>&#35813;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20999;&#25442;&#33258;&#22238;&#24402;&#20302;&#31209;&#24352;&#37327;&#65288;SALT&#65289;&#27169;&#22411;&#65292;&#23427;&#23558;&#33258;&#22238;&#24402;&#38544;Markov&#27169;&#22411;&#65288;ARHMM&#65289;&#21644;&#20999;&#25442;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#65288;SLDS&#65289;&#30340;&#20248;&#28857;&#32467;&#21512;&#36215;&#26469;&#65292;&#36890;&#36807;&#20302;&#31209;&#21442;&#25968;&#21270;&#25552;&#39640;&#20102;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.03291</link><description>&lt;p&gt;
&#20999;&#25442;&#33258;&#22238;&#24402;&#20302;&#31209;&#24352;&#37327;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Switching Autoregressive Low-rank Tensor Models. (arXiv:2306.03291v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03291
&lt;/p&gt;
&lt;p&gt;
&#35813;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20999;&#25442;&#33258;&#22238;&#24402;&#20302;&#31209;&#24352;&#37327;&#65288;SALT&#65289;&#27169;&#22411;&#65292;&#23427;&#23558;&#33258;&#22238;&#24402;&#38544;Markov&#27169;&#22411;&#65288;ARHMM&#65289;&#21644;&#20999;&#25442;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#65288;SLDS&#65289;&#30340;&#20248;&#28857;&#32467;&#21512;&#36215;&#26469;&#65292;&#36890;&#36807;&#20302;&#31209;&#21442;&#25968;&#21270;&#25552;&#39640;&#20102;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#24207;&#20998;&#26512;&#20013;&#19968;&#20010;&#37325;&#35201;&#30340;&#38382;&#39064;&#26159;&#23545;&#20855;&#26377;&#26102;&#21464;&#21160;&#21147;&#23398;&#30340;&#31995;&#32479;&#36827;&#34892;&#24314;&#27169;&#12290;&#20849;&#21516;&#36830;&#32493;&#21644;&#31163;&#25955;&#28508;&#24577;&#30340;&#27010;&#29575;&#27169;&#22411;&#20026;&#36825;&#26679;&#30340;&#25968;&#25454;&#25552;&#20379;&#20102;&#21487;&#35299;&#37322;&#12289;&#39640;&#25928;&#21644;&#23454;&#39564;&#24615;&#26377;&#29992;&#30340;&#25551;&#36848;&#12290;&#24120;&#29992;&#30340;&#27169;&#22411;&#21253;&#25324;&#33258;&#22238;&#24402;&#38544;Markov&#27169;&#22411;&#65288;ARHMM&#65289;&#21644;&#20999;&#25442;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#65288;SLDS&#65289;&#65292;&#23427;&#20204;&#21508;&#26377;&#20248;&#32570;&#28857;&#12290;ARHMM&#20801;&#35768;&#31934;&#30830;&#25512;&#29702;&#21644;&#31616;&#21333;&#30340;&#21442;&#25968;&#20272;&#35745;&#65292;&#20294;&#22312;&#23545;&#38271;&#20381;&#36182;&#20851;&#31995;&#24314;&#27169;&#26102;&#20855;&#26377;&#21442;&#25968;&#23494;&#38598;&#24615;&#65292;&#22240;&#27492;&#23481;&#26131;&#20986;&#29616;&#36807;&#25311;&#21512;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#36890;&#36807;&#39532;&#23572;&#21487;&#22827;&#28508;&#24577;&#21160;&#21147;&#23398;&#65292;SLDS&#21487;&#20197;&#20197;&#21442;&#25968;&#39640;&#25928;&#30340;&#26041;&#24335;&#25429;&#25417;&#38271;&#36317;&#31163;&#20381;&#36182;&#24615;&#65292;&#20294;&#22256;&#38590;&#30340;&#21442;&#25968;&#20272;&#35745;&#20219;&#21153;&#21644;&#19968;&#20010;&#38590;&#20197;&#22788;&#29702;&#30340;&#20284;&#28982;&#20989;&#25968;&#21364;&#26159;&#20854;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22320;&#26041;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20999;&#25442;&#33258;&#22238;&#24402;&#20302;&#31209;&#24352;&#37327;&#65288;SALT&#65289;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20445;&#30041;&#20102;&#20004;&#31181;&#26041;&#27861;&#30340;&#20248;&#28857;&#65292;&#21516;&#26102;&#25913;&#21892;&#20102;&#20854;&#23616;&#38480;&#24615;&#12290;SALT&#23558;ARHMM&#30340;&#24352;&#37327;&#21442;&#25968;&#21270;&#20026;&#20302;&#31209;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
An important problem in time-series analysis is modeling systems with time-varying dynamics. Probabilistic models with joint continuous and discrete latent states offer interpretable, efficient, and experimentally useful descriptions of such data. Commonly used models include autoregressive hidden Markov models (ARHMMs) and switching linear dynamical systems (SLDSs), each with its own advantages and disadvantages. ARHMMs permit exact inference and easy parameter estimation, but are parameter intensive when modeling long dependencies, and hence are prone to overfitting. In contrast, SLDSs can capture long-range dependencies in a parameter efficient way through Markovian latent dynamics, but present an intractable likelihood and a challenging parameter estimation task. In this paper, we propose switching autoregressive low-rank tensor (SALT) models, which retain the advantages of both approaches while ameliorating the weaknesses. SALT parameterizes the tensor of an ARHMM with a low-rank 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;Equity-Transformer&#26469;&#35299;&#20915;&#22823;&#35268;&#27169;&#30340;&#26368;&#23567;&#26368;&#22823;&#36335;&#24452;&#38382;&#39064;&#12290;&#35813;&#27169;&#22411;&#21033;&#29992;&#21487;&#25193;&#23637;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#39034;&#24207;&#20915;&#31574;&#65292;&#24182;&#29983;&#25104;&#32771;&#34385;&#20844;&#24179;&#24037;&#20316;&#36127;&#36733;&#30340;&#39034;&#24207;&#21160;&#20316;&#12290;&#30740;&#31350;&#26174;&#31034;&#65292;Equity-Transformer&#22312;&#20004;&#20010;&#20195;&#34920;&#24615;&#26368;&#23567;&#26368;&#22823;&#36335;&#24452;&#38382;&#39064;&#20013;&#20855;&#26377;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.02689</link><description>&lt;p&gt;
&#23558;NP&#22256;&#38590;&#30340;&#26368;&#23567;&#26368;&#22823;&#36335;&#24452;&#38382;&#39064;&#20316;&#20026;&#20855;&#26377;&#20844;&#24179;&#32972;&#26223;&#30340;&#39034;&#24207;&#29983;&#25104;&#26469;&#35299;&#20915;
&lt;/p&gt;
&lt;p&gt;
Solving NP-hard Min-max Routing Problems as Sequential Generation with Equity Context. (arXiv:2306.02689v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02689
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;Equity-Transformer&#26469;&#35299;&#20915;&#22823;&#35268;&#27169;&#30340;&#26368;&#23567;&#26368;&#22823;&#36335;&#24452;&#38382;&#39064;&#12290;&#35813;&#27169;&#22411;&#21033;&#29992;&#21487;&#25193;&#23637;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#39034;&#24207;&#20915;&#31574;&#65292;&#24182;&#29983;&#25104;&#32771;&#34385;&#20844;&#24179;&#24037;&#20316;&#36127;&#36733;&#30340;&#39034;&#24207;&#21160;&#20316;&#12290;&#30740;&#31350;&#26174;&#31034;&#65292;Equity-Transformer&#22312;&#20004;&#20010;&#20195;&#34920;&#24615;&#26368;&#23567;&#26368;&#22823;&#36335;&#24452;&#38382;&#39064;&#20013;&#20855;&#26377;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#23567;&#26368;&#22823;&#36335;&#24452;&#38382;&#39064;&#26088;&#22312;&#26368;&#23567;&#21270;&#25152;&#26377;&#20195;&#29702;&#21830;&#21327;&#21516;&#35775;&#38382;&#25152;&#26377;&#22478;&#24066;&#30340;&#26368;&#22823;&#26053;&#28216;&#38271;&#24230;&#65292;&#21363;&#23436;&#25104;&#26102;&#38388;&#12290;&#36825;&#20123;&#38382;&#39064;&#21253;&#25324;&#26377;&#24433;&#21709;&#21147;&#30340;&#23454;&#38469;&#24212;&#29992;&#65292;&#20294;&#34987;&#35748;&#20026;&#26159;NP&#22256;&#38590;&#30340;&#12290;&#29616;&#26377;&#26041;&#27861;&#38754;&#20020;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#22312;&#38656;&#35201;&#21327;&#35843;&#20247;&#22810;&#20195;&#29702;&#21830;&#35206;&#30422;&#25968;&#21315;&#20010;&#22478;&#24066;&#30340;&#22823;&#35268;&#27169;&#38382;&#39064;&#20013;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#26469;&#35299;&#20915;&#22823;&#35268;&#27169;&#30340;&#26368;&#23567;&#26368;&#22823;&#36335;&#24452;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#22810;&#20010;&#20195;&#29702;&#21830;&#30340;&#21516;&#26102;&#20915;&#31574;&#24314;&#27169;&#20026;&#39034;&#24207;&#29983;&#25104;&#36807;&#31243;&#65292;&#20801;&#35768;&#21033;&#29992;&#21487;&#25193;&#23637;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#39034;&#24207;&#20915;&#31574;&#12290;&#22312;&#39034;&#24207;&#36817;&#20284;&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#19978;&#19979;&#25991;Transformer&#27169;&#22411;Equity-Transformer&#65292;&#23427;&#29983;&#25104;&#32771;&#34385;&#20854;&#20182;&#20195;&#29702;&#21830;&#20043;&#38388;&#20844;&#24179;&#24037;&#20316;&#36127;&#36733;&#30340;&#39034;&#24207;&#21160;&#20316;&#12290;Equity-Transformer&#30340;&#26377;&#25928;&#24615;&#36890;&#36807;&#20854;&#22312;&#20004;&#20010;&#20195;&#34920;&#24615;&#26368;&#23567;&#26368;&#22823;&#36335;&#24452;&#38382;&#39064;&#20013;&#20855;&#26377;&#21331;&#36234;&#30340;&#24615;&#33021;&#24471;&#21040;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Min-max routing problems aim to minimize the maximum tour length among agents as they collaboratively visit all cities, i.e., the completion time. These problems include impactful real-world applications but are known as NP-hard. Existing methods are facing challenges, particularly in large-scale problems that require the coordination of numerous agents to cover thousands of cities. This paper proposes a new deep-learning framework to solve large-scale min-max routing problems. We model the simultaneous decision-making of multiple agents as a sequential generation process, allowing the utilization of scalable deep-learning models for sequential decision-making. In the sequentially approximated problem, we propose a scalable contextual Transformer model, Equity-Transformer, which generates sequential actions considering an equitable workload among other agents. The effectiveness of Equity-Transformer is demonstrated through its superior performance in two representative min-max routing 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Meta-SAGE&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#32452;&#21512;&#20248;&#21270;&#20219;&#21153;&#20013;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#21487;&#25193;&#23637;&#24615;&#30340;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#27604;&#20363;&#20803;&#23398;&#20064;&#21644;&#26102;&#38388;&#34920;&#35843;&#25972;&#26469;&#36866;&#24212;&#27169;&#22411;&#65292;&#24182;&#30495;&#23454;&#22320;&#20248;&#21270;&#20102;&#30456;&#20851;&#20219;&#21153;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.02688</link><description>&lt;p&gt;
Meta-SAGE&#65306;&#29992;&#24341;&#23548;&#25506;&#32034;&#30340;&#35268;&#21010;&#26041;&#27861;&#21644;&#27604;&#20363;&#19968;&#20803;&#23398;&#20064;&#36827;&#34892;&#21327;&#21516;&#20248;&#21270;&#35268;&#27169;&#20559;&#31227;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Meta-SAGE: Scale Meta-Learning Scheduled Adaptation with Guided Exploration for Mitigating Scale Shift on Combinatorial Optimization. (arXiv:2306.02688v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02688
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Meta-SAGE&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#32452;&#21512;&#20248;&#21270;&#20219;&#21153;&#20013;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#21487;&#25193;&#23637;&#24615;&#30340;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#27604;&#20363;&#20803;&#23398;&#20064;&#21644;&#26102;&#38388;&#34920;&#35843;&#25972;&#26469;&#36866;&#24212;&#27169;&#22411;&#65292;&#24182;&#30495;&#23454;&#22320;&#20248;&#21270;&#20102;&#30456;&#20851;&#20219;&#21153;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20043;&#20026;Meta-SAGE&#30340;&#26032;&#26041;&#27861;&#65292;&#26088;&#22312;&#25913;&#21892;&#32452;&#21512;&#20248;&#21270;&#65288;CO&#65289;&#20219;&#21153;&#30340;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;&#26412;&#26041;&#27861;&#36890;&#36807;&#24314;&#35758;&#20004;&#20010;&#32452;&#20214;&#26469;&#22312;&#27979;&#35797;&#26102;&#38388;&#36866;&#24212;&#39044;&#35757;&#32451;&#27169;&#22411;&#20197;&#35299;&#20915;&#35268;&#27169;&#38382;&#39064;&#65306;&#19968;&#20010;&#26159;&#27604;&#20363;&#20803;&#23398;&#20064;&#22120;&#65288;SML&#65289;&#65292;&#21478;&#19968;&#20010;&#26159;&#20855;&#26377;&#24341;&#23548;&#25506;&#32034;&#21644;&#26102;&#38388;&#34920;&#35843;&#25972;&#21151;&#33021;&#30340;scheduled adaptation with guided exploration&#65288;SAGE&#65289;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;Meta-SAGE&#20248;&#20110;&#20197;&#21069;&#30340;&#36866;&#24212;&#26041;&#27861;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#20102;&#20195;&#34920;&#24615;CO&#20219;&#21153;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes Meta-SAGE, a novel approach for improving the scalability of deep reinforcement learning models for combinatorial optimization (CO) tasks. Our method adapts pre-trained models to larger-scale problems in test time by suggesting two components: a scale meta-learner (SML) and scheduled adaptation with guided exploration (SAGE). First, SML transforms the context embedding for subsequent adaptation of SAGE based on scale information. Then, SAGE adjusts the model parameters dedicated to the context embedding for a specific instance. SAGE introduces locality bias, which encourages selecting nearby locations to determine the next location. The locality bias gradually decays as the model is adapted to the target instance. Results show that Meta-SAGE outperforms previous adaptation methods and significantly improves scalability in representative CO tasks. Our source code is available at https://github.com/kaist-silab/meta-sage
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20803;&#23398;&#20064;&#25511;&#21046;&#21464;&#37327;&#30340;&#26041;&#27861;&#65292;&#21487;&#22312;&#26377;&#38480;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#20943;&#23567;&#33945;&#29305;&#21345;&#32599;&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#65292;&#24182;&#23545;&#22810;&#20010;&#20219;&#21153;&#36827;&#34892;&#22788;&#29702;&#12290;</title><link>http://arxiv.org/abs/2303.04756</link><description>&lt;p&gt;
&#20803;&#23398;&#20064;&#25511;&#21046;&#21464;&#37327;&#65306;&#26377;&#38480;&#25968;&#25454;&#20013;&#26041;&#24046;&#32553;&#20943;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Meta-learning Control Variates: Variance Reduction with Limited Data. (arXiv:2303.04756v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.04756
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20803;&#23398;&#20064;&#25511;&#21046;&#21464;&#37327;&#30340;&#26041;&#27861;&#65292;&#21487;&#22312;&#26377;&#38480;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#20943;&#23567;&#33945;&#29305;&#21345;&#32599;&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#65292;&#24182;&#23545;&#22810;&#20010;&#20219;&#21153;&#36827;&#34892;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25511;&#21046;&#21464;&#37327;&#26159;&#20943;&#23567;&#33945;&#29305;&#21345;&#32599;&#20272;&#35745;&#22120;&#26041;&#24046;&#30340;&#26377;&#21147;&#24037;&#20855;&#65292;&#20294;&#22312;&#26679;&#26412;&#25968;&#37327;&#36739;&#23567;&#30340;&#24773;&#20917;&#19979;&#26500;&#24314;&#26377;&#25928;&#30340;&#25511;&#21046;&#21464;&#37327;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#24403;&#38656;&#35201;&#35745;&#31639;&#22823;&#37327;&#30456;&#20851;&#31215;&#20998;&#26102;&#65292;&#21363;&#20351;&#27599;&#20010;&#20219;&#21153;&#30340;&#26679;&#26412;&#25968;&#24456;&#23569;&#65292;&#20063;&#21487;&#20197;&#21033;&#29992;&#36825;&#20123;&#31215;&#20998;&#20219;&#21153;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#26469;&#25552;&#39640;&#24615;&#33021;&#12290;&#25105;&#20204;&#25152;&#25552;&#20986;&#30340;&#20803;&#23398;&#20064;CV&#65288;Meta-CVs&#65289;&#26041;&#27861;&#21487;&#29992;&#20110;&#22788;&#29702;&#25968;&#30334;&#20010;&#25110;&#25968;&#21315;&#20010;&#20219;&#21153;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;Meta-CVs&#21487;&#20197;&#26174;&#33879;&#20943;&#23567;&#26041;&#24046;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#30830;&#23450;&#20102;Meta-CVs&#25104;&#21151;&#35757;&#32451;&#30340;&#19968;&#33324;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
Control variates can be a powerful tool to reduce the variance of Monte Carlo estimators, but constructing effective control variates can be challenging when the number of samples is small. In this paper, we show that when a large number of related integrals need to be computed, it is possible to leverage the similarity between these integration tasks to improve performance even when the number of samples per task is very small. Our approach, called meta learning CVs (Meta-CVs), can be used for up to hundreds or thousands of tasks. Our empirical assessment indicates that Meta-CVs can lead to significant variance reduction in such settings, and our theoretical analysis establishes general conditions under which Meta-CVs can be successfully trained.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#31616;&#21270;&#65292;&#25552;&#20986;&#20102;&#40654;&#26364;&#27491;&#24120;&#22352;&#26631;&#30340;&#24191;&#20041;&#29256;&#26412;&#65292;&#21487;&#29992;&#20110;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#30340;&#23376;&#27969;&#24418;&#20248;&#21270;&#65292;&#24182;&#20026;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;&#65292;&#26080;&#38656;&#26174;&#24335;&#30697;&#38453;&#27714;&#36870;&#12290;</title><link>http://arxiv.org/abs/2302.09738</link><description>&lt;p&gt;
&#31616;&#21270;&#22522;&#20110;&#21160;&#37327;&#30340;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Simplifying Momentum-based Riemannian Submanifold Optimization. (arXiv:2302.09738v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09738
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#31616;&#21270;&#65292;&#25552;&#20986;&#20102;&#40654;&#26364;&#27491;&#24120;&#22352;&#26631;&#30340;&#24191;&#20041;&#29256;&#26412;&#65292;&#21487;&#29992;&#20110;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#30340;&#23376;&#27969;&#24418;&#20248;&#21270;&#65292;&#24182;&#20026;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;&#65292;&#26080;&#38656;&#26174;&#24335;&#30697;&#38453;&#27714;&#36870;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24102;&#26377;&#21160;&#37327;&#30340;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;&#22312;&#35745;&#31639;&#19978;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#30830;&#20445;&#36845;&#20195;&#20445;&#25345;&#22312;&#23376;&#27969;&#24418;&#19978;&#36890;&#24120;&#38656;&#35201;&#35299;&#20915;&#22256;&#38590;&#30340;&#24494;&#20998;&#26041;&#31243;&#12290;&#26412;&#25991;&#38024;&#23545;&#20855;&#26377;&#20223;&#23556;&#19981;&#21464;&#24230;&#37327;&#30340;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#30340;&#23376;&#27969;&#24418;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#31616;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#40654;&#26364;&#27491;&#24120;&#22352;&#26631;&#30340;&#24191;&#20041;&#29256;&#26412;&#65292;&#21487;&#20197;&#23558;&#38382;&#39064;&#21160;&#24577;&#22320;&#31616;&#21270;&#20026;&#27431;&#20960;&#37324;&#24471;&#26080;&#32422;&#26463;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#26469;&#35299;&#37322;&#21644;&#31616;&#21270;&#29616;&#26377;&#30340;&#32467;&#26500;&#21270;&#21327;&#26041;&#24046;&#26041;&#27861;&#65292;&#24182;&#20026;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;&#65292;&#32780;&#26080;&#38656;&#26174;&#24335;&#30697;&#38453;&#27714;&#36870;&#12290;
&lt;/p&gt;
&lt;p&gt;
Riemannian submanifold optimization with momentum is computationally challenging because ensuring iterates remain on the submanifold often requires solving difficult differential equations. We simplify such optimization algorithms for the submanifold of symmetric positive-definite matrices with the affine invariant metric. We propose a generalized version of the Riemannian normal coordinates which dynamically trivializes the problem into a Euclidean unconstrained problem. We use our approach to explain and simplify existing approaches for structured covariances and develop efficient second-order optimizers for deep learning without explicit matrix inverses.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#31350;&#20102;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;&#36801;&#31227;&#23398;&#20064;&#22312;&#20302;&#25968;&#25454;&#29366;&#24577;&#19979;&#30340;&#25968;&#25454;&#32553;&#25918;&#65292;&#21457;&#29616;&#20102;&#19968;&#31181;&#31216;&#20026;&#24748;&#23830;&#23398;&#20064;&#30340;&#29616;&#35937;&#65292;&#23427;&#21453;&#26144;&#20102;&#23398;&#20064;&#31639;&#27861;&#30340;&#20808;&#39564;&#30693;&#35782;&#19982;&#20219;&#21153;&#20043;&#38388;&#30340;&#20860;&#23481;&#31243;&#24230;&#12290;</title><link>http://arxiv.org/abs/2302.07348</link><description>&lt;p&gt;
&#24748;&#23830;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Cliff-Learning. (arXiv:2302.07348v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07348
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#31350;&#20102;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;&#36801;&#31227;&#23398;&#20064;&#22312;&#20302;&#25968;&#25454;&#29366;&#24577;&#19979;&#30340;&#25968;&#25454;&#32553;&#25918;&#65292;&#21457;&#29616;&#20102;&#19968;&#31181;&#31216;&#20026;&#24748;&#23830;&#23398;&#20064;&#30340;&#29616;&#35937;&#65292;&#23427;&#21453;&#26144;&#20102;&#23398;&#20064;&#31639;&#27861;&#30340;&#20808;&#39564;&#30693;&#35782;&#19982;&#20219;&#21153;&#20043;&#38388;&#30340;&#20860;&#23481;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#36827;&#34892;&#36801;&#31227;&#23398;&#20064;&#22312;&#20302;&#19979;&#28216;&#25968;&#25454;&#29366;&#24577;&#19979;&#30340;&#25968;&#25454;&#32553;&#25918;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#20102;&#19968;&#20010;&#26377;&#36259;&#30340;&#29616;&#35937;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#24748;&#23830;&#23398;&#20064;&#12290;&#24748;&#23830;&#23398;&#20064;&#26159;&#25351;&#22312;&#25968;&#25454;&#32553;&#25918;&#27861;&#21017;&#30340;&#26576;&#20123;&#21306;&#22495;&#20013;&#65292;&#24615;&#33021;&#30340;&#25552;&#21319;&#36895;&#24230;&#24555;&#20110;&#24130;&#24459;&#36895;&#24230;&#30340;&#29616;&#35937;&#65288;&#21363;&#22312;&#23545;&#25968;&#32553;&#25918;&#22270;&#19978;&#30340;&#20985;&#24418;&#21306;&#22495;&#65289;&#12290;&#25105;&#20204;&#23545;&#22522;&#30784;&#27169;&#22411;&#30340;&#24748;&#23830;&#23398;&#20064;&#36827;&#34892;&#20102;&#28145;&#20837;&#35843;&#26597;&#24182;&#30740;&#31350;&#20102;&#36825;&#19968;&#29616;&#35937;&#30340;&#29609;&#20855;&#27169;&#22411;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#24748;&#23830;&#23398;&#20064;&#30340;&#31243;&#24230;&#21453;&#26144;&#20102;&#23398;&#20064;&#31639;&#27861;&#30340;&#20808;&#39564;&#30693;&#35782;&#21644;&#25152;&#23398;&#20219;&#21153;&#20043;&#38388;&#30340;&#20860;&#23481;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the data-scaling of transfer learning from foundation models in the low-downstream-data regime. We observe an intriguing phenomenon which we call cliff-learning. Cliff-learning refers to regions of data-scaling laws where performance improves at a faster than power law rate (i.e. regions of concavity on a log-log scaling plot). We conduct an in-depth investigation of foundation-model cliff-learning and study toy models of the phenomenon. We observe that the degree of cliff-learning reflects the degree of compatibility between the priors of a learning algorithm and the task being learned.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#36870;&#21521;&#21487;&#36776;&#35782;&#21452;&#23556;&#22240;&#26524;&#27169;&#22411;&#65292;&#30830;&#31435;&#20102;&#20854;&#22312;&#19977;&#31181;&#24120;&#35265;&#22240;&#26524;&#32467;&#26500;&#19979;&#30340;&#36870;&#21521;&#21487;&#36776;&#35782;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#26377;&#25928;&#30340;&#36870;&#21521;&#39044;&#27979;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2302.02228</link><description>&lt;p&gt;
&#36870;&#21521;&#21487;&#36776;&#35782;&#21452;&#23556;&#22240;&#26524;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Counterfactual Identifiability of Bijective Causal Models. (arXiv:2302.02228v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02228
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#36870;&#21521;&#21487;&#36776;&#35782;&#21452;&#23556;&#22240;&#26524;&#27169;&#22411;&#65292;&#30830;&#31435;&#20102;&#20854;&#22312;&#19977;&#31181;&#24120;&#35265;&#22240;&#26524;&#32467;&#26500;&#19979;&#30340;&#36870;&#21521;&#21487;&#36776;&#35782;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#26377;&#25928;&#30340;&#36870;&#21521;&#39044;&#27979;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20855;&#26377;&#21452;&#23556;&#29983;&#25104;&#26426;&#21046;&#65288;BGM&#65289;&#30340;&#22240;&#26524;&#27169;&#22411;&#20013;&#30340;&#36870;&#21521;&#21487;&#36776;&#35782;&#24615;&#65292;&#20854;&#20013;BGM&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#20110;&#25991;&#29486;&#20013;&#30340;&#22240;&#26524;&#27169;&#22411;&#31867;&#12290;&#25105;&#20204;&#30830;&#31435;&#20102;&#19977;&#31181;&#24120;&#35265;&#30340;&#20855;&#26377;&#26410;&#35266;&#23519;&#21040;&#28151;&#26434;&#21464;&#37327;&#22240;&#26524;&#32467;&#26500;&#30340;&#36870;&#21521;&#21487;&#36776;&#35782;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#23558;&#23398;&#20064;BGM&#36716;&#21270;&#20026;&#32467;&#26500;&#21270;&#29983;&#25104;&#24314;&#27169;&#12290;&#23398;&#20064;&#21040;&#30340;BGM&#21487;&#20197;&#23454;&#29616;&#26377;&#25928;&#30340;&#36870;&#21521;&#39044;&#27979;&#20272;&#35745;&#65292;&#24182;&#21487;&#20197;&#20351;&#29992;&#21508;&#31181;&#28145;&#24230;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#33719;&#24471;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#35270;&#35273;&#20219;&#21153;&#20013;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#25216;&#26415;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22312;&#29616;&#23454;&#19990;&#30028;&#35270;&#39057;&#27969;&#23186;&#20307;&#20223;&#30495;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study counterfactual identifiability in causal models with bijective generation mechanisms (BGM), a class that generalizes several widely-used causal models in the literature. We establish their counterfactual identifiability for three common causal structures with unobserved confounding, and propose a practical learning method that casts learning a BGM as structured generative modeling. Learned BGMs enable efficient counterfactual estimation and can be obtained using a variety of deep conditional generative models. We evaluate our techniques in a visual task and demonstrate its application in a real-world video streaming simulation task.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#22240;&#26524;&#27169;&#22411; (DCM)&#65292;&#23427;&#21487;&#20197;&#22312;&#21482;&#26377;&#35266;&#27979;&#25968;&#25454;&#21644;&#22240;&#26524;&#22270;&#21487;&#29992;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#24178;&#39044;&#21644;&#21453;&#20107;&#23454;&#25512;&#26029;&#65292;&#20854;&#20855;&#26377;&#36739;&#22909;&#30340;&#34920;&#29616;&#12290;&#21516;&#26102;&#65292;&#35770;&#25991;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#20998;&#26512;&#21453;&#20107;&#23454;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#26356;&#24191;&#27867;&#30340;&#22330;&#26223;&#12290;</title><link>http://arxiv.org/abs/2302.00860</link><description>&lt;p&gt;
&#21033;&#29992;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#24178;&#39044;&#21644;&#21453;&#20107;&#23454;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Interventional and Counterfactual Inference with Diffusion Models. (arXiv:2302.00860v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00860
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#22240;&#26524;&#27169;&#22411; (DCM)&#65292;&#23427;&#21487;&#20197;&#22312;&#21482;&#26377;&#35266;&#27979;&#25968;&#25454;&#21644;&#22240;&#26524;&#22270;&#21487;&#29992;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#24178;&#39044;&#21644;&#21453;&#20107;&#23454;&#25512;&#26029;&#65292;&#20854;&#20855;&#26377;&#36739;&#22909;&#30340;&#34920;&#29616;&#12290;&#21516;&#26102;&#65292;&#35770;&#25991;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#20998;&#26512;&#21453;&#20107;&#23454;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#26356;&#24191;&#27867;&#30340;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#21482;&#26377;&#35266;&#27979;&#25968;&#25454;&#21644;&#22240;&#26524;&#22270;&#21487;&#29992;&#30340;&#22240;&#26524;&#20805;&#20998;&#35774;&#32622;&#20013;&#22238;&#31572;&#35266;&#27979;&#12289;&#24178;&#39044;&#21644;&#21453;&#20107;&#23454;&#26597;&#35810;&#30340;&#38382;&#39064;&#12290;&#21033;&#29992;&#25193;&#25955;&#27169;&#22411;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#25193;&#25955;&#30340;&#22240;&#26524;&#27169;&#22411; (DCM)&#65292;&#26469;&#23398;&#20064;&#29983;&#25104;&#29420;&#29305;&#30340;&#28508;&#22312;&#32534;&#30721;&#30340;&#22240;&#26524;&#26426;&#21046;&#12290;&#36825;&#20123;&#32534;&#30721;&#20351;&#25105;&#20204;&#33021;&#22815;&#22312;&#24178;&#39044;&#19979;&#30452;&#25509;&#37319;&#26679;&#21644;&#36827;&#34892;&#21453;&#20107;&#23454;&#25512;&#26029;&#12290;&#25193;&#25955;&#27169;&#22411;&#22312;&#36825;&#37324;&#26159;&#19968;&#20010;&#33258;&#28982;&#30340;&#36873;&#25321;&#65292;&#22240;&#20026;&#23427;&#20204;&#21487;&#20197;&#23558;&#27599;&#20010;&#33410;&#28857;&#32534;&#30721;&#20026;&#19968;&#20010;&#20195;&#34920;&#22806;&#29983;&#22122;&#22768;&#30340;&#28508;&#22312;&#34920;&#31034;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;&#22312;&#22238;&#31572;&#22240;&#26524;&#26597;&#35810;&#26041;&#38754;&#65292;&#19982;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#30456;&#27604;&#65292;&#26377;&#26174;&#30528;&#30340;&#25913;&#36827;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#32467;&#26524;&#65292;&#20026;&#20998;&#26512;&#19968;&#33324;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#20013;&#30340;&#21453;&#20107;&#23454;&#20272;&#35745;&#25552;&#20379;&#19968;&#31181;&#26041;&#27861;&#65292;&#36825;&#23545;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#20197;&#22806;&#30340;&#35774;&#32622;&#21487;&#33021;&#20063;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of answering observational, interventional, and counterfactual queries in a causally sufficient setting where only observational data and the causal graph are available. Utilizing the recent developments in diffusion models, we introduce diffusion-based causal models (DCM) to learn causal mechanisms, that generate unique latent encodings. These encodings enable us to directly sample under interventions and perform abduction for counterfactuals. Diffusion models are a natural fit here, since they can encode each node to a latent representation that acts as a proxy for exogenous noise. Our empirical evaluations demonstrate significant improvements over existing state-of-the-art methods for answering causal queries. Furthermore, we provide theoretical results that offer a methodology for analyzing counterfactual estimation in general encoder-decoder models, which could be useful in settings beyond our proposed approach.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26377; MCMC &#30340;&#24046;&#20998;&#38544;&#31169;&#20998;&#24067;&#24335;&#36125;&#21494;&#26031;&#32447;&#24615;&#22238;&#24402;&#31639;&#27861;&#65292;&#25552;&#20379;&#20102;&#24555;&#36895;&#29256;&#26412;&#65292;&#20855;&#26377;&#35745;&#31639;&#19978;&#30340;&#20248;&#21183;&#65292;&#24182;&#22312;&#23454;&#38469;&#25968;&#25454;&#21644;&#27169;&#25311;&#25968;&#25454;&#19978;&#36827;&#34892;&#25968;&#23383;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;&#31639;&#27861;&#33021;&#22815;&#25552;&#20379;&#20840;&#38754;&#30340;&#20272;&#35745;&#21644;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2301.13778</link><description>&lt;p&gt;
&#24102;&#26377;MCMC&#30340;&#24046;&#20998;&#38544;&#31169;&#20998;&#24067;&#24335;&#36125;&#21494;&#26031;&#32447;&#24615;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Distributed Bayesian Linear Regression with MCMC. (arXiv:2301.13778v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13778
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26377; MCMC &#30340;&#24046;&#20998;&#38544;&#31169;&#20998;&#24067;&#24335;&#36125;&#21494;&#26031;&#32447;&#24615;&#22238;&#24402;&#31639;&#27861;&#65292;&#25552;&#20379;&#20102;&#24555;&#36895;&#29256;&#26412;&#65292;&#20855;&#26377;&#35745;&#31639;&#19978;&#30340;&#20248;&#21183;&#65292;&#24182;&#22312;&#23454;&#38469;&#25968;&#25454;&#21644;&#27169;&#25311;&#25968;&#25454;&#19978;&#36827;&#34892;&#25968;&#23383;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;&#31639;&#27861;&#33021;&#22815;&#25552;&#20379;&#20840;&#38754;&#30340;&#20272;&#35745;&#21644;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#24067;&#24335;&#24046;&#20998;&#38544;&#31169;&#32447;&#24615;&#22238;&#24402;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#26694;&#26550;&#12290;&#25105;&#20204;&#32771;&#34385;&#21040;&#22312;&#22810;&#20010;&#21442;&#19982;&#26041;&#25317;&#26377;&#37096;&#20998;&#25968;&#25454;&#24182;&#20998;&#20139;&#20854;&#37096;&#20998;&#30340;&#26576;&#20123;&#24635;&#32467;&#32479;&#35745;&#20449;&#24687;&#30340;&#20998;&#24067;&#24335;&#29615;&#22659;&#20013;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#29983;&#25104;&#24335;&#32479;&#35745;&#27169;&#22411;&#65292;&#29992;&#20110;&#31169;&#19979;&#20849;&#20139;&#30340;&#32479;&#35745;&#20449;&#24687;&#65292;&#35813;&#27169;&#22411;&#21033;&#29992;&#20102;&#32447;&#24615;&#22238;&#24402;&#25688;&#35201;&#32479;&#35745;&#20449;&#24687;&#20043;&#38388;&#30340;&#26377;&#29992;&#20998;&#24067;&#20851;&#31995;&#12290;&#22238;&#24402;&#31995;&#25968;&#30340;&#36125;&#21494;&#26031;&#20272;&#35745;&#20027;&#35201;&#36890;&#36807;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#31639;&#27861;&#36827;&#34892;&#65292;&#21516;&#26102;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#24555;&#36895;&#29256;&#26412;&#65292;&#20197;&#22312;&#19968;&#27425;&#36845;&#20195;&#20013;&#25191;&#34892;&#36125;&#21494;&#26031;&#20272;&#35745;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20855;&#26377;&#35745;&#31639;&#19978;&#30340;&#20248;&#21183;&#12290;&#25105;&#20204;&#22312;&#23454;&#38469;&#25968;&#25454;&#21644;&#27169;&#25311;&#25968;&#25454;&#19978;&#25552;&#20379;&#20102;&#25968;&#23383;&#23454;&#39564;&#32467;&#26524;&#65292;&#36825;&#20123;&#32467;&#26524;&#34920;&#26126;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#33021;&#22815;&#25552;&#20379;&#20840;&#38754;&#30340;&#20272;&#35745;&#21644;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel Bayesian inference framework for distributed differentially private linear regression. We consider a distributed setting where multiple parties hold parts of the data and share certain summary statistics of their portions in privacy-preserving noise. We develop a novel generative statistical model for privately shared statistics, which exploits a useful distributional relation between the summary statistics of linear regression. Bayesian estimation of the regression coefficients is conducted mainly using Markov chain Monte Carlo algorithms, while we also provide a fast version to perform Bayesian estimation in one iteration. The proposed methods have computational advantages over their competitors. We provide numerical results on both real and simulated data, which demonstrate that the proposed algorithms provide well-rounded estimation and prediction.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#27491;&#21017;&#21270;&#27969;&#65292;&#19987;&#20026;&#19977;&#32500;&#31354;&#38388;&#20013;&#22810;&#20010;&#29289;&#20307;&#30340;&#20301;&#32622;&#21644;&#26041;&#21521;&#24314;&#27169;&#32780;&#35774;&#35745;&#12290;&#36890;&#36807;&#22312;&#21333;&#20301;&#22235;&#20803;&#25968;&#32676;&#19978;&#23450;&#20041;&#24179;&#28369;&#21644;&#34920;&#29616;&#21147;&#24378;&#30340;&#27969;&#20197;&#21450;&#23450;&#20041;&#36866;&#24403;&#30340;&#23494;&#24230;&#65292;&#22312;&#26059;&#36716;&#32676;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#25105;&#20204;&#21487;&#20197;&#25104;&#21151;&#22320;&#37319;&#26679;&#20998;&#23376;&#26230;&#20307;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2301.11355</link><description>&lt;p&gt;
&#29992;&#20110;&#37319;&#26679;&#20998;&#23376;&#26230;&#20307;&#32467;&#26500;&#30340;&#21018;&#20307;&#27969;
&lt;/p&gt;
&lt;p&gt;
Rigid body flows for sampling molecular crystal structures. (arXiv:2301.11355v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11355
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#27491;&#21017;&#21270;&#27969;&#65292;&#19987;&#20026;&#19977;&#32500;&#31354;&#38388;&#20013;&#22810;&#20010;&#29289;&#20307;&#30340;&#20301;&#32622;&#21644;&#26041;&#21521;&#24314;&#27169;&#32780;&#35774;&#35745;&#12290;&#36890;&#36807;&#22312;&#21333;&#20301;&#22235;&#20803;&#25968;&#32676;&#19978;&#23450;&#20041;&#24179;&#28369;&#21644;&#34920;&#29616;&#21147;&#24378;&#30340;&#27969;&#20197;&#21450;&#23450;&#20041;&#36866;&#24403;&#30340;&#23494;&#24230;&#65292;&#22312;&#26059;&#36716;&#32676;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#25105;&#20204;&#21487;&#20197;&#25104;&#21151;&#22320;&#37319;&#26679;&#20998;&#23376;&#26230;&#20307;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27491;&#21017;&#21270;&#27969;(NF)&#26159;&#19968;&#31867;&#24378;&#22823;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#30001;&#20110;&#20854;&#39640;&#24230;&#28789;&#27963;&#21644;&#34920;&#29616;&#21147;&#65292;&#36817;&#24180;&#26469;&#24191;&#21463;&#27426;&#36814;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#27491;&#21017;&#21270;&#27969;&#65292;&#19987;&#20026;&#19977;&#32500;&#31354;&#38388;&#20013;&#22810;&#20010;&#29289;&#20307;&#30340;&#20301;&#32622;&#21644;&#26041;&#21521;&#24314;&#27169;&#32780;&#35774;&#35745;&#65292;&#20363;&#22914;&#26230;&#20307;&#20013;&#30340;&#20998;&#23376;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#20004;&#20010;&#20851;&#38190;&#24605;&#24819;:&#39318;&#20808;&#65292;&#25105;&#20204;&#22312;&#21333;&#20301;&#22235;&#20803;&#25968;&#32676;&#19978;&#23450;&#20041;&#24179;&#28369;&#21644;&#34920;&#29616;&#21147;&#24378;&#30340;&#27969;&#65292;&#20174;&#32780;&#21487;&#20197;&#25429;&#25417;&#21018;&#20307;&#30340;&#36830;&#32493;&#26059;&#36716;&#36816;&#21160;;&#20854;&#27425;&#65292;&#25105;&#20204;&#21033;&#29992;&#21333;&#20301;&#22235;&#20803;&#25968;&#30340;&#21452;&#35206;&#30422;&#29305;&#24615;&#65292;&#22312;&#26059;&#36716;&#32676;&#19978;&#23450;&#20041;&#19968;&#20010;&#36866;&#24403;&#30340;&#23494;&#24230;&#12290;&#36825;&#30830;&#20445;&#25105;&#20204;&#30340;&#27169;&#22411;&#21487;&#20197;&#20351;&#29992;&#26631;&#20934;&#30340;&#22522;&#20110;&#20284;&#28982;&#26041;&#27861;&#25110;&#22522;&#20110;&#28909;&#21147;&#23398;&#30446;&#26631;&#23494;&#24230;&#30340;&#21464;&#20998;&#25512;&#26029;&#36827;&#34892;&#35757;&#32451;&#12290;&#25105;&#20204;&#36890;&#36807;&#35757;&#32451;&#20004;&#20010;&#20998;&#23376;&#31034;&#20363;&#30340;Boltzmann&#29983;&#25104;&#22120;&#26469;&#35780;&#20272;&#35813;&#26041;&#27861;&#65292;&#21363;&#22235;&#38754;&#20307;&#31995;&#32479;&#30340;&#22810;&#27169;&#24577;&#23494;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Normalizing flows (NF) are a class of powerful generative models that have gained popularity in recent years due to their ability to model complex distributions with high flexibility and expressiveness. In this work, we introduce a new type of normalizing flow that is tailored for modeling positions and orientations of multiple objects in three-dimensional space, such as molecules in a crystal. Our approach is based on two key ideas: first, we define smooth and expressive flows on the group of unit quaternions, which allows us to capture the continuous rotational motion of rigid bodies; second, we use the double cover property of unit quaternions to define a proper density on the rotation group. This ensures that our model can be trained using standard likelihood-based methods or variational inference with respect to a thermodynamic target density. We evaluate the method by training Boltzmann generators for two molecular examples, namely the multi-modal density of a tetrahedral system 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#32593;&#26684;&#31070;&#32463;&#31639;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#21442;&#25968;&#21270;&#20559;&#24494;&#20998;&#26041;&#31243;&#65292;&#21019;&#26032;&#22320;&#23558;&#27010;&#29575;&#27979;&#24230;&#36171;&#20104;&#31354;&#38388;&#22495;&#65292;&#24418;&#25104;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#35299;&#20915;&#25968;&#25454;&#21463;&#22122;&#22768;&#24178;&#25200;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2301.11040</link><description>&lt;p&gt;
&#38754;&#21521;&#21442;&#25968;&#21270;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#38543;&#26426;&#32593;&#26684;&#31070;&#32463;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Random Grid Neural Processes for Parametric Partial Differential Equations. (arXiv:2301.11040v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11040
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#32593;&#26684;&#31070;&#32463;&#31639;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#21442;&#25968;&#21270;&#20559;&#24494;&#20998;&#26041;&#31243;&#65292;&#21019;&#26032;&#22320;&#23558;&#27010;&#29575;&#27979;&#24230;&#36171;&#20104;&#31354;&#38388;&#22495;&#65292;&#24418;&#25104;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#35299;&#20915;&#25968;&#25454;&#21463;&#22122;&#22768;&#24178;&#25200;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31867;&#26032;&#30340;&#22522;&#20110;&#21487;&#25193;&#23637;&#21464;&#20998;&#31070;&#32463;&#36807;&#31243;&#30340;&#20855;&#26377;&#31354;&#38388;&#38543;&#26426;&#29289;&#29702;&#23398;&#21644;&#25968;&#25454;&#20449;&#24687;&#30340;&#28145;&#24230;&#28508;&#22312;&#27169;&#22411;&#65292;&#29992;&#20110;&#22788;&#29702;&#21442;&#25968;&#21270;&#20559;&#24494;&#20998;&#26041;&#31243;(PDE)&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#27010;&#29575;&#27979;&#24230;&#36171;&#20104;&#31354;&#38388;&#22495;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#30340;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;&#37197;&#28857;&#32593;&#26684;&#35270;&#20026;&#38543;&#26426;&#21464;&#37327;&#26469;&#36793;&#38469;&#21270;&#12290;&#36890;&#36807;&#36866;&#24212;&#36825;&#31181;&#31354;&#38388;&#32479;&#35745;&#35270;&#22270;&#65292;&#25105;&#20204;&#20197;&#20135;&#29983;&#35299;&#22330;&#30340;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#20316;&#20026;&#32467;&#26524;&#65292;&#35299;&#20915;&#21442;&#25968;PDE&#30340;&#27491;&#21521;&#21644;&#21453;&#21521;&#38382;&#39064;&#12290;&#36825;&#20123;&#38543;&#26426;&#32593;&#26684;&#30340;&#23454;&#29616;&#20026;&#21453;&#21521;&#29289;&#29702;&#20449;&#24687;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#29420;&#29305;&#30340;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Grid Invariant Convolutional Networks(GICNets)&#30340;&#26032;&#26550;&#26500;&#26469;&#20811;&#26381;&#36825;&#20123;&#25361;&#25112;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#22914;&#20309;&#20197;&#21407;&#21017;&#24615;&#30340;&#26041;&#24335;&#23558;&#26377;&#22122;&#22768;&#30340;&#25968;&#25454;&#32435;&#20837;&#25105;&#20204;&#30340;&#29289;&#29702;&#30693;&#35782;&#27169;&#22411;&#20013;&#65292;&#20197;&#25913;&#36827;&#23545;&#19968;&#20123;&#21487;&#33021;&#26377;&#21487;&#29992;&#25968;&#25454;&#20294;&#27979;&#37327;&#32467;&#26524;&#34987;&#22122;&#22768;&#27745;&#26579;&#30340;&#38382;&#39064;&#30340;&#39044;&#27979;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new class of spatially stochastic physics and data informed deep latent models for parametric partial differential equations (PDEs) which operate through scalable variational neural processes. We achieve this by assigning probability measures to the spatial domain, which allows us to treat collocation grids probabilistically as random variables to be marginalised out. Adapting this spatial statistics view, we solve forward and inverse problems for parametric PDEs in a way that leads to the construction of Gaussian process models of solution fields. The implementation of these random grids poses a unique set of challenges for inverse physics informed deep learning frameworks and we propose a new architecture called Grid Invariant Convolutional Networks (GICNets) to overcome these challenges. We further show how to incorporate noisy data in a principled manner into our physics informed model to improve predictions for problems where data may be available but whose measurem
&lt;/p&gt;</description></item><item><title>Tracr&#26159;&#19968;&#20010;&#32534;&#35793;&#22120;&#65292;&#23558;&#21487;&#35835;&#24615;&#24378;&#30340;&#31243;&#24207;&#32534;&#35793;&#25104;&#26631;&#20934;&#30340;&#20165;&#35299;&#30721;&#21464;&#21387;&#22120;&#27169;&#22411;&#65292;&#35813;&#32534;&#35793;&#27169;&#22411;&#30340;&#24050;&#30693;&#32467;&#26500;&#21487;&#20197;&#29992;&#20110;&#35774;&#35745;&#23454;&#39564;&#21644;&#35780;&#20272;&#21487;&#35299;&#37322;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2301.05062</link><description>&lt;p&gt;
Tracr: &#32534;&#35793;&#21464;&#21387;&#22120;&#27169;&#22411;&#20316;&#20026;&#21487;&#35299;&#37322;&#24615;&#23454;&#39564;&#23460;
&lt;/p&gt;
&lt;p&gt;
Tracr: Compiled Transformers as a Laboratory for Interpretability. (arXiv:2301.05062v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.05062
&lt;/p&gt;
&lt;p&gt;
Tracr&#26159;&#19968;&#20010;&#32534;&#35793;&#22120;&#65292;&#23558;&#21487;&#35835;&#24615;&#24378;&#30340;&#31243;&#24207;&#32534;&#35793;&#25104;&#26631;&#20934;&#30340;&#20165;&#35299;&#30721;&#21464;&#21387;&#22120;&#27169;&#22411;&#65292;&#35813;&#32534;&#35793;&#27169;&#22411;&#30340;&#24050;&#30693;&#32467;&#26500;&#21487;&#20197;&#29992;&#20110;&#35774;&#35745;&#23454;&#39564;&#21644;&#35780;&#20272;&#21487;&#35299;&#37322;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#21487;&#35835;&#24615;&#24378;&#30340;&#31243;&#24207;&#32534;&#35793;&#25104;&#26631;&#20934;&#30340;&#20165;&#35299;&#30721;&#21464;&#21387;&#22120;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#32534;&#35793;&#22120;Tracr&#29983;&#25104;&#20855;&#26377;&#24050;&#30693;&#32467;&#26500;&#30340;&#27169;&#22411;&#65292;&#21487;&#20197;&#29992;&#20110;&#35774;&#35745;&#23454;&#39564;&#12290;&#20363;&#22914;&#65292;&#25105;&#20204;&#20351;&#29992;&#23427;&#26469;&#30740;&#31350;&#25191;&#34892;&#22810;&#27493;&#31639;&#27861;&#30340;&#21464;&#21387;&#22120;&#20013;&#30340;&#8220;&#21472;&#21152;&#8221;&#12290;&#27492;&#22806;&#65292;Tracr&#32534;&#35793;&#27169;&#22411;&#30340;&#24050;&#30693;&#32467;&#26500;&#21487;&#20197;&#20316;&#20026;&#35780;&#20272;&#21487;&#35299;&#37322;&#26041;&#27861;&#30340;&#30495;&#23454;&#22522;&#20934;&#12290;&#36890;&#24120;&#65292;&#30001;&#20110;&#21464;&#21387;&#22120;&#23398;&#20064;&#30340;&#8220;&#31243;&#24207;&#8221;&#26159;&#26410;&#30693;&#30340;&#65292;&#22240;&#27492;&#19981;&#28165;&#26970;&#35299;&#37322;&#26159;&#21542;&#25104;&#21151;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#29616;&#21644;&#26816;&#26597;&#21253;&#25324;&#35745;&#31639;&#20196;&#29260;&#39057;&#29575;&#12289;&#25490;&#24207;&#21644;&#25324;&#21495;&#26816;&#26597;&#22312;&#20869;&#30340;&#31243;&#24207;&#26469;&#28436;&#31034;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;https://github.com/deepmind/tracr&#25552;&#20379;&#20102;Tracr&#30340;&#24320;&#28304;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show how to "compile" human-readable programs into standard decoder-only transformer models. Our compiler, Tracr, generates models with known structure. This structure can be used to design experiments. For example, we use it to study "superposition" in transformers that execute multi-step algorithms. Additionally, the known structure of Tracr-compiled models can serve as ground-truth for evaluating interpretability methods. Commonly, because the "programs" learned by transformers are unknown it is unclear whether an interpretation succeeded. We demonstrate our approach by implementing and examining programs including computing token frequencies, sorting, and parenthesis checking. We provide an open-source implementation of Tracr at https://github.com/deepmind/tracr.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#32773;&#35777;&#26126;&#23545;&#20110;&#22343;&#26041;&#35823;&#24046;&#21644;&#20132;&#21449;&#29109;&#25439;&#22833;&#65292;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#20013;&#20986;&#29616;&#30340;&#20840;&#23616;&#35299;&#22312;&#19981;&#21516;&#25968;&#25454;&#19978;&#37117;&#20855;&#26377;&#31070;&#32463;&#22604;&#38519;&#30340;&#29305;&#24615;&#65292;&#21363;&#26368;&#21518;&#19968;&#23618;&#29305;&#24449;&#20250;&#23849;&#28291;&#20026;&#31867;&#22343;&#20540;&#65292;&#32780;&#36825;&#20123;&#31867;&#22343;&#20540;&#26159;&#31561;&#35282;&#32039;&#26694;&#26550;&#30340;&#39030;&#28857;&#12290;</title><link>http://arxiv.org/abs/2301.00437</link><description>&lt;p&gt;
&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#20013;&#30340;&#31070;&#32463;&#22604;&#38519;:&#20174;&#24179;&#34913;&#21040;&#19981;&#24179;&#34913;&#30340;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Neural Collapse in Deep Linear Networks: From Balanced to Imbalanced Data. (arXiv:2301.00437v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.00437
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#32773;&#35777;&#26126;&#23545;&#20110;&#22343;&#26041;&#35823;&#24046;&#21644;&#20132;&#21449;&#29109;&#25439;&#22833;&#65292;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#20013;&#20986;&#29616;&#30340;&#20840;&#23616;&#35299;&#22312;&#19981;&#21516;&#25968;&#25454;&#19978;&#37117;&#20855;&#26377;&#31070;&#32463;&#22604;&#38519;&#30340;&#29305;&#24615;&#65292;&#21363;&#26368;&#21518;&#19968;&#23618;&#29305;&#24449;&#20250;&#23849;&#28291;&#20026;&#31867;&#22343;&#20540;&#65292;&#32780;&#36825;&#20123;&#31867;&#22343;&#20540;&#26159;&#31561;&#35282;&#32039;&#26694;&#26550;&#30340;&#39030;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#22270;&#20687;&#20998;&#31867;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#31561;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#36825;&#20123;&#20855;&#26377;&#22823;&#37327;&#21442;&#25968;&#30340;&#22797;&#26434;&#31995;&#32479;&#22312;&#35757;&#32451;&#21040;&#25910;&#25947;&#26102;&#65292;&#23427;&#20204;&#30340;&#26368;&#21518;&#19968;&#23618;&#29305;&#24449;&#21644;&#20998;&#31867;&#22120;&#22312;&#32463;&#20856;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#30456;&#21516;&#30340;&#32467;&#26500;&#24615;&#36136;&#12290;&#29305;&#21035;&#22320;&#65292;&#35266;&#23519;&#21040;&#26368;&#21518;&#19968;&#23618;&#29305;&#24449;&#20250;&#23849;&#28291;&#20026;&#31867;&#22343;&#20540;&#65292;&#24182;&#19988;&#36825;&#20123;&#31867;&#22343;&#20540;&#26159;&#31561;&#35282;&#32039;&#26694;&#26550;(simplex Equiangular Tight Frame)&#30340;&#39030;&#28857;&#12290;&#36825;&#31181;&#29616;&#35937;&#34987;&#31216;&#20026;&#31070;&#32463;&#22604;&#38519;(NC)&#12290;&#26368;&#36817;&#30340;&#35770;&#25991;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#22312;&#31616;&#21270;&#30340;&#8220;&#26080;&#32422;&#26463;&#29305;&#24449;&#27169;&#22411;&#8221;&#35757;&#32451;&#38382;&#39064;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#20013;&#20986;&#29616;&#20102;$\mathcal{NC}$&#12290;&#22312;&#36825;&#20010;&#35821;&#22659;&#19979;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#22312;&#24120;&#29992;&#30340;&#22343;&#26041;&#35823;&#24046;(MSE)&#21644;&#20132;&#21449;&#29109;(CE)&#25439;&#22833;&#19979;&#65292;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#20013;&#20063;&#20250;&#21457;&#29983;$\mathcal{NC}$&#29616;&#35937;&#65292;&#34920;&#26126;&#20840;&#23616;&#35299;&#22312;&#19981;&#21516;&#25968;&#25454;&#19978;&#37117;&#20855;&#26377;$\mathcal{NC}$&#30340;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern deep neural networks have achieved impressive performance on tasks from image classification to natural language processing. Surprisingly, these complex systems with massive amounts of parameters exhibit the same structural properties in their last-layer features and classifiers across canonical datasets when training until convergence. In particular, it has been observed that the last-layer features collapse to their class-means, and those class-means are the vertices of a simplex Equiangular Tight Frame (ETF). This phenomenon is known as Neural Collapse ($\mathcal{NC}$). Recent papers have theoretically shown that $\mathcal{NC}$ emerges in the global minimizers of training problems with the simplified ``unconstrained feature model''. In this context, we take a step further and prove the $\mathcal{NC}$ occurrences in deep linear networks for the popular mean squared error (MSE) and cross entropy (CE) losses, showing that global solutions exhibit $\mathcal{NC}$ properties across
&lt;/p&gt;</description></item><item><title>&#21327;&#21464;&#37327;&#36716;&#31227;&#21644;&#23545;&#25239;&#25200;&#21160;&#23545;&#32479;&#35745;&#23398;&#20064;&#30340;&#31283;&#20581;&#24615;&#25552;&#20986;&#20102;&#25361;&#25112;&#12290;&#26412;&#25991;&#22312;&#26080;&#38480;&#32500;&#24230;&#30340;&#24773;&#20917;&#19979;&#30740;&#31350;&#20102;&#23545;&#25239;&#21327;&#21464;&#37327;&#36716;&#31227;&#23545;&#22806;&#25512;&#21306;&#22495;&#30340;&#24433;&#21709;&#20197;&#21450;&#20854;&#23545;&#21518;&#32493;&#23398;&#20064;&#30340;&#24179;&#34913;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2212.02457</link><description>&lt;p&gt;
&#21327;&#21464;&#37327;&#36716;&#31227;&#30340;&#31069;&#31119;&#21644;&#35781;&#21650;&#65306;&#23545;&#25239;&#23398;&#20064;&#21160;&#24577;&#12289;&#26041;&#21521;&#25910;&#25947;&#21644;&#24179;&#34913;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Blessings and Curses of Covariate Shifts: Adversarial Learning Dynamics, Directional Convergence, and Equilibria. (arXiv:2212.02457v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.02457
&lt;/p&gt;
&lt;p&gt;
&#21327;&#21464;&#37327;&#36716;&#31227;&#21644;&#23545;&#25239;&#25200;&#21160;&#23545;&#32479;&#35745;&#23398;&#20064;&#30340;&#31283;&#20581;&#24615;&#25552;&#20986;&#20102;&#25361;&#25112;&#12290;&#26412;&#25991;&#22312;&#26080;&#38480;&#32500;&#24230;&#30340;&#24773;&#20917;&#19979;&#30740;&#31350;&#20102;&#23545;&#25239;&#21327;&#21464;&#37327;&#36716;&#31227;&#23545;&#22806;&#25512;&#21306;&#22495;&#30340;&#24433;&#21709;&#20197;&#21450;&#20854;&#23545;&#21518;&#32493;&#23398;&#20064;&#30340;&#24179;&#34913;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21327;&#21464;&#37327;&#20998;&#24067;&#36716;&#31227;&#21644;&#23545;&#25239;&#25200;&#21160;&#23545;&#20256;&#32479;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#30340;&#31283;&#20581;&#24615;&#25552;&#20986;&#20102;&#25361;&#25112;&#65306;&#27979;&#35797;&#21327;&#21464;&#37327;&#20998;&#24067;&#20013;&#30340;&#36731;&#24494;&#36716;&#31227;&#33021;&#26174;&#33879;&#24433;&#21709;&#22522;&#20110;&#35757;&#32451;&#20998;&#24067;&#23398;&#20064;&#30340;&#32479;&#35745;&#27169;&#22411;&#24615;&#33021;&#12290;&#24403;&#22806;&#25512;&#21457;&#29983;&#26102;&#65292;&#21363;&#21327;&#21464;&#37327;&#36716;&#31227;&#21040;&#35757;&#32451;&#20998;&#24067;&#31232;&#32570;&#30340;&#21306;&#22495;&#26102;&#65292;&#27169;&#22411;&#24615;&#33021;&#36890;&#24120;&#20250;&#38477;&#20302;&#65292;&#22240;&#27492;&#65292;&#23398;&#20064;&#27169;&#22411;&#20449;&#24687;&#24456;&#23569;&#12290;&#20026;&#20102;&#31283;&#20581;&#24615;&#21644;&#27491;&#21017;&#21270;&#32771;&#34385;&#65292;&#24314;&#35758;&#37319;&#29992;&#23545;&#25239;&#25200;&#21160;&#25216;&#26415;&#65292;&#28982;&#32780;&#65292;&#38656;&#35201;&#23545;&#32473;&#23450;&#23398;&#20064;&#27169;&#22411;&#26102;&#23545;&#25239;&#21327;&#21464;&#37327;&#36716;&#31227;&#30340;&#22806;&#25512;&#21306;&#22495;&#36827;&#34892;&#20180;&#32454;&#30740;&#31350;&#12290;&#26412;&#25991;&#22312;&#26080;&#38480;&#32500;&#24230;&#30340;&#35774;&#32622;&#20013;&#31934;&#30830;&#21051;&#30011;&#20102;&#22806;&#25512;&#21306;&#22495;&#65292;&#22312;&#22238;&#24402;&#21644;&#20998;&#31867;&#26041;&#38754;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#30740;&#31350;&#20102;&#23545;&#25239;&#21327;&#21464;&#37327;&#36716;&#31227;&#23545;&#38543;&#21518;&#30340;&#24179;&#34913;&#23398;&#20064;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Covariate distribution shifts and adversarial perturbations present robustness challenges to the conventional statistical learning framework: mild shifts in the test covariate distribution can significantly affect the performance of the statistical model learned based on the training distribution. The model performance typically deteriorates when extrapolation happens: namely, covariates shift to a region where the training distribution is scarce, and naturally, the learned model has little information. For robustness and regularization considerations, adversarial perturbation techniques are proposed as a remedy; however, careful study needs to be carried out about what extrapolation region adversarial covariate shift will focus on, given a learned model. This paper precisely characterizes the extrapolation region, examining both regression and classification in an infinite-dimensional setting. We study the implications of adversarial covariate shifts to subsequent learning of the equi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#35777;&#25454;&#34920;&#26126;&#65292;&#33073;&#32806;&#34920;&#31034;&#19982;&#31232;&#30095;&#22522;&#39044;&#27979;&#22120;&#30456;&#32467;&#21512;&#21487;&#25552;&#39640;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23454;&#29992;&#26041;&#27861;&#26469;&#23398;&#20064;&#36825;&#31181;&#34920;&#31034;&#65292;&#24182;&#22312;&#23569;&#26679;&#26412;&#20998;&#31867;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;&#31454;&#20105;&#24615;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2211.14666</link><description>&lt;p&gt;
&#33073;&#32806;&#34920;&#31034;&#19982;&#31232;&#30095;&#24615;&#20043;&#38388;&#30340;&#21327;&#21516;&#20316;&#29992;&#65306;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#30340;&#27867;&#21270;&#21644;&#21487;&#35782;&#21035;&#24615;
&lt;/p&gt;
&lt;p&gt;
Synergies between Disentanglement and Sparsity: Generalization and Identifiability in Multi-Task Learning. (arXiv:2211.14666v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.14666
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#35777;&#25454;&#34920;&#26126;&#65292;&#33073;&#32806;&#34920;&#31034;&#19982;&#31232;&#30095;&#22522;&#39044;&#27979;&#22120;&#30456;&#32467;&#21512;&#21487;&#25552;&#39640;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23454;&#29992;&#26041;&#27861;&#26469;&#23398;&#20064;&#36825;&#31181;&#34920;&#31034;&#65292;&#24182;&#22312;&#23569;&#26679;&#26412;&#20998;&#31867;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;&#31454;&#20105;&#24615;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#33073;&#32806;&#34920;&#31034;&#32463;&#24120;&#34987;&#35748;&#20026;&#23545;&#19979;&#28216;&#20219;&#21153;&#26377;&#30410;&#65292;&#20294;&#30446;&#21069;&#30340;&#32463;&#39564;&#21644;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#26377;&#38480;&#12290;&#26412;&#25991;&#25552;&#20379;&#35777;&#25454;&#34920;&#26126;&#65292;&#19982;&#31232;&#30095;&#22522;&#39044;&#27979;&#22120;&#30456;&#32467;&#21512;&#30340;&#33073;&#32806;&#34920;&#31034;&#21487;&#25552;&#39640;&#27867;&#21270;&#33021;&#21147;&#12290;&#22312;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#26032;&#30340;&#21487;&#35782;&#21035;&#24615;&#32467;&#26524;&#65292;&#35813;&#32467;&#26524;&#25552;&#20379;&#20102;&#26368;&#22823;&#31232;&#30095;&#22522;&#39044;&#27979;&#22120;&#20135;&#29983;&#33073;&#32806;&#34920;&#31034;&#30340;&#26465;&#20214;&#12290;&#21463;&#36825;&#20010;&#29702;&#35770;&#32467;&#26524;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31232;&#30095;&#20419;&#36827;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#23398;&#20064;&#33073;&#32806;&#34920;&#31034;&#30340;&#23454;&#29992;&#26041;&#27861;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#19968;&#20010;&#22522;&#20110;&#32452; Lasso &#22810;&#31867; SVM &#22522;&#39044;&#27979;&#22120;&#30340;&#20803;&#23398;&#20064;&#29256;&#26412;&#30340;&#31639;&#27861;&#65292;&#20026;&#27492;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#21487;&#34892;&#30340;&#23545;&#20598;&#20844;&#24335;&#12290;&#23427;&#22312;&#26631;&#20934;&#30340;&#23569;&#26679;&#26412;&#20998;&#31867;&#22522;&#20934;&#27979;&#35797;&#19978;&#33719;&#24471;&#20102;&#31454;&#20105;&#24615;&#30340;&#32467;&#26524;&#65292;&#32780;&#27599;&#20010;&#20219;&#21153;&#20165;&#20351;&#29992;&#20102;&#19968;&#23567;&#37096;&#20998;&#23398;&#20064;&#21040;&#30340;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Although disentangled representations are often said to be beneficial for downstream tasks, current empirical and theoretical understanding is limited. In this work, we provide evidence that disentangled representations coupled with sparse base-predictors improve generalization. In the context of multi-task learning, we prove a new identifiability result that provides conditions under which maximally sparse base-predictors yield disentangled representations. Motivated by this theoretical result, we propose a practical approach to learn disentangled representations based on a sparsity-promoting bi-level optimization problem. Finally, we explore a meta-learning version of this algorithm based on group Lasso multiclass SVM base-predictors, for which we derive a tractable dual formulation. It obtains competitive results on standard few-shot classification benchmarks, while each task is using only a fraction of the learned representations.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#26367;&#20195;&#30828;&#36127;&#20363;&#25366;&#25496;&#30340;&#20840;&#23616;&#23545;&#27604;&#25209;&#37327;&#37319;&#26679;&#26041;&#27861;GCBS&#65292;&#33021;&#22815;&#25552;&#39640;&#23545;&#27604;&#23398;&#20064;&#20219;&#21153;&#30340;&#24615;&#33021;&#34920;&#29616;&#65292;&#26131;&#20110;&#23454;&#29616;&#19988;&#36866;&#29992;&#20110;&#21508;&#31181;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2210.12874</link><description>&lt;p&gt;
&#22522;&#20110;&#26679;&#26412;&#25490;&#21015;&#20248;&#21270;&#30340;&#20840;&#23616;&#23545;&#27604;&#25209;&#37327;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Global Contrastive Batch Sampling via Optimization on Sample Permutations. (arXiv:2210.12874v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.12874
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#26367;&#20195;&#30828;&#36127;&#20363;&#25366;&#25496;&#30340;&#20840;&#23616;&#23545;&#27604;&#25209;&#37327;&#37319;&#26679;&#26041;&#27861;GCBS&#65292;&#33021;&#22815;&#25552;&#39640;&#23545;&#27604;&#23398;&#20064;&#20219;&#21153;&#30340;&#24615;&#33021;&#34920;&#29616;&#65292;&#26131;&#20110;&#23454;&#29616;&#19988;&#36866;&#29992;&#20110;&#21508;&#31181;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#27604;&#23398;&#20064;&#26368;&#36817;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#35768;&#22810;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#20351;&#29992;&#25366;&#25496;&#30340;&#30828;&#36127;&#20363;&#26469;&#22312;&#35757;&#32451;&#26399;&#38388;&#20351;&#25209;&#22788;&#29702;&#26356;&#21152;&#20449;&#24687;&#20016;&#23500;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#25928;&#29575;&#20302;&#19979;&#65292;&#22240;&#20026;&#23427;&#20204;&#22686;&#21152;&#20102;&#19982;&#25366;&#25496;&#36127;&#20363;&#25968;&#25104;&#27604;&#20363;&#30340;&#32426;&#20803;&#38271;&#24230;&#65292;&#24182;&#38656;&#35201;&#39057;&#32321;&#26356;&#26032;&#26368;&#36817;&#37051;&#23621;&#32034;&#24341;&#25110;&#20174;&#26368;&#36817;&#30340;&#25209;&#27425;&#20013;&#36827;&#34892;&#25366;&#25496;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#21478;&#19968;&#31181;&#30828;&#36127;&#20363;&#25366;&#25496;&#30340;&#26367;&#20195;&#26041;&#26696;&#65306;&#20840;&#23616;&#23545;&#27604;&#25209;&#37327;&#37319;&#26679;&#65288;GCBS&#65289;&#65292;&#19968;&#31181;&#26377;&#25928;&#30340;&#36817;&#20284;&#25209;&#22788;&#29702;&#20998;&#37197;&#38382;&#39064;&#65292;&#23427;&#19978;&#30028;&#20102;&#23545;&#27604;&#23398;&#20064;&#35774;&#32622;&#20013;&#30340;&#20840;&#23616;&#25439;&#22833;&#21644;&#35757;&#32451;&#25439;&#22833;&#20043;&#38388;&#30340;&#24046;&#36317;$\mathcal{L}^{Global} - \mathcal{L}^{Train}$&#12290;&#36890;&#36807;&#23454;&#39564;&#65292;&#25105;&#20204;&#21457;&#29616;GCBS&#25913;&#21892;&#20102;&#21477;&#23376;&#23884;&#20837;&#21644;&#20195;&#30721;&#25628;&#32034;&#20219;&#21153;&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;GCBS&#26131;&#20110;&#23454;&#29616;&#65292;&#22240;&#20026;&#23427;&#21482;&#38656;&#35201;&#23569;&#37327;&#38468;&#21152;&#20195;&#30721;&#65292;&#19981;&#38656;&#35201;&#32500;&#25252;&#22806;&#37096;&#25968;&#25454;&#32467;&#26500;&#65292;&#22914;&#26368;&#36817;&#37051;&#23621;&#32034;&#24341;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#21508;&#31181;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Contrastive Learning has recently achieved state-of-the-art performance in a wide range of tasks. Many contrastive learning approaches use mined hard negatives to make batches more informative during training but these approaches are inefficient as they increase epoch length proportional to the number of mined negatives and require frequent updates of nearest neighbor indices or mining from recent batches. In this work, we provide an alternative to hard negative mining, Global Contrastive Batch Sampling (GCBS), an efficient approximation to the batch assignment problem that upper bounds the gap between the global and training losses, $\mathcal{L}^{Global} - \mathcal{L}^{Train}$, in contrastive learning settings. Through experimentation we find GCBS improves state-of-the-art performance in sentence embedding and code-search tasks. Additionally, GCBS is easy to implement as it requires only a few additional lines of code, does not maintain external data structures such as nearest neighbo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23637;&#31034;&#20102;SGD&#20351;&#29992;&#22823;&#27493;&#38271;&#35757;&#32451;&#33021;&#22815;&#23398;&#20064;&#31232;&#30095;&#29305;&#24449;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#36890;&#36807;&#27493;&#38271;&#35843;&#24230;&#65292;&#26799;&#24230;&#21644;&#22122;&#22768;&#30456;&#20114;&#20316;&#29992;&#65292;&#20849;&#21516;&#39537;&#21160;SGD&#21160;&#24577;&#31359;&#36807;&#31070;&#32463;&#32593;&#32476;&#30340;&#25439;&#22833;&#24179;&#38754;&#65292;&#20174;&#32780;&#21457;&#29616;&#31232;&#30095;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2210.05337</link><description>&lt;p&gt;
SGD&#20351;&#29992;&#22823;&#27493;&#38271;&#35757;&#32451;&#33021;&#22815;&#23398;&#20064;&#31232;&#30095;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
SGD with Large Step Sizes Learns Sparse Features. (arXiv:2210.05337v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.05337
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#20102;SGD&#20351;&#29992;&#22823;&#27493;&#38271;&#35757;&#32451;&#33021;&#22815;&#23398;&#20064;&#31232;&#30095;&#29305;&#24449;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#36890;&#36807;&#27493;&#38271;&#35843;&#24230;&#65292;&#26799;&#24230;&#21644;&#22122;&#22768;&#30456;&#20114;&#20316;&#29992;&#65292;&#20849;&#21516;&#39537;&#21160;SGD&#21160;&#24577;&#31359;&#36807;&#31070;&#32463;&#32593;&#32476;&#30340;&#25439;&#22833;&#24179;&#38754;&#65292;&#20174;&#32780;&#21457;&#29616;&#31232;&#30095;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#22312;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#20013;&#21160;&#21147;&#23398;&#30340;&#37325;&#35201;&#29305;&#24449;&#12290;&#25105;&#20204;&#21457;&#29616;&#65306;&#24120;&#29992;&#30340;&#22823;&#27493;&#38271;&#20250;&#23548;&#33268;&#36845;&#20195;&#20174;&#23665;&#35895;&#30340;&#19968;&#20391;&#36339;&#21040;&#21478;&#19968;&#20391;&#23548;&#33268;&#25439;&#22833;&#31283;&#23450;&#65292;&#21516;&#26102;&#36825;&#31181;&#31283;&#23450;&#24615;&#20250;&#24341;&#36215;&#19968;&#20010;&#38544;&#21547;&#30340;&#12289;&#22402;&#30452;&#20110;&#36339;&#36291;&#26041;&#21521;&#30340;&#38543;&#26426;&#21160;&#24577;&#65292;&#23558;&#20854;&#20559;&#21521;&#20110;&#31232;&#30095;&#39044;&#27979;&#22120;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23454;&#39564;&#35777;&#26126;&#65292;&#38271;&#26102;&#38388;&#20351;&#29992;&#22823;&#27493;&#38271;&#21487;&#20445;&#25345;SGD&#22312;&#25439;&#22833;&#24179;&#38754;&#20013;&#30340;&#39640;&#24230;&#65292;&#36827;&#32780;&#33021;&#26356;&#22909;&#22320;&#23454;&#29616;&#38544;&#24335;&#27491;&#21017;&#21270;&#21644;&#21457;&#29616;&#31232;&#30095;&#34920;&#31034;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#37324;&#27809;&#26377;&#20351;&#29992;&#20219;&#20309;&#26174;&#24335;&#27491;&#21017;&#21270;&#65292;&#22240;&#27492;&#27491;&#21017;&#21270;&#25928;&#26524;&#23436;&#20840;&#26469;&#33258;&#20110;&#21463;&#27493;&#38271;&#35843;&#24230;&#24433;&#21709;&#30340;SGD&#35757;&#32451;&#21160;&#24577;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#21457;&#29616;&#25581;&#31034;&#20102;&#36890;&#36807;&#27493;&#38271;&#35843;&#24230;&#65292;&#26799;&#24230;&#21644;&#22122;&#22768;&#22914;&#20309;&#20849;&#21516;&#39537;&#21160;SGD&#21160;&#24577;&#31359;&#36807;&#31070;&#32463;&#32593;&#32476;&#30340;&#25439;&#22833;&#24179;&#38754;&#12290;&#25105;&#20204;&#36890;&#36807;&#23637;&#31034;&#24130;&#24459;&#27493;&#38271;&#35843;&#24230;&#21305;&#37197;&#22885;&#24681;&#26031;&#22374;-&#20044;&#20262;&#36125;&#20811;&#36807;&#31243;&#30340;&#29702;&#35770;&#39044;&#27979;&#24182;&#23548;&#33268;&#26368;&#31283;&#20581;&#21644;&#26368;&#31232;&#30095;&#30340;&#34920;&#31034;&#26469;&#35777;&#26126;&#36825;&#20123;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We showcase important features of the dynamics of the Stochastic Gradient Descent (SGD) in the training of neural networks. We present empirical observations that commonly used large step sizes (i) lead the iterates to jump from one side of a valley to the other causing loss stabilization, and (ii) this stabilization induces a hidden stochastic dynamics orthogonal to the bouncing directions that biases it implicitly toward sparse predictors. Furthermore, we show empirically that the longer large step sizes keep SGD high in the loss landscape valleys, the better the implicit regularization can operate and find sparse representations. Notably, no explicit regularization is used so that the regularization effect comes solely from the SGD training dynamics influenced by the step size schedule. Therefore, these observations unveil how, through the step size schedules, both gradient and noise drive together the SGD dynamics through the loss landscape of neural networks. We justify these find
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#23454;&#20540;&#20989;&#25968;&#20013;&#23545;&#25239;&#40065;&#26834;PAC&#23398;&#20064;&#24615;&#65292;&#21457;&#29616;&#26377;&#38480;&#32982;&#25240;&#23556;&#32500;&#30340;&#31867;&#26082;&#21487;&#20197;&#22312;&#23454;&#29616;&#21644;&#19981;&#21487;&#30693;&#35774;&#32622;&#20013;&#34987;&#23398;&#20064;&#65292;&#20984;&#20989;&#25968;&#31867;&#21487;&#20197;&#27491;&#30830;&#23398;&#20064;&#65292;&#32780;&#19968;&#20123;&#38750;&#20984;&#20989;&#25968;&#31867;&#38656;&#35201;&#19981;&#27491;&#24403;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2206.12977</link><description>&lt;p&gt;
&#22312;&#23454;&#20540;&#20989;&#25968;&#20013;&#23545;&#25239;&#40065;&#26834;PAC&#23398;&#20064;&#24615;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Adversarially Robust PAC Learnability of Real-Valued Functions. (arXiv:2206.12977v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.12977
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#23454;&#20540;&#20989;&#25968;&#20013;&#23545;&#25239;&#40065;&#26834;PAC&#23398;&#20064;&#24615;&#65292;&#21457;&#29616;&#26377;&#38480;&#32982;&#25240;&#23556;&#32500;&#30340;&#31867;&#26082;&#21487;&#20197;&#22312;&#23454;&#29616;&#21644;&#19981;&#21487;&#30693;&#35774;&#32622;&#20013;&#34987;&#23398;&#20064;&#65292;&#20984;&#20989;&#25968;&#31867;&#21487;&#20197;&#27491;&#30830;&#23398;&#20064;&#65292;&#32780;&#19968;&#20123;&#38750;&#20984;&#20989;&#25968;&#31867;&#38656;&#35201;&#19981;&#27491;&#24403;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#20351;&#29992;$\ell_p$&#25439;&#22833;&#21644;&#20219;&#24847;&#25200;&#21160;&#38598;&#30340;&#22238;&#24402;&#35774;&#32622;&#20013;&#65292;&#23545;&#27979;&#35797;&#26102;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#31283;&#20581;&#24615;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#21738;&#20123;&#20989;&#25968;&#31867;&#26159;PAC&#21487;&#23398;&#20064;&#30340;&#12290;&#25105;&#20204;&#34920;&#26126;&#26377;&#38480;&#32982;&#25240;&#23556;&#32500;&#30340;&#31867;&#26082;&#21487;&#20197;&#22312;&#23454;&#29616;&#21644;&#19981;&#21487;&#30693;&#35774;&#32622;&#20013;&#34987;&#23398;&#20064;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#20984;&#20989;&#25968;&#31867;&#65292;&#23427;&#20204;&#29978;&#33267;&#21487;&#20197;&#27491;&#30830;&#23398;&#20064;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#19968;&#20123;&#38750;&#20984;&#20989;&#25968;&#31867;&#26174;&#28982;&#38656;&#35201;&#19981;&#27491;&#24403;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#25216;&#26415;&#22522;&#20110;&#26500;&#24314;&#19968;&#20010;&#30001;&#32982;&#25240;&#23556;&#32500;&#20915;&#23450;&#22823;&#23567;&#30340;&#20855;&#26377;&#23545;&#25239;&#40065;&#26834;&#24615;&#30340;&#26679;&#26412;&#21387;&#32553;&#26041;&#26696;&#12290;&#22312;&#27492;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#38754;&#21521;&#23454;&#20540;&#20989;&#25968;&#30340;&#19981;&#21487;&#30693;&#26679;&#26412;&#21387;&#32553;&#26041;&#26696;&#65292;&#36825;&#21487;&#33021;&#26159;&#20855;&#26377;&#29420;&#31435;&#20852;&#36259;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study robustness to test-time adversarial attacks in the regression setting with $\ell_p$ losses and arbitrary perturbation sets. We address the question of which function classes are PAC learnable in this setting. We show that classes of finite fat-shattering dimension are learnable in both realizable and agnostic settings. Moreover, for convex function classes, they are even properly learnable. In contrast, some non-convex function classes provably require improper learning algorithms. Our main technique is based on a construction of an adversarially robust sample compression scheme of a size determined by the fat-shattering dimension. Along the way, we introduce a novel agnostic sample compression scheme for real-valued functions, which may be of independent interest.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#36923;&#36753;&#21644;&#8221;&#30340;&#32463;&#39564;&#31070;&#32463;&#20999;&#21521;&#26680;&#36817;&#20284;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#35745;&#31639;&#37327;&#19978;&#26174;&#33879;&#38477;&#20302;&#65292;&#21516;&#26102;&#32463;&#36807;&#35777;&#26126;&#22312;&#23485;&#30340;&#26368;&#32456;&#8220;&#35835;&#20986;&#8221;&#23618;&#30340;&#32593;&#32476;&#20013;&#21021;&#22987;&#21270;&#21518;&#25910;&#25947;&#20110;&#30495;&#23454;&#30340;eNTK&#12290;</title><link>http://arxiv.org/abs/2206.12543</link><description>&lt;p&gt;
&#19968;&#31181;&#23545;&#32463;&#39564;&#31070;&#32463;&#20999;&#21521;&#26680;&#30340;&#24555;&#36895;&#19988;&#26377;&#26681;&#25454;&#30340;&#36817;&#20284;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Fast, Well-Founded Approximation to the Empirical Neural Tangent Kernel. (arXiv:2206.12543v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.12543
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#36923;&#36753;&#21644;&#8221;&#30340;&#32463;&#39564;&#31070;&#32463;&#20999;&#21521;&#26680;&#36817;&#20284;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#35745;&#31639;&#37327;&#19978;&#26174;&#33879;&#38477;&#20302;&#65292;&#21516;&#26102;&#32463;&#36807;&#35777;&#26126;&#22312;&#23485;&#30340;&#26368;&#32456;&#8220;&#35835;&#20986;&#8221;&#23618;&#30340;&#32593;&#32476;&#20013;&#21021;&#22987;&#21270;&#21518;&#25910;&#25947;&#20110;&#30495;&#23454;&#30340;eNTK&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32463;&#39564;&#31070;&#32463;&#20999;&#21521;&#26680;&#65288;eNTK&#65289;&#21487;&#20197;&#24456;&#22909;&#22320;&#29702;&#35299;&#32473;&#23450;&#32593;&#32476;&#30340;&#34920;&#31034;&#65306;&#23427;&#20204;&#36890;&#24120;&#27604;&#26080;&#38480;&#23485;NTK&#35745;&#31639;&#20415;&#23452;&#24471;&#22810;&#65292;&#36866;&#29992;&#33539;&#22260;&#26356;&#24191;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#20855;&#26377;O&#20010;&#36755;&#20986;&#21333;&#20803;&#65288;&#20363;&#22914;O&#31867;&#20998;&#31867;&#22120;&#65289;&#30340;&#32593;&#32476;&#65292;N&#20010;&#36755;&#20837;&#30340;eNTK&#30340;&#22823;&#23567;&#20026;$NO\times NO$&#65292;&#38656;&#35201;$O((NO)^2)$&#30340;&#20869;&#23384;&#21644;&#39640;&#36798;$O((NO)^3)$&#30340;&#35745;&#31639;&#37327;&#12290;&#22240;&#27492;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#24212;&#29992;&#31243;&#24207;&#20351;&#29992;&#23569;&#25968;&#20960;&#20010;&#36817;&#20284;&#20540;&#20043;&#19968;&#65292;&#21487;&#20197;&#20135;&#29983;$N\times N$&#20869;&#26680;&#30697;&#38453;&#65292;&#20174;&#32780;&#33410;&#30465;&#25968;&#37327;&#32423;&#30340;&#35745;&#31639;&#65292;&#20294;&#27809;&#26377;&#25110;&#26497;&#23569;&#26377;&#29702;&#35770;&#20381;&#25454;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20854;&#20013;&#19968;&#31181;&#36817;&#20284;&#26041;&#27861;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#8220;&#36923;&#36753;&#21644;&#8221;&#65292;&#23545;&#20110;&#20219;&#20309;&#20855;&#26377;&#23485;&#30340;&#26368;&#32456;&#8220;&#35835;&#20986;&#8221;&#23618;&#30340;&#32593;&#32476;&#65292;&#22312;&#21021;&#22987;&#21270;&#26102;&#25910;&#25947;&#20110;&#30495;&#23454;&#30340;eNTK&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#23637;&#31034;&#20102;&#36825;&#20010;&#36817;&#20284;&#26041;&#27861;&#22312;&#21508;&#31181;&#19981;&#21516;&#35774;&#32622;&#20013;&#30340;&#21508;&#31181;&#29992;&#36884;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Empirical neural tangent kernels (eNTKs) can provide a good understanding of a given network's representation: they are often far less expensive to compute and applicable more broadly than infinite width NTKs. For networks with O output units (e.g. an O-class classifier), however, the eNTK on N inputs is of size $NO \times NO$, taking $O((NO)^2)$ memory and up to $O((NO)^3)$ computation. Most existing applications have therefore used one of a handful of approximations yielding $N \times N$ kernel matrices, saving orders of magnitude of computation, but with limited to no justification. We prove that one such approximation, which we call "sum of logits", converges to the true eNTK at initialization for any network with a wide final "readout" layer. Our experiments demonstrate the quality of this approximation for various uses across a range of settings.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#8212;&#8212;&#31070;&#32463;&#25193;&#25955;&#36807;&#31243;&#65288;NDPs&#65289;&#65292;&#36890;&#36807;&#26377;&#38480;&#36793;&#32536;&#23398;&#20064;&#20174;&#20016;&#23500;&#30340;&#20989;&#25968;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;NDPs &#21487;&#20197;&#25429;&#33719;&#25509;&#36817;&#30495;&#23454;&#36125;&#21494;&#26031;&#21518;&#39564;&#30340;&#20989;&#25968;&#20998;&#24067;&#65292;&#20855;&#26377;&#36229;&#36234;&#31070;&#32463;&#36807;&#31243;&#30340;&#34920;&#29616;&#65292;&#23454;&#29616;&#20102;&#22810;&#31181;&#19979;&#28216;&#20219;&#21153;&#65292;&#27604;&#22914;&#22238;&#24402;&#12289;&#38544;&#24335;&#36229;&#21442;&#25968;&#36793;&#32536;&#21270;&#12289;&#38750;&#39640;&#26031;&#21518;&#39564;&#39044;&#27979;&#21644;&#20840;&#23616;&#20248;&#21270;&#12290;</title><link>http://arxiv.org/abs/2206.03992</link><description>&lt;p&gt;
&#31070;&#32463;&#25193;&#25955;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Neural Diffusion Processes. (arXiv:2206.03992v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.03992
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#8212;&#8212;&#31070;&#32463;&#25193;&#25955;&#36807;&#31243;&#65288;NDPs&#65289;&#65292;&#36890;&#36807;&#26377;&#38480;&#36793;&#32536;&#23398;&#20064;&#20174;&#20016;&#23500;&#30340;&#20989;&#25968;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;NDPs &#21487;&#20197;&#25429;&#33719;&#25509;&#36817;&#30495;&#23454;&#36125;&#21494;&#26031;&#21518;&#39564;&#30340;&#20989;&#25968;&#20998;&#24067;&#65292;&#20855;&#26377;&#36229;&#36234;&#31070;&#32463;&#36807;&#31243;&#30340;&#34920;&#29616;&#65292;&#23454;&#29616;&#20102;&#22810;&#31181;&#19979;&#28216;&#20219;&#21153;&#65292;&#27604;&#22914;&#22238;&#24402;&#12289;&#38544;&#24335;&#36229;&#21442;&#25968;&#36793;&#32536;&#21270;&#12289;&#38750;&#39640;&#26031;&#21518;&#39564;&#39044;&#27979;&#21644;&#20840;&#23616;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19982;&#20989;&#25968;&#20803;&#23398;&#20064;&#20998;&#24067;&#30456;&#20851;&#30340;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#20855;&#26377;&#28789;&#27963;&#24615;&#22686;&#24378;&#21644;&#25512;&#26029;&#22797;&#26434;&#24615;&#38477;&#20302;&#30340;&#20248;&#28857;&#12290;&#22312;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#29992;&#20110;&#29983;&#25104;&#24314;&#27169;&#26041;&#38754;&#21462;&#24471;&#25104;&#21151;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#8212;&#8212;&#31070;&#32463;&#25193;&#25955;&#36807;&#31243;&#65288;NDPs&#65289;&#65292;&#36890;&#36807;&#26377;&#38480;&#36793;&#32536;&#23398;&#20064;&#20174;&#20016;&#23500;&#30340;&#20989;&#25968;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#36890;&#36807;&#24341;&#20837;&#33258;&#23450;&#20041;&#27880;&#24847;&#21147;&#22359;&#65292;&#25105;&#20204;&#33021;&#22815;&#23558;&#38543;&#26426;&#36807;&#31243;&#30340;&#23646;&#24615;&#65288;&#22914;&#21487;&#20132;&#25442;&#24615;&#65289;&#30452;&#25509;&#32435;&#20837; NDP &#30340;&#26550;&#26500;&#20013;&#12290;&#25105;&#20204;&#20174;&#23454;&#35777;&#35282;&#24230;&#35777;&#26126;&#20102; NDPs &#21487;&#20197;&#25429;&#33719;&#25509;&#36817;&#30495;&#23454;&#36125;&#21494;&#26031;&#21518;&#39564;&#30340;&#20989;&#25968;&#20998;&#24067;&#65292;&#34920;&#26126;&#23427;&#20204;&#33021;&#22815;&#25104;&#21151;&#27169;&#25311;&#39640;&#26031;&#36807;&#31243;&#30340;&#34892;&#20026;&#24182;&#36229;&#36234;&#31070;&#32463;&#36807;&#31243;&#30340;&#34920;&#29616;&#12290;NDPs &#21487;&#20197;&#36827;&#34892;&#22810;&#31181;&#19979;&#28216;&#20219;&#21153;&#65292;&#21253;&#25324;&#22238;&#24402;&#12289;&#38544;&#24335;&#36229;&#21442;&#25968;&#36793;&#32536;&#21270;&#12289;&#38750;&#39640;&#26031;&#21518;&#39564;&#39044;&#27979;&#21644;&#20840;&#23616;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural network approaches for meta-learning distributions over functions have desirable properties such as increased flexibility and a reduced complexity of inference. Building on the successes of denoising diffusion models for generative modelling, we propose Neural Diffusion Processes (NDPs), a novel approach that learns to sample from a rich distribution over functions through its finite marginals. By introducing a custom attention block we are able to incorporate properties of stochastic processes, such as exchangeability, directly into the NDP's architecture. We empirically show that NDPs can capture functional distributions close to the true Bayesian posterior, demonstrating that they can successfully emulate the behaviour of Gaussian processes and surpass the performance of neural processes. NDPs enable a variety of downstream tasks, including regression, implicit hyperparameter marginalisation, non-Gaussian posterior prediction and global optimisation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;dboost&#65292;&#23427;&#26159;&#31532;&#19968;&#20010;&#20026;&#8220;&#39044;&#27979;&#65292;&#28982;&#21518;&#20248;&#21270;&#8221;&#38382;&#39064;&#35774;&#35745;&#30340;&#26234;&#33021;&#26799;&#24230;&#25552;&#21319;&#23454;&#29616;&#12290;&#35813;&#26694;&#26550;&#25903;&#25345;&#20984;&#20108;&#27425;&#38181;&#35268;&#21010;&#65292;&#24182;&#36890;&#36807;&#33258;&#23450;&#20041;&#19981;&#21160;&#28857;&#26144;&#23556;&#30340;&#38544;&#24335;&#24494;&#20998;&#26469;&#25191;&#34892;&#26799;&#24230;&#25552;&#21319;&#65292;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>http://arxiv.org/abs/2204.06895</link><description>&lt;p&gt;
&#22522;&#20110;&#26799;&#24230;&#25552;&#21319;&#30340;&#20984;&#38181;&#39044;&#27979;&#21644;&#20248;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Gradient boosting for convex cone predict and optimize problems. (arXiv:2204.06895v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.06895
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;dboost&#65292;&#23427;&#26159;&#31532;&#19968;&#20010;&#20026;&#8220;&#39044;&#27979;&#65292;&#28982;&#21518;&#20248;&#21270;&#8221;&#38382;&#39064;&#35774;&#35745;&#30340;&#26234;&#33021;&#26799;&#24230;&#25552;&#21319;&#23454;&#29616;&#12290;&#35813;&#26694;&#26550;&#25903;&#25345;&#20984;&#20108;&#27425;&#38181;&#35268;&#21010;&#65292;&#24182;&#36890;&#36807;&#33258;&#23450;&#20041;&#19981;&#21160;&#28857;&#26144;&#23556;&#30340;&#38544;&#24335;&#24494;&#20998;&#26469;&#25191;&#34892;&#26799;&#24230;&#25552;&#21319;&#65292;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#27169;&#22411;&#36890;&#24120;&#29420;&#31435;&#20110;&#20915;&#31574;&#20248;&#21270;&#36827;&#34892;&#20248;&#21270;&#12290;&#26234;&#33021;&#39044;&#27979;&#20248;&#21270;&#65288;SPO&#65289;&#26694;&#26550;&#20248;&#21270;&#39044;&#27979;&#27169;&#22411;&#20197;&#26368;&#23567;&#21270;&#19979;&#28216;&#20915;&#31574;&#36951;&#25022;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;dboost&#65292;&#38024;&#23545;&#8220;&#39044;&#27979;&#65292;&#28982;&#21518;&#20248;&#21270;&#8221;&#38382;&#39064;&#30340;&#31532;&#19968;&#20010;&#36890;&#29992;&#30340;&#26234;&#33021;&#26799;&#24230;&#25552;&#21319;&#23454;&#29616;&#12290;&#35813;&#26694;&#26550;&#25903;&#25345;&#20984;&#20108;&#27425;&#38181;&#35268;&#21010;&#65292;&#36890;&#36807;&#33258;&#23450;&#20041;&#19981;&#21160;&#28857;&#26144;&#23556;&#30340;&#38544;&#24335;&#24494;&#20998;&#26469;&#25191;&#34892;&#26799;&#24230;&#25552;&#21319;&#12290;&#19982;&#26368;&#20808;&#36827;&#30340;SPO&#26041;&#27861;&#30340;&#23454;&#39564;&#27604;&#36739;&#34920;&#26126;&#65292;dboost&#21487;&#20197;&#36827;&#19968;&#27493;&#20943;&#23569;&#26679;&#26412;&#22806;&#20915;&#31574;&#36951;&#25022;&#12290;
&lt;/p&gt;
&lt;p&gt;
Prediction models are typically optimized independently from decision optimization. A smart predict then optimize (SPO) framework optimizes prediction models to minimize downstream decision regret. In this paper we present dboost, the first general purpose implementation of smart gradient boosting for `predict, then optimize' problems. The framework supports convex quadratic cone programming and gradient boosting is performed by implicit differentiation of a custom fixed-point mapping. Experiments comparing with state-of-the-art SPO methods show that dboost can further reduce out-of-sample decision regret.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#22870;&#21169;&#23398;&#20064;&#20013;&#22870;&#21169;&#20989;&#25968;&#30340;&#37096;&#20998;&#21487;&#35782;&#21035;&#24615;&#65292;&#24182;&#20998;&#26512;&#20102;&#36825;&#31181;&#37096;&#20998;&#21487;&#35782;&#21035;&#24615;&#23545;&#25919;&#31574;&#20248;&#21270;&#31561;&#19979;&#28216;&#20219;&#21153;&#30340;&#24433;&#21709;&#12290;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#23545;&#27604;&#22870;&#21169;&#23398;&#20064;&#30340;&#25968;&#25454;&#28304;&#21644;&#19979;&#28216;&#20219;&#21153;&#65292;&#20197;&#20854;&#19981;&#21464;&#24615;&#20026;&#20381;&#25454;&#65292;&#23545;&#22870;&#21169;&#23398;&#20064;&#30340;&#25968;&#25454;&#28304;&#30340;&#35774;&#35745;&#21644;&#36873;&#25321;&#20135;&#29983;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2203.07475</link><description>&lt;p&gt;
&#25919;&#31574;&#20248;&#21270;&#20013;&#30340;&#19981;&#21464;&#24615;&#21450;&#22870;&#21169;&#23398;&#20064;&#20013;&#30340;&#37096;&#20998;&#21487;&#35782;&#21035;&#24615;
&lt;/p&gt;
&lt;p&gt;
Invariance in Policy Optimisation and Partial Identifiability in Reward Learning. (arXiv:2203.07475v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.07475
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22870;&#21169;&#23398;&#20064;&#20013;&#22870;&#21169;&#20989;&#25968;&#30340;&#37096;&#20998;&#21487;&#35782;&#21035;&#24615;&#65292;&#24182;&#20998;&#26512;&#20102;&#36825;&#31181;&#37096;&#20998;&#21487;&#35782;&#21035;&#24615;&#23545;&#25919;&#31574;&#20248;&#21270;&#31561;&#19979;&#28216;&#20219;&#21153;&#30340;&#24433;&#21709;&#12290;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#23545;&#27604;&#22870;&#21169;&#23398;&#20064;&#30340;&#25968;&#25454;&#28304;&#21644;&#19979;&#28216;&#20219;&#21153;&#65292;&#20197;&#20854;&#19981;&#21464;&#24615;&#20026;&#20381;&#25454;&#65292;&#23545;&#22870;&#21169;&#23398;&#20064;&#30340;&#25968;&#25454;&#28304;&#30340;&#35774;&#35745;&#21644;&#36873;&#25321;&#20135;&#29983;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#22797;&#26434;&#30340;&#29616;&#23454;&#20219;&#21153;&#65292;&#25163;&#21160;&#35774;&#35745;&#22870;&#21169;&#20989;&#25968;&#36890;&#24120;&#26159;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#21487;&#20197;&#20351;&#29992;&#22870;&#21169;&#23398;&#20064;&#20174;&#25968;&#25454;&#20013;&#25512;&#26029;&#22870;&#21169;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#21363;&#20351;&#22312;&#26080;&#38480;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#24120;&#20063;&#20250;&#26377;&#22810;&#20010;&#22870;&#21169;&#20989;&#25968;&#21487;&#20197;&#24456;&#22909;&#22320;&#25311;&#21512;&#25968;&#25454;&#12290;&#36825;&#24847;&#21619;&#30528;&#22870;&#21169;&#20989;&#25968;&#21482;&#33021;&#34987;&#37096;&#20998;&#22320;&#35782;&#21035;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#27491;&#24335;&#25551;&#36848;&#20102;&#22312;&#20960;&#31181;&#27969;&#34892;&#30340;&#22870;&#21169;&#23398;&#20064;&#25968;&#25454;&#28304;&#65288;&#21253;&#25324;&#19987;&#23478;&#28436;&#31034;&#21644;&#36712;&#36857;&#27604;&#36739;&#65289;&#19979;&#22870;&#21169;&#20989;&#25968;&#30340;&#37096;&#20998;&#21487;&#35782;&#21035;&#24615;&#12290;&#25105;&#20204;&#36824;&#20998;&#26512;&#20102;&#36825;&#31181;&#37096;&#20998;&#21487;&#35782;&#21035;&#24615;&#23545;&#20110;&#20960;&#39033;&#19979;&#28216;&#20219;&#21153;&#65288;&#20363;&#22914;&#25919;&#31574;&#20248;&#21270;&#65289;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#26694;&#26550;&#20013;&#32479;&#19968;&#20102;&#25105;&#20204;&#30340;&#32467;&#26524;&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#20854;&#19981;&#21464;&#24615;&#23545;&#27604;&#25968;&#25454;&#28304;&#21644;&#19979;&#28216;&#20219;&#21153;&#65292;&#24182;&#23545;&#22870;&#21169;&#23398;&#20064;&#30340;&#25968;&#25454;&#28304;&#30340;&#35774;&#35745;&#21644;&#36873;&#25321;&#20135;&#29983;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is often very challenging to manually design reward functions for complex, real-world tasks. To solve this, one can instead use reward learning to infer a reward function from data. However, there are often multiple reward functions that fit the data equally well, even in the infinite-data limit. This means that the reward function is only partially identifiable. In this work, we formally characterise the partial identifiability of the reward function given several popular reward learning data sources, including expert demonstrations and trajectory comparisons. We also analyse the impact of this partial identifiability for several downstream tasks, such as policy optimisation. We unify our results in a framework for comparing data sources and downstream tasks by their invariances, with implications for the design and selection of data sources for reward learning.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21322;&#21442;&#25968;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#26041;&#27861;&#65292;&#21363;&#36890;&#36807;&#25197;&#26354;&#39640;&#26031;DLMs&#36827;&#34892;&#24314;&#27169;&#65292;&#25197;&#26354;&#20989;&#25968;&#30001;&#36716;&#25442;&#31639;&#23376;&#21644;&#21462;&#25972;&#31639;&#23376;&#32452;&#25104;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#25197;&#26354;DLMs&#30340;&#20849;&#36717;&#25512;&#26029;&#26041;&#27861;&#65292;&#29983;&#25104;&#20102;&#29992;&#20110;&#25512;&#26029;&#21644;&#39044;&#27979;&#30340;&#23450;&#21046;&#21644;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#21253;&#25324;&#33945;&#29305;&#21345;&#32599;&#27169;&#25311;&#20197;&#36827;&#34892;&#31163;&#32447;&#20998;&#26512;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#27169;&#25311;&#21644;&#29616;&#23454;&#19990;&#30028;&#30340;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2110.14790</link><description>&lt;p&gt;
&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#30340;&#25197;&#26354;&#21160;&#24577;&#32447;&#24615;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Warped Dynamic Linear Models for Time Series of Counts. (arXiv:2110.14790v4 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.14790
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21322;&#21442;&#25968;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#26041;&#27861;&#65292;&#21363;&#36890;&#36807;&#25197;&#26354;&#39640;&#26031;DLMs&#36827;&#34892;&#24314;&#27169;&#65292;&#25197;&#26354;&#20989;&#25968;&#30001;&#36716;&#25442;&#31639;&#23376;&#21644;&#21462;&#25972;&#31639;&#23376;&#32452;&#25104;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#25197;&#26354;DLMs&#30340;&#20849;&#36717;&#25512;&#26029;&#26041;&#27861;&#65292;&#29983;&#25104;&#20102;&#29992;&#20110;&#25512;&#26029;&#21644;&#39044;&#27979;&#30340;&#23450;&#21046;&#21644;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#21253;&#25324;&#33945;&#29305;&#21345;&#32599;&#27169;&#25311;&#20197;&#36827;&#34892;&#31163;&#32447;&#20998;&#26512;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#27169;&#25311;&#21644;&#29616;&#23454;&#19990;&#30028;&#30340;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21160;&#24577;&#32447;&#24615;&#27169;&#22411;(DLMs)&#26159;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#20013;&#24120;&#29992;&#30340;&#27169;&#22411;&#65292;&#22240;&#20854;&#32467;&#26500;&#28789;&#27963;&#12289;&#36882;&#24402;&#26356;&#26032;&#31616;&#21333;&#12289;&#33021;&#22815;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#12289;&#33021;&#22815;&#36827;&#34892;&#27010;&#29575;&#39044;&#27979;&#32780;&#21463;&#21040;&#24191;&#27867;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#32780;&#35328;&#65292;&#36873;&#39033;&#21364;&#38750;&#24120;&#26377;&#38480;&#65306;&#39640;&#26031;DLMs&#38656;&#35201;&#36830;&#32493;&#25968;&#25454;&#65292;&#32780;&#22522;&#20110;&#27850;&#26494;&#20998;&#24067;&#30340;&#26367;&#20195;&#26041;&#26696;&#21017;&#24120;&#24120;&#32570;&#20047;&#36275;&#22815;&#30340;&#24314;&#27169;&#28789;&#27963;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21322;&#21442;&#25968;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#26041;&#27861;&#65292;&#21363;&#36890;&#36807;&#25197;&#26354;&#39640;&#26031;DLMs&#36827;&#34892;&#24314;&#27169;&#12290;&#25197;&#26354;&#20989;&#25968;&#30001;&#20004;&#20010;&#37096;&#20998;&#32452;&#25104;&#65306;&#19968;&#20010;(&#38750;&#21442;&#25968;&#21270;&#30340;)&#36716;&#25442;&#31639;&#23376;&#65292;&#25552;&#20379;&#27010;&#29575;&#20998;&#24067;&#30340;&#28789;&#27963;&#24615;&#65307;&#20197;&#21450;&#19968;&#20010;&#21462;&#25972;&#31639;&#23376;&#65292;&#30830;&#20445;&#31163;&#25955;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#27491;&#30830;&#24615;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#25197;&#26354;DLMs&#30340;&#20849;&#36717;&#25512;&#26029;&#26041;&#27861;&#65292;&#20351;&#24471;&#29366;&#24577;&#31354;&#38388;&#28388;&#27874;&#21644;&#24179;&#28369;&#20998;&#24067;&#30340;&#20998;&#26512;&#21644;&#36882;&#24402;&#26356;&#26032;&#25104;&#20026;&#21487;&#33021;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20123;&#32467;&#26524;&#29983;&#25104;&#20102;&#29992;&#20110;&#25512;&#26029;&#21644;&#39044;&#27979;&#30340;&#23450;&#21046;&#21644;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#21253;&#25324;&#33945;&#29305;&#21345;&#32599;&#27169;&#25311;&#20197;&#36827;&#34892;&#31163;&#32447;&#20998;&#26512;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#27169;&#25311;&#21644;&#29616;&#23454;&#19990;&#30028;&#30340;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dynamic Linear Models (DLMs) are commonly employed for time series analysis due to their versatile structure, simple recursive updating, ability to handle missing data, and probabilistic forecasting. However, the options for count time series are limited: Gaussian DLMs require continuous data, while Poisson-based alternatives often lack sufficient modeling flexibility. We introduce a novel semiparametric methodology for count time series by warping a Gaussian DLM. The warping function has two components: a (nonparametric) transformation operator that provides distributional flexibility and a rounding operator that ensures the correct support for the discrete data-generating process. We develop conjugate inference for the warped DLM, which enables analytic and recursive updates for the state space filtering and smoothing distributions. We leverage these results to produce customized and efficient algorithms for inference and forecasting, including Monte Carlo simulation for offline anal
&lt;/p&gt;</description></item><item><title>&#26680;&#32454;&#21270;&#26159;&#19968;&#31181;&#26356;&#26377;&#25928;&#30340;&#21387;&#32553;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#23558;$n$&#28857;&#36817;&#20284;&#30340;&#20998;&#24067;&#21387;&#32553;&#21040;&#20855;&#26377;&#21487;&#27604;&#36739;&#26368;&#22351;&#31215;&#20998;&#35823;&#24046;&#30340;$\sqrt{n}$&#28857;&#36817;&#20284;&#65292;&#20854;&#20122;&#25351;&#25968;&#20445;&#35777;&#31867;&#20284;&#20110;&#22312;$[0,1]^d$&#19978;&#22343;&#21248;$\mathbb{P}$&#30340;&#32463;&#20856;&#20934;&#33945;&#29305;&#21345;&#32599;&#35823;&#24046;&#29575;&#65292;&#20294;&#36866;&#29992;&#20110;$\mathbb{R}^d$&#19978;&#30340;&#19968;&#33324;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2105.05842</link><description>&lt;p&gt;
&#26680;&#32454;&#21270;
&lt;/p&gt;
&lt;p&gt;
Kernel Thinning. (arXiv:2105.05842v9 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.05842
&lt;/p&gt;
&lt;p&gt;
&#26680;&#32454;&#21270;&#26159;&#19968;&#31181;&#26356;&#26377;&#25928;&#30340;&#21387;&#32553;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#23558;$n$&#28857;&#36817;&#20284;&#30340;&#20998;&#24067;&#21387;&#32553;&#21040;&#20855;&#26377;&#21487;&#27604;&#36739;&#26368;&#22351;&#31215;&#20998;&#35823;&#24046;&#30340;$\sqrt{n}$&#28857;&#36817;&#20284;&#65292;&#20854;&#20122;&#25351;&#25968;&#20445;&#35777;&#31867;&#20284;&#20110;&#22312;$[0,1]^d$&#19978;&#22343;&#21248;$\mathbb{P}$&#30340;&#32463;&#20856;&#20934;&#33945;&#29305;&#21345;&#32599;&#35823;&#24046;&#29575;&#65292;&#20294;&#36866;&#29992;&#20110;$\mathbb{R}^d$&#19978;&#30340;&#19968;&#33324;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#26680;&#32454;&#21270;&#65292;&#19968;&#31181;&#27604;&#29420;&#31435;&#21516;&#20998;&#24067;&#37319;&#26679;&#25110;&#26631;&#20934;&#32454;&#21270;&#26356;&#26377;&#25928;&#22320;&#21387;&#32553;&#20998;&#24067;$\mathbb{P}$&#30340;&#26032;&#26041;&#27861;&#12290;&#32473;&#23450;&#19968;&#20010;&#21512;&#36866;&#30340;&#20877;&#29983;&#26680;$\mathbf{k}_{\star}$&#21644;$\mathcal{O}(n^2)$&#26102;&#38388;&#65292;&#26680;&#32454;&#21270;&#23558;&#19968;&#20010;$n$&#28857;&#36817;&#20284;&#30340;$\mathbb{P}$&#21387;&#32553;&#25104;&#19968;&#20010;&#20855;&#26377;&#19982;&#30456;&#20851;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#21487;&#27604;&#36739;&#26368;&#22351;&#31215;&#20998;&#35823;&#24046;&#30340;$\sqrt{n}$&#28857;&#36817;&#20284;&#12290;&#22312;&#27010;&#29575;&#19978;&#65292;&#32039;&#25903;&#25745;&#30340;$\mathbb{P}$&#30340;&#31215;&#20998;&#35823;&#24046;&#26368;&#22823;&#24046;&#21035;&#20026;$\mathcal{O}_d(n^{-1/2}\sqrt{\log n})$&#65292;&#22312;$\mathbb{R}^d$&#19978;&#30340;&#20122;&#25351;&#25968;$\mathbb{P}$&#20026;$\mathcal{O}_d(n^{-\frac{1}{2}} (\log n)^{(d+1)/2}\sqrt{\log\log n})$&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#26469;&#33258;$\mathbb{P}$&#30340;&#31561;&#22823;&#23567;i.i.d.&#26679;&#26412;&#38754;&#20020;$\Omega(n^{-1/4})$&#30340;&#31215;&#20998;&#35823;&#24046;&#12290;&#25105;&#20204;&#30340;&#20122;&#25351;&#25968;&#20445;&#35777;&#31867;&#20284;&#20110;&#22312;$[0,1]^d$&#19978;&#22343;&#21248;$\mathbb{P}$&#30340;&#32463;&#20856;&#20934;&#33945;&#29305;&#21345;&#32599;&#35823;&#24046;&#29575;&#65292;&#20294;&#36866;&#29992;&#20110;$\mathbb{R}^d$&#19978;&#30340;&#19968;&#33324;&#20998;&#24067;&#21644;&#19968;&#20010;&#22823;
&lt;/p&gt;
&lt;p&gt;
We introduce kernel thinning, a new procedure for compressing a distribution $\mathbb{P}$ more effectively than i.i.d. sampling or standard thinning. Given a suitable reproducing kernel $\mathbf{k}_{\star}$ and $\mathcal{O}(n^2)$ time, kernel thinning compresses an $n$-point approximation to $\mathbb{P}$ into a $\sqrt{n}$-point approximation with comparable worst-case integration error across the associated reproducing kernel Hilbert space. The maximum discrepancy in integration error is $\mathcal{O}_d(n^{-1/2}\sqrt{\log n})$ in probability for compactly supported $\mathbb{P}$ and $\mathcal{O}_d(n^{-\frac{1}{2}} (\log n)^{(d+1)/2}\sqrt{\log\log n})$ for sub-exponential $\mathbb{P}$ on $\mathbb{R}^d$. In contrast, an equal-sized i.i.d. sample from $\mathbb{P}$ suffers $\Omega(n^{-1/4})$ integration error. Our sub-exponential guarantees resemble the classical quasi-Monte Carlo error rates for uniform $\mathbb{P}$ on $[0,1]^d$ but apply to general distributions on $\mathbb{R}^d$ and a wid
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#26031;&#20998;&#23618;&#28508;&#22312;&#29380;&#21033;&#20811;&#38647;&#20998;&#37197;&#27169;&#22411;&#65292;&#36890;&#36807;&#24341;&#20837;&#23618;&#27425;&#32467;&#26500;&#24674;&#22797;&#20102;&#25429;&#25417;&#22810;&#20041;&#24615;&#30340;&#33021;&#21147;&#65292;&#30456;&#23545;&#20110;&#22522;&#20110;&#39640;&#26031;&#30340;&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#22810;&#20041;&#35789;&#26816;&#27979;&#24615;&#33021;&#65292;&#30456;&#23545;&#20110;&#28508;&#22312;&#29380;&#21033;&#20811;&#38647;&#20998;&#37197;&#30340;&#23618;&#27425;&#27169;&#22411;&#20855;&#26377;&#26356;&#21152;&#31616;&#27905;&#30340;&#20027;&#39064;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2002.10855</link><description>&lt;p&gt;
&#39640;&#26031;&#20998;&#23618;&#28508;&#22312;&#29380;&#21033;&#20811;&#38647;&#20998;&#37197;&#65306;&#20877;&#29616;&#22810;&#20041;&#35789;
&lt;/p&gt;
&lt;p&gt;
Gaussian Hierarchical Latent Dirichlet Allocation: Bringing Polysemy Back. (arXiv:2002.10855v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2002.10855
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#26031;&#20998;&#23618;&#28508;&#22312;&#29380;&#21033;&#20811;&#38647;&#20998;&#37197;&#27169;&#22411;&#65292;&#36890;&#36807;&#24341;&#20837;&#23618;&#27425;&#32467;&#26500;&#24674;&#22797;&#20102;&#25429;&#25417;&#22810;&#20041;&#24615;&#30340;&#33021;&#21147;&#65292;&#30456;&#23545;&#20110;&#22522;&#20110;&#39640;&#26031;&#30340;&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#22810;&#20041;&#35789;&#26816;&#27979;&#24615;&#33021;&#65292;&#30456;&#23545;&#20110;&#28508;&#22312;&#29380;&#21033;&#20811;&#38647;&#20998;&#37197;&#30340;&#23618;&#27425;&#27169;&#22411;&#20855;&#26377;&#26356;&#21152;&#31616;&#27905;&#30340;&#20027;&#39064;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35805;&#39064;&#27169;&#22411;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#21457;&#29616;&#19968;&#32452;&#25991;&#26723;&#30340;&#28508;&#22312;&#34920;&#31034;&#12290;&#20004;&#31181;&#20856;&#22411;&#30340;&#27169;&#22411;&#26159;&#28508;&#22312;&#29380;&#21033;&#20811;&#38647;&#20998;&#37197;&#21644;&#39640;&#26031;&#28508;&#22312;&#29380;&#21033;&#20811;&#38647;&#20998;&#37197;&#65292;&#21069;&#32773;&#20351;&#29992;&#21333;&#35789;&#19978;&#30340;&#22810;&#39033;&#24335;&#20998;&#24067;&#65292;&#21518;&#32773;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#21333;&#35789;&#23884;&#20837;&#21521;&#37327;&#19978;&#30340;&#22810;&#20803;&#39640;&#26031;&#20998;&#24067;&#20316;&#20026;&#28508;&#22312;&#20027;&#39064;&#34920;&#31034;&#12290;&#19982;&#28508;&#22312;&#29380;&#21033;&#20811;&#38647;&#20998;&#37197;&#30456;&#27604;&#65292;&#39640;&#26031;&#28508;&#22312;&#29380;&#21033;&#20811;&#38647;&#20998;&#37197;&#22312;&#25429;&#25417;&#8220;&#38134;&#34892;&#8221;&#31561;&#35789;&#30340;&#22810;&#20041;&#24615;&#26041;&#38754;&#23384;&#22312;&#38480;&#21046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#39640;&#26031;&#20998;&#23618;&#28508;&#22312;&#29380;&#21033;&#20811;&#38647;&#20998;&#37197;&#36890;&#36807;&#20026;&#27169;&#22411;&#21487;&#20197;&#29992;&#20110;&#34920;&#31034;&#32473;&#23450;&#25991;&#26723;&#30340;&#20027;&#39064;&#38598;&#21512;&#24341;&#20837;&#23618;&#27425;&#32467;&#26500;&#65292;&#21487;&#20197;&#24674;&#22797;&#25429;&#25417;&#22810;&#20041;&#24615;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#39640;&#26031;&#20998;&#23618;&#28508;&#22312;&#29380;&#21033;&#20811;&#38647;&#20998;&#37197;&#30456;&#23545;&#20110;&#22522;&#20110;&#39640;&#26031;&#30340;&#27169;&#22411;&#26174;&#33879;&#25552;&#39640;&#20102;&#22810;&#20041;&#35789;&#26816;&#27979;&#30340;&#33021;&#21147;&#65292;&#24182;&#25552;&#20379;&#20102;&#27604;&#22522;&#20110;&#28508;&#22312;&#29380;&#21033;&#20811;&#38647;&#20998;&#37197;&#30340;&#23618;&#27425;&#27169;&#22411;&#26356;&#20026;&#31616;&#27905;&#30340;&#20027;&#39064;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Topic models are widely used to discover the latent representation of a set of documents. The two canonical models are latent Dirichlet allocation, and Gaussian latent Dirichlet allocation, where the former uses multinomial distributions over words, and the latter uses multivariate Gaussian distributions over pre-trained word embedding vectors as the latent topic representations, respectively. Compared with latent Dirichlet allocation, Gaussian latent Dirichlet allocation is limited in the sense that it does not capture the polysemy of a word such as ``bank.'' In this paper, we show that Gaussian latent Dirichlet allocation could recover the ability to capture polysemy by introducing a hierarchical structure in the set of topics that the model can use to represent a given document. Our Gaussian hierarchical latent Dirichlet allocation significantly improves polysemy detection compared with Gaussian-based models and provides more parsimonious topic representations compared with hierarch
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#31209;&#19968;&#26356;&#26032;&#30340;ROIPCA&#21644;fROIPCA&#20004;&#31181;&#22312;&#32447;PCA&#31639;&#27861;&#65292;&#22312;&#20869;&#23384;&#38480;&#21046;&#30340;&#24773;&#20917;&#19979;&#65292;&#31639;&#27861;&#20934;&#30830;&#24615;&#22909;&#12289;&#36816;&#34892;&#26102;&#38388;&#30701;&#12290;&#20854;&#20013;fROIPCA&#20026;&#26799;&#24230;&#31639;&#27861;&#65292;&#20855;&#26377;&#26368;&#20248;&#23398;&#20064;&#29575;&#12290;</title><link>http://arxiv.org/abs/1911.11049</link><description>&lt;p&gt;
ROIPCA&#65306;&#19968;&#31181;&#22522;&#20110;&#31209;&#19968;&#26356;&#26032;&#30340;&#22312;&#32447;&#20869;&#23384;&#21463;&#38480;PCA&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
ROIPCA: An online memory-restricted PCA algorithm based on rank-one updates. (arXiv:1911.11049v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1911.11049
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#31209;&#19968;&#26356;&#26032;&#30340;ROIPCA&#21644;fROIPCA&#20004;&#31181;&#22312;&#32447;PCA&#31639;&#27861;&#65292;&#22312;&#20869;&#23384;&#38480;&#21046;&#30340;&#24773;&#20917;&#19979;&#65292;&#31639;&#27861;&#20934;&#30830;&#24615;&#22909;&#12289;&#36816;&#34892;&#26102;&#38388;&#30701;&#12290;&#20854;&#20013;fROIPCA&#20026;&#26799;&#24230;&#31639;&#27861;&#65292;&#20855;&#26377;&#26368;&#20248;&#23398;&#20064;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#26159;&#25968;&#25454;&#20998;&#26512;&#20013;&#22522;&#26412;&#30340;&#31639;&#27861;&#12290;&#20854;&#20869;&#23384;&#21463;&#38480;&#30340;&#22312;&#32447;&#29256;&#26412;&#22312;&#35768;&#22810;&#29616;&#20195;&#24212;&#29992;&#20013;&#38750;&#24120;&#26377;&#29992;&#65292;&#20854;&#20013;&#25968;&#25454;&#36807;&#22823;&#32780;&#26080;&#27861;&#22312;&#20869;&#23384;&#20013;&#23384;&#20648;&#65292;&#25110;&#32773;&#25968;&#25454;&#21040;&#36798;&#26102;&#20026;&#19968;&#31995;&#21015;&#39033;&#30446;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;ROIPCA&#21644;fROIPCA&#20004;&#31181;&#22522;&#20110;&#31209;&#19968;&#26356;&#26032;&#30340;&#22312;&#32447;PCA&#31639;&#27861;&#12290;&#34429;&#28982;ROIPCA&#36890;&#24120;&#26356;&#20934;&#30830;&#65292;&#20294;fROIPCA&#26356;&#24555;&#65292;&#24182;&#19988;&#20855;&#26377;&#21487;&#27604;&#36739;&#30340;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;fROIPCA&#19982;&#29616;&#26377;&#27969;&#34892;&#30340;&#22312;&#32447;PCA&#26799;&#24230;&#31639;&#27861;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#19988;&#29305;&#21035;&#35777;&#26126;&#20102;fROIPCA&#23454;&#38469;&#19978;&#26159;&#20855;&#26377;&#26368;&#20248;&#23398;&#20064;&#29575;&#30340;&#26799;&#24230;&#31639;&#27861;&#12290;&#25105;&#20204;&#22312;&#25968;&#20540;&#19978;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#20934;&#30830;&#24615;&#21644;&#36816;&#34892;&#26102;&#38388;&#26041;&#38754;&#27604;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#31639;&#27861;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Principal components analysis (PCA) is a fundamental algorithm in data analysis. Its memory-restricted online versions are useful in many modern applications, where the data are too large to fit in memory, or when data arrive as a stream of items. In this paper, we propose ROIPCA and fROIPCA, two online PCA algorithms that are based on rank-one updates. While ROIPCA is typically more accurate, fROIPCA is faster and has comparable accuracy. We show the relation between fROIPCA and an existing popular gradient algorithm for online PCA, and in particular, prove that fROIPCA is in fact a gradient algorithm with an optimal learning rate. We demonstrate numerically the advantages of our algorithms over existing state-of-the-art algorithms in terms of accuracy and runtime.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20004;&#31181;&#26368;&#23567;&#21270;&#20984;&#30446;&#26631;&#20989;&#25968;&#30340;&#26032;&#20272;&#35745;&#26041;&#27861;&#65292;&#20854;&#20013;&#26680;&#33539;&#25968;&#32602;&#39033;&#26377;&#21161;&#20110;&#35299;&#20915;&#20302;&#31209;&#22238;&#24402;&#22120;&#19979;&#30340;&#20132;&#20114;&#22266;&#23450;&#25928;&#24212;&#27169;&#22411;&#30340;&#28508;&#22312;&#35782;&#21035;&#38382;&#39064;&#65292;&#24182;&#19988;&#20855;&#26377;&#24456;&#37325;&#35201;&#30340;&#35745;&#31639;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/1810.10987</link><description>&lt;p&gt;
&#38754;&#26495;&#22238;&#24402;&#27169;&#22411;&#30340;&#26680;&#33539;&#25968;&#35268;&#21017;&#21270;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Nuclear Norm Regularized Estimation of Panel Regression Models. (arXiv:1810.10987v3 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1810.10987
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20004;&#31181;&#26368;&#23567;&#21270;&#20984;&#30446;&#26631;&#20989;&#25968;&#30340;&#26032;&#20272;&#35745;&#26041;&#27861;&#65292;&#20854;&#20013;&#26680;&#33539;&#25968;&#32602;&#39033;&#26377;&#21161;&#20110;&#35299;&#20915;&#20302;&#31209;&#22238;&#24402;&#22120;&#19979;&#30340;&#20132;&#20114;&#22266;&#23450;&#25928;&#24212;&#27169;&#22411;&#30340;&#28508;&#22312;&#35782;&#21035;&#38382;&#39064;&#65292;&#24182;&#19988;&#20855;&#26377;&#24456;&#37325;&#35201;&#30340;&#35745;&#31639;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20855;&#26377;&#20132;&#20114;&#22266;&#23450;&#25928;&#24212;&#30340;&#38754;&#26495;&#22238;&#24402;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#26368;&#23567;&#21270;&#20984;&#30446;&#26631;&#20989;&#25968;&#30340;&#26032;&#20272;&#35745;&#26041;&#27861;&#12290;&#31532;&#19968;&#31181;&#26041;&#27861;&#26368;&#23567;&#21270;&#27531;&#24046;&#24179;&#26041;&#21644;&#65292;&#24102;&#26377;&#26680;&#65288;&#36857;&#65289;&#33539;&#25968;&#35268;&#21017;&#21270;&#12290;&#31532;&#20108;&#31181;&#26041;&#27861;&#26368;&#23567;&#21270;&#27531;&#24046;&#30340;&#26680;&#33539;&#25968;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#20004;&#20010;&#20272;&#35745;&#22120;&#30340;&#19968;&#33268;&#24615;&#12290;&#36825;&#20123;&#20272;&#35745;&#22120;&#19982;&#29616;&#26377;&#30340;&#26368;&#23567;&#20108;&#20056;&#65288;LS&#65289;&#20272;&#35745;&#22120;&#30456;&#27604;&#20855;&#26377;&#38750;&#24120;&#37325;&#35201;&#30340;&#35745;&#31639;&#20248;&#21183;&#65292;&#22240;&#20026;&#23427;&#20204;&#34987;&#23450;&#20041;&#20026;&#20984;&#30446;&#26631;&#20989;&#25968;&#30340;&#26368;&#23567;&#21270;&#22120;&#12290;&#27492;&#22806;&#65292;&#26680;&#33539;&#25968;&#32602;&#39033;&#26377;&#21161;&#20110;&#35299;&#20915;&#20132;&#20114;&#22266;&#23450;&#25928;&#24212;&#27169;&#22411;&#30340;&#28508;&#22312;&#35782;&#21035;&#38382;&#39064;&#65292;&#23588;&#20854;&#26159;&#24403;&#22238;&#24402;&#22120;&#26159;&#20302;&#31209;&#30340;&#19988;&#22240;&#32032;&#25968;&#37327;&#26410;&#30693;&#26102;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#20351;&#29992;&#25105;&#20204;&#30340;&#26680;&#33539;&#25968;&#35268;&#21017;&#21270;&#20272;&#35745;&#22120;&#26500;&#36896;&#28176;&#36817;&#31561;&#25928;&#20110;Bai&#65288;2009&#24180;&#65289;&#21644;Moon&#21644;Weidner&#65288;2017&#24180;&#65289;&#26368;&#23567;&#20108;&#20056;&#65288;LS&#65289;&#20272;&#35745;&#22120;&#30340;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we investigate panel regression models with interactive fixed effects. We propose two new estimation methods that are based on minimizing convex objective functions. The first method minimizes the sum of squared residuals with a nuclear (trace) norm regularization. The second method minimizes the nuclear norm of the residuals. We establish the consistency of the two resulting estimators. Those estimators have a very important computational advantage compared to the existing least squares (LS) estimator, in that they are defined as minimizers of a convex objective function. In addition, the nuclear norm penalization helps to resolve a potential identification problem for interactive fixed effect models, in particular when the regressors are low-rank and the number of the factors is unknown. We also show how to construct estimators that are asymptotically equivalent to the least squares (LS) estimator in Bai (2009) and Moon and Weidner (2017) by using our nuclear norm regul
&lt;/p&gt;</description></item></channel></rss>