<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#20223;&#30495;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;SBBO&#65289;&#20316;&#20026;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#36890;&#36807;&#20165;&#38656;&#22522;&#20110;&#37319;&#26679;&#30340;&#35775;&#38382;&#26469;&#20248;&#21270;&#33719;&#21462;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2401.10811</link><description>&lt;p&gt;
&#22522;&#20110;&#20223;&#30495;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Simulation Based Bayesian Optimization. (arXiv:2401.10811v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10811
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#20223;&#30495;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;SBBO&#65289;&#20316;&#20026;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#36890;&#36807;&#20165;&#38656;&#22522;&#20110;&#37319;&#26679;&#30340;&#35775;&#38382;&#26469;&#20248;&#21270;&#33719;&#21462;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31181;&#23558;&#20808;&#39564;&#30693;&#35782;&#19982;&#25345;&#32493;&#20989;&#25968;&#35780;&#20272;&#30456;&#32467;&#21512;&#30340;&#24378;&#22823;&#26041;&#27861;&#65292;&#29992;&#20110;&#20248;&#21270;&#40657;&#30418;&#20989;&#25968;&#12290;&#36125;&#21494;&#26031;&#20248;&#21270;&#36890;&#36807;&#26500;&#24314;&#19982;&#21327;&#21464;&#37327;&#30456;&#20851;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;&#27010;&#29575;&#20195;&#29702;&#27169;&#22411;&#26469;&#25351;&#23548;&#26410;&#26469;&#35780;&#20272;&#28857;&#30340;&#36873;&#25321;&#12290;&#23545;&#20110;&#24179;&#28369;&#36830;&#32493;&#30340;&#25628;&#32034;&#31354;&#38388;&#65292;&#39640;&#26031;&#36807;&#31243;&#32463;&#24120;&#34987;&#29992;&#20316;&#20195;&#29702;&#27169;&#22411;&#65292;&#22240;&#20026;&#23427;&#20204;&#25552;&#20379;&#23545;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#30340;&#35299;&#26512;&#35775;&#38382;&#65292;&#20174;&#32780;&#20415;&#20110;&#35745;&#31639;&#21644;&#20248;&#21270;&#33719;&#21462;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#22312;&#28041;&#21450;&#23545;&#20998;&#31867;&#25110;&#28151;&#21512;&#21327;&#21464;&#37327;&#31354;&#38388;&#36827;&#34892;&#20248;&#21270;&#30340;&#22797;&#26434;&#24773;&#20917;&#19979;&#65292;&#39640;&#26031;&#36807;&#31243;&#21487;&#33021;&#19981;&#26159;&#29702;&#24819;&#30340;&#36873;&#25321;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#22522;&#20110;&#20223;&#30495;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;SBBO&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20165;&#38656;&#35201;&#23545;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#36827;&#34892;&#22522;&#20110;&#37319;&#26679;&#30340;&#35775;&#38382;&#65292;&#20197;&#20248;&#21270;&#33719;&#21462;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian Optimization (BO) is a powerful method for optimizing black-box functions by combining prior knowledge with ongoing function evaluations. BO constructs a probabilistic surrogate model of the objective function given the covariates, which is in turn used to inform the selection of future evaluation points through an acquisition function. For smooth continuous search spaces, Gaussian Processes (GPs) are commonly used as the surrogate model as they offer analytical access to posterior predictive distributions, thus facilitating the computation and optimization of acquisition functions. However, in complex scenarios involving optimizations over categorical or mixed covariate spaces, GPs may not be ideal.  This paper introduces Simulation Based Bayesian Optimization (SBBO) as a novel approach to optimizing acquisition functions that only requires \emph{sampling-based} access to posterior predictive distributions. SBBO allows the use of surrogate probabilistic models tailored for co
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ROME&#30340;&#40065;&#26834;&#22810;&#27169;&#24577;&#23494;&#24230;&#20272;&#35745;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#32858;&#31867;&#23558;&#22810;&#27169;&#24577;&#26679;&#26412;&#38598;&#20998;&#21106;&#25104;&#22810;&#20010;&#21333;&#27169;&#24577;&#26679;&#26412;&#38598;&#65292;&#24182;&#36890;&#36807;&#31616;&#21333;&#30340;KDE&#20272;&#35745;&#26469;&#20272;&#35745;&#25972;&#20307;&#20998;&#24067;&#12290;&#36825;&#31181;&#26041;&#27861;&#35299;&#20915;&#20102;&#22810;&#27169;&#24577;&#12289;&#38750;&#27491;&#24577;&#21644;&#39640;&#30456;&#20851;&#20998;&#24067;&#20272;&#35745;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2401.10566</link><description>&lt;p&gt;
&#40065;&#26834;&#30340;&#22810;&#27169;&#24577;&#23494;&#24230;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Robust Multi-Modal Density Estimation. (arXiv:2401.10566v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10566
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ROME&#30340;&#40065;&#26834;&#22810;&#27169;&#24577;&#23494;&#24230;&#20272;&#35745;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#32858;&#31867;&#23558;&#22810;&#27169;&#24577;&#26679;&#26412;&#38598;&#20998;&#21106;&#25104;&#22810;&#20010;&#21333;&#27169;&#24577;&#26679;&#26412;&#38598;&#65292;&#24182;&#36890;&#36807;&#31616;&#21333;&#30340;KDE&#20272;&#35745;&#26469;&#20272;&#35745;&#25972;&#20307;&#20998;&#24067;&#12290;&#36825;&#31181;&#26041;&#27861;&#35299;&#20915;&#20102;&#22810;&#27169;&#24577;&#12289;&#38750;&#27491;&#24577;&#21644;&#39640;&#30456;&#20851;&#20998;&#24067;&#20272;&#35745;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#27010;&#29575;&#39044;&#27979;&#27169;&#22411;&#30340;&#21457;&#23637;&#24341;&#21457;&#20102;&#23545;&#32508;&#21512;&#35780;&#20272;&#25351;&#26631;&#30340;&#38656;&#27714;&#12290;&#34429;&#28982;&#26377;&#20960;&#20010;&#25351;&#26631;&#21487;&#20197;&#34920;&#24449;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#65288;&#20363;&#22914;&#65292;&#36127;&#23545;&#25968;&#20284;&#28982;&#12289;Jensen-Shannon&#25955;&#24230;&#65289;&#65292;&#20294;&#36825;&#20123;&#25351;&#26631;&#36890;&#24120;&#20316;&#29992;&#20110;&#27010;&#29575;&#23494;&#24230;&#19978;&#12290;&#22240;&#27492;&#65292;&#23558;&#23427;&#20204;&#24212;&#29992;&#20110;&#32431;&#31929;&#22522;&#20110;&#26679;&#26412;&#30340;&#39044;&#27979;&#27169;&#22411;&#38656;&#35201;&#20272;&#35745;&#24213;&#23618;&#23494;&#24230;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#24120;&#35265;&#30340;&#26041;&#27861;&#22914;&#26680;&#23494;&#24230;&#20272;&#35745;&#65288;KDE&#65289;&#24050;&#34987;&#35777;&#26126;&#22312;&#40065;&#26834;&#24615;&#26041;&#38754;&#23384;&#22312;&#19981;&#36275;&#65292;&#32780;&#26356;&#22797;&#26434;&#30340;&#26041;&#27861;&#22312;&#22810;&#27169;&#24577;&#20272;&#35745;&#38382;&#39064;&#20013;&#23578;&#26410;&#24471;&#21040;&#35780;&#20272;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#30340;&#23494;&#24230;&#20272;&#35745;&#26041;&#27861;ROME&#65288;RObust Multi-modal density Estimator&#65289;&#65292;&#23427;&#35299;&#20915;&#20102;&#20272;&#35745;&#22810;&#27169;&#24577;&#12289;&#38750;&#27491;&#24577;&#21644;&#39640;&#30456;&#20851;&#20998;&#24067;&#30340;&#25361;&#25112;&#12290;ROME&#21033;&#29992;&#32858;&#31867;&#23558;&#22810;&#27169;&#24577;&#26679;&#26412;&#38598;&#20998;&#21106;&#25104;&#22810;&#20010;&#21333;&#27169;&#24577;&#26679;&#26412;&#38598;&#65292;&#28982;&#21518;&#32467;&#21512;&#31616;&#21333;&#30340;KDE&#20272;&#35745;&#26469;&#24471;&#21040;&#24635;&#20307;&#30340;&#20272;&#35745;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Development of multi-modal, probabilistic prediction models has lead to a need for comprehensive evaluation metrics. While several metrics can characterize the accuracy of machine-learned models (e.g., negative log-likelihood, Jensen-Shannon divergence), these metrics typically operate on probability densities. Applying them to purely sample-based prediction models thus requires that the underlying density function is estimated. However, common methods such as kernel density estimation (KDE) have been demonstrated to lack robustness, while more complex methods have not been evaluated in multi-modal estimation problems. In this paper, we present ROME (RObust Multi-modal density Estimator), a non-parametric approach for density estimation which addresses the challenge of estimating multi-modal, non-normal, and highly correlated distributions. ROME utilizes clustering to segment a multi-modal set of samples into multiple uni-modal ones and then combines simple KDE estimates obtained for i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21483;&#20570;LDReg&#30340;&#26412;&#22320;&#32500;&#24230;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#32500;&#24230;&#22349;&#32553;&#38382;&#39064;&#12290;&#36890;&#36807;&#22686;&#21152;&#23616;&#37096;&#20869;&#22312;&#32500;&#24230;&#65292;LDReg&#33021;&#22815;&#25913;&#21892;&#34920;&#31034;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.10474</link><description>&lt;p&gt;
LDReg: &#26412;&#22320;&#32500;&#24230;&#27491;&#21017;&#21270;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
LDReg: Local Dimensionality Regularized Self-Supervised Learning. (arXiv:2401.10474v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10474
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21483;&#20570;LDReg&#30340;&#26412;&#22320;&#32500;&#24230;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#32500;&#24230;&#22349;&#32553;&#38382;&#39064;&#12290;&#36890;&#36807;&#22686;&#21152;&#23616;&#37096;&#20869;&#22312;&#32500;&#24230;&#65292;LDReg&#33021;&#22815;&#25913;&#21892;&#34920;&#31034;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#23398;&#20064;&#30340;&#34920;&#31034;&#21487;&#33021;&#23481;&#26131;&#20986;&#29616;&#32500;&#24230;&#22349;&#32553;&#65292;&#20854;&#20013;&#23398;&#20064;&#30340;&#34920;&#31034;&#23376;&#31354;&#38388;&#32500;&#24230;&#26497;&#20302;&#65292;&#22240;&#27492;&#26080;&#27861;&#34920;&#31034;&#23436;&#25972;&#30340;&#25968;&#25454;&#20998;&#24067;&#21644;&#27169;&#24577;&#12290;&#32500;&#24230;&#22349;&#32553;&#20063;&#34987;&#31216;&#20026;&#8220;&#22635;&#20805;&#19981;&#36275;&#8221;&#29616;&#35937;&#65292;&#26159;&#19979;&#28216;&#20219;&#21153;&#24615;&#33021;&#19979;&#38477;&#30340;&#20027;&#35201;&#21407;&#22240;&#20043;&#19968;&#12290;&#20043;&#21069;&#30340;&#24037;&#20316;&#22312;&#20840;&#23616;&#23618;&#38754;&#19978;&#30740;&#31350;&#20102;SSL&#30340;&#32500;&#24230;&#22349;&#32553;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#34920;&#31034;&#21487;&#20197;&#22312;&#20840;&#23616;&#19978;&#35206;&#30422;&#39640;&#32500;&#31354;&#38388;&#65292;&#20294;&#22312;&#23616;&#37096;&#19978;&#20250;&#22349;&#32553;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#26412;&#22320;&#32500;&#24230;&#27491;&#21017;&#21270;&#65288;LDReg&#65289;&#8221;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#20844;&#24335;&#26159;&#22522;&#20110;Fisher-Rao&#24230;&#37327;&#30340;&#25512;&#23548;&#65292;&#29992;&#20110;&#27604;&#36739;&#21644;&#20248;&#21270;&#27599;&#20010;&#25968;&#25454;&#28857;&#22312;&#28176;&#36827;&#23567;&#21322;&#24452;&#22788;&#30340;&#23616;&#37096;&#36317;&#31163;&#20998;&#24067;&#12290;&#36890;&#36807;&#22686;&#21152;&#23616;&#37096;&#20869;&#22312;&#32500;&#24230;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#31995;&#21015;&#23454;&#39564;&#35777;&#26126;LDReg&#21487;&#20197;&#25913;&#21892;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Representations learned via self-supervised learning (SSL) can be susceptible to dimensional collapse, where the learned representation subspace is of extremely low dimensionality and thus fails to represent the full data distribution and modalities. Dimensional collapse also known as the "underfilling" phenomenon is one of the major causes of degraded performance on downstream tasks. Previous work has investigated the dimensional collapse problem of SSL at a global level. In this paper, we demonstrate that representations can span over high dimensional space globally, but collapse locally. To address this, we propose a method called $\textit{local dimensionality regularization (LDReg)}$. Our formulation is based on the derivation of the Fisher-Rao metric to compare and optimize local distance distributions at an asymptotically small radius for each data point. By increasing the local intrinsic dimensionality, we demonstrate through a range of experiments that LDReg improves the repres
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#22810;&#26234;&#33021;&#20307;&#22270;&#24418;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#31639;&#27861;Multi-G-UCB&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.10383</link><description>&lt;p&gt;
&#21512;&#20316;&#22810;&#26234;&#33021;&#20307;&#22270;&#24418;&#36172;&#21338;&#26426;&#65306;UCB&#31639;&#27861;&#21644;&#36951;&#25022;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Cooperative Multi-Agent Graph Bandits: UCB Algorithm and Regret Analysis. (arXiv:2401.10383v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10383
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#22810;&#26234;&#33021;&#20307;&#22270;&#24418;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#31639;&#27861;Multi-G-UCB&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#22810;&#26234;&#33021;&#20307;&#22270;&#24418;&#36172;&#21338;&#26426;&#38382;&#39064;&#24314;&#27169;&#20026;Zhang&#12289;Johansson&#21644;Li&#22312;[CISS 57, 1-6 (2023)]&#20013;&#25552;&#20986;&#30340;&#22270;&#24418;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#22810;&#26234;&#33021;&#20307;&#25193;&#23637;&#12290;&#22312;&#25105;&#20204;&#30340;&#27169;&#22411;&#20013;&#65292;N&#20010;&#21512;&#20316;&#26234;&#33021;&#20307;&#22312;&#19968;&#20010;&#36830;&#36890;&#30340;&#22270;G&#19978;&#31227;&#21160;&#65292;&#22270;G&#26377;K&#20010;&#33410;&#28857;&#12290;&#25269;&#36798;&#27599;&#20010;&#33410;&#28857;&#26102;&#65292;&#26234;&#33021;&#20307;&#35266;&#23519;&#21040;&#20174;&#19968;&#20010;&#19982;&#33410;&#28857;&#30456;&#20851;&#30340;&#27010;&#29575;&#20998;&#24067;&#20013;&#38543;&#26426;&#25277;&#21462;&#30340;&#22870;&#21169;&#12290;&#31995;&#32479;&#22870;&#21169;&#34987;&#24314;&#27169;&#20026;&#26234;&#33021;&#20307;&#35266;&#27979;&#21040;&#30340;&#22870;&#21169;&#30340;&#21152;&#26435;&#21644;&#65292;&#20854;&#20013;&#26435;&#37325;&#34920;&#36798;&#20102;&#22810;&#20010;&#26234;&#33021;&#20307;&#21516;&#26102;&#23545;&#21516;&#19968;&#33410;&#28857;&#36827;&#34892;&#37319;&#26679;&#30340;&#36793;&#38469;&#20943;&#23569;&#22870;&#21169;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#19978;&#38480;&#32622;&#20449;&#21306;&#38388;&#65288;UCB&#65289;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#31216;&#20026;Multi-G-UCB&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;T&#27493;&#20869;&#20854;&#26399;&#26395;&#36951;&#25022;&#34987;&#30028;&#23450;&#20026;$O(N\log(T)[\sqrt{KT} + DK])$&#65292;&#20854;&#20013;D&#26159;&#22270;G&#30340;&#30452;&#24452;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#19982;&#20854;&#20182;&#26041;&#27861;&#36827;&#34892;&#27604;&#36739;&#23545;&#31639;&#27861;&#36827;&#34892;&#20102;&#25968;&#20540;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we formulate the multi-agent graph bandit problem as a multi-agent extension of the graph bandit problem introduced by Zhang, Johansson, and Li [CISS 57, 1-6 (2023)]. In our formulation, $N$ cooperative agents travel on a connected graph $G$ with $K$ nodes. Upon arrival at each node, agents observe a random reward drawn from a node-dependent probability distribution. The reward of the system is modeled as a weighted sum of the rewards the agents observe, where the weights capture the decreasing marginal reward associated with multiple agents sampling the same node at the same time. We propose an Upper Confidence Bound (UCB)-based learning algorithm, Multi-G-UCB, and prove that its expected regret over $T$ steps is bounded by $O(N\log(T)[\sqrt{KT} + DK])$, where $D$ is the diameter of graph $G$. Lastly, we numerically test our algorithm by comparing it to alternative methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;Vision Transformer&#20013;&#27880;&#24847;&#21147;&#22270;&#30340;&#32479;&#35745;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#27880;&#24847;&#21147;&#20316;&#20026;&#21487;&#38752;&#30340;&#23450;&#37327;&#35777;&#25454;&#25351;&#26631;&#29992;&#20110;&#20915;&#31574;&#65292;&#24182;&#36890;&#36807;p&#20540;&#36827;&#34892;&#32479;&#35745;&#26174;&#33879;&#24615;&#37327;&#21270;&#12290;</title><link>http://arxiv.org/abs/2401.08169</link><description>&lt;p&gt;
Vision Transformer&#20013;&#30340;&#27880;&#24847;&#21147;&#22270;&#32479;&#35745;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Statistical Test for Attention Map in Vision Transformer. (arXiv:2401.08169v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08169
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;Vision Transformer&#20013;&#27880;&#24847;&#21147;&#22270;&#30340;&#32479;&#35745;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#27880;&#24847;&#21147;&#20316;&#20026;&#21487;&#38752;&#30340;&#23450;&#37327;&#35777;&#25454;&#25351;&#26631;&#29992;&#20110;&#20915;&#31574;&#65292;&#24182;&#36890;&#36807;p&#20540;&#36827;&#34892;&#32479;&#35745;&#26174;&#33879;&#24615;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Vision Transformer&#65288;ViT&#65289;&#22312;&#21508;&#31181;&#35745;&#31639;&#26426;&#35270;&#35273;&#20219;&#21153;&#20013;&#23637;&#31034;&#20986;&#20102;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;&#27880;&#24847;&#21147;&#23545;&#20110;ViT&#25429;&#25417;&#22270;&#20687;&#34917;&#19969;&#20043;&#38388;&#22797;&#26434;&#24191;&#27867;&#30340;&#20851;&#31995;&#38750;&#24120;&#37325;&#35201;&#65292;&#20351;&#24471;&#27169;&#22411;&#21487;&#20197;&#26435;&#34913;&#22270;&#20687;&#34917;&#19969;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#24110;&#21161;&#25105;&#20204;&#29702;&#35299;&#20915;&#31574;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#24403;&#23558;ViT&#30340;&#27880;&#24847;&#21147;&#29992;&#20316;&#39640;&#39118;&#38505;&#20915;&#31574;&#20219;&#21153;&#65288;&#22914;&#21307;&#23398;&#35786;&#26029;&#65289;&#20013;&#30340;&#35777;&#25454;&#26102;&#65292;&#38754;&#20020;&#19968;&#20010;&#25361;&#25112;&#65292;&#21363;&#27880;&#24847;&#26426;&#21046;&#21487;&#33021;&#38169;&#35823;&#22320;&#20851;&#27880;&#26080;&#20851;&#30340;&#21306;&#22495;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;ViT&#27880;&#24847;&#21147;&#30340;&#32479;&#35745;&#26816;&#39564;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;&#27880;&#24847;&#21147;&#20316;&#20026;&#21487;&#38752;&#30340;&#23450;&#37327;&#35777;&#25454;&#25351;&#26631;&#29992;&#20110;ViT&#30340;&#20915;&#31574;&#65292;&#24182;&#20005;&#26684;&#25511;&#21046;&#35823;&#24046;&#29575;&#12290;&#20351;&#29992;&#36873;&#25321;&#24615;&#25512;&#29702;&#26694;&#26550;&#65292;&#25105;&#20204;&#20197;p&#20540;&#30340;&#24418;&#24335;&#37327;&#21270;&#27880;&#24847;&#21147;&#30340;&#32479;&#35745;&#26174;&#33879;&#24615;&#65292;&#20174;&#32780;&#33021;&#22815;&#29702;&#35770;&#19978;&#22522;&#20110;&#20551;&#38451;&#24615;&#26816;&#27979;&#27010;&#29575;&#37327;&#21270;&#27880;&#24847;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Vision Transformer (ViT) demonstrates exceptional performance in various computer vision tasks. Attention is crucial for ViT to capture complex wide-ranging relationships among image patches, allowing the model to weigh the importance of image patches and aiding our understanding of the decision-making process. However, when utilizing the attention of ViT as evidence in high-stakes decision-making tasks such as medical diagnostics, a challenge arises due to the potential of attention mechanisms erroneously focusing on irrelevant regions. In this study, we propose a statistical test for ViT's attentions, enabling us to use the attentions as reliable quantitative evidence indicators for ViT's decision-making with a rigorously controlled error rate. Using the framework called selective inference, we quantify the statistical significance of attentions in the form of p-values, which enables the theoretically grounded quantification of the false positive detection probability of attentio
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#23558;&#27010;&#29575;Lambert&#38382;&#39064;&#19982;&#26368;&#20248;&#36136;&#37327;&#20256;&#36755;&#12289;Schr\"odinger&#26725;&#21644;&#21453;&#24212;-&#25193;&#25955;&#20559;&#24494;&#20998;&#26041;&#31243;&#31561;&#39046;&#22495;&#36830;&#25509;&#36215;&#26469;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#27010;&#29575;Lambert&#38382;&#39064;&#30340;&#35299;&#30340;&#23384;&#22312;&#21644;&#21807;&#19968;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#25968;&#20540;&#27714;&#35299;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.07961</link><description>&lt;p&gt;
&#27010;&#29575;Lambert&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#26696;&#65306;&#19982;&#26368;&#20248;&#36136;&#37327;&#20256;&#36755;&#12289;Schr\"odinger&#26725;&#21644;&#21453;&#24212;-&#25193;&#25955;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#36830;&#25509;
&lt;/p&gt;
&lt;p&gt;
Solution of the Probabilistic Lambert Problem: Connections with Optimal Mass Transport, Schr\"odinger Bridge and Reaction-Diffusion PDEs. (arXiv:2401.07961v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.07961
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#23558;&#27010;&#29575;Lambert&#38382;&#39064;&#19982;&#26368;&#20248;&#36136;&#37327;&#20256;&#36755;&#12289;Schr\"odinger&#26725;&#21644;&#21453;&#24212;-&#25193;&#25955;&#20559;&#24494;&#20998;&#26041;&#31243;&#31561;&#39046;&#22495;&#36830;&#25509;&#36215;&#26469;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#27010;&#29575;Lambert&#38382;&#39064;&#30340;&#35299;&#30340;&#23384;&#22312;&#21644;&#21807;&#19968;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#25968;&#20540;&#27714;&#35299;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Lambert&#38382;&#39064;&#28041;&#21450;&#36890;&#36807;&#36895;&#24230;&#25511;&#21046;&#22312;&#35268;&#23450;&#30340;&#39134;&#34892;&#26102;&#38388;&#20869;&#23558;&#33322;&#22825;&#22120;&#20174;&#32473;&#23450;&#30340;&#21021;&#22987;&#20301;&#32622;&#36716;&#31227;&#21040;&#32473;&#23450;&#30340;&#32456;&#31471;&#20301;&#32622;&#65292;&#21463;&#21040;&#37325;&#21147;&#21147;&#22330;&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;Lambert&#38382;&#39064;&#30340;&#27010;&#29575;&#21464;&#31181;&#65292;&#20854;&#20013;&#20301;&#32622;&#21521;&#37327;&#30340;&#31471;&#28857;&#32422;&#26463;&#30340;&#30693;&#35782;&#34987;&#23427;&#20204;&#21508;&#33258;&#30340;&#32852;&#21512;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#25152;&#26367;&#20195;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20855;&#26377;&#31471;&#28857;&#32852;&#21512;&#27010;&#29575;&#23494;&#24230;&#32422;&#26463;&#30340;Lambert&#38382;&#39064;&#26159;&#19968;&#20010;&#24191;&#20041;&#30340;&#26368;&#20248;&#36136;&#37327;&#20256;&#36755;&#65288;OMT&#65289;&#38382;&#39064;&#65292;&#20174;&#32780;&#23558;&#36825;&#20010;&#32463;&#20856;&#30340;&#22825;&#20307;&#21160;&#21147;&#23398;&#38382;&#39064;&#19982;&#29616;&#20195;&#38543;&#26426;&#25511;&#21046;&#21644;&#38543;&#26426;&#26426;&#22120;&#23398;&#20064;&#30340;&#26032;&#20852;&#30740;&#31350;&#39046;&#22495;&#32852;&#31995;&#36215;&#26469;&#12290;&#36825;&#20010;&#26032;&#21457;&#29616;&#30340;&#36830;&#25509;&#20351;&#25105;&#20204;&#33021;&#22815;&#20005;&#26684;&#24314;&#31435;&#27010;&#29575;Lambert&#38382;&#39064;&#30340;&#35299;&#30340;&#23384;&#22312;&#24615;&#21644;&#21807;&#19968;&#24615;&#12290;&#21516;&#26679;&#30340;&#36830;&#25509;&#36824;&#24110;&#21161;&#36890;&#36807;&#25193;&#25955;&#27491;&#35268;&#21270;&#25968;&#20540;&#27714;&#35299;&#27010;&#29575;Lambert&#38382;&#39064;&#65292;&#21363;&#36890;&#36807;&#36827;&#19968;&#27493;&#30340;&#36830;&#25509;&#26469;&#21033;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Lambert's problem concerns with transferring a spacecraft from a given initial to a given terminal position within prescribed flight time via velocity control subject to a gravitational force field. We consider a probabilistic variant of the Lambert problem where the knowledge of the endpoint constraints in position vectors are replaced by the knowledge of their respective joint probability density functions. We show that the Lambert problem with endpoint joint probability density constraints is a generalized optimal mass transport (OMT) problem, thereby connecting this classical astrodynamics problem with a burgeoning area of research in modern stochastic control and stochastic machine learning. This newfound connection allows us to rigorously establish the existence and uniqueness of solution for the probabilistic Lambert problem. The same connection also helps to numerically solve the probabilistic Lambert problem via diffusion regularization, i.e., by leveraging further connection 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#12289;&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#20998;&#31867;&#21644;&#34920;&#24449;&#21160;&#21147;&#23398;&#21464;&#21270;&#30340;&#25299;&#25169;&#19981;&#21464;&#29305;&#24449;&#25552;&#21462;&#65292;&#29305;&#21035;&#20851;&#27880;&#36229;&#20020;&#30028;&#38669;&#26222;&#20998;&#27495;&#12290;&#36825;&#20010;&#26041;&#27861;&#21487;&#20197;&#24110;&#21161;&#39044;&#27979;&#31995;&#32479;&#30340;&#36136;&#21464;&#21644;&#24120;&#21457;&#34892;&#20026;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2312.09234</link><description>&lt;p&gt;
&#20570;&#26102;&#38388;&#25197;&#26354;&#21543;&#65306;&#23398;&#20064;&#21160;&#21147;&#31995;&#32479;&#30340;&#25299;&#25169;&#19981;&#21464;&#37327;
&lt;/p&gt;
&lt;p&gt;
Let's do the time-warp-attend: Learning topological invariants of dynamical systems. (arXiv:2312.09234v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.09234
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#12289;&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#20998;&#31867;&#21644;&#34920;&#24449;&#21160;&#21147;&#23398;&#21464;&#21270;&#30340;&#25299;&#25169;&#19981;&#21464;&#29305;&#24449;&#25552;&#21462;&#65292;&#29305;&#21035;&#20851;&#27880;&#36229;&#20020;&#30028;&#38669;&#26222;&#20998;&#27495;&#12290;&#36825;&#20010;&#26041;&#27861;&#21487;&#20197;&#24110;&#21161;&#39044;&#27979;&#31995;&#32479;&#30340;&#36136;&#21464;&#21644;&#24120;&#21457;&#34892;&#20026;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31185;&#23398;&#39046;&#22495;&#20013;&#30340;&#21160;&#21147;&#31995;&#32479;&#65292;&#20174;&#30005;&#36335;&#21040;&#29983;&#24577;&#32593;&#32476;&#65292;&#24403;&#20854;&#22522;&#26412;&#21442;&#25968;&#36328;&#36234;&#38408;&#20540;&#26102;&#65292;&#20250;&#21457;&#29983;&#36136;&#21464;&#21644;&#24120;&#21457;&#24615;&#30340;&#34892;&#20026;&#21464;&#21270;&#65292;&#31216;&#20026;&#20998;&#27495;&#12290;&#29616;&#26377;&#26041;&#27861;&#33021;&#22815;&#39044;&#27979;&#21333;&#20010;&#31995;&#32479;&#20013;&#21363;&#23558;&#21457;&#29983;&#30340;&#28798;&#38590;&#65292;&#20294;&#20027;&#35201;&#22522;&#20110;&#26102;&#38388;&#24207;&#21015;&#65292;&#24182;&#19988;&#22312;&#20998;&#31867;&#19981;&#21516;&#31995;&#32479;&#30340;&#23450;&#24615;&#21160;&#21147;&#23398;&#21464;&#21270;&#21644;&#25512;&#24191;&#21040;&#30495;&#23454;&#25968;&#25454;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#30340;&#12289;&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#23545;&#21160;&#21147;&#23398;&#21464;&#21270;&#36827;&#34892;&#20998;&#31867;&#24182;&#34920;&#24449;&#20998;&#27495;&#36793;&#30028;&#30340;&#25299;&#25169;&#19981;&#21464;&#29305;&#24449;&#25552;&#21462;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#36229;&#20020;&#30028;&#38669;&#26222;&#20998;&#27495;&#30340;&#20856;&#22411;&#26696;&#20363;&#65292;&#20854;&#29992;&#20110;&#27169;&#25311;&#24191;&#27867;&#24212;&#29992;&#30340;&#21608;&#26399;&#24615;&#21160;&#21147;&#23398;&#12290;&#25105;&#20204;&#30340;&#21367;&#31215;&#20851;&#27880;&#26041;&#27861;&#32463;&#36807;&#20102;&#25968;&#25454;&#22686;&#24378;&#35757;&#32451;&#65292;&#40723;&#21169;&#23398;&#20064;&#21487;&#20197;&#29992;&#20110;&#26816;&#27979;&#20998;&#27495;&#36793;&#30028;&#30340;&#25299;&#25169;&#19981;&#21464;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dynamical systems across the sciences, from electrical circuits to ecological networks, undergo qualitative and often catastrophic changes in behavior, called bifurcations, when their underlying parameters cross a threshold. Existing methods predict oncoming catastrophes in individual systems but are primarily time-series-based and struggle both to categorize qualitative dynamical regimes across diverse systems and to generalize to real data. To address this challenge, we propose a data-driven, physically-informed deep-learning framework for classifying dynamical regimes and characterizing bifurcation boundaries based on the extraction of topologically invariant features. We focus on the paradigmatic case of the supercritical Hopf bifurcation, which is used to model periodic dynamics across a wide range of applications. Our convolutional attention method is trained with data augmentations that encourage the learning of topological invariants which can be used to detect bifurcation boun
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#21464;&#37327;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#38750;&#23618;&#27425;&#21270;&#22810;&#20445;&#30495;&#24230;&#33258;&#36866;&#24212;&#37319;&#26679;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#21033;&#29992;&#19981;&#21516;&#20445;&#30495;&#24230;&#27169;&#22411;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#20197;&#26356;&#39640;&#25928;&#22320;&#25506;&#32034;&#21644;&#21033;&#29992;&#35774;&#35745;&#31354;&#38388;&#12290;</title><link>http://arxiv.org/abs/2310.03298</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#38750;&#23618;&#27425;&#21270;&#22810;&#20445;&#30495;&#24230;&#33258;&#36866;&#24212;&#37319;&#26679;&#30340;&#28508;&#21464;&#37327;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Latent Variable Approach for Non-Hierarchical Multi-Fidelity Adaptive Sampling. (arXiv:2310.03298v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03298
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#21464;&#37327;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#38750;&#23618;&#27425;&#21270;&#22810;&#20445;&#30495;&#24230;&#33258;&#36866;&#24212;&#37319;&#26679;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#21033;&#29992;&#19981;&#21516;&#20445;&#30495;&#24230;&#27169;&#22411;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#20197;&#26356;&#39640;&#25928;&#22320;&#25506;&#32034;&#21644;&#21033;&#29992;&#35774;&#35745;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20445;&#30495;&#24230;&#65288;MF&#65289;&#26041;&#27861;&#22312;&#25552;&#39640;&#26367;&#20195;&#27169;&#22411;&#21644;&#35774;&#35745;&#20248;&#21270;&#26041;&#38754;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#65292;&#36890;&#36807;&#25972;&#21512;&#26469;&#33258;&#19981;&#21516;&#20302;&#20445;&#30495;&#24230;&#65288;LF&#65289;&#27169;&#22411;&#30340;&#25968;&#25454;&#12290;&#23613;&#31649;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;MF&#26041;&#27861;&#20551;&#23450;&#20102;&#19968;&#20010;&#22266;&#23450;&#30340;&#25968;&#25454;&#38598;&#65292;&#20294;&#26159;&#21160;&#24577;&#20998;&#37197;&#36164;&#28304;&#22312;&#19981;&#21516;&#20445;&#30495;&#24230;&#27169;&#22411;&#20043;&#38388;&#21487;&#20197;&#23454;&#29616;&#26356;&#39640;&#30340;&#25506;&#32034;&#21644;&#21033;&#29992;&#35774;&#35745;&#31354;&#38388;&#30340;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;MF&#26041;&#27861;&#20381;&#36182;&#20110;&#20445;&#30495;&#24230;&#32423;&#21035;&#30340;&#23618;&#27425;&#20551;&#35774;&#65292;&#25110;&#32773;&#26080;&#27861;&#25429;&#25417;&#22810;&#20010;&#20445;&#30495;&#24230;&#32423;&#21035;&#20043;&#38388;&#30340;&#30456;&#20114;&#20851;&#31995;&#24182;&#21033;&#29992;&#20854;&#26469;&#37327;&#21270;&#26410;&#26469;&#26679;&#26412;&#30340;&#20215;&#20540;&#21644;&#23548;&#33322;&#33258;&#36866;&#24212;&#37319;&#26679;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38556;&#30861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#19981;&#21516;&#20445;&#30495;&#24230;&#27169;&#22411;&#30340;&#28508;&#21464;&#37327;&#23884;&#20837;&#21644;&#30456;&#20851;&#30340;&#20808;&#39564;-&#21518;&#39564;&#20998;&#26512;&#30340;&#26694;&#26550;&#65292;&#20197;&#26174;&#24335;&#22320;&#21033;&#29992;&#23427;&#20204;&#30340;&#30456;&#20851;&#24615;&#36827;&#34892;&#33258;&#36866;&#24212;&#37319;&#26679;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#20013;&#65292;&#27599;&#20010;&#22635;&#20805;&#37319;&#26679;&#36845;&#20195;&#21253;&#25324;&#20004;&#20010;&#27493;&#39588;&#65306;&#39318;&#20808;&#25105;&#20204;&#30830;&#23450;&#20855;&#26377;&#26368;&#22823;&#28508;&#21147;&#24433;&#21709;&#30340;&#20301;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-fidelity (MF) methods are gaining popularity for enhancing surrogate modeling and design optimization by incorporating data from various low-fidelity (LF) models. While most existing MF methods assume a fixed dataset, adaptive sampling methods that dynamically allocate resources among fidelity models can achieve higher efficiency in the exploring and exploiting the design space. However, most existing MF methods rely on the hierarchical assumption of fidelity levels or fail to capture the intercorrelation between multiple fidelity levels and utilize it to quantify the value of the future samples and navigate the adaptive sampling. To address this hurdle, we propose a framework hinged on a latent embedding for different fidelity models and the associated pre-posterior analysis to explicitly utilize their correlation for adaptive sampling. In this framework, each infill sampling iteration includes two steps: We first identify the location of interest with the greatest potential imp
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#30340;&#19981;&#30830;&#23450;&#24615;&#26657;&#20934;&#65288;U2C&#65289;&#26694;&#26550;&#65292;&#29992;&#20110;&#21512;&#24182;&#21487;&#30693;&#21644;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#65292;&#23454;&#29616;&#20102;&#38754;&#23545;&#22256;&#38590;&#26679;&#20363;&#26102;&#30340;&#20934;&#30830;&#39044;&#27979;&#21644;&#26657;&#20934;&#12290;</title><link>http://arxiv.org/abs/2310.01202</link><description>&lt;p&gt;
&#32479;&#19968;&#30340;&#19981;&#30830;&#23450;&#24615;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Unified Uncertainty Calibration. (arXiv:2310.01202v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01202
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#30340;&#19981;&#30830;&#23450;&#24615;&#26657;&#20934;&#65288;U2C&#65289;&#26694;&#26550;&#65292;&#29992;&#20110;&#21512;&#24182;&#21487;&#30693;&#21644;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#65292;&#23454;&#29616;&#20102;&#38754;&#23545;&#22256;&#38590;&#26679;&#20363;&#26102;&#30340;&#20934;&#30830;&#39044;&#27979;&#21644;&#26657;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#26500;&#24314;&#20581;&#22766;&#65292;&#20844;&#24179;&#21644;&#23433;&#20840;&#30340;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#65292;&#25105;&#20204;&#24076;&#26395;&#22312;&#38754;&#23545;&#22256;&#38590;&#25110;&#36229;&#20986;&#35757;&#32451;&#31867;&#21035;&#30340;&#27979;&#35797;&#26679;&#20363;&#26102;&#65292;&#20998;&#31867;&#22120;&#33021;&#22815;&#35828;&#8220;&#25105;&#19981;&#30693;&#36947;&#8221;&#12290;&#26222;&#36941;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#31574;&#30053;&#26159;&#31616;&#21333;&#30340;&#8220;&#25298;&#32477;&#25110;&#20998;&#31867;&#8221;&#35268;&#21017;&#65306;&#22914;&#26524;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#39640;&#65292;&#21017;&#25918;&#24323;&#39044;&#27979;&#65292;&#21542;&#21017;&#36827;&#34892;&#20998;&#31867;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#19981;&#20801;&#35768;&#19981;&#21516;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#30456;&#20114;&#36890;&#20449;&#65292;&#20250;&#20135;&#29983;&#26410;&#26657;&#20934;&#30340;&#39044;&#27979;&#65292;&#24182;&#19988;&#19981;&#33021;&#32416;&#27491;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#20013;&#30340;&#38169;&#35823;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19977;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#32479;&#19968;&#30340;&#19981;&#30830;&#23450;&#24615;&#26657;&#20934;&#65288;U2C&#65289;&#30340;&#25972;&#20307;&#26694;&#26550;&#65292;&#29992;&#20110;&#21512;&#24182;&#21487;&#30693;&#21644;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#12290;U2C&#33021;&#22815;&#36827;&#34892;&#28165;&#26224;&#30340;&#23398;&#20064;&#29702;&#35770;&#20998;&#26512;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#24182;&#19988;&#22312;&#21508;&#31181;ImageNet&#22522;&#20934;&#27979;&#35797;&#20013;&#20248;&#20110;&#25298;&#32477;&#25110;&#20998;&#31867;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
To build robust, fair, and safe AI systems, we would like our classifiers to say ``I don't know'' when facing test examples that are difficult or fall outside of the training classes.The ubiquitous strategy to predict under uncertainty is the simplistic \emph{reject-or-classify} rule: abstain from prediction if epistemic uncertainty is high, classify otherwise.Unfortunately, this recipe does not allow different sources of uncertainty to communicate with each other, produces miscalibrated predictions, and it does not allow to correct for misspecifications in our uncertainty estimates. To address these three issues, we introduce \emph{unified uncertainty calibration (U2C)}, a holistic framework to combine aleatoric and epistemic uncertainties. U2C enables a clean learning-theoretical analysis of uncertainty estimation, and outperforms reject-or-classify across a variety of ImageNet benchmarks.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#32622;&#25442;&#19981;&#21464;&#31070;&#32463;&#32593;&#32476;&#23545;&#38598;&#21512;&#22825;&#27668;&#39044;&#27979;&#36827;&#34892;&#21518;&#22788;&#29702;&#65292;&#19981;&#21516;&#20110;&#20043;&#21069;&#30340;&#26041;&#27861;&#65292;&#35813;&#32593;&#32476;&#23558;&#39044;&#27979;&#38598;&#21512;&#35270;&#20026;&#19968;&#32452;&#26080;&#24207;&#30340;&#25104;&#21592;&#39044;&#27979;&#65292;&#24182;&#23398;&#20064;&#23545;&#25104;&#21592;&#39034;&#24207;&#30340;&#25490;&#21015;&#32622;&#25442;&#20855;&#26377;&#19981;&#21464;&#24615;&#30340;&#38142;&#25509;&#20989;&#25968;&#12290;&#22312;&#22320;&#34920;&#28201;&#24230;&#21644;&#39118;&#36895;&#39044;&#27979;&#30340;&#26696;&#20363;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26368;&#20808;&#36827;&#30340;&#39044;&#27979;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2309.04452</link><description>&lt;p&gt;
&#20351;&#29992;&#32622;&#25442;&#19981;&#21464;&#31070;&#32463;&#32593;&#32476;&#23545;&#38598;&#21512;&#22825;&#27668;&#39044;&#27979;&#36827;&#34892;&#21518;&#22788;&#29702;
&lt;/p&gt;
&lt;p&gt;
Postprocessing of Ensemble Weather Forecasts Using Permutation-invariant Neural Networks. (arXiv:2309.04452v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04452
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#32622;&#25442;&#19981;&#21464;&#31070;&#32463;&#32593;&#32476;&#23545;&#38598;&#21512;&#22825;&#27668;&#39044;&#27979;&#36827;&#34892;&#21518;&#22788;&#29702;&#65292;&#19981;&#21516;&#20110;&#20043;&#21069;&#30340;&#26041;&#27861;&#65292;&#35813;&#32593;&#32476;&#23558;&#39044;&#27979;&#38598;&#21512;&#35270;&#20026;&#19968;&#32452;&#26080;&#24207;&#30340;&#25104;&#21592;&#39044;&#27979;&#65292;&#24182;&#23398;&#20064;&#23545;&#25104;&#21592;&#39034;&#24207;&#30340;&#25490;&#21015;&#32622;&#25442;&#20855;&#26377;&#19981;&#21464;&#24615;&#30340;&#38142;&#25509;&#20989;&#25968;&#12290;&#22312;&#22320;&#34920;&#28201;&#24230;&#21644;&#39118;&#36895;&#39044;&#27979;&#30340;&#26696;&#20363;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26368;&#20808;&#36827;&#30340;&#39044;&#27979;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32479;&#35745;&#21518;&#22788;&#29702;&#29992;&#20110;&#23558;&#21407;&#22987;&#25968;&#20540;&#22825;&#27668;&#39044;&#25253;&#30340;&#38598;&#21512;&#36716;&#21270;&#20026;&#21487;&#38752;&#30340;&#27010;&#29575;&#39044;&#27979;&#20998;&#24067;&#12290;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#32771;&#23519;&#20102;&#20351;&#29992;&#32622;&#25442;&#19981;&#21464;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#36825;&#19968;&#20219;&#21153;&#30340;&#26041;&#27861;&#12290;&#19982;&#20197;&#24448;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#36890;&#24120;&#22522;&#20110;&#38598;&#21512;&#27010;&#35201;&#32479;&#35745;&#20449;&#24687;&#24182;&#24573;&#30053;&#38598;&#21512;&#20998;&#24067;&#30340;&#32454;&#33410;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#32593;&#32476;&#23558;&#39044;&#27979;&#38598;&#21512;&#35270;&#20026;&#19968;&#32452;&#26080;&#24207;&#30340;&#25104;&#21592;&#39044;&#27979;&#65292;&#24182;&#23398;&#20064;&#23545;&#25104;&#21592;&#39034;&#24207;&#30340;&#25490;&#21015;&#32622;&#25442;&#20855;&#26377;&#19981;&#21464;&#24615;&#30340;&#38142;&#25509;&#20989;&#25968;&#12290;&#25105;&#20204;&#36890;&#36807;&#26657;&#20934;&#24230;&#21644;&#38160;&#24230;&#35780;&#20272;&#25152;&#33719;&#24471;&#30340;&#39044;&#27979;&#20998;&#24067;&#30340;&#36136;&#37327;&#65292;&#24182;&#23558;&#27169;&#22411;&#19982;&#32463;&#20856;&#30340;&#22522;&#20934;&#26041;&#27861;&#21644;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#36827;&#34892;&#27604;&#36739;&#12290;&#36890;&#36807;&#22788;&#29702;&#22320;&#34920;&#28201;&#24230;&#21644;&#39118;&#36895;&#39044;&#27979;&#30340;&#26696;&#20363;&#30740;&#31350;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26368;&#20808;&#36827;&#30340;&#39044;&#27979;&#36136;&#37327;&#12290;&#20026;&#20102;&#21152;&#28145;&#23545;&#23398;&#20064;&#25512;&#29702;&#36807;&#31243;&#30340;&#29702;&#35299;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#22522;&#20110;&#32622;&#25442;&#30340;&#37325;&#35201;&#24615;&#35780;&#20272;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Statistical postprocessing is used to translate ensembles of raw numerical weather forecasts into reliable probabilistic forecast distributions. In this study, we examine the use of permutation-invariant neural networks for this task. In contrast to previous approaches, which often operate on ensemble summary statistics and dismiss details of the ensemble distribution, we propose networks which treat forecast ensembles as a set of unordered member forecasts and learn link functions that are by design invariant to permutations of the member ordering. We evaluate the quality of the obtained forecast distributions in terms of calibration and sharpness, and compare the models against classical and neural network-based benchmark methods. In case studies addressing the postprocessing of surface temperature and wind gust forecasts, we demonstrate state-of-the-art prediction quality. To deepen the understanding of the learned inference process, we further propose a permutation-based importance
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20351;&#29992;&#24402;&#19968;&#21270;&#27969;&#23398;&#20064;&#36793;&#32536;&#20284;&#28982;&#30340;&#35843;&#21644;&#24179;&#22343;&#20272;&#35745;&#65292;&#22312;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#20013;&#35299;&#20915;&#20102;&#21407;&#22987;&#26041;&#27861;&#20013;&#30340;&#26041;&#24046;&#29190;&#28856;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.00048</link><description>&lt;p&gt;
&#20351;&#29992;&#24402;&#19968;&#21270;&#27969;&#23398;&#20064;&#36793;&#32536;&#20284;&#28982;&#30340;&#35843;&#21644;&#24179;&#22343;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Learned harmonic mean estimation of the marginal likelihood with normalizing flows. (arXiv:2307.00048v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00048
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20351;&#29992;&#24402;&#19968;&#21270;&#27969;&#23398;&#20064;&#36793;&#32536;&#20284;&#28982;&#30340;&#35843;&#21644;&#24179;&#22343;&#20272;&#35745;&#65292;&#22312;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#20013;&#35299;&#20915;&#20102;&#21407;&#22987;&#26041;&#27861;&#20013;&#30340;&#26041;&#24046;&#29190;&#28856;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35745;&#31639;&#36793;&#32536;&#20284;&#28982;&#65288;&#20063;&#31216;&#20026;&#36125;&#21494;&#26031;&#27169;&#22411;&#35777;&#25454;&#65289;&#26159;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#20013;&#30340;&#19968;&#39033;&#37325;&#35201;&#20219;&#21153;&#65292;&#23427;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#21407;&#21017;&#30340;&#23450;&#37327;&#27604;&#36739;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290;&#23398;&#20064;&#30340;&#35843;&#21644;&#24179;&#22343;&#20272;&#35745;&#22120;&#35299;&#20915;&#20102;&#21407;&#22987;&#35843;&#21644;&#24179;&#22343;&#20272;&#35745;&#36793;&#32536;&#20284;&#28982;&#30340;&#26041;&#24046;&#29190;&#28856;&#38382;&#39064;&#12290;&#23398;&#20064;&#30340;&#35843;&#21644;&#24179;&#22343;&#20272;&#35745;&#22120;&#23398;&#20064;&#20102;&#19968;&#20010;&#37325;&#35201;&#24615;&#37319;&#26679;&#30446;&#26631;&#20998;&#24067;&#65292;&#35813;&#20998;&#24067;&#36817;&#20284;&#20110;&#26368;&#20248;&#20998;&#24067;&#12290;&#34429;&#28982;&#36817;&#20284;&#19981;&#24517;&#38750;&#24120;&#20934;&#30830;&#65292;&#20294;&#30830;&#20445;&#23398;&#20064;&#20998;&#24067;&#30340;&#27010;&#29575;&#36136;&#37327;&#21253;&#21547;&#22312;&#21518;&#39564;&#20998;&#24067;&#20013;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#65292;&#20197;&#36991;&#20813;&#26041;&#24046;&#29190;&#28856;&#38382;&#39064;&#12290;&#22312;&#20808;&#21069;&#30340;&#24037;&#20316;&#20013;&#65292;&#20026;&#20102;&#30830;&#20445;&#28385;&#36275;&#36825;&#20010;&#24615;&#36136;&#65292;&#22312;&#35757;&#32451;&#27169;&#22411;&#26102;&#24341;&#20837;&#20102;&#19968;&#31181;&#19987;&#38376;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20351;&#29992;&#24402;&#19968;&#21270;&#27969;&#26469;&#34920;&#31034;&#37325;&#35201;&#24615;&#37319;&#26679;&#30446;&#26631;&#20998;&#24067;&#12290;&#22522;&#20110;&#27969;&#30340;&#27169;&#22411;&#36890;&#36807;&#26368;&#22823;&#20284;&#28982;&#20174;&#21518;&#39564;&#26679;&#26412;&#20013;&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
Computing the marginal likelihood (also called the Bayesian model evidence) is an important task in Bayesian model selection, providing a principled quantitative way to compare models. The learned harmonic mean estimator solves the exploding variance problem of the original harmonic mean estimation of the marginal likelihood. The learned harmonic mean estimator learns an importance sampling target distribution that approximates the optimal distribution. While the approximation need not be highly accurate, it is critical that the probability mass of the learned distribution is contained within the posterior in order to avoid the exploding variance problem. In previous work a bespoke optimization problem is introduced when training models in order to ensure this property is satisfied. In the current article we introduce the use of normalizing flows to represent the importance sampling target distribution. A flow-based model is trained on samples from the posterior by maximum likelihood e
&lt;/p&gt;</description></item><item><title>TemperatureGAN&#26159;&#19968;&#20010;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65292;&#20351;&#29992;&#22320;&#38754;&#20197;&#19978;2m&#30340;&#22823;&#27668;&#28201;&#24230;&#25968;&#25454;&#65292;&#33021;&#22815;&#29983;&#25104;&#20855;&#26377;&#33391;&#22909;&#31354;&#38388;&#34920;&#31034;&#21644;&#19982;&#26172;&#22812;&#21608;&#26399;&#19968;&#33268;&#30340;&#26102;&#38388;&#21160;&#24577;&#30340;&#39640;&#20445;&#30495;&#26679;&#26412;&#12290;</title><link>http://arxiv.org/abs/2306.17248</link><description>&lt;p&gt;
TemperatureGAN: &#21306;&#22495;&#22823;&#27668;&#28201;&#24230;&#30340;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
TemperatureGAN: Generative Modeling of Regional Atmospheric Temperatures. (arXiv:2306.17248v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17248
&lt;/p&gt;
&lt;p&gt;
TemperatureGAN&#26159;&#19968;&#20010;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65292;&#20351;&#29992;&#22320;&#38754;&#20197;&#19978;2m&#30340;&#22823;&#27668;&#28201;&#24230;&#25968;&#25454;&#65292;&#33021;&#22815;&#29983;&#25104;&#20855;&#26377;&#33391;&#22909;&#31354;&#38388;&#34920;&#31034;&#21644;&#19982;&#26172;&#22812;&#21608;&#26399;&#19968;&#33268;&#30340;&#26102;&#38388;&#21160;&#24577;&#30340;&#39640;&#20445;&#30495;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#29983;&#25104;&#22120;&#23545;&#20110;&#20272;&#35745;&#27668;&#20505;&#23545;&#21508;&#20010;&#39046;&#22495;&#30340;&#24433;&#21709;&#38750;&#24120;&#26377;&#29992;&#12290;&#22312;&#21508;&#20010;&#39046;&#22495;&#20013;&#36827;&#34892;&#27668;&#20505;&#39118;&#38505;&#30340;&#39044;&#27979;&#65292;&#20363;&#22914;&#33021;&#28304;&#31995;&#32479;&#65292;&#38656;&#35201;&#20934;&#30830;&#65288;&#19982;&#22522;&#20934;&#30495;&#23454;&#25968;&#25454;&#26377;&#32479;&#35745;&#30456;&#20284;&#24615;&#65289;&#12289;&#21487;&#38752;&#65288;&#19981;&#20135;&#29983;&#38169;&#35823;&#26679;&#26412;&#65289;&#21644;&#39640;&#25928;&#30340;&#29983;&#25104;&#22120;&#12290;&#25105;&#20204;&#21033;&#29992;&#26469;&#33258;&#21271;&#32654;&#38470;&#22320;&#25968;&#25454;&#21516;&#21270;&#31995;&#32479;&#30340;&#25968;&#25454;&#65292;&#24341;&#20837;&#20102;TemperatureGAN&#65292;&#36825;&#26159;&#19968;&#20010;&#20197;&#26376;&#20221;&#12289;&#20301;&#32622;&#21644;&#26102;&#38388;&#27573;&#20026;&#26465;&#20214;&#30340;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65292;&#20197;&#27599;&#23567;&#26102;&#20998;&#36776;&#29575;&#29983;&#25104;&#22320;&#38754;&#20197;&#19978;2m&#30340;&#22823;&#27668;&#28201;&#24230;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#35780;&#20272;&#26041;&#27861;&#21644;&#25351;&#26631;&#26469;&#34913;&#37327;&#29983;&#25104;&#26679;&#26412;&#30340;&#36136;&#37327;&#12290;&#25105;&#20204;&#35777;&#26126;TemperatureGAN&#33021;&#22815;&#29983;&#25104;&#20855;&#26377;&#33391;&#22909;&#31354;&#38388;&#34920;&#31034;&#21644;&#19982;&#24050;&#30693;&#26172;&#22812;&#21608;&#26399;&#19968;&#33268;&#30340;&#26102;&#38388;&#21160;&#24577;&#30340;&#39640;&#20445;&#30495;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic generators are useful for estimating climate impacts on various sectors. Projecting climate risk in various sectors, e.g. energy systems, requires generators that are accurate (statistical resemblance to ground-truth), reliable (do not produce erroneous examples), and efficient. Leveraging data from the North American Land Data Assimilation System, we introduce TemperatureGAN, a Generative Adversarial Network conditioned on months, locations, and time periods, to generate 2m above ground atmospheric temperatures at an hourly resolution. We propose evaluation methods and metrics to measure the quality of generated samples. We show that TemperatureGAN produces high-fidelity examples with good spatial representation and temporal dynamics consistent with known diurnal cycles.
&lt;/p&gt;</description></item><item><title>innsight&#26159;&#19968;&#20010;&#36890;&#29992;&#30340;R&#21253;&#65292;&#33021;&#22815;&#29420;&#31435;&#20110;&#28145;&#24230;&#23398;&#20064;&#24211;&#65292;&#35299;&#37322;&#26469;&#33258;&#20219;&#20309;R&#21253;&#30340;&#27169;&#22411;&#65292;&#24182;&#25552;&#20379;&#20102;&#20016;&#23500;&#30340;&#21487;&#35270;&#21270;&#24037;&#20855;&#65292;&#20197;&#25581;&#31034;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#30340;&#21464;&#37327;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2306.10822</link><description>&lt;p&gt;
&#21033;&#29992;innsight&#21253;&#35299;&#37322;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Interpreting Deep Neural Networks with the Package innsight. (arXiv:2306.10822v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10822
&lt;/p&gt;
&lt;p&gt;
innsight&#26159;&#19968;&#20010;&#36890;&#29992;&#30340;R&#21253;&#65292;&#33021;&#22815;&#29420;&#31435;&#20110;&#28145;&#24230;&#23398;&#20064;&#24211;&#65292;&#35299;&#37322;&#26469;&#33258;&#20219;&#20309;R&#21253;&#30340;&#27169;&#22411;&#65292;&#24182;&#25552;&#20379;&#20102;&#20016;&#23500;&#30340;&#21487;&#35270;&#21270;&#24037;&#20855;&#65292;&#20197;&#25581;&#31034;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#30340;&#21464;&#37327;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
R&#21253;innsight&#25552;&#20379;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#24037;&#20855;&#31665;&#65292;&#36890;&#36807;&#25152;&#35859;&#30340;&#29305;&#24449;&#24402;&#22240;&#26041;&#27861;&#65292;&#25581;&#31034;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#30340;&#21464;&#37327;&#35299;&#37322;&#12290;&#38500;&#20102;&#32479;&#19968;&#30340;&#29992;&#25143;&#21451;&#22909;&#30340;&#26694;&#26550;&#22806;&#65292;&#35813;&#21253;&#22312;&#19977;&#20010;&#26041;&#38754;&#33073;&#39062;&#32780;&#20986;&#65306;&#39318;&#20808;&#65292;&#23427;&#36890;&#24120;&#26159;&#31532;&#19968;&#20010;&#23454;&#29616;&#31070;&#32463;&#32593;&#32476;&#29305;&#24449;&#24402;&#22240;&#26041;&#27861;&#30340;R&#21253;&#12290;&#20854;&#27425;&#65292;&#23427;&#29420;&#31435;&#20110;&#28145;&#24230;&#23398;&#20064;&#24211;&#65292;&#20801;&#35768;&#35299;&#37322;&#26469;&#33258;&#20219;&#20309;R&#21253;&#65292;&#21253;&#25324;keras&#12289;torch&#12289;neuralnet&#29978;&#33267;&#29992;&#25143;&#23450;&#20041;&#27169;&#22411;&#30340;&#27169;&#22411;&#12290;&#23613;&#31649;&#23427;&#24456;&#28789;&#27963;&#65292;&#20294;innsight&#22312;&#20869;&#37096;&#20174;torch&#21253;&#30340;&#24555;&#36895;&#21644;&#39640;&#25928;&#30340;&#25968;&#32452;&#35745;&#31639;&#20013;&#21463;&#30410;&#65292;&#36825;&#24314;&#31435;&#22312;LibTorch&#65288;PyTorch&#30340;C++&#21518;&#31471;&#65289;&#19978;&#65292;&#32780;&#19981;&#38656;&#35201;Python&#20381;&#36182;&#12290;&#26368;&#21518;&#65292;&#23427;&#25552;&#20379;&#20102;&#21508;&#31181;&#21487;&#35270;&#21270;&#24037;&#20855;&#65292;&#29992;&#20110;&#34920;&#26684;&#12289;&#20449;&#21495;&#12289;&#22270;&#20687;&#25968;&#25454;&#25110;&#36825;&#20123;&#25968;&#25454;&#30340;&#32452;&#21512;&#12290;&#27492;&#22806;&#65292;&#21487;&#20197;&#20351;&#29992;plotly&#21253;&#20197;&#20132;&#20114;&#26041;&#24335;&#21576;&#29616;&#36825;&#20123;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;
The R package innsight offers a general toolbox for revealing variable-wise interpretations of deep neural networks' predictions with so-called feature attribution methods. Aside from the unified and user-friendly framework, the package stands out in three ways: It is generally the first R package implementing feature attribution methods for neural networks. Secondly, it operates independently of the deep learning library allowing the interpretation of models from any R package, including keras, torch, neuralnet, and even custom models. Despite its flexibility, innsight benefits internally from the torch package's fast and efficient array calculations, which builds on LibTorch $-$ PyTorch's C++ backend $-$ without a Python dependency. Finally, it offers a variety of visualization tools for tabular, signal, image data or a combination of these. Additionally, the plots can be rendered interactively using the plotly package.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;$\alpha$-&#25955;&#24230;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#22312;&#20272;&#35745;&#38543;&#26426;&#29109;&#20135;&#29983;&#26102;&#34920;&#29616;&#20986;&#26356;&#21152;&#31283;&#20581;&#30340;&#24615;&#33021;&#65292;&#23588;&#20854;&#22312;&#24378;&#38750;&#24179;&#34913;&#39537;&#21160;&#25110;&#32773;&#32531;&#24930;&#21160;&#21147;&#23398;&#30340;&#24773;&#20917;&#19979;&#12290;&#36873;&#25321;$\alpha=-0.5$&#33021;&#33719;&#24471;&#26368;&#20248;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2303.02901</link><description>&lt;p&gt;
$\alpha$-&#25955;&#24230;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#25913;&#36827;&#20102;&#29109;&#20135;&#29983;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
$\alpha$-divergence Improves the Entropy Production Estimation via Machine Learning. (arXiv:2303.02901v2 [cond-mat.stat-mech] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.02901
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;$\alpha$-&#25955;&#24230;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#22312;&#20272;&#35745;&#38543;&#26426;&#29109;&#20135;&#29983;&#26102;&#34920;&#29616;&#20986;&#26356;&#21152;&#31283;&#20581;&#30340;&#24615;&#33021;&#65292;&#23588;&#20854;&#22312;&#24378;&#38750;&#24179;&#34913;&#39537;&#21160;&#25110;&#32773;&#32531;&#24930;&#21160;&#21147;&#23398;&#30340;&#24773;&#20917;&#19979;&#12290;&#36873;&#25321;$\alpha=-0.5$&#33021;&#33719;&#24471;&#26368;&#20248;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20960;&#24180;&#65292;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#20174;&#36712;&#36857;&#25968;&#25454;&#20272;&#35745;&#38543;&#26426;&#29109;&#20135;&#29983;&#65288;EP&#65289;&#30340;&#31639;&#27861;&#24341;&#36215;&#20102;&#26497;&#22823;&#20852;&#36259;&#12290;&#36825;&#31867;&#31639;&#27861;&#30340;&#20851;&#38190;&#26159;&#25214;&#21040;&#19968;&#20010;&#25439;&#22833;&#20989;&#25968;&#65292;&#20351;&#20854;&#26368;&#23567;&#21270;&#33021;&#22815;&#20445;&#35777;&#20934;&#30830;&#30340;EP&#20272;&#35745;&#12290;&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#23384;&#22312;&#19968;&#31867;&#25439;&#22833;&#20989;&#25968;&#65292;&#21363;&#37027;&#20123;&#23454;&#29616;&#20102;$\alpha$-&#25955;&#24230;&#30340;&#21464;&#20998;&#34920;&#31034;&#30340;&#20989;&#25968;&#65292;&#21487;&#20197;&#29992;&#20110;EP&#20272;&#35745;&#12290;&#36890;&#36807;&#23558;$\alpha$&#22266;&#23450;&#20026;&#22312;-1&#21040;0&#20043;&#38388;&#30340;&#20540;&#65292;$\alpha$-NEEP&#65288;Entropy Production&#30340;&#31070;&#32463;&#20272;&#35745;&#22120;&#65289;&#22312;&#24378;&#38750;&#24179;&#34913;&#39537;&#21160;&#25110;&#32773;&#32531;&#24930;&#21160;&#21147;&#23398;&#30340;&#24773;&#20917;&#19979;&#34920;&#29616;&#20986;&#26356;&#20026;&#31283;&#20581;&#30340;&#24615;&#33021;&#65292;&#32780;&#36825;&#20123;&#24773;&#20917;&#23545;&#22522;&#20110;Kullback-Leibler&#25955;&#24230;&#65288;$\alpha=0$&#65289;&#30340;&#29616;&#26377;&#26041;&#27861;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#12290;&#29305;&#21035;&#22320;&#65292;&#36873;&#25321;$\alpha=-0.5$&#24448;&#24448;&#33021;&#24471;&#21040;&#26368;&#20248;&#32467;&#26524;&#12290;&#20026;&#20102;&#35777;&#23454;&#25105;&#20204;&#30340;&#21457;&#29616;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#21487;&#31934;&#30830;&#27714;&#35299;&#30340;EP&#20272;&#35745;&#38382;&#39064;&#31616;&#21270;&#27169;&#22411;&#65292;&#20854;&#25439;&#22833;&#20989;&#25968;&#20026;land
&lt;/p&gt;
&lt;p&gt;
Recent years have seen a surge of interest in the algorithmic estimation of stochastic entropy production (EP) from trajectory data via machine learning. A crucial element of such algorithms is the identification of a loss function whose minimization guarantees the accurate EP estimation. In this study, we show that there exists a host of loss functions, namely those implementing a variational representation of the $\alpha$-divergence, which can be used for the EP estimation. By fixing $\alpha$ to a value between $-1$ and $0$, the $\alpha$-NEEP (Neural Estimator for Entropy Production) exhibits a much more robust performance against strong nonequilibrium driving or slow dynamics, which adversely affects the existing method based on the Kullback-Leibler divergence ($\alpha = 0$). In particular, the choice of $\alpha = -0.5$ tends to yield the optimal results. To corroborate our findings, we present an exactly solvable simplification of the EP estimation problem, whose loss function land
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#27979;&#35797;&#23545;&#25968;&#20284;&#28982;&#36827;&#34892;&#27604;&#36739;&#21487;&#33021;&#19982;&#20854;&#20182;&#25351;&#26631;&#30456;&#30683;&#30462;&#65292;&#24182;&#19988;&#39640;&#27979;&#35797;&#23545;&#25968;&#20284;&#28982;&#19981;&#24847;&#21619;&#30528;&#26356;&#20934;&#30830;&#30340;&#21518;&#39564;&#36817;&#20284;&#12290;</title><link>http://arxiv.org/abs/2212.00219</link><description>&lt;p&gt;
&#20320;&#26159;&#21542;&#27491;&#30830;&#20351;&#29992;&#20102;&#27979;&#35797;&#23545;&#25968;&#20284;&#28982;&#65311;
&lt;/p&gt;
&lt;p&gt;
Are you using test log-likelihood correctly?. (arXiv:2212.00219v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.00219
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#27979;&#35797;&#23545;&#25968;&#20284;&#28982;&#36827;&#34892;&#27604;&#36739;&#21487;&#33021;&#19982;&#20854;&#20182;&#25351;&#26631;&#30456;&#30683;&#30462;&#65292;&#24182;&#19988;&#39640;&#27979;&#35797;&#23545;&#25968;&#20284;&#28982;&#19981;&#24847;&#21619;&#30528;&#26356;&#20934;&#30830;&#30340;&#21518;&#39564;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27979;&#35797;&#23545;&#25968;&#20284;&#28982;&#24120;&#34987;&#29992;&#26469;&#27604;&#36739;&#19981;&#21516;&#27169;&#22411;&#30340;&#21516;&#19968;&#25968;&#25454;&#65292;&#25110;&#32773;&#27604;&#36739;&#25311;&#21512;&#21516;&#19968;&#27010;&#29575;&#27169;&#22411;&#30340;&#19981;&#21516;&#36817;&#20284;&#25512;&#26029;&#31639;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#31616;&#21333;&#30340;&#20363;&#23376;&#23637;&#31034;&#20102;&#22914;&#20309;&#22522;&#20110;&#27979;&#35797;&#23545;&#25968;&#20284;&#28982;&#30340;&#27604;&#36739;&#21487;&#33021;&#19982;&#20854;&#20182;&#30446;&#26631;&#30456;&#30683;&#30462;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#20363;&#23376;&#34920;&#26126;&#65306;&#65288;i&#65289;&#36798;&#21040;&#26356;&#39640;&#27979;&#35797;&#23545;&#25968;&#20284;&#28982;&#30340;&#36817;&#20284;&#36125;&#21494;&#26031;&#25512;&#26029;&#31639;&#27861;&#19981;&#24517;&#24847;&#21619;&#30528;&#33021;&#22815;&#20135;&#29983;&#26356;&#20934;&#30830;&#30340;&#21518;&#39564;&#36817;&#20284;&#65292;&#65288;ii&#65289;&#22522;&#20110;&#27979;&#35797;&#23545;&#25968;&#20284;&#28982;&#27604;&#36739;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#32467;&#35770;&#21487;&#33021;&#19982;&#22522;&#20110;&#22343;&#26041;&#26681;&#35823;&#24046;&#30340;&#32467;&#35770;&#19981;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
Test log-likelihood is commonly used to compare different models of the same data or different approximate inference algorithms for fitting the same probabilistic model. We present simple examples demonstrating how comparisons based on test log-likelihood can contradict comparisons according to other objectives. Specifically, our examples show that (i) approximate Bayesian inference algorithms that attain higher test log-likelihoods need not also yield more accurate posterior approximations and (ii) conclusions about forecast accuracy based on test log-likelihood comparisons may not agree with conclusions based on root mean squared error.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#28151;&#21512;&#27169;&#22411;&#65292;&#29992;&#20110;&#28151;&#21512;&#21464;&#37327;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#24182;&#19988;&#22312;&#25628;&#32034;&#21644;&#20195;&#29702;&#27169;&#22411;&#38454;&#27573;&#37117;&#20855;&#26377;&#21019;&#26032;&#20043;&#22788;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#28151;&#21512;&#27169;&#22411;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2206.01409</link><description>&lt;p&gt;
&#28151;&#21512;&#21464;&#37327;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#28151;&#21512;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Hybrid Models for Mixed Variables in Bayesian Optimization. (arXiv:2206.01409v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.01409
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#28151;&#21512;&#27169;&#22411;&#65292;&#29992;&#20110;&#28151;&#21512;&#21464;&#37327;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#24182;&#19988;&#22312;&#25628;&#32034;&#21644;&#20195;&#29702;&#27169;&#22411;&#38454;&#27573;&#37117;&#20855;&#26377;&#21019;&#26032;&#20043;&#22788;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#28151;&#21512;&#27169;&#22411;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#28151;&#21512;&#27169;&#22411;&#65292;&#29992;&#20110;&#22788;&#29702;&#28151;&#21512;&#21464;&#37327;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#23450;&#37327;&#65288;&#36830;&#32493;&#21644;&#25972;&#25968;&#65289;&#21644;&#23450;&#24615;&#65288;&#20998;&#31867;&#65289;&#31867;&#22411;&#12290;&#25105;&#20204;&#30340;&#28151;&#21512;&#27169;&#22411;&#23558;&#33945;&#29305;&#21345;&#27931;&#26641;&#25628;&#32034;&#32467;&#26500;&#65288;MCTS&#65289;&#29992;&#20110;&#20998;&#31867;&#21464;&#37327;&#65292;&#24182;&#23558;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#29992;&#20110;&#36830;&#32493;&#21464;&#37327;&#12290;&#22312;&#25628;&#32034;&#38454;&#27573;&#20013;&#65292;&#25105;&#20204;&#23558;&#39057;&#29575;&#27966;&#30340;&#19978;&#32622;&#20449;&#24230;&#26641;&#25628;&#32034;&#65288;UCTS&#65289;&#21644;&#36125;&#21494;&#26031;&#29380;&#21033;&#20811;&#38647;&#25628;&#32034;&#31574;&#30053;&#36827;&#34892;&#23545;&#27604;&#65292;&#23637;&#31034;&#20102;&#26641;&#32467;&#26500;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#34701;&#21512;&#12290;&#22312;&#20195;&#29702;&#27169;&#22411;&#38454;&#27573;&#65292;&#25105;&#20204;&#30340;&#21019;&#26032;&#20043;&#22788;&#22312;&#20110;&#38024;&#23545;&#28151;&#21512;&#21464;&#37327;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#22312;&#32447;&#26680;&#36873;&#25321;&#12290;&#25105;&#20204;&#30340;&#21019;&#26032;&#65292;&#21253;&#25324;&#21160;&#24577;&#26680;&#36873;&#25321;&#12289;&#29420;&#29305;&#30340;UCTS&#65288;hybridM&#65289;&#21644;&#36125;&#21494;&#26031;&#26356;&#26032;&#31574;&#30053;&#65288;hybridD&#65289;&#65292;&#23558;&#25105;&#20204;&#30340;&#28151;&#21512;&#27169;&#22411;&#23450;&#20301;&#20026;&#28151;&#21512;&#21464;&#37327;&#20195;&#29702;&#27169;&#22411;&#30340;&#36827;&#27493;&#12290;&#25968;&#20540;&#23454;&#39564;&#20984;&#26174;&#20102;&#28151;&#21512;&#27169;&#22411;&#30340;&#20248;&#36234;&#24615;&#65292;&#20984;&#26174;&#20102;&#23427;&#20204;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a new type of hybrid models for Bayesian optimization (BO) adept at managing mixed variables, encompassing both quantitative (continuous and integer) and qualitative (categorical) types. Our proposed new hybrid models merge Monte Carlo Tree Search structure (MCTS) for categorical variables with Gaussian Processes (GP) for continuous ones. Addressing efficiency in searching phase, we juxtapose the original (frequentist) upper confidence bound tree search (UCTS) and the Bayesian Dirichlet search strategies, showcasing the tree architecture's integration into Bayesian optimization. Central to our innovation in surrogate modeling phase is online kernel selection for mixed-variable BO. Our innovations, including dynamic kernel selection, unique UCTS (hybridM) and Bayesian update strategies (hybridD), position our hybrid models as an advancement in mixed-variable surrogate models. Numerical experiments underscore the hybrid models' superiority, highlighting their potentia
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#21160;&#24577;&#32447;&#24615;&#25237;&#24433;&#26041;&#27861;&#26469;&#20998;&#26512;&#27969;&#34892;&#30340;&#38750;&#32447;&#24615;&#27169;&#22411;&#30340;&#23616;&#37096;&#35299;&#37322;&#30340;&#26041;&#27861;&#65292;&#25506;&#32034;&#39044;&#27979;&#21464;&#37327;&#20043;&#38388;&#30340;&#20132;&#20114;&#22914;&#20309;&#24433;&#21709;&#21464;&#37327;&#37325;&#35201;&#24615;&#20272;&#35745;&#65292;&#36825;&#23545;&#20110;&#29702;&#35299;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#38750;&#24120;&#26377;&#29992;&#12290;</title><link>http://arxiv.org/abs/2205.05359</link><description>&lt;p&gt;
&#20351;&#29992;&#21160;&#24577;&#32447;&#24615;&#25237;&#24433;&#26041;&#27861;&#25506;&#32034;&#38750;&#32447;&#24615;&#27169;&#22411;&#30340;&#23616;&#37096;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Exploring Local Explanations of Nonlinear Models Using Animated Linear Projections. (arXiv:2205.05359v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.05359
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#21160;&#24577;&#32447;&#24615;&#25237;&#24433;&#26041;&#27861;&#26469;&#20998;&#26512;&#27969;&#34892;&#30340;&#38750;&#32447;&#24615;&#27169;&#22411;&#30340;&#23616;&#37096;&#35299;&#37322;&#30340;&#26041;&#27861;&#65292;&#25506;&#32034;&#39044;&#27979;&#21464;&#37327;&#20043;&#38388;&#30340;&#20132;&#20114;&#22914;&#20309;&#24433;&#21709;&#21464;&#37327;&#37325;&#35201;&#24615;&#20272;&#35745;&#65292;&#36825;&#23545;&#20110;&#29702;&#35299;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#38750;&#24120;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#33021;&#21147;&#26085;&#30410;&#22686;&#24378;&#65292;&#20294;&#19982;&#21442;&#25968;&#32479;&#35745;&#27169;&#22411;&#30456;&#27604;&#65292;&#20854;&#22797;&#26434;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#19979;&#38477;&#12290;&#36825;&#31181;&#25240;&#34935;&#23548;&#33268;&#20102;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#30340;&#20986;&#29616;&#65292;&#25552;&#20379;&#20102;&#35832;&#22914;&#23616;&#37096;&#35299;&#37322;&#65288;LE&#65289;&#21644;&#23616;&#37096;&#21464;&#37327;&#24402;&#22240;&#65288;LVA&#65289;&#20043;&#31867;&#30340;&#26041;&#27861;&#65292;&#20197;&#25581;&#31034;&#27169;&#22411;&#22914;&#20309;&#20351;&#29992;&#39044;&#27979;&#21464;&#37327;&#36827;&#34892;&#39044;&#27979;&#12290;&#28982;&#32780;&#65292;LVA&#36890;&#24120;&#19981;&#33021;&#26377;&#25928;&#22788;&#29702;&#39044;&#27979;&#21464;&#37327;&#20043;&#38388;&#30340;&#20851;&#32852;&#12290;&#20026;&#20102;&#29702;&#35299;&#39044;&#27979;&#21464;&#37327;&#20043;&#38388;&#30340;&#20132;&#20114;&#22914;&#20309;&#24433;&#21709;&#21464;&#37327;&#37325;&#35201;&#24615;&#20272;&#35745;&#65292;&#21487;&#20197;&#23558;LVA&#36716;&#25442;&#20026;&#32447;&#24615;&#25237;&#24433;&#65292;&#24182;&#20351;&#29992;&#24452;&#21521;&#28216;&#35272;&#12290;&#36825;&#23545;&#20110;&#23398;&#20064;&#27169;&#22411;&#22914;&#20309;&#29359;&#38169;&#65292;&#25110;&#24322;&#24120;&#20540;&#30340;&#24433;&#21709;&#65292;&#25110;&#35266;&#27979;&#20540;&#30340;&#32858;&#31867;&#20063;&#38750;&#24120;&#26377;&#29992;&#12290;&#26412;&#25991;&#20351;&#29992;&#21508;&#31181;&#27969;&#34892;&#30340;&#38750;&#32447;&#24615;&#27169;&#22411;&#65288;&#21253;&#25324;&#38543;&#26426;&#26862;&#26519;&#21644;&#31070;&#32463;&#32593;&#32476;&#65289;&#30340;&#31034;&#20363;&#26469;&#35828;&#26126;&#36825;&#31181;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The increased predictive power of machine learning models comes at the cost of increased complexity and loss of interpretability, particularly in comparison to parametric statistical models. This trade-off has led to the emergence of eXplainable AI (XAI) which provides methods, such as local explanations (LEs) and local variable attributions (LVAs), to shed light on how a model use predictors to arrive at a prediction. These provide a point estimate of the linear variable importance in the vicinity of a single observation. However, LVAs tend not to effectively handle association between predictors. To understand how the interaction between predictors affects the variable importance estimate, we can convert LVAs into linear projections and use the radial tour. This is also useful for learning how a model has made a mistake, or the effect of outliers, or the clustering of observations. The approach is illustrated with examples from categorical (penguin species, chocolate types) and quant
&lt;/p&gt;</description></item></channel></rss>