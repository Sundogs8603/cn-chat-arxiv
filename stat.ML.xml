<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#37096;&#20998;&#20010;&#24615;&#21270;&#32852;&#37030;&#23398;&#20064;&#27169;&#22411;&#65292;&#23558;&#21464;&#37327;&#20998;&#20026;&#20840;&#23616;&#21442;&#25968;&#21644;&#20010;&#20307;&#26412;&#22320;&#21442;&#25968;&#65292;&#35299;&#20915;&#20102;&#25968;&#25454;&#24322;&#26500;&#38382;&#39064;&#65292;&#20026;&#27599;&#20010;&#23458;&#25143;&#31471;&#25552;&#20379;&#23436;&#32654;&#25968;&#25454;&#25311;&#21512;&#30340;&#20840;&#23616;&#21442;&#25968;&#12290;&#27492;&#26041;&#27861;&#30340;&#20849;&#20139;&#30340;&#20840;&#23616;&#21442;&#25968;&#21487;&#29992;&#20110;&#23398;&#20064;&#20248;&#31168;&#30340;&#25968;&#25454;&#34920;&#31034;&#65292;&#32780;&#20010;&#24615;&#21270;&#23618;&#21017;&#21487;&#29992;&#20110;&#29305;&#23450;&#23458;&#25143;&#31471;&#30340;&#24494;&#35843;&#12290;</title><link>http://arxiv.org/abs/2305.18285</link><description>&lt;p&gt;
&#37096;&#20998;&#20010;&#24615;&#21270;&#32852;&#37030;&#23398;&#20064;&#65306;&#25171;&#30772;&#25968;&#25454;&#24322;&#26500;&#20043;&#21650;
&lt;/p&gt;
&lt;p&gt;
Partially Personalized Federated Learning: Breaking the Curse of Data Heterogeneity. (arXiv:2305.18285v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18285
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#37096;&#20998;&#20010;&#24615;&#21270;&#32852;&#37030;&#23398;&#20064;&#27169;&#22411;&#65292;&#23558;&#21464;&#37327;&#20998;&#20026;&#20840;&#23616;&#21442;&#25968;&#21644;&#20010;&#20307;&#26412;&#22320;&#21442;&#25968;&#65292;&#35299;&#20915;&#20102;&#25968;&#25454;&#24322;&#26500;&#38382;&#39064;&#65292;&#20026;&#27599;&#20010;&#23458;&#25143;&#31471;&#25552;&#20379;&#23436;&#32654;&#25968;&#25454;&#25311;&#21512;&#30340;&#20840;&#23616;&#21442;&#25968;&#12290;&#27492;&#26041;&#27861;&#30340;&#20849;&#20139;&#30340;&#20840;&#23616;&#21442;&#25968;&#21487;&#29992;&#20110;&#23398;&#20064;&#20248;&#31168;&#30340;&#25968;&#25454;&#34920;&#31034;&#65292;&#32780;&#20010;&#24615;&#21270;&#23618;&#21017;&#21487;&#29992;&#20110;&#29305;&#23450;&#23458;&#25143;&#31471;&#30340;&#24494;&#35843;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#37096;&#20998;&#20010;&#24615;&#21270;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#30340;&#27169;&#22411;&#65292;&#26088;&#22312;&#24179;&#34913;&#20010;&#24615;&#21270;&#19982;&#20840;&#23616;&#35757;&#32451;&#30340;&#21512;&#20316;&#24615;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#65292;&#25105;&#20204;&#23558;&#21464;&#37327;&#20998;&#20026;&#20840;&#23616;&#21442;&#25968;&#21644;&#20010;&#20307;&#26412;&#22320;&#21442;&#25968;&#12290;&#35777;&#26126;&#20102;&#22312;&#27491;&#30830;&#30340;&#21442;&#25968;&#25286;&#20998;&#19979;&#65292;&#21487;&#20197;&#25214;&#21040;&#20801;&#35768;&#27599;&#20010;&#23458;&#25143;&#31471;&#23436;&#32654;&#25311;&#21512;&#20854;&#25968;&#25454;&#30340;&#20840;&#23616;&#21442;&#25968;&#65292;&#24182;&#23558;&#25152;&#24471;&#21040;&#30340;&#38382;&#39064;&#31216;&#20026;&#36807;&#24230;&#20010;&#24615;&#21270;&#38382;&#39064;&#12290;&#20849;&#20139;&#30340;&#20840;&#23616;&#21442;&#25968;&#21487;&#20197;&#29992;&#20110;&#23398;&#20064;&#20248;&#31168;&#30340;&#25968;&#25454;&#34920;&#31034;&#65292;&#32780;&#20010;&#24615;&#21270;&#23618;&#21017;&#20026;&#29305;&#23450;&#23458;&#25143;&#31471;&#36827;&#34892;&#24494;&#35843;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#37096;&#20998;&#20010;&#24615;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#20026;&#25152;&#26377;&#23458;&#25143;&#31471;&#24102;&#26469;&#20102;&#26174;&#33879;&#30340;&#30410;&#22788;&#12290;&#29305;&#21035;&#22320;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#22914;&#20351;&#29992;&#26412;&#22320;&#27493;&#39588;&#65292;&#24322;&#27493;&#35757;&#32451;&#21644;&#25308;&#21344;&#24237;-&#40065;&#26834;&#35757;&#32451;&#20013;&#65292;&#36825;&#31181;&#31639;&#27861;&#25171;&#30772;&#20102;&#25968;&#25454;&#24322;&#26500;&#30340;&#21650;&#35821;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a partially personalized formulation of Federated Learning (FL) that strikes a balance between the flexibility of personalization and cooperativeness of global training. In our framework, we split the variables into global parameters, which are shared across all clients, and individual local parameters, which are kept private. We prove that under the right split of parameters, it is possible to find global parameters that allow each client to fit their data perfectly, and refer to the obtained problem as overpersonalized. For instance, the shared global parameters can be used to learn good data representations, whereas the personalized layers are fine-tuned for a specific client. Moreover, we present a simple algorithm for the partially personalized formulation that offers significant benefits to all clients. In particular, it breaks the curse of data heterogeneity in several settings, such as training with local steps, asynchronous training, and Byzantine-robust training.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#21450;&#20854;&#26465;&#20214;&#65292;&#35777;&#26126;&#20102;&#21160;&#24577;&#19979;&#26799;&#24230;&#19979;&#38477;&#21487;&#20197;&#36890;&#36807;&#26377;&#38480;&#25968;&#37327;&#30340;&#22823;&#25209;&#37327;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#26469;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#65292;&#24182;&#25214;&#21040;&#20102;&#22810;&#20010;&#21644;&#21333;&#19968;&#26041;&#21521;&#30340;&#26368;&#20339;&#25209;&#37327;&#22823;&#23567;&#65292;&#26377;&#21161;&#20110;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#21644;&#26041;&#21521;&#30340;&#19987;&#19994;&#21270;&#12290;</title><link>http://arxiv.org/abs/2305.18270</link><description>&lt;p&gt;
&#23398;&#20064;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#65306;&#19968;&#27425;(&#24040;&#22823;)&#30340;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning Two-Layer Neural Networks, One (Giant) Step at a Time. (arXiv:2305.18270v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18270
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#21450;&#20854;&#26465;&#20214;&#65292;&#35777;&#26126;&#20102;&#21160;&#24577;&#19979;&#26799;&#24230;&#19979;&#38477;&#21487;&#20197;&#36890;&#36807;&#26377;&#38480;&#25968;&#37327;&#30340;&#22823;&#25209;&#37327;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#26469;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#65292;&#24182;&#25214;&#21040;&#20102;&#22810;&#20010;&#21644;&#21333;&#19968;&#26041;&#21521;&#30340;&#26368;&#20339;&#25209;&#37327;&#22823;&#23567;&#65292;&#26377;&#21161;&#20110;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#21644;&#26041;&#21521;&#30340;&#19987;&#19994;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#30740;&#31350;&#20102;&#26377;&#38480;&#25968;&#37327;&#30340;&#22823;&#25209;&#37327;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#26377;&#21161;&#20110;&#22312;&#26680;&#24515;&#33539;&#22260;&#20043;&#22806;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#30340;&#26465;&#20214;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#25209;&#37327;&#22823;&#23567;&#21644;&#22810;&#20010;(&#20294;&#26377;&#38480;&#30340;)&#27493;&#39588;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#21333;&#27493;&#39588;&#36807;&#31243;&#65292;&#21457;&#29616;&#25209;&#37327;&#22823;&#23567;&#20026;$n=O(d)$&#21487;&#20197;&#20419;&#36827;&#29305;&#24449;&#23398;&#20064;&#65292;&#20294;&#21482;&#36866;&#21512;&#23398;&#20064;&#21333;&#19968;&#26041;&#21521;&#25110;&#21333;&#32034;&#24341;&#27169;&#22411;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;$n=O(d^2)$&#23545;&#20110;&#23398;&#20064;&#22810;&#20010;&#26041;&#21521;&#21644;&#19987;&#19994;&#21270;&#33267;&#20851;&#37325;&#35201;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#8220;&#30828;&#8221;&#26041;&#21521;&#32570;&#20047;&#21069;$\ell$&#20010;Hermite&#31995;&#25968;&#65292;&#20173;&#26410;&#34987;&#21457;&#29616;&#65292;&#24182;&#19988;&#38656;&#35201;&#25209;&#37327;&#22823;&#23567;&#20026;$n=O(d^\ell)$&#25165;&#33021;&#34987;&#26799;&#24230;&#19979;&#38477;&#25429;&#33719;&#12290;&#32463;&#36807;&#20960;&#27425;&#36845;&#20195;&#65292;&#24773;&#20917;&#21457;&#29983;&#21464;&#21270;&#65306;&#25209;&#37327;&#22823;&#23567;&#20026;$n=O(d)$&#36275;&#20197;&#23398;&#20064;&#26032;&#30340;&#30446;&#26631;&#26041;&#21521;&#65292;&#36825;&#20123;&#26041;&#21521;&#22312;Hermite&#22522;&#30784;&#19978;&#32447;&#24615;&#36830;&#25509;&#21040;&#20043;&#21069;&#23398;&#20064;&#30340;&#26041;&#21521;&#25152;&#28085;&#30422;&#30340;&#23376;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the training dynamics of shallow neural networks, investigating the conditions under which a limited number of large batch gradient descent steps can facilitate feature learning beyond the kernel regime. We compare the influence of batch size and that of multiple (but finitely many) steps. Our analysis of a single-step process reveals that while a batch size of $n = O(d)$ enables feature learning, it is only adequate for learning a single direction, or a single-index model. In contrast, $n = O(d^2)$ is essential for learning multiple directions and specialization. Moreover, we demonstrate that ``hard'' directions, which lack the first $\ell$ Hermite coefficients, remain unobserved and require a batch size of $n = O(d^\ell)$ for being captured by gradient descent. Upon iterating a few steps, the scenario changes: a batch-size of $n = O(d)$ is enough to learn new target directions spanning the subspace linearly connected in the Hermite basis to the previously learned directions,
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;Maximize to Explore (MEX)&#65292;&#21482;&#38656;&#20248;&#21270;&#19968;&#20010;&#26080;&#32422;&#26463;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#33258;&#21160;&#24179;&#34913;&#25506;&#32034;&#21644;&#21033;&#29992;&#65292;&#23454;&#29616;&#27425;&#32447;&#24615;&#36951;&#25022;&#12290;</title><link>http://arxiv.org/abs/2305.18258</link><description>&lt;p&gt;
&#19968;&#31181;&#34701;&#21512;&#20272;&#35745;&#21644;&#35268;&#21010;&#23454;&#29616;&#25506;&#32034;&#30340;&#26368;&#22823;&#21270;&#30446;&#26631;&#20989;&#25968;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
One Objective to Rule Them All: A Maximization Objective Fusing Estimation and Planning for Exploration. (arXiv:2305.18258v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18258
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;Maximize to Explore (MEX)&#65292;&#21482;&#38656;&#20248;&#21270;&#19968;&#20010;&#26080;&#32422;&#26463;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#33258;&#21160;&#24179;&#34913;&#25506;&#32034;&#21644;&#21033;&#29992;&#65292;&#23454;&#29616;&#27425;&#32447;&#24615;&#36951;&#25022;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#24179;&#34913;&#25506;&#32034;&#21644;&#21033;&#29992;&#23545;&#20110;&#20197;&#26377;&#25928;&#30340;&#26041;&#24335;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#29616;&#26377;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#36890;&#24120;&#21253;&#25324;&#19977;&#20010;&#32452;&#25104;&#37096;&#20998;&#65306;&#20272;&#35745;&#12289;&#35268;&#21010;&#21644;&#25506;&#32034;&#12290;&#28982;&#32780;&#65292;&#20026;&#20102;&#24212;&#23545;&#36890;&#29992;&#20989;&#25968;&#36924;&#36817;&#22120;&#65292;&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#37117;&#38656;&#35201;&#20351;&#29992;&#19981;&#20999;&#23454;&#38469;&#30340;&#31639;&#27861;&#32452;&#20214;&#26469;&#28608;&#21169;&#25506;&#32034;&#65292;&#20363;&#22914;&#25968;&#25454;&#30456;&#20851;&#30340;&#32423;&#21035;&#38598;&#20869;&#20248;&#21270;&#25110;&#32321;&#29712;&#30340;&#37319;&#26679;&#36807;&#31243;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26131;&#20110;&#23454;&#29616;&#30340;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#31216;&#20026;Maximize to Explore (MEX) &#65292;&#23427;&#21482;&#38656;&#35201;&#26080;&#32422;&#26463;&#22320;&#20248;&#21270;&#19968;&#20010;&#38598;&#25104;&#20102;&#20272;&#35745;&#21644;&#35268;&#21010;&#32452;&#20214;&#30340;&#21333;&#19968;&#30446;&#26631;&#20989;&#25968;&#65292;&#21516;&#26102;&#33258;&#21160;&#24179;&#34913;&#25506;&#32034;&#21644;&#21033;&#29992;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#36890;&#29992;&#20989;&#25968;&#36924;&#36817;&#65292;MEX&#23454;&#29616;&#20102;&#19968;&#20010;&#27425;&#32447;&#24615;&#30340;&#36951;&#25022;&#65292;&#36827;&#19968;&#27493;&#65306;
&lt;/p&gt;
&lt;p&gt;
In online reinforcement learning (online RL), balancing exploration and exploitation is crucial for finding an optimal policy in a sample-efficient way. To achieve this, existing sample-efficient online RL algorithms typically consist of three components: estimation, planning, and exploration. However, in order to cope with general function approximators, most of them involve impractical algorithmic components to incentivize exploration, such as optimization within data-dependent level-sets or complicated sampling procedures. To address this challenge, we propose an easy-to-implement RL framework called \textit{Maximize to Explore} (\texttt{MEX}), which only needs to optimize \emph{unconstrainedly} a single objective that integrates the estimation and planning components while balancing exploration and exploitation automatically. Theoretically, we prove that \texttt{MEX} achieves a sublinear regret with general function approximations for Markov decision processes (MDP) and is further 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#20004;&#38454;&#27573;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#22270;&#20687;&#21387;&#32553;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#34920;&#29616;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#19968;&#23450;&#27604;&#29305;&#29575;&#19979;&#33021;&#22815;&#25552;&#39640;&#22270;&#20687;&#30340;&#24863;&#30693;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2305.18231</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#39640;&#20445;&#30495;&#22270;&#20687;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
High-Fidelity Image Compression with Score-based Generative Models. (arXiv:2305.18231v1 [eess.IV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18231
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#20004;&#38454;&#27573;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#22270;&#20687;&#21387;&#32553;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#34920;&#29616;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#19968;&#23450;&#27604;&#29305;&#29575;&#19979;&#33021;&#22815;&#25552;&#39640;&#22270;&#20687;&#30340;&#24863;&#30693;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#22312;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#65292;&#20294;&#22312;&#22270;&#20687;&#21387;&#32553;&#39046;&#22495;&#22797;&#21046;&#36825;&#20010;&#25104;&#21151;&#21364;&#24456;&#22256;&#38590;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25193;&#25955;&#27169;&#22411;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22312;&#32473;&#23450;&#27604;&#29305;&#29575;&#19979;&#30340;&#24863;&#30693;&#36136;&#37327;&#65292;&#36890;&#36807; FID &#20998;&#25968;&#35780;&#20272;&#65292;&#34920;&#29616;&#36229;&#36234;&#20102; PO-ELIC &#21644; HiFiC &#30340;&#29616;&#26377;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#31616;&#21333;&#20294;&#22312;&#29702;&#35770;&#19978;&#26377;&#21160;&#26426;&#30340;&#20004;&#38454;&#27573;&#26041;&#27861;&#23454;&#29616;&#20102;&#36825;&#19968;&#28857;&#65292;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#20197; MSE &#20026;&#30446;&#26631;&#30340;&#33258;&#21160;&#32534;&#30721;&#22120;&#21644;&#19968;&#20010;&#36827;&#19968;&#27493;&#22522;&#20110;&#20998;&#25968;&#30340;&#35299;&#30721;&#22120;&#12290;&#28982;&#32780;&#65292;&#27491;&#22914;&#25105;&#20204;&#23558;&#23637;&#31034;&#30340;&#37027;&#26679;&#65292;&#23454;&#29616;&#32454;&#33410;&#24456;&#37325;&#35201;&#65292;&#26368;&#20339;&#35774;&#35745;&#20915;&#31574;&#21487;&#33021;&#19982;&#20856;&#22411;&#30340;&#25991;&#26412;&#21040;&#22270;&#20687;&#27169;&#22411;&#26377;&#24456;&#22823;&#19981;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the tremendous success of diffusion generative models in text-to-image generation, replicating this success in the domain of image compression has proven difficult. In this paper, we demonstrate that diffusion can significantly improve perceptual quality at a given bit-rate, outperforming state-of-the-art approaches PO-ELIC and HiFiC as measured by FID score. This is achieved using a simple but theoretically motivated two-stage approach combining an autoencoder targeting MSE followed by a further score-based decoder. However, as we will show, implementation details matter and the optimal design decisions can differ greatly from typical text-to-image models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37327;&#23376;&#26680;&#28151;&#21512;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#34920;&#31034;&#36830;&#32493;&#21644;&#31163;&#25955;&#38543;&#26426;&#21464;&#37327;&#30340;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#12290;&#35813;&#26694;&#26550;&#20801;&#35768;&#26500;&#24314;&#21487;&#24494;&#20998;&#30340;&#27169;&#22411;&#65292;&#36866;&#29992;&#20110;&#23494;&#24230;&#20272;&#35745;&#12289;&#25512;&#29702;&#21644;&#37319;&#26679;&#65292;&#20197;&#21450;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#21253;&#25324;&#29983;&#25104;&#24314;&#27169;&#21644;&#21028;&#21035;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2305.18204</link><description>&lt;p&gt;
&#27010;&#29575;&#28145;&#24230;&#23398;&#20064;&#30340;&#37327;&#23376;&#26680;&#28151;&#21512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Quantum Kernel Mixtures for Probabilistic Deep Learning. (arXiv:2305.18204v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18204
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37327;&#23376;&#26680;&#28151;&#21512;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#34920;&#31034;&#36830;&#32493;&#21644;&#31163;&#25955;&#38543;&#26426;&#21464;&#37327;&#30340;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#12290;&#35813;&#26694;&#26550;&#20801;&#35768;&#26500;&#24314;&#21487;&#24494;&#20998;&#30340;&#27169;&#22411;&#65292;&#36866;&#29992;&#20110;&#23494;&#24230;&#20272;&#35745;&#12289;&#25512;&#29702;&#21644;&#37319;&#26679;&#65292;&#20197;&#21450;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#21253;&#25324;&#29983;&#25104;&#24314;&#27169;&#21644;&#21028;&#21035;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#8212;&#8212;&#37327;&#23376;&#26680;&#28151;&#21512;&#65292;&#23427;&#26159;&#20174;&#37327;&#23376;&#23494;&#24230;&#30697;&#38453;&#30340;&#25968;&#23398;&#24418;&#24335;&#20013;&#25512;&#23548;&#20986;&#26469;&#30340;&#12290;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26426;&#21046;&#65292;&#29992;&#20110;&#34920;&#31034;&#36830;&#32493;&#21644;&#31163;&#25955;&#38543;&#26426;&#21464;&#37327;&#30340;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#12290;&#35813;&#26694;&#26550;&#20801;&#35768;&#26500;&#24314;&#21487;&#24494;&#20998;&#30340;&#27169;&#22411;&#65292;&#29992;&#20110;&#23494;&#24230;&#20272;&#35745;&#12289;&#25512;&#29702;&#21644;&#37319;&#26679;&#65292;&#20174;&#32780;&#33021;&#22815;&#25972;&#21512;&#21040;&#31471;&#21040;&#31471;&#30340;&#28145;&#24230;&#31070;&#32463;&#27169;&#22411;&#20013;&#12290;&#36890;&#36807;&#36825;&#26679;&#20570;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#22810;&#21151;&#33021;&#30340;&#36793;&#38469;&#21644;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#34920;&#31034;&#65292;&#21487;&#20197;&#24320;&#21457;&#19968;&#31181;&#21487;&#24494;&#20998;&#30340;&#12289;&#32452;&#21512;&#30340;&#21644;&#21487;&#36870;&#30340;&#25512;&#29702;&#36807;&#31243;&#65292;&#28085;&#30422;&#20102;&#24191;&#27867;&#30340;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#21253;&#25324;&#23494;&#24230;&#20272;&#35745;&#12289;&#21028;&#21035;&#23398;&#20064;&#21644;&#29983;&#25104;&#24314;&#27169;&#12290;&#25105;&#20204;&#36890;&#36807;&#20004;&#20010;&#31034;&#20363;&#26469;&#35828;&#26126;&#35813;&#26694;&#26550;&#30340;&#24191;&#27867;&#36866;&#29992;&#24615;&#65306;&#19968;&#20010;&#22270;&#20687;&#20998;&#31867;&#27169;&#22411;&#65292;&#23427;&#21487;&#20197;&#33258;&#28982;&#22320;&#36716;&#21270;&#20026;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#65292;&#24471;&#30410;&#20110;&#37327;&#23376;&#26680;&#28151;&#21512;&#30340;&#34920;&#31034;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a novel approach to probabilistic deep learning (PDL), quantum kernel mixtures, derived from the mathematical formalism of quantum density matrices, which provides a simpler yet effective mechanism for representing joint probability distributions of both continuous and discrete random variables. The framework allows for the construction of differentiable models for density estimation, inference, and sampling, enabling integration into end-to-end deep neural models. In doing so, we provide a versatile representation of marginal and joint probability distributions that allows us to develop a differentiable, compositional, and reversible inference procedure that covers a wide range of machine learning tasks, including density estimation, discriminative learning, and generative modeling. We illustrate the broad applicability of the framework with two examples: an image classification model, which can be naturally transformed into a conditional generative model thanks to
&lt;/p&gt;</description></item><item><title>&#21453;&#20107;&#23454;&#25968;&#25454;&#22686;&#24378;&#26159;&#19968;&#31181;&#32531;&#35299;&#25968;&#25454;&#20013;&#28151;&#28102;&#20559;&#24046;&#30340;&#26041;&#27861;&#65292;&#26412;&#25991;&#20174;&#22240;&#26524;&#30340;&#35282;&#24230;&#20998;&#26512;&#20102;&#28151;&#28102;&#20559;&#24046;&#23545;&#20998;&#31867;&#22120;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#21435;&#38500;&#28151;&#28102;&#20559;&#24046;&#30340;&#25163;&#27573;&#65292;&#26377;&#21161;&#20110;&#22312;&#35266;&#23519;&#21040;&#30340;&#25968;&#25454;&#20998;&#24067;&#20043;&#22806;&#36827;&#34892;&#27867;&#21270;&#12290;&#20316;&#32773;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#31639;&#27861;&#29992;&#20110;&#29983;&#25104;&#21453;&#20107;&#23454;&#22270;&#20687;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.18183</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#28151;&#28102;&#19979;&#30340;&#21453;&#20107;&#23454;&#25968;&#25454;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
Rethinking Counterfactual Data Augmentation Under Confounding. (arXiv:2305.18183v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18183
&lt;/p&gt;
&lt;p&gt;
&#21453;&#20107;&#23454;&#25968;&#25454;&#22686;&#24378;&#26159;&#19968;&#31181;&#32531;&#35299;&#25968;&#25454;&#20013;&#28151;&#28102;&#20559;&#24046;&#30340;&#26041;&#27861;&#65292;&#26412;&#25991;&#20174;&#22240;&#26524;&#30340;&#35282;&#24230;&#20998;&#26512;&#20102;&#28151;&#28102;&#20559;&#24046;&#23545;&#20998;&#31867;&#22120;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#21435;&#38500;&#28151;&#28102;&#20559;&#24046;&#30340;&#25163;&#27573;&#65292;&#26377;&#21161;&#20110;&#22312;&#35266;&#23519;&#21040;&#30340;&#25968;&#25454;&#20998;&#24067;&#20043;&#22806;&#36827;&#34892;&#27867;&#21270;&#12290;&#20316;&#32773;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#31639;&#27861;&#29992;&#20110;&#29983;&#25104;&#21453;&#20107;&#23454;&#22270;&#20687;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#20107;&#23454;&#25968;&#25454;&#22686;&#24378;&#26368;&#36817;&#34987;&#25552;&#20986;&#26469;&#20316;&#20026;&#32531;&#35299;&#35757;&#32451;&#25968;&#25454;&#20013;&#28151;&#28102;&#20559;&#24046;&#30340;&#19968;&#31181;&#26041;&#27861;&#12290;&#36825;&#20123;&#20559;&#24046;&#65292;&#27604;&#22914;&#34394;&#20551;&#30340;&#20851;&#32852;&#65292;&#26159;&#30001;&#20110;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#20013;&#21508;&#31181;&#35266;&#23519;&#21040;&#30340;&#21644;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#21464;&#37327;&#24341;&#36215;&#30340;&#12290;&#26412;&#25991;&#27491;&#24335;&#20998;&#26512;&#20102;&#28151;&#28102;&#20559;&#24046;&#22914;&#20309;&#24433;&#21709;&#19979;&#28216;&#20998;&#31867;&#22120;&#65292;&#24182;&#20174;&#22240;&#26524;&#30340;&#35282;&#24230;&#25506;&#35752;&#22522;&#20110;&#21453;&#20107;&#23454;&#25968;&#25454;&#22686;&#24378;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#25506;&#35752;&#22914;&#20309;&#21435;&#38500;&#28151;&#28102;&#20559;&#24046;&#20316;&#20026;&#23398;&#20064;&#19981;&#21464;&#29305;&#24449;&#30340;&#25163;&#27573;&#65292;&#26368;&#32456;&#26377;&#21161;&#20110;&#22312;&#35266;&#23519;&#21040;&#30340;&#25968;&#25454;&#20998;&#24067;&#20043;&#22806;&#36827;&#34892;&#27867;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#20294;&#24378;&#22823;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#21453;&#20107;&#23454;&#22270;&#20687;&#65292;&#26377;&#25928;&#22320;&#32531;&#35299;&#28151;&#28102;&#25928;&#24212;&#23545;&#19979;&#28216;&#20998;&#31867;&#22120;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#22312;MNIST&#21464;&#20307;&#21644;CelebA&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counterfactual data augmentation has recently emerged as a method to mitigate confounding biases in the training data for a machine learning model. These biases, such as spurious correlations, arise due to various observed and unobserved confounding variables in the data generation process. In this paper, we formally analyze how confounding biases impact downstream classifiers and present a causal viewpoint to the solutions based on counterfactual data augmentation. We explore how removing confounding biases serves as a means to learn invariant features, ultimately aiding in generalization beyond the observed data distribution. Additionally, we present a straightforward yet powerful algorithm for generating counterfactual images, which effectively mitigates the influence of confounding effects on downstream classifiers. Through experiments on MNIST variants and the CelebA datasets, we demonstrate the effectiveness and practicality of our approach.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#31163;&#25955;&#20998;&#24067;&#26679;&#26412;&#23545;&#20110;&#31867;&#21035;&#38388;&#30340;&#22343;&#21248;&#20998;&#24067;&#25311;&#21512;&#38382;&#39064;&#19979;&#30340;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;&#65292;&#22312;&#32570;&#23569;&#29699;&#24418;&#26367;&#20195;&#26041;&#26696;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20102;&#35752;&#35770;&#65292;&#36890;&#36807;&#31163;&#25955;&#30452;&#26041;&#22270;&#36827;&#34892;&#26816;&#39564;&#65292;&#33719;&#24471;&#20102;&#19968;&#31181;&#20855;&#26377;&#31934;&#30830;&#21051;&#30011;&#30340;&#26816;&#39564;&#26041;&#27861;&#65292;&#24182;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#20102;&#26174;&#33879;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.18111</link><description>&lt;p&gt;
&#22312;&#32570;&#23569;&#29699;&#24418;&#26367;&#20195;&#26041;&#26696;&#19979;&#27979;&#35797;&#31163;&#25955;&#20998;&#24067;&#30452;&#26041;&#22270;&#22343;&#21248;&#24615;&#30340;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;
The minimax risk in testing the histogram of discrete distributions for uniformity under missing ball alternatives. (arXiv:2305.18111v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18111
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#31163;&#25955;&#20998;&#24067;&#26679;&#26412;&#23545;&#20110;&#31867;&#21035;&#38388;&#30340;&#22343;&#21248;&#20998;&#24067;&#25311;&#21512;&#38382;&#39064;&#19979;&#30340;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;&#65292;&#22312;&#32570;&#23569;&#29699;&#24418;&#26367;&#20195;&#26041;&#26696;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20102;&#35752;&#35770;&#65292;&#36890;&#36807;&#31163;&#25955;&#30452;&#26041;&#22270;&#36827;&#34892;&#26816;&#39564;&#65292;&#33719;&#24471;&#20102;&#19968;&#31181;&#20855;&#26377;&#31934;&#30830;&#21051;&#30011;&#30340;&#26816;&#39564;&#26041;&#27861;&#65292;&#24182;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#20102;&#26174;&#33879;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#27979;&#35797;&#19968;&#20010;&#26469;&#33258;&#35768;&#22810;&#31867;&#21035;&#30340;&#31163;&#25955;&#26679;&#26412;&#23545;&#20110;&#31867;&#21035;&#38388;&#30340;&#22343;&#21248;&#20998;&#24067;&#25311;&#21512;&#30340;&#38382;&#39064;&#12290;&#20316;&#20026;&#21478;&#19968;&#31867;&#26367;&#20195;&#20551;&#35774;&#65292;&#25105;&#20204;&#32771;&#34385;&#21435;&#38500;&#21322;&#24452;&#20026;$\epsilon$&#30340;$\ell_p$&#29699;&#24418;&#26367;&#20195;&#26041;&#26696;&#65292;&#20854;&#20013;$p\leq 2$&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#22522;&#20110;&#30452;&#26041;&#22270;&#65288;&#32570;&#22833;&#31867;&#21035;&#12289;&#21333;&#20363;&#12289;&#30896;&#25758;&#30340;&#25968;&#37327;&#65289;&#30340;&#26816;&#39564;&#22312;&#26679;&#26412;&#25968;&#21644;&#32500;&#25968;&#36235;&#21521;&#26080;&#31351;&#22823;&#65292;$\epsilon\to0$&#26102;&#65292;&#28176;&#36827;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;&#30340;&#19968;&#20010;&#31934;&#30830;&#21051;&#30011;&#12290;&#20363;&#22914;&#65292;&#24403;$p=1$&#19988;&#26399;&#26395;&#26679;&#26412;&#25968;$n$&#19982;&#31867;&#21035;&#25968;$N$&#30340;&#27604;&#20540;&#24456;&#23567;&#65288;&#20063;&#31216;&#20026;&#8220;&#27425;&#32447;&#24615;&#8221;&#21306;&#22495;&#65289;&#26102;&#65292;&#28176;&#36827;&#26497;&#23567;&#26497;&#22823;&#39118;&#38505;$R^*_\epsilon$&#36235;&#36817;&#20110;$2\bar{\Phi}\left(n\epsilon^2/\sqrt{8N}\right)$&#65292;&#20854;&#20013;$\bar{\Phi}(x)$&#26159;&#27491;&#24577;&#27531;&#23384;&#20989;&#25968;&#12290;&#22312;&#19968;&#31995;&#21015;&#38382;&#39064;&#21442;&#25968;&#33539;&#22260;&#20869;&#30340;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;&#36825;&#20010;&#20272;&#35745;&#22312;&#26377;&#38480;&#26679;&#26412;&#20013;&#24456;&#31934;&#30830;&#65292;&#24182;&#19988;&#25105;&#20204;&#30340;&#26816;&#39564;&#26174;&#33879;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of testing the fit of a discrete sample of items from many categories to the uniform distribution over the categories. As a class of alternative hypotheses, we consider the removal of an $\ell_p$ ball of radius $\epsilon$ around the uniform rate sequence for $p \leq 2$. We deliver a sharp characterization of the asymptotic minimax risk when $\epsilon \to 0$ as the number of samples and number of dimensions go to infinity, for testing based on the occurrences' histogram (number of absent categories, singletons, collisions, ...). For example, for $p=1$ and in the limit of a small expected number of samples $n$ compared to the number of categories $N$ (aka "sub-linear" regime), the minimax risk $R^*_\epsilon$ asymptotes to $2 \bar{\Phi}\left(n \epsilon^2/\sqrt{8N}\right) $, with $\bar{\Phi}(x)$ the normal survival function. Empirical studies over a range of problem parameters show that this estimate is accurate in finite samples, and that our test is significantly 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28436;&#36827;&#21464;&#21270;&#26469;&#25913;&#21892;&#36719;&#20214;&#24320;&#21457;&#36807;&#31243;&#36136;&#37327;&#30340;&#26041;&#27861;&#65292;&#20854;&#21253;&#25324;&#20351;&#29992;&#32479;&#35745;&#36807;&#31243;&#25511;&#21046;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#26469;&#20998;&#26512;&#24212;&#29992;&#31243;&#24207;&#29983;&#21629;&#21608;&#26399;&#31649;&#29702;&#25152;&#25429;&#33719;&#30340;&#21464;&#26356;&#25968;&#25454;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#26041;&#27861;&#26159;&#26377;&#25928;&#30340;&#12290;</title><link>http://arxiv.org/abs/2305.18061</link><description>&lt;p&gt;
&#21033;&#29992;&#28436;&#36827;&#21464;&#21270;&#25552;&#39640;&#36719;&#20214;&#36807;&#31243;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Leveraging Evolutionary Changes for Software Process Quality. (arXiv:2305.18061v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18061
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28436;&#36827;&#21464;&#21270;&#26469;&#25913;&#21892;&#36719;&#20214;&#24320;&#21457;&#36807;&#31243;&#36136;&#37327;&#30340;&#26041;&#27861;&#65292;&#20854;&#21253;&#25324;&#20351;&#29992;&#32479;&#35745;&#36807;&#31243;&#25511;&#21046;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#26469;&#20998;&#26512;&#24212;&#29992;&#31243;&#24207;&#29983;&#21629;&#21608;&#26399;&#31649;&#29702;&#25152;&#25429;&#33719;&#30340;&#21464;&#26356;&#25968;&#25454;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#26041;&#27861;&#26159;&#26377;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#36719;&#20214;&#24212;&#29992;&#24517;&#39035;&#19981;&#26029;&#28436;&#36827;&#25165;&#33021;&#20445;&#25345;&#30456;&#20851;&#24615;&#12290;&#20256;&#32479;&#30340;&#36719;&#20214;&#36136;&#37327;&#25511;&#21046;&#26041;&#27861;&#28041;&#21450;&#36719;&#20214;&#36136;&#37327;&#27169;&#22411;&#21644;&#25345;&#32493;&#30340;&#20195;&#30721;&#26816;&#26597;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#36719;&#20214;&#24320;&#21457;&#36807;&#31243;&#30340;&#36136;&#37327;&#19982;&#26368;&#32456;&#36719;&#20214;&#20135;&#21697;&#30340;&#36136;&#37327;&#20043;&#38388;&#23384;&#22312;&#24378;&#20851;&#32852;&#21644;&#22240;&#26524;&#20851;&#31995;&#12290;&#22240;&#27492;&#65292;&#38388;&#25509;&#25552;&#39640;&#36719;&#20214;&#20135;&#21697;&#30340;&#36136;&#37327;&#38656;&#35201;&#25913;&#21892;&#36719;&#20214;&#24320;&#21457;&#36807;&#31243;&#30340;&#36136;&#37327;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#24320;&#21457;&#36807;&#31243;&#30340;&#28436;&#36827;&#21464;&#21270;&#26469;&#25552;&#39640;&#36719;&#20214;&#36136;&#37327;&#30340;&#26032;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21253;&#25324;&#20351;&#29992;&#32479;&#35745;&#36807;&#31243;&#25511;&#21046;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#26469;&#20998;&#26512;&#24212;&#29992;&#31243;&#24207;&#29983;&#21629;&#21608;&#26399;&#31649;&#29702;&#25152;&#25429;&#33719;&#30340;&#21464;&#26356;&#25968;&#25454;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Real-world software applications must constantly evolve to remain relevant. This evolution occurs when developing new applications or adapting existing ones to meet new requirements, make corrections, or incorporate future functionality. Traditional methods of software quality control involve software quality models and continuous code inspection tools. These measures focus on directly assessing the quality of the software. However, there is a strong correlation and causation between the quality of the development process and the resulting software product. Therefore, improving the development process indirectly improves the software product, too. To achieve this, effective learning from past processes is necessary, often embraced through post mortem organizational learning. While qualitative evaluation of large artifacts is common, smaller quantitative changes captured by application lifecycle management are often overlooked. In addition to software metrics, these smaller changes can 
&lt;/p&gt;</description></item><item><title>ITO Learning&#26159;&#19968;&#20010;&#23398;&#20064;&#20998;&#23376;&#21160;&#21147;&#23398;&#22810;&#26102;&#38388;&#20998;&#36776;&#29575;&#20195;&#29702;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#29983;&#25104;&#33258;&#27965;&#30340;&#38543;&#26426;&#21160;&#21147;&#23398;&#65292;&#33410;&#30465;&#25968;&#30334;&#20493;&#30340;&#26102;&#38388;&#12290;</title><link>http://arxiv.org/abs/2305.18046</link><description>&lt;p&gt;
&#38544;&#24335;&#36716;&#31227;&#31639;&#23376;&#23398;&#20064;&#65306;&#20998;&#23376;&#21160;&#21147;&#23398;&#22810;&#26102;&#38388;&#20998;&#36776;&#29575;&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
Implicit Transfer Operator Learning: Multiple Time-Resolution Surrogates for Molecular Dynamics. (arXiv:2305.18046v1 [physics.chem-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18046
&lt;/p&gt;
&lt;p&gt;
ITO Learning&#26159;&#19968;&#20010;&#23398;&#20064;&#20998;&#23376;&#21160;&#21147;&#23398;&#22810;&#26102;&#38388;&#20998;&#36776;&#29575;&#20195;&#29702;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#29983;&#25104;&#33258;&#27965;&#30340;&#38543;&#26426;&#21160;&#21147;&#23398;&#65292;&#33410;&#30465;&#25968;&#30334;&#20493;&#30340;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35745;&#31639;&#20998;&#23376;&#31995;&#32479;&#30340;&#24615;&#36136;&#38656;&#35201;&#20272;&#35745;&#65288;&#26410;&#24402;&#19968;&#21270;&#30340;&#65289;&#29627;&#23572;&#20857;&#26364;&#20998;&#24067;&#30340;&#26399;&#26395;&#20540;&#12290;&#20998;&#23376;&#21160;&#21147;&#23398;&#65288;MD&#65289;&#26159;&#19968;&#31181;&#24191;&#27867;&#37319;&#29992;&#30340;&#25216;&#26415;&#65292;&#29992;&#20110;&#36817;&#20284;&#36825;&#31181;&#37327;&#12290;&#28982;&#32780;&#65292;&#31283;&#23450;&#30340;&#27169;&#25311;&#38656;&#35201;&#38750;&#24120;&#23567;&#30340;&#31215;&#20998;&#26102;&#38388;&#27493;&#38271;&#65288;$10^{-15}$&#31186;&#65289;&#65292;&#32780;&#19968;&#20123;&#30697;&#30340;&#25910;&#25947;&#24615;&#65292;&#20363;&#22914;&#32467;&#21512;&#33258;&#30001;&#33021;&#25110;&#36895;&#29575;&#65292;&#21487;&#33021;&#20381;&#36182;&#20110;&#38271;&#36798;$10^{-1}$&#31186;&#30340;&#26102;&#38388;&#23610;&#24230;&#19978;&#30340;&#37319;&#26679;&#36807;&#31243;&#65292;&#24182;&#19988;&#24517;&#39035;&#23545;&#27599;&#20010;&#20998;&#23376;&#31995;&#32479;&#36827;&#34892;&#29420;&#31435;&#27169;&#25311;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#38544;&#24335;&#36716;&#31227;&#31639;&#23376;&#65288;ITO&#65289;&#23398;&#20064;&#65292;&#36825;&#26159;&#19968;&#20010;&#23398;&#20064;&#20855;&#26377;&#22810;&#20010;&#26102;&#38388;&#20998;&#36776;&#29575;&#30340;&#27169;&#25311;&#36807;&#31243;&#20195;&#29702;&#30340;&#26694;&#26550;&#12290;&#25105;&#20204;&#20351;&#29992;&#20855;&#26377;&#26032;SE&#65288;3&#65289;&#31561;&#21464;&#20307;&#31995;&#32467;&#26500;&#30340;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#23454;&#29616;ITO&#65292;&#24182;&#23637;&#31034;&#32467;&#26524;&#27169;&#22411;&#21487;&#20197;&#22312;&#22810;&#20010;&#26102;&#38388;&#23610;&#24230;&#19978;&#29983;&#25104;&#33258;&#27965;&#30340;&#38543;&#26426;&#21160;&#21147;&#23398;&#65292;&#21363;&#20351;&#21482;&#26377;&#37096;&#20998;&#35266;&#27979;&#21040;&#31995;&#32479;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31895;&#31890;&#21270;&#30340;CG-SE3-ITO&#27169;&#22411;&#65292;&#24182;&#23637;&#31034;&#23427;&#21487;&#20197;&#22312;&#27169;&#25311;&#36807;&#31243;&#20013;&#33410;&#30465;&#25968;&#30334;&#20493;&#30340;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
Computing properties of molecular systems rely on estimating expectations of the (unnormalized) Boltzmann distribution. Molecular dynamics (MD) is a broadly adopted technique to approximate such quantities. However, stable simulations rely on very small integration time-steps ($10^{-15}\,\mathrm{s}$), whereas convergence of some moments, e.g. binding free energy or rates, might rely on sampling processes on time-scales as long as $10^{-1}\, \mathrm{s}$, and these simulations must be repeated for every molecular system independently. Here, we present Implict Transfer Operator (ITO) Learning, a framework to learn surrogates of the simulation process with multiple time-resolutions. We implement ITO with denoising diffusion probabilistic models with a new SE(3) equivariant architecture and show the resulting models can generate self-consistent stochastic dynamics across multiple time-scales, even when the system is only partially observed. Finally, we present a coarse-grained CG-SE3-ITO mo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#33609;&#22270;&#25216;&#26415;&#23558;&#31890;&#23376;&#26041;&#27861;&#21644;&#24352;&#37327;&#32593;&#32476;&#26041;&#27861;&#32467;&#21512;&#30340;&#26041;&#27861;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#36825;&#31181;&#26041;&#27861;&#21253;&#25324;&#31890;&#23376;&#27169;&#25311;&#21644;&#24352;&#37327;&#32593;&#32476;&#37325;&#26032;&#20272;&#35745;&#65292;&#24182;&#21487;&#29992;&#20316;&#31890;&#23376;&#25968;&#25511;&#21046;&#30340;&#21487;&#26367;&#20195;&#26041;&#27861;&#12290;&#22312;&#27169;&#25311;Fokker-Planck&#26041;&#31243;&#21644;&#37327;&#23376;&#34394;&#26102;&#38388;&#28436;&#21270;&#26041;&#38754;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#20986;&#36890;&#29992;&#24615;&#21644;&#28789;&#27963;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.17884</link><description>&lt;p&gt;
&#36890;&#36807;&#33609;&#22270;&#25216;&#26415;&#65292;&#23558;&#31890;&#23376;&#26041;&#27861;&#21644;&#24352;&#37327;&#32593;&#32476;&#26041;&#27861;&#32467;&#21512;&#29992;&#20110;&#20559;&#24494;&#20998;&#26041;&#31243;&#27714;&#35299;
&lt;/p&gt;
&lt;p&gt;
Combining Particle and Tensor-network Methods for Partial Differential Equations via Sketching. (arXiv:2305.17884v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17884
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#33609;&#22270;&#25216;&#26415;&#23558;&#31890;&#23376;&#26041;&#27861;&#21644;&#24352;&#37327;&#32593;&#32476;&#26041;&#27861;&#32467;&#21512;&#30340;&#26041;&#27861;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#36825;&#31181;&#26041;&#27861;&#21253;&#25324;&#31890;&#23376;&#27169;&#25311;&#21644;&#24352;&#37327;&#32593;&#32476;&#37325;&#26032;&#20272;&#35745;&#65292;&#24182;&#21487;&#29992;&#20316;&#31890;&#23376;&#25968;&#25511;&#21046;&#30340;&#21487;&#26367;&#20195;&#26041;&#27861;&#12290;&#22312;&#27169;&#25311;Fokker-Planck&#26041;&#31243;&#21644;&#37327;&#23376;&#34394;&#26102;&#38388;&#28436;&#21270;&#26041;&#38754;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#20986;&#36890;&#29992;&#24615;&#21644;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#24352;&#37327;&#32593;&#32476;&#26694;&#26550;&#65292;&#20854;&#20013;&#25105;&#20204;&#37319;&#29992;&#31890;&#23376;&#27169;&#25311;&#26356;&#26032;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#20351;&#29992;&#26368;&#36817;&#25552;&#20986;&#30340;&#24352;&#37327;&#21015;&#36710;&#33609;&#22270;&#25216;&#26415;&#23558;&#26032;&#35299;&#20915;&#26041;&#26696;&#37325;&#26032;&#20272;&#35745;&#20026;&#24352;&#37327;&#32593;&#32476;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36824;&#21487;&#20197;&#34987;&#35299;&#37322;&#20026;&#36890;&#36807;&#20551;&#35774;&#31890;&#23376;&#26469;&#33258;&#24213;&#23618;&#24352;&#37327;&#32593;&#32476;&#26469;&#25191;&#34892;&#31890;&#23376;&#25968;&#25511;&#21046;&#30340;&#21487;&#26367;&#20195;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#20854;&#24212;&#29992;&#20110;&#20004;&#31181;&#29305;&#23450;&#30340;&#24773;&#26223;&#26469;&#23637;&#31034;&#25105;&#20204;&#26041;&#27861;&#30340;&#36890;&#29992;&#24615;&#21644;&#28789;&#27963;&#24615;&#65306;&#36890;&#36807;Langevin&#21160;&#21147;&#23398;&#27169;&#25311;Fokker-Planck&#26041;&#31243;&#21644;&#36890;&#36807;&#36741;&#21161;&#22330;&#37327;&#23376;&#33945;&#29305;&#21345;&#32599;&#27169;&#25311;&#37327;&#23376;&#34394;&#26102;&#38388;&#28436;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a general framework for solving high-dimensional partial differential equations with tensor networks. Our approach offers a comprehensive solution methodology, wherein we employ a combination of particle simulations to update the solution and re-estimations of the new solution as a tensor-network using a recently proposed tensor train sketching technique. Our method can also be interpreted as an alternative approach for performing particle number control by assuming the particles originate from an underlying tensor network. We demonstrate the versatility and flexibility of our approach by applying it to two specific scenarios: simulating the Fokker-Planck equation through Langevin dynamics and quantum imaginary time evolution via auxiliary-field quantum Monte Carlo.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#22810;&#39033;&#24335; logistic &#27169;&#22411;&#20013;&#38646;&#21327;&#21464;&#37327;&#19978;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#20026;&#27979;&#35797;&#32473;&#23450;&#29305;&#24449;&#26174;&#30528;&#24615;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.17825</link><description>&lt;p&gt;
&#22810;&#39033;&#24335; Logistic &#22238;&#24402;&#65306;&#39640;&#32500;&#31354;&#38388;&#20013;&#38646;&#21327;&#21464;&#37327;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Multinomial Logistic Regression: Asymptotic Normality on Null Covariates in High-Dimensions. (arXiv:2305.17825v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17825
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#22810;&#39033;&#24335; logistic &#27169;&#22411;&#20013;&#38646;&#21327;&#21464;&#37327;&#19978;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#20026;&#27979;&#35797;&#32473;&#23450;&#29305;&#24449;&#26174;&#30528;&#24615;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32500;&#25968;&#21644;&#26679;&#26412;&#37327;&#30456;&#21516;&#30340;&#39640;&#32500;&#24773;&#20917;&#19979;&#22810;&#39033;&#24335; logistic &#27169;&#22411;&#20013;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#28176;&#36817;&#20998;&#24067;&#12290;&#23613;&#31649;&#32463;&#20856;&#30340;&#22823;&#26679;&#26412;&#29702;&#35770;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#25552;&#20379;&#20102; MLE &#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#20294;&#26159;&#36825;&#20123;&#32463;&#20856;&#32467;&#26524;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#26377;&#26395;&#22833;&#36133;&#65292;&#23601;&#20687; Sur &#21644; Cand\`es [2019] &#22312;&#20108;&#20998;&#31867; logistic &#24773;&#20917;&#19979;&#30340;&#24320;&#21019;&#24615;&#24037;&#20316;&#25152;&#35760;&#24405;&#30340;&#37027;&#26679;&#12290;&#26412;&#25991;&#36890;&#36807;&#24320;&#21457;&#38646;&#21327;&#21464;&#37327;&#19978;&#30340;&#22810;&#39033;&#24335; logistic MLE (&#20063;&#31216;&#20026;&#20132;&#21449;&#29109;&#26368;&#23567;&#21270;&#22120;)&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#21644;&#28176;&#36817;&#21345;&#26041;&#32467;&#26524;&#65292;&#35299;&#20915;&#20102;&#19977;&#31867;&#21450;&#20197;&#19978;&#20998;&#31867;&#38382;&#39064;&#20013;&#30340;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20026;&#27979;&#35797;&#32473;&#23450;&#29305;&#24449;&#30340;&#26174;&#30528;&#24615;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#35770;&#12290;&#23545;&#21512;&#25104;&#25968;&#25454;&#30340;&#24191;&#27867;&#27169;&#25311;&#30740;&#31350;&#35777;&#23454;&#20102;&#36825;&#20123;&#28176;&#36817;&#32467;&#26524;&#65292;&#24182;&#30830;&#35748;&#20102;&#29992;&#20110;&#27979;&#35797;&#32473;&#23450;&#29305;&#24449;&#30340;&#25552;&#35758;&#30340; p &#20540;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates the asymptotic distribution of the maximum-likelihood estimate (MLE) in multinomial logistic models in the high-dimensional regime where dimension and sample size are of the same order. While classical large-sample theory provides asymptotic normality of the MLE under certain conditions, such classical results are expected to fail in high-dimensions as documented for the binary logistic case in the seminal work of Sur and Cand\`es [2019]. We address this issue in classification problems with 3 or more classes, by developing asymptotic normality and asymptotic chi-square results for the multinomial logistic MLE (also known as cross-entropy minimizer) on null covariates. Our theory leads to a new methodology to test the significance of a given feature. Extensive simulation studies on synthetic data corroborate these asymptotic results and confirm the validity of proposed p-values for testing the significance of a given feature.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#21160;&#37327;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGDM&#65289;&#21644;&#20854;Polyak-averaging&#29256;&#26412;&#30340;&#29305;&#24615;&#65292;&#34920;&#26126;&#22312;&#36739;&#22823;&#30340;&#25209;&#37327;&#22823;&#23567;&#19979;&#65292;&#23567;&#25209;&#37327;SGDM&#27604;&#23567;&#25209;&#37327;SGD&#26356;&#24555;&#22320;&#25910;&#25947;&#21040;&#26368;&#20248;&#20540;&#30340;&#37051;&#22495;&#12290;</title><link>http://arxiv.org/abs/2305.17665</link><description>&lt;p&gt;
&#36890;&#36807;&#24179;&#22343;&#21152;&#36895;&#21160;&#37327;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65306;&#26377;&#38480;&#26679;&#26412;&#36895;&#29575;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;
&lt;/p&gt;
&lt;p&gt;
Acceleration of stochastic gradient descent with momentum by averaging: finite-sample rates and asymptotic normality. (arXiv:2305.17665v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17665
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#21160;&#37327;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGDM&#65289;&#21644;&#20854;Polyak-averaging&#29256;&#26412;&#30340;&#29305;&#24615;&#65292;&#34920;&#26126;&#22312;&#36739;&#22823;&#30340;&#25209;&#37327;&#22823;&#23567;&#19979;&#65292;&#23567;&#25209;&#37327;SGDM&#27604;&#23567;&#25209;&#37327;SGD&#26356;&#24555;&#22320;&#25910;&#25947;&#21040;&#26368;&#20248;&#20540;&#30340;&#37051;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21160;&#37327;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGDM&#65289;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#24212;&#29992;&#20013;&#12290;&#23613;&#31649;SGDM&#30456;&#23545;&#20110;&#20256;&#32479;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20855;&#26377;&#35266;&#23519;&#21040;&#30340;&#32463;&#39564;&#20248;&#21183;&#65292;&#20294;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#21160;&#37327;&#23545;&#19981;&#21516;&#23398;&#20064;&#29575;&#30340;&#20316;&#29992;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#26159;&#24320;&#25918;&#30340;&#12290;&#25105;&#20204;&#22312;&#24378;&#20984;&#35774;&#32622;&#19979;&#20998;&#26512;&#20102;SGDM&#30340;&#26377;&#38480;&#26679;&#26412;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#34920;&#26126;&#22312;&#36739;&#22823;&#30340;&#25209;&#37327;&#22823;&#23567;&#19979;&#65292;&#23567;&#25209;&#37327;SGDM&#27604;&#23567;&#25209;&#37327;SGD&#26356;&#24555;&#22320;&#25910;&#25947;&#21040;&#26368;&#20248;&#20540;&#30340;&#37051;&#22495;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;SGDM&#20272;&#35745;&#37327;&#30340;Polyak&#24179;&#22343;&#29256;&#26412;&#65292;&#24314;&#31435;&#20102;&#23427;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#19982;&#24179;&#22343;SGD&#30340;&#28176;&#36817;&#31561;&#20215;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic gradient descent with momentum (SGDM) has been widely used in many machine learning and statistical applications. Despite the observed empirical benefits of SGDM over traditional SGD, the theoretical understanding of the role of momentum for different learning rates in the optimization process remains widely open. We analyze the finite-sample convergence rate of SGDM under the strongly convex settings and show that, with a large batch size, the mini-batch SGDM converges faster than mini-batch SGD to a neighborhood of the optimal value. Furthermore, we analyze the Polyak-averaging version of the SGDM estimator, establish its asymptotic normality, and justify its asymptotic equivalence to the averaged SGD.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35760;&#24405;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35757;&#32451;&#20013;&#30340;&#22870;&#21169;&#22604;&#38519;&#29616;&#35937;&#65292;&#23548;&#33268;&#22312;&#35757;&#32451;&#32467;&#26463;&#26102;&#65292;&#19981;&#21516;&#30340;&#25552;&#31034;&#29983;&#25104;&#30340;&#22870;&#21169;&#20998;&#24067;&#30456;&#21516;&#12290;&#36825;&#20027;&#35201;&#26159;&#22240;&#20026;&#25490;&#21517;&#30340;&#30446;&#26631;&#20989;&#25968;&#26080;&#27861;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#32771;&#34385;&#19982;&#25552;&#31034;&#30456;&#20851;&#30340;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2305.17608</link><description>&lt;p&gt;
&#23545;&#40784;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#22870;&#21169;&#22604;&#32553;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
Reward Collapse in Aligning Large Language Models. (arXiv:2305.17608v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17608
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35760;&#24405;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35757;&#32451;&#20013;&#30340;&#22870;&#21169;&#22604;&#38519;&#29616;&#35937;&#65292;&#23548;&#33268;&#22312;&#35757;&#32451;&#32467;&#26463;&#26102;&#65292;&#19981;&#21516;&#30340;&#25552;&#31034;&#29983;&#25104;&#30340;&#22870;&#21169;&#20998;&#24067;&#30456;&#21516;&#12290;&#36825;&#20027;&#35201;&#26159;&#22240;&#20026;&#25490;&#21517;&#30340;&#30446;&#26631;&#20989;&#25968;&#26080;&#27861;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#32771;&#34385;&#19982;&#25552;&#31034;&#30456;&#20851;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#22914;ChatGPT&#21644;GPT-4&#65292;&#20855;&#26377;&#38750;&#20961;&#30340;&#33021;&#21147;&#65292;&#37096;&#20998;&#21407;&#22240;&#22312;&#20110;&#23558;&#23427;&#20204;&#19982;&#35757;&#32451;&#22312;&#20154;&#31867;&#20559;&#22909;&#19978;&#30340;&#22870;&#21169;&#27169;&#22411;&#23545;&#40784;&#65292;&#36825;&#20123;&#20559;&#22909;&#36890;&#24120;&#34920;&#31034;&#20026;&#23545;&#21709;&#24212;&#25552;&#31034;&#30340;&#25490;&#21517;&#12290;&#26412;&#25991;&#35760;&#24405;&#20102;&#22870;&#21169;&#22604;&#38519;&#29616;&#35937;&#65292;&#36825;&#26159;&#19968;&#31181;&#32463;&#39564;&#35266;&#23519;&#65292;&#20854;&#20013;&#22522;&#20110;&#25490;&#21517;&#30340;&#26041;&#27861;&#23548;&#33268;&#22312;&#35757;&#32451;&#30340;&#32456;&#27490;&#38454;&#27573;&#29983;&#25104;&#30340;&#23436;&#25972;&#22870;&#21169;&#20998;&#24067;\textit{&#26080;&#35770;}\textbf{prompt&#26159;&#20160;&#20040;}&#37117;&#26159;\textit{&#30456;&#21516;&#30340;}&#12290;&#36825;&#31181;&#32467;&#26524;&#26159;&#19981;&#21487;&#21462;&#30340;&#65292;&#22240;&#20026;&#20687;&#8220;&#20889;&#19968;&#31687;&#20851;&#20110;&#20320;&#26368;&#22909;&#30340;&#26379;&#21451;&#30340;&#31616;&#30701;&#25925;&#20107;&#8221;&#36825;&#26679;&#30340;&#24320;&#25918;&#24335;&#25552;&#31034;&#24212;&#29983;&#25104;&#23436;&#25104;&#23427;&#20204;&#30340;&#36830;&#32493;&#22870;&#21169;&#33539;&#22260;&#65292;&#32780;&#20687;&#8220;&#26032;&#35199;&#20848;&#30340;&#39318;&#37117;&#26159;&#20160;&#20040;&#8221;&#36825;&#26679;&#30340;&#29305;&#23450;&#25552;&#31034;&#24212;&#29983;&#25104;&#39640;&#25110;&#20302;&#22870;&#21169;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#35843;&#26597;&#34920;&#26126;&#65292;&#22870;&#21169;&#22604;&#38519;&#20027;&#35201;&#26159;&#30001;&#20110;&#22522;&#20110;&#25490;&#21517;&#30340;&#30446;&#26631;&#20989;&#25968;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#26410;&#33021;&#32435;&#20837;&#19982;&#25552;&#31034;&#30456;&#20851;&#30340;&#20449;&#24687;&#25152;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
The extraordinary capabilities of large language models (LLMs) such as ChatGPT and GPT-4 are in part unleashed by aligning them with reward models that are trained on human preferences, which are often represented as rankings of responses to prompts. In this paper, we document the phenomenon of \textit{reward collapse}, an empirical observation where the prevailing ranking-based approach results in an \textit{identical} reward distribution \textit{regardless} of the prompts during the terminal phase of training. This outcome is undesirable as open-ended prompts like ``write a short story about your best friend'' should yield a continuous range of rewards for their completions, while specific prompts like ``what is the capital of New Zealand'' should generate either high or low rewards. Our theoretical investigation reveals that reward collapse is primarily due to the insufficiency of the ranking-based objective function to incorporate prompt-related information during optimization. Thi
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35814;&#32454;&#30740;&#31350;&#20102;&#36890;&#36807;&#23545;&#31216;&#24615;&#26126;&#30830;&#22320;&#24341;&#20837;&#20219;&#21153;&#29305;&#23450;&#30340;&#24402;&#32435;&#20559;&#24046;&#25152;&#23548;&#33268;&#30340;&#36924;&#36817;-&#27867;&#21270;&#26435;&#34913;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#36825;&#31181;&#27169;&#22411;&#22312;&#25429;&#33719;&#20219;&#21153;&#29305;&#23450;&#23545;&#31216;&#24615;&#30340;&#21516;&#26102;&#20250;&#25913;&#36827;&#27867;&#21270;&#12290;&#36825;&#19968;&#32467;&#26524;&#23545;&#20110;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30340;&#24615;&#33021;&#20855;&#26377;&#38750;&#24120;&#22823;&#30340;&#24110;&#21161;&#12290;</title><link>http://arxiv.org/abs/2305.17592</link><description>&lt;p&gt;
(&#36817;&#20284;)&#32676;&#31561;&#21464;&#24615;&#19979;&#30340;&#36924;&#36817;-&#27867;&#21270;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
Approximation-Generalization Trade-offs under (Approximate) Group Equivariance. (arXiv:2305.17592v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17592
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35814;&#32454;&#30740;&#31350;&#20102;&#36890;&#36807;&#23545;&#31216;&#24615;&#26126;&#30830;&#22320;&#24341;&#20837;&#20219;&#21153;&#29305;&#23450;&#30340;&#24402;&#32435;&#20559;&#24046;&#25152;&#23548;&#33268;&#30340;&#36924;&#36817;-&#27867;&#21270;&#26435;&#34913;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#36825;&#31181;&#27169;&#22411;&#22312;&#25429;&#33719;&#20219;&#21153;&#29305;&#23450;&#23545;&#31216;&#24615;&#30340;&#21516;&#26102;&#20250;&#25913;&#36827;&#27867;&#21270;&#12290;&#36825;&#19968;&#32467;&#26524;&#23545;&#20110;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30340;&#24615;&#33021;&#20855;&#26377;&#38750;&#24120;&#22823;&#30340;&#24110;&#21161;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#31216;&#24615;&#26126;&#30830;&#22320;&#24341;&#20837;&#20219;&#21153;&#29305;&#23450;&#30340;&#24402;&#32435;&#20559;&#24046;&#24050;&#25104;&#20026;&#39640;&#24615;&#33021;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#24320;&#21457;&#20013;&#30340;&#24120;&#35268;&#35774;&#35745;&#20934;&#21017;&#12290;&#20363;&#22914;&#65292;&#32676;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#22312;&#34507;&#30333;&#36136;&#21644;&#33647;&#29289;&#35774;&#35745;&#31561;&#21508;&#20010;&#39046;&#22495;&#21644;&#24212;&#29992;&#20013;&#23637;&#29616;&#20102;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;&#36825;&#31181;&#27169;&#22411;&#30340;&#26222;&#36941;&#24863;&#35273;&#26159;&#65292;&#23558;&#30456;&#20851;&#23545;&#31216;&#24615;&#25972;&#21512;&#21040;&#27169;&#22411;&#20013;&#20250;&#22686;&#24378;&#27867;&#21270;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#26377;&#20154;&#35748;&#20026;&#65292;&#24403;&#25968;&#25454;&#21644;/&#25110;&#27169;&#22411;&#21482;&#33021;&#34920;&#29616;&#20986;$\textit{&#36817;&#20284;}$&#25110;$\textit{&#37096;&#20998;}$&#23545;&#31216;&#24615;&#26102;&#65292;&#26368;&#20248;&#25110;&#26368;&#22909;&#24615;&#33021;&#30340;&#27169;&#22411;&#26159;&#19968;&#20010;&#27169;&#22411;&#23545;&#40784;&#20110;&#25968;&#25454;&#23545;&#31216;&#24615;&#30340;&#27169;&#22411;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23545;&#36825;&#20123;&#30452;&#35273;&#36827;&#34892;&#20102;&#27491;&#24335;&#30340;&#32479;&#19968;&#30740;&#31350;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#19968;&#33324;&#30340;&#25968;&#37327;&#30028;&#38480;&#65292;&#35777;&#26126;&#25429;&#33719;&#20219;&#21153;&#29305;&#23450;&#23545;&#31216;&#24615;&#30340;&#27169;&#22411;&#23558;&#23548;&#33268;&#25913;&#36827;&#30340;&#27867;&#21270;&#12290;&#20107;&#23454;&#19978;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#19981;&#35201;&#27714;&#21464;&#25442;&#26159;&#26377;&#38480;&#30340;&#65292;&#29978;&#33267;&#19981;&#38656;&#35201;&#24418;&#25104;&#23436;&#25972;&#30340;....
&lt;/p&gt;
&lt;p&gt;
The explicit incorporation of task-specific inductive biases through symmetry has emerged as a general design precept in the development of high-performance machine learning models. For example, group equivariant neural networks have demonstrated impressive performance across various domains and applications such as protein and drug design. A prevalent intuition about such models is that the integration of relevant symmetry results in enhanced generalization. Moreover, it is posited that when the data and/or the model may only exhibit $\textit{approximate}$ or $\textit{partial}$ symmetry, the optimal or best-performing model is one where the model symmetry aligns with the data symmetry. In this paper, we conduct a formal unified investigation of these intuitions. To begin, we present general quantitative bounds that demonstrate how models capturing task-specific symmetries lead to improved generalization. In fact, our results do not require the transformations to be finite or even form
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#19982;&#31070;&#32463;&#32593;&#32476;&#23436;&#20840;&#23545;&#24212;&#30340;&#26080;&#38480;&#26641;&#29366;PGMs&#26469;&#35299;&#20915;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#32570;&#20047;PGMs&#30340;&#31934;&#30830;&#35821;&#20041;&#21644;&#26126;&#30830;&#23450;&#20041;&#30340;&#27010;&#29575;&#35299;&#37322;&#30340;&#38382;&#39064;&#12290;&#30740;&#31350;&#21457;&#29616;DNNs&#22312;&#21069;&#21521;&#20256;&#25773;&#26102;&#30830;&#23454;&#25191;&#34892;PGM&#25512;&#26029;&#30340;&#36817;&#20284;&#65292;&#36825;&#19982;&#29616;&#26377;&#30740;&#31350;&#19981;&#21516;&#65292;&#23427;&#38416;&#26126;&#20102;DNNs&#23545;PGMs&#20013;&#30340;&#31934;&#30830;&#25512;&#29702;&#30340;&#26356;&#30452;&#25509;&#36817;&#20284;&#65292;&#28508;&#22312;&#30340;&#22909;&#22788;&#21253;&#25324;&#25913;&#36827;DNNs&#30340;&#25945;&#23398;&#21644;&#35299;&#37322;&#65292;&#20197;&#21450;&#33021;&#22815;&#21512;&#24182;PGMs&#21644;DNNs&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.17583</link><description>&lt;p&gt;
&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#26080;&#38480;&#26641;&#29366;&#27010;&#29575;&#22270;&#27169;&#22411;&#30340;&#35770;&#25991;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Neural Networks as Infinite Tree-Structured Probabilistic Graphical Models. (arXiv:2305.17583v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17583
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#19982;&#31070;&#32463;&#32593;&#32476;&#23436;&#20840;&#23545;&#24212;&#30340;&#26080;&#38480;&#26641;&#29366;PGMs&#26469;&#35299;&#20915;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#32570;&#20047;PGMs&#30340;&#31934;&#30830;&#35821;&#20041;&#21644;&#26126;&#30830;&#23450;&#20041;&#30340;&#27010;&#29575;&#35299;&#37322;&#30340;&#38382;&#39064;&#12290;&#30740;&#31350;&#21457;&#29616;DNNs&#22312;&#21069;&#21521;&#20256;&#25773;&#26102;&#30830;&#23454;&#25191;&#34892;PGM&#25512;&#26029;&#30340;&#36817;&#20284;&#65292;&#36825;&#19982;&#29616;&#26377;&#30740;&#31350;&#19981;&#21516;&#65292;&#23427;&#38416;&#26126;&#20102;DNNs&#23545;PGMs&#20013;&#30340;&#31934;&#30830;&#25512;&#29702;&#30340;&#26356;&#30452;&#25509;&#36817;&#20284;&#65292;&#28508;&#22312;&#30340;&#22909;&#22788;&#21253;&#25324;&#25913;&#36827;DNNs&#30340;&#25945;&#23398;&#21644;&#35299;&#37322;&#65292;&#20197;&#21450;&#33021;&#22815;&#21512;&#24182;PGMs&#21644;DNNs&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#32570;&#20047;&#27010;&#29575;&#22270;&#27169;&#22411;(PGMs)&#30340;&#31934;&#30830;&#35821;&#20041;&#21644;&#26126;&#30830;&#23450;&#20041;&#30340;&#27010;&#29575;&#35299;&#37322;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#19982;&#31070;&#32463;&#32593;&#32476;&#23436;&#20840;&#23545;&#24212;&#30340;&#26080;&#38480;&#26641;&#29366;PGMs&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;DNNs&#22312;&#21069;&#21521;&#20256;&#25773;&#26399;&#38388;&#30830;&#23454;&#25191;&#34892;PGM&#25512;&#26029;&#30340;&#36817;&#20284;&#65292;&#36825;&#19982;&#26366;&#32463;&#30340;&#31070;&#32463;&#32593;&#32476;&#25551;&#36848;&#20026;&#26680;&#26426;&#22120;&#25110;&#26080;&#38480;&#22823;&#23567;&#30340;&#39640;&#26031;&#36807;&#31243;&#30340;&#29616;&#26377;&#30740;&#31350;&#19981;&#21516;&#65292;&#23427;&#38416;&#26126;&#20102;DNNs&#23545;PGMs&#20013;&#30340;&#31934;&#30830;&#25512;&#29702;&#30340;&#26356;&#30452;&#25509;&#36817;&#20284;&#12290;&#28508;&#22312;&#30340;&#22909;&#22788;&#21253;&#25324;&#25913;&#36827;DNNs&#30340;&#25945;&#23398;&#21644;&#35299;&#37322;&#65292;&#20197;&#21450;&#33021;&#22815;&#21512;&#24182;PGMs&#21644;DNNs&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks (DNNs) lack the precise semantics and definitive probabilistic interpretation of probabilistic graphical models (PGMs). In this paper, we propose an innovative solution by constructing infinite tree-structured PGMs that correspond exactly to neural networks. Our research reveals that DNNs, during forward propagation, indeed perform approximations of PGM inference that are precise in this alternative PGM structure. Not only does our research complement existing studies that describe neural networks as kernel machines or infinite-sized Gaussian processes, it also elucidates a more direct approximation that DNNs make to exact inference in PGMs. Potential benefits include improved pedagogy and interpretation of DNNs, and algorithms that can merge the strengths of PGMs and DNNs.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#30142;&#30149;&#24739;&#32773;&#20010;&#20307;&#30340;&#26681;&#26412;&#21407;&#22240;&#30340;&#26032;&#20844;&#24335;&#65292;&#21487;&#20197;&#29992;&#20110;&#33258;&#21160;&#20174;&#25968;&#25454;&#20013;&#26816;&#27979;&#26681;&#26412;&#21407;&#22240;&#65292;&#24182;&#32771;&#34385;&#20102;&#22122;&#22768;&#26631;&#31614;&#21644;&#30142;&#30149;&#27969;&#34892;&#29575;&#31561;&#22240;&#32032;&#65292;&#21516;&#26102;&#20855;&#26377;&#24555;&#36895;&#35745;&#31639;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2305.17574</link><description>&lt;p&gt;
&#30142;&#30149;&#24739;&#32773;&#20010;&#20307;&#26681;&#26412;&#21407;&#22240;&#30340;&#21453;&#20107;&#23454;&#20844;&#24335;&#21270;
&lt;/p&gt;
&lt;p&gt;
Counterfactual Formulation of Patient-Specific Root Causes of Disease. (arXiv:2305.17574v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17574
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#30142;&#30149;&#24739;&#32773;&#20010;&#20307;&#30340;&#26681;&#26412;&#21407;&#22240;&#30340;&#26032;&#20844;&#24335;&#65292;&#21487;&#20197;&#29992;&#20110;&#33258;&#21160;&#20174;&#25968;&#25454;&#20013;&#26816;&#27979;&#26681;&#26412;&#21407;&#22240;&#65292;&#24182;&#32771;&#34385;&#20102;&#22122;&#22768;&#26631;&#31614;&#21644;&#30142;&#30149;&#27969;&#34892;&#29575;&#31561;&#22240;&#32032;&#65292;&#21516;&#26102;&#20855;&#26377;&#24555;&#36895;&#35745;&#31639;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30142;&#30149;&#30340;&#26681;&#26412;&#21407;&#22240;&#30452;&#35266;&#22320;&#23545;&#24212;&#20110;&#22686;&#21152;&#35786;&#26029;&#21487;&#33021;&#24615;&#30340;&#26681;&#26412;&#39030;&#28857;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26681;&#26412;&#21407;&#22240;&#30340;&#25551;&#36848;&#32570;&#20047;&#35745;&#31639;&#26426;&#31639;&#27861;&#21457;&#23637;&#25152;&#38656;&#30340;&#20005;&#26684;&#25968;&#23398;&#20844;&#24335;&#12290;&#22312;&#20197;&#21069;&#30340;&#24037;&#20316;&#20013;&#65292;&#20351;&#29992;&#24178;&#39044;&#20027;&#20041;&#32773;&#24080;&#25143;&#23450;&#20041;&#20102;&#30142;&#30149;&#30340;&#30149;&#20154;&#29305;&#23450;&#26681;&#26412;&#21407;&#22240;&#65292;&#35813;&#24080;&#25143;&#20165;&#25856;&#21319;&#21040;&#29645;&#29664;&#30340;&#22240;&#26524;Ladder&#30340;&#31532;&#20108;&#23618;&#12290;&#22312;&#36825;&#20010;&#29702;&#35770;&#24615;&#30340;&#25991;&#31456;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#21453;&#20107;&#23454;&#30340;&#23450;&#20041;&#26469;&#25856;&#21319;&#21040;&#31532;&#19977;&#23618;&#65292;&#20197;&#21305;&#37197;&#22522;&#20110;&#22266;&#23450;&#20107;&#23454;&#25968;&#25454;&#30340;&#20020;&#24202;&#30452;&#35273;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#30340;Shapley&#20540;&#20026;&#27599;&#20010;&#21464;&#37327;&#20998;&#37197;&#26681;&#22240;&#36129;&#29486;&#24471;&#20998;&#12290;&#25552;&#20986;&#30340;&#30142;&#30149;&#24739;&#32773;&#20010;&#20307;&#26681;&#26412;&#21407;&#22240;&#30340;&#21453;&#20107;&#23454;&#20844;&#24335;&#21270;&#32771;&#34385;&#20102;&#22122;&#22768;&#26631;&#31614;&#65292;&#36866;&#24212;&#20102;&#30142;&#30149;&#30340;&#27969;&#34892;&#29575;&#65292;&#24182;&#20801;&#35768;&#24555;&#36895;&#35745;&#31639;&#65292;&#26080;&#38656;&#21453;&#20107;&#23454;&#27169;&#25311;&#12290;
&lt;/p&gt;
&lt;p&gt;
Root causes of disease intuitively correspond to root vertices that increase the likelihood of a diagnosis. This description of a root cause nevertheless lacks the rigorous mathematical formulation needed for the development of computer algorithms designed to automatically detect root causes from data. Prior work defined patient-specific root causes of disease using an interventionalist account that only climbs to the second rung of Pearl's Ladder of Causation. In this theoretical piece, we climb to the third rung by proposing a counterfactual definition matching clinical intuition based on fixed factual data alone. We then show how to assign a root causal contribution score to each variable using Shapley values from explainable artificial intelligence. The proposed counterfactual formulation of patient-specific root causes of disease accounts for noisy labels, adapts to disease prevalence and admits fast computation without the need for counterfactual simulation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#36890;&#36807;&#36172;&#21338;&#30340;&#26041;&#24335;&#36827;&#34892;&#20844;&#24179;&#24615;&#23457;&#35745;&#30340;&#26041;&#27861;&#65292;&#30456;&#27604;&#20043;&#21069;&#30340;&#26041;&#27861;&#65292;&#36825;&#31181;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#23454;&#29992;&#24615;&#21644;&#25928;&#29575;&#65292;&#33021;&#22815;&#23545;&#19981;&#26029;&#20135;&#29983;&#30340;&#25968;&#25454;&#36827;&#34892;&#36830;&#32493;&#30340;&#30417;&#25511;&#65292;&#24182;&#22788;&#29702;&#22240;&#20998;&#24067;&#28418;&#31227;&#23548;&#33268;&#30340;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.17570</link><description>&lt;p&gt;
&#36890;&#36807;&#36172;&#21338;&#36827;&#34892;&#20844;&#24179;&#24615;&#23457;&#35745;
&lt;/p&gt;
&lt;p&gt;
Auditing Fairness by Betting. (arXiv:2305.17570v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17570
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#36890;&#36807;&#36172;&#21338;&#30340;&#26041;&#24335;&#36827;&#34892;&#20844;&#24179;&#24615;&#23457;&#35745;&#30340;&#26041;&#27861;&#65292;&#30456;&#27604;&#20043;&#21069;&#30340;&#26041;&#27861;&#65292;&#36825;&#31181;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#23454;&#29992;&#24615;&#21644;&#25928;&#29575;&#65292;&#33021;&#22815;&#23545;&#19981;&#26029;&#20135;&#29983;&#30340;&#25968;&#25454;&#36827;&#34892;&#36830;&#32493;&#30340;&#30417;&#25511;&#65292;&#24182;&#22788;&#29702;&#22240;&#20998;&#24067;&#28418;&#31227;&#23548;&#33268;&#30340;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#23454;&#29992;&#12289;&#39640;&#25928;&#12289;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#29992;&#20110;&#23457;&#35745;&#24050;&#37096;&#32626;&#30340;&#20998;&#31867;&#21644;&#22238;&#24402;&#27169;&#22411;&#30340;&#20844;&#24179;&#24615;&#12290;&#30456;&#27604;&#20043;&#21069;&#20381;&#36182;&#20110;&#22266;&#23450;&#26679;&#26412;&#37327;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#24207;&#36143;&#30340;&#65292;&#24182;&#20801;&#35768;&#23545;&#19981;&#26029;&#20135;&#29983;&#30340;&#25968;&#25454;&#36827;&#34892;&#36830;&#32493;&#30340;&#30417;&#25511;&#65292;&#22240;&#27492;&#38750;&#24120;&#36866;&#29992;&#20110;&#36319;&#36394;&#29616;&#23454;&#19990;&#30028;&#31995;&#32479;&#30340;&#20844;&#24179;&#24615;&#12290;&#25105;&#20204;&#20063;&#20801;&#35768;&#25968;&#25454;&#36890;&#36807;&#27010;&#29575;&#31574;&#30053;&#36827;&#34892;&#25910;&#38598;&#65292;&#32780;&#19981;&#26159;&#20174;&#20154;&#21475;&#20013;&#22343;&#21248;&#37319;&#26679;&#12290;&#36825;&#20351;&#24471;&#23457;&#35745;&#21487;&#20197;&#22312;&#20026;&#20854;&#20182;&#30446;&#30340;&#25910;&#38598;&#30340;&#25968;&#25454;&#19978;&#36827;&#34892;&#12290;&#27492;&#22806;&#65292;&#35813;&#31574;&#30053;&#21487;&#20197;&#38543;&#26102;&#38388;&#25913;&#21464;&#65292;&#24182;&#19988;&#19981;&#21516;&#30340;&#23376;&#20154;&#32676;&#21487;&#20197;&#20351;&#29992;&#19981;&#21516;&#30340;&#31574;&#30053;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#22788;&#29702;&#22240;&#27169;&#22411;&#21464;&#26356;&#25110;&#22522;&#30784;&#20154;&#32676;&#21464;&#26356;&#23548;&#33268;&#30340;&#20998;&#24067;&#28418;&#31227;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#26368;&#36817;&#20851;&#20110; anytime-valid &#25512;&#26029;&#21644;&#21338;&#24328;&#32479;&#35745;&#23398;&#30340;&#36827;&#23637;&#65292;&#23588;&#20854;&#26159;"&#36890;&#36807;&#36172;&#21338;&#36827;&#34892;&#27979;&#35797;"&#26694;&#26550;&#12290;&#36825;&#20123;&#32852;&#31995;&#30830;&#20445;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#21487;&#35299;&#37322;&#24615;&#12289;&#24555;&#36895;&#21644;&#25552;&#20379;&#32479;&#35745;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide practical, efficient, and nonparametric methods for auditing the fairness of deployed classification and regression models. Whereas previous work relies on a fixed-sample size, our methods are sequential and allow for the continuous monitoring of incoming data, making them highly amenable to tracking the fairness of real-world systems. We also allow the data to be collected by a probabilistic policy as opposed to sampled uniformly from the population. This enables auditing to be conducted on data gathered for another purpose. Moreover, this policy may change over time and different policies may be used on different subpopulations. Finally, our methods can handle distribution shift resulting from either changes to the model or changes in the underlying population. Our approach is based on recent progress in anytime-valid inference and game-theoretic statistics-the "testing by betting" framework in particular. These connections ensure that our methods are interpretable, fast, 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#34394;&#25311;&#31890;&#23376;&#38543;&#26426;&#36924;&#36817;&#30340;&#21487;&#35777;&#36895;&#38480;&#21046;&#21464;&#31181;&#30340;SVGD&#31639;&#27861;&#65292;&#20855;&#26377;&#21487;&#35777;&#36895;&#30340;&#26377;&#38480;&#31890;&#23376;&#25910;&#25947;&#29575;&#12290;</title><link>http://arxiv.org/abs/2305.17558</link><description>&lt;p&gt;
&#22522;&#20110;&#34394;&#25311;&#31890;&#23376;&#38543;&#26426;&#36924;&#36817;&#30340;&#21487;&#35777;&#36895;&#38480;&#21046;&#21464;&#31181;&#30340;SVGD&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Provably Fast Finite Particle Variants of SVGD via Virtual Particle Stochastic Approximation. (arXiv:2305.17558v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17558
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#34394;&#25311;&#31890;&#23376;&#38543;&#26426;&#36924;&#36817;&#30340;&#21487;&#35777;&#36895;&#38480;&#21046;&#21464;&#31181;&#30340;SVGD&#31639;&#27861;&#65292;&#20855;&#26377;&#21487;&#35777;&#36895;&#30340;&#26377;&#38480;&#31890;&#23376;&#25910;&#25947;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Stein&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#65288;SVGD&#65289;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#23427;&#27169;&#25311;&#30456;&#20114;&#20316;&#29992;&#30340;&#31890;&#23376;&#31995;&#32479;&#20197;&#36817;&#20284;&#20174;&#30446;&#26631;&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#20855;&#26377;&#21508;&#31181;&#39046;&#22495;&#30340;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#32463;&#39564;&#24615;&#33021;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#23427;&#30340;&#32676;&#20307;&#65288;&#21363;&#65292;&#26080;&#38480;&#31890;&#23376;&#65289;&#26497;&#38480;&#21160;&#21147;&#23398;&#24050;&#32463;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#30740;&#31350;&#65292;&#20294;&#26159;SVGD&#22312;&#26377;&#38480;&#31890;&#23376;&#20307;&#21046;&#19979;&#30340;&#34892;&#20026;&#21017;&#19981;&#22826;&#28165;&#26970;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#31181;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;SVGD&#21464;&#20307;&#65292;&#21363;VP-SVGD&#65288;&#20174;&#27010;&#24565;&#19978;&#35762;&#24456;&#20248;&#38597;&#65289;&#21644;GB-SVGD&#65288;&#20174;&#32463;&#39564;&#19978;&#30475;&#24456;&#26377;&#25928;&#65289;&#65292;&#20855;&#26377;&#21487;&#35777;&#36895;&#30340;&#26377;&#38480;&#31890;&#23376;&#25910;&#25947;&#29575;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#8220;&#34394;&#25311;&#31890;&#23376;&#8221;&#30340;&#27010;&#24565;&#65292;&#24182;&#22312;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#20013;&#24320;&#21457;&#20102;&#20154;&#21475;&#26497;&#38480;SVGD&#21160;&#21147;&#23398;&#30340;&#26032;&#22411;&#38543;&#26426;&#36924;&#36817;&#26041;&#27861;&#65292;&#23427;&#20204;&#21487;&#20197;&#20351;&#29992;&#26377;&#38480;&#25968;&#37327;&#30340;&#31890;&#23376;&#31934;&#30830;&#23454;&#29616;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#20197;&#30475;&#20316;&#26159;SVGD&#30340;&#29305;&#23450;&#38543;&#26426;&#25209;&#22788;&#29702;&#36924;&#36817;&#65292;&#27604;&#26222;&#36890;&#26041;&#27861;&#26356;&#20855;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stein Variational Gradient Descent (SVGD) is a popular variational inference algorithm which simulates an interacting particle system to approximately sample from a target distribution, with impressive empirical performance across various domains. Theoretically, its population (i.e, infinite-particle) limit dynamics is well studied but the behavior of SVGD in the finite-particle regime is much less understood. In this work, we design two computationally efficient variants of SVGD, namely VP-SVGD (which is conceptually elegant) and GB-SVGD (which is empirically effective), with provably fast finite-particle convergence rates. We introduce the notion of \emph{virtual particles} and develop novel stochastic approximations of population-limit SVGD dynamics in the space of probability measures, which are exactly implementable using a finite number of particles. Our algorithms can be viewed as specific random-batch approximations of SVGD, which are computationally more efficient than ordinar
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#20844;&#24179;&#32858;&#31867;&#20844;&#24335;&#65292;&#35813;&#20844;&#24335;&#36890;&#36807;&#23618;&#27425;&#20844;&#24179;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#23454;&#29616;&#20844;&#24179;&#32858;&#31867;&#30340;&#30446;&#26631;&#12290;</title><link>http://arxiv.org/abs/2305.17557</link><description>&lt;p&gt;
&#36890;&#36807;&#23618;&#27425;&#20844;&#24179;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#23454;&#29616;&#20844;&#24179;&#32858;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fair Clustering via Hierarchical Fair-Dirichlet Process. (arXiv:2305.17557v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17557
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#20844;&#24179;&#32858;&#31867;&#20844;&#24335;&#65292;&#35813;&#20844;&#24335;&#36890;&#36807;&#23618;&#27425;&#20844;&#24179;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#23454;&#29616;&#20844;&#24179;&#32858;&#31867;&#30340;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#39537;&#21160;&#30340;&#20915;&#31574;&#21046;&#23450;&#21644;&#25919;&#31574;&#21046;&#23450;&#30340;&#20986;&#29616;&#65292;&#23548;&#33268;&#36234;&#26469;&#36234;&#22810;&#22320;&#20851;&#27880;&#31639;&#27861;&#30340;&#20844;&#24179;&#24615;&#12290;&#30001;&#20110;&#32858;&#31867;&#26159;&#26368;&#24120;&#29992;&#30340;&#26080;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#20043;&#19968;&#65292;&#22240;&#27492;&#33258;&#28982;&#32780;&#28982;&#22320;&#20986;&#29616;&#20102;&#22823;&#37327;&#26377;&#20851;&#8220;&#20844;&#24179;&#32858;&#31867;&#8221;&#30340;&#25991;&#29486;&#12290;&#32858;&#31867;&#20013;&#20844;&#24179;&#30340;&#19968;&#31181;&#26222;&#36941;&#27010;&#24565;&#35201;&#27714;&#32676;&#38598;&#26159;&#8220;&#24179;&#34913;&#30340;&#8221;&#65292;&#21363;&#21463;&#20445;&#25252;&#23646;&#24615;&#30340;&#27599;&#20010;&#32423;&#21035;&#22312;&#27599;&#20010;&#32676;&#38598;&#20013;&#37117;&#35201;&#22823;&#32422;&#30456;&#31561;&#22320;&#20195;&#34920;&#12290;&#22312;&#20445;&#25345;&#21407;&#22987;&#26694;&#26550;&#30340;&#22522;&#30784;&#19978;&#65292;&#36825;&#26041;&#38754;&#30340;&#25991;&#29486;&#22312;&#21508;&#20010;&#26041;&#38754;&#36805;&#36895;&#25193;&#23637;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#20844;&#24179;&#32858;&#31867;&#20844;&#24335;&#65292;&#34917;&#20805;&#20102;&#29616;&#26377;&#25991;&#29486;&#20960;&#20046;&#23436;&#20840;&#22522;&#20110;&#20248;&#21270;&#36866;&#24403;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;&#19981;&#36275;&#20043;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
The advent of ML-driven decision-making and policy formation has led to an increasing focus on algorithmic fairness. As clustering is one of the most commonly used unsupervised machine learning approaches, there has naturally been a proliferation of literature on {\em fair clustering}. A popular notion of fairness in clustering mandates the clusters to be {\em balanced}, i.e., each level of a protected attribute must be approximately equally represented in each cluster. Building upon the original framework, this literature has rapidly expanded in various aspects. In this article, we offer a novel model-based formulation of fair clustering, complementing the existing literature which is almost exclusively based on optimizing appropriate objective functions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#28789;&#27963;&#30340;PFN&#20316;&#20026;BO&#20195;&#29702;&#24314;&#27169;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#20801;&#35768;&#36827;&#19968;&#27493;&#20449;&#24687;&#32435;&#20837;&#20197;&#36827;&#34892;&#38750;&#36828;&#35270;BO&#12290;&#22312;&#19977;&#31181;&#19981;&#21516;&#30340;&#38382;&#39064;&#19978;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.17535</link><description>&lt;p&gt;
PFN&#26159;&#36866;&#29992;&#20110;&#23454;&#38469;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#28789;&#27963;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
PFNs Are Flexible Models for Real-World Bayesian Optimization. (arXiv:2305.17535v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17535
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#28789;&#27963;&#30340;PFN&#20316;&#20026;BO&#20195;&#29702;&#24314;&#27169;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#20801;&#35768;&#36827;&#19968;&#27493;&#20449;&#24687;&#32435;&#20837;&#20197;&#36827;&#34892;&#38750;&#36828;&#35270;BO&#12290;&#22312;&#19977;&#31181;&#19981;&#21516;&#30340;&#38382;&#39064;&#19978;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#20808;&#39564;&#25968;&#25454;&#25311;&#21512;&#32593;&#32476;(PFNs)&#20316;&#20026;&#36125;&#21494;&#26031;&#20248;&#21270;(BO)&#30340;&#28789;&#27963;&#20195;&#29702;&#12290;PFN&#26159;&#19968;&#31181;&#31070;&#32463;&#36807;&#31243;&#65292;&#34987;&#35757;&#32451;&#29992;&#20110;&#36817;&#20284;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;(PPD)&#65292;&#36866;&#29992;&#20110;&#20219;&#20309;&#21487;&#26377;&#25928;&#37319;&#26679;&#30340;&#20808;&#39564;&#20998;&#24067;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#22914;&#20309;&#21033;&#29992;&#36825;&#31181;&#28789;&#27963;&#24615;&#26469;&#36827;&#34892;BO&#30340;&#20195;&#29702;&#24314;&#27169;&#12290;&#25105;&#20204;&#20351;&#29992;PFN&#26469;&#27169;&#25311;&#19968;&#20010;&#26420;&#32032;&#39640;&#26031;&#36807;&#31243;(GP)&#65292;&#19968;&#20010;&#20808;&#36827;&#30340;GP&#21644;&#19968;&#20010;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;(BNN)&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#36827;&#19968;&#27493;&#30340;&#20449;&#24687;&#32435;&#20837;&#20808;&#39564;&#65292;&#20363;&#22914;&#20801;&#35768;&#26377;&#20851;&#26368;&#20248;&#20301;&#32622;&#30340;&#25552;&#31034;(&#29992;&#25143;&#20808;&#39564;)&#65292;&#24573;&#30053;&#19981;&#30456;&#20851;&#30340;&#32500;&#24230;&#65292;&#24182;&#36890;&#36807;&#23398;&#20064;&#33719;&#21462;&#20989;&#25968;&#26469;&#25191;&#34892;&#38750;&#36828;&#35270;BO&#12290;&#36825;&#20123;&#25193;&#23637;&#30340;&#28789;&#27963;&#24615;&#20026;&#20351;&#29992;PFN&#36827;&#34892;BO&#24320;&#36767;&#20102;&#24191;&#38420;&#30340;&#21487;&#33021;&#24615;&#12290;&#25105;&#20204;&#22312;&#20154;&#24037;&#39640;&#26031;&#36807;&#31243;&#26679;&#26412;&#21644;&#19977;&#20010;&#19981;&#21516;&#30340;&#36229;&#21442;&#25968;&#20248;&#21270;&#27979;&#35797;&#24179;&#21488;&#19978;&#23637;&#31034;&#20102;PFN&#23545;BO&#30340;&#26377;&#29992;&#24615;&#65306;HPO-B&#12289;Bayesmark&#21644;PD1&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we use Prior-data Fitted Networks (PFNs) as a flexible surrogate for Bayesian Optimization (BO). PFNs are neural processes that are trained to approximate the posterior predictive distribution (PPD) for any prior distribution that can be efficiently sampled from. We describe how this flexibility can be exploited for surrogate modeling in BO. We use PFNs to mimic a naive Gaussian process (GP), an advanced GP, and a Bayesian Neural Network (BNN). In addition, we show how to incorporate further information into the prior, such as allowing hints about the position of optima (user priors), ignoring irrelevant dimensions, and performing non-myopic BO by learning the acquisition function. The flexibility underlying these extensions opens up vast possibilities for using PFNs for BO. We demonstrate the usefulness of PFNs for BO in a large-scale evaluation on artificial GP samples and three different hyperparameter optimization testbeds: HPO-B, Bayesmark, and PD1. We publish code 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#21160;&#24577;&#31283;&#23450;&#24615;&#38544;&#24335;&#27491;&#21017;&#21270;&#65292;&#35777;&#26126;&#20102;&#20854;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.17490</link><description>&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20013;&#21160;&#24577;&#31283;&#23450;&#24615;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
The Implicit Regularization of Dynamical Stability in Stochastic Gradient Descent. (arXiv:2305.17490v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17490
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#21160;&#24577;&#31283;&#23450;&#24615;&#38544;&#24335;&#27491;&#21017;&#21270;&#65292;&#35777;&#26126;&#20102;&#20854;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#8220;&#21160;&#24577;&#31283;&#23450;&#24615;&#8221;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#12290;&#25105;&#20204;&#39318;&#20808;&#20462;&#27491;&#20102;&#29616;&#26377;SGD&#31283;&#23450;&#24615;&#20998;&#26512;&#30340;&#38382;&#39064;&#65292;&#23637;&#31034;&#20102;Hessian&#30697;&#38453;&#30340;Frobenius&#33539;&#25968;&#21644;&#36857;&#19982;&#19981;&#21516;&#31283;&#23450;&#24615;&#27010;&#24565;&#30340;&#20851;&#31995;&#12290;&#29305;&#21035;&#22320;&#65292;&#22914;&#26524;&#20840;&#23616;&#26368;&#23567;&#20540;&#22312;SGD&#20013;&#26159;&#32447;&#24615;&#31283;&#23450;&#30340;&#65292;&#21017;Hessian&#30697;&#38453;&#30340;&#36857;&#24517;&#39035;&#23567;&#20110;&#25110;&#31561;&#20110;$2/\eta$&#65292;&#20854;&#20013;$\eta$&#34920;&#31034;&#23398;&#20064;&#29575;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#65292;&#31283;&#23450;&#24615;&#21482;&#23545;Hessian&#30697;&#38453;&#30340;&#26368;&#22823;&#29305;&#24449;&#20540;&#26045;&#21152;&#31867;&#20284;&#30340;&#32422;&#26463;&#12290;&#25105;&#20204;&#25509;&#30528;&#20998;&#26512;&#20102;&#36825;&#20123;&#31283;&#23450;&#26497;&#20540;&#30340;&#27867;&#21270;&#24615;&#36136;&#65292;&#30528;&#37325;&#20851;&#27880;&#20102;&#20004;&#23618;ReLU&#32593;&#32476;&#21644;&#23545;&#35282;&#32447;&#24615;&#32593;&#32476;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#36825;&#20004;&#20010;&#27169;&#22411;&#30340;&#23574;&#38160;&#24230;&#24230;&#37327;&#21644;&#26576;&#20123;&#21442;&#25968;&#35268;&#33539;&#20043;&#38388;&#30340;&#8220;&#31561;&#20215;&#24615;&#8221;&#65292;&#20174;&#32780;&#35777;&#26126;&#20102;SGD&#30340;&#31283;&#23450;&#26497;&#20540;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#24615;&#12290;&#28982;&#32780;&#65292;GD&#30340;&#31283;&#23450;&#24615;&#27491;&#21017;&#21270;&#21482;&#22312;&#29305;&#23450;&#24773;&#20917;&#19979;&#20135;&#29983;&#27867;&#21270;&#25928;&#30410;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#29702;&#35770;&#24212;&#29992;&#20110;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#38382;&#39064;&#65292;&#32467;&#26524;&#34920;&#26126;&#23427;&#23545;&#26576;&#20123;&#27169;&#22411;&#30340;&#34920;&#29616;&#20248;&#20110;Lasso&#25110;&#23725;&#27491;&#21017;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the implicit regularization of stochastic gradient descent (SGD) through the lens of {\em dynamical stability} (Wu et al., 2018). We start by revising existing stability analyses of SGD, showing how the Frobenius norm and trace of Hessian relate to different notions of stability. Notably, if a global minimum is linearly stable for SGD, then the trace of Hessian must be less than or equal to $2/\eta$, where $\eta$ denotes the learning rate. By contrast, for gradient descent (GD), the stability imposes a similar constraint but only on the largest eigenvalue of Hessian. We then turn to analyze the generalization properties of these stable minima, focusing specifically on two-layer ReLU networks and diagonal linear networks. Notably, we establish the {\em equivalence} between these metrics of sharpness and certain parameter norms for the two models, which allows us to show that the stable minima of SGD provably generalize well. By contrast, the stability-induced reg
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20351;&#29992;&#28145;&#24230;&#21464;&#20998;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#23454;&#29616;&#30149;&#21464;-&#32570;&#38519;&#25512;&#26029;&#20219;&#21153;&#65292;&#24314;&#31435;&#34920;&#36798;&#24615;&#23618;&#27425;&#27169;&#22411;&#65292;&#21487;&#20272;&#35745;&#32852;&#21512;&#25439;&#20260;&#21644;&#32570;&#38519;&#20998;&#24067;&#65292;&#26465;&#20214;&#20026;&#28508;&#22312;&#31070;&#32463;&#24213;&#29289;&#12290;</title><link>http://arxiv.org/abs/2305.17478</link><description>&lt;p&gt;
&#28145;&#24230;&#21464;&#20998;&#30149;&#21464;-&#32570;&#38519;&#26144;&#23556;
&lt;/p&gt;
&lt;p&gt;
Deep Variational Lesion-Deficit Mapping. (arXiv:2305.17478v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17478
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20351;&#29992;&#28145;&#24230;&#21464;&#20998;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#23454;&#29616;&#30149;&#21464;-&#32570;&#38519;&#25512;&#26029;&#20219;&#21153;&#65292;&#24314;&#31435;&#34920;&#36798;&#24615;&#23618;&#27425;&#27169;&#22411;&#65292;&#21487;&#20272;&#35745;&#32852;&#21512;&#25439;&#20260;&#21644;&#32570;&#38519;&#20998;&#24067;&#65292;&#26465;&#20214;&#20026;&#28508;&#22312;&#31070;&#32463;&#24213;&#29289;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#33041;&#30340;&#21151;&#33021;&#32452;&#32455;&#30340;&#22240;&#26524;&#26144;&#23556;&#38656;&#35201;&#33258;&#28982;&#36215;&#28304;&#30149;&#29702;&#25439;&#20260;&#30340;&#24517;&#35201;&#24615;&#35777;&#25454;&#65292;&#20854;&#35268;&#27169;&#20165;&#22312;&#36275;&#22815;&#28789;&#27963;&#30340;&#25512;&#26029;&#27169;&#22411;&#20013;&#20855;&#22791;&#12290;&#36825;&#38656;&#35201;&#20855;&#26377;&#36275;&#22815;&#28789;&#27963;&#24615;&#30340;&#25512;&#26029;&#27169;&#22411;&#65292;&#26082;&#21487;&#25429;&#33719;&#30149;&#29702;&#25439;&#20260;&#30340;&#21487;&#35266;&#27979;&#20998;&#24067;&#65292;&#20063;&#21487;&#25429;&#33719;&#31070;&#32463;&#24213;&#29289;&#30340;&#26410;&#35266;&#27979;&#20998;&#24067;&#12290;&#30446;&#21069;&#30340;&#27169;&#22411;&#26694;&#26550; - &#26080;&#35770;&#26159;&#22823;&#22810;&#25968;&#21333;&#21464;&#37327;&#30340;&#36824;&#26159;&#22810;&#21464;&#37327;&#30340; - &#35201;&#20040;&#24573;&#30053;&#20102;&#20998;&#24067;&#24335;&#30340;&#25439;&#20260;&#32570;&#38519;&#20851;&#31995;&#65292;&#35201;&#20040;&#27809;&#26377;&#26126;&#30830;&#22320;&#23545;&#23427;&#20204;&#24314;&#27169;&#65292;&#32780;&#26159;&#20381;&#38752;&#19982;&#39044;&#27979;&#20219;&#21153;&#26080;&#20851;&#30340;&#29305;&#24449;&#21270;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#24320;&#22987;&#23558;&#28145;&#24230;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#24212;&#29992;&#20110;&#25439;&#20260;-&#32570;&#38519;&#25512;&#26029;&#20219;&#21153;&#65292;&#23558;&#20854;&#23450;&#20041;&#20026;&#22522;&#20110;&#28508;&#22312;&#31070;&#32463;&#24213;&#29289;&#30340;&#32852;&#21512;&#25439;&#20260;&#21644;&#32570;&#38519;&#20998;&#24067;&#30340;&#34920;&#36798;&#24615;&#23618;&#27425;&#27169;&#22411;&#30340;&#20272;&#35745;&#12290;&#25105;&#20204;&#20351;&#29992;&#21464;&#20998;&#21367;&#31215;&#20307;&#31215;&#33258;&#32534;&#30721;&#22120;&#23454;&#29616;&#20102;&#36825;&#26679;&#30340;&#28145;&#24230;&#25439;&#20260;&#32570;&#38519;&#25512;&#26029;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Causal mapping of the functional organisation of the human brain requires evidence of \textit{necessity} available at adequate scale only from pathological lesions of natural origin. This demands inferential models with sufficient flexibility to capture both the observable distribution of pathological damage and the unobserved distribution of the neural substrate. Current model frameworks -- both mass-univariate and multivariate -- either ignore distributed lesion-deficit relations or do not model them explicitly, relying on featurization incidental to a predictive task. Here we initiate the application of deep generative neural network architectures to the task of lesion-deficit inference, formulating it as the estimation of an expressive hierarchical model of the joint lesion and deficit distributions conditioned on a latent neural substrate. We implement such deep lesion deficit inference with variational convolutional volumetric auto-encoders. We introduce a comprehensive framework
&lt;/p&gt;</description></item><item><title>&#29983;&#25104;&#24335;&#25968;&#25454;&#22686;&#24191;&#36890;&#36807;&#20174;&#35757;&#32451;&#30340;&#29983;&#25104;&#27169;&#22411;&#20013;&#33719;&#24471;&#34394;&#20551;&#30340;&#26631;&#35760;&#31034;&#20363;&#65292;&#25552;&#39640;&#20998;&#31867;&#24615;&#33021;&#65307;&#26412;&#25991;&#24314;&#31435;&#20102;&#19968;&#20010;&#26222;&#36941;&#30340;&#31283;&#23450;&#24615;&#30028;&#38480;&#65292;&#24182;&#21457;&#29616;&#20854;&#25928;&#26524;&#19982;&#29983;&#25104;&#27169;&#22411;&#30340;&#36873;&#25321;&#21644;&#35757;&#32451;&#38598;&#22823;&#23567;&#23494;&#20999;&#30456;&#20851;&#12290;</title><link>http://arxiv.org/abs/2305.17476</link><description>&lt;p&gt;
&#25506;&#31350;&#29983;&#25104;&#24335;&#25968;&#25454;&#22686;&#24191;&#30340;&#24847;&#20041;
&lt;/p&gt;
&lt;p&gt;
Toward Understanding Generative Data Augmentation. (arXiv:2305.17476v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17476
&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#25968;&#25454;&#22686;&#24191;&#36890;&#36807;&#20174;&#35757;&#32451;&#30340;&#29983;&#25104;&#27169;&#22411;&#20013;&#33719;&#24471;&#34394;&#20551;&#30340;&#26631;&#35760;&#31034;&#20363;&#65292;&#25552;&#39640;&#20998;&#31867;&#24615;&#33021;&#65307;&#26412;&#25991;&#24314;&#31435;&#20102;&#19968;&#20010;&#26222;&#36941;&#30340;&#31283;&#23450;&#24615;&#30028;&#38480;&#65292;&#24182;&#21457;&#29616;&#20854;&#25928;&#26524;&#19982;&#29983;&#25104;&#27169;&#22411;&#30340;&#36873;&#25321;&#21644;&#35757;&#32451;&#38598;&#22823;&#23567;&#23494;&#20999;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20174;&#35757;&#32451;&#30340;&#26377;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#20013;&#33719;&#24471;&#34394;&#20551;&#30340;&#26631;&#35760;&#31034;&#20363;&#65292;&#29983;&#25104;&#24335;&#25968;&#25454;&#22686;&#24191;&#21487;&#20197;&#25193;&#23637;&#25968;&#25454;&#38598;&#65292;&#24182;&#25552;&#39640;&#21508;&#31181;&#23398;&#20064;&#20219;&#21153;&#65288;&#21253;&#25324;&#65288;&#21322;&#65289;&#30417;&#30563;&#23398;&#20064;&#12289;&#23569;&#26679;&#26412;&#23398;&#20064;&#21644;&#23545;&#25239;&#24615;&#40065;&#26834;&#23398;&#20064;&#65289;&#20013;&#30340;&#20998;&#31867;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#24456;&#23569;&#26377;&#29702;&#35770;&#24037;&#20316;&#25506;&#31350;&#29983;&#25104;&#24335;&#25968;&#25454;&#22686;&#24191;&#30340;&#25928;&#26524;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#22312;&#36825;&#20010;&#38750;&#29420;&#31435;&#21644;&#21516;&#20998;&#24067;&#65288;non-i.i.d.&#65289;&#30340;&#35774;&#32622;&#20013;&#24314;&#31435;&#20102;&#19968;&#20010;&#26222;&#36941;&#30340;&#31283;&#23450;&#24615;&#30028;&#38480;&#65292;&#20854;&#20013;&#23398;&#20064;&#30340;&#20998;&#24067;&#20381;&#36182;&#20110;&#21407;&#22987;&#35757;&#32451;&#38598;&#65292;&#36890;&#24120;&#19982;&#30495;&#23454;&#20998;&#24067;&#19981;&#21516;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#21253;&#25324;&#23398;&#20064;&#20998;&#24067;&#21644;&#30495;&#23454;&#20998;&#24067;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#24403;&#21457;&#25955;&#39033;&#30340;&#38454;&#25968;&#20026;$ o(\max\left( \log(m)\beta_m, 1 / \sqrt{m})\right)$&#26102;&#65292;&#29983;&#25104;&#24335;&#25968;&#25454;&#22686;&#24191;&#21487;&#20197;&#20139;&#21463;&#26356;&#24555;&#30340;&#23398;&#20064;&#36895;&#29575;&#65292;&#20854;&#20013;$m$&#20026;&#35757;&#32451;&#38598;&#22823;&#23567;&#65292;$\beta_m$&#20026;&#30456;&#24212;&#30340;&#31283;&#23450;&#24615;&#24120;&#25968;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#30028;&#38480;&#30340;&#22823;&#23567;&#19982;&#21457;&#25955;&#38454;&#25968;&#21644;&#35757;&#32451;&#38598;&#22823;&#23567;&#25104;&#27491;&#27604;&#65292;&#36825;&#34920;&#26126;&#29983;&#25104;&#24335;&#25968;&#25454;&#22686;&#24191;&#30340;&#25928;&#26524;&#19982;&#29983;&#25104;&#27169;&#22411;&#30340;&#36873;&#25321;&#21644;&#35757;&#32451;&#38598;&#30340;&#22823;&#23567;&#23494;&#20999;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative data augmentation, which scales datasets by obtaining fake labeled examples from a trained conditional generative model, boosts classification performance in various learning tasks including (semi-)supervised learning, few-shot learning, and adversarially robust learning. However, little work has theoretically investigated the effect of generative data augmentation. To fill this gap, we establish a general stability bound in this not independently and identically distributed (non-i.i.d.) setting, where the learned distribution is dependent on the original train set and generally not the same as the true distribution. Our theoretical result includes the divergence between the learned distribution and the true distribution. It shows that generative data augmentation can enjoy a faster learning rate when the order of divergence term is $o(\max\left( \log(m)\beta_m, 1 / \sqrt{m})\right)$, where $m$ is the train set size and $\beta_m$ is the corresponding stability constant. We f
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#31232;&#30095;&#26368;&#23567;&#20108;&#20056;&#25311;&#21512;&#19968;&#22823;&#32452;&#20505;&#36873;&#20989;&#25968;&#65292;&#20351;&#29992; $\ell_1-\ell_2$ &#31232;&#30095;&#20248;&#21270;&#26041;&#27861;&#36827;&#34892;&#32467;&#26500;&#27169;&#22411;&#36873;&#25321;&#65292;&#23454;&#29616;&#20174;&#19981;&#20805;&#20998;&#19988;&#22024;&#26434;&#30340;&#26102;&#31354;&#25968;&#25454;&#20013;&#35782;&#21035;&#32467;&#26500;&#21270;&#21160;&#24577;&#31995;&#32479;&#65307;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#20102;&#39564;&#35777;&#65292;&#24182;&#35777;&#26126;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#21644;&#39640;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.17467</link><description>&lt;p&gt;
&#36890;&#36807; $\ell_1-\ell_2$ &#20248;&#21270;&#36827;&#34892;&#32467;&#26500;&#27169;&#22411;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Structured model selection via $\ell_1-\ell_2$ optimization. (arXiv:2305.17467v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17467
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#31232;&#30095;&#26368;&#23567;&#20108;&#20056;&#25311;&#21512;&#19968;&#22823;&#32452;&#20505;&#36873;&#20989;&#25968;&#65292;&#20351;&#29992; $\ell_1-\ell_2$ &#31232;&#30095;&#20248;&#21270;&#26041;&#27861;&#36827;&#34892;&#32467;&#26500;&#27169;&#22411;&#36873;&#25321;&#65292;&#23454;&#29616;&#20174;&#19981;&#20805;&#20998;&#19988;&#22024;&#26434;&#30340;&#26102;&#31354;&#25968;&#25454;&#20013;&#35782;&#21035;&#32467;&#26500;&#21270;&#21160;&#24577;&#31995;&#32479;&#65307;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#20102;&#39564;&#35777;&#65292;&#24182;&#35777;&#26126;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#21644;&#39640;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#21270;&#27169;&#22411;&#36873;&#25321;&#22312;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#20855;&#26377;&#37325;&#35201;&#24212;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#31232;&#30095;&#26368;&#23567;&#20108;&#20056;&#25311;&#21512;&#19968;&#22823;&#32452;&#20505;&#36873;&#20989;&#25968;&#65292;&#29992;&#19968;&#31181;&#38750;&#20984; $\ell_1-\ell_2$ &#31232;&#30095;&#20248;&#21270;&#26041;&#27861;&#27714;&#35299;&#65292;&#36890;&#36807;&#20132;&#26367;&#26041;&#21521;&#20056;&#27861;&#30340;&#26041;&#27861;&#36827;&#34892;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22914;&#26524;&#20505;&#36873;&#20989;&#25968;&#38598;&#21512;&#24418;&#25104;&#36793;&#30028;&#27491;&#20132;&#31995;&#32479;&#30340;&#32467;&#26500;&#38543;&#26426;&#37319;&#26679;&#30697;&#38453;&#65292;&#23601;&#21487;&#20197;&#36890;&#36807;&#20271;&#24681;&#26031;&#22374;&#26679;&#24335;&#30340;&#19981;&#31561;&#24335;&#21644;&#19968;&#33268;&#24615;&#26465;&#20214;&#31283;&#23450;&#24674;&#22797;&#65292;&#24182;&#19988;&#35823;&#24046;&#26377;&#30028;&#12290;&#35813;&#23398;&#20064;&#26041;&#27861;&#22312;&#30001;&#31896;&#24615;Burgers'&#26041;&#31243;&#21644;&#20004;&#20010;&#21453;&#24212;&#25193;&#25955;&#26041;&#31243;&#20135;&#29983;&#30340;&#21512;&#25104;&#25968;&#25454;&#19978;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;&#35745;&#31639;&#32467;&#26524;&#35777;&#26126;&#20102;&#25104;&#21151;&#30340;&#29702;&#35770;&#20445;&#35777;&#21644;&#30456;&#23545;&#20110;&#29615;&#22659;&#32500;&#25968;&#21644;&#20505;&#36873;&#20989;&#25968;&#25968;&#37327;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Automated model selection is an important application in science and engineering. In this work, we develop a learning approach for identifying structured dynamical systems from undersampled and noisy spatiotemporal data. The learning is performed by a sparse least-squares fitting over a large set of candidate functions via a nonconvex $\ell_1-\ell_2$ sparse optimization solved by the alternating direction method of multipliers. Using a Bernstein-like inequality with a coherence condition, we show that if the set of candidate functions forms a structured random sampling matrix of a bounded orthogonal system, the recovery is stable and the error is bounded. The learning approach is validated on synthetic data generated by the viscous Burgers' equation and two reaction-diffusion equations. The computational results demonstrate the theoretical guarantees of success and the efficiency with respect to the ambient dimension and the number of candidate functions.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;R-SVD&#22312;&#20302;&#31209;&#20449;&#21495;&#21152;&#22122;&#22768;&#27979;&#37327;&#27169;&#22411;&#19979;&#30340;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#24403;&#20449;&#22122;&#27604;(SNR)&#36229;&#36807;&#26576;&#20010;&#20381;&#36182;&#20110;&#38477;&#32500;&#22240;&#23376;&#30340;&#21487;&#26816;&#27979;&#38376;&#38480;&#26102;&#65292;R-SVD&#20135;&#29983;&#30340;&#26368;&#22823;&#22855;&#24322;&#20540;&#26159;&#19968;&#20010;&#31163;&#32676;&#20540;&#65307;&#22312;&#38376;&#38480;&#20197;&#19979;&#65292;&#27809;&#26377;&#31163;&#32676;&#20540;&#20174;&#22855;&#24322;&#20540;&#22359;&#20013;&#20135;&#29983;</title><link>http://arxiv.org/abs/2305.17435</link><description>&lt;p&gt;
&#20851;&#20110;&#38543;&#26426;SVD&#30340;&#22122;&#22768;&#25935;&#24863;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Noise Sensitivity of the Randomized SVD. (arXiv:2305.17435v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17435
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;R-SVD&#22312;&#20302;&#31209;&#20449;&#21495;&#21152;&#22122;&#22768;&#27979;&#37327;&#27169;&#22411;&#19979;&#30340;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#24403;&#20449;&#22122;&#27604;(SNR)&#36229;&#36807;&#26576;&#20010;&#20381;&#36182;&#20110;&#38477;&#32500;&#22240;&#23376;&#30340;&#21487;&#26816;&#27979;&#38376;&#38480;&#26102;&#65292;R-SVD&#20135;&#29983;&#30340;&#26368;&#22823;&#22855;&#24322;&#20540;&#26159;&#19968;&#20010;&#31163;&#32676;&#20540;&#65307;&#22312;&#38376;&#38480;&#20197;&#19979;&#65292;&#27809;&#26377;&#31163;&#32676;&#20540;&#20174;&#22855;&#24322;&#20540;&#22359;&#20013;&#20135;&#29983;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#22855;&#24322;&#20540;&#20998;&#35299;(R-SVD)&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#22522;&#20110;&#33609;&#22270;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#26377;&#25928;&#35745;&#31639;&#22823;&#30697;&#38453;&#30340;&#37096;&#20998;&#22855;&#24322;&#20540;&#20998;&#35299;&#12290;&#24403;&#30697;&#38453;&#26159;&#20302;&#31209;&#26102;&#65292;R-SVD&#21487;&#20197;&#31934;&#30830;&#22320;&#20135;&#29983;&#20854;&#37096;&#20998;&#22855;&#24322;&#20540;&#20998;&#35299;&#65307;&#20294;&#24403;&#31209;&#36739;&#22823;&#26102;&#65292;&#23427;&#21482;&#33021;&#20135;&#29983;&#36817;&#20284;&#20540;&#12290;&#21463;&#25968;&#25454;&#31185;&#23398;&#21644;&#20027;&#25104;&#20998;&#20998;&#26512;(PCA)&#24212;&#29992;&#30340;&#39537;&#21160;&#65292;&#25105;&#20204;&#22312;&#20302;&#31209;&#20449;&#21495;&#21152;&#22122;&#22768;&#27979;&#37327;&#27169;&#22411;&#19979;&#20998;&#26512;&#20102;R-SVD&#65307;&#20855;&#20307;&#26469;&#35828;&#65292;&#24403;&#20854;&#36755;&#20837;&#20026;&#23574;&#23792;&#22411;&#38543;&#26426;&#30697;&#38453;&#26102;&#12290;&#35777;&#26126;&#20102;R-SVD&#20135;&#29983;&#30340;&#22855;&#24322;&#20540;&#34920;&#29616;&#20986;&#31867;&#20284;BBP&#30340;&#30456;&#21464;&#65306;&#24403;&#20449;&#22122;&#27604;(SNR)&#36229;&#36807;&#26576;&#20010;&#20381;&#36182;&#20110;&#38477;&#32500;&#22240;&#23376;&#30340;&#21487;&#26816;&#27979;&#38376;&#38480;&#26102;&#65292;&#26368;&#22823;&#22855;&#24322;&#20540;&#26159;&#19968;&#20010;&#31163;&#32676;&#20540;&#65307;&#22312;&#38376;&#38480;&#20197;&#19979;&#65292;&#27809;&#26377;&#31163;&#32676;&#20540;&#20174;&#22855;&#24322;&#20540;&#22359;&#20013;&#20135;&#29983;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35745;&#31639;&#20102;&#22320;&#38754;&#30495;&#20540;&#20449;&#21495;&#22855;&#24322;&#21521;&#37327;&#19982;R-SVD&#20135;&#29983;&#30340;&#36817;&#20284;&#20540;&#20043;&#38388;&#30340;&#37325;&#21472;&#30340;&#28176;&#36817;&#20844;&#24335;&#12290;&#38477;&#32500;&#20855;&#26377;&#36127;&#38754;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
The randomized singular value decomposition (R-SVD) is a popular sketching-based algorithm for efficiently computing the partial SVD of a large matrix. When the matrix is low-rank, the R-SVD produces its partial SVD exactly; but when the rank is large, it only yields an approximation.  Motivated by applications in data science and principal component analysis (PCA), we analyze the R-SVD under a low-rank signal plus noise measurement model; specifically, when its input is a spiked random matrix. The singular values produced by the R-SVD are shown to exhibit a BBP-like phase transition: when the SNR exceeds a certain detectability threshold, that depends on the dimension reduction factor, the largest singular value is an outlier; below the threshold, no outlier emerges from the bulk of singular values. We further compute asymptotic formulas for the overlap between the ground truth signal singular vectors and the approximations produced by the R-SVD.  Dimensionality reduction has the adve
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#23545;&#25239;&#24615;&#25439;&#22833;&#21644;&#23545;&#25239;&#24615;&#36716;&#25442;&#65292;&#19988;&#21518;&#24724;&#36880;&#28176;&#22686;&#21152;&#19982;&#23545;&#25163;&#30340;&#24694;&#24847;&#31243;&#24230;&#25104;&#27604;&#20363;&#12290;</title><link>http://arxiv.org/abs/2305.17380</link><description>&lt;p&gt;
&#20855;&#26377;&#23545;&#25239;&#24615;&#25439;&#22833;&#21644;&#36716;&#25442;&#30340;&#26080;&#36951;&#25022;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
No-Regret Online Reinforcement Learning with Adversarial Losses and Transitions. (arXiv:2305.17380v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17380
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#23545;&#25239;&#24615;&#25439;&#22833;&#21644;&#23545;&#25239;&#24615;&#36716;&#25442;&#65292;&#19988;&#21518;&#24724;&#36880;&#28176;&#22686;&#21152;&#19982;&#23545;&#25163;&#30340;&#24694;&#24847;&#31243;&#24230;&#25104;&#27604;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#23545;&#25239;&#24615;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#22312;&#19982;&#23545;&#25163;&#30340;$ T $&#36718;&#20132;&#20114;&#20043;&#21518;&#23454;&#29616;${ O}(\sqrt{T})$&#30340;&#21518;&#24724;&#65292;&#21363;&#20351;&#25439;&#22833;&#20989;&#25968;&#26159;&#30001;&#23545;&#25163;&#20219;&#24847;&#36873;&#25321;&#30340;&#65292;&#20294;&#21069;&#25552;&#26159;&#36716;&#31227;&#20989;&#25968;&#24517;&#39035;&#22266;&#23450;&#12290;&#36825;&#26159;&#22240;&#20026;&#24050;&#32463;&#26377;&#30740;&#31350;&#34920;&#26126;&#65292;&#23545;&#25239;&#24615;&#36716;&#31227;&#20989;&#25968;&#20351;&#26080;&#24724;&#23398;&#20064;&#21464;&#24471;&#19981;&#21487;&#33021;&#12290;&#23613;&#31649;&#23384;&#22312;&#36825;&#31181;&#19981;&#21487;&#33021;&#24615;&#32467;&#26524;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#21487;&#20197;&#22788;&#29702;&#23545;&#25239;&#24615;&#25439;&#22833;&#21644;&#23545;&#25239;&#24615;&#36716;&#25442;&#30340;&#31639;&#27861;&#65292;&#21518;&#24724;&#36880;&#28176;&#22686;&#21152;&#19982;&#23545;&#25163;&#30340;&#24694;&#24847;&#31243;&#24230;&#25104;&#27604;&#20363;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#23427;&#30340;&#21518;&#24724;&#20026;$\widetilde{{O}}(\sqrt{T} + C^{\textsf{P}})$&#65292;&#20854;&#20013;$C^{\textsf{P}}$&#34920;&#31034;&#36716;&#25442;&#20989;&#25968;&#30340;&#23545;&#25239;&#24615;&#65292;&#26368;&#22810;&#21487;&#20197;&#20026;${O}(T)$&#12290;&#34429;&#28982;&#27492;&#31639;&#27861;&#26412;&#36523;&#38656;&#35201;$C^{\textsf{P}}$&#30340;&#30693;&#35782;&#65292;&#20294;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#40657;&#30418;&#32553;&#20943;&#26041;&#27861;&#26469;&#28040;&#38500;&#27492;&#35201;&#27714;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#19968;&#31181;&#36827;&#19968;&#27493;&#30340;&#26041;&#27861;&#65292;&#20351;&#24471;&#31639;&#27861;&#33021;&#22815;&#22788;&#29702;&#20219;&#24847;&#38271;&#24230;&#30340;&#38170;&#23450;&#26399;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing online learning algorithms for adversarial Markov Decision Processes achieve ${O}(\sqrt{T})$ regret after $T$ rounds of interactions even if the loss functions are chosen arbitrarily by an adversary, with the caveat that the transition function has to be fixed. This is because it has been shown that adversarial transition functions make no-regret learning impossible. Despite such impossibility results, in this work, we develop algorithms that can handle both adversarial losses and adversarial transitions, with regret increasing smoothly in the degree of maliciousness of the adversary. More concretely, we first propose an algorithm that enjoys $\widetilde{{O}}(\sqrt{T} + C^{\textsf{P}})$ regret where $C^{\textsf{P}}$ measures how adversarial the transition functions are and can be at most ${O}(T)$. While this algorithm itself requires knowledge of $C^{\textsf{P}}$, we further develop a black-box reduction approach that removes this requirement. Moreover, we also show that furth
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#31283;&#23450;&#24615;&#24809;&#32602;&#33258;&#36866;&#24212;&#65288;SPA&#65289;&#23398;&#20064;&#29575;&#65292;&#35813;&#23398;&#20064;&#29575;&#20351;FTRL&#20855;&#26377;&#31232;&#30095;&#24615;&#12289;&#28216;&#25103;&#20381;&#36182;&#24615;&#21644;&#26368;&#20339;&#19990;&#30028;&#65288;BOBW&#65289;&#19977;&#31181;&#36866;&#24212;&#24615;&#31867;&#22411;&#65292;&#20854;&#20013;SPA-sparse&#31639;&#27861;&#21487;&#36866;&#24212;&#20110;&#26410;&#30693;&#30340;&#31232;&#30095;&#32423;&#21035;&#65292;SPA-game-dependency&#31639;&#27861;&#21487;&#26681;&#25454;&#25152;&#29609;&#30340;&#28216;&#25103;&#33258;&#36866;&#24212;&#22320;&#25913;&#21464;&#20854;&#34892;&#20026;&#65292;BOBW&#31639;&#27861;&#21017;&#26159;&#26082;&#20855;&#26377;&#31232;&#30095;&#24615;&#21448;&#20855;&#26377;&#28216;&#25103;&#20381;&#36182;&#24615;&#30340;&#36866;&#24212;&#24615;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.17301</link><description>&lt;p&gt;
&#31283;&#23450;&#24615;&#24809;&#32602;&#33258;&#36866;&#24212;&#36319;&#38543;&#27491;&#21017;&#21270;&#39046;&#34966;&#65306;&#31232;&#30095;&#24615;&#12289;&#28216;&#25103;&#20381;&#36182;&#24615;&#21644;&#26368;&#20339;&#19990;&#30028;&#30340;&#24182;&#23384;
&lt;/p&gt;
&lt;p&gt;
Stability-penalty-adaptive Follow-the-regularized-leader: Sparsity, Game-dependency, and Best-of-both-worlds. (arXiv:2305.17301v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17301
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#31283;&#23450;&#24615;&#24809;&#32602;&#33258;&#36866;&#24212;&#65288;SPA&#65289;&#23398;&#20064;&#29575;&#65292;&#35813;&#23398;&#20064;&#29575;&#20351;FTRL&#20855;&#26377;&#31232;&#30095;&#24615;&#12289;&#28216;&#25103;&#20381;&#36182;&#24615;&#21644;&#26368;&#20339;&#19990;&#30028;&#65288;BOBW&#65289;&#19977;&#31181;&#36866;&#24212;&#24615;&#31867;&#22411;&#65292;&#20854;&#20013;SPA-sparse&#31639;&#27861;&#21487;&#36866;&#24212;&#20110;&#26410;&#30693;&#30340;&#31232;&#30095;&#32423;&#21035;&#65292;SPA-game-dependency&#31639;&#27861;&#21487;&#26681;&#25454;&#25152;&#29609;&#30340;&#28216;&#25103;&#33258;&#36866;&#24212;&#22320;&#25913;&#21464;&#20854;&#34892;&#20026;&#65292;BOBW&#31639;&#27861;&#21017;&#26159;&#26082;&#20855;&#26377;&#31232;&#30095;&#24615;&#21448;&#20855;&#26377;&#28216;&#25103;&#20381;&#36182;&#24615;&#30340;&#36866;&#24212;&#24615;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39034;&#24207;&#20915;&#31574;&#38382;&#39064;&#20013;&#65292;&#36866;&#24212;&#38382;&#39064;&#30340;&#22256;&#38590;&#31243;&#24230;&#26159;&#25193;&#23637;&#31639;&#27861;&#36866;&#29992;&#24615;&#30340;&#20851;&#38190;&#23646;&#24615;&#12290;&#36319;&#38543;&#27491;&#21017;&#21270;&#39046;&#34966;&#36817;&#24180;&#26469;&#25104;&#20026;&#33719;&#21462;&#28120;&#27760;&#27861;&#20013;&#21508;&#31181;&#31867;&#22411;&#36866;&#24212;&#24615;&#30340;&#26368;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#20043;&#19968;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#25512;&#24191;&#36825;&#31181;&#36866;&#24212;&#24615;&#65292;&#25105;&#20204;&#20026;FTRL&#24320;&#21457;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#65292;&#31216;&#20026;&#31283;&#23450;&#24615;&#24809;&#32602;&#33258;&#36866;&#24212;&#65288;SPA&#65289;&#23398;&#20064;&#29575;&#12290;&#35813;&#23398;&#20064;&#29575;&#20135;&#29983;&#30340;&#36951;&#25022;&#30028;&#20849;&#21516;&#21462;&#20915;&#20110;&#31639;&#27861;&#30340;&#31283;&#23450;&#24615;&#21644;&#24809;&#32602;&#65292;&#20854;&#20013;FTRL&#30340;&#36951;&#25022;&#36890;&#24120;&#34987;&#20998;&#35299;&#12290;&#20973;&#20511;&#36825;&#20010;&#32467;&#26524;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#20960;&#20010;&#20855;&#26377;&#19977;&#31181;&#36866;&#24212;&#24615;&#31867;&#22411;&#30340;&#31639;&#27861;&#65306;&#31232;&#30095;&#24615;&#12289;&#28216;&#25103;&#20381;&#36182;&#24615;&#21644;&#26368;&#20339;&#19990;&#30028;&#65288;BOBW&#65289;&#12290;&#31232;&#30095;&#24615;&#32463;&#24120;&#20986;&#29616;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#38382;&#39064;&#20013;&#65292;&#20294;&#26159;&#65292;&#29616;&#26377;&#30340;&#31232;&#30095;&#22810;&#33218;&#36172;&#21338;&#31639;&#27861;$k$-arms&#20551;&#23450;&#20107;&#20808;&#24050;&#30693;&#31232;&#30095;&#32423;&#21035;$s \leq k$&#65292;&#32780;&#36825;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#24773;&#20917;&#19979;&#36890;&#24120;&#19981;&#26159;&#24773;&#20917;&#12290;&#20026;&#20102;&#36866;&#24212;&#26410;&#30693;&#30340;&#31232;&#30095;&#32423;&#21035;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;SPA-sparse&#65292;&#35813;&#31639;&#27861;&#26174;&#31034;&#27604;&#29616;&#26377;&#31232;&#30095;&#31639;&#27861;&#30340;&#24615;&#33021;&#25552;&#39640;&#20102;&#12290;&#28216;&#25103;&#20381;&#36182;&#24615;&#26159;&#21478;&#19968;&#31181;&#36866;&#24212;&#24615;&#31867;&#22411;&#65292;&#24403;&#29992;&#20110;&#29983;&#25104;&#25968;&#25454;&#30340;&#28216;&#25103;&#21457;&#29983;&#21464;&#21270;&#26102;&#65292;&#21363;&#24517;&#38656;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;SPA-game-dependency&#65292;&#35813;&#31639;&#27861;&#26681;&#25454;&#25152;&#29609;&#30340;&#28216;&#25103;&#33258;&#36866;&#24212;&#22320;&#25913;&#21464;&#20854;&#34892;&#20026;&#65292;&#24182;&#34920;&#26126;&#23427;&#27604;&#38750;&#33258;&#36866;&#24212;&#31639;&#27861;&#30340;&#24615;&#33021;&#26356;&#22909;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26082;&#20855;&#26377;&#31232;&#30095;&#24615;&#21448;&#20855;&#26377;&#28216;&#25103;&#20381;&#36182;&#24615;&#36866;&#24212;&#24615;&#30340;BOBW&#31639;&#27861;&#65292;&#24182;&#26174;&#31034;&#23427;&#27604;&#20165;&#38598;&#20013;&#20110;&#19968;&#31181;&#36866;&#24212;&#24615;&#31867;&#22411;&#30340;&#31639;&#27861;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adaptivity to the difficulties of a problem is a key property in sequential decision-making problems to broaden the applicability of algorithms. Follow-the-Regularized-Leader (FTRL) has recently emerged as one of the most promising approaches for obtaining various types of adaptivity in bandit problems. Aiming to further generalize this adaptivity, we develop a generic adaptive learning rate, called Stability-Penalty-Adaptive (SPA) learning rate for FTRL. This learning rate yields a regret bound jointly depending on stability and penalty of the algorithm, into which the regret of FTRL is typically decomposed. With this result, we establish several algorithms with three types of adaptivity: sparsity, game-dependency, and Best-of-Both-Worlds (BOBW). Sparsity frequently appears in real-world problems. However, existing sparse multi-armed bandit algorithms with $k$-arms assume that the sparsity level $s \leq k$ is known in advance, which is often not the case in real-world scenarios. To ad
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#21307;&#30103;&#24212;&#29992;&#30340;&#35270;&#35282;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20915;&#31574;&#26641;&#36317;&#31163;&#24230;&#37327;&#65292;&#24182;&#29992;&#23427;&#26469;&#30830;&#23450;&#26641;&#30340;&#31283;&#23450;&#27700;&#24179;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22521;&#35757;&#31283;&#23450;&#20915;&#31574;&#26641;&#30340;&#26041;&#27861;&#65292;&#24182;&#25506;&#31350;&#31283;&#23450;&#24615;&#12289;&#39044;&#27979;&#33021;&#21147;&#21644;&#21487;&#35299;&#37322;&#24615;&#20043;&#38388;&#19981;&#21487;&#36991;&#20813;&#30340;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2305.17299</link><description>&lt;p&gt;
&#25552;&#39640;&#20915;&#31574;&#26641;&#27169;&#22411;&#30340;&#31283;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Improving Stability in Decision Tree Models. (arXiv:2305.17299v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17299
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#21307;&#30103;&#24212;&#29992;&#30340;&#35270;&#35282;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20915;&#31574;&#26641;&#36317;&#31163;&#24230;&#37327;&#65292;&#24182;&#29992;&#23427;&#26469;&#30830;&#23450;&#26641;&#30340;&#31283;&#23450;&#27700;&#24179;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22521;&#35757;&#31283;&#23450;&#20915;&#31574;&#26641;&#30340;&#26041;&#27861;&#65292;&#24182;&#25506;&#31350;&#31283;&#23450;&#24615;&#12289;&#39044;&#27979;&#33021;&#21147;&#21644;&#21487;&#35299;&#37322;&#24615;&#20043;&#38388;&#19981;&#21487;&#36991;&#20813;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20854;&#32467;&#26500;&#26131;&#20110;&#29702;&#35299;&#65292;&#20915;&#31574;&#26641;&#36890;&#24120;&#22312;&#38656;&#35201;&#21487;&#35299;&#37322;&#24615;&#30340;&#24212;&#29992;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#36817;&#26399;&#30340;&#24037;&#20316;&#38598;&#20013;&#20110;&#25913;&#36827;&#20915;&#31574;&#26641;&#30340;&#21508;&#20010;&#26041;&#38754;&#65292;&#21253;&#25324;&#39044;&#27979;&#33021;&#21147;&#21644;&#40065;&#26834;&#24615;&#65307;&#28982;&#32780;&#65292;&#20854;&#19981;&#31283;&#23450;&#24615;&#34429;&#28982;&#26377;&#20805;&#20998;&#30340;&#35760;&#24405;&#65292;&#20294;&#21364;&#24471;&#21040;&#20102;&#36739;&#23569;&#30340;&#20851;&#27880;&#12290;&#26412;&#25991;&#36890;&#36807;&#23454;&#38469;&#30340;&#21307;&#30103;&#24212;&#29992;&#30340;&#35270;&#35282;&#65292;&#25552;&#20986;&#20102;&#31283;&#23450;&#21270;&#20915;&#31574;&#26641;&#27169;&#22411;&#30340;&#19968;&#23567;&#27493;&#12290;&#30001;&#20110;&#31283;&#23450;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#22312;&#21307;&#30103;&#39046;&#22495;&#20855;&#26377;&#37325;&#35201;&#24615;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#20915;&#31574;&#26641;&#36317;&#31163;&#24230;&#37327;&#65292;&#24182;&#23558;&#20854;&#29992;&#20110;&#30830;&#23450;&#26641;&#30340;&#31283;&#23450;&#27700;&#24179;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22521;&#35757;&#31283;&#23450;&#20915;&#31574;&#26641;&#30340;&#26041;&#27861;&#65292;&#24182;&#35843;&#26597;&#20102;&#20915;&#31574;&#26641;&#27169;&#22411;&#20043;&#38388;&#19981;&#21487;&#36991;&#20813;&#30340;&#26435;&#34913;&#65292;&#21253;&#25324;&#22312;&#31283;&#23450;&#24615;&#12289;&#39044;&#27979;&#33021;&#21147;&#21644;&#21487;&#35299;&#37322;&#24615;&#20043;&#38388;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#20845;&#20010;&#25968;&#25454;&#38598;&#30340;&#24191;&#27867;&#23450;&#37327;&#21644;&#23450;&#24615;&#20998;&#26512;&#23637;&#31034;&#20102;&#25152;&#25552;&#35758;&#26041;&#27861;&#30340;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Owing to their inherently interpretable structure, decision trees are commonly used in applications where interpretability is essential. Recent work has focused on improving various aspects of decision trees, including their predictive power and robustness; however, their instability, albeit well-documented, has been addressed to a lesser extent. In this paper, we take a step towards the stabilization of decision tree models through the lens of real-world health care applications due to the relevance of stability and interpretability in this space. We introduce a new distance metric for decision trees and use it to determine a tree's level of stability. We propose a novel methodology to train stable decision trees and investigate the existence of trade-offs that are inherent to decision tree models - including between stability, predictive power, and interpretability. We demonstrate the value of the proposed methodology through an extensive quantitative and qualitative analysis of six 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20302;&#31209;&#32467;&#26500;&#20294;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#30340;&#24773;&#20917;&#65292;&#22312;&#20998;&#31163;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#30340;&#20551;&#35774;&#19979;&#65292;&#35299;&#20915;&#20102;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#20998;&#24067;&#20559;&#31227;&#30340;&#24773;&#20917;&#19979;&#65292;&#26412;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;&#27867;&#21270;&#35823;&#24046;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.17297</link><description>&lt;p&gt;
&#26080;&#29420;&#31435;&#24615;&#30340;&#27867;&#21270;&#35823;&#24046;&#65306;&#21435;&#22122;&#12289;&#32447;&#24615;&#22238;&#24402;&#21644;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Generalization Error without Independence: Denoising, Linear Regression, and Transfer Learning. (arXiv:2305.17297v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17297
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20302;&#31209;&#32467;&#26500;&#20294;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#30340;&#24773;&#20917;&#65292;&#22312;&#20998;&#31163;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#30340;&#20551;&#35774;&#19979;&#65292;&#35299;&#20915;&#20102;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#20998;&#24067;&#20559;&#31227;&#30340;&#24773;&#20917;&#19979;&#65292;&#26412;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;&#27867;&#21270;&#35823;&#24046;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#32447;&#24615;&#27169;&#22411;&#22312;&#30495;&#23454;&#25968;&#25454;&#20013;&#30340;&#27867;&#21270;&#33021;&#21147;&#26159;&#32479;&#35745;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#12290;&#20808;&#21069;&#30340;&#19968;&#20123;&#37325;&#35201;&#24037;&#20316;&#39564;&#35777;&#20102;&#29702;&#35770;&#24037;&#20316;&#19982;&#30495;&#23454;&#25968;&#25454;&#30340;&#30456;&#20851;&#24615;&#65292;&#20294;&#36825;&#20123;&#24037;&#20316;&#30001;&#20110;&#25216;&#26415;&#20551;&#35774;&#23384;&#22312;&#38480;&#21046;&#65292;&#36825;&#20123;&#20551;&#35774;&#21253;&#25324;&#20855;&#26377;&#33391;&#22909;&#26465;&#20214;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#20197;&#21450;&#20855;&#26377;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#65292;&#36825;&#20123;&#20551;&#35774;&#22312;&#30495;&#23454;&#25968;&#25454;&#20013;&#24182;&#19981;&#19968;&#23450;&#25104;&#31435;&#12290;&#27492;&#22806;&#65292;&#20197;&#21069;&#30340;&#19968;&#20123;&#20851;&#20110;&#20998;&#24067;&#20559;&#31227;&#30340;&#24037;&#20316;&#36890;&#24120;&#23545;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#30340;&#32852;&#21512;&#20998;&#24067;&#36827;&#34892;&#25216;&#26415;&#20551;&#35774;&#65292;&#24182;&#19988;&#19981;&#22312;&#30495;&#23454;&#25968;&#25454;&#19978;&#36827;&#34892;&#27979;&#35797;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#24182;&#26356;&#22909;&#22320;&#23545;&#30495;&#23454;&#25968;&#25454;&#36827;&#34892;&#24314;&#27169;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#20302;&#31209;&#32467;&#26500;&#20294;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#30340;&#24773;&#20917;&#65292;&#21516;&#26102;&#36890;&#36807;&#20998;&#31163;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#30340;&#20551;&#35774;&#26469;&#35299;&#20915;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;&#25105;&#20204;&#36824;&#22312;&#36825;&#20123;&#26494;&#24347;&#30340;&#20551;&#35774;&#19979;&#65292;&#30740;&#31350;&#20102;&#21435;&#22122;&#38382;&#39064;&#12289;&#32447;&#24615;&#22238;&#24402;&#21644;&#36801;&#31227;&#23398;&#20064;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#30456;&#27604;&#20197;&#21069;&#30340;&#26041;&#27861;&#65292;&#22312;&#20998;&#24067;&#20559;&#31227;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;&#27867;&#21270;&#35823;&#24046;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Studying the generalization abilities of linear models with real data is a central question in statistical learning. While there exist a limited number of prior important works (Loureiro et al. (2021A, 2021B), Wei et al. 2022) that do validate theoretical work with real data, these works have limitations due to technical assumptions. These assumptions include having a well-conditioned covariance matrix and having independent and identically distributed data. These assumptions are not necessarily valid for real data. Additionally, prior works that do address distributional shifts usually make technical assumptions on the joint distribution of the train and test data (Tripuraneni et al. 2021, Wu and Xu 2020), and do not test on real data.  In an attempt to address these issues and better model real data, we look at data that is not I.I.D. but has a low-rank structure. Further, we address distributional shift by decoupling assumptions on the training and test distribution. We provide anal
&lt;/p&gt;</description></item><item><title>GC-Flow&#26159;&#19968;&#31181;&#29983;&#25104;&#27169;&#22411;&#65292;&#21487;&#20197;&#21516;&#26102;&#24314;&#27169;&#31867;&#21035;&#26465;&#20214;&#27010;&#29575;&#21644;&#31867;&#21035;&#20808;&#39564;&#65292;&#36890;&#36807;&#37197;&#22791;&#39640;&#26031;&#28151;&#21512;&#34920;&#31034;&#31354;&#38388;&#65292;&#20445;&#25345;&#39044;&#27979;&#33021;&#21147;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#33391;&#22909;&#20998;&#31163;&#30340;&#32858;&#31867;&#12290;</title><link>http://arxiv.org/abs/2305.17284</link><description>&lt;p&gt;
GC-Flow: &#19968;&#31181;&#22522;&#20110;&#22270;&#30340;&#27969;&#32593;&#32476;&#29992;&#20110;&#26377;&#25928;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
GC-Flow: A Graph-Based Flow Network for Effective Clustering. (arXiv:2305.17284v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17284
&lt;/p&gt;
&lt;p&gt;
GC-Flow&#26159;&#19968;&#31181;&#29983;&#25104;&#27169;&#22411;&#65292;&#21487;&#20197;&#21516;&#26102;&#24314;&#27169;&#31867;&#21035;&#26465;&#20214;&#27010;&#29575;&#21644;&#31867;&#21035;&#20808;&#39564;&#65292;&#36890;&#36807;&#37197;&#22791;&#39640;&#26031;&#28151;&#21512;&#34920;&#31034;&#31354;&#38388;&#65292;&#20445;&#25345;&#39044;&#27979;&#33021;&#21147;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#33391;&#22909;&#20998;&#31163;&#30340;&#32858;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#21367;&#31215;&#32593;&#32476;&#65288;GCN&#65289;&#26159;&#30452;&#25509;&#24314;&#27169;&#21322;&#30417;&#30563;&#20998;&#31867;&#22270;&#25968;&#25454;&#31867;&#21518;&#39564;&#27010;&#29575;$p&#65288;y|\mathbf{x}&#65289;$&#30340;&#21028;&#21035;&#27169;&#22411;&#12290;&#34429;&#28982;&#20316;&#20026;&#19968;&#31181;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#38750;&#24120;&#26377;&#25928;&#65292;&#20294;&#26159;&#20174;GCN&#20013;&#25552;&#21462;&#30340;&#33410;&#28857;&#34920;&#24449;&#24120;&#32570;&#23569;&#26377;&#25928;&#32858;&#31867;&#25152;&#38656;&#30340;&#26377;&#29992;&#20449;&#24687;&#65292;&#22240;&#20026;&#23427;&#20204;&#30340;&#30446;&#26631;&#19981;&#21516;&#12290;&#26412;&#30740;&#31350;&#35774;&#35745;&#20102;&#24402;&#19968;&#21270;&#27969;&#65292;&#29992;&#20110;&#26367;&#25442;GCN&#23618;&#65292;&#26500;&#24314;&#19968;&#31181;&#29983;&#25104;&#27169;&#22411;&#65292;&#21516;&#26102;&#24314;&#27169;&#31867;&#21035;&#26465;&#20214;&#27010;&#29575;$p(\mathbf{x}|y)$&#21644;&#31867;&#21035;&#20808;&#39564;$p(y)$&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#31070;&#32463;&#32593;&#32476;GC-Flow&#20445;&#30041;&#20102;&#22270;&#21367;&#31215;&#25805;&#20316;&#65292;&#21516;&#26102;&#37197;&#22791;&#20102;&#39640;&#26031;&#28151;&#21512;&#34920;&#31034;&#31354;&#38388;&#12290;&#36825;&#26377;&#20004;&#20010;&#22909;&#22788;&#65306;&#23427;&#19981;&#20165;&#20445;&#25345;&#20102;GCN&#30340;&#39044;&#27979;&#33021;&#21147;&#65292;&#36824;&#30001;&#20110;&#34920;&#31034;&#31354;&#38388;&#30340;&#32467;&#26500;&#32780;&#20135;&#29983;&#20102;&#33391;&#22909;&#20998;&#31163;&#30340;&#32858;&#31867;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#36825;&#20123;&#20248;&#21183;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#39069;&#22806;&#30340;&#21442;&#25968;&#21270;&#27491;&#21017;&#21270;&#20248;&#21183;&#21644;&#36890;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph convolutional networks (GCNs) are \emph{discriminative models} that directly model the class posterior $p(y|\mathbf{x})$ for semi-supervised classification of graph data. While being effective, as a representation learning approach, the node representations extracted from a GCN often miss useful information for effective clustering, because the objectives are different. In this work, we design normalizing flows that replace GCN layers, leading to a \emph{generative model} that models both the class conditional likelihood $p(\mathbf{x}|y)$ and the class prior $p(y)$. The resulting neural network, GC-Flow, retains the graph convolution operations while being equipped with a Gaussian mixture representation space. It enjoys two benefits: it not only maintains the predictive power of GCN, but also produces well-separated clusters, due to the structuring of the representation space. We demonstrate these benefits on a variety of benchmark data sets. Moreover, we show that additional par
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#23618;&#31639;&#27861;&#26469;&#35299;&#20915;&#23398;&#20064;DAGs&#20013;&#30340;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#22806;&#23618;&#21033;&#29992;&#25299;&#25169;&#20132;&#25442;&#20248;&#21270;&#25299;&#25169;&#39034;&#24207;&#65292;&#36890;&#36807;&#24320;&#21457;&#19968;&#31181;&#20505;&#36873;&#20132;&#25442;&#23545;&#30340;&#26041;&#27861;&#65292;&#31639;&#27861;&#22312;&#23398;&#20064;&#39640;&#36136;&#37327;DAGs&#26041;&#38754;&#20855;&#26377;&#39640;&#25928;&#21644;&#31283;&#23450;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2305.17277</link><description>&lt;p&gt;
&#36890;&#36807;&#25299;&#25169;&#20132;&#25442;&#20248;&#21270;NOTEARS&#30446;&#26631;
&lt;/p&gt;
&lt;p&gt;
Optimizing NOTEARS Objectives via Topological Swaps. (arXiv:2305.17277v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17277
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#23618;&#31639;&#27861;&#26469;&#35299;&#20915;&#23398;&#20064;DAGs&#20013;&#30340;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#22806;&#23618;&#21033;&#29992;&#25299;&#25169;&#20132;&#25442;&#20248;&#21270;&#25299;&#25169;&#39034;&#24207;&#65292;&#36890;&#36807;&#24320;&#21457;&#19968;&#31181;&#20505;&#36873;&#20132;&#25442;&#23545;&#30340;&#26041;&#27861;&#65292;&#31639;&#27861;&#22312;&#23398;&#20064;&#39640;&#36136;&#37327;DAGs&#26041;&#38754;&#20855;&#26377;&#39640;&#25928;&#21644;&#31283;&#23450;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22312;&#23398;&#20064;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAGs&#65289;&#30340;&#32972;&#26223;&#19979;&#65292;&#20986;&#29616;&#20102;&#19968;&#31867;&#26377;&#36259;&#30340;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#36825;&#20123;&#38382;&#39064;&#28041;&#21450;&#21040;&#22312;&#32473;&#23450;&#25439;&#22833;&#25110;&#24471;&#20998;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#23567;&#21270;&#19968;&#20010;&#24809;&#32602;&#22270;&#20013;&#23384;&#22312;&#24490;&#29615;&#30340;&#38750;&#20984;&#36830;&#32493;&#32422;&#26463;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#19982;&#36825;&#31867;&#38750;&#20984;&#31243;&#24207;&#30456;&#20851;&#30340;&#20248;&#21270;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#23618;&#31639;&#27861;&#65292;&#20197;&#26032;&#39062;&#30340;&#26041;&#24335;&#21033;&#29992;&#38750;&#20984;&#32422;&#26463;&#12290;&#31639;&#27861;&#30340;&#22806;&#23618;&#36890;&#36807;&#36845;&#20195;&#22320;&#20132;&#25442;DAG&#30340;&#25299;&#25169;&#39034;&#24207;&#20013;&#30340;&#33410;&#28857;&#23545;&#26469;&#20248;&#21270;&#25299;&#25169;&#39034;&#24207;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#19968;&#20010;&#20851;&#38190;&#21019;&#26032;&#26159;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#20026;&#27599;&#27425;&#36845;&#20195;&#29983;&#25104;&#19968;&#32452;&#20505;&#36873;&#20132;&#25442;&#23545;&#12290;&#22312;&#20869;&#23618;&#20013;&#65292;&#32473;&#23450;&#25299;&#25169;&#39034;&#24207;&#65292;&#25105;&#20204;&#21033;&#29992;&#33021;&#22815;&#22788;&#29702;&#32447;&#24615;&#32422;&#26463;&#30340;&#29616;&#25104;&#27714;&#35299;&#22120;&#12290;&#25105;&#20204;&#25152;&#25552;&#20986;&#31639;&#27861;&#30340;&#20027;&#35201;&#20248;&#21183;&#26159;&#65292;&#23427;&#20445;&#35777;&#25910;&#25947;&#21040;&#20248;&#21270;&#38382;&#39064;&#30340;&#19968;&#20010;&#31283;&#23450;&#28857;&#65292;&#32780;&#29616;&#26377;&#26041;&#27861;&#21487;&#33021;&#20250;&#38519;&#20837;&#20122;&#26368;&#20248;&#35299;&#20013;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#31639;&#27861;&#22312;&#23398;&#20064;&#39640;&#36136;&#37327;DAGs&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, an intriguing class of non-convex optimization problems has emerged in the context of learning directed acyclic graphs (DAGs). These problems involve minimizing a given loss or score function, subject to a non-convex continuous constraint that penalizes the presence of cycles in a graph. In this work, we delve into the optimization challenges associated with this class of non-convex programs. To address these challenges, we propose a bi-level algorithm that leverages the non-convex constraint in a novel way. The outer level of the algorithm optimizes over topological orders by iteratively swapping pairs of nodes within the topological order of a DAG. A key innovation of our approach is the development of an effective method for generating a set of candidate swapping pairs for each iteration. At the inner level, given a topological order, we utilize off-the-shelf solvers that can handle linear constraints. The key advantage of our proposed algorithm is that it is guaranteed to
&lt;/p&gt;</description></item><item><title>FineMorphs&#26159;&#19968;&#31181;&#22810;&#20803;&#22238;&#24402;&#27169;&#22411;&#65292;&#36890;&#36807;&#24418;&#29366;&#20998;&#26512;&#20013;&#30340;&#24494;&#20998;&#21516;&#32986;&#27010;&#24565;&#23545;&#27169;&#22411;&#29366;&#24577;&#36827;&#34892;&#20248;&#21270;&#65292;&#33021;&#22815;&#33258;&#28982;&#22320;&#20943;&#23569;&#65288;&#25110;&#22686;&#21152;&#65289;&#32500;&#24230;&#24182;&#36866;&#24212;&#22823;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2305.17255</link><description>&lt;p&gt;
FineMorphs:&#29992;&#20110;&#22238;&#24402;&#30340;&#20223;&#23556;-&#24494;&#20998;&#21516;&#32986;&#24207;&#21015;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
FineMorphs: Affine-diffeomorphic sequences for regression. (arXiv:2305.17255v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17255
&lt;/p&gt;
&lt;p&gt;
FineMorphs&#26159;&#19968;&#31181;&#22810;&#20803;&#22238;&#24402;&#27169;&#22411;&#65292;&#36890;&#36807;&#24418;&#29366;&#20998;&#26512;&#20013;&#30340;&#24494;&#20998;&#21516;&#32986;&#27010;&#24565;&#23545;&#27169;&#22411;&#29366;&#24577;&#36827;&#34892;&#20248;&#21270;&#65292;&#33021;&#22815;&#33258;&#28982;&#22320;&#20943;&#23569;&#65288;&#25110;&#22686;&#21152;&#65289;&#32500;&#24230;&#24182;&#36866;&#24212;&#22823;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20223;&#23556;&#21644;&#24494;&#20998;&#21516;&#32986;&#21464;&#25442;&#24207;&#21015;&#30340;&#22810;&#20803;&#22238;&#24402;&#27169;&#22411;FineMorphs&#12290;&#35813;&#27169;&#22411;&#21033;&#29992;&#24418;&#29366;&#20998;&#26512;&#30340;&#27010;&#24565;&#65292;&#22312;&#23398;&#20064;&#26399;&#38388;&#36890;&#36807;&#30001;&#20809;&#28369;&#21521;&#37327;&#22330;&#29983;&#25104;&#30340;&#24494;&#20998;&#21516;&#32986;&#20248;&#21270;&#22320;&#8220;&#37325;&#22609;&#8221;&#27169;&#22411;&#29366;&#24577;&#12290;&#20223;&#23556;&#21464;&#25442;&#21644;&#21521;&#37327;&#22330;&#22312;&#26368;&#20248;&#25511;&#21046;&#29615;&#22659;&#20013;&#36827;&#34892;&#20248;&#21270;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#27425;&#20248;&#21521;&#37327;&#22330;&#33258;&#28982;&#22320;&#20943;&#23569;&#65288;&#25110;&#22686;&#21152;&#65289;&#32500;&#24230;&#24182;&#36866;&#24212;&#22823;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#35813;&#27169;&#22411;&#30340;&#35299;&#23384;&#22312;&#24615;&#35777;&#26126;&#21644;&#26368;&#20248;&#24615;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;FineMorphs&#22312;&#19982;&#25991;&#29486;&#20013;&#26368;&#20808;&#36827;&#21644;&#22522;&#20110;TensorFlow&#30340;&#31264;&#23494;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#27604;&#36739;&#20013;&#65292;&#21462;&#24471;&#20102;&#26377;&#21033;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
A multivariate regression model of affine and diffeomorphic transformation sequences - FineMorphs - is presented. Leveraging concepts from shape analysis, model states are optimally "reshaped" by diffeomorphisms generated by smooth vector fields during learning. Affine transformations and vector fields are optimized within an optimal control setting, and the model can naturally reduce (or increase) dimensionality and adapt to large datasets via suboptimal vector fields. An existence proof of solution and necessary conditions for optimality for the model are derived. Experimental results on real datasets from the UCI repository are presented, with favorable results in comparison with state-of-the-art in the literature and densely-connected neural networks in TensorFlow.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#20013;&#38388;&#38382;&#39064;&#65306;&#22240;&#26524;&#25104;&#20998;&#20998;&#26512;(CauCA)&#65292;&#23427;&#26159;&#29420;&#31435;&#25104;&#20998;&#20998;&#26512;(ICA)&#21644;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;(CRL)&#30340;&#27867;&#21270;&#21644;&#29305;&#20363;&#65292;&#20854;&#30446;&#26631;&#26159;&#23398;&#20064;&#35299;&#28151;&#20989;&#25968;&#21644;&#22240;&#26524;&#26426;&#21046;&#65292;&#39044;&#35774;&#20102;&#22240;&#26524;&#22270;&#30340;&#30693;&#35782;&#12290;</title><link>http://arxiv.org/abs/2305.17225</link><description>&lt;p&gt;
&#22240;&#26524;&#25104;&#20998;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Causal Component Analysis. (arXiv:2305.17225v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17225
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#20013;&#38388;&#38382;&#39064;&#65306;&#22240;&#26524;&#25104;&#20998;&#20998;&#26512;(CauCA)&#65292;&#23427;&#26159;&#29420;&#31435;&#25104;&#20998;&#20998;&#26512;(ICA)&#21644;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;(CRL)&#30340;&#27867;&#21270;&#21644;&#29305;&#20363;&#65292;&#20854;&#30446;&#26631;&#26159;&#23398;&#20064;&#35299;&#28151;&#20989;&#25968;&#21644;&#22240;&#26524;&#26426;&#21046;&#65292;&#39044;&#35774;&#20102;&#22240;&#26524;&#22270;&#30340;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29420;&#31435;&#25104;&#20998;&#20998;&#26512;(ICA)&#30340;&#30446;&#26631;&#26159;&#20174;&#28151;&#21512;&#35266;&#27979;&#21040;&#30340;&#21464;&#37327;&#20013;&#24674;&#22797;&#29420;&#31435;&#30340;&#28508;&#22312;&#21464;&#37327;&#12290;&#32780;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;(CRL)&#30340;&#30446;&#26631;&#26159;&#25512;&#26029;&#22240;&#26524;&#20851;&#31995;&#24378;&#30456;&#20851;&#24615;&#30340;&#28508;&#22312;&#21464;&#37327;&#65292;&#20197;&#21450;&#32534;&#30721;&#23427;&#20204;&#30340;&#22240;&#26524;&#20851;&#31995;&#30340;&#26410;&#30693;&#22270;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20013;&#38388;&#38382;&#39064;&#65292;&#31216;&#20026;&#22240;&#26524;&#25104;&#20998;&#20998;&#26512;(CauCA)&#12290;CauCA&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;ICA&#30340;&#19968;&#31181;&#25512;&#24191;&#65292;&#23545;&#28508;&#22312;&#25104;&#20998;&#20043;&#38388;&#30340;&#22240;&#26524;&#20381;&#36182;&#24314;&#27169;&#65292;&#20063;&#26159;CRL&#30340;&#19968;&#20010;&#29305;&#20363;&#12290;&#19982;CRL&#19981;&#21516;&#30340;&#26159;&#65292;&#23427;&#39044;&#35774;&#20102;&#22240;&#26524;&#22270;&#30340;&#30693;&#35782;&#65292;&#20165;&#20851;&#27880;&#20110;&#23398;&#20064;&#35299;&#28151;&#20989;&#25968;&#21644;&#22240;&#26524;&#26426;&#21046;&#12290;&#25152;&#26377;&#20851;&#20110;CauCA&#22238;&#25910;&#22522;&#30784;&#30495;&#30456;&#30340;&#19981;&#21487;&#33021;&#32467;&#26524;&#20063;&#36866;&#29992;&#20110;CRL&#65292;&#32780;&#21487;&#33021;&#24615;&#32467;&#26524;&#21487;&#20197;&#20316;&#20026;&#25193;&#23637;CRL&#30340;&#22522;&#30784;&#12290;&#25105;&#20204;&#23558;&#20174;&#23545;&#28508;&#22312;&#22240;&#26524;&#21464;&#37327;&#23454;&#26045;&#19981;&#21516;&#31867;&#22411;&#24178;&#39044;&#30340;&#22810;&#20010;&#25968;&#25454;&#38598;&#20013;&#34920;&#24449;CauCA&#30340;&#21487;&#35782;&#21035;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Independent Component Analysis (ICA) aims to recover independent latent variables from observed mixtures thereof. Causal Representation Learning (CRL) aims instead to infer causally related (thus often statistically dependent) latent variables, together with the unknown graph encoding their causal relationships. We introduce an intermediate problem termed Causal Component Analysis (CauCA). CauCA can be viewed as a generalization of ICA, modelling the causal dependence among the latent components, and as a special case of CRL. In contrast to CRL, it presupposes knowledge of the causal graph, focusing solely on learning the unmixing function and the causal mechanisms. Any impossibility results regarding the recovery of the ground truth in CauCA also apply for CRL, while possibility results may serve as a stepping stone for extensions to CRL. We characterize CauCA identifiability from multiple datasets generated through different types of interventions on the latent causal variables. As a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#38024;&#23545;&#20302;&#31209;&#30697;&#38453;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#22312;&#20445;&#35777;&#26497;&#23567;&#26497;&#20540;&#20248;&#21270;&#24615;&#33021;&#30340;&#21516;&#26102;&#65292;&#35299;&#20915;&#20102;&#38750;&#20984;&#26799;&#24230;&#19979;&#38477;&#25910;&#25947;&#32531;&#24930;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.17224</link><description>&lt;p&gt;
&#38750;&#20984;&#26799;&#24230;&#19979;&#38477;&#27861;&#24555;&#36895;&#26497;&#23567;&#21270;&#20302;&#31209;&#30697;&#38453;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Fast and Minimax Optimal Estimation of Low-Rank Matrices via Non-Convex Gradient Descent. (arXiv:2305.17224v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17224
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#38024;&#23545;&#20302;&#31209;&#30697;&#38453;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#22312;&#20445;&#35777;&#26497;&#23567;&#26497;&#20540;&#20248;&#21270;&#24615;&#33021;&#30340;&#21516;&#26102;&#65292;&#35299;&#20915;&#20102;&#38750;&#20984;&#26799;&#24230;&#19979;&#38477;&#25910;&#25947;&#32531;&#24930;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#22122;&#22768;&#27979;&#37327;&#20013;&#20272;&#35745;&#20302;&#31209;&#30697;&#38453;&#30340;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#26088;&#22312;&#23454;&#29616;&#26497;&#23567;&#26497;&#20540;&#35823;&#24046;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#30001;&#20110;&#38750;&#20984;&#26799;&#24230;&#19979;&#38477;&#30340;&#33021;&#21147;&#21487;&#20197;&#25193;&#23637;&#21040;&#22823;&#35268;&#27169;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#65292;&#36825;&#20010;&#38382;&#39064;&#36890;&#24120;&#20351;&#29992;&#38750;&#20984;&#26799;&#24230;&#19979;&#38477;&#26469;&#35299;&#20915;&#12290;&#29702;&#35770;&#19978;&#65292;&#38750;&#20984;&#26799;&#24230;&#19979;&#38477;&#33021;&#22815;&#23454;&#29616;&#26497;&#23567;&#26497;&#20540;&#35823;&#24046;&#12290;&#20294;&#22312;&#23454;&#36341;&#20013;&#65292;&#23427;&#32463;&#24120;&#25910;&#25947;&#24471;&#38750;&#24120;&#32531;&#24930;&#65292;&#20197;&#33267;&#20110;&#29978;&#33267;&#26080;&#27861;&#22312;&#21512;&#29702;&#30340;&#26102;&#38388;&#20869;&#25552;&#20379;&#36866;&#24230;&#20934;&#30830;&#30340;&#20272;&#35745;&#20540;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#36890;&#36807;&#37325;&#26032;&#32553;&#25918;&#25110;&#39044;&#22788;&#29702;&#25913;&#36827;&#38750;&#20984;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#26041;&#27861;&#20063;&#20250;&#22823;&#22823;&#25918;&#22823;&#27979;&#37327;&#35823;&#24046;&#65292;&#23548;&#33268;&#24471;&#21040;&#30340;&#20272;&#35745;&#27604;&#29702;&#35770;&#19978;&#21487;&#23454;&#29616;&#30340;&#26497;&#23567;&#26497;&#20540;&#35823;&#24046;&#23569;&#20960;&#20010;&#25968;&#37327;&#32423;&#30340;&#20934;&#30830;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#36890;&#24120;&#30340;&#38750;&#20984;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#36827;&#34892;&#36731;&#24494;&#20462;&#25913;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#25910;&#25947;&#32531;&#24930;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#21487;&#35777;&#26126;&#20445;&#30041;&#20854;&#26497;&#23567;&#26497;&#20540;&#20248;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of estimating a low-rank matrix from noisy measurements, with the specific goal of achieving minimax optimal error. In practice, the problem is commonly solved using non-convex gradient descent, due to its ability to scale to large-scale real-world datasets. In theory, non-convex gradient descent is capable of achieving minimax error. But in practice, it often converges extremely slowly, such that it cannot even deliver estimations of modest accuracy within reasonable time. On the other hand, methods that improve the convergence of non-convex gradient descent, through rescaling or preconditioning, also greatly amplify the measurement noise, resulting in estimations that are orders of magnitude less accurate than what is theoretically achievable with minimax optimal error. In this paper, we propose a slight modification to the usual non-convex gradient descent method that remedies the issue of slow convergence, while provably preserving its minimax optimality. Our p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#21151;&#33021;&#27969;&#21305;&#37197;&#65288;FFM&#65289;&#30340;&#20989;&#25968;&#31354;&#38388;&#29983;&#25104;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21033;&#29992;&#27010;&#29575;&#27979;&#24230;&#25554;&#20540;&#21644;&#23398;&#20064;&#24213;&#23618;&#20989;&#25968;&#31354;&#38388;&#19978;&#29983;&#25104;&#27979;&#24230;&#30340;&#21521;&#37327;&#22330;&#26469;&#29983;&#25104;&#25968;&#25454;&#20998;&#24067;&#12290;&#36825;&#31181;&#26080;&#38656;&#20284;&#28982;&#25110;&#27169;&#25311;&#30340;&#26041;&#27861;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#65292;&#20248;&#20110;&#26368;&#36817;&#25552;&#20986;&#30340;&#20960;&#31181;&#20989;&#25968;&#31354;&#38388;&#29983;&#25104;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2305.17209</link><description>&lt;p&gt;
&#21151;&#33021;&#27969;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Functional Flow Matching. (arXiv:2305.17209v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17209
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#21151;&#33021;&#27969;&#21305;&#37197;&#65288;FFM&#65289;&#30340;&#20989;&#25968;&#31354;&#38388;&#29983;&#25104;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21033;&#29992;&#27010;&#29575;&#27979;&#24230;&#25554;&#20540;&#21644;&#23398;&#20064;&#24213;&#23618;&#20989;&#25968;&#31354;&#38388;&#19978;&#29983;&#25104;&#27979;&#24230;&#30340;&#21521;&#37327;&#22330;&#26469;&#29983;&#25104;&#25968;&#25454;&#20998;&#24067;&#12290;&#36825;&#31181;&#26080;&#38656;&#20284;&#28982;&#25110;&#27169;&#25311;&#30340;&#26041;&#27861;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#65292;&#20248;&#20110;&#26368;&#36817;&#25552;&#20986;&#30340;&#20960;&#31181;&#20989;&#25968;&#31354;&#38388;&#29983;&#25104;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21151;&#33021;&#27969;&#21305;&#37197;&#65288;Functional Flow Matching, FFM&#65289;&#30340;&#20989;&#25968;&#31354;&#38388;&#29983;&#25104;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#23558;&#26368;&#36817;&#24341;&#20837;&#30340;&#27969;&#21305;&#37197;&#65288;Flow Matching&#65289;&#30452;&#25509;&#25512;&#24191;&#21040;&#26080;&#38480;&#32500;&#31354;&#38388;&#20013;&#36827;&#34892;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#39318;&#20808;&#23450;&#20041;&#20102;&#19968;&#32452;&#27010;&#29575;&#27979;&#24230;&#36335;&#24452;&#65292;&#22312;&#22266;&#23450;&#30340;&#39640;&#26031;&#27979;&#24230;&#21644;&#25968;&#25454;&#20998;&#24067;&#20043;&#38388;&#36827;&#34892;&#25554;&#20540;&#65292;&#28982;&#21518;&#23398;&#20064;&#20989;&#25968;&#30340;&#24213;&#23618;&#31354;&#38388;&#19978;&#29983;&#25104;&#27492;&#27979;&#24230;&#36335;&#24452;&#30340;&#21521;&#37327;&#22330;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#20381;&#36182;&#20110;&#20284;&#28982;&#25110;&#27169;&#25311;&#65292;&#22240;&#27492;&#38750;&#24120;&#36866;&#21512;&#20989;&#25968;&#31354;&#38388;&#30340;&#35774;&#32622;&#12290;&#25105;&#20204;&#19981;&#20165;&#25552;&#20379;&#26500;&#24314;&#36825;&#31181;&#27169;&#22411;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#36824;&#23545;&#25105;&#20204;&#30340;&#25216;&#26415;&#36827;&#34892;&#20102;&#32463;&#39564;&#35780;&#20272;&#12290;&#36890;&#36807;&#23545;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#22522;&#20934;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;FFM&#26041;&#27861;&#20248;&#20110;&#26368;&#36817;&#25552;&#20986;&#30340;&#20960;&#31181;&#20989;&#25968;&#31354;&#38388;&#29983;&#25104;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we propose Functional Flow Matching (FFM), a function-space generative model that generalizes the recently-introduced Flow Matching model to operate directly in infinite-dimensional spaces. Our approach works by first defining a path of probability measures that interpolates between a fixed Gaussian measure and the data distribution, followed by learning a vector field on the underlying space of functions that generates this path of measures. Our method does not rely on likelihoods or simulations, making it well-suited to the function space setting. We provide both a theoretical framework for building such models and an empirical evaluation of our techniques. We demonstrate through experiments on synthetic and real-world benchmarks that our proposed FFM method outperforms several recently proposed function-space generative models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#21521;&#37327;&#20540;&#38543;&#26426;&#29305;&#24449;&#23398;&#20064;&#30340;&#23436;&#25972;&#35823;&#24046;&#20998;&#26512;&#65292;&#21253;&#25324;&#22312;&#27169;&#22411;&#38169;&#35823;&#35828;&#26126;&#19979;&#21521;&#37327;&#20540;RF&#20272;&#35745;&#22120;&#30340;&#24378;&#19968;&#33268;&#24615;&#21644;&#22312;&#33391;&#22909;&#35268;&#23450;&#30340;&#24773;&#20917;&#19979;&#26497;&#23567;&#21270;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2305.17170</link><description>&lt;p&gt;
&#21521;&#37327;&#20540;&#38543;&#26426;&#29305;&#24449;&#23398;&#20064;&#30340;&#35823;&#24046;&#30028;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Error Bounds for Learning with Vector-Valued Random Features. (arXiv:2305.17170v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17170
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#21521;&#37327;&#20540;&#38543;&#26426;&#29305;&#24449;&#23398;&#20064;&#30340;&#23436;&#25972;&#35823;&#24046;&#20998;&#26512;&#65292;&#21253;&#25324;&#22312;&#27169;&#22411;&#38169;&#35823;&#35828;&#26126;&#19979;&#21521;&#37327;&#20540;RF&#20272;&#35745;&#22120;&#30340;&#24378;&#19968;&#33268;&#24615;&#21644;&#22312;&#33391;&#22909;&#35268;&#23450;&#30340;&#24773;&#20917;&#19979;&#26497;&#23567;&#21270;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#20110;&#21521;&#37327;&#20540;&#38543;&#26426;&#29305;&#24449;&#23398;&#20064;&#30340;&#23436;&#25972;&#35823;&#24046;&#20998;&#26512;&#12290;&#35813;&#29702;&#35770;&#26159;&#38024;&#23545;&#23436;&#20840;&#36890;&#29992;&#30340;&#26080;&#38480;&#32500;&#24230;&#36755;&#20837;-&#36755;&#20986;&#35774;&#23450;&#20013;&#30340;RF Ridge&#22238;&#24402;&#32780;&#24320;&#21457;&#30340;&#65292;&#20294;&#20173;&#36866;&#29992;&#20110;&#24182;&#25913;&#36827;&#20102;&#29616;&#26377;&#30340;&#26377;&#38480;&#32500;&#24230;&#20998;&#26512;&#12290;&#19982;&#25991;&#29486;&#20013;&#20854;&#20182;&#31867;&#20284;&#30340;&#24037;&#20316;&#30456;&#27604;&#65292;&#26412;&#25991;&#25552;&#20986;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#24213;&#23618;&#39118;&#38505;&#20989;&#25968;&#30340;&#30452;&#25509;&#20998;&#26512;&#65292;&#23436;&#20840;&#36991;&#20813;&#20102;&#22522;&#20110;&#38543;&#26426;&#30697;&#38453;&#30340;&#26174;&#24335;RF Ridge&#22238;&#24402;&#35299;&#20915;&#26041;&#26696;&#20844;&#24335;&#30340;&#20351;&#29992;&#12290;&#36825;&#28040;&#38500;&#20102;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#20013;&#30340;&#27987;&#24230;&#32467;&#26524;&#25110;&#20854;&#23545;&#38543;&#26426;&#31639;&#23376;&#30340;&#25512;&#24191;&#30340;&#38656;&#27714;&#12290;&#26412;&#25991;&#24314;&#31435;&#30340;&#20027;&#35201;&#32467;&#26524;&#21253;&#25324;&#22312;&#27169;&#22411;&#38169;&#35823;&#35828;&#26126;&#19979;&#21521;&#37327;&#20540;RF&#20272;&#35745;&#22120;&#30340;&#24378;&#19968;&#33268;&#24615;&#21644;&#22312;&#33391;&#22909;&#35268;&#23450;&#30340;&#24773;&#20917;&#19979;&#26497;&#23567;&#21270;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;&#23454;&#29616;&#36825;&#20123;&#25910;&#25947;&#36895;&#29575;&#25152;&#38656;&#30340;&#21442;&#25968;&#22797;&#26434;&#24230;(&#38543;&#26426;&#29305;&#24449;&#25968;&#37327;)&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;(&#26631;&#35760;&#25968;&#25454;&#25968;&#37327;)&#19982;
&lt;/p&gt;
&lt;p&gt;
This paper provides a comprehensive error analysis of learning with vector-valued random features (RF). The theory is developed for RF ridge regression in a fully general infinite-dimensional input-output setting, but nonetheless applies to and improves existing finite-dimensional analyses. In contrast to comparable work in the literature, the approach proposed here relies on a direct analysis of the underlying risk functional and completely avoids the explicit RF ridge regression solution formula in terms of random matrices. This removes the need for concentration results in random matrix theory or their generalizations to random operators. The main results established in this paper include strong consistency of vector-valued RF estimators under model misspecification and minimax optimal convergence rates in the well-specified setting. The parameter complexity (number of random features) and sample complexity (number of labeled data) required to achieve such rates are comparable with 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#26377;&#30028;&#23485;&#24230;&#21644;&#20219;&#24847;&#28145;&#24230;&#30340;&#22797;&#20540;&#31070;&#32463;&#32593;&#32476;&#30340;&#26222;&#36866;&#24615;&#65292;&#21457;&#29616;&#24403;&#19988;&#20165;&#24403;&#28608;&#27963;&#20989;&#25968;&#26082;&#19981;&#26159;&#20840;&#32431;&#30340;&#65292;&#20063;&#19981;&#26159;&#21453;&#20840;&#32431;&#30340;&#65292;&#20063;&#19981;&#26159; $\mathbb{R}$-&#20223;&#23556;&#30340;&#26102;&#65292;&#28145;&#31364;&#30340;&#22797;&#20540;&#32593;&#32476;&#20855;&#26377;&#26222;&#36866;&#36924;&#36817;&#33021;&#21147;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#36275;&#22815;&#30340;&#23485;&#24230;&#20381;&#36182;&#20110;&#32771;&#34385;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#23545;&#20110;&#19968;&#31867;&#21487;&#20801;&#35768;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#23485;&#24230;&#20026; $n+m+4$ &#26159;&#36275;&#22815;&#30340;&#12290;</title><link>http://arxiv.org/abs/2305.16910</link><description>&lt;p&gt;
&#24102;&#26377;&#22797;&#20540;&#30340;&#28145;&#31364;&#31070;&#32463;&#32593;&#32476;&#30340;&#26222;&#36866;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Universal approximation with complex-valued deep narrow neural networks. (arXiv:2305.16910v1 [math.FA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16910
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#26377;&#30028;&#23485;&#24230;&#21644;&#20219;&#24847;&#28145;&#24230;&#30340;&#22797;&#20540;&#31070;&#32463;&#32593;&#32476;&#30340;&#26222;&#36866;&#24615;&#65292;&#21457;&#29616;&#24403;&#19988;&#20165;&#24403;&#28608;&#27963;&#20989;&#25968;&#26082;&#19981;&#26159;&#20840;&#32431;&#30340;&#65292;&#20063;&#19981;&#26159;&#21453;&#20840;&#32431;&#30340;&#65292;&#20063;&#19981;&#26159; $\mathbb{R}$-&#20223;&#23556;&#30340;&#26102;&#65292;&#28145;&#31364;&#30340;&#22797;&#20540;&#32593;&#32476;&#20855;&#26377;&#26222;&#36866;&#36924;&#36817;&#33021;&#21147;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#36275;&#22815;&#30340;&#23485;&#24230;&#20381;&#36182;&#20110;&#32771;&#34385;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#23545;&#20110;&#19968;&#31867;&#21487;&#20801;&#35768;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#23485;&#24230;&#20026; $n+m+4$ &#26159;&#36275;&#22815;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#26377;&#30028;&#23485;&#24230;&#21644;&#20219;&#24847;&#28145;&#24230;&#30340;&#22797;&#20540;&#31070;&#32463;&#32593;&#32476;&#30340;&#26222;&#36866;&#24615;&#12290;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#37027;&#20123;&#28608;&#27963;&#20989;&#25968; $\varrho:\mathbb{CC}\to \mathbb{C}$ &#30340;&#23436;&#25972;&#25551;&#36848;&#65292;&#36825;&#20123;&#20989;&#25968;&#20855;&#26377;&#36825;&#26679;&#19968;&#20010;&#23646;&#24615;&#65306;&#23427;&#20204;&#20851;&#32852;&#30340;&#32593;&#32476;&#26159;&#26222;&#36866;&#30340;&#65292;&#21363;&#33021;&#22815;&#22312;&#32039;&#33268;&#22495;&#19978;&#36924;&#36817;&#36830;&#32493;&#20989;&#25968;&#33267;&#20219;&#24847;&#31934;&#24230;&#12290;&#20934;&#30830;&#22320;&#35828;&#65292;&#25105;&#20204;&#34920;&#26126;&#20102;&#24403;&#19988;&#20165;&#24403;&#23427;&#20204;&#30340;&#28608;&#27963;&#20989;&#25968;&#26082;&#19981;&#26159;&#20840;&#32431;&#30340;&#65292;&#20063;&#19981;&#26159;&#21453;&#20840;&#32431;&#30340;&#65292;&#20063;&#19981;&#26159; $\mathbb{R}$-&#20223;&#23556;&#30340;&#65292;&#28145;&#31364;&#30340;&#22797;&#20540;&#32593;&#32476;&#26159;&#26222;&#36866;&#30340;&#12290;&#36825;&#26159;&#19968;&#20010;&#27604;&#23485;&#24230;&#20219;&#24847;&#12289;&#28145;&#24230;&#22266;&#23450;&#30340;&#23545;&#20598;&#35774;&#32622;&#20013;&#26356;&#22823;&#30340;&#20989;&#25968;&#31867;&#12290;&#19982;&#23454;&#20540;&#24773;&#20917;&#19981;&#21516;&#30340;&#26159;&#65292;&#36275;&#22815;&#30340;&#23485;&#24230;&#20381;&#36182;&#20110;&#32771;&#34385;&#30340;&#28608;&#27963;&#20989;&#25968;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#23485;&#24230;&#20026; $2n+2m+5$ &#24635;&#26159;&#36275;&#22815;&#30340;&#65292;&#24182;&#19988;&#36890;&#24120; $\max\{2n,2m\}$ &#26159;&#24517;&#35201;&#30340;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#19968;&#31867;&#21487;&#20801;&#35768;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#23485;&#24230;&#20026; $n+m+4$ &#26159;&#36275;&#22815;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the universality of complex-valued neural networks with bounded widths and arbitrary depths. Under mild assumptions, we give a full description of those activation functions $\varrho:\mathbb{CC}\to \mathbb{C}$ that have the property that their associated networks are universal, i.e., are capable of approximating continuous functions to arbitrary accuracy on compact domains. Precisely, we show that deep narrow complex-valued networks are universal if and only if their activation function is neither holomorphic, nor antiholomorphic, nor $\mathbb{R}$-affine. This is a much larger class of functions than in the dual setting of arbitrary width and fixed depth. Unlike in the real case, the sufficient width differs significantly depending on the considered activation function. We show that a width of $2n+2m+5$ is always sufficient and that in general a width of $\max\{2n,2m\}$ is necessary. We prove, however, that a width of $n+m+4$ suffices for a rich subclass of the admissible acti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#31070;&#32463;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#36827;&#34892;&#30417;&#30563;&#23398;&#20064;&#30340;&#27867;&#21270;&#33021;&#21147;&#38382;&#39064;&#65292;&#36890;&#36807;&#37327;&#21270;&#31163;&#25955;&#21270;&#20559;&#24046;&#21644;&#21033;&#26222;&#24076;&#33576;&#20989;&#25968;&#36924;&#36817;&#35823;&#24046;&#65292;&#24471;&#21040;&#20102;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#22120;&#19982;&#36125;&#21494;&#26031;&#26368;&#20248;&#39118;&#38505;&#30340;&#27867;&#21270;&#24046;&#36317;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2305.16791</link><description>&lt;p&gt;
&#31070;&#32463;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#30340;&#27867;&#21270;&#33021;&#21147;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Generalization Capacities of Neural Controlled Differential Equations. (arXiv:2305.16791v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16791
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#31070;&#32463;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#36827;&#34892;&#30417;&#30563;&#23398;&#20064;&#30340;&#27867;&#21270;&#33021;&#21147;&#38382;&#39064;&#65292;&#36890;&#36807;&#37327;&#21270;&#31163;&#25955;&#21270;&#20559;&#24046;&#21644;&#21033;&#26222;&#24076;&#33576;&#20989;&#25968;&#36924;&#36817;&#35823;&#24046;&#65292;&#24471;&#21040;&#20102;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#22120;&#19982;&#36125;&#21494;&#26031;&#26368;&#20248;&#39118;&#38505;&#30340;&#27867;&#21270;&#24046;&#36317;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#31070;&#32463;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#65288;Kidger&#65292;Morrill&#31561;&#65292;2020&#65289;&#20174;&#19981;&#35268;&#21017;&#37319;&#26679;&#30340;&#26102;&#38388;&#24207;&#21015;&#26679;&#26412;&#20013;&#39044;&#27979;&#32467;&#26524;&#30340;&#30417;&#30563;&#23398;&#20064;&#35774;&#32622;&#12290;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#65292;&#26102;&#38388;&#24207;&#21015;&#26159;&#19968;&#20010;&#26410;&#35266;&#23519;&#21040;&#30340;&#36830;&#32493;&#36335;&#24452;&#30340;&#31163;&#25955;&#21270;&#65292;&#32467;&#26524;&#36890;&#36807;&#19968;&#20010;&#20855;&#26377;&#26410;&#30693;&#21521;&#37327;&#22330;&#30340;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#20381;&#36182;&#20110;&#36825;&#20010;&#36335;&#24452;&#12290;&#20351;&#29992;&#31163;&#25955;&#25968;&#25454;&#36827;&#34892;&#23398;&#20064;&#20250;&#24341;&#20837;&#31163;&#25955;&#20559;&#24046;&#65292;&#25105;&#20204;&#31934;&#30830;&#22320;&#37327;&#21270;&#20102;&#36825;&#31181;&#20559;&#24046;&#12290;&#36890;&#36807;&#20351;&#29992;&#20851;&#20110;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#27969;&#30340;&#36830;&#32493;&#24615;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36924;&#36817;&#20559;&#24046;&#30452;&#25509;&#19982;&#30001;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#23450;&#20041;&#29983;&#25104;&#27169;&#22411;&#30340;&#21033;&#26222;&#24076;&#33576;&#20989;&#25968;&#30340;&#36924;&#36817;&#35823;&#24046;&#30456;&#20851;&#12290;&#36890;&#36807;&#32467;&#21512;&#26368;&#36817;&#30340;&#24037;&#20316;&#23558;&#31070;&#32463;&#32593;&#32476;&#30340;&#21033;&#26222;&#24076;&#33576;&#24120;&#25968;&#19982;&#20854;&#27867;&#21270;&#33021;&#21147;&#32852;&#31995;&#36215;&#26469;&#65292;&#25105;&#20204;&#19978;&#30028;&#20102;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#22120;&#36798;&#21040;&#30340;&#26399;&#26395;&#25439;&#22833;&#19982;&#36125;&#21494;&#26031;&#26368;&#20248;&#39118;&#38505;&#20043;&#38388;&#30340;&#27867;&#21270;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a supervised learning setup in which the goal is to predicts an outcome from a sample of irregularly sampled time series using Neural Controlled Differential Equations (Kidger, Morrill, et al. 2020). In our framework, the time series is a discretization of an unobserved continuous path, and the outcome depends on this path through a controlled differential equation with unknown vector field. Learning with discrete data thus induces a discretization bias, which we precisely quantify. Using theoretical results on the continuity of the flow of controlled differential equations, we show that the approximation bias is directly related to the approximation error of a Lipschitz function defining the generative model by a shallow neural network. By combining these result with recent work linking the Lipschitz constant of neural networks to their generalization capacities, we upper bound the generalization gap between the expected loss attained by the empirical risk minimizer and th
&lt;/p&gt;</description></item><item><title>&#23545;&#27604;&#23398;&#20064;&#26159;&#19968;&#31181;&#34920;&#31034;&#23398;&#20064;&#25216;&#26415;&#65292;&#23545;&#20110;&#26377;&#30417;&#30563;&#30340;&#24773;&#20917;&#26131;&#20110;&#20135;&#29983;&#31867;&#22349;&#22604;&#65292;&#26080;&#30417;&#30563;&#24773;&#20917;&#19979;&#26131;&#20110;&#25233;&#21046;&#31867;&#21035;&#30456;&#20851;&#30340;&#22797;&#26434;&#29305;&#24449;&#65307;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#20559;&#21521;&#20110;&#23547;&#25214;&#26356;&#31616;&#21333;&#30340;&#35299;&#20915;&#26041;&#26696;&#26159;&#23548;&#33268;&#36825;&#31181;&#29616;&#35937;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;</title><link>http://arxiv.org/abs/2305.16536</link><description>&lt;p&gt;
&#23545;&#27604;&#23398;&#20064;&#23398;&#21040;&#20102;&#21738;&#20123;&#29305;&#24449;&#65311;&#20851;&#20110;&#31616;&#26131;&#20559;&#24046;&#22312;&#31867;&#22349;&#22604;&#21644;&#29305;&#24449;&#25233;&#21046;&#20013;&#30340;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Which Features are Learnt by Contrastive Learning? On the Role of Simplicity Bias in Class Collapse and Feature Suppression. (arXiv:2305.16536v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16536
&lt;/p&gt;
&lt;p&gt;
&#23545;&#27604;&#23398;&#20064;&#26159;&#19968;&#31181;&#34920;&#31034;&#23398;&#20064;&#25216;&#26415;&#65292;&#23545;&#20110;&#26377;&#30417;&#30563;&#30340;&#24773;&#20917;&#26131;&#20110;&#20135;&#29983;&#31867;&#22349;&#22604;&#65292;&#26080;&#30417;&#30563;&#24773;&#20917;&#19979;&#26131;&#20110;&#25233;&#21046;&#31867;&#21035;&#30456;&#20851;&#30340;&#22797;&#26434;&#29305;&#24449;&#65307;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#20559;&#21521;&#20110;&#23547;&#25214;&#26356;&#31616;&#21333;&#30340;&#35299;&#20915;&#26041;&#26696;&#26159;&#23548;&#33268;&#36825;&#31181;&#29616;&#35937;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#27604;&#23398;&#20064;&#20855;&#22791;&#26080;&#30417;&#30563;&#21644;&#26377;&#30417;&#30563;&#23398;&#20064;&#30340;&#34920;&#31034;&#23398;&#20064;&#25216;&#26415;&#65292;&#22312;&#26377;&#30417;&#30563;&#22330;&#26223;&#19979;&#26131;&#20110;&#22349;&#22604;&#21516;&#19968;&#31867;&#21035;&#20869;&#30340;&#23376;&#31867;&#34920;&#31034;&#65292;&#20002;&#22833;&#19968;&#37096;&#20998;&#29305;&#24449;&#20449;&#24687;&#65307;&#32780;&#26080;&#30417;&#30563;&#23398;&#20064;&#21017;&#21487;&#33021;&#36890;&#36807;&#23398;&#20064;&#26131;&#20110;&#22788;&#29702;&#30340;&#31867;&#21035;&#26080;&#20851;&#29305;&#24449;&#32780;&#26080;&#35270;&#19968;&#20123;&#31867;&#21035;&#30456;&#20851;&#30340;&#22797;&#26434;&#29305;&#24449;&#20449;&#24687;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#20250;&#26174;&#33879;&#22320;&#38477;&#20302;&#34920;&#24449;&#30340;&#36136;&#37327;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#32479;&#19968;&#20005;&#35880;&#30340;&#26694;&#26550;&#26469;&#29702;&#35299;&#27979;&#35797;&#26102;&#30340;&#31867;&#22349;&#22604;&#21644;&#29305;&#24449;&#25233;&#21046;&#20135;&#29983;&#30340;&#21407;&#22240;&#65292;&#30456;&#20851;&#20998;&#26512;&#34920;&#26126;&#65292;&#65288;&#38543;&#26426;&#65289;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#20559;&#21521;&#20110;&#23547;&#25214;&#26356;&#31616;&#21333;&#30340;&#35299;&#20915;&#26041;&#26696;&#26159;&#23548;&#33268;&#23376;&#31867;&#34920;&#31034;&#22349;&#22604;&#21644;&#31867;&#21035;&#30456;&#20851;&#30340;&#22797;&#26434;&#29305;&#24449;&#34987;&#25233;&#21046;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21033;&#29992;&#25552;&#39640;&#23884;&#20837;&#32500;&#24230;&#21644;&#25913;&#36827;&#25968;&#25454;&#22686;&#24378;&#30340;&#26041;&#27861;&#26469;&#25552;&#20379;&#26377;&#25928;&#30340;&#39044;&#38450;&#25514;&#26045;&#12290;
&lt;/p&gt;
&lt;p&gt;
Contrastive learning (CL) has emerged as a powerful technique for representation learning, with or without label supervision. However, supervised CL is prone to collapsing representations of subclasses within a class by not capturing all their features, and unsupervised CL may suppress harder class-relevant features by focusing on learning easy class-irrelevant features; both significantly compromise representation quality. Yet, there is no theoretical understanding of \textit{class collapse} or \textit{feature suppression} at \textit{test} time. We provide the first unified theoretically rigorous framework to determine \textit{which} features are learnt by CL. Our analysis indicate that, perhaps surprisingly, bias of (stochastic) gradient descent towards finding simpler solutions is a key factor in collapsing subclass representations and suppressing harder class-relevant features. Moreover, we present increasing embedding dimensionality and improving the quality of data augmentations 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21518;&#22788;&#29702;&#33021;&#35265;&#24230;&#38598;&#21512;&#39044;&#27979;&#30340;&#19981;&#21516;&#26041;&#27861;&#65292;&#21457;&#29616;&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#21644;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#26041;&#27861;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#19988;&#21487;&#20197;&#26174;&#30528;&#25552;&#39640;&#38598;&#21512;&#39044;&#27979;&#30340;&#25216;&#33021;&#21644;&#21487;&#38752;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.15325</link><description>&lt;p&gt;
&#33021;&#35265;&#24230;&#38598;&#21512;&#39044;&#27979;&#30340;&#32479;&#35745;&#21518;&#22788;&#29702;
&lt;/p&gt;
&lt;p&gt;
Statistical post-processing of visibility ensemble forecasts. (arXiv:2305.15325v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15325
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21518;&#22788;&#29702;&#33021;&#35265;&#24230;&#38598;&#21512;&#39044;&#27979;&#30340;&#19981;&#21516;&#26041;&#27861;&#65292;&#21457;&#29616;&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#21644;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#26041;&#27861;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#19988;&#21487;&#20197;&#26174;&#30528;&#25552;&#39640;&#38598;&#21512;&#39044;&#27979;&#30340;&#25216;&#33021;&#21644;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#22815;&#20934;&#30830;&#21487;&#38752;&#22320;&#39044;&#27979;&#33021;&#35265;&#24230;&#23545;&#20110;&#39134;&#34892;&#27668;&#35937;&#65292;&#27700;&#36335;&#21644;&#36947;&#36335;&#36816;&#36755;&#20855;&#26377;&#33267;&#20851;&#37325;&#35201;&#30340;&#24847;&#20041;&#12290;&#29616;&#20170;&#65292;&#19968;&#20123;&#27668;&#35937;&#26381;&#21153;&#25552;&#20379;&#33021;&#35265;&#24230;&#30340;&#38598;&#21512;&#39044;&#27979;; &#28982;&#32780;&#65292;&#30456;&#27604;&#20110;&#20854;&#20182;&#21464;&#37327;&#65288;&#22914;&#28201;&#24230;&#25110;&#39118;&#36895;&#65289;&#65292;&#33021;&#35265;&#24230;&#39044;&#27979;&#30340;&#25216;&#33021;&#21644;&#21487;&#38752;&#24615;&#38477;&#20302;&#24456;&#22810;&#12290;&#22240;&#27492;&#65292;&#24378;&#28872;&#24314;&#35758;&#37319;&#29992;&#26576;&#31181;&#24418;&#24335;&#30340;&#26657;&#20934;&#65292;&#36890;&#24120;&#24847;&#21619;&#30528;&#36890;&#36807;&#21442;&#25968;&#25110;&#38750;&#21442;&#25968;&#26041;&#27861;&#65288;&#21253;&#25324;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#25216;&#26415;&#65289;&#20272;&#35745;&#25152;&#28041;&#21450;&#30340;&#22825;&#27668;&#25968;&#37327;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;&#30001;&#20110;&#26681;&#25454;&#19990;&#30028;&#27668;&#35937;&#32452;&#32455;&#30340;&#24314;&#35758;&#65292;&#36890;&#24120;&#20197;&#31163;&#25955;&#20540;&#25253;&#21578;&#33021;&#35265;&#24230;&#35266;&#27979;&#20540;&#65292;&#22240;&#27492;&#35813;&#29305;&#23450;&#21464;&#37327;&#30340;&#39044;&#27979;&#20998;&#24067;&#26159;&#31163;&#25955;&#27010;&#29575;&#20998;&#24067;&#65292;&#22240;&#27492;&#26657;&#20934;&#21487;&#20197;&#31616;&#21270;&#20026;&#20998;&#31867;&#38382;&#39064;&#12290;&#22522;&#20110;&#27431;&#27954;&#20013;&#26399;&#22825;&#27668;&#39044;&#25253;&#20013;&#24515;&#30340;&#33021;&#35265;&#24230;&#38598;&#21512;&#39044;&#27979;&#65288;ECMWF&#65289;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19981;&#21516;&#30340;&#26041;&#27861;&#29992;&#20110;&#21518;&#22788;&#29702;&#33021;&#35265;&#24230;&#27010;&#29575;&#39044;&#27979;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#34920;&#26126;&#65292;&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#21644;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#26041;&#27861;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#19988;&#21487;&#20197;&#26174;&#30528;&#25552;&#39640;&#38598;&#21512;&#39044;&#27979;&#30340;&#25216;&#33021;&#21644;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
To be able to produce accurate and reliable predictions of visibility has crucial importance in aviation meteorology, as well as in water- and road transportation. Nowadays, several meteorological services provide ensemble forecasts of visibility; however, the skill, and reliability of visibility predictions are far reduced compared to other variables, such as temperature or wind speed. Hence, some form of calibration is strongly advised, which usually means estimation of the predictive distribution of the weather quantity at hand either by parametric or non-parametric approaches, including also machine learning-based techniques. As visibility observations - according to the suggestion of the World Meteorological Organization - are usually reported in discrete values, the predictive distribution for this particular variable is a discrete probability law, hence calibration can be reduced to a classification problem. Based on visibility ensemble forecasts of the European Centre for Mediu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#25216;&#26415;&#65292;&#36890;&#36807;&#36125;&#21494;&#26031;&#26041;&#27861;&#23558;&#36755;&#20837;&#25968;&#25454;&#30340;&#19981;&#30830;&#23450;&#24615;&#32435;&#20837;&#22238;&#24402;&#27169;&#22411;&#39044;&#27979;&#20013;&#12290;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#20855;&#26377;&#26222;&#36866;&#24615;&#21644;&#19981;&#38169;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.11586</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#20013;&#34701;&#20837;&#19981;&#30830;&#23450;&#36755;&#20837;
&lt;/p&gt;
&lt;p&gt;
Bayesian approach to Gaussian process regression with uncertain inputs. (arXiv:2305.11586v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11586
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#25216;&#26415;&#65292;&#36890;&#36807;&#36125;&#21494;&#26031;&#26041;&#27861;&#23558;&#36755;&#20837;&#25968;&#25454;&#30340;&#19981;&#30830;&#23450;&#24615;&#32435;&#20837;&#22238;&#24402;&#27169;&#22411;&#39044;&#27979;&#20013;&#12290;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#20855;&#26377;&#26222;&#36866;&#24615;&#21644;&#19981;&#38169;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#20165;&#20551;&#35774;&#27169;&#22411;&#35266;&#27979;&#25968;&#25454;&#30340;&#36755;&#20986;&#20855;&#26377;&#22122;&#22768;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#31185;&#23398;&#21644;&#24037;&#31243;&#24212;&#29992;&#20013;&#65292;&#30001;&#20110;&#24314;&#27169;&#20551;&#35774;&#12289;&#27979;&#37327;&#35823;&#24046;&#31561;&#22240;&#32032;&#65292;&#35266;&#27979;&#25968;&#25454;&#30340;&#36755;&#20837;&#20301;&#32622;&#21487;&#33021;&#20063;&#23384;&#22312;&#19981;&#30830;&#23450;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#23558;&#36755;&#20837;&#25968;&#25454;&#30340;&#21487;&#21464;&#24615;&#34701;&#20837;&#21040;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#20013;&#12290;&#32771;&#34385;&#20004;&#31181;&#21487;&#35266;&#27979;&#37327;&#8212;&#8212;&#20855;&#26377;&#22266;&#23450;&#36755;&#20837;&#30340;&#22122;&#22768;&#27745;&#26579;&#36755;&#20986;&#21644;&#20855;&#26377;&#20808;&#39564;&#20998;&#24067;&#23450;&#20041;&#30340;&#19981;&#30830;&#23450;&#36755;&#20837;&#65292;&#36890;&#36807;&#36125;&#21494;&#26031;&#26694;&#26550;&#20272;&#35745;&#21518;&#39564;&#20998;&#24067;&#20197;&#25512;&#26029;&#19981;&#30830;&#23450;&#30340;&#25968;&#25454;&#20301;&#32622;&#12290;&#28982;&#21518;&#65292;&#21033;&#29992;&#36793;&#38469;&#21270;&#26041;&#27861;&#23558;&#36825;&#20123;&#36755;&#20837;&#30340;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#32435;&#20837;&#39640;&#26031;&#36807;&#31243;&#39044;&#27979;&#20013;&#12290;&#36890;&#36807;&#20960;&#20010;&#25968;&#20540;&#23454;&#39564;&#65292;&#23637;&#31034;&#20102;&#36825;&#31181;&#26032;&#22238;&#24402;&#25216;&#26415;&#30340;&#26377;&#25928;&#24615;&#65292;&#22312;&#20854;&#20013;&#35266;&#23519;&#21040;&#19981;&#21516;&#27700;&#24179;&#36755;&#20837;&#25968;&#25454;&#19981;&#30830;&#23450;&#24615;&#19979;&#30340;&#26222;&#36866;&#33391;&#22909;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conventional Gaussian process regression exclusively assumes the existence of noise in the output data of model observations. In many scientific and engineering applications, however, the input locations of observational data may also be compromised with uncertainties owing to modeling assumptions, measurement errors, etc. In this work, we propose a Bayesian method that integrates the variability of input data into Gaussian process regression. Considering two types of observables -- noise-corrupted outputs with fixed inputs and those with prior-distribution-defined uncertain inputs, a posterior distribution is estimated via a Bayesian framework to infer the uncertain data locations. Thereafter, such quantified uncertainties of inputs are incorporated into Gaussian process predictions by means of marginalization. The effectiveness of this new regression technique is demonstrated through several numerical examples, in which a consistently good performance of generalization is observed, w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#21152;&#26435;&#30340;&#26368;&#23567;&#26497;&#22823;&#39118;&#38505;&#20998;&#31867;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#36991;&#20813;&#21327;&#21464;&#37327;&#28418;&#31227;&#23545;&#30417;&#30563;&#23398;&#20064;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2305.08637</link><description>&lt;p&gt;
&#20026;&#21327;&#21464;&#37327;&#28418;&#31227;&#33258;&#36866;&#24212;&#24341;&#20837;&#21452;&#37325;&#21152;&#26435;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Double-Weighting for Covariate Shift Adaptation. (arXiv:2305.08637v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08637
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#21152;&#26435;&#30340;&#26368;&#23567;&#26497;&#22823;&#39118;&#38505;&#20998;&#31867;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#36991;&#20813;&#21327;&#21464;&#37327;&#28418;&#31227;&#23545;&#30417;&#30563;&#23398;&#20064;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30417;&#30563;&#23398;&#20064;&#20013;&#24120;&#24120;&#21463;&#21040;&#21327;&#21464;&#37327;&#28418;&#31227;&#24433;&#21709;&#65292;&#21363;&#35757;&#32451;&#26679;&#26412;&#21644;&#27979;&#35797;&#26679;&#26412;&#30340;&#23454;&#20363;&#36793;&#32536;&#20998;&#24067;&#19981;&#21516;&#20294;&#26631;&#31614;&#26465;&#20214;&#30456;&#21516;&#12290;&#29616;&#26377;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#27604;&#29575;p_te&#65288;x&#65289;/p_tr&#65288;x&#65289;&#23545;&#35757;&#32451;&#26679;&#26412;&#36827;&#34892;&#21152;&#26435;&#65288;&#37325;&#26032;&#21152;&#26435;&#26041;&#27861;&#65289;&#65292;&#25110;&#32773;&#20351;&#29992;&#27604;&#29575;p_tr&#65288;x&#65289;/p_te&#65288;x&#65289;&#23545;&#27979;&#35797;&#26679;&#26412;&#36827;&#34892;&#21152;&#26435;&#65288;&#40065;&#26834;&#26041;&#27861;&#65289;&#26469;&#35299;&#20915;&#36825;&#31181;&#21327;&#21464;&#37327;&#28418;&#31227;&#12290;&#28982;&#32780;&#65292;&#22312;&#25903;&#25345;&#19981;&#21305;&#37197;&#25110;&#19978;&#36848;&#27604;&#29575;&#21462;&#22823;&#20540;&#26102;&#65292;&#36825;&#20123;&#26041;&#27861;&#30340;&#24615;&#33021;&#21487;&#33021;&#24456;&#24046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#23567;&#26497;&#22823;&#39118;&#38505;&#20998;&#31867;(MRC)&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#35757;&#32451;&#26679;&#26412;&#21644;&#27979;&#35797;&#26679;&#26412;&#36827;&#34892;&#21152;&#26435;&#26469;&#36991;&#20813;&#36825;&#31181;&#38480;&#21046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#26377;&#25928;&#30340;&#25216;&#26415;&#26469;&#33719;&#24471;&#20004;&#32452;&#21152;&#26435;&#65292;&#24182;&#25512;&#24191;&#20102;&#20256;&#32479;&#30340;&#26680;&#22343;&#20540;&#21305;&#37197;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#26032;&#30340;&#29983;&#25104;&#27169;&#22411;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#26469;&#35777;&#26126;&#25105;&#20204;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Supervised learning is often affected by a covariate shift in which the marginal distributions of instances (covariates $x$) of training and testing samples $\mathrm{p}_\text{tr}(x)$ and $\mathrm{p}_\text{te}(x)$ are different but the label conditionals coincide. Existing approaches address such covariate shift by either using the ratio $\mathrm{p}_\text{te}(x)/\mathrm{p}_\text{tr}(x)$ to weight training samples (reweighting methods) or using the ratio $\mathrm{p}_\text{tr}(x)/\mathrm{p}_\text{te}(x)$ to weight testing samples (robust methods). However, the performance of such approaches can be poor under support mismatch or when the above ratios take large values. We propose a minimax risk classification (MRC) approach for covariate shift adaptation that avoids such limitations by weighting both training and testing samples. In addition, we develop effective techniques that obtain both sets of weights and generalize the conventional kernel mean matching method. We provide novel genera
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#22343;&#20540;&#28418;&#31227;&#31639;&#27861;&#30340;&#27169;&#20272;&#35745;&#24207;&#21015;&#30340;&#25910;&#25947;&#20445;&#35777;&#65292;&#24182;&#25193;&#23637;&#20102;&#29616;&#26377;&#30340;&#28085;&#30422;&#35299;&#26512;&#26680;&#21644;Epanechnikov&#26680;&#30340;&#21457;&#29616;&#65292;&#24847;&#20041;&#22312;&#20110;&#28085;&#30422;&#20102;&#22312;&#22522;&#20110;KDE&#30340;&#27169;&#20272;&#35745;&#30340;&#28176;&#36817;&#32479;&#35745;&#25928;&#29575;&#26041;&#38754;&#26368;&#20248;&#30340;&#38750;&#36127;&#26680;&#8212;&#8212;&#21452;&#37325;&#26680;&#12290;</title><link>http://arxiv.org/abs/2305.08463</link><description>&lt;p&gt;
&#22343;&#20540;&#28418;&#31227;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Convergence Analysis of Mean Shift. (arXiv:2305.08463v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08463
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#22343;&#20540;&#28418;&#31227;&#31639;&#27861;&#30340;&#27169;&#20272;&#35745;&#24207;&#21015;&#30340;&#25910;&#25947;&#20445;&#35777;&#65292;&#24182;&#25193;&#23637;&#20102;&#29616;&#26377;&#30340;&#28085;&#30422;&#35299;&#26512;&#26680;&#21644;Epanechnikov&#26680;&#30340;&#21457;&#29616;&#65292;&#24847;&#20041;&#22312;&#20110;&#28085;&#30422;&#20102;&#22312;&#22522;&#20110;KDE&#30340;&#27169;&#20272;&#35745;&#30340;&#28176;&#36817;&#32479;&#35745;&#25928;&#29575;&#26041;&#38754;&#26368;&#20248;&#30340;&#38750;&#36127;&#26680;&#8212;&#8212;&#21452;&#37325;&#26680;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22343;&#20540;&#28418;&#31227;&#65288;MS&#65289;&#31639;&#27861;&#23547;&#25214;&#26680;&#23494;&#24230;&#20272;&#35745;&#65288;KDE&#65289;&#30340;&#27169;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#30001;MS&#31639;&#27861;&#20135;&#29983;&#30340;&#27169;&#20272;&#35745;&#24207;&#21015;&#30340;&#25910;&#25947;&#20445;&#35777;&#65292;&#24182;&#22312;&#30456;&#24403;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#65292;&#20511;&#21161;&#20110;&#20851;&#20110;{\L}ojasiewicz&#19981;&#31561;&#24335;&#30340;&#35770;&#35777;&#65292;&#35780;&#20272;&#20102;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#25193;&#23637;&#20102;&#29616;&#26377;&#30340;&#28085;&#30422;&#35299;&#26512;&#26680;&#21644;Epanechnikov&#26680;&#30340;&#21457;&#29616;&#65292;&#24847;&#20041;&#22312;&#20110;&#28085;&#30422;&#20102;&#22312;&#22522;&#20110;KDE&#30340;&#27169;&#20272;&#35745;&#30340;&#28176;&#36817;&#32479;&#35745;&#25928;&#29575;&#26041;&#38754;&#26368;&#20248;&#30340;&#38750;&#36127;&#26680;&#8212;&#8212;&#21452;&#37325;&#26680;&#12290;
&lt;/p&gt;
&lt;p&gt;
The mean shift (MS) algorithm seeks a mode of the kernel density estimate (KDE). This study presents a convergence guarantee of the mode estimate sequence generated by the MS algorithm and an evaluation of the convergence rate, under fairly mild conditions, with the help of the argument concerning the {\L}ojasiewicz inequality. Our findings, which extend existing ones covering analytic kernels and the Epanechnikov kernel, are significant in that they cover the biweight kernel that is optimal among non-negative kernels in terms of the asymptotic statistical efficiency for the KDE-based mode estimation.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22522;&#20110;&#26680;&#20989;&#25968;&#30340;&#37492;&#21035;&#22120;&#35757;&#32451;GAN&#30340;&#26799;&#24230;&#19979;&#38477;-&#19978;&#21319;&#31639;&#27861;&#30340;&#23616;&#37096;&#25910;&#25947;&#24615;&#65292;&#25581;&#31034;&#20102;&#23398;&#20064;&#29575;&#12289;&#27491;&#21017;&#21270;&#21644;&#24102;&#23485;&#23545;&#20854;&#24433;&#21709;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#25910;&#25947;&#12289;&#25391;&#33633;&#25110;&#21457;&#25955;&#30340;&#30456;&#21464;&#29616;&#35937;&#12290;</title><link>http://arxiv.org/abs/2305.08277</link><description>&lt;p&gt;
&#35757;&#32451;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;&#26799;&#24230;&#19979;&#38477;-&#19978;&#21319;&#31639;&#27861;&#30340;&#23616;&#37096;&#25910;&#25947;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Local Convergence of Gradient Descent-Ascent for Training Generative Adversarial Networks. (arXiv:2305.08277v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08277
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22522;&#20110;&#26680;&#20989;&#25968;&#30340;&#37492;&#21035;&#22120;&#35757;&#32451;GAN&#30340;&#26799;&#24230;&#19979;&#38477;-&#19978;&#21319;&#31639;&#27861;&#30340;&#23616;&#37096;&#25910;&#25947;&#24615;&#65292;&#25581;&#31034;&#20102;&#23398;&#20064;&#29575;&#12289;&#27491;&#21017;&#21270;&#21644;&#24102;&#23485;&#23545;&#20854;&#24433;&#21709;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#25910;&#25947;&#12289;&#25391;&#33633;&#25110;&#21457;&#25955;&#30340;&#30456;&#21464;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#22797;&#26434;&#39640;&#32500;&#25968;&#25454;&#29983;&#25104;&#27169;&#22411;&#30340;&#35757;&#32451;&#26041;&#27861;&#12290;&#35757;&#32451;GAN&#30340;&#26631;&#20934;&#26041;&#27861;&#28041;&#21450;&#23545;&#26497;&#23567;-&#26497;&#22823;&#20248;&#21270;&#38382;&#39064;&#36827;&#34892;&#26799;&#24230;&#19979;&#38477;-&#19978;&#21319;&#65288;GDA&#65289;&#36807;&#31243;&#12290;&#30001;&#20110;&#21160;&#24577;&#30340;&#38750;&#32447;&#24615;&#24615;&#36136;&#65292;&#35813;&#36807;&#31243;&#36890;&#24120;&#24456;&#38590;&#20998;&#26512;&#12290;&#26412;&#30740;&#31350;&#37325;&#28857;&#30740;&#31350;&#20102;&#20351;&#29992;&#22522;&#20110;&#26680;&#20989;&#25968;&#30340;&#37492;&#21035;&#22120;&#35757;&#32451;GAN&#26102;&#30340;GDA&#23616;&#37096;&#21160;&#24577;&#12290;&#35813;&#25910;&#25947;&#24615;&#20998;&#26512;&#26159;&#22312;[Becker et al. 2022]&#30340;&#8220;&#23396;&#31435;&#28857;&#27169;&#22411;&#8221;&#20551;&#35774;&#19979;&#65292;&#23545;&#25551;&#36848;GDA&#36845;&#20195;&#30340;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#31995;&#32479;&#36827;&#34892;&#32447;&#24615;&#21270;&#24471;&#21040;&#30340;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;&#23398;&#20064;&#29575;&#12289;&#27491;&#21017;&#21270;&#21644;&#26680;&#21028;&#21035;&#22120;&#30340;&#24102;&#23485;&#23545;GDA&#23616;&#37096;&#25910;&#25947;&#36895;&#24230;&#30340;&#24433;&#21709;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#30456;&#21464;&#29616;&#35937;&#65292;&#34920;&#26126;&#31995;&#32479;&#20309;&#26102;&#25910;&#25947;&#12289;&#25391;&#33633;&#25110;&#21457;&#25955;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#39564;&#35777;&#25105;&#20204;&#32467;&#35770;&#30340;&#25968;&#20540;&#27169;&#25311;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative Adversarial Networks (GANs) are a popular formulation to train generative models for complex high dimensional data. The standard method for training GANs involves a gradient descent-ascent (GDA) procedure on a minimax optimization problem. This procedure is hard to analyze in general due to the nonlinear nature of the dynamics. We study the local dynamics of GDA for training a GAN with a kernel-based discriminator. This convergence analysis is based on a linearization of a non-linear dynamical system that describes the GDA iterations, under an \textit{isolated points model} assumption from [Becker et al. 2022]. Our analysis brings out the effect of the learning rates, regularization, and the bandwidth of the kernel discriminator, on the local convergence rate of GDA. Importantly, we show phase transitions that indicate when the system converges, oscillates, or diverges. We also provide numerical simulations that verify our claims.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32858;&#31867;&#30340;&#40065;&#26834;&#26816;&#27979;&#28382;&#21518;&#22810;&#22240;&#23376;&#27169;&#22411;&#20013;&#30340;&#39046;&#20808;&#28382;&#21518;&#20851;&#31995;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#21508;&#31181;&#32858;&#31867;&#25216;&#26415;&#21644;&#30456;&#20284;&#24230;&#24230;&#37327;&#26041;&#27861;&#23454;&#29616;&#20102;&#23545;&#39046;&#20808;&#28382;&#21518;&#20272;&#35745;&#30340;&#32858;&#21512;&#65292;&#20174;&#32780;&#24378;&#21270;&#20102;&#23545;&#21407;&#22987;&#23431;&#23449;&#20013;&#30340;&#19968;&#33268;&#20851;&#31995;&#30340;&#35782;&#21035;&#12290;</title><link>http://arxiv.org/abs/2305.06704</link><description>&lt;p&gt;
&#28382;&#21518;&#22810;&#22240;&#23376;&#27169;&#22411;&#20013;&#39046;&#20808;&#28382;&#21518;&#20851;&#31995;&#30340;&#40065;&#26834;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Robust Detection of Lead-Lag Relationships in Lagged Multi-Factor Models. (arXiv:2305.06704v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06704
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32858;&#31867;&#30340;&#40065;&#26834;&#26816;&#27979;&#28382;&#21518;&#22810;&#22240;&#23376;&#27169;&#22411;&#20013;&#30340;&#39046;&#20808;&#28382;&#21518;&#20851;&#31995;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#21508;&#31181;&#32858;&#31867;&#25216;&#26415;&#21644;&#30456;&#20284;&#24230;&#24230;&#37327;&#26041;&#27861;&#23454;&#29616;&#20102;&#23545;&#39046;&#20808;&#28382;&#21518;&#20272;&#35745;&#30340;&#32858;&#21512;&#65292;&#20174;&#32780;&#24378;&#21270;&#20102;&#23545;&#21407;&#22987;&#23431;&#23449;&#20013;&#30340;&#19968;&#33268;&#20851;&#31995;&#30340;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#31995;&#32479;&#20013;&#65292;&#36890;&#36807;&#21457;&#29616;&#25968;&#25454;&#20013;&#22266;&#26377;&#30340;&#39046;&#20808;&#28382;&#21518;&#20851;&#31995;&#65292;&#21487;&#20197;&#33719;&#24471;&#20851;&#38190;&#20449;&#24687;&#65292;&#36825;&#25351;&#30340;&#26159;&#20004;&#20010;&#30456;&#23545;&#26102;&#38388;&#20114;&#31227;&#30340;&#26102;&#38388;&#24207;&#21015;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#21487;&#20197;&#29992;&#20110;&#25511;&#21046;&#12289;&#39044;&#27979;&#25110;&#32858;&#31867;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#32858;&#31867;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#40065;&#26834;&#26816;&#27979;&#28382;&#21518;&#22810;&#22240;&#23376;&#27169;&#22411;&#20013;&#30340;&#39046;&#20808;&#28382;&#21518;&#20851;&#31995;&#12290;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#65292;&#25152;&#35774;&#24819;&#30340;&#31649;&#36947;&#25509;&#25910;&#19968;&#32452;&#26102;&#38388;&#24207;&#21015;&#20316;&#20026;&#36755;&#20837;&#65292;&#24182;&#20351;&#29992;&#28369;&#21160;&#31383;&#21475;&#26041;&#27861;&#20174;&#27599;&#20010;&#36755;&#20837;&#26102;&#38388;&#24207;&#21015;&#20013;&#25552;&#21462;&#19968;&#32452;&#23376;&#24207;&#21015;&#26102;&#38388;&#24207;&#21015;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24212;&#29992;&#21508;&#31181;&#32858;&#31867;&#25216;&#26415;&#65288;&#20363;&#22914;K-means++&#21644;&#35889;&#32858;&#31867;&#65289;&#65292;&#37319;&#29992;&#21508;&#31181;&#25104;&#23545;&#30456;&#20284;&#24615;&#24230;&#37327;&#65292;&#21253;&#25324;&#38750;&#32447;&#24615;&#30340;&#30456;&#20284;&#24615;&#24230;&#37327;&#12290;&#19968;&#26086;&#32858;&#31867;&#34987;&#25552;&#21462;&#20986;&#26469;&#65292;&#36328;&#32858;&#31867;&#30340;&#39046;&#20808;&#28382;&#21518;&#20272;&#35745;&#34987;&#32858;&#21512;&#36215;&#26469;&#65292;&#20197;&#22686;&#24378;&#23545;&#21407;&#22987;&#23431;&#23449;&#20013;&#19968;&#33268;&#20851;&#31995;&#30340;&#35782;&#21035;&#12290;&#30001;&#20110;&#22810;
&lt;/p&gt;
&lt;p&gt;
In multivariate time series systems, key insights can be obtained by discovering lead-lag relationships inherent in the data, which refer to the dependence between two time series shifted in time relative to one another, and which can be leveraged for the purposes of control, forecasting or clustering. We develop a clustering-driven methodology for the robust detection of lead-lag relationships in lagged multi-factor models. Within our framework, the envisioned pipeline takes as input a set of time series, and creates an enlarged universe of extracted subsequence time series from each input time series, by using a sliding window approach. We then apply various clustering techniques (e.g, K-means++ and spectral clustering), employing a variety of pairwise similarity measures, including nonlinear ones. Once the clusters have been extracted, lead-lag estimates across clusters are aggregated to enhance the identification of the consistent relationships in the original universe. Since multi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#31867;&#20998;&#31867;&#20013;&#25932;&#23545;&#35757;&#32451;&#30340;&#40065;&#26834;&#35299;&#23384;&#22312;&#24615;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#27599;&#20010;&#27169;&#22411;&#20013;&#23384;&#22312; Borel &#21487;&#27979;&#30340;&#40065;&#26834;&#20998;&#31867;&#22120;&#65292;&#24182;&#19982;&#26368;&#20248;&#20256;&#36755;&#21644;&#24635;&#21464;&#24046;&#27491;&#21017;&#21270;&#24314;&#31435;&#20102;&#32852;&#31995;&#12290;&#22312;&#20108;&#20803;&#20998;&#31867;&#38382;&#39064;&#20013;&#65292;&#23545;&#19981;&#21487;&#30693;&#20998;&#31867;&#22120;&#30340;&#25932;&#23545;&#35757;&#32451;&#38382;&#39064;&#23384;&#22312; Borel &#21487;&#27979;&#30340;&#35299;&#12290;</title><link>http://arxiv.org/abs/2305.00075</link><description>&lt;p&gt;
&#22810;&#31867;&#20998;&#31867;&#20013;&#25932;&#23545;&#35757;&#32451;&#35299;&#30340;&#23384;&#22312;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the existence of solutions to adversarial training in multiclass classification. (arXiv:2305.00075v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00075
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#31867;&#20998;&#31867;&#20013;&#25932;&#23545;&#35757;&#32451;&#30340;&#40065;&#26834;&#35299;&#23384;&#22312;&#24615;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#27599;&#20010;&#27169;&#22411;&#20013;&#23384;&#22312; Borel &#21487;&#27979;&#30340;&#40065;&#26834;&#20998;&#31867;&#22120;&#65292;&#24182;&#19982;&#26368;&#20248;&#20256;&#36755;&#21644;&#24635;&#21464;&#24046;&#27491;&#21017;&#21270;&#24314;&#31435;&#20102;&#32852;&#31995;&#12290;&#22312;&#20108;&#20803;&#20998;&#31867;&#38382;&#39064;&#20013;&#65292;&#23545;&#19981;&#21487;&#30693;&#20998;&#31867;&#22120;&#30340;&#25932;&#23545;&#35757;&#32451;&#38382;&#39064;&#23384;&#22312; Borel &#21487;&#27979;&#30340;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25932;&#23545;&#35757;&#32451;&#22312;&#22810;&#31867;&#20998;&#31867;&#38382;&#39064;&#20013;&#30340;&#19977;&#31181;&#27169;&#22411;&#65292;&#26088;&#22312;&#26500;&#24314;&#23545;&#25239;&#25200;&#21160;&#19979;&#40065;&#26834;&#30340;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#27599;&#20010;&#27169;&#22411;&#20013;&#23384;&#22312; Borel &#21487;&#27979;&#30340;&#40065;&#26834;&#20998;&#31867;&#22120;&#65292;&#24182;&#25552;&#20379;&#20102;&#25932;&#23545;&#35757;&#32451;&#38382;&#39064;&#30340;&#32479;&#19968;&#35270;&#35282;&#65292;&#25299;&#23637;&#20102;&#20316;&#32773;&#20043;&#21069;&#30340;&#26368;&#20248;&#20256;&#36755;&#32852;&#31995;&#65292;&#24182;&#22312;&#22810;&#31867;&#24773;&#20917;&#19979;&#25932;&#23545;&#35757;&#32451;&#21644;&#24635;&#21464;&#24046;&#27491;&#21017;&#21270;&#20043;&#38388;&#24314;&#31435;&#20102;&#26032;&#30340;&#32852;&#31995;&#12290;&#20316;&#20026;&#25105;&#20204;&#32467;&#26524;&#30340;&#25512;&#35770;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#20108;&#20803;&#20998;&#31867;&#35774;&#32622;&#20013;&#65292;&#23545;&#19981;&#21487;&#30693;&#20998;&#31867;&#22120;&#30340;&#25932;&#23545;&#35757;&#32451;&#38382;&#39064;&#23384;&#22312; Borel &#21487;&#27979;&#30340;&#35299;&#65292;&#36825;&#19968;&#32467;&#26524;&#25913;&#36827;&#20102;&#20851;&#20110;&#25932;&#23545;&#35757;&#32451;&#30340;&#25991;&#29486;&#65292;&#25991;&#29486;&#20013;&#20165;&#24050;&#30693;&#21482;&#26377;&#22312;&#29305;&#24449;&#31354;&#38388;&#30340;&#25193;&#22823;&#36890;&#29992; $&#963;$-&#20195;&#25968;&#20869;&#23384;&#22312;&#40065;&#26834;&#30340;&#20998;&#31867;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study three models of the problem of adversarial training in multiclass classification designed to construct robust classifiers against adversarial perturbations of data in the agnostic-classifier setting. We prove the existence of Borel measurable robust classifiers in each model and provide a unified perspective of the adversarial training problem, expanding the connections with optimal transport initiated by the authors in previous work and developing new connections between adversarial training in the multiclass setting and total variation regularization. As a corollary of our results, we prove the existence of Borel measurable solutions to the agnostic adversarial training problem in the binary classification setting, a result that improves results in the literature of adversarial training, where robust classifiers were only known to exist within the enlarged universal $\sigma$-algebra of the feature space.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;INDEED&#65292;&#23427;&#21487;&#20197;&#21516;&#26102;&#23398;&#20064;&#19981;&#21516;&#24494;&#20998;&#26041;&#31243;&#38382;&#39064;&#30340;&#25805;&#20316;&#31526;&#65292;&#32780;&#26080;&#38656;&#37325;&#26032;&#35757;&#32451;&#65292;&#19988;&#21482;&#38656;&#35201;&#26497;&#23569;&#30340;&#28436;&#31034;&#12290;</title><link>http://arxiv.org/abs/2304.07993</link><description>&lt;p&gt;
&#20869;&#22312;&#19978;&#19979;&#25991;&#31639;&#23376;&#23398;&#20064;&#29992;&#20110;&#24494;&#20998;&#26041;&#31243;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
In-Context Operator Learning for Differential Equation Problems. (arXiv:2304.07993v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07993
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;INDEED&#65292;&#23427;&#21487;&#20197;&#21516;&#26102;&#23398;&#20064;&#19981;&#21516;&#24494;&#20998;&#26041;&#31243;&#38382;&#39064;&#30340;&#25805;&#20316;&#31526;&#65292;&#32780;&#26080;&#38656;&#37325;&#26032;&#35757;&#32451;&#65292;&#19988;&#21482;&#38656;&#35201;&#26497;&#23569;&#30340;&#28436;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#8212;&#8212;IN-context Differential Equation Encoder-Decoder&#65288;INDEED&#65289;&#65292;&#29992;&#20110;&#20174;&#25968;&#25454;&#20013;&#21516;&#26102;&#23398;&#20064;&#25805;&#20316;&#31526;&#24182;&#22312;&#25512;&#29702;&#38454;&#27573;&#23558;&#20854;&#24212;&#29992;&#20110;&#26032;&#38382;&#39064;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#20219;&#20309;&#26435;&#37325;&#26356;&#26032;&#12290;&#29616;&#26377;&#26041;&#27861;&#23616;&#38480;&#20110;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#36924;&#36817;&#29305;&#23450;&#30340;&#26041;&#31243;&#35299;&#25110;&#29305;&#23450;&#30340;&#25805;&#20316;&#31526;&#65292;&#38656;&#35201;&#37325;&#26032;&#35757;&#32451;&#26469;&#22788;&#29702;&#20855;&#26377;&#19981;&#21516;&#26041;&#31243;&#30340;&#26032;&#38382;&#39064;&#12290;&#36890;&#36807;&#35757;&#32451;&#21333;&#20010;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#25805;&#20316;&#31526;&#23398;&#20064;&#22120;&#65292;&#25105;&#20204;&#19981;&#20165;&#21487;&#20197;&#25670;&#33073;&#20026;&#26032;&#38382;&#39064;&#37325;&#26032;&#35757;&#32451;&#65288;&#29978;&#33267;&#24494;&#35843;&#65289;&#31070;&#32463;&#32593;&#32476;&#30340;&#22256;&#25200;&#65292;&#36824;&#21487;&#20197;&#21033;&#29992;&#25805;&#20316;&#31526;&#20043;&#38388;&#20849;&#20139;&#30340;&#20849;&#21516;&#28857;&#65292;&#36825;&#26679;&#22312;&#23398;&#20064;&#26032;&#30340;&#25805;&#20316;&#31526;&#26102;&#21482;&#38656;&#35201;&#26497;&#23569;&#30340;&#28436;&#31034;&#21363;&#21487;&#12290;&#25105;&#20204;&#30340;&#25968;&#20540;&#32467;&#26524;&#26174;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#23569;&#26679;&#26412;&#23398;&#20064;&#22120;&#30340;&#33021;&#21147;&#65292;&#29992;&#20110;&#21508;&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#24494;&#20998;&#26041;&#31243;&#38382;&#39064;&#65292;&#21253;&#25324;ODE&#21644;PDE&#30340;&#27491;&#21521;&#21644;&#21453;&#21521;&#38382;&#39064;&#65292;&#21516;&#26102;&#26174;&#31034;&#23427;&#21487;&#20197;&#25512;&#24191;&#23398;&#20064;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a new neural-network-based approach, namely IN-context Differential Equation Encoder-Decoder (INDEED), to simultaneously learn operators from data and apply it to new questions during the inference stage, without any weight update. Existing methods are limited to using a neural network to approximate a specific equation solution or a specific operator, requiring retraining when switching to a new problem with different equations. By training a single neural network as an operator learner, we can not only get rid of retraining (even fine-tuning) the neural network for new problems, but also leverage the commonalities shared across operators so that only a few demos are needed when learning a new operator. Our numerical results show the neural network's capability as a few-shot operator learner for a diversified type of differential equation problems, including forward and inverse problems of ODEs and PDEs, and also show that it can generalize its learning capabilit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861; Iterative Markovian Fitting&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#24230; Schr\"odinger&#26725;&#65288;SBs&#65289;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#30340;&#25968;&#20540;&#23454;&#39564;&#34920;&#29616;&#20986;&#22312;&#20934;&#30830;&#24615;&#21644;&#24615;&#33021;&#26041;&#38754;&#30340;&#26174;&#33879;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2303.16852</link><description>&lt;p&gt;
&#25193;&#25955;Schr\"odinger&#26725;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Diffusion Schr\"odinger Bridge Matching. (arXiv:2303.16852v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16852
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861; Iterative Markovian Fitting&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#24230; Schr\"odinger&#26725;&#65288;SBs&#65289;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#30340;&#25968;&#20540;&#23454;&#39564;&#34920;&#29616;&#20986;&#22312;&#20934;&#30830;&#24615;&#21644;&#24615;&#33021;&#26041;&#38754;&#30340;&#26174;&#33879;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#20915;&#36816;&#36755;&#38382;&#39064;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#26377;&#30528;&#35768;&#22810;&#24212;&#29992;&#65292;&#20363;&#22914;&#26032;&#22411;&#30340;&#36136;&#37327;&#20256;&#36755;&#26041;&#27861;&#65292;&#22914;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#65288;DDMs&#65289;&#21644;&#27969;&#21305;&#37197;&#27169;&#22411;&#65288;FMMs&#65289;&#65292;&#36890;&#36807;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#25110;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#23454;&#29616;&#36825;&#26679;&#30340;&#20256;&#36755;&#12290;&#28982;&#32780;&#65292;&#34429;&#28982;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#36817;&#20284;&#30830;&#23450;&#24615;&#21160;&#24577;&#26368;&#20248;&#20256;&#36755;&#65288;OT&#65289;&#26144;&#23556;&#26159;&#21487;&#21462;&#30340;&#65292;&#22240;&#20026;&#20855;&#26377;&#21560;&#24341;&#20154;&#30340;&#24615;&#36136;&#65292;&#20294; DDMs &#21644; FMMs &#24182;&#19981;&#33021;&#20445;&#35777;&#25552;&#20379;&#25509;&#36817; OT &#26144;&#23556;&#30340;&#20256;&#36755;&#12290;&#30456;&#21453;&#65292;Schr\"odinger&#26725;&#65288;SBs&#65289;&#35745;&#31639;&#38543;&#26426;&#21160;&#24577;&#26144;&#23556;&#65292;&#21487;&#20197;&#24674;&#22797;&#27491;&#21017;&#29109;&#29256;&#26412;&#30340; OT&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#29616;&#26377;&#30340;&#25968;&#20540;&#26041;&#27861;&#36817;&#20284; SBs &#30340;&#32500;&#24230;&#32553;&#25918;&#24046;&#25110;&#22312;&#36845;&#20195;&#20013;&#31215;&#32047;&#35823;&#24046;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#36845;&#20195;&#39532;&#23572;&#31185;&#22827;&#25311;&#21512;&#65292;&#19968;&#31181;&#35299;&#20915;&#39640;&#32500;&#24230; SB &#38382;&#39064;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#26041;&#27861;&#35774;&#35745;&#20026;&#19968;&#20010;&#36845;&#20195;&#36807;&#31243;&#65292;&#23558;&#32622;&#20449;&#20256;&#25773;&#25193;&#23637;&#21040; KL &#25955;&#24230;&#65292;&#21033;&#29992;&#26465;&#20214;&#29420;&#31435;&#24615;&#38477;&#20302;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#24182;&#30830;&#20445;&#19968;&#33268;&#24615;&#21644;&#25910;&#25947;&#24615;&#36136;&#12290;&#25105;&#20204;&#30340;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#30456;&#23545;&#20110;&#29616;&#26377;&#25104;&#26524;&#26041;&#27861;&#65292;&#22312;&#20934;&#30830;&#24615;&#21644;&#24615;&#33021;&#26041;&#38754;&#37117;&#26377;&#26174;&#33879;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Solving transport problems, i.e. finding a map transporting one given distribution to another, has numerous applications in machine learning. Novel mass transport methods motivated by generative modeling have recently been proposed, e.g. Denoising Diffusion Models (DDMs) and Flow Matching Models (FMMs) implement such a transport through a Stochastic Differential Equation (SDE) or an Ordinary Differential Equation (ODE). However, while it is desirable in many applications to approximate the deterministic dynamic Optimal Transport (OT) map which admits attractive properties, DDMs and FMMs are not guaranteed to provide transports close to the OT map. In contrast, Schr\"odinger bridges (SBs) compute stochastic dynamic mappings which recover entropy-regularized versions of OT. Unfortunately, existing numerical methods approximating SBs either scale poorly with dimension or accumulate errors across iterations. In this work, we introduce Iterative Markovian Fitting, a new methodology for solv
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24191;&#20041;&#35823;&#24046;&#39044;&#27979;&#22120;&#30340;&#26377;&#25928;&#24615;&#65292;&#25506;&#35752;&#20102;&#32622;&#20449;&#24230;&#12289;&#23616;&#37096;&#27969;&#24418;&#24179;&#28369;&#24230;&#21644;&#27169;&#22411;&#19968;&#33268;&#24615;&#35780;&#20998;&#20989;&#25968;&#30340;&#20248;&#32570;&#28857;&#65292;&#21457;&#29616;&#22312;&#22797;&#26434;&#26426;&#21046;&#32570;&#22833;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#20808;&#36827;&#30340;&#35780;&#20998;&#26080;&#27861;&#22312;&#20998;&#24067;&#36716;&#31227;&#21644;&#25439;&#22351;&#19979;&#36229;&#36234;&#31616;&#21333;&#30340;&#27169;&#22411;&#19968;&#33268;&#24615;&#12290;&#21516;&#26102;&#65292;&#22312;&#21463;&#25439;&#35757;&#32451;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#27169;&#22411;&#19968;&#33268;&#24615;&#25171;&#20998;&#20173;&#28982;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#19988;&#38598;&#25104;&#22810;&#26679;&#24615;&#26377;&#21161;&#20110;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2303.13589</link><description>&lt;p&gt;
Scoring Functions &#21644; Generalization Prediction &#30340;&#35814;&#32454;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Closer Look at Scoring Functions and Generalization Prediction. (arXiv:2303.13589v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.13589
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24191;&#20041;&#35823;&#24046;&#39044;&#27979;&#22120;&#30340;&#26377;&#25928;&#24615;&#65292;&#25506;&#35752;&#20102;&#32622;&#20449;&#24230;&#12289;&#23616;&#37096;&#27969;&#24418;&#24179;&#28369;&#24230;&#21644;&#27169;&#22411;&#19968;&#33268;&#24615;&#35780;&#20998;&#20989;&#25968;&#30340;&#20248;&#32570;&#28857;&#65292;&#21457;&#29616;&#22312;&#22797;&#26434;&#26426;&#21046;&#32570;&#22833;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#20808;&#36827;&#30340;&#35780;&#20998;&#26080;&#27861;&#22312;&#20998;&#24067;&#36716;&#31227;&#21644;&#25439;&#22351;&#19979;&#36229;&#36234;&#31616;&#21333;&#30340;&#27169;&#22411;&#19968;&#33268;&#24615;&#12290;&#21516;&#26102;&#65292;&#22312;&#21463;&#25439;&#35757;&#32451;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#27169;&#22411;&#19968;&#33268;&#24615;&#25171;&#20998;&#20173;&#28982;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#19988;&#38598;&#25104;&#22810;&#26679;&#24615;&#26377;&#21161;&#20110;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24191;&#20041;&#35823;&#24046;&#39044;&#27979;&#22120;&#65288;GEPs&#65289;&#30340;&#25928;&#26524;&#65292;&#36825;&#20123; GEPs &#26088;&#22312;&#36890;&#36807;&#20174;&#26679;&#26412;&#32423;&#20998;&#25968;&#20013;&#25512;&#23548;&#20986;&#25968;&#25454;&#38598;&#32423;&#35823;&#24046;&#20272;&#35745;&#20540;&#65292;&#20174;&#32780;&#39044;&#27979;&#27169;&#22411;&#22312;&#26410;&#35265;&#20998;&#24067;&#19978;&#30340;&#34920;&#29616;&#12290;&#28982;&#32780;&#65292;GEPs &#24120;&#24120;&#21033;&#29992;&#19981;&#21516;&#30340;&#26426;&#21046;&#65288;&#20363;&#22914;&#65292;&#22238;&#24402;&#22120;&#12289;&#38408;&#20540;&#20989;&#25968;&#12289;&#26657;&#20934;&#25968;&#25454;&#38598;&#31561;&#65289;&#65292;&#26469;&#25512;&#23548;&#36825;&#31181;&#35823;&#24046;&#20272;&#35745;&#20540;&#65292;&#36825;&#20250;&#28151;&#28102;&#29305;&#23450;&#35780;&#20998;&#20989;&#25968;&#30340;&#20248;&#28857;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#22312;&#26426;&#21046;&#36873;&#25321;&#29420;&#31435;&#30340;&#24773;&#20917;&#19979;&#65292;&#28145;&#20837;&#30740;&#31350;&#20102;&#27969;&#34892;&#30340;&#35780;&#20998;&#20989;&#25968;&#30340;&#26377;&#25928;&#24615;&#65288;&#32622;&#20449;&#24230;&#12289;&#23616;&#37096;&#27969;&#24418;&#24179;&#28369;&#24230;&#12289;&#27169;&#22411;&#19968;&#33268;&#24615;&#65289;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#22797;&#26434;&#26426;&#21046;&#32570;&#22833;&#30340;&#24773;&#20917;&#19979;&#65292;&#24403;&#20272;&#35745;&#20998;&#24067;&#36716;&#31227;&#21644;&#25439;&#22351;&#19979;&#30340;&#35823;&#24046;&#26102;&#65292;&#26368;&#20808;&#36827;&#30340;&#32622;&#20449;&#24230;&#21644;&#24179;&#28369;&#24230;&#22522;&#30784;&#35780;&#20998;&#26080;&#27861;&#36229;&#36234;&#31616;&#21333;&#30340;&#27169;&#22411;&#19968;&#33268;&#24615;&#12290;&#27492;&#22806;&#65292;&#22312;&#23454;&#38469;&#24773;&#20917;&#19979;&#65292;&#24403;&#35757;&#32451;&#25968;&#25454;&#21463;&#21040;&#25439;&#23475;&#26102;&#65288;&#20363;&#22914;&#26631;&#31614;&#22122;&#22768;&#12289;&#27979;&#37327;&#22122;&#22768;&#12289;&#27424;&#37319;&#26679;&#65289;&#65292;&#25105;&#20204;&#21457;&#29616;&#27169;&#22411;&#19968;&#33268;&#24615;&#25171;&#20998;&#20173;&#28982;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#19988;&#38598;&#25104;&#22810;&#26679;&#24615;&#26377;&#21161;&#20110;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generalization error predictors (GEPs) aim to predict model performance on unseen distributions by deriving dataset-level error estimates from sample-level scores. However, GEPs often utilize disparate mechanisms (e.g., regressors, thresholding functions, calibration datasets, etc), to derive such error estimates, which can obfuscate the benefits of a particular scoring function. Therefore, in this work, we rigorously study the effectiveness of popular scoring functions (confidence, local manifold smoothness, model agreement), independent of mechanism choice. We find, absent complex mechanisms, that state-of-the-art confidence- and smoothness- based scores fail to outperform simple model-agreement scores when estimating error under distribution shifts and corruptions. Furthermore, on realistic settings where the training data has been compromised (e.g., label noise, measurement noise, undersampling), we find that model-agreement scores continue to perform well and that ensemble diversi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#36845;&#20195;&#19968;&#38454;&#31639;&#27861;&#39640;&#25928;&#36817;&#20284;&#20132;&#21449;&#39564;&#35777;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#22823;&#35268;&#27169;&#38382;&#39064;&#20013;&#22240;&#38480;&#21046;&#35745;&#31639;&#36164;&#28304;&#25110;&#26089;&#20572;&#32780;&#38590;&#20197;&#24471;&#21040;ERM&#38382;&#39064;&#30830;&#20999;&#35299;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2303.02732</link><description>&lt;p&gt;
&#36845;&#20195;&#36817;&#20284;&#20132;&#21449;&#39564;&#35777;
&lt;/p&gt;
&lt;p&gt;
Iterative Approximate Cross-Validation. (arXiv:2303.02732v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.02732
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#36845;&#20195;&#19968;&#38454;&#31639;&#27861;&#39640;&#25928;&#36817;&#20284;&#20132;&#21449;&#39564;&#35777;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#22823;&#35268;&#27169;&#38382;&#39064;&#20013;&#22240;&#38480;&#21046;&#35745;&#31639;&#36164;&#28304;&#25110;&#26089;&#20572;&#32780;&#38590;&#20197;&#24471;&#21040;ERM&#38382;&#39064;&#30830;&#20999;&#35299;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20132;&#21449;&#39564;&#35777;(CV)&#26159;&#35780;&#20272;&#21644;&#36873;&#25321;&#39044;&#27979;&#27169;&#22411;&#30340;&#26368;&#27969;&#34892;&#24037;&#20855;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#26631;&#20934;CV&#22312;&#25240;&#25968;&#36739;&#22810;&#26102;&#35745;&#31639;&#25104;&#26412;&#24456;&#39640;&#12290;&#26368;&#36817;&#65292;&#22312;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;(ERM)&#26694;&#26550;&#19979;&#65292;&#19968;&#31995;&#21015;&#24037;&#20316;&#25552;&#20986;&#20102;&#22522;&#20110;&#23436;&#25972;&#25968;&#25454;&#38598;&#35757;&#32451;&#30340;ERM&#38382;&#39064;&#35299;&#30340;&#26377;&#25928;&#26041;&#27861;&#26469;&#36817;&#20284;CV&#12290;&#28982;&#32780;&#65292;&#22312;&#22823;&#35268;&#27169;&#38382;&#39064;&#20013;&#65292;&#30001;&#20110;&#26377;&#38480;&#30340;&#35745;&#31639;&#36164;&#28304;&#25110;&#26089;&#20572;&#30340;&#26041;&#24335;&#38450;&#27490;&#36807;&#25311;&#21512;&#65292;&#24456;&#38590;&#24471;&#21040;ERM&#38382;&#39064;&#30340;&#30830;&#20999;&#35299;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33539;&#24335;&#65292;&#22312;&#36890;&#36807;&#36845;&#20195;&#19968;&#38454;&#31639;&#27861;&#27714;&#35299;ERM&#38382;&#39064;&#26102;&#39640;&#25928;&#22320;&#36817;&#20284;CV&#65292;&#32780;&#26080;&#38656;&#36816;&#34892;&#21040;&#25910;&#25947;&#29366;&#24577;&#12290;&#25105;&#20204;&#30340;&#26032;&#26041;&#27861;&#25193;&#23637;&#20102;&#29616;&#26377;&#30340;CV&#36817;&#20284;&#20445;&#35777;&#65292;&#20351;&#20854;&#22312;&#25972;&#20010;&#31639;&#27861;&#36712;&#36857;&#20013;&#65288;&#21253;&#25324;&#25910;&#25947;&#26102;&#65289;&#37117;&#25104;&#31435;&#65292;&#20174;&#32780;&#25512;&#24191;&#20102;&#29616;&#26377;&#30340;CV&#36817;&#20284;&#26041;&#27861;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cross-validation (CV) is one of the most popular tools for assessing and selecting predictive models. However, standard CV suffers from high computational cost when the number of folds is large. Recently, under the empirical risk minimization (ERM) framework, a line of works proposed efficient methods to approximate CV based on the solution of the ERM problem trained on the full dataset. However, in large-scale problems, it can be hard to obtain the exact solution of the ERM problem, either due to limited computational resources or due to early stopping as a way of preventing overfitting. In this paper, we propose a new paradigm to efficiently approximate CV when the ERM problem is solved via an iterative first-order algorithm, without running until convergence. Our new method extends existing guarantees for CV approximation to hold along the whole trajectory of the algorithm, including at convergence, thus generalizing existing CV approximation methods. Finally, we illustrate the accu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#28145;&#24230;&#36864;&#21270;&#29616;&#35937;&#65292;&#22312;&#20840;&#36830;&#25509;ReLU&#32593;&#32476;&#21021;&#22987;&#21270;&#26102;&#65292;&#20004;&#20010;&#36755;&#20837;&#20043;&#38388;&#30340;&#35282;&#24230;&#20250;&#36235;&#36817;&#20110;0&#12290;&#36890;&#36807;&#20351;&#29992;&#32452;&#21512;&#23637;&#24320;&#65292;&#24471;&#21040;&#20102;&#20854;&#36235;&#21521;&#20110;0&#30340;&#36895;&#24230;&#30340;&#31934;&#30830;&#20844;&#24335;&#65292;&#24182;&#39564;&#35777;&#20102;&#36825;&#20123;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2302.09712</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#28145;&#24230;&#36864;&#21270;&#65306;&#20840;&#36830;&#25509;ReLU&#32593;&#32476;&#21021;&#22987;&#21270;&#26102;&#65292;&#28040;&#22833;&#35282;&#24230;&#30340;&#29616;&#35937; (arXiv:2302.09712v2 [stat.ML] &#26356;&#26032;&#29256;)
&lt;/p&gt;
&lt;p&gt;
Depth Degeneracy in Neural Networks: Vanishing Angles in Fully Connected ReLU Networks on Initialization. (arXiv:2302.09712v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09712
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#28145;&#24230;&#36864;&#21270;&#29616;&#35937;&#65292;&#22312;&#20840;&#36830;&#25509;ReLU&#32593;&#32476;&#21021;&#22987;&#21270;&#26102;&#65292;&#20004;&#20010;&#36755;&#20837;&#20043;&#38388;&#30340;&#35282;&#24230;&#20250;&#36235;&#36817;&#20110;0&#12290;&#36890;&#36807;&#20351;&#29992;&#32452;&#21512;&#23637;&#24320;&#65292;&#24471;&#21040;&#20102;&#20854;&#36235;&#21521;&#20110;0&#30340;&#36895;&#24230;&#30340;&#31934;&#30830;&#20844;&#24335;&#65292;&#24182;&#39564;&#35777;&#20102;&#36825;&#20123;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#35768;&#22810;&#20854;&#24615;&#36136;&#20173;&#26410;&#34987;&#29702;&#35770;&#19978;&#29702;&#35299;&#65292;&#20854;&#20013;&#19968;&#20010;&#35868;&#22242;&#26159;&#28145;&#24230;&#36864;&#21270;&#29616;&#35937;&#65306;&#32593;&#32476;&#23618;&#25968;&#36234;&#28145;&#65292;&#21021;&#22987;&#21270;&#26102;&#32593;&#32476;&#36234;&#25509;&#36817;&#20110;&#24120;&#25968;&#20989;&#25968;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;ReLU&#31070;&#32463;&#32593;&#32476;&#20004;&#20010;&#36755;&#20837;&#20043;&#38388;&#38543;&#30528;&#23618;&#25968;&#21464;&#21270;&#30340;&#35282;&#24230;&#28436;&#21464;&#24773;&#20917;&#12290;&#36890;&#36807;&#20351;&#29992;&#32452;&#21512;&#23637;&#24320;&#65292;&#25105;&#20204;&#25214;&#21040;&#20102;&#23427;&#38543;&#28145;&#24230;&#22686;&#21152;&#36235;&#21521;&#20110;0&#30340;&#36895;&#24230;&#30340;&#31934;&#30830;&#20844;&#24335;&#65292;&#36825;&#20123;&#20844;&#24335;&#25429;&#25417;&#20102;&#24494;&#35266;&#27874;&#21160;&#12290;&#25105;&#20204;&#29992;Monte Carlo&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#24182;&#35777;&#26126;&#20102;&#32467;&#26524;&#20934;&#30830;&#22320;&#36817;&#20284;&#20102;&#26377;&#38480;&#32593;&#32476;&#30340;&#34892;&#20026;&#12290;&#36825;&#20123;&#20844;&#24335;&#20197;&#36890;&#36807;ReLU&#20989;&#25968;&#30340;&#30456;&#20851;&#39640;&#26031;&#21464;&#37327;&#30340;&#28151;&#21512;&#30697;&#24418;&#24335;&#32473;&#20986;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#20102;&#19968;&#20010;&#20196;&#20154;&#24778;&#35766;&#30340;&#32452;&#21512;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite remarkable performance on a variety of tasks, many properties of deep neural networks are not yet theoretically understood. One such mystery is the depth degeneracy phenomenon: the deeper you make your network, the closer your network is to a constant function on initialization. In this paper, we examine the evolution of the angle between two inputs to a ReLU neural network as a function of the number of layers. By using combinatorial expansions, we find precise formulas for how fast this angle goes to zero as depth increases. These formulas capture microscopic fluctuations that are not visible in the popular framework of infinite width limits, and leads to qualitatively different predictions. We validate our theoretical results with Monte Carlo experiments and show that our results accurately approximate finite network behaviour. The formulas are given in terms of the mixed moments of correlated Gaussians passed through the ReLU function. We also find a surprising combinatoria
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20851;&#20110;&#21028;&#21035;&#24335;&#19982;&#29983;&#25104;&#24335;&#20998;&#31867;&#22120;&#30340;&#32463;&#20856;&#20027;&#39064;&#65292;&#21033;&#29992;&#22810;&#31867;$\mathcal{H}$-&#19968;&#33268;&#24615;&#19979;&#30028;&#65292;&#35777;&#26126;&#20102;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#22810;&#31867;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#26679;&#26412;&#35201;&#27714;&#27604;&#36923;&#36753;&#22238;&#24402;&#20998;&#31867;&#22120;&#22810;&#20102;$O(\log n)$&#12290;</title><link>http://arxiv.org/abs/2302.02334</link><description>&lt;p&gt;
&#37325;&#26032;&#23457;&#35270;&#21028;&#21035;&#24335;&#20998;&#31867;&#22120;&#19982;&#29983;&#25104;&#24335;&#20998;&#31867;&#22120;&#65306;&#29702;&#35770;&#19982;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Revisiting Discriminative vs. Generative Classifiers: Theory and Implications. (arXiv:2302.02334v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02334
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20851;&#20110;&#21028;&#21035;&#24335;&#19982;&#29983;&#25104;&#24335;&#20998;&#31867;&#22120;&#30340;&#32463;&#20856;&#20027;&#39064;&#65292;&#21033;&#29992;&#22810;&#31867;$\mathcal{H}$-&#19968;&#33268;&#24615;&#19979;&#30028;&#65292;&#35777;&#26126;&#20102;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#22810;&#31867;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#26679;&#26412;&#35201;&#27714;&#27604;&#36923;&#36753;&#22238;&#24402;&#20998;&#31867;&#22120;&#22810;&#20102;$O(\log n)$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#28145;&#24230;&#27169;&#22411;&#39044;&#20808;&#22312;&#22823;&#35268;&#27169;&#26631;&#35760;&#25110;&#26410;&#26631;&#35760;&#25968;&#25454;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#36716;&#31227;&#21040;&#19979;&#28216;&#20219;&#21153;&#12290;&#32447;&#24615;&#35780;&#20272;&#23558;&#39044;&#20808;&#35757;&#32451;&#30340;&#27169;&#22411;&#20013;&#30340;&#21442;&#25968;&#20923;&#32467;&#65292;&#24182;&#21333;&#29420;&#35757;&#32451;&#19968;&#20010;&#32447;&#24615;&#20998;&#31867;&#22120;&#65292;&#36825;&#26159;&#19968;&#31181;&#26377;&#25928;&#19988;&#26377;&#21560;&#24341;&#21147;&#30340;&#36716;&#31227;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#24456;&#23569;&#26377;&#30740;&#31350;&#32447;&#24615;&#35780;&#20272;&#20013;&#30340;&#20998;&#31867;&#22120;&#65292;&#38500;&#20102;&#40664;&#35748;&#30340;&#36923;&#36753;&#22238;&#24402;&#20998;&#31867;&#22120;&#12290;&#26412;&#25991;&#21463;&#21040;&#26420;&#32032;&#36125;&#21494;&#26031;&#30340;&#32479;&#35745;&#25928;&#29575;&#21551;&#21457;&#65292;&#37325;&#26032;&#23457;&#35270;&#20102;&#20851;&#20110;&#21028;&#21035;&#24335;&#19982;&#29983;&#25104;&#24335;&#20998;&#31867;&#22120;&#30340;&#32463;&#20856;&#20027;&#39064;&#12290;&#29702;&#35770;&#19978;&#65292;&#26412;&#25991;&#32771;&#34385;&#20351;&#29992;&#20195;&#29702;&#25439;&#22833;&#32780;&#19981;&#26159;0-1&#25439;&#22833;&#36827;&#34892;&#20998;&#26512;&#65292;&#24182;&#23558;&#32463;&#20856;&#32467;&#26524;&#20174;&#20108;&#20803;&#24773;&#20917;&#25512;&#24191;&#21040;&#22810;&#31867;&#24773;&#20917;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#22810;&#31867;&#26420;&#32032;&#36125;&#21494;&#26031;&#38656;&#35201;$O(\log n)$&#20010;&#26679;&#26412;&#26469;&#25509;&#36817;&#20854;&#28176;&#36817;&#35823;&#24046;&#65292;&#32780;&#30456;&#24212;&#30340;&#22810;&#31867;&#36923;&#36753;&#22238;&#24402;&#38656;&#35201;$O(n)$&#20010;&#26679;&#26412;&#65292;&#20854;&#20013;$n$&#26159;&#29305;&#24449;&#32500;&#24230;&#12290;&#20026;&#20102;&#35777;&#26126;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#31867;$\mathcal{H}$-&#19968;&#33268;&#24615;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
A large-scale deep model pre-trained on massive labeled or unlabeled data transfers well to downstream tasks. Linear evaluation freezes parameters in the pre-trained model and trains a linear classifier separately, which is efficient and attractive for transfer. However, little work has investigated the classifier in linear evaluation except for the default logistic regression. Inspired by the statistical efficiency of naive Bayes, the paper revisits the classical topic on discriminative vs. generative classifiers. Theoretically, the paper considers the surrogate loss instead of the zero-one loss in analyses and generalizes the classical results from binary cases to multiclass ones. We show that, under mild assumptions, multiclass naive Bayes requires $O(\log n)$ samples to approach its asymptotic error while the corresponding multiclass logistic regression requires $O(n)$ samples, where $n$ is the feature dimension. To establish it, we present a multiclass $\mathcal{H}$-consistency bo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#38543;&#26426;&#29305;&#24449;&#21644;&#31070;&#32463;&#20999;&#21521;&#26680;&#65288;NTK&#65289;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65292;&#35777;&#26126;&#20102;&#22312;&#38543;&#26426;&#29305;&#24449;&#20013;&#65292;&#21363;&#20351;&#28385;&#36275;&#31283;&#20581;&#24615;&#30340;&#36890;&#29992;&#23450;&#24459;&#25152;&#38656;&#30340;&#24517;&#35201;&#26465;&#20214;&#65292;&#27169;&#22411;&#20063;&#19981;&#20855;&#26377;&#20219;&#20309;&#36807;&#24230;&#21442;&#25968;&#21270;&#31243;&#24230;&#30340;&#31283;&#20581;&#24615;&#12290;&#30456;&#23545;&#22320;&#65292;&#23545;&#20110;&#20598;&#28608;&#27963;&#24773;&#20917;&#65292;NTK&#27169;&#22411;&#28385;&#36275;&#26222;&#36941;&#19979;&#38480;&#65292;&#21482;&#35201;&#28385;&#36275;&#36807;&#21442;&#25968;&#26465;&#20214;&#23601;&#33021;&#31283;&#20581;&#12290;&#36825;&#20026;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#31283;&#20581;&#24615;&#25552;&#20379;&#20102;&#26356;&#23574;&#38160;&#30340;&#27861;&#21017;&#65292;&#36229;&#36234;&#20102;&#20808;&#21069;&#24314;&#31435;&#30340;&#26222;&#36866;&#23450;&#24459;&#12290;</title><link>http://arxiv.org/abs/2302.01629</link><description>&lt;p&gt;
&#36229;&#36234;&#31283;&#20581;&#24615;&#30340;&#26222;&#36866;&#23450;&#24459;&#65306;&#38543;&#26426;&#29305;&#24449;&#21644;&#31070;&#32463;&#20999;&#21521;&#26680;&#30340;&#26356;&#23574;&#38160;&#27861;&#21017;
&lt;/p&gt;
&lt;p&gt;
Beyond the Universal Law of Robustness: Sharper Laws for Random Features and Neural Tangent Kernels. (arXiv:2302.01629v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.01629
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#38543;&#26426;&#29305;&#24449;&#21644;&#31070;&#32463;&#20999;&#21521;&#26680;&#65288;NTK&#65289;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65292;&#35777;&#26126;&#20102;&#22312;&#38543;&#26426;&#29305;&#24449;&#20013;&#65292;&#21363;&#20351;&#28385;&#36275;&#31283;&#20581;&#24615;&#30340;&#36890;&#29992;&#23450;&#24459;&#25152;&#38656;&#30340;&#24517;&#35201;&#26465;&#20214;&#65292;&#27169;&#22411;&#20063;&#19981;&#20855;&#26377;&#20219;&#20309;&#36807;&#24230;&#21442;&#25968;&#21270;&#31243;&#24230;&#30340;&#31283;&#20581;&#24615;&#12290;&#30456;&#23545;&#22320;&#65292;&#23545;&#20110;&#20598;&#28608;&#27963;&#24773;&#20917;&#65292;NTK&#27169;&#22411;&#28385;&#36275;&#26222;&#36941;&#19979;&#38480;&#65292;&#21482;&#35201;&#28385;&#36275;&#36807;&#21442;&#25968;&#26465;&#20214;&#23601;&#33021;&#31283;&#20581;&#12290;&#36825;&#20026;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#31283;&#20581;&#24615;&#25552;&#20379;&#20102;&#26356;&#23574;&#38160;&#30340;&#27861;&#21017;&#65292;&#36229;&#36234;&#20102;&#20808;&#21069;&#24314;&#31435;&#30340;&#26222;&#36866;&#23450;&#24459;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#24615;&#24178;&#25200;&#65292;Bubeck&#21644;Sellke&#30340;&#19968;&#20010;&#26377;&#24605;&#24819;&#21551;&#31034;&#30340;&#25991;&#31456;&#36890;&#36807;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#35270;&#35282;&#20998;&#26512;&#20102;&#36825;&#19968;&#29616;&#35937;&#65306;&#24179;&#28369;&#22320;&#25554;&#20540;&#25968;&#25454;&#38656;&#35201;&#30340;&#21442;&#25968;&#26174;&#33879;&#22810;&#20110;&#31616;&#21333;&#22320;&#35760;&#24518;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#8220;&#26222;&#36866;&#8221;&#30340;&#27861;&#21017;&#20165;&#20026;&#31283;&#20581;&#24615;&#25552;&#20379;&#20102;&#24517;&#35201;&#26465;&#20214;&#65292;&#26080;&#27861;&#21306;&#20998;&#27169;&#22411;&#12290;&#26412;&#25991;&#36890;&#36807;&#19987;&#27880;&#20110;&#38543;&#26426;&#29305;&#24449;&#21644;&#31070;&#32463;&#20999;&#21521;&#26680;&#65288;NTK&#65289;&#30340;&#20004;&#20010;&#20856;&#22411;&#35774;&#32622;&#20013;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#26469;&#35299;&#20915;&#36825;&#20123;&#24046;&#36317;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#38543;&#26426;&#29305;&#24449;&#20013;&#65292;&#21363;&#20351;&#28385;&#36275;&#31283;&#20581;&#24615;&#30340;&#36890;&#29992;&#23450;&#24459;&#25152;&#38656;&#30340;&#24517;&#35201;&#26465;&#20214;&#65292;&#27169;&#22411;&#20063;&#19981;&#20855;&#26377;&#20219;&#20309;&#36807;&#24230;&#21442;&#25968;&#21270;&#31243;&#24230;&#30340;&#31283;&#20581;&#24615;&#12290;&#30456;&#21453;&#65292;&#23545;&#20110;&#20598;&#28608;&#27963;&#24773;&#20917;&#65292;NTK&#27169;&#22411;&#28385;&#36275;&#26222;&#36941;&#19979;&#38480;&#65292;&#21482;&#35201;&#28385;&#36275;&#36807;&#21442;&#25968;&#26465;&#20214;&#23601;&#33021;&#31283;&#20581;&#12290;&#36825;&#20063;&#35299;&#20915;&#20102;&#20808;&#21069;&#22312;NTK&#26550;&#26500;&#30340;&#26368;&#20248;&#24615;&#19978;&#30340;&#29468;&#24819;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20026;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#31283;&#20581;&#24615;&#25552;&#20379;&#20102;&#26356;&#23574;&#38160;&#30340;&#27861;&#21017;&#65292;&#36229;&#36234;&#20102;&#20808;&#21069;&#24314;&#31435;&#30340;&#26222;&#36866;&#23450;&#24459;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning models are vulnerable to adversarial perturbations, and a thought-provoking paper by Bubeck and Sellke has analyzed this phenomenon through the lens of over-parameterization: interpolating smoothly the data requires significantly more parameters than simply memorizing it. However, this "universal" law provides only a necessary condition for robustness, and it is unable to discriminate between models. In this paper, we address these gaps by focusing on empirical risk minimization in two prototypical settings, namely, random features and the neural tangent kernel (NTK). We prove that, for random features, the model is not robust for any degree of over-parameterization, even when the necessary condition coming from the universal law of robustness is satisfied. In contrast, for even activations, the NTK model meets the universal lower bound, and it is robust as soon as the necessary condition on over-parameterization is fulfilled. This also addresses a conjecture in prior 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#20272;&#35745;&#22120;&#8212;&#8212;&#19978;&#19979;&#25991;&#22871;&#32034;&#65292;&#21487;&#20197;&#36890;&#36807;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#35299;&#20915;&#35299;&#37322;&#24615;&#21644;&#25311;&#21512;&#33021;&#21147;&#30340;&#30683;&#30462;&#38382;&#39064;&#65292;&#23454;&#29616;&#23545;&#21487;&#35299;&#37322;&#29305;&#24449;&#30340;&#31232;&#30095;&#25311;&#21512;&#65292;&#24182;&#19988;&#31232;&#30095;&#27169;&#24335;&#21644;&#31995;&#25968;&#20250;&#38543;&#30528;&#19978;&#19979;&#25991;&#29305;&#24449;&#30340;&#21464;&#21270;&#32780;&#21457;&#29983;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2302.00878</link><description>&lt;p&gt;
&#19978;&#19979;&#25991;&#22871;&#32034;&#65306;&#36890;&#36807;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#23454;&#29616;&#31232;&#30095;&#32447;&#24615;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
The contextual lasso: Sparse linear models via deep neural networks. (arXiv:2302.00878v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00878
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#20272;&#35745;&#22120;&#8212;&#8212;&#19978;&#19979;&#25991;&#22871;&#32034;&#65292;&#21487;&#20197;&#36890;&#36807;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#35299;&#20915;&#35299;&#37322;&#24615;&#21644;&#25311;&#21512;&#33021;&#21147;&#30340;&#30683;&#30462;&#38382;&#39064;&#65292;&#23454;&#29616;&#23545;&#21487;&#35299;&#37322;&#29305;&#24449;&#30340;&#31232;&#30095;&#25311;&#21512;&#65292;&#24182;&#19988;&#31232;&#30095;&#27169;&#24335;&#21644;&#31995;&#25968;&#20250;&#38543;&#30528;&#19978;&#19979;&#25991;&#29305;&#24449;&#30340;&#21464;&#21270;&#32780;&#21457;&#29983;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#32447;&#24615;&#27169;&#22411;&#26159;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#30340;&#40644;&#37329;&#26631;&#20934;&#24037;&#20855;&#65292;&#26412;&#35770;&#25991;&#36890;&#36807;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23545;&#31232;&#30095;&#32447;&#24615;&#27169;&#22411;&#36827;&#34892;&#25913;&#36827;&#65292;&#23454;&#29616;&#20102;&#21487;&#35299;&#37322;&#24615;&#21644;&#24378;&#22823;&#30340;&#25311;&#21512;&#33021;&#21147;&#12290;&#19978;&#19979;&#25991;&#22871;&#32034;&#26159;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#20272;&#35745;&#22120;&#65292;&#23427;&#23558;&#36755;&#20837;&#29305;&#24449;&#20998;&#25104;&#21487;&#35299;&#37322;&#29305;&#24449;&#21644;&#19978;&#19979;&#25991;&#29305;&#24449;&#20004;&#32452;&#65292;&#24182;&#23545;&#21487;&#35299;&#37322;&#29305;&#24449;&#36827;&#34892;&#31232;&#30095;&#25311;&#21512;&#65292;&#21516;&#26102;&#20854;&#31232;&#30095;&#27169;&#24335;&#21644;&#31995;&#25968;&#20250;&#38543;&#30528;&#19978;&#19979;&#25991;&#29305;&#24449;&#30340;&#21464;&#21270;&#32780;&#21457;&#29983;&#21464;&#21270;&#65292;&#36825;&#20010;&#36807;&#31243;&#36890;&#36807;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26080;&#38656;&#21442;&#25968;&#22320;&#36827;&#34892;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse linear models are a gold standard tool for interpretable machine learning, a field of emerging importance as predictive models permeate decision-making in many domains. Unfortunately, sparse linear models are far less flexible as functions of their input features than black-box models like deep neural networks. With this capability gap in mind, we study a not-uncommon situation where the input features dichotomize into two groups: explanatory features, which are candidates for inclusion as variables in an interpretable model, and contextual features, which select from the candidate variables and determine their effects. This dichotomy leads us to the contextual lasso, a new statistical estimator that fits a sparse linear model to the explanatory features such that the sparsity pattern and coefficients vary as a function of the contextual features. The fitting process learns this function nonparametrically via a deep neural network. To attain sparse coefficients, we train the net
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#32447;&#32447;&#24615;&#20248;&#21270;&#65288;OLO&#65289;&#28041;&#21450;&#26080;&#32422;&#26463;&#38382;&#39064;&#21644;&#21160;&#24577;&#36951;&#25022;&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#37325;&#26032;&#26500;&#36896;&#38382;&#39064;&#20026;&#31232;&#30095;&#32534;&#30721;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#26041;&#24335;&#65292;&#22312;&#36866;&#24212;&#24615;&#21644;&#24212;&#29992;&#19978;&#26377;&#36739;&#22909;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2301.13349</link><description>&lt;p&gt;
&#36890;&#36807;&#31232;&#30095;&#32534;&#30721;&#23454;&#29616;&#26080;&#32422;&#26463;&#21160;&#24577;&#36951;&#25022;
&lt;/p&gt;
&lt;p&gt;
Unconstrained Dynamic Regret via Sparse Coding. (arXiv:2301.13349v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13349
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#32447;&#32447;&#24615;&#20248;&#21270;&#65288;OLO&#65289;&#28041;&#21450;&#26080;&#32422;&#26463;&#38382;&#39064;&#21644;&#21160;&#24577;&#36951;&#25022;&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#37325;&#26032;&#26500;&#36896;&#38382;&#39064;&#20026;&#31232;&#30095;&#32534;&#30721;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#26041;&#24335;&#65292;&#22312;&#36866;&#24212;&#24615;&#21644;&#24212;&#29992;&#19978;&#26377;&#36739;&#22909;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#24433;&#21709;&#65292;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#32447;&#32447;&#24615;&#20248;&#21270;&#65288;OLO&#65289;&#22312;&#20004;&#20010;&#38382;&#39064;&#32467;&#26500;&#30340;&#32806;&#21512;&#19979;&#30340;&#24773;&#20917;&#65306;&#22495;&#26080;&#30028;&#65292;&#32780;&#31639;&#27861;&#30340;&#24615;&#33021;&#26159;&#36890;&#36807;&#21160;&#24577;&#36951;&#25022;&#26469;&#34913;&#37327;&#30340;&#12290;&#22788;&#29702;&#20219;&#19968;&#38382;&#39064;&#37117;&#35201;&#27714;&#36951;&#25022;&#30028;&#38480;&#20381;&#36182;&#20110;&#27604;&#36739;&#24207;&#21015;&#30340;&#26576;&#20123;&#22797;&#26434;&#24230;&#37327;&#24230; - &#29305;&#21035;&#26159;&#26080;&#32422;&#26463;OLO&#20013;&#30340;&#27604;&#36739;&#22120;&#33539;&#25968;&#65292;&#20197;&#21450;&#21160;&#24577;&#36951;&#25022;&#20013;&#30340;&#36335;&#24452;&#38271;&#24230;&#12290;&#19982;&#26368;&#36817;&#19968;&#31687;&#25991;&#31456;(Jacobsen&amp; Cutkosky&#65292;2022)&#36866;&#24212;&#36825;&#20004;&#20010;&#22797;&#26434;&#24230;&#37327;&#24230;&#30456;&#27604;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#37325;&#26032;&#26500;&#36896;&#38382;&#39064;&#20026;&#31232;&#30095;&#32534;&#30721;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#26041;&#24335;&#12290;&#21487;&#20197;&#36890;&#36807;&#19968;&#20010;&#31616;&#21333;&#30340;&#27169;&#22359;&#21270;&#26694;&#26550;&#23454;&#29616;&#36866;&#24212;&#24615;&#65292;&#36825;&#20010;&#26694;&#26550;&#33258;&#28982;&#22320;&#21033;&#29992;&#20102;&#29615;&#22659;&#26356;&#22797;&#26434;&#30340;&#21069;&#32622;&#30693;&#35782;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38745;&#24577;&#26080;&#32422;&#26463;OLO&#26799;&#24230;&#33258;&#36866;&#24212;&#31639;&#27861;&#65292;&#20351;&#29992;&#20102;&#26032;&#39062;&#30340;&#36830;&#32493;&#26102;&#38388;&#26426;&#21046;&#35774;&#35745;&#12290;&#36825;&#21487;&#33021;&#26159;&#20855;&#26377;&#29420;&#31435;&#20852;&#36259;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by time series forecasting, we study Online Linear Optimization (OLO) under the coupling of two problem structures: the domain is unbounded, and the performance of an algorithm is measured by its dynamic regret. Handling either of them requires the regret bound to depend on certain complexity measure of the comparator sequence -- specifically, the comparator norm in unconstrained OLO, and the path length in dynamic regret. In contrast to a recent work (Jacobsen &amp; Cutkosky, 2022) that adapts to the combination of these two complexity measures, we propose an alternative complexity measure by recasting the problem into sparse coding. Adaptivity can be achieved by a simple modular framework, which naturally exploits more intricate prior knowledge of the environment. Along the way, we also present a new gradient adaptive algorithm for static unconstrained OLO, designed using novel continuous time machinery. This could be of independent interest.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31232;&#30095;&#36870;Cholesky&#22240;&#23376;&#30340;&#39640;&#26031;&#20998;&#24067;&#30340;&#21464;&#20998;&#36924;&#36817;&#26041;&#27861;&#65292;&#32467;&#21512;&#21516;&#26679;&#39640;&#25928;&#30340;SIC&#32422;&#26463;&#30340;Kullback-Leibler&#26368;&#20248;&#20808;&#39564;&#36924;&#36817;&#65292;&#24182;&#22312;&#29305;&#23450;SIC&#25490;&#24207;&#21644;&#31232;&#30095;&#27169;&#24335;&#19979;&#65292;&#23454;&#29616;&#23545;&#28508;&#22312;&#39640;&#26031;&#36807;&#31243;&#30340;&#39640;&#24230;&#20934;&#30830;&#20808;&#39564;&#21644;&#21518;&#39564;&#36924;&#36817;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#31867;&#20284;&#35745;&#31639;&#22797;&#26434;&#24230;&#19979;&#26356;&#20934;&#30830;&#22320;&#39044;&#27979;&#24179;&#31283;&#26680;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2301.13303</link><description>&lt;p&gt;
&#21452;Kullback-Leibler&#26368;&#23567;&#21270;&#30340;&#21464;&#20998;&#31232;&#30095;&#36870;Cholesky&#36817;&#20284;&#29992;&#20110;&#28508;&#22312;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Variational sparse inverse Cholesky approximation for latent Gaussian processes via double Kullback-Leibler minimization. (arXiv:2301.13303v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13303
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31232;&#30095;&#36870;Cholesky&#22240;&#23376;&#30340;&#39640;&#26031;&#20998;&#24067;&#30340;&#21464;&#20998;&#36924;&#36817;&#26041;&#27861;&#65292;&#32467;&#21512;&#21516;&#26679;&#39640;&#25928;&#30340;SIC&#32422;&#26463;&#30340;Kullback-Leibler&#26368;&#20248;&#20808;&#39564;&#36924;&#36817;&#65292;&#24182;&#22312;&#29305;&#23450;SIC&#25490;&#24207;&#21644;&#31232;&#30095;&#27169;&#24335;&#19979;&#65292;&#23454;&#29616;&#23545;&#28508;&#22312;&#39640;&#26031;&#36807;&#31243;&#30340;&#39640;&#24230;&#20934;&#30830;&#20808;&#39564;&#21644;&#21518;&#39564;&#36924;&#36817;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#31867;&#20284;&#35745;&#31639;&#22797;&#26434;&#24230;&#19979;&#26356;&#20934;&#30830;&#22320;&#39044;&#27979;&#24179;&#31283;&#26680;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#23454;&#29616;&#21487;&#25193;&#23637;&#21644;&#20934;&#30830;&#30340;&#28508;&#22312;&#39640;&#26031;&#36807;&#31243;&#25512;&#26029;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#19968;&#26063;&#20855;&#26377;&#31232;&#30095;&#36870;Cholesky&#65288;SIC&#65289;&#22240;&#23376;&#30340;&#39640;&#26031;&#20998;&#24067;&#30340;&#21464;&#20998;&#36924;&#36817;&#12290;&#25105;&#20204;&#23558;&#35813;&#21464;&#20998;&#36924;&#36817;&#30340;&#21518;&#39564;&#19982;&#31867;&#20284;&#30340;&#39640;&#25928;SIC&#32422;&#26463;&#30340;Kullback-Leibler&#26368;&#20248;&#20808;&#39564;&#36924;&#36817;&#30456;&#32467;&#21512;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#37325;&#28857;&#30740;&#31350;&#20102;&#29305;&#23450;&#30340;SIC&#25490;&#24207;&#21644;&#22522;&#20110;&#26368;&#36817;&#37051;&#30340;&#31232;&#30095;&#27169;&#24335;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#39640;&#24230;&#20934;&#30830;&#30340;&#20808;&#39564;&#21644;&#21518;&#39564;&#36924;&#36817;&#12290;&#23545;&#20110;&#36825;&#31181;&#35774;&#32622;&#65292;&#25105;&#20204;&#30340;&#21464;&#20998;&#36924;&#36817;&#21487;&#20197;&#36890;&#36807;&#27599;&#27425;&#36845;&#20195;&#30340;&#23545;&#25968;&#22810;&#39033;&#24335;&#26102;&#38388;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26469;&#35745;&#31639;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#25968;&#23383;&#27604;&#36739;&#65292;&#34920;&#26126;&#25152;&#25552;&#20986;&#30340;&#21452;Kullback-Leibler&#26368;&#20248;&#39640;&#26031;&#36807;&#31243;&#36924;&#36817;&#65288;DKLGP&#65289;&#26377;&#26102;&#21487;&#20197;&#27604;&#35832;&#22914;&#35825;&#23548;&#28857;&#21644;&#22343;&#20540;&#22330;&#36924;&#36817;&#31561;&#22312;&#31867;&#20284;&#35745;&#31639;&#22797;&#26434;&#24230;&#19979;&#26356;&#20934;&#30830;&#22320;&#39044;&#27979;&#24179;&#31283;&#26680;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
To achieve scalable and accurate inference for latent Gaussian processes, we propose a variational approximation based on a family of Gaussian distributions whose covariance matrices have sparse inverse Cholesky (SIC) factors. We combine this variational approximation of the posterior with a similar and efficient SIC-restricted Kullback-Leibler-optimal approximation of the prior. We then focus on a particular SIC ordering and nearest-neighbor-based sparsity pattern resulting in highly accurate prior and posterior approximations. For this setting, our variational approximation can be computed via stochastic gradient descent in polylogarithmic time per iteration. We provide numerical comparisons showing that the proposed double-Kullback-Leibler-optimal Gaussian-process approximation (DKLGP) can sometimes be vastly more accurate for stationary kernels than alternative approaches such as inducing-point and mean-field approximations at similar computational complexity.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#25968;&#25454;&#29420;&#31435;&#20998;&#35299;&#37319;&#26679;&#35268;&#21017;&#65292;&#35777;&#26126;&#20102;&#38543;&#26426;&#26641;&#20998;&#35299;&#37319;&#26679;&#22120;&#26377;&#21033;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#20419;&#36827;&#20102;&#38543;&#26426;&#20998;&#35299;&#19978;&#32622;&#20449;&#24230;&#31639;&#27861;&#65288;RDUCB&#65289;&#30340;&#21457;&#23637;&#12290;</title><link>http://arxiv.org/abs/2301.12844</link><description>&lt;p&gt;
&#22312;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#65292;&#38543;&#26426;&#20998;&#35299;&#26159;&#21542;&#36275;&#22815;&#65311;
&lt;/p&gt;
&lt;p&gt;
Are Random Decompositions all we need in High Dimensional Bayesian Optimisation?. (arXiv:2301.12844v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12844
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25968;&#25454;&#29420;&#31435;&#20998;&#35299;&#37319;&#26679;&#35268;&#21017;&#65292;&#35777;&#26126;&#20102;&#38543;&#26426;&#26641;&#20998;&#35299;&#37319;&#26679;&#22120;&#26377;&#21033;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#20419;&#36827;&#20102;&#38543;&#26426;&#20998;&#35299;&#19978;&#32622;&#20449;&#24230;&#31639;&#27861;&#65288;RDUCB&#65289;&#30340;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#26114;&#36149;&#30340;&#40657;&#30418;&#20989;&#25968;&#20998;&#35299;&#26377;&#26395;&#23558;&#36125;&#21494;&#26031;&#20248;&#21270;&#25193;&#23637;&#21040;&#39640;&#32500;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#25216;&#26415;&#30340;&#25104;&#21151;&#21462;&#20915;&#20110;&#25214;&#21040;&#20934;&#30830;&#34920;&#31034;&#40657;&#30418;&#20989;&#25968;&#30340;&#36866;&#24403;&#20998;&#35299;&#12290;&#25105;&#20204;&#30740;&#31350;&#26412;&#25991;&#20013;&#20851;&#20110;&#25968;&#25454;&#29420;&#31435;&#20998;&#35299;&#37319;&#26679;&#35268;&#21017;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22522;&#20110;&#25968;&#25454;&#23398;&#20064;&#20998;&#35299;&#21487;&#20197;&#24456;&#23481;&#26131;&#22320;&#34987;&#35823;&#23548;&#21040;&#23616;&#37096;&#20998;&#35299;&#19978;&#65292;&#32780;&#36825;&#20123;&#20998;&#35299;&#22312;&#25972;&#20010;&#25628;&#32034;&#31354;&#38388;&#20013;&#24182;&#19981;&#20934;&#30830;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#27491;&#24335;&#35777;&#26126;&#20102;&#22522;&#20110;&#38543;&#26426;&#26641;&#30340;&#20998;&#35299;&#37319;&#26679;&#22120;&#23637;&#29616;&#20102;&#26377;&#21033;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#21487;&#20197;&#26377;&#25928;&#26435;&#34913;&#26368;&#22823;&#20449;&#24687;&#22686;&#30410;&#21644;&#23454;&#38469;&#40657;&#30418;&#20989;&#25968;&#21450;&#20854;&#20998;&#35299;&#20043;&#38388;&#30340;&#20989;&#25968;&#22833;&#37197;&#12290;&#36825;&#20123;&#32467;&#26524;&#20419;&#36827;&#20102;&#38543;&#26426;&#20998;&#35299;&#19978;&#32622;&#20449;&#24230;&#31639;&#27861;&#65288;RDUCB&#65289;&#30340;&#21457;&#23637;&#65292;&#35813;&#31639;&#27861;&#26131;&#20110;&#23454;&#29616;&#65292;&#20960;&#20046;&#26159;&#21363;&#25554;&#21363;&#29992;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning decompositions of expensive-to-evaluate black-box functions promises to scale Bayesian optimisation (BO) to high-dimensional problems. However, the success of these techniques depends on finding proper decompositions that accurately represent the black-box. While previous works learn those decompositions based on data, we investigate data-independent decomposition sampling rules in this paper. We find that data-driven learners of decompositions can be easily misled towards local decompositions that do not hold globally across the search space. Then, we formally show that a random tree-based decomposition sampler exhibits favourable theoretical guarantees that effectively trade off maximal information gain and functional mismatch between the actual black-box and its surrogate as provided by the decomposition. Those results motivate the development of the random decomposition upper-confidence bound algorithm (RDUCB) that is straightforward to implement - (almost) plug-and-play -
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23398;&#20064;&#30740;&#31350;&#32676;&#20307;&#20013;&#30340;&#20849;&#20139;&#21644;&#29305;&#23450;&#20110;&#32452;&#30340;&#20449;&#24687;&#65292;&#20351;&#29992;Causal Multi-task Deep Ensemble&#65288;CMDE&#65289;&#30340;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#22320;&#22788;&#29702;&#39640;&#32500;&#21644;&#22810;&#27169;&#24577;&#21327;&#21464;&#37327;&#65292;&#24182;&#25552;&#20379;&#22240;&#26524;&#25928;&#24212;&#30340;&#28857;&#20272;&#35745;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2301.11351</link><description>&lt;p&gt;
&#20351;&#29992;&#22810;&#20219;&#21153;&#28145;&#24230;&#38598;&#21512;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;
Estimating Causal Effects using a Multi-task Deep Ensemble. (arXiv:2301.11351v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11351
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23398;&#20064;&#30740;&#31350;&#32676;&#20307;&#20013;&#30340;&#20849;&#20139;&#21644;&#29305;&#23450;&#20110;&#32452;&#30340;&#20449;&#24687;&#65292;&#20351;&#29992;Causal Multi-task Deep Ensemble&#65288;CMDE&#65289;&#30340;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#22320;&#22788;&#29702;&#39640;&#32500;&#21644;&#22810;&#27169;&#24577;&#21327;&#21464;&#37327;&#65292;&#24182;&#25552;&#20379;&#22240;&#26524;&#25928;&#24212;&#30340;&#28857;&#20272;&#35745;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24050;&#26377;&#35768;&#22810;&#26041;&#27861;&#34987;&#25552;&#20986;&#26469;&#29992;&#20110;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#65292;&#28982;&#32780;&#24456;&#23569;&#26377;&#26041;&#27861;&#21487;&#20197;&#22788;&#29702;&#20687;&#22270;&#20687;&#31561;&#20855;&#26377;&#22797;&#26434;&#32467;&#26500;&#30340;&#25968;&#25454;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Causal Multi-task Deep Ensemble (CMDE)&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#23398;&#20064;&#30740;&#31350;&#32676;&#20307;&#20013;&#30340;&#20849;&#20139;&#21644;&#29305;&#23450;&#20110;&#32452;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#35777;&#26126;&#65292;&#35777;&#26126;&#20102;CMDE&#19982;&#20808;&#39564;&#20013;&#30340;&#22810;&#20219;&#21153;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#20855;&#26377;&#21516;&#31561;&#25928;&#26524;&#12290;&#19982;&#22810;&#20219;&#21153;GP&#30456;&#27604;&#65292;CMDE&#21487;&#20197;&#26377;&#25928;&#22320;&#22788;&#29702;&#39640;&#32500;&#21644;&#22810;&#27169;&#24577;&#21327;&#21464;&#37327;&#65292;&#24182;&#25552;&#20379;&#22240;&#26524;&#25928;&#24212;&#30340;&#28857;&#20272;&#35745;&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#21508;&#31181;&#31867;&#22411;&#30340;&#25968;&#25454;&#38598;&#21644;&#20219;&#21153;&#20013;&#21457;&#29616;CMDE&#22312;&#22823;&#22810;&#25968;&#20219;&#21153;&#19978;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
A number of methods have been proposed for causal effect estimation, yet few have demonstrated efficacy in handling data with complex structures, such as images. To fill this gap, we propose Causal Multi-task Deep Ensemble (CMDE), a novel framework that learns both shared and group-specific information from the study population. We provide proofs demonstrating equivalency of CDME to a multi-task Gaussian process (GP) with a coregionalization kernel a priori. Compared to multi-task GP, CMDE efficiently handles high-dimensional and multi-modal covariates and provides pointwise uncertainty estimates of causal effects. We evaluate our method across various types of datasets and tasks and find that CMDE outperforms state-of-the-art methods on a majority of these tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#26368;&#22823;&#26368;&#20248;&#24615;&#36793;&#38469;&#8221;&#30340;&#26032;&#26041;&#27861;&#26469;&#35299;&#20915;&#39044;&#27979;-&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#19979;&#28216;&#20248;&#21270;&#30340;&#26368;&#20248;&#24615;&#26465;&#20214;&#35774;&#35745;&#26426;&#22120;&#23398;&#20064;&#25439;&#22833;&#20989;&#25968;&#65292;&#20860;&#20855;&#35745;&#31639;&#25928;&#29575;&#21644;&#36739;&#22909;&#30340;&#29702;&#35770;&#24615;&#36136;&#65292;&#32780;&#19988;&#21482;&#38656;&#35201;&#35757;&#32451;&#25968;&#25454;&#20013;&#26368;&#20248;&#35299;&#30340;&#35266;&#27979;&#20540;&#12290;</title><link>http://arxiv.org/abs/2301.11260</link><description>&lt;p&gt;
&#26368;&#22823;&#26368;&#20248;&#24615;&#36793;&#38469;&#65306;&#19978;&#19979;&#25991;&#32447;&#24615;&#35268;&#21010;&#21644;&#36870;&#32447;&#24615;&#35268;&#21010;&#30340;&#32479;&#19968;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Maximum Optimality Margin: A Unified Approach for Contextual Linear Programming and Inverse Linear Programming. (arXiv:2301.11260v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11260
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#26368;&#22823;&#26368;&#20248;&#24615;&#36793;&#38469;&#8221;&#30340;&#26032;&#26041;&#27861;&#26469;&#35299;&#20915;&#39044;&#27979;-&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#19979;&#28216;&#20248;&#21270;&#30340;&#26368;&#20248;&#24615;&#26465;&#20214;&#35774;&#35745;&#26426;&#22120;&#23398;&#20064;&#25439;&#22833;&#20989;&#25968;&#65292;&#20860;&#20855;&#35745;&#31639;&#25928;&#29575;&#21644;&#36739;&#22909;&#30340;&#29702;&#35770;&#24615;&#36136;&#65292;&#32780;&#19988;&#21482;&#38656;&#35201;&#35757;&#32451;&#25968;&#25454;&#20013;&#26368;&#20248;&#35299;&#30340;&#35266;&#27979;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39044;&#27979;-&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#20219;&#21153;&#30340;&#36755;&#20986;&#29992;&#20316;&#26576;&#20010;&#19979;&#28216;&#20248;&#21270;&#38382;&#39064;&#65288;&#20363;&#22914;&#32447;&#24615;&#35268;&#21010;&#30340;&#30446;&#26631;&#31995;&#25968;&#21521;&#37327;&#65289;&#30340;&#36755;&#20837;&#12290;&#35813;&#38382;&#39064;&#20063;&#34987;&#31216;&#20026;&#39044;&#27979;&#20998;&#26512;&#25110;&#19978;&#19979;&#25991;&#32447;&#24615;&#35268;&#21010;&#12290;&#29616;&#26377;&#26041;&#27861;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#35201;&#20040;&#21463;&#21040;&#65288;i&#65289;&#20248;&#21270;&#19981;&#21487;&#35299;&#24615;&#65288;&#38750;&#20984;&#30446;&#26631;&#20989;&#25968;&#65289;/&#32479;&#35745;&#25928;&#29575;&#20302;&#19979;&#65288;&#23376;&#20248;&#19968;&#33324;&#21270;&#30028;&#38480;&#65289;&#30340;&#22256;&#25200;&#65292;&#35201;&#20040;&#35201;&#27714;&#24378;&#26465;&#20214;&#65288;&#20363;&#22914;&#27809;&#26377;&#32422;&#26463;&#25110;&#25439;&#22833;&#26657;&#20934;&#65289;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#26368;&#22823;&#26368;&#20248;&#24615;&#36793;&#38469;&#8221;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#19979;&#28216;&#20248;&#21270;&#30340;&#26368;&#20248;&#24615;&#26465;&#20214;&#35774;&#35745;&#26426;&#22120;&#23398;&#20064;&#25439;&#22833;&#20989;&#25968;&#12290;&#26368;&#22823;&#36793;&#38469;&#20844;&#24335;&#26082;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#65292;&#21448;&#20855;&#26377;&#22909;&#30340;&#23398;&#20064;&#31243;&#24207;&#30340;&#29702;&#35770;&#24615;&#36136;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26032;&#26041;&#27861;&#21482;&#38656;&#35201;&#35757;&#32451;&#25968;&#25454;&#20013;&#26368;&#20248;&#35299;&#30340;&#35266;&#27979;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the predict-then-optimize problem where the output of a machine learning prediction task is used as the input of some downstream optimization problem, say, the objective coefficient vector of a linear program. The problem is also known as predictive analytics or contextual linear programming. The existing approaches largely suffer from either (i) optimization intractability (a non-convex objective function)/statistical inefficiency (a suboptimal generalization bound) or (ii) requiring strong condition(s) such as no constraint or loss calibration. We develop a new approach to the problem called \textit{maximum optimality margin} which designs the machine learning loss function by the optimality condition of the downstream optimization. The max-margin formulation enjoys both computational efficiency and good theoretical properties for the learning procedure. More importantly, our new approach only needs the observations of the optimal solution in the training data
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23398;&#20064;Boltzmann&#23494;&#24230;&#21464;&#24418;&#36712;&#36857;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#36890;&#36807;&#25554;&#20540;&#33021;&#37327;&#20989;&#25968;&#31561;&#23454;&#29616;Boltzmann&#23494;&#24230;&#30340;&#21464;&#24418;&#65292;&#28982;&#21518;&#25214;&#21040;&#19968;&#20010;&#26102;&#38388;&#20381;&#36182;&#21521;&#37327;&#22330;&#65292;&#23558;&#26679;&#26412;&#20174;&#19968;&#20010;&#20998;&#24067;&#36716;&#31227;&#21040;&#21478;&#19968;&#20010;&#20998;&#24067;&#65292;&#20854;&#34920;&#29616;&#22312;&#39640;&#26031;&#28151;&#21512;&#21644;&#37327;&#23376;&#21147;&#23398;&#31890;&#23376;&#30340;Boltzmann&#23494;&#24230;&#19978;&#27604;KL-&#21453;&#25955;&#24230;&#26356;&#20855;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2301.07388</link><description>&lt;p&gt;
&#23398;&#20064;Boltzmann&#23494;&#24230;&#30340;&#21464;&#24418;&#36712;&#36857;
&lt;/p&gt;
&lt;p&gt;
Learning Deformation Trajectories of Boltzmann Densities. (arXiv:2301.07388v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.07388
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23398;&#20064;Boltzmann&#23494;&#24230;&#21464;&#24418;&#36712;&#36857;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#36890;&#36807;&#25554;&#20540;&#33021;&#37327;&#20989;&#25968;&#31561;&#23454;&#29616;Boltzmann&#23494;&#24230;&#30340;&#21464;&#24418;&#65292;&#28982;&#21518;&#25214;&#21040;&#19968;&#20010;&#26102;&#38388;&#20381;&#36182;&#21521;&#37327;&#22330;&#65292;&#23558;&#26679;&#26412;&#20174;&#19968;&#20010;&#20998;&#24067;&#36716;&#31227;&#21040;&#21478;&#19968;&#20010;&#20998;&#24067;&#65292;&#20854;&#34920;&#29616;&#22312;&#39640;&#26031;&#28151;&#21512;&#21644;&#37327;&#23376;&#21147;&#23398;&#31890;&#23376;&#30340;Boltzmann&#23494;&#24230;&#19978;&#27604;KL-&#21453;&#25955;&#24230;&#26356;&#20855;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36830;&#32493;&#26631;&#20934;&#21270;&#27969;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#27809;&#26377;&#26679;&#26412;&#20294;&#23384;&#22312;&#33021;&#37327;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#20351;&#29992;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#33021;&#37327;&#20989;&#25968;$f_1$&#21644;&#24191;&#20041;&#39640;&#26031;&#20989;&#25968;$f_0$&#20043;&#38388;&#30340;&#39044;&#23450;&#25110;&#23398;&#20064;&#25554;&#20540;$f_t$&#12290;&#33021;&#37327;&#20989;&#25968;&#30340;&#25554;&#20540;&#24341;&#36215;Boltzmann&#23494;&#24230;$p_t\propto e^{-f_t}$&#30340;&#25554;&#20540;&#65292;&#25105;&#20204;&#26088;&#22312;&#25214;&#21040;&#19968;&#20010;&#27839;&#30528;&#26063;$p_t$&#30340;&#26102;&#38388;&#20381;&#36182;&#21521;&#37327;&#22330;$V_t$&#65292;&#23558;&#26679;&#26412;&#20174;&#19968;&#20010;&#20998;&#24067;&#36716;&#31227;&#21040;&#21478;&#19968;&#20010;&#20998;&#24067;&#12290;&#23558;&#26679;&#26412;&#27839;&#30528;&#26063;$p_t$&#20174;&#19968;&#20010;&#20998;&#24067;&#36716;&#31227;&#21040;&#21478;&#19968;&#20010;&#20998;&#24067;&#30340;&#26465;&#20214;&#21487;&#20197;&#36716;&#21270;&#20026;$V_t$&#21644;$f_t$&#20043;&#38388;&#30340;PDE&#65292;&#25105;&#20204;&#20248;&#21270;$V_t$&#21644;$f_t$&#20197;&#28385;&#36275;&#27492;PDE&#12290;&#25105;&#20204;&#22312;&#39640;&#26031;&#28151;&#21512;&#21644;&#21452;&#20117;&#21183;&#30340;&#37327;&#23376;&#21147;&#23398;&#31890;&#23376;&#30340;Boltzmann&#23494;&#24230;&#19978;&#23454;&#39564;&#27604;&#36739;&#20102;&#25152;&#25552;&#20986;&#30340;&#35757;&#32451;&#30446;&#26631;&#19982;KL-&#21453;&#25955;&#24230;&#30340;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a training objective for continuous normalizing flows that can be used in the absence of samples but in the presence of an energy function. Our method relies on either a prescribed or a learnt interpolation $f_t$ of energy functions between the target energy $f_1$ and the energy function of a generalized Gaussian $f_0(x) = ||x/\sigma||_p^p$. The interpolation of energy functions induces an interpolation of Boltzmann densities $p_t \propto e^{-f_t}$ and we aim to find a time-dependent vector field $V_t$ that transports samples along the family $p_t$ of densities. The condition of transporting samples along the family $p_t$ can be translated to a PDE between $V_t$ and $f_t$ and we optimize $V_t$ and $f_t$ to satisfy this PDE. We experimentally compare the proposed training objective to the reverse KL-divergence on Gaussian mixtures and on the Boltzmann density of a quantum mechanical particle in a double-well potential.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#23558;&#27010;&#29575;&#30475;&#20316;&#30456;&#23545;&#24230;&#37327;&#30340;&#35266;&#28857;&#65292;&#24314;&#31435;&#20102;&#26377;&#38480;&#32467;&#26524;&#31354;&#38388;&#19978;&#30456;&#23545;&#27010;&#29575;&#20989;&#25968;&#30340;&#20844;&#29702;&#21270;&#65292;&#25552;&#20379;&#20102;&#20854;&#23454;&#20363;&#21644;&#32452;&#21512;&#31995;&#32479;&#65292;&#24182;&#35752;&#35770;&#20102;&#30456;&#23545;&#36125;&#21494;&#26031;&#25512;&#26029;&#21450;&#20854;&#25968;&#23383;&#23454;&#29616;&#65292;&#35777;&#26126;&#20102;&#30456;&#23545;&#27010;&#29575;&#31354;&#38388;&#30340;&#25299;&#25169;&#38381;&#21253;&#65292;&#31361;&#26174;&#20102;&#20854;&#22312;&#26497;&#38480;&#19979;&#20445;&#30041;&#20449;&#24687;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2212.14555</link><description>&lt;p&gt;
&#26377;&#38480;&#32467;&#26524;&#31354;&#38388;&#19978;&#30340;&#30456;&#23545;&#27010;&#29575;&#65306;&#20854;&#20844;&#29702;&#21270;&#12289;&#23646;&#24615;&#21644;&#24212;&#29992;&#30340;&#31995;&#32479;&#32771;&#23519;
&lt;/p&gt;
&lt;p&gt;
Relative Probability on Finite Outcome Spaces: A Systematic Examination of its Axiomatization, Properties, and Applications. (arXiv:2212.14555v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.14555
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#23558;&#27010;&#29575;&#30475;&#20316;&#30456;&#23545;&#24230;&#37327;&#30340;&#35266;&#28857;&#65292;&#24314;&#31435;&#20102;&#26377;&#38480;&#32467;&#26524;&#31354;&#38388;&#19978;&#30456;&#23545;&#27010;&#29575;&#20989;&#25968;&#30340;&#20844;&#29702;&#21270;&#65292;&#25552;&#20379;&#20102;&#20854;&#23454;&#20363;&#21644;&#32452;&#21512;&#31995;&#32479;&#65292;&#24182;&#35752;&#35770;&#20102;&#30456;&#23545;&#36125;&#21494;&#26031;&#25512;&#26029;&#21450;&#20854;&#25968;&#23383;&#23454;&#29616;&#65292;&#35777;&#26126;&#20102;&#30456;&#23545;&#27010;&#29575;&#31354;&#38388;&#30340;&#25299;&#25169;&#38381;&#21253;&#65292;&#31361;&#26174;&#20102;&#20854;&#22312;&#26497;&#38480;&#19979;&#20445;&#30041;&#20449;&#24687;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#23558;&#27010;&#29575;&#30475;&#20316;&#30456;&#23545;&#24230;&#37327;&#32780;&#38750;&#32477;&#23545;&#24230;&#37327;&#30340;&#35266;&#28857;&#12290;&#20026;&#20102;&#35777;&#26126;&#36825;&#19968;&#27010;&#24565;&#65292;&#25105;&#20204;&#23558;&#28966;&#28857;&#25918;&#22312;&#26377;&#38480;&#32467;&#26524;&#31354;&#38388;&#19978;&#65292;&#24182;&#24314;&#31435;&#20102;&#19977;&#20010;&#22522;&#26412;&#20844;&#29702;&#65292;&#20197;&#30830;&#31435;&#30456;&#23545;&#27010;&#29575;&#20989;&#25968;&#30340;&#35201;&#27714;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#32452;&#36825;&#20123;&#20989;&#25968;&#30340;&#23454;&#20363;&#24211;&#21644;&#19968;&#20010;&#32452;&#21512;&#31995;&#32479;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#30456;&#23545;&#36125;&#21494;&#26031;&#25512;&#26029;&#21450;&#20854;&#25968;&#23383;&#23454;&#29616;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#30456;&#23545;&#27010;&#29575;&#31354;&#38388;&#30340;&#25299;&#25169;&#38381;&#21253;&#65292;&#31361;&#26174;&#20102;&#20854;&#22312;&#26497;&#38480;&#19979;&#20445;&#30041;&#20449;&#24687;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work proposes a view of probability as a relative measure rather than an absolute one. To demonstrate this concept, we focus on finite outcome spaces and develop three fundamental axioms that establish requirements for relative probability functions. We then provide a library of examples of these functions and a system for composing them. Additionally, we discuss a relative version of Bayesian inference and its digital implementation. Finally, we prove the topological closure of the relative probability space, highlighting its ability to preserve information under limits.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#24179;&#28369;&#26799;&#24230;&#19979;&#38477;&#19978;&#21319;&#27861; (DSGDA)&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#38750;&#20984;-&#38750;&#20985;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#65292;&#24182;&#19988;&#33021;&#22815;&#20840;&#23616;&#25910;&#25947;&#24182;&#28040;&#38500;&#26497;&#38480;&#29615;&#12290;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#65292;DSGDA &#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#36798;&#21040;&#20102;&#25991;&#29486;&#20013;&#21333;&#24490;&#29615;&#31639;&#27861;&#30340;&#26368;&#20339;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2212.12978</link><description>&lt;p&gt;
&#21452;&#37325;&#24179;&#28369;GDA&#65306;&#29992;&#20110;&#38750;&#20984;-&#38750;&#20985;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#30340;&#20840;&#23616;&#25910;&#25947;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Doubly Smoothed GDA: Global Convergent Algorithm for Constrained Nonconvex-Nonconcave Minimax Optimization. (arXiv:2212.12978v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.12978
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#24179;&#28369;&#26799;&#24230;&#19979;&#38477;&#19978;&#21319;&#27861; (DSGDA)&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#38750;&#20984;-&#38750;&#20985;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#65292;&#24182;&#19988;&#33021;&#22815;&#20840;&#23616;&#25910;&#25947;&#24182;&#28040;&#38500;&#26497;&#38480;&#29615;&#12290;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#65292;DSGDA &#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#36798;&#21040;&#20102;&#25991;&#29486;&#20013;&#21333;&#24490;&#29615;&#31639;&#27861;&#30340;&#26368;&#20339;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#20984;-&#38750;&#20985;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#36817;&#24180;&#26469;&#21463;&#21040;&#20102;&#24191;&#27867;&#30340;&#20851;&#27880;&#65292;&#20854;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#31639;&#27861;&#19981;&#33021;&#20445;&#35777;&#20840;&#23616;&#25910;&#25947;&#65292;&#29978;&#33267;&#20250;&#36973;&#21463;&#26497;&#38480;&#29615;&#30340;&#22256;&#25200;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21333;&#24490;&#29615;&#31639;&#27861;&#65292;&#31216;&#20026;&#21452;&#37325;&#24179;&#28369;&#26799;&#24230;&#19979;&#38477;&#19978;&#21319;&#27861; (DSGDA)&#65292;&#23427;&#33021;&#22815;&#33258;&#28982;&#22320;&#24179;&#34913;&#21407;&#22987;&#19982;&#23545;&#20598;&#26356;&#26032;&#65292;&#24182;&#19988;&#23558;&#26497;&#20854;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38750;&#20984;-&#38750;&#20985;&#20363;&#23376;&#20013;&#30340;&#26497;&#38480;&#29615;&#28040;&#38500;&#65292;&#21253;&#25324; Forsaken&#65292;Bilinearly-coupled minimax&#65292;Sixth-order polynomial &#21644; PolarGame&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#65292;&#22312;&#19968;&#20010;&#21333;&#20391;&#30340; $\theta\in(0,1)$ Kurdyka-\L{}ojasiewicz&#26465;&#20214;&#65288;&#25110;&#20984;&#21407;&#22987;/&#20985;&#23545;&#20598;&#20989;&#25968;&#65289;&#19979;&#65292;DSGDA &#21487;&#20197;&#25214;&#21040;&#19968;&#20010;&#28216;&#25103;&#24179;&#34913;&#28857;&#65292;&#24182;&#19988;&#20855;&#26377;&#36845;&#20195;&#22797;&#26434;&#24230; $\mathcal{O}(\epsilon^{-2\max\{2\theta,1\}})$&#65288;&#25110; $\mathcal{O}(\epsilon^{-4})$&#65289;&#65292;&#36825;&#20123;&#19982;&#25991;&#29486;&#20013;&#21333;&#24490;&#29615;&#31639;&#27861;&#30340;&#26368;&#20339;&#32467;&#26524;&#30456;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nonconvex-nonconcave minimax optimization has received intense attention over the last decade due to its broad applications in machine learning. Unfortunately, most existing algorithms cannot be guaranteed to converge globally and even suffer from limit cycles. To address this issue, we propose a novel single-loop algorithm called doubly smoothed gradient descent ascent method (DSGDA), which naturally balances the primal and dual updates. The proposed DSGDA can get rid of limit cycles in various challenging nonconvex-nonconcave examples in the literature, including Forsaken, Bilinearly-coupled minimax, Sixth-order polynomial, and PolarGame. We further show that under an one-sided Kurdyka-\L{}ojasiewicz condition with exponent $\theta\in(0,1)$ (resp. convex primal/concave dual function), DSGDA can find a game-stationary point with an iteration complexity of $\mathcal{O}(\epsilon^{-2\max\{2\theta,1\}})$ (resp. $\mathcal{O}(\epsilon^{-4})$). These match the best results for single-loop al
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#19979;&#30340;&#32447;&#24615;&#20998;&#31867;&#22120;&#65292;&#20998;&#26512;&#20102;&#23545;&#25239;&#40065;&#26834;&#24615;&#23545;&#20934;&#30830;&#24615;&#19981;&#24179;&#34913;&#30340;&#24433;&#21709;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#31283;&#23450;&#20998;&#24067;&#30340;&#19968;&#33324;&#23478;&#26063;&#20013;&#20063;&#23384;&#22312;&#31867;&#20284;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2211.15762</link><description>&lt;p&gt;
&#29702;&#35299;&#23545;&#20934;&#30830;&#24615;&#19981;&#24179;&#34913;&#24433;&#21709;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Understanding the Impact of Adversarial Robustness on Accuracy Disparity. (arXiv:2211.15762v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.15762
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#19979;&#30340;&#32447;&#24615;&#20998;&#31867;&#22120;&#65292;&#20998;&#26512;&#20102;&#23545;&#25239;&#40065;&#26834;&#24615;&#23545;&#20934;&#30830;&#24615;&#19981;&#24179;&#34913;&#30340;&#24433;&#21709;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#31283;&#23450;&#20998;&#24067;&#30340;&#19968;&#33324;&#23478;&#26063;&#20013;&#20063;&#23384;&#22312;&#31867;&#20284;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#38271;&#26399;&#20197;&#26469;&#24050;&#32463;&#20174;&#32463;&#39564;&#19978;&#35266;&#23519;&#21040;&#23545;&#25239;&#40065;&#26834;&#24615;&#21487;&#33021;&#19982;&#26631;&#20934;&#20934;&#30830;&#24615;&#23384;&#22312;&#19968;&#20123;&#30683;&#30462;&#65292;&#24182;&#19988;&#21487;&#33021;&#23545;&#19981;&#21516;&#31867;&#21035;&#20135;&#29983;&#19981;&#24179;&#31561;&#24433;&#21709;&#65292;&#20294;&#23427;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#65292;&#21363;&#36825;&#20123;&#35266;&#23519;&#26377;&#22810;&#22823;&#31243;&#24230;&#30340;&#20445;&#25345;&#65292;&#20197;&#21450;&#31867;&#21035;&#19981;&#24179;&#34913;&#22312;&#20854;&#20013;&#25198;&#28436;&#20160;&#20040;&#26679;&#30340;&#35282;&#33394;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35797;&#22270;&#36890;&#36807;&#26356;&#28145;&#20837;&#22320;&#30740;&#31350;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#19979;&#30340;&#32447;&#24615;&#20998;&#31867;&#22120;&#26469;&#29702;&#35299;&#36825;&#20010;&#20934;&#30830;&#24615;&#19981;&#24179;&#34913;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#23545;&#25239;&#40065;&#26834;&#24615;&#30340;&#24433;&#21709;&#20998;&#35299;&#25104;&#20004;&#37096;&#20998;&#65306;&#19968;&#37096;&#20998;&#26159;&#22240;&#20026;&#40065;&#26834;&#24615;&#32422;&#26463;&#32780;&#20250;&#38477;&#20302;&#25152;&#26377;&#31867;&#21035;&#30340;&#26631;&#20934;&#20934;&#30830;&#24615;&#32780;&#22266;&#26377;&#30340;&#24433;&#21709;&#65292;&#21478;&#19968;&#37096;&#20998;&#26159;&#30001;&#20110;&#31867;&#21035;&#19981;&#24179;&#34913;&#27604;&#29575;&#24341;&#36215;&#30340;&#65292;&#36825;&#23558;&#22686;&#21152;&#19982;&#26631;&#20934;&#35757;&#32451;&#30456;&#27604;&#30340;&#20934;&#30830;&#24615;&#24046;&#24322;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#34920;&#26126;&#36825;&#20123;&#24433;&#21709;&#36229;&#36234;&#20102;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65292;&#36890;&#36807;&#23558;&#25968;&#25454;&#27169;&#22411;&#25512;&#24191;&#21040;&#31283;&#23450;&#20998;&#24067;&#30340;&#19968;&#33324;&#23478;&#26063;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#34429;&#28982;&#23545;&#25239;&#40065;&#26834;&#24615;&#30340;&#32422;&#26463;&#19968;&#33268;&#20250;&#20943;&#23569;&#25152;&#26377;&#31867;&#21035;&#30340;&#26631;&#20934;&#20934;&#30830;&#24615;&#65292;&#20294;&#36890;&#24120;&#20250;&#22686;&#21152;&#23545;&#23569;&#25968;&#31867;&#21035;&#30340;&#20934;&#30830;&#24615;&#19981;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
While it has long been empirically observed that adversarial robustness may be at odds with standard accuracy and may have further disparate impacts on different classes, it remains an open question to what extent such observations hold and how the class imbalance plays a role within. In this paper, we attempt to understand this question of accuracy disparity by taking a closer look at linear classifiers under a Gaussian mixture model. We decompose the impact of adversarial robustness into two parts: an inherent effect that will degrade the standard accuracy on all classes due to the robustness constraint, and the other caused by the class imbalance ratio, which will increase the accuracy disparity compared to standard training. Furthermore, we also show that such effects extend beyond the Gaussian mixture model, by generalizing our data model to the general family of stable distributions. More specifically, we demonstrate that while the constraint of adversarial robustness consistentl
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#38646;&#38454;&#20132;&#26367;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#21644;&#38646;&#38454;&#26041;&#24046;&#20943;&#23569;&#20132;&#26367;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#19968;&#31867;&#38750;&#20984;&#38750;&#20985;&#30340;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#20998;&#21035;&#22312;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#29615;&#22659;&#19979;&#12290;&#23427;&#20204;&#26159;&#35299;&#20915;&#36825;&#31867;&#38382;&#39064;&#30340;&#31532;&#19968;&#21644;&#31532;&#20108;&#20010;&#36845;&#20195;&#22797;&#26434;&#24230;&#20445;&#35777;&#30340;&#38646;&#38454;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2211.13668</link><description>&lt;p&gt;
&#19968;&#31867;&#38750;&#20984;&#38750;&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#38646;&#38454;&#20132;&#26367;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Zeroth-Order Alternating Gradient Descent Ascent Algorithms for a Class of Nonconvex-Nonconcave Minimax Problems. (arXiv:2211.13668v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.13668
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#38646;&#38454;&#20132;&#26367;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#21644;&#38646;&#38454;&#26041;&#24046;&#20943;&#23569;&#20132;&#26367;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#19968;&#31867;&#38750;&#20984;&#38750;&#20985;&#30340;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#20998;&#21035;&#22312;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#29615;&#22659;&#19979;&#12290;&#23427;&#20204;&#26159;&#35299;&#20915;&#36825;&#31867;&#38382;&#39064;&#30340;&#31532;&#19968;&#21644;&#31532;&#20108;&#20010;&#36845;&#20195;&#22797;&#26434;&#24230;&#20445;&#35777;&#30340;&#38646;&#38454;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#19968;&#31867;&#38750;&#20984;&#38750;&#20985;&#30340;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#21363;NC-PL&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#20854;&#30446;&#26631;&#20989;&#25968;&#38024;&#23545;&#20869;&#37096;&#21464;&#37327;&#28385;&#36275;Polyak-L&#244;jasiewicz&#65288;PL&#65289;&#26465;&#20214;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#38646;&#38454;&#20132;&#26367;&#26799;&#24230;&#19979;&#38477;&#19978;&#21319;&#65288;ZO-AGDA&#65289;&#31639;&#27861;&#21644;&#38646;&#38454;&#26041;&#24046;&#20943;&#23569;&#20132;&#26367;&#26799;&#24230;&#19979;&#38477;&#19978;&#21319;&#65288;ZO-VRAGDA&#65289;&#31639;&#27861;&#65292;&#20998;&#21035;&#29992;&#20110;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#29615;&#22659;&#19979;&#35299;&#20915;NC-PL&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#12290;&#20351;&#29992;ZO-AGDA&#21644;ZO-VRAGDA&#31639;&#27861;&#24471;&#21040;NC-PL&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#949;-&#31283;&#23450;&#28857;&#25152;&#38656;&#30340;&#24635;&#20989;&#25968;&#20540;&#26597;&#35810;&#27425;&#25968;&#19978;&#30028;&#20998;&#21035;&#20026;O(&#949;^(-2))&#21644;O(&#949;^(-3))&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#23427;&#20204;&#26159;&#35299;&#20915;NC-PL&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#31532;&#19968;&#21644;&#31532;&#20108;&#20010;&#36845;&#20195;&#22797;&#26434;&#24230;&#20445;&#35777;&#30340;&#38646;&#38454;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider a class of nonconvex-nonconcave minimax problems, i.e., NC-PL minimax problems, whose objective functions satisfy the Polyak-\L ojasiewicz (PL) condition with respect to the inner variable. We propose a zeroth-order alternating gradient descent ascent (ZO-AGDA) algorithm and a zeroth-order variance reduced alternating gradient descent ascent (ZO-VRAGDA) algorithm for solving NC-PL minimax problem under the deterministic and the stochastic setting, respectively. The total number of function value queries to obtain an $\epsilon$-stationary point of ZO-AGDA and ZO-VRAGDA algorithm for solving NC-PL minimax problem is upper bounded by $\mathcal{O}(\varepsilon^{-2})$ and $\mathcal{O}(\varepsilon^{-3})$, respectively. To the best of our knowledge, they are the first two zeroth-order algorithms with the iteration complexity gurantee for solving NC-PL minimax problems.
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#20852;&#30340;&#22312;&#32447;&#38750;&#38543;&#26426;&#25511;&#21046;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#19968;&#32452;&#31574;&#30053;&#20013;&#23547;&#25214;&#20302;&#21518;&#24724;&#65292;&#33719;&#24471;&#23545;&#26368;&#20248;&#31574;&#30053;&#30340;&#36817;&#20284;&#12290;</title><link>http://arxiv.org/abs/2211.09619</link><description>&lt;p&gt;
&#22312;&#32447;&#38750;&#38543;&#26426;&#25511;&#21046;&#31616;&#20171;
&lt;/p&gt;
&lt;p&gt;
Introduction to Online Nonstochastic Control. (arXiv:2211.09619v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.09619
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#20852;&#30340;&#22312;&#32447;&#38750;&#38543;&#26426;&#25511;&#21046;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#19968;&#32452;&#31574;&#30053;&#20013;&#23547;&#25214;&#20302;&#21518;&#24724;&#65292;&#33719;&#24471;&#23545;&#26368;&#20248;&#31574;&#30053;&#30340;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#20852;&#30340;&#21160;&#24577;&#31995;&#32479;&#25511;&#21046;&#19982;&#21487;&#24494;&#24378;&#21270;&#23398;&#20064;&#33539;&#24335;&#8212;&#8212;&#22312;&#32447;&#38750;&#38543;&#26426;&#25511;&#21046;&#65292;&#24182;&#24212;&#29992;&#22312;&#32447;&#20984;&#20248;&#21270;&#21644;&#20984;&#26494;&#24347;&#25216;&#26415;&#24471;&#21040;&#20102;&#20855;&#26377;&#21487;&#35777;&#26126;&#20445;&#35777;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#26368;&#20339;&#21644;&#40065;&#26834;&#25511;&#21046;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#25104;&#26524;&#12290;&#19982;&#20854;&#20182;&#26694;&#26550;&#19981;&#21516;&#65292;&#35813;&#26041;&#27861;&#30340;&#30446;&#26631;&#26159;&#23545;&#25239;&#24615;&#25915;&#20987;&#65292;&#22312;&#26080;&#27861;&#39044;&#27979;&#25200;&#21160;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#22312;&#19968;&#32452;&#31574;&#30053;&#20013;&#23547;&#25214;&#20302;&#21518;&#24724;&#65292;&#33719;&#24471;&#23545;&#26368;&#20248;&#31574;&#30053;&#30340;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;
This text presents an introduction to an emerging paradigm in control of dynamical systems and differentiable reinforcement learning called online nonstochastic control. The new approach applies techniques from online convex optimization and convex relaxations to obtain new methods with provable guarantees for classical settings in optimal and robust control.  The primary distinction between online nonstochastic control and other frameworks is the objective. In optimal control, robust control, and other control methodologies that assume stochastic noise, the goal is to perform comparably to an offline optimal strategy. In online nonstochastic control, both the cost functions as well as the perturbations from the assumed dynamical model are chosen by an adversary. Thus the optimal policy is not defined a priori. Rather, the target is to attain low regret against the best policy in hindsight from a benchmark class of policies.  This objective suggests the use of the decision making frame
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;PAC-Bayesian&#26041;&#27861;&#20998;&#26512;&#31163;&#32447;&#24773;&#22659;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#26032;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#20248;&#21270;&#26032;&#30340;&#27867;&#21270;&#30028;&#38480;&#25552;&#20379;&#20102;&#20445;&#35777;&#65292;&#24182;&#22312;&#23454;&#38469;&#24773;&#22659;&#20013;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2210.13132</link><description>&lt;p&gt;
&#20855;&#26377;&#20445;&#35777;&#30340;PAC-Bayesian&#31163;&#32447;&#24773;&#22659;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
PAC-Bayesian Offline Contextual Bandits With Guarantees. (arXiv:2210.13132v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.13132
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;PAC-Bayesian&#26041;&#27861;&#20998;&#26512;&#31163;&#32447;&#24773;&#22659;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#26032;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#20248;&#21270;&#26032;&#30340;&#27867;&#21270;&#30028;&#38480;&#25552;&#20379;&#20102;&#20445;&#35777;&#65292;&#24182;&#22312;&#23454;&#38469;&#24773;&#22659;&#20013;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;PAC-Bayesian&#26041;&#27861;&#30340;&#31163;&#32447;&#24773;&#22659;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#12290;&#19982;&#20043;&#21069;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#35813;&#26041;&#27861;&#19981;&#26159;&#20174;&#38590;&#20197;&#22788;&#29702;&#25110;&#19981;&#20934;&#30830;&#30340;&#30028;&#38480;&#25512;&#23548;&#23398;&#20064;&#21407;&#21017;&#12290;&#25105;&#20204;&#36890;&#36807;PAC-Bayesian&#26041;&#27861;&#20998;&#26512;&#38382;&#39064;&#65292;&#23558;&#31574;&#30053;&#35299;&#37322;&#20026;&#20915;&#31574;&#35268;&#21017;&#30340;&#28151;&#21512;&#29289;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#25552;&#20986;&#26032;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#25552;&#20379;&#21487;&#35299;&#31639;&#27861;&#26469;&#20248;&#21270;&#23427;&#20204;&#12290;&#25105;&#20204;&#35777;&#26126;&#25152;&#24471;&#30028;&#38480;&#27604;&#31454;&#20105;&#23545;&#25163;&#26356;&#32039;&#65292;&#21487;&#20197;&#30452;&#25509;&#20248;&#21270;&#20197;&#22312;&#31163;&#32447;&#24773;&#20917;&#19979;&#33258;&#20449;&#22320;&#25913;&#36827;&#35760;&#24405;&#31574;&#30053;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23398;&#20064;&#24102;&#20445;&#35777;&#30340;&#31574;&#30053;&#65292;&#20351;&#29992;&#25152;&#26377;&#21487;&#29992;&#25968;&#25454;&#65292;&#24182;&#19981;&#38656;&#35201;&#22312;&#20445;&#30041;&#38598;&#19978;&#35843;&#25972;&#26356;&#22810;&#30340;&#36229;&#21442;&#25968;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22312;&#23454;&#38469;&#24773;&#26223;&#20013;&#25552;&#20379;&#24615;&#33021;&#20445;&#35777;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a new principled approach for off-policy learning in contextual bandits. Unlike previous work, our approach does not derive learning principles from intractable or loose bounds. We analyse the problem through the PAC-Bayesian lens, interpreting policies as mixtures of decision rules. This allows us to propose novel generalization bounds and provide tractable algorithms to optimize them. We prove that the derived bounds are tighter than their competitors, and can be optimized directly to confidently improve upon the logging policy offline. Our approach learns policies with guarantees, uses all available data and does not require tuning additional hyperparameters on held-out sets. We demonstrate through extensive experiments the effectiveness of our approach in providing performance guarantees in practical scenarios.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25289;&#26222;&#25289;&#26031;&#22686;&#24378;&#30340;&#20302;&#31209;&#24352;&#37327;&#26679;&#26465;&#20811;&#37324;&#37329;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#26377;&#38480;&#35266;&#27979;&#19979;&#36827;&#34892;&#22823;&#35268;&#27169;&#20132;&#36890;&#36895;&#24230;&#20272;&#35745;&#65292;&#20197;&#20174;&#19981;&#23436;&#25972;&#30340;&#25968;&#25454;&#20013;&#24674;&#22797;&#21487;&#20449;&#30340;&#20272;&#35745;&#20540;&#12290;</title><link>http://arxiv.org/abs/2210.11780</link><description>&lt;p&gt;
&#22522;&#20110;&#25289;&#26222;&#25289;&#26031;&#22686;&#24378;&#30340;&#20302;&#31209;&#24352;&#37327;&#26679;&#26465;&#20811;&#37324;&#37329;&#26041;&#27861;&#30340;&#31232;&#30095;&#20256;&#24863;&#22823;&#35268;&#27169;&#20132;&#36890;&#36895;&#24230;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Correlating sparse sensing for large-scale traffic speed estimation: A Laplacian-enhanced low-rank tensor kriging approach. (arXiv:2210.11780v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.11780
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25289;&#26222;&#25289;&#26031;&#22686;&#24378;&#30340;&#20302;&#31209;&#24352;&#37327;&#26679;&#26465;&#20811;&#37324;&#37329;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#26377;&#38480;&#35266;&#27979;&#19979;&#36827;&#34892;&#22823;&#35268;&#27169;&#20132;&#36890;&#36895;&#24230;&#20272;&#35745;&#65292;&#20197;&#20174;&#19981;&#23436;&#25972;&#30340;&#25968;&#25454;&#20013;&#24674;&#22797;&#21487;&#20449;&#30340;&#20272;&#35745;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20132;&#36890;&#36895;&#24230;&#26159;&#34920;&#24449;&#36947;&#36335;&#32593;&#32476;&#27969;&#21160;&#24615;&#30340;&#26680;&#24515;&#22240;&#32032;&#65292;&#35768;&#22810;&#20132;&#36890;&#24212;&#29992;&#31243;&#24207;&#37117;&#20381;&#36182;&#20110;&#23427;&#65292;&#22914;&#23454;&#26102;&#23548;&#33322;&#12289;&#21160;&#24577;&#36335;&#32447;&#35268;&#21010;&#21644;&#25317;&#22581;&#31649;&#29702;&#12290;&#20256;&#24863;&#21644;&#36890;&#20449;&#25216;&#26415;&#30340;&#24555;&#36895;&#36827;&#23637;&#20351;&#20132;&#36890;&#36895;&#24230;&#26816;&#27979;&#27604;&#20197;&#24448;&#20219;&#20309;&#26102;&#20505;&#37117;&#26356;&#21152;&#23481;&#26131;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#38745;&#24577;&#20256;&#24863;&#22120;&#30340;&#31232;&#30095;&#37096;&#32626;&#25110;&#31227;&#21160;&#20256;&#24863;&#22120;&#30340;&#20302;&#28183;&#36879;&#65292;&#26816;&#27979;&#21040;&#30340;&#36895;&#24230;&#26159;&#19981;&#23436;&#25972;&#30340;&#65292;&#24182;&#19988;&#36828;&#31163;&#20840;&#32593;&#20351;&#29992;&#12290;&#27492;&#22806;&#65292;&#30001;&#20110;&#21508;&#31181;&#21407;&#22240;&#20256;&#24863;&#22120;&#23481;&#26131;&#20986;&#29616;&#35823;&#24046;&#25110;&#32570;&#22833;&#25968;&#25454;&#65292;&#36825;&#20123;&#20256;&#24863;&#22120;&#26816;&#27979;&#21040;&#30340;&#36895;&#24230;&#20250;&#21464;&#24471;&#38750;&#24120;&#22024;&#26434;&#12290;&#22240;&#27492;&#65292;&#38656;&#35201;&#26377;&#25928;&#30340;&#25216;&#26415;&#20174;&#19981;&#23436;&#25972;&#30340;&#25968;&#25454;&#20013;&#24674;&#22797;&#21487;&#20449;&#30340;&#20272;&#35745;&#20540;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#23558;&#38382;&#39064;&#30830;&#23450;&#20026;&#19968;&#20010;&#26102;&#31354;&#20811;&#37324;&#37329;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#25289;&#26222;&#25289;&#26031;&#22686;&#24378;&#30340;&#20302;&#31209;&#24352;&#37327;&#23436;&#25104;&#65288;LETC&#65289;&#26694;&#26550;&#65292;&#20854;&#20855;&#26377;&#20302;&#31209;&#24615;&#21644;&#22810;&#32500;&#30456;&#20851;&#24615;&#65292;&#29992;&#20110;&#22312;&#26377;&#38480;&#35266;&#27979;&#19979;&#36827;&#34892;&#22823;&#35268;&#27169;&#20132;&#36890;&#36895;&#24230;&#20811;&#37324;&#37329;&#12290;
&lt;/p&gt;
&lt;p&gt;
Traffic speed is central to characterizing the fluidity of the road network. Many transportation applications rely on it, such as real-time navigation, dynamic route planning, and congestion management. Rapid advances in sensing and communication techniques make traffic speed detection easier than ever. However, due to sparse deployment of static sensors or low penetration of mobile sensors, speeds detected are incomplete and far from network-wide use. In addition, sensors are prone to error or missing data due to various kinds of reasons, speeds from these sensors can become highly noisy. These drawbacks call for effective techniques to recover credible estimates from the incomplete data. In this work, we first identify the issue as a spatiotemporal kriging problem and propose a Laplacian enhanced low-rank tensor completion (LETC) framework featuring both lowrankness and multi-dimensional correlations for large-scale traffic speed kriging under limited observations. To be specific, th
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#31526;&#21512;p&#20540;&#30340;&#39044;&#27979;&#36873;&#25321;&#26041;&#27861;&#65292;&#20351;&#29992;&#32479;&#35745;&#35777;&#25454;&#30340;p&#20540;&#26469;&#25511;&#21046;&#34394;&#38451;&#24615;&#36873;&#25321;&#21333;&#20301;&#65292;&#21487;&#29992;&#20110;&#21021;&#27493;&#31579;&#36873;&#32844;&#19994;&#25307;&#32856;&#21644;&#33647;&#29289;&#21457;&#29616;&#30340;&#20505;&#36873;&#20154;&#38598;&#21512;&#12290;</title><link>http://arxiv.org/abs/2210.01408</link><description>&lt;p&gt;
&#22522;&#20110;&#31526;&#21512;p&#20540;&#30340;&#39044;&#27979;&#36873;&#25321;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Selection by Prediction with Conformal p-values. (arXiv:2210.01408v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.01408
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#31526;&#21512;p&#20540;&#30340;&#39044;&#27979;&#36873;&#25321;&#26041;&#27861;&#65292;&#20351;&#29992;&#32479;&#35745;&#35777;&#25454;&#30340;p&#20540;&#26469;&#25511;&#21046;&#34394;&#38451;&#24615;&#36873;&#25321;&#21333;&#20301;&#65292;&#21487;&#29992;&#20110;&#21021;&#27493;&#31579;&#36873;&#32844;&#19994;&#25307;&#32856;&#21644;&#33647;&#29289;&#21457;&#29616;&#30340;&#20505;&#36873;&#20154;&#38598;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28041;&#21450;&#21040;&#32844;&#19994;&#25307;&#32856;&#21644;&#33647;&#29289;&#21457;&#29616;&#31561;&#20915;&#31574;&#21644;&#31185;&#23398;&#21457;&#29616;&#27969;&#31243;&#36890;&#24120;&#28041;&#21450;&#22810;&#20010;&#38454;&#27573;&#65306;&#22312;&#20219;&#20309;&#36164;&#28304;&#23494;&#38598;&#22411;&#27493;&#39588;&#20043;&#21069;&#65292;&#36890;&#24120;&#20250;&#36827;&#34892;&#21021;&#22987;&#31579;&#36873;&#65292;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#26469;&#20174;&#22823;&#37327;&#20505;&#36873;&#20154;&#20013;&#31579;&#36873;&#20986;&#23569;&#25968;&#20154;&#12290;&#25105;&#20204;&#30740;&#31350;&#26088;&#22312;&#36873;&#25321;&#26410;&#35266;&#23519;&#32467;&#26524;&#36229;&#36807;&#29992;&#25143;&#25351;&#23450;&#20540;&#30340;&#20505;&#36873;&#20154;&#30340;&#31579;&#36873;&#31243;&#24207;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22260;&#32469;&#20219;&#20309;&#39044;&#27979;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20197;&#20135;&#29983;&#19968;&#20010;&#20505;&#36873;&#20154;&#38598;&#21512;&#65292;&#21516;&#26102;&#25511;&#21046;&#34394;&#38451;&#24615;&#36873;&#25321;&#21333;&#20301;&#30340;&#27604;&#20363;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#24314;&#31435;&#22312;&#31526;&#21512;&#25512;&#26029;&#26694;&#26550;&#20043;&#19978;&#65292;&#39318;&#20808;&#26500;&#24314;&#37327;&#21270;&#22823;&#22411;&#32467;&#26524;&#30340;&#32479;&#35745;&#35777;&#25454;&#30340;p&#20540;&#65307;&#28982;&#21518;&#36890;&#36807;&#23558;p&#20540;&#19982;&#22810;&#37325;&#26816;&#39564;&#25991;&#29486;&#20013;&#24341;&#20837;&#30340;&#38408;&#20540;&#36827;&#34892;&#27604;&#36739;&#65292;&#30830;&#23450;&#30701;&#21517;&#21333;&#12290;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#35813;&#36807;&#31243;&#36873;&#25321;&#30340;&#20505;&#36873;&#20154;&#30340;&#39044;&#27979;&#39640;&#20110;&#22522;&#20110;&#25968;&#25454;&#30340;&#38408;&#20540;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20445;&#35777;&#22312;&#28201;&#21644;&#30340;&#20132;&#25442;&#26465;&#20214;&#19979;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;
Decision making or scientific discovery pipelines such as job hiring and drug discovery often involve multiple stages: before any resource-intensive step, there is often an initial screening that uses predictions from a machine learning model to shortlist a few candidates from a large pool. We study screening procedures that aim to select candidates whose unobserved outcomes exceed user-specified values. We develop a method that wraps around any prediction model to produce a subset of candidates while controlling the proportion of falsely selected units. Building upon the conformal inference framework, our method first constructs p-values that quantify the statistical evidence for large outcomes; it then determines the shortlist by comparing the p-values to a threshold introduced in the multiple testing literature. In many cases, the procedure selects candidates whose predictions are above a data-dependent threshold. Our theoretical guarantee holds under mild exchangeability conditions
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22810;&#20307;&#36924;&#36817;&#30340;&#26041;&#27861;&#26469;&#20998;&#35299;&#38750;&#36127;&#24352;&#37327;&#65292;&#36890;&#36807;&#33021;&#37327;&#24314;&#27169;&#26469;&#36991;&#20813;&#20840;&#23616;&#20248;&#21270;&#21644;&#30446;&#26631;&#31209;&#36873;&#25321;&#30340;&#22256;&#38590;&#65292;&#21487;&#36890;&#36807;&#32771;&#34385;&#27169;&#24335;&#20043;&#38388;&#30340;&#20132;&#20114;&#36827;&#34892;&#20840;&#23616;&#20248;&#21270;; &#22312;&#35768;&#22810;&#20219;&#21153;&#20013;&#37117;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2209.15338</link><description>&lt;p&gt;
&#38750;&#36127;&#24352;&#37327;&#30340;&#22810;&#20307;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Many-body Approximation for Non-negative Tensors. (arXiv:2209.15338v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.15338
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22810;&#20307;&#36924;&#36817;&#30340;&#26041;&#27861;&#26469;&#20998;&#35299;&#38750;&#36127;&#24352;&#37327;&#65292;&#36890;&#36807;&#33021;&#37327;&#24314;&#27169;&#26469;&#36991;&#20813;&#20840;&#23616;&#20248;&#21270;&#21644;&#30446;&#26631;&#31209;&#36873;&#25321;&#30340;&#22256;&#38590;&#65292;&#21487;&#36890;&#36807;&#32771;&#34385;&#27169;&#24335;&#20043;&#38388;&#30340;&#20132;&#20114;&#36827;&#34892;&#20840;&#23616;&#20248;&#21270;; &#22312;&#35768;&#22810;&#20219;&#21153;&#20013;&#37117;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#26041;&#27861;&#26469;&#20998;&#35299;&#38750;&#36127;&#24352;&#37327;&#65292;&#31216;&#20026;&#22810;&#20307;&#36924;&#36817;&#12290;&#20256;&#32479;&#30340;&#20998;&#35299;&#26041;&#27861;&#20551;&#35774;&#34920;&#31034;&#20855;&#26377;&#20302;&#31209;&#24615;&#65292;&#23548;&#33268;&#20840;&#23616;&#20248;&#21270;&#21644;&#30446;&#26631;&#31209;&#36873;&#25321;&#30340;&#22256;&#38590;&#12290;&#25105;&#20204;&#36890;&#36807;&#24352;&#37327;&#30340;&#33021;&#37327;&#24314;&#27169;&#36991;&#20813;&#20102;&#36825;&#20123;&#38382;&#39064;&#65292;&#20854;&#20013;&#24352;&#37327;&#21644;&#20854;&#27169;&#24335;&#20998;&#21035;&#23545;&#24212;&#20110;&#27010;&#29575;&#20998;&#24067;&#21644;&#38543;&#26426;&#21464;&#37327;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#32771;&#34385;&#27169;&#24335;&#20043;&#38388;&#30340;&#20132;&#20114;&#26469;&#36827;&#34892;&#20840;&#23616;&#20248;&#21270;&#65292;&#21487;&#20197;&#27604;&#31209;&#26356;&#30452;&#35266;&#22320;&#36827;&#34892;&#35843;&#25972;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#27169;&#24335;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#21487;&#35270;&#21270;&#20026;&#24352;&#37327;&#32593;&#32476;&#65292;&#25581;&#31034;&#20102;&#22810;&#20307;&#36924;&#36817;&#21644;&#20302;&#31209;&#36924;&#36817;&#20043;&#38388;&#30340;&#38750;&#24179;&#20961;&#20851;&#31995;&#12290;&#25105;&#20204;&#22312;&#24352;&#37327;&#23436;&#25104;&#21644;&#36924;&#36817;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present an alternative approach to decompose non-negative tensors, called many-body approximation. Traditional decomposition methods assume low-rankness in the representation, resulting in difficulties in global optimization and target rank selection. We avoid these problems by energy-based modeling of tensors, where a tensor and its mode correspond to a probability distribution and a random variable, respectively. Our model can be globally optimized in terms of the KL divergence minimization by taking the interaction between variables, i.e. modes, into account that can be tuned more intuitively than ranks. Furthermore, we visualize interactions between modes as tensor networks and reveal a nontrivial relationship between many-body approximation and low-rank approximation. We demonstrate the effectiveness of our approach in tensor completion and approximation.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20284;&#28982;&#20989;&#25968;&#20462;&#27491;&#30340;&#21322;&#23450;&#35268;&#21010;&#26041;&#27861;&#29992;&#20110;&#24322;&#36136;&#25968;&#25454;&#32858;&#31867;&#12290;&#32463;&#36807;&#23454;&#39564;&#34920;&#26126;&#65292;&#26412;&#26041;&#27861;&#22312;&#22788;&#29702;&#32858;&#31867;&#24418;&#29366;&#19981;&#21516;&#30340;&#25968;&#25454;&#24322;&#36136;&#24615;&#26102;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2209.15097</link><description>&lt;p&gt;
&#22522;&#20110;&#20284;&#28982;&#20989;&#25968;&#20462;&#27491;&#30340;&#21322;&#23450;&#35268;&#21010;&#26041;&#27861;&#29992;&#20110;&#24322;&#36136;&#25968;&#25454;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Likelihood Adjusted Semidefinite Programs for Clustering Heterogeneous Data. (arXiv:2209.15097v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.15097
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20284;&#28982;&#20989;&#25968;&#20462;&#27491;&#30340;&#21322;&#23450;&#35268;&#21010;&#26041;&#27861;&#29992;&#20110;&#24322;&#36136;&#25968;&#25454;&#32858;&#31867;&#12290;&#32463;&#36807;&#23454;&#39564;&#34920;&#26126;&#65292;&#26412;&#26041;&#27861;&#22312;&#22788;&#29702;&#32858;&#31867;&#24418;&#29366;&#19981;&#21516;&#30340;&#25968;&#25454;&#24322;&#36136;&#24615;&#26102;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32858;&#31867;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#24037;&#20855;&#12290;&#22522;&#20110;&#27169;&#22411;&#30340;&#32858;&#31867;&#26159;&#19968;&#31181;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#29992;&#26469;&#22788;&#29702;&#32858;&#31867;&#20855;&#26377;&#19981;&#21516;&#24418;&#29366;&#30340;&#25968;&#25454;&#30340;&#24322;&#36136;&#24615;&#12290;&#23545;&#20110;&#28151;&#21512;&#20998;&#24067;&#30340;&#22522;&#20110;&#20284;&#28982;&#30340;&#25512;&#26029;&#36890;&#24120;&#28041;&#21450;&#38750;&#20984;&#21644;&#39640;&#32500;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#24102;&#26469;&#20102;&#22797;&#26434;&#30340;&#35745;&#31639;&#21644;&#32479;&#35745;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#22522;&#20110;&#20284;&#28982;&#20989;&#25968;&#20462;&#27491;&#30340;&#21322;&#23450;&#35268;&#21010;&#65288;LA-SDP&#65289;&#26041;&#27861;&#24212;&#29992;&#20110;&#24322;&#36136;&#25968;&#25454;&#32858;&#31867;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#19968;&#32452;&#26032;&#30340;&#30697;&#38453;&#19981;&#31561;&#24335;&#23454;&#29616;&#20102;&#20284;&#28982;&#20989;&#25968;&#35843;&#25972;&#30340;&#20984;&#26494;&#24347;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#28151;&#21512;&#32452;&#20998;&#30340;&#19968;&#20123;&#28201;&#21644;&#30340;&#21069;&#25552;&#26465;&#20214;&#19979;&#65292;LA-SDP &#21487;&#20197;&#19968;&#33268;&#32780;&#26377;&#25928;&#22320;&#35745;&#31639;&#20986;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#20540;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#19982;&#29616;&#26377;&#30340;&#26041;&#27861;&#30456;&#27604;&#65292;&#23588;&#20854;&#26159;&#24403;&#32858;&#31867;&#26174;&#33879;&#24322;&#36136;&#26102;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#30495;&#23454;&#25968;&#25454;&#30340;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Clustering is a widely deployed unsupervised learning tool. Model-based clustering is a flexible framework to tackle data heterogeneity when the clusters have different shapes. Likelihood-based inference for mixture distributions often involves non-convex and high-dimensional objective functions, imposing difficult computational and statistical challenges. The classic expectation-maximization (EM) algorithm is a computationally thrifty iterative method that maximizes a surrogate function minorizing the log-likelihood of observed data in each iteration, which however suffers from bad local maxima even in the special case of the standard Gaussian mixture model with common isotropic covariance matrices. On the other hand, recent studies reveal that the unique global solution of a semidefinite programming (SDP) relaxed $K$-means achieves the information-theoretically sharp threshold for perfectly recovering the cluster labels under the standard Gaussian mixture model. In this paper, we ext
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#39640;&#32500;&#25209;&#37327;&#35757;&#32451;&#20013;&#20855;&#26377;&#39640;&#24230;&#40065;&#26834;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#30340;&#32447;&#24615;&#23398;&#20064;&#26041;&#27861;&#65292;&#22312;&#22810;&#20010;&#24212;&#29992;&#31243;&#24207;&#20013;&#22343;&#33021;&#36798;&#21040;&#25509;&#36817;&#26368;&#20248;&#30340;&#20272;&#35745;&#36895;&#29575;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#24320;&#28304;&#30340;Python&#24211;&#36827;&#34892;&#23454;&#29616;&#12290;</title><link>http://arxiv.org/abs/2208.05447</link><description>&lt;p&gt;
&#27169;&#22411;&#35757;&#32451;&#20013;&#40065;&#26834;&#24615;&#39640;&#30340;&#39640;&#32500;&#32447;&#24615;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Robust Methods for High-Dimensional Linear Learning. (arXiv:2208.05447v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.05447
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#39640;&#32500;&#25209;&#37327;&#35757;&#32451;&#20013;&#20855;&#26377;&#39640;&#24230;&#40065;&#26834;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#30340;&#32447;&#24615;&#23398;&#20064;&#26041;&#27861;&#65292;&#22312;&#22810;&#20010;&#24212;&#29992;&#31243;&#24207;&#20013;&#22343;&#33021;&#36798;&#21040;&#25509;&#36817;&#26368;&#20248;&#30340;&#20272;&#35745;&#36895;&#29575;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#24320;&#28304;&#30340;Python&#24211;&#36827;&#34892;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#32500;&#25209;&#22788;&#29702;&#20013;&#20855;&#26377;&#32479;&#35745;&#40065;&#26834;&#24615;&#21644;&#35745;&#31639;&#26377;&#25928;&#24615;&#30340;&#32447;&#24615;&#23398;&#20064;&#26041;&#27861;&#65292;&#20854;&#20013;&#29305;&#24449;&#25968;d&#21487;&#33021;&#36229;&#36807;&#26679;&#26412;&#25968;n&#12290;&#25105;&#20204;&#22312;&#36890;&#29992;&#23398;&#20064;&#35774;&#32622;&#20013;&#37319;&#29992;&#20102;&#20004;&#31181;&#31639;&#27861;&#65292;&#21462;&#20915;&#20110;&#25152;&#32771;&#34385;&#30340;&#25439;&#22833;&#20989;&#25968;&#26159;&#21542;&#26159;&#26799;&#24230;Lipschitz&#30340;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26694;&#26550;&#23454;&#20363;&#21270;&#21040;&#20960;&#20010;&#24212;&#29992;&#31243;&#24207;&#19978;&#65292;&#21253;&#25324;&#39321;&#33609;&#31232;&#30095;&#65292;&#32452;&#31232;&#30095;&#21644;&#20302;&#31209;&#30697;&#38453;&#24674;&#22797;&#12290;&#36825;&#23548;&#33268;&#20102;&#27599;&#20010;&#24212;&#29992;&#31243;&#24207;&#30340;&#39640;&#25928;&#21644;&#40065;&#26834;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#37325;&#23614;&#20998;&#24067;&#21644;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#65292;&#36798;&#21040;&#25509;&#36817;&#26368;&#20248;&#30340;&#20272;&#35745;&#36895;&#29575;&#12290;&#23545;&#20110;&#39321;&#33609;$s$-&#31232;&#30095;&#65292;&#25105;&#20204;&#33021;&#22815;&#22312;&#37325;&#23614;&#21644;$\eta$-&#27745;&#26579;&#19979;&#36798;&#21040;$s\log(d)/n$&#30340;&#36895;&#29575;&#65292;&#35745;&#31639;&#25104;&#26412;&#19982;&#38750;&#40065;&#26834;&#27169;&#25311;&#30456;&#24403;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#24320;&#28304;&#30340;$\mathtt{Python}$&#24211;$\mathtt{linlearn}$&#26469;&#23454;&#29616;&#25105;&#20204;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#36825;&#20010;&#24211;&#36827;&#34892;&#25968;&#20540;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose statistically robust and computationally efficient linear learning methods in the high-dimensional batch setting, where the number of features $d$ may exceed the sample size $n$. We employ, in a generic learning setting, two algorithms depending on whether the considered loss function is gradient-Lipschitz or not. Then, we instantiate our framework on several applications including vanilla sparse, group-sparse and low-rank matrix recovery. This leads, for each application, to efficient and robust learning algorithms, that reach near-optimal estimation rates under heavy-tailed distributions and the presence of outliers. For vanilla $s$-sparsity, we are able to reach the $s\log (d)/n$ rate under heavy-tails and $\eta$-corruption, at a computational cost comparable to that of non-robust analogs. We provide an efficient implementation of our algorithms in an open-source $\mathtt{Python}$ library called $\mathtt{linlearn}$, by means of which we carry out numerical experiments whi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#22522;&#20110;&#27969;&#27169;&#22411;&#30340;&#21435;&#22122;&#22312;&#27969;&#24418;&#20551;&#35774;&#19979;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#39318;&#27425;&#25299;&#23637;&#21040;&#20102;&#30446;&#26631;&#20998;&#24067;&#21463;&#27969;&#24418;&#32422;&#26463;&#25110;&#36890;&#36807;&#32463;&#39564;&#20998;&#24067;&#32473;&#20986;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2208.05314</link><description>&lt;p&gt;
&#22522;&#20110;&#27969;&#27169;&#22411;&#30340;&#21435;&#22122;&#22312;&#27969;&#24418;&#20551;&#35774;&#19979;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Convergence of denoising diffusion models under the manifold hypothesis. (arXiv:2208.05314v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.05314
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#22522;&#20110;&#27969;&#27169;&#22411;&#30340;&#21435;&#22122;&#22312;&#27969;&#24418;&#20551;&#35774;&#19979;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#39318;&#27425;&#25299;&#23637;&#21040;&#20102;&#30446;&#26631;&#20998;&#24067;&#21463;&#27969;&#24418;&#32422;&#26463;&#25110;&#36890;&#36807;&#32463;&#39564;&#20998;&#24067;&#32473;&#20986;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21435;&#22122;&#27969;&#27169;&#22411;&#26159;&#19968;&#31867;&#29983;&#25104;&#27169;&#22411;&#65292;&#22312;&#22270;&#20687;&#21644;&#38899;&#39057;&#21512;&#25104;&#26041;&#38754;&#34920;&#29616;&#20986;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#36825;&#26679;&#30340;&#27169;&#22411;&#36817;&#20284;&#20110;&#20174;&#30446;&#26631;&#20998;&#24067;&#21040;&#21442;&#32771;&#23494;&#24230;&#65288;&#36890;&#24120;&#20026;&#39640;&#26031;&#20998;&#24067;&#65289;&#30340;&#27491;&#21521;&#22122;&#22768;&#36807;&#31243;&#30340;&#26102;&#38388;&#21453;&#28436;&#12290;&#23613;&#31649;&#23427;&#20204;&#20855;&#26377;&#24378;&#22823;&#30340;&#23454;&#35777;&#32467;&#26524;&#65292;&#20294;&#23545;&#36825;&#20123;&#27169;&#22411;&#30340;&#29702;&#35770;&#20998;&#26512;&#20173;&#28982;&#26377;&#38480;&#12290;&#29305;&#21035;&#22320;&#65292;&#25152;&#26377;&#24403;&#21069;&#30340;&#26041;&#27861;&#37117;&#20851;&#38190;&#22320;&#20551;&#35774;&#30446;&#26631;&#20998;&#24067;&#30456;&#23545;&#20110;&#21202;&#36125;&#26684;&#27979;&#24230;&#23384;&#22312;&#23494;&#24230;&#12290;&#36825;&#19981;&#28085;&#30422;&#30446;&#26631;&#20998;&#24067;&#21463;&#20302;&#32500;&#27969;&#24418;&#32422;&#26463;&#25110;&#36890;&#36807;&#26576;&#20123;&#32463;&#39564;&#20998;&#24067;&#32473;&#20986;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#38024;&#23545;&#27969;&#27169;&#22411;&#22312;&#36825;&#31181;&#26356;&#21152;&#26222;&#36941;&#30340;&#24773;&#20917;&#19979;&#30340;&#25910;&#25947;&#24615;&#32467;&#26524;&#24182;&#25552;&#20379;&#19968;&#38454;Wasserstein&#36317;&#31163;&#37327;&#21270;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Denoising diffusion models are a recent class of generative models exhibiting state-of-the-art performance in image and audio synthesis. Such models approximate the time-reversal of a forward noising process from a target distribution to a reference density, which is usually Gaussian. Despite their strong empirical results, the theoretical analysis of such models remains limited. In particular, all current approaches crucially assume that the target density admits a density w.r.t. the Lebesgue measure. This does not cover settings where the target distribution is supported on a lower-dimensional manifold or is given by some empirical distribution. In this paper, we bridge this gap by providing the first convergence results for diffusion models in this more general setting. In particular, we provide quantitative bounds on the Wasserstein distance of order one between the target data distribution and the generative distribution of the diffusion model.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24046;&#20998;&#38544;&#31169;&#32852;&#21512;&#32452;&#21512;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25506;&#35752;&#20102;&#20195;&#29702;&#22312;&#20849;&#21516;&#23398;&#20064;&#26102;&#22914;&#20309;&#20445;&#25345;&#25968;&#25454;&#30340;&#38544;&#31169;&#65292;&#24182;&#25552;&#20986;&#20102;&#22312;&#21518;&#24724;&#21644;&#38544;&#31169;&#20043;&#38388;&#23454;&#29616;&#24179;&#34913;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2206.13192</link><description>&lt;p&gt;
&#24102;&#32422;&#26463;&#26465;&#20214;&#30340;&#24046;&#20998;&#38544;&#31169;&#32852;&#21512;&#32452;&#21512;&#36172;&#21338;&#26426;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Federated Combinatorial Bandits with Constraints. (arXiv:2206.13192v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.13192
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24046;&#20998;&#38544;&#31169;&#32852;&#21512;&#32452;&#21512;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25506;&#35752;&#20102;&#20195;&#29702;&#22312;&#20849;&#21516;&#23398;&#20064;&#26102;&#22914;&#20309;&#20445;&#25345;&#25968;&#25454;&#30340;&#38544;&#31169;&#65292;&#24182;&#25552;&#20986;&#20102;&#22312;&#21518;&#24724;&#21644;&#38544;&#31169;&#20043;&#38388;&#23454;&#29616;&#24179;&#34913;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22312;&#32447;&#23398;&#20064;&#27169;&#24335;&#20013;&#65292;&#21512;&#20316;&#23398;&#20064;&#33539;&#24335;&#65288;&#21363;&#32852;&#37030;&#23398;&#20064;&#65289;&#24555;&#36895;&#22686;&#38271;&#12290;&#19982;&#22823;&#22810;&#25968;&#32852;&#37030;&#23398;&#20064;&#24773;&#26223;&#19981;&#21516;&#30340;&#26159;&#65292;&#26377;&#24456;&#22810;&#24773;&#20917;&#19979;&#20195;&#29702;&#26159;&#31454;&#20105;&#30340;&#12290;&#27599;&#20010;&#20195;&#29702;&#37117;&#24819;&#20174;&#20854;&#20182;&#20154;&#37027;&#37324;&#23398;&#20064;&#65292;&#20294;&#23427;&#20998;&#20139;&#32473;&#20854;&#20182;&#20154;&#23398;&#20064;&#30340;&#20449;&#24687;&#26377;&#21487;&#33021;&#26159;&#25935;&#24863;&#30340;&#65292;&#22240;&#27492;&#23427;&#38656;&#35201;&#38544;&#31169;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#32452;&#20195;&#29702;&#21516;&#26102;&#35299;&#20915;&#31867;&#20284;&#30340;&#32452;&#21512;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#21516;&#26102;&#20445;&#25345;&#36136;&#37327;&#32422;&#26463;&#12290;&#36825;&#20123;&#20195;&#29702;&#26159;&#21542;&#21487;&#20197;&#36890;&#36807;&#37319;&#29992;&#24046;&#20998;&#38544;&#31169;&#26469;&#20445;&#25345;&#26426;&#23494;&#24615;&#65292;&#38598;&#20307;&#23398;&#20064;&#65311;&#25105;&#20204;&#35266;&#23519;&#21040;&#36890;&#20449;&#21487;&#20197;&#38477;&#20302;&#21518;&#24724;&#12290;&#20294;&#26159;&#65292;&#20445;&#25252;&#25935;&#24863;&#20449;&#24687;&#30340;&#24046;&#20998;&#38544;&#31169;&#25216;&#26415;&#20351;&#25968;&#25454;&#21464;&#24471;&#24456;&#22024;&#26434;&#65292;&#21487;&#33021;&#20250;&#24694;&#21270;&#32780;&#19981;&#26159;&#26377;&#24110;&#21161;&#22320;&#25552;&#39640;&#21518;&#24724;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25351;&#20986;&#20915;&#23450;&#20309;&#26102;&#36890;&#20449;&#20197;&#21450;&#23398;&#20064;&#21738;&#20123;&#20849;&#20139;&#25968;&#25454;&#26469;&#22312;&#21518;&#24724;&#21644;&#38544;&#31169;&#20043;&#38388;&#23454;&#29616;&#21151;&#33021;&#24179;&#34913;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is a rapid increase in the cooperative learning paradigm in online learning settings, i.e., federated learning (FL). Unlike most FL settings, there are many situations where the agents are competitive. Each agent would like to learn from others, but the part of the information it shares for others to learn from could be sensitive; thus, it desires its privacy. This work investigates a group of agents working concurrently to solve similar combinatorial bandit problems while maintaining quality constraints. Can these agents collectively learn while keeping their sensitive information confidential by employing differential privacy? We observe that communicating can reduce the regret. However, differential privacy techniques for protecting sensitive information makes the data noisy and may deteriorate than help to improve regret. Hence, we note that it is essential to decide when to communicate and what shared data to learn to strike a functional balance between regret and privacy. F
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#38024;&#23545;&#37096;&#20998;&#23458;&#25143;&#31471;&#21442;&#19982;&#30340;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550; FedAMD&#65292;&#20854;&#20013;&#26680;&#24515;&#24605;&#24819;&#26159;&#38170;&#23450;&#25277;&#26679;&#65292;&#23558;&#21442;&#19982;&#32773;&#20998;&#20026;&#38170;&#23450;&#32452;&#21644;&#30719;&#24037;&#32452;&#65292;&#20197;&#35299;&#20915;&#25968;&#25454;&#24322;&#26500;&#24615;&#12290;</title><link>http://arxiv.org/abs/2206.05891</link><description>&lt;p&gt;
&#38024;&#23545;&#37096;&#20998;&#23458;&#25143;&#31471;&#21442;&#19982;&#30340;&#32852;&#37030;&#23398;&#20064;&#30340;&#38170;&#23450;&#25277;&#26679;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Anchor Sampling for Federated Learning with Partial Client Participation. (arXiv:2206.05891v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.05891
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#38024;&#23545;&#37096;&#20998;&#23458;&#25143;&#31471;&#21442;&#19982;&#30340;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550; FedAMD&#65292;&#20854;&#20013;&#26680;&#24515;&#24605;&#24819;&#26159;&#38170;&#23450;&#25277;&#26679;&#65292;&#23558;&#21442;&#19982;&#32773;&#20998;&#20026;&#38170;&#23450;&#32452;&#21644;&#30719;&#24037;&#32452;&#65292;&#20197;&#35299;&#20915;&#25968;&#25454;&#24322;&#26500;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30456;&#36739;&#20110;&#20840;&#23458;&#25143;&#31471;&#21442;&#19982;&#65292;&#37096;&#20998;&#23458;&#25143;&#31471;&#21442;&#19982;&#26159;&#32852;&#37030;&#23398;&#20064;&#20013;&#26356;&#24120;&#35265;&#30340;&#22330;&#26223;&#65292;&#20294;&#26159;&#20250;&#21152;&#37325;&#19968;&#20123;&#25361;&#25112;&#65292;&#20363;&#22914;&#25968;&#25454;&#24322;&#26500;&#24615;&#12290;&#22312;&#37096;&#20998;&#23458;&#25143;&#31471;&#21442;&#19982;&#30340;&#24773;&#20917;&#19979;&#32570;&#23569;&#38750;&#27963;&#21160;&#23458;&#25143;&#31471;&#30340;&#26356;&#26032;&#65292;&#21487;&#33021;&#20250;&#23548;&#33268;&#27169;&#22411;&#32858;&#21512;&#20559;&#31163;&#22522;&#20110;&#20840;&#23458;&#25143;&#31471;&#21442;&#19982;&#30340;&#32858;&#21512;&#12290;&#36890;&#24120;&#25552;&#20986;&#37319;&#29992;&#22312;&#20010;&#20307;&#23458;&#25143;&#31471;&#19978;&#20351;&#29992;&#22823;&#25209;&#37327;&#26469;&#36827;&#34892;&#35757;&#32451;&#20197;&#35299;&#20915;&#25968;&#25454;&#24322;&#26500;&#24615;&#65292;&#20294;&#20854;&#22312;&#37096;&#20998;&#23458;&#25143;&#31471;&#21442;&#19982;&#30340;&#24773;&#20917;&#19979;&#30340;&#26377;&#25928;&#24615;&#19981;&#26126;&#30830;&#12290;&#22312;&#32771;&#34385;&#36825;&#20123;&#25361;&#25112;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38024;&#23545;&#37096;&#20998;&#23458;&#25143;&#31471;&#21442;&#19982;&#30340;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#65292;&#31216;&#20026;FedAMD&#65292;&#20854;&#26680;&#24515;&#24605;&#24819;&#26159;&#38170;&#23450;&#25277;&#26679;&#65292;&#23558;&#37096;&#20998;&#21442;&#19982;&#32773;&#20998;&#20026;&#38170;&#23450;&#32452;&#21644;&#30719;&#24037;&#32452;&#12290;
&lt;/p&gt;
&lt;p&gt;
Compared with full client participation, partial client participation is a more practical scenario in federated learning, but it may amplify some challenges in federated learning, such as data heterogeneity. The lack of inactive clients' updates in partial client participation makes it more likely for the model aggregation to deviate from the aggregation based on full client participation. Training with large batches on individual clients is proposed to address data heterogeneity in general, but their effectiveness under partial client participation is not clear. Motivated by these challenges, we propose to develop a novel federated learning framework, referred to as FedAMD, for partial client participation. The core idea is anchor sampling, which separates partial participants into anchor and miner groups. Each client in the anchor group aims at the local bullseye with the gradient computation using a large batch. Guided by the bullseyes, clients in the miner group steer multiple near
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21333;&#19968;&#27491;&#26631;&#31614;&#30340;&#37319;&#26679;&#26041;&#27861;S2M&#65292;&#20197;&#23454;&#29616;&#23545;&#22810;&#26631;&#31614;&#26679;&#26412;&#30340;&#29983;&#25104;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#22810;&#26631;&#31614;&#25968;&#25454;&#38598;&#21046;&#20316;&#26102;&#39640;&#26114;&#30340;&#27880;&#37322;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2206.05764</link><description>&lt;p&gt;
&#20174;&#21333;&#19968;&#27491;&#26631;&#31614;&#20013;&#25366;&#25496;&#22810;&#26631;&#31614;&#26679;&#26412;
&lt;/p&gt;
&lt;p&gt;
Mining Multi-Label Samples from Single Positive Labels. (arXiv:2206.05764v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.05764
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21333;&#19968;&#27491;&#26631;&#31614;&#30340;&#37319;&#26679;&#26041;&#27861;S2M&#65292;&#20197;&#23454;&#29616;&#23545;&#22810;&#26631;&#31614;&#26679;&#26412;&#30340;&#29983;&#25104;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#22810;&#26631;&#31614;&#25968;&#25454;&#38598;&#21046;&#20316;&#26102;&#39640;&#26114;&#30340;&#27880;&#37322;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26465;&#20214;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;cGAN&#65289;&#22312;&#31867;&#21035;&#26377;&#26465;&#20214;&#30340;&#29983;&#25104;&#20219;&#21153;&#20013;&#24050;&#32463;&#35777;&#26126;&#20855;&#26377;&#20986;&#33394;&#30340;&#32467;&#26524;&#12290;&#20026;&#20102;&#21516;&#26102;&#25511;&#21046;&#22810;&#20010;&#26465;&#20214;&#65292;cGAN&#38656;&#35201;&#22810;&#26631;&#31614;&#35757;&#32451;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21487;&#20197;&#20026;&#27599;&#20010;&#25968;&#25454;&#23454;&#20363;&#20998;&#37197;&#22810;&#20010;&#26631;&#31614;&#12290;&#28982;&#32780;&#65292;&#24040;&#22823;&#30340;&#27880;&#37322;&#25104;&#26412;&#38480;&#21046;&#20102;&#22810;&#26631;&#31614;&#25968;&#25454;&#38598;&#22312;&#29616;&#23454;&#22330;&#26223;&#20013;&#30340;&#21487;&#35775;&#38382;&#24615;&#12290;&#22240;&#27492;&#65292;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#23454;&#38469;&#35774;&#32622;&#30340;&#31216;&#20026;&#21333;&#27491;&#26631;&#31614;&#35774;&#32622;&#65292;&#20854;&#20013;&#27599;&#20010;&#25968;&#25454;&#23454;&#20363;&#20165;&#30001;&#19968;&#20010;&#27491;&#26631;&#31614;&#27880;&#37322;&#65292;&#27809;&#26377;&#26126;&#30830;&#30340;&#36127;&#26631;&#31614;&#12290;&#20026;&#20102;&#22312;&#21333;&#27491;&#26631;&#31614;&#35774;&#32622;&#20013;&#29983;&#25104;&#22810;&#26631;&#31614;&#25968;&#25454;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#30340;&#26032;&#22411;&#37319;&#26679;&#26041;&#27861;&#65292;&#31216;&#20026;&#21333;&#21040;&#22810;&#26631;&#31614;&#65288;S2M&#65289;&#37319;&#26679;&#12290;&#20316;&#20026;&#24191;&#27867;&#36866;&#29992;&#30340;&#8220;&#38468;&#21152;&#8221;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;S2M&#37319;&#26679;&#26041;&#27861;&#20351;&#29616;&#26377;&#30340;&#26080;&#26465;&#20214;&#21644;&#26465;&#20214;GAN&#33021;&#22815;&#20197;&#26368;&#23567;&#30340;&#27880;&#37322;&#25104;&#26412;&#32472;&#21046;&#39640;&#36136;&#37327;&#30340;&#22810;&#26631;&#31614;&#25968;&#25454;&#12290;&#22312;&#23454;&#38469;&#22270;&#20687;&#21644;&#25991;&#26412;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#21508;&#31181;&#24773;&#20917;&#19979;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conditional generative adversarial networks (cGANs) have shown superior results in class-conditional generation tasks. To simultaneously control multiple conditions, cGANs require multi-label training datasets, where multiple labels can be assigned to each data instance. Nevertheless, the tremendous annotation cost limits the accessibility of multi-label datasets in real-world scenarios. Therefore, in this study we explore the practical setting called the single positive setting, where each data instance is annotated by only one positive label with no explicit negative labels. To generate multi-label data in the single positive setting, we propose a novel sampling approach called single-to-multi-label (S2M) sampling, based on the Markov chain Monte Carlo method. As a widely applicable "add-on" method, our proposed S2M sampling method enables existing unconditional and conditional GANs to draw high-quality multi-label data with a minimal annotation cost. Extensive experiments on real im
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;&#20110;&#36866;&#24403;&#21442;&#25968;&#35268;&#33539;&#30340;&#21160;&#24577;&#25511;&#21046;&#32467;&#21512;&#22522;&#20110;&#21442;&#25968;&#35268;&#33539;&#30340; Rademacher &#22797;&#26434;&#24230;&#20272;&#35745;&#23548;&#20986;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#65292;&#36866;&#29992;&#20110;&#21253;&#25324; MLP &#21644; CNN &#22312;&#20869;&#30340;&#24191;&#27867;&#32593;&#32476;&#26550;&#26500;&#65292;&#32467;&#26524;&#34920;&#26126;&#36825;&#20010;&#26041;&#27861;&#33021;&#22815;&#36866;&#24212;&#20248;&#21270;&#22120;&#21644;&#32593;&#32476;&#36229;&#21442;&#25968;&#30340;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2206.03299</link><description>&lt;p&gt;
&#30001; SGD &#35757;&#32451;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;
&lt;/p&gt;
&lt;p&gt;
Generalization Error Bounds for Deep Neural Networks Trained by SGD. (arXiv:2206.03299v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.03299
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#20110;&#36866;&#24403;&#21442;&#25968;&#35268;&#33539;&#30340;&#21160;&#24577;&#25511;&#21046;&#32467;&#21512;&#22522;&#20110;&#21442;&#25968;&#35268;&#33539;&#30340; Rademacher &#22797;&#26434;&#24230;&#20272;&#35745;&#23548;&#20986;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#65292;&#36866;&#29992;&#20110;&#21253;&#25324; MLP &#21644; CNN &#22312;&#20869;&#30340;&#24191;&#27867;&#32593;&#32476;&#26550;&#26500;&#65292;&#32467;&#26524;&#34920;&#26126;&#36825;&#20010;&#26041;&#27861;&#33021;&#22815;&#36866;&#24212;&#20248;&#21270;&#22120;&#21644;&#32593;&#32476;&#36229;&#21442;&#25968;&#30340;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23558;&#36866;&#24403;&#21442;&#25968;&#35268;&#33539;&#30340;&#21160;&#24577;&#25511;&#21046;&#21644;&#22522;&#20110;&#21442;&#25968;&#35268;&#33539;&#30340; Rademacher &#22797;&#26434;&#24230;&#20272;&#35745;&#30456;&#32467;&#21512;&#65292;&#23548;&#20986;&#20102;&#30001;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#35757;&#32451;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#12290;&#36825;&#20123;&#30028;&#26126;&#30830;&#21462;&#20915;&#20110;&#27839;&#35757;&#32451;&#36712;&#36857;&#30340;&#25439;&#22833;&#65292;&#24182;&#36866;&#29992;&#20110;&#21253;&#25324;&#22810;&#23618;&#24863;&#30693;&#26426;&#65288;MLP&#65289;&#21644;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#22312;&#20869;&#30340;&#24191;&#27867;&#32593;&#32476;&#26550;&#26500;&#12290;&#19982;&#20854;&#20182;&#31639;&#27861;&#20381;&#36182;&#30340;&#27867;&#21270;&#20272;&#35745;&#65288;&#22914;&#22522;&#20110;&#20840;&#23616;&#31283;&#23450;&#24615;&#30340;&#30028;&#65289;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#30028;&#19981;&#38656;&#35201;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#30340; $L$-&#24179;&#28369;&#24615;&#65292;&#24182;&#19988;&#30452;&#25509;&#36866;&#29992;&#20110; SGD&#65292;&#32780;&#19981;&#26159;&#38543;&#26426; Langevin &#26799;&#24230;&#19979;&#38477;&#65288;SGLD&#65289;&#12290;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#30028;&#26159;&#38750;&#34394;&#20551;&#21644;&#24378;&#20581;&#30340;&#65292;&#33021;&#22815;&#36866;&#24212;&#20248;&#21270;&#22120;&#21644;&#32593;&#32476;&#36229;&#21442;&#25968;&#30340;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generalization error bounds for deep neural networks trained by stochastic gradient descent (SGD) are derived by combining a dynamical control of an appropriate parameter norm and the Rademacher complexity estimate based on parameter norms. The bounds explicitly depend on the loss along the training trajectory, and work for a wide range of network architectures including multilayer perceptron (MLP) and convolutional neural networks (CNN). Compared with other algorithm-depending generalization estimates such as uniform stability-based bounds, our bounds do not require $L$-smoothness of the nonconvex loss function, and apply directly to SGD instead of Stochastic Langevin gradient descent (SGLD). Numerical results show that our bounds are non-vacuous and robust with the change of optimizer and network hyperparameters.
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#29420;&#31435;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#19979;&#30340;&#22810;&#29615;&#22659;&#26041;&#27861;&#65292;&#21487;&#20197;&#26816;&#27979;&#35266;&#27979;&#25968;&#25454;&#20013;&#30340;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#65292;&#24182;&#25552;&#20986;&#20102;&#27979;&#35797;&#29420;&#31435;&#24615;&#30340;&#31243;&#24207;&#12290;</title><link>http://arxiv.org/abs/2205.13935</link><description>&lt;p&gt;
&#20351;&#29992;&#22810;&#29615;&#22659;&#26041;&#27861;&#26816;&#27979;&#35266;&#27979;&#25968;&#25454;&#20013;&#30340;&#38544;&#24335;&#28151;&#28102;
&lt;/p&gt;
&lt;p&gt;
Detecting hidden confounding in observational data using multiple environments. (arXiv:2205.13935v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.13935
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#29420;&#31435;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#19979;&#30340;&#22810;&#29615;&#22659;&#26041;&#27861;&#65292;&#21487;&#20197;&#26816;&#27979;&#35266;&#27979;&#25968;&#25454;&#20013;&#30340;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#65292;&#24182;&#25552;&#20986;&#20102;&#27979;&#35797;&#29420;&#31435;&#24615;&#30340;&#31243;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22240;&#26524;&#25512;&#26029;&#20013;&#65292;&#24120;&#35265;&#30340;&#20551;&#35774;&#26159;&#27809;&#26377;&#38544;&#24335;&#28151;&#28102;&#12290;&#28982;&#32780;&#65292;&#22312;&#21333;&#20010;&#25968;&#25454;&#38598;&#20013;&#19981;&#33021;&#30830;&#23450;&#36825;&#20010;&#20551;&#35774;&#36890;&#24120;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#22312;&#29420;&#31435;&#30340;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#22312;&#22810;&#20010;&#26469;&#33258;&#19981;&#21516;&#29615;&#22659;&#30340;&#35266;&#27979;&#25968;&#25454;&#38598;&#20013;&#26816;&#27979;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#27979;&#35797;&#21487;&#39564;&#35777;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#30340;&#29702;&#35770;&#65292;&#36825;&#31181;&#29420;&#31435;&#24615;&#20165;&#24403;&#23384;&#22312;&#28151;&#28102;&#22240;&#32032;&#26102;&#25165;&#19981;&#23384;&#22312;&#65292;&#24182;&#26816;&#26597;&#20102;&#36829;&#21453;&#20854;&#20551;&#35774;&#30340;&#24773;&#20917;&#65306;&#36864;&#21270;&#21644;&#20381;&#36182;&#26426;&#21046;&#20197;&#21450;&#24544;&#23454;&#24230;&#36829;&#21453;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31243;&#24207;&#26469;&#27979;&#35797;&#36825;&#20123;&#29420;&#31435;&#24615;&#65292;&#24182;&#20351;&#29992;&#22522;&#20110;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#30340;&#21322;&#21512;&#25104;&#25968;&#25454;&#21644;&#27169;&#25311;&#30740;&#31350;&#30740;&#31350;&#20854;&#32463;&#39564;&#26377;&#38480;&#26679;&#26412;&#34892;&#20026;&#12290;&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#65292;&#25552;&#20986;&#30340;&#31243;&#24207;&#33021;&#22815;&#27491;&#30830;&#39044;&#27979;&#23384;&#22312;&#38544;&#24335;&#28151;&#28102;&#65292;&#29305;&#21035;&#26159;&#24403;&#28151;&#28102;&#20559;&#24046;&#24456;&#22823;&#26102;&#12290;
&lt;/p&gt;
&lt;p&gt;
A common assumption in causal inference from observational data is that there is no hidden confounding. Yet it is, in general, impossible to verify this assumption from a single dataset. Under the assumption of independent causal mechanisms underlying the data-generating process, we demonstrate a way to detect unobserved confounders when having multiple observational datasets coming from different environments. We present a theory for testable conditional independencies that are only absent when there is hidden confounding and examine cases where we violate its assumptions: degenerate &amp; dependent mechanisms, and faithfulness violations. Additionally, we propose a procedure to test these independencies and study its empirical finite-sample behavior using simulation studies and semi-synthetic data based on a real-world dataset. In most cases, the proposed procedure correctly predicts the presence of hidden confounding, particularly when the confounding bias is large.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#22312;&#26377;&#38480;&#32500;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#21387;&#32553;&#32463;&#39564;&#27979;&#24230;&#30340;&#26041;&#27861;&#65292;&#23548;&#20986;&#20102;&#20851;&#20110;&#36825;&#26679;&#19968;&#20010;&#36817;&#20284;&#30340;&#26680;&#24515;&#38598;&#24517;&#39035;&#26377;&#30340;&#22823;&#23567;&#30340;&#39640;&#27010;&#29575;&#19979;&#38480;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20123;&#25216;&#26415;&#20197;&#23558;&#21387;&#32553;&#26041;&#27861;&#24212;&#29992;&#20110;&#20855;&#20307;&#30340;&#25512;&#26029;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2204.08847</link><description>&lt;p&gt;
&#26377;&#38480;&#32500;&#19979;&#30340;&#21387;&#32553;&#32463;&#39564;&#27979;&#24230;
&lt;/p&gt;
&lt;p&gt;
Compressed Empirical Measures (in finite dimensions). (arXiv:2204.08847v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.08847
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#22312;&#26377;&#38480;&#32500;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#21387;&#32553;&#32463;&#39564;&#27979;&#24230;&#30340;&#26041;&#27861;&#65292;&#23548;&#20986;&#20102;&#20851;&#20110;&#36825;&#26679;&#19968;&#20010;&#36817;&#20284;&#30340;&#26680;&#24515;&#38598;&#24517;&#39035;&#26377;&#30340;&#22823;&#23567;&#30340;&#39640;&#27010;&#29575;&#19979;&#38480;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20123;&#25216;&#26415;&#20197;&#23558;&#21387;&#32553;&#26041;&#27861;&#24212;&#29992;&#20110;&#20855;&#20307;&#30340;&#25512;&#26029;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#26377;&#38480;&#32500;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHSs&#65289;&#20013;&#21387;&#32553;&#32463;&#39564;&#27979;&#24230;&#30340;&#26041;&#27861;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#32463;&#39564;&#27979;&#24230;&#21253;&#21547;&#22312;&#19968;&#20010;&#33258;&#28982;&#30340;&#20984;&#38598;&#20013;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#20984;&#20248;&#21270;&#26041;&#27861;&#26469;&#36817;&#20284;&#12290;&#22312;&#26576;&#20123;&#26465;&#20214;&#19979;&#65292;&#36825;&#31181;&#36817;&#20284;&#20250;&#23548;&#33268;&#25968;&#25454;&#28857;&#30340;coreset&#12290;&#25511;&#21046;&#36825;&#26679;&#19968;&#20010;coreset&#24517;&#39035;&#26377;&#22810;&#22823;&#30340;&#19968;&#20010;&#20851;&#38190;&#25968;&#37327;&#26159;&#21253;&#21547;&#22312;&#32463;&#39564;&#20984;&#38598;&#20013;&#30340;&#32463;&#39564;&#27979;&#37327;&#21608;&#22260;&#30340;&#26368;&#22823;&#29699;&#30340;&#22823;&#23567;&#12290;&#25105;&#20204;&#30340;&#22823;&#37096;&#20998;&#24037;&#20316;&#26159;&#22312;&#21508;&#31181;&#26465;&#20214;&#19979;&#23548;&#20986;&#20851;&#20110;&#36825;&#26679;&#19968;&#20010;&#29699;&#30340;&#22823;&#23567;&#30340;&#39640;&#27010;&#29575;&#19979;&#38480;&#12290;&#25105;&#20204;&#36890;&#36807;&#24320;&#21457;&#25216;&#26415;&#65292;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#23558;&#21387;&#32553;&#26041;&#27861;&#24212;&#29992;&#20110;&#20855;&#20307;&#30340;&#25512;&#26029;&#38382;&#39064;&#65292;&#22914;&#26680;&#23725;&#22238;&#24402;&#65292;&#26469;&#34917;&#20805;&#36825;&#31181;&#19979;&#38480;&#30340;&#27966;&#29983;&#12290;&#25105;&#20204;&#26368;&#21518;&#20171;&#32461;&#20102;&#19968;&#31181;&#26080;&#38480;&#32500;RKHS&#30340;&#26500;&#36896;&#65292;&#20854;&#20013;&#21387;&#32553;&#24456;&#24046;&#65292;&#31361;&#20986;&#20102;&#25105;&#20204;&#38754;&#20020;&#30340;&#19968;&#20123;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study approaches for compressing the empirical measure in the context of finite dimensional reproducing kernel Hilbert spaces (RKHSs).In this context, the empirical measure is contained within a natural convex set and can be approximated using convex optimization methods.Such an approximation gives under certain conditions rise to a coreset of data points. A key quantity that controls how large such a coreset has to be is the size of the largest ball around the empirical measure that is contained within the empirical convex set. The bulk of our work is concerned with deriving high probability lower bounds on the size of such a ball under various conditions. We complement this derivation of the lower bound by developing techniques that allow us to apply the compression approach to concrete inference problems such as kernel ridge regression. We conclude with a construction of an infinite dimensional RKHS for which the compression is poor, highlighting some of the difficulties one face
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#22312;&#27979;&#22320;&#24230;&#37327;&#31354;&#38388;&#20013;&#30340;Sion&#26497;&#23567;&#26497;&#22823;&#23450;&#29702;&#21644;&#40654;&#26364;&#22806;&#25512;&#31639;&#27861;&#65292;&#22312;&#20445;&#25345;&#38382;&#39064;&#21487;&#22788;&#29702;&#30340;&#21516;&#26102;&#65292;&#20026;&#38750;&#20984;-&#38750;&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#25552;&#20379;&#20102;&#19968;&#20010;&#24191;&#27867;&#30340;&#25512;&#24191;&#12290;</title><link>http://arxiv.org/abs/2202.06950</link><description>&lt;p&gt;
&#22312;&#27979;&#22320;&#24230;&#37327;&#31354;&#38388;&#20013;&#30340;Sion&#26497;&#23567;&#26497;&#22823;&#23450;&#29702;&#21644;&#40654;&#26364;&#22806;&#25512;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sion's Minimax Theorem in Geodesic Metric Spaces and a Riemannian Extragradient Algorithm. (arXiv:2202.06950v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.06950
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#22312;&#27979;&#22320;&#24230;&#37327;&#31354;&#38388;&#20013;&#30340;Sion&#26497;&#23567;&#26497;&#22823;&#23450;&#29702;&#21644;&#40654;&#26364;&#22806;&#25512;&#31639;&#27861;&#65292;&#22312;&#20445;&#25345;&#38382;&#39064;&#21487;&#22788;&#29702;&#30340;&#21516;&#26102;&#65292;&#20026;&#38750;&#20984;-&#38750;&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#25552;&#20379;&#20102;&#19968;&#20010;&#24191;&#27867;&#30340;&#25512;&#24191;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21028;&#26029;&#38750;&#20984;-&#38750;&#20985;&#38382;&#39064;&#26159;&#21542;&#23384;&#22312;&#38797;&#28857;&#36890;&#24120;&#26159;&#38590;&#20197;&#22788;&#29702;&#30340;&#12290;&#35813;&#35770;&#25991;&#21521;&#29702;&#35299;&#19968;&#31867;&#20445;&#25345;&#21487;&#22788;&#29702;&#30340;&#38750;&#20984;-&#38750;&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#36808;&#20986;&#20102;&#19968;&#27493;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#23427;&#30740;&#31350;&#20102;&#27979;&#22320;&#24230;&#37327;&#31354;&#38388;&#19978;&#30340;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#36825;&#25552;&#20379;&#20102;&#36890;&#24120;&#30340;&#20984;-&#20985;&#38797;&#28857;&#38382;&#39064;&#30340;&#24191;&#27867;&#25512;&#24191;&#12290;&#35770;&#25991;&#30340;&#31532;&#19968;&#20010;&#20027;&#35201;&#32467;&#26524;&#26159;Sion&#26497;&#23567;&#26497;&#22823;&#23450;&#29702;&#30340;&#27979;&#22320;&#24230;&#37327;&#31354;&#38388;&#29256;&#26412;; &#25105;&#20204;&#35748;&#20026;&#25105;&#20204;&#30340;&#35777;&#26126;&#26159;&#26032;&#39062;&#19988;&#24191;&#27867;&#21487;&#29992;&#30340;&#65292;&#22240;&#20026;&#23427;&#20165;&#22522;&#20110;&#26377;&#38480;&#20132;&#21449;&#24615;&#36136;&#12290;&#31532;&#20108;&#20010;&#20027;&#35201;&#32467;&#26524;&#26159;&#38024;&#23545;&#23436;&#25972;&#27979;&#22320;&#40654;&#26364;&#27969;&#24418;&#30340;&#19987;&#19994;&#21270;&#65306;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#35774;&#35745;&#21644;&#20998;&#26512;&#20102;&#20809;&#28369;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#19968;&#38454;&#26041;&#27861;&#30340;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deciding whether saddle points exist or are approximable for nonconvex-nonconcave problems is usually intractable. This paper takes a step towards understanding a broad class of nonconvex-nonconcave minimax problems that do remain tractable. Specifically, it studies minimax problems over geodesic metric spaces, which provide a vast generalization of the usual convex-concave saddle point problems. The first main result of the paper is a geodesic metric space version of Sion's minimax theorem; we believe our proof is novel and broadly accessible as it relies on the finite intersection property alone. The second main result is a specialization to geodesically complete Riemannian manifolds: here, we devise and analyze the complexity of first-order methods for smooth minimax problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#35299;&#20915;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22797;&#21512;&#26816;&#39564;&#38382;&#39064;&#65292;&#20854;&#26680;&#24515;&#24605;&#24819;&#26159;&#22312;&#27491;&#30830;&#30340;&#27169;&#22411;&#35268;&#33539;&#30340;&#38646;&#20551;&#35774;&#19979;&#65292;&#38750;&#21442;&#25968;&#22320;&#20272;&#35745;&#21442;&#25968;&#65288;&#25110;&#27169;&#25311;&#22120;&#65289;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2111.10275</link><description>&lt;p&gt;
&#24102;&#26377;&#26680;&#30340;&#22797;&#21512;&#36866;&#21512;&#24615;&#26816;&#39564;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Composite Goodness-of-fit Tests with Kernels. (arXiv:2111.10275v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.10275
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#35299;&#20915;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22797;&#21512;&#26816;&#39564;&#38382;&#39064;&#65292;&#20854;&#26680;&#24515;&#24605;&#24819;&#26159;&#22312;&#27491;&#30830;&#30340;&#27169;&#22411;&#35268;&#33539;&#30340;&#38646;&#20551;&#35774;&#19979;&#65292;&#38750;&#21442;&#25968;&#22320;&#20272;&#35745;&#21442;&#25968;&#65288;&#25110;&#27169;&#25311;&#22120;&#65289;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22411;&#38169;&#35823;&#35828;&#26126;&#21487;&#33021;&#20250;&#23545;&#27010;&#29575;&#27169;&#22411;&#30340;&#23454;&#29616;&#36896;&#25104;&#37325;&#22823;&#25361;&#25112;&#65292;&#36825;&#20419;&#20351;&#24320;&#21457;&#20986;&#19968;&#20123;&#30452;&#25509;&#35299;&#20915;&#27492;&#38382;&#39064;&#30340;&#40065;&#26834;&#26041;&#27861;&#12290;&#20294;&#26159;&#65292;&#36825;&#20123;&#26356;&#20026;&#22797;&#26434;&#30340;&#26041;&#27861;&#26159;&#21542;&#38656;&#35201;&#21462;&#20915;&#20110;&#27169;&#22411;&#26159;&#21542;&#30495;&#30340;&#38169;&#35823;&#65292;&#30446;&#21069;&#32570;&#20047;&#36890;&#29992;&#30340;&#26041;&#27861;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#26680;&#30340;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22797;&#21512;&#26816;&#39564;&#38382;&#39064;&#65292;&#21363;&#25105;&#20204;&#26159;&#21542;&#24863;&#20852;&#36259;&#30340;&#25968;&#25454;&#26469;&#33258;&#26576;&#20123;&#21442;&#25968;&#27169;&#22411;&#26063;&#20013;&#30340;&#20219;&#20309;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#27979;&#35797;&#21033;&#29992;&#22522;&#20110;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#21644;&#26680;Stein&#24046;&#24322;&#30340;&#26368;&#23567;&#36317;&#31163;&#20272;&#35745;&#22120;&#12290;&#23427;&#20204;&#20855;&#26377;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#65292;&#21253;&#25324;&#24403;&#21442;&#25968;&#27169;&#22411;&#30340;&#23494;&#24230;&#24050;&#30693;&#38500;&#26631;&#20934;&#21270;&#24120;&#25968;&#22806;&#65292;&#25110;&#32773;&#22914;&#26524;&#27169;&#22411;&#37319;&#29992;&#27169;&#25311;&#22120;&#24418;&#24335;&#12290;&#20316;&#20026;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#27491;&#30830;&#30340;&#27169;&#22411;&#35268;&#33539;&#30340;&#38646;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#33021;&#22815;&#38750;&#21442;&#25968;&#22320;&#20272;&#35745;&#21442;&#25968;&#65288;&#25110;&#27169;&#25311;&#22120;&#65289;&#20998;&#24067;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#24314;&#31435;&#25105;&#20204;&#26041;&#27861;&#26377;&#25928;&#24615;&#30340;&#29702;&#35770;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#21644;&#24322;&#24120;&#26816;&#27979;&#24212;&#29992;&#26696;&#20363;&#28436;&#31034;&#20102;&#20854;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model misspecification can create significant challenges for the implementation of probabilistic models, and this has led to development of a range of robust methods which directly account for this issue. However, whether these more involved methods are required will depend on whether the model is really misspecified, and there is a lack of generally applicable methods to answer this question. In this paper, we propose one such method. More precisely, we propose kernel-based hypothesis tests for the challenging composite testing problem, where we are interested in whether the data comes from any distribution in some parametric family. Our tests make use of minimum distance estimators based on the maximum mean discrepancy and the kernel Stein discrepancy. They are widely applicable, including whenever the density of the parametric model is known up to normalisation constant, or if the model takes the form of a simulator. As our main result, we show that we are able to estimate the param
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65288;MMD&#65289;&#30340;&#38750;&#21442;&#25968;&#21452;&#26679;&#26412;&#26680;&#26816;&#39564;&#65292;&#24182;&#26500;&#36896;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#24179;&#22343;&#27979;&#35797;&#65292;&#31216;&#20026;MMDAgg&#65292;&#20197;&#35299;&#20915;&#24179;&#28369;&#21442;&#25968;&#26410;&#30693;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2110.15073</link><description>&lt;p&gt;
MMD&#32858;&#21512;&#21452;&#26679;&#26412;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
MMD Aggregated Two-Sample Test. (arXiv:2110.15073v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.15073
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65288;MMD&#65289;&#30340;&#38750;&#21442;&#25968;&#21452;&#26679;&#26412;&#26680;&#26816;&#39564;&#65292;&#24182;&#26500;&#36896;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#24179;&#22343;&#27979;&#35797;&#65292;&#31216;&#20026;MMDAgg&#65292;&#20197;&#35299;&#20915;&#24179;&#28369;&#21442;&#25968;&#26410;&#30693;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65288;MMD&#65289;&#30340;&#38750;&#21442;&#25968;&#21452;&#26679;&#26412;&#26680;&#26816;&#39564;&#12290;&#39318;&#20808;&#65292;&#23545;&#20110;&#22266;&#23450;&#30340;&#26680;&#65292;&#25105;&#20204;&#20351;&#29992;&#25490;&#21015;&#25110;&#37326;&#34542;&#33258;&#20030;&#65288;wild bootstrap&#65289;&#26500;&#36896;&#20102;&#19968;&#20010;MMD&#26816;&#39564;&#65292;&#36825;&#20004;&#31181;&#27969;&#34892;&#30340;&#25968;&#20540;&#31243;&#24207;&#21487;&#30830;&#23450;&#27979;&#35797;&#38408;&#20540;&#12290;&#25105;&#20204;&#35777;&#26126;&#36825;&#20010;&#27979;&#35797;&#21487;&#20197;&#22312;&#38750;&#28176;&#36817;&#24773;&#20917;&#19979;&#25511;&#21046;I&#22411;&#38169;&#35823;&#30340;&#27010;&#29575;&#12290;&#22240;&#27492;&#65292;&#21363;&#20351;&#22312;&#23567;&#26679;&#26412;&#24773;&#20917;&#19979;&#65292;&#23427;&#20173;&#28982;&#20445;&#25345;&#33391;&#22909;&#30340;&#26657;&#20934;&#24615;&#65292;&#36825;&#19982;&#20197;&#21069;&#30340;MMD&#27979;&#35797;&#19981;&#21516;&#65292;&#21069;&#32773;&#21482;&#33021;&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#20445;&#35777;&#27491;&#30830;&#30340;&#27979;&#35797;&#27700;&#24179;&#12290;&#24403;&#23494;&#24230;&#24046;&#24322;&#22312;Sobolev&#29699;&#20013;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;MMD&#26816;&#39564;&#22312;&#29305;&#23450;&#30340;&#26680;&#20989;&#25968;&#19979;&#26159;&#26368;&#20248;&#30340;&#65292;&#35813;&#26680;&#20989;&#25968;&#20381;&#36182;&#20110;Sobolev&#29699;&#30340;&#24179;&#28369;&#21442;&#25968;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#36825;&#20010;&#21442;&#25968;&#26159;&#26410;&#30693;&#30340;&#65292;&#22240;&#27492;&#19981;&#33021;&#20351;&#29992;&#20855;&#26377;&#29305;&#23450;&#26680;&#30340;&#26368;&#20248;MMD&#26816;&#39564;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#26500;&#36896;&#20102;&#19968;&#20010;&#33258;&#36866;&#24212;&#24179;&#22343;&#27979;&#35797;&#65292;&#31216;&#20026;MMDAgg&#12290;&#27979;&#35797;&#21151;&#29575;&#22312;Sobolev&#29699;&#30340;&#24179;&#28369;&#21442;&#25968;&#19978;&#26368;&#22823;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose two novel nonparametric two-sample kernel tests based on the Maximum Mean Discrepancy (MMD). First, for a fixed kernel, we construct an MMD test using either permutations or a wild bootstrap, two popular numerical procedures to determine the test threshold. We prove that this test controls the probability of type I error non-asymptotically. Hence, it can be used reliably even in settings with small sample sizes as it remains well-calibrated, which differs from previous MMD tests which only guarantee correct test level asymptotically. When the difference in densities lies in a Sobolev ball, we prove minimax optimality of our MMD test with a specific kernel depending on the smoothness parameter of the Sobolev ball. In practice, this parameter is unknown and, hence, the optimal MMD test with this particular kernel cannot be used. To overcome this issue, we construct an aggregated test, called MMDAgg, which is adaptive to the smoothness parameter. The test power is maximised ove
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;Sinkhorn&#36317;&#31163;&#36827;&#34892;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65292;&#25512;&#23548;&#20986;&#26356;&#23481;&#26131;&#22788;&#29702;&#19988;&#22312;&#23454;&#38469;&#20013;&#26356;&#21512;&#29702;&#30340;&#26368;&#22351;&#24773;&#20917;&#20998;&#24067;&#65292;&#25552;&#20986;&#20102;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2109.11926</link><description>&lt;p&gt;
Sinkhorn&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Sinkhorn Distributionally Robust Optimization. (arXiv:2109.11926v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.11926
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;Sinkhorn&#36317;&#31163;&#36827;&#34892;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65292;&#25512;&#23548;&#20986;&#26356;&#23481;&#26131;&#22788;&#29702;&#19988;&#22312;&#23454;&#38469;&#20013;&#26356;&#21512;&#29702;&#30340;&#26368;&#22351;&#24773;&#20917;&#20998;&#24067;&#65292;&#25552;&#20986;&#20102;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;Sinkhorn&#36317;&#31163; -&#19968;&#31181;&#22522;&#20110;&#29109;&#27491;&#21017;&#21270;&#30340;Wasserstein&#36317;&#31163;&#21464;&#20307;- &#30340;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;DRO&#65289;&#12290;&#25105;&#20204;&#20026;&#19968;&#33324;&#21517;&#20041;&#20998;&#24067;&#25512;&#23548;&#20102;&#20984;&#35268;&#21010;&#23545;&#20598;&#37325;&#26500;&#12290;&#30456;&#27604;&#20110;Wasserstein DRO&#65292;&#23545;&#20110;&#26356;&#22823;&#31867;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#23427;&#22312;&#35745;&#31639;&#19978;&#26356;&#23481;&#26131;&#22788;&#29702;&#65292;&#23427;&#30340;&#26368;&#22351;&#24773;&#20917;&#20998;&#24067;&#23545;&#23454;&#38469;&#24212;&#29992;&#26356;&#21512;&#29702;&#12290;&#20026;&#20102;&#35299;&#20915;&#23545;&#20598;&#37325;&#26500;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#20351;&#29992;&#26377;&#20559;&#26799;&#24230;&#31070;&#32463;&#20803;&#30340;&#38543;&#26426;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#20854;&#25910;&#25947;&#36895;&#24230;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20351;&#29992;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#30340;&#25968;&#20540;&#23454;&#20363;&#65292;&#20197;&#35777;&#26126;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study distributionally robust optimization (DRO) with Sinkhorn distance -a variant of Wasserstein distance based on entropic regularization. We derive convex programming dual reformulation for a general nominal distribution. Compared with Wasserstein DRO, it is computationally tractable for a larger class of loss functions, and its worst-case distribution is more reasonable for practical applications. To solve the dual reformulation, we develop a stochastic mirror descent algorithm using biased gradient oracles and analyze its convergence rate. Finally, we provide numerical examples using synthetic and real data to demonstrate its superior performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#26500;&#24314;&#20102;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#24102;&#26377;&#23450;&#24120;&#22823;&#23398;&#20064;&#29575;&#30340;SGD&#21487;&#33021;&#34920;&#29616;&#20986;&#35768;&#22810;&#22855;&#24618;&#19988;&#28508;&#22312;&#30340;&#19981;&#33391;&#34892;&#20026;&#65292;&#21253;&#25324;&#65306;&#25910;&#25947;&#20110;&#23616;&#37096;&#26368;&#22823;&#20540;&#12289;&#32531;&#24930;&#36234;&#36807;&#38797;&#28857;&#21644;&#26356;&#21916;&#27426;&#23574;&#38160;&#30340;&#26368;&#23567;&#20540;&#12290;&#36825;&#24378;&#35843;&#20102;&#28145;&#20837;&#20998;&#26512;SGD&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#20316;&#29992;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2107.11774</link><description>&lt;p&gt;
&#24102;&#26377;&#23450;&#24120;&#22823;&#23398;&#20064;&#29575;&#30340;SGD&#21487;&#33021;&#25910;&#25947;&#20110;&#23616;&#37096;&#26368;&#22823;&#20540;
&lt;/p&gt;
&lt;p&gt;
SGD with a Constant Large Learning Rate Can Converge to Local Maxima. (arXiv:2107.11774v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.11774
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26500;&#24314;&#20102;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#24102;&#26377;&#23450;&#24120;&#22823;&#23398;&#20064;&#29575;&#30340;SGD&#21487;&#33021;&#34920;&#29616;&#20986;&#35768;&#22810;&#22855;&#24618;&#19988;&#28508;&#22312;&#30340;&#19981;&#33391;&#34892;&#20026;&#65292;&#21253;&#25324;&#65306;&#25910;&#25947;&#20110;&#23616;&#37096;&#26368;&#22823;&#20540;&#12289;&#32531;&#24930;&#36234;&#36807;&#38797;&#28857;&#21644;&#26356;&#21916;&#27426;&#23574;&#38160;&#30340;&#26368;&#23567;&#20540;&#12290;&#36825;&#24378;&#35843;&#20102;&#28145;&#20837;&#20998;&#26512;SGD&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#20316;&#29992;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#20851;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#30740;&#31350;&#36890;&#24120;&#30528;&#30524;&#20110;&#20854;&#25104;&#21151;&#65292;&#26412;&#30740;&#31350;&#26500;&#24314;&#20102;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22312;&#20808;&#21069;&#30740;&#31350;&#36890;&#24120;&#20551;&#35774;&#19981;&#25104;&#31435;&#30340;&#24773;&#20917;&#19979;&#65292;SGD&#21487;&#33021;&#34920;&#29616;&#20986;&#35768;&#22810;&#22855;&#24618;&#19988;&#28508;&#22312;&#30340;&#19981;&#33391;&#34892;&#20026;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#26223;&#35266;&#21644;&#25968;&#25454;&#20998;&#24067;&#65292;&#20351;&#24471;&#65288;1&#65289;SGD&#25910;&#25947;&#20110;&#23616;&#37096;&#26368;&#22823;&#20540;&#65292;&#65288;2&#65289;SGD&#32531;&#24930;&#36234;&#36807;&#38797;&#28857;&#65292;(3) SGD&#26356;&#21916;&#27426;&#23574;&#38160;&#30340;&#26368;&#23567;&#20540;&#32780;&#38750;&#24179;&#22374;&#30340;&#26368;&#23567;&#20540;&#65292;(4) AMSGrad&#25910;&#25947;&#20110;&#23616;&#37096;&#26368;&#22823;&#20540;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#26497;&#31616;&#30340;&#31070;&#32463;&#32593;&#32476;&#31034;&#20363;&#36827;&#34892;&#20102;&#23454;&#29616;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#24378;&#35843;&#20102;&#21516;&#26102;&#20998;&#26512;&#23567;&#25209;&#37327;&#37319;&#26679;&#12289;&#31163;&#25955;&#26102;&#38388;&#26356;&#26032;&#35268;&#21017;&#21644;&#29616;&#23454;&#26223;&#35266;&#20197;&#20102;&#35299;SGD&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#20316;&#29992;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Previous works on stochastic gradient descent (SGD) often focus on its success. In this work, we construct worst-case optimization problems illustrating that, when not in the regimes that the previous works often assume, SGD can exhibit many strange and potentially undesirable behaviors. Specifically, we construct landscapes and data distributions such that (1) SGD converges to local maxima, (2) SGD escapes saddle points arbitrarily slowly, (3) SGD prefers sharp minima over flat ones, and (4) AMSGrad converges to local maxima. We also realize results in a minimal neural network-like example. Our results highlight the importance of simultaneously analyzing the minibatch sampling, discrete-time updates rules, and realistic landscapes to understand the role of SGD in deep learning.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22810;&#33218;&#32769;&#34382;&#26426;&#28216;&#25103;&#20013;&#35782;&#21035;&#26368;&#20248;&#33218;&#30340;&#38382;&#39064;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#25506;&#32034;&#33218;&#30340;&#22870;&#21169;&#24046;&#36317;&#21644;&#26041;&#24046;&#65292;&#24182;&#20351;&#29992;&#19968;&#31181;&#31216;&#20026;&#20998;&#32452;&#20013;&#20301;&#25968;&#28120;&#27760;&#30340;&#26032;&#26041;&#27861;&#26681;&#25454;&#25910;&#38598;&#30340;&#20449;&#24687;&#20570;&#20986;&#26410;&#26469;&#20915;&#31574;&#12290;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#20445;&#35777;&#20197;&#27010;&#29575;(1-&#948;)&#36755;&#20986;&#26368;&#20248;&#33218;&#65292;&#24182;&#20351;&#29992;&#26368;&#22810;&#30340;O&#65288;&#931;(i=1)^n (&#963;i&#178;/&#916;i&#178;+1/&#916;i)(ln&#948;-1+ln ln&#916;i-1)&#65289;&#20010;&#26679;&#26412;&#65292;&#36825;&#27604;&#26041;&#24046;&#29420;&#31435;&#31639;&#27861;&#33719;&#24471;&#20102;&#26126;&#26174;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2106.10417</link><description>&lt;p&gt;
&#26041;&#24046;&#30456;&#20851;&#30340;&#26368;&#20248;&#33218;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Variance-Dependent Best Arm Identification. (arXiv:2106.10417v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.10417
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22810;&#33218;&#32769;&#34382;&#26426;&#28216;&#25103;&#20013;&#35782;&#21035;&#26368;&#20248;&#33218;&#30340;&#38382;&#39064;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#25506;&#32034;&#33218;&#30340;&#22870;&#21169;&#24046;&#36317;&#21644;&#26041;&#24046;&#65292;&#24182;&#20351;&#29992;&#19968;&#31181;&#31216;&#20026;&#20998;&#32452;&#20013;&#20301;&#25968;&#28120;&#27760;&#30340;&#26032;&#26041;&#27861;&#26681;&#25454;&#25910;&#38598;&#30340;&#20449;&#24687;&#20570;&#20986;&#26410;&#26469;&#20915;&#31574;&#12290;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#20445;&#35777;&#20197;&#27010;&#29575;(1-&#948;)&#36755;&#20986;&#26368;&#20248;&#33218;&#65292;&#24182;&#20351;&#29992;&#26368;&#22810;&#30340;O&#65288;&#931;(i=1)^n (&#963;i&#178;/&#916;i&#178;+1/&#916;i)(ln&#948;-1+ln ln&#916;i-1)&#65289;&#20010;&#26679;&#26412;&#65292;&#36825;&#27604;&#26041;&#24046;&#29420;&#31435;&#31639;&#27861;&#33719;&#24471;&#20102;&#26126;&#26174;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38543;&#26426;&#22810;&#33218;&#32769;&#34382;&#26426;&#28216;&#25103;&#20013;&#35782;&#21035;&#26368;&#20248;&#33218;&#30340;&#38382;&#39064;&#12290;&#32473;&#23450;&#19968;&#20010;&#20174;1&#21040;n&#26631;&#21495;&#30340;&#33218;&#30340;&#38598;&#21512;&#65292;&#27599;&#20010;&#33218;i&#37117;&#19982;&#19968;&#20010;&#25903;&#25345;[0,1]&#19978;&#24179;&#22343;&#20540;&#20026;&#952;i&#21644;&#26041;&#24046;&#20026;&#963;i&#178;&#30340;&#26410;&#30693;&#22870;&#21169;&#20998;&#24067;&#30456;&#20851;&#32852;&#12290;&#20551;&#35774;&#952;1&gt;&#952;2&#8805;...&#8805;&#952;n&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#25506;&#32034;&#33218;&#30340;&#22870;&#21169;&#24046;&#36317;&#21644;&#26041;&#24046;&#65292;&#24182;&#20351;&#29992;&#19968;&#31181;&#31216;&#20026;&#20998;&#32452;&#20013;&#20301;&#25968;&#28120;&#27760;&#30340;&#26032;&#26041;&#27861;&#26681;&#25454;&#25910;&#38598;&#30340;&#20449;&#24687;&#20570;&#20986;&#26410;&#26469;&#20915;&#31574;&#12290;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#20445;&#35777;&#20197;&#27010;&#29575;(1-&#948;)&#36755;&#20986;&#26368;&#20248;&#33218;&#65292;&#24182;&#20351;&#29992;&#26368;&#22810;&#30340;O&#65288;&#931;(i=1)^n (&#963;i&#178;/&#916;i&#178;+1/&#916;i)(ln&#948;-1+ln ln&#916;i-1)&#65289;&#20010;&#26679;&#26412;&#65292;&#20854;&#20013; &#916;i (i&#8805;2)&#34920;&#31034;&#33218;i&#19982;&#26368;&#20248;&#33218;&#20043;&#38388;&#30340;&#22870;&#21169;&#24046;&#36317;&#65292;&#25105;&#20204;&#23450;&#20041; &#916;1 = &#916;2&#12290;&#36825;&#27604;&#26041;&#24046;&#29420;&#31435;&#31639;&#27861;&#33719;&#24471;&#20102;&#26126;&#26174;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of identifying the best arm in a stochastic multi-armed bandit game. Given a set of $n$ arms indexed from $1$ to $n$, each arm $i$ is associated with an unknown reward distribution supported on $[0,1]$ with mean $\theta_i$ and variance $\sigma_i^2$. Assume $\theta_1 &gt; \theta_2 \geq \cdots \geq\theta_n$. We propose an adaptive algorithm which explores the gaps and variances of the rewards of the arms and makes future decisions based on the gathered information using a novel approach called \textit{grouped median elimination}. The proposed algorithm guarantees to output the best arm with probability $(1-\delta)$ and uses at most $O \left(\sum_{i = 1}^n \left(\frac{\sigma_i^2}{\Delta_i^2} + \frac{1}{\Delta_i}\right)(\ln \delta^{-1} + \ln \ln \Delta_i^{-1})\right)$ samples, where $\Delta_i$ ($i \geq 2$) denotes the reward gap between arm $i$ and the best arm and we define $\Delta_1 = \Delta_2$. This achieves a significant advantage over the variance-independent algorit
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#22312;&#20855;&#26377;&#29366;&#24577;&#20998;&#24067;$[\pi_x:x \in \mathcal{X}]$&#21644;&#36716;&#31227;&#27010;&#29575;&#30697;&#38453;&#65288;t.p.m.&#65289;$P$&#30340;&#23383;&#27597;&#34920;$\mathcal{X}$&#19978;&#65292;Markov&#26679;&#26412;&#30340;&#32570;&#22833;&#31283;&#24577;&#36136;&#37327;&#65288;&#21363;&#32570;&#22833;&#31526;&#21495;&#30340;&#24635;&#31283;&#24577;&#27010;&#29575;&#65289;&#30340;GT&#20272;&#35745;&#22120;&#30340;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2102.01938</link><description>&lt;p&gt;
Good-Turing&#22312;&#39532;&#23572;&#21487;&#22827;&#37319;&#26679;&#20013;&#30340;&#24212;&#29992;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
How good is Good-Turing for Markov samples?. (arXiv:2102.01938v3 [cs.IT] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.01938
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#22312;&#20855;&#26377;&#29366;&#24577;&#20998;&#24067;$[\pi_x:x \in \mathcal{X}]$&#21644;&#36716;&#31227;&#27010;&#29575;&#30697;&#38453;&#65288;t.p.m.&#65289;$P$&#30340;&#23383;&#27597;&#34920;$\mathcal{X}$&#19978;&#65292;Markov&#26679;&#26412;&#30340;&#32570;&#22833;&#31283;&#24577;&#36136;&#37327;&#65288;&#21363;&#32570;&#22833;&#31526;&#21495;&#30340;&#24635;&#31283;&#24577;&#27010;&#29575;&#65289;&#30340;GT&#20272;&#35745;&#22120;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Good-Turing&#65288;GT&#65289;&#20272;&#35745;&#22120;&#29992;&#20110;&#20272;&#35745;$n$&#20010;&#26679;&#26412;&#20013;&#32570;&#22833;&#30340;&#36136;&#37327;&#65288;&#21363;&#32570;&#22833;&#31526;&#21495;&#30340;&#24635;&#27010;&#29575;&#65289;&#26159;&#20986;&#29616;&#19968;&#27425;&#30340;&#31526;&#21495;&#25968;&#37327;&#38500;&#20197;$n$&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20855;&#26377;&#29366;&#24577;&#20998;&#24067;$[\pi_x:x \in \mathcal{X}]$&#21644;&#36716;&#31227;&#27010;&#29575;&#30697;&#38453;&#65288;t.p.m.&#65289;$P$&#30340;&#23383;&#27597;&#34920;$\mathcal{X}$&#19978;&#65292;Markov&#26679;&#26412;&#30340;&#32570;&#22833;&#31283;&#24577;&#36136;&#37327;&#65288;&#21363;&#32570;&#22833;&#31526;&#21495;&#30340;&#24635;&#31283;&#24577;&#27010;&#29575;&#65289;&#30340;GT&#20272;&#35745;&#22120;&#30340;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;GT&#30340;&#25910;&#25947;&#24615;&#21462;&#20915;&#20110;$(P^{\sim x})^n$&#30340;&#25910;&#25947;&#24615;&#65292;&#20854;&#20013;$P^{\sim x}$&#26159;&#22312;$P$&#30340;&#31532;$x$&#21015;&#32622;&#38646;&#21518;&#30340;&#30697;&#38453;&#12290;&#36825;&#20010;&#38382;&#39064;&#23545;&#20110;&#20855;&#26377;&#26102;&#38388;&#20381;&#36182;&#24615;&#30340;&#24212;&#29992;&#31243;&#24207;&#38750;&#24120;&#37325;&#35201;&#21644;&#26377;&#36259;&#65292;&#27604;&#22914;&#23558;&#27010;&#29575;&#36171;&#32473;&#21333;&#35789;&#24207;&#21015;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#36825;&#20123;&#27169;&#22411;&#34987;&#24314;&#27169;&#20026;Markov&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Good-Turing (GT) estimator for the missing mass (i.e., total probability of missing symbols) in $n$ samples is the number of symbols that appeared exactly once divided by $n$. For i.i.d. samples, the bias and squared-error risk of the GT estimator can be shown to fall as $1/n$ by bounding the expected error uniformly over all symbols. In this work, we study convergence of the GT estimator for missing stationary mass (i.e., total stationary probability of missing symbols) of Markov samples on an alphabet $\mathcal{X}$ with stationary distribution $[\pi_x:x \in \mathcal{X}]$ and transition probability matrix (t.p.m.) $P$. This is an important and interesting problem because GT is widely used in applications with temporal dependencies such as language models assigning probabilities to word sequences, which are modelled as Markov. We show that convergence of GT depends on convergence of $(P^{\sim x})^n$, where $P^{\sim x}$ is $P$ with the $x$-th column zeroed out. This, in turn, depend
&lt;/p&gt;</description></item><item><title>&#36825;&#26412;&#19987;&#33879;&#20171;&#32461;&#20102;&#22312;&#32447;&#23398;&#20064;&#30340;&#22522;&#26412;&#27010;&#24565;&#20197;&#21450;&#20984;&#20248;&#21270;&#32972;&#26223;&#19979;&#30340;&#19968;&#38454;&#21644;&#20108;&#38454;&#31639;&#27861;, &#21253;&#25324;&#27431;&#20960;&#37324;&#24471;&#21644;&#38750;&#27431;&#20960;&#37324;&#24471;&#35774;&#32622;&#20013;&#30340;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#25110;&#36981;&#24490;&#27491;&#21017;&#21270;&#39046;&#23548;&#32773;&#31561;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/1912.13213</link><description>&lt;p&gt;
&#22312;&#32447;&#23398;&#20064;&#30340;&#29616;&#20195;&#20171;&#32461;
&lt;/p&gt;
&lt;p&gt;
A Modern Introduction to Online Learning. (arXiv:1912.13213v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1912.13213
&lt;/p&gt;
&lt;p&gt;
&#36825;&#26412;&#19987;&#33879;&#20171;&#32461;&#20102;&#22312;&#32447;&#23398;&#20064;&#30340;&#22522;&#26412;&#27010;&#24565;&#20197;&#21450;&#20984;&#20248;&#21270;&#32972;&#26223;&#19979;&#30340;&#19968;&#38454;&#21644;&#20108;&#38454;&#31639;&#27861;, &#21253;&#25324;&#27431;&#20960;&#37324;&#24471;&#21644;&#38750;&#27431;&#20960;&#37324;&#24471;&#35774;&#32622;&#20013;&#30340;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#25110;&#36981;&#24490;&#27491;&#21017;&#21270;&#39046;&#23548;&#32773;&#31561;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#26412;&#19987;&#33879;&#20013;&#65292;&#25105;&#36890;&#36807;&#29616;&#20195;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#35270;&#35282;&#20171;&#32461;&#20102;&#22312;&#32447;&#23398;&#20064;&#30340;&#22522;&#26412;&#27010;&#24565;&#12290;&#22312;&#36825;&#37324;&#65292;&#22312;&#32447;&#23398;&#20064;&#25351;&#30340;&#26159;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#36951;&#25022;&#26368;&#23567;&#21270;&#26694;&#26550;&#12290;&#25105;&#20171;&#32461;&#20102;&#19968;&#38454;&#21644;&#20108;&#38454;&#20855;&#26377;&#20984;&#25439;&#22833;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#20197;&#27431;&#20960;&#37324;&#24471;&#21644;&#38750;&#27431;&#20960;&#37324;&#24471;&#35774;&#32622;&#20026;&#22522;&#30784;&#65292;&#25152;&#26377;&#31639;&#27861;&#37117;&#28165;&#26224;&#22320;&#21576;&#29616;&#20026;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#25110;&#36981;&#24490;&#27491;&#21017;&#21270;&#39046;&#23548;&#32773;&#21450;&#20854;&#21464;&#24418;&#30340;&#23454;&#20363;&#12290;&#29305;&#21035;&#20851;&#27880;&#31639;&#27861;&#21442;&#25968;&#30340;&#35843;&#25972;&#38382;&#39064;&#21644;&#36890;&#36807;&#33258;&#36866;&#24212;&#21644;&#26080;&#21442;&#25968;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#22312;&#26080;&#30028;&#22495;&#20013;&#30340;&#23398;&#20064;&#12290; &#20984;&#25439;&#22833;&#36890;&#36807;&#20984;&#20195;&#29702;&#25439;&#22833;&#21644;&#38543;&#26426;&#21270;&#22788;&#29702;&#65292;&#26469;&#22788;&#29702;&#38750;&#20984;&#25439;&#22833;&#12290;&#21516;&#26102;&#36824;&#31616;&#35201;&#35752;&#35770;&#20102;&#36172;&#21338;&#35774;&#32622;&#65292;&#28041;&#21450;&#25932;&#23545;&#21644;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#12290;&#36825;&#20123;&#31508;&#35760;&#19981;&#38656;&#35201;&#20808;&#21069;&#23545;&#20984;&#20998;&#26512;&#30340;&#20102;&#35299;&#65292;&#24182;&#19988;&#25152;&#26377;&#25152;&#38656;&#30340;&#25968;&#23398;&#24037;&#20855;&#37117;&#24050;&#20005;&#35880;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this monograph, I introduce the basic concepts of Online Learning through a modern view of Online Convex Optimization. Here, online learning refers to the framework of regret minimization under worst-case assumptions. I present first-order and second-order algorithms for online learning with convex losses, in Euclidean and non-Euclidean settings. All the algorithms are clearly presented as instantiation of Online Mirror Descent or Follow-The-Regularized-Leader and their variants. Particular attention is given to the issue of tuning the parameters of the algorithms and learning in unbounded domains, through adaptive and parameter-free online learning algorithms. Non-convex losses are dealt through convex surrogate losses and through randomization. The bandit setting is also briefly discussed, touching on the problem of adversarial and stochastic multi-armed bandits. These notes do not require prior knowledge of convex analysis and all the required mathematical tools are rigorously ex
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#30340;&#26041;&#27861;&#26469;&#24555;&#36895;&#35745;&#31639;Dirichlet&#20998;&#24067;&#30340;MLE&#21442;&#25968;&#65292;&#30456;&#36739;&#20110;&#29616;&#26377;&#23454;&#29616;&#26041;&#27861;&#65292;&#21482;&#38656;&#35201;&#19968;&#36941;&#36941;&#21382;&#25968;&#25454;&#38598;&#23601;&#21487;&#20197;&#22823;&#22823;&#20943;&#23569;&#36816;&#34892;&#26102;&#38388;&#12290;</title><link>http://arxiv.org/abs/1405.0099</link><description>&lt;p&gt;
Dirichlet&#22810;&#39033;&#24335;&#30340;&#24555;&#36895;MLE&#35745;&#31639;
&lt;/p&gt;
&lt;p&gt;
Fast MLE Computation for the Dirichlet Multinomial. (arXiv:1405.0099v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1405.0099
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#30340;&#26041;&#27861;&#26469;&#24555;&#36895;&#35745;&#31639;Dirichlet&#20998;&#24067;&#30340;MLE&#21442;&#25968;&#65292;&#30456;&#36739;&#20110;&#29616;&#26377;&#23454;&#29616;&#26041;&#27861;&#65292;&#21482;&#38656;&#35201;&#19968;&#36941;&#36941;&#21382;&#25968;&#25454;&#38598;&#23601;&#21487;&#20197;&#22823;&#22823;&#20943;&#23569;&#36816;&#34892;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32473;&#23450;&#19968;&#20010;&#20998;&#31867;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#24076;&#26395;&#25214;&#21040;&#19968;&#20010;Dirichlet&#20998;&#24067;&#30340;&#21442;&#25968;&#65292;&#20351;&#24471;&#22312;&#35813;&#20998;&#24067;&#19979;&#65292;&#36825;&#20010;&#25968;&#25454;&#38598;&#30340;&#20284;&#28982;&#20989;&#25968;&#26368;&#22823;&#21270;&#12290;&#36890;&#24120;&#21033;&#29992;&#29275;&#39039;&#36845;&#20195;&#27861;&#26469;&#27714;&#35299;&#65292;&#20294;&#30446;&#21069;&#30340;&#23454;&#29616;&#38656;&#35201;&#27599;&#27425;&#36845;&#20195;&#37117;&#35835;&#21462;&#25972;&#20010;&#25968;&#25454;&#38598;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#26041;&#27861;&#65292;&#21482;&#38656;&#35201;&#19968;&#27425;&#36890;&#36807;&#25968;&#25454;&#38598;&#65292;&#24182;&#22823;&#22823;&#20943;&#23569;&#20102;&#36816;&#34892;&#26102;&#38388;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#20174;&#29702;&#35770;&#21644;&#23454;&#35777;&#30340;&#35282;&#24230;&#20998;&#26512;&#20102;&#35813;&#31639;&#27861;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20379;&#20102;&#24320;&#28304;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given a collection of categorical data, we want to find the parameters of a Dirichlet distribution which maximizes the likelihood of that data. Newton's method is typically used for this purpose but current implementations require reading through the entire dataset on each iteration. In this paper, we propose a modification which requires only a single pass through the dataset and substantially decreases running time. Furthermore we analyze both theoretically and empirically the performance of the proposed algorithm, and provide an open source implementation.
&lt;/p&gt;</description></item></channel></rss>