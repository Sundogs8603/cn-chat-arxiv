<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20132;&#20114;&#24335;&#38382;&#31572;&#26469;&#35782;&#21035;&#20195;&#29702;&#20154;&#30340;&#39118;&#38505;&#35268;&#36991;&#12290;&#22312;&#19968;&#26399;&#24773;&#26223;&#21644;&#26080;&#38480;&#26399;&#24773;&#26223;&#19979;&#65292;&#25105;&#20204;&#36890;&#36807;&#35201;&#27714;&#20195;&#29702;&#20154;&#23637;&#31034;&#22905;&#30340;&#26368;&#20248;&#31574;&#30053;&#26469;&#22238;&#31572;&#38382;&#39064;&#65292;&#20351;&#29992;&#38543;&#26426;&#35774;&#35745;&#30340;&#38382;&#39064;&#26469;&#35782;&#21035;&#20195;&#29702;&#20154;&#30340;&#39118;&#38505;&#35268;&#36991;&#12290;&#36825;&#20010;&#26041;&#27861;&#21487;&#20197;&#36890;&#36807;&#19968;&#20010;&#26377;&#38480;&#30340;&#20505;&#36873;&#38598;&#26377;&#25928;&#22320;&#35782;&#21035;&#20986;&#20195;&#29702;&#20154;&#30340;&#39118;&#38505;&#35268;&#36991;&#12290;</title><link>http://arxiv.org/abs/2308.08427</link><description>&lt;p&gt;
&#20511;&#21161;&#20132;&#20114;&#24335;&#38382;&#31572;&#36890;&#36807;&#36870;&#24378;&#21270;&#23398;&#20064;&#26469;&#24341;&#23548;&#39118;&#38505;&#35268;&#36991;
&lt;/p&gt;
&lt;p&gt;
Eliciting Risk Aversion with Inverse Reinforcement Learning via Interactive Questioning. (arXiv:2308.08427v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08427
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20132;&#20114;&#24335;&#38382;&#31572;&#26469;&#35782;&#21035;&#20195;&#29702;&#20154;&#30340;&#39118;&#38505;&#35268;&#36991;&#12290;&#22312;&#19968;&#26399;&#24773;&#26223;&#21644;&#26080;&#38480;&#26399;&#24773;&#26223;&#19979;&#65292;&#25105;&#20204;&#36890;&#36807;&#35201;&#27714;&#20195;&#29702;&#20154;&#23637;&#31034;&#22905;&#30340;&#26368;&#20248;&#31574;&#30053;&#26469;&#22238;&#31572;&#38382;&#39064;&#65292;&#20351;&#29992;&#38543;&#26426;&#35774;&#35745;&#30340;&#38382;&#39064;&#26469;&#35782;&#21035;&#20195;&#29702;&#20154;&#30340;&#39118;&#38505;&#35268;&#36991;&#12290;&#36825;&#20010;&#26041;&#27861;&#21487;&#20197;&#36890;&#36807;&#19968;&#20010;&#26377;&#38480;&#30340;&#20505;&#36873;&#38598;&#26377;&#25928;&#22320;&#35782;&#21035;&#20986;&#20195;&#29702;&#20154;&#30340;&#39118;&#38505;&#35268;&#36991;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#20132;&#20114;&#24335;&#38382;&#31572;&#26469;&#35782;&#21035;&#20195;&#29702;&#20154;&#30340;&#39118;&#38505;&#35268;&#36991;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#22312;&#20004;&#31181;&#24773;&#26223;&#20013;&#36827;&#34892;&#65306;&#19968;&#26399;&#24773;&#26223;&#21644;&#26080;&#38480;&#26399;&#24773;&#26223;&#12290;&#22312;&#19968;&#26399;&#24773;&#26223;&#20013;&#65292;&#25105;&#20204;&#20551;&#35774;&#20195;&#29702;&#20154;&#30340;&#39118;&#38505;&#35268;&#36991;&#30001;&#29366;&#24577;&#30340;&#25104;&#26412;&#20989;&#25968;&#21644;&#22833;&#30495;&#39118;&#38505;&#24230;&#37327;&#25152;&#34920;&#24449;&#12290;&#22312;&#26080;&#38480;&#26399;&#24773;&#26223;&#20013;&#65292;&#25105;&#20204;&#29992;&#19968;&#20010;&#39069;&#22806;&#30340;&#25104;&#20998;&#65292;&#25240;&#25187;&#22240;&#23376;&#65292;&#26469;&#24314;&#27169;&#39118;&#38505;&#35268;&#36991;&#12290;&#20551;&#35774;&#25105;&#20204;&#21487;&#20197;&#35775;&#38382;&#19968;&#20010;&#21253;&#21547;&#20195;&#29702;&#20154;&#30495;&#23454;&#39118;&#38505;&#35268;&#36991;&#30340;&#26377;&#38480;&#20505;&#36873;&#38598;&#65292;&#25105;&#20204;&#35777;&#26126;&#36890;&#36807;&#35201;&#27714;&#20195;&#29702;&#20154;&#22312;&#21508;&#31181;&#29615;&#22659;&#20013;&#23637;&#31034;&#22905;&#30340;&#26368;&#20248;&#25919;&#31574;&#26469;&#22238;&#31572;&#38382;&#39064;&#65292;&#36825;&#21487;&#20197;&#26377;&#25928;&#22320;&#35782;&#21035;&#20195;&#29702;&#20154;&#30340;&#39118;&#38505;&#35268;&#36991;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#38382;&#39064;&#30340;&#25968;&#37327;&#36235;&#36817;&#26080;&#31351;&#22823;&#24182;&#19988;&#38382;&#39064;&#26159;&#38543;&#26426;&#35774;&#35745;&#30340;&#26102;&#20505;&#65292;&#21487;&#20197;&#35782;&#21035;&#20986;&#20195;&#29702;&#20154;&#30340;&#39118;&#38505;&#35268;&#36991;&#12290;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#20010;&#31639;&#27861;&#29992;&#20110;&#35774;&#35745;&#26368;&#20248;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#35777;&#35777;&#25454;&#26469;&#25903;&#25345;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a novel framework for identifying an agent's risk aversion using interactive questioning. Our study is conducted in two scenarios: a one-period case and an infinite horizon case. In the one-period case, we assume that the agent's risk aversion is characterized by a cost function of the state and a distortion risk measure. In the infinite horizon case, we model risk aversion with an additional component, a discount factor. Assuming the access to a finite set of candidates containing the agent's true risk aversion, we show that asking the agent to demonstrate her optimal policies in various environment, which may depend on their previous answers, is an effective means of identifying the agent's risk aversion. Specifically, we prove that the agent's risk aversion can be identified as the number of questions tends to infinity, and the questions are randomly designed. We also develop an algorithm for designing optimal questions and provide empirical evidence that our met
&lt;/p&gt;</description></item><item><title>Continuous Sweep&#26159;&#19968;&#31181;&#25913;&#36827;&#30340;&#20108;&#20803;&#37327;&#21270;&#22120;&#65292;&#36890;&#36807;&#20351;&#29992;&#21442;&#25968;&#21270;&#31867;&#21035;&#20998;&#24067;&#12289;&#20248;&#21270;&#20915;&#31574;&#36793;&#30028;&#20197;&#21450;&#35745;&#31639;&#22343;&#20540;&#31561;&#26041;&#27861;&#65292;&#23427;&#22312;&#37327;&#21270;&#23398;&#20064;&#20013;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.08387</link><description>&lt;p&gt;
Continuous Sweep: &#19968;&#31181;&#25913;&#36827;&#30340;&#20108;&#20803;&#37327;&#21270;&#22120;
&lt;/p&gt;
&lt;p&gt;
Continuous Sweep: an improved, binary quantifier. (arXiv:2308.08387v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08387
&lt;/p&gt;
&lt;p&gt;
Continuous Sweep&#26159;&#19968;&#31181;&#25913;&#36827;&#30340;&#20108;&#20803;&#37327;&#21270;&#22120;&#65292;&#36890;&#36807;&#20351;&#29992;&#21442;&#25968;&#21270;&#31867;&#21035;&#20998;&#24067;&#12289;&#20248;&#21270;&#20915;&#31574;&#36793;&#30028;&#20197;&#21450;&#35745;&#31639;&#22343;&#20540;&#31561;&#26041;&#27861;&#65292;&#23427;&#22312;&#37327;&#21270;&#23398;&#20064;&#20013;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#21270;&#26159;&#19968;&#31181;&#30417;&#30563;&#24335;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#20854;&#20851;&#27880;&#30340;&#26159;&#20272;&#35745;&#25968;&#25454;&#38598;&#20013;&#31867;&#21035;&#30340;&#26222;&#36941;&#24615;&#65292;&#32780;&#19981;&#26159;&#26631;&#35760;&#20854;&#20010;&#20307;&#35266;&#27979;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;Continuous Sweep&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#30340;&#21442;&#25968;&#21270;&#20108;&#20803;&#37327;&#21270;&#22120;&#65292;&#21463;&#21040;&#34920;&#29616;&#33391;&#22909;&#30340;Median Sweep&#30340;&#21551;&#21457;&#12290;Median Sweep&#30446;&#21069;&#26159;&#26368;&#22909;&#30340;&#20108;&#20803;&#37327;&#21270;&#22120;&#20043;&#19968;&#65292;&#20294;&#25105;&#20204;&#22312;&#19977;&#20010;&#26041;&#38754;&#25913;&#21464;&#20102;&#36825;&#20010;&#37327;&#21270;&#22120;&#65292;&#21363;1&#65289;&#20351;&#29992;&#21442;&#25968;&#21270;&#30340;&#31867;&#21035;&#20998;&#24067;&#32780;&#19981;&#26159;&#32463;&#39564;&#20998;&#24067;&#65292;2&#65289;&#20248;&#21270;&#20915;&#31574;&#36793;&#30028;&#32780;&#19981;&#26159;&#24212;&#29992;&#31163;&#25955;&#30340;&#20915;&#31574;&#35268;&#21017;&#65292;3&#65289;&#35745;&#31639;&#22343;&#20540;&#32780;&#19981;&#26159;&#20013;&#20301;&#25968;&#12290;&#22312;&#19968;&#33324;&#27169;&#22411;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;Continuous Sweep&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#12290;&#36825;&#26159;&#37327;&#21270;&#23398;&#20064;&#39046;&#22495;&#20013;&#30340;&#39318;&#27425;&#29702;&#35770;&#36129;&#29486;&#20043;&#19968;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#25512;&#23548;&#20351;&#25105;&#20204;&#33021;&#22815;&#25214;&#21040;&#26368;&#20248;&#30340;&#20915;&#31574;&#36793;&#30028;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#30340;&#27169;&#25311;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#24191;&#27867;&#30340;&#24773;&#20917;&#19979;&#65292;Continuous Sweep&#20248;&#20110;Median Sweep&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantification is a supervised machine learning task, focused on estimating the class prevalence of a dataset rather than labeling its individual observations. We introduce Continuous Sweep, a new parametric binary quantifier inspired by the well-performing Median Sweep. Median Sweep is currently one of the best binary quantifiers, but we have changed this quantifier on three points, namely 1) using parametric class distributions instead of empirical distributions, 2) optimizing decision boundaries instead of applying discrete decision rules, and 3) calculating the mean instead of the median. We derive analytic expressions for the bias and variance of Continuous Sweep under general model assumptions. This is one of the first theoretical contributions in the field of quantification learning. Moreover, these derivations enable us to find the optimal decision boundaries. Finally, our simulation study shows that Continuous Sweep outperforms Median Sweep in a wide range of situations.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#20004;&#23618;&#38750;&#32447;&#24615;&#21333;&#20803;&#22238;&#24402;&#30340;&#25910;&#25947;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;softmax ReLU&#22238;&#24402;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;Hessian&#30340;&#24615;&#36136;&#65292;&#24341;&#20837;&#20102;&#22522;&#20110;&#36817;&#20284;&#29275;&#39039;&#27861;&#30340;&#36138;&#23146;&#31639;&#27861;&#65292;&#26368;&#21518;&#35777;&#26126;&#20102;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.08358</link><description>&lt;p&gt;
&#20004;&#23618;&#38750;&#32447;&#24615;&#21333;&#20803;&#22238;&#24402;&#30340;&#25910;&#25947;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Convergence of Two-Layer Regression with Nonlinear Units. (arXiv:2308.08358v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08358
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#20004;&#23618;&#38750;&#32447;&#24615;&#21333;&#20803;&#22238;&#24402;&#30340;&#25910;&#25947;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;softmax ReLU&#22238;&#24402;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;Hessian&#30340;&#24615;&#36136;&#65292;&#24341;&#20837;&#20102;&#22522;&#20110;&#36817;&#20284;&#29275;&#39039;&#27861;&#30340;&#36138;&#23146;&#31639;&#27861;&#65292;&#26368;&#21518;&#35777;&#26126;&#20102;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#22914;ChatGPT&#21644;GPT4&#65292;&#22312;&#35768;&#22810;&#20154;&#31867;&#29983;&#27963;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;&#27880;&#24847;&#21147;&#35745;&#31639;&#22312;&#35757;&#32451;LLMs&#20013;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;Softmax&#21333;&#20803;&#21644;ReLU&#21333;&#20803;&#26159;&#27880;&#24847;&#21147;&#35745;&#31639;&#30340;&#20851;&#38190;&#32467;&#26500;&#12290;&#21463;&#21040;&#23427;&#20204;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;softmax ReLU&#22238;&#24402;&#38382;&#39064;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#25214;&#21040;&#28041;&#21450;ReLU&#21333;&#20803;&#30340;&#22238;&#24402;&#38382;&#39064;&#30340;&#26368;&#20248;&#35299;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35745;&#31639;&#20102;&#25439;&#22833;&#20989;&#25968;&#30340;Hessian&#30340;&#38381;&#21512;&#24418;&#24335;&#34920;&#31034;&#12290;&#22312;&#19968;&#23450;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;Hessian&#30340;Lipschitz&#36830;&#32493;&#24615;&#21644;PSD&#24615;&#36136;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#36817;&#20284;&#29275;&#39039;&#27861;&#30340;&#36138;&#23146;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#36317;&#31163;&#26368;&#20248;&#35299;&#30340;&#24847;&#20041;&#19979;&#25910;&#25947;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25918;&#23485;&#20102;Lipschitz&#26465;&#20214;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#25439;&#22833;&#20540;&#30340;&#24847;&#20041;&#19979;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs), such as ChatGPT and GPT4, have shown outstanding performance in many human life task. Attention computation plays an important role in training LLMs. Softmax unit and ReLU unit are the key structure in attention computation. Inspired by them, we put forward a softmax ReLU regression problem. Generally speaking, our goal is to find an optimal solution to the regression problem involving the ReLU unit. In this work, we calculate a close form representation for the Hessian of the loss function. Under certain assumptions, we prove the Lipschitz continuous and the PSDness of the Hessian. Then, we introduce an greedy algorithm based on approximate Newton method, which converges in the sense of the distance to optimal solution. Last, We relax the Lipschitz condition and prove the convergence in the sense of loss value.
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#25197;&#26354;&#20960;&#20309;&#23398;&#30340;&#27010;&#24565;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#39640;&#32500;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#20013;&#20248;&#21270;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#22312;&#37325;&#26032;&#23450;&#20041;&#30340;&#40654;&#26364;&#27969;&#24418;&#19978;&#36827;&#34892;&#35745;&#31639;&#65292;&#25214;&#21040;&#20102;&#20989;&#25968;&#30340;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2308.08305</link><description>&lt;p&gt;
&#22312;&#27431;&#20960;&#37324;&#24503;&#20989;&#25968;&#20248;&#21270;&#20013;&#30340;&#25197;&#26354;&#20960;&#20309;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
Warped geometric information on the optimisation of Euclidean functions. (arXiv:2308.08305v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08305
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#25197;&#26354;&#20960;&#20309;&#23398;&#30340;&#27010;&#24565;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#39640;&#32500;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#20013;&#20248;&#21270;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#22312;&#37325;&#26032;&#23450;&#20041;&#30340;&#40654;&#26364;&#27969;&#24418;&#19978;&#36827;&#34892;&#35745;&#31639;&#65292;&#25214;&#21040;&#20102;&#20989;&#25968;&#30340;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#22312;&#28508;&#22312;&#39640;&#32500;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#20013;&#20248;&#21270;&#23454;&#20540;&#20989;&#25968;&#30340;&#22522;&#26412;&#20219;&#21153;&#65292;&#20363;&#22914;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#25439;&#22833;&#20989;&#25968;&#25110;&#32479;&#35745;&#25512;&#26029;&#20013;&#30340;&#27010;&#29575;&#20998;&#24067;&#30340;&#23545;&#25968;&#12290;&#25105;&#20204;&#20351;&#29992;&#25197;&#26354;&#40654;&#26364;&#20960;&#20309;&#27010;&#24565;&#65292;&#23558;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#19978;&#30340;&#20989;&#25968;&#20248;&#21270;&#38382;&#39064;&#37325;&#26032;&#23450;&#20041;&#20026;&#19968;&#20010;&#24102;&#26377;&#25197;&#26354;&#24230;&#37327;&#30340;&#40654;&#26364;&#27969;&#24418;&#65292;&#24182;&#22312;&#35813;&#27969;&#24418;&#19978;&#25214;&#21040;&#20989;&#25968;&#30340;&#26368;&#20248;&#35299;&#12290;&#36873;&#25321;&#29992;&#20110;&#25628;&#32034;&#22495;&#30340;&#25197;&#26354;&#24230;&#37327;&#24341;&#20837;&#20102;&#19968;&#20010;&#35745;&#31639;&#21451;&#22909;&#30340;&#24230;&#37327;&#24352;&#37327;&#65292;&#20351;&#24471;&#22312;&#27969;&#24418;&#19978;&#25214;&#21040;&#26368;&#20248;&#25628;&#32034;&#26041;&#21521;&#19982;&#27979;&#22320;&#32447;&#21464;&#24471;&#26356;&#23481;&#26131;&#35745;&#31639;&#12290;&#27839;&#27979;&#22320;&#32447;&#36827;&#34892;&#20248;&#21270;&#36890;&#24120;&#26159;&#19981;&#21487;&#34892;&#30340;&#65292;&#20294;&#25105;&#20204;&#34920;&#26126;&#22312;&#36825;&#20010;&#29305;&#23450;&#30340;&#27969;&#24418;&#20013;&#65292;&#25105;&#20204;&#21487;&#20197;&#35299;&#26512;&#22320;&#24471;&#21040;&#39640;&#36798;&#19977;&#38454;&#30340;&#27888;&#21202;&#36817;&#20284;&#12290;&#19968;&#33324;&#24773;&#20917;&#19979;&#65292;&#36825;&#20123;&#23545;&#27979;&#22320;&#32447;&#30340;&#36817;&#20284;&#19981;&#20250;&#20301;&#20110;&#27969;&#24418;&#19978;&#65292;&#20294;&#25105;&#20204;&#26500;&#36896;&#20102;&#21512;&#36866;&#30340;&#22238;&#32553;&#26041;&#31243;&#23558;&#36825;&#20123;&#36817;&#20284;&#37325;&#26032;&#26144;&#23556;&#21040;&#27969;&#24418;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the fundamental task of optimizing a real-valued function defined in a potentially high-dimensional Euclidean space, such as the loss function in many machine-learning tasks or the logarithm of the probability distribution in statistical inference. We use the warped Riemannian geometry notions to redefine the optimisation problem of a function on Euclidean space to a Riemannian manifold with a warped metric, and then find the function's optimum along this manifold. The warped metric chosen for the search domain induces a computational friendly metric-tensor for which optimal search directions associate with geodesic curves on the manifold becomes easier to compute. Performing optimization along geodesics is known to be generally infeasible, yet we show that in this specific manifold we can analytically derive Taylor approximations up to third-order. In general these approximations to the geodesic curve will not lie on the manifold, however we construct suitable retraction m
&lt;/p&gt;</description></item><item><title>&#26368;&#36817;&#37051;&#20998;&#31867;&#22120;&#30340;&#32553;&#25918;&#24459;&#21487;&#20998;&#20026;&#20004;&#20010;&#38454;&#27573;&#65306;&#31532;&#19968;&#38454;&#27573;&#20013;&#65292;&#27867;&#21270;&#35823;&#24046;&#22810;&#39033;&#24335;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#24182;&#36805;&#36895;&#20943;&#23567;&#65307;&#31532;&#20108;&#38454;&#27573;&#20013;&#65292;&#35823;&#24046;&#25351;&#25968;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#24182;&#32531;&#24930;&#20943;&#23567;&#12290;&#36825;&#34920;&#26126;&#26368;&#36817;&#37051;&#20998;&#31867;&#22120;&#22312;&#25968;&#25454;&#20998;&#24067;&#33391;&#22909;&#26102;&#21487;&#20197;&#23454;&#29616;&#27867;&#21270;&#35823;&#24046;&#22810;&#39033;&#24335;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#65292;&#32780;&#19981;&#26159;&#25351;&#25968;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#12290;</title><link>http://arxiv.org/abs/2308.08247</link><description>&lt;p&gt;
&#26368;&#36817;&#37051;&#20998;&#31867;&#22120;&#30340;&#20004;&#20010;&#38454;&#27573;&#30340;&#32553;&#25918;&#24459;
&lt;/p&gt;
&lt;p&gt;
Two Phases of Scaling Laws for Nearest Neighbor Classifiers. (arXiv:2308.08247v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08247
&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#37051;&#20998;&#31867;&#22120;&#30340;&#32553;&#25918;&#24459;&#21487;&#20998;&#20026;&#20004;&#20010;&#38454;&#27573;&#65306;&#31532;&#19968;&#38454;&#27573;&#20013;&#65292;&#27867;&#21270;&#35823;&#24046;&#22810;&#39033;&#24335;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#24182;&#36805;&#36895;&#20943;&#23567;&#65307;&#31532;&#20108;&#38454;&#27573;&#20013;&#65292;&#35823;&#24046;&#25351;&#25968;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#24182;&#32531;&#24930;&#20943;&#23567;&#12290;&#36825;&#34920;&#26126;&#26368;&#36817;&#37051;&#20998;&#31867;&#22120;&#22312;&#25968;&#25454;&#20998;&#24067;&#33391;&#22909;&#26102;&#21487;&#20197;&#23454;&#29616;&#27867;&#21270;&#35823;&#24046;&#22810;&#39033;&#24335;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#65292;&#32780;&#19981;&#26159;&#25351;&#25968;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32553;&#25918;&#24459;&#26159;&#25351;&#24403;&#35757;&#32451;&#25968;&#25454;&#25968;&#37327;&#22686;&#21152;&#26102;&#65292;&#27169;&#22411;&#30340;&#27979;&#35797;&#24615;&#33021;&#20250;&#25552;&#39640;&#30340;&#35266;&#23519;&#32467;&#26524;&#12290;&#24555;&#36895;&#30340;&#32553;&#25918;&#24459;&#24847;&#21619;&#30528;&#36890;&#36807;&#22686;&#21152;&#25968;&#25454;&#21644;&#27169;&#22411;&#22823;&#23567;&#23601;&#33021;&#35299;&#20915;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#22686;&#21152;&#26356;&#22810;&#25968;&#25454;&#30340;&#22909;&#22788;&#21487;&#33021;&#26159;&#24494;&#19981;&#36275;&#36947;&#30340;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26368;&#36817;&#37051;&#20998;&#31867;&#22120;&#30340;&#32553;&#25918;&#24459;&#12290;&#25105;&#20204;&#21457;&#29616;&#32553;&#25918;&#24459;&#21487;&#33021;&#26377;&#20004;&#20010;&#38454;&#27573;&#65306;&#22312;&#31532;&#19968;&#38454;&#27573;&#65292;&#27867;&#21270;&#35823;&#24046;&#22810;&#39033;&#24335;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#24182;&#19988;&#24555;&#36895;&#20943;&#23567;&#65307;&#32780;&#22312;&#31532;&#20108;&#38454;&#27573;&#65292;&#35823;&#24046;&#25351;&#25968;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#24182;&#19988;&#20943;&#23567;&#24471;&#24930;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#31361;&#26174;&#20102;&#25968;&#25454;&#20998;&#24067;&#22312;&#20915;&#23450;&#27867;&#21270;&#35823;&#24046;&#20013;&#30340;&#22797;&#26434;&#24615;&#12290;&#24403;&#25968;&#25454;&#20998;&#24067;&#33391;&#22909;&#26102;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#26368;&#36817;&#37051;&#20998;&#31867;&#22120;&#21487;&#20197;&#23454;&#29616;&#27867;&#21270;&#35823;&#24046;&#22810;&#39033;&#24335;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#65292;&#32780;&#19981;&#26159;&#25351;&#25968;&#22320;&#20381;&#36182;&#20110;&#25968;&#25454;&#32500;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
A scaling law refers to the observation that the test performance of a model improves as the number of training data increases. A fast scaling law implies that one can solve machine learning problems by simply boosting the data and the model sizes. Yet, in many cases, the benefit of adding more data can be negligible. In this work, we study the rate of scaling laws of nearest neighbor classifiers. We show that a scaling law can have two phases: in the first phase, the generalization error depends polynomially on the data dimension and decreases fast; whereas in the second phase, the error depends exponentially on the data dimension and decreases slowly. Our analysis highlights the complexity of the data distribution in determining the generalization error. When the data distributes benignly, our result suggests that nearest neighbor classifier can achieve a generalization error that depends polynomially, instead of exponentially, on the data dimension.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#22788;&#29702;&#38750;&#38543;&#26426;&#32570;&#22833;&#25968;&#25454;&#30340;&#28145;&#24230;&#29983;&#25104;&#22635;&#20805;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#26032;&#30340;&#35282;&#24230;&#21435;&#22788;&#29702;&#36825;&#20010;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#24182;&#19988;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#30452;&#25509;&#23558;&#32479;&#35745;&#26041;&#27861;&#32435;&#20837;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#27425;&#20248;&#20043;&#22788;&#12290;</title><link>http://arxiv.org/abs/2308.08158</link><description>&lt;p&gt;
&#28145;&#24230;&#29983;&#25104;&#22635;&#20805;&#27169;&#22411;&#29992;&#20110;&#38750;&#38543;&#26426;&#32570;&#22833;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Deep Generative Imputation Model for Missing Not At Random Data. (arXiv:2308.08158v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08158
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#22788;&#29702;&#38750;&#38543;&#26426;&#32570;&#22833;&#25968;&#25454;&#30340;&#28145;&#24230;&#29983;&#25104;&#22635;&#20805;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#26032;&#30340;&#35282;&#24230;&#21435;&#22788;&#29702;&#36825;&#20010;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#24182;&#19988;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#30452;&#25509;&#23558;&#32479;&#35745;&#26041;&#27861;&#32435;&#20837;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#27425;&#20248;&#20043;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#20998;&#26512;&#36890;&#24120;&#38754;&#20020;&#38750;&#38543;&#26426;&#32570;&#22833;&#65288;MNAR&#65289;&#38382;&#39064;&#65292;&#20854;&#20013;&#32570;&#22833;&#20540;&#30340;&#21407;&#22240;&#27809;&#26377;&#23436;&#20840;&#35266;&#23519;&#21040;&#12290;&#19982;&#31616;&#21333;&#30340;&#23436;&#20840;&#38543;&#26426;&#32570;&#22833;&#65288;MCAR&#65289;&#38382;&#39064;&#30456;&#27604;&#65292;&#36825;&#26356;&#31526;&#21512;&#23454;&#38469;&#24773;&#20917;&#65292;&#20063;&#26356;&#22797;&#26434;&#21644;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#29616;&#26377;&#30340;&#32479;&#35745;&#26041;&#27861;&#36890;&#36807;&#19981;&#21516;&#30340;&#23436;&#25972;&#25968;&#25454;&#21644;&#32570;&#22833;&#33945;&#29256;&#30340;&#32852;&#21512;&#20998;&#24067;&#20998;&#35299;&#26469;&#24314;&#27169;MNAR&#26426;&#21046;&#12290;&#20294;&#25105;&#20204;&#22312;&#32463;&#39564;&#19978;&#21457;&#29616;&#65292;&#30452;&#25509;&#23558;&#36825;&#20123;&#32479;&#35745;&#26041;&#27861;&#32435;&#20837;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#26159;&#27425;&#20248;&#30340;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#23427;&#20250;&#24573;&#35270;MNAR&#22635;&#20805;&#36807;&#31243;&#20013;&#37325;&#26500;&#33945;&#29256;&#30340;&#32622;&#20449;&#24230;&#65292;&#23548;&#33268;&#20449;&#24687;&#25552;&#21462;&#19981;&#36275;&#21644;&#22635;&#20805;&#36136;&#37327;&#19981;&#22815;&#21487;&#38752;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#19968;&#31181;&#26032;&#30340;&#35282;&#24230;&#37325;&#26032;&#23457;&#35270;MNAR&#38382;&#39064;&#65292;&#21363;&#23436;&#25972;&#25968;&#25454;&#21644;&#32570;&#22833;&#33945;&#29256;&#26159;&#20004;&#20010;&#19981;&#23436;&#25972;&#25968;&#25454;&#30340;&#27169;&#24577;&#12290;&#27839;&#30528;&#36825;&#26465;&#32447;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29983;&#25104;&#27169;&#22411;&#29305;&#23450;&#30340;&#32852;&#21512;&#39044;&#27979;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Data analysis usually suffers from the Missing Not At Random (MNAR) problem, where the cause of the value missing is not fully observed. Compared to the naive Missing Completely At Random (MCAR) problem, it is more in line with the realistic scenario whereas more complex and challenging. Existing statistical methods model the MNAR mechanism by different decomposition of the joint distribution of the complete data and the missing mask. But we empirically find that directly incorporating these statistical methods into deep generative models is sub-optimal. Specifically, it would neglect the confidence of the reconstructed mask during the MNAR imputation process, which leads to insufficient information extraction and less-guaranteed imputation quality. In this paper, we revisit the MNAR problem from a novel perspective that the complete data and missing mask are two modalities of incomplete data on an equal footing. Along with this line, we put forward a generative-model-specific joint pr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#22823;&#20223;&#23556;&#22238;&#24402;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#26799;&#24230;&#19979;&#38477;&#21644;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#20998;&#26512;&#26041;&#27861;&#12290;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#29702;&#35770;&#32467;&#26524;&#30340;&#26377;&#25928;&#24615;&#12290;&#35813;&#26041;&#27861;&#22312;&#36816;&#34892;&#26102;&#38388;&#21644;&#35266;&#27979;&#27425;&#25968;&#36739;&#23569;&#26102;&#37117;&#33021;&#21462;&#24471;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.08070</link><description>&lt;p&gt;
&#26368;&#22823;&#20223;&#23556;&#22238;&#24402;&#21450;&#20854;&#19968;&#38454;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Max-affine regression via first-order methods. (arXiv:2308.08070v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08070
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#22823;&#20223;&#23556;&#22238;&#24402;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#26799;&#24230;&#19979;&#38477;&#21644;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#20998;&#26512;&#26041;&#27861;&#12290;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#29702;&#35770;&#32467;&#26524;&#30340;&#26377;&#25928;&#24615;&#12290;&#35813;&#26041;&#27861;&#22312;&#36816;&#34892;&#26102;&#38388;&#21644;&#35266;&#27979;&#27425;&#25968;&#36739;&#23569;&#26102;&#37117;&#33021;&#21462;&#24471;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#26368;&#22823;&#20223;&#23556;&#27169;&#22411;&#30340;&#22238;&#24402;&#38382;&#39064;&#65292;&#35813;&#27169;&#22411;&#36890;&#36807;&#20351;&#29992;&#26368;&#22823;&#21270;&#20989;&#25968;&#23558;&#20223;&#23556;&#27169;&#22411;&#32452;&#21512;&#25104;&#20998;&#27573;&#32447;&#24615;&#27169;&#22411;&#12290;&#26368;&#22823;&#20223;&#23556;&#27169;&#22411;&#24191;&#27867;&#24212;&#29992;&#20110;&#20449;&#21495;&#22788;&#29702;&#21644;&#32479;&#35745;&#23398;&#20013;&#65292;&#21253;&#25324;&#22810;&#31867;&#21035;&#20998;&#31867;&#12289;&#25293;&#21334;&#38382;&#39064;&#21644;&#20984;&#22238;&#24402;&#12290;&#23427;&#36824;&#25512;&#24191;&#20102;&#30456;&#20301;&#24674;&#22797;&#21644;&#23398;&#20064;&#25972;&#27969;&#32447;&#24615;&#21333;&#20803;&#28608;&#27963;&#20989;&#25968;&#12290;&#25105;&#20204;&#23545;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#21644;&#23567;&#25209;&#37327;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#26041;&#27861;&#22312;&#26368;&#22823;&#20223;&#23556;&#22238;&#24402;&#20013;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#24615;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#20551;&#35774;&#27169;&#22411;&#20197;&#38543;&#26426;&#20301;&#32622;&#35266;&#27979;&#65292;&#36981;&#24490;&#27425;&#39640;&#26031;&#20998;&#24067;&#21644;&#20855;&#26377;&#21152;&#24615;&#27425;&#39640;&#26031;&#22122;&#22768;&#30340;&#21453;&#27987;&#24230;&#12290;&#22312;&#36825;&#20123;&#20551;&#35774;&#19979;&#65292;&#36866;&#24403;&#21021;&#22987;&#21270;&#30340;GD&#21644;SGD&#33021;&#22815;&#32447;&#24615;&#25910;&#25947;&#21040;&#30001;&#30456;&#24212;&#35823;&#24046;&#30028;&#38480;&#30830;&#23450;&#30340;&#30446;&#26631;&#21306;&#22495;&#38468;&#36817;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19982;&#29702;&#35770;&#21457;&#29616;&#30456;&#19968;&#33268;&#30340;&#25968;&#20540;&#32467;&#26524;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;SGD&#19981;&#20165;&#22312;&#36816;&#34892;&#26102;&#38388;&#19978;&#25910;&#25947;&#26356;&#24555;&#65292;&#32780;&#19988;&#22312;&#35266;&#27979;&#27425;&#25968;&#36739;&#23569;&#26102;&#20063;&#33021;&#33719;&#24471;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider regression of a max-affine model that produces a piecewise linear model by combining affine models via the max function. The max-affine model ubiquitously arises in applications in signal processing and statistics including multiclass classification, auction problems, and convex regression. It also generalizes phase retrieval and learning rectifier linear unit activation functions. We present a non-asymptotic convergence analysis of gradient descent (GD) and mini-batch stochastic gradient descent (SGD) for max-affine regression when the model is observed at random locations following the sub-Gaussianity and an anti-concentration with additive sub-Gaussian noise. Under these assumptions, a suitably initialized GD and SGD converge linearly to a neighborhood of the ground truth specified by the corresponding error bound. We provide numerical results that corroborate the theoretical finding. Importantly, SGD not only converges faster in run time with fewer observations than alt
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#40065;&#26834;&#30340;&#36125;&#21494;&#26031;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;&#65292;&#20351;&#29992;&#38646;&#33192;&#32960;&#27850;&#26494;&#27169;&#22411;&#26469;&#22788;&#29702;&#21253;&#21547;&#36807;&#22810;&#38646;&#20540;&#30340;&#39640;&#32500;&#35745;&#25968;&#25968;&#25454;&#12290;&#20026;&#20102;&#35299;&#20915;&#38543;&#26426;&#24615;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;&#19968;&#33268;&#32858;&#21512;&#30340;&#26041;&#27861;&#12290;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.08060</link><description>&lt;p&gt;
&#40065;&#26834;&#36125;&#21494;&#26031;&#24352;&#37327;&#20998;&#35299;&#19982;&#38646;&#33192;&#32960;&#27850;&#26494;&#27169;&#22411;&#21644;&#19968;&#33268;&#32858;&#21512;
&lt;/p&gt;
&lt;p&gt;
Robust Bayesian Tensor Factorization with Zero-Inflated Poisson Model and Consensus Aggregation. (arXiv:2308.08060v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08060
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#40065;&#26834;&#30340;&#36125;&#21494;&#26031;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;&#65292;&#20351;&#29992;&#38646;&#33192;&#32960;&#27850;&#26494;&#27169;&#22411;&#26469;&#22788;&#29702;&#21253;&#21547;&#36807;&#22810;&#38646;&#20540;&#30340;&#39640;&#32500;&#35745;&#25968;&#25968;&#25454;&#12290;&#20026;&#20102;&#35299;&#20915;&#38543;&#26426;&#24615;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;&#19968;&#33268;&#32858;&#21512;&#30340;&#26041;&#27861;&#12290;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24352;&#37327;&#20998;&#35299;&#26159;&#19968;&#31181;&#29992;&#20110;&#39640;&#25928;&#34920;&#31034;&#21644;&#20998;&#26512;&#22810;&#32500;&#25968;&#25454;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;&#22522;&#20110;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;&#22312;&#24212;&#29992;&#20110;&#21253;&#21547;&#36807;&#22810;&#38646;&#20540;&#30340;&#35745;&#25968;&#25968;&#25454;&#65288;&#22914;&#21333;&#32454;&#32990;RNA&#27979;&#24207;&#25968;&#25454;&#65289;&#26102;&#34920;&#29616;&#19981;&#20339;&#12290;&#27492;&#22806;&#65292;&#24352;&#37327;&#20998;&#35299;&#30340;&#38543;&#26426;&#24615;&#23548;&#33268;&#22240;&#23376;&#22312;&#22810;&#27425;&#36816;&#34892;&#20013;&#21464;&#21270;&#65292;&#20351;&#24471;&#32467;&#26524;&#30340;&#35299;&#37322;&#21644;&#37325;&#29616;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;&#38646;&#33192;&#32960;&#27850;&#26494;&#24352;&#37327;&#20998;&#35299;&#65288;ZIPTF&#65289;&#65292;&#29992;&#20110;&#20998;&#35299;&#20855;&#26377;&#36807;&#22810;&#38646;&#20540;&#30340;&#39640;&#32500;&#35745;&#25968;&#25968;&#25454;&#12290;&#20026;&#20102;&#35299;&#20915;&#38543;&#26426;&#24615;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;&#19968;&#33268;&#38646;&#33192;&#32960;&#27850;&#26494;&#24352;&#37327;&#20998;&#35299;&#65288;C-ZIPTF&#65289;&#30340;&#26041;&#27861;&#65292;&#23558;ZIPTF&#19982;&#22522;&#20110;&#19968;&#33268;&#24615;&#30340;&#20803;&#20998;&#26512;&#30456;&#32467;&#21512;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#30340;&#38646;&#33192;&#32960;&#35745;&#25968;&#25968;&#25454;&#21644;&#21512;&#25104;&#30340;&#30495;&#23454;&#21333;&#32454;&#32990;RNA&#27979;&#24207;&#25968;&#25454;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;ZIPTF&#21644;C-ZIPTF&#26041;&#27861;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;ZIPTF&#26041;&#27861;&#22312;&#24615;&#33021;&#19978;&#22987;&#32456;&#20248;&#20110;&#22522;&#32447;&#30697;&#38453;&#21644;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tensor factorizations (TF) are powerful tools for the efficient representation and analysis of multidimensional data. However, classic TF methods based on maximum likelihood estimation underperform when applied to zero-inflated count data, such as single-cell RNA sequencing (scRNA-seq) data. Additionally, the stochasticity inherent in TFs results in factors that vary across repeated runs, making interpretation and reproducibility of the results challenging. In this paper, we introduce Zero Inflated Poisson Tensor Factorization (ZIPTF), a novel approach for the factorization of high-dimensional count data with excess zeros. To address the challenge of stochasticity, we introduce Consensus Zero Inflated Poisson Tensor Factorization (C-ZIPTF), which combines ZIPTF with a consensus-based meta-analysis. We evaluate our proposed ZIPTF and C-ZIPTF on synthetic zero-inflated count data and synthetic and real scRNA-seq data. ZIPTF consistently outperforms baseline matrix and tensor factorizatio
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#22312;&#21482;&#33021;&#36890;&#36807;&#19968;&#33268;&#24615;&#39044;&#35328;&#26426;&#35775;&#38382;&#31867;&#30340;&#27169;&#22411;&#19979;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#31616;&#21333;&#19988;&#25928;&#26524;&#26356;&#22909;&#30340;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#26368;&#22810;&#20250;&#29359;O(256^d)&#20010;&#38169;&#35823;&#65292;&#24182;&#35266;&#23519;&#21040;&#19981;&#23384;&#22312;&#19968;&#20010;&#26368;&#22810;&#20250;&#29359;2^(d+1)-2&#20010;&#38169;&#35823;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.08055</link><description>&lt;p&gt;
&#36890;&#36807;&#19968;&#33268;&#24615;&#39044;&#35328;&#26426;&#36827;&#34892;&#31616;&#21333;&#30340;&#22312;&#32447;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Simple online learning with consistency oracle. (arXiv:2308.08055v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08055
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#22312;&#21482;&#33021;&#36890;&#36807;&#19968;&#33268;&#24615;&#39044;&#35328;&#26426;&#35775;&#38382;&#31867;&#30340;&#27169;&#22411;&#19979;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#31616;&#21333;&#19988;&#25928;&#26524;&#26356;&#22909;&#30340;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#26368;&#22810;&#20250;&#29359;O(256^d)&#20010;&#38169;&#35823;&#65292;&#24182;&#35266;&#23519;&#21040;&#19981;&#23384;&#22312;&#19968;&#20010;&#26368;&#22810;&#20250;&#29359;2^(d+1)-2&#20010;&#38169;&#35823;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#21482;&#33021;&#36890;&#36807;&#19968;&#33268;&#24615;&#39044;&#35328;&#26426;&#35775;&#38382;&#31867;&#30340;&#27169;&#22411;&#19979;&#30340;&#22312;&#32447;&#23398;&#20064;&#8212;&#8212;&#22312;&#20219;&#20309;&#26102;&#21051;&#65292;&#39044;&#35328;&#26426;&#37117;&#33021;&#32473;&#20986;&#19982;&#30446;&#21069;&#20026;&#27490;&#30475;&#21040;&#30340;&#25152;&#26377;&#31034;&#20363;&#19968;&#33268;&#30340;&#31867;&#20989;&#25968;&#12290;&#35813;&#27169;&#22411;&#26368;&#36817;&#30001;Assos&#31561;&#20154;&#65288;COLT'23&#65289;&#32771;&#34385;&#12290;&#36825;&#20010;&#27169;&#22411;&#30340;&#21160;&#26426;&#26159;&#26631;&#20934;&#30340;&#22312;&#32447;&#23398;&#20064;&#26041;&#27861;&#20381;&#36182;&#20110;&#35745;&#31639;&#23376;&#31867;&#30340;Littlestone&#32500;&#24230;&#65292;&#36825;&#26159;&#19968;&#20010;&#35745;&#31639;&#22797;&#26434;&#30340;&#38382;&#39064;&#12290;Assos&#31561;&#20154;&#22312;&#36825;&#20010;&#27169;&#22411;&#20013;&#32473;&#20986;&#20102;&#19968;&#20010;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#23545;&#20110;Littlestone&#32500;&#24230;&#20026;d&#30340;&#31867;&#65292;&#26368;&#22810;&#20250;&#29359;C^d&#20010;&#38169;&#35823;&#65292;&#20854;&#20013;C&#26159;&#19968;&#20010;&#26410;&#25351;&#23450;&#30340;&#32477;&#23545;&#24120;&#25968;&#19988;&#22823;&#20110;0&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#31639;&#27861;&#65292;&#26368;&#22810;&#20250;&#29359;O(256^d)&#20010;&#38169;&#35823;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#26356;&#31616;&#21333;&#65292;&#21482;&#20351;&#29992;&#20102;Littlestone&#32500;&#24230;&#30340;&#22522;&#26412;&#23646;&#24615;&#12290;&#25105;&#20204;&#36824;&#35266;&#23519;&#21040;&#65292;&#19981;&#23384;&#22312;&#19968;&#20010;&#22312;&#36825;&#20010;&#27169;&#22411;&#20013;&#26368;&#22810;&#20250;&#29359;2^(d+1)-2&#20010;&#38169;&#35823;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#36824;&#35266;&#23519;&#21040;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#65288;&#20197;&#21450;Assos&#31561;&#20154;&#30340;&#31639;&#27861;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider online learning in the model where a learning algorithm can access the class only via the consistency oracle -- an oracle, that, at any moment, can give a function from the class that agrees with all examples seen so far. This model was recently considered by Assos et al. (COLT'23). It is motivated by the fact that standard methods of online learning rely on computing the Littlestone dimension of subclasses, a problem that is computationally intractable. Assos et al. gave an online learning algorithm in this model that makes at most $C^d$ mistakes on classes of Littlestone dimension $d$, for some absolute unspecified constant $C &gt; 0$. We give a novel algorithm that makes at most $O(256^d)$ mistakes. Our proof is significantly simpler and uses only very basic properties of the Littlestone dimension. We also observe that there exists no algorithm in this model that makes at most $2^{d+1}-2$ mistakes. We also observe that our algorithm (as well as the algorithm of Assos et al.
&lt;/p&gt;</description></item><item><title>&#22312;&#22810;&#26234;&#33021;&#20307;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#20840;&#38754;&#30740;&#31350;&#20102;&#21518;&#24724;&#19979;&#30028;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#20855;&#26377;&#33391;&#22909;&#36830;&#36890;&#24615;&#23646;&#24615;&#21644;&#38543;&#26426;&#20998;&#24067;&#22870;&#21169;&#30340;&#24773;&#20917;&#19979;&#65292;&#23384;&#22312;&#32039;&#23494;&#30340;&#23454;&#20363;&#30456;&#20851;&#21644;&#23454;&#20363;&#26080;&#20851;&#30340;&#19979;&#30028;&#12290;</title><link>http://arxiv.org/abs/2308.08046</link><description>&lt;p&gt;
&#22810;&#26234;&#33021;&#20307;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#30340;&#21518;&#24724;&#19979;&#30028;
&lt;/p&gt;
&lt;p&gt;
Regret Lower Bounds in Multi-agent Multi-armed Bandit. (arXiv:2308.08046v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08046
&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#26234;&#33021;&#20307;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#20840;&#38754;&#30740;&#31350;&#20102;&#21518;&#24724;&#19979;&#30028;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#20855;&#26377;&#33391;&#22909;&#36830;&#36890;&#24615;&#23646;&#24615;&#21644;&#38543;&#26426;&#20998;&#24067;&#22870;&#21169;&#30340;&#24773;&#20917;&#19979;&#65292;&#23384;&#22312;&#32039;&#23494;&#30340;&#23454;&#20363;&#30456;&#20851;&#21644;&#23454;&#20363;&#26080;&#20851;&#30340;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#33218;&#36172;&#21338;&#26426;&#28608;&#21457;&#20102;&#20855;&#26377;&#21487;&#35777;&#26126;&#21518;&#24724;&#19978;&#30028;&#30340;&#26041;&#27861;&#65292;&#19982;&#20043;&#23545;&#24212;&#30340;&#21518;&#24724;&#19979;&#30028;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#20063;&#34987;&#24191;&#27867;&#30740;&#31350;&#12290;&#26368;&#36817;&#65292;&#22810;&#26234;&#33021;&#20307;&#22810;&#33218;&#36172;&#21338;&#26426;&#22312;&#21508;&#20010;&#39046;&#22495;&#20013;&#24471;&#21040;&#20102;&#26174;&#33879;&#30340;&#20851;&#27880;&#65292;&#20854;&#20013;&#20010;&#20307;&#23458;&#25143;&#20197;&#20998;&#24067;&#24335;&#30340;&#26041;&#24335;&#38754;&#20020;&#30528;&#36172;&#21338;&#38382;&#39064;&#65292;&#30446;&#26631;&#26159;&#25972;&#20307;&#31995;&#32479;&#30340;&#24615;&#33021;&#65292;&#36890;&#24120;&#29992;&#21518;&#24724;&#26469;&#34913;&#37327;&#12290;&#23613;&#31649;&#24050;&#32463;&#20986;&#29616;&#20102;&#20855;&#26377;&#21518;&#24724;&#19978;&#30028;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#20294;&#23545;&#24212;&#30340;&#21518;&#24724;&#19979;&#30028;&#21364;&#27809;&#26377;&#24471;&#21040;&#36275;&#22815;&#30340;&#20851;&#27880;&#65292;&#38500;&#20102;&#26368;&#36817;&#38024;&#23545;&#23545;&#25239;&#35774;&#32622;&#30340;&#19968;&#20010;&#19979;&#30028;&#65292;&#28982;&#32780;&#65292;&#23427;&#19982;&#24050;&#30693;&#19978;&#30028;&#26377;&#24046;&#36317;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#22312;&#19981;&#21516;&#30340;&#35774;&#32622;&#19979;&#25552;&#20379;&#20102;&#31532;&#19968;&#27425;&#20840;&#38754;&#30740;&#31350;&#21518;&#24724;&#19979;&#30028;&#65292;&#24182;&#24314;&#31435;&#20102;&#23427;&#20204;&#30340;&#32039;&#23494;&#24615;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#24403;&#22270;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#36830;&#36890;&#24615;&#23646;&#24615;&#19988;&#22870;&#21169;&#38543;&#26426;&#20998;&#24067;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#38454;&#20026;$O(\log T)$&#30340;&#23454;&#20363;&#30456;&#20851;&#19979;&#30028;&#21644;$O(\log T)$&#30340;&#23454;&#20363;&#26080;&#20851;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-armed Bandit motivates methods with provable upper bounds on regret and also the counterpart lower bounds have been extensively studied in this context. Recently, Multi-agent Multi-armed Bandit has gained significant traction in various domains, where individual clients face bandit problems in a distributed manner and the objective is the overall system performance, typically measured by regret. While efficient algorithms with regret upper bounds have emerged, limited attention has been given to the corresponding regret lower bounds, except for a recent lower bound for adversarial settings, which, however, has a gap with let known upper bounds. To this end, we herein provide the first comprehensive study on regret lower bounds across different settings and establish their tightness. Specifically, when the graphs exhibit good connectivity properties and the rewards are stochastically distributed, we demonstrate a lower bound of order $O(\log T)$ for instance-dependent bounds and $
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#20351;&#29992;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#22312;&#27809;&#26377;&#23545;&#27169;&#22411;&#21442;&#25968;&#26045;&#21152;&#38480;&#21046;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#30001;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#29983;&#25104;&#30340;&#26080;&#30028;&#25968;&#25454;&#36827;&#34892;&#20108;&#20998;&#31867;&#12290;&#25105;&#20204;&#39318;&#27425;&#33719;&#24471;&#20102;&#25910;&#25947;&#36895;&#24230;&#19981;&#21463;&#32500;&#24230;&#35781;&#21650;&#24433;&#21709;&#30340;&#38750;&#28176;&#36817;&#19978;&#30028;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#39640;&#26031;&#20998;&#24067;&#30340;&#29305;&#24615;&#22312;&#26080;&#38480;&#22495;&#19978;&#36827;&#34892;&#20102;&#20998;&#31867;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2308.08030</link><description>&lt;p&gt;
&#20351;&#29992;&#28145;&#24230;ReLU&#32593;&#32476;&#23545;&#30001;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#29983;&#25104;&#30340;&#25968;&#25454;&#36827;&#34892;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Classification of Data Generated by Gaussian Mixture Models Using Deep ReLU Networks. (arXiv:2308.08030v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08030
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#20351;&#29992;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#22312;&#27809;&#26377;&#23545;&#27169;&#22411;&#21442;&#25968;&#26045;&#21152;&#38480;&#21046;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#30001;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#29983;&#25104;&#30340;&#26080;&#30028;&#25968;&#25454;&#36827;&#34892;&#20108;&#20998;&#31867;&#12290;&#25105;&#20204;&#39318;&#27425;&#33719;&#24471;&#20102;&#25910;&#25947;&#36895;&#24230;&#19981;&#21463;&#32500;&#24230;&#35781;&#21650;&#24433;&#21709;&#30340;&#38750;&#28176;&#36817;&#19978;&#30028;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#39640;&#26031;&#20998;&#24067;&#30340;&#29305;&#24615;&#22312;&#26080;&#38480;&#22495;&#19978;&#36827;&#34892;&#20102;&#20998;&#31867;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#23545;&#30001;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#29983;&#25104;&#30340;&#26080;&#30028;&#25968;&#25454;&#36827;&#34892;&#20108;&#20998;&#31867;&#12290;&#25105;&#20204;&#39318;&#27425;&#33719;&#24471;&#20102;&#23545;&#20110;&#27809;&#26377;&#23545;&#27169;&#22411;&#21442;&#25968;&#26045;&#21152;&#38480;&#21046;&#30340;&#20998;&#31867;&#20219;&#21153;&#20013;&#36229;&#20986;&#39118;&#38505;&#65288;&#36229;&#20986;&#38169;&#35823;&#20998;&#31867;&#29575;&#65289;&#30340;&#38750;&#28176;&#36817;&#19978;&#30028;&#21644;&#25910;&#25947;&#36895;&#29575;&#12290;&#25105;&#20204;&#24471;&#21040;&#30340;&#25910;&#25947;&#36895;&#29575;&#19981;&#20381;&#36182;&#20110;&#32500;&#24230;$d$&#65292;&#35777;&#26126;&#20102;&#28145;&#24230;ReLU&#32593;&#32476;&#21487;&#20197;&#20811;&#26381;&#22312;&#20998;&#31867;&#20013;&#30340;&#32500;&#24230;&#35781;&#21650;&#12290;&#34429;&#28982;&#29616;&#26377;&#30340;&#20998;&#31867;&#31639;&#27861;&#30340;&#24191;&#20041;&#20998;&#26512;&#22823;&#22810;&#20381;&#36182;&#20110;&#26377;&#30028;&#22495;&#65292;&#20294;&#25105;&#20204;&#36890;&#36807;&#21033;&#29992;&#39640;&#26031;&#20998;&#24067;&#30340;&#35299;&#26512;&#24615;&#21644;&#24555;&#36895;&#34928;&#20943;&#23558;&#20854;&#24212;&#29992;&#20110;&#26080;&#30028;&#22495;&#12290;&#20026;&#20102;&#20415;&#20110;&#25105;&#20204;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#20010;&#20351;&#29992;ReLU&#32593;&#32476;&#23545;&#19968;&#33324;&#35299;&#26512;&#20989;&#25968;&#30340;&#26032;&#36817;&#20284;&#35823;&#24046;&#30028;&#65292;&#36825;&#21487;&#33021;&#20855;&#26377;&#29420;&#31435;&#30340;&#30740;&#31350;&#20215;&#20540;&#12290;&#39640;&#26031;&#20998;&#24067;&#21487;&#20197;&#24456;&#22909;&#22320;&#29992;&#20110;&#24314;&#27169;&#20135;&#29983;&#30340;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the binary classification of unbounded data from ${\mathbb R}^d$ generated under Gaussian Mixture Models (GMMs) using deep ReLU neural networks. We obtain $\unicode{x2013}$ for the first time $\unicode{x2013}$ non-asymptotic upper bounds and convergence rates of the excess risk (excess misclassification error) for the classification without restrictions on model parameters. The convergence rates we derive do not depend on dimension $d$, demonstrating that deep ReLU networks can overcome the curse of dimensionality in classification. While the majority of existing generalization analysis of classification algorithms relies on a bounded domain, we consider an unbounded domain by leveraging the analyticity and fast decay of Gaussian distributions. To facilitate our analysis, we give a novel approximation error bound for general analytic functions using ReLU networks, which may be of independent interest. Gaussian distributions can be adopted nicely to model data arising
&lt;/p&gt;</description></item><item><title>&#37327;&#23376;&#35745;&#31639;&#22312;&#33021;&#28304;&#25928;&#29575;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#65292;&#24182;&#19988;&#33021;&#22815;&#22312;&#30408;&#21033;&#21644;&#33021;&#28304;&#25928;&#29575;&#19978;&#36229;&#36234;&#32463;&#20856;&#35745;&#31639;&#12290;&#36825;&#20351;&#24471;&#37327;&#23376;&#35745;&#31639;&#25104;&#20026;&#35745;&#31639;&#34892;&#19994;&#26356;&#21487;&#25345;&#32493;&#30340;&#36873;&#25321;&#12290;</title><link>http://arxiv.org/abs/2308.08025</link><description>&lt;p&gt;
&#37327;&#23376;&#32463;&#27982;&#30340;&#21183;&#33021;&#20248;&#21183;
&lt;/p&gt;
&lt;p&gt;
Potential Energy Advantage of Quantum Economy. (arXiv:2308.08025v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08025
&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#35745;&#31639;&#22312;&#33021;&#28304;&#25928;&#29575;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#65292;&#24182;&#19988;&#33021;&#22815;&#22312;&#30408;&#21033;&#21644;&#33021;&#28304;&#25928;&#29575;&#19978;&#36229;&#36234;&#32463;&#20856;&#35745;&#31639;&#12290;&#36825;&#20351;&#24471;&#37327;&#23376;&#35745;&#31639;&#25104;&#20026;&#35745;&#31639;&#34892;&#19994;&#26356;&#21487;&#25345;&#32493;&#30340;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#35268;&#27169;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21644;&#35821;&#35328;&#27169;&#22411;&#30340;&#24191;&#27867;&#37096;&#32626;&#65292;&#33021;&#28304;&#25104;&#26412;&#36234;&#26469;&#36234;&#20851;&#38190;&#12290;&#23545;&#20110;&#25552;&#20379;&#35745;&#31639;&#26381;&#21153;&#30340;&#20844;&#21496;&#26469;&#35828;&#65292;&#20302;&#33021;&#32791;&#23545;&#20110;&#24066;&#22330;&#22686;&#38271;&#21644;&#25919;&#24220;&#27861;&#35268;&#26469;&#35828;&#37117;&#38750;&#24120;&#37325;&#35201;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#37327;&#23376;&#35745;&#31639;&#19982;&#32463;&#20856;&#35745;&#31639;&#20043;&#38388;&#30340;&#33021;&#28304;&#20248;&#21183;&#12290;&#25105;&#20204;&#22312;&#33021;&#28304;&#25928;&#29575;&#30340;&#32972;&#26223;&#19979;&#37325;&#26032;&#23450;&#20041;&#20248;&#21183;&#65292;&#19982;&#20165;&#22522;&#20110;&#35745;&#31639;&#22797;&#26434;&#24615;&#30340;&#20256;&#32479;&#37327;&#23376;&#20248;&#21183;&#19981;&#21516;&#12290;&#36890;&#36807;&#19968;&#20010;&#20197;&#33021;&#37327;&#20351;&#29992;&#20026;&#32422;&#26463;&#26465;&#20214;&#30340;Cournot&#31454;&#20105;&#27169;&#22411;&#65292;&#25105;&#20204;&#35777;&#26126;&#37327;&#23376;&#35745;&#31639;&#20844;&#21496;&#22312;Nash&#22343;&#34913;&#28857;&#19978;&#22312;&#30408;&#21033;&#33021;&#21147;&#21644;&#33021;&#28304;&#25928;&#29575;&#26041;&#38754;&#37117;&#33021;&#36229;&#36234;&#32463;&#20856;&#23545;&#25163;&#12290;&#22240;&#27492;&#65292;&#37327;&#23376;&#35745;&#31639;&#21487;&#33021;&#20195;&#34920;&#35745;&#31639;&#34892;&#19994;&#26356;&#21487;&#25345;&#32493;&#30340;&#21457;&#23637;&#36335;&#24452;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#37327;&#23376;&#35745;&#31639;&#32463;&#27982;&#30340;&#33021;&#28304;&#21033;&#30410;&#21462;&#20915;&#20110;&#22823;&#35268;&#27169;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
Energy cost is increasingly crucial in the modern computing industry with the wide deployment of large-scale machine learning models and language models. For the firms that provide computing services, low energy consumption is important both from the perspective of their own market growth and the government's regulations. In this paper, we study the energy benefits of quantum computing vis-a-vis classical computing. Deviating from the conventional notion of quantum advantage based solely on computational complexity, we redefine advantage in an energy efficiency context. Through a Cournot competition model constrained by energy usage, we demonstrate quantum computing firms can outperform classical counterparts in both profitability and energy efficiency at Nash equilibrium. Therefore quantum computing may represent a more sustainable pathway for the computing industry. Moreover, we discover that the energy benefits of quantum computing economies are contingent on large-scale computation
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#36125;&#21494;&#26031;&#26694;&#26550;&#19979;&#21033;&#29992;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#35299;&#20915;&#38750;&#23436;&#22791;&#32447;&#24615;&#36870;&#38382;&#39064;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#21033;&#29992;&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#20808;&#39564;&#32467;&#26500;&#21644;Feynman-Kac&#27169;&#22411;&#65292;&#24182;&#36827;&#34892;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#65292;&#34920;&#29616;&#20986;&#27604;&#31454;&#20105;&#23545;&#25163;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.07983</link><description>&lt;p&gt;
&#33945;&#29305;&#21345;&#27931;&#24341;&#23548;&#25193;&#25955;&#30340;&#36125;&#21494;&#26031;&#32447;&#24615;&#36870;&#38382;&#39064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Monte Carlo guided Diffusion for Bayesian linear inverse problems. (arXiv:2308.07983v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07983
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#36125;&#21494;&#26031;&#26694;&#26550;&#19979;&#21033;&#29992;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#35299;&#20915;&#38750;&#23436;&#22791;&#32447;&#24615;&#36870;&#38382;&#39064;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#21033;&#29992;&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#20808;&#39564;&#32467;&#26500;&#21644;Feynman-Kac&#27169;&#22411;&#65292;&#24182;&#36827;&#34892;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#65292;&#34920;&#29616;&#20986;&#27604;&#31454;&#20105;&#23545;&#25163;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#23436;&#22791;&#30340;&#32447;&#24615;&#36870;&#38382;&#39064;&#32463;&#24120;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#20986;&#29616;&#65292;&#20174;&#35745;&#31639;&#25668;&#24433;&#21040;&#21307;&#23398;&#25104;&#20687;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#38598;&#20013;&#20110;&#20351;&#29992;&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;SGMs&#65289;&#65292;&#22312;&#22635;&#34917;&#38382;&#39064;&#20013;&#20135;&#29983;&#20855;&#26377;&#24863;&#30693;&#21512;&#29702;&#24615;&#30340;&#22270;&#20687;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;&#26412;&#30740;&#31350;&#21033;&#29992;SGM&#23450;&#20041;&#30340;&#20808;&#39564;&#32467;&#26500;&#26469;&#21046;&#23450;&#36125;&#21494;&#26031;&#26694;&#26550;&#19979;&#30340;&#24674;&#22797;&#38382;&#39064;&#65292;&#23558;&#20854;&#20316;&#20026;Feynman-Kac&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#25913;&#32534;&#33258;&#29992;&#20110;&#26500;&#24314;&#22522;&#20110;&#24471;&#20998;&#25193;&#25955;&#30340;&#21069;&#21521;&#25193;&#25955;&#27169;&#22411;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;Feynman-Kac&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#12290;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;MCGdiff&#22312;&#29702;&#35770;&#19978;&#26159;&#26377;&#26681;&#25454;&#30340;&#65292;&#24182;&#19988;&#25105;&#20204;&#25552;&#20379;&#20102;&#25968;&#20540;&#27169;&#25311;&#32467;&#26524;&#65292;&#34920;&#26126;&#23427;&#22312;&#22788;&#29702;&#38750;&#23436;&#22791;&#36870;&#38382;&#39064;&#26102;&#20248;&#20110;&#31454;&#20105;&#23545;&#25163;&#30340;&#22522;&#20934;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ill-posed linear inverse problems that combine knowledge of the forward measurement model with prior models arise frequently in various applications, from computational photography to medical imaging. Recent research has focused on solving these problems with score-based generative models (SGMs) that produce perceptually plausible images, especially in inpainting problems. In this study, we exploit the particular structure of the prior defined in the SGM to formulate recovery in a Bayesian framework as a Feynman--Kac model adapted from the forward diffusion model used to construct score-based diffusion. To solve this Feynman--Kac problem, we propose the use of Sequential Monte Carlo methods. The proposed algorithm, MCGdiff, is shown to be theoretically grounded and we provide numerical simulations showing that it outperforms competing baselines when dealing with ill-posed inverse problems.
&lt;/p&gt;</description></item><item><title>SciRE-Solver&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;&#37319;&#26679;&#22120;&#65292;&#36890;&#36807;&#24341;&#20837;&#24471;&#20998;&#31215;&#20998;&#27714;&#35299;&#22120;&#21644;&#36882;&#24402;&#23548;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#23427;&#35299;&#20915;&#20102;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#37319;&#26679;&#36807;&#31243;&#32531;&#24930;&#30340;&#25361;&#25112;&#65292;&#24182;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#37319;&#26679;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.07896</link><description>&lt;p&gt;
SciRE-Solver: &#29992;&#24471;&#20998;&#31215;&#20998;&#27714;&#35299;&#22120;&#21644;&#36882;&#24402;&#23548;&#25968;&#20272;&#35745;&#24555;&#36895;&#37319;&#26679;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
SciRE-Solver: Efficient Sampling of Diffusion Probabilistic Models by Score-integrand Solver with Recursive Derivative Estimation. (arXiv:2308.07896v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07896
&lt;/p&gt;
&lt;p&gt;
SciRE-Solver&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;&#37319;&#26679;&#22120;&#65292;&#36890;&#36807;&#24341;&#20837;&#24471;&#20998;&#31215;&#20998;&#27714;&#35299;&#22120;&#21644;&#36882;&#24402;&#23548;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#23427;&#35299;&#20915;&#20102;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#37319;&#26679;&#36807;&#31243;&#32531;&#24930;&#30340;&#25361;&#25112;&#65292;&#24182;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#37319;&#26679;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;(DPMs)&#26159;&#19968;&#31867;&#24378;&#22823;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#20197;&#20854;&#29983;&#25104;&#39640;&#20445;&#30495;&#22270;&#20687;&#26679;&#26412;&#30340;&#33021;&#21147;&#32780;&#38395;&#21517;&#12290;DPMs&#30340;&#23454;&#29616;&#38754;&#20020;&#30340;&#20027;&#35201;&#25361;&#25112;&#26159;&#37319;&#26679;&#36807;&#31243;&#32531;&#24930;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;DPMs&#37319;&#26679;&#22120;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#38024;&#23545;&#19982;DPMs&#37319;&#26679;&#36807;&#31243;&#23545;&#24212;&#30340;&#25193;&#25955;ODE&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#24471;&#20998;&#30340;&#31934;&#30830;&#35299;&#20915;&#26041;&#26696;&#33539;&#24335;&#65292;&#35813;&#33539;&#24335;&#20026;&#27714;&#35299;&#25193;&#25955;ODE&#30340;&#25968;&#20540;&#31639;&#27861;&#24320;&#21457;&#25552;&#20379;&#20102;&#26032;&#30340;&#35270;&#35282;&#12290;&#20026;&#20102;&#23454;&#29616;&#39640;&#25928;&#30340;&#37319;&#26679;&#22120;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36882;&#24402;&#23548;&#25968;&#20272;&#35745;(RDE)&#26041;&#27861;&#26469;&#20943;&#23567;&#20272;&#35745;&#35823;&#24046;&#12290;&#36890;&#36807;&#25105;&#20204;&#25552;&#20986;&#30340;&#35299;&#20915;&#26041;&#26696;&#33539;&#24335;&#21644;RDE&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20855;&#26377;&#25910;&#25947;&#39034;&#24207;&#20445;&#35777;&#30340;&#24471;&#20998;&#31215;&#20998;&#27714;&#35299;&#22120;(SciRE-Solver)&#26469;&#35299;&#20915;&#25193;&#25955;ODEs&#12290;SciRE-Solver&#22312;&#31163;&#25955;&#26102;&#38388;&#21644;&#36830;&#32493;&#26102;&#38388;DPMs&#19978;&#33719;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#37319;&#26679;&#24615;&#33021;&#65292;&#24182;&#19988;&#20165;&#38656;&#26377;&#38480;&#25968;&#37327;&#30340;&#24471;&#20998;&#20989;&#25968;&#35780;&#20272;(NFE)&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion probabilistic models (DPMs) are a powerful class of generative models known for their ability to generate high-fidelity image samples. A major challenge in the implementation of DPMs is the slow sampling process. In this work, we bring a high-efficiency sampler for DPMs. Specifically, we propose a score-based exact solution paradigm for the diffusion ODEs corresponding to the sampling process of DPMs, which introduces a new perspective on developing numerical algorithms for solving diffusion ODEs. To achieve an efficient sampler, we propose a recursive derivative estimation (RDE) method to reduce the estimation error. With our proposed solution paradigm and RDE method, we propose the score-integrand solver with the convergence order guarantee as efficient solver (SciRE-Solver) for solving diffusion ODEs. The SciRE-Solver attains state-of-the-art (SOTA) sampling performance with a limited number of score function evaluations (NFE) on both discrete-time and continuous-time DPMs
&lt;/p&gt;</description></item><item><title>&#23398;&#20064;&#20108;&#20803;&#20551;&#35774;&#31867;&#20855;&#26377;&#26679;&#26412;&#21387;&#32553;&#26041;&#26696;&#65292;&#32780;&#22810;&#31867;&#21035;&#20551;&#35774;&#31867;&#21017;&#19981;&#20855;&#22791;&#36825;&#20010;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2308.06424</link><description>&lt;p&gt;
&#23398;&#20064;&#33021;&#21147;&#19982;&#26679;&#26412;&#21387;&#32553;&#24182;&#19981;&#30456;&#21516;&#30340;&#22810;&#31867;&#21035;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Multiclass Learnability Does Not Imply Sample Compression. (arXiv:2308.06424v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06424
&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#20108;&#20803;&#20551;&#35774;&#31867;&#20855;&#26377;&#26679;&#26412;&#21387;&#32553;&#26041;&#26696;&#65292;&#32780;&#22810;&#31867;&#21035;&#20551;&#35774;&#31867;&#21017;&#19981;&#20855;&#22791;&#36825;&#20010;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#26524;&#19968;&#20010;&#20551;&#35774;&#31867;&#33021;&#22815;&#36890;&#36807;&#21482;&#20445;&#30041;&#19968;&#20010;&#23567;&#30340;&#23376;&#26679;&#26412;&#25512;&#26029;&#20986;&#25972;&#20010;&#26679;&#26412;&#30340;&#26631;&#31614;&#65292;&#37027;&#20040;&#23427;&#23601;&#20855;&#26377;&#26679;&#26412;&#21387;&#32553;&#26041;&#26696;&#12290;&#23398;&#20064;&#20108;&#20803;&#20551;&#35774;&#31867;&#65288;&#24517;&#39035;&#20855;&#26377;&#26377;&#38480;&#30340;VC&#32500;&#24230;&#65289;&#37117;&#21487;&#20197;&#36890;&#36807;VC&#32500;&#24230;&#30340;&#19968;&#20010;&#26377;&#38480;&#20989;&#25968;&#22823;&#23567;&#30340;&#26679;&#26412;&#21387;&#32553;&#26041;&#26696;&#23454;&#29616;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#22810;&#31867;&#21035;&#20551;&#35774;&#31867;&#26469;&#35828;&#65292;DS&#32500;&#24230;&#26159;&#30456;&#23545;&#24212;&#30340;&#65292;&#25105;&#20204;&#21457;&#29616;&#23398;&#20064;&#22810;&#31867;&#21035;&#20551;&#35774;&#31867;&#65288;&#24517;&#39035;&#20855;&#26377;&#26377;&#38480;&#30340;DS&#32500;&#24230;&#65289;&#24182;&#19981;&#33021;&#36890;&#36807;&#19968;&#20010;DS&#32500;&#24230;&#30340;&#26377;&#38480;&#20989;&#25968;&#22823;&#23567;&#30340;&#26679;&#26412;&#21387;&#32553;&#26041;&#26696;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
A hypothesis class admits a sample compression scheme, if for every sample labeled by a hypothesis from the class, it is possible to retain only a small subsample, using which the labels on the entire sample can be inferred. The size of the compression scheme is an upper bound on the size of the subsample produced. Every learnable binary hypothesis class (which must necessarily have finite VC dimension) admits a sample compression scheme of size only a finite function of its VC dimension, independent of the sample size. For multiclass hypothesis classes, the analog of VC dimension is the DS dimension. We show that the analogous statement pertaining to sample compression is not true for multiclass hypothesis classes: every learnable multiclass hypothesis class, which must necessarily have finite DS dimension, does not admit a sample compression scheme of size only a finite function of its DS dimension.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#21160;&#36873;&#25321;&#26368;&#20339;&#30340;&#20301;&#23485;&#21644;&#23618;&#23485;&#26469;&#25552;&#39640;&#32593;&#32476;&#25928;&#29575;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#21098;&#26525;&#21644;&#32858;&#31867;&#25216;&#26415;&#65292;&#20248;&#21270;&#20102;&#25628;&#32034;&#36807;&#31243;&#65292;&#24182;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#20005;&#26684;&#27979;&#35797;&#65292;&#32467;&#26524;&#26174;&#31034;&#35813;&#26041;&#27861;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.06422</link><description>&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;&#32858;&#31867;&#30340;&#26641;&#29366;Parzen&#20272;&#35745;&#30340;&#25935;&#24863;&#24615;&#24863;&#30693;&#28151;&#21512;&#31934;&#24230;&#37327;&#21270;&#21644;&#23485;&#24230;&#20248;&#21270;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Sensitivity-Aware Mixed-Precision Quantization and Width Optimization of Deep Neural Networks Through Cluster-Based Tree-Structured Parzen Estimation. (arXiv:2308.06422v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06422
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#21160;&#36873;&#25321;&#26368;&#20339;&#30340;&#20301;&#23485;&#21644;&#23618;&#23485;&#26469;&#25552;&#39640;&#32593;&#32476;&#25928;&#29575;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#21098;&#26525;&#21644;&#32858;&#31867;&#25216;&#26415;&#65292;&#20248;&#21270;&#20102;&#25628;&#32034;&#36807;&#31243;&#65292;&#24182;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#20005;&#26684;&#27979;&#35797;&#65292;&#32467;&#26524;&#26174;&#31034;&#35813;&#26041;&#27861;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#22797;&#26434;&#24615;&#21644;&#35745;&#31639;&#38656;&#27714;&#30340;&#25552;&#39640;&#65292;&#23545;&#31070;&#32463;&#32593;&#32476;&#35774;&#35745;&#30340;&#26377;&#25928;&#20248;&#21270;&#26041;&#27861;&#30340;&#38656;&#27714;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#25628;&#32034;&#26426;&#21046;&#65292;&#29992;&#20110;&#33258;&#21160;&#36873;&#25321;&#21333;&#20010;&#31070;&#32463;&#32593;&#32476;&#23618;&#30340;&#26368;&#20339;&#20301;&#23485;&#21644;&#23618;&#23485;&#12290;&#36825;&#23548;&#33268;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25928;&#29575;&#30340;&#26126;&#26174;&#25552;&#39640;&#12290;&#36890;&#36807;&#21033;&#29992;&#22522;&#20110;Hessian&#30340;&#21098;&#26525;&#31574;&#30053;&#65292;&#26377;&#36873;&#25321;&#22320;&#20943;&#23569;&#25628;&#32034;&#22495;&#65292;&#30830;&#20445;&#31227;&#38500;&#38750;&#20851;&#38190;&#21442;&#25968;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#32858;&#31867;&#30340;&#26641;&#29366;Parzen&#20272;&#35745;&#22120;&#24320;&#21457;&#26377;&#21033;&#21644;&#19981;&#21033;&#32467;&#26524;&#30340;&#26367;&#20195;&#27169;&#22411;&#12290;&#36825;&#31181;&#31574;&#30053;&#20801;&#35768;&#23545;&#26550;&#26500;&#21487;&#33021;&#24615;&#36827;&#34892;&#31616;&#21270;&#30340;&#25506;&#32034;&#65292;&#24182;&#36805;&#36895;&#30830;&#23450;&#34920;&#29616;&#26368;&#22909;&#30340;&#35774;&#35745;&#12290;&#36890;&#36807;&#23545;&#30693;&#21517;&#25968;&#25454;&#38598;&#36827;&#34892;&#20005;&#26684;&#27979;&#35797;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#35777;&#26126;&#20102;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#30340;&#26126;&#26174;&#20248;&#21183;&#12290;&#19982;&#39046;&#20808;&#30340;&#21387;&#32553;&#31574;&#30053;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21462;&#24471;&#20102;&#20196;&#20154;&#30633;&#30446;&#30340;&#25104;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
As the complexity and computational demands of deep learning models rise, the need for effective optimization methods for neural network designs becomes paramount. This work introduces an innovative search mechanism for automatically selecting the best bit-width and layer-width for individual neural network layers. This leads to a marked enhancement in deep neural network efficiency. The search domain is strategically reduced by leveraging Hessian-based pruning, ensuring the removal of non-crucial parameters. Subsequently, we detail the development of surrogate models for favorable and unfavorable outcomes by employing a cluster-based tree-structured Parzen estimator. This strategy allows for a streamlined exploration of architectural possibilities and swift pinpointing of top-performing designs. Through rigorous testing on well-known datasets, our method proves its distinct advantage over existing methods. Compared to leading compression strategies, our approach records an impressive 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21464;&#20998;&#28508;&#22312;&#31163;&#25955;&#34920;&#31034;&#27169;&#22411;&#65292;&#20854;&#20013;&#31163;&#25955;&#29366;&#24577;&#37319;&#29992;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#24182;&#22312;&#24314;&#31569;&#31649;&#29702;&#25968;&#25454;&#38598;&#21644;&#30005;&#21147;&#21464;&#21387;&#22120;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24615;&#33021;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2306.15282</link><description>&lt;p&gt;
&#21464;&#20998;&#28508;&#22312;&#31163;&#25955;&#34920;&#31034;&#22312;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Variational Latent Discrete Representation for Time Series Modelling. (arXiv:2306.15282v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15282
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21464;&#20998;&#28508;&#22312;&#31163;&#25955;&#34920;&#31034;&#27169;&#22411;&#65292;&#20854;&#20013;&#31163;&#25955;&#29366;&#24577;&#37319;&#29992;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#24182;&#22312;&#24314;&#31569;&#31649;&#29702;&#25968;&#25454;&#38598;&#21644;&#30005;&#21147;&#21464;&#21387;&#22120;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24615;&#33021;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#31163;&#25955;&#28508;&#22312;&#31354;&#38388;&#27169;&#22411;&#22312;&#28145;&#24230;&#21464;&#20998;&#25512;&#26029;&#20013;&#30340;&#24615;&#33021;&#19982;&#20854;&#36830;&#32493;&#23545;&#24212;&#29289;&#30456;&#23218;&#32654;&#12290;&#34429;&#28982;&#23427;&#20204;&#20173;&#28982;&#38754;&#20020;&#21508;&#31181;&#23454;&#29616;&#25361;&#25112;&#65292;&#20294;&#36825;&#20123;&#27169;&#22411;&#20026;&#28508;&#22312;&#31354;&#38388;&#30340;&#26356;&#22909;&#35299;&#37322;&#25552;&#20379;&#20102;&#26426;&#20250;&#65292;&#21516;&#26102;&#26356;&#30452;&#25509;&#22320;&#34920;&#31034;&#33258;&#28982;&#31163;&#25955;&#29616;&#35937;&#12290;&#26368;&#36817;&#30340;&#19968;&#20123;&#26041;&#27861;&#24314;&#35758;&#20998;&#21035;&#22312;&#31163;&#25955;&#28508;&#22312;&#25968;&#25454;&#19978;&#35757;&#32451;&#38750;&#24120;&#39640;&#32500;&#30340;&#20808;&#39564;&#27169;&#22411;&#65292;&#36825;&#26412;&#36523;&#23601;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#28508;&#22312;&#25968;&#25454;&#27169;&#22411;&#65292;&#20854;&#20013;&#31163;&#25955;&#29366;&#24577;&#26159;&#19968;&#20010;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#23427;&#20801;&#35768;&#24555;&#36895;&#31471;&#21040;&#31471;&#35757;&#32451;&#12290;&#25105;&#20204;&#23545;&#25105;&#20204;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#24314;&#31569;&#31649;&#29702;&#25968;&#25454;&#38598;&#21644;&#20844;&#24320;&#21487;&#29992;&#30340;&#30005;&#21147;&#21464;&#21387;&#22120;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24615;&#33021;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Discrete latent space models have recently achieved performance on par with their continuous counterparts in deep variational inference. While they still face various implementation challenges, these models offer the opportunity for a better interpretation of latent spaces, as well as a more direct representation of naturally discrete phenomena. Most recent approaches propose to train separately very high-dimensional prior models on the discrete latent data which is a challenging task on its own. In this paper, we introduce a latent data model where the discrete state is a Markov chain, which allows fast end-to-end training. The performance of our generative model is assessed on a building management dataset and on the publicly available Electricity Transformer Dataset.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#28508;&#22312;&#21464;&#37327;&#27169;&#22411; LDIDPs&#65292;&#21033;&#29992;&#38544;&#24335;&#25193;&#25955;&#36807;&#31243;&#20174;&#21160;&#24577;&#28508;&#22312;&#36807;&#31243;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#28982;&#21518;&#29983;&#25104;&#30456;&#24212;&#30340;&#39034;&#24207;&#35266;&#23519;&#26679;&#26412;&#65292;&#30456;&#36739;&#20110;&#26368;&#20808;&#36827;&#30340;&#39034;&#24207;&#29983;&#25104;&#27169;&#22411;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.07077</link><description>&lt;p&gt;
&#28508;&#22312;&#21160;&#24577;&#38544;&#24335;&#25193;&#25955;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Latent Dynamical Implicit Diffusion Processes. (arXiv:2306.07077v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07077
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#28508;&#22312;&#21464;&#37327;&#27169;&#22411; LDIDPs&#65292;&#21033;&#29992;&#38544;&#24335;&#25193;&#25955;&#36807;&#31243;&#20174;&#21160;&#24577;&#28508;&#22312;&#36807;&#31243;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#28982;&#21518;&#29983;&#25104;&#30456;&#24212;&#30340;&#39034;&#24207;&#35266;&#23519;&#26679;&#26412;&#65292;&#30456;&#36739;&#20110;&#26368;&#20808;&#36827;&#30340;&#39034;&#24207;&#29983;&#25104;&#27169;&#22411;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28508;&#22312;&#21160;&#24577;&#27169;&#22411;&#24120;&#34987;&#29992;&#26469;&#23398;&#20064;&#20195;&#34920;&#19968;&#31995;&#21015;&#22122;&#22768;&#25968;&#25454;&#26679;&#26412;&#30340;&#28508;&#22312;&#21160;&#24577;&#36807;&#31243;&#30340;&#20998;&#24067;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#28508;&#22312;&#30340;&#21644;&#35266;&#27979;&#21160;&#24577;&#30340;&#22797;&#26434;&#24615;&#21644;&#21464;&#24322;&#24615;&#65292;&#20135;&#29983;&#20855;&#26377;&#39640;&#20445;&#30495;&#24230;&#30340;&#26679;&#26412;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26368;&#36817;&#65292;&#22312;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;&#20363;&#22914;DDPM&#21644;NCSN&#65289;&#26041;&#38754;&#21462;&#24471;&#30340;&#36827;&#23637;&#65292;&#23637;&#31034;&#20102;&#19968;&#20123;&#26377;&#21069;&#26223;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#20174;&#20808;&#39564;&#20998;&#24067;&#20013;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#24207;&#21015;&#26679;&#26412;&#65292;&#30456;&#36739;&#20110;&#20808;&#36827;&#30340;&#28508;&#22312;&#29983;&#25104;&#27169;&#22411;&#65288;&#22914;&#31070;&#32463;ODE&#12289;RNN&#21644;&#27491;&#21017;&#21270;&#27969;&#32593;&#32476;&#65289;&#12290;&#28982;&#32780;&#65292;&#23558;&#23427;&#20204;&#24212;&#29992;&#20110;&#24314;&#27169;&#20855;&#26377;&#28508;&#22312;&#21160;&#24577;&#27169;&#22411;&#30340;&#24207;&#21015;&#25968;&#25454;&#23578;&#26410;&#34987;&#25506;&#32034;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28508;&#22312;&#21160;&#24577;&#38544;&#24335;&#25193;&#25955;&#36807;&#31243;&#65288;LDIDPs&#65289;&#30340;&#26032;&#22411;&#28508;&#22312;&#21464;&#37327;&#27169;&#22411;&#65292;&#21033;&#29992;&#38544;&#24335;&#25193;&#25955;&#36807;&#31243;&#20174;&#21160;&#24577;&#28508;&#22312;&#36807;&#31243;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#28982;&#21518;&#29983;&#25104;&#30456;&#24212;&#30340;&#39034;&#24207;&#35266;&#23519;&#26679;&#26412;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#27169;&#25311;&#31070;&#32463;&#25968;&#25454;&#19978;&#27979;&#35797;&#20102;LDIDPs&#65292;&#24182;&#35777;&#26126;&#23427;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#39034;&#24207;&#29983;&#25104;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Latent dynamical models are commonly used to learn the distribution of a latent dynamical process that represents a sequence of noisy data samples. However, producing samples from such models with high fidelity is challenging due to the complexity and variability of latent and observation dynamics. Recent advances in diffusion-based generative models, such as DDPM and NCSN, have shown promising alternatives to state-of-the-art latent generative models, such as Neural ODEs, RNNs, and Normalizing flow networks, for generating high-quality sequential samples from a prior distribution. However, their application in modeling sequential data with latent dynamical models is yet to be explored. Here, we propose a novel latent variable model named latent dynamical implicit diffusion processes (LDIDPs), which utilizes implicit diffusion processes to sample from dynamical latent processes and generate sequential observation samples accordingly. We tested LDIDPs on synthetic and simulated neural d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;QBSD&#30340;&#23454;&#26102;&#39044;&#27979;&#26041;&#27861;&#65292;&#20197;&#22312;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#20013;&#21462;&#24471;&#26368;&#20339;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2306.05989</link><description>&lt;p&gt;
&#22522;&#20110;&#22235;&#20998;&#20301;&#25968;&#30340;&#23395;&#33410;&#24615;&#20998;&#35299;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#21644;&#24322;&#24120;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Quartile-Based Seasonality Decomposition for Time Series Forecasting and Anomaly Detection. (arXiv:2306.05989v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05989
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;QBSD&#30340;&#23454;&#26102;&#39044;&#27979;&#26041;&#27861;&#65292;&#20197;&#22312;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#20013;&#21462;&#24471;&#26368;&#20339;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30005;&#20449;&#39046;&#22495;&#65292;&#21450;&#26102;&#26816;&#27979;&#24322;&#24120;&#38750;&#24120;&#37325;&#35201;&#65292;&#22240;&#20026;&#36825;&#26377;&#21161;&#20110;&#35782;&#21035;&#21644;&#34920;&#24449;&#19981;&#35268;&#21017;&#27169;&#24335;&#12289;&#24322;&#24120;&#34892;&#20026;&#21644;&#32593;&#32476;&#24322;&#24120;&#65292;&#20174;&#32780;&#25552;&#39640;&#26381;&#21153;&#36136;&#37327;&#21644;&#25805;&#20316;&#25928;&#29575;&#12290;&#31934;&#30830;&#22320;&#39044;&#27979;&#21644;&#28040;&#38500;&#21487;&#39044;&#27979;&#30340;&#26102;&#38388;&#24207;&#21015;&#27169;&#24335;&#26159;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22522;&#20110;&#22235;&#20998;&#20301;&#25968;&#30340;&#23395;&#33410;&#24615;&#20998;&#35299;&#65288;QBSD&#65289;&#30340;&#23454;&#26102;&#39044;&#27979;&#26041;&#27861;&#65292;&#20197;&#22312;&#35745;&#31639;&#22797;&#26434;&#24230;&#21644;&#39044;&#27979;&#20934;&#30830;&#29575;&#20043;&#38388;&#21462;&#24471;&#26368;&#20339;&#24179;&#34913;&#12290;&#26412;&#25991;&#27604;&#36739;&#20102;QBSD&#19982;&#29616;&#26377;&#39044;&#27979;&#26041;&#27861;&#30340;&#24615;&#33021;&#21450;&#20854;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The timely detection of anomalies is essential in the telecom domain as it facilitates the identification and characterization of irregular patterns, abnormal behaviors, and network anomalies, contributing to enhanced service quality and operational efficiency. Precisely forecasting and eliminating predictable time series patterns constitutes a vital component of time series anomaly detection. While the state-of-the-art methods aim to maximize forecasting accuracy, the computational performance takes a hit. In a system composed of a large number of time series variables, e.g., cell Key Performance Indicators (KPIs), the time and space complexity of the forecasting employed is of crucial importance. Quartile-Based Seasonality Decomposition (QBSD) is a live forecasting method proposed in this paper to make an optimal trade-off between computational complexity and forecasting accuracy. This paper compares the performance of QBSD to the state-of-the-art forecasting methods and their applic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#27979;&#37327;&#33410;&#28857;&#20043;&#38388;&#25104;&#23545;&#20132;&#20114;&#30340;&#27700;&#24179;&#65292;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#20998;&#26512;&#65292;&#20197;&#30830;&#23450;&#20855;&#26377;&#19968;&#23450;&#23481;&#37327;&#30340;MPNN&#21487;&#20197;&#23398;&#20064;&#21738;&#20123;&#33410;&#28857;&#29305;&#24449;&#30340;&#20989;&#25968;&#31867;&#21035;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#20026;&#20102;&#20445;&#35777;&#33410;&#28857;&#23545;&#20043;&#38388;&#30340;&#20805;&#20998;&#36890;&#20449;&#65292;MPNN&#30340;&#23481;&#37327;&#24517;&#39035;&#26159;...</title><link>http://arxiv.org/abs/2306.03589</link><description>&lt;p&gt;
&#36807;&#24230;&#21387;&#32553;&#22914;&#20309;&#24433;&#21709;GNN&#30340;&#33021;&#21147;&#65311;
&lt;/p&gt;
&lt;p&gt;
How does over-squashing affect the power of GNNs?. (arXiv:2306.03589v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03589
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#27979;&#37327;&#33410;&#28857;&#20043;&#38388;&#25104;&#23545;&#20132;&#20114;&#30340;&#27700;&#24179;&#65292;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#20998;&#26512;&#65292;&#20197;&#30830;&#23450;&#20855;&#26377;&#19968;&#23450;&#23481;&#37327;&#30340;MPNN&#21487;&#20197;&#23398;&#20064;&#21738;&#20123;&#33410;&#28857;&#29305;&#24449;&#30340;&#20989;&#25968;&#31867;&#21035;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#20026;&#20102;&#20445;&#35777;&#33410;&#28857;&#23545;&#20043;&#38388;&#30340;&#20805;&#20998;&#36890;&#20449;&#65292;MPNN&#30340;&#23481;&#37327;&#24517;&#39035;&#26159;...
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#26159;&#22788;&#29702;&#22270;&#32467;&#26500;&#25968;&#25454;&#30340;&#26426;&#22120;&#23398;&#20064;&#30340;&#26368;&#20808;&#36827;&#27169;&#22411;&#12290;&#26368;&#27969;&#34892;&#30340;GNN&#31867;&#21035;&#26159;&#36890;&#36807;&#30456;&#37051;&#33410;&#28857;&#38388;&#30340;&#20449;&#24687;&#20132;&#25442;&#26469;&#25805;&#20316;&#30340;&#65292;&#31216;&#20026;&#28040;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#65288;MPNN&#65289;&#12290;&#37492;&#20110;&#23427;&#20204;&#30340;&#24191;&#27867;&#24212;&#29992;&#65292;&#20102;&#35299;MPNN&#30340;&#34920;&#36798;&#33021;&#21147;&#26159;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#32467;&#26524;&#36890;&#24120;&#32771;&#34385;&#20855;&#26377;&#26080;&#20449;&#24687;&#33410;&#28857;&#29305;&#24449;&#30340;&#29615;&#22659;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#20005;&#26684;&#30340;&#20998;&#26512;&#26041;&#27861;&#65292;&#20197;&#30830;&#23450;&#20855;&#26377;&#19968;&#23450;&#23481;&#37327;&#30340;MPNN&#21487;&#20197;&#23398;&#20064;&#21738;&#20123;&#33410;&#28857;&#29305;&#24449;&#30340;&#20989;&#25968;&#31867;&#21035;&#12290;&#25105;&#20204;&#36890;&#36807;&#27979;&#37327;MPNN&#20801;&#35768;&#30340;&#33410;&#28857;&#20043;&#38388;&#30340;&#25104;&#23545;&#20132;&#20114;&#27700;&#24179;&#26469;&#23454;&#29616;&#27492;&#30446;&#30340;&#12290;&#35813;&#27979;&#37327;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#37327;&#21270;&#29305;&#24615;&#65292;&#21363;&#25152;&#35859;&#30340;&#36807;&#24230;&#21387;&#32553;&#25928;&#24212;&#65292;&#35813;&#25928;&#24212;&#34987;&#35266;&#23519;&#21040;&#26159;&#24403;&#22823;&#37327;&#30340;&#20449;&#24687;&#32858;&#21512;&#25104;&#22266;&#23450;&#22823;&#23567;&#30340;&#21521;&#37327;&#26102;&#21457;&#29983;&#30340;&#12290;&#20351;&#29992;&#25105;&#20204;&#30340;&#27979;&#37327;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#20026;&#20102;&#20445;&#35777;&#33410;&#28857;&#23545;&#20043;&#38388;&#30340;&#20805;&#20998;&#36890;&#20449;&#65292;MPNN&#30340;&#23481;&#37327;&#24517;&#39035;&#26159;...
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) are the state-of-the-art model for machine learning on graph-structured data. The most popular class of GNNs operate by exchanging information between adjacent nodes, and are known as Message Passing Neural Networks (MPNNs). Given their widespread use, understanding the expressive power of MPNNs is a key question. However, existing results typically consider settings with uninformative node features. In this paper, we provide a rigorous analysis to determine which function classes of node features can be learned by an MPNN of a given capacity. We do so by measuring the level of pairwise interactions between nodes that MPNNs allow for. This measure provides a novel quantitative characterization of the so-called over-squashing effect, which is observed to occur when a large volume of messages is aggregated into fixed-size vectors. Using our measure, we prove that, to guarantee sufficient communication between pairs of nodes, the capacity of the MPNN must be l
&lt;/p&gt;</description></item><item><title>&#21307;&#23398;&#24433;&#20687;&#27169;&#22411;&#32534;&#30721;&#24739;&#32773;&#20154;&#21475;&#32479;&#35745;&#20449;&#24687;&#65292;&#24341;&#21457;&#26377;&#20851;&#28508;&#22312;&#27495;&#35270;&#30340;&#25285;&#24551;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#19981;&#32534;&#30721;&#20154;&#21475;&#23646;&#24615;&#30340;&#27169;&#22411;&#23481;&#26131;&#25439;&#22833;&#39044;&#27979;&#24615;&#33021;&#65292;&#32780;&#32771;&#34385;&#20154;&#21475;&#32479;&#35745;&#23646;&#24615;&#30340;&#21453;&#20107;&#23454;&#27169;&#22411;&#19981;&#21464;&#24615;&#23384;&#22312;&#22797;&#26434;&#24615;&#12290;&#20154;&#21475;&#32479;&#35745;&#23398;&#32534;&#30721;&#21487;&#20197;&#34987;&#35748;&#20026;&#26159;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2305.01397</link><description>&lt;p&gt;
&#21307;&#23398;&#24433;&#20687;&#20013;&#30340;&#20154;&#21475;&#32479;&#35745;&#23398;&#19981;&#21464;&#27169;&#22411;&#21644;&#34920;&#31034;&#26159;&#21542;&#20844;&#24179;&#65311;
&lt;/p&gt;
&lt;p&gt;
Are demographically invariant models and representations in medical imaging fair?. (arXiv:2305.01397v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01397
&lt;/p&gt;
&lt;p&gt;
&#21307;&#23398;&#24433;&#20687;&#27169;&#22411;&#32534;&#30721;&#24739;&#32773;&#20154;&#21475;&#32479;&#35745;&#20449;&#24687;&#65292;&#24341;&#21457;&#26377;&#20851;&#28508;&#22312;&#27495;&#35270;&#30340;&#25285;&#24551;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#19981;&#32534;&#30721;&#20154;&#21475;&#23646;&#24615;&#30340;&#27169;&#22411;&#23481;&#26131;&#25439;&#22833;&#39044;&#27979;&#24615;&#33021;&#65292;&#32780;&#32771;&#34385;&#20154;&#21475;&#32479;&#35745;&#23646;&#24615;&#30340;&#21453;&#20107;&#23454;&#27169;&#22411;&#19981;&#21464;&#24615;&#23384;&#22312;&#22797;&#26434;&#24615;&#12290;&#20154;&#21475;&#32479;&#35745;&#23398;&#32534;&#30721;&#21487;&#20197;&#34987;&#35748;&#20026;&#26159;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#34920;&#26126;&#65292;&#21307;&#23398;&#25104;&#20687;&#27169;&#22411;&#22312;&#20854;&#28508;&#22312;&#34920;&#31034;&#20013;&#32534;&#30721;&#20102;&#26377;&#20851;&#24739;&#32773;&#20154;&#21475;&#32479;&#35745;&#23398;&#20449;&#24687;&#65288;&#24180;&#40836;&#12289;&#31181;&#26063;&#12289;&#24615;&#21035;&#65289;&#65292;&#36825;&#24341;&#21457;&#20102;&#26377;&#20851;&#20854;&#28508;&#22312;&#27495;&#35270;&#30340;&#25285;&#24551;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#35810;&#38382;&#26159;&#21542;&#21487;&#34892;&#21644;&#20540;&#24471;&#35757;&#32451;&#19981;&#32534;&#30721;&#20154;&#21475;&#23646;&#24615;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#32771;&#34385;&#19981;&#21516;&#31867;&#22411;&#30340;&#19982;&#20154;&#21475;&#32479;&#35745;&#23398;&#23646;&#24615;&#30340;&#19981;&#21464;&#24615;&#65292;&#21363;&#36793;&#38469;&#12289;&#31867;&#26465;&#20214;&#21644;&#21453;&#20107;&#23454;&#27169;&#22411;&#19981;&#21464;&#24615;&#65292;&#24182;&#35828;&#26126;&#23427;&#20204;&#19982;&#31639;&#27861;&#20844;&#24179;&#30340;&#26631;&#20934;&#27010;&#24565;&#30340;&#31561;&#20215;&#24615;&#12290;&#26681;&#25454;&#29616;&#26377;&#29702;&#35770;&#65292;&#25105;&#20204;&#21457;&#29616;&#36793;&#38469;&#21644;&#31867;&#26465;&#20214;&#30340;&#19981;&#21464;&#24615;&#21487;&#34987;&#35748;&#20026;&#26159;&#23454;&#29616;&#26576;&#20123;&#20844;&#24179;&#27010;&#24565;&#30340;&#36807;&#24230;&#38480;&#21046;&#26041;&#27861;&#65292;&#23548;&#33268;&#26174;&#33879;&#30340;&#39044;&#27979;&#24615;&#33021;&#25439;&#22833;&#12290;&#20851;&#20110;&#21453;&#20107;&#23454;&#27169;&#22411;&#19981;&#21464;&#24615;&#65292;&#25105;&#20204;&#27880;&#24847;&#21040;&#23545;&#20110;&#20154;&#21475;&#32479;&#35745;&#23398;&#23646;&#24615;&#65292;&#23450;&#20041;&#21307;&#23398;&#22270;&#20687;&#21453;&#20107;&#23454;&#23384;&#22312;&#22797;&#26434;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35748;&#20026;&#20154;&#21475;&#32479;&#35745;&#23398;&#32534;&#30721;&#29978;&#33267;&#21487;&#20197;&#34987;&#35748;&#20026;&#26159;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Medical imaging models have been shown to encode information about patient demographics (age, race, sex) in their latent representation, raising concerns about their potential for discrimination. Here, we ask whether it is feasible and desirable to train models that do not encode demographic attributes. We consider different types of invariance with respect to demographic attributes marginal, class-conditional, and counterfactual model invariance - and lay out their equivalence to standard notions of algorithmic fairness. Drawing on existing theory, we find that marginal and class-conditional invariance can be considered overly restrictive approaches for achieving certain fairness notions, resulting in significant predictive performance losses. Concerning counterfactual model invariance, we note that defining medical image counterfactuals with respect to demographic attributes is fraught with complexities. Finally, we posit that demographic encoding may even be considered advantageou
&lt;/p&gt;</description></item><item><title>&#22312;&#20844;&#24179;&#20998;&#31867;&#20013;&#65292;&#27169;&#22411;&#30340;&#39044;&#27979;&#26041;&#24046;&#26159;&#19968;&#20010;&#37325;&#35201;&#20294;&#40092;&#20026;&#20154;&#30693;&#30340;&#35823;&#24046;&#26469;&#28304;&#38382;&#39064;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#27965;&#24615;&#26631;&#20934;&#26469;&#34913;&#37327;&#27979;&#37327;&#21644;&#20943;&#23569;&#38543;&#24847;&#24615;&#12290;&#20316;&#32773;&#36824;&#24320;&#21457;&#20102;&#19968;&#20010;&#31639;&#27861;&#26469;&#22788;&#29702;&#38543;&#24847;&#24615;&#39044;&#27979;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#25581;&#31034;&#20102;&#24403;&#21069;&#27169;&#22411;&#26080;&#27861;&#22788;&#29702;&#26576;&#20123;&#31867;&#22411;&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2301.11562</link><description>&lt;p&gt;
&#39044;&#27979;&#26159;&#21542;&#38543;&#24847;&#65311;&#22312;&#20844;&#24179;&#20998;&#31867;&#20013;&#35780;&#20272;&#33258;&#27965;&#24615;
&lt;/p&gt;
&lt;p&gt;
Is My Prediction Arbitrary? Measuring Self-Consistency in Fair Classification. (arXiv:2301.11562v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11562
&lt;/p&gt;
&lt;p&gt;
&#22312;&#20844;&#24179;&#20998;&#31867;&#20013;&#65292;&#27169;&#22411;&#30340;&#39044;&#27979;&#26041;&#24046;&#26159;&#19968;&#20010;&#37325;&#35201;&#20294;&#40092;&#20026;&#20154;&#30693;&#30340;&#35823;&#24046;&#26469;&#28304;&#38382;&#39064;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#27965;&#24615;&#26631;&#20934;&#26469;&#34913;&#37327;&#27979;&#37327;&#21644;&#20943;&#23569;&#38543;&#24847;&#24615;&#12290;&#20316;&#32773;&#36824;&#24320;&#21457;&#20102;&#19968;&#20010;&#31639;&#27861;&#26469;&#22788;&#29702;&#38543;&#24847;&#24615;&#39044;&#27979;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#25581;&#31034;&#20102;&#24403;&#21069;&#27169;&#22411;&#26080;&#27861;&#22788;&#29702;&#26576;&#20123;&#31867;&#22411;&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20844;&#24179;&#20998;&#31867;&#20013;&#65292;&#19981;&#21516;&#32463;&#36807;&#35757;&#32451;&#30340;&#27169;&#22411;&#20043;&#38388;&#30340;&#39044;&#27979;&#26041;&#24046;&#26159;&#19968;&#20010;&#37325;&#35201;&#20294;&#40092;&#20026;&#20154;&#30693;&#30340;&#35823;&#24046;&#26469;&#28304;&#38382;&#39064;&#12290; &#23454;&#35777;&#34920;&#26126;&#65292;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#39044;&#27979;&#30340;&#26041;&#24046;&#24046;&#24322;&#38750;&#24120;&#22823;&#65292;&#20197;&#33267;&#20110;&#20915;&#31574;&#23454;&#38469;&#19978;&#26159;&#38543;&#24847;&#30340;&#12290; &#20026;&#20102;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#22823;&#35268;&#27169;&#30340;&#23454;&#35777;&#30740;&#31350;&#65292;&#24182;&#20570;&#20986;&#20102;&#22235;&#20010;&#24635;&#20307;&#36129;&#29486;&#65306;&#25105;&#20204;1&#65289;&#23450;&#20041;&#20102;&#19968;&#31181;&#22522;&#20110;&#26041;&#24046;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#31216;&#20026;&#33258;&#27965;&#24615;&#65292;&#22312;&#27979;&#37327;&#21644;&#20943;&#23569;&#38543;&#24847;&#24615;&#26102;&#20351;&#29992;&#65307; 2&#65289;&#24320;&#21457;&#20102;&#19968;&#31181;&#21512;&#29702;&#30340;&#31639;&#27861;&#65292;&#24403;&#39044;&#27979;&#26080;&#27861;&#20570;&#20986;&#20915;&#31574;&#26102;&#65292;&#21487;&#20197;&#25918;&#24323;&#20998;&#31867;&#65307; 3&#65289;&#36827;&#34892;&#20102;&#36804;&#20170;&#20026;&#27490;&#26377;&#20851;&#20844;&#24179;&#20998;&#31867;&#20013;&#26041;&#24046;&#65288;&#30456;&#23545;&#20110;&#33258;&#27965;&#24615;&#21644;&#38543;&#24847;&#24615;&#65289;&#20316;&#29992;&#30340;&#26368;&#22823;&#35268;&#27169;&#23454;&#35777;&#30740;&#31350;&#65307; 4&#65289;&#25512;&#20986;&#20102;&#19968;&#20010;&#24037;&#20855;&#21253;&#65292;&#20351;&#32654;&#22269;&#20303;&#25151;&#25269;&#25276;&#36151;&#27454;&#25259;&#38706;&#27861;&#26696;&#65288;HMDA&#65289;&#25968;&#25454;&#38598;&#26131;&#20110;&#29992;&#20110;&#26410;&#26469;&#30740;&#31350;&#12290; &#24635;&#30340;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#23454;&#35777;&#32467;&#26524;&#25581;&#31034;&#20102;&#20851;&#20110;&#21487;&#37325;&#22797;&#24615;&#30340;&#20196;&#20154;&#38663;&#24778;&#30340;&#35265;&#35299;&#12290;&#24403;&#32771;&#34385;&#21040;&#26041;&#24046;&#21644;&#38543;&#24847;&#39044;&#27979;&#30340;&#21487;&#33021;&#24615;&#26102;&#65292;&#22823;&#22810;&#25968;&#20844;&#24179;&#20998;&#31867;&#22522;&#20934;&#25509;&#36817;&#20844;&#24179;&#12290; &#20294;&#26159;&#65292;&#19968;&#23567;&#37096;&#20998;&#23454;&#20363;&#26174;&#31034;&#20986;&#26497;&#22823;&#30340;&#38543;&#24847;&#24615;&#27700;&#24179;&#65292;&#36825;&#34920;&#26126;&#24403;&#21069;&#30340;&#27169;&#22411;&#21487;&#33021;&#26080;&#27861;&#22788;&#29702;&#26576;&#20123;&#31867;&#22411;&#30340;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variance in predictions across different trained models is a significant, under-explored source of error in fair classification. Empirically, the variance on some instances is so large that decisions can be effectively arbitrary. To study this problem, we perform a large-scale empirical study and make four overarching contributions: We 1) Define a metric called self-consistency, derived from variance, which we use as a proxy for measuring and reducing arbitrariness; 2) Develop an ensembling algorithm that abstains from classification when a prediction would be arbitrary; 3) Conduct the largest to-date empirical study of the role of variance (vis-a-vis self-consistency and arbitrariness) in fair classification; and, 4) Release a toolkit that makes the US Home Mortgage Disclosure Act (HMDA) datasets easily usable for future research. Altogether, our empirical results reveal shocking insights about reproducibility. Most fairness classification benchmarks are close-to-fair when taking into
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#31163;&#25955;&#33609;&#22270;&#25968;&#25454;&#30340;&#19968;&#33268;&#24615;&#39057;&#29575;&#20272;&#35745;&#26041;&#27861;&#65292;&#21487;&#20197;&#26500;&#24314;&#26597;&#35810;&#23545;&#35937;&#22312;&#22823;&#35268;&#27169;&#31163;&#25955;&#25968;&#25454;&#38598;&#20013;&#39057;&#29575;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#36890;&#36807;&#26032;&#39062;&#30340;&#19968;&#33268;&#24615;&#26657;&#20934;&#25216;&#26415;&#65292;&#25552;&#20379;&#20102;&#23545;&#25968;&#25454;&#30340;&#31163;&#25955;&#24615;&#21644;&#24322;&#36136;&#26597;&#35810;&#39057;&#29575;&#30340;&#26356;&#24378;&#25512;&#26029;&#65292;&#24182;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2211.04612</link><description>&lt;p&gt;
&#20351;&#29992;&#31163;&#25955;&#30340;&#33609;&#22270;&#25968;&#25454;&#21644;&#35206;&#30422;&#29575;&#36827;&#34892;&#19968;&#33268;&#24615;&#39057;&#29575;&#20272;&#35745;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Conformal Frequency Estimation using Discrete Sketched Data with Coverage for Distinct Queries. (arXiv:2211.04612v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.04612
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#31163;&#25955;&#33609;&#22270;&#25968;&#25454;&#30340;&#19968;&#33268;&#24615;&#39057;&#29575;&#20272;&#35745;&#26041;&#27861;&#65292;&#21487;&#20197;&#26500;&#24314;&#26597;&#35810;&#23545;&#35937;&#22312;&#22823;&#35268;&#27169;&#31163;&#25955;&#25968;&#25454;&#38598;&#20013;&#39057;&#29575;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#36890;&#36807;&#26032;&#39062;&#30340;&#19968;&#33268;&#24615;&#26657;&#20934;&#25216;&#26415;&#65292;&#25552;&#20379;&#20102;&#23545;&#25968;&#25454;&#30340;&#31163;&#25955;&#24615;&#21644;&#24322;&#36136;&#26597;&#35810;&#39057;&#29575;&#30340;&#26356;&#24378;&#25512;&#26029;&#65292;&#24182;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#19968;&#33268;&#24615;&#25512;&#26029;&#26041;&#27861;&#65292;&#21487;&#20197;&#22522;&#20110;&#20855;&#26377;&#36739;&#23567;&#20869;&#23384;&#21344;&#29992;&#30340;&#33609;&#22270;&#65292;&#26500;&#24314;&#19968;&#20010;&#26597;&#35810;&#23545;&#35937;&#22312;&#22823;&#35268;&#27169;&#31163;&#25955;&#25968;&#25454;&#38598;&#20013;&#39057;&#29575;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#36825;&#31181;&#26041;&#27861;&#19981;&#38656;&#35201;&#23545;&#25968;&#25454;&#20998;&#24067;&#26377;&#20219;&#20309;&#20102;&#35299;&#65292;&#24182;&#19988;&#21487;&#20197;&#19982;&#20219;&#20309;&#33609;&#22270;&#31639;&#27861;&#32467;&#21512;&#20351;&#29992;&#65292;&#21253;&#25324;&#20294;&#19981;&#38480;&#20110;&#33879;&#21517;&#30340;count-min&#33609;&#22270;&#12289;count-sketch&#20197;&#21450;&#23427;&#20204;&#30340;&#21464;&#20307;&#12290;&#22312;&#35299;&#37322;&#22914;&#20309;&#23454;&#29616;&#21487;&#20132;&#25442;&#38543;&#26426;&#26597;&#35810;&#30340;&#36793;&#38469;&#35206;&#30422;&#21518;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#35299;&#20915;&#26041;&#26696;&#25193;&#23637;&#21040;&#25552;&#20379;&#26356;&#24378;&#30340;&#25512;&#26029;&#65292;&#21487;&#20197;&#32771;&#34385;&#25968;&#25454;&#30340;&#31163;&#25955;&#24615;&#21644;&#24322;&#36136;&#26597;&#35810;&#39057;&#29575;&#65292;&#36824;&#22686;&#21152;&#20102;&#23545;&#21487;&#33021;&#30340;&#20998;&#24067;&#36716;&#25442;&#30340;&#40065;&#26834;&#24615;&#12290;&#36825;&#20123;&#32467;&#26524;&#24471;&#30410;&#20110;&#19968;&#31181;&#26032;&#39062;&#30340;&#19968;&#33268;&#24615;&#26657;&#20934;&#25216;&#26415;&#65292;&#21487;&#20197;&#20445;&#35777;&#22823;&#37096;&#20998;&#19981;&#21516;&#30340;&#38543;&#26426;&#26597;&#35810;&#20855;&#26377;&#26377;&#25928;&#30340;&#35206;&#30422;&#29575;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30456;&#27604;&#20110;&#29616;&#26377;&#30340;&#39057;&#29575;&#27966;&#21644;&#36125;&#21494;&#26031;&#27966;&#26367;&#20195;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#32463;&#39564;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper develops conformal inference methods to construct a confidence interval for the frequency of a queried object in a very large discrete data set, based on a sketch with a lower memory footprint. This approach requires no knowledge of the data distribution and can be combined with any sketching algorithm, including but not limited to the renowned count-min sketch, the count-sketch, and variations thereof. After explaining how to achieve marginal coverage for exchangeable random queries, we extend our solution to provide stronger inferences that can account for the discreteness of the data and for heterogeneous query frequencies, increasing also robustness to possible distribution shifts. These results are facilitated by a novel conformal calibration technique that guarantees valid coverage for a large fraction of distinct random queries. Finally, we show our methods have improved empirical performance compared to existing frequentist and Bayesian alternatives in simulations as
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;DCNNs&#65289;&#22312;&#27424;&#21442;&#25968;&#21644;&#36807;&#21442;&#25968;&#35774;&#32622;&#19979;&#30340;&#23398;&#20064;&#33021;&#21147;&#65292;&#24314;&#31435;&#20102;&#27424;&#21442;&#25968;DCNNs&#30340;&#23398;&#20064;&#36895;&#24230;&#65292;&#24182;&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#32593;&#32476;&#21152;&#28145;&#26041;&#26696;&#33719;&#24471;&#20102;&#25554;&#20540;DCNN&#65292;&#20174;&#32780;&#39564;&#35777;&#20102;&#36807;&#25311;&#21512;&#30340;DCNN&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2210.14184</link><description>&lt;p&gt;
&#25554;&#20540;&#28145;&#24230;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Learning Ability of Interpolating Deep Convolutional Neural Networks. (arXiv:2210.14184v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.14184
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;DCNNs&#65289;&#22312;&#27424;&#21442;&#25968;&#21644;&#36807;&#21442;&#25968;&#35774;&#32622;&#19979;&#30340;&#23398;&#20064;&#33021;&#21147;&#65292;&#24314;&#31435;&#20102;&#27424;&#21442;&#25968;DCNNs&#30340;&#23398;&#20064;&#36895;&#24230;&#65292;&#24182;&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#32593;&#32476;&#21152;&#28145;&#26041;&#26696;&#33719;&#24471;&#20102;&#25554;&#20540;DCNN&#65292;&#20174;&#32780;&#39564;&#35777;&#20102;&#36807;&#25311;&#21512;&#30340;DCNN&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#21442;&#25968;&#31070;&#32463;&#32593;&#32476;&#24448;&#24448;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#29616;&#26377;&#30340;&#29702;&#35770;&#24037;&#20316;&#20027;&#35201;&#30740;&#31350;&#20102;&#32447;&#24615;&#35774;&#32622;&#25110;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#24773;&#20917;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#37325;&#35201;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#21363;&#28145;&#24230;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;DCNNs&#65289;&#22312;&#27424;&#21442;&#25968;&#21644;&#36807;&#21442;&#25968;&#35774;&#32622;&#19979;&#30340;&#23398;&#20064;&#33021;&#21147;&#12290;&#25105;&#20204;&#22312;&#25991;&#29486;&#20013;&#39318;&#27425;&#24314;&#31435;&#20102;&#26080;&#21442;&#25968;&#25110;&#20989;&#25968;&#21464;&#37327;&#32467;&#26500;&#38480;&#21046;&#30340;&#27424;&#21442;&#25968;DCNNs&#30340;&#23398;&#20064;&#36895;&#24230;&#12290;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#36890;&#36807;&#21521;&#38750;&#25554;&#20540;DCNN&#28155;&#21152;&#33391;&#23450;&#20041;&#30340;&#23618;&#65292;&#21487;&#20197;&#33719;&#24471;&#19968;&#20123;&#20445;&#25345;&#38750;&#25554;&#20540;DCNN&#33391;&#22909;&#23398;&#20064;&#36895;&#24230;&#30340;&#25554;&#20540;DCNN&#12290;&#36825;&#19968;&#32467;&#26524;&#26159;&#36890;&#36807;&#20026;DCNN&#35774;&#35745;&#30340;&#19968;&#31181;&#26032;&#39062;&#30340;&#32593;&#32476;&#21152;&#28145;&#26041;&#26696;&#23454;&#29616;&#30340;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#22312;&#29702;&#35770;&#19978;&#39564;&#35777;&#20102;&#36807;&#25311;&#21512;&#30340;DCNN&#22914;&#20309;&#33391;&#22909;&#22320;&#36827;&#34892;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is frequently observed that overparameterized neural networks generalize well. Regarding such phenomena, existing theoretical work mainly devotes to linear settings or fully-connected neural networks. This paper studies the learning ability of an important family of deep neural networks, deep convolutional neural networks (DCNNs), under both underparameterized and overparameterized settings. We establish the first learning rates of underparameterized DCNNs without parameter or function variable structure restrictions presented in the literature. We also show that by adding well-defined layers to a non-interpolating DCNN, we can obtain some interpolating DCNNs that maintain the good learning rates of the non-interpolating DCNN. This result is achieved by a novel network deepening scheme designed for DCNNs. Our work provides theoretical verification of how overfitted DCNNs generalize well.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#29983;&#25104;&#31163;&#25955;&#22270;&#26102;&#20351;&#29992;&#31163;&#25955;&#22122;&#22768;&#30340;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#20043;&#21069;&#30340;&#26041;&#27861;&#65292;&#23454;&#39564;&#35777;&#26126;&#20351;&#29992;&#31163;&#25955;&#22122;&#22768;&#21487;&#20197;&#29983;&#25104;&#26356;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#65292;&#21516;&#26102;&#37319;&#26679;&#36807;&#31243;&#36895;&#24230;&#25552;&#39640;&#20102;30&#20493;&#12290;</title><link>http://arxiv.org/abs/2210.01549</link><description>&lt;p&gt;
&#22270;&#30340;&#25193;&#25955;&#27169;&#22411;&#21463;&#30410;&#20110;&#31163;&#25955;&#29366;&#24577;&#31354;&#38388;
&lt;/p&gt;
&lt;p&gt;
Diffusion Models for Graphs Benefit From Discrete State Spaces. (arXiv:2210.01549v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.01549
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#29983;&#25104;&#31163;&#25955;&#22270;&#26102;&#20351;&#29992;&#31163;&#25955;&#22122;&#22768;&#30340;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#20043;&#21069;&#30340;&#26041;&#27861;&#65292;&#23454;&#39564;&#35777;&#26126;&#20351;&#29992;&#31163;&#25955;&#22122;&#22768;&#21487;&#20197;&#29983;&#25104;&#26356;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#65292;&#21516;&#26102;&#37319;&#26679;&#36807;&#31243;&#36895;&#24230;&#25552;&#39640;&#20102;30&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#21644;&#35780;&#20998;&#21305;&#37197;&#27169;&#22411;&#24050;&#34987;&#35777;&#26126;&#22312;&#29983;&#25104;&#20219;&#21153;&#20013;&#38750;&#24120;&#24378;&#22823;&#12290;&#34429;&#28982;&#36825;&#20123;&#26041;&#27861;&#20063;&#34987;&#24212;&#29992;&#20110;&#31163;&#25955;&#22270;&#30340;&#29983;&#25104;&#65292;&#20294;&#36804;&#20170;&#20026;&#27490;&#65292;&#23427;&#20204;&#20173;&#20381;&#36182;&#20110;&#36830;&#32493;&#39640;&#26031;&#25200;&#21160;&#12290;&#30456;&#21453;&#65292;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;&#31163;&#25955;&#22122;&#22768;&#36827;&#34892;&#21069;&#21521;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#12290;&#36825;&#30830;&#20445;&#22312;&#27599;&#20010;&#20013;&#38388;&#27493;&#39588;&#20013;&#65292;&#22270;&#20445;&#25345;&#31163;&#25955;&#12290;&#19982;&#20808;&#21069;&#30340;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#22312;&#22235;&#20010;&#25968;&#25454;&#38598;&#21644;&#22810;&#20010;&#26550;&#26500;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#20351;&#29992;&#31163;&#25955;&#22122;&#22768;&#22788;&#29702;&#36807;&#31243;&#29983;&#25104;&#30340;&#26679;&#26412;&#36136;&#37327;&#26356;&#39640;&#65292;&#24179;&#22343; MMDs &#38477;&#20302;&#20102;1.5&#20493;&#12290;&#27492;&#22806;&#65292;&#21435;&#22122;&#27493;&#39588;&#30340;&#25968;&#37327;&#20174;1000&#20943;&#23569;&#21040;32&#27493;&#65292;&#23548;&#33268;&#37319;&#26679;&#36807;&#31243;&#36895;&#24230;&#25552;&#39640;&#20102;30&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;
Denoising diffusion probabilistic models and score-matching models have proven to be very powerful for generative tasks. While these approaches have also been applied to the generation of discrete graphs, they have, so far, relied on continuous Gaussian perturbations. Instead, in this work, we suggest using discrete noise for the forward Markov process. This ensures that in every intermediate step the graph remains discrete. Compared to the previous approach, our experimental results on four datasets and multiple architectures show that using a discrete noising process results in higher quality generated samples indicated with an average MMDs reduced by a factor of 1.5. Furthermore, the number of denoising steps is reduced from 1000 to 32 steps, leading to a 30 times faster sampling procedure.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#27424;&#38459;&#23612; Langevin &#21160;&#21147;&#23398;&#36827;&#34892;&#26080;&#20559;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#23545;&#20855;&#26377;&#38750;&#36127;&#23494;&#24230;&#30340;&#27010;&#29575;&#27979;&#24230;&#36827;&#34892;&#20272;&#35745;&#65292;&#36890;&#36807;&#20351;&#29992;&#31163;&#25955;&#21270;&#29256;&#26412;&#30340;&#21160;&#21147;&#23398;&#21644;&#21452;&#37325;&#38543;&#26426;&#20272;&#35745;&#26041;&#26696;&#65292;&#28040;&#38500;&#20102;&#31163;&#25955;&#21270;&#20559;&#24046;&#21644;&#26377;&#38480;&#27425;&#36816;&#34892;&#21160;&#21147;&#23398;&#20135;&#29983;&#30340;&#20559;&#24046;&#12290;</title><link>http://arxiv.org/abs/2206.07202</link><description>&lt;p&gt;
&#20351;&#29992;&#27424;&#38459;&#23612; Langevin &#21160;&#21147;&#23398;&#36827;&#34892;&#26080;&#20559;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Unbiased Estimation using Underdamped Langevin Dynamics. (arXiv:2206.07202v2 [stat.CO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.07202
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#27424;&#38459;&#23612; Langevin &#21160;&#21147;&#23398;&#36827;&#34892;&#26080;&#20559;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#23545;&#20855;&#26377;&#38750;&#36127;&#23494;&#24230;&#30340;&#27010;&#29575;&#27979;&#24230;&#36827;&#34892;&#20272;&#35745;&#65292;&#36890;&#36807;&#20351;&#29992;&#31163;&#25955;&#21270;&#29256;&#26412;&#30340;&#21160;&#21147;&#23398;&#21644;&#21452;&#37325;&#38543;&#26426;&#20272;&#35745;&#26041;&#26696;&#65292;&#28040;&#38500;&#20102;&#31163;&#25955;&#21270;&#20559;&#24046;&#21644;&#26377;&#38480;&#27425;&#36816;&#34892;&#21160;&#21147;&#23398;&#20135;&#29983;&#30340;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#23545;&#20855;&#26377;&#38750;&#36127; Lebesgue &#23494;&#24230;&#19988;&#22312;&#24402;&#19968;&#21270;&#24120;&#25968;&#19978;&#24050;&#30693;&#30340;&#27010;&#29575;&#27979;&#24230;&#36827;&#34892;&#26080;&#20559;&#20272;&#35745;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#36890;&#36807;&#27424;&#38459;&#23612; Langevin &#21160;&#21147;&#23398;&#24320;&#21457;&#19968;&#31181;&#26080;&#20559;&#26041;&#27861;&#65292;&#36825;&#31181;&#26041;&#27861;&#36817;&#26469;&#22312;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#22312;&#36830;&#32493;&#26102;&#38388;&#19979;&#65292;&#21487;&#20197;&#26500;&#36896;&#36825;&#31181;&#21160;&#21147;&#23398;&#20351;&#20854;&#38543;&#30528;&#26102;&#38388;&#36235;&#20110;&#26080;&#31351;&#65292;&#20854;&#31283;&#24577;&#27979;&#24230;&#20026;&#25152;&#20851;&#27880;&#30340;&#27010;&#29575;&#27979;&#24230;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#32463;&#24120;&#20351;&#29992;&#31163;&#25955;&#21270;&#30340;&#27424;&#38459;&#23612; Langevin &#21160;&#21147;&#23398;&#30340;&#26102;&#38388;&#31163;&#25955;&#29256;&#26412;&#65292;&#20165;&#36816;&#34892;&#26377;&#38480;&#27425;&#36845;&#20195;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21452;&#37325;&#38543;&#26426;&#20272;&#35745;&#30340;&#26032;&#26041;&#26696;&#65292;&#35813;&#26041;&#26696;&#20165;&#38656;&#35201;&#20351;&#29992;&#26102;&#38388;&#31163;&#25955;&#29256;&#26412;&#30340;&#21160;&#21147;&#23398;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#26696;&#26088;&#22312;&#28040;&#38500;&#31163;&#25955;&#21270;&#20559;&#24046;&#21644;&#30001;&#20110;&#26377;&#38480;&#27425;&#36816;&#34892;&#21160;&#21147;&#23398;&#20135;&#29983;&#30340;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work we consider the unbiased estimation of expectations w.r.t.~probability measures that have non-negative Lebesgue density, and which are known point-wise up-to a normalizing constant. We focus upon developing an unbiased method via the underdamped Langevin dynamics, which has proven to be popular of late due to applications in statistics and machine learning. Specifically in continuous-time, the dynamics can be constructed {so that as the time goes to infinity they} admit the probability of interest as a stationary measure. {In many cases, time-discretized versions of the underdamped Langevin dynamics are used in practice which are run only with a fixed number of iterations.} We develop a novel scheme based upon doubly randomized estimation as in \cite{ub_grad,disc_model}, which requires access only to time-discretized versions of the dynamics. {The proposed scheme aims to remove the dicretization bias and the bias resulting from running the dynamics for a finite number of i
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#26102;&#38388;&#22343;&#21248;&#30340;&#28176;&#36817;&#32622;&#20449;&#24207;&#21015;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#24207;&#21015;&#22312;&#26102;&#38388;&#19978;&#26159;&#32479;&#19968;&#26377;&#25928;&#30340;&#65292;&#33021;&#22815;&#22312;&#20219;&#24847;&#20572;&#27490;&#26102;&#38388;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#65292;&#24182;&#22635;&#34917;&#20102;&#29616;&#26377;&#25991;&#29486;&#20013;&#38750;&#28176;&#36817;&#32622;&#20449;&#24207;&#21015;&#19982;&#28176;&#36817;&#32622;&#20449;&#21306;&#38388;&#20043;&#38388;&#30340;&#31354;&#30333;&#12290;</title><link>http://arxiv.org/abs/2103.06476</link><description>&lt;p&gt;
&#26102;&#38388;&#22343;&#21248;&#30340;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#21644;&#28176;&#36817;&#32622;&#20449;&#24207;&#21015;
&lt;/p&gt;
&lt;p&gt;
Time-uniform central limit theory and asymptotic confidence sequences. (arXiv:2103.06476v7 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2103.06476
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#26102;&#38388;&#22343;&#21248;&#30340;&#28176;&#36817;&#32622;&#20449;&#24207;&#21015;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#24207;&#21015;&#22312;&#26102;&#38388;&#19978;&#26159;&#32479;&#19968;&#26377;&#25928;&#30340;&#65292;&#33021;&#22815;&#22312;&#20219;&#24847;&#20572;&#27490;&#26102;&#38388;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#65292;&#24182;&#22635;&#34917;&#20102;&#29616;&#26377;&#25991;&#29486;&#20013;&#38750;&#28176;&#36817;&#32622;&#20449;&#24207;&#21015;&#19982;&#28176;&#36817;&#32622;&#20449;&#21306;&#38388;&#20043;&#38388;&#30340;&#31354;&#30333;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65288;CLT&#65289;&#30340;&#32622;&#20449;&#21306;&#38388;&#26159;&#32463;&#20856;&#32479;&#35745;&#23398;&#30340;&#22522;&#30707;&#12290;&#23613;&#31649;&#21482;&#26159;&#28176;&#36817;&#26377;&#25928;&#30340;&#65292;&#20294;&#23427;&#20204;&#26222;&#36941;&#23384;&#22312;&#65292;&#22240;&#20026;&#23427;&#20204;&#20801;&#35768;&#22312;&#38750;&#24120;&#24369;&#30340;&#20551;&#35774;&#19979;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#65292;&#24182;&#19988;&#36890;&#24120;&#21487;&#20197;&#24212;&#29992;&#20110;&#21363;&#20351;&#38750;&#28176;&#36817;&#25512;&#26029;&#20063;&#19981;&#21487;&#33021;&#30340;&#38382;&#39064;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#26102;&#38388;&#22343;&#21248;&#30340;&#31867;&#20284;&#20110;&#36825;&#26679;&#30340;&#28176;&#36817;&#32622;&#20449;&#21306;&#38388;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#37319;&#29992;&#32622;&#20449;&#24207;&#21015;&#65288;CS&#65289;&#30340;&#24418;&#24335; - &#32622;&#20449;&#21306;&#38388;&#30340;&#24207;&#21015;&#65292;&#36825;&#20123;&#21306;&#38388;&#22312;&#26102;&#38388;&#19978;&#26159;&#32479;&#19968;&#26377;&#25928;&#30340;&#12290;CS&#21487;&#22312;&#20219;&#24847;&#20572;&#27490;&#26102;&#38388;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#65292;&#32780;&#19981;&#38656;&#35201;&#20687;&#32463;&#20856;&#32622;&#20449;&#21306;&#38388;&#37027;&#26679;&#22312;&#20808;&#22266;&#23450;&#26679;&#26412;&#22823;&#23567;&#30340;&#24773;&#20917;&#19979;&#20135;&#29983;&#8220;&#31397;&#35270;&#8221;&#25968;&#25454;&#30340;&#24809;&#32602;&#12290;&#29616;&#26377;&#25991;&#29486;&#20013;&#30340;CS&#37117;&#26159;&#38750;&#28176;&#36817;&#30340;&#65292;&#22240;&#27492;&#19981;&#33021;&#20139;&#21463;&#28176;&#36817;&#32622;&#20449;&#21306;&#38388;&#30340;&#24191;&#27867;&#36866;&#29992;&#24615;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#22635;&#34917;&#20102;&#36825;&#19968;&#31354;&#30333;&#65292;&#32473;&#20986;&#20102;&#8220;&#28176;&#36817;CS&#8221;&#30340;&#23450;&#20041;&#65292;&#24182;&#25512;&#23548;&#20986;&#19968;&#20010;&#36890;&#29992;&#30340;&#28176;&#36817;&#32622;&#20449;&#24207;&#21015;&#12290;
&lt;/p&gt;
&lt;p&gt;
Confidence intervals based on the central limit theorem (CLT) are a cornerstone of classical statistics. Despite being only asymptotically valid, they are ubiquitous because they permit statistical inference under very weak assumptions, and can often be applied to problems even when nonasymptotic inference is impossible. This paper introduces time-uniform analogues of such asymptotic confidence intervals. To elaborate, our methods take the form of confidence sequences (CS) -- sequences of confidence intervals that are uniformly valid over time. CSs provide valid inference at arbitrary stopping times, incurring no penalties for "peeking" at the data, unlike classical confidence intervals which require the sample size to be fixed in advance. Existing CSs in the literature are nonasymptotic, and hence do not enjoy the aforementioned broad applicability of asymptotic confidence intervals. Our work bridges the gap by giving a definition for "asymptotic CSs", and deriving a universal asympto
&lt;/p&gt;</description></item></channel></rss>