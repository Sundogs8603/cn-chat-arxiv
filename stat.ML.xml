<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#26088;&#22312;&#24320;&#21457;&#19968;&#20010;&#22522;&#20110;MOOSE&#30340;&#20808;&#36827;&#21046;&#36896;&#27169;&#22411;&#30340;&#20934;&#30830;&#19988;&#36816;&#34892;&#36895;&#24230;&#24555;&#30340;&#38477;&#38454;&#27169;&#22411;&#65288;ROM&#65289;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#22312;&#22522;&#20110;DRL&#30340;&#36807;&#31243;&#25511;&#21046;&#21644;&#20248;&#21270;&#26041;&#27861;&#20013;&#20351;&#29992;&#12290;&#20351;&#29992;&#36816;&#31639;&#31526;&#23398;&#20064;&#65288;OL&#65289;&#26041;&#27861;&#65292;&#23398;&#20064;&#19968;&#26063;&#30001;&#25913;&#21464;&#30340;&#36807;&#31243;&#21464;&#37327;&#20135;&#29983;&#30340;&#24494;&#20998;&#26041;&#31243;&#12290;</title><link>http://arxiv.org/abs/2308.09691</link><description>&lt;p&gt;
&#22522;&#20110;MOOSE&#30340;&#20808;&#36827;&#21046;&#36896;&#27169;&#22411;&#30340;&#38477;&#38454;&#24314;&#27169;&#19982;&#36816;&#31639;&#31526;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Reduced Order Modeling of a MOOSE-based Advanced Manufacturing Model with Operator Learning. (arXiv:2308.09691v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09691
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#24320;&#21457;&#19968;&#20010;&#22522;&#20110;MOOSE&#30340;&#20808;&#36827;&#21046;&#36896;&#27169;&#22411;&#30340;&#20934;&#30830;&#19988;&#36816;&#34892;&#36895;&#24230;&#24555;&#30340;&#38477;&#38454;&#27169;&#22411;&#65288;ROM&#65289;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#22312;&#22522;&#20110;DRL&#30340;&#36807;&#31243;&#25511;&#21046;&#21644;&#20248;&#21270;&#26041;&#27861;&#20013;&#20351;&#29992;&#12290;&#20351;&#29992;&#36816;&#31639;&#31526;&#23398;&#20064;&#65288;OL&#65289;&#26041;&#27861;&#65292;&#23398;&#20064;&#19968;&#26063;&#30001;&#25913;&#21464;&#30340;&#36807;&#31243;&#21464;&#37327;&#20135;&#29983;&#30340;&#24494;&#20998;&#26041;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#36827;&#21046;&#36896;&#65288;AM&#65289;&#22240;&#20854;&#22312;&#26680;&#26448;&#26009;&#39046;&#22495;&#30340;&#28508;&#22312;&#24212;&#29992;&#32780;&#24341;&#36215;&#20102;&#26680;&#31038;&#21306;&#30340;&#24191;&#27867;&#20851;&#27880;&#12290;&#19968;&#20010;&#25361;&#25112;&#26159;&#36890;&#36807;&#22312;&#36816;&#34892;&#26102;&#25511;&#21046;&#21046;&#36896;&#36807;&#31243;&#26469;&#33719;&#24471;&#25152;&#38656;&#30340;&#26448;&#26009;&#24615;&#36136;&#12290;&#22522;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#30340;&#26234;&#33021;AM&#20381;&#36182;&#20110;&#33258;&#21160;&#21270;&#30340;&#36807;&#31243;&#32423;&#25511;&#21046;&#26426;&#21046;&#65292;&#20197;&#29983;&#25104;&#29992;&#20110;&#25913;&#36827;&#26368;&#32456;&#20135;&#21697;&#24615;&#36136;&#30340;&#26368;&#20339;&#35774;&#35745;&#21464;&#37327;&#21644;&#33258;&#36866;&#24212;&#31995;&#32479;&#35774;&#32622;&#12290;&#26368;&#36817;&#22312;&#29233;&#36798;&#33655;&#22269;&#23478;&#23454;&#39564;&#23460;&#65288;INL&#65289;&#30340;MOOSE&#26694;&#26550;&#20013;&#24320;&#21457;&#20102;&#19968;&#20010;&#29992;&#20110;&#30452;&#25509;&#33021;&#37327;&#27785;&#31215;&#30340;&#39640;&#20445;&#30495;&#24230;&#28909;&#21147;&#26426;&#26800;&#27169;&#22411;&#12290;&#35813;&#24037;&#20316;&#30340;&#30446;&#26631;&#26159;&#20026;&#36825;&#20010;&#22522;&#20110;MOOSE&#30340;AM&#27169;&#22411;&#24320;&#21457;&#19968;&#20010;&#20934;&#30830;&#19988;&#36816;&#34892;&#36895;&#24230;&#24555;&#30340;&#38477;&#38454;&#27169;&#22411;&#65288;ROM&#65289;&#65292;&#20197;&#20415;&#22312;&#22522;&#20110;DRL&#30340;&#36807;&#31243;&#25511;&#21046;&#21644;&#20248;&#21270;&#26041;&#27861;&#20013;&#20351;&#29992;&#12290;&#30001;&#20110;&#23427;&#20204;&#33021;&#22815;&#23398;&#20064;&#19968;&#26063;&#30001;&#25913;&#21464;&#30340;&#36807;&#31243;&#21464;&#37327;&#20135;&#29983;&#30340;&#24494;&#20998;&#26041;&#31243;&#65292;&#22240;&#27492;&#23558;&#37319;&#29992;&#22522;&#20110;&#36816;&#31639;&#31526;&#23398;&#20064;&#65288;OL&#65289;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Advanced Manufacturing (AM) has gained significant interest in the nuclear community for its potential application on nuclear materials. One challenge is to obtain desired material properties via controlling the manufacturing process during runtime. Intelligent AM based on deep reinforcement learning (DRL) relies on an automated process-level control mechanism to generate optimal design variables and adaptive system settings for improved end-product properties. A high-fidelity thermo-mechanical model for direct energy deposition has recently been developed within the MOOSE framework at the Idaho National Laboratory (INL). The goal of this work is to develop an accurate and fast-running reduced order model (ROM) for this MOOSE-based AM model that can be used in a DRL-based process control and optimization method. Operator learning (OL)-based methods will be employed due to their capability to learn a family of differential equations, in this work, produced by changing process variables 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;MC-CP&#30340;&#26032;&#22411;&#28151;&#21512;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#33258;&#36866;&#24212;&#33945;&#29305;&#21345;&#27931;dropout&#26041;&#27861;&#19982;&#21512;&#35268;&#39044;&#27979;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#33410;&#30465;&#36164;&#28304;&#21644;&#20135;&#29983;&#40065;&#26834;&#39044;&#27979;&#38598;/&#21306;&#38388;&#30340;&#30446;&#26631;&#12290;&#23454;&#39564;&#35777;&#26126;MC-CP&#22312;&#20998;&#31867;&#20219;&#21153;&#20013;&#30456;&#27604;&#20854;&#20182;&#20808;&#36827;&#26041;&#27861;&#20855;&#26377;&#26174;&#33879;&#25552;&#21319;</title><link>http://arxiv.org/abs/2308.09647</link><description>&lt;p&gt;
&#20351;&#29992;&#21512;&#35268;&#30340;&#33945;&#29305;&#21345;&#27931;&#39044;&#27979;&#23454;&#29616;&#40065;&#26834;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Robust Uncertainty Quantification using Conformalised Monte Carlo Prediction. (arXiv:2308.09647v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09647
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;MC-CP&#30340;&#26032;&#22411;&#28151;&#21512;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#33258;&#36866;&#24212;&#33945;&#29305;&#21345;&#27931;dropout&#26041;&#27861;&#19982;&#21512;&#35268;&#39044;&#27979;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#33410;&#30465;&#36164;&#28304;&#21644;&#20135;&#29983;&#40065;&#26834;&#39044;&#27979;&#38598;/&#21306;&#38388;&#30340;&#30446;&#26631;&#12290;&#23454;&#39564;&#35777;&#26126;MC-CP&#22312;&#20998;&#31867;&#20219;&#21153;&#20013;&#30456;&#27604;&#20854;&#20182;&#20808;&#36827;&#26041;&#27861;&#20855;&#26377;&#26174;&#33879;&#25552;&#21319;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23433;&#20840;&#20851;&#38190;&#24212;&#29992;&#20013;&#37096;&#32626;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20173;&#28982;&#26159;&#19968;&#39033;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#38656;&#35201;&#23545;&#36825;&#20123;&#27169;&#22411;&#30340;&#21487;&#38752;&#36816;&#34892;&#25552;&#20379;&#20445;&#35777;&#12290;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65288;UQ&#65289;&#26041;&#27861;&#20272;&#35745;&#27599;&#20010;&#39044;&#27979;&#30340;&#27169;&#22411;&#32622;&#20449;&#24230;&#65292;&#36890;&#36807;&#32771;&#34385;&#38543;&#26426;&#24615;&#21644;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#21270;&#30340;&#24433;&#21709;&#26469;&#25351;&#23548;&#20915;&#31574;&#12290;&#23613;&#31649;&#26368;&#20808;&#36827;&#30340;UQ&#26041;&#27861;&#21462;&#24471;&#20102;&#19968;&#20123;&#36827;&#23637;&#65292;&#20294;&#23427;&#20204;&#22312;&#35745;&#31639;&#19978;&#35201;&#20040;&#38750;&#24120;&#26114;&#36149;&#65292;&#35201;&#20040;&#20135;&#29983;&#20445;&#23432;&#30340;&#39044;&#27979;&#38598;/&#21306;&#38388;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#28151;&#21512;UQ&#26041;&#27861;MC-CP&#65292;&#23427;&#23558;&#19968;&#31181;&#26032;&#30340;&#33258;&#36866;&#24212;&#33945;&#29305;&#21345;&#27931;&#65288;MC&#65289;dropout&#26041;&#27861;&#19982;&#21512;&#35268;&#39044;&#27979;&#65288;CP&#65289;&#30456;&#32467;&#21512;&#12290;MC-CP&#22312;&#36816;&#34892;&#26102;&#33258;&#36866;&#24212;&#35843;&#33410;&#20256;&#32479;&#30340;MC dropout&#20197;&#33410;&#30465;&#20869;&#23384;&#21644;&#35745;&#31639;&#36164;&#28304;&#65292;&#20351;&#24471;&#39044;&#27979;&#21487;&#20197;&#34987;CP&#20351;&#29992;&#65292;&#24471;&#21040;&#40065;&#26834;&#30340;&#39044;&#27979;&#38598;/&#21306;&#38388;&#12290;&#36890;&#36807;&#20840;&#38754;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;MC-CP&#30456;&#27604;MC dropout&#12289;RAPS&#21644;CQR&#31561;&#20808;&#36827;&#30340;UQ&#26041;&#27861;&#33021;&#22815;&#26174;&#33879;&#25913;&#21892;&#20998;&#31867;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Deploying deep learning models in safety-critical applications remains a very challenging task, mandating the provision of assurances for the dependable operation of these models. Uncertainty quantification (UQ) methods estimate the model's confidence per prediction, informing decision-making by considering the effect of randomness and model misspecification. Despite the advances of state-of-the-art UQ methods, they are computationally expensive or produce conservative prediction sets/intervals. We introduce MC-CP, a novel hybrid UQ method that combines a new adaptive Monte Carlo (MC) dropout method with conformal prediction (CP). MC-CP adaptively modulates the traditional MC dropout at runtime to save memory and computation resources, enabling predictions to be consumed by CP, yielding robust prediction sets/intervals. Throughout comprehensive experiments, we show that MC-CP delivers significant improvements over advanced UQ methods, like MC dropout, RAPS and CQR, both in classificati
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20005;&#26684;&#20998;&#26512;&#20102;&#22312;&#29699;&#38754;&#19978;&#35299;&#20915;PDEs&#30340;&#29289;&#29702;&#20449;&#24687;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;PICNN&#65289;&#65292;&#36890;&#36807;&#20351;&#29992;&#26368;&#26032;&#30340;&#36924;&#36817;&#32467;&#26524;&#21644;&#29699;&#35856;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#36924;&#36817;&#35823;&#24046;&#19982;Sobolev&#33539;&#25968;&#30340;&#19978;&#30028;&#65292;&#24182;&#24314;&#31435;&#20102;&#24555;&#36895;&#25910;&#25947;&#36895;&#29575;&#12290;&#23454;&#39564;&#32467;&#26524;&#20063;&#39564;&#35777;&#20102;&#29702;&#35770;&#20998;&#26512;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.09605</link><description>&lt;p&gt;
&#20351;&#29992;&#29289;&#29702;&#20449;&#24687;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#22312;&#29699;&#38754;&#19978;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;
&lt;/p&gt;
&lt;p&gt;
Solving PDEs on Spheres with Physics-Informed Convolutional Neural Networks. (arXiv:2308.09605v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09605
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20005;&#26684;&#20998;&#26512;&#20102;&#22312;&#29699;&#38754;&#19978;&#35299;&#20915;PDEs&#30340;&#29289;&#29702;&#20449;&#24687;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;PICNN&#65289;&#65292;&#36890;&#36807;&#20351;&#29992;&#26368;&#26032;&#30340;&#36924;&#36817;&#32467;&#26524;&#21644;&#29699;&#35856;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#36924;&#36817;&#35823;&#24046;&#19982;Sobolev&#33539;&#25968;&#30340;&#19978;&#30028;&#65292;&#24182;&#24314;&#31435;&#20102;&#24555;&#36895;&#25910;&#25947;&#36895;&#29575;&#12290;&#23454;&#39564;&#32467;&#26524;&#20063;&#39564;&#35777;&#20102;&#29702;&#35770;&#20998;&#26512;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#65288;PINNs&#65289;&#24050;&#34987;&#35777;&#26126;&#22312;&#35299;&#20915;&#21508;&#31181;&#23454;&#39564;&#35282;&#24230;&#20013;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDEs&#65289;&#26041;&#38754;&#38750;&#24120;&#39640;&#25928;&#12290;&#19968;&#20123;&#26368;&#36817;&#30340;&#30740;&#31350;&#36824;&#25552;&#20986;&#20102;&#38024;&#23545;&#34920;&#38754;&#65292;&#21253;&#25324;&#29699;&#38754;&#19978;&#30340;PDEs&#30340;PINN&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;PINNs&#30340;&#25968;&#20540;&#24615;&#33021;&#65292;&#23588;&#20854;&#26159;&#22312;&#34920;&#38754;&#25110;&#27969;&#24418;&#19978;&#30340;PINNs&#65292;&#20173;&#28982;&#32570;&#20047;&#29702;&#35770;&#29702;&#35299;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23545;&#29992;&#20110;&#22312;&#29699;&#38754;&#19978;&#35299;&#20915;PDEs&#30340;&#29289;&#29702;&#20449;&#24687;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;PICNN&#65289;&#36827;&#34892;&#20102;&#20005;&#26684;&#20998;&#26512;&#12290;&#36890;&#36807;&#20351;&#29992;&#21644;&#25913;&#36827;&#28145;&#24230;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#21644;&#29699;&#35856;&#20998;&#26512;&#30340;&#26368;&#26032;&#36924;&#36817;&#32467;&#26524;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#36924;&#36817;&#35823;&#24046;&#19982;Sobolev&#33539;&#25968;&#30340;&#19978;&#30028;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#23558;&#36825;&#19968;&#32467;&#26524;&#19982;&#21019;&#26032;&#30340;&#23616;&#37096;&#22797;&#26434;&#24230;&#20998;&#26512;&#30456;&#32467;&#21512;&#65292;&#24314;&#31435;&#20102;PICNN&#30340;&#24555;&#36895;&#25910;&#25947;&#36895;&#29575;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#20063;&#24471;&#21040;&#20102;&#23454;&#39564;&#30340;&#39564;&#35777;&#21644;&#34917;&#20805;&#12290;&#37492;&#20110;&#36825;&#20123;&#21457;&#29616;&#65292;
&lt;/p&gt;
&lt;p&gt;
Physics-informed neural networks (PINNs) have been demonstrated to be efficient in solving partial differential equations (PDEs) from a variety of experimental perspectives. Some recent studies have also proposed PINN algorithms for PDEs on surfaces, including spheres. However, theoretical understanding of the numerical performance of PINNs, especially PINNs on surfaces or manifolds, is still lacking. In this paper, we establish rigorous analysis of the physics-informed convolutional neural network (PICNN) for solving PDEs on the sphere. By using and improving the latest approximation results of deep convolutional neural networks and spherical harmonic analysis, we prove an upper bound for the approximation error with respect to the Sobolev norm. Subsequently, we integrate this with innovative localization complexity analysis to establish fast convergence rates for PICNN. Our theoretical results are also confirmed and supplemented by our experiments. In light of these findings, we expl
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25581;&#31034;&#20102;&#23618;&#24402;&#19968;&#21270;&#21644;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#26631;&#31614;&#20559;&#31227;&#38382;&#39064;&#20043;&#38388;&#30340;&#28145;&#21051;&#32852;&#31995;&#65292;&#36890;&#36807;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#24212;&#29992;&#29305;&#24449;&#24402;&#19968;&#21270;&#65292;&#20351;&#24471;&#23545;&#20005;&#37325;&#20542;&#26012;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#21152;&#36895;&#20840;&#23616;&#35757;&#32451;&#65292;&#20174;&#32780;&#22312;&#26497;&#31471;&#26631;&#31614;&#20559;&#31227;&#19979;&#33719;&#24471;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2308.09565</link><description>&lt;p&gt;
&#35268;&#33539;&#21270;&#23601;&#26159;&#20320;&#25152;&#38656;&#35201;&#30340;&#65306;&#29702;&#35299;&#26497;&#31471;&#26631;&#31614;&#20559;&#31227;&#19979;&#30340;&#23618;&#24402;&#19968;&#21270;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Normalization Is All You Need: Understanding Layer-Normalized Federated Learning under Extreme Label Shift. (arXiv:2308.09565v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09565
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25581;&#31034;&#20102;&#23618;&#24402;&#19968;&#21270;&#21644;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#26631;&#31614;&#20559;&#31227;&#38382;&#39064;&#20043;&#38388;&#30340;&#28145;&#21051;&#32852;&#31995;&#65292;&#36890;&#36807;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#24212;&#29992;&#29305;&#24449;&#24402;&#19968;&#21270;&#65292;&#20351;&#24471;&#23545;&#20005;&#37325;&#20542;&#26012;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#21152;&#36895;&#20840;&#23616;&#35757;&#32451;&#65292;&#20174;&#32780;&#22312;&#26497;&#31471;&#26631;&#31614;&#20559;&#31227;&#19979;&#33719;&#24471;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23618;&#24402;&#19968;&#21270;&#65288;LN&#65289;&#26159;&#19968;&#20010;&#24191;&#27867;&#37319;&#29992;&#30340;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#65292;&#29305;&#21035;&#22312;&#22522;&#30784;&#27169;&#22411;&#30340;&#26102;&#20195;&#12290;&#26368;&#36817;&#65292;&#24050;&#32463;&#35777;&#26126;LN&#22312;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#19978;&#30340;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#20013;&#38750;&#24120;&#26377;&#25928;&#12290;&#28982;&#32780;&#65292;&#23427;&#20026;&#20160;&#20040;&#20197;&#21450;&#22914;&#20309;&#36215;&#20316;&#29992;&#20173;&#28982;&#26159;&#20010;&#35868;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#23618;&#24402;&#19968;&#21270;&#21644;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#26631;&#31614;&#20559;&#31227;&#38382;&#39064;&#20043;&#38388;&#30340;&#28145;&#21051;&#32852;&#31995;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;FL&#20013;&#30340;&#23618;&#24402;&#19968;&#21270;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#35268;&#33539;&#21270;&#26041;&#27861;&#22312;FL&#20013;&#30340;&#20851;&#38190;&#36129;&#29486;&#26426;&#21046;&#65292;&#31216;&#20043;&#20026;&#29305;&#24449;&#24402;&#19968;&#21270;&#65288;FN&#65289;&#65292;&#23427;&#22312;&#20998;&#31867;&#22120;&#22836;&#20043;&#21069;&#23558;&#24402;&#19968;&#21270;&#24212;&#29992;&#20110;&#28508;&#22312;&#29305;&#24449;&#34920;&#31034;&#12290;&#34429;&#28982;LN&#21644;FN&#19981;&#20250;&#25552;&#39640;&#34920;&#36798;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#25511;&#21046;&#29305;&#24449;&#23849;&#28291;&#21644;&#23616;&#37096;&#36807;&#25311;&#21512;&#65292;&#20351;&#24471;&#23545;&#20005;&#37325;&#20542;&#26012;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#21152;&#36895;&#20840;&#23616;&#35757;&#32451;&#12290;&#32463;&#39564;&#35777;&#26126;&#65292;&#35268;&#33539;&#21270;&#22312;&#26497;&#31471;&#26631;&#31614;&#20559;&#31227;&#19979;&#21487;&#20197;&#24341;&#36215;&#26631;&#20934;&#22522;&#20934;&#30340;&#26174;&#33879;&#25913;&#36827;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#22823;&#37327;&#30340;&#21106;&#38500;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Layer normalization (LN) is a widely adopted deep learning technique especially in the era of foundation models. Recently, LN has been shown to be surprisingly effective in federated learning (FL) with non-i.i.d. data. However, exactly why and how it works remains mysterious. In this work, we reveal the profound connection between layer normalization and the label shift problem in federated learning. To understand layer normalization better in FL, we identify the key contributing mechanism of normalization methods in FL, called feature normalization (FN), which applies normalization to the latent feature representation before the classifier head. Although LN and FN do not improve expressive power, they control feature collapse and local overfitting to heavily skewed datasets, and thus accelerates global training. Empirically, we show that normalization leads to drastic improvements on standard benchmarks under extreme label shift. Moreover, we conduct extensive ablation studies to unde
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#20998;&#26512;&#22312;&#20855;&#26377;&#35768;&#22810;&#27425;&#20248;&#23616;&#37096;&#26368;&#23567;&#20540;&#30340;&#21487;&#24494;&#20989;&#25968;&#30340;&#20840;&#23616;&#20248;&#21270;&#20013;&#21033;&#29992;&#26799;&#24230;&#30340;&#21407;&#29702;&#65292;&#23637;&#31034;&#20102;&#26799;&#24230;&#22312;&#20840;&#23616;&#20248;&#21270;&#20013;&#30340;&#23454;&#29992;&#24615;&#65292;&#24182;&#36827;&#34892;&#20102;&#30456;&#24212;&#30340;&#23454;&#39564;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2308.09556</link><description>&lt;p&gt;
&#20855;&#26377;&#26799;&#24230;&#30340;&#20840;&#23616;&#20248;&#21270;&#21407;&#29702;
&lt;/p&gt;
&lt;p&gt;
A Principle for Global Optimization with Gradients. (arXiv:2308.09556v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09556
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#20998;&#26512;&#22312;&#20855;&#26377;&#35768;&#22810;&#27425;&#20248;&#23616;&#37096;&#26368;&#23567;&#20540;&#30340;&#21487;&#24494;&#20989;&#25968;&#30340;&#20840;&#23616;&#20248;&#21270;&#20013;&#21033;&#29992;&#26799;&#24230;&#30340;&#21407;&#29702;&#65292;&#23637;&#31034;&#20102;&#26799;&#24230;&#22312;&#20840;&#23616;&#20248;&#21270;&#20013;&#30340;&#23454;&#29992;&#24615;&#65292;&#24182;&#36827;&#34892;&#20102;&#30456;&#24212;&#30340;&#23454;&#39564;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#23637;&#31034;&#20102;&#22312;&#20855;&#26377;&#35768;&#22810;&#27425;&#20248;&#23616;&#37096;&#26368;&#23567;&#20540;&#30340;&#21487;&#24494;&#20989;&#25968;&#30340;&#20840;&#23616;&#20248;&#21270;&#20013;&#65292;&#26799;&#24230;&#30340;&#23454;&#29992;&#24615;&#12290;&#20026;&#27492;&#65292;&#20998;&#26512;&#20102;&#36890;&#36807;&#26799;&#24230;&#29983;&#25104;&#38750;&#23616;&#37096;&#20108;&#27425;&#36817;&#20284;&#25628;&#23547;&#26041;&#21521;&#30340;&#21407;&#21017;&#12290;&#23454;&#39564;&#27979;&#37327;&#20102;&#38750;&#23616;&#37096;&#25628;&#23547;&#26041;&#21521;&#30340;&#36136;&#37327;&#20197;&#21450;&#25552;&#20986;&#30340;&#31616;&#21270;&#31639;&#27861;&#12289;&#21327;&#26041;&#24046;&#30697;&#38453;&#36866;&#24212;&#36827;&#21270;&#31574;&#30053;(CMA-ES)&#21644;&#38543;&#26426;&#37325;&#26032;&#21021;&#22987;&#21270;&#30340;Broyden-Fletcher-Goldfarb-Shanno(BFGS)&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work demonstrates the utility of gradients for the global optimization of certain differentiable functions with many suboptimal local minima. To this end, a principle for generating search directions from non-local quadratic approximants based on gradients of the objective function is analyzed. Experiments measure the quality of non-local search directions as well as the performance of a proposed simplistic algorithm, of the covariance matrix adaptation evolution strategy (CMA-ES), and of a randomly reinitialized Broyden-Fletcher-Goldfarb-Shanno (BFGS) method.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#36895;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#20984;&#20960;&#20309;&#30340;&#25104;&#20687;&#36870;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#38543;&#26426;&#24347;&#32531;&#32437;&#22352;&#26631;&#36845;&#20195;&#23454;&#29616;&#65292;&#23545;&#20110;&#39640;&#26031;&#30446;&#26631;&#26159;&#28176;&#36817;&#26080;&#20559;&#30340;&#65292;&#24182;&#19988;&#23545;&#20110;$\kappa$-&#24378;&#23545;&#25968;&#20985;&#30340;&#20219;&#20309;&#30446;&#26631;&#37117;&#33021;&#20197;&#21152;&#36895;&#26041;&#24335;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2308.09460</link><description>&lt;p&gt;
&#21152;&#36895;&#36125;&#21494;&#26031;&#25104;&#20687;&#30340;&#24347;&#32531;&#32437;&#22352;&#26631;&#20848;&#27663;&#25277;&#26679;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Accelerated Bayesian imaging by relaxed proximal-point Langevin sampling. (arXiv:2308.09460v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09460
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#36895;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#20984;&#20960;&#20309;&#30340;&#25104;&#20687;&#36870;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#38543;&#26426;&#24347;&#32531;&#32437;&#22352;&#26631;&#36845;&#20195;&#23454;&#29616;&#65292;&#23545;&#20110;&#39640;&#26031;&#30446;&#26631;&#26159;&#28176;&#36817;&#26080;&#20559;&#30340;&#65292;&#24182;&#19988;&#23545;&#20110;$\kappa$-&#24378;&#23545;&#25968;&#20985;&#30340;&#20219;&#20309;&#30446;&#26631;&#37117;&#33021;&#20197;&#21152;&#36895;&#26041;&#24335;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21152;&#36895;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20855;&#26377;&#20984;&#20960;&#20309;&#30340;&#25104;&#20687;&#36870;&#38382;&#39064;&#20013;&#36827;&#34892;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;&#25152;&#25552;&#20986;&#30340;&#31574;&#30053;&#37319;&#29992;&#38543;&#26426;&#24347;&#32531;&#32437;&#22352;&#26631;&#36845;&#20195;&#30340;&#24418;&#24335;&#65292;&#20855;&#26377;&#20004;&#31181;&#20114;&#34917;&#30340;&#35299;&#37322;&#26041;&#24335;&#12290;&#23545;&#20110;&#36890;&#36807;Moreau-Yosida&#24179;&#28369;&#36827;&#34892;&#24179;&#28369;&#25110;&#27491;&#21017;&#21270;&#30340;&#27169;&#22411;&#65292;&#35813;&#31639;&#27861;&#31561;&#20215;&#20110;&#30446;&#26631;&#21518;&#39564;&#20998;&#24067;&#19978;&#30340;&#38544;&#24335;&#20013;&#28857;&#31163;&#25955;&#21270;&#36807;&#28857;&#20848;&#27663;&#25193;&#25955;&#65292;&#23545;&#20110;&#39640;&#26031;&#30446;&#26631;&#26159;&#28176;&#36817;&#26080;&#20559;&#30340;&#65292;&#24182;&#19988;&#23545;&#20110;$\kappa$-&#24378;&#23545;&#25968;&#20985;&#65288;&#21363;&#38656;&#35201;&#22823;&#32422;$\sqrt{\kappa}$&#27425;&#36845;&#20195;&#26469;&#25910;&#25947;&#65292;&#31867;&#20284;&#20110;&#21152;&#36895;&#20248;&#21270;&#26041;&#26696;&#65289;&#30340;&#20219;&#20309;&#30446;&#26631;&#37117;&#25910;&#25947;&#21152;&#36895;&#65292;&#19982;[M. Pereyra, L. Vargas Mieles, K.C. Zygalakis, SIAM J. Imaging Sciences, 13, 2 (2020), pp. 905-935]&#30456;&#27604;&#65292;&#22312;&#39640;&#26031;&#30446;&#26631;&#19978;&#21482;&#33021;&#35777;&#26126;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a new accelerated proximal Markov chain Monte Carlo methodology to perform Bayesian inference in imaging inverse problems with an underlying convex geometry. The proposed strategy takes the form of a stochastic relaxed proximal-point iteration that admits two complementary interpretations. For models that are smooth or regularised by Moreau-Yosida smoothing, the algorithm is equivalent to an implicit midpoint discretisation of an overdamped Langevin diffusion targeting the posterior distribution of interest. This discretisation is asymptotically unbiased for Gaussian targets and shown to converge in an accelerated manner for any target that is $\kappa$-strongly log-concave (i.e., requiring in the order of $\sqrt{\kappa}$ iterations to converge, similarly to accelerated optimisation schemes), comparing favorably to [M. Pereyra, L. Vargas Mieles, K.C. Zygalakis, SIAM J. Imaging Sciences, 13, 2 (2020), pp. 905-935] which is only provably accelerated for Gaussian target
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#40065;&#26834;&#24615;&#21644;&#31616;&#21333;&#24615;&#65292;&#21482;&#38656;&#35201;&#36827;&#34892;1&#27425;&#36845;&#20195;&#23398;&#20064;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#26356;&#22909;&#22320;&#22788;&#29702;&#25968;&#25454;&#19981;&#30830;&#23450;&#24615;&#21644;&#36870;&#38382;&#39064;&#65292;&#24182;&#19988;&#26377;&#28508;&#21147;&#26500;&#24314;&#33021;&#22815;&#21033;&#29992;&#20998;&#24067;&#38543;&#26426;&#25277;&#26679;&#36827;&#34892;&#38543;&#26426;&#21464;&#24322;&#21644;&#21464;&#24322;&#25511;&#21046;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2308.09444</link><description>&lt;p&gt;
&#19968;&#31181;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#39640;&#25928;&#19968;&#27425;&#36845;&#20195;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Efficient 1 Iteration Learning Algorithm for Gaussian Mixture Model And Gaussian Mixture Embedding For Neural Network. (arXiv:2308.09444v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09444
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#40065;&#26834;&#24615;&#21644;&#31616;&#21333;&#24615;&#65292;&#21482;&#38656;&#35201;&#36827;&#34892;1&#27425;&#36845;&#20195;&#23398;&#20064;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#26356;&#22909;&#22320;&#22788;&#29702;&#25968;&#25454;&#19981;&#30830;&#23450;&#24615;&#21644;&#36870;&#38382;&#39064;&#65292;&#24182;&#19988;&#26377;&#28508;&#21147;&#26500;&#24314;&#33021;&#22815;&#21033;&#29992;&#20998;&#24067;&#38543;&#26426;&#25277;&#26679;&#36827;&#34892;&#38543;&#26426;&#21464;&#24322;&#21644;&#21464;&#24322;&#25511;&#21046;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25105;&#20204;&#20043;&#21069;&#30340;GMM&#25193;&#23637;&#24605;&#24819;&#30340;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65288;GMM&#65289;&#23398;&#20064;&#31639;&#27861;&#12290;&#26032;&#31639;&#27861;&#27604;&#20256;&#32479;&#30340;&#26399;&#26395;&#26368;&#22823;&#21270;&#65288;EM&#65289;&#31639;&#27861;&#26356;&#20855;&#40065;&#26834;&#24615;&#21644;&#31616;&#21333;&#24615;&#12290;&#23427;&#36824;&#25552;&#39640;&#20102;&#20934;&#30830;&#24615;&#65292;&#24182;&#19988;&#21482;&#38656;&#35201;&#36827;&#34892;1&#27425;&#36845;&#20195;&#23398;&#20064;&#12290;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#36825;&#31181;&#26032;&#31639;&#27861;&#26080;&#35770;&#21442;&#25968;&#21021;&#22987;&#21270;&#22914;&#20309;&#37117;&#33021;&#20445;&#35777;&#25910;&#25947;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;GMM&#25193;&#23637;&#26041;&#27861;&#19982;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#32463;&#20856;&#27010;&#29575;&#23618;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#32467;&#26524;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#26356;&#22909;&#22320;&#20811;&#26381;&#25968;&#25454;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#36870;&#38382;&#39064;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#27979;&#35797;&#20102;&#22522;&#20110;GMM&#30340;&#29983;&#25104;&#22120;&#65292;&#26174;&#31034;&#20986;&#20102;&#36827;&#19968;&#27493;&#21033;&#29992;&#20998;&#24067;&#38543;&#26426;&#25277;&#26679;&#36827;&#34892;&#38543;&#26426;&#21464;&#24322;&#21644;&#21464;&#24322;&#25511;&#21046;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose an Gaussian Mixture Model (GMM) learning algorithm, based on our previous work of GMM expansion idea. The new algorithm brings more robustness and simplicity than classic Expectation Maximization (EM) algorithm. It also improves the accuracy and only take 1 iteration for learning. We theoretically proof that this new algorithm is guarantee to converge regardless the parameters initialisation. We compare our GMM expansion method with classic probability layers in neural network leads to demonstrably better capability to overcome data uncertainty and inverse problem. Finally, we test GMM based generator which shows a potential to build further application that able to utilized distribution random sampling for stochastic variation as well as variation control.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#30340;&#22122;&#22768;&#25935;&#24863;&#24615;&#21644;&#31283;&#23450;&#24615;&#65292;&#23545;&#38750;&#40065;&#26834;&#24615;&#29616;&#35937;&#36827;&#34892;&#20102;&#25506;&#32034;&#65292;&#24182;&#28548;&#28165;&#20102;&#36825;&#20123;&#27010;&#24565;&#30340;&#23450;&#20041;&#21644;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2308.09374</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#20108;&#20998;&#31867;&#20013;&#30340;&#22122;&#22768;&#25935;&#24863;&#24615;&#21644;&#31283;&#23450;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Noise Sensitivity and Stability of Deep Neural Networks for Binary Classification. (arXiv:2308.09374v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09374
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#30340;&#22122;&#22768;&#25935;&#24863;&#24615;&#21644;&#31283;&#23450;&#24615;&#65292;&#23545;&#38750;&#40065;&#26834;&#24615;&#29616;&#35937;&#36827;&#34892;&#20102;&#25506;&#32034;&#65292;&#24182;&#28548;&#28165;&#20102;&#36825;&#20123;&#27010;&#24565;&#30340;&#23450;&#20041;&#21644;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#24067;&#23572;&#20989;&#25968;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#23545;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#20998;&#31867;&#22120;&#30340;&#38750;&#40065;&#26834;&#24615;&#29616;&#35937;&#36827;&#34892;&#20102;&#21021;&#27493;&#25506;&#32034;&#12290;&#36890;&#36807;&#30740;&#31350;&#24120;&#35265;DNN&#27169;&#22411;&#34920;&#31034;&#30340;&#24067;&#23572;&#20989;&#25968;&#24207;&#21015;&#26159;&#21542;&#20855;&#26377;&#22122;&#22768;&#25935;&#24863;&#24615;&#25110;&#22122;&#22768;&#31283;&#23450;&#24615;&#65292;&#23545;&#36825;&#20123;&#27010;&#24565;&#36827;&#34892;&#20102;&#25512;&#24191;&#65292;&#24182;&#32771;&#34385;&#20102;&#36864;&#28779;&#21644;&#28140;&#28779;&#29256;&#26412;&#12290;&#26412;&#25991;&#28548;&#28165;&#20102;&#36825;&#20123;&#23450;&#20041;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#30740;&#31350;&#20102;&#20004;&#31181;&#24120;&#35265;DNN&#26550;&#26500;&#65292;&#21363;&#20840;&#36830;&#25509;&#21644;&#21367;&#31215;&#27169;&#22411;&#65292;&#22312;&#21021;&#22987;&#21270;&#26102;&#20351;&#29992;&#39640;&#26031;&#26435;&#37325;&#30340;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
A first step is taken towards understanding often observed non-robustness phenomena of deep neural net (DNN) classifiers. This is done from the perspective of Boolean functions by asking if certain sequences of Boolean functions represented by common DNN models are noise sensitive or noise stable, concepts defined in the Boolean function literature. Due to the natural randomness in DNN models, these concepts are extended to annealed and quenched versions. Here we sort out the relation between these definitions and investigate the properties of two standard DNN architectures, the fully connected and convolutional models, when initiated with Gaussian weights.
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#20013;&#19990;&#32426;&#25289;&#19969;&#35821;&#35789;&#20856;&#30340;&#23450;&#21046;&#25163;&#20889;&#25991;&#26412;&#35782;&#21035;&#31995;&#32479;&#65292;&#36890;&#36807;&#24341;&#20837;&#31471;&#21040;&#31471;&#30340;&#27969;&#27700;&#32447;&#21644;&#26368;&#26032;&#30340;&#22270;&#20687;&#20998;&#21106;&#27169;&#22411;&#65292;&#25104;&#21151;&#22320;&#23450;&#20301;&#12289;&#25552;&#21462;&#21644;&#36716;&#24405;&#24341;&#25991;&#65292;&#24182;&#19988;&#36890;&#36807;&#20351;&#29992;Transformer&#27169;&#22411;&#21644;&#25968;&#25454;&#22686;&#24378;&#31561;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#30340;&#23383;&#31526;&#38169;&#35823;&#29575;&#12290;</title><link>http://arxiv.org/abs/2308.09368</link><description>&lt;p&gt;
&#38024;&#23545;&#20013;&#19990;&#32426;&#25289;&#19969;&#35821;&#30340;&#23450;&#21046;&#25163;&#20889;&#25991;&#26412;&#35782;&#21035;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
A tailored Handwritten-Text-Recognition System for Medieval Latin. (arXiv:2308.09368v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09368
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#20013;&#19990;&#32426;&#25289;&#19969;&#35821;&#35789;&#20856;&#30340;&#23450;&#21046;&#25163;&#20889;&#25991;&#26412;&#35782;&#21035;&#31995;&#32479;&#65292;&#36890;&#36807;&#24341;&#20837;&#31471;&#21040;&#31471;&#30340;&#27969;&#27700;&#32447;&#21644;&#26368;&#26032;&#30340;&#22270;&#20687;&#20998;&#21106;&#27169;&#22411;&#65292;&#25104;&#21151;&#22320;&#23450;&#20301;&#12289;&#25552;&#21462;&#21644;&#36716;&#24405;&#24341;&#25991;&#65292;&#24182;&#19988;&#36890;&#36807;&#20351;&#29992;Transformer&#27169;&#22411;&#21644;&#25968;&#25454;&#22686;&#24378;&#31561;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#30340;&#23383;&#31526;&#38169;&#35823;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24052;&#20240;&#21033;&#20122;&#31185;&#23398;&#21644;&#20154;&#25991;&#23398;&#38498;&#26088;&#22312;&#25968;&#23383;&#21270;&#20854;&#20013;&#19990;&#32426;&#25289;&#19969;&#35821;&#35789;&#20856;&#12290;&#35813;&#35789;&#20856;&#21253;&#21547;&#20102;&#28041;&#21450;&#20013;&#19990;&#32426;&#25289;&#19969;&#35821;&#24341;&#25991;&#30340;&#35760;&#24405;&#21345;&#29255;, &#36825;&#26159;&#19968;&#31181;&#20302;&#36164;&#28304;&#35821;&#35328;&#12290;&#25968;&#23383;&#21270;&#36807;&#31243;&#30340;&#20851;&#38190;&#27493;&#39588;&#26159;&#35782;&#21035;&#36825;&#20123;&#35760;&#24405;&#21345;&#29255;&#19978;&#25163;&#20889;&#30340;&#24341;&#25991;&#30340;&#25163;&#20889;&#25991;&#26412;&#35782;&#21035;&#65288;HTR&#65289;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#31471;&#21040;&#31471;&#30340;&#27969;&#27700;&#32447;&#65292;&#19987;&#38376;&#38024;&#23545;&#20013;&#19990;&#32426;&#25289;&#19969;&#35821;&#35789;&#20856;&#36827;&#34892;&#23450;&#21046;&#65292;&#29992;&#20110;&#23450;&#20301;&#12289;&#25552;&#21462;&#21644;&#36716;&#24405;&#24341;&#25991;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#20004;&#20010;&#26368;&#20808;&#36827;&#30340;&#22270;&#20687;&#20998;&#21106;&#27169;&#22411;&#26469;&#20934;&#22791;HTR&#20219;&#21153;&#30340;&#21021;&#22987;&#25968;&#25454;&#38598;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23581;&#35797;&#20102;&#19981;&#21516;&#30340;&#22522;&#20110;Transformer&#30340;&#27169;&#22411;&#65292;&#24182;&#36827;&#34892;&#20102;&#19968;&#31995;&#21015;&#23454;&#39564;&#65292;&#25506;&#32034;&#20102;&#19981;&#21516;&#32452;&#21512;&#30340;&#35270;&#35273;&#32534;&#30721;&#22120;&#21644;GPT-2&#35299;&#30721;&#22120;&#30340;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24212;&#29992;&#20102;&#22823;&#37327;&#30340;&#25968;&#25454;&#22686;&#24378;&#65292;&#24471;&#21040;&#20102;&#19968;&#20010;&#31454;&#20105;&#21147;&#26497;&#39640;&#30340;&#27169;&#22411;&#12290;&#26368;&#20339;&#34920;&#29616;&#30340;&#37197;&#32622;&#23454;&#29616;&#20102;0.015&#30340;&#23383;&#31526;&#38169;&#35823;&#29575;&#65288;CER&#65289;&#65292;&#29978;&#33267;&#20248;&#20110;&#29616;&#26377;&#20844;&#35748;&#30340;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Bavarian Academy of Sciences and Humanities aims to digitize its Medieval Latin Dictionary. This dictionary entails record cards referring to lemmas in medieval Latin, a low-resource language. A crucial step of the digitization process is the Handwritten Text Recognition (HTR) of the handwritten lemmas found on these record cards. In our work, we introduce an end-to-end pipeline, tailored to the medieval Latin dictionary, for locating, extracting, and transcribing the lemmas. We employ two state-of-the-art (SOTA) image segmentation models to prepare the initial data set for the HTR task. Furthermore, we experiment with different transformer-based models and conduct a set of experiments to explore the capabilities of different combinations of vision encoders with a GPT-2 decoder. Additionally, we also apply extensive data augmentation resulting in a highly competitive model. The best-performing setup achieved a Character Error Rate (CER) of 0.015, which is even superior to the comme
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20197;&#30315;&#30187;&#39044;&#27979;&#20026;&#30446;&#26631;&#65292;&#36890;&#36807;&#33258;&#21160;&#21457;&#29616;&#21644;&#37327;&#21270;&#24739;&#32773;&#29305;&#23450;&#30340;&#32479;&#35745;&#29305;&#24449;&#65292;&#29305;&#21035;&#26159;&#26368;&#26032;&#30340;&#36335;&#24452;&#31614;&#21517;&#31639;&#27861;&#65292;&#25506;&#32034;&#20854;&#22312;&#30315;&#30187;&#39044;&#27979;&#20013;&#30340;&#24615;&#33021;&#65292;&#20026;&#20010;&#24615;&#21270;&#30340;&#30315;&#30187;&#39044;&#27979;&#35299;&#20915;&#26041;&#26696;&#25552;&#20379;&#20102;&#21442;&#32771;&#12290;</title><link>http://arxiv.org/abs/2308.09312</link><description>&lt;p&gt;
&#30315;&#30187;&#39044;&#27979;&#20013;&#30340;&#36335;&#24452;&#31614;&#21517;
&lt;/p&gt;
&lt;p&gt;
Path Signatures for Seizure Forecasting. (arXiv:2308.09312v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09312
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20197;&#30315;&#30187;&#39044;&#27979;&#20026;&#30446;&#26631;&#65292;&#36890;&#36807;&#33258;&#21160;&#21457;&#29616;&#21644;&#37327;&#21270;&#24739;&#32773;&#29305;&#23450;&#30340;&#32479;&#35745;&#29305;&#24449;&#65292;&#29305;&#21035;&#26159;&#26368;&#26032;&#30340;&#36335;&#24452;&#31614;&#21517;&#31639;&#27861;&#65292;&#25506;&#32034;&#20854;&#22312;&#30315;&#30187;&#39044;&#27979;&#20013;&#30340;&#24615;&#33021;&#65292;&#20026;&#20010;&#24615;&#21270;&#30340;&#30315;&#30187;&#39044;&#27979;&#35299;&#20915;&#26041;&#26696;&#25552;&#20379;&#20102;&#21442;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#27979;&#21040;&#30340;&#26102;&#38388;&#24207;&#21015;&#20013;&#39044;&#27979;&#31995;&#32479;&#29366;&#24577;&#26159;&#35768;&#22810;&#39046;&#22495;&#65288;&#22914;&#35745;&#31639;&#31070;&#32463;&#31185;&#23398;&#65289;&#30340;&#30740;&#31350;&#35838;&#39064;&#12290;&#22312;&#36825;&#37324;&#65292;&#20174;&#22823;&#33041;&#27979;&#37327;&#20013;&#39044;&#27979;&#30315;&#30187;&#21457;&#20316;&#26159;&#19968;&#20010;&#23578;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#26082;&#27809;&#26377;&#23436;&#25972;&#30340;&#25551;&#36848;&#24213;&#23618;&#22823;&#33041;&#21160;&#24577;&#30340;&#27169;&#22411;&#65292;&#20063;&#27809;&#26377;&#21333;&#20010;&#24739;&#32773;&#34920;&#29616;&#20986;&#21333;&#19968;&#30340;&#30315;&#30187;&#21457;&#20316;&#27169;&#24335;&#65292;&#36825;&#20351;&#24471;&#24320;&#21457;&#8220;&#19968;&#20992;&#20999;&#8221;&#30340;&#35299;&#20915;&#26041;&#26696;&#21464;&#24471;&#22797;&#26434;&#12290;&#22522;&#20110;&#32437;&#21521;&#24739;&#32773;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#33258;&#21160;&#21457;&#29616;&#21644;&#37327;&#21270;&#21487;&#29992;&#20110;&#20197;&#24739;&#32773;&#20026;&#20013;&#24515;&#30340;&#30315;&#30187;&#39044;&#27979;&#30340;&#32479;&#35745;&#29305;&#24449;&#65288;&#29983;&#29289;&#26631;&#24535;&#29289;&#65289;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#29616;&#26377;&#21644;&#26032;&#39062;&#30340;&#29305;&#24449;&#25552;&#21462;&#31639;&#27861;&#65292;&#23588;&#20854;&#26159;&#36335;&#24452;&#31614;&#21517;&#65292;&#21363;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#30340;&#26368;&#26032;&#21457;&#23637;&#12290;&#29305;&#21035;&#20540;&#24471;&#20851;&#27880;&#30340;&#26159;&#65292;&#19982;&#31616;&#21333;&#30340;&#32447;&#24615;&#29305;&#24449;&#30456;&#27604;&#65292;&#36825;&#32452;&#22797;&#26434;&#30340;&#38750;&#32447;&#24615;&#29305;&#24449;&#22312;&#36825;&#20010;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#22914;&#20309;&#12290;&#25105;&#20204;&#30340;&#25512;&#26029;&#22522;&#20110;&#32479;&#35745;&#20998;&#31867;&#31639;&#27861;&#65292;&#24182;&#24102;&#26377;&#20869;&#32622;&#30340;&#23376;&#38598;&#36873;&#25321;&#21151;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Forecasting the state of a system from an observed time series is the subject of research in many domains, such as computational neuroscience. Here, the prediction of epileptic seizures from brain measurements is an unresolved problem. There are neither complete models describing underlying brain dynamics, nor do individual patients exhibit a single seizure onset pattern, which complicates the development of a `one-size-fits-all' solution. Based on a longitudinal patient data set, we address the automated discovery and quantification of statistical features (biomarkers) that can be used to forecast seizures in a patient-specific way. We use existing and novel feature extraction algorithms, in particular the path signature, a recent development in time series analysis. Of particular interest is how this set of complex, nonlinear features performs compared to simpler, linear features on this task. Our inference is based on statistical classification algorithms with in-built subset select
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#20027;&#21160;&#21644;&#34987;&#21160;&#22240;&#26524;&#25512;&#26029;&#23398;&#20064;&#30340;&#37325;&#35201;&#20551;&#35774;&#21644;&#25216;&#26415;&#65292;&#24182;&#20197;&#35752;&#35770;&#22240;&#26524;&#25512;&#26029;&#30340;&#32570;&#22833;&#26041;&#38754;&#32467;&#26463;&#65292;&#20026;&#35835;&#32773;&#25552;&#20379;&#20102;&#19968;&#20010;&#22810;&#26679;&#24615;&#36215;&#28857;&#12290;</title><link>http://arxiv.org/abs/2308.09248</link><description>&lt;p&gt;
&#20027;&#21160;&#21644;&#34987;&#21160;&#22240;&#26524;&#25512;&#26029;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Active and Passive Causal Inference Learning. (arXiv:2308.09248v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09248
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#20027;&#21160;&#21644;&#34987;&#21160;&#22240;&#26524;&#25512;&#26029;&#23398;&#20064;&#30340;&#37325;&#35201;&#20551;&#35774;&#21644;&#25216;&#26415;&#65292;&#24182;&#20197;&#35752;&#35770;&#22240;&#26524;&#25512;&#26029;&#30340;&#32570;&#22833;&#26041;&#38754;&#32467;&#26463;&#65292;&#20026;&#35835;&#32773;&#25552;&#20379;&#20102;&#19968;&#20010;&#22810;&#26679;&#24615;&#36215;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#26159;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#20154;&#21592;&#12289;&#24037;&#31243;&#24072;&#21644;&#23398;&#29983;&#23545;&#22240;&#26524;&#25512;&#26029;&#24863;&#20852;&#36259;&#20294;&#23578;&#26410;&#29087;&#24713;&#30340;&#19968;&#20010;&#36215;&#28857;&#12290;&#25105;&#20204;&#39318;&#20808;&#21015;&#20030;&#20102;&#19968;&#32452;&#37325;&#35201;&#30340;&#29992;&#20110;&#22240;&#26524;&#35782;&#21035;&#30340;&#20551;&#35774;&#65292;&#22914;&#21487;&#20132;&#25442;&#24615;&#12289;&#31215;&#26497;&#24615;&#12289;&#19968;&#33268;&#24615;&#21644;&#24178;&#25200;&#30340;&#32570;&#22833;&#12290;&#22522;&#20110;&#36825;&#20123;&#20551;&#35774;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#22871;&#37325;&#35201;&#30340;&#22240;&#26524;&#25512;&#26029;&#25216;&#26415;&#65292;&#24182;&#23558;&#20854;&#20998;&#20026;&#20004;&#31867;&#65306;&#20027;&#21160;&#21644;&#34987;&#21160;&#26041;&#27861;&#12290;&#25105;&#20204;&#25551;&#36848;&#21644;&#35752;&#35770;&#20102;&#20027;&#21160;&#26041;&#27861;&#20013;&#30340;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#21644;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;&#28982;&#21518;&#25105;&#20204;&#25551;&#36848;&#20102;&#34987;&#21160;&#26041;&#27861;&#20013;&#30340;&#32463;&#20856;&#26041;&#27861;&#65292;&#22914;&#21305;&#37197;&#21644;&#36870;&#27010;&#29575;&#21152;&#26435;&#65292;&#20197;&#21450;&#26368;&#36817;&#30340;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#31639;&#27861;&#12290;&#36890;&#36807;&#20171;&#32461;&#26412;&#25991;&#20013;&#19968;&#20123;&#22240;&#26524;&#25512;&#26029;&#30340;&#32570;&#22833;&#26041;&#38754;&#65292;&#22914;&#30896;&#25758;&#20559;&#24046;&#65292;&#25105;&#20204;&#26399;&#26395;&#26412;&#25991;&#20026;&#35835;&#32773;&#25552;&#20379;&#20102;&#19968;&#20010;&#22810;&#26679;&#24615;&#36215;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper serves as a starting point for machine learning researchers, engineers and students who are interested in but not yet familiar with causal inference. We start by laying out an important set of assumptions that are collectively needed for causal identification, such as exchangeability, positivity, consistency and the absence of interference. From these assumptions, we build out a set of important causal inference techniques, which we do so by categorizing them into two buckets; active and passive approaches. We describe and discuss randomized controlled trials and bandit-based approaches from the active category. We then describe classical approaches, such as matching and inverse probability weighting, in the passive category, followed by more recent deep learning based algorithms. By finishing the paper with some of the missing aspects of causal inference from this paper, such as collider biases, we expect this paper to provide readers with a diverse set of starting points f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22270;&#19978;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#25910;&#25947;&#24615;&#12290;&#36890;&#36807;&#30740;&#31350;&#27431;&#20960;&#37324;&#24503;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#21644;Metropolis MCMC&#31639;&#27861;&#30340;&#25913;&#36827;&#29256;&#26412;&#22312;&#22270;&#19978;&#30340;&#34920;&#29616;&#65292;&#25105;&#20204;&#24471;&#20986;&#20102;&#38543;&#30528;&#22270;&#22823;&#23567;&#36235;&#36817;&#20110;&#26080;&#31351;&#22823;&#65292;&#38543;&#26426;&#36807;&#31243;&#30340;&#36712;&#36857;&#20250;&#25910;&#25947;&#21040;&#30830;&#23450;&#24615;&#26497;&#38480;&#30340;&#32467;&#35770;&#12290;&#36825;&#20123;&#26497;&#38480;&#26159;&#27979;&#24230;&#20540;&#22270;&#19978;&#30340;&#26354;&#32447;&#65292;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#24230;&#37327;&#65292;&#22312;&#36825;&#20010;&#31354;&#38388;&#20013;&#25552;&#20379;&#20102;&#33258;&#28982;&#30340;&#25910;&#25947;&#27010;&#24565;&#12290;</title><link>http://arxiv.org/abs/2308.09214</link><description>&lt;p&gt;
&#22823;&#22270;&#19978;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#36335;&#24452;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Path convergence of Markov chains on large graphs. (arXiv:2308.09214v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09214
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22270;&#19978;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#25910;&#25947;&#24615;&#12290;&#36890;&#36807;&#30740;&#31350;&#27431;&#20960;&#37324;&#24503;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#21644;Metropolis MCMC&#31639;&#27861;&#30340;&#25913;&#36827;&#29256;&#26412;&#22312;&#22270;&#19978;&#30340;&#34920;&#29616;&#65292;&#25105;&#20204;&#24471;&#20986;&#20102;&#38543;&#30528;&#22270;&#22823;&#23567;&#36235;&#36817;&#20110;&#26080;&#31351;&#22823;&#65292;&#38543;&#26426;&#36807;&#31243;&#30340;&#36712;&#36857;&#20250;&#25910;&#25947;&#21040;&#30830;&#23450;&#24615;&#26497;&#38480;&#30340;&#32467;&#35770;&#12290;&#36825;&#20123;&#26497;&#38480;&#26159;&#27979;&#24230;&#20540;&#22270;&#19978;&#30340;&#26354;&#32447;&#65292;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#24230;&#37327;&#65292;&#22312;&#36825;&#20010;&#31354;&#38388;&#20013;&#25552;&#20379;&#20102;&#33258;&#28982;&#30340;&#25910;&#25947;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#26377;&#38480;&#26080;&#26631;&#24230;&#22270;&#19978;&#30340;&#20004;&#31867;&#33258;&#28982;&#38543;&#26426;&#36807;&#31243;&#12290;&#36825;&#20123;&#36807;&#31243;&#21253;&#25324;&#22312;&#21152;&#26435;&#22270;&#30340;&#37051;&#25509;&#30697;&#38453;&#19978;&#30340;&#27431;&#20960;&#37324;&#24503;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#20197;&#21450;&#22312;&#26080;&#26435;&#22270;&#19978;&#30340;Metropolis MCMC&#31639;&#27861;&#30340;&#25913;&#36827;&#29256;&#26412;&#12290;&#22312;&#36825;&#20004;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#38543;&#30528;&#22270;&#30340;&#35268;&#27169;&#36235;&#36817;&#20110;&#26080;&#31351;&#22823;&#65292;&#38543;&#26426;&#36807;&#31243;&#30340;&#38543;&#26426;&#36712;&#36857;&#25910;&#25947;&#20110;&#30830;&#23450;&#24615;&#26497;&#38480;&#12290;&#36825;&#20123;&#30830;&#23450;&#24615;&#26497;&#38480;&#26159;&#27979;&#24230;&#20540;&#22270;&#19978;&#30340;&#26354;&#32447;&#12290;&#30001;Lov\'{a}sz&#21644;Szegedy&#24341;&#20837;&#30340;&#27979;&#24230;&#20540;&#22270;&#26159;&#22270;&#26500;&#26550;&#27010;&#24565;&#30340;&#32454;&#21270;&#65292;&#33021;&#22815;&#21306;&#20998;&#20351;&#24471;&#30456;&#21516;&#22270;&#26500;&#26550;&#26497;&#38480;&#30340;&#20004;&#20010;&#26080;&#31351;&#21487;&#20132;&#25442;&#25968;&#32452;&#12290;&#25105;&#20204;&#22312;&#36825;&#20010;&#31354;&#38388;&#19978;&#24341;&#20837;&#20102;&#26032;&#30340;&#24230;&#37327;&#65292;&#20026;&#25105;&#20204;&#30340;&#26497;&#38480;&#23450;&#29702;&#25552;&#20379;&#20102;&#33258;&#28982;&#30340;&#25910;&#25947;&#27010;&#24565;&#12290;&#36825;&#20010;&#27010;&#24565;&#31561;&#20215;&#20110;&#26080;&#31351;&#21487;&#20132;&#25442;&#25968;&#32452;&#30340;&#25910;&#25947;&#12290;&#22312;&#36866;&#24403;&#30340;&#26102;&#38388;&#32553;&#25918;&#19979;&#65292;Metropolis&#38142;&#20855;&#26377;&#25193;&#25955;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider two classes of natural stochastic processes on finite unlabeled graphs. These are Euclidean stochastic optimization algorithms on the adjacency matrix of weighted graphs and a modified version of the Metropolis MCMC algorithm on stochastic block models over unweighted graphs. In both cases we show that, as the size of the graph goes to infinity, the random trajectories of the stochastic processes converge to deterministic limits. These deterministic limits are curves on the space of measure-valued graphons. Measure-valued graphons, introduced by Lov\'{a}sz and Szegedy, are a refinement of the concept of graphons that can distinguish between two infinite exchangeable arrays that give rise to the same graphon limit. We introduce new metrics on this space which provide us with a natural notion of convergence for our limit theorems. This notion is equivalent to the convergence of infinite-exchangeable arrays. Under a suitable time-scaling, the Metropolis chain admits a diffusio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28857;&#36807;&#31243;&#36827;&#34892;&#23454;&#26102;&#25237;&#26631;&#65288;RTB&#65289;&#29983;&#24577;&#31995;&#32479;&#20013;&#37325;&#22797;&#25293;&#21334;&#24314;&#27169;&#30340;&#36890;&#29992;&#38543;&#26426;&#26694;&#26550;&#12290;&#35813;&#26694;&#26550;&#28789;&#27963;&#24615;&#39640;&#65292;&#21487;&#24212;&#29992;&#20110;&#21508;&#31181;&#25293;&#21334;&#22330;&#26223;&#65292;&#24182;&#25552;&#20986;&#20102;&#21487;&#23558;&#35813;&#36807;&#31243;&#36817;&#20284;&#20026;&#27850;&#26494;&#28857;&#36807;&#31243;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#32771;&#34385;&#25928;&#29992;&#21644;&#24066;&#22330;&#26465;&#20214;&#30340;&#32852;&#21512;&#20998;&#24067;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;</title><link>http://arxiv.org/abs/2308.09122</link><description>&lt;p&gt;
&#20351;&#29992;&#28857;&#36807;&#31243;&#30340;RTB&#24314;&#27169;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
RTB Formulation Using Point Process. (arXiv:2308.09122v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09122
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28857;&#36807;&#31243;&#36827;&#34892;&#23454;&#26102;&#25237;&#26631;&#65288;RTB&#65289;&#29983;&#24577;&#31995;&#32479;&#20013;&#37325;&#22797;&#25293;&#21334;&#24314;&#27169;&#30340;&#36890;&#29992;&#38543;&#26426;&#26694;&#26550;&#12290;&#35813;&#26694;&#26550;&#28789;&#27963;&#24615;&#39640;&#65292;&#21487;&#24212;&#29992;&#20110;&#21508;&#31181;&#25293;&#21334;&#22330;&#26223;&#65292;&#24182;&#25552;&#20986;&#20102;&#21487;&#23558;&#35813;&#36807;&#31243;&#36817;&#20284;&#20026;&#27850;&#26494;&#28857;&#36807;&#31243;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#32771;&#34385;&#25928;&#29992;&#21644;&#24066;&#22330;&#26465;&#20214;&#30340;&#32852;&#21512;&#20998;&#24067;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20351;&#29992;&#28857;&#36807;&#31243;&#36827;&#34892;&#24314;&#27169;&#30340;&#36890;&#29992;&#38543;&#26426;&#26694;&#26550;&#65292;&#29992;&#20110;&#27169;&#25311;&#23454;&#26102;&#25237;&#26631;&#65288;RTB&#65289;&#29983;&#24577;&#31995;&#32479;&#20013;&#30340;&#37325;&#22797;&#25293;&#21334;&#12290;&#35813;&#26694;&#26550;&#30340;&#28789;&#27963;&#24615;&#20351;&#24471;&#21487;&#20197;&#24212;&#29992;&#20110;&#21508;&#31181;&#25293;&#21334;&#22330;&#26223;&#65292;&#21253;&#25324;&#29609;&#23478;&#25552;&#20379;&#30340;&#20449;&#24687;&#37197;&#32622;&#12289;&#30830;&#23450;&#25293;&#21334;&#30340;&#33719;&#32988;&#32773;&#20197;&#21450;&#34913;&#37327;&#27599;&#20010;&#25293;&#21334;&#25152;&#33719;&#24471;&#30340;&#25928;&#29992;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20851;&#20110;&#22914;&#20309;&#23558;&#27492;&#36807;&#31243;&#30340;&#20844;&#24335;&#36817;&#20284;&#20026;&#27850;&#26494;&#28857;&#36807;&#31243;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#20174;&#32780;&#20351;&#20998;&#26512;&#32773;&#33021;&#22815;&#21033;&#29992;&#24050;&#24314;&#31435;&#30340;&#24615;&#36136;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#29609;&#23478;&#22312;&#19981;&#21516;&#22330;&#26223;&#19979;&#30340;&#26368;&#20248;&#31574;&#30053;&#12290;&#25105;&#20204;&#36824;&#24378;&#35843;&#20102;&#32771;&#34385;&#25928;&#29992;&#21644;&#24066;&#22330;&#26465;&#20214;&#30340;&#32852;&#21512;&#20998;&#24067;&#32780;&#19981;&#26159;&#29420;&#31435;&#20272;&#35745;&#36793;&#38469;&#20998;&#24067;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a general stochastic framework for modelling repeated auctions in the Real Time Bidding (RTB) ecosystem using point processes. The flexibility of the framework allows a variety of auction scenarios including configuration of information provided to player, determination of auction winner and quantification of utility gained from each auctions. We propose theoretical results on how this formulation of process can be approximated to a Poisson point process, which enables the analyzer to take advantage of well-established properties. Under this framework, we specify the player's optimal strategy under various scenarios. We also emphasize that it is critical to consider the joint distribution of utility and market condition instead of estimating the marginal distributions independently.
&lt;/p&gt;</description></item><item><title>&#22810;&#20445;&#30495;&#24230;&#20613;&#37324;&#21494;&#31070;&#32463;&#31639;&#23376;&#29992;&#20110;&#35299;&#20915;&#22823;&#35268;&#27169;&#22320;&#36136;&#30899;&#20648;&#23384;&#38382;&#39064;&#65292;&#36890;&#36807;&#21033;&#29992;&#32463;&#27982;&#24615;&#26356;&#39640;&#30340;&#22810;&#20445;&#30495;&#24230;&#35757;&#32451;&#25968;&#25454;&#38598;&#65292;&#33021;&#22815;&#20197;&#19982;&#39640;&#20445;&#30495;&#24230;&#27169;&#22411;&#30456;&#24403;&#30340;&#20934;&#30830;&#24615;&#36827;&#34892;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2308.09113</link><description>&lt;p&gt;
&#22810;&#20445;&#30495;&#24230;&#20613;&#37324;&#21494;&#31070;&#32463;&#31639;&#23376;&#29992;&#20110;&#24555;&#36895;&#24314;&#27169;&#22823;&#35268;&#27169;&#22320;&#36136;&#30899;&#20648;&#23384;
&lt;/p&gt;
&lt;p&gt;
Multi-fidelity Fourier Neural Operator for Fast Modeling of Large-Scale Geological Carbon Storage. (arXiv:2308.09113v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09113
&lt;/p&gt;
&lt;p&gt;
&#22810;&#20445;&#30495;&#24230;&#20613;&#37324;&#21494;&#31070;&#32463;&#31639;&#23376;&#29992;&#20110;&#35299;&#20915;&#22823;&#35268;&#27169;&#22320;&#36136;&#30899;&#20648;&#23384;&#38382;&#39064;&#65292;&#36890;&#36807;&#21033;&#29992;&#32463;&#27982;&#24615;&#26356;&#39640;&#30340;&#22810;&#20445;&#30495;&#24230;&#35757;&#32451;&#25968;&#25454;&#38598;&#65292;&#33021;&#22815;&#20197;&#19982;&#39640;&#20445;&#30495;&#24230;&#27169;&#22411;&#30456;&#24403;&#30340;&#20934;&#30830;&#24615;&#36827;&#34892;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#20195;&#29702;&#27169;&#22411;&#24050;&#24191;&#27867;&#24212;&#29992;&#20110;&#22320;&#36136;&#30899;&#20648;&#23384;&#65288;GCS&#65289;&#38382;&#39064;&#65292;&#20197;&#21152;&#24555;&#39044;&#27979;&#20648;&#21387;&#21644;&#20108;&#27687;&#21270;&#30899;&#20113;&#23618;&#31227;&#21160;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#39640;&#35745;&#31639;&#25104;&#26412;&#65292;&#22823;&#35268;&#27169;&#19977;&#32500;&#38382;&#39064;&#30340;&#21487;&#29992;&#35757;&#32451;&#25968;&#25454;&#22987;&#32456;&#26377;&#38480;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#22810;&#20445;&#30495;&#24230;&#20613;&#37324;&#21494;&#31070;&#32463;&#31639;&#23376;&#26469;&#35299;&#20915;&#22823;&#35268;&#27169;GCS&#38382;&#39064;&#65292;&#21033;&#29992;&#26356;&#20855;&#32463;&#27982;&#24615;&#30340;&#22810;&#20445;&#30495;&#24230;&#35757;&#32451;&#25968;&#25454;&#38598;&#12290;&#20613;&#37324;&#21494;&#31070;&#32463;&#31639;&#23376;&#20855;&#26377;&#33391;&#22909;&#30340;&#32593;&#26684;&#19981;&#21464;&#24615;&#65292;&#31616;&#21270;&#20102;&#19981;&#21516;&#31163;&#25955;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;&#36801;&#31227;&#23398;&#20064;&#36807;&#31243;&#12290;&#25105;&#20204;&#39318;&#20808;&#22312;&#19968;&#20010;GCS&#20648;&#23618;&#27169;&#22411;&#19978;&#36827;&#34892;&#27169;&#22411;&#26377;&#25928;&#24615;&#27979;&#35797;&#65292;&#35813;&#27169;&#22411;&#34987;&#21010;&#20998;&#20026;110,000&#20010;&#32593;&#26684;&#21333;&#20803;&#12290;&#22810;&#20445;&#30495;&#24230;&#27169;&#22411;&#30340;&#39044;&#27979;&#20934;&#30830;&#24230;&#21487;&#19982;&#39640;&#20445;&#30495;&#24230;&#27169;&#22411;&#30340;&#35757;&#32451;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning-based surrogate models have been widely applied in geological carbon storage (GCS) problems to accelerate the prediction of reservoir pressure and CO2 plume migration. Large amounts of data from physics-based numerical simulators are required to train a model to accurately predict the complex physical behaviors associated with this process. In practice, the available training data are always limited in large-scale 3D problems due to the high computational cost. Therefore, we propose to use a multi-fidelity Fourier Neural Operator to solve large-scale GCS problems with more affordable multi-fidelity training datasets. The Fourier Neural Operator has a desirable grid-invariant property, which simplifies the transfer learning procedure between datasets with different discretization. We first test the model efficacy on a GCS reservoir model being discretized into 110k grid cells. The multi-fidelity model can predict with accuracy comparable to a high-fidelity model trained wi
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#35889;&#20449;&#24687;&#20934;&#21017;&#65288;SIC&#65289;&#65292;&#21487;&#20197;&#20316;&#20026;&#33258;&#21160;&#32920;&#37096;&#26816;&#27979;&#22120;&#65292;&#25552;&#21462;&#20102;&#35823;&#24046;&#26354;&#32447;&#30340;&#20960;&#20309;&#29305;&#24449;&#65292;&#24182;&#32473;&#20986;&#20102;&#36873;&#25321;&#21807;&#19968;&#27169;&#22411;&#30340;&#23454;&#29992;&#35268;&#21017;&#12290;</title><link>http://arxiv.org/abs/2308.09108</link><description>&lt;p&gt;
&#33258;&#21160;&#32920;&#37096;&#26816;&#27979;&#30340;&#35889;&#20449;&#24687;&#20934;&#21017;
&lt;/p&gt;
&lt;p&gt;
Spectral information criterion for automatic elbow detection. (arXiv:2308.09108v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09108
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#35889;&#20449;&#24687;&#20934;&#21017;&#65288;SIC&#65289;&#65292;&#21487;&#20197;&#20316;&#20026;&#33258;&#21160;&#32920;&#37096;&#26816;&#27979;&#22120;&#65292;&#25552;&#21462;&#20102;&#35823;&#24046;&#26354;&#32447;&#30340;&#20960;&#20309;&#29305;&#24449;&#65292;&#24182;&#32473;&#20986;&#20102;&#36873;&#25321;&#21807;&#19968;&#27169;&#22411;&#30340;&#23454;&#29992;&#35268;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#24191;&#20041;&#30340;&#20449;&#24687;&#20934;&#21017;&#65292;&#20854;&#20013;&#21253;&#21547;&#20854;&#20182;&#20247;&#25152;&#21608;&#30693;&#30340;&#20449;&#24687;&#20934;&#21017;&#65292;&#22914;&#36125;&#21494;&#26031;&#20449;&#24687;&#20934;&#21017;&#65288;BIC&#65289;&#21644;&#36196;&#27744;&#20449;&#24687;&#20934;&#21017;&#65288;AIC&#65289;&#65292;&#20316;&#20026;&#29305;&#27530;&#24773;&#20917;&#12290;&#27492;&#22806;&#65292;&#25152;&#25552;&#20986;&#30340;&#35889;&#20449;&#24687;&#20934;&#21017;&#65288;SIC&#65289;&#20063;&#27604;&#20854;&#20182;&#20449;&#24687;&#20934;&#21017;&#26356;&#36890;&#29992;&#65292;&#20363;&#22914;&#65292;&#19981;&#20005;&#26684;&#35201;&#27714;&#20284;&#28982;&#20989;&#25968;&#30340;&#30693;&#35782;&#12290;SIC&#25552;&#21462;&#20102;&#35823;&#24046;&#26354;&#32447;&#30340;&#20960;&#20309;&#29305;&#24449;&#65292;&#22240;&#27492;&#21487;&#20197;&#34987;&#35270;&#20026;&#33258;&#21160;&#32920;&#37096;&#26816;&#27979;&#22120;&#12290;SIC&#25552;&#20379;&#20102;&#21487;&#33021;&#27169;&#22411;&#30340;&#23376;&#38598;&#65292;&#20854;&#22522;&#25968;&#36890;&#24120;&#36828;&#23567;&#20110;&#21487;&#33021;&#27169;&#22411;&#30340;&#24635;&#25968;&#12290;&#35813;&#23376;&#38598;&#30340;&#20803;&#32032;&#26159;&#35823;&#24046;&#26354;&#32447;&#30340;&#32920;&#37096;&#12290;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#32920;&#37096;&#38598;&#21512;&#20013;&#36873;&#25321;&#21807;&#19968;&#27169;&#22411;&#30340;&#23454;&#29992;&#35268;&#21017;&#12290;&#20998;&#26512;&#20102;SIC&#30340;&#29702;&#35770;&#19981;&#21464;&#24615;&#24615;&#36136;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;&#29702;&#24819;&#24773;&#20917;&#19979;&#27979;&#35797;&#20102;SIC&#65292;&#22312;&#36825;&#20123;&#24773;&#20917;&#19979;&#22987;&#32456;&#25552;&#20379;&#26368;&#20339;&#39044;&#26399;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#22312;&#20960;&#20010;&#25968;&#20540;&#23454;&#39564;&#20013;&#27979;&#35797;&#20102;SIC&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a generalized information criterion that contains other well-known information criteria, such as Bayesian information Criterion (BIC) and Akaike information criterion (AIC), as special cases. Furthermore, the proposed spectral information criterion (SIC) is also more general than the other information criteria, e.g., since the knowledge of a likelihood function is not strictly required. SIC extracts geometric features of the error curve and, as a consequence, it can be considered an automatic elbow detector. SIC provides a subset of all possible models, with a cardinality that often is much smaller than the total number of possible models. The elements of this subset are elbows of the error curve. A practical rule for selecting a unique model within the sets of elbows is suggested as well. Theoretical invariance properties of SIC are analyzed. Moreover, we test SIC in ideal scenarios where provides always the optimal expected results. We also test SIC in several numerical 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20013;&#20351;&#29992;Lasso&#21644;Horseshoe&#20004;&#31181;&#32553;&#20943;&#25216;&#26415;&#36827;&#34892;&#27169;&#22411;&#21387;&#32553;&#30340;&#26041;&#27861;&#12290;&#20026;&#20102;&#23454;&#29616;&#32467;&#26500;&#31232;&#30095;&#65292;&#36890;&#36807;&#25552;&#20986;&#23574;&#23792;&#19982;&#22359;&#32452;&#31232;&#30095;Lasso&#21644;&#23574;&#23792;&#19982;&#22359;&#32452;Horseshoe&#20808;&#39564;&#65292;&#24182;&#24320;&#21457;&#20102;&#21487;&#35745;&#31639;&#30340;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#20445;&#25345;&#25512;&#29702;&#25928;&#29575;&#30340;&#21516;&#26102;&#23454;&#29616;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27169;&#22411;&#21387;&#32553;&#12290;</title><link>http://arxiv.org/abs/2308.09104</link><description>&lt;p&gt;
&#22522;&#20110;&#23574;&#23792;&#19982;&#22359;&#32553;&#20943;&#20808;&#39564;&#30340;&#32467;&#26500;&#31232;&#30095;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#20840;&#38754;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A comprehensive study of spike and slab shrinkage priors for structurally sparse Bayesian neural networks. (arXiv:2308.09104v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09104
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20013;&#20351;&#29992;Lasso&#21644;Horseshoe&#20004;&#31181;&#32553;&#20943;&#25216;&#26415;&#36827;&#34892;&#27169;&#22411;&#21387;&#32553;&#30340;&#26041;&#27861;&#12290;&#20026;&#20102;&#23454;&#29616;&#32467;&#26500;&#31232;&#30095;&#65292;&#36890;&#36807;&#25552;&#20986;&#23574;&#23792;&#19982;&#22359;&#32452;&#31232;&#30095;Lasso&#21644;&#23574;&#23792;&#19982;&#22359;&#32452;Horseshoe&#20808;&#39564;&#65292;&#24182;&#24320;&#21457;&#20102;&#21487;&#35745;&#31639;&#30340;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#20445;&#25345;&#25512;&#29702;&#25928;&#29575;&#30340;&#21516;&#26102;&#23454;&#29616;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27169;&#22411;&#21387;&#32553;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#22797;&#26434;&#24230;&#21644;&#35745;&#31639;&#25928;&#29575;&#24050;&#32463;&#25104;&#20026;&#28145;&#24230;&#23398;&#20064;&#20013;&#36234;&#26469;&#36234;&#37325;&#35201;&#30340;&#26041;&#38754;&#12290;&#31232;&#30095;&#28145;&#24230;&#23398;&#20064;&#36890;&#36807;&#20943;&#23569;&#36807;&#21442;&#25968;&#21270;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26469;&#24674;&#22797;&#24213;&#23618;&#30446;&#26631;&#20989;&#25968;&#30340;&#31232;&#30095;&#34920;&#31034;&#65292;&#35299;&#20915;&#20102;&#36825;&#20123;&#25361;&#25112;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#36890;&#36807;&#32467;&#26500;&#31232;&#30095;&#65288;&#22914;&#33410;&#28857;&#31232;&#30095;&#65289;&#21387;&#32553;&#30340;&#28145;&#24230;&#31070;&#32463;&#26550;&#26500;&#25552;&#20379;&#20102;&#20302;&#24310;&#36831;&#25512;&#29702;&#12289;&#26356;&#39640;&#30340;&#25968;&#25454;&#21534;&#21520;&#37327;&#21644;&#26356;&#20302;&#30340;&#33021;&#37327;&#28040;&#32791;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#31181;&#24191;&#27867;&#24212;&#29992;&#30340;&#32553;&#20943;&#25216;&#26415;&#65292;Lasso&#21644;Horseshoe&#65292;&#22312;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20013;&#36827;&#34892;&#27169;&#22411;&#21387;&#32553;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#23574;&#23792;&#19982;&#22359;&#32452;&#31232;&#30095;Lasso (SS-GL)&#21644;&#22522;&#20110;&#23574;&#23792;&#19982;&#22359;&#32452;Horseshoe (SS-GHS)&#20808;&#39564;&#30340;&#32467;&#26500;&#31232;&#30095;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#24320;&#21457;&#20102;&#21487;&#35745;&#31639;&#30340;&#21464;&#20998;&#25512;&#26029;&#65292;&#21253;&#25324;&#23545;&#20271;&#21162;&#21033;&#21464;&#37327;&#30340;&#36830;&#32493;&#26494;&#24347;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#21464;&#20998;&#25512;&#26029;&#30340;&#25910;&#32553;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Network complexity and computational efficiency have become increasingly significant aspects of deep learning. Sparse deep learning addresses these challenges by recovering a sparse representation of the underlying target function by reducing heavily over-parameterized deep neural networks. Specifically, deep neural architectures compressed via structured sparsity (e.g. node sparsity) provide low latency inference, higher data throughput, and reduced energy consumption. In this paper, we explore two well-established shrinkage techniques, Lasso and Horseshoe, for model compression in Bayesian neural networks. To this end, we propose structurally sparse Bayesian neural networks which systematically prune excessive nodes with (i) Spike-and-Slab Group Lasso (SS-GL), and (ii) Spike-and-Slab Group Horseshoe (SS-GHS) priors, and develop computationally tractable variational inference including continuous relaxation of Bernoulli variables. We establish the contraction rates of the variational 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#21407;&#22987;&#26041;&#27861;&#26469;&#35299;&#20915;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#26465;&#20214;&#37319;&#26679;&#20013;&#30340;&#22256;&#38590;&#65292;&#24182;&#22312;&#37319;&#26679;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#25913;&#36827;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.09078</link><description>&lt;p&gt;
&#36890;&#36807;&#36845;&#20195;&#36817;&#20284;&#31062;&#20808;&#37319;&#26679;&#23454;&#29616;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#26465;&#20214;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Conditional Sampling of Variational Autoencoders via Iterated Approximate Ancestral Sampling. (arXiv:2308.09078v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09078
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#21407;&#22987;&#26041;&#27861;&#26469;&#35299;&#20915;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#26465;&#20214;&#37319;&#26679;&#20013;&#30340;&#22256;&#38590;&#65292;&#24182;&#22312;&#37319;&#26679;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#25913;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#65292;&#22914;&#32570;&#22833;&#25968;&#25454;&#22635;&#20805;&#65292;&#38656;&#35201;&#23545;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#36827;&#34892;&#26465;&#20214;&#37319;&#26679;&#65292;&#20294;&#36825;&#26159;&#35745;&#31639;&#19978;&#19981;&#21487;&#34892;&#30340;&#12290;&#28176;&#36817;&#31934;&#30830;&#26465;&#20214;&#37319;&#26679;&#30340;&#21407;&#21017;&#36873;&#25321;&#26159;Metropolis-within-Gibbs&#65288;MWG&#65289;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;VAE&#20542;&#21521;&#20110;&#23398;&#20064;&#32467;&#26500;&#21270;&#28508;&#21464;&#37327;&#31354;&#38388;&#65292;&#36825;&#26159;&#19968;&#20010;&#24120;&#35265;&#30340;&#26399;&#26395;&#29305;&#24615;&#65292;&#20294;&#21364;&#23548;&#33268;MWG&#37319;&#26679;&#22120;&#36828;&#31163;&#30446;&#26631;&#20998;&#24067;&#12290;&#26412;&#25991;&#20811;&#26381;&#20102;MWG&#30340;&#23616;&#38480;&#24615;&#65306;&#25105;&#20204;&#31995;&#32479;&#22320;&#27010;&#36848;&#20102;&#22312;VAE&#19978;&#19978;&#36848;&#23616;&#38480;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#21407;&#22987;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#22312;&#19968;&#32452;&#37319;&#26679;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#25913;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conditional sampling of variational autoencoders (VAEs) is needed in various applications, such as missing data imputation, but is computationally intractable. A principled choice for asymptotically exact conditional sampling is Metropolis-within-Gibbs (MWG). However, we observe that the tendency of VAEs to learn a structured latent space, a commonly desired property, can cause the MWG sampler to get "stuck" far from the target distribution. This paper mitigates the limitations of MWG: we systematically outline the pitfalls in the context of VAEs, propose two original methods that address these pitfalls, and demonstrate an improved performance of the proposed methods on a set of sampling tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22238;&#24402;&#20219;&#21153;&#30340;&#24191;&#20041;AuxUE&#26041;&#26696;&#65292;&#30446;&#30340;&#26159;&#23454;&#29616;&#26356;&#40065;&#26834;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35813;&#26041;&#26696;&#36890;&#36807;&#32771;&#34385;&#19981;&#21516;&#30340;&#20998;&#24067;&#20551;&#35774;&#65292;&#36873;&#25321;Laplace&#20998;&#24067;&#26469;&#36817;&#20284;p&#65292;&#20197;&#23454;&#29616;&#26356;&#40065;&#26834;&#30340;&#26412;&#36136;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2308.09065</link><description>&lt;p&gt;
&#36890;&#36807;&#31163;&#25955;&#21270;&#24341;&#21457;&#30340;Dirichlet&#21518;&#39564;&#29992;&#20110;&#22238;&#24402;&#38382;&#39064;&#30340;&#40065;&#26834;&#24615;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Discretization-Induced Dirichlet Posterior for Robust Uncertainty Quantification on Regression. (arXiv:2308.09065v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09065
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22238;&#24402;&#20219;&#21153;&#30340;&#24191;&#20041;AuxUE&#26041;&#26696;&#65292;&#30446;&#30340;&#26159;&#23454;&#29616;&#26356;&#40065;&#26834;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35813;&#26041;&#26696;&#36890;&#36807;&#32771;&#34385;&#19981;&#21516;&#30340;&#20998;&#24067;&#20551;&#35774;&#65292;&#36873;&#25321;Laplace&#20998;&#24067;&#26469;&#36817;&#20284;p&#65292;&#20197;&#23454;&#29616;&#26356;&#40065;&#26834;&#30340;&#26412;&#36136;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#23545;&#20110;&#37096;&#32626;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#33267;&#20851;&#37325;&#35201;&#12290;&#36741;&#21161;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#22120;&#65288;AuxUE&#65289;&#26159;&#19968;&#31181;&#22312;&#19981;&#20462;&#25913;&#20027;&#20219;&#21153;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#20027;&#20219;&#21153;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#26368;&#26377;&#25928;&#25163;&#27573;&#20043;&#19968;&#12290;&#20026;&#20102;&#34987;&#35748;&#20026;&#26159;&#40065;&#26834;&#30340;&#65292;AuxUE&#24517;&#39035;&#33021;&#22815;&#22312;&#36935;&#21040;&#36229;&#20986;&#20998;&#24067;&#33539;&#22260;&#30340;&#36755;&#20837;&#26102;&#20445;&#25345;&#24615;&#33021;&#24182;&#24341;&#21457;&#26356;&#39640;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#21363;&#25552;&#20379;&#40065;&#26834;&#30340;&#26412;&#36136;&#19981;&#30830;&#23450;&#24615;&#21644;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#35270;&#35273;&#22238;&#24402;&#20219;&#21153;&#65292;&#24403;&#21069;&#30340;AuxUE&#35774;&#35745;&#20027;&#35201;&#29992;&#20110;&#26412;&#36136;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#24182;&#19988;&#23578;&#26410;&#25506;&#32034;AuxUE&#30340;&#40065;&#26834;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22238;&#24402;&#20219;&#21153;&#30340;&#26356;&#40065;&#26834;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#24191;&#20041;AuxUE&#26041;&#26696;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#20026;&#20102;&#23454;&#29616;&#26356;&#40065;&#26834;&#30340;&#26412;&#36136;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#22312;&#24322;&#26041;&#24046;&#22122;&#22768;&#26041;&#38754;&#32771;&#34385;&#20102;&#19981;&#21516;&#30340;&#20998;&#24067;&#20551;&#35774;&#65292;&#24182;&#26368;&#32456;&#36873;&#25321;Laplace&#20998;&#24067;&#26469;&#36817;&#20284;p
&lt;/p&gt;
&lt;p&gt;
Uncertainty quantification is critical for deploying deep neural networks (DNNs) in real-world applications. An Auxiliary Uncertainty Estimator (AuxUE) is one of the most effective means to estimate the uncertainty of the main task prediction without modifying the main task model. To be considered robust, an AuxUE must be capable of maintaining its performance and triggering higher uncertainties while encountering Out-of-Distribution (OOD) inputs, i.e., to provide robust aleatoric and epistemic uncertainty. However, for vision regression tasks, current AuxUE designs are mainly adopted for aleatoric uncertainty estimates, and AuxUE robustness has not been explored. In this work, we propose a generalized AuxUE scheme for more robust uncertainty quantification on regression tasks. Concretely, to achieve a more robust aleatoric uncertainty estimation, different distribution assumptions are considered for heteroscedastic noise, and Laplace distribution is finally chosen to approximate the p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#26080;&#20284;&#28982;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#23545;&#24050;&#30693;&#23646;&#20110;&#20004;&#20010;&#31867;&#21035;&#30340;&#36755;&#20837;&#36827;&#34892;&#20998;&#31867;&#30340;&#38382;&#39064;&#65292;&#22312;&#26080;&#20284;&#28982;&#25512;&#26029;&#39046;&#22495;&#65292;&#36890;&#36807;&#23558;&#26631;&#35760;&#26679;&#26412;&#36890;&#36807;&#27491;&#21521;&#27169;&#25311;&#33719;&#24471;&#65292;&#26410;&#26631;&#35760;&#26679;&#26412;&#36890;&#36807;&#23454;&#39564;&#25910;&#38598;&#65292;&#32473;&#20986;&#20102;&#19968;&#20010;&#26435;&#34913;m&#21644;n&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.09043</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;&#30340;&#26080;&#20284;&#28982;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Kernel-Based Tests for Likelihood-Free Hypothesis Testing. (arXiv:2308.09043v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09043
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#26080;&#20284;&#28982;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#23545;&#24050;&#30693;&#23646;&#20110;&#20004;&#20010;&#31867;&#21035;&#30340;&#36755;&#20837;&#36827;&#34892;&#20998;&#31867;&#30340;&#38382;&#39064;&#65292;&#22312;&#26080;&#20284;&#28982;&#25512;&#26029;&#39046;&#22495;&#65292;&#36890;&#36807;&#23558;&#26631;&#35760;&#26679;&#26412;&#36890;&#36807;&#27491;&#21521;&#27169;&#25311;&#33719;&#24471;&#65292;&#26410;&#26631;&#35760;&#26679;&#26412;&#36890;&#36807;&#23454;&#39564;&#25910;&#38598;&#65292;&#32473;&#20986;&#20102;&#19968;&#20010;&#26435;&#34913;m&#21644;n&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#20004;&#20010;&#24179;&#34913;&#31867;&#21035;&#30340;n&#20010;&#35266;&#27979;&#20013;&#65292;&#32771;&#34385;&#23545;&#39069;&#22806;m&#20010;&#24050;&#30693;&#23646;&#20110;&#20854;&#20013;&#19968;&#20010;&#31867;&#21035;&#30340;&#36755;&#20837;&#36827;&#34892;&#20998;&#31867;&#30340;&#20219;&#21153;&#12290;&#35813;&#38382;&#39064;&#30340;&#29305;&#27530;&#24773;&#20917;&#24050;&#32463;&#34987;&#24191;&#27867;&#30740;&#31350;&#65306;&#24403;&#23436;&#20840;&#20102;&#35299;&#31867;&#21035;&#20998;&#24067;&#26102;&#65288;n=&#8734;&#65289;&#65292;&#26368;&#20248;&#35299;&#26159;&#20351;&#29992;&#20284;&#28982;&#27604;&#26816;&#39564;&#65307;&#24403;m=1&#26102;&#65292;&#23545;&#24212;&#20108;&#20998;&#31867;&#38382;&#39064;&#65307;&#24403;m&#8776;n&#26102;&#65292;&#31561;&#21516;&#20110;&#20004;&#26679;&#26412;&#26816;&#39564;&#12290;&#20013;&#38388;&#30340;&#24773;&#20917;&#20986;&#29616;&#22312;&#26080;&#20284;&#28982;&#25512;&#26029;&#39046;&#22495;&#65292;&#20854;&#20013;&#26631;&#35760;&#26679;&#26412;&#36890;&#36807;&#36816;&#34892;&#27491;&#21521;&#27169;&#25311;&#33719;&#24471;&#65292;&#32780;&#26410;&#26631;&#35760;&#26679;&#26412;&#36890;&#36807;&#23454;&#39564;&#25910;&#38598;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;m&#21644;n&#20043;&#38388;&#23384;&#22312;&#26681;&#26412;&#24615;&#30340;&#26435;&#34913;&#65306;&#22686;&#21152;&#25968;&#25454;&#26679;&#26412;m&#20250;&#20943;&#23569;&#25152;&#38656;&#30340;&#35757;&#32451;/&#27169;&#25311;&#25968;&#25454;&#37327;n&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#65288;a&#65289;&#24341;&#20837;&#20102;&#19968;&#20010;&#24120;&#24120;&#36935;&#21040;&#30340;&#24773;&#20917;&#65292;&#21363;&#26410;&#26631;&#35760;&#26679;&#26412;&#26469;&#33258;&#20004;&#20010;&#31867;&#21035;&#30340;&#28151;&#21512;&#29289;&#65307;&#65288;b&#65289;&#30740;&#31350;&#20102;&#26368;&#23567;&#21270;&#39118;&#38505;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#39118;&#38505;&#23450;&#20041;&#20026;&#35823;&#20998;&#31867;&#27010;&#29575;&#30340;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given $n$ observations from two balanced classes, consider the task of labeling an additional $m$ inputs that are known to all belong to \emph{one} of the two classes. Special cases of this problem are well-known: with complete knowledge of class distributions ($n=\infty$) the problem is solved optimally by the likelihood-ratio test; when $m=1$ it corresponds to binary classification; and when $m\approx n$ it is equivalent to two-sample testing. The intermediate settings occur in the field of likelihood-free inference, where labeled samples are obtained by running forward simulations and the unlabeled sample is collected experimentally. In recent work it was discovered that there is a fundamental trade-off between $m$ and $n$: increasing the data sample $m$ reduces the amount $n$ of training/simulation data needed. In this work we (a) introduce a generalization where unlabeled samples come from a mixture of the two classes -- a case often encountered in practice; (b) study the minimax 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24212;&#29992;&#20110;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#21644;&#22810;&#32034;&#24341;&#27169;&#22411;&#20013;&#30340;&#27969;&#24335;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#23398;&#20064;&#21160;&#21147;&#23398;&#12290;&#36890;&#36807;&#24314;&#31435;&#20102;&#19968;&#20010;&#26222;&#36890;&#24494;&#20998;&#26041;&#31243;&#31995;&#32479;&#26469;&#25551;&#36848;&#39118;&#38505;&#21644;&#27425;&#20248;&#24615;&#24230;&#37327;&#31561;&#32479;&#35745;&#37327;&#65292;&#33719;&#24471;&#20102;&#31283;&#23450;&#24615;&#23398;&#20064;&#29575;&#38408;&#20540;&#21644;&#25910;&#25947;&#20445;&#35777;&#12290;&#21516;&#26102;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;&#31616;&#21270;&#25193;&#25955;&#31995;&#25968;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#27169;&#22411;&#65292;&#29992;&#20110;&#20998;&#26512;SGD&#36845;&#20195;&#30340;&#32479;&#35745;&#21160;&#21147;&#23398;&#12290;&#36890;&#36807;&#26631;&#20934;&#31034;&#20363;&#21644;&#25968;&#20540;&#27169;&#25311;&#65292;&#39564;&#35777;&#20102;&#35813;&#29702;&#35770;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.08977</link><description>&lt;p&gt;
&#25171;&#30772;&#39640;&#32500;&#38899;&#31526;&#65306;&#20851;&#20110;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#21644;&#22810;&#32034;&#24341;&#27169;&#22411;&#19978; SGD &#23398;&#20064;&#21160;&#21147;&#23398;&#30340; ODE &#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Hitting the High-Dimensional Notes: An ODE for SGD learning dynamics on GLMs and multi-index models. (arXiv:2308.08977v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08977
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24212;&#29992;&#20110;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#21644;&#22810;&#32034;&#24341;&#27169;&#22411;&#20013;&#30340;&#27969;&#24335;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#23398;&#20064;&#21160;&#21147;&#23398;&#12290;&#36890;&#36807;&#24314;&#31435;&#20102;&#19968;&#20010;&#26222;&#36890;&#24494;&#20998;&#26041;&#31243;&#31995;&#32479;&#26469;&#25551;&#36848;&#39118;&#38505;&#21644;&#27425;&#20248;&#24615;&#24230;&#37327;&#31561;&#32479;&#35745;&#37327;&#65292;&#33719;&#24471;&#20102;&#31283;&#23450;&#24615;&#23398;&#20064;&#29575;&#38408;&#20540;&#21644;&#25910;&#25947;&#20445;&#35777;&#12290;&#21516;&#26102;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;&#31616;&#21270;&#25193;&#25955;&#31995;&#25968;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#27169;&#22411;&#65292;&#29992;&#20110;&#20998;&#26512;SGD&#36845;&#20195;&#30340;&#32479;&#35745;&#21160;&#21147;&#23398;&#12290;&#36890;&#36807;&#26631;&#20934;&#31034;&#20363;&#21644;&#25968;&#20540;&#27169;&#25311;&#65292;&#39564;&#35777;&#20102;&#35813;&#29702;&#35770;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#22312;&#24212;&#29992;&#20110;&#20855;&#26377;&#19968;&#33324;&#25968;&#25454;&#21327;&#26041;&#24046;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#21644;&#22810;&#32034;&#24341;&#27169;&#22411;&#65288;&#20363;&#22914;&#36923;&#36753;&#22238;&#24402;&#12289;&#30456;&#20301;&#24674;&#22797;&#65289;&#26102;&#65292;&#27969;&#24335;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#22312;&#39640;&#32500;&#38480;&#21046;&#19979;&#30340;&#21160;&#21147;&#23398;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102; SGD &#30340;&#30830;&#23450;&#24615;&#31561;&#25928;&#24418;&#24335;&#65292;&#21363;&#19968;&#32452;&#25551;&#36848;&#39118;&#38505;&#21644;&#20854;&#20182;&#27425;&#20248;&#24615;&#24230;&#37327;&#30340;&#26222;&#36890;&#24494;&#20998;&#26041;&#31243;&#31995;&#32479;&#12290;&#24403;&#27169;&#22411;&#21442;&#25968;&#25968;&#37327;&#19982;&#25968;&#25454;&#25968;&#37327;&#25104;&#27491;&#27604;&#22686;&#38271;&#26102;&#65292;&#35813;&#31561;&#25928;&#24615;&#20197;&#26497;&#22823;&#27010;&#29575;&#21457;&#29983;&#12290;&#35813;&#26694;&#26550;&#20351;&#25105;&#20204;&#33021;&#22815;&#33719;&#24471; SGD &#31283;&#23450;&#24615;&#30340;&#23398;&#20064;&#29575;&#38408;&#20540;&#20197;&#21450;&#25910;&#25947;&#20445;&#35777;&#12290;&#38500;&#20102;&#30830;&#23450;&#24615;&#31561;&#25928;&#24615;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20855;&#26377;&#31616;&#21270;&#25193;&#25955;&#31995;&#25968;&#30340; SDE&#65288;&#22343;&#21248;&#21270; SGD&#65289;&#65292;&#23427;&#20351;&#25105;&#20204;&#33021;&#22815;&#20998;&#26512; SGD &#36845;&#20195;&#30340;&#24120;&#35268;&#32479;&#35745;&#21160;&#21147;&#23398;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22312;&#19968;&#20123;&#26631;&#20934;&#31034;&#20363;&#19978;&#28436;&#31034;&#20102;&#35813;&#29702;&#35770;&#65292;&#24182;&#23637;&#31034;&#20102;&#25968;&#20540;&#27169;&#25311;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyze the dynamics of streaming stochastic gradient descent (SGD) in the high-dimensional limit when applied to generalized linear models and multi-index models (e.g. logistic regression, phase retrieval) with general data-covariance. In particular, we demonstrate a deterministic equivalent of SGD in the form of a system of ordinary differential equations that describes a wide class of statistics, such as the risk and other measures of sub-optimality. This equivalence holds with overwhelming probability when the model parameter count grows proportionally to the number of data. This framework allows us to obtain learning rate thresholds for stability of SGD as well as convergence guarantees. In addition to the deterministic equivalent, we introduce an SDE with a simplified diffusion coefficient (homogenized SGD) which allows us to analyze the dynamics of general statistics of SGD iterates. Finally, we illustrate this theory on some standard examples and show numerical simulations w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#33258;&#30001;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#38646;&#21644;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#20013;&#23454;&#29616;&#19982;&#27169;&#22411;&#20026;&#22522;&#30784;&#31639;&#27861;&#30456;&#21516;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#39318;&#27425;&#35777;&#26126;&#20102;&#27169;&#22411;&#33258;&#30001;&#31639;&#27861;&#21487;&#20197;&#22312;&#26102;&#38388;&#27573;&#20381;&#36182;&#24615;&#26041;&#38754;&#36798;&#21040;&#21516;&#26679;&#30340;&#20248;&#21270;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.08858</link><description>&lt;p&gt;
&#27809;&#26377;&#27169;&#22411;&#30340;&#31639;&#27861;&#22312;&#38646;&#21644;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#20013;&#25552;&#39640;&#20102;&#26679;&#26412;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;
Model-Free Algorithm with Improved Sample Efficiency for Zero-Sum Markov Games. (arXiv:2308.08858v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08858
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#33258;&#30001;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#38646;&#21644;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#20013;&#23454;&#29616;&#19982;&#27169;&#22411;&#20026;&#22522;&#30784;&#31639;&#27861;&#30456;&#21516;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#39318;&#27425;&#35777;&#26126;&#20102;&#27169;&#22411;&#33258;&#30001;&#31639;&#27861;&#21487;&#20197;&#22312;&#26102;&#38388;&#27573;&#20381;&#36182;&#24615;&#26041;&#38754;&#36798;&#21040;&#21516;&#26679;&#30340;&#20248;&#21270;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#20004;&#20154;&#38646;&#21644;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#38382;&#39064;&#22312;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#30340;&#29702;&#35770;&#30740;&#31350;&#20013;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20852;&#36259;&#12290;&#29305;&#21035;&#26159;&#23545;&#20110;&#26377;&#38480;&#26102;&#38388;&#27573;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65292;&#24050;&#32463;&#35777;&#26126;&#20102;&#27169;&#22411;&#20026;&#22522;&#30784;&#30340;&#31639;&#27861;&#21487;&#20197;&#36890;&#36807;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$O(H^3SAB/\epsilon^2)$&#25214;&#21040;$\epsilon$-&#26368;&#20248;&#30340;&#32435;&#20160;&#22343;&#34913;&#65288;NE&#65289;&#65292;&#20854;&#20013;$H$&#26159;&#26102;&#38388;&#27573;&#65292;$S$&#26159;&#29366;&#24577;&#25968;&#37327;&#65288;$A$&#21644;$B$&#20998;&#21035;&#34920;&#31034;&#20004;&#20010;&#29609;&#23478;&#30340;&#21160;&#20316;&#25968;&#37327;&#65289;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#27809;&#26377;&#19968;&#31181;&#29616;&#26377;&#30340;&#27169;&#22411;&#33258;&#30001;&#31639;&#27861;&#21487;&#20197;&#36798;&#21040;&#36825;&#26679;&#30340;&#20248;&#21270;&#25928;&#26524;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#33258;&#30001;&#30340;&#38454;&#27573;&#24615;Q&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#23637;&#31034;&#23427;&#23454;&#29616;&#20102;&#19982;&#26368;&#20339;&#27169;&#22411;&#20026;&#22522;&#30784;&#31639;&#27861;&#30456;&#21516;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#22240;&#27492;&#39318;&#27425;&#35777;&#26126;&#20102;&#27169;&#22411;&#33258;&#30001;&#31639;&#27861;&#21487;&#20197;&#22312;&#26102;&#38388;&#27573;&#20381;&#36182;&#24615;&#26041;&#38754;&#20139;&#21463;&#19982;&#27169;&#22411;&#20026;&#22522;&#30784;&#31639;&#27861;&#30456;&#21516;&#30340;&#20248;&#21270;&#25928;&#26524;&#12290;&#23545;&#20110;$H$&#30340;&#20381;&#36182;&#24615;&#30340;&#20027;&#35201;&#25913;&#36827;&#26469;&#28304;&#20110;...
&lt;/p&gt;
&lt;p&gt;
The problem of two-player zero-sum Markov games has recently attracted increasing interests in theoretical studies of multi-agent reinforcement learning (RL). In particular, for finite-horizon episodic Markov decision processes (MDPs), it has been shown that model-based algorithms can find an $\epsilon$-optimal Nash Equilibrium (NE) with the sample complexity of $O(H^3SAB/\epsilon^2)$, which is optimal in the dependence of the horizon $H$ and the number of states $S$ (where $A$ and $B$ denote the number of actions of the two players, respectively). However, none of the existing model-free algorithms can achieve such an optimality. In this work, we propose a model-free stage-based Q-learning algorithm and show that it achieves the same sample complexity as the best model-based algorithm, and hence for the first time demonstrate that model-free algorithms can enjoy the same optimality in the $H$ dependence as model-based algorithms. The main improvement of the dependency on $H$ arises by
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#21452;&#37325;&#20132;&#26367;&#26041;&#21521;&#20056;&#23376;&#27861; (ADMM) &#21644;&#21322;&#24179;&#28369;&#29275;&#39039; (SSN) &#22522;&#20110;&#22686;&#24191;&#23545;&#20598;&#27861; (ALM) &#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#39640;&#25928;&#31639;&#27861;&#26469;&#23398;&#20064;&#20855;&#26377;&#32467;&#26500;&#31232;&#30095;&#24615;&#30340;&#26680;&#24515;&#22270;&#24418;Lasso&#27169;&#22411;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#22312;&#22823;&#32500;&#24230;&#30340;&#20219;&#21153;&#20013;&#33410;&#30465;&#36229;&#36807;70\%&#30340;&#25191;&#34892;&#26102;&#38388;&#65292;&#24182;&#19988;&#20855;&#26377;&#36739;&#39640;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.08852</link><description>&lt;p&gt;
&#36890;&#36807;&#39640;&#25928;&#31639;&#27861;&#23398;&#20064;&#20855;&#26377;&#32467;&#26500;&#31232;&#30095;&#24615;&#30340;&#26680;&#24515;&#22270;&#24418;Lasso&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning the hub graphical Lasso model with the structured sparsity via an efficient algorithm. (arXiv:2308.08852v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08852
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#21452;&#37325;&#20132;&#26367;&#26041;&#21521;&#20056;&#23376;&#27861; (ADMM) &#21644;&#21322;&#24179;&#28369;&#29275;&#39039; (SSN) &#22522;&#20110;&#22686;&#24191;&#23545;&#20598;&#27861; (ALM) &#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#39640;&#25928;&#31639;&#27861;&#26469;&#23398;&#20064;&#20855;&#26377;&#32467;&#26500;&#31232;&#30095;&#24615;&#30340;&#26680;&#24515;&#22270;&#24418;Lasso&#27169;&#22411;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#22312;&#22823;&#32500;&#24230;&#30340;&#20219;&#21153;&#20013;&#33410;&#30465;&#36229;&#36807;70\%&#30340;&#25191;&#34892;&#26102;&#38388;&#65292;&#24182;&#19988;&#20855;&#26377;&#36739;&#39640;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#24418;&#27169;&#22411;&#22312;&#20174;&#29983;&#29289;&#20998;&#26512;&#21040;&#25512;&#33616;&#31995;&#32479;&#31561;&#20247;&#22810;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#20102;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#20855;&#26377;&#26680;&#24515;&#33410;&#28857;&#30340;&#22270;&#24418;&#27169;&#22411;&#22312;&#25968;&#25454;&#32500;&#24230;&#36739;&#22823;&#26102;&#35745;&#31639;&#19978;&#23384;&#22312;&#22256;&#38590;&#12290;&#20026;&#20102;&#39640;&#25928;&#20272;&#35745;&#26680;&#24515;&#22270;&#24418;&#27169;&#22411;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#31639;&#27861;&#12290;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#39318;&#20808;&#36890;&#36807;&#21452;&#37325;&#20132;&#26367;&#26041;&#21521;&#20056;&#23376;&#27861; (ADMM) &#29983;&#25104;&#19968;&#20010;&#33391;&#22909;&#30340;&#21021;&#22987;&#28857;&#65292;&#28982;&#21518;&#20351;&#29992;&#21322;&#24179;&#28369;&#29275;&#39039; (SSN) &#22522;&#20110;&#22686;&#24191;&#23545;&#20598;&#27861; (ALM) &#30340;&#26041;&#27861;&#36827;&#34892;&#28909;&#21551;&#21160;&#65292;&#20197;&#35745;&#31639;&#20986;&#33021;&#22815;&#22312;&#23454;&#38469;&#20219;&#21153;&#20013;&#31934;&#30830;&#21040;&#36275;&#22815;&#31243;&#24230;&#30340;&#35299;&#12290;&#24191;&#20041;&#38597;&#21487;&#27604;&#30697;&#38453;&#30340;&#31232;&#30095;&#32467;&#26500;&#30830;&#20445;&#20102;&#35813;&#31639;&#27861;&#33021;&#22815;&#38750;&#24120;&#39640;&#25928;&#22320;&#33719;&#24471;&#19968;&#20010;&#33391;&#22909;&#30340;&#35299;&#12290;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#30495;&#23454;&#25968;&#25454;&#30340;&#20840;&#38754;&#23454;&#39564;&#20013;&#65292;&#35813;&#31639;&#27861;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#31639;&#27861;&#12290;&#29305;&#21035;&#26159;&#22312;&#26576;&#20123;&#39640;&#32500;&#20219;&#21153;&#20013;&#65292;&#23427;&#21487;&#20197;&#33410;&#30465;&#36229;&#36807;70\%&#30340;&#25191;&#34892;&#26102;&#38388;&#65292;&#21516;&#26102;&#20173;&#28982;&#21487;&#20197;&#36798;&#21040;&#24456;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graphical models have exhibited their performance in numerous tasks ranging from biological analysis to recommender systems. However, graphical models with hub nodes are computationally difficult to fit, particularly when the dimension of the data is large. To efficiently estimate the hub graphical models, we introduce a two-phase algorithm. The proposed algorithm first generates a good initial point via a dual alternating direction method of multipliers (ADMM), and then warm starts a semismooth Newton (SSN) based augmented Lagrangian method (ALM) to compute a solution that is accurate enough for practical tasks. The sparsity structure of the generalized Jacobian ensures that the algorithm can obtain a nice solution very efficiently. Comprehensive experiments on both synthetic data and real data show that it obviously outperforms the existing state-of-the-art algorithms. In particular, in some high dimensional tasks, it can save more than 70\% of the execution time, meanwhile still ach
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#21387;&#32553;&#32852;&#37030;&#23398;&#20064;&#31639;&#27861;(SCALLION&#21644;SCAFCOM)&#65292;&#36890;&#36807;&#37325;&#26032;&#23457;&#35270;&#32463;&#20856;&#30340;&#38543;&#26426;&#25511;&#21046;&#24179;&#22343;&#27861;&#24182;&#25552;&#20986;&#20102;&#31561;&#20215;&#20294;&#26356;&#39640;&#25928;/&#31616;&#21270;&#30340;&#24418;&#24335;&#65292;&#20943;&#23569;&#20102;&#19978;&#34892;&#36890;&#20449;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2308.08165</link><description>&lt;p&gt;
&#24102;&#26377;&#36890;&#20449;&#21387;&#32553;&#30340;&#38543;&#26426;&#25511;&#21046;&#24179;&#22343;&#27861;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Stochastic Controlled Averaging for Federated Learning with Communication Compression. (arXiv:2308.08165v1 [math.OC] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08165
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#21387;&#32553;&#32852;&#37030;&#23398;&#20064;&#31639;&#27861;(SCALLION&#21644;SCAFCOM)&#65292;&#36890;&#36807;&#37325;&#26032;&#23457;&#35270;&#32463;&#20856;&#30340;&#38543;&#26426;&#25511;&#21046;&#24179;&#22343;&#27861;&#24182;&#25552;&#20986;&#20102;&#31561;&#20215;&#20294;&#26356;&#39640;&#25928;/&#31616;&#21270;&#30340;&#24418;&#24335;&#65292;&#20943;&#23569;&#20102;&#19978;&#34892;&#36890;&#20449;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#20449;&#21387;&#32553;&#26159;&#19968;&#31181;&#26088;&#22312;&#20943;&#23569;&#36890;&#36807;&#26080;&#32447;&#20256;&#36755;&#30340;&#20449;&#24687;&#37327;&#30340;&#25216;&#26415;&#65292;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#24341;&#36215;&#20102;&#26497;&#22823;&#30340;&#20851;&#27880;&#65292;&#22240;&#20026;&#23427;&#26377;&#28508;&#21147;&#20943;&#36731;&#36890;&#20449;&#24320;&#38144;&#12290;&#28982;&#32780;&#65292;&#36890;&#20449;&#21387;&#32553;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#65292;&#21253;&#25324;&#21387;&#32553;&#24341;&#36215;&#30340;&#20449;&#24687;&#22833;&#30495;&#20197;&#21450;&#32852;&#37030;&#23398;&#20064;&#30340;&#29305;&#24615;&#65292;&#22914;&#37096;&#20998;&#21442;&#19982;&#21644;&#25968;&#25454;&#24322;&#26500;&#24615;&#12290;&#23613;&#31649;&#36817;&#24180;&#26469;&#26377;&#25152;&#21457;&#23637;&#65292;&#21387;&#32553;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#30340;&#24615;&#33021;&#23578;&#26410;&#20805;&#20998;&#21033;&#29992;&#12290;&#29616;&#26377;&#26041;&#27861;&#35201;&#20040;&#19981;&#33021;&#36866;&#24212;&#20219;&#24847;&#30340;&#25968;&#25454;&#24322;&#26500;&#24615;&#25110;&#37096;&#20998;&#21442;&#19982;&#65292;&#35201;&#20040;&#35201;&#27714;&#23545;&#21387;&#32553;&#26377;&#20005;&#26684;&#30340;&#26465;&#20214;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#20855;&#26377;&#24320;&#38144;&#20943;&#21322;&#30340;&#19978;&#34892;&#36890;&#20449;&#25104;&#26412;&#30340;&#32463;&#20856;&#38543;&#26426;&#25511;&#21046;&#24179;&#22343;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#21387;&#32553;&#32852;&#37030;&#23398;&#20064;&#31639;&#27861;&#65292;SCALLION&#21644;SCAFCOM&#12290;
&lt;/p&gt;
&lt;p&gt;
Communication compression, a technique aiming to reduce the information volume to be transmitted over the air, has gained great interests in Federated Learning (FL) for the potential of alleviating its communication overhead. However, communication compression brings forth new challenges in FL due to the interplay of compression-incurred information distortion and inherent characteristics of FL such as partial participation and data heterogeneity. Despite the recent development, the performance of compressed FL approaches has not been fully exploited. The existing approaches either cannot accommodate arbitrary data heterogeneity or partial participation, or require stringent conditions on compression.  In this paper, we revisit the seminal stochastic controlled averaging method by proposing an equivalent but more efficient/simplified formulation with halved uplink communication costs. Building upon this implementation, we propose two compressed FL algorithms, SCALLION and SCAFCOM, to s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#25955;&#20999;&#21106;Wasserstein&#25439;&#22833;&#30340;&#24615;&#36136;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#27491;&#21017;&#24615;&#21644;&#20248;&#21270;&#24615;&#36136;&#20197;&#21450;&#36890;&#36807;&#33945;&#29305;&#21345;&#27931;&#36817;&#20284;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.10352</link><description>&lt;p&gt;
&#31163;&#25955;&#20999;&#21106;Wasserstein&#25439;&#22833;&#30340;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
Properties of Discrete Sliced Wasserstein Losses. (arXiv:2307.10352v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10352
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#25955;&#20999;&#21106;Wasserstein&#25439;&#22833;&#30340;&#24615;&#36136;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#27491;&#21017;&#24615;&#21644;&#20248;&#21270;&#24615;&#36136;&#20197;&#21450;&#36890;&#36807;&#33945;&#29305;&#21345;&#27931;&#36817;&#20284;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20999;&#21106;Wasserstein&#65288;SW&#65289;&#36317;&#31163;&#24050;&#25104;&#20026;&#27604;&#36739;&#27010;&#29575;&#27979;&#24230;&#30340;Wasserstein&#36317;&#31163;&#30340;&#19968;&#31181;&#27969;&#34892;&#26367;&#20195;&#26041;&#27861;&#12290;&#24191;&#27867;&#24212;&#29992;&#21253;&#25324;&#22270;&#20687;&#22788;&#29702;&#12289;&#39046;&#22495;&#33258;&#36866;&#24212;&#21644;&#29983;&#25104;&#24314;&#27169;&#65292;&#24120;&#24120;&#38656;&#35201;&#20248;&#21270;&#19968;&#20123;&#21442;&#25968;&#20197;&#26368;&#23567;&#21270;SW&#65292;&#35813;&#21442;&#25968;&#20805;&#24403;&#31163;&#25955;&#27010;&#29575;&#27979;&#24230;&#20043;&#38388;&#30340;&#25439;&#22833;&#20989;&#25968;&#65288;&#22240;&#20026;&#20855;&#26377;&#23494;&#24230;&#30340;&#27979;&#24230;&#22312;&#25968;&#20540;&#19978;&#26159;&#26080;&#27861;&#23454;&#29616;&#30340;&#65289;&#12290;&#25152;&#26377;&#36825;&#20123;&#20248;&#21270;&#38382;&#39064;&#37117;&#23384;&#22312;&#30456;&#21516;&#30340;&#23376;&#38382;&#39064;&#65292;&#21363;&#26368;&#23567;&#21270;&#20999;&#21106;Wasserstein&#33021;&#37327;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;$\mathcal{E}: Y \longmapsto \mathrm{SW}_2^2(\gamma_Y, \gamma_Z)$&#30340;&#23646;&#24615;&#65292;&#21363;&#20004;&#20010;&#20855;&#26377;&#19982;&#19968;&#20010;&#27979;&#24230;&#30340;&#25903;&#25745;&#30456;&#21516;&#25968;&#37327;&#30340;&#31163;&#25955;&#22343;&#21248;&#27979;&#24230;&#20043;&#38388;&#30340;SW&#36317;&#31163;&#20316;&#20026;&#25903;&#25745;$Y \in \mathbb{R}^{n \times d}$&#20989;&#25968;&#30340;&#33021;&#37327;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#36825;&#20010;&#33021;&#37327;&#30340;&#27491;&#21017;&#24615;&#21644;&#20248;&#21270;&#24615;&#36136;&#65292;&#20197;&#21450;&#20854;&#36890;&#36807;&#33945;&#29305;&#21345;&#27931;&#36817;&#20284;$\mathcal{E}_p$&#65288;&#20351;&#29992;SW&#20013;&#30340;&#26399;&#26395;&#20272;&#35745;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Sliced Wasserstein (SW) distance has become a popular alternative to the Wasserstein distance for comparing probability measures. Widespread applications include image processing, domain adaptation and generative modelling, where it is common to optimise some parameters in order to minimise SW, which serves as a loss function between discrete probability measures (since measures admitting densities are numerically unattainable). All these optimisation problems bear the same sub-problem, which is minimising the Sliced Wasserstein energy. In this paper we study the properties of $\mathcal{E}: Y \longmapsto \mathrm{SW}_2^2(\gamma_Y, \gamma_Z)$, i.e. the SW distance between two uniform discrete measures with the same amount of points as a function of the support $Y \in \mathbb{R}^{n \times d}$ of one of the measures. We investigate the regularity and optimisation properties of this energy, as well as its Monte-Carlo approximation $\mathcal{E}_p$ (estimating the expectation in SW using 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21463;&#38480;&#29627;&#23572;&#20857;&#26364;&#26426;&#65288;RBMs&#65289;&#30340;&#20108;&#20540;&#22270;&#20687;&#21435;&#22122;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#20351;&#29992;&#20108;&#27425;&#26080;&#32422;&#26463;&#20108;&#20540;&#20248;&#21270;&#65288;QUBO&#65289;&#24418;&#24335;&#30340;&#21435;&#22122;&#30446;&#26631;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#37327;&#23376;&#36864;&#28779;&#12290;&#36890;&#36807;&#24179;&#34913;&#35757;&#32451;&#30340;RBMs&#23398;&#20064;&#21040;&#30340;&#20998;&#24067;&#21644;&#22122;&#22768;&#22270;&#20687;&#20559;&#31163;&#30340;&#24809;&#32602;&#39033;&#65292;&#23454;&#29616;&#20102;&#21435;&#22122;&#30446;&#26631;&#12290;&#36890;&#36807;&#36827;&#34892;&#23454;&#39564;&#65292;&#30740;&#31350;&#21457;&#29616;&#35813;&#26041;&#27861;&#24471;&#21040;&#30340;&#21435;&#22122;&#22270;&#20687;&#22312;&#26399;&#26395;&#24847;&#20041;&#19979;&#26126;&#26174;&#27604;&#22122;&#22768;&#22270;&#20687;&#26356;&#25509;&#36817;&#26080;&#22122;&#22768;&#22270;&#20687;&#12290;</title><link>http://arxiv.org/abs/2307.06542</link><description>&lt;p&gt;
&#37327;&#23376;&#36864;&#28779;&#20013;&#36866;&#21512;&#30340;&#22270;&#20687;&#21435;&#22122;&#26694;&#26550;&#65306;QUBO&#21644;&#21463;&#38480;&#29627;&#23572;&#20857;&#26364;&#26426;
&lt;/p&gt;
&lt;p&gt;
An Image-Denoising Framework Fit for Quantum Annealing via QUBO and Restricted Boltzmann Machines. (arXiv:2307.06542v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06542
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21463;&#38480;&#29627;&#23572;&#20857;&#26364;&#26426;&#65288;RBMs&#65289;&#30340;&#20108;&#20540;&#22270;&#20687;&#21435;&#22122;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#20351;&#29992;&#20108;&#27425;&#26080;&#32422;&#26463;&#20108;&#20540;&#20248;&#21270;&#65288;QUBO&#65289;&#24418;&#24335;&#30340;&#21435;&#22122;&#30446;&#26631;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#37327;&#23376;&#36864;&#28779;&#12290;&#36890;&#36807;&#24179;&#34913;&#35757;&#32451;&#30340;RBMs&#23398;&#20064;&#21040;&#30340;&#20998;&#24067;&#21644;&#22122;&#22768;&#22270;&#20687;&#20559;&#31163;&#30340;&#24809;&#32602;&#39033;&#65292;&#23454;&#29616;&#20102;&#21435;&#22122;&#30446;&#26631;&#12290;&#36890;&#36807;&#36827;&#34892;&#23454;&#39564;&#65292;&#30740;&#31350;&#21457;&#29616;&#35813;&#26041;&#27861;&#24471;&#21040;&#30340;&#21435;&#22122;&#22270;&#20687;&#22312;&#26399;&#26395;&#24847;&#20041;&#19979;&#26126;&#26174;&#27604;&#22122;&#22768;&#22270;&#20687;&#26356;&#25509;&#36817;&#26080;&#22122;&#22768;&#22270;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#36890;&#36807;&#21463;&#38480;&#29627;&#23572;&#20857;&#26364;&#26426;&#65288;RBMs&#65289;&#23454;&#29616;&#30340;&#20108;&#20540;&#22270;&#20687;&#21435;&#22122;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#24341;&#20837;&#20102;&#19968;&#20010;&#20108;&#27425;&#26080;&#32422;&#26463;&#20108;&#20540;&#20248;&#21270;&#65288;QUBO&#65289;&#24418;&#24335;&#30340;&#21435;&#22122;&#30446;&#26631;&#65292;&#24182;&#19988;&#38750;&#24120;&#36866;&#21512;&#37327;&#23376;&#36864;&#28779;&#12290;&#36890;&#36807;&#22312;&#35757;&#32451;&#30340;RBMs&#19978;&#23398;&#20064;&#21040;&#30340;&#20998;&#24067;&#19982;&#22122;&#22768;&#22270;&#20687;&#20559;&#31163;&#30340;&#24809;&#32602;&#39033;&#30340;&#24179;&#34913;&#65292;&#23454;&#29616;&#20102;&#21435;&#22122;&#30446;&#26631;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#22312;&#30446;&#26631;&#20998;&#24067;&#34987;&#33391;&#22909;&#36817;&#20284;&#30340;&#24773;&#20917;&#19979;&#65292;&#24809;&#32602;&#21442;&#25968;&#30340;&#32479;&#35745;&#26368;&#20248;&#36873;&#25321;&#65292;&#24182;&#36827;&#19968;&#27493;&#24314;&#35758;&#20102;&#19968;&#31181;&#32463;&#36807;&#32463;&#39564;&#35777;&#25903;&#25345;&#30340;&#20462;&#25913;&#26041;&#27861;&#65292;&#20351;&#35813;&#26041;&#27861;&#23545;&#20110;&#29702;&#24819;&#21270;&#20551;&#35774;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#36824;&#22312;&#39069;&#22806;&#30340;&#20551;&#35774;&#19979;&#23637;&#31034;&#20102;&#65292;&#25105;&#20204;&#26041;&#27861;&#24471;&#21040;&#30340;&#21435;&#22122;&#22270;&#20687;&#22312;&#26399;&#26395;&#24847;&#20041;&#19979;&#26126;&#26174;&#27604;&#22122;&#22768;&#22270;&#20687;&#26356;&#25509;&#36817;&#26080;&#22122;&#22768;&#22270;&#20687;&#12290;&#34429;&#28982;&#25105;&#20204;&#23558;&#35813;&#27169;&#22411;&#26500;&#24314;&#20026;&#22270;&#20687;&#21435;&#22122;&#27169;&#22411;&#65292;&#20294;&#23427;&#21487;&#20197;&#24212;&#29992;&#20110;&#20219;&#20309;&#20108;&#20540;&#25968;&#25454;&#12290;&#30001;&#20110;QUBO&#20844;&#24335;&#38750;&#24120;&#36866;&#21512;&#22312;&#37327;&#23376;&#36864;&#28779;&#22120;&#19978;&#23454;&#29616;&#65292;&#25105;&#20204;&#22312;&#19968;&#20010;&#25968;&#25454;&#38598;&#19978;&#23545;&#35813;&#27169;&#22411;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate a framework for binary image denoising via restricted Boltzmann machines (RBMs) that introduces a denoising objective in quadratic unconstrained binary optimization (QUBO) form and is well-suited for quantum annealing. The denoising objective is attained by balancing the distribution learned by a trained RBM with a penalty term for derivations from the noisy image. We derive the statistically optimal choice of the penalty parameter assuming the target distribution has been well-approximated, and further suggest an empirically supported modification to make the method robust to that idealistic assumption. We also show under additional assumptions that the denoised images attained by our method are, in expectation, strictly closer to the noise-free images than the noisy images are. While we frame the model as an image denoising model, it can be applied to any binary data. As the QUBO formulation is well-suited for implementation on quantum annealers, we test the model on a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#32473;&#20986;&#20102;&#19968;&#20010;&#29616;&#26377;&#26041;&#27861;&#31934;&#32454;&#21270;&#30340;&#32467;&#26524;&#65292;&#23454;&#29616;&#20102;&#26080;&#28145;&#24230;&#20381;&#36182;&#24615;&#30340;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2306.01992</link><description>&lt;p&gt;
&#20851;&#20110;ReLU&#32593;&#32476;&#30340;&#22823;&#23567;&#26080;&#20851;&#26679;&#26412;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
On Size-Independent Sample Complexity of ReLU Networks. (arXiv:2306.01992v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01992
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#32473;&#20986;&#20102;&#19968;&#20010;&#29616;&#26377;&#26041;&#27861;&#31934;&#32454;&#21270;&#30340;&#32467;&#26524;&#65292;&#23454;&#29616;&#20102;&#26080;&#28145;&#24230;&#20381;&#36182;&#24615;&#30340;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20174;&#27867;&#21270;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#23398;&#20064;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#22312;&#26435;&#37325;&#30697;&#38453;&#19978;&#32473;&#23450;&#33539;&#25968;&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#65292;&#19968;&#20010;&#24120;&#35265;&#30340;&#26041;&#27861;&#26159;&#20272;&#35745;&#30456;&#20851;&#20989;&#25968;&#31867;&#30340;Rademacher&#22797;&#26434;&#24230;&#12290;&#20043;&#21069;Golowich-Rakhlin-Shamir (2020)&#33719;&#24471;&#20102;&#19968;&#20010;&#19981;&#20381;&#36182;&#20110;&#32593;&#32476;&#22823;&#23567;&#30340;&#65288;&#19982;Frobenius&#33539;&#25968;&#30340;&#20056;&#31215;&#25104;&#27604;&#20363;&#65289;&#19978;&#30028;&#65292;&#38500;&#20102;&#19968;&#20010;&#24179;&#26041;&#26681;&#28145;&#24230;&#30340;&#22240;&#23376;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#20010;&#31934;&#32454;&#21270;&#30340;&#32467;&#26524;&#65292;&#36890;&#24120;&#26681;&#26412;&#27809;&#26377;&#26126;&#26174;&#30340;&#28145;&#24230;&#20381;&#36182;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the sample complexity of learning ReLU neural networks from the point of view of generalization. Given norm constraints on the weight matrices, a common approach is to estimate the Rademacher complexity of the associated function class. Previously Golowich-Rakhlin-Shamir (2020) obtained a bound independent of the network size (scaling with a product of Frobenius norms) except for a factor of the square-root depth. We give a refinement which often has no explicit depth-dependence at all.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;Platt&#32553;&#25918;&#21450;&#20854;&#26657;&#20934;&#26041;&#27861;&#65292;&#20854;&#29702;&#35770;&#22522;&#30784;&#24378;&#22823;&#65292;&#21487;&#20197;&#22788;&#29702;&#20998;&#24067;&#28418;&#31227;&#21644;&#23545;&#25239;&#24615;&#32467;&#26524;&#24207;&#21015;&#65292;&#26080;&#38656;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#22312;&#19968;&#31995;&#21015;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.00070</link><description>&lt;p&gt;
&#22312;&#32447;Platt&#32553;&#25918;&#21450;&#20854;&#26657;&#20934;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Online Platt Scaling with Calibeating. (arXiv:2305.00070v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00070
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;Platt&#32553;&#25918;&#21450;&#20854;&#26657;&#20934;&#26041;&#27861;&#65292;&#20854;&#29702;&#35770;&#22522;&#30784;&#24378;&#22823;&#65292;&#21487;&#20197;&#22788;&#29702;&#20998;&#24067;&#28418;&#31227;&#21644;&#23545;&#25239;&#24615;&#32467;&#26524;&#24207;&#21015;&#65292;&#26080;&#38656;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#22312;&#19968;&#31995;&#21015;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#21518;&#26657;&#20934;&#26041;&#27861;&#65292;&#31216;&#20026;&#22312;&#32447;Platt&#32553;&#25918;(OPS)&#65292;&#23427;&#23558;Platt&#32553;&#25918;&#25216;&#26415;&#19982;&#22312;&#32447;&#36923;&#36753;&#22238;&#24402;&#30456;&#32467;&#21512;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;OPS&#22914;&#20309;&#22312;&#20998;&#24067;&#28418;&#31227;&#30340;i.i.d.&#21644;&#38750;i.i.d.&#24773;&#20917;&#19979;&#24179;&#31283;&#36866;&#24212;&#12290;&#27492;&#22806;&#65292;&#24403;&#26368;&#20339;&#30340;Platt&#32553;&#25918;&#27169;&#22411;&#26412;&#36523;&#34987;&#38169;&#35823;&#26657;&#20934;&#26102;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#31181;&#26368;&#36817;&#24320;&#21457;&#30340;&#31216;&#20026;calibeating&#30340;&#25216;&#26415;&#26469;&#22686;&#24378;OPS&#65292;&#20351;&#20854;&#26356;&#21152;&#40065;&#26834;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#24471;&#21040;&#30340;OPS+calibeating&#26041;&#27861;&#23545;&#20110;&#23545;&#25239;&#24615;&#32467;&#26524;&#24207;&#21015;&#26159;&#20445;&#35777;&#26657;&#20934;&#30340;&#12290;&#22312;&#23454;&#39564;&#19978;&#65292;&#23427;&#22312;&#19968;&#31995;&#21015;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#22343;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#65292;&#26080;&#38656;&#36229;&#21442;&#25968;&#35843;&#25972;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#25152;&#26377;OPS&#24605;&#24819;&#25193;&#23637;&#21040;beta&#32553;&#25918;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present an online post-hoc calibration method, called Online Platt Scaling (OPS), which combines the Platt scaling technique with online logistic regression. We demonstrate that OPS smoothly adapts between i.i.d. and non-i.i.d. settings with distribution drift. Further, in scenarios where the best Platt scaling model is itself miscalibrated, we enhance OPS by incorporating a recently developed technique called calibeating to make it more robust. Theoretically, our resulting OPS+calibeating method is guaranteed to be calibrated for adversarial outcome sequences. Empirically, it is effective on a range of synthetic and real-world datasets, with and without distribution drifts, achieving superior performance without hyperparameter tuning. Finally, we extend all OPS ideas to the beta scaling method.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;DGAI&#31639;&#27861;&#65292;&#23427;&#21487;&#20197;&#22312;&#22909;&#25163;&#33218;&#35782;&#21035;&#38382;&#39064;&#20013;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#24335;&#20943;&#23569;&#26679;&#26412;&#22797;&#26434;&#24615;&#65292;&#24182;&#19988;&#22312;&#20855;&#26377;&#32473;&#23450;&#38408;&#20540;&#30340;&#24773;&#20917;&#19979;&#36827;&#19968;&#27493;&#25552;&#39640;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2303.07154</link><description>&lt;p&gt;
&#19981;&#21516;&#30340;&#22909;&#25163;&#33218;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Differential Good Arm Identification. (arXiv:2303.07154v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.07154
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;DGAI&#31639;&#27861;&#65292;&#23427;&#21487;&#20197;&#22312;&#22909;&#25163;&#33218;&#35782;&#21035;&#38382;&#39064;&#20013;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#24335;&#20943;&#23569;&#26679;&#26412;&#22797;&#26434;&#24615;&#65292;&#24182;&#19988;&#22312;&#20855;&#26377;&#32473;&#23450;&#38408;&#20540;&#30340;&#24773;&#20917;&#19979;&#36827;&#19968;&#27493;&#25552;&#39640;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#19968;&#31181;&#21464;&#20307;&#30340;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#65292;&#31216;&#20043;&#20026;&#22909;&#25163;&#33218;&#35782;&#21035;&#65288;GAI&#65289;&#12290; GAI&#26159;&#19968;&#20010;&#32431;&#25506;&#32034;&#30340;&#36172;&#21338;&#38382;&#39064;&#65292;&#20854;&#30446;&#26631;&#26159;&#22312;&#23613;&#21487;&#33021;&#23569;&#30340;&#26679;&#26412;&#25968;&#19979;&#36755;&#20986;&#23613;&#21487;&#33021;&#22810;&#30340;&#22909;&#25163;&#33218;&#65292;&#20854;&#20013;&#22909;&#25163;&#33218;&#34987;&#23450;&#20041;&#20026;&#20854;&#26399;&#26395;&#22870;&#21169;&#22823;&#20110;&#32473;&#23450;&#38408;&#20540;&#30340;&#25163;&#33218;&#12290; &#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;DGAI-&#19968;&#31181;&#21487;&#24494;&#30340;&#22909;&#25163;&#33218;&#35782;&#21035;&#31639;&#27861;&#65292;&#20197;&#25968;&#25454;&#39537;&#21160;&#26041;&#24335;&#25913;&#36827;&#20102;&#29616;&#26377;&#25216;&#26415;HDoC&#31639;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290; &#25105;&#20204;&#36824;&#23637;&#31034;&#20102;DGAI&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#21319;&#36890;&#29992;&#22810;&#33218;&#36172;&#21338;&#65288;MAB&#65289;&#38382;&#39064;&#30340;&#24615;&#33021;&#65292;&#32473;&#23450;&#19968;&#20010;&#38408;&#20540;&#20316;&#20026;&#20808;&#39564;&#30693;&#35782;&#24212;&#29992;&#20110;&#25163;&#33218;&#38598;&#12290; &#22823;&#37327;&#23454;&#39564;&#35777;&#23454;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#20013;&#30340;GAI&#21644;MAB&#20219;&#21153;&#20013;&#26174;&#33879;&#20248;&#20110;&#22522;&#32447;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper targets a variant of the stochastic multi-armed bandit problem called good arm identification (GAI). GAI is a pure-exploration bandit problem with the goal to output as many good arms using as few samples as possible, where a good arm is defined as an arm whose expected reward is greater than a given threshold. In this work, we propose DGAI - a differentiable good arm identification algorithm to improve the sample complexity of the state-of-the-art HDoC algorithm in a data-driven fashion. We also showed that the DGAI can further boost the performance of a general multi-arm bandit (MAB) problem given a threshold as a prior knowledge to the arm set. Extensive experiments confirm that our algorithm outperform the baseline algorithms significantly in both synthetic and real world datasets for both GAI and MAB tasks.
&lt;/p&gt;</description></item><item><title>&#21435;&#22122;&#25193;&#25955;&#37319;&#26679;&#22120; (DDS) &#36817;&#20284;&#22320;&#20174;&#38750;&#26631;&#20934;&#21270;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#20013;&#37319;&#26679;&#65292;&#24182;&#20272;&#35745;&#20854;&#26631;&#20934;&#21270;&#24120;&#25968;&#12290;</title><link>http://arxiv.org/abs/2302.13834</link><description>&lt;p&gt;
&#21435;&#22122;&#25193;&#25955;&#37319;&#26679;&#22120;
&lt;/p&gt;
&lt;p&gt;
Denoising Diffusion Samplers. (arXiv:2302.13834v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.13834
&lt;/p&gt;
&lt;p&gt;
&#21435;&#22122;&#25193;&#25955;&#37319;&#26679;&#22120; (DDS) &#36817;&#20284;&#22320;&#20174;&#38750;&#26631;&#20934;&#21270;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#20013;&#37319;&#26679;&#65292;&#24182;&#20272;&#35745;&#20854;&#26631;&#20934;&#21270;&#24120;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#26159;&#19968;&#31181;&#21463;&#27426;&#36814;&#30340;&#29983;&#25104;&#27169;&#22411;&#31867;&#21035;&#65292;&#22312;&#35768;&#22810;&#39046;&#22495;&#25552;&#20379;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;&#36890;&#36807;&#20351;&#29992;&#25193;&#25955;&#36880;&#28176;&#21521;&#25968;&#25454;&#28155;&#21152;&#22122;&#22768;&#65292;&#23558;&#25968;&#25454;&#20998;&#24067;&#36716;&#21270;&#20026;&#39640;&#26031;&#20998;&#24067;&#12290;&#29983;&#25104;&#27169;&#22411;&#30340;&#26679;&#26412;&#36890;&#36807;&#27169;&#25311;&#35813;&#25193;&#25955;&#30340;&#26102;&#38388;&#21453;&#28436;&#30340;&#36817;&#20284;&#65292;&#24182;&#21021;&#22987;&#21270;&#20026;&#39640;&#26031;&#26679;&#26412;&#26469;&#33719;&#24471;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#36890;&#36807;&#20351;&#29992;&#35780;&#20998;&#21305;&#37197;&#25216;&#26415;&#23545;&#26102;&#38388;&#21453;&#28436;&#36807;&#31243;&#20013;&#20986;&#29616;&#30340;&#26840;&#25163;&#30340;&#35780;&#20998;&#39033;&#36827;&#34892;&#36817;&#20284;&#12290;&#25105;&#20204;&#22312;&#36825;&#37324;&#25506;&#32034;&#20102;&#19968;&#31181;&#31867;&#20284;&#30340;&#24819;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#37319;&#26679;&#38750;&#26631;&#20934;&#21270;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#24182;&#20272;&#35745;&#20854;&#26631;&#20934;&#21270;&#24120;&#25968;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#30446;&#26631;&#23494;&#24230;&#21521;&#39640;&#26031;&#25193;&#25955;&#30340;&#36807;&#31243;&#12290;&#21435;&#22122;&#25193;&#25955;&#37319;&#26679;&#22120; (DDS) &#26159;&#36890;&#36807;&#36817;&#20284;&#30456;&#24212;&#30340;&#26102;&#38388;&#21453;&#28436;&#32780;&#33719;&#24471;&#30340;&#12290;&#23613;&#31649;&#35780;&#20998;&#21305;&#37197;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#19981;&#36866;&#29992;&#65292;&#20294;&#25105;&#20204;&#21487;&#20197;&#21033;&#29992;&#22312; Monte Carlo &#37319;&#26679;&#20013;&#24341;&#20837;&#30340;&#35768;&#22810;&#24605;&#24819;&#12290;
&lt;/p&gt;
&lt;p&gt;
Denoising diffusion models are a popular class of generative models providing state-of-the-art results in many domains. One adds gradually noise to data using a diffusion to transform the data distribution into a Gaussian distribution. Samples from the generative model are then obtained by simulating an approximation of the time-reversal of this diffusion initialized by Gaussian samples. Practically, the intractable score terms appearing in the time-reversed process are approximated using score matching techniques. We explore here a similar idea to sample approximately from unnormalized probability density functions and estimate their normalizing constants. We consider a process where the target density diffuses towards a Gaussian. Denoising Diffusion Samplers (DDS) are obtained by approximating the corresponding time-reversal. While score matching is not applicable in this context, we can leverage many of the ideas introduced in generative modeling for Monte Carlo sampling. Existing t
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#29983;&#29289;&#21307;&#23398;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#21487;&#20449;&#24230;&#38382;&#39064;&#65292;&#36890;&#36807;&#24320;&#21457;&#22686;&#24378;&#25915;&#20987;&#25216;&#26415;&#65292;&#25104;&#21151;&#22320;&#33021;&#22815;&#36890;&#36807;&#26368;&#23567;&#30340;&#29305;&#24449;&#25913;&#21464;&#26174;&#33879;&#25552;&#39640;&#20998;&#31867;&#22120;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#24182;&#20445;&#25345;&#21407;&#22987;&#25968;&#25454;&#21644;&#22686;&#24378;&#25968;&#25454;&#20043;&#38388;&#30340;&#39640;&#29305;&#24449;&#30456;&#20284;&#24615;&#12290;</title><link>http://arxiv.org/abs/2301.01885</link><description>&lt;p&gt;
&#29983;&#29289;&#21307;&#23398;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#22686;&#24378;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Enhancement attacks in biomedical machine learning. (arXiv:2301.01885v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.01885
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#29983;&#29289;&#21307;&#23398;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#21487;&#20449;&#24230;&#38382;&#39064;&#65292;&#36890;&#36807;&#24320;&#21457;&#22686;&#24378;&#25915;&#20987;&#25216;&#26415;&#65292;&#25104;&#21151;&#22320;&#33021;&#22815;&#36890;&#36807;&#26368;&#23567;&#30340;&#29305;&#24449;&#25913;&#21464;&#26174;&#33879;&#25552;&#39640;&#20998;&#31867;&#22120;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#24182;&#20445;&#25345;&#21407;&#22987;&#25968;&#25454;&#21644;&#22686;&#24378;&#25968;&#25454;&#20043;&#38388;&#30340;&#39640;&#29305;&#24449;&#30456;&#20284;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#22312;&#29983;&#29289;&#21307;&#23398;&#30740;&#31350;&#20013;&#30340;&#24212;&#29992;&#26085;&#30410;&#22686;&#22810;&#65292;&#28982;&#32780;&#23545;&#20110;&#36825;&#20123;&#30740;&#31350;&#21487;&#20449;&#24230;&#30340;&#20851;&#27880;&#21364;&#24448;&#24448;&#34987;&#24573;&#35270;&#12290;&#23613;&#31649;&#19968;&#20123;&#20808;&#21069;&#30340;&#30740;&#31350;&#25506;&#35752;&#20102;&#23545;&#21307;&#23398;&#22270;&#20687;&#27169;&#22411;&#24615;&#33021;&#36827;&#34892;&#30772;&#22351;&#30340;&#23545;&#25239;&#25915;&#20987;&#30340;&#33021;&#21147;&#65292;&#20294;&#26368;&#36817;&#20986;&#29616;&#30340;&#8220;&#22686;&#24378;&#25915;&#20987;&#8221;&#36890;&#36807;&#35823;&#23548;&#22320;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#21487;&#33021;&#20250;&#23545;&#29983;&#29289;&#21307;&#23398;&#26426;&#22120;&#23398;&#20064;&#26500;&#25104;&#26356;&#22823;&#30340;&#23041;&#32961;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#20102;&#35299;&#21487;&#20449;&#24230;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#20004;&#31181;&#25216;&#26415;&#65292;&#21487;&#20197;&#36890;&#36807;&#26497;&#23567;&#30340;&#29305;&#24449;&#25913;&#21464;&#26174;&#33879;&#25552;&#39640;&#20998;&#31867;&#22120;&#30340;&#39044;&#27979;&#24615;&#33021;&#65306;1&#65289;&#26222;&#36941;&#24615;&#33021;&#22686;&#24378;&#21644;2&#65289;&#26576;&#31181;&#26041;&#27861;&#30456;&#23545;&#20110;&#20854;&#20182;&#26041;&#27861;&#30340;&#22686;&#24378;&#12290;&#25105;&#20204;&#30340;&#22686;&#24378;&#26694;&#26550;&#21487;&#20197;&#23558;&#20998;&#31867;&#22120;&#30340;&#20934;&#30830;&#29575;&#20174;50&#65285;&#34394;&#20551;&#25552;&#39640;&#21040;&#25509;&#36817;100&#65285;&#65292;&#21516;&#26102;&#20445;&#25345;&#21407;&#22987;&#25968;&#25454;&#21644;&#22686;&#24378;&#25968;&#25454;&#20043;&#38388;&#30340;&#39640;&#29305;&#24449;&#30456;&#20284;&#24615;&#65288;Pearson's r&gt;0.99&#65289;&#12290;&#31867;&#20284;&#22320;&#65292;&#22522;&#20110;&#26041;&#27861;&#30340;&#22686;&#24378;&#26694;&#26550;&#26377;&#25928;&#22320;&#34394;&#20551;&#25552;&#39640;&#20102;&#26576;&#31181;&#26041;&#27861;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The prevalence of machine learning in biomedical research is rapidly growing, yet the trustworthiness of such research is often overlooked. While some previous works have investigated the ability of adversarial attacks to degrade model performance in medical imaging, the ability to falsely improve performance via recently-developed "enhancement attacks" may be a greater threat to biomedical machine learning. In the spirit of developing attacks to better understand trustworthiness, we developed two techniques to drastically enhance prediction performance of classifiers with minimal changes to features: 1) general enhancement of prediction performance, and 2) enhancement of a particular method over another. Our enhancement framework falsely improved classifiers' accuracy from 50% to almost 100% while maintaining high feature similarities between original and enhanced data (Pearson's r's&gt;0.99). Similarly, the method-specific enhancement framework was effective in falsely improving the per
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#22810;&#36895;&#29575;VAE&#65288;MR-VAE&#65289;&#30340;&#26694;&#26550;&#65292;&#21487;&#22312;&#21333;&#27425;&#35757;&#32451;&#20013;&#23398;&#20064;&#19982;&#19981;&#21516;&#946;&#23545;&#24212;&#30340;&#26368;&#20248;&#21442;&#25968;&#65292;&#36890;&#36807;&#20351;&#29992;&#36229;&#32593;&#32476;&#23558;&#946;&#26144;&#23556;&#21040;&#26368;&#20248;&#21442;&#25968;&#65292;&#20197;&#23454;&#29616;&#29575;&#22833;&#30495;&#26354;&#32447;&#30340;&#23436;&#25972;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2212.03905</link><description>&lt;p&gt;
&#22810;&#36895;&#29575;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65306;&#19968;&#27425;&#35757;&#32451;&#65292;&#24471;&#21040;&#23436;&#25972;&#30340;&#29575;&#22833;&#30495;&#26354;&#32447;
&lt;/p&gt;
&lt;p&gt;
Multi-Rate VAE: Train Once, Get the Full Rate-Distortion Curve. (arXiv:2212.03905v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.03905
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#22810;&#36895;&#29575;VAE&#65288;MR-VAE&#65289;&#30340;&#26694;&#26550;&#65292;&#21487;&#22312;&#21333;&#27425;&#35757;&#32451;&#20013;&#23398;&#20064;&#19982;&#19981;&#21516;&#946;&#23545;&#24212;&#30340;&#26368;&#20248;&#21442;&#25968;&#65292;&#36890;&#36807;&#20351;&#29992;&#36229;&#32593;&#32476;&#23558;&#946;&#26144;&#23556;&#21040;&#26368;&#20248;&#21442;&#25968;&#65292;&#20197;&#23454;&#29616;&#29575;&#22833;&#30495;&#26354;&#32447;&#30340;&#23436;&#25972;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAEs&#65289;&#26159;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#25968;&#25454;&#30340;&#28508;&#22312;&#34920;&#31034;&#30340;&#24378;&#22823;&#24037;&#20855;&#65292;&#24191;&#27867;&#24212;&#29992;&#20110;&#21508;&#31181;&#24212;&#29992;&#39046;&#22495;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;VAEs&#36890;&#24120;&#38656;&#35201;&#22810;&#27425;&#35757;&#32451;&#26469;&#36873;&#25321;&#28508;&#22312;&#21464;&#37327;&#24212;&#35813;&#20445;&#30041;&#30340;&#20449;&#24687;&#37327;&#12290;&#37325;&#26500;&#35823;&#24046;&#65288;&#22833;&#30495;&#65289;&#21644;KL&#25955;&#24230;&#65288;&#29575;&#65289;&#20043;&#38388;&#30340;&#26435;&#34913;&#36890;&#24120;&#30001;&#36229;&#21442;&#25968;&#946;&#21442;&#25968;&#21270;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22810;&#36895;&#29575;VAE&#65288;MR-VAE&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#21333;&#27425;&#35757;&#32451;&#20013;&#23398;&#20064;&#19982;&#19981;&#21516;&#946;&#23545;&#24212;&#30340;&#26368;&#20248;&#21442;&#25968;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#20351;&#29992;&#36229;&#32593;&#32476;&#26126;&#30830;&#22320;&#21046;&#23450;&#19968;&#20010;&#21709;&#24212;&#20989;&#25968;&#65292;&#23558;&#946;&#26144;&#23556;&#21040;&#26368;&#20248;&#21442;&#25968;&#12290;MR-VAEs&#26500;&#24314;&#20102;&#19968;&#20010;&#32039;&#20945;&#30340;&#21709;&#24212;&#36229;&#32593;&#32476;&#65292;&#20854;&#20013;&#30340;&#39044;&#28608;&#27963;&#26681;&#25454;&#946;&#36827;&#34892;&#26377;&#26465;&#20214;&#30340;&#38376;&#25511;&#12290;&#36890;&#36807;&#20998;&#26512;&#32447;&#24615;VAEs&#24182;&#23637;&#31034;&#23427;&#33021;&#22815;&#20934;&#30830;&#34920;&#31034;&#32447;&#24615;VAEs&#30340;&#21709;&#24212;&#20989;&#25968;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26550;&#26500;&#30340;&#21512;&#29702;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational autoencoders (VAEs) are powerful tools for learning latent representations of data used in a wide range of applications. In practice, VAEs usually require multiple training rounds to choose the amount of information the latent variable should retain. This trade-off between the reconstruction error (distortion) and the KL divergence (rate) is typically parameterized by a hyperparameter $\beta$. In this paper, we introduce Multi-Rate VAE (MR-VAE), a computationally efficient framework for learning optimal parameters corresponding to various $\beta$ in a single training run. The key idea is to explicitly formulate a response function that maps $\beta$ to the optimal parameters using hypernetworks. MR-VAEs construct a compact response hypernetwork where the pre-activations are conditionally gated based on $\beta$. We justify the proposed architecture by analyzing linear VAEs and showing that it can represent response functions exactly for linear VAEs. With the learned hypernetw
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#36229;&#32479;&#35745;&#23398;&#26041;&#27861;&#65292;&#29992;&#20110;&#36125;&#21494;&#26031;&#20272;&#35745;&#21160;&#24577;&#35748;&#30693;&#27169;&#22411;&#12290;&#36890;&#36807;&#24341;&#20837;&#26102;&#38388;&#32500;&#24230;&#21644;&#36229;&#32479;&#35745;&#35270;&#35282;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#20272;&#35745;&#31995;&#32479;&#20013;&#30340;&#21160;&#24577;&#24615;&#36136;&#65292;&#24182;&#21033;&#29992;&#20223;&#30495;&#21644;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#36125;&#21494;&#26031;&#25512;&#29702;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#24674;&#22797;&#26102;&#21464;&#21644;&#26102;&#19981;&#21464;&#21442;&#25968;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2211.13165</link><description>&lt;p&gt;
&#31070;&#32463;&#36229;&#32479;&#35745;&#23398;&#29992;&#20110;&#36125;&#21494;&#26031;&#20272;&#35745;&#21160;&#24577;&#35748;&#30693;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Neural Superstatistics for Bayesian Estimation of Dynamic Cognitive Model. (arXiv:2211.13165v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.13165
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#36229;&#32479;&#35745;&#23398;&#26041;&#27861;&#65292;&#29992;&#20110;&#36125;&#21494;&#26031;&#20272;&#35745;&#21160;&#24577;&#35748;&#30693;&#27169;&#22411;&#12290;&#36890;&#36807;&#24341;&#20837;&#26102;&#38388;&#32500;&#24230;&#21644;&#36229;&#32479;&#35745;&#35270;&#35282;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#20272;&#35745;&#31995;&#32479;&#20013;&#30340;&#21160;&#24577;&#24615;&#36136;&#65292;&#24182;&#21033;&#29992;&#20223;&#30495;&#21644;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#36125;&#21494;&#26031;&#25512;&#29702;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#24674;&#22797;&#26102;&#21464;&#21644;&#26102;&#19981;&#21464;&#21442;&#25968;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35748;&#30693;&#30340;&#25968;&#23398;&#27169;&#22411;&#36890;&#24120;&#26159;&#26080;&#35760;&#24518;&#30340;&#65292;&#24573;&#30053;&#20102;&#21442;&#25968;&#30340;&#28508;&#22312;&#27874;&#21160;&#12290;&#28982;&#32780;&#65292;&#20154;&#31867;&#35748;&#30693;&#26412;&#36136;&#19978;&#26159;&#21160;&#24577;&#30340;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#22312;&#26426;&#26800;&#35748;&#30693;&#27169;&#22411;&#20013;&#24341;&#20837;&#26102;&#38388;&#32500;&#24230;&#65292;&#24182;&#20174;&#36229;&#32479;&#35745;&#23398;&#30340;&#35282;&#24230;&#20272;&#35745;&#25152;&#24471;&#21040;&#30340;&#21160;&#24577;&#24615;&#36136;&#12290;&#36825;&#26679;&#30340;&#27169;&#22411;&#21253;&#25324;&#20102;&#19968;&#20010;&#20302;&#32423;&#35266;&#27979;&#27169;&#22411;&#21644;&#19968;&#20010;&#39640;&#32423;&#36716;&#25442;&#27169;&#22411;&#20043;&#38388;&#30340;&#23618;&#27425;&#32467;&#26500;&#12290;&#35266;&#27979;&#27169;&#22411;&#25551;&#36848;&#20102;&#31995;&#32479;&#30340;&#23616;&#37096;&#34892;&#20026;&#65292;&#36716;&#25442;&#27169;&#22411;&#35268;&#23450;&#20102;&#35266;&#27979;&#27169;&#22411;&#21442;&#25968;&#38543;&#26102;&#38388;&#28436;&#21270;&#30340;&#26041;&#24335;&#12290;&#20026;&#20102;&#20811;&#26381;&#36229;&#32479;&#35745;&#27169;&#22411;&#22797;&#26434;&#24615;&#24102;&#26469;&#30340;&#20272;&#35745;&#25361;&#25112;&#65292;&#25105;&#20204;&#24320;&#21457;&#24182;&#39564;&#35777;&#20102;&#19968;&#31181;&#22522;&#20110;&#20223;&#30495;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#36125;&#21494;&#26031;&#25512;&#29702;&#65292;&#21487;&#20197;&#24674;&#22797;&#26102;&#21464;&#21644;&#26102;&#19981;&#21464;&#21442;&#25968;&#12290;&#25105;&#20204;&#39318;&#20808;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#20004;&#20010;&#24050;&#26377;&#30340;&#33021;&#22815;&#20272;&#35745;&#26102;&#21464;&#21442;&#25968;&#30340;&#26694;&#26550;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#25311;&#21512;&#21160;&#24577;&#29256;&#26412;&#30340;&#24046;&#20998;&#26041;&#31243;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mathematical models of cognition are often memoryless and ignore potential fluctuations of their parameters. However, human cognition is inherently dynamic. Thus, we propose to augment mechanistic cognitive models with a temporal dimension and estimate the resulting dynamics from a superstatistics perspective. Such a model entails a hierarchy between a low-level observation model and a high-level transition model. The observation model describes the local behavior of a system, and the transition model specifies how the parameters of the observation model evolve over time. To overcome the estimation challenges resulting from the complexity of superstatistical models, we develop and validate a simulation-based deep learning method for Bayesian inference, which can recover both time-varying and time-invariant parameters. We first benchmark our method against two existing frameworks capable of estimating time-varying parameters. We then apply our method to fit a dynamic version of the diff
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#20984;&#38598;&#30340;&#26032;&#35282;&#24230;&#31995;&#32479;&#22320;&#21457;&#23637;&#20102;&#25439;&#22833;&#20989;&#25968;&#29702;&#35770;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#33258;&#21160;&#21512;&#36866;&#30340;&#25439;&#22833;&#20989;&#25968;&#23450;&#20041;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#25439;&#22833;&#21644;&#33539;&#25968;&#20043;&#38388;&#20851;&#31995;&#30340;&#26032;&#26426;&#20250;&#65292;&#20197;&#21450;&#20984;&#38598;&#24494;&#31215;&#20998;&#19979;&#30340;&#25439;&#22833;&#25554;&#20540;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2209.00238</link><description>&lt;p&gt;
&#25439;&#22833;&#30340;&#20960;&#20309;&#21644;&#24494;&#31215;&#20998;
&lt;/p&gt;
&lt;p&gt;
The Geometry and Calculus of Losses. (arXiv:2209.00238v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.00238
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#20984;&#38598;&#30340;&#26032;&#35282;&#24230;&#31995;&#32479;&#22320;&#21457;&#23637;&#20102;&#25439;&#22833;&#20989;&#25968;&#29702;&#35770;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#33258;&#21160;&#21512;&#36866;&#30340;&#25439;&#22833;&#20989;&#25968;&#23450;&#20041;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#25439;&#22833;&#21644;&#33539;&#25968;&#20043;&#38388;&#20851;&#31995;&#30340;&#26032;&#26426;&#20250;&#65292;&#20197;&#21450;&#20984;&#38598;&#24494;&#31215;&#20998;&#19979;&#30340;&#25439;&#22833;&#25554;&#20540;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32479;&#35745;&#20915;&#31574;&#38382;&#39064;&#26159;&#32479;&#35745;&#26426;&#22120;&#23398;&#20064;&#30340;&#26680;&#24515;&#12290;&#26368;&#31616;&#21333;&#30340;&#38382;&#39064;&#26159;&#20108;&#20803;&#21644;&#22810;&#31867;&#20998;&#31867;&#20197;&#21450;&#31867;&#27010;&#29575;&#20272;&#35745;&#12290;&#23427;&#20204;&#30340;&#23450;&#20041;&#30340;&#26680;&#24515;&#26159;&#36873;&#25321;&#25439;&#22833;&#20989;&#25968;&#65292;&#36825;&#26159;&#35780;&#20272;&#35299;&#20915;&#26041;&#26696;&#36136;&#37327;&#30340;&#25163;&#27573;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#19968;&#31181;&#26032;&#39062;&#30340;&#35282;&#24230;&#31995;&#32479;&#22320;&#21457;&#23637;&#20102;&#36825;&#31867;&#38382;&#39064;&#30340;&#25439;&#22833;&#20989;&#25968;&#29702;&#35770;&#65292;&#20854;&#22522;&#26412;&#35201;&#32032;&#26159;&#20855;&#26377;&#29305;&#23450;&#32467;&#26500;&#30340;&#20984;&#38598;&#12290;&#25439;&#22833;&#20989;&#25968;&#34987;&#23450;&#20041;&#20026;&#20984;&#38598;&#30340;&#25903;&#25745;&#20989;&#25968;&#30340;&#27425;&#26799;&#24230;&#12290;&#22240;&#27492;&#65292;&#23427;&#33258;&#21160;&#26159;&#21512;&#36866;&#30340;&#65288;&#29992;&#20110;&#27010;&#29575;&#20272;&#35745;&#65289;&#12290;&#36825;&#31181;&#35270;&#35282;&#25552;&#20379;&#20102;&#19977;&#20010;&#26032;&#39062;&#30340;&#26426;&#20250;&#12290;&#23427;&#20351;&#24471;&#25439;&#22833;&#21644;(&#21453;)&#33539;&#25968;&#20043;&#38388;&#30340;&#22522;&#26412;&#20851;&#31995;&#30340;&#21457;&#23637;&#25104;&#20026;&#21487;&#33021;&#65292;&#36825;&#20284;&#20046;&#20197;&#21069;&#27809;&#26377;&#34987;&#27880;&#24847;&#21040;&#12290;&#20854;&#27425;&#65292;&#23427;&#36890;&#36807;&#20984;&#38598;&#30340;&#24494;&#31215;&#20998;&#20351;&#24471;&#25439;&#22833;&#30340;&#24494;&#31215;&#20998;&#30340;&#21457;&#23637;&#25104;&#20026;&#21487;&#33021;&#65292;&#20174;&#32780;&#20801;&#35768;&#22312;&#19981;&#21516;&#30340;&#25439;&#22833;&#20043;&#38388;&#36827;&#34892;&#25554;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Statistical decision problems lie at the heart of statistical machine learning. The simplest problems are binary and multiclass classification and class probability estimation. Central to their definition is the choice of loss function, which is the means by which the quality of a solution is evaluated. In this paper we systematically develop the theory of loss functions for such problems from a novel perspective whose basic ingredients are convex sets with a particular structure. The loss function is defined as the subgradient of the support function of the convex set. It is consequently automatically proper (calibrated for probability estimation). This perspective provides three novel opportunities. It enables the development of a fundamental relationship between losses and (anti)-norms that appears to have not been noticed before. Second, it enables the development of a calculus of losses induced by the calculus of convex sets which allows the interpolation between different losses,
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#23558;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#31639;&#27861;&#24212;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#65292;&#20197;&#25552;&#39640;&#38754;&#26495;&#25968;&#25454;&#20013;&#30340;&#22240;&#26524;&#25512;&#26029;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#31639;&#27861;&#22312;&#21508;&#31181;&#24773;&#26223;&#19979;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#20026;&#38754;&#26495;&#25968;&#25454;&#30740;&#31350;&#25552;&#20379;&#20102;&#26032;&#30340;&#26041;&#27861;&#21644;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2208.03489</link><description>&lt;p&gt;
&#38754;&#26495;&#25968;&#25454;&#22240;&#26524;&#25512;&#26029;&#30340;&#39044;&#27979;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Forecasting Algorithms for Causal Inference with Panel Data. (arXiv:2208.03489v2 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.03489
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#23558;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#31639;&#27861;&#24212;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#65292;&#20197;&#25552;&#39640;&#38754;&#26495;&#25968;&#25454;&#20013;&#30340;&#22240;&#26524;&#25512;&#26029;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#31639;&#27861;&#22312;&#21508;&#31181;&#24773;&#26223;&#19979;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#20026;&#38754;&#26495;&#25968;&#25454;&#30740;&#31350;&#25552;&#20379;&#20102;&#26032;&#30340;&#26041;&#27861;&#21644;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31038;&#20250;&#31185;&#23398;&#30740;&#31350;&#20013;&#65292;&#20351;&#29992;&#38754;&#26495;&#25968;&#25454;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#26159;&#19968;&#39033;&#26680;&#24515;&#25361;&#25112;&#12290;&#25105;&#20204;&#23558;&#19968;&#31181;&#28145;&#24230;&#31070;&#32463;&#26550;&#26500;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#65288;N-BEATS&#31639;&#27861;&#65289;&#65292;&#20197;&#26356;&#20934;&#30830;&#22320;&#39044;&#27979;&#22312;&#26410;&#36827;&#34892;&#22788;&#29702;&#30340;&#24773;&#20917;&#19979;&#21463;&#27835;&#30103;&#21333;&#20301;&#30340;&#21453;&#20107;&#23454;&#28436;&#21464;&#12290;&#22312;&#21508;&#31181;&#24773;&#22659;&#19979;&#65292;&#25152;&#24471;&#21040;&#30340;&#20272;&#35745;&#22120;&#65288;&#8220;SyNBEATS&#8221;&#65289;&#22312;&#24615;&#33021;&#19978;&#26126;&#26174;&#20248;&#20110;&#24120;&#29992;&#26041;&#27861;&#65288;&#21512;&#25104;&#23545;&#29031;&#27861;&#12289;&#21452;&#21521;&#22266;&#23450;&#25928;&#24212;&#65289;&#65292;&#24182;&#19988;&#19982;&#26368;&#36817;&#25552;&#20986;&#30340;&#26041;&#27861;&#65288;&#21512;&#25104;&#24046;&#24322;&#27861;&#12289;&#30697;&#38453;&#34917;&#20840;&#65289;&#22312;&#20934;&#30830;&#24615;&#19978;&#36798;&#21040;&#20102;&#30456;&#24403;&#30340;&#27700;&#24179;&#25110;&#26356;&#39640;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#31361;&#26174;&#20102;&#22914;&#20309;&#21033;&#29992;&#39044;&#27979;&#25991;&#29486;&#30340;&#36827;&#23637;&#26469;&#25913;&#21892;&#38754;&#26495;&#25968;&#25454;&#29615;&#22659;&#19979;&#30340;&#22240;&#26524;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conducting causal inference with panel data is a core challenge in social science research. We adapt a deep neural architecture for time series forecasting (the N-BEATS algorithm) to more accurately predict the counterfactual evolution of a treated unit had treatment not occurred. Across a range of settings, the resulting estimator ("SyNBEATS") significantly outperforms commonly employed methods (synthetic controls, two-way fixed effects), and attains comparable or more accurate performance compared to recently proposed methods (synthetic difference-in-differences, matrix completion). Our results highlight how advances in the forecasting literature can be harnessed to improve causal inference in panel data settings.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#38754;&#31283;&#20581;&#30340;&#25968;&#25454;&#39537;&#21160;&#20844;&#24335;&#65292;&#33021;&#22815;&#21516;&#26102;&#20445;&#25252;&#19977;&#20010;&#36807;&#25311;&#21512;&#30340;&#28304;&#22836;&#65306;&#26377;&#38480;&#26679;&#26412;&#25968;&#25454;&#30340;&#32479;&#35745;&#35823;&#24046;&#12289;&#25968;&#25454;&#28857;&#30340;&#26377;&#38480;&#31934;&#24230;&#27979;&#37327;&#24341;&#36215;&#30340;&#25968;&#25454;&#22122;&#22768;&#65292;&#20197;&#21450;&#34987;&#30772;&#22351;&#30340;&#37096;&#20998;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2207.09560</link><description>&lt;p&gt;
&#20840;&#38754;&#31283;&#20581;&#30340;&#25968;&#25454;&#39537;&#21160;&#20915;&#31574;
&lt;/p&gt;
&lt;p&gt;
Holistic Robust Data-Driven Decisions. (arXiv:2207.09560v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.09560
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#38754;&#31283;&#20581;&#30340;&#25968;&#25454;&#39537;&#21160;&#20844;&#24335;&#65292;&#33021;&#22815;&#21516;&#26102;&#20445;&#25252;&#19977;&#20010;&#36807;&#25311;&#21512;&#30340;&#28304;&#22836;&#65306;&#26377;&#38480;&#26679;&#26412;&#25968;&#25454;&#30340;&#32479;&#35745;&#35823;&#24046;&#12289;&#25968;&#25454;&#28857;&#30340;&#26377;&#38480;&#31934;&#24230;&#27979;&#37327;&#24341;&#36215;&#30340;&#25968;&#25454;&#22122;&#22768;&#65292;&#20197;&#21450;&#34987;&#30772;&#22351;&#30340;&#37096;&#20998;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35774;&#35745;&#20855;&#26377;&#33391;&#22909;&#26679;&#26412;&#22806;&#24615;&#33021;&#30340;&#26426;&#22120;&#23398;&#20064;&#21644;&#20915;&#31574;&#30340;&#25968;&#25454;&#39537;&#21160;&#20844;&#24335;&#26159;&#19968;&#20010;&#20851;&#38190;&#30340;&#25361;&#25112;&#12290;&#22909;&#30340;&#26679;&#26412;&#20869;&#24615;&#33021;&#19981;&#19968;&#23450;&#33021;&#20445;&#35777;&#22909;&#30340;&#26679;&#26412;&#22806;&#24615;&#33021;&#65292;&#36825;&#34987;&#26222;&#36941;&#35748;&#20026;&#26159;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;&#23454;&#38469;&#30340;&#36807;&#25311;&#21512;&#36890;&#24120;&#19981;&#33021;&#24402;&#22240;&#20110;&#21333;&#19968;&#21407;&#22240;&#65292;&#32780;&#26159;&#30001;&#22810;&#20010;&#22240;&#32032;&#21516;&#26102;&#24341;&#36215;&#30340;&#12290;&#25105;&#20204;&#22312;&#36825;&#37324;&#32771;&#34385;&#20102;&#19977;&#20010;&#36807;&#25311;&#21512;&#30340;&#28304;&#22836;&#65306;&#65288;&#19968;&#65289;&#32479;&#35745;&#35823;&#24046;&#65292;&#30001;&#20110;&#20351;&#29992;&#26377;&#38480;&#30340;&#26679;&#26412;&#25968;&#25454;&#32780;&#20135;&#29983;&#30340;&#35823;&#24046;&#65292;&#65288;&#20108;&#65289;&#25968;&#25454;&#22122;&#22768;&#65292;&#24403;&#25968;&#25454;&#28857;&#21482;&#29992;&#26377;&#38480;&#31934;&#24230;&#27979;&#37327;&#26102;&#20135;&#29983;&#30340;&#22122;&#22768;&#65292;&#65288;&#19977;&#65289;&#25968;&#25454;&#38169;&#35823;&#65292;&#21363;&#20840;&#37096;&#25968;&#25454;&#20013;&#26377;&#19968;&#23567;&#37096;&#20998;&#25968;&#25454;&#34987;&#23436;&#20840;&#30772;&#22351;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#23613;&#31649;&#29616;&#26377;&#30340;&#25968;&#25454;&#39537;&#21160;&#20844;&#24335;&#22312;&#21333;&#29420;&#22788;&#29702;&#36825;&#19977;&#20010;&#28304;&#22836;&#26102;&#21487;&#33021;&#26159;&#31283;&#20581;&#30340;&#65292;&#20294;&#23427;&#20204;&#19981;&#33021;&#21516;&#26102;&#25552;&#20379;&#23545;&#25152;&#26377;&#36807;&#25311;&#21512;&#28304;&#22836;&#30340;&#20840;&#38754;&#20445;&#25252;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25968;&#25454;&#39537;&#21160;&#20844;&#24335;&#65292;&#21487;&#20197;&#20445;&#35777;&#36825;&#31181;&#20840;&#38754;&#20445;&#25252;&#12290;
&lt;/p&gt;
&lt;p&gt;
The design of data-driven formulations for machine learning and decision-making with good out-of-sample performance is a key challenge. The observation that good in-sample performance does not guarantee good out-of-sample performance is generally known as overfitting. Practical overfitting can typically not be attributed to a single cause but instead is caused by several factors all at once. We consider here three overfitting sources: (i) statistical error as a result of working with finite sample data, (ii) data noise which occurs when the data points are measured only with finite precision, and finally (iii) data misspecification in which a small fraction of all data may be wholly corrupted. We argue that although existing data-driven formulations may be robust against one of these three sources in isolation they do not provide holistic protection against all overfitting sources simultaneously. We design a novel data-driven formulation which does guarantee such holistic protection an
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39532;&#23572;&#31185;&#22827;&#39640;&#26031;&#36807;&#31243;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;MGPVAE&#65289;&#27169;&#22411;&#65292;&#36890;&#36807;&#21033;&#29992;&#39532;&#23572;&#31185;&#22827;&#39640;&#26031;&#36807;&#31243;&#30340;&#31561;&#25928;&#31163;&#25955;&#29366;&#24577;&#31354;&#38388;&#34920;&#31034;&#65292;&#24182;&#20351;&#29992;&#21345;&#23572;&#26364;&#28388;&#27874;&#21644;&#24179;&#28369;&#25216;&#26415;&#23454;&#29616;&#20102;&#32447;&#24615;&#26102;&#38388;&#30340;GPVAE&#35757;&#32451;&#12290;&#22312;&#21508;&#31181;&#39640;&#32500;&#26102;&#38388;&#21644;&#26102;&#31354;&#20219;&#21153;&#20013;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2207.05543</link><description>&lt;p&gt;
&#39532;&#23572;&#31185;&#22827;&#39640;&#26031;&#36807;&#31243;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Markovian Gaussian Process Variational Autoencoders. (arXiv:2207.05543v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.05543
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39532;&#23572;&#31185;&#22827;&#39640;&#26031;&#36807;&#31243;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;MGPVAE&#65289;&#27169;&#22411;&#65292;&#36890;&#36807;&#21033;&#29992;&#39532;&#23572;&#31185;&#22827;&#39640;&#26031;&#36807;&#31243;&#30340;&#31561;&#25928;&#31163;&#25955;&#29366;&#24577;&#31354;&#38388;&#34920;&#31034;&#65292;&#24182;&#20351;&#29992;&#21345;&#23572;&#26364;&#28388;&#27874;&#21644;&#24179;&#28369;&#25216;&#26415;&#23454;&#29616;&#20102;&#32447;&#24615;&#26102;&#38388;&#30340;GPVAE&#35757;&#32451;&#12290;&#22312;&#21508;&#31181;&#39640;&#32500;&#26102;&#38388;&#21644;&#26102;&#31354;&#20219;&#21153;&#20013;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#38382;&#39064;&#20013;&#65292;&#24207;&#21015;VAE&#24050;&#32463;&#34987;&#24191;&#27867;&#24212;&#29992;&#65292;&#20854;&#20013;&#35768;&#22810;&#21464;&#31181;&#27169;&#22411;&#20381;&#36182;&#20110;&#31163;&#25955;&#26102;&#38388;&#26426;&#21046;&#65292;&#22914;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65288;RNN&#65289;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#36830;&#32493;&#26102;&#38388;&#26041;&#27861;&#26368;&#36817;&#22312;&#38750;&#35268;&#21017;&#37319;&#26679;&#26102;&#38388;&#24207;&#21015;&#30340;&#32972;&#26223;&#19979;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20852;&#36259;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#23427;&#20204;&#21487;&#20197;&#26356;&#22909;&#22320;&#22788;&#29702;&#25968;&#25454;&#12290;&#20854;&#20013;&#19968;&#31181;&#26159;&#39640;&#26031;&#36807;&#31243;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;GPVAEs&#65289;&#65292;&#20854;&#20013;VAE&#20808;&#39564;&#34987;&#35774;&#32622;&#20026;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#12290;&#28982;&#32780;&#65292;GPVAEs&#30340;&#19968;&#20010;&#20027;&#35201;&#38480;&#21046;&#26159;&#23427;&#32487;&#25215;&#20102;&#39640;&#26031;&#36807;&#31243;&#30340;&#31435;&#26041;&#35745;&#31639;&#25104;&#26412;&#65292;&#20351;&#20854;&#23545;&#23454;&#38469;&#24212;&#29992;&#32773;&#19981;&#22826;&#21560;&#24341;&#20154;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#39532;&#23572;&#31185;&#22827;&#39640;&#26031;&#36807;&#31243;&#30340;&#31561;&#25928;&#31163;&#25955;&#29366;&#24577;&#31354;&#38388;&#34920;&#31034;&#65292;&#36890;&#36807;&#21345;&#23572;&#26364;&#28388;&#27874;&#21644;&#24179;&#28369;&#26469;&#23454;&#29616;&#32447;&#24615;&#26102;&#38388;&#30340;GPVAE&#35757;&#32451;&#12290;&#23545;&#20110;&#25105;&#20204;&#30340;&#27169;&#22411;&#65292;&#39532;&#23572;&#21487;&#22827;&#39640;&#26031;&#36807;&#31243;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;MGPVAE&#65289;&#65292;&#25105;&#20204;&#22312;&#21508;&#31181;&#39640;&#32500;&#26102;&#38388;&#21644;&#26102;&#31354;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#21033;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential VAEs have been successfully considered for many high-dimensional time series modelling problems, with many variant models relying on discrete-time mechanisms such as recurrent neural networks (RNNs). On the other hand, continuous-time methods have recently gained attraction, especially in the context of irregularly-sampled time series, where they can better handle the data than discrete-time methods. One such class are Gaussian process variational autoencoders (GPVAEs), where the VAE prior is set as a Gaussian process (GP). However, a major limitation of GPVAEs is that it inherits the cubic computational cost as GPs, making it unattractive to practioners. In this work, we leverage the equivalent discrete state space representation of Markovian GPs to enable linear time GPVAE training via Kalman filtering and smoothing. For our model, Markovian GPVAE (MGPVAE), we show on a variety of high-dimensional temporal and spatiotemporal tasks that our method performs favourably compar
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#26497;&#38480;&#19979;&#20855;&#26377;&#24658;&#23450;&#27493;&#38271;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65288;SGD&#65289;&#30340;&#21487;&#25193;&#23637;&#26497;&#38480;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#32500;&#24230;&#36235;&#20110;&#26080;&#31351;&#26102;&#65292;SGD&#30340;&#36712;&#36857;&#30340;&#26497;&#38480;&#23450;&#29702;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#36873;&#25321;&#35201;&#36319;&#36394;&#30340;&#24635;&#32467;&#32479;&#35745;&#37327;&#12289;&#21021;&#22987;&#21270;&#21644;&#27493;&#38271;&#65292;&#24182;&#19988;&#24471;&#21040;&#20102;&#29699;&#24418;&#65288;ODE&#65289;&#21644;&#25193;&#25955;&#65288;SDE&#65289;&#26497;&#38480;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#27493;&#38271;&#30340;&#20020;&#30028;&#23610;&#24230;&#65292;&#36825;&#20010;&#23610;&#24230;&#19979;&#65292;&#26377;&#25928;&#30340;&#29699;&#24418;&#21160;&#21147;&#23398;&#19982;&#26799;&#24230;&#27969;&#30456;&#21305;&#37197;&#65292;&#20294;&#26159;&#20986;&#29616;&#20102;&#19968;&#20010;&#26032;&#30340;&#20462;&#27491;&#39033;&#65292;&#25913;&#21464;&#20102;&#30456;&#22270;&#12290;&#36825;&#20010;&#26377;&#25928;&#21160;&#21147;&#23398;&#30340;&#19981;&#21160;&#28857;&#23545;&#24212;&#30340;&#25193;&#25955;&#26497;&#38480;&#21487;&#33021;&#38750;&#24120;&#22797;&#26434;&#12290;</title><link>http://arxiv.org/abs/2206.04030</link><description>&lt;p&gt;
SGD&#30340;&#39640;&#32500;&#26497;&#38480;&#23450;&#29702;&#65306;&#26377;&#25928;&#21160;&#21147;&#23398;&#21644;&#20020;&#30028;&#23610;&#24230;
&lt;/p&gt;
&lt;p&gt;
High-dimensional limit theorems for SGD: Effective dynamics and critical scaling. (arXiv:2206.04030v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.04030
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#26497;&#38480;&#19979;&#20855;&#26377;&#24658;&#23450;&#27493;&#38271;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65288;SGD&#65289;&#30340;&#21487;&#25193;&#23637;&#26497;&#38480;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#32500;&#24230;&#36235;&#20110;&#26080;&#31351;&#26102;&#65292;SGD&#30340;&#36712;&#36857;&#30340;&#26497;&#38480;&#23450;&#29702;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#36873;&#25321;&#35201;&#36319;&#36394;&#30340;&#24635;&#32467;&#32479;&#35745;&#37327;&#12289;&#21021;&#22987;&#21270;&#21644;&#27493;&#38271;&#65292;&#24182;&#19988;&#24471;&#21040;&#20102;&#29699;&#24418;&#65288;ODE&#65289;&#21644;&#25193;&#25955;&#65288;SDE&#65289;&#26497;&#38480;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#27493;&#38271;&#30340;&#20020;&#30028;&#23610;&#24230;&#65292;&#36825;&#20010;&#23610;&#24230;&#19979;&#65292;&#26377;&#25928;&#30340;&#29699;&#24418;&#21160;&#21147;&#23398;&#19982;&#26799;&#24230;&#27969;&#30456;&#21305;&#37197;&#65292;&#20294;&#26159;&#20986;&#29616;&#20102;&#19968;&#20010;&#26032;&#30340;&#20462;&#27491;&#39033;&#65292;&#25913;&#21464;&#20102;&#30456;&#22270;&#12290;&#36825;&#20010;&#26377;&#25928;&#21160;&#21147;&#23398;&#30340;&#19981;&#21160;&#28857;&#23545;&#24212;&#30340;&#25193;&#25955;&#26497;&#38480;&#21487;&#33021;&#38750;&#24120;&#22797;&#26434;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#26497;&#38480;&#19979;&#65292;&#20855;&#26377;&#24658;&#23450;&#27493;&#38271;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#21487;&#25193;&#23637;&#26497;&#38480;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;SGD&#30340;&#24635;&#32467;&#32479;&#35745;&#36712;&#36857;&#65288;&#21363;&#26377;&#38480;&#32500;&#20989;&#25968;&#65289;&#22312;&#32500;&#24230;&#36235;&#20110;&#26080;&#31351;&#22823;&#26102;&#30340;&#26497;&#38480;&#23450;&#29702;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#36873;&#25321;&#35201;&#36319;&#36394;&#30340;&#24635;&#32467;&#32479;&#35745;&#37327;&#12289;&#21021;&#22987;&#21270;&#21644;&#27493;&#38271;&#12290;&#23427;&#20135;&#29983;&#20102;&#19968;&#20010;&#22312;&#21069;&#36848;&#36873;&#25321;&#19978;&#26497;&#20854;&#20381;&#36182;&#30340;&#29699;&#24418;&#65288;ODE&#65289;&#21644;&#25193;&#25955;&#65288;SDE&#65289;&#26497;&#38480;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#27493;&#38271;&#30340;&#20020;&#30028;&#23610;&#24230;&#65292;&#20302;&#20110;&#36825;&#20010;&#23610;&#24230;&#65292;&#26377;&#25928;&#30340;&#29699;&#24418;&#21160;&#21147;&#23398;&#19982;&#20154;&#21475;&#25439;&#22833;&#30340;&#26799;&#24230;&#27969;&#30456;&#21305;&#37197;&#65292;&#20294;&#22312;&#36825;&#20010;&#23610;&#24230;&#19978;&#65292;&#20986;&#29616;&#20102;&#19968;&#20010;&#26032;&#30340;&#20462;&#27491;&#39033;&#65292;&#25913;&#21464;&#20102;&#30456;&#22270;&#12290;&#20851;&#20110;&#36825;&#20010;&#26377;&#25928;&#21160;&#21147;&#23398;&#30340;&#19981;&#21160;&#28857;&#65292;&#30456;&#24212;&#30340;&#25193;&#25955;&#26497;&#38480;&#21487;&#33021;&#38750;&#24120;&#22797;&#26434;&#29978;&#33267;&#36864;&#21270;&#12290;&#25105;&#20204;&#22312;&#19968;&#20123;&#27969;&#34892;&#30340;&#20363;&#23376;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#23574;&#23792;&#30697;&#38453;&#21644;&#24352;&#37327;&#27169;&#22411;&#30340;&#20272;&#35745;&#20197;&#21450;&#36890;&#36807;&#20004;&#23618;&#32593;&#32476;&#36827;&#34892;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the scaling limits of stochastic gradient descent (SGD) with constant step-size in the high-dimensional regime. We prove limit theorems for the trajectories of summary statistics (i.e., finite-dimensional functions) of SGD as the dimension goes to infinity. Our approach allows one to choose the summary statistics that are tracked, the initialization, and the step-size. It yields both ballistic (ODE) and diffusive (SDE) limits, with the limit depending dramatically on the former choices. We show a critical scaling regime for the step-size, below which the effective ballistic dynamics matches gradient flow for the population loss, but at which, a new correction term appears which changes the phase diagram. About the fixed points of this effective dynamics, the corresponding diffusive limits can be quite complex and even degenerate. We demonstrate our approach on popular examples including estimation for spiked matrix and tensor models and classification via two-layer networks fo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32593;&#32476;&#32467;&#26500;&#30340;&#23616;&#37096;&#33258;&#36866;&#24212;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#23558;LD&#32593;&#32476;&#25968;&#25454;&#21644;&#22810;&#20010;&#26679;&#26412;&#30340;&#36741;&#21161;&#25968;&#25454;&#25972;&#21512;&#36215;&#26469;&#65292;&#36890;&#36807;&#25968;&#25454;&#39537;&#21160;&#30340;&#26435;&#37325;&#20998;&#37197;&#26041;&#27861;&#23454;&#29616;&#23545;&#22810;&#37325;&#26816;&#39564;&#30340;&#25511;&#21046;&#65292;&#24182;&#22312;&#32593;&#32476;&#25968;&#25454;&#20855;&#26377;&#20449;&#24687;&#37327;&#26102;&#20855;&#26377;&#26356;&#39640;&#30340;&#21151;&#25928;&#12290;</title><link>http://arxiv.org/abs/2203.11461</link><description>&lt;p&gt;
&#22522;&#20110;&#32593;&#32476;&#32467;&#26500;&#30340;&#23616;&#37096;&#33258;&#36866;&#24212;&#22810;&#37325;&#26816;&#39564;&#31639;&#27861;&#65292;&#21450;&#20854;&#22312;&#20840;&#22522;&#22240;&#32452;&#20851;&#32852;&#30740;&#31350;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Locally Adaptive Algorithms for Multiple Testing with Network Structure, with Application to Genome-Wide Association Studies. (arXiv:2203.11461v4 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.11461
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32593;&#32476;&#32467;&#26500;&#30340;&#23616;&#37096;&#33258;&#36866;&#24212;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#23558;LD&#32593;&#32476;&#25968;&#25454;&#21644;&#22810;&#20010;&#26679;&#26412;&#30340;&#36741;&#21161;&#25968;&#25454;&#25972;&#21512;&#36215;&#26469;&#65292;&#36890;&#36807;&#25968;&#25454;&#39537;&#21160;&#30340;&#26435;&#37325;&#20998;&#37197;&#26041;&#27861;&#23454;&#29616;&#23545;&#22810;&#37325;&#26816;&#39564;&#30340;&#25511;&#21046;&#65292;&#24182;&#22312;&#32593;&#32476;&#25968;&#25454;&#20855;&#26377;&#20449;&#24687;&#37327;&#26102;&#20855;&#26377;&#26356;&#39640;&#30340;&#21151;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38142;&#25509;&#20998;&#26512;&#22312;&#20840;&#22522;&#22240;&#32452;&#20851;&#32852;&#30740;&#31350;&#20013;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#65292;&#29305;&#21035;&#26159;&#22312;&#25581;&#31034;&#19982;&#30142;&#30149;&#34920;&#22411;&#30456;&#20851;&#30340;&#36830;&#38145;&#19981;&#24179;&#34913;&#65288;LD&#65289;&#30340;SNP&#20849;&#21516;&#24433;&#21709;&#26041;&#38754;&#12290;&#28982;&#32780;&#65292;LD&#32593;&#32476;&#25968;&#25454;&#30340;&#28508;&#21147;&#22312;&#25991;&#29486;&#20013;&#24448;&#24448;&#34987;&#24573;&#35270;&#25110;&#26410;&#20805;&#20998;&#21033;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23616;&#37096;&#33258;&#36866;&#24212;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#65288;LASLA&#65289;&#65292;&#20026;&#25972;&#21512;&#32593;&#32476;&#25968;&#25454;&#25110;&#26469;&#33258;&#30456;&#20851;&#28304;&#22495;&#30340;&#22810;&#20010;&#26679;&#26412;&#30340;&#36741;&#21161;&#25968;&#25454;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#21407;&#21017;&#19988;&#36890;&#29992;&#30340;&#26694;&#26550;&#65307;&#21487;&#33021;&#20855;&#26377;&#19981;&#21516;&#30340;&#32500;&#24230;/&#32467;&#26500;&#21644;&#19981;&#21516;&#30340;&#20154;&#32676;&#12290;LASLA&#37319;&#29992;$p$&#20540;&#21152;&#26435;&#26041;&#27861;&#65292;&#21033;&#29992;&#32467;&#26500;&#27934;&#23519;&#21147;&#20026;&#21508;&#20010;&#26816;&#39564;&#28857;&#20998;&#37197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26435;&#37325;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#24403;&#20027;&#35201;&#32479;&#35745;&#37327;&#29420;&#31435;&#25110;&#24369;&#30456;&#20851;&#26102;&#65292;LASLA&#21487;&#20197;&#28176;&#36817;&#22320;&#25511;&#21046;FDR&#65292;&#24182;&#22312;&#32593;&#32476;&#25968;&#25454;&#20855;&#26377;&#20449;&#24687;&#37327;&#26102;&#23454;&#29616;&#26356;&#39640;&#30340;&#21151;&#25928;&#12290;&#36890;&#36807;&#21508;&#31181;&#21512;&#25104;&#23454;&#39564;&#21644;&#19968;&#20010;&#24212;&#29992;&#26696;&#20363;&#65292;&#23637;&#31034;&#20102;LASLA&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Linkage analysis has provided valuable insights to the GWAS studies, particularly in revealing that SNPs in linkage disequilibrium (LD) can jointly influence disease phenotypes. However, the potential of LD network data has often been overlooked or underutilized in the literature. In this paper, we propose a locally adaptive structure learning algorithm (LASLA) that provides a principled and generic framework for incorporating network data or multiple samples of auxiliary data from related source domains; possibly in different dimensions/structures and from diverse populations. LASLA employs a $p$-value weighting approach, utilizing structural insights to assign data-driven weights to individual test points. Theoretical analysis shows that LASLA can asymptotically control FDR with independent or weakly dependent primary statistics, and achieve higher power when the network data is informative. Efficiency again of LASLA is illustrated through various synthetic experiments and an applica
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#25968;&#25454;&#32452;&#21512;&#35299;&#20915;&#20102;&#38271;&#26399;&#27835;&#30103;&#25928;&#26524;&#35782;&#21035;&#21644;&#20272;&#35745;&#20013;&#30340;&#25345;&#32493;&#26410;&#27979;&#37327;&#28151;&#28102;&#22240;&#32032;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#19977;&#31181;&#26032;&#30340;&#35782;&#21035;&#31574;&#30053;&#21644;&#20272;&#35745;&#22120;&#12290;</title><link>http://arxiv.org/abs/2202.07234</link><description>&lt;p&gt;
&#38271;&#26399;&#25345;&#32493;&#28151;&#28102;&#24773;&#20917;&#19979;&#30340;&#22240;&#26524;&#25512;&#26029;&#19982;&#25968;&#25454;&#32452;&#21512;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Long-term Causal Inference Under Persistent Confounding via Data Combination. (arXiv:2202.07234v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.07234
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#25968;&#25454;&#32452;&#21512;&#35299;&#20915;&#20102;&#38271;&#26399;&#27835;&#30103;&#25928;&#26524;&#35782;&#21035;&#21644;&#20272;&#35745;&#20013;&#30340;&#25345;&#32493;&#26410;&#27979;&#37327;&#28151;&#28102;&#22240;&#32032;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#19977;&#31181;&#26032;&#30340;&#35782;&#21035;&#31574;&#30053;&#21644;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#24403;&#23454;&#39564;&#25968;&#25454;&#21644;&#35266;&#23519;&#25968;&#25454;&#21516;&#26102;&#23384;&#22312;&#26102;&#65292;&#38271;&#26399;&#27835;&#30103;&#25928;&#26524;&#30340;&#35782;&#21035;&#21644;&#20272;&#35745;&#38382;&#39064;&#12290;&#30001;&#20110;&#38271;&#26399;&#32467;&#26524;&#20165;&#22312;&#38271;&#26102;&#38388;&#24310;&#36831;&#21518;&#25165;&#35266;&#23519;&#21040;&#65292;&#22312;&#23454;&#39564;&#25968;&#25454;&#20013;&#26080;&#27861;&#27979;&#37327;&#65292;&#20294;&#22312;&#35266;&#23519;&#25968;&#25454;&#20013;&#26377;&#35760;&#24405;&#12290;&#28982;&#32780;&#65292;&#36825;&#20004;&#31181;&#31867;&#22411;&#30340;&#25968;&#25454;&#37117;&#21253;&#21547;&#23545;&#19968;&#20123;&#30701;&#26399;&#32467;&#26524;&#30340;&#35266;&#23519;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#29420;&#29305;&#22320;&#35299;&#20915;&#20102;&#25345;&#32493;&#26410;&#27979;&#37327;&#28151;&#28102;&#22240;&#32032;&#30340;&#25361;&#25112;&#65292;&#21363;&#19968;&#20123;&#26410;&#27979;&#37327;&#28151;&#28102;&#22240;&#32032;&#21487;&#20197;&#21516;&#26102;&#24433;&#21709;&#27835;&#30103;&#12289;&#30701;&#26399;&#32467;&#26524;&#21644;&#38271;&#26399;&#32467;&#26524;&#65292;&#32780;&#36825;&#20250;&#20351;&#24471;&#20043;&#21069;&#25991;&#29486;&#20013;&#30340;&#35782;&#21035;&#31574;&#30053;&#26080;&#25928;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#21033;&#29992;&#22810;&#20010;&#30701;&#26399;&#32467;&#26524;&#30340;&#36830;&#32493;&#32467;&#26500;&#65292;&#20026;&#24179;&#22343;&#38271;&#26399;&#27835;&#30103;&#25928;&#26524;&#25552;&#20986;&#20102;&#19977;&#31181;&#26032;&#30340;&#35782;&#21035;&#31574;&#30053;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19977;&#31181;&#23545;&#24212;&#30340;&#20272;&#35745;&#22120;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#28176;&#36817;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#20272;&#35745;&#38271;&#26399;&#27835;&#30103;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the identification and estimation of long-term treatment effects when both experimental and observational data are available. Since the long-term outcome is observed only after a long delay, it is not measured in the experimental data, but only recorded in the observational data. However, both types of data include observations of some short-term outcomes. In this paper, we uniquely tackle the challenge of persistent unmeasured confounders, i.e., some unmeasured confounders that can simultaneously affect the treatment, short-term outcomes and the long-term outcome, noting that they invalidate identification strategies in previous literature. To address this challenge, we exploit the sequential structure of multiple short-term outcomes, and develop three novel identification strategies for the average long-term treatment effect. We further propose three corresponding estimators and prove their asymptotic consistency and asymptotic normality. We finally apply our methods to esti
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#26368;&#23567;&#21270;&#26368;&#22823;&#21270;&#39118;&#38505;&#20998;&#31867;&#22120;&#65288;MRCs&#65289;&#65292;&#26088;&#22312;&#36890;&#36807;&#26368;&#23567;&#21270;&#19982;&#21487;&#33021;&#21253;&#21547;&#22522;&#30784;&#20998;&#24067;&#30340;&#20998;&#24067;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#30456;&#23545;&#24212;&#30340;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;0-1&#25439;&#22833;&#26469;&#25552;&#20379;&#20005;&#26684;&#30340;&#24615;&#33021;&#20445;&#35777;&#12290;&#20351;&#29992;&#29305;&#24449;&#26144;&#23556;&#21644;&#29305;&#24449;&#26680;&#65292;MRCs&#22312;&#23398;&#20064;&#26102;&#20855;&#26377;&#24378;&#24230;&#26222;&#36941;&#19968;&#33268;&#24615;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#39640;&#25928;&#30340;&#20248;&#21270;&#25216;&#26415;&#21644;&#20934;&#30830;&#30340;&#20998;&#31867;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2201.06487</link><description>&lt;p&gt;
&#26368;&#23567;&#21270;&#26368;&#22823;&#21270;&#39118;&#38505;&#20998;&#31867;&#22120;&#19982;0-1&#25439;&#22833;
&lt;/p&gt;
&lt;p&gt;
Minimax risk classifiers with 0-1 loss. (arXiv:2201.06487v6 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.06487
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#26368;&#23567;&#21270;&#26368;&#22823;&#21270;&#39118;&#38505;&#20998;&#31867;&#22120;&#65288;MRCs&#65289;&#65292;&#26088;&#22312;&#36890;&#36807;&#26368;&#23567;&#21270;&#19982;&#21487;&#33021;&#21253;&#21547;&#22522;&#30784;&#20998;&#24067;&#30340;&#20998;&#24067;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#30456;&#23545;&#24212;&#30340;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;0-1&#25439;&#22833;&#26469;&#25552;&#20379;&#20005;&#26684;&#30340;&#24615;&#33021;&#20445;&#35777;&#12290;&#20351;&#29992;&#29305;&#24449;&#26144;&#23556;&#21644;&#29305;&#24449;&#26680;&#65292;MRCs&#22312;&#23398;&#20064;&#26102;&#20855;&#26377;&#24378;&#24230;&#26222;&#36941;&#19968;&#33268;&#24615;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#39640;&#25928;&#30340;&#20248;&#21270;&#25216;&#26415;&#21644;&#20934;&#30830;&#30340;&#20998;&#31867;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30417;&#30563;&#20998;&#31867;&#25216;&#26415;&#20351;&#29992;&#35757;&#32451;&#26679;&#26412;&#26469;&#23398;&#20064;&#19968;&#31181;&#20855;&#26377;&#23567;&#26399;&#26395;0-1&#25439;&#22833;&#65288;&#38169;&#35823;&#27010;&#29575;&#65289;&#30340;&#20998;&#31867;&#35268;&#21017;&#12290;&#20256;&#32479;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#20195;&#29702;&#25439;&#22833;&#32780;&#19981;&#26159;0-1&#25439;&#22833;&#65292;&#24182;&#32771;&#34385;&#29305;&#23450;&#30340;&#35268;&#21017;&#26063;&#65288;&#20551;&#35774;&#31867;&#65289;&#26469;&#23454;&#29616;&#21487;&#35745;&#31639;&#30340;&#23398;&#20064;&#21644;&#26679;&#26412;&#22806;&#27867;&#21270;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#26368;&#23567;&#21270;&#26368;&#22823;&#21270;&#39118;&#38505;&#20998;&#31867;&#22120;&#65288;MRCs&#65289;&#65292;&#23427;&#20204;&#26368;&#23567;&#21270;&#19982;&#21487;&#20197;&#21253;&#21547;&#22522;&#30784;&#20998;&#24067;&#30340;&#20998;&#24067;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#30456;&#23545;&#24212;&#30340;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;0-1&#25439;&#22833;&#65292;&#20855;&#26377;&#21487;&#35843;&#30340;&#32622;&#20449;&#24230;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;MRCs&#21487;&#20197;&#22312;&#23398;&#20064;&#26102;&#25552;&#20379;&#20005;&#26684;&#30340;&#24615;&#33021;&#20445;&#35777;&#65292;&#24182;&#19988;&#20351;&#29992;&#30001;&#29305;&#24449;&#26144;&#23556;&#32473;&#20986;&#30340;&#29305;&#24449;&#26680;&#26159;&#24378;&#24230;&#26222;&#36941;&#19968;&#33268;&#30340;&#12290;&#26412;&#25991;&#36824;&#25552;&#20986;&#20102;MRC&#23398;&#20064;&#30340;&#39640;&#25928;&#20248;&#21270;&#25216;&#26415;&#65292;&#24182;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#23454;&#36341;&#20013;&#21487;&#20197;&#25552;&#20379;&#20934;&#30830;&#30340;&#20998;&#31867;&#21644;&#20005;&#26684;&#30340;&#24615;&#33021;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Supervised classification techniques use training samples to learn a classification rule with small expected 0-1 loss (error probability). Conventional methods enable tractable learning and provide out-of-sample generalization by using surrogate losses instead of the 0-1 loss and considering specific families of rules (hypothesis classes). This paper presents minimax risk classifiers (MRCs) that minize the worst-case 0-1 loss with respect to uncertainty sets of distributions that can include the underlying distribution, with a tunable confidence. We show that MRCs can provide tight performance guarantees at learning and are strongly universally consistent using feature mappings given by characteristic kernels. The paper also proposes efficient optimization techniques for MRC learning and shows that the methods presented can provide accurate classification together with tight performance guarantees in practice.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#12289;&#19981;&#38656;&#35201;&#35843;&#25972;&#25351;&#25968;&#21442;&#25968;&#30340;MNL-Contextual Bandit&#38382;&#39064;&#30340;&#31616;&#20415;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#12290;&#31639;&#27861;&#20855;&#26377;&#19982;&#35813;&#38382;&#39064;&#30340;&#26368;&#20339;&#29702;&#35770;&#30028;&#38480;&#21305;&#37197;&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2011.14033</link><description>&lt;p&gt;
MNL&#19978;&#19979;&#25991;Bandit&#38382;&#39064;&#30340;&#31616;&#20415;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Tractable Online Learning Algorithm for the Multinomial Logit Contextual Bandit. (arXiv:2011.14033v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2011.14033
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#12289;&#19981;&#38656;&#35201;&#35843;&#25972;&#25351;&#25968;&#21442;&#25968;&#30340;MNL-Contextual Bandit&#38382;&#39064;&#30340;&#31616;&#20415;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#12290;&#31639;&#27861;&#20855;&#26377;&#19982;&#35813;&#38382;&#39064;&#30340;&#26368;&#20339;&#29702;&#35770;&#30028;&#38480;&#21305;&#37197;&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;MNL-Bandit&#38382;&#39064;&#30340;&#19978;&#19979;&#25991;&#21464;&#20307;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#21160;&#24577;&#38598;&#21512;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#20915;&#31574;&#32773;&#21521;&#28040;&#36153;&#32773;&#25552;&#20379;&#19968;&#32452;&#20135;&#21697;&#65288;&#36141;&#29289;&#28165;&#21333;&#65289;&#65292;&#24182;&#22312;&#27599;&#20010;&#22238;&#21512;&#35266;&#23519;&#21709;&#24212;&#12290;&#28040;&#36153;&#32773;&#36141;&#20080;&#20135;&#21697;&#20197;&#26368;&#22823;&#21270;&#20182;&#20204;&#30340;&#25928;&#29992;&#12290;&#25105;&#20204;&#20551;&#35774;&#19968;&#32452;&#23646;&#24615;&#25551;&#36848;&#20102;&#20135;&#21697;&#65292;&#20135;&#21697;&#30340;&#24179;&#22343;&#25928;&#29992;&#19982;&#36825;&#20123;&#23646;&#24615;&#30340;&#20540;&#21576;&#32447;&#24615;&#20851;&#31995;&#12290;&#25105;&#20204;&#20351;&#29992;&#24191;&#27867;&#20351;&#29992;&#30340;Multinomial Logit&#65288;MNL&#65289;&#27169;&#22411;&#24314;&#27169;&#28040;&#36153;&#32773;&#36873;&#25321;&#34892;&#20026;&#65292;&#24182;&#32771;&#34385;&#22312;&#20248;&#21270;&#38144;&#21806;&#21608;&#26399;$T$&#20869;&#32047;&#31215;&#25910;&#30410;&#30340;&#21516;&#26102;&#21160;&#24577;&#23398;&#20064;&#27169;&#22411;&#21442;&#25968;&#30340;&#20915;&#31574;&#32773;&#38382;&#39064;&#12290;&#23613;&#31649;&#36825;&#20010;&#38382;&#39064;&#36817;&#26469;&#24341;&#36215;&#20102;&#30456;&#24403;&#22823;&#30340;&#20851;&#27880;&#65292;&#20294;&#35768;&#22810;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#28041;&#21450;&#35299;&#20915;&#19968;&#20010;&#38590;&#20197;&#22788;&#29702;&#30340;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#20182;&#20204;&#30340;&#29702;&#35770;&#24615;&#33021;&#20445;&#35777;&#21462;&#20915;&#20110;&#19968;&#20010;&#21487;&#33021;&#38750;&#24120;&#22823;&#30340;&#38382;&#39064;&#30456;&#20851;&#21442;&#25968;&#12290;&#29305;&#21035;&#22320;&#65292;&#29616;&#26377;&#26041;&#27861;&#38656;&#35201;&#35843;&#25972;&#38543;&#30528;&#23646;&#24615;&#38598;&#35268;&#27169;&#25351;&#25968;&#22686;&#38271;&#30340;&#35843;&#25972;&#21442;&#25968;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;MNL-Contextual Bandit&#38382;&#39064;&#30340;&#31616;&#20415;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#23427;&#19981;&#38656;&#35201;&#35843;&#25972;&#27492;&#31867;&#25351;&#25968;&#21442;&#25968;&#12290;&#25105;&#20204;&#23637;&#31034;&#25105;&#20204;&#30340;&#31639;&#27861;&#20855;&#26377;&#19982;&#35813;&#38382;&#39064;&#30340;&#26368;&#20339;&#29702;&#35770;&#30028;&#38480;&#21305;&#37197;&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#27169;&#25311;&#21644;&#30495;&#23454;&#19990;&#30028;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider the contextual variant of the MNL-Bandit problem. More specifically, we consider a dynamic set optimization problem, where a decision-maker offers a subset (assortment) of products to a consumer and observes the response in every round. Consumers purchase products to maximize their utility. We assume that a set of attributes describe the products, and the mean utility of a product is linear in the values of these attributes. We model consumer choice behavior using the widely used Multinomial Logit (MNL) model and consider the decision maker problem of dynamically learning the model parameters while optimizing cumulative revenue over the selling horizon $T$. Though this problem has attracted considerable attention in recent times, many existing methods often involve solving an intractable non-convex optimization problem. Their theoretical performance guarantees depend on a problem-dependent parameter which could be prohibitively large. In particular, existing 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#21033;&#29992;&#23616;&#37096;&#20989;&#25968;&#22797;&#26434;&#24615;&#65288;LFC&#65289;&#30340;&#20272;&#35745;&#65292;&#24314;&#31435;&#20102;&#19968;&#20010;&#23616;&#37096;&#32467;&#26500;&#22797;&#26434;&#24615;&#30340;&#27010;&#24565;&#65292;&#24182;&#23558;&#20854;&#29992;&#20110;&#21457;&#23637;&#19968;&#20010;&#19982;&#27169;&#22411;&#26080;&#20851;&#30340;&#20027;&#21160;&#23398;&#20064;&#26694;&#26550;&#12290;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#65288;GPR&#65289;&#30340;&#23616;&#37096;&#22810;&#39033;&#24335;&#24179;&#28369;&#65288;LPS&#65289;&#27169;&#22411;&#30340;&#31867;&#27604;&#65292;&#20351;&#24471;&#35813;&#26694;&#26550;&#20855;&#26377;&#40065;&#26834;&#24615;&#21644;&#21487;&#20280;&#32553;&#24615;&#12290;</title><link>http://arxiv.org/abs/1902.10664</link><description>&lt;p&gt;
&#36890;&#36807;&#39640;&#26031;&#36807;&#31243;&#28151;&#21512;&#23454;&#29616;&#20027;&#21160;&#23398;&#20064;&#20013;&#30340;&#23616;&#37096;&#20989;&#25968;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
Local Function Complexity for Active Learning via Mixture of Gaussian Processes. (arXiv:1902.10664v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1902.10664
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#21033;&#29992;&#23616;&#37096;&#20989;&#25968;&#22797;&#26434;&#24615;&#65288;LFC&#65289;&#30340;&#20272;&#35745;&#65292;&#24314;&#31435;&#20102;&#19968;&#20010;&#23616;&#37096;&#32467;&#26500;&#22797;&#26434;&#24615;&#30340;&#27010;&#24565;&#65292;&#24182;&#23558;&#20854;&#29992;&#20110;&#21457;&#23637;&#19968;&#20010;&#19982;&#27169;&#22411;&#26080;&#20851;&#30340;&#20027;&#21160;&#23398;&#20064;&#26694;&#26550;&#12290;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#65288;GPR&#65289;&#30340;&#23616;&#37096;&#22810;&#39033;&#24335;&#24179;&#28369;&#65288;LPS&#65289;&#27169;&#22411;&#30340;&#31867;&#27604;&#65292;&#20351;&#24471;&#35813;&#26694;&#26550;&#20855;&#26377;&#40065;&#26834;&#24615;&#21644;&#21487;&#20280;&#32553;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#30340;&#19981;&#22343;&#21248;&#24615;&#65292;&#20363;&#22914;&#35266;&#27979;&#22122;&#22768;&#27700;&#24179;&#30340;&#21464;&#21270;&#25110;&#28304;&#20989;&#25968;&#32467;&#26500;&#22797;&#26434;&#24615;&#30340;&#21464;&#21270;&#65292;&#32473;&#32479;&#35745;&#25512;&#26029;&#24102;&#26469;&#20102;&#19968;&#31995;&#21015;&#29420;&#29305;&#30340;&#25361;&#25112;&#12290;&#32771;&#34385;&#21040;&#36825;&#20123;&#22240;&#32032;&#21487;&#20197;&#22312;&#29289;&#29702;&#36164;&#28304;&#25110;&#35745;&#31639;&#26102;&#38388;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#26174;&#33879;&#25552;&#39640;&#39044;&#27979;&#33021;&#21147;&#12290;&#26412;&#25991;&#20511;&#37492;&#20102;&#26368;&#36817;&#20851;&#20110;&#23616;&#37096;&#22810;&#39033;&#24335;&#24179;&#28369;&#65288;LPS&#65289;&#39046;&#22495;&#20013;&#23616;&#37096;&#20989;&#25968;&#22797;&#26434;&#24615;&#65288;LFC&#65289;&#30340;&#20272;&#35745;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#24314;&#31435;&#20102;&#19968;&#20010;&#23616;&#37096;&#32467;&#26500;&#22797;&#26434;&#24615;&#30340;&#27010;&#24565;&#65292;&#24182;&#29992;&#23427;&#26469;&#24320;&#21457;&#19968;&#20010;&#19982;&#27169;&#22411;&#26080;&#20851;&#30340;&#20027;&#21160;&#23398;&#20064;&#65288;AL&#65289;&#26694;&#26550;&#12290;&#30001;&#20110;&#20854;&#20381;&#36182;&#20110;&#28857;&#20272;&#35745;&#65292;LPS&#27169;&#22411;&#31867;&#22312;&#22788;&#29702;&#36890;&#24120;&#20276;&#38543;&#30495;&#23454;&#19990;&#30028;&#38382;&#39064;&#30340;&#22823;&#36755;&#20837;&#31354;&#38388;&#32500;&#24230;&#26102;&#19981;&#20855;&#26377;&#40065;&#26834;&#24615;&#21644;&#21487;&#20280;&#32553;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25512;&#23548;&#21644;&#20272;&#35745;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#65288;GPR&#65289;&#30340;LPS-based LFC&#30340;&#31867;&#27604;&#65292;&#24182;&#23558;&#20854;&#20316;&#20026;&#20197;&#19978;&#26694;&#26550;&#30340;&#26367;&#20195;&#65292;&#20351;&#20043;&#20855;&#26377;&#40065;&#26834;&#24615;&#21644;&#21487;&#20280;&#32553;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inhomogeneities in real-world data, e.g., due to changes in the observation noise level or variations in the structural complexity of the source function, pose a unique set of challenges for statistical inference. Accounting for them can greatly improve predictive power when physical resources or computation time is limited. In this paper, we draw on recent theoretical results on the estimation of local function complexity (LFC), derived from the domain of local polynomial smoothing (LPS), to establish a notion of local structural complexity, which is used to develop a model-agnostic active learning (AL) framework. Due to its reliance on pointwise estimates, the LPS model class is not robust and scalable concerning large input space dimensions that typically come along with real-world problems. Here, we derive and estimate the Gaussian process regression (GPR)-based analog of the LPS-based LFC and use it as a substitute in the above framework to make it robust and scalable. We assess t
&lt;/p&gt;</description></item></channel></rss>