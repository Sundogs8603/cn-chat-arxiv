<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20197;&#25193;&#25955;&#27169;&#22411;&#20026;&#28789;&#24863;&#30340;&#28145;&#24230;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#65292;&#23427;&#20855;&#26377;&#21487;&#35299;&#37322;&#24615;&#24182;&#21487;&#22312;&#25968;&#37327;&#30456;&#21516;&#30340;&#21487;&#35757;&#32451;&#21442;&#25968;&#19979;&#19982;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#25552;&#20379;&#21487;&#27604;&#36739;&#30340;&#25968;&#20540;&#32467;&#26524;&#12290;&#36890;&#36807;&#25512;&#23548;&#24471;&#20998;&#21305;&#37197;&#30340;&#23646;&#24615;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#29616;&#26377;&#38543;&#26426;&#29305;&#24449;&#32467;&#26524;&#65292;&#24182;&#24471;&#20986;&#20102;&#26679;&#26412;&#25968;&#25454;&#20998;&#24067;&#19982;&#30495;&#23454;&#20998;&#24067;&#20043;&#38388;&#30340;&#27867;&#21270;&#36793;&#30028;&#12290;</title><link>http://arxiv.org/abs/2310.04417</link><description>&lt;p&gt;
&#25193;&#25955;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Diffusion Random Feature Model. (arXiv:2310.04417v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04417
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20197;&#25193;&#25955;&#27169;&#22411;&#20026;&#28789;&#24863;&#30340;&#28145;&#24230;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#65292;&#23427;&#20855;&#26377;&#21487;&#35299;&#37322;&#24615;&#24182;&#21487;&#22312;&#25968;&#37327;&#30456;&#21516;&#30340;&#21487;&#35757;&#32451;&#21442;&#25968;&#19979;&#19982;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#25552;&#20379;&#21487;&#27604;&#36739;&#30340;&#25968;&#20540;&#32467;&#26524;&#12290;&#36890;&#36807;&#25512;&#23548;&#24471;&#20998;&#21305;&#37197;&#30340;&#23646;&#24615;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#29616;&#26377;&#38543;&#26426;&#29305;&#24449;&#32467;&#26524;&#65292;&#24182;&#24471;&#20986;&#20102;&#26679;&#26412;&#25968;&#25454;&#20998;&#24067;&#19982;&#30495;&#23454;&#20998;&#24067;&#20043;&#38388;&#30340;&#27867;&#21270;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#24050;&#25104;&#21151;&#29992;&#20110;&#29983;&#25104;&#20174;&#22122;&#22768;&#20013;&#20135;&#29983;&#30340;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#25193;&#25955;&#27169;&#22411;&#35745;&#31639;&#25104;&#26412;&#39640;&#26114;&#65292;&#38590;&#20197;&#35299;&#37322;&#65292;&#32570;&#20047;&#29702;&#35770;&#20381;&#25454;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#30001;&#20110;&#20854;&#21487;&#35299;&#37322;&#24615;&#65292;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#21464;&#24471;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#65292;&#20294;&#20854;&#22312;&#22797;&#26434;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#20173;&#28982;&#26377;&#38480;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#25193;&#25955;&#27169;&#22411;&#21551;&#21457;&#30340;&#28145;&#24230;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#65292;&#23427;&#26082;&#20855;&#26377;&#21487;&#35299;&#37322;&#24615;&#65292;&#21448;&#33021;&#32473;&#20986;&#19982;&#20855;&#26377;&#30456;&#21516;&#21487;&#35757;&#32451;&#21442;&#25968;&#25968;&#37327;&#30340;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30456;&#24403;&#30340;&#25968;&#20540;&#32467;&#26524;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#29616;&#26377;&#30340;&#38543;&#26426;&#29305;&#24449;&#32467;&#26524;&#65292;&#21033;&#29992;&#24471;&#20998;&#21305;&#37197;&#30340;&#23646;&#24615;&#23548;&#20986;&#20102;&#26679;&#26412;&#25968;&#25454;&#20998;&#24067;&#19982;&#30495;&#23454;&#20998;&#24067;&#20043;&#38388;&#30340;&#27867;&#21270;&#36793;&#30028;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#26102;&#23578;MNIST&#25968;&#25454;&#38598;&#21644;&#20048;&#22120;&#38899;&#39057;&#25968;&#25454;&#19978;&#29983;&#25104;&#26679;&#26412;&#26469;&#39564;&#35777;&#25105;&#20204;&#30340;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion probabilistic models have been successfully used to generate data from noise. However, most diffusion models are computationally expensive and difficult to interpret with a lack of theoretical justification. Random feature models on the other hand have gained popularity due to their interpretability but their application to complex machine learning tasks remains limited. In this work, we present a diffusion model-inspired deep random feature model that is interpretable and gives comparable numerical results to a fully connected neural network having the same number of trainable parameters. Specifically, we extend existing results for random features and derive generalization bounds between the distribution of sampled data and the true distribution using properties of score matching. We validate our findings by generating samples on the fashion MNIST dataset and instrumental audio data.
&lt;/p&gt;</description></item><item><title>MoatPlus&#26159;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#20215;&#26684;&#24322;&#24120;&#26816;&#27979;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#26080;&#30417;&#30563;&#32479;&#35745;&#29305;&#24449;&#21644;&#21382;&#21490;&#20215;&#26684;&#36235;&#21183;&#29983;&#25104;&#19978;&#38480;&#20215;&#26684;&#36793;&#30028;&#65292;&#20197;&#35299;&#20915;&#22312;&#32447;&#24066;&#22330;&#20013;&#30340;&#25968;&#25454;&#36136;&#37327;&#21644;&#38169;&#35823;&#20215;&#26684;&#21457;&#24067;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.04367</link><description>&lt;p&gt;
&#19968;&#20010;&#22823;&#35268;&#27169;&#24066;&#22330;&#20215;&#26684;&#24322;&#24120;&#26816;&#27979;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
A Marketplace Price Anomaly Detection System at Scale. (arXiv:2310.04367v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04367
&lt;/p&gt;
&lt;p&gt;
MoatPlus&#26159;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#20215;&#26684;&#24322;&#24120;&#26816;&#27979;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#26080;&#30417;&#30563;&#32479;&#35745;&#29305;&#24449;&#21644;&#21382;&#21490;&#20215;&#26684;&#36235;&#21183;&#29983;&#25104;&#19978;&#38480;&#20215;&#26684;&#36793;&#30028;&#65292;&#20197;&#35299;&#20915;&#22312;&#32447;&#24066;&#22330;&#20013;&#30340;&#25968;&#25454;&#36136;&#37327;&#21644;&#38169;&#35823;&#20215;&#26684;&#21457;&#24067;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#24066;&#22330;&#27599;&#22825;&#22312;&#24179;&#21488;&#19978;&#25191;&#34892;&#22823;&#37327;&#30340;&#20215;&#26684;&#26356;&#26032;&#65292;&#36825;&#20123;&#26356;&#26032;&#30001;&#20010;&#20307;&#24066;&#22330;&#21334;&#23478;&#21457;&#36215;&#12290;&#36825;&#31181;&#20215;&#26684;&#27665;&#20027;&#21270;&#38543;&#30528;&#25968;&#25454;&#36136;&#37327;&#30340;&#25361;&#25112;&#32780;&#22686;&#21152;&#12290;&#30456;&#23545;&#20110;&#20256;&#32479;&#30340;&#22312;&#32447;&#38646;&#21806;&#21830;&#65292;&#32570;&#20047;&#38598;&#20013;&#30340;&#38450;&#25252;&#25514;&#26045;&#20250;&#23548;&#33268;&#26356;&#39640;&#30340;&#38169;&#35823;&#20215;&#26684;&#22312;&#32593;&#31449;&#19978;&#21457;&#24067;&#65292;&#20174;&#32780;&#32473;&#39038;&#23458;&#20307;&#39564;&#24102;&#26469;&#24046;&#35780;&#21644;&#28508;&#22312;&#30340;&#25910;&#20837;&#25439;&#22833;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;MoatPlus&#65288;&#20351;&#29992;&#26641;&#12289;&#22522;&#20110;&#37051;&#36817;&#24230;&#30340;&#26631;&#31614;&#20197;&#21450;&#26080;&#30417;&#30563;&#32479;&#35745;&#29305;&#24449;&#30340;&#33945;&#38754;&#26368;&#20248;&#38170;&#28857;&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#19981;&#26029;&#22686;&#38271;&#30340;&#24066;&#22330;&#24179;&#21488;&#30340;&#21487;&#25193;&#23637;&#20215;&#26684;&#24322;&#24120;&#26816;&#27979;&#26694;&#26550;&#12290;&#30446;&#26631;&#26159;&#21033;&#29992;&#37051;&#36817;&#24230;&#21644;&#21382;&#21490;&#20215;&#26684;&#36235;&#21183;&#30340;&#26080;&#30417;&#30563;&#32479;&#35745;&#29305;&#24449;&#26469;&#29983;&#25104;&#19978;&#38480;&#20215;&#26684;&#36793;&#30028;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#27169;&#22411;&#38598;&#21512;&#26469;&#26816;&#27979;&#22522;&#20110;&#20215;&#26684;&#30340;&#29305;&#24449;&#20013;&#30340;&#24322;&#24120;&#24773;&#20917;&#65292;&#25490;&#38500;&#24322;&#24120;&#29305;&#24449;&#65292;&#24182;&#20351;&#29992;&#20248;&#21270;&#30340;&#21152;&#26435;&#26041;&#26696;&#26469;&#26500;&#24314;&#23454;&#26102;&#23450;&#20215;&#31649;&#36947;&#20013;&#21487;&#38752;&#30340;&#20215;&#26684;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online marketplaces execute large volume of price updates that are initiated by individual marketplace sellers each day on the platform. This price democratization comes with increasing challenges with data quality. Lack of centralized guardrails that are available for a traditional online retailer causes a higher likelihood for inaccurate prices to get published on the website, leading to poor customer experience and potential for revenue loss. We present MoatPlus (Masked Optimal Anchors using Trees, Proximity-based Labeling and Unsupervised Statistical-features), a scalable price anomaly detection framework for a growing marketplace platform. The goal is to leverage proximity and historical price trends from unsupervised statistical features to generate an upper price bound. We build an ensemble of models to detect irregularities in price-based features, exclude irregular features and use optimized weighting scheme to build a reliable price bound in real-time pricing pipeline. We obs
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#21033;&#29992;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#24314;&#31435;&#20102;&#19968;&#33268;&#24615;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#32032;&#25551;&#23725;&#22238;&#24402;&#38598;&#21512;&#30340;&#39044;&#27979;&#39118;&#38505;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#27491;&#21017;&#21270;&#21644;&#32032;&#25551;&#21442;&#25968;&#30340;&#39640;&#25928;&#19968;&#33268;&#35843;&#25972;&#12290;</title><link>http://arxiv.org/abs/2310.04357</link><description>&lt;p&gt;
&#28176;&#36827;&#20813;&#36153;&#32032;&#25551;&#31232;&#30095;&#23725;&#38598;&#21512;&#65306;&#39118;&#38505;&#65292;&#20132;&#21449;&#39564;&#35777;&#21644;&#35843;&#25972;
&lt;/p&gt;
&lt;p&gt;
Asymptotically free sketched ridge ensembles: Risks, cross-validation, and tuning. (arXiv:2310.04357v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04357
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#21033;&#29992;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#24314;&#31435;&#20102;&#19968;&#33268;&#24615;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#32032;&#25551;&#23725;&#22238;&#24402;&#38598;&#21512;&#30340;&#39044;&#27979;&#39118;&#38505;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#27491;&#21017;&#21270;&#21644;&#32032;&#25551;&#21442;&#25968;&#30340;&#39640;&#25928;&#19968;&#33268;&#35843;&#25972;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#21033;&#29992;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#65292;&#24314;&#31435;&#20102;&#25512;&#24191;&#20132;&#21449;&#39564;&#35777;&#65288;GCV&#65289;&#29992;&#20110;&#20272;&#35745;&#32032;&#25551;&#23725;&#22238;&#24402;&#38598;&#21512;&#30340;&#39044;&#27979;&#39118;&#38505;&#30340;&#19968;&#33268;&#24615;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#27491;&#21017;&#21270;&#21644;&#32032;&#25551;&#21442;&#25968;&#30340;&#39640;&#25928;&#19968;&#33268;&#35843;&#25972;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#19968;&#31867;&#24191;&#27867;&#30340;&#28176;&#36827;&#20813;&#36153;&#32032;&#25551;&#65292;&#23545;&#25968;&#25454;&#20551;&#35774;&#38750;&#24120;&#28201;&#21644;&#12290;&#23545;&#20110;&#24179;&#26041;&#39044;&#27979;&#39118;&#38505;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#20998;&#35299;&#25104;&#31561;&#25928;&#38750;&#32032;&#25551;&#38544;&#21547;&#23725;&#20559;&#24046;&#21644;&#22522;&#20110;&#32032;&#25551;&#30340;&#26041;&#24046;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#39118;&#38505;&#21487;&#20197;&#36890;&#36807;&#20165;&#35843;&#25972;&#26080;&#38480;&#38598;&#21512;&#20013;&#30340;&#32032;&#25551;&#22823;&#23567;&#26469;&#20840;&#23616;&#20248;&#21270;&#12290;&#23545;&#20110;&#19968;&#33324;&#30340;&#20122;&#20108;&#27425;&#39044;&#27979;&#39118;&#38505;&#20989;&#25968;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;GCV&#26469;&#26500;&#24314;&#19968;&#33268;&#30340;&#39118;&#38505;&#20272;&#35745;&#65292;&#20174;&#32780;&#22312;Wasserstein-2&#24230;&#37327;&#19979;&#33719;&#24471;&#20102;GCV&#20462;&#27491;&#30340;&#39044;&#27979;&#30340;&#20998;&#24067;&#25910;&#25947;&#24615;&#12290;&#36825;&#29305;&#21035;&#20801;&#35768;&#22312;&#35757;&#32451;&#25968;&#25454;&#26465;&#20214;&#19979;&#26500;&#24314;&#20855;&#26377;&#28176;&#36827;&#27491;&#30830;&#35206;&#30422;&#29575;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#8220;&#38598;&#21512;&#25216;&#24039;&#8221;&#65292;&#36890;&#36807;&#36825;&#31181;&#25216;&#24039;&#21487;&#20197;&#25512;&#26029;&#26410;&#32463;&#36807;&#25551;&#32472;&#30340;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;
We employ random matrix theory to establish consistency of generalized cross validation (GCV) for estimating prediction risks of sketched ridge regression ensembles, enabling efficient and consistent tuning of regularization and sketching parameters. Our results hold for a broad class of asymptotically free sketches under very mild data assumptions. For squared prediction risk, we provide a decomposition into an unsketched equivalent implicit ridge bias and a sketching-based variance, and prove that the risk can be globally optimized by only tuning sketch size in infinite ensembles. For general subquadratic prediction risk functionals, we extend GCV to construct consistent risk estimators, and thereby obtain distributional convergence of the GCV-corrected predictions in Wasserstein-2 metric. This in particular allows construction of prediction intervals with asymptotically correct coverage conditional on the training data. We also propose an "ensemble trick" whereby the risk for unsket
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#21464;&#25442;&#20316;&#20026;&#35299;&#20915;&#27010;&#29575;&#30005;&#36335;&#30340;&#39044;&#27979;&#38480;&#21046;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#22312;&#26426;&#22120;&#20154;&#22330;&#26223;&#20013;&#23637;&#31034;&#20102;&#35813;&#38480;&#21046;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#33021;&#22815;&#22312;&#20351;&#29992;&#36739;&#23569;&#30340;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#26356;&#39640;&#30340;&#20284;&#28982;&#27010;&#29575;&#12290;&#27492;&#22806;&#65292;&#36824;&#35752;&#35770;&#20102;&#22914;&#20309;&#23558;&#21464;&#25442;&#25972;&#21512;&#21040;&#22522;&#20110;&#26641;&#30340;&#23398;&#20064;&#36807;&#31243;&#20013;&#65292;&#24182;&#25351;&#20986;&#20102;&#31934;&#30830;&#25512;&#29702;&#30340;&#19981;&#21487;&#34892;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.04354</link><description>&lt;p&gt;
&#22312;&#27010;&#29575;&#30005;&#36335;&#20013;&#25972;&#21512;&#21464;&#25442;
&lt;/p&gt;
&lt;p&gt;
Integrating Transformations in Probabilistic Circuits. (arXiv:2310.04354v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04354
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#21464;&#25442;&#20316;&#20026;&#35299;&#20915;&#27010;&#29575;&#30005;&#36335;&#30340;&#39044;&#27979;&#38480;&#21046;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#22312;&#26426;&#22120;&#20154;&#22330;&#26223;&#20013;&#23637;&#31034;&#20102;&#35813;&#38480;&#21046;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#33021;&#22815;&#22312;&#20351;&#29992;&#36739;&#23569;&#30340;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#26356;&#39640;&#30340;&#20284;&#28982;&#27010;&#29575;&#12290;&#27492;&#22806;&#65292;&#36824;&#35752;&#35770;&#20102;&#22914;&#20309;&#23558;&#21464;&#25442;&#25972;&#21512;&#21040;&#22522;&#20110;&#26641;&#30340;&#23398;&#20064;&#36807;&#31243;&#20013;&#65292;&#24182;&#25351;&#20986;&#20102;&#31934;&#30830;&#25512;&#29702;&#30340;&#19981;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35299;&#20915;&#20102;&#27010;&#29575;&#30005;&#36335;&#30340;&#39044;&#27979;&#38480;&#21046;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#21464;&#25442;&#20316;&#20026;&#20811;&#26381;&#35813;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;&#26426;&#22120;&#20154;&#22330;&#26223;&#20013;&#35777;&#26126;&#20102;&#36825;&#31181;&#38480;&#21046;&#12290;&#25105;&#20204;&#35748;&#20026;&#29420;&#31435;&#20998;&#37327;&#20998;&#26512;&#26159;&#20445;&#25345;&#27010;&#29575;&#30005;&#36335;&#29420;&#31435;&#24615;&#23646;&#24615;&#30340;&#26377;&#25928;&#24037;&#20855;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#32852;&#21512;&#27010;&#29575;&#26641;&#30340;&#25193;&#23637;&#65292;&#23427;&#20204;&#26159;&#26080;&#27169;&#22411;&#30830;&#23450;&#24615;&#30005;&#36335;&#12290;&#36890;&#36807;&#36825;&#26679;&#20570;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#33021;&#22815;&#22312;&#20351;&#29992;&#36739;&#23569;&#30340;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#22312;&#19971;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#20197;&#21450;&#30495;&#23454;&#26426;&#22120;&#20154;&#25968;&#25454;&#19978;&#23454;&#29616;&#26356;&#39640;&#30340;&#20284;&#28982;&#27010;&#29575;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#22914;&#20309;&#23558;&#21464;&#25442;&#25972;&#21512;&#21040;&#22522;&#20110;&#26641;&#30340;&#23398;&#20064;&#36807;&#31243;&#20013;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35748;&#20026;&#20351;&#29992;&#36716;&#25442;&#21518;&#30340;&#20998;&#20301;&#21442;&#25968;&#21270;&#20998;&#24067;&#36827;&#34892;&#31934;&#30830;&#25512;&#29702;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#36827;&#34892;&#39640;&#25928;&#30340;&#37319;&#26679;&#21644;&#36817;&#20284;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study addresses the predictive limitation of probabilistic circuits and introduces transformations as a remedy to overcome it. We demonstrate this limitation in robotic scenarios. We motivate that independent component analysis is a sound tool to preserve the independence properties of probabilistic circuits. Our approach is an extension of joint probability trees, which are model-free deterministic circuits. By doing so, it is demonstrated that the proposed approach is able to achieve higher likelihoods while using fewer parameters compared to the joint probability trees on seven benchmark data sets as well as on real robot data. Furthermore, we discuss how to integrate transformations into tree-based learning routines. Finally, we argue that exact inference with transformed quantile parameterized distributions is not tractable. However, our approach allows for efficient sampling and approximate inference.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20851;&#27880;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#20844;&#24179;&#24615;&#30340;&#26041;&#38754;&#65292;&#21457;&#23637;&#20102;&#19968;&#31181;&#22522;&#20110;&#20915;&#31574;&#26641;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#35780;&#20998;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.04352</link><description>&lt;p&gt;
&#29992;&#20110;&#35299;&#37322;&#22522;&#20110;&#26641;&#27169;&#22411;&#21644;&#26367;&#20195;&#27169;&#22411;&#30340;&#20844;&#24179;&#29305;&#24449;&#37325;&#35201;&#24615;&#35780;&#20998;
&lt;/p&gt;
&lt;p&gt;
Fair Feature Importance Scores for Interpreting Tree-Based Methods and Surrogates. (arXiv:2310.04352v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04352
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#20844;&#24179;&#24615;&#30340;&#26041;&#38754;&#65292;&#21457;&#23637;&#20102;&#19968;&#31181;&#22522;&#20110;&#20915;&#31574;&#26641;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#35780;&#20998;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21307;&#30103;&#20445;&#20581;&#12289;&#21009;&#20107;&#21496;&#27861;&#12289;&#22269;&#23478;&#23433;&#20840;&#12289;&#37329;&#34701;&#21644;&#25216;&#26415;&#31561;&#21508;&#20010;&#39046;&#22495;&#65292;&#22823;&#35268;&#27169;&#30340;&#26426;&#22120;&#23398;&#20064;(ML)&#21644;&#20154;&#24037;&#26234;&#33021;(AI)&#31995;&#32479;&#34987;&#37096;&#32626;&#29992;&#20110;&#36827;&#34892;&#20851;&#38190;&#30340;&#25968;&#25454;&#39537;&#21160;&#20915;&#31574;&#12290;&#35768;&#22810;&#20154;&#24819;&#30693;&#36947;&#25105;&#20204;&#26159;&#21542;&#21487;&#20197;&#20449;&#20219;&#36825;&#20123;ML&#31995;&#32479;&#36827;&#34892;&#36825;&#20123;&#20915;&#31574;&#12290;&#23545;&#20110;&#20449;&#20219;ML&#31995;&#32479;&#26469;&#35828;&#65292;&#20004;&#20010;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#26159;&#24517;&#22791;&#30340;&#65306;&#21487;&#35299;&#37322;&#24615;&#65292;&#21363;&#33021;&#22815;&#29702;&#35299;ML&#31995;&#32479;&#20026;&#20160;&#20040;&#20570;&#20986;&#36825;&#26679;&#30340;&#20915;&#31574;&#65307;&#20844;&#24179;&#24615;&#65292;&#30830;&#20445;ML&#31995;&#32479;&#19981;&#23545;&#26576;&#20123;&#20010;&#20307;&#25110;&#32676;&#20307;&#23384;&#22312;&#20559;&#35265;&#12290;&#21487;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;&#37117;&#24456;&#37325;&#35201;&#65292;&#24182;&#22312;ML&#25991;&#29486;&#20013;&#20998;&#21035;&#24471;&#21040;&#20102;&#22823;&#37327;&#20851;&#27880;&#65292;&#20294;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#24456;&#23569;&#26377;&#26041;&#27861;&#30452;&#25509;&#35299;&#37322;&#27169;&#22411;&#30340;&#20844;&#24179;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30528;&#37325;&#35752;&#35770;&#21487;&#33021;&#26159;&#26368;&#27969;&#34892;&#30340;ML&#35299;&#37322;&#31867;&#22411;&#20043;&#19968;&#65306;&#29305;&#24449;&#37325;&#35201;&#24615;&#35780;&#20998;&#12290;&#21463;&#21040;&#22312;&#30693;&#35782;&#33976;&#39311;&#20013;&#20351;&#29992;&#20915;&#31574;&#26641;&#30340;&#21551;&#21457;&#65292;
&lt;/p&gt;
&lt;p&gt;
Across various sectors such as healthcare, criminal justice, national security, finance, and technology, large-scale machine learning (ML) and artificial intelligence (AI) systems are being deployed to make critical data-driven decisions. Many have asked if we can and should trust these ML systems to be making these decisions. Two critical components are prerequisites for trust in ML systems: interpretability, or the ability to understand why the ML system makes the decisions it does, and fairness, which ensures that ML systems do not exhibit bias against certain individuals or groups. Both interpretability and fairness are important and have separately received abundant attention in the ML literature, but so far, there have been very few methods developed to directly interpret models with regard to their fairness. In this paper, we focus on arguably the most popular type of ML interpretation: feature importance scores. Inspired by the use of decision trees in knowledge distillation, w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24178;&#39044;&#22806;&#25512;&#30340;&#20219;&#21153;&#65292;&#35777;&#26126;&#20102;&#21487;&#35782;&#21035;&#30340;&#34920;&#31034;&#26041;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#35299;&#20915;&#36825;&#20010;&#20219;&#21153;&#65292;&#21363;&#20351;&#24178;&#39044;&#23545;&#32467;&#26524;&#20135;&#29983;&#38750;&#32447;&#24615;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.04295</link><description>&lt;p&gt;
&#35782;&#21035;&#24178;&#39044;&#22806;&#25512;&#30340;&#34920;&#31034;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Identifying Representations for Intervention Extrapolation. (arXiv:2310.04295v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04295
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24178;&#39044;&#22806;&#25512;&#30340;&#20219;&#21153;&#65292;&#35777;&#26126;&#20102;&#21487;&#35782;&#21035;&#30340;&#34920;&#31034;&#26041;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#35299;&#20915;&#36825;&#20010;&#20219;&#21153;&#65292;&#21363;&#20351;&#24178;&#39044;&#23545;&#32467;&#26524;&#20135;&#29983;&#38750;&#32447;&#24615;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35782;&#21035;&#21644;&#22240;&#26524;&#20851;&#31995;&#34920;&#31034;&#23398;&#20064;&#30340;&#21069;&#25552;&#26159;&#25913;&#36827;&#24403;&#21069;&#30340;&#34920;&#31034;&#23398;&#20064;&#33539;&#24335;&#65292;&#20197;&#25552;&#39640;&#27867;&#21270;&#24615;&#25110;&#40065;&#26834;&#24615;&#12290;&#23613;&#31649;&#22312;&#21487;&#35782;&#21035;&#24615;&#38382;&#39064;&#19978;&#21462;&#24471;&#20102;&#36817;&#26399;&#30340;&#36827;&#23637;&#65292;&#20294;&#20173;&#38656;&#35201;&#26356;&#22810;&#29702;&#35770;&#32467;&#26524;&#26469;&#35777;&#26126;&#36825;&#20123;&#26041;&#27861;&#23545;&#19979;&#28216;&#20219;&#21153;&#30340;&#20855;&#20307;&#20248;&#21183;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#24178;&#39044;&#22806;&#25512;&#30340;&#20219;&#21153;&#65306;&#39044;&#27979;&#24178;&#39044;&#22914;&#20309;&#24433;&#21709;&#32467;&#26524;&#65292;&#21363;&#20351;&#36825;&#20123;&#24178;&#39044;&#22312;&#35757;&#32451;&#26102;&#27809;&#26377;&#35266;&#23519;&#21040;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21487;&#35782;&#21035;&#30340;&#34920;&#31034;&#33021;&#22815;&#20026;&#36825;&#20010;&#20219;&#21153;&#25552;&#20379;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21363;&#20351;&#24178;&#39044;&#23545;&#32467;&#26524;&#20135;&#29983;&#38750;&#32447;&#24615;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#35774;&#32622;&#21253;&#25324;&#19968;&#20010;&#32467;&#26524;Y&#65292;&#35266;&#23519;&#21040;&#30340;&#29305;&#24449;X&#65292;&#36825;&#20123;&#29305;&#24449;&#26159;&#28508;&#22312;&#29305;&#24449;Z&#30340;&#38750;&#32447;&#24615;&#36716;&#25442;&#65292;&#20197;&#21450;&#24433;&#21709;Z&#30340;&#22806;&#29983;&#34892;&#20026;&#21464;&#37327;A&#12290;&#24178;&#39044;&#22806;&#25512;&#30340;&#30446;&#26631;&#26159;&#39044;&#27979;&#20301;&#20110;&#35757;&#32451;&#25903;&#25345;&#20043;&#22806;&#30340;A&#19978;&#30340;&#24178;&#39044;&#22914;&#20309;&#24433;&#21709;Y&#12290;&#22312;&#36825;&#37324;&#65292;&#22806;&#25512;&#21464;&#24471;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
The premise of identifiable and causal representation learning is to improve the current representation learning paradigm in terms of generalizability or robustness. Despite recent progress in questions of identifiability, more theoretical results demonstrating concrete advantages of these methods for downstream tasks are needed. In this paper, we consider the task of intervention extrapolation: predicting how interventions affect an outcome, even when those interventions are not observed at training time, and show that identifiable representations can provide an effective solution to this task even if the interventions affect the outcome non-linearly. Our setup includes an outcome Y, observed features X, which are generated as a non-linear transformation of latent features Z, and exogenous action variables A, which influence Z. The objective of intervention extrapolation is to predict how interventions on A that lie outside the training support of A affect Y. Here, extrapolation becom
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#25968;&#30340;&#23545;&#25239;&#29983;&#25104;&#26694;&#26550;&#65288;ScoreAG&#65289;&#65292;&#21487;&#20197;&#29983;&#25104;&#36229;&#36807;$\ell_p$-&#33539;&#25968;&#32422;&#26463;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#65292;&#24182;&#36890;&#36807;&#22270;&#20687;&#36716;&#25442;&#25110;&#26032;&#22270;&#20687;&#21512;&#25104;&#30340;&#26041;&#27861;&#20445;&#25345;&#22270;&#20687;&#30340;&#26680;&#24515;&#35821;&#20041;&#65292;&#22823;&#22823;&#22686;&#24378;&#20102;&#20998;&#31867;&#22120;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.04285</link><description>&lt;p&gt;
&#36890;&#36807;&#22522;&#20110;&#20998;&#25968;&#30340;&#23545;&#25239;&#22270;&#20687;&#29983;&#25104;&#35780;&#20272;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Assessing Robustness via Score-Based Adversarial Image Generation. (arXiv:2310.04285v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04285
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#25968;&#30340;&#23545;&#25239;&#29983;&#25104;&#26694;&#26550;&#65288;ScoreAG&#65289;&#65292;&#21487;&#20197;&#29983;&#25104;&#36229;&#36807;$\ell_p$-&#33539;&#25968;&#32422;&#26463;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#65292;&#24182;&#36890;&#36807;&#22270;&#20687;&#36716;&#25442;&#25110;&#26032;&#22270;&#20687;&#21512;&#25104;&#30340;&#26041;&#27861;&#20445;&#25345;&#22270;&#20687;&#30340;&#26680;&#24515;&#35821;&#20041;&#65292;&#22823;&#22823;&#22686;&#24378;&#20102;&#20998;&#31867;&#22120;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#23545;&#25239;&#25915;&#20987;&#21644;&#38450;&#24481;&#37117;&#38598;&#20013;&#22312;&#23567;&#30340;$\ell_p$-&#33539;&#25968;&#32422;&#26463;&#20869;&#30340;&#25200;&#21160;&#19978;&#12290;&#28982;&#32780;&#65292;$\ell_p$&#23041;&#32961;&#27169;&#22411;&#26080;&#27861;&#25429;&#25417;&#21040;&#25152;&#26377;&#30456;&#20851;&#30340;&#20445;&#30041;&#35821;&#20041;&#30340;&#25200;&#21160;&#65292;&#22240;&#27492;&#65292;&#40065;&#26834;&#24615;&#35780;&#20272;&#30340;&#33539;&#22260;&#26159;&#26377;&#38480;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#20998;&#25968;&#30340;&#23545;&#25239;&#29983;&#25104;&#65288;ScoreAG&#65289;&#65292;&#19968;&#31181;&#21033;&#29992;&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#36827;&#23637;&#26469;&#29983;&#25104;&#36229;&#36807;$\ell_p$-&#33539;&#25968;&#32422;&#26463;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#30340;&#26032;&#30340;&#26694;&#26550;&#65292;&#31216;&#20026;&#26080;&#38480;&#21046;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#65292;&#20811;&#26381;&#20102;&#23427;&#20204;&#30340;&#23616;&#38480;&#24615;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#65292;ScoreAG&#22312;&#29983;&#25104;&#36924;&#30495;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#26102;&#20445;&#25345;&#22270;&#20687;&#30340;&#26680;&#24515;&#35821;&#20041;&#65292;&#21487;&#20197;&#36890;&#36807;&#36716;&#25442;&#29616;&#26377;&#22270;&#20687;&#25110;&#23436;&#20840;&#20174;&#38646;&#24320;&#22987;&#21512;&#25104;&#26032;&#22270;&#20687;&#30340;&#26041;&#24335;&#23454;&#29616;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#21033;&#29992;ScoreAG&#30340;&#29983;&#25104;&#33021;&#21147;&#26469;&#20928;&#21270;&#22270;&#20687;&#65292;&#20174;&#32463;&#39564;&#19978;&#22686;&#24378;&#20998;&#31867;&#22120;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#30340;&#22823;&#37327;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;ScoreAG&#19982;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#23545;&#25239;&#25915;&#20987;&#26041;&#27861;&#30340;&#24615;&#33021;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most adversarial attacks and defenses focus on perturbations within small $\ell_p$-norm constraints. However, $\ell_p$ threat models cannot capture all relevant semantic-preserving perturbations, and hence, the scope of robustness evaluations is limited. In this work, we introduce Score-Based Adversarial Generation (ScoreAG), a novel framework that leverages the advancements in score-based generative models to generate adversarial examples beyond $\ell_p$-norm constraints, so-called unrestricted adversarial examples, overcoming their limitations. Unlike traditional methods, ScoreAG maintains the core semantics of images while generating realistic adversarial examples, either by transforming existing images or synthesizing new ones entirely from scratch. We further exploit the generative capability of ScoreAG to purify images, empirically enhancing the robustness of classifiers. Our extensive empirical evaluation demonstrates that ScoreAG matches the performance of state-of-the-art atta
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20027;&#25104;&#20998;&#20998;&#26512;&#20013;&#19981;&#31934;&#30830;&#28040;&#38500;&#27861;&#30340;&#35823;&#24046;&#20256;&#25773;&#38382;&#39064;&#65292;&#32473;&#20986;&#20102;&#20004;&#20010;&#20027;&#35201;&#32467;&#26524;</title><link>http://arxiv.org/abs/2310.04283</link><description>&lt;p&gt;
&#20851;&#20110;&#19981;&#31934;&#30830;&#28040;&#38500;&#27861;&#22312;&#20027;&#25104;&#20998;&#20998;&#26512;&#20013;&#30340;&#35823;&#24046;&#20256;&#25773;
&lt;/p&gt;
&lt;p&gt;
On the Error-Propagation of Inexact Deflation for Principal Component Analysis. (arXiv:2310.04283v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04283
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20027;&#25104;&#20998;&#20998;&#26512;&#20013;&#19981;&#31934;&#30830;&#28040;&#38500;&#27861;&#30340;&#35823;&#24046;&#20256;&#25773;&#38382;&#39064;&#65292;&#32473;&#20986;&#20102;&#20004;&#20010;&#20027;&#35201;&#32467;&#26524;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#26159;&#25968;&#25454;&#20998;&#26512;&#20013;&#24120;&#29992;&#30340;&#24037;&#20855;&#65292;&#23588;&#20854;&#26159;&#22312;&#39640;&#32500;&#25968;&#25454;&#24773;&#20917;&#19979;&#12290;PCA&#26088;&#22312;&#25214;&#21040;&#30001;&#25152;&#35859;&#8220;&#20027;&#25104;&#20998;&#8221;&#25152;&#24352;&#25104;&#30340;&#23376;&#31354;&#38388;&#65292;&#36825;&#20123;&#20027;&#25104;&#20998;&#26368;&#33021;&#35299;&#37322;&#25968;&#25454;&#38598;&#30340;&#26041;&#24046;&#12290;&#28040;&#38500;&#27861;&#26159;&#19968;&#31181;&#24120;&#29992;&#30340;&#20803;&#31639;&#27861;&#65292;&#29992;&#20110;&#21457;&#29616;&#36825;&#26679;&#30340;&#23376;&#31354;&#38388;&#65292;&#23427;&#20174;&#26368;&#37325;&#35201;&#30340;&#20027;&#25104;&#20998;&#24320;&#22987;&#39034;&#24207;&#22320;&#25214;&#21040;&#27599;&#20010;&#20027;&#25104;&#20998;&#65292;&#30452;&#21040;&#25214;&#21040;&#36739;&#19981;&#37325;&#35201;&#30340;&#20027;&#25104;&#20998;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20854;&#39034;&#24207;&#24615;&#36136;&#65292;&#30001;&#20110;&#19981;&#23436;&#20840;&#20272;&#35745;&#20027;&#25104;&#20998;&#24341;&#20837;&#30340;&#25968;&#20540;&#35823;&#24046; - &#20363;&#22914;&#65292;&#30001;&#20110;&#27492;&#36807;&#31243;&#20013;&#30340;&#25968;&#20540;&#36817;&#20284; - &#20250;&#38543;&#30528;&#28040;&#38500;&#30340;&#36827;&#34892;&#32780;&#20256;&#25773;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#31687;&#22312;&#25968;&#23398;&#19978;&#23545;&#19981;&#31934;&#30830;&#28040;&#38500;&#27861;&#30340;&#35823;&#24046;&#20256;&#25773;&#36827;&#34892;&#20102;&#29305;&#24615;&#21270;&#30340;&#24037;&#20316;&#65292;&#36825;&#26159;&#26412;&#25991;&#30340;&#20851;&#38190;&#36129;&#29486;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#20010;&#20027;&#35201;&#32467;&#26524;&#65306;$ i&#65289;$&#24403;&#29992;&#20110;&#26597;&#25214;&#20027;&#35201;&#29305;&#24449;&#21521;&#37327;&#30340;&#23376;&#20363;&#31243;&#26159;&#27867;&#22411;&#30340;&#26102;&#20505;&#65292;&#20197;&#21450;$ ii&#65289;$
&lt;/p&gt;
&lt;p&gt;
Principal Component Analysis (PCA) is a popular tool in data analysis, especially when the data is high-dimensional. PCA aims to find subspaces, spanned by the so-called \textit{principal components}, that best explain the variance in the dataset. The deflation method is a popular meta-algorithm -used to discover such subspaces -- that sequentially finds individual principal components, starting from the most important one and working its way towards the less important ones. However, due to its sequential nature, the numerical error introduced by not estimating principal components exactly -- e.g., due to numerical approximations through this process -- propagates, as deflation proceeds. To the best of our knowledge, this is the first work that mathematically characterizes the error propagation of the inexact deflation method, and this is the key contribution of this paper. We provide two main results: $i)$ when the sub-routine for finding the leading eigenvector is generic, and $ii)
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#32463;&#20856;transformer attention&#27867;&#21270;&#21040;&#33021;&#22815;&#25429;&#25417;&#19977;&#20803;&#30456;&#20851;&#24615;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#26377;&#30028;&#36755;&#20837;&#19979;&#20855;&#26377;&#36817;&#32447;&#24615;&#26102;&#38388;&#22797;&#26434;&#24230;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.04064</link><description>&lt;p&gt;
&#22914;&#20309;&#25429;&#25417;&#39640;&#38454;&#30456;&#20851;&#24615;&#65311;&#23558;&#30697;&#38453;Softmax Attention&#25512;&#24191;&#21040;Kronecker&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
How to Capture Higher-order Correlations? Generalizing Matrix Softmax Attention to Kronecker Computation. (arXiv:2310.04064v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04064
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#32463;&#20856;transformer attention&#27867;&#21270;&#21040;&#33021;&#22815;&#25429;&#25417;&#19977;&#20803;&#30456;&#20851;&#24615;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#26377;&#30028;&#36755;&#20837;&#19979;&#20855;&#26377;&#36817;&#32447;&#24615;&#26102;&#38388;&#22797;&#26434;&#24230;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32463;&#20856;&#30340;transformer attention&#26041;&#26696;&#20013;&#65292;&#25105;&#20204;&#32473;&#23450;&#19977;&#20010;&#22823;&#23567;&#20026;$n \times d$&#30340;&#30697;&#38453;$Q, K, V$&#65288;&#26597;&#35810;&#12289;&#38190;&#21644;&#20540;&#26631;&#35760;&#65289;&#65292;&#30446;&#26631;&#26159;&#35745;&#31639;&#19968;&#20010;&#26032;&#30340;&#22823;&#23567;&#20026;$n \times d$&#30340;&#30697;&#38453;$D^{-1} \exp(QK^\top) V$&#65292;&#20854;&#20013;$D = \mathrm{diag}( \exp(QK^\top) {\bf 1}_n )$&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#33021;&#22815;&#25429;&#25417;&#19977;&#20803;&#30456;&#20851;&#24615;&#30340;&#27880;&#24847;&#21147;&#30340;&#27867;&#21270;&#12290;&#36825;&#31181;&#27867;&#21270;&#33021;&#22815;&#35299;&#20915;&#20851;&#20110;&#26816;&#27979;transformers&#26080;&#27861;&#35299;&#20915;&#30340;&#19977;&#20803;&#36830;&#25509;&#30340;&#38382;&#39064;&#12290;&#36825;&#31181;&#27867;&#21270;&#30340;&#28508;&#22312;&#32570;&#28857;&#26159;&#65292;&#35745;&#31639;&#20284;&#20046;&#26356;&#21152;&#22256;&#38590;&#65292;&#22240;&#20026;&#30452;&#25509;&#30340;&#31639;&#27861;&#22312;$n$&#30340;&#31435;&#26041;&#26102;&#38388;&#20869;&#23436;&#25104;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#26377;&#30028;&#36755;&#20837;&#30340;&#24773;&#20917;&#19979;&#65288;&#23454;&#36341;&#20013;&#32463;&#24120;&#20986;&#29616;&#65292;&#24182;&#19988;&#22312;&#29702;&#35770;&#21644;&#23454;&#36341;&#20013;&#37117;&#26377;&#24191;&#27867;&#30740;&#31350;&#65289;&#65292;&#23454;&#38469;&#19978;&#23384;&#22312;&#19968;&#20010;&#36817;&#32447;&#24615;&#26102;&#38388;&#30340;&#31639;&#27861;&#12290;&#26356;&#20934;&#30830;&#22320;&#35828;&#65292;&#25105;&#20204;&#35777;&#26126;&#26377;&#30028;&#36755;&#20837;&#26082;&#26159;&#24555;&#36895;&#25191;&#34892;&#24191;&#20041;&#35745;&#31639;&#30340;&#24517;&#35201;&#26465;&#20214;&#20063;&#26159;&#20805;&#20998;&#26465;&#20214;&#65306; $\bul
&lt;/p&gt;
&lt;p&gt;
In the classical transformer attention scheme, we are given three $n \times d$ size matrices $Q, K, V$ (the query, key, and value tokens), and the goal is to compute a new $n \times d$ size matrix $D^{-1} \exp(QK^\top) V$ where $D = \mathrm{diag}( \exp(QK^\top) {\bf 1}_n )$. In this work, we study a generalization of attention which captures triple-wise correlations. This generalization is able to solve problems about detecting triple-wise connections that were shown to be impossible for transformers. The potential downside of this generalization is that it appears as though computations are even more difficult, since the straightforward algorithm requires cubic time in $n$. However, we show that in the bounded-entry setting (which arises in practice, and which is well-studied in both theory and practice), there is actually a near-linear time algorithm. More precisely, we show that bounded entries are both necessary and sufficient for quickly performing generalized computations:  $\bul
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#31867;&#20284;&#26679;&#26412;&#32858;&#31867;&#8221;&#30340;&#25216;&#26415;&#65292;&#36890;&#36807;&#26367;&#25442;&#20010;&#20307;&#30340;&#25935;&#24863;&#29305;&#24449;&#20026;&#32858;&#31867;&#30340;&#24179;&#22343;&#20540;&#26469;&#22686;&#24378;&#38544;&#31169;&#12290;&#36890;&#36807;&#23545;&#20351;&#29992;&#21311;&#21517;&#32858;&#31867;&#20013;&#24515;&#35757;&#32451;&#27169;&#22411;&#30340;&#31934;&#30830;&#20998;&#26512;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#19981;&#21516;&#27169;&#22411;&#32452;&#25104;&#37096;&#20998;&#23545;&#27867;&#21270;&#35823;&#24046;&#30340;&#24433;&#21709;&#65292;&#24182;&#35777;&#26126;&#22312;&#26576;&#20123;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#21311;&#21517;&#32858;&#31867;&#20013;&#24515;&#36827;&#34892;&#35757;&#32451;&#21487;&#20197;&#21462;&#24471;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.04015</link><description>&lt;p&gt;
&#36890;&#36807;&#31867;&#20284;&#26679;&#26412;&#32858;&#31867;&#23398;&#20064;&#65306;&#23545;&#27169;&#22411;&#27867;&#21270;&#30340;&#31934;&#30830;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Learning via Look-Alike Clustering: A Precise Analysis of Model Generalization. (arXiv:2310.04015v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04015
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#31867;&#20284;&#26679;&#26412;&#32858;&#31867;&#8221;&#30340;&#25216;&#26415;&#65292;&#36890;&#36807;&#26367;&#25442;&#20010;&#20307;&#30340;&#25935;&#24863;&#29305;&#24449;&#20026;&#32858;&#31867;&#30340;&#24179;&#22343;&#20540;&#26469;&#22686;&#24378;&#38544;&#31169;&#12290;&#36890;&#36807;&#23545;&#20351;&#29992;&#21311;&#21517;&#32858;&#31867;&#20013;&#24515;&#35757;&#32451;&#27169;&#22411;&#30340;&#31934;&#30830;&#20998;&#26512;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#19981;&#21516;&#27169;&#22411;&#32452;&#25104;&#37096;&#20998;&#23545;&#27867;&#21270;&#35823;&#24046;&#30340;&#24433;&#21709;&#65292;&#24182;&#35777;&#26126;&#22312;&#26576;&#20123;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#21311;&#21517;&#32858;&#31867;&#20013;&#24515;&#36827;&#34892;&#35757;&#32451;&#21487;&#20197;&#21462;&#24471;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#21464;&#24471;&#36234;&#26469;&#36234;&#27969;&#34892;&#65292;&#20294;&#30830;&#20445;&#29992;&#25143;&#25968;&#25454;&#30340;&#20445;&#25252;&#20173;&#28982;&#26159;&#36825;&#20123;&#23398;&#20064;&#31995;&#32479;&#24320;&#21457;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#20851;&#27880;&#28857;&#12290;&#22686;&#24378;&#38544;&#31169;&#30340;&#24120;&#35265;&#26041;&#27861;&#26159;&#20351;&#29992;&#21311;&#21517;&#25968;&#25454;&#32780;&#19981;&#26159;&#20010;&#20307;&#25968;&#25454;&#26469;&#35757;&#32451;&#27169;&#22411;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#31867;&#20284;&#26679;&#26412;&#32858;&#31867;&#8221;&#30340;&#33258;&#28982;&#25216;&#26415;&#65292;&#23427;&#28041;&#21450;&#23558;&#20010;&#20307;&#30340;&#25935;&#24863;&#29305;&#24449;&#26367;&#25442;&#20026;&#32858;&#31867;&#30340;&#24179;&#22343;&#20540;&#12290;&#25105;&#20204;&#23545;&#20351;&#29992;&#21311;&#21517;&#32858;&#31867;&#20013;&#24515;&#35757;&#32451;&#27169;&#22411;&#22914;&#20309;&#24433;&#21709;&#20854;&#27867;&#21270;&#33021;&#21147;&#36827;&#34892;&#20102;&#31934;&#30830;&#30340;&#20998;&#26512;&#12290;&#25105;&#20204;&#20851;&#27880;&#19968;&#20010;&#28176;&#36817;&#24773;&#20917;&#65292;&#21363;&#35757;&#32451;&#38598;&#30340;&#22823;&#23567;&#19982;&#29305;&#24449;&#32500;&#24230;&#25104;&#27604;&#20363;&#22686;&#38271;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#22522;&#20110;&#20984;&#39640;&#26031;&#26497;&#23567;&#21270;&#26497;&#22823;&#23450;&#29702;&#65288;Convex Gaussian Minimax Theorem&#65292;CGMT&#65289;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#22312;&#29702;&#35770;&#19978;&#29702;&#35299;&#19981;&#21516;&#27169;&#22411;&#32452;&#25104;&#37096;&#20998;&#23545;&#27867;&#21270;&#35823;&#24046;&#30340;&#20316;&#29992;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#26576;&#20123;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#21311;&#21517;&#32858;&#31867;&#20013;&#24515;&#36827;&#34892;&#35757;&#32451;&#33021;&#22815;&#21462;&#24471;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
While personalized recommendations systems have become increasingly popular, ensuring user data protection remains a paramount concern in the development of these learning systems. A common approach to enhancing privacy involves training models using anonymous data rather than individual data. In this paper, we explore a natural technique called \emph{look-alike clustering}, which involves replacing sensitive features of individuals with the cluster's average values. We provide a precise analysis of how training models using anonymous cluster centers affects their generalization capabilities. We focus on an asymptotic regime where the size of the training set grows in proportion to the features dimension. Our analysis is based on the Convex Gaussian Minimax Theorem (CGMT) and allows us to theoretically understand the role of different model components on the generalization error. In addition, we demonstrate that in certain high-dimensional regimes, training over anonymous cluster cente
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38416;&#36848;&#20102;&#20851;&#20110;&#38543;&#26426;&#21521;&#37327;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#30340;&#19979;&#30028;&#65292;&#37325;&#28857;&#26159;&#20223;&#23556;&#21464;&#25442;&#65292;&#24182;&#24212;&#29992;&#20110;&#27969;&#22411;&#23398;&#20064;&#21644;&#25163;&#20889;&#25968;&#25454;&#38598;&#27169;&#25311;&#12290;</title><link>http://arxiv.org/abs/2310.03945</link><description>&lt;p&gt;
&#20851;&#20110;&#38543;&#26426;&#21521;&#37327;&#30340;&#20223;&#23556;&#21464;&#25442;&#30340;Wasserstein&#36317;&#31163;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Wasserstein distances for affine transformations of random vectors. (arXiv:2310.03945v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03945
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38416;&#36848;&#20102;&#20851;&#20110;&#38543;&#26426;&#21521;&#37327;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#30340;&#19979;&#30028;&#65292;&#37325;&#28857;&#26159;&#20223;&#23556;&#21464;&#25442;&#65292;&#24182;&#24212;&#29992;&#20110;&#27969;&#22411;&#23398;&#20064;&#21644;&#25163;&#20889;&#25968;&#25454;&#38598;&#27169;&#25311;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#38416;&#36848;&#20102;&#20851;&#20110;&#22312;Wasserstein&#31354;&#38388;&#20013;&#29992;&#20110;&#25968;&#25454;&#27969;&#22411;&#23398;&#20064;&#30340;&#38543;&#26426;&#21521;&#37327;&#20043;&#38388;&#30340;&#20108;&#27425;Wasserstein&#36317;&#31163;&#30340;&#19968;&#20123;&#24050;&#30693;&#19979;&#30028;&#65292;&#37325;&#28857;&#26159;&#20223;&#23556;&#21464;&#25442;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#36890;&#36807;&#35745;&#31639;&#21327;&#26041;&#24046;&#30697;&#38453;&#20043;&#38388;&#30340;Bures&#36317;&#31163;&#65292;&#32473;&#20986;&#20102;&#26059;&#36716;&#30340;&#38543;&#26426;&#21521;&#37327;&#22312;&#20855;&#26377;&#19981;&#30456;&#20851;&#20998;&#37327;&#30340;$\mathbb{R}^2$&#31354;&#38388;&#20013;&#30340;&#20855;&#20307;&#19979;&#30028;&#12290;&#25105;&#20204;&#36824;&#24471;&#21040;&#20102;&#20223;&#23556;&#21464;&#25442;&#30340;&#32452;&#21512;&#30340;&#19978;&#30028;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#24212;&#29992;&#20110;&#21021;&#22987;&#25968;&#25454;&#27979;&#24230;&#30340;&#20016;&#23500;&#30340;&#24494;&#20998;&#21516;&#32986;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#30028;&#24212;&#29992;&#20110;&#21253;&#25324;&#22312;$\mathbb{R}^2$&#20013;&#30340;&#19968;&#32500;&#27969;&#22411;&#19978;&#30340;&#21508;&#31181;&#20998;&#24067;&#65292;&#24182;&#35828;&#26126;&#20102;&#36825;&#20123;&#30028;&#30340;&#36136;&#37327;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#22312;&#27969;&#22411;&#23398;&#20064;&#26694;&#26550;&#20013;&#21487;&#20197;&#24212;&#29992;&#20110;&#27169;&#25311;&#25163;&#20889;&#25968;&#23383;&#25110;&#23383;&#27597;&#25968;&#25454;&#38598;&#30340;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
We expound on some known lower bounds of the quadratic Wasserstein distance between random vectors in $\mathbb{R}^n$ with an emphasis on affine transformations that have been used in manifold learning of data in Wasserstein space. In particular, we give concrete lower bounds for rotated copies of random vectors in $\mathbb{R}^2$ with uncorrelated components by computing the Bures metric between the covariance matrices. We also derive upper bounds for compositions of affine maps which yield a fruitful variety of diffeomorphisms applied to an initial data measure. We apply these bounds to various distributions including those lying on a 1-dimensional manifold in $\mathbb{R}^2$ and illustrate the quality of the bounds. Finally, we give a framework for mimicking handwritten digit or alphabet datasets that can be applied in a manifold learning framework.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#36864;&#28779;&#26041;&#27861;&#20272;&#35745;&#24402;&#19968;&#21270;&#24120;&#25968;&#30340;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#12290;&#36890;&#36807;&#35780;&#20272;&#19981;&#21516;&#35774;&#35745;&#36873;&#25321;&#23545;&#20272;&#35745;&#35823;&#24046;&#30340;&#24433;&#21709;&#65292;&#32467;&#26524;&#34920;&#26126;&#20351;&#29992;&#36864;&#28779;&#22122;&#22768;&#23545;&#27604;&#20272;&#35745;&#22120;&#26356;&#26377;&#25928;&#65292;&#24182;&#19988;&#20351;&#29992;&#20960;&#20309;&#36335;&#24452;&#21487;&#20197;&#38477;&#20302;&#20272;&#35745;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2310.03902</link><description>&lt;p&gt;
&#36890;&#36807;&#36864;&#28779;&#26469;&#20272;&#35745;&#24402;&#19968;&#21270;&#24120;&#25968;&#30340;&#21487;&#35777;&#26126;&#30340;&#30410;&#22788;&#65306;&#37325;&#35201;&#24615;&#25277;&#26679;&#65292;&#22122;&#22768;&#23545;&#27604;&#20272;&#35745;&#65292;&#20197;&#21450;&#26356;&#22810;
&lt;/p&gt;
&lt;p&gt;
Provable benefits of annealing for estimating normalizing constants: Importance Sampling, Noise-Contrastive Estimation, and beyond. (arXiv:2310.03902v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03902
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#36864;&#28779;&#26041;&#27861;&#20272;&#35745;&#24402;&#19968;&#21270;&#24120;&#25968;&#30340;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#12290;&#36890;&#36807;&#35780;&#20272;&#19981;&#21516;&#35774;&#35745;&#36873;&#25321;&#23545;&#20272;&#35745;&#35823;&#24046;&#30340;&#24433;&#21709;&#65292;&#32467;&#26524;&#34920;&#26126;&#20351;&#29992;&#36864;&#28779;&#22122;&#22768;&#23545;&#27604;&#20272;&#35745;&#22120;&#26356;&#26377;&#25928;&#65292;&#24182;&#19988;&#20351;&#29992;&#20960;&#20309;&#36335;&#24452;&#21487;&#20197;&#38477;&#20302;&#20272;&#35745;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#23637;&#20102;&#20960;&#31181;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#26469;&#20272;&#35745;&#24402;&#19968;&#21270;&#24120;&#25968;&#65288;&#37197;&#20998;&#20989;&#25968;&#65289;&#65292;&#36825;&#20123;&#26041;&#27861;&#22522;&#20110;&#36864;&#28779;&#30340;&#24605;&#24819;&#12290;&#21363;&#20174;&#21487;&#35745;&#31639;&#30340;&#8220;&#25552;&#35758;&#8221;&#20998;&#24067;&#21644;&#26410;&#24402;&#19968;&#21270;&#30340;&#8220;&#30446;&#26631;&#8221;&#20998;&#24067;&#20043;&#38388;&#30340;&#36335;&#24452;&#36880;&#27493;&#37319;&#26679;&#12290;&#36825;&#20123;&#23478;&#26063;&#20013;&#30340;&#37325;&#35201;&#20272;&#35745;&#22120;&#21253;&#25324;&#36864;&#28779;&#37325;&#35201;&#24615;&#25277;&#26679;&#21644;&#36864;&#28779;&#22122;&#22768;&#23545;&#27604;&#20272;&#35745;&#65288;NCE&#65289;&#12290;&#36825;&#26679;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#35768;&#22810;&#35774;&#35745;&#36873;&#25321;&#65306;&#20351;&#29992;&#21738;&#20010;&#20272;&#35745;&#22120;&#12289;&#20351;&#29992;&#21738;&#20010;&#20998;&#24067;&#36335;&#24452;&#20197;&#21450;&#26159;&#21542;&#20351;&#29992;&#20998;&#24067;&#36335;&#24452;&#65307;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#23545;&#20110;&#21738;&#20123;&#36873;&#25321;&#26159;&#26377;&#25928;&#30340;&#36824;&#27809;&#26377;&#26126;&#30830;&#30340;&#29702;&#35770;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#36890;&#36807;&#20135;&#29983;&#30340;&#28176;&#36817;&#20272;&#35745;&#35823;&#24046;&#26469;&#35780;&#20272;&#27599;&#20010;&#35774;&#35745;&#36873;&#25321;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20351;&#29992;NCE&#27604;&#37325;&#35201;&#24615;&#25277;&#26679;&#20272;&#35745;&#22120;&#26356;&#26377;&#25928;&#65292;&#20294;&#22312;&#26080;&#38480;&#23567;&#30340;&#36335;&#24452;&#27493;&#38271;&#30340;&#26497;&#38480;&#19979;&#65292;&#24046;&#24322;&#28040;&#22833;&#20102;&#12290;&#31532;&#20108;&#65292;&#25105;&#20204;&#21457;&#29616;&#20351;&#29992;&#20960;&#20309;&#36335;&#24452;&#23558;&#20272;&#35745;&#35823;&#24046;&#20174;&#25351;&#25968;&#32423;&#38477;&#20302;&#21040;...
&lt;/p&gt;
&lt;p&gt;
Recent research has developed several Monte Carlo methods for estimating the normalization constant (partition function) based on the idea of annealing. This means sampling successively from a path of distributions that interpolate between a tractable "proposal" distribution and the unnormalized "target" distribution. Prominent estimators in this family include annealed importance sampling and annealed noise-contrastive estimation (NCE). Such methods hinge on a number of design choices: which estimator to use, which path of distributions to use and whether to use a path at all; so far, there is no definitive theory on which choices are efficient. Here, we evaluate each design choice by the asymptotic estimation error it produces. First, we show that using NCE is more efficient than the importance sampling estimator, but in the limit of infinitesimal path steps, the difference vanishes. Second, we find that using the geometric path brings down the estimation error from an exponential to
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#20110;&#24037;&#20316;&#20013;&#30340;&#20449;&#24687;&#35770;&#32773;&#26469;&#35828;&#65292;&#20449;&#24687;&#20960;&#20309;&#30340;&#22522;&#26412;&#27010;&#36848;&#12290;&#35299;&#37322;&#20102;&#32479;&#35745;&#27969;&#24418;&#19978;&#30340;&#24046;&#24322;&#12289;&#36317;&#31163;&#12289;&#27491;&#20132;&#24615;&#21644;&#27979;&#22320;&#32447;&#30340;&#27010;&#24565;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#20123;&#26368;&#36817;&#30340;&#20449;&#24687;&#20960;&#20309;&#21457;&#23637;&#12290;</title><link>http://arxiv.org/abs/2310.03884</link><description>&lt;p&gt;
&#20449;&#24687;&#20960;&#20309;&#23545;&#20110;&#24037;&#20316;&#20013;&#30340;&#20449;&#24687;&#35770;&#32773;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Information Geometry for the Working Information Theorist. (arXiv:2310.03884v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03884
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#20110;&#24037;&#20316;&#20013;&#30340;&#20449;&#24687;&#35770;&#32773;&#26469;&#35828;&#65292;&#20449;&#24687;&#20960;&#20309;&#30340;&#22522;&#26412;&#27010;&#36848;&#12290;&#35299;&#37322;&#20102;&#32479;&#35745;&#27969;&#24418;&#19978;&#30340;&#24046;&#24322;&#12289;&#36317;&#31163;&#12289;&#27491;&#20132;&#24615;&#21644;&#27979;&#22320;&#32447;&#30340;&#27010;&#24565;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#20123;&#26368;&#36817;&#30340;&#20449;&#24687;&#20960;&#20309;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#20960;&#20309;&#26159;&#20174;&#20960;&#20309;&#35282;&#24230;&#30740;&#31350;&#32479;&#35745;&#27969;&#24418;&#65292;&#21363;&#27010;&#29575;&#20998;&#24067;&#31354;&#38388;&#30340;&#23398;&#31185;&#12290;&#20854;&#32463;&#20856;&#30340;&#20449;&#24687;&#29702;&#35770;&#24212;&#29992;&#19982;&#32479;&#35745;&#27010;&#24565;&#65288;&#22914;&#36153;&#33293;&#23572;&#20449;&#24687;&#12289;&#20805;&#20998;&#32479;&#35745;&#37327;&#21644;&#26377;&#25928;&#20272;&#35745;&#37327;&#65289;&#26377;&#20851;&#12290;&#22914;&#20170;&#65292;&#20449;&#24687;&#20960;&#20309;&#24050;&#32463;&#25104;&#20026;&#19968;&#20010;&#36328;&#23398;&#31185;&#39046;&#22495;&#65292;&#22312;&#38647;&#36798;&#24863;&#30693;&#12289;&#38453;&#21015;&#20449;&#21495;&#22788;&#29702;&#12289;&#37327;&#23376;&#29289;&#29702;&#12289;&#28145;&#24230;&#23398;&#20064;&#21644;&#26368;&#20248;&#20256;&#36755;&#31561;&#21508;&#20010;&#39046;&#22495;&#20013;&#25214;&#21040;&#24212;&#29992;&#12290;&#26412;&#25991;&#23545;&#20110;&#19981;&#29087;&#24713;&#36825;&#19968;&#20196;&#20154;&#28608;&#21160;&#30340;&#30740;&#31350;&#39046;&#22495;&#30340;&#20449;&#24687;&#35770;&#32773;&#65292;&#25552;&#20379;&#20102;&#22522;&#26412;&#30340;&#20449;&#24687;&#20960;&#20309;&#27010;&#36848;&#12290;&#25105;&#20204;&#35299;&#37322;&#20102;&#32479;&#35745;&#27969;&#24418;&#19978;&#30340;&#24046;&#24322;&#27010;&#24565;&#65292;&#24191;&#20041;&#30340;&#36317;&#31163;&#27010;&#24565;&#65292;&#27491;&#20132;&#24615;&#21644;&#27979;&#22320;&#32447;&#65292;&#20174;&#32780;&#20026;&#20855;&#20307;&#30340;&#24212;&#29992;&#21644;&#26032;&#39062;&#30340;&#29702;&#35770;&#30740;&#31350;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;&#25105;&#20204;&#36824;&#24378;&#35843;&#20102;&#19968;&#20123;&#36817;&#26399;&#30340;&#20449;&#24687;&#20960;&#20309;&#21457;&#23637;&#65292;&#36825;&#20123;&#21457;&#23637;&#23545;&#20110;&#26356;&#24191;&#27867;&#30340;&#20449;&#24687;&#35770;&#32773;&#20855;&#26377;&#20852;&#36259;&#12290;
&lt;/p&gt;
&lt;p&gt;
Information geometry is a study of statistical manifolds, that is, spaces of probability distributions from a geometric perspective. Its classical information-theoretic applications relate to statistical concepts such as Fisher information, sufficient statistics, and efficient estimators. Today, information geometry has emerged as an interdisciplinary field that finds applications in diverse areas such as radar sensing, array signal processing, quantum physics, deep learning, and optimal transport. This article presents an overview of essential information geometry to initiate an information theorist, who may be unfamiliar with this exciting area of research. We explain the concepts of divergences on statistical manifolds, generalized notions of distances, orthogonality, and geodesics, thereby paving the way for concrete applications and novel theoretical investigations. We also highlight some recent information-geometric developments, which are of interest to the broader information t
&lt;/p&gt;</description></item><item><title>Fishnets&#26159;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#20449;&#24687;&#26368;&#20248;&#30340;&#38598;&#21512;&#21644;&#22270;&#32858;&#21512;&#30340;&#26041;&#27861;&#65292;&#22312;&#35268;&#27169;&#19978;&#21487;&#20197;&#20248;&#21270;&#21040;&#20219;&#24847;&#25968;&#37327;&#30340;&#25968;&#25454;&#23545;&#35937;&#65292;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#33021;&#22815;&#39281;&#21644;&#36125;&#21494;&#26031;&#20449;&#24687;&#20869;&#23481;&#65292;&#24182;&#21487;&#29992;&#20110;GNNs&#20013;&#30340;&#28040;&#24687;&#20256;&#36882;&#12290;</title><link>http://arxiv.org/abs/2310.03812</link><description>&lt;p&gt;
&#40060;&#32593;&#65306;&#20449;&#24687;&#26368;&#20248;&#65292;&#21487;&#25193;&#23637;&#30340;&#38598;&#21512;&#21644;&#22270;&#32858;&#21512;
&lt;/p&gt;
&lt;p&gt;
Fishnets: Information-Optimal, Scalable Aggregation for Sets and Graphs. (arXiv:2310.03812v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03812
&lt;/p&gt;
&lt;p&gt;
Fishnets&#26159;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#20449;&#24687;&#26368;&#20248;&#30340;&#38598;&#21512;&#21644;&#22270;&#32858;&#21512;&#30340;&#26041;&#27861;&#65292;&#22312;&#35268;&#27169;&#19978;&#21487;&#20197;&#20248;&#21270;&#21040;&#20219;&#24847;&#25968;&#37327;&#30340;&#25968;&#25454;&#23545;&#35937;&#65292;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#33021;&#22815;&#39281;&#21644;&#36125;&#21494;&#26031;&#20449;&#24687;&#20869;&#23481;&#65292;&#24182;&#21487;&#29992;&#20110;GNNs&#20013;&#30340;&#28040;&#24687;&#20256;&#36882;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#38598;&#21512;&#30340;&#23398;&#20064;&#26159;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#21644;&#32593;&#32476;&#31185;&#23398;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#21450;&#20854;&#19981;&#21547;&#36793;&#30340;&#23545;&#24212;&#29289;Deepsets&#22312;&#19981;&#35268;&#21017;&#21644;&#25299;&#25169;&#22797;&#26434;&#30340;&#25968;&#25454;&#38598;&#19978;&#34987;&#35777;&#26126;&#38750;&#24120;&#26377;&#29992;&#12290;&#20026;&#20102;&#23398;&#20064;&#38598;&#21512;&#25104;&#21592;&#30340;&#20449;&#24687;&#20016;&#23500;&#30340;&#23884;&#20837;&#65292;&#20851;&#38190;&#26159;&#25351;&#23450;&#19968;&#20010;&#32858;&#21512;&#20989;&#25968;&#65292;&#36890;&#24120;&#26159;&#27714;&#21644;&#12289;&#26368;&#22823;&#20540;&#25110;&#22343;&#20540;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;Fishnets&#65292;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#38598;&#21512;&#25968;&#25454;&#21644;&#22270;&#32858;&#21512;&#30340;&#20449;&#24687;&#26368;&#20248;&#23884;&#20837;&#31574;&#30053;&#65292;&#36866;&#29992;&#20110;&#36125;&#21494;&#26031;&#25512;&#29702;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#65306;i&#65289;Fishnets&#31070;&#32463;&#25688;&#35201;&#21487;&#20197;&#26368;&#20248;&#22320;&#25193;&#23637;&#21040;&#20219;&#24847;&#25968;&#37327;&#30340;&#25968;&#25454;&#23545;&#35937;&#65307;ii&#65289;Fishnets&#32858;&#21512;&#23545;&#25968;&#25454;&#20998;&#24067;&#30340;&#25913;&#21464;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#32780;&#26631;&#20934;&#30340;Deepsets&#19981;&#20855;&#22791;&#36825;&#31181;&#29305;&#24615;&#65307;iii&#65289;Fishnets&#39281;&#21644;&#36125;&#21494;&#26031;&#20449;&#24687;&#20869;&#23481;&#65292;&#24182;&#25193;&#23637;&#21040;MCMC&#25216;&#26415;&#22833;&#36133;&#30340;&#39046;&#22495;&#65307;iv&#65289;Fishnets&#21487;&#20197;&#20316;&#20026;GNN&#20013;&#30340;&#19968;&#20010;&#25554;&#20837;&#24335;&#32858;&#21512;&#26041;&#26696;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#37319;&#29992;Fishnets&#32858;&#21512;&#26041;&#26696;&#36827;&#34892;&#28040;&#24687;&#20256;&#36882;&#65292;GNNs&#21487;&#20197;&#23454;&#29616; &#36798;&#21040;
&lt;/p&gt;
&lt;p&gt;
Set-based learning is an essential component of modern deep learning and network science. Graph Neural Networks (GNNs) and their edge-free counterparts Deepsets have proven remarkably useful on ragged and topologically challenging datasets. The key to learning informative embeddings for set members is a specified aggregation function, usually a sum, max, or mean. We propose Fishnets, an aggregation strategy for learning information-optimal embeddings for sets of data for both Bayesian inference and graph aggregation. We demonstrate that i) Fishnets neural summaries can be scaled optimally to an arbitrary number of data objects, ii) Fishnets aggregations are robust to changes in data distribution, unlike standard deepsets, iii) Fishnets saturate Bayesian information content and extend to regimes where MCMC techniques fail and iv) Fishnets can be used as a drop-in aggregation scheme within GNNs. We show that by adopting a Fishnets aggregation scheme for message passing, GNNs can achieve 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23558;&#33258;&#36866;&#24212;&#26680;&#26041;&#27861;&#24212;&#29992;&#20110;&#20004;&#20010;&#24072;&#29983;&#27169;&#22411;&#65292;&#39044;&#27979;&#20102;&#29305;&#24449;&#23398;&#20064;&#21644; Grokking &#30340;&#24615;&#36136;&#65292;&#24182;&#23637;&#31034;&#20102; Grokking &#19982;&#30456;&#21464;&#29702;&#35770;&#20043;&#38388;&#30340;&#26144;&#23556;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2310.03789</link><description>&lt;p&gt;
&#22909;&#34920;&#31034;&#30340;&#28082;&#28404;&#65306;&#22312;&#20004;&#23618;&#32593;&#32476;&#20013; grokking &#20316;&#20026;&#19968;&#38454;&#30456;&#21464;
&lt;/p&gt;
&lt;p&gt;
Droplets of Good Representations: Grokking as a First Order Phase Transition in Two Layer Networks. (arXiv:2310.03789v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03789
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#33258;&#36866;&#24212;&#26680;&#26041;&#27861;&#24212;&#29992;&#20110;&#20004;&#20010;&#24072;&#29983;&#27169;&#22411;&#65292;&#39044;&#27979;&#20102;&#29305;&#24449;&#23398;&#20064;&#21644; Grokking &#30340;&#24615;&#36136;&#65292;&#24182;&#23637;&#31034;&#20102; Grokking &#19982;&#30456;&#21464;&#29702;&#35770;&#20043;&#38388;&#30340;&#26144;&#23556;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476; (DNN) &#30340;&#19968;&#20010;&#20851;&#38190;&#29305;&#24615;&#26159;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#33021;&#22815;&#23398;&#20064;&#26032;&#30340;&#29305;&#24449;&#12290;&#36825;&#31181;&#28145;&#24230;&#23398;&#20064;&#30340;&#26377;&#36259;&#26041;&#38754;&#22312;&#26368;&#36817;&#25253;&#36947;&#30340; Grokking &#29616;&#35937;&#20013;&#34920;&#29616;&#24471;&#26368;&#20026;&#26126;&#26174;&#12290;&#34429;&#28982;&#20027;&#35201;&#20307;&#29616;&#20026;&#27979;&#35797;&#20934;&#30830;&#24615;&#30340;&#31361;&#21464;&#22686;&#21152;&#65292;&#20294; Grokking &#20063;&#34987;&#35748;&#20026;&#26159;&#19968;&#31181;&#36229;&#36234;&#25042;&#24816;&#23398;&#20064;/&#39640;&#26031;&#36807;&#31243; (GP) &#30340;&#29616;&#35937;&#65292;&#28041;&#21450;&#29305;&#24449;&#23398;&#20064;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#23558;&#29305;&#24449;&#23398;&#20064;&#29702;&#35770;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#33258;&#36866;&#24212;&#26680;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#20855;&#26377;&#31435;&#26041;&#22810;&#39033;&#24335;&#21644;&#27169;&#21152;&#27861;&#25945;&#24072;&#30340;&#20004;&#20010;&#24072;&#29983;&#27169;&#22411;&#12290;&#25105;&#20204;&#22312;&#36825;&#20123;&#27169;&#22411;&#19978;&#25552;&#20379;&#20102;&#20851;&#20110;&#29305;&#24449;&#23398;&#20064;&#21644; Grokking &#24615;&#36136;&#30340;&#20998;&#26512;&#39044;&#27979;&#65292;&#24182;&#23637;&#31034;&#20102; Grokking &#19982;&#30456;&#21464;&#29702;&#35770;&#20043;&#38388;&#30340;&#26144;&#23556;&#20851;&#31995;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312; Grokking &#20043;&#21518;&#65292;DNN &#30340;&#29366;&#24577;&#31867;&#20284;&#20110;&#19968;&#38454;&#30456;&#21464;&#21518;&#30340;&#28151;&#21512;&#30456;&#12290;&#22312;&#36825;&#20010;&#28151;&#21512;&#30456;&#20013;&#65292;DNN &#29983;&#25104;&#20102;&#19982;&#20043;&#21069;&#26126;&#26174;&#19981;&#21516;&#30340;&#25945;&#24072;&#30340;&#26377;&#29992;&#20869;&#37096;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
A key property of deep neural networks (DNNs) is their ability to learn new features during training. This intriguing aspect of deep learning stands out most clearly in recently reported Grokking phenomena. While mainly reflected as a sudden increase in test accuracy, Grokking is also believed to be a beyond lazy-learning/Gaussian Process (GP) phenomenon involving feature learning. Here we apply a recent development in the theory of feature learning, the adaptive kernel approach, to two teacher-student models with cubic-polynomial and modular addition teachers. We provide analytical predictions on feature learning and Grokking properties of these models and demonstrate a mapping between Grokking and the theory of phase transitions. We show that after Grokking, the state of the DNN is analogous to the mixed phase following a first-order phase transition. In this mixed phase, the DNN generates useful internal representations of the teacher that are sharply distinct from those before the 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#38750;&#32447;&#24615;&#29983;&#25104;&#24335;&#21387;&#32553;&#24863;&#30693;&#20013;&#23454;&#29616;&#32479;&#19968;&#30340;&#20449;&#21495;&#24674;&#22797;&#12290;&#35813;&#26694;&#26550;&#36866;&#29992;&#20110;&#38750;&#32447;&#24615;&#21644;&#21487;&#33021;&#38750;&#36830;&#32493;&#25110;&#26410;&#30693;&#30340;&#35266;&#27979;&#27169;&#22411;&#65292;&#24182;&#19988;&#21487;&#20197;&#24674;&#22797;&#29983;&#25104;&#27169;&#22411;&#20013;&#25152;&#26377;&#21487;&#33021;&#30340;&#20449;&#21495;&#12290;</title><link>http://arxiv.org/abs/2310.03758</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#29983;&#25104;&#24335;&#21387;&#32553;&#24863;&#30693;&#20013;&#32479;&#19968;&#20449;&#21495;&#24674;&#22797;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Unified Framework for Uniform Signal Recovery in Nonlinear Generative Compressed Sensing. (arXiv:2310.03758v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03758
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#38750;&#32447;&#24615;&#29983;&#25104;&#24335;&#21387;&#32553;&#24863;&#30693;&#20013;&#23454;&#29616;&#32479;&#19968;&#30340;&#20449;&#21495;&#24674;&#22797;&#12290;&#35813;&#26694;&#26550;&#36866;&#29992;&#20110;&#38750;&#32447;&#24615;&#21644;&#21487;&#33021;&#38750;&#36830;&#32493;&#25110;&#26410;&#30693;&#30340;&#35266;&#27979;&#27169;&#22411;&#65292;&#24182;&#19988;&#21487;&#20197;&#24674;&#22797;&#29983;&#25104;&#27169;&#22411;&#20013;&#25152;&#26377;&#21487;&#33021;&#30340;&#20449;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29983;&#25104;&#24335;&#21387;&#32553;&#24863;&#30693;&#20013;&#65292;&#25105;&#20204;&#24076;&#26395;&#20351;&#29992;&#29983;&#25104;&#20808;&#39564;&#20174;m&#20010;&#27979;&#37327;&#20013;&#65288;m&#8810;n&#65289;&#24674;&#22797;&#19968;&#20010;&#20449;&#21495;x&#8727;&#8712;Rn&#65292;&#20854;&#20013;G&#36890;&#24120;&#26159;&#19968;&#20010;L-Lipschitz&#36830;&#32493;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;B2k(r)&#34920;&#31034;Rk&#20013;&#30340;&#21322;&#24452;&#20026;r&#30340;&#8467;2&#29699;&#12290;&#22312;&#38750;&#32447;&#24615;&#27979;&#37327;&#19979;&#65292;&#22823;&#22810;&#25968;&#20808;&#21069;&#30340;&#32467;&#26524;&#26159;&#38750;&#22343;&#21248;&#30340;&#65292;&#21363;&#23427;&#20204;&#23545;&#20110;&#22266;&#23450;&#30340;x&#8727;&#20855;&#26377;&#39640;&#27010;&#29575;&#65292;&#32780;&#19981;&#26159;&#23545;&#20110;&#25152;&#26377;&#30340;x&#8727;&#21516;&#26102;&#25104;&#31435;&#12290;&#26412;&#25991;&#24314;&#31435;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#26469;&#25512;&#23548;&#38750;&#32447;&#24615;&#29983;&#25104;&#24335;&#21387;&#32553;&#24863;&#30693;&#20013;&#30340;&#22343;&#21248;&#24674;&#22797;&#20445;&#35777;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#38750;&#32447;&#24615;&#21644;&#21487;&#33021;&#38750;&#36830;&#32493;&#25110;&#26410;&#30693;&#30340;&#35266;&#27979;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21253;&#25324;&#20102;1&#20301;/&#22343;&#21248;&#37327;&#21270;&#35266;&#27979;&#21644;&#21333;&#32034;&#24341;&#27169;&#22411;&#20316;&#20026;&#35268;&#33539;&#31034;&#20363;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#20351;&#29992;&#24863;&#30693;&#38598;&#21512;&#30340;&#21333;&#20010;&#23454;&#29616;&#21644;&#24191;&#20041;Lasso&#65292;&#25152;&#26377;&#30340;x&#8727;&#8712;G(B2k(r))&#21487;&#20197;&#24674;&#22797;&#21040;&#19968;&#20010;el
&lt;/p&gt;
&lt;p&gt;
In generative compressed sensing (GCS), we want to recover a signal $\mathbf{x}^* \in \mathbb{R}^n$ from $m$ measurements ($m\ll n$) using a generative prior $\mathbf{x}^*\in G(\mathbb{B}_2^k(r))$, where $G$ is typically an $L$-Lipschitz continuous generative model and $\mathbb{B}_2^k(r)$ represents the radius-$r$ $\ell_2$-ball in $\mathbb{R}^k$. Under nonlinear measurements, most prior results are non-uniform, i.e., they hold with high probability for a fixed $\mathbf{x}^*$ rather than for all $\mathbf{x}^*$ simultaneously. In this paper, we build a unified framework to derive uniform recovery guarantees for nonlinear GCS where the observation model is nonlinear and possibly discontinuous or unknown. Our framework accommodates GCS with 1-bit/uniformly quantized observations and single index models as canonical examples. Specifically, using a single realization of the sensing ensemble and generalized Lasso, {\em all} $\mathbf{x}^*\in G(\mathbb{B}_2^k(r))$ can be recovered up to an $\el
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#20351;&#29992;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#21644;&#32447;&#24615;&#26368;&#23567;&#20108;&#20056;&#27861;&#30340;&#31616;&#21333;&#26694;&#26550;&#65292;&#28436;&#31034;&#20102;&#20132;&#21449;&#23398;&#20064;&#30340;&#26426;&#21046;&#12290;</title><link>http://arxiv.org/abs/2310.03751</link><description>&lt;p&gt;
&#32447;&#24615;&#26368;&#23567;&#20108;&#20056;&#38382;&#39064;&#20013;&#20351;&#29992;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#36827;&#34892;&#20132;&#21449;&#23398;&#20064;&#30340;&#31616;&#21333;&#31034;&#20363;
&lt;/p&gt;
&lt;p&gt;
A Simple Illustration of Interleaved Learning using Kalman Filter for Linear Least Squares. (arXiv:2310.03751v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03751
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#20351;&#29992;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#21644;&#32447;&#24615;&#26368;&#23567;&#20108;&#20056;&#27861;&#30340;&#31616;&#21333;&#26694;&#26550;&#65292;&#28436;&#31034;&#20102;&#20132;&#21449;&#23398;&#20064;&#30340;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20132;&#21449;&#23398;&#20064;&#26159;&#19968;&#31181;&#21463;&#29983;&#29289;&#21551;&#21457;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#20013;&#26377;&#30528;&#24456;&#22909;&#30340;&#32467;&#26524;&#12290;&#22312;&#36825;&#20010;&#31616;&#30701;&#30340;&#35828;&#26126;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#22522;&#20110;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#21644;&#32447;&#24615;&#26368;&#23567;&#20108;&#20056;&#27861;&#30340;&#31616;&#21333;&#32479;&#35745;&#21644;&#20248;&#21270;&#26694;&#26550;&#65292;&#26469;&#28436;&#31034;&#20132;&#21449;&#23398;&#20064;&#30340;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Interleaved learning in machine learning algorithms is a biologically inspired training method with promising results. In this short note, we illustrate the interleaving mechanism via a simple statistical and optimization framework based on Kalman Filter for Linear Least Squares.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22522;&#20110;&#27169;&#22411;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#21709;&#24212;&#31867;&#22411;&#30340;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#19981;&#21464;&#24615;&#20551;&#35774;&#20174;&#24322;&#36136;&#29615;&#22659;&#30340;&#25968;&#25454;&#20013;&#36755;&#20986;&#19968;&#37096;&#20998;&#22240;&#26524;&#29305;&#24449;&#30340;&#23376;&#38598;&#65292;&#36866;&#29992;&#20110;&#19968;&#33324;&#30340;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#21644;&#38750;&#21442;&#25968;&#35774;&#32622;&#65292;&#35299;&#20915;&#20102;&#38750;&#21442;&#25968;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#20302;&#21151;&#29575;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.12833</link><description>&lt;p&gt;
&#22522;&#20110;&#27169;&#22411;&#30340;&#36890;&#29992;&#21709;&#24212;&#31867;&#22411;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Model-based causal feature selection for general response types. (arXiv:2309.12833v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12833
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22522;&#20110;&#27169;&#22411;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#21709;&#24212;&#31867;&#22411;&#30340;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#19981;&#21464;&#24615;&#20551;&#35774;&#20174;&#24322;&#36136;&#29615;&#22659;&#30340;&#25968;&#25454;&#20013;&#36755;&#20986;&#19968;&#37096;&#20998;&#22240;&#26524;&#29305;&#24449;&#30340;&#23376;&#38598;&#65292;&#36866;&#29992;&#20110;&#19968;&#33324;&#30340;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#21644;&#38750;&#21442;&#25968;&#35774;&#32622;&#65292;&#35299;&#20915;&#20102;&#38750;&#21442;&#25968;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#20302;&#21151;&#29575;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#21457;&#29616;&#22240;&#26524;&#20851;&#31995;&#26159;&#19968;&#39033;&#22522;&#26412;&#32780;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#22312;&#26576;&#20123;&#24212;&#29992;&#20013;&#65292;&#20165;&#23398;&#20064;&#32473;&#23450;&#21709;&#24212;&#21464;&#37327;&#30340;&#22240;&#26524;&#29305;&#24449;&#21487;&#33021;&#24050;&#32463;&#36275;&#22815;&#65292;&#32780;&#19981;&#26159;&#23398;&#20064;&#25972;&#20010;&#28508;&#22312;&#30340;&#22240;&#26524;&#32467;&#26500;&#12290;&#19981;&#21464;&#22240;&#26524;&#39044;&#27979;&#65288;ICP&#65289;&#26159;&#19968;&#31181;&#29992;&#20110;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#30340;&#26041;&#27861;&#65292;&#38656;&#35201;&#26469;&#33258;&#24322;&#36136;&#29615;&#22659;&#30340;&#25968;&#25454;&#12290;ICP&#20551;&#35774;&#20174;&#30452;&#25509;&#21407;&#22240;&#29983;&#25104;&#21709;&#24212;&#30340;&#26426;&#21046;&#22312;&#25152;&#26377;&#29615;&#22659;&#20013;&#37117;&#30456;&#21516;&#65292;&#24182;&#21033;&#29992;&#36825;&#31181;&#19981;&#21464;&#24615;&#36755;&#20986;&#19968;&#37096;&#20998;&#22240;&#26524;&#29305;&#24449;&#30340;&#23376;&#38598;&#12290;ICP&#30340;&#26694;&#26550;&#24050;&#32463;&#25193;&#23637;&#21040;&#19968;&#33324;&#30340;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#21644;&#38750;&#21442;&#25968;&#35774;&#32622;&#65292;&#20351;&#29992;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#12290;&#28982;&#32780;&#65292;&#38750;&#21442;&#25968;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#32463;&#24120;&#21463;&#21040;&#20302;&#21151;&#29575;&#65288;&#25110;&#36739;&#24046;&#30340;&#31867;&#22411;I&#38169;&#35823;&#25511;&#21046;&#65289;&#30340;&#22256;&#25200;&#65292;&#24182;&#19988;&#19978;&#36848;&#21442;&#25968;&#27169;&#22411;&#19981;&#36866;&#29992;&#20110;&#21709;&#24212;&#19981;&#26159;&#22312;&#36830;&#32493;&#21051;&#24230;&#19978;&#27979;&#37327;&#30340;&#24212;&#29992;&#24773;&#20917;&#65292;&#32780;&#26159;&#21453;&#26144;&#20102;&#20998;&#31867;&#20449;&#24687;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Discovering causal relationships from observational data is a fundamental yet challenging task. In some applications, it may suffice to learn the causal features of a given response variable, instead of learning the entire underlying causal structure. Invariant causal prediction (ICP, Peters et al., 2016) is a method for causal feature selection which requires data from heterogeneous settings. ICP assumes that the mechanism for generating the response from its direct causes is the same in all settings and exploits this invariance to output a subset of the causal features. The framework of ICP has been extended to general additive noise models and to nonparametric settings using conditional independence testing. However, nonparametric conditional independence testing often suffers from low power (or poor type I error control) and the aforementioned parametric models are not suitable for applications in which the response is not measured on a continuous scale, but rather reflects categor
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#26657;&#20934;&#30340;&#22522;&#20934;&#30740;&#31350;&#65292;&#21033;&#29992;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#31354;&#38388;&#25506;&#32034;&#20102;&#27169;&#22411;&#26657;&#20934;&#23646;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#27169;&#22411;&#26657;&#20934;&#21487;&#20197;&#22312;&#19981;&#21516;&#20219;&#21153;&#20013;&#27867;&#21270;&#65292;&#24182;&#21487;&#20197;&#21516;&#26102;&#20860;&#39038;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#26657;&#20934;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.11838</link><description>&lt;p&gt;
&#19968;&#20010;&#20851;&#20110;&#26657;&#20934;&#30340;&#22522;&#20934;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Benchmark Study on Calibration. (arXiv:2308.11838v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11838
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#26657;&#20934;&#30340;&#22522;&#20934;&#30740;&#31350;&#65292;&#21033;&#29992;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#31354;&#38388;&#25506;&#32034;&#20102;&#27169;&#22411;&#26657;&#20934;&#23646;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#27169;&#22411;&#26657;&#20934;&#21487;&#20197;&#22312;&#19981;&#21516;&#20219;&#21153;&#20013;&#27867;&#21270;&#65292;&#24182;&#21487;&#20197;&#21516;&#26102;&#20860;&#39038;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#26657;&#20934;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#36234;&#26469;&#36234;&#24191;&#27867;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#36825;&#20123;&#27169;&#22411;&#22797;&#26434;&#24615;&#30340;&#22686;&#21152;&#65292;&#23427;&#20204;&#24448;&#24448;&#38754;&#20020;&#26657;&#20934;&#38382;&#39064;&#65292;&#23613;&#31649;&#39044;&#27979;&#20934;&#30830;&#24615;&#26377;&#25152;&#25552;&#39640;&#12290;&#35768;&#22810;&#30740;&#31350;&#36890;&#36807;&#25968;&#25454;&#39044;&#22788;&#29702;&#12289;&#20351;&#29992;&#29305;&#23450;&#25439;&#22833;&#20989;&#25968;&#21644;&#35757;&#32451;&#26694;&#26550;&#26469;&#25913;&#21892;&#26657;&#20934;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#23545;&#26657;&#20934;&#23646;&#24615;&#30340;&#30740;&#31350;&#26377;&#28857;&#34987;&#24573;&#35270;&#20102;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21033;&#29992;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#65288;NAS&#65289;&#25628;&#32034;&#31354;&#38388;&#65292;&#22312;&#20840;&#38754;&#25506;&#32034;&#26657;&#20934;&#23646;&#24615;&#30340;&#27169;&#22411;&#26550;&#26500;&#31354;&#38388;&#20013;&#25552;&#20379;&#20102;&#19968;&#20010;&#35814;&#23613;&#30340;&#27169;&#22411;&#26550;&#26500;&#31354;&#38388;&#12290;&#25105;&#20204;&#29305;&#21035;&#21019;&#24314;&#20102;&#19968;&#20010;&#27169;&#22411;&#26657;&#20934;&#25968;&#25454;&#38598;&#12290;&#35813;&#25968;&#25454;&#38598;&#22312;&#24191;&#27867;&#20351;&#29992;&#30340;NATS-Bench&#25628;&#32034;&#31354;&#38388;&#20013;&#35780;&#20272;&#20102;90&#20010;&#22522;&#20110;&#21306;&#38388;&#30340;&#26657;&#20934;&#24230;&#37327;&#21644;12&#20010;&#20854;&#20182;&#26657;&#20934;&#24230;&#37327;&#65292;&#28085;&#30422;&#20102;117,702&#20010;&#29420;&#29305;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#26088;&#22312;&#36890;&#36807;&#25105;&#20204;&#25552;&#20986;&#30340;&#25968;&#25454;&#38598;&#22238;&#31572;&#35813;&#39046;&#22495;&#19968;&#20123;&#38271;&#26399;&#23384;&#22312;&#30340;&#38382;&#39064;&#65306;&#65288;i&#65289;&#27169;&#22411;&#26657;&#20934;&#33021;&#21542;&#22312;&#19981;&#21516;&#20219;&#21153;&#20013;&#27867;&#21270;&#65311;&#65288;ii&#65289;&#33021;&#21542;&#21516;&#26102;&#20860;&#39038;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#26657;&#20934;&#24615;&#33021;&#65311;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks are increasingly utilized in various machine learning tasks. However, as these models grow in complexity, they often face calibration issues, despite enhanced prediction accuracy. Many studies have endeavored to improve calibration performance through data preprocessing, the use of specific loss functions, and training frameworks. Yet, investigations into calibration properties have been somewhat overlooked. Our study leverages the Neural Architecture Search (NAS) search space, offering an exhaustive model architecture space for thorough calibration properties exploration. We specifically create a model calibration dataset. This dataset evaluates 90 bin-based and 12 additional calibration measurements across 117,702 unique neural networks within the widely employed NATS-Bench search space. Our analysis aims to answer several longstanding questions in the field, using our proposed dataset: (i) Can model calibration be generalized across different tasks? (ii) Can rob
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32508;&#21512;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#65288;PINN&#65289;&#35774;&#35745;&#21644;&#35757;&#32451;&#21327;&#35758;&#30340;&#36873;&#25321;&#38382;&#39064;&#12290;&#36890;&#36807;&#23558;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#21644;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#31561;&#20215;&#36215;&#26469;&#65292;&#25512;&#23548;&#20986;&#20102;&#19968;&#31181;&#22312;&#22823;&#25968;&#25454;&#38598;&#38480;&#21046;&#19979;&#20915;&#23450;PINN&#39044;&#27979;&#30340;&#31215;&#20998;&#24494;&#20998;&#26041;&#31243;&#65292;&#20197;&#21450;&#36890;&#36807;&#21407;&#22987;&#24494;&#20998;&#26041;&#31243;&#20013;&#28304;&#39033;&#30340;&#35889;&#20998;&#35299;&#26469;&#37327;&#21270;&#32593;&#32476;&#24341;&#20837;&#30340;&#38544;&#21547;&#20559;&#24046;&#12290;</title><link>http://arxiv.org/abs/2307.06362</link><description>&lt;p&gt;
&#20855;&#26377;&#35889;&#20559;&#24046;&#21644;&#20869;&#26680;-&#20219;&#21153;&#23545;&#40784;&#30340;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Spectral-Bias and Kernel-Task Alignment in Physically Informed Neural Networks. (arXiv:2307.06362v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06362
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32508;&#21512;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#65288;PINN&#65289;&#35774;&#35745;&#21644;&#35757;&#32451;&#21327;&#35758;&#30340;&#36873;&#25321;&#38382;&#39064;&#12290;&#36890;&#36807;&#23558;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#21644;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#31561;&#20215;&#36215;&#26469;&#65292;&#25512;&#23548;&#20986;&#20102;&#19968;&#31181;&#22312;&#22823;&#25968;&#25454;&#38598;&#38480;&#21046;&#19979;&#20915;&#23450;PINN&#39044;&#27979;&#30340;&#31215;&#20998;&#24494;&#20998;&#26041;&#31243;&#65292;&#20197;&#21450;&#36890;&#36807;&#21407;&#22987;&#24494;&#20998;&#26041;&#31243;&#20013;&#28304;&#39033;&#30340;&#35889;&#20998;&#35299;&#26469;&#37327;&#21270;&#32593;&#32476;&#24341;&#20837;&#30340;&#38544;&#21547;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#65288;PINN&#65289;&#26159;&#35299;&#20915;&#24494;&#20998;&#26041;&#31243;&#30340;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#26032;&#26041;&#27861;&#12290;&#19982;&#35768;&#22810;&#20854;&#20182;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#19968;&#26679;&#65292;PINN&#30340;&#35774;&#35745;&#21644;&#35757;&#32451;&#21327;&#35758;&#30340;&#36873;&#25321;&#38656;&#35201;&#31934;&#24515;&#21046;&#23450;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32508;&#21512;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#23545;&#36825;&#20010;&#37325;&#35201;&#38382;&#39064;&#36827;&#34892;&#20102;&#38416;&#36848;&#12290;&#36890;&#36807;&#21033;&#29992;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#21644;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#65288;GPR&#65289;&#20043;&#38388;&#30340;&#31561;&#20215;&#24615;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#19968;&#31181;&#22312;&#22823;&#25968;&#25454;&#38598;&#38480;&#21046;&#19979;&#20915;&#23450;PINN&#39044;&#27979;&#30340;&#31215;&#20998;&#24494;&#20998;&#26041;&#31243;&#8212;&#8212;&#31070;&#32463;&#20449;&#24687;&#26041;&#31243;&#65288;NIE&#65289;&#12290;&#35813;&#26041;&#31243;&#36890;&#36807;&#21453;&#26144;&#26550;&#26500;&#36873;&#25321;&#30340;&#20869;&#26680;&#39033;&#26469;&#34917;&#20805;&#21407;&#22987;&#26041;&#31243;&#65292;&#24182;&#36890;&#36807;&#21407;&#22987;&#24494;&#20998;&#26041;&#31243;&#20013;&#28304;&#39033;&#30340;&#35889;&#20998;&#35299;&#26469;&#37327;&#21270;&#32593;&#32476;&#24341;&#20837;&#30340;&#38544;&#21547;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Physically informed neural networks (PINNs) are a promising emerging method for solving differential equations. As in many other deep learning approaches, the choice of PINN design and training protocol requires careful craftsmanship. Here, we suggest a comprehensive theoretical framework that sheds light on this important problem. Leveraging an equivalence between infinitely over-parameterized neural networks and Gaussian process regression (GPR), we derive an integro-differential equation that governs PINN prediction in the large data-set limit -- the Neurally-Informed Equation (NIE). This equation augments the original one by a kernel term reflecting architecture choices and allows quantifying implicit bias induced by the network via a spectral decomposition of the source term in the original differential equation.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#34394;&#25311;&#31890;&#23376;&#38543;&#26426;&#36924;&#36817;&#30340;&#21487;&#35777;&#36895;&#38480;&#21046;&#21464;&#31181;&#30340;SVGD&#31639;&#27861;&#65292;&#20855;&#26377;&#21487;&#35777;&#36895;&#30340;&#26377;&#38480;&#31890;&#23376;&#25910;&#25947;&#29575;&#12290;</title><link>http://arxiv.org/abs/2305.17558</link><description>&lt;p&gt;
&#22522;&#20110;&#34394;&#25311;&#31890;&#23376;&#38543;&#26426;&#36924;&#36817;&#30340;&#21487;&#35777;&#36895;&#38480;&#21046;&#21464;&#31181;&#30340;SVGD&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Provably Fast Finite Particle Variants of SVGD via Virtual Particle Stochastic Approximation. (arXiv:2305.17558v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17558
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#34394;&#25311;&#31890;&#23376;&#38543;&#26426;&#36924;&#36817;&#30340;&#21487;&#35777;&#36895;&#38480;&#21046;&#21464;&#31181;&#30340;SVGD&#31639;&#27861;&#65292;&#20855;&#26377;&#21487;&#35777;&#36895;&#30340;&#26377;&#38480;&#31890;&#23376;&#25910;&#25947;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Stein&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#65288;SVGD&#65289;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#23427;&#27169;&#25311;&#30456;&#20114;&#20316;&#29992;&#30340;&#31890;&#23376;&#31995;&#32479;&#20197;&#36817;&#20284;&#20174;&#30446;&#26631;&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#20855;&#26377;&#21508;&#31181;&#39046;&#22495;&#30340;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#32463;&#39564;&#24615;&#33021;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#23427;&#30340;&#32676;&#20307;&#65288;&#21363;&#65292;&#26080;&#38480;&#31890;&#23376;&#65289;&#26497;&#38480;&#21160;&#21147;&#23398;&#24050;&#32463;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#30740;&#31350;&#65292;&#20294;&#26159;SVGD&#22312;&#26377;&#38480;&#31890;&#23376;&#20307;&#21046;&#19979;&#30340;&#34892;&#20026;&#21017;&#19981;&#22826;&#28165;&#26970;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#31181;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;SVGD&#21464;&#20307;&#65292;&#21363;VP-SVGD&#65288;&#20174;&#27010;&#24565;&#19978;&#35762;&#24456;&#20248;&#38597;&#65289;&#21644;GB-SVGD&#65288;&#20174;&#32463;&#39564;&#19978;&#30475;&#24456;&#26377;&#25928;&#65289;&#65292;&#20855;&#26377;&#21487;&#35777;&#36895;&#30340;&#26377;&#38480;&#31890;&#23376;&#25910;&#25947;&#29575;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#8220;&#34394;&#25311;&#31890;&#23376;&#8221;&#30340;&#27010;&#24565;&#65292;&#24182;&#22312;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#20013;&#24320;&#21457;&#20102;&#20154;&#21475;&#26497;&#38480;SVGD&#21160;&#21147;&#23398;&#30340;&#26032;&#22411;&#38543;&#26426;&#36924;&#36817;&#26041;&#27861;&#65292;&#23427;&#20204;&#21487;&#20197;&#20351;&#29992;&#26377;&#38480;&#25968;&#37327;&#30340;&#31890;&#23376;&#31934;&#30830;&#23454;&#29616;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#20197;&#30475;&#20316;&#26159;SVGD&#30340;&#29305;&#23450;&#38543;&#26426;&#25209;&#22788;&#29702;&#36924;&#36817;&#65292;&#27604;&#26222;&#36890;&#26041;&#27861;&#26356;&#20855;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stein Variational Gradient Descent (SVGD) is a popular variational inference algorithm which simulates an interacting particle system to approximately sample from a target distribution, with impressive empirical performance across various domains. Theoretically, its population (i.e, infinite-particle) limit dynamics is well studied but the behavior of SVGD in the finite-particle regime is much less understood. In this work, we design two computationally efficient variants of SVGD, namely VP-SVGD (which is conceptually elegant) and GB-SVGD (which is empirically effective), with provably fast finite-particle convergence rates. We introduce the notion of \emph{virtual particles} and develop novel stochastic approximations of population-limit SVGD dynamics in the space of probability measures, which are exactly implementable using a finite number of particles. Our algorithms can be viewed as specific random-batch approximations of SVGD, which are computationally more efficient than ordinar
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#27604;&#20272;&#35745;&#21644;&#21322;&#30417;&#30563;&#23398;&#20064;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#30417;&#30563;&#20998;&#31867;&#22120;&#20195;&#26367;&#23494;&#24230;&#27604;&#26469;&#20272;&#35745;&#20840;&#23616;&#26368;&#20248;&#35299;&#30340;&#20004;&#32452;&#25968;&#25454;&#30340;&#31867;&#21035;&#27010;&#29575;&#65292;&#36991;&#20813;&#20102;&#20998;&#31867;&#22120;&#23545;&#20840;&#23616;&#35299;&#20915;&#26041;&#26696;&#36807;&#20110;&#33258;&#20449;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.15612</link><description>&lt;p&gt;
&#22522;&#20110;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Density Ratio Estimation-based Bayesian Optimization with Semi-Supervised Learning. (arXiv:2305.15612v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15612
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#27604;&#20272;&#35745;&#21644;&#21322;&#30417;&#30563;&#23398;&#20064;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#30417;&#30563;&#20998;&#31867;&#22120;&#20195;&#26367;&#23494;&#24230;&#27604;&#26469;&#20272;&#35745;&#20840;&#23616;&#26368;&#20248;&#35299;&#30340;&#20004;&#32452;&#25968;&#25454;&#30340;&#31867;&#21035;&#27010;&#29575;&#65292;&#36991;&#20813;&#20102;&#20998;&#31867;&#22120;&#23545;&#20840;&#23616;&#35299;&#20915;&#26041;&#26696;&#36807;&#20110;&#33258;&#20449;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#31185;&#23398;&#19982;&#24037;&#31243;&#30340;&#22810;&#20010;&#39046;&#22495;&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#22240;&#20026;&#23427;&#33021;&#39640;&#25928;&#22320;&#25214;&#21040;&#26114;&#36149;&#40657;&#30418;&#20989;&#25968;&#30340;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;&#36890;&#24120;&#65292;&#19968;&#20010;&#27010;&#29575;&#22238;&#24402;&#27169;&#22411;&#65292;&#22914;&#39640;&#26031;&#36807;&#31243;&#12289;&#38543;&#26426;&#26862;&#26519;&#21644;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65292;&#34987;&#24191;&#27867;&#29992;&#20316;&#26367;&#20195;&#20989;&#25968;&#65292;&#29992;&#20110;&#27169;&#25311;&#22312;&#32473;&#23450;&#36755;&#20837;&#21644;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#24773;&#20917;&#19979;&#20989;&#25968;&#35780;&#20272;&#30340;&#26174;&#24335;&#20998;&#24067;&#12290;&#38500;&#20102;&#22522;&#20110;&#27010;&#29575;&#22238;&#24402;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#22522;&#20110;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#24050;&#34987;&#25552;&#20986;&#26469;&#20272;&#35745;&#30456;&#23545;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#30456;&#23545;&#25509;&#36817;&#21644;&#30456;&#23545;&#36828;&#31163;&#30340;&#20004;&#32452;&#23494;&#24230;&#27604;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#21457;&#23637;&#36825;&#19968;&#30740;&#31350;&#65292;&#21487;&#20197;&#20351;&#29992;&#30417;&#30563;&#20998;&#31867;&#22120;&#26469;&#20272;&#35745;&#36825;&#20004;&#32452;&#30340;&#31867;&#21035;&#27010;&#29575;&#65292;&#32780;&#19981;&#26159;&#23494;&#24230;&#27604;&#12290;&#28982;&#32780;&#65292;&#27492;&#31574;&#30053;&#20013;&#20351;&#29992;&#30340;&#30417;&#30563;&#20998;&#31867;&#22120;&#20542;&#21521;&#20110;&#23545;&#20840;&#23616;&#35299;&#20915;&#26041;&#26696;&#36807;&#20110;&#33258;&#20449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization has attracted huge attention from diverse research areas in science and engineering, since it is capable of finding a global optimum of an expensive-to-evaluate black-box function efficiently. In general, a probabilistic regression model, e.g., Gaussian processes, random forests, and Bayesian neural networks, is widely used as a surrogate function to model an explicit distribution over function evaluations given an input to estimate and a training dataset. Beyond the probabilistic regression-based Bayesian optimization, density ratio estimation-based Bayesian optimization has been suggested in order to estimate a density ratio of the groups relatively close and relatively far to a global optimum. Developing this line of research further, a supervised classifier can be employed to estimate a class probability for the two groups instead of a density ratio. However, the supervised classifiers used in this strategy tend to be overconfident for a global solution candid
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21487;&#35745;&#31639;&#26799;&#24230;&#30340;&#29305;&#23450;&#31867;&#22411;&#30005;&#36335;&#30340;&#32463;&#20856;&#35757;&#32451;&#21327;&#35758;&#65292;&#29992;&#20110;&#22312;&#27010;&#29575;&#20998;&#24067;&#19978;&#35757;&#32451;&#37327;&#23376;&#29983;&#25104;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2210.13442</link><description>&lt;p&gt;
&#22312;&#27010;&#29575;&#20998;&#24067;&#19978;&#36827;&#34892;&#32463;&#20856;&#35757;&#32451;&#30340;&#37327;&#23376;&#29983;&#25104;&#27169;&#22411;&#30340;&#21327;&#35758;
&lt;/p&gt;
&lt;p&gt;
Protocols for classically training quantum generative models on probability distributions. (arXiv:2210.13442v2 [quant-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.13442
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21487;&#35745;&#31639;&#26799;&#24230;&#30340;&#29305;&#23450;&#31867;&#22411;&#30005;&#36335;&#30340;&#32463;&#20856;&#35757;&#32451;&#21327;&#35758;&#65292;&#29992;&#20110;&#22312;&#27010;&#29575;&#20998;&#24067;&#19978;&#35757;&#32451;&#37327;&#23376;&#29983;&#25104;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#29983;&#25104;&#24314;&#27169;(QGM)&#20381;&#36182;&#20110;&#20934;&#22791;&#37327;&#23376;&#24577;&#24182;&#20174;&#36825;&#20123;&#24577;&#20013;&#29983;&#25104;&#26679;&#26412;&#20316;&#20026;&#38544;&#34255; - &#25110;&#24050;&#30693; - &#27010;&#29575;&#20998;&#24067;&#12290;&#30001;&#20110;&#26576;&#20123;&#31867;&#21035;&#30340;&#37327;&#23376;&#24577;(&#30005;&#36335;)&#30340;&#20998;&#24067;&#22312;&#32463;&#20856;&#24773;&#20917;&#19979;&#24456;&#38590;&#37319;&#26679;&#65292;QGM&#25104;&#20026;&#37327;&#23376;&#32479;&#27835;&#23454;&#39564;&#30340;&#29702;&#24819;&#24179;&#21488;&#12290;&#27492;&#22806;&#65292;&#29983;&#25104;&#20219;&#21153;&#23545;&#20110;&#24037;&#19994;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#36234;&#26469;&#36234;&#37325;&#35201;&#65292;&#22240;&#27492;QGM&#26159;&#23637;&#31034;&#23454;&#38469;&#37327;&#23376;&#20248;&#21183;&#30340;&#19968;&#20010;&#24378;&#26377;&#21147;&#30340;&#20505;&#36873;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#36825;&#35201;&#27714;&#37327;&#23376;&#30005;&#36335;&#35201;&#32463;&#36807;&#35757;&#32451;&#20197;&#34920;&#31034;&#19982;&#24037;&#19994;&#30456;&#20851;&#30340;&#20998;&#24067;&#65292;&#24182;&#19988;&#30446;&#21069;&#30340;&#37327;&#23376;&#30828;&#20214;&#22312;&#23454;&#36341;&#20013;&#23545;&#35757;&#32451;&#38454;&#27573;&#20855;&#26377;&#26497;&#39640;&#30340;&#35757;&#32451;&#25104;&#26412;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29305;&#23450;&#31867;&#22411;&#30005;&#36335;&#30340;QGM&#30340;&#32463;&#20856;&#35757;&#32451;&#21327;&#35758;&#65292;&#35813;&#21327;&#35758;&#20801;&#35768;&#26377;&#25928;&#35745;&#31639;&#26799;&#24230;&#65292;&#21516;&#26102;&#20445;&#25345;&#37319;&#26679;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantum Generative Modelling (QGM) relies on preparing quantum states and generating samples from these states as hidden - or known - probability distributions. As distributions from some classes of quantum states (circuits) are inherently hard to sample classically, QGM represents an excellent testbed for quantum supremacy experiments. Furthermore, generative tasks are increasingly relevant for industrial machine learning applications, and thus QGM is a strong candidate for demonstrating a practical quantum advantage. However, this requires that quantum circuits are trained to represent industrially relevant distributions, and the corresponding training stage has an extensive training cost for current quantum hardware in practice. In this work, we propose protocols for classical training of QGMs based on circuits of the specific type that admit an efficient gradient computation, while remaining hard to sample. In particular, we consider Instantaneous Quantum Polynomial (IQP) circuits 
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;SGD&#21644;&#26435;&#37325;&#34928;&#20943;&#35757;&#32451;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#20250;&#23548;&#33268;&#23545;&#20110;&#26435;&#37325;&#30697;&#38453;&#30340;&#31209;&#26368;&#23567;&#21270;&#30340;&#20559;&#24046;&#65292;&#29305;&#21035;&#26159;&#22312;&#20351;&#29992;&#36739;&#23567;&#25209;&#37327;&#22823;&#23567;&#12289;&#26356;&#39640;&#23398;&#20064;&#29575;&#25110;&#22686;&#21152;&#26435;&#37325;&#34928;&#20943;&#26102;&#26356;&#20026;&#26174;&#33879;&#12290;&#27492;&#22806;&#65292;&#22312;&#20013;&#38388;&#31070;&#32463;&#32593;&#32476;&#23849;&#28291;&#26102;&#65292;&#23398;&#20064;&#30340;&#26435;&#37325;&#29305;&#21035;&#20302;&#31209;&#12290;&#36825;&#31181;&#20559;&#24046;&#19982;&#27867;&#21270;&#20043;&#38388;&#23384;&#22312;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2206.05794</link><description>&lt;p&gt;
SGD&#21644;&#26435;&#37325;&#34928;&#20943;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#34987;&#35777;&#26126;&#20250;&#24341;&#20837;&#20302;&#31209;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
SGD and Weight Decay Provably Induce a Low-Rank Bias in Neural Networks. (arXiv:2206.05794v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.05794
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;SGD&#21644;&#26435;&#37325;&#34928;&#20943;&#35757;&#32451;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#20250;&#23548;&#33268;&#23545;&#20110;&#26435;&#37325;&#30697;&#38453;&#30340;&#31209;&#26368;&#23567;&#21270;&#30340;&#20559;&#24046;&#65292;&#29305;&#21035;&#26159;&#22312;&#20351;&#29992;&#36739;&#23567;&#25209;&#37327;&#22823;&#23567;&#12289;&#26356;&#39640;&#23398;&#20064;&#29575;&#25110;&#22686;&#21152;&#26435;&#37325;&#34928;&#20943;&#26102;&#26356;&#20026;&#26174;&#33879;&#12290;&#27492;&#22806;&#65292;&#22312;&#20013;&#38388;&#31070;&#32463;&#32593;&#32476;&#23849;&#28291;&#26102;&#65292;&#23398;&#20064;&#30340;&#26435;&#37325;&#29305;&#21035;&#20302;&#31209;&#12290;&#36825;&#31181;&#20559;&#24046;&#19982;&#27867;&#21270;&#20043;&#38388;&#23384;&#22312;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#22312;&#35757;&#32451;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#26102;&#23398;&#20064;&#20302;&#31209;&#26435;&#37325;&#30697;&#38453;&#30340;&#20559;&#24046;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;&#23567;&#25209;&#37327;SGD&#21644;&#26435;&#37325;&#34928;&#20943;&#26469;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#20250;&#23548;&#33268;&#23545;&#20110;&#26435;&#37325;&#30697;&#38453;&#30340;&#31209;&#26368;&#23567;&#21270;&#30340;&#20559;&#24046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#39564;&#35777;&#26126;&#65292;&#24403;&#20351;&#29992;&#36739;&#23567;&#30340;&#25209;&#37327;&#22823;&#23567;&#12289;&#26356;&#39640;&#30340;&#23398;&#20064;&#29575;&#25110;&#22686;&#21152;&#30340;&#26435;&#37325;&#34928;&#20943;&#26102;&#65292;&#36825;&#31181;&#20559;&#24046;&#26356;&#21152;&#26174;&#33879;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#39044;&#27979;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#26435;&#37325;&#34928;&#20943;&#26159;&#23454;&#29616;&#36825;&#31181;&#20559;&#24046;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21457;&#29616;&#22312;&#20013;&#38388;&#31070;&#32463;&#32593;&#32476;&#23849;&#28291;&#30340;&#24773;&#20917;&#19979;&#65292;&#23398;&#20064;&#30340;&#26435;&#37325;&#29305;&#21035;&#20302;&#31209;&#12290;&#19982;&#20808;&#21069;&#30340;&#25991;&#29486;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#19981;&#20381;&#36182;&#20110;&#20851;&#20110;&#25968;&#25454;&#12289;&#25910;&#25947;&#24615;&#25110;&#26435;&#37325;&#30697;&#38453;&#20248;&#21270;&#30340;&#20551;&#35774;&#12290;&#27492;&#22806;&#65292;&#23427;&#36866;&#29992;&#20110;&#20219;&#24847;&#23485;&#24230;&#25110;&#28145;&#24230;&#30340;&#21508;&#31181;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#31181;&#20559;&#24046;&#19982;&#27867;&#21270;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the bias of Stochastic Gradient Descent (SGD) to learn low-rank weight matrices when training deep ReLU neural networks. Our results show that training neural networks with mini-batch SGD and weight decay causes a bias towards rank minimization over the weight matrices. Specifically, we show, both theoretically and empirically, that this bias is more pronounced when using smaller batch sizes, higher learning rates, or increased weight decay. Additionally, we predict and observe empirically that weight decay is necessary to achieve this bias. In addition, we show that in the presence of intermediate neural collapse, the learned weights are particularly low-rank. Unlike previous literature, our analysis does not rely on assumptions about the data, convergence, or optimality of the weight matrices. Furthermore, it applies to a wide range of neural network architectures of any width or depth. Finally, we empirically investigate the connection between this bias and generalization, 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#37096;&#20998;&#38597;&#21487;&#27604;&#30697;&#38453;&#30340;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#35786;&#26029;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20020;&#30028;&#24615;&#30340;&#23454;&#29992;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#36882;&#24402;&#20851;&#31995;&#20998;&#26512;&#20102;&#24102;&#26377;LayerNorm&#21644;/&#25110;&#27531;&#24046;&#36830;&#25509;&#30340;&#28145;&#24230;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#20020;&#30028;&#24615;&#12290;</title><link>http://arxiv.org/abs/2111.12143</link><description>&lt;p&gt;
&#36890;&#36807;&#37096;&#20998;&#38597;&#21487;&#27604;&#30697;&#38453;&#23454;&#29616;&#23485;&#32780;&#28145;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#20851;&#38190;&#21021;&#22987;&#21270;&#65306;&#19968;&#33324;&#29702;&#35770;&#21644;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Critical Initialization of Wide and Deep Neural Networks through Partial Jacobians: General Theory and Applications. (arXiv:2111.12143v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.12143
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#37096;&#20998;&#38597;&#21487;&#27604;&#30697;&#38453;&#30340;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#35786;&#26029;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20020;&#30028;&#24615;&#30340;&#23454;&#29992;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#36882;&#24402;&#20851;&#31995;&#20998;&#26512;&#20102;&#24102;&#26377;LayerNorm&#21644;/&#25110;&#27531;&#24046;&#36830;&#25509;&#30340;&#28145;&#24230;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#20020;&#30028;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22240;&#20854;&#38590;&#20197;&#36827;&#34892;&#29702;&#35770;&#30740;&#31350;&#32780;&#38395;&#21517;&#12290;&#28982;&#32780;&#65292;&#24403;&#27599;&#20010;&#23618;&#20013;&#30340;&#21442;&#25968;&#25968;&#37327;&#36235;&#20110;&#26080;&#31351;&#26102;&#65292;&#32593;&#32476;&#20989;&#25968;&#25104;&#20026;&#19968;&#20010;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#65292;&#24182;&#19988;&#21487;&#20197;&#36827;&#34892;&#23450;&#37327;&#39044;&#27979;&#25551;&#36848;&#12290;&#39640;&#26031;&#36817;&#20284;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#21046;&#23450;&#36873;&#25321;&#36229;&#21442;&#25968;&#65288;&#20363;&#22914;&#26435;&#37325;&#21644;&#20559;&#24046;&#30340;&#26041;&#24046;&#20197;&#21450;&#23398;&#20064;&#29575;&#65289;&#30340;&#26631;&#20934;&#12290;&#36825;&#20123;&#26631;&#20934;&#20381;&#36182;&#20110;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23450;&#20041;&#30340;&#20020;&#30028;&#24615;&#27010;&#24565;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#31181;&#35786;&#26029;&#20020;&#30028;&#24615;&#30340;&#26032;&#23454;&#29992;&#26041;&#24335;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#32593;&#32476;&#30340;&#8220;&#37096;&#20998;&#38597;&#21487;&#27604;&#30697;&#38453;&#8221;&#65292;&#23450;&#20041;&#20026;&#23618;$l$&#20013;&#30340;&#39044;&#28608;&#27963;&#23545;&#20110;&#23618;$l_0\leq l$&#20013;&#30340;&#39044;&#28608;&#27963;&#30340;&#23548;&#25968;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#37096;&#20998;&#38597;&#21487;&#27604;&#30697;&#38453;&#33539;&#25968;&#30340;&#36882;&#24402;&#20851;&#31995;&#65292;&#24182;&#21033;&#29992;&#36825;&#20123;&#20851;&#31995;&#20998;&#26512;&#20102;&#24102;&#26377;LayerNorm&#21644;/&#25110;&#27531;&#24046;&#36830;&#25509;&#30340;&#28145;&#24230;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#20020;&#30028;&#24615;&#12290;&#25105;&#20204;&#25512;&#23548;&#24182;&#23454;&#29616;&#20102;&#19968;&#31181;&#31616;&#21333;&#19988;&#24265;&#20215;&#30340;&#25968;&#20540;&#27979;&#35797;&#65292;&#20351;&#24471;&#21487;&#20197;&#36873;&#25321;&#36866;&#24403;&#30340;&#26435;&#37325;&#21644;&#20559;&#24046;&#26041;&#24046;&#20197;&#21450;&#23398;&#20064;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks are notorious for defying theoretical treatment. However, when the number of parameters in each layer tends to infinity, the network function is a Gaussian process (GP) and quantitatively predictive description is possible. Gaussian approximation allows one to formulate criteria for selecting hyperparameters, such as variances of weights and biases, as well as the learning rate. These criteria rely on the notion of criticality defined for deep neural networks. In this work we describe a new practical way to diagnose criticality. We introduce \emph{partial Jacobians} of a network, defined as derivatives of preactivations in layer $l$ with respect to preactivations in layer $l_0\leq l$. We derive recurrence relations for the norms of partial Jacobians and utilize these relations to analyze criticality of deep fully connected neural networks with LayerNorm and/or residual connections. We derive and implement a simple and cheap numerical test that allows one to select 
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36716;&#25442;&#39118;&#38505;&#26368;&#23567;&#21270;&#26694;&#26550;&#65292;&#21487;&#20197;&#21516;&#26102;&#23398;&#20064;&#39044;&#27979;&#27169;&#22411;&#21644;&#25968;&#25454;&#21464;&#25442;&#65292;&#29305;&#21035;&#26159;&#20998;&#24067;&#30340;&#21464;&#25442;&#12290;&#25105;&#20204;&#20197;&#23398;&#20064;&#22270;&#20687;&#22686;&#24378;&#20026;&#20027;&#35201;&#24212;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#35299;&#20915;&#36807;&#25311;&#21512;&#38382;&#39064;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2111.08190</link><description>&lt;p&gt;
&#20351;&#29992;&#36716;&#25442;&#39118;&#38505;&#26368;&#23567;&#21270;&#23398;&#20064;&#22686;&#24378;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Learning Augmentation Distributions using Transformed Risk Minimization. (arXiv:2111.08190v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.08190
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36716;&#25442;&#39118;&#38505;&#26368;&#23567;&#21270;&#26694;&#26550;&#65292;&#21487;&#20197;&#21516;&#26102;&#23398;&#20064;&#39044;&#27979;&#27169;&#22411;&#21644;&#25968;&#25454;&#21464;&#25442;&#65292;&#29305;&#21035;&#26159;&#20998;&#24067;&#30340;&#21464;&#25442;&#12290;&#25105;&#20204;&#20197;&#23398;&#20064;&#22270;&#20687;&#22686;&#24378;&#20026;&#20027;&#35201;&#24212;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#35299;&#20915;&#36807;&#25311;&#21512;&#38382;&#39064;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#8220;&#36716;&#25442;&#39118;&#38505;&#26368;&#23567;&#21270;&#8221;&#65288;TRM&#65289;&#26694;&#26550;&#65292;&#20316;&#20026;&#20256;&#32479;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#25193;&#23637;&#12290;&#22312;TRM&#20013;&#65292;&#25105;&#20204;&#19981;&#20165;&#20248;&#21270;&#39044;&#27979;&#27169;&#22411;&#65292;&#36824;&#20248;&#21270;&#25968;&#25454;&#21464;&#25442;&#65292;&#29305;&#21035;&#26159;&#20998;&#24067;&#30340;&#21464;&#25442;&#12290;&#20316;&#20026;&#19968;&#20010;&#20851;&#38190;&#24212;&#29992;&#65292;&#25105;&#20204;&#20851;&#27880;&#23398;&#20064;&#22686;&#24378;&#65292;&#20363;&#22914;&#36866;&#24403;&#26059;&#36716;&#22270;&#20687;&#65292;&#20197;&#25552;&#39640;&#32473;&#23450;&#39044;&#27979;&#22120;&#31867;&#21035;&#30340;&#20998;&#31867;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;TRM&#26041;&#27861;&#65306;&#65288;1&#65289;&#22312;&#21333;&#20010;&#35757;&#32451;&#24490;&#29615;&#20013;&#32852;&#21512;&#23398;&#20064;&#21464;&#25442;&#21644;&#27169;&#22411;&#65307;&#65288;2&#65289;&#36866;&#29992;&#20110;&#20219;&#20309;&#36866;&#29992;&#20110;&#26631;&#20934;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#35757;&#32451;&#31639;&#27861;&#65307;&#65288;3&#65289;&#22788;&#29702;&#20219;&#20309;&#21464;&#25442;&#65292;&#20363;&#22914;&#31163;&#25955;&#21644;&#36830;&#32493;&#31867;&#30340;&#22686;&#24378;&#12290;&#20026;&#20102;&#36991;&#20813;&#22312;&#23454;&#26045;&#32463;&#39564;&#36716;&#25442;&#39118;&#38505;&#26368;&#23567;&#21270;&#26102;&#36807;&#25311;&#21512;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;PAC-Bayes&#29702;&#35770;&#30340;&#26032;&#22411;&#27491;&#21017;&#21270;&#22120;&#12290;&#23545;&#20110;&#23398;&#20064;&#22270;&#20687;&#30340;&#22686;&#24378;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20960;&#20309;&#21464;&#25442;&#22359;&#30340;&#38543;&#26426;&#32452;&#21512;&#23545;&#22686;&#24378;&#31354;&#38388;&#36827;&#34892;&#21442;&#25968;&#21270;&#30340;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new \emph{Transformed Risk Minimization} (TRM) framework as an extension of classical risk minimization. In TRM, we optimize not only over predictive models, but also over data transformations; specifically over distributions thereof. As a key application, we focus on learning augmentations; for instance appropriate rotations of images, to improve classification performance with a given class of predictors. Our TRM method (1) jointly learns transformations and models in a \emph{single training loop}, (2) works with any training algorithm applicable to standard risk minimization, and (3) handles any transforms, such as discrete and continuous classes of augmentations. To avoid overfitting when implementing empirical transformed risk minimization, we propose a novel regularizer based on PAC-Bayes theory. For learning augmentations of images, we propose a new parametrization of the space of augmentations via a stochastic composition of blocks of geometric transforms. This lea
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#20108;&#36827;&#21046;&#39044;&#27979;&#35774;&#32622;&#20013;&#30340;&#26657;&#20934;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#26657;&#20934;&#35823;&#24046;&#30340;&#937;(T^(0.528))&#19979;&#30028;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#36229;&#36807;&#8730;T&#30340;&#19979;&#30028;&#12290;</title><link>http://arxiv.org/abs/2012.03454</link><description>&lt;p&gt;
&#24378;&#21270;&#26657;&#20934;&#19979;&#30028;&#36890;&#36807;&#32469;&#36807;
&lt;/p&gt;
&lt;p&gt;
Stronger Calibration Lower Bounds via Sidestepping. (arXiv:2012.03454v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2012.03454
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#20108;&#36827;&#21046;&#39044;&#27979;&#35774;&#32622;&#20013;&#30340;&#26657;&#20934;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#26657;&#20934;&#35823;&#24046;&#30340;&#937;(T^(0.528))&#19979;&#30028;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#36229;&#36807;&#8730;T&#30340;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#31181;&#22312;&#32447;&#20108;&#36827;&#21046;&#39044;&#27979;&#35774;&#32622;&#65292;&#20854;&#20013;&#39044;&#27979;&#21592;&#36880;&#20010;&#35266;&#23519;&#19968;&#31995;&#21015;T&#20010;&#27604;&#29305;&#20301;&#12290;&#22312;&#25581;&#31034;&#27599;&#20010;&#27604;&#29305;&#20301;&#20043;&#21069;&#65292;&#39044;&#27979;&#21592;&#39044;&#27979;&#35813;&#27604;&#29305;&#20301;&#20026;1&#30340;&#27010;&#29575;&#12290;&#22914;&#26524;&#23545;&#20110;&#27599;&#20010;p&#8712;[0,1]&#65292;&#22312;&#39044;&#27979;&#21592;&#39044;&#27979;&#27010;&#29575;&#20026;p&#30340;n_p&#20010;&#27604;&#29305;&#20301;&#20013;&#65292;&#23454;&#38469;&#20986;&#29616;&#30340;1&#30340;&#25968;&#37327;m_p&#30830;&#23454;&#31561;&#20110;p&#8901;n_p&#65292;&#21017;&#31216;&#39044;&#27979;&#21592;&#20855;&#26377;&#33391;&#22909;&#26657;&#20934;&#24615;&#12290;&#26657;&#20934;&#35823;&#24046;&#23450;&#20041;&#20026;&#8721;_p|mp&#8901;p&#8901;np|&#65292;&#29992;&#26469;&#34913;&#37327;&#39044;&#27979;&#21592;&#20559;&#31163;&#33391;&#22909;&#26657;&#20934;&#24615;&#30340;&#31243;&#24230;&#12290;&#23613;&#31649;&#24050;&#32463;&#30693;&#36947;&#21363;&#20351;&#22312;&#27604;&#29305;&#20301;&#26159;&#23545;&#25239;&#24615;&#36873;&#25321;&#30340;&#24773;&#20917;&#19979;&#65292;&#22522;&#20110;&#20043;&#21069;&#30340;&#39044;&#27979;&#20063;&#21487;&#33021;&#23454;&#29616;O(T^(2/3))&#30340;&#26657;&#20934;&#35823;&#24046;&#65292;&#20294;&#26159;&#23545;&#20110;&#19979;&#30028;&#26041;&#38754;&#20960;&#20046;&#27809;&#26377;&#20219;&#20309;&#20102;&#35299;&#65292;&#38500;&#20102;&#36890;&#36807;&#29420;&#31435;&#20844;&#24179;&#30828;&#24065;&#32763;&#36716;&#30340;&#24179;&#20961;&#20363;&#23376;&#24471;&#21040;&#30340;&#937;(&#8730;T)&#19979;&#30028;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#26657;&#20934;&#35823;&#24046;&#30340;&#937;(T^(0.528))&#19979;&#30028;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#36229;&#36807;&#8730;T&#30340;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider an online binary prediction setting where a forecaster observes a sequence of $T$ bits one by one. Before each bit is revealed, the forecaster predicts the probability that the bit is $1$. The forecaster is called well-calibrated if for each $p \in [0, 1]$, among the $n_p$ bits for which the forecaster predicts probability $p$, the actual number of ones, $m_p$, is indeed equal to $p \cdot n_p$. The calibration error, defined as $\sum_p |m_p p n_p|$, quantifies the extent to which the forecaster deviates from being well-calibrated. It has long been known that an $O(T^{2/3})$ calibration error is achievable even when the bits are chosen adversarially, and possibly based on the previous predictions. However, little is known on the lower bound side, except an $\Omega(\sqrt{T})$ bound that follows from the trivial example of independent fair coin flips.  In this paper, we prove an $\Omega(T^{0.528})$ bound on the calibration error, which is the first super-$\sqrt{T}$ lower bou
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22797;&#21512;&#20256;&#36755;&#25955;&#24230;&#30340;&#39640;&#26031;&#28151;&#21512;&#31616;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#26031;&#28151;&#21512;&#22312;&#36882;&#24402;&#26356;&#26032;&#20013;&#38454;&#25968;&#25351;&#25968;&#22686;&#21152;&#30340;&#25512;&#26029;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2002.08410</link><description>&lt;p&gt;
&#29992;&#22797;&#21512;&#20256;&#36755;&#25955;&#24230;&#36827;&#34892;&#39640;&#26031;&#28151;&#21512;&#31616;&#21270;
&lt;/p&gt;
&lt;p&gt;
Gaussian Mixture Reduction with Composite Transportation Divergence. (arXiv:2002.08410v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2002.08410
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22797;&#21512;&#20256;&#36755;&#25955;&#24230;&#30340;&#39640;&#26031;&#28151;&#21512;&#31616;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#26031;&#28151;&#21512;&#22312;&#36882;&#24402;&#26356;&#26032;&#20013;&#38454;&#25968;&#25351;&#25968;&#22686;&#21152;&#30340;&#25512;&#26029;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#28151;&#21512;&#22312;&#23494;&#24230;&#20272;&#35745;&#12289;&#20449;&#24565;&#20256;&#25773;&#21644;&#36125;&#21494;&#26031;&#28388;&#27874;&#31561;&#21508;&#31181;&#24212;&#29992;&#20013;&#34987;&#24191;&#27867;&#29992;&#20110;&#36924;&#36817;&#23494;&#24230;&#20989;&#25968;&#12290;&#36825;&#20123;&#24212;&#29992;&#36890;&#24120;&#21033;&#29992;&#39640;&#26031;&#28151;&#21512;&#20316;&#20026;&#36882;&#24402;&#26356;&#26032;&#30340;&#21021;&#22987;&#36817;&#20284;&#12290;&#36825;&#20123;&#36882;&#24402;&#36807;&#31243;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#28304;&#20110;&#28151;&#21512;&#38454;&#25968;&#30340;&#25351;&#25968;&#22686;&#21152;&#65292;&#23548;&#33268;&#38590;&#20197;&#27714;&#35299;&#30340;&#25512;&#26029;&#38382;&#39064;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#22256;&#38590;&#65292;&#21487;&#20197;&#20351;&#29992;&#39640;&#26031;&#28151;&#21512;&#31616;&#21270;&#65288;GMR&#65289;&#23558;&#39640;&#38454;&#39640;&#26031;&#28151;&#21512;&#36817;&#20284;&#20026;&#20302;&#38454;&#28151;&#21512;&#12290;&#23613;&#31649;&#29616;&#26377;&#30340;&#22522;&#20110;&#32858;&#31867;&#30340;&#26041;&#27861;&#22312;&#24615;&#33021;&#21644;&#35745;&#31639;&#25928;&#29575;&#19978;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#23427;&#20204;&#30340;&#25910;&#25947;&#24615;&#36136;&#21644;&#26368;&#20248;&#30446;&#26631;&#20173;&#28982;&#26410;&#30693;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22797;&#21512;&#20256;&#36755;&#25955;&#24230;&#30340;&#26032;&#22411;&#20248;&#21270;GMR&#26041;&#27861;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#20027;&#20803;&#26368;&#23567;&#21270;&#31639;&#27861;&#26469;&#35745;&#31639;&#31616;&#21270;&#30340;&#28151;&#21512;&#65292;&#24182;&#22312;g&#20013;&#24314;&#31435;&#20102;&#20854;&#29702;&#35770;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian mixtures are widely used for approximating density functions in various applications such as density estimation, belief propagation, and Bayesian filtering. These applications often utilize Gaussian mixtures as initial approximations that are updated recursively. A key challenge in these recursive processes stems from the exponential increase in the mixture's order, resulting in intractable inference. To overcome the difficulty, the Gaussian mixture reduction (GMR), which approximates a high order Gaussian mixture by one with a lower order, can be used. Although existing clustering-based methods are known for their satisfactory performance and computational efficiency, their convergence properties and optimal targets remain unknown. In this paper, we propose a novel optimization-based GMR method based on composite transportation divergence (CTD). We develop a majorization-minimization algorithm for computing the reduced mixture and establish its theoretical convergence under g
&lt;/p&gt;</description></item><item><title>&#21487;&#21464;&#24418;&#29983;&#25104;&#22120;&#32593;&#32476;&#33021;&#22815;&#20197;&#26080;&#30417;&#30563;&#30340;&#26041;&#24335;&#35299;&#32806;&#22270;&#20687;&#21644;&#35270;&#39057;&#20013;&#30340;&#22806;&#35266;&#21644;&#20960;&#20309;&#20449;&#24687;&#65292;&#36890;&#36807;&#29983;&#25104;&#21464;&#24418;&#22330;&#23454;&#29616;&#20960;&#20309;&#21464;&#24418;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#36890;&#29992;&#19988;&#26377;&#25928;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/1806.06298</link><description>&lt;p&gt;
&#21487;&#21464;&#24418;&#29983;&#25104;&#22120;&#32593;&#32476;&#65306;&#26080;&#30417;&#30563;&#35299;&#32806;&#22806;&#35266;&#21644;&#20960;&#20309;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
Deformable Generator Networks: Unsupervised Disentanglement of Appearance and Geometry. (arXiv:1806.06298v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1806.06298
&lt;/p&gt;
&lt;p&gt;
&#21487;&#21464;&#24418;&#29983;&#25104;&#22120;&#32593;&#32476;&#33021;&#22815;&#20197;&#26080;&#30417;&#30563;&#30340;&#26041;&#24335;&#35299;&#32806;&#22270;&#20687;&#21644;&#35270;&#39057;&#20013;&#30340;&#22806;&#35266;&#21644;&#20960;&#20309;&#20449;&#24687;&#65292;&#36890;&#36807;&#29983;&#25104;&#21464;&#24418;&#22330;&#23454;&#29616;&#20960;&#20309;&#21464;&#24418;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#36890;&#29992;&#19988;&#26377;&#25928;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#21464;&#24418;&#29983;&#25104;&#22120;&#27169;&#22411;&#65292;&#20197;&#32431;&#31929;&#26080;&#30417;&#30563;&#30340;&#26041;&#24335;&#35299;&#32806;&#22270;&#20687;&#21644;&#35270;&#39057;&#25968;&#25454;&#30340;&#22806;&#35266;&#21644;&#20960;&#20309;&#20449;&#24687;&#12290;&#22806;&#35266;&#29983;&#25104;&#22120;&#32593;&#32476;&#27169;&#25311;&#19982;&#22806;&#35266;&#30456;&#20851;&#30340;&#20449;&#24687;&#65292;&#21253;&#25324;&#39068;&#33394;&#12289;&#29031;&#26126;&#12289;&#36523;&#20221;&#25110;&#31867;&#21035;&#65292;&#32780;&#20960;&#20309;&#29983;&#25104;&#22120;&#36890;&#36807;&#29983;&#25104;&#21464;&#24418;&#22330;&#26469;&#25191;&#34892;&#20960;&#20309;&#21464;&#24418;&#65292;&#22914;&#26059;&#36716;&#21644;&#25289;&#20280;&#65292;&#36890;&#36807;&#25197;&#26354;&#29983;&#25104;&#30340;&#22806;&#35266;&#26469;&#33719;&#21462;&#26368;&#32456;&#30340;&#22270;&#20687;&#25110;&#35270;&#39057;&#24207;&#21015;&#12290;&#20004;&#20010;&#29983;&#25104;&#22120;&#25509;&#25910;&#29420;&#31435;&#30340;&#28508;&#22312;&#21521;&#37327;&#20316;&#20026;&#36755;&#20837;&#65292;&#20174;&#22270;&#20687;&#25110;&#35270;&#39057;&#24207;&#21015;&#20013;&#35299;&#32806;&#22806;&#35266;&#21644;&#20960;&#20309;&#20449;&#24687;&#12290;&#23545;&#20110;&#35270;&#39057;&#25968;&#25454;&#65292;&#24341;&#20837;&#38750;&#32447;&#24615;&#36716;&#25442;&#27169;&#22411;&#21040;&#22806;&#35266;&#21644;&#20960;&#20309;&#29983;&#25104;&#22120;&#20013;&#65292;&#20197;&#25429;&#25417;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#21160;&#24577;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#26696;&#26159;&#36890;&#29992;&#30340;&#65292;&#21487;&#20197;&#36731;&#26494;&#38598;&#25104;&#21040;&#19981;&#21516;&#30340;&#29983;&#25104;&#27169;&#22411;&#20013;&#12290;&#22823;&#37327;&#30340;&#23450;&#24615;&#21644;&#23450;&#37327;&#23454;&#39564;&#34920;&#26126;&#22806;&#35266;&#21644;&#20960;&#20309;&#20449;&#24687;&#21487;&#20197;&#25104;&#21151;&#35299;&#32806;&#65292;&#24182;&#19988;&#33021;&#22815;&#26377;&#25928;&#22320;&#29983;&#25104;&#22810;&#26679;&#21270;&#30340;&#22270;&#20687;&#21644;&#35270;&#39057;&#24207;&#21015;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a deformable generator model to disentangle the appearance and geometric information for both image and video data in a purely unsupervised manner. The appearance generator network models the information related to appearance, including color, illumination, identity or category, while the geometric generator performs geometric warping, such as rotation and stretching, through generating deformation field which is used to warp the generated appearance to obtain the final image or video sequences. Two generators take independent latent vectors as input to disentangle the appearance and geometric information from image or video sequences. For video data, a nonlinear transition model is introduced to both the appearance and geometric generators to capture the dynamics over time. The proposed scheme is general and can be easily integrated into different generative models. An extensive set of qualitative and quantitative experiments shows that the appearance and geometric informat
&lt;/p&gt;</description></item></channel></rss>