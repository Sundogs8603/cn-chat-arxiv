<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#20302;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#29983;&#25104;&#36807;&#31243;&#26469;&#21019;&#24314;&#21253;&#21547;&#24322;&#24120;&#29255;&#27573;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#35299;&#37322;&#20102;&#24120;&#29992;&#31639;&#27861;&#22312;&#27491;&#24120;&#21644;&#24322;&#24120;&#29255;&#27573;&#20043;&#38388;&#30340;&#20998;&#24067;&#37325;&#21472;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.12925</link><description>&lt;p&gt;
&#20302;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Low-count Time Series Anomaly Detection. (arXiv:2308.12925v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12925
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#20302;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#29983;&#25104;&#36807;&#31243;&#26469;&#21019;&#24314;&#21253;&#21547;&#24322;&#24120;&#29255;&#27573;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#35299;&#37322;&#20102;&#24120;&#29992;&#31639;&#27861;&#22312;&#27491;&#24120;&#21644;&#24322;&#24120;&#29255;&#27573;&#20043;&#38388;&#30340;&#20998;&#24067;&#37325;&#21472;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#25551;&#36848;&#31232;&#30095;&#25110;&#38388;&#26029;&#20107;&#20214;&#65292;&#36825;&#22312;&#25429;&#33719;&#21644;&#30417;&#25511;&#19981;&#21516;&#25968;&#25454;&#31867;&#22411;&#30340;&#22823;&#35268;&#27169;&#22312;&#32447;&#24179;&#21488;&#20013;&#24456;&#24120;&#35265;&#12290;&#24314;&#27169;&#20302;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#38754;&#20020;&#20960;&#20010;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#20302;&#20449;&#22122;&#27604;&#65288;&#24403;&#24322;&#24120;&#31614;&#21517;&#26080;&#27861;&#26816;&#27979;&#26102;&#65289;&#21644;&#38750;&#22343;&#21248;&#24615;&#33021;&#65288;&#24179;&#22343;&#24230;&#37327;&#25351;&#26631;&#19981;&#33021;&#20195;&#34920;&#23616;&#37096;&#34892;&#20026;&#65289;&#12290;&#24403;&#21069;&#30340;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#39046;&#22495;&#32570;&#20047;&#26126;&#30830;&#30340;&#24037;&#20855;&#21644;&#27969;&#31243;&#26469;&#24314;&#27169;&#21644;&#21487;&#38752;&#22320;&#26816;&#27979;&#36825;&#20123;&#24773;&#20917;&#19979;&#30340;&#24322;&#24120;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#29983;&#25104;&#36807;&#31243;&#65292;&#29992;&#20110;&#21019;&#24314;&#21253;&#21547;&#26377;&#24322;&#24120;&#29255;&#27573;&#30340;&#20302;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#12290;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#30340;&#28151;&#21512;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#35299;&#37322;&#20102;&#24120;&#29992;&#31639;&#27861;&#22312;&#27491;&#24120;&#21644;&#24322;&#24120;&#29255;&#27573;&#20043;&#38388;&#30340;&#20998;&#24067;&#37325;&#21472;&#20013;&#36935;&#21040;&#30340;&#22256;&#38590;&#12290;&#20026;&#20102;&#20943;&#36731;&#36825;&#20010;&#32570;&#28857;&#65292;&#25105;&#20204;&#21033;&#29992;&#25105;&#20204;&#30340;&#21457;&#29616;&#26469;&#23637;&#31034;&#22914;&#20309;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Low-count time series describe sparse or intermittent events, which are prevalent in large-scale online platforms that capture and monitor diverse data types. Several distinct challenges surface when modelling low-count time series, particularly low signal-to-noise ratios (when anomaly signatures are provably undetectable), and non-uniform performance (when average metrics are not representative of local behaviour). The time series anomaly detection community currently lacks explicit tooling and processes to model and reliably detect anomalies in these settings. We address this gap by introducing a novel generative procedure for creating benchmark datasets comprising of low-count time series with anomalous segments. Via a mixture of theoretical and empirical analysis, our work explains how widely-used algorithms struggle with the distribution overlap between normal and anomalous segments. In order to mitigate this shortcoming, we then leverage our findings to demonstrate how anomaly sc
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;&#21518;&#32493;&#39564;&#35777;&#30340;&#27491;&#24335;&#27979;&#35797;&#31243;&#24207;&#65292;&#29992;&#20110;&#26816;&#27979;&#27169;&#22411;&#20998;&#37197;&#22266;&#23450;&#39044;&#27979;&#30340;&#24773;&#20917;&#12290;&#36890;&#36807;&#24320;&#21457;&#21487;&#38752;&#30340;&#26426;&#21046;&#65292;&#21487;&#20197;&#30830;&#23450;&#32473;&#23450;&#27169;&#22411;&#26159;&#21542;&#33021;&#20026;&#20915;&#31574;&#23545;&#35937;&#25552;&#20379;&#21518;&#32493;&#25514;&#26045;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#27169;&#22411;&#20998;&#37197;&#22266;&#23450;&#39044;&#27979;&#21487;&#33021;&#24102;&#26469;&#30340;&#38382;&#39064;&#12290;&#35813;&#30740;&#31350;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#20013;&#30830;&#20445;&#21518;&#32493;&#25514;&#26045;&#21644;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#36151;&#27454;&#25968;&#25454;&#38598;&#20013;&#23454;&#29616;&#21518;&#32493;&#25514;&#26045;&#30340;&#19981;&#21487;&#34892;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.12820</link><description>&lt;p&gt;
&#19981;&#25490;&#38500;&#39044;&#27979;&#65306;&#22522;&#20110;&#21487;&#36798;&#38598;&#30340;&#21518;&#32493;&#39564;&#35777;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Prediction without Preclusion: Recourse Verification with Reachable Sets. (arXiv:2308.12820v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12820
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;&#21518;&#32493;&#39564;&#35777;&#30340;&#27491;&#24335;&#27979;&#35797;&#31243;&#24207;&#65292;&#29992;&#20110;&#26816;&#27979;&#27169;&#22411;&#20998;&#37197;&#22266;&#23450;&#39044;&#27979;&#30340;&#24773;&#20917;&#12290;&#36890;&#36807;&#24320;&#21457;&#21487;&#38752;&#30340;&#26426;&#21046;&#65292;&#21487;&#20197;&#30830;&#23450;&#32473;&#23450;&#27169;&#22411;&#26159;&#21542;&#33021;&#20026;&#20915;&#31574;&#23545;&#35937;&#25552;&#20379;&#21518;&#32493;&#25514;&#26045;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#27169;&#22411;&#20998;&#37197;&#22266;&#23450;&#39044;&#27979;&#21487;&#33021;&#24102;&#26469;&#30340;&#38382;&#39064;&#12290;&#35813;&#30740;&#31350;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#20013;&#30830;&#20445;&#21518;&#32493;&#25514;&#26045;&#21644;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#36151;&#27454;&#25968;&#25454;&#38598;&#20013;&#23454;&#29616;&#21518;&#32493;&#25514;&#26045;&#30340;&#19981;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#24120;&#34987;&#29992;&#20110;&#20915;&#23450;&#35841;&#26377;&#36164;&#26684;&#24471;&#21040;&#36151;&#27454;&#12289;&#38754;&#35797;&#25110;&#20844;&#20849;&#31119;&#21033;&#12290;&#26631;&#20934;&#25216;&#26415;&#29992;&#20110;&#26500;&#24314;&#36825;&#20123;&#27169;&#22411;&#26102;&#65292;&#20250;&#20351;&#29992;&#20851;&#20110;&#20154;&#30340;&#29305;&#24449;&#65292;&#20294;&#24573;&#35270;&#20182;&#20204;&#30340;&#21487;&#25805;&#20316;&#24615;&#12290;&#22240;&#27492;&#65292;&#27169;&#22411;&#21487;&#33021;&#20250;&#20998;&#37197;&#22266;&#23450;&#30340;&#39044;&#27979;&#65292;&#36825;&#24847;&#21619;&#30528;&#34987;&#25298;&#32477;&#36151;&#27454;&#12289;&#38754;&#35797;&#25110;&#31119;&#21033;&#30340;&#28040;&#36153;&#32773;&#21487;&#33021;&#27704;&#20037;&#34987;&#25490;&#38500;&#22312;&#33719;&#24471;&#20449;&#36151;&#12289;&#23601;&#19994;&#25110;&#25588;&#21161;&#30340;&#26426;&#20250;&#20043;&#22806;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#27491;&#24335;&#30340;&#27979;&#35797;&#31243;&#24207;&#26469;&#26816;&#27979;&#20998;&#37197;&#22266;&#23450;&#39044;&#27979;&#30340;&#27169;&#22411;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#21518;&#32493;&#39564;&#35777;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#22871;&#26426;&#21046;&#21487;&#38752;&#22320;&#30830;&#23450;&#32473;&#23450;&#27169;&#22411;&#26159;&#21542;&#33021;&#25552;&#20379;&#23545;&#20915;&#31574;&#23545;&#35937;&#30340;&#21518;&#32493;&#25163;&#27573;&#65292;&#36825;&#20123;&#25163;&#27573;&#30001;&#29992;&#25143;&#25351;&#23450;&#30340;&#21487;&#25805;&#20316;&#24615;&#32422;&#26463;&#30830;&#23450;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;&#25105;&#20204;&#30340;&#24037;&#20855;&#22914;&#20309;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#20013;&#30830;&#20445;&#21518;&#32493;&#25514;&#26045;&#21644;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#24182;&#21033;&#29992;&#23427;&#20204;&#30740;&#31350;&#20102;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#36151;&#27454;&#25968;&#25454;&#38598;&#20013;&#23454;&#29616;&#21518;&#32493;&#25514;&#26045;&#30340;&#19981;&#21487;&#34892;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20984;&#26174;&#20102;&#27169;&#22411;&#22914;&#20309;&#26080;&#24847;&#20013;&#20998;&#37197;&#22266;&#23450;&#39044;&#27979;&#65292;&#20174;&#32780;&#27704;&#20037;&#31105;&#27490;&#20351;&#29992;&#32773;&#33719;&#24471;&#30456;&#20851;&#26435;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning models are often used to decide who will receive a loan, a job interview, or a public benefit. Standard techniques to build these models use features about people but overlook their actionability. In turn, models can assign predictions that are fixed, meaning that consumers who are denied loans, interviews, or benefits may be permanently locked out from access to credit, employment, or assistance. In this work, we introduce a formal testing procedure to flag models that assign fixed predictions that we call recourse verification. We develop machinery to reliably determine if a given model can provide recourse to its decision subjects from a set of user-specified actionability constraints. We demonstrate how our tools can ensure recourse and adversarial robustness in real-world datasets and use them to study the infeasibility of recourse in real-world lending datasets. Our results highlight how models can inadvertently assign fixed predictions that permanently bar acces
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21333;&#27425;MC dropout&#36817;&#20284;&#26041;&#27861;&#65292;&#20197;&#23558;&#31070;&#32463;&#32593;&#32476;&#36716;&#25442;&#20026;&#36125;&#21494;&#26031;&#21464;&#20307;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#19982;&#26222;&#36890;&#31070;&#32463;&#32593;&#32476;&#30456;&#21516;&#30340;&#35745;&#31639;&#36895;&#24230;&#65292;&#21516;&#26102;&#20445;&#30041;&#20102;&#36125;&#21494;&#26031;&#21464;&#20307;&#31070;&#32463;&#32593;&#32476;&#25552;&#20379;&#30340;&#19981;&#30830;&#23450;&#24230;&#27979;&#37327;&#12290;</title><link>http://arxiv.org/abs/2308.12785</link><description>&lt;p&gt;
&#21333;&#27425;&#36125;&#21494;&#26031;&#36817;&#20284;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Single-shot Bayesian approximation for neural networks. (arXiv:2308.12785v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12785
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21333;&#27425;MC dropout&#36817;&#20284;&#26041;&#27861;&#65292;&#20197;&#23558;&#31070;&#32463;&#32593;&#32476;&#36716;&#25442;&#20026;&#36125;&#21494;&#26031;&#21464;&#20307;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#19982;&#26222;&#36890;&#31070;&#32463;&#32593;&#32476;&#30456;&#21516;&#30340;&#35745;&#31639;&#36895;&#24230;&#65292;&#21516;&#26102;&#20445;&#30041;&#20102;&#36125;&#21494;&#26031;&#21464;&#20307;&#31070;&#32463;&#32593;&#32476;&#25552;&#20379;&#30340;&#19981;&#30830;&#23450;&#24230;&#27979;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20197;&#20854;&#39640;&#39044;&#27979;&#24615;&#33021;&#32780;&#38395;&#21517;&#12290;&#28982;&#32780;&#65292;&#24403;&#36935;&#21040;&#23436;&#20840;&#26032;&#30340;&#24773;&#20917;&#24182;&#19988;&#27809;&#26377;&#25351;&#31034;&#20854;&#19981;&#30830;&#23450;&#24615;&#26102;&#65292;&#31070;&#32463;&#32593;&#32476;&#24456;&#23481;&#26131;&#20135;&#29983;&#19981;&#21487;&#38752;&#30340;&#39044;&#27979;&#12290;&#36125;&#21494;&#26031;&#21464;&#20307;&#30340;&#31070;&#32463;&#32593;&#32476;&#65288;BNNs&#65289;&#65292;&#22914;&#33945;&#29305;&#21345;&#27931;&#65288;MC&#65289;dropout BNNs&#65292;&#22312;&#25552;&#20379;&#19981;&#30830;&#23450;&#24230;&#27979;&#37327;&#30340;&#21516;&#26102;&#25552;&#39640;&#20102;&#39044;&#27979;&#24615;&#33021;&#12290;BNNs&#21807;&#19968;&#30340;&#32570;&#28857;&#26159;&#23427;&#20204;&#22312;&#27979;&#35797;&#26102;&#35745;&#31639;&#26102;&#38388;&#36739;&#38271;&#65292;&#22240;&#20026;&#23427;&#20204;&#20381;&#36182;&#20110;&#19968;&#31181;&#37319;&#26679;&#26041;&#27861;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21333;&#27425;MC dropout&#36817;&#20284;&#65292;&#23427;&#20445;&#30041;&#20102;BNNs&#30340;&#20248;&#28857;&#65292;&#21516;&#26102;&#19982;&#31070;&#32463;&#32593;&#32476;&#19968;&#26679;&#24555;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#30697;&#20256;&#25773;&#65288;MP&#65289;&#65292;&#21487;&#20197;&#22312;&#24120;&#29992;&#30340;&#31070;&#32463;&#32593;&#32476;&#23618;&#65288;&#21367;&#31215;&#12289;&#26368;&#22823;&#27744;&#21270;&#12289;&#20840;&#36830;&#25509;&#12289;softmax&#21644;dropout&#23618;&#65289;&#20013;&#35299;&#26512;&#22320;&#36817;&#20284;MC dropout&#20449;&#21495;&#30340;&#26399;&#26395;&#20540;&#21644;&#26041;&#24046;&#12290;MP&#26041;&#27861;&#21487;&#20197;&#22312;&#19981;&#37325;&#26032;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#23558;&#31070;&#32463;&#32593;&#32476;&#36716;&#25442;&#20026;BNN&#65292;&#21482;&#35201;NN&#24050;&#32463;&#20351;&#29992;&#26631;&#20934;&#30340;dropout&#36827;&#34892;&#20102;&#35757;&#32451;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks (NNs) are known for their high-prediction performances. However, NNs are prone to yield unreliable predictions when encountering completely new situations without indicating their uncertainty. Bayesian variants of NNs (BNNs), such as Monte Carlo (MC) dropout BNNs, do provide uncertainty measures and simultaneously increase the prediction performance. The only disadvantage of BNNs is their higher computation time during test time because they rely on a sampling approach. Here we present a single-shot MC dropout approximation that preserves the advantages of BNNs while being as fast as NNs. Our approach is based on moment propagation (MP) and allows to analytically approximate the expected value and the variance of the MC dropout signal for commonly used layers in NNs, i.e. convolution, max pooling, dense, softmax, and dropout layers. The MP approach can convert an NN into a BNN without re-training given the NN has been trained with standard dropout. We evaluate our 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#24179;&#22343;&#23884;&#20837;&#30340;&#19968;&#33268;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#34913;&#37327;&#26041;&#27861;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#29616;&#23454;&#19990;&#30028;&#30340;&#24179;&#22343;&#23884;&#20837;&#22312;&#25512;&#33616;&#20013;&#19968;&#33268;&#24615;&#36739;&#20302;&#65292;&#20026;&#36827;&#19968;&#27493;&#25913;&#36827;&#29616;&#23454;&#19990;&#30028;&#23884;&#20837;&#25552;&#20379;&#20102;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2308.12767</link><description>&lt;p&gt;
&#20851;&#20110;&#24179;&#22343;&#23884;&#20837;&#29992;&#20110;&#29289;&#21697;&#25512;&#33616;&#30340;&#19968;&#33268;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Consistency of Average Embeddings for Item Recommendation. (arXiv:2308.12767v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12767
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#24179;&#22343;&#23884;&#20837;&#30340;&#19968;&#33268;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#34913;&#37327;&#26041;&#27861;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#29616;&#23454;&#19990;&#30028;&#30340;&#24179;&#22343;&#23884;&#20837;&#22312;&#25512;&#33616;&#20013;&#19968;&#33268;&#24615;&#36739;&#20302;&#65292;&#20026;&#36827;&#19968;&#27493;&#25913;&#36827;&#29616;&#23454;&#19990;&#30028;&#23884;&#20837;&#25552;&#20379;&#20102;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20013;&#19968;&#31181;&#27969;&#34892;&#30340;&#20570;&#27861;&#26159;&#23558;&#29289;&#21697;&#23884;&#20837;&#36827;&#34892;&#24179;&#22343;&#20197;&#22312;&#21516;&#19968;&#23884;&#20837;&#31354;&#38388;&#20013;&#20195;&#34920;&#29992;&#25143;&#25110;&#26356;&#39640;&#32423;&#30340;&#27010;&#24565;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#36825;&#31181;&#20570;&#27861;&#30340;&#30456;&#20851;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26399;&#26395;&#31934;&#24230;&#20998;&#25968;&#65292;&#29992;&#20110;&#34913;&#37327;&#24179;&#22343;&#23884;&#20837;&#19982;&#20854;&#26500;&#24314;&#25152;&#20351;&#29992;&#30340;&#29289;&#21697;&#30340;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#38543;&#21518;&#22312;&#20855;&#26377;&#29305;&#23450;&#20551;&#35774;&#30340;&#29702;&#35770;&#29615;&#22659;&#21644;&#26469;&#33258;&#38899;&#20048;&#27969;&#23186;&#20307;&#26381;&#21153;&#30340;&#30495;&#23454;&#25968;&#25454;&#19978;&#20998;&#26512;&#20102;&#35813;&#20998;&#25968;&#30340;&#25968;&#23398;&#34920;&#36798;&#24335;&#21450;&#20854;&#32463;&#39564;&#34920;&#29616;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#24378;&#35843;&#20102;&#29616;&#23454;&#19990;&#30028;&#30340;&#24179;&#22343;&#20540;&#22312;&#25512;&#33616;&#20013;&#30340;&#19968;&#33268;&#24615;&#36739;&#20302;&#65292;&#20026;&#26410;&#26469;&#30740;&#31350;&#26356;&#22909;&#22320;&#23558;&#29616;&#23454;&#19990;&#30028;&#30340;&#23884;&#20837;&#19982;&#25105;&#20204;&#29702;&#35770;&#29615;&#22659;&#30340;&#20551;&#35774;&#30456;&#19968;&#33268;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
A prevalent practice in recommender systems consists of averaging item embeddings to represent users or higher-level concepts in the same embedding space. This paper investigates the relevance of such a practice. For this purpose, we propose an expected precision score, designed to measure the consistency of an average embedding relative to the items used for its construction. We subsequently analyze the mathematical expression of this score in a theoretical setting with specific assumptions, as well as its empirical behavior on real-world data from music streaming services. Our results emphasize that real-world averages are less consistent for recommendation, which paves the way for future research to better align real-world embeddings with assumptions from our theoretical setting.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#38750;&#32447;&#24615;&#36793;&#38469;&#21453;&#39304;&#21644;&#22810;&#26679;&#24615;&#32422;&#26463;&#30340;&#21069;K&#20010;&#32452;&#21512;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#26032;&#22411;&#20027;&#20174;&#26550;&#26500;&#65292;&#36890;&#36807;&#24341;&#20837;&#20845;&#20010;&#20174;&#27169;&#22411;&#21644;&#25945;&#24072;&#23398;&#20064;&#20248;&#21270;&#20197;&#21450;&#31574;&#30053;&#20849;&#35757;&#32451;&#25216;&#26415;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#25506;&#32034;&#21644;&#21033;&#29992;&#20043;&#38388;&#30340;&#20915;&#31574;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2308.12680</link><description>&lt;p&gt;
&#20351;&#29992;&#20027;&#20174;&#28145;&#24230;&#26550;&#26500;&#35299;&#20915;&#20855;&#26377;&#38750;&#32447;&#24615;&#36793;&#38469;&#21453;&#39304;&#21644;&#22810;&#26679;&#24615;&#32422;&#26463;&#30340;&#21069;K&#20010;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Master-slave Deep Architecture for Top-K Multi-armed Bandits with Non-linear Bandit Feedback and Diversity Constraints. (arXiv:2308.12680v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12680
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#38750;&#32447;&#24615;&#36793;&#38469;&#21453;&#39304;&#21644;&#22810;&#26679;&#24615;&#32422;&#26463;&#30340;&#21069;K&#20010;&#32452;&#21512;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#26032;&#22411;&#20027;&#20174;&#26550;&#26500;&#65292;&#36890;&#36807;&#24341;&#20837;&#20845;&#20010;&#20174;&#27169;&#22411;&#21644;&#25945;&#24072;&#23398;&#20064;&#20248;&#21270;&#20197;&#21450;&#31574;&#30053;&#20849;&#35757;&#32451;&#25216;&#26415;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#25506;&#32034;&#21644;&#21033;&#29992;&#20043;&#38388;&#30340;&#20915;&#31574;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20027;&#20174;&#26550;&#26500;&#65292;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#38750;&#32447;&#24615;&#36793;&#38469;&#21453;&#39304;&#21644;&#22810;&#26679;&#24615;&#32422;&#26463;&#30340;&#21069;K&#20010;&#32452;&#21512;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#36172;&#21338;&#21453;&#39304;&#19979;&#32771;&#34385;&#22810;&#26679;&#24615;&#32422;&#26463;&#30340;&#32452;&#21512;&#33218;&#36172;&#21338;&#26426;&#35774;&#32622;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#20026;&#20102;&#39640;&#25928;&#22320;&#25506;&#32034;&#32452;&#21512;&#21644;&#21463;&#32422;&#26463;&#30340;&#34892;&#21160;&#31354;&#38388;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20845;&#20010;&#20855;&#26377;&#26174;&#33879;&#20248;&#28857;&#30340;&#20174;&#27169;&#22411;&#65292;&#20197;&#29983;&#25104;&#24179;&#34913;&#22870;&#21169;&#21644;&#32422;&#26463;&#20197;&#21450;&#25928;&#29575;&#30340;&#22810;&#26679;&#21270;&#26679;&#26412;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#25945;&#24072;&#23398;&#20064;&#30340;&#20248;&#21270;&#21644;&#31574;&#30053;&#20849;&#35757;&#32451;&#25216;&#26415;&#65292;&#20197;&#25552;&#21319;&#22810;&#20010;&#20174;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#28982;&#21518;&#65292;&#20027;&#27169;&#22411;&#25910;&#38598;&#20174;&#27169;&#22411;&#25552;&#20379;&#30340;&#31934;&#33521;&#26679;&#26412;&#65292;&#24182;&#36890;&#36807;&#22522;&#20110;&#31070;&#32463;&#19978;&#19979;&#25991;UCB&#32593;&#32476;&#20272;&#35745;&#30340;&#26368;&#20339;&#26679;&#26412;&#26469;&#20570;&#20986;&#22312;&#25506;&#32034;&#21644;&#21033;&#29992;&#20043;&#38388;&#26435;&#34913;&#30340;&#20915;&#31574;&#12290;&#30001;&#20110;&#20174;&#27169;&#22411;&#30340;&#31934;&#24515;&#35774;&#35745;&#65292;&#20849;&#21516;&#35757;&#32451;&#26426;&#21046;&#25104;&#25928;&#26174;&#33879;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel master-slave architecture to solve the top-$K$ combinatorial multi-armed bandits problem with non-linear bandit feedback and diversity constraints, which, to the best of our knowledge, is the first combinatorial bandits setting considering diversity constraints under bandit feedback. Specifically, to efficiently explore the combinatorial and constrained action space, we introduce six slave models with distinguished merits to generate diversified samples well balancing rewards and constraints as well as efficiency. Moreover, we propose teacher learning based optimization and the policy co-training technique to boost the performance of the multiple slave models. The master model then collects the elite samples provided by the slave models and selects the best sample estimated by a neural contextual UCB-based network to make a decision with a trade-off between exploration and exploitation. Thanks to the elaborate design of slave models, the co-training mechanism among s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#27979;&#22320;&#32447;&#27169;&#24335;&#36830;&#36890;&#24615;&#30340;&#29616;&#35937;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#36817;&#20284;&#27979;&#22320;&#32447;&#65292;&#23454;&#29616;&#20102;&#27169;&#24335;&#36830;&#36890;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.12666</link><description>&lt;p&gt;
&#27979;&#22320;&#32447;&#27169;&#24335;&#36830;&#36890;&#24615;
&lt;/p&gt;
&lt;p&gt;
Geodesic Mode Connectivity. (arXiv:2308.12666v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12666
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#27979;&#22320;&#32447;&#27169;&#24335;&#36830;&#36890;&#24615;&#30340;&#29616;&#35937;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#36817;&#20284;&#27979;&#22320;&#32447;&#65292;&#23454;&#29616;&#20102;&#27169;&#24335;&#36830;&#36890;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#24335;&#36830;&#36890;&#24615;&#26159;&#25351;&#35757;&#32451;&#22909;&#30340;&#27169;&#22411;&#20043;&#38388;&#23384;&#22312;&#19968;&#26465;&#20302;&#25439;&#22833;&#36335;&#24452;&#30340;&#29616;&#35937;&#12290;&#25105;&#20204;&#23558;&#36825;&#19968;&#29616;&#35937;&#37325;&#26032;&#35299;&#37322;&#20026;&#20449;&#24687;&#20960;&#20309;&#30340;&#19968;&#37096;&#20998;&#65292;&#20854;&#20013;&#31070;&#32463;&#32593;&#32476;&#34987;&#30740;&#31350;&#20026;&#20855;&#26377;&#26354;&#32447;&#20960;&#20309;&#30340;&#21442;&#25968;&#21270;&#20998;&#24067;&#31354;&#38388;&#12290;&#25105;&#20204;&#20551;&#35774;&#36825;&#20123;&#31354;&#38388;&#20013;&#30340;&#26368;&#30701;&#36335;&#24452;&#65292;&#21363;&#27979;&#22320;&#32447;&#65292;&#23545;&#24212;&#20110;&#25439;&#22833;&#26223;&#35266;&#20013;&#30340;&#27169;&#24335;&#36830;&#25509;&#36335;&#24452;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#27979;&#22320;&#32447;&#30340;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20854;&#23454;&#29616;&#20102;&#27169;&#24335;&#36830;&#36890;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mode connectivity is a phenomenon where trained models are connected by a path of low loss. We reframe this in the context of Information Geometry, where neural networks are studied as spaces of parameterized distributions with curved geometry. We hypothesize that shortest paths in these spaces, known as geodesics, correspond to mode-connecting paths in the loss landscape. We propose an algorithm to approximate geodesics and demonstrate that they achieve mode connectivity.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#22871;&#24037;&#19994;&#32423;&#21256;&#29273;&#21033;&#25991;&#26412;&#22788;&#29702;&#27169;&#22411;&#65292;&#21033;&#29992;HuSpaCy&#26694;&#26550;&#23454;&#29616;&#65292;&#36890;&#36807;&#22810;&#39033;&#25913;&#36827;&#22312;&#36164;&#28304;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#20043;&#38388;&#21462;&#24471;&#20102;&#25509;&#36817;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#36825;&#20123;&#27169;&#22411;&#20855;&#22791;&#39640;&#20934;&#30830;&#24615;&#21644;&#21534;&#21520;&#37327;&#65292;&#24182;&#22312;&#25152;&#26377;&#22522;&#26412;&#25991;&#26412;&#22788;&#29702;&#27493;&#39588;&#20013;&#23637;&#31034;&#20102;&#31454;&#20105;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.12635</link><description>&lt;p&gt;
&#20351;&#29992;HuSpaCy&#25512;&#36827;&#21256;&#29273;&#21033;&#25991;&#26412;&#22788;&#29702;&#65306;&#39640;&#25928;&#20934;&#30830;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#31649;&#36947;
&lt;/p&gt;
&lt;p&gt;
Advancing Hungarian Text Processing with HuSpaCy: Efficient and Accurate NLP Pipelines. (arXiv:2308.12635v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12635
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#22871;&#24037;&#19994;&#32423;&#21256;&#29273;&#21033;&#25991;&#26412;&#22788;&#29702;&#27169;&#22411;&#65292;&#21033;&#29992;HuSpaCy&#26694;&#26550;&#23454;&#29616;&#65292;&#36890;&#36807;&#22810;&#39033;&#25913;&#36827;&#22312;&#36164;&#28304;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#20043;&#38388;&#21462;&#24471;&#20102;&#25509;&#36817;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#36825;&#20123;&#27169;&#22411;&#20855;&#22791;&#39640;&#20934;&#30830;&#24615;&#21644;&#21534;&#21520;&#37327;&#65292;&#24182;&#22312;&#25152;&#26377;&#22522;&#26412;&#25991;&#26412;&#22788;&#29702;&#27493;&#39588;&#20013;&#23637;&#31034;&#20102;&#31454;&#20105;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#22871;&#29992;&#20110;&#21256;&#29273;&#21033;&#25991;&#26412;&#22788;&#29702;&#30340;&#24037;&#19994;&#32423;&#27169;&#22411;&#65292;&#36825;&#20123;&#27169;&#22411;&#22312;&#36164;&#28304;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#20043;&#38388;&#21462;&#24471;&#20102;&#25509;&#36817;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#36825;&#20123;&#27169;&#22411;&#26159;&#22522;&#20110;spaCy&#26694;&#26550;&#23454;&#29616;&#30340;&#65292;&#22312;HuSpaCy&#24037;&#20855;&#21253;&#30340;&#26550;&#26500;&#19978;&#36827;&#34892;&#20102;&#22810;&#20010;&#25913;&#36827;&#12290;&#19982;&#29616;&#26377;&#30340;&#21256;&#29273;&#21033;&#35821;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24037;&#20855;&#30456;&#27604;&#65292;&#25105;&#20204;&#25152;&#26377;&#30340;&#31649;&#36947;&#37117;&#20855;&#22791;&#21253;&#25324;&#26631;&#35760;&#21270;&#12289;&#21477;&#23376;&#36793;&#30028;&#26816;&#27979;&#12289;&#35789;&#24615;&#26631;&#27880;&#12289;&#35789;&#24418;&#29305;&#24449;&#26631;&#27880;&#12289;&#35789;&#24418;&#36824;&#21407;&#12289;&#20381;&#23384;&#21477;&#27861;&#20998;&#26512;&#21644;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#22312;&#20869;&#30340;&#25152;&#26377;&#22522;&#26412;&#25991;&#26412;&#22788;&#29702;&#27493;&#39588;&#65292;&#24182;&#19988;&#20855;&#26377;&#39640;&#20934;&#30830;&#24615;&#21644;&#39640;&#21534;&#21520;&#37327;&#12290;&#25105;&#20204;&#23545;&#25552;&#20986;&#30340;&#25913;&#36827;&#36827;&#34892;&#20102;&#20840;&#38754;&#35780;&#20272;&#65292;&#23558;&#31649;&#36947;&#19982;&#26368;&#20808;&#36827;&#30340;&#24037;&#20855;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#24182;&#22312;&#25152;&#26377;&#25991;&#26412;&#39044;&#22788;&#29702;&#27493;&#39588;&#20013;&#23637;&#31034;&#20102;&#26032;&#27169;&#22411;&#30340;&#31454;&#20105;&#24615;&#33021;&#12290;&#25152;&#26377;&#23454;&#39564;&#37117;&#21487;&#20197;&#37325;&#29616;&#65292;&#24182;&#19988;&#36825;&#20123;&#31649;&#36947;&#21487;&#20197;&#20813;&#36153;&#20351;&#29992;&#24182;&#37319;&#29992;&#23485;&#26494;&#30340;&#35768;&#21487;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a set of industrial-grade text processing models for Hungarian that achieve near state-of-the-art performance while balancing resource efficiency and accuracy. Models have been implemented in the spaCy framework, extending the HuSpaCy toolkit with several improvements to its architecture. Compared to existing NLP tools for Hungarian, all of our pipelines feature all basic text processing steps including tokenization, sentence-boundary detection, part-of-speech tagging, morphological feature tagging, lemmatization, dependency parsing and named entity recognition with high accuracy and throughput. We thoroughly evaluated the proposed enhancements, compared the pipelines with state-of-the-art tools and demonstrated the competitive performance of the new models in all text preprocessing steps. All experiments are reproducible and the pipelines are freely available under a permissive license.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#35299;&#20915;&#22871;&#39184;&#20248;&#21270;&#38382;&#39064;&#30340;&#26032;&#39062;&#32452;&#21512;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#38024;&#23545;&#30005;&#20449;&#36816;&#33829;&#21830;&#22312;&#36873;&#25321;&#28608;&#21169;&#22871;&#39184;&#21644;&#30446;&#26631;&#29992;&#25143;&#26102;&#38754;&#20020;&#30340;&#22256;&#38590;&#36827;&#34892;&#20102;&#35299;&#20915;&#12290;</title><link>http://arxiv.org/abs/2308.12606</link><description>&lt;p&gt;
&#19968;&#20010;&#29992;&#20110;&#21521;&#30005;&#20449;&#29992;&#25143;&#25552;&#20379;&#30340;&#36138;&#24515;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Greedy Approach for Offering to Telecom Subscribers. (arXiv:2308.12606v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12606
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#35299;&#20915;&#22871;&#39184;&#20248;&#21270;&#38382;&#39064;&#30340;&#26032;&#39062;&#32452;&#21512;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#38024;&#23545;&#30005;&#20449;&#36816;&#33829;&#21830;&#22312;&#36873;&#25321;&#28608;&#21169;&#22871;&#39184;&#21644;&#30446;&#26631;&#29992;&#25143;&#26102;&#38754;&#20020;&#30340;&#22256;&#38590;&#36827;&#34892;&#20102;&#35299;&#20915;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23458;&#25143;&#20445;&#30041;&#25110;&#20943;&#23569;&#27969;&#22833;&#26159;&#30005;&#20449;&#36816;&#33829;&#21830;&#38754;&#20020;&#30340;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#20854;&#20013;&#19968;&#20010;&#26377;&#25928;&#30340;&#26041;&#27861;&#26159;&#21521;&#29992;&#25143;&#25552;&#20379;&#19968;&#20123;&#26377;&#21560;&#24341;&#21147;&#30340;&#28608;&#21169;&#25514;&#26045;&#25110;&#38468;&#21152;&#26381;&#21153;&#25110;&#37329;&#38065;&#65292;&#20197;&#20445;&#25345;&#20182;&#20204;&#30340;&#21442;&#19982;&#24182;&#30830;&#20445;&#20182;&#20204;&#22312;&#36816;&#33829;&#21830;&#30340;&#32593;&#32476;&#20013;&#20572;&#30041;&#26356;&#38271;&#26102;&#38388;&#12290;&#36890;&#24120;&#65292;&#36816;&#33829;&#21830;&#20250;&#20998;&#37197;&#19968;&#23450;&#37329;&#39069;&#30340;&#39044;&#31639;&#26469;&#36827;&#34892;&#25512;&#24191;&#27963;&#21160;&#12290;&#36825;&#39033;&#27963;&#21160;&#30340;&#22256;&#38590;&#20043;&#22788;&#22312;&#20110;&#20174;&#24222;&#22823;&#30340;&#35746;&#25143;&#32676;&#20307;&#20013;&#36873;&#25321;&#19968;&#32452;&#23458;&#25143;&#65292;&#24182;&#20915;&#23450;&#24212;&#35813;&#21521;&#20010;&#20307;&#25552;&#20379;&#22810;&#23569;&#37329;&#39069;&#65292;&#20197;&#23454;&#29616;&#36816;&#33829;&#21830;&#30340;&#30446;&#26631;&#12290;&#36873;&#25321;&#35746;&#25143;&#21644;&#36873;&#25321;&#25552;&#20379;&#32473;&#34987;&#36873;&#23450;&#35746;&#25143;&#30340;&#22871;&#39184;&#21487;&#33021;&#26377;&#22810;&#20010;&#30446;&#26631;&#65288;&#20363;&#22914;&#65292;&#26368;&#22823;&#21270;&#25910;&#20837;&#65292;&#26368;&#23567;&#21270;&#27969;&#22833;&#25968;&#37327;&#65289;&#12290;&#38500;&#20102;&#37329;&#38065;&#21033;&#30410;&#65292;&#22871;&#39184;&#36824;&#21487;&#20197;&#21253;&#25324;&#39069;&#22806;&#30340;&#25968;&#25454;&#12289;&#30701;&#20449;&#12289;&#25163;&#26426;&#28909;&#28857;&#20849;&#20139;&#31561;&#31561;&#12290;&#36825;&#20010;&#38382;&#39064;&#34987;&#31216;&#20026;&#22871;&#39184;&#20248;&#21270;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#32452;&#21512;&#31639;&#27861;&#26469;&#35299;&#20915;&#22871;&#39184;&#20248;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Customer retention or churn prevention is a challenging task of a telecom operator. One of the effective approaches is to offer some attractive incentive or additional services or money to the subscribers for keeping them engaged and make sure they stay in the operator's network for longer time. Often, operators allocate certain amount of monetary budget to carry out the offer campaign. The difficult part of this campaign is the selection of a set of customers from a large subscriber-base and deciding the amount that should be offered to an individual so that operator's objective is achieved. There may be multiple objectives (e.g., maximizing revenue, minimizing number of churns) for selection of subscriber and selection of an offer to the selected subscriber. Apart from monetary benefit, offers may include additional data, SMS, hots-spot tethering, and many more. This problem is known as offer optimization. In this paper, we propose a novel combinatorial algorithm for solving offer op
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#21644;&#22810;&#27169;&#24577;&#27169;&#22411;&#30340;&#21464;&#20998;&#20449;&#24687;&#36861;&#27714;(V-IP)&#26694;&#26550;&#65292;&#36890;&#36807;&#39034;&#24207;&#36873;&#25321;&#20219;&#21153;&#30456;&#20851;&#30340;&#21487;&#35299;&#37322;&#26597;&#35810;&#65292;&#23454;&#29616;&#21487;&#35299;&#37322;&#39044;&#27979;&#12290;&#20026;&#20102;&#35299;&#20915;&#25968;&#25454;&#26631;&#27880;&#30340;&#38480;&#21046;&#65292;&#24341;&#20837;&#20102;&#22522;&#30784;&#27169;&#22411;(FMs)&#65292;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#29983;&#25104;&#20505;&#36873;&#21487;&#35299;&#37322;&#27010;&#24565;&#38598;&#65292;&#24182;&#20351;&#29992;&#22823;&#22411;&#22810;&#27169;&#24577;&#27169;&#22411;&#27880;&#37322;&#27599;&#20010;&#25968;&#25454;&#26679;&#26412;&#12290;&#27492;&#26041;&#27861;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2308.12562</link><description>&lt;p&gt;
&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#21644;&#22810;&#27169;&#24577;&#27169;&#22411;&#36827;&#34892;&#21487;&#35299;&#37322;&#39044;&#27979;&#30340;&#21464;&#20998;&#20449;&#24687;&#36861;&#27714;
&lt;/p&gt;
&lt;p&gt;
Variational Information Pursuit with Large Language and Multimodal Models for Interpretable Predictions. (arXiv:2308.12562v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12562
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#21644;&#22810;&#27169;&#24577;&#27169;&#22411;&#30340;&#21464;&#20998;&#20449;&#24687;&#36861;&#27714;(V-IP)&#26694;&#26550;&#65292;&#36890;&#36807;&#39034;&#24207;&#36873;&#25321;&#20219;&#21153;&#30456;&#20851;&#30340;&#21487;&#35299;&#37322;&#26597;&#35810;&#65292;&#23454;&#29616;&#21487;&#35299;&#37322;&#39044;&#27979;&#12290;&#20026;&#20102;&#35299;&#20915;&#25968;&#25454;&#26631;&#27880;&#30340;&#38480;&#21046;&#65292;&#24341;&#20837;&#20102;&#22522;&#30784;&#27169;&#22411;(FMs)&#65292;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#29983;&#25104;&#20505;&#36873;&#21487;&#35299;&#37322;&#27010;&#24565;&#38598;&#65292;&#24182;&#20351;&#29992;&#22823;&#22411;&#22810;&#27169;&#24577;&#27169;&#22411;&#27880;&#37322;&#27599;&#20010;&#25968;&#25454;&#26679;&#26412;&#12290;&#27492;&#26041;&#27861;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#20449;&#24687;&#36861;&#27714;(V-IP)&#26159;&#19968;&#20010;&#36890;&#36807;&#39034;&#24207;&#36873;&#25321;&#19982;&#20219;&#21153;&#30456;&#20851;&#12289;&#29992;&#25143;&#23450;&#20041;&#21644;&#21487;&#35299;&#37322;&#30340;&#25968;&#25454;&#26597;&#35810;&#26469;&#35774;&#35745;&#21487;&#35299;&#37322;&#39044;&#27979;&#30340;&#26694;&#26550;&#12290;&#34429;&#28982;&#36825;&#20351;&#24471;&#39044;&#27979;&#27169;&#22411;&#20855;&#26377;&#20869;&#32622;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#20294;&#23558;V-IP&#24212;&#29992;&#20110;&#20219;&#20309;&#20219;&#21153;&#37117;&#38656;&#35201;&#20855;&#26377;&#30001;&#39046;&#22495;&#19987;&#23478;&#36827;&#34892;&#23494;&#38598;&#27010;&#24565;&#26631;&#27880;&#30340;&#25968;&#25454;&#26679;&#26412;&#65292;&#38480;&#21046;&#20102;V-IP&#22312;&#25163;&#21160;&#25968;&#25454;&#27880;&#37322;&#21487;&#34892;&#30340;&#23567;&#35268;&#27169;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#22522;&#30784;&#27169;&#22411;(FMs)&#26469;&#25193;&#23637;V-IP&#26694;&#26550;&#65292;&#20197;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#20010;&#20004;&#27493;&#27969;&#31243;&#65292;&#39318;&#20808;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#29983;&#25104;&#36275;&#22815;&#22823;&#30340;&#20505;&#36873;&#20219;&#21153;&#30456;&#20851;&#21487;&#35299;&#37322;&#27010;&#24565;&#38598;&#65292;&#28982;&#21518;&#21033;&#29992;&#22823;&#22411;&#22810;&#27169;&#24577;&#27169;&#22411;&#36890;&#36807;&#19982;&#29983;&#25104;&#30340;&#27010;&#24565;&#38598;&#20013;&#30340;&#27599;&#20010;&#27010;&#24565;&#30340;&#35821;&#20041;&#30456;&#20284;&#24615;&#23545;&#27599;&#20010;&#25968;&#25454;&#26679;&#26412;&#36827;&#34892;&#27880;&#37322;&#12290;&#34429;&#28982;&#36824;&#26377;&#20854;&#20182;&#21487;&#35299;&#37322;&#35774;&#35745;&#26694;&#26550;&#65292;&#27604;&#22914;Concept Bot&#65292;&#20294;&#36825;&#20123;&#26694;&#26550;&#19981;&#36866;&#21512;&#22788;&#29702;&#22823;&#35268;&#27169;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational Information Pursuit (V-IP) is a framework for making interpretable predictions by design by sequentially selecting a short chain of task-relevant, user-defined and interpretable queries about the data that are most informative for the task. While this allows for built-in interpretability in predictive models, applying V-IP to any task requires data samples with dense concept-labeling by domain experts, limiting the application of V-IP to small-scale tasks where manual data annotation is feasible. In this work, we extend the V-IP framework with Foundational Models (FMs) to address this limitation. More specifically, we use a two-step process, by first leveraging Large Language Models (LLMs) to generate a sufficiently large candidate set of task-relevant interpretable concepts, then using Large Multimodal Models to annotate each data sample by semantic similarity with each concept in the generated concept set. While other interpretable-by-design frameworks such as Concept Bot
&lt;/p&gt;</description></item><item><title>&#40664;&#35748;-ERM&#27169;&#22411;&#36890;&#36807;&#26368;&#22823;&#21270;&#38388;&#38548;&#26469;&#20248;&#21270;&#35757;&#32451;&#65292;&#23548;&#33268;&#27169;&#22411;&#26356;&#22810;&#20381;&#36182;&#20110;&#25463;&#24452;&#32780;&#38750;&#31283;&#23450;&#29305;&#24449;&#65292;&#36825;&#23545;&#24863;&#30693;&#20219;&#21153;&#26469;&#35828;&#26159;&#19981;&#21512;&#36866;&#30340;&#12290;</title><link>http://arxiv.org/abs/2308.12553</link><description>&lt;p&gt;
&#19981;&#35201;&#24618;&#25968;&#25454;&#38598;&#36716;&#31227;&#65281;&#26799;&#24230;&#21644;&#20132;&#21449;&#29109;&#23548;&#33268;&#20102;&#25463;&#24452;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Don't blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy. (arXiv:2308.12553v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12553
&lt;/p&gt;
&lt;p&gt;
&#40664;&#35748;-ERM&#27169;&#22411;&#36890;&#36807;&#26368;&#22823;&#21270;&#38388;&#38548;&#26469;&#20248;&#21270;&#35757;&#32451;&#65292;&#23548;&#33268;&#27169;&#22411;&#26356;&#22810;&#20381;&#36182;&#20110;&#25463;&#24452;&#32780;&#38750;&#31283;&#23450;&#29305;&#24449;&#65292;&#36825;&#23545;&#24863;&#30693;&#20219;&#21153;&#26469;&#35828;&#26159;&#19981;&#21512;&#36866;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24120;&#35265;&#23545;&#20110;&#25463;&#24452;&#23398;&#20064;&#30340;&#35299;&#37322;&#35748;&#20026;&#25463;&#24452;&#22312;&#35757;&#32451;&#20998;&#24067;&#19979;&#25913;&#21892;&#20102;&#39044;&#27979;&#32467;&#26524;&#65292;&#20294;&#22312;&#27979;&#35797;&#20998;&#24067;&#19979;&#21364;&#27809;&#26377;&#25913;&#21892;&#12290;&#22240;&#27492;&#65292;&#36890;&#36807;&#20856;&#22411;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#20132;&#21449;&#29109;&#20248;&#21270;&#35757;&#32451;&#30340;&#27169;&#22411;&#65288;&#25105;&#20204;&#31216;&#20854;&#20026;&#40664;&#35748;-ERM&#65289;&#21033;&#29992;&#20102;&#36825;&#20010;&#25463;&#24452;&#12290;&#28982;&#32780;&#65292;&#21363;&#20351;&#22312;&#35757;&#32451;&#20998;&#24067;&#20013;&#31283;&#23450;&#29305;&#24449;&#20915;&#23450;&#20102;&#26631;&#31614;&#32780;&#25463;&#24452;&#24182;&#27809;&#26377;&#25552;&#20379;&#39069;&#22806;&#30340;&#20449;&#24687;&#65292;&#27604;&#22914;&#22312;&#24863;&#30693;&#20219;&#21153;&#20013;&#65292;&#40664;&#35748;-ERM&#20173;&#28982;&#34920;&#29616;&#20986;&#20102;&#25463;&#24452;&#23398;&#20064;&#12290;&#20026;&#20160;&#20040;&#36825;&#26679;&#30340;&#35299;&#20915;&#26041;&#26696;&#26356;&#21463;&#38738;&#30544;&#65292;&#24403;&#21487;&#20197;&#21333;&#29420;&#20351;&#29992;&#31283;&#23450;&#29305;&#24449;&#23558;&#40664;&#35748;-ERM&#30340;&#25439;&#22833;&#39537;&#21160;&#20026;&#38646;&#26102;&#65311;&#36890;&#36807;&#30740;&#31350;&#32447;&#24615;&#24863;&#30693;&#20219;&#21153;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#40664;&#35748;-ERM&#23545;&#20110;&#26368;&#22823;&#21270;&#38388;&#38548;&#30340;&#20559;&#22909;&#23548;&#33268;&#20102;&#26356;&#22810;&#20381;&#36182;&#20110;&#25463;&#24452;&#32780;&#38750;&#31283;&#23450;&#29305;&#24449;&#30340;&#27169;&#22411;&#65292;&#21363;&#20351;&#27809;&#26377;&#36807;&#24230;&#21442;&#25968;&#21270;&#12290;&#36825;&#19968;&#21457;&#29616;&#34920;&#26126;&#65292;&#40664;&#35748;-ERM&#30340;&#38544;&#24615;&#24402;&#32435;&#20559;&#22909;&#21363;&#26368;&#22823;&#38388;&#38548;&#23545;&#20110;&#24863;&#30693;&#20219;&#21153;&#26159;&#19981;&#21512;&#36866;&#30340;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#21512;&#24863;&#30693;&#20219;&#21153;&#30340;&#24402;&#32435;&#20559;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Common explanations for shortcut learning assume that the shortcut improves prediction under the training distribution but not in the test distribution. Thus, models trained via the typical gradient-based optimization of cross-entropy, which we call default-ERM, utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM still exhibits shortcut learning. Why are such solutions preferred when the loss for default-ERM can be driven to zero using the stable feature alone? By studying a linear perception task, we show that default-ERM's preference for maximizing the margin leads to models that depend more on the shortcut than the stable feature, even without overparameterization. This insight suggests that default-ERM's implicit inductive bias towards max-margin is unsuitable for perception tasks. Instead, we develop an inductive bias toward 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; Dr. DRL &#30340;&#33258;&#24840;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31995;&#32479;&#20013;&#30340;&#19968;&#20123;&#25928;&#29575;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#22312;&#36830;&#32493;&#23398;&#20064;&#20013;&#24341;&#20837;&#26377;&#24847;&#36951;&#24536;&#30340;&#26426;&#21046;&#26469;&#24212;&#23545;&#29615;&#22659;&#28418;&#31227;&#24341;&#36215;&#30340;&#22256;&#25200;&#12290;</title><link>http://arxiv.org/abs/2308.12445</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#26377;&#24847;&#36951;&#24536;&#39537;&#21160;&#30340;&#33258;&#24840;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31995;&#32479;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Intentional Forgetting-Driven Self-Healing Method For Deep Reinforcement Learning Systems. (arXiv:2308.12445v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12445
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; Dr. DRL &#30340;&#33258;&#24840;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31995;&#32479;&#20013;&#30340;&#19968;&#20123;&#25928;&#29575;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#22312;&#36830;&#32493;&#23398;&#20064;&#20013;&#24341;&#20837;&#26377;&#24847;&#36951;&#24536;&#30340;&#26426;&#21046;&#26469;&#24212;&#23545;&#29615;&#22659;&#28418;&#31227;&#24341;&#36215;&#30340;&#22256;&#25200;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24378;&#21270;&#23398;&#20064; (DRL) &#22312;&#20687; Netflix &#21644; Facebook &#36825;&#26679;&#30340;&#22823;&#35268;&#27169;&#24212;&#29992;&#20013;&#36234;&#26469;&#36234;&#22810;&#12290;&#21644;&#22823;&#22810;&#25968;&#25968;&#25454;&#39537;&#21160;&#31995;&#32479;&#19968;&#26679;&#65292;DRL &#31995;&#32479;&#21487;&#33021;&#30001;&#20110;&#29615;&#22659;&#28418;&#31227;&#23548;&#33268;&#19981;&#33391;&#34892;&#20026;&#65292;&#32780;&#36825;&#31181;&#28418;&#31227;&#32463;&#24120;&#21457;&#29983;&#22312;&#19981;&#26029;&#21464;&#21270;&#30340;&#29983;&#20135;&#29615;&#22659;&#20013;&#12290;&#36830;&#32493;&#23398;&#20064; (CL) &#26159;&#33258;&#24840;&#26041;&#27861;&#65292;&#29992;&#20110;&#26681;&#25454;&#29615;&#22659;&#26465;&#20214;&#30340;&#21464;&#21270;&#35843;&#25972; DRL &#20195;&#29702;&#12290;&#28982;&#32780;&#65292;&#22823;&#35268;&#27169;&#30340;&#36830;&#32493;&#21464;&#21270;&#21487;&#33021;&#23548;&#33268;&#29983;&#20135;&#29615;&#22659;&#20174;&#21407;&#22987;&#29366;&#24577;&#20559;&#31163;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#36825;&#20123;&#29615;&#22659;&#28418;&#31227;&#24448;&#24448;&#23548;&#33268;&#36830;&#32493;&#23398;&#20064;&#36827;&#20837;&#38271;&#26102;&#38388;&#30340;&#33258;&#24840;&#21608;&#26399;&#65292;&#29978;&#33267;&#26080;&#27861;&#25104;&#21151;&#65292;&#36825;&#26159;&#30001;&#20110;&#28798;&#38590;&#24615;&#36951;&#24536;&#12289;&#28201;&#21644;&#36215;&#22987;&#22833;&#36133;&#21644;&#25910;&#25947;&#32531;&#24930;&#31561;&#25928;&#29575;&#20302;&#19979;&#38382;&#39064;&#24341;&#36215;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986; Dr. DRL&#65292;&#19968;&#31181;&#23545; DRL &#31995;&#32479;&#30340;&#26377;&#25928;&#33258;&#24840;&#26041;&#27861;&#65292;&#23427;&#23558;&#26377;&#24847;&#36951;&#24536;&#30340;&#26032;&#39062;&#26426;&#21046;&#25972;&#21512;&#21040;&#21407;&#22987;&#30340;&#36830;&#32493;&#23398;&#20064;&#20013;&#20197;&#35299;&#20915;&#20854;&#20027;&#35201;&#38382;&#39064;&#12290;Dr. DRL &#26377;&#24847;&#22320;&#25830;&#38500;...
&lt;/p&gt;
&lt;p&gt;
Deep reinforcement learning (DRL) is increasingly applied in large-scale productions like Netflix and Facebook. As with most data-driven systems, DRL systems can exhibit undesirable behaviors due to environmental drifts, which often occur in constantly-changing production settings. Continual Learning (CL) is the inherent self-healing approach for adapting the DRL agent in response to the environment's conditions shifts. However, successive shifts of considerable magnitude may cause the production environment to drift from its original state. Recent studies have shown that these environmental drifts tend to drive CL into long, or even unsuccessful, healing cycles, which arise from inefficiencies such as catastrophic forgetting, warm-starting failure, and slow convergence. In this paper, we propose Dr. DRL, an effective self-healing approach for DRL systems that integrates a novel mechanism of intentional forgetting into vanilla CL to overcome its main issues. Dr. DRL deliberately erases
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#30740;&#31350;&#20102;&#37327;&#23376;&#27979;&#37327;&#31867;&#30340;&#21487;&#23398;&#20064;&#24615;&#65292;&#24182;&#24314;&#31435;&#20102;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#65292;&#21516;&#26102;&#32473;&#20986;&#20102;&#23545;&#24212;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#19978;&#30028;&#12290;&#25105;&#20204;&#21457;&#29616;&#26631;&#20934;ERM&#26410;&#28385;&#36275;&#32479;&#19968;&#25910;&#25947;&#24615;&#30340;&#38382;&#39064;&#65292;&#20110;&#26159;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23398;&#20064;&#35268;&#21017;&#8212;&#8212;&#21435;&#22122;ERM&#65292;&#35813;&#35268;&#21017;&#22312;POVM&#21644;&#27010;&#29575;&#35266;&#27979;&#30340;&#27010;&#24565;&#31867;&#21035;&#20013;&#20855;&#26377;&#26222;&#36866;&#24615;&#24182;&#28385;&#36275;&#32479;&#19968;&#25910;&#25947;&#24615;&#30340;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2308.12304</link><description>&lt;p&gt;
&#33026;&#32938;&#30862;&#21270;&#12289;&#32852;&#21512;&#21487;&#27979;&#24615;&#21644;POVM&#20551;&#35774;&#31867;&#30340;PAC&#21487;&#23398;&#20064;&#24615;
&lt;/p&gt;
&lt;p&gt;
Fat Shattering, Joint Measurability, and PAC Learnability of POVM Hypothesis Classes. (arXiv:2308.12304v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12304
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#37327;&#23376;&#27979;&#37327;&#31867;&#30340;&#21487;&#23398;&#20064;&#24615;&#65292;&#24182;&#24314;&#31435;&#20102;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#65292;&#21516;&#26102;&#32473;&#20986;&#20102;&#23545;&#24212;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#19978;&#30028;&#12290;&#25105;&#20204;&#21457;&#29616;&#26631;&#20934;ERM&#26410;&#28385;&#36275;&#32479;&#19968;&#25910;&#25947;&#24615;&#30340;&#38382;&#39064;&#65292;&#20110;&#26159;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23398;&#20064;&#35268;&#21017;&#8212;&#8212;&#21435;&#22122;ERM&#65292;&#35813;&#35268;&#21017;&#22312;POVM&#21644;&#27010;&#29575;&#35266;&#27979;&#30340;&#27010;&#24565;&#31867;&#21035;&#20013;&#20855;&#26377;&#26222;&#36866;&#24615;&#24182;&#28385;&#36275;&#32479;&#19968;&#25910;&#25947;&#24615;&#30340;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24314;&#31435;&#21305;&#37197;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#32473;&#20986;&#30456;&#24212;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#19978;&#30028;&#65292;&#25105;&#20204;&#23545;&#37327;&#23376;&#27979;&#37327;&#31867;&#30340;&#21487;&#23398;&#20064;&#24615;&#36827;&#34892;&#20102;&#21051;&#30011;&#65292;&#20854;&#20013;&#23398;&#20064;&#22120;&#20165;&#33021;&#25509;&#35302;&#21040;&#24050;&#20934;&#22791;&#22909;&#30340;&#37327;&#23376;&#24577;&#12290;&#25105;&#20204;&#39318;&#20808;&#25506;&#31350;&#20102;&#20808;&#21069;&#20316;&#21697;&#20013;&#20851;&#20110;&#35813;&#35774;&#32622;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#19968;&#20123;&#21487;&#23398;&#20064;&#31867;&#21035;&#20013;&#65292;&#20808;&#21069;&#20316;&#21697;&#20013;&#23450;&#20041;&#30340;&#32463;&#39564;&#39118;&#38505;&#19982;&#32463;&#20856;&#29702;&#35770;&#20013;&#30340;&#23450;&#20041;&#30456;&#19968;&#33268;&#65292;&#20294;&#26410;&#33021;&#28385;&#36275;&#32479;&#19968;&#25910;&#25947;&#24615;&#36136;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#65292;&#20808;&#21069;&#20316;&#21697;&#20013;&#23545;VC&#32500;&#24230;&#24191;&#20041;&#19978;&#30028;&#30340;&#25512;&#24191;&#24120;&#24120;&#26159;&#26080;&#31351;&#30340;&#65292;&#21363;&#20351;&#23545;&#20110;&#26377;&#38480;&#32500;&#30340;POVM&#31867;&#21035;&#20063;&#26159;&#22914;&#27492;&#12290;&#20026;&#20102;&#20811;&#26381;&#26631;&#20934;ERM&#26410;&#33021;&#28385;&#36275;&#32479;&#19968;&#25910;&#25947;&#24615;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23398;&#20064;&#35268;&#21017;&#8212;&#8212;&#21435;&#22122;ERM&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;POVM&#21644;&#27010;&#29575;&#35266;&#27979;&#30340;&#27010;&#24565;&#31867;&#21035;&#65292;&#36825;&#26159;&#19968;&#31181;&#36890;&#29992;&#30340;&#23398;&#20064;&#35268;&#21017;&#65292;&#24182;&#32473;&#20986;&#20102;&#23427;&#28385;&#36275;&#32479;&#19968;&#25910;&#25947;&#24615;&#30340;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
We characterize learnability for quantum measurement classes by establishing matching necessary and sufficient conditions for their PAC learnability, along with corresponding sample complexity bounds, in the setting where the learner is given access only to prepared quantum states. We first probe the results from previous works on this setting. We show that the empirical risk defined in previous works and matching the definition in the classical theory fails to satisfy the uniform convergence property enjoyed in the classical setting for some learnable classes. Moreover, we show that VC dimension generalization upper bounds in previous work are frequently infinite, even for finite-dimensional POVM classes. To surmount the failure of the standard ERM to satisfy uniform convergence, we define a new learning rule -- denoised ERM. We show this to be a universal learning rule for POVM and probabilistically observed concept classes, and the condition for it to satisfy uniform convergence is 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#30446;&#26631;&#24310;&#32493;&#26041;&#27861;&#65292;&#29992;&#20110;&#35745;&#31639;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27491;&#21017;&#21270;&#36335;&#24452;&#65292;&#20197;&#35299;&#20915;DNNs&#20013;&#31232;&#30095;&#24615;&#21644;&#25968;&#20540;&#25928;&#29575;&#20043;&#38388;&#30340;&#20914;&#31361;&#12290;</title><link>http://arxiv.org/abs/2308.12044</link><description>&lt;p&gt;
&#29992;&#20110;&#35745;&#31639;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#27491;&#21017;&#21270;&#36335;&#24452;&#30340;&#22810;&#30446;&#26631;&#24310;&#32493;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A multiobjective continuation method to compute the regularization path of deep neural networks. (arXiv:2308.12044v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12044
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#30446;&#26631;&#24310;&#32493;&#26041;&#27861;&#65292;&#29992;&#20110;&#35745;&#31639;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27491;&#21017;&#21270;&#36335;&#24452;&#65292;&#20197;&#35299;&#20915;DNNs&#20013;&#31232;&#30095;&#24615;&#21644;&#25968;&#20540;&#25928;&#29575;&#20043;&#38388;&#30340;&#20914;&#31361;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#24615;&#26159;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#20013;&#38750;&#24120;&#29702;&#24819;&#30340;&#29305;&#24449;&#65292;&#22240;&#20026;&#23427;&#30830;&#20445;&#20102;&#25968;&#20540;&#25928;&#29575;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;(&#30001;&#20110;&#30456;&#20851;&#29305;&#24449;&#30340;&#25968;&#37327;&#36739;&#23569;)&#21644;&#40065;&#26834;&#24615;&#12290;&#22312;&#22522;&#20110;&#32447;&#24615;&#27169;&#22411;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#20013;&#65292;&#20247;&#25152;&#21608;&#30693;&#22312;$\ell^1$&#33539;&#25968;(&#21363;&#38646;&#26435;&#37325;)&#30340;&#26368;&#31232;&#30095;&#35299;&#21644;&#38750;&#27491;&#21017;&#21270;&#35299;&#20043;&#38388;&#23384;&#22312;&#19968;&#26465;&#36830;&#25509;&#36335;&#24452;&#65292;&#36825;&#26465;&#36335;&#24452;&#34987;&#31216;&#20026;&#27491;&#21017;&#21270;&#36335;&#24452;&#12290;&#26368;&#36817;&#65292;&#36890;&#36807;&#23558;&#32463;&#39564;&#25439;&#22833;&#21644;&#31232;&#30095;&#24615;($\ell^1$&#33539;&#25968;)&#20316;&#20026;&#20004;&#20010;&#20914;&#31361;&#30340;&#26631;&#20934;&#65292;&#24182;&#35299;&#20915;&#30001;&#27492;&#20135;&#29983;&#30340;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#65292;&#39318;&#27425;&#23581;&#35797;&#23558;&#27491;&#21017;&#21270;&#36335;&#24452;&#30340;&#27010;&#24565;&#25193;&#23637;&#21040;DNNs&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;$\ell^1$&#33539;&#25968;&#30340;&#19981;&#20809;&#28369;&#24615;&#21644;&#21442;&#25968;&#25968;&#37327;&#30340;&#39640;&#24230;&#65292;&#20174;&#35745;&#31639;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#36825;&#31181;&#26041;&#27861;&#24182;&#19981;&#26159;&#24456;&#26377;&#25928;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#36817;&#20284;&#35745;&#31639;&#25972;&#20010;&#24085;&#32047;&#25176;&#26354;&#32447;
&lt;/p&gt;
&lt;p&gt;
Sparsity is a highly desired feature in deep neural networks (DNNs) since it ensures numerical efficiency, improves the interpretability of models (due to the smaller number of relevant features), and robustness. In machine learning approaches based on linear models, it is well known that there exists a connecting path between the sparsest solution in terms of the $\ell^1$ norm (i.e., zero weights) and the non-regularized solution, which is called the regularization path. Very recently, there was a first attempt to extend the concept of regularization paths to DNNs by means of treating the empirical loss and sparsity ($\ell^1$ norm) as two conflicting criteria and solving the resulting multiobjective optimization problem. However, due to the non-smoothness of the $\ell^1$ norm and the high number of parameters, this approach is not very efficient from a computational perspective. To overcome this limitation, we present an algorithm that allows for the approximation of the entire Pareto
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#39044;&#31639;&#30340;&#38543;&#26426;&#20108;&#33218;&#36172;&#21338;&#26426;&#20013;&#36827;&#34892;&#26368;&#20339;&#33218;&#36873;&#25321;&#30340;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#19981;&#23384;&#22312;&#27604;&#31561;&#27010;&#29575;&#37319;&#26679;&#31639;&#27861;&#26356;&#22909;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#33268;&#31283;&#23450;&#31639;&#27861;&#30340;&#27010;&#24565;&#65292;&#24182;&#35777;&#26126;&#20219;&#20309;&#22312;&#25152;&#26377;&#24773;&#20917;&#19979;&#19982;&#31561;&#27010;&#29575;&#37319;&#26679;&#31639;&#27861;&#34920;&#29616;&#19968;&#26679;&#22909;&#30340;&#31639;&#27861;&#24517;&#39035;&#23646;&#20110;&#36825;&#20010;&#31867;&#21035;&#12290;&#36825;&#19968;&#32467;&#26524;&#35299;&#20915;&#20102;&#20043;&#21069;&#30340;&#20004;&#20010;&#26410;&#35299;&#20043;&#35868;&#12290;</title><link>http://arxiv.org/abs/2308.12000</link><description>&lt;p&gt;
&#26377;&#20851;&#22312;&#26377;&#38480;&#39044;&#31639;&#20108;&#33218;&#36172;&#21338;&#26426;&#20013;&#36827;&#34892;&#26368;&#20339;&#33218;&#36873;&#25321;&#30340;&#32479;&#19968;&#26368;&#20248;&#31639;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Uniformly Optimal Algorithms for Best Arm Identification in Two-Armed Bandits with Fixed Budget. (arXiv:2308.12000v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12000
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#39044;&#31639;&#30340;&#38543;&#26426;&#20108;&#33218;&#36172;&#21338;&#26426;&#20013;&#36827;&#34892;&#26368;&#20339;&#33218;&#36873;&#25321;&#30340;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#19981;&#23384;&#22312;&#27604;&#31561;&#27010;&#29575;&#37319;&#26679;&#31639;&#27861;&#26356;&#22909;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#33268;&#31283;&#23450;&#31639;&#27861;&#30340;&#27010;&#24565;&#65292;&#24182;&#35777;&#26126;&#20219;&#20309;&#22312;&#25152;&#26377;&#24773;&#20917;&#19979;&#19982;&#31561;&#27010;&#29575;&#37319;&#26679;&#31639;&#27861;&#34920;&#29616;&#19968;&#26679;&#22909;&#30340;&#31639;&#27861;&#24517;&#39035;&#23646;&#20110;&#36825;&#20010;&#31867;&#21035;&#12290;&#36825;&#19968;&#32467;&#26524;&#35299;&#20915;&#20102;&#20043;&#21069;&#30340;&#20004;&#20010;&#26410;&#35299;&#20043;&#35868;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20855;&#26377;&#20271;&#21162;&#21033;&#22870;&#21169;&#30340;&#38543;&#26426;&#20108;&#33218;&#36172;&#21338;&#26426;&#20013;&#65292;&#20351;&#29992;&#26377;&#38480;&#39044;&#31639;&#36827;&#34892;&#26368;&#20339;&#33218;&#36873;&#25321;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#19981;&#23384;&#22312;&#19968;&#20010;&#31639;&#27861;&#21487;&#20197;&#22312;&#25152;&#26377;&#24773;&#20917;&#19979;&#19982;&#31561;&#27010;&#29575;&#37319;&#26679;&#31639;&#27861;&#34920;&#29616;&#19968;&#26679;&#22909;&#65288;&#35813;&#31639;&#27861;&#34987;&#31216;&#20026;&#8220;&#22343;&#21248;&#37319;&#26679;&#8221;&#31639;&#27861;&#65289;&#65292;&#24182;&#19988;&#22312;&#33267;&#23569;&#19968;&#20010;&#24773;&#20917;&#19979;&#26126;&#26174;&#20248;&#20110;&#35813;&#31639;&#27861;&#12290;&#31616;&#32780;&#35328;&#20043;&#65292;&#19981;&#23384;&#22312;&#27604;&#22343;&#21248;&#37319;&#26679;&#31639;&#27861;&#26356;&#22909;&#30340;&#31639;&#27861;&#12290;&#20026;&#20102;&#35777;&#26126;&#36825;&#19968;&#32467;&#26524;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#8220;&#19968;&#33268;&#8221;&#21644;&#8220;&#31283;&#23450;&#8221;&#31639;&#27861;&#30340;&#33258;&#28982;&#31867;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#20219;&#20309;&#31639;&#27861;&#35201;&#22312;&#25152;&#26377;&#24773;&#20917;&#19979;&#19982;&#22343;&#21248;&#37319;&#26679;&#31639;&#27861;&#34920;&#29616;&#19968;&#26679;&#22909;&#65292;&#24517;&#39035;&#23646;&#20110;&#36825;&#20010;&#31867;&#21035;&#12290;&#36890;&#36807;&#23548;&#20986;&#28385;&#36275;&#20219;&#20309;&#19968;&#33268;&#19988;&#31283;&#23450;&#31639;&#27861;&#30340;&#38169;&#35823;&#29575;&#30340;&#19979;&#30028;&#65292;&#24182;&#35777;&#26126;&#22343;&#21248;&#37319;&#26679;&#31639;&#27861;&#19982;&#27492;&#19979;&#30028;&#30456;&#21305;&#37197;&#65292;&#25105;&#20204;&#23436;&#25104;&#20102;&#35777;&#26126;&#36807;&#31243;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#35299;&#20915;&#20102;\cite{qin2022open}&#20013;&#25552;&#20986;&#30340;&#20004;&#20010;&#26410;&#35299;&#20043;&#35868;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of best-arm identification with fixed budget in stochastic two-arm bandits with Bernoulli rewards. We prove that surprisingly, there is no algorithm that (i) performs as well as the algorithm sampling each arm equally (this algorithm is referred to as the {\it uniform sampling} algorithm) on all instances, and that (ii) strictly outperforms this algorithm on at least one instance. In short, there is no algorithm better than the uniform sampling algorithm. Towards this result, we introduce the natural class of {\it consistent} and {\it stable} algorithms, and show that any algorithm that performs as well as the uniform sampling algorithm on all instances belongs to this class. The proof is completed by deriving a lower bound on the error rate satisfied by any consistent and stable algorithm, and by showing that the uniform sampling algorithm matches this lower bound. Our results provide a solution to the two open problems presented in \cite{qin2022open}.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#26469;&#29702;&#35299;&#21644;&#39044;&#27979;&#32467;&#26500;&#19981;&#31283;&#23450;&#19979;&#30340;&#24418;&#24577;&#21457;&#29983;&#30340;&#26102;&#31354;&#22797;&#26434;&#24615;&#65292;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#30740;&#31350;&#20869;&#22806;&#37096;&#21147;&#39537;&#21160;&#19979;&#30340;&#24418;&#24577;&#21457;&#29983;&#65292;&#24182;&#36890;&#36807;&#26500;&#24314;&#25968;&#23383;&#21270;&#22270;&#20070;&#39302;&#35782;&#21035;&#24322;&#24120;&#12289;&#39044;&#27979;&#24418;&#24577;&#21457;&#23637;&#65292;&#20026;&#30142;&#30149;&#35786;&#26029;&#21644;&#25239;&#19981;&#31283;&#23450;&#35774;&#35745;&#25552;&#20379;&#20102;&#25351;&#23548;&#12290;</title><link>http://arxiv.org/abs/2308.11846</link><description>&lt;p&gt;
&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#32467;&#26500;&#19981;&#31283;&#23450;&#19979;&#30340;&#24418;&#24577;&#21457;&#29983;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Data-Driven Approach to Morphogenesis under Structural Instability. (arXiv:2308.11846v1 [nlin.PS] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11846
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#26469;&#29702;&#35299;&#21644;&#39044;&#27979;&#32467;&#26500;&#19981;&#31283;&#23450;&#19979;&#30340;&#24418;&#24577;&#21457;&#29983;&#30340;&#26102;&#31354;&#22797;&#26434;&#24615;&#65292;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#30740;&#31350;&#20869;&#22806;&#37096;&#21147;&#39537;&#21160;&#19979;&#30340;&#24418;&#24577;&#21457;&#29983;&#65292;&#24182;&#36890;&#36807;&#26500;&#24314;&#25968;&#23383;&#21270;&#22270;&#20070;&#39302;&#35782;&#21035;&#24322;&#24120;&#12289;&#39044;&#27979;&#24418;&#24577;&#21457;&#23637;&#65292;&#20026;&#30142;&#30149;&#35786;&#26029;&#21644;&#25239;&#19981;&#31283;&#23450;&#35774;&#35745;&#25552;&#20379;&#20102;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32467;&#26500;&#19981;&#31283;&#23450;&#26465;&#20214;&#19979;&#30340;&#24418;&#24577;&#21457;&#29983;&#23545;&#29983;&#21629;&#31995;&#32479;&#21644;&#24037;&#31243;&#32467;&#26500;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#26469;&#29702;&#35299;&#21644;&#39044;&#27979;&#23427;&#20204;&#30340;&#26102;&#31354;&#22797;&#26434;&#24615;&#12290;&#22522;&#20110;&#29289;&#29702;&#24314;&#27169;&#30340;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#34987;&#25552;&#20986;&#65292;&#29992;&#20110;&#30740;&#31350;&#20869;&#37096;&#25110;&#22806;&#37096;&#21147;&#39537;&#21160;&#19979;&#30340;&#24418;&#24577;&#21457;&#29983;&#12290;&#20174;&#27169;&#25311;&#25968;&#25454;&#26500;&#24314;&#20102;&#32467;&#26500;&#27169;&#24335;&#30340;&#25968;&#23383;&#21270;&#22270;&#20070;&#39302;&#65292;&#28982;&#21518;&#29992;&#20110;&#35782;&#21035;&#24322;&#24120;&#12289;&#39044;&#27979;&#24418;&#24577;&#21457;&#23637;&#65292;&#24182;&#36741;&#21161;&#39118;&#38505;&#35780;&#20272;&#21644;&#39044;&#27979;&#12290;&#36890;&#36807;&#22823;&#33041;&#29983;&#38271;&#21644;&#33322;&#31354;&#33322;&#22825;&#32467;&#26500;&#35774;&#35745;&#30340;&#31034;&#20363;&#65292;&#28436;&#31034;&#20102;&#20174;&#20840;&#23616;&#21644;&#23616;&#37096;&#29305;&#24449;&#35782;&#21035;&#20851;&#38190;&#30340;&#20998;&#23700;&#29305;&#24449;&#21644;&#39044;&#27979;&#21382;&#21490;&#20381;&#36182;&#24615;&#21457;&#23637;&#30340;&#33021;&#21147;&#65292;&#20026;&#30142;&#30149;&#35786;&#26029;/&#39044;&#27979;&#21644;&#25239;&#19981;&#31283;&#23450;&#35774;&#35745;&#25552;&#20379;&#20102;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;
Morphological development into evolutionary patterns under structural instability is ubiquitous in living systems and often of vital importance for engineering structures. Here we propose a data-driven approach to understand and predict their spatiotemporal complexities. A machine-learning framework is proposed based on the physical modeling of morphogenesis triggered by internal or external forcing. Digital libraries of structural patterns are constructed from the simulation data, which are then used to recognize the abnormalities, predict their development, and assist in risk assessment and prognosis. The capabilities to identify the key bifurcation characteristics and predict the history-dependent development from the global and local features are demonstrated by examples of brain growth and aerospace structural design, which offer guidelines for disease diagnosis/prognosis and instability-tolerant design.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;Wasserstein&#20960;&#20309;&#29983;&#25104;&#22120;&#23398;&#20064;&#26465;&#20214;&#20998;&#24067;&#65292;&#29983;&#25104;&#32473;&#23450;&#29305;&#23450;&#26631;&#31614;&#30340;&#26679;&#26412;&#12290;&#20351;&#29992;&#26368;&#20248;&#36755;&#36816;&#29702;&#35770;&#25552;&#20986;&#30340;&#26041;&#27861;&#33021;&#23398;&#20064;&#35266;&#23519;&#22495;&#30340;&#26465;&#20214;&#20998;&#24067;&#21644;&#23427;&#20204;&#20043;&#38388;&#30340;&#26368;&#20248;&#36755;&#36816;&#26144;&#23556;&#12290;&#22312;&#20154;&#33080;&#22270;&#20687;&#25968;&#25454;&#19978;&#30340;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.10145</link><description>&lt;p&gt;
Wasserstein&#20960;&#20309;&#29983;&#25104;&#22120;&#29992;&#20110;&#26465;&#20214;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Wasserstein Geodesic Generator for Conditional Distributions. (arXiv:2308.10145v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10145
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;Wasserstein&#20960;&#20309;&#29983;&#25104;&#22120;&#23398;&#20064;&#26465;&#20214;&#20998;&#24067;&#65292;&#29983;&#25104;&#32473;&#23450;&#29305;&#23450;&#26631;&#31614;&#30340;&#26679;&#26412;&#12290;&#20351;&#29992;&#26368;&#20248;&#36755;&#36816;&#29702;&#35770;&#25552;&#20986;&#30340;&#26041;&#27861;&#33021;&#23398;&#20064;&#35266;&#23519;&#22495;&#30340;&#26465;&#20214;&#20998;&#24067;&#21644;&#23427;&#20204;&#20043;&#38388;&#30340;&#26368;&#20248;&#36755;&#36816;&#26144;&#23556;&#12290;&#22312;&#20154;&#33080;&#22270;&#20687;&#25968;&#25454;&#19978;&#30340;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#32473;&#23450;&#29305;&#23450;&#26631;&#31614;&#30340;&#26679;&#26412;&#38656;&#35201;&#20272;&#35745;&#26465;&#20214;&#20998;&#24067;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#26465;&#20214;&#20998;&#24067;&#20043;&#38388;Wasserstein&#36317;&#31163;&#30340;&#21487;&#22788;&#29702;&#30340;&#19978;&#30028;&#65292;&#20197;&#24314;&#31435;&#23398;&#20064;&#26465;&#20214;&#20998;&#24067;&#30340;&#29702;&#35770;&#22522;&#30784;&#12290;&#22522;&#20110;&#36825;&#19968;&#32467;&#26524;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26465;&#20214;&#29983;&#25104;&#31639;&#27861;&#65292;&#20854;&#20013;&#26465;&#20214;&#20998;&#24067;&#23436;&#20840;&#30001;&#30001;&#32479;&#35745;&#36317;&#31163;&#23450;&#20041;&#30340;&#24230;&#37327;&#31354;&#38388;&#26469;&#34920;&#24449;&#12290;&#25105;&#20204;&#21033;&#29992;&#26368;&#20248;&#36755;&#36816;&#29702;&#35770;&#26469;&#25552;&#20986;&#20102;Wasserstein&#20960;&#20309;&#29983;&#25104;&#22120;&#65292;&#19968;&#31181;&#23398;&#20064;Wasserstein&#20960;&#20309;&#30340;&#26032;&#30340;&#26465;&#20214;&#29983;&#25104;&#22120;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#23398;&#20064;&#35266;&#23519;&#22495;&#30340;&#26465;&#20214;&#20998;&#24067;&#21644;&#23427;&#20204;&#20043;&#38388;&#30340;&#26368;&#20248;&#36755;&#36816;&#26144;&#23556;&#12290;&#32473;&#23450;&#20004;&#20010;&#35266;&#23519;&#22495;&#26631;&#31614;&#65292;&#26410;&#35266;&#23519;&#21040;&#30340;&#20013;&#38388;&#22495;&#30340;&#26465;&#20214;&#20998;&#24067;&#20301;&#20110;&#32473;&#23450;&#30340;&#26465;&#20214;&#20998;&#24067;&#20043;&#38388;&#30340;Wasserstein&#20960;&#20309;&#20013;&#12290;&#22312;&#20197;&#20809;&#29031;&#26465;&#20214;&#20026;&#22495;&#26631;&#31614;&#30340;&#20154;&#33080;&#22270;&#20687;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generating samples given a specific label requires estimating conditional distributions. We derive a tractable upper bound of the Wasserstein distance between conditional distributions to lay the theoretical groundwork to learn conditional distributions. Based on this result, we propose a novel conditional generation algorithm where conditional distributions are fully characterized by a metric space defined by a statistical distance. We employ optimal transport theory to propose the \textit{Wasserstein geodesic generator}, a new conditional generator that learns the Wasserstein geodesic. The proposed method learns both conditional distributions for observed domains and optimal transport maps between them. The conditional distributions given unobserved intermediate domains are on the Wasserstein geodesic between conditional distributions given two observed domain labels. Experiments on face images with light conditions as domain labels demonstrate the efficacy of the proposed method.
&lt;/p&gt;</description></item><item><title>&#22810;&#20445;&#30495;&#24230;&#20613;&#37324;&#21494;&#31070;&#32463;&#31639;&#23376;&#29992;&#20110;&#35299;&#20915;&#22823;&#35268;&#27169;&#22320;&#36136;&#30899;&#20648;&#23384;&#38382;&#39064;&#65292;&#36890;&#36807;&#21033;&#29992;&#32463;&#27982;&#24615;&#26356;&#39640;&#30340;&#22810;&#20445;&#30495;&#24230;&#35757;&#32451;&#25968;&#25454;&#38598;&#65292;&#33021;&#22815;&#20197;&#19982;&#39640;&#20445;&#30495;&#24230;&#27169;&#22411;&#30456;&#24403;&#30340;&#20934;&#30830;&#24615;&#36827;&#34892;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2308.09113</link><description>&lt;p&gt;
&#22810;&#20445;&#30495;&#24230;&#20613;&#37324;&#21494;&#31070;&#32463;&#31639;&#23376;&#29992;&#20110;&#24555;&#36895;&#24314;&#27169;&#22823;&#35268;&#27169;&#22320;&#36136;&#30899;&#20648;&#23384;
&lt;/p&gt;
&lt;p&gt;
Multi-fidelity Fourier Neural Operator for Fast Modeling of Large-Scale Geological Carbon Storage. (arXiv:2308.09113v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09113
&lt;/p&gt;
&lt;p&gt;
&#22810;&#20445;&#30495;&#24230;&#20613;&#37324;&#21494;&#31070;&#32463;&#31639;&#23376;&#29992;&#20110;&#35299;&#20915;&#22823;&#35268;&#27169;&#22320;&#36136;&#30899;&#20648;&#23384;&#38382;&#39064;&#65292;&#36890;&#36807;&#21033;&#29992;&#32463;&#27982;&#24615;&#26356;&#39640;&#30340;&#22810;&#20445;&#30495;&#24230;&#35757;&#32451;&#25968;&#25454;&#38598;&#65292;&#33021;&#22815;&#20197;&#19982;&#39640;&#20445;&#30495;&#24230;&#27169;&#22411;&#30456;&#24403;&#30340;&#20934;&#30830;&#24615;&#36827;&#34892;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#20195;&#29702;&#27169;&#22411;&#24050;&#24191;&#27867;&#24212;&#29992;&#20110;&#22320;&#36136;&#30899;&#20648;&#23384;&#65288;GCS&#65289;&#38382;&#39064;&#65292;&#20197;&#21152;&#24555;&#39044;&#27979;&#20648;&#21387;&#21644;&#20108;&#27687;&#21270;&#30899;&#20113;&#23618;&#31227;&#21160;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#39640;&#35745;&#31639;&#25104;&#26412;&#65292;&#22823;&#35268;&#27169;&#19977;&#32500;&#38382;&#39064;&#30340;&#21487;&#29992;&#35757;&#32451;&#25968;&#25454;&#22987;&#32456;&#26377;&#38480;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#22810;&#20445;&#30495;&#24230;&#20613;&#37324;&#21494;&#31070;&#32463;&#31639;&#23376;&#26469;&#35299;&#20915;&#22823;&#35268;&#27169;GCS&#38382;&#39064;&#65292;&#21033;&#29992;&#26356;&#20855;&#32463;&#27982;&#24615;&#30340;&#22810;&#20445;&#30495;&#24230;&#35757;&#32451;&#25968;&#25454;&#38598;&#12290;&#20613;&#37324;&#21494;&#31070;&#32463;&#31639;&#23376;&#20855;&#26377;&#33391;&#22909;&#30340;&#32593;&#26684;&#19981;&#21464;&#24615;&#65292;&#31616;&#21270;&#20102;&#19981;&#21516;&#31163;&#25955;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;&#36801;&#31227;&#23398;&#20064;&#36807;&#31243;&#12290;&#25105;&#20204;&#39318;&#20808;&#22312;&#19968;&#20010;GCS&#20648;&#23618;&#27169;&#22411;&#19978;&#36827;&#34892;&#27169;&#22411;&#26377;&#25928;&#24615;&#27979;&#35797;&#65292;&#35813;&#27169;&#22411;&#34987;&#21010;&#20998;&#20026;110,000&#20010;&#32593;&#26684;&#21333;&#20803;&#12290;&#22810;&#20445;&#30495;&#24230;&#27169;&#22411;&#30340;&#39044;&#27979;&#20934;&#30830;&#24230;&#21487;&#19982;&#39640;&#20445;&#30495;&#24230;&#27169;&#22411;&#30340;&#35757;&#32451;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning-based surrogate models have been widely applied in geological carbon storage (GCS) problems to accelerate the prediction of reservoir pressure and CO2 plume migration. Large amounts of data from physics-based numerical simulators are required to train a model to accurately predict the complex physical behaviors associated with this process. In practice, the available training data are always limited in large-scale 3D problems due to the high computational cost. Therefore, we propose to use a multi-fidelity Fourier Neural Operator to solve large-scale GCS problems with more affordable multi-fidelity training datasets. The Fourier Neural Operator has a desirable grid-invariant property, which simplifies the transfer learning procedure between datasets with different discretization. We first test the model efficacy on a GCS reservoir model being discretized into 110k grid cells. The multi-fidelity model can predict with accuracy comparable to a high-fidelity model trained wi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32039;&#26680;&#30340;&#31639;&#23376;&#29702;&#35770;&#26041;&#27861;&#26469;&#35299;&#20915;&#26465;&#20214;&#26399;&#26395;&#20272;&#35745;&#38382;&#39064;&#65292;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#23454;&#29616;&#65292;&#26131;&#20110;&#23454;&#29616;&#65292;&#19988;&#25104;&#21151;&#24212;&#29992;&#20110;&#23454;&#38469;&#38382;&#39064;&#20013;&#12290;</title><link>http://arxiv.org/abs/2306.10592</link><description>&lt;p&gt;
&#22522;&#20110;&#32039;&#26680;&#30340;&#26465;&#20214;&#26399;&#26395;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Conditional expectation via compact kernels. (arXiv:2306.10592v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10592
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32039;&#26680;&#30340;&#31639;&#23376;&#29702;&#35770;&#26041;&#27861;&#26469;&#35299;&#20915;&#26465;&#20214;&#26399;&#26395;&#20272;&#35745;&#38382;&#39064;&#65292;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#23454;&#29616;&#65292;&#26131;&#20110;&#23454;&#29616;&#65292;&#19988;&#25104;&#21151;&#24212;&#29992;&#20110;&#23454;&#38469;&#38382;&#39064;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21435;&#22122;&#12289;&#26465;&#20214;&#26399;&#26395;&#21644;&#27969;&#24418;&#23398;&#20064;&#20219;&#21153;&#36890;&#24120;&#21487;&#20197;&#22312;&#23547;&#25214;&#20004;&#20010;&#38543;&#26426;&#21464;&#37327;&#31215;&#30340;&#26465;&#20214;&#26399;&#26395;&#30340;&#20844;&#20849;&#29615;&#22659;&#19979;&#34920;&#36848;&#12290;&#26412;&#25991;&#38024;&#23545;&#36825;&#20010;&#26356;&#19968;&#33324;&#30340;&#38382;&#39064;&#65292;&#25551;&#36848;&#20102;&#19968;&#31181;&#31639;&#23376;&#29702;&#35770;&#26041;&#27861;&#26469;&#20272;&#35745;&#26465;&#20214;&#26399;&#26395;&#12290;&#26680;&#31215;&#20998;&#31639;&#23376;&#34987;&#29992;&#20316;&#32039;&#33268;&#21270;&#24037;&#20855;&#65292;&#23558;&#20272;&#35745;&#38382;&#39064;&#35774;&#32622;&#20026;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#32447;&#24615;&#36870;&#38382;&#39064;&#12290;&#35813;&#26041;&#31243;&#30340;&#35299;&#34987;&#35777;&#26126;&#23545;&#25968;&#20540;&#36924;&#36817;&#26159;&#31283;&#23450;&#30340;&#65292;&#20174;&#32780;&#30830;&#20445;&#20102;&#25968;&#25454;&#39537;&#21160;&#23454;&#29616;&#30340;&#25910;&#25947;&#24615;&#12290;&#24635;&#20307;&#25216;&#26415;&#26131;&#20110;&#23454;&#29616;&#65292;&#36824;&#23637;&#31034;&#20102;&#20854;&#22312;&#19968;&#20123;&#23454;&#38469;&#38382;&#39064;&#20013;&#30340;&#25104;&#21151;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
The separate tasks of denoising, conditional expectation and manifold learning can often be posed in a common setting of finding the conditional expectations arising from a product of two random variables. This paper focuses on this more general problem and describes an operator theoretic approach to estimating the conditional expectation. Kernel integral operators are used as a compactification tool, to set up the estimation problem as a linear inverse problem in a reproducing kernel Hilbert space. This equation is shown to have solutions that are stable to numerical approximation, thus guaranteeing the convergence of data-driven implementations. The overall technique is easy to implement, and their successful application to some real-world problems are also shown.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#31934;&#30830;&#25512;&#29702;&#31163;&#25955;&#32479;&#35745;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#25903;&#25345;&#31163;&#25955;&#37319;&#26679;&#12289;&#36830;&#32493;&#37319;&#26679;&#12289;&#31163;&#25955;&#35266;&#27979;&#12289;&#20223;&#23556;&#20989;&#25968;&#12289;&#65288;&#38543;&#26426;&#65289;&#20998;&#25903;&#21644;&#20107;&#20214;&#26465;&#20214;&#12290;&#36890;&#36807;&#27010;&#29575;&#29983;&#25104;&#20989;&#25968;&#23454;&#29616;&#21518;&#39564;&#27010;&#29575;&#12289;&#26399;&#26395;&#12289;&#26041;&#24046;&#21644;&#39640;&#38454;&#30697;&#30340;&#31934;&#30830;&#35745;&#31639;&#12290;&#35813;&#26041;&#27861;&#24615;&#33021;&#20248;&#20110;&#36817;&#20284;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#65292;&#24182;&#36991;&#20813;&#20102;&#36817;&#20284;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2305.17058</link><description>&lt;p&gt;
&#36890;&#36807;&#27010;&#29575;&#29983;&#25104;&#20989;&#25968;&#30340;&#36125;&#21494;&#26031;&#31163;&#25955;&#27169;&#22411;&#31934;&#30830;&#25512;&#29702;&#65306;&#27010;&#29575;&#32534;&#31243;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Exact Bayesian Inference on Discrete Models via Probability Generating Functions: A Probabilistic Programming Approach. (arXiv:2305.17058v1 [cs.PL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17058
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#31934;&#30830;&#25512;&#29702;&#31163;&#25955;&#32479;&#35745;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#25903;&#25345;&#31163;&#25955;&#37319;&#26679;&#12289;&#36830;&#32493;&#37319;&#26679;&#12289;&#31163;&#25955;&#35266;&#27979;&#12289;&#20223;&#23556;&#20989;&#25968;&#12289;&#65288;&#38543;&#26426;&#65289;&#20998;&#25903;&#21644;&#20107;&#20214;&#26465;&#20214;&#12290;&#36890;&#36807;&#27010;&#29575;&#29983;&#25104;&#20989;&#25968;&#23454;&#29616;&#21518;&#39564;&#27010;&#29575;&#12289;&#26399;&#26395;&#12289;&#26041;&#24046;&#21644;&#39640;&#38454;&#30697;&#30340;&#31934;&#30830;&#35745;&#31639;&#12290;&#35813;&#26041;&#27861;&#24615;&#33021;&#20248;&#20110;&#36817;&#20284;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#65292;&#24182;&#36991;&#20813;&#20102;&#36817;&#20284;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31163;&#25955;&#32479;&#35745;&#27169;&#22411;&#30340;&#31934;&#30830;&#36125;&#21494;&#26031;&#25512;&#29702;&#26041;&#27861;&#65292;&#21363;&#20351;&#26159;&#23545;&#20110;&#26080;&#38480;&#25903;&#25345;&#21644;&#36830;&#32493;&#20808;&#39564;&#20063;&#21487;&#20197;&#25214;&#21040;&#20934;&#30830;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#20026;&#20102;&#34920;&#36798;&#36825;&#26679;&#30340;&#27169;&#22411;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#25903;&#25345;&#31163;&#25955;&#21644;&#36830;&#32493;&#37319;&#26679;&#12289;&#31163;&#25955;&#35266;&#27979;&#12289;&#20223;&#23556;&#20989;&#25968;&#12289;&#65288;&#38543;&#26426;&#65289;&#20998;&#25903;&#21644;&#20107;&#20214;&#26465;&#20214;&#30340;&#27010;&#29575;&#32534;&#31243;&#35821;&#35328;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#24037;&#20855;&#26159;&#27010;&#29575;&#29983;&#25104;&#20989;&#25968;&#65306;&#23427;&#20204;&#25552;&#20379;&#20102;&#23450;&#20041;&#31243;&#24207;&#30340;&#20998;&#24067;&#30340;&#32039;&#20945;&#38381;&#21512;&#24418;&#24335;&#34920;&#31034;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#21518;&#39564;&#27010;&#29575;&#12289;&#26399;&#26395;&#12289;&#26041;&#24046;&#21644;&#39640;&#38454;&#30697;&#30340;&#31934;&#30830;&#35745;&#31639;&#12290;&#25105;&#20204;&#30340;&#25512;&#29702;&#26041;&#27861;&#26159;&#21487;&#35777;&#26126;&#27491;&#30830;&#30340;&#12289;&#23436;&#20840;&#33258;&#21160;&#21270;&#30340;&#65292;&#20351;&#29992;&#33258;&#21160;&#24494;&#20998;&#65288;&#29305;&#21035;&#26159;&#27888;&#21202;&#22810;&#39033;&#24335;&#65289;&#65292;&#20294;&#19981;&#38656;&#35201;&#35745;&#31639;&#26426;&#20195;&#25968;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#23427;&#22312;&#19968;&#31995;&#21015;&#30495;&#23454;&#19990;&#30028;&#30340;&#20363;&#23376;&#20013;&#30340;&#24615;&#33021;&#19982;&#36817;&#20284;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#31454;&#20105;&#65292;&#21516;&#26102;&#36991;&#20813;&#20102;&#36817;&#20284;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present an exact Bayesian inference method for discrete statistical models, which can find exact solutions to many discrete inference problems, even with infinite support and continuous priors. To express such models, we introduce a probabilistic programming language that supports discrete and continuous sampling, discrete observations, affine functions, (stochastic) branching, and conditioning on events. Our key tool is probability generating functions: they provide a compact closed-form representation of distributions that are definable by programs, thus enabling the exact computation of posterior probabilities, expectation, variance, and higher moments. Our inference method is provably correct, fully automated and uses automatic differentiation (specifically, Taylor polynomials), but does not require computer algebra. Our experiments show that its performance on a range of real-world examples is competitive with approximate Monte Carlo methods, while avoiding approximation errors
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#22810;&#27425;&#23581;&#35797;Metropolis&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#23616;&#37096;&#24179;&#34913;&#31574;&#30053;&#30340;&#26435;&#37325;&#20989;&#25968;&#65292;&#35299;&#20915;&#20102;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#25910;&#25947;&#38454;&#27573;&#20986;&#29616;&#30340;&#24322;&#24120;&#34892;&#20026;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2211.11613</link><description>&lt;p&gt;
&#25913;&#36827;&#22810;&#27425;&#23581;&#35797;Metropolis&#31639;&#27861;&#65292;&#20351;&#29992;&#23616;&#37096;&#24179;&#34913;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Improving multiple-try Metropolis with local balancing. (arXiv:2211.11613v2 [stat.CO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.11613
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#22810;&#27425;&#23581;&#35797;Metropolis&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#23616;&#37096;&#24179;&#34913;&#31574;&#30053;&#30340;&#26435;&#37325;&#20989;&#25968;&#65292;&#35299;&#20915;&#20102;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#25910;&#25947;&#38454;&#27573;&#20986;&#29616;&#30340;&#24322;&#24120;&#34892;&#20026;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27425;&#23581;&#35797;Metropolis&#65288;MTM&#65289;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;Markov&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#65292;&#20855;&#26377;&#21487;&#24182;&#34892;&#35745;&#31639;&#30340;&#21560;&#24341;&#21147;&#29305;&#24449;&#12290;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#65292;&#23427;&#20250;&#23545;&#39532;&#23572;&#31185;&#22827;&#38142;&#30340;&#19979;&#19968;&#20010;&#29366;&#24577;&#36827;&#34892;&#22810;&#20010;&#20505;&#36873;&#26679;&#26412;&#65292;&#24182;&#26681;&#25454;&#26435;&#37325;&#20989;&#25968;&#38543;&#26426;&#36873;&#25321;&#19968;&#20010;&#12290;&#32463;&#36807;&#29702;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#29305;&#21035;&#26159;&#22312;&#25910;&#25947;&#38454;&#27573;&#65292;&#35813;&#26435;&#37325;&#20989;&#25968;&#20250;&#23548;&#33268;&#24322;&#24120;&#34892;&#20026;&#12290;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;&#31867;&#20284;&#20110;Zanella&#65288;2020&#65289;&#30340;&#23616;&#37096;&#24179;&#34913;&#25552;&#35758;&#20998;&#24067;&#30340;&#26435;&#37325;&#20989;&#25968;&#65292;&#20174;&#32780;&#24471;&#21040;&#19981;&#20250;&#20986;&#29616;&#36825;&#20123;&#24322;&#24120;&#34892;&#20026;&#30340;MTM&#31639;&#27861;&#12290;&#20026;&#20102;&#29702;&#35770;&#20998;&#26512;&#36825;&#20123;&#31639;&#27861;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#21487;&#20197;&#35270;&#20026;&#27599;&#27425;&#36845;&#20195;&#37319;&#26679;&#26080;&#38480;&#25968;&#30446;&#20505;&#36873;&#26679;&#26412;&#30340;&#29702;&#24819;&#26041;&#26696;&#30340;&#39640;&#32500;&#24615;&#33021;&#65292;&#20197;&#21450;&#36825;&#20123;&#26041;&#26696;&#19982;MTM&#31639;&#27861;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multiple-try Metropolis (MTM) is a popular Markov chain Monte Carlo method with the appealing feature of being amenable to parallel computing. At each iteration, it samples several candidates for the next state of the Markov chain and randomly selects one of them based on a weight function. The canonical weight function is proportional to the target density. We show both theoretically and empirically that this weight function induces pathological behaviours in high dimensions, especially during the convergence phase. We propose to instead use weight functions akin to the locally-balanced proposal distributions of Zanella (2020), thus yielding MTM algorithms that do not exhibit those pathological behaviours. To theoretically analyse these algorithms, we study the high-dimensional performance of ideal schemes that can be thought of as MTM algorithms which sample an infinite number of candidates at each iteration, as well as the discrepancy between such schemes and the MTM algorithms whic
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22797;&#26434;&#27169;&#22411;&#20013;&#36827;&#34892;&#21464;&#20998;&#25512;&#26029;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#28982;&#26799;&#24230;&#26356;&#26032;&#21644;&#40654;&#26364;&#27969;&#24418;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#39640;&#26031;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#24182;&#39564;&#35777;&#20102;&#20854;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2210.14598</link><description>&lt;p&gt;
&#30830;&#20999;&#30340;&#27969;&#24418;&#39640;&#26031;&#21464;&#20998;&#36125;&#21494;&#26031;
&lt;/p&gt;
&lt;p&gt;
Exact Manifold Gaussian Variational Bayes. (arXiv:2210.14598v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.14598
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22797;&#26434;&#27169;&#22411;&#20013;&#36827;&#34892;&#21464;&#20998;&#25512;&#26029;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#28982;&#26799;&#24230;&#26356;&#26032;&#21644;&#40654;&#26364;&#27969;&#24418;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#39640;&#26031;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#24182;&#39564;&#35777;&#20102;&#20854;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22797;&#26434;&#27169;&#22411;&#20013;&#21464;&#20998;&#25512;&#26029;&#65288;VI&#65289;&#30340;&#20248;&#21270;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#33258;&#28982;&#26799;&#24230;&#26356;&#26032;&#65292;&#20854;&#20013;&#21464;&#20998;&#31354;&#38388;&#26159;&#19968;&#20010;&#40654;&#26364;&#27969;&#24418;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;&#39640;&#26031;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#20197;&#38544;&#24335;&#28385;&#36275;&#21464;&#20998;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#27491;&#23450;&#32422;&#26463;&#12290;&#25105;&#20204;&#30340;&#30830;&#20999;&#27969;&#24418;&#39640;&#26031;&#21464;&#20998;&#36125;&#21494;&#26031;&#65288;EMGVB&#65289;&#25552;&#20379;&#20102;&#31934;&#30830;&#20294;&#31616;&#21333;&#30340;&#26356;&#26032;&#35268;&#21017;&#65292;&#24182;&#19988;&#26131;&#20110;&#23454;&#29616;&#12290;&#30001;&#20110;&#20854;&#40657;&#30418;&#24615;&#36136;&#65292;EMGVB&#25104;&#20026;&#22797;&#26434;&#27169;&#22411;&#20013;&#21363;&#25554;&#21363;&#29992;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#36890;&#36807;&#22312;&#19981;&#21516;&#32479;&#35745;&#12289;&#35745;&#37327;&#21644;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#19978;&#20351;&#29992;&#20116;&#20010;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#23545;&#25105;&#20204;&#30340;&#21487;&#34892;&#24615;&#26041;&#27861;&#36827;&#34892;&#20102;&#23454;&#35777;&#39564;&#35777;&#65292;&#24182;&#19982;&#22522;&#20934;&#26041;&#27861;&#36827;&#34892;&#20102;&#24615;&#33021;&#35752;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose an optimization algorithm for Variational Inference (VI) in complex models. Our approach relies on natural gradient updates where the variational space is a Riemann manifold. We develop an efficient algorithm for Gaussian Variational Inference that implicitly satisfies the positive definite constraint on the variational covariance matrix. Our Exact manifold Gaussian Variational Bayes (EMGVB) provides exact but simple update rules and is straightforward to implement. Due to its black-box nature, EMGVB stands as a ready-to-use solution for VI in complex models. Over five datasets, we empirically validate our feasible approach on different statistical, econometric, and deep learning models, discussing its performance with respect to baseline methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#29992;&#20110;&#20010;&#20307;&#38544;&#31169;&#26680;&#31639;&#30340;&#39640;&#26031;&#24046;&#20998;&#38544;&#31169;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#33258;&#36866;&#24212;&#32452;&#21512;&#38543;&#26426;&#26426;&#21046;&#36827;&#34892;&#20180;&#32454;&#20998;&#26512;&#65292;&#20026;&#39640;&#26031;&#26426;&#21046;&#25552;&#20379;&#20102;&#26368;&#20248;&#36793;&#30028;&#12290;</title><link>http://arxiv.org/abs/2209.15596</link><description>&lt;p&gt;
&#29992;&#39640;&#26031;&#26426;&#22120;&#38544;&#31169;&#23454;&#29616;&#20010;&#20307;&#38544;&#31169;&#26680;&#31639;
&lt;/p&gt;
&lt;p&gt;
Individual Privacy Accounting with Gaussian Differential Privacy. (arXiv:2209.15596v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.15596
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#29992;&#20110;&#20010;&#20307;&#38544;&#31169;&#26680;&#31639;&#30340;&#39640;&#26031;&#24046;&#20998;&#38544;&#31169;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#33258;&#36866;&#24212;&#32452;&#21512;&#38543;&#26426;&#26426;&#21046;&#36827;&#34892;&#20180;&#32454;&#20998;&#26512;&#65292;&#20026;&#39640;&#26031;&#26426;&#21046;&#25552;&#20379;&#20102;&#26368;&#20248;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#20307;&#38544;&#31169;&#26680;&#31639;&#33021;&#22815;&#20026;&#21442;&#19982;&#20998;&#26512;&#30340;&#27599;&#20010;&#21442;&#19982;&#32773;&#20010;&#21035;&#22320;&#38480;&#21046;&#24046;&#20998;&#38544;&#31169;&#25439;&#22833;&#12290;&#36825;&#36890;&#24120;&#26159;&#26377;&#24847;&#20041;&#30340;&#65292;&#22240;&#20026;&#20010;&#20307;&#38544;&#31169;&#25439;&#22833;&#24448;&#24448;&#27604;&#32771;&#34385;&#27599;&#27425;&#25968;&#25454;&#35775;&#38382;&#30340;&#26368;&#22351;&#24773;&#20917;&#36793;&#30028;&#25152;&#31034;&#30340;&#24046;&#20998;&#38544;&#31169;&#36793;&#30028;&#35201;&#23567;&#24471;&#22810;&#12290;&#20026;&#20102;&#20197;&#26377;&#21407;&#21017;&#30340;&#26041;&#24335;&#26680;&#31639;&#20010;&#20307;&#38544;&#31169;&#25439;&#22833;&#65292;&#25105;&#20204;&#38656;&#35201;&#19968;&#31181;&#38024;&#23545;&#33258;&#36866;&#24212;&#32452;&#21512;&#38543;&#26426;&#26426;&#21046;&#30340;&#38544;&#31169;&#26680;&#31639;&#26041;&#27861;&#65292;&#20854;&#20013;&#22312;&#32473;&#23450;&#30340;&#25968;&#25454;&#35775;&#38382;&#20013;&#25152;&#20135;&#29983;&#30340;&#25439;&#22833;&#20801;&#35768;&#27604;&#26368;&#22351;&#24773;&#20917;&#25439;&#22833;&#35201;&#23567;&#12290;&#36153;&#23572;&#24503;&#26364;&#21644;&#20857;&#23572;&#23612;&#20811;&#65288;2021&#65289;&#24050;&#23545;R&#233;nyi&#24046;&#20998;&#38544;&#31169;&#65288;RDP&#65289;&#36827;&#34892;&#20102;&#36825;&#31181;&#20998;&#26512;&#65292;&#20294;&#23578;&#26410;&#24212;&#29992;&#20110;&#25152;&#35859;&#30340;&#26368;&#20248;&#38544;&#31169;&#26680;&#31639;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#39640;&#26031;&#24046;&#20998;&#38544;&#31169;&#36827;&#34892;&#20180;&#32454;&#20998;&#26512;&#65292;&#20026;&#27492;&#26041;&#21521;&#36808;&#20986;&#20102;&#31532;&#19968;&#27493;&#65292;&#39640;&#26031;&#24046;&#20998;&#38544;&#31169;&#20026;&#26368;&#22810;&#21151;&#33021;&#30340;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#20043;&#19968;&#25552;&#20379;&#20102;&#26368;&#20248;&#36793;&#30028;&#12290;&#36825;&#31181;&#26041;&#27861;&#22522;&#20110;...
&lt;/p&gt;
&lt;p&gt;
Individual privacy accounting enables bounding differential privacy (DP) loss individually for each participant involved in the analysis. This can be informative as often the individual privacy losses are considerably smaller than those indicated by the DP bounds that are based on considering worst-case bounds at each data access. In order to account for the individual privacy losses in a principled manner, we need a privacy accountant for adaptive compositions of randomised mechanisms, where the loss incurred at a given data access is allowed to be smaller than the worst-case loss. This kind of analysis has been carried out for the R\'enyi differential privacy (RDP) by Feldman and Zrnic (2021), however not yet for the so-called optimal privacy accountants. We make first steps in this direction by providing a careful analysis using the Gaussian differential privacy which gives optimal bounds for the Gaussian mechanism, one of the most versatile DP mechanisms. This approach is based on 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25506;&#32034;&#20102;&#36890;&#36807;&#20869;&#37096;&#31070;&#32463;&#20803;&#20171;&#23548;&#36882;&#24402;&#36890;&#20449;&#19982;&#30452;&#25509;&#36882;&#24402;&#36830;&#25509;&#30456;&#27604;&#30340;&#35745;&#31639;&#20248;&#21183;&#65292;&#36890;&#36807;&#20998;&#26512;&#36830;&#32493;&#31361;&#35302;&#21160;&#24577;&#21644;&#25968;&#20540;&#27169;&#25311;&#65292;&#34920;&#26126;&#20855;&#26377;&#20869;&#37096;&#31070;&#32463;&#20803;&#30340;&#32593;&#32476;&#27604;&#20855;&#26377;&#30452;&#25509;&#36882;&#24402;&#36830;&#25509;&#30340;&#32593;&#32476;&#26356;&#33021;&#25269;&#25239;&#21021;&#22987;&#21270;&#30340;&#24178;&#25200;&#12290;</title><link>http://arxiv.org/abs/2209.10634</link><description>&lt;p&gt;
&#22312;&#32479;&#35745;&#33258;&#36866;&#24212;&#20013;&#65292;&#20869;&#37096;&#31070;&#32463;&#20803;&#21152;&#36895;&#20102;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#21160;&#24577;
&lt;/p&gt;
&lt;p&gt;
Interneurons accelerate learning dynamics in recurrent neural networks for statistical adaptation. (arXiv:2209.10634v2 [q-bio.NC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.10634
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25506;&#32034;&#20102;&#36890;&#36807;&#20869;&#37096;&#31070;&#32463;&#20803;&#20171;&#23548;&#36882;&#24402;&#36890;&#20449;&#19982;&#30452;&#25509;&#36882;&#24402;&#36830;&#25509;&#30456;&#27604;&#30340;&#35745;&#31639;&#20248;&#21183;&#65292;&#36890;&#36807;&#20998;&#26512;&#36830;&#32493;&#31361;&#35302;&#21160;&#24577;&#21644;&#25968;&#20540;&#27169;&#25311;&#65292;&#34920;&#26126;&#20855;&#26377;&#20869;&#37096;&#31070;&#32463;&#20803;&#30340;&#32593;&#32476;&#27604;&#20855;&#26377;&#30452;&#25509;&#36882;&#24402;&#36830;&#25509;&#30340;&#32593;&#32476;&#26356;&#33021;&#25269;&#25239;&#21021;&#22987;&#21270;&#30340;&#24178;&#25200;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#33041;&#20013;&#30340;&#26089;&#26399;&#24863;&#30693;&#31995;&#32479;&#24555;&#36895;&#36866;&#24212;&#27874;&#21160;&#30340;&#36755;&#20837;&#32479;&#35745;&#65292;&#36825;&#38656;&#35201;&#31070;&#32463;&#20803;&#20043;&#38388;&#30340;&#36882;&#24402;&#36890;&#20449;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#36890;&#36807;&#20869;&#37096;&#31070;&#32463;&#20803;&#20171;&#23548;&#36882;&#24402;&#36890;&#20449;&#19982;&#30452;&#25509;&#36882;&#24402;&#36830;&#25509;&#30456;&#27604;&#30340;&#35745;&#31639;&#20248;&#21183;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#20004;&#31181;&#25968;&#23398;&#21487;&#36861;&#36394;&#30340;&#36882;&#24402;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#65292;&#23427;&#20204;&#23545;&#36755;&#20837;&#36827;&#34892;&#32479;&#35745;&#30333;&#21270;&#8212;&#8212;&#19968;&#31181;&#20855;&#26377;&#30452;&#25509;&#36882;&#24402;&#36830;&#25509;&#65292;&#21478;&#19968;&#31181;&#20855;&#26377;&#20171;&#23548;&#36882;&#24402;&#36890;&#20449;&#30340;&#20869;&#37096;&#31070;&#32463;&#20803;&#12290;&#36890;&#36807;&#20998;&#26512;&#30456;&#24212;&#30340;&#36830;&#32493;&#31361;&#35302;&#21160;&#24577;&#24182;&#23545;&#32593;&#32476;&#36827;&#34892;&#25968;&#20540;&#27169;&#25311;&#65292;&#25105;&#20204;&#34920;&#26126;&#20855;&#26377;&#20869;&#37096;&#31070;&#32463;&#20803;&#30340;&#32593;&#32476;&#27604;&#20855;&#26377;&#30452;&#25509;&#36882;&#24402;&#36830;&#25509;&#30340;&#32593;&#32476;&#26356;&#33021;&#25269;&#25239;&#21021;&#22987;&#21270;&#30340;&#24178;&#25200;&#65292;&#21363;&#20869;&#37096;&#31070;&#32463;&#20803;&#32593;&#32476;&#30340;&#31361;&#35302;&#21160;&#24577;&#30340;&#25910;&#25947;&#26102;&#38388;&#65288;&#25110;&#32773;&#30452;&#25509;&#36882;&#24402;&#36830;&#25509;&#30340;&#32593;&#32476;&#65289;&#21576;&#23545;&#25968;&#23610;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Early sensory systems in the brain rapidly adapt to fluctuating input statistics, which requires recurrent communication between neurons. Mechanistically, such recurrent communication is often indirect and mediated by local interneurons. In this work, we explore the computational benefits of mediating recurrent communication via interneurons compared with direct recurrent connections. To this end, we consider two mathematically tractable recurrent linear neural networks that statistically whiten their inputs -- one with direct recurrent connections and the other with interneurons that mediate recurrent communication. By analyzing the corresponding continuous synaptic dynamics and numerically simulating the networks, we show that the network with interneurons is more robust to initialization than the network with direct recurrent connections in the sense that the convergence time for the synaptic dynamics in the network with interneurons (resp. direct recurrent connections) scales logar
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#32479;&#19968;&#19981;&#21516;&#25968;&#25454;&#30340;&#26799;&#24230;&#26469;&#38450;&#24481;&#22522;&#20110;&#35780;&#20998;&#30340;&#26597;&#35810;&#25915;&#20987;&#65288;SQAs&#65289;&#65292;&#36825;&#26679;SQAs&#21482;&#33021;&#25506;&#27979;&#21040;&#19968;&#20010;&#26356;&#24369;&#30340;&#25915;&#20987;&#26041;&#21521;&#65292;&#20445;&#25252;&#30495;&#23454;&#19990;&#30028;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#12290;</title><link>http://arxiv.org/abs/2208.06228</link><description>&lt;p&gt;
&#23558;&#26799;&#24230;&#32479;&#19968;&#21270;&#20197;&#25552;&#39640;&#28145;&#24230;&#32593;&#32476;&#30340;&#30495;&#23454;&#19990;&#30028;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Unifying Gradients to Improve Real-world Robustness for Deep Networks. (arXiv:2208.06228v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.06228
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#32479;&#19968;&#19981;&#21516;&#25968;&#25454;&#30340;&#26799;&#24230;&#26469;&#38450;&#24481;&#22522;&#20110;&#35780;&#20998;&#30340;&#26597;&#35810;&#25915;&#20987;&#65288;SQAs&#65289;&#65292;&#36825;&#26679;SQAs&#21482;&#33021;&#25506;&#27979;&#21040;&#19968;&#20010;&#26356;&#24369;&#30340;&#25915;&#20987;&#26041;&#21521;&#65292;&#20445;&#25252;&#30495;&#23454;&#19990;&#30028;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#30340;&#24191;&#27867;&#24212;&#29992;&#23545;&#23427;&#20204;&#30340;&#30495;&#23454;&#19990;&#30028;&#40065;&#26834;&#24615;&#25552;&#20986;&#20102;&#26356;&#22810;&#20851;&#27880;&#65292;&#21363;DNN&#26159;&#21542;&#33021;&#22815;&#25269;&#25239;&#40657;&#30418;&#23545;&#25239;&#25915;&#20987;&#65292;&#20854;&#20013;&#22522;&#20110;&#35780;&#20998;&#30340;&#26597;&#35810;&#25915;&#20987;&#65288;SQAs&#65289;&#26368;&#20855;&#23041;&#32961;&#24615;&#65292;&#22240;&#20026;&#23427;&#20204;&#21482;&#33021;&#36890;&#36807;&#35775;&#38382;&#27169;&#22411;&#36755;&#20986;&#26377;&#25928;&#22320;&#25915;&#20987;&#21463;&#23475;&#32593;&#32476;&#12290;&#25269;&#24481;SQAs&#38656;&#35201;&#23545;&#36755;&#20986;&#36827;&#34892;&#36731;&#24494;&#20294;&#24039;&#22937;&#30340;&#21464;&#21270;&#65292;&#22240;&#20026;&#29992;&#25143;&#19982;SQAs&#20849;&#20139;&#30456;&#21516;&#30340;&#36755;&#20986;&#20449;&#24687;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#32479;&#19968;&#19981;&#21516;&#25968;&#25454;&#30340;&#26799;&#24230;&#26469;&#36827;&#34892;&#30495;&#23454;&#19990;&#30028;&#38450;&#24481;&#30340;&#26041;&#27861;&#65292;&#20351;&#24471;SQAs&#21482;&#33021;&#25506;&#27979;&#21040;&#19968;&#20010;&#26356;&#24369;&#30340;&#25915;&#20987;&#26041;&#21521;&#65292;&#36825;&#20010;&#25915;&#20987;&#26041;&#21521;&#23545;&#20110;&#19981;&#21516;&#26679;&#26412;&#26159;&#30456;&#20284;&#30340;&#12290;&#30001;&#20110;&#36825;&#31181;&#32479;&#19968;&#30340;&#25915;&#20987;&#25200;&#21160;&#34987;&#39564;&#35777;&#20026;&#27604;&#36755;&#20837;&#29305;&#23450;&#30340;&#25200;&#21160;&#26356;&#19981;&#20855;&#20405;&#30053;&#24615;&#65292;UniG&#36890;&#36807;&#25351;&#31034;&#25915;&#20987;&#32773;&#19968;&#20010;&#25197;&#26354;&#19988;&#20449;&#24687;&#36739;&#23569;&#30340;&#25915;&#20987;&#26041;&#21521;&#26469;&#20445;&#25252;&#30495;&#23454;&#19990;&#30028;&#30340;DNN&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#21487;&#25554;&#25300;&#30340;Hadamard&#20056;&#31215;&#27169;&#22359;&#39640;&#25928;&#23454;&#29616;&#20102;UniG&#12290;
&lt;/p&gt;
&lt;p&gt;
The wide application of deep neural networks (DNNs) demands an increasing amount of attention to their real-world robustness, i.e., whether a DNN resists black-box adversarial attacks, among which score-based query attacks (SQAs) are most threatening since they can effectively hurt a victim network with the only access to model outputs. Defending against SQAs requires a slight but artful variation of outputs due to the service purpose for users, who share the same output information with SQAs. In this paper, we propose a real-world defense by Unifying Gradients (UniG) of different data so that SQAs could only probe a much weaker attack direction that is similar for different samples. Since such universal attack perturbations have been validated as less aggressive than the input-specific perturbations, UniG protects real-world DNNs by indicating attackers a twisted and less informative attack direction. We implement UniG efficiently by a Hadamard product module which is plug-and-play. A
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#32447;&#24615;&#27169;&#22411;&#19979;&#22522;&#20110;&#20154;&#21475;&#24179;&#31561;&#32422;&#26463;&#30340;&#22238;&#24402;&#38382;&#39064;&#30340;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#35823;&#24046;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#21253;&#21547;&#26356;&#24191;&#27867;&#27495;&#35270;&#20559;&#24046;&#26469;&#28304;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#36825;&#20010;&#27169;&#22411;&#20013;&#65292;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#35823;&#24046;&#19982;&#26679;&#26412;&#22823;&#23567;&#12289;&#32500;&#25968;&#21644;&#20154;&#21475;&#32676;&#32452;&#25968;&#37327;&#23384;&#22312;&#20851;&#31995;&#65292;&#24182;&#19988;&#35823;&#24046;&#20250;&#38543;&#30528;&#27169;&#22411;&#20013;&#20559;&#24046;&#30340;&#22686;&#21152;&#32780;&#22686;&#21152;&#12290;</title><link>http://arxiv.org/abs/2206.11546</link><description>&lt;p&gt;
&#22312;&#32447;&#24615;&#27169;&#22411;&#19979;&#22522;&#20110;&#20154;&#21475;&#24179;&#31561;&#32422;&#26463;&#30340;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#22238;&#24402;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Demographic Parity Constrained Minimax Optimal Regression under Linear Model. (arXiv:2206.11546v3 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.11546
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#32447;&#24615;&#27169;&#22411;&#19979;&#22522;&#20110;&#20154;&#21475;&#24179;&#31561;&#32422;&#26463;&#30340;&#22238;&#24402;&#38382;&#39064;&#30340;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#35823;&#24046;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#21253;&#21547;&#26356;&#24191;&#27867;&#27495;&#35270;&#20559;&#24046;&#26469;&#28304;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#36825;&#20010;&#27169;&#22411;&#20013;&#65292;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#35823;&#24046;&#19982;&#26679;&#26412;&#22823;&#23567;&#12289;&#32500;&#25968;&#21644;&#20154;&#21475;&#32676;&#32452;&#25968;&#37327;&#23384;&#22312;&#20851;&#31995;&#65292;&#24182;&#19988;&#35823;&#24046;&#20250;&#38543;&#30528;&#27169;&#22411;&#20013;&#20559;&#24046;&#30340;&#22686;&#21152;&#32780;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#24615;&#27169;&#22411;&#19979;&#22522;&#20110;&#20154;&#21475;&#24179;&#31561;&#32422;&#26463;&#30340;&#22238;&#24402;&#38382;&#39064;&#30340;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#35823;&#24046;&#12290;&#30456;&#36739;&#20110;Chzhen&#21644;Schreuder&#65288;2022&#65289;&#25552;&#20986;&#30340;&#27169;&#22411;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#27169;&#22411;&#28085;&#30422;&#20102;&#26356;&#24191;&#27867;&#30340;&#27495;&#35270;&#20559;&#24046;&#26469;&#28304;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#22312;&#25105;&#20204;&#30340;&#27169;&#22411;&#19979;&#65292;&#20154;&#21475;&#24179;&#31561;&#32422;&#26463;&#22238;&#24402;&#38382;&#39064;&#30340;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#35823;&#24046;&#30001;$\Theta(\frac{dM}{n})$&#25152;&#25551;&#36848;&#65292;&#20854;&#20013;$n$&#34920;&#31034;&#26679;&#26412;&#22823;&#23567;&#65292;$d$&#34920;&#31034;&#32500;&#25968;&#65292;$M$&#34920;&#31034;&#30001;&#25935;&#24863;&#23646;&#24615;&#24341;&#36215;&#30340;&#20154;&#21475;&#32676;&#32452;&#25968;&#37327;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35823;&#24046;&#30340;&#26368;&#23567;&#26368;&#22823;&#20540;&#19982;&#27169;&#22411;&#20013;&#36739;&#22823;&#30340;&#20559;&#24046;&#21576;&#27491;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
We explore the minimax optimal error associated with a demographic parity-constrained regression problem within the context of a linear model. Our proposed model encompasses a broader range of discriminatory bias sources compared to the model presented by Chzhen and Schreuder (2022). Our analysis reveals that the minimax optimal error for the demographic parity-constrained regression problem under our model is characterized by $\Theta(\frac{dM}{n})$, where $n$ denotes the sample size, $d$ represents the dimensionality, and $M$ signifies the number of demographic groups arising from sensitive attributes. Moreover, we demonstrate that the minimax error increases in conjunction with a larger bias present in the model.
&lt;/p&gt;</description></item><item><title>StableDR&#26159;&#19968;&#31181;&#31283;&#23450;&#30340;&#21452;&#37325;&#31283;&#20581;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#25968;&#25454;&#32570;&#22833;&#38750;&#38543;&#26426;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#20943;&#23569;&#23545;&#22806;&#25512;&#30340;&#20381;&#36182;&#65292;StableDR&#33021;&#22815;&#21516;&#26102;&#20855;&#26377;&#26377;&#30028;&#30340;&#20559;&#24046;&#12289;&#26041;&#24046;&#21644;&#27867;&#21270;&#35823;&#24046;&#30028;&#65292;&#22312;&#19981;&#20934;&#30830;&#30340;&#20272;&#35745;&#35823;&#24046;&#21644;&#20219;&#24847;&#23567;&#30340;&#20542;&#21521;&#24615;&#19979;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2205.04701</link><description>&lt;p&gt;
StableDR:&#31283;&#23450;&#30340;&#21452;&#37325;&#31283;&#20581;&#23398;&#20064;&#26041;&#27861;&#29992;&#20110;&#25968;&#25454;&#32570;&#22833;&#38750;&#38543;&#26426;&#30340;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
StableDR: Stabilized Doubly Robust Learning for Recommendation on Data Missing Not at Random. (arXiv:2205.04701v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.04701
&lt;/p&gt;
&lt;p&gt;
StableDR&#26159;&#19968;&#31181;&#31283;&#23450;&#30340;&#21452;&#37325;&#31283;&#20581;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#25512;&#33616;&#31995;&#32479;&#20013;&#25968;&#25454;&#32570;&#22833;&#38750;&#38543;&#26426;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#20943;&#23569;&#23545;&#22806;&#25512;&#30340;&#20381;&#36182;&#65292;StableDR&#33021;&#22815;&#21516;&#26102;&#20855;&#26377;&#26377;&#30028;&#30340;&#20559;&#24046;&#12289;&#26041;&#24046;&#21644;&#27867;&#21270;&#35823;&#24046;&#30028;&#65292;&#22312;&#19981;&#20934;&#30830;&#30340;&#20272;&#35745;&#35823;&#24046;&#21644;&#20219;&#24847;&#23567;&#30340;&#20542;&#21521;&#24615;&#19979;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#29992;&#25143;&#20542;&#21521;&#20110;&#36873;&#25321;&#33258;&#24049;&#21916;&#27426;&#30340;&#29289;&#21697;&#36827;&#34892;&#35780;&#20215;&#65292;&#36825;&#23548;&#33268;&#20102;&#25968;&#25454;&#32570;&#22833;&#38750;&#38543;&#26426;&#30340;&#38382;&#39064;&#65292;&#22312;&#23545;&#39044;&#27979;&#27169;&#22411;&#36827;&#34892;&#26080;&#20559;&#35780;&#20272;&#21644;&#23398;&#20064;&#26102;&#24102;&#26469;&#20102;&#24456;&#22823;&#25361;&#25112;&#12290;&#30446;&#21069;&#65292;&#21452;&#37325;&#31283;&#20581;&#65288;DR&#65289;&#26041;&#27861;&#24050;&#32463;&#24471;&#21040;&#24191;&#27867;&#30740;&#31350;&#65292;&#24182;&#23637;&#31034;&#20986;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;DR&#26041;&#27861;&#30340;&#19981;&#31283;&#23450;&#24615;&#20197;&#21450;&#23545;&#26497;&#23567;&#30340;&#20542;&#21521;&#24615;&#20855;&#26377;&#26080;&#30028;&#20559;&#24046;&#12289;&#26041;&#24046;&#21644;&#27867;&#21270;&#30028;&#38480;&#30340;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;DR&#26356;&#22810;&#22320;&#20381;&#36182;&#22806;&#25512;&#65292;&#36825;&#20250;&#23548;&#33268;&#27425;&#20248;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#35299;&#20915;&#20197;&#19978;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31283;&#23450;&#30340;&#21452;&#37325;&#31283;&#20581;&#65288;StableDR&#65289;&#23398;&#20064;&#26041;&#27861;&#65292;&#23545;&#22806;&#25512;&#30340;&#20381;&#36182;&#36739;&#24369;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#22312;&#19981;&#20934;&#30830;&#30340;&#20272;&#35745;&#35823;&#24046;&#21644;&#20219;&#24847;&#23567;&#30340;&#20542;&#21521;&#24615;&#19979;&#65292;StableDR&#21516;&#26102;&#20855;&#26377;&#26377;&#30028;&#30340;&#20559;&#24046;&#12289;&#26041;&#24046;&#21644;&#27867;&#21270;&#35823;&#24046;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;StableDR&#30340;&#26032;&#22411;&#23398;&#20064;&#26041;&#27861;&#26469;&#26356;&#26032;&#20272;&#35745;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recommender systems, users always choose the favorite items to rate, which leads to data missing not at random and poses a great challenge for unbiased evaluation and learning of prediction models. Currently, the doubly robust (DR) methods have been widely studied and demonstrate superior performance. However, in this paper, we show that DR methods are unstable and have unbounded bias, variance, and generalization bounds to extremely small propensities. Moreover, the fact that DR relies more on extrapolation will lead to suboptimal performance. To address the above limitations while retaining double robustness, we propose a stabilized doubly robust (StableDR) learning approach with a weaker reliance on extrapolation. Theoretical analysis shows that StableDR has bounded bias, variance, and generalization error bound simultaneously under inaccurate imputed errors and arbitrarily small propensities. In addition, we propose a novel learning approach for StableDR that updates the imputat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#27969;&#24418;&#19978;&#30340;min-max&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;Riemannian Hamiltonian&#26041;&#27861;&#20316;&#20026;&#20854;&#20195;&#29702;&#26041;&#27861;&#12290;&#36890;&#36807;&#26368;&#23567;&#21270;Hamiltonian&#20989;&#25968;&#65292;&#21487;&#20197;&#24471;&#21040;&#25152;&#38656;&#30340;min-max&#38797;&#28857;&#12290;&#35813;&#26041;&#27861;&#22312;geodesic-bilinear&#20248;&#21270;&#38382;&#39064;&#20013;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#20294;&#36890;&#36807;&#35299;&#20915;&#20195;&#29702;&#38382;&#39064;&#21487;&#20197;&#24471;&#21040;&#20840;&#23616;&#26368;&#20248;&#25628;&#32034;&#26041;&#21521;&#12290;&#35813;&#26041;&#27861;&#22312;&#22810;&#20010;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2204.11418</link><description>&lt;p&gt;
&#27969;&#24418;&#19978;&#30340;Riemannian Hamiltonian&#26041;&#27861;&#29992;&#20110;min-max&#20248;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Riemannian Hamiltonian methods for min-max optimization on manifolds. (arXiv:2204.11418v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.11418
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#27969;&#24418;&#19978;&#30340;min-max&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;Riemannian Hamiltonian&#26041;&#27861;&#20316;&#20026;&#20854;&#20195;&#29702;&#26041;&#27861;&#12290;&#36890;&#36807;&#26368;&#23567;&#21270;Hamiltonian&#20989;&#25968;&#65292;&#21487;&#20197;&#24471;&#21040;&#25152;&#38656;&#30340;min-max&#38797;&#28857;&#12290;&#35813;&#26041;&#27861;&#22312;geodesic-bilinear&#20248;&#21270;&#38382;&#39064;&#20013;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#20294;&#36890;&#36807;&#35299;&#20915;&#20195;&#29702;&#38382;&#39064;&#21487;&#20197;&#24471;&#21040;&#20840;&#23616;&#26368;&#20248;&#25628;&#32034;&#26041;&#21521;&#12290;&#35813;&#26041;&#27861;&#22312;&#22810;&#20010;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#27969;&#24418;&#19978;&#30340;min-max&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;Riemannian Hamiltonian&#20989;&#25968;&#65292;&#20854;&#26368;&#23567;&#21270;&#20316;&#20026;&#35299;&#20915;&#21407;&#22987;min-max&#38382;&#39064;&#30340;&#20195;&#29702;&#12290;&#22312;Riemannian Polyak-{\L}ojasiewicz&#26465;&#20214;&#19979;&#65292;&#20854;&#26368;&#23567;&#20540;&#23545;&#24212;&#20110;&#25152;&#38656;&#30340;min-max&#38797;&#28857;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#28385;&#36275;&#27492;&#26465;&#20214;&#30340;&#24773;&#20917;&#12290;&#29305;&#21035;&#26159;&#23545;&#20110;geodesic-bilinear&#20248;&#21270;&#65292;&#22312;&#35299;&#20915;&#20195;&#29702;&#38382;&#39064;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#24471;&#21040;&#27491;&#30830;&#30340;&#20840;&#23616;&#26368;&#20248;&#25628;&#32034;&#26041;&#21521;&#65292;&#32780;&#22312;min-max&#24418;&#24335;&#21270;&#20013;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#26368;&#23567;&#21270;Hamiltonian&#20989;&#25968;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Riemannian Hamiltonian&#26041;&#27861;&#65288;RHM&#65289;&#24182;&#25552;&#20986;&#20102;&#23427;&#20204;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;&#25105;&#20204;&#23558;RHM&#25193;&#23637;&#21040;&#21253;&#25324;&#20849;&#35782;&#27491;&#21017;&#21270;&#21644;&#38543;&#26426;&#35774;&#32622;&#12290;&#25105;&#20204;&#36890;&#36807;&#24212;&#29992;&#22914;&#23376;&#31354;&#38388;&#40065;&#26834;Wasserstein&#36317;&#31163;&#12289;&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#35757;&#32451;&#21644;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#31561;&#26469;&#35828;&#26126;&#25152;&#25552;&#20986;&#30340;RHM&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study min-max optimization problems on Riemannian manifolds. We introduce a Riemannian Hamiltonian function, minimization of which serves as a proxy for solving the original min-max problems. Under the Riemannian Polyak--{\L}ojasiewicz condition on the Hamiltonian function, its minimizer corresponds to the desired min-max saddle point. We also provide cases where this condition is satisfied. For geodesic-bilinear optimization in particular, solving the proxy problem leads to the correct search direction towards global optimality, which becomes challenging with the min-max formulation. To minimize the Hamiltonian function, we propose Riemannian Hamiltonian methods (RHM) and present their convergence analyses. We extend RHM to include consensus regularization and to the stochastic setting. We illustrate the efficacy of the proposed RHM in applications such as subspace robust Wasserstein distance, robust training of neural networks, and generative adversarial networks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23545;&#25239;&#25915;&#20987;&#19979;&#30340;UCB&#26368;&#20248;&#25289;&#33218;&#31574;&#30053;&#65292;&#25104;&#26412;&#20026;$\sqrt{\log T}$&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#27492;&#25915;&#20987;&#31574;&#30053;&#36817;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2008.09312</link><description>&lt;p&gt;
UCB Bandits&#22312;&#23545;&#25239;&#25915;&#20987;&#20013;&#30340;&#36817;&#20046;&#26368;&#20248;&#25915;&#20987;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Near Optimal Adversarial Attack on UCB Bandits. (arXiv:2008.09312v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2008.09312
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23545;&#25239;&#25915;&#20987;&#19979;&#30340;UCB&#26368;&#20248;&#25289;&#33218;&#31574;&#30053;&#65292;&#25104;&#26412;&#20026;$\sqrt{\log T}$&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#27492;&#25915;&#20987;&#31574;&#30053;&#36817;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#31181;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#65292;&#20854;&#20013;&#22870;&#21169;&#21463;&#21040;&#23545;&#25239;&#24615;&#30772;&#22351;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25915;&#20987;&#31574;&#30053;&#65292;&#36890;&#36807;&#25805;&#20316;UCB&#21407;&#21017;&#26469;&#25289;&#21160;&#19968;&#20123;&#38750;&#26368;&#20248;&#30446;&#26631;&#33218;$T-o(T)$&#27425;&#65292;&#32047;&#31215;&#25104;&#26412;&#30340;&#26631;&#24230;&#20026;$\sqrt{\log T}$&#65292;&#20854;&#20013;$T$&#20026;&#22238;&#21512;&#25968;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#32047;&#31215;&#25915;&#20987;&#25104;&#26412;&#30340;&#31532;&#19968;&#20010;&#19979;&#30028;&#12290;&#25105;&#20204;&#30340;&#19979;&#30028;&#19982;&#25105;&#20204;&#30340;&#19978;&#30028;&#21305;&#37197;&#65292;&#38500;&#20102;$\log\log T$&#22240;&#23376;&#65292;&#34920;&#26126;&#25105;&#20204;&#30340;&#25915;&#20987;&#31574;&#30053;&#36817;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a stochastic multi-arm bandit problem where rewards are subject to adversarial corruption. We propose a novel attack strategy that manipulates a UCB principle into pulling some non-optimal target arm $T - o(T)$ times with a cumulative cost that scales as $\sqrt{\log T}$, where $T$ is the number of rounds. We also prove the first lower bound on the cumulative attack cost. Our lower bound matches our upper bound up to $\log \log T$ factors, showing our attack to be near optimal.
&lt;/p&gt;</description></item></channel></rss>