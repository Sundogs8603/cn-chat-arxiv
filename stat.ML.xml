<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#38024;&#23545;&#38169;&#20301;&#22788;&#29702;&#38382;&#39064;&#65292;&#23558;&#20854;&#35270;&#20026;&#27835;&#30103;&#20999;&#25442;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#27010;&#29575;&#27169;&#22411;&#35299;&#20915;&#20102;&#22797;&#22686;&#21644;&#26411;&#20107;&#20214;&#20559;&#24046;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2304.03247</link><description>&lt;p&gt;
&#19968;&#31181;&#22312;&#19981;&#21487;&#36991;&#20813;&#39118;&#38505;&#23384;&#22312;&#19979;&#36827;&#34892;&#22797;&#21457;&#20107;&#20214;&#22240;&#26524;&#20998;&#26512;&#30340;&#36125;&#21494;&#26031;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Bayesian Framework for Causal Analysis of Recurrent Events in Presence of Immortal Risk. (arXiv:2304.03247v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03247
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#38024;&#23545;&#38169;&#20301;&#22788;&#29702;&#38382;&#39064;&#65292;&#23558;&#20854;&#35270;&#20026;&#27835;&#30103;&#20999;&#25442;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#27010;&#29575;&#27169;&#22411;&#35299;&#20915;&#20102;&#22797;&#22686;&#21644;&#26411;&#20107;&#20214;&#20559;&#24046;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#29289;&#21307;&#23398;&#32479;&#35745;&#23398;&#20013;&#23545;&#22797;&#21457;&#20107;&#20214;&#29575;&#30340;&#35266;&#27979;&#30740;&#31350;&#24456;&#24120;&#35265;&#12290;&#36890;&#24120;&#30340;&#30446;&#26631;&#26159;&#22312;&#35268;&#23450;&#30340;&#38543;&#35775;&#26102;&#38388;&#31383;&#21475;&#20869;&#65292;&#20272;&#35745;&#22312;&#19968;&#20010;&#26126;&#30830;&#23450;&#20041;&#30340;&#30446;&#26631;&#20154;&#32676;&#20013;&#20004;&#31181;&#27835;&#30103;&#26041;&#27861;&#30340;&#20107;&#20214;&#29575;&#24046;&#24322;&#12290;&#20351;&#29992;&#35266;&#27979;&#24615;&#32034;&#36180;&#25968;&#25454;&#36827;&#34892;&#20272;&#35745;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#22312;&#30446;&#26631;&#20154;&#32676;&#30340;&#25104;&#21592;&#36164;&#26684;&#26041;&#38754;&#23450;&#20041;&#26102;&#65292;&#24456;&#23569;&#22312;&#36164;&#26684;&#30830;&#35748;&#26102;&#20934;&#30830;&#20998;&#37197;&#27835;&#30103;&#26041;&#24335;&#12290;&#30446;&#21069;&#30340;&#35299;&#20915;&#26041;&#26696;&#36890;&#24120;&#26159;&#38169;&#20301;&#22788;&#29702;&#65292;&#27604;&#22914;&#22522;&#20110;&#21518;&#32493;&#20998;&#37197;&#65292;&#22312;&#36164;&#26684;&#30830;&#35748;&#26102;&#20998;&#37197;&#27835;&#30103;&#26041;&#24335;&#65292;&#36825;&#20250;&#23558;&#20808;&#21069;&#30340;&#20107;&#20214;&#29575;&#38169;&#35823;&#22320;&#24402;&#22240;&#20110;&#27835;&#30103;-&#20174;&#32780;&#20135;&#29983;&#19981;&#21487;&#36991;&#20813;&#30340;&#39118;&#38505;&#20559;&#24046;&#12290;&#21363;&#20351;&#36164;&#26684;&#21644;&#27835;&#30103;&#24050;&#32463;&#23545;&#40784;&#65292;&#32456;&#27490;&#20107;&#20214;&#36807;&#31243;&#65288;&#20363;&#22914;&#27515;&#20129;&#65289;&#20063;&#32463;&#24120;&#20572;&#27490;&#24863;&#20852;&#36259;&#30340;&#22797;&#21457;&#20107;&#20214;&#36807;&#31243;&#12290;&#21516;&#26679;&#65292;&#36825;&#20004;&#20010;&#36807;&#31243;&#20063;&#21463;&#21040;&#23457;&#26597;&#30340;&#24433;&#21709;&#65292;&#22240;&#27492;&#22312;&#25972;&#20010;&#38543;&#35775;&#26102;&#38388;&#31383;&#21475;&#20869;&#19981;&#33021;&#35266;&#23519;&#21040;&#20107;&#20214;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#38169;&#20301;&#22788;&#29702;&#36716;&#21270;&#20026;&#27835;&#30103;&#20999;&#25442;&#38382;&#39064;&#65306;&#19968;&#20123;&#24739;&#32773;&#22312;&#25972;&#20010;&#38543;&#35775;&#26102;&#38388;&#31383;&#21475;&#20869;&#22362;&#25345;&#19968;&#20010;&#29305;&#23450;&#30340;&#27835;&#30103;&#31574;&#30053;&#65292;&#21478;&#19968;&#20123;&#24739;&#32773;&#22312;&#36825;&#20010;&#26102;&#38388;&#31383;&#21475;&#20869;&#32463;&#21382;&#27835;&#30103;&#31574;&#30053;&#30340;&#20999;&#25442;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#27010;&#29575;&#27169;&#22411;&#65292;&#20854;&#20013;&#21253;&#25324;&#20004;&#20010;&#22522;&#26412;&#20803;&#32032;&#65306;&#36890;&#36807;&#19968;&#20010;&#21512;&#29702;&#30340;&#26102;&#21051;&#20999;&#25442;&#27169;&#22411;&#65292;&#27491;&#30830;&#22320;&#24314;&#27169;&#27835;&#30103;&#20043;&#38388;&#30340;&#20999;&#25442;&#21644;&#19981;&#21487;&#36991;&#20813;&#39118;&#38505;&#65292;&#36890;&#36807;&#23558;&#38750;&#35266;&#23519;&#20107;&#20214;&#27169;&#22411;&#21270;&#20026;&#22797;&#21457;&#20107;&#20214;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#22797;&#22686;&#21644;&#26411;&#20107;&#20214;&#20559;&#24046;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Observational studies of recurrent event rates are common in biomedical statistics. Broadly, the goal is to estimate differences in event rates under two treatments within a defined target population over a specified followup window. Estimation with observational claims data is challenging because while membership in the target population is defined in terms of eligibility criteria, treatment is rarely assigned exactly at the time of eligibility. Ad-hoc solutions to this timing misalignment, such as assigning treatment at eligibility based on subsequent assignment, incorrectly attribute prior event rates to treatment - resulting in immortal risk bias. Even if eligibility and treatment are aligned, a terminal event process (e.g. death) often stops the recurrent event process of interest. Both processes are also censored so that events are not observed over the entire followup window. Our approach addresses misalignment by casting it as a treatment switching problem: some patients are on
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#26032;&#30340;Oracle&#19981;&#31561;&#24335;&#65292;&#22312;&#36755;&#20837;&#22495;&#19978;&#30340;&#19968;&#33324;&#30418;&#35745;&#25968;&#32500;&#24230;&#20551;&#35774;&#21644;&#22122;&#22768;&#26465;&#20214;&#25110;&#26631;&#20934;&#24179;&#28369;&#26465;&#20214;&#19979;&#65292;&#23545;&#20110;&#39640;&#26031;&#25104;&#23545;&#25490;&#21517;&#20272;&#35745;&#22120;&#24471;&#20986;&#20102;&#24555;&#36895;&#23398;&#20064;&#29575;&#12290;&#36825;&#34920;&#26126;&#65292;&#36755;&#20837;&#31354;&#38388;&#30340;&#20302;&#22266;&#26377;&#32500;&#24230;&#21487;&#20197;&#24110;&#21161;&#36991;&#20813;&#32500;&#24230;&#35781;&#21650;&#12290;</title><link>http://arxiv.org/abs/2304.03185</link><description>&lt;p&gt;
&#24102;&#39640;&#26031;&#26680;&#30340;&#25104;&#23545;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
Pairwise Ranking with Gaussian Kernels. (arXiv:2304.03185v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03185
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#26032;&#30340;Oracle&#19981;&#31561;&#24335;&#65292;&#22312;&#36755;&#20837;&#22495;&#19978;&#30340;&#19968;&#33324;&#30418;&#35745;&#25968;&#32500;&#24230;&#20551;&#35774;&#21644;&#22122;&#22768;&#26465;&#20214;&#25110;&#26631;&#20934;&#24179;&#28369;&#26465;&#20214;&#19979;&#65292;&#23545;&#20110;&#39640;&#26031;&#25104;&#23545;&#25490;&#21517;&#20272;&#35745;&#22120;&#24471;&#20986;&#20102;&#24555;&#36895;&#23398;&#20064;&#29575;&#12290;&#36825;&#34920;&#26126;&#65292;&#36755;&#20837;&#31354;&#38388;&#30340;&#20302;&#22266;&#26377;&#32500;&#24230;&#21487;&#20197;&#24110;&#21161;&#36991;&#20813;&#32500;&#24230;&#35781;&#21650;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24102;&#39640;&#26031;&#26680;&#30340;&#27491;&#21017;&#25104;&#23545;&#25490;&#21517;&#26159;&#21069;&#27839;&#30340;&#23398;&#20064;&#31639;&#27861;&#20043;&#19968;&#12290;&#23613;&#31649;&#24212;&#29992;&#33539;&#22260;&#24191;&#27867;&#65292;&#20294;&#32570;&#20047;&#20005;&#26684;&#30340;&#29702;&#35770;&#35777;&#26126;&#26469;&#25903;&#25345;&#36825;&#31181;&#25490;&#21517;&#20272;&#35745;&#22120;&#30340;&#24615;&#33021;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#20026;&#27491;&#21017;&#25104;&#23545;&#25490;&#21517;&#24320;&#21457;&#26032;&#30340; Oracle &#19981;&#31561;&#24335;&#26469;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#20511;&#21161;&#36825;&#20123; Oracle &#19981;&#31561;&#24335;&#65292;&#32467;&#21512;&#36755;&#20837;&#22495;&#19978;&#30340;&#19968;&#33324;&#30418;&#35745;&#25968;&#32500;&#24230;&#20551;&#35774;&#21644;&#22122;&#22768;&#26465;&#20214;&#25110;&#26631;&#20934;&#24179;&#28369;&#26465;&#20214;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#39640;&#26031;&#25490;&#21517;&#20272;&#35745;&#22120;&#30340;&#24555;&#36895;&#23398;&#20064;&#29575;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#25913;&#36827;&#20102;&#29616;&#26377;&#30340;&#20272;&#35745;&#65292;&#24182;&#26174;&#31034;&#36755;&#20837;&#31354;&#38388;&#30340;&#20302;&#22266;&#26377;&#32500;&#24230;&#21487;&#20197;&#24110;&#21161;&#36895;&#29575;&#36991;&#20813;&#32500;&#24230;&#35781;&#21650;&#12290;
&lt;/p&gt;
&lt;p&gt;
Regularized pairwise ranking with Gaussian kernels is one of the cutting-edge learning algorithms. Despite a wide range of applications, a rigorous theoretical demonstration still lacks to support the performance of such ranking estimators. This work aims to fill this gap by developing novel oracle inequalities for regularized pairwise ranking. With the help of these oracle inequalities, we derive fast learning rates of Gaussian ranking estimators under a general box-counting dimension assumption on the input domain combined with the noise conditions or the standard smoothness condition. Our theoretical analysis improves the existing estimates and shows that a low intrinsic dimension of input space can help the rates circumvent the curse of dimensionality.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#30340;&#26041;&#27861;&#21517;&#20026;d-SAGE&#65292;&#29992;&#20110;&#21152;&#36895;SAGE&#36924;&#36817;&#31639;&#27861;&#65292;&#26174;&#33879;&#38477;&#20302;&#35745;&#31639;&#24320;&#38144;&#21644;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#23637;&#31034;&#20102;$d$-SAGE&#30340;&#36924;&#36817;&#35823;&#24046;&#20250;&#25910;&#25947;&#20110;&#38646;&#65292;&#23454;&#39564;&#19978;&#20307;&#29616;&#20102;&#39640;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2304.03113</link><description>&lt;p&gt;
&#36890;&#36807;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#23454;&#29616;&#39640;&#25928;&#30340;SAGE&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Efficient SAGE Estimation via Causal Structure Learning. (arXiv:2304.03113v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03113
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#30340;&#26041;&#27861;&#21517;&#20026;d-SAGE&#65292;&#29992;&#20110;&#21152;&#36895;SAGE&#36924;&#36817;&#31639;&#27861;&#65292;&#26174;&#33879;&#38477;&#20302;&#35745;&#31639;&#24320;&#38144;&#21644;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#23637;&#31034;&#20102;$d$-SAGE&#30340;&#36924;&#36817;&#35823;&#24046;&#20250;&#25910;&#25947;&#20110;&#38646;&#65292;&#23454;&#39564;&#19978;&#20307;&#29616;&#20102;&#39640;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Shapley Additive Global Importance (SAGE)&#26159;&#19968;&#31181;&#29702;&#35770;&#19978;&#26377;&#21560;&#24341;&#21147;&#30340;&#21487;&#35299;&#37322;&#24615;&#26041;&#27861;&#65292;&#23427;&#20844;&#24179;&#22320;&#23558;&#20840;&#23616;&#37325;&#35201;&#24615;&#24402;&#22240;&#20110;&#27169;&#22411;&#30340;&#29305;&#24449;&#12290;&#28982;&#32780;&#65292;&#23427;&#30340;&#31934;&#30830;&#35745;&#31639;&#38656;&#35201;&#35745;&#31639;&#29305;&#24449;&#38598;&#30340;&#25351;&#25968;&#25968;&#37327;&#30340;&#21097;&#20313;&#24615;&#33021;&#36129;&#29486;&#65292;&#36825;&#22312;&#35745;&#31639;&#19978;&#38750;&#24120;&#26114;&#36149;&#65292;&#23588;&#20854;&#26159;&#22240;&#20026;&#20272;&#35745;&#21097;&#20313;&#24615;&#33021;&#36129;&#29486;&#38656;&#35201;&#20174;&#26465;&#20214;&#20998;&#24067;&#20013;&#37319;&#26679;&#12290;&#22240;&#27492;&#65292;SAGE&#36924;&#36817;&#31639;&#27861;&#21482;&#32771;&#34385;&#20102;&#19968;&#23567;&#37096;&#20998;&#29305;&#24449;&#38598;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;$d$-SAGE&#30340;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#21152;&#36895;SAGE&#36924;&#36817;&#12290;$d$-SAGE&#26159;&#30001;&#20110;&#35266;&#23519;&#21040;&#29305;&#24449;&#21644;&#27169;&#22411;&#30446;&#26631;&#20043;&#38388;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615; (CI) &#24847;&#21619;&#30528;&#38646;&#21097;&#20313;&#36129;&#29486;&#65292;&#22240;&#27492;&#21487;&#20197;&#36339;&#36807;&#23427;&#20204;&#30340;&#35745;&#31639;&#12290;&#20026;&#20102;&#35782;&#21035;CI&#65292;&#25105;&#20204;&#21033;&#29992;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;(CSL)&#26469;&#25512;&#26029;&#19968;&#20010;&#22270;&#65292;&#35813;&#22270;&#23558;&#25968;&#25454;&#20013;&#30340;(&#26465;&#20214;)&#29420;&#31435;&#24615;&#32534;&#30721;&#20026;$d$&#20998;&#31163;&#12290;&#36825;&#22312;&#35745;&#31639;&#19978;&#26356;&#26377;&#25928;&#65292;&#22240;&#20026;&#25105;&#20204;&#21482;&#38656;&#35201;&#35745;&#31639;&#38750;$d$&#20998;&#31163;&#29305;&#24449;&#38598;&#30340;SAGE&#20540;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#65292;&#35828;&#26126;&#38543;&#30528;$d$&#30340;&#22686;&#21152;&#65292;$d$-SAGE&#30340;&#36924;&#36817;&#35823;&#24046;&#20250;&#25910;&#25947;&#20110;&#38646;&#12290;&#22312;&#23454;&#39564;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;$d$-SAGE&#38656;&#35201;&#27604;&#29616;&#26377;&#30340;SAGE&#36924;&#36817;&#31639;&#27861;&#26356;&#23569;&#30340;&#29305;&#24449;&#38598;&#65292;&#21516;&#26102;&#20445;&#25345;&#39640;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Shapley Additive Global Importance (SAGE) value is a theoretically appealing interpretability method that fairly attributes global importance to a model's features. However, its exact calculation requires the computation of the feature's surplus performance contributions over an exponential number of feature sets. This is computationally expensive, particularly because estimating the surplus contributions requires sampling from conditional distributions. Thus, SAGE approximation algorithms only take a fraction of the feature sets into account. We propose $d$-SAGE, a method that accelerates SAGE approximation. $d$-SAGE is motivated by the observation that conditional independencies (CIs) between a feature and the model target imply zero surplus contributions, such that their computation can be skipped. To identify CIs, we leverage causal structure learning (CSL) to infer a graph that encodes (conditional) independencies in the data as $d$-separations. This is computationally more ef
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38745;&#24577;&#27169;&#31946;&#35789;&#34955;&#27169;&#22411;&#65292;&#21487;&#25552;&#20379;&#39044;&#23450;&#20041;&#32500;&#24230;&#30340;&#21477;&#23376;&#23884;&#20837;&#12290;&#35813;&#27169;&#22411;&#22312;&#35821;&#20041;&#25991;&#26412;&#30456;&#20284;&#24615;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#65292;&#24182;&#35201;&#27714;&#20302;&#35745;&#31639;&#36164;&#28304;&#12290;</title><link>http://arxiv.org/abs/2304.03098</link><description>&lt;p&gt;
&#38745;&#24577;&#27169;&#31946;&#35789;&#34955;&#65306;&#19968;&#31181;&#36731;&#37327;&#32423;&#21477;&#23376;&#23884;&#20837;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Static Fuzzy Bag-of-Words: a lightweight sentence embedding algorithm. (arXiv:2304.03098v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03098
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38745;&#24577;&#27169;&#31946;&#35789;&#34955;&#27169;&#22411;&#65292;&#21487;&#25552;&#20379;&#39044;&#23450;&#20041;&#32500;&#24230;&#30340;&#21477;&#23376;&#23884;&#20837;&#12290;&#35813;&#27169;&#22411;&#22312;&#35821;&#20041;&#25991;&#26412;&#30456;&#20284;&#24615;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#65292;&#24182;&#35201;&#27714;&#20302;&#35745;&#31639;&#36164;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23884;&#20837;&#25216;&#26415;&#30340;&#24341;&#20837;&#26174;&#33879;&#25512;&#21160;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#21457;&#23637;&#12290;&#35768;&#22810;&#25552;&#20986;&#30340;&#35299;&#20915;&#26041;&#26696;&#37117;&#26159;&#38024;&#23545;&#21333;&#35789;&#32423;&#21035;&#30340;&#32534;&#30721;&#12290;&#28982;&#32780;&#65292;&#22312;&#36807;&#21435;&#30340;&#20960;&#24180;&#20013;&#65292;&#20986;&#29616;&#20102;&#19968;&#20123;&#26032;&#30340;&#26426;&#21046;&#26469;&#22788;&#29702;&#26356;&#39640;&#23618;&#27425;&#30340;&#20449;&#24687;&#22788;&#29702;&#65292;&#20363;&#22914;&#21477;&#23376;&#21644;&#25991;&#26723;&#32423;&#21035;&#12290;&#26412;&#25991;&#19987;&#38376;&#35752;&#35770;&#21477;&#23376;&#23884;&#20837;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#38745;&#24577;&#27169;&#31946;&#35789;&#34955;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#26159;&#27169;&#31946;&#35789;&#34955;&#26041;&#27861;&#30340;&#19968;&#31181;&#25913;&#36827;&#65292;&#38024;&#23545;&#39044;&#23450;&#20041;&#32500;&#24230;&#25552;&#20379;&#21477;&#23376;&#23884;&#20837;&#12290;SFBoW&#22312;&#35821;&#20041;&#25991;&#26412;&#30456;&#20284;&#24615;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#31454;&#20105;&#21147;&#65292;&#21516;&#26102;&#35201;&#27714;&#20302;&#35745;&#31639;&#36164;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;
The introduction of embedding techniques has pushed forward significantly the Natural Language Processing field. Many of the proposed solutions have been presented for word-level encoding; anyhow, in the last years, new mechanism to treat information at an higher level of aggregation, like at sentence- and document-level, have emerged. With this work we address specifically the sentence embeddings problem, presenting the Static Fuzzy Bag-of-Word model. Our model is a refinement of the Fuzzy Bag-of-Words approach, providing sentence embeddings with a predefined dimension. SFBoW provides competitive performances in Semantic Textual Similarity benchmarks, while requiring low computational resources.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#35889;/&#22270;&#24418;&#20449;&#24687;&#36827;&#34892;&#31070;&#32463;&#32593;&#32476;&#27491;&#21017;&#21270;&#30340;&#26032;&#26041;&#27861;&#65292;&#21363;Fiedler&#27491;&#21017;&#21270;&#12290;&#36890;&#36807;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#24213;&#23618;&#22270;&#30340;Fiedler&#20540;&#20316;&#20026;&#27491;&#21017;&#21270;&#24037;&#20855;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#32467;&#26500;&#21152;&#26435;&#30340; $\text{L}_1$ &#24809;&#32602;&#24182;&#25552;&#20379;&#32479;&#19968;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#30340;&#20998;&#26512;&#65292;&#36825;&#20351;&#24471;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#35768;&#22810;&#25968;&#25454;&#38598;&#19978;&#37117;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.03096</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#30340;&#35889;&#38388;&#38553;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Spectral Gap Regularization of Neural Networks. (arXiv:2304.03096v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03096
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#35889;/&#22270;&#24418;&#20449;&#24687;&#36827;&#34892;&#31070;&#32463;&#32593;&#32476;&#27491;&#21017;&#21270;&#30340;&#26032;&#26041;&#27861;&#65292;&#21363;Fiedler&#27491;&#21017;&#21270;&#12290;&#36890;&#36807;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#24213;&#23618;&#22270;&#30340;Fiedler&#20540;&#20316;&#20026;&#27491;&#21017;&#21270;&#24037;&#20855;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#32467;&#26500;&#21152;&#26435;&#30340; $\text{L}_1$ &#24809;&#32602;&#24182;&#25552;&#20379;&#32479;&#19968;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#30340;&#20998;&#26512;&#65292;&#36825;&#20351;&#24471;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#35768;&#22810;&#25968;&#25454;&#38598;&#19978;&#37117;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;Fiedler&#27491;&#21017;&#21270;&#65292;&#36825;&#26159;&#19968;&#31181;&#21033;&#29992;&#35889;/&#22270;&#24418;&#20449;&#24687;&#23545;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#27491;&#21017;&#21270;&#30340;&#26032;&#26041;&#27861;&#12290;&#29616;&#26377;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#24120;&#24120;&#36890;&#36807;&#20840;&#23616;/&#22343;&#21248;&#22320;&#24809;&#32602;&#26435;&#37325;&#26469;&#23454;&#29616;&#65292;&#24573;&#30053;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#36830;&#36890;&#24615;&#32467;&#26500;&#12290;&#25105;&#20204;&#25552;&#20986;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#24213;&#23618;&#22270;&#30340;Fiedler&#20540;&#20316;&#20026;&#27491;&#21017;&#21270;&#24037;&#20855;&#12290;&#25105;&#20204;&#36890;&#36807;&#35889;&#22270;&#29702;&#35770;&#25552;&#20379;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#29702;&#35770;&#21160;&#26426;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;Fiedler&#20540;&#30340;&#20960;&#20010;&#26377;&#29992;&#23646;&#24615;&#65292;&#20351;&#20854;&#25104;&#20026;&#27491;&#21017;&#21270;&#24037;&#20855;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#36817;&#20284;&#30340;&#21464;&#20998;&#26041;&#27861;&#65292;&#20197;&#20415;&#22312;&#35757;&#32451;&#26399;&#38388;&#26356;&#24555;&#22320;&#35745;&#31639;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#35813;&#26694;&#26550;&#30340;&#21478;&#19968;&#31181;&#24418;&#24335;&#65292;&#36825;&#26159;&#19968;&#31181;&#32467;&#26500;&#21152;&#26435;&#30340; $\text{L}_1$ &#24809;&#32602;&#65292;&#22240;&#27492;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#31232;&#30095;&#24863;&#24212;&#32852;&#31995;&#36215;&#26469;&#12290;&#25105;&#20204;&#36890;&#36807;Rademacher&#22797;&#26434;&#24615;&#20998;&#26512;&#25552;&#20379;&#20102;Fiedler&#27491;&#21017;&#21270;&#30340;&#32479;&#19968;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#12290;&#25105;&#20204;&#23545;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#23454;&#39564;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce Fiedler regularization, a novel approach for regularizing neural networks that utilizes spectral/graphical information. Existing regularization methods often focus on penalizing weights in a global/uniform manner that ignores the connectivity structure of the neural network. We propose to use the Fiedler value of the neural network's underlying graph as a tool for regularization. We provide theoretical motivation for this approach via spectral graph theory. We demonstrate several useful properties of the Fiedler value that make it useful as a regularization tool. We provide an approximate, variational approach for faster computation during training. We provide an alternative formulation of this framework in the form of a structurally weighted $\text{L}_1$ penalty, thus linking our approach to sparsity induction. We provide uniform generalization error bounds for Fiedler regularization via a Rademacher complexity analysis. We performed experiments on datasets that compare F
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#30340;&#33258;&#36866;&#24212;&#23398;&#29983;t&#20998;&#24067;&#26041;&#27861;&#65292;&#22522;&#20110;&#26041;&#27861;&#30340;&#19968;&#33324;&#33258;&#36866;&#24212;&#30697;&#21487;&#20197;&#20351;&#29992;&#24265;&#20215;&#30340;&#25351;&#25968;&#31227;&#21160;&#24179;&#22343;&#20540;&#65288;EMA&#65289;&#26469;&#20272;&#35745;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/2304.03069</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#23398;&#29983;t&#20998;&#24067;&#19982;&#26041;&#27861;&#30697;&#31227;&#21160;&#20272;&#35745;&#22120;&#29992;&#20110;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;
&lt;/p&gt;
&lt;p&gt;
Adaptive Student's t-distribution with method of moments moving estimator for nonstationary time series. (arXiv:2304.03069v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03069
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#30340;&#33258;&#36866;&#24212;&#23398;&#29983;t&#20998;&#24067;&#26041;&#27861;&#65292;&#22522;&#20110;&#26041;&#27861;&#30340;&#19968;&#33324;&#33258;&#36866;&#24212;&#30697;&#21487;&#20197;&#20351;&#29992;&#24265;&#20215;&#30340;&#25351;&#25968;&#31227;&#21160;&#24179;&#22343;&#20540;&#65288;EMA&#65289;&#26469;&#20272;&#35745;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30495;&#23454;&#30340;&#26102;&#38388;&#24207;&#21015;&#36890;&#24120;&#26159;&#38750;&#24179;&#31283;&#30340;&#65292;&#36825;&#24102;&#26469;&#20102;&#27169;&#22411;&#36866;&#24212;&#30340;&#38590;&#39064;&#12290;&#20256;&#32479;&#26041;&#27861;&#22914;GARCH&#20551;&#23450;&#20219;&#24847;&#31867;&#22411;&#30340;&#20381;&#36182;&#24615;&#12290;&#20026;&#20102;&#36991;&#20813;&#36825;&#31181;&#20559;&#24046;&#65292;&#25105;&#20204;&#23558;&#30528;&#30524;&#20110;&#26368;&#36817;&#25552;&#20986;&#30340;&#19981;&#21487;&#30693;&#30340;&#31227;&#21160;&#20272;&#35745;&#22120;&#21746;&#23398;&#65306;&#22312;&#26102;&#38388;$t$&#25214;&#21040;&#20248;&#21270;$F_t=\sum_{\tau&lt;t} (1-\eta)^{t-\tau} \ln(\rho_\theta (x_\tau))$&#31227;&#21160;&#23545;&#25968;&#20284;&#28982;&#30340;&#21442;&#25968;&#65292;&#38543;&#26102;&#38388;&#28436;&#21270;&#12290;&#20363;&#22914;&#65292;&#23427;&#20801;&#35768;&#20351;&#29992;&#24265;&#20215;&#30340;&#25351;&#25968;&#31227;&#21160;&#24179;&#22343;&#20540;&#65288;EMA&#65289;&#26469;&#20272;&#35745;&#21442;&#25968;&#65292;&#20363;&#22914;&#32477;&#23545;&#20013;&#24515;&#30697;$E[|x-\mu|^p]$&#38543;$p\in\mathbb{R}^+$&#30340;&#21464;&#21270;&#32780;&#28436;&#21270;$m_{p,t+1} = m_{p,t} + \eta (|x_t-\mu_t|^p-m_{p,t})$&#12290;&#36825;&#31181;&#22522;&#20110;&#26041;&#27861;&#30340;&#19968;&#33324;&#33258;&#36866;&#24212;&#30697;&#30340;&#24212;&#29992;&#23558;&#21576;&#29616;&#22312;&#23398;&#29983;t&#20998;&#24067;&#19978;&#65292;&#23588;&#20854;&#26159;&#22312;&#32463;&#27982;&#24212;&#29992;&#20013;&#27969;&#34892;&#65292;&#36825;&#37324;&#24212;&#29992;&#20110;DJIA&#20844;&#21496;&#30340;&#23545;&#25968;&#25910;&#30410;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
The real life time series are usually nonstationary, bringing a difficult question of model adaptation. Classical approaches like GARCH assume arbitrary type of dependence. To prevent such bias, we will focus on recently proposed agnostic philosophy of moving estimator: in time $t$ finding parameters optimizing e.g. $F_t=\sum_{\tau&lt;t} (1-\eta)^{t-\tau} \ln(\rho_\theta (x_\tau))$ moving log-likelihood, evolving in time. It allows for example to estimate parameters using inexpensive exponential moving averages (EMA), like absolute central moments $E[|x-\mu|^p]$ evolving with $m_{p,t+1} = m_{p,t} + \eta (|x_t-\mu_t|^p-m_{p,t})$ for one or multiple powers $p\in\mathbb{R}^+$. Application of such general adaptive methods of moments will be presented on Student's t-distribution, popular especially in economical applications, here applied to log-returns of DJIA companies.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25512;&#23548;&#20102;Dirichlet&#38543;&#26426;&#21464;&#37327;&#30340;&#21152;&#26435;&#21644;&#30340;&#38160;&#24615;&#26377;&#38480;&#24046;&#20998;&#30028;&#65292;&#21516;&#26102;&#24212;&#29992;&#20110;&#36125;&#21494;&#26031;bootstrap&#21644;&#22810;&#33218;&#36172;&#21338;&#26426;&#20998;&#26512;&#65292;&#30456;&#23545;&#20110;&#29616;&#26377;&#30340;&#32467;&#26524;&#20855;&#26377;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.03056</link><description>&lt;p&gt;
Dirichlet&#21152;&#26435;&#21644;&#30340;&#38160;&#24615;&#20559;&#24046;&#30028;&#21450;&#20854;&#22312;&#36125;&#21494;&#26031;&#31639;&#27861;&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Sharp Deviations Bounds for Dirichlet Weighted Sums with Application to analysis of Bayesian algorithms. (arXiv:2304.03056v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03056
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25512;&#23548;&#20102;Dirichlet&#38543;&#26426;&#21464;&#37327;&#30340;&#21152;&#26435;&#21644;&#30340;&#38160;&#24615;&#26377;&#38480;&#24046;&#20998;&#30028;&#65292;&#21516;&#26102;&#24212;&#29992;&#20110;&#36125;&#21494;&#26031;bootstrap&#21644;&#22810;&#33218;&#36172;&#21338;&#26426;&#20998;&#26512;&#65292;&#30456;&#23545;&#20110;&#29616;&#26377;&#30340;&#32467;&#26524;&#20855;&#26377;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25512;&#23548;&#20102;Dirichlet&#38543;&#26426;&#21464;&#37327;&#30340;&#21152;&#26435;&#21644;&#30340;&#38160;&#24615;&#26377;&#38480;&#24046;&#20998;&#30028;&#65292;&#36825;&#20123;&#30028;&#22522;&#20110;&#21152;&#26435;Dirichlet&#21644;&#23494;&#24230;&#30340;&#26032;&#30340;&#31215;&#20998;&#34920;&#36798;&#24335;&#65292;&#24182;&#21033;&#29992;&#20960;&#20309;&#21644;&#22797;&#20998;&#26512;&#26041;&#27861;&#24471;&#21040;&#20102;&#19982;&#39640;&#26031;&#31867;&#20284;&#30340;&#36924;&#36817;&#21644;&#21644;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25512;&#24191;&#20102;&#32463;&#20856;&#35770;&#25991;Alfers&#21644;Dinges&#65288;1984&#65289;&#20013;Beta&#20998;&#24067;&#25152;&#24471;&#21040;&#30340;&#31867;&#20284;&#30028;&#65292;&#21516;&#26102;&#20063;&#21487;&#20197;&#30475;&#20316;&#26159;&#38024;&#23545;&#36125;&#21494;&#26031;&#38382;&#39064;&#20013;Sanov&#23450;&#29702;&#30340;&#38160;&#24615;&#26377;&#38480;&#29256;&#26412;&#65292;&#36825;&#19968;&#28857;&#30001;Ganesh&#21644;O'Connell&#65288;1999&#65289;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#21033;&#29992;&#36825;&#20123;&#32467;&#26524;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#23545;Dirichlet&#36807;&#31243;&#21518;&#39564;&#22343;&#20540;&#30340;&#26032;&#30340;&#20559;&#24046;&#30028;&#65292;&#24182;&#36890;&#36807;&#36125;&#21494;&#26031;bootstrap&#24212;&#29992;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#24212;&#29992;&#25105;&#20204;&#30340;&#20272;&#35745;&#32467;&#26524;&#21040;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#30340;Multinomial Thompson Sampling&#65288;TS&#65289;&#31639;&#27861;&#20998;&#26512;&#20013;&#65292;&#26126;&#26174;&#22320;&#25913;&#36827;&#20102;&#29616;&#26377;&#36951;&#25022;&#30340;&#30028;&#38480;&#32780;&#20351;&#23427;&#20204;&#19981;&#20381;&#36182;&#20110;&#38382;&#39064;&#35268;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we derive sharp non-asymptotic deviation bounds for weighted sums of Dirichlet random variables. These bounds are based on a novel integral representation of the density of a weighted Dirichlet sum. This representation allows us to obtain a Gaussian-like approximation for the sum distribution using geometry and complex analysis methods. Our results generalize similar bounds for the Beta distribution obtained in the seminal paper Alfers and Dinges [1984]. Additionally, our results can be considered a sharp non-asymptotic version of the inverse of Sanov's theorem studied by Ganesh and O'Connell [1999] in the Bayesian setting. Based on these results, we derive new deviation bounds for the Dirichlet process posterior means with application to Bayesian bootstrap. Finally, we apply our estimates to the analysis of the Multinomial Thompson Sampling (TS) algorithm in multi-armed bandits and significantly sharpen the existing regret bounds by making them independent of the size of
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#20351;&#29992;&#35299;&#26512;&#30340;&#26041;&#27861;&#35757;&#32451;&#21452;&#23618;ReLU&#32593;&#32476;&#65292;&#30456;&#27604;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#21644;Adam&#20248;&#21270;&#22120;&#33021;&#22815;&#25214;&#21040;&#26356;&#28145;&#30340;&#26368;&#23567;&#20540;&#65292;&#22312;&#22235;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#20013;&#33719;&#24471;&#20102;&#26174;&#33879;&#26356;&#23567;&#30340;&#35757;&#32451;&#25439;&#22833;&#20540;&#65292;&#21516;&#26102;&#35813;&#26041;&#27861;&#36895;&#24230;&#26356;&#24555;&#65292;&#35843;&#21442;&#21442;&#25968;&#26356;&#23569;&#12290;</title><link>http://arxiv.org/abs/2304.02972</link><description>&lt;p&gt;
&#35299;&#26512;&#35757;&#32451;&#21452;&#23618;ReLU&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Training a Two Layer ReLU Network Analytically. (arXiv:2304.02972v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02972
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#20351;&#29992;&#35299;&#26512;&#30340;&#26041;&#27861;&#35757;&#32451;&#21452;&#23618;ReLU&#32593;&#32476;&#65292;&#30456;&#27604;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#21644;Adam&#20248;&#21270;&#22120;&#33021;&#22815;&#25214;&#21040;&#26356;&#28145;&#30340;&#26368;&#23567;&#20540;&#65292;&#22312;&#22235;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#20013;&#33719;&#24471;&#20102;&#26174;&#33879;&#26356;&#23567;&#30340;&#35757;&#32451;&#25439;&#22833;&#20540;&#65292;&#21516;&#26102;&#35813;&#26041;&#27861;&#36895;&#24230;&#26356;&#24555;&#65292;&#35843;&#21442;&#21442;&#25968;&#26356;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#36890;&#24120;&#20351;&#29992;&#21508;&#31181;&#26799;&#24230;&#19979;&#38477;&#30340;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#35757;&#32451;&#65292;&#22914;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#25110;Adam&#20248;&#21270;&#22120;&#12290;&#26368;&#36817;&#30340;&#29702;&#35770;&#30740;&#31350;&#34920;&#26126;&#65292;&#21452;&#23618;ReLU&#32593;&#32476;&#30340;&#20020;&#30028;&#28857;&#65288;&#25439;&#22833;&#26799;&#24230;&#20026;&#38646;&#30340;&#28857;&#65289;&#19981;&#37117;&#26159;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;&#28982;&#32780;&#65292;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23558;&#25506;&#35752;&#19968;&#31181;&#20351;&#29992;ReLU&#28608;&#27963;&#30340;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#21644;&#24179;&#26041;&#25439;&#22833;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20132;&#26367;&#22320;&#22312;&#19968;&#20010;&#23618;&#30340;&#24773;&#20917;&#19979;&#35299;&#26512;&#22320;&#25214;&#21040;&#25439;&#22833;&#20989;&#25968;&#30340;&#20020;&#30028;&#28857;&#65292;&#21516;&#26102;&#20445;&#25345;&#21478;&#19968;&#20010;&#23618;&#21644;&#31070;&#32463;&#20803;&#28608;&#27963;&#27169;&#24335;&#19981;&#21464;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#36825;&#20010;&#31616;&#21333;&#30340;&#31639;&#27861;&#27604;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#25110;Adam&#20248;&#21270;&#22120;&#33021;&#22815;&#25214;&#21040;&#26356;&#28145;&#30340;&#26368;&#23567;&#20540;&#65292;&#22312;&#35780;&#20272;&#30340;&#20116;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#20013;&#26377;&#22235;&#20010;&#33719;&#24471;&#20102;&#26174;&#33879;&#26356;&#23567;&#30340;&#35757;&#32451;&#25439;&#22833;&#20540;&#12290;&#32780;&#19988;&#65292;&#35813;&#26041;&#27861;&#27604;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#26356;&#24555;&#65292;&#20960;&#20046;&#27809;&#26377;&#35843;&#21442;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural networks are usually trained with different variants of gradient descent based optimization algorithms such as stochastic gradient descent or the Adam optimizer. Recent theoretical work states that the critical points (where the gradient of the loss is zero) of two-layer ReLU networks with the square loss are not all local minima. However, in this work we will explore an algorithm for training two-layer neural networks with ReLU-like activation and the square loss that alternatively finds the critical points of the loss function analytically for one layer while keeping the other layer and the neuron activation pattern fixed. Experiments indicate that this simple algorithm can find deeper optima than Stochastic Gradient Descent or the Adam optimizer, obtaining significantly smaller training loss values on four out of the five real datasets evaluated. Moreover, the method is faster than the gradient descent methods and has virtually no tuning parameters.
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;RAID&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#22810;&#20803;&#21160;&#24577;&#36807;&#31243;&#20013;&#26816;&#27979;&#24322;&#24120;&#34892;&#20026;&#65292;&#20855;&#26377;&#36866;&#24212;&#38750;&#24179;&#31283;&#25928;&#24212;&#12289;&#19981;&#38656;&#25913;&#21464;&#29616;&#26377;&#36807;&#31243;&#33258;&#21160;&#21270;&#22522;&#30784;&#35774;&#26045;&#31561;&#29305;&#28857;&#65292;&#21487;&#22312;&#19981;&#21516;&#39046;&#22495;&#39640;&#24230;&#37096;&#32626;&#65292;&#24182;&#36890;&#36807;&#23454;&#38469;&#25968;&#25454;&#26696;&#20363;&#30740;&#31350;&#35777;&#26126;&#20854;&#25913;&#36827;&#30340;&#26816;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.02947</link><description>&lt;p&gt;
&#23454;&#26102;&#29289;&#32852;&#32593;&#31995;&#32479;&#20013;&#26032;&#39062;&#24615;&#26816;&#27979;&#30340;&#21487;&#36866;&#24212;&#21644;&#21487;&#35299;&#37322;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Adaptable and Interpretable Framework for Novelty Detection in Real-Time IoT Systems. (arXiv:2304.02947v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02947
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;RAID&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#22810;&#20803;&#21160;&#24577;&#36807;&#31243;&#20013;&#26816;&#27979;&#24322;&#24120;&#34892;&#20026;&#65292;&#20855;&#26377;&#36866;&#24212;&#38750;&#24179;&#31283;&#25928;&#24212;&#12289;&#19981;&#38656;&#25913;&#21464;&#29616;&#26377;&#36807;&#31243;&#33258;&#21160;&#21270;&#22522;&#30784;&#35774;&#26045;&#31561;&#29305;&#28857;&#65292;&#21487;&#22312;&#19981;&#21516;&#39046;&#22495;&#39640;&#24230;&#37096;&#32626;&#65292;&#24182;&#36890;&#36807;&#23454;&#38469;&#25968;&#25454;&#26696;&#20363;&#30740;&#31350;&#35777;&#26126;&#20854;&#25913;&#36827;&#30340;&#26816;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;Real-time Adaptive and Interpretable Detection (RAID)&#31639;&#27861;&#30340;&#26032;&#39062;&#26041;&#27861;&#65292;&#23427;&#35299;&#20915;&#20102;&#22810;&#20803;&#21160;&#24577;&#36807;&#31243;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#65292;&#36825;&#20123;&#26041;&#27861;&#20165;&#38480;&#20110;&#22312;&#27169;&#22411;&#35757;&#32451;&#26465;&#20214;&#33539;&#22260;&#20869;&#26816;&#27979;&#24322;&#24120;&#12290;RAID&#31639;&#27861;&#36866;&#24212;&#20102;&#38750;&#24179;&#31283;&#25928;&#24212;&#65292;&#22914;&#25968;&#25454;&#28418;&#31227;&#21644;&#21464;&#21270;&#28857;&#65292;&#22312;&#27169;&#22411;&#24320;&#21457;&#26399;&#38388;&#21487;&#33021;&#27809;&#26377;&#36827;&#34892;&#36134;&#21153;&#65292;&#20174;&#32780;&#24310;&#38271;&#20102;&#26381;&#21153;&#23551;&#21629;&#12290;&#22522;&#20110;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#30340;&#21160;&#24577;&#27169;&#22411;&#22788;&#29702;&#31995;&#32479;&#20013;&#30340;&#24322;&#24120;&#34892;&#20026;&#26816;&#27979;&#21644;&#22522;&#20110;&#33258;&#36866;&#24212;&#36807;&#31243;&#38480;&#21046;&#30340;&#26681;&#26412;&#21407;&#22240;&#38548;&#31163;&#12290;RAID&#31639;&#27861;&#19981;&#38656;&#35201;&#26356;&#25913;&#29616;&#26377;&#30340;&#36807;&#31243;&#33258;&#21160;&#21270;&#22522;&#30784;&#35774;&#26045;&#65292;&#22240;&#27492;&#21487;&#22312;&#19981;&#21516;&#39046;&#22495;&#39640;&#24230;&#37096;&#32626;&#12290;&#20004;&#20010;&#28041;&#21450;&#23454;&#38469;&#21160;&#24577;&#31995;&#32479;&#25968;&#25454;&#30340;&#26696;&#20363;&#30740;&#31350;&#35777;&#26126;&#20102;RAID&#31639;&#27861;&#30340;&#22909;&#22788;&#65292;&#21253;&#25324;&#21464;&#26356;&#28857;&#36866;&#24212;&#24615;&#12289;&#26681;&#26412;&#21407;&#22240;&#38548;&#31163;&#21644;&#25913;&#36827;&#30340;&#26816;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents the Real-time Adaptive and Interpretable Detection (RAID) algorithm. The novel approach addresses the limitations of state-of-the-art anomaly detection methods for multivariate dynamic processes, which are restricted to detecting anomalies within the scope of the model training conditions. The RAID algorithm adapts to non-stationary effects such as data drift and change points that may not be accounted for during model development, resulting in prolonged service life. A dynamic model based on joint probability distribution handles anomalous behavior detection in a system and the root cause isolation based on adaptive process limits. RAID algorithm does not require changes to existing process automation infrastructures, making it highly deployable across different domains. Two case studies involving real dynamic system data demonstrate the benefits of the RAID algorithm, including change point adaptation, root cause isolation, and improved detection accuracy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#26041;&#27861;&#65292;&#23545;&#39640;&#32500;&#36229;&#32479;&#35745;&#29305;&#24449;&#19979;&#30340;&#25968;&#25454;&#36827;&#34892;&#20998;&#31867;&#65292;&#24182;&#20998;&#26512;&#20102;&#27491;&#21017;&#21270;&#21644;&#20998;&#24067;&#23610;&#24230;&#21442;&#25968;&#23545;&#20998;&#31867;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2304.02912</link><description>&lt;p&gt;
&#39640;&#32500;&#36229;&#32479;&#35745;&#29305;&#24449;&#30340;&#20998;&#31867;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Classification of Superstatistical Features in High Dimensions. (arXiv:2304.02912v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02912
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#26041;&#27861;&#65292;&#23545;&#39640;&#32500;&#36229;&#32479;&#35745;&#29305;&#24449;&#19979;&#30340;&#25968;&#25454;&#36827;&#34892;&#20998;&#31867;&#65292;&#24182;&#20998;&#26512;&#20102;&#27491;&#21017;&#21270;&#21644;&#20998;&#24067;&#23610;&#24230;&#21442;&#25968;&#23545;&#20998;&#31867;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#36890;&#36807;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#26041;&#27861;&#65292;&#23545;&#20855;&#26377;&#19968;&#33324;&#20013;&#24515;&#28857;&#30340;&#20004;&#20010;&#25968;&#25454;&#20113;&#30340;&#28151;&#21512;&#36827;&#34892;&#20102;&#23398;&#20064;&#65292;&#20551;&#35774;&#20855;&#26377;&#36890;&#29992;&#30340;&#20984;&#25439;&#22833;&#21644;&#20984;&#27491;&#21017;&#21270;&#12290;&#27599;&#20010;&#25968;&#25454;&#20113;&#26159;&#36890;&#36807;&#20174;&#21487;&#33021;&#26159;&#19981;&#21487;&#25968;&#30340;&#39640;&#26031;&#20998;&#24067;&#21472;&#21152;&#20013;&#36827;&#34892;&#37319;&#26679;&#26469;&#33719;&#24471;&#30340;&#65292;&#20854;&#26041;&#24046;&#20855;&#26377;&#36890;&#29992;&#30340;&#27010;&#29575;&#23494;&#24230;$\varrho$&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#28085;&#30422;&#20102;&#22823;&#37327;&#30340;&#25968;&#25454;&#20998;&#24067;&#65292;&#21253;&#25324;&#27809;&#26377;&#21327;&#26041;&#24046;&#30340;&#24130;&#24459;&#23614;&#37096;&#20998;&#24067;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#25152;&#24471;&#20272;&#35745;&#22120;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#20998;&#26512;&#20102;&#27491;&#21017;&#21270;&#30340;&#20316;&#29992;&#20197;&#21450;&#20998;&#31163;&#36716;&#25442;&#19982;&#20998;&#24067;&#23610;&#24230;&#21442;&#25968;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We characterise the learning of a mixture of two clouds of data points with generic centroids via empirical risk minimisation in the high dimensional regime, under the assumptions of generic convex loss and convex regularisation. Each cloud of data points is obtained by sampling from a possibly uncountable superposition of Gaussian distributions, whose variance has a generic probability density $\varrho$. Our analysis covers therefore a large family of data distributions, including the case of power-law-tailed distributions with no covariance. We study the generalisation performance of the obtained estimator, we analyse the role of regularisation, and the dependence of the separability transition on the distribution scale parameters.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#37325;&#23614;&#37096;&#27491;&#21017;&#21270;&#30340;&#25216;&#26415;&#65292;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#36890;&#36807;&#26126;&#30830;&#25552;&#20513;&#26356;&#37325;&#30340;&#37325;&#23614;&#35889;&#26469;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;&#19982;&#26631;&#20934;&#27491;&#21017;&#21270;&#25216;&#26415;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26174;&#30528;&#30340;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2304.02911</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#37325;&#23614;&#37096;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Heavy-Tailed Regularization of Weight Matrices in Deep Neural Networks. (arXiv:2304.02911v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02911
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#37325;&#23614;&#37096;&#27491;&#21017;&#21270;&#30340;&#25216;&#26415;&#65292;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#36890;&#36807;&#26126;&#30830;&#25552;&#20513;&#26356;&#37325;&#30340;&#37325;&#23614;&#35889;&#26469;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;&#19982;&#26631;&#20934;&#27491;&#21017;&#21270;&#25216;&#26415;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26174;&#30528;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25104;&#21151;&#21644;&#26174;&#33879;&#30340;&#27867;&#21270;&#33021;&#21147;&#32972;&#21518;&#30340;&#21407;&#22240;&#20173;&#28982;&#26159;&#19968;&#20010;&#24040;&#22823;&#30340;&#25361;&#25112;&#12290;&#20174;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#24471;&#21040;&#30340;&#26368;&#26032;&#20449;&#24687;&#65292;&#29305;&#21035;&#26159;&#28041;&#21450;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#26435;&#37325;&#30697;&#38453;&#30340;&#35889;&#20998;&#26512;&#30340;&#20449;&#24687;&#65292;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#32447;&#32034;&#12290;&#19968;&#20010;&#20851;&#38190;&#21457;&#29616;&#26159;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#24615;&#33021;&#19982;&#20854;&#26435;&#37325;&#30697;&#38453;&#30340;&#35889;&#30340;&#37325;&#23614;&#31243;&#24230;&#30456;&#20851;&#12290;&#20026;&#20102;&#21033;&#29992;&#36825;&#19968;&#21457;&#29616;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#31216;&#20026;&#37325;&#23614;&#37096;&#27491;&#21017;&#21270;&#65292;&#36890;&#36807;&#27491;&#21017;&#21270;&#26126;&#30830;&#25552;&#20513;&#26435;&#37325;&#30697;&#38453;&#20013;&#26356;&#37325;&#30340;&#37325;&#23614;&#35889;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#37319;&#29992;&#21152;&#26435;&#38463;&#23572;&#27861;&#21644;&#31283;&#23450;&#31209;&#20316;&#20026;&#24809;&#32602;&#39033;&#65292;&#20004;&#32773;&#37117;&#21487;&#24494;&#20998;&#65292;&#20174;&#32780;&#21487;&#20197;&#30452;&#25509;&#35745;&#31639;&#23427;&#20204;&#30340;&#26799;&#24230;&#12290;&#20026;&#20102;&#36991;&#20813;&#36807;&#24230;&#27491;&#21017;&#21270;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#20004;&#31181;&#24809;&#32602;&#20989;&#25968;&#30340;&#21464;&#20307;&#12290;&#28982;&#21518;&#65292;&#37319;&#29992;&#36125;&#21494;&#26031;&#32479;&#35745;&#35270;&#35282;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#37325;&#23614;&#37096;&#27491;&#21017;&#21270;&#30340;&#27010;&#29575;&#35299;&#37322;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;&#20854;&#25928;&#26524;&#29702;&#35299;&#20026;&#26435;&#37325;&#30697;&#38453;&#30340;&#20808;&#39564;&#12290;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;&#19982;&#26631;&#20934;&#27491;&#21017;&#21270;&#25216;&#26415;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26126;&#26174;&#25552;&#39640;&#20102;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unraveling the reasons behind the remarkable success and exceptional generalization capabilities of deep neural networks presents a formidable challenge. Recent insights from random matrix theory, specifically those concerning the spectral analysis of weight matrices in deep neural networks, offer valuable clues to address this issue. A key finding indicates that the generalization performance of a neural network is associated with the degree of heavy tails in the spectrum of its weight matrices. To capitalize on this discovery, we introduce a novel regularization technique, termed Heavy-Tailed Regularization, which explicitly promotes a more heavy-tailed spectrum in the weight matrix through regularization. Firstly, we employ the Weighted Alpha and Stable Rank as penalty terms, both of which are differentiable, enabling the direct calculation of their gradients. To circumvent over-regularization, we introduce two variations of the penalty function. Then, adopting a Bayesian statistics
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#23545;&#31216;&#24615;&#22312;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20013;&#23454;&#29616;&#39640;&#25928;MCMC&#37319;&#26679;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#31070;&#32463;&#20803;&#21487;&#20114;&#25442;&#24615;&#21644;&#26576;&#20123;&#28608;&#27963;&#20989;&#25968;&#24341;&#36215;&#30340;&#23545;&#31216;&#24615;&#22312;&#21442;&#25968;&#21518;&#39564;&#30340;&#22810;&#27169;&#24577;&#24615;&#20013;&#25214;&#21040;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2304.02902</link><description>&lt;p&gt;
&#21033;&#29992;&#23545;&#31216;&#24615;&#22312;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20013;&#23454;&#29616;&#39640;&#25928;MCMC&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Towards Efficient MCMC Sampling in Bayesian Neural Networks by Exploiting Symmetry. (arXiv:2304.02902v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02902
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#23545;&#31216;&#24615;&#22312;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20013;&#23454;&#29616;&#39640;&#25928;MCMC&#37319;&#26679;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#31070;&#32463;&#20803;&#21487;&#20114;&#25442;&#24615;&#21644;&#26576;&#20123;&#28608;&#27963;&#20989;&#25968;&#24341;&#36215;&#30340;&#23545;&#31216;&#24615;&#22312;&#21442;&#25968;&#21518;&#39564;&#30340;&#22810;&#27169;&#24577;&#24615;&#20013;&#25214;&#21040;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#39640;&#32500;&#65292;&#24378;&#22810;&#27169;&#24577;&#21442;&#25968;&#21518;&#39564;&#23494;&#24230;&#26223;&#35266;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#21487;&#20197;&#28176;&#36827;&#24615;&#22320;&#24674;&#22797;&#30495;&#23454;&#21518;&#39564;&#65292;&#20294;&#22240;&#20854;&#22312;&#22823;&#35268;&#27169;&#29616;&#20195;&#26550;&#26500;&#19978;&#34987;&#35748;&#20026;&#26159;&#20195;&#20215;&#39640;&#26114;&#32780;&#38590;&#20197;&#24212;&#29992;&#12290;&#32780;&#23616;&#37096;&#26041;&#27861;&#65292;&#20316;&#20026;&#19968;&#31181;&#27969;&#34892;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#32858;&#28966;&#20110;&#21487;&#36890;&#36807;&#21487;&#31215;&#20989;&#25968;&#36817;&#20284;&#30340;&#29305;&#23450;&#21442;&#25968;&#21306;&#22495;&#12290;&#34429;&#28982;&#36825;&#20123;&#26041;&#27861;&#24120;&#24120;&#33021;&#22815;&#20135;&#29983;&#28385;&#24847;&#30340;&#23454;&#35777;&#32467;&#26524;&#65292;&#20294;&#23427;&#20204;&#26410;&#33021;&#32771;&#34385;&#21442;&#25968;&#21518;&#39564;&#30340;&#22810;&#27169;&#24577;&#24615;&#12290;&#26412;&#25991;&#35748;&#20026;&#65292;&#21487;&#20197;&#36890;&#36807;&#21033;&#29992;&#21518;&#39564;&#26223;&#35266;&#20013;&#30340;&#23545;&#31216;&#24615;&#26469;&#32531;&#35299;&#31934;&#30830;&#20294;&#20195;&#20215;&#26114;&#36149;&#21644;&#24265;&#20215;&#20294;&#19981;&#31934;&#30830;&#26041;&#27861;&#20043;&#38388;&#30340;&#22256;&#22659;&#12290;&#36825;&#31181;&#23545;&#31216;&#24615;&#30001;&#31070;&#32463;&#20803;&#21487;&#20114;&#25442;&#24615;&#21644;&#26576;&#20123;&#28608;&#27963;&#20989;&#25968;&#24341;&#36215;&#65292;&#22312;&#19981;&#21516;&#30340;&#21442;&#25968;&#20540;&#23548;&#33268;&#30456;&#21516;&#30340;&#21151;&#33021;&#36755;&#20986;&#20540;&#12290;&#25105;&#20204;&#29702;&#35770;&#19978;&#35777;&#26126;&#21518;&#39564;&#39044;&#27979;&#21487;&#20197;&#21033;&#29992;&#23545;&#31216;&#24615;&#34987;&#39640;&#25928;&#22320;&#35745;&#31639;&#21644;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian inference in deep neural networks is challenging due to the high-dimensional, strongly multi-modal parameter posterior density landscape. Markov chain Monte Carlo approaches asymptotically recover the true posterior but are considered prohibitively expensive for large modern architectures. Local methods, which have emerged as a popular alternative, focus on specific parameter regions that can be approximated by functions with tractable integrals. While these often yield satisfactory empirical results, they fail, by definition, to account for the multi-modality of the parameter posterior. In this work, we argue that the dilemma between exact-but-unaffordable and cheap-but-inexact approaches can be mitigated by exploiting symmetries in the posterior landscape. Such symmetries, induced by neuron interchangeability and certain activation functions, manifest in different parameter values leading to the same functional output value. We show theoretically that the posterior predictiv
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21464;&#22797;&#26434;&#24230;&#21152;&#26435;&#35843;&#33410; Gibbs &#37319;&#26679;&#22120;&#65292;&#29992;&#20110;&#36125;&#21494;&#26031;&#21464;&#37327;&#36873;&#25321;&#65292;&#21487;&#20197;&#38477;&#20302;&#27599;&#20010;MCMC&#36845;&#20195;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#26377;&#38480;&#30340;&#36845;&#20195;&#27425;&#25968;&#20869;&#25511;&#21046;&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#12290;</title><link>http://arxiv.org/abs/2304.02899</link><description>&lt;p&gt;
&#21464;&#22797;&#26434;&#24230;&#21152;&#26435;&#35843;&#33410; Gibbs &#37319;&#26679;&#29992;&#20110;&#36125;&#21494;&#26031;&#21464;&#37327;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Variable-Complexity Weighted-Tempered Gibbs Samplers for Bayesian Variable Selection. (arXiv:2304.02899v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02899
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21464;&#22797;&#26434;&#24230;&#21152;&#26435;&#35843;&#33410; Gibbs &#37319;&#26679;&#22120;&#65292;&#29992;&#20110;&#36125;&#21494;&#26031;&#21464;&#37327;&#36873;&#25321;&#65292;&#21487;&#20197;&#38477;&#20302;&#27599;&#20010;MCMC&#36845;&#20195;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#26377;&#38480;&#30340;&#36845;&#20195;&#27425;&#25968;&#20869;&#25511;&#21046;&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;Jankowiak&#24341;&#20837;&#20102;&#23376;&#38598;&#21152;&#26435;&#35843;&#33410; Gibbs &#37319;&#26679;&#22120;&#65288;wTGS&#65289;&#65292;&#29992;&#20110;&#22312;&#39640;&#32500;&#24212;&#29992;&#31243;&#24207;&#20013;&#38477;&#20302;&#27599;&#20010;MCMC&#36845;&#20195;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#20854;&#20013;&#21518;&#39564;&#21253;&#21547;&#27010;&#29575;&#65288;PIP&#65289;&#30340;&#31934;&#30830;&#35745;&#31639;&#24182;&#19981;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#19982;&#35813;&#37319;&#26679;&#22120;&#30456;&#20851;&#30340;Rao-Backwellized&#20272;&#35745;&#22120;&#20855;&#26377;&#39640;&#26041;&#24046;&#65292;&#22240;&#20026;&#20449;&#21495;&#32500;&#24230;&#19982;&#26465;&#20214;PIP&#20272;&#35745;&#25968;&#20043;&#27604;&#24456;&#22823;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#26032;&#30340;&#23376;&#38598;&#21152;&#26435;&#35843;&#33410; Gibbs &#37319;&#26679;&#22120;&#65288;wTGS&#65289;&#65292;&#20854;&#20013;&#27599;&#20010;MCMC&#36845;&#20195;&#20013;&#21487;&#39044;&#26399;&#30340;&#26465;&#20214;PIP&#35745;&#31639;&#25968;&#37327;&#21487;&#20197;&#36828;&#23567;&#20110;&#20449;&#21495;&#32500;&#24230;&#12290;&#19982;&#23376;&#38598;wTGS&#21644;wTGS&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#37319;&#26679;&#22120;&#20855;&#26377;&#21487;&#21464;&#30340;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#22312;&#26377;&#38480;&#30340;&#36845;&#20195;&#27425;&#25968; $T$ &#19978;&#25552;&#20379;&#20102;&#19982;&#35813;&#37319;&#26679;&#22120;&#20851;&#32852;&#30340;Rao-Blackwellized&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#19978;&#38480;&#65292;&#24182;&#23637;&#31034;&#20102;&#35813;&#26041;&#24046;&#20026; $O\big(\big(\frac{P}{S}\big)^2 \frac{\log T}{T}\big)$&#65292;&#20854;&#20013; $\frac{P}{S}$ &#26159;&#26465;&#20214;PIP&#20272;&#35745;&#25968;&#21644;&#20449;&#21495;&#32500;&#24230;&#20043;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
Subset weighted-Tempered Gibbs Sampler (wTGS) has been recently introduced by Jankowiak to reduce the computation complexity per MCMC iteration in high-dimensional applications where the exact calculation of the posterior inclusion probabilities (PIP) is not essential. However, the Rao-Backwellized estimator associated with this sampler has a high variance as the ratio between the signal dimension and the number of conditional PIP estimations is large. In this paper, we design a new subset weighted-Tempered Gibbs Sampler (wTGS) where the expected number of computations of conditional PIPs per MCMC iteration can be much smaller than the signal dimension. Different from the subset wTGS and wTGS, our sampler has a variable complexity per MCMC iteration. We provide an upper bound on the variance of an associated Rao-Blackwellized estimator for this sampler at a finite number of iterations, $T$, and show that the variance is $O\big(\big(\frac{P}{S}\big)^2 \frac{\log T}{T}\big)$ for a given 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38598;&#25104;&#23398;&#20064;&#21644;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#30340;&#24212;&#29992;&#65292;&#38024;&#23545;&#31867;&#21035;&#19981;&#24179;&#34913;&#38382;&#39064;&#65292;&#36890;&#36807;&#35745;&#31639;&#35780;&#20272;&#65292;&#25214;&#21040;&#20102;&#26368;&#26377;&#25928;&#30340;&#32452;&#21512;&#12290;</title><link>http://arxiv.org/abs/2304.02858</link><description>&lt;p&gt;
&#38754;&#21521;&#31867;&#21035;&#19981;&#22343;&#38382;&#39064;&#30340;&#38598;&#25104;&#23398;&#20064;&#21644;&#25968;&#25454;&#22686;&#24378;&#27169;&#22411;&#32508;&#36848;&#65306;&#32452;&#21512;&#12289;&#23454;&#29616;&#21644;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
A review of ensemble learning and data augmentation models for class imbalanced problems: combination, implementation and evaluation. (arXiv:2304.02858v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02858
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38598;&#25104;&#23398;&#20064;&#21644;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#30340;&#24212;&#29992;&#65292;&#38024;&#23545;&#31867;&#21035;&#19981;&#24179;&#34913;&#38382;&#39064;&#65292;&#36890;&#36807;&#35745;&#31639;&#35780;&#20272;&#65292;&#25214;&#21040;&#20102;&#26368;&#26377;&#25928;&#30340;&#32452;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#31867;&#38382;&#39064;&#20013;&#30340;&#31867;&#21035;&#19981;&#24179;&#34913;&#65288;CI&#65289;&#26159;&#25351;&#23646;&#20110;&#19968;&#20010;&#31867;&#30340;&#35266;&#27979;&#20540;&#25968;&#37327;&#20302;&#20110;&#20854;&#20182;&#31867;&#30340;&#25968;&#37327;&#12290;&#38598;&#25104;&#23398;&#20064;&#32467;&#21512;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#24050;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#35299;&#20915;&#31867;&#21035;&#19981;&#24179;&#34913;&#38382;&#39064;&#12290;&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#37324;&#65292;&#19968;&#20123;&#31574;&#30053;&#24050;&#32463;&#34987;&#24212;&#29992;&#20110;&#22686;&#24378;&#38598;&#25104;&#23398;&#20064;&#21644;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#65292;&#21516;&#26102;&#36824;&#24320;&#21457;&#20102;&#19968;&#20123;&#26032;&#26041;&#27861;&#65292;&#22914;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#12290;&#26412;&#25991;&#23545;&#29992;&#20110;&#35299;&#20915;&#22522;&#20934;CI&#38382;&#39064;&#30340;&#25968;&#25454;&#22686;&#24378;&#21644;&#38598;&#25104;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#35745;&#31639;&#35780;&#20272;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#35780;&#20272;CI&#38382;&#39064;&#30340;10&#20010;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#21644;10&#20010;&#38598;&#25104;&#23398;&#20064;&#26041;&#27861;&#30340;&#36890;&#29992;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#35782;&#21035;&#25552;&#39640;&#20998;&#31867;&#25928;&#26524;&#26368;&#26377;&#25928;&#30340;&#32452;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Class imbalance (CI) in classification problems arises when the number of observations belonging to one class is lower than the other classes. Ensemble learning that combines multiple models to obtain a robust model has been prominently used with data augmentation methods to address class imbalance problems. In the last decade, a number of strategies have been added to enhance ensemble learning and data augmentation methods, along with new methods such as generative adversarial networks (GANs). A combination of these has been applied in many studies, but the true rank of different combinations would require a computational review. In this paper, we present a computational review to evaluate data augmentation and ensemble learning methods used to address prominent benchmark CI problems. We propose a general framework that evaluates 10 data augmentation and 10 ensemble learning methods for CI problems. Our objective was to identify the most effective combination for improving classificat
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#31867;&#26041;&#27861;&#65292;&#29992;&#20110;&#25552;&#39640;&#40065;&#26834;&#24615;&#65292;&#20943;&#23569;&#26631;&#31614;&#22122;&#22768;&#30340;&#24433;&#21709;&#65292;&#20854;&#22522;&#20110;&#27491;&#24577;&#20998;&#24067;&#65292;&#24182;&#21487;&#36890;&#36807;&#26368;&#23567;&#21270;&#36127;&#23545;&#25968;&#20284;&#28982;&#26469;&#23398;&#20064;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/2304.02849</link><description>&lt;p&gt;
&#20998;&#31867;&#20013;&#24322;&#26041;&#24046;&#26631;&#31614;&#22122;&#22768;&#30340;&#36923;&#36753;&#27491;&#24577;&#20284;&#28982;
&lt;/p&gt;
&lt;p&gt;
Logistic-Normal Likelihoods for Heteroscedastic Label Noise in Classification. (arXiv:2304.02849v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02849
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#31867;&#26041;&#27861;&#65292;&#29992;&#20110;&#25552;&#39640;&#40065;&#26834;&#24615;&#65292;&#20943;&#23569;&#26631;&#31614;&#22122;&#22768;&#30340;&#24433;&#21709;&#65292;&#20854;&#22522;&#20110;&#27491;&#24577;&#20998;&#24067;&#65292;&#24182;&#21487;&#36890;&#36807;&#26368;&#23567;&#21270;&#36127;&#23545;&#25968;&#20284;&#28982;&#26469;&#23398;&#20064;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22238;&#24402;&#20013;&#20272;&#35745;&#24322;&#26041;&#24046;&#26631;&#31614;&#22122;&#22768;&#30340;&#19968;&#31181;&#33258;&#28982;&#26041;&#27861;&#26159;&#23558;&#35266;&#27979;&#21040;&#30340;&#65288;&#21487;&#33021;&#24102;&#26377;&#22122;&#22768;&#30340;&#65289;&#30446;&#26631;&#24314;&#27169;&#20026;&#19968;&#20010;&#27491;&#24577;&#20998;&#24067;&#30340;&#26679;&#26412;&#65292;&#20854;&#21442;&#25968;&#21487;&#20197;&#36890;&#36807;&#26368;&#23567;&#21270;&#36127;&#23545;&#25968;&#20284;&#28982;&#26469;&#23398;&#20064;&#12290;&#35813;&#25439;&#22833;&#20855;&#26377;&#26399;&#26395;&#30340;&#25439;&#22833;&#34928;&#20943;&#29305;&#24615;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#38477;&#20302;&#39640;&#35823;&#24046;&#31034;&#20363;&#30340;&#36129;&#29486;&#12290;&#30452;&#35266;&#22320;&#35828;&#65292;&#36825;&#31181;&#34892;&#20026;&#21487;&#20197;&#36890;&#36807;&#20943;&#23569;&#36807;&#25311;&#21512;&#26469;&#25552;&#39640;&#23545;&#26631;&#31614;&#22122;&#22768;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#36825;&#31181;&#31616;&#21333;&#19988;&#27010;&#29575;&#21270;&#26041;&#27861;&#22312;&#20998;&#31867;&#20013;&#30340;&#25193;&#23637;&#65292;&#20855;&#26377;&#30456;&#21516;&#30340;&#26399;&#26395;&#25439;&#22833;&#34928;&#20943;&#29305;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#27979;&#37327;&#20854;&#23545;&#20998;&#31867;&#20013;&#26631;&#31614;&#22122;&#22768;&#30340;&#40065;&#26834;&#24615;&#26469;&#35780;&#20272;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#21551;&#21457;&#24615;&#30340;&#23454;&#39564;&#65292;&#25506;&#32034;&#20102;&#35813;&#26041;&#27861;&#30340;&#20869;&#37096;&#24037;&#20316;&#21407;&#29702;&#65292;&#21253;&#25324;&#23545;&#36229;&#21442;&#25968;&#30340;&#25935;&#24863;&#24615;&#65292;&#28040;&#34701;&#30740;&#31350;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
A natural way of estimating heteroscedastic label noise in regression is to model the observed (potentially noisy) target as a sample from a normal distribution, whose parameters can be learned by minimizing the negative log-likelihood. This loss has desirable loss attenuation properties, as it can reduce the contribution of high-error examples. Intuitively, this behavior can improve robustness against label noise by reducing overfitting. We propose an extension of this simple and probabilistic approach to classification that has the same desirable loss attenuation properties. We evaluate the effectiveness of the method by measuring its robustness against label noise in classification. We perform enlightening experiments exploring the inner workings of the method, including sensitivity to hyperparameters, ablation studies, and more.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#21098;&#26525;&#26041;&#27861;&#65306;&#36890;&#36807;&#23545;&#40784;&#35757;&#32451;&#21160;&#24577;&#26469;&#25552;&#39640;&#21098;&#26525;&#25928;&#26524;&#65292;&#20855;&#20307;&#26469;&#35828;&#23601;&#26159;&#21098;&#21435;&#23545;NTK&#39057;&#35889;&#24433;&#21709;&#26368;&#23567;&#30340;&#36830;&#25509;&#12290;&#37319;&#29992;&#36825;&#31181;&#26041;&#27861;&#26377;&#21161;&#20110;&#32500;&#25345;NTK&#39057;&#35889;&#65292;&#20174;&#32780;&#23558;&#35757;&#32451;&#21160;&#24577;&#21644;&#20854;&#23494;&#38598;&#23545;&#24212;&#29289;&#30340;&#35757;&#32451;&#21160;&#24577;&#23545;&#40784;&#12290;</title><link>http://arxiv.org/abs/2304.02840</link><description>&lt;p&gt;
NTK-SAP: &#36890;&#36807;&#23545;&#40784;&#35757;&#32451;&#21160;&#24577;&#26469;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#21098;&#26525;
&lt;/p&gt;
&lt;p&gt;
NTK-SAP: Improving neural network pruning by aligning training dynamics. (arXiv:2304.02840v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02840
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#21098;&#26525;&#26041;&#27861;&#65306;&#36890;&#36807;&#23545;&#40784;&#35757;&#32451;&#21160;&#24577;&#26469;&#25552;&#39640;&#21098;&#26525;&#25928;&#26524;&#65292;&#20855;&#20307;&#26469;&#35828;&#23601;&#26159;&#21098;&#21435;&#23545;NTK&#39057;&#35889;&#24433;&#21709;&#26368;&#23567;&#30340;&#36830;&#25509;&#12290;&#37319;&#29992;&#36825;&#31181;&#26041;&#27861;&#26377;&#21161;&#20110;&#32500;&#25345;NTK&#39057;&#35889;&#65292;&#20174;&#32780;&#23558;&#35757;&#32451;&#21160;&#24577;&#21644;&#20854;&#23494;&#38598;&#23545;&#24212;&#29289;&#30340;&#35757;&#32451;&#21160;&#24577;&#23545;&#40784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35757;&#32451;&#20043;&#21069;&#21098;&#26525;&#31070;&#32463;&#32593;&#32476;&#22240;&#20854;&#20943;&#23569;&#35757;&#32451;&#26102;&#38388;&#21644;&#23384;&#20648;&#31354;&#38388;&#30340;&#28508;&#21147;&#32780;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#20854;&#20013;&#19968;&#31181;&#27969;&#34892;&#30340;&#26041;&#27861;&#26159;&#22522;&#20110;&#26576;&#31181;&#24230;&#37327;&#23545;&#36830;&#25509;&#36827;&#34892;&#21098;&#26525;&#65292;&#20294;&#26159;&#20160;&#20040;&#24230;&#37327;&#26159;&#26368;&#22909;&#30340;&#36873;&#25321;&#36824;&#19981;&#23436;&#20840;&#28165;&#26970;&#12290;&#31070;&#32463;&#20999;&#21521;&#26680;&#65288;NTK&#65289;&#29702;&#35770;&#30340;&#26368;&#26032;&#36827;&#23637;&#34920;&#26126;&#65292;&#36275;&#22815;&#22823;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#19982;NTK&#30340;&#39057;&#35889;&#23494;&#20999;&#30456;&#20851;&#12290;&#22312;&#27492;&#21457;&#29616;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#24314;&#35758;&#21098;&#26525;&#37027;&#20123;&#23545;NTK&#39057;&#35889;&#24433;&#21709;&#26368;&#23567;&#30340;&#36830;&#25509;&#12290;&#36825;&#31181;&#26041;&#27861;&#26377;&#21161;&#20110;&#32500;&#25345;NTK&#39057;&#35889;&#65292;&#36825;&#21487;&#33021;&#26377;&#21161;&#20110;&#23558;&#35757;&#32451;&#21160;&#24577;&#19982;&#20854;&#23494;&#38598;&#23545;&#24212;&#29289;&#30340;&#35757;&#32451;&#21160;&#24577;&#23545;&#40784;&#12290;&#28982;&#32780;&#65292;&#19968;&#20010;&#21487;&#33021;&#30340;&#38382;&#39064;&#26159;&#32473;&#23450;&#21021;&#22987;&#28857;&#23545;&#24212;&#30340;&#22266;&#23450;&#26435;&#20540;NTK&#21487;&#33021;&#19982;&#35757;&#32451;&#38454;&#27573;&#21518;&#30340;&#36845;&#20195;&#23545;&#24212;&#30340;NTK&#38750;&#24120;&#19981;&#21516;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#35758;&#23545;&#38543;&#26426;&#26435;&#37325;&#30340;&#22810;&#20010;&#23454;&#29616;&#36827;&#34892;&#37319;&#26679;&#20197;&#20272;&#35745;NTK&#39057;&#35889;&#12290;&#35831;&#27880;&#24847;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#26435;&#37325;&#26080;&#20851;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pruning neural networks before training has received increasing interest due to its potential to reduce training time and memory. One popular method is to prune the connections based on a certain metric, but it is not entirely clear what metric is the best choice. Recent advances in neural tangent kernel (NTK) theory suggest that the training dynamics of large enough neural networks is closely related to the spectrum of the NTK. Motivated by this finding, we propose to prune the connections that have the least influence on the spectrum of the NTK. This method can help maintain the NTK spectrum, which may help align the training dynamics to that of its dense counterpart. However, one possible issue is that the fixed-weight-NTK corresponding to a given initial point can be very different from the NTK corresponding to later iterates during the training phase. We further propose to sample multiple realizations of random weights to estimate the NTK spectrum. Note that our approach is weight
&lt;/p&gt;</description></item><item><title>MethaneMapper&#26159;&#19968;&#20010;&#21487;&#29992;&#20110;&#20809;&#35889;&#22495;&#20869;&#23450;&#20301;&#30002;&#28919;&#25490;&#25918;&#21306;&#22495;&#30340;Transformer&#32593;&#32476;&#65292;&#24182;&#22312;&#27169;&#22411;&#23610;&#23544;&#19978;&#23454;&#29616;&#20102;&#20248;&#21270;&#12290;&#21516;&#26102;&#65292;&#20316;&#32773;&#20171;&#32461;&#20102;&#19968;&#20010;&#29992;&#20110;&#30740;&#31350;&#30002;&#28919;&#26816;&#27979;&#38382;&#39064;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2304.02767</link><description>&lt;p&gt;
MethaneMapper: &#20809;&#35889;&#21560;&#25910;&#24863;&#30693;&#39640;&#20809;&#35889;&#36716;&#25442;&#22120;&#29992;&#20110;&#30002;&#28919;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
MethaneMapper: Spectral Absorption aware Hyperspectral Transformer for Methane Detection. (arXiv:2304.02767v1 [eess.IV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02767
&lt;/p&gt;
&lt;p&gt;
MethaneMapper&#26159;&#19968;&#20010;&#21487;&#29992;&#20110;&#20809;&#35889;&#22495;&#20869;&#23450;&#20301;&#30002;&#28919;&#25490;&#25918;&#21306;&#22495;&#30340;Transformer&#32593;&#32476;&#65292;&#24182;&#22312;&#27169;&#22411;&#23610;&#23544;&#19978;&#23454;&#29616;&#20102;&#20248;&#21270;&#12290;&#21516;&#26102;&#65292;&#20316;&#32773;&#20171;&#32461;&#20102;&#19968;&#20010;&#29992;&#20110;&#30740;&#31350;&#30002;&#28919;&#26816;&#27979;&#38382;&#39064;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30002;&#28919;(CH4)&#26159;&#20840;&#29699;&#27668;&#20505;&#21464;&#21270;&#30340;&#20027;&#35201;&#36129;&#29486;&#32773;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20840;&#26032;&#30340;&#31471;&#21040;&#31471;&#30340;&#20809;&#35889;&#21560;&#25910;&#27874;&#38271;&#24863;&#30693;Transformer&#32593;&#32476;MethaneMapper&#65292;&#29992;&#20110;&#26816;&#27979;&#21644;&#23450;&#37327;&#25490;&#25918;&#12290;MethaneMapper&#24341;&#20837;&#20102;&#20004;&#20010;&#26032;&#27169;&#22359;&#65292;&#24110;&#21161;&#22312;&#20809;&#35889;&#22495;&#20013;&#23450;&#20301;&#26368;&#30456;&#20851;&#30340;&#30002;&#28919;&#20113;&#21306;&#22495;&#65292;&#24182;&#29992;&#20110;&#20934;&#30830;&#22320;&#23450;&#20301;&#23427;&#20204;&#12290;&#20805;&#20998;&#30340;&#35780;&#20272;&#34920;&#26126;MethaneMapper&#22312;&#26816;&#27979;&#26041;&#38754;&#36798;&#21040;&#20102;0.63 mAP&#65292;&#24182;&#22312;&#27169;&#22411;&#23610;&#23544;&#19978;&#65288;&#32553;&#23567;5&#20493;&#65289;&#19982;&#29616;&#26377;&#25216;&#26415;&#27700;&#24179;&#30456;&#27604;&#23454;&#29616;&#20102;&#20248;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#20171;&#32461;&#20102;&#19968;&#20010;&#22823;&#35268;&#27169;&#30340;&#30002;&#28919;&#20113;&#20998;&#21106;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#36229;&#36807;1000&#24352;AVIRIS-NG&#22270;&#20687;&#20197;&#21450;&#23427;&#20204;&#30340;&#30495;&#23454;&#19990;&#30028;&#22320;&#29702;&#21442;&#32771;&#25968;&#25454;&#12290;&#36825;&#20010;&#25968;&#25454;&#38598;&#23558;&#24110;&#21161;&#30740;&#31350;&#20154;&#21592;&#26356;&#22909;&#22320;&#29702;&#35299;&#21644;&#35299;&#20915;&#22312;&#32418;&#22806;&#21644;&#21487;&#35265;&#20809;&#27874;&#38271;&#19979;&#30340;&#30002;&#28919;&#26816;&#27979;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Methane (CH$_4$) is the chief contributor to global climate change. Recent Airborne Visible-Infrared Imaging Spectrometer-Next Generation (AVIRIS-NG) has been very useful in quantitative mapping of methane emissions. Existing methods for analyzing this data are sensitive to local terrain conditions, often require manual inspection from domain experts, prone to significant error and hence are not scalable. To address these challenges, we propose a novel end-to-end spectral absorption wavelength aware transformer network, MethaneMapper, to detect and quantify the emissions. MethaneMapper introduces two novel modules that help to locate the most relevant methane plume regions in the spectral domain and uses them to localize these accurately. Thorough evaluation shows that MethaneMapper achieves 0.63 mAP in detection and reduces the model size (by 5x) compared to the current state of the art. In addition, we also introduce a large-scale dataset of methane plume segmentation mask for over 1
&lt;/p&gt;</description></item><item><title>&#38750;&#23545;&#25968;&#20985;&#21183;V&#30340;&#39640;&#32500;&#37319;&#26679;&#36895;&#29575;&#21487;&#20197;&#22312;&#19968;&#20123;&#26465;&#20214;&#19979;&#23454;&#29616;&#19982;&#20984;&#20989;&#25968;&#30456;&#21516;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2303.03237</link><description>&lt;p&gt;
&#38750;&#23545;&#25968;&#20985;&#37319;&#26679;&#21644;&#23545;&#25968;&#20998;&#21306;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Convergence Rates for Non-Log-Concave Sampling and Log-Partition Estimation. (arXiv:2303.03237v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.03237
&lt;/p&gt;
&lt;p&gt;
&#38750;&#23545;&#25968;&#20985;&#21183;V&#30340;&#39640;&#32500;&#37319;&#26679;&#36895;&#29575;&#21487;&#20197;&#22312;&#19968;&#20123;&#26465;&#20214;&#19979;&#23454;&#29616;&#19982;&#20984;&#20989;&#25968;&#30456;&#21516;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#21513;&#24067;&#26031;&#20998;&#24067;$p(x)\propto\exp(-V(x)/\epsilon)$&#20013;&#37319;&#26679;&#24182;&#35745;&#31639;&#20854;&#23545;&#25968;&#20998;&#21306;&#20989;&#25968;&#26159;&#32479;&#35745;&#23398;&#12289;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#29289;&#29702;&#20013;&#30340;&#22522;&#26412;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#34429;&#28982;&#26377;&#25928;&#30340;&#31639;&#27861;&#24050;&#30693;&#20110;&#20984;&#21183;&#20989;&#25968;$V$&#65292;&#20294;&#38750;&#20984;&#24773;&#20917;&#19979;&#30340;&#24773;&#20917;&#35201;&#22256;&#38590;&#24471;&#22810;&#65292;&#31639;&#27861;&#24517;&#28982;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#21463;&#21040;&#32500;&#24230;&#28798;&#38590;&#30340;&#22256;&#25200;&#12290;&#26368;&#36817;&#65292;&#24050;&#32463;&#35777;&#26126;&#22312;&#36866;&#24403;&#30340;&#26465;&#20214;&#19979;&#65292;&#39640;&#32500;&#37319;&#26679;&#38750;&#23545;&#25968;&#20985;&#21183;V&#30340;&#36895;&#29575;&#20063;&#21487;&#20197;&#36798;&#21040;&#21516;&#26679;&#24555;&#30340;&#36895;&#24230;&#12290;&#26412;&#25991;&#23545;&#36825;&#20123;&#32467;&#26524;&#36827;&#34892;&#20102;&#22238;&#39038;&#65292;&#24182;&#24378;&#35843;&#20102;&#39046;&#22495;&#20013;&#30340;&#19968;&#20123;&#24320;&#25918;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sampling from Gibbs distributions $p(x) \propto \exp(-V(x)/\varepsilon)$ and computing their log-partition function are fundamental tasks in statistics, machine learning, and statistical physics. However, while efficient algorithms are known for convex potentials $V$, the situation is much more difficult in the non-convex case, where algorithms necessarily suffer from the curse of dimensionality in the worst case. For optimization, which can be seen as a low-temperature limit of sampling, it is known that smooth functions $V$ allow faster convergence rates. Specifically, for $m$-times differentiable functions in $d$ dimensions, the optimal rate for algorithms with $n$ function evaluations is known to be $O(n^{-m/d})$, where the constant can potentially depend on $m, d$ and the function to be optimized. Hence, the curse of dimensionality can be alleviated for smooth functions at least in terms of the convergence rate. Recently, it has been shown that similarly fast rates can also be ach
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#23545;&#25239;&#24615;&#35757;&#32451;&#26694;&#26550;&#65292;&#31216;&#20026;&#21512;&#29702;&#23545;&#25239;&#24615;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#65288;PAD&#65289;&#65292;&#23427;&#36890;&#36807;&#21487;&#23398;&#20064;&#30340;&#20984;&#24230;&#37327;&#20445;&#25252;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#22120;&#20813;&#21463;&#25915;&#20987;&#32773;&#30340;&#24433;&#21709;&#65292;&#32780;&#19981;&#26159;&#31616;&#21333;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#65292;&#25552;&#39640;&#20102;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#30340;&#38450;&#24481;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2302.11328</link><description>&lt;p&gt;
PAD: &#38754;&#21521;&#23545;&#25239;&#36867;&#36991;&#25915;&#20987;&#30340;&#21512;&#29702;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
PAD: Towards Principled Adversarial Malware Detection Against Evasion Attacks. (arXiv:2302.11328v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.11328
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#23545;&#25239;&#24615;&#35757;&#32451;&#26694;&#26550;&#65292;&#31216;&#20026;&#21512;&#29702;&#23545;&#25239;&#24615;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#65288;PAD&#65289;&#65292;&#23427;&#36890;&#36807;&#21487;&#23398;&#20064;&#30340;&#20984;&#24230;&#37327;&#20445;&#25252;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#22120;&#20813;&#21463;&#25915;&#20987;&#32773;&#30340;&#24433;&#21709;&#65292;&#32780;&#19981;&#26159;&#31616;&#21333;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#65292;&#25552;&#39640;&#20102;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#30340;&#38450;&#24481;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#21487;&#20197;&#20419;&#36827;&#24694;&#24847;&#36719;&#20214;&#65288;&#31616;&#31216;&#20026;&#24694;&#24847;&#36719;&#20214;&#65289;&#30340;&#33258;&#21160;&#26816;&#27979;&#65292;&#20294;&#21463;&#21040;&#36867;&#36991;&#25915;&#20987;&#30340;&#24433;&#21709;&#12290;&#35768;&#22810;&#30740;&#31350;&#37319;&#29992;&#21551;&#21457;&#24335;&#26041;&#27861;&#26469;&#24212;&#23545;&#36825;&#20123;&#25915;&#20987;&#65292;&#32570;&#20047;&#29702;&#35770;&#20445;&#35777;&#21644;&#26377;&#25928;&#30340;&#38450;&#24481;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#23545;&#25239;&#24615;&#35757;&#32451;&#26694;&#26550;&#65292;&#31216;&#20026;&#21512;&#29702;&#23545;&#25239;&#24615;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#65288;PAD&#65289;&#65292;&#23427;&#38024;&#23545;&#24378;&#22823;&#30340;&#20248;&#21270;&#26041;&#27861;&#25552;&#20379;&#20102;&#25910;&#25947;&#20445;&#35777;&#12290;PAD&#24314;&#31435;&#22312;&#21487;&#23398;&#20064;&#30340;&#20984;&#24230;&#37327;&#19978;&#65292;&#37327;&#21270;&#20998;&#24067;&#24335;&#31163;&#25955;&#25200;&#21160;&#65292;&#20197;&#20445;&#25252;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#22120;&#20813;&#21463;&#25915;&#20987;&#32773;&#30340;&#24433;&#21709;&#65292;&#23545;&#20110;&#24179;&#28369;&#26816;&#27979;&#22120;&#65292;&#21487;&#20197;&#36827;&#34892;&#29702;&#35770;&#19978;&#30340;&#23545;&#25239;&#24615;&#35757;&#32451;&#12290;&#20026;&#20102;&#25552;&#39640;&#38450;&#24481;&#25928;&#26524;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28151;&#21512;&#25915;&#20987;&#26041;&#27861;&#26469;&#23454;&#29616;PAD&#65292;&#20197;&#22686;&#24378;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27979;&#37327;&#21644;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#22120;&#12290;&#22312;&#20004;&#20010;Android&#24694;&#24847;&#36719;&#20214;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65306;&#65288;i&#65289;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine Learning (ML) techniques can facilitate the automation of malicious software (malware for short) detection, but suffer from evasion attacks. Many studies counter such attacks in heuristic manners, lacking theoretical guarantees and defense effectiveness. In this paper, we propose a new adversarial training framework, termed Principled Adversarial Malware Detection (PAD), which offers convergence guarantees for robust optimization methods. PAD lays on a learnable convex measurement that quantifies distribution-wise discrete perturbations to protect malware detectors from adversaries, whereby for smooth detectors, adversarial training can be performed with theoretical treatments. To promote defense effectiveness, we propose a new mixture of attacks to instantiate PAD to enhance deep neural network-based measurements and malware detectors. Experimental results on two Android malware datasets demonstrate: (i) the proposed method significantly outperforms the state-of-the-art defens
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;GD&#35757;&#32451;&#36807;&#31243;&#20013;&#31070;&#32463;&#20999;&#21521;&#26680;&#65288;NTK&#65289;&#36817;&#20284;&#26041;&#27861;&#65292;&#25506;&#31350;&#20102;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#27973;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;Lipschitz&#20989;&#25968;&#30340;&#33021;&#21147;&#65292;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#33021;&#22815;&#20135;&#29983;&#26368;&#20248;&#36895;&#29575;&#30340;&#23454;&#29992;&#26089;&#20572;&#35268;&#21017;&#12290;</title><link>http://arxiv.org/abs/2212.13848</link><description>&lt;p&gt;
&#36890;&#36807;GD&#35757;&#32451;&#30340;&#36807;&#24230;&#21442;&#25968;&#21270;&#27973;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;Lipschitz&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Learning Lipschitz Functions by GD-trained Shallow Overparameterized ReLU Neural Networks. (arXiv:2212.13848v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.13848
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;GD&#35757;&#32451;&#36807;&#31243;&#20013;&#31070;&#32463;&#20999;&#21521;&#26680;&#65288;NTK&#65289;&#36817;&#20284;&#26041;&#27861;&#65292;&#25506;&#31350;&#20102;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#27973;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;Lipschitz&#20989;&#25968;&#30340;&#33021;&#21147;&#65292;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#33021;&#22815;&#20135;&#29983;&#26368;&#20248;&#36895;&#29575;&#30340;&#23454;&#29992;&#26089;&#20572;&#35268;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#31350;&#20102;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#27973;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#22312;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#35757;&#32451;&#26102;&#23398;&#20064;&#20855;&#26377;&#21152;&#24615;&#22122;&#22768;&#30340;Lipschitz&#12289;&#19981;&#21487;&#24494;&#20998;&#12289;&#26377;&#30028;&#20989;&#25968;&#30340;&#33021;&#21147;&#12290;&#20026;&#36991;&#20813;&#23384;&#22312;&#22122;&#22768;&#26102;&#65292;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#21040;&#25509;&#36817;0&#30340;&#35757;&#32451;&#35823;&#24046;&#26102;&#19981;&#19968;&#33268;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#20572;&#27490;&#36739;&#26089;&#30340;GD&#65292;&#20174;&#32780;&#23637;&#31034;&#20102;&#19968;&#33268;&#24615;&#21644;&#26368;&#20248;&#36895;&#29575;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#20174;GD&#35757;&#32451;&#30340;&#26377;&#38480;&#23485;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#31070;&#32463;&#20999;&#21521;&#26680;&#65288;NTK&#65289;&#36817;&#20284;&#30340;&#35270;&#35282;&#25506;&#32034;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#21482;&#35201;&#22312;ReLU&#28608;&#27963;&#20989;&#25968;&#24341;&#36215;&#30340;&#26680;&#30340;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#65292;&#26576;&#20123;&#26089;&#20572;&#35268;&#21017;&#20445;&#35777;&#33021;&#22815;&#32473;&#20986;&#26368;&#20248;&#30340;&#36229;&#39069;&#39118;&#38505;&#36895;&#29575;&#65292;&#37027;&#20040;&#30456;&#21516;&#30340;&#35268;&#21017;&#23601;&#21487;&#20197;&#34987;&#29992;&#20110;&#23454;&#29616;&#22312;Lipschitz&#20989;&#25968;&#25152;&#32771;&#34385;&#30340;&#31867;&#20013;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#30340;&#26497;&#23567;&#26497;&#20540;&#36895;&#29575;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#20960;&#20010;&#26080;&#38656;&#25968;&#25454;&#21644;&#25968;&#25454;&#30456;&#20851;&#30340;&#23454;&#38469;&#21560;&#24341;&#21147;&#20572;&#27490;&#20934;&#21017;&#65292;&#36825;&#20123;&#20934;&#21017;&#20135;&#29983;&#20102;&#26368;&#20248;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We explore the ability of overparameterized shallow ReLU neural networks to learn Lipschitz, nondifferentiable, bounded functions with additive noise when trained by Gradient Descent (GD). To avoid the problem that in the presence of noise, neural networks trained to nearly zero training error are inconsistent in this class, we focus on the early-stopped GD which allows us to show consistency and optimal rates. In particular, we explore this problem from the viewpoint of the Neural Tangent Kernel (NTK) approximation of a GD-trained finite-width neural network. We show that whenever some early stopping rule is guaranteed to give an optimal rate (of excess risk) on the Hilbert space of the kernel induced by the ReLU activation function, the same rule can be used to achieve minimax optimal rate for learning on the class of considered Lipschitz functions by neural networks. We discuss several data-free and data-dependent practically appealing stopping rules that yield optimal rates.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#30340;&#26680;CUSUM&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#29616;&#26377;&#26041;&#27861;&#26356;&#25935;&#24863;&#65292;&#25552;&#20379;&#20102;&#20934;&#30830;&#30340;&#20851;&#38190;&#24615;&#33021;&#25351;&#26631;&#20998;&#26512;&#65292;&#24182;&#24314;&#31435;&#20102;&#26368;&#20248;&#31383;&#21475;&#38271;&#24230;&#65292;&#24341;&#20837;&#20102;&#36882;&#24402;&#35745;&#31639;&#31243;&#24207;&#26469;&#30830;&#20445;&#35745;&#31639;&#21644;&#20869;&#23384;&#22797;&#26434;&#24230;&#24658;&#23450;&#12290;</title><link>http://arxiv.org/abs/2211.15070</link><description>&lt;p&gt;
&#22312;&#32447;&#26680;CUSUM&#26041;&#27861;&#36827;&#34892;&#21464;&#28857;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Online Kernel CUSUM for Change-Point Detection. (arXiv:2211.15070v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.15070
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#30340;&#26680;CUSUM&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#29616;&#26377;&#26041;&#27861;&#26356;&#25935;&#24863;&#65292;&#25552;&#20379;&#20102;&#20934;&#30830;&#30340;&#20851;&#38190;&#24615;&#33021;&#25351;&#26631;&#20998;&#26512;&#65292;&#24182;&#24314;&#31435;&#20102;&#26368;&#20248;&#31383;&#21475;&#38271;&#24230;&#65292;&#24341;&#20837;&#20102;&#36882;&#24402;&#35745;&#31639;&#31243;&#24207;&#26469;&#30830;&#20445;&#35745;&#31639;&#21644;&#20869;&#23384;&#22797;&#26434;&#24230;&#24658;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#22312;&#32447;&#26680;Cumulative Sum (CUSUM)&#26041;&#27861;&#65292;&#29992;&#20110;&#21464;&#28857;&#26816;&#27979;&#65292;&#21033;&#29992;&#26680;&#32479;&#35745;&#37327;&#38598;&#21512;&#20013;&#30340;&#26368;&#22823;&#20540;&#26469;&#32771;&#34385;&#26410;&#30693;&#30340;&#21464;&#28857;&#20301;&#32622;&#12290;&#30456;&#27604;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#22914;Scan-B&#32479;&#35745;&#37327;&#65292;&#21363;&#23545;&#24212;&#20110;&#38750;&#21442;&#25968;Shewhart&#22270;&#36807;&#31243;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23545;&#20110;&#23567;&#21464;&#21270;&#20855;&#26377;&#26356;&#39640;&#30340;&#25935;&#24863;&#24615;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#20010;&#20851;&#38190;&#24615;&#33021;&#25351;&#26631;&#30340;&#20934;&#30830;&#20998;&#26512;&#36817;&#20284;&#20540;&#65306;&#24179;&#22343;&#36816;&#34892;&#38271;&#24230;&#65288;ARL&#65289;&#21644;&#39044;&#26399;&#26816;&#27979;&#24310;&#36831;&#65288;EDD&#65289;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#24314;&#31435;&#19968;&#20010;&#19982;ARL&#23545;&#25968;&#21516;&#38454;&#30340;&#26368;&#20248;&#31383;&#21475;&#38271;&#24230;&#65292;&#20197;&#30830;&#20445;&#30456;&#23545;&#20110;&#20855;&#26377;&#26080;&#38480;&#20869;&#23384;&#30340;&#29702;&#35770;&#27169;&#22411;&#33021;&#22815;&#20445;&#25345;&#26368;&#23567;&#21151;&#29575;&#25439;&#22833;&#12290;&#36825;&#31867;&#20284;&#20110;&#21442;&#25968;&#21464;&#28857;&#26816;&#27979;&#25991;&#29486;&#20013;&#30340;&#31383;&#21475;&#38480;&#21046;&#24191;&#20041;&#20284;&#28982;&#27604;&#65288;GLR&#65289;&#36807;&#31243;&#30340;&#32463;&#20856;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#36882;&#24402;&#35745;&#31639;&#31243;&#24207;&#65292;&#29992;&#20110;&#26816;&#27979;&#32479;&#35745;&#37327;&#65292;&#20197;&#30830;&#20445;&#35745;&#31639;&#21644;&#20869;&#23384;&#22797;&#26434;&#24230;&#24658;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose an efficient online kernel Cumulative Sum (CUSUM) method for change-point detection that utilizes the maximum over a set of kernel statistics to account for the unknown change-point location. Our approach exhibits increased sensitivity to small changes compared to existing methods, such as the Scan-B statistic, which corresponds to a non-parametric Shewhart chart-type procedure. We provide accurate analytic approximations for two key performance metrics: the Average Run Length (ARL) and Expected Detection Delay (EDD), which enable us to establish an optimal window length on the order of the logarithm of ARL to ensure minimal power loss relative to an oracle procedure with infinite memory. Such a finding parallels the classic result for window-limited Generalized Likelihood Ratio (GLR) procedure in parametric change-point detection literature. Moreover, we introduce a recursive calculation procedure for detection statistics to ensure constant computational and memory complexi
&lt;/p&gt;</description></item><item><title>&#31526;&#21512;&#24615;&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#20915;&#31574;&#36807;&#31243;&#20013;&#24212;&#29992;&#31526;&#21512;&#24615;&#39044;&#27979;&#38598;&#65292;&#21487;&#20197;&#32416;&#27491;&#30001;&#20110;&#27169;&#22411;&#35268;&#33539;&#19981;&#24403;&#21644;&#21327;&#21464;&#37327;&#36716;&#31227;&#24102;&#26469;&#30340;&#20027;&#35266;&#19978;&#19981;&#21487;&#33021;&#30340;&#32467;&#26524;&#65292;&#24182;&#22312;&#40657;&#30418;&#20248;&#21270;&#20219;&#21153;&#21644;&#34920;&#26684;&#25490;&#21517;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2210.12496</link><description>&lt;p&gt;
&#24102;&#26377;&#31526;&#21512;&#24615;&#39044;&#27979;&#38598;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Bayesian Optimization with Conformal Prediction Sets. (arXiv:2210.12496v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.12496
&lt;/p&gt;
&lt;p&gt;
&#31526;&#21512;&#24615;&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#20915;&#31574;&#36807;&#31243;&#20013;&#24212;&#29992;&#31526;&#21512;&#24615;&#39044;&#27979;&#38598;&#65292;&#21487;&#20197;&#32416;&#27491;&#30001;&#20110;&#27169;&#22411;&#35268;&#33539;&#19981;&#24403;&#21644;&#21327;&#21464;&#37327;&#36716;&#31227;&#24102;&#26469;&#30340;&#20027;&#35266;&#19978;&#19981;&#21487;&#33021;&#30340;&#32467;&#26524;&#65292;&#24182;&#22312;&#40657;&#30418;&#20248;&#21270;&#20219;&#21153;&#21644;&#34920;&#26684;&#25490;&#21517;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#38754;&#23545;&#19981;&#30830;&#23450;&#24615;&#26102;&#20570;&#20986;&#20915;&#31574;&#30340;&#26222;&#36941;&#26041;&#27861;&#65292;&#24212;&#29992;&#21253;&#25324;&#22810;&#33218;&#32769;&#34382;&#26426;&#12289;&#20027;&#21160;&#23398;&#20064;&#21644;&#40657;&#30418;&#20248;&#21270;&#12290;&#36125;&#21494;&#26031;&#20248;&#21270;&#36890;&#36807;&#22522;&#20110;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#21518;&#39564;&#20998;&#24067;&#36873;&#25321;&#20855;&#26377;&#26368;&#22823;&#39044;&#26399;&#25928;&#29992;&#30340;&#20915;&#31574;(&#21363;&#30446;&#26631;&#20989;&#25968;&#26597;&#35810;)&#65292;&#35813;&#21518;&#39564;&#20998;&#24067;&#37327;&#21270;&#20102;&#26597;&#35810;&#32467;&#26524;&#30340;&#21487;&#20943;&#23569;&#30340;&#20808;&#39564;&#20449;&#24687;&#19981;&#30830;&#23450;&#24615;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#22240;&#27169;&#22411;&#35268;&#33539;&#19981;&#24403;&#21644;&#21327;&#21464;&#37327;&#36716;&#31227;&#30340;&#21407;&#22240;&#65292;&#20027;&#35266;&#19978;&#19981;&#21487;&#33021;&#30340;&#32467;&#26524;&#21487;&#33021;&#32463;&#24120;&#21457;&#29983;&#12290;&#31526;&#21512;&#24615;&#39044;&#27979;&#26159;&#19968;&#31181;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#21363;&#20351;&#23545;&#20110;&#35268;&#33539;&#19981;&#33391;&#30340;&#27169;&#22411;&#20063;&#20855;&#26377;&#35206;&#30422;&#20445;&#35777;&#65292;&#24182;&#19988;&#20855;&#26377;&#32416;&#27491;&#21327;&#21464;&#37327;&#36716;&#31227;&#30340;&#31616;&#21333;&#26426;&#21046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#31526;&#21512;&#24615;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#23558;&#26597;&#35810;&#24341;&#23548;&#21040;&#27169;&#22411;&#39044;&#27979;&#20855;&#26377;&#20445;&#35777;&#26377;&#25928;&#24615;&#30340;&#25628;&#32034;&#31354;&#38388;&#21306;&#22495;&#65292;&#24182;&#30740;&#31350;&#20102;&#23427;&#22312;&#19968;&#32452;&#40657;&#30418;&#20248;&#21270;&#20219;&#21153;&#21644;&#34920;&#26684;&#25490;&#21517;&#20219;&#21153;&#20013;&#30340;&#34892;&#20026;&#12290;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#21457;&#29616;&#31526;&#21512;&#24615;&#36125;&#21494;&#26031;&#20248;&#21270;&#20248;&#20110;&#26631;&#20934;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization is a coherent, ubiquitous approach to decision-making under uncertainty, with applications including multi-arm bandits, active learning, and black-box optimization. Bayesian optimization selects decisions (i.e. objective function queries) with maximal expected utility with respect to the posterior distribution of a Bayesian model, which quantifies reducible, epistemic uncertainty about query outcomes. In practice, subjectively implausible outcomes can occur regularly for two reasons: 1) model misspecification and 2) covariate shift. Conformal prediction is an uncertainty quantification method with coverage guarantees even for misspecified models and a simple mechanism to correct for covariate shift. We propose conformal Bayesian optimization, which directs queries towards regions of search space where the model predictions have guaranteed validity, and investigate its behavior on a suite of black-box optimization tasks and tabular ranking tasks. In many cases we f
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;ORCHID&#26694;&#26550;&#65292;&#23558;Ollivier-Ricci&#26354;&#29575;&#25512;&#24191;&#21040;&#36229;&#22270;&#39046;&#22495;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#20855;&#26377;&#33391;&#22909;&#30340;&#29702;&#35770;&#29305;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;ORCHID&#26354;&#29575;&#23545;&#20110;&#36229;&#22270;&#20219;&#21153;&#26377;&#24456;&#22909;&#30340;&#24212;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2210.12048</link><description>&lt;p&gt;
&#36229;&#22270;&#30340;Ollivier-Ricci&#26354;&#29575;&#65306;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Ollivier-Ricci Curvature for Hypergraphs: A Unified Framework. (arXiv:2210.12048v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.12048
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;ORCHID&#26694;&#26550;&#65292;&#23558;Ollivier-Ricci&#26354;&#29575;&#25512;&#24191;&#21040;&#36229;&#22270;&#39046;&#22495;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#20855;&#26377;&#33391;&#22909;&#30340;&#29702;&#35770;&#29305;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;ORCHID&#26354;&#29575;&#23545;&#20110;&#36229;&#22270;&#20219;&#21153;&#26377;&#24456;&#22909;&#30340;&#24212;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26354;&#29575;&#26159;&#19968;&#31181;&#24378;&#22823;&#32780;&#23500;&#26377;&#34920;&#29616;&#21147;&#30340;&#19981;&#21464;&#37327;&#65292;&#36830;&#25509;&#20102;&#20960;&#20309;&#21644;&#25299;&#25169;&#12290;&#34429;&#28982;&#22312;&#27969;&#24418;&#21644;&#22270;&#30340;&#32972;&#26223;&#19979;&#65292;&#26354;&#29575;&#30340;&#25928;&#29992;&#24050;&#32463;&#22312;&#29702;&#35770;&#21644;&#23454;&#35777;&#19978;&#24471;&#21040;&#20102;&#35777;&#23454;&#65292;&#20294;&#20854;&#22312;&#26032;&#20852;&#30340;&#36229;&#22270;&#39046;&#22495;&#30340;&#25512;&#24191;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#34987;&#20805;&#20998;&#25506;&#32034;&#30340;&#38382;&#39064;&#12290;&#22312;&#22270;&#19978;&#65292;Ollivier-Ricci&#26354;&#29575;&#36890;&#36807;Wasserstein&#36317;&#31163;&#24230;&#37327;&#38543;&#26426;&#28216;&#36208;&#20043;&#38388;&#30340;&#19981;&#21516;&#65292;&#20174;&#32780;&#23558;&#20960;&#20309;&#27010;&#24565;&#33853;&#23454;&#21040;&#27010;&#29575;&#35770;&#21644;&#26368;&#20248;&#36755;&#36816;&#30340;&#24605;&#24819;&#20013;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;ORCHID&#65292;&#19968;&#20010;&#23558;Ollivier-Ricci&#26354;&#29575;&#25512;&#24191;&#21040;&#36229;&#22270;&#30340;&#28789;&#27963;&#26694;&#26550;&#65292;&#24182;&#35777;&#26126;&#20102;&#25152;&#24471;&#26354;&#29575;&#20855;&#26377;&#33391;&#22909;&#30340;&#29702;&#35770;&#23646;&#24615;&#12290;&#36890;&#36807;&#23545;&#26469;&#33258;&#19981;&#21516;&#39046;&#22495;&#30340;&#21512;&#25104;&#21644;&#30495;&#23454;&#36229;&#22270;&#30340;&#24191;&#27867;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;ORCHID&#26354;&#29575;&#26082;&#20855;&#26377;&#21487;&#25193;&#23637;&#24615;&#65292;&#20063;&#26377;&#29992;&#20110;&#36827;&#34892;&#21508;&#31181;&#36229;&#22270;&#20219;&#21153;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bridging geometry and topology, curvature is a powerful and expressive invariant. While the utility of curvature has been theoretically and empirically confirmed in the context of manifolds and graphs, its generalization to the emerging domain of hypergraphs has remained largely unexplored. On graphs, the Ollivier-Ricci curvature measures differences between random walks via Wasserstein distances, thus grounding a geometric concept in ideas from probability theory and optimal transport. We develop ORCHID, a flexible framework generalizing Ollivier-Ricci curvature to hypergraphs, and prove that the resulting curvatures have favorable theoretical properties. Through extensive experiments on synthetic and real-world hypergraphs from different domains, we demonstrate that ORCHID curvatures are both scalable and useful to perform a variety of hypergraph tasks in practice.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#24191;&#20041;&#32447;&#24615;&#36172;&#21338;&#26426;&#20013;&#30340;&#24310;&#36831;&#22870;&#21169;&#29616;&#35937;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#28982;&#30340;&#20048;&#35266;&#31639;&#27861;&#65292;&#21487;&#23454;&#29616;&#19968;&#20010;&#29420;&#31435;&#20110;&#26102;&#38388;&#30340;&#24809;&#32602;&#20989;&#25968;&#65292;&#38477;&#20302;&#20102;&#29616;&#26377;&#24037;&#20316;&#20013;&#38543;&#30528;&#26102;&#38388;&#22686;&#38271;&#32780;&#22686;&#21152;&#30340;&#24809;&#32602;&#20989;&#25968;&#30340;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2207.10786</link><description>&lt;p&gt;
&#24310;&#36831;&#21453;&#39304;&#22312;&#24191;&#20041;&#32447;&#24615;&#36172;&#21338;&#26426;&#20013;&#30340;&#30740;&#31350;&#20877;&#35775;
&lt;/p&gt;
&lt;p&gt;
Delayed Feedback in Generalised Linear Bandits Revisited. (arXiv:2207.10786v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.10786
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#24191;&#20041;&#32447;&#24615;&#36172;&#21338;&#26426;&#20013;&#30340;&#24310;&#36831;&#22870;&#21169;&#29616;&#35937;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#28982;&#30340;&#20048;&#35266;&#31639;&#27861;&#65292;&#21487;&#23454;&#29616;&#19968;&#20010;&#29420;&#31435;&#20110;&#26102;&#38388;&#30340;&#24809;&#32602;&#20989;&#25968;&#65292;&#38477;&#20302;&#20102;&#29616;&#26377;&#24037;&#20316;&#20013;&#38543;&#30528;&#26102;&#38388;&#22686;&#38271;&#32780;&#22686;&#21152;&#30340;&#24809;&#32602;&#20989;&#25968;&#30340;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#35768;&#22810;&#30495;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#20013;&#22870;&#21169;&#20960;&#20046;&#24635;&#26159;&#34987;&#24310;&#36831;&#65292;&#23548;&#33268;&#35201;&#27714;&#21363;&#26102;&#22870;&#21169;&#30340;&#27169;&#22411;&#38590;&#20197;&#24212;&#29992;&#12290;&#26412;&#25991;&#23558;&#30740;&#31350;&#22312;&#24191;&#20041;&#32447;&#24615;&#36172;&#21338;&#26426;&#20013;&#24310;&#36831;&#22870;&#21169;&#30340;&#29616;&#35937;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#31181;&#33258;&#28982;&#30340;&#20048;&#35266;&#31639;&#27861;&#36866;&#24212;&#24310;&#36831;&#21453;&#39304;&#39046;&#22495;&#33021;&#22815;&#26377;&#19968;&#20010;&#19982;&#26102;&#38388;&#26080;&#20851;&#30340;&#24809;&#32602;&#20989;&#25968;&#12290;&#36825;&#27604;&#29616;&#26377;&#30340;&#24037;&#20316;&#26174;&#33879;&#30340;&#25552;&#39640;&#20102;&#65292;&#22240;&#20026;&#26368;&#20339;&#30340;&#24050;&#30693;&#30340;&#24809;&#32602;&#20989;&#25968;&#30340;&#30028;&#38480;&#38543;&#30528;&#26102;&#38388;&#30340;&#25512;&#31227;&#32780;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;
The stochastic generalised linear bandit is a well-understood model for sequential decision-making problems, with many algorithms achieving near-optimal regret guarantees under immediate feedback. However, the stringent requirement for immediate rewards is unmet in many real-world applications where the reward is almost always delayed. We study the phenomenon of delayed rewards in generalised linear bandits in a theoretical manner. We show that a natural adaptation of an optimistic algorithm to the delayed feedback achieves a regret bound where the penalty for the delays is independent of the horizon. This result significantly improves upon existing work, where the best known regret bound has the delay penalty increasing with the horizon. We verify our theoretical results through experiments on simulated data.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27010;&#29575;&#26426;&#22120;&#23398;&#20064;&#25193;&#23637;&#24179;&#28369;&#27169;&#22411;&#26816;&#39564;(smMC)&#26041;&#27861;&#30340;&#24605;&#36335;&#65292;&#20174;&#32780;&#20351;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;smMC&#36866;&#29992;&#20110;&#26356;&#22823;&#30340;&#25968;&#25454;&#38598;&#21644;&#23454;&#38469;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2205.05398</link><description>&lt;p&gt;
&#24102;&#38543;&#26426;&#21464;&#37327;&#30340;&#21442;&#25968;&#21270;&#39564;&#35777;-&#38543;&#26426;&#21464;&#20998;&#20809;&#28369;&#27169;&#22411;&#26816;&#39564;&#30340;&#21487;&#25193;&#23637;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Scalable Stochastic Parametric Verification with Stochastic Variational Smoothed Model Checking. (arXiv:2205.05398v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.05398
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27010;&#29575;&#26426;&#22120;&#23398;&#20064;&#25193;&#23637;&#24179;&#28369;&#27169;&#22411;&#26816;&#39564;(smMC)&#26041;&#27861;&#30340;&#24605;&#36335;&#65292;&#20174;&#32780;&#20351;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;smMC&#36866;&#29992;&#20110;&#26356;&#22823;&#30340;&#25968;&#25454;&#38598;&#21644;&#23454;&#38469;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#38543;&#26426;&#27169;&#22411;&#30340;&#32447;&#24615;&#26102;&#24577;&#24615;&#23646;&#24615;&#30340;&#21442;&#25968;&#21270;&#39564;&#35777;&#21487;&#20197;&#34920;&#31034;&#20026;&#35745;&#31639;&#28385;&#36275;&#19968;&#23450;&#23646;&#24615;&#30340;&#27010;&#29575;&#65292;&#20989;&#25968;&#30340;&#21442;&#25968;&#20026;&#36825;&#20010;&#27169;&#22411;&#30340;&#21442;&#25968;&#12290;&#24179;&#28369;&#27169;&#22411;&#26816;&#39564;(smMC)&#26088;&#22312;&#20174;&#36890;&#36807;&#27169;&#25311;&#33719;&#24471;&#30340;&#26377;&#38480;&#30340;&#35266;&#27979;&#20540;&#20013;&#25512;&#26029;&#20986;&#25972;&#20010;&#21442;&#25968;&#31354;&#38388;&#19978;&#30340;&#28385;&#36275;&#20989;&#25968;&#12290;&#30001;&#20110;&#35266;&#27979;&#25104;&#26412;&#39640;&#19988;&#22122;&#22768;&#22823;&#65292;&#22240;&#27492;smMC&#34987;&#26500;&#24314;&#20026;&#36125;&#21494;&#26031;&#25512;&#29702;&#38382;&#39064;&#65292;&#20351;&#20272;&#35745;&#20540;&#20855;&#26377;&#39069;&#22806;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#22312;smMC&#20013;&#65292;&#20316;&#32773;&#20351;&#29992;&#30001;&#26399;&#26395;&#20256;&#25773;&#31639;&#27861;&#25512;&#26029;&#20986;&#30340;&#39640;&#26031;&#36807;&#31243;(GP)&#12290;&#36825;&#31181;&#26041;&#27861;&#25552;&#20379;&#20102;&#20934;&#30830;&#30340;&#37325;&#26500;&#21644;&#32479;&#35745;&#19978;&#21512;&#29702;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#28982;&#32780;&#65292;&#23427;&#32487;&#25215;&#20102;GP&#30340;&#33879;&#21517;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#21033;&#29992;&#27010;&#29575;&#26426;&#22120;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#23558;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;smMC&#25193;&#23637;&#21040;&#26356;&#22823;&#30340;&#25968;&#25454;&#38598;&#65292;&#24182;&#20351;&#20854;&#36866;&#29992;&#20110;&#23454;&#38469;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Parametric verification of linear temporal properties for stochastic models can be expressed as computing the satisfaction probability of a certain property as a function of the parameters of the model. Smoothed model checking (smMC) aims at inferring the satisfaction function over the entire parameter space from a limited set of observations obtained via simulation. As observations are costly and noisy, smMC is framed as a Bayesian inference problem so that the estimates have an additional quantification of the uncertainty. In smMC the authors use Gaussian Processes (GP), inferred by means of the Expectation Propagation algorithm. This approach provides accurate reconstructions with statistically sound quantification of the uncertainty. However, it inherits the well-known scalability issues of GP. In this paper, we exploit recent advances in probabilistic machine learning to push this limitation forward, making Bayesian inference of smMC scalable to larger datasets and enabling its ap
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;WOODS&#30340;&#26102;&#38388;&#24207;&#21015;&#22522;&#20934;&#27979;&#35797;&#65292;&#33268;&#21147;&#20110;&#35299;&#20915;&#22312;&#31163;&#32676;&#20998;&#24067;&#19979;&#30340;&#27867;&#21270;&#36807;&#31243;&#20013;&#38754;&#20020;&#30340;&#25361;&#25112;&#65292;&#36824;&#25913;&#36827;&#20102;&#30446;&#21069;&#26102;&#38388;&#24207;&#21015;&#20219;&#21153;&#20013;&#30340;&#31163;&#32676;&#20998;&#24067;&#24191;&#20041;&#24615;&#31639;&#27861;&#65292;&#24182;&#34920;&#26126;&#20173;&#26377;&#24456;&#22823;&#30340;&#25913;&#36827;&#31354;&#38388;&#12290;</title><link>http://arxiv.org/abs/2203.09978</link><description>&lt;p&gt;
WOODS: &#26102;&#38388;&#24207;&#21015;&#39046;&#22495;&#30340;&#31163;&#32676;&#20998;&#24067;&#24191;&#20041;&#24615;&#30340;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
WOODS: Benchmarks for Out-of-Distribution Generalization in Time Series. (arXiv:2203.09978v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.09978
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;WOODS&#30340;&#26102;&#38388;&#24207;&#21015;&#22522;&#20934;&#27979;&#35797;&#65292;&#33268;&#21147;&#20110;&#35299;&#20915;&#22312;&#31163;&#32676;&#20998;&#24067;&#19979;&#30340;&#27867;&#21270;&#36807;&#31243;&#20013;&#38754;&#20020;&#30340;&#25361;&#25112;&#65292;&#36824;&#25913;&#36827;&#20102;&#30446;&#21069;&#26102;&#38388;&#24207;&#21015;&#20219;&#21153;&#20013;&#30340;&#31163;&#32676;&#20998;&#24067;&#24191;&#20041;&#24615;&#31639;&#27861;&#65292;&#24182;&#34920;&#26126;&#20173;&#26377;&#24456;&#22823;&#30340;&#25913;&#36827;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#20998;&#24067;&#20559;&#31227;&#19979;&#24448;&#24448;&#38590;&#20197;&#36827;&#34892;&#24456;&#22909;&#30340;&#27867;&#21270;&#12290;&#29702;&#35299;&#21644;&#20811;&#26381;&#36825;&#20123;&#38382;&#39064;&#24418;&#25104;&#20102;&#31163;&#32676;&#20998;&#24067;&#24191;&#20041;&#24615;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#23613;&#31649;&#23545;&#20110;&#38745;&#24577;&#35745;&#31639;&#26426;&#35270;&#35273;&#20219;&#21153;&#24050;&#32463;&#24471;&#21040;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#22312;&#26102;&#38388;&#24207;&#21015;&#20219;&#21153;&#20013;&#65292;&#31163;&#32676;&#20998;&#24067;&#24191;&#20041;&#24615;&#21364;&#40092;&#26377;&#25506;&#32034;&#12290;&#20026;&#20943;&#23569;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#25552;&#20986;WOODS&#65306;&#20843;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24320;&#28304;&#26102;&#38388;&#24207;&#21015;&#22522;&#20934;&#27979;&#35797;&#65292;&#28085;&#30422;&#20102;&#21508;&#31181;&#25968;&#25454;&#27169;&#24577;&#65292;&#20363;&#22914;&#35270;&#39057;&#12289;&#33041;&#35760;&#24405;&#21644;&#20256;&#24863;&#22120;&#20449;&#21495;&#12290;&#25105;&#20204;&#25913;&#36827;&#20102;&#29616;&#26377;&#30340;&#26102;&#38388;&#24207;&#21015;&#20219;&#21153;&#30340;&#31163;&#32676;&#20998;&#24067;&#24191;&#20041;&#24615;&#31639;&#27861;&#65292;&#24182;&#20351;&#29992;&#25105;&#20204;&#30340;&#31995;&#32479;&#26694;&#26550;&#36827;&#34892;&#35780;&#20272;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#26174;&#31034;&#65292;&#23545;&#20110;&#25105;&#20204;&#30340;&#25968;&#25454;&#38598;&#65292;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#21644;&#31163;&#32676;&#20998;&#24067;&#24191;&#20041;&#24615;&#31639;&#27861;&#20173;&#26377;&#24456;&#22823;&#30340;&#25913;&#36827;&#31354;&#38388;&#65292;&#20174;&#32780;&#20984;&#26174;&#20102;&#26102;&#38388;&#24207;&#21015;&#20219;&#21153;&#38754;&#20020;&#30340;&#26032;&#25361;&#25112;&#12290;&#20195;&#30721;&#21644;&#25991;&#26723;&#21487;&#22312;https://woods-benchmarks.github.io&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning models often fail to generalize well under distributional shifts. Understanding and overcoming these failures have led to a research field of Out-of-Distribution (OOD) generalization. Despite being extensively studied for static computer vision tasks, OOD generalization has been underexplored for time series tasks. To shine light on this gap, we present WOODS: eight challenging open-source time series benchmarks covering a diverse range of data modalities, such as videos, brain recordings, and sensor signals. We revise the existing OOD generalization algorithms for time series tasks and evaluate them using our systematic framework. Our experiments show a large room for improvement for empirical risk minimization and OOD generalization algorithms on our datasets, thus underscoring the new challenges posed by time series tasks. Code and documentation are available at https://woods-benchmarks.github.io .
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#24207;&#21015;&#33945;&#29305;&#21345;&#32599;&#37319;&#26679;&#21644;&#26631;&#20934;&#21270;&#27969;&#21464;&#20998;&#25512;&#26029;&#30340;&#36830;&#32493;&#37325;&#22797;&#36864;&#28779;&#27969;&#36755;&#36816;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#26631;&#20934;&#21270;&#27969;&#30340;&#35757;&#32451;&#65292;&#23454;&#29616;&#19981;&#21516;&#28201;&#24230;&#19979;&#30340;&#20256;&#36755;&#65292;&#24182;&#22312;&#22810;&#20010;&#23454;&#20363;&#20013;&#23637;&#31034;&#20102;&#20854;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2201.13117</link><description>&lt;p&gt;
&#36830;&#32493;&#37325;&#22797;&#36864;&#28779;&#27969;&#36755;&#36816;&#33945;&#29305;&#21345;&#32599;
&lt;/p&gt;
&lt;p&gt;
Continual Repeated Annealed Flow Transport Monte Carlo. (arXiv:2201.13117v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.13117
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#24207;&#21015;&#33945;&#29305;&#21345;&#32599;&#37319;&#26679;&#21644;&#26631;&#20934;&#21270;&#27969;&#21464;&#20998;&#25512;&#26029;&#30340;&#36830;&#32493;&#37325;&#22797;&#36864;&#28779;&#27969;&#36755;&#36816;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#26631;&#20934;&#21270;&#27969;&#30340;&#35757;&#32451;&#65292;&#23454;&#29616;&#19981;&#21516;&#28201;&#24230;&#19979;&#30340;&#20256;&#36755;&#65292;&#24182;&#22312;&#22810;&#20010;&#23454;&#20363;&#20013;&#23637;&#31034;&#20102;&#20854;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#36830;&#32493;&#37325;&#22797;&#36864;&#28779;&#27969;&#36755;&#36816;&#33945;&#29305;&#21345;&#32599;&#65288;CRAFT&#65289;&#26041;&#27861;&#65292;&#23558;&#24207;&#21015;&#33945;&#29305;&#21345;&#32599;&#65288;SMC&#65289;&#37319;&#26679;&#22120;&#65288;&#33258;&#36523;&#26159;&#36880;&#27493;&#37325;&#35201;&#37319;&#26679;&#30340;&#25512;&#24191;&#65289;&#19982;&#20351;&#29992;&#26631;&#20934;&#21270;&#27969;&#30340;&#21464;&#20998;&#25512;&#26029;&#30456;&#32467;&#21512;&#12290;&#26631;&#20934;&#21270;&#27969;&#30452;&#25509;&#35757;&#32451;&#20197;&#22312;&#27599;&#20010;&#36716;&#25442;&#20043;&#38388;&#20256;&#36755;&#36864;&#28779;&#28201;&#24230;&#65292;&#20351;&#29992;KL&#25955;&#24230;&#36827;&#34892;&#20248;&#21270;&#30446;&#26631;&#65292;&#27492;&#20248;&#21270;&#30446;&#26631;&#26412;&#36523;&#20351;&#29992;&#26631;&#20934;&#21270;&#27969;/ SMC&#36817;&#20284;&#20272;&#35745;&#12290;&#25105;&#20204;&#22312;&#27010;&#24565;&#19978;&#21644;&#22810;&#20010;&#32463;&#39564;&#23454;&#20363;&#20013;&#23637;&#31034;&#20102;CRAFT&#20248;&#20110;Annealed Flow Transport Monte Carlo&#65288;Arbel&#31561;&#20154;&#65292;2021&#65289;&#65292;&#24182;&#22312;&#20854;&#22522;&#30784;&#19978;&#25913;&#36827;&#20102;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#65288;MCMC&#65289;&#30340;&#38543;&#26426;&#26631;&#20934;&#21270;&#27969;&#65288;Wu&#31561;&#20154;&#65292;2020&#65289;&#12290;&#36890;&#36807;&#22312;&#31890;&#23376;MCMC&#20013;&#32467;&#21512;CRAFT&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#26679;&#23398;&#20064;&#30340;&#37319;&#26679;&#22120;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#26230;&#26684;&#22330;&#35770;&#23454;&#20363;&#19978;&#21487;&#20197;&#23454;&#29616;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#31934;&#30830;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose Continual Repeated Annealed Flow Transport Monte Carlo (CRAFT), a method that combines a sequential Monte Carlo (SMC) sampler (itself a generalization of Annealed Importance Sampling) with variational inference using normalizing flows. The normalizing flows are directly trained to transport between annealing temperatures using a KL divergence for each transition. This optimization objective is itself estimated using the normalizing flow/SMC approximation. We show conceptually and using multiple empirical examples that CRAFT improves on Annealed Flow Transport Monte Carlo (Arbel et al., 2021), on which it builds and also on Markov chain Monte Carlo (MCMC) based Stochastic Normalizing Flows (Wu et al., 2020). By incorporating CRAFT within particle MCMC, we show that such learnt samplers can achieve impressively accurate results on a challenging lattice field theory example.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23545;&#25239;&#24615;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#22522;&#20110;&#32593;&#32476;&#30340;&#25972;&#20307;&#23637;&#24320;&#30340;&#23545;&#25239;&#25439;&#22833;&#19978;&#30028;&#26469;&#23454;&#29616;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#20102;&#26368;&#26032;&#30340;&#31283;&#20581;&#20248;&#21270;&#39046;&#22495;&#30340;&#24037;&#20855;&#65292;&#21487;&#20197;&#22312;&#20445;&#35777;&#36755;&#20986;&#23618;&#32465;&#23450;&#32039;&#23494;&#24615;&#30340;&#21516;&#26102;&#65292;&#26377;&#25928;&#22320;&#36827;&#34892;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2112.09279</link><description>&lt;p&gt;
&#31283;&#20581;&#23545;&#25239;&#24615;&#35757;&#32451;&#30340;&#24378;&#21147;&#19978;&#30028;
&lt;/p&gt;
&lt;p&gt;
Robust Upper Bounds for Adversarial Training. (arXiv:2112.09279v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.09279
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23545;&#25239;&#24615;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#22522;&#20110;&#32593;&#32476;&#30340;&#25972;&#20307;&#23637;&#24320;&#30340;&#23545;&#25239;&#25439;&#22833;&#19978;&#30028;&#26469;&#23454;&#29616;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#20102;&#26368;&#26032;&#30340;&#31283;&#20581;&#20248;&#21270;&#39046;&#22495;&#30340;&#24037;&#20855;&#65292;&#21487;&#20197;&#22312;&#20445;&#35777;&#36755;&#20986;&#23618;&#32465;&#23450;&#32039;&#23494;&#24615;&#30340;&#21516;&#26102;&#65292;&#26377;&#25928;&#22320;&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#25552;&#20379;&#23545;&#25239;&#25915;&#20987;&#30340;&#23433;&#20840;&#20445;&#35777;&#65292;&#35768;&#22810;&#26368;&#20808;&#36827;&#30340;&#28145;&#24230;&#23398;&#20064;&#23545;&#25239;&#24615;&#35757;&#32451;&#26041;&#27861;&#21033;&#29992;&#23545;&#25239;&#25439;&#22833;&#30340;&#19978;&#30028;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#20381;&#36182;&#20110;&#20984;&#26494;&#24347;&#26469;&#20256;&#25773;&#20013;&#38388;&#23618;&#30340;&#19979;&#30028;&#21644;&#19978;&#30028;&#65292;&#36825;&#20250;&#24433;&#21709;&#36755;&#20986;&#23618;&#32465;&#23450;&#30340;&#32039;&#23494;&#24615;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#23545;&#25239;&#24615;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#22522;&#20110;&#32593;&#32476;&#30340;&#25972;&#20307;&#23637;&#24320;&#30340;&#23545;&#25239;&#25439;&#22833;&#19978;&#30028;&#26469;&#23454;&#29616;&#12290;&#35813;&#19978;&#30028;&#21033;&#29992;&#20102;&#31283;&#20581;&#20248;&#21270;&#39046;&#22495;&#30340;&#26368;&#26032;&#24037;&#20855;&#65292;&#20855;&#26377;&#38381;&#21512;&#24418;&#24335;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#21453;&#21521;&#20256;&#25773;&#36827;&#34892;&#26377;&#25928;&#35757;&#32451;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#26041;&#27861;&#26469;&#23454;&#29616;&#36825;&#31181;&#26041;&#27861;&#12290;&#31532;&#19968;&#31181;&#26041;&#27861;&#65288;&#36817;&#20284;&#31283;&#20581;&#19978;&#30028;&#25110;aRUB&#65289;&#20351;&#29992;&#32593;&#32476;&#30340;&#19968;&#38454;&#36817;&#20284;&#21644;&#32447;&#24615;&#31283;&#20581;&#20248;&#21270;&#30340;&#22522;&#26412;&#24037;&#20855;&#65292;&#33719;&#24471;&#23545;&#25239;&#25439;&#22833;&#30340;&#32463;&#39564;&#19978;&#30028;&#65292;&#21487;&#20197;&#36731;&#26494;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many state-of-the-art adversarial training methods for deep learning leverage upper bounds of the adversarial loss to provide security guarantees against adversarial attacks. Yet, these methods rely on convex relaxations to propagate lower and upper bounds for intermediate layers, which affect the tightness of the bound at the output layer. We introduce a new approach to adversarial training by minimizing an upper bound of the adversarial loss that is based on a holistic expansion of the network instead of separate bounds for each layer. This bound is facilitated by state-of-the-art tools from Robust Optimization; it has closed-form and can be effectively trained using backpropagation. We derive two new methods with the proposed approach. The first method (Approximated Robust Upper Bound or aRUB) uses the first order approximation of the network as well as basic tools from Linear Robust Optimization to obtain an empirical upper bound of the adversarial loss that can be easily implement
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#39640;&#26031;&#36807;&#31243;&#21518;&#39564;&#30340;&#20027;&#25104;&#20998;&#20998;&#26512;&#25193;&#23637;&#65292;&#35299;&#20915;&#20102;&#22914;&#20309;&#23450;&#20041;&#19968;&#32452;&#20855;&#26377;&#26080;&#38480;&#32500;&#21442;&#25968;&#30340;GP&#30340;&#32467;&#26500;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#36890;&#36807;&#20803;&#23398;&#20064;&#25552;&#39640;&#30446;&#26631;&#20219;&#21153;&#24615;&#33021;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2107.07115</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#21518;&#39564;&#30340;&#20027;&#25104;&#20998;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Principal component analysis for Gaussian process posteriors. (arXiv:2107.07115v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.07115
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#39640;&#26031;&#36807;&#31243;&#21518;&#39564;&#30340;&#20027;&#25104;&#20998;&#20998;&#26512;&#25193;&#23637;&#65292;&#35299;&#20915;&#20102;&#22914;&#20309;&#23450;&#20041;&#19968;&#32452;&#20855;&#26377;&#26080;&#38480;&#32500;&#21442;&#25968;&#30340;GP&#30340;&#32467;&#26500;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#36890;&#36807;&#20803;&#23398;&#20064;&#25552;&#39640;&#30446;&#26631;&#20219;&#21153;&#24615;&#33021;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#39640;&#26031;&#36807;&#31243;&#21518;&#39564;&#30340;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;GP-PCA&#65289;&#25193;&#23637;&#12290;&#30001;&#20110;GP-PCA&#20272;&#35745;&#20102;&#19968;&#20010;&#20302;&#32500;&#24230;&#30340;GP&#21518;&#39564;&#31354;&#38388;&#65292;&#22240;&#27492;&#21487;&#20197;&#29992;&#20110;&#20803;&#23398;&#20064;&#65292;&#36825;&#26159;&#19968;&#31181;&#36890;&#36807;&#20272;&#35745;&#19968;&#32452;&#20219;&#21153;&#30340;&#32467;&#26500;&#26469;&#25552;&#39640;&#30446;&#26631;&#20219;&#21153;&#24615;&#33021;&#30340;&#26694;&#26550;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#32771;&#34385;&#20855;&#26377;&#30456;&#21516;&#20808;&#39564;&#30340;GP&#21518;&#39564;&#31354;&#38388;&#65292;&#22312;&#20449;&#24687;&#20960;&#20309;&#26694;&#26550;&#19979;&#23558;GP&#30340;&#26080;&#38480;&#32500;&#24230;&#38382;&#39064;&#32553;&#20943;&#20026;&#26377;&#38480;&#32500;&#24230;&#30340;&#24773;&#20917;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#22914;&#20309;&#23450;&#20041;&#19968;&#32452;&#20855;&#26377;&#26080;&#38480;&#32500;&#21442;&#25968;&#65288;&#22914;&#22352;&#26631;&#31995;&#21644;&#21457;&#25955;&#65289;&#30340;GP&#30340;&#32467;&#26500;&#30340;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21464;&#20998;&#25512;&#29702;&#30340;GP-PCA&#36817;&#20284;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;GP-PCA&#20316;&#20026;&#20803;&#23398;&#20064;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes an extension of principal component analysis for Gaussian process (GP) posteriors, denoted by GP-PCA. Since GP-PCA estimates a low-dimensional space of GP posteriors, it can be used for meta-learning, which is a framework for improving the performance of target tasks by estimating a structure of a set of tasks. The issue is how to define a structure of a set of GPs with an infinite-dimensional parameter, such as coordinate system and a divergence. In this study, we reduce the infiniteness of GP to the finite-dimensional case under the information geometrical framework by considering a space of GP posteriors that have the same prior. In addition, we propose an approximation method of GP-PCA based on variational inference and demonstrate the effectiveness of GP-PCA as meta-learning through experiments.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#25239;&#39034;&#24207;&#26816;&#27979;&#22120;&#65292;&#20351;&#29992;&#24102;&#26631;&#35760;&#30340;&#28857;&#36807;&#31243;&#27169;&#22411;&#25429;&#25417;&#24207;&#21015;&#20107;&#20214;&#20013;&#30340;&#30456;&#20851;&#24615;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#26816;&#27979;&#24322;&#24120;&#24207;&#21015;&#65292;&#36890;&#36807;&#35299;&#20915;&#26368;&#23567;&#26368;&#22823;&#38382;&#39064;&#65292;&#38024;&#23545;&#26368;&#22351;&#24773;&#20917;&#30340;&#29983;&#25104;&#22120;&#65292;&#25214;&#21040;&#26368;&#20339;&#26816;&#27979;&#22120;&#12290;</title><link>http://arxiv.org/abs/1910.09161</link><description>&lt;p&gt;
&#29992;&#20110;&#19968;&#31867;&#20107;&#20214;&#25968;&#25454;&#30340;&#39034;&#24207;&#23545;&#25239;&#24322;&#24120;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Sequential Adversarial Anomaly Detection for One-Class Event Data. (arXiv:1910.09161v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1910.09161
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#25239;&#39034;&#24207;&#26816;&#27979;&#22120;&#65292;&#20351;&#29992;&#24102;&#26631;&#35760;&#30340;&#28857;&#36807;&#31243;&#27169;&#22411;&#25429;&#25417;&#24207;&#21015;&#20107;&#20214;&#20013;&#30340;&#30456;&#20851;&#24615;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#26816;&#27979;&#24322;&#24120;&#24207;&#21015;&#65292;&#36890;&#36807;&#35299;&#20915;&#26368;&#23567;&#26368;&#22823;&#38382;&#39064;&#65292;&#38024;&#23545;&#26368;&#22351;&#24773;&#20917;&#30340;&#29983;&#25104;&#22120;&#65292;&#25214;&#21040;&#26368;&#20339;&#26816;&#27979;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#21333;&#31867;&#22330;&#26223;&#19979;&#30340;&#39034;&#24207;&#24322;&#24120;&#26816;&#27979;&#38382;&#39064;&#65292;&#20165;&#22312;&#24322;&#24120;&#24207;&#21015;&#21487;&#29992;&#26102;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#25239;&#39034;&#24207;&#26816;&#27979;&#22120;&#65292;&#36890;&#36807;&#35299;&#20915;&#26368;&#23567;&#26368;&#22823;&#38382;&#39064;&#65292;&#38024;&#23545;&#26368;&#22351;&#24773;&#20917;&#30340;&#29983;&#25104;&#22120;&#65292;&#25214;&#21040;&#26368;&#20339;&#26816;&#27979;&#22120;&#12290;&#29983;&#25104;&#22120;&#20351;&#29992;&#24102;&#26631;&#35760;&#30340;&#28857;&#36807;&#31243;&#27169;&#22411;&#25429;&#25417;&#24207;&#21015;&#20107;&#20214;&#20013;&#30340;&#30456;&#20851;&#24615;&#12290;&#26816;&#27979;&#22120;&#39034;&#24207;&#35780;&#20272;&#27979;&#35797;&#24207;&#21015;&#30340;&#21487;&#33021;&#24615;&#65292;&#24182;&#23558;&#20854;&#19982;&#23398;&#20064;&#33258;&#26368;&#23567;&#26368;&#22823;&#38382;&#39064;&#30340;&#26102;&#38388;&#21464;&#21270;&#38408;&#20540;&#36827;&#34892;&#27604;&#36739;&#12290;&#25105;&#20204;&#22312;&#27169;&#25311;&#21644;&#19987;&#26377;&#30340;&#22823;&#35268;&#27169;&#20449;&#29992;&#21345;&#27450;&#35784;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#25552;&#20986;&#26041;&#27861;&#30340;&#33391;&#22909;&#24615;&#33021;&#12290;&#35813;&#26041;&#27861;&#36890;&#24120;&#36866;&#29992;&#20110;&#26816;&#27979;&#24322;&#24120;&#24207;&#21015;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the sequential anomaly detection problem in the one-class setting when only the anomalous sequences are available and propose an adversarial sequential detector by solving a minimax problem to find an optimal detector against the worst-case sequences from a generator. The generator captures the dependence in sequential events using the marked point process model. The detector sequentially evaluates the likelihood of a test sequence and compares it with a time-varying threshold, also learned from data through the minimax problem. We demonstrate our proposed method's good performance using numerical experiments on simulations and proprietary large-scale credit card fraud datasets. The proposed method can generally apply to detecting anomalous sequences.
&lt;/p&gt;</description></item></channel></rss>