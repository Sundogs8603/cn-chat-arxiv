<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#21644;&#20027;&#21160;&#37319;&#26679;&#30340;&#21518;&#39564;&#27169;&#25311;&#22120;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#22343;&#20540;&#39044;&#27979;&#19978;&#36827;&#34892;&#20998;&#32423;&#37319;&#26679;&#65292;&#22312;&#20445;&#25345;&#20934;&#30830;&#24615;&#30340;&#21069;&#25552;&#19979;&#23454;&#29616;&#20102;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#30340;&#24182;&#34892;&#22788;&#29702;&#65292;&#26377;&#25928;&#38477;&#20302;&#20102;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2305.19267</link><description>&lt;p&gt;
&#33945;&#29305;&#21345;&#32599;&#37319;&#26679;&#19979;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#20027;&#21160;&#23398;&#20064;&#20013;&#24182;&#34892;&#33719;&#21462;&#26679;&#26412;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Parallelized Acquisition for Active Learning using Monte Carlo Sampling. (arXiv:2305.19267v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19267
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#21644;&#20027;&#21160;&#37319;&#26679;&#30340;&#21518;&#39564;&#27169;&#25311;&#22120;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#22343;&#20540;&#39044;&#27979;&#19978;&#36827;&#34892;&#20998;&#32423;&#37319;&#26679;&#65292;&#22312;&#20445;&#25345;&#20934;&#30830;&#24615;&#30340;&#21069;&#25552;&#19979;&#23454;&#29616;&#20102;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#30340;&#24182;&#34892;&#22788;&#29702;&#65292;&#26377;&#25928;&#38477;&#20302;&#20102;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#25512;&#26029;&#20173;&#28982;&#26159;&#20219;&#20309;&#31185;&#23398;&#23478;&#26368;&#37325;&#35201;&#30340;&#24037;&#20855;&#20043;&#19968;&#65292;&#20294;&#26159;&#38543;&#30528;&#36234;&#26469;&#36234;&#22797;&#26434;&#30340;&#23454;&#39564;&#38656;&#35201;&#36234;&#26469;&#36234;&#26114;&#36149;&#30340;&#20284;&#28982;&#20989;&#25968;&#65292;&#29983;&#25104;&#21518;&#39564;&#27010;&#29575;&#30340;&#33945;&#29305;&#21345;&#32599;&#26679;&#26412;&#30340;&#25104;&#26412;&#20063;&#22312;&#22686;&#21152;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#21518;&#39564;&#36817;&#20284;&#27169;&#25311;&#22120;&#21644;&#20027;&#21160;&#37319;&#26679;&#30340;&#32467;&#21512;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#65292;&#20197;&#23454;&#29616;&#22312;&#26356;&#23569;&#30340;&#20284;&#28982;&#20989;&#25968;&#35780;&#20272;&#30340;&#24773;&#20917;&#19979;&#33719;&#24471;&#21487;&#27604;&#36739;&#30340;&#31934;&#24230;&#12290;&#35813;&#26041;&#27861;&#30340;&#20851;&#38190;&#22312;&#20110;&#25209;&#37327;&#33719;&#21462;&#24314;&#35758;&#65292;&#20197;&#20415;&#21487;&#20197;&#24182;&#34892;&#35780;&#20272;&#30495;&#27491;&#30340;&#21518;&#39564;&#27010;&#29575;&#12290;&#36825;&#36890;&#24120;&#36890;&#36807;&#36830;&#32493;&#26368;&#22823;&#21270;&#39640;&#24230;&#22810;&#23792;&#30340;&#33719;&#21462;&#20989;&#25968;&#26469;&#23454;&#29616;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#31181;&#26041;&#27861;&#30340;&#24182;&#34892;&#22788;&#29702;&#25928;&#26524;&#19981;&#22909;&#65292;&#23481;&#26131;&#38519;&#20837;&#23616;&#37096;&#26368;&#22823;&#20540;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#22312;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#24179;&#22343;&#39044;&#27979;&#19978;&#36827;&#34892;&#20960;&#20046;&#23604;&#23596;&#22320;&#24182;&#34892;&#20998;&#23618;&#37319;&#26679;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#22240;&#27492;&#20135;&#29983;&#30340;&#20960;&#20046;&#25490;&#24207;&#30340;&#33945;&#29305;&#21345;&#32599;&#26679;&#26412;&#21487;&#20197;&#24182;&#34892;&#35780;&#20272;&#65292;&#20174;&#32780;&#22312;&#20445;&#25345;&#36817;&#20284;&#21518;&#39564;&#30340;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#23454;&#29616;&#26174;&#33879;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian inference remains one of the most important tool-kits for any scientist, but increasingly expensive likelihood functions are required for ever-more complex experiments, raising the cost of generating a Monte Carlo sample of the posterior. Recent attention has been directed towards the use of emulators of the posterior based on Gaussian Process (GP) regression combined with active sampling to achieve comparable precision with far fewer costly likelihood evaluations. Key to this approach is the batched acquisition of proposals, so that the true posterior can be evaluated in parallel. This is usually achieved via sequential maximization of the highly multimodal acquisition function. Unfortunately, this approach parallelizes poorly and is prone to getting stuck in local maxima. Our approach addresses this issue by generating nearly-optimal batches of candidates using an almost-embarrassingly parallel Nested Sampler on the mean prediction of the GP. The resulting nearly-sorted Mont
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#20801;&#35768;&#20219;&#24847;&#25968;&#25454;&#25490;&#24207;&#30340;&#26222;&#36890;SGD&#31639;&#27861;,&#24182;&#34920;&#26126;&#22312;&#38750;&#20984;&#20989;&#25968;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#21644;&#21333;&#27425;&#27927;&#29260;&#30340;SGD&#27604;&#32463;&#20856;&#26367;&#25442;&#30340;SGD&#26356;&#24555;&#25110;&#33267;&#23569;&#19982;&#20854;&#19968;&#26679;&#22909;&#65292;&#26080;&#35770;&#36845;&#20195;&#27425;&#25968;&#22914;&#20309;&#12290;</title><link>http://arxiv.org/abs/2305.19259</link><description>&lt;p&gt;
Shuffle SGD&#24635;&#26159;&#27604;SGD&#26356;&#22909;&#65306;&#23545;&#20855;&#26377;&#20219;&#24847;&#25968;&#25454;&#39034;&#24207;&#30340;SGD&#36827;&#34892;&#25913;&#36827;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Shuffle SGD is Always Better than SGD: Improved Analysis of SGD with Arbitrary Data Orders. (arXiv:2305.19259v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19259
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#20801;&#35768;&#20219;&#24847;&#25968;&#25454;&#25490;&#24207;&#30340;&#26222;&#36890;SGD&#31639;&#27861;,&#24182;&#34920;&#26126;&#22312;&#38750;&#20984;&#20989;&#25968;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#21644;&#21333;&#27425;&#27927;&#29260;&#30340;SGD&#27604;&#32463;&#20856;&#26367;&#25442;&#30340;SGD&#26356;&#24555;&#25110;&#33267;&#23569;&#19982;&#20854;&#19968;&#26679;&#22909;&#65292;&#26080;&#35770;&#36845;&#20195;&#27425;&#25968;&#22914;&#20309;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#31639;&#27861;&#34987;&#24191;&#27867;&#29992;&#20110;&#20248;&#21270;&#31070;&#32463;&#32593;&#32476;&#65292;&#38543;&#26426;&#37325;&#25490;&#65288;RR&#65289;&#21644;&#21333;&#27425;&#27927;&#29260;&#65288;SS&#65289;&#26159;&#36890;&#36807;&#24490;&#29615;&#36941;&#21382;&#35757;&#32451;&#25968;&#25454;&#30340;&#38543;&#26426;&#25110;&#21333;&#20010;&#25490;&#21015;&#30340;&#24120;&#35265;&#36873;&#25321;&#65292;&#28982;&#32780;&#36825;&#20123;&#31639;&#27861;&#22312;&#38750;&#20984;&#24773;&#20917;&#19979;&#30340;&#25910;&#25947;&#24615;&#36136;&#23578;&#26410;&#23436;&#20840;&#29702;&#35299;&#12290;&#29616;&#26377;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#23454;&#38469;&#30340;&#35757;&#32451;&#22330;&#26223;&#20013;&#65292;&#24403;&#26102;&#20195;&#30340;&#25968;&#37327;&#23567;&#20110;&#35757;&#32451;&#38598;&#22823;&#23567;&#26102;&#65292;RR&#21487;&#33021;&#34920;&#29616;&#19981;&#22914;SGD&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;&#19968;&#31181;&#20801;&#35768;&#20219;&#24847;&#25968;&#25454;&#25490;&#24207;&#30340;&#26222;&#36890;SGD&#31639;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#38750;&#20984;&#20989;&#25968;&#24773;&#20917;&#19979;&#30340;&#25913;&#36827;&#25910;&#25947;&#36895;&#24230;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#38543;&#26426;&#21644;&#21333;&#27425;&#27927;&#29260;&#30340;SGD&#27604;&#32463;&#20856;&#26367;&#25442;&#30340;SGD&#26356;&#24555;&#25110;&#33267;&#23569;&#19982;&#20854;&#19968;&#26679;&#22909;&#65292;&#26080;&#35770;&#36845;&#20195;&#27425;&#25968;&#22914;&#20309;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#20984;&#26174;&#20102;&#20351;&#29992;&#38543;&#26426;/&#21333;&#27425;&#27927;&#29260;&#30340;SGD&#30340;&#22909;&#22788;&#65292;&#24182;&#20026;&#20854;&#38750;&#20984;&#25910;&#25947;&#24615;&#36136;&#25552;&#20379;&#20102;&#26032;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic Gradient Descent (SGD) algorithms are widely used in optimizing neural networks, with Random Reshuffling (RR) and Single Shuffle (SS) being popular choices for cycling through random or single permutations of the training data. However, the convergence properties of these algorithms in the non-convex case are not fully understood. Existing results suggest that, in realistic training scenarios where the number of epochs is smaller than the training set size, RR may perform worse than SGD.  In this paper, we analyze a general SGD algorithm that allows for arbitrary data orderings and show improved convergence rates for non-convex functions. Specifically, our analysis reveals that SGD with random and single shuffling is always faster or at least as good as classical SGD with replacement, regardless of the number of iterations. Overall, our study highlights the benefits of using SGD with random/single shuffling and provides new insights into its convergence properties for non-co
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;PAC-Bayes&#35757;&#32451;&#26694;&#26550;&#65292;&#26080;&#38656;&#39069;&#22806;&#27491;&#21017;&#21270;&#21644;&#32593;&#26684;&#25628;&#32034;&#35843;&#25972;&#36229;&#21442;&#25968;&#21363;&#21487;&#36798;&#21040;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#23218;&#32654;&#30340;&#27979;&#35797;&#24615;&#33021;&#65292;&#26174;&#33879;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#33021;&#21147;&#24182;&#20855;&#26377;&#23454;&#38469;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2305.19243</link><description>&lt;p&gt;
Auto-tune: &#31070;&#32463;&#32593;&#32476;&#30340;&#20808;&#39564;&#19982;&#21518;&#39564;PAC-Bayes&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Auto-tune: PAC-Bayes Optimization over Prior and Posterior for Neural Networks. (arXiv:2305.19243v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19243
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;PAC-Bayes&#35757;&#32451;&#26694;&#26550;&#65292;&#26080;&#38656;&#39069;&#22806;&#27491;&#21017;&#21270;&#21644;&#32593;&#26684;&#25628;&#32034;&#35843;&#25972;&#36229;&#21442;&#25968;&#21363;&#21487;&#36798;&#21040;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#23218;&#32654;&#30340;&#27979;&#35797;&#24615;&#33021;&#65292;&#26174;&#33879;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#33021;&#21147;&#24182;&#20855;&#26377;&#23454;&#38469;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#31934;&#24515;&#35774;&#35745;&#35757;&#32451;&#36807;&#31243;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#30446;&#21069;&#26368;&#20808;&#36827;&#30340;&#35757;&#32451;&#26041;&#27861;&#28041;&#21450;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#25110;Adam&#20248;&#21270;&#31639;&#27861;&#65292;&#20197;&#21450;&#39069;&#22806;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#22914;&#26435;&#37325;&#34928;&#20943;&#12289;Dropout&#25110;&#22122;&#22768;&#27880;&#20837;&#12290;&#36890;&#36807;&#32593;&#26684;&#25628;&#32034;&#35843;&#25972;&#25968;&#37327;&#20247;&#22810;&#30340;&#36229;&#21442;&#25968;&#25165;&#33021;&#36798;&#21040;&#26368;&#20248;&#27867;&#21270;&#65292;&#36825;&#21487;&#33021;&#32791;&#26102;&#65292;&#24182;&#38656;&#35201;&#39069;&#22806;&#30340;&#39564;&#35777;&#25968;&#25454;&#38598;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20999;&#23454;&#21487;&#34892;&#30340;PAC-Bayes&#35757;&#32451;&#26694;&#26550;&#65292;&#20960;&#20046;&#26159;&#26080;&#38656;&#35843;&#25972;&#65292;&#20063;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#27491;&#21017;&#21270;&#65292;&#32780;&#22312;&#23436;&#25104;&#32593;&#26684;&#25628;&#32034;&#21644;&#21152;&#20837;&#39069;&#22806;&#27491;&#21017;&#21270;&#21518;&#65292;&#36798;&#21040;&#20102;&#19982;SGD/Adam&#21487;&#27604;&#36739;&#30340;&#27979;&#35797;&#24615;&#33021;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#23637;&#31034;&#20102;PAC&#35757;&#32451;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#19978;&#23454;&#29616;&#26368;&#20808;&#36827;&#24615;&#33021;&#30340;&#26174;&#33879;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is widely recognized that the generalization ability of neural networks can be greatly enhanced through carefully designing the training procedure. The current state-of-the-art training approach involves utilizing stochastic gradient descent (SGD) or Adam optimization algorithms along with a combination of additional regularization techniques such as weight decay, dropout, or noise injection. Optimal generalization can only be achieved by tuning a multitude of hyperparameters through grid search, which can be time-consuming and necessitates additional validation datasets. To address this issue, we introduce a practical PAC-Bayes training framework that is nearly tuning-free and requires no additional regularization while achieving comparable testing performance to that of SGD/Adam after a complete grid search and with extra regularizations. Our proposed algorithm demonstrates the remarkable potential of PAC training to achieve state-of-the-art performance on deep neural networks wit
&lt;/p&gt;</description></item><item><title>dotears&#26159;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;DAG&#32467;&#26500;&#23398;&#20064;&#26694;&#26550;&#65292;&#20351;&#29992;&#35266;&#27979;&#21644;&#24178;&#39044;&#25968;&#25454;&#26469;&#25512;&#26029;&#21333;&#20010;&#22240;&#26524;&#32467;&#26500;&#12290;&#23427;&#30452;&#25509;&#20272;&#35745;&#22806;&#29983;&#35823;&#24046;&#32467;&#26500;&#65292;&#36991;&#20813;&#20102;&#24490;&#29615;&#20272;&#35745;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.19215</link><description>&lt;p&gt;
dotears: &#20351;&#29992;&#35266;&#27979;&#21644;&#24178;&#39044;&#25968;&#25454;&#36827;&#34892;&#21487;&#25193;&#23637;&#21644;&#19968;&#33268;&#30340;DAG&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
dotears: Scalable, consistent DAG estimation using observational and interventional data. (arXiv:2305.19215v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19215
&lt;/p&gt;
&lt;p&gt;
dotears&#26159;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;DAG&#32467;&#26500;&#23398;&#20064;&#26694;&#26550;&#65292;&#20351;&#29992;&#35266;&#27979;&#21644;&#24178;&#39044;&#25968;&#25454;&#26469;&#25512;&#26029;&#21333;&#20010;&#22240;&#26524;&#32467;&#26500;&#12290;&#23427;&#30452;&#25509;&#20272;&#35745;&#22806;&#29983;&#35823;&#24046;&#32467;&#26500;&#65292;&#36991;&#20813;&#20102;&#24490;&#29615;&#20272;&#35745;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#22240;&#26524;&#26377;&#21521;&#26080;&#29615;&#22270; (DAG)&#38754;&#20020;&#30528;&#21487;&#36776;&#35782;&#24615;&#32570;&#22833;&#21644;&#35299;&#20915;&#26041;&#26696;&#32452;&#21512;&#31354;&#38388;&#30340;&#22797;&#26434;&#24615;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#25552;&#39640;&#20102;&#35266;&#27979;&#25968;&#25454;&#20013;&#22522;&#20110;&#24471;&#20998;&#30340;DAG&#32467;&#26500;&#23398;&#20064;&#30340;&#21487;&#25805;&#20316;&#24615;&#65292;&#20294;&#23545;&#22806;&#29983;&#35823;&#24046;&#26041;&#24046;&#30340;&#32467;&#26500;&#25935;&#24863;&#12290;&#21516;&#26102;&#65292;&#20174;&#35266;&#27979;&#25968;&#25454;&#23398;&#20064;&#22806;&#29983;&#26041;&#24046;&#32467;&#26500;&#38656;&#35201;&#32467;&#26500;&#30340;&#20808;&#39564;&#30693;&#35782;&#12290;&#38024;&#23545;&#26032;&#30340;&#29983;&#29289;&#25216;&#26415;&#65292;&#23558;&#39640;&#24230;&#24182;&#34892;&#30340;&#22522;&#22240;&#24178;&#39044;&#19982;&#39640;&#32500;&#35266;&#27979;&#25968;&#25454;&#32852;&#31995;&#36215;&#26469;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#32467;&#26500;&#23398;&#20064;&#26694;&#26550;dotears&#65292;&#36890;&#36807;&#36830;&#32493;&#20248;&#21270;&#21033;&#29992;&#35266;&#27979;&#21644;&#24178;&#39044;&#25968;&#25454;&#26469;&#25512;&#26029;&#21333;&#20010;&#22240;&#26524;&#32467;&#26500;&#12290;dotears&#21033;&#29992;&#24178;&#39044;&#30340;&#21487;&#39044;&#27979;&#30340;&#32467;&#26500;&#21518;&#26524;&#30452;&#25509;&#20272;&#35745;&#22806;&#29983;&#35823;&#24046;&#32467;&#26500;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#24490;&#29615;&#20272;&#35745;&#38382;&#39064;&#12290;&#25105;&#20204;&#25193;&#23637;&#20102;&#20808;&#21069;&#30340;&#24037;&#20316;&#65292;&#20174;&#32463;&#39564;&#21644;&#20998;&#26512;&#26041;&#38754;&#36827;&#34892;&#20102;&#23637;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning causal directed acyclic graphs (DAGs) from data is complicated by a lack of identifiability and the combinatorial space of solutions. Recent work has improved tractability of score-based structure learning of DAGs in observational data, but is sensitive to the structure of the exogenous error variances. On the other hand, learning exogenous variance structure from observational data requires prior knowledge of structure. Motivated by new biological technologies that link highly parallel gene interventions to a high-dimensional observation, we present $\texttt{dotears}$ [doo-tairs], a scalable structure learning framework which leverages observational and interventional data to infer a single causal structure through continuous optimization. $\texttt{dotears}$ exploits predictable structural consequences of interventions to directly estimate the exogenous error structure, bypassing the circular estimation problem. We extend previous work to show, both empirically and analytical
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#23545;&#20110;&#20302;&#31209;&#30697;&#38453;&#36924;&#36817;&#38382;&#39064;&#65292;&#20351;&#29992;&#23567;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#20855;&#26377;&#38750;&#24120;&#24555;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#23588;&#20854;&#26159;&#24403;&#26368;&#22823;&#29305;&#24449;&#20540;&#30456;&#21516;&#26102;&#12290;&#36864;&#21270;&#33258;&#30001;&#31639;&#27861;&#27604;Riemannian&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#26356;&#26377;&#25928;&#65292;&#22312;&#36816;&#34892;&#26102;&#38388;&#19978;&#21487;&#20197;&#20943;&#23569;29&#65285;&#12290;</title><link>http://arxiv.org/abs/2305.19206</link><description>&lt;p&gt;
&#20302;&#31209;&#30697;&#38453;&#36924;&#36817;&#30340;&#26799;&#24230;&#19979;&#38477;&#20840;&#23616;&#24555;&#36895;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Fast global convergence of gradient descent for low-rank matrix approximation. (arXiv:2305.19206v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19206
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#23545;&#20110;&#20302;&#31209;&#30697;&#38453;&#36924;&#36817;&#38382;&#39064;&#65292;&#20351;&#29992;&#23567;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#20855;&#26377;&#38750;&#24120;&#24555;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#23588;&#20854;&#26159;&#24403;&#26368;&#22823;&#29305;&#24449;&#20540;&#30456;&#21516;&#26102;&#12290;&#36864;&#21270;&#33258;&#30001;&#31639;&#27861;&#27604;Riemannian&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#26356;&#26377;&#25928;&#65292;&#22312;&#36816;&#34892;&#26102;&#38388;&#19978;&#21487;&#20197;&#20943;&#23569;29&#65285;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#27714;&#35299;&#20302;&#31209;&#30697;&#38453;&#36924;&#36817;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#23545;&#20110;&#23545;&#31216;&#30697;&#38453;&#36924;&#36817;&#65292;&#26799;&#24230;&#19979;&#38477;&#30340;&#23616;&#37096;&#32447;&#24615;&#25910;&#25947;&#24615;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#26799;&#24230;&#19979;&#38477;&#22312;&#20351;&#29992;&#38543;&#26426;&#23567;&#20540;&#21021;&#22987;&#21270;&#26102;&#20855;&#26377;&#38750;&#24120;&#24555;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#21363;&#20351;&#26159;&#22312;&#20013;&#31561;&#22823;&#23567;&#30340;&#38543;&#26426;&#21021;&#22987;&#21270;&#24773;&#20917;&#19979;&#65292;&#21253;&#25324;&#20351;&#29992;&#23567;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#29305;&#27530;&#24773;&#20917;&#22312;&#20869;&#65292;&#24403;&#26368;&#22823;&#29305;&#24449;&#20540;&#30456;&#21516;&#26102;&#65292;&#26799;&#24230;&#19979;&#38477;&#22312;&#24555;&#36895;&#25910;&#25947;&#26041;&#38754;&#20063;&#20855;&#26377;&#24456;&#22909;&#30340;&#25928;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#25105;&#20204;&#30340;&#20998;&#26512;&#20197;&#35299;&#20915;&#38750;&#23545;&#31216;&#30697;&#38453;&#36924;&#36817;&#38382;&#39064;&#65292;&#24182;&#35843;&#26597;&#20102;&#19968;&#31181;&#19981;&#20381;&#36182;&#25237;&#24433;&#30340;&#29305;&#24449;&#31354;&#38388;&#35745;&#31639;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#25968;&#20540;&#23454;&#39564;&#24378;&#28872;&#25903;&#25345;&#25105;&#20204;&#30340;&#29702;&#35770;&#12290;&#29305;&#21035;&#22320;&#65292;&#36864;&#21270;&#33258;&#30001;&#31639;&#27861;&#20248;&#20110;&#23545;&#24212;&#30340;Riemannian&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#23548;&#33268;&#36816;&#34892;&#26102;&#38388;&#26174;&#30528;&#20943;&#23569;&#20102;29&#65285;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates gradient descent for solving low-rank matrix approximation problems. We begin by establishing the local linear convergence of gradient descent for symmetric matrix approximation. Building on this result, we prove the rapid global convergence of gradient descent, particularly when initialized with small random values. Remarkably, we show that even with moderate random initialization, which includes small random initialization as a special case, gradient descent achieves fast global convergence in scenarios where the top eigenvalues are identical. Furthermore, we extend our analysis to address asymmetric matrix approximation problems and investigate the effectiveness of a retraction-free eigenspace computation method. Numerical experiments strongly support our theory. In particular, the retraction-free algorithm outperforms the corresponding Riemannian gradient descent method, resulting in a significant 29\% reduction in runtime.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#24212;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#20449;&#24230;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#30740;&#31350;&#40657;&#30418;&#27169;&#22411;&#20013;&#32622;&#20449;&#24230;&#19982;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#36873;&#25321;&#24615;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#12290;</title><link>http://arxiv.org/abs/2305.19187</link><description>&lt;p&gt;
&#29983;&#25104;&#21487;&#20449;&#30340;&#25991;&#26412;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Generating with Confidence: Uncertainty Quantification for Black-box Large Language Models. (arXiv:2305.19187v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19187
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#24212;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#20449;&#24230;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#30740;&#31350;&#40657;&#30418;&#27169;&#22411;&#20013;&#32622;&#20449;&#24230;&#19982;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#36873;&#25321;&#24615;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#65292;&#19987;&#38376;&#29992;&#20110;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#21508;&#20010;&#39046;&#22495;&#34920;&#29616;&#20986;&#20102;&#24456;&#22909;&#30340;&#33021;&#21147;&#65292;&#20294;&#26159;&#35780;&#20272;LLMs&#29983;&#25104;&#30340;&#32467;&#26524;&#30340;&#21487;&#20449;&#24230;&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#65292;&#20851;&#20110;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#30740;&#31350;&#20063;&#36739;&#23569;&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#30340;&#25991;&#29486;&#36890;&#24120;&#20551;&#23450;&#23545;&#35821;&#35328;&#27169;&#22411;&#30340;&#30333;&#30418;&#35775;&#38382;&#65292;&#36825;&#35201;&#20040;&#26159;&#30001;&#20110;&#26368;&#26032;&#30340;LLMs&#30340;&#23553;&#38381;&#28304;&#20195;&#30721;&#30340;&#24615;&#36136;&#65292;&#35201;&#20040;&#26159;&#30001;&#20110;&#35745;&#31639;&#38480;&#21046;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#40657;&#30418;LLMs&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#21306;&#20998;&#20102;&#20004;&#31181;&#23494;&#20999;&#30456;&#20851;&#30340;&#27010;&#24565;: &#21482;&#19982;&#36755;&#20837;&#26377;&#20851;&#30340;&#8220;&#19981;&#30830;&#23450;&#24615;&#8221;&#21644;&#36824;&#19982;&#29983;&#25104;&#30340;&#22238;&#22797;&#26377;&#20851;&#30340;&#8220;&#32622;&#20449;&#24230;&#8221;&#12290;&#28982;&#21518;&#25105;&#20204;&#25552;&#20986;&#24182;&#27604;&#36739;&#20102;&#20960;&#20010;&#32622;&#20449;&#24230;/&#19981;&#30830;&#23450;&#24230;&#25351;&#26631;&#65292;&#23558;&#23427;&#20204;&#24212;&#29992;&#20110;&#8220;&#36873;&#25321;&#24615;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#8221;&#65292;&#20854;&#20013;&#19981;&#21487;&#38752;&#30340;&#32467;&#26524;&#21487;&#20197;&#34987;&#24573;&#30053;&#25110;&#32773;&#31227;&#20132;&#32473;&#36827;&#19968;&#27493;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) specializing in natural language generation (NLG) have recently started exhibiting promising capabilities across a variety of domains. However, gauging the trustworthiness of responses generated by LLMs remains an open challenge, with limited research on uncertainty quantification for NLG. Furthermore, existing literature typically assumes white-box access to language models, which is becoming unrealistic either due to the closed-source nature of the latest LLMs or due to computational constraints. In this work, we investigate uncertainty quantification in NLG for $\textit{black-box}$ LLMs. We first differentiate two closely-related notions: $\textit{uncertainty}$, which depends only on the input, and $\textit{confidence}$, which additionally depends on the generated response. We then propose and compare several confidence/uncertainty metrics, applying them to $\textit{selective NLG}$, where unreliable results could either be ignored or yielded for further 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;Bayesian&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#26469;&#21387;&#32553;&#25968;&#25454;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270; $\beta$-ELBO &#30452;&#25509;&#20248;&#21270;&#30721;-&#22833;&#30495;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#35843;&#25972; $\beta$ &#26469;&#38024;&#23545;&#32473;&#23450;&#30340;&#32593;&#32476;&#32467;&#26500;&#23454;&#29616;&#19981;&#21516;&#30340;&#30721;-&#22833;&#30495;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2305.19185</link><description>&lt;p&gt;
Bayesian&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#19979;&#30340;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
Compression with Bayesian Implicit Neural Representations. (arXiv:2305.19185v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19185
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;Bayesian&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#26469;&#21387;&#32553;&#25968;&#25454;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270; $\beta$-ELBO &#30452;&#25509;&#20248;&#21270;&#30721;-&#22833;&#30495;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#35843;&#25972; $\beta$ &#26469;&#38024;&#23545;&#32473;&#23450;&#30340;&#32593;&#32476;&#32467;&#26500;&#23454;&#29616;&#19981;&#21516;&#30340;&#30721;-&#22833;&#30495;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#24120;&#35265;&#31867;&#22411;&#30340;&#25968;&#25454;&#21487;&#20197;&#34920;&#31034;&#20026;&#23558;&#22352;&#26631;&#26144;&#23556;&#21040;&#20449;&#21495;&#20540;&#30340;&#20989;&#25968;&#65292;&#20363;&#22914;&#22270;&#20687;&#20013;&#30340;&#20687;&#32032;&#20301;&#32622;&#21040;RGB&#20540;&#12290;&#22522;&#20110;&#36825;&#20010;&#35266;&#28857;&#65292;&#21487;&#20197;&#36890;&#36807;&#23545;&#25968;&#25454;&#30340;&#21151;&#33021;&#34920;&#31034;&#36827;&#34892;&#36229;&#25311;&#21512;&#65292;&#28982;&#21518;&#32534;&#30721;&#32593;&#32476;&#26435;&#37325;&#26469;&#21387;&#32553;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#24403;&#21069;&#30340;&#35299;&#20915;&#26041;&#26696;&#37117;&#25928;&#29575;&#20302;&#19979;&#65292;&#22240;&#20026;&#23558;&#31934;&#24230;&#37327;&#21270;&#21040;&#20302;&#27604;&#29305;&#20250;&#22823;&#24133;&#38477;&#20302;&#37325;&#26500;&#36136;&#37327;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36807;&#24230;&#25311;&#21512;&#21464;&#20998;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26469;&#21387;&#32553;&#36817;&#20284;&#21518;&#39564;&#26435;&#37325;&#26679;&#26412;&#65292;&#32780;&#19981;&#26159;&#37327;&#21270;&#21644;&#29109;&#32534;&#30721;&#23427;&#12290;&#35813;&#31574;&#30053;&#36890;&#36807;&#26368;&#23567;&#21270; $\beta$-ELBO &#30452;&#25509;&#20248;&#21270;&#30721;-&#22833;&#30495;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#35843;&#25972; $\beta$ &#26469;&#38024;&#23545;&#32473;&#23450;&#30340;&#32593;&#32476;&#32467;&#26500;&#23454;&#29616;&#19981;&#21516;&#30340;&#30721;-&#22833;&#30495;&#24179;&#34913;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#23398;&#20064;&#20808;&#39564;&#26435;&#37325;&#20998;&#24067;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#24182;&#37319;&#29992;&#20027;&#21160;&#23610;&#23544;&#35843;&#25972;&#26469;&#36827;&#19968;&#27493;&#25552;&#39640;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many common types of data can be represented as functions that map coordinates to signal values, such as pixel locations to RGB values in the case of an image. Based on this view, data can be compressed by overfitting a compact neural network to its functional representation and then encoding the network weights. However, most current solutions for this are inefficient, as quantization to low-bit precision substantially degrades the reconstruction quality. To address this issue, we propose overfitting variational Bayesian neural networks to the data and compressing an approximate posterior weight sample using relative entropy coding instead of quantizing and entropy coding it. This strategy enables direct optimization of the rate-distortion performance by minimizing the $\beta$-ELBO, and target different rate-distortion trade-offs for a given network architecture by adjusting $\beta$. Moreover, we introduce an iterative algorithm for learning prior weight distributions and employ a pro
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21512;&#20316;&#38408;&#20540; Lasso &#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#22810;&#26234;&#33021;&#20307;&#31232;&#30095;&#19978;&#19979;&#25991;&#32447;&#24615; Bandit &#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#38477;&#32500;&#19982;&#20449;&#24687;&#20849;&#20139;&#65292;&#20197;&#38477;&#20302;&#36890;&#20449;&#25104;&#26412;&#65292;&#21516;&#26102;&#20445;&#35777;&#27599;&#20010;&#26234;&#33021;&#20307;&#30340;&#26368;&#23567;&#32047;&#35745;&#36951;&#25022;&#12290;</title><link>http://arxiv.org/abs/2305.19161</link><description>&lt;p&gt;
&#21512;&#20316;&#38408;&#20540; Lasso &#22788;&#29702;&#31232;&#30095;&#32447;&#24615; Bandit &#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Cooperative Thresholded Lasso for Sparse Linear Bandit. (arXiv:2305.19161v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19161
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21512;&#20316;&#38408;&#20540; Lasso &#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#22810;&#26234;&#33021;&#20307;&#31232;&#30095;&#19978;&#19979;&#25991;&#32447;&#24615; Bandit &#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#38477;&#32500;&#19982;&#20449;&#24687;&#20849;&#20139;&#65292;&#20197;&#38477;&#20302;&#36890;&#20449;&#25104;&#26412;&#65292;&#21516;&#26102;&#20445;&#35777;&#27599;&#20010;&#26234;&#33021;&#20307;&#30340;&#26368;&#23567;&#32047;&#35745;&#36951;&#25022;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#22810;&#26234;&#33021;&#20307;&#31232;&#30095;&#19978;&#19979;&#25991;&#32447;&#24615; Bandit &#38382;&#39064;&#65292;&#20854;&#20013;&#29305;&#24449;&#21521;&#37327;&#20855;&#26377;&#39640;&#32500;&#24230; $d$&#65292;&#32780;&#22870;&#21169;&#20989;&#25968;&#20165;&#20381;&#36182;&#20110;&#19968;&#32452;&#26377;&#38480;&#30340;&#29305;&#24449;&#65292;&#31934;&#30830;&#22320;&#20026; $s_0 \ll d$&#12290;&#27492;&#22806;&#65292;&#23398;&#20064;&#22312;&#20449;&#24687;&#20849;&#20139;&#32422;&#26463;&#19979;&#36827;&#34892;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#37319;&#29992; Lasso &#22238;&#24402;&#36827;&#34892;&#38477;&#32500;&#65292;&#20801;&#35768;&#27599;&#20010;&#26234;&#33021;&#20307;&#29420;&#31435;&#20272;&#35745;&#19968;&#20010;&#36817;&#20284;&#30340;&#20027;&#32500;&#24230;&#38598;&#21512;&#65292;&#24182;&#26681;&#25454;&#32593;&#32476;&#32467;&#26500;&#19982;&#20854;&#20182;&#26234;&#33021;&#20307;&#20849;&#20139;&#35813;&#20449;&#24687;&#12290;&#28982;&#21518;&#36890;&#36807;&#29305;&#23450;&#30340;&#36807;&#31243;&#32858;&#21512;&#20449;&#24687;&#24182;&#19982;&#25152;&#26377;&#26234;&#33021;&#20307;&#20849;&#20139;&#12290;&#28982;&#21518;&#65292;&#27599;&#20010;&#26234;&#33021;&#20307;&#21482;&#20851;&#27880;&#25552;&#21462;&#30340;&#32500;&#24230;&#65292;&#36890;&#36807;&#23725;&#22238;&#24402;&#35299;&#20915;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#38024;&#23545;&#26143;&#24418;&#32593;&#32476;&#21644;&#28857;&#23545;&#28857;&#32593;&#32476;&#30340;&#31639;&#27861;&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#30830;&#20445;&#27599;&#20010;&#26234;&#33021;&#20307;&#30340;&#26368;&#23567;&#32047;&#35745;&#36951;&#25022;&#30340;&#21516;&#26102;&#26377;&#25928;&#22320;&#38477;&#20302;&#20102;&#36890;&#20449;&#25104;&#26412;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#20855;&#26377; $O(s_0 \sqrt{T \log d})$ &#21644; $O(\sqrt{s_0} \sqrt{T \log d})$ &#30340;&#36951;&#25022;&#30028;&#65292;&#20854;&#20013; $T$ &#34920;&#31034;&#25152;&#26377;&#26234;&#33021;&#20307;&#29609;&#28216;&#25103;&#30340;&#22238;&#21512;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel approach to address the multi-agent sparse contextual linear bandit problem, in which the feature vectors have a high dimension $d$ whereas the reward function depends on only a limited set of features precisely $s_0 \ll d$. Furthermore, the learning follows under information-sharing constraints. The proposed method employs Lasso regression for dimension reduction, allowing each agent to independently estimate an approximate set of main dimensions and share that information with others depending on the network's structure. The information is then aggregated through a specific process and shared with all agents. Each agent then resolves the problem with ridge regression focusing solely on the extracted dimensions. We represent algorithms for both a star-shaped network and a peer-to-peer network. The approaches effectively reduce communication costs while ensuring minimal cumulative regret per agent. Theoretically, we show that our proposed methods have a regret boun
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22522;&#20110;&#24433;&#21709;&#20989;&#25968;&#20960;&#20309;&#25552;&#20986;&#20102;&#19968;&#20010;&#30697;&#21305;&#37197;&#26694;&#26550;&#26469;&#36866;&#24212;&#26631;&#31614;&#20559;&#31227;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#8220;&#39640;&#25928;&#26631;&#31614;&#20559;&#31227;&#36866;&#24212;&#8221;&#30340;&#36866;&#24212;&#26041;&#27861;&#65292;&#20855;&#26377;&#19968;&#33268;&#24615;&#21644;&#28176;&#36827;&#27491;&#24577;&#24615;&#65292;&#21487;&#22312;&#19981;&#38656;&#35201;&#21518;&#39044;&#27979;&#26657;&#20934;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#26368;&#20808;&#36827;&#30340;&#20272;&#35745;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.19123</link><description>&lt;p&gt;
ELSA: &#22522;&#20110;&#21322;&#21442;&#25968;&#27169;&#22411;&#30340;&#39640;&#25928;&#26631;&#31614;&#20559;&#31227;&#36866;&#24212;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
ELSA: Efficient Label Shift Adaptation through the Lens of Semiparametric Models. (arXiv:2305.19123v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19123
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22522;&#20110;&#24433;&#21709;&#20989;&#25968;&#20960;&#20309;&#25552;&#20986;&#20102;&#19968;&#20010;&#30697;&#21305;&#37197;&#26694;&#26550;&#26469;&#36866;&#24212;&#26631;&#31614;&#20559;&#31227;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#8220;&#39640;&#25928;&#26631;&#31614;&#20559;&#31227;&#36866;&#24212;&#8221;&#30340;&#36866;&#24212;&#26041;&#27861;&#65292;&#20855;&#26377;&#19968;&#33268;&#24615;&#21644;&#28176;&#36827;&#27491;&#24577;&#24615;&#65292;&#21487;&#22312;&#19981;&#38656;&#35201;&#21518;&#39044;&#27979;&#26657;&#20934;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#26368;&#20808;&#36827;&#30340;&#20272;&#35745;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26631;&#31614;&#20559;&#31227;&#19979;&#30340;&#22495;&#36866;&#24212;&#38382;&#39064;&#12290;&#22312;&#26631;&#31614;&#20559;&#31227;&#30340;&#24773;&#20917;&#19979;&#65292;&#26631;&#31614;&#30340;&#36793;&#38469;&#20998;&#24067;&#22312;&#35757;&#32451;&#38598;&#21644;&#27979;&#35797;&#38598;&#20043;&#38388;&#19981;&#21516;&#65292;&#32780;&#32473;&#23450;&#26631;&#31614;&#30340;&#29305;&#24449;&#30340;&#26465;&#20214;&#20998;&#24067;&#30456;&#21516;&#12290;&#20256;&#32479;&#30340;&#26631;&#31614;&#20559;&#31227;&#36866;&#24212;&#26041;&#27861;&#35201;&#20040;&#23384;&#22312;&#20272;&#35745;&#35823;&#24046;&#36739;&#22823;&#30340;&#38382;&#39064;&#65292;&#35201;&#20040;&#38656;&#35201;&#32321;&#29712;&#30340;&#21518;&#39044;&#27979;&#26657;&#20934;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#24433;&#21709;&#20989;&#25968;&#20960;&#20309;&#30340;&#30697;&#21305;&#37197;&#26694;&#26550;&#26469;&#36866;&#24212;&#26631;&#31614;&#20559;&#31227;&#12290;&#22312;&#27492;&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#39640;&#25928;&#26631;&#31614;&#20559;&#31227;&#36866;&#24212;&#8221;&#30340;&#26032;&#26041;&#27861;(ELSA)&#65292;&#20854;&#20013;&#36866;&#24212;&#26435;&#37325;&#21487;&#20197;&#36890;&#36807;&#35299;&#32447;&#24615;&#31995;&#32479;&#26469;&#20272;&#35745;&#12290;&#20174;&#29702;&#35770;&#19978;&#35762;&#65292;ELSA&#20272;&#35745;&#22120;&#26159;$\sqrt{n}$-&#19968;&#33268;&#30340;(n&#26159;&#28304;&#25968;&#25454;&#30340;&#26679;&#26412;&#22823;&#23567;)&#65292;&#32780;&#19988;&#26159;&#28176;&#36827;&#27491;&#24577;&#30340;&#12290;&#23454;&#38469;&#19978;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;ELSA&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#37117;&#21487;&#20197;&#22312;&#19981;&#38656;&#35201;&#21518;&#39044;&#27979;&#26657;&#20934;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#26368;&#20808;&#36827;&#30340;&#20272;&#35745;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the domain adaptation problem with label shift in this work. Under the label shift context, the marginal distribution of the label varies across the training and testing datasets, while the conditional distribution of features given the label is the same. Traditional label shift adaptation methods either suffer from large estimation errors or require cumbersome post-prediction calibrations. To address these issues, we first propose a moment-matching framework for adapting the label shift based on the geometry of the influence function. Under such a framework, we propose a novel method named \underline{E}fficient \underline{L}abel \underline{S}hift \underline{A}daptation (ELSA), in which the adaptation weights can be estimated by solving linear systems. Theoretically, the ELSA estimator is $\sqrt{n}$-consistent ($n$ is the sample size of the source data) and asymptotically normal. Empirically, we show that ELSA can achieve state-of-the-art estimation performances without post-p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27979;&#37327;&#20102;Barron&#31354;&#38388;&#21644;&#35889;Barron&#31354;&#38388;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#25552;&#20379;&#20102;&#23884;&#20837;&#19981;&#31561;&#24335;&#12290;</title><link>http://arxiv.org/abs/2305.19082</link><description>&lt;p&gt;
Barron&#22411;&#31354;&#38388;&#30340;&#23884;&#20837;&#19981;&#31561;&#24335;
&lt;/p&gt;
&lt;p&gt;
Embedding Inequalities for Barron-type Spaces. (arXiv:2305.19082v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19082
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27979;&#37327;&#20102;Barron&#31354;&#38388;&#21644;&#35889;Barron&#31354;&#38388;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#25552;&#20379;&#20102;&#23884;&#20837;&#19981;&#31561;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#26159;&#29702;&#35299;&#39640;&#32500;&#26465;&#20214;&#19979;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#21644;&#27867;&#21270;&#24615;&#36136;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#30740;&#31350;&#20154;&#21592;&#24341;&#20837;&#20102;Barron&#31354;&#38388;$\mathcal{B}_s(\Omega)$&#21644;&#35889;Barron&#31354;&#38388;$\mathcal{F}_s(\Omega)$&#65292;&#20854;&#20013;&#25351;&#25968;$s$&#34920;&#24449;&#20102;&#36825;&#20123;&#31354;&#38388;&#20013;&#20989;&#25968;&#30340;&#24179;&#28369;&#24615;&#65292;$\Omega\subset\mathbb{R}^d$&#34920;&#31034;&#36755;&#20837;&#22495;&#12290;&#28982;&#32780;&#65292;&#20004;&#31181;&#31867;&#22411;&#30340;Barron&#31354;&#38388;&#20043;&#38388;&#30340;&#20851;&#31995;&#20173;&#19981;&#28165;&#26970;&#12290;&#26412;&#25991;&#36890;&#36807;&#20197;&#19979;&#19981;&#31561;&#24335;&#24314;&#31435;&#20102;&#36825;&#20123;&#31354;&#38388;&#20043;&#38388;&#30340;&#36830;&#32493;&#23884;&#20837;&#65306;&#23545;&#20110;&#20219;&#24847;$\delta\in(0,1),s\in\mathbb{N}^{+}$&#21644;$f:\Omega \mapsto \mathbb{R}$&#65292;&#37117;&#26377;\[ \delta\gamma^{\delta-s}_{\Omega}\|f\|_{\mathcal{F}_{s-\delta}(\Omega)}\lesssim_s \|f\|_{\mathcal{B}_s(\Omega)}\lesssim_s \|f\|_{\mathcal{F}_{s+1}(\Omega)}, \]&#20854;&#20013;$\gamma_{\Omega}=\sup_{\|v\|_2=1,x\in\Omega}|v^Tx|$&#65292;$\lesssim_s$&#34920;&#31034;&#20165;&#19982;&#24179;&#28369;&#21442;&#25968;$s$&#26377;&#20851;&#30340;&#24120;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
One of the fundamental problems in deep learning theory is understanding the approximation and generalization properties of two-layer neural networks in high dimensions. In order to tackle this issue, researchers have introduced the Barron space $\mathcal{B}_s(\Omega)$ and the spectral Barron space $\mathcal{F}_s(\Omega)$, where the index $s$ characterizes the smoothness of functions within these spaces and $\Omega\subset\mathbb{R}^d$ represents the input domain. However, it is still not clear what is the relationship between the two types of Barron spaces. In this paper, we establish continuous embeddings between these spaces as implied by the following inequality: for any $\delta\in (0,1), s\in \mathbb{N}^{+}$ and $f: \Omega \mapsto\mathbb{R}$, it holds that \[ \delta\gamma^{\delta-s}_{\Omega}\|f\|_{\mathcal{F}_{s-\delta}(\Omega)}\lesssim_s \|f\|_{\mathcal{B}_s(\Omega)}\lesssim_s \|f\|_{\mathcal{F}_{s+1}(\Omega)}, \] where $\gamma_{\Omega}=\sup_{\|v\|_2=1,x\in\Omega}|v^Tx|$ and notab
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20302;&#21442;&#25968;&#35757;&#32451;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#23558;&#21367;&#31215;&#20998;&#35299;&#20026;&#24352;&#37327;Tucker&#26684;&#24335;&#65292;&#24182;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#33258;&#36866;&#24212;&#22320;&#20462;&#21098;&#21367;&#31215;&#26680;&#30340;Tucker&#31209;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#38477;&#20302;&#35757;&#32451;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2305.19059</link><description>&lt;p&gt;
&#35757;&#32451;&#26399;&#38388;&#30340;&#33258;&#36866;&#24212;&#31209;&#35889;&#21098;&#26525;&#21367;&#31215;&#23618;
&lt;/p&gt;
&lt;p&gt;
Rank-adaptive spectral pruning of convolutional layers during training. (arXiv:2305.19059v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19059
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20302;&#21442;&#25968;&#35757;&#32451;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#23558;&#21367;&#31215;&#20998;&#35299;&#20026;&#24352;&#37327;Tucker&#26684;&#24335;&#65292;&#24182;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#33258;&#36866;&#24212;&#22320;&#20462;&#21098;&#21367;&#31215;&#26680;&#30340;Tucker&#31209;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#38477;&#20302;&#35757;&#32451;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22312;&#35745;&#31639;&#25104;&#26412;&#21644;&#20869;&#23384;&#38656;&#27714;&#26041;&#38754;&#22686;&#38271;&#36805;&#36895;&#65292;&#22240;&#27492;&#24050;&#32463;&#21457;&#23637;&#20102;&#21508;&#31181;&#21098;&#26525;&#25216;&#26415;&#20197;&#20943;&#23569;&#27169;&#22411;&#21442;&#25968;&#12290;&#22823;&#22810;&#25968;&#25216;&#26415;&#20391;&#37325;&#20110;&#36890;&#36807;&#22312;&#23436;&#25972;&#35757;&#32451;&#21518;&#23545;&#32593;&#32476;&#36827;&#34892;&#20462;&#21098;&#20197;&#20943;&#23569;&#25512;&#29702;&#25104;&#26412;&#12290;&#23569;&#37327;&#30340;&#26041;&#27861;&#35299;&#20915;&#20102;&#20943;&#23569;&#35757;&#32451;&#25104;&#26412;&#30340;&#38382;&#39064;&#65292;&#20027;&#35201;&#26159;&#36890;&#36807;&#20302;&#31209;&#23618;&#20998;&#35299;&#26469;&#21387;&#32553;&#32593;&#32476;&#12290;&#23613;&#31649;&#36825;&#20123;&#26041;&#27861;&#23545;&#20110;&#32447;&#24615;&#23618;&#26159;&#26377;&#25928;&#30340;&#65292;&#20294;&#26159;&#23427;&#20204;&#26080;&#27861;&#26377;&#25928;&#22788;&#29702;&#21367;&#31215;&#28388;&#27874;&#22120;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20302;&#21442;&#25968;&#35757;&#32451;&#26041;&#27861;&#65292;&#23558;&#21367;&#31215;&#20998;&#35299;&#20026;&#24352;&#37327;Tucker&#26684;&#24335;&#65292;&#24182;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#33258;&#36866;&#24212;&#22320;&#20462;&#21098;&#21367;&#31215;&#26680;&#30340;Tucker&#31209;&#12290;&#21033;&#29992;&#24494;&#20998;&#26041;&#31243;&#22312;&#24352;&#37327;&#27969;&#24418;&#19978;&#30340;&#20960;&#20309;&#31215;&#20998;&#29702;&#35770;&#30340;&#22522;&#26412;&#32467;&#26524;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19968;&#20010;&#40065;&#26834;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#35777;&#26126;&#33021;&#22815;&#36924;&#36817;&#23436;&#25972;&#30340;&#22522;&#32447;&#24615;&#33021;&#24182;&#20445;&#35777;&#25439;&#22833;&#19979;&#38477;&#12290;
&lt;/p&gt;
&lt;p&gt;
The computing cost and memory demand of deep learning pipelines have grown fast in recent years and thus a variety of pruning techniques have been developed to reduce model parameters. The majority of these techniques focus on reducing inference costs by pruning the network after a pass of full training. A smaller number of methods address the reduction of training costs, mostly based on compressing the network via low-rank layer factorizations. Despite their efficiency for linear layers, these methods fail to effectively handle convolutional filters. In this work, we propose a low-parametric training method that factorizes the convolutions into tensor Tucker format and adaptively prunes the Tucker ranks of the convolutional kernel during training. Leveraging fundamental results from geometric integration theory of differential equations on tensor manifolds, we obtain a robust training algorithm that provably approximates the full baseline performance and guarantees loss descent. A var
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28909;&#25193;&#25955;&#35270;&#35282;&#30340;&#22320;&#24418;&#20445;&#25345;&#38477;&#32500;&#26041;&#27861;&#65292;&#24314;&#31435;&#20102;&#28909;&#25193;&#25955;&#19982;&#27969;&#24418;&#36317;&#31163;&#20043;&#38388;&#30340;&#29702;&#35770;&#32852;&#31995;&#12290;&#35813;&#26041;&#27861;&#22312;&#20445;&#25345;&#27969;&#24418;&#36317;&#31163;&#21644;&#31751;&#32467;&#26500;&#26041;&#38754;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.19043</link><description>&lt;p&gt;
&#22522;&#20110;&#28909;&#25193;&#25955;&#35270;&#35282;&#30340;&#22320;&#24418;&#20445;&#25345;&#38477;&#32500;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Heat Diffusion Perspective on Geodesic Preserving Dimensionality Reduction. (arXiv:2305.19043v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19043
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28909;&#25193;&#25955;&#35270;&#35282;&#30340;&#22320;&#24418;&#20445;&#25345;&#38477;&#32500;&#26041;&#27861;&#65292;&#24314;&#31435;&#20102;&#28909;&#25193;&#25955;&#19982;&#27969;&#24418;&#36317;&#31163;&#20043;&#38388;&#30340;&#29702;&#35770;&#32852;&#31995;&#12290;&#35813;&#26041;&#27861;&#22312;&#20445;&#25345;&#27969;&#24418;&#36317;&#31163;&#21644;&#31751;&#32467;&#26500;&#26041;&#38754;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#25193;&#25955;&#30340;&#27969;&#24418;&#23398;&#20064;&#26041;&#27861;&#22312;&#22788;&#29702;&#29616;&#20195;&#39640;&#32500;&#12289;&#39640;&#36890;&#37327;&#12289;&#22122;&#22768;&#25968;&#25454;&#38598;&#30340;&#34920;&#31034;&#23398;&#20064;&#21644;&#38477;&#32500;&#20013;&#24050;&#32463;&#35777;&#26126;&#38750;&#24120;&#26377;&#29992;&#65292;&#29305;&#21035;&#26159;&#22312;&#29983;&#29289;&#23398;&#21644;&#29289;&#29702;&#23398;&#31561;&#39046;&#22495;&#12290;&#34429;&#28982;&#20154;&#20204;&#35748;&#20026;&#36825;&#20123;&#26041;&#27861;&#36890;&#36807;&#23398;&#20064;&#27979;&#22320;&#32447;&#36317;&#31163;&#30340;&#20195;&#29702;&#26469;&#20445;&#25345;&#25968;&#25454;&#30340;&#24213;&#23618;&#27969;&#24418;&#32467;&#26500;&#65292;&#20294;&#27809;&#26377;&#30830;&#20999;&#30340;&#29702;&#35770;&#32852;&#31995;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#32467;&#26524;&#24314;&#31435;&#20102;&#36825;&#26679;&#30340;&#32852;&#31995;&#65292;&#26126;&#30830;&#20102;&#28909;&#25193;&#25955;&#19982;&#27969;&#24418;&#36317;&#31163;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#22312;&#27492;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#26222;&#36941;&#30340;&#22522;&#20110;&#28909;&#26680;&#30340;&#27969;&#24418;&#23884;&#20837;&#26041;&#27861;&#65292;&#31216;&#20026;&#28909;&#27979;&#22320;&#32447;&#23884;&#20837;&#12290;&#36825;&#31181;&#26032;&#39062;&#30340;&#35270;&#35282;&#20351;&#27969;&#24418;&#23398;&#20064;&#21644;&#21435;&#22122;&#20013;&#30340;&#36873;&#25321;&#26356;&#21152;&#28165;&#26224;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20445;&#25345;&#22522;&#20934;&#27969;&#24418;&#36317;&#31163;&#21644;&#20445;&#25345;&#29609;&#20855;&#25968;&#25454;&#38598;&#20013;&#30340;&#31751;&#32467;&#26500;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#21333;&#32454;&#32990;RNA&#27979;&#24207;&#25968;&#25454;&#19978;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion-based manifold learning methods have proven useful in representation learning and dimensionality reduction of modern high dimensional, high throughput, noisy datasets. Such datasets are especially present in fields like biology and physics. While it is thought that these methods preserve underlying manifold structure of data by learning a proxy for geodesic distances, no specific theoretical links have been established. Here, we establish such a link via results in Riemannian geometry explicitly connecting heat diffusion to manifold distances. In this process, we also formulate a more general heat kernel based manifold embedding method that we call heat geodesic embeddings. This novel perspective makes clearer the choices available in manifold learning and denoising. Results show that our method outperforms existing state of the art in preserving ground truth manifold distances, and preserving cluster structure in toy datasets. We also showcase our method on single cell RNA-s
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25581;&#31034;&#20102;&#28145;&#24230;&#23398;&#20064;&#31070;&#32463;&#32593;&#36335;&#23398;&#20064;&#36755;&#20837;&#20302;&#32500;&#24230;&#34920;&#31034;&#21644;&#26368;&#23567;&#21270;&#29305;&#24449;&#26144;&#23556;&#20013;&#30340;&#22797;&#26434;&#24615;/&#19981;&#35268;&#21017;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#25511;&#21046;&#20102;&#35268;&#24459;&#24615;&#65292;&#24182;&#21033;&#29992;&#29702;&#35770;&#24037;&#20855;&#35777;&#26126;&#20102;&#29942;&#39048;&#32467;&#26500;&#30340;&#23384;&#22312;&#12290;</title><link>http://arxiv.org/abs/2305.19008</link><description>&lt;p&gt;
&#23398;&#20064;&#29305;&#24449;&#20013;&#30340;&#29942;&#39048;&#32467;&#26500;&#65306;&#20302;&#32500;&#24230;&#19982;&#35268;&#24459;&#24615;&#30340;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
Bottleneck Structure in Learned Features: Low-Dimension vs Regularity Tradeoff. (arXiv:2305.19008v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19008
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25581;&#31034;&#20102;&#28145;&#24230;&#23398;&#20064;&#31070;&#32463;&#32593;&#36335;&#23398;&#20064;&#36755;&#20837;&#20302;&#32500;&#24230;&#34920;&#31034;&#21644;&#26368;&#23567;&#21270;&#29305;&#24449;&#26144;&#23556;&#20013;&#30340;&#22797;&#26434;&#24615;/&#19981;&#35268;&#21017;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#25511;&#21046;&#20102;&#35268;&#24459;&#24615;&#65292;&#24182;&#21033;&#29992;&#29702;&#35770;&#24037;&#20855;&#35777;&#26126;&#20102;&#29942;&#39048;&#32467;&#26500;&#30340;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#30740;&#31350;&#34920;&#26126;&#65292;&#20855;&#26377;&#22823;&#28145;&#24230;$L$&#21644;$L_{2}$&#27491;&#21017;&#21270;&#30340;DNN&#20559;&#21521;&#20110;&#23398;&#20064;&#36755;&#20837;&#30340;&#20302;&#32500;&#34920;&#31034;&#65292;&#21487;&#20197;&#35299;&#37322;&#20026;&#26368;&#23567;&#21270;&#23398;&#20064;&#20989;&#25968;$f$&#30340;&#31209;$R^{(0)}(f)$&#30340;&#27010;&#24565;&#65292;&#20854;&#34987;&#25512;&#27979;&#20026;&#29942;&#39048;&#31209;&#12290;&#25105;&#20204;&#35745;&#31639;&#20102;&#36825;&#20010;&#32467;&#26524;&#30340;&#26377;&#38480;&#28145;&#24230;&#20462;&#27491;&#65292;&#25581;&#31034;&#20102;&#19968;&#20010;&#24230;&#37327;$R^{(1)}$&#30340;&#35268;&#24459;&#24615;&#65292;&#23427;&#25511;&#21046;&#20102;&#38597;&#21487;&#27604;&#30697;&#38453;$\left|Jf(x)\right|_{+}$&#30340;&#20266;&#34892;&#21015;&#24335;&#24182;&#22312;&#32452;&#21512;&#21644;&#21152;&#27861;&#19979;&#26159;&#27425;&#21487;&#21152;&#30340;&#12290;&#36825;&#20351;&#24471;&#32593;&#32476;&#21487;&#20197;&#22312;&#23398;&#20064;&#20302;&#32500;&#34920;&#31034;&#21644;&#26368;&#23567;&#21270;&#29305;&#24449;&#26144;&#23556;&#20013;&#30340;&#22797;&#26434;&#24615;/&#19981;&#35268;&#21017;&#24615;&#20043;&#38388;&#20445;&#25345;&#24179;&#34913;&#65292;&#20174;&#32780;&#23398;&#20064;&#8220;&#27491;&#30830;&#8221;&#30340;&#20869;&#37096;&#23610;&#23544;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22823;&#23398;&#20064;&#36895;&#29575;&#22914;&#20309;&#25511;&#21046;&#23398;&#20064;&#20989;&#25968;&#30340;&#35268;&#24459;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#36825;&#20123;&#29702;&#35770;&#24037;&#20855;&#35777;&#26126;&#20102;&#29942;&#39048;&#32467;&#26500;&#22312;$L\to\infty$&#26102;&#22312;&#23398;&#20064;&#29305;&#24449;&#20013;&#30340;&#29468;&#24819;&#65306;&#23545;&#20110;&#22823;&#28145;&#24230;&#65292;&#20960;&#20046;&#25152;&#26377;&#30340;&#38544;&#34255;&#34920;&#31034;&#37117;&#38598;&#20013;&#22312;...
&lt;/p&gt;
&lt;p&gt;
Previous work has shown that DNNs with large depth $L$ and $L_{2}$-regularization are biased towards learning low-dimensional representations of the inputs, which can be interpreted as minimizing a notion of rank $R^{(0)}(f)$ of the learned function $f$, conjectured to be the Bottleneck rank. We compute finite depth corrections to this result, revealing a measure $R^{(1)}$ of regularity which bounds the pseudo-determinant of the Jacobian $\left|Jf(x)\right|_{+}$ and is subadditive under composition and addition. This formalizes a balance between learning low-dimensional representations and minimizing complexity/irregularity in the feature maps, allowing the network to learn the `right' inner dimension. We also show how large learning rates also control the regularity of the learned function. Finally, we use these theoretical tools to prove the conjectured bottleneck structure in the learned features as $L\to\infty$: for large depths, almost all hidden representations concentrates aroun
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#20010;&#24191;&#27867;&#20351;&#29992;&#30340;&#31639;&#27861;&#25152;&#38656;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#20855;&#26377;&#39640;&#27010;&#29575;&#25910;&#25947;&#20445;&#35777;&#19988;&#19982;&#23481;&#24046;&#27700;&#24179;&#30340;&#20851;&#32852;&#24615;&#26368;&#20339;&#12290;</title><link>http://arxiv.org/abs/2305.19001</link><description>&lt;p&gt;
&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#31574;&#30053;&#35780;&#20272;&#30340;&#39640;&#27010;&#29575;&#26679;&#26412;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
Sharp high-probability sample complexities for policy evaluation with linear function approximation. (arXiv:2305.19001v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19001
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#20010;&#24191;&#27867;&#20351;&#29992;&#30340;&#31639;&#27861;&#25152;&#38656;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#20855;&#26377;&#39640;&#27010;&#29575;&#25910;&#25947;&#20445;&#35777;&#19988;&#19982;&#23481;&#24046;&#27700;&#24179;&#30340;&#20851;&#32852;&#24615;&#26368;&#20339;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#28041;&#21450;&#20351;&#29992;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#22312;&#26080;&#38480;&#26102;&#38388;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#36827;&#34892;&#31574;&#30053;&#35780;&#20272;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#31574;&#30053;&#35780;&#20272;&#31639;&#27861;&#65288;&#26102;&#38388;&#24046;&#20998;&#23398;&#20064;&#31639;&#27861;&#21644;&#24102;&#26377;&#26799;&#24230;&#26657;&#27491;&#30340;&#20004;&#20010;&#26102;&#38388;&#23610;&#24230;&#32447;&#24615;&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;&#65289;&#25152;&#38656;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#20197;&#20445;&#35777;&#26368;&#20339;&#32447;&#24615;&#31995;&#25968;&#30340;&#39044;&#23450;&#20041;&#20272;&#35745;&#35823;&#24046;&#12290;&#22312;&#31574;&#30053;&#35774;&#32622;&#21644;&#31163;&#32447;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#31532;&#19968;&#20010;&#20855;&#26377;&#39640;&#27010;&#29575;&#25910;&#25947;&#20445;&#35777;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#65292;&#36798;&#21040;&#20102;&#19982;&#23481;&#24046;&#27700;&#24179;&#30340;&#26368;&#20339;&#20851;&#32852;&#24615;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#19982;&#38382;&#39064;&#30456;&#20851;&#37327;&#26126;&#30830;&#30340;&#20851;&#31995;&#65292;&#24182;&#22312;&#31574;&#30053;&#35774;&#32622;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#19978;&#38480;&#30028;&#38480;&#19982;&#20851;&#38190;&#38382;&#39064;&#21442;&#25968;&#19978;&#30340;&#26497;&#23567;&#26497;&#22823;&#19979;&#38480;&#30028;&#38480;&#30456;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is concerned with the problem of policy evaluation with linear function approximation in discounted infinite horizon Markov decision processes. We investigate the sample complexities required to guarantee a predefined estimation error of the best linear coefficients for two widely-used policy evaluation algorithms: the temporal difference (TD) learning algorithm and the two-timescale linear TD with gradient correction (TDC) algorithm. In both the on-policy setting, where observations are generated from the target policy, and the off-policy setting, where samples are drawn from a behavior policy potentially different from the target policy, we establish the first sample complexity bound with high-probability convergence guarantee that attains the optimal dependence on the tolerance level. We also exhihit an explicit dependence on problem-related quantities, and show in the on-policy setting that our upper bound matches the minimax lower bound on crucial problem parameters, in
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#20915;&#31574;&#26641;&#21644;&#38543;&#26426;&#26862;&#26519;&#26469;&#23450;&#20301;&#24191;&#20041;&#33258;&#22238;&#24402;&#24471;&#20998;&#27169;&#22411;&#30340;&#21442;&#25968;&#65292;&#25913;&#21892;&#20854;&#39044;&#27979;&#65292;&#24182;&#25581;&#31034;&#20102;&#32929;&#31080;&#22238;&#25253;&#27874;&#21160;&#29575;&#21644;&#23494;&#24230;&#39044;&#27979;&#20013;&#30340;&#26464;&#26438;&#25928;&#24212;&#21644;&#26041;&#24046;&#39118;&#38505;&#28322;&#20215;&#25928;&#24212;&#65292;&#20197;&#21450;&#32929;&#31080;-&#20538;&#21048;&#20381;&#36182;&#24615;&#20013;&#30340;&#27969;&#21521;&#36136;&#37327;&#25928;&#24212;&#21644;&#39640;&#39057;&#20132;&#26131;&#25345;&#32493;&#26102;&#38388;&#20013;&#30340;&#25104;&#20132;&#37327;-&#27874;&#21160;&#24615;&#25928;&#24212;&#12290;</title><link>http://arxiv.org/abs/2305.18991</link><description>&lt;p&gt;
&#24191;&#20041;&#33258;&#22238;&#24402;&#24471;&#20998;&#26641;&#19982;&#26862;&#26519;
&lt;/p&gt;
&lt;p&gt;
Generalized Autoregressive Score Trees and Forests. (arXiv:2305.18991v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18991
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#20915;&#31574;&#26641;&#21644;&#38543;&#26426;&#26862;&#26519;&#26469;&#23450;&#20301;&#24191;&#20041;&#33258;&#22238;&#24402;&#24471;&#20998;&#27169;&#22411;&#30340;&#21442;&#25968;&#65292;&#25913;&#21892;&#20854;&#39044;&#27979;&#65292;&#24182;&#25581;&#31034;&#20102;&#32929;&#31080;&#22238;&#25253;&#27874;&#21160;&#29575;&#21644;&#23494;&#24230;&#39044;&#27979;&#20013;&#30340;&#26464;&#26438;&#25928;&#24212;&#21644;&#26041;&#24046;&#39118;&#38505;&#28322;&#20215;&#25928;&#24212;&#65292;&#20197;&#21450;&#32929;&#31080;-&#20538;&#21048;&#20381;&#36182;&#24615;&#20013;&#30340;&#27969;&#21521;&#36136;&#37327;&#25928;&#24212;&#21644;&#39640;&#39057;&#20132;&#26131;&#25345;&#32493;&#26102;&#38388;&#20013;&#30340;&#25104;&#20132;&#37327;-&#27874;&#21160;&#24615;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#20915;&#31574;&#26641;&#21644;&#38543;&#26426;&#26862;&#26519;&#26469;&#23450;&#20301;&#24191;&#20041;&#33258;&#22238;&#24402;&#24471;&#20998;&#65288;GAS&#65289;&#27169;&#22411;&#65288;Creal et. al, 2013; Harvey, 2013&#65289;&#30340;&#21442;&#25968;&#65292;&#20174;&#32780;&#25913;&#21892;&#20854;&#39044;&#27979;&#12290;&#36825;&#20123;&#26041;&#27861;&#36991;&#20813;&#20102;&#22522;&#20110;&#26680;&#20989;&#25968;&#30340;&#26041;&#27861;&#25152;&#38754;&#20020;&#30340;&#32500;&#24230;&#28798;&#38590;&#65292;&#24182;&#20801;&#35768;&#21516;&#26102;&#21033;&#29992;&#22810;&#20010;&#29366;&#24577;&#21464;&#37327;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#23558;&#26032;&#27169;&#22411;&#24212;&#29992;&#20110;&#22235;&#31181;&#19981;&#21516;&#30340;&#23454;&#35777;&#20998;&#26512;&#20013;&#65292;&#24182;&#19988;&#22312;&#25152;&#26377;&#24212;&#29992;&#20013;&#65292;&#26032;&#30340;&#26041;&#27861;&#37117;&#26174;&#33879;&#20248;&#20110;&#22522;&#32447;GAS&#27169;&#22411;&#12290;&#22312;&#25105;&#20204;&#24212;&#29992;&#20110;&#32929;&#31080;&#22238;&#25253;&#27874;&#21160;&#29575;&#21644;&#23494;&#24230;&#39044;&#27979;&#30340;&#23454;&#39564;&#20013;&#65292;&#26368;&#20248;&#30340;GAS&#26641;&#27169;&#22411;&#25581;&#31034;&#20102;&#26464;&#26438;&#25928;&#24212;&#21644;&#26041;&#24046;&#39118;&#38505;&#28322;&#20215;&#25928;&#24212;&#12290;&#25105;&#20204;&#22312;&#32929;&#31080;-&#20538;&#21048;&#20381;&#36182;&#24615;&#30340;&#30740;&#31350;&#20013;&#21457;&#29616;&#20102;&#20248;&#21270;&#30340;GAS&#26862;&#26519;&#39044;&#27979;&#20013;&#30340;&#27969;&#21521;&#36136;&#37327;&#25928;&#24212;&#65292;&#25105;&#20204;&#23545;&#39640;&#39057;&#20132;&#26131;&#25345;&#32493;&#26102;&#38388;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;&#25104;&#20132;&#37327;-&#27874;&#21160;&#24615;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose methods to improve the forecasts from generalized autoregressive score (GAS) models (Creal et. al, 2013; Harvey, 2013) by localizing their parameters using decision trees and random forests. These methods avoid the curse of dimensionality faced by kernel-based approaches, and allow one to draw on information from multiple state variables simultaneously. We apply the new models to four distinct empirical analyses, and in all applications the proposed new methods significantly outperform the baseline GAS model. In our applications to stock return volatility and density prediction, the optimal GAS tree model reveals a leverage effect and a variance risk premium effect. Our study of stock-bond dependence finds evidence of a flight-to-quality effect in the optimal GAS forest forecasts, while our analysis of high-frequency trade durations uncovers a volume-volatility effect.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#21253;&#25324;&#24322;&#24120;&#28857;&#30340;&#39640;&#32500;&#20581;&#22766;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#20351;&#29992;&#19981;&#21516;&#25439;&#22833;&#20989;&#25968;&#30340;&#31934;&#30830;&#28176;&#36817;&#29305;&#24615;&#65292;&#23545;&#27867;&#21270;&#35823;&#24046;&#36827;&#34892;&#20102;&#31616;&#21333;&#26657;&#20934;&#24182;&#35745;&#31639;&#20102;&#25910;&#25947;&#36895;&#29575;&#65292;&#20294;&#30001;&#20110;&#33539;&#25968;&#26657;&#20934;&#19981;&#21305;&#37197;&#65292;&#23545;&#20272;&#35745;&#35823;&#24046;&#30340;&#19968;&#33268;&#24615;&#38656;&#35201;&#19968;&#20010;&#36739;&#24378;&#30340;&#25910;&#25947;&#20551;&#35774;&#12290;</title><link>http://arxiv.org/abs/2305.18974</link><description>&lt;p&gt;
&#24322;&#24120;&#28857;&#23384;&#22312;&#26102;&#20581;&#22766;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#24615;&#33021;&#30340;&#28176;&#36827;&#29305;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Asymptotic Characterisation of Robust Empirical Risk Minimisation Performance in the Presence of Outliers. (arXiv:2305.18974v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18974
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#21253;&#25324;&#24322;&#24120;&#28857;&#30340;&#39640;&#32500;&#20581;&#22766;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#20351;&#29992;&#19981;&#21516;&#25439;&#22833;&#20989;&#25968;&#30340;&#31934;&#30830;&#28176;&#36817;&#29305;&#24615;&#65292;&#23545;&#27867;&#21270;&#35823;&#24046;&#36827;&#34892;&#20102;&#31616;&#21333;&#26657;&#20934;&#24182;&#35745;&#31639;&#20102;&#25910;&#25947;&#36895;&#29575;&#65292;&#20294;&#30001;&#20110;&#33539;&#25968;&#26657;&#20934;&#19981;&#21305;&#37197;&#65292;&#23545;&#20272;&#35745;&#35823;&#24046;&#30340;&#19968;&#33268;&#24615;&#38656;&#35201;&#19968;&#20010;&#36739;&#24378;&#30340;&#25910;&#25947;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#39640;&#32500;&#20581;&#22766;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#65292;&#24403;&#32500;&#24230;$d$&#21644;&#25968;&#25454;&#28857;&#25968;&#37327;$n$&#20197;&#22266;&#23450;&#27604;&#29575;$\alpha=n/d$&#21457;&#25955;&#65292;&#24182;&#30740;&#31350;&#20102;&#21253;&#25324;&#24322;&#24120;&#28857;&#22312;&#20869;&#30340;&#25968;&#25454;&#27169;&#22411;&#12290;&#25105;&#20204;&#23545;&#20351;&#29992;$\ell_2$ -&#27491;&#21017;&#21270;$\ell_2$&#65292;$\ell_1$&#65292;&#21644; Huber &#25439;&#22833;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;ERM&#65289;&#24615;&#33021;&#25552;&#20379;&#20102;&#31934;&#30830;&#30340;&#28176;&#36817;&#29305;&#24615;&#65292;&#36825;&#26159;&#35299;&#20915;&#36825;&#31867;&#38382;&#39064;&#30340;&#26631;&#20934;&#26041;&#27861;&#12290;&#25105;&#20204;&#20851;&#27880;&#24615;&#33021;&#30340;&#20004;&#20010;&#25351;&#26631;&#65306;&#20855;&#26377;&#24322;&#24120;&#28857;&#30340;&#30456;&#20284;&#25968;&#25454;&#38598;&#30340;&#27867;&#21270;&#35823;&#24046;&#21644;&#21407;&#22987;&#26080;&#27745;&#26579;&#20989;&#25968;&#30340;&#20272;&#35745;&#35823;&#24046;&#12290;&#25105;&#20204;&#23558;&#32467;&#26524;&#19982;&#20449;&#24687;&#35770;&#36125;&#21494;&#26031;&#26368;&#20248;&#20272;&#35745;&#30028;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#23545;&#20110;&#27867;&#21270;&#35823;&#24046;&#65292;&#25105;&#20204;&#21457;&#29616;&#22914;&#26524;&#36827;&#34892;&#31616;&#21333;&#30340;&#26657;&#20934;&#24182;&#35745;&#31639;&#25910;&#25947;&#36895;&#29575;&#65292;&#21017;&#26368;&#20248;&#27491;&#21017;&#21270;ERM&#22312;&#22823;&#26679;&#26412;&#22797;&#26434;&#24230;&#38480;&#21046;&#19979;&#26159;&#28176;&#36817;&#19968;&#33268;&#30340;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#20272;&#35745;&#35823;&#24046;&#65292;&#30001;&#20110;&#33539;&#25968;&#26657;&#20934;&#19981;&#21305;&#37197;&#65292;&#25105;&#20204;&#34920;&#26126;&#20272;&#35745;&#22120;&#30340;&#19968;&#33268;&#24615;&#38656;&#35201;&#19968;&#20010;&#36739;&#24378;&#30340;&#25910;&#25947;&#20551;&#35774;&#65292;&#36825;&#23545;&#38382;&#39064;&#30340;&#35299;&#20915;&#36824;&#38656;&#35201;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study robust linear regression in high-dimension, when both the dimension $d$ and the number of data points $n$ diverge with a fixed ratio $\alpha=n/d$, and study a data model that includes outliers. We provide exact asymptotics for the performances of the empirical risk minimisation (ERM) using $\ell_2$-regularised $\ell_2$, $\ell_1$, and Huber loss, which are the standard approach to such problems. We focus on two metrics for the performance: the generalisation error to similar datasets with outliers, and the estimation error of the original, unpolluted function. Our results are compared with the information theoretic Bayes-optimal estimation bound. For the generalization error, we find that optimally-regularised ERM is asymptotically consistent in the large sample complexity limit if one perform a simple calibration, and compute the rates of convergence. For the estimation error however, we show that due to a norm calibration mismatch, the consistency of the estimator requires an
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22810;&#36890;&#36947;&#30417;&#30563;&#23398;&#20064;&#30340;&#37327;&#23376;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#30828;&#20214;&#36866;&#24212;&#24615;&#30340;&#37327;&#23376;&#30005;&#36335;ansatzes&#29992;&#20316;&#21367;&#31215;&#26680;&#65292;&#33021;&#22815;&#26377;&#25928;&#23398;&#20064;&#36890;&#36947;&#38388;&#20449;&#24687;&#65292;&#20248;&#20110;&#29616;&#26377;&#30340;QCNNs&#12290;</title><link>http://arxiv.org/abs/2305.18961</link><description>&lt;p&gt;
&#22810;&#36890;&#36947;&#30417;&#30563;&#23398;&#20064;&#30340;&#37327;&#23376;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Quantum Convolutional Neural Networks for Multi-Channel Supervised Learning. (arXiv:2305.18961v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18961
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22810;&#36890;&#36947;&#30417;&#30563;&#23398;&#20064;&#30340;&#37327;&#23376;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#30828;&#20214;&#36866;&#24212;&#24615;&#30340;&#37327;&#23376;&#30005;&#36335;ansatzes&#29992;&#20316;&#21367;&#31215;&#26680;&#65292;&#33021;&#22815;&#26377;&#25928;&#23398;&#20064;&#36890;&#36947;&#38388;&#20449;&#24687;&#65292;&#20248;&#20110;&#29616;&#26377;&#30340;QCNNs&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30340;&#24555;&#36895;&#21457;&#23637;&#65292;&#21046;&#36896;&#20986;&#38750;&#24120;&#26377;&#29992;&#30340;&#24037;&#20855;&#21644;&#27169;&#22411;&#65292;&#37327;&#23376;&#35745;&#31639;&#20026;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#25552;&#20379;&#21152;&#36895;&#30340;&#28508;&#21147;&#27491;&#22312;&#26085;&#30410;&#21463;&#21040;&#37325;&#35270;&#12290;&#29305;&#21035;&#26159;&#65292;&#30740;&#31350;&#29992;&#20110;&#22522;&#20110;&#22270;&#20687;&#26816;&#27979;&#20219;&#21153;&#30340;&#37327;&#23376;&#30005;&#36335;&#21462;&#20195;&#32463;&#20856;&#21367;&#31215;&#28388;&#27874;&#22120;&#20197;&#21033;&#29992;&#37327;&#23376;&#20248;&#21183;&#30340;&#23581;&#35797;&#65292;&#31216;&#20026;&#37327;&#23376;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;QCNNs&#65289;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#23581;&#35797;&#32570;&#20047;&#22788;&#29702;&#20855;&#26377;&#22810;&#20010;&#36890;&#36947;&#30340;&#25968;&#25454;&#30340;&#33021;&#21147;&#65292;&#22240;&#27492;&#21482;&#36866;&#29992;&#20110;&#30456;&#23545;&#31616;&#21333;&#30340;&#36755;&#20837;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22810;&#31181;&#30828;&#20214;&#36866;&#24212;&#24615;&#30340;&#37327;&#23376;&#30005;&#36335;ansatzes&#29992;&#20316;&#21367;&#31215;&#26680;&#65292;&#24182;&#35777;&#26126;&#25105;&#20204;&#25253;&#21578;&#30340;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#22312;&#28041;&#21450;&#22810;&#36890;&#36947;&#25968;&#25454;&#30340;&#20998;&#31867;&#20219;&#21153;&#20013;&#20248;&#20110;&#29616;&#26377;&#30340;QCNNs&#12290;&#25105;&#20204;&#39044;&#35745;&#65292;&#36825;&#20123;&#23454;&#29616;&#26377;&#25928;&#23398;&#20064;&#36890;&#36947;&#38388;&#20449;&#24687;&#30340;&#33021;&#21147;&#23558;&#20801;&#35768;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#22312;&#22788;&#29702;&#29616;&#23454;&#20219;&#21153;&#26102;&#33719;&#24471;&#37325;&#22823;&#31361;&#30772;&#12290;
&lt;/p&gt;
&lt;p&gt;
As the rapidly evolving field of machine learning continues to produce incredibly useful tools and models, the potential for quantum computing to provide speed up for machine learning algorithms is becoming increasingly desirable. In particular, quantum circuits in place of classical convolutional filters for image detection-based tasks are being investigated for the ability to exploit quantum advantage. However, these attempts, referred to as quantum convolutional neural networks (QCNNs), lack the ability to efficiently process data with multiple channels and therefore are limited to relatively simple inputs. In this work, we present a variety of hardware-adaptable quantum circuit ansatzes for use as convolutional kernels, and demonstrate that the quantum neural networks we report outperform existing QCNNs on classification tasks involving multi-channel data. We envision that the ability of these implementations to effectively learn inter-channel information will allow quantum machine
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25253;&#36947;&#20102;Clip21&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#36866;&#29992;&#20110;&#26799;&#24230;&#35009;&#21098;&#30340;&#20998;&#24067;&#24335;&#35757;&#32451;&#30340;&#26377;&#25928;&#35823;&#24046;&#21453;&#39304;&#26041;&#27861;&#65292;&#33021;&#22815;&#35299;&#20915;&#20005;&#37325;&#30340;&#25910;&#25947;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#20854;&#25910;&#25947;&#36895;&#24230;&#19982;&#20998;&#24067;&#24335;&#26041;&#27861;&#30456;&#21516;&#12290;</title><link>http://arxiv.org/abs/2305.18929</link><description>&lt;p&gt;
Clip21&#65306;&#26799;&#24230;&#35009;&#21098;&#30340;&#35823;&#24046;&#21453;&#39304;
&lt;/p&gt;
&lt;p&gt;
Clip21: Error Feedback for Gradient Clipping. (arXiv:2305.18929v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18929
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25253;&#36947;&#20102;Clip21&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#36866;&#29992;&#20110;&#26799;&#24230;&#35009;&#21098;&#30340;&#20998;&#24067;&#24335;&#35757;&#32451;&#30340;&#26377;&#25928;&#35823;&#24046;&#21453;&#39304;&#26041;&#27861;&#65292;&#33021;&#22815;&#35299;&#20915;&#20005;&#37325;&#30340;&#25910;&#25947;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#20854;&#25910;&#25947;&#36895;&#24230;&#19982;&#20998;&#24067;&#24335;&#26041;&#27861;&#30456;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#21040;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#32422;&#26463;&#19979;&#22823;&#35268;&#27169;&#35757;&#32451;&#30340;&#26085;&#30410;&#26222;&#21450;&#21644;&#37325;&#35201;&#24615;&#30340;&#25512;&#21160;&#65292;&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#26799;&#24230;&#35009;&#21098;&#30340;&#20998;&#24067;&#24335;&#26799;&#24230;&#26041;&#27861;&#65292;&#21363;&#22312;&#33410;&#28857;&#22788;&#35745;&#31639;&#30340;&#26799;&#24230;&#24212;&#29992;&#35009;&#21098;&#12290;&#34429;&#28982;&#26799;&#24230;&#35009;&#21098;&#26159;&#23558;&#27491;&#24335;DP&#20445;&#35777;&#27880;&#20837;&#26799;&#24230;&#20026;&#22522;&#30784;&#30340;&#26041;&#27861;&#30340;&#37325;&#35201;&#24037;&#20855;&#65292;&#20294;&#23427;&#20063;&#20250;&#24341;&#20837;&#20559;&#24046;&#65292;&#20174;&#32780;&#24341;&#36215;&#20998;&#24067;&#24335;&#29615;&#22659;&#19979;&#20005;&#37325;&#30340;&#25910;&#25947;&#38382;&#39064;&#12290;&#21551;&#21457;&#20110;&#26368;&#36817;&#22312;&#35823;&#24046;&#21453;&#39304;&#25991;&#29486;&#20013;&#21462;&#24471;&#30340;&#36827;&#23637;&#65292;&#35813;&#25991;&#29486;&#38598;&#20013;&#20110;&#39535;&#26381;&#36890;&#20449;&#21387;&#32553;&#36816;&#31639;&#31526;&#65288;&#20363;&#22914;Top - k&#65289;&#24341;&#20837;&#30340;&#20559;&#24046;/&#35823;&#24046;&#65292;&#20197;&#21450;&#35009;&#21098;&#36816;&#31639;&#31526;&#19982;&#25910;&#32553;&#21387;&#32553;&#36816;&#31639;&#31526;&#20043;&#38388;&#30340;&#25968;&#23398;&#30456;&#20284;&#24615;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102; Clip21&#65292;&#36825;&#26159;&#20998;&#24067;&#24335;&#26799;&#24230;&#35009;&#21098;&#30340;&#31532;&#19968;&#20010;&#33021;&#22815;&#34987;&#35777;&#26126;&#26377;&#25928;&#19988;&#23454;&#29992;&#30340;&#35823;&#24046;&#21453;&#39304;&#26426;&#21046;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#20998;&#24067;&#24335;&#25910;&#25947;&#36895;&#24230;&#30456;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by the increasing popularity and importance of large-scale training under differential privacy (DP) constraints, we study distributed gradient methods with gradient clipping, i.e., clipping applied to the gradients computed from local information at the nodes. While gradient clipping is an essential tool for injecting formal DP guarantees into gradient-based methods [1], it also induces bias which causes serious convergence issues specific to the distributed setting. Inspired by recent progress in the error-feedback literature which is focused on taming the bias/error introduced by communication compression operators such as Top-$k$ [2], and mathematical similarities between the clipping operator and contractive compression operators, we design Clip21 -- the first provably effective and practically useful error feedback mechanism for distributed methods with gradient clipping. We prove that our method converges at the same $\mathcal{O}\left(\frac{1}{K}\right)$ rate as distrib
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#25200;&#21160;&#30340;&#26041;&#27861;&#26469;&#35299;&#37322;&#39044;&#27979;&#65292;&#30456;&#23545;&#20110;&#20256;&#32479;&#30340;&#22522;&#20110;&#25200;&#21160;&#30340;&#26174;&#33879;&#24615;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#26174;&#30528;&#25552;&#39640;&#23545;&#20110;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#35299;&#37322;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2305.18840</link><description>&lt;p&gt;
&#23398;&#20064;&#25200;&#21160;&#26469;&#35299;&#37322;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Learning Perturbations to Explain Time Series Predictions. (arXiv:2305.18840v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18840
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#25200;&#21160;&#30340;&#26041;&#27861;&#26469;&#35299;&#37322;&#39044;&#27979;&#65292;&#30456;&#23545;&#20110;&#20256;&#32479;&#30340;&#22522;&#20110;&#25200;&#21160;&#30340;&#26174;&#33879;&#24615;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#26174;&#30528;&#25552;&#39640;&#23545;&#20110;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#35299;&#37322;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#37322;&#22522;&#20110;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#39044;&#27979;&#20855;&#26377;&#39069;&#22806;&#30340;&#22256;&#38590;&#65292;&#38656;&#35201;&#22788;&#29702;&#22810;&#20010;&#29305;&#24449;&#20197;&#21450;&#26102;&#38388;&#20381;&#36182;&#20851;&#31995;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#20351;&#29992;&#22522;&#20110;&#25200;&#21160;&#30340;&#26174;&#33879;&#24615;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#36890;&#36807;&#20351;&#29992;&#21487;&#35757;&#32451;&#30340;&#25513;&#30721;&#25200;&#21160;&#36755;&#20837;&#65292;&#21457;&#29616;&#21738;&#20123;&#29305;&#24449;&#22312;&#21738;&#20010;&#26102;&#21051;&#39537;&#21160;&#20102;&#39044;&#27979;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#24341;&#20837;&#20102;&#22266;&#23450;&#30340;&#25200;&#21160;&#65292;&#21463;&#21040;&#38745;&#24577;&#25968;&#25454;&#31867;&#20284;&#26041;&#27861;&#30340;&#21551;&#21457;&#65292;&#32780;&#20284;&#20046;&#22312;&#26102;&#38388;&#19978;&#27809;&#26377;&#20160;&#20040;&#21160;&#26426;&#36825;&#26679;&#20570;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#36890;&#36807;&#23398;&#20064;&#20851;&#32852;&#25200;&#21160;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#25513;&#30721;&#65292;&#26469;&#35299;&#37322;&#39044;&#27979;&#12290;&#25105;&#20204;&#20174;&#23454;&#35777;&#19978;&#35777;&#26126;&#65292;&#23398;&#20064;&#36825;&#20123;&#25200;&#21160;&#26174;&#30528;&#25552;&#39640;&#20102;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#35299;&#37322;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Explaining predictions based on multivariate time series data carries the additional difficulty of handling not only multiple features, but also time dependencies. It matters not only what happened, but also when, and the same feature could have a very different impact on a prediction depending on this time information. Previous work has used perturbation-based saliency methods to tackle this issue, perturbing an input using a trainable mask to discover which features at which times are driving the predictions. However these methods introduce fixed perturbations, inspired from similar methods on static data, while there seems to be little motivation to do so on temporal data. In this work, we aim to explain predictions by learning not only masks, but also associated perturbations. We empirically show that learning these perturbations significantly improves the quality of these explanations on time series data.
&lt;/p&gt;</description></item><item><title>PyPOTS&#26159;&#19968;&#20010;Python&#24037;&#20855;&#31665;&#65292;&#29992;&#20110;&#23545;&#37096;&#20998;&#35266;&#27979;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#36827;&#34892;&#25968;&#25454;&#25366;&#25496;&#21644;&#20998;&#26512;&#65292;&#21253;&#25324;&#25554;&#20540;&#12289;&#20998;&#31867;&#12289;&#32858;&#31867;&#21644;&#39044;&#27979;&#31561;&#22235;&#20010;&#20219;&#21153;&#65292;&#31639;&#27861;&#31181;&#31867;&#32321;&#22810;&#65292;&#36866;&#29992;&#20110;&#23398;&#26415;&#30740;&#31350;&#21644;&#24037;&#19994;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2305.18811</link><description>&lt;p&gt;
PyPOTS&#65306;&#29992;&#20110;&#37096;&#20998;&#35266;&#27979;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#25366;&#25496;&#30340;Python&#24037;&#20855;&#31665;
&lt;/p&gt;
&lt;p&gt;
PyPOTS: A Python Toolbox for Data Mining on Partially-Observed Time Series. (arXiv:2305.18811v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18811
&lt;/p&gt;
&lt;p&gt;
PyPOTS&#26159;&#19968;&#20010;Python&#24037;&#20855;&#31665;&#65292;&#29992;&#20110;&#23545;&#37096;&#20998;&#35266;&#27979;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#36827;&#34892;&#25968;&#25454;&#25366;&#25496;&#21644;&#20998;&#26512;&#65292;&#21253;&#25324;&#25554;&#20540;&#12289;&#20998;&#31867;&#12289;&#32858;&#31867;&#21644;&#39044;&#27979;&#31561;&#22235;&#20010;&#20219;&#21153;&#65292;&#31639;&#27861;&#31181;&#31867;&#32321;&#22810;&#65292;&#36866;&#29992;&#20110;&#23398;&#26415;&#30740;&#31350;&#21644;&#24037;&#19994;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
PyPOTS&#26159;&#19968;&#20010;&#24320;&#28304;&#30340;Python&#24211;&#65292;&#33268;&#21147;&#20110;&#22312;&#22810;&#20803;&#37096;&#20998;&#35266;&#27979;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#19978;&#36827;&#34892;&#25968;&#25454;&#25366;&#25496;&#21644;&#20998;&#26512;&#65292;&#21363;&#38024;&#23545;&#23384;&#22312;&#32570;&#22833;&#20540;&#30340;&#19981;&#23436;&#25972;&#26102;&#38388;&#24207;&#21015;&#65292;&#20063;&#31216;&#20026;&#19981;&#35268;&#21017;&#37319;&#26679;&#26102;&#38388;&#24207;&#21015;&#12290;&#29305;&#21035;&#22320;&#65292;&#23427;&#25552;&#20379;&#20102;&#23545;&#22235;&#20010;&#20219;&#21153;&#20998;&#31867;&#30340;&#19981;&#21516;&#31639;&#27861;&#30340;&#26131;&#29992;&#24615;&#25903;&#25345;&#65306;&#25554;&#20540;&#12289;&#20998;&#31867;&#12289;&#32858;&#31867;&#21644;&#39044;&#27979;&#12290;&#23427;&#21253;&#21547;&#20102;&#27010;&#29575;&#26041;&#27861;&#21644;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#35774;&#35745;&#33391;&#22909;&#12289;&#23436;&#25972;&#25991;&#26723;&#30340;&#32534;&#31243;&#25509;&#21475;&#65292;&#20379;&#23398;&#26415;&#30740;&#31350;&#20154;&#21592;&#21644;&#24037;&#19994;&#19987;&#19994;&#20154;&#21592;&#20351;&#29992;&#12290;&#35813;&#24037;&#20855;&#21253;&#30340;&#35774;&#35745;&#29702;&#24565;&#26159;&#40065;&#26834;&#24615;&#21644;&#21487;&#20280;&#32553;&#24615;&#65292;&#24320;&#21457;&#36807;&#31243;&#20013;&#36981;&#24490;&#20102;&#36719;&#20214;&#26500;&#24314;&#30340;&#26368;&#20339;&#23454;&#36341;&#65292;&#20363;&#22914;&#21333;&#20803;&#27979;&#35797;&#12289;&#25345;&#32493;&#38598;&#25104;&#65288;CI&#65289;&#21644;&#25345;&#32493;&#20132;&#20184;&#65288;CD&#65289;&#12289;&#20195;&#30721;&#35206;&#30422;&#29575;&#12289;&#21487;&#32500;&#25252;&#24615;&#35780;&#20272;&#12289;&#20132;&#20114;&#24335;&#25945;&#31243;&#21644;&#24182;&#34892;&#21270;&#31561;&#21407;&#21017;&#12290;&#35813;&#24037;&#20855;&#31665;&#21487;&#22312;Python&#21253;&#32034;&#24341;&#65288;PyPI&#65289;&#21644;Anaconda&#19978;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
PyPOTS is an open-source Python library dedicated to data mining and analysis on multivariate partially-observed time series, i.e. incomplete time series with missing values, A.K.A. irregularlysampled time series. Particularly, it provides easy access to diverse algorithms categorized into four tasks: imputation, classification, clustering, and forecasting. The included models contain probabilistic approaches as well as neural-network methods, with a well-designed and fully-documented programming interface for both academic researchers and industrial professionals to use. With robustness and scalability in its design philosophy, best practices of software construction, for example, unit testing, continuous integration (CI) and continuous delivery (CD), code coverage, maintainability evaluation, interactive tutorials, and parallelization, are carried out as principles during the development of PyPOTS. The toolkit is available on both Python Package Index (PyPI) and Anaconda. PyPOTS is o
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22686;&#37327;&#23398;&#20064;&#20998;&#31867;&#26041;&#27861;&#8212;&#8212;&#22522;&#20110;&#39044;&#27979;&#35823;&#24046;&#30340;&#20998;&#31867;&#26041;&#27861;&#65288;PEC&#65289;&#12290;&#23545;PEC&#30340;&#35780;&#20272;&#34920;&#26126;&#65292;&#22312;&#21508;&#31181;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;PEC&#21487;&#20197;&#19982;&#26368;&#20808;&#36827;&#30340;&#22686;&#37327;&#23398;&#20064;&#26041;&#27861;&#30456;&#31454;&#20105;&#65292;&#24182;&#20855;&#26377;&#35768;&#22810;&#23454;&#38469;&#20248;&#21183;&#65292;&#20363;&#22914;&#26679;&#26412;&#25928;&#29575;&#39640;&#12289;&#26131;&#20110;&#35843;&#25972;&#12290;</title><link>http://arxiv.org/abs/2305.18806</link><description>&lt;p&gt;
&#22522;&#20110;&#39044;&#27979;&#35823;&#24046;&#30340;&#22686;&#37327;&#23398;&#20064;&#20998;&#31867;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Prediction Error-based Classification for Class-Incremental Learning. (arXiv:2305.18806v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18806
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22686;&#37327;&#23398;&#20064;&#20998;&#31867;&#26041;&#27861;&#8212;&#8212;&#22522;&#20110;&#39044;&#27979;&#35823;&#24046;&#30340;&#20998;&#31867;&#26041;&#27861;&#65288;PEC&#65289;&#12290;&#23545;PEC&#30340;&#35780;&#20272;&#34920;&#26126;&#65292;&#22312;&#21508;&#31181;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;PEC&#21487;&#20197;&#19982;&#26368;&#20808;&#36827;&#30340;&#22686;&#37327;&#23398;&#20064;&#26041;&#27861;&#30456;&#31454;&#20105;&#65292;&#24182;&#20855;&#26377;&#35768;&#22810;&#23454;&#38469;&#20248;&#21183;&#65292;&#20363;&#22914;&#26679;&#26412;&#25928;&#29575;&#39640;&#12289;&#26131;&#20110;&#35843;&#25972;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22686;&#37327;&#23398;&#20064;&#20998;&#31867;&#26159;&#36830;&#32493;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#25361;&#25112;&#24615;&#38382;&#39064;&#65292;&#30446;&#26631;&#26159;&#23398;&#20064;&#26469;&#21306;&#20998;&#25152;&#26377;&#31867;&#21035;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#22312;&#22788;&#29702;&#22823;&#37327;&#20998;&#31867;&#26102;&#23481;&#26131;&#20986;&#29616;&#36807;&#24230;&#36951;&#24536;&#21644;&#20998;&#25968;&#19981;&#22343;&#34913;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21517;&#20026;&#39044;&#27979;&#35823;&#24046;&#20998;&#31867;&#65288;PEC&#65289;&#65292;&#23427;&#19982;&#20256;&#32479;&#30340;&#21028;&#21035;&#21644;&#29983;&#25104;&#20998;&#31867;&#33539;&#24335;&#26377;&#25152;&#19981;&#21516;&#12290;PEC&#36890;&#36807;&#27979;&#37327;&#27169;&#22411;&#22312;&#20174;&#35813;&#31867;&#21035;&#20013;&#23398;&#20064;&#30340;&#25968;&#25454;&#19978;&#22797;&#21046;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#36755;&#20986;&#30340;&#39044;&#27979;&#35823;&#24046;&#26469;&#35745;&#31639;&#31867;&#21035;&#24471;&#20998;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#35299;&#37322;&#20026;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#21518;&#39564;&#26041;&#24046;&#30340;&#20998;&#31867;&#35268;&#21017;&#30340;&#36817;&#20284;&#12290;PEC&#20855;&#26377;&#20960;&#20010;&#23454;&#38469;&#20248;&#21183;&#65292;&#21253;&#25324;&#26679;&#26412;&#25928;&#29575;&#39640;&#12289;&#26131;&#20110;&#35843;&#25972;&#20197;&#21450;&#21363;&#20351;&#22312;&#36880;&#20010;&#21576;&#29616;&#25968;&#25454;&#26102;&#20063;&#24456;&#26377;&#25928;&#12290;&#26412;&#25991;&#30340;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;PEC&#22312;&#24191;&#27867;&#30340;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#21487;&#20197;&#19982;&#26368;&#20808;&#36827;&#30340;&#22686;&#37327;&#23398;&#20064;&#26041;&#27861;&#30456;&#31454;&#20105;&#12290;
&lt;/p&gt;
&lt;p&gt;
Class-incremental learning (CIL) is a particularly challenging variant of continual learning, where the goal is to learn to discriminate between all classes presented in an incremental fashion. Existing approaches often suffer from excessive forgetting and imbalance of the scores assigned to classes that have not been seen together during training. In this study, we introduce a novel approach, Prediction Error-based Classification (PEC), which differs from traditional discriminative and generative classification paradigms. PEC computes a class score by measuring the prediction error of a model trained to replicate the outputs of a frozen random neural network on data from that class. The method can be interpreted as approximating a classification rule based on Gaussian Process posterior variance. PEC offers several practical advantages, including sample efficiency, ease of tuning, and effectiveness even when data are presented one class at a time. Our empirical results show that PEC pe
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#19968;&#20010;&#26032;&#30340;&#21512;&#20316;&#22810;&#26234;&#33021;&#20307;&#32769;&#34382;&#26426;&#35774;&#32622;&#65292;&#24182;&#21457;&#23637;&#20102;&#21435;&#20013;&#24515;&#21270;&#31639;&#27861;&#20197;&#20943;&#23569;&#20195;&#29702;&#20043;&#38388;&#30340;&#38598;&#20307;&#36951;&#25022;&#65292;&#22312;&#25968;&#23398;&#20998;&#26512;&#20013;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.18784</link><description>&lt;p&gt;
&#21512;&#20316;&#22810;&#26234;&#33021;&#20307;&#24322;&#26500;&#22810;&#33218;&#32769;&#34382;&#26426;&#32763;&#35793;&#35770;&#25991;
&lt;/p&gt;
&lt;p&gt;
Collaborative Multi-Agent Heterogeneous Multi-Armed Bandits. (arXiv:2305.18784v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18784
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#19968;&#20010;&#26032;&#30340;&#21512;&#20316;&#22810;&#26234;&#33021;&#20307;&#32769;&#34382;&#26426;&#35774;&#32622;&#65292;&#24182;&#21457;&#23637;&#20102;&#21435;&#20013;&#24515;&#21270;&#31639;&#27861;&#20197;&#20943;&#23569;&#20195;&#29702;&#20043;&#38388;&#30340;&#38598;&#20307;&#36951;&#25022;&#65292;&#22312;&#25968;&#23398;&#20998;&#26512;&#20013;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#21512;&#20316;&#22810;&#26234;&#33021;&#20307;&#32769;&#34382;&#26426;&#30340;&#30740;&#31350;&#21560;&#24341;&#20102;&#24456;&#22810;&#20851;&#27880;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24320;&#22987;&#30740;&#31350;&#19968;&#20010;&#26032;&#30340;&#21512;&#20316;&#35774;&#32622;&#65292;&#20854;&#20013;$N$&#20010;&#26234;&#33021;&#20307;&#20013;&#30340;&#27599;&#20010;&#26234;&#33021;&#20307;&#27491;&#22312;&#23398;&#20064;$M$&#20010;&#20855;&#26377;&#38543;&#26426;&#24615;&#30340;&#22810;&#33218;&#32769;&#34382;&#26426;&#65292;&#20197;&#20943;&#23569;&#20182;&#20204;&#30340;&#38598;&#20307;&#32047;&#35745;&#36951;&#25022;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#21435;&#20013;&#24515;&#21270;&#31639;&#27861;&#65292;&#20419;&#36827;&#20102;&#20195;&#29702;&#20043;&#38388;&#30340;&#21512;&#20316;&#65292;&#24182;&#38024;&#23545;&#20004;&#31181;&#24773;&#20917;&#36827;&#34892;&#20102;&#24615;&#33021;&#34920;&#24449;&#12290;&#36890;&#36807;&#25512;&#23548;&#27599;&#20010;&#20195;&#29702;&#30340;&#32047;&#31215;&#36951;&#25022;&#21644;&#38598;&#20307;&#36951;&#25022;&#30340;&#19978;&#38480;&#65292;&#25105;&#20204;&#23545;&#36825;&#20123;&#31639;&#27861;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#34920;&#24449;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#36825;&#31181;&#24773;&#20917;&#19979;&#38598;&#20307;&#36951;&#25022;&#30340;&#19979;&#38480;&#65292;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#31639;&#27861;&#30340;&#36817;&#20046;&#26368;&#20248;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The study of collaborative multi-agent bandits has attracted significant attention recently. In light of this, we initiate the study of a new collaborative setting, consisting of $N$ agents such that each agent is learning one of $M$ stochastic multi-armed bandits to minimize their group cumulative regret. We develop decentralized algorithms which facilitate collaboration between the agents under two scenarios. We characterize the performance of these algorithms by deriving the per agent cumulative regret and group regret upper bounds. We also prove lower bounds for the group regret in this setting, which demonstrates the near-optimal behavior of the proposed algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23545;&#20110;&#23545;&#25239;&#29983;&#25104;&#30340;&#31034;&#20363;&#32570;&#20047;&#40065;&#26834;&#24615;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#20960;&#20309;&#35282;&#24230;&#20986;&#21457;&#30340;&#26032;&#39062;&#35270;&#35282;&#65292;&#20171;&#32461;&#19968;&#26063;&#27010;&#29575;&#38750;&#23616;&#37096;&#21608;&#38271;&#20989;&#25968;&#26469;&#20248;&#21270;&#27010;&#29575;&#40065;&#26834;&#23398;&#20064;&#65288;PRL&#65289;&#30340;&#21407;&#22987;&#34920;&#36848;&#65292;&#20197;&#25552;&#39640;&#20854;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.18779</link><description>&lt;p&gt;
&#20174;&#20960;&#20309;&#35282;&#24230;&#30475;&#24453;&#27010;&#29575;&#40065;&#26834;&#23398;&#20064;&#20013;&#30340;&#36793;&#30028;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
It begins with a boundary: A geometric view on probabilistically robust learning. (arXiv:2305.18779v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18779
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23545;&#20110;&#23545;&#25239;&#29983;&#25104;&#30340;&#31034;&#20363;&#32570;&#20047;&#40065;&#26834;&#24615;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#20960;&#20309;&#35282;&#24230;&#20986;&#21457;&#30340;&#26032;&#39062;&#35270;&#35282;&#65292;&#20171;&#32461;&#19968;&#26063;&#27010;&#29575;&#38750;&#23616;&#37096;&#21608;&#38271;&#20989;&#25968;&#26469;&#20248;&#21270;&#27010;&#29575;&#40065;&#26834;&#23398;&#20064;&#65288;PRL&#65289;&#30340;&#21407;&#22987;&#34920;&#36848;&#65292;&#20197;&#25552;&#39640;&#20854;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#35768;&#22810;&#20998;&#31867;&#20219;&#21153;&#19978;&#24050;&#32463;&#23454;&#29616;&#20102;&#36229;&#20154;&#31867;&#30340;&#34920;&#29616;&#65292;&#20294;&#23427;&#20204;&#24448;&#24448;&#23545;&#20110;&#23545;&#25239;&#29983;&#25104;&#30340;&#31034;&#20363;&#32570;&#20047;&#40065;&#26834;&#24615;&#65292;&#22240;&#27492;&#38656;&#35201;&#23558;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;ERM&#65289;&#37325;&#26500;&#20026;&#23545;&#25239;&#24615;&#40065;&#26834;&#30340;&#26694;&#26550;&#12290;&#26368;&#36817;&#65292;&#20851;&#27880;&#28857;&#24050;&#32463;&#36716;&#21521;&#20102;&#20171;&#20110;&#23545;&#25239;&#24615;&#35757;&#32451;&#25552;&#20379;&#30340;&#40065;&#26834;&#24615;&#21644;ERM&#25552;&#20379;&#30340;&#26356;&#39640;&#24178;&#20928;&#20934;&#30830;&#24615;&#21644;&#26356;&#24555;&#35757;&#32451;&#26102;&#38388;&#20043;&#38388;&#30340;&#26041;&#27861;&#12290;&#26412;&#25991;&#20174;&#20960;&#20309;&#35282;&#24230;&#20986;&#21457;&#65292;&#23545;&#19968;&#31181;&#36825;&#26679;&#30340;&#26041;&#27861;&#8212;&#8212;&#27010;&#29575;&#40065;&#26834;&#23398;&#20064;&#65288;PRL&#65289;&#65288;Robey&#31561;&#20154;&#65292;ICML&#65292;2022&#65289;&#36827;&#34892;&#20102;&#26032;&#39062;&#30340;&#20960;&#20309;&#35270;&#35282;&#30340;&#25506;&#35752;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20960;&#20309;&#26694;&#26550;&#26469;&#29702;&#35299;PRL&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#30830;&#23450;&#20854;&#21407;&#22987;&#34920;&#36848;&#20013;&#30340;&#24494;&#22937;&#32570;&#38519;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#26063;&#27010;&#29575;&#38750;&#23616;&#37096;&#21608;&#38271;&#20989;&#25968;&#26469;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#26032;&#39062;&#30340;&#26494;&#24347;&#26041;&#27861;&#35777;&#26126;&#20102;&#35299;&#30340;&#23384;&#22312;&#65292;&#24182;&#30740;&#31350;&#20102;&#24341;&#20837;&#30340;&#38750;&#23616;&#37096;&#21608;&#38271;&#20989;&#25968;&#30340;&#29305;&#24615;&#20197;&#21450;&#23616;&#37096;&#26497;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Although deep neural networks have achieved super-human performance on many classification tasks, they often exhibit a worrying lack of robustness towards adversarially generated examples. Thus, considerable effort has been invested into reformulating Empirical Risk Minimization (ERM) into an adversarially robust framework. Recently, attention has shifted towards approaches which interpolate between the robustness offered by adversarial training and the higher clean accuracy and faster training times of ERM. In this paper, we take a fresh and geometric view on one such method -- Probabilistically Robust Learning (PRL) (Robey et al., ICML, 2022). We propose a geometric framework for understanding PRL, which allows us to identify a subtle flaw in its original formulation and to introduce a family of probabilistic nonlocal perimeter functionals to address this. We prove existence of solutions using novel relaxation methods and study properties as well as local limits of the introduced per
&lt;/p&gt;</description></item><item><title>SFCNeXt&#26159;&#19968;&#20010;&#31616;&#21333;&#30340;&#20840;&#21367;&#31215;&#32593;&#32476;&#65292;&#29992;&#20110;&#23567;&#22411;&#38431;&#21015;&#20013;&#36827;&#34892;&#33041;&#40836;&#20272;&#35745;&#65292;&#36890;&#36807;SPEC&#21644;HRL&#31639;&#27861;&#65292;&#20197;&#36731;&#37327;&#21270;&#30340;&#26041;&#24335;&#20805;&#20998;&#25506;&#32034;&#27599;&#20010;&#25209;&#27425;&#30340;MRI&#12289;&#24180;&#40836;&#21644;&#25490;&#21517;&#29305;&#24449;&#65292;&#36991;&#20813;&#23545;&#22823;&#37327;MRI&#30340;&#20381;&#36182;&#21644;&#22797;&#26434;&#27169;&#22411;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2305.18771</link><description>&lt;p&gt;
SFCNeXt&#65306;&#19968;&#31181;&#29992;&#20110;&#23567;&#26679;&#26412;&#19979;&#26377;&#25928;&#30340;&#33041;&#40836;&#20272;&#35745;&#30340;&#31616;&#21333;&#20840;&#21367;&#31215;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
SFCNeXt: a simple fully convolutional network for effective brain age estimation with small sample size. (arXiv:2305.18771v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18771
&lt;/p&gt;
&lt;p&gt;
SFCNeXt&#26159;&#19968;&#20010;&#31616;&#21333;&#30340;&#20840;&#21367;&#31215;&#32593;&#32476;&#65292;&#29992;&#20110;&#23567;&#22411;&#38431;&#21015;&#20013;&#36827;&#34892;&#33041;&#40836;&#20272;&#35745;&#65292;&#36890;&#36807;SPEC&#21644;HRL&#31639;&#27861;&#65292;&#20197;&#36731;&#37327;&#21270;&#30340;&#26041;&#24335;&#20805;&#20998;&#25506;&#32034;&#27599;&#20010;&#25209;&#27425;&#30340;MRI&#12289;&#24180;&#40836;&#21644;&#25490;&#21517;&#29305;&#24449;&#65292;&#36991;&#20813;&#23545;&#22823;&#37327;MRI&#30340;&#20381;&#36182;&#21644;&#22797;&#26434;&#27169;&#22411;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#34987;&#35774;&#35745;&#20986;&#26469;&#20174;T1&#21152;&#26435;&#30913;&#20849;&#25391;&#22270;&#20687;&#20013;&#39044;&#27979;&#20581;&#24247;&#22823;&#33041;&#30340;&#24180;&#40836;&#65292;&#39044;&#27979;&#30340;&#33041;&#40836;&#21487;&#20197;&#20316;&#20026;&#26089;&#26399;&#26816;&#27979;&#21457;&#23637;&#30456;&#20851;&#25110;&#34928;&#32769;&#30456;&#20851;&#30142;&#30149;&#30340;&#26377;&#20215;&#20540;&#30340;&#29983;&#29289;&#26631;&#24535;&#29289;&#12290;&#28982;&#32780;&#65292;&#36817;&#26399;&#29992;&#20110;&#33041;&#40836;&#39044;&#27979;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36890;&#24120;&#36807;&#20110;&#20381;&#36182;&#20110;&#22823;&#26679;&#26412;&#37327;&#21644;&#22810;&#38454;&#27573;&#29305;&#24449;&#20248;&#21270;&#30340;&#22797;&#26434;&#32593;&#32476;&#32467;&#26500;&#12290;&#22312;&#20020;&#24202;&#24212;&#29992;&#22330;&#26223;&#20013;&#65292;&#30740;&#31350;&#20154;&#21592;&#36890;&#24120;&#19981;&#33021;&#22312;&#27599;&#20010;&#25968;&#25454;&#20013;&#24515;&#33719;&#24471;&#25104;&#21315;&#19978;&#19975;&#30340;MRI&#20197;&#20805;&#20998;&#35757;&#32451;&#36825;&#20123;&#22797;&#26434;&#30340;&#27169;&#22411;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20855;&#26377;&#20559;&#20506;&#24180;&#40836;&#20998;&#24067;&#30340;&#23567;&#22411;&#38431;&#21015;&#20013;&#36827;&#34892;&#33041;&#40836;&#20272;&#35745;&#30340;&#31616;&#21333;&#20840;&#21367;&#31215;&#32593;&#32476;&#65288;SFCNeXt&#65289;&#12290; SFCNeXt&#30001;Single Pathway Encoded ConvNeXt&#65288;SPEC&#65289;&#21644;Hybrid Ranking Loss&#65288;HRL&#65289;&#32452;&#25104;&#65292;&#26088;&#22312;&#20197;&#36731;&#37327;&#21270;&#30340;&#26041;&#24335;&#20272;&#35745;&#33041;&#40836;&#65292;&#24182;&#20805;&#20998;&#25506;&#32034;&#27599;&#25209;&#25195;&#25551;&#30340;MRI&#12289;&#24180;&#40836;&#21644;&#25490;&#21517;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks (DNN) have been designed to predict the chronological age of a healthy brain from T1-weighted magnetic resonance images (T1 MRIs), and the predicted brain age could serve as a valuable biomarker for the early detection of development-related or aging-related disorders. Recent DNN models for brain age estimations usually rely too much on large sample sizes and complex network structures for multi-stage feature refinement. However, in clinical application scenarios, researchers usually cannot obtain thousands or tens of thousands of MRIs in each data center for thorough training of these complex models. This paper proposes a simple fully convolutional network (SFCNeXt) for brain age estimation in small-sized cohorts with biased age distributions. The SFCNeXt consists of Single Pathway Encoded ConvNeXt (SPEC) and Hybrid Ranking Loss (HRL), aiming to estimate brain ages in a lightweight way with a sufficient exploration of MRI, age, and ranking features of each batch o
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20248;&#21270;&#36866;&#24403;&#30340;&#25439;&#22833;&#20989;&#25968;&#26159;&#21542;&#33021;&#22312;&#21463;&#38480;&#30340;&#39044;&#27979;&#22120;&#26063;&#20013;&#24471;&#21040;&#26657;&#20934;&#30340;&#27169;&#22411;&#65292;&#20351;&#29992;&#23616;&#37096;&#26368;&#20248;&#26465;&#20214;&#21462;&#20195;&#20840;&#23616;&#26368;&#20248;&#24615;&#26465;&#20214;&#24182;&#22312;&#27492;&#22522;&#30784;&#19978;&#36827;&#34892;&#20102;&#20005;&#26684;&#30340;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2305.18764</link><description>&lt;p&gt;
&#20248;&#21270;&#36866;&#24403;&#30340;&#25439;&#22833;&#20989;&#25968;&#26159;&#21542;&#33021;&#24471;&#21040;&#26657;&#20934;&#30340;&#39044;&#27979;&#22120;&#65311;
&lt;/p&gt;
&lt;p&gt;
When Does Optimizing a Proper Loss Yield Calibration?. (arXiv:2305.18764v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18764
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20248;&#21270;&#36866;&#24403;&#30340;&#25439;&#22833;&#20989;&#25968;&#26159;&#21542;&#33021;&#22312;&#21463;&#38480;&#30340;&#39044;&#27979;&#22120;&#26063;&#20013;&#24471;&#21040;&#26657;&#20934;&#30340;&#27169;&#22411;&#65292;&#20351;&#29992;&#23616;&#37096;&#26368;&#20248;&#26465;&#20214;&#21462;&#20195;&#20840;&#23616;&#26368;&#20248;&#24615;&#26465;&#20214;&#24182;&#22312;&#27492;&#22522;&#30784;&#19978;&#36827;&#34892;&#20102;&#20005;&#26684;&#30340;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20248;&#21270;&#36866;&#24403;&#30340;&#25439;&#22833;&#20989;&#25968;&#34987;&#24191;&#27867;&#35748;&#20026;&#20250;&#24471;&#21040;&#20855;&#26377;&#33391;&#22909;&#26657;&#20934;&#29305;&#24615;&#30340;&#39044;&#27979;&#22120;&#65292;&#36825;&#26159;&#22240;&#20026;&#23545;&#20110;&#36825;&#26679;&#30340;&#25439;&#22833;&#65292;&#20840;&#23616;&#26368;&#20248;&#35299;&#26159;&#39044;&#27979;&#30495;&#23454;&#27010;&#29575;&#65292;&#36825;&#30830;&#23454;&#26159;&#26657;&#20934;&#30340;&#12290;&#20294;&#26159;&#65292;&#20856;&#22411;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26159;&#35757;&#32451;&#26469;&#36817;&#20284;&#22320;&#26368;&#23567;&#21270;&#22312;&#21463;&#38480;&#21046;&#30340;&#39044;&#27979;&#22120;&#26063;&#20013;&#30340;&#25439;&#22833;&#65292;&#36825;&#20123;&#39044;&#27979;&#22120;&#26063;&#19981;&#22826;&#21487;&#33021;&#21253;&#21547;&#30495;&#23454;&#30340;&#27010;&#29575;&#12290;&#22312;&#20160;&#20040;&#24773;&#20917;&#19979;&#65292;&#20248;&#21270;&#21463;&#38480;&#21046;&#30340;&#39044;&#27979;&#22120;&#26063;&#20013;&#36866;&#24403;&#30340;&#25439;&#22833;&#21487;&#20197;&#24471;&#21040;&#26657;&#20934;&#30340;&#27169;&#22411;&#65311;&#23427;&#25552;&#20379;&#20102;&#20160;&#20040;&#31934;&#30830;&#30340;&#26657;&#20934;&#20445;&#35777;&#65311;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#36825;&#20123;&#38382;&#39064;&#30340;&#20005;&#26684;&#31572;&#26696;&#12290;&#25105;&#20204;&#29992;&#23616;&#37096;&#26368;&#20248;&#26465;&#20214;&#26367;&#25442;&#20840;&#23616;&#26368;&#20248;&#24615;&#26465;&#20214;&#65292;&#35813;&#26465;&#20214;&#35268;&#23450;&#20102;&#39044;&#27979;&#22120;&#65288;&#36866;&#24403;&#30340;&#65289;&#25439;&#22833;&#19981;&#33021;&#36890;&#36807;&#20351;&#29992;&#19968;&#23450;&#26063;&#32676;&#30340;Lipschitz&#20989;&#25968;&#21518;&#22788;&#29702;&#20854;&#39044;&#27979;&#32780;&#38477;&#20302;&#22826;&#22810;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20855;&#26377;&#36825;&#31181;&#23616;&#37096;&#26368;&#20248;&#24615;&#36136;&#30340;&#20219;&#20309;&#39044;&#27979;&#22120;&#37117;&#28385;&#36275;Kakade-Foster(2008)&#12289;B&#322;asiok&#31561;&#20154;(2023)&#20013;&#23450;&#20041;&#30340;&#24179;&#31283;&#26657;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
Optimizing proper loss functions is popularly believed to yield predictors with good calibration properties; the intuition being that for such losses, the global optimum is to predict the ground-truth probabilities, which is indeed calibrated. However, typical machine learning models are trained to approximately minimize loss over restricted families of predictors, that are unlikely to contain the ground truth. Under what circumstances does optimizing proper loss over a restricted family yield calibrated models? What precise calibration guarantees does it give? In this work, we provide a rigorous answer to these questions. We replace the global optimality with a local optimality condition stipulating that the (proper) loss of the predictor cannot be reduced much by post-processing its predictions with a certain family of Lipschitz functions. We show that any predictor with this local optimality satisfies smooth calibration as defined in Kakade-Foster (2008), B{\l}asiok et al. (2023). L
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#26041;&#24046;&#32422;&#31616;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#20197;&#23454;&#29616;&#23545;&#22810;&#22359;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#30340;&#39640;&#25928;&#27714;&#35299;&#65292;&#21516;&#26102;&#21305;&#37197;&#21333;&#22359;&#26631;&#20934; BO &#38382;&#39064;&#30340;&#26368;&#20248;&#22797;&#26434;&#24230;&#12289;&#23454;&#29616;&#24182;&#34892;&#21270;&#21152;&#36895;&#65292;&#20197;&#21450;&#36991;&#20813;&#35745;&#31639;&#39640;&#32500;&#24230;&#30340; Hessian &#30697;&#38453;&#30340;&#36870;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2305.18730</link><description>&lt;p&gt;
&#22810;&#22359;&#21452;&#23618;&#20248;&#21270;&#30340;&#20998;&#22359;&#38543;&#26426;&#26041;&#24046;&#32422;&#31616;&#26041;&#27861;&#21450;&#24182;&#34892;&#21152;&#36895;
&lt;/p&gt;
&lt;p&gt;
Blockwise Stochastic Variance-Reduced Methods with Parallel Speedup for Multi-Block Bilevel Optimization. (arXiv:2305.18730v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18730
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#26041;&#24046;&#32422;&#31616;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#20197;&#23454;&#29616;&#23545;&#22810;&#22359;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#30340;&#39640;&#25928;&#27714;&#35299;&#65292;&#21516;&#26102;&#21305;&#37197;&#21333;&#22359;&#26631;&#20934; BO &#38382;&#39064;&#30340;&#26368;&#20248;&#22797;&#26434;&#24230;&#12289;&#23454;&#29616;&#24182;&#34892;&#21270;&#21152;&#36895;&#65292;&#20197;&#21450;&#36991;&#20813;&#35745;&#31639;&#39640;&#32500;&#24230;&#30340; Hessian &#30697;&#38453;&#30340;&#36870;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#38750;&#20984;&#30340;&#22810;&#22359;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#20998;&#22359;&#26041;&#24046;&#32422;&#31616;&#30340;&#20248;&#21270;&#31639;&#27861;&#12290;&#20026;&#20102;&#36798;&#21040;&#31639;&#27861;&#30340;&#19977;&#20010;&#26399;&#26395;&#65306;&#65288;a&#65289;&#33021;&#21305;&#37197;&#21333;&#22359;&#26631;&#20934; BO &#38382;&#39064;&#30340;&#26368;&#20248;&#22797;&#26434;&#24230;&#65307;&#65288;b&#65289;&#23454;&#29616;&#24182;&#34892;&#21270;&#21152;&#36895;&#65292;&#27599;&#20010;&#36845;&#20195;&#20013;&#37319;&#26679; $I$ &#22359;&#24182;&#23545;&#27599;&#20010;&#37319;&#26679;&#22359;&#37319;&#26679; $B$ &#20010;&#26679;&#26412;&#65307;&#65288;c&#65289;&#36991;&#20813;&#35745;&#31639;&#39640;&#32500;&#24230;&#30340; Hessian &#30697;&#38453;&#30340;&#36870;&#20272;&#35745;&#12290;&#26412;&#25991;&#26088;&#22312;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#25506;&#35752;&#20102;&#29616;&#26377;&#31639;&#27861;&#30340;&#20851;&#32852;&#24615;&#20197;&#21450;&#19981;&#36275;&#20043;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider non-convex multi-block bilevel optimization (MBBO) problems, which involve $m\gg 1$ lower level problems and have important applications in machine learning. Designing a stochastic gradient and controlling its variance is more intricate due to the hierarchical sampling of blocks and data and the unique challenge of estimating hyper-gradient. We aim to achieve three nice properties for our algorithm: (a) matching the state-of-the-art complexity of standard BO problems with a single block; (b) achieving parallel speedup by sampling $I$ blocks and sampling $B$ samples for each sampled block per-iteration; (c) avoiding the computation of the inverse of a high-dimensional Hessian matrix estimator. However, it is non-trivial to achieve all of these by observing that existing works only achieve one or two of these properties. To address the involved challenges for achieving (a, b, c), we propose two stochastic algorithms by using advanced blockwise variance-reductio
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#19968;&#31181;&#21487;&#33021;&#8220;&#35268;&#33539;&#19981;&#27491;&#30830;&#8221;&#27169;&#22411;&#30340;&#36890;&#29992;&#21327;&#35758;&#65292;&#8220;&#25554;&#20214;&#24335;&#34920;&#29616;&#20248;&#21270;&#8221;&#12290;</title><link>http://arxiv.org/abs/2305.18728</link><description>&lt;p&gt;
&#25554;&#20214;&#21270;&#34920;&#29616;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Plug-in Performative Optimization. (arXiv:2305.18728v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18728
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#19968;&#31181;&#21487;&#33021;&#8220;&#35268;&#33539;&#19981;&#27491;&#30830;&#8221;&#27169;&#22411;&#30340;&#36890;&#29992;&#21327;&#35758;&#65292;&#8220;&#25554;&#20214;&#24335;&#34920;&#29616;&#20248;&#21270;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#39044;&#27979;&#20855;&#26377;&#34920;&#29616;&#24615;&#26102;&#65292;&#36873;&#25321;&#21738;&#20010;&#39044;&#27979;&#22120;&#37096;&#32626;&#23558;&#24433;&#21709;&#26410;&#26469;&#35266;&#27979;&#30340;&#20998;&#24067;&#12290;&#22312;&#34920;&#29616;&#24615;&#23398;&#20064;&#20013;&#65292;&#24635;&#20307;&#30446;&#26631;&#26159;&#25214;&#21040;&#20855;&#26377;&#20302;&#8220;&#34920;&#29616;&#24615;&#39118;&#38505;&#8221;&#30340;&#39044;&#27979;&#22120;&#65292;&#21363;&#22312;&#20854;&#24341;&#23548;&#30340;&#20998;&#24067;&#19978;&#34920;&#29616;&#33391;&#22909;&#12290;&#26368;&#20248;&#21270;&#34920;&#29616;&#24615;&#39118;&#38505;&#30340;&#19968;&#31995;&#21015;&#35299;&#20915;&#26041;&#26696;&#65292;&#21253;&#25324;&#36172;&#24466;&#31639;&#27861;&#21644;&#20854;&#20182;&#26080;&#23548;&#25968;&#26041;&#27861;&#65292;&#22312;&#34920;&#29616;&#24615;&#21453;&#39304;&#20013;&#19981;&#30693;&#36947;&#20219;&#20309;&#32467;&#26500;&#65292;&#23548;&#33268;&#25910;&#25947;&#36895;&#24230;&#26497;&#24930;&#12290;&#34917;&#20805;&#30340;&#19968;&#31995;&#21015;&#35299;&#20915;&#26041;&#26696;&#21033;&#29992;&#21453;&#39304;&#20013;&#30340;&#26174;&#24335;&#8220;&#27169;&#22411;&#8221;&#65292;&#20363;&#22914;&#25112;&#30053;&#20998;&#31867;&#20013;&#30340;&#26368;&#20339;&#21709;&#24212;&#27169;&#22411;&#65292;&#21487;&#20197;&#23454;&#29616;&#26356;&#24555;&#30340;&#36895;&#29575;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#36895;&#29575;&#20851;&#38190;&#20381;&#36182;&#20110;&#21453;&#39304;&#27169;&#22411;&#30340;&#35268;&#33539;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#21551;&#21160;&#20102;&#23545;&#22312;&#34920;&#29616;&#24615;&#39044;&#27979;&#20013;&#20351;&#29992;&#21487;&#33021;&#30340;&#8220;&#35268;&#33539;&#19981;&#27491;&#30830;&#8221;&#27169;&#22411;&#30340;&#30740;&#31350;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#20351;&#29992;&#27169;&#22411;&#30340;&#36890;&#29992;&#21327;&#35758;&#65292;&#31216;&#20026;&#8220;&#25554;&#20214;&#24335;&#34920;&#29616;&#20248;&#21270;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;
When predictions are performative, the choice of which predictor to deploy influences the distribution of future observations. The overarching goal in learning under performativity is to find a predictor that has low \emph{performative risk}, that is, good performance on its induced distribution. One family of solutions for optimizing the performative risk, including bandits and other derivative-free methods, is agnostic to any structure in the performative feedback, leading to exceedingly slow convergence rates. A complementary family of solutions makes use of explicit \emph{models} for the feedback, such as best-response models in strategic classification, enabling significantly faster rates. However, these rates critically rely on the feedback model being well-specified. In this work we initiate a study of the use of possibly \emph{misspecified} models in performative prediction. We study a general protocol for making use of models, called \emph{plug-in performative optimization}, a
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#26469;&#35843;&#25972;&#35757;&#32451;&#38598;&#20013;&#30340;&#38543;&#26426;&#26679;&#26412;&#65292;&#20197;&#20351;PDE&#35299;&#30340;&#27531;&#20313;&#22312;&#26368;&#23567;&#21270;&#26102;&#33021;&#20445;&#25345;&#24179;&#28369;&#30340;&#36718;&#24275;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#23545;&#25239;&#24615;&#25439;&#22833;&#39033;&#20248;&#21270;PINN&#27169;&#22411;&#65292;&#20174;&#32780;&#20351;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#31283;&#23450;&#30340;&#35299;&#12290;&#21516;&#26102;&#26412;&#25991;&#36824;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#21487;&#20197;&#25193;&#23637;&#21040;&#32435;&#20837;&#26368;&#20248;&#20256;&#36755;&#32422;&#26463;&#65292;&#20174;&#32780;&#24418;&#25104;&#20102;&#23558;PINN&#21644;&#26368;&#20248;&#20256;&#36755;&#30340;&#20248;&#28857;&#32467;&#21512;&#36215;&#26469;&#30340;&#32479;&#19968;&#26694;&#26550;&#65292;&#29992;&#20110;PDE&#36817;&#20284;&#12290;</title><link>http://arxiv.org/abs/2305.18702</link><description>&lt;p&gt;
&#23545;&#25239;&#24335;&#33258;&#36866;&#24212;&#37319;&#26679;&#65306;&#23558;PINN&#21644;&#26368;&#20248;&#20256;&#36755;&#32479;&#19968;&#29992;&#20110;PDE&#36817;&#20284;
&lt;/p&gt;
&lt;p&gt;
Adversarial Adaptive Sampling: Unify PINN and Optimal Transport for the Approximation of PDEs. (arXiv:2305.18702v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18702
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#26469;&#35843;&#25972;&#35757;&#32451;&#38598;&#20013;&#30340;&#38543;&#26426;&#26679;&#26412;&#65292;&#20197;&#20351;PDE&#35299;&#30340;&#27531;&#20313;&#22312;&#26368;&#23567;&#21270;&#26102;&#33021;&#20445;&#25345;&#24179;&#28369;&#30340;&#36718;&#24275;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#23545;&#25239;&#24615;&#25439;&#22833;&#39033;&#20248;&#21270;PINN&#27169;&#22411;&#65292;&#20174;&#32780;&#20351;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#31283;&#23450;&#30340;&#35299;&#12290;&#21516;&#26102;&#26412;&#25991;&#36824;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#21487;&#20197;&#25193;&#23637;&#21040;&#32435;&#20837;&#26368;&#20248;&#20256;&#36755;&#32422;&#26463;&#65292;&#20174;&#32780;&#24418;&#25104;&#20102;&#23558;PINN&#21644;&#26368;&#20248;&#20256;&#36755;&#30340;&#20248;&#28857;&#32467;&#21512;&#36215;&#26469;&#30340;&#32479;&#19968;&#26694;&#26550;&#65292;&#29992;&#20110;PDE&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27714;&#35299;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDE&#65289;&#26159;&#31185;&#23398;&#35745;&#31639;&#30340;&#19968;&#20010;&#26680;&#24515;&#20219;&#21153;&#12290;&#36817;&#24180;&#26469;&#65292;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;PDE&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#65292;&#20855;&#26377;&#26080;&#32593;&#26684;&#31163;&#25955;&#30340;&#28789;&#27963;&#24615;&#21644;&#35299;&#20915;&#39640;&#32500;&#38382;&#39064;&#30340;&#28508;&#21147;&#12290;&#19968;&#20010;&#22522;&#26412;&#30340;&#35745;&#31639;&#22256;&#38590;&#26159;&#35757;&#32451;&#38598;&#20013;&#30340;&#38543;&#26426;&#26679;&#26412;&#24341;&#20837;&#20102;&#32479;&#35745;&#38169;&#35823;&#65292;&#21487;&#33021;&#25104;&#20026;&#26368;&#32456;&#36924;&#36817;&#20013;&#21344;&#20027;&#23548;&#30340;&#35823;&#24046;&#65292;&#20174;&#32780;&#25513;&#30422;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#24314;&#27169;&#33021;&#21147;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;minmax&#20844;&#24335;&#65292;&#21516;&#26102;&#20248;&#21270;&#36817;&#20284;&#30340;&#35299;&#21644;&#30001;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#25552;&#20379;&#30340;&#35757;&#32451;&#38598;&#20013;&#30340;&#38543;&#26426;&#26679;&#26412;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#35843;&#25972;&#35757;&#32451;&#38598;&#20013;&#30340;&#38543;&#26426;&#26679;&#26412;&#65292;&#20351;&#36817;&#20284;PDE&#35299;&#24341;&#36215;&#30340;&#27531;&#20313;&#22312;&#26368;&#23567;&#21270;&#26102;&#33021;&#20445;&#25345;&#24179;&#28369;&#30340;&#36718;&#24275;&#12290;&#36825;&#31181;&#24819;&#27861;&#26159;&#36890;&#36807;&#22312;PINN&#20248;&#21270;&#36807;&#31243;&#20013;&#24341;&#20837;&#23545;&#25239;&#24615;&#25439;&#22833;&#39033;&#26469;&#23454;&#29616;&#30340;&#65292;&#35813;&#25439;&#22833;&#39033;&#40723;&#21169;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#31283;&#23450;&#30340;&#35299;&#65292;&#21363;&#20351;&#35757;&#32451;&#38598;&#20013;&#30340;&#26679;&#26412;&#26377;&#38480;&#25110;&#36755;&#20837;&#21547;&#22122;&#22768;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#33258;&#28982;&#22320;&#25193;&#23637;&#21040;&#32435;&#20837;&#26368;&#20248;&#20256;&#36755;&#32422;&#26463;&#65292;&#20174;&#32780;&#24418;&#25104;&#23558;PINN&#21644;&#26368;&#20248;&#20256;&#36755;&#30340;&#20248;&#28857;&#32467;&#21512;&#36215;&#26469;&#30340;&#32479;&#19968;&#26694;&#26550;&#65292;&#29992;&#20110;PDE&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;
Solving partial differential equations (PDEs) is a central task in scientific computing. Recently, neural network approximation of PDEs has received increasing attention due to its flexible meshless discretization and its potential for high-dimensional problems. One fundamental numerical difficulty is that random samples in the training set introduce statistical errors into the discretization of loss functional which may become the dominant error in the final approximation, and therefore overshadow the modeling capability of the neural network. In this work, we propose a new minmax formulation to optimize simultaneously the approximate solution, given by a neural network model, and the random samples in the training set, provided by a deep generative model. The key idea is to use a deep generative model to adjust random samples in the training set such that the residual induced by the approximate PDE solution can maintain a smooth profile when it is being minimized. Such an idea is ach
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24207;&#25968;&#22238;&#24402;&#27604;&#20363;&#20943;&#23569;&#27169;&#22411;&#30340;&#26494;&#24347;&#26041;&#27861;PRESTO&#65292;&#36890;&#36807;&#23545;&#30456;&#37051;&#26435;&#21521;&#37327;&#20013;&#30456;&#21516;&#29305;&#24449;&#20043;&#38388;&#30340;&#24046;&#24322;&#26045;&#21152;L1&#24809;&#32602;&#65292;&#21033;&#29992;&#20808;&#21069;&#26356;&#20016;&#23500;&#30340;&#25968;&#25454;&#26469;&#25913;&#21892;&#32597;&#35265;&#20107;&#20214;&#30340;&#27010;&#29575;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2305.18700</link><description>&lt;p&gt;
&#36890;&#36807;&#21521;&#27604;&#20363;&#20943;&#23569;&#39044;&#27979;&#32597;&#35265;&#20107;&#20214;
&lt;/p&gt;
&lt;p&gt;
Predicting Rare Events by Shrinking Towards Proportional Odds. (arXiv:2305.18700v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18700
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24207;&#25968;&#22238;&#24402;&#27604;&#20363;&#20943;&#23569;&#27169;&#22411;&#30340;&#26494;&#24347;&#26041;&#27861;PRESTO&#65292;&#36890;&#36807;&#23545;&#30456;&#37051;&#26435;&#21521;&#37327;&#20013;&#30456;&#21516;&#29305;&#24449;&#20043;&#38388;&#30340;&#24046;&#24322;&#26045;&#21152;L1&#24809;&#32602;&#65292;&#21033;&#29992;&#20808;&#21069;&#26356;&#20016;&#23500;&#30340;&#25968;&#25454;&#26469;&#25913;&#21892;&#32597;&#35265;&#20107;&#20214;&#30340;&#27010;&#29575;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#20998;&#31867;&#22120;&#22312;&#20005;&#37325;&#30340;&#31867;&#21035;&#19981;&#24179;&#34913;&#19979;&#26159;&#22256;&#38590;&#30340;&#65292;&#20294;&#35768;&#22810;&#32597;&#35265;&#20107;&#20214;&#26159;&#30001;&#35768;&#22810;&#24120;&#35265;&#30340;&#20013;&#38388;&#32467;&#26524;&#24207;&#21015;&#32452;&#25104;&#30340;&#12290;&#20363;&#22914;&#65292;&#22312;&#22312;&#32447;&#33829;&#38144;&#20013;&#65292;&#29992;&#25143;&#20808;&#30475;&#21040;&#24191;&#21578;&#65292;&#28982;&#21518;&#21487;&#33021;&#28857;&#20987;&#23427;&#65292;&#26368;&#21518;&#21487;&#33021;&#36141;&#20080;&#65307;&#30001;&#20110;&#23427;&#20204;&#30340;&#32597;&#35265;&#24615;&#65292;&#20272;&#35745;&#36141;&#20080;&#30340;&#27010;&#29575;&#26159;&#22256;&#38590;&#30340;&#12290;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#21644;&#25968;&#25454;&#23454;&#39564;&#23637;&#31034;&#20102;&#26089;&#26399;&#27493;&#39588;&#20013;&#26356;&#20016;&#23500;&#30340;&#25968;&#25454;&#21487;&#33021;&#34987;&#21033;&#29992;&#26469;&#25913;&#21892;&#32597;&#35265;&#20107;&#20214;&#30340;&#27010;&#29575;&#20272;&#35745;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;PRESTO&#65292;&#19968;&#31181;&#24207;&#25968;&#22238;&#24402;&#27604;&#20363;&#20943;&#23569;&#27169;&#22411;&#30340;&#26494;&#24347;&#26041;&#27861;&#12290;&#25105;&#20204;&#19981;&#26159;&#20026;&#19968;&#20010;&#20998;&#31163;&#36229;&#24179;&#38754;&#20272;&#35745;&#26435;&#37325;&#65292;&#24182;&#36890;&#36807;&#27599;&#20010;&#20272;&#35745;Bayes&#20915;&#31574;&#36793;&#30028;&#20043;&#38388;&#30340;&#20998;&#31867;&#21453;&#24212;&#23545;&#24212;&#30340;&#21333;&#29420;&#25318;&#25130;&#36827;&#34892;&#24179;&#31227;&#12290;&#25105;&#20204;&#20272;&#35745;&#27599;&#27425;&#36825;&#20123;&#36716;&#25442;&#30340;&#21333;&#29420;&#26435;&#37325;&#12290;&#25105;&#20204;&#23545;&#30456;&#37051;&#26435;&#21521;&#37327;&#20013;&#30456;&#21516;&#29305;&#24449;&#20043;&#38388;&#30340;&#24046;&#24322;&#26045;&#21152;L1&#24809;&#32602;&#65292;&#20197;&#32553;&#23567;&#36825;&#20123;&#26435;&#37325;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training classifiers is difficult with severe class imbalance, but many rare events are the culmination of a sequence with much more common intermediate outcomes. For example, in online marketing a user first sees an ad, then may click on it, and finally may make a purchase; estimating the probability of purchases is difficult because of their rarity. We show both theoretically and through data experiments that the more abundant data in earlier steps may be leveraged to improve estimation of probabilities of rare events. We present PRESTO, a relaxation of the proportional odds model for ordinal regression. Instead of estimating weights for one separating hyperplane that is shifted by separate intercepts for each of the estimated Bayes decision boundaries between adjacent pairs of categorical responses, we estimate separate weights for each of these transitions. We impose an L1 penalty on the differences between weights for the same feature in adjacent weight vectors in order to shrink 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#19968;&#31181;&#26032;&#30340;&#26657;&#20934;&#39044;&#27979;&#30446;&#26631;&#8212;&#8212;parity&#26657;&#20934;&#65292;&#20854;&#32771;&#34385;&#26102;&#38388;&#24207;&#21015;&#20013;&#26410;&#26469;&#35266;&#27979;&#20540;&#30340;&#22686;&#21152;&#25110;&#20943;&#23569;&#12290;&#25105;&#20204;&#20351;&#29992;&#22312;&#32447;&#20108;&#36827;&#21046;&#26657;&#20934;&#26041;&#27861;&#23454;&#29616;&#20102;parity&#26657;&#20934;&#65292;&#24182;&#22312;&#27969;&#34892;&#30149;&#23398;&#12289;&#22825;&#27668;&#39044;&#25253;&#21644;&#26680;&#32858;&#21464;&#25511;&#21046;&#31561;&#39046;&#22495;&#20013;&#34920;&#26126;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.18655</link><description>&lt;p&gt;
Parity&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Parity Calibration. (arXiv:2305.18655v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18655
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#19968;&#31181;&#26032;&#30340;&#26657;&#20934;&#39044;&#27979;&#30446;&#26631;&#8212;&#8212;parity&#26657;&#20934;&#65292;&#20854;&#32771;&#34385;&#26102;&#38388;&#24207;&#21015;&#20013;&#26410;&#26469;&#35266;&#27979;&#20540;&#30340;&#22686;&#21152;&#25110;&#20943;&#23569;&#12290;&#25105;&#20204;&#20351;&#29992;&#22312;&#32447;&#20108;&#36827;&#21046;&#26657;&#20934;&#26041;&#27861;&#23454;&#29616;&#20102;parity&#26657;&#20934;&#65292;&#24182;&#22312;&#27969;&#34892;&#30149;&#23398;&#12289;&#22825;&#27668;&#39044;&#25253;&#21644;&#26680;&#32858;&#21464;&#25511;&#21046;&#31561;&#39046;&#22495;&#20013;&#34920;&#26126;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24207;&#21015;&#22238;&#24402;&#35774;&#32622;&#20013;&#65292;&#20915;&#31574;&#32773;&#21487;&#33021;&#26356;&#20851;&#27880;&#26410;&#26469;&#35266;&#27979;&#20540;&#26159;&#21542;&#27604;&#24403;&#21069;&#20540;&#22686;&#21152;&#25110;&#20943;&#23569;&#65292;&#32780;&#19981;&#26159;&#26410;&#26469;&#35266;&#27979;&#20540;&#30340;&#23454;&#38469;&#20540;&#12290;&#22312;&#27492;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#24179;&#31561;&#26657;&#20934;&#30340;&#27010;&#24565;&#65292;&#23427;&#25429;&#25417;&#20102;&#26102;&#38388;&#24207;&#21015;&#22686;&#20943;&#20107;&#20214;&#30340;&#26657;&#20934;&#39044;&#27979;&#30446;&#26631;&#12290;&#24179;&#31561;&#27010;&#29575;&#21487;&#20197;&#20174;&#36755;&#20986;&#30340;&#39044;&#27979;&#20998;&#24067;&#20013;&#25552;&#21462;&#65292;&#20294;&#25105;&#20204;&#26174;&#31034;&#36825;&#31181;&#31574;&#30053;&#23548;&#33268;&#29702;&#35770;&#19978;&#30340;&#19981;&#21487;&#39044;&#27979;&#24615;&#21644;&#24046;&#21170;&#30340;&#23454;&#38469;&#24615;&#33021;&#12290;&#28982;&#21518;&#25105;&#20204;&#21457;&#29616;&#65292;&#34429;&#28982;&#21407;&#20219;&#21153;&#26159;&#22238;&#24402;&#65292;&#20294;&#24179;&#31561;&#26657;&#20934;&#21487;&#20197;&#34987;&#34920;&#36798;&#20026;&#20108;&#36827;&#21046;&#26657;&#20934;&#12290;&#22522;&#20110;&#36825;&#31181;&#32852;&#31995;&#65292;&#25105;&#20204;&#20351;&#29992;&#22312;&#32447;&#20108;&#36827;&#21046;&#26657;&#20934;&#26041;&#27861;&#23454;&#29616;&#20102;&#24179;&#31561;&#26657;&#20934;&#12290;&#25105;&#20204;&#36890;&#36807;&#27969;&#34892;&#30149;&#23398;&#12289;&#22825;&#27668;&#39044;&#25253;&#21644;&#22522;&#20110;&#27169;&#22411;&#30340;&#26680;&#32858;&#21464;&#25511;&#21046;&#30340;&#23454;&#38469;&#26696;&#20363;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In a sequential regression setting, a decision-maker may be primarily concerned with whether the future observation will increase or decrease compared to the current one, rather than the actual value of the future observation. In this context, we introduce the notion of parity calibration, which captures the goal of calibrated forecasting for the increase-decrease (or "parity") event in a timeseries. Parity probabilities can be extracted from a forecasted distribution for the output, but we show that such a strategy leads to theoretical unpredictability and poor practical performance. We then observe that although the original task was regression, parity calibration can be expressed as binary calibration. Drawing on this connection, we use an online binary calibration method to achieve parity calibration. We demonstrate the effectiveness of our approach on real-world case studies in epidemiology, weather forecasting, and model-based control in nuclear fusion.
&lt;/p&gt;</description></item><item><title>Global-QSGD&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#20840;&#23616;&#32553;&#25918;&#37327;&#21270;&#26426;&#21046;&#65292;&#21487;&#20197;&#25552;&#39640;&#20998;&#24067;&#24335;&#23398;&#20064;&#30340;&#25928;&#29575;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#26114;&#36149;&#30340;&#35823;&#24046;&#21453;&#39304;&#65292;&#24182;&#25552;&#20379;&#20102;&#39640;&#36798;$O(\ sqrt{n})$&#30340;&#39069;&#22806;&#21387;&#32553;&#27604;&#12290;</title><link>http://arxiv.org/abs/2305.18627</link><description>&lt;p&gt;
&#20840;&#23616;&#32553;&#25918;&#37327;&#21270;&#65306;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#30340;&#20998;&#24067;&#24335;&#23398;&#20064;&#23454;&#29992;&#30340;&#26080;&#28014;&#28857;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Global-QSGD: Practical Floatless Quantization for Distributed Learning with Theoretical Guarantees. (arXiv:2305.18627v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18627
&lt;/p&gt;
&lt;p&gt;
Global-QSGD&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#20840;&#23616;&#32553;&#25918;&#37327;&#21270;&#26426;&#21046;&#65292;&#21487;&#20197;&#25552;&#39640;&#20998;&#24067;&#24335;&#23398;&#20064;&#30340;&#25928;&#29575;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#26114;&#36149;&#30340;&#35823;&#24046;&#21453;&#39304;&#65292;&#24182;&#25552;&#20379;&#20102;&#39640;&#36798;$O(\ sqrt{n})$&#30340;&#39069;&#22806;&#21387;&#32553;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#25928;&#30340;&#20998;&#24067;&#24335;&#35757;&#32451;&#26159;&#25512;&#21160;&#28145;&#24230;&#23398;&#20064;&#36817;&#26399;&#36827;&#23637;&#30340;&#20027;&#35201;&#39537;&#21160;&#21147;&#12290;&#28982;&#32780;&#65292;&#36890;&#20449;&#24120;&#24120;&#26159;&#31995;&#32479;&#30340;&#20027;&#35201;&#29942;&#39048;&#24182;&#20855;&#26377;&#39640;&#26114;&#30340;&#20195;&#20215;&#12290;&#22240;&#27492;&#65292;&#38656;&#35201;&#35774;&#35745;&#39640;&#25928;&#30340;&#36890;&#20449;&#26426;&#21046;&#65292;&#26082;&#33021;&#22312;&#32463;&#39564;&#19978;&#25552;&#39640;&#21534;&#21520;&#37327;&#65292;&#21448;&#33021;&#25552;&#20379;&#29702;&#35770;&#20445;&#35777;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#20840;&#23616;-QSGD&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#37327;&#21270;&#36816;&#31639;&#31526;&#65292;&#36890;&#36807;&#20840;&#23616;&#32553;&#25918;&#35774;&#35745;&#26469;&#21152;&#36895;&#22522;&#20110;&#20998;&#24067;&#24335;&#23398;&#20064;&#12290;&#25105;&#20204;&#35777;&#26126;Global-QSGD&#26159;&#31532;&#19968;&#20010;&#29702;&#35770;&#19978;&#20005;&#26684;&#30340;Allreduce&#20860;&#23481;&#21387;&#32553;&#26426;&#21046;&#65292;&#36890;&#36807;&#22312;&#21387;&#32553;&#35823;&#24046;&#21644;&#36890;&#20449;&#33410;&#30465;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#26469;&#23454;&#29616;&#21487;&#35777;&#26126;&#30340;&#21152;&#36895;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#30001;&#20110;&#20854;&#22266;&#26377;&#30340;&#26080;&#20559;&#24615;&#65292;Global-QSGD&#19981;&#20381;&#36182;&#26114;&#36149;&#30340;&#35823;&#24046;&#21453;&#39304;&#65292;&#24182;&#19988;&#30456;&#23545;&#20110;&#27969;&#34892;&#30340;QSGD&#37327;&#21270;&#33021;&#25552;&#20379;&#39640;&#36798;$O(\sqrt{n})$ &#30340;&#39069;&#22806;&#21387;&#32553;&#27604;&#65288;&#20854;&#20013;$n$&#34920;&#31034;&#24037;&#20316;&#32773;&#30340;&#25968;&#37327;&#65289;&#12290;&#20026;&#20102;&#33719;&#24471;&#29702;&#35770;&#20445;&#35777;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#20449;&#24687;&#35770;&#21644;&#20984;&#20998;&#26512;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Efficient distributed training is a principal driver of recent advances in deep learning. However, communication often proves costly and becomes the primary bottleneck in these systems. As a result, there is a demand for the design of efficient communication mechanisms that can empirically boost throughput while providing theoretical guarantees. In this work, we introduce Global-QSGD, a novel family of quantization operators, engineered to accelerate distributed training based on global scaling. We demonstrate that Global-QSGD is the first theoretically rigorous Allreduce-compatible compression mechanism that achieves a provable speed-up by striking a balance between compression error and communication savings. Importantly, Global-QSGD does not rely on costly error feedback due to its inherent unbiasedness and offers up to $O(\sqrt{n})$ additional compression ratio compared to the popular QSGD quantization ($n$ represents the number of workers). To obtain theoretical guarantees, we gen
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;QATS&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#25928;&#35299;&#30721;&#38544;&#34255;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#24207;&#21015;&#12290;&#23427;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#20026;&#22810;&#23545;&#25968;&#21644;&#31435;&#26041;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#20855;&#26377;&#30456;&#23545;&#36739;&#23569;&#29366;&#24577;&#30340;&#22823;&#22411;HMM&#12290;</title><link>http://arxiv.org/abs/2305.18578</link><description>&lt;p&gt;
&#24555;&#36895;&#33258;&#36866;&#24212;&#19977;&#20803;&#20998;&#21106;&#65306;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#30340;&#26377;&#25928;&#35299;&#30721;&#31243;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quick Adaptive Ternary Segmentation: An Efficient Decoding Procedure For Hidden Markov Models. (arXiv:2305.18578v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18578
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;QATS&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#25928;&#35299;&#30721;&#38544;&#34255;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#24207;&#21015;&#12290;&#23427;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#20026;&#22810;&#23545;&#25968;&#21644;&#31435;&#26041;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#20855;&#26377;&#30456;&#23545;&#36739;&#23569;&#29366;&#24577;&#30340;&#22823;&#22411;HMM&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#65288;HMM&#65289;&#20197;&#19981;&#21487;&#35266;&#23519;&#30340;&#65288;&#38544;&#34255;&#30340;&#65289;&#39532;&#23572;&#21487;&#22827;&#38142;&#21644;&#21487;&#35266;&#27979;&#30340;&#36807;&#31243;&#20026;&#29305;&#24449;&#65292;&#21518;&#32773;&#26159;&#38544;&#34255;&#38142;&#30340;&#22122;&#22768;&#29256;&#26412;&#12290;&#20174;&#22024;&#26434;&#30340;&#35266;&#27979;&#20013;&#35299;&#30721;&#21407;&#22987;&#20449;&#21495;&#65288;&#21363;&#38544;&#34255;&#38142;&#65289;&#26159;&#20960;&#20046;&#25152;&#26377;&#22522;&#20110;HMM&#30340;&#25968;&#25454;&#20998;&#26512;&#30340;&#20027;&#35201;&#30446;&#26631;&#12290;&#29616;&#26377;&#30340;&#35299;&#30721;&#31639;&#27861;&#65292;&#22914;&#32500;&#29305;&#27604;&#31639;&#27861;&#65292;&#22312;&#35266;&#27979;&#24207;&#21015;&#38271;&#24230;&#26368;&#22810;&#32447;&#24615;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#24182;&#19988;&#22312;&#39532;&#23572;&#21487;&#22827;&#38142;&#29366;&#24577;&#31354;&#38388;&#30340;&#22823;&#23567;&#20013;&#20855;&#26377;&#27425;&#20108;&#27425;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#24555;&#36895;&#33258;&#36866;&#24212;&#19977;&#20803;&#20998;&#21106;&#65288;QATS&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#20998;&#32780;&#27835;&#20043;&#30340;&#36807;&#31243;&#65292;&#21487;&#22312;&#24207;&#21015;&#38271;&#24230;&#30340;&#22810;&#23545;&#25968;&#35745;&#31639;&#22797;&#26434;&#24230;&#21644;&#39532;&#23572;&#21487;&#22827;&#38142;&#29366;&#24577;&#31354;&#38388;&#30340;&#19977;&#27425;&#35745;&#31639;&#22797;&#26434;&#24230;&#19979;&#35299;&#30721;&#38544;&#34255;&#30340;&#24207;&#21015;&#65292;&#22240;&#27492;&#29305;&#21035;&#36866;&#29992;&#20110;&#20855;&#26377;&#30456;&#23545;&#36739;&#23569;&#29366;&#24577;&#30340;&#22823;&#35268;&#27169;HMM&#12290;&#35813;&#31243;&#24207;&#36824;&#24314;&#35758;&#19968;&#31181;&#26377;&#25928;&#30340;&#25968;&#25454;&#23384;&#20648;&#26041;&#24335;&#65292;&#21363;&#29305;&#23450;&#30340;&#32047;&#31215;&#24635;&#21644;&#12290;&#23454;&#36136;&#19978;&#65292;&#20272;&#35745;&#30340;&#29366;&#24577;&#24207;&#21015;&#25353;&#39034;&#24207;&#26368;&#22823;&#21270;&#23616;&#37096;&#20284;&#28982;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hidden Markov models (HMMs) are characterized by an unobservable (hidden) Markov chain and an observable process, which is a noisy version of the hidden chain. Decoding the original signal (i.e., hidden chain) from the noisy observations is one of the main goals in nearly all HMM based data analyses. Existing decoding algorithms such as the Viterbi algorithm have computational complexity at best linear in the length of the observed sequence, and sub-quadratic in the size of the state space of the Markov chain. We present Quick Adaptive Ternary Segmentation (QATS), a divide-and-conquer procedure which decodes the hidden sequence in polylogarithmic computational complexity in the length of the sequence, and cubic in the size of the state space, hence particularly suited for large scale HMMs with relatively few states. The procedure also suggests an effective way of data storage as specific cumulative sums. In essence, the estimated sequence of states sequentially maximizes local likeliho
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#26500;&#21463;&#21040;&#25968;&#23398;&#21551;&#21457;&#30340;L2O&#27169;&#22411;&#65292;&#20854;&#20855;&#26377;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#21644;&#33391;&#22909;&#30340;&#25512;&#24191;&#24615;&#33021;&#65292;&#24182;&#22522;&#20110;&#25104;&#21151;&#30340;&#26356;&#26032;&#35268;&#21017;&#36890;&#24120;&#28385;&#36275;&#30340;&#22522;&#26412;&#25968;&#23398;&#26465;&#20214;&#36827;&#34892;&#20102;&#25512;&#23548;&#12290;</title><link>http://arxiv.org/abs/2305.18577</link><description>&lt;p&gt;
&#20026;&#23398;&#20064;&#20248;&#21270;&#26500;&#24314;&#25968;&#23398;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
Towards Constituting Mathematical Structures for Learning to Optimize. (arXiv:2305.18577v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18577
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#26500;&#21463;&#21040;&#25968;&#23398;&#21551;&#21457;&#30340;L2O&#27169;&#22411;&#65292;&#20854;&#20855;&#26377;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#21644;&#33391;&#22909;&#30340;&#25512;&#24191;&#24615;&#33021;&#65292;&#24182;&#22522;&#20110;&#25104;&#21151;&#30340;&#26356;&#26032;&#35268;&#21017;&#36890;&#24120;&#28385;&#36275;&#30340;&#22522;&#26412;&#25968;&#23398;&#26465;&#20214;&#36827;&#34892;&#20102;&#25512;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#20174;&#25968;&#25454;&#20013;&#33258;&#21160;&#23398;&#20064;&#20248;&#21270;&#31639;&#27861;&#30340;&#23398;&#20064;&#20248;&#21270;(L2O)&#25216;&#26415;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#24191;&#27867;&#20851;&#27880;&#12290;&#19968;&#31181;&#36890;&#29992;&#30340;L2O&#26041;&#27861;&#21442;&#25968;&#21270;&#20102;&#36845;&#20195;&#26356;&#26032;&#35268;&#21017;&#65292;&#24182;&#23558;&#26356;&#26032;&#26041;&#21521;&#20316;&#20026;&#40657;&#30418;&#32593;&#32476;&#36827;&#34892;&#23398;&#20064;&#12290;&#34429;&#28982;&#36890;&#29992;&#26041;&#27861;&#20855;&#26377;&#24191;&#27867;&#36866;&#29992;&#24615;&#65292;&#20294;&#23398;&#20064;&#30340;&#27169;&#22411;&#21487;&#33021;&#36807;&#25311;&#21512;&#65292;&#26080;&#27861;&#24456;&#22909;&#22320;&#25512;&#24191;&#21040;&#20998;&#24067;&#19981;&#21516;&#30340;&#27979;&#35797;&#38598;&#20013;&#12290;&#26412;&#25991;&#25512;&#23548;&#20102;&#25104;&#21151;&#30340;&#26356;&#26032;&#35268;&#21017;&#36890;&#24120;&#28385;&#36275;&#30340;&#22522;&#26412;&#25968;&#23398;&#26465;&#20214;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;L2O&#27169;&#22411;&#65292;&#20854;&#32467;&#26500;&#21463;&#21040;&#25968;&#23398;&#21551;&#21457;&#65292;&#24182;&#19988;&#20855;&#26377;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#21644;&#33391;&#22909;&#30340;&#25512;&#24191;&#24615;&#33021;&#12290;&#25968;&#20540;&#27169;&#25311;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#65292;&#24182;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;L2O&#27169;&#22411;&#30340;&#33391;&#22909;&#23454;&#39564;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning to Optimize (L2O), a technique that utilizes machine learning to learn an optimization algorithm automatically from data, has gained arising attention in recent years. A generic L2O approach parameterizes the iterative update rule and learns the update direction as a black-box network. While the generic approach is widely applicable, the learned model can overfit and may not generalize well to out-of-distribution test sets. In this paper, we derive the basic mathematical conditions that successful update rules commonly satisfy. Consequently, we propose a novel L2O model with a mathematics-inspired structure that is broadly applicable and generalized well to out-of-distribution problems. Numerical simulations validate our theoretical findings and demonstrate the superior empirical performance of the proposed L2O model.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#30340;&#24378;&#20581;Lipschitz&#36172;&#24466;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#27425;&#32447;&#24615;&#36951;&#25022;&#65292;&#24182;&#22312;&#24378;&#25932;&#25163;&#24773;&#20917;&#19979;&#26368;&#20248;&#12290;</title><link>http://arxiv.org/abs/2305.18543</link><description>&lt;p&gt;
&#38024;&#23545;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#24378;&#20581;Lipschitz&#36172;&#24466;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Robust Lipschitz Bandits to Adversarial Corruptions. (arXiv:2305.18543v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18543
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#30340;&#24378;&#20581;Lipschitz&#36172;&#24466;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#27425;&#32447;&#24615;&#36951;&#25022;&#65292;&#24182;&#22312;&#24378;&#25932;&#25163;&#24773;&#20917;&#19979;&#26368;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Lipschitz&#36172;&#24466;&#31639;&#27861;&#26159;&#19968;&#31181;&#22788;&#29702;&#23450;&#20041;&#22312;&#24230;&#37327;&#31354;&#38388;&#19978;&#30340;&#36830;&#32493;&#33218;&#38598;&#30340;&#38543;&#26426;&#36172;&#24466;&#31639;&#27861;&#30340;&#21464;&#20307;&#65292;&#20854;&#20013;&#22870;&#21169;&#20989;&#25968;&#21463;&#21040;Lipschitz&#32422;&#26463;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;Lipschitz&#36172;&#24466;&#38382;&#39064;&#65292;&#21363;&#22312;&#23545;&#25239;&#24615;&#30772;&#22351;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#33258;&#36866;&#24212;&#25932;&#25163;&#23558;&#38543;&#26426;&#22870;&#21169;&#25439;&#22351;&#21040;&#24635;&#39044;&#31639; $C$&#12290; &#39044;&#31639;&#36890;&#36807;&#26102;&#38388;&#36328;&#24230; $T$ &#20013;&#30340;&#30772;&#22351;&#27700;&#24179;&#20043;&#21644;&#26469;&#34913;&#37327;&#12290; &#25105;&#20204;&#32771;&#34385;&#24369;&#21644;&#24378;&#25932;&#25163;&#65292;&#20854;&#20013;&#24369;&#25932;&#25163;&#22312;&#25915;&#20987;&#20043;&#21069;&#19981;&#30693;&#36947;&#24403;&#21069;&#30340;&#34892;&#21160;&#65292;&#32780;&#24378;&#25932;&#25163;&#21487;&#20197;&#35266;&#23519;&#34892;&#21160;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#25552;&#20986;&#20102;&#31532;&#19968;&#34892;&#24378;&#20581;Lipschitz&#36172;&#24466;&#31639;&#27861;&#65292;&#22312;&#20004;&#31181;&#31867;&#22411;&#30340;&#25932;&#25163;&#19979;&#65292;&#29978;&#33267;&#22312;&#25439;&#22351;&#24635;&#39044;&#31639; $C$ &#26410;&#21521;&#20195;&#29702;&#25259;&#38706;&#30340;&#24773;&#20917;&#19979;&#65292;&#22343;&#33021;&#23454;&#29616;&#27425;&#32447;&#24615;&#36951;&#25022;&#12290;&#25105;&#20204;&#22312;&#27599;&#31181;&#31867;&#22411;&#30340;&#25932;&#25163;&#19979;&#25552;&#20379;&#19979;&#38480;&#65292;&#24182;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#24378;&#31867;&#22411;&#19979;&#26159;&#26368;&#20248;&#30340;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36827;&#34892;&#23454;&#39564;&#20197;&#35828;&#26126;&#35813;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Lipschitz bandit is a variant of stochastic bandits that deals with a continuous arm set defined on a metric space, where the reward function is subject to a Lipschitz constraint. In this paper, we introduce a new problem of Lipschitz bandits in the presence of adversarial corruptions where an adaptive adversary corrupts the stochastic rewards up to a total budget $C$. The budget is measured by the sum of corruption levels across the time horizon $T$. We consider both weak and strong adversaries, where the weak adversary is unaware of the current action before the attack, while the strong one can observe it. Our work presents the first line of robust Lipschitz bandit algorithms that can achieve sub-linear regret under both types of adversary, even when the total budget of corruption $C$ is unrevealed to the agent. We provide a lower bound under each type of adversary, and show that our algorithm is optimal under the strong case. Finally, we conduct experiments to illustrate the effecti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25351;&#20986;&#65292;&#23545;&#20110;&#20351;&#29992;&#24179;&#26041;&#25439;&#22833;&#20989;&#25968;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;(ERM)&#65292;&#20854;&#27425;&#20248;&#24615;&#24517;&#39035;&#24402;&#22240;&#20110;&#22823;&#30340;&#20559;&#24046;&#32780;&#38750;&#26041;&#24046;&#65292;&#24182;&#19988;&#22312;ERM&#30340;&#24179;&#26041;&#35823;&#24046;&#30340;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;&#20013;&#65292;&#26041;&#24046;&#39033;&#24517;&#28982;&#20855;&#26377;&#26497;&#23567;&#30340;&#22833;&#35823;&#29575;&#12290;&#20316;&#32773;&#36824;&#25552;&#20379;&#20102;Chatterjee&#30340;&#19981;&#21487;&#20801;&#35768;&#24615;&#23450;&#29702;&#30340;&#31616;&#21333;&#35777;&#26126;&#65292;&#24182;&#34920;&#31034;&#20182;&#20204;&#30340;&#20272;&#35745;&#34920;&#26126;ERM&#30340;&#31283;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.18508</link><description>&lt;p&gt;
&#35770;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#26041;&#24046;&#12289;&#21487;&#20801;&#35768;&#24615;&#21644;&#31283;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Variance, Admissibility, and Stability of Empirical Risk Minimization. (arXiv:2305.18508v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18508
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25351;&#20986;&#65292;&#23545;&#20110;&#20351;&#29992;&#24179;&#26041;&#25439;&#22833;&#20989;&#25968;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;(ERM)&#65292;&#20854;&#27425;&#20248;&#24615;&#24517;&#39035;&#24402;&#22240;&#20110;&#22823;&#30340;&#20559;&#24046;&#32780;&#38750;&#26041;&#24046;&#65292;&#24182;&#19988;&#22312;ERM&#30340;&#24179;&#26041;&#35823;&#24046;&#30340;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;&#20013;&#65292;&#26041;&#24046;&#39033;&#24517;&#28982;&#20855;&#26377;&#26497;&#23567;&#30340;&#22833;&#35823;&#29575;&#12290;&#20316;&#32773;&#36824;&#25552;&#20379;&#20102;Chatterjee&#30340;&#19981;&#21487;&#20801;&#35768;&#24615;&#23450;&#29702;&#30340;&#31616;&#21333;&#35777;&#26126;&#65292;&#24182;&#34920;&#31034;&#20182;&#20204;&#30340;&#20272;&#35745;&#34920;&#26126;ERM&#30340;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#20351;&#29992;&#24179;&#26041;&#25439;&#22833;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#21487;&#33021;&#20250;&#36798;&#21040;&#26497;&#23567;&#30340;&#26368;&#22823;&#22833;&#35823;&#29575;&#12290;&#26412;&#25991;&#30340;&#20851;&#38190;&#20449;&#24687;&#26159;&#65292;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;ERM&#30340;&#27425;&#20248;&#24615;&#24517;&#39035;&#24402;&#22240;&#20110;&#22823;&#30340;&#20559;&#24046;&#32780;&#38750;&#26041;&#24046;&#12290;&#22312;ERM&#30340;&#24179;&#26041;&#35823;&#24046;&#30340;&#20559;&#24046;-&#26041;&#24046;&#20998;&#35299;&#20013;&#65292;&#26041;&#24046;&#39033;&#24517;&#28982;&#20855;&#26377;&#26497;&#23567;&#30340;&#22833;&#35823;&#29575;&#12290;&#25105;&#20204;&#20026;&#22266;&#23450;&#35774;&#35745;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#12289;&#20351;&#29992;&#27010;&#29575;&#26041;&#27861;&#35777;&#26126;&#36825;&#19968;&#20107;&#23454;&#30340;&#35777;&#26126;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#22312;&#38543;&#26426;&#35774;&#35745;&#35774;&#32622;&#19979;&#20026;&#21508;&#31181;&#27169;&#22411;&#35777;&#26126;&#20102;&#36825;&#19968;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102; Chatterjee &#19981;&#21487;&#20801;&#35768;&#24615;&#23450;&#29702; (Chatterjee, 2014, Theorem 1.4) &#30340;&#31616;&#21333;&#35777;&#26126;&#65292;&#35813;&#23450;&#29702;&#25351;&#20986;&#65292;&#22312;&#22266;&#23450;&#35774;&#35745;&#35774;&#32622;&#20013;&#65292;ERM&#19981;&#33021;&#34987;&#25490;&#38500;&#20026;&#19968;&#31181;&#26368;&#20248;&#26041;&#27861;&#65292;&#24182;&#23558;&#35813;&#32467;&#26524;&#25193;&#23637;&#21040;&#38543;&#26426;&#35774;&#35745;&#35774;&#32622;&#12290;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#34920;&#26126;ERM&#30340;&#31283;&#23450;&#24615;&#65292;&#20026;Caponnetto&#21644;Rakhlin(2006)&#30340;&#38750;Donsker&#31867;&#30340;&#20027;&#35201;&#32467;&#26524;&#25552;&#20379;&#20102;&#34917;&#20805;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is well known that Empirical Risk Minimization (ERM) with squared loss may attain minimax suboptimal error rates (Birg\'e and Massart, 1993). The key message of this paper is that, under mild assumptions, the suboptimality of ERM must be due to large bias rather than variance. More precisely, in the bias-variance decomposition of the squared error of the ERM, the variance term necessarily enjoys the minimax rate. In the case of fixed design, we provide an elementary proof of this fact using the probabilistic method. Then, we prove this result for various models in the random design setting. In addition, we provide a simple proof of Chatterjee's admissibility theorem (Chatterjee, 2014, Theorem 1.4), which states that ERM cannot be ruled out as an optimal method, in the fixed design setting, and extend this result to the random design setting. We also show that our estimates imply stability of ERM, complementing the main result of Caponnetto and Rakhlin (2006) for non-Donsker classes.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;$\mathbb{S}^{d-1}$&#19978;&#20351;&#29992;ReLU&#28608;&#27963;&#20989;&#25968;&#30340;&#23485;&#27531;&#24046;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#34920;&#26126;&#24403;&#23485;&#24230;$m\rightarrow\infty$&#26102;&#65292;&#27531;&#24046;&#32593;&#32476;&#26680;(RNK)&#32479;&#19968;&#25910;&#25947;&#21040;&#27531;&#24046;&#31070;&#32463;&#20999;&#21521;&#26680;(RNTK)&#65292;&#24182;&#19988;&#26089;&#20572;&#31574;&#30053;&#30340;&#23485;&#27531;&#24046;&#32593;&#32476;&#21487;&#20197;&#36798;&#21040;&#26497;&#23567;&#21270;&#36895;&#29575;&#65292;&#20294;&#22312;&#35757;&#32451;&#36807;&#24230;&#25311;&#21512;&#25968;&#25454;&#26102;&#26080;&#27861;&#24456;&#22909;&#22320;&#25512;&#24191;&#12290;</title><link>http://arxiv.org/abs/2305.18506</link><description>&lt;p&gt;
&#23485;&#27531;&#24046;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Generalization Ability of Wide Residual Networks. (arXiv:2305.18506v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18506
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;$\mathbb{S}^{d-1}$&#19978;&#20351;&#29992;ReLU&#28608;&#27963;&#20989;&#25968;&#30340;&#23485;&#27531;&#24046;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#34920;&#26126;&#24403;&#23485;&#24230;$m\rightarrow\infty$&#26102;&#65292;&#27531;&#24046;&#32593;&#32476;&#26680;(RNK)&#32479;&#19968;&#25910;&#25947;&#21040;&#27531;&#24046;&#31070;&#32463;&#20999;&#21521;&#26680;(RNTK)&#65292;&#24182;&#19988;&#26089;&#20572;&#31574;&#30053;&#30340;&#23485;&#27531;&#24046;&#32593;&#32476;&#21487;&#20197;&#36798;&#21040;&#26497;&#23567;&#21270;&#36895;&#29575;&#65292;&#20294;&#22312;&#35757;&#32451;&#36807;&#24230;&#25311;&#21512;&#25968;&#25454;&#26102;&#26080;&#27861;&#24456;&#22909;&#22320;&#25512;&#24191;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;$\mathbb{S}^{d-1}$&#19978;&#20351;&#29992;ReLU&#28608;&#27963;&#20989;&#25968;&#30340;&#23485;&#27531;&#24046;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#39318;&#20808;&#34920;&#26126;&#65292;&#24403;&#23485;&#24230;$m\rightarrow\infty$&#26102;&#65292;&#27531;&#24046;&#32593;&#32476;&#26680;(RNK)&#32479;&#19968;&#25910;&#25947;&#21040;&#27531;&#24046;&#31070;&#32463;&#20999;&#21521;&#26680;(RNTK)&#12290;&#36825;&#31181;&#32479;&#19968;&#25910;&#25947;&#36827;&#19968;&#27493;&#20445;&#35777;&#20102;&#27531;&#24046;&#32593;&#32476;&#30340;&#27867;&#21270;&#35823;&#24046;&#25910;&#25947;&#20110;&#30456;&#23545;&#20110;RNTK&#30340;&#26680;&#22238;&#24402;&#30340;&#35823;&#24046;&#12290;&#20316;&#20026;&#30452;&#25509;&#25512;&#35770;&#65292;&#25105;&#20204;&#25351;&#20986;&#65306;$i$)&#22914;&#26524;&#30446;&#26631;&#22238;&#24402;&#20989;&#25968;&#33853;&#22312;&#19982;RNTK&#30456;&#20851;&#32852;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;(RKHS)&#20013;&#65292;&#37319;&#29992;&#26089;&#20572;&#31574;&#30053;&#30340;&#23485;&#27531;&#24046;&#32593;&#32476;&#21487;&#20197;&#36798;&#21040;&#26497;&#23567;&#21270;&#36895;&#29575;&#65307;$ii$)&#22914;&#26524;&#35757;&#32451;&#21040;&#36807;&#24230;&#25311;&#21512;&#25968;&#25454;&#65292;&#21017;&#26080;&#27861;&#24456;&#22909;&#22320;&#25512;&#24191;&#23485;&#27531;&#24046;&#32593;&#32476;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20171;&#32461;&#19968;&#20123;&#23454;&#39564;&#26469;&#35843;&#21644;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#19982;&#24191;&#27867;&#35266;&#23519;&#21040;&#30340;&#8220;&#33391;&#24615;&#36807;&#25311;&#21512;&#29616;&#35937;&#8221;&#20043;&#38388;&#30340;&#30683;&#30462;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the generalization ability of the wide residual network on $\mathbb{S}^{d-1}$ with the ReLU activation function. We first show that as the width $m\rightarrow\infty$, the residual network kernel (RNK) uniformly converges to the residual neural tangent kernel (RNTK). This uniform convergence further guarantees that the generalization error of the residual network converges to that of the kernel regression with respect to the RNTK. As direct corollaries, we then show $i)$ the wide residual network with the early stopping strategy can achieve the minimax rate provided that the target regression function falls in the reproducing kernel Hilbert space (RKHS) associated with the RNTK; $ii)$ the wide residual network can not generalize well if it is trained till overfitting the data. We finally illustrate some experiments to reconcile the contradiction between our theoretical result and the widely observed ``benign overfitting phenomenon''
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#24378;&#21270;&#23398;&#20064;&#20013;&#20154;&#31867;&#21453;&#39304;&#26597;&#35810;&#30340;&#26377;&#25928;&#37319;&#26679;&#26041;&#27861;&#65292;&#20197;&#22312;&#26368;&#23569;&#30340;&#20154;&#31867;&#21453;&#39304;&#19979;&#23398;&#20064;&#26368;&#20339;&#31574;&#30053;&#65292;&#24182;&#21487;&#24212;&#29992;&#20110;&#20855;&#26377;&#32447;&#24615;&#21442;&#25968;&#21270;&#21644;&#26410;&#30693;&#36807;&#28193;&#30340;&#20559;&#22909;&#27169;&#22411;&#65292;&#24182;&#24341;&#20837;&#20102;&#22522;&#20110;&#34892;&#21160;&#27604;&#36739;&#21453;&#39304;&#30340;RLHF&#12290;</title><link>http://arxiv.org/abs/2305.18505</link><description>&lt;p&gt;
&#22914;&#20309;&#26377;&#25928;&#22320;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#36827;&#34892;&#20154;&#31867;&#21453;&#39304;&#26597;&#35810;&#65311;
&lt;/p&gt;
&lt;p&gt;
How to Query Human Feedback Efficiently in RL?. (arXiv:2305.18505v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18505
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#24378;&#21270;&#23398;&#20064;&#20013;&#20154;&#31867;&#21453;&#39304;&#26597;&#35810;&#30340;&#26377;&#25928;&#37319;&#26679;&#26041;&#27861;&#65292;&#20197;&#22312;&#26368;&#23569;&#30340;&#20154;&#31867;&#21453;&#39304;&#19979;&#23398;&#20064;&#26368;&#20339;&#31574;&#30053;&#65292;&#24182;&#21487;&#24212;&#29992;&#20110;&#20855;&#26377;&#32447;&#24615;&#21442;&#25968;&#21270;&#21644;&#26410;&#30693;&#36807;&#28193;&#30340;&#20559;&#22909;&#27169;&#22411;&#65292;&#24182;&#24341;&#20837;&#20102;&#22522;&#20110;&#34892;&#21160;&#27604;&#36739;&#21453;&#39304;&#30340;RLHF&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#31867;&#21453;&#39304;&#24378;&#21270;&#23398;&#20064;&#65288;RLHF&#65289;&#26159;&#19968;&#31181;&#33539;&#20363;&#65292;&#22312;&#27492;&#33539;&#20363;&#19979;&#65292;RL&#20195;&#29702;&#23398;&#20064;&#20351;&#29992;&#23545;&#36712;&#36857;&#30340;&#25104;&#23545;&#20248;&#20808;&#32423;&#21453;&#39304;&#26469;&#26368;&#20248;&#21270;&#20219;&#21153;&#65292;&#32780;&#19981;&#26159;&#20351;&#29992;&#26126;&#30830;&#30340;&#22870;&#21169;&#20449;&#21495;&#12290;&#23613;&#31649;RLHF&#22312;&#24494;&#35843;&#35821;&#35328;&#27169;&#22411;&#26041;&#38754;&#24050;&#32463;&#21462;&#24471;&#20102;&#23454;&#29992;&#25104;&#21151;&#65292;&#20294;&#29616;&#26377;&#30340;&#23454;&#35777;&#30740;&#31350;&#24182;&#26410;&#35299;&#20915;&#22914;&#20309;&#39640;&#25928;&#37319;&#26679;&#36712;&#36857;&#23545;&#20197;&#26597;&#35810;&#20154;&#31867;&#21453;&#39304;&#30340;&#25361;&#25112;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#37319;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#33719;&#21462;&#25506;&#32034;&#24615;&#36712;&#36857;&#65292;&#22312;&#25910;&#38598;&#20219;&#20309;&#20154;&#31867;&#21453;&#39304;&#20043;&#21069;&#65292;&#20351;&#23398;&#20064;&#38544;&#34255;&#30340;&#22870;&#21169;&#20989;&#25968;&#26356;&#21152;&#20934;&#30830;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#19982;&#29616;&#26377;&#25991;&#29486;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#32447;&#24615;&#21442;&#25968;&#21270;&#21644;&#26410;&#30693;&#36807;&#28193;&#30340;&#22522;&#20110;&#20559;&#22909;&#27169;&#22411;&#19979;&#23398;&#20064;&#26368;&#20248;&#31574;&#30053;&#25152;&#38656;&#30340;&#20154;&#31867;&#21453;&#39304;&#26356;&#23569;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#32435;&#20837;&#32447;&#24615;&#21644;&#20302;&#31209;MDPs&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;&#22522;&#20110;&#34892;&#21160;&#27604;&#36739;&#30340;&#21453;&#39304;&#30340;RLHF&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#37319;&#26679;&#26041;&#27861;&#65292;&#20197;&#22312;&#20248;&#21270;&#20855;&#26377;&#26377;&#38480;&#21453;&#39304;&#30340;&#20219;&#21153;&#26102;&#33719;&#24471;&#25506;&#32034;&#24615;&#36712;&#36857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning with Human Feedback (RLHF) is a paradigm in which an RL agent learns to optimize a task using pair-wise preference-based feedback over trajectories, rather than explicit reward signals. While RLHF has demonstrated practical success in fine-tuning language models, existing empirical work does not address the challenge of how to efficiently sample trajectory pairs for querying human feedback. In this study, we propose an efficient sampling approach to acquiring exploratory trajectories that enable accurate learning of hidden reward functions before collecting any human feedback. Theoretical analysis demonstrates that our algorithm requires less human feedback for learning the optimal policy under preference-based models with linear parameterization and unknown transitions, compared to the existing literature. Specifically, our framework can incorporate linear and low-rank MDPs. Additionally, we investigate RLHF with action-based comparison feedback and introduce an
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25506;&#35752;&#22312; SGD &#19979;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#21333;&#25351;&#25968;&#30446;&#26631;&#20989;&#25968;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#38382;&#39064;&#65292;&#21457;&#29616;&#36807;&#21442;&#25968;&#21270;&#21482;&#20250;&#22686;&#21152;&#19968;&#23450;&#22240;&#23376;&#30340;&#25910;&#25947;&#24615;&#65292;&#19981;&#21516;&#32500;&#24230;&#21644;&#23485;&#24230;&#30340;&#21069;&#32622;&#22240;&#23376;&#31934;&#30830;&#32467;&#26524;&#25581;&#31034;&#12290;</title><link>http://arxiv.org/abs/2305.18502</link><description>&lt;p&gt;
&#36867;&#31163;&#24179;&#24248;&#65306;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#22914;&#20309;&#22312; SGD &#19979;&#23398;&#20064;&#22256;&#38590;&#30340;&#21333;&#25351;&#26631;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Escaping mediocrity: how two-layer networks learn hard single-index models with SGD. (arXiv:2305.18502v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18502
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25506;&#35752;&#22312; SGD &#19979;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#21333;&#25351;&#25968;&#30446;&#26631;&#20989;&#25968;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#38382;&#39064;&#65292;&#21457;&#29616;&#36807;&#21442;&#25968;&#21270;&#21482;&#20250;&#22686;&#21152;&#19968;&#23450;&#22240;&#23376;&#30340;&#25910;&#25947;&#24615;&#65292;&#19981;&#21516;&#32500;&#24230;&#21644;&#23485;&#24230;&#30340;&#21069;&#32622;&#22240;&#23376;&#31934;&#30830;&#32467;&#26524;&#25581;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#19979;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#21333;&#25351;&#25968;&#30446;&#26631;&#20989;&#25968;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#38382;&#39064;&#65292;&#37325;&#28857;&#20851;&#27880;&#22312;&#21021;&#22987;&#21270;&#26102;&#23384;&#22312;&#35768;&#22810;&#24179;&#22374;&#26041;&#21521;&#30340;&#25361;&#25112;&#24615;&#24773;&#20917;&#12290;&#24050;&#32463;&#26377;&#30740;&#31350;&#34920;&#26126;&#65292;&#36825;&#31181;&#24773;&#20917;&#19979;&#36890;&#24120;&#38656;&#35201; $n=O(d\log{d})$ &#20010;&#26679;&#26412;&#12290;&#20294;&#26159;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#22312;&#39640;&#32500;&#24230;&#21644;&#19981;&#21516;&#23485;&#24230;&#24773;&#20917;&#19979;&#30340;&#21069;&#32622;&#22240;&#23376;&#30340;&#31934;&#30830;&#32467;&#26524;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#21457;&#29616;&#34920;&#26126;&#65292;&#22312;&#36825;&#20010;&#38382;&#39064;&#31867;&#20013;&#65292;&#36807;&#21442;&#25968;&#21270;&#21482;&#20250;&#22686;&#21152;&#19968;&#23450;&#22240;&#23376;&#30340;&#25910;&#25947;&#24615;&#12290;&#36825;&#20123;&#35265;&#35299;&#22522;&#20110; SGD &#21160;&#24577;&#30340;&#20302;&#32500;&#24230;&#38543;&#26426;&#36807;&#31243;&#27169;&#22411;&#65292;&#20854;&#20013;&#36867;&#31163;&#24179;&#24248;&#31561;&#21516;&#20110;&#35745;&#31639;&#20986;&#31449;&#20986;&#26102;&#38388;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35777;&#26126;&#36825;&#20010;&#36807;&#31243;&#30340;&#30830;&#23450;&#24615;&#36817;&#20284;&#36275;&#20197;&#20195;&#34920;&#36867;&#36920;&#26102;&#38388;&#65292;&#36825;&#24847;&#21619;&#30528;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#38543;&#26426;&#24615;&#30340;&#20316;&#29992;&#21487;&#33021;&#24456;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study explores the sample complexity for two-layer neural networks to learn a single-index target function under Stochastic Gradient Descent (SGD), focusing on the challenging regime where many flat directions are present at initialization. It is well-established that in this scenario $n=O(d\log{d})$ samples are typically needed. However, we provide precise results concerning the pre-factors in high-dimensional contexts and for varying widths. Notably, our findings suggest that overparameterization can only enhance convergence by a constant factor within this problem class. These insights are grounded in the reduction of SGD dynamics to a stochastic process in lower dimensions, where escaping mediocrity equates to calculating an exit time. Yet, we demonstrate that a deterministic approximation of this process adequately represents the escape time, implying that the role of stochasticity may be minimal in this scenario.
&lt;/p&gt;</description></item><item><title>&#27492;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#20030;&#38598;&#23725;&#20272;&#35745;&#22120;&#20013;&#23376;&#37319;&#26679;&#21644;&#23725;&#22238;&#24402;&#20043;&#38388;&#30340;&#31561;&#20215;&#24615;&#65292;&#21457;&#29616;&#20108;&#32773;&#22312;&#19968;&#23450;&#36335;&#24452;&#20013;&#26159;&#28176;&#36817;&#31561;&#20215;&#30340;&#65292;&#24182;&#25552;&#20986;&#20102;&#25968;&#25454;&#30456;&#20851;&#30340;&#26041;&#27861;&#30830;&#23450;&#31561;&#20215;&#36335;&#24452;&#65292;&#38388;&#25509;&#35299;&#20915;&#20102;&#23725;&#22238;&#24402;&#35843;&#20248;&#20013;&#39044;&#27979;&#39118;&#38505;&#21333;&#35843;&#24615;&#30340;&#24433;&#21709;&#22240;&#32032;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.18496</link><description>&lt;p&gt;
&#23376;&#37319;&#26679;&#19982;&#23725;&#22238;&#24402;&#30340;&#24191;&#20041;&#31561;&#20215;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Generalized equivalences between subsampling and ridge regularization. (arXiv:2305.18496v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18496
&lt;/p&gt;
&lt;p&gt;
&#27492;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#20030;&#38598;&#23725;&#20272;&#35745;&#22120;&#20013;&#23376;&#37319;&#26679;&#21644;&#23725;&#22238;&#24402;&#20043;&#38388;&#30340;&#31561;&#20215;&#24615;&#65292;&#21457;&#29616;&#20108;&#32773;&#22312;&#19968;&#23450;&#36335;&#24452;&#20013;&#26159;&#28176;&#36817;&#31561;&#20215;&#30340;&#65292;&#24182;&#25552;&#20986;&#20102;&#25968;&#25454;&#30456;&#20851;&#30340;&#26041;&#27861;&#30830;&#23450;&#31561;&#20215;&#36335;&#24452;&#65292;&#38388;&#25509;&#35299;&#20915;&#20102;&#23725;&#22238;&#24402;&#35843;&#20248;&#20013;&#39044;&#27979;&#39118;&#38505;&#21333;&#35843;&#24615;&#30340;&#24433;&#21709;&#22240;&#32032;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#38024;&#23545;&#20030;&#38598;&#23725;&#20272;&#35745;&#22120;&#65292;&#24314;&#31435;&#20102;&#23376;&#37319;&#26679;&#21644;&#23725;&#22238;&#24402;&#20043;&#38388;&#30340;&#31934;&#30830;&#32467;&#26500;&#21644;&#39118;&#38505;&#31561;&#20215;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#24403;&#29992;&#19981;&#21516;&#30340;&#23725;&#27491;&#21017;&#21270;&#27700;&#24179;$\lambda$&#21644;&#23376;&#37319;&#26679;&#27604;&#20363;$\psi$&#25311;&#21512;&#23376;&#26679;&#23725;&#20272;&#35745;&#22120;&#30340;&#32447;&#24615;&#21644;&#20108;&#27425;&#27867;&#20989;&#65292;&#22312;$(\lambda,\psi)$-&#24179;&#38754;&#19978;&#27839;&#30528;&#29305;&#23450;&#36335;&#24452;&#28176;&#36817;&#31561;&#20215;&#65288;&#20854;&#20013;$\psi$&#26159;&#29305;&#24449;&#32500;&#24230;&#19982;&#23376;&#37319;&#26679;&#22823;&#23567;&#30340;&#27604;&#29575;&#65289;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20165;&#35201;&#27714;&#29305;&#24449;&#21644;&#21709;&#24212;&#20998;&#24067;&#20855;&#26377;&#26377;&#30028;&#30697;&#65292;&#24182;&#20801;&#35768;&#20219;&#24847;&#32852;&#21512;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#25968;&#25454;&#30456;&#20851;&#30340;&#26041;&#27861;&#26469;&#30830;&#23450;$(\lambda,\psi)$&#30340;&#31561;&#20215;&#36335;&#24452;&#12290;&#25105;&#20204;&#32467;&#26524;&#30340;&#38388;&#25509;&#21547;&#20041;&#26159;&#65292;&#22312;&#25968;&#25454;&#26041;&#38754;&#27604;&#20363;&#20013;&#65292;&#35843;&#20248;&#30340;&#23725;&#22238;&#24402;&#21576;&#29616;&#20986;&#21333;&#35843;&#39044;&#27979;&#39118;&#38505;&#12290;&#36825;&#35299;&#20915;&#20102;Nakkiran&#31561;&#20154;&#25552;&#20986;&#30340;&#19968;&#20010;&#36817;&#26399;&#26410;&#35299;&#20915;&#30340;&#24320;&#25918;&#24615;&#38382;&#39064;&#65292;&#22312;&#19968;&#33324;&#25968;&#25454;&#20998;&#24067;&#21644;&#28201;&#21644;&#30340;&#27491;&#21017;&#26465;&#20214;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
We establish precise structural and risk equivalences between subsampling and ridge regularization for ensemble ridge estimators. Specifically, we prove that linear and quadratic functionals of subsample ridge estimators, when fitted with different ridge regularization levels $\lambda$ and subsample aspect ratios $\psi$, are asymptotically equivalent along specific paths in the $(\lambda, \psi )$-plane (where $\psi$ is the ratio of the feature dimension to the subsample size). Our results only require bounded moment assumptions on feature and response distributions and allow for arbitrary joint distributions. Furthermore, we provide a datadependent method to determine the equivalent paths of $(\lambda, \psi )$. An indirect implication of our equivalences is that optimally-tuned ridge regression exhibits a monotonic prediction risk in the data aspect ratio. This resolves a recent open problem raised by Nakkiran et al. under general data distributions and a mild regularity condition that
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#21518;&#39564;&#38598;&#20013;&#30340;&#36125;&#21494;&#26031;&#31232;&#30095;&#22240;&#23376;&#27169;&#22411;&#65292;&#21487;&#20197;&#25512;&#26029;&#22240;&#23376;&#32500;&#25968;&#21644;&#21152;&#36733;&#30697;&#38453;&#30340;&#31232;&#30095;&#32467;&#26500;&#65292;&#21516;&#26102;&#20445;&#25345;&#35745;&#31639;&#21487;&#34892;&#24615;&#65292;&#24182;&#33719;&#24471;&#20102;&#20248;&#36234;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.18488</link><description>&lt;p&gt;
&#19968;&#31181;&#33258;&#36866;&#24212;&#21518;&#39564;&#38598;&#20013;&#30340;&#36125;&#21494;&#26031;&#31232;&#30095;&#22240;&#23376;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Bayesian sparse factor model with adaptive posterior concentration. (arXiv:2305.18488v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18488
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#21518;&#39564;&#38598;&#20013;&#30340;&#36125;&#21494;&#26031;&#31232;&#30095;&#22240;&#23376;&#27169;&#22411;&#65292;&#21487;&#20197;&#25512;&#26029;&#22240;&#23376;&#32500;&#25968;&#21644;&#21152;&#36733;&#30697;&#38453;&#30340;&#31232;&#30095;&#32467;&#26500;&#65292;&#21516;&#26102;&#20445;&#25345;&#35745;&#31639;&#21487;&#34892;&#24615;&#65292;&#24182;&#33719;&#24471;&#20102;&#20248;&#36234;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#29992;&#20110;&#39640;&#32500;&#31232;&#30095;&#22240;&#23376;&#27169;&#22411;&#30340;&#25512;&#26029;&#65292;&#26082;&#21487;&#20197;&#25512;&#26029;&#22240;&#23376;&#32500;&#25968;&#65292;&#21448;&#21487;&#20197;&#25512;&#26029;&#21152;&#36733;&#30697;&#38453;&#30340;&#31232;&#30095;&#32467;&#26500;&#12290;&#20854;&#21019;&#26032;&#20043;&#22788;&#22312;&#20110;&#24341;&#20837;&#20102;&#19968;&#23450;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#20351;&#24471;&#31232;&#30095;&#27700;&#24179;&#21644;&#22240;&#23376;&#32500;&#25968;&#36827;&#34892;&#33258;&#36866;&#24212;&#21518;&#39564;&#38598;&#20013;&#65292;&#21516;&#26102;&#20445;&#25345;&#35745;&#31639;&#21487;&#34892;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#21518;&#39564;&#20998;&#24067;&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#38598;&#20013;&#20110;&#30495;&#23454;&#22240;&#23376;&#32500;&#24230;&#65292;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#36825;&#31181;&#21518;&#39564;&#19968;&#33268;&#24615;&#20250;&#38543;&#30528;&#30495;&#23454;&#21152;&#36733;&#30697;&#38453;&#30340;&#31232;&#30095;&#27700;&#24179;&#21644;&#22122;&#22768;&#26041;&#24046;&#32780;&#33258;&#36866;&#24212;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#22312;&#26356;&#19968;&#33324;&#30340;&#24773;&#20917;&#19979;&#36798;&#21040;&#20102;&#22240;&#23376;&#32500;&#25968;&#30340;&#26368;&#20248;&#26816;&#27979;&#29575;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#33719;&#24471;&#20102;&#36817;&#20046;&#26368;&#20248;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#21518;&#39564;&#38598;&#20013;&#36895;&#29575;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#25968;&#20540;&#23454;&#39564;&#65292;&#24182;&#23637;&#31034;&#20102;&#19982;&#29616;&#26377;&#26041;&#27861;&#30340;&#27604;&#36739;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a new Bayesian inference method for a high-dimensional sparse factor model that allows both the factor dimensionality and the sparse structure of the loading matrix to be inferred. The novelty is to introduce a certain dependence between the sparsity level and the factor dimensionality, which leads to adaptive posterior concentration while keeping computational tractability. We show that the posterior distribution asymptotically concentrates on the true factor dimensionality, and more importantly, this posterior consistency is adaptive to the sparsity level of the true loading matrix and the noise variance. We also prove that the proposed Bayesian model attains the optimal detection rate of the factor dimensionality in a more general situation than those found in the literature. Moreover, we obtain a near-optimal posterior concentration rate of the covariance matrix. Numerical studies are conducted and show the superiority of the proposed method compared with 
&lt;/p&gt;</description></item><item><title>&#31070;&#32463;&#20613;&#37324;&#21494;&#21464;&#25442;&#26159;&#19968;&#31181;&#36890;&#29992;&#30340;&#31561;&#21464;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#22312;&#19981;&#38656;&#35201;&#26174;&#24335;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#32452;&#30340;&#28508;&#22312;&#32447;&#24615;&#20316;&#29992;&#65292;&#23454;&#29616;&#23545;&#25968;&#25454;&#38544;&#34255;&#32467;&#26500;&#30340;&#25552;&#21462;&#12290;</title><link>http://arxiv.org/abs/2305.18484</link><description>&lt;p&gt;
&#31070;&#32463;&#20613;&#37324;&#21494;&#21464;&#25442;&#65306;&#31561;&#21464;&#34920;&#31034;&#23398;&#20064;&#30340;&#36890;&#29992;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Neural Fourier Transform: A General Approach to Equivariant Representation Learning. (arXiv:2305.18484v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18484
&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#20613;&#37324;&#21494;&#21464;&#25442;&#26159;&#19968;&#31181;&#36890;&#29992;&#30340;&#31561;&#21464;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#22312;&#19981;&#38656;&#35201;&#26174;&#24335;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#32452;&#30340;&#28508;&#22312;&#32447;&#24615;&#20316;&#29992;&#65292;&#23454;&#29616;&#23545;&#25968;&#25454;&#38544;&#34255;&#32467;&#26500;&#30340;&#25552;&#21462;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#31216;&#23398;&#20064;&#24050;&#34987;&#35777;&#26126;&#26159;&#25552;&#21462;&#25968;&#25454;&#38544;&#34255;&#32467;&#26500;&#30340;&#26377;&#25928;&#26041;&#27861;&#65292;&#20854;&#20013;&#31561;&#21464;&#20851;&#31995;&#27010;&#24565;&#36215;&#30528;&#20013;&#24515;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#24403;&#21069;&#30740;&#31350;&#37117;&#24314;&#31435;&#22312;&#24314;&#31569;&#29702;&#35770;&#21644;&#23545;&#25968;&#25454;&#24418;&#24335;&#30340;&#30456;&#24212;&#20551;&#35774;&#20043;&#19978;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#31070;&#32463;&#20613;&#37324;&#21494;&#21464;&#25442;&#65288;NFT&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#23398;&#20064;&#32452;&#30340;&#28508;&#22312;&#32447;&#24615;&#20316;&#29992;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#32780;&#26080;&#38656;&#20551;&#35774;&#20851;&#20110;&#32452;&#22914;&#20309;&#20316;&#29992;&#20110;&#25968;&#25454;&#30340;&#26174;&#24335;&#30693;&#35782;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;NFT&#30340;&#29702;&#35770;&#22522;&#30784;&#65292;&#24182;&#34920;&#26126;&#31561;&#21464;&#29305;&#24449;&#30340;&#23384;&#22312;&#65292;&#21363;&#22312;&#31561;&#21464;&#24615;&#23398;&#20064;&#20013;&#26222;&#36941;&#20551;&#23450;&#30340;&#65292;&#31561;&#20215;&#20110;&#25968;&#25454;&#31354;&#38388;&#20013;&#23384;&#22312;&#19968;&#32452;&#19981;&#21464;&#26680;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#23454;&#39564;&#32467;&#26524;&#65292;&#28436;&#31034;&#20102;&#22312;&#20855;&#26377;&#19981;&#21516;&#31243;&#24230;&#30340;&#20851;&#20110;&#25805;&#20316;&#32452;&#30340;&#30693;&#35782;&#30340;&#20856;&#22411;&#22330;&#26223;&#20013;&#24212;&#29992;NFT&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Symmetry learning has proven to be an effective approach for extracting the hidden structure of data, with the concept of equivariance relation playing the central role. However, most of the current studies are built on architectural theory and corresponding assumptions on the form of data. We propose Neural Fourier Transform (NFT), a general framework of learning the latent linear action of the group without assuming explicit knowledge of how the group acts on data. We present the theoretical foundations of NFT and show that the existence of a linear equivariant feature, which has been assumed ubiquitously in equivariance learning, is equivalent to the existence of a group invariant kernel on the dataspace. We also provide experimental results to demonstrate the application of NFT in typical scenarios with varying levels of knowledge about the acting group.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19982;NMF&#31639;&#27861;&#19968;&#26679;&#31616;&#21333;&#19988;&#21487;&#25193;&#23637;&#30340;K&#22343;&#20540;&#32858;&#31867;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#35299;&#20915;&#38750;&#36127;&#20302;&#31209;&#21322;&#23450;&#35268;&#21010;&#38382;&#39064;&#33719;&#24471;&#20102;&#24378;&#22823;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#20445;&#35777;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#31639;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2305.18436</link><description>&lt;p&gt;
&#36890;&#36807;&#38750;&#36127;&#20302;&#31209;&#21322;&#23450;&#35268;&#21010;&#23454;&#29616;&#26368;&#20248;K&#22343;&#20540;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Statistically Optimal K-means Clustering via Nonnegative Low-rank Semidefinite Programming. (arXiv:2305.18436v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18436
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19982;NMF&#31639;&#27861;&#19968;&#26679;&#31616;&#21333;&#19988;&#21487;&#25193;&#23637;&#30340;K&#22343;&#20540;&#32858;&#31867;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#35299;&#20915;&#38750;&#36127;&#20302;&#31209;&#21322;&#23450;&#35268;&#21010;&#38382;&#39064;&#33719;&#24471;&#20102;&#24378;&#22823;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#20445;&#35777;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#31639;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
K&#22343;&#20540;&#32858;&#31867;&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#20110;&#22823;&#25968;&#25454;&#38598;&#20013;&#21457;&#29616;&#27169;&#24335;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#12290;&#21322;&#23450;&#35268;&#21010;&#65288;SDP&#65289;&#26494;&#24347;&#26368;&#36817;&#34987;&#25552;&#20986;&#29992;&#20110;&#35299;&#20915;K&#22343;&#20540;&#20248;&#21270;&#38382;&#39064;&#65292;&#20855;&#26377;&#24456;&#24378;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#20445;&#35777;&#12290;&#20294;&#23454;&#29616;SDP&#27714;&#35299;&#22120;&#30340;&#24040;&#22823;&#25104;&#26412;&#20351;&#24471;&#36825;&#20123;&#20445;&#35777;&#26080;&#27861;&#24212;&#29992;&#20110;&#23454;&#38469;&#25968;&#25454;&#38598;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#65288;NMF&#65289;&#26159;&#19968;&#31181;&#31616;&#21333;&#30340;&#32858;&#31867;&#31639;&#27861;&#65292;&#34987;&#26426;&#22120;&#23398;&#20064;&#20174;&#19994;&#32773;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#32570;&#20047;&#22362;&#23454;&#30340;&#32479;&#35745;&#22522;&#30784;&#25110;&#20005;&#26684;&#30340;&#20445;&#35777;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#31181;&#31867;&#20284;&#20110;NMF&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#38750;&#20984;Burer-Monteiro&#20998;&#35299;&#26041;&#27861;&#35299;&#20915;&#21322;&#23450;&#35268;&#21010;&#26494;&#24347;&#30340;K&#22343;&#20540;&#20844;&#24335;&#30340;&#38750;&#36127;&#20302;&#31209;&#38480;&#21046;&#12290;&#25152;&#24471;&#21040;&#30340;&#31639;&#27861;&#19982;&#26368;&#20808;&#36827;&#30340;NMF&#31639;&#27861;&#19968;&#26679;&#31616;&#21333;&#21644;&#21487;&#25193;&#23637;&#65292;&#21516;&#26102;&#20063;&#20139;&#26377;&#19982;SDP&#30456;&#21516;&#30340;&#24378;&#22823;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#20445;&#35777;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;NMF&#31639;&#27861;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#19982;&#26368;&#20808;&#36827;&#30340;SDP&#27714;&#35299;&#22120;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
$K$-means clustering is a widely used machine learning method for identifying patterns in large datasets. Semidefinite programming (SDP) relaxations have recently been proposed for solving the $K$-means optimization problem that enjoy strong statistical optimality guarantees, but the prohibitive cost of implementing an SDP solver renders these guarantees inaccessible to practical datasets. By contrast, nonnegative matrix factorization (NMF) is a simple clustering algorithm that is widely used by machine learning practitioners, but without a solid statistical underpinning nor rigorous guarantees. In this paper, we describe an NMF-like algorithm that works by solving a nonnegative low-rank restriction of the SDP relaxed $K$-means formulation using a nonconvex Burer--Monteiro factorization approach. The resulting algorithm is just as simple and scalable as state-of-the-art NMF algorithms, while also enjoying the same strong statistical optimality guarantees as the SDP. In our experiments,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28155;&#21152;&#22122;&#22768;&#30340;&#22810;&#23618;Sigmoid&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#22312;&#23398;&#20064;&#24207;&#21015;&#20998;&#31867;&#38382;&#39064;&#19978;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#38382;&#39064;&#65292;&#21457;&#29616;&#24102;&#22122;&#22768;&#24773;&#20917;&#19979;&#26679;&#26412;&#22797;&#26434;&#24230;&#21487;&#20197;&#29992;$\log(T/\sigma)$&#26469;&#30028;&#23450;&#65292;&#19981;&#23384;&#22312;&#22122;&#22768;&#26102;&#19979;&#30028;&#20026;$wT$&#65292;&#20004;&#32773;&#23384;&#22312;&#25351;&#25968;&#32423;&#21035;&#30340;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2305.18423</link><description>&lt;p&gt;
&#22122;&#38899;&#22312;&#23398;&#20064;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20013;&#30340;&#20316;&#29992;&#65306;&#38271;&#24207;&#21015;&#30340;&#25351;&#25968;&#24046;&#36317;
&lt;/p&gt;
&lt;p&gt;
On the Role of Noise in the Sample Complexity of Learning Recurrent Neural Networks: Exponential Gaps for Long Sequences. (arXiv:2305.18423v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18423
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28155;&#21152;&#22122;&#22768;&#30340;&#22810;&#23618;Sigmoid&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#22312;&#23398;&#20064;&#24207;&#21015;&#20998;&#31867;&#38382;&#39064;&#19978;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#38382;&#39064;&#65292;&#21457;&#29616;&#24102;&#22122;&#22768;&#24773;&#20917;&#19979;&#26679;&#26412;&#22797;&#26434;&#24230;&#21487;&#20197;&#29992;$\log(T/\sigma)$&#26469;&#30028;&#23450;&#65292;&#19981;&#23384;&#22312;&#22122;&#22768;&#26102;&#19979;&#30028;&#20026;$wT$&#65292;&#20004;&#32773;&#23384;&#22312;&#25351;&#25968;&#32423;&#21035;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#28155;&#21152;&#29420;&#31435;&#22122;&#38899;&#30340;&#22810;&#23618;Sigmoid&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#26469;&#20998;&#31867;&#38271;&#24230;&#20026;T&#30340;&#24207;&#21015;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20010;&#31867;&#30340;PAC&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#21487;&#20197;&#34987;&#30028;&#23450;&#20026;$O (w\log(T/\sigma))$&#12290;&#23545;&#20110;&#30456;&#21516;&#31867;&#30340;&#38750;&#22122;&#22768;&#29256;&#26412;&#65288;&#21363;$\sigma=0$&#65289;&#65292;&#25105;&#20204;&#35777;&#26126;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#19979;&#30028;&#20026;$\Omega (wT)$&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;&#20986;&#22312;&#22122;&#22768;&#21644;&#38750;&#22122;&#22768;&#32593;&#32476;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#23545;T&#30340;&#20381;&#36182;&#24615;&#20013;&#23384;&#22312;&#25351;&#25968;&#24046;&#36317;&#12290;&#27492;&#22806;&#65292;&#32771;&#34385;&#21040;&#19978;&#38480;&#23545;$1/\sigma$&#30340;&#23545;&#25968;&#20381;&#36182;&#24230;&#24456;&#23567;&#65292;&#21363;&#20351;&#38024;&#23545;&#25968;&#20540;&#19978;&#21487;&#20197;&#24573;&#30053;&#30340;$\sigma$&#65292;&#36825;&#20010;&#24046;&#36317;&#20173;&#28982;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the class of noisy multi-layered sigmoid recurrent neural networks with $w$ (unbounded) weights for classification of sequences of length $T$, where independent noise distributed according to $\mathcal{N}(0,\sigma^2)$ is added to the output of each neuron in the network. Our main result shows that the sample complexity of PAC learning this class can be bounded by $O (w\log(T/\sigma))$. For the non-noisy version of the same class (i.e., $\sigma=0$), we prove a lower bound of $\Omega (wT)$ for the sample complexity. Our results indicate an exponential gap in the dependence of sample complexity on $T$ for noisy versus non-noisy networks. Moreover, given the mild logarithmic dependence of the upper bound on $1/\sigma$, this gap still holds even for numerically negligible values of $\sigma$.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#39062;&#30340;&#26080;&#27169;&#22411;&#31639;&#27861;&#65292;&#20026;&#21160;&#24577;&#20915;&#31574;&#38754;&#23545;&#20998;&#24067;&#21464;&#21270;&#38382;&#39064;&#25552;&#20379;&#20102;&#40065;&#26834;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#36890;&#36807;&#23558;Q-learning&#19982;&#26041;&#24046;&#20943;&#23569;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#26377;&#25928;&#25511;&#21046;&#12290;</title><link>http://arxiv.org/abs/2305.18420</link><description>&lt;p&gt;
&#26041;&#24046;&#20943;&#23569;&#30340;&#20998;&#24067;&#24335;&#40065;&#26834;Q-learning&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
Sample Complexity of Variance-reduced Distributionally Robust Q-learning. (arXiv:2305.18420v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18420
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#39062;&#30340;&#26080;&#27169;&#22411;&#31639;&#27861;&#65292;&#20026;&#21160;&#24577;&#20915;&#31574;&#38754;&#23545;&#20998;&#24067;&#21464;&#21270;&#38382;&#39064;&#25552;&#20379;&#20102;&#40065;&#26834;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#36890;&#36807;&#23558;Q-learning&#19982;&#26041;&#24046;&#20943;&#23569;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#26377;&#25928;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#30340;&#29702;&#35770;&#21644;&#24212;&#29992;&#20013;&#65292;&#38754;&#23545;&#20998;&#24067;&#36716;&#31227;&#30340;&#21160;&#24577;&#20915;&#31574;&#26159;&#22522;&#26412;&#38382;&#39064;&#65292;&#22240;&#20026;&#25968;&#25454;&#25910;&#38598;&#25152;&#22522;&#20110;&#30340;&#29615;&#22659;&#20998;&#24067;&#21487;&#33021;&#20250;&#19981;&#21516;&#20110;&#27169;&#22411;&#37096;&#32626;&#25152;&#22522;&#20110;&#30340;&#20998;&#24067;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#39062;&#30340;&#26080;&#27169;&#22411;&#31639;&#27861;&#65292;&#21363;&#20998;&#24067;&#24335;&#40065;&#26834;Q-learning&#21644;&#23427;&#30340;&#26041;&#24046;&#20943;&#23569;&#23545;&#24212;&#31639;&#27861;&#65292;&#33021;&#22815;&#39640;&#25928;&#22320;&#23398;&#20064;&#40065;&#26834;&#31574;&#30053;&#65292;&#23613;&#31649;&#20250;&#38754;&#23545;&#20998;&#24067;&#21464;&#21270;&#12290;&#36825;&#20123;&#31639;&#27861;&#26088;&#22312;&#23558;&#24102;&#26377;Kullback-Leibler&#19981;&#30830;&#23450;&#24615;&#38598;&#30340;&#26080;&#38480;&#26102;&#22495;$\gamma$-&#25240;&#25187;&#40065;&#26834;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;$q$-&#20989;&#25968;&#20197;&#20803;&#32032;$\epsilon$-&#31934;&#24230;&#26377;&#25928;&#36924;&#36817;&#12290;&#36827;&#19968;&#27493;&#22320;&#65292;&#26041;&#24046;&#20943;&#23569;&#30340;&#20998;&#24067;&#24335;&#40065;&#26834;Q-learning&#23558;&#21516;&#27493;Q-learning&#19982;&#26041;&#24046;&#20943;&#23569;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#20197;&#22686;&#24378;&#20854;&#24615;&#33021;&#65292;&#24182;&#19988;&#25105;&#20204;&#24314;&#31435;&#20102;&#23427;&#36798;&#21040;$ \tilde O(|S||A|(1-\gamma)^{-4}\epsilon^{-4}$&#30340;&#26368;&#23567;&#26368;&#22823;&#26679;&#26412;&#22797;&#26434;&#24230;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dynamic decision making under distributional shifts is of fundamental interest in theory and applications of reinforcement learning: The distribution of the environment on which the data is collected can differ from that of the environment on which the model is deployed. This paper presents two novel model-free algorithms, namely the distributionally robust Q-learning and its variance-reduced counterpart, that can effectively learn a robust policy despite distributional shifts. These algorithms are designed to efficiently approximate the $q$-function of an infinite-horizon $\gamma$-discounted robust Markov decision process with Kullback-Leibler uncertainty set to an entry-wise $\epsilon$-degree of precision. Further, the variance-reduced distributionally robust Q-learning combines the synchronous Q-learning with variance-reduction techniques to enhance its performance. Consequently, we establish that it attains a minmax sample complexity upper bound of $\tilde O(|S||A|(1-\gamma)^{-4}\e
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#29992;&#26550;&#26500;&#20960;&#20309;&#20195;&#25968;&#21464;&#25442;&#22120;&#65288;GATr&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#20960;&#20309;&#25968;&#25454;&#38382;&#39064;&#12290;GATr&#20351;&#29992;&#25237;&#24433;&#20960;&#20309;&#20195;&#25968;&#34920;&#31034;&#36755;&#20837;&#36755;&#20986;&#21644;&#29366;&#24577;&#65292;&#20855;&#26377;&#21487;&#32553;&#25918;&#24615;&#12289;&#34920;&#36798;&#24615;&#12289;&#22810;&#21151;&#33021;&#24615;&#12290;&#22312;n&#20307;&#24314;&#27169;&#21644;&#26426;&#22120;&#20154;&#35268;&#21010;&#30340;&#23454;&#39564;&#20013;&#65292;GATr&#30456;&#23545;&#20110;&#38750;&#20960;&#20309;&#22522;&#32447;&#34920;&#29616;&#20986;&#24378;&#22823;&#30340;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2305.18415</link><description>&lt;p&gt;
&#20960;&#20309;&#20195;&#25968;&#21464;&#25442;&#22120;
&lt;/p&gt;
&lt;p&gt;
Geometric Algebra Transformers. (arXiv:2305.18415v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18415
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#29992;&#26550;&#26500;&#20960;&#20309;&#20195;&#25968;&#21464;&#25442;&#22120;&#65288;GATr&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#20960;&#20309;&#25968;&#25454;&#38382;&#39064;&#12290;GATr&#20351;&#29992;&#25237;&#24433;&#20960;&#20309;&#20195;&#25968;&#34920;&#31034;&#36755;&#20837;&#36755;&#20986;&#21644;&#29366;&#24577;&#65292;&#20855;&#26377;&#21487;&#32553;&#25918;&#24615;&#12289;&#34920;&#36798;&#24615;&#12289;&#22810;&#21151;&#33021;&#24615;&#12290;&#22312;n&#20307;&#24314;&#27169;&#21644;&#26426;&#22120;&#20154;&#35268;&#21010;&#30340;&#23454;&#39564;&#20013;&#65292;GATr&#30456;&#23545;&#20110;&#38750;&#20960;&#20309;&#22522;&#32447;&#34920;&#29616;&#20986;&#24378;&#22823;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20960;&#20309;&#25968;&#25454;&#38382;&#39064;&#28041;&#21450;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#26426;&#22120;&#20154;&#12289;&#21270;&#23398;&#21644;&#29289;&#29702;&#39046;&#22495;&#12290;&#36825;&#20123;&#25968;&#25454;&#21487;&#20197;&#37319;&#29992;&#35768;&#22810;&#24418;&#24335;&#65292;&#20363;&#22914;&#28857;&#12289;&#26041;&#21521;&#21521;&#37327;&#12289;&#24179;&#38754;&#25110;&#21464;&#25442;&#65292;&#20294;&#36804;&#20170;&#20026;&#27490;&#36824;&#27809;&#26377;&#19968;&#31181;&#21333;&#19968;&#30340;&#26550;&#26500;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#22914;&#27492;&#22810;&#31181;&#20960;&#20309;&#31867;&#22411;, &#21516;&#26102;&#23562;&#37325;&#23427;&#20204;&#30340;&#23545;&#31216;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#20960;&#20309;&#20195;&#25968;&#21464;&#25442;&#22120;&#65288;GATr&#65289;&#65292;&#19968;&#31181;&#29992;&#20110;&#20960;&#20309;&#25968;&#25454;&#30340;&#36890;&#29992;&#26550;&#26500;&#12290;GATr&#20351;&#29992;&#25237;&#24433;&#20960;&#20309;&#20195;&#25968;&#26469;&#34920;&#31034;&#36755;&#20837;&#12289;&#36755;&#20986;&#21644;&#38544;&#34255;&#29366;&#24577;&#65292;&#20854;&#25552;&#20379;&#24120;&#35265;&#20960;&#20309;&#23545;&#35937;&#30340;&#39640;&#25928;16&#32500;&#21521;&#37327;&#31354;&#38388;&#34920;&#31034;&#20197;&#21450;&#20316;&#29992;&#20110;&#23427;&#20204;&#30340;&#36816;&#31639;&#31526;&#12290;GATr&#26159;&#30456;&#23545;&#20110;E(3)&#65288;3D&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#30340;&#23545;&#31216;&#32676;&#65289;&#31561;&#21464;&#30340;&#12290;&#20316;&#20026;&#21464;&#25442;&#22120;&#65292;GATr&#21487;&#25193;&#23637;&#12289;&#34920;&#36798;&#20016;&#23500;&#19988;&#22810;&#21151;&#33021;&#12290;&#22312;n&#20307;&#24314;&#27169;&#21644;&#26426;&#22120;&#20154;&#35268;&#21010;&#30340;&#23454;&#39564;&#20013;&#65292;GATr&#30456;&#23545;&#20110;&#38750;&#20960;&#20309;&#22522;&#32447;&#22343;&#34920;&#29616;&#20986;&#24378;&#22823;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Problems involving geometric data arise in a variety of fields, including computer vision, robotics, chemistry, and physics. Such data can take numerous forms, such as points, direction vectors, planes, or transformations, but to date there is no single architecture that can be applied to such a wide variety of geometric types while respecting their symmetries. In this paper we introduce the Geometric Algebra Transformer (GATr), a general-purpose architecture for geometric data. GATr represents inputs, outputs, and hidden states in the projective geometric algebra, which offers an efficient 16-dimensional vector space representation of common geometric objects as well as operators acting on them. GATr is equivariant with respect to E(3), the symmetry group of 3D Euclidean space. As a transformer, GATr is scalable, expressive, and versatile. In experiments with n-body modeling and robotic planning, GATr shows strong improvements over non-geometric baselines.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38754;&#21521;&#26041;&#21521;&#30340;&#22810;&#30446;&#26631;&#38382;&#39064;&#65292;&#24182;&#32473;&#20986;&#20102;&#20004;&#31181;&#38543;&#26426;&#31639;&#27861;&#20197;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#29702;&#35770;&#19978;&#25910;&#25947;&#21040;&#24085;&#32047;&#25176;&#31283;&#23450;&#28857;&#12290;</title><link>http://arxiv.org/abs/2305.18409</link><description>&lt;p&gt;
&#38754;&#21521;&#26041;&#21521;&#30340;&#22810;&#30446;&#26631;&#23398;&#20064;&#65306;&#31616;&#21333;&#19988;&#21487;&#35777;&#26126;&#30340;&#38543;&#26426;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Direction-oriented Multi-objective Learning: Simple and Provable Stochastic Algorithms. (arXiv:2305.18409v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18409
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38754;&#21521;&#26041;&#21521;&#30340;&#22810;&#30446;&#26631;&#38382;&#39064;&#65292;&#24182;&#32473;&#20986;&#20102;&#20004;&#31181;&#38543;&#26426;&#31639;&#27861;&#20197;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#29702;&#35770;&#19978;&#25910;&#25947;&#21040;&#24085;&#32047;&#25176;&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#30446;&#26631;&#20248;&#21270;&#65288;MOO&#65289;&#24050;&#25104;&#20026;&#35768;&#22810;&#19982;&#22810;&#20010;&#30446;&#26631;&#30456;&#20851;&#30340;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#65288;&#22914;&#22810;&#26631;&#20934;&#23398;&#20064;&#21644;&#22810;&#20219;&#21153;&#23398;&#20064;&#65288;MTL&#65289;&#65289;&#20013;&#19968;&#20010;&#26377;&#24433;&#21709;&#21147;&#30340;&#26694;&#26550;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38754;&#21521;&#26041;&#21521;&#30340;&#22810;&#30446;&#26631;&#38382;&#39064;&#65292;&#36890;&#36807;&#22312;&#19968;&#20010;&#26041;&#21521;&#30340;&#37051;&#22495;&#20869;&#38480;&#21046;&#20844;&#20849;&#19979;&#38477;&#26041;&#21521;&#26469;&#35268;&#33539;&#32447;&#24615;&#32452;&#21512;&#30446;&#26631;&#30340;&#26368;&#20248;&#26041;&#21521;&#65292;&#20363;&#22914;MTL&#20013;&#30340;&#24179;&#22343;&#25439;&#22833;&#12290; &#36825;&#20010;&#20844;&#24335;&#21253;&#25324;GD&#21644;MGDA&#20316;&#20026;&#29305;&#27530;&#24773;&#20917;&#65292;&#20139;&#21463;&#20687;CAGrad&#20013;&#30340;&#38754;&#21521;&#26041;&#21521;&#30340;&#22909;&#22788;&#65292;&#20197;&#21450;&#26377;&#21033;&#20110;&#38543;&#26426;&#31639;&#27861;&#30340;&#35774;&#35745;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#38543;&#26426;&#26041;&#21521;&#23548;&#21521;&#22810;&#30446;&#26631;&#26799;&#24230;&#19979;&#38477;&#65288;SDMGrad&#65289;&#65292;&#23427;&#20351;&#29992;&#31616;&#21333;&#30340;SGD&#31867;&#22411;&#30340;&#26356;&#26032;&#31639;&#27861;&#65292;&#20197;&#21450;&#22312;&#30446;&#26631;&#25968;&#37327;&#36739;&#22810;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#39640;&#25928;&#30340;&#30446;&#26631;&#37319;&#26679;&#30340;SDMGrad-OS&#31639;&#27861;&#12290; &#23545;&#20110;&#24658;&#23450;&#30340;&#27491;&#21017;&#21270;&#21442;&#25968;&#955;&#65292;&#25105;&#20204;&#35777;&#26126;SDMGrad&#21644;SDMGrad-OS&#30830;&#23454;&#25910;&#25947;&#21040;&#24085;&#32047;&#25176;&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-objective optimization (MOO) has become an influential framework in many machine learning problems with multiple objectives such as learning with multiple criteria and multi-task learning (MTL). In this paper, we propose a new direction-oriented multi-objective problem by regularizing the common descent direction within a neighborhood of a direction that optimizes a linear combination of objectives such as the average loss in MTL. This formulation includes GD and MGDA as special cases, enjoys the direction-oriented benefit as in CAGrad, and facilitates the design of stochastic algorithms. To solve this problem, we propose Stochastic Direction-oriented Multi-objective Gradient descent (SDMGrad) with simple SGD type of updates, and its variant SDMGrad-OS with an efficient objective sampling in the setting where the number of objectives is large. For a constant-level regularization parameter $\lambda$, we show that SDMGrad and SDMGrad-OS provably converge to a Pareto stationary poin
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22914;&#20309;&#21033;&#29992;&#31526;&#21512;&#24615;&#39044;&#27979;&#25216;&#26415;&#65292;&#22312;&#22810;&#39033;&#36873;&#25321;&#39064;&#22238;&#31572;&#20219;&#21153;&#20013;&#20026;&#35821;&#35328;&#27169;&#22411;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#21457;&#29616;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#19982;&#39044;&#27979;&#20934;&#30830;&#24615;&#23494;&#20999;&#30456;&#20851;&#12290;</title><link>http://arxiv.org/abs/2305.18404</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#39033;&#36873;&#25321;&#39064;&#31572;&#26696;&#30830;&#35748;&#39044;&#27979;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Conformal Prediction with Large Language Models for Multi-Choice Question Answering. (arXiv:2305.18404v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18404
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22914;&#20309;&#21033;&#29992;&#31526;&#21512;&#24615;&#39044;&#27979;&#25216;&#26415;&#65292;&#22312;&#22810;&#39033;&#36873;&#25321;&#39064;&#22238;&#31572;&#20219;&#21153;&#20013;&#20026;&#35821;&#35328;&#27169;&#22411;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#21457;&#29616;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#19982;&#39044;&#27979;&#20934;&#30830;&#24615;&#23494;&#20999;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24191;&#27867;&#24320;&#21457;&#65292;&#23545;&#23427;&#20204;&#36827;&#34892;&#20581;&#22766;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#25216;&#26415;&#23558;&#25104;&#20026;&#23427;&#20204;&#22312;&#39640;&#39118;&#38505;&#22330;&#26223;&#19979;&#23433;&#20840;&#37096;&#32626;&#30340;&#20851;&#38190;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22914;&#20309;&#21033;&#29992;&#31526;&#21512;&#24615;&#39044;&#27979;&#25216;&#26415;&#65292;&#22312;&#22810;&#39033;&#36873;&#25321;&#39064;&#22238;&#31572;&#20219;&#21153;&#20013;&#20026;&#35821;&#35328;&#27169;&#22411;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#21457;&#29616;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#19982;&#39044;&#27979;&#20934;&#30830;&#24615;&#23494;&#20999;&#30456;&#20851;&#12290;&#36825;&#31181;&#35266;&#23519;&#23545;&#20110;&#19979;&#28216;&#24212;&#29992;&#65292;&#22914;&#36873;&#25321;&#24615;&#20998;&#31867;&#21644;&#36807;&#28388;&#20302;&#36136;&#37327;&#39044;&#27979;&#65292;&#21487;&#33021;&#20250;&#26377;&#29992;&#12290;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#31526;&#21512;&#24615;&#39044;&#27979;&#23545;&#20110;&#36229;&#20986;&#20027;&#39064;&#30340;&#38382;&#39064;&#30340;&#20132;&#25442;&#24615;&#20551;&#35774;&#65292;&#36825;&#21487;&#33021;&#26159;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#30340;&#26356;&#20026;&#29616;&#23454;&#30340;&#22330;&#26223;&#12290;&#26412;&#30740;&#31350;&#20026;&#22312;&#38656;&#35201;&#21487;&#38752;&#20445;&#35777;&#38169;&#35823;&#29575;&#30340;&#23433;&#20840;&#20851;&#38190;&#24773;&#20917;&#19979;&#26356;&#21152;&#20540;&#24471;&#20449;&#36182;&#21644;&#21487;&#38752;&#22320;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
As large language models continue to be widely developed, robust uncertainty quantification techniques will become crucial for their safe deployment in high-stakes scenarios. In this work, we explore how conformal prediction can be used to provide uncertainty quantification in language models for the specific task of multiple-choice question-answering. We find that the uncertainty estimates from conformal prediction are tightly correlated with prediction accuracy. This observation can be useful for downstream applications such as selective classification and filtering out low-quality predictions. We also investigate the exchangeability assumption required by conformal prediction to out-of-subject questions, which may be a more realistic scenario for many practical applications. Our work contributes towards more trustworthy and reliable usage of large language models in safety-critical situations, where robust guarantees of error rate are required.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340; Gram &#30697;&#38453;&#32467;&#26500;&#65292;&#35777;&#26126;&#20102;&#28608;&#27963;&#20989;&#25968;&#21644;&#23618;&#35268;&#33539;&#21270;&#32467;&#21512;&#20351;&#29992;&#21487;&#20197;&#22312;&#21021;&#22987;&#21270;&#26102;&#20559;&#21521;&#25351;&#25968;&#32423;&#28145;&#24230;&#31561;&#36317;&#65292;&#20174;&#32780;&#24357;&#34917;&#20102;&#29616;&#26377;&#29702;&#35770;&#30340;&#31354;&#30333;&#12290;</title><link>http://arxiv.org/abs/2305.18399</link><description>&lt;p&gt;
&#20851;&#20110;&#28608;&#27963;&#20989;&#25968;&#21644;&#35268;&#33539;&#21270;&#23545;&#21021;&#22987;&#21270;&#31561;&#36317;&#23884;&#20837;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
On the impact of activation and normalization in obtaining isometric embeddings at initialization. (arXiv:2305.18399v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18399
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340; Gram &#30697;&#38453;&#32467;&#26500;&#65292;&#35777;&#26126;&#20102;&#28608;&#27963;&#20989;&#25968;&#21644;&#23618;&#35268;&#33539;&#21270;&#32467;&#21512;&#20351;&#29992;&#21487;&#20197;&#22312;&#21021;&#22987;&#21270;&#26102;&#20559;&#21521;&#25351;&#25968;&#32423;&#28145;&#24230;&#31561;&#36317;&#65292;&#20174;&#32780;&#24357;&#34917;&#20102;&#29616;&#26377;&#29702;&#35770;&#30340;&#31354;&#30333;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#20498;&#25968;&#31532;&#20108;&#20010; Gram &#30697;&#38453;&#30340;&#32467;&#26500;&#65292;&#35813;&#30697;&#38453;&#21253;&#21547;&#19982;&#19968;&#25209;&#36755;&#20837;&#23545;&#24212;&#30340;&#36755;&#20986;&#20043;&#38388;&#30340;&#25104;&#23545;&#20869;&#31215;&#12290;&#22312;&#20960;&#31181;&#26550;&#26500;&#20013;&#65292;&#35266;&#23519;&#21040;&#22312;&#21021;&#22987;&#21270;&#26102;&#35813; Gram &#30697;&#38453;&#20250;&#38543;&#30528;&#28145;&#24230;&#21464;&#24471;&#36864;&#21270;&#65292;&#20174;&#32780;&#20005;&#37325;&#20943;&#32531;&#35757;&#32451;&#36895;&#24230;&#12290;&#35268;&#33539;&#21270;&#23618;&#22914;&#25209;&#22788;&#29702;&#35268;&#33539;&#21270;&#25110;&#23618;&#35268;&#33539;&#21270;&#65292;&#22312;&#38450;&#27490;&#31209;&#23849;&#28291;&#38382;&#39064;&#26041;&#38754;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#28982;&#32780;&#29616;&#26377;&#30340;&#29702;&#35770;&#32467;&#26524;&#26080;&#27861;&#20840;&#38754;&#35206;&#30422;&#24191;&#27867;&#29992;&#20110; transformer &#20013;&#30340;&#23618;&#35268;&#33539;&#21270;&#21644;&#26377;&#38480;&#28145;&#24230;&#19979;&#35268;&#33539;&#21270;&#30340;&#37327;&#21270;&#20559;&#24046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#21021;&#22987;&#21270;&#26102;&#65292;&#32467;&#21512;&#28608;&#27963;&#20989;&#25968;&#23618;&#20351;&#29992;&#30340;&#23618;&#35268;&#33539;&#21270;&#21487;&#20197;&#20351;&#22810;&#23618;&#24863;&#30693;&#26426;&#30340; Gram &#30697;&#38453;&#20559;&#21521;&#25351;&#25968;&#32423;&#28145;&#24230;&#31561;&#36317;&#65292;&#24182;&#20351;&#29992;&#28608;&#27963;&#20989;&#25968;&#30340; Hermite &#23637;&#24320;&#26469;&#37327;&#21270;&#36825;&#20010;&#36895;&#24230;&#65292;&#20174;&#32780;&#22635;&#34917;&#20102;&#29616;&#26377;&#29702;&#35770;&#30340;&#31354;&#30333;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we explore the structure of the penultimate Gram matrix in deep neural networks, which contains the pairwise inner products of outputs corresponding to a batch of inputs. In several architectures it has been observed that this Gram matrix becomes degenerate with depth at initialization, which dramatically slows training. Normalization layers, such as batch or layer normalization, play a pivotal role in preventing the rank collapse issue. Despite promising advances, the existing theoretical results (i) do not extend to layer normalization, which is widely used in transformers, (ii) can not characterize the bias of normalization quantitatively at finite depth.  To bridge this gap, we provide a proof that layer normalization, in conjunction with activation layers, biases the Gram matrix of a multilayer perceptron towards isometry at an exponential rate with depth at initialization. We quantify this rate using the Hermite expansion of the activation function, highlighting th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#26102;&#38388;&#24046;&#20998;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#20998;&#26512;&#20102;&#37327;&#21270;&#26102;&#38388;&#24046;&#20998;&#23398;&#20064;&#31639;&#27861;&#22312;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#21363;&#20351;&#20174;&#23454;&#36341;&#32773;&#27809;&#26377;&#36229;&#36807;&#24179;&#22343;&#22238;&#25253;&#20043;&#22806;&#30340;&#22238;&#25253;&#20998;&#24067;&#30340;&#20852;&#36259;&#20043;&#22788;&#65292;&#22312;&#34920;&#26684;&#35774;&#32622;&#20013;&#65292;QTD&#20063;&#21487;&#20197;&#25552;&#20379;&#27604;&#20256;&#32479;TD&#23398;&#20064;&#31561;&#26041;&#27861;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.18388</link><description>&lt;p&gt;
&#37327;&#21270;&#26102;&#38388;&#24046;&#20998;&#23398;&#20064;&#22312;&#20215;&#20540;&#20272;&#35745;&#20013;&#30340;&#32479;&#35745;&#20248;&#21183;
&lt;/p&gt;
&lt;p&gt;
The Statistical Benefits of Quantile Temporal-Difference Learning for Value Estimation. (arXiv:2305.18388v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18388
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#26102;&#38388;&#24046;&#20998;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#20998;&#26512;&#20102;&#37327;&#21270;&#26102;&#38388;&#24046;&#20998;&#23398;&#20064;&#31639;&#27861;&#22312;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#21363;&#20351;&#20174;&#23454;&#36341;&#32773;&#27809;&#26377;&#36229;&#36807;&#24179;&#22343;&#22238;&#25253;&#20043;&#22806;&#30340;&#22238;&#25253;&#20998;&#24067;&#30340;&#20852;&#36259;&#20043;&#22788;&#65292;&#22312;&#34920;&#26684;&#35774;&#32622;&#20013;&#65292;QTD&#20063;&#21487;&#20197;&#25552;&#20379;&#27604;&#20256;&#32479;TD&#23398;&#20064;&#31561;&#26041;&#27861;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#24378;&#21270;&#23398;&#20064;&#20013;&#22522;&#20110;&#26102;&#38388;&#24046;&#20998;&#30340;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#20998;&#26512;&#20102;&#19968;&#31181;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#8212;&#8212;&#37327;&#21270;&#26102;&#38388;&#24046;&#20998;&#23398;&#20064;&#65288;QTD&#65289;&#22312;&#36825;&#20010;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#24471;&#20986;&#20102;&#19968;&#20010;&#24778;&#20154;&#30340;&#32467;&#35770;&#65306;&#21363;&#20351;&#20174;&#23454;&#36341;&#32773;&#27809;&#26377;&#36229;&#36807;&#24179;&#22343;&#22238;&#25253;&#20043;&#22806;&#30340;&#22238;&#25253;&#20998;&#24067;&#30340;&#20852;&#36259;&#20043;&#22788;&#65292;&#22312;&#34920;&#26684;&#35774;&#32622;&#20013;&#65292;QTD&#65288;&#23398;&#20064;&#20851;&#20110;&#20840;&#37096;&#22238;&#25253;&#20998;&#24067;&#30340;&#39044;&#27979;&#65289;&#20063;&#21487;&#20197;&#25552;&#20379;&#27604;&#35832;&#22914;&#20256;&#32479;TD&#23398;&#20064;&#65288;&#20165;&#39044;&#27979;&#24179;&#22343;&#22238;&#25253;&#65289;&#31561;&#26041;&#27861;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of temporal-difference-based policy evaluation in reinforcement learning. In particular, we analyse the use of a distributional reinforcement learning algorithm, quantile temporal-difference learning (QTD), for this task. We reach the surprising conclusion that even if a practitioner has no interest in the return distribution beyond the mean, QTD (which learns predictions about the full distribution of returns) may offer performance superior to approaches such as classical TD learning, which predict only the mean return, even in the tabular setting.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#32479;&#35745;&#21147;&#23398;&#30340;&#29616;&#35937;&#23398;&#27169;&#22411;&#65292;&#20351;&#29992;&#31867;&#20284;&#28201;&#24230;&#21644;&#36127;&#36733;&#30340;&#27169;&#22411;&#21442;&#25968;&#26469;&#24314;&#27169;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#36229;&#21442;&#25968;&#23545;&#20462;&#21098;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#20998;&#31867;&#20462;&#21098;&#21518;&#31070;&#32463;&#32593;&#32476;&#25439;&#22833;&#26223;&#35266;&#30340;&#20840;&#23616;&#32467;&#26500;&#26500;&#24314;&#20102;&#19968;&#20010;&#19977;&#37325;&#27169;&#22411;&#65292;&#25581;&#31034;&#20102;&#20462;&#21098;&#30340;&#20248;&#21270;&#36807;&#31243;&#20197;&#21450;&#23545;&#31070;&#32463;&#32593;&#32476;&#25439;&#22833;&#26223;&#35266;&#30340;&#21464;&#21270;&#35268;&#24459;&#12290;</title><link>http://arxiv.org/abs/2305.18383</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20462;&#21098;&#30340;&#19977;&#37325;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Three-regime Model of Network Pruning. (arXiv:2305.18383v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18383
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#32479;&#35745;&#21147;&#23398;&#30340;&#29616;&#35937;&#23398;&#27169;&#22411;&#65292;&#20351;&#29992;&#31867;&#20284;&#28201;&#24230;&#21644;&#36127;&#36733;&#30340;&#27169;&#22411;&#21442;&#25968;&#26469;&#24314;&#27169;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#36229;&#21442;&#25968;&#23545;&#20462;&#21098;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#20998;&#31867;&#20462;&#21098;&#21518;&#31070;&#32463;&#32593;&#32476;&#25439;&#22833;&#26223;&#35266;&#30340;&#20840;&#23616;&#32467;&#26500;&#26500;&#24314;&#20102;&#19968;&#20010;&#19977;&#37325;&#27169;&#22411;&#65292;&#25581;&#31034;&#20102;&#20462;&#21098;&#30340;&#20248;&#21270;&#36807;&#31243;&#20197;&#21450;&#23545;&#31070;&#32463;&#32593;&#32476;&#25439;&#22833;&#26223;&#35266;&#30340;&#21464;&#21270;&#35268;&#24459;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#24378;&#35843;&#20102;&#35757;&#32451;&#36229;&#21442;&#25968;&#65288;&#20363;&#22914;&#35757;&#32451;&#36718;&#25968;&#65289;&#23545;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20462;&#21098;&#30340;&#24433;&#21709;&#65292;&#28982;&#32780;&#22914;&#20309;&#31934;&#30830;&#39044;&#27979;&#35843;&#25972;&#26576;&#19968;&#29305;&#23450;&#36229;&#21442;&#25968;&#23545;&#20462;&#21098;&#30340;&#24433;&#21709;&#20173;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#32479;&#35745;&#21147;&#23398;&#30340;&#29616;&#35937;&#23398;&#27169;&#22411;&#65292;&#20351;&#29992;&#31867;&#20284;&#28201;&#24230;&#21644;&#36127;&#36733;&#30340;&#27169;&#22411;&#21442;&#25968;&#26469;&#24314;&#27169;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#36229;&#21442;&#25968;&#23545;&#20462;&#21098;&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#21457;&#29616;&#20102;&#19968;&#20010;&#20851;&#38190;&#30340;&#23454;&#35777;&#32467;&#26524;&#65306;&#26681;&#25454;&#20462;&#21098;&#21518;&#30340;&#27169;&#22411;&#20013;&#30340;&#19968;&#31181;&#36127;&#36733;&#31867;&#21442;&#25968;&#30340;&#20540;&#65292;&#24403;&#22686;&#21152;&#20462;&#21098;&#21069;&#27169;&#22411;&#20013;&#19968;&#31181;&#31867;&#20284;&#28201;&#24230;&#30340;&#21442;&#25968;&#30340;&#20540;&#26102;&#65292;&#20462;&#21098;&#24615;&#33021;&#21487;&#33021;&#20250;&#24471;&#21040;&#20248;&#21270;&#25110;&#25439;&#23475;&#12290;&#22522;&#20110;&#36825;&#31181;&#36716;&#21464;&#65292;&#25105;&#20204;&#36890;&#36807;&#20998;&#31867;&#20462;&#21098;&#21518;&#31070;&#32463;&#32593;&#32476;&#25439;&#22833;&#26223;&#35266;&#30340;&#20840;&#23616;&#32467;&#26500;&#26500;&#24314;&#20102;&#19968;&#20010;&#19977;&#37325;&#27169;&#22411;&#12290;&#35813;&#27169;&#22411;&#25581;&#31034;&#20102;&#20462;&#21098;&#30340;&#20248;&#21270;&#36807;&#31243;&#20197;&#21450;&#19982;&#20462;&#21098;&#30456;&#20851;&#30340;&#31070;&#32463;&#32593;&#32476;&#25439;&#22833;&#26223;&#35266;&#30340;&#21464;&#21270;&#35268;&#24459;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work has highlighted the complex influence training hyperparameters, e.g., the number of training epochs, can have on the prunability of machine learning models. Perhaps surprisingly, a systematic approach to predict precisely how adjusting a specific hyperparameter will affect prunability remains elusive. To address this gap, we introduce a phenomenological model grounded in the statistical mechanics of learning. Our approach uses temperature-like and load-like parameters to model the impact of neural network (NN) training hyperparameters on pruning performance. A key empirical result we identify is a sharp transition phenomenon: depending on the value of a load-like parameter in the pruned model, increasing the value of a temperature-like parameter in the pre-pruned model may either enhance or impair subsequent pruning performance. Based on this transition, we build a three-regime model by taxonomizing the global structure of the pruned NN loss landscape. Our model reveals tha
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#30340;&#19981;&#31934;&#30830;&#29275;&#39039;&#27861;&#26469;&#27714;&#35299;&#31561;&#24335;&#32422;&#26463;&#30340;&#38750;&#32447;&#24615;&#12289;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#38543;&#26426;&#36845;&#20195;&#33609;&#22270;&#27714;&#35299;&#22686;&#24191;&#25289;&#26684;&#26391;&#26085;&#29275;&#39039;&#31995;&#32479;&#65292;&#24182;&#36890;&#36807;&#22312;&#31934;&#30830;&#22686;&#24191;&#25289;&#26684;&#26391;&#26085;&#20248;&#21183;&#20989;&#25968;&#19978;&#25191;&#34892;&#32447;&#25628;&#32034;&#26469;&#36873;&#25321;&#21512;&#36866;&#30340;&#27493;&#38271;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#39640;&#25928;&#12289;&#40065;&#26834;&#24615;&#22909;&#30340;&#29305;&#28857;&#12290;</title><link>http://arxiv.org/abs/2305.18379</link><description>&lt;p&gt;
&#31934;&#30830;&#22686;&#24191;&#25289;&#26684;&#26391;&#26085;&#21644;&#38543;&#26426;&#36845;&#20195;&#33609;&#22270;&#31639;&#27861;&#27714;&#35299;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Constrained Optimization via Exact Augmented Lagrangian and Randomized Iterative Sketching. (arXiv:2305.18379v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18379
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#30340;&#19981;&#31934;&#30830;&#29275;&#39039;&#27861;&#26469;&#27714;&#35299;&#31561;&#24335;&#32422;&#26463;&#30340;&#38750;&#32447;&#24615;&#12289;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#38543;&#26426;&#36845;&#20195;&#33609;&#22270;&#27714;&#35299;&#22686;&#24191;&#25289;&#26684;&#26391;&#26085;&#29275;&#39039;&#31995;&#32479;&#65292;&#24182;&#36890;&#36807;&#22312;&#31934;&#30830;&#22686;&#24191;&#25289;&#26684;&#26391;&#26085;&#20248;&#21183;&#20989;&#25968;&#19978;&#25191;&#34892;&#32447;&#25628;&#32034;&#26469;&#36873;&#25321;&#21512;&#36866;&#30340;&#27493;&#38271;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#39640;&#25928;&#12289;&#40065;&#26834;&#24615;&#22909;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#35299;&#20915;&#31561;&#24335;&#32422;&#26463;&#30340;&#38750;&#32447;&#24615;&#12289;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#36825;&#31867;&#38382;&#39064;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#24037;&#31243;&#39046;&#22495;&#30340;&#21508;&#31181;&#24212;&#29992;&#20013;&#24191;&#27867;&#20986;&#29616;&#65292;&#21253;&#25324;&#21463;&#32422;&#26463;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#12289;&#26368;&#20248;&#25511;&#21046;&#21644;PDE&#32422;&#26463;&#20248;&#21270;&#12290;&#25105;&#20204;&#38024;&#23545;&#36825;&#31867;&#38382;&#39064;&#24320;&#21457;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#30340;&#19981;&#31934;&#30830;&#29275;&#39039;&#27861;&#12290;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#38543;&#26426;&#36845;&#20195;&#33609;&#22270;&#27714;&#35299;&#22686;&#24191;&#25289;&#26684;&#26391;&#26085;&#29275;&#39039;&#31995;&#32479;&#65292;&#24182;&#36890;&#36807;&#22312;&#31934;&#30830;&#22686;&#24191;&#25289;&#26684;&#26391;&#26085;&#20248;&#21183;&#20989;&#25968;&#19978;&#25191;&#34892;&#32447;&#25628;&#32034;&#26469;&#36873;&#25321;&#21512;&#36866;&#30340;&#27493;&#38271;&#12290;&#24403;&#37197;&#22791;&#36866;&#24403;&#30340;&#33609;&#22270;&#30697;&#38453;&#26102;&#65292;&#38543;&#26426;&#27714;&#35299;&#22120;&#30456;&#23545;&#20110;&#30830;&#23450;&#24615;&#32447;&#24615;&#31995;&#32479;&#27714;&#35299;&#22120;&#20855;&#26377;&#26126;&#26174;&#20248;&#21183;&#65292;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#27599;&#27425;&#36845;&#20195;&#30340;&#28014;&#28857;&#36816;&#31639;&#22797;&#26434;&#24230;&#21644;&#23384;&#20648;&#25104;&#26412;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#33258;&#36866;&#24212;&#22320;&#25511;&#21046;&#38543;&#26426;&#27714;&#35299;&#22120;&#30340;&#31934;&#24230;&#21644;&#22686;&#24191;&#25289;&#26684;&#26391;&#26085;&#30340;&#24809;&#32602;&#21442;&#25968;&#65292;&#20197;&#30830;&#20445;&#19981;&#31934;&#30830;&#30340;&#29275;&#39039;&#26041;&#21521;&#26159;&#31934;&#30830;&#22686;&#24191;&#25289;&#26684;&#26391;&#26085;&#20989;&#25968;&#30340;&#19979;&#38477;&#26041;&#21521;&#12290;&#29702;&#35770;&#20998;&#26512;&#21644;&#25968;&#20540;&#23454;&#39564;&#22343;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#25928;&#29575;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider solving equality-constrained nonlinear, nonconvex optimization problems. This class of problems appears widely in a variety of applications in machine learning and engineering, ranging from constrained deep neural networks, to optimal control, to PDE-constrained optimization. We develop an adaptive inexact Newton method for this problem class. In each iteration, we solve the Lagrangian Newton system inexactly via a randomized iterative sketching solver, and select a suitable stepsize by performing line search on an exact augmented Lagrangian merit function. The randomized solvers have advantages over deterministic linear system solvers by significantly reducing per-iteration flops complexity and storage cost, when equipped with suitable sketching matrices. Our method adaptively controls the accuracy of the randomized solver and the penalty parameters of the exact augmented Lagrangian, to ensure that the inexact Newton direction is a descent direction of the exact augmented 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#28508;&#22312;&#37327;&#21270;&#30340;&#26041;&#24335;&#23454;&#29616;&#20102;&#35299;&#32544;&#34920;&#31034;&#23398;&#20064;&#65292;&#24182;&#36890;&#36807;&#20005;&#26684;&#30340;&#20132;&#27969;&#29942;&#39048;&#21644;&#24378;&#22823;&#30340;&#27169;&#22411;&#35268;&#33539;&#21270;&#25104;&#21151;&#23558;&#25968;&#25454;&#36827;&#34892;&#20102;&#32452;&#21512;&#32534;&#30721;&#21644;&#35299;&#30721;&#65292;&#26368;&#32456;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#35299;&#32544;&#24615;&#33021;&#65292;&#24182;&#25552;&#39640;&#20102;&#26631;&#20934;VAE&#27169;&#22411;&#23398;&#20064;&#34920;&#24449;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.18378</link><description>&lt;p&gt;
&#36890;&#36807;&#28508;&#22312;&#37327;&#21270;&#36827;&#34892;&#35299;&#32544;
&lt;/p&gt;
&lt;p&gt;
Disentanglement via Latent Quantization. (arXiv:2305.18378v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18378
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#28508;&#22312;&#37327;&#21270;&#30340;&#26041;&#24335;&#23454;&#29616;&#20102;&#35299;&#32544;&#34920;&#31034;&#23398;&#20064;&#65292;&#24182;&#36890;&#36807;&#20005;&#26684;&#30340;&#20132;&#27969;&#29942;&#39048;&#21644;&#24378;&#22823;&#30340;&#27169;&#22411;&#35268;&#33539;&#21270;&#25104;&#21151;&#23558;&#25968;&#25454;&#36827;&#34892;&#20102;&#32452;&#21512;&#32534;&#30721;&#21644;&#35299;&#30721;&#65292;&#26368;&#32456;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#35299;&#32544;&#24615;&#33021;&#65292;&#24182;&#25552;&#39640;&#20102;&#26631;&#20934;VAE&#27169;&#22411;&#23398;&#20064;&#34920;&#24449;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35299;&#32544;&#34920;&#31034;&#23398;&#20064;&#20013;&#65292;&#27169;&#22411;&#38656;&#35201;&#23558;&#25968;&#25454;&#38598;&#30340;&#22522;&#30784;&#21464;&#21270;&#22240;&#32032;&#20998;&#24320;&#24182;&#29420;&#31435;&#22320;&#34920;&#31034;&#20986;&#26469;&#65292;&#32780;&#27169;&#22411;&#24182;&#27809;&#26377;&#25552;&#20379;&#26377;&#20851;&#36825;&#20123;&#22240;&#32032;&#30340;&#30495;&#23454;&#20449;&#24687;&#65292;&#24402;&#32435;&#20559;&#35265;&#22312;&#23454;&#29616;&#35299;&#32544;&#26041;&#38754;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#26045;&#21152;&#20005;&#26684;&#30340;&#20132;&#27969;&#29942;&#39048;&#21644;&#24378;&#22823;&#30340;&#27169;&#22411;&#35268;&#33539;&#21270;&#65292;&#26500;&#24314;&#20102;&#19968;&#31181;&#26397;&#30528;&#32452;&#21512;&#32534;&#30721;&#21644;&#35299;&#30721;&#25968;&#25454;&#30340;&#24402;&#32435;&#20559;&#35265;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#23545;&#28508;&#22312;&#32500;&#24230;&#36827;&#34892;&#21487;&#23398;&#20064;&#30340;&#31163;&#25955;&#32534;&#30721;&#65292;&#24182;&#20026;&#27599;&#20010;&#32500;&#24230;&#24212;&#29992;&#19968;&#20010;&#21333;&#29420;&#30340;&#26631;&#37327;&#30721;&#20070;&#12290;&#28508;&#22312;&#37327;&#21270;&#36843;&#20351;&#32534;&#30721;&#22120;&#22312;&#35768;&#22810;&#25968;&#25454;&#28857;&#19978;&#20351;&#29992;&#23569;&#37327;&#28508;&#22312;&#20540;&#65292;&#20174;&#32780;&#20351;&#35299;&#30721;&#22120;&#33021;&#22815;&#20026;&#27599;&#20010;&#20540;&#20998;&#37197;&#19968;&#33268;&#30340;&#21547;&#20041;&#12290;&#35268;&#33539;&#21270;&#26377;&#21161;&#20110;&#23558;&#27169;&#22411;&#24341;&#21521;&#36825;&#31181;&#31616;&#26126;&#31574;&#30053;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#24191;&#27867;&#24212;&#29992;&#24615;&#65292;&#24182;&#19988;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;&#19968;&#31995;&#21015;&#26631;&#20934;VAE&#27169;&#22411;&#23398;&#20064;&#30340;&#34920;&#24449;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In disentangled representation learning, a model is asked to tease apart a dataset's underlying sources of variation and represent them independently of one another. Since the model is provided with no ground truth information about these sources, inductive biases take a paramount role in enabling disentanglement. In this work, we construct an inductive bias towards compositionally encoding and decoding data by enforcing a harsh communication bottleneck. Concretely, we do this by (i) quantizing the latent space into learnable discrete codes with a separate scalar codebook per dimension and (ii) applying strong model regularization via an unusually high weight decay. Intuitively, the quantization forces the encoder to use a small number of latent values across many datapoints, which in turn enables the decoder to assign a consistent meaning to each value. Regularization then serves to drive the model towards this parsimonious strategy. We demonstrate the broad applicability of this appr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#22914;&#20309;&#20351;&#29992;&#23398;&#20064;&#36339;&#36291;&#26041;&#27861;&#26469;&#29983;&#25104;&#24314;&#27169;&#21508;&#31181;&#31867;&#22411;&#30340;&#25968;&#25454;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#35745;&#25968;&#21644;&#38750;&#36127;&#36830;&#32493;&#25968;&#25454;&#31561;&#39640;&#31232;&#30095;&#24230;&#12289;&#20542;&#26012;&#24230;&#12289;&#37325;&#23614;&#24230;&#25110;&#36807;&#24230;&#20998;&#25955;&#24230;&#30340;&#25968;&#25454;&#65292;&#20351;&#29992;&#23398;&#20064;&#36339;&#36291;&#30456;&#27604;&#20110;&#23398;&#20064;&#21435;&#22122;&#26377;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.18375</link><description>&lt;p&gt;
&#23398;&#20064;&#36339;&#36291;: &#34180;&#21270;&#21644;&#21152;&#21402;&#28508;&#22312;&#35745;&#25968;&#29992;&#20110;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Learning to Jump: Thinning and Thickening Latent Counts for Generative Modeling. (arXiv:2305.18375v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18375
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22914;&#20309;&#20351;&#29992;&#23398;&#20064;&#36339;&#36291;&#26041;&#27861;&#26469;&#29983;&#25104;&#24314;&#27169;&#21508;&#31181;&#31867;&#22411;&#30340;&#25968;&#25454;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#35745;&#25968;&#21644;&#38750;&#36127;&#36830;&#32493;&#25968;&#25454;&#31561;&#39640;&#31232;&#30095;&#24230;&#12289;&#20542;&#26012;&#24230;&#12289;&#37325;&#23614;&#24230;&#25110;&#36807;&#24230;&#20998;&#25955;&#24230;&#30340;&#25968;&#25454;&#65292;&#20351;&#29992;&#23398;&#20064;&#36339;&#36291;&#30456;&#27604;&#20110;&#23398;&#20064;&#21435;&#22122;&#26377;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#21435;&#22122;&#24050;&#25104;&#20026;&#35774;&#35745;&#26368;&#20808;&#36827;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65288;&#22914;&#25193;&#25955;&#27169;&#22411;&#65289;&#30340;&#37325;&#35201;&#33539;&#24335;&#65292;&#29992;&#20110;&#24314;&#27169;&#36830;&#32493;&#30340;&#23454;&#20540;&#25968;&#25454;&#21644;&#20998;&#31867;&#25968;&#25454;&#24050;&#32463;&#26377;&#24456;&#22909;&#30340;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#26412;&#25991;&#21457;&#29616;&#23398;&#20064;&#21435;&#22122;&#22312;&#24314;&#27169;&#26576;&#20123;&#20854;&#20182;&#31867;&#22411;&#30340;&#25968;&#25454;&#65288;&#22914;&#35745;&#25968;&#21644;&#38750;&#36127;&#36830;&#32493;&#25968;&#25454;&#65289;&#26102;&#33021;&#21147;&#26377;&#38480;&#65292;&#36825;&#20123;&#25968;&#25454;&#32463;&#24120;&#26159;&#39640;&#24230;&#31232;&#30095;&#12289;&#20542;&#26012;&#12289;&#37325;&#23614;&#25110;&#36807;&#24230;&#20998;&#25955;&#30340;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23398;&#20064;&#36339;&#36291;&#20316;&#20026;&#21508;&#31181;&#31867;&#22411;&#25968;&#25454;&#30340;&#29983;&#25104;&#24314;&#27169;&#30340;&#36890;&#29992;&#26041;&#27861;&#12290;&#20351;&#29992;&#27491;&#21521;&#35745;&#25968;&#31232;&#21270;&#26041;&#27861;&#26500;&#24314;&#23398;&#20064;&#30446;&#26631;&#65292;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#36870;&#21521;&#35745;&#25968;&#21152;&#21402;&#36807;&#31243;&#36845;&#20195;&#22320;&#25913;&#36827;&#20854;&#29983;&#25104;&#32467;&#26524;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;&#20160;&#20040;&#24773;&#20917;&#19979;&#23398;&#20064;&#36339;&#36291;&#19982;&#23398;&#20064;&#21435;&#22122;&#34920;&#29616;&#30456;&#24403;&#65292;&#24182;&#19988;&#20160;&#20040;&#24773;&#20917;&#19979;&#23398;&#20064;&#36339;&#36291;&#34920;&#29616;&#26356;&#22909;&#12290;&#20363;&#22914;&#65292;&#24314;&#35758;&#22312;&#24314;&#27169;&#35745;&#25968;&#21644;&#38750;&#36127;&#36830;&#32493;&#25968;&#25454;&#26102;&#20351;&#29992;&#23398;&#20064;&#36339;&#36291;&#65292;&#36825;&#20123;&#25968;&#25454;&#24448;&#24448;&#20855;&#26377;&#31232;&#30095;&#24615;&#12289;&#20542;&#26012;&#24615;&#12289;&#37325;&#23614;&#24615;&#25110;&#36807;&#24230;&#20998;&#25955;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning to denoise has emerged as a prominent paradigm to design state-of-the-art deep generative models for natural images. How to use it to model the distributions of both continuous real-valued data and categorical data has been well studied in recently proposed diffusion models. However, it is found in this paper to have limited ability in modeling some other types of data, such as count and non-negative continuous data, that are often highly sparse, skewed, heavy-tailed, and/or overdispersed. To this end, we propose learning to jump as a general recipe for generative modeling of various types of data. Using a forward count thinning process to construct learning objectives to train a deep neural network, it employs a reverse count thickening process to iteratively refine its generation through that network. We demonstrate when learning to jump is expected to perform comparably to learning to denoise, and when it is expected to perform better. For example, learning to jump is recom
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#31232;&#30095;&#26368;&#23567;&#20108;&#20056;&#25311;&#21512;&#19968;&#22823;&#32452;&#20505;&#36873;&#20989;&#25968;&#65292;&#20351;&#29992; $\ell_1-\ell_2$ &#31232;&#30095;&#20248;&#21270;&#26041;&#27861;&#36827;&#34892;&#32467;&#26500;&#27169;&#22411;&#36873;&#25321;&#65292;&#23454;&#29616;&#20174;&#19981;&#20805;&#20998;&#19988;&#22024;&#26434;&#30340;&#26102;&#31354;&#25968;&#25454;&#20013;&#35782;&#21035;&#32467;&#26500;&#21270;&#21160;&#24577;&#31995;&#32479;&#65307;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#20102;&#39564;&#35777;&#65292;&#24182;&#35777;&#26126;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#21644;&#39640;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.17467</link><description>&lt;p&gt;
&#36890;&#36807; $\ell_1-\ell_2$ &#20248;&#21270;&#36827;&#34892;&#32467;&#26500;&#27169;&#22411;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Structured model selection via $\ell_1-\ell_2$ optimization. (arXiv:2305.17467v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17467
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#31232;&#30095;&#26368;&#23567;&#20108;&#20056;&#25311;&#21512;&#19968;&#22823;&#32452;&#20505;&#36873;&#20989;&#25968;&#65292;&#20351;&#29992; $\ell_1-\ell_2$ &#31232;&#30095;&#20248;&#21270;&#26041;&#27861;&#36827;&#34892;&#32467;&#26500;&#27169;&#22411;&#36873;&#25321;&#65292;&#23454;&#29616;&#20174;&#19981;&#20805;&#20998;&#19988;&#22024;&#26434;&#30340;&#26102;&#31354;&#25968;&#25454;&#20013;&#35782;&#21035;&#32467;&#26500;&#21270;&#21160;&#24577;&#31995;&#32479;&#65307;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#20102;&#39564;&#35777;&#65292;&#24182;&#35777;&#26126;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#21644;&#39640;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#21270;&#27169;&#22411;&#36873;&#25321;&#22312;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#20855;&#26377;&#37325;&#35201;&#24212;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#31232;&#30095;&#26368;&#23567;&#20108;&#20056;&#25311;&#21512;&#19968;&#22823;&#32452;&#20505;&#36873;&#20989;&#25968;&#65292;&#29992;&#19968;&#31181;&#38750;&#20984; $\ell_1-\ell_2$ &#31232;&#30095;&#20248;&#21270;&#26041;&#27861;&#27714;&#35299;&#65292;&#36890;&#36807;&#20132;&#26367;&#26041;&#21521;&#20056;&#27861;&#30340;&#26041;&#27861;&#36827;&#34892;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22914;&#26524;&#20505;&#36873;&#20989;&#25968;&#38598;&#21512;&#24418;&#25104;&#36793;&#30028;&#27491;&#20132;&#31995;&#32479;&#30340;&#32467;&#26500;&#38543;&#26426;&#37319;&#26679;&#30697;&#38453;&#65292;&#23601;&#21487;&#20197;&#36890;&#36807;&#20271;&#24681;&#26031;&#22374;&#26679;&#24335;&#30340;&#19981;&#31561;&#24335;&#21644;&#19968;&#33268;&#24615;&#26465;&#20214;&#31283;&#23450;&#24674;&#22797;&#65292;&#24182;&#19988;&#35823;&#24046;&#26377;&#30028;&#12290;&#35813;&#23398;&#20064;&#26041;&#27861;&#22312;&#30001;&#31896;&#24615;Burgers'&#26041;&#31243;&#21644;&#20004;&#20010;&#21453;&#24212;&#25193;&#25955;&#26041;&#31243;&#20135;&#29983;&#30340;&#21512;&#25104;&#25968;&#25454;&#19978;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;&#35745;&#31639;&#32467;&#26524;&#35777;&#26126;&#20102;&#25104;&#21151;&#30340;&#29702;&#35770;&#20445;&#35777;&#21644;&#30456;&#23545;&#20110;&#29615;&#22659;&#32500;&#25968;&#21644;&#20505;&#36873;&#20989;&#25968;&#25968;&#37327;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Automated model selection is an important application in science and engineering. In this work, we develop a learning approach for identifying structured dynamical systems from undersampled and noisy spatiotemporal data. The learning is performed by a sparse least-squares fitting over a large set of candidate functions via a nonconvex $\ell_1-\ell_2$ sparse optimization solved by the alternating direction method of multipliers. Using a Bernstein-like inequality with a coherence condition, we show that if the set of candidate functions forms a structured random sampling matrix of a bounded orthogonal system, the recovery is stable and the error is bounded. The learning approach is validated on synthetic data generated by the viscous Burgers' equation and two reaction-diffusion equations. The computational results demonstrate the theoretical guarantees of success and the efficiency with respect to the ambient dimension and the number of candidate functions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#23545;&#25239;&#24615;&#25439;&#22833;&#21644;&#23545;&#25239;&#24615;&#36716;&#25442;&#65292;&#19988;&#21518;&#24724;&#36880;&#28176;&#22686;&#21152;&#19982;&#23545;&#25163;&#30340;&#24694;&#24847;&#31243;&#24230;&#25104;&#27604;&#20363;&#12290;</title><link>http://arxiv.org/abs/2305.17380</link><description>&lt;p&gt;
&#20855;&#26377;&#23545;&#25239;&#24615;&#25439;&#22833;&#21644;&#36716;&#25442;&#30340;&#26080;&#36951;&#25022;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
No-Regret Online Reinforcement Learning with Adversarial Losses and Transitions. (arXiv:2305.17380v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17380
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#23545;&#25239;&#24615;&#25439;&#22833;&#21644;&#23545;&#25239;&#24615;&#36716;&#25442;&#65292;&#19988;&#21518;&#24724;&#36880;&#28176;&#22686;&#21152;&#19982;&#23545;&#25163;&#30340;&#24694;&#24847;&#31243;&#24230;&#25104;&#27604;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#23545;&#25239;&#24615;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#22312;&#19982;&#23545;&#25163;&#30340;$ T $&#36718;&#20132;&#20114;&#20043;&#21518;&#23454;&#29616;${ O}(\sqrt{T})$&#30340;&#21518;&#24724;&#65292;&#21363;&#20351;&#25439;&#22833;&#20989;&#25968;&#26159;&#30001;&#23545;&#25163;&#20219;&#24847;&#36873;&#25321;&#30340;&#65292;&#20294;&#21069;&#25552;&#26159;&#36716;&#31227;&#20989;&#25968;&#24517;&#39035;&#22266;&#23450;&#12290;&#36825;&#26159;&#22240;&#20026;&#24050;&#32463;&#26377;&#30740;&#31350;&#34920;&#26126;&#65292;&#23545;&#25239;&#24615;&#36716;&#31227;&#20989;&#25968;&#20351;&#26080;&#24724;&#23398;&#20064;&#21464;&#24471;&#19981;&#21487;&#33021;&#12290;&#23613;&#31649;&#23384;&#22312;&#36825;&#31181;&#19981;&#21487;&#33021;&#24615;&#32467;&#26524;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#21487;&#20197;&#22788;&#29702;&#23545;&#25239;&#24615;&#25439;&#22833;&#21644;&#23545;&#25239;&#24615;&#36716;&#25442;&#30340;&#31639;&#27861;&#65292;&#21518;&#24724;&#36880;&#28176;&#22686;&#21152;&#19982;&#23545;&#25163;&#30340;&#24694;&#24847;&#31243;&#24230;&#25104;&#27604;&#20363;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#23427;&#30340;&#21518;&#24724;&#20026;$\widetilde{{O}}(\sqrt{T} + C^{\textsf{P}})$&#65292;&#20854;&#20013;$C^{\textsf{P}}$&#34920;&#31034;&#36716;&#25442;&#20989;&#25968;&#30340;&#23545;&#25239;&#24615;&#65292;&#26368;&#22810;&#21487;&#20197;&#20026;${O}(T)$&#12290;&#34429;&#28982;&#27492;&#31639;&#27861;&#26412;&#36523;&#38656;&#35201;$C^{\textsf{P}}$&#30340;&#30693;&#35782;&#65292;&#20294;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#40657;&#30418;&#32553;&#20943;&#26041;&#27861;&#26469;&#28040;&#38500;&#27492;&#35201;&#27714;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#19968;&#31181;&#36827;&#19968;&#27493;&#30340;&#26041;&#27861;&#65292;&#20351;&#24471;&#31639;&#27861;&#33021;&#22815;&#22788;&#29702;&#20219;&#24847;&#38271;&#24230;&#30340;&#38170;&#23450;&#26399;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing online learning algorithms for adversarial Markov Decision Processes achieve ${O}(\sqrt{T})$ regret after $T$ rounds of interactions even if the loss functions are chosen arbitrarily by an adversary, with the caveat that the transition function has to be fixed. This is because it has been shown that adversarial transition functions make no-regret learning impossible. Despite such impossibility results, in this work, we develop algorithms that can handle both adversarial losses and adversarial transitions, with regret increasing smoothly in the degree of maliciousness of the adversary. More concretely, we first propose an algorithm that enjoys $\widetilde{{O}}(\sqrt{T} + C^{\textsf{P}})$ regret where $C^{\textsf{P}}$ measures how adversarial the transition functions are and can be at most ${O}(T)$. While this algorithm itself requires knowledge of $C^{\textsf{P}}$, we further develop a black-box reduction approach that removes this requirement. Moreover, we also show that furth
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#38543;&#26426;&#24120;&#25968;&#28145;&#24230;&#32593;&#32476;&#30340;PTAS&#26041;&#27861;&#65292;&#23545;&#20110;&#20219;&#20309;&#22266;&#23450;&#35823;&#24046;&#21644;&#28145;&#24230;&#65292;&#20960;&#20046;&#25152;&#26377;&#30340;&#31070;&#32463;&#32593;&#32476;&#37117;&#26159;&#21487;&#23398;&#20064;&#30340;&#12290;</title><link>http://arxiv.org/abs/2305.16508</link><description>&lt;p&gt;
&#22823;&#37096;&#20998;&#31070;&#32463;&#32593;&#32476;&#20960;&#20046;&#26159;&#21487;&#23398;&#20064;&#30340;
&lt;/p&gt;
&lt;p&gt;
Most Neural Networks Are Almost Learnable. (arXiv:2305.16508v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16508
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#38543;&#26426;&#24120;&#25968;&#28145;&#24230;&#32593;&#32476;&#30340;PTAS&#26041;&#27861;&#65292;&#23545;&#20110;&#20219;&#20309;&#22266;&#23450;&#35823;&#24046;&#21644;&#28145;&#24230;&#65292;&#20960;&#20046;&#25152;&#26377;&#30340;&#31070;&#32463;&#32593;&#32476;&#37117;&#26159;&#21487;&#23398;&#20064;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;PTAS&#26469;&#23398;&#20064;&#38543;&#26426;&#24120;&#25968;&#28145;&#24230;&#32593;&#32476;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#20219;&#20309;&#22266;&#23450;&#30340;$\epsilon&gt;0$&#21644;&#28145;&#24230;$i$&#65292;&#23384;&#22312;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#65292;&#23545;&#20110;$\sqrt{d} \cdot \mathbb{S}^{d-1}$&#19978;&#30340;&#20219;&#20309;&#20998;&#24067;&#65292;&#23398;&#20064;&#38543;&#26426;Xavier&#32593;&#32476;&#30340;&#28145;&#24230;$i$&#65292;&#35823;&#24046;&#20026;$\epsilon$&#12290;&#35813;&#31639;&#27861;&#30340;&#26102;&#38388;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$(\bar{d})^{\mathrm{poly}(\epsilon^{-1})}$&#65292;&#20854;&#20013;$\bar d$&#26159;&#32593;&#32476;&#30340;&#22823;&#23567;&#12290;&#23545;&#20110;&#26576;&#20123;&#31867;&#20284;&#20110;Sigmoid&#21644;ReLU&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#21487;&#20197;&#23558;&#35823;&#24046;&#30028;&#38480;&#25913;&#36827;&#20026;$(\bar{d})^{\mathrm{polylog}(\epsilon^{-1})}$&#65292;&#20174;&#32780;&#24471;&#21040;&#19968;&#31181;&#20960;&#20046;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#26469;&#23398;&#20064;&#24120;&#25968;&#28145;&#24230;&#38543;&#26426;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a PTAS for learning random constant-depth networks. We show that for any fixed $\epsilon&gt;0$ and depth $i$, there is a poly-time algorithm that for any distribution on $\sqrt{d} \cdot \mathbb{S}^{d-1}$ learns random Xavier networks of depth $i$, up to an additive error of $\epsilon$. The algorithm runs in time and sample complexity of $(\bar{d})^{\mathrm{poly}(\epsilon^{-1})}$, where $\bar d$ is the size of the network. For some cases of sigmoid and ReLU-like activations the bound can be improved to $(\bar{d})^{\mathrm{polylog}(\epsilon^{-1})}$, resulting in a quasi-poly-time algorithm for learning constant depth random networks.
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#25200;&#21160;&#29983;&#25104;&#26641;&#30340;&#21487;&#24494;&#32858;&#31867;&#26041;&#27861;&#65292;&#20381;&#36182;&#20110;&#32447;&#24615;&#35268;&#21010;&#35299;&#30340;&#38543;&#26426;&#25200;&#21160;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.16358</link><description>&lt;p&gt;
&#24102;&#25200;&#21160;&#29983;&#25104;&#26641;&#30340;&#21487;&#24494;&#32858;&#31867;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Differentiable Clustering with Perturbed Spanning Forests. (arXiv:2305.16358v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16358
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#25200;&#21160;&#29983;&#25104;&#26641;&#30340;&#21487;&#24494;&#32858;&#31867;&#26041;&#27861;&#65292;&#20381;&#36182;&#20110;&#32447;&#24615;&#35268;&#21010;&#35299;&#30340;&#38543;&#26426;&#25200;&#21160;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#23567;&#26435;&#37325;&#29983;&#25104;&#26641;&#30340;&#21487;&#24494;&#32858;&#31867;&#26041;&#27861;&#65292;&#23427;&#26159;&#29983;&#25104;&#26641;&#30340;&#19968;&#31181;&#21464;&#20307;&#65292;&#20855;&#26377;&#22810;&#20010;&#36830;&#36890;&#20998;&#37327;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#32447;&#24615;&#35268;&#21010;&#35299;&#30340;&#38543;&#26426;&#25200;&#21160;&#65292;&#20197;&#23454;&#29616;&#24179;&#28369;&#21644;&#39640;&#25928;&#30340;&#26799;&#24230;&#35745;&#31639;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#22312;&#31471;&#21040;&#31471;&#21487;&#35757;&#32451;&#30340;&#27969;&#27700;&#32447;&#20013;&#21253;&#21547;&#32858;&#31867;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21363;&#20351;&#22312;&#22024;&#26434;&#30340;&#25968;&#25454;&#38598;&#21644;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20960;&#20309;&#29615;&#22659;&#19979;&#20063;&#33021;&#33391;&#22909;&#22320;&#24037;&#20316;&#12290;&#25105;&#20204;&#36824;&#21033;&#29992;&#36825;&#31181;&#26041;&#27861;&#21046;&#23450;&#20102;&#19968;&#20010;&#29305;&#21035;&#30340;&#25439;&#22833;&#65292;&#20197;&#26377;&#25928;&#22320;&#20174;&#37096;&#20998;&#32858;&#31867;&#25968;&#25454;&#23398;&#20064;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#29616;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#23427;&#22312;&#30417;&#30563;&#21644;&#21322;&#30417;&#30563;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a differentiable clustering method based on minimum-weight spanning forests, a variant of spanning trees with several connected components. Our method relies on stochastic perturbations of solutions of linear programs, for smoothing and efficient gradient computations. This allows us to include clustering in end-to-end trainable pipelines. We show that our method performs well even in difficult settings, such as datasets with high noise and challenging geometries. We also formulate an ad hoc loss to efficiently learn from partial clustering data using this operation. We demonstrate its performance on several real world datasets for supervised and semi-supervised tasks.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23567;&#25439;&#22833;&#36793;&#30028;&#30340;&#35270;&#35282;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20998;&#24067;&#24335;RL&#22909;&#22788;&#30340;&#19968;&#20010;&#35299;&#37322;&#65292;&#35813;&#36793;&#30028;&#19982;&#23454;&#20363;&#30456;&#20851;&#30340;&#26368;&#20248;&#25104;&#26412;&#25104;&#27604;&#20363;&#12290;&#22914;&#26524;&#26368;&#20248;&#25104;&#26412;&#24456;&#23567;&#65292;&#20998;&#24067;&#24335;&#26041;&#27861;&#20248;&#20110;&#38750;&#20998;&#24067;&#24335;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.15703</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#30340;&#22909;&#22788;&#65306;&#23567;&#25439;&#22833;&#36793;&#30028;
&lt;/p&gt;
&lt;p&gt;
The Benefits of Being Distributional: Small-Loss Bounds for Reinforcement Learning. (arXiv:2305.15703v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15703
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23567;&#25439;&#22833;&#36793;&#30028;&#30340;&#35270;&#35282;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20998;&#24067;&#24335;RL&#22909;&#22788;&#30340;&#19968;&#20010;&#35299;&#37322;&#65292;&#35813;&#36793;&#30028;&#19982;&#23454;&#20363;&#30456;&#20851;&#30340;&#26368;&#20248;&#25104;&#26412;&#25104;&#27604;&#20363;&#12290;&#22914;&#26524;&#26368;&#20248;&#25104;&#26412;&#24456;&#23567;&#65292;&#20998;&#24067;&#24335;&#26041;&#27861;&#20248;&#20110;&#38750;&#20998;&#24067;&#24335;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#24050;&#32463;&#21462;&#24471;&#20102;&#23454;&#35777;&#25104;&#26524;&#65292;&#20294;&#20854;&#20309;&#26102;&#20309;&#22320;&#26377;&#30410;&#30340;&#38382;&#39064;&#23578;&#26410;&#24471;&#21040;&#22238;&#31572;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#36890;&#36807;&#23567;&#25439;&#22833;&#36793;&#30028;&#30340;&#35270;&#35282;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20998;&#24067;&#24335;RL&#22909;&#22788;&#30340;&#19968;&#20010;&#35299;&#37322;&#65292;&#35813;&#36793;&#30028;&#19982;&#23454;&#20363;&#30456;&#20851;&#30340;&#26368;&#20248;&#25104;&#26412;&#25104;&#27604;&#20363;&#12290;&#22914;&#26524;&#26368;&#20248;&#25104;&#26412;&#24456;&#23567;&#65292;&#25105;&#20204;&#30340;&#36793;&#30028;&#20250;&#27604;&#38750;&#20998;&#24067;&#24335;&#26041;&#27861;&#26356;&#24378;&#12290;&#20316;&#20026;&#28909;&#36523;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23398;&#20064;&#25104;&#26412;&#20998;&#24067;&#20250;&#22312;&#24773;&#22659;&#23637;&#24320;&#65288;CB&#65289;&#20013;&#23548;&#33268;&#23567;&#25439;&#22833;&#21518;&#24724;&#36793;&#30028;&#65292;&#25105;&#20204;&#21457;&#29616;&#20998;&#24067;&#24335;CB&#22312;&#19977;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#19978;&#27604;&#26368;&#20808;&#36827;&#30340;&#25216;&#26415;&#22312;&#23454;&#35777;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;&#23545;&#20110;&#22312;&#32447;RL&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20998;&#24067;&#24335;&#29256;&#26412;&#31354;&#38388;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20351;&#29992;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#22312;&#34920;&#26684;MDP&#20013;&#23454;&#29616;&#20102;&#23567;&#25439;&#22833;&#21518;&#24724;&#65292;&#21516;&#26102;&#22312;&#28508;&#21464;&#37327;&#27169;&#22411;&#20013;&#20139;&#26377;&#23567;&#25439;&#22833;PAC&#36793;&#30028;&#12290;&#20197;&#31867;&#20284;&#30340;&#35265;&#35299;&#20026;&#22522;&#30784;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20998;&#24067;&#24335;&#31163;&#32447;RL&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
While distributional reinforcement learning (RL) has demonstrated empirical success, the question of when and why it is beneficial has remained unanswered. In this work, we provide one explanation for the benefits of distributional RL through the lens of small-loss bounds, which scale with the instance-dependent optimal cost. If the optimal cost is small, our bounds are stronger than those from non-distributional approaches. As warmup, we show that learning the cost distribution leads to small-loss regret bounds in contextual bandits (CB), and we find that distributional CB empirically outperforms the state-of-the-art on three challenging tasks. For online RL, we propose a distributional version-space algorithm that constructs confidence sets using maximum likelihood estimation, and we prove that it achieves small-loss regret in the tabular MDPs and enjoys small-loss PAC bounds in latent variable models. Building on similar insights, we propose a distributional offline RL algorithm bas
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#31350;&#20102;&#39640;&#26031;-&#26031;&#22374;&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#21160;&#24577;&#24615;&#12290;&#23545;&#20110;&#20174;&#39640;&#26031;&#30446;&#26631;&#20013;&#37319;&#26679;&#65292;&#21482;&#35201;&#21021;&#22987;&#20540;&#26159;&#39640;&#26031;&#30340;&#65292;&#20855;&#26377;&#21452;&#32447;&#24615;&#26680;&#30340;SVGD&#21160;&#24577;&#23558;&#20445;&#25345;&#39640;&#26031;&#29366;&#24577;&#12290;&#24403;&#30446;&#26631;&#20989;&#25968;&#21576;&#29616;&#20986;&#24378;&#23545;&#25968;&#20985;&#24615;&#26102;&#65292;&#35777;&#26126;&#20102;&#22343;&#22330;&#39640;&#26031;-SVGD&#21160;&#24577;&#20250;&#32447;&#24615;&#25910;&#25947;&#20110;KL&#25955;&#24230;&#19979;&#26368;&#25509;&#36817;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#12290;&#22312;&#26377;&#38480;&#31890;&#23376;&#35774;&#32622;&#20013;&#65292;&#23384;&#22312;&#23545;&#22343;&#22330;&#26497;&#38480;&#30340;&#26102;&#38388;&#24494;&#27493;&#19968;&#33268;&#25910;&#25947;&#20197;&#21450;&#32447;&#24615;&#25910;&#25947;&#33267;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2305.14076</link><description>&lt;p&gt;
&#20851;&#20110;&#39640;&#26031;-&#26031;&#22374;&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#21160;&#24577;&#24615;&#30340;&#25506;&#31350;
&lt;/p&gt;
&lt;p&gt;
Towards Understanding the Dynamics of Gaussian--Stein Variational Gradient Descent. (arXiv:2305.14076v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14076
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#31350;&#20102;&#39640;&#26031;-&#26031;&#22374;&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#21160;&#24577;&#24615;&#12290;&#23545;&#20110;&#20174;&#39640;&#26031;&#30446;&#26631;&#20013;&#37319;&#26679;&#65292;&#21482;&#35201;&#21021;&#22987;&#20540;&#26159;&#39640;&#26031;&#30340;&#65292;&#20855;&#26377;&#21452;&#32447;&#24615;&#26680;&#30340;SVGD&#21160;&#24577;&#23558;&#20445;&#25345;&#39640;&#26031;&#29366;&#24577;&#12290;&#24403;&#30446;&#26631;&#20989;&#25968;&#21576;&#29616;&#20986;&#24378;&#23545;&#25968;&#20985;&#24615;&#26102;&#65292;&#35777;&#26126;&#20102;&#22343;&#22330;&#39640;&#26031;-SVGD&#21160;&#24577;&#20250;&#32447;&#24615;&#25910;&#25947;&#20110;KL&#25955;&#24230;&#19979;&#26368;&#25509;&#36817;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#12290;&#22312;&#26377;&#38480;&#31890;&#23376;&#35774;&#32622;&#20013;&#65292;&#23384;&#22312;&#23545;&#22343;&#22330;&#26497;&#38480;&#30340;&#26102;&#38388;&#24494;&#27493;&#19968;&#33268;&#25910;&#25947;&#20197;&#21450;&#32447;&#24615;&#25910;&#25947;&#33267;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Stein Variational Gradient Descent (SVGD)&#26159;&#19968;&#31181;&#38750;&#21442;&#25968;&#22522;&#20110;&#31890;&#23376;&#30340;&#30830;&#23450;&#24615;&#37319;&#26679;&#31639;&#27861;&#12290;&#23613;&#31649;&#20854;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#29702;&#35299;SVGD&#30340;&#29702;&#35770;&#23646;&#24615;&#19968;&#30452;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;&#23545;&#20110;&#20174;&#39640;&#26031;&#30446;&#26631;&#20013;&#37319;&#26679;&#65292;&#21482;&#35201;&#21021;&#22987;&#20540;&#26159;&#39640;&#26031;&#30340;&#65292;&#20855;&#26377;&#21452;&#32447;&#24615;&#26680;&#30340;SVGD&#21160;&#24577;&#23558;&#20445;&#25345;&#39640;&#26031;&#29366;&#24577;&#12290;&#21463;&#27492;&#20107;&#23454;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#36890;&#36807;&#21452;&#32447;&#24615;&#26680;&#23558;SVGD&#25237;&#24433;&#21040;&#39640;&#26031;&#20998;&#24067;&#26063;&#20013;&#65292;&#21363;&#39640;&#26031;&#21464;&#20998;&#25512;&#26029; (GVI) &#19982; SVGD&#12290;&#25105;&#20204;&#36890;&#36807;&#32771;&#34385;&#22343;&#22330; PDE &#21644;&#31163;&#25955;&#31890;&#23376;&#31995;&#32479;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#23436;&#25972;&#30340;&#22270;&#20687;&#12290;&#24403;&#30446;&#26631;&#20989;&#25968;&#21576;&#29616;&#20986;&#24378;&#23545;&#25968;&#20985;&#24615;&#26102;&#65292;&#35777;&#26126;&#20102;&#22343;&#22330;&#39640;&#26031;-SVGD&#21160;&#24577;&#20250;&#32447;&#24615;&#25910;&#25947;&#20110;KL&#25955;&#24230;&#19979;&#26368;&#25509;&#36817;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#12290;&#22312;&#26377;&#38480;&#31890;&#23376;&#35774;&#32622;&#20013;&#65292;&#23384;&#22312;&#23545;&#22343;&#22330;&#26497;&#38480;&#30340;&#26102;&#38388;&#24494;&#27493;&#19968;&#33268;&#25910;&#25947;&#20197;&#21450;&#32447;&#24615;&#25910;&#25947;&#33267;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#22522;&#20110;&#19968;&#20010;&#26032;&#30340;&#20195;&#25968;&#24658;&#31561;&#24335;&#65292;&#35813;&#31561;&#24335;&#23558;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#30340;&#36153;&#24076;&#23572;&#20449;&#24687;&#30697;&#38453;&#19982;&#31890;&#23376;&#22343;&#21248;&#20998;&#24067;&#30340;&#36153;&#24076;&#23572;&#20449;&#24687;&#30697;&#38453;&#30456;&#20851;&#32852;&#12290;&#36825;&#20010;&#31561;&#24335;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#36879;&#35270; GVI with SVGD &#22312;&#22343;&#22330;&#21644;&#31890;&#23376;&#35774;&#32622;&#20013;&#30340;&#21160;&#24577;&#24615;&#30340;&#32479;&#19968;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stein Variational Gradient Descent (SVGD) is a nonparametric particle-based deterministic sampling algorithm. Despite its wide usage, understanding the theoretical properties of SVGD has remained a challenging problem. For sampling from a Gaussian target, the SVGD dynamics with a bilinear kernel will remain Gaussian as long as the initializer is Gaussian. Inspired by this fact, we undertake a detailed theoretical study of the Gaussian-SVGD, i.e., SVGD projected to the family of Gaussian distributions via the bilinear kernel, or equivalently Gaussian variational inference (GVI) with SVGD. We present a complete picture by considering both the mean-field PDE and discrete particle systems. When the target is strongly log-concave, the mean-field Gaussian-SVGD dynamics is proven to converge linearly to the Gaussian distribution closest to the target in KL divergence. In the finite-particle setting, there is both uniform in time convergence to the mean-field limit and linear convergence in ti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#26465;&#20214;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65292;&#26681;&#25454;cGAN&#30340;&#21028;&#21035;&#22120;&#25968;&#25454;&#35782;&#21035;&#20986;&#26368;&#25509;&#36817;&#30446;&#26631;&#30340;&#29616;&#26377;&#27169;&#24335;&#65292;&#24182;&#36890;&#36807;&#25193;&#23637;&#36830;&#32493;&#23398;&#20064;&#27169;&#22411;&#65292;&#20351;&#29992;&#22238;&#25918;&#29983;&#25104;&#30340;&#25968;&#25454;&#26469;&#35757;&#32451;&#30446;&#26631;&#27169;&#24335;&#30340;cGAN&#27169;&#22411;&#65292;&#20197;&#36991;&#20813;&#28798;&#38590;&#24615;&#36951;&#24536;&#65292;&#25552;&#39640;&#20102;&#29983;&#25104;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.11400</link><description>&lt;p&gt;
&#38754;&#21521;&#26377;&#26465;&#20214;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;&#23569;&#26679;&#26412;&#36830;&#32493;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Few-Shot Continual Learning for Conditional Generative Adversarial Networks. (arXiv:2305.11400v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11400
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#26465;&#20214;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65292;&#26681;&#25454;cGAN&#30340;&#21028;&#21035;&#22120;&#25968;&#25454;&#35782;&#21035;&#20986;&#26368;&#25509;&#36817;&#30446;&#26631;&#30340;&#29616;&#26377;&#27169;&#24335;&#65292;&#24182;&#36890;&#36807;&#25193;&#23637;&#36830;&#32493;&#23398;&#20064;&#27169;&#22411;&#65292;&#20351;&#29992;&#22238;&#25918;&#29983;&#25104;&#30340;&#25968;&#25454;&#26469;&#35757;&#32451;&#30446;&#26631;&#27169;&#24335;&#30340;cGAN&#27169;&#22411;&#65292;&#20197;&#36991;&#20813;&#28798;&#38590;&#24615;&#36951;&#24536;&#65292;&#25552;&#39640;&#20102;&#29983;&#25104;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29983;&#25104;&#27169;&#22411;&#30340;&#23569;&#26679;&#26412;&#36830;&#32493;&#23398;&#20064;&#20013;&#65292;&#24517;&#39035;&#23398;&#20064;&#30446;&#26631;&#27169;&#24335;&#65292;&#24182;&#22312;&#19981;&#24433;&#21709;&#20808;&#21069;&#23398;&#20064;&#21040;&#30340;&#27169;&#24335;&#30340;&#24773;&#20917;&#19979;&#20165;&#20351;&#29992;&#26377;&#38480;&#30340;&#26679;&#26412;&#12290;&#26412;&#25991;&#38024;&#23545;&#26465;&#20214;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#65292;&#22522;&#20110;&#19968;&#31181;&#26032;&#30340;&#29992;&#20110;&#29983;&#25104;&#24314;&#27169;&#30340;&#27169;&#24335;&#20146;&#21644;&#21147;&#37327;&#24230;&#12290;&#25105;&#20204;&#30340;&#24230;&#37327;&#23436;&#20840;&#22522;&#20110;cGAN&#30340;&#21028;&#21035;&#22120;&#65292;&#21487;&#20197;&#35782;&#21035;&#26368;&#25509;&#36817;&#30446;&#26631;&#30340;&#29616;&#26377;&#27169;&#24335;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#21253;&#21547;&#22522;&#20110;&#26368;&#25509;&#36817;&#27169;&#24335;&#30340;&#21152;&#26435;&#26631;&#31614;&#26469;&#25193;&#23637;&#36830;&#32493;&#23398;&#20064;&#27169;&#22411;&#12290;&#20026;&#20102;&#39044;&#38450;&#28798;&#38590;&#24615;&#36951;&#24536;&#65292;&#25105;&#20204;&#39318;&#20808;&#20351;&#29992;cGAN&#30340;&#29983;&#25104;&#22120;&#29983;&#25104;&#24102;&#26631;&#31614;&#30340;&#25968;&#25454;&#26679;&#26412;&#65292;&#28982;&#21518;&#36890;&#36807;&#22238;&#25918;&#29983;&#25104;&#30340;&#25968;&#25454;&#26469;&#35757;&#32451;&#30446;&#26631;&#27169;&#24335;&#30340;cGAN&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25552;&#39640;&#29983;&#25104;&#24615;&#33021;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#65292;&#36229;&#36234;&#20102;&#21508;&#31181;&#26631;&#20934;&#21644;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In few-shot continual learning for generative models, a target mode must be learned with limited samples without adversely affecting the previously learned modes. In this paper, we propose a new continual learning approach for conditional generative adversarial networks (cGAN) based on a new mode-affinity measure for generative modeling. Our measure is entirely based on the cGAN's discriminator and can identify the existing modes that are most similar to the target. Subsequently, we expand the continual learning model by including the target mode using a weighted label derived from those of the closest modes. To prevent catastrophic forgetting, we first generate labeled data samples using the cGAN's generator, and then train the cGAN model for the target mode while memory replaying with the generated data. Our experimental results demonstrate the efficacy of our approach in improving the generation performance over the baselines and the state-of-the-art approaches for various standard 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#38024;&#23545;&#21152;&#26435;&#22240;&#26524; DAGs&#30340;&#26032;&#24230;&#37327;&#21644;&#25628;&#32034;&#31639;&#27861;&#65292;&#21457;&#29616;&#20102;&#29992;&#20110;&#33258;&#36866;&#24212;&#24178;&#39044;&#30340;&#22240;&#26524;&#22270;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#26469;&#25429;&#25417;&#25628;&#32034;&#31639;&#27861;&#30340;&#26368;&#22351;&#24178;&#39044;&#25104;&#26412;&#65292;&#24182;&#25552;&#20379;&#33258;&#36866;&#24212;&#25628;&#32034;&#31639;&#27861;&#23454;&#29616;&#23545;&#25968;&#36924;&#36817;&#12290;</title><link>http://arxiv.org/abs/2305.04445</link><description>&lt;p&gt;
&#29992;&#20110;&#21152;&#26435;&#22240;&#26524; DAG &#30340;&#26032;&#24230;&#37327;&#21644;&#25628;&#32034;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
New metrics and search algorithms for weighted causal DAGs. (arXiv:2305.04445v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04445
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#38024;&#23545;&#21152;&#26435;&#22240;&#26524; DAGs&#30340;&#26032;&#24230;&#37327;&#21644;&#25628;&#32034;&#31639;&#27861;&#65292;&#21457;&#29616;&#20102;&#29992;&#20110;&#33258;&#36866;&#24212;&#24178;&#39044;&#30340;&#22240;&#26524;&#22270;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#26469;&#25429;&#25417;&#25628;&#32034;&#31639;&#27861;&#30340;&#26368;&#22351;&#24178;&#39044;&#25104;&#26412;&#65292;&#24182;&#25552;&#20379;&#33258;&#36866;&#24212;&#25628;&#32034;&#31639;&#27861;&#23454;&#29616;&#23545;&#25968;&#36924;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#25968;&#25454;&#20013;&#24674;&#22797;&#22240;&#26524;&#20851;&#31995;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#38382;&#39064;&#12290;&#22312;&#20351;&#29992;&#35266;&#27979;&#25968;&#25454;&#26102;&#65292;&#21482;&#33021;&#24674;&#22797;&#21040;&#19968;&#20010;&#39532;&#23572;&#31185;&#22827;&#31561;&#20215;&#31867;&#30340;&#22240;&#26524;&#22270;&#65292;&#24182;&#19988;&#38656;&#35201;&#39069;&#22806;&#30340;&#20551;&#35774;&#25110;&#24178;&#39044;&#25968;&#25454;&#26469;&#23436;&#25104;&#24674;&#22797;&#12290;&#26412;&#25991;&#22312;&#19968;&#20123;&#26631;&#20934;&#20551;&#35774;&#19979;&#65292;&#36890;&#36807;&#33410;&#28857;&#30456;&#20851;&#24178;&#39044;&#25104;&#26412;&#30340;&#33258;&#36866;&#24212;&#24178;&#39044;&#65292;&#30740;&#31350;&#22240;&#26524;&#22270;&#21457;&#29616;&#12290;&#23545;&#20110;&#36825;&#31181;&#24773;&#20917;&#65292;&#25105;&#20204;&#35777;&#26126;&#27809;&#26377;&#31639;&#27861;&#33021;&#22815;&#27604;&#39564;&#35777;&#27425;&#25968;&#30340;&#39034;&#24207;&#26356;&#22909;&#22320;&#23454;&#29616;&#28176;&#36817;&#20445;&#35777;&#65292;&#39564;&#35777;&#27425;&#25968;&#26159;&#33258;&#36866;&#24212;&#25628;&#32034;&#31639;&#27861;&#30340;&#19968;&#20010;&#25104;&#29087;&#22522;&#20934;&#12290;&#22312;&#36825;&#20010;&#36127;&#38754;&#32467;&#26524;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#23450;&#20041;&#20102;&#19968;&#20010;&#25429;&#25417;&#20219;&#20309;&#25628;&#32034;&#31639;&#27861;&#26368;&#22351;&#24178;&#39044;&#25104;&#26412;&#30340;&#26032;&#22522;&#20934;&#12290;&#27492;&#22806;&#65292;&#38024;&#23545;&#36825;&#20010;&#26032;&#22522;&#20934;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#33258;&#36866;&#24212;&#25628;&#32034;&#31639;&#27861;&#65292;&#22312;&#21508;&#31181;&#35774;&#32622;&#19979;&#37117;&#33021;&#23454;&#29616;&#23545;&#25968;&#36924;&#36817;&#65306;&#21407;&#23376;&#12289;&#26377;&#30028;&#22823;&#23567;&#30340;&#24178;&#39044;&#21644;&#24191;&#20041;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recovering causal relationships from data is an important problem. Using observational data, one can typically only recover causal graphs up to a Markov equivalence class and additional assumptions or interventional data are needed for complete recovery. In this work, under some standard assumptions, we study causal graph discovery via adaptive interventions with node-dependent interventional costs. For this setting, we show that no algorithm can achieve an approximation guarantee that is asymptotically better than linear in the number of vertices with respect to the verification number; a well-established benchmark for adaptive search algorithms. Motivated by this negative result, we define a new benchmark that captures the worst-case interventional cost for any search algorithm. Furthermore, with respect to this new benchmark, we provide adaptive search algorithms that achieve logarithmic approximations under various settings: atomic, bounded size interventions and generalized cost o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#25193;&#23637;&#30340; Wasserstein PAC-Bayes &#26694;&#26550;&#65292;&#21033;&#29992;&#25439;&#22833;&#20989;&#25968;&#19978;&#30340;&#20960;&#20309;&#20551;&#35774;&#25552;&#20379;&#20102;&#26032;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#36890;&#36807;&#35813;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102; \cite{lambert2022variational} &#20013;&#31639;&#27861;&#30340;&#36755;&#20986;&#20855;&#26377;&#24378;&#22823;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#21516;&#26102;&#65292;&#24314;&#31435;&#20102; PAC-Bayes &#21644;&#20248;&#21270;&#31639;&#27861;&#20043;&#38388;&#30340;&#26725;&#26753;&#12290;</title><link>http://arxiv.org/abs/2304.07048</link><description>&lt;p&gt;
Wasserstein PAC-Bayes &#23398;&#20064;&#65306;&#27867;&#21270;&#19982;&#20248;&#21270;&#20043;&#38388;&#30340;&#26725;&#26753;&#12290;
&lt;/p&gt;
&lt;p&gt;
Wasserstein PAC-Bayes Learning: A Bridge Between Generalisation and Optimisation. (arXiv:2304.07048v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07048
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#25193;&#23637;&#30340; Wasserstein PAC-Bayes &#26694;&#26550;&#65292;&#21033;&#29992;&#25439;&#22833;&#20989;&#25968;&#19978;&#30340;&#20960;&#20309;&#20551;&#35774;&#25552;&#20379;&#20102;&#26032;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#36890;&#36807;&#35813;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102; \cite{lambert2022variational} &#20013;&#31639;&#27861;&#30340;&#36755;&#20986;&#20855;&#26377;&#24378;&#22823;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#21516;&#26102;&#65292;&#24314;&#31435;&#20102; PAC-Bayes &#21644;&#20248;&#21270;&#31639;&#27861;&#20043;&#38388;&#30340;&#26725;&#26753;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
PAC-Bayes &#23398;&#20064;&#26159;&#19968;&#31181;&#24050;&#24314;&#31435;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#35757;&#32451;&#38454;&#27573;&#35780;&#20272;&#23398;&#20064;&#31639;&#27861;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#22312;&#35757;&#32451;&#20043;&#21069;&#65292;&#24324;&#28165;&#26970;&#20026;&#20160;&#20040;&#30693;&#21517;&#31639;&#27861;&#30340;&#36755;&#20986;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#29305;&#24615;&#32780; PAC-Bayes &#26159;&#21542;&#26377;&#29992;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#25193;&#23637;&#31616;&#35201;&#20171;&#32461;&#22312;&#25991;&#29486; \cite{amit2022ipm} &#20013;&#25552;&#20986;&#30340; \emph{Wasserstein PAC-Bayes} &#26694;&#26550;&#26469;&#31215;&#26497;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#26032;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#21033;&#29992;&#25439;&#22833;&#20989;&#25968;&#19978;&#30340;&#20960;&#20309;&#20551;&#35774;&#12290;&#20351;&#29992;&#25105;&#20204;&#30340;&#26694;&#26550;&#65292;&#25105;&#20204;&#22312;&#20219;&#20309;&#35757;&#32451;&#20043;&#21069;&#23601;&#35777;&#26126;&#20102; \cite{lambert2022variational} &#20013;&#31639;&#27861;&#30340;&#36755;&#20986;&#20855;&#26377;&#24378;&#22823;&#30340;&#28176;&#36817;&#27867;&#21270;&#33021;&#21147;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#27867;&#21270;&#26694;&#26550;&#20013;&#23558;&#20248;&#21270;&#32467;&#26524;&#32467;&#21512;&#36215;&#26469;&#65292;&#26500;&#24314;&#20102; PAC-Bayes &#21644;&#20248;&#21270;&#31639;&#27861;&#20043;&#38388;&#30340;&#26725;&#26753;&#12290;
&lt;/p&gt;
&lt;p&gt;
PAC-Bayes learning is an established framework to assess the generalisation ability of learning algorithm during the training phase. However, it remains challenging to know whether PAC-Bayes is useful to understand, before training, why the output of well-known algorithms generalise well. We positively answer this question by expanding the \emph{Wasserstein PAC-Bayes} framework, briefly introduced in \cite{amit2022ipm}. We provide new generalisation bounds exploiting geometric assumptions on the loss function. Using our framework, we prove, before any training, that the output of an algorithm from \citet{lambert2022variational} has a strong asymptotic generalisation ability. More precisely, we show that it is possible to incorporate optimisation results within a generalisation framework, building a bridge between PAC-Bayes and optimisation algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#37325;&#22797;&#37319;&#26679;&#30340;&#25919;&#31574;&#35780;&#20272;&#26041;&#27861;&#65292;&#20197;&#35780;&#20272;&#22312;&#32447; RL &#31639;&#27861;&#23454;&#29616;&#30340;&#20010;&#24615;&#21270;&#31243;&#24230;&#12290;&#35813;&#26041;&#27861;&#21487;&#29992;&#20110;&#20248;&#21270;&#25968;&#23383;&#20581;&#24247;&#30340;&#20010;&#24615;&#21270;&#24178;&#39044;&#12290;</title><link>http://arxiv.org/abs/2304.05365</link><description>&lt;p&gt;
&#25105;&#20204;&#23454;&#29616;&#20102;&#20010;&#24615;&#21270;&#27835;&#30103;&#21527;&#65311;&#20351;&#29992;&#37325;&#22797;&#37319;&#26679;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#20010;&#24615;&#21270;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Did we personalize? Assessing personalization by an online reinforcement learning algorithm using resampling. (arXiv:2304.05365v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05365
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#37325;&#22797;&#37319;&#26679;&#30340;&#25919;&#31574;&#35780;&#20272;&#26041;&#27861;&#65292;&#20197;&#35780;&#20272;&#22312;&#32447; RL &#31639;&#27861;&#23454;&#29616;&#30340;&#20010;&#24615;&#21270;&#31243;&#24230;&#12290;&#35813;&#26041;&#27861;&#21487;&#29992;&#20110;&#20248;&#21270;&#25968;&#23383;&#20581;&#24247;&#30340;&#20010;&#24615;&#21270;&#24178;&#39044;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#23383;&#20581;&#24247;&#20013;&#65292;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20010;&#24615;&#21270;&#27835;&#30103;&#24207;&#21015;&#20197;&#25903;&#25345;&#29992;&#25143;&#37319;&#21462;&#26356;&#20581;&#24247;&#30340;&#34892;&#20026;&#36234;&#26469;&#36234;&#21463;&#21040;&#20851;&#27880;&#12290;&#36825;&#31181;&#36830;&#32493;&#20915;&#31574;&#38382;&#39064;&#28041;&#21450;&#21040;&#22522;&#20110;&#29992;&#25143;&#30340;&#19978;&#19979;&#25991;&#65288;&#20363;&#22914;&#65292;&#20808;&#21069;&#30340;&#27963;&#21160;&#27700;&#24179;&#12289;&#20301;&#32622;&#31561;&#65289;&#22312;&#20309;&#26102;&#27835;&#30103;&#20197;&#21450;&#22914;&#20309;&#27835;&#30103;&#30340;&#20915;&#23450;&#12290;&#22312;&#32447;RL&#31639;&#27861;&#26159;&#36825;&#20010;&#38382;&#39064;&#30340;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#65292;&#22240;&#20026;&#23427;&#22522;&#20110;&#27599;&#20010;&#29992;&#25143;&#30340;&#21382;&#21490;&#21453;&#39304;&#36827;&#34892;&#23398;&#20064;&#65292;&#24182;&#21033;&#29992;&#36825;&#20123;&#30693;&#35782;&#20010;&#24615;&#21270;&#36825;&#20123;&#20915;&#31574;&#12290;&#28982;&#32780;&#65292;&#35201;&#20915;&#23450;&#26159;&#21542;&#24212;&#22312;&#23454;&#38469;&#37096;&#32626;&#30340;&#8220;&#20248;&#21270;&#8221;&#24178;&#39044;&#20013;&#21253;&#21547;RL&#31639;&#27861;&#65292;&#25105;&#20204;&#24517;&#39035;&#35780;&#20272;&#25968;&#25454;&#35777;&#25454;&#65292;&#34920;&#26126;RL&#31639;&#27861;&#23454;&#38469;&#19978;&#27491;&#22312;&#23558;&#27835;&#30103;&#20010;&#24615;&#21270;&#36866;&#24212;&#20854;&#29992;&#25143;&#12290;&#30001;&#20110;RL&#31639;&#27861;&#20013;&#30340;&#38543;&#26426;&#24615;&#65292;&#20154;&#20204;&#21487;&#33021;&#20250;&#23545;&#20854;&#22312;&#26576;&#20123;&#29366;&#24577;&#19979;&#30340;&#23398;&#20064;&#24182;&#20351;&#29992;&#27492;&#23398;&#20064;&#26469;&#25552;&#20379;&#29305;&#23450;&#27835;&#30103;&#30340;&#33021;&#21147;&#20135;&#29983;&#35823;&#35299;&#12290;&#25105;&#20204;&#20351;&#29992;&#24037;&#20316;&#23450;&#20041;&#30340;&#20010;&#24615;&#21270;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#31181;&#37325;&#22797;&#37319;&#26679;&#25919;&#31574;&#35780;&#20272;&#26041;&#27861;&#26469;&#35780;&#20272;&#22312;&#32447;RL&#31639;&#27861;&#23454;&#29616;&#30340;&#20010;&#24615;&#21270;&#27700;&#24179;&#12290;&#25105;&#20204;&#20351;&#29992;&#27169;&#25311;&#35780;&#20272;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20934;&#30830;&#22320;&#35782;&#21035;&#20010;&#24615;&#21270;&#30340;&#31574;&#30053;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#20248;&#21270;&#25968;&#23383;&#20581;&#24247;&#30340;&#20010;&#24615;&#21270;&#24178;&#39044;&#26041;&#38754;&#20855;&#26377;&#28508;&#22312;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is a growing interest in using reinforcement learning (RL) to personalize sequences of treatments in digital health to support users in adopting healthier behaviors. Such sequential decision-making problems involve decisions about when to treat and how to treat based on the user's context (e.g., prior activity level, location, etc.). Online RL is a promising data-driven approach for this problem as it learns based on each user's historical responses and uses that knowledge to personalize these decisions. However, to decide whether the RL algorithm should be included in an ``optimized'' intervention for real-world deployment, we must assess the data evidence indicating that the RL algorithm is actually personalizing the treatments to its users. Due to the stochasticity in the RL algorithm, one may get a false impression that it is learning in certain states and using this learning to provide specific treatments. We use a working definition of personalization and introduce a resamp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#25955;&#21270;&#30340;&#21704;&#23494;&#39039;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#24341;&#36215;&#30340;Hamiltonian&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#36890;&#29992;&#36924;&#36817;&#33021;&#21147;&#65292;&#35777;&#26126;&#20102;&#20854;&#20013;&#30340;&#19968;&#37096;&#20998;&#27969;&#21487;&#20197;&#36880;&#28176;&#36924;&#36817;&#32039;&#33268;&#22495;&#19978;&#30340;&#20219;&#20309;&#36830;&#32493;&#20989;&#25968;&#65292;&#20026;&#23454;&#38469;&#20351;&#29992;&#25552;&#20379;&#20102;&#29702;&#35770;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2303.12147</link><description>&lt;p&gt;
Hamiltonian&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#19975;&#33021;&#36924;&#36817;&#24615;&#36136;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Universal Approximation Property of Hamiltonian Deep Neural Networks. (arXiv:2303.12147v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12147
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#25955;&#21270;&#30340;&#21704;&#23494;&#39039;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#24341;&#36215;&#30340;Hamiltonian&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#36890;&#29992;&#36924;&#36817;&#33021;&#21147;&#65292;&#35777;&#26126;&#20102;&#20854;&#20013;&#30340;&#19968;&#37096;&#20998;&#27969;&#21487;&#20197;&#36880;&#28176;&#36924;&#36817;&#32039;&#33268;&#22495;&#19978;&#30340;&#20219;&#20309;&#36830;&#32493;&#20989;&#25968;&#65292;&#20026;&#23454;&#38469;&#20351;&#29992;&#25552;&#20379;&#20102;&#29702;&#35770;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#30001;&#31163;&#25955;&#21270;&#30340;&#21704;&#23494;&#39039;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#24341;&#36215;&#30340;Hamiltonian&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;HDNN&#65289;&#30340;&#36890;&#29992;&#36924;&#36817;&#33021;&#21147;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;HDNN&#22240;&#35774;&#35745;&#32780;&#20855;&#26377;&#38750;&#28040;&#22833;&#26799;&#24230;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#25552;&#20379;&#25968;&#20540;&#31283;&#23450;&#24615;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#22312;&#20960;&#20010;&#24212;&#29992;&#20013;HDNN&#24050;&#32463;&#23637;&#31034;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#20294;&#32570;&#23569;&#37327;&#21270;&#20854;&#34920;&#29616;&#21147;&#30340;&#20840;&#38754;&#30740;&#31350;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;HDNN&#30340;&#36890;&#29992;&#36924;&#36817;&#23450;&#29702;&#65292;&#24182;&#35777;&#26126;&#20102;HDNN&#30340;&#19968;&#37096;&#20998;&#27969;&#21487;&#20197;&#36880;&#28176;&#36924;&#36817;&#32039;&#33268;&#22495;&#19978;&#30340;&#20219;&#20309;&#36830;&#32493;&#20989;&#25968;&#12290;&#27492;&#32467;&#26524;&#20026;&#23454;&#38469;&#20351;&#29992;HDNN&#25552;&#20379;&#20102;&#29282;&#22266;&#30340;&#29702;&#35770;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates the universal approximation capabilities of Hamiltonian Deep Neural Networks (HDNNs) that arise from the discretization of Hamiltonian Neural Ordinary Differential Equations. Recently, it has been shown that HDNNs enjoy, by design, non-vanishing gradients, which provide numerical stability during training. However, although HDNNs have demonstrated state-of-the-art performance in several applications, a comprehensive study to quantify their expressivity is missing. In this regard, we provide a universal approximation theorem for HDNNs and prove that a portion of the flow of HDNNs can approximate arbitrary well any continuous function over a compact domain. This result provides a solid theoretical foundation for the practical use of HDNNs.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#28145;&#20837;&#30740;&#31350;&#21644;&#25551;&#36848;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#30340;&#20989;&#25968;&#30340;Lipschitz&#34892;&#20026;&#65292;&#22312;&#22810;&#31181;&#35774;&#32622;&#19979;&#36827;&#34892;&#23454;&#35777;&#30740;&#31350;&#65292;&#24182;&#25581;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#20989;&#25968;Lipschitz&#36830;&#32493;&#24615;&#30340;&#22522;&#26412;&#21644;&#26377;&#36259;&#30340;&#29305;&#24615;&#65292;&#20854;&#20013;&#26368;&#24341;&#20154;&#27880;&#30446;&#30340;&#26159;&#22312;Lipschitz&#24120;&#25968;&#30340;&#19978;&#38480;&#21644;&#19979;&#38480;&#20013;&#35782;&#21035;&#20986;&#20102;&#26126;&#26174;&#30340;&#21452;&#19979;&#38477;&#36235;&#21183;&#12290;</title><link>http://arxiv.org/abs/2302.10886</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20989;&#25968;&#30340;Lipschitz&#36830;&#32493;&#24615;&#30340;&#19968;&#20123;&#22522;&#26412;&#26041;&#38754;
&lt;/p&gt;
&lt;p&gt;
Some Fundamental Aspects about Lipschitz Continuity of Neural Network Functions. (arXiv:2302.10886v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10886
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#28145;&#20837;&#30740;&#31350;&#21644;&#25551;&#36848;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#30340;&#20989;&#25968;&#30340;Lipschitz&#34892;&#20026;&#65292;&#22312;&#22810;&#31181;&#35774;&#32622;&#19979;&#36827;&#34892;&#23454;&#35777;&#30740;&#31350;&#65292;&#24182;&#25581;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#20989;&#25968;Lipschitz&#36830;&#32493;&#24615;&#30340;&#22522;&#26412;&#21644;&#26377;&#36259;&#30340;&#29305;&#24615;&#65292;&#20854;&#20013;&#26368;&#24341;&#20154;&#27880;&#30446;&#30340;&#26159;&#22312;Lipschitz&#24120;&#25968;&#30340;&#19978;&#38480;&#21644;&#19979;&#38480;&#20013;&#35782;&#21035;&#20986;&#20102;&#26126;&#26174;&#30340;&#21452;&#19979;&#38477;&#36235;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Lipschitz&#36830;&#32493;&#24615;&#26159;&#20219;&#20309;&#39044;&#27979;&#27169;&#22411;&#30340;&#19968;&#20010;&#31616;&#21333;&#20294;&#20851;&#38190;&#30340;&#21151;&#33021;&#24615;&#36136;&#65292;&#23427;&#22788;&#20110;&#27169;&#22411;&#30340;&#31283;&#20581;&#24615;&#12289;&#27867;&#21270;&#24615;&#21644;&#23545;&#25239;&#24615;&#33030;&#24369;&#24615;&#30340;&#26680;&#24515;&#12290;&#26412;&#25991;&#26088;&#22312;&#28145;&#20837;&#30740;&#31350;&#21644;&#25551;&#36848;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#30340;&#20989;&#25968;&#30340;Lipschitz&#34892;&#20026;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#36890;&#36807;&#32791;&#23613;&#26368;&#31616;&#21333;&#21644;&#26368;&#19968;&#33324;&#30340;&#19979;&#38480;&#21644;&#19978;&#38480;&#30340;&#26497;&#38480;&#65292;&#22312;&#21508;&#31181;&#19981;&#21516;&#35774;&#32622;&#19979;&#36827;&#34892;&#23454;&#35777;&#30740;&#31350;&#65288;&#21363;&#65292;&#20307;&#31995;&#32467;&#26500;&#12289;&#25439;&#22833;&#12289;&#20248;&#21270;&#22120;&#12289;&#26631;&#31614;&#22122;&#38899;&#31561;&#65289;&#65292;&#34429;&#28982;&#36825;&#19968;&#36873;&#25321;&#20027;&#35201;&#26159;&#21463;&#35745;&#31639;&#38590;&#24230;&#32467;&#26524;&#30340;&#39537;&#21160;&#65292;&#20294;&#23427;&#20063;&#38750;&#24120;&#20016;&#23500;&#65292;&#24182;&#25581;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#20989;&#25968;Lipschitz&#36830;&#32493;&#24615;&#30340;&#20960;&#20010;&#22522;&#26412;&#21644;&#26377;&#36259;&#30340;&#29305;&#24615;&#65292;&#25105;&#20204;&#36824;&#34917;&#20805;&#20102;&#36866;&#24403;&#30340;&#29702;&#35770;&#35770;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Lipschitz continuity is a simple yet crucial functional property of any predictive model for it lies at the core of the model's robustness, generalisation, as well as adversarial vulnerability. Our aim is to thoroughly investigate and characterise the Lipschitz behaviour of the functions realised by neural networks. Thus, we carry out an empirical investigation in a range of different settings (namely, architectures, losses, optimisers, label noise, and more) by exhausting the limits of the simplest and the most general lower and upper bounds. Although motivated primarily by computational hardness results, this choice nevertheless turns out to be rather resourceful and sheds light on several fundamental and intriguing traits of the Lipschitz continuity of neural network functions, which we also supplement with suitable theoretical arguments. As a highlight of this investigation, we identify a striking double descent trend in both upper and lower bounds to the Lipschitz constant with in
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#27604;&#36739;&#20004;&#20010;&#39044;&#27979;&#27169;&#22411;&#30340;&#26679;&#26412;&#22806;$r^2$&#30340;&#26080;&#20559;&#20272;&#35745;&#22120;&#65292;&#24182;&#21033;&#29992;&#26368;&#36817;&#20851;&#20110;&#25968;&#25454;&#19981;&#30830;&#23450;&#24615;&#30340;&#29702;&#35770;&#36827;&#23637;&#12290;</title><link>http://arxiv.org/abs/2302.05131</link><description>&lt;p&gt;
&#26679;&#26412;&#22806;$R^2$&#65306;&#20272;&#35745;&#21644;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
The out-of-sample $R^2$: estimation and inference. (arXiv:2302.05131v1 [stat.ME] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05131
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#27604;&#36739;&#20004;&#20010;&#39044;&#27979;&#27169;&#22411;&#30340;&#26679;&#26412;&#22806;$r^2$&#30340;&#26080;&#20559;&#20272;&#35745;&#22120;&#65292;&#24182;&#21033;&#29992;&#26368;&#36817;&#20851;&#20110;&#25968;&#25454;&#19981;&#30830;&#23450;&#24615;&#30340;&#29702;&#35770;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26679;&#26412;&#22806;&#39044;&#27979;&#26159;&#39044;&#27979;&#27169;&#22411;&#30340;&#19968;&#39033;&#37325;&#35201;&#27979;&#35797;&#65292;&#28982;&#32780;&#29420;&#31435;&#30340;&#27979;&#35797;&#25968;&#25454;&#38598;&#36890;&#24120;&#19981;&#21487;&#29992;&#20110;&#35780;&#20272;&#39044;&#27979;&#35823;&#24046;&#12290;&#22240;&#27492;&#65292;&#36890;&#24120;&#20351;&#29992;&#25968;&#25454;&#25286;&#20998;&#31639;&#27861;&#65288;&#22914;&#20132;&#21449;&#39564;&#35777;&#25110;&#33258;&#21161;&#27861;&#65289;&#26469;&#20272;&#35745;&#26679;&#26412;&#22806;&#34920;&#29616;&#12290;&#23545;&#20110;&#23450;&#37327;&#32467;&#26524;&#65292;&#21487;&#35299;&#37322;&#30340;&#26041;&#24046;&#19982;&#24635;&#26041;&#24046;&#30340;&#27604;&#29575;&#21487;&#20197;&#36890;&#36807;&#30830;&#23450;&#31995;&#25968;&#25110;&#26679;&#26412;&#20869;$R^2$&#26469;&#24635;&#32467;&#65292;&#36825;&#26131;&#20110;&#35299;&#37322;&#24182;&#21487;&#22312;&#19981;&#21516;&#32467;&#26524;&#21464;&#37327;&#20043;&#38388;&#36827;&#34892;&#27604;&#36739;&#12290;&#19982;&#26679;&#26412;&#20869;$R^2$&#30456;&#21453;&#65292;&#26679;&#26412;&#22806;$R^2$&#27809;&#26377;&#24456;&#22909;&#22320;&#23450;&#20041;&#65292;&#26679;&#26412;&#22806;$\hat{R}^2$&#30340;&#21464;&#24322;&#24615;&#34987;&#22823;&#37327;&#24573;&#35270;&#12290;&#36890;&#24120;&#20165;&#25253;&#21578;&#20854;&#28857;&#20272;&#35745;&#20540;&#65292;&#36825;&#38459;&#30861;&#20102;&#19981;&#21516;&#32467;&#26524;&#21464;&#37327;&#21487;&#39044;&#27979;&#24615;&#30340;&#27491;&#24335;&#27604;&#36739;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26126;&#30830;&#23558;&#26679;&#26412;&#22806;$R^2$&#23450;&#20041;&#20026;&#20004;&#20010;&#39044;&#27979;&#27169;&#22411;&#30340;&#27604;&#36739;&#65292;&#24182;&#25552;&#20379;&#26080;&#20559;&#20272;&#35745;&#22120;&#65292;&#21033;&#29992;&#26368;&#36817;&#20851;&#20110;&#25968;&#25454;&#19981;&#30830;&#23450;&#24615;&#30340;&#29702;&#35770;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Out-of-sample prediction is the acid test of predictive models, yet an independent test dataset is often not available for assessment of the prediction error. For this reason, out-of-sample performance is commonly estimated using data splitting algorithms such as cross-validation or the bootstrap. For quantitative outcomes, the ratio of variance explained to total variance can be summarized by the coefficient of determination or in-sample $R^2$, which is easy to interpret and to compare across different outcome variables. As opposed to the in-sample $R^2$, the out-of-sample $R^2$ has not been well defined and the variability on the out-of-sample $\hat{R}^2$ has been largely ignored. Usually only its point estimate is reported, hampering formal comparison of predictability of different outcome variables. Here we explicitly define the out-of-sample $R^2$ as a comparison of two predictive models, provide an unbiased estimator and exploit recent theoretical advances on uncertainty of data 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20449;&#24687;&#29702;&#35770;&#37325;&#35201;&#24615;&#37319;&#26679;&#32858;&#31867;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26368;&#23567;&#21270;&#22312;&#20998;&#24067;&#20559;&#24046;&#32422;&#26463;&#19979;&#26399;&#26395;&#22833;&#30495;&#30340;&#26368;&#22351;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2302.04421</link><description>&lt;p&gt;
&#20449;&#24687;&#29702;&#35770;&#37325;&#35201;&#24615;&#37319;&#26679;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Information Theoretical Importance Sampling Clustering. (arXiv:2302.04421v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04421
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20449;&#24687;&#29702;&#35770;&#37325;&#35201;&#24615;&#37319;&#26679;&#32858;&#31867;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26368;&#23567;&#21270;&#22312;&#20998;&#24067;&#20559;&#24046;&#32422;&#26463;&#19979;&#26399;&#26395;&#22833;&#30495;&#30340;&#26368;&#22351;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#32858;&#31867;&#26041;&#27861;&#20551;&#35774;&#35757;&#32451;&#25968;&#25454;&#21644;&#26410;&#26469;&#25968;&#25454;&#26469;&#33258;&#30456;&#21516;&#30340;&#20998;&#24067;&#65292;&#20294;&#22312;&#22823;&#22810;&#25968;&#30495;&#23454;&#22330;&#26223;&#19979;&#65292;&#36825;&#31181;&#20551;&#35774;&#21487;&#33021;&#19981;&#25104;&#31435;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#29702;&#35770;&#37325;&#35201;&#24615;&#37319;&#26679;&#30340;&#32858;&#31867;&#26041;&#27861;&#65288;ITISC&#65289;&#65292;&#20854;&#22312;&#20998;&#24067;&#20559;&#24046;&#30340;&#32422;&#26463;&#19979;&#26368;&#23567;&#21270;&#26399;&#26395;&#22833;&#30495;&#30340;&#26368;&#22351;&#24773;&#20917;&#12290;&#20998;&#24067;&#20559;&#24046;&#32422;&#26463;&#21487;&#20197;&#36716;&#25442;&#20026;&#20197;&#22522;&#20110;&#37325;&#35201;&#24615;&#37319;&#26679;&#30340;&#22343;&#21248;&#20998;&#24067;&#20026;&#20013;&#24515;&#30340;&#19968;&#32452;&#26435;&#37325;&#20998;&#24067;&#30340;&#32422;&#26463;&#12290;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#30446;&#26631;&#26159;&#22312;&#26368;&#22823;&#38477;&#32423;&#19979;&#26368;&#23567;&#21270;&#25439;&#22833;&#65292;&#22240;&#27492;&#24471;&#21040;&#30340;&#38382;&#39064;&#26159;&#19968;&#20010;&#24102;&#26377;&#32422;&#26463;&#30340;&#26368;&#23567;&#26368;&#22823;&#21270;&#20248;&#21270;&#38382;&#39064;&#65292;&#21487;&#20197;&#20351;&#29992;&#25289;&#26684;&#26391;&#26085;&#26041;&#27861;&#23558;&#20854;&#37325;&#26032;&#34920;&#36798;&#20026;&#26080;&#32422;&#26463;&#38382;&#39064;&#12290;&#35813;&#20248;&#21270;&#38382;&#39064;&#21487;&#20197;&#36890;&#36807;&#20132;&#26367;&#20248;&#21270;&#31639;&#27861;&#25110;&#20351;&#29992;&#21830;&#19994;&#21487;&#29992;&#36719;&#20214;&#30340;&#36890;&#29992;&#20248;&#21270;&#20363;&#31243;&#26469;&#35299;&#20915;&#12290;
&lt;/p&gt;
&lt;p&gt;
A current assumption of most clustering methods is that the training data and future data are taken from the same distribution. However, this assumption may not hold in most real-world scenarios. In this paper, we propose an information theoretical importance sampling based approach for clustering problems (ITISC) which minimizes the worst case of expected distortions under the constraint of distribution deviation. The distribution deviation constraint can be converted to the constraint over a set of weight distributions centered on the uniform distribution derived from importance sampling. The objective of the proposed approach is to minimize the loss under maximum degradation hence the resulting problem is a constrained minimax optimization problem which can be reformulated to an unconstrained problem using the Lagrange method. The optimization problem can be solved by both an alternative optimization algorithm or a general optimization routine by commercially available software. Exp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;PAC-Bayesian bound&#20316;&#20026;Soft Actor-Critic (SAC)&#31639;&#27861;&#35780;&#35770;&#23478;&#35757;&#32451;&#30446;&#26631;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#35757;&#32451;&#19981;&#31283;&#23450;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#35780;&#35770;&#23478;&#24341;&#23548;&#30340;&#38543;&#26426;&#25628;&#32034;&#25506;&#32034;&#22810;&#20010;&#26410;&#26469;&#26469;&#25552;&#39640;&#22312;&#32447;&#23398;&#20064;&#24615;&#33021;&#12290;&#22312;&#22810;&#20010;&#32463;&#20856;&#25511;&#21046;&#21644;&#36816;&#21160;&#20219;&#21153;&#20013;&#65292;&#35813;&#31639;&#27861;&#20855;&#26377;&#26679;&#26412;&#25928;&#29575;&#21644;&#36951;&#25022;&#26368;&#23567;&#21270;&#26041;&#38754;&#30340;&#26126;&#26174;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2301.12776</link><description>&lt;p&gt;
PAC-Bayesian&#36719;&#28436;&#21592;-&#35780;&#35770;&#23478;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
PAC-Bayesian Soft Actor-Critic Learning. (arXiv:2301.12776v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12776
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;PAC-Bayesian bound&#20316;&#20026;Soft Actor-Critic (SAC)&#31639;&#27861;&#35780;&#35770;&#23478;&#35757;&#32451;&#30446;&#26631;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#35757;&#32451;&#19981;&#31283;&#23450;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#35780;&#35770;&#23478;&#24341;&#23548;&#30340;&#38543;&#26426;&#25628;&#32034;&#25506;&#32034;&#22810;&#20010;&#26410;&#26469;&#26469;&#25552;&#39640;&#22312;&#32447;&#23398;&#20064;&#24615;&#33021;&#12290;&#22312;&#22810;&#20010;&#32463;&#20856;&#25511;&#21046;&#21644;&#36816;&#21160;&#20219;&#21153;&#20013;&#65292;&#35813;&#31639;&#27861;&#20855;&#26377;&#26679;&#26412;&#25928;&#29575;&#21644;&#36951;&#25022;&#26368;&#23567;&#21270;&#26041;&#38754;&#30340;&#26126;&#26174;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28436;&#21592;-&#35780;&#35770;&#23478;&#31639;&#27861;&#36890;&#36807;&#20004;&#20010;&#20998;&#21035;&#20316;&#31574;&#30053;&#35780;&#20272;&#21644;&#25913;&#36827;&#30340;&#21151;&#33021;&#36924;&#36817;&#22120;&#26469;&#35299;&#20915;&#22686;&#24378;&#23398;&#20064;(RL)&#30340;&#21452;&#37325;&#30446;&#26631;&#12290;&#27492;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#26159;&#20197;&#35757;&#32451;&#19981;&#31283;&#23450;&#20026;&#20195;&#20215;&#30340;&#65292;&#20027;&#35201;&#21407;&#22240;&#26159;&#35780;&#35770;&#23478;&#36924;&#36817;&#35823;&#24046;&#23545;&#28436;&#21592;&#30340;&#30772;&#22351;&#24615;&#24433;&#21709;&#12290;&#25105;&#20204;&#36890;&#36807;&#39318;&#27425;&#37319;&#29992;&#19968;&#20010;&#29616;&#26377;&#30340;&#21487;&#33021;&#36817;&#20284;&#27491;&#30830;(PAC)Bayesian&#30028;&#38480;&#20316;&#20026;Soft Actor-Critic (SAC)&#31639;&#27861;&#30340;&#35780;&#35770;&#23478;&#35757;&#32451;&#30446;&#26631;&#26469;&#35299;&#20915;&#36825;&#20010;&#29942;&#39048;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#24403;&#38543;&#26426;&#28436;&#21592;&#36890;&#36807;&#35780;&#35770;&#23478;&#24341;&#23548;&#30340;&#38543;&#26426;&#25628;&#32034;&#25506;&#32034;&#22810;&#20010;&#26410;&#26469;&#26102;&#65292;&#22312;&#32447;&#23398;&#20064;&#24615;&#33021;&#26174;&#33879;&#25552;&#39640;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#25105;&#20204;&#24471;&#21040;&#30340;&#31639;&#27861;&#22312;&#22810;&#20010;&#32463;&#20856;&#25511;&#21046;&#21644;&#36816;&#21160;&#20219;&#21153;&#20013;&#65292;&#22312;&#26679;&#26412;&#25928;&#29575;&#21644;&#36951;&#25022;&#26368;&#23567;&#21270;&#26041;&#38754;&#19982;&#29616;&#26377;&#25216;&#26415;&#30456;&#27604;&#20855;&#26377;&#26126;&#26174;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Actor-critic algorithms address the dual goals of reinforcement learning (RL), policy evaluation and improvement, via two separate function approximators. The practicality of this approach comes at the expense of training instability, caused mainly by the destructive effect of the approximation errors of the critic on the actor. We tackle this bottleneck by employing an existing Probably Approximately Correct (PAC) Bayesian bound for the first time as the critic training objective of the Soft Actor-Critic (SAC) algorithm. We further demonstrate that online learning performance improves significantly when a stochastic actor explores multiple futures by critic-guided random search. We observe our resulting algorithm to compare favorably to the state of the art on multiple classical control and locomotion tasks in terms of both sample efficiency and regret minimization.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26368;&#20248;&#20256;&#36755;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22810;&#20010;&#25991;&#26412;&#25552;&#31034;&#26469;&#23454;&#29616;&#38646;&#26679;&#26412;&#20998;&#21106;&#65292;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#27700;&#24179;&#12290;</title><link>http://arxiv.org/abs/2301.12171</link><description>&lt;p&gt;
ZegOT:&#20351;&#29992;&#25991;&#26412;&#25552;&#31034;&#30340;&#26368;&#20248;&#20256;&#36755;&#23454;&#29616;&#38646;&#26679;&#26412;&#20998;&#21106;&#12290;
&lt;/p&gt;
&lt;p&gt;
ZegOT: Zero-shot Segmentation Through Optimal Transport of Text Prompts. (arXiv:2301.12171v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12171
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26368;&#20248;&#20256;&#36755;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22810;&#20010;&#25991;&#26412;&#25552;&#31034;&#26469;&#23454;&#29616;&#38646;&#26679;&#26412;&#20998;&#21106;&#65292;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23558;&#22270;&#20687;&#21644;&#25991;&#26412;&#23545;&#40784;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22823;&#35268;&#27169;&#23545;&#27604;&#24615;&#35821;&#35328;-&#22270;&#20687;&#39044;&#35757;&#32451;&#65288;CLIP&#65289;&#30340;&#25104;&#21151;&#20026;&#38646;&#26679;&#26412;&#35821;&#20041;&#20998;&#21106;&#24102;&#26469;&#20102;&#24456;&#22823;&#30340;&#24076;&#26395;&#65292;&#28982;&#32780;&#29616;&#26377;&#30340;&#26041;&#27861;&#36890;&#24120;&#38656;&#35201;&#39069;&#22806;&#30340;&#22270;&#20687;&#32534;&#30721;&#22120;&#25110;&#23545;CLIP&#27169;&#22359;&#36827;&#34892;&#37325;&#26032;&#35757;&#32451;&#25110;&#24494;&#35843;&#12290;&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;ZegOT&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#20248;&#20256;&#36755;&#23558;&#22810;&#20010;&#25991;&#26412;&#25552;&#31034;&#19982;&#20923;&#32467;&#30340;&#22270;&#20687;&#23884;&#20837;&#21305;&#37197;&#65292;&#20174;&#32780;&#23454;&#29616;&#38646;&#26679;&#26412;&#20998;&#21106;&#12290;&#29305;&#21035;&#26159;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#26032;&#30340;&#22810;&#25552;&#31034;&#26368;&#20248;&#20256;&#36755;&#27714;&#35299;&#22120;&#65288;MPOT&#65289;&#65292;&#35813;&#26041;&#27861;&#20026;&#27599;&#20010;&#25991;&#26412;&#25552;&#31034;&#19982;&#20923;&#32467;&#30340;&#22270;&#20687;&#32534;&#30721;&#22120;&#38544;&#34255;&#23618;&#30340;&#35270;&#35273;&#29305;&#24449;&#26144;&#23556;&#20043;&#38388;&#23398;&#20064;&#20102;&#19968;&#31181;&#26368;&#20248;&#26144;&#23556;&#12290;&#36825;&#31181;&#29420;&#29305;&#30340;&#26144;&#23556;&#26041;&#27861;&#26377;&#25928;&#22320;&#20351;&#27599;&#20010;&#25991;&#26412;&#25552;&#31034;&#20851;&#27880;&#19981;&#21516;&#30340;&#35270;&#35273;&#35821;&#20041;&#23646;&#24615;&#12290;&#36890;&#36807;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#24191;&#27867;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent success of large-scale Contrastive Language-Image Pre-training (CLIP) has led to great promise in zero-shot semantic segmentation by transferring image-text aligned knowledge to pixel-level classification. However, existing methods usually require an additional image encoder or retraining/tuning the CLIP module. Here, we propose a novel Zero-shot segmentation with Optimal Transport (ZegOT) method that matches multiple text prompts with frozen image embeddings through optimal transport. In particular, we introduce a novel Multiple Prompt Optimal Transport Solver (MPOT), which is designed to learn an optimal mapping between multiple text prompts and visual feature maps of the frozen image encoder hidden layers. This unique mapping method facilitates each of the multiple text prompts to effectively focus on distinct visual semantic attributes. Through extensive experiments on benchmark datasets, we show that our method achieves the state-of-the-art (SOTA) performance over existing 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30828;&#24065;&#25237;&#27880;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#23436;&#20840;&#19981;&#38656;&#35201;&#23398;&#20064;&#36895;&#29575;&#65292;&#21487;&#20197;&#22312;&#39640;&#32500;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2301.11294</link><description>&lt;p&gt;
&#22522;&#20110;&#30828;&#24065;&#37319;&#26679;&#30340;&#26080;&#38656;&#23398;&#20064;&#36895;&#29575;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Coin Sampling: Gradient-Based Bayesian Inference without Learning Rates. (arXiv:2301.11294v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11294
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30828;&#24065;&#25237;&#27880;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#23436;&#20840;&#19981;&#38656;&#35201;&#23398;&#20064;&#36895;&#29575;&#65292;&#21487;&#20197;&#22312;&#39640;&#32500;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22522;&#20110;&#31890;&#23376;&#30340;&#21464;&#20998;&#25512;&#26029;&#65288;ParVI&#65289;&#26041;&#27861;&#22914;Stein&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#65288;SVGD&#65289;&#22240;&#21487;&#25193;&#23637;&#24615;&#22312;&#36125;&#21494;&#26031;&#25512;&#29702;&#20013;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#30340;&#24615;&#36136;&#19981;&#21487;&#36991;&#20813;&#22320;&#21462;&#20915;&#20110;&#36229;&#21442;&#25968;&#65288;&#22914;&#23398;&#20064;&#36895;&#29575;&#65289;&#65292;&#24517;&#39035;&#30001;&#20174;&#19994;&#32773;&#20180;&#32454;&#35843;&#25972;&#65292;&#20197;&#30830;&#20445;&#20197;&#21512;&#36866;&#30340;&#36895;&#29575;&#25910;&#25947;&#21040;&#30446;&#26631;&#27979;&#24230;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#32452;&#26032;&#30340;&#22522;&#20110;&#30828;&#24065;&#25237;&#27880;&#30340;&#21487;&#25193;&#23637;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#23436;&#20840;&#19981;&#38656;&#35201;&#23398;&#20064;&#36895;&#29575;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#25968;&#20540;&#20363;&#23376;&#20013;&#28436;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#21253;&#25324;&#20960;&#20010;&#39640;&#32500;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#65292;&#35777;&#26126;&#20102;&#19982;&#20854;&#20182;ParVI&#31639;&#27861;&#30456;&#24403;&#30340;&#24615;&#33021;&#65292;&#32780;&#26080;&#38656;&#35843;&#25972;&#23398;&#20064;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, particle-based variational inference (ParVI) methods such as Stein variational gradient descent (SVGD) have grown in popularity as scalable methods for Bayesian inference. Unfortunately, the properties of such methods invariably depend on hyperparameters such as the learning rate, which must be carefully tuned by the practitioner in order to ensure convergence to the target measure at a suitable rate. In this paper, we introduce a suite of new particle-based methods for scalable Bayesian inference based on coin betting, which are entirely learning-rate free. We illustrate the performance of our approach on a range of numerical examples, including several high-dimensional models and datasets, demonstrating comparable performance to other ParVI algorithms with no need to tune a learning rate.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#26399;&#26395;&#26465;&#20214;&#39118;&#38505;&#24230;&#37327;&#30340;&#39118;&#38505;&#21388;&#24694;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#31574;&#30053;&#26799;&#24230;&#26356;&#26032;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#32422;&#26463;&#21644;&#26080;&#32422;&#26463;&#24773;&#20917;&#19979;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#21644;&#36845;&#20195;&#22797;&#26434;&#24230;&#65292;&#24182;&#27979;&#35797;&#20102;REINFORCE&#21644;actor-critic&#31639;&#27861;&#30340;&#39118;&#38505;&#21388;&#24694;&#21464;&#20307;&#26469;&#23637;&#31034;&#26041;&#27861;&#30340;&#23454;&#29992;&#20215;&#20540;&#21644;&#39118;&#38505;&#25511;&#21046;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2301.10932</link><description>&lt;p&gt;
&#20851;&#20110;&#20855;&#26377;&#26399;&#26395;&#26465;&#20214;&#39118;&#38505;&#24230;&#37327;&#30340;&#39118;&#38505;&#21388;&#24694;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Global Convergence of Risk-Averse Policy Gradient Methods with Expected Conditional Risk Measures. (arXiv:2301.10932v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.10932
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#26399;&#26395;&#26465;&#20214;&#39118;&#38505;&#24230;&#37327;&#30340;&#39118;&#38505;&#21388;&#24694;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#31574;&#30053;&#26799;&#24230;&#26356;&#26032;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#32422;&#26463;&#21644;&#26080;&#32422;&#26463;&#24773;&#20917;&#19979;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#21644;&#36845;&#20195;&#22797;&#26434;&#24230;&#65292;&#24182;&#27979;&#35797;&#20102;REINFORCE&#21644;actor-critic&#31639;&#27861;&#30340;&#39118;&#38505;&#21388;&#24694;&#21464;&#20307;&#26469;&#23637;&#31034;&#26041;&#27861;&#30340;&#23454;&#29992;&#20215;&#20540;&#21644;&#39118;&#38505;&#25511;&#21046;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39118;&#38505;&#25935;&#24863;&#30340;&#24378;&#21270;&#23398;&#20064;&#24050;&#32463;&#25104;&#20026;&#25511;&#21046;&#19981;&#30830;&#23450;&#32467;&#26524;&#21644;&#30830;&#20445;&#21508;&#31181;&#39034;&#24207;&#20915;&#31574;&#38382;&#39064;&#30340;&#21487;&#38752;&#24615;&#33021;&#30340;&#27969;&#34892;&#24037;&#20855;&#12290;&#34429;&#28982;&#38024;&#23545;&#39118;&#38505;&#25935;&#24863;&#30340;&#24378;&#21270;&#23398;&#20064;&#24050;&#32463;&#24320;&#21457;&#20986;&#20102;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#26159;&#21542;&#20855;&#26377;&#19982;&#39118;&#38505;&#20013;&#24615;&#24773;&#20917;&#19979;&#30456;&#21516;&#30340;&#20840;&#23616;&#25910;&#25947;&#20445;&#35777;&#36824;&#19981;&#28165;&#26970;&#12290;&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#31867;&#21160;&#24577;&#26102;&#38388;&#19968;&#33268;&#39118;&#38505;&#24230;&#37327;&#65292;&#31216;&#20026;&#26399;&#26395;&#26465;&#20214;&#39118;&#38505;&#24230;&#37327;&#65288;ECRM&#65289;&#65292;&#24182;&#20026;&#22522;&#20110;ECRM&#30340;&#30446;&#26631;&#20989;&#25968;&#25512;&#23548;&#20986;&#31574;&#30053;&#26799;&#24230;&#26356;&#26032;&#12290;&#22312;&#32422;&#26463;&#30452;&#25509;&#21442;&#25968;&#21270;&#21644;&#26080;&#32422;&#26463;softmax&#21442;&#25968;&#21270;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#30456;&#24212;&#30340;&#39118;&#38505;&#21388;&#24694;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#21644;&#36845;&#20195;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#27979;&#35797;&#20102;REINFORCE&#21644;actor-critic&#31639;&#27861;&#30340;&#39118;&#38505;&#21388;&#24694;&#21464;&#20307;&#65292;&#20197;&#23637;&#31034;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#39118;&#38505;&#25511;&#21046;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Risk-sensitive reinforcement learning (RL) has become a popular tool to control the risk of uncertain outcomes and ensure reliable performance in various sequential decision-making problems. While policy gradient methods have been developed for risk-sensitive RL, it remains unclear if these methods enjoy the same global convergence guarantees as in the risk-neutral case. In this paper, we consider a class of dynamic time-consistent risk measures, called Expected Conditional Risk Measures (ECRMs), and derive policy gradient updates for ECRM-based objective functions. Under both constrained direct parameterization and unconstrained softmax parameterization, we provide global convergence and iteration complexities of the corresponding risk-averse policy gradient algorithms. We further test risk-averse variants of REINFORCE and actor-critic algorithms to demonstrate the efficacy of our method and the importance of risk control.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23398;&#20064;Boltzmann&#23494;&#24230;&#21464;&#24418;&#36712;&#36857;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#36890;&#36807;&#25554;&#20540;&#33021;&#37327;&#20989;&#25968;&#31561;&#23454;&#29616;Boltzmann&#23494;&#24230;&#30340;&#21464;&#24418;&#65292;&#28982;&#21518;&#25214;&#21040;&#19968;&#20010;&#26102;&#38388;&#20381;&#36182;&#21521;&#37327;&#22330;&#65292;&#23558;&#26679;&#26412;&#20174;&#19968;&#20010;&#20998;&#24067;&#36716;&#31227;&#21040;&#21478;&#19968;&#20010;&#20998;&#24067;&#65292;&#20854;&#34920;&#29616;&#22312;&#39640;&#26031;&#28151;&#21512;&#21644;&#37327;&#23376;&#21147;&#23398;&#31890;&#23376;&#30340;Boltzmann&#23494;&#24230;&#19978;&#27604;KL-&#21453;&#25955;&#24230;&#26356;&#20855;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2301.07388</link><description>&lt;p&gt;
&#23398;&#20064;Boltzmann&#23494;&#24230;&#30340;&#21464;&#24418;&#36712;&#36857;
&lt;/p&gt;
&lt;p&gt;
Learning Deformation Trajectories of Boltzmann Densities. (arXiv:2301.07388v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.07388
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23398;&#20064;Boltzmann&#23494;&#24230;&#21464;&#24418;&#36712;&#36857;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#36890;&#36807;&#25554;&#20540;&#33021;&#37327;&#20989;&#25968;&#31561;&#23454;&#29616;Boltzmann&#23494;&#24230;&#30340;&#21464;&#24418;&#65292;&#28982;&#21518;&#25214;&#21040;&#19968;&#20010;&#26102;&#38388;&#20381;&#36182;&#21521;&#37327;&#22330;&#65292;&#23558;&#26679;&#26412;&#20174;&#19968;&#20010;&#20998;&#24067;&#36716;&#31227;&#21040;&#21478;&#19968;&#20010;&#20998;&#24067;&#65292;&#20854;&#34920;&#29616;&#22312;&#39640;&#26031;&#28151;&#21512;&#21644;&#37327;&#23376;&#21147;&#23398;&#31890;&#23376;&#30340;Boltzmann&#23494;&#24230;&#19978;&#27604;KL-&#21453;&#25955;&#24230;&#26356;&#20855;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36830;&#32493;&#26631;&#20934;&#21270;&#27969;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#27809;&#26377;&#26679;&#26412;&#20294;&#23384;&#22312;&#33021;&#37327;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#20351;&#29992;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#33021;&#37327;&#20989;&#25968;$f_1$&#21644;&#24191;&#20041;&#39640;&#26031;&#20989;&#25968;$f_0$&#20043;&#38388;&#30340;&#39044;&#23450;&#25110;&#23398;&#20064;&#25554;&#20540;$f_t$&#12290;&#33021;&#37327;&#20989;&#25968;&#30340;&#25554;&#20540;&#24341;&#36215;Boltzmann&#23494;&#24230;$p_t\propto e^{-f_t}$&#30340;&#25554;&#20540;&#65292;&#25105;&#20204;&#26088;&#22312;&#25214;&#21040;&#19968;&#20010;&#27839;&#30528;&#26063;$p_t$&#30340;&#26102;&#38388;&#20381;&#36182;&#21521;&#37327;&#22330;$V_t$&#65292;&#23558;&#26679;&#26412;&#20174;&#19968;&#20010;&#20998;&#24067;&#36716;&#31227;&#21040;&#21478;&#19968;&#20010;&#20998;&#24067;&#12290;&#23558;&#26679;&#26412;&#27839;&#30528;&#26063;$p_t$&#20174;&#19968;&#20010;&#20998;&#24067;&#36716;&#31227;&#21040;&#21478;&#19968;&#20010;&#20998;&#24067;&#30340;&#26465;&#20214;&#21487;&#20197;&#36716;&#21270;&#20026;$V_t$&#21644;$f_t$&#20043;&#38388;&#30340;PDE&#65292;&#25105;&#20204;&#20248;&#21270;$V_t$&#21644;$f_t$&#20197;&#28385;&#36275;&#27492;PDE&#12290;&#25105;&#20204;&#22312;&#39640;&#26031;&#28151;&#21512;&#21644;&#21452;&#20117;&#21183;&#30340;&#37327;&#23376;&#21147;&#23398;&#31890;&#23376;&#30340;Boltzmann&#23494;&#24230;&#19978;&#23454;&#39564;&#27604;&#36739;&#20102;&#25152;&#25552;&#20986;&#30340;&#35757;&#32451;&#30446;&#26631;&#19982;KL-&#21453;&#25955;&#24230;&#30340;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a training objective for continuous normalizing flows that can be used in the absence of samples but in the presence of an energy function. Our method relies on either a prescribed or a learnt interpolation $f_t$ of energy functions between the target energy $f_1$ and the energy function of a generalized Gaussian $f_0(x) = ||x/\sigma||_p^p$. The interpolation of energy functions induces an interpolation of Boltzmann densities $p_t \propto e^{-f_t}$ and we aim to find a time-dependent vector field $V_t$ that transports samples along the family $p_t$ of densities. The condition of transporting samples along the family $p_t$ can be translated to a PDE between $V_t$ and $f_t$ and we optimize $V_t$ and $f_t$ to satisfy this PDE. We experimentally compare the proposed training objective to the reverse KL-divergence on Gaussian mixtures and on the Boltzmann density of a quantum mechanical particle in a double-well potential.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36866;&#29992;&#20110;&#26102;&#24207;&#25968;&#25454;&#30340;&#33258;&#36866;&#24212;&#37325;&#26032;&#20272;&#35745;&#26465;&#20214;&#20998;&#20301;&#25968;&#30340;&#32622;&#20449;&#39044;&#27979;&#31639;&#27861;SPCI&#65292;&#30456;&#36739;&#20110;&#20854;&#20182;&#29616;&#26377;&#26041;&#27861;&#65292;SPCI&#22312;&#25152;&#38656;&#32463;&#39564;&#35206;&#30422;&#19979;&#30340;&#21306;&#38388;&#23485;&#24230;&#26174;&#33879;&#20943;&#23567;&#12290;</title><link>http://arxiv.org/abs/2212.03463</link><description>&lt;p&gt;
&#26102;&#24207;&#25968;&#25454;&#30340;&#24207;&#21015;&#39044;&#27979;&#32622;&#20449;&#25512;&#26029;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sequential Predictive Conformal Inference for Time Series. (arXiv:2212.03463v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.03463
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36866;&#29992;&#20110;&#26102;&#24207;&#25968;&#25454;&#30340;&#33258;&#36866;&#24212;&#37325;&#26032;&#20272;&#35745;&#26465;&#20214;&#20998;&#20301;&#25968;&#30340;&#32622;&#20449;&#39044;&#27979;&#31639;&#27861;SPCI&#65292;&#30456;&#36739;&#20110;&#20854;&#20182;&#29616;&#26377;&#26041;&#27861;&#65292;SPCI&#22312;&#25152;&#38656;&#32463;&#39564;&#35206;&#30422;&#19979;&#30340;&#21306;&#38388;&#23485;&#24230;&#26174;&#33879;&#20943;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#24067;&#33258;&#30001;&#30340;&#24207;&#21015;&#25968;&#25454;&#65288;&#20363;&#22914;&#26102;&#38388;&#24207;&#21015;&#65289;&#32622;&#20449;&#39044;&#27979;&#31639;&#27861;&#65292;&#31216;&#20026;&#8220;&#24207;&#21015;&#39044;&#27979;&#32622;&#20449;&#25512;&#26029;&#8221;&#65288;SPCI&#65289;&#12290;&#25105;&#20204;&#29305;&#21035;&#32771;&#34385;&#21040;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#26159;&#19981;&#21487;&#20132;&#25442;&#30340;&#24615;&#36136;&#65292;&#22240;&#27492;&#35768;&#22810;&#29616;&#26377;&#30340;&#32622;&#20449;&#39044;&#27979;&#31639;&#27861;&#19981;&#36866;&#29992;&#12290;&#20027;&#35201;&#24605;&#24819;&#26159;&#22312;&#21033;&#29992;&#23427;&#20204;&#20043;&#38388;&#30340;&#26102;&#38388;&#20381;&#36182;&#24615;&#26102;&#65292;&#33258;&#36866;&#24212;&#37325;&#26032;&#20272;&#35745;&#38750;&#19968;&#33268;&#24615;&#20998;&#25968;&#65288;&#20363;&#22914;&#39044;&#27979;&#27531;&#24046;&#65289;&#30340;&#26465;&#20214;&#20998;&#20301;&#25968;&#12290;&#26356;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#23558;&#32622;&#20449;&#39044;&#27979;&#21306;&#38388;&#30340;&#38382;&#39064;&#35270;&#20026;&#39044;&#27979;&#26410;&#26469;&#27531;&#24046;&#30340;&#20998;&#20301;&#25968;&#65292;&#32473;&#23450;&#29992;&#25143;&#25351;&#23450;&#30340;&#28857;&#39044;&#27979;&#31639;&#27861;&#12290;&#20174;&#29702;&#35770;&#19978;&#35762;&#65292;&#22312;&#25193;&#23637;&#20998;&#20301;&#25968;&#22238;&#24402;&#30340;&#19968;&#33268;&#24615;&#20998;&#26512;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#28176;&#36817;&#26377;&#25928;&#30340;&#26465;&#20214;&#35206;&#30422;&#12290;&#36890;&#36807;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;SPCI&#30456;&#23545;&#20110;&#20854;&#20182;&#29616;&#26377;&#26041;&#27861;&#22312;&#25152;&#38656;&#32463;&#39564;&#35206;&#30422;&#19979;&#30340;&#21306;&#38388;&#23485;&#24230;&#26174;&#33879;&#20943;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a new distribution-free conformal prediction algorithm for sequential data (e.g., time series), called the \textit{sequential predictive conformal inference} (\texttt{SPCI}). We specifically account for the nature that time series data are non-exchangeable, and thus many existing conformal prediction algorithms are not applicable. The main idea is to adaptively re-estimate the conditional quantile of non-conformity scores (e.g., prediction residuals), upon exploiting the temporal dependence among them. More precisely, we cast the problem of conformal prediction interval as predicting the quantile of a future residual, given a user-specified point prediction algorithm. Theoretically, we establish asymptotic valid conditional coverage upon extending consistency analyses in quantile regression. Using simulation and real-data experiments, we demonstrate a significant reduction in interval width of \texttt{SPCI} compared to other existing methods under the desired empirical cover
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#22238;&#28335;&#24335;&#21453;&#20107;&#23454;&#25512;&#29702;&#30340;&#24418;&#24335;&#21270;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#22270;&#24418;&#27169;&#22411;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#26356;&#21152;&#33258;&#28982;&#21644;&#30452;&#35266;&#30340;&#25512;&#29702;&#36807;&#21435;&#26102;&#21453;&#20107;&#23454;&#24773;&#26223;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2211.00472</link><description>&lt;p&gt;
&#22238;&#28335;&#24335;&#21453;&#20107;&#23454;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Backtracking Counterfactuals. (arXiv:2211.00472v3 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.00472
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#22238;&#28335;&#24335;&#21453;&#20107;&#23454;&#25512;&#29702;&#30340;&#24418;&#24335;&#21270;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#22270;&#24418;&#27169;&#22411;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#26356;&#21152;&#33258;&#28982;&#21644;&#30452;&#35266;&#30340;&#25512;&#29702;&#36807;&#21435;&#26102;&#21453;&#20107;&#23454;&#24773;&#26223;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#20107;&#23454;&#25512;&#29702;&#26159;&#20154;&#31867;&#24605;&#32500;&#20013;&#24191;&#27867;&#23384;&#22312;&#30340;&#19968;&#31181;&#25512;&#29702;&#26041;&#24335;&#8212;&#8212;&#35774;&#24819;&#19968;&#20123;&#20551;&#35774;&#22330;&#26223;&#25110;&#21487;&#33021;&#23384;&#22312;&#30340;&#24773;&#20917;&#65292;&#36825;&#20123;&#24773;&#20917;&#19982;&#23454;&#38469;&#24773;&#20917;&#19981;&#21516;&#12290;&#20256;&#32479;&#19978;&#65292;&#21453;&#20107;&#23454;&#24773;&#26223;&#34987;&#35270;&#20026;&#23616;&#37096;&#36829;&#21453;&#33258;&#28982;&#35268;&#24459;&#30340;&#8220;&#23567;&#22855;&#36857;&#8221;&#65292;&#20294;&#23427;&#20204;&#20855;&#26377;&#30456;&#21516;&#30340;&#21021;&#22987;&#26465;&#20214;&#12290;&#32780;&#22312;Pearl&#30340;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;(SCM)&#26694;&#26550;&#20013;&#65292;&#36825;&#36890;&#36807;&#20462;&#25913;&#22240;&#26524;&#23450;&#24459;&#30340;&#24178;&#39044;&#32780;&#20351;&#24471;&#22806;&#29983;&#21464;&#37327;&#30340;&#20540;&#20849;&#20139;&#24471;&#21040;&#20102;&#25968;&#23398;&#19978;&#30340;&#20005;&#26684;&#21270;&#12290;&#20294;&#36817;&#24180;&#26469;&#65292;&#21746;&#23398;&#23478;&#21644;&#24515;&#29702;&#23398;&#23478;&#23545;&#36825;&#31181;&#21333;&#32431;&#30340;&#24178;&#39044;&#20027;&#20041;&#21453;&#20107;&#23454;&#35266;&#28857;&#25552;&#20986;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#36136;&#30097;&#12290;&#30456;&#21453;&#65292;&#20182;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22238;&#28335;&#24335;&#21453;&#20107;&#23454;&#35266;&#28857;&#65292;&#21363;&#22312;&#21453;&#20107;&#23454;&#19990;&#30028;&#20013;&#22240;&#26524;&#23450;&#24459;&#20445;&#25345;&#19981;&#21464;&#65292;&#23558;&#19982;&#23454;&#38469;&#24773;&#20917;&#30340;&#24046;&#24322;&#8220;&#22238;&#28335;&#8221;&#21040;&#25913;&#21464;&#30340;&#21021;&#22987;&#26465;&#20214;(&#22806;&#29983;&#21464;&#37327;)&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31616;&#21333;&#20294;&#28789;&#27963;&#30340;&#22270;&#24418;&#27169;&#22411;&#30340;&#22238;&#28335;&#24335;&#21453;&#20107;&#23454;&#25512;&#29702;&#30340;&#24418;&#24335;&#21270;&#26041;&#27861;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#29305;&#21035;&#26159;&#22312;&#25512;&#29702;&#36807;&#21435;&#26102;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#25552;&#20379;&#20102;&#19968;&#31181;&#26356;&#33258;&#28982;&#12289;&#26356;&#30452;&#35266;&#30340;&#21453;&#20107;&#23454;&#25512;&#29702;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counterfactual reasoning -- envisioning hypothetical scenarios, or possible worlds, where some circumstances are different from what (f)actually occurred (counter-to-fact) -- is ubiquitous in human cognition. Conventionally, counterfactually-altered circumstances have been treated as "small miracles" that locally violate the laws of nature while sharing the same initial conditions. In Pearl's structural causal model (SCM) framework this is made mathematically rigorous via interventions that modify the causal laws while the values of exogenous variables are shared. In recent years, however, this purely interventionist account of counterfactuals has increasingly come under scrutiny from both philosophers and psychologists. Instead, they suggest a backtracking account of counterfactuals, according to which the causal laws remain unchanged in the counterfactual world; differences to the factual world are instead "backtracked" to altered initial conditions (exogenous variables). In the pres
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#39044;&#35774;&#26041;&#27861;&#65292;&#20197;&#36873;&#25321;&#22312;&#38543;&#26426;&#35797;&#39564;&#20013;&#35843;&#25972;&#21738;&#20123;&#21464;&#37327;&#65292;&#20197;&#21450;&#20197;&#20309;&#31181;&#24418;&#24335;&#36827;&#34892;&#35843;&#25972;&#65292;&#20174;&#32780;&#26368;&#22823;&#21270;&#31934;&#24230;&#65292;&#21516;&#26102;&#20445;&#25345;&#8544;&#31867;&#38169;&#35823;&#25511;&#21046;&#12290;</title><link>http://arxiv.org/abs/2210.17453</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#36873;&#25321;&#26368;&#20248;&#31574;&#30053;&#20197;&#25552;&#39640;&#38543;&#26426;&#35797;&#39564;&#30340;&#31934;&#24230;&#21644;&#21151;&#25928;
&lt;/p&gt;
&lt;p&gt;
Adaptive Selection of the Optimal Strategy to Improve Precision and Power in Randomized Trials. (arXiv:2210.17453v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.17453
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#39044;&#35774;&#26041;&#27861;&#65292;&#20197;&#36873;&#25321;&#22312;&#38543;&#26426;&#35797;&#39564;&#20013;&#35843;&#25972;&#21738;&#20123;&#21464;&#37327;&#65292;&#20197;&#21450;&#20197;&#20309;&#31181;&#24418;&#24335;&#36827;&#34892;&#35843;&#25972;&#65292;&#20174;&#32780;&#26368;&#22823;&#21270;&#31934;&#24230;&#65292;&#21516;&#26102;&#20445;&#25345;&#8544;&#31867;&#38169;&#35823;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Benkeser&#31561;&#20154;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#38543;&#26426;&#35797;&#39564;&#20013;&#35843;&#25972;&#22522;&#32447;&#21327;&#21464;&#37327;&#65292;&#20174;&#32780;&#26377;&#24847;&#20041;&#22320;&#25552;&#39640;&#21508;&#31181;&#32467;&#26524;&#31867;&#22411;&#30340;&#31934;&#24230;&#12290;&#20182;&#20204;&#30340;&#30740;&#31350;&#24314;&#31435;&#22312;&#24456;&#38271;&#26102;&#38388;&#30340;&#21382;&#21490;&#22522;&#30784;&#19978;&#65292;&#22987;&#20110;1932&#24180;&#30340;R.A. Fisher&#65292;&#21253;&#25324;&#32654;&#22269;&#39135;&#21697;&#21644;&#33647;&#29289;&#31649;&#29702;&#23616;&#20197;&#21450;&#27431;&#27954;&#33647;&#21697;&#31649;&#29702;&#23616;&#26368;&#36817;&#30340;&#35748;&#21487;&#12290;&#26412;&#25991;&#30528;&#37325;&#25506;&#35752;&#20102;&#19968;&#20010;&#37325;&#35201;&#30340;&#23454;&#38469;&#38382;&#39064;&#65306;&#22914;&#20309;&#36873;&#25321;&#35843;&#25972;&#26041;&#27861;&#65292;&#21363;&#21738;&#20123;&#21464;&#37327;&#20197;&#21450;&#20197;&#20309;&#31181;&#24418;&#24335;&#65292;&#20197;&#26368;&#22823;&#21270;&#31934;&#24230;&#65292;&#21516;&#26102;&#20445;&#25345;&#8544;&#31867;&#38169;&#35823;&#25511;&#21046;&#12290;Balzer&#31561;&#20154;&#20197;&#21069;&#25552;&#20986;&#20102;&#22312;TMLE&#20013;&#30340;&#33258;&#36866;&#24212;&#39044;&#35774;&#27861;&#65292;&#20197;&#28789;&#27963;&#33258;&#21160;&#22320;&#20174;&#39044;&#20808;&#35268;&#23450;&#30340;&#38598;&#21512;&#20013;&#36873;&#25321;&#22312;&#23567;&#22411;&#35797;&#39564;&#65288;N &lt; 40&#65289;&#20013;&#26368;&#22823;&#21270;&#32463;&#39564;&#25928;&#29575;&#30340;&#26041;&#27861;&#12290;&#20026;&#20102;&#36991;&#20813;&#22312;&#23569;&#25968;&#38543;&#26426;&#21333;&#20301;&#20013;&#36807;&#24230;&#25311;&#21512;&#65292;&#20043;&#21069;&#30340;&#36873;&#25321;&#20165;&#38480;&#20110;&#24037;&#20316;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65292;&#35843;&#25972;&#21333;&#20010;&#21327;&#21464;&#37327;&#12290;&#29616;&#22312;&#65292;&#25105;&#20204;&#23558;&#33258;&#36866;&#24212;&#39044;&#35774;&#27861;&#38024;&#23545;&#20855;&#26377;&#35768;&#22810;&#38543;&#26426;&#21333;&#20803;&#30340;&#35797;&#39564;&#36827;&#34892;&#20102;&#35843;&#25972;&#12290;&#20351;&#29992;V-fold
&lt;/p&gt;
&lt;p&gt;
Benkeser et al. demonstrate how adjustment for baseline covariates in randomized trials can meaningfully improve precision for a variety of outcome types. Their findings build on a long history, starting in 1932 with R.A. Fisher and including more recent endorsements by the U.S. Food and Drug Administration and the European Medicines Agency. Here, we address an important practical consideration: *how* to select the adjustment approach -- which variables and in which form -- to maximize precision, while maintaining Type-I error control. Balzer et al. previously proposed *Adaptive Prespecification* within TMLE to flexibly and automatically select, from a prespecified set, the approach that maximizes empirical efficiency in small trials (N$&lt;$40). To avoid overfitting with few randomized units, selection was previously limited to working generalized linear models, adjusting for a single covariate. Now, we tailor Adaptive Prespecification to trials with many randomized units. Using $V$-fold
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31216;&#20026;&#30495;&#23454;&#35299;&#37322;&#30340;&#26032;&#27010;&#24565;&#65292;&#36890;&#36807;&#20613;&#31435;&#21494;&#20998;&#26512;&#33719;&#24471;&#20005;&#26684;&#20445;&#35777;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#20854;&#22312;&#25903;&#25345;&#20551;&#35774;&#24773;&#26223;&#21644;&#38477;&#20302;&#35299;&#37322;&#35823;&#24046;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2210.17426</link><description>&lt;p&gt;
&#20613;&#31435;&#21494;&#20998;&#26512;&#23454;&#29616;&#19968;&#33268;&#19988;&#30495;&#23454;&#30340;&#27169;&#22411;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Consistent and Truthful Interpretation with Fourier Analysis. (arXiv:2210.17426v1 [cs.LG] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.17426
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31216;&#20026;&#30495;&#23454;&#35299;&#37322;&#30340;&#26032;&#27010;&#24565;&#65292;&#36890;&#36807;&#20613;&#31435;&#21494;&#20998;&#26512;&#33719;&#24471;&#20005;&#26684;&#20445;&#35777;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#20854;&#22312;&#25903;&#25345;&#20551;&#35774;&#24773;&#26223;&#21644;&#38477;&#20302;&#35299;&#37322;&#35823;&#24046;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#35768;&#22810;&#36328;&#23398;&#31185;&#39046;&#22495;&#65292;&#26426;&#22120;&#23398;&#20064;&#30340;&#35299;&#37322;&#38656;&#35201;&#19982;&#24403;&#21069;&#26696;&#20363;&#30456;&#20851;&#30340;&#20551;&#35774;&#24773;&#26223;&#19968;&#33268;&#65292;&#21363;&#22914;&#26524;&#19968;&#20010;&#22240;&#32032;&#25913;&#21464;&#65292;&#27169;&#22411;&#20250;&#22914;&#20309;&#21453;&#24212;&#65311;&#23613;&#31649;&#24402;&#22240;&#26041;&#27861;&#30001;&#20248;&#38597;&#30340;&#20844;&#29702;&#31995;&#32479;&#25903;&#25345;&#65292;&#20294;&#23427;&#20204;&#20027;&#35201;&#20851;&#27880;&#21333;&#20010;&#36755;&#20837;&#65292;&#24182;&#19988;&#36890;&#24120;&#19981;&#19968;&#33268;&#12290;&#20026;&#25903;&#25345;&#20551;&#35774;&#24773;&#26223;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#31216;&#20026;&#30495;&#23454;&#35299;&#37322;&#30340;&#26032;&#27010;&#24565;&#65292;&#24182;&#24212;&#29992;&#24067;&#23572;&#20989;&#25968;&#30340;&#20613;&#31435;&#21494;&#20998;&#26512;&#26469;&#33719;&#24471;&#20005;&#26684;&#30340;&#20445;&#35777;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#23545;&#20110;&#21508;&#31181;&#21322;&#24452;&#30340;&#37051;&#22495;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#27604;&#65292;&#21487;&#20197;&#23454;&#29616;2&#20493;&#33267;50&#20493;&#26356;&#20302;&#30340;&#35299;&#37322;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
For many interdisciplinary fields, ML interpretations need to be consistent with what-if scenarios related to the current case, i.e., if one factor changes, how does the model react? Although the attribution methods are supported by the elegant axiomatic systems, they mainly focus on individual inputs, and are generally inconsistent. To support what-if scenarios, we introduce a new notion called truthful interpretation, and apply Fourier analysis of Boolean functions to get rigorous guarantees. Experimental results show that for neighborhoods with various radii, our method achieves 2x - 50x lower interpretation error compared with the other methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#36880;&#27493;&#35745;&#31639;&#26816;&#27979;&#32479;&#35745;&#37327;&#30340;&#32047;&#31215;&#21644;&#26469;&#26816;&#27979;&#21464;&#28857;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#21644;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2210.17312</link><description>&lt;p&gt;
&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#26102;&#24207;&#21464;&#28857;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Training Neural Networks for Sequential Change-point Detection. (arXiv:2210.17312v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.17312
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#36880;&#27493;&#35745;&#31639;&#26816;&#27979;&#32479;&#35745;&#37327;&#30340;&#32047;&#31215;&#21644;&#26469;&#26816;&#27979;&#21464;&#28857;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#21644;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#27979;&#25968;&#25454;&#27969;&#20013;&#30340;&#31361;&#21464;&#20998;&#24067;&#36716;&#25442;&#65292;&#21363;&#25152;&#35859;&#30340;&#21464;&#28857;&#26816;&#27979;&#65292;&#26159;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26469;&#36880;&#27493;&#35745;&#31639;&#26816;&#27979;&#32479;&#35745;&#37327;&#30340;&#32047;&#31215;&#21644;&#65292;&#24403;&#21457;&#29983;&#21464;&#28857;&#26102;&#65292;&#35813;&#37327;&#20250;&#26174;&#33879;&#21464;&#21270;&#12290;&#25105;&#20204;&#20351;&#29992;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#26816;&#27979;&#21464;&#28857;&#26041;&#38754;&#30340;&#20248;&#36234;&#24615;&#21644;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Detecting an abrupt distributional shift of a data stream, known as change-point detection, is a fundamental problem in statistics and machine learning. We introduce a novel approach for online change-point detection using neural networks. To be specific, our approach is training neural networks to compute the cumulative sum of a detection statistic sequentially, which exhibits a significant change when a change-point occurs. We demonstrated the superiority and potential of the proposed method in detecting change-point using both synthetic and real-world data.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#21452;&#25511;&#21046;&#21464;&#37327;&#26041;&#27861;&#65292;&#33021;&#22815;&#21516;&#26102;&#20943;&#23569;&#25968;&#25454;&#23376;&#25277;&#26679;&#21644;&#33945;&#29305;&#21345;&#32599;&#25277;&#26679;&#24102;&#26469;&#30340;&#26799;&#24230;&#20272;&#35745;&#26041;&#24046;&#65292;&#25552;&#39640;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2210.07290</link><description>&lt;p&gt;
&#21452;&#25511;&#21046;&#21464;&#37327;&#21152;&#36895;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Dual control variate for faster black-box variational inference. (arXiv:2210.07290v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.07290
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#21452;&#25511;&#21046;&#21464;&#37327;&#26041;&#27861;&#65292;&#33021;&#22815;&#21516;&#26102;&#20943;&#23569;&#25968;&#25454;&#23376;&#25277;&#26679;&#21644;&#33945;&#29305;&#21345;&#32599;&#25277;&#26679;&#24102;&#26469;&#30340;&#26799;&#24230;&#20272;&#35745;&#26041;&#24046;&#65292;&#25552;&#39640;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#36125;&#21494;&#26031;&#21518;&#39564;&#25512;&#26029;&#26694;&#26550;&#65292;&#20294;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#26799;&#24230;&#20272;&#35745;&#20013;&#30340;&#39640;&#26041;&#24046;&#20250;&#25439;&#23475;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#12290;&#36825;&#31181;&#26041;&#24046;&#26469;&#33258;&#20004;&#20010;&#38543;&#26426;&#28304;&#65306;&#25968;&#25454;&#23376;&#25277;&#26679;&#21644;&#33945;&#29305;&#21345;&#32599;&#25277;&#26679;&#12290;&#29616;&#26377;&#30340;&#25511;&#21046;&#21464;&#37327;&#20165;&#35299;&#20915;&#33945;&#29305;&#21345;&#32599;&#22122;&#22768;&#65292;&#32780;&#22686;&#37327;&#26799;&#24230;&#26041;&#27861;&#36890;&#24120;&#20165;&#35299;&#20915;&#25968;&#25454;&#23376;&#25277;&#26679;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#8220;&#21452;&#8221;&#25511;&#21046;&#21464;&#37327;&#65292;&#33021;&#22815;&#21516;&#26102;&#20943;&#23569;&#20004;&#31181;&#22122;&#22768;&#28304;&#30340;&#26041;&#24046;&#12290;&#25105;&#20204;&#30830;&#35748;&#36825;&#23548;&#33268;&#20102;&#20943;&#23569;&#26041;&#24046;&#21644;&#22312;&#22810;&#20010;&#29616;&#23454;&#19990;&#30028;&#24212;&#29992;&#20013;&#25552;&#39640;&#20248;&#21270;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Black-box variational inference is a widely-used framework for Bayesian posterior inference, but in some cases suffers from high variance in gradient estimates, harming accuracy and efficiency. This variance comes from two sources of randomness: Data subsampling and Monte Carlo sampling. Whereas existing control variates only address Monte Carlo noise and incremental gradient methods typically only address data subsampling, we propose a new "dual" control variate capable of jointly reducing variance from both sources of noise. We confirm that this leads to reduced variance and improved optimization in several real-world applications.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;InfoOT&#65292;&#23427;&#26159;&#19968;&#31181;&#20449;&#24687;&#35770;&#25193;&#23637;&#30340;&#26368;&#20248;&#36755;&#36816;&#26041;&#27861;&#65292;&#33021;&#22815;&#35299;&#20915;&#26368;&#20248;&#36755;&#36816;&#24573;&#30053;&#20102;&#25968;&#25454;&#20013;&#30456;&#24178;&#32467;&#26500;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#33021;&#22815;&#22788;&#29702;&#31163;&#32676;&#20540;&#21644;&#38598;&#25104;&#26032;&#25968;&#25454;&#28857;&#65292;&#21487;&#20197;&#25552;&#39640;&#22495;&#33258;&#36866;&#24212;&#12289;&#36328;&#22495;&#26816;&#32034;&#21644;&#21333;&#32454;&#32990;&#23545;&#40784;&#31561;&#20219;&#21153;&#30340;&#23545;&#40784;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2210.03164</link><description>&lt;p&gt;
InfoOT: &#20449;&#24687;&#26368;&#22823;&#21270;&#30340;&#26368;&#20248;&#36755;&#36816;
&lt;/p&gt;
&lt;p&gt;
InfoOT: Information Maximizing Optimal Transport. (arXiv:2210.03164v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.03164
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;InfoOT&#65292;&#23427;&#26159;&#19968;&#31181;&#20449;&#24687;&#35770;&#25193;&#23637;&#30340;&#26368;&#20248;&#36755;&#36816;&#26041;&#27861;&#65292;&#33021;&#22815;&#35299;&#20915;&#26368;&#20248;&#36755;&#36816;&#24573;&#30053;&#20102;&#25968;&#25454;&#20013;&#30456;&#24178;&#32467;&#26500;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#33021;&#22815;&#22788;&#29702;&#31163;&#32676;&#20540;&#21644;&#38598;&#25104;&#26032;&#25968;&#25454;&#28857;&#65292;&#21487;&#20197;&#25552;&#39640;&#22495;&#33258;&#36866;&#24212;&#12289;&#36328;&#22495;&#26816;&#32034;&#21644;&#21333;&#32454;&#32990;&#23545;&#40784;&#31561;&#20219;&#21153;&#30340;&#23545;&#40784;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20248;&#36755;&#36816;&#36890;&#36807;&#26368;&#23567;&#21270;&#23427;&#20204;&#20043;&#38388;&#30340;&#36816;&#36755;&#25104;&#26412;&#65288;&#20363;&#22914;&#20960;&#20309;&#36317;&#31163;&#65289;&#23545;&#20998;&#24067;&#20013;&#30340;&#26679;&#26412;&#36827;&#34892;&#23545;&#40784;&#12290;&#28982;&#32780;&#65292;&#23427;&#24573;&#30053;&#20102;&#25968;&#25454;&#20013;&#30340;&#30456;&#24178;&#32467;&#26500;&#65292;&#20363;&#22914;&#31751;&#65292;&#19981;&#33021;&#24456;&#22909;&#22320;&#22788;&#29702;&#31163;&#32676;&#20540;&#65292;&#20063;&#19981;&#33021;&#38598;&#25104;&#26032;&#25968;&#25454;&#28857;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;InfoOT&#65292;&#23427;&#26159;&#26368;&#20248;&#36755;&#36816;&#30340;&#20449;&#24687;&#35770;&#25193;&#23637;&#65292;&#21487;&#20197;&#22312;&#26368;&#23567;&#21270;&#20960;&#20309;&#36317;&#31163;&#30340;&#21516;&#26102;&#26368;&#22823;&#21270;&#22495;&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#12290;&#26368;&#32456;&#30340;&#30446;&#26631;&#20173;&#28982;&#21487;&#20197;&#34987;&#20844;&#24335;&#21270;&#20026;&#65288;&#24191;&#20041;&#30340;&#65289;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#65292;&#24182;&#21487;&#20197;&#36890;&#36807;&#25237;&#24433;&#26799;&#24230;&#19979;&#38477;&#26377;&#25928;&#22320;&#27714;&#35299;&#12290;&#36825;&#31181;&#20844;&#24335;&#21270;&#20135;&#29983;&#20102;&#19968;&#31181;&#26032;&#30340;&#25237;&#24433;&#26041;&#27861;&#65292;&#23427;&#23545;&#31163;&#32676;&#20540;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#24182;&#19988;&#21487;&#20197;&#25512;&#24191;&#21040;&#26410;&#35265;&#36807;&#30340;&#26679;&#26412;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#22495;&#33258;&#36866;&#24212;&#12289;&#36328;&#22495;&#26816;&#32034;&#21644;&#21333;&#32454;&#32990;&#23545;&#40784;&#31561;&#22522;&#20934;&#20013;&#65292;InfoOT&#21487;&#20197;&#25552;&#39640;&#23545;&#40784;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Optimal transport aligns samples across distributions by minimizing the transportation cost between them, e.g., the geometric distances. Yet, it ignores coherence structure in the data such as clusters, does not handle outliers well, and cannot integrate new data points. To address these drawbacks, we propose InfoOT, an information-theoretic extension of optimal transport that maximizes the mutual information between domains while minimizing geometric distances. The resulting objective can still be formulated as a (generalized) optimal transport problem, and can be efficiently solved by projected gradient descent. This formulation yields a new projection method that is robust to outliers and generalizes to unseen samples. Empirically, InfoOT improves the quality of alignments across benchmarks in domain adaptation, cross-domain retrieval, and single-cell alignment.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32771;&#34385;&#25968;&#25454;&#28857;&#20381;&#36182;&#20851;&#31995;&#30340;&#24402;&#19968;&#21270;&#27969;&#20284;&#28982;&#30446;&#26631;&#21644;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#23454;&#29616;&#26356;&#22909;&#30340;&#32463;&#39564;&#32467;&#26524;&#21644;&#26356;&#39640;&#30340;&#32479;&#35745;&#21151;&#25928;&#12290;</title><link>http://arxiv.org/abs/2209.14933</link><description>&lt;p&gt;
&#20174;&#30456;&#20851;&#25968;&#25454;&#20013;&#35757;&#32451;&#24402;&#19968;&#21270;&#27969;
&lt;/p&gt;
&lt;p&gt;
Training Normalizing Flows from Dependent Data. (arXiv:2209.14933v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.14933
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32771;&#34385;&#25968;&#25454;&#28857;&#20381;&#36182;&#20851;&#31995;&#30340;&#24402;&#19968;&#21270;&#27969;&#20284;&#28982;&#30446;&#26631;&#21644;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#23454;&#29616;&#26356;&#22909;&#30340;&#32463;&#39564;&#32467;&#26524;&#21644;&#26356;&#39640;&#30340;&#32479;&#35745;&#21151;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24402;&#19968;&#21270;&#27969;&#26159;&#19968;&#31181;&#21151;&#33021;&#24378;&#22823;&#30340;&#38750;&#21442;&#25968;&#32479;&#35745;&#27169;&#22411;&#65292;&#23427;&#26159;&#23494;&#24230;&#20272;&#35745;&#22120;&#21644;&#29983;&#25104;&#27169;&#22411;&#20043;&#38388;&#30340;&#28151;&#21512;&#20307;&#12290;&#30446;&#21069;&#30340;&#24402;&#19968;&#21270;&#27969;&#23398;&#20064;&#31639;&#27861;&#20551;&#23450;&#25968;&#25454;&#28857;&#26159;&#29420;&#31435;&#37319;&#26679;&#30340;&#65292;&#36825;&#19968;&#20551;&#35774;&#22312;&#23454;&#36341;&#20013;&#32463;&#24120;&#34987;&#36829;&#21453;&#65292;&#21487;&#33021;&#23548;&#33268;&#23494;&#24230;&#20272;&#35745;&#21644;&#25968;&#25454;&#29983;&#25104;&#30340;&#38169;&#35823;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32771;&#34385;&#25968;&#25454;&#28857;&#20043;&#38388;&#20381;&#36182;&#20851;&#31995;&#30340;&#24402;&#19968;&#21270;&#27969;&#20284;&#28982;&#30446;&#26631;&#65292;&#24182;&#20026;&#27492;&#25512;&#23548;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#19981;&#21516;&#20381;&#36182;&#32467;&#26500;&#30340;&#28789;&#27963;&#39640;&#25928;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#23562;&#37325;&#35266;&#23519;&#20540;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#21487;&#20197;&#25913;&#21892;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#30340;&#32463;&#39564;&#32467;&#26524;&#65292;&#24182;&#22312;&#23545;&#20840;&#22522;&#22240;&#32452;&#20851;&#32852;&#30740;&#31350;&#30340;&#19979;&#28216;&#24212;&#29992;&#20013;&#23548;&#33268;&#26356;&#39640;&#30340;&#32479;&#35745;&#21151;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
Normalizing flows are powerful non-parametric statistical models that function as a hybrid between density estimators and generative models. Current learning algorithms for normalizing flows assume that data points are sampled independently, an assumption that is frequently violated in practice, which may lead to erroneous density estimation and data generation. We propose a likelihood objective of normalizing flows incorporating dependencies between the data points, for which we derive a flexible and efficient learning algorithm suitable for different dependency structures. We show that respecting dependencies between observations can improve empirical results on both synthetic and real-world data, and leads to higher statistical power in a downstream application to genome-wide association studies.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;GNN&#22312;&#33410;&#28857;&#20998;&#31867;&#20013;&#25554;&#20540;&#24102;&#38480;&#20989;&#25968;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;GNN&#32467;&#26500;&#20197;&#30456;&#21516;&#30340;&#31934;&#24230;&#25554;&#20540;&#24102;&#38480;&#20989;&#25968;&#25152;&#38656;&#30340;&#26435;&#37325;&#27604;&#20351;&#29992;&#23436;&#20840;&#36830;&#25509;&#30340;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#23569;&#24471;&#22810;&#12290;</title><link>http://arxiv.org/abs/2206.05904</link><description>&lt;p&gt;
GNN&#22312;&#25512;&#24191;&#24102;&#38480;&#20989;&#25968;&#26041;&#38754;&#30340;&#20248;&#36234;&#24615;&#27604;NN&#26356;&#21152;&#26126;&#26174;
&lt;/p&gt;
&lt;p&gt;
Superiority of GNN over NN in generalizing bandlimited functions. (arXiv:2206.05904v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.05904
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;GNN&#22312;&#33410;&#28857;&#20998;&#31867;&#20013;&#25554;&#20540;&#24102;&#38480;&#20989;&#25968;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;GNN&#32467;&#26500;&#20197;&#30456;&#21516;&#30340;&#31934;&#24230;&#25554;&#20540;&#24102;&#38480;&#20989;&#25968;&#25152;&#38656;&#30340;&#26435;&#37325;&#27604;&#20351;&#29992;&#23436;&#20840;&#36830;&#25509;&#30340;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#23569;&#24471;&#22810;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#20197;&#20854;&#25972;&#21512;&#22270;&#24418;&#20449;&#24687;&#30340;&#33021;&#21147;&#34987;&#24191;&#27867;&#29992;&#20110;&#25968;&#25454;&#20998;&#26512;&#12290;&#28982;&#32780;&#65292;GNN&#30340;&#34920;&#36798;&#33021;&#21147;&#20165;&#38024;&#23545;&#22270;&#32423;&#20219;&#21153;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#32780;&#19981;&#26159;&#38024;&#23545;&#33410;&#28857;&#32423;&#20219;&#21153;&#65292;&#20363;&#22914;&#33410;&#28857;&#20998;&#31867;&#65292;&#20854;&#20013;&#35797;&#22270;&#20174;&#35266;&#23519;&#21040;&#30340;&#33410;&#28857;&#26631;&#31614;&#20013;&#25554;&#20540;&#20986;&#32570;&#22833;&#30340;&#26631;&#31614;&#20449;&#24687;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;GNN&#22312;&#25152;&#36848;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#23427;&#23454;&#36136;&#19978;&#26159;&#19968;&#20010;&#20989;&#25968;&#25554;&#20540;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;GNN&#25554;&#20540;$\mathbb{R}^d$&#20013;&#24102;&#38480;&#20989;&#25968;&#25152;&#38656;&#30340;&#26435;&#37325;&#21644;&#23618;&#25968;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;&#65292;&#20351;&#29992;GNN&#26550;&#26500;&#20197;$\epsilon$-&#36817;&#20284;&#31163;&#25955;&#24102;&#38480;&#20449;&#21495;&#20165;&#38656;&#35201;$O((\log \epsilon^{-1})^{d})$&#20010;&#26435;&#37325;&#65292;&#36825;&#27604;&#20351;&#29992;&#23436;&#20840;&#36830;&#25509;&#30340;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#24471;&#21040;&#30340;&#26368;&#20339;&#32467;&#26524;&#30340;&#25152;&#38656;&#26435;&#37325;&#23569;&#24471;&#22810; - &#29305;&#21035;&#22320;&#65292;&#20351;&#29992;&#20351;&#29992;$O((\log \epsilon^{-1})^{d})$&#20010;&#26679;&#26412;&#26469;&#35757;&#32451;GNN&#20197;$\epsilon$-&#36924;&#36817;&#24102;&#38480;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Network (GNN) with its ability to integrate graph information has been widely used for data analyses. However, the expressive power of GNN has only been studied for graph-level tasks but not for node-level tasks, such as node classification, where one tries to interpolate missing nodal labels from the observed ones. In this paper, we study the expressive power of GNN for the said classification task, which is in essence a function interpolation problem. Explicitly, we derive the number of weights and layers needed for a GNN to interpolate a band-limited function in $\mathbb{R}^d$. Our result shows that, the number of weights needed to $\epsilon$-approximate a bandlimited function using the GNN architecture is much fewer than the best known one using a fully connected neural network (NN) - in particular, one only needs $O((\log \epsilon^{-1})^{d})$ weights using a GNN trained by $O((\log \epsilon^{-1})^{d})$ samples to $\epsilon$-approximate a discretized bandlimited signal
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;Doob h&#21464;&#25442;&#30340;&#35745;&#31639;&#26694;&#26550;&#65292;&#29992;&#20110;&#31163;&#25955;&#35266;&#27979;&#38750;&#32447;&#24615;&#25193;&#25955;&#36807;&#31243;&#30340;&#22312;&#32447;&#28388;&#27874;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#39640;&#24230;&#20449;&#24687;&#21270;&#12289;&#35266;&#27979;&#20540;&#22312;&#27169;&#22411;&#19979;&#26497;&#31471;&#25110;&#29366;&#24577;&#32500;&#25968;&#36739;&#22823;&#26102;&#27604;&#26368;&#20808;&#36827;&#30340;&#31890;&#23376;&#28388;&#27874;&#22120;&#39640;&#20960;&#20010;&#25968;&#37327;&#32423;&#30340;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2206.03369</link><description>&lt;p&gt;
&#31163;&#25955;&#35266;&#27979;&#25193;&#25955;&#36807;&#31243;&#30340;&#35745;&#31639;Doob h&#21464;&#25442;&#22312;&#32447;&#28388;&#27874;
&lt;/p&gt;
&lt;p&gt;
Computational Doob's h-transforms for Online Filtering of Discretely Observed Diffusions. (arXiv:2206.03369v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.03369
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;Doob h&#21464;&#25442;&#30340;&#35745;&#31639;&#26694;&#26550;&#65292;&#29992;&#20110;&#31163;&#25955;&#35266;&#27979;&#38750;&#32447;&#24615;&#25193;&#25955;&#36807;&#31243;&#30340;&#22312;&#32447;&#28388;&#27874;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#39640;&#24230;&#20449;&#24687;&#21270;&#12289;&#35266;&#27979;&#20540;&#22312;&#27169;&#22411;&#19979;&#26497;&#31471;&#25110;&#29366;&#24577;&#32500;&#25968;&#36739;&#22823;&#26102;&#27604;&#26368;&#20808;&#36827;&#30340;&#31890;&#23376;&#28388;&#27874;&#22120;&#39640;&#20960;&#20010;&#25968;&#37327;&#32423;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#30340;&#26159;&#31163;&#25955;&#35266;&#27979;&#38750;&#32447;&#24615;&#25193;&#25955;&#36807;&#31243;&#30340;&#22312;&#32447;&#28388;&#27874;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#23436;&#20840;&#36866;&#24212;&#30340;&#36741;&#21161;&#31890;&#23376;&#28388;&#27874;&#22120;&#65292;&#20854;&#20013;&#21253;&#25324;&#36890;&#24120;&#38590;&#20197;&#22788;&#29702;&#30340;Doob h&#21464;&#25442;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#35745;&#31639;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#38750;&#32447;&#24615;Feynman-Kac&#20844;&#24335;&#21644;&#31070;&#32463;&#32593;&#32476;&#27714;&#35299;&#28508;&#22312;&#30340;&#21453;&#21521;Kolmogorov&#26041;&#31243;&#26469;&#36817;&#20284;&#36825;&#20123;h&#21464;&#25442;&#12290;&#35813;&#26041;&#27861;&#20801;&#35768;&#22312;&#25968;&#25454;&#21516;&#21270;&#36807;&#31243;&#20043;&#21069;&#35757;&#32451;&#23616;&#37096;&#26368;&#20248;&#30340;&#31890;&#23376;&#28388;&#27874;&#22120;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#24403;&#35266;&#27979;&#20540;&#39640;&#24230;&#20449;&#24687;&#21270;&#65292;&#35266;&#27979;&#20540;&#22312;&#27169;&#22411;&#19979;&#26497;&#31471;&#65292;&#25110;&#29366;&#24577;&#32500;&#25968;&#36739;&#22823;&#26102;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#27604;&#26368;&#20808;&#36827;&#30340;&#31890;&#23376;&#28388;&#27874;&#22120;&#39640;&#20960;&#20010;&#25968;&#37327;&#32423;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is concerned with online filtering of discretely observed nonlinear diffusion processes. Our approach is based on the fully adapted auxiliary particle filter, which involves Doob's $h$-transforms that are typically intractable. We propose a computational framework to approximate these $h$-transforms by solving the underlying backward Kolmogorov equations using nonlinear Feynman-Kac formulas and neural networks. The methodology allows one to train a locally optimal particle filter prior to the data-assimilation procedure. Numerical experiments illustrate that the proposed approach can be orders of magnitude more efficient than state-of-the-art particle filters in the regime of highly informative observations, when the observations are extreme under the model, or if the state dimension is large.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#33218;&#32769;&#34382;&#26426;&#26694;&#26550;&#65292;&#29992;&#20110;&#39034;&#24207;&#36873;&#25321;TLM&#39044;&#35757;&#32451;&#36229;&#21442;&#25968;&#65292;&#26088;&#22312;&#20197;&#36164;&#28304;&#39640;&#25928;&#30340;&#26041;&#24335;&#20248;&#21270;&#35821;&#35328;&#27169;&#22411;&#24615;&#33021;&#12290;&#24182;&#35774;&#35745;&#20102;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#30340;Thompson&#25277;&#26679;&#65288;GP-TS&#65289;&#31639;&#27861;&#65292;&#21152;&#36895;Pre-training&#36807;&#31243;&#24182;&#38477;&#20302;MLM&#25439;&#22833;&#12290;</title><link>http://arxiv.org/abs/2203.13151</link><description>&lt;p&gt;
&#22810;&#33218;&#32769;&#34382;&#26426;&#29992;&#20110;&#35821;&#35328;&#27169;&#22411;&#39044;&#35757;&#32451;&#30340;&#36164;&#28304;&#39640;&#25928;&#12289;&#22312;&#32447;&#20248;&#21270;&#65306;&#21160;&#24577;&#36974;&#30422;&#30340;&#20351;&#29992;&#26696;&#20363;
&lt;/p&gt;
&lt;p&gt;
Multi-armed bandits for resource efficient, online optimization of language model pre-training: the use case of dynamic masking. (arXiv:2203.13151v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.13151
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#33218;&#32769;&#34382;&#26426;&#26694;&#26550;&#65292;&#29992;&#20110;&#39034;&#24207;&#36873;&#25321;TLM&#39044;&#35757;&#32451;&#36229;&#21442;&#25968;&#65292;&#26088;&#22312;&#20197;&#36164;&#28304;&#39640;&#25928;&#30340;&#26041;&#24335;&#20248;&#21270;&#35821;&#35328;&#27169;&#22411;&#24615;&#33021;&#12290;&#24182;&#35774;&#35745;&#20102;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#30340;Thompson&#25277;&#26679;&#65288;GP-TS&#65289;&#31639;&#27861;&#65292;&#21152;&#36895;Pre-training&#36807;&#31243;&#24182;&#38477;&#20302;MLM&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35774;&#35745;&#24182;&#35780;&#20272;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#20248;&#21270;&#26694;&#26550;&#65292;&#20197;&#36164;&#28304;&#39640;&#25928;&#30340;&#26041;&#24335;&#39044;&#35757;&#32451;&#22522;&#20110;Transformer&#30340;&#35821;&#35328;&#27169;&#22411;&#65288;TLM&#65289;&#12290; TLM&#39044;&#35757;&#32451;&#38656;&#35201;&#39640;&#35745;&#31639;&#36164;&#28304;&#65292;&#24182;&#24341;&#20837;&#35768;&#22810;&#26410;&#35299;&#20915;&#30340;&#35774;&#35745;&#36873;&#25321;&#65292;&#20363;&#22914;&#36873;&#25321;&#20854;&#39044;&#35757;&#32451;&#36229;&#21442;&#25968;&#12290; &#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#33218;&#32769;&#34382;&#26426;&#26694;&#26550;&#65292;&#29992;&#20110;&#39034;&#24207;&#36873;&#25321;TLM&#39044;&#35757;&#32451;&#36229;&#21442;&#25968;&#65292;&#26088;&#22312;&#20197;&#36164;&#28304;&#39640;&#25928;&#30340;&#26041;&#24335;&#20248;&#21270;&#35821;&#35328;&#27169;&#22411;&#24615;&#33021;&#12290; &#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;Thompson&#25277;&#26679;&#31639;&#27861;&#65292;&#29992;&#20110;&#20854;&#39034;&#24207;&#26368;&#23567;&#21270;&#30340;&#24102;&#26377;&#25513;&#30721;&#35821;&#35328;&#27169;&#22411;&#65288;MLM&#65289;&#39044;&#35757;&#32451;&#30446;&#26631;&#30340;&#20195;&#29702;&#39640;&#26031;&#36807;&#31243;&#22870;&#21169;&#27169;&#22411;&#12290; &#25552;&#20986;&#30340;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#30340;Thompson&#25277;&#26679;&#65288;GP-TS&#65289;&#19981;&#26159;&#20351;&#29992;&#22266;&#23450;&#25513;&#30721;&#27010;&#29575;&#36827;&#34892;MLM&#39044;&#35757;&#32451;&#65292;&#32780;&#26159;&#36890;&#36807;&#39034;&#24207;&#36873;&#25321;&#25913;&#21892;&#24615;&#33021;&#30340;&#25513;&#30721;&#36229;&#21442;&#25968;&#26469;&#21152;&#36895;&#39044;&#35757;&#32451;&#12290; &#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;GP-TS&#22914;&#20309;&#39640;&#25928;&#36827;&#34892;&#35821;&#35328;&#27169;&#22411;&#30340;&#39044;&#35757;&#32451;&#65292;&#21363;&#22312;&#23569;&#37327;&#36845;&#20195;&#20013;&#23454;&#29616;&#26356;&#20302;&#30340;MLM&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;
We design and evaluate a Bayesian optimization framework for resource efficient pre-training of Transformer-based language models (TLMs). TLM pre-training requires high computational resources and introduces many unresolved design choices, such as selecting its pre-training hyperparameters. We propose a multi-armed bandit framework for the sequential selection of TLM pre-training hyperparameters, aimed at optimizing language model performance, in a resource efficient manner. We design a Thompson sampling algorithm, with a surrogate Gaussian process reward model of the Masked Language Model (MLM) pre-training objective, for its sequential minimization. Instead of MLM pre-training with fixed masking probabilities, the proposed Gaussian process-based Thompson sampling (GP-TS) accelerates pre-training by sequentially selecting masking hyperparameters that improve performance. We empirically demonstrate how GP-TS pre-trains language models efficiently, i.e., it achieves lower MLM loss in fe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#29992;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#35299;&#20915;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#30340;&#21152;&#36895;&#38543;&#26426;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2203.00813</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#30340;&#21152;&#36895;&#38543;&#26426;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Accelerated Stochastic Algorithm for Solving the Optimal Transport Problem. (arXiv:2203.00813v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.00813
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#29992;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#35299;&#20915;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#30340;&#21152;&#36895;&#38543;&#26426;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21407;&#22987;-&#23545;&#20598;&#21152;&#36895;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#19982;&#26041;&#24046;&#32422;&#20943;&#31639;&#27861;(PDASGD)&#65292;&#29992;&#20110;&#35299;&#20915;&#32447;&#24615;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#12290; PDASGD&#21487;&#24212;&#29992;&#20110;&#35299;&#20915;&#31163;&#25955;&#26368;&#20248;&#36755;&#36816;&#65288;OT&#65289;&#38382;&#39064;&#65292;&#24182;&#20855;&#26377;&#24050;&#30693;&#30340;&#26368;&#20339;&#35745;&#31639;&#22797;&#26434;&#24230;-$\widetilde{\mathcal{O}}(n^2/\epsilon)$&#65292;&#20854;&#20013;$n$&#26159;&#21407;&#23376;&#25968;&#65292;$\epsilon&gt; 0$&#26159;&#31934;&#24230;&#12290; &#26412;&#25991;&#36824;&#35752;&#35770;&#20102;&#20351;&#24471;PDASGD&#20855;&#26377;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#30340;&#26465;&#20214;&#65292;&#26469;&#35299;&#20915;&#32447;&#24615;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#12290; &#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#31639;&#27861;&#22312;&#35299;&#20915;OT&#38382;&#39064;&#26102;&#21487;&#20197;&#23558;&#22797;&#26434;&#24230;&#30340;&#36895;&#29575;&#25552;&#39640;&#20102;$\widetilde{\mathcal{O}}(\sqrt{n})$&#12290;
&lt;/p&gt;
&lt;p&gt;
A primal-dual accelerated stochastic gradient descent with variance reduction algorithm (PDASGD) is proposed to solve linear-constrained optimization problems. PDASGD could be applied to solve the discrete optimal transport (OT) problem and enjoys the best-known computational complexity -$\widetilde{\mathcal{O}}(n^2/\epsilon)$, where $n$ is the number of atoms, and $\epsilon&gt;0$ is the accuracy. In the literature, some primal-dual accelerated first-order algorithms, e.g., APDAGD, have been proposed and have the order of $\widetilde{\mathcal{O}}(n^{2.5}/\epsilon)$ for solving the OT problem. To understand why our proposed algorithm could improve the rate by a factor of $\widetilde{\mathcal{O}}(\sqrt{n})$, the conditions under which our stochastic algorithm has a lower order of computational complexity for solving linear-constrained optimization problems are discussed. It is demonstrated that the OT problem could satisfy the aforementioned conditions. Numerical experiments demonstrate s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#19968;&#31867;&#21452;&#23618;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#26080;&#38656;warm-start&#20063;&#21487;&#23454;&#29616;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2202.03397</link><description>&lt;p&gt;
&#26377;&#19979;&#23618;&#21387;&#32553;&#30340;&#21452;&#23618;&#20248;&#21270;: &#26080;warm-start&#24773;&#20917;&#19979;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Bilevel Optimization with a Lower-level Contraction: Optimal Sample Complexity without Warm-Start. (arXiv:2202.03397v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.03397
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#19968;&#31867;&#21452;&#23618;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#26080;&#38656;warm-start&#20063;&#21487;&#23454;&#29616;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#19968;&#31867;&#19968;&#33324;&#30340;&#21452;&#23618;&#38382;&#39064;&#65292;&#20854;&#20013;&#19978;&#23618;&#38382;&#39064;&#26159;&#23558;&#19968;&#20809;&#28369;&#30446;&#26631;&#20989;&#25968;&#26368;&#23567;&#21270;&#65292;&#19979;&#23618;&#38382;&#39064;&#26159;&#23547;&#25214;&#19968;&#20809;&#28369;&#25910;&#32553;&#26144;&#23556;&#30340;&#19981;&#21160;&#28857;&#12290;&#36825;&#31867;&#38382;&#39064;&#21253;&#25324;&#20803;&#23398;&#20064;&#12289;&#22343;&#34913;&#27169;&#22411;&#12289;&#36229;&#21442;&#25968;&#20248;&#21270;&#21644;&#25968;&#25454;&#27745;&#26579;&#23545;&#25239;&#25915;&#20987;&#30340;&#23454;&#20363;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#65292;&#21363;&#20351;&#27809;&#26377;warm-start&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#22914;&#20803;&#23398;&#20064;&#21644;&#22343;&#34913;&#27169;&#22411;&#65292;&#20173;&#28982;&#21487;&#20197;&#23454;&#29616;&#39034;&#24207;&#26368;&#20248;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyse a general class of bilevel problems, in which the upper-level problem consists in the minimization of a smooth objective function and the lower-level problem is to find the fixed point of a smooth contraction map. This type of problems include instances of meta-learning, equilibrium models, hyperparameter optimization and data poisoning adversarial attacks. Several recent works have proposed algorithms which warm-start the lower-level problem, i.e. they use the previous lower-level approximate solution as a staring point for the lower-level solver. This warm-start procedure allows one to improve the sample complexity in both the stochastic and deterministic settings, achieving in some cases the order-wise optimal sample complexity. However, there are situations, e.g., meta learning and equilibrium models, in which the warm-start procedure is not well-suited or ineffective. In this work we show that without warm-start, it is still possible to achieve order-wise (near) optimal
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#25104;&#21592;&#26080;&#20998;&#24067;&#27169;&#22411;&#65292;&#29992;&#20110;&#37325;&#21472;&#21152;&#26435;&#32593;&#32476;&#30340;&#31038;&#32676;&#26816;&#27979;&#65292;&#25903;&#25345;&#33410;&#28857;&#25152;&#23646;&#22810;&#20010;&#31038;&#32676;&#21644;&#26377;&#38480;&#23454;&#25968;&#26435;&#20540;&#12290;&#25552;&#20986;&#30340;&#27169;&#22411;&#21487;&#20197;&#25512;&#24191;&#21040;&#20043;&#21069;&#30340;&#27169;&#22411;&#65292;&#21253;&#25324;&#28151;&#21512;&#25104;&#21592;&#38543;&#26426;&#22359;&#27169;&#22411;&#65292;&#24182;&#25903;&#25345;&#20855;&#26377;&#28508;&#22312;&#31038;&#32676;&#32467;&#26500;&#30340;&#37325;&#21472;&#31526;&#21495;&#32593;&#32476;&#30340;&#29983;&#25104;&#12290;&#25105;&#20204;&#20351;&#29992;&#39640;&#25928;&#35889;&#31639;&#27861;&#20272;&#35745;&#27169;&#22411;&#19979;&#30340;&#31038;&#32676;&#25104;&#21592;&#36164;&#26684;&#65292;&#24182;&#25552;&#20986;&#20102;&#27169;&#31946;&#21152;&#26435;&#27169;&#22359;&#24230;&#26469;&#35780;&#20272;&#37325;&#21472;&#21152;&#26435;&#32593;&#32476;&#30340;&#31038;&#32676;&#26816;&#27979;&#36136;&#37327;&#24182;&#30830;&#23450;&#21152;&#26435;&#32593;&#32476;&#31038;&#32676;&#25968;&#37327;&#12290;</title><link>http://arxiv.org/abs/2112.04389</link><description>&lt;p&gt;
&#28151;&#21512;&#25104;&#21592;&#26080;&#20998;&#24067;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Mixed Membership Distribution-Free Model. (arXiv:2112.04389v4 [cs.SI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.04389
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#25104;&#21592;&#26080;&#20998;&#24067;&#27169;&#22411;&#65292;&#29992;&#20110;&#37325;&#21472;&#21152;&#26435;&#32593;&#32476;&#30340;&#31038;&#32676;&#26816;&#27979;&#65292;&#25903;&#25345;&#33410;&#28857;&#25152;&#23646;&#22810;&#20010;&#31038;&#32676;&#21644;&#26377;&#38480;&#23454;&#25968;&#26435;&#20540;&#12290;&#25552;&#20986;&#30340;&#27169;&#22411;&#21487;&#20197;&#25512;&#24191;&#21040;&#20043;&#21069;&#30340;&#27169;&#22411;&#65292;&#21253;&#25324;&#28151;&#21512;&#25104;&#21592;&#38543;&#26426;&#22359;&#27169;&#22411;&#65292;&#24182;&#25903;&#25345;&#20855;&#26377;&#28508;&#22312;&#31038;&#32676;&#32467;&#26500;&#30340;&#37325;&#21472;&#31526;&#21495;&#32593;&#32476;&#30340;&#29983;&#25104;&#12290;&#25105;&#20204;&#20351;&#29992;&#39640;&#25928;&#35889;&#31639;&#27861;&#20272;&#35745;&#27169;&#22411;&#19979;&#30340;&#31038;&#32676;&#25104;&#21592;&#36164;&#26684;&#65292;&#24182;&#25552;&#20986;&#20102;&#27169;&#31946;&#21152;&#26435;&#27169;&#22359;&#24230;&#26469;&#35780;&#20272;&#37325;&#21472;&#21152;&#26435;&#32593;&#32476;&#30340;&#31038;&#32676;&#26816;&#27979;&#36136;&#37327;&#24182;&#30830;&#23450;&#21152;&#26435;&#32593;&#32476;&#31038;&#32676;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#20855;&#26377;&#37325;&#21472;&#21152;&#26435;&#32593;&#32476;&#20013;&#36827;&#34892;&#31038;&#32676;&#26816;&#27979;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#33410;&#28857;&#21487;&#20197;&#23646;&#20110;&#22810;&#20010;&#31038;&#32676;&#65292;&#36793;&#26435;&#21487;&#20197;&#26159;&#26377;&#38480;&#23454;&#25968;&#12290;&#20026;&#20102;&#23545;&#36825;&#26679;&#30340;&#22797;&#26434;&#32593;&#32476;&#36827;&#34892;&#24314;&#27169;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#8212;&#8212;&#28151;&#21512;&#25104;&#21592;&#26080;&#20998;&#24067;&#65288;MMDF&#65289;&#27169;&#22411;&#12290;MMDF&#27809;&#26377;&#23545;&#36793;&#26435;&#30340;&#20998;&#24067;&#32422;&#26463;&#65292;&#21487;&#20197;&#34987;&#35270;&#20026;&#19968;&#20123;&#20808;&#21069;&#27169;&#22411;&#30340;&#25512;&#24191;&#65292;&#21253;&#25324;&#33879;&#21517;&#30340;&#28151;&#21512;&#25104;&#21592;&#38543;&#26426;&#22359;&#27169;&#22411;&#12290;&#29305;&#21035;&#22320;&#65292;&#20855;&#26377;&#28508;&#22312;&#31038;&#32676;&#32467;&#26500;&#30340;&#37325;&#21472;&#31526;&#21495;&#32593;&#32476;&#20063;&#21487;&#20197;&#20174;&#25105;&#20204;&#30340;&#27169;&#22411;&#20013;&#29983;&#25104;&#12290;&#25105;&#20204;&#20351;&#29992;&#20855;&#26377;&#25910;&#25947;&#29575;&#29702;&#35770;&#20445;&#35777;&#30340;&#39640;&#25928;&#35889;&#31639;&#27861;&#26469;&#20272;&#35745;&#27169;&#22411;&#19979;&#30340;&#31038;&#32676;&#25104;&#21592;&#36164;&#26684;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#27169;&#31946;&#21152;&#26435;&#27169;&#22359;&#24230;&#26469;&#35780;&#20272;&#20855;&#26377;&#27491;&#36127;&#36793;&#26435;&#30340;&#37325;&#21472;&#21152;&#26435;&#32593;&#32476;&#30340;&#31038;&#32676;&#26816;&#27979;&#36136;&#37327;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#21033;&#29992;&#25105;&#20204;&#30340;fuzzy weighted modularity&#26469;&#30830;&#23450;&#21152;&#26435;&#32593;&#32476;&#31038;&#32676;&#25968;&#37327;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of community detection in overlapping weighted networks, where nodes can belong to multiple communities and edge weights can be finite real numbers. To model such complex networks, we propose a general framework - the mixed membership distribution-free (MMDF) model. MMDF has no distribution constraints of edge weights and can be viewed as generalizations of some previous models, including the well-known mixed membership stochastic blockmodels. Especially, overlapping signed networks with latent community structures can also be generated from our model. We use an efficient spectral algorithm with a theoretical guarantee of convergence rate to estimate community memberships under the model. We also propose fuzzy weighted modularity to evaluate the quality of community detection for overlapping weighted networks with positive and negative edge weights. We then provide a method to determine the number of communities for weighted networks by taking advantage of our f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32676;&#31561;&#21464;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#65288;GNPE&#65289;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#21442;&#25968;&#21644;&#25968;&#25454;&#32852;&#21512;&#21464;&#25442;&#19979;&#25972;&#21512;&#31561;&#21464;&#24615;&#65292;&#29992;&#20110;&#20174;&#24341;&#21147;&#27874;&#35266;&#27979;&#20013;&#23545;&#21452;&#40657;&#27934;&#31995;&#32479;&#36827;&#34892;&#25674;&#38144;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2111.13139</link><description>&lt;p&gt;
&#32676;&#31561;&#21464;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Group equivariant neural posterior estimation. (arXiv:2111.13139v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.13139
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32676;&#31561;&#21464;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#65288;GNPE&#65289;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#21442;&#25968;&#21644;&#25968;&#25454;&#32852;&#21512;&#21464;&#25442;&#19979;&#25972;&#21512;&#31561;&#21464;&#24615;&#65292;&#29992;&#20110;&#20174;&#24341;&#21147;&#27874;&#35266;&#27979;&#20013;&#23545;&#21452;&#40657;&#27934;&#31995;&#32479;&#36827;&#34892;&#25674;&#38144;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#26465;&#20214;&#31070;&#32463;&#23494;&#24230;&#20272;&#35745;&#30340;&#20223;&#30495;&#25512;&#29702;&#26159;&#35299;&#20915;&#31185;&#23398;&#39046;&#22495;&#21453;&#38382;&#39064;&#30340;&#24378;&#22823;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#23558;&#22522;&#30784;&#27491;&#21521;&#27169;&#22411;&#35270;&#20026;&#19968;&#20010;&#40657;&#30418;&#23376;&#65292;&#19981;&#20250;&#21033;&#29992;&#31561;&#21464;&#24615;&#31561;&#20960;&#20309;&#24615;&#36136;&#12290;&#31561;&#21464;&#24615;&#22312;&#31185;&#23398;&#27169;&#22411;&#20013;&#24456;&#24120;&#35265;&#65292;&#20294;&#23558;&#20854;&#30452;&#25509;&#25972;&#21512;&#21040;&#34920;&#36798;&#24335;&#25512;&#29702;&#32593;&#32476;&#65288;&#22914;&#24402;&#19968;&#21270;&#27969;&#65289;&#20013;&#24182;&#19981;&#31616;&#21333;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26367;&#20195;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#21442;&#25968;&#21644;&#25968;&#25454;&#30340;&#32852;&#21512;&#21464;&#25442;&#19979;&#25972;&#21512;&#31561;&#21464;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#8212;&#8212;&#31216;&#20026;&#32676;&#31561;&#21464;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#65288;GNPE&#65289;&#8212;&#8212;&#22522;&#20110;&#33258;&#27965;&#22320;&#26631;&#20934;&#21270;&#25968;&#25454;&#30340;&#8220;&#23039;&#24577;&#8221;&#65292;&#21516;&#26102;&#20272;&#35745;&#21442;&#25968;&#21518;&#39564;&#12290;&#23427;&#26159;&#29420;&#31435;&#20110;&#20307;&#31995;&#32467;&#26500;&#30340;&#65292;&#24182;&#36866;&#29992;&#20110;&#31934;&#30830;&#21644;&#36817;&#20284;&#31561;&#21464;&#24615;&#12290;&#20316;&#20026;&#29616;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#65292;&#25105;&#20204;&#21033;&#29992;GNPE&#20174;&#24341;&#21147;&#27874;&#35266;&#27979;&#20013;&#23545;&#21452;&#40657;&#27934;&#31995;&#32479;&#36827;&#34892;&#20102;&#25674;&#38144;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
Simulation-based inference with conditional neural density estimators is a powerful approach to solving inverse problems in science. However, these methods typically treat the underlying forward model as a black box, with no way to exploit geometric properties such as equivariances. Equivariances are common in scientific models, however integrating them directly into expressive inference networks (such as normalizing flows) is not straightforward. We here describe an alternative method to incorporate equivariances under joint transformations of parameters and data. Our method -- called group equivariant neural posterior estimation (GNPE) -- is based on self-consistently standardizing the "pose" of the data while estimating the posterior over parameters. It is architecture-independent, and applies both to exact and approximate equivariances. As a real-world application, we use GNPE for amortized inference of astrophysical binary black hole systems from gravitational-wave observations. W
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#34920;&#26126;&#65292;&#20351;&#29992;&#20248;&#21270;&#35774;&#35745;&#30340;&#36172;&#21338;&#31639;&#27861;&#36951;&#25022;&#20998;&#24067;&#20855;&#26377;&#38750;&#24120;&#37325;&#30340;&#23614;&#37096;&#65292;&#23545;&#20110;$p&gt;1$&#65292;&#36951;&#25022;&#20998;&#24067;&#30340;$p$'th&#30697;&#22686;&#38271;&#35201;&#27604;&#22810;&#23545;&#25968;&#32423;&#21035;&#24555;&#24471;&#22810;&#65292;&#24403;&#38382;&#39064;&#30053;&#24494;&#38169;&#35823;&#26102;&#65292;&#20248;&#21270;UCB&#36172;&#21338;&#35774;&#35745;&#30340;&#36951;&#25022;&#21487;&#20197;&#27604;&#20256;&#32479;&#29702;&#35770;&#24314;&#35758;&#30340;&#22686;&#38271;&#24471;&#26356;&#24555;&#12290;</title><link>http://arxiv.org/abs/2109.13595</link><description>&lt;p&gt;
&#20248;&#21270;&#36172;&#21338;&#31639;&#27861;&#30340;&#33030;&#24369;&#24615;
&lt;/p&gt;
&lt;p&gt;
The Fragility of Optimized Bandit Algorithms. (arXiv:2109.13595v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.13595
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#34920;&#26126;&#65292;&#20351;&#29992;&#20248;&#21270;&#35774;&#35745;&#30340;&#36172;&#21338;&#31639;&#27861;&#36951;&#25022;&#20998;&#24067;&#20855;&#26377;&#38750;&#24120;&#37325;&#30340;&#23614;&#37096;&#65292;&#23545;&#20110;$p&gt;1$&#65292;&#36951;&#25022;&#20998;&#24067;&#30340;$p$'th&#30697;&#22686;&#38271;&#35201;&#27604;&#22810;&#23545;&#25968;&#32423;&#21035;&#24555;&#24471;&#22810;&#65292;&#24403;&#38382;&#39064;&#30053;&#24494;&#38169;&#35823;&#26102;&#65292;&#20248;&#21270;UCB&#36172;&#21338;&#35774;&#35745;&#30340;&#36951;&#25022;&#21487;&#20197;&#27604;&#20256;&#32479;&#29702;&#35770;&#24314;&#35758;&#30340;&#22686;&#38271;&#24471;&#26356;&#24555;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#37096;&#20998;&#20851;&#20110;&#36172;&#21338;&#31639;&#27861;&#26368;&#20248;&#35774;&#35745;&#30340;&#25991;&#29486;&#37117;&#26159;&#22522;&#20110;&#26399;&#26395;&#36951;&#25022;&#30340;&#26368;&#23567;&#21270;&#12290;&#24050;&#30693;&#23545;&#20110;&#26576;&#20123;&#25351;&#25968;&#26063;&#65292;&#26368;&#20248;&#35774;&#35745;&#22312;&#25289;&#20381;-&#32599;&#23486;&#26031;&#19979;&#30028;&#25351;&#23548;&#19979;&#65292;&#21487;&#23454;&#29616;&#26399;&#26395;&#36951;&#25022;&#20197;&#23545;&#25968;&#32423;&#21035;&#22686;&#38271;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#24403;&#20351;&#29992;&#36825;&#31181;&#26368;&#20248;&#35774;&#35745;&#26102;&#65292;&#20851;&#32852;&#31639;&#27861;&#30340;&#36951;&#25022;&#20998;&#24067;&#24517;&#28982;&#20855;&#26377;&#19968;&#20010;&#38750;&#24120;&#37325;&#30340;&#23614;&#37096;&#65292;&#20855;&#20307;&#26469;&#35828;&#26159;&#25130;&#26029;&#26607;&#35199;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;$p&gt;1$&#65292;&#36951;&#25022;&#20998;&#24067;&#30340;$p$'th&#30697;&#22686;&#38271;&#35201;&#27604;&#22810;&#23545;&#25968;&#32423;&#21035;&#24555;&#24471;&#22810;&#65292;&#29305;&#21035;&#26159;&#20316;&#20026;&#34915;&#34966;&#25968;&#30340;&#24130;&#20989;&#25968;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#20248;&#21270;UCB&#36172;&#21338;&#35774;&#35745;&#22312;&#21478;&#19968;&#20010;&#26041;&#38754;&#20063;&#24456;&#33030;&#24369;&#65292;&#21363;&#24403;&#38382;&#39064;&#30053;&#24494;&#38169;&#35823;&#26102;&#65292;&#36951;&#25022;&#21487;&#20197;&#27604;&#20256;&#32479;&#29702;&#35770;&#24314;&#35758;&#30340;&#22686;&#38271;&#24471;&#26356;&#24555;&#12290;&#25105;&#20204;&#30340;&#35770;&#28857;&#22522;&#20110;&#26631;&#20934;&#30340;&#25514;&#26045;&#25913;&#21464;&#24605;&#24819;&#65292;&#24182;&#34920;&#26126;&#26368;&#20248;&#35774;&#35745;&#21487;&#33021;&#23548;&#33268;&#19968;&#20123;&#19981;&#22826;&#21487;&#33021;&#21457;&#29983;&#30340;&#24773;&#20917;&#65292;&#22240;&#27492;&#24212;&#35813;&#20197;&#35880;&#24910;&#30340;&#26041;&#24335;&#23545;&#24453;&#12290;
&lt;/p&gt;
&lt;p&gt;
Much of the literature on optimal design of bandit algorithms is based on minimization of expected regret. It is well known that designs that are optimal over certain exponential families can achieve expected regret that grows logarithmically in the number of arm plays, at a rate governed by the Lai-Robbins lower bound. In this paper, we show that when one uses such optimized designs, the regret distribution of the associated algorithms necessarily has a very heavy tail, specifically, that of a truncated Cauchy distribution. Furthermore, for $p&gt;1$, the $p$'th moment of the regret distribution grows much faster than poly-logarithmically, in particular as a power of the total number of arm plays. We show that optimized UCB bandit designs are also fragile in an additional sense, namely when the problem is even slightly mis-specified, the regret can grow much faster than the conventional theory suggests. Our arguments are based on standard change-of-measure ideas, and indicate that the mos
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Bipartite Distribution-Free&#30340;&#27169;&#22411;&#65292;&#21487;&#29992;&#20110;&#24314;&#27169;&#21644;&#25506;&#27979;&#21152;&#26435;&#20108;&#20998;&#32593;&#32476;&#30340;&#31038;&#21306;&#32467;&#26500;&#65292;&#35813;&#27169;&#22411;&#32771;&#34385;&#20102;&#33410;&#28857;&#24230;&#25968;&#30340;&#21464;&#21270;&#20197;&#21450;&#26399;&#26395;&#30340;&#22359;&#32467;&#26500;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35889;&#31639;&#27861;&#29992;&#20110;&#35782;&#21035;&#31038;&#21306;&#12290;</title><link>http://arxiv.org/abs/2109.10319</link><description>&lt;p&gt;
&#21152;&#26435;&#20108;&#20998;&#32593;&#32476;&#30340;&#31038;&#21306;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Community detection for weighted bipartite networks. (arXiv:2109.10319v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.10319
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Bipartite Distribution-Free&#30340;&#27169;&#22411;&#65292;&#21487;&#29992;&#20110;&#24314;&#27169;&#21644;&#25506;&#27979;&#21152;&#26435;&#20108;&#20998;&#32593;&#32476;&#30340;&#31038;&#21306;&#32467;&#26500;&#65292;&#35813;&#27169;&#22411;&#32771;&#34385;&#20102;&#33410;&#28857;&#24230;&#25968;&#30340;&#21464;&#21270;&#20197;&#21450;&#26399;&#26395;&#30340;&#22359;&#32467;&#26500;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35889;&#31639;&#27861;&#29992;&#20110;&#35782;&#21035;&#31038;&#21306;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20108;&#20998;&#32593;&#32476;&#20986;&#29616;&#22312;&#22810;&#20010;&#39046;&#22495;&#65292;&#20363;&#22914;&#29983;&#29289;&#23398;&#12289;&#31038;&#20250;&#23398;&#12289;&#29983;&#29702;&#23398;&#21644;&#35745;&#31639;&#26426;&#31185;&#23398;&#20013;&#12290;&#36807;&#21435;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#38543;&#26426;&#20849;&#21516;&#22359;&#27169;&#22411;&#65288;ScBM&#65289;&#26469;&#26816;&#27979;&#20108;&#20998;&#22270;&#25968;&#25454;&#30340;&#31038;&#21306;&#32467;&#26500;&#65292;&#20294;&#26159;ScBM&#23436;&#20840;&#24573;&#30053;&#36793;&#26435;&#24182;&#19988;&#26080;&#27861;&#35299;&#37322;&#21152;&#26435;&#20108;&#20998;&#32593;&#32476;&#30340;&#22359;&#32467;&#26500;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#36890;&#36807;&#25918;&#23485;ScBM&#30340;&#20998;&#24067;&#32422;&#26463;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;Bipartite Distribution-Free&#30340;&#27169;&#22411;&#26469;&#24314;&#27169;&#21152;&#26435;&#20108;&#20998;&#32593;&#32476;&#65292;&#24182;&#32771;&#34385;&#33410;&#28857;&#24230;&#25968;&#30340;&#21464;&#21270;&#26469;&#26500;&#24314;&#27169;&#22411;&#25193;&#23637;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#19981;&#38656;&#35201;&#22312;&#37051;&#25509;&#30697;&#38453;&#30340;&#29983;&#25104;&#20803;&#19978;&#25351;&#23450;&#29305;&#23450;&#30340;&#20998;&#24067;&#65292;&#32780;&#21482;&#38656;&#35201;&#22312;&#26399;&#26395;&#37051;&#25509;&#30697;&#38453;&#19978;&#25351;&#23450;&#22359;&#32467;&#26500;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#30340;&#35889;&#31639;&#27861;&#65292;&#26469;&#35782;&#21035;&#31038;&#21306;&#12290;&#36890;&#36807;&#27169;&#25311;&#21644;&#23454;&#35777;&#20363;&#23376;&#26469;&#23637;&#31034;&#25105;&#20204;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#21644;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The bipartite network appears in various areas, such as biology, sociology, physiology, and computer science. \cite{rohe2016co} proposed Stochastic co-Blockmodel (ScBM) as a tool for detecting community structure of binary bipartite graph data in network studies. However, ScBM completely ignores edge weight and is unable to explain the block structure of a weighted bipartite network. Here, to model a weighted bipartite network, we introduce a Bipartite Distribution-Free model by releasing ScBM's distribution restriction. We also build an extension of the proposed model by considering the variation of node degree. Our models do not require a specific distribution on generating elements of the adjacency matrix but only a block structure on the expected adjacency matrix. Spectral algorithms with theoretical guarantees on the consistent estimation of node labels are presented to identify communities. Our proposed methods are illustrated by simulated and empirical examples.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20174;&#22240;&#26524;&#30340;&#35282;&#24230;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#38754;&#30340;&#26497;&#23567;&#21270;&#20998;&#26512;&#65292;&#26088;&#22312;&#22238;&#31572;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#36716;&#31227;&#31283;&#23450;&#20449;&#24687;&#26102;&#24212;&#35813;&#36716;&#31227;&#21738;&#20010;&#23376;&#38598;&#20174;&#32780;&#36798;&#21040;&#26368;&#20339;&#30340;&#27867;&#21270;&#33021;&#21147;&#36825;&#19968;&#38382;&#39064;</title><link>http://arxiv.org/abs/2107.01876</link><description>&lt;p&gt;
&#25105;&#20204;&#24212;&#35813;&#36716;&#31227;&#21738;&#31181;&#19981;&#21464;&#24615;&#65311;&#19968;&#31181;&#22240;&#26524;&#26497;&#23567;&#21270;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Which Invariance Should We Transfer? A Causal Minimax Learning Approach. (arXiv:2107.01876v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.01876
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20174;&#22240;&#26524;&#30340;&#35282;&#24230;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#38754;&#30340;&#26497;&#23567;&#21270;&#20998;&#26512;&#65292;&#26088;&#22312;&#22238;&#31572;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#36716;&#31227;&#31283;&#23450;&#20449;&#24687;&#26102;&#24212;&#35813;&#36716;&#31227;&#21738;&#20010;&#23376;&#38598;&#20174;&#32780;&#36798;&#21040;&#26368;&#20339;&#30340;&#27867;&#21270;&#33021;&#21147;&#36825;&#19968;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26080;&#27861;&#21487;&#38752;&#24212;&#23545;&#25968;&#25454;&#38598;&#21464;&#21270;&#65292;&#22240;&#27492;&#22823;&#22810;&#25968;&#29616;&#26377;&#30740;&#31350;&#35797;&#22270;&#23558;&#31283;&#23450;&#20449;&#24687;&#36716;&#31227;&#21040;&#30475;&#19981;&#35265;&#30340;&#29615;&#22659;&#20013;&#12290;&#29305;&#21035;&#22320;&#65292;&#22522;&#20110;&#29420;&#31435;&#22240;&#26524;&#26426;&#21046;&#30340;&#26041;&#27861;&#36890;&#36807;do-operator&#28040;&#38500;&#21487;&#21464;&#30340;&#22240;&#26524;&#26426;&#21046;&#12290;&#19982;&#20043;&#21069;&#30340;&#26041;&#27861;&#30456;&#27604;&#65292;&#25152;&#24471;&#21040;&#30340;&#31283;&#23450;&#39044;&#27979;&#22240;&#20026;&#33021;&#22815;&#26356;&#26377;&#25928;&#22320;&#35782;&#21035;&#31283;&#23450;&#20449;&#24687;&#32780;&#26356;&#21152;&#26377;&#25928;&#12290;&#28982;&#32780;&#65292;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#20173;&#28982;&#23384;&#22312;&#65306;&#20026;&#20102;&#36798;&#21040;&#26368;&#20339;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#24212;&#35813;&#36716;&#31227;&#36825;&#25972;&#20010;&#31283;&#23450;&#20449;&#24687;&#20013;&#30340;&#21738;&#20010;&#23376;&#38598;&#65311;&#20026;&#20102;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20174;&#22240;&#26524;&#30340;&#35282;&#24230;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#38754;&#30340;&#26497;&#23567;&#21270;&#20998;&#26512;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#39318;&#20808;&#25552;&#20379;&#20102;&#19968;&#20010;&#29992;&#20110;&#21028;&#26029;&#25972;&#20010;&#31283;&#23450;&#38598;&#26159;&#21542;&#26368;&#20248;&#30340;&#22270;&#24418;&#26465;&#20214;&#12290;&#24403;&#36825;&#20010;&#26465;&#20214;&#22833;&#36133;&#26102;&#65292;&#25105;&#20204;&#24778;&#35766;&#22320;&#21457;&#29616;&#65292;&#36890;&#36807;&#19968;&#20010;&#20363;&#23376;&#65292;&#36825;&#20010;&#25972;&#20010;&#31283;&#23450;&#38598;&#34429;&#28982;&#33021;&#22815;&#20805;&#20998;&#21033;&#29992;&#31283;&#23450;&#20449;&#24687;&#65292;&#20294;&#24182;&#19981;&#26159;&#26368;&#20248;&#30340;&#36716;&#31227;&#38598;&#12290;&#20026;&#20102;&#30830;&#23450;&#26368;&#20248;&#38598;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22240;&#26524;&#26368;&#23567;&#21547;&#20041;&#30340;&#26041;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#20223;&#30495;&#21644;&#23454;&#38469;&#25968;&#25454;&#20013;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
A major barrier to deploying current machine learning models lies in their non-reliability to dataset shifts. To resolve this problem, most existing studies attempted to transfer stable information to unseen environments. Particularly, independent causal mechanisms-based methods proposed to remove mutable causal mechanisms via the do-operator. Compared to previous methods, the obtained stable predictors are more effective in identifying stable information. However, a key question remains: which subset of this whole stable information should the model transfer, in order to achieve optimal generalization ability? To answer this question, we present a comprehensive minimax analysis from a causal perspective. Specifically, we first provide a graphical condition for the whole stable set to be optimal. When this condition fails, we surprisingly find with an example that this whole stable set, although can fully exploit stable information, is not the optimal one to transfer. To identify the o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26080;&#38656;&#20449;&#20219;&#26381;&#21153;&#22120;&#25110;&#20854;&#20182;&#25968;&#25454;&#28304;&#30340;&#36328; silo &#32852;&#37030;&#23398;&#20064;&#65292;&#32771;&#34385;&#20102;&#36328; silo &#35760;&#24405;&#32423;&#24046;&#20998;&#38544;&#31169; ISRL-DP&#12290;&#35813;&#31639;&#27861;&#21487;&#20197;&#30830;&#20445;&#26469;&#33258;&#27599;&#20010;&#20154;&#30340;&#25968;&#25454;&#37117;&#19981;&#20250;&#34987;&#27844;&#28431;&#12290;</title><link>http://arxiv.org/abs/2106.09779</link><description>&lt;p&gt;
&#26080;&#38656;&#20449;&#20219;&#30340;&#31169;&#26377;&#32852;&#37030;&#23398;&#20064;&#65306;&#20984;&#25439;&#22833;&#20989;&#25968;&#30340;&#26368;&#20248;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Private Federated Learning Without a Trusted Server: Optimal Algorithms for Convex Losses. (arXiv:2106.09779v7 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.09779
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26080;&#38656;&#20449;&#20219;&#26381;&#21153;&#22120;&#25110;&#20854;&#20182;&#25968;&#25454;&#28304;&#30340;&#36328; silo &#32852;&#37030;&#23398;&#20064;&#65292;&#32771;&#34385;&#20102;&#36328; silo &#35760;&#24405;&#32423;&#24046;&#20998;&#38544;&#31169; ISRL-DP&#12290;&#35813;&#31639;&#27861;&#21487;&#20197;&#30830;&#20445;&#26469;&#33258;&#27599;&#20010;&#20154;&#30340;&#25968;&#25454;&#37117;&#19981;&#20250;&#34987;&#27844;&#28431;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#30340;&#30740;&#31350;&#65292;&#29305;&#21035;&#26159;&#36328;&#25968;&#25454;&#28304;&#65288;&#36328; silo&#65289;FL&#65292;&#36825;&#20123;&#25968;&#25454;&#28304;&#30340;&#25968;&#25454;&#20027;&#20154;&#37117;&#19981;&#20449;&#20219;&#26381;&#21153;&#22120;&#25110;&#20854;&#20182; silos&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#27599;&#20010;&#25968;&#25454;&#28304;&#65288;&#20363;&#22914;&#21307;&#38498;&#65289;&#37117;&#26377;&#26469;&#33258;&#19981;&#21516;&#20154;&#65288;&#20363;&#22914;&#24739;&#32773;&#65289;&#30340;&#25968;&#25454;&#65292;&#24182;&#19988;&#24517;&#39035;&#32500;&#25252;&#27599;&#20010;&#20154;&#65288;&#20363;&#22914;&#21307;&#30103;&#35760;&#24405;&#65289;&#25968;&#25454;&#30340;&#38544;&#31169;&#65292;&#21363;&#20351;&#26381;&#21153;&#22120;&#25110;&#20854;&#20182;&#25968;&#25454;&#28304;&#26159;&#24694;&#24847;&#30417;&#21548;&#32773;&#12290;&#36825;&#31181;&#35201;&#27714;&#20419;&#36827;&#20102;&#23545;&#36328; silo &#35760;&#24405;&#32423;&#24046;&#20998;&#38544;&#31169;&#65288;ISRL-DP&#65289;&#30340;&#30740;&#31350;&#65292;&#23427;&#35201;&#27714; silo i &#30340;&#36890;&#20449;&#28385;&#36275;&#35760;&#24405; / &#39033;&#30446;&#32423;&#24046;&#20998;&#38544;&#31169; (DP)&#12290;ISRL-DP &#30830;&#20445; silo i &#20013;&#27599;&#20010;&#20154;&#65288;&#20363;&#22914;&#24739;&#32773;&#65289;&#30340;&#25968;&#25454;&#37117;&#19981;&#20250;&#27844;&#28431;&#12290;ISRL-DP &#19981;&#21516;&#20110;&#21508;&#31181;&#24050;&#26377;&#30340;&#38544;&#31169;&#27010;&#24565;&#12290;&#20013;&#24515;&#21644;&#29992;&#25143;&#32423;&#24046;&#20998;&#38544;&#31169;&#20551;&#23450;&#20154;&#20204;&#20449;&#20219;&#26381;&#21153;&#22120;/&#20854;&#20182;&#25968;&#25454;&#28304;&#12290;&#22312;&#26497;&#31471;&#24773;&#20917;&#19979;&#65292;&#26412;&#22320;DP &#20551;&#23450;&#20154;&#20204;&#26681;&#26412;&#19981;&#20449;&#20219;&#20219;&#20309;&#20154;&#65288;&#29978;&#33267;&#26159;&#20182;&#20204;&#33258;&#24049;&#30340;&#25968;&#25454;&#28304;&#65289;&#12290;ISRL-DP &#22788;&#20110;&#20013;&#24515;&#21644;&#26412;&#22320;DP &#20043;&#38388;&#65292;&#20351;&#24471;&#22312;&#36328; silo &#30340;&#30495;&#23454;&#24773;&#20917;&#19979;&#20855;&#26377;&#29616;&#23454;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies federated learning (FL)--especially cross-silo FL--with data from people who do not trust the server or other silos. In this setting, each silo (e.g. hospital) has data from different people (e.g. patients) and must maintain the privacy of each person's data (e.g. medical record), even if the server or other silos act as adversarial eavesdroppers. This requirement motivates the study of Inter-Silo Record-Level Differential Privacy (ISRL-DP), which requires silo i's communications to satisfy record/item-level differential privacy (DP). ISRL-DP ensures that the data of each person (e.g. patient) in silo i (e.g. hospital i) cannot be leaked. ISRL-DP is different from well-studied privacy notions. Central and user-level DP assume that people trust the server/other silos. On the other end of the spectrum, local DP assumes that people do not trust anyone at all (even their own silo). Sitting between central and local DP, ISRL-DP makes the realistic assumption (in cross-sil
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25913;&#36827;Moment Accountant&#26041;&#27861;&#65292;DP-SGD&#20855;&#26377;&#21487;&#20851;&#38381;&#24418;&#24335;&#30340;$(\epsilon&#65292;\delta)$-DP&#20445;&#35777;&#65292;&#24182;&#19988;&#20854;&#20445;&#35777;&#25509;&#36817;&#26159;&#32039;&#23494;&#30340;&#65292;&#20855;&#26377;&#26368;&#23567;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2102.09030</link><description>&lt;p&gt;
&#35770;DP-SGD&#30340;Moment Accountant&#26041;&#27861;&#30340;&#32039;&#23494;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Tightness of the Moment Accountant for DP-SGD. (arXiv:2102.09030v8 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.09030
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25913;&#36827;Moment Accountant&#26041;&#27861;&#65292;DP-SGD&#20855;&#26377;&#21487;&#20851;&#38381;&#24418;&#24335;&#30340;$(\epsilon&#65292;\delta)$-DP&#20445;&#35777;&#65292;&#24182;&#19988;&#20854;&#20445;&#35777;&#25509;&#36817;&#26159;&#32039;&#23494;&#30340;&#65292;&#20855;&#26377;&#26368;&#23567;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#25552;&#20379;&#24046;&#20998;&#38544;&#31169;&#65292;&#22312;&#24046;&#20998;&#38544;&#31169;SGD&#65288;DP-SGD&#65289;&#20013;&#65292;&#22312;&#25191;&#34892;&#21098;&#20999;&#25805;&#20316;&#21518;&#65292;&#21521;&#26412;&#22320;SGD&#26356;&#26032;&#28155;&#21152;&#26631;&#20934;&#24046;&#20026;$ \sigma $&#30340;&#39640;&#26031;&#22122;&#22768;&#12290;&#36890;&#36807;&#38750;&#24179;&#20961;&#22320;&#25913;&#36827;Moment Accountant&#26041;&#27861;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#23553;&#38381;&#24418;&#24335;&#30340;$(\epsilon&#65292;\delta)$-DP&#20445;&#35777;&#65306;&#22914;&#26524;$ \sigma=\sqrt{ 2(\epsilon+\ln(1/\delta))/\epsilon} $&#65292;&#21017;DP-SGD&#26159;$ (\epsilon \leq 1/2&#65292;\delta = 1 / N) $-DP&#65292;&#20854;&#20013;$T$&#33267;&#23569;&#20026;$ \approx 2k^2/\epsilon$&#65292; $(2/e)^2k^2-1/2\geq \ln(N)$&#65292;&#20854;&#20013;$T$&#26159;&#22238;&#21512;&#30340;&#24635;&#25968;&#65292;$ K = kN $&#26159;&#26799;&#24230;&#35745;&#31639;&#30340;&#24635;&#25968;&#65292;&#20854;&#20013;$ k $&#29992;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;$N$&#30340;&#26102;&#20195;&#25968;&#37327;&#26469;&#34913;&#37327;&#12290;&#25105;&#20204;&#35777;&#26126;&#25105;&#20204;&#30340;&#34920;&#36798;&#24335;&#25509;&#36817;&#32039;&#65292;&#22312;$T$&#23567;&#20110;&#32422;&#20026;$ 8 $&#20493;&#20110;&#19979;&#30028;$ \approx 2k^2/\epsilon$&#30340;&#24120;&#25968;&#22240;&#23376;&#26102;&#65292;$(\epsilon&#65292;\delta)$-DP&#20445;&#35777;&#23558;&#34987;&#36829;&#21453;&#12290;&#36873;&#25321;&#26368;&#23567;&#21487;&#33021;&#20540;&#30340;$T \approx 2k^2/\epsilon$&#19981;&#20165;&#20250;&#23548;&#33268;&#25509;&#36817;&#23494;&#38598;&#30340;DP&#20445;&#35777;&#65292;&#32780;&#19988;&#36824;&#20250;&#26368;&#23567;&#21270;&#35745;&#31639;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
In order to provide differential privacy, Gaussian noise with standard deviation $\sigma$ is added to local SGD updates after performing a clipping operation in Differential Private SGD (DP-SGD). By non-trivially improving the moment account method we prove a closed form $(\epsilon,\delta)$-DP guarantee: DP-SGD is $(\epsilon\leq 1/2,\delta=1/N)$-DP if $\sigma=\sqrt{2(\epsilon +\ln(1/\delta))/\epsilon}$ with $T$ at least $\approx 2k^2/\epsilon$ and $(2/e)^2k^2-1/2\geq \ln(N)$, where $T$ is the total number of rounds, and $K=kN$ is the total number of gradient computations where $k$ measures $K$ in number of epochs of size $N$ of the local data set. We prove that our expression is close to tight in that if $T$ is more than a constant factor $\approx 8$ smaller than the lower bound $\approx 2k^2/\epsilon$, then the $(\epsilon,\delta)$-DP guarantee is violated. Choosing the smallest possible value $T\approx 2k^2/\epsilon$ not only leads to a close to tight DP guarantee, but also minimizes 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#20026;2&#30340;&#24102;&#38480;&#21046;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#36890;&#36807;&#25968;&#23398;&#35777;&#26126;&#30830;&#23450;&#20102;&#24403;&#38544;&#34255;&#21442;&#25968;&#20998;&#24067;&#20110;&#26377;&#30028;&#22495;&#26102;&#65292;&#32593;&#32476;&#21487;&#33021;&#26080;&#27861;&#36798;&#21040;&#38646;&#36924;&#36817;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2008.08427</link><description>&lt;p&gt;
&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#24102;&#38480;&#21046;&#30340;&#38543;&#26426;&#26435;&#37325;&#26377;&#22810;&#22823;&#30340;&#33021;&#21147;&#65311;
&lt;/p&gt;
&lt;p&gt;
How Powerful are Shallow Neural Networks with Bandlimited Random Weights?. (arXiv:2008.08427v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2008.08427
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#20026;2&#30340;&#24102;&#38480;&#21046;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#36890;&#36807;&#25968;&#23398;&#35777;&#26126;&#30830;&#23450;&#20102;&#24403;&#38544;&#34255;&#21442;&#25968;&#20998;&#24067;&#20110;&#26377;&#30028;&#22495;&#26102;&#65292;&#32593;&#32476;&#21487;&#33021;&#26080;&#27861;&#36798;&#21040;&#38646;&#36924;&#36817;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#28145;&#24230;&#20026;2&#30340;&#24102;&#38480;&#21046;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;&#38543;&#26426;&#32593;&#32476;&#26159;&#25351;&#38544;&#34255;&#23618;&#21442;&#25968;&#34987;&#20923;&#32467;&#24182;&#36171;&#20104;&#38543;&#26426;&#20998;&#37197;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#21482;&#26377;&#36755;&#20986;&#23618;&#21442;&#25968;&#36890;&#36807;&#25439;&#22833;&#26368;&#23567;&#21270;&#36827;&#34892;&#35757;&#32451;&#12290;&#20351;&#29992;&#38543;&#26426;&#26435;&#37325;&#30340;&#38544;&#34255;&#23618;&#26159;&#36991;&#20813;&#26631;&#20934;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#20013;&#30340;&#38750;&#20984;&#20248;&#21270;&#30340;&#26377;&#25928;&#26041;&#27861;&#65292;&#24182;&#24050;&#34987;&#36817;&#26399;&#28145;&#24230;&#23398;&#20064;&#29702;&#35770;&#25152;&#37319;&#29992;&#12290;&#23613;&#31649;&#31070;&#32463;&#32593;&#32476;&#26159;&#26222;&#36866;&#36924;&#36817;&#22120;&#30340;&#20247;&#25152;&#21608;&#30693;&#30340;&#20107;&#23454;&#65292;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25968;&#23398;&#19978;&#35777;&#26126;&#20102;&#24403;&#38544;&#34255;&#21442;&#25968;&#20998;&#24067;&#20110;&#26377;&#30028;&#22495;&#26102;&#65292;&#32593;&#32476;&#21487;&#33021;&#26080;&#27861;&#36798;&#21040;&#38646;&#36924;&#36817;&#35823;&#24046;&#12290;&#25105;&#20204;&#29305;&#21035;&#23548;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#38750;&#24179;&#20961;&#36924;&#36817;&#35823;&#24046;&#19979;&#30028;&#12290;&#35777;&#26126;&#21033;&#29992;&#20102;Ridgelet&#20998;&#26512;&#25216;&#26415;&#65292;&#36825;&#26159;&#19968;&#31181;&#20026;&#31070;&#32463;&#32593;&#32476;&#35774;&#35745;&#30340;&#35856;&#27874;&#20998;&#26512;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#21463;&#21040;&#20102;&#32463;&#20856;&#20449;&#21495;&#22788;&#29702;&#20013;&#30340;&#22522;&#26412;&#21407;&#29702;&#30340;&#21551;&#21457;&#65292;&#29305;&#21035;&#26159;&#20449;&#21495;&#22312;&#26576;&#31181;&#38480;&#21046;&#19979;&#30340;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the expressive power of depth-2 bandlimited random neural networks. A random net is a neural network where the hidden layer parameters are frozen with random assignment, and only the output layer parameters are trained by loss minimization. Using random weights for a hidden layer is an effective method to avoid non-convex optimization in standard gradient descent learning. It has also been adopted in recent deep learning theories. Despite the well-known fact that a neural network is a universal approximator, in this study, we mathematically show that when hidden parameters are distributed in a bounded domain, the network may not achieve zero approximation error. In particular, we derive a new nontrivial approximation error lower bound. The proof utilizes the technique of ridgelet analysis, a harmonic analysis method designed for neural networks. This method is inspired by fundamental principles in classical signal processing, specifically the idea that signals with limit
&lt;/p&gt;</description></item></channel></rss>