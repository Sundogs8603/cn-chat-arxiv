<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#22312;&#38750;&#20809;&#28369;&#38543;&#26426;&#20984;&#20248;&#21270;&#20013;&#65292;&#36866;&#24212;&#24615;&#30340;&#20195;&#20215;&#26159;&#26080;&#27861;&#36991;&#20813;&#30340;&#65292;&#24182;&#19988;&#32473;&#20986;&#20102;&#20851;&#20110;&#19981;&#30830;&#23450;&#24615;&#21442;&#25968;&#30340;&#27425;&#20248;&#24615;&#20056;&#27861;&#22686;&#21152;&#30340;&#19979;&#30028;&#12290;</title><link>https://arxiv.org/abs/2402.10898</link><description>&lt;p&gt;
&#38543;&#26426;&#20984;&#20248;&#21270;&#20013;&#36866;&#24212;&#24615;&#30340;&#20195;&#20215;
&lt;/p&gt;
&lt;p&gt;
The Price of Adaptivity in Stochastic Convex Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10898
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#22312;&#38750;&#20809;&#28369;&#38543;&#26426;&#20984;&#20248;&#21270;&#20013;&#65292;&#36866;&#24212;&#24615;&#30340;&#20195;&#20215;&#26159;&#26080;&#27861;&#36991;&#20813;&#30340;&#65292;&#24182;&#19988;&#32473;&#20986;&#20102;&#20851;&#20110;&#19981;&#30830;&#23450;&#24615;&#21442;&#25968;&#30340;&#27425;&#20248;&#24615;&#20056;&#27861;&#22686;&#21152;&#30340;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#38750;&#20809;&#28369;&#38543;&#26426;&#20984;&#20248;&#21270;&#20013;&#36866;&#24212;&#24615;&#30340;&#19981;&#21487;&#33021;&#24615;&#32467;&#26524;&#12290;&#32473;&#23450;&#19968;&#32452;&#25105;&#20204;&#24076;&#26395;&#36866;&#24212;&#30340;&#38382;&#39064;&#21442;&#25968;&#65292;&#25105;&#20204;&#23450;&#20041;&#20102;&#8220;&#36866;&#24212;&#24615;&#30340;&#20195;&#20215;&#8221;&#65288;PoA&#65289;&#65292;&#31895;&#30053;&#22320;&#35828;&#65292;&#23427;&#34913;&#37327;&#20102;&#30001;&#20110;&#36825;&#20123;&#21442;&#25968;&#30340;&#19981;&#30830;&#23450;&#24615;&#32780;&#23548;&#33268;&#30340;&#27425;&#20248;&#24615;&#30340;&#20056;&#27861;&#22686;&#21152;&#12290;&#24403;&#21021;&#22987;&#36317;&#31163;&#26368;&#20248;&#35299;&#26410;&#30693;&#20294;&#26799;&#24230;&#33539;&#25968;&#26377;&#30028;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;PoA&#33267;&#23569;&#23545;&#20110;&#26399;&#26395;&#27425;&#20248;&#24615;&#26159;&#23545;&#25968;&#32423;&#21035;&#65292;&#23545;&#20110;&#20013;&#20301;&#25968;&#27425;&#20248;&#24615;&#26159;&#21452;&#23545;&#25968;&#32423;&#21035;&#12290;&#24403;&#36317;&#31163;&#21644;&#26799;&#24230;&#33539;&#25968;&#37117;&#23384;&#22312;&#19981;&#30830;&#23450;&#24615;&#26102;&#65292;&#25105;&#20204;&#34920;&#26126;PoA&#24517;&#39035;&#26159;&#19982;&#19981;&#30830;&#23450;&#24615;&#27700;&#24179;&#22810;&#39033;&#24335;&#30456;&#20851;&#30340;&#12290;&#25105;&#20204;&#30340;&#19979;&#30028;&#20960;&#20046;&#19982;&#29616;&#26377;&#30340;&#19978;&#30028;&#30456;&#21305;&#37197;&#65292;&#24182;&#19988;&#30830;&#23450;&#20102;&#27809;&#26377;&#26080;&#21442;&#25968;&#21320;&#39184;&#30340;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10898v1 Announce Type: cross  Abstract: We prove impossibility results for adaptivity in non-smooth stochastic convex optimization. Given a set of problem parameters we wish to adapt to, we define a "price of adaptivity" (PoA) that, roughly speaking, measures the multiplicative increase in suboptimality due to uncertainty in these parameters. When the initial distance to the optimum is unknown but a gradient norm bound is known, we show that the PoA is at least logarithmic for expected suboptimality, and double-logarithmic for median suboptimality. When there is uncertainty in both distance and gradient norm, we show that the PoA must be polynomial in the level of uncertainty. Our lower bounds nearly match existing upper bounds, and establish that there is no parameter-free lunch.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22312;&#20302;&#32500;&#26367;&#20195;&#31354;&#38388;&#20013;&#30340;&#20984;&#22810;&#38754;&#20307;&#39030;&#28857;&#19978;&#23884;&#20837;&#32467;&#26524;&#65292;&#24182;&#25506;&#31350;&#21333;&#32431;&#24418;&#20013;&#30340;&#19968;&#33268;&#24615;&#21306;&#22495;&#65292;&#26435;&#34913;&#20102;&#26367;&#20195;&#25439;&#22833;&#32500;&#24230;&#12289;&#38382;&#39064;&#23454;&#20363;&#25968;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.10818</link><description>&lt;p&gt;
&#22312;&#27169;&#22411;&#30340;&#20984;&#26367;&#20195;&#21697;&#30340;&#19968;&#33268;&#24615;&#21644;&#32500;&#24230;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
Trading off Consistency and Dimensionality of Convex Surrogates for the Mode
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10818
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22312;&#20302;&#32500;&#26367;&#20195;&#31354;&#38388;&#20013;&#30340;&#20984;&#22810;&#38754;&#20307;&#39030;&#28857;&#19978;&#23884;&#20837;&#32467;&#26524;&#65292;&#24182;&#25506;&#31350;&#21333;&#32431;&#24418;&#20013;&#30340;&#19968;&#33268;&#24615;&#21306;&#22495;&#65292;&#26435;&#34913;&#20102;&#26367;&#20195;&#25439;&#22833;&#32500;&#24230;&#12289;&#38382;&#39064;&#23454;&#20363;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#31867;&#20998;&#31867;&#20013;&#65292;&#24517;&#39035;&#23558;&#32467;&#26524;&#23884;&#20837;&#21040;&#33267;&#23569;&#26377;$n-1$&#32500;&#30340;&#23454;&#25968;&#31354;&#38388;&#20013;&#65292;&#20197;&#35774;&#35745;&#19968;&#31181;&#19968;&#33268;&#30340;&#26367;&#20195;&#25439;&#22833;&#20989;&#25968;&#65292;&#36825;&#20250;&#23548;&#33268;"&#27491;&#30830;"&#30340;&#20998;&#31867;&#65292;&#32780;&#19981;&#21463;&#25968;&#25454;&#20998;&#24067;&#30340;&#24433;&#21709;&#12290;&#22312;&#20449;&#24687;&#26816;&#32034;&#21644;&#32467;&#26500;&#21270;&#39044;&#27979;&#20219;&#21153;&#31561;&#38656;&#35201;&#22823;&#37327;n&#26102;&#65292;&#20248;&#21270;n-1&#32500;&#26367;&#20195;&#24120;&#24120;&#26159;&#26840;&#25163;&#30340;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#22810;&#31867;&#20998;&#31867;&#20013;&#22914;&#20309;&#26435;&#34913;&#26367;&#20195;&#25439;&#22833;&#32500;&#24230;&#12289;&#38382;&#39064;&#23454;&#20363;&#25968;&#37327;&#20197;&#21450;&#22312;&#21333;&#32431;&#24418;&#19978;&#32422;&#26463;&#19968;&#33268;&#24615;&#21306;&#22495;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#36319;&#38543;&#36807;&#21435;&#30340;&#30740;&#31350;&#65292;&#25506;&#35752;&#20102;&#19968;&#31181;&#30452;&#35266;&#30340;&#23884;&#20837;&#36807;&#31243;&#65292;&#23558;&#32467;&#26524;&#26144;&#23556;&#21040;&#20302;&#32500;&#26367;&#20195;&#31354;&#38388;&#20013;&#30340;&#20984;&#22810;&#38754;&#20307;&#30340;&#39030;&#28857;&#19978;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#27599;&#20010;&#28857;&#36136;&#37327;&#20998;&#24067;&#21608;&#22260;&#23384;&#22312;&#21333;&#32431;&#24418;&#30340;&#20840;&#32500;&#23376;&#38598;&#65292;&#20854;&#20013;&#19968;&#33268;&#24615;&#25104;&#31435;&#65292;&#20294;&#26159;&#65292;&#23569;&#20110;n-1&#32500;&#24230;&#30340;&#24773;&#20917;&#19979;&#65292;&#23384;&#22312;&#19968;&#20123;&#20998;&#24067;&#65292;&#23545;&#20110;&#36825;&#20123;&#20998;&#24067;&#65292;&#19968;&#31181;&#29616;&#35937;&#24615;&#26159;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10818v1 Announce Type: new  Abstract: In multiclass classification over $n$ outcomes, the outcomes must be embedded into the reals with dimension at least $n-1$ in order to design a consistent surrogate loss that leads to the "correct" classification, regardless of the data distribution. For large $n$, such as in information retrieval and structured prediction tasks, optimizing a surrogate in $n-1$ dimensions is often intractable. We investigate ways to trade off surrogate loss dimension, the number of problem instances, and restricting the region of consistency in the simplex for multiclass classification. Following past work, we examine an intuitive embedding procedure that maps outcomes into the vertices of convex polytopes in a low-dimensional surrogate space. We show that full-dimensional subsets of the simplex exist around each point mass distribution for which consistency holds, but also, with less than $n-1$ dimensions, there exist distributions for which a phenomeno
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#31639;&#27861;&#65292;Variational Primal-Dual Policy Optimization (VPDPO)&#65292;&#36890;&#36807;&#23454;&#29616;Lagrangian&#21644;Fenchel&#23545;&#20598;&#26469;&#23558;&#21407;&#22987;&#21463;&#38480;&#38382;&#39064;&#37325;&#26500;&#20026;&#26080;&#32422;&#26463;&#30340;&#21407;&#22987;-&#23545;&#20598;&#20248;&#21270;&#65292;&#24182;&#19988;&#37319;&#29992;&#20048;&#35266;&#21407;&#21017;&#26356;&#26032;&#21407;&#22987;&#21464;&#37327;&#21644;&#26799;&#24230;&#19978;&#21319;&#26356;&#26032;&#23545;&#20598;&#21464;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.10810</link><description>&lt;p&gt;
&#21452;&#37325;&#23545;&#20598;&#65306;&#29992;&#20110;&#21463;&#38480;&#21046;&#24378;&#21270;&#23398;&#20064;&#30340;&#21464;&#20998;&#21407;&#22987;&#23545;&#20598;&#31574;&#30053;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Double Duality: Variational Primal-Dual Policy Optimization for Constrained Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10810
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#31639;&#27861;&#65292;Variational Primal-Dual Policy Optimization (VPDPO)&#65292;&#36890;&#36807;&#23454;&#29616;Lagrangian&#21644;Fenchel&#23545;&#20598;&#26469;&#23558;&#21407;&#22987;&#21463;&#38480;&#38382;&#39064;&#37325;&#26500;&#20026;&#26080;&#32422;&#26463;&#30340;&#21407;&#22987;-&#23545;&#20598;&#20248;&#21270;&#65292;&#24182;&#19988;&#37319;&#29992;&#20048;&#35266;&#21407;&#21017;&#26356;&#26032;&#21407;&#22987;&#21464;&#37327;&#21644;&#26799;&#24230;&#19978;&#21319;&#26356;&#26032;&#23545;&#20598;&#21464;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#21463;&#38480;&#20984;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#65292;&#30446;&#26631;&#26159;&#26368;&#23567;&#21270;&#35775;&#38382;&#24230;&#37327;&#30340;&#20984;&#27867;&#20989;&#65292;&#21463;&#21040;&#20984;&#32422;&#26463;&#30340;&#38480;&#21046;&#12290;&#20026;&#21463;&#38480;&#20984;MDP&#35774;&#35745;&#31639;&#27861;&#38754;&#20020;&#20960;&#20010;&#25361;&#25112;&#65292;&#21253;&#25324;&#65288;1&#65289;&#22788;&#29702;&#22823;&#29366;&#24577;&#31354;&#38388;&#65292;&#65288;2&#65289;&#31649;&#29702;&#25506;&#32034;/&#24320;&#25299;&#30340;&#26435;&#34913;&#65292;&#20197;&#21450;&#65288;3&#65289;&#35299;&#20915;&#32422;&#26463;&#20248;&#21270;&#65292;&#20854;&#20013;&#30446;&#26631;&#21644;&#32422;&#26463;&#37117;&#26159;&#35775;&#38382;&#24230;&#37327;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#31639;&#27861;&#65292;&#21464;&#20998;&#21407;&#22987;&#23545;&#20598;&#31574;&#30053;&#20248;&#21270;&#65288;VPDPO&#65289;&#65292;&#20854;&#20013;Lagrangian &#21644; Fenchel &#23545;&#20598;&#34987;&#29992;&#20110;&#23558;&#21407;&#22987;&#21463;&#38480;&#38382;&#39064;&#37325;&#26032;&#20844;&#24335;&#21270;&#20026;&#26080;&#38480;&#21046;&#21407;&#22987;-&#23545;&#20598;&#20248;&#21270;&#12290;&#27492;&#22806;&#65292;&#21407;&#22987;&#21464;&#37327;&#36890;&#36807;&#22522;&#20110;&#27169;&#22411;&#30340;&#20540;&#36845;&#20195;&#26356;&#26032;&#65292;&#36981;&#24490;&#19981;&#30830;&#23450;&#24615;&#38754;&#21069;&#30340;&#20048;&#35266;&#21407;&#21017;&#65288;OFU&#65289;&#65292;&#32780;&#23545;&#20598;&#21464;&#37327;&#21017;&#36890;&#36807;&#26799;&#24230;&#19978;&#21319;&#26356;&#26032;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10810v1 Announce Type: new  Abstract: We study the Constrained Convex Markov Decision Process (MDP), where the goal is to minimize a convex functional of the visitation measure, subject to a convex constraint. Designing algorithms for a constrained convex MDP faces several challenges, including (1) handling the large state space, (2) managing the exploration/exploitation tradeoff, and (3) solving the constrained optimization where the objective and the constraint are both nonlinear functions of the visitation measure. In this work, we present a model-based algorithm, Variational Primal-Dual Policy Optimization (VPDPO), in which Lagrangian and Fenchel duality are implemented to reformulate the original constrained problem into an unconstrained primal-dual optimization. Moreover, the primal variables are updated by model-based value iteration following the principle of Optimism in the Face of Uncertainty (OFU), while the dual variables are updated by gradient ascent. Moreover,
&lt;/p&gt;</description></item><item><title>BlackJAX&#26159;&#19968;&#20010;&#23454;&#29616;&#22312;JAX&#20013;&#32452;&#21512;&#24335;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#24211;&#65292;&#37319;&#29992;&#20989;&#25968;&#24335;&#26041;&#27861;&#25552;&#39640;&#26131;&#29992;&#24615;&#12289;&#36895;&#24230;&#21644;&#27169;&#22359;&#21270;&#65292;&#36866;&#29992;&#20110;&#38656;&#35201;&#23574;&#31471;&#26041;&#27861;&#12289;&#30740;&#31350;&#20154;&#21592;&#21644;&#24819;&#35201;&#20102;&#35299;&#24037;&#20316;&#21407;&#29702;&#30340;&#20154;&#12290;</title><link>https://arxiv.org/abs/2402.10797</link><description>&lt;p&gt;
BlackJAX: JAX&#20013;&#30340;&#32452;&#21512;&#24335;&#36125;&#21494;&#26031;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
BlackJAX: Composable Bayesian inference in JAX
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10797
&lt;/p&gt;
&lt;p&gt;
BlackJAX&#26159;&#19968;&#20010;&#23454;&#29616;&#22312;JAX&#20013;&#32452;&#21512;&#24335;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#24211;&#65292;&#37319;&#29992;&#20989;&#25968;&#24335;&#26041;&#27861;&#25552;&#39640;&#26131;&#29992;&#24615;&#12289;&#36895;&#24230;&#21644;&#27169;&#22359;&#21270;&#65292;&#36866;&#29992;&#20110;&#38656;&#35201;&#23574;&#31471;&#26041;&#27861;&#12289;&#30740;&#31350;&#20154;&#21592;&#21644;&#24819;&#35201;&#20102;&#35299;&#24037;&#20316;&#21407;&#29702;&#30340;&#20154;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
BlackJAX&#26159;&#19968;&#20010;&#24211;&#65292;&#23454;&#29616;&#20102;&#22312;&#36125;&#21494;&#26031;&#35745;&#31639;&#20013;&#24120;&#29992;&#30340;&#25277;&#26679;&#21644;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#12290;&#23427;&#36890;&#36807;&#37319;&#29992;&#20989;&#25968;&#24335;&#26041;&#27861;&#23454;&#29616;&#31639;&#27861;&#65292;&#26088;&#22312;&#25552;&#39640;&#26131;&#29992;&#24615;&#12289;&#36895;&#24230;&#21644;&#27169;&#22359;&#21270;&#12290;BlackJAX&#20351;&#29992;Python&#32534;&#20889;&#65292;&#21033;&#29992;JAX&#22312;CPU&#12289;GPU&#21644;TPU&#19978;&#32534;&#35793;&#21644;&#36816;&#34892;&#31867;&#20284;Numpy&#30340;&#25277;&#26679;&#22120;&#21644;&#21464;&#20998;&#26041;&#27861;&#12290;&#35813;&#24211;&#36890;&#36807;&#30452;&#25509;&#22788;&#29702;&#65288;&#38750;&#27491;&#21017;&#21270;&#65289;&#30446;&#26631;&#23545;&#25968;&#23494;&#24230;&#20989;&#25968;&#65292;&#19982;&#27010;&#29575;&#32534;&#31243;&#35821;&#35328;&#24456;&#22909;&#22320;&#38598;&#25104;&#12290;BlackJAX&#26088;&#22312;&#25104;&#20026;&#22522;&#26412;&#32479;&#35745;&#8220;&#22522;&#20803;&#8221;&#30340;&#20302;&#32423;&#21487;&#32452;&#21512;&#23454;&#29616;&#30340;&#38598;&#21512;&#65292;&#21487;&#32452;&#21512;&#25191;&#34892;&#23450;&#20041;&#33391;&#22909;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#65292;&#21516;&#26102;&#36824;&#25552;&#20379;&#39640;&#32423;&#20363;&#31243;&#20197;&#25552;&#39640;&#26131;&#29992;&#24615;&#12290;&#23427;&#38754;&#21521;&#38656;&#35201;&#23574;&#31471;&#26041;&#27861;&#30340;&#29992;&#25143;&#12289;&#24076;&#26395;&#21019;&#24314;&#22797;&#26434;&#25277;&#26679;&#26041;&#27861;&#30340;&#30740;&#31350;&#20154;&#21592;&#65292;&#20197;&#21450;&#24819;&#35201;&#20102;&#35299;&#36825;&#20123;&#26041;&#27861;&#24037;&#20316;&#21407;&#29702;&#30340;&#20154;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10797v1 Announce Type: cross  Abstract: BlackJAX is a library implementing sampling and variational inference algorithms commonly used in Bayesian computation. It is designed for ease of use, speed, and modularity by taking a functional approach to the algorithms' implementation. BlackJAX is written in Python, using JAX to compile and run NumpPy-like samplers and variational methods on CPUs, GPUs, and TPUs. The library integrates well with probabilistic programming languages by working directly with the (un-normalized) target log density function. BlackJAX is intended as a collection of low-level, composable implementations of basic statistical 'atoms' that can be combined to perform well-defined Bayesian inference, but also provides high-level routines for ease of use. It is designed for users who need cutting-edge methods, researchers who want to create complex sampling methods, and people who want to learn how these work.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#29616;&#20195;&#24418;&#24335;&#30340;&#38169;&#35823;&#21453;&#39304;EF21&#65292;&#23558;&#20854;&#20381;&#36182;&#30340;&#36890;&#20449;&#22797;&#26434;&#24230;&#20174;&#24179;&#26041;&#24179;&#22343;&#20540;&#25913;&#36827;&#20026;&#26356;&#23567;&#30340;&#31639;&#26415;&#24179;&#22343;&#20540;&#65292;&#22312;&#23454;&#36341;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>https://arxiv.org/abs/2402.10774</link><description>&lt;p&gt;
&#38169;&#35823;&#21453;&#39304;&#37325;&#26032;&#21152;&#36733;&#65306;&#20174;&#24179;&#26041;&#21040;&#24179;&#28369;&#24230;&#24120;&#25968;&#30340;&#31639;&#26415;&#24179;&#22343;&#20540;
&lt;/p&gt;
&lt;p&gt;
Error Feedback Reloaded: From Quadratic to Arithmetic Mean of Smoothness Constants
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10774
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#29616;&#20195;&#24418;&#24335;&#30340;&#38169;&#35823;&#21453;&#39304;EF21&#65292;&#23558;&#20854;&#20381;&#36182;&#30340;&#36890;&#20449;&#22797;&#26434;&#24230;&#20174;&#24179;&#26041;&#24179;&#22343;&#20540;&#25913;&#36827;&#20026;&#26356;&#23567;&#30340;&#31639;&#26415;&#24179;&#22343;&#20540;&#65292;&#22312;&#23454;&#36341;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38169;&#35823;&#21453;&#39304;&#65288;EF&#65289;&#26159;&#19968;&#31181;&#38750;&#24120;&#27969;&#34892;&#19988;&#26497;&#20854;&#26377;&#25928;&#30340;&#26426;&#21046;&#65292;&#29992;&#20110;&#35299;&#20915;&#20998;&#24067;&#24335;&#35757;&#32451;&#26041;&#27861;&#65288;&#22914;&#20998;&#24067;&#24335;GD&#25110;SGD&#65289;&#20013;&#30001;&#20110;&#19982;&#36138;&#23146;&#36890;&#20449;&#21387;&#32553;&#25216;&#26415;&#65288;&#22914;TopK&#65289;&#32467;&#21512;&#32780;&#20135;&#29983;&#30340;&#25910;&#25947;&#38382;&#39064;&#12290;&#23613;&#31649;EF&#25552;&#20986;&#24050;&#26377;&#36817;&#21313;&#24180;&#26102;&#38388;&#65288;Seide&#31561;&#20154;&#65292;2014&#24180;&#65289;&#65292;&#24182;&#19988;&#23613;&#31649;&#31038;&#21306;&#20026;&#25512;&#36827;&#23545;&#35813;&#26426;&#21046;&#30340;&#29702;&#35770;&#29702;&#35299;&#32780;&#38598;&#20013;&#21162;&#21147;&#65292;&#20173;&#26377;&#24456;&#22810;&#23578;&#24453;&#25506;&#32034;&#20043;&#22788;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#21517;&#20026;EF21&#65288;Richtarik&#31561;&#20154;&#65292;2021&#24180;&#65289;&#30340;&#29616;&#20195;&#24418;&#24335;&#30340;&#38169;&#35823;&#21453;&#39304;&#65292;&#23427;&#25552;&#20379;&#20102;&#30446;&#21069;&#24050;&#30693;&#30340;&#26368;&#20339;&#29702;&#35770;&#20445;&#35777;&#65292;&#22312;&#26368;&#24369;&#30340;&#20551;&#35774;&#19979;&#20063;&#22312;&#23454;&#36341;&#20013;&#36816;&#34892;&#33391;&#22909;&#12290;&#29305;&#21035;&#22320;&#65292;&#34429;&#28982;EF21&#30340;&#29702;&#35770;&#36890;&#20449;&#22797;&#26434;&#24230;&#21462;&#20915;&#20110;&#26576;&#20123;&#24179;&#28369;&#24230;&#21442;&#25968;&#30340;&#24179;&#26041;&#22343;&#20540;&#65292;&#25105;&#20204;&#23558;&#36825;&#31181;&#20381;&#36182;&#24615;&#25913;&#36827;&#20026;&#23427;&#20204;&#30340;&#31639;&#26415;&#24179;&#22343;&#20540;&#65292;&#21518;&#32773;&#22987;&#32456;&#26356;&#23567;&#65292;&#23588;&#20854;&#26159;&#22312;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10774v1 Announce Type: cross  Abstract: Error Feedback (EF) is a highly popular and immensely effective mechanism for fixing convergence issues which arise in distributed training methods (such as distributed GD or SGD) when these are enhanced with greedy communication compression techniques such as TopK. While EF was proposed almost a decade ago (Seide et al., 2014), and despite concentrated effort by the community to advance the theoretical understanding of this mechanism, there is still a lot to explore. In this work we study a modern form of error feedback called EF21 (Richtarik et al., 2021) which offers the currently best-known theoretical guarantees, under the weakest assumptions, and also works well in practice. In particular, while the theoretical communication complexity of EF21 depends on the quadratic mean of certain smoothness parameters, we improve this dependence to their arithmetic mean, which is always smaller, and can be substantially smaller, especially in
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SLIPS&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#36845;&#20195;&#21518;&#39564;&#25277;&#26679;&#23454;&#29616;&#38543;&#26426;&#23450;&#20301;&#65292;&#22635;&#34917;&#20102;&#20174;&#38750;&#26631;&#20934;&#21270;&#30446;&#26631;&#23494;&#24230;&#20013;&#25277;&#26679;&#30340;&#38382;&#39064;&#30340;&#31354;&#30333;&#12290;</title><link>https://arxiv.org/abs/2402.10758</link><description>&lt;p&gt;
&#36890;&#36807;&#36845;&#20195;&#21518;&#39564;&#25277;&#26679;&#23454;&#29616;&#38543;&#26426;&#23450;&#20301;
&lt;/p&gt;
&lt;p&gt;
Stochastic Localization via Iterative Posterior Sampling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10758
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SLIPS&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#36845;&#20195;&#21518;&#39564;&#25277;&#26679;&#23454;&#29616;&#38543;&#26426;&#23450;&#20301;&#65292;&#22635;&#34917;&#20102;&#20174;&#38750;&#26631;&#20934;&#21270;&#30446;&#26631;&#23494;&#24230;&#20013;&#25277;&#26679;&#30340;&#38382;&#39064;&#30340;&#31354;&#30333;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24314;&#31435;&#22312;&#22522;&#20110;&#24471;&#20998;&#23398;&#20064;&#30340;&#22522;&#30784;&#19978;&#65292;&#36817;&#26399;&#23545;&#38543;&#26426;&#23450;&#20301;&#25216;&#26415;&#20135;&#29983;&#20102;&#26032;&#30340;&#20852;&#36259;&#12290;&#22312;&#36825;&#20123;&#27169;&#22411;&#20013;&#65292;&#20154;&#20204;&#36890;&#36807;&#38543;&#26426;&#36807;&#31243;&#65288;&#31216;&#20026;&#35266;&#27979;&#36807;&#31243;&#65289;&#20026;&#25968;&#25454;&#20998;&#24067;&#20013;&#30340;&#26679;&#26412;&#24341;&#20837;&#22122;&#22768;&#65292;&#24182;&#36880;&#28176;&#23398;&#20064;&#19982;&#35813;&#21160;&#21147;&#23398;&#20851;&#32852;&#30340;&#21435;&#22122;&#22120;&#12290;&#38500;&#20102;&#29305;&#23450;&#24212;&#29992;&#20043;&#22806;&#65292;&#23545;&#20110;&#20174;&#38750;&#26631;&#20934;&#21270;&#30446;&#26631;&#23494;&#24230;&#20013;&#25277;&#26679;&#30340;&#38382;&#39064;&#65292;&#23545;&#38543;&#26426;&#23450;&#20301;&#30340;&#20351;&#29992;&#23578;&#26410;&#24471;&#21040;&#24191;&#27867;&#25506;&#35752;&#12290;&#26412;&#39033;&#24037;&#20316;&#26088;&#22312;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#38543;&#26426;&#23450;&#20301;&#26694;&#26550;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31867;&#26126;&#30830;&#30340;&#35266;&#27979;&#36807;&#31243;&#65292;&#19982;&#28789;&#27963;&#30340;&#21435;&#22122;&#26102;&#38388;&#34920;&#30456;&#20851;&#32852;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#23436;&#25972;&#30340;&#26041;&#27861;&#35770;&#65292;&#21363;&#8220;&#36890;&#36807;&#36845;&#20195;&#21518;&#39564;&#25277;&#26679;&#23454;&#29616;&#38543;&#26426;&#23450;&#20301;&#8221;&#65288;SLIPS&#65289;&#65292;&#20197;&#33719;&#24471;&#35813;&#21160;&#21147;&#23398;&#30340;&#36817;&#20284;&#26679;&#26412;&#65292;&#24182;&#20316;&#20026;&#21103;&#20135;&#21697;&#65292;&#26679;&#26412;&#26469;&#33258;&#30446;&#26631;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#26041;&#26696;&#22522;&#20110;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10758v1 Announce Type: cross  Abstract: Building upon score-based learning, new interest in stochastic localization techniques has recently emerged. In these models, one seeks to noise a sample from the data distribution through a stochastic process, called observation process, and progressively learns a denoiser associated to this dynamics. Apart from specific applications, the use of stochastic localization for the problem of sampling from an unnormalized target density has not been explored extensively. This work contributes to fill this gap. We consider a general stochastic localization framework and introduce an explicit class of observation processes, associated with flexible denoising schedules. We provide a complete methodology, $\textit{Stochastic Localization via Iterative Posterior Sampling}$ (SLIPS), to obtain approximate samples of this dynamics, and as a by-product, samples from the target distribution. Our scheme is based on a Markov chain Monte Carlo estimati
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#39118;&#38505;&#20998;&#35299;&#21644;&#36866;&#24403;&#35780;&#20998;&#35268;&#21017;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#26469;&#37327;&#21270;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#19981;&#21516;&#26469;&#28304;&#65292;&#24182;&#28548;&#28165;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2402.10727</link><description>&lt;p&gt;
&#36890;&#36807;&#39118;&#38505;&#20998;&#35299;&#23454;&#29616;&#20005;&#26684;&#36866;&#24403;&#35780;&#20998;&#35268;&#21017;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Predictive Uncertainty Quantification via Risk Decompositions for Strictly Proper Scoring Rules
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10727
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#39118;&#38505;&#20998;&#35299;&#21644;&#36866;&#24403;&#35780;&#20998;&#35268;&#21017;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#26469;&#37327;&#21270;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#19981;&#21516;&#26469;&#28304;&#65292;&#24182;&#28548;&#28165;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#39044;&#27979;&#27169;&#22411;&#24212;&#29992;&#20013;&#65292;&#21306;&#20998;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#26469;&#28304;&#33267;&#20851;&#37325;&#35201;&#12290;&#23613;&#31649;&#25552;&#20986;&#20102;&#35768;&#22810;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#20294;&#24182;&#27809;&#26377;&#20005;&#26684;&#30340;&#23450;&#20041;&#26469;&#35299;&#24320;&#23427;&#20204;&#12290;&#27492;&#22806;&#65292;&#19981;&#21516;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#25514;&#26045;&#20043;&#38388;&#30340;&#20851;&#31995;&#20173;&#28982;&#26377;&#20123;&#19981;&#28165;&#26224;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26681;&#26893;&#20110;&#32479;&#35745;&#25512;&#29702;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#19981;&#20165;&#20801;&#35768;&#21019;&#24314;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#36824;&#28548;&#28165;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#30456;&#20114;&#20851;&#31995;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#32479;&#35745;&#39118;&#38505;&#26469;&#21306;&#20998;aleatoric&#21644;epistemic&#19981;&#30830;&#23450;&#24615;&#25104;&#20998;&#65292;&#24182;&#21033;&#29992;&#36866;&#24403;&#30340;&#35780;&#20998;&#35268;&#21017;&#23545;&#20854;&#36827;&#34892;&#37327;&#21270;&#12290;&#20026;&#20102;&#20351;&#20854;&#22312;&#23454;&#36341;&#20013;&#26131;&#20110;&#22788;&#29702;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#36825;&#19968;&#26694;&#26550;&#20013;&#25972;&#21512;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;&#24819;&#27861;&#65292;&#24182;&#35752;&#35770;&#20102;&#25152;&#25552;&#36817;&#20284;&#30340;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10727v1 Announce Type: cross  Abstract: Distinguishing sources of predictive uncertainty is of crucial importance in the application of forecasting models across various domains. Despite the presence of a great variety of proposed uncertainty measures, there are no strict definitions to disentangle them. Furthermore, the relationship between different measures of uncertainty quantification remains somewhat unclear. In this work, we introduce a general framework, rooted in statistical reasoning, which not only allows the creation of new uncertainty measures but also clarifies their interrelations. Our approach leverages statistical risk to distinguish aleatoric and epistemic uncertainty components and utilizes proper scoring rules to quantify them. To make it practically tractable, we propose an idea to incorporate Bayesian reasoning into this framework and discuss the properties of the proposed approximation.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#19968;&#33268;&#39044;&#27979;&#26041;&#27861;&#26469;&#23398;&#20064;&#21487;&#20449;&#38598;&#21512;&#39044;&#27979;&#22120;&#30340;&#26041;&#27861;&#65292;&#33021;&#26377;&#25928;&#34920;&#31034;&#39044;&#27979;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.10723</link><description>&lt;p&gt;
&#32479;&#19968;&#30340;&#21487;&#20449;&#38598;&#21512;&#39044;&#27979;&#22120;
&lt;/p&gt;
&lt;p&gt;
Conformalized Credal Set Predictors
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10723
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#19968;&#33268;&#39044;&#27979;&#26041;&#27861;&#26469;&#23398;&#20064;&#21487;&#20449;&#38598;&#21512;&#39044;&#27979;&#22120;&#30340;&#26041;&#27861;&#65292;&#33021;&#26377;&#25928;&#34920;&#31034;&#39044;&#27979;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#20449;&#38598;&#21512;&#26159;&#34987;&#35270;&#20026;&#19981;&#30830;&#23450;&#24050;&#30693;&#30495;&#23454;&#20998;&#24067;&#30340;&#20505;&#36873;&#27010;&#29575;&#20998;&#24067;&#38598;&#21512;&#12290;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#30001;&#20110;&#21487;&#20449;&#38598;&#21512;&#33021;&#22815;&#34920;&#31034;&#39044;&#27979;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#23588;&#20854;&#26159;&#33021;&#22815;&#34920;&#31034;&#39044;&#27979;&#30340;aleatoric&#21644;epistemic&#19981;&#30830;&#23450;&#24615;&#65292;&#22240;&#27492;&#36817;&#26469;&#24050;&#32463;&#24341;&#36215;&#20102;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#35774;&#35745;&#29992;&#20110;&#23398;&#20064;&#21487;&#20449;&#38598;&#21512;&#39044;&#27979;&#22120;&#30340;&#26041;&#27861;&#20173;&#28982;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#19968;&#33268;&#39044;&#27979;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#26356;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;&#20998;&#31867;&#20219;&#21153;&#20013;&#39044;&#27979;&#21487;&#20449;&#38598;&#21512;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#26631;&#35760;&#20026;&#27010;&#29575;&#20998;&#24067;&#30340;&#35757;&#32451;&#25968;&#25454;&#12290;&#30001;&#20110;&#25105;&#20204;&#30340;&#26041;&#27861;&#32487;&#25215;&#20102;&#19968;&#33268;&#39044;&#27979;&#30340;&#35206;&#30422;&#24615;&#20445;&#35777;&#65292;&#25105;&#20204;&#30340;&#19968;&#33268;&#21487;&#20449;&#38598;&#21512;&#26377;&#24456;&#39640;&#30340;&#27010;&#29575;&#20445;&#35777;&#26159;&#26377;&#25928;&#30340;&#65288;&#32780;&#26080;&#38656;&#23545;&#27169;&#22411;&#25110;&#20998;&#24067;&#20570;&#20986;&#20219;&#20309;&#20551;&#35774;&#65289;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#33258;&#28982;&#35821;&#35328;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10723v1 Announce Type: cross  Abstract: Credal sets are sets of probability distributions that are considered as candidates for an imprecisely known ground-truth distribution. In machine learning, they have recently attracted attention as an appealing formalism for uncertainty representation, in particular due to their ability to represent both the aleatoric and epistemic uncertainty in a prediction. However, the design of methods for learning credal set predictors remains a challenging problem. In this paper, we make use of conformal prediction for this purpose. More specifically, we propose a method for predicting credal sets in the classification task, given training data labeled by probability distributions. Since our method inherits the coverage guarantees of conformal prediction, our conformal credal sets are guaranteed to be valid with high probability (without any assumptions on model or distribution). We demonstrate the applicability of our method to natural languag
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#23884;&#22871;&#30697;&#38453;&#24352;&#37327;&#27169;&#22411;&#20013;&#22810;&#35270;&#22270;&#32858;&#31867;&#30340;&#24615;&#33021;&#24046;&#36317;&#65292;&#37327;&#21270;&#20102;&#24352;&#37327;&#26041;&#27861;&#21644;&#30697;&#38453;&#26041;&#27861;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#36317;&#65292;&#24182;&#21457;&#29616;&#20102;&#23637;&#24320;&#26041;&#27861;&#30340;&#31639;&#27861;&#38408;&#20540;&#65292;&#23637;&#31034;&#20102;&#31867;&#20284;BBP&#36807;&#28193;&#34892;&#20026;&#12290;</title><link>https://arxiv.org/abs/2402.10677</link><description>&lt;p&gt;
&#22810;&#35270;&#22270;&#32858;&#31867;&#22312;&#23884;&#22871;&#30697;&#38453;&#24352;&#37327;&#27169;&#22411;&#19979;&#30340;&#24615;&#33021;&#24046;&#24322;
&lt;/p&gt;
&lt;p&gt;
Performance Gaps in Multi-view Clustering under the Nested Matrix-Tensor Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10677
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#23884;&#22871;&#30697;&#38453;&#24352;&#37327;&#27169;&#22411;&#20013;&#22810;&#35270;&#22270;&#32858;&#31867;&#30340;&#24615;&#33021;&#24046;&#36317;&#65292;&#37327;&#21270;&#20102;&#24352;&#37327;&#26041;&#27861;&#21644;&#30697;&#38453;&#26041;&#27861;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#36317;&#65292;&#24182;&#21457;&#29616;&#20102;&#23637;&#24320;&#26041;&#27861;&#30340;&#31639;&#27861;&#38408;&#20540;&#65292;&#23637;&#31034;&#20102;&#31867;&#20284;BBP&#36807;&#28193;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#26368;&#36817;&#24341;&#20837;&#30340;&#23884;&#22871;&#30697;&#38453;&#24352;&#37327;&#27169;&#22411;&#20013;&#38544;&#34255;&#30340;&#26893;&#20837;&#20449;&#21495;&#30340;&#20272;&#35745;&#65292;&#35813;&#27169;&#22411;&#26159;&#32463;&#20856;&#23574;&#23792;&#31209;&#19968;&#24352;&#37327;&#27169;&#22411;&#30340;&#25193;&#23637;&#65292;&#21463;&#22810;&#35270;&#22270;&#32858;&#31867;&#30340;&#21551;&#21457;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#22312;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;&#22522;&#20110;&#24352;&#37327;&#30340;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#35813;&#26041;&#27861;&#20381;&#36182;&#20110;&#25214;&#21040;&#26368;&#20339;&#31209;&#19968;&#36924;&#36817;&#65292;&#36825;&#26159;&#19968;&#20010;&#35745;&#31639;&#38590;&#39064;&#12290;&#19968;&#20010;&#21487;&#34892;&#30340;&#26367;&#20195;&#26041;&#27861;&#26159;&#35745;&#31639;&#35266;&#27979;&#21040;&#30340;&#24352;&#37327;&#25968;&#25454;&#23637;&#24320;&#30340;&#26368;&#20339;&#31209;&#19968;&#65288;&#30697;&#38453;&#65289;&#36924;&#36817;&#65292;&#20294;&#20854;&#24615;&#33021;&#36804;&#20170;&#20026;&#27490;&#26410;&#30693;&#12290;&#25105;&#20204;&#22312;&#36825;&#37324;&#37327;&#21270;&#20102;&#36825;&#20004;&#31181;&#26041;&#27861;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#36317;&#65292;&#29305;&#21035;&#26159;&#36890;&#36807;&#25512;&#23548;&#20986;&#23637;&#24320;&#26041;&#27861;&#30340;&#31934;&#30830;&#31639;&#27861;&#38408;&#20540;&#65292;&#24182;&#23637;&#31034;&#23427;&#23637;&#29616;&#20986;&#31867;&#20284;BBP&#36807;&#28193;&#34892;&#20026;&#12290;&#22240;&#27492;&#65292;&#36825;&#39033;&#24037;&#20316;&#19982;&#26368;&#36817;&#30340;&#36129;&#29486;&#19968;&#33268;&#65292;&#36825;&#20123;&#36129;&#29486;&#21152;&#28145;&#20102;&#25105;&#20204;&#23545;&#20026;&#20160;&#20040;&#24352;&#37327;&#26041;&#27861;&#20248;&#20110;&#30697;&#38453;&#26041;&#27861;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10677v1 Announce Type: cross  Abstract: We study the estimation of a planted signal hidden in a recently introduced nested matrix-tensor model, which is an extension of the classical spiked rank-one tensor model, motivated by multi-view clustering. Prior work has theoretically examined the performance of a tensor-based approach, which relies on finding a best rank-one approximation, a problem known to be computationally hard. A tractable alternative approach consists in computing instead the best rank-one (matrix) approximation of an unfolding of the observed tensor data, but its performance was hitherto unknown. We quantify here the performance gap between these two approaches, in particular by deriving the precise algorithmic threshold of the unfolding approach and demonstrating that it exhibits a BBP-type transition behavior. This work is therefore in line with recent contributions which deepen our understanding of why tensor-based methods surpass matrix-based methods in 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#27169;&#22411;&#65292;&#21516;&#26102;&#32771;&#34385;&#20102;&#23454;&#39564;&#20869;&#37096;&#24615;&#33021;&#21644;&#23454;&#39564;&#21518;&#32467;&#26524;&#65292;&#22312;&#20248;&#21270;&#22823;&#35268;&#27169;&#20154;&#32676;&#20013;&#30340;&#34920;&#29616;&#26041;&#38754;&#25552;&#20379;&#20102;&#23574;&#38160;&#29702;&#35770;&#65292;&#25581;&#31034;&#20102;&#26032;&#39062;&#30340;&#35265;&#35299;</title><link>https://arxiv.org/abs/2402.10592</link><description>&lt;p&gt;
&#20248;&#21270;&#33258;&#36866;&#24212;&#23454;&#39564;&#65306;&#26368;&#23567;&#21270;&#21518;&#24724;&#21644;&#26368;&#20339;&#33218;&#35782;&#21035;&#30340;&#32479;&#19968;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Optimizing Adaptive Experiments: A Unified Approach to Regret Minimization and Best-Arm Identification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10592
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#27169;&#22411;&#65292;&#21516;&#26102;&#32771;&#34385;&#20102;&#23454;&#39564;&#20869;&#37096;&#24615;&#33021;&#21644;&#23454;&#39564;&#21518;&#32467;&#26524;&#65292;&#22312;&#20248;&#21270;&#22823;&#35268;&#27169;&#20154;&#32676;&#20013;&#30340;&#34920;&#29616;&#26041;&#38754;&#25552;&#20379;&#20102;&#23574;&#38160;&#29702;&#35770;&#65292;&#25581;&#31034;&#20102;&#26032;&#39062;&#30340;&#35265;&#35299;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36827;&#34892;&#33258;&#36866;&#24212;&#23454;&#39564;&#30340;&#20174;&#19994;&#32773;&#36890;&#24120;&#38754;&#20020;&#20004;&#20010;&#31454;&#20105;&#24615;&#20248;&#20808;&#32423;&#65306;&#36890;&#36807;&#22312;&#23454;&#39564;&#36807;&#31243;&#20013;&#26377;&#25928;&#22320;&#20998;&#37197;&#27835;&#30103;&#26469;&#38477;&#20302;&#23454;&#39564;&#25104;&#26412;&#65292;&#20197;&#21450;&#36805;&#36895;&#25910;&#38598;&#20449;&#24687;&#20197;&#32467;&#26463;&#23454;&#39564;&#24182;&#22312;&#25972;&#20010;&#20154;&#32676;&#20013;&#23454;&#26045;&#27835;&#30103;&#12290;&#24403;&#21069;&#65292;&#25991;&#29486;&#24847;&#35265;&#20998;&#27495;&#65292;&#26377;&#20851;&#26368;&#23567;&#21270;&#21518;&#24724;&#30340;&#30740;&#31350;&#29420;&#31435;&#22320;&#22788;&#29702;&#21069;&#32773;&#30340;&#20248;&#20808;&#32423;&#65292;&#32780;&#26377;&#20851;&#26368;&#20339;&#33218;&#35782;&#21035;&#30340;&#30740;&#31350;&#21017;&#19987;&#27880;&#20110;&#21518;&#32773;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#27169;&#22411;&#65292;&#32771;&#34385;&#21040;&#23454;&#39564;&#20869;&#37096;&#24615;&#33021;&#21644;&#23454;&#39564;&#21518;&#32467;&#26524;&#12290;&#25105;&#20204;&#38543;&#21518;&#25552;&#20379;&#20102;&#19968;&#20010;&#38024;&#23545;&#22823;&#35268;&#27169;&#20154;&#32676;&#30340;&#26368;&#20339;&#24615;&#33021;&#30340;&#23574;&#38160;&#29702;&#35770;&#65292;&#23558;&#25991;&#29486;&#20013;&#30340;&#32463;&#20856;&#32467;&#26524;&#32479;&#19968;&#36215;&#26469;&#12290;&#36825;&#31181;&#32479;&#19968;&#36824;&#25581;&#31034;&#20102;&#26032;&#30340;&#35265;&#35299;&#12290;&#20363;&#22914;&#65292;&#29702;&#35770;&#25581;&#31034;&#20102;&#31867;&#20284;&#26368;&#36817;&#25552;&#20986;&#30340;&#39030;&#37096;&#20004;&#20010;Thompson&#25277;&#26679;&#31639;&#27861;&#31561;&#29087;&#24713;&#31639;&#27861;&#21487;&#34987;&#35843;&#25972;&#20197;&#20248;&#21270;&#24191;&#27867;&#31867;&#21035;&#30340;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10592v1 Announce Type: new  Abstract: Practitioners conducting adaptive experiments often encounter two competing priorities: reducing the cost of experimentation by effectively assigning treatments during the experiment itself, and gathering information swiftly to conclude the experiment and implement a treatment across the population. Currently, the literature is divided, with studies on regret minimization addressing the former priority in isolation, and research on best-arm identification focusing solely on the latter. This paper proposes a unified model that accounts for both within-experiment performance and post-experiment outcomes. We then provide a sharp theory of optimal performance in large populations that unifies canonical results in the literature. This unification also uncovers novel insights. For example, the theory reveals that familiar algorithms, like the recently proposed top-two Thompson sampling algorithm, can be adapted to optimize a broad class of obj
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#21644;&#36125;&#21494;&#26031;&#28155;&#21152;&#22238;&#24402;&#26641;&#20316;&#20026;&#32447;&#24615;&#24809;&#32602;&#20272;&#35745;&#30340;&#28789;&#27963;&#25193;&#23637;&#65292;&#35299;&#20915;&#20102;&#28151;&#21512;&#39057;&#29575;&#25968;&#25454;&#20013;&#30340;&#39057;&#29575;&#19981;&#21305;&#37197;&#38382;&#39064;&#65292;&#25552;&#39640;&#20102;&#29616;&#22330;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.10574</link><description>&lt;p&gt;
&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#28151;&#21512;&#39057;&#29575;&#25968;&#25454;&#30340;&#29616;&#22330;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Nowcasting with mixed frequency data using Gaussian processes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10574
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#21644;&#36125;&#21494;&#26031;&#28155;&#21152;&#22238;&#24402;&#26641;&#20316;&#20026;&#32447;&#24615;&#24809;&#32602;&#20272;&#35745;&#30340;&#28789;&#27963;&#25193;&#23637;&#65292;&#35299;&#20915;&#20102;&#28151;&#21512;&#39057;&#29575;&#25968;&#25454;&#20013;&#30340;&#39057;&#29575;&#19981;&#21305;&#37197;&#38382;&#39064;&#65292;&#25552;&#39640;&#20102;&#29616;&#22330;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#24182;&#35752;&#35770;&#20102;&#29992;&#20110;&#28151;&#21512;&#25968;&#25454;&#37319;&#26679;&#65288;MIDAS&#65289;&#22238;&#24402;&#30340;&#36125;&#21494;&#26031;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#12290;&#36825;&#28041;&#21450;&#20351;&#29992;&#21463;&#38480;&#21644;&#38750;&#21463;&#38480;&#30340;MIDAS&#21464;&#20307;&#22788;&#29702;&#39057;&#29575;&#19981;&#21305;&#37197;&#65292;&#24182;&#25351;&#23450;&#35768;&#22810;&#39044;&#27979;&#21464;&#37327;&#19982;&#22240;&#21464;&#37327;&#20043;&#38388;&#30340;&#20989;&#25968;&#20851;&#31995;&#12290;&#25105;&#20204;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#21644;&#36125;&#21494;&#26031;&#28155;&#21152;&#22238;&#24402;&#26641;&#65288;BART&#65289;&#20316;&#20026;&#32447;&#24615;&#24809;&#32602;&#20272;&#35745;&#30340;&#28789;&#27963;&#25193;&#23637;&#12290;&#22312;&#29616;&#22330;&#39044;&#27979;&#21644;&#39044;&#27979;&#32451;&#20064;&#20013;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#23395;&#24230;&#32654;&#22269;&#20135;&#20986;&#22686;&#38271;&#21644;GDP&#20215;&#26684;&#25351;&#25968;&#30340;&#36890;&#36135;&#33192;&#32960;&#12290;&#36825;&#20123;&#26032;&#27169;&#22411;&#20197;&#35745;&#31639;&#25928;&#29575;&#30340;&#26041;&#24335;&#21033;&#29992;&#23439;&#35266;&#32463;&#27982;&#22823;&#25968;&#25454;&#65292;&#24182;&#22312;&#22810;&#20010;&#32500;&#24230;&#19978;&#25552;&#20379;&#20102;&#39044;&#27979;&#20934;&#30830;&#24230;&#30340;&#22686;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10574v1 Announce Type: new  Abstract: We propose and discuss Bayesian machine learning methods for mixed data sampling (MIDAS) regressions. This involves handling frequency mismatches with restricted and unrestricted MIDAS variants and specifying functional relationships between many predictors and the dependent variable. We use Gaussian processes (GP) and Bayesian additive regression trees (BART) as flexible extensions to linear penalized estimation. In a nowcasting and forecasting exercise we focus on quarterly US output growth and inflation in the GDP deflator. The new models leverage macroeconomic Big Data in a computationally efficient way and offer gains in predictive accuracy along several dimensions.
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#30740;&#31350;&#20102;&#20108;&#27425;Littlewood-Offord&#38382;&#39064;&#30340;&#32479;&#35745;&#40065;&#26834;&#24615;&#65292;&#20272;&#35745;&#20102;&#23545;&#25239;&#24615;&#22122;&#22768;&#23545;&#20108;&#27425;Radamecher&#28151;&#27788;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#20108;&#27425;&#21644;&#21452;&#32447;&#24615;Rademacher&#28151;&#27788;&#30340;&#32479;&#35745;&#40065;&#26834;&#24615;&#30340;&#19979;&#38480;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2402.10504</link><description>&lt;p&gt;
&#20108;&#27425;Littlewood-Offord&#38382;&#39064;&#30340;&#24377;&#24615;
&lt;/p&gt;
&lt;p&gt;
Resilience of the quadratic Littlewood-Offord problem
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10504
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#30740;&#31350;&#20102;&#20108;&#27425;Littlewood-Offord&#38382;&#39064;&#30340;&#32479;&#35745;&#40065;&#26834;&#24615;&#65292;&#20272;&#35745;&#20102;&#23545;&#25239;&#24615;&#22122;&#22768;&#23545;&#20108;&#27425;Radamecher&#28151;&#27788;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#20108;&#27425;&#21644;&#21452;&#32447;&#24615;Rademacher&#28151;&#27788;&#30340;&#32479;&#35745;&#40065;&#26834;&#24615;&#30340;&#19979;&#38480;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#39640;&#32500;&#25968;&#25454;&#30340;&#32479;&#35745;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25552;&#20379;&#20102;&#20851;&#20110;&#23545;&#25239;&#24615;&#22122;&#22768;&#23545;&#20108;&#27425;Radamecher&#28151;&#27788;$\boldsymbol{\xi}^{\mathsf{T}} M \boldsymbol{\xi}$&#21453;&#38598;&#20013;&#29305;&#24615;&#30340;&#24433;&#21709;&#30340;&#20272;&#35745;&#65292;&#20854;&#20013;$M$&#26159;&#19968;&#20010;&#22266;&#23450;&#30340;&#65288;&#39640;&#32500;&#65289;&#30697;&#38453;&#65292;$\boldsymbol{\xi}$&#26159;&#19968;&#20010;&#20849;&#24418;Rademacher&#21521;&#37327;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;$\boldsymbol{\xi}$&#33021;&#22815;&#25215;&#21463;&#22810;&#23569;&#23545;&#25239;&#24615;&#31526;&#21495;&#32763;&#36716;&#32780;&#19981;&#8220;&#33192;&#32960;&#8221;$\sup_{x\in \mathbb{R}} \mathbb{P} \left\{\boldsymbol{\xi}^{\mathsf{T}} M \boldsymbol{\xi} = x\right\}$&#65292;&#20174;&#32780;&#8220;&#21435;&#38500;&#8221;&#21407;&#22987;&#20998;&#24067;&#23548;&#33268;&#26356;&#8220;&#26377;&#31890;&#24230;&#8221;&#21644;&#23545;&#25239;&#24615;&#20559;&#20506;&#30340;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20026;&#20108;&#27425;&#21644;&#21452;&#32447;&#24615;Rademacher&#28151;&#27788;&#30340;&#32479;&#35745;&#40065;&#26834;&#24615;&#25552;&#20379;&#20102;&#19979;&#38480;&#20272;&#35745;&#65307;&#36825;&#20123;&#32467;&#26524;&#22312;&#20851;&#38190;&#21306;&#22495;&#34987;&#35777;&#26126;&#26159;&#28176;&#36817;&#32039;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10504v1 Announce Type: cross  Abstract: We study the statistical resilience of high-dimensional data. Our results provide estimates as to the effects of adversarial noise over the anti-concentration properties of the quadratic Radamecher chaos $\boldsymbol{\xi}^{\mathsf{T}} M \boldsymbol{\xi}$, where $M$ is a fixed (high-dimensional) matrix and $\boldsymbol{\xi}$ is a conformal Rademacher vector. Specifically, we pursue the question of how many adversarial sign-flips can $\boldsymbol{\xi}$ sustain without "inflating" $\sup_{x\in \mathbb{R}} \mathbb{P} \left\{\boldsymbol{\xi}^{\mathsf{T}} M \boldsymbol{\xi} = x\right\}$ and thus "de-smooth" the original distribution resulting in a more "grainy" and adversarially biased distribution. Our results provide lower bound estimations for the statistical resilience of the quadratic and bilinear Rademacher chaos; these are shown to be asymptotically tight across key regimes.
&lt;/p&gt;</description></item><item><title>&#33258;&#33976;&#39311;&#22312;&#22810;&#31867;&#21035;&#20998;&#31867;&#20013;&#25198;&#28436;&#30528;&#26631;&#31614;&#24179;&#22343;&#21270;&#30340;&#35282;&#33394;&#65292;&#26377;&#21161;&#20110;&#27169;&#22411;&#20851;&#27880;&#19982;&#29305;&#23450;&#23454;&#20363;&#30456;&#20851;&#30340;&#29305;&#24449;&#31751;&#20197;&#39044;&#27979;&#26631;&#31614;&#65292;&#20294;&#38543;&#30528;&#33976;&#39311;&#36718;&#27425;&#22686;&#21152;&#65292;&#24615;&#33021;&#20250;&#38477;&#20302;&#12290;&#27492;&#22806;&#65292;&#22312;&#26631;&#31614;&#22122;&#22768;&#24773;&#26223;&#19979;&#33258;&#33976;&#39311;&#34987;&#35777;&#26126;&#26159;&#26377;&#25928;&#30340;&#65292;&#25214;&#21040;&#20102;&#23454;&#29616;100%&#20998;&#31867;&#20934;&#30830;&#29575;&#25152;&#38656;&#30340;&#26368;&#23567;&#33976;&#39311;&#36718;&#27425;&#12290;</title><link>https://arxiv.org/abs/2402.10482</link><description>&lt;p&gt;
&#29702;&#35299;&#24102;&#26377;&#26631;&#31614;&#22122;&#38899;&#30340;&#22810;&#31867;&#21035;&#20998;&#31867;&#20013;&#30340;&#33258;&#33976;&#39311;&#21644;&#37096;&#20998;&#26631;&#31614;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Understanding Self-Distillation and Partial Label Learning in Multi-Class Classification with Label Noise
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10482
&lt;/p&gt;
&lt;p&gt;
&#33258;&#33976;&#39311;&#22312;&#22810;&#31867;&#21035;&#20998;&#31867;&#20013;&#25198;&#28436;&#30528;&#26631;&#31614;&#24179;&#22343;&#21270;&#30340;&#35282;&#33394;&#65292;&#26377;&#21161;&#20110;&#27169;&#22411;&#20851;&#27880;&#19982;&#29305;&#23450;&#23454;&#20363;&#30456;&#20851;&#30340;&#29305;&#24449;&#31751;&#20197;&#39044;&#27979;&#26631;&#31614;&#65292;&#20294;&#38543;&#30528;&#33976;&#39311;&#36718;&#27425;&#22686;&#21152;&#65292;&#24615;&#33021;&#20250;&#38477;&#20302;&#12290;&#27492;&#22806;&#65292;&#22312;&#26631;&#31614;&#22122;&#22768;&#24773;&#26223;&#19979;&#33258;&#33976;&#39311;&#34987;&#35777;&#26126;&#26159;&#26377;&#25928;&#30340;&#65292;&#25214;&#21040;&#20102;&#23454;&#29616;100%&#20998;&#31867;&#20934;&#30830;&#29575;&#25152;&#38656;&#30340;&#26368;&#23567;&#33976;&#39311;&#36718;&#27425;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#33976;&#39311;&#65288;SD&#65289;&#26159;&#20351;&#29992;&#25945;&#24072;&#27169;&#22411;&#30340;&#36755;&#20986;&#35757;&#32451;&#23398;&#29983;&#27169;&#22411;&#30340;&#36807;&#31243;&#65292;&#20004;&#20010;&#27169;&#22411;&#20849;&#20139;&#30456;&#21516;&#30340;&#26550;&#26500;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#20174;&#29702;&#35770;&#19978;&#32771;&#23519;&#20102;&#20351;&#29992;&#20132;&#21449;&#29109;&#25439;&#22833;&#30340;&#22810;&#31867;&#21035;&#20998;&#31867;&#20013;&#30340;SD&#65292;&#25506;&#32034;&#20102;&#22810;&#36718;SD&#21644;&#20855;&#26377;&#31934;&#28860;&#25945;&#24072;&#36755;&#20986;&#30340;SD&#65292;&#36825;&#20123;&#28789;&#24863;&#26469;&#33258;&#37096;&#20998;&#26631;&#31614;&#23398;&#20064;&#65288;PLL&#65289;&#12290;&#36890;&#36807;&#25512;&#23548;&#23398;&#29983;&#27169;&#22411;&#36755;&#20986;&#30340;&#23553;&#38381;&#24418;&#24335;&#35299;&#65292;&#25105;&#20204;&#21457;&#29616;SD&#26412;&#36136;&#19978;&#26159;&#22312;&#20855;&#26377;&#39640;&#29305;&#24449;&#30456;&#20851;&#24615;&#30340;&#23454;&#20363;&#20043;&#38388;&#36827;&#34892;&#26631;&#31614;&#24179;&#22343;&#12290;&#26368;&#21021;&#26377;&#30410;&#30340;&#24179;&#22343;&#21270;&#26377;&#21161;&#20110;&#27169;&#22411;&#19987;&#27880;&#20110;&#19982;&#32473;&#23450;&#23454;&#20363;&#30456;&#20851;&#32852;&#30340;&#29305;&#24449;&#31751;&#20197;&#39044;&#27979;&#26631;&#31614;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#33976;&#39311;&#36718;&#27425;&#30340;&#22686;&#21152;&#65292;&#24615;&#33021;&#20250;&#19979;&#38477;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;SD&#22312;&#26631;&#31614;&#22122;&#22768;&#24773;&#26223;&#20013;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#30830;&#23450;&#23454;&#29616;100%&#20998;&#31867;&#20934;&#30830;&#29575;&#25152;&#38656;&#30340;&#26631;&#31614;&#25439;&#22351;&#26465;&#20214;&#21644;&#26368;&#23567;&#33976;&#39311;&#36718;&#27425;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10482v1 Announce Type: new  Abstract: Self-distillation (SD) is the process of training a student model using the outputs of a teacher model, with both models sharing the same architecture. Our study theoretically examines SD in multi-class classification with cross-entropy loss, exploring both multi-round SD and SD with refined teacher outputs, inspired by partial label learning (PLL). By deriving a closed-form solution for the student model's outputs, we discover that SD essentially functions as label averaging among instances with high feature correlations. Initially beneficial, this averaging helps the model focus on feature clusters correlated with a given instance for predicting the label. However, it leads to diminishing performance with increasing distillation rounds. Additionally, we demonstrate SD's effectiveness in label noise scenarios and identify the label corruption condition and minimum number of distillation rounds needed to achieve 100% classification accur
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#27491;&#21017;&#21270;&#22238;&#24402;&#65292;&#22312;&#36229;&#21442;&#25968;&#21270;&#33539;&#22260;&#20869;&#65292;&#26681;&#25454;&#29305;&#23450;&#36873;&#25321;&#30340;&#20984;&#20989;&#25968;&#24182;&#36866;&#24403;&#22686;&#21152;&#19968;&#20010;&#27491;&#21017;&#21270;&#39033;&#65292;&#21487;&#20197;&#23454;&#29616;&#31232;&#30095;&#21644;&#19968;&#20301;&#35299;&#20915;&#26041;&#26696;&#65292;&#20854;&#24615;&#33021;&#20960;&#20046;&#19982;&#26368;&#20339;&#20998;&#31867;&#24615;&#33021;&#30456;&#21516;&#12290;</title><link>https://arxiv.org/abs/2402.10474</link><description>&lt;p&gt;
&#19968;&#20301;&#37327;&#21270;&#21644;&#31232;&#30095;&#21270;&#29992;&#20110;&#22810;&#31867;&#32447;&#24615;&#20998;&#31867;&#30340;&#27491;&#21017;&#21270;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
One-Bit Quantization and Sparsification for Multiclass Linear Classification via Regularized Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10474
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#27491;&#21017;&#21270;&#22238;&#24402;&#65292;&#22312;&#36229;&#21442;&#25968;&#21270;&#33539;&#22260;&#20869;&#65292;&#26681;&#25454;&#29305;&#23450;&#36873;&#25321;&#30340;&#20984;&#20989;&#25968;&#24182;&#36866;&#24403;&#22686;&#21152;&#19968;&#20010;&#27491;&#21017;&#21270;&#39033;&#65292;&#21487;&#20197;&#23454;&#29616;&#31232;&#30095;&#21644;&#19968;&#20301;&#35299;&#20915;&#26041;&#26696;&#65292;&#20854;&#24615;&#33021;&#20960;&#20046;&#19982;&#26368;&#20339;&#20998;&#31867;&#24615;&#33021;&#30456;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#24615;&#22238;&#24402;&#20013;&#29992;&#20110;&#22810;&#31867;&#20998;&#31867;&#30340;&#38382;&#39064;&#65292;&#36825;&#20123;&#38382;&#39064;&#22312;&#36229;&#21442;&#25968;&#21270;&#33539;&#22260;&#20869;&#65292;&#35757;&#32451;&#25968;&#25454;&#20013;&#19968;&#20123;&#26631;&#35760;&#38169;&#35823;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20026;&#20102;&#36991;&#20813;&#36807;&#24230;&#25311;&#21512;&#38169;&#35823;&#26631;&#35760;&#30340;&#25968;&#25454;&#65292;&#38656;&#35201;&#28155;&#21152;&#19968;&#20010;&#26174;&#24335;&#30340;&#27491;&#21017;&#21270;&#39033;&#65292;$\lambda f(w)$&#65292;&#20854;&#20013;$f(\cdot)$&#26159;&#26576;&#20010;&#20984;&#20989;&#25968;&#12290;&#22312;&#25105;&#20204;&#30340;&#20998;&#26512;&#20013;&#65292;&#25105;&#20204;&#20551;&#35774;&#25968;&#25454;&#26159;&#20174;&#19968;&#20010;&#20855;&#26377;&#30456;&#31561;&#31867;&#22823;&#23567;&#30340;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20013;&#37319;&#26679;&#30340;&#65292;&#24182;&#19988;&#27599;&#20010;&#31867;&#21035;&#30340;&#35757;&#32451;&#26631;&#31614;&#20013;&#26377;&#19968;&#37096;&#20998;&#27604;&#20363;&#20026;$c$&#26159;&#38169;&#35823;&#30340;&#12290;&#22312;&#36825;&#20123;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;$f(\cdot) = \|\cdot\|^2_2$&#19988;$\lambda \to \infty$&#26102;&#65292;&#21487;&#20197;&#33719;&#24471;&#26368;&#20339;&#30340;&#20998;&#31867;&#24615;&#33021;&#12290;&#28982;&#21518;&#25105;&#20204;&#32487;&#32493;&#20998;&#26512;&#20102;&#22312;&#22823;$\lambda$&#33539;&#22260;&#20869;$f(\cdot) = \|\cdot\|_1$&#21644;$f(\cdot) = \|\cdot\|_\infty$&#30340;&#20998;&#31867;&#38169;&#35823;&#65292;&#24182;&#19988;&#27880;&#24847;&#21040;&#36890;&#24120;&#21487;&#20197;&#25214;&#21040;&#31232;&#30095;&#21644;&#19968;&#20301;&#35299;&#20915;&#26041;&#26696;&#65292;&#20998;&#21035;&#34920;&#29616;&#20960;&#20046;&#19982;$f(\cdot) = \|\cdot\|^2_2$&#30456;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10474v1 Announce Type: new  Abstract: We study the use of linear regression for multiclass classification in the over-parametrized regime where some of the training data is mislabeled. In such scenarios it is necessary to add an explicit regularization term, $\lambda f(w)$, for some convex function $f(\cdot)$, to avoid overfitting the mislabeled data. In our analysis, we assume that the data is sampled from a Gaussian Mixture Model with equal class sizes, and that a proportion $c$ of the training labels is corrupted for each class. Under these assumptions, we prove that the best classification performance is achieved when $f(\cdot) = \|\cdot\|^2_2$ and $\lambda \to \infty$. We then proceed to analyze the classification errors for $f(\cdot) = \|\cdot\|_1$ and $f(\cdot) = \|\cdot\|_\infty$ in the large $\lambda$ regime and notice that it is often possible to find sparse and one-bit solutions, respectively, that perform almost as well as the one corresponding to $f(\cdot) = \|\
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#34920;&#26126;&#21508;&#31181;&#23545;&#25239;&#24615;&#25200;&#21160;&#65288;&#29978;&#33267;&#26159;&#20960;&#20010;&#20687;&#32032;&#30340;&#25200;&#21160;&#65289;&#21253;&#21547;&#36275;&#22815;&#30340;&#31867;&#29305;&#24449;&#29992;&#20110;&#27867;&#21270;&#65292;&#36827;&#19968;&#27493;&#25581;&#31034;&#20102;&#20174;&#25200;&#21160;&#20013;&#23398;&#20064;&#26102;&#30340;&#20915;&#31574;&#36793;&#30028;</title><link>https://arxiv.org/abs/2402.10470</link><description>&lt;p&gt;
&#23545;&#20174;&#23545;&#25239;&#24615;&#25200;&#21160;&#20013;&#23398;&#20064;&#30340;&#29702;&#35770;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Theoretical Understanding of Learning from Adversarial Perturbations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10470
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#34920;&#26126;&#21508;&#31181;&#23545;&#25239;&#24615;&#25200;&#21160;&#65288;&#29978;&#33267;&#26159;&#20960;&#20010;&#20687;&#32032;&#30340;&#25200;&#21160;&#65289;&#21253;&#21547;&#36275;&#22815;&#30340;&#31867;&#29305;&#24449;&#29992;&#20110;&#27867;&#21270;&#65292;&#36827;&#19968;&#27493;&#25581;&#31034;&#20102;&#20174;&#25200;&#21160;&#20013;&#23398;&#20064;&#26102;&#30340;&#20915;&#31574;&#36793;&#30028;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23578;&#26410;&#23436;&#20840;&#29702;&#35299;&#20026;&#20160;&#20040;&#23545;&#25239;&#24615;&#31034;&#20363;&#21487;&#20197;&#27450;&#39575;&#31070;&#32463;&#32593;&#32476;&#24182;&#22312;&#19981;&#21516;&#32593;&#32476;&#20043;&#38388;&#20256;&#36882;&#12290;&#20026;&#20102;&#38416;&#26126;&#36825;&#19968;&#28857;&#65292;&#20960;&#39033;&#30740;&#31350;&#20551;&#35774;&#65292;&#23613;&#31649;&#23545;&#25239;&#24615;&#25200;&#21160;&#30475;&#20284;&#26159;&#22122;&#38899;&#65292;&#20294;&#23454;&#38469;&#19978;&#21253;&#21547;&#31867;&#29305;&#24449;&#12290;&#36825;&#24471;&#21040;&#20102;&#36890;&#36807;&#23454;&#35777;&#35777;&#25454;&#25903;&#25345;&#65292;&#21363;&#23545;&#20110;&#22312;&#38169;&#35823;&#26631;&#35760;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#19978;&#35757;&#32451;&#30340;&#32593;&#32476;&#20173;&#28982;&#21487;&#20197;&#24456;&#22909;&#22320;&#25512;&#24191;&#21040;&#27491;&#30830;&#26631;&#35760;&#30340;&#27979;&#35797;&#26679;&#26412;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#25200;&#21160;&#22914;&#20309;&#21253;&#21547;&#31867;&#29305;&#24449;&#24182;&#20419;&#36827;&#27867;&#21270;&#30340;&#29702;&#35770;&#29702;&#35299;&#26159;&#26377;&#38480;&#30340;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#29992;&#20110;&#29702;&#35299;&#36890;&#36807;&#22312;&#30456;&#20114;&#27491;&#20132;&#26679;&#26412;&#19978;&#35757;&#32451;&#30340;&#21333;&#38544;&#34255;&#23618;&#32593;&#32476;&#20174;&#25200;&#21160;&#20013;&#23398;&#20064;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#31361;&#26174;&#20102;&#21508;&#31181;&#23545;&#25239;&#24615;&#25200;&#21160;&#65292;&#29978;&#33267;&#26159;&#20960;&#20010;&#20687;&#32032;&#30340;&#25200;&#21160;&#65292;&#22343;&#21253;&#21547;&#36275;&#22815;&#30340;&#31867;&#29305;&#24449;&#29992;&#20110;&#27867;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#20174;&#25200;&#21160;&#23398;&#20064;&#26102;&#30340;&#20915;&#31574;&#36793;&#30028;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10470v1 Announce Type: new  Abstract: It is not fully understood why adversarial examples can deceive neural networks and transfer between different networks. To elucidate this, several studies have hypothesized that adversarial perturbations, while appearing as noises, contain class features. This is supported by empirical evidence showing that networks trained on mislabeled adversarial examples can still generalize well to correctly labeled test samples. However, a theoretical understanding of how perturbations include class features and contribute to generalization is limited. In this study, we provide a theoretical framework for understanding learning from perturbations using a one-hidden-layer network trained on mutually orthogonal samples. Our results highlight that various adversarial perturbations, even perturbations of a few pixels, contain sufficient class features for generalization. Moreover, we reveal that the decision boundary when learning from perturbations m
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;POTNet&#30340;&#29983;&#25104;&#24314;&#27169;&#32593;&#32476;&#65292;&#22522;&#20110;&#36793;&#32536;&#24809;&#32602;&#30340;Wasserstein&#25439;&#22833;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#24314;&#27169;&#21516;&#26102;&#21253;&#21547;&#20998;&#31867;&#21644;&#36830;&#32493;&#29305;&#24449;&#30340;&#34920;&#26684;&#25968;&#25454;&#12290;</title><link>https://arxiv.org/abs/2402.10456</link><description>&lt;p&gt;
&#36890;&#36807;&#24809;&#32602;&#26368;&#20248;&#36755;&#36816;&#32593;&#32476;&#23545;&#34920;&#26684;&#25968;&#25454;&#36827;&#34892;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Generative Modeling for Tabular Data via Penalized Optimal Transport Network
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10456
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;POTNet&#30340;&#29983;&#25104;&#24314;&#27169;&#32593;&#32476;&#65292;&#22522;&#20110;&#36793;&#32536;&#24809;&#32602;&#30340;Wasserstein&#25439;&#22833;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#24314;&#27169;&#21516;&#26102;&#21253;&#21547;&#20998;&#31867;&#21644;&#36830;&#32493;&#29305;&#24449;&#30340;&#34920;&#26684;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20934;&#30830;&#23398;&#20064;&#34920;&#26684;&#25968;&#25454;&#20013;&#34892;&#30340;&#27010;&#29575;&#20998;&#24067;&#24182;&#29983;&#25104;&#30495;&#23454;&#30340;&#21512;&#25104;&#26679;&#26412;&#30340;&#20219;&#21153;&#26082;&#20851;&#38190;&#21448;&#38750;&#24179;&#20961;&#12290;Wasserstein&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;(WGAN)&#22312;&#29983;&#25104;&#24314;&#27169;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#35299;&#20915;&#20102;&#20854;&#21069;&#36523;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#25152;&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#34920;&#26684;&#25968;&#25454;&#20013;&#23384;&#22312;&#28151;&#21512;&#25968;&#25454;&#31867;&#22411;&#21644;&#22810;&#27169;&#24577;&#24615;&#65292;&#29983;&#25104;&#22120;&#21644;&#37492;&#21035;&#22120;&#20043;&#38388;&#30340;&#24494;&#22937;&#24179;&#34913;&#20197;&#21450;Wasserstein&#36317;&#31163;&#22312;&#39640;&#32500;&#24230;&#20013;&#30340;&#22266;&#26377;&#19981;&#31283;&#23450;&#24615;&#65292;WGAN&#36890;&#24120;&#26080;&#27861;&#29983;&#25104;&#39640;&#20445;&#30495;&#26679;&#26412;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;POTNet&#65288;&#24809;&#32602;&#26368;&#20248;&#36755;&#36816;&#32593;&#32476;&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#26032;&#39062;&#12289;&#24378;&#22823;&#19988;&#21487;&#35299;&#37322;&#30340;&#36793;&#38469;&#24809;&#32602;Wasserstein&#65288;MPW&#65289;&#25439;&#22833;&#30340;&#29983;&#25104;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#12290;POTNet&#33021;&#22815;&#26377;&#25928;&#22320;&#24314;&#27169;&#21253;&#21547;&#20998;&#31867;&#21644;&#36830;&#32493;&#29305;&#24449;&#30340;&#34920;&#26684;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10456v1 Announce Type: cross  Abstract: The task of precisely learning the probability distribution of rows within tabular data and producing authentic synthetic samples is both crucial and non-trivial. Wasserstein generative adversarial network (WGAN) marks a notable improvement in generative modeling, addressing the challenges faced by its predecessor, generative adversarial network. However, due to the mixed data types and multimodalities prevalent in tabular data, the delicate equilibrium between the generator and discriminator, as well as the inherent instability of Wasserstein distance in high dimensions, WGAN often fails to produce high-fidelity samples. To this end, we propose POTNet (Penalized Optimal Transport Network), a generative deep neural network based on a novel, robust, and interpretable marginally-penalized Wasserstein (MPW) loss. POTNet can effectively model tabular data containing both categorical and continuous features. Moreover, it offers the flexibil
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#20351;&#29992;&#19981;&#21516;&#26631;&#27880;&#20989;&#25968;&#30340;&#21327;&#20316;&#23398;&#20064;&#20013;&#65292;&#22522;&#20110;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31639;&#27861;&#22312;&#22686;&#24378;&#20551;&#35774;&#31867;&#19978;&#30340;&#39640;&#25928;&#23398;&#20064;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.10445</link><description>&lt;p&gt;
&#20351;&#29992;&#19981;&#21516;&#26631;&#27880;&#20989;&#25968;&#30340;&#21327;&#20316;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Collaborative Learning with Different Labeling Functions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10445
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#20351;&#29992;&#19981;&#21516;&#26631;&#27880;&#20989;&#25968;&#30340;&#21327;&#20316;&#23398;&#20064;&#20013;&#65292;&#22522;&#20110;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31639;&#27861;&#22312;&#22686;&#24378;&#20551;&#35774;&#31867;&#19978;&#30340;&#39640;&#25928;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181; Collaborative PAC Learning &#30340;&#21464;&#20307;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#26088;&#22312;&#23398;&#20064;&#27599;&#20010;$n$&#20010;&#25968;&#25454;&#20998;&#24067;&#30340;&#20934;&#30830;&#20998;&#31867;&#22120;&#65292;&#21516;&#26102;&#26368;&#23567;&#21270;&#20174;&#23427;&#20204;&#24635;&#20849;&#25277;&#21462;&#30340;&#26679;&#26412;&#25968;&#37327;&#12290;&#19982;&#36890;&#24120;&#30340;&#21327;&#20316;&#23398;&#20064;&#35774;&#32622;&#19981;&#21516;&#65292;&#19981;&#20551;&#35774;&#23384;&#22312;&#19968;&#20010;&#21516;&#26102;&#23545;&#25152;&#26377;&#20998;&#24067;&#20934;&#30830;&#30340;&#21333;&#19968;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#24403;&#25968;&#25454;&#20998;&#24067;&#28385;&#36275;&#36739;&#24369;&#30340;&#21487;&#23454;&#29616;&#24615;&#20551;&#35774;&#26102;&#65292;&#20173;&#28982;&#21487;&#20197;&#23454;&#29616;&#39640;&#25928;&#30340;&#23398;&#20064;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;(ERM)&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#24212;&#29992;&#20110;&#20551;&#35774;&#31867;&#30340;&#19968;&#20010;&#33258;&#28982;&#22686;&#24378;&#65292;&#20998;&#26512;&#20381;&#36182;&#20110;&#23545;&#35813;&#22686;&#24378;&#31867;&#30340;VC&#32500;&#30340;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10445v1 Announce Type: new  Abstract: We study a variant of Collaborative PAC Learning, in which we aim to learn an accurate classifier for each of the $n$ data distributions, while minimizing the number of samples drawn from them in total. Unlike in the usual collaborative learning setup, it is not assumed that there exists a single classifier that is simultaneously accurate for all distributions.   We show that, when the data distributions satisfy a weaker realizability assumption, sample-efficient learning is still feasible. We give a learning algorithm based on Empirical Risk Minimization (ERM) on a natural augmentation of the hypothesis class, and the analysis relies on an upper bound on the VC dimension of this augmented class.   In terms of the computational efficiency, we show that ERM on the augmented hypothesis class is NP-hard, which gives evidence against the existence of computationally efficient learners in general. On the positive side, for two special cases, 
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#22312;&#36125;&#21494;&#26031;&#35774;&#32622;&#20013;&#25506;&#35752;&#20102;&#22266;&#23450;&#32622;&#20449;&#24230;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#20256;&#32479;&#39057;&#29575;&#35774;&#23450;&#19979;&#30340;&#31639;&#27861;&#22312;&#27492;&#35774;&#32622;&#19979;&#34920;&#29616;&#27425;&#20248;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#24615;&#33021;&#19982;&#29702;&#35770;&#19979;&#38480;&#30456;&#21305;&#37197;&#30340;&#36830;&#32493;&#25490;&#38500;&#21464;&#31181;&#12290;</title><link>https://arxiv.org/abs/2402.10429</link><description>&lt;p&gt;
&#22312;&#36125;&#21494;&#26031;&#35774;&#32622;&#20013;&#30340;&#22266;&#23450;&#32622;&#20449;&#24230;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Fixed Confidence Best Arm Identification in the Bayesian Setting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10429
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#22312;&#36125;&#21494;&#26031;&#35774;&#32622;&#20013;&#25506;&#35752;&#20102;&#22266;&#23450;&#32622;&#20449;&#24230;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#20256;&#32479;&#39057;&#29575;&#35774;&#23450;&#19979;&#30340;&#31639;&#27861;&#22312;&#27492;&#35774;&#32622;&#19979;&#34920;&#29616;&#27425;&#20248;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#24615;&#33021;&#19982;&#29702;&#35770;&#19979;&#38480;&#30456;&#21305;&#37197;&#30340;&#36830;&#32493;&#25490;&#38500;&#21464;&#31181;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#36125;&#21494;&#26031;&#35774;&#32622;&#20013;&#30340;&#22266;&#23450;&#32622;&#20449;&#24230;&#26368;&#20339;&#33218;&#35782;&#21035;&#65288;FC-BAI&#65289;&#38382;&#39064;&#12290;&#35813;&#38382;&#39064;&#26088;&#22312;&#22312;&#24050;&#30693;&#20808;&#39564;&#37319;&#26679;&#30340;&#24773;&#20917;&#19979;&#20197;&#22266;&#23450;&#32622;&#20449;&#27700;&#24179;&#25214;&#21040;&#22343;&#20540;&#26368;&#22823;&#30340;&#33218;&#12290;&#22823;&#22810;&#25968;&#20851;&#20110;FC-BAI&#38382;&#39064;&#30340;&#30740;&#31350;&#37117;&#26159;&#22312;&#39057;&#29575;&#35774;&#23450;&#20013;&#36827;&#34892;&#30340;&#65292;&#22312;&#35813;&#35774;&#23450;&#19979;&#65292;&#28216;&#25103;&#24320;&#22987;&#21069;&#21363;&#30830;&#23450;&#20102;&#36172;&#21338;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#36125;&#21494;&#26031;&#35774;&#32622;&#20013;&#65292;&#20256;&#32479;&#30340;&#22312;&#39057;&#29575;&#35774;&#23450;&#20013;&#30740;&#31350;&#30340;FC-BAI&#31639;&#27861;&#65288;&#22914;track-and-stop&#21644;top-two&#31639;&#27861;&#65289;&#20250;&#23548;&#33268;&#20219;&#24847;&#27425;&#20248;&#30340;&#34920;&#29616;&#12290;&#25105;&#20204;&#21516;&#26102;&#35777;&#26126;&#20102;&#22312;&#36125;&#21494;&#26031;&#35774;&#32622;&#19979;&#39044;&#26399;&#26679;&#26412;&#25968;&#30340;&#19979;&#38480;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#36830;&#32493;&#25490;&#38500;&#30340;&#21464;&#31181;&#65292;&#20854;&#24615;&#33021;&#19982;&#19979;&#38480;&#30456;&#21305;&#37197;&#65292;&#26368;&#22810;&#24046;&#19968;&#20010;&#23545;&#25968;&#22240;&#23376;&#12290;&#20223;&#30495;&#39564;&#35777;&#20102;&#29702;&#35770;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10429v1 Announce Type: cross  Abstract: We consider the fixed-confidence best arm identification (FC-BAI) problem in the Bayesian Setting. This problem aims to find the arm of the largest mean with a fixed confidence level when the bandit model has been sampled from the known prior. Most studies on the FC-BAI problem have been conducted in the frequentist setting, where the bandit model is predetermined before the game starts. We show that the traditional FC-BAI algorithms studied in the frequentist setting, such as track-and-stop and top-two algorithms, result in arbitrary suboptimal performances in the Bayesian setting. We also prove a lower bound of the expected number of samples in the Bayesian setting and introduce a variant of successive elimination that has a matching performance with the lower bound up to a logarithmic factor. Simulations verify the theoretical results.
&lt;/p&gt;</description></item><item><title>&#30417;&#30563;&#23398;&#20064;&#38382;&#39064;&#30340;&#22256;&#38590;&#24615;&#20855;&#26377;&#32039;&#20945;&#30340;&#26377;&#38480;&#29305;&#24615;&#34920;&#24449;&#12290;</title><link>https://arxiv.org/abs/2402.10360</link><description>&lt;p&gt;
&#23398;&#20064;&#24615;&#26159;&#19968;&#31181;&#32039;&#20945;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
Learnability is a Compact Property
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10360
&lt;/p&gt;
&lt;p&gt;
&#30417;&#30563;&#23398;&#20064;&#38382;&#39064;&#30340;&#22256;&#38590;&#24615;&#20855;&#26377;&#32039;&#20945;&#30340;&#26377;&#38480;&#29305;&#24615;&#34920;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20851;&#20110;&#23398;&#20064;&#30340;&#24037;&#20316;&#21462;&#24471;&#20102;&#19968;&#20010;&#24341;&#20154;&#27880;&#30446;&#30340;&#32467;&#26524;&#65306;&#21508;&#31181;&#38382;&#39064;&#30340;&#21487;&#23398;&#20064;&#24615;&#21487;&#33021;&#26159;&#19981;&#21487;&#21028;&#23450;&#30340;&#65292;&#25110;&#32773;&#19982;&#26631;&#20934;&#38598;&#21512;&#35770;ZFC&#20844;&#29702;&#26080;&#20851;&#12290;&#27492;&#22806;&#65292;&#36825;&#31181;&#38382;&#39064;&#30340;&#21487;&#23398;&#20064;&#24615;&#21487;&#33021;&#19981;&#26159;&#20855;&#26377;&#26377;&#38480;&#29305;&#24615;&#30340;&#23646;&#24615;&#65306;&#38750;&#27491;&#24335;&#22320;&#35828;&#65292;&#23427;&#19981;&#33021;&#36890;&#36807;&#26816;&#26597;&#38382;&#39064;&#30340;&#26377;&#38480;&#25237;&#24433;&#26469;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10360v1 Announce Type: new  Abstract: Recent work on learning has yielded a striking result: the learnability of various problems can be undecidable, or independent of the standard ZFC axioms of set theory. Furthermore, the learnability of such problems can fail to be a property of finite character: informally, it cannot be detected by examining finite projections of the problem.   On the other hand, learning theory abounds with notions of dimension that characterize learning and consider only finite restrictions of the problem, i.e., are properties of finite character. How can these results be reconciled? More precisely, which classes of learning problems are vulnerable to logical undecidability, and which are within the grasp of finite characterizations?   We demonstrate that the difficulty of supervised learning with metric losses admits a tight finite characterization. In particular, we prove that the sample complexity of learning a hypothesis class can be detected by ex
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;Langevin MCMC&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#39640;&#25928;&#37319;&#26679;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#36845;&#20195;&#27493;&#25968;&#20026;$\tilde{O}(\epsilon^{-2})$&#26102;&#65292;Langevin MCMC&#30340;&#36845;&#20195;&#20250;&#19982;&#30446;&#26631;&#20998;&#24067;&#22312;$\epsilon$-Wasserstein&#36317;&#31163;&#20869;&#12290;</title><link>https://arxiv.org/abs/2402.10357</link><description>&lt;p&gt;
&#36890;&#36807;Langevin MCMC&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#39640;&#25928;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Efficient Sampling on Riemannian Manifolds via Langevin MCMC
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10357
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;Langevin MCMC&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#39640;&#25928;&#37319;&#26679;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#36845;&#20195;&#27493;&#25968;&#20026;$\tilde{O}(\epsilon^{-2})$&#26102;&#65292;Langevin MCMC&#30340;&#36845;&#20195;&#20250;&#19982;&#30446;&#26631;&#20998;&#24067;&#22312;$\epsilon$-Wasserstein&#36317;&#31163;&#20869;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#36890;&#36807;&#65288;&#20960;&#20309;&#65289;Langevin MCMC&#22312;&#40654;&#26364;&#27969;&#24418;$M$&#19978;&#39640;&#25928;&#22320;&#20174;Gibbs&#20998;&#24067;$d \pi^* = e^{-h} d {vol}_g$&#20013;&#37319;&#26679;&#30340;&#20219;&#21153;&#65307;&#35813;&#31639;&#27861;&#28041;&#21450;&#22312;&#38543;&#26426;&#39640;&#26031;&#26041;&#21521;&#19978;&#35745;&#31639;&#25351;&#25968;&#26144;&#23556;&#65292;&#22312;&#23454;&#36341;&#20013;&#21487;&#20197;&#39640;&#25928;&#23454;&#29616;&#12290;&#25105;&#20204;&#23545;Langevin MCMC&#30340;&#20998;&#26512;&#30340;&#20851;&#38190;&#22312;&#20110;&#23545;&#20960;&#20309;Euler-Murayama&#26041;&#26696;&#30340;&#31163;&#25955;&#21270;&#35823;&#24046;&#20570;&#20986;&#30340;&#30028;&#38480;&#65292;&#20551;&#35774;$\nabla h$&#26159;Lipschitz&#30340;&#65292;&#19988;$M$&#20855;&#26377;&#26377;&#30028;&#30340;&#26354;&#29575;&#25130;&#38754;&#12290;&#25105;&#20204;&#30340;&#35823;&#24046;&#30028;&#38480;&#19982;&#27431;&#20960;&#37324;&#24471;Euler-Murayama&#22312;&#27493;&#38271;&#20381;&#36182;&#24615;&#26041;&#38754;&#30340;&#35823;&#24046;&#30456;&#21305;&#37197;&#12290;&#32467;&#21512;Kendall-Cranston&#32806;&#21512;&#19979;&#23545;&#20960;&#20309;Langevin&#25193;&#25955;&#30340;&#25910;&#32553;&#20445;&#35777;&#65292;&#25105;&#20204;&#35777;&#26126;Langevin MCMC&#36845;&#20195;&#22312;&#32463;&#36807;$\tilde{O}(\epsilon^{-2})$&#27493;&#21518;&#19982;$\pi^*$&#20043;&#38388;&#30340;$\epsilon$-Wasserstein&#36317;&#31163;&#20869;&#65292;&#36825;&#19982;&#27431;&#20960;&#37324;&#24471;Langevin MCMC&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#30456;&#21305;&#37197;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#19968;&#33324;&#35774;&#32622;&#65292;&#20854;&#20013;$h$&#21487;&#20197;&#26159;&#38750;&#20984;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10357v1 Announce Type: cross  Abstract: We study the task of efficiently sampling from a Gibbs distribution $d \pi^* = e^{-h} d {vol}_g$ over a Riemannian manifold $M$ via (geometric) Langevin MCMC; this algorithm involves computing exponential maps in random Gaussian directions and is efficiently implementable in practice. The key to our analysis of Langevin MCMC is a bound on the discretization error of the geometric Euler-Murayama scheme, assuming $\nabla h$ is Lipschitz and $M$ has bounded sectional curvature. Our error bound matches the error of Euclidean Euler-Murayama in terms of its stepsize dependence. Combined with a contraction guarantee for the geometric Langevin Diffusion under Kendall-Cranston coupling, we prove that the Langevin MCMC iterates lie within $\epsilon$-Wasserstein distance of $\pi^*$ after $\tilde{O}(\epsilon^{-2})$ steps, which matches the iteration complexity for Euclidean Langevin MCMC. Our results apply in general settings where $h$ can be nonc
&lt;/p&gt;</description></item><item><title>&#25968;&#23383;&#23402;&#29983;&#20013;&#30340;&#25968;&#23398;&#26426;&#36935;&#38656;&#35201;&#22522;&#30784;&#25968;&#23398;&#36827;&#23637;&#65292;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#65292;&#25968;&#23383;&#23402;&#29983;&#20174;&#29305;&#23450;&#29616;&#23454;&#20986;&#21457;&#65292;&#38656;&#35201;&#22810;&#23610;&#24230;&#24314;&#27169;&#21644;&#32806;&#21512;&#65292;&#36890;&#36807;&#20256;&#24863;&#22120;&#23558;&#25968;&#25454;&#36755;&#20837;&#65292;&#24110;&#21161;&#20154;&#31867;&#20570;&#20986;&#20915;&#31574;&#12290;</title><link>https://arxiv.org/abs/2402.10326</link><description>&lt;p&gt;
&#25968;&#23383;&#23402;&#29983;&#20013;&#30340;&#25968;&#23398;&#26426;&#36935;&#65288;MATH-DT&#65289;
&lt;/p&gt;
&lt;p&gt;
Mathematical Opportunities in Digital Twins (MATH-DT)
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10326
&lt;/p&gt;
&lt;p&gt;
&#25968;&#23383;&#23402;&#29983;&#20013;&#30340;&#25968;&#23398;&#26426;&#36935;&#38656;&#35201;&#22522;&#30784;&#25968;&#23398;&#36827;&#23637;&#65292;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#65292;&#25968;&#23383;&#23402;&#29983;&#20174;&#29305;&#23450;&#29616;&#23454;&#20986;&#21457;&#65292;&#38656;&#35201;&#22810;&#23610;&#24230;&#24314;&#27169;&#21644;&#32806;&#21512;&#65292;&#36890;&#36807;&#20256;&#24863;&#22120;&#23558;&#25968;&#25454;&#36755;&#20837;&#65292;&#24110;&#21161;&#20154;&#31867;&#20570;&#20986;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#20221;&#25253;&#21578;&#25551;&#36848;&#20102;2023&#24180;12&#26376;11&#26085;&#33267;13&#26085;&#22312;&#20052;&#27835;&#26757;&#26862;&#22823;&#23398;&#20030;&#21150;&#30340;&#8220;&#25968;&#23383;&#23402;&#29983;&#20013;&#30340;&#25968;&#23398;&#26426;&#36935;&#8221;&#65288;MATH-DT&#65289;&#30740;&#35752;&#20250;&#30340;&#35752;&#35770;&#12290;&#25253;&#21578;&#25351;&#20986;&#65292;&#25968;&#23383;&#23402;&#29983;&#65288;DT&#65289;&#38656;&#35201;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#30340;&#22522;&#30784;&#25968;&#23398;&#36827;&#23637;&#12290;&#20256;&#32479;&#27169;&#22411;&#22312;&#29983;&#29289;&#23398;&#12289;&#29289;&#29702;&#23398;&#12289;&#24037;&#31243;&#23398;&#25110;&#21307;&#23398;&#20013;&#36215;&#22987;&#20110;&#36890;&#29992;&#29289;&#29702;&#23450;&#24459;&#65288;&#20363;&#22914;&#26041;&#31243;&#65289;&#65292;&#36890;&#24120;&#26159;&#23545;&#29616;&#23454;&#30340;&#31616;&#21270;&#12290;&#25968;&#23383;&#23402;&#29983;&#21017;&#20174;&#29305;&#23450;&#30340;&#29983;&#24577;&#31995;&#32479;&#12289;&#29289;&#20307;&#25110;&#20010;&#20154;&#65288;&#20363;&#22914;&#20010;&#24615;&#21270;&#21307;&#30103;&#65289;&#20316;&#20026;&#29616;&#23454;&#20986;&#21457;&#65292;&#38656;&#35201;&#22810;&#23610;&#24230;&#12289;&#22810;&#29289;&#29702;&#24314;&#27169;&#21644;&#32806;&#21512;&#12290;&#22240;&#27492;&#65292;&#36825;&#20123;&#36807;&#31243;&#22312;&#27169;&#25311;&#21644;&#24314;&#27169;&#27969;&#31243;&#30340;&#20004;&#31471;&#24320;&#22987;&#65292;&#38656;&#35201;&#19981;&#21516;&#30340;&#21487;&#38752;&#24615;&#26631;&#20934;&#21644;&#19981;&#30830;&#23450;&#24615;&#35780;&#20272;&#12290;&#27492;&#22806;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#65292;&#25968;&#23383;&#23402;&#29983;&#24110;&#21161;&#20154;&#31867;&#20026;&#29289;&#29702;&#31995;&#32479;&#20570;&#20986;&#20915;&#31574;&#65292;&#20854;&#36890;&#36807;&#20256;&#24863;&#22120;&#23558;&#25968;&#25454;&#20256;&#36755;&#21040;&#25968;&#23383;&#23402;&#29983;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10326v1 Announce Type: cross  Abstract: The report describes the discussions from the Workshop on Mathematical Opportunities in Digital Twins (MATH-DT) from December 11-13, 2023, George Mason University.   It illustrates that foundational Mathematical advances are required for Digital Twins (DTs) that are different from traditional approaches. A traditional model, in biology, physics, engineering or medicine, starts with a generic physical law (e.g., equations) and is often a simplification of reality. A DT starts with a specific ecosystem, object or person (e.g., personalized care) representing reality, requiring multi -scale, -physics modeling and coupling. Thus, these processes begin at opposite ends of the simulation and modeling pipeline, requiring different reliability criteria and uncertainty assessments. Additionally, unlike existing approaches, a DT assists humans to make decisions for the physical system, which (via sensors) in turn feeds data into the DT, and oper
&lt;/p&gt;</description></item><item><title>KCUSUM&#31639;&#27861;&#26159;&#19968;&#31181;&#38750;&#21442;&#25968;&#25193;&#23637;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#39640;&#23481;&#37327;&#25968;&#25454;&#24773;&#26223;&#19979;&#23454;&#26102;&#26816;&#27979;&#31361;&#21464;&#21464;&#21270;&#65292;&#30456;&#27604;&#20110;&#29616;&#26377;&#31639;&#27861;&#65292;&#20854;&#33021;&#22815;&#26356;&#28789;&#27963;&#22320;&#22312;&#22312;&#32447;&#29615;&#22659;&#20013;&#36827;&#34892;&#21464;&#28857;&#26816;&#27979;&#12290;</title><link>https://arxiv.org/abs/2402.10291</link><description>&lt;p&gt;
&#20351;&#29992;KCUSUM&#31639;&#27861;&#35780;&#20272;&#23454;&#26102;&#33258;&#36866;&#24212;&#37319;&#26679;&#21464;&#28857;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
An Evaluation of Real-time Adaptive Sampling Change Point Detection Algorithm using KCUSUM
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10291
&lt;/p&gt;
&lt;p&gt;
KCUSUM&#31639;&#27861;&#26159;&#19968;&#31181;&#38750;&#21442;&#25968;&#25193;&#23637;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#39640;&#23481;&#37327;&#25968;&#25454;&#24773;&#26223;&#19979;&#23454;&#26102;&#26816;&#27979;&#31361;&#21464;&#21464;&#21270;&#65292;&#30456;&#27604;&#20110;&#29616;&#26377;&#31639;&#27861;&#65292;&#20854;&#33021;&#22815;&#26356;&#28789;&#27963;&#22320;&#22312;&#22312;&#32447;&#29615;&#22659;&#20013;&#36827;&#34892;&#21464;&#28857;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#31185;&#23398;&#27169;&#25311;&#25968;&#25454;&#27969;&#20013;&#23454;&#26102;&#26816;&#27979;&#31361;&#21464;&#21464;&#21270;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#35201;&#27714;&#37096;&#32626;&#20934;&#30830;&#21644;&#39640;&#25928;&#30340;&#31639;&#27861;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#22522;&#20110;&#26680;&#30340;&#32047;&#31215;&#21644;&#65288;KCUSUM&#65289;&#31639;&#27861;&#65292;&#19968;&#31181;&#20256;&#32479;&#32047;&#31215;&#21644;&#65288;CUSUM&#65289;&#26041;&#27861;&#30340;&#38750;&#21442;&#25968;&#25193;&#23637;&#65292;&#20197;&#20854;&#22312;&#36739;&#23569;&#38480;&#21046;&#26465;&#20214;&#19979;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#32780;&#22791;&#21463;&#20851;&#27880;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10291v1 Announce Type: new  Abstract: Detecting abrupt changes in real-time data streams from scientific simulations presents a challenging task, demanding the deployment of accurate and efficient algorithms. Identifying change points in live data stream involves continuous scrutiny of incoming observations for deviations in their statistical characteristics, particularly in high-volume data scenarios. Maintaining a balance between sudden change detection and minimizing false alarms is vital. Many existing algorithms for this purpose rely on known probability distributions, limiting their feasibility. In this study, we introduce the Kernel-based Cumulative Sum (KCUSUM) algorithm, a non-parametric extension of the traditional Cumulative Sum (CUSUM) method, which has gained prominence for its efficacy in online change point detection under less restrictive conditions. KCUSUM splits itself by comparing incoming samples directly with reference samples and computes a statistic gr
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#22312;&#37096;&#20998;&#35266;&#23519;&#21040;&#30340;&#19978;&#19979;&#25991;&#29305;&#24449;&#32769;&#34382;&#26426;&#20013;&#20351;&#29992;Thompson Sampling&#31574;&#30053;&#65292;&#20197;&#23398;&#20064;&#36873;&#25321;&#26368;&#20339;&#33218;&#30340;&#38382;&#39064;</title><link>https://arxiv.org/abs/2402.10289</link><description>&lt;p&gt;
Thompson Sampling&#22312;&#37096;&#20998;&#21487;&#35266;&#23519;&#30340;&#19978;&#19979;&#25991;&#29305;&#24449;&#33218;&#32769;&#34382;&#26426;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Thompson Sampling in Partially Observable Contextual Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10289
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#22312;&#37096;&#20998;&#35266;&#23519;&#21040;&#30340;&#19978;&#19979;&#25991;&#29305;&#24449;&#32769;&#34382;&#26426;&#20013;&#20351;&#29992;Thompson Sampling&#31574;&#30053;&#65292;&#20197;&#23398;&#20064;&#36873;&#25321;&#26368;&#20339;&#33218;&#30340;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19978;&#19979;&#25991;&#29305;&#24449;&#33218;&#32769;&#34382;&#26426;&#26500;&#25104;&#20102;&#19968;&#20010;&#32463;&#20856;&#30340;&#19981;&#30830;&#23450;&#24615;&#20915;&#31574;&#26694;&#26550;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#30446;&#26631;&#26159;&#22312;&#19978;&#19979;&#25991;&#20449;&#24687;&#30340;&#26465;&#20214;&#19979;&#23398;&#20064;&#20855;&#26377;&#26368;&#39640;&#22870;&#21169;&#30340;&#33218;&#65292;&#21516;&#26102;&#38656;&#35201;&#36890;&#36807;&#23454;&#39564;&#26469;&#23398;&#20064;&#27599;&#20010;&#33218;&#30340;&#26410;&#30693;&#22870;&#21169;&#21442;&#25968;&#12290;&#22240;&#27492;&#65292;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#26159;&#22312;&#25506;&#32034;&#65288;&#21363;&#25289;&#21160;&#19981;&#21516;&#33218;&#20197;&#23398;&#20064;&#23427;&#20204;&#30340;&#21442;&#25968;&#65289;&#21644;&#24320;&#21457;&#65288;&#21363;&#25289;&#21160;&#26368;&#20339;&#33218;&#20197;&#33719;&#24471;&#22870;&#21169;&#65289;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#12290;&#29616;&#26377;&#25991;&#29486;&#22823;&#22810;&#32771;&#34385;&#23436;&#20840;&#35266;&#23519;&#21040;&#30340;&#19978;&#19979;&#25991;&#24773;&#22659;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#22312;&#29702;&#35770;&#19978;&#26356;&#19968;&#33324;&#19988;&#22312;&#23454;&#36341;&#20013;&#26356;&#26377;&#22810;&#26679;&#24615;&#65292;&#20294;&#37096;&#20998;&#19978;&#19979;&#25991;&#35266;&#23519;&#24773;&#26223;&#33267;&#20170;&#20173;&#26410;&#34987;&#25506;&#32034;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#35266;&#23519;&#25968;&#25454;&#26159;&#26410;&#35266;&#23519;&#21040;&#30340;&#19978;&#19979;&#25991;&#21521;&#37327;&#30340;&#22122;&#22768;&#32447;&#24615;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#36873;&#25321;&#26368;&#20339;&#33218;&#30340;&#32769;&#34382;&#26426;&#31574;&#30053;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;Thompson&#37319;&#26679;&#31639;&#27861;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10289v1 Announce Type: cross  Abstract: Contextual bandits constitute a classical framework for decision-making under uncertainty. In this setting, the goal is to learn the arms of highest reward subject to contextual information, while the unknown reward parameters of each arm need to be learned by experimenting that specific arm. Accordingly, a fundamental problem is that of balancing exploration (i.e., pulling different arms to learn their parameters), versus exploitation (i.e., pulling the best arms to gain reward). To study this problem, the existing literature mostly considers perfectly observed contexts. However, the setting of partial context observations remains unexplored to date, despite being theoretically more general and practically more versatile. We study bandit policies for learning to select optimal arms based on the data of observations, which are noisy linear functions of the unobserved context vectors. Our theoretical analysis shows that the Thompson sam
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#23481;&#37327;&#30340;&#26032;&#36951;&#25022;&#30028;&#38480;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#20013;&#20171;&#21453;&#39304;&#30340;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#21516;&#26102;&#22312;&#25932;&#23545;&#21644;&#38543;&#26426;&#35774;&#32622;&#20013;&#25552;&#20379;&#20102;&#36817;&#20046;&#21305;&#37197;&#30340;&#19979;&#30028;&#12290;</title><link>https://arxiv.org/abs/2402.10282</link><description>&lt;p&gt;
&#20855;&#26377;&#20013;&#20171;&#21453;&#39304;&#30340;&#36172;&#21338;&#26426;&#20449;&#24687;&#23481;&#37327;&#36951;&#25022;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Information Capacity Regret Bounds for Bandits with Mediator Feedback
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10282
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#23481;&#37327;&#30340;&#26032;&#36951;&#25022;&#30028;&#38480;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#20013;&#20171;&#21453;&#39304;&#30340;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#21516;&#26102;&#22312;&#25932;&#23545;&#21644;&#38543;&#26426;&#35774;&#32622;&#20013;&#25552;&#20379;&#20102;&#36817;&#20046;&#21305;&#37197;&#30340;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#35299;&#20915;&#20102;&#20013;&#20171;&#21453;&#39304;&#38382;&#39064;&#65292;&#21363;&#20915;&#31574;&#38598;&#21253;&#25324;&#22810;&#20010;&#31574;&#30053;&#65292;&#27599;&#20010;&#31574;&#30053;&#19982;&#20849;&#21516;&#32467;&#26524;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#20998;&#24067;&#30456;&#20851;&#32852;&#12290;&#36873;&#25321;&#19968;&#20010;&#31574;&#30053;&#21518;&#65292;&#23398;&#20064;&#32773;&#35266;&#23519;&#20174;&#20854;&#20998;&#24067;&#20013;&#37319;&#26679;&#30340;&#32467;&#26524;&#65292;&#24182;&#22312;&#24403;&#21069;&#22238;&#21512;&#20013;&#25215;&#25285;&#20998;&#37197;&#32473;&#35813;&#32467;&#26524;&#30340;&#25439;&#22833;&#12290;&#25105;&#20204;&#24341;&#20837;&#31574;&#30053;&#38598;&#23481;&#37327;&#20316;&#20026;&#34913;&#37327;&#31574;&#30053;&#38598;&#22797;&#26434;&#24615;&#30340;&#20449;&#24687;&#35770;&#25351;&#26631;&#12290;&#37319;&#29992;&#32463;&#20856;&#30340;EXP4&#31639;&#27861;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#26032;&#30340;&#36951;&#25022;&#30028;&#38480;&#65292;&#21462;&#20915;&#20110;&#31574;&#30053;&#38598;&#23481;&#37327;&#22312;&#25932;&#23545;&#21644;&#38543;&#26426;&#35774;&#32622;&#20013;&#30340;&#24615;&#33021;&#12290;&#23545;&#20110;&#19968;&#20123;&#31574;&#30053;&#38598;&#23478;&#26063;&#30340;&#36873;&#25321;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36817;&#20046;&#21305;&#37197;&#30340;&#19979;&#30028;&#65292;&#19982;&#23481;&#37327;&#31867;&#20284;&#22320;&#25193;&#23637;&#12290;&#25105;&#20204;&#36824;&#32771;&#34385;&#20102;&#31574;&#30053;&#20998;&#24067;&#22312;&#22238;&#21512;&#20043;&#38388;&#21487;&#20197;&#21464;&#21270;&#30340;&#24773;&#20917;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#30456;&#20851;&#30340;&#20855;&#26377;&#19987;&#23478;&#24314;&#35758;&#30340;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25105;&#20204;&#22312;&#20854;&#20808;&#21069;&#32467;&#26524;&#19978;&#26377;&#25152;&#25913;&#36827;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10282v1 Announce Type: new  Abstract: This work addresses the mediator feedback problem, a bandit game where the decision set consists of a number of policies, each associated with a probability distribution over a common space of outcomes. Upon choosing a policy, the learner observes an outcome sampled from its distribution and incurs the loss assigned to this outcome in the present round. We introduce the policy set capacity as an information-theoretic measure for the complexity of the policy set. Adopting the classical EXP4 algorithm, we provide new regret bounds depending on the policy set capacity in both the adversarial and the stochastic settings. For a selection of policy set families, we prove nearly-matching lower bounds, scaling similarly with the capacity. We also consider the case when the policies' distributions can vary between rounds, thus addressing the related bandits with expert advice problem, which we improve upon its prior results. Additionally, we prov
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25581;&#31034;&#20102;&#22312;&#32447;&#25511;&#21046;&#38382;&#39064;&#20013;&#65292;&#23545;&#20110;&#20984;&#25104;&#26412;&#65292;&#21487;&#20197;&#23454;&#29616; $ \widetilde{O}(\sqrt{T}) $ &#30340;&#36951;&#25022;&#30028;&#65292;&#29978;&#33267;&#22312;&#23384;&#22312;&#26080;&#30028;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65307;&#21516;&#26102;&#65292;&#22312;&#25104;&#26412;&#20855;&#26377;&#24378;&#20984;&#24615;&#26102;&#65292;&#21487;&#20197;&#22312;&#19981;&#38656;&#35201;&#22122;&#22768;&#21327;&#26041;&#24046;&#26159;&#38750;&#36864;&#21270;&#30340;&#24773;&#20917;&#19979;&#24314;&#31435; $ O({\rm poly} (\log T)) $ &#30340;&#36951;&#25022;&#30028;&#12290;</title><link>https://arxiv.org/abs/2402.10252</link><description>&lt;p&gt;
&#20855;&#26377;&#26080;&#30028;&#21644;&#36864;&#21270;&#22122;&#22768;&#30340;&#32447;&#24615;&#31995;&#32479;&#22312;&#32447;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Online Control of Linear Systems with Unbounded and Degenerate Noise
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10252
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25581;&#31034;&#20102;&#22312;&#32447;&#25511;&#21046;&#38382;&#39064;&#20013;&#65292;&#23545;&#20110;&#20984;&#25104;&#26412;&#65292;&#21487;&#20197;&#23454;&#29616; $ \widetilde{O}(\sqrt{T}) $ &#30340;&#36951;&#25022;&#30028;&#65292;&#29978;&#33267;&#22312;&#23384;&#22312;&#26080;&#30028;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65307;&#21516;&#26102;&#65292;&#22312;&#25104;&#26412;&#20855;&#26377;&#24378;&#20984;&#24615;&#26102;&#65292;&#21487;&#20197;&#22312;&#19981;&#38656;&#35201;&#22122;&#22768;&#21327;&#26041;&#24046;&#26159;&#38750;&#36864;&#21270;&#30340;&#24773;&#20917;&#19979;&#24314;&#31435; $ O({\rm poly} (\log T)) $ &#30340;&#36951;&#25022;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#21487;&#33021;&#23384;&#22312;&#26080;&#30028;&#21644;&#36864;&#21270;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#25511;&#21046;&#32447;&#24615;&#31995;&#32479;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#25104;&#26412;&#20989;&#25968;&#26410;&#30693;&#65292;&#34987;&#31216;&#20026;&#22312;&#32447;&#25511;&#21046;&#38382;&#39064;&#12290;&#19982;&#29616;&#26377;&#30340;&#20165;&#20551;&#35774;&#22122;&#22768;&#26377;&#30028;&#24615;&#30340;&#30740;&#31350;&#19981;&#21516;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#23545;&#20110;&#20984;&#25104;&#26412;&#65292;&#21363;&#20351;&#22312;&#23384;&#22312;&#26080;&#30028;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#20063;&#21487;&#20197;&#23454;&#29616; $ \widetilde{O}(\sqrt{T}) $ &#30340;&#36951;&#25022;&#30028;&#65292;&#20854;&#20013; $ T $ &#34920;&#31034;&#26102;&#38388;&#36328;&#24230;&#12290;&#27492;&#22806;&#65292;&#24403;&#25104;&#26412;&#20855;&#26377;&#24378;&#20984;&#24615;&#26102;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010; $ O({\rm poly} (\log T)) $ &#30340;&#36951;&#25022;&#30028;&#65292;&#32780;&#19981;&#38656;&#35201;&#22122;&#22768;&#21327;&#26041;&#24046;&#26159;&#38750;&#36864;&#21270;&#30340;&#20551;&#35774;&#65292;&#36825;&#22312;&#25991;&#29486;&#20013;&#26159;&#24517;&#38656;&#30340;&#12290;&#28040;&#38500;&#22122;&#22768;&#31209;&#30340;&#20851;&#38190;&#26159;&#19982;&#22122;&#22768;&#21327;&#26041;&#24046;&#30456;&#20851;&#32852;&#30340;&#31995;&#32479;&#36716;&#21270;&#12290;&#36825;&#21516;&#26102;&#23454;&#29616;&#20102;&#22312;&#32447;&#25511;&#21046;&#31639;&#27861;&#30340;&#21442;&#25968;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10252v1 Announce Type: cross  Abstract: This paper investigates the problem of controlling a linear system under possibly unbounded and degenerate noise with unknown cost functions, known as an online control problem. In contrast to the existing work, which assumes the boundedness of noise, we reveal that for convex costs, an $ \widetilde{O}(\sqrt{T}) $ regret bound can be achieved even for unbounded noise, where $ T $ denotes the time horizon. Moreover, when the costs are strongly convex, we establish an $ O({\rm poly} (\log T)) $ regret bound without the assumption that noise covariance is non-degenerate, which has been required in the literature. The key ingredient in removing the rank assumption on noise is a system transformation associated with the noise covariance. This simultaneously enables the parameter reduction of an online control algorithm.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;Johnson-Lindenstrauss&#65288;JL&#65289;&#24341;&#29702;&#30340;&#31616;&#21333;&#32479;&#19968;&#20998;&#26512;&#65292;&#31616;&#21270;&#21644;&#32479;&#19968;&#20102;&#21508;&#31181;&#26500;&#36896;&#65292;&#21253;&#25324;&#29699;&#24418;&#12289;&#39640;&#26031;&#12289;&#20108;&#36827;&#21046;&#30828;&#24065;&#21644;&#27425;&#39640;&#26031;&#27169;&#22411;&#65292;&#36890;&#36807;&#21019;&#26032;&#24615;&#22320;&#23558;Hanson-Wright&#19981;&#31561;&#24335;&#25299;&#23637;&#21040;&#39640;&#32500;&#24230;&#65292;&#26631;&#24535;&#30528;&#23545;&#25968;&#25454;&#22266;&#26377;&#20960;&#20309;&#30340;&#20445;&#25345;&#21462;&#24471;&#37325;&#22823;&#36827;&#23637;&#12290;</title><link>https://arxiv.org/abs/2402.10232</link><description>&lt;p&gt;
Johnson-Lindenstrauss&#30340;&#31616;&#21333;&#32479;&#19968;&#20998;&#26512;&#21450;&#20854;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Simple, unified analysis of Johnson-Lindenstrauss with applications
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10232
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;Johnson-Lindenstrauss&#65288;JL&#65289;&#24341;&#29702;&#30340;&#31616;&#21333;&#32479;&#19968;&#20998;&#26512;&#65292;&#31616;&#21270;&#21644;&#32479;&#19968;&#20102;&#21508;&#31181;&#26500;&#36896;&#65292;&#21253;&#25324;&#29699;&#24418;&#12289;&#39640;&#26031;&#12289;&#20108;&#36827;&#21046;&#30828;&#24065;&#21644;&#27425;&#39640;&#26031;&#27169;&#22411;&#65292;&#36890;&#36807;&#21019;&#26032;&#24615;&#22320;&#23558;Hanson-Wright&#19981;&#31561;&#24335;&#25299;&#23637;&#21040;&#39640;&#32500;&#24230;&#65292;&#26631;&#24535;&#30528;&#23545;&#25968;&#25454;&#22266;&#26377;&#20960;&#20309;&#30340;&#20445;&#25345;&#21462;&#24471;&#37325;&#22823;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Johnson-Lindenstrauss&#65288;JL&#65289;&#24341;&#29702;&#30340;&#31616;&#21333;&#32479;&#19968;&#20998;&#26512;&#65292;&#36825;&#26159;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#33267;&#20851;&#37325;&#35201;&#30340;&#38477;&#32500;&#39046;&#22495;&#20013;&#30340;&#22522;&#30707;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#20165;&#31616;&#21270;&#20102;&#29702;&#35299;&#65292;&#36824;&#23558;&#21508;&#31181;&#26500;&#36896;&#32479;&#19968;&#21040;JL&#26694;&#26550;&#19979;&#65292;&#21253;&#25324;&#29699;&#24418;&#12289;&#39640;&#26031;&#12289;&#20108;&#36827;&#21046;&#30828;&#24065;&#21644;&#27425;&#39640;&#26031;&#27169;&#22411;&#12290;&#36825;&#31181;&#31616;&#21270;&#21644;&#32479;&#19968;&#22312;&#20445;&#25345;&#25968;&#25454;&#22266;&#26377;&#20960;&#20309;&#30340;&#37325;&#35201;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#65292;&#23545;&#20174;&#27969;&#31639;&#27861;&#21040;&#24378;&#21270;&#23398;&#20064;&#31561;&#21508;&#31181;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#22312;&#36825;&#20010;&#31616;&#21270;&#26694;&#26550;&#20869;&#25552;&#20986;&#20102;&#29699;&#24418;&#26500;&#36896;&#26377;&#25928;&#24615;&#30340;&#31532;&#19968;&#20010;&#20005;&#26684;&#35777;&#26126;&#12290;&#25105;&#20204;&#36129;&#29486;&#30340;&#26680;&#24515;&#26159;&#23558;Hanson-Wright&#19981;&#31561;&#24335;&#25299;&#23637;&#21040;&#39640;&#32500;&#24230;&#65292;&#20855;&#26377;&#26126;&#30830;&#30340;&#24120;&#25968;&#65292;&#36825;&#26631;&#24535;&#30528;&#25991;&#29486;&#20013;&#36136;&#30340;&#39134;&#36291;&#12290;&#36890;&#36807;&#36816;&#29992;&#31616;&#21333;&#32780;&#24378;&#22823;&#30340;&#27010;&#29575;&#24037;&#20855;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10232v1 Announce Type: new  Abstract: In this work, we present a simple and unified analysis of the Johnson-Lindenstrauss (JL) lemma, a cornerstone in the field of dimensionality reduction critical for managing high-dimensional data. Our approach not only simplifies the understanding but also unifies various constructions under the JL framework, including spherical, Gaussian, binary coin, and sub-Gaussian models. This simplification and unification make significant strides in preserving the intrinsic geometry of data, essential across diverse applications from streaming algorithms to reinforcement learning. Notably, we deliver the first rigorous proof of the spherical construction's effectiveness within this simplified framework. At the heart of our contribution is an innovative extension of the Hanson-Wright inequality to high dimensions, complete with explicit constants, marking a substantial leap in the literature. By employing simple yet powerful probabilistic tools and 
&lt;/p&gt;</description></item><item><title>HyperAgent&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#12289;&#39640;&#25928;&#12289;&#21487;&#25193;&#23637;&#30340;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#22312;&#22797;&#26434;&#29615;&#22659;&#19979;&#33021;&#22815;&#23454;&#29616;&#39640;&#25928;&#30340;&#35745;&#31639;&#21644;&#25968;&#25454;&#36873;&#25321;&#65292;&#26159;&#39318;&#20010;&#36798;&#21040;&#21487;&#35777;&#26126;&#21487;&#25193;&#23637;&#30340;&#27599;&#27493;&#35745;&#31639;&#22797;&#26434;&#24230;&#20197;&#21450;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.10228</link><description>&lt;p&gt;
HyperAgent&#65306;&#19968;&#31181;&#31616;&#21333;&#12289;&#21487;&#25193;&#23637;&#12289;&#39640;&#25928;&#19988;&#21487;&#35777;&#26126;&#29992;&#20110;&#22797;&#26434;&#29615;&#22659;&#30340;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
HyperAgent: A Simple, Scalable, Efficient and Provable Reinforcement Learning Framework for Complex Environments
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10228
&lt;/p&gt;
&lt;p&gt;
HyperAgent&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#12289;&#39640;&#25928;&#12289;&#21487;&#25193;&#23637;&#30340;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#22312;&#22797;&#26434;&#29615;&#22659;&#19979;&#33021;&#22815;&#23454;&#29616;&#39640;&#25928;&#30340;&#35745;&#31639;&#21644;&#25968;&#25454;&#36873;&#25321;&#65292;&#26159;&#39318;&#20010;&#36798;&#21040;&#21487;&#35777;&#26126;&#21487;&#25193;&#23637;&#30340;&#27599;&#27493;&#35745;&#31639;&#22797;&#26434;&#24230;&#20197;&#21450;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#22312;&#36164;&#28304;&#32422;&#26463;&#19979;&#35299;&#20915;&#22797;&#26434;&#20219;&#21153;&#65292;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20195;&#29702;&#38656;&#35201;&#31616;&#21333;&#12289;&#39640;&#25928;&#12289;&#21487;&#25193;&#23637;&#12289;&#20855;&#26377;&#22823;&#29366;&#24577;&#31354;&#38388;&#21644;&#19981;&#26029;&#31215;&#32047;&#30340;&#20132;&#20114;&#25968;&#25454;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;HyperAgent&#65292;&#36825;&#26159;&#19968;&#20010;&#20855;&#26377;&#36229;&#27169;&#22411;&#12289;&#32034;&#24341;&#25277;&#26679;&#26041;&#26696;&#21644;&#22686;&#37327;&#26356;&#26032;&#26426;&#21046;&#30340;RL&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#19968;&#33324;&#20215;&#20540;&#20989;&#25968;&#36924;&#36817;&#20013;&#36827;&#34892;&#35745;&#31639;&#39640;&#25928;&#30340;&#39034;&#24207;&#21518;&#39564;&#36924;&#36817;&#21644;&#25968;&#25454;&#39640;&#25928;&#30340;&#21160;&#20316;&#36873;&#25321;&#65292;&#36229;&#36234;&#20102;&#20849;&#36717;&#24615;&#12290;HyperAgent&#30340;&#23454;&#29616;&#31616;&#21333;&#65292;&#21482;&#38656;&#35201;&#22312;DDQN&#20013;&#28155;&#21152;&#19968;&#20010;&#27169;&#22359;&#21644;&#19968;&#34892;&#39069;&#22806;&#20195;&#30721;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;HyperAgent&#22312;&#22823;&#35268;&#27169;&#28145;&#24230;RL&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#31283;&#20581;&#30340;&#24615;&#33021;&#65292;&#26080;&#35770;&#26159;&#22312;&#25968;&#25454;&#36824;&#26159;&#35745;&#31639;&#26041;&#38754;&#37117;&#33719;&#24471;&#20102;&#26174;&#30528;&#30340;&#25928;&#29575;&#25552;&#21319;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#22312;&#23454;&#38469;&#21487;&#25193;&#23637;&#30340;&#31639;&#27861;&#20013;&#65292;HyperAgent&#26159;&#31532;&#19968;&#20010;&#33021;&#22815;&#23454;&#29616;&#21487;&#35777;&#26126;&#21487;&#25193;&#23637;&#30340;&#27599;&#27493;&#35745;&#31639;&#22797;&#26434;&#24230;&#20197;&#21450;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10228v1 Announce Type: cross  Abstract: To solve complex tasks under resource constraints, reinforcement learning (RL) agents need to be simple, efficient, and scalable with (1) large state space and (2) increasingly accumulated data of interactions. We propose the HyperAgent, a RL framework with hypermodel, index sampling schemes and incremental update mechanism, enabling computation-efficient sequential posterior approximation and data-efficient action selection under general value function approximation beyond conjugacy. The implementation of \HyperAgent is simple as it only adds one module and one line of code additional to DDQN. Practically, HyperAgent demonstrates its robust performance in large-scale deep RL benchmarks with significant efficiency gain in terms of both data and computation. Theoretically, among the practically scalable algorithms, HyperAgent is the first method to achieve provably scalable per-step computational complexity as well as sublinear regret u
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#30456;&#20851;&#25289;&#26684;&#26391;&#26085;&#34203;&#23450;&#35860;&#26725;&#65288;CLSB&#65289;&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#20154;&#21475;&#32423;&#27491;&#21017;&#21270;&#26469;&#23398;&#20064;&#36328;&#25130;&#38754;&#26679;&#26412;&#20013;&#30340;&#31995;&#32479;&#21160;&#24577;&#65292;&#36866;&#24212;&#20010;&#20307;&#31890;&#23376;&#34892;&#20026;&#30340;&#24322;&#36136;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.10227</link><description>&lt;p&gt;
&#30456;&#20851;&#25289;&#26684;&#26391;&#26085;&#34203;&#23450;&#35860;&#26725;&#65306;&#36890;&#36807;&#20154;&#21475;&#32423;&#27491;&#21017;&#21270;&#23398;&#20064;&#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
Correlational Lagrangian Schr\"odinger Bridge: Learning Dynamics with Population-Level Regularization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10227
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#30456;&#20851;&#25289;&#26684;&#26391;&#26085;&#34203;&#23450;&#35860;&#26725;&#65288;CLSB&#65289;&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#20154;&#21475;&#32423;&#27491;&#21017;&#21270;&#26469;&#23398;&#20064;&#36328;&#25130;&#38754;&#26679;&#26412;&#20013;&#30340;&#31995;&#32479;&#21160;&#24577;&#65292;&#36866;&#24212;&#20010;&#20307;&#31890;&#23376;&#34892;&#20026;&#30340;&#24322;&#36136;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31995;&#32479;&#21160;&#24577;&#30340;&#20934;&#30830;&#24314;&#27169;&#22312;&#21253;&#25324;&#32454;&#32990;&#21160;&#21147;&#23398;&#21644;&#27969;&#20307;&#21147;&#23398;&#22312;&#20869;&#30340;&#24191;&#27867;&#31185;&#23398;&#39046;&#22495;&#20013;&#20855;&#26377;&#24341;&#20154;&#27880;&#30446;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#24403;&#65288;i&#65289;&#35266;&#23519;&#20165;&#38480;&#20110;&#27178;&#25130;&#38754;&#26679;&#26412;&#65288;&#20010;&#20307;&#36712;&#36857;&#19981;&#21487;&#23398;&#20064;&#65289;&#26102;&#65292;&#20197;&#21450;&#65288;ii&#65289;&#20010;&#20307;&#31890;&#23376;&#34892;&#20026;&#24322;&#36136;&#26102;&#65288;&#23588;&#20854;&#26159;&#30001;&#20110;&#29983;&#29289;&#22810;&#26679;&#24615;&#32780;&#20026;&#29983;&#29289;&#31995;&#32479;&#65289;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#21517;&#20026;&#30456;&#20851;&#25289;&#26684;&#26391;&#26085;&#34203;&#23450;&#35860;&#26725;&#65288;CLSB&#65289;&#30340;&#26032;&#26694;&#26550;&#65292;&#26088;&#22312;&#23547;&#27714;&#22312;&#27178;&#25130;&#35266;&#23519;&#20043;&#38388;&#30340;&#28436;&#21464;&#8220;&#26725;&#26753;&#8221;&#65292;&#21516;&#26102;&#20197;&#26368;&#23567;&#20154;&#21475;&#8220;&#25104;&#26412;&#8221;&#36827;&#34892;&#27491;&#21017;&#21270;&#12290;&#19982;&#20808;&#21069;&#20381;&#36182;\textit{&#20010;&#20307;}&#32423;&#27491;&#21017;&#21270;&#22120;&#30340;&#26041;&#27861;&#24418;&#25104;&#23545;&#27604;&#65288;&#20363;&#22914;&#65292;&#38480;&#21046;&#20010;&#20307;&#36816;&#21160;&#65289;&#65292;CLSB&#22312;&#20154;&#21475;&#27700;&#24179;&#36816;&#34892;&#65292;&#25509;&#21463;&#24322;&#36136;&#24615;&#26412;&#36136;&#65292;&#20174;&#32780;&#20135;&#29983;&#26356;&#20855;&#27867;&#21270;&#24615;&#30340;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10227v1 Announce Type: new  Abstract: Accurate modeling of system dynamics holds intriguing potential in broad scientific fields including cytodynamics and fluid mechanics. This task often presents significant challenges when (i) observations are limited to cross-sectional samples (where individual trajectories are inaccessible for learning), and moreover, (ii) the behaviors of individual particles are heterogeneous (especially in biological systems due to biodiversity). To address them, we introduce a novel framework dubbed correlational Lagrangian Schr\"odinger bridge (CLSB), aiming to seek for the evolution "bridging" among cross-sectional observations, while regularized for the minimal population "cost". In contrast to prior methods relying on \textit{individual}-level regularizers for all particles \textit{homogeneously} (e.g. restraining individual motions), CLSB operates at the population level admitting the heterogeneity nature, resulting in a more generalizable mode
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;GPT-4&#22312;&#21307;&#30103;&#24212;&#29992;&#20013;&#30340;&#34920;&#29616;&#35780;&#20272;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#21453;&#39304;&#23545;&#30456;&#23545;&#32622;&#20449;&#24230;&#26377;&#24433;&#21709;&#65292;&#20294;&#24182;&#19981;&#19968;&#33268;&#22320;&#22686;&#21152;&#25110;&#20943;&#23569;&#12290;</title><link>https://arxiv.org/abs/2402.09654</link><description>&lt;p&gt;
GPT-4&#22312;&#22522;&#20110;USMLE&#30340;&#26696;&#20363;&#30740;&#31350;&#20013;&#30340;&#34920;&#29616;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
GPT-4's assessment of its performance in a USMLE-based case study
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09654
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;GPT-4&#22312;&#21307;&#30103;&#24212;&#29992;&#20013;&#30340;&#34920;&#29616;&#35780;&#20272;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#21453;&#39304;&#23545;&#30456;&#23545;&#32622;&#20449;&#24230;&#26377;&#24433;&#21709;&#65292;&#20294;&#24182;&#19981;&#19968;&#33268;&#22320;&#22686;&#21152;&#25110;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35843;&#26597;GPT-4&#22312;&#21307;&#30103;&#24212;&#29992;&#20013;&#30340;&#34920;&#29616;&#35780;&#20272;&#12290;&#36890;&#36807;&#20351;&#29992;&#31616;&#21333;&#30340;&#25552;&#31034;&#25216;&#26415;&#65292;&#20174;&#32654;&#22269;&#21307;&#23398;&#25191;&#29031;&#32771;&#35797;&#65288;USMLE&#65289;&#38382;&#21367;&#20013;&#25552;&#21462;&#38382;&#39064;&#30340;&#26041;&#24335;&#65292;&#20219;&#21153;&#26159;&#35780;&#20272;&#27169;&#22411;&#22312;&#25552;&#38382;&#20043;&#21069;&#21644;&#25552;&#38382;&#20043;&#21518;&#30340;&#32622;&#20449;&#24230;&#24471;&#20998;&#12290;&#38382;&#21367;&#26681;&#25454;&#26159;&#21542;&#26377;&#21453;&#39304;&#20998;&#20026;&#20004;&#32452;&#65306;&#21453;&#39304;&#32452;&#65288;WF&#65289;&#21644;&#26080;&#21453;&#39304;&#32452;&#65288;NF&#65289;&#12290;&#35201;&#27714;&#27169;&#22411;&#22312;&#27599;&#20010;&#38382;&#39064;&#20043;&#21069;&#21644;&#20043;&#21518;&#25552;&#20379;&#32477;&#23545;&#21644;&#30456;&#23545;&#32622;&#20449;&#24230;&#24471;&#20998;&#12290;&#36890;&#36807;&#20351;&#29992;&#32479;&#35745;&#24037;&#20855;&#20998;&#26512;&#23454;&#39564;&#32467;&#26524;&#65292;&#30740;&#31350;&#20102;WF&#21644;NF&#32452;&#30340;&#32622;&#20449;&#24230;&#21464;&#24322;&#24615;&#12290;&#27492;&#22806;&#65292;&#36827;&#34892;&#20102;&#39034;&#24207;&#20998;&#26512;&#20197;&#35266;&#23519;WF&#21644;NF&#32452;&#30340;&#24615;&#33021;&#21464;&#21270;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#21453;&#39304;&#20250;&#24433;&#21709;&#30456;&#23545;&#32622;&#20449;&#24230;&#65292;&#20294;&#24182;&#19981;&#24635;&#26159;&#22686;&#21152;&#25110;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09654v1 Announce Type: new  Abstract: This study investigates GPT-4's assessment of its performance in healthcare applications. A simple prompting technique was used to prompt the LLM with questions taken from the United States Medical Licensing Examination (USMLE) questionnaire and it was tasked to evaluate its confidence score before posing the question and after asking the question. The questionnaire was categorized into two groups-questions with feedback (WF) and questions with no feedback(NF) post-question. The model was asked to provide absolute and relative confidence scores before and after each question. The experimental findings were analyzed using statistical tools to study the variability of confidence in WF and NF groups. Additionally, a sequential analysis was conducted to observe the performance variation for the WF and NF groups. Results indicate that feedback influences relative confidence but doesn't consistently increase or decrease it. Understanding the p
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#21464;&#37327;&#39640;&#26031;&#36807;&#31243;&#30340;&#22810;&#28304;&#25968;&#25454;&#34701;&#21512;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#22810;&#20010;&#25968;&#25454;&#28304;&#20043;&#38388;&#36136;&#37327;&#21644;&#20840;&#38754;&#24615;&#24046;&#24322;&#32473;&#31995;&#32479;&#20248;&#21270;&#24102;&#26469;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.04146</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#22810;&#28304;&#25968;&#25454;&#34701;&#21512;&#36890;&#36807;&#28508;&#21464;&#37327;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Interpretable Multi-Source Data Fusion Through Latent Variable Gaussian Process
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04146
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#21464;&#37327;&#39640;&#26031;&#36807;&#31243;&#30340;&#22810;&#28304;&#25968;&#25454;&#34701;&#21512;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#22810;&#20010;&#25968;&#25454;&#28304;&#20043;&#38388;&#36136;&#37327;&#21644;&#20840;&#38754;&#24615;&#24046;&#24322;&#32473;&#31995;&#32479;&#20248;&#21270;&#24102;&#26469;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#21644;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#30340;&#20986;&#29616;&#65292;&#21508;&#20010;&#31185;&#23398;&#21644;&#24037;&#31243;&#39046;&#22495;&#24050;&#32463;&#21033;&#29992;&#25968;&#25454;&#39537;&#21160;&#30340;&#26367;&#20195;&#27169;&#22411;&#26469;&#24314;&#27169;&#26469;&#33258;&#22823;&#37327;&#20449;&#24687;&#28304;&#65288;&#25968;&#25454;&#65289;&#30340;&#22797;&#26434;&#31995;&#32479;&#12290;&#36825;&#31181;&#22686;&#21152;&#23548;&#33268;&#20102;&#24320;&#21457;&#20986;&#29992;&#20110;&#25191;&#34892;&#29305;&#23450;&#21151;&#33021;&#30340;&#20248;&#36234;&#31995;&#32479;&#25152;&#38656;&#30340;&#25104;&#26412;&#21644;&#26102;&#38388;&#30340;&#26174;&#33879;&#38477;&#20302;&#12290;&#36825;&#26679;&#30340;&#26367;&#20195;&#27169;&#22411;&#24448;&#24448;&#24191;&#27867;&#22320;&#34701;&#21512;&#22810;&#20010;&#25968;&#25454;&#26469;&#28304;&#65292;&#21487;&#33021;&#26159;&#21457;&#34920;&#30340;&#35770;&#25991;&#12289;&#19987;&#21033;&#12289;&#24320;&#25918;&#36164;&#28304;&#24211;&#25110;&#20854;&#20182;&#36164;&#28304;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#24050;&#30693;&#21644;&#26410;&#30693;&#30340;&#20449;&#24687;&#26469;&#28304;&#30340;&#22522;&#30784;&#29289;&#29702;&#21442;&#25968;&#30340;&#36136;&#37327;&#21644;&#20840;&#38754;&#24615;&#30340;&#24046;&#24322;&#65292;&#21487;&#33021;&#23545;&#31995;&#32479;&#20248;&#21270;&#36807;&#31243;&#20135;&#29983;&#21518;&#32493;&#24433;&#21709;&#65292;&#21364;&#27809;&#26377;&#24471;&#21040;&#20805;&#20998;&#30340;&#20851;&#27880;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#21464;&#37327;&#39640;&#26031;&#36807;&#31243;&#65288;LVGP&#65289;&#30340;&#22810;&#28304;&#25968;&#25454;&#34701;&#21512;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the advent of artificial intelligence (AI) and machine learning (ML), various domains of science and engineering communites has leveraged data-driven surrogates to model complex systems from numerous sources of information (data). The proliferation has led to significant reduction in cost and time involved in development of superior systems designed to perform specific functionalities. A high proposition of such surrogates are built extensively fusing multiple sources of data, may it be published papers, patents, open repositories, or other resources. However, not much attention has been paid to the differences in quality and comprehensiveness of the known and unknown underlying physical parameters of the information sources that could have downstream implications during system optimization. Towards resolving this issue, a multi-source data fusion framework based on Latent Variable Gaussian Process (LVGP) is proposed. The individual data sources are tagged as a characteristic cate
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#39640;&#26031;&#36807;&#31243;&#26679;&#26412;&#36335;&#24452;&#27491;&#21017;&#24615;&#30340;&#26032;&#39062;&#21644;&#32039;&#20945;&#30340;&#29305;&#24449;&#25551;&#36848;&#65292;&#36890;&#36807;&#21327;&#26041;&#24046;&#26680;&#23545;&#24212;&#30340;GP&#26679;&#26412;&#36335;&#24452;&#36798;&#21040;&#19968;&#23450;&#27491;&#21017;&#24615;&#30340;&#20805;&#20998;&#24517;&#35201;&#26465;&#20214;&#65292;&#23545;&#24120;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#30340;GPs&#30340;&#26679;&#26412;&#36335;&#24452;&#27491;&#21017;&#24615;&#36827;&#34892;&#20102;&#25506;&#35752;&#12290;</title><link>https://arxiv.org/abs/2312.14886</link><description>&lt;p&gt;
&#26469;&#33258;&#21327;&#26041;&#24046;&#26680;&#30340;&#39640;&#26031;&#36807;&#31243;&#26679;&#26412;&#36335;&#24452;&#27491;&#21017;&#24615;
&lt;/p&gt;
&lt;p&gt;
Sample Path Regularity of Gaussian Processes from the Covariance Kernel
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.14886
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#39640;&#26031;&#36807;&#31243;&#26679;&#26412;&#36335;&#24452;&#27491;&#21017;&#24615;&#30340;&#26032;&#39062;&#21644;&#32039;&#20945;&#30340;&#29305;&#24449;&#25551;&#36848;&#65292;&#36890;&#36807;&#21327;&#26041;&#24046;&#26680;&#23545;&#24212;&#30340;GP&#26679;&#26412;&#36335;&#24452;&#36798;&#21040;&#19968;&#23450;&#27491;&#21017;&#24615;&#30340;&#20805;&#20998;&#24517;&#35201;&#26465;&#20214;&#65292;&#23545;&#24120;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#30340;GPs&#30340;&#26679;&#26412;&#36335;&#24452;&#27491;&#21017;&#24615;&#36827;&#34892;&#20102;&#25506;&#35752;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#65288;GPs&#65289;&#26159;&#23450;&#20041;&#20989;&#25968;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#20998;&#24067;&#30340;&#26368;&#24120;&#35265;&#24418;&#24335;&#20027;&#20041;&#12290;&#23613;&#31649;GPs&#30340;&#24212;&#29992;&#24191;&#27867;&#65292;&#20294;&#23545;&#20110;GP&#26679;&#26412;&#36335;&#24452;&#30340;&#20840;&#38754;&#29702;&#35299;&#65292;&#21363;&#23427;&#20204;&#23450;&#20041;&#27010;&#29575;&#27979;&#24230;&#30340;&#20989;&#25968;&#31354;&#38388;&#65292;&#23578;&#32570;&#20047;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;GPs&#19981;&#26159;&#36890;&#36807;&#27010;&#29575;&#27979;&#24230;&#26500;&#24314;&#30340;&#65292;&#32780;&#26159;&#36890;&#36807;&#22343;&#20540;&#20989;&#25968;&#21644;&#21327;&#26041;&#24046;&#26680;&#26500;&#24314;&#30340;&#12290;&#26412;&#25991;&#38024;&#23545;&#21327;&#26041;&#24046;&#26680;&#25552;&#20379;&#20102;GP&#26679;&#26412;&#36335;&#24452;&#36798;&#21040;&#32473;&#23450;&#27491;&#21017;&#24615;&#25152;&#38656;&#30340;&#20805;&#20998;&#24517;&#35201;&#26465;&#20214;&#12290;&#25105;&#20204;&#20351;&#29992;H\"older&#27491;&#21017;&#24615;&#26694;&#26550;&#65292;&#22240;&#20026;&#23427;&#25552;&#20379;&#20102;&#29305;&#21035;&#31616;&#21333;&#30340;&#26465;&#20214;&#65292;&#22312;&#24179;&#31283;&#21644;&#21508;&#21521;&#21516;&#24615;GPs&#30340;&#24773;&#20917;&#19979;&#36827;&#19968;&#27493;&#31616;&#21270;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#25105;&#20204;&#30340;&#32467;&#26524;&#20801;&#35768;&#23545;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#24120;&#29992;&#30340;GPs&#30340;&#26679;&#26412;&#36335;&#24452;&#27491;&#21017;&#24615;&#36827;&#34892;&#26032;&#39062;&#19988;&#24322;&#24120;&#32039;&#20945;&#30340;&#34920;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.14886v2 Announce Type: replace  Abstract: Gaussian processes (GPs) are the most common formalism for defining probability distributions over spaces of functions. While applications of GPs are myriad, a comprehensive understanding of GP sample paths, i.e. the function spaces over which they define a probability measure, is lacking. In practice, GPs are not constructed through a probability measure, but instead through a mean function and a covariance kernel. In this paper we provide necessary and sufficient conditions on the covariance kernel for the sample paths of the corresponding GP to attain a given regularity. We use the framework of H\"older regularity as it grants particularly straightforward conditions, which simplify further in the cases of stationary and isotropic GPs. We then demonstrate that our results allow for novel and unusually tight characterisations of the sample path regularities of the GPs commonly used in machine learning applications, such as the Mat\'
&lt;/p&gt;</description></item><item><title>&#39318;&#27425;&#23558;&#22343;&#22330; Langevin &#21160;&#21147;&#23398;&#25193;&#23637;&#21040;&#27010;&#29575;&#20998;&#24067;&#19978;&#30340;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#65292;&#25552;&#20986;&#20102; MFL-AG &#21644; MFL-ABR &#20004;&#31181;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#28151;&#21512; Nash &#24179;&#34913;&#30340;&#25910;&#25947;&#65292;&#36824;&#30740;&#31350;&#20102;&#26102;&#38388;&#21644;&#31890;&#23376;&#31163;&#25955;&#21270;&#21046;&#24230;&#20197;&#21450;&#20256;&#25773;&#28151;&#27788;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2312.01127</link><description>&lt;p&gt;
&#23545;&#20998;&#24067;&#26368;&#23567;&#26368;&#22823;&#38382;&#39064;&#30340;&#23545;&#31216;&#22343;&#22330; Langevin &#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
Symmetric Mean-field Langevin Dynamics for Distributional Minimax Problems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.01127
&lt;/p&gt;
&lt;p&gt;
&#39318;&#27425;&#23558;&#22343;&#22330; Langevin &#21160;&#21147;&#23398;&#25193;&#23637;&#21040;&#27010;&#29575;&#20998;&#24067;&#19978;&#30340;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#65292;&#25552;&#20986;&#20102; MFL-AG &#21644; MFL-ABR &#20004;&#31181;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#28151;&#21512; Nash &#24179;&#34913;&#30340;&#25910;&#25947;&#65292;&#36824;&#30740;&#31350;&#20102;&#26102;&#38388;&#21644;&#31890;&#23376;&#31163;&#25955;&#21270;&#21046;&#24230;&#20197;&#21450;&#20256;&#25773;&#28151;&#27788;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#23558;&#22343;&#22330; Langevin &#21160;&#21147;&#23398;&#25193;&#23637;&#21040;&#27010;&#29575;&#20998;&#24067;&#19978;&#30340;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#65292;&#20351;&#29992;&#23545;&#31216;&#19988;&#32463;&#36807;&#35777;&#26126;&#25910;&#25947;&#30340;&#26356;&#26032;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22343;&#22330; Langevin &#24179;&#22343;&#26799;&#24230;&#65288;MFL-AG&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#21333;&#24490;&#29615;&#31639;&#27861;&#65292;&#36890;&#36807;&#26032;&#39062;&#30340;&#21152;&#26435;&#24179;&#22343;&#65292;&#22312;&#20998;&#24067;&#31354;&#38388;&#20013;&#23454;&#29616;&#26799;&#24230;&#19979;&#38477;&#19978;&#21319;&#65292;&#24182;&#30830;&#31435;&#20102;&#23545;&#28151;&#21512; Nash &#24179;&#34913;&#30340;&#24179;&#22343;&#36845;&#20195;&#25910;&#25947;&#12290;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#26102;&#38388;&#21644;&#31890;&#23376;&#31163;&#25955;&#21270;&#21046;&#24230;&#65292;&#24182;&#35777;&#26126;&#20102;&#19968;&#20010;&#26032;&#30340;&#26102;&#38388;&#22343;&#21248;&#20256;&#25773;&#28151;&#27788;&#32467;&#26524;&#65292;&#35813;&#32467;&#26524;&#32771;&#34385;&#20102;&#31890;&#23376;&#30456;&#20114;&#20316;&#29992;&#23545;&#25152;&#26377;&#20808;&#21069;&#20998;&#24067;&#30340;&#20381;&#36182;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22343;&#22330; Langevin &#38170;&#23450;&#26368;&#20339;&#21709;&#24212;&#65288;MFL-ABR&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#26368;&#20339;&#21709;&#24212;&#21160;&#24577;&#30340;&#23545;&#31216;&#21452;&#24490;&#29615;&#31639;&#27861;&#65292;&#20855;&#26377;&#32447;&#24615;&#30340;&#26368;&#36845;&#20195;&#25910;&#25947;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38646;&#21644;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#30340;&#24212;&#29992;&#65292;&#24182;&#36827;&#34892;&#20102;&#27169;&#25311;&#65292;&#23637;&#31034;&#20102;&#38271;&#26399;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.01127v2 Announce Type: replace-cross  Abstract: In this paper, we extend mean-field Langevin dynamics to minimax optimization over probability distributions for the first time with symmetric and provably convergent updates. We propose mean-field Langevin averaged gradient (MFL-AG), a single-loop algorithm that implements gradient descent ascent in the distribution spaces with a novel weighted averaging, and establish average-iterate convergence to the mixed Nash equilibrium. We also study both time and particle discretization regimes and prove a new uniform-in-time propagation of chaos result which accounts for the dependency of the particle interactions on all previous distributions. Furthermore, we propose mean-field Langevin anchored best response (MFL-ABR), a symmetric double-loop algorithm based on best response dynamics with linear last-iterate convergence. Finally, we study applications to zero-sum Markov games and conduct simulations demonstrating long-term optimalit
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;iDeepViewLearn&#65288;&#21487;&#35299;&#37322;&#30340;&#22810;&#35270;&#22270;&#23398;&#20064;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65289;&#29992;&#20110;&#22810;&#35270;&#22270;&#25968;&#25454;&#30340;&#38750;&#32447;&#24615;&#20851;&#31995;&#23398;&#20064;&#21644;&#29305;&#24449;&#36873;&#25321;&#65292;&#34701;&#21512;&#28145;&#24230;&#23398;&#20064;&#30340;&#28789;&#27963;&#24615;&#21644;&#32479;&#35745;&#20248;&#21183;&#65292;&#32473;&#20986;&#21487;&#35299;&#37322;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2302.07930</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#22810;&#35270;&#22270;&#23398;&#20064;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Interpretable Deep Learning Methods for Multiview Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2302.07930
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;iDeepViewLearn&#65288;&#21487;&#35299;&#37322;&#30340;&#22810;&#35270;&#22270;&#23398;&#20064;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65289;&#29992;&#20110;&#22810;&#35270;&#22270;&#25968;&#25454;&#30340;&#38750;&#32447;&#24615;&#20851;&#31995;&#23398;&#20064;&#21644;&#29305;&#24449;&#36873;&#25321;&#65292;&#34701;&#21512;&#28145;&#24230;&#23398;&#20064;&#30340;&#28789;&#27963;&#24615;&#21644;&#32479;&#35745;&#20248;&#21183;&#65292;&#32473;&#20986;&#21487;&#35299;&#37322;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25216;&#26415;&#36827;&#27493;&#24050;&#32463;&#23454;&#29616;&#20102;&#29983;&#25104;&#29420;&#29305;&#19988;&#20114;&#34917;&#31867;&#22411;&#30340;&#25968;&#25454;&#25110;&#35270;&#22270;&#65288;&#20363;&#22914;&#22522;&#22240;&#32452;&#23398;&#12289;&#34507;&#30333;&#36136;&#32452;&#23398;&#12289;&#20195;&#35874;&#32452;&#23398;&#65289;&#65292;&#24182;&#24320;&#21019;&#20102;&#22810;&#35270;&#22270;&#23398;&#20064;&#30740;&#31350;&#26032;&#26102;&#20195;&#65292;&#26377;&#28508;&#21147;&#24102;&#26469;&#26032;&#30340;&#29983;&#29289;&#21307;&#23398;&#21457;&#29616;&#12290;&#25105;&#20204;&#25552;&#20986; iDeepViewLearn&#65288;Interpretable Deep Learning Method for Multiview Learning&#65289;&#65292;&#29992;&#20110;&#23398;&#20064;&#26469;&#33258;&#22810;&#35270;&#22270;&#25968;&#25454;&#20013;&#30340;&#38750;&#32447;&#24615;&#20851;&#31995;&#65292;&#21516;&#26102;&#23454;&#29616;&#29305;&#24449;&#36873;&#25321;&#12290;iDeepViewLearn&#32467;&#21512;&#20102;&#28145;&#24230;&#23398;&#20064;&#30340;&#28789;&#27963;&#24615;&#19982;&#25968;&#25454;&#21644;&#22522;&#20110;&#30693;&#35782;&#30340;&#29305;&#24449;&#36873;&#25321;&#30340;&#32479;&#35745;&#20248;&#21183;&#65292;&#20197;&#32473;&#20986;&#21487;&#35299;&#37322;&#30340;&#32467;&#26524;&#12290;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#36890;&#36807;&#26368;&#23567;&#21270;&#35266;&#23519;&#25968;&#25454;&#19982;&#37325;&#26500;&#25968;&#25454;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#24182;&#23545;&#37325;&#26500;&#25968;&#25454;&#26045;&#21152;&#27491;&#21017;&#21270;&#24809;&#32602;&#26469;&#23398;&#20064;&#35270;&#22270;&#29420;&#31435;&#30340;&#20302;&#32500;&#23884;&#20837;&#12290;&#22270;&#30340;&#24402;&#19968;&#21270;&#25289;&#26222;&#25289;&#26031;&#29992;&#20110;&#24314;&#27169;&#21464;&#37327;&#20043;&#38388;&#30340;&#21452;&#36793;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2302.07930v2 Announce Type: replace  Abstract: Technological advances have enabled the generation of unique and complementary types of data or views (e.g. genomics, proteomics, metabolomics) and opened up a new era in multiview learning research with the potential to lead to new biomedical discoveries. We propose iDeepViewLearn (Interpretable Deep Learning Method for Multiview Learning) for learning nonlinear relationships in data from multiple views while achieving feature selection. iDeepViewLearn combines deep learning flexibility with the statistical benefits of data and knowledge-driven feature selection, giving interpretable results. Deep neural networks are used to learn view-independent low-dimensional embedding through an optimization problem that minimizes the difference between observed and reconstructed data, while imposing a regularization penalty on the reconstructed data. The normalized Laplacian of a graph is used to model bilateral relationships between variables
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#20248;&#25193;&#23637;&#37051;&#22495;&#35268;&#21017;&#30340;&#38598;&#25104;&#26041;&#27861;&#65292;&#36890;&#36807;&#26032;&#35268;&#21017;&#30830;&#23450;&#37051;&#23621;&#21644;&#27169;&#22411;&#36873;&#25321;&#31574;&#30053;&#26469;&#35299;&#20915;&#20256;&#32479;$k$&#26368;&#36817;&#37051;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#21644;&#25552;&#21319;&#38598;&#25104;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2211.11278</link><description>&lt;p&gt;
&#26368;&#20248;&#25193;&#23637;&#37051;&#22495;&#35268;&#21017;$k$&#26368;&#36817;&#37051;&#38598;&#25104;
&lt;/p&gt;
&lt;p&gt;
Optimal Extended Neighbourhood Rule $k$ Nearest Neighbours Ensemble
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2211.11278
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#20248;&#25193;&#23637;&#37051;&#22495;&#35268;&#21017;&#30340;&#38598;&#25104;&#26041;&#27861;&#65292;&#36890;&#36807;&#26032;&#35268;&#21017;&#30830;&#23450;&#37051;&#23621;&#21644;&#27169;&#22411;&#36873;&#25321;&#31574;&#30053;&#26469;&#35299;&#20915;&#20256;&#32479;$k$&#26368;&#36817;&#37051;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#21644;&#25552;&#21319;&#38598;&#25104;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;$k$&#26368;&#36817;&#37051;($k$NN)&#26041;&#27861;&#20351;&#29992;&#19968;&#20010;&#29699;&#24418;&#21306;&#22495;&#20869;&#30340;&#36317;&#31163;&#20844;&#24335;&#26469;&#30830;&#23450;&#35757;&#32451;&#35266;&#27979;&#20013;&#19982;&#27979;&#35797;&#26679;&#26412;&#28857;&#26368;&#25509;&#36817;&#30340;$k$&#20010;&#35266;&#27979;&#12290;&#28982;&#32780;&#65292;&#24403;&#27979;&#35797;&#28857;&#20301;&#20110;&#35813;&#21306;&#22495;&#20043;&#22806;&#26102;&#65292;&#36825;&#31181;&#26041;&#27861;&#21487;&#33021;&#19981;&#36215;&#20316;&#29992;&#12290;&#27492;&#22806;&#65292;&#32858;&#21512;&#35768;&#22810;&#22522;&#30784;$k$NN&#23398;&#20064;&#22120;&#21487;&#33021;&#20250;&#23548;&#33268;&#30001;&#20110;&#39640;&#20998;&#31867;&#35823;&#24046;&#32780;&#34920;&#29616;&#19981;&#20339;&#30340;&#38598;&#25104;&#24615;&#33021;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#26368;&#20248;&#25193;&#23637;&#37051;&#22495;&#35268;&#21017;&#30340;&#38598;&#25104;&#26041;&#27861;&#12290;&#35813;&#35268;&#21017;&#20174;&#36317;&#31163;&#26410;&#35265;&#35266;&#27979;&#26368;&#36817;&#30340;&#26679;&#26412;&#28857;&#24320;&#22987;&#65292;&#32463;&#36807;$k$&#27493;&#30830;&#23450;&#37051;&#23621;&#65292;&#24182;&#36873;&#25321;&#30452;&#21040;&#36798;&#21040;&#25152;&#38656;&#25968;&#37327;&#30340;&#35266;&#27979;&#25968;&#25454;&#28857;&#12290;&#27599;&#20010;&#22522;&#30784;&#27169;&#22411;&#37117;&#26159;&#22312;&#19968;&#20010;&#38543;&#26426;&#29305;&#24449;&#23376;&#38598;&#19978;&#30340;&#33258;&#20030;&#26679;&#26412;&#19978;&#26500;&#24314;&#30340;&#65292;&#24182;&#19988;&#22312;&#26500;&#24314;&#36275;&#22815;&#25968;&#37327;&#30340;&#27169;&#22411;&#21518;&#22522;&#20110;&#34955;&#22806;&#34920;&#29616;&#36873;&#25321;&#26368;&#20248;&#27169;&#22411;&#12290;&#25552;&#20986;&#30340;&#38598;&#25104;&#26041;&#27861;&#19982;st&#36827;&#34892;&#20102;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
arXiv:2211.11278v2 Announce Type: replace-cross  Abstract: The traditional k nearest neighbor (kNN) approach uses a distance formula within a spherical region to determine the k closest training observations to a test sample point. However, this approach may not work well when test point is located outside this region. Moreover, aggregating many base kNN learners can result in poor ensemble performance due to high classification errors. To address these issues, a new optimal extended neighborhood rule based ensemble method is proposed in this paper. This rule determines neighbors in k steps starting from the closest sample point to the unseen observation and selecting subsequent nearest data points until the required number of observations is reached. Each base model is constructed on a bootstrap sample with a random subset of features, and optimal models are selected based on out-of-bag performance after building a sufficient number of models. The proposed ensemble is compared with st
&lt;/p&gt;</description></item><item><title>&#25552;&#20379;&#20102;&#26465;&#20214;&#30697;&#38480;&#21046;&#38382;&#39064;&#30340;&#21151;&#33021;&#21270;&#24191;&#20041;&#32463;&#39564;&#20284;&#28982;&#20272;&#35745;&#26041;&#27861;&#65292;&#24182;&#25506;&#32034;&#20102;&#20854;&#22312;&#23567;&#26679;&#26412;&#24615;&#33021;&#19978;&#30340;&#20248;&#21183;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#22522;&#20110;&#26680;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#23454;&#29616;&#26041;&#24335;&#12290;</title><link>https://arxiv.org/abs/2207.04771</link><description>&lt;p&gt;
&#26465;&#20214;&#30697;&#38480;&#21046;&#30340;&#21151;&#33021;&#21270;&#24191;&#20041;&#32463;&#39564;&#20284;&#28982;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Functional Generalized Empirical Likelihood Estimation for Conditional Moment Restrictions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2207.04771
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20379;&#20102;&#26465;&#20214;&#30697;&#38480;&#21046;&#38382;&#39064;&#30340;&#21151;&#33021;&#21270;&#24191;&#20041;&#32463;&#39564;&#20284;&#28982;&#20272;&#35745;&#26041;&#27861;&#65292;&#24182;&#25506;&#32034;&#20102;&#20854;&#22312;&#23567;&#26679;&#26412;&#24615;&#33021;&#19978;&#30340;&#20248;&#21183;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#22522;&#20110;&#26680;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#23454;&#29616;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22240;&#26524;&#25512;&#26029;&#12289;&#32463;&#27982;&#23398;&#20064;&#20197;&#21450;&#26356;&#19968;&#33324;&#30340;&#40065;&#26834;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#37325;&#35201;&#38382;&#39064;&#21487;&#20197;&#34987;&#34920;&#36798;&#20026;&#26465;&#20214;&#30697;&#38480;&#21046;&#65292;&#20294;&#30001;&#20110;&#38656;&#35201;&#35299;&#20915;&#19968;&#31995;&#21015;&#30340;&#26080;&#26465;&#20214;&#30697;&#38480;&#21046;&#65292;&#20272;&#35745;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#36890;&#36807;&#23558;&#24191;&#20041;&#30697;&#27861;&#65288;GMM&#65289;&#25193;&#23637;&#21040;&#36830;&#32493;&#30697;&#38480;&#21046;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#19982;&#27492;&#30456;&#21453;&#65292;&#24191;&#20041;&#32463;&#39564;&#20284;&#28982;&#65288;GEL&#65289;&#25552;&#20379;&#20102;&#19968;&#20010;&#26356;&#19968;&#33324;&#30340;&#26694;&#26550;&#65292;&#24182;&#19988;&#24050;&#32463;&#34987;&#35777;&#26126;&#22312;&#23567;&#26679;&#26412;&#24615;&#33021;&#19978;&#20248;&#20110;&#22522;&#20110;GMM&#30340;&#20272;&#35745;&#37327;&#12290;&#20026;&#20102;&#20174;&#26368;&#36817;&#30340;&#26426;&#22120;&#23398;&#20064;&#21457;&#23637;&#20013;&#21463;&#30410;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;GEL&#30340;&#21151;&#33021;&#37325;&#26500;&#65292;&#20854;&#20013;&#21487;&#20197;&#21033;&#29992;&#20219;&#24847;&#27169;&#22411;&#12290;&#21463;&#32467;&#26524;&#30340;&#26080;&#38480;&#32500;&#20248;&#21270;&#38382;&#39064;&#30340;&#23545;&#20598;&#24418;&#24335;&#21551;&#21457;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#23454;&#29992;&#26041;&#27861;&#24182;&#25506;&#35752;&#20102;&#20854;&#28176;&#36817;&#24615;&#36136;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#22522;&#20110;&#26680;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#23454;&#29616;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2207.04771v2 Announce Type: replace  Abstract: Important problems in causal inference, economics, and, more generally, robust machine learning can be expressed as conditional moment restrictions, but estimation becomes challenging as it requires solving a continuum of unconditional moment restrictions. Previous works addressed this problem by extending the generalized method of moments (GMM) to continuum moment restrictions. In contrast, generalized empirical likelihood (GEL) provides a more general framework and has been shown to enjoy favorable small-sample properties compared to GMM-based estimators. To benefit from recent developments in machine learning, we provide a functional reformulation of GEL in which arbitrary models can be leveraged. Motivated by a dual formulation of the resulting infinite dimensional optimization problem, we devise a practical method and explore its asymptotic properties. Finally, we provide kernel- and neural network-based implementations of the e
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#22240;&#26524;&#35780;&#20998;&#20316;&#20026;&#19968;&#31181;&#26032;&#22411;&#26041;&#27861;&#65292;&#25903;&#25345;&#20915;&#31574;&#21046;&#23450;&#65292;&#25552;&#20379;&#27934;&#23519;&#21147;&#65292;&#24182;&#21487;&#29992;&#20110;&#25928;&#24212;&#20272;&#35745;&#12289;&#25928;&#24212;&#25490;&#24207;&#21644;&#25928;&#24212;&#20998;&#31867;&#12290;</title><link>https://arxiv.org/abs/2206.12532</link><description>&lt;p&gt;
&#22240;&#26524;&#35780;&#20998;&#65306;&#25928;&#24212;&#20272;&#35745;&#12289;&#25928;&#24212;&#25490;&#24207;&#21644;&#25928;&#24212;&#20998;&#31867;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Causal Scoring: A Framework for Effect Estimation, Effect Ordering, and Effect Classification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2206.12532
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#22240;&#26524;&#35780;&#20998;&#20316;&#20026;&#19968;&#31181;&#26032;&#22411;&#26041;&#27861;&#65292;&#25903;&#25345;&#20915;&#31574;&#21046;&#23450;&#65292;&#25552;&#20379;&#27934;&#23519;&#21147;&#65292;&#24182;&#21487;&#29992;&#20110;&#25928;&#24212;&#20272;&#35745;&#12289;&#25928;&#24212;&#25490;&#24207;&#21644;&#25928;&#24212;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#22240;&#26524;&#35780;&#20998;&#24341;&#20837;&#21040;&#20915;&#31574;&#21046;&#23450;&#30340;&#32972;&#26223;&#20013;&#20316;&#20026;&#19968;&#31181;&#26032;&#39062;&#26041;&#27861;&#65292;&#28041;&#21450;&#20272;&#35745;&#25903;&#25345;&#20915;&#31574;&#21046;&#23450;&#30340;&#24471;&#20998;&#65292;&#20174;&#32780;&#25552;&#20379;&#22240;&#26524;&#25928;&#24212;&#30340;&#27934;&#23519;&#21147;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#36825;&#20123;&#35780;&#20998;&#30340;&#19977;&#31181;&#26377;&#20215;&#20540;&#30340;&#22240;&#26524;&#35299;&#37322;&#65306;&#25928;&#24212;&#20272;&#35745;&#65288;EE&#65289;&#12289;&#25928;&#24212;&#25490;&#24207;&#65288;EO&#65289;&#21644;&#25928;&#24212;&#20998;&#31867;&#65288;EC&#65289;&#12290;&#22312;EE&#35299;&#37322;&#20013;&#65292;&#22240;&#26524;&#35780;&#20998;&#20195;&#34920;&#20102;&#25928;&#24212;&#26412;&#36523;&#12290;EO&#35299;&#37322;&#26263;&#31034;&#35780;&#20998;&#21487;&#20197;&#20316;&#20026;&#25928;&#24212;&#22823;&#23567;&#30340;&#20195;&#29702;&#65292;&#21487;&#20197;&#26681;&#25454;&#20854;&#22240;&#26524;&#25928;&#24212;&#23545;&#20010;&#20307;&#36827;&#34892;&#25490;&#24207;&#12290;EC&#35299;&#37322;&#36890;&#36807;&#39044;&#23450;&#20041;&#30340;&#38408;&#20540;&#65292;&#20351;&#20010;&#20307;&#20998;&#20026;&#39640;&#25928;&#24212;&#21644;&#20302;&#25928;&#24212;&#31867;&#21035;&#12290;&#25105;&#20204;&#36890;&#36807;&#20004;&#20010;&#20851;&#38190;&#32467;&#26524;&#23637;&#31034;&#20102;&#36825;&#20123;&#26367;&#20195;&#22240;&#26524;&#35299;&#37322;&#65288;EO&#21644;EC&#65289;&#30340;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2206.12532v4 Announce Type: replace-cross  Abstract: This paper introduces causal scoring as a novel approach to frame causal estimation in the context of decision making. Causal scoring entails the estimation of scores that support decision making by providing insights into causal effects. We present three valuable causal interpretations of these scores: effect estimation (EE), effect ordering (EO), and effect classification (EC). In the EE interpretation, the causal score represents the effect itself. The EO interpretation implies that the score can serve as a proxy for the magnitude of the effect, enabling the sorting of individuals based on their causal effects. The EC interpretation enables the classification of individuals into high- and low-effect categories using a predefined threshold. We demonstrate the value of these alternative causal interpretations (EO and EC) through two key results. First, we show that aligning the statistical modeling with the desired causal inte
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#22411;&#22810;&#33218;&#36172;&#21338;&#26426;&#35774;&#32622;&#65292;&#25429;&#25417;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#29992;&#25143;&#31163;&#24320;&#30340;&#24773;&#20917;&#65292;&#39318;&#27425;&#35777;&#26126;&#20102;&#22312;&#25152;&#26377;&#29992;&#25143;&#20849;&#20139;&#30456;&#21516;&#31867;&#22411;&#26102;&#65292;&#22522;&#20110;UCB&#30340;&#31639;&#27861;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>https://arxiv.org/abs/2203.13423</link><description>&lt;p&gt;
&#29992;&#31163;&#24320;&#30340;&#36172;&#21338;&#26426;&#27169;&#22411;&#24314;&#35758;&#31995;&#32479;&#20013;&#30340;&#27969;&#22833;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
Modeling Attrition in Recommender Systems with Departing Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2203.13423
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#22411;&#22810;&#33218;&#36172;&#21338;&#26426;&#35774;&#32622;&#65292;&#25429;&#25417;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#29992;&#25143;&#31163;&#24320;&#30340;&#24773;&#20917;&#65292;&#39318;&#27425;&#35777;&#26126;&#20102;&#22312;&#25152;&#26377;&#29992;&#25143;&#20849;&#20139;&#30456;&#21516;&#31867;&#22411;&#26102;&#65292;&#22522;&#20110;UCB&#30340;&#31639;&#27861;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20256;&#32479;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#65292;&#25512;&#33616;&#31995;&#32479;&#30340;&#31574;&#30053;&#24433;&#21709;&#22870;&#21169;&#30340;&#33719;&#21462;&#65292;&#20294;&#19981;&#24433;&#21709;&#20132;&#20114;&#30340;&#38271;&#24230;&#12290;&#28982;&#32780;&#65292;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#65292;&#19981;&#28385;&#36275;&#30340;&#29992;&#25143;&#21487;&#33021;&#20250;&#31163;&#24320;&#65288;&#24182;&#27704;&#36828;&#19981;&#20877;&#22238;&#26469;&#65289;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25429;&#25417;&#36825;&#31181;&#31574;&#30053;&#20381;&#36182;&#24615;&#26102;&#27573;&#30340;&#26032;&#22411;&#22810;&#33218;&#36172;&#21338;&#26426;&#35774;&#32622;&#12290;&#25105;&#20204;&#30340;&#35774;&#32622;&#21253;&#25324;&#19968;&#20010;&#26377;&#38480;&#30340;&#29992;&#25143;&#31867;&#22411;&#38598;&#21512;&#65292;&#21644;&#22810;&#20010;&#20855;&#26377;&#20271;&#21162;&#21033;&#22238;&#25253;&#30340;&#33218;&#12290;&#27599;&#20010;&#65288;&#29992;&#25143;&#31867;&#22411;&#65292;&#33218;&#65289;&#20803;&#32452;&#23545;&#24212;&#19968;&#20010;&#65288;&#26410;&#30693;&#30340;&#65289;&#22870;&#21169;&#27010;&#29575;&#12290;&#27599;&#20010;&#29992;&#25143;&#30340;&#31867;&#22411;&#26368;&#21021;&#26159;&#26410;&#30693;&#30340;&#65292;&#21482;&#33021;&#36890;&#36807;&#20854;&#23545;&#25512;&#33616;&#30340;&#21709;&#24212;&#26469;&#25512;&#26029;&#12290;&#27492;&#22806;&#65292;&#22914;&#26524;&#29992;&#25143;&#23545;&#20182;&#20204;&#30340;&#25512;&#33616;&#19981;&#28385;&#24847;&#65292;&#20182;&#20204;&#21487;&#33021;&#20250;&#31163;&#24320;&#31995;&#32479;&#12290;&#25105;&#20204;&#39318;&#20808;&#35299;&#20915;&#20102;&#25152;&#26377;&#29992;&#25143;&#20849;&#20139;&#30456;&#21516;&#31867;&#22411;&#30340;&#24773;&#20917;&#65292;&#35777;&#26126;&#20102;&#26368;&#36817;&#22522;&#20110;UCB&#30340;&#31639;&#27861;&#30340;&#26368;&#20248;&#24615;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36716;&#21521;&#26356;&#20855;&#25361;&#25112;&#24615;&#30340;&#24773;&#20917;&#65292;&#21363;&#29992;&#25143;&#20998;&#20026;&#20004;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2203.13423v2 Announce Type: replace  Abstract: Traditionally, when recommender systems are formalized as multi-armed bandits, the policy of the recommender system influences the rewards accrued, but not the length of interaction. However, in real-world systems, dissatisfied users may depart (and never come back). In this work, we propose a novel multi-armed bandit setup that captures such policy-dependent horizons. Our setup consists of a finite set of user types, and multiple arms with Bernoulli payoffs. Each (user type, arm) tuple corresponds to an (unknown) reward probability. Each user's type is initially unknown and can only be inferred through their response to recommendations. Moreover, if a user is dissatisfied with their recommendation, they might depart the system. We first address the case where all users share the same type, demonstrating that a recent UCB-based algorithm is optimal. We then move forward to the more challenging case, where users are divided among two 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#26032;&#30340;&#24191;&#20041;&#23725;&#22238;&#24402;&#25910;&#32553;&#36335;&#24452;&#65292;&#36890;&#36807;&#26368;&#23567;&#22343;&#26041;&#35823;&#24046;&#39118;&#38505;&#30340;&#26368;&#22823;&#20284;&#28982;&#23454;&#29616;&#26368;&#20339;&#26041;&#24046;-&#20559;&#24046;&#26435;&#34913;&#65292;&#25552;&#20379;&#20102;&#23453;&#36149;&#30340;&#25968;&#25454;&#20998;&#26512;&#35265;&#35299;&#12290;</title><link>https://arxiv.org/abs/2103.05161</link><description>&lt;p&gt;
&#39640;&#25928;&#25910;&#32553;&#36335;&#24452;&#65306;&#26368;&#23567;&#22343;&#26041;&#35823;&#24046;&#39118;&#38505;&#30340;&#26368;&#22823;&#20284;&#28982;
&lt;/p&gt;
&lt;p&gt;
The Efficient Shrinkage Path: Maximum Likelihood of Minimum MSE Risk
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2103.05161
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#26032;&#30340;&#24191;&#20041;&#23725;&#22238;&#24402;&#25910;&#32553;&#36335;&#24452;&#65292;&#36890;&#36807;&#26368;&#23567;&#22343;&#26041;&#35823;&#24046;&#39118;&#38505;&#30340;&#26368;&#22823;&#20284;&#28982;&#23454;&#29616;&#26368;&#20339;&#26041;&#24046;-&#20559;&#24046;&#26435;&#34913;&#65292;&#25552;&#20379;&#20102;&#23453;&#36149;&#30340;&#25968;&#25454;&#20998;&#26512;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24191;&#20041;&#23725;&#22238;&#24402;&#25910;&#32553;&#36335;&#24452;&#65292;&#35813;&#36335;&#24452;&#26159;&#22312;&#36890;&#36807;&#20351;&#24635;&#20307;&#22312;&#27491;&#24577;&#20998;&#24067;&#29702;&#35770;&#19979;&#23454;&#29616;&#26368;&#20339;&#26041;&#24046;-&#20559;&#24046;&#26435;&#34913;&#30340;&#22238;&#24402;&#31995;&#25968;&#20272;&#35745;&#21521;&#37327;&#30340;&#38480;&#21046;&#26465;&#20214;&#19979;&#23613;&#21487;&#33021;&#30701;&#12290;&#28608;&#21169;&#21644;&#23637;&#31034;&#20102;&#20116;&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#23725;&#36335;&#24452;&#36712;&#36857;&#26174;&#31034;&#20197;&#21450;&#20854;&#20182;&#22270;&#24418;&#12290;&#36825;&#20123;&#21487;&#35270;&#21270;&#25552;&#20379;&#20102;&#23453;&#36149;&#30340;&#25968;&#25454;&#20998;&#26512;&#35265;&#35299;&#65292;&#24182;&#25552;&#39640;&#20102;&#23545;&#23558;&#32447;&#24615;&#27169;&#22411;&#25311;&#21512;&#21040;&#30149;&#24577;&#65288;&#28151;&#28102;&#65289;&#25968;&#25454;&#30340;&#30740;&#31350;&#20154;&#21592;&#21644;&#25968;&#25454;&#31185;&#23398;&#23478;&#30340;&#33258;&#20449;&#24515;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2103.05161v5 Announce Type: replace-cross  Abstract: A new generalized ridge regression shrinkage path is proposed that is as short as possible under the restriction that it must pass through the vector of regression coefficient estimators that make the overall Optimal Variance-Bias Trade-Off under Normal distribution-theory. Five distinct types of ridge TRACE displays plus other graphics for this efficient path are motivated and illustrated here. These visualizations provide invaluable data-analytic insights and improved self-confidence to researchers and data scientists fitting linear models to ill-conditioned (confounded) data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;Fr&#233;chet&#38543;&#26426;&#26862;&#26519;&#65292;&#20801;&#35768;&#22788;&#29702;&#20540;&#22312;&#19968;&#33324;&#24230;&#37327;&#31354;&#38388;&#30340;&#25968;&#25454;&#65292;&#24182;&#24341;&#20837;&#20102;&#26032;&#30340;&#26641;&#33410;&#28857;&#20998;&#35010;&#26041;&#24335;&#65292;&#25193;&#23637;&#20102;&#39044;&#27979;&#36807;&#31243;&#65292;&#25552;&#20986;&#20102;&#19968;&#33268;&#24615;&#23450;&#29702;&#65292;&#24182;&#36866;&#29992;&#20110;&#25968;&#25454;&#39537;&#21160;&#20998;&#21306;&#30340;Fr&#233;chet&#32431;&#19968;&#33268;&#38543;&#26426;&#26641;</title><link>https://arxiv.org/abs/1906.01741</link><description>&lt;p&gt;
&#38024;&#23545;&#20855;&#26377;&#38750;&#27431;&#20960;&#37324;&#24503;&#39044;&#27979;&#21464;&#37327;&#30340;&#24230;&#37327;&#31354;&#38388;&#22238;&#24402;&#38382;&#39064;&#30340;Fr&#233;chet&#38543;&#26426;&#26862;&#26519;
&lt;/p&gt;
&lt;p&gt;
Fr\'echet random forests for metric space valued regression with non euclidean predictors
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/1906.01741
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;Fr&#233;chet&#38543;&#26426;&#26862;&#26519;&#65292;&#20801;&#35768;&#22788;&#29702;&#20540;&#22312;&#19968;&#33324;&#24230;&#37327;&#31354;&#38388;&#30340;&#25968;&#25454;&#65292;&#24182;&#24341;&#20837;&#20102;&#26032;&#30340;&#26641;&#33410;&#28857;&#20998;&#35010;&#26041;&#24335;&#65292;&#25193;&#23637;&#20102;&#39044;&#27979;&#36807;&#31243;&#65292;&#25552;&#20986;&#20102;&#19968;&#33268;&#24615;&#23450;&#29702;&#65292;&#24182;&#36866;&#29992;&#20110;&#25968;&#25454;&#39537;&#21160;&#20998;&#21306;&#30340;Fr&#233;chet&#32431;&#19968;&#33268;&#38543;&#26426;&#26641;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26862;&#26519;&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#20110;&#31185;&#23398;&#30740;&#31350;&#39046;&#22495;&#30340;&#32479;&#35745;&#23398;&#20064;&#26041;&#27861;&#65292;&#22240;&#20026;&#23427;&#33021;&#22815;&#23398;&#20064;&#36755;&#20837;&#21644;&#36755;&#20986;&#21464;&#37327;&#20043;&#38388;&#22797;&#26434;&#30340;&#20851;&#31995;&#65292;&#21516;&#26102;&#20063;&#33021;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#30340;&#38543;&#26426;&#26862;&#26519;&#26041;&#27861;&#23545;&#22788;&#29702;&#26354;&#32447;&#12289;&#22270;&#20687;&#21644;&#24418;&#29366;&#31561;&#24322;&#36136;&#25968;&#25454;&#30340;&#28789;&#27963;&#24615;&#19981;&#22815;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;Fr&#233;chet&#26641;&#21644;Fr&#233;chet&#38543;&#26426;&#26862;&#26519;&#65292;&#20801;&#35768;&#22788;&#29702;&#36755;&#20837;&#21644;&#36755;&#20986;&#21464;&#37327;&#21462;&#20540;&#22312;&#19968;&#33324;&#24230;&#37327;&#31354;&#38388;&#20013;&#30340;&#25968;&#25454;&#12290;&#20026;&#27492;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26641;&#33410;&#28857;&#20998;&#35010;&#26041;&#24335;&#65292;&#24182;&#24191;&#20041;&#21270;&#20102;&#26641;&#21644;&#26862;&#26519;&#30340;&#39044;&#27979;&#36807;&#31243;&#12290;&#38543;&#26426;&#26862;&#26519;&#30340;&#34955;&#22806;&#35823;&#24046;&#21644;&#21464;&#37327;&#37325;&#35201;&#24615;&#24471;&#20998;&#33258;&#28982;&#24471;&#21040;&#20102;&#35843;&#25972;&#12290;&#32473;&#20986;&#20102;&#20351;&#29992;&#25968;&#25454;&#39537;&#21160;&#20998;&#21306;&#30340;Fr&#233;chet&#22238;&#24402;&#22270;&#39044;&#27979;&#22120;&#30340;&#19968;&#33268;&#24615;&#23450;&#29702;&#65292;&#24182;&#24212;&#29992;&#20110;Fr&#233;chet&#32431;&#19968;&#33268;&#38543;&#26426;&#26641;&#12290;&#35813;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
arXiv:1906.01741v3 Announce Type: replace-cross  Abstract: Random forests are a statistical learning method widely used in many areas of scientific research because of its ability to learn complex relationships between input and output variables and also its capacity to handle high-dimensional data. However, current random forest approaches are not flexible enough to handle heterogeneous data such as curves, images and shapes. In this paper, we introduce Fr\'echet trees and Fr\'echet random forests, which allow to handle data for which input and output variables take values in general metric spaces. To this end, a new way of splitting the nodes of trees is introduced and the prediction procedures of trees and forests are generalized. Then, random forests out-of-bag error and variable importance score are naturally adapted. A consistency theorem for Fr\'echet regressogram predictor using data-driven partitions is given and applied to Fr\'echet purely uniformly random trees. The method i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#31283;&#20581;&#20272;&#35745;&#26041;&#27861;&#65288;MTuM&#65289;&#65292;&#29992;&#20110;&#20174;&#20998;&#32452;&#25968;&#25454;&#20013;&#20272;&#35745;Pareto&#20998;&#24067;&#30340;&#23614;&#25351;&#25968;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#24212;&#29992;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#21644;&#27169;&#25311;&#30740;&#31350;&#39564;&#35777;&#20102;&#20854;&#25512;&#29702;&#21512;&#29702;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.14593</link><description>&lt;p&gt;
&#20174;&#20998;&#32452;&#25968;&#25454;&#20013;&#31283;&#20581;&#20272;&#35745;Pareto&#30340;&#23610;&#24230;&#21442;&#25968;
&lt;/p&gt;
&lt;p&gt;
Robust Estimation of Pareto's Scale Parameter from Grouped Data. (arXiv:2401.14593v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14593
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#31283;&#20581;&#20272;&#35745;&#26041;&#27861;&#65288;MTuM&#65289;&#65292;&#29992;&#20110;&#20174;&#20998;&#32452;&#25968;&#25454;&#20013;&#20272;&#35745;Pareto&#20998;&#24067;&#30340;&#23614;&#25351;&#25968;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#24212;&#29992;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#21644;&#27169;&#25311;&#30740;&#31350;&#39564;&#35777;&#20102;&#20854;&#25512;&#29702;&#21512;&#29702;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21487;&#33719;&#21462;&#30340;&#23436;&#20840;&#35266;&#27979;&#21040;&#30340;&#20174;&#22836;&#33267;&#23614;&#30340;&#25439;&#22833;&#20005;&#37325;&#24615;&#26679;&#26412;&#25968;&#25454;&#38598;&#23384;&#22312;&#26102;&#65292;&#23384;&#22312;&#35768;&#22810;&#31283;&#20581;&#20272;&#35745;&#22120;&#20316;&#20026;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#65288;MLE&#65289;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#24403;&#22788;&#29702;&#20998;&#32452;&#25439;&#22833;&#20005;&#37325;&#24615;&#25968;&#25454;&#26102;&#65292;&#31283;&#20581;&#30340;MLE&#26367;&#20195;&#26041;&#26696;&#30340;&#36873;&#25321;&#21464;&#24471;&#38750;&#24120;&#26377;&#38480;&#65292;&#21482;&#26377;&#23569;&#25968;&#26041;&#27861;&#21487;&#29992;&#65292;&#20363;&#22914;&#26368;&#23567;&#20108;&#20056;&#27861;&#12289;&#26368;&#23567;Hellinger&#36317;&#31163;&#21644;&#26368;&#20248;&#26377;&#30028;&#24433;&#21709;&#20989;&#25968;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#25130;&#26029;&#30697;&#27861;&#30340;&#26032;&#22411;&#31283;&#20581;&#20272;&#35745;&#25216;&#26415;&#65292;&#35813;&#26041;&#27861;&#19987;&#38376;&#29992;&#20110;&#20174;&#20998;&#32452;&#25968;&#25454;&#20272;&#35745;Pareto&#20998;&#24067;&#30340;&#23614;&#25351;&#25968;&#12290;&#36890;&#36807;&#24212;&#29992;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#21644;&#36890;&#36807;&#20840;&#38754;&#30340;&#27169;&#25311;&#30740;&#31350;&#39564;&#35777;&#20102;MTuM&#30340;&#25512;&#29702;&#21512;&#29702;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Numerous robust estimators exist as alternatives to the maximum likelihood estimator (MLE) when a completely observed ground-up loss severity sample dataset is available. However, the options for robust alternatives to MLE become significantly limited when dealing with grouped loss severity data, with only a handful of methods like least squares, minimum Hellinger distance, and optimal bounded influence function available. This paper introduces a novel robust estimation technique, the Method of Truncated Moments (MTuM), specifically designed to estimate the tail index of a Pareto distribution from grouped data. Inferential justification of MTuM is established by employing the central limit theorem and validating them through a comprehensive simulation study.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#22686;&#24378;&#30340;&#31616;&#21333;&#38750;&#23545;&#31216;&#22270;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;GraphACL&#65292;&#36890;&#36807;&#32771;&#34385;&#37051;&#23621;&#33410;&#28857;&#30340;&#38750;&#23545;&#31216;&#35270;&#22270;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#22312;&#21516;&#31867;&#21644;&#24322;&#31867;&#22270;&#19978;&#36827;&#34892;&#23545;&#27604;&#23398;&#20064;&#65292;&#23545;&#20110;&#24314;&#27169;&#24322;&#31867;&#22270;&#38750;&#24120;&#37325;&#35201;&#12290;</title><link>http://arxiv.org/abs/2310.18884</link><description>&lt;p&gt;
&#26080;&#38656;&#22686;&#24378;&#30340;&#31616;&#21333;&#38750;&#23545;&#31216;&#22270;&#23545;&#27604;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Simple and Asymmetric Graph Contrastive Learning without Augmentations. (arXiv:2310.18884v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18884
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#22686;&#24378;&#30340;&#31616;&#21333;&#38750;&#23545;&#31216;&#22270;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;GraphACL&#65292;&#36890;&#36807;&#32771;&#34385;&#37051;&#23621;&#33410;&#28857;&#30340;&#38750;&#23545;&#31216;&#35270;&#22270;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#22312;&#21516;&#31867;&#21644;&#24322;&#31867;&#22270;&#19978;&#36827;&#34892;&#23545;&#27604;&#23398;&#20064;&#65292;&#23545;&#20110;&#24314;&#27169;&#24322;&#31867;&#22270;&#38750;&#24120;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#23545;&#27604;&#23398;&#20064;&#65288;GCL&#65289;&#22312;&#22270;&#32467;&#26500;&#25968;&#25454;&#30340;&#34920;&#31034;&#23398;&#20064;&#20013;&#26174;&#31034;&#20986;&#20102;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;GCL&#26041;&#27861;&#20381;&#36182;&#20110;&#39044;&#21046;&#30340;&#22270;&#22686;&#24378;&#21644;&#21516;&#31867;&#20551;&#35774;&#12290;&#22240;&#27492;&#65292;&#23427;&#20204;&#22312;&#36830;&#36890;&#33410;&#28857;&#21487;&#33021;&#20855;&#26377;&#19981;&#21516;&#31867;&#26631;&#31614;&#21644;&#19981;&#30456;&#20284;&#29305;&#24449;&#30340;&#24322;&#31867;&#22270;&#19978;&#26080;&#27861;&#24456;&#22909;&#22320;&#25512;&#24191;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#21516;&#31867;&#21644;&#24322;&#31867;&#22270;&#19978;&#36827;&#34892;&#23545;&#27604;&#23398;&#20064;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#36890;&#36807;&#32771;&#34385;&#37051;&#23621;&#33410;&#28857;&#30340;&#38750;&#23545;&#31216;&#35270;&#22270;&#65292;&#25105;&#20204;&#21487;&#20197;&#23454;&#29616;&#26377;&#24076;&#26395;&#30340;&#24615;&#33021;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#31616;&#21333;&#31639;&#27861;&#65292;&#31216;&#20026;&#22270;&#30340;&#38750;&#23545;&#31216;&#23545;&#27604;&#23398;&#20064;(GraphACL)&#65292;&#26131;&#20110;&#23454;&#29616;&#65292;&#19981;&#20381;&#36182;&#20110;&#22270;&#22686;&#24378;&#21644;&#21516;&#31867;&#20551;&#35774;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#21644;&#23454;&#35777;&#35777;&#25454;&#65292;&#35777;&#26126;GraphACL&#33021;&#22815;&#25429;&#25417;&#21333;&#36339;&#26412;&#22320;&#37051;&#22495;&#20449;&#24687;&#21644;&#21452;&#36339;&#21333;&#19968;&#30456;&#20284;&#24615;&#65292;&#36825;&#20004;&#32773;&#23545;&#20110;&#24314;&#27169;&#24322;&#31867;&#22270;&#38750;&#24120;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Contrastive Learning (GCL) has shown superior performance in representation learning in graph-structured data. Despite their success, most existing GCL methods rely on prefabricated graph augmentation and homophily assumptions. Thus, they fail to generalize well to heterophilic graphs where connected nodes may have different class labels and dissimilar features. In this paper, we study the problem of conducting contrastive learning on homophilic and heterophilic graphs. We find that we can achieve promising performance simply by considering an asymmetric view of the neighboring nodes. The resulting simple algorithm, Asymmetric Contrastive Learning for Graphs (GraphACL), is easy to implement and does not rely on graph augmentations and homophily assumptions. We provide theoretical and empirical evidence that GraphACL can capture one-hop local neighborhood information and two-hop monophily similarity, which are both important for modeling heterophilic graphs. Experimental results s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#29983;&#25104;&#27169;&#22411;&#22312;&#28151;&#21512;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#23545;&#31283;&#23450;&#24615;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#35777;&#26126;&#21021;&#22987;&#29983;&#25104;&#27169;&#22411;&#36275;&#22815;&#25509;&#36817;&#25968;&#25454;&#20998;&#24067;&#24182;&#19988;&#25968;&#25454;&#27604;&#20363;&#36866;&#24403;&#65292;&#36845;&#20195;&#35757;&#32451;&#26159;&#31283;&#23450;&#30340;&#12290;</title><link>http://arxiv.org/abs/2310.00429</link><description>&lt;p&gt;
&#20851;&#20110;&#29983;&#25104;&#27169;&#22411;&#22312;&#20854;&#33258;&#24049;&#30340;&#25968;&#25454;&#19978;&#36845;&#20195;&#35757;&#32451;&#30340;&#31283;&#23450;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Stability of Iterative Retraining of Generative Models on their own Data. (arXiv:2310.00429v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00429
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#29983;&#25104;&#27169;&#22411;&#22312;&#28151;&#21512;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#23545;&#31283;&#23450;&#24615;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#35777;&#26126;&#21021;&#22987;&#29983;&#25104;&#27169;&#22411;&#36275;&#22815;&#25509;&#36817;&#25968;&#25454;&#20998;&#24067;&#24182;&#19988;&#25968;&#25454;&#27604;&#20363;&#36866;&#24403;&#65292;&#36845;&#20195;&#35757;&#32451;&#26159;&#31283;&#23450;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#22312;&#24314;&#27169;&#22797;&#26434;&#25968;&#25454;&#26041;&#38754;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#36827;&#23637;&#65292;&#24448;&#24448;&#23637;&#29616;&#20986;&#36229;&#36807;&#20856;&#22411;&#20154;&#31867;&#33021;&#21147;&#30340;&#26679;&#26412;&#30495;&#23454;&#24615;&#36776;&#21035;&#33021;&#21147;&#12290;&#36825;&#19968;&#25104;&#21151;&#30340;&#20851;&#38190;&#39537;&#21160;&#21147;&#26080;&#30097;&#26159;&#36825;&#20123;&#27169;&#22411;&#28040;&#32791;&#28023;&#37327;&#32593;&#32476;&#35268;&#27169;&#25968;&#25454;&#30340;&#32467;&#26524;&#12290;&#30001;&#20110;&#36825;&#20123;&#27169;&#22411;&#24778;&#20154;&#30340;&#24615;&#33021;&#21644;&#26131;&#24471;&#24615;&#65292;&#32593;&#32476;&#19978;&#23558;&#19981;&#21487;&#36991;&#20813;&#22320;&#20986;&#29616;&#36234;&#26469;&#36234;&#22810;&#30340;&#21512;&#25104;&#20869;&#23481;&#12290;&#36825;&#20010;&#20107;&#23454;&#30452;&#25509;&#24847;&#21619;&#30528;&#29983;&#25104;&#27169;&#22411;&#30340;&#26410;&#26469;&#36845;&#20195;&#24517;&#39035;&#38754;&#23545;&#19968;&#20010;&#29616;&#23454;&#65306;&#23427;&#20204;&#30340;&#35757;&#32451;&#25968;&#25454;&#30001;&#28165;&#27905;&#25968;&#25454;&#21644;&#20808;&#21069;&#27169;&#22411;&#29983;&#25104;&#30340;&#20154;&#24037;&#25968;&#25454;&#32452;&#25104;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#26694;&#26550;&#26469;&#23545;&#28151;&#21512;&#25968;&#25454;&#38598;&#65288;&#21253;&#25324;&#30495;&#23454;&#25968;&#25454;&#21644;&#21512;&#25104;&#25968;&#25454;&#65289;&#19978;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#23545;&#31283;&#23450;&#24615;&#30340;&#24433;&#21709;&#36827;&#34892;&#20005;&#26684;&#30740;&#31350;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#22312;&#21021;&#22987;&#29983;&#25104;&#27169;&#22411;&#36275;&#22815;&#22909;&#22320;&#36817;&#20284;&#25968;&#25454;&#20998;&#24067;&#24182;&#19988;&#30495;&#23454;&#25968;&#25454;&#19982;&#21512;&#25104;&#25968;&#25454;&#30340;&#27604;&#20363;&#36866;&#24403;&#30340;&#24773;&#20917;&#19979;&#65292;&#36845;&#20195;&#35757;&#32451;&#30340;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep generative models have made tremendous progress in modeling complex data, often exhibiting generation quality that surpasses a typical human's ability to discern the authenticity of samples. Undeniably, a key driver of this success is enabled by the massive amounts of web-scale data consumed by these models. Due to these models' striking performance and ease of availability, the web will inevitably be increasingly populated with synthetic content. Such a fact directly implies that future iterations of generative models must contend with the reality that their training is curated from both clean data and artificially generated data from past models. In this paper, we develop a framework to rigorously study the impact of training generative models on mixed datasets (of real and synthetic data) on their stability. We first prove the stability of iterative training under the condition that the initial generative models approximate the data distribution well enough and the proportion o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20934;&#33945;&#29305;&#21345;&#27931;&#65288;QMC&#65289;&#26041;&#27861;&#29992;&#20110;&#19977;&#32500;&#20999;&#29255;Wasserstein&#65288;SW&#65289;&#30340;&#36817;&#20284;&#35745;&#31639;&#65292;&#24182;&#36890;&#36807;&#22810;&#31181;&#26041;&#27861;&#22312;&#19977;&#32500;&#21333;&#20301;&#36229;&#29699;&#38754;&#19978;&#26500;&#36896;&#20102;QMC&#28857;&#38598;&#12290;&#27492;&#22806;&#65292;&#36824;&#20171;&#32461;&#20102;&#23558;QSW&#25193;&#23637;&#20026;&#38543;&#26426;&#20934;&#20999;&#29255;Wasserstein&#65288;RQSW&#65289;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.11713</link><description>&lt;p&gt;
&#19977;&#32500;&#20999;&#29255;Wasserstein&#30340;&#20934;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Quasi-Monte Carlo for 3D Sliced Wasserstein. (arXiv:2309.11713v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11713
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20934;&#33945;&#29305;&#21345;&#27931;&#65288;QMC&#65289;&#26041;&#27861;&#29992;&#20110;&#19977;&#32500;&#20999;&#29255;Wasserstein&#65288;SW&#65289;&#30340;&#36817;&#20284;&#35745;&#31639;&#65292;&#24182;&#36890;&#36807;&#22810;&#31181;&#26041;&#27861;&#22312;&#19977;&#32500;&#21333;&#20301;&#36229;&#29699;&#38754;&#19978;&#26500;&#36896;&#20102;QMC&#28857;&#38598;&#12290;&#27492;&#22806;&#65292;&#36824;&#20171;&#32461;&#20102;&#23558;QSW&#25193;&#23637;&#20026;&#38543;&#26426;&#20934;&#20999;&#29255;Wasserstein&#65288;RQSW&#65289;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Monte Carlo (MC)&#26041;&#27861;&#34987;&#29992;&#20316;&#35745;&#31639;&#20999;&#29255;Wasserstein (SW)&#36317;&#31163;&#30340;&#26631;&#20934;&#26041;&#27861;&#65292;&#22240;&#20026;&#23427;&#22312;&#20998;&#26512;&#24418;&#24335;&#20013;&#20855;&#26377;&#26840;&#25163;&#30340;&#26399;&#26395;&#12290;&#28982;&#32780;&#65292;MC&#26041;&#27861;&#22312;&#26368;&#23567;&#21270;&#32477;&#23545;&#36817;&#20284;&#35823;&#24046;&#26041;&#38754;&#24182;&#19981;&#20248;&#21270;&#12290;&#20026;&#20102;&#25552;&#20379;&#26356;&#22909;&#30340;&#32463;&#39564;SW&#31867;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#20934;&#33945;&#29305;&#21345;&#27931;&#65288;QMC&#65289;&#26041;&#27861;&#30340;&#20934;&#20999;&#29255;Wasserstein&#65288;QSW&#65289;&#36924;&#36817;&#12290;&#20026;&#20102;&#23545;SW&#30340;QMC&#36827;&#34892;&#20840;&#38754;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#19977;&#32500;&#35774;&#32622;&#65292;&#29305;&#21035;&#26159;&#35745;&#31639;&#19977;&#32500;&#27010;&#29575;&#27979;&#24230;&#20043;&#38388;&#30340;SW&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#35777;&#39564;&#35777;&#20102;&#22312;&#19977;&#32500;&#21333;&#20301;&#36229;&#29699;&#38754;&#19978;&#26500;&#36896;QMC&#28857;&#38598;&#30340;&#22810;&#31181;&#26041;&#27861;&#65292;&#21253;&#25324;&#22522;&#20110;&#39640;&#26031;&#30340;&#26144;&#23556;&#65292;&#31561;&#38754;&#31215;&#26144;&#23556;&#65292;&#24191;&#20041;&#34746;&#26059;&#28857;&#21644;&#26368;&#20248;&#21270;&#24046;&#24322;&#33021;&#37327;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#33719;&#24471;&#38543;&#26426;&#20248;&#21270;&#30340;&#26080;&#20559;&#20272;&#35745;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#25152;&#35752;&#35770;&#30340;&#20302;&#32500;&#35774;&#32622;&#20013;&#24341;&#20837;&#38543;&#26426;&#24615;&#65292;&#23558;QSW&#25193;&#23637;&#20026;&#38543;&#26426;&#20934;&#20999;&#29255;Wasserstein&#65288;RQSW&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Monte Carlo (MC) approximation has been used as the standard computation approach for the Sliced Wasserstein (SW) distance, which has an intractable expectation in its analytical form. However, the MC method is not optimal in terms of minimizing the absolute approximation error. To provide a better class of empirical SW, we propose quasi-sliced Wasserstein (QSW) approximations that rely on Quasi-Monte Carlo (QMC) methods. For a comprehensive investigation of QMC for SW, we focus on the 3D setting, specifically computing the SW between probability measures in three dimensions. In greater detail, we empirically verify various ways of constructing QMC points sets on the 3D unit-hypersphere, including Gaussian-based mapping, equal area mapping, generalized spiral points, and optimizing discrepancy energies. Furthermore, to obtain an unbiased estimation for stochastic optimization, we extend QSW into Randomized Quasi-Sliced Wasserstein (RQSW) by introducing randomness to the discussed low-d
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#20960;&#20046;&#32447;&#24615;&#20108;&#27425;&#22411;&#35843;&#33410;&#22120;&#31995;&#32479;&#20013;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#65292;&#21487;&#20197;&#20197;&#32447;&#24615;&#36895;&#29575;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2303.08431</link><description>&lt;p&gt;
&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#25910;&#25947;&#20110;&#20960;&#20046;&#32447;&#24615;&#20108;&#27425;&#22411;&#35843;&#33410;&#22120;&#30340;&#20840;&#23616;&#26368;&#20248;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Policy Gradient Converges to the Globally Optimal Policy for Nearly Linear-Quadratic Regulators. (arXiv:2303.08431v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08431
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#20960;&#20046;&#32447;&#24615;&#20108;&#27425;&#22411;&#35843;&#33410;&#22120;&#31995;&#32479;&#20013;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#65292;&#21487;&#20197;&#20197;&#32447;&#24615;&#36895;&#29575;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20915;&#31574;&#32773;&#21482;&#33719;&#24471;&#20102;&#38750;&#23436;&#25972;&#20449;&#24687;&#30340;&#38750;&#32447;&#24615;&#25511;&#21046;&#31995;&#32479;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#26222;&#36941;&#23384;&#22312;&#12290;&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#25214;&#21040;&#20960;&#20046;&#32447;&#24615;&#20108;&#27425;&#22411;&#35843;&#33410;&#22120;&#31995;&#32479;&#20013;&#26368;&#20248;&#31574;&#30053;&#12290;&#25105;&#20204;&#32771;&#34385;&#19968;&#20010;&#21160;&#24577;&#31995;&#32479;&#65292;&#32467;&#21512;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#32452;&#25104;&#37096;&#20998;&#65292;&#24182;&#30001;&#30456;&#21516;&#32467;&#26500;&#30340;&#31574;&#30053;&#36827;&#34892;&#31649;&#29702;&#12290;&#22312;&#20551;&#35774;&#38750;&#32447;&#24615;&#32452;&#25104;&#37096;&#20998;&#21253;&#21547;&#20855;&#26377;&#23567;&#22411;Lipschitz&#31995;&#25968;&#30340;&#20869;&#26680;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23545;&#25104;&#26412;&#20989;&#25968;&#30340;&#20248;&#21270;&#36827;&#34892;&#20102;&#34920;&#24449;&#12290;&#34429;&#28982;&#25104;&#26412;&#20989;&#25968;&#36890;&#24120;&#26159;&#38750;&#20984;&#30340;&#65292;&#20294;&#25105;&#20204;&#30830;&#31435;&#20102;&#20840;&#23616;&#26368;&#20248;&#35299;&#38468;&#36817;&#23616;&#37096;&#30340;&#24378;&#20984;&#24615;&#21644;&#20809;&#28369;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21021;&#22987;&#21270;&#26426;&#21046;&#65292;&#20197;&#21033;&#29992;&#36825;&#20123;&#23646;&#24615;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#65292;&#21487;&#20197;&#20445;&#35777;&#20197;&#32447;&#24615;&#36895;&#29575;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nonlinear control systems with partial information to the decision maker are prevalent in a variety of applications. As a step toward studying such nonlinear systems, this work explores reinforcement learning methods for finding the optimal policy in the nearly linear-quadratic regulator systems. In particular, we consider a dynamic system that combines linear and nonlinear components, and is governed by a policy with the same structure. Assuming that the nonlinear component comprises kernels with small Lipschitz coefficients, we characterize the optimization landscape of the cost function. Although the cost function is nonconvex in general, we establish the local strong convexity and smoothness in the vicinity of the global optimizer. Additionally, we propose an initialization mechanism to leverage these properties. Building on the developments, we design a policy gradient algorithm that is guaranteed to converge to the globally optimal policy with a linear rate.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;DGAI&#31639;&#27861;&#65292;&#23427;&#21487;&#20197;&#22312;&#22909;&#25163;&#33218;&#35782;&#21035;&#38382;&#39064;&#20013;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#24335;&#20943;&#23569;&#26679;&#26412;&#22797;&#26434;&#24615;&#65292;&#24182;&#19988;&#22312;&#20855;&#26377;&#32473;&#23450;&#38408;&#20540;&#30340;&#24773;&#20917;&#19979;&#36827;&#19968;&#27493;&#25552;&#39640;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2303.07154</link><description>&lt;p&gt;
&#19981;&#21516;&#30340;&#22909;&#25163;&#33218;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Differential Good Arm Identification. (arXiv:2303.07154v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.07154
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;DGAI&#31639;&#27861;&#65292;&#23427;&#21487;&#20197;&#22312;&#22909;&#25163;&#33218;&#35782;&#21035;&#38382;&#39064;&#20013;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#24335;&#20943;&#23569;&#26679;&#26412;&#22797;&#26434;&#24615;&#65292;&#24182;&#19988;&#22312;&#20855;&#26377;&#32473;&#23450;&#38408;&#20540;&#30340;&#24773;&#20917;&#19979;&#36827;&#19968;&#27493;&#25552;&#39640;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#19968;&#31181;&#21464;&#20307;&#30340;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#65292;&#31216;&#20043;&#20026;&#22909;&#25163;&#33218;&#35782;&#21035;&#65288;GAI&#65289;&#12290; GAI&#26159;&#19968;&#20010;&#32431;&#25506;&#32034;&#30340;&#36172;&#21338;&#38382;&#39064;&#65292;&#20854;&#30446;&#26631;&#26159;&#22312;&#23613;&#21487;&#33021;&#23569;&#30340;&#26679;&#26412;&#25968;&#19979;&#36755;&#20986;&#23613;&#21487;&#33021;&#22810;&#30340;&#22909;&#25163;&#33218;&#65292;&#20854;&#20013;&#22909;&#25163;&#33218;&#34987;&#23450;&#20041;&#20026;&#20854;&#26399;&#26395;&#22870;&#21169;&#22823;&#20110;&#32473;&#23450;&#38408;&#20540;&#30340;&#25163;&#33218;&#12290; &#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;DGAI-&#19968;&#31181;&#21487;&#24494;&#30340;&#22909;&#25163;&#33218;&#35782;&#21035;&#31639;&#27861;&#65292;&#20197;&#25968;&#25454;&#39537;&#21160;&#26041;&#24335;&#25913;&#36827;&#20102;&#29616;&#26377;&#25216;&#26415;HDoC&#31639;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290; &#25105;&#20204;&#36824;&#23637;&#31034;&#20102;DGAI&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#21319;&#36890;&#29992;&#22810;&#33218;&#36172;&#21338;&#65288;MAB&#65289;&#38382;&#39064;&#30340;&#24615;&#33021;&#65292;&#32473;&#23450;&#19968;&#20010;&#38408;&#20540;&#20316;&#20026;&#20808;&#39564;&#30693;&#35782;&#24212;&#29992;&#20110;&#25163;&#33218;&#38598;&#12290; &#22823;&#37327;&#23454;&#39564;&#35777;&#23454;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#20013;&#30340;GAI&#21644;MAB&#20219;&#21153;&#20013;&#26174;&#33879;&#20248;&#20110;&#22522;&#32447;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper targets a variant of the stochastic multi-armed bandit problem called good arm identification (GAI). GAI is a pure-exploration bandit problem with the goal to output as many good arms using as few samples as possible, where a good arm is defined as an arm whose expected reward is greater than a given threshold. In this work, we propose DGAI - a differentiable good arm identification algorithm to improve the sample complexity of the state-of-the-art HDoC algorithm in a data-driven fashion. We also showed that the DGAI can further boost the performance of a general multi-arm bandit (MAB) problem given a threshold as a prior knowledge to the arm set. Extensive experiments confirm that our algorithm outperform the baseline algorithms significantly in both synthetic and real world datasets for both GAI and MAB tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;JKO&#26041;&#26696;&#30340;&#21487;&#36870;&#24402;&#19968;&#21270;&#27969;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#25353;&#22359;&#36827;&#34892;&#27531;&#24046;&#22359;&#30340;&#35757;&#32451;&#65292;&#20943;&#23569;&#20102;&#20869;&#23384;&#36127;&#36733;&#21644;&#28145;&#24230;&#27969;&#32593;&#32476;&#35757;&#32451;&#30340;&#38590;&#24230;&#12290;&#24182;&#19988;&#36890;&#36807;&#33258;&#36866;&#24212;&#26102;&#38388;&#37325;&#26032;&#21442;&#25968;&#21270;&#30340;&#27969;&#32593;&#32476;&#65292;&#22312;&#27010;&#29575;&#31354;&#38388;&#20013;&#36880;&#27493;&#32454;&#21270;&#36712;&#36857;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#35757;&#32451;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2212.14424</link><description>&lt;p&gt;
&#22522;&#20110;JKO&#26041;&#26696;&#30340;&#21487;&#36870;&#24402;&#19968;&#21270;&#27969;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Invertible normalizing flow neural networks by JKO scheme. (arXiv:2212.14424v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.14424
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;JKO&#26041;&#26696;&#30340;&#21487;&#36870;&#24402;&#19968;&#21270;&#27969;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#25353;&#22359;&#36827;&#34892;&#27531;&#24046;&#22359;&#30340;&#35757;&#32451;&#65292;&#20943;&#23569;&#20102;&#20869;&#23384;&#36127;&#36733;&#21644;&#28145;&#24230;&#27969;&#32593;&#32476;&#35757;&#32451;&#30340;&#38590;&#24230;&#12290;&#24182;&#19988;&#36890;&#36807;&#33258;&#36866;&#24212;&#26102;&#38388;&#37325;&#26032;&#21442;&#25968;&#21270;&#30340;&#27969;&#32593;&#32476;&#65292;&#22312;&#27010;&#29575;&#31354;&#38388;&#20013;&#36880;&#27493;&#32454;&#21270;&#36712;&#36857;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#35757;&#32451;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24402;&#19968;&#21270;&#27969;&#26159;&#19968;&#31867;&#29992;&#20110;&#39640;&#25928;&#37319;&#26679;&#21644;&#23494;&#24230;&#20272;&#35745;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#12290;&#23454;&#38469;&#20013;&#65292;&#27969;&#36890;&#24120;&#34920;&#31034;&#20026;&#19968;&#31995;&#21015;&#21487;&#36870;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22359;&#38142;; &#20026;&#20102;&#20415;&#20110;&#35757;&#32451;&#65292;&#29616;&#26377;&#30340;&#24037;&#20316;&#23545;&#27969;&#36712;&#36857;&#36827;&#34892;&#20102;&#27491;&#21017;&#21270;&#65292;&#24182;&#35774;&#35745;&#20102;&#29305;&#27530;&#30340;&#32593;&#32476;&#26550;&#26500;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#21463;Jordan-Kinderleherer-Otto (JKO)&#26041;&#26696;&#21551;&#21457;&#30340;&#31070;&#32463;ODE&#27969;&#32593;&#32476;&#65292;&#23427;&#20801;&#35768;&#26377;&#25928;&#22320;&#25353;&#22359;&#36827;&#34892;&#27531;&#24046;&#22359;&#30340;&#35757;&#32451;&#65292;&#26080;&#38656;&#37319;&#26679;SDE&#36712;&#36857;&#25110;&#20998;&#25968;&#21305;&#37197;&#25110;&#21464;&#20998;&#23398;&#20064;&#30340;&#20869;&#24490;&#29615;&#12290;&#30001;&#20110;JKO&#26041;&#26696;&#23637;&#24320;&#20102;&#26799;&#24230;&#27969;&#30340;&#21160;&#24577;&#65292;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#33258;&#28982;&#22320;&#36880;&#20010;&#22534;&#21472;&#27531;&#24046;&#32593;&#32476;&#22359;&#65292;&#38477;&#20302;&#20102;&#20869;&#23384;&#36127;&#36733;&#21644;&#36827;&#34892;&#31471;&#21040;&#31471;&#28145;&#24230;&#27969;&#32593;&#32476;&#35757;&#32451;&#30340;&#38590;&#24230;&#12290;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#33258;&#36866;&#24212;&#26102;&#38388;&#37325;&#26032;&#21442;&#25968;&#21270;&#30340;&#27969;&#32593;&#32476;&#65292;&#36890;&#36807;&#22312;&#27010;&#29575;&#31354;&#38388;&#20013;&#36880;&#27493;&#32454;&#21270;&#36712;&#36857;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#35757;&#32451;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Normalizing flow is a class of deep generative models for efficient sampling and density estimation. In practice, the flow often appears as a chain of invertible neural network blocks; to facilitate training, existing works have regularized flow trajectories and designed special network architectures. The current paper develops a neural ODE flow network inspired by the Jordan-Kinderleherer-Otto (JKO) scheme, which allows efficient block-wise training of the residual blocks without sampling SDE trajectories or inner loops of score matching or variational learning. As the JKO scheme unfolds the dynamic of gradient flow, the proposed model naturally stacks residual network blocks one by one, reducing the memory load and difficulty in performing end-to-end deep flow network training. We also develop adaptive time reparameterization of the flow network with a progressive refinement of the trajectory in probability space, which improves the model training efficiency and accuracy in practice.
&lt;/p&gt;</description></item></channel></rss>