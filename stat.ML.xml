<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#32622;&#25442;&#19981;&#21464;&#31070;&#32463;&#32593;&#32476;&#23545;&#38598;&#21512;&#22825;&#27668;&#39044;&#27979;&#36827;&#34892;&#21518;&#22788;&#29702;&#65292;&#19981;&#21516;&#20110;&#20043;&#21069;&#30340;&#26041;&#27861;&#65292;&#35813;&#32593;&#32476;&#23558;&#39044;&#27979;&#38598;&#21512;&#35270;&#20026;&#19968;&#32452;&#26080;&#24207;&#30340;&#25104;&#21592;&#39044;&#27979;&#65292;&#24182;&#23398;&#20064;&#23545;&#25104;&#21592;&#39034;&#24207;&#30340;&#25490;&#21015;&#32622;&#25442;&#20855;&#26377;&#19981;&#21464;&#24615;&#30340;&#38142;&#25509;&#20989;&#25968;&#12290;&#22312;&#22320;&#34920;&#28201;&#24230;&#21644;&#39118;&#36895;&#39044;&#27979;&#30340;&#26696;&#20363;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26368;&#20808;&#36827;&#30340;&#39044;&#27979;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2309.04452</link><description>&lt;p&gt;
&#20351;&#29992;&#32622;&#25442;&#19981;&#21464;&#31070;&#32463;&#32593;&#32476;&#23545;&#38598;&#21512;&#22825;&#27668;&#39044;&#27979;&#36827;&#34892;&#21518;&#22788;&#29702;
&lt;/p&gt;
&lt;p&gt;
Postprocessing of Ensemble Weather Forecasts Using Permutation-invariant Neural Networks. (arXiv:2309.04452v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04452
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#32622;&#25442;&#19981;&#21464;&#31070;&#32463;&#32593;&#32476;&#23545;&#38598;&#21512;&#22825;&#27668;&#39044;&#27979;&#36827;&#34892;&#21518;&#22788;&#29702;&#65292;&#19981;&#21516;&#20110;&#20043;&#21069;&#30340;&#26041;&#27861;&#65292;&#35813;&#32593;&#32476;&#23558;&#39044;&#27979;&#38598;&#21512;&#35270;&#20026;&#19968;&#32452;&#26080;&#24207;&#30340;&#25104;&#21592;&#39044;&#27979;&#65292;&#24182;&#23398;&#20064;&#23545;&#25104;&#21592;&#39034;&#24207;&#30340;&#25490;&#21015;&#32622;&#25442;&#20855;&#26377;&#19981;&#21464;&#24615;&#30340;&#38142;&#25509;&#20989;&#25968;&#12290;&#22312;&#22320;&#34920;&#28201;&#24230;&#21644;&#39118;&#36895;&#39044;&#27979;&#30340;&#26696;&#20363;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26368;&#20808;&#36827;&#30340;&#39044;&#27979;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32479;&#35745;&#21518;&#22788;&#29702;&#29992;&#20110;&#23558;&#21407;&#22987;&#25968;&#20540;&#22825;&#27668;&#39044;&#25253;&#30340;&#38598;&#21512;&#36716;&#21270;&#20026;&#21487;&#38752;&#30340;&#27010;&#29575;&#39044;&#27979;&#20998;&#24067;&#12290;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#32771;&#23519;&#20102;&#20351;&#29992;&#32622;&#25442;&#19981;&#21464;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#36825;&#19968;&#20219;&#21153;&#30340;&#26041;&#27861;&#12290;&#19982;&#20197;&#24448;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#36890;&#24120;&#22522;&#20110;&#38598;&#21512;&#27010;&#35201;&#32479;&#35745;&#20449;&#24687;&#24182;&#24573;&#30053;&#38598;&#21512;&#20998;&#24067;&#30340;&#32454;&#33410;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#32593;&#32476;&#23558;&#39044;&#27979;&#38598;&#21512;&#35270;&#20026;&#19968;&#32452;&#26080;&#24207;&#30340;&#25104;&#21592;&#39044;&#27979;&#65292;&#24182;&#23398;&#20064;&#23545;&#25104;&#21592;&#39034;&#24207;&#30340;&#25490;&#21015;&#32622;&#25442;&#20855;&#26377;&#19981;&#21464;&#24615;&#30340;&#38142;&#25509;&#20989;&#25968;&#12290;&#25105;&#20204;&#36890;&#36807;&#26657;&#20934;&#24230;&#21644;&#38160;&#24230;&#35780;&#20272;&#25152;&#33719;&#24471;&#30340;&#39044;&#27979;&#20998;&#24067;&#30340;&#36136;&#37327;&#65292;&#24182;&#23558;&#27169;&#22411;&#19982;&#32463;&#20856;&#30340;&#22522;&#20934;&#26041;&#27861;&#21644;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#36827;&#34892;&#27604;&#36739;&#12290;&#36890;&#36807;&#22788;&#29702;&#22320;&#34920;&#28201;&#24230;&#21644;&#39118;&#36895;&#39044;&#27979;&#30340;&#26696;&#20363;&#30740;&#31350;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26368;&#20808;&#36827;&#30340;&#39044;&#27979;&#36136;&#37327;&#12290;&#20026;&#20102;&#21152;&#28145;&#23545;&#23398;&#20064;&#25512;&#29702;&#36807;&#31243;&#30340;&#29702;&#35299;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#22522;&#20110;&#32622;&#25442;&#30340;&#37325;&#35201;&#24615;&#35780;&#20272;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Statistical postprocessing is used to translate ensembles of raw numerical weather forecasts into reliable probabilistic forecast distributions. In this study, we examine the use of permutation-invariant neural networks for this task. In contrast to previous approaches, which often operate on ensemble summary statistics and dismiss details of the ensemble distribution, we propose networks which treat forecast ensembles as a set of unordered member forecasts and learn link functions that are by design invariant to permutations of the member ordering. We evaluate the quality of the obtained forecast distributions in terms of calibration and sharpness, and compare the models against classical and neural network-based benchmark methods. In case studies addressing the postprocessing of surface temperature and wind gust forecasts, we demonstrate state-of-the-art prediction quality. To deepen the understanding of the learned inference process, we further propose a permutation-based importance
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#33324;&#21270;&#30028;&#38480;&#30340;&#20004;&#20010;&#35270;&#35282;&#65306;&#20449;&#24687;&#35770;&#21644;PAC-Bayesian&#65292;&#24182;&#25506;&#35752;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#32852;&#31995;&#21644;&#20849;&#21516;&#28857;&#12290;&#36825;&#23545;&#20110;&#29702;&#35770;&#26426;&#22120;&#23398;&#20064;&#30340;&#36827;&#19968;&#27493;&#21457;&#23637;&#21644;&#26032;&#31639;&#27861;&#30340;&#35774;&#35745;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2309.04381</link><description>&lt;p&gt;
&#19968;&#33324;&#21270;&#30028;&#38480;&#65306;&#20449;&#24687;&#35770;&#21644;PAC-Bayesian&#30340;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Generalization Bounds: Perspectives from Information Theory and PAC-Bayes. (arXiv:2309.04381v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04381
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#33324;&#21270;&#30028;&#38480;&#30340;&#20004;&#20010;&#35270;&#35282;&#65306;&#20449;&#24687;&#35770;&#21644;PAC-Bayesian&#65292;&#24182;&#25506;&#35752;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#32852;&#31995;&#21644;&#20849;&#21516;&#28857;&#12290;&#36825;&#23545;&#20110;&#29702;&#35770;&#26426;&#22120;&#23398;&#20064;&#30340;&#36827;&#19968;&#27493;&#21457;&#23637;&#21644;&#26032;&#31639;&#27861;&#30340;&#35774;&#35745;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29702;&#35770;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#26159;&#19968;&#33324;&#21270;&#12290;&#22312;&#36807;&#21435;&#30340;&#20960;&#21313;&#24180;&#37324;&#65292;PAC-Bayesian&#26041;&#27861;&#24050;&#32463;&#34987;&#30830;&#23450;&#20026;&#19968;&#20010;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#29992;&#26469;&#35299;&#20915;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#19968;&#33324;&#21270;&#33021;&#21147;&#65292;&#24182;&#35774;&#35745;&#26032;&#30340;&#31639;&#27861;&#12290;&#26368;&#36817;&#65292;&#30001;&#20110;&#20854;&#23545;&#22810;&#31181;&#23398;&#20064;&#31639;&#27861;&#65288;&#21253;&#25324;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65289;&#30340;&#28508;&#22312;&#36866;&#29992;&#24615;&#65292;&#23427;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#36824;&#21457;&#23637;&#20102;&#19968;&#31181;&#20449;&#24687;&#35770;&#30340;&#35270;&#35282;&#65292;&#20854;&#20013;&#24314;&#31435;&#20102;&#19968;&#33324;&#21270;&#19982;&#21508;&#31181;&#20449;&#24687;&#24230;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#36825;&#20010;&#26694;&#26550;&#19982;PAC-Bayesian&#26041;&#27861;&#23494;&#20999;&#30456;&#20851;&#65292;&#24182;&#19988;&#22312;&#20004;&#20010;&#26041;&#38754;&#37117;&#26377;&#29420;&#31435;&#21457;&#29616;&#30340;&#24456;&#22810;&#32467;&#26524;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24378;&#35843;&#36825;&#31181;&#24378;&#36830;&#25509;&#65292;&#24182;&#25552;&#20986;&#19968;&#31181;&#32479;&#19968;&#30340;&#19968;&#33324;&#21270;&#22788;&#29702;&#26041;&#27861;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#20004;&#20010;&#35270;&#35282;&#20849;&#21516;&#25317;&#26377;&#30340;&#25216;&#26415;&#21644;&#32467;&#26524;&#65292;&#24182;&#35752;&#35770;&#20102;&#19981;&#21516;&#30340;&#26041;&#27861;&#21644;&#35299;&#37322;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#36830;&#25509;&#22914;&#20309;&#20135;&#29983;&#26032;&#30340;&#27934;&#35265;&#21644;&#29702;&#35770;&#30340;&#21457;&#23637;&#65292;&#24182;&#23637;&#31034;&#20102;&#36825;&#20004;&#20010;&#39046;&#22495;&#30340;&#20132;&#21449;&#24212;&#29992;&#21644;&#28508;&#22312;&#30340;&#36827;&#19968;&#27493;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
A fundamental question in theoretical machine learning is generalization. Over the past decades, the PAC-Bayesian approach has been established as a flexible framework to address the generalization capabilities of machine learning algorithms, and design new ones. Recently, it has garnered increased interest due to its potential applicability for a variety of learning algorithms, including deep neural networks. In parallel, an information-theoretic view of generalization has developed, wherein the relation between generalization and various information measures has been established. This framework is intimately connected to the PAC-Bayesian approach, and a number of results have been independently discovered in both strands. In this monograph, we highlight this strong connection and present a unified treatment of generalization. We present techniques and results that the two perspectives have in common, and discuss the approaches and interpretations that differ. In particular, we demons
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#31232;&#30095;MoEs&#26469;&#32553;&#23567;&#35270;&#35273;&#21464;&#25442;&#22120;&#65288;ViTs&#65289;&#30340;&#35268;&#27169;&#65292;&#20197;&#25552;&#39640;&#22312;&#36164;&#28304;&#21463;&#38480;&#30340;&#35270;&#35273;&#24212;&#29992;&#20013;&#30340;&#24615;&#33021;&#21644;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2309.04354</link><description>&lt;p&gt;
&#31227;&#21160;V-MoEs&#65306;&#36890;&#36807;&#31232;&#30095;MoEs&#32553;&#23567;&#35270;&#35273;&#21464;&#25442;&#22120;&#30340;&#35268;&#27169;
&lt;/p&gt;
&lt;p&gt;
Mobile V-MoEs: Scaling Down Vision Transformers via Sparse Mixture-of-Experts. (arXiv:2309.04354v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04354
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#31232;&#30095;MoEs&#26469;&#32553;&#23567;&#35270;&#35273;&#21464;&#25442;&#22120;&#65288;ViTs&#65289;&#30340;&#35268;&#27169;&#65292;&#20197;&#25552;&#39640;&#22312;&#36164;&#28304;&#21463;&#38480;&#30340;&#35270;&#35273;&#24212;&#29992;&#20013;&#30340;&#24615;&#33021;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#31232;&#30095;&#30340;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#65288;MoEs&#65289;&#22240;&#20854;&#33021;&#22815;&#36890;&#36807;&#20165;&#28608;&#27963;&#32473;&#23450;&#36755;&#20837;&#20196;&#29260;&#30340;&#27169;&#22411;&#21442;&#25968;&#30340;&#19968;&#23567;&#37096;&#20998;&#32780;&#23558;&#27169;&#22411;&#35268;&#27169;&#19982;&#25512;&#29702;&#25928;&#29575;&#20998;&#31163;&#32780;&#21463;&#21040;&#20851;&#27880;&#12290;&#22240;&#27492;&#65292;&#31232;&#30095;&#30340;MoEs&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#35745;&#31639;&#26426;&#35270;&#35273;&#31561;&#39046;&#22495;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;&#31232;&#30095;MoEs&#26469;&#32553;&#23567;&#35270;&#35273;&#21464;&#25442;&#22120;&#65288;ViTs&#65289;&#30340;&#35268;&#27169;&#65292;&#20197;&#20351;&#20854;&#22312;&#36164;&#28304;&#21463;&#38480;&#30340;&#35270;&#35273;&#24212;&#29992;&#20013;&#26356;&#20855;&#21560;&#24341;&#21147;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21270;&#21644;&#36866;&#29992;&#20110;&#31227;&#21160;&#35774;&#22791;&#30340;MoE&#35774;&#35745;&#65292;&#20854;&#20013;&#25972;&#20010;&#22270;&#20687;&#32780;&#19981;&#26159;&#21333;&#20010;&#34917;&#19969;&#34987;&#36335;&#30001;&#21040;&#19987;&#23478;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#31283;&#23450;&#30340;MoE&#35757;&#32451;&#36807;&#31243;&#65292;&#20351;&#29992;&#36229;&#31867;&#20449;&#24687;&#26469;&#24341;&#23548;&#36335;&#30001;&#22120;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#31232;&#30095;&#31227;&#21160;&#35270;&#35273;MoEs&#65288;V-MoEs&#65289;&#21487;&#20197;&#22312;&#24615;&#33021;&#21644;&#25928;&#29575;&#20043;&#38388;&#36798;&#21040;&#26356;&#22909;&#30340;&#25240;&#34935;&#12290;&#20363;&#22914;&#65292;&#23545;&#20110;...
&lt;/p&gt;
&lt;p&gt;
Sparse Mixture-of-Experts models (MoEs) have recently gained popularity due to their ability to decouple model size from inference efficiency by only activating a small subset of the model parameters for any given input token. As such, sparse MoEs have enabled unprecedented scalability, resulting in tremendous successes across domains such as natural language processing and computer vision. In this work, we instead explore the use of sparse MoEs to scale-down Vision Transformers (ViTs) to make them more attractive for resource-constrained vision applications. To this end, we propose a simplified and mobile-friendly MoE design where entire images rather than individual patches are routed to the experts. We also propose a stable MoE training procedure that uses super-class information to guide the router. We empirically show that our sparse Mobile Vision MoEs (V-MoEs) can achieve a better trade-off between performance and efficiency than the corresponding dense ViTs. For example, for the
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#20351;&#29992;&#30697;&#31070;&#32463;&#32593;&#32476;&#30340;&#28436;&#21592;-&#35780;&#35770;&#21592;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#24179;&#22343;&#22330;&#25511;&#21046;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#22522;&#20110;&#26799;&#24230;&#30340;&#20215;&#20540;&#20989;&#25968;&#34920;&#31034;&#65292;&#24182;&#36890;&#36807;&#30452;&#25509;&#37319;&#26679;&#20998;&#24067;&#30340;&#36712;&#36857;&#26469;&#23454;&#29616;&#23398;&#20064;&#12290;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22810;&#32500;&#21644;&#38750;&#32447;&#24615;&#20108;&#27425;&#25511;&#21046;&#38382;&#39064;&#31561;&#19981;&#21516;&#24773;&#22659;&#19979;&#20855;&#26377;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.04317</link><description>&lt;p&gt;
&#20351;&#29992;&#30697;&#31070;&#32463;&#32593;&#32476;&#30340;&#24179;&#22343;&#22330;&#25511;&#21046;&#20013;&#30340;&#28436;&#21592;-&#35780;&#35770;&#21592;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Actor critic learning algorithms for mean-field control with moment neural networks. (arXiv:2309.04317v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04317
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#20351;&#29992;&#30697;&#31070;&#32463;&#32593;&#32476;&#30340;&#28436;&#21592;-&#35780;&#35770;&#21592;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#24179;&#22343;&#22330;&#25511;&#21046;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#22522;&#20110;&#26799;&#24230;&#30340;&#20215;&#20540;&#20989;&#25968;&#34920;&#31034;&#65292;&#24182;&#36890;&#36807;&#30452;&#25509;&#37319;&#26679;&#20998;&#24067;&#30340;&#36712;&#36857;&#26469;&#23454;&#29616;&#23398;&#20064;&#12290;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22810;&#32500;&#21644;&#38750;&#32447;&#24615;&#20108;&#27425;&#25511;&#21046;&#38382;&#39064;&#31561;&#19981;&#21516;&#24773;&#22659;&#19979;&#20855;&#26377;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#36830;&#32493;&#26102;&#38388;&#24378;&#21270;&#23398;&#20064;&#29615;&#22659;&#20013;&#24320;&#21457;&#20102;&#19968;&#31181;&#35299;&#20915;&#24179;&#22343;&#22330;&#25511;&#21046;&#38382;&#39064;&#30340;&#26032;&#30340;&#31574;&#30053;&#26799;&#24230;&#21644;&#28436;&#21592;-&#35780;&#35770;&#21592;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#22522;&#20110;&#26799;&#24230;&#30340;&#20215;&#20540;&#20989;&#25968;&#34920;&#31034;&#65292;&#37319;&#29992;&#21442;&#25968;&#21270;&#30340;&#38543;&#26426;&#31574;&#30053;&#12290;&#28436;&#21592;&#65288;&#31574;&#30053;&#65289;&#21644;&#35780;&#35770;&#21592;&#65288;&#20215;&#20540;&#20989;&#25968;&#65289;&#30340;&#23398;&#20064;&#26159;&#36890;&#36807;&#22312;&#27010;&#29575;&#27979;&#24230;&#30340;Wasserstein&#31354;&#38388;&#19978;&#30340;&#19968;&#31867;&#30697;&#31070;&#32463;&#32593;&#32476;&#20989;&#25968;&#26469;&#23454;&#29616;&#30340;&#65292;&#20854;&#20851;&#38190;&#29305;&#24449;&#26159;&#30452;&#25509;&#37319;&#26679;&#20998;&#24067;&#30340;&#36712;&#36857;&#12290;&#36825;&#39033;&#30740;&#31350;&#20013;&#35299;&#20915;&#30340;&#19968;&#20010;&#26680;&#24515;&#25361;&#25112;&#28041;&#21450;&#21040;&#23545;&#20110;&#24179;&#22343;&#22330;&#26694;&#26550;&#29305;&#26377;&#30340;&#36816;&#31639;&#31526;&#30340;&#35745;&#31639;&#22788;&#29702;&#12290;&#20026;&#20102;&#35828;&#26126;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31995;&#21015;&#20840;&#38754;&#30340;&#25968;&#20540;&#32467;&#26524;&#12290;&#36825;&#20123;&#32467;&#26524;&#28085;&#30422;&#20102;&#22810;&#32500;&#35774;&#32622;&#21644;&#20855;&#26377;&#21463;&#25511;&#27874;&#21160;&#24615;&#30340;&#38750;&#32447;&#24615;&#20108;&#27425;&#24179;&#22343;&#22330;&#25511;&#21046;&#38382;&#39064;&#31561;&#19981;&#21516;&#30340;&#20363;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a new policy gradient and actor-critic algorithm for solving mean-field control problems within a continuous time reinforcement learning setting. Our approach leverages a gradient-based representation of the value function, employing parametrized randomized policies. The learning for both the actor (policy) and critic (value function) is facilitated by a class of moment neural network functions on the Wasserstein space of probability measures, and the key feature is to sample directly trajectories of distributions. A central challenge addressed in this study pertains to the computational treatment of an operator specific to the mean-field framework. To illustrate the effectiveness of our methods, we provide a comprehensive set of numerical results. These encompass diverse examples, including multi-dimensional settings and nonlinear quadratic mean-field control problems with controlled volatility.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#22823;&#32500;&#24230;&#25968;&#25454;&#30340;&#26680;&#22238;&#24402;&#30340;&#26368;&#20248;&#27604;&#29575;&#65292;&#36890;&#36807;&#20351;&#29992;Mendelson&#22797;&#26434;&#24615;&#21644;&#24230;&#37327;&#29109;&#26469;&#21051;&#30011;&#20854;&#19978;&#30028;&#21644;&#26368;&#23567;&#21270;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#21457;&#29616;&#26368;&#20248;&#27604;&#29575;&#38543;&#30528;&#32500;&#24230;&#19982;&#26679;&#26412;&#22823;&#23567;&#20851;&#31995;&#30340;&#21464;&#21270;&#21576;&#29616;&#20986;&#22810;&#27425;&#19979;&#38477;&#30340;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2309.04268</link><description>&lt;p&gt;
&#22823;&#32500;&#24230;&#24773;&#20917;&#19979;&#26680;&#22238;&#24402;&#30340;&#26368;&#20248;&#27604;&#29575;
&lt;/p&gt;
&lt;p&gt;
Optimal Rate of Kernel Regression in Large Dimensions. (arXiv:2309.04268v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04268
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#22823;&#32500;&#24230;&#25968;&#25454;&#30340;&#26680;&#22238;&#24402;&#30340;&#26368;&#20248;&#27604;&#29575;&#65292;&#36890;&#36807;&#20351;&#29992;Mendelson&#22797;&#26434;&#24615;&#21644;&#24230;&#37327;&#29109;&#26469;&#21051;&#30011;&#20854;&#19978;&#30028;&#21644;&#26368;&#23567;&#21270;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#21457;&#29616;&#26368;&#20248;&#27604;&#29575;&#38543;&#30528;&#32500;&#24230;&#19982;&#26679;&#26412;&#22823;&#23567;&#20851;&#31995;&#30340;&#21464;&#21270;&#21576;&#29616;&#20986;&#22810;&#27425;&#19979;&#38477;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;&#22823;&#32500;&#24230;&#25968;&#25454;&#65288;&#26679;&#26412;&#22823;&#23567;$n$&#19982;&#26679;&#26412;&#32500;&#24230;$d$&#30340;&#20851;&#31995;&#20026;&#22810;&#39033;&#24335;&#65292;&#21363;$n\asymp d^{\gamma}$&#65292;&#20854;&#20013;$\gamma&gt;0$&#65289;&#30340;&#26680;&#22238;&#24402;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#25105;&#20204;&#39318;&#20808;&#36890;&#36807;Mendelson&#22797;&#26434;&#24615;$\varepsilon_{n}^{2}$&#21644;&#24230;&#37327;&#29109;$\bar{\varepsilon}_{n}^{2}$&#26469;&#24314;&#31435;&#19968;&#20010;&#36890;&#29992;&#24037;&#20855;&#65292;&#29992;&#20110;&#21051;&#30011;&#22823;&#32500;&#24230;&#25968;&#25454;&#30340;&#26680;&#22238;&#24402;&#30340;&#19978;&#30028;&#21644;&#26368;&#23567;&#21270;&#19979;&#30028;&#12290;&#24403;&#30446;&#26631;&#20989;&#25968;&#23646;&#20110;&#19982;$\mathbb{S}^{d}$&#19978;&#23450;&#20041;&#30340;&#65288;&#19968;&#33324;&#65289;&#20869;&#31215;&#27169;&#22411;&#30456;&#20851;&#32852;&#30340;RKHS&#26102;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#20010;&#26032;&#24037;&#20855;&#26469;&#23637;&#31034;&#26680;&#22238;&#24402;&#30340;&#36807;&#37327;&#39118;&#38505;&#30340;&#26368;&#23567;&#21270;&#29575;&#26159;$n^{-1/2}$&#65292;&#24403;$n\asymp d^{\gamma}$&#65292;&#20854;&#20013;$\gamma=2, 4, 6, 8, \cdots$&#12290;&#28982;&#21518;&#25105;&#20204;&#36827;&#19968;&#27493;&#30830;&#23450;&#20102;&#23545;&#20110;&#25152;&#26377;$\gamma&gt;0$&#65292;&#26680;&#22238;&#24402;&#36807;&#37327;&#39118;&#38505;&#30340;&#26368;&#20248;&#27604;&#29575;&#65292;&#24182;&#21457;&#29616;&#38543;&#30528;$\gamma$&#30340;&#21464;&#21270;&#65292;&#26368;&#20248;&#27604;&#29575;&#30340;&#26354;&#32447;&#23637;&#29616;&#20986;&#20960;&#20010;&#26032;&#29616;&#35937;&#65292;&#21253;&#25324;&#22810;&#27425;&#19979;&#38477;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
We perform a study on kernel regression for large-dimensional data (where the sample size $n$ is polynomially depending on the dimension $d$ of the samples, i.e., $n\asymp d^{\gamma}$ for some $\gamma &gt;0$ ). We first build a general tool to characterize the upper bound and the minimax lower bound of kernel regression for large dimensional data through the Mendelson complexity $\varepsilon_{n}^{2}$ and the metric entropy $\bar{\varepsilon}_{n}^{2}$ respectively. When the target function falls into the RKHS associated with a (general) inner product model defined on $\mathbb{S}^{d}$, we utilize the new tool to show that the minimax rate of the excess risk of kernel regression is $n^{-1/2}$ when $n\asymp d^{\gamma}$ for $\gamma =2, 4, 6, 8, \cdots$. We then further determine the optimal rate of the excess risk of kernel regression for all the $\gamma&gt;0$ and find that the curve of optimal rate varying along $\gamma$ exhibits several new phenomena including the {\it multiple descent behavior
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#33258;&#36866;&#24212;&#20998;&#24067;&#24335;&#26680;&#23725;&#22238;&#24402;&#65288;AdaDKRR&#65289;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#32771;&#34385;&#33258;&#27835;&#24615;&#12289;&#38544;&#31169;&#24615;&#21644;&#21512;&#20316;&#24615;&#35299;&#20915;&#20102;&#25968;&#25454;&#23396;&#31435;&#30340;&#38382;&#39064;&#65292;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#19982;&#25972;&#20307;&#25968;&#25454;&#36816;&#34892;&#26368;&#20248;&#23398;&#20064;&#31639;&#27861;&#31867;&#20284;&#12290;</title><link>http://arxiv.org/abs/2309.04236</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#20998;&#24067;&#24335;&#26680;&#23725;&#22238;&#24402;&#65306;&#19968;&#31181;&#21487;&#34892;&#30340;&#35299;&#20915;&#25968;&#25454;&#23396;&#31435;&#30340;&#20998;&#24067;&#24335;&#23398;&#20064;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Adaptive Distributed Kernel Ridge Regression: A Feasible Distributed Learning Scheme for Data Silos. (arXiv:2309.04236v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04236
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#33258;&#36866;&#24212;&#20998;&#24067;&#24335;&#26680;&#23725;&#22238;&#24402;&#65288;AdaDKRR&#65289;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#32771;&#34385;&#33258;&#27835;&#24615;&#12289;&#38544;&#31169;&#24615;&#21644;&#21512;&#20316;&#24615;&#35299;&#20915;&#20102;&#25968;&#25454;&#23396;&#31435;&#30340;&#38382;&#39064;&#65292;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#19982;&#25972;&#20307;&#25968;&#25454;&#36816;&#34892;&#26368;&#20248;&#23398;&#20064;&#31639;&#27861;&#31867;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#23396;&#31435;&#20027;&#35201;&#30001;&#38544;&#31169;&#21644;&#20114;&#25805;&#20316;&#24615;&#24341;&#36215;&#65292;&#26174;&#33879;&#38480;&#21046;&#20102;&#19981;&#21516;&#32452;&#32455;&#22312;&#30456;&#21516;&#30446;&#30340;&#19979;&#20855;&#26377;&#30456;&#20284;&#25968;&#25454;&#30340;&#21512;&#20316;&#12290;&#22522;&#20110;&#20998;&#32780;&#27835;&#20043;&#30340;&#20998;&#24067;&#24335;&#23398;&#20064;&#20026;&#35299;&#20915;&#25968;&#25454;&#23396;&#31435;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#65292;&#20294;&#20854;&#38754;&#20020;&#30528;&#33258;&#27835;&#24615;&#12289;&#38544;&#31169;&#20445;&#35777;&#21644;&#21512;&#20316;&#30340;&#24517;&#35201;&#24615;&#31561;&#35832;&#22810;&#25361;&#25112;&#12290;&#26412;&#25991;&#20391;&#37325;&#20110;&#24320;&#21457;&#19968;&#31181;&#33258;&#36866;&#24212;&#20998;&#24067;&#24335;&#26680;&#23725;&#22238;&#24402;&#65288;AdaDKRR&#65289;&#26041;&#27861;&#65292;&#32771;&#34385;&#21442;&#25968;&#36873;&#25321;&#30340;&#33258;&#27835;&#24615;&#12289;&#20256;&#36882;&#38750;&#25935;&#24863;&#20449;&#24687;&#30340;&#38544;&#31169;&#24615;&#21644;&#24615;&#33021;&#25913;&#36827;&#30340;&#21512;&#20316;&#24615;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;AdaDKRR&#30340;&#22362;&#23454;&#29702;&#35770;&#39564;&#35777;&#21644;&#20840;&#38754;&#23454;&#39564;&#26469;&#35777;&#26126;&#20854;&#21487;&#34892;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#19968;&#20123;&#28201;&#21644;&#26465;&#20214;&#19979;&#65292;AdaDKRR&#22312;&#25972;&#20010;&#25968;&#25454;&#19978;&#36816;&#34892;&#26368;&#20248;&#23398;&#20064;&#31639;&#27861;&#30340;&#24615;&#33021;&#31867;&#20284;&#65292;&#39564;&#35777;&#20102;&#21512;&#20316;&#30340;&#24517;&#35201;&#24615;&#65292;&#24182;&#34920;&#26126;&#27809;&#26377;&#20854;&#20182;&#26041;&#27861;&#33021;&#22815;&#36798;&#21040;&#31867;&#20284;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data silos, mainly caused by privacy and interoperability, significantly constrain collaborations among different organizations with similar data for the same purpose. Distributed learning based on divide-and-conquer provides a promising way to settle the data silos, but it suffers from several challenges, including autonomy, privacy guarantees, and the necessity of collaborations. This paper focuses on developing an adaptive distributed kernel ridge regression (AdaDKRR) by taking autonomy in parameter selection, privacy in communicating non-sensitive information, and the necessity of collaborations in performance improvement into account. We provide both solid theoretical verification and comprehensive experiments for AdaDKRR to demonstrate its feasibility and effectiveness. Theoretically, we prove that under some mild conditions, AdaDKRR performs similarly to running the optimal learning algorithms on the whole data, verifying the necessity of collaborations and showing that no other
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35752;&#35770;&#20102;&#22312;&#23384;&#22312;&#28508;&#22312;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#31163;&#32447;&#25512;&#33616;&#31995;&#32479;&#35780;&#20272;&#30340;&#38382;&#39064;&#65292;&#24182;&#29305;&#21035;&#20851;&#27880;&#25512;&#33616;&#31995;&#32479;&#29992;&#20363;&#12290;&#36890;&#36807;&#23545;&#22522;&#20110;&#31574;&#30053;&#30340;&#20272;&#35745;&#22120;&#36827;&#34892;&#30740;&#31350;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#30001;&#28151;&#28102;&#22240;&#32032;&#24341;&#36215;&#30340;&#32479;&#35745;&#20559;&#24046;&#12290;</title><link>http://arxiv.org/abs/2309.04222</link><description>&lt;p&gt;
&#26410;&#35266;&#23519;&#21040;&#28508;&#22312;&#28151;&#28102;&#22240;&#32032;&#19979;&#30340;&#31163;&#32447;&#25512;&#33616;&#31995;&#32479;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Offline Recommender System Evaluation under Unobserved Confounding. (arXiv:2309.04222v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04222
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35752;&#35770;&#20102;&#22312;&#23384;&#22312;&#28508;&#22312;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#31163;&#32447;&#25512;&#33616;&#31995;&#32479;&#35780;&#20272;&#30340;&#38382;&#39064;&#65292;&#24182;&#29305;&#21035;&#20851;&#27880;&#25512;&#33616;&#31995;&#32479;&#29992;&#20363;&#12290;&#36890;&#36807;&#23545;&#22522;&#20110;&#31574;&#30053;&#30340;&#20272;&#35745;&#22120;&#36827;&#34892;&#30740;&#31350;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#30001;&#28151;&#28102;&#22240;&#32032;&#24341;&#36215;&#30340;&#32479;&#35745;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#25919;&#31574;&#20272;&#35745;&#26041;&#27861;(OPE)&#20801;&#35768;&#25105;&#20204;&#20174;&#35760;&#24405;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#21644;&#35780;&#20272;&#20915;&#31574;&#31574;&#30053;&#65292;&#20351;&#23427;&#20204;&#25104;&#20026;&#31163;&#32447;&#35780;&#20272;&#25512;&#33616;&#31995;&#32479;&#30340;&#21560;&#24341;&#20154;&#36873;&#25321;&#12290;&#26368;&#36817;&#30340;&#19968;&#20123;&#20316;&#21697;&#25253;&#36947;&#20102;&#25104;&#21151;&#37319;&#29992;OPE&#26041;&#27861;&#30340;&#24773;&#20917;&#12290;&#36825;&#39033;&#24037;&#20316;&#30340;&#19968;&#20010;&#37325;&#35201;&#20551;&#35774;&#26159;&#19981;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#65306;&#22312;&#25968;&#25454;&#25910;&#38598;&#26102;&#24433;&#21709;&#34892;&#21160;&#21644;&#22870;&#21169;&#30340;&#38543;&#26426;&#21464;&#37327;&#12290;&#30001;&#20110;&#25968;&#25454;&#25910;&#38598;&#31574;&#30053;&#36890;&#24120;&#22312;&#20174;&#19994;&#32773;&#30340;&#25511;&#21046;&#20043;&#19979;&#65292;&#22240;&#27492;&#24456;&#23569;&#26126;&#30830;&#22320;&#25552;&#21450;&#26080;&#28151;&#28102;&#20551;&#35774;&#65292;&#24182;&#19988;&#29616;&#26377;&#25991;&#29486;&#20013;&#24456;&#23569;&#22788;&#29702;&#20854;&#36829;&#35268;&#38382;&#39064;&#12290;&#36825;&#39033;&#24037;&#20316;&#26088;&#22312;&#24378;&#35843;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#31163;&#32447;&#31574;&#30053;&#20272;&#35745;&#26102;&#20986;&#29616;&#30340;&#38382;&#39064;&#65292;&#29305;&#21035;&#20851;&#27880;&#25512;&#33616;&#31995;&#32479;&#30340;&#29992;&#20363;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#22522;&#20110;&#31574;&#30053;&#30340;&#20272;&#35745;&#22120;&#65292;&#20854;&#20013;&#26085;&#24535;&#20542;&#21521;&#26159;&#20174;&#35760;&#24405;&#25968;&#25454;&#20013;&#23398;&#20064;&#30340;&#12290;&#25105;&#20204;&#23545;&#30001;&#20110;&#28151;&#28102;&#22240;&#32032;&#24341;&#36215;&#30340;&#32479;&#35745;&#20559;&#24046;&#36827;&#34892;&#20102;&#25551;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;
Off-Policy Estimation (OPE) methods allow us to learn and evaluate decision-making policies from logged data. This makes them an attractive choice for the offline evaluation of recommender systems, and several recent works have reported successful adoption of OPE methods to this end. An important assumption that makes this work is the absence of unobserved confounders: random variables that influence both actions and rewards at data collection time. Because the data collection policy is typically under the practitioner's control, the unconfoundedness assumption is often left implicit, and its violations are rarely dealt with in the existing literature.  This work aims to highlight the problems that arise when performing off-policy estimation in the presence of unobserved confounders, specifically focusing on a recommendation use-case. We focus on policy-based estimators, where the logging propensities are learned from logged data. We characterise the statistical bias that arises due to
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;Riemannian Langevin Monte Carlo&#26041;&#26696;&#65292;&#29992;&#20110;&#20174;&#20855;&#26377;&#22266;&#23450;&#31209;&#30340;PSD&#30697;&#38453;&#20013;&#37319;&#26679;&#12290;&#36825;&#20123;&#26041;&#26696;&#36890;&#36807;&#22312;&#27969;&#24418;&#19978;&#20351;&#29992;&#24067;&#26391;&#36816;&#21160;&#30340;Riemannian Langevin&#26041;&#31243;&#30340;Euler-Maruyama&#31163;&#25955;&#21270;&#26469;&#23454;&#29616;&#37319;&#26679;&#65292;&#20855;&#26377;&#23454;&#38469;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2309.04072</link><description>&lt;p&gt;
Riemannian Langevin Monte Carlo&#26041;&#26696;&#29992;&#20110;&#20174;&#20855;&#26377;&#22266;&#23450;&#31209;&#30340;PSD&#30697;&#38453;&#20013;&#36827;&#34892;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Riemannian Langevin Monte Carlo schemes for sampling PSD matrices with fixed rank. (arXiv:2309.04072v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04072
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;Riemannian Langevin Monte Carlo&#26041;&#26696;&#65292;&#29992;&#20110;&#20174;&#20855;&#26377;&#22266;&#23450;&#31209;&#30340;PSD&#30697;&#38453;&#20013;&#37319;&#26679;&#12290;&#36825;&#20123;&#26041;&#26696;&#36890;&#36807;&#22312;&#27969;&#24418;&#19978;&#20351;&#29992;&#24067;&#26391;&#36816;&#21160;&#30340;Riemannian Langevin&#26041;&#31243;&#30340;Euler-Maruyama&#31163;&#25955;&#21270;&#26469;&#23454;&#29616;&#37319;&#26679;&#65292;&#20855;&#26377;&#23454;&#38469;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#26174;&#24335;&#26041;&#26696;&#65292;&#29992;&#20110;&#20174; $\mathcal S^{n,p}_+$ &#20013;&#30340;Gibbs&#20998;&#24067;&#20013;&#37319;&#26679;&#30697;&#38453;&#65292;&#20854;&#20013; $\mathcal S^{n,p}_+$ &#26159;&#23610;&#23544;&#20026;$n\times n$&#65292;&#31209;&#20026;$p$&#30340;&#23454;&#27491;&#21322;&#23450;&#65288;PSD&#65289;&#30697;&#38453;&#27969;&#24418;&#12290;&#32473;&#23450;&#19968;&#20010;&#33021;&#37327;&#20989;&#25968; $\mathcal E:\mathcal S^{n,p}_+\to \mathbb{R}$ &#21644;&#26576;&#20123;&#22312; $\mathcal S^{n,p}_+$ &#19978;&#30340;Riemannian&#24230;&#37327; $g$&#65292;&#36825;&#20123;&#26041;&#26696;&#20381;&#36182;&#20110;&#22312;&#27969;&#24418;&#19978;&#20351;&#29992;&#24067;&#26391;&#36816;&#21160;&#30340;Riemannian Langevin&#26041;&#31243;&#65288;RLE&#65289;&#30340;Euler-Maruyama&#31163;&#25955;&#21270;&#12290;&#25105;&#20204;&#38024;&#23545; $\mathcal S^{n,p}_+$ &#19978;&#30340;&#20004;&#20010;&#22522;&#26412;&#24230;&#37327;&#65288;a&#65289;&#20174;&#23884;&#20837; $\mathcal S^{n,p}_+ \subset \mathbb{R}^{n\times n} $ &#33719;&#24471;&#30340;&#24230;&#37327;&#65307;&#20197;&#21450;&#65288;b&#65289;&#23545;&#24212;&#20110;&#21830;&#27969;&#24418;&#20960;&#20309;&#30340;Bures-Wasserstein&#24230;&#37327;&#65292;&#25552;&#20379;&#20102;RLE&#30340;&#25968;&#20540;&#26041;&#26696;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#20855;&#26377;&#26126;&#30830;Gibbs&#20998;&#24067;&#30340;&#33021;&#37327;&#20989;&#25968;&#30340;&#31034;&#20363;&#65292;&#20197;&#20415;&#23545;&#36825;&#20123;&#26041;&#26696;&#36827;&#34892;&#25968;&#20540;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces two explicit schemes to sample matrices from Gibbs distributions on $\mathcal S^{n,p}_+$, the manifold of real positive semi-definite (PSD) matrices of size $n\times n$ and rank $p$. Given an energy function $\mathcal E:\mathcal S^{n,p}_+\to \mathbb{R}$ and certain Riemannian metrics $g$ on $\mathcal S^{n,p}_+$, these schemes rely on an Euler-Maruyama discretization of the Riemannian Langevin equation (RLE) with Brownian motion on the manifold. We present numerical schemes for RLE under two fundamental metrics on $\mathcal S^{n,p}_+$: (a) the metric obtained from the embedding of $\mathcal S^{n,p}_+ \subset \mathbb{R}^{n\times n} $; and (b) the Bures-Wasserstein metric corresponding to quotient geometry. We also provide examples of energy functions with explicit Gibbs distributions that allow numerical validation of these schemes.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#28385;&#36275;&#26080;&#26465;&#20214;&#33021;&#37327;&#32791;&#25955;&#23450;&#24459;&#12289;&#22312;&#20984;&#35774;&#32622;&#20013;&#35777;&#26126;&#32447;&#24615;&#25910;&#25947;&#30340;&#26032;&#22411;&#20248;&#21270;&#31639;&#27861;E-RSAV&#65292;&#24182;&#19988;&#22312;&#21333;&#21464;&#37327;&#24773;&#20917;&#19979;&#25913;&#36827;&#20102;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#20026;&#36229;&#32447;&#24615;&#65292;&#36824;&#25552;&#20986;&#20102;&#33258;&#36866;&#24212;&#29256;&#26412;&#30340;E-RSAV&#31639;&#27861;&#21152;&#20197;&#23454;&#29616;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2309.04013</link><description>&lt;p&gt;
&#19968;&#31181;&#36880;&#20803;&#24179;&#26041;&#21644;&#25918;&#26494;&#30340;&#36741;&#21161;&#21464;&#37327;&#31639;&#27861;&#29992;&#20110;&#26080;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
An Element-wise RSAV Algorithm for Unconstrained Optimization Problems. (arXiv:2309.04013v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04013
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#28385;&#36275;&#26080;&#26465;&#20214;&#33021;&#37327;&#32791;&#25955;&#23450;&#24459;&#12289;&#22312;&#20984;&#35774;&#32622;&#20013;&#35777;&#26126;&#32447;&#24615;&#25910;&#25947;&#30340;&#26032;&#22411;&#20248;&#21270;&#31639;&#27861;E-RSAV&#65292;&#24182;&#19988;&#22312;&#21333;&#21464;&#37327;&#24773;&#20917;&#19979;&#25913;&#36827;&#20102;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#20026;&#36229;&#32447;&#24615;&#65292;&#36824;&#25552;&#20986;&#20102;&#33258;&#36866;&#24212;&#29256;&#26412;&#30340;E-RSAV&#31639;&#27861;&#21152;&#20197;&#23454;&#29616;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#21363;&#36880;&#20803;&#25918;&#26494;&#30340;&#36741;&#21161;&#26631;&#37327;&#21464;&#37327;&#65288;E-RSAV&#65289;&#65292;&#23427;&#28385;&#36275;&#26080;&#26465;&#20214;&#30340;&#33021;&#37327;&#32791;&#25955;&#23450;&#24459;&#65292;&#24182;&#19988;&#25913;&#36827;&#20102;&#20462;&#25913;&#21518;&#19982;&#21407;&#33021;&#37327;&#30340;&#23545;&#40784;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#20984;&#35774;&#32622;&#20013;&#35777;&#26126;&#20102;&#32447;&#24615;&#25910;&#25947;&#30340;&#20005;&#26684;&#35777;&#26126;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#21152;&#36895;&#31639;&#27861;&#65292;&#21487;&#20197;&#25913;&#21892;&#21333;&#21464;&#37327;&#24773;&#20917;&#19979;&#30340;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#20026;&#36229;&#32447;&#24615;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#29256;&#26412;&#30340;E-RSAV&#31639;&#27861;&#65292;&#37319;&#29992;Steffensen&#27493;&#38271;&#12290;&#36890;&#36807;&#22823;&#37327;&#30340;&#25968;&#20540;&#23454;&#39564;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25105;&#20204;&#31639;&#27861;&#30340;&#40065;&#26834;&#24615;&#21644;&#24555;&#36895;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel optimization algorithm, element-wise relaxed scalar auxiliary variable (E-RSAV), that satisfies an unconditional energy dissipation law and exhibits improved alignment between the modified and the original energy. Our algorithm features rigorous proofs of linear convergence in the convex setting. Furthermore, we present a simple accelerated algorithm that improves the linear convergence rate to super-linear in the univariate case. We also propose an adaptive version of E-RSAV with Steffensen step size. We validate the robustness and fast convergence of our algorithm through ample numerical experiments.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;FFT&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#24674;&#22797;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#22240;&#26524;&#32467;&#26500;&#12290;&#36890;&#36807;&#38477;&#20302;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#20174;&#26102;&#38388;&#24207;&#21015;&#20013;&#33719;&#21462;&#21160;&#24577;&#22240;&#26524;&#25928;&#24212;&#12290;</title><link>http://arxiv.org/abs/2309.02571</link><description>&lt;p&gt;
&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#22240;&#26524;&#32467;&#26500;&#24674;&#22797;&#65306;&#22522;&#20110;FFT&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Causal Structure Recovery of Linear Dynamical Systems: An FFT based Approach. (arXiv:2309.02571v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02571
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;FFT&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#24674;&#22797;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#22240;&#26524;&#32467;&#26500;&#12290;&#36890;&#36807;&#38477;&#20302;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#20174;&#26102;&#38388;&#24207;&#21015;&#20013;&#33719;&#21462;&#21160;&#24577;&#22240;&#26524;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#22240;&#26524;&#25928;&#24212;&#26159;&#31185;&#23398;&#20013;&#19968;&#20010;&#22522;&#30784;&#19988;&#24191;&#27867;&#30740;&#31350;&#30340;&#38382;&#39064;&#65292;&#23588;&#20854;&#26159;&#24403;&#22240;&#26524;&#20851;&#31995;&#26159;&#38745;&#24577;&#30340;&#26102;&#20505;&#12290;&#28982;&#32780;&#65292;&#22312;&#23384;&#22312;&#36328;&#26102;&#38388;&#28857;&#23454;&#20307;&#20043;&#38388;&#20381;&#36182;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#21160;&#24577;&#22240;&#26524;&#25928;&#24212;&#30340;&#35782;&#21035;&#36739;&#23569;&#34987;&#25506;&#32034;&#12290;&#19982;&#38745;&#24577;&#24773;&#20917;&#30456;&#27604;&#65292;&#20174;&#26102;&#38388;&#24207;&#21015;&#35266;&#27979;&#20013;&#33719;&#21462;&#21160;&#24577;&#22240;&#26524;&#25928;&#24212;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#36739;&#39640;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#23545;&#21521;&#37327;&#33258;&#22238;&#24402; (VAR) &#27169;&#22411;&#24674;&#22797;&#22240;&#26524;&#32467;&#26500;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#20026; $O(Tn^3N^2)$&#65292;&#20854;&#20013; $n$ &#26159;&#33410;&#28857;&#25968;&#65292;$T$ &#26159;&#26679;&#26412;&#25968;&#65292;$N$ &#26159;&#23454;&#20307;&#20043;&#38388;&#30340;&#26368;&#22823;&#26102;&#38388;&#28382;&#21518;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22797;&#26434;&#24230;&#20026; $O(Tn^3\log N)$ &#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#24674;&#22797;&#22240;&#26524;&#32467;&#26500;&#20197;&#33719;&#24471;&#39057;&#22495; (FD) &#34920;&#31034;&#30340;&#26102;&#38388;&#24207;&#21015;&#12290;&#30001;&#20110;FFT&#23558;&#25152;&#26377;&#26102;&#38388;&#20381;&#36182;&#20851;&#31995;&#31215;&#32047;&#22312;&#27599;&#20010;&#39057;&#29575;&#19978;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning causal effects from data is a fundamental and well-studied problem across science, especially when the cause-effect relationship is static in nature. However, causal effect is less explored when there are dynamical dependencies, i.e., when dependencies exist between entities across time. Identifying dynamic causal effects from time-series observations is computationally expensive when compared to the static scenario. We demonstrate that the computational complexity of recovering the causation structure for the vector auto-regressive (VAR) model is $O(Tn^3N^2)$, where $n$ is the number of nodes, $T$ is the number of samples, and $N$ is the largest time-lag in the dependency between entities. We report a method, with a reduced complexity of $O(Tn^3 \log N)$, to recover the causation structure to obtain frequency-domain (FD) representations of time-series. Since FFT accumulates all the time dependencies on every frequency, causal inference can be performed efficiently by consider
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#20998;&#31867;&#22120;&#30340;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#31639;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#26631;&#35760;&#35757;&#32451;&#25968;&#25454;&#38598;&#26469;&#36817;&#20284;&#35745;&#31639;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#30340;&#27604;&#29575;&#12290;</title><link>http://arxiv.org/abs/2307.16035</link><description>&lt;p&gt;
&#22522;&#20110;&#31070;&#32463;&#20998;&#31867;&#22120;&#30340;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;
&lt;/p&gt;
&lt;p&gt;
Neural Classifiers based Monte Carlo simulation. (arXiv:2307.16035v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16035
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#20998;&#31867;&#22120;&#30340;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#31639;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#26631;&#35760;&#35757;&#32451;&#25968;&#25454;&#38598;&#26469;&#36817;&#20284;&#35745;&#31639;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#30340;&#27604;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25509;&#21463;-&#25298;&#32477;(AR)&#65292;&#29420;&#31435;Metropolis Hastings&#65288;IMH&#65289;&#25110;&#37325;&#35201;&#24615;&#25277;&#26679;&#65288;IS&#65289;&#33945;&#29305;&#21345;&#27931;&#65288;MC&#65289;&#27169;&#25311;&#31639;&#27861;&#37117;&#28041;&#21450;&#35745;&#31639;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#65288;pdf&#65289;&#30340;&#27604;&#29575;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#20998;&#31867;&#22120;&#21487;&#20197;&#21306;&#20998;&#28151;&#21512;&#23494;&#24230;&#27169;&#22411;&#20135;&#29983;&#30340;&#26631;&#35760;&#26679;&#26412;&#65292;&#21363;&#20004;&#20010;pdf&#30340;&#20984;&#32447;&#24615;&#32452;&#21512;&#65292;&#24182;&#19988;&#21487;&#20197;&#29992;&#20110;&#36817;&#20284;&#36825;&#20004;&#20010;&#23494;&#24230;&#30340;&#27604;&#29575;&#12290;&#36825;&#20010;&#27169;&#25311;&#21644;&#20998;&#31867;&#25216;&#26415;&#20043;&#38388;&#30340;&#26725;&#26753;&#20351;&#25105;&#20204;&#33021;&#22815;&#25552;&#20986;&#20165;&#22522;&#20110;&#26631;&#35760;&#35757;&#32451;&#25968;&#25454;&#38598;&#26500;&#24314;&#30340;&#65288;&#36817;&#20284;&#65289;pdf&#27604;&#29575;&#30340;&#27169;&#25311;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Acceptance-rejection (AR), Independent Metropolis Hastings (IMH) or importance sampling (IS) Monte Carlo (MC) simulation algorithms all involve computing ratios of probability density functions (pdfs). On the other hand, classifiers discriminate labellized samples produced by a mixture density model, i.e., a convex linear combination of two pdfs, and can thus be used for approximating the ratio of these two densities. This bridge between simulation and classification techniques enables us to propose (approximate) pdf-ratios-based simulation algorithms which are built only from a labellized training data set.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26680;&#21270;&#24402;&#19968;&#21270;&#27969;&#33539;&#24335;&#65292;&#31216;&#20026;Ferumal&#27969;&#65292;&#23427;&#23558;&#26680;&#20989;&#25968;&#38598;&#25104;&#21040;&#24402;&#19968;&#21270;&#27969;&#30340;&#26694;&#26550;&#20013;&#12290;&#30456;&#23545;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#27969;&#65292;&#26680;&#21270;&#27969;&#21487;&#20197;&#22312;&#20302;&#25968;&#25454;&#29615;&#22659;&#20013;&#20135;&#29983;&#31454;&#20105;&#21147;&#25110;&#20248;&#36234;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#20445;&#25345;&#21442;&#25968;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2307.14839</link><description>&lt;p&gt;
&#26680;&#21270;&#24402;&#19968;&#21270;&#27969;
&lt;/p&gt;
&lt;p&gt;
Kernelised Normalising Flows. (arXiv:2307.14839v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14839
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26680;&#21270;&#24402;&#19968;&#21270;&#27969;&#33539;&#24335;&#65292;&#31216;&#20026;Ferumal&#27969;&#65292;&#23427;&#23558;&#26680;&#20989;&#25968;&#38598;&#25104;&#21040;&#24402;&#19968;&#21270;&#27969;&#30340;&#26694;&#26550;&#20013;&#12290;&#30456;&#23545;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#27969;&#65292;&#26680;&#21270;&#27969;&#21487;&#20197;&#22312;&#20302;&#25968;&#25454;&#29615;&#22659;&#20013;&#20135;&#29983;&#31454;&#20105;&#21147;&#25110;&#20248;&#36234;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#20445;&#25345;&#21442;&#25968;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24402;&#19968;&#21270;&#27969;&#26159;&#20197;&#20854;&#21487;&#36870;&#30340;&#26550;&#26500;&#32780;&#34987;&#25551;&#36848;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#21487;&#36870;&#24615;&#35201;&#27714;&#23545;&#20854;&#34920;&#36798;&#33021;&#21147;&#26045;&#21152;&#38480;&#21046;&#65292;&#38656;&#35201;&#22823;&#37327;&#30340;&#21442;&#25968;&#21644;&#21019;&#26032;&#30340;&#26550;&#26500;&#35774;&#35745;&#26469;&#36798;&#21040;&#28385;&#24847;&#30340;&#32467;&#26524;&#12290;&#34429;&#28982;&#22522;&#20110;&#27969;&#30340;&#27169;&#22411;&#20027;&#35201;&#20381;&#36182;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#36716;&#25442;&#26469;&#23454;&#29616;&#34920;&#36798;&#33021;&#21147;&#65292;&#20294;&#26367;&#20195;&#30340;&#36716;&#25442;&#26041;&#27861;&#21364;&#21463;&#21040;&#20102;&#26377;&#38480;&#30340;&#20851;&#27880;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26680;&#21270;&#24402;&#19968;&#21270;&#27969;&#33539;&#24335;&#65292;&#31216;&#20026;Ferumal&#27969;&#65292;&#23427;&#23558;&#26680;&#20989;&#25968;&#38598;&#25104;&#21040;&#26694;&#26550;&#20013;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#30456;&#27604;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#27969;&#65292;&#26680;&#21270;&#27969;&#21487;&#20197;&#20135;&#29983;&#26377;&#31454;&#20105;&#21147;&#25110;&#20248;&#36234;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#20445;&#25345;&#21442;&#25968;&#25928;&#29575;&#12290;&#26680;&#21270;&#27969;&#22312;&#20302;&#25968;&#25454;&#29615;&#22659;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#21487;&#20197;&#22312;&#25968;&#25454;&#31232;&#32570;&#30340;&#24212;&#29992;&#20013;&#36827;&#34892;&#28789;&#27963;&#30340;&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Normalising Flows are generative models characterised by their invertible architecture. However, the requirement of invertibility imposes constraints on their expressiveness, necessitating a large number of parameters and innovative architectural designs to achieve satisfactory outcomes. Whilst flow-based models predominantly rely on neural-network-based transformations for expressive designs, alternative transformation methods have received limited attention. In this work, we present Ferumal flow, a novel kernelised normalising flow paradigm that integrates kernels into the framework. Our results demonstrate that a kernelised flow can yield competitive or superior results compared to neural network-based flows whilst maintaining parameter efficiency. Kernelised flows excel especially in the low-data regime, enabling flexible non-parametric density estimation in applications with sparse data availability.
&lt;/p&gt;</description></item><item><title>&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;Wasserstein&#32479;&#35745;&#22312;&#20223;&#23556;&#21464;&#24418;&#32479;&#35745;&#27169;&#22411;&#20013;&#30340;&#20449;&#24687;&#20960;&#20309;&#29305;&#24449;&#65292;&#27604;&#36739;&#20102;&#20449;&#24687;&#20960;&#20309;&#21644;Wasserstein&#20960;&#20309;&#30340;&#20272;&#35745;&#22120;&#30340;&#20248;&#32570;&#28857;&#65292;&#24182;&#21457;&#29616;Wasserstein&#20272;&#35745;&#37327;&#22312;&#26925;&#22278;&#23545;&#31216;&#20223;&#23556;&#21464;&#24418;&#27169;&#22411;&#20013;&#26159;&#30697;&#20272;&#35745;&#37327;&#65292;&#22312;&#27874;&#24418;&#20026;&#39640;&#26031;&#20998;&#24067;&#26102;&#19982;&#20449;&#24687;&#20960;&#20309;&#20272;&#35745;&#37327;&#37325;&#21512;&#12290;</title><link>http://arxiv.org/abs/2307.12508</link><description>&lt;p&gt;
&#24418;&#29366;&#21644;&#20223;&#23556;&#21464;&#24418;&#30340;Wasserstein&#32479;&#35745;&#30340;&#20449;&#24687;&#20960;&#20309;
&lt;/p&gt;
&lt;p&gt;
Information Geometry of Wasserstein Statistics on Shapes and Affine Deformations. (arXiv:2307.12508v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12508
&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;Wasserstein&#32479;&#35745;&#22312;&#20223;&#23556;&#21464;&#24418;&#32479;&#35745;&#27169;&#22411;&#20013;&#30340;&#20449;&#24687;&#20960;&#20309;&#29305;&#24449;&#65292;&#27604;&#36739;&#20102;&#20449;&#24687;&#20960;&#20309;&#21644;Wasserstein&#20960;&#20309;&#30340;&#20272;&#35745;&#22120;&#30340;&#20248;&#32570;&#28857;&#65292;&#24182;&#21457;&#29616;Wasserstein&#20272;&#35745;&#37327;&#22312;&#26925;&#22278;&#23545;&#31216;&#20223;&#23556;&#21464;&#24418;&#27169;&#22411;&#20013;&#26159;&#30697;&#20272;&#35745;&#37327;&#65292;&#22312;&#27874;&#24418;&#20026;&#39640;&#26031;&#20998;&#24067;&#26102;&#19982;&#20449;&#24687;&#20960;&#20309;&#20272;&#35745;&#37327;&#37325;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#20960;&#20309;&#21644;Wasserstein&#20960;&#20309;&#26159;&#20171;&#32461;&#27010;&#29575;&#20998;&#24067;&#27969;&#24418;&#20013;&#30340;&#20004;&#20010;&#20027;&#35201;&#32467;&#26500;&#65292;&#23427;&#20204;&#25429;&#25417;&#20102;&#19981;&#21516;&#30340;&#29305;&#24449;&#12290;&#25105;&#20204;&#22312;&#20223;&#23556;&#21464;&#24418;&#32479;&#35745;&#27169;&#22411;&#30340;Li&#21644;Zhao&#65288;2023&#65289;&#26694;&#26550;&#20013;&#30740;&#31350;&#20102;Wasserstein&#20960;&#20309;&#30340;&#29305;&#24449;&#65292;&#23427;&#26159;&#20301;&#32622;-&#23610;&#24230;&#27169;&#22411;&#30340;&#22810;&#32500;&#27867;&#21270;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#22522;&#20110;&#20449;&#24687;&#20960;&#20309;&#21644;Wasserstein&#20960;&#20309;&#30340;&#20272;&#35745;&#22120;&#30340;&#20248;&#28857;&#21644;&#32570;&#28857;&#12290;&#22312;Wasserstein&#20960;&#20309;&#20013;&#65292;&#27010;&#29575;&#20998;&#24067;&#30340;&#24418;&#29366;&#21644;&#20223;&#23556;&#21464;&#24418;&#26159;&#20998;&#31163;&#30340;&#65292;&#34920;&#26126;&#22312;&#23545;&#27874;&#24418;&#25200;&#21160;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#21516;&#26102;&#65292;&#20250;&#25439;&#22833;Fisher&#25928;&#29575;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#26925;&#22278;&#23545;&#31216;&#20223;&#23556;&#21464;&#24418;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;Wasserstein&#20272;&#35745;&#37327;&#26159;&#30697;&#20272;&#35745;&#37327;&#12290;&#23427;&#19982;&#20449;&#24687;&#20960;&#20309;&#20272;&#35745;&#37327;&#65288;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#37327;&#65289;&#20165;&#22312;&#27874;&#24418;&#20026;&#39640;&#26031;&#20998;&#24067;&#26102;&#37325;&#21512;&#12290;Wasserstein&#25928;&#29575;&#30340;&#20316;&#29992;&#26159;...
&lt;/p&gt;
&lt;p&gt;
Information geometry and Wasserstein geometry are two main structures introduced in a manifold of probability distributions, and they capture its different characteristics. We study characteristics of Wasserstein geometry in the framework of Li and Zhao (2023) for the affine deformation statistical model, which is a multi-dimensional generalization of the location-scale model. We compare merits and demerits of estimators based on information geometry and Wasserstein geometry. The shape of a probability distribution and its affine deformation are separated in the Wasserstein geometry, showing its robustness against the waveform perturbation in exchange for the loss in Fisher efficiency. We show that the Wasserstein estimator is the moment estimator in the case of the elliptically symmetric affine deformation model. It coincides with the information-geometrical estimator (maximum-likelihood estimator) when and only when the waveform is Gaussian. The role of the Wasserstein efficiency is 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#20195;&#25968;&#35780;&#20272;&#22120;&#26469;&#20272;&#35745;&#26410;&#26631;&#35760;&#25968;&#25454;&#20013;&#26377;&#22122;&#22768;&#20108;&#20803;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#12290;&#20854;&#20013;&#65292;&#31532;&#20108;&#31181;&#35780;&#20272;&#22120;&#30340;&#27491;&#30830;&#24615;&#34987;&#20445;&#35777;&#12290;&#20316;&#32773;&#36890;&#36807;&#21033;&#29992;&#29420;&#31435;&#35780;&#20272;&#22120;&#26080;&#27861;&#36820;&#22238;&#21512;&#29702;&#20272;&#35745;&#30340;&#22833;&#36133;&#65292;&#32531;&#35299;&#20102;&#22996;&#25176;/&#20195;&#29702;&#30417;&#25511;&#24726;&#35770;&#65292;&#24182;&#36890;&#36807;&#25628;&#32034;&#26469;&#23547;&#25214;&#20960;&#20046;&#26080;&#35823;&#24046;&#30340;&#19977;&#20803;&#32452;&#12290;</title><link>http://arxiv.org/abs/2306.01726</link><description>&lt;p&gt;
&#35780;&#20272;&#26377;&#22122;&#22768;&#21028;&#21035;&#22120;&#23545;&#26410;&#26631;&#35760;&#25968;&#25454;&#30340;&#27969;&#24335;&#31639;&#27861; -- &#20108;&#20803;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Streaming algorithms for evaluating noisy judges on unlabeled data -- binary classification. (arXiv:2306.01726v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01726
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#20195;&#25968;&#35780;&#20272;&#22120;&#26469;&#20272;&#35745;&#26410;&#26631;&#35760;&#25968;&#25454;&#20013;&#26377;&#22122;&#22768;&#20108;&#20803;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#12290;&#20854;&#20013;&#65292;&#31532;&#20108;&#31181;&#35780;&#20272;&#22120;&#30340;&#27491;&#30830;&#24615;&#34987;&#20445;&#35777;&#12290;&#20316;&#32773;&#36890;&#36807;&#21033;&#29992;&#29420;&#31435;&#35780;&#20272;&#22120;&#26080;&#27861;&#36820;&#22238;&#21512;&#29702;&#20272;&#35745;&#30340;&#22833;&#36133;&#65292;&#32531;&#35299;&#20102;&#22996;&#25176;/&#20195;&#29702;&#30417;&#25511;&#24726;&#35770;&#65292;&#24182;&#36890;&#36807;&#25628;&#32034;&#26469;&#23547;&#25214;&#20960;&#20046;&#26080;&#35823;&#24046;&#30340;&#19977;&#20803;&#32452;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#23545;&#26410;&#26631;&#35760;&#25968;&#25454;&#20013;&#30340;&#26377;&#22122;&#22768;&#20108;&#20803;&#20998;&#31867;&#22120;&#30340;&#35780;&#20272;&#20316;&#20026;&#27969;&#24335;&#20219;&#21153;&#36827;&#34892;&#30740;&#31350;: &#32473;&#23450;&#19968;&#20010;&#20998;&#31867;&#22120;&#20915;&#31574;&#30340;&#25968;&#25454;&#33609;&#22270;&#65292;&#20272;&#35745;&#26631;&#31614;&#30340;&#30495;&#23454;&#27969;&#34892;&#24230;&#20197;&#21450;&#27599;&#20010;&#20998;&#31867;&#22120;&#23545;&#23427;&#20204;&#30340;&#20934;&#30830;&#24230;&#12290;&#26412;&#25991;&#26500;&#24314;&#20102;&#20004;&#31181;&#23436;&#20840;&#20195;&#25968;&#21270;&#30340;&#35780;&#20272;&#22120;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#12290;&#20004;&#31181;&#35780;&#20272;&#22120;&#37117;&#22522;&#20110;&#20998;&#31867;&#22120;&#20135;&#29983;&#29420;&#31435;&#38169;&#35823;&#30340;&#20551;&#35774;&#12290;&#31532;&#19968;&#31181;&#26159;&#22522;&#20110;&#22810;&#25968;&#25237;&#31080;&#30340;&#12290;&#32780;&#31532;&#20108;&#31181;&#21017;&#26159;&#26412;&#25991;&#30340;&#20027;&#35201;&#36129;&#29486;&#65292;&#24182;&#34987;&#20445;&#35777;&#26159;&#27491;&#30830;&#30340;&#12290;&#20294;&#26159;&#22914;&#20309;&#30830;&#20445;&#20998;&#31867;&#22120;&#22312;&#20219;&#20309;&#32473;&#23450;&#30340;&#27979;&#35797;&#20013;&#26159;&#29420;&#31435;&#30340;&#21602;&#65311;&#26412;&#25991;&#36890;&#36807;&#21033;&#29992;&#29420;&#31435;&#35780;&#20272;&#22120;&#26080;&#27861;&#36820;&#22238;&#21512;&#29702;&#20272;&#35745;&#30340;&#22833;&#36133;&#26469;&#32531;&#35299;&#36825;&#20010;&#22996;&#25176;/&#20195;&#29702;&#30417;&#25511;&#24726;&#35770;&#12290;&#36890;&#36807;&#21033;&#29992;&#20195;&#25968;&#25925;&#38556;&#27169;&#24335;&#26469;&#25298;&#32477;&#22826;&#30456;&#20851;&#30340;&#35780;&#20272;&#38598;&#21512;&#65292;&#20351;&#29992; \texttt{adult}&#65292;\texttt{mushroom} &#21644; \texttt{two-norm} &#25968;&#25454;&#38598;&#23545;&#19968;&#32452;&#20960;&#20046;&#26080;&#35823;&#24046;&#19977;&#20803;&#32452;&#36827;&#34892;&#20102;&#23454;&#35777;&#25628;&#32034;&#12290;&#36825;&#20123;&#25628;&#32034;&#36890;&#36807;&#26500;&#24314;&#35780;&#20272;&#31354;&#38388;&#20013;&#30340;&#34920;&#38754;&#26469;&#36827;&#34892;&#31934;&#32454;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
The evaluation of noisy binary classifiers on unlabeled data is treated as a streaming task: given a data sketch of the decisions by an ensemble, estimate the true prevalence of the labels as well as each classifier's accuracy on them. Two fully algebraic evaluators are constructed to do this. Both are based on the assumption that the classifiers make independent errors. The first is based on majority voting. The second, the main contribution of the paper, is guaranteed to be correct. But how do we know the classifiers are independent on any given test? This principal/agent monitoring paradox is ameliorated by exploiting the failures of the independent evaluator to return sensible estimates. A search for nearly error independent trios is empirically carried out on the \texttt{adult}, \texttt{mushroom}, and \texttt{two-norm} datasets by using the algebraic failure modes to reject evaluation ensembles as too correlated. The searches are refined by constructing a surface in evaluation spa
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#39564;&#35777;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21363;&#35757;&#32451;&#26131;&#20110;&#39564;&#35777;&#30340;&#38480;&#21046;&#27169;&#22411;&#31867;&#26469;&#35299;&#20915;&#20915;&#31574;&#26641;&#38598;&#25104;&#30340; NP-hard &#38382;&#39064;&#65292;&#24182;&#25104;&#21151;&#35774;&#35745;&#20986;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#20351;&#24471;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#21487;&#20197;&#36827;&#34892;&#23433;&#20840;&#39564;&#35777;&#65292;&#32780;&#19988;&#20173;&#20445;&#25345;&#30528;&#35813;&#39046;&#22495;&#26368;&#22909;&#30340;&#40065;&#26834;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.03626</link><description>&lt;p&gt;
&#40065;&#26834;&#20915;&#31574;&#26641;&#38598;&#25104;&#30340;&#21487;&#39564;&#35777;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Verifiable Learning for Robust Tree Ensembles. (arXiv:2305.03626v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03626
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#39564;&#35777;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21363;&#35757;&#32451;&#26131;&#20110;&#39564;&#35777;&#30340;&#38480;&#21046;&#27169;&#22411;&#31867;&#26469;&#35299;&#20915;&#20915;&#31574;&#26641;&#38598;&#25104;&#30340; NP-hard &#38382;&#39064;&#65292;&#24182;&#25104;&#21151;&#35774;&#35745;&#20986;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#20351;&#24471;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#21487;&#20197;&#36827;&#34892;&#23433;&#20840;&#39564;&#35777;&#65292;&#32780;&#19988;&#20173;&#20445;&#25345;&#30528;&#35813;&#39046;&#22495;&#26368;&#22909;&#30340;&#40065;&#26834;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#27979;&#35797;&#26102;&#38388;&#20869;&#39564;&#35777;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#23545;&#25239;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#30740;&#31350;&#38382;&#39064;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#30830;&#23450;&#65292;&#23545;&#20110;&#20915;&#31574;&#26641;&#38598;&#25104;&#65292;&#36825;&#20010;&#38382;&#39064;&#26159; NP-hard &#65292;&#22240;&#27492;&#23545;&#20110;&#29305;&#23450;&#30340;&#36755;&#20837;&#26469;&#35828;&#26159;&#19981;&#21487;&#35299;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#19968;&#31867;&#21463;&#38480;&#20915;&#31574;&#26641;&#38598;&#25104;&#65292;&#31216;&#20026; large-spread &#38598;&#25104;&#65292;&#20854;&#20801;&#35768;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#36816;&#34892;&#23433;&#20840;&#39564;&#35777;&#31639;&#27861;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#31216;&#20026;&#21487;&#39564;&#35777;&#23398;&#20064;&#65292;&#35813;&#26041;&#27861;&#20513;&#23548;&#35757;&#32451;&#36825;&#31181;&#26131;&#20110;&#39564;&#35777;&#30340;&#21463;&#38480;&#27169;&#22411;&#31867;&#12290;&#25105;&#20204;&#36890;&#36807;&#35774;&#35745;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#20174;&#26631;&#35760;&#25968;&#25454;&#20013;&#33258;&#21160;&#23398;&#20064; large-spread &#20915;&#31574;&#26641;&#38598;&#25104;&#26469;&#23637;&#31034;&#36825;&#31181;&#26041;&#27861;&#30340;&#30410;&#22788;&#65292;&#20174;&#32780;&#20351;&#20854;&#33021;&#22815;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#36827;&#34892;&#23433;&#20840;&#39564;&#35777;&#12290;&#20844;&#24320;&#21487;&#29992;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#35777;&#23454;&#65292;&#20351;&#29992;&#25105;&#20204;&#30340;&#31639;&#27861;&#35757;&#32451;&#30340; large-spread &#38598;&#25104;&#21487;&#20197;&#22312;&#20960;&#31186;&#38047;&#20869;&#20351;&#29992;&#26631;&#20934;&#21322;&#23450;&#32534;&#31243;&#27714;&#35299;&#22120;&#36827;&#34892;&#39564;&#35777;&#65292;&#21516;&#26102;&#23545;&#25239;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#25915;&#20987;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Verifying the robustness of machine learning models against evasion attacks at test time is an important research problem. Unfortunately, prior work established that this problem is NP-hard for decision tree ensembles, hence bound to be intractable for specific inputs. In this paper, we identify a restricted class of decision tree ensembles, called large-spread ensembles, which admit a security verification algorithm running in polynomial time. We then propose a new approach called verifiable learning, which advocates the training of such restricted model classes which are amenable for efficient verification. We show the benefits of this idea by designing a new training algorithm that automatically learns a large-spread decision tree ensemble from labelled data, thus enabling its security verification in polynomial time. Experimental results on publicly available datasets confirm that large-spread ensembles trained using our algorithm can be verified in a matter of seconds, using stand
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#22312;&#23398;&#20064;&#27010;&#29575;&#27979;&#24230;&#30340;Wasserstein&#31354;&#38388;&#21644;&#20989;&#25968;&#31354;&#38388;&#20043;&#38388;&#30340;&#26144;&#23556;&#20013;&#30340;&#24212;&#29992;&#12290;&#25552;&#20986;&#20102;&#20004;&#31867;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#36890;&#29992;&#36924;&#36817;&#23450;&#29702;&#29702;&#35770;&#25903;&#25345;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#23637;&#31034;&#20102;&#20854;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;&#20381;&#36182;&#20110;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#26102;&#38388;&#30456;&#20851;&#30340;&#22343;&#22330;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2210.15179</link><description>&lt;p&gt;
&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#65306;&#23398;&#20064;Wasserstein&#31354;&#38388;&#19978;&#30340;&#26144;&#23556;
&lt;/p&gt;
&lt;p&gt;
Mean-field neural networks: learning mappings on Wasserstein space. (arXiv:2210.15179v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.15179
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#22312;&#23398;&#20064;&#27010;&#29575;&#27979;&#24230;&#30340;Wasserstein&#31354;&#38388;&#21644;&#20989;&#25968;&#31354;&#38388;&#20043;&#38388;&#30340;&#26144;&#23556;&#20013;&#30340;&#24212;&#29992;&#12290;&#25552;&#20986;&#20102;&#20004;&#31867;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#36890;&#29992;&#36924;&#36817;&#23450;&#29702;&#29702;&#35770;&#25903;&#25345;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#23637;&#31034;&#20102;&#20854;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;&#20381;&#36182;&#20110;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#26102;&#38388;&#30456;&#20851;&#30340;&#22343;&#22330;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#27010;&#29575;&#27979;&#24230;&#30340;Wasserstein&#31354;&#38388;&#21644;&#20989;&#25968;&#31354;&#38388;&#20043;&#38388;&#36827;&#34892;&#26144;&#23556;&#30340;&#27169;&#22411;&#30340;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#20363;&#22914;&#22312;&#22343;&#22330;&#21338;&#24328;/&#25511;&#21046;&#38382;&#39064;&#20013;&#12290;&#25552;&#20986;&#20102;&#20004;&#31867;&#22522;&#20110;&#20108;&#36827;&#21046;&#23494;&#24230;&#21644;&#22278;&#26609;&#36924;&#36817;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#29992;&#20110;&#23398;&#20064;&#36825;&#20123;&#25152;&#35859;&#30340;&#22343;&#22330;&#20989;&#25968;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#33719;&#24471;&#20102;&#36890;&#29992;&#36924;&#36817;&#23450;&#29702;&#30340;&#25903;&#25345;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#20960;&#20010;&#25968;&#20540;&#23454;&#39564;&#26469;&#35757;&#32451;&#36825;&#20004;&#20010;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#20204;&#22312;&#21508;&#31181;&#27979;&#35797;&#20998;&#24067;&#20013;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#20197;&#21450;&#27867;&#21270;&#35823;&#24046;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20381;&#36182;&#20110;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#30340;&#19981;&#21516;&#31639;&#27861;&#26469;&#35299;&#20915;&#26102;&#38388;&#30456;&#20851;&#30340;&#22343;&#22330;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#27979;&#35797;&#22312;&#27010;&#29575;&#27979;&#24230;&#30340;Wasserstein&#31354;&#38388;&#20013;&#30340;&#21322;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#20363;&#23376;&#26469;&#35828;&#26126;&#25105;&#20204;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the machine learning task for models with operators mapping between the Wasserstein space of probability measures and a space of functions, like e.g. in mean-field games/control problems. Two classes of neural networks, based on bin density and on cylindrical approximation, are proposed to learn these so-called mean-field functions, and are theoretically supported by universal approximation theorems. We perform several numerical experiments for training these two mean-field neural networks, and show their accuracy and efficiency in the generalization error with various test distributions. Finally, we present different algorithms relying on mean-field neural networks for solving time-dependent mean-field problems, and illustrate our results with numerical tests for the example of a semi-linear partial differential equation in the Wasserstein space of probability measures.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#24341;&#20837;&#20102;&#20004;&#31867;&#26032;&#30340;&#20449;&#24687;&#24230;&#37327;&#26041;&#27861;&#65292;&#25193;&#23637;&#21644;&#32479;&#19968;&#20102;&#19981;&#21516;&#20998;&#24067;&#20043;&#38388;&#30340;&#25955;&#24230;&#65292;&#36890;&#36807;&#20449;&#24687;&#24230;&#37327;&#21644;&#36125;&#21494;&#26031;&#39118;&#38505;&#20043;&#38388;&#30340;&#20960;&#20309;&#20851;&#31995;&#20197;&#21450;&#20449;&#24687;&#22788;&#29702;&#31561;&#24335;&#65292;&#25581;&#31034;&#20102;&#22312;&#32463;&#20856;&#39118;&#38505;&#26368;&#23567;&#21270;&#20013;&#36873;&#25321;&#20551;&#35774;&#31867;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2207.11987</link><description>&lt;p&gt;
&#20449;&#24687;&#22788;&#29702;&#30456;&#31561;&#24615;&#21644;&#20449;&#24687;&#39118;&#38505;&#26725;&#26753;
&lt;/p&gt;
&lt;p&gt;
Information Processing Equalities and the Information-Risk Bridge. (arXiv:2207.11987v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.11987
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#24341;&#20837;&#20102;&#20004;&#31867;&#26032;&#30340;&#20449;&#24687;&#24230;&#37327;&#26041;&#27861;&#65292;&#25193;&#23637;&#21644;&#32479;&#19968;&#20102;&#19981;&#21516;&#20998;&#24067;&#20043;&#38388;&#30340;&#25955;&#24230;&#65292;&#36890;&#36807;&#20449;&#24687;&#24230;&#37327;&#21644;&#36125;&#21494;&#26031;&#39118;&#38505;&#20043;&#38388;&#30340;&#20960;&#20309;&#20851;&#31995;&#20197;&#21450;&#20449;&#24687;&#22788;&#29702;&#31561;&#24335;&#65292;&#25581;&#31034;&#20102;&#22312;&#32463;&#20856;&#39118;&#38505;&#26368;&#23567;&#21270;&#20013;&#36873;&#25321;&#20551;&#35774;&#31867;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#31867;&#26032;&#30340;&#20449;&#24687;&#24230;&#37327;&#26041;&#27861;&#65292;&#29992;&#20110;&#32479;&#35745;&#23454;&#39564;&#65292;&#25512;&#24191;&#20102;&#21644;&#21253;&#21547;&#20102;$\phi$-&#25955;&#24230;&#12289;&#31215;&#20998;&#27010;&#29575;&#24230;&#37327;&#12289;$\mathfrak{N}$-&#36317;&#31163;&#65288;MMD&#65289;&#21644;&#20004;&#20010;&#25110;&#22810;&#20010;&#20998;&#24067;&#20043;&#38388;&#30340;$(f,\Gamma)$-&#25955;&#24230;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#25512;&#23548;&#20986;&#20449;&#24687;&#24230;&#37327;&#21644;&#32479;&#35745;&#20915;&#31574;&#38382;&#39064;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#20043;&#38388;&#30340;&#31616;&#21333;&#20960;&#20309;&#20851;&#31995;&#65292;&#20174;&#32780;&#20197;&#23436;&#20840;&#23545;&#31216;&#30340;&#26041;&#24335;&#23558;&#21464;&#20998;$\phi$-&#25955;&#24230;&#34920;&#31034;&#25193;&#23637;&#21040;&#22810;&#20010;&#20998;&#24067;&#20013;&#12290;&#26032;&#30340;&#25955;&#24230;&#26063;&#22312;&#39532;&#23572;&#21487;&#22827;&#31639;&#23376;&#30340;&#20316;&#29992;&#19979;&#20445;&#25345;&#19981;&#21464;&#65292;&#20135;&#29983;&#20102;&#19968;&#20010;&#20449;&#24687;&#22788;&#29702;&#31561;&#24335;&#65292;&#23427;&#26159;&#32463;&#20856;&#25968;&#25454;&#22788;&#29702;&#19981;&#31561;&#24335;&#30340;&#32454;&#21270;&#21644;&#25512;&#24191;&#12290;&#36825;&#20010;&#31561;&#24335;&#25581;&#31034;&#20102;&#22312;&#32463;&#20856;&#39118;&#38505;&#26368;&#23567;&#21270;&#20013;&#36873;&#25321;&#20551;&#35774;&#31867;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce two new classes of measures of information for statistical experiments which generalise and subsume $\phi$-divergences, integral probability metrics, $\mathfrak{N}$-distances (MMD), and $(f,\Gamma)$ divergences between two or more distributions. This enables us to derive a simple geometrical relationship between measures of information and the Bayes risk of a statistical decision problem, thus extending the variational $\phi$-divergence representation to multiple distributions in an entirely symmetric manner. The new families of divergence are closed under the action of Markov operators which yields an information processing equality which is a refinement and generalisation of the classical data processing inequality. This equality gives insight into the significance of the choice of the hypothesis class in classical risk minimization.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20215;&#26684;&#30340;&#32593;&#32476;&#25910;&#30410;&#31649;&#29702;&#38382;&#39064;&#65292;&#21516;&#26102;&#32771;&#34385;&#20102;&#38656;&#27714;&#23398;&#20064;&#21644;&#20844;&#24179;&#36164;&#28304;&#28040;&#32791;&#24179;&#34913;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;UCB&#38656;&#27714;&#23398;&#20064;&#26041;&#27861;&#30340;&#21407;&#22987;&#23545;&#20598;&#22312;&#32447;&#31574;&#30053;&#26469;&#26368;&#22823;&#21270;&#35268;&#33539;&#21270;&#25910;&#30410;&#12290;</title><link>http://arxiv.org/abs/2207.11159</link><description>&lt;p&gt;
&#22522;&#20110;&#38656;&#27714;&#23398;&#20064;&#21644;&#20844;&#24179;&#36164;&#28304;&#28040;&#32791;&#24179;&#34913;&#30340;&#32593;&#32476;&#25910;&#30410;&#31649;&#29702;
&lt;/p&gt;
&lt;p&gt;
Network Revenue Management with Demand Learning and Fair Resource-Consumption Balancing. (arXiv:2207.11159v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.11159
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20215;&#26684;&#30340;&#32593;&#32476;&#25910;&#30410;&#31649;&#29702;&#38382;&#39064;&#65292;&#21516;&#26102;&#32771;&#34385;&#20102;&#38656;&#27714;&#23398;&#20064;&#21644;&#20844;&#24179;&#36164;&#28304;&#28040;&#32791;&#24179;&#34913;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;UCB&#38656;&#27714;&#23398;&#20064;&#26041;&#27861;&#30340;&#21407;&#22987;&#23545;&#20598;&#22312;&#32447;&#31574;&#30053;&#26469;&#26368;&#22823;&#21270;&#35268;&#33539;&#21270;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38500;&#20102;&#26368;&#22823;&#21270;&#24635;&#25910;&#30410;&#22806;&#65292;&#24456;&#22810;&#34892;&#19994;&#30340;&#20915;&#31574;&#32773;&#36824;&#24076;&#26395;&#30830;&#20445;&#19981;&#21516;&#36164;&#28304;&#20043;&#38388;&#28040;&#32791;&#30340;&#24179;&#34913;&#12290;&#20363;&#22914;&#65292;&#22312;&#38646;&#21806;&#34892;&#19994;&#20013;&#65292;&#30830;&#20445;&#26469;&#33258;&#19981;&#21516;&#20379;&#24212;&#21830;&#30340;&#36164;&#28304;&#24179;&#34913;&#28040;&#32791;&#26377;&#21161;&#20110;&#25552;&#39640;&#20844;&#24179;&#24615;&#24182;&#32500;&#25345;&#33391;&#22909;&#30340;&#28192;&#36947;&#20851;&#31995;&#65307;&#22312;&#20113;&#35745;&#31639;&#34892;&#19994;&#20013;&#65292;&#36164;&#28304;&#28040;&#32791;&#30340;&#24179;&#34913;&#26377;&#21161;&#20110;&#25552;&#39640;&#23458;&#25143;&#28385;&#24847;&#24230;&#24182;&#38477;&#20302;&#36816;&#33829;&#25104;&#26412;&#12290;&#38024;&#23545;&#36825;&#20123;&#23454;&#38469;&#38656;&#27714;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20215;&#26684;&#30340;&#32593;&#32476;&#25910;&#30410;&#31649;&#29702;&#38382;&#39064;&#65292;&#21516;&#26102;&#32771;&#34385;&#20102;&#38656;&#27714;&#23398;&#20064;&#21644;&#20844;&#24179;&#36164;&#28304;&#28040;&#32791;&#24179;&#34913;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#35268;&#33539;&#21270;&#25910;&#30410;&#30340;&#27010;&#24565;&#65292;&#21363;&#36890;&#36807;&#24179;&#34913;&#27491;&#21017;&#21270;&#23558;&#20844;&#24179;&#30340;&#36164;&#28304;&#28040;&#32791;&#24179;&#34913;&#32435;&#20837;&#21040;&#25910;&#30410;&#26368;&#22823;&#21270;&#30340;&#30446;&#26631;&#20013;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#19978;&#32622;&#20449;&#30028;&#38480;&#65288;UCB&#65289;&#38656;&#27714;&#23398;&#20064;&#26041;&#27861;&#30340;&#21407;&#22987;&#23545;&#20598;&#22312;&#32447;&#31574;&#30053;&#26469;&#26368;&#22823;&#21270;&#35268;&#33539;&#21270;&#25910;&#30410;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#20960;&#20010;&#21019;&#26032;&#26041;&#27861;&#26469;&#24212;&#23545;&#38656;&#27714;&#23398;&#20064;&#21644;&#36164;&#28304;&#28040;&#32791;&#24179;&#34913;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
In addition to maximizing the total revenue, decision-makers in lots of industries would like to guarantee balanced consumption across different resources. For instance, in the retailing industry, ensuring a balanced consumption of resources from different suppliers enhances fairness and helps main a good channel relationship; in the cloud computing industry, resource-consumption balance helps increase customer satisfaction and reduce operational costs. Motivated by these practical needs, this paper studies the price-based network revenue management (NRM) problem with both demand learning and fair resource-consumption balancing. We introduce the regularized revenue, i.e., the total revenue with a balancing regularization, as our objective to incorporate fair resource-consumption balancing into the revenue maximization goal. We propose a primal-dual-type online policy with the Upper-Confidence-Bound (UCB) demand learning method to maximize the regularized revenue. We adopt several innov
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;Wasserstein&#26799;&#24230;&#27969;&#23454;&#29616;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#22343;&#22330;&#21464;&#20998;&#25512;&#29702;&#30340;&#36890;&#29992;&#35745;&#31639;&#26694;&#26550;&#65292;&#20811;&#26381;&#20102;&#20808;&#39564;&#21644;&#21464;&#20998;&#36817;&#20284;&#25152;&#38656;&#30340;&#29305;&#23450;&#20849;&#36717;&#32467;&#26500;&#38480;&#21046;&#65292;&#24182;&#23637;&#31034;&#20102;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#21644;MF&#21464;&#20998;&#21518;&#39564;&#38598;&#20013;&#24615;&#30340;&#24378;&#21270;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2207.08074</link><description>&lt;p&gt;
&#36890;&#36807;Wasserstein&#26799;&#24230;&#27969;&#36827;&#34892;&#22343;&#22330;&#21464;&#20998;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Mean-field Variational Inference via Wasserstein Gradient Flow. (arXiv:2207.08074v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.08074
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;Wasserstein&#26799;&#24230;&#27969;&#23454;&#29616;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#22343;&#22330;&#21464;&#20998;&#25512;&#29702;&#30340;&#36890;&#29992;&#35745;&#31639;&#26694;&#26550;&#65292;&#20811;&#26381;&#20102;&#20808;&#39564;&#21644;&#21464;&#20998;&#36817;&#20284;&#25152;&#38656;&#30340;&#29305;&#23450;&#20849;&#36717;&#32467;&#26500;&#38480;&#21046;&#65292;&#24182;&#23637;&#31034;&#20102;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#21644;MF&#21464;&#20998;&#21518;&#39564;&#38598;&#20013;&#24615;&#30340;&#24378;&#21270;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#25512;&#29702;&#65292;&#22914;&#22343;&#22330;&#65288;MF&#65289;&#36817;&#20284;&#65292;&#23545;&#20110;&#39640;&#25928;&#35745;&#31639;&#38656;&#35201;&#29305;&#23450;&#30340;&#20849;&#36717;&#32467;&#26500;&#12290;&#36825;&#21487;&#33021;&#23545;&#21487;&#34892;&#30340;&#20808;&#39564;&#20998;&#24067;&#26063;&#21644;&#21464;&#20998;&#36817;&#20284;&#26063;&#26045;&#21152;&#19981;&#24517;&#35201;&#30340;&#38480;&#21046;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#35745;&#31639;&#26694;&#26550;&#65292;&#20351;&#29992;Wasserstein&#26799;&#24230;&#27969;&#65288;WGF&#65289;&#23454;&#29616;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#22343;&#22330;&#21464;&#20998;&#25512;&#29702;&#65292;&#26080;&#35770;&#26159;&#21542;&#23384;&#22312;&#28508;&#21464;&#37327;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#25552;&#20986;&#26041;&#27861;&#30340;&#31639;&#27861;&#25910;&#25947;&#24615;&#65292;&#25552;&#20379;&#20102;&#25910;&#32553;&#22240;&#23376;&#30340;&#26174;&#24335;&#34920;&#36798;&#24335;&#12290;&#36890;&#36807;&#21033;&#29992;&#26102;&#38388;&#31163;&#25955;&#21270;&#30340;WGF&#30340;&#19981;&#21160;&#28857;&#26041;&#31243;&#65292;&#25105;&#20204;&#36824;&#23558;&#29616;&#26377;&#30340;&#20851;&#20110;MF&#21464;&#20998;&#21518;&#39564;&#38598;&#20013;&#24615;&#30340;&#32467;&#26524;&#20174;&#22810;&#39033;&#24335;&#25910;&#32553;&#24378;&#21270;&#21040;&#25351;&#25968;&#25910;&#32553;&#12290;&#22312;&#35745;&#31639;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26080;&#32422;&#26463;&#20989;&#25968;&#36924;&#36817;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Variational inference, such as the mean-field (MF) approximation, requires certain conjugacy structures for efficient computation. These can impose unnecessary restrictions on the viable prior distribution family and further constraints on the variational approximation family. In this work, we introduce a general computational framework to implement MF variational inference for Bayesian models, with or without latent variables, using the Wasserstein gradient flow (WGF), a modern mathematical technique for realizing a gradient flow over the space of probability measures. Theoretically, we analyze the algorithmic convergence of the proposed approaches, providing an explicit expression for the contraction factor. We also strengthen existing results on MF variational posterior concentration from a polynomial to an exponential contraction, by utilizing the fixed point equation of the time-discretized WGF. Computationally, we propose a new constraint-free function approximation method using 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#25913;&#36827;&#29256;&#26412;&#30340;&#38543;&#26426;&#26368;&#23567;&#20108;&#20056;&#20540;&#36845;&#20195;&#65288;RLSVI&#65289;&#31639;&#27861;&#65292;&#36890;&#36807;&#23545;&#34892;&#21160;&#20540;&#20989;&#25968;&#30340;&#26368;&#23567;&#20108;&#20056;&#36924;&#36817;&#36827;&#34892;&#25200;&#21160;&#65292;&#35825;&#23548;&#20986;&#20102;&#25506;&#32034;&#36807;&#31243;&#12290;&#22312;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20855;&#26377;&#20302;&#31209;&#36716;&#31227;&#21160;&#24577;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;RLSVI&#30340;&#39057;&#29575;&#21518;&#24724;&#19978;&#30028;&#20026;$\widetilde O(d^2 H^2 \sqrt{T})$&#12290;&#36825;&#26159;&#23545;&#20110;&#24102;&#26377;&#20989;&#25968;&#36924;&#36817;&#30340;&#38543;&#26426;&#25506;&#32034;&#30340;&#39318;&#20010;&#39057;&#29575;&#21518;&#24724;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/1911.00567</link><description>&lt;p&gt;
&#38543;&#26426;&#26368;&#23567;&#20108;&#20056;&#20540;&#36845;&#20195;&#30340;&#39057;&#29575;&#21518;&#24724;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Frequentist Regret Bounds for Randomized Least-Squares Value Iteration. (arXiv:1911.00567v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1911.00567
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#25913;&#36827;&#29256;&#26412;&#30340;&#38543;&#26426;&#26368;&#23567;&#20108;&#20056;&#20540;&#36845;&#20195;&#65288;RLSVI&#65289;&#31639;&#27861;&#65292;&#36890;&#36807;&#23545;&#34892;&#21160;&#20540;&#20989;&#25968;&#30340;&#26368;&#23567;&#20108;&#20056;&#36924;&#36817;&#36827;&#34892;&#25200;&#21160;&#65292;&#35825;&#23548;&#20986;&#20102;&#25506;&#32034;&#36807;&#31243;&#12290;&#22312;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20855;&#26377;&#20302;&#31209;&#36716;&#31227;&#21160;&#24577;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;RLSVI&#30340;&#39057;&#29575;&#21518;&#24724;&#19978;&#30028;&#20026;$\widetilde O(d^2 H^2 \sqrt{T})$&#12290;&#36825;&#26159;&#23545;&#20110;&#24102;&#26377;&#20989;&#25968;&#36924;&#36817;&#30340;&#38543;&#26426;&#25506;&#32034;&#30340;&#39318;&#20010;&#39057;&#29575;&#21518;&#24724;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#26377;&#38480;&#26102;&#38388;&#22495;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#25506;&#32034;-&#21033;&#29992;&#22256;&#22659;&#12290;&#24403;&#29366;&#24577;&#31354;&#38388;&#24456;&#22823;&#25110;&#36830;&#32493;&#26102;&#65292;&#20256;&#32479;&#30340;&#34920;&#26684;&#26041;&#27861;&#19981;&#21487;&#34892;&#65292;&#24517;&#39035;&#37319;&#29992;&#20989;&#25968;&#36924;&#36817;&#30340;&#24418;&#24335;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#20048;&#35266;&#21021;&#22987;&#21270;&#30340;&#25913;&#36827;&#29256;&#26412;&#30340;&#38543;&#26426;&#26368;&#23567;&#20108;&#20056;&#20540;&#36845;&#20195;&#65288;RLSVI&#65289;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#26159;&#19968;&#31181;&#26080;&#27169;&#22411;&#31639;&#27861;&#65292;&#20854;&#20013;&#25506;&#32034;&#26159;&#36890;&#36807;&#25200;&#21160;&#34892;&#21160;&#20540;&#20989;&#25968;&#30340;&#26368;&#23567;&#20108;&#20056;&#36924;&#36817;&#26469;&#35825;&#23548;&#30340;&#12290;&#22312;&#20551;&#35774;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20855;&#26377;&#20302;&#31209;&#36716;&#31227;&#21160;&#24577;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;RLSVI&#30340;&#39057;&#29575;&#21518;&#24724;&#23558;&#19978;&#30028;&#20026;$\widetilde O(d^2 H^2 \sqrt{T})$&#65292;&#20854;&#20013;$ d $&#26159;&#29305;&#24449;&#32500;&#24230;&#65292;$ H $&#26159;&#26102;&#38388;&#38480;&#21046;&#65292;$ T $&#26159;&#24635;&#27493;&#25968;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#23545;&#20110;&#24102;&#26377;&#20989;&#25968;&#36924;&#36817;&#30340;&#38543;&#26426;&#25506;&#32034;&#30340;&#31532;&#19968;&#20010;&#39057;&#29575;&#21518;&#24724;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the exploration-exploitation dilemma in finite-horizon reinforcement learning (RL). When the state space is large or continuous, traditional tabular approaches are unfeasible and some form of function approximation is mandatory. In this paper, we introduce an optimistically-initialized variant of the popular randomized least-squares value iteration (RLSVI), a model-free algorithm where exploration is induced by perturbing the least-squares approximation of the action-value function. Under the assumption that the Markov decision process has low-rank transition dynamics, we prove that the frequentist regret of RLSVI is upper-bounded by $\widetilde O(d^2 H^2 \sqrt{T})$ where $ d $ are the feature dimension, $ H $ is the horizon, and $ T $ is the total number of steps. To the best of our knowledge, this is the first frequentist regret analysis for randomized exploration with function approximation.
&lt;/p&gt;</description></item></channel></rss>