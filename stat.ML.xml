<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22522;&#20110;&#20302;&#31209;&#21152;&#23545;&#35282;&#32447;&#21442;&#25968;&#21270;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#21051;&#30011;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#35823;&#24046;&#30340;&#33258;&#30456;&#20851;&#24615;&#65292;&#24182;&#20855;&#26377;&#22797;&#26434;&#24230;&#20302;&#12289;&#26657;&#20934;&#39044;&#27979;&#20934;&#30830;&#24615;&#39640;&#31561;&#20248;&#28857;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01000</link><description>&lt;p&gt;
&#22810;&#20803;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#19982;&#30456;&#20851;&#35823;&#24046;
&lt;/p&gt;
&lt;p&gt;
Multivariate Probabilistic Time Series Forecasting with Correlated Errors
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01000
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22522;&#20110;&#20302;&#31209;&#21152;&#23545;&#35282;&#32447;&#21442;&#25968;&#21270;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#21051;&#30011;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#35823;&#24046;&#30340;&#33258;&#30456;&#20851;&#24615;&#65292;&#24182;&#20855;&#26377;&#22797;&#26434;&#24230;&#20302;&#12289;&#26657;&#20934;&#39044;&#27979;&#20934;&#30830;&#24615;&#39640;&#31561;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24314;&#27169;&#35823;&#24046;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#19982;&#27169;&#22411;&#33021;&#22815;&#20934;&#30830;&#37327;&#21270;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#23494;&#20999;&#30456;&#20851;&#12290;&#26368;&#36817;&#30340;&#22810;&#20803;&#27169;&#22411;&#22312;&#32771;&#34385;&#35823;&#24046;&#20043;&#38388;&#30340;&#21516;&#26102;&#30456;&#20851;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#28982;&#32780;&#65292;&#23545;&#20110;&#32479;&#35745;&#31616;&#21270;&#30340;&#30446;&#30340;&#65292;&#23545;&#36825;&#20123;&#35823;&#24046;&#30340;&#24120;&#35265;&#20551;&#35774;&#26159;&#23427;&#20204;&#22312;&#26102;&#38388;&#19978;&#26159;&#29420;&#31435;&#30340;&#12290;&#28982;&#32780;&#65292;&#23454;&#38469;&#35266;&#27979;&#24448;&#24448;&#20559;&#31163;&#20102;&#36825;&#20010;&#20551;&#35774;&#65292;&#22240;&#20026;&#35823;&#24046;&#36890;&#24120;&#30001;&#20110;&#21508;&#31181;&#22240;&#32032;&#65288;&#22914;&#25490;&#38500;&#26102;&#38388;&#30456;&#20851;&#30340;&#21327;&#21464;&#37327;&#65289;&#32780;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#33258;&#30456;&#20851;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20302;&#31209;&#21152;&#23545;&#35282;&#32447;&#21442;&#25968;&#21270;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#21051;&#30011;&#35823;&#24046;&#30340;&#33258;&#30456;&#20851;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20855;&#26377;&#20960;&#20010;&#21487;&#21462;&#30340;&#29305;&#24615;&#65306;&#22797;&#26434;&#24230;&#19981;&#38543;&#26102;&#38388;&#24207;&#21015;&#25968;&#30446;&#22686;&#21152;&#65292;&#24471;&#21040;&#30340;&#21327;&#26041;&#24046;&#21487;&#20197;&#29992;&#20110;&#26657;&#20934;&#39044;&#27979;&#65292;&#19988;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modeling the correlations among errors is closely associated with how accurately the model can quantify predictive uncertainty in probabilistic time series forecasting. Recent multivariate models have made significant progress in accounting for contemporaneous correlations among errors, while a common assumption on these errors is that they are temporally independent for the sake of statistical simplicity. However, real-world observations often deviate from this assumption, since errors usually exhibit substantial autocorrelation due to various factors such as the exclusion of temporally correlated covariates. In this work, we propose an efficient method, based on a low-rank-plus-diagonal parameterization of the covariance matrix, which can effectively characterize the autocorrelation of errors. The proposed method possesses several desirable properties: the complexity does not scale with the number of time series, the resulting covariance can be used for calibrating predictions, and i
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#21033;&#29992;&#26680;&#24515;&#23376;&#38598;&#36873;&#25321;&#36827;&#34892;&#25968;&#25454;&#37325;&#26032;&#21152;&#26435;&#30340;&#26041;&#27861;&#65292;&#26377;&#25928;&#20248;&#21270;&#20102;&#35745;&#31639;&#26102;&#38388;&#21644;&#27169;&#22411;&#24615;&#33021;&#65292;&#31361;&#26174;&#20854;&#20316;&#20026;&#27169;&#22411;&#35757;&#32451;&#30340;&#21487;&#25193;&#23637;&#21644;&#31934;&#30830;&#35299;&#20915;&#26041;&#26696;&#30340;&#28508;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.12166</link><description>&lt;p&gt;
&#23569;&#25968;&#20010;&#20307;&#30340;&#21147;&#37327;&#65306;&#21033;&#29992;&#26680;&#24515;&#23376;&#38598;&#36873;&#25321;&#21152;&#36895;&#21644;&#20248;&#21270;&#25968;&#25454;&#37325;&#26032;&#21152;&#26435;
&lt;/p&gt;
&lt;p&gt;
The Power of Few: Accelerating and Enhancing Data Reweighting with Coreset Selection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12166
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#21033;&#29992;&#26680;&#24515;&#23376;&#38598;&#36873;&#25321;&#36827;&#34892;&#25968;&#25454;&#37325;&#26032;&#21152;&#26435;&#30340;&#26041;&#27861;&#65292;&#26377;&#25928;&#20248;&#21270;&#20102;&#35745;&#31639;&#26102;&#38388;&#21644;&#27169;&#22411;&#24615;&#33021;&#65292;&#31361;&#26174;&#20854;&#20316;&#20026;&#27169;&#22411;&#35757;&#32451;&#30340;&#21487;&#25193;&#23637;&#21644;&#31934;&#30830;&#35299;&#20915;&#26041;&#26696;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#19981;&#26029;&#21457;&#23637;&#65292;&#36235;&#21183;&#26159;&#25910;&#38598;&#26356;&#22823;&#30340;&#25968;&#25454;&#38598;&#24182;&#35757;&#32451;&#35268;&#27169;&#36234;&#26469;&#36234;&#22823;&#30340;&#27169;&#22411;&#12290;&#34429;&#28982;&#36825;&#25552;&#39640;&#20102;&#20934;&#30830;&#24615;&#65292;&#20294;&#20063;&#23558;&#35745;&#31639;&#25104;&#26412;&#25552;&#39640;&#21040;&#19981;&#21487;&#25345;&#32493;&#30340;&#27700;&#24179;&#12290;&#38024;&#23545;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#26088;&#22312;&#22312;&#35745;&#31639;&#25928;&#29575;&#21644;&#27169;&#22411;&#20934;&#30830;&#24615;&#20043;&#38388;&#21462;&#24471;&#24494;&#22937;&#30340;&#24179;&#34913;&#65292;&#36825;&#26159;&#35813;&#39046;&#22495;&#20013;&#19968;&#30452;&#23384;&#22312;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21033;&#29992;&#26680;&#24515;&#23376;&#38598;&#36873;&#25321;&#36827;&#34892;&#37325;&#26032;&#21152;&#26435;&#30340;&#26032;&#26041;&#27861;&#65292;&#26377;&#25928;&#20248;&#21270;&#20102;&#35745;&#31639;&#26102;&#38388;&#21644;&#27169;&#22411;&#24615;&#33021;&#12290;&#36890;&#36807;&#19987;&#27880;&#20110; strategically selected coreset&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#20010;&#31283;&#20581;&#30340;&#34920;&#31034;&#65292;&#22240;&#20026;&#23427;&#26377;&#25928;&#22320;&#26368;&#23567;&#21270;&#20102;&#24322;&#24120;&#20540;&#30340;&#24433;&#21709;&#12290;&#28982;&#21518;&#65292;&#37325;&#26032;&#26657;&#20934;&#30340;&#26435;&#37325;&#34987;&#26144;&#23556;&#22238;&#24182;&#20256;&#25773;&#21040;&#25972;&#20010;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#35777;&#23454;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#31361;&#26174;&#20102;&#23427;&#20316;&#20026;&#27169;&#22411;&#35757;&#32451;&#30340;&#21487;&#25193;&#23637;&#21644;&#31934;&#30830;&#35299;&#20915;&#26041;&#26696;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12166v1 Announce Type: new  Abstract: As machine learning tasks continue to evolve, the trend has been to gather larger datasets and train increasingly larger models. While this has led to advancements in accuracy, it has also escalated computational costs to unsustainable levels. Addressing this, our work aims to strike a delicate balance between computational efficiency and model accuracy, a persisting challenge in the field. We introduce a novel method that employs core subset selection for reweighting, effectively optimizing both computational time and model performance. By focusing on a strategically selected coreset, our approach offers a robust representation, as it efficiently minimizes the influence of outliers. The re-calibrated weights are then mapped back to and propagated across the entire dataset. Our experimental results substantiate the effectiveness of this approach, underscoring its potential as a scalable and precise solution for model training.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#20855;&#26377;&#39640;&#26031;&#22122;&#22768;&#39537;&#21160;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#30340;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#21464;&#20998;&#31639;&#27861;&#21644;&#32467;&#26500;&#21270;&#36924;&#36817;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#35780;&#20272;ELBO&#21644;&#33719;&#21462;&#20302;&#26041;&#24046;&#30340;&#38543;&#26426;&#26799;&#24230;&#20272;&#35745;&#65292;&#36890;&#36807;&#21033;&#29992;&#20302;&#31209;&#33945;&#29305;&#21345;&#32599;&#36924;&#36817;&#21644;&#25512;&#26029;&#32593;&#32476;&#30340;&#31934;&#24230;&#30697;&#38453;&#26356;&#26032;&#65292;&#23558;&#36817;&#20284;&#24179;&#28369;&#38382;&#39064;&#36716;&#21270;&#20026;&#36817;&#20284;&#28388;&#27874;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.01371</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#21464;&#20998;&#39640;&#26031;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Large-scale variational Gaussian state-space models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01371
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#20855;&#26377;&#39640;&#26031;&#22122;&#22768;&#39537;&#21160;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#30340;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#21464;&#20998;&#31639;&#27861;&#21644;&#32467;&#26500;&#21270;&#36924;&#36817;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#35780;&#20272;ELBO&#21644;&#33719;&#21462;&#20302;&#26041;&#24046;&#30340;&#38543;&#26426;&#26799;&#24230;&#20272;&#35745;&#65292;&#36890;&#36807;&#21033;&#29992;&#20302;&#31209;&#33945;&#29305;&#21345;&#32599;&#36924;&#36817;&#21644;&#25512;&#26029;&#32593;&#32476;&#30340;&#31934;&#24230;&#30697;&#38453;&#26356;&#26032;&#65292;&#23558;&#36817;&#20284;&#24179;&#28369;&#38382;&#39064;&#36716;&#21270;&#20026;&#36817;&#20284;&#28388;&#27874;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#23884;&#22871;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#21644;&#32467;&#26500;&#21270;&#21464;&#20998;&#36924;&#36817;&#26041;&#27861;&#65292;&#20854;&#20013;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#30001;&#39640;&#26031;&#22122;&#22768;&#39537;&#21160;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#20801;&#35768;&#22312;&#27809;&#26377;&#37319;&#29992;&#23545;&#35282;&#39640;&#26031;&#36924;&#36817;&#30340;&#24773;&#20917;&#19979;&#26377;&#25928;&#22320;&#35780;&#20272;ELBO&#21644;&#20302;&#26041;&#24046;&#38543;&#26426;&#26799;&#24230;&#20272;&#35745;&#65292;&#36890;&#36807;&#21033;&#29992;&#65288;i&#65289;&#36890;&#36807;&#21160;&#21147;&#23398;&#23545;&#38544;&#29366;&#24577;&#36827;&#34892;&#36793;&#32536;&#21270;&#30340;&#33945;&#29305;&#21345;&#32599;&#36924;&#36817;&#30340;&#20302;&#31209;&#32467;&#26500;&#65292;&#65288;ii&#65289;&#19968;&#20010;&#25512;&#26029;&#32593;&#32476;&#65292;&#35813;&#32593;&#32476;&#36890;&#36807;&#20302;&#31209;&#31934;&#24230;&#30697;&#38453;&#26356;&#26032;&#26469;&#36817;&#20284;&#26356;&#26032;&#27493;&#39588;&#65292;&#65288;iii&#65289;&#23558;&#24403;&#21069;&#21644;&#26410;&#26469;&#35266;&#27979;&#32534;&#30721;&#20026;&#20266;&#35266;&#27979;--&#23558;&#36817;&#20284;&#24179;&#28369;&#38382;&#39064;&#36716;&#25442;&#20026;&#65288;&#26356;&#31616;&#21333;&#30340;&#65289;&#36817;&#20284;&#28388;&#27874;&#38382;&#39064;&#12290;&#25972;&#20307;&#32780;&#35328;&#65292;&#24517;&#35201;&#30340;&#32479;&#35745;&#20449;&#24687;&#21644;ELBO&#21487;&#20197;&#22312;$O&#65288;TL&#65288;Sr+S^2+r^2&#65289;&#65289;$&#26102;&#38388;&#20869;&#35745;&#31639;&#65292;&#20854;&#20013;$T$&#26159;&#31995;&#21015;&#38271;&#24230;&#65292;$L$&#26159;&#29366;&#24577;&#31354;&#38388;&#32500;&#25968;&#65292;$S$&#26159;&#29992;&#20110;&#36924;&#36817;&#30340;&#26679;&#26412;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01371v1 Announce Type: cross  Abstract: We introduce an amortized variational inference algorithm and structured variational approximation for state-space models with nonlinear dynamics driven by Gaussian noise. Importantly, the proposed framework allows for efficient evaluation of the ELBO and low-variance stochastic gradient estimates without resorting to diagonal Gaussian approximations by exploiting (i) the low-rank structure of Monte-Carlo approximations to marginalize the latent state through the dynamics (ii) an inference network that approximates the update step with low-rank precision matrix updates (iii) encoding current and future observations into pseudo observations -- transforming the approximate smoothing problem into an (easier) approximate filtering problem. Overall, the necessary statistics and ELBO can be computed in $O(TL(Sr + S^2 + r^2))$ time where $T$ is the series length, $L$ is the state-space dimensionality, $S$ are the number of samples used to app
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#31163;&#25955;&#26102;&#38388;&#25193;&#25955;&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#65292;&#25913;&#36827;&#20102;&#23545;&#26356;&#22823;&#31867;&#30340;&#20998;&#24067;&#30340;&#25910;&#25947;&#20445;&#35777;&#65292;&#24182;&#25552;&#39640;&#20102;&#20855;&#26377;&#26377;&#30028;&#25903;&#25745;&#30340;&#20998;&#24067;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.13901</link><description>&lt;p&gt;
&#31163;&#25955;&#26102;&#38388;&#25193;&#25955;&#27169;&#22411;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#65306;&#26032;&#26041;&#27861;&#21644;&#25913;&#36827;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Non-asymptotic Convergence of Discrete-time Diffusion Models: New Approach and Improved Rate
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13901
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#31163;&#25955;&#26102;&#38388;&#25193;&#25955;&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#65292;&#25913;&#36827;&#20102;&#23545;&#26356;&#22823;&#31867;&#30340;&#20998;&#24067;&#30340;&#25910;&#25947;&#20445;&#35777;&#65292;&#24182;&#25552;&#39640;&#20102;&#20855;&#26377;&#26377;&#30028;&#25903;&#25745;&#30340;&#20998;&#24067;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#19968;&#31181;&#24378;&#22823;&#30340;&#29983;&#25104;&#25216;&#26415;&#20986;&#29616;&#65292;&#23558;&#22122;&#22768;&#36716;&#21270;&#20026;&#25968;&#25454;&#12290;&#29702;&#35770;&#19978;&#20027;&#35201;&#30740;&#31350;&#20102;&#36830;&#32493;&#26102;&#38388;&#25193;&#25955;&#27169;&#22411;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;&#65292;&#24182;&#19988;&#20165;&#22312;&#25991;&#29486;&#20013;&#23545;&#20855;&#26377;&#26377;&#30028;&#25903;&#25745;&#30340;&#20998;&#24067;&#30340;&#31163;&#25955;&#26102;&#38388;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#20102;&#33719;&#24471;&#12290;&#26412;&#25991;&#20026;&#26356;&#22823;&#31867;&#30340;&#20998;&#24067;&#24314;&#31435;&#20102;&#31163;&#25955;&#26102;&#38388;&#25193;&#25955;&#27169;&#22411;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;&#65292;&#24182;&#36827;&#19968;&#27493;&#25913;&#36827;&#20102;&#23545;&#20855;&#26377;&#26377;&#30028;&#25903;&#25745;&#30340;&#20998;&#24067;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;&#29305;&#21035;&#22320;&#65292;&#39318;&#20808;&#20026;&#20855;&#26377;&#26377;&#38480;&#20108;&#38454;&#30697;&#30340;&#24179;&#28369;&#21644;&#19968;&#33324;&#65288;&#21487;&#33021;&#38750;&#20809;&#28369;&#65289;&#20998;&#24067;&#24314;&#31435;&#20102;&#25910;&#25947;&#36895;&#29575;&#12290;&#28982;&#21518;&#23558;&#32467;&#26524;&#19987;&#38376;&#24212;&#29992;&#20110;&#19968;&#20123;&#26377;&#26126;&#30830;&#21442;&#25968;&#20381;&#36182;&#20851;&#31995;&#30340;&#26377;&#36259;&#20998;&#24067;&#31867;&#21035;&#65292;&#21253;&#25324;&#20855;&#26377;Lipschitz&#20998;&#25968;&#12289;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#21644;&#20855;&#26377;&#26377;&#30028;&#25903;&#25745;&#30340;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13901v1 Announce Type: new  Abstract: The denoising diffusion model emerges recently as a powerful generative technique that converts noise into data. Theoretical convergence guarantee has been mainly studied for continuous-time diffusion models, and has been obtained for discrete-time diffusion models only for distributions with bounded support in the literature. In this paper, we establish the convergence guarantee for substantially larger classes of distributions under discrete-time diffusion models and further improve the convergence rate for distributions with bounded support. In particular, we first establish the convergence rates for both smooth and general (possibly non-smooth) distributions having finite second moment. We then specialize our results to a number of interesting classes of distributions with explicit parameter dependencies, including distributions with Lipschitz scores, Gaussian mixture distributions, and distributions with bounded support. We further 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#25552;&#31034;&#23398;&#20064;&#20013;&#32771;&#34385;&#26377;&#38480;&#39044;&#31639;&#32422;&#26463;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24314;&#31435;&#25552;&#31034;&#23398;&#20064;&#21644;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;TRIPLE&#65292;&#36890;&#36807;&#21033;&#29992;&#32858;&#31867;&#21644;&#23884;&#20837;&#24605;&#24819;&#23454;&#29616;&#20102;&#20004;&#20010;&#22686;&#24378;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.09723</link><description>&lt;p&gt;
&#26377;&#38480;&#39044;&#31639;&#19979;&#30340;&#36805;&#36895;&#23398;&#20064;&#26368;&#20339;&#33218;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Best Arm Identification for Prompt Learning under a Limited Budget
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09723
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#25552;&#31034;&#23398;&#20064;&#20013;&#32771;&#34385;&#26377;&#38480;&#39044;&#31639;&#32422;&#26463;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24314;&#31435;&#25552;&#31034;&#23398;&#20064;&#21644;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;TRIPLE&#65292;&#36890;&#36807;&#21033;&#29992;&#32858;&#31867;&#21644;&#23884;&#20837;&#24605;&#24819;&#23454;&#29616;&#20102;&#20004;&#20010;&#22686;&#24378;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#26174;&#33879;&#25351;&#20196;&#36319;&#38543;&#33021;&#21147;&#24341;&#21457;&#20102;&#23545;&#33258;&#21160;&#23398;&#20064;&#21512;&#36866;&#25552;&#31034;&#30340;&#20852;&#36259;&#12290;&#28982;&#32780;&#65292;&#34429;&#28982;&#25552;&#20986;&#20102;&#35768;&#22810;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#20294;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#20135;&#29983;&#30340;&#25104;&#26412;&#65288;&#20363;&#22914;&#35775;&#38382;LLM&#21644;&#35780;&#20272;&#21709;&#24212;&#65289;&#23578;&#26410;&#24471;&#21040;&#32771;&#34385;&#12290;&#20026;&#20811;&#26381;&#36825;&#20010;&#38480;&#21046;&#65292;&#26412;&#24037;&#20316;&#22312;&#25552;&#31034;&#23398;&#20064;&#20013;&#26126;&#30830;&#24341;&#20837;&#20102;&#26377;&#38480;&#39044;&#31639;&#32422;&#26463;&#12290;&#20026;&#20102;&#24320;&#21457;&#26377;&#21407;&#21017;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#26412;&#30740;&#31350;&#22312;&#25552;&#31034;&#23398;&#20064;&#21644;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#65288;BAI-FB&#65289;&#20043;&#38388;&#24314;&#31435;&#20102;&#19968;&#31181;&#26032;&#30340;&#32852;&#31995;&#12290;&#22522;&#20110;&#36825;&#31181;&#32852;&#31995;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;TRIPLE&#65288;&#29992;&#20110;&#25552;&#31034;&#23398;&#20064;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#65289;&#65292;&#20197;&#31995;&#32479;&#22320;&#21033;&#29992;BAI-FB&#22312;&#25552;&#31034;&#23398;&#20064;&#20013;&#30340;&#21147;&#37327;&#12290;&#25552;&#31034;&#23398;&#20064;&#30340;&#29420;&#29305;&#29305;&#28857;&#36827;&#19968;&#27493;&#36890;&#36807;&#21033;&#29992;&#32858;&#31867;&#21644;&#23884;&#20837;&#24605;&#24819;&#25552;&#20986;&#20102;TRIPLE&#30340;&#20004;&#20010;&#22522;&#20110;&#23884;&#20837;&#30340;&#22686;&#24378;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09723v1 Announce Type: cross  Abstract: The remarkable instruction-following capability of large language models (LLMs) has sparked a growing interest in automatically learning suitable prompts. However, while many effective methods have been proposed, the cost incurred during the learning process (e.g., accessing LLM and evaluating the responses) has not been considered. To overcome this limitation, this work explicitly incorporates a finite budget constraint into prompt learning. Towards developing principled solutions, a novel connection is established between prompt learning and fixed-budget best arm identification (BAI-FB) in multi-armed bandits (MAB). Based on this connection, a general framework TRIPLE (besT aRm Identification for Prompt LEarning) is proposed to harness the power of BAI-FB in prompt learning systematically. Unique characteristics of prompt learning further lead to two embedding-based enhancements of TRIPLE by exploiting the ideas of clustering and fun
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#25968;&#23383;&#24179;&#21488;&#19978;&#36827;&#34892;&#36328;&#26102;&#39044;&#27979;&#21327;&#35843;&#30340;&#38750;&#32447;&#24615;&#20998;&#23618;&#39044;&#27979;&#21327;&#35843;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#30452;&#25509;&#19988;&#33258;&#21160;&#21270;&#22320;&#29983;&#25104;&#36328;&#26102;&#39044;&#27979;&#21327;&#35843;&#30340;&#39044;&#27979;&#65292;&#36890;&#36807;&#23545;&#26469;&#33258;&#25353;&#38656;&#20132;&#20184;&#24179;&#21488;&#30340;&#22823;&#35268;&#27169;&#27969;&#24335;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#35777;&#27979;&#35797;&#12290;</title><link>https://arxiv.org/abs/2402.09033</link><description>&lt;p&gt;
&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#22312;&#25968;&#23383;&#24179;&#21488;&#19978;&#36827;&#34892;&#36328;&#26102;&#39044;&#27979;&#21327;&#35843;
&lt;/p&gt;
&lt;p&gt;
Cross-Temporal Forecast Reconciliation at Digital Platforms with Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09033
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#25968;&#23383;&#24179;&#21488;&#19978;&#36827;&#34892;&#36328;&#26102;&#39044;&#27979;&#21327;&#35843;&#30340;&#38750;&#32447;&#24615;&#20998;&#23618;&#39044;&#27979;&#21327;&#35843;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#30452;&#25509;&#19988;&#33258;&#21160;&#21270;&#22320;&#29983;&#25104;&#36328;&#26102;&#39044;&#27979;&#21327;&#35843;&#30340;&#39044;&#27979;&#65292;&#36890;&#36807;&#23545;&#26469;&#33258;&#25353;&#38656;&#20132;&#20184;&#24179;&#21488;&#30340;&#22823;&#35268;&#27169;&#27969;&#24335;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#35777;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24179;&#21488;&#19994;&#21153;&#22312;&#25968;&#23383;&#26680;&#24515;&#19978;&#36816;&#20316;&#65292;&#20854;&#20915;&#31574;&#38656;&#35201;&#19981;&#21516;&#23618;&#27425;&#65288;&#20363;&#22914;&#22320;&#29702;&#21306;&#22495;&#65289;&#21644;&#26102;&#38388;&#32858;&#21512;&#65288;&#20363;&#22914;&#20998;&#38047;&#21040;&#22825;&#65289;&#30340;&#39640;&#32500;&#20934;&#30830;&#39044;&#27979;&#27969;&#12290;&#20026;&#20102;&#30830;&#20445;&#19981;&#21516;&#35268;&#21010;&#21333;&#20803;&#65288;&#22914;&#23450;&#20215;&#12289;&#20135;&#21697;&#12289;&#25511;&#21046;&#21644;&#25112;&#30053;&#65289;&#20043;&#38388;&#30340;&#20915;&#31574;&#19968;&#33268;&#65292;&#20063;&#38656;&#35201;&#22312;&#23618;&#27425;&#32467;&#26500;&#30340;&#25152;&#26377;&#32423;&#21035;&#19978;&#36827;&#34892;&#21327;&#35843;&#39044;&#27979;&#12290;&#37492;&#20110;&#24179;&#21488;&#25968;&#25454;&#27969;&#20855;&#26377;&#22797;&#26434;&#30340;&#29305;&#24449;&#21644;&#30456;&#20114;&#20381;&#36182;&#20851;&#31995;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#38750;&#32447;&#24615;&#20998;&#23618;&#39044;&#27979;&#21327;&#35843;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#27969;&#34892;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#30452;&#25509;&#21644;&#33258;&#21160;&#21270;&#30340;&#26041;&#24335;&#29983;&#25104;&#36328;&#26102;&#39044;&#27979;&#21327;&#35843;&#30340;&#39044;&#27979;&#12290;&#35813;&#26041;&#27861;&#36275;&#22815;&#24555;&#65292;&#21487;&#20197;&#28385;&#36275;&#24179;&#21488;&#25152;&#38656;&#30340;&#22522;&#20110;&#39044;&#27979;&#30340;&#39640;&#39057;&#20915;&#31574;&#12290;&#25105;&#20204;&#20351;&#29992;&#26469;&#33258;&#39046;&#20808;&#30340;&#25353;&#38656;&#20132;&#20184;&#24179;&#21488;&#30340;&#29420;&#29305;&#22823;&#35268;&#27169;&#27969;&#24335;&#25968;&#25454;&#38598;&#23545;&#25105;&#20204;&#30340;&#26694;&#26550;&#36827;&#34892;&#20102;&#23454;&#35777;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09033v1 Announce Type: new Abstract: Platform businesses operate on a digital core and their decision making requires high-dimensional accurate forecast streams at different levels of cross-sectional (e.g., geographical regions) and temporal aggregation (e.g., minutes to days). It also necessitates coherent forecasts across all levels of the hierarchy to ensure aligned decision making across different planning units such as pricing, product, controlling and strategy. Given that platform data streams feature complex characteristics and interdependencies, we introduce a non-linear hierarchical forecast reconciliation method that produces cross-temporal reconciled forecasts in a direct and automated way through the use of popular machine learning methods. The method is sufficiently fast to allow forecast-based high-frequency decision making that platforms require. We empirically test our framework on a unique, large-scale streaming dataset from a leading on-demand delivery plat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#36895;&#26799;&#24230;&#26041;&#27861;&#26469;&#35299;&#20915;&#20855;&#26377;&#20984;&#19979;&#23618;&#38382;&#39064;&#30340;&#31616;&#21333;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#23616;&#37096;&#36924;&#36817;&#19979;&#23618;&#38382;&#39064;&#30340;&#35299;&#38598;&#21644;&#21152;&#36895;&#26799;&#24230;&#26356;&#26032;&#26041;&#27861;&#65292;&#22312;&#26377;&#38480;&#27425;&#36845;&#20195;&#20869;&#25214;&#21040;&#19968;&#20010;&#20855;&#26377;&#19968;&#23450;&#31934;&#24230;&#30340;&#26368;&#20248;&#35299;&#12290;</title><link>https://arxiv.org/abs/2402.08097</link><description>&lt;p&gt;
&#19968;&#31181;&#21152;&#36895;&#26799;&#24230;&#26041;&#27861;&#27714;&#35299;&#20855;&#26377;&#20984;&#19979;&#23618;&#38382;&#39064;&#30340;&#31616;&#21333;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
An Accelerated Gradient Method for Simple Bilevel Optimization with Convex Lower-level Problem
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08097
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#36895;&#26799;&#24230;&#26041;&#27861;&#26469;&#35299;&#20915;&#20855;&#26377;&#20984;&#19979;&#23618;&#38382;&#39064;&#30340;&#31616;&#21333;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#23616;&#37096;&#36924;&#36817;&#19979;&#23618;&#38382;&#39064;&#30340;&#35299;&#38598;&#21644;&#21152;&#36895;&#26799;&#24230;&#26356;&#26032;&#26041;&#27861;&#65292;&#22312;&#26377;&#38480;&#27425;&#36845;&#20195;&#20869;&#25214;&#21040;&#19968;&#20010;&#20855;&#26377;&#19968;&#23450;&#31934;&#24230;&#30340;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#31616;&#21333;&#30340;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#21363;&#22312;&#21478;&#19968;&#20010;&#20984;&#20809;&#28369;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#30340;&#26368;&#20248;&#35299;&#38598;&#19978;&#26368;&#23567;&#21270;&#19968;&#20010;&#20984;&#20809;&#28369;&#30446;&#26631;&#20989;&#25968;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21452;&#23618;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#20999;&#24179;&#38754;&#26041;&#27861;&#23616;&#37096;&#36924;&#36817;&#19979;&#23618;&#38382;&#39064;&#30340;&#35299;&#38598;&#65292;&#24182;&#37319;&#29992;&#21152;&#36895;&#26799;&#24230;&#26356;&#26032;&#26041;&#27861;&#38477;&#20302;&#36817;&#20284;&#35299;&#38598;&#19978;&#30340;&#19978;&#23618;&#30446;&#26631;&#20989;&#25968;&#12290;&#25105;&#20204;&#36890;&#36807;&#23376;&#26368;&#20248;&#35299;&#21644;&#19981;&#21487;&#34892;&#35823;&#24046;&#24230;&#37327;&#25105;&#20204;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#20004;&#20010;&#35823;&#24046;&#26631;&#20934;&#30340;&#38750;&#28176;&#36827;&#25910;&#25947;&#24615;&#20445;&#35777;&#12290;&#29305;&#21035;&#22320;&#65292;&#24403;&#21487;&#34892;&#38598;&#26159;&#32039;&#33268;&#30340;&#26102;&#20505;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#26368;&#22810;&#38656;&#35201;$\mathcal{O}(\max\{1/\sqrt{\epsilon_{f}}, 1/\epsilon_g\})$&#27425;&#36845;&#20195;&#25165;&#33021;&#25214;&#21040;&#19968;&#20010;$\epsilon_f$-&#23376;&#26368;&#20248;&#19988;$\epsilon_g$-&#19981;&#21487;&#34892;&#30340;&#35299;&#12290;&#27492;&#22806;&#65292;&#22312;&#39069;&#22806;&#20551;&#35774;&#19979;&#65292;&#19979;&#23618;&#30446;&#26631;&#28385;&#36275;$r$&#38454;H\"olderian&#35823;&#24046;&#26102;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#35299;&#30340;&#25910;&#25947;&#36895;&#24230;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we focus on simple bilevel optimization problems, where we minimize a convex smooth objective function over the optimal solution set of another convex smooth constrained optimization problem. We present a novel bilevel optimization method that locally approximates the solution set of the lower-level problem using a cutting plane approach and employs an accelerated gradient-based update to reduce the upper-level objective function over the approximated solution set. We measure the performance of our method in terms of suboptimality and infeasibility errors and provide non-asymptotic convergence guarantees for both error criteria. Specifically, when the feasible set is compact, we show that our method requires at most $\mathcal{O}(\max\{1/\sqrt{\epsilon_{f}}, 1/\epsilon_g\})$ iterations to find a solution that is $\epsilon_f$-suboptimal and $\epsilon_g$-infeasible. Moreover, under the additional assumption that the lower-level objective satisfies the $r$-th H\"olderian err
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#20004;&#31181;&#31169;&#26377;&#21464;&#20307;&#30340;&#38750;&#21442;&#25968;bootstrap&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#24046;&#20998;&#38544;&#31169;&#30340;&#24773;&#20917;&#19979;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#12290;&#26041;&#27861;&#22312;&#35745;&#31639;&#25928;&#29575;&#21644;&#32622;&#20449;&#21306;&#38388;&#38271;&#24230;&#19978;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#26377;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2402.07131</link><description>&lt;p&gt;
&#38024;&#23545;&#31169;&#26377;&#32479;&#35745;&#25512;&#26029;&#30340;&#37325;&#37319;&#26679;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Resampling methods for Private Statistical Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07131
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#20004;&#31181;&#31169;&#26377;&#21464;&#20307;&#30340;&#38750;&#21442;&#25968;bootstrap&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#24046;&#20998;&#38544;&#31169;&#30340;&#24773;&#20917;&#19979;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#12290;&#26041;&#27861;&#22312;&#35745;&#31639;&#25928;&#29575;&#21644;&#32622;&#20449;&#21306;&#38388;&#38271;&#24230;&#19978;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#26377;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#30340;&#20219;&#21153;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#31169;&#26377;&#21464;&#20307;&#30340;&#38750;&#21442;&#25968;bootstrap&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#25968;&#25454;&#30340;&#20998;&#21306;&#19978;&#31169;&#19979;&#35745;&#31639;&#22810;&#20010;&#8220;&#23567;&#8221;bootstrap&#30340;&#32467;&#26524;&#30340;&#20013;&#20301;&#25968;&#65292;&#24182;&#32473;&#20986;&#20102;&#24471;&#21040;&#30340;&#32622;&#20449;&#21306;&#38388;&#30340;&#28176;&#36827;&#35206;&#30422;&#35823;&#24046;&#19978;&#30028;&#12290;&#23545;&#20110;&#22266;&#23450;&#30340;&#24046;&#20998;&#38544;&#31169;&#21442;&#25968;&#949;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26679;&#26412;&#22823;&#23567;n&#19978;&#30340;&#35823;&#24046;&#29575;&#19982;&#38750;&#31169;&#26377;bootstrap&#30456;&#24403;&#65292;&#21482;&#26159;&#22312;&#23545;&#25968;&#22240;&#23376;&#20869;&#12290;&#25105;&#20204;&#20351;&#29992;&#30495;&#23454;&#25968;&#25454;&#21644;&#21512;&#25104;&#25968;&#25454;&#22312;&#22343;&#20540;&#20272;&#35745;&#12289;&#20013;&#20301;&#25968;&#20272;&#35745;&#21644;&#36923;&#36753;&#22238;&#24402;&#26041;&#38754;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#32463;&#39564;&#39564;&#35777;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25552;&#20379;&#31867;&#20284;&#30340;&#35206;&#30422;&#31934;&#24230;&#30340;&#21516;&#26102;&#65292;&#27604;&#20197;&#21069;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#26174;&#33879;&#32553;&#30701;&#65288;&#22823;&#32422;10&#20493;&#65289;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the task of constructing confidence intervals with differential privacy. We propose two private variants of the non-parametric bootstrap, which privately compute the median of the results of multiple ``little'' bootstraps run on partitions of the data and give asymptotic bounds on the coverage error of the resulting confidence intervals. For a fixed differential privacy parameter $\epsilon$, our methods enjoy the same error rates as that of the non-private bootstrap to within logarithmic factors in the sample size $n$. We empirically validate the performance of our methods for mean estimation, median estimation, and logistic regression with both real and synthetic data. Our methods achieve similar coverage accuracy to existing methods (and non-private baselines) while providing notably shorter ($\gtrsim 10$ times) confidence intervals than previous approaches.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24037;&#20855;&#21464;&#37327;&#27861;&#35782;&#21035;&#21644;&#20272;&#35745;&#36830;&#32493;&#22788;&#29702;&#30340;&#22240;&#26524;&#25928;&#24212;&#24322;&#36136;&#24615;&#30340;&#26041;&#27861;&#65292;&#24182;&#24320;&#21457;&#20102;&#19977;&#31867;&#30456;&#24212;&#30340;&#20272;&#35745;&#22120;&#65292;&#24182;&#23545;&#20854;&#36827;&#34892;&#20102;&#32479;&#35745;&#24615;&#36136;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2401.11130</link><description>&lt;p&gt;
&#36890;&#36807;&#24037;&#20855;&#21464;&#37327;&#27861;&#35782;&#21035;&#21644;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#20559;&#22240;&#26524;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;
Identification and Estimation of Conditional Average Partial Causal Effects via Instrumental Variable. (arXiv:2401.11130v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11130
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24037;&#20855;&#21464;&#37327;&#27861;&#35782;&#21035;&#21644;&#20272;&#35745;&#36830;&#32493;&#22788;&#29702;&#30340;&#22240;&#26524;&#25928;&#24212;&#24322;&#36136;&#24615;&#30340;&#26041;&#27861;&#65292;&#24182;&#24320;&#21457;&#20102;&#19977;&#31867;&#30456;&#24212;&#30340;&#20272;&#35745;&#22120;&#65292;&#24182;&#23545;&#20854;&#36827;&#34892;&#20102;&#32479;&#35745;&#24615;&#36136;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#23545;&#20110;&#20272;&#35745;&#24322;&#36136;&#22240;&#26524;&#25928;&#24212;&#30340;&#20852;&#36259;&#26085;&#30410;&#22686;&#21152;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#26465;&#20214;&#24179;&#22343;&#20559;&#22240;&#26524;&#25928;&#24212;&#65288;CAPCE&#65289;&#65292;&#20197;&#25581;&#31034;&#36830;&#32493;&#22788;&#29702;&#30340;&#22240;&#26524;&#25928;&#24212;&#30340;&#24322;&#36136;&#24615;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#22312;&#24037;&#20855;&#21464;&#37327;&#35774;&#32622;&#19979;&#35782;&#21035;CAPCE&#30340;&#26465;&#20214;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19977;&#31867;CAPCE&#20272;&#35745;&#22120;&#65306;&#31579;&#36873;&#12289;&#21442;&#25968;&#21270;&#21644;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;-&#22522;&#30784;&#65292;&#20998;&#26512;&#20102;&#23427;&#20204;&#30340;&#32479;&#35745;&#24615;&#36136;&#12290;&#25105;&#20204;&#36890;&#36807;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#23545;&#25552;&#20986;&#30340;CAPCE&#20272;&#35745;&#22120;&#36827;&#34892;&#20102;&#35828;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
There has been considerable recent interest in estimating heterogeneous causal effects. In this paper, we introduce conditional average partial causal effects (CAPCE) to reveal the heterogeneity of causal effects with continuous treatment. We provide conditions for identifying CAPCE in an instrumental variable setting. We develop three families of CAPCE estimators: sieve, parametric, and reproducing kernel Hilbert space (RKHS)-based, and analyze their statistical properties. We illustrate the proposed CAPCE estimators on synthetic and real-world data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#24230;&#21644;&#37325;&#23614;&#24178;&#25200;&#26465;&#20214;&#19979;&#30340;&#40065;&#26834;&#22238;&#24402;&#20272;&#35745;&#22120;&#30340;&#24615;&#36136;&#65292;&#36890;&#36807;&#30740;&#31350;&#19968;&#31867;&#26925;&#22278;&#21327;&#21464;&#37327;&#21644;&#22122;&#22768;&#25968;&#25454;&#20998;&#24067;&#30340;M-&#20272;&#35745;&#22120;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#23384;&#22312;&#37325;&#23614;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65292;Huber&#25439;&#22833;&#38656;&#35201;&#36827;&#19968;&#27493;&#27491;&#21017;&#21270;&#25165;&#33021;&#36798;&#21040;&#26368;&#20248;&#24615;&#33021;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25512;&#23548;&#20986;&#20102;&#23725;&#22238;&#24402;&#30340;&#36229;&#39069;&#39118;&#38505;&#30340;&#34928;&#20943;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2309.16476</link><description>&lt;p&gt;
&#39640;&#32500;&#24230;&#19979;&#37325;&#23614;&#25968;&#25454;&#19979;&#30340;&#40065;&#26834;&#22238;&#24402;: &#28176;&#36817;&#24615;&#21644;&#26222;&#36866;&#24615;
&lt;/p&gt;
&lt;p&gt;
High-dimensional robust regression under heavy-tailed data: Asymptotics and Universality. (arXiv:2309.16476v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16476
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#24230;&#21644;&#37325;&#23614;&#24178;&#25200;&#26465;&#20214;&#19979;&#30340;&#40065;&#26834;&#22238;&#24402;&#20272;&#35745;&#22120;&#30340;&#24615;&#36136;&#65292;&#36890;&#36807;&#30740;&#31350;&#19968;&#31867;&#26925;&#22278;&#21327;&#21464;&#37327;&#21644;&#22122;&#22768;&#25968;&#25454;&#20998;&#24067;&#30340;M-&#20272;&#35745;&#22120;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#23384;&#22312;&#37325;&#23614;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65292;Huber&#25439;&#22833;&#38656;&#35201;&#36827;&#19968;&#27493;&#27491;&#21017;&#21270;&#25165;&#33021;&#36798;&#21040;&#26368;&#20248;&#24615;&#33021;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25512;&#23548;&#20986;&#20102;&#23725;&#22238;&#24402;&#30340;&#36229;&#39069;&#39118;&#38505;&#30340;&#34928;&#20943;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#21327;&#21464;&#37327;&#21644;&#21709;&#24212;&#20989;&#25968;&#37117;&#21463;&#37325;&#23614;&#24178;&#25200;&#30340;&#24773;&#20917;&#19979;&#65292;&#40065;&#26834;&#22238;&#24402;&#20272;&#35745;&#37327;&#30340;&#39640;&#32500;&#24615;&#36136;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#38024;&#23545;&#19968;&#31867;&#21253;&#21547;&#26925;&#22278;&#21327;&#21464;&#37327;&#21644;&#22122;&#22768;&#25968;&#25454;&#20998;&#24067;&#30340;M-&#20272;&#35745;&#22120;&#25552;&#20379;&#20102;&#38160;&#21033;&#30340;&#28176;&#36817;&#29305;&#24449;&#21270;&#65292;&#21253;&#25324;&#20108;&#38454;&#21450;&#20197;&#19978;&#30697;&#19981;&#23384;&#22312;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#23384;&#22312;&#37325;&#23614;&#22122;&#22768;&#30340;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#23613;&#31649;Huber&#25439;&#22833;&#36890;&#36807;&#26368;&#20248;&#35843;&#25972;&#30340;&#20301;&#32622;&#21442;&#25968;$\delta$&#26159;&#19968;&#33268;&#30340;&#65292;&#20294;&#20854;&#22312;&#24615;&#33021;&#19978;&#26159;&#27425;&#20248;&#30340;&#65292;&#31361;&#26174;&#20102;&#36827;&#19968;&#27493;&#27491;&#21017;&#21270;&#20197;&#36798;&#21040;&#26368;&#20248;&#24615;&#33021;&#30340;&#24517;&#35201;&#24615;&#12290;&#36825;&#20010;&#32467;&#26524;&#36824;&#25581;&#31034;&#20102;$\delta$&#20316;&#20026;&#26679;&#26412;&#22797;&#26434;&#24230;&#21644;&#27745;&#26579;&#30340;&#20989;&#25968;&#23384;&#22312;&#30340;&#19968;&#20010;&#26377;&#36259;&#30340;&#36716;&#21464;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25512;&#23548;&#20986;&#23725;&#22238;&#24402;&#20013;&#36229;&#39069;&#39118;&#38505;&#30340;&#34928;&#20943;&#36895;&#29575;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23545;&#20110;&#20855;&#26377;&#26377;&#38480;&#20108;&#38454;&#30697;&#30340;&#22122;&#22768;&#20998;&#24067;&#65292;&#23725;&#22238;&#24402;&#19981;&#20165;&#26159;&#26368;&#20248;&#30340;&#65292;&#32780;&#19988;&#26159;&#26222;&#36866;&#30340;&#65292;&#20294;&#20854;&#34928;&#20943;&#36895;&#29575;&#21487;&#20197;&#26159;...
&lt;/p&gt;
&lt;p&gt;
We investigate the high-dimensional properties of robust regression estimators in the presence of heavy-tailed contamination of both the covariates and response functions. In particular, we provide a sharp asymptotic characterisation of M-estimators trained on a family of elliptical covariate and noise data distributions including cases where second and higher moments do not exist. We show that, despite being consistent, the Huber loss with optimally tuned location parameter $\delta$ is suboptimal in the high-dimensional regime in the presence of heavy-tailed noise, highlighting the necessity of further regularisation to achieve optimal performance. This result also uncovers the existence of a curious transition in $\delta$ as a function of the sample complexity and contamination. Moreover, we derive the decay rates for the excess risk of ridge regression. We show that, while it is both optimal and universal for noise distributions with finite second moment, its decay rate can be consi
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#20010;&#25308;&#21344;&#24237;&#40065;&#26834;&#12289;&#36890;&#20449;&#39640;&#25928;&#21644;&#31169;&#23494;&#30340;&#31639;&#27861;(Subspace-Median)&#26469;&#35299;&#20915;&#22312;&#32852;&#37030;&#29615;&#22659;&#20013;&#20272;&#35745;&#23545;&#31216;&#30697;&#38453;&#20027;&#23376;&#31354;&#38388;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#36824;&#30740;&#31350;&#20102;&#32852;&#37030;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#21644;&#27700;&#24179;&#32852;&#37030;&#20302;&#31209;&#21015;&#24863;&#30693;&#65288;LRCCS&#65289;&#30340;&#29305;&#27530;&#24773;&#20917;&#65292;&#24182;&#23637;&#31034;&#20102;Subspace-Median&#31639;&#27861;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2309.14512</link><description>&lt;p&gt;
&#25308;&#21344;&#24237;&#40065;&#26834;&#30340;&#32852;&#37030;PCA&#21644;&#20302;&#31209;&#30697;&#38453;&#24674;&#22797;
&lt;/p&gt;
&lt;p&gt;
Byzantine-Resilient Federated PCA and Low Rank Matrix Recovery. (arXiv:2309.14512v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14512
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#20010;&#25308;&#21344;&#24237;&#40065;&#26834;&#12289;&#36890;&#20449;&#39640;&#25928;&#21644;&#31169;&#23494;&#30340;&#31639;&#27861;(Subspace-Median)&#26469;&#35299;&#20915;&#22312;&#32852;&#37030;&#29615;&#22659;&#20013;&#20272;&#35745;&#23545;&#31216;&#30697;&#38453;&#20027;&#23376;&#31354;&#38388;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#36824;&#30740;&#31350;&#20102;&#32852;&#37030;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#21644;&#27700;&#24179;&#32852;&#37030;&#20302;&#31209;&#21015;&#24863;&#30693;&#65288;LRCCS&#65289;&#30340;&#29305;&#27530;&#24773;&#20917;&#65292;&#24182;&#23637;&#31034;&#20102;Subspace-Median&#31639;&#27861;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#22312;&#32852;&#37030;&#29615;&#22659;&#20013;&#20272;&#35745;&#23545;&#31216;&#30697;&#38453;&#30340;&#20027;&#23376;&#31354;&#38388;&#65288;&#21069;r&#20010;&#22855;&#24322;&#21521;&#37327;&#30340;&#24352;&#25104;&#65289;&#30340;&#38382;&#39064;&#65292;&#24403;&#27599;&#20010;&#33410;&#28857;&#37117;&#21487;&#20197;&#35775;&#38382;&#23545;&#36825;&#20010;&#30697;&#38453;&#30340;&#20272;&#35745;&#26102;&#12290;&#25105;&#20204;&#30740;&#31350;&#22914;&#20309;&#20351;&#36825;&#20010;&#38382;&#39064;&#20855;&#26377;&#25308;&#21344;&#24237;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21487;&#35777;&#26126;&#30340;&#25308;&#21344;&#24237;&#40065;&#26834;&#12289;&#36890;&#20449;&#39640;&#25928;&#21644;&#31169;&#23494;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;&#23376;&#31354;&#38388;&#20013;&#20540;&#31639;&#27861;&#65288;Subspace-Median&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#30340;&#26368;&#33258;&#28982;&#30340;&#35299;&#27861;&#65292;&#22522;&#20110;&#20960;&#20309;&#20013;&#20540;&#30340;&#20462;&#25913;&#30340;&#32852;&#37030;&#24130;&#26041;&#27861;&#65292;&#24182;&#35299;&#37322;&#20026;&#20160;&#20040;&#23427;&#26159;&#26080;&#29992;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#40065;&#26834;&#23376;&#31354;&#38388;&#20272;&#35745;&#20803;&#38382;&#39064;&#30340;&#20004;&#20010;&#29305;&#27530;&#24773;&#20917; - &#32852;&#37030;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#21644;&#27700;&#24179;&#32852;&#37030;&#20302;&#31209;&#21015;&#24863;&#30693;&#65288;LRCCS&#65289;&#30340;&#35889;&#21021;&#22987;&#21270;&#27493;&#39588;&#12290;&#23545;&#20110;&#36825;&#20004;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23376;&#31354;&#38388;&#20013;&#20540;&#31639;&#27861;&#25552;&#20379;&#20102;&#26082;&#20855;&#26377;&#40065;&#26834;&#24615;&#21448;&#20855;&#26377;&#39640;&#36890;&#20449;&#25928;&#29575;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#22343;&#20540;&#30340;&#20013;&#20301;&#25968;&#25193;&#23637;&#20063;&#34987;&#24320;&#21457;&#20986;&#26469;&#20102;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work we consider the problem of estimating the principal subspace (span of the top r singular vectors) of a symmetric matrix in a federated setting, when each node has access to estimates of this matrix. We study how to make this problem Byzantine resilient. We introduce a novel provably Byzantine-resilient, communication-efficient, and private algorithm, called Subspace-Median, to solve it. We also study the most natural solution for this problem, a geometric median based modification of the federated power method, and explain why it is not useful. We consider two special cases of the resilient subspace estimation meta-problem - federated principal components analysis (PCA) and the spectral initialization step of horizontally federated low rank column-wise sensing (LRCCS) in this work. For both these problems we show how Subspace Median provides a resilient solution that is also communication-efficient. Median of Means extensions are developed for both problems. Extensive simu
&lt;/p&gt;</description></item><item><title>BayOTIDE&#26159;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#22312;&#32447;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#19982;&#20989;&#25968;&#20998;&#35299;&#27169;&#22411;&#65292;&#36890;&#36807;&#23558;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#35270;&#20026;&#20302;&#31209;&#26102;&#24207;&#22240;&#23376;&#32452;&#30340;&#21152;&#26435;&#32452;&#21512;&#26469;&#36827;&#34892;&#25554;&#34917;&#65292;&#21516;&#26102;&#35299;&#20915;&#20102;&#20840;&#23616;&#36235;&#21183;&#21644;&#21608;&#26399;&#24615;&#27169;&#24335;&#30340;&#24573;&#30053;&#20197;&#21450;&#19981;&#35268;&#21017;&#37319;&#26679;&#26102;&#38388;&#24207;&#21015;&#30340;&#22788;&#29702;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.14906</link><description>&lt;p&gt;
BayOTIDE: &#22522;&#20110;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#22312;&#32447;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#19982;&#20989;&#25968;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
BayOTIDE: Bayesian Online Multivariate Time series Imputation with functional decomposition. (arXiv:2308.14906v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14906
&lt;/p&gt;
&lt;p&gt;
BayOTIDE&#26159;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#22312;&#32447;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#19982;&#20989;&#25968;&#20998;&#35299;&#27169;&#22411;&#65292;&#36890;&#36807;&#23558;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#35270;&#20026;&#20302;&#31209;&#26102;&#24207;&#22240;&#23376;&#32452;&#30340;&#21152;&#26435;&#32452;&#21512;&#26469;&#36827;&#34892;&#25554;&#34917;&#65292;&#21516;&#26102;&#35299;&#20915;&#20102;&#20840;&#23616;&#36235;&#21183;&#21644;&#21608;&#26399;&#24615;&#27169;&#24335;&#30340;&#24573;&#30053;&#20197;&#21450;&#19981;&#35268;&#21017;&#37319;&#26679;&#26102;&#38388;&#24207;&#21015;&#30340;&#22788;&#29702;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#22330;&#26223;&#20013;&#65292;&#22914;&#20132;&#36890;&#21644;&#33021;&#28304;&#65292;&#32463;&#24120;&#35266;&#23519;&#21040;&#20855;&#26377;&#32570;&#22833;&#20540;&#21644;&#22122;&#22768;&#30340;&#22823;&#35268;&#27169;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#29978;&#33267;&#26159;&#19981;&#35268;&#21017;&#37319;&#26679;&#12290;&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#25554;&#34917;&#26041;&#27861;&#65292;&#20294;&#23427;&#20204;&#22823;&#22810;&#25968;&#21482;&#36866;&#29992;&#20110;&#23616;&#37096;&#35270;&#35282;&#65292;&#21363;&#23558;&#38271;&#24207;&#21015;&#25286;&#20998;&#20026;&#36866;&#24403;&#22823;&#23567;&#30340;&#25209;&#27425;&#36827;&#34892;&#35757;&#32451;&#12290;&#36825;&#31181;&#23616;&#37096;&#35270;&#35282;&#21487;&#33021;&#20351;&#27169;&#22411;&#24573;&#30053;&#20840;&#23616;&#36235;&#21183;&#25110;&#21608;&#26399;&#24615;&#27169;&#24335;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#20960;&#20046;&#25152;&#26377;&#26041;&#27861;&#37117;&#20551;&#35774;&#35266;&#27979;&#20540;&#22312;&#35268;&#21017;&#30340;&#26102;&#38388;&#38388;&#38548;&#36827;&#34892;&#37319;&#26679;&#65292;&#24182;&#19988;&#26080;&#27861;&#22788;&#29702;&#26469;&#33258;&#19981;&#21516;&#24212;&#29992;&#30340;&#22797;&#26434;&#19981;&#35268;&#21017;&#37319;&#26679;&#26102;&#38388;&#24207;&#21015;&#12290;&#27492;&#22806;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#37117;&#26159;&#22312;&#31163;&#32447;&#29366;&#24577;&#19979;&#36827;&#34892;&#23398;&#20064;&#30340;&#12290;&#22240;&#27492;&#65292;&#23545;&#20110;&#37027;&#20123;&#26377;&#24555;&#36895;&#21040;&#36798;&#30340;&#27969;&#25968;&#25454;&#30340;&#24212;&#29992;&#26469;&#35828;&#65292;&#23427;&#20204;&#24182;&#19981;&#21512;&#36866;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;BayOTIDE&#65306;&#22522;&#20110;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#22312;&#32447;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#19982;&#20989;&#25968;&#20998;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
In real-world scenarios like traffic and energy, massive time-series data with missing values and noises are widely observed, even sampled irregularly. While many imputation methods have been proposed, most of them work with a local horizon, which means models are trained by splitting the long sequence into batches of fit-sized patches. This local horizon can make models ignore global trends or periodic patterns. More importantly, almost all methods assume the observations are sampled at regular time stamps, and fail to handle complex irregular sampled time series arising from different applications. Thirdly, most existing methods are learned in an offline manner. Thus, it is not suitable for many applications with fast-arriving streaming data. To overcome these limitations, we propose \ours: Bayesian Online Multivariate Time series Imputation with functional decomposition. We treat the multivariate time series as the weighted combination of groups of low-rank temporal factors with dif
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28040;&#38500;OCV&#65288;Aliasing&#65289;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#22797;&#25968;&#21367;&#31215;&#65292;&#21516;&#26102;&#37319;&#29992;Gabor&#26679;&#24335;&#30340;&#21367;&#31215;&#26680;&#65292;&#21487;&#20197;&#25552;&#39640;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#31867;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2212.00394</link><description>&lt;p&gt;
&#20174;CNN&#21040;&#22522;&#20110;&#22797;&#23567;&#27874;&#30340;&#24179;&#31227;&#19981;&#21464;&#21452;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
From CNNs to Shift-Invariant Twin Models Based on Complex Wavelets. (arXiv:2212.00394v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.00394
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28040;&#38500;OCV&#65288;Aliasing&#65289;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#22797;&#25968;&#21367;&#31215;&#65292;&#21516;&#26102;&#37319;&#29992;Gabor&#26679;&#24335;&#30340;&#21367;&#31215;&#26680;&#65292;&#21487;&#20197;&#25552;&#39640;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#31867;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25239;&#28151;&#21472;&#26041;&#27861;&#26469;&#22686;&#21152;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#24179;&#31227;&#19981;&#21464;&#24615;&#21644;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#29992;&#8220;&#22797;&#20540;&#21367;&#31215;+&#27169;&#36816;&#31639;&#8221;&#65288;$\mathbb{C}$Mod&#65289;&#20195;&#26367;&#31532;&#19968;&#23618;&#30340;&#8220;&#23454;&#20540;&#21367;&#31215;+&#26368;&#22823;&#27744;&#21270;&#8221;&#65288;$\mathbb{R}$Max&#65289;&#65292;&#22240;&#20026;&#23427;&#31283;&#23450;&#20110;&#24179;&#31227;&#12290;&#20026;&#20102;&#35777;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#22768;&#31216;&#24403;&#21367;&#31215;&#26680;&#26159;&#24102;&#36890;&#21644;&#23450;&#21521;&#30340;&#65288;&#31867;&#20284;&#20110;Gabor&#28388;&#27874;&#22120;&#65289;&#26102;&#65292;$\mathbb{C}$Mod&#21644;$\mathbb{R}$Max&#20135;&#29983;&#21487;&#27604;&#36739;&#30340;&#36755;&#20986;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;$\mathbb{C}$Mod&#21487;&#20197;&#34987;&#35748;&#20026;&#26159;$\mathbb{R}$Max&#30340;&#31283;&#23450;&#26367;&#20195;&#21697;&#12290;&#22240;&#27492;&#65292;&#22312;&#25239;&#28151;&#21472;&#20043;&#21069;&#65292;&#25105;&#20204;&#24378;&#21046;&#21367;&#31215;&#26680;&#37319;&#29992;&#36825;&#31181;Gabor&#26679;&#24335;&#30340;&#32467;&#26500;&#12290;&#30456;&#24212;&#30340;&#26550;&#26500;&#31216;&#20026;&#25968;&#23398;&#21452;&#27169;&#22411;&#65292;&#22240;&#20026;&#23427;&#20351;&#29992;&#19968;&#20010;&#26126;&#30830;&#23450;&#20041;&#30340;&#25968;&#23398;&#36816;&#31639;&#31526;&#26469;&#27169;&#25311;&#21407;&#22987;&#30340;&#33258;&#30001;&#35757;&#32451;&#27169;&#22411;&#30340;&#34892;&#20026;&#12290;&#25105;&#20204;&#30340;&#25239;&#28151;&#21472;&#26041;&#27861;&#22312;Imagenet&#21644;CIFAR-10&#20998;&#31867;&#20219;&#21153;&#19978;&#23454;&#29616;&#20102;&#27604;&#20043;&#21069;&#26356;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel antialiasing method to increase shift invariance and prediction accuracy in convolutional neural networks. Specifically, we replace the first-layer combination "real-valued convolutions + max pooling" ($\mathbb{R}$Max) by "complex-valued convolutions + modulus" ($\mathbb{C}$Mod), which is stable to translations. To justify our approach, we claim that $\mathbb{C}$Mod and $\mathbb{R}$Max produce comparable outputs when the convolution kernel is band-pass and oriented (Gabor-like filter). In this context, $\mathbb{C}$Mod can be considered as a stable alternative to $\mathbb{R}$Max. Thus, prior to antialiasing, we force the convolution kernels to adopt such a Gabor-like structure. The corresponding architecture is called mathematical twin, because it employs a well-defined mathematical operator to mimic the behavior of the original, freely-trained model. Our antialiasing approach achieves superior accuracy on ImageNet and CIFAR-10 classification tasks, compared to prior 
&lt;/p&gt;</description></item></channel></rss>