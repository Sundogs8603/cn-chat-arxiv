<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#30456;&#26426;&#36827;&#34892;&#38543;&#24847;&#25429;&#25417;&#30340;&#26041;&#27861;&#26469;&#39044;&#27979;&#32455;&#29289;&#30340;&#33258;&#30001;&#33853;&#20307;&#25928;&#24212;&#65292;&#24182;&#21019;&#26032;&#24615;&#22320;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#25311;&#21040;&#30495;&#23454;&#30340;&#31574;&#30053;&#26469;&#35757;&#32451;&#23398;&#20064;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#21487;&#20197;&#36755;&#20986;&#23436;&#25972;&#30340;&#21147;&#23398;&#21442;&#25968;&#38598;&#12290;</title><link>http://arxiv.org/abs/2304.06704</link><description>&lt;p&gt;
&#22914;&#20309;&#39044;&#27979;&#32455;&#29289;&#30340;&#33258;&#30001;&#33853;&#20307;&#25928;&#24212;? &#36890;&#36807;&#28145;&#24230;&#22270;&#20687;&#25429;&#25417;&#32455;&#29289;&#21147;&#23398;&#29305;&#24615;
&lt;/p&gt;
&lt;p&gt;
How Will It Drape Like? Capturing Fabric Mechanics from Depth Images. (arXiv:2304.06704v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06704
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#30456;&#26426;&#36827;&#34892;&#38543;&#24847;&#25429;&#25417;&#30340;&#26041;&#27861;&#26469;&#39044;&#27979;&#32455;&#29289;&#30340;&#33258;&#30001;&#33853;&#20307;&#25928;&#24212;&#65292;&#24182;&#21019;&#26032;&#24615;&#22320;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#25311;&#21040;&#30495;&#23454;&#30340;&#31574;&#30053;&#26469;&#35757;&#32451;&#23398;&#20064;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#21487;&#20197;&#36755;&#20986;&#23436;&#25972;&#30340;&#21147;&#23398;&#21442;&#25968;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#30456;&#26426;&#36827;&#34892;&#38543;&#24847;&#25429;&#25417;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#32455;&#29289;&#30340;&#21147;&#23398;&#21442;&#25968;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#21019;&#24314;&#30495;&#23454;&#19990;&#30028;&#32442;&#32455;&#26448;&#26009;&#30340;&#26426;&#26800;&#27491;&#30830;&#25968;&#23383;&#34920;&#31034;&#65292;&#36825;&#26159;&#35768;&#22810;&#20132;&#20114;&#24335;&#35774;&#35745;&#21644;&#24037;&#31243;&#24212;&#29992;&#30340;&#22522;&#26412;&#27493;&#39588;&#12290;&#19982;&#29616;&#26377;&#30340;&#25429;&#25417;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#35299;&#20915;&#26041;&#26696;&#21487;&#20197;&#22312;&#35268;&#27169;&#19978;&#36827;&#34892;&#25429;&#25417;&#65292;&#19982;&#32442;&#32455;&#21697;&#30340;&#20809;&#23398;&#22806;&#35266;&#26080;&#20851;&#65292;&#24182;&#19988;&#26131;&#20110;&#30001;&#38750;&#19987;&#19994;&#25805;&#20316;&#32773;&#36827;&#34892;&#32455;&#29289;&#25490;&#21015;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#25311;&#21040;&#30495;&#23454;&#30340;&#31574;&#30053;&#65292;&#20197;&#35757;&#32451;&#19968;&#20010;&#22522;&#20110;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#21487;&#20197;&#23558;&#19968;&#20010;&#25110;&#22810;&#20010;&#22270;&#20687;&#20316;&#20026;&#36755;&#20837;&#24182;&#36755;&#20986;&#23436;&#25972;&#30340;&#21147;&#23398;&#21442;&#25968;&#38598;&#12290;&#30001;&#20110;&#32463;&#36807;&#31934;&#24515;&#35774;&#35745;&#30340;&#25968;&#25454;&#22686;&#24378;&#21644;&#36716;&#31227;&#23398;&#20064;&#21327;&#35758;&#65292;&#25105;&#20204;&#30340;&#35299;&#20915;&#26041;&#26696;&#21487;&#20197;&#25512;&#24191;&#21040;&#30495;&#23454;&#22270;&#20687;&#65292;&#23613;&#31649;&#21482;&#26159;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#22240;&#27492;&#25104;&#21151;&#22320;&#20851;&#38381;&#20102;&#27169;&#25311;&#21040;&#30495;&#23454;&#30340;&#24490;&#29615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a method to estimate the mechanical parameters of fabrics using a casual capture setup with a depth camera. Our approach enables to create mechanically-correct digital representations of real-world textile materials, which is a fundamental step for many interactive design and engineering applications. As opposed to existing capture methods, which typically require expensive setups, video sequences, or manual intervention, our solution can capture at scale, is agnostic to the optical appearance of the textile, and facilitates fabric arrangement by non-expert operators. To this end, we propose a sim-to-real strategy to train a learning-based framework that can take as input one or multiple images and outputs a full set of mechanical parameters. Thanks to carefully designed data augmentation and transfer learning protocols, our solution generalizes to real images despite being trained only on synthetic data, hence successfully closing the sim-to-real loop.Key in our work is to 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; OKRidge &#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#30830;&#23450;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#31232;&#30095;&#25511;&#21046;&#26041;&#31243;&#65292;&#24182;&#36890;&#36807;&#27714;&#35299;&#31232;&#30095;&#23725;&#22238;&#24402;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#21487;&#25193;&#23637;&#24615;&#21644;&#24555;&#36895;&#24615;&#65292;&#21644;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#26377;&#30528;&#26356;&#39640;&#30340;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2304.06686</link><description>&lt;p&gt;
OKRidge: &#29992;&#20110;&#23398;&#20064;&#21160;&#24577;&#31995;&#32479;&#30340;&#21487;&#25193;&#23637; k &#31232;&#30095;&#23725;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
OKRidge: Scalable Optimal k-Sparse Ridge Regression for Learning Dynamical Systems. (arXiv:2304.06686v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06686
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; OKRidge &#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#30830;&#23450;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#31232;&#30095;&#25511;&#21046;&#26041;&#31243;&#65292;&#24182;&#36890;&#36807;&#27714;&#35299;&#31232;&#30095;&#23725;&#22238;&#24402;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#21487;&#25193;&#23637;&#24615;&#21644;&#24555;&#36895;&#24615;&#65292;&#21644;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#26377;&#30528;&#26356;&#39640;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#31185;&#23398;&#21457;&#29616;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#65292;&#21363;&#65292;&#30830;&#23450;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#31232;&#30095;&#25511;&#21046;&#26041;&#31243;&#65292;&#36890;&#36807;&#27714;&#35299;&#31232;&#30095;&#23725;&#22238;&#24402;&#38382;&#39064;&#21487;&#20197;&#35777;&#26126;&#26368;&#20248;&#24615;&#65292;&#20197;&#30830;&#23450;&#39537;&#21160;&#22522;&#30784;&#21160;&#24577;&#30340;&#39033;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026; OKRidge &#30340;&#24555;&#36895;&#31639;&#27861;&#65292;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#19979;&#30028;&#35745;&#31639;&#26041;&#27861;&#65292;&#28041;&#21450;&#38797;&#28857;&#20844;&#24335;&#65292;&#28982;&#21518;&#20351;&#29992;&#32447;&#24615;&#31995;&#32479;&#25110;&#22522;&#20110; ADMM &#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#65292;&#20854;&#20013;&#21487;&#20197;&#36890;&#36807;&#35299;&#20915;&#21478;&#19968;&#20010;&#32447;&#24615;&#31995;&#32479;&#21644;&#21333;&#35843;&#22238;&#24402;&#38382;&#39064;&#26469;&#26377;&#25928;&#22320;&#35745;&#31639;&#36817;&#31471;&#31639;&#23376;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#21551;&#21160;&#25105;&#20204;&#27714;&#35299;&#22120;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#20102;&#27874;&#26463;&#25628;&#32034;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36798;&#21040;&#21487;&#35777;&#26126;&#30340;&#26368;&#20248;&#24615;&#65292;&#24182;&#19988;&#36816;&#34892;&#26102;&#38388;&#27604;&#21830;&#19994;&#27714;&#35299;&#22120; Gurobi &#35299;&#20915;&#30340;&#29616;&#26377; MIP&#20844;&#24335;&#36816;&#34892;&#26102;&#38388;&#24555;&#20960;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider an important problem in scientific discovery, identifying sparse governing equations for nonlinear dynamical systems. This involves solving sparse ridge regression problems to provable optimality in order to determine which terms drive the underlying dynamics. We propose a fast algorithm, OKRidge, for sparse ridge regression, using a novel lower bound calculation involving, first, a saddle point formulation, and from there, either solving (i) a linear system or (ii) using an ADMM-based approach, where the proximal operators can be efficiently evaluated by solving another linear system and an isotonic regression problem. We also propose a method to warm-start our solver, which leverages a beam search. Experimentally, our methods attain provable optimality with run times that are orders of magnitude faster than those of the existing MIP formulations solved by the commercial solver Gurobi.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#21033;&#29992;&#22522;&#20110;&#20989;&#25968;&#20808;&#39564;&#30340;&#36125;&#21494;&#26031;&#35270;&#35282;&#26469;&#30740;&#31350;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#30340;&#34920;&#29616;&#26469;&#28304;&#65292;&#32467;&#26524;&#34920;&#26126;DNNs&#20043;&#25152;&#20197;&#25104;&#21151;&#65292;&#26159;&#22240;&#20026;&#23427;&#23545;&#20110;&#20855;&#26377;&#32467;&#26500;&#30340;&#25968;&#25454;&#65292;&#20855;&#22791;&#19968;&#31181;&#20869;&#22312;&#30340;&#22885;&#21345;&#22982;&#21059;&#20992;&#24335;&#30340;&#24402;&#32435;&#20559;&#24046;&#65292;&#36275;&#20197;&#25269;&#28040;&#20989;&#25968;&#25968;&#37327;&#21450;&#22797;&#26434;&#24230;&#30340;&#25351;&#25968;&#32423;&#22686;&#38271;&#12290;</title><link>http://arxiv.org/abs/2304.06670</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26159;&#21542;&#20855;&#22791;&#20869;&#32622;&#30340;&#22885;&#21345;&#22982;&#21059;&#20992;&#65311;
&lt;/p&gt;
&lt;p&gt;
Do deep neural networks have an inbuilt Occam's razor?. (arXiv:2304.06670v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06670
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#21033;&#29992;&#22522;&#20110;&#20989;&#25968;&#20808;&#39564;&#30340;&#36125;&#21494;&#26031;&#35270;&#35282;&#26469;&#30740;&#31350;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#30340;&#34920;&#29616;&#26469;&#28304;&#65292;&#32467;&#26524;&#34920;&#26126;DNNs&#20043;&#25152;&#20197;&#25104;&#21151;&#65292;&#26159;&#22240;&#20026;&#23427;&#23545;&#20110;&#20855;&#26377;&#32467;&#26500;&#30340;&#25968;&#25454;&#65292;&#20855;&#22791;&#19968;&#31181;&#20869;&#22312;&#30340;&#22885;&#21345;&#22982;&#21059;&#20992;&#24335;&#30340;&#24402;&#32435;&#20559;&#24046;&#65292;&#36275;&#20197;&#25269;&#28040;&#20989;&#25968;&#25968;&#37327;&#21450;&#22797;&#26434;&#24230;&#30340;&#25351;&#25968;&#32423;&#22686;&#38271;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36229;&#21442;&#25968;&#21270;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#30340;&#21331;&#36234;&#24615;&#33021;&#24517;&#39035;&#28304;&#33258;&#20110;&#32593;&#32476;&#26550;&#26500;&#12289;&#35757;&#32451;&#31639;&#27861;&#21644;&#25968;&#25454;&#32467;&#26500;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#20026;&#20102;&#21306;&#20998;&#36825;&#19977;&#20010;&#37096;&#20998;&#65292;&#25105;&#20204;&#24212;&#29992;&#20102;&#22522;&#20110;DNN&#25152;&#34920;&#36798;&#30340;&#20989;&#25968;&#30340;&#36125;&#21494;&#26031;&#35270;&#35282;&#26469;&#36827;&#34892;&#30417;&#30563;&#23398;&#20064;&#12290;&#32463;&#36807;&#32593;&#32476;&#30830;&#23450;&#30340;&#20989;&#25968;&#20808;&#39564;&#36890;&#36807;&#21033;&#29992;&#26377;&#24207;&#21644;&#28151;&#27788;&#29366;&#24577;&#20043;&#38388;&#30340;&#36716;&#21464;&#32780;&#21464;&#21270;&#12290;&#23545;&#20110;&#24067;&#23572;&#20989;&#25968;&#20998;&#31867;&#65292;&#25105;&#20204;&#21033;&#29992;&#20989;&#25968;&#30340;&#35823;&#24046;&#35889;&#22312;&#25968;&#25454;&#19978;&#36827;&#34892;&#21487;&#33021;&#24615;&#30340;&#36817;&#20284;&#12290;&#24403;&#19982;&#20808;&#39564;&#30456;&#32467;&#21512;&#26102;&#65292;&#23427;&#21487;&#20197;&#31934;&#30830;&#22320;&#39044;&#27979;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;DNN&#30340;&#21518;&#39564;&#27010;&#29575;&#12290;&#35813;&#20998;&#26512;&#25581;&#31034;&#20102;&#32467;&#26500;&#21270;&#25968;&#25454;&#65292;&#20197;&#21450;&#20869;&#22312;&#30340;&#22885;&#21345;&#22982;&#21059;&#20992;&#24335;&#24402;&#32435;&#20559;&#24046;&#65292;&#21363;&#36275;&#20197;&#25269;&#28040;&#22797;&#26434;&#24230;&#38543;&#20989;&#25968;&#25968;&#37327;&#21576;&#25351;&#25968;&#22686;&#38271;&#32780;&#20135;&#29983;&#30340;&#24433;&#21709;&#65292;&#26159;DNNs&#25104;&#21151;&#30340;&#20851;&#38190;&#12290;
&lt;/p&gt;
&lt;p&gt;
The remarkable performance of overparameterized deep neural networks (DNNs) must arise from an interplay between network architecture, training algorithms, and structure in the data. To disentangle these three components, we apply a Bayesian picture, based on the functions expressed by a DNN, to supervised learning. The prior over functions is determined by the network, and is varied by exploiting a transition between ordered and chaotic regimes. For Boolean function classification, we approximate the likelihood using the error spectrum of functions on data. When combined with the prior, this accurately predicts the posterior, measured for DNNs trained with stochastic gradient descent. This analysis reveals that structured data, combined with an intrinsic Occam's razor-like inductive bias towards (Kolmogorov) simple functions that is strong enough to counteract the exponential growth of the number of functions with complexity, is a key to the success of DNNs.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;Tsallis&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#65292;&#22312;&#35752;&#35770;&#27491;&#21017;&#21270;&#21442;&#25968;&#25509;&#36817;0&#26102;&#30340;&#25910;&#25947;&#36895;&#29575;&#26102;&#65292;&#21033;&#29992;&#37327;&#21270;&#21644;&#24433;&#23376;&#26041;&#27861;&#30830;&#23450;&#20102;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#19982;KL&#25955;&#24230;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#35777;&#26126;KL&#25955;&#24230;&#22312;Tsallis&#30456;&#23545;&#29109;&#24847;&#20041;&#19979;&#20855;&#26377;&#26368;&#24555;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2304.06616</link><description>&lt;p&gt;
Tsallis&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#30340;&#25910;&#25947;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Convergence rate of Tsallis entropic regularized optimal transport. (arXiv:2304.06616v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06616
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;Tsallis&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#65292;&#22312;&#35752;&#35770;&#27491;&#21017;&#21270;&#21442;&#25968;&#25509;&#36817;0&#26102;&#30340;&#25910;&#25947;&#36895;&#29575;&#26102;&#65292;&#21033;&#29992;&#37327;&#21270;&#21644;&#24433;&#23376;&#26041;&#27861;&#30830;&#23450;&#20102;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#19982;KL&#25955;&#24230;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#35777;&#26126;KL&#25955;&#24230;&#22312;Tsallis&#30456;&#23545;&#29109;&#24847;&#20041;&#19979;&#20855;&#26377;&#26368;&#24555;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;Tsallis&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#65292;&#24182;&#19988;&#35752;&#35770;&#20102;&#24403;&#27491;&#21017;&#21270;&#21442;&#25968;$\varepsilon$&#36235;&#36817;&#20110;0&#26102;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#21033;&#29992;Eckstein-Nutz&#25552;&#20986;&#30340;&#37327;&#21270;&#21644;&#24433;&#23376;&#26041;&#27861;&#26469;&#30830;&#23450;Tsallis&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;&#25105;&#20204;&#23558;&#20854;&#19982;&#20351;&#29992;Kullback-Leibler&#65288;KL&#65289;&#25955;&#24230;&#30340;&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#30340;&#25910;&#25947;&#36895;&#29575;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;Tsallis&#30456;&#23545;&#29109;&#24847;&#20041;&#19979;KL&#20855;&#26377;&#26368;&#24555;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider Tsallis entropic regularized optimal transport and discuss the convergence rate as the regularization parameter $\varepsilon$ goes to $0$. In particular, we establish the convergence rate of the Tsallis entropic regularized optimal transport using the quantization and shadow arguments developed by Eckstein--Nutz. We compare this to the convergence rate of the entropic regularized optimal transport with Kullback--Leibler (KL) divergence and show that KL is the fastest convergence rate in terms of Tsallis relative entropy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#25512;&#26029;&#31639;&#27861;&#30340;&#36339;&#36291;&#25193;&#25955;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#24456;&#22909;&#22320;&#27169;&#25311;&#29983;&#21270;&#21453;&#24212;&#32593;&#32476;&#30340;&#21160;&#24577;&#65292;&#23588;&#20854;&#26159;&#22312;&#21442;&#25968;&#21644;&#31181;&#32676;&#29366;&#24577;&#26041;&#38754;&#38590;&#20197;&#34920;&#24449;&#30340;&#24773;&#20917;&#19979;&#12290;</title><link>http://arxiv.org/abs/2304.06592</link><description>&lt;p&gt;
&#29983;&#21270;&#21453;&#24212;&#32593;&#32476;&#30340;&#36339;&#36291;&#25193;&#25955;&#36924;&#36817;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Bayesian Inference for Jump-Diffusion Approximations of Biochemical Reaction Networks. (arXiv:2304.06592v1 [q-bio.QM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06592
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#25512;&#26029;&#31639;&#27861;&#30340;&#36339;&#36291;&#25193;&#25955;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#24456;&#22909;&#22320;&#27169;&#25311;&#29983;&#21270;&#21453;&#24212;&#32593;&#32476;&#30340;&#21160;&#24577;&#65292;&#23588;&#20854;&#26159;&#22312;&#21442;&#25968;&#21644;&#31181;&#32676;&#29366;&#24577;&#26041;&#38754;&#38590;&#20197;&#34920;&#24449;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#21270;&#21453;&#24212;&#32593;&#32476;&#26159;&#30001;&#22810;&#20010;&#19981;&#21516;&#29289;&#31181;&#20043;&#38388;&#30456;&#20114;&#20316;&#29992;&#30340;&#21453;&#24212;&#32452;&#25104;&#30340;&#12290;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#30001;&#20110;&#21453;&#24212;&#36895;&#29575;&#21644;&#29289;&#31181;&#20016;&#24230;&#30340;&#39640;&#24230;&#21464;&#21270;&#65292;&#36825;&#20123;&#32593;&#32476;&#20250;&#34920;&#29616;&#20986;&#22810;&#23610;&#24230;&#34892;&#20026;&#12290;&#25152;&#35859;&#30340;&#36339;&#36291;&#25193;&#25955;&#36924;&#36817;&#26159;&#36825;&#31181;&#31995;&#32479;&#24314;&#27169;&#30340;&#26377;&#20215;&#20540;&#24037;&#20855;&#12290;&#35813;&#36924;&#36817;&#36890;&#36807;&#23558;&#21453;&#24212;&#32593;&#32476;&#20998;&#20026;&#24555;&#21453;&#24212;&#21644;&#24930;&#21453;&#24212;&#30340;&#24555;&#21644;&#24930;&#23376;&#32452;&#26469;&#26500;&#24314;&#12290;&#36825;&#20351;&#24471;&#21487;&#20197;&#20351;&#29992; Langevin &#26041;&#31243;&#27169;&#25311;&#24555;&#32452;&#30340;&#21160;&#24577;&#65292;&#21516;&#26102;&#20026;&#24930;&#32452;&#30340;&#21160;&#24577;&#20445;&#30041;&#39532;&#23572;&#21487;&#22827;&#36339;&#36291;&#36807;&#31243;&#27169;&#22411;&#12290;&#30001;&#20110;&#22823;&#22810;&#25968;&#29983;&#21270;&#36807;&#31243;&#22312;&#21442;&#25968;&#21644;&#31181;&#32676;&#29366;&#24577;&#26041;&#38754;&#37117;&#24456;&#38590;&#34920;&#24449;&#65292;&#22240;&#27492;&#20272;&#35745;&#38544;&#34255;&#21464;&#37327;&#30340;&#26041;&#27861;&#38750;&#24120;&#37325;&#35201;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22522;&#20110;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#24320;&#21457;&#20102;&#19968;&#31181;&#26131;&#20110;&#22788;&#29702;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#31639;&#27861;&#12290;&#25152;&#25552;&#20986;&#30340;&#38459;&#22622; Gibbs &#31890;&#23376;
&lt;/p&gt;
&lt;p&gt;
Biochemical reaction networks are an amalgamation of reactions where each reaction represents the interaction of different species. Generally, these networks exhibit a multi-scale behavior caused by the high variability in reaction rates and abundances of species. The so-called jump-diffusion approximation is a valuable tool in the modeling of such systems. The approximation is constructed by partitioning the reaction network into a fast and slow subgroup of fast and slow reactions, respectively. This enables the modeling of the dynamics using a Langevin equation for the fast group, while a Markov jump process model is kept for the dynamics of the slow group. Most often biochemical processes are poorly characterized in terms of parameters and population states. As a result of this, methods for estimating hidden quantities are of significant interest. In this paper, we develop a tractable Bayesian inference algorithm based on Markov chain Monte Carlo. The presented blocked Gibbs particl
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#20998;&#31867;&#22120;&#30340;&#38382;&#39064;&#65292;&#21457;&#29616;&#36125;&#21494;&#26031;&#20915;&#31574;&#35268;&#21017;&#36890;&#24120;&#26080;&#27861;&#35782;&#21035;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#31639;&#27861;&#26469;&#23398;&#20064;&#36125;&#21494;&#26031;&#20915;&#31574;&#35268;&#21017;&#65292;&#19981;&#38656;&#35201;&#30693;&#36947;&#22122;&#22768;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2304.06574</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#26080;&#27861;&#20174;&#20855;&#26377;&#26410;&#30693;&#22122;&#22768;&#29575;&#30340;&#22024;&#26434;&#21709;&#24212;&#20013;&#23398;&#20064;&#12290;(arXiv:2304.06574v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
Bayes classifier cannot be learned from noisy responses with unknown noise rates. (arXiv:2304.06574v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06574
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#20998;&#31867;&#22120;&#30340;&#38382;&#39064;&#65292;&#21457;&#29616;&#36125;&#21494;&#26031;&#20915;&#31574;&#35268;&#21017;&#36890;&#24120;&#26080;&#27861;&#35782;&#21035;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#31639;&#27861;&#26469;&#23398;&#20064;&#36125;&#21494;&#26031;&#20915;&#31574;&#35268;&#21017;&#65292;&#19981;&#38656;&#35201;&#30693;&#36947;&#22122;&#22768;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29992;&#22024;&#26434;&#30340;&#26631;&#31614;&#35757;&#32451;&#20998;&#31867;&#22120;&#36890;&#24120;&#38656;&#35201;&#23398;&#20064;&#32773;&#25351;&#23450;&#26631;&#31614;&#22122;&#38899;&#30340;&#20998;&#24067;&#65292;&#20294;&#22312;&#23454;&#38469;&#20013;&#24448;&#24448;&#26159;&#26410;&#30693;&#30340;&#12290;&#23613;&#31649;&#26368;&#36817;&#26377;&#19968;&#20123;&#23581;&#35797;&#25918;&#23485;&#35813;&#35201;&#27714;&#65292;&#20294;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312;&#22823;&#22810;&#25968;&#22024;&#26434;&#26631;&#31614;&#20998;&#31867;&#38382;&#39064;&#20013;&#65292;&#36125;&#21494;&#26031;&#20915;&#31574;&#35268;&#21017;&#26159;&#26080;&#27861;&#35782;&#21035;&#30340;&#12290;&#36825;&#34920;&#26126;&#19968;&#33324;&#24773;&#20917;&#19979;&#26080;&#27861;&#32469;&#36807;&#25110;&#25918;&#23485;&#35813;&#35201;&#27714;&#12290;&#22312;&#36125;&#21494;&#26031;&#20915;&#31574;&#35268;&#21017;&#34987;&#35782;&#21035;&#30340;&#29305;&#27530;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#31639;&#27861;&#26469;&#23398;&#20064;&#36125;&#21494;&#26031;&#20915;&#31574;&#35268;&#21017;&#65292;&#19981;&#38656;&#35201;&#30693;&#36947;&#22122;&#22768;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training a classifier with noisy labels typically requires the learner to specify the distribution of label noise, which is often unknown in practice. Although there have been some recent attempts to relax that requirement, we show that the Bayes decision rule is unidentified in most classification problems with noisy labels. This suggests it is generally not possible to bypass/relax the requirement. In the special cases in which the Bayes decision rule is identified, we develop a simple algorithm to learn the Bayes decision rule, that does not require knowledge of the noise distribution.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#32479;&#19968;&#19988;&#27169;&#22359;&#21270;&#30340; R6 &#25509;&#21475;&#65292;&#29992;&#20110;&#20855;&#20307;&#23454;&#29616;&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#12290;&#36890;&#36807;&#23454;&#29616;&#19977;&#31181;&#26041;&#27861;&#24182;&#25512;&#24191;&#21040;&#19981;&#21516;&#30340;&#24773;&#22659;&#20013;&#65292;&#32467;&#21512;&#30495;&#23454;&#29992;&#20363;&#65292;&#27492;&#26041;&#27861;&#33021;&#22815;&#24555;&#36895;&#20934;&#30830;&#22320;&#24471;&#20986;&#26377;&#20851;&#22914;&#20309;&#26356;&#25913;&#21333;&#20010;&#35266;&#27979;&#20540;&#30340;&#29305;&#24449;&#20540;&#20197;&#33719;&#24471;&#25152;&#38656;&#39044;&#27979;&#30340;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2304.06569</link><description>&lt;p&gt;
counterfactuals: &#29992;&#20110;&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#30340; R &#21253;
&lt;/p&gt;
&lt;p&gt;
counterfactuals: An R Package for Counterfactual Explanation Methods. (arXiv:2304.06569v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06569
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#32479;&#19968;&#19988;&#27169;&#22359;&#21270;&#30340; R6 &#25509;&#21475;&#65292;&#29992;&#20110;&#20855;&#20307;&#23454;&#29616;&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#12290;&#36890;&#36807;&#23454;&#29616;&#19977;&#31181;&#26041;&#27861;&#24182;&#25512;&#24191;&#21040;&#19981;&#21516;&#30340;&#24773;&#22659;&#20013;&#65292;&#32467;&#21512;&#30495;&#23454;&#29992;&#20363;&#65292;&#27492;&#26041;&#27861;&#33021;&#22815;&#24555;&#36895;&#20934;&#30830;&#22320;&#24471;&#20986;&#26377;&#20851;&#22914;&#20309;&#26356;&#25913;&#21333;&#20010;&#35266;&#27979;&#20540;&#30340;&#29305;&#24449;&#20540;&#20197;&#33719;&#24471;&#25152;&#38656;&#39044;&#27979;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#25552;&#20379;&#26377;&#20851;&#22914;&#20309;&#26356;&#25913;&#21333;&#20010;&#35266;&#27979;&#20540;&#30340;&#29305;&#24449;&#20540;&#20197;&#33719;&#24471;&#25152;&#38656;&#39044;&#27979;&#30340;&#20449;&#24687;&#12290;&#23613;&#31649;&#30740;&#31350;&#20013;&#25552;&#20986;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#26041;&#27861;&#65292;&#20294;&#21482;&#26377;&#23569;&#25968;&#20855;&#26377;&#24191;&#27867;&#21464;&#21270;&#30340;&#25509;&#21475;&#21644;&#35201;&#27714;&#30340;&#23454;&#29616;&#23384;&#22312;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461; counterfactuals R &#21253;&#65292;&#23427;&#25552;&#20379;&#20102;&#19968;&#20010;&#22522;&#20110; R6 &#30340;&#27169;&#22359;&#21270;&#21644;&#32479;&#19968;&#30340;&#25509;&#21475;&#65292;&#29992;&#20110;&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#12290;&#25105;&#20204;&#24050;&#32463;&#23454;&#29616;&#20102;&#19977;&#31181;&#29616;&#26377;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20123;&#21487;&#36873;&#30340;&#26041;&#27861;&#23398;&#25193;&#23637;&#65292;&#20197;&#23558;&#36825;&#20123;&#26041;&#27861;&#25512;&#24191;&#21040;&#19981;&#21516;&#30340;&#22330;&#26223;&#24182;&#20351;&#20854;&#26356;&#20855;&#21487;&#27604;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#30495;&#23454;&#29992;&#20363;&#35299;&#37322;&#20102;&#21253;&#30340;&#32467;&#26500;&#21644;&#24037;&#20316;&#27969;&#31243;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#20854;&#20182;&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#38598;&#25104;&#21040;&#21253;&#20013;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#38024;&#23545;&#21508;&#31181;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#27604;&#36739;&#20102;&#23454;&#26045;&#30340;&#26041;&#27861;&#65292;&#20197;&#35780;&#20272;&#20854;&#21453;&#20107;&#23454;&#35299;&#37322;&#30340;&#36136;&#37327;&#21644;&#36816;&#34892;&#26102;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counterfactual explanation methods provide information on how feature values of individual observations must be changed to obtain a desired prediction. Despite the increasing amount of proposed methods in research, only a few implementations exist whose interfaces and requirements vary widely. In this work, we introduce the counterfactuals R package, which provides a modular and unified R6-based interface for counterfactual explanation methods. We implemented three existing counterfactual explanation methods and propose some optional methodological extensions to generalize these methods to different scenarios and to make them more comparable. We explain the structure and workflow of the package using real use cases and show how to integrate additional counterfactual explanation methods into the package. In addition, we compared the implemented methods for a variety of models and datasets with regard to the quality of their counterfactual explanations and their runtime behavior.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32806;&#21512;&#26041;&#27861;&#20998;&#26512;&#20102;&#22312;$d$&#32500;&#29615;&#38754;$\mathbb{T}_L^d$&#19978;&#23450;&#20041;&#30340;&#22312;Haar&#27979;&#24230;&#30456;&#23545;&#20110;&#23494;&#24230;&#21487;&#20801;&#35768;&#30340;&#27010;&#29575;&#24230;&#37327;&#30340;Sinkhorn&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#65292;&#35777;&#26126;&#20102;Sinkhorn&#36845;&#20195;&#21450;&#20854;&#26799;&#24230;&#30340;&#28857;&#24120;&#25351;&#25968;&#25910;&#25947;&#24615;&#65292;&#21516;&#26102;&#23548;&#20986;&#20102;&#20854;&#38750;&#28176;&#36817;&#35823;&#24046;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#19982;&#29615;&#22659;&#32500;&#25968;$d$&#21644;&#31163;&#25955;&#20803;&#32032;&#20195;&#20215;&#30697;&#38453;&#30340;&#23610;&#23544;&#26080;&#20851;&#12290;</title><link>http://arxiv.org/abs/2304.06549</link><description>&lt;p&gt;
&#38024;&#23545;Sinkhorn&#36845;&#20195;&#21450;&#20854;&#26799;&#24230;&#30340;&#38750;&#28176;&#36827;&#25910;&#25947;&#30028;&#38480;: &#19968;&#31181;&#32806;&#21512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Non-asymptotic convergence bounds for Sinkhorn iterates and their gradients: a coupling approach. (arXiv:2304.06549v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06549
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32806;&#21512;&#26041;&#27861;&#20998;&#26512;&#20102;&#22312;$d$&#32500;&#29615;&#38754;$\mathbb{T}_L^d$&#19978;&#23450;&#20041;&#30340;&#22312;Haar&#27979;&#24230;&#30456;&#23545;&#20110;&#23494;&#24230;&#21487;&#20801;&#35768;&#30340;&#27010;&#29575;&#24230;&#37327;&#30340;Sinkhorn&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#65292;&#35777;&#26126;&#20102;Sinkhorn&#36845;&#20195;&#21450;&#20854;&#26799;&#24230;&#30340;&#28857;&#24120;&#25351;&#25968;&#25910;&#25947;&#24615;&#65292;&#21516;&#26102;&#23548;&#20986;&#20102;&#20854;&#38750;&#28176;&#36817;&#35823;&#24046;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#19982;&#29615;&#22659;&#32500;&#25968;$d$&#21644;&#31163;&#25955;&#20803;&#32032;&#20195;&#20215;&#30697;&#38453;&#30340;&#23610;&#23544;&#26080;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#35745;&#31639;&#26368;&#20248;&#20256;&#36755;&#65288;OT&#65289;&#20316;&#20026;&#19968;&#20010;&#22312;&#21508;&#20010;&#39046;&#22495;&#24212;&#29992;&#30340;&#24378;&#26377;&#21147;&#30340;&#26694;&#26550;&#20986;&#29616;&#20102;&#12290;&#26412;&#25991;&#30528;&#37325;&#35752;&#35770;&#23545;&#21407;&#22987;OT&#38382;&#39064;&#30340;&#19968;&#31181;&#25918;&#26494;&#24418;&#24335;&#65292;&#21363;&#29109;OT&#38382;&#39064;&#65292;&#23427;&#21487;&#20197;&#23454;&#29616;&#39640;&#25928;&#30340;&#23454;&#38469;&#31639;&#27861;&#35299;&#20915;&#26041;&#26696;&#65292;&#21363;&#20351;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#20063;&#26159;&#22914;&#27492;&#12290;&#36825;&#20010;&#20844;&#24335;&#20063;&#34987;&#31216;&#20026;Schr\"odinger&#26725;&#38382;&#39064;&#65292;&#26174;&#28982;&#19982;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#65288;SOC&#65289;&#30456;&#20851;&#65292;&#24182;&#19988;&#21487;&#20197;&#29992;&#27969;&#34892;&#30340;Sinkhorn&#31639;&#27861;&#26469;&#35299;&#20915;&#12290;&#23545;&#20110;&#31163;&#25955;&#29366;&#24577;&#31354;&#38388;&#30340;&#24773;&#20917;&#65292;&#24050;&#30693;&#35813;&#31639;&#27861;&#20855;&#26377;&#25351;&#25968;&#25910;&#25947;&#24615;&#65307;&#28982;&#32780;&#65292;&#22312;&#26356;&#19968;&#33324;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#31867;&#20284;&#30340;&#25910;&#25947;&#36895;&#29575;&#20173;&#28982;&#26159;&#19968;&#20010;&#31215;&#26497;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#22312;$d$&#32500;&#29615;&#38754;$\mathbb{T}_L^d$&#19978;&#23450;&#20041;&#30340;&#22312;Haar&#27979;&#24230;&#30456;&#23545;&#20110;&#23494;&#24230;&#21487;&#20801;&#35768;&#30340;&#27010;&#29575;&#24230;&#37327;&#30340;Sinkhorn&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;&#29305;&#21035;&#30340;&#65292;&#22312;&#36873;&#25321;&#19968;&#23450;&#33539;&#22260;&#20869;&#30340;&#29109;&#21442;&#25968;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;Sinkhorn&#36845;&#20195;&#21450;&#20854;&#26799;&#24230;&#30340;&#28857;&#24120;&#25351;&#25968;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#25216;&#26415;&#20381;&#36182;&#20110;&#19968;&#31181;&#32806;&#21512;&#26041;&#27861;&#65292;&#21463;&#21040;[C. E. Brubaker, M. Fathi&#21644;G. Peyr&#233;, NeurIPS 2020]&#30340;&#26368;&#26032;&#24037;&#20316;&#30340;&#21551;&#21457;&#12290;&#25105;&#20204;&#36824;&#25512;&#23548;&#20102;Sinkhorn&#31639;&#27861;&#30340;&#26032;&#25910;&#25947;&#36895;&#29575;&#65292;&#20174;&#32780;&#23548;&#20986;&#20102;Sinkhorn&#36845;&#20195;&#21644;&#32806;&#21512;&#30340;&#38750;&#28176;&#36817;&#35823;&#24046;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#29420;&#31435;&#20110;&#29615;&#22659;&#32500;&#25968;$d$&#21644;&#31163;&#25955;&#20803;&#32032;&#20195;&#20215;&#30697;&#38453;&#30340;&#23610;&#23544;&#12290;
&lt;/p&gt;
&lt;p&gt;
Computational optimal transport (OT) has recently emerged as a powerful framework with applications in various fields. In this paper we focus on a relaxation of the original OT problem, the entropic OT problem, which allows to implement efficient and practical algorithmic solutions, even in high dimensional settings. This formulation, also known as the Schr\"odinger Bridge problem, notably connects with Stochastic Optimal Control (SOC) and can be solved with the popular Sinkhorn algorithm. In the case of discrete-state spaces, this algorithm is known to have exponential convergence; however, achieving a similar rate of convergence in a more general setting is still an active area of research. In this work, we analyze the convergence of the Sinkhorn algorithm for probability measures defined on the $d$-dimensional torus $\mathbb{T}_L^d$, that admit densities with respect to the Haar measure of $\mathbb{T}_L^d$. In particular, we prove pointwise exponential convergence of Sinkhorn iterat
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#20449;&#21495;&#24314;&#27169;&#21363;&#21487;&#35782;&#21035;&#20449;&#21495;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#26679;&#26412;&#21644;&#20854;&#37051;&#23621;&#20043;&#38388;&#30456;&#23545;&#36317;&#31163;&#65292;&#21487;&#20197;&#22312;&#23567;&#26679;&#26412;&#21644;&#39640;&#32500;&#25968;&#25454;&#20013;&#35782;&#21035;&#8220;&#31867;&#20284;&#20110;&#20449;&#21495;&#8221;&#30340;&#21464;&#37327;&#12290;</title><link>http://arxiv.org/abs/2304.06522</link><description>&lt;p&gt;
&#26080;&#38656;&#20449;&#21495;&#24314;&#27169;&#30340;&#20449;&#21495;&#35782;&#21035;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Signal identification without signal formulation. (arXiv:2304.06522v1 [physics.data-an])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06522
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#20449;&#21495;&#24314;&#27169;&#21363;&#21487;&#35782;&#21035;&#20449;&#21495;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#26679;&#26412;&#21644;&#20854;&#37051;&#23621;&#20043;&#38388;&#30456;&#23545;&#36317;&#31163;&#65292;&#21487;&#20197;&#22312;&#23567;&#26679;&#26412;&#21644;&#39640;&#32500;&#25968;&#25454;&#20013;&#35782;&#21035;&#8220;&#31867;&#20284;&#20110;&#20449;&#21495;&#8221;&#30340;&#21464;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20449;&#21495;&#21644;&#22122;&#22768;&#28151;&#21512;&#26102;&#65292;&#29289;&#29702;&#23398;&#23478;&#36890;&#24120;&#36890;&#36807;&#20449;&#21495;&#24314;&#27169;&#26469;&#35782;&#21035;&#20449;&#21495;&#65292;&#32780;&#32479;&#35745;&#23398;&#23478;&#21017;&#30456;&#21453;&#65292;&#20182;&#20204;&#35797;&#22270;&#23545;&#22122;&#22768;&#36827;&#34892;&#24314;&#27169;&#26469;&#35782;&#21035;&#20449;&#21495;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24212;&#29992;&#20102;&#32479;&#35745;&#23398;&#23478;&#30340;&#20449;&#21495;&#26816;&#27979;&#27010;&#24565;&#65292;&#23545;&#20855;&#26377;&#23567;&#26679;&#26412;&#21644;&#39640;&#32500;&#25968;&#25454;&#30340;&#29289;&#29702;&#25968;&#25454;&#36827;&#34892;&#20102;&#22788;&#29702;&#65292;&#32780;&#19981;&#23545;&#20449;&#21495;&#36827;&#34892;&#24314;&#27169;&#12290;&#33258;&#28982;&#30028;&#20013;&#30340;&#22823;&#37096;&#20998;&#25968;&#25454;&#65292;&#26080;&#35770;&#26159;&#22122;&#22768;&#36824;&#26159;&#20449;&#21495;&#65292;&#37117;&#34987;&#20551;&#23450;&#20026;&#26159;&#30001;&#21160;&#24577;&#31995;&#32479;&#29983;&#25104;&#30340;&#65307;&#22240;&#27492;&#65292;&#22312;&#36825;&#20123;&#29983;&#25104;&#36807;&#31243;&#20043;&#38388;&#22522;&#26412;&#19978;&#27809;&#26377;&#21306;&#21035;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#21160;&#24577;&#31995;&#32479;&#30340;&#30456;&#20851;&#38271;&#24230;&#21644;&#26679;&#26412;&#25968;&#23545;&#20110;&#22312;&#36825;&#26679;&#30340;&#31995;&#32479;&#20013;&#29983;&#25104;&#30340;&#20449;&#21495;&#21464;&#37327;&#20013;&#21306;&#20998;&#22122;&#22768;&#21464;&#37327;&#30340;&#23454;&#38469;&#23450;&#20041;&#33267;&#20851;&#37325;&#35201;&#12290;&#30001;&#20110;&#20855;&#26377;&#30701;&#26399;&#30456;&#20851;&#24615;&#30340;&#21464;&#37327;&#38543;&#30528;&#26679;&#26412;&#25968;&#30340;&#20943;&#23569;&#20250;&#26356;&#24555;&#22320;&#36798;&#21040;&#27491;&#24577;&#20998;&#24067;&#65292;&#22240;&#27492;&#23427;&#20204;&#34987;&#35748;&#20026;&#26159;&#8220;&#31867;&#20284;&#20110;&#22122;&#22768;&#8221;&#30340;&#21464;&#37327;&#65292;&#32780;&#20855;&#26377;&#30456;&#21453;&#29305;&#24615;&#30340;&#21464;&#37327;&#21017;&#26159;&#8220;&#31867;&#20284;&#20110;&#20449;&#21495;&#8221;&#30340;&#21464;&#37327;&#12290;&#27491;&#24577;&#24615;&#26816;&#39564;&#19981;&#36866;&#29992;&#20110;&#23567;&#26679;&#26412;&#21644;&#39640;&#32500;&#25968;&#25454;&#65292;&#22240;&#27492;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26679;&#26412;&#21644;&#20854;&#37051;&#23621;&#20043;&#38388;&#30456;&#23545;&#36317;&#31163;&#30340;&#26032;&#26041;&#27861;&#26469;&#35782;&#21035;&#8220;&#31867;&#20284;&#20110;&#22122;&#22768;&#8221;&#30340;&#21464;&#37327;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#22312;&#19981;&#36827;&#34892;&#20219;&#20309;&#20449;&#21495;&#24314;&#27169;&#30340;&#24773;&#20917;&#19979;&#35782;&#21035;&#8220;&#31867;&#20284;&#20110;&#20449;&#21495;&#8221;&#30340;&#21464;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
When there are signals and noises, physicists try to identify signals by modeling them, whereas statisticians oppositely try to model noise to identify signals. In this study, we applied the statisticians' concept of signal detection of physics data with small-size samples and high dimensions without modeling the signals. Most of the data in nature, whether noises or signals, are assumed to be generated by dynamical systems; thus, there is essentially no distinction between these generating processes. We propose that the correlation length of a dynamical system and the number of samples are crucial for the practical definition of noise variables among the signal variables generated by such a system. Since variables with short-term correlations reach normal distributions faster as the number of samples decreases, they are regarded to be ``noise-like'' variables, whereas variables with opposite properties are ``signal-like'' variables. Normality tests are not effective for data of small-
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32508;&#21512;&#30340;&#12289;&#22810;&#38454;&#27573;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#21033;&#29992;&#20998;&#20301;&#25968;&#22238;&#24402;&#26862;&#26519;&#29983;&#25104;&#21306;&#38388;&#39044;&#27979;&#26469;&#35299;&#20915;&#39044;&#27979;&#27969;&#31243;&#30417;&#25511;&#20013;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#20351;&#29992;SHapley&#21487;&#21152;&#35299;&#37322;&#26469;&#35299;&#37322;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;&#26469;&#28304;&#12290;</title><link>http://arxiv.org/abs/2304.06412</link><description>&lt;p&gt;
&#37327;&#21270;&#21644;&#35299;&#37322;&#39044;&#27979;&#27969;&#31243;&#30417;&#25511;&#20013;&#30340;&#26426;&#22120;&#23398;&#20064;&#19981;&#30830;&#23450;&#24615;&#65306;&#36816;&#31609;&#23398;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Quantifying and Explaining Machine Learning Uncertainty in Predictive Process Monitoring: An Operations Research Perspective. (arXiv:2304.06412v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06412
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32508;&#21512;&#30340;&#12289;&#22810;&#38454;&#27573;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#21033;&#29992;&#20998;&#20301;&#25968;&#22238;&#24402;&#26862;&#26519;&#29983;&#25104;&#21306;&#38388;&#39044;&#27979;&#26469;&#35299;&#20915;&#39044;&#27979;&#27969;&#31243;&#30417;&#25511;&#20013;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#20351;&#29992;SHapley&#21487;&#21152;&#35299;&#37322;&#26469;&#35299;&#37322;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;&#26469;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#32508;&#21512;&#30340;&#12289;&#22810;&#38454;&#27573;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#26377;&#25928;&#22320;&#23558;&#20449;&#24687;&#31995;&#32479;&#21644;&#20154;&#24037;&#26234;&#33021;&#34701;&#21512;&#65292;&#20197;&#22686;&#24378;&#36816;&#31609;&#23398;&#39046;&#22495;&#20869;&#30340;&#20915;&#31574;&#36807;&#31243;&#12290;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#24039;&#22937;&#22320;&#35299;&#20915;&#20102;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#26222;&#36941;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#27604;&#22914;&#24573;&#30053;&#20851;&#38190;&#29983;&#20135;&#21442;&#25968;&#30340;&#25968;&#25454;&#39537;&#21160;&#20272;&#35745;&#12289;&#20165;&#29983;&#25104;&#28857;&#39044;&#27979;&#32780;&#19981;&#32771;&#34385;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#20197;&#21450;&#32570;&#20047;&#20851;&#20110;&#36825;&#31181;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#30340;&#35299;&#37322;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20998;&#20301;&#25968;&#22238;&#24402;&#26862;&#26519;&#29983;&#25104;&#21306;&#38388;&#39044;&#27979;&#65292;&#21516;&#26102;&#20351;&#29992;&#26412;&#22320;&#21644;&#20840;&#23616;&#21464;&#20307;&#30340;SHapley&#21487;&#21152;&#35299;&#37322;&#26469;&#35299;&#20915;&#30740;&#31350;&#30340;&#39044;&#27979;&#24615;&#36807;&#31243;&#30417;&#25511;&#38382;&#39064;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#19968;&#20010;&#30495;&#23454;&#30340;&#29983;&#20135;&#35745;&#21010;&#26696;&#20363;&#20013;&#24471;&#21040;&#20102;&#23454;&#38469;&#24212;&#29992;&#65292;&#24182;&#24378;&#35843;&#20102;&#35268;&#23450;&#24615;&#20998;&#26512;&#22312;&#31934;&#32454;&#21270;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#28508;&#21147;&#12290;&#26412;&#25991;&#24378;&#35843;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a comprehensive, multi-stage machine learning methodology that effectively integrates information systems and artificial intelligence to enhance decision-making processes within the domain of operations research. The proposed framework adeptly addresses common limitations of existing solutions, such as the neglect of data-driven estimation for vital production parameters, exclusive generation of point forecasts without considering model uncertainty, and lacking explanations regarding the sources of such uncertainty. Our approach employs Quantile Regression Forests for generating interval predictions, alongside both local and global variants of SHapley Additive Explanations for the examined predictive process monitoring problem. The practical applicability of the proposed methodology is substantiated through a real-world production planning case study, emphasizing the potential of prescriptive analytics in refining decision-making procedures. This paper accentuates
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26680;&#22238;&#24402;&#30340;&#23545;&#25239;&#35757;&#32451;&#21644;&#24102;&#22122;&#22768;&#30340;&#25968;&#25454;&#22686;&#24378;&#65292;&#21457;&#29616;&#22914;&#26524;&#27809;&#26377;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#21487;&#33021;&#20250;&#23548;&#33268;&#36807;&#25311;&#21512;&#29616;&#35937;&#65292;&#20294;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#21487;&#20197;&#32531;&#35299;&#36825;&#31181;&#29616;&#35937;&#65292;&#25552;&#39640;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.06326</link><description>&lt;p&gt;
&#29702;&#35299;&#26680;&#22238;&#24402;&#23545;&#25239;&#35757;&#32451;&#20013;&#30340;&#36807;&#25311;&#21512;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
Understanding Overfitting in Adversarial Training in Kernel Regression. (arXiv:2304.06326v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06326
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26680;&#22238;&#24402;&#30340;&#23545;&#25239;&#35757;&#32451;&#21644;&#24102;&#22122;&#22768;&#30340;&#25968;&#25454;&#22686;&#24378;&#65292;&#21457;&#29616;&#22914;&#26524;&#27809;&#26377;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#21487;&#33021;&#20250;&#23548;&#33268;&#36807;&#25311;&#21512;&#29616;&#35937;&#65292;&#20294;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#21487;&#20197;&#32531;&#35299;&#36825;&#31181;&#29616;&#35937;&#65292;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#35757;&#32451;&#21644;&#24102;&#22122;&#22768;&#30340;&#25968;&#25454;&#22686;&#24378;&#26159;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#24615;&#33021;&#30340;&#24120;&#35265;&#26041;&#27861;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20877;&#29983;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#20013;&#27491;&#21017;&#21270;&#22238;&#24402;&#30340;&#23545;&#25239;&#35757;&#32451;&#21644;&#24102;&#22122;&#22768;&#30340;&#25968;&#25454;&#22686;&#24378;&#12290;&#24403;&#25915;&#20987;&#21644;&#22122;&#22768;&#22823;&#23567;&#20197;&#21450;&#27491;&#21017;&#21270;&#21442;&#25968;&#36235;&#21521;&#20110;&#38646;&#26102;&#65292;&#24314;&#31435;&#20102;&#36825;&#20123;&#25216;&#26415;&#30340;&#26497;&#38480;&#20844;&#24335;&#12290;&#26681;&#25454;&#35813;&#26497;&#38480;&#20844;&#24335;&#65292;&#20998;&#26512;&#20102;&#29305;&#23450;&#24773;&#20917;&#24182;&#35777;&#26126;&#20102;&#65292;&#22914;&#26524;&#27809;&#26377;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#21487;&#33021;&#20855;&#26377;&#22823;&#20110;&#26631;&#20934;&#26680;&#22238;&#24402;&#30340;&#24191;&#20041;&#35823;&#24046;&#21644;Lipschitz&#24120;&#25968;&#12290;&#28982;&#32780;&#65292;&#36890;&#36807;&#36873;&#25321;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#21442;&#25968;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#21487;&#20197;&#20248;&#20110;&#26631;&#20934;&#26680;&#22238;&#24402;&#65292;&#36798;&#21040;&#26356;&#23567;&#30340;&#24191;&#20041;&#35823;&#24046;&#21644;Lipschitz&#24120;&#25968;&#12290;&#36825;&#20123;&#21457;&#29616;&#25903;&#25345;&#23545;&#25239;&#35757;&#32451;&#21487;&#33021;&#23548;&#33268;&#36807;&#25311;&#21512;&#30340;&#32463;&#39564;&#35266;&#23519;&#65292;&#20197;&#21450;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#33021;&#22815;&#32531;&#35299;&#36825;&#31181;&#36807;&#25311;&#21512;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial training and data augmentation with noise are widely adopted techniques to enhance the performance of neural networks. This paper investigates adversarial training and data augmentation with noise in the context of regularized regression in a reproducing kernel Hilbert space (RKHS). We establish the limiting formula for these techniques as the attack and noise size, as well as the regularization parameter, tend to zero. Based on this limiting formula, we analyze specific scenarios and demonstrate that, without appropriate regularization, these two methods may have larger generalization error and Lipschitz constant than standard kernel regression. However, by selecting the appropriate regularization parameter, these two methods can outperform standard kernel regression and achieve smaller generalization error and Lipschitz constant. These findings support the empirical observations that adversarial training can lead to overfitting, and appropriate regularization methods, suc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#38543;&#26426;&#32771;&#35797;&#35780;&#20998;&#31639;&#27861;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;&#26368;&#22823;&#20284;&#28982;&#35780;&#20998;&#31639;&#27861;Maximal-margin algorithm&#65292;&#21033;&#29992;Bradley-Terry-Luce&#27169;&#22411;&#36827;&#34892;&#35780;&#20998;&#12290;&#22312;&#23454;&#39564;&#21644;&#27169;&#25311;&#20013;&#65292;&#30456;&#36739;&#20110;&#31616;&#21333;&#24179;&#22343;&#26041;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#39044;&#27979;&#31934;&#20934;&#24230;&#21644;&#20844;&#24179;&#24615;&#26041;&#38754;&#34920;&#29616;&#26356;&#20248;&#12290;</title><link>http://arxiv.org/abs/2304.06254</link><description>&lt;p&gt;
&#38754;&#21521;&#38543;&#26426;&#32771;&#35797;&#30340;&#20844;&#24179;&#35780;&#20998;&#31639;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Fair Grading Algorithms for Randomized Exams. (arXiv:2304.06254v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06254
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#38543;&#26426;&#32771;&#35797;&#35780;&#20998;&#31639;&#27861;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;&#26368;&#22823;&#20284;&#28982;&#35780;&#20998;&#31639;&#27861;Maximal-margin algorithm&#65292;&#21033;&#29992;Bradley-Terry-Luce&#27169;&#22411;&#36827;&#34892;&#35780;&#20998;&#12290;&#22312;&#23454;&#39564;&#21644;&#27169;&#25311;&#20013;&#65292;&#30456;&#36739;&#20110;&#31616;&#21333;&#24179;&#22343;&#26041;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#39044;&#27979;&#31934;&#20934;&#24230;&#21644;&#20844;&#24179;&#24615;&#26041;&#38754;&#34920;&#29616;&#26356;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#32771;&#35797;&#30340;&#35780;&#20998;&#31639;&#27861;&#12290;&#22312;&#38543;&#26426;&#32771;&#35797;&#20013;&#65292;&#27599;&#20010;&#23398;&#29983;&#38656;&#22238;&#31572;&#26469;&#33258;&#36739;&#22823;&#39064;&#24211;&#30340;&#38543;&#26426;&#39064;&#30446;&#65292;&#35780;&#20998;&#35268;&#21017;&#36890;&#24120;&#37319;&#29992;&#31616;&#21333;&#24179;&#22343;&#30340;&#26041;&#24335;&#65292;&#21363;&#35745;&#31639;&#27599;&#20010;&#23398;&#29983;&#22238;&#31572;&#30340;&#39064;&#30446;&#24471;&#20998;&#30340;&#24179;&#22343;&#20540;&#12290;&#34429;&#28982;&#36825;&#31181;&#26041;&#24335;&#22312;&#38543;&#26426;&#36873;&#25321;&#39064;&#30446;&#26102;&#26159;&#20844;&#24179;&#30340;&#65292;&#20294;&#22312;&#20855;&#20307;&#31572;&#39064;&#24773;&#22659;&#20013;&#24182;&#19981;&#20844;&#24179;&#12290;&#20844;&#24179;&#35780;&#20998;&#38382;&#39064;&#26159;&#35201;&#35780;&#20272;&#27599;&#20010;&#23398;&#29983;&#22312;&#20840;&#39064;&#24211;&#19978;&#30340;&#24179;&#22343;&#25104;&#32489;&#12290;&#26412;&#25991;&#20351;&#29992;&#30340;Maximal-margin algorithm&#21487;&#29992;&#20110;&#20256;&#32479;&#30340;Bradley-Terry-Luce&#27169;&#22411;&#12290;&#32463;&#36807;&#23454;&#35777;&#30740;&#31350;&#21644;&#27169;&#25311;&#39564;&#35777;&#65292;&#22312;&#23567;&#29677;&#32423;&#21644;&#32771;&#35797;&#30340;&#31934;&#24230;&#21644;&#20844;&#24179;&#24615;&#26041;&#38754;&#65292;&#25105;&#20204;&#30340;&#35780;&#20998;&#31639;&#27861;&#26126;&#26174;&#20248;&#20110;&#31616;&#21333;&#24179;&#22343;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies grading algorithms for randomized exams. In a randomized exam, each student is asked a small number of random questions from a large question bank. The predominant grading rule is simple averaging, i.e., calculating grades by averaging scores on the questions each student is asked, which is fair ex-ante, over the randomized questions, but not fair ex-post, on the realized questions. The fair grading problem is to estimate the average grade of each student on the full question bank. The maximum-likelihood estimator for the Bradley-Terry-Luce model on the bipartite student-question graph is shown to be consistent with high probability when the number of questions asked to each student is at least the cubed-logarithm of the number of students. In an empirical study on exam data and in simulations, our algorithm based on the maximum-likelihood estimator significantly outperforms simple averaging in prediction accuracy and ex-post fairness even with a small class and exam
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35814;&#32454;&#20171;&#32461;&#20102;&#19968;&#31181;&#26131;&#20110;&#23454;&#26045;&#30340;MCMC&#31639;&#27861;IIT&#21450;&#20854;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#30340;&#24212;&#29992;&#12290;&#35813;&#31639;&#27861;&#22987;&#32456;&#25509;&#21463;&#26377;&#20449;&#24687;&#30340;&#25552;&#35758;&#65292;&#21487;&#19982;&#20854;&#20182;MCMC&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#24182;&#24102;&#26469;&#26032;&#30340;&#20248;&#21270;&#25277;&#26679;&#22120;&#30340;&#26426;&#20250;&#12290;</title><link>http://arxiv.org/abs/2304.06251</link><description>&lt;p&gt;
&#23454;&#29992;&#25351;&#21335;&#65306;&#20851;&#20110;&#30693;&#24773;&#37325;&#35201;&#24615;&#35843;&#33410;&#26041;&#27861;&#30340;&#35814;&#32454;&#20171;&#32461;
&lt;/p&gt;
&lt;p&gt;
Importance is Important: A Guide to Informed Importance Tempering Methods. (arXiv:2304.06251v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06251
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35814;&#32454;&#20171;&#32461;&#20102;&#19968;&#31181;&#26131;&#20110;&#23454;&#26045;&#30340;MCMC&#31639;&#27861;IIT&#21450;&#20854;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#30340;&#24212;&#29992;&#12290;&#35813;&#31639;&#27861;&#22987;&#32456;&#25509;&#21463;&#26377;&#20449;&#24687;&#30340;&#25552;&#35758;&#65292;&#21487;&#19982;&#20854;&#20182;MCMC&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#24182;&#24102;&#26469;&#26032;&#30340;&#20248;&#21270;&#25277;&#26679;&#22120;&#30340;&#26426;&#20250;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#24773;&#37325;&#35201;&#24615;&#35843;&#33410; (IIT) &#26159;&#19968;&#31181;&#26131;&#20110;&#23454;&#26045;&#30340;MCMC&#31639;&#27861;&#65292;&#21487;&#35270;&#20026;&#36890;&#24120;&#30340;Metropolis-Hastings&#31639;&#27861;&#30340;&#25193;&#23637;&#65292;&#20855;&#26377;&#22987;&#32456;&#25509;&#21463;&#26377;&#20449;&#24687;&#30340;&#25552;&#35758;&#30340;&#29305;&#27530;&#21151;&#33021;&#65292;&#22312;Zhou&#21644;Smith&#65288;2022&#24180;&#65289;&#30340;&#30740;&#31350;&#20013;&#34920;&#26126;&#22312;&#19968;&#20123;&#24120;&#35265;&#24773;&#20917;&#19979;&#25910;&#25947;&#26356;&#24555;&#12290;&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#20010;&#26032;&#30340;&#12289;&#20840;&#38754;&#30340;&#25351;&#21335;&#65292;&#20171;&#32461;&#20102;IIT&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#30340;&#24212;&#29992;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;IIT&#26041;&#26696;&#65292;&#36825;&#20123;&#26041;&#26696;&#22312;&#31163;&#25955;&#31354;&#38388;&#19978;&#30340;&#36816;&#34892;&#36895;&#24230;&#27604;&#29616;&#26377;&#30340;&#30693;&#24773;MCMC&#26041;&#27861;&#26356;&#24555;&#65292;&#22240;&#20026;&#23427;&#20204;&#19981;&#38656;&#35201;&#35745;&#31639;&#25152;&#26377;&#30456;&#37051;&#29366;&#24577;&#30340;&#21518;&#39564;&#27010;&#29575;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#23558;IIT&#19982;&#20854;&#20182;MCMC&#25216;&#26415;&#65288;&#21253;&#25324;&#27169;&#25311;&#22238;&#28779;&#12289;&#20266;&#36793;&#32536;&#21644;&#22810;&#37325;&#23581;&#35797;&#26041;&#27861;&#65292;&#22312;&#19968;&#33324;&#29366;&#24577;&#31354;&#38388;&#19978;&#23454;&#26045;&#20026;Metropolis-Hastings&#26041;&#26696;&#65292;&#21487;&#33021;&#36973;&#21463;&#20302;&#25509;&#21463;&#29575;&#30340;&#38382;&#39064;&#65289;&#36827;&#34892;&#20102;&#25972;&#21512;&#12290;&#20351;&#29992;IIT&#20351;&#25105;&#20204;&#33021;&#22815;&#22987;&#32456;&#25509;&#21463;&#25552;&#35758;&#65292;&#24182;&#24102;&#26469;&#20102;&#20248;&#21270;&#25277;&#26679;&#22120;&#30340;&#26032;&#26426;&#20250;&#65292;&#36825;&#26159;&#22312;Metropolis-Hastings&#31639;&#27861;&#19979;&#19981;&#21487;&#33021;&#30340;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#23454;&#29992;&#30340;&#25351;&#21335;&#65292;&#20197;&#36873;&#25321;IIT&#26041;&#26696;&#21644;&#35843;&#25972;&#31639;&#27861;&#21442;&#25968;&#12290;&#23545;&#21508;&#31181;&#27169;&#22411;&#30340;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;&#25105;&#20204;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Informed importance tempering (IIT) is an easy-to-implement MCMC algorithm that can be seen as an extension of the familiar Metropolis-Hastings algorithm with the special feature that informed proposals are always accepted, and which was shown in Zhou and Smith (2022) to converge much more quickly in some common circumstances. This work develops a new, comprehensive guide to the use of IIT in many situations. First, we propose two IIT schemes that run faster than existing informed MCMC methods on discrete spaces by not requiring the posterior evaluation of all neighboring states. Second, we integrate IIT with other MCMC techniques, including simulated tempering, pseudo-marginal and multiple-try methods (on general state spaces), which have been conventionally implemented as Metropolis-Hastings schemes and can suffer from low acceptance rates. The use of IIT allows us to always accept proposals and brings about new opportunities for optimizing the sampler which are not possible under th
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#20351;&#29992;&#26080;&#20998;&#24067;&#20449;&#36182;&#24102;&#30340; uniform conformal inference &#31639;&#27861;&#65292;&#23454;&#29616;&#20219;&#24847;&#25968;&#25454;&#30456;&#20851;&#35823;&#35206;&#30422;&#27700;&#24179;&#30340;&#26377;&#38480;&#26679;&#26412;&#39044;&#27979;&#20445;&#35777;&#30340;&#32479;&#19968;&#19968;&#33268;&#24615;&#25512;&#29702;&#12290;</title><link>http://arxiv.org/abs/2304.06158</link><description>&lt;p&gt;
&#20026;&#19968;&#33268;&#24615;&#39044;&#27979;&#30340;&#21518;&#36873;&#25512;&#29702;&#65306;&#26435;&#34913;&#31934;&#24230;&#21644;&#35206;&#30422;&#33539;&#22260;
&lt;/p&gt;
&lt;p&gt;
Post-selection Inference for Conformal Prediction: Trading off Coverage for Precision. (arXiv:2304.06158v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06158
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#20351;&#29992;&#26080;&#20998;&#24067;&#20449;&#36182;&#24102;&#30340; uniform conformal inference &#31639;&#27861;&#65292;&#23454;&#29616;&#20219;&#24847;&#25968;&#25454;&#30456;&#20851;&#35823;&#35206;&#30422;&#27700;&#24179;&#30340;&#26377;&#38480;&#26679;&#26412;&#39044;&#27979;&#20445;&#35777;&#30340;&#32479;&#19968;&#19968;&#33268;&#24615;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#33268;&#24615;&#25512;&#29702;&#22312;&#20026;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#30340;&#40657;&#30418;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#31639;&#27861;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#19978;&#21457;&#25381;&#20102;&#37325;&#35201;&#20316;&#29992;&#12290;&#20256;&#32479;&#19978;&#65292;&#19968;&#33268;&#24615;&#39044;&#27979;&#25512;&#29702;&#38656;&#35201;&#29420;&#31435;&#20110;&#25968;&#25454;&#30340;&#38169;&#35823;&#35206;&#30422;&#27700;&#24179;&#35268;&#33539;&#12290;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#20154;&#20204;&#21487;&#33021;&#20250;&#22312;&#35745;&#31639;&#20986;&#39044;&#27979;&#38598;&#20043;&#21518;&#26356;&#26032;&#38169;&#35823;&#35206;&#30422;&#27700;&#24179;&#12290;&#20363;&#22914;&#65292;&#22312;&#20108;&#20803;&#20998;&#31867;&#30340;&#24773;&#20917;&#19979;&#65292;&#20998;&#26512;&#20154;&#21592;&#21487;&#33021;&#20250;&#20174;&#19968;&#20010;95&#65285;&#30340;&#39044;&#27979;&#38598;&#24320;&#22987;&#65292;&#24182;&#21457;&#29616;&#22823;&#22810;&#25968;&#39044;&#27979;&#38598;&#21253;&#21547;&#25152;&#26377;&#36755;&#20986;&#31867;&#21035;&#12290;&#22914;&#26524;&#20004;&#20010;&#31867;&#21035;&#37117;&#19981;&#21487;&#21462;&#65292;&#20998;&#26512;&#20154;&#21592;&#21487;&#33021;&#20250;&#32771;&#34385;80&#65285;&#30340;&#39044;&#27979;&#38598;&#12290;&#20855;&#26377;&#25968;&#25454;&#30456;&#20851;&#30340;&#35823;&#35206;&#30422;&#27700;&#24179;&#21644;&#20445;&#35777;&#35206;&#30422;&#33539;&#22260;&#30340;&#39044;&#27979;&#38598;&#30340;&#26500;&#24314;&#21487;&#20197;&#34987;&#35748;&#20026;&#26159;&#19968;&#20010;&#21518;&#36873;&#25512;&#29702;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#26080;&#20998;&#24067;&#20449;&#36182;&#24102;&#65292;&#24320;&#21457;&#20102;&#20855;&#26377;&#20219;&#24847;&#25968;&#25454;&#30456;&#20851;&#35823;&#35206;&#30422;&#27700;&#24179;&#30340;&#26377;&#38480;&#26679;&#26412;&#39044;&#27979;&#20445;&#35777;&#30340;&#32479;&#19968;&#19968;&#33268;&#24615;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conformal inference has played a pivotal role in providing uncertainty quantification for black-box ML prediction algorithms with finite sample guarantees. Traditionally, conformal prediction inference requires a data-independent specification of miscoverage level. In practical applications, one might want to update the miscoverage level after computing the prediction set. For example, in the context of binary classification, the analyst might start with a $95\%$ prediction sets and see that most prediction sets contain all outcome classes. Prediction sets with both classes being undesirable, the analyst might desire to consider, say $80\%$ prediction set. Construction of prediction sets that guarantee coverage with data-dependent miscoverage level can be considered as a post-selection inference problem. In this work, we develop uniform conformal inference with finite sample prediction guarantee with arbitrary data-dependent miscoverage levels using distribution-free confidence bands f
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#33021;&#37327;&#22522;&#30784;&#27169;&#22411;&#21644;&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#35299;&#20915;&#29983;&#25104;&#24314;&#27169;&#38382;&#39064;&#12290;&#25105;&#20204;&#22312;2D&#24773;&#26223;&#21644;&#22270;&#20687;&#21040;&#22270;&#20687;&#32763;&#35793;&#38382;&#39064;&#20013;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.06094</link><description>&lt;p&gt;
&#33021;&#37327;&#24341;&#23548;&#30340;&#29109;&#31070;&#32463;&#26368;&#20248;&#36755;&#36816;
&lt;/p&gt;
&lt;p&gt;
Energy-guided Entropic Neural Optimal Transport. (arXiv:2304.06094v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06094
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#33021;&#37327;&#22522;&#30784;&#27169;&#22411;&#21644;&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#35299;&#20915;&#29983;&#25104;&#24314;&#27169;&#38382;&#39064;&#12290;&#25105;&#20204;&#22312;2D&#24773;&#26223;&#21644;&#22270;&#20687;&#21040;&#22270;&#20687;&#32763;&#35793;&#38382;&#39064;&#20013;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#37327;&#22522;&#30784;&#27169;&#22411;&#65288;EBMs&#65289;&#22312;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#24050;&#32463;&#26377;&#25968;&#21313;&#24180;&#30340;&#21382;&#21490;&#12290;&#33258;&#20004;&#21315;&#24180;&#20195;&#36215;&#65292;&#19968;&#30452;&#26377;&#24456;&#22810;&#39640;&#25928;&#30340;&#26041;&#27861;&#36890;&#36807;&#33021;&#37327;&#21183;&#65288;&#38750;&#24402;&#19968;&#21270;&#30340;&#20284;&#28982;&#20989;&#25968;&#65289;&#26469;&#35299;&#20915;&#29983;&#25104;&#24314;&#27169;&#38382;&#39064;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#26368;&#20248;&#36755;&#36816;&#65288;OT&#65289;&#39046;&#22495;&#65292;&#23588;&#20854;&#26159;&#31070;&#32463;OT&#27714;&#35299;&#22120;&#65292;&#21463;&#21040;&#30340;&#25506;&#32034;&#35201;&#23569;&#24471;&#22810;&#65292;&#20165;&#26377;&#19968;&#20123;&#36817;&#26399;&#30340;&#30740;&#31350;&#65288;&#19981;&#21253;&#25324;&#21033;&#29992;OT&#20316;&#20026;&#25439;&#22833;&#20989;&#25968;&#26469;&#35299;&#20915;&#38382;&#39064;&#30340;WGAN&#26041;&#27861;&#65289;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24357;&#21512;&#20102;EBMs&#21644;&#29109;&#27491;&#21017;&#21270;OT&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#20801;&#35768;&#21033;&#29992;&#21069;&#32773;&#30340;&#26368;&#26032;&#21457;&#23637;&#21644;&#25216;&#26415;&#25913;&#36827;&#26469;&#20016;&#23500;&#21518;&#32773;&#12290;&#25105;&#20204;&#22312;2D&#24773;&#26223;&#21644;&#26631;&#20934;&#30340;&#22270;&#20687;&#21040;&#22270;&#20687;&#32763;&#35793;&#38382;&#39064;&#20013;&#39564;&#35777;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#12290;&#20026;&#31616;&#21333;&#36215;&#35265;&#65292;&#25105;&#20204;&#36873;&#25321;&#20102;&#31616;&#30701;&#21644;&#38271;&#36305;&#30340;EBMs&#12290;
&lt;/p&gt;
&lt;p&gt;
Energy-Based Models (EBMs) are known in the Machine Learning community for the decades. Since the seminal works devoted to EBMs dating back to the noughties there have been appearing a lot of efficient methods which solve the generative modelling problem by means of energy potentials (unnormalized likelihood functions). In contrast, the realm of Optimal Transport (OT) and, in particular, neural OT solvers is much less explored and limited by few recent works (excluding WGAN based approaches which utilize OT as a loss function and do not model OT maps themselves). In our work, we bridge the gap between EBMs and Entropy-regularized OT. We present the novel methodology which allows utilizing the recent developments and technical improvements of the former in order to enrich the latter. We validate the applicability of our method on toy 2D scenarios as well as standard unpaired image-to-image translation problems. For the sake of simplicity, we choose simple short- and long- run EBMs as a 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#21453;&#23556;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#21453;&#23556;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#25200;&#21160;&#35780;&#20998;&#20989;&#25968;&#65292;&#23558;&#25968;&#25454;&#32422;&#26463;&#21407;&#21017;&#24615;&#22320;&#25972;&#21512;&#21040;&#29983;&#25104;&#36807;&#31243;&#20013;&#65292;&#20197;&#21462;&#20195;&#20043;&#21069;&#37319;&#29992;&#30340;&#23548;&#33268;&#19981;&#33258;&#28982;&#26679;&#26412;&#30340;&#38408;&#20540;&#22788;&#29702;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2304.04740</link><description>&lt;p&gt;
&#21453;&#23556;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Reflected Diffusion Models. (arXiv:2304.04740v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04740
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#21453;&#23556;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#21453;&#23556;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#25200;&#21160;&#35780;&#20998;&#20989;&#25968;&#65292;&#23558;&#25968;&#25454;&#32422;&#26463;&#21407;&#21017;&#24615;&#22320;&#25972;&#21512;&#21040;&#29983;&#25104;&#36807;&#31243;&#20013;&#65292;&#20197;&#21462;&#20195;&#20043;&#21069;&#37319;&#29992;&#30340;&#23548;&#33268;&#19981;&#33258;&#28982;&#26679;&#26412;&#30340;&#38408;&#20540;&#22788;&#29702;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20998;&#25968;&#30340;&#25193;&#25955;&#27169;&#22411;&#23398;&#20064;&#23558;&#25968;&#25454;&#26144;&#23556;&#21040;&#22122;&#22768;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#21453;&#21521;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#22797;&#26434;&#20219;&#21153;&#65292;&#25968;&#20540;&#35823;&#24046;&#21487;&#20197;&#32047;&#31215;&#24182;&#23548;&#33268;&#39640;&#24230;&#19981;&#33258;&#28982;&#30340;&#26679;&#26412;&#12290;&#20197;&#21069;&#30340;&#24037;&#20316;&#36890;&#36807;&#38408;&#20540;&#22788;&#29702;&#26469;&#32531;&#35299;&#28418;&#31227;&#65292;&#27599;&#27425;&#25193;&#25955;&#27493;&#39588;&#21518;&#25237;&#24433;&#21040;&#33258;&#28982;&#25968;&#25454;&#22495;&#65288;&#20363;&#22914;&#22270;&#20687;&#30340;&#20687;&#32032;&#31354;&#38388;&#65289;&#65292;&#20294;&#36825;&#23548;&#33268;&#35757;&#32451;&#21644;&#29983;&#25104;&#36807;&#31243;&#20043;&#38388;&#23384;&#22312;&#19981;&#21305;&#37197;&#12290;&#20026;&#20102;&#20197;&#19968;&#31181;&#21407;&#21017;&#24615;&#30340;&#26041;&#24335;&#21512;&#24182;&#25968;&#25454;&#32422;&#26463;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21453;&#23556;&#25193;&#25955;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21453;&#21521;&#28436;&#21270;&#22312;&#25968;&#25454;&#25903;&#25345;&#30340;&#21453;&#23556;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#19978;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#19968;&#33324;&#21270;&#30340;&#20998;&#25968;&#21305;&#37197;&#25439;&#22833;&#20989;&#25968;&#23398;&#20064;&#25200;&#21160;&#35780;&#20998;&#20989;&#25968;&#65292;&#24182;&#25193;&#23637;&#20102;&#26631;&#20934;&#25193;&#25955;&#27169;&#22411;&#30340;&#20851;&#38190;&#32452;&#20214;&#65292;&#21253;&#25324;&#25193;&#25955;&#24341;&#23548;&#12289;&#22522;&#20110;&#20284;&#28982;&#30340;&#35757;&#32451;&#21644;ODE&#37319;&#26679;&#12290;&#25105;&#20204;&#36824;&#24357;&#21512;&#20102;&#38408;&#20540;&#22788;&#29702;&#30340;&#29702;&#35770;&#24046;&#36317;:&#36825;&#26679;&#30340;&#26041;&#26696;&#21482;&#26159;&#21453;&#23556;SDE&#30340;&#31163;&#25955;&#21270;&#12290;&#22312;&#26631;&#20934;&#22270;&#20687;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#25105;&#20204;&#30340;
&lt;/p&gt;
&lt;p&gt;
Score-based diffusion models learn to reverse a stochastic differential equation that maps data to noise. However, for complex tasks, numerical error can compound and result in highly unnatural samples. Previous work mitigates this drift with thresholding, which projects to the natural data domain (such as pixel space for images) after each diffusion step, but this leads to a mismatch between the training and generative processes. To incorporate data constraints in a principled manner, we present Reflected Diffusion Models, which instead reverse a reflected stochastic differential equation evolving on the support of the data. Our approach learns the perturbed score function through a generalize score matching loss and extends key components of standard diffusion models including diffusion guidance, likelihood-based training, and ODE sampling. We also bridge the theoretical gap with thresholding: such schemes are just discretizations of reflected SDEs. On standard image benchmarks, our 
&lt;/p&gt;</description></item><item><title>PriorCVAE &#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564; MCMC &#21442;&#25968;&#25512;&#26029;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#29983;&#25104;&#24314;&#27169;&#26032;&#26041;&#27861;&#65292;&#21487;&#36890;&#36807;&#23558; VAE &#24314;&#27169;&#26465;&#20214;&#21270;&#20110;&#38543;&#26426;&#36807;&#31243;&#36229;&#21442;&#25968;&#22788;&#29702;&#36229;&#21442;&#25968;&#25512;&#26029;&#19982;&#23398;&#20064;&#20808;&#39564;&#20043;&#38388;&#30340;&#20449;&#24687;&#27969;&#26029;&#35010;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2304.04307</link><description>&lt;p&gt;
PriorCVAE: &#22522;&#20110;&#36125;&#21494;&#26031;&#28145;&#24230;&#29983;&#25104;&#24314;&#27169;&#30340;&#21487;&#25193;&#23637; MCMC &#21442;&#25968;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
PriorCVAE: scalable MCMC parameter inference with Bayesian deep generative modelling. (arXiv:2304.04307v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04307
&lt;/p&gt;
&lt;p&gt;
PriorCVAE &#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564; MCMC &#21442;&#25968;&#25512;&#26029;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#29983;&#25104;&#24314;&#27169;&#26032;&#26041;&#27861;&#65292;&#21487;&#36890;&#36807;&#23558; VAE &#24314;&#27169;&#26465;&#20214;&#21270;&#20110;&#38543;&#26426;&#36807;&#31243;&#36229;&#21442;&#25968;&#22788;&#29702;&#36229;&#21442;&#25968;&#25512;&#26029;&#19982;&#23398;&#20064;&#20808;&#39564;&#20043;&#38388;&#30340;&#20449;&#24687;&#27969;&#26029;&#35010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24212;&#29992;&#22330;&#26223;&#20013;&#65292;&#25512;&#29702;&#36895;&#24230;&#21644;&#27169;&#22411;&#28789;&#27963;&#24615;&#33267;&#20851;&#37325;&#35201;&#65292;&#36125;&#21494;&#26031;&#25512;&#26029;&#22312;&#20855;&#26377;&#38543;&#26426;&#36807;&#31243;&#20808;&#39564;&#30340;&#27169;&#22411;&#20013;&#65288;&#22914;&#39640;&#26031;&#36807;&#31243;&#65289;&#34987;&#24191;&#27867;&#24212;&#29992;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#20351;&#29992;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#31561;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#21487;&#20197;&#32534;&#30721;&#30001; GP &#20808;&#39564;&#25110;&#20854;&#26377;&#38480;&#23454;&#29616;&#24341;&#36215;&#30340;&#35745;&#31639;&#29942;&#39048;&#65292;&#24182;&#19988;&#25152;&#23398;&#29983;&#25104;&#22120;&#21487;&#20197;&#20195;&#26367; MCMC &#25512;&#26029;&#20013;&#30340;&#21407;&#22987;&#20808;&#39564;&#12290;&#34429;&#28982;&#27492;&#26041;&#27861;&#23454;&#29616;&#20102;&#24555;&#36895;&#32780;&#39640;&#25928;&#30340;&#25512;&#29702;&#65292;&#20294;&#23427;&#20002;&#22833;&#20102;&#20851;&#20110;&#38543;&#26426;&#36807;&#31243;&#36229;&#21442;&#25968;&#30340;&#20449;&#24687;&#65292;&#23548;&#33268;&#36229;&#21442;&#25968;&#25512;&#26029;&#19981;&#21487;&#33021;&#21644;&#23398;&#21040;&#30340;&#20808;&#39564;&#27169;&#31946;&#19981;&#28165;&#12290;&#25105;&#20204;&#24314;&#35758;&#35299;&#20915;&#19978;&#36848;&#38382;&#39064;&#65292;&#36890;&#36807;&#23558; VAE &#24314;&#27169;&#26465;&#20214;&#21270;&#20110;&#38543;&#26426;&#36807;&#31243;&#36229;&#21442;&#25968;&#65292;&#20197;&#20415;&#36229;&#21442;&#25968;&#19982; GP &#23454;&#29616;&#19968;&#36215;&#36827;&#34892;&#32534;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
In applied fields where the speed of inference and model flexibility are crucial, the use of Bayesian inference for models with a stochastic process as their prior, e.g. Gaussian processes (GPs) is ubiquitous. Recent literature has demonstrated that the computational bottleneck caused by GP priors or their finite realizations can be encoded using deep generative models such as variational autoencoders (VAEs), and the learned generators can then be used instead of the original priors during Markov chain Monte Carlo (MCMC) inference in a drop-in manner. While this approach enables fast and highly efficient inference, it loses information about the stochastic process hyperparameters, and, as a consequence, makes inference over hyperparameters impossible and the learned priors indistinct. We propose to resolve the aforementioned issue and disentangle the learned priors by conditioning the VAE on stochastic process hyperparameters. This way, the hyperparameters are encoded alongside GP real
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#21033;&#29992;&#32447;&#24615;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#65288;LMEM&#65289;&#26469;&#20998;&#26512;&#26426;&#22120;&#23398;&#20064;&#24615;&#33021;&#35780;&#20272;&#20998;&#25968;&#65292;&#24182;&#32771;&#34385;&#22810;&#20010;&#26041;&#24046;&#26469;&#28304;&#21450;&#20854;&#19982;&#25968;&#25454;&#29305;&#24615;&#30456;&#20114;&#20316;&#29992;&#65292;&#20174;&#32780;&#35780;&#20272;&#21487;&#38752;&#24615;&#21644;&#21487;&#22797;&#21046;&#24615;&#65292;&#20419;&#36827;&#23545;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#34892;&#20026;&#30340;&#26356;&#20840;&#38754;&#29702;&#35299;&#12290;</title><link>http://arxiv.org/abs/2302.04054</link><description>&lt;p&gt;
&#36861;&#27714;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#30340;&#25512;&#29702;&#22797;&#29616;&#24615;
&lt;/p&gt;
&lt;p&gt;
Towards Inferential Reproducibility of Machine Learning Research. (arXiv:2302.04054v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04054
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#21033;&#29992;&#32447;&#24615;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#65288;LMEM&#65289;&#26469;&#20998;&#26512;&#26426;&#22120;&#23398;&#20064;&#24615;&#33021;&#35780;&#20272;&#20998;&#25968;&#65292;&#24182;&#32771;&#34385;&#22810;&#20010;&#26041;&#24046;&#26469;&#28304;&#21450;&#20854;&#19982;&#25968;&#25454;&#29305;&#24615;&#30456;&#20114;&#20316;&#29992;&#65292;&#20174;&#32780;&#35780;&#20272;&#21487;&#38752;&#24615;&#21644;&#21487;&#22797;&#21046;&#24615;&#65292;&#20419;&#36827;&#23545;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#34892;&#20026;&#30340;&#26356;&#20840;&#38754;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#35780;&#20272;&#30340;&#21487;&#38752;&#24615;&#8212;&#8212;&#21363;&#22312;&#22797;&#21046;&#30340;&#27169;&#22411;&#35757;&#32451;&#36816;&#34892;&#20013;&#35266;&#23519;&#21040;&#30340;&#35780;&#20272;&#20998;&#25968;&#30340;&#19968;&#33268;&#24615;&#8212;&#8212;&#21463;&#21040;&#20960;&#31181;&#38750;&#30830;&#23450;&#24615;&#26469;&#28304;&#30340;&#24433;&#21709;&#65292;&#21487;&#20197;&#34987;&#35270;&#20026;&#27979;&#37327;&#22122;&#22768;&#12290;&#30446;&#21069;&#30340;&#36235;&#21183;&#26159;&#21435;&#38500;&#22122;&#22768;&#65292;&#20197;&#24378;&#21046;&#30740;&#31350;&#32467;&#26524;&#30340;&#21487;&#22797;&#21046;&#24615;&#65292;&#24573;&#30053;&#20102;&#23454;&#29616;&#23618;&#38754;&#22266;&#26377;&#30340;&#38750;&#30830;&#23450;&#24615;&#20197;&#21450;&#31639;&#27861;&#22122;&#22768;&#22240;&#32032;&#21644;&#25968;&#25454;&#29305;&#24615;&#20043;&#38388;&#30340;&#20851;&#38190;&#30456;&#20114;&#20316;&#29992;&#25928;&#24212;&#12290;&#36825;&#38480;&#21046;&#20102;&#20174;&#36825;&#20123;&#23454;&#39564;&#20013;&#21487;&#20197;&#24471;&#20986;&#30340;&#32467;&#35770;&#33539;&#22260;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#26159;&#23558;&#20960;&#20010;&#26041;&#24046;&#26469;&#28304;&#65292;&#21253;&#25324;&#23427;&#20204;&#19982;&#25968;&#25454;&#29305;&#24615;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#32435;&#20837;&#26426;&#22120;&#23398;&#20064;&#35780;&#20272;&#30340;&#26174;&#33879;&#24615;&#21644;&#21487;&#38752;&#24615;&#20998;&#26512;&#20013;&#65292;&#20197;&#26399;&#20174;&#35757;&#32451;&#27169;&#22411;&#30340;&#29305;&#23450;&#23454;&#20363;&#24471;&#20986;&#25512;&#29702;&#32467;&#35770;, &#32780;&#38750;&#21435;&#38500;&#22122;&#22768;&#12290;&#25105;&#20204;&#23637;&#31034;&#22914;&#20309;&#20351;&#29992;&#32447;&#24615;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#65288;LMEM&#65289;&#26469;&#20998;&#26512;&#24615;&#33021;&#35780;&#20272;&#20998;&#25968;&#65292;&#24182;&#29992;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#31995;&#32479;&#30340;&#26041;&#24335;&#26469;&#32771;&#34385;&#31639;&#27861;&#21644;&#25968;&#25454;&#30456;&#20851;&#30340;&#22122;&#22768;&#26469;&#28304;&#65292;&#24182;&#20351;&#25105;&#20204;&#33021;&#22815;&#37327;&#21270;&#21508;&#20010;&#26041;&#24046;&#26469;&#28304;&#23545;&#26426;&#22120;&#23398;&#20064;&#23454;&#39564;&#30340;&#21487;&#38752;&#24615;&#21644;&#21487;&#22797;&#21046;&#24615;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#28436;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#65292;&#24182;&#35828;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22914;&#20309;&#20419;&#36827;&#23545;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#34892;&#20026;&#30340;&#26356;&#20840;&#38754;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reliability of machine learning evaluation -- the consistency of observed evaluation scores across replicated model training runs -- is affected by several sources of nondeterminism which can be regarded as measurement noise. Current tendencies to remove noise in order to enforce reproducibility of research results neglect inherent nondeterminism at the implementation level and disregard crucial interaction effects between algorithmic noise factors and data properties. This limits the scope of conclusions that can be drawn from such experiments. Instead of removing noise, we propose to incorporate several sources of variance, including their interaction with data properties, into an analysis of significance and reliability of machine learning evaluation, with the aim to draw inferences beyond particular instances of trained models. We show how to use linear mixed effects models (LMEMs) to analyze performance evaluation scores, and to conduct statistical inference with a generalized lik
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;KL&#25955;&#24230;&#30340;&#28145;&#24230;&#23398;&#20064;&#31243;&#24207;&#65292;&#29992;&#20110;&#35299;&#20915;&#29983;&#23384;&#20998;&#26512;&#20013;&#30701;&#25968;&#25454;&#38382;&#39064;&#65292;&#36890;&#36807;&#23558;&#22806;&#37096;&#29983;&#23384;&#39044;&#27979;&#27169;&#22411;&#19982;&#26032;&#25910;&#38598;&#30340;&#26102;&#38388;&#33267;&#20107;&#20214;&#25968;&#25454;&#30456;&#32467;&#21512;&#26469;&#33719;&#24471;&#26356;&#22909;&#30340;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2208.05100</link><description>&lt;p&gt;
&#22522;&#20110;KL&#25955;&#24230;&#30340;&#31163;&#25955;&#26102;&#38388;&#27169;&#22411;&#28145;&#24230;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
KL-divergence Based Deep Learning for Discrete Time Model. (arXiv:2208.05100v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.05100
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;KL&#25955;&#24230;&#30340;&#28145;&#24230;&#23398;&#20064;&#31243;&#24207;&#65292;&#29992;&#20110;&#35299;&#20915;&#29983;&#23384;&#20998;&#26512;&#20013;&#30701;&#25968;&#25454;&#38382;&#39064;&#65292;&#36890;&#36807;&#23558;&#22806;&#37096;&#29983;&#23384;&#39044;&#27979;&#27169;&#22411;&#19982;&#26032;&#25910;&#38598;&#30340;&#26102;&#38388;&#33267;&#20107;&#20214;&#25968;&#25454;&#30456;&#32467;&#21512;&#26469;&#33719;&#24471;&#26356;&#22909;&#30340;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#65288;&#28145;&#24230;&#23398;&#20064;&#65289;&#26159;&#20154;&#24037;&#26234;&#33021;&#20013;&#30340;&#29616;&#20195;&#27169;&#22411;&#65292;&#24182;&#24050;&#34987;&#21033;&#29992;&#20110;&#29983;&#23384;&#20998;&#26512;&#20013;&#12290;&#23613;&#31649;&#20043;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#23637;&#31034;&#20102;&#19968;&#20123;&#25913;&#36827;&#65292;&#20294;&#35757;&#32451;&#20986;&#19968;&#20010;&#20248;&#31168;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#38656;&#35201;&#22823;&#37327;&#30340;&#25968;&#25454;&#65292;&#22312;&#23454;&#36341;&#20013;&#21487;&#33021;&#24182;&#19981;&#23384;&#22312;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;Kullback-Leibler&#65288;KL&#65289;&#30340;&#28145;&#24230;&#23398;&#20064;&#31243;&#24207;&#65292;&#23558;&#22806;&#37096;&#29983;&#23384;&#39044;&#27979;&#27169;&#22411;&#19982;&#26032;&#25910;&#38598;&#30340;&#26102;&#38388;&#33267;&#20107;&#20214;&#25968;&#25454;&#30456;&#32467;&#21512;&#12290;&#21033;&#29992;&#26102;&#38388;&#30456;&#20851;&#30340;KL&#21306;&#20998;&#20449;&#24687;&#26469;&#34913;&#37327;&#22806;&#37096;&#25968;&#25454;&#21644;&#20869;&#37096;&#25968;&#25454;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#32771;&#34385;&#20351;&#29992;&#20808;&#21069;&#20449;&#24687;&#26469;&#22788;&#29702;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#30701;&#25968;&#25454;&#38382;&#39064;&#30340;&#24037;&#20316;&#12290;&#27169;&#25311;&#21644;&#23454;&#38469;&#25968;&#25454;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;&#30456;&#27604;&#65292;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#21644;&#26356;&#39640;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural Network (Deep Learning) is a modern model in Artificial Intelligence and it has been exploited in Survival Analysis. Although several improvements have been shown by previous works, training an excellent deep learning model requires a huge amount of data, which may not hold in practice. To address this challenge, we develop a Kullback-Leibler-based (KL) deep learning procedure to integrate external survival prediction models with newly collected time-to-event data. Time-dependent KL discrimination information is utilized to measure the discrepancy between the external and internal data. This is the first work considering using prior information to deal with short data problem in Survival Analysis for deep learning. Simulation and real data results show that the proposed model achieves better performance and higher robustness compared with previous works.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31867;&#20284;&#25193;&#25955;&#30340;&#27169;&#22411;&#26469;&#29983;&#25104;&#22270;&#20687;&#65292;&#23427;&#36890;&#36807;&#38543;&#26426;&#21453;&#36716;&#28909;&#26041;&#31243;&#22312;2D&#24179;&#38754;&#19978;&#36816;&#34892;&#26469;&#29983;&#25104;&#22270;&#20687;&#65292;&#24182;&#23637;&#31034;&#20102;&#19982;&#26631;&#20934;&#25193;&#25955;&#27169;&#22411;&#19981;&#21516;&#30340;&#26032;&#39062;&#23450;&#24615;&#24615;&#36136;&#65292;&#21253;&#25324;&#22270;&#20687;&#20013;&#25972;&#20307;&#39068;&#33394;&#21644;&#24418;&#29366;&#30340;&#35299;&#32544;&#32469;&#29616;&#35937;&#12290;</title><link>http://arxiv.org/abs/2206.13397</link><description>&lt;p&gt;
&#24102;&#26377;&#36870;&#28909;&#20256;&#23548;&#30340;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Generative Modelling With Inverse Heat Dissipation. (arXiv:2206.13397v7 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.13397
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31867;&#20284;&#25193;&#25955;&#30340;&#27169;&#22411;&#26469;&#29983;&#25104;&#22270;&#20687;&#65292;&#23427;&#36890;&#36807;&#38543;&#26426;&#21453;&#36716;&#28909;&#26041;&#31243;&#22312;2D&#24179;&#38754;&#19978;&#36816;&#34892;&#26469;&#29983;&#25104;&#22270;&#20687;&#65292;&#24182;&#23637;&#31034;&#20102;&#19982;&#26631;&#20934;&#25193;&#25955;&#27169;&#22411;&#19981;&#21516;&#30340;&#26032;&#39062;&#23450;&#24615;&#24615;&#36136;&#65292;&#21253;&#25324;&#22270;&#20687;&#20013;&#25972;&#20307;&#39068;&#33394;&#21644;&#24418;&#29366;&#30340;&#35299;&#32544;&#32469;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#25193;&#25955;&#27169;&#22411;&#22312;&#22270;&#20687;&#29983;&#25104;&#26041;&#38754;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#65292;&#20294;&#23427;&#20204;&#30340;&#22122;&#22768;&#21453;&#28436;&#29983;&#25104;&#36807;&#31243;&#24182;&#27809;&#26377;&#26126;&#30830;&#32771;&#34385;&#22270;&#20687;&#30340;&#32467;&#26500;&#65292;&#20363;&#22914;&#20854;&#22266;&#26377;&#30340;&#22810;&#23610;&#24230;&#24615;&#36136;&#12290;&#21463;&#21040;&#25193;&#25955;&#27169;&#22411;&#21644;&#31895;&#21040;&#32454;&#24314;&#27169;&#30340;&#23454;&#35777;&#25104;&#21151;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31867;&#20284;&#25193;&#25955;&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#38543;&#26426;&#22320;&#21453;&#36716;&#28909;&#26041;&#31243;&#22312;2D&#24179;&#38754;&#19978;&#36816;&#34892;&#26469;&#29983;&#25104;&#22270;&#20687;&#65292;&#24403;&#20854;&#36816;&#34892;&#26102;&#22320;&#23616;&#37096;&#25273;&#21435;&#20102;&#22270;&#20687;&#30340;&#32454;&#23610;&#24230;&#20449;&#24687;&#12290;&#25105;&#20204;&#23558;&#20855;&#26377;&#24658;&#23450;&#21152;&#24615;&#22122;&#22768;&#30340;&#27491;&#21521;&#28909;&#26041;&#31243;&#30340;&#35299;&#37322;&#20026;&#25193;&#25955;&#28508;&#22312;&#21464;&#37327;&#27169;&#22411;&#20013;&#30340;&#21464;&#20998;&#36817;&#20284;&#12290;&#25105;&#20204;&#30340;&#26032;&#27169;&#22411;&#26174;&#31034;&#20986;&#24182;&#19981;&#22312;&#26631;&#20934;&#25193;&#25955;&#27169;&#22411;&#20013;&#30475;&#21040;&#30340;&#26032;&#39062;&#30340;&#23450;&#24615;&#24615;&#36136;&#65292;&#20363;&#22914;&#22270;&#20687;&#20013;&#25972;&#20307;&#39068;&#33394;&#21644;&#24418;&#29366;&#30340;&#35299;&#32544;&#32469;&#29616;&#35937;&#12290;&#33258;&#28982;&#22270;&#20687;&#30340;&#35889;&#20998;&#26512;&#31361;&#20986;&#20102;&#19982;&#25193;&#25955;&#27169;&#22411;&#30340;&#32852;&#31995;&#24182;&#25581;&#31034;&#20102;&#20854;&#20013;&#19968;&#20010;&#38544;&#21547;&#30340;&#31895;&#21040;&#32454;&#24402;&#32435;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
While diffusion models have shown great success in image generation, their noise-inverting generative process does not explicitly consider the structure of images, such as their inherent multi-scale nature. Inspired by diffusion models and the empirical success of coarse-to-fine modelling, we propose a new diffusion-like model that generates images through stochastically reversing the heat equation, a PDE that locally erases fine-scale information when run over the 2D plane of the image. We interpret the solution of the forward heat equation with constant additive noise as a variational approximation in the diffusion latent variable model. Our new model shows emergent qualitative properties not seen in standard diffusion models, such as disentanglement of overall colour and shape in images. Spectral analysis on natural images highlights connections to diffusion models and reveals an implicit coarse-to-fine inductive bias in them.
&lt;/p&gt;</description></item><item><title>&#35780;&#20272;&#40657;&#31665;&#39044;&#27979;&#27169;&#22411;&#20013;&#21464;&#37327;&#37325;&#35201;&#24615;&#30340;&#27969;&#34892;&#26041;&#27861;&#19981;&#21487;&#20449;&#65292;&#22240;&#20026;&#20351;&#29992;&#20102;&#19981;&#21487;&#33021;&#30340;&#25968;&#25454;&#12290;&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#21517;&#20026;Cohort Shapley&#30340;&#26041;&#27861;&#65292;&#23427;&#22522;&#20110;&#32463;&#27982;&#21338;&#24328;&#29702;&#35770;&#65292;&#20165;&#20351;&#29992;&#23454;&#38469;&#35266;&#27979;&#21040;&#30340;&#25968;&#25454;&#26469;&#37327;&#21270;&#21464;&#37327;&#37325;&#35201;&#24615;&#65292;&#21487;&#20197;&#35299;&#20915;&#31639;&#27861;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2205.15750</link><description>&lt;p&gt;
&#26080;&#38656;&#19981;&#21487;&#33021;&#25968;&#25454;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#20998;&#26512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Variable importance without impossible data. (arXiv:2205.15750v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.15750
&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#40657;&#31665;&#39044;&#27979;&#27169;&#22411;&#20013;&#21464;&#37327;&#37325;&#35201;&#24615;&#30340;&#27969;&#34892;&#26041;&#27861;&#19981;&#21487;&#20449;&#65292;&#22240;&#20026;&#20351;&#29992;&#20102;&#19981;&#21487;&#33021;&#30340;&#25968;&#25454;&#12290;&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#21517;&#20026;Cohort Shapley&#30340;&#26041;&#27861;&#65292;&#23427;&#22522;&#20110;&#32463;&#27982;&#21338;&#24328;&#29702;&#35770;&#65292;&#20165;&#20351;&#29992;&#23454;&#38469;&#35266;&#27979;&#21040;&#30340;&#25968;&#25454;&#26469;&#37327;&#21270;&#21464;&#37327;&#37325;&#35201;&#24615;&#65292;&#21487;&#20197;&#35299;&#20915;&#31639;&#27861;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#65292;&#35780;&#20272;&#40657;&#31665;&#39044;&#27979;&#27169;&#22411;&#20013;&#21464;&#37327;&#37325;&#35201;&#24615;&#30340;&#26368;&#27969;&#34892;&#26041;&#27861;&#26159;&#20351;&#29992;&#20154;&#24037;&#21512;&#25104;&#30340;&#36755;&#20837;&#25968;&#25454;&#65292;&#36825;&#20123;&#25968;&#25454;&#32467;&#21512;&#20102;&#22810;&#20010;&#21442;&#19982;&#32773;&#30340;&#39044;&#27979;&#21464;&#37327;&#65292;&#36825;&#20123;&#36755;&#20837;&#25968;&#25454;&#21487;&#33021;&#26159;&#19981;&#21487;&#33021;&#30340;&#12289;&#29289;&#29702;&#19978;&#19981;&#21487;&#33021;&#30340;&#65292;&#29978;&#33267;&#26159;&#36923;&#36753;&#19978;&#19981;&#21487;&#33021;&#30340;&#65292;&#30001;&#27492;&#24471;&#20986;&#30340;&#39044;&#27979;&#32467;&#26524;&#21487;&#33021;&#19982;&#40657;&#31665;&#35757;&#32451;&#25968;&#25454;&#26377;&#24456;&#22823;&#19981;&#21516;&#12290;&#22240;&#27492;&#65292;&#24403;&#35299;&#37322;&#20915;&#31574;&#26102;&#20351;&#29992;&#36825;&#20123;&#20540;&#26102;&#65292;&#29992;&#25143;&#19981;&#33021;&#20449;&#20219;&#39044;&#27979;&#31639;&#27861;&#30340;&#35299;&#37322;&#12290;&#25105;&#20204;&#25552;&#20513;&#19968;&#31181;&#21517;&#20026;Cohort Shapley&#30340;&#26041;&#27861;&#65292;&#23427;&#22522;&#20110;&#32463;&#27982;&#21338;&#24328;&#29702;&#35770;&#65292;&#19982;&#22823;&#22810;&#25968;&#20854;&#20182;&#21338;&#24328;&#35770;&#26041;&#27861;&#19981;&#21516;&#65292;&#20165;&#20351;&#29992;&#23454;&#38469;&#35266;&#27979;&#21040;&#30340;&#25968;&#25454;&#26469;&#37327;&#21270;&#21464;&#37327;&#37325;&#35201;&#24615;&#12290;Cohort Shapley&#36890;&#36807;&#32553;&#23567;&#19982;&#30446;&#26631;&#23545;&#35937;&#22312;&#19968;&#20010;&#25110;&#22810;&#20010;&#29305;&#24449;&#19978;&#30456;&#20284;&#30340;&#23545;&#35937;&#32452;&#26469;&#23454;&#29616;&#12290;&#25105;&#20204;&#23558;&#20854;&#24212;&#29992;&#20110;&#19968;&#20010;&#31639;&#27861;&#20844;&#24179;&#24615;&#38382;&#39064;&#65292;&#20854;&#20013;&#24517;&#39035;&#23558;&#37325;&#35201;&#24615;&#24402;&#22240;&#20110;&#27169;&#22411;&#26410;&#32463;&#35757;&#32451;&#30340;&#21463;&#20445;&#25252;&#21464;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
The most popular methods for measuring importance of the variables in a black box prediction algorithm make use of synthetic inputs that combine predictor variables from multiple subjects. These inputs can be unlikely, physically impossible, or even logically impossible. As a result, the predictions for such cases can be based on data very unlike any the black box was trained on. We think that users cannot trust an explanation of the decision of a prediction algorithm when the explanation uses such values. Instead we advocate a method called Cohort Shapley that is grounded in economic game theory and unlike most other game theoretic methods, it uses only actually observed data to quantify variable importance. Cohort Shapley works by narrowing the cohort of subjects judged to be similar to a target subject on one or more features. We illustrate it on an algorithmic fairness problem where it is essential to attribute importance to protected variables that the model was not trained on.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21487;&#20197;&#23545;&#20219;&#24847;&#21442;&#25968;&#32500;&#24230;&#19979;&#30340;&#20219;&#24847;&#22495;&#20869;&#27491;&#24577;&#20998;&#24067;&#36827;&#34892;&#31215;&#20998;&#30340;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#27861;&#21521;&#21521;&#37327;&#20989;&#25968;&#30340;&#30456;&#20851;&#27010;&#29575;&#23494;&#24230;&#21644;&#32479;&#35745;&#25351;&#26631;&#65292;&#21516;&#26102;&#36824;&#25552;&#20379;&#20102;&#21487;&#20197;&#23545;&#20219;&#24847;&#25968;&#37327;&#27491;&#24577;&#20998;&#24067;&#36827;&#34892;&#20998;&#31867;&#30340;&#26041;&#27861;&#21644;&#32500;&#24230;&#38477;&#20302;&#21644;&#21487;&#35270;&#21270;&#30340;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2012.14331</link><description>&lt;p&gt;
&#19968;&#31181;&#25972;&#21512;&#21644;&#20998;&#31867;&#27491;&#24577;&#20998;&#24067;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A method to integrate and classify normal distributions. (arXiv:2012.14331v8 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2012.14331
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21487;&#20197;&#23545;&#20219;&#24847;&#21442;&#25968;&#32500;&#24230;&#19979;&#30340;&#20219;&#24847;&#22495;&#20869;&#27491;&#24577;&#20998;&#24067;&#36827;&#34892;&#31215;&#20998;&#30340;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#27861;&#21521;&#21521;&#37327;&#20989;&#25968;&#30340;&#30456;&#20851;&#27010;&#29575;&#23494;&#24230;&#21644;&#32479;&#35745;&#25351;&#26631;&#65292;&#21516;&#26102;&#36824;&#25552;&#20379;&#20102;&#21487;&#20197;&#23545;&#20219;&#24847;&#25968;&#37327;&#27491;&#24577;&#20998;&#24067;&#36827;&#34892;&#20998;&#31867;&#30340;&#26041;&#27861;&#21644;&#32500;&#24230;&#38477;&#20302;&#21644;&#21487;&#35270;&#21270;&#30340;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21333;&#21464;&#37327;&#21644;&#22810;&#21464;&#37327;&#27491;&#24577;&#27010;&#29575;&#20998;&#24067;&#22312;&#27169;&#25311;&#19981;&#30830;&#23450;&#24615;&#20915;&#31574;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#35745;&#31639;&#36825;&#20123;&#27169;&#22411;&#30340;&#24615;&#33021;&#38656;&#35201;&#22312;&#29305;&#23450;&#21306;&#22495;&#20869;&#23545;&#36825;&#20123;&#20998;&#24067;&#36827;&#34892;&#31215;&#20998;&#65292;&#36825;&#22312;&#19981;&#21516;&#30340;&#27169;&#22411;&#20013;&#21487;&#20197;&#26377;&#24456;&#22823;&#30340;&#24046;&#24322;&#12290;&#38500;&#20102;&#19968;&#20123;&#29305;&#27530;&#24773;&#20917;&#65292;&#30446;&#21069;&#19981;&#23384;&#22312;&#36890;&#29992;&#30340;&#20998;&#26512;&#34920;&#36798;&#24335;&#12289;&#26631;&#20934;&#25968;&#20540;&#26041;&#27861;&#25110;&#36719;&#20214;&#26469;&#35745;&#31639;&#36825;&#20123;&#31215;&#20998;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#25968;&#23398;&#32467;&#26524;&#21644;&#24320;&#28304;&#36719;&#20214;&#65292;&#21487;&#20197;&#25552;&#20379;&#20197;&#19979;&#20869;&#23481;&#65306;&#65288;i&#65289;&#20219;&#24847;&#21442;&#25968;&#32500;&#24230;&#19979;&#20219;&#24847;&#22495;&#20869;&#27861;&#21521;&#30340;&#27010;&#29575;&#65292;&#65288;ii&#65289;&#27861;&#21521;&#21521;&#37327;&#20989;&#25968;&#30340;&#27010;&#29575;&#23494;&#24230;&#12289;&#32047;&#31215;&#20998;&#24067;&#21644;&#36870;&#32047;&#31215;&#20998;&#24067;&#65292;&#65288;iii&#65289;&#20219;&#24847;&#25968;&#37327;&#27491;&#24577;&#20998;&#24067;&#20043;&#38388;&#30340;&#20998;&#31867;&#35823;&#24046;&#12289;&#36125;&#21494;&#26031;&#26368;&#20248;&#36776;&#21035;&#25351;&#25968;&#20197;&#21450;&#20854;&#19982;&#24037;&#20316;&#29305;&#24449;&#26354;&#32447;&#30340;&#20851;&#31995;&#65292;&#65288;iv&#65289;&#27492;&#31867;&#38382;&#39064;&#30340;&#32500;&#24230;&#38477;&#20302;&#21644;&#21487;&#35270;&#21270;&#65292;&#20197;&#21450;&#65288;v&#65289;&#23545;&#20110;&#32473;&#23450;&#25968;&#25454;&#36825;&#20123;&#26041;&#27861;&#30340;&#21487;&#38752;&#24615;&#27979;&#35797;&#12290;&#25105;&#20204;&#36890;&#36807;&#20960;&#20010;&#20855;&#20307;&#30340;&#20363;&#23376;&#65292;&#21253;&#25324;&#37329;&#34701;&#12289;&#29983;&#29289;&#21644;&#24515;&#29702;&#23398;&#26469;&#28436;&#31034;&#36825;&#20123;&#21151;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Univariate and multivariate normal probability distributions are widely used when modeling decisions under uncertainty. Computing the performance of such models requires integrating these distributions over specific domains, which can vary widely across models. Besides some special cases, there exist no general analytical expressions, standard numerical methods or software for these integrals. Here we present mathematical results and open-source software that provide (i) the probability in any domain of a normal in any dimensions with any parameters, (ii) the probability density, cumulative distribution, and inverse cumulative distribution of any function of a normal vector, (iii) the classification errors among any number of normal distributions, the Bayes-optimal discriminability index and relation to the operating characteristic, (iv) dimension reduction and visualizations for such problems, and (v) tests for how reliably these methods may be used on given data. We demonstrate these
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#38543;&#26426;&#32534;&#30721;&#30340;&#20998;&#31867;&#22120;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#24182;&#24471;&#20986;&#20102;&#27867;&#21270;&#35823;&#24046;&#21463;&#36755;&#20837;&#29305;&#24449;&#21644;&#28508;&#31354;&#38388;&#34920;&#31034;&#20043;&#38388;&#20114;&#20449;&#24687;&#38480;&#21046;&#30340;&#32467;&#35770;&#12290;</title><link>http://arxiv.org/abs/2010.11642</link><description>&lt;p&gt;
&#20114;&#20449;&#24687;&#22312;&#21464;&#20998;&#20998;&#31867;&#22120;&#20013;&#30340;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
The Role of Mutual Information in Variational Classifiers. (arXiv:2010.11642v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2010.11642
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#38543;&#26426;&#32534;&#30721;&#30340;&#20998;&#31867;&#22120;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#24182;&#24471;&#20986;&#20102;&#27867;&#21270;&#35823;&#24046;&#21463;&#36755;&#20837;&#29305;&#24449;&#21644;&#28508;&#31354;&#38388;&#34920;&#31034;&#20043;&#38388;&#20114;&#20449;&#24687;&#38480;&#21046;&#30340;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#25311;&#21512;&#26159;&#19968;&#31181;&#20247;&#25152;&#21608;&#30693;&#30340;&#29616;&#35937;&#65292;&#19982;&#29983;&#25104;&#36807;&#24230;&#25311;&#21512;&#29305;&#23450;&#25968;&#25454;&#23454;&#20363;&#30340;&#27169;&#22411;&#26377;&#20851;&#65292;&#22240;&#27492;&#21487;&#33021;&#26080;&#27861;&#21487;&#38752;&#22320;&#39044;&#27979;&#26410;&#26469;&#35266;&#23519;&#32467;&#26524;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#36890;&#36807;&#21508;&#31181;&#65292;&#26377;&#26102;&#26159;&#21551;&#21457;&#24335;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#25511;&#21046;&#27492;&#34892;&#20026;&#65292;&#36825;&#20123;&#25216;&#26415;&#30340;&#21160;&#26426;&#26159;&#20197;&#24320;&#21457;&#19978;&#38480;&#26469;&#27867;&#21270;&#35823;&#24046;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;&#22312;&#20132;&#21449;&#29109;&#25439;&#22833;&#19978;&#35757;&#32451;&#30340;&#38543;&#26426;&#32534;&#30721;&#30340;&#20998;&#31867;&#22120;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#36825;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#32463;&#24120;&#29992;&#20110;&#20998;&#31867;&#38382;&#39064;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#27867;&#21270;&#35823;&#24046;&#30340;&#36793;&#30028;&#65292;&#34920;&#26126;&#23384;&#22312;&#19968;&#31181;&#21306;&#22495;&#65292;&#20854;&#20013;&#27867;&#21270;&#35823;&#24046;&#30001;&#36755;&#20837;&#29305;&#24449;&#21644;&#19982;&#32534;&#30721;&#20998;&#24067;&#38543;&#26426;&#29983;&#25104;&#30340;&#28508;&#31354;&#38388;&#20013;&#30340;&#30456;&#24212;&#34920;&#31034;&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#25152;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#36793;&#30028;&#25552;&#20379;&#20102;&#23545;&#25152;&#35859;&#30340;&#21464;&#24322;&#32423;&#21035;&#30340;&#27867;&#21270;&#30340;&#20449;&#24687;&#35770;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Overfitting data is a well-known phenomenon related with the generation of a model that mimics too closely (or exactly) a particular instance of data, and may therefore fail to predict future observations reliably. In practice, this behaviour is controlled by various--sometimes heuristics--regularization techniques, which are motivated by developing upper bounds to the generalization error. In this work, we study the generalization error of classifiers relying on stochastic encodings trained on the cross-entropy loss, which is often used in deep learning for classification problems. We derive bounds to the generalization error showing that there exists a regime where the generalization error is bounded by the mutual information between input features and the corresponding representations in the latent space, which are randomly generated according to the encoding distribution. Our bounds provide an information-theoretic understanding of generalization in the so-called class of variation
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36229;&#22270;&#23398;&#20064;&#26041;&#27861;&#65292;&#21363;&#8220;&#32447;&#25193;&#23637;(LE)&#8221;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23558;&#39030;&#28857;-&#36229;&#36793;&#23545;&#20316;&#20026;&#8220;&#32447;&#33410;&#28857;&#8221;&#65292;&#22312;&#36229;&#22270;&#20013;&#24341;&#20986;&#21516;&#26500;&#32467;&#26500;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#36229;&#22270;&#25193;&#23637;&#24182;&#36798;&#21040;&#20102;&#26174;&#33879;&#20248;&#20110;SOTA&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2005.04843</link><description>&lt;p&gt;
&#22522;&#20110;&#36229;&#22270;&#32447;&#25193;&#23637;&#30340;&#21322;&#30417;&#30563;&#36229;&#22270;&#33410;&#28857;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Semi-supervised Hypergraph Node Classification on Hypergraph Line Expansion. (arXiv:2005.04843v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2005.04843
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36229;&#22270;&#23398;&#20064;&#26041;&#27861;&#65292;&#21363;&#8220;&#32447;&#25193;&#23637;(LE)&#8221;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23558;&#39030;&#28857;-&#36229;&#36793;&#23545;&#20316;&#20026;&#8220;&#32447;&#33410;&#28857;&#8221;&#65292;&#22312;&#36229;&#22270;&#20013;&#24341;&#20986;&#21516;&#26500;&#32467;&#26500;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#36229;&#22270;&#25193;&#23637;&#24182;&#36798;&#21040;&#20102;&#26174;&#33879;&#20248;&#20110;SOTA&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#30340;&#36229;&#22270;&#25193;&#23637;&#20165;&#22312;&#39030;&#28857;&#32423;&#21035;&#25110;&#36229;&#36793;&#32423;&#21035;&#19978;&#36827;&#34892;&#65292;&#22240;&#27492;&#32570;&#20047;&#25968;&#25454;&#20849;&#29616;&#30340;&#23545;&#31216;&#24615;&#65292;&#23548;&#33268;&#20449;&#24687;&#25439;&#22833;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#24179;&#31561;&#23545;&#24453;&#39030;&#28857;&#21644;&#36229;&#36793;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;\emph{&#32447;&#25193;&#23637;(LE)}&#30340;&#26032;&#22411;&#36229;&#22270;&#23398;&#20064;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#23558;&#39030;&#28857;-&#36229;&#36793;&#23545;&#20316;&#20026;&#8220;&#32447;&#33410;&#28857;&#8221;&#65292;&#22312;&#36229;&#22270;&#20013;&#21452;&#23556;&#24341;&#20986;&#19968;&#31181;&#21516;&#26500;&#32467;&#26500;&#12290;&#36890;&#36807;&#23558;&#36229;&#22270;&#20943;&#23569;&#20026;&#31616;&#21333;&#22270;&#65292;&#25552;&#20986;&#30340;\emph{&#32447;&#25193;&#23637;}&#20351;&#24471;&#24050;&#26377;&#30340;&#22270;&#23398;&#20064;&#31639;&#27861;&#36866;&#29992;&#20110;&#39640;&#38454;&#32467;&#26500;&#65292;&#24182;&#24050;&#34987;&#35777;&#26126;&#26159;&#21508;&#31181;&#36229;&#22270;&#25193;&#23637;&#30340;&#32479;&#19968;&#26694;&#26550;&#12290;&#25105;&#20204;&#22312;&#20116;&#20010;&#36229;&#22270;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25152;&#25552;&#20986;&#30340;&#32447;&#25193;&#23637;&#65292;&#32467;&#26524;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#26174;&#33879;&#20248;&#20110;SOTA&#22522;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;
Previous hypergraph expansions are solely carried out on either vertex level or hyperedge level, thereby missing the symmetric nature of data co-occurrence, and resulting in information loss. To address the problem, this paper treats vertices and hyperedges equally and proposes a new hypergraph formulation named the \emph{line expansion (LE)} for hypergraphs learning. The new expansion bijectively induces a homogeneous structure from the hypergraph by treating vertex-hyperedge pairs as "line nodes". By reducing the hypergraph to a simple graph, the proposed \emph{line expansion} makes existing graph learning algorithms compatible with the higher-order structure and has been proven as a unifying framework for various hypergraph expansions. We evaluate the proposed line expansion on five hypergraph datasets, the results show that our method beats SOTA baselines by a significant margin.
&lt;/p&gt;</description></item></channel></rss>