<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36890;&#36807;&#20351;&#29992;&#20998;&#31867;&#20195;&#26367;&#22238;&#24402;&#35757;&#32451;&#20540;&#20989;&#25968;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#26041;&#27861;&#26469;&#25913;&#21892;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#24615;&#33021;&#21644;&#21487;&#25193;&#23637;&#24615;</title><link>https://arxiv.org/abs/2403.03950</link><description>&lt;p&gt;
&#20572;&#27490;&#22238;&#24402;&#65306;&#36890;&#36807;&#20998;&#31867;&#35757;&#32451;&#20540;&#20989;&#25968;&#23454;&#29616;&#21487;&#25193;&#23637;&#30340;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Stop Regressing: Training Value Functions via Classification for Scalable Deep RL
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03950
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#20998;&#31867;&#20195;&#26367;&#22238;&#24402;&#35757;&#32451;&#20540;&#20989;&#25968;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#26041;&#27861;&#26469;&#25913;&#21892;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#24615;&#33021;&#21644;&#21487;&#25193;&#23637;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20540;&#20989;&#25968;&#26159;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#30340;&#26680;&#24515;&#32452;&#20214;&#12290;&#36825;&#20123;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#30340;&#20989;&#25968;&#65292;&#20351;&#29992;&#22343;&#26041;&#35823;&#24046;&#22238;&#24402;&#30446;&#26631;&#36827;&#34892;&#35757;&#32451;&#65292;&#20197;&#21305;&#37197;&#33258;&#20030;&#30446;&#26631;&#20540;&#12290;&#28982;&#32780;&#65292;&#23558;&#20351;&#29992;&#22238;&#24402;&#30340;&#20215;&#20540;&#22411;RL&#26041;&#27861;&#25193;&#23637;&#21040;&#22823;&#22411;&#32593;&#32476;&#65292;&#22914;&#39640;&#23481;&#37327;&#30340;Transformers&#65292;&#24050;&#34987;&#35777;&#26126;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#26412;&#25991;&#35266;&#23519;&#21040;&#20102;&#36825;&#19968;&#24046;&#24322;&#65292;&#25506;&#35752;&#20102;&#36890;&#36807;&#20351;&#29992;&#20998;&#31867;&#32780;&#19981;&#26159;&#22238;&#24402;&#26469;&#35757;&#32451;&#20540;&#20989;&#25968;&#26159;&#21542;&#20063;&#21487;&#20197;&#31616;&#21333;&#22320;&#25552;&#39640;&#28145;&#24230;RL&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#20351;&#29992;&#20998;&#31867;&#20132;&#21449;&#29109;&#35757;&#32451;&#30340;&#20540;&#20989;&#25968;&#22312;&#21508;&#31181;&#39046;&#22495;&#20013;&#26174;&#33879;&#25552;&#39640;&#20102;&#24615;&#33021;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;&#36825;&#20123;&#39046;&#22495;&#21253;&#25324;&#65306;&#22312;Atari 2600&#28216;&#25103;&#19978;&#20351;&#29992;SoftMoEs&#36827;&#34892;&#21333;&#19968;&#20219;&#21153;RL&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03950v1 Announce Type: cross  Abstract: Value functions are a central component of deep reinforcement learning (RL). These functions, parameterized by neural networks, are trained using a mean squared error regression objective to match bootstrapped target values. However, scaling value-based RL methods that use regression to large networks, such as high-capacity Transformers, has proven challenging. This difficulty is in stark contrast to supervised learning: by leveraging a cross-entropy classification loss, supervised methods have scaled reliably to massive networks. Observing this discrepancy, in this paper, we investigate whether the scalability of deep RL can also be improved simply by using classification in place of regression for training value functions. We demonstrate that value functions trained with categorical cross-entropy significantly improves performance and scalability in a variety of domains. These include: single-task RL on Atari 2600 games with SoftMoEs
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#23545;&#20110;$k$-PCA&#31639;&#27861;&#20013;&#36817;&#20284;&#21442;&#25968;&#36864;&#21270;&#30340;&#36793;&#30028;&#24471;&#21040;&#20102;&#26174;&#33879;&#26356;&#20026;&#31934;&#30830;&#30340;&#30028;&#38480;</title><link>https://arxiv.org/abs/2403.03905</link><description>&lt;p&gt;
&#40657;&#30418;$k$-to-$1$-PCA&#38477;&#32500;&#65306;&#29702;&#35770;&#19982;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Black-Box $k$-to-$1$-PCA Reductions: Theory and Applications
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03905
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#23545;&#20110;$k$-PCA&#31639;&#27861;&#20013;&#36817;&#20284;&#21442;&#25968;&#36864;&#21270;&#30340;&#36793;&#30028;&#24471;&#21040;&#20102;&#26174;&#33879;&#26356;&#20026;&#31934;&#30830;&#30340;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
$k$-&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;$k$-PCA&#65289;&#38382;&#39064;&#26159;&#19968;&#31181;&#22522;&#26412;&#30340;&#31639;&#27861;&#21407;&#35821;&#65292;&#22312;&#25968;&#25454;&#20998;&#26512;&#21644;&#38477;&#32500;&#24212;&#29992;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#22312;&#32479;&#35745;&#29615;&#22659;&#20013;&#65292;$k$-PCA&#30340;&#30446;&#26631;&#26159;&#35782;&#21035;&#19968;&#20010;&#20998;&#24067;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#39030;&#37096;&#29305;&#24449;&#31354;&#38388;&#65292;&#25105;&#20204;&#21482;&#33021;&#36890;&#36807;&#26679;&#26412;&#38544;&#24335;&#35775;&#38382;&#36825;&#20010;&#30697;&#38453;&#12290;&#21463;&#36825;&#20123;&#38544;&#24335;&#35774;&#32622;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#20998;&#26512;&#40657;&#30418;&#32553;&#20943;&#26041;&#27861;&#20316;&#20026;&#35774;&#35745;$k$-PCA&#31639;&#27861;&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;&#25105;&#20204;&#36890;&#36807;&#40657;&#30418;$1$-PCA&#39044;&#35328;&#27169;&#25311;&#23545;&#26410;&#30693;&#30446;&#26631;&#30697;&#38453;&#30340;&#35775;&#38382;&#65292;&#35813;&#39044;&#35328;&#36820;&#22238;&#19968;&#20010;&#36817;&#20284;&#30340;&#39030;&#37096;&#29305;&#24449;&#21521;&#37327;&#65292;&#26681;&#25454;&#20004;&#20010;&#27969;&#34892;&#30340;&#36817;&#20284;&#27010;&#24565;&#12290;&#23613;&#31649;&#36825;&#31181;&#40657;&#30418;&#26041;&#27861;&#21487;&#33021;&#26159;&#35774;&#35745;$k$-PCA&#31639;&#27861;&#20013;&#26368;&#33258;&#28982;&#30340;&#22522;&#20110;&#38477;&#32500;&#30340;&#26041;&#27861;&#65292;&#36825;&#31181;&#26041;&#27861;&#65292;&#21363;&#36890;&#36807;&#36882;&#24402;&#35843;&#29992;$1$-PCA&#39044;&#35328;&#35843;&#29992;&#20102;$k$&#27425;&#65292;&#20197;&#21069;&#24456;&#38590;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03905v1 Announce Type: cross  Abstract: The $k$-principal component analysis ($k$-PCA) problem is a fundamental algorithmic primitive that is widely-used in data analysis and dimensionality reduction applications. In statistical settings, the goal of $k$-PCA is to identify a top eigenspace of the covariance matrix of a distribution, which we only have implicit access to via samples. Motivated by these implicit settings, we analyze black-box deflation methods as a framework for designing $k$-PCA algorithms, where we model access to the unknown target matrix via a black-box $1$-PCA oracle which returns an approximate top eigenvector, under two popular notions of approximation. Despite being arguably the most natural reduction-based approach to $k$-PCA algorithm design, such black-box methods, which recursively call a $1$-PCA oracle $k$ times, were previously poorly-understood.   Our main contribution is significantly sharper bounds on the approximation parameter degradation of
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26500;&#24314;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#31934;&#30830;&#35206;&#30422;&#30340;&#39044;&#27979;&#38598;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#21487;&#20197;&#35299;&#20915;&#22312;&#25968;&#25454;&#39537;&#21160;&#24773;&#22659;&#20013;&#30001;&#20110;&#36873;&#25321;&#20559;&#24046;&#23548;&#33268;&#30340;&#36793;&#32536;&#26377;&#25928;&#39044;&#27979;&#21306;&#38388;&#35823;&#23548;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.03868</link><description>&lt;p&gt;
&#28966;&#28857;&#32622;&#20449;: &#24102;&#26377;&#36873;&#25321;&#26465;&#20214;&#35206;&#30422;&#30340;&#25972;&#20307;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Confidence on the Focal: Conformal Prediction with Selection-Conditional Coverage
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03868
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26500;&#24314;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#31934;&#30830;&#35206;&#30422;&#30340;&#39044;&#27979;&#38598;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#21487;&#20197;&#35299;&#20915;&#22312;&#25968;&#25454;&#39537;&#21160;&#24773;&#22659;&#20013;&#30001;&#20110;&#36873;&#25321;&#20559;&#24046;&#23548;&#33268;&#30340;&#36793;&#32536;&#26377;&#25928;&#39044;&#27979;&#21306;&#38388;&#35823;&#23548;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25972;&#20307;&#39044;&#27979;&#24314;&#31435;&#22312;&#36793;&#32536;&#26377;&#25928;&#30340;&#39044;&#27979;&#21306;&#38388;&#19978;&#65292;&#35813;&#21306;&#38388;&#20197;&#26576;&#31181;&#35268;&#23450;&#30340;&#27010;&#29575;&#35206;&#30422;&#20102;&#38543;&#26426;&#25277;&#21462;&#30340;&#26032;&#27979;&#35797;&#28857;&#30340;&#26410;&#30693;&#32467;&#26524;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#24120;&#35265;&#24773;&#20917;&#26159;&#65292;&#22312;&#30475;&#21040;&#27979;&#35797;&#21333;&#20803;&#21518;&#65292;&#20174;&#19994;&#32773;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#20915;&#23450;&#20851;&#27880;&#21738;&#20123;&#27979;&#35797;&#21333;&#20803;&#65292;&#24182;&#24076;&#26395;&#37327;&#21270;&#28966;&#28857;&#21333;&#20803;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#23545;&#20110;&#36825;&#20123;&#28966;&#28857;&#21333;&#20803;&#30340;&#36793;&#32536;&#26377;&#25928;&#39044;&#27979;&#21306;&#38388;&#21487;&#33021;&#20250;&#22240;&#36873;&#25321;&#20559;&#24046;&#32780;&#20855;&#26377;&#35823;&#23548;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26500;&#24314;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#31934;&#30830;&#35206;&#30422;&#30340;&#39044;&#27979;&#38598;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#35813;&#35206;&#30422;&#26159;&#26377;&#26465;&#20214;&#20110;&#25152;&#36873;&#21333;&#20803;&#30340;&#12290;&#20854;&#19968;&#33324;&#24418;&#24335;&#36866;&#29992;&#20110;&#20219;&#24847;&#36873;&#25321;&#35268;&#21017;&#65292;&#24182;&#23558;Mondrian&#25972;&#20307;&#39044;&#27979;&#25512;&#24191;&#21040;&#22810;&#20010;&#27979;&#35797;&#21333;&#20803;&#21644;&#38750;&#31561;&#21464;&#20998;&#31867;&#22120;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20026;&#22810;&#20010;&#29616;&#23454;&#30340;&#36873;&#25321;&#35268;&#21017;&#35745;&#31639;&#20102;&#36866;&#29992;&#20110;&#25105;&#20204;&#26694;&#26550;&#30340;&#35745;&#31639;&#25928;&#29575;&#23454;&#29616;&#65292;&#21253;&#25324;top-K&#36873;&#25321;&#12289;&#20248;&#21270;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03868v1 Announce Type: cross  Abstract: Conformal prediction builds marginally valid prediction intervals which cover the unknown outcome of a randomly drawn new test point with a prescribed probability. In practice, a common scenario is that, after seeing the test unit(s), practitioners decide which test unit(s) to focus on in a data-driven manner, and wish to quantify the uncertainty for the focal unit(s). In such cases, marginally valid prediction intervals for these focal units can be misleading due to selection bias. This paper presents a general framework for constructing a prediction set with finite-sample exact coverage conditional on the unit being selected. Its general form works for arbitrary selection rules, and generalizes Mondrian Conformal Prediction to multiple test units and non-equivariant classifiers. We then work out computationally efficient implementation of our framework for a number of realistic selection rules, including top-K selection, optimization
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#32447;&#24615;&#34920;&#31034;&#30340;&#36215;&#28304;&#65292;&#36890;&#36807;&#24341;&#20837;&#31616;&#21333;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#24182;&#23637;&#31034;&#20102;&#26799;&#24230;&#19979;&#38477;&#30340;&#38544;&#24615;&#20559;&#24046;&#19982;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#30446;&#26631;&#20849;&#21516;&#20419;&#36827;&#20102;&#27010;&#24565;&#30340;&#32447;&#24615;&#34920;&#31034;&#12290;</title><link>https://arxiv.org/abs/2403.03867</link><description>&lt;p&gt;
&#35770;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#32447;&#24615;&#34920;&#31034;&#30340;&#36215;&#28304;
&lt;/p&gt;
&lt;p&gt;
On the Origins of Linear Representations in Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03867
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#32447;&#24615;&#34920;&#31034;&#30340;&#36215;&#28304;&#65292;&#36890;&#36807;&#24341;&#20837;&#31616;&#21333;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#24182;&#23637;&#31034;&#20102;&#26799;&#24230;&#19979;&#38477;&#30340;&#38544;&#24615;&#20559;&#24046;&#19982;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#30446;&#26631;&#20849;&#21516;&#20419;&#36827;&#20102;&#27010;&#24565;&#30340;&#32447;&#24615;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#30740;&#31350;&#34920;&#26126;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#34920;&#31034;&#31354;&#38388;&#20013;&#32534;&#30721;&#20102;&#39640;&#23618;&#35821;&#20041;&#27010;&#24565;&#26159;"&#32447;&#24615;"&#30340;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#36825;&#31181;&#32447;&#24615;&#34920;&#31034;&#30340;&#36215;&#28304;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#26469;&#25277;&#35937;&#21644;&#24418;&#24335;&#21270;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#30340;&#27010;&#24565;&#21160;&#24577;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#31181;&#24418;&#24335;&#21270;&#23637;&#31034;&#20102;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#30446;&#26631;&#65288;&#20855;&#26377;&#20132;&#21449;&#29109;&#30340;softmax&#65289;&#21644;&#26799;&#24230;&#19979;&#38477;&#30340;&#38544;&#24615;&#20559;&#24046;&#20849;&#21516;&#20419;&#36827;&#20102;&#27010;&#24565;&#30340;&#32447;&#24615;&#34920;&#31034;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#24403;&#23398;&#20064;&#19982;&#28508;&#21464;&#37327;&#27169;&#22411;&#21305;&#37197;&#30340;&#25968;&#25454;&#26102;&#65292;&#32447;&#24615;&#34920;&#31034;&#20250;&#20986;&#29616;&#65292;&#20174;&#32780;&#30830;&#35748;&#36825;&#31181;&#31616;&#21333;&#32467;&#26500;&#24050;&#36275;&#20197;&#20135;&#29983;&#32447;&#24615;&#34920;&#31034;&#12290;&#25105;&#20204;&#36824;&#20351;&#29992; LLaMA-2 &#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#39564;&#35777;&#20102;&#36825;&#19968;&#29702;&#35770;&#30340;&#37096;&#20998;&#39044;&#27979;&#65292;&#35777;&#26126;&#20102;&#31616;&#21270;&#27169;&#22411;&#25552;&#20379;&#20102;&#21487;&#25512;&#24191;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03867v1 Announce Type: new  Abstract: Recent works have argued that high-level semantic concepts are encoded "linearly" in the representation space of large language models. In this work, we study the origins of such linear representations. To that end, we introduce a simple latent variable model to abstract and formalize the concept dynamics of the next token prediction. We use this formalism to show that the next token prediction objective (softmax with cross-entropy) and the implicit bias of gradient descent together promote the linear representation of concepts. Experiments show that linear representations emerge when learning from data matching the latent variable model, confirming that this simple structure already suffices to yield linear representations. We additionally confirm some predictions of the theory using the LLaMA-2 large language model, giving evidence that the simplified model yields generalizable insights.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#30740;&#31350;&#20102;&#20844;&#20849;&#25968;&#25454;&#36741;&#21161;&#30340;&#31169;&#26377;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#22312;&#38543;&#26426;&#20984;&#20248;&#21270;&#38382;&#39064;&#20013;&#30340;&#38480;&#21046;&#21644;&#33021;&#21147;&#65292;&#23637;&#31034;&#20986;&#31616;&#21333;&#31574;&#30053;&#22312;&#36825;&#19968;&#39046;&#22495;&#30340;&#26368;&#20248;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.03856</link><description>&lt;p&gt;
&#20844;&#20849;&#25968;&#25454;&#36741;&#21161;&#19979;&#30340;&#31169;&#26377;&#38543;&#26426;&#20248;&#21270;&#65306;&#21160;&#21147;&#21644;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
Public-data Assisted Private Stochastic Optimization: Power and Limitations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03856
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#30740;&#31350;&#20102;&#20844;&#20849;&#25968;&#25454;&#36741;&#21161;&#30340;&#31169;&#26377;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#22312;&#38543;&#26426;&#20984;&#20248;&#21270;&#38382;&#39064;&#20013;&#30340;&#38480;&#21046;&#21644;&#33021;&#21147;&#65292;&#23637;&#31034;&#20986;&#31616;&#21333;&#31574;&#30053;&#22312;&#36825;&#19968;&#39046;&#22495;&#30340;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20844;&#20849;&#25968;&#25454;&#36741;&#21161;&#30340;&#24046;&#20998;&#38544;&#31169;&#65288;PA-DP&#65289;&#31639;&#27861;&#30340;&#38480;&#21046;&#21644;&#33021;&#21147;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#20851;&#27880;&#20855;&#26377;&#26631;&#35760;&#25110;&#26410;&#26631;&#35760;&#20844;&#20849;&#25968;&#25454;&#30340;&#38543;&#26426;&#20984;&#20248;&#21270;&#65288;SCO&#65289;&#38382;&#39064;&#12290;&#23545;&#20110;&#23436;&#25972;/&#26631;&#35760;&#30340;&#20844;&#20849;&#25968;&#25454;&#65292;&#25105;&#20204;&#34920;&#26126;&#20219;&#20309;$(\epsilon,\delta)$-PA-DP&#37117;&#20855;&#26377;&#36229;&#20986;&#39118;&#38505;$\tilde{\Omega}\big(\min\big\{\frac{1}{\sqrt{n_{\text{pub}}}},\frac{1}{\sqrt{n}}+\frac{\sqrt{d}}{n\epsilon} \big\} \big)$&#65292;&#20854;&#20013;$d$&#26159;&#32500;&#25968;&#65292;${n_{\text{pub}}}$&#26159;&#20844;&#20849;&#26679;&#26412;&#25968;&#37327;&#65292;${n_{\text{priv}}}$&#26159;&#31169;&#26377;&#26679;&#26412;&#25968;&#37327;&#65292;$n={n_{\text{pub}}}+{n_{\text{priv}}}$. &#36825;&#20123;&#19979;&#30028;&#26159;&#36890;&#36807;&#25105;&#20204;&#23545;PA-DP&#22343;&#20540;&#20272;&#35745;&#30340;&#26032;&#19979;&#30028;&#24314;&#31435;&#30340;&#65292;&#20854;&#24418;&#24335;&#30456;&#20284;&#12290;&#22312;&#24120;&#25968;&#22240;&#32032;&#30340;&#24433;&#21709;&#19979;&#65292;&#36825;&#20123;&#19979;&#30028;&#34920;&#26126;&#23558;&#25152;&#26377;&#25968;&#25454;&#35270;&#20026;&#31169;&#26377;&#25110;&#20002;&#24323;&#31169;&#26377;&#25968;&#25454;&#30340;&#31616;&#21333;&#31574;&#30053;&#26159;&#26368;&#20248;&#30340;&#12290;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#20855;&#26377;&#26410;&#26631;&#35760;&#20844;&#20849;&#25968;&#25454;&#30340;PA-DP&#30417;&#30563;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03856v1 Announce Type: new  Abstract: We study the limits and capability of public-data assisted differentially private (PA-DP) algorithms. Specifically, we focus on the problem of stochastic convex optimization (SCO) with either labeled or unlabeled public data. For complete/labeled public data, we show that any $(\epsilon,\delta)$-PA-DP has excess risk $\tilde{\Omega}\big(\min\big\{\frac{1}{\sqrt{n_{\text{pub}}}},\frac{1}{\sqrt{n}}+\frac{\sqrt{d}}{n\epsilon} \big\} \big)$, where $d$ is the dimension, ${n_{\text{pub}}}$ is the number of public samples, ${n_{\text{priv}}}$ is the number of private samples, and $n={n_{\text{pub}}}+{n_{\text{priv}}}$. These lower bounds are established via our new lower bounds for PA-DP mean estimation, which are of a similar form. Up to constant factors, these lower bounds show that the simple strategy of either treating all data as private or discarding the private data, is optimal. We also study PA-DP supervised learning with \textit{unlabe
&lt;/p&gt;</description></item><item><title>&#35774;&#35745;&#20102;&#26032;&#39062;&#30340;&#26080;&#38656;&#35757;&#32451;&#30340;&#31639;&#27861;&#65292;&#20197;&#21152;&#36895;&#27969;&#34892;&#30340;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#37319;&#26679;&#22120;&#65292;&#25913;&#36827;&#20102;&#30830;&#23450;&#24615;&#37319;&#26679;&#22120;&#30340;&#25910;&#25947;&#36895;&#29575;&#33267;$O(1/{T}^2)$&#65292;&#25552;&#21319;&#20102;&#38543;&#26426;&#37319;&#26679;&#22120;&#30340;&#25910;&#25947;&#36895;&#29575;&#33267;$O(1/T)$&#12290;</title><link>https://arxiv.org/abs/2403.03852</link><description>&lt;p&gt;
&#21152;&#36895;&#22522;&#20110;&#20998;&#25968;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#25910;&#25947;&#24615;&#65292;&#26377;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Accelerating Convergence of Score-Based Diffusion Models, Provably
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03852
&lt;/p&gt;
&lt;p&gt;
&#35774;&#35745;&#20102;&#26032;&#39062;&#30340;&#26080;&#38656;&#35757;&#32451;&#30340;&#31639;&#27861;&#65292;&#20197;&#21152;&#36895;&#27969;&#34892;&#30340;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#37319;&#26679;&#22120;&#65292;&#25913;&#36827;&#20102;&#30830;&#23450;&#24615;&#37319;&#26679;&#22120;&#30340;&#25910;&#25947;&#36895;&#29575;&#33267;$O(1/{T}^2)$&#65292;&#25552;&#21319;&#20102;&#38543;&#26426;&#37319;&#26679;&#22120;&#30340;&#25910;&#25947;&#36895;&#29575;&#33267;$O(1/T)$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20998;&#25968;&#30340;&#25193;&#25955;&#27169;&#22411;&#22312;&#23454;&#36341;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#32463;&#39564;&#24615;&#33021;&#65292;&#20294;&#36890;&#24120;&#30001;&#20110;&#22312;&#37319;&#26679;&#38454;&#27573;&#38656;&#35201;&#36827;&#34892;&#22823;&#37327;&#20989;&#25968;&#35780;&#20272;&#32780;&#23548;&#33268;&#37319;&#26679;&#36895;&#24230;&#36739;&#24930;&#12290;&#23613;&#31649;&#36817;&#24180;&#26469;&#19968;&#31995;&#21015;&#24037;&#20316;&#33268;&#21147;&#20110;&#21152;&#36895;&#25193;&#25955;&#29983;&#25104;&#24314;&#27169;&#65292;&#20294;&#21152;&#36895;&#25216;&#26415;&#30340;&#29702;&#35770;&#22522;&#30784;&#20173;&#28982;&#20005;&#37325;&#26377;&#38480;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#26032;&#39062;&#30340;&#26080;&#38656;&#35757;&#32451;&#30340;&#31639;&#27861;&#26469;&#21152;&#36895;&#27969;&#34892;&#30340;&#30830;&#23450;&#24615;&#65288;&#21363;DDIM&#65289;&#21644;&#38543;&#26426;&#65288;&#21363;DDPM&#65289;&#37319;&#26679;&#22120;&#12290;&#25105;&#20204;&#30340;&#21152;&#36895;&#30830;&#23450;&#24615;&#37319;&#26679;&#22120;&#20197;$O(1/{T}^2)$&#30340;&#36895;&#29575;&#25910;&#25947;&#65292;&#20854;&#20013;$T$&#20026;&#27493;&#25968;&#65292;&#25913;&#36827;&#20102;DDIM&#37319;&#26679;&#22120;&#30340;$O(1/T)$&#36895;&#29575;&#65307;&#32780;&#25105;&#20204;&#30340;&#21152;&#36895;&#38543;&#26426;&#37319;&#26679;&#22120;&#20197;$O(1/T)$&#30340;&#36895;&#29575;&#25910;&#25947;&#65292;&#20248;&#20110;DDPM&#37319;&#26679;&#22120;&#30340;$O(1/\sqrt{T})$&#36895;&#29575;&#12290;&#25105;&#20204;&#31639;&#27861;&#30340;&#35774;&#35745;&#21033;&#29992;&#20102;&#26356;&#39640;&#38454;&#36924;&#36817;&#30340;&#35265;&#35299;&#65292;&#24182;&#20855;&#26377;&#31867;&#20284;&#20110;&#27969;&#34892;&#30340;&#39640;&#38454;ODE&#27714;&#35299;&#22120;&#30340;&#30452;&#35273;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03852v1 Announce Type: cross  Abstract: Score-based diffusion models, while achieving remarkable empirical performance, often suffer from low sampling speed, due to extensive function evaluations needed during the sampling phase. Despite a flurry of recent activities towards speeding up diffusion generative modeling in practice, theoretical underpinnings for acceleration techniques remain severely limited. In this paper, we design novel training-free algorithms to accelerate popular deterministic (i.e., DDIM) and stochastic (i.e., DDPM) samplers. Our accelerated deterministic sampler converges at a rate $O(1/{T}^2)$ with $T$ the number of steps, improving upon the $O(1/T)$ rate for the DDIM sampler; and our accelerated stochastic sampler converges at a rate $O(1/T)$, outperforming the rate $O(1/\sqrt{T})$ for the DDPM sampler. The design of our algorithms leverages insights from higher-order approximation, and shares similar intuitions as popular high-order ODE solvers like 
&lt;/p&gt;</description></item><item><title>&#24320;&#21457;&#20102;&#19968;&#31181;&#21517;&#20026;$\texttt{MultiDimSPCI}$&#30340;&#39034;&#24207;CP&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#20013;&#26500;&#24314;&#39044;&#27979;&#21306;&#22495;&#65292;&#20855;&#26377;&#26356;&#23567;&#30340;&#39044;&#27979;&#21306;&#22495;&#21644;&#26377;&#25928;&#30340;&#35206;&#30422;&#12290;</title><link>https://arxiv.org/abs/2403.03850</link><description>&lt;p&gt;
&#21033;&#29992;&#26925;&#29699;&#38598;&#36827;&#34892;&#22810;&#32500;&#26102;&#38388;&#24207;&#21015;&#30340;&#21512;&#35268;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Conformal prediction for multi-dimensional time series by ellipsoidal sets
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03850
&lt;/p&gt;
&lt;p&gt;
&#24320;&#21457;&#20102;&#19968;&#31181;&#21517;&#20026;$\texttt{MultiDimSPCI}$&#30340;&#39034;&#24207;CP&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#20013;&#26500;&#24314;&#39044;&#27979;&#21306;&#22495;&#65292;&#20855;&#26377;&#26356;&#23567;&#30340;&#39044;&#27979;&#21306;&#22495;&#21644;&#26377;&#25928;&#30340;&#35206;&#30422;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21512;&#35268;&#39044;&#27979;&#65288;CP&#65289;&#22240;&#20854;&#26080;&#38656;&#20551;&#35774;&#20998;&#24067;&#12289;&#19981;&#21463;&#27169;&#22411;&#38480;&#21046;&#19988;&#22312;&#29702;&#35770;&#19978;&#21487;&#38752;&#32780;&#25104;&#20026;&#19968;&#31181;&#27969;&#34892;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#12290;&#23545;&#20110;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#39044;&#27979;&#38382;&#39064;&#65292;&#22823;&#22810;&#25968;CP&#26041;&#27861;&#19987;&#27880;&#20110;&#20026;&#21333;&#21464;&#37327;&#21709;&#24212;&#26500;&#24314;&#39044;&#27979;&#21306;&#38388;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#21517;&#20026;$\texttt{MultiDimSPCI}$&#30340;&#39034;&#24207;CP&#26041;&#27861;&#65292;&#29992;&#20110;&#20026;&#22810;&#20803;&#21709;&#24212;&#26500;&#24314;&#39044;&#27979;&#21306;&#22495;&#65292;&#29305;&#21035;&#26159;&#22312;&#19981;&#21487;&#20132;&#25442;&#30340;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#29615;&#22659;&#20013;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#20272;&#35745;&#20102;&#26465;&#20214;&#35206;&#30422;&#38388;&#38553;&#30340;&#26377;&#38480;&#26679;&#26412;&#39640;&#27010;&#29575;&#30028;&#38480;&#12290;&#22312;&#23454;&#35777;&#26041;&#38754;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;$\texttt{MultiDimSPCI}$&#22312;&#21508;&#31181;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#19978;&#20445;&#25345;&#26377;&#25928;&#35206;&#30422;&#65292;&#21516;&#26102;&#20135;&#29983;&#27604;CP&#21644;&#38750;CP&#22522;&#32447;&#26356;&#23567;&#30340;&#39044;&#27979;&#21306;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03850v1 Announce Type: cross  Abstract: Conformal prediction (CP) has been a popular method for uncertainty quantification because it is distribution-free, model-agnostic, and theoretically sound. For forecasting problems in supervised learning, most CP methods focus on building prediction intervals for univariate responses. In this work, we develop a sequential CP method called $\texttt{MultiDimSPCI}$ that builds prediction regions for a multivariate response, especially in the context of multivariate time series, which are not exchangeable. Theoretically, we estimate finite-sample high-probability bounds on the conditional coverage gap. Empirically, we demonstrate that $\texttt{MultiDimSPCI}$ maintains valid coverage on a wide range of multivariate time series while producing smaller prediction regions than CP and non-CP baselines.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20855;&#26377;&#22122;&#22768;&#21442;&#25968;&#30340;&#40657;&#30418;&#27169;&#25311;&#22120;&#30340;&#40065;&#26834;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#32852;&#21512;&#32771;&#34385;&#25511;&#21046;&#21442;&#25968;&#21644;&#19981;&#30830;&#23450;&#24615;&#21442;&#25968;&#65292;&#20197;&#26377;&#25928;&#20943;&#23569;&#26041;&#24046;&#24182;&#20805;&#20998;&#21033;&#29992;&#25511;&#21046;&#19982;&#22122;&#22768;&#30340;&#20132;&#20114;&#20316;&#29992;&#12290;</title><link>https://arxiv.org/abs/2403.03816</link><description>&lt;p&gt;
&#38024;&#23545;&#26041;&#24046;&#20943;&#23569;&#65306;&#20855;&#26377;&#22122;&#22768;&#21442;&#25968;&#30340;&#40657;&#30418;&#27169;&#25311;&#22120;&#30340;&#40065;&#26834;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Targeted Variance Reduction: Robust Bayesian Optimization of Black-Box Simulators with Noise Parameters
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03816
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20855;&#26377;&#22122;&#22768;&#21442;&#25968;&#30340;&#40657;&#30418;&#27169;&#25311;&#22120;&#30340;&#40065;&#26834;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#32852;&#21512;&#32771;&#34385;&#25511;&#21046;&#21442;&#25968;&#21644;&#19981;&#30830;&#23450;&#24615;&#21442;&#25968;&#65292;&#20197;&#26377;&#25928;&#20943;&#23569;&#26041;&#24046;&#24182;&#20805;&#20998;&#21033;&#29992;&#25511;&#21046;&#19982;&#22122;&#22768;&#30340;&#20132;&#20114;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#31185;&#23398;&#24212;&#29992;&#20013;&#65292;&#38656;&#35201;&#20248;&#21270;&#25511;&#21046;&#21442;&#25968;$\mathbf{x}$&#30340;&#40657;&#30418;&#27169;&#25311;&#22120;&#12290;&#22312;&#36825;&#20123;&#24212;&#29992;&#20013;&#65292;&#27169;&#25311;&#22120;&#36890;&#24120;&#37319;&#29992;&#24418;&#24335;$f(\mathbf{x},\boldsymbol{\theta})$&#65292;&#20854;&#20013;$\boldsymbol{\theta}$&#26159;&#23454;&#36341;&#20013;&#19981;&#30830;&#23450;&#30340;&#21442;&#25968;&#12290;&#40065;&#26834;&#20248;&#21270;&#30340;&#30446;&#26631;&#26159;&#20248;&#21270;&#26399;&#26395;$\mathbb{E}[f(\mathbf{x},\boldsymbol{\Theta})]$&#65292;&#20854;&#20013;$\boldsymbol{\Theta} \sim \mathcal{P}$&#26159;&#27169;&#25311;$\boldsymbol{\theta}$&#19981;&#30830;&#23450;&#24615;&#30340;&#38543;&#26426;&#21464;&#37327;&#12290;&#20026;&#27492;&#65292;&#29616;&#26377;&#30340;&#40657;&#30418;&#26041;&#27861;&#36890;&#24120;&#37319;&#29992;&#20004;&#38454;&#27573;&#26041;&#27861;&#26469;&#36873;&#25321;&#19979;&#19968;&#20010;&#28857;$(\mathbf{x},\boldsymbol{\theta})$&#65292;&#20854;&#20013;$\mathbf{x}$&#21644;$\boldsymbol{\theta}$&#36890;&#36807;&#19981;&#21516;&#30340;&#25910;&#33719;&#20989;&#25968;&#20998;&#21035;&#20248;&#21270;&#12290;&#22240;&#27492;&#65292;&#36825;&#20123;&#26041;&#27861;&#26410;&#23545;$(\mathbf{x},\boldsymbol{\theta})$&#36827;&#34892;&#32852;&#21512;&#33719;&#21462;&#65292;&#21487;&#33021;&#26080;&#27861;&#20805;&#20998;&#21033;&#29992;&#25511;&#21046;&#19982;&#22122;&#22768;&#30456;&#20114;&#20316;&#29992;&#23454;&#29616;&#26377;&#25928;&#30340;&#40065;&#26834;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03816v1 Announce Type: cross  Abstract: The optimization of a black-box simulator over control parameters $\mathbf{x}$ arises in a myriad of scientific applications. In such applications, the simulator often takes the form $f(\mathbf{x},\boldsymbol{\theta})$, where $\boldsymbol{\theta}$ are parameters that are uncertain in practice. Robust optimization aims to optimize the objective $\mathbb{E}[f(\mathbf{x},\boldsymbol{\Theta})]$, where $\boldsymbol{\Theta} \sim \mathcal{P}$ is a random variable that models uncertainty on $\boldsymbol{\theta}$. For this, existing black-box methods typically employ a two-stage approach for selecting the next point $(\mathbf{x},\boldsymbol{\theta})$, where $\mathbf{x}$ and $\boldsymbol{\theta}$ are optimized separately via different acquisition functions. As such, these approaches do not employ a joint acquisition over $(\mathbf{x},\boldsymbol{\theta})$, and thus may fail to fully exploit control-to-noise interactions for effective robust opti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#20010;&#37325;&#22797;&#30340;&#22996;&#25176;-&#20195;&#29702;&#36172;&#21338;&#28216;&#25103;&#65292;&#22312;&#20854;&#20013;&#22996;&#25176;&#26041;&#36890;&#36807;&#25552;&#20379;&#28608;&#21169;&#20197;&#24433;&#21709;&#20195;&#29702;&#26041;&#30340;&#20915;&#31574;&#65292;&#30446;&#26631;&#26159;&#36845;&#20195;&#23398;&#20064;&#28608;&#21169;&#31574;&#30053;&#26368;&#22823;&#21270;&#25928;&#29992;&#65292;&#25552;&#20986;&#20102;&#20851;&#20110;&#22996;&#25176;&#26041;&#21518;&#24724;&#30340;&#20960;&#20046;&#26368;&#20248;&#23398;&#20064;&#31639;&#27861;&#65292;&#25903;&#25745;&#29702;&#35770;&#20445;&#35777;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#12290;</title><link>https://arxiv.org/abs/2403.03811</link><description>&lt;p&gt;
&#22996;&#25176;-&#20195;&#29702;&#36172;&#21338;&#28216;&#25103;&#20013;&#30340;&#28608;&#21169;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Incentivized Learning in Principal-Agent Bandit Games
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03811
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#20010;&#37325;&#22797;&#30340;&#22996;&#25176;-&#20195;&#29702;&#36172;&#21338;&#28216;&#25103;&#65292;&#22312;&#20854;&#20013;&#22996;&#25176;&#26041;&#36890;&#36807;&#25552;&#20379;&#28608;&#21169;&#20197;&#24433;&#21709;&#20195;&#29702;&#26041;&#30340;&#20915;&#31574;&#65292;&#30446;&#26631;&#26159;&#36845;&#20195;&#23398;&#20064;&#28608;&#21169;&#31574;&#30053;&#26368;&#22823;&#21270;&#25928;&#29992;&#65292;&#25552;&#20986;&#20102;&#20851;&#20110;&#22996;&#25176;&#26041;&#21518;&#24724;&#30340;&#20960;&#20046;&#26368;&#20248;&#23398;&#20064;&#31639;&#27861;&#65292;&#25903;&#25745;&#29702;&#35770;&#20445;&#35777;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#20010;&#37325;&#22797;&#30340;&#22996;&#25176;-&#20195;&#29702;&#36172;&#21338;&#28216;&#25103;&#65292;&#22996;&#25176;&#26041;&#21482;&#33021;&#36890;&#36807;&#20195;&#29702;&#19982;&#29615;&#22659;&#20114;&#21160;&#12290;&#22996;&#25176;&#26041;&#21644;&#20195;&#29702;&#26041;&#30340;&#30446;&#26631;&#19981;&#19968;&#33268;&#65292;&#36873;&#25321;&#34892;&#21160;&#30340;&#26435;&#21033;&#20165;&#24402;&#20195;&#29702;&#26041;&#25152;&#26377;&#12290;&#28982;&#32780;&#65292;&#22996;&#25176;&#26041;&#21487;&#20197;&#36890;&#36807;&#25552;&#20379;&#28608;&#21169;&#26469;&#24433;&#21709;&#20195;&#29702;&#26041;&#30340;&#20915;&#31574;&#65292;&#28608;&#21169;&#23558;&#35745;&#20837;&#20854;&#22870;&#21169;&#20043;&#20013;&#12290;&#22996;&#25176;&#26041;&#30340;&#30446;&#26631;&#26159;&#36845;&#20195;&#23398;&#20064;&#19968;&#31181;&#28608;&#21169;&#31574;&#30053;&#65292;&#20197;&#26368;&#22823;&#21270;&#20854;&#24635;&#25928;&#29992;&#12290;&#36825;&#19968;&#26694;&#26550;&#25193;&#23637;&#20102;&#20256;&#32479;&#30340;&#36172;&#21338;&#38382;&#39064;&#65292;&#24182;&#21463;&#21040;&#20102;&#20960;&#20010;&#23454;&#38469;&#24212;&#29992;&#30340;&#21551;&#21457;&#65292;&#22914;&#21307;&#30103;&#20445;&#20581;&#25110;&#29983;&#24577;&#31246;&#25910;&#65292;&#20256;&#32479;&#30340;&#26426;&#21046;&#35774;&#35745;&#29702;&#35770;&#24448;&#24448;&#24573;&#35270;&#20102;&#38382;&#39064;&#30340;&#23398;&#20064;&#26041;&#38754;&#12290;&#25105;&#20204;&#22312;&#22810;&#33218;&#21644;&#32447;&#24615;&#32972;&#26223;&#35774;&#32622;&#19979;&#25552;&#20986;&#20102;&#20851;&#20110;&#22996;&#25176;&#26041;&#21518;&#24724;&#30340;&#20960;&#20046;&#26368;&#20248;&#65288;&#30456;&#23545;&#20110;&#19968;&#20010;&#26102;&#22495; T &#30340;&#65289;&#23398;&#20064;&#31639;&#27861;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#25903;&#25345;&#25105;&#20204;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03811v1 Announce Type: cross  Abstract: This work considers a repeated principal-agent bandit game, where the principal can only interact with her environment through the agent. The principal and the agent have misaligned objectives and the choice of action is only left to the agent. However, the principal can influence the agent's decisions by offering incentives which add up to his rewards. The principal aims to iteratively learn an incentive policy to maximize her own total utility. This framework extends usual bandit problems and is motivated by several practical applications, such as healthcare or ecological taxation, where traditionally used mechanism design theories often overlook the learning aspect of the problem. We present nearly optimal (with respect to a horizon $T$) learning algorithms for the principal's regret in both multi-armed and linear contextual settings. Finally, we support our theoretical guarantees through numerical experiments.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26377;&#25928;&#22320;&#24182;&#34892;&#21270;&#29616;&#26377;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#65292;&#26412;&#30740;&#31350;&#23454;&#29616;&#20102;&#23545;&#25968;&#21315;&#20010;&#32500;&#24230;&#30340;&#25193;&#23637;&#65292;&#29305;&#21035;&#26159;&#23558;LiNGAM&#26041;&#27861;&#24182;&#34892;&#21270;&#65292;&#33719;&#24471;&#20102;&#22810;&#36798;32&#20493;&#30340;&#21152;&#36895;&#12290;</title><link>https://arxiv.org/abs/2403.03772</link><description>&lt;p&gt;
&#21152;&#36895;LiNGAM: &#20197;GPU&#36895;&#24230;&#23398;&#20064;&#22240;&#26524;DAGs
&lt;/p&gt;
&lt;p&gt;
AcceleratedLiNGAM: Learning Causal DAGs at the speed of GPUs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03772
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26377;&#25928;&#22320;&#24182;&#34892;&#21270;&#29616;&#26377;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#65292;&#26412;&#30740;&#31350;&#23454;&#29616;&#20102;&#23545;&#25968;&#21315;&#20010;&#32500;&#24230;&#30340;&#25193;&#23637;&#65292;&#29305;&#21035;&#26159;&#23558;LiNGAM&#26041;&#27861;&#24182;&#34892;&#21270;&#65292;&#33719;&#24471;&#20102;&#22810;&#36798;32&#20493;&#30340;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#22522;&#20110;&#32452;&#21512;&#20248;&#21270;&#25110;&#25628;&#32034;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#36895;&#24230;&#36739;&#24930;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#30340;&#24212;&#29992;&#12290;&#26368;&#36817;&#30340;&#19968;&#20123;&#26041;&#27861;&#23581;&#35797;&#36890;&#36807;&#36830;&#32493;&#20248;&#21270;&#30340;&#32467;&#26500;&#23398;&#20064;&#26469;&#35299;&#20915;&#36825;&#19968;&#38480;&#21046;&#65292;&#20294;&#36804;&#20170;&#20026;&#27490;&#36825;&#20123;&#26041;&#27861;&#24182;&#26410;&#25552;&#20379;&#32479;&#35745;&#20445;&#35777;&#12290;&#26412;&#25991;&#36890;&#36807;&#26377;&#25928;&#22320;&#24182;&#34892;&#21270;&#29616;&#26377;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#65292;&#23637;&#31034;&#25105;&#20204;&#23454;&#38469;&#19978;&#21487;&#20197;&#23558;&#23427;&#20204;&#25193;&#23637;&#21040;&#25968;&#21315;&#20010;&#32500;&#24230;&#65292;&#20351;&#20854;&#22312;&#35268;&#27169;&#26356;&#22823;&#30340;&#38382;&#39064;&#19978;&#21464;&#24471;&#23454;&#29992;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23545;LiNGAM&#26041;&#27861;&#36827;&#34892;&#20102;&#24182;&#34892;&#21270;&#65292;&#36825;&#31181;&#26041;&#27861;&#19982;&#21464;&#37327;&#25968;&#37327;&#25104;&#20108;&#27425;&#20851;&#31995;&#65292;&#19982;&#29616;&#26377;&#30340;&#39034;&#24207;&#23454;&#29616;&#30456;&#27604;&#65292;&#25105;&#20204;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#33719;&#24471;&#20102;&#22810;&#36798;32&#20493;&#30340;&#21152;&#36895;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;DirectLiNGAM&#20013;&#30340;&#22240;&#26524;&#25490;&#24207;&#23376;&#36807;&#31243;&#65292;&#24182;&#23454;&#29616;&#20102;GPU&#26680;&#24515;&#20197;&#21152;&#36895;&#23427;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;DirectLiNGAM&#24212;&#29992;&#20110;&#22240;&#26524;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03772v1 Announce Type: new  Abstract: Existing causal discovery methods based on combinatorial optimization or search are slow, prohibiting their application on large-scale datasets. In response, more recent methods attempt to address this limitation by formulating causal discovery as structure learning with continuous optimization but such approaches thus far provide no statistical guarantees. In this paper, we show that by efficiently parallelizing existing causal discovery methods, we can in fact scale them to thousands of dimensions, making them practical for substantially larger-scale problems. In particular, we parallelize the LiNGAM method, which is quadratic in the number of variables, obtaining up to a 32-fold speed-up on benchmark datasets when compared with existing sequential implementations. Specifically, we focus on the causal ordering subprocedure in DirectLiNGAM and implement GPU kernels to accelerate it. This allows us to apply DirectLiNGAM to causal inferen
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#20026;&#27431;&#27954;&#20013;&#31243;&#27668;&#35937;&#20013;&#24515;&#30340;&#38598;&#25104;&#39044;&#27979;&#31995;&#32479;&#24320;&#21457;&#27169;&#22411;&#35823;&#24046;&#26657;&#27491;&#65292;&#20197;&#35299;&#20915;&#26426;&#22120;&#23398;&#20064;&#22825;&#27668;&#39044;&#25253;&#27169;&#22411;&#22312;&#34920;&#31034;&#21160;&#21147;&#24179;&#34913;&#21644;&#36866;&#29992;&#20110;&#25968;&#25454;&#21516;&#21270;&#23454;&#39564;&#26041;&#38754;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2403.03702</link><description>&lt;p&gt;
&#22312;&#32447;&#27169;&#22411;&#35823;&#24046;&#26657;&#27491;&#19982;&#31070;&#32463;&#32593;&#32476;: &#24212;&#29992;&#20110;&#38598;&#25104;&#39044;&#27979;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Online model error correction with neural networks: application to the Integrated Forecasting System
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03702
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#20026;&#27431;&#27954;&#20013;&#31243;&#27668;&#35937;&#20013;&#24515;&#30340;&#38598;&#25104;&#39044;&#27979;&#31995;&#32479;&#24320;&#21457;&#27169;&#22411;&#35823;&#24046;&#26657;&#27491;&#65292;&#20197;&#35299;&#20915;&#26426;&#22120;&#23398;&#20064;&#22825;&#27668;&#39044;&#25253;&#27169;&#22411;&#22312;&#34920;&#31034;&#21160;&#21147;&#24179;&#34913;&#21644;&#36866;&#29992;&#20110;&#25968;&#25454;&#21516;&#21270;&#23454;&#39564;&#26041;&#38754;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20960;&#24180;&#65292;&#22312;&#20840;&#29699;&#25968;&#20540;&#22825;&#27668;&#39044;&#25253;&#27169;&#22411;&#30340;&#23436;&#20840;&#25968;&#25454;&#39537;&#21160;&#24320;&#21457;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#12290;&#36825;&#20123;&#26426;&#22120;&#23398;&#20064;&#22825;&#27668;&#39044;&#25253;&#27169;&#22411;&#20855;&#26377;&#20854;&#20248;&#21183;&#65292;&#23588;&#20854;&#26159;&#20934;&#30830;&#24615;&#21644;&#36739;&#20302;&#30340;&#35745;&#31639;&#38656;&#27714;&#65292;&#20294;&#20063;&#23384;&#22312;&#20854;&#24369;&#28857;&#65306;&#23427;&#20204;&#38590;&#20197;&#34920;&#31034;&#22522;&#26412;&#21160;&#21147;&#24179;&#34913;&#65292;&#24182;&#19988;&#36828;&#26410;&#36866;&#29992;&#20110;&#36164;&#26009;&#21516;&#21270;&#23454;&#39564;&#12290;&#28151;&#21512;&#24314;&#27169;&#20986;&#29616;&#20026;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#30340;&#19968;&#31181;&#26377;&#24076;&#26395;&#30340;&#26041;&#27861;&#12290;&#28151;&#21512;&#27169;&#22411;&#23558;&#22522;&#20110;&#29289;&#29702;&#30340;&#26680;&#24515;&#32452;&#20214;&#19982;&#32479;&#35745;&#32452;&#20214;&#65288;&#36890;&#24120;&#26159;&#31070;&#32463;&#32593;&#32476;&#65289;&#38598;&#25104;&#22312;&#19968;&#36215;&#65292;&#20197;&#22686;&#24378;&#39044;&#27979;&#33021;&#21147;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#20026;&#27431;&#27954;&#20013;&#31243;&#27668;&#35937;&#20013;&#24515;&#30340;&#36816;&#34892;&#38598;&#25104;&#39044;&#27979;&#31995;&#32479;&#65288;IFS&#65289;&#24320;&#21457;&#27169;&#22411;&#35823;&#24046;&#26657;&#27491;&#12290;&#31070;&#32463;&#32593;&#32476;&#26368;&#21021;&#20250;&#31163;&#32447;&#36827;&#34892;&#39044;&#35757;&#32451;&#65292;&#20351;&#29992;&#22823;&#37327;&#36816;&#34892;&#20998;&#26512;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03702v1 Announce Type: cross  Abstract: In recent years, there has been significant progress in the development of fully data-driven global numerical weather prediction models. These machine learning weather prediction models have their strength, notably accuracy and low computational requirements, but also their weakness: they struggle to represent fundamental dynamical balances, and they are far from being suitable for data assimilation experiments. Hybrid modelling emerges as a promising approach to address these limitations. Hybrid models integrate a physics-based core component with a statistical component, typically a neural network, to enhance prediction capabilities. In this article, we propose to develop a model error correction for the operational Integrated Forecasting System (IFS) of the European Centre for Medium-Range Weather Forecasts using a neural network. The neural network is initially pre-trained offline using a large dataset of operational analyses and a
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#19981;&#22343;&#21248;&#23574;&#23792;&#32500;&#26684;&#32435;&#27169;&#22411;&#30340;&#26368;&#20248;&#20809;&#35889;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#36716;&#21270;&#30697;&#38453;&#30340;&#28145;&#20837;&#20005;&#26684;&#20998;&#26512;&#65292;&#22312;&#26368;&#20339;&#38408;&#20540;&#22788;&#23454;&#29616;&#20102;&#24322;&#24120;&#20540;&#21644;&#27491;&#37325;&#21472;&#30340;&#30456;&#20301;&#36716;&#25442;&#12290;</title><link>https://arxiv.org/abs/2403.03695</link><description>&lt;p&gt;
&#20855;&#26377;&#22359;&#32467;&#26500;&#23574;&#23792;&#27169;&#22411;&#20013;&#30340;&#20809;&#35889;&#30456;&#20301;&#36716;&#25442;&#21644;&#26368;&#20248;PCA
&lt;/p&gt;
&lt;p&gt;
Spectral Phase Transition and Optimal PCA in Block-Structured Spiked models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03695
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#19981;&#22343;&#21248;&#23574;&#23792;&#32500;&#26684;&#32435;&#27169;&#22411;&#30340;&#26368;&#20248;&#20809;&#35889;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#36716;&#21270;&#30697;&#38453;&#30340;&#28145;&#20837;&#20005;&#26684;&#20998;&#26512;&#65292;&#22312;&#26368;&#20339;&#38408;&#20540;&#22788;&#23454;&#29616;&#20102;&#24322;&#24120;&#20540;&#21644;&#27491;&#37325;&#21472;&#30340;&#30456;&#20301;&#36716;&#25442;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35752;&#35770;&#20102;&#19981;&#22343;&#21248;&#23574;&#23792;&#32500;&#26684;&#32435;&#27169;&#22411;&#65292;&#36825;&#26159;&#26368;&#36817;&#24341;&#20837;&#30340;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#29992;&#20110;&#30740;&#31350;&#21508;&#31181;&#23398;&#20064;&#22330;&#26223;&#20013;&#30340;&#32467;&#26500;&#22122;&#22768;&#65292;&#36890;&#36807;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#26865;&#38236;&#65292;&#29305;&#21035;&#20851;&#27880;&#20854;&#20809;&#35889;&#29305;&#24615;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#25214;&#21040;&#19968;&#31181;&#26368;&#20248;&#30340;&#20809;&#35889;&#26041;&#27861;&#65292;&#24182;&#23558;&#22312;&#19981;&#22343;&#21248;&#65292;&#22359;&#32467;&#26500;&#30340;&#32500;&#26684;&#32435;&#27169;&#22411;&#20013;&#26377;&#21517;&#30340;\cite{BBP}&#65288;BBP&#65289;&#30456;&#20301;&#36716;&#25442;&#20934;&#21017;&#25193;&#23637;&#21040;&#25105;&#20204;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#23545;&#19968;&#20010;&#36716;&#25442;&#30697;&#38453;&#36827;&#34892;&#20102;&#24443;&#24213;&#30340;&#20005;&#26684;&#20998;&#26512;&#65292;&#24182;&#23637;&#31034;&#20102;&#20986;&#29616;1&#65289;&#22312;&#26497;&#38480;&#20809;&#35889;&#20998;&#24067;&#30340;&#32676;&#22806;&#30340;&#24322;&#24120;&#20540;&#21644;2&#65289;&#30456;&#20851;&#29305;&#24449;&#21521;&#37327;&#19982;&#20449;&#21495;&#20043;&#38388;&#30340;&#27491;&#37325;&#21472;&#30340;&#36716;&#21464;&#27491;&#22909;&#21457;&#29983;&#22312;&#26368;&#20339;&#38408;&#20540;&#22788;&#65292;&#20351;&#24471;&#25152;&#25552;&#20986;&#30340;&#20809;&#35889;&#26041;&#27861;&#22312;&#19981;&#22343;&#21248;&#32500;&#26684;&#32435;&#38382;&#39064;&#30340;&#36845;&#20195;&#26041;&#27861;&#31867;&#20013;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03695v1 Announce Type: cross  Abstract: We discuss the inhomogeneous spiked Wigner model, a theoretical framework recently introduced to study structured noise in various learning scenarios, through the prism of random matrix theory, with a specific focus on its spectral properties. Our primary objective is to find an optimal spectral method and to extend the celebrated \cite{BBP} (BBP) phase transition criterion -- well-known in the homogeneous case -- to our inhomogeneous, block-structured, Wigner model. We provide a thorough rigorous analysis of a transformed matrix and show that the transition for the appearance of 1) an outlier outside the bulk of the limiting spectral distribution and 2) a positive overlap between the associated eigenvector and the signal, occurs precisely at the optimal threshold, making the proposed spectral method optimal within the class of iterative methods for the inhomogeneous Wigner problem.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35270;&#35282;&#65292;&#23558;&#36755;&#20837;&#25968;&#25454;&#35270;&#20026;&#23884;&#20837;&#21040;&#26356;&#39640;&#32500;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#30340;&#20302;&#32500;&#27969;&#24418;&#65292;&#24182;&#30740;&#31350;&#20102;&#22312;RKHS&#20013;&#35889;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#28909;&#26680;&#29983;&#25104;&#30340;&#25193;&#25955;&#31354;&#38388;&#65292;&#36890;&#36807;&#31215;&#20998;&#31639;&#23376;&#25216;&#26415;&#25512;&#23548;&#20102;&#20851;&#20110;&#24191;&#20041;&#33539;&#25968;&#30340;&#32039;&#25910;&#25947;&#19978;&#30028;&#65292;&#20351;&#20272;&#35745;&#22120;&#22312;&#24378;&#24847;&#20041;&#19979;&#25910;&#25947;&#21040;&#30446;&#26631;&#20989;&#25968;&#12290;</title><link>https://arxiv.org/abs/2403.03669</link><description>&lt;p&gt;
&#36890;&#36807;&#25193;&#25955;&#22312;&#27969;&#24418;&#19978;&#30340;&#35889;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Spectral Algorithms on Manifolds through Diffusion
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03669
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35270;&#35282;&#65292;&#23558;&#36755;&#20837;&#25968;&#25454;&#35270;&#20026;&#23884;&#20837;&#21040;&#26356;&#39640;&#32500;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#30340;&#20302;&#32500;&#27969;&#24418;&#65292;&#24182;&#30740;&#31350;&#20102;&#22312;RKHS&#20013;&#35889;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#28909;&#26680;&#29983;&#25104;&#30340;&#25193;&#25955;&#31354;&#38388;&#65292;&#36890;&#36807;&#31215;&#20998;&#31639;&#23376;&#25216;&#26415;&#25512;&#23548;&#20102;&#20851;&#20110;&#24191;&#20041;&#33539;&#25968;&#30340;&#32039;&#25910;&#25947;&#19978;&#30028;&#65292;&#20351;&#20272;&#35745;&#22120;&#22312;&#24378;&#24847;&#20041;&#19979;&#25910;&#25947;&#21040;&#30446;&#26631;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#37325;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#20013;&#24212;&#29992;&#30340;&#35889;&#31639;&#27861;&#30340;&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#19968;&#33324;&#26680;&#20989;&#25968;&#19978;&#65292;&#32463;&#24120;&#24573;&#30053;&#36755;&#20837;&#29305;&#24449;&#31354;&#38388;&#30340;&#22266;&#26377;&#32467;&#26500;&#12290;&#25105;&#20204;&#30340;&#35770;&#25991;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#35270;&#35282;&#65292;&#20027;&#24352;&#36755;&#20837;&#25968;&#25454;&#20301;&#20110;&#19968;&#20010;&#23884;&#20837;&#21040;&#26356;&#39640;&#32500;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#30340;&#20302;&#32500;&#27969;&#24418;&#20869;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;RKHS&#20013;&#35889;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#37027;&#20123;&#30001;&#28909;&#26680;&#29983;&#25104;&#30340;&#65292;&#34987;&#31216;&#20026;&#25193;&#25955;&#31354;&#38388;&#30340;&#31354;&#38388;&#12290;&#36890;&#36807;&#32467;&#21512;&#36755;&#20837;&#30340;&#27969;&#24418;&#32467;&#26500;&#65292;&#25105;&#20204;&#37319;&#29992;&#31215;&#20998;&#31639;&#23376;&#25216;&#26415;&#25512;&#23548;&#20102;&#20851;&#20110;&#24191;&#20041;&#33539;&#25968;&#30340;&#32039;&#25910;&#25947;&#19978;&#30028;&#65292;&#36825;&#34920;&#26126;&#20272;&#35745;&#22120;&#22312;&#24378;&#24847;&#20041;&#19979;&#25910;&#25947;&#21040;&#30446;&#26631;&#20989;&#25968;&#65292;&#24847;&#21619;&#30528;&#20989;&#25968;&#26412;&#36523;&#21450;&#20854;&#23548;&#25968;&#21516;&#26102;&#25910;&#25947;&#12290;&#36825;&#20123;&#30028;&#25552;&#20379;&#20102;&#20004;&#20010;&#37325;&#35201;&#20248;&#21183;&#65306;&#39318;&#20808;&#65292;&#23427;&#20204;&#26159;&#23436;&#20840;&#36830;&#32493;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03669v1 Announce Type: cross  Abstract: The existing research on spectral algorithms, applied within a Reproducing Kernel Hilbert Space (RKHS), has primarily focused on general kernel functions, often neglecting the inherent structure of the input feature space. Our paper introduces a new perspective, asserting that input data are situated within a low-dimensional manifold embedded in a higher-dimensional Euclidean space. We study the convergence performance of spectral algorithms in the RKHSs, specifically those generated by the heat kernels, known as diffusion spaces. Incorporating the manifold structure of the input, we employ integral operator techniques to derive tight convergence upper bounds concerning generalized norms, which indicates that the estimators converge to the target function in strong sense, entailing the simultaneous convergence of the function itself and its derivatives. These bounds offer two significant advantages: firstly, they are exclusively contin
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#21033;&#29992;&#38543;&#26426;&#23545;&#20598;&#29702;&#35770;&#65292;&#23545;&#38543;&#26426;&#32447;&#24615;&#35268;&#21010;&#30340;&#30830;&#20999;&#30446;&#26631;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#29305;&#21035;&#20851;&#27880;&#32447;&#24615;&#30446;&#26631;&#19982;&#38543;&#26426;&#22810;&#38754;&#20307;&#30340;&#24179;&#22343;&#23485;&#24230;&#30340;&#32852;&#31995;&#12290;</title><link>https://arxiv.org/abs/2403.03637</link><description>&lt;p&gt;
&#38543;&#26426;&#32447;&#24615;&#35268;&#21010;&#30340;&#30830;&#20999;&#30446;&#26631;&#21644;&#38543;&#26426;&#22810;&#38754;&#20307;&#30340;&#24179;&#22343;&#23485;&#24230;
&lt;/p&gt;
&lt;p&gt;
Exact objectives of random linear programs and mean widths of random polyhedrons
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03637
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#21033;&#29992;&#38543;&#26426;&#23545;&#20598;&#29702;&#35770;&#65292;&#23545;&#38543;&#26426;&#32447;&#24615;&#35268;&#21010;&#30340;&#30830;&#20999;&#30446;&#26631;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#29305;&#21035;&#20851;&#27880;&#32447;&#24615;&#30446;&#26631;&#19982;&#38543;&#26426;&#22810;&#38754;&#20307;&#30340;&#24179;&#22343;&#23485;&#24230;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;\emph{&#38543;&#26426;&#32447;&#24615;&#35268;&#21010;}&#65288;rlps&#65289;&#20316;&#20026;\emph{&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;}&#65288;rops&#65289;&#30340;&#19968;&#20010;&#23376;&#31867;&#65292;&#24182;&#30740;&#31350;&#23427;&#20204;&#30340;&#20856;&#22411;&#34892;&#20026;&#12290;&#25105;&#20204;&#29305;&#21035;&#20851;&#27880;&#19982;&#38543;&#26426;&#22810;&#38754;&#20307;/&#22810;&#38754;&#20307;&#30340;&#24179;&#22343;&#23485;&#24230;&#30456;&#20851;&#30340;&#36866;&#24403;&#32447;&#24615;&#30446;&#26631;&#12290;&#21033;&#29992;\emph{&#38543;&#26426;&#23545;&#20598;&#29702;&#35770;}&#65288;RDT&#65289;\cite{StojnicRegRndDlt10}&#24378;&#22823;&#30340;&#24037;&#20855;&#65292;&#25105;&#20204;&#22312;&#22823;&#32500;&#24230;&#24773;&#22659;&#19979;&#33719;&#24471;&#20102;&#31243;&#24207;&#30446;&#26631;&#30340;&#30830;&#20999;&#29305;&#24449;&#12290;&#29305;&#21035;&#26159;&#65292;&#23545;&#20110;&#20219;&#24847;$\alpha=\lim_{n\rightarrow\infty}\frac{m}{n}\in(0,\infty)$&#65292;&#20219;&#24847;&#21333;&#20301;&#21521;&#37327;$\mathbf{c}\in{\mathbb R}^n$&#65292;&#20219;&#24847;&#22266;&#23450;&#30340;$\mathbf{a}\in{\mathbb R}^n$&#65292;&#21644;&#20855;&#26377;iid&#26631;&#20934;&#27491;&#24577;&#39033;&#30340;$A\in {\mathbb R}^{m\times n}$&#65292;&#25105;&#20204;&#26377;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03637v1 Announce Type: cross  Abstract: We consider \emph{random linear programs} (rlps) as a subclass of \emph{random optimization problems} (rops) and study their typical behavior. Our particular focus is on appropriate linear objectives which connect the rlps to the mean widths of random polyhedrons/polytopes. Utilizing the powerful machinery of \emph{random duality theory} (RDT) \cite{StojnicRegRndDlt10}, we obtain, in a large dimensional context, the exact characterizations of the program's objectives. In particular, for any $\alpha=\lim_{n\rightarrow\infty}\frac{m}{n}\in(0,\infty)$, any unit vector $\mathbf{c}\in{\mathbb R}^n$, any fixed $\mathbf{a}\in{\mathbb R}^n$, and $A\in {\mathbb R}^{m\times n}$ with iid standard normal entries, we have   \begin{eqnarray*}   \lim_{n\rightarrow\infty}{\mathbb P}_{A} \left ( (1-\epsilon) \xi_{opt}(\alpha;\mathbf{a})   \leq \min_{A\mathbf{x}\leq \mathbf{a}}\mathbf{c}^T\mathbf{x} \leq (1+\epsilon) \xi_{opt}(\alpha;\mathbf{a}) \right 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20943;&#23569;&#23618;&#27425;&#20998;&#31867;&#21464;&#37327;&#32500;&#24230;&#21644;&#31890;&#24230;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23454;&#20307;&#23884;&#20837;&#21644;&#33258;&#19978;&#32780;&#19979;&#32858;&#31867;&#31639;&#27861;&#26469;&#38477;&#20302;&#23618;&#20869;&#32500;&#24230;&#21644;&#25972;&#20307;&#31890;&#24230;&#12290;</title><link>https://arxiv.org/abs/2403.03613</link><description>&lt;p&gt;
&#20943;&#23569;&#23618;&#27425;&#20998;&#31867;&#21464;&#37327;&#30340;&#32500;&#24230;&#21644;&#31890;&#24230;
&lt;/p&gt;
&lt;p&gt;
Reducing the dimensionality and granularity in hierarchical categorical variables
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03613
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20943;&#23569;&#23618;&#27425;&#20998;&#31867;&#21464;&#37327;&#32500;&#24230;&#21644;&#31890;&#24230;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23454;&#20307;&#23884;&#20837;&#21644;&#33258;&#19978;&#32780;&#19979;&#32858;&#31867;&#31639;&#27861;&#26469;&#38477;&#20302;&#23618;&#20869;&#32500;&#24230;&#21644;&#25972;&#20307;&#31890;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23618;&#27425;&#20998;&#31867;&#21464;&#37327;&#24448;&#24448;&#20855;&#26377;&#35768;&#22810;&#32423;&#21035;&#65288;&#39640;&#31890;&#24230;&#65289;&#21644;&#27599;&#20010;&#32423;&#21035;&#20869;&#35768;&#22810;&#31867;&#21035;&#65288;&#39640;&#32500;&#24230;&#65289;&#12290;&#23558;&#36825;&#20123;&#21327;&#21464;&#37327;&#21253;&#21547;&#22312;&#39044;&#27979;&#27169;&#22411;&#20013;&#21487;&#33021;&#23548;&#33268;&#36807;&#24230;&#25311;&#21512;&#21644;&#20272;&#35745;&#38382;&#39064;&#12290;&#22312;&#24403;&#21069;&#25991;&#29486;&#20013;&#65292;&#23618;&#27425;&#21327;&#21464;&#37327;&#36890;&#24120;&#36890;&#36807;&#23884;&#22871;&#38543;&#26426;&#25928;&#24212;&#26469;&#32435;&#20837;&#12290;&#28982;&#32780;&#65292;&#36825;&#24182;&#19981;&#26377;&#21161;&#20110;&#20551;&#35774;&#31867;&#21035;&#23545;&#21709;&#24212;&#21464;&#37327;&#20855;&#26377;&#30456;&#21516;&#30340;&#24433;&#21709;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33719;&#24471;&#23618;&#27425;&#20998;&#31867;&#21464;&#37327;&#31616;&#21270;&#34920;&#31034;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#23618;&#27425;&#35774;&#32622;&#20013;&#24212;&#29992;&#23454;&#20307;&#23884;&#20837;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#19978;&#32780;&#19979;&#30340;&#32858;&#31867;&#31639;&#27861;&#65292;&#21033;&#29992;&#23884;&#20837;&#20013;&#32534;&#30721;&#30340;&#20449;&#24687;&#26469;&#20943;&#23569;&#23618;&#20869;&#32500;&#24230;&#20197;&#21450;&#23618;&#27425;&#20998;&#31867;&#21464;&#37327;&#30340;&#25972;&#20307;&#31890;&#24230;&#12290;&#22312;&#27169;&#25311;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#22320;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03613v1 Announce Type: cross  Abstract: Hierarchical categorical variables often exhibit many levels (high granularity) and many classes within each level (high dimensionality). This may cause overfitting and estimation issues when including such covariates in a predictive model. In current literature, a hierarchical covariate is often incorporated via nested random effects. However, this does not facilitate the assumption of classes having the same effect on the response variable. In this paper, we propose a methodology to obtain a reduced representation of a hierarchical categorical variable. We show how entity embedding can be applied in a hierarchical setting. Subsequently, we propose a top-down clustering algorithm which leverages the information encoded in the embeddings to reduce both the within-level dimensionality as well as the overall granularity of the hierarchical categorical variable. In simulation experiments, we show that our methodology can effectively appro
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22522;&#20110;&#25968;&#25454;&#30340;&#26041;&#27861;&#27169;&#25311;&#20102;&#27668;&#32568;&#21387;&#21147;&#21644;&#24490;&#29615;&#21464;&#21270;&#65292;&#20197;&#35299;&#20915;&#26080;&#27861;&#25429;&#25417;&#24490;&#29615;&#21464;&#21270;&#30340;&#38382;&#39064;&#65292;&#23545;&#20110;&#29123;&#28903;&#25511;&#21046;&#35774;&#35745;&#38750;&#24120;&#37325;&#35201;</title><link>https://arxiv.org/abs/2403.03602</link><description>&lt;p&gt;
&#22522;&#20110;&#25968;&#25454;&#30340;&#20855;&#26377;&#24490;&#29615;&#21464;&#21270;&#30340;&#27668;&#32568;&#21387;&#21147;&#27169;&#22411;&#29992;&#20110;&#29123;&#28903;&#25511;&#21046;&#65306;RCCI&#21457;&#21160;&#26426;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Data-Based In-Cylinder Pressure Model with Cyclic Variations for Combustion Control: A RCCI Engine Application
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03602
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22522;&#20110;&#25968;&#25454;&#30340;&#26041;&#27861;&#27169;&#25311;&#20102;&#27668;&#32568;&#21387;&#21147;&#21644;&#24490;&#29615;&#21464;&#21270;&#65292;&#20197;&#35299;&#20915;&#26080;&#27861;&#25429;&#25417;&#24490;&#29615;&#21464;&#21270;&#30340;&#38382;&#39064;&#65292;&#23545;&#20110;&#29123;&#28903;&#25511;&#21046;&#35774;&#35745;&#38750;&#24120;&#37325;&#35201;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27668;&#32568;&#21387;&#21147;&#22522;&#30784;&#25511;&#21046;&#26159;&#20808;&#36827;&#30340;&#39044;&#28151;&#21512;&#29123;&#28903;&#27010;&#24565;&#30340;&#20851;&#38190;&#25512;&#21160;&#22240;&#32032;&#65292;&#38500;&#20102;&#30830;&#20445;&#31283;&#20581;&#19988;&#23433;&#20840;&#30340;&#25805;&#20316;&#22806;&#65292;&#36824;&#21487;&#20197;&#23454;&#29616;&#27668;&#32568;&#21387;&#21147;&#21644;&#28909;&#37322;&#25918;&#30340;&#22609;&#36896;&#12290;&#36825;&#38656;&#35201;&#24555;&#36895;&#30340;&#38754;&#21521;&#25511;&#21046;&#30340;&#29123;&#28903;&#27169;&#22411;&#12290;&#22810;&#24180;&#26469;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#24179;&#22343;&#20540;&#27169;&#22411;&#65292;&#21487;&#20197;&#39044;&#27979;&#29123;&#28903;&#25351;&#26631;&#65288;&#20363;&#22914;&#65292;&#24635;&#30340;&#25351;&#31034;&#24179;&#22343;&#26377;&#25928;&#21387;&#21147;&#65292;&#25110;&#37322;&#25918;&#24635;&#28909;&#37327;&#30340;&#26354;&#36724;&#26059;&#36716;&#35282;&#24230;&#65289;&#65292;&#25110;&#32773;&#39044;&#27979;&#23436;&#25972;&#30340;&#27668;&#32568;&#21387;&#21147;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#26080;&#27861;&#25429;&#25417;&#24490;&#29615;&#21464;&#21270;&#65292;&#36825;&#23545;&#20110;&#29123;&#28903;&#27010;&#24565;&#30340;&#25511;&#21046;&#35774;&#35745;&#33267;&#20851;&#37325;&#35201;&#65292;&#20363;&#22914;&#65292;&#21453;&#24212;&#24615;&#25511;&#21046;&#21387;&#32553;&#28857;&#28779;&#65292;&#36825;&#21487;&#33021;&#20250;&#36973;&#21463;&#22823;&#24133;&#24230;&#30340;&#24490;&#29615;&#21464;&#21270;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#20351;&#29992;&#22522;&#20110;&#25968;&#25454;&#30340;&#26041;&#27861;&#23545;&#27668;&#32568;&#21387;&#21147;&#21644;&#24490;&#29615;&#21464;&#21270;&#36827;&#34892;&#20102;&#24314;&#27169;&#12290;&#35813;&#27169;&#22411;&#32467;&#21512;&#20102;&#20027;&#25104;&#20998;&#20998;&#35299;&#21644;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#12290;&#36827;&#34892;&#20102;&#35814;&#32454;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03602v1 Announce Type: cross  Abstract: Cylinder pressure-based control is a key enabler for advanced pre-mixed combustion concepts. Besides guaranteeing robust and safe operation, it allows for cylinder pressure and heat release shaping. This requires fast control-oriented combustion models. Over the years, mean-value models have been proposed that can predict combustion measures (e.g., Gross Indicated Mean Effective Pressure, or the crank angle where 50% of the total heat is released) or models that predict the full in-cylinder pressure. However, these models are not able to capture cyclic variations. This is important in the control design for combustion concepts, like Reactivity Controlled Compression Ignition, that can suffer from large cyclic variations. In this study, the in-cylinder pressure and cyclic variation are modelled using a data-based approach. The model combines Principle Component Decomposition and Gaussian Process Regression. A detailed study is performed
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#26377;&#25928;&#22320;&#20272;&#35745;&#22788;&#29702;&#25928;&#24212;&#30340;&#27963;&#36291;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#21327;&#21464;&#37327;&#23494;&#24230;&#21644;&#20542;&#21521;&#24471;&#20998;&#26469;&#38477;&#20302;&#28176;&#36817;&#26041;&#24046;&#12290;</title><link>https://arxiv.org/abs/2403.03589</link><description>&lt;p&gt;
&#29992;&#20110;&#22788;&#29702;&#22240;&#21464;&#37327;&#36873;&#25321;&#30340;&#27963;&#36291;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;&#30340;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Active Adaptive Experimental Design for Treatment Effect Estimation with Covariate Choices
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03589
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#26377;&#25928;&#22320;&#20272;&#35745;&#22788;&#29702;&#25928;&#24212;&#30340;&#27963;&#36291;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#21327;&#21464;&#37327;&#23494;&#24230;&#21644;&#20542;&#21521;&#24471;&#20998;&#26469;&#38477;&#20302;&#28176;&#36817;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#35774;&#35745;&#20102;&#19968;&#20010;&#33258;&#36866;&#24212;&#23454;&#39564;&#65292;&#29992;&#20110;&#39640;&#25928;&#22320;&#20272;&#35745;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATEs&#65289;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#33258;&#36866;&#24212;&#23454;&#39564;&#65292;&#20854;&#20013;&#23454;&#39564;&#32773;&#25353;&#39034;&#24207;&#20174;&#30001;&#23454;&#39564;&#32773;&#20915;&#23450;&#30340;&#21327;&#21464;&#37327;&#23494;&#24230;&#20013;&#25277;&#26679;&#19968;&#20010;&#23454;&#39564;&#21333;&#20803;&#65292;&#24182;&#20998;&#37197;&#19968;&#31181;&#22788;&#29702;&#12290;&#22312;&#20998;&#37197;&#22788;&#29702;&#21518;&#65292;&#23454;&#39564;&#32773;&#31435;&#21363;&#35266;&#23519;&#30456;&#24212;&#30340;&#32467;&#26524;&#12290;&#22312;&#23454;&#39564;&#32467;&#26463;&#26102;&#65292;&#23454;&#39564;&#32773;&#21033;&#29992;&#25910;&#38598;&#30340;&#26679;&#26412;&#20272;&#31639;&#20986;&#19968;&#20010;ATE&#12290;&#23454;&#39564;&#32773;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#36739;&#23567;&#30340;&#28176;&#36817;&#26041;&#24046;&#20272;&#35745;ATE&#12290;&#29616;&#26377;&#30740;&#31350;&#24050;&#32463;&#35774;&#35745;&#20102;&#19968;&#20123;&#33021;&#22815;&#33258;&#36866;&#24212;&#20248;&#21270;&#20542;&#21521;&#24471;&#20998;&#65288;&#22788;&#29702;&#20998;&#37197;&#27010;&#29575;&#65289;&#30340;&#23454;&#39564;&#12290;&#20316;&#20026;&#36825;&#31181;&#26041;&#27861;&#30340;&#19968;&#20010;&#27010;&#25324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#19979;&#23454;&#39564;&#32773;&#20248;&#21270;&#21327;&#21464;&#37327;&#23494;&#24230;&#20197;&#21450;&#20542;&#21521;&#24471;&#20998;&#65292;&#24182;&#21457;&#29616;&#20248;&#21270;&#21327;&#21464;&#37327;&#23494;&#24230;&#21644;&#20542;&#21521;&#24471;&#20998;&#27604;&#20165;&#20248;&#21270;&#20542;&#21521;&#24471;&#20998;&#21487;&#20197;&#20943;&#23569;&#28176;&#36817;&#26041;&#24046;&#26356;&#22810;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03589v1 Announce Type: cross  Abstract: This study designs an adaptive experiment for efficiently estimating average treatment effect (ATEs). We consider an adaptive experiment where an experimenter sequentially samples an experimental unit from a covariate density decided by the experimenter and assigns a treatment. After assigning a treatment, the experimenter observes the corresponding outcome immediately. At the end of the experiment, the experimenter estimates an ATE using gathered samples. The objective of the experimenter is to estimate the ATE with a smaller asymptotic variance. Existing studies have designed experiments that adaptively optimize the propensity score (treatment-assignment probability). As a generalization of such an approach, we propose a framework under which an experimenter optimizes the covariate density, as well as the propensity score, and find that optimizing both covariate density and propensity score reduces the asymptotic variance more than o
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#32676;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#20004;&#32423;&#26377;&#38480;&#21644;&#20985;&#20984;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#32467;&#26500;&#21644;&#38543;&#26426;&#26041;&#24046;&#20943;&#23567;&#38236;&#20687;Prox&#31639;&#27861;&#65292;&#23454;&#29616;&#23545;&#25152;&#26377;&#32452;&#30340;&#26041;&#24046;&#20943;&#23569;&#65292;&#24182;&#25903;&#25345;&#38750;&#24658;&#23450;&#23398;&#20064;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.03562</link><description>&lt;p&gt;
&#39640;&#25928;&#31639;&#27861;&#29992;&#20110;&#32463;&#39564;&#32676;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#21450;&#26356;&#22810;
&lt;/p&gt;
&lt;p&gt;
Efficient Algorithms for Empirical Group Distributional Robust Optimization and Beyond
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03562
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#32676;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#20004;&#32423;&#26377;&#38480;&#21644;&#20985;&#20984;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#32467;&#26500;&#21644;&#38543;&#26426;&#26041;&#24046;&#20943;&#23567;&#38236;&#20687;Prox&#31639;&#27861;&#65292;&#23454;&#29616;&#23545;&#25152;&#26377;&#32452;&#30340;&#26041;&#24046;&#20943;&#23569;&#65292;&#24182;&#25903;&#25345;&#38750;&#24658;&#23450;&#23398;&#20064;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#32676;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;GDRO&#65289;&#30340;&#32463;&#39564;&#23545;&#24212;&#38382;&#39064;&#65292;&#26088;&#22312;&#26368;&#23567;&#21270;$m$&#20010;&#19981;&#21516;&#32452;&#20013;&#30340;&#26368;&#22823;&#32463;&#39564;&#39118;&#38505;&#12290;&#25105;&#20204;&#23558;&#32463;&#39564;GDRO&#34920;&#36848;&#20026;$\textit{&#20004;&#32423;}$&#26377;&#38480;&#21644;&#20985;&#20984;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#38543;&#26426;&#26041;&#24046;&#20943;&#23567;&#38236;&#20687;Prox&#31639;&#27861;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#36890;&#36807;&#36880;&#32452;&#25277;&#26679;&#25216;&#26415;&#26500;&#24314;&#20102;&#38543;&#26426;&#26799;&#24230;&#65292;&#24182;&#20026;&#25152;&#26377;&#32452;&#25191;&#34892;&#26041;&#24046;&#20943;&#23569;&#65292;&#20805;&#20998;&#21033;&#29992;&#20102;&#32463;&#39564;GDRO&#30340;$\textit{&#20004;&#32423;}$&#26377;&#38480;&#21644;&#32467;&#26500;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#19968;&#32034;&#24341;&#20559;&#31227;&#21152;&#26435;&#24179;&#22343;&#26469;&#35745;&#31639;&#24555;&#29031;&#21644;&#38236;&#20687;&#24555;&#29031;&#28857;&#65292;&#36825;&#20351;&#25105;&#20204;&#19982;&#26420;&#32032;&#30340;&#36941;&#21382;&#24179;&#22343;&#26041;&#27861;&#26377;&#25152;&#19981;&#21516;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#36824;&#25903;&#25345;&#38750;&#24658;&#23450;&#23398;&#20064;&#29575;&#65292;&#36825;&#19982;&#29616;&#26377;&#25991;&#29486;&#19981;&#21516;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#26399;&#26395;&#21644;&#39640;&#27010;&#29575;&#25910;&#25947;&#20445;&#35777;&#65292;&#23637;&#31034;&#20986;$\m
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03562v1 Announce Type: new  Abstract: We investigate the empirical counterpart of group distributionally robust optimization (GDRO), which aims to minimize the maximal empirical risk across $m$ distinct groups. We formulate empirical GDRO as a $\textit{two-level}$ finite-sum convex-concave minimax optimization problem and develop a stochastic variance reduced mirror prox algorithm. Unlike existing methods, we construct the stochastic gradient by per-group sampling technique and perform variance reduction for all groups, which fully exploits the $\textit{two-level}$ finite-sum structure of empirical GDRO. Furthermore, we compute the snapshot and mirror snapshot point by a one-index-shifted weighted average, which distinguishes us from the naive ergodic average. Our algorithm also supports non-constant learning rates, which is different from existing literature. We establish convergence guarantees both in expectation and with high probability, demonstrating a complexity of $\m
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#38598;&#21512;&#21345;&#23572;&#26364;&#21453;&#28436;&#26041;&#27861;&#38024;&#23545;DeepONets&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#25512;&#26029;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.03444</link><description>&lt;p&gt;
&#20351;&#29992;&#38598;&#21512;&#21345;&#23572;&#26364;&#21453;&#28436;&#36827;&#34892;DeepONets&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Uncertainty quantification for deeponets with ensemble kalman inversion
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03444
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#38598;&#21512;&#21345;&#23572;&#26364;&#21453;&#28436;&#26041;&#27861;&#38024;&#23545;DeepONets&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#25512;&#26029;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#25805;&#20316;&#21592;&#23398;&#20064;&#65292;&#29305;&#21035;&#26159;DeepONet&#65292;&#22240;&#20854;&#39640;&#25928;&#22320;&#23398;&#20064;&#36328;&#19981;&#21516;&#39046;&#22495;&#30340;&#36755;&#20837;&#21644;&#36755;&#20986;&#20989;&#25968;&#20043;&#38388;&#30340;&#22797;&#26434;&#26144;&#23556;&#32780;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#12290;&#22312;&#26377;&#38480;&#19988;&#24102;&#22122;&#22768;&#25968;&#25454;&#30340;&#23454;&#38469;&#22330;&#26223;&#20013;&#65292;&#35775;&#38382;DeepONet&#39044;&#27979;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#65292;&#29305;&#21035;&#26159;&#22312;&#20351;&#21629;&#20851;&#38190;&#25110;&#23433;&#20840;&#20851;&#38190;&#24212;&#29992;&#20013;&#12290;&#29616;&#26377;&#26041;&#27861;&#35201;&#20040;&#35745;&#31639;&#23494;&#38598;&#65292;&#35201;&#20040;&#20135;&#29983;&#20196;&#20154;&#19981;&#28385;&#24847;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#20026;DeepONets&#37327;&#36523;&#23450;&#21046;&#39640;&#25928;&#19988;&#20449;&#24687;&#20016;&#23500;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65288;UQ&#65289;&#25216;&#26415;&#30041;&#19979;&#20102;&#31354;&#38388;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#38598;&#21512;&#21345;&#23572;&#26364;&#21453;&#28436;&#65288;EKI&#65289;&#26041;&#27861;&#30340;&#26032;&#22411;&#25512;&#26029;&#26041;&#27861;&#65292;&#29992;&#20110;&#25805;&#20316;&#21592;&#23398;&#20064;&#30340;&#39640;&#25928;UQ&#12290;EKI&#20197;&#20854;&#26080;&#23548;&#25968;&#12289;&#22122;&#22768;&#25239;&#24178;&#25200;&#21644;&#39640;&#24230;&#21487;&#24182;&#34892;&#21270;&#30340;&#29305;&#24615;&#32780;&#38395;&#21517;&#65292;&#24050;&#32463;&#35777;&#26126;&#20102;&#22312;&#38754;&#21521;&#29289;&#29702;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;UQ&#20013;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03444v1 Announce Type: cross  Abstract: In recent years, operator learning, particularly the DeepONet, has received much attention for efficiently learning complex mappings between input and output functions across diverse fields. However, in practical scenarios with limited and noisy data, accessing the uncertainty in DeepONet predictions becomes essential, especially in mission-critical or safety-critical applications. Existing methods, either computationally intensive or yielding unsatisfactory uncertainty quantification, leave room for developing efficient and informative uncertainty quantification (UQ) techniques tailored for DeepONets. In this work, we proposed a novel inference approach for efficient UQ for operator learning by harnessing the power of the Ensemble Kalman Inversion (EKI) approach. EKI, known for its derivative-free, noise-robust, and highly parallelizable feature, has demonstrated its advantages for UQ for physics-informed neural networks [28]. Our inn
&lt;/p&gt;</description></item><item><title>CoRMF&#26159;&#19968;&#31181;&#22522;&#20110;RNN&#30340;&#39640;&#25928;&#20234;&#36763;&#27169;&#22411;&#27714;&#35299;&#22120;&#65292;&#21033;&#29992;&#20851;&#38190;&#26377;&#24207;&#33258;&#26059;&#24207;&#21015;&#21644;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#26469;&#23454;&#29616;&#21464;&#20998;&#22343;&#22330;&#21644; RNN &#20043;&#38388;&#30340;&#32479;&#19968;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23545;&#36890;&#24120;&#38590;&#20197;&#22788;&#29702;&#30340;&#20234;&#36763;&#27169;&#22411;&#30340;&#39640;&#25928;&#25506;&#32034;&#12290;</title><link>https://arxiv.org/abs/2403.03391</link><description>&lt;p&gt;
CoRMF: &#20020;&#30028;&#26377;&#24207;&#24490;&#29615;&#22343;&#22330;&#20234;&#36763;&#27714;&#35299;&#22120;
&lt;/p&gt;
&lt;p&gt;
CoRMF: Criticality-Ordered Recurrent Mean Field Ising Solver
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03391
&lt;/p&gt;
&lt;p&gt;
CoRMF&#26159;&#19968;&#31181;&#22522;&#20110;RNN&#30340;&#39640;&#25928;&#20234;&#36763;&#27169;&#22411;&#27714;&#35299;&#22120;&#65292;&#21033;&#29992;&#20851;&#38190;&#26377;&#24207;&#33258;&#26059;&#24207;&#21015;&#21644;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#26469;&#23454;&#29616;&#21464;&#20998;&#22343;&#22330;&#21644; RNN &#20043;&#38388;&#30340;&#32479;&#19968;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23545;&#36890;&#24120;&#38590;&#20197;&#22788;&#29702;&#30340;&#20234;&#36763;&#27169;&#22411;&#30340;&#39640;&#25928;&#25506;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;RNN&#30340;&#39640;&#25928;&#20234;&#36763;&#27169;&#22411;&#27714;&#35299;&#22120;&#65292;&#31216;&#20026;Criticality-ordered Recurrent Mean Field (CoRMF)&#65292;&#29992;&#20110;&#21069;&#21521;&#20234;&#36763;&#38382;&#39064;&#12290;&#22312;&#20854;&#26680;&#24515;&#37096;&#20998;&#65292;&#36890;&#36807;&#36138;&#23146;&#31639;&#27861;&#23545;N&#20010;&#33258;&#26059;&#30340;&#20234;&#36763;&#27169;&#22411;&#36827;&#34892;&#20102;&#20851;&#38190;&#26377;&#24207;&#33258;&#26059;&#24207;&#21015;&#30340;&#24341;&#20837;&#65292;&#20174;&#32780;&#21487;&#20197;&#21033;&#29992;&#33258;&#22238;&#24402;&#22343;&#22330;&#22240;&#23376;&#20998;&#35299;&#65292;&#24182;&#36890;&#36807;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;(RNNs)&#36827;&#34892;&#20248;&#21270;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#20004;&#20010;&#26174;&#33879;&#29305;&#28857;&#65306;(i)&#36890;&#36807;&#21033;&#29992;&#24213;&#23618;&#20234;&#36763;&#22270;&#30340;&#36817;&#20284;&#26641;&#32467;&#26500;&#65292;&#26032;&#33719;&#24471;&#30340;&#20851;&#38190;&#24615;&#39034;&#24207;&#20351;&#21464;&#20998;&#22343;&#22330;&#21644;RNN&#20043;&#38388;&#24471;&#20197;&#32479;&#19968;&#65292;&#20174;&#32780;&#20801;&#35768;&#26377;&#25928;&#22320;&#21033;&#29992;&#27010;&#29575;&#25512;&#26029;&#26469;&#25506;&#31350;&#36890;&#24120;&#38590;&#20197;&#22788;&#29702;&#30340;&#20234;&#36763;&#27169;&#22411;;(ii)&#23427;&#20855;&#26377;&#33391;&#22909;&#30340;&#27169;&#22359;&#21270;&#12289;&#29420;&#31435;&#20110;&#27169;&#22411;&#32780;&#21448;&#36275;&#22815;&#34920;&#36798;&#33021;&#21147;&#65292;&#22240;&#27492;&#21487;&#20197;&#23436;&#20840;&#36866;&#29992;&#20110;&#20219;&#20309;&#21069;&#21521;&#20234;&#36763;&#25512;&#29702;&#38382;&#39064;&#65292;&#32780;&#19988;&#24037;&#20316;&#37327;&#26497;&#23567;&#12290;&#35745;&#31639;&#19978;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26041;&#24046;&#20943;&#23569;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03391v1 Announce Type: cross  Abstract: We propose an RNN-based efficient Ising model solver, the Criticality-ordered Recurrent Mean Field (CoRMF), for forward Ising problems. In its core, a criticality-ordered spin sequence of an $N$-spin Ising model is introduced by sorting mission-critical edges with greedy algorithm, such that an autoregressive mean-field factorization can be utilized and optimized with Recurrent Neural Networks (RNNs). Our method has two notable characteristics: (i) by leveraging the approximated tree structure of the underlying Ising graph, the newly-obtained criticality order enables the unification between variational mean-field and RNN, allowing the generally intractable Ising model to be efficiently probed with probabilistic inference; (ii) it is well-modulized, model-independent while at the same time expressive enough, and hence fully applicable to any forward Ising inference problems with minimal effort. Computationally, by using a variance-redu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#36172;&#21338;&#38382;&#39064;&#20013;Thompson-Sampling&#31639;&#27861;&#21464;&#20307;&#30340;&#36125;&#21494;&#26031;&#36951;&#25022;&#65292;&#36890;&#36807;&#20351;&#29992;&#38142;&#25509;&#35770;&#35777;&#24314;&#31435;&#20102;&#20855;&#26377;&#24230;&#37327;&#21160;&#20316;&#31354;&#38388;&#30340;&#26032;&#30028;&#38480;&#65292;&#20026;$d$&#32500;&#32447;&#24615;&#36172;&#21338;&#38382;&#39064;&#25552;&#20379;&#20102;$O(d\sqrt{T})$&#30340;&#20005;&#26684;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.03361</link><description>&lt;p&gt;
&#38142;&#24335;&#20449;&#24687;&#35770;&#30028;&#38480;&#21644;&#32447;&#24615;&#36172;&#21338;&#38382;&#39064;&#30340;&#20005;&#26684;&#36951;&#25022;&#29575;
&lt;/p&gt;
&lt;p&gt;
Chained Information-Theoretic bounds and Tight Regret Rate for Linear Bandit Problems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03361
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#36172;&#21338;&#38382;&#39064;&#20013;Thompson-Sampling&#31639;&#27861;&#21464;&#20307;&#30340;&#36125;&#21494;&#26031;&#36951;&#25022;&#65292;&#36890;&#36807;&#20351;&#29992;&#38142;&#25509;&#35770;&#35777;&#24314;&#31435;&#20102;&#20855;&#26377;&#24230;&#37327;&#21160;&#20316;&#31354;&#38388;&#30340;&#26032;&#30028;&#38480;&#65292;&#20026;$d$&#32500;&#32447;&#24615;&#36172;&#21338;&#38382;&#39064;&#25552;&#20379;&#20102;$O(d\sqrt{T})$&#30340;&#20005;&#26684;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;Thompson-Sampling&#31639;&#27861;&#21464;&#20307;&#22312;&#36172;&#21338;&#38382;&#39064;&#20013;&#30340;&#36125;&#21494;&#26031;&#36951;&#25022;&#12290;&#23427;&#22522;&#20110;[Russo and Van Roy&#65292;2015]&#30340;&#20449;&#24687;&#35770;&#26694;&#26550;&#65292;&#26356;&#20855;&#20307;&#22320;&#65292;&#22522;&#20110;[Dong and Van Roy&#65292;2020]&#30340;&#29575;-&#22833;&#30495;&#20998;&#26512;&#65292;&#22312;&#37027;&#37324;&#20182;&#20204;&#35777;&#26126;&#20102;$d$&#32500;&#32447;&#24615;&#36172;&#21338;&#35774;&#32622;&#30340;&#36951;&#25022;&#29575;&#20026;$O(d\sqrt{T \log(T)})$&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#20855;&#26377;&#24230;&#37327;&#21160;&#20316;&#31354;&#38388;&#30340;&#36172;&#21338;&#38382;&#39064;&#65292;&#24182;&#20351;&#29992;&#38142;&#25509;&#35770;&#35777;&#24314;&#31435;&#20102;&#20381;&#36182;&#20110;&#21160;&#20316;&#31354;&#38388;&#24230;&#37327;&#29109;&#30340;&#26032;&#30028;&#38480;&#65292;&#38024;&#23545;Thompson-Sampling&#30340;&#19968;&#20010;&#21464;&#20307;&#12290;&#22312;&#22870;&#21169;&#30340;&#36866;&#24403;&#36830;&#32493;&#24615;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#20026;$d$&#32500;&#32447;&#24615;&#36172;&#21338;&#38382;&#39064;&#25552;&#20379;&#20102;$O(d\sqrt{T})$&#30340;&#20005;&#26684;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03361v1 Announce Type: cross  Abstract: This paper studies the Bayesian regret of a variant of the Thompson-Sampling algorithm for bandit problems. It builds upon the information-theoretic framework of [Russo and Van Roy, 2015] and, more specifically, on the rate-distortion analysis from [Dong and Van Roy, 2020], where they proved a bound with regret rate of $O(d\sqrt{T \log(T)})$ for the $d$-dimensional linear bandit setting. We focus on bandit problems with a metric action space and, using a chaining argument, we establish new bounds that depend on the metric entropy of the action space for a variant of Thompson-Sampling.   Under suitable continuity assumption of the rewards, our bound offers a tight rate of $O(d\sqrt{T})$ for $d$-dimensional linear bandit problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24212;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#23398;&#20064;&#20551;&#35774;&#31354;&#38388;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#20877;&#29983;&#26680;Banach&#31354;&#38388;&#65292;&#30740;&#31350;&#20102;&#27491;&#21017;&#21270;&#23398;&#20064;&#21644;&#26368;&#23567;&#25554;&#20540;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#23398;&#20064;&#27169;&#22411;&#30340;&#35299;&#21487;&#20197;&#34920;&#31034;&#20026;&#32447;&#24615;&#32452;&#21512;&#12290;</title><link>https://arxiv.org/abs/2403.03353</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#20551;&#35774;&#31354;&#38388;
&lt;/p&gt;
&lt;p&gt;
Hypothesis Spaces for Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03353
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24212;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#23398;&#20064;&#20551;&#35774;&#31354;&#38388;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#20877;&#29983;&#26680;Banach&#31354;&#38388;&#65292;&#30740;&#31350;&#20102;&#27491;&#21017;&#21270;&#23398;&#20064;&#21644;&#26368;&#23567;&#25554;&#20540;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#23398;&#20064;&#27169;&#22411;&#30340;&#35299;&#21487;&#20197;&#34920;&#31034;&#20026;&#32447;&#24615;&#32452;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24212;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#30340;&#28145;&#24230;&#23398;&#20064;&#20551;&#35774;&#31354;&#38388;&#12290;&#36890;&#36807;&#23558;DNN&#35270;&#20026;&#20004;&#20010;&#21464;&#37327;&#30340;&#20989;&#25968;&#65292;&#21363;&#29289;&#29702;&#21464;&#37327;&#21644;&#21442;&#25968;&#21464;&#37327;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;DNNs&#30340;&#21407;&#22987;&#38598;&#21512;&#65292;&#21442;&#25968;&#21464;&#37327;&#20301;&#20110;&#30001;DNNs&#30340;&#26435;&#37325;&#30697;&#38453;&#21644;&#20559;&#32622;&#20915;&#23450;&#30340;&#19968;&#32452;&#28145;&#24230;&#21644;&#23485;&#24230;&#20013;&#12290;&#28982;&#21518;&#22312;&#24369;*&#25299;&#25169;&#20013;&#23436;&#25104;&#21407;&#22987;DNN&#38598;&#21512;&#30340;&#32447;&#24615;&#36328;&#24230;&#65292;&#20197;&#26500;&#24314;&#19968;&#20010;&#29289;&#29702;&#21464;&#37327;&#20989;&#25968;&#30340;Banach&#31354;&#38388;&#12290;&#25105;&#20204;&#35777;&#26126;&#25152;&#26500;&#36896;&#30340;Banach&#31354;&#38388;&#26159;&#19968;&#20010;&#20877;&#29983;&#26680;Banach&#31354;&#38388;&#65288;RKBS&#65289;&#65292;&#24182;&#26500;&#36896;&#20854;&#20877;&#29983;&#26680;&#12290;&#36890;&#36807;&#20026;&#23398;&#20064;&#27169;&#22411;&#30340;&#35299;&#24314;&#31435;&#34920;&#36798;&#23450;&#29702;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#20010;&#23398;&#20064;&#27169;&#22411;&#65292;&#27491;&#21017;&#21270;&#23398;&#20064;&#21644;&#26368;&#23567;&#25554;&#20540;&#38382;&#39064;&#22312;&#32467;&#26524;RKBS&#20013;&#12290;&#34920;&#36798;&#23450;&#29702;&#25581;&#31034;&#20102;&#36825;&#20123;&#23398;&#20064;&#27169;&#22411;&#30340;&#35299;&#21487;&#20197;&#34920;&#31034;&#20026;&#32447;&#24615;&#32452;&#21512;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03353v1 Announce Type: cross  Abstract: This paper introduces a hypothesis space for deep learning that employs deep neural networks (DNNs). By treating a DNN as a function of two variables, the physical variable and parameter variable, we consider the primitive set of the DNNs for the parameter variable located in a set of the weight matrices and biases determined by a prescribed depth and widths of the DNNs. We then complete the linear span of the primitive DNN set in a weak* topology to construct a Banach space of functions of the physical variable. We prove that the Banach space so constructed is a reproducing kernel Banach space (RKBS) and construct its reproducing kernel. We investigate two learning models, regularized learning and minimum interpolation problem in the resulting RKBS, by establishing representer theorems for solutions of the learning models. The representer theorems unfold that solutions of these learning models can be expressed as linear combination of
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#19977;&#37325;/&#21435;&#20559;Lasso&#26041;&#27861;&#65292;&#29992;&#20110;&#32479;&#35745;&#25512;&#26029;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65292;&#19981;&#35201;&#27714;&#30452;&#25509;&#20551;&#35774;&#31232;&#30095;&#24615;&#65292;&#26377;&#25928;&#20272;&#35745;&#20102;&#32447;&#24615;&#27169;&#22411;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;</title><link>https://arxiv.org/abs/2403.03240</link><description>&lt;p&gt;
&#29992;&#20110;&#32479;&#35745;&#25512;&#26029;&#30340;&#19977;&#37325;/&#21435;&#20559;Lasso&#65306;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;
Triple/Debiased Lasso for Statistical Inference of Conditional Average Treatment Effects
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03240
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#19977;&#37325;/&#21435;&#20559;Lasso&#26041;&#27861;&#65292;&#29992;&#20110;&#32479;&#35745;&#25512;&#26029;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65292;&#19981;&#35201;&#27714;&#30452;&#25509;&#20551;&#35774;&#31232;&#30095;&#24615;&#65292;&#26377;&#25928;&#20272;&#35745;&#20102;&#32447;&#24615;&#27169;&#22411;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#20851;&#20110;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;CATEs&#65289;&#30340;&#20272;&#35745;&#21644;&#32479;&#35745;&#25512;&#26029;&#65292;CATEs&#20316;&#20026;&#34920;&#31034;&#20010;&#24615;&#21270;&#22240;&#26524;&#25928;&#24212;&#30340;&#19968;&#20010;&#25351;&#26631;&#24050;&#32463;&#24341;&#36215;&#20102;&#20851;&#27880;&#12290;&#22312;&#25105;&#20204;&#30340;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#20551;&#35774;&#19982;&#20108;&#20540;&#22788;&#29702;&#30456;&#20851;&#32852;&#30340;&#32467;&#26524;&#37319;&#29992;&#32447;&#24615;&#27169;&#22411;&#65292;&#24182;&#23558;CATE&#23450;&#20041;&#20026;&#36825;&#20123;&#32447;&#24615;&#27169;&#22411;&#30340;&#39044;&#26399;&#32467;&#26524;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#26412;&#30740;&#31350;&#20801;&#35768;&#32447;&#24615;&#27169;&#22411;&#26159;&#39640;&#32500;&#30340;&#65292;&#25105;&#20204;&#30340;&#20852;&#36259;&#22312;&#20110;&#23545;CATE&#36827;&#34892;&#19968;&#33268;&#20272;&#35745;&#21644;&#32479;&#35745;&#25512;&#26029;&#12290;&#22312;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#65292;&#19968;&#31181;&#20856;&#22411;&#30340;&#26041;&#27861;&#26159;&#20551;&#35774;&#31232;&#30095;&#24615;&#12290;&#20294;&#26159;&#65292;&#22312;&#25105;&#20204;&#30340;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#19981;&#30452;&#25509;&#20551;&#35774;&#31232;&#30095;&#24615;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#20165;&#22312;&#32447;&#24615;&#27169;&#22411;&#30340;&#24046;&#24322;&#20013;&#32771;&#34385;&#31232;&#30095;&#24615;&#12290;&#25105;&#20204;&#39318;&#20808;&#20351;&#29992;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;&#26469;&#36817;&#20284;&#36825;&#31181;&#24046;&#24322;&#65292;&#28982;&#21518;&#29992;Lasso&#27491;&#21017;&#21270;&#23558;&#24046;&#24322;&#22238;&#24402;&#21040;&#21327;&#21464;&#37327;&#19978;&#12290;&#23613;&#31649;&#36825;&#31181;&#22238;&#24402;&#20272;&#35745;&#37327;&#26159;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03240v1 Announce Type: cross  Abstract: This study investigates the estimation and the statistical inference about Conditional Average Treatment Effects (CATEs), which have garnered attention as a metric representing individualized causal effects. In our data-generating process, we assume linear models for the outcomes associated with binary treatments and define the CATE as a difference between the expected outcomes of these linear models. This study allows the linear models to be high-dimensional, and our interest lies in consistent estimation and statistical inference for the CATE. In high-dimensional linear regression, one typical approach is to assume sparsity. However, in our study, we do not assume sparsity directly. Instead, we consider sparsity only in the difference of the linear models. We first use a doubly robust estimator to approximate this difference and then regress the difference on covariates with Lasso regularization. Although this regression estimator is
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#20197;&#37327;&#21270;&#35745;&#31639;&#27169;&#22411;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#30340;&#20004;&#31181;&#26469;&#28304;&#65292;&#36890;&#36807;&#32467;&#21512;&#25968;&#25454;&#19968;&#33268;&#24615;&#21644;&#23398;&#20064;&#19981;&#30830;&#23450;&#37327;&#26694;&#26550;&#65292;&#21487;&#20197;&#26377;&#25928;&#22788;&#29702;&#27979;&#37327;&#35823;&#24046;&#21644;&#20852;&#36259;&#25968;&#37327;&#26144;&#23556;&#38382;&#39064;</title><link>https://arxiv.org/abs/2403.03233</link><description>&lt;p&gt;
&#20174;&#20301;&#31227;&#21040;&#20998;&#24067;&#65306;&#19968;&#31181;&#29992;&#20110;&#37327;&#21270;&#35745;&#31639;&#27169;&#22411;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#30340;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
From Displacements to Distributions: A Machine-Learning Enabled Framework for Quantifying Uncertainties in Parameters of Computational Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03233
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#20197;&#37327;&#21270;&#35745;&#31639;&#27169;&#22411;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#30340;&#20004;&#31181;&#26469;&#28304;&#65292;&#36890;&#36807;&#32467;&#21512;&#25968;&#25454;&#19968;&#33268;&#24615;&#21644;&#23398;&#20064;&#19981;&#30830;&#23450;&#37327;&#26694;&#26550;&#65292;&#21487;&#20197;&#26377;&#25928;&#22788;&#29702;&#27979;&#37327;&#35823;&#24046;&#21644;&#20852;&#36259;&#25968;&#37327;&#26144;&#23556;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#32467;&#21512;&#20004;&#31181;&#26694;&#26550;&#30340;&#26032;&#25193;&#23637;&#65292;&#29992;&#20110;&#37327;&#21270;&#24037;&#31243;&#31995;&#32479;&#24314;&#27169;&#20013;&#30340;&#28151;&#21512;&#19981;&#30830;&#23450;&#24615;&#28304;&#65292;&#21363;aleatoric&#65288;&#21363;&#19981;&#21487;&#20943;&#23569;&#30340;&#65289;&#21644;epistemic&#65288;&#21363;&#21487;&#20943;&#23569;&#30340;&#65289;&#12290;&#25968;&#25454;&#19968;&#33268;&#24615;&#65288;DC&#65289;&#26694;&#26550;&#25552;&#20986;&#20102;&#19968;&#20010;&#36870;&#38382;&#39064;&#21644;&#35299;&#20915;&#26041;&#26696;&#65292;&#20197;&#37327;&#21270;&#20197;&#32473;&#23450;&#37327;&#21270;&#20852;&#36259;&#22270;&#23450;&#30340;&#22238;&#25289;&#21644;&#25512;&#36827;&#27979;&#24230;&#30340;aleatoric&#19981;&#30830;&#23450;&#24615;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#39044;&#20808;&#25351;&#23450;&#30340;&#20852;&#36259;&#25968;&#37327;&#26144;&#23556;&#24182;&#19981;&#24635;&#26159;&#22312;&#19982;&#31995;&#32479;&#36755;&#20986;&#30456;&#20851;&#30340;&#25968;&#25454;&#25910;&#38598;&#20043;&#21069;&#26159;&#21487;&#29992;&#30340;&#12290;&#25968;&#25454;&#26412;&#36523;&#32463;&#24120;&#21463;&#21040;&#27979;&#37327;&#35823;&#24046;&#65288;&#21363;epistemic&#19981;&#30830;&#23450;&#24615;&#65289;&#30340;&#27745;&#26579;&#65292;&#36825;&#20351;&#24471;&#25351;&#23450;&#19968;&#20010;&#26377;&#29992;&#30340;&#20852;&#36259;&#25968;&#37327;&#26144;&#23556;&#30340;&#36807;&#31243;&#21464;&#24471;&#22797;&#26434;&#12290;&#23398;&#20064;&#19981;&#30830;&#23450;&#37327;&#65288;LUQ&#65289;&#26694;&#26550;&#23450;&#20041;&#20102;&#19968;&#20010;&#27491;&#24335;&#30340;&#19977;&#27493;&#26426;&#22120;&#23398;&#20064;&#21551;&#29992;&#36807;&#31243;&#65292;&#29992;&#20110;&#23558;&#22024;&#26434;&#25968;&#25454;&#38598;&#36716;&#21270;&#20026;&#23398;&#20064;&#21040;&#30340;&#20852;&#36259;&#30340;&#26144;&#23556;&#26679;&#26412;&#65292;&#20197;&#21551;&#29992;&#22522;&#20110;DC&#30340;&#21453;&#28436;&#12290;&#25105;&#20204;&#22312;LUQ&#20013;&#24320;&#21457;&#20102;&#19968;&#20010;&#24378;&#22823;&#30340;&#36807;&#28388;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03233v1 Announce Type: cross  Abstract: This work presents novel extensions for combining two frameworks for quantifying both aleatoric (i.e., irreducible) and epistemic (i.e., reducible) sources of uncertainties in the modeling of engineered systems. The data-consistent (DC) framework poses an inverse problem and solution for quantifying aleatoric uncertainties in terms of pullback and push-forward measures for a given Quantity of Interest (QoI) map. Unfortunately, a pre-specified QoI map is not always available a priori to the collection of data associated with system outputs. The data themselves are often polluted with measurement errors (i.e., epistemic uncertainties), which complicates the process of specifying a useful QoI. The Learning Uncertain Quantities (LUQ) framework defines a formal three-step machine-learning enabled process for transforming noisy datasets into samples of a learned QoI map to enable DC-based inversion. We develop a robust filtering step in LUQ 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30740;&#31350;&#21457;&#29616;&#65292;&#24403;&#20195;&#29702;&#22312;&#22810;&#26679;&#21270;&#20219;&#21153;&#19978;&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;&#20855;&#26377;&#30701;&#35270;&#25506;&#32034;&#35774;&#35745;&#30340;&#36890;&#29992;&#31574;&#30053;&#20849;&#20139;&#31639;&#27861;&#21487;&#20197;&#22312;&#22810;&#20219;&#21153;&#24378;&#21270;&#23398;&#20064;&#20013;&#26174;&#33879;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.01636</link><description>&lt;p&gt;
&#36890;&#36807;&#22810;&#20219;&#21153;&#24378;&#21270;&#23398;&#20064;&#23454;&#29616;&#39640;&#25928;&#30340;&#30701;&#35270;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Sample Efficient Myopic Exploration Through Multitask Reinforcement Learning with Diverse Tasks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01636
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30740;&#31350;&#21457;&#29616;&#65292;&#24403;&#20195;&#29702;&#22312;&#22810;&#26679;&#21270;&#20219;&#21153;&#19978;&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;&#20855;&#26377;&#30701;&#35270;&#25506;&#32034;&#35774;&#35745;&#30340;&#36890;&#29992;&#31574;&#30053;&#20849;&#20139;&#31639;&#27861;&#21487;&#20197;&#22312;&#22810;&#20219;&#21153;&#24378;&#21270;&#23398;&#20064;&#20013;&#26174;&#33879;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20219;&#21153;&#24378;&#21270;&#23398;&#20064;&#65288;MTRL&#65289;&#26041;&#27861;&#22312;&#35768;&#22810;&#37325;&#35201;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20219;&#21153;&#20013;&#24212;&#29992;&#24191;&#27867;&#65292;&#20294;&#36817;&#26399;MTRL&#29702;&#35770;&#30340;&#36827;&#23637;&#20027;&#35201;&#38598;&#20013;&#22312;&#36890;&#36807;&#20551;&#35774;&#20219;&#21153;&#38388;&#20849;&#20139;&#32467;&#26500;&#26469;&#25552;&#39640;&#32479;&#35745;&#25928;&#29575;&#65292;&#23545;&#20110;RL&#20013;&#33267;&#20851;&#37325;&#35201;&#30340;&#25506;&#32034;&#36825;&#19968;&#20851;&#38190;&#26041;&#38754;&#21364;&#22823;&#22810;&#34987;&#24573;&#35270;&#12290;&#26412;&#25991;&#36890;&#36807;&#23637;&#31034;&#65292;&#24403;&#20195;&#29702;&#22312;&#36275;&#22815;&#22810;&#26679;&#21270;&#30340;&#20219;&#21153;&#38598;&#19978;&#35757;&#32451;&#26102;&#65292;&#20855;&#26377;&#30701;&#35270;&#25506;&#32034;&#35774;&#35745;&#65288;&#22914;$\epsilon$-&#36138;&#24515;&#65289;&#30340;&#36890;&#29992;&#31574;&#30053;&#20849;&#20139;&#31639;&#27861;&#21487;&#20197;&#22312;MTRL&#20013;&#20855;&#26377;&#39640;&#26679;&#26412;&#25928;&#29575;&#65292;&#20174;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#23545;&#8220;&#25506;&#32034;&#25910;&#30410;&#8221;&#22312;MTRL&#20013;&#30340;&#39318;&#27425;&#29702;&#35770;&#35777;&#26126;&#65292;&#20063;&#26377;&#21161;&#20110;&#35299;&#37322;&#30701;&#35270;&#25506;&#32034;&#22312;&#23454;&#36341;&#20013;&#24212;&#29992;&#24191;&#27867;&#30340;&#25104;&#21151;&#12290;&#20026;&#20102;&#39564;&#35777;&#22810;&#26679;&#24615;&#30340;&#20316;&#29992;&#65292;&#25105;&#20204;&#22312;&#21512;&#25104;&#26426;&#22120;&#20154;&#25511;&#21046;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01636v1 Announce Type: cross  Abstract: Multitask Reinforcement Learning (MTRL) approaches have gained increasing attention for its wide applications in many important Reinforcement Learning (RL) tasks. However, while recent advancements in MTRL theory have focused on the improved statistical efficiency by assuming a shared structure across tasks, exploration--a crucial aspect of RL--has been largely overlooked. This paper addresses this gap by showing that when an agent is trained on a sufficiently diverse set of tasks, a generic policy-sharing algorithm with myopic exploration design like $\epsilon$-greedy that are inefficient in general can be sample-efficient for MTRL. To the best of our knowledge, this is the first theoretical demonstration of the "exploration benefits" of MTRL. It may also shed light on the enigmatic success of the wide applications of myopic exploration in practice. To validate the role of diversity, we conduct experiments on synthetic robotic control
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#26041;&#21521;&#20559;&#22909;&#23545;&#40784;&#65288;DPA&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#22810;&#30446;&#26631;&#22870;&#21169;&#27169;&#25311;&#19981;&#21516;&#20559;&#22909;&#37197;&#32622;&#65292;&#20197;&#23454;&#29616;&#29992;&#25143;&#30456;&#20851;&#30340;&#20559;&#22909;&#25511;&#21046;&#12290;</title><link>https://arxiv.org/abs/2402.18571</link><description>&lt;p&gt;
&#29992;&#20110;&#28385;&#36275;&#22810;&#26679;&#29992;&#25143;&#20559;&#22909;&#30340;&#31639;&#26415;&#25511;&#21046;LLMs&#65306;&#20855;&#26377;&#22810;&#30446;&#26631;&#22870;&#21169;&#30340;&#26041;&#21521;&#20559;&#22909;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Arithmetic Control of LLMs for Diverse User Preferences: Directional Preference Alignment with Multi-Objective Rewards
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18571
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#26041;&#21521;&#20559;&#22909;&#23545;&#40784;&#65288;DPA&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#22810;&#30446;&#26631;&#22870;&#21169;&#27169;&#25311;&#19981;&#21516;&#20559;&#22909;&#37197;&#32622;&#65292;&#20197;&#23454;&#29616;&#29992;&#25143;&#30456;&#20851;&#30340;&#20559;&#22909;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#31934;&#32454;&#25511;&#21046;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#35201;&#25361;&#25112;&#65292;&#38459;&#30861;&#20102;&#23427;&#20204;&#36866;&#24212;&#21508;&#31181;&#29992;&#25143;&#38656;&#27714;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#26041;&#21521;&#20559;&#22909;&#23545;&#40784;&#65288;DPA&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#22810;&#30446;&#26631;&#22870;&#21169;&#24314;&#27169;&#26469;&#34920;&#31034;&#22810;&#26679;&#21270;&#30340;&#20559;&#22909;&#37197;&#32622;&#65292;&#23558;&#29992;&#25143;&#20559;&#22909;&#24314;&#27169;&#20026;&#22870;&#21169;&#31354;&#38388;&#20013;&#30340;&#26041;&#21521;&#65288;&#21363;&#21333;&#20301;&#21521;&#37327;&#65289;&#20197;&#23454;&#29616;&#29992;&#25143;&#30456;&#20851;&#30340;&#20559;&#22909;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18571v1 Announce Type: cross  Abstract: Fine-grained control over large language models (LLMs) remains a significant challenge, hindering their adaptability to diverse user needs. While Reinforcement Learning from Human Feedback (RLHF) shows promise in aligning LLMs, its reliance on scalar rewards often limits its ability to capture diverse user preferences in real-world applications. To address this limitation, we introduce the Directional Preference Alignment (DPA) framework. Unlike the scalar-reward RLHF, DPA incorporates multi-objective reward modeling to represent diverse preference profiles. Additionally, DPA models user preferences as directions (i.e., unit vectors) in the reward space to achieve user-dependent preference control. Our method involves training a multi-objective reward model and then fine-tuning the LLM with a preference-conditioned variant of Rejection Sampling Finetuning (RSF), an RLHF method adopted by Llama 2. This method enjoys a better performance
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20248;&#21270;&#26694;&#26550;&#65292;&#21487;&#22312;&#31232;&#30095;&#31283;&#20581;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#19968;&#32500;&#23376;&#31354;&#38388;&#65292;&#36890;&#36807;&#24341;&#20837;&#32447;&#24615;&#26494;&#24347;&#26041;&#27861;&#21644;&#26032;&#39062;&#30340;&#25311;&#21512;&#31243;&#24207;&#65292;&#23454;&#29616;&#20102;&#20840;&#23616;&#26368;&#20248;&#30340;&#31283;&#20581;&#31232;&#30095;&#23376;&#31354;&#38388;&#65292;&#20855;&#26377;&#22810;&#39033;&#24335;&#26102;&#38388;&#25928;&#29575;&#19988;&#21487;&#25193;&#23637;&#24615;&#24378;&#12290;</title><link>https://arxiv.org/abs/2402.16712</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#30340;&#31283;&#20581;&#31232;&#30095;&#20027;&#25104;&#20998;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Scalable Robust Sparse Principal Component Analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16712
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20248;&#21270;&#26694;&#26550;&#65292;&#21487;&#22312;&#31232;&#30095;&#31283;&#20581;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#19968;&#32500;&#23376;&#31354;&#38388;&#65292;&#36890;&#36807;&#24341;&#20837;&#32447;&#24615;&#26494;&#24347;&#26041;&#27861;&#21644;&#26032;&#39062;&#30340;&#25311;&#21512;&#31243;&#24207;&#65292;&#23454;&#29616;&#20102;&#20840;&#23616;&#26368;&#20248;&#30340;&#31283;&#20581;&#31232;&#30095;&#23376;&#31354;&#38388;&#65292;&#20855;&#26377;&#22810;&#39033;&#24335;&#26102;&#38388;&#25928;&#29575;&#19988;&#21487;&#25193;&#23637;&#24615;&#24378;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20248;&#21270;&#26694;&#26550;&#26469;&#20272;&#35745;&#31232;&#30095;&#31283;&#20581;&#30340;&#19968;&#32500;&#23376;&#31354;&#38388;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#26368;&#23567;&#21270;&#34920;&#31034;&#35823;&#24046;&#21644;l1&#33539;&#25968;&#20934;&#21017;&#19979;&#30340;&#24809;&#32602;&#12290;&#37492;&#20110;&#38382;&#39064;&#26159;NP&#38590;&#30340;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#32447;&#24615;&#26494;&#24347;&#30340;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#31616;&#21333;&#27604;&#20363;&#21644;&#25490;&#24207;&#25216;&#26415;&#30340;&#26032;&#22411;&#25311;&#21512;&#31243;&#24207;&#12290;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#23637;&#31034;&#20102;$O(n^2 m \log n)$&#30340;&#26368;&#22351;&#26102;&#38388;&#22797;&#26434;&#24230;&#65292;&#24182;&#19988;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#23454;&#29616;&#20102;&#31232;&#30095;&#31283;&#20581;&#23376;&#31354;&#38388;&#30340;&#20840;&#23616;&#26368;&#20248;&#65292;&#20174;&#32780;&#23637;&#31034;&#20102;&#22810;&#39033;&#24335;&#26102;&#38388;&#25928;&#29575;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#25214;&#21040;&#20855;&#26377;&#26368;&#20302;&#19981;&#19968;&#33268;&#24615;&#30340;&#23376;&#31354;&#38388;&#65292;&#25552;&#20379;&#20102;&#22312;&#31232;&#30095;&#24615;&#21644;&#25311;&#21512;&#20043;&#38388;&#26356;&#24179;&#28369;&#30340;&#26435;&#34913;&#12290;&#20854;&#26550;&#26500;&#20855;&#26377;&#21487;&#25193;&#23637;&#24615;&#65292;&#23545;&#20110;2000x2000&#30340;&#30697;&#38453;&#65292;&#35745;&#31639;&#36895;&#24230;&#30456;&#36739;CPU&#29256;&#26412;&#25552;&#21319;&#20102;16&#20493;&#12290;&#27492;&#22806;&#65292;&#36825;&#31181;&#26041;&#27861;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16712v1 Announce Type: new  Abstract: In this work, we propose an optimization framework for estimating a sparse robust one-dimensional subspace. Our objective is to minimize both the representation error and the penalty, in terms of the l1-norm criterion. Given that the problem is NP-hard, we introduce a linear relaxation-based approach. Additionally, we present a novel fitting procedure, utilizing simple ratios and sorting techniques. The proposed algorithm demonstrates a worst-case time complexity of $O(n^2 m \log n)$ and, in certain instances, achieves global optimality for the sparse robust subspace, thereby exhibiting polynomial time efficiency. Compared to extant methodologies, the proposed algorithm finds the subspace with the lowest discordance, offering a smoother trade-off between sparsity and fit. Its architecture affords scalability, evidenced by a 16-fold improvement in computational speeds for matrices of 2000x2000 over CPU version. Furthermore, this method is
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#23545;&#38543;&#26426;&#32447;&#24615;&#36172;&#33218;&#29615;&#22659;&#20013;&#30340;&#38598;&#25104;&#25277;&#26679;&#36827;&#34892;&#20102;&#39318;&#27425;&#23454;&#29992;&#21644;&#20005;&#26684;&#30340;&#20998;&#26512;&#65292;&#23637;&#31034;&#20102;&#22312;&#26631;&#20934;&#20551;&#35774;&#19979;&#65292;&#37319;&#29992;&#35268;&#27169;&#20026;$d \log T$&#30340;&#38598;&#25104;&#25277;&#26679;&#21487;&#20197;&#33719;&#24471;&#25509;&#36817;$\sqrt{T}$&#38454;&#30340;&#21518;&#24724;&#65292;&#32780;&#19981;&#38656;&#35201;&#38598;&#25104;&#22823;&#23567;&#19982;$T$&#32447;&#24615;&#25193;&#23637;&#12290;</title><link>https://arxiv.org/abs/2311.08376</link><description>&lt;p&gt;
&#32447;&#24615;&#36172;&#33218;&#30340;&#38598;&#25104;&#25277;&#26679;&#65306;&#23567;&#38598;&#25104;&#36275;&#30691;
&lt;/p&gt;
&lt;p&gt;
Ensemble sampling for linear bandits: small ensembles suffice
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.08376
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#23545;&#38543;&#26426;&#32447;&#24615;&#36172;&#33218;&#29615;&#22659;&#20013;&#30340;&#38598;&#25104;&#25277;&#26679;&#36827;&#34892;&#20102;&#39318;&#27425;&#23454;&#29992;&#21644;&#20005;&#26684;&#30340;&#20998;&#26512;&#65292;&#23637;&#31034;&#20102;&#22312;&#26631;&#20934;&#20551;&#35774;&#19979;&#65292;&#37319;&#29992;&#35268;&#27169;&#20026;$d \log T$&#30340;&#38598;&#25104;&#25277;&#26679;&#21487;&#20197;&#33719;&#24471;&#25509;&#36817;$\sqrt{T}$&#38454;&#30340;&#21518;&#24724;&#65292;&#32780;&#19981;&#38656;&#35201;&#38598;&#25104;&#22823;&#23567;&#19982;$T$&#32447;&#24615;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#39318;&#27425;&#23545;&#38543;&#26426;&#32447;&#24615;&#36172;&#33218;&#35774;&#23450;&#19979;&#30340;&#38598;&#25104;&#25277;&#26679;&#36827;&#34892;&#20102;&#26377;&#29992;&#19988;&#20005;&#35880;&#30340;&#20998;&#26512;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#26631;&#20934;&#20551;&#35774;&#19979;&#65292;&#23545;&#20110;&#19968;&#20010;&#20855;&#26377;&#20132;&#20114;&#20316;&#29992;&#26102;&#38388;&#36328;&#24230;$T$&#30340;$d$&#32500;&#38543;&#26426;&#32447;&#24615;&#36172;&#33218;&#65292;&#37319;&#29992;&#38598;&#25104;&#22823;&#23567;&#20026;$\smash{d \log T}$&#30340;&#38598;&#25104;&#25277;&#26679;&#65292;&#36973;&#21463;&#30340;&#21518;&#24724;&#26368;&#22810;&#20026;$\smash{(d \log T)^{5/2} \sqrt{T}}$&#38454;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26159;&#22312;&#20219;&#20309;&#32467;&#26500;&#21270;&#29615;&#22659;&#20013;&#31532;&#19968;&#20010;&#19981;&#35201;&#27714;&#38598;&#25104;&#22823;&#23567;&#19982;$T$&#32447;&#24615;&#25193;&#23637;&#30340;&#32467;&#26524;&#65292;&#36825;&#20351;&#24471;&#38598;&#25104;&#25277;&#26679;&#22833;&#21435;&#24847;&#20041;&#65292;&#21516;&#26102;&#33719;&#24471;&#20102;&#25509;&#36817;$\smash{\sqrt{T}}$&#38454;&#30340;&#21518;&#24724;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20063;&#26159;&#31532;&#19968;&#20010;&#20801;&#35768;&#26080;&#38480;&#21160;&#20316;&#38598;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.08376v2 Announce Type: replace-cross  Abstract: We provide the first useful and rigorous analysis of ensemble sampling for the stochastic linear bandit setting. In particular, we show that, under standard assumptions, for a $d$-dimensional stochastic linear bandit with an interaction horizon $T$, ensemble sampling with an ensemble of size of order $\smash{d \log T}$ incurs regret at most of the order $\smash{(d \log T)^{5/2} \sqrt{T}}$. Ours is the first result in any structured setting not to require the size of the ensemble to scale linearly with $T$ -- which defeats the purpose of ensemble sampling -- while obtaining near $\smash{\sqrt{T}}$ order regret. Ours is also the first result that allows infinite action sets.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;EVILL&#30340;&#38543;&#26426;&#25506;&#32034;&#26041;&#27861;&#65292;&#36890;&#36807;&#35299;&#20915;&#32447;&#24615;&#25200;&#21160;&#30340;&#36127;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#30340;&#26497;&#23567;&#21270;&#38382;&#39064;&#26469;&#24037;&#20316;&#65292;&#25552;&#20379;&#20102;&#20851;&#20110;&#38543;&#26426;&#22870;&#21169;&#25200;&#21160;&#20135;&#29983;&#33391;&#22909;&#36172;&#21338;&#31639;&#27861;&#30340;&#31616;&#27905;&#35299;&#37322;&#65292;&#24182;&#22312;&#23454;&#36341;&#20013;&#23637;&#31034;&#20102;&#19982;&#27748;&#26222;&#26862;&#25277;&#26679;&#39118;&#26684;&#21442;&#25968;&#25200;&#21160;&#26041;&#27861;&#24615;&#33021;&#30456;&#21305;&#37197;&#30340;&#33021;&#21147;</title><link>https://arxiv.org/abs/2311.07565</link><description>&lt;p&gt;
&#36890;&#36807;&#32447;&#24615;&#25200;&#21160;&#30340;&#25439;&#22833;&#26368;&#23567;&#21270;&#26469;&#36827;&#34892;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Exploration via linearly perturbed loss minimisation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.07565
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;EVILL&#30340;&#38543;&#26426;&#25506;&#32034;&#26041;&#27861;&#65292;&#36890;&#36807;&#35299;&#20915;&#32447;&#24615;&#25200;&#21160;&#30340;&#36127;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#30340;&#26497;&#23567;&#21270;&#38382;&#39064;&#26469;&#24037;&#20316;&#65292;&#25552;&#20379;&#20102;&#20851;&#20110;&#38543;&#26426;&#22870;&#21169;&#25200;&#21160;&#20135;&#29983;&#33391;&#22909;&#36172;&#21338;&#31639;&#27861;&#30340;&#31616;&#27905;&#35299;&#37322;&#65292;&#24182;&#22312;&#23454;&#36341;&#20013;&#23637;&#31034;&#20102;&#19982;&#27748;&#26222;&#26862;&#25277;&#26679;&#39118;&#26684;&#21442;&#25968;&#25200;&#21160;&#26041;&#27861;&#24615;&#33021;&#30456;&#21305;&#37197;&#30340;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;&#36890;&#36807;&#32447;&#24615;&#25439;&#22833;&#25200;&#21160;&#36827;&#34892;&#25506;&#32034;&#65288;EVILL&#65289;&#30340;&#38543;&#26426;&#25506;&#32034;&#26041;&#27861;&#65292;&#29992;&#20110;&#32467;&#26500;&#21270;&#38543;&#26426;&#36172;&#21338;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#35299;&#20915;&#32447;&#24615;&#25200;&#21160;&#27491;&#21017;&#21270;&#36127;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#30340;&#26497;&#23567;&#21270;&#38382;&#39064;&#26469;&#24037;&#20316;&#12290;&#25105;&#20204;&#23637;&#31034;&#65292;&#23545;&#20110;&#24191;&#20041;&#32447;&#24615;&#36172;&#21338;&#38382;&#39064;&#65292;EVILL&#21487;&#20197;&#31616;&#21270;&#20026;&#25200;&#21160;&#21382;&#21490;&#25506;&#32034;&#65288;PHE&#65289;&#65292;&#19968;&#31181;&#36890;&#36807;&#22312;&#38543;&#26426;&#25200;&#21160;&#22870;&#21169;&#19978;&#36827;&#34892;&#35757;&#32451;&#26469;&#36827;&#34892;&#25506;&#32034;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#36825;&#26679;&#20570;&#65292;&#25105;&#20204;&#23545;&#38543;&#26426;&#22870;&#21169;&#25200;&#21160;&#20309;&#26102;&#20197;&#21450;&#20026;&#20309;&#20135;&#29983;&#33391;&#22909;&#30340;&#36172;&#21338;&#31639;&#27861;&#25552;&#20379;&#20102;&#31616;&#21333;&#24178;&#20928;&#30340;&#35299;&#37322;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20808;&#21069;PHE&#31867;&#22411;&#26041;&#27861;&#20013;&#19981;&#21547;&#30340;&#25968;&#25454;&#30456;&#20851;&#25200;&#21160;&#65292;&#20351;EVILL&#33021;&#22815;&#22312;&#29702;&#35770;&#21644;&#23454;&#36341;&#20013;&#19982;&#27748;&#26222;&#26862;&#25277;&#26679;&#39118;&#26684;&#21442;&#25968;&#25200;&#21160;&#26041;&#27861;&#30340;&#24615;&#33021;&#30456;&#21305;&#37197;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#36229;&#20986;&#24191;&#20041;&#32447;&#24615;&#36172;&#21338;&#30340;&#20363;&#23376;&#65292;&#20854;&#20013;PHE&#23548;&#33268;&#19981;&#19968;&#33268;&#30340;&#20272;&#35745;&#65292;&#20174;&#32780;&#23548;&#33268;&#32447;&#24615;&#21518;&#24724;&#65292;&#32780;EVILL&#21017;&#20445;&#25345;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.07565v2 Announce Type: replace  Abstract: We introduce exploration via linear loss perturbations (EVILL), a randomised exploration method for structured stochastic bandit problems that works by solving for the minimiser of a linearly perturbed regularised negative log-likelihood function. We show that, for the case of generalised linear bandits, EVILL reduces to perturbed history exploration (PHE), a method where exploration is done by training on randomly perturbed rewards. In doing so, we provide a simple and clean explanation of when and why random reward perturbations give rise to good bandit algorithms. We propose data-dependent perturbations not present in previous PHE-type methods that allow EVILL to match the performance of Thompson-sampling-style parameter-perturbation methods, both in theory and in practice. Moreover, we show an example outside generalised linear bandits where PHE leads to inconsistent estimates, and thus linear regret, while EVILL remains performa
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#36830;&#32493;&#28145;&#24230;&#22270;&#31070;&#32463;&#32593;&#32476;KuramotoGNN&#65292;&#36890;&#36807;&#37319;&#29992;Kuramoto&#27169;&#22411;&#26469;&#20943;&#36731;GNN&#20013;&#30340;&#36807;&#24230;&#24179;&#28369;&#29616;&#35937;&#65292;&#23454;&#29616;&#33410;&#28857;&#29305;&#24449;&#30340;&#24046;&#24322;&#21270;&#65292;&#21462;&#24471;&#20102;&#20248;&#20110;&#22522;&#32447;GNN&#21644;&#29616;&#26377;&#26041;&#27861;&#30340;&#23454;&#39564;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2311.03260</link><description>&lt;p&gt;
&#20174;&#32806;&#21512;&#25391;&#33633;&#22120;&#21040;&#22270;&#31070;&#32463;&#32593;&#32476;&#65306;&#22522;&#20110;Kuramoto&#27169;&#22411;&#30340;&#26041;&#27861;&#20943;&#36731;&#36807;&#24230;&#24179;&#28369;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
From Coupled Oscillators to Graph Neural Networks: Reducing Over-smoothing via a Kuramoto Model-based Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.03260
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#36830;&#32493;&#28145;&#24230;&#22270;&#31070;&#32463;&#32593;&#32476;KuramotoGNN&#65292;&#36890;&#36807;&#37319;&#29992;Kuramoto&#27169;&#22411;&#26469;&#20943;&#36731;GNN&#20013;&#30340;&#36807;&#24230;&#24179;&#28369;&#29616;&#35937;&#65292;&#23454;&#29616;&#33410;&#28857;&#29305;&#24449;&#30340;&#24046;&#24322;&#21270;&#65292;&#21462;&#24471;&#20102;&#20248;&#20110;&#22522;&#32447;GNN&#21644;&#29616;&#26377;&#26041;&#27861;&#30340;&#23454;&#39564;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;Kuramoto&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;KuramotoGNN&#65289;&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#36830;&#32493;&#28145;&#24230;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#65292;&#23427;&#37319;&#29992;Kuramoto&#27169;&#22411;&#26469;&#32531;&#35299;&#36807;&#24230;&#24179;&#28369;&#29616;&#35937;&#65292;&#21363;&#38543;&#30528;&#23618;&#25968;&#22686;&#21152;&#65292;GNN&#20013;&#33410;&#28857;&#29305;&#24449;&#21464;&#24471;&#38590;&#20197;&#21306;&#20998;&#30340;&#38382;&#39064;&#12290;Kuramoto&#27169;&#22411;&#25429;&#25417;&#20102;&#38750;&#32447;&#24615;&#32806;&#21512;&#25391;&#33633;&#22120;&#30340;&#21516;&#27493;&#34892;&#20026;&#12290;&#20174;&#32806;&#21512;&#25391;&#33633;&#22120;&#30340;&#35270;&#35282;&#65292;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;Kuramoto&#27169;&#22411;&#19982;&#22522;&#26412;GNN&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#28982;&#21518;&#35828;&#26126;&#20102;GNN&#20013;&#30340;&#36807;&#24230;&#24179;&#28369;&#29616;&#35937;&#21487;&#20197;&#34987;&#35299;&#37322;&#20026;Kuramoto&#27169;&#22411;&#20013;&#30340;&#30456;&#20301;&#21516;&#27493;&#12290;KuramotoGNN&#29992;&#39057;&#29575;&#21516;&#27493;&#21462;&#20195;&#20102;&#36825;&#31181;&#30456;&#20301;&#21516;&#27493;&#65292;&#20197;&#38450;&#27490;&#33410;&#28857;&#29305;&#24449;&#25910;&#25947;&#21040;&#19968;&#36215;&#65292;&#21516;&#26102;&#20351;&#31995;&#32479;&#36798;&#21040;&#31283;&#23450;&#30340;&#21516;&#27493;&#29366;&#24577;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;KuramotoGNN&#22312;&#20943;&#23569;&#36807;&#24230;&#24179;&#28369;&#26041;&#38754;&#30456;&#23545;&#20110;&#22522;&#32447;GNN&#21644;&#29616;&#26377;&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.03260v2 Announce Type: replace-cross  Abstract: We propose the Kuramoto Graph Neural Network (KuramotoGNN), a novel class of continuous-depth graph neural networks (GNNs) that employs the Kuramoto model to mitigate the over-smoothing phenomenon, in which node features in GNNs become indistinguishable as the number of layers increases. The Kuramoto model captures the synchronization behavior of non-linear coupled oscillators. Under the view of coupled oscillators, we first show the connection between Kuramoto model and basic GNN and then over-smoothing phenomenon in GNNs can be interpreted as phase synchronization in Kuramoto model. The KuramotoGNN replaces this phase synchronization with frequency synchronization to prevent the node features from converging into each other while allowing the system to reach a stable synchronized state. We experimentally verify the advantages of the KuramotoGNN over the baseline GNNs and existing methods in reducing over-smoothing on various 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#25972;&#21512;&#39640;&#20998;&#36776;&#29575;&#32437;&#21521;&#25968;&#25454;&#19982;&#29983;&#23384;&#27169;&#22411;&#21160;&#24577;&#39044;&#27979;&#33021;&#21147;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#20302;&#20998;&#36776;&#29575;&#25968;&#25454;&#21644;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#25552;&#21462;&#30340;&#39044;&#27979;&#29305;&#24449;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#39044;&#27979;&#33021;&#21147;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#27169;&#22411;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>https://arxiv.org/abs/2301.11146</link><description>&lt;p&gt;
&#20004;&#27493;&#21487;&#35299;&#37322;&#24314;&#27169;&#65306;&#37325;&#30151;&#30417;&#25252;&#33719;&#24471;&#24615;&#24863;&#26579;
&lt;/p&gt;
&lt;p&gt;
Two-step interpretable modeling of Intensive Care Acquired Infections
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2301.11146
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#25972;&#21512;&#39640;&#20998;&#36776;&#29575;&#32437;&#21521;&#25968;&#25454;&#19982;&#29983;&#23384;&#27169;&#22411;&#21160;&#24577;&#39044;&#27979;&#33021;&#21147;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#20302;&#20998;&#36776;&#29575;&#25968;&#25454;&#21644;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#25552;&#21462;&#30340;&#39044;&#27979;&#29305;&#24449;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#39044;&#27979;&#33021;&#21147;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#27169;&#22411;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#23558;&#39640;&#20998;&#36776;&#29575;&#30340;&#32437;&#21521;&#25968;&#25454;&#19982;&#29983;&#23384;&#27169;&#22411;&#30340;&#21160;&#24577;&#39044;&#27979;&#33021;&#21147;&#30456;&#32467;&#21512;&#12290;&#20854;&#30446;&#30340;&#26159;&#21452;&#37325;&#30340;&#65306;&#25552;&#39640;&#39044;&#27979;&#33021;&#21147;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;&#20026;&#20102;&#36229;&#36234;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#30340;&#40657;&#21283;&#23376;&#33539;&#24335;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#32422;&#19988;&#31283;&#20581;&#30340;&#21322;&#21442;&#25968;&#26041;&#27861;&#65288;&#21363;&#22522;&#20110;&#37324;&#31243;&#30865;&#31454;&#20105;&#39118;&#38505;&#27169;&#22411;&#65289;&#65292;&#23558;&#24120;&#35268;&#25910;&#38598;&#30340;&#20302;&#20998;&#36776;&#29575;&#25968;&#25454;&#19982;&#20174;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20013;&#25552;&#21462;&#30340;&#39044;&#27979;&#29305;&#24449;&#30456;&#32467;&#21512;&#65292;&#35813;&#31070;&#32463;&#32593;&#32476;&#26159;&#22312;&#39640;&#20998;&#36776;&#29575;&#30340;&#26102;&#38388;&#30456;&#20851;&#20449;&#24687;&#19978;&#35757;&#32451;&#30340;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#26174;&#33879;&#24615;&#22320;&#22270;&#26469;&#20998;&#26512;&#21644;&#35299;&#37322;&#35813;&#27169;&#22411;&#30340;&#39069;&#22806;&#39044;&#27979;&#33021;&#21147;&#12290;&#20026;&#20102;&#35828;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#37325;&#28857;&#20851;&#27880;&#34987;&#36865;&#24448;&#37325;&#30151;&#30417;&#25252;&#30149;&#25151;&#30340;&#24739;&#32773;&#20013;&#19982;&#21307;&#30103;&#30456;&#20851;&#30340;&#24863;&#26579;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2301.11146v2 Announce Type: replace-cross  Abstract: We present a novel methodology for integrating high resolution longitudinal data with the dynamic prediction capabilities of survival models. The aim is two-fold: to improve the predictive power while maintaining interpretability of the models. To go beyond the black box paradigm of artificial neural networks, we propose a parsimonious and robust semi-parametric approach (i.e., a landmarking competing risks model) that combines routinely collected low-resolution data with predictive features extracted from a convolutional neural network, that was trained on high resolution time-dependent information. We then use saliency maps to analyze and explain the extra predictive power of this model. To illustrate our methodology, we focus on healthcare-associated infections in patients admitted to an intensive care unit.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#20855;&#26377;&#20984;&#25439;&#22833;&#30340;&#32447;&#24615;&#39044;&#27979;&#22120;&#30340;$(\epsilon,\delta)$-&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;&#38382;&#39064;&#65292;&#20026;&#20004;&#20010;&#25439;&#22833;&#20989;&#25968;&#23376;&#31867;&#25552;&#20379;&#20102;&#32467;&#26524;&#65292;&#24182;&#22312;&#25152;&#26377;&#21442;&#25968;&#19978;&#23637;&#31034;&#20102;&#22522;&#26412;&#32039;&#23494;&#30340;&#19978;&#30028;&#21644;&#19979;&#30028;&#12290;</title><link>https://arxiv.org/abs/2205.03014</link><description>&lt;p&gt;
&#37325;&#26032;&#23457;&#35270;&#24046;&#20998;&#38544;&#31169;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Generalized Linear Models Revisited
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2205.03014
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#20855;&#26377;&#20984;&#25439;&#22833;&#30340;&#32447;&#24615;&#39044;&#27979;&#22120;&#30340;$(\epsilon,\delta)$-&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;&#38382;&#39064;&#65292;&#20026;&#20004;&#20010;&#25439;&#22833;&#20989;&#25968;&#23376;&#31867;&#25552;&#20379;&#20102;&#32467;&#26524;&#65292;&#24182;&#22312;&#25152;&#26377;&#21442;&#25968;&#19978;&#23637;&#31034;&#20102;&#22522;&#26412;&#32039;&#23494;&#30340;&#19978;&#30028;&#21644;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#20984;&#25439;&#22833;&#30340;&#32447;&#24615;&#39044;&#27979;&#22120;&#30340;$(\epsilon,\delta)$-&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;&#38382;&#39064;&#12290;&#25105;&#20204;&#38024;&#23545;&#20004;&#20010;&#25439;&#22833;&#20989;&#25968;&#23376;&#31867;&#25552;&#20379;&#20102;&#32467;&#26524;&#12290;&#31532;&#19968;&#31181;&#24773;&#20917;&#26159;&#24403;&#25439;&#22833;&#26159;&#20809;&#28369;&#19988;&#38750;&#36127;&#20294;&#19981;&#19968;&#23450;&#21033;&#26222;&#24076;&#20857;&#26102;&#65288;&#22914;&#24179;&#26041;&#25439;&#22833;&#65289;&#12290;&#23545;&#20110;&#36825;&#31181;&#24773;&#20917;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#20851;&#20110;&#36807;&#37327;&#24635;&#20307;&#39118;&#38505;&#30340;&#19978;&#30028;&#65292;&#20026;$\tilde{O}\left(\frac{\Vert w^*\Vert}{\sqrt{n}} + \min\left\{\frac{\Vert w^* \Vert^2}{(n\epsilon)^{2/3}},\frac{\sqrt{d}\Vert w^*\Vert^2}{n\epsilon}\right\}\right)$&#65292;&#20854;&#20013;$n$&#26159;&#26679;&#26412;&#25968;&#65292;$d$&#26159;&#38382;&#39064;&#30340;&#32500;&#24230;&#65292;$w^*$&#26159;&#24635;&#20307;&#39118;&#38505;&#30340;&#26368;&#23567;&#21270;&#32773;&#12290;&#38500;&#20102;&#23545;$\Vert w^\ast\Vert$&#30340;&#20381;&#36182;&#20043;&#22806;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#22312;&#25152;&#26377;&#21442;&#25968;&#19978;&#22522;&#26412;&#19978;&#26159;&#32039;&#23494;&#30340;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;$\tilde{\Omega}\left(\frac{1}{\sqrt{n}} + {\min\left\{\frac{\Vert w^*\Vert^{4/3}}{(n\epsilon)^{2/3}}, \frac{\sqrt{d}\Vert w^*\Vert}{n\epsilon}\right\}}$&#30340;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2205.03014v2 Announce Type: replace  Abstract: We study the problem of $(\epsilon,\delta)$-differentially private learning of linear predictors with convex losses. We provide results for two subclasses of loss functions. The first case is when the loss is smooth and non-negative but not necessarily Lipschitz (such as the squared loss). For this case, we establish an upper bound on the excess population risk of $\tilde{O}\left(\frac{\Vert w^*\Vert}{\sqrt{n}} + \min\left\{\frac{\Vert w^* \Vert^2}{(n\epsilon)^{2/3}},\frac{\sqrt{d}\Vert w^*\Vert^2}{n\epsilon}\right\}\right)$, where $n$ is the number of samples, $d$ is the dimension of the problem, and $w^*$ is the minimizer of the population risk. Apart from the dependence on $\Vert w^\ast\Vert$, our bound is essentially tight in all parameters. In particular, we show a lower bound of $\tilde{\Omega}\left(\frac{1}{\sqrt{n}} + {\min\left\{\frac{\Vert w^*\Vert^{4/3}}{(n\epsilon)^{2/3}}, \frac{\sqrt{d}\Vert w^*\Vert}{n\epsilon}\right\}}
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26679;&#26412;&#36873;&#25321;&#20559;&#24046;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#21033;&#29992;&#38598;&#25104;&#22810;&#26679;&#24615;&#36827;&#34892;&#40065;&#26834;&#30340;&#33258;&#35757;&#32451;&#30340;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#20449;&#24230;&#24230;&#37327;&#26041;&#27861;-$\mathcal{T}$-&#30456;&#20284;&#24230;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#19977;&#31181;&#19981;&#21516;&#20266;&#26631;&#31614;&#31574;&#30053;&#19979;&#20855;&#26377;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.14814</link><description>&lt;p&gt;
&#22312;&#26679;&#26412;&#36873;&#25321;&#20559;&#24046;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#21033;&#29992;&#38598;&#25104;&#22810;&#26679;&#24615;&#36827;&#34892;&#40065;&#26834;&#30340;&#33258;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Leveraging Ensemble Diversity for Robust Self-Training in the Presence of Sample Selection Bias. (arXiv:2310.14814v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14814
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26679;&#26412;&#36873;&#25321;&#20559;&#24046;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#21033;&#29992;&#38598;&#25104;&#22810;&#26679;&#24615;&#36827;&#34892;&#40065;&#26834;&#30340;&#33258;&#35757;&#32451;&#30340;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#20449;&#24230;&#24230;&#37327;&#26041;&#27861;-$\mathcal{T}$-&#30456;&#20284;&#24230;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#19977;&#31181;&#19981;&#21516;&#20266;&#26631;&#31614;&#31574;&#30053;&#19979;&#20855;&#26377;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#35757;&#32451;&#26159;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#19968;&#31181;&#20247;&#25152;&#21608;&#30693;&#30340;&#26041;&#27861;&#12290;&#23427;&#21253;&#25324;&#23545;&#27169;&#22411;&#33258;&#20449;&#24230;&#39640;&#30340;&#26410;&#26631;&#35760;&#25968;&#25454;&#36827;&#34892;&#20266;&#26631;&#31614;&#20998;&#37197;&#65292;&#24182;&#23558;&#20854;&#35270;&#20026;&#26631;&#35760;&#26679;&#26412;&#36827;&#34892;&#22788;&#29702;&#12290;&#23545;&#20110;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#24120;&#20351;&#29992;softmax&#39044;&#27979;&#27010;&#29575;&#20316;&#20026;&#33258;&#20449;&#24230;&#24230;&#37327;&#65292;&#23613;&#31649;&#24050;&#30693;&#23427;&#20204;&#23545;&#38169;&#35823;&#39044;&#27979;&#20063;&#36807;&#20110;&#33258;&#20449;&#12290;&#24403;&#25968;&#25454;&#26631;&#27880;&#21463;&#21040;&#26576;&#31181;&#32422;&#26463;&#26102;&#65292;&#36825;&#31181;&#29616;&#35937;&#23588;&#20026;&#26126;&#26174;&#65292;&#21363;&#26679;&#26412;&#36873;&#25321;&#20559;&#24046;&#23384;&#22312;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#20449;&#24230;&#24230;&#37327;&#26041;&#27861;&#65292;&#31216;&#20026;$\mathcal{T}$-&#30456;&#20284;&#24230;&#65292;&#23427;&#22522;&#20110;&#32447;&#24615;&#20998;&#31867;&#22120;&#30340;&#38598;&#25104;&#39044;&#27979;&#22810;&#26679;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#30740;&#31350;&#31283;&#23450;&#28857;&#24182;&#25551;&#36848;&#21333;&#20010;&#25104;&#21592;&#30340;&#22810;&#26679;&#24615;&#19982;&#20854;&#24615;&#33021;&#20043;&#38388;&#30340;&#20851;&#31995;&#26469;&#25552;&#20379;&#25105;&#20204;&#26041;&#27861;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#19977;&#31181;&#19981;&#21516;&#20266;&#26631;&#31614;&#31574;&#30053;&#30340;&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#33258;&#20449;&#24230;&#24230;&#37327;&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-training is a well-known approach for semi-supervised learning. It consists of iteratively assigning pseudo-labels to unlabeled data for which the model is confident and treating them as labeled examples. For neural networks, softmax prediction probabilities are often used as a confidence measure, despite the fact that they are known to be overconfident, even for wrong predictions. This phenomenon is particularly intensified in the presence of sample selection bias, i.e., when data labeling is subject to some constraint. To address this issue, we propose a novel confidence measure, called $\mathcal{T}$-similarity, built upon the prediction diversity of an ensemble of linear classifiers. We provide the theoretical analysis of our approach by studying stationary points and describing the relationship between the diversity of the individual members and their performance. We empirically demonstrate the benefit of our confidence measure for three different pseudo-labeling policies on c
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22788;&#29702;&#20855;&#26377;&#31038;&#20250;&#24847;&#20041;&#30340;&#26080;&#20998;&#24067;&#32479;&#35745;&#31163;&#25955;&#24230;&#25511;&#21046;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#39640;&#39118;&#38505;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2309.13786</link><description>&lt;p&gt;
&#31038;&#20250;&#24212;&#29992;&#30340;&#26080;&#20998;&#24067;&#32479;&#35745;&#31163;&#25955;&#24230;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Distribution-Free Statistical Dispersion Control for Societal Applications. (arXiv:2309.13786v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13786
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22788;&#29702;&#20855;&#26377;&#31038;&#20250;&#24847;&#20041;&#30340;&#26080;&#20998;&#24067;&#32479;&#35745;&#31163;&#25955;&#24230;&#25511;&#21046;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#39640;&#39118;&#38505;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36127;&#36131;&#20219;&#30340;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#23545;&#27169;&#22411;&#24615;&#33021;&#30340;&#26174;&#24335;&#26377;&#38480;&#26679;&#26412;&#32479;&#35745;&#20445;&#35777;&#26159;&#19968;&#20010;&#37325;&#35201;&#22240;&#32032;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;&#20110;&#30028;&#23450;&#39044;&#27979;&#22120;&#30340;&#26399;&#26395;&#25439;&#22833;&#25110;&#32773;&#20010;&#20307;&#39044;&#27979;&#23558;&#25215;&#21463;&#30340;&#25439;&#22833;&#20540;&#22312;&#19968;&#20010;&#25351;&#23450;&#33539;&#22260;&#20869;&#30340;&#27010;&#29575;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#35768;&#22810;&#39640;&#39118;&#38505;&#24212;&#29992;&#32780;&#35328;&#65292;&#29702;&#35299;&#21644;&#25511;&#21046;&#25439;&#22833;&#20998;&#24067;&#30340;&#31163;&#25955;&#24230;&#65292;&#25110;&#32773;&#35828;&#20154;&#32676;&#20013;&#19981;&#21516;&#20010;&#20307;&#23545;&#31639;&#27861;&#20915;&#31574;&#30340;&#24433;&#21709;&#31243;&#24230;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#25105;&#20204;&#24320;&#22987;&#30740;&#31350;&#20855;&#26377;&#31038;&#20250;&#24847;&#20041;&#30340;&#26080;&#20998;&#24067;&#32479;&#35745;&#31163;&#25955;&#24230;&#25511;&#21046;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#20294;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#22788;&#29702;&#27604;&#20197;&#21069;&#30340;&#24037;&#20316;&#26356;&#20016;&#23500;&#30340;&#32479;&#35745;&#21151;&#33021;&#31867;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#26377;&#27602;&#35780;&#35770;&#26816;&#27979;&#12289;&#21307;&#23398;&#24433;&#20687;&#21644;&#30005;&#24433;&#25512;&#33616;&#31561;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Explicit finite-sample statistical guarantees on model performance are an important ingredient in responsible machine learning. Previous work has focused mainly on bounding either the expected loss of a predictor or the probability that an individual prediction will incur a loss value in a specified range. However, for many high-stakes applications, it is crucial to understand and control the dispersion of a loss distribution, or the extent to which different members of a population experience unequal effects of algorithmic decisions. We initiate the study of distribution-free control of statistical dispersion measures with societal implications and propose a simple yet flexible framework that allows us to handle a much richer class of statistical functionals beyond previous work. Our methods are verified through experiments in toxic comment detection, medical imaging, and film recommendation.
&lt;/p&gt;</description></item><item><title>AbDiffuser&#26159;&#19968;&#20010;&#29289;&#29702;&#24615;&#25193;&#25955;&#27169;&#22411;&#65292;&#29992;&#20110;&#32852;&#21512;&#29983;&#25104;&#25239;&#20307;&#30340;&#19977;&#32500;&#32467;&#26500;&#21644;&#24207;&#21015;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#39046;&#22495;&#30693;&#35782;&#21644;&#22522;&#20110;&#29289;&#29702;&#30340;&#32422;&#26463;&#25913;&#21892;&#34507;&#30333;&#36136;&#25193;&#25955;&#65292;&#22788;&#29702;&#24207;&#21015;&#38271;&#24230;&#21464;&#21270;&#65292;&#24182;&#33021;&#22815;&#29983;&#25104;&#19982;&#21442;&#32771;&#38598;&#21512;&#30340;&#24207;&#21015;&#21644;&#32467;&#26500;&#29305;&#24615;&#23494;&#20999;&#21305;&#37197;&#30340;&#25239;&#20307;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;AbDiffuser&#33021;&#22815;&#29983;&#25104;&#39640;&#27700;&#24179;&#34920;&#36798;&#30340;&#25239;&#20307;&#65292;&#20854;&#20013;57.1%&#30340;&#35774;&#35745;&#36873;&#25321;&#26159;&#32039;&#23494;&#32467;&#21512;&#21058;&#12290;</title><link>http://arxiv.org/abs/2308.05027</link><description>&lt;p&gt;
AbDiffuser&#65306;&#20307;&#22806;&#21151;&#33021;&#25239;&#20307;&#30340;&#20840;&#21407;&#23376;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
AbDiffuser: Full-Atom Generation of In-Vitro Functioning Antibodies. (arXiv:2308.05027v1 [q-bio.BM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05027
&lt;/p&gt;
&lt;p&gt;
AbDiffuser&#26159;&#19968;&#20010;&#29289;&#29702;&#24615;&#25193;&#25955;&#27169;&#22411;&#65292;&#29992;&#20110;&#32852;&#21512;&#29983;&#25104;&#25239;&#20307;&#30340;&#19977;&#32500;&#32467;&#26500;&#21644;&#24207;&#21015;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#39046;&#22495;&#30693;&#35782;&#21644;&#22522;&#20110;&#29289;&#29702;&#30340;&#32422;&#26463;&#25913;&#21892;&#34507;&#30333;&#36136;&#25193;&#25955;&#65292;&#22788;&#29702;&#24207;&#21015;&#38271;&#24230;&#21464;&#21270;&#65292;&#24182;&#33021;&#22815;&#29983;&#25104;&#19982;&#21442;&#32771;&#38598;&#21512;&#30340;&#24207;&#21015;&#21644;&#32467;&#26500;&#29305;&#24615;&#23494;&#20999;&#21305;&#37197;&#30340;&#25239;&#20307;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;AbDiffuser&#33021;&#22815;&#29983;&#25104;&#39640;&#27700;&#24179;&#34920;&#36798;&#30340;&#25239;&#20307;&#65292;&#20854;&#20013;57.1%&#30340;&#35774;&#35745;&#36873;&#25321;&#26159;&#32039;&#23494;&#32467;&#21512;&#21058;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;AbDiffuser&#30340;&#31561;&#21464;&#29289;&#29702;&#24615;&#25193;&#25955;&#27169;&#22411;&#65292;&#29992;&#20110;&#32852;&#21512;&#29983;&#25104;&#25239;&#20307;&#30340;&#19977;&#32500;&#32467;&#26500;&#21644;&#24207;&#21015;&#12290;AbDiffuser&#24314;&#31435;&#22312;&#19968;&#31181;&#26032;&#30340;&#34507;&#30333;&#36136;&#32467;&#26500;&#34920;&#31034;&#19978;&#65292;&#20381;&#36182;&#20110;&#19968;&#31181;&#38024;&#23545;&#40784;&#20301;&#34507;&#30333;&#30340;&#26032;&#22411;&#26550;&#26500;&#65292;&#24182;&#21033;&#29992;&#24378;&#25193;&#25955;&#20808;&#39564;&#25913;&#21892;&#21435;&#22122;&#36807;&#31243;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#21033;&#29992;&#39046;&#22495;&#30693;&#35782;&#21644;&#22522;&#20110;&#29289;&#29702;&#30340;&#32422;&#26463;&#25913;&#21892;&#20102;&#34507;&#30333;&#36136;&#25193;&#25955;&#65307;&#22788;&#29702;&#24207;&#21015;&#38271;&#24230;&#21464;&#21270;&#65307;&#24182;&#23558;&#20869;&#23384;&#22797;&#26434;&#24615;&#38477;&#20302;&#19968;&#20010;&#25968;&#37327;&#32423;&#65292;&#23454;&#29616;&#20102;&#39592;&#26550;&#21644;&#20391;&#38142;&#30340;&#29983;&#25104;&#12290;&#25105;&#20204;&#22312;&#20307;&#20869;&#21644;&#20307;&#22806;&#39564;&#35777;&#20102;AbDiffuser&#12290;&#25968;&#20540;&#23454;&#39564;&#23637;&#31034;&#20102;AbDiffuser&#29983;&#25104;&#19982;&#21442;&#32771;&#38598;&#21512;&#30340;&#24207;&#21015;&#21644;&#32467;&#26500;&#29305;&#24615;&#23494;&#20999;&#21305;&#37197;&#30340;&#25239;&#20307;&#30340;&#33021;&#21147;&#12290;&#23454;&#39564;&#23460;&#23454;&#39564;&#35777;&#23454;&#65292;&#21457;&#29616;&#30340;16&#31181;HER2&#25239;&#20307;&#22343;&#20197;&#39640;&#27700;&#24179;&#34920;&#36798;&#65292;&#24182;&#19988;57.1%&#30340;&#35774;&#35745;&#36873;&#25321;&#26159;&#32039;&#23494;&#32467;&#21512;&#21058;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce AbDiffuser, an equivariant and physics-informed diffusion model for the joint generation of antibody 3D structures and sequences. AbDiffuser is built on top of a new representation of protein structure, relies on a novel architecture for aligned proteins, and utilizes strong diffusion priors to improve the denoising process. Our approach improves protein diffusion by taking advantage of domain knowledge and physics-based constraints; handles sequence-length changes; and reduces memory complexity by an order of magnitude enabling backbone and side chain generation. We validate AbDiffuser in silico and in vitro. Numerical experiments showcase the ability of AbDiffuser to generate antibodies that closely track the sequence and structural properties of a reference set. Laboratory experiments confirm that all 16 HER2 antibodies discovered were expressed at high levels and that 57.1% of selected designs were tight binders.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#38543;&#26426;&#23450;&#20301;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#35299;&#20915;&#25193;&#25955;&#27169;&#22411;&#20013;&#32447;&#24615;&#25910;&#25947;&#30028;&#38480;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#22312;&#26377;&#38480;&#20108;&#38454;&#30697;&#26465;&#20214;&#19979;&#36798;&#21040;&#21487;&#25509;&#21463;&#30340;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2308.03686</link><description>&lt;p&gt;
&#36890;&#36807;&#38543;&#26426;&#23450;&#20301;&#26041;&#27861;&#33719;&#24471;&#25193;&#25955;&#27169;&#22411;&#30340;&#32447;&#24615;&#25910;&#25947;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Linear Convergence Bounds for Diffusion Models via Stochastic Localization. (arXiv:2308.03686v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03686
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#38543;&#26426;&#23450;&#20301;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#35299;&#20915;&#25193;&#25955;&#27169;&#22411;&#20013;&#32447;&#24615;&#25910;&#25947;&#30028;&#38480;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#22312;&#26377;&#38480;&#20108;&#38454;&#30697;&#26465;&#20214;&#19979;&#36798;&#21040;&#21487;&#25509;&#21463;&#30340;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#26159;&#20174;&#39640;&#32500;&#25968;&#25454;&#20998;&#24067;&#20013;&#29983;&#25104;&#36817;&#20284;&#26679;&#26412;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;&#26368;&#36817;&#30340;&#19968;&#20123;&#30740;&#31350;&#32467;&#26524;&#25552;&#20379;&#20102;&#20851;&#20110;&#36825;&#31181;&#27169;&#22411;&#30340;&#25910;&#25947;&#36895;&#24230;&#30340;&#22810;&#39033;&#24335;&#30028;&#38480;&#65292;&#20551;&#35774;$L^2$&#20934;&#30830;&#30340;&#24471;&#20998;&#20272;&#35745;&#22120;&#12290;&#28982;&#32780;&#65292;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#24050;&#30693;&#30340;&#26368;&#20339;&#30028;&#38480;&#35201;&#20040;&#23545;&#25968;&#25454;&#32500;&#24230;&#26159;&#36229;&#32447;&#24615;&#30340;&#65292;&#35201;&#20040;&#38656;&#35201;&#24378;&#24179;&#28369;&#24615;&#20551;&#35774;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#20551;&#35774;&#21482;&#38656;&#35201;&#25968;&#25454;&#20998;&#24067;&#26377;&#26377;&#38480;&#20108;&#38454;&#30697;&#30340;&#25910;&#25947;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#23545;&#20110;&#25968;&#25454;&#32500;&#24230;&#26159;&#32447;&#24615;&#30340;&#65288;&#20056;&#20197;&#23545;&#25968;&#22240;&#23376;&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25193;&#25955;&#27169;&#22411;&#26368;&#22810;&#38656;&#35201;$\tilde O(\frac{d \log^2(1/\delta)}{\varepsilon^2})$&#27493;&#65292;&#23601;&#21487;&#20197;&#23558;&#24102;&#26377;&#26041;&#24046;&#20026;$\delta$&#30340;&#39640;&#26031;&#22122;&#22768;&#25439;&#22351;&#30340;&#20219;&#24847;&#25968;&#25454;&#20998;&#24067;&#22312;Kullback--Leibler&#25955;&#24230;&#19979;&#36817;&#20284;&#21040;$\varepsilon^2$&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#20381;&#36182;&#20110;&#21069;&#20154;&#30340;Girsanov&#26041;&#27861;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#23545;&#20110;&#21453;&#21521;SD&#31163;&#25955;&#21270;&#35823;&#24046;&#30340;&#31934;&#32454;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models are a powerful method for generating approximate samples from high-dimensional data distributions. Several recent results have provided polynomial bounds on the convergence rate of such models, assuming $L^2$-accurate score estimators. However, up until now the best known such bounds were either superlinear in the data dimension or required strong smoothness assumptions. We provide the first convergence bounds which are linear in the data dimension (up to logarithmic factors) assuming only finite second moments of the data distribution. We show that diffusion models require at most $\tilde O(\frac{d \log^2(1/\delta)}{\varepsilon^2})$ steps to approximate an arbitrary data distribution on $\mathbb{R}^d$ corrupted with Gaussian noise of variance $\delta$ to within $\varepsilon^2$ in Kullback--Leibler divergence. Our proof builds on the Girsanov-based methods of previous works. We introduce a refined treatment of the error arising from the discretization of the reverse SD
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#38750;&#38646;&#30456;&#20851;&#24615;&#30340;&#38543;&#26426;&#22270;&#21305;&#37197;&#30340;&#22810;&#39033;&#24335;&#36845;&#20195;&#31639;&#27861;&#65292;&#24182;&#19988;&#22312;&#36793;&#32536;&#30456;&#20851;&#24615;&#38750;&#38646;&#26102;&#25104;&#21151;&#24674;&#22797;&#28508;&#22312;&#21305;&#37197;&#12290;</title><link>http://arxiv.org/abs/2306.00266</link><description>&lt;p&gt;
&#19968;&#31181;&#20855;&#26377;&#38750;&#38646;&#30456;&#20851;&#24615;&#30340;&#38543;&#26426;&#22270;&#21305;&#37197;&#30340;&#22810;&#39033;&#24335;&#36845;&#20195;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A polynomial-time iterative algorithm for random graph matching with non-vanishing correlation. (arXiv:2306.00266v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00266
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#38750;&#38646;&#30456;&#20851;&#24615;&#30340;&#38543;&#26426;&#22270;&#21305;&#37197;&#30340;&#22810;&#39033;&#24335;&#36845;&#20195;&#31639;&#27861;&#65292;&#24182;&#19988;&#22312;&#36793;&#32536;&#30456;&#20851;&#24615;&#38750;&#38646;&#26102;&#25104;&#21151;&#24674;&#22797;&#28508;&#22312;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#21305;&#37197;&#20004;&#20010;&#30456;&#20851;&#30340;Erd&#337;s-R&#233;nyi&#22270;&#34920;&#30340;&#26377;&#25928;&#31639;&#27861;&#65292;&#23427;&#20204;&#20855;&#26377; $n$ &#20010;&#39030;&#28857;&#65292;&#20854;&#36793;&#32536;&#36890;&#36807;&#28508;&#22312;&#30340;&#39030;&#28857;&#23545;&#24212;&#20851;&#31995;&#30456;&#20114;&#20851;&#32852;&#12290;&#24403;&#36793;&#32536;&#23494;&#24230; $q=n^{-\alpha+o(1)}$&#65292;&#23545;&#20110;&#19968;&#20010;&#24120;&#25968; $\alpha \in [0,1)$ &#26102;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#20855;&#26377;&#22810;&#39033;&#24335;&#36816;&#34892;&#26102;&#38388;&#65292;&#24182;&#19988;&#21482;&#35201;&#36793;&#32536;&#30456;&#20851;&#24615;&#38750;&#38646;&#65292;&#23601;&#33021;&#25104;&#21151;&#24674;&#22797;&#28508;&#22312;&#21305;&#37197;&#12290;&#36825;&#19982;&#25105;&#20204;&#20808;&#21069;&#20851;&#20110;&#21305;&#37197;&#20004;&#20010;&#20855;&#26377;&#38750;&#38646;&#30456;&#20851;&#24615;&#30340;&#39640;&#26031;Wigner&#30697;&#38453;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#30340;&#24037;&#20316;&#23494;&#20999;&#30456;&#20851;&#65292;&#24182;&#19988;&#22312;&#36793;&#32536;&#30456;&#20851;&#24615;&#20302;&#20110;Otter&#24120;&#25968;&#30340;&#24179;&#26041;&#26681;&#65288;&#32422;&#20026;0.338&#65289;&#26102;&#65292;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#38543;&#26426;&#22270;&#21305;&#37197;&#31639;&#27861;&#65288;&#26080;&#35770; $q$ &#30340;&#33539;&#22260;&#22914;&#20309;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose an efficient algorithm for matching two correlated Erd\H{o}s--R\'enyi graphs with $n$ vertices whose edges are correlated through a latent vertex correspondence. When the edge density $q= n^{- \alpha+o(1)}$ for a constant $\alpha \in [0,1)$, we show that our algorithm has polynomial running time and succeeds to recover the latent matching as long as the edge correlation is non-vanishing. This is closely related to our previous work on a polynomial-time algorithm that matches two Gaussian Wigner matrices with non-vanishing correlation, and provides the first polynomial-time random graph matching algorithm (regardless of the regime of $q$) when the edge correlation is below the square root of the Otter's constant (which is $\approx 0.338$).
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#20004;&#38454;&#27573;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#22270;&#20687;&#21387;&#32553;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#34920;&#29616;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#19968;&#23450;&#27604;&#29305;&#29575;&#19979;&#33021;&#22815;&#25552;&#39640;&#22270;&#20687;&#30340;&#24863;&#30693;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2305.18231</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#39640;&#20445;&#30495;&#22270;&#20687;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
High-Fidelity Image Compression with Score-based Generative Models. (arXiv:2305.18231v1 [eess.IV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18231
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#20004;&#38454;&#27573;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#22270;&#20687;&#21387;&#32553;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#34920;&#29616;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#19968;&#23450;&#27604;&#29305;&#29575;&#19979;&#33021;&#22815;&#25552;&#39640;&#22270;&#20687;&#30340;&#24863;&#30693;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#22312;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#65292;&#20294;&#22312;&#22270;&#20687;&#21387;&#32553;&#39046;&#22495;&#22797;&#21046;&#36825;&#20010;&#25104;&#21151;&#21364;&#24456;&#22256;&#38590;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25193;&#25955;&#27169;&#22411;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22312;&#32473;&#23450;&#27604;&#29305;&#29575;&#19979;&#30340;&#24863;&#30693;&#36136;&#37327;&#65292;&#36890;&#36807; FID &#20998;&#25968;&#35780;&#20272;&#65292;&#34920;&#29616;&#36229;&#36234;&#20102; PO-ELIC &#21644; HiFiC &#30340;&#29616;&#26377;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#31616;&#21333;&#20294;&#22312;&#29702;&#35770;&#19978;&#26377;&#21160;&#26426;&#30340;&#20004;&#38454;&#27573;&#26041;&#27861;&#23454;&#29616;&#20102;&#36825;&#19968;&#28857;&#65292;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#20197; MSE &#20026;&#30446;&#26631;&#30340;&#33258;&#21160;&#32534;&#30721;&#22120;&#21644;&#19968;&#20010;&#36827;&#19968;&#27493;&#22522;&#20110;&#20998;&#25968;&#30340;&#35299;&#30721;&#22120;&#12290;&#28982;&#32780;&#65292;&#27491;&#22914;&#25105;&#20204;&#23558;&#23637;&#31034;&#30340;&#37027;&#26679;&#65292;&#23454;&#29616;&#32454;&#33410;&#24456;&#37325;&#35201;&#65292;&#26368;&#20339;&#35774;&#35745;&#20915;&#31574;&#21487;&#33021;&#19982;&#20856;&#22411;&#30340;&#25991;&#26412;&#21040;&#22270;&#20687;&#27169;&#22411;&#26377;&#24456;&#22823;&#19981;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the tremendous success of diffusion generative models in text-to-image generation, replicating this success in the domain of image compression has proven difficult. In this paper, we demonstrate that diffusion can significantly improve perceptual quality at a given bit-rate, outperforming state-of-the-art approaches PO-ELIC and HiFiC as measured by FID score. This is achieved using a simple but theoretically motivated two-stage approach combining an autoencoder targeting MSE followed by a further score-based decoder. However, as we will show, implementation details matter and the optimal design decisions can differ greatly from typical text-to-image models.
&lt;/p&gt;</description></item></channel></rss>