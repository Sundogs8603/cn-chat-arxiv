<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#20219;&#21153;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21516;&#26102;&#35299;&#20915;&#20102;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#21644;&#20984;&#32452;&#21512;&#26435;&#37325;&#23398;&#20064;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#22238;&#24402;&#20998;&#25903;&#23398;&#20064;&#26435;&#37325;&#21644;&#20998;&#31867;&#20998;&#25903;&#36873;&#25321;&#20855;&#26377;&#22810;&#26679;&#24615;&#30340;&#39044;&#27979;&#26041;&#27861;&#65292;&#25552;&#39640;&#20102;&#22522;&#20110;&#29305;&#24449;&#30340;&#39044;&#27979;&#30340;&#31934;&#30830;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.20545</link><description>&lt;p&gt;
&#22810;&#20219;&#21153;&#23398;&#20064;&#20984;&#32452;&#21512;&#39044;&#27979;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Multi-task learning of convex combinations of forecasting models. (arXiv:2310.20545v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20545
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#20219;&#21153;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21516;&#26102;&#35299;&#20915;&#20102;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#21644;&#20984;&#32452;&#21512;&#26435;&#37325;&#23398;&#20064;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#22238;&#24402;&#20998;&#25903;&#23398;&#20064;&#26435;&#37325;&#21644;&#20998;&#31867;&#20998;&#25903;&#36873;&#25321;&#20855;&#26377;&#22810;&#26679;&#24615;&#30340;&#39044;&#27979;&#26041;&#27861;&#65292;&#25552;&#39640;&#20102;&#22522;&#20110;&#29305;&#24449;&#30340;&#39044;&#27979;&#30340;&#31934;&#30830;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#32452;&#21512;&#28041;&#21450;&#20351;&#29992;&#22810;&#20010;&#39044;&#27979;&#26469;&#21019;&#24314;&#21333;&#19968;&#12289;&#26356;&#31934;&#30830;&#30340;&#39044;&#27979;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#29305;&#24449;&#30340;&#39044;&#27979;&#24050;&#34987;&#29992;&#20110;&#36873;&#25321;&#26368;&#21512;&#36866;&#30340;&#39044;&#27979;&#27169;&#22411;&#25110;&#23398;&#20064;&#23427;&#20204;&#30340;&#20984;&#32452;&#21512;&#26435;&#37325;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21516;&#26102;&#35299;&#20915;&#36825;&#20004;&#20010;&#38382;&#39064;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#65292;&#20854;&#20013;&#21253;&#25324;&#20004;&#20010;&#20998;&#25903;&#65306;&#22238;&#24402;&#20998;&#25903;&#36890;&#36807;&#26368;&#23567;&#21270;&#32452;&#21512;&#39044;&#27979;&#35823;&#24046;&#26469;&#23398;&#20064;&#21508;&#31181;&#39044;&#27979;&#26041;&#27861;&#30340;&#26435;&#37325;&#65292;&#20998;&#31867;&#20998;&#25903;&#21017;&#37325;&#28857;&#36873;&#25321;&#22810;&#26679;&#24615;&#30340;&#39044;&#27979;&#26041;&#27861;&#12290;&#20026;&#20102;&#20026;&#20998;&#31867;&#20219;&#21153;&#29983;&#25104;&#35757;&#32451;&#26631;&#31614;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#20248;&#21270;&#39537;&#21160;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#30830;&#23450;&#32473;&#23450;&#26102;&#38388;&#24207;&#21015;&#30340;&#26368;&#21512;&#36866;&#30340;&#26041;&#27861;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#25581;&#31034;&#20102;&#22522;&#20110;&#29305;&#24449;&#30340;&#39044;&#27979;&#20013;&#22810;&#26679;&#24615;&#30340;&#37325;&#35201;&#20316;&#29992;&#65292;&#24182;&#20984;&#26174;&#20102;&#27169;&#22411;&#32452;&#21512;&#21644;&#36873;&#25321;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Forecast combination involves using multiple forecasts to create a single, more accurate prediction. Recently, feature-based forecasting has been employed to either select the most appropriate forecasting models or to learn the weights of their convex combination. In this paper, we present a multi-task learning methodology that simultaneously addresses both problems. This approach is implemented through a deep neural network with two branches: the regression branch, which learns the weights of various forecasting methods by minimizing the error of combined forecasts, and the classification branch, which selects forecasting methods with an emphasis on their diversity. To generate training labels for the classification task, we introduce an optimization-driven approach that identifies the most appropriate methods for a given time series. The proposed approach elicits the essential role of diversity in feature-based forecasting and highlights the interplay between model combination and mo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#29983;&#25104;&#27169;&#22411;&#22312;&#28151;&#21512;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#23545;&#31283;&#23450;&#24615;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#35777;&#26126;&#21021;&#22987;&#29983;&#25104;&#27169;&#22411;&#36275;&#22815;&#25509;&#36817;&#25968;&#25454;&#20998;&#24067;&#24182;&#19988;&#25968;&#25454;&#27604;&#20363;&#36866;&#24403;&#65292;&#36845;&#20195;&#35757;&#32451;&#26159;&#31283;&#23450;&#30340;&#12290;</title><link>http://arxiv.org/abs/2310.00429</link><description>&lt;p&gt;
&#20851;&#20110;&#29983;&#25104;&#27169;&#22411;&#22312;&#20854;&#33258;&#24049;&#30340;&#25968;&#25454;&#19978;&#36845;&#20195;&#35757;&#32451;&#30340;&#31283;&#23450;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Stability of Iterative Retraining of Generative Models on their own Data. (arXiv:2310.00429v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00429
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#29983;&#25104;&#27169;&#22411;&#22312;&#28151;&#21512;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#23545;&#31283;&#23450;&#24615;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#35777;&#26126;&#21021;&#22987;&#29983;&#25104;&#27169;&#22411;&#36275;&#22815;&#25509;&#36817;&#25968;&#25454;&#20998;&#24067;&#24182;&#19988;&#25968;&#25454;&#27604;&#20363;&#36866;&#24403;&#65292;&#36845;&#20195;&#35757;&#32451;&#26159;&#31283;&#23450;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#22312;&#24314;&#27169;&#22797;&#26434;&#25968;&#25454;&#26041;&#38754;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#36827;&#23637;&#65292;&#24448;&#24448;&#23637;&#29616;&#20986;&#36229;&#36807;&#20856;&#22411;&#20154;&#31867;&#33021;&#21147;&#30340;&#26679;&#26412;&#30495;&#23454;&#24615;&#36776;&#21035;&#33021;&#21147;&#12290;&#36825;&#19968;&#25104;&#21151;&#30340;&#20851;&#38190;&#39537;&#21160;&#21147;&#26080;&#30097;&#26159;&#36825;&#20123;&#27169;&#22411;&#28040;&#32791;&#28023;&#37327;&#32593;&#32476;&#35268;&#27169;&#25968;&#25454;&#30340;&#32467;&#26524;&#12290;&#30001;&#20110;&#36825;&#20123;&#27169;&#22411;&#24778;&#20154;&#30340;&#24615;&#33021;&#21644;&#26131;&#24471;&#24615;&#65292;&#32593;&#32476;&#19978;&#23558;&#19981;&#21487;&#36991;&#20813;&#22320;&#20986;&#29616;&#36234;&#26469;&#36234;&#22810;&#30340;&#21512;&#25104;&#20869;&#23481;&#12290;&#36825;&#20010;&#20107;&#23454;&#30452;&#25509;&#24847;&#21619;&#30528;&#29983;&#25104;&#27169;&#22411;&#30340;&#26410;&#26469;&#36845;&#20195;&#24517;&#39035;&#38754;&#23545;&#19968;&#20010;&#29616;&#23454;&#65306;&#23427;&#20204;&#30340;&#35757;&#32451;&#25968;&#25454;&#30001;&#28165;&#27905;&#25968;&#25454;&#21644;&#20808;&#21069;&#27169;&#22411;&#29983;&#25104;&#30340;&#20154;&#24037;&#25968;&#25454;&#32452;&#25104;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#26694;&#26550;&#26469;&#23545;&#28151;&#21512;&#25968;&#25454;&#38598;&#65288;&#21253;&#25324;&#30495;&#23454;&#25968;&#25454;&#21644;&#21512;&#25104;&#25968;&#25454;&#65289;&#19978;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#23545;&#31283;&#23450;&#24615;&#30340;&#24433;&#21709;&#36827;&#34892;&#20005;&#26684;&#30740;&#31350;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#22312;&#21021;&#22987;&#29983;&#25104;&#27169;&#22411;&#36275;&#22815;&#22909;&#22320;&#36817;&#20284;&#25968;&#25454;&#20998;&#24067;&#24182;&#19988;&#30495;&#23454;&#25968;&#25454;&#19982;&#21512;&#25104;&#25968;&#25454;&#30340;&#27604;&#20363;&#36866;&#24403;&#30340;&#24773;&#20917;&#19979;&#65292;&#36845;&#20195;&#35757;&#32451;&#30340;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep generative models have made tremendous progress in modeling complex data, often exhibiting generation quality that surpasses a typical human's ability to discern the authenticity of samples. Undeniably, a key driver of this success is enabled by the massive amounts of web-scale data consumed by these models. Due to these models' striking performance and ease of availability, the web will inevitably be increasingly populated with synthetic content. Such a fact directly implies that future iterations of generative models must contend with the reality that their training is curated from both clean data and artificially generated data from past models. In this paper, we develop a framework to rigorously study the impact of training generative models on mixed datasets (of real and synthetic data) on their stability. We first prove the stability of iterative training under the condition that the initial generative models approximate the data distribution well enough and the proportion o
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#20013;&#26399;&#26395;&#20449;&#24687;&#22686;&#30410;&#26799;&#24230;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#20248;&#21270;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#36890;&#36807;&#21518;&#39564;&#26399;&#26395;&#34920;&#31034;&#26469;&#20272;&#35745;&#19982;&#35774;&#35745;&#21464;&#37327;&#30456;&#20851;&#30340;&#26799;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;UEEG-MCMC&#21644;BEEG-AP&#20004;&#31181;&#20272;&#35745;&#26041;&#27861;&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#19981;&#21516;&#30340;&#23454;&#39564;&#35774;&#35745;&#38382;&#39064;&#19978;&#37117;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.09888</link><description>&lt;p&gt;
&#20851;&#20110;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#20013;&#26399;&#26395;&#20449;&#24687;&#22686;&#30410;&#26799;&#24230;&#30340;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
On Estimating the Gradient of the Expected Information Gain in Bayesian Experimental Design. (arXiv:2308.09888v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09888
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#20013;&#26399;&#26395;&#20449;&#24687;&#22686;&#30410;&#26799;&#24230;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#20248;&#21270;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#36890;&#36807;&#21518;&#39564;&#26399;&#26395;&#34920;&#31034;&#26469;&#20272;&#35745;&#19982;&#35774;&#35745;&#21464;&#37327;&#30456;&#20851;&#30340;&#26799;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;UEEG-MCMC&#21644;BEEG-AP&#20004;&#31181;&#20272;&#35745;&#26041;&#27861;&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#19981;&#21516;&#30340;&#23454;&#39564;&#35774;&#35745;&#38382;&#39064;&#19978;&#37117;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#26088;&#22312;&#25214;&#21040;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#26368;&#20339;&#23454;&#39564;&#26465;&#20214;&#65292;&#36890;&#24120;&#34987;&#25551;&#36848;&#20026;&#20248;&#21270;&#26399;&#26395;&#20449;&#24687;&#22686;&#30410;&#65288;EIG&#65289;&#12290;&#20026;&#20102;&#39640;&#25928;&#22320;&#20248;&#21270;EIG&#65292;&#24448;&#24448;&#38656;&#35201;&#26799;&#24230;&#20449;&#24687;&#65292;&#22240;&#27492;&#20272;&#35745;EIG&#30340;&#26799;&#24230;&#33021;&#21147;&#23545;&#20110;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#38382;&#39064;&#33267;&#20851;&#37325;&#35201;&#12290;&#35813;&#24037;&#20316;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#24320;&#21457;&#20272;&#35745;EIG&#26799;&#24230;&#30340;&#26041;&#27861;&#65292;&#32467;&#21512;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#23454;&#29616;EIG&#30340;&#39640;&#25928;&#20248;&#21270;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#20171;&#32461;&#20102;&#19982;&#35774;&#35745;&#21464;&#37327;&#30456;&#20851;&#30340;EIG&#26799;&#24230;&#30340;&#21518;&#39564;&#26399;&#26395;&#34920;&#31034;&#12290;&#22522;&#20110;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#20272;&#35745;EIG&#26799;&#24230;&#30340;&#26041;&#27861;&#65292;UEEG-MCMC&#21033;&#29992;&#36890;&#36807;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#65288;MCMC&#65289;&#29983;&#25104;&#30340;&#21518;&#39564;&#26679;&#26412;&#26469;&#20272;&#35745;EIG&#26799;&#24230;&#65292;&#32780;BEEG-AP&#21017;&#19987;&#27880;&#20110;&#36890;&#36807;&#21453;&#22797;&#20351;&#29992;&#21442;&#25968;&#26679;&#26412;&#26469;&#23454;&#29616;&#39640;&#27169;&#25311;&#25928;&#29575;&#12290;&#29702;&#35770;&#20998;&#26512;&#21644;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#19981;&#21516;&#30340;&#23454;&#39564;&#35774;&#35745;&#38382;&#39064;&#19978;&#37117;&#33021;&#33719;&#24471;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian Experimental Design (BED), which aims to find the optimal experimental conditions for Bayesian inference, is usually posed as to optimize the expected information gain (EIG). The gradient information is often needed for efficient EIG optimization, and as a result the ability to estimate the gradient of EIG is essential for BED problems. The primary goal of this work is to develop methods for estimating the gradient of EIG, which, combined with the stochastic gradient descent algorithms, result in efficient optimization of EIG. Specifically, we first introduce a posterior expected representation of the EIG gradient with respect to the design variables. Based on this, we propose two methods for estimating the EIG gradient, UEEG-MCMC that leverages posterior samples generated through Markov Chain Monte Carlo (MCMC) to estimate the EIG gradient, and BEEG-AP that focuses on achieving high simulation efficiency by repeatedly using parameter samples. Theoretical analysis and numerica
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22238;&#24402;&#20219;&#21153;&#30340;&#24191;&#20041;AuxUE&#26041;&#26696;&#65292;&#30446;&#30340;&#26159;&#23454;&#29616;&#26356;&#40065;&#26834;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35813;&#26041;&#26696;&#36890;&#36807;&#32771;&#34385;&#19981;&#21516;&#30340;&#20998;&#24067;&#20551;&#35774;&#65292;&#36873;&#25321;Laplace&#20998;&#24067;&#26469;&#36817;&#20284;p&#65292;&#20197;&#23454;&#29616;&#26356;&#40065;&#26834;&#30340;&#26412;&#36136;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2308.09065</link><description>&lt;p&gt;
&#36890;&#36807;&#31163;&#25955;&#21270;&#24341;&#21457;&#30340;Dirichlet&#21518;&#39564;&#29992;&#20110;&#22238;&#24402;&#38382;&#39064;&#30340;&#40065;&#26834;&#24615;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Discretization-Induced Dirichlet Posterior for Robust Uncertainty Quantification on Regression. (arXiv:2308.09065v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09065
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22238;&#24402;&#20219;&#21153;&#30340;&#24191;&#20041;AuxUE&#26041;&#26696;&#65292;&#30446;&#30340;&#26159;&#23454;&#29616;&#26356;&#40065;&#26834;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35813;&#26041;&#26696;&#36890;&#36807;&#32771;&#34385;&#19981;&#21516;&#30340;&#20998;&#24067;&#20551;&#35774;&#65292;&#36873;&#25321;Laplace&#20998;&#24067;&#26469;&#36817;&#20284;p&#65292;&#20197;&#23454;&#29616;&#26356;&#40065;&#26834;&#30340;&#26412;&#36136;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#23545;&#20110;&#37096;&#32626;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#33267;&#20851;&#37325;&#35201;&#12290;&#36741;&#21161;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#22120;&#65288;AuxUE&#65289;&#26159;&#19968;&#31181;&#22312;&#19981;&#20462;&#25913;&#20027;&#20219;&#21153;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#20027;&#20219;&#21153;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#26368;&#26377;&#25928;&#25163;&#27573;&#20043;&#19968;&#12290;&#20026;&#20102;&#34987;&#35748;&#20026;&#26159;&#40065;&#26834;&#30340;&#65292;AuxUE&#24517;&#39035;&#33021;&#22815;&#22312;&#36935;&#21040;&#36229;&#20986;&#20998;&#24067;&#33539;&#22260;&#30340;&#36755;&#20837;&#26102;&#20445;&#25345;&#24615;&#33021;&#24182;&#24341;&#21457;&#26356;&#39640;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#21363;&#25552;&#20379;&#40065;&#26834;&#30340;&#26412;&#36136;&#19981;&#30830;&#23450;&#24615;&#21644;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#35270;&#35273;&#22238;&#24402;&#20219;&#21153;&#65292;&#24403;&#21069;&#30340;AuxUE&#35774;&#35745;&#20027;&#35201;&#29992;&#20110;&#26412;&#36136;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#24182;&#19988;&#23578;&#26410;&#25506;&#32034;AuxUE&#30340;&#40065;&#26834;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22238;&#24402;&#20219;&#21153;&#30340;&#26356;&#40065;&#26834;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#24191;&#20041;AuxUE&#26041;&#26696;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#20026;&#20102;&#23454;&#29616;&#26356;&#40065;&#26834;&#30340;&#26412;&#36136;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#22312;&#24322;&#26041;&#24046;&#22122;&#22768;&#26041;&#38754;&#32771;&#34385;&#20102;&#19981;&#21516;&#30340;&#20998;&#24067;&#20551;&#35774;&#65292;&#24182;&#26368;&#32456;&#36873;&#25321;Laplace&#20998;&#24067;&#26469;&#36817;&#20284;p
&lt;/p&gt;
&lt;p&gt;
Uncertainty quantification is critical for deploying deep neural networks (DNNs) in real-world applications. An Auxiliary Uncertainty Estimator (AuxUE) is one of the most effective means to estimate the uncertainty of the main task prediction without modifying the main task model. To be considered robust, an AuxUE must be capable of maintaining its performance and triggering higher uncertainties while encountering Out-of-Distribution (OOD) inputs, i.e., to provide robust aleatoric and epistemic uncertainty. However, for vision regression tasks, current AuxUE designs are mainly adopted for aleatoric uncertainty estimates, and AuxUE robustness has not been explored. In this work, we propose a generalized AuxUE scheme for more robust uncertainty quantification on regression tasks. Concretely, to achieve a more robust aleatoric uncertainty estimation, different distribution assumptions are considered for heteroscedastic noise, and Laplace distribution is finally chosen to approximate the p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22823;&#25968;&#25454;-&#20379;&#24212;&#38142;&#31649;&#29702;&#26694;&#26550;&#65292;&#36890;&#36807;&#25968;&#25454;&#39044;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#23454;&#29616;&#20379;&#24212;&#38142;&#39044;&#27979;&#65292;&#20248;&#21270;&#25805;&#20316;&#31649;&#29702;&#12289;&#36879;&#26126;&#24230;&#65292;&#24182;&#35752;&#35770;&#20102;&#24187;&#24433;&#24211;&#23384;&#23545;&#39044;&#27979;&#30340;&#19981;&#21033;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2307.12971</link><description>&lt;p&gt;
&#22823;&#25968;&#25454;-&#20379;&#24212;&#38142;&#31649;&#29702;&#26694;&#26550;&#30340;&#39044;&#27979;&#65306;&#25968;&#25454;&#39044;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Big Data - Supply Chain Management Framework for Forecasting: Data Preprocessing and Machine Learning Techniques. (arXiv:2307.12971v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12971
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22823;&#25968;&#25454;-&#20379;&#24212;&#38142;&#31649;&#29702;&#26694;&#26550;&#65292;&#36890;&#36807;&#25968;&#25454;&#39044;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#23454;&#29616;&#20379;&#24212;&#38142;&#39044;&#27979;&#65292;&#20248;&#21270;&#25805;&#20316;&#31649;&#29702;&#12289;&#36879;&#26126;&#24230;&#65292;&#24182;&#35752;&#35770;&#20102;&#24187;&#24433;&#24211;&#23384;&#23545;&#39044;&#27979;&#30340;&#19981;&#21033;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#31995;&#32479;&#22320;&#35782;&#21035;&#21644;&#27604;&#36739;&#20998;&#26512;&#26368;&#20808;&#36827;&#30340;&#20379;&#24212;&#38142;&#39044;&#27979;&#31574;&#30053;&#21644;&#25216;&#26415;&#12290;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#23558;&#22823;&#25968;&#25454;&#20998;&#26512;&#24212;&#29992;&#20110;&#20379;&#24212;&#38142;&#31649;&#29702;&#20013;&#65292;&#21253;&#25324;&#38382;&#39064;&#35782;&#21035;&#12289;&#25968;&#25454;&#26469;&#28304;&#12289;&#25506;&#32034;&#24615;&#25968;&#25454;&#20998;&#26512;&#12289;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#35757;&#32451;&#12289;&#36229;&#21442;&#25968;&#35843;&#20248;&#12289;&#24615;&#33021;&#35780;&#20272;&#21644;&#20248;&#21270;&#65292;&#20197;&#21450;&#39044;&#27979;&#23545;&#20154;&#21147;&#12289;&#24211;&#23384;&#21644;&#25972;&#20010;&#20379;&#24212;&#38142;&#30340;&#24433;&#21709;&#12290;&#39318;&#20808;&#35752;&#35770;&#20102;&#26681;&#25454;&#20379;&#24212;&#38142;&#31574;&#30053;&#25910;&#38598;&#25968;&#25454;&#30340;&#38656;&#27714;&#20197;&#21450;&#22914;&#20309;&#25910;&#38598;&#25968;&#25454;&#12290;&#25991;&#31456;&#35752;&#35770;&#20102;&#26681;&#25454;&#21608;&#26399;&#25110;&#20379;&#24212;&#38142;&#30446;&#26631;&#38656;&#35201;&#19981;&#21516;&#31867;&#22411;&#30340;&#39044;&#27979;&#12290;&#25512;&#33616;&#20351;&#29992;&#20379;&#24212;&#38142;&#32489;&#25928;&#25351;&#26631;&#21644;&#35823;&#24046;&#27979;&#37327;&#31995;&#32479;&#26469;&#20248;&#21270;&#34920;&#29616;&#26368;&#20339;&#30340;&#27169;&#22411;&#12290;&#36824;&#35752;&#35770;&#20102;&#24187;&#24433;&#24211;&#23384;&#23545;&#39044;&#27979;&#30340;&#19981;&#21033;&#24433;&#21709;&#20197;&#21450;&#31649;&#29702;&#20915;&#31574;&#20381;&#36182;&#20379;&#24212;&#38142;&#32489;&#25928;&#25351;&#26631;&#26469;&#30830;&#23450;&#27169;&#22411;&#24615;&#33021;&#21442;&#25968;&#21644;&#25913;&#36827;&#36816;&#33829;&#31649;&#29702;&#12289;&#36879;&#26126;&#24230;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article intends to systematically identify and comparatively analyze state-of-the-art supply chain (SC) forecasting strategies and technologies. A novel framework has been proposed incorporating Big Data Analytics in SC Management (problem identification, data sources, exploratory data analysis, machine-learning model training, hyperparameter tuning, performance evaluation, and optimization), forecasting effects on human-workforce, inventory, and overall SC. Initially, the need to collect data according to SC strategy and how to collect them has been discussed. The article discusses the need for different types of forecasting according to the period or SC objective. The SC KPIs and the error-measurement systems have been recommended to optimize the top-performing model. The adverse effects of phantom inventory on forecasting and the dependence of managerial decisions on the SC KPIs for determining model performance parameters and improving operations management, transparency, and 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#24555;&#36895;&#28151;&#21512;&#39532;&#23572;&#21487;&#22827;&#38142;&#20013;&#23454;&#29616;&#26679;&#26412;&#39640;&#25928;&#30340;&#24191;&#20041;&#24471;&#20998;&#21305;&#37197;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#24471;&#20998;&#21305;&#37197;&#31639;&#27861;&#22312;&#20855;&#26377;&#36739;&#24046;&#31561;&#21608;&#24615;&#36136;&#30340;&#20998;&#24067;&#19978;&#30340;&#32479;&#35745;&#20195;&#20215;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.09332</link><description>&lt;p&gt;
Fit Like You Sample: &#20174;&#24555;&#36895;&#28151;&#21512;&#39532;&#23572;&#21487;&#22827;&#38142;&#20013;&#23454;&#29616;&#26679;&#26412;&#39640;&#25928;&#30340;&#24191;&#20041;&#24471;&#20998;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Fit Like You Sample: Sample-Efficient Generalized Score Matching from Fast Mixing Markov Chains. (arXiv:2306.09332v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09332
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#24555;&#36895;&#28151;&#21512;&#39532;&#23572;&#21487;&#22827;&#38142;&#20013;&#23454;&#29616;&#26679;&#26412;&#39640;&#25928;&#30340;&#24191;&#20041;&#24471;&#20998;&#21305;&#37197;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#24471;&#20998;&#21305;&#37197;&#31639;&#27861;&#22312;&#20855;&#26377;&#36739;&#24046;&#31561;&#21608;&#24615;&#36136;&#30340;&#20998;&#24067;&#19978;&#30340;&#32479;&#35745;&#20195;&#20215;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24471;&#20998;&#21305;&#37197;&#26159;&#19968;&#31181;&#23398;&#20064;&#27010;&#29575;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#20854;&#21442;&#25968;&#21270;&#20026;&#27604;&#20363;&#24120;&#25968;&#65288;&#20363;&#22914;&#65292;&#33021;&#37327;&#22522;&#27169;&#22411;&#65289;&#12290;&#20854;&#24605;&#24819;&#26159;&#25311;&#21512;&#20998;&#24067;&#30340;&#24471;&#20998;&#65292;&#32780;&#19981;&#26159;&#20284;&#28982;&#20989;&#25968;&#65292;&#20174;&#32780;&#36991;&#20813;&#35780;&#20272;&#27604;&#20363;&#24120;&#25968;&#30340;&#38656;&#27714;&#12290;&#34429;&#28982;&#36825;&#20855;&#26377;&#26126;&#26174;&#30340;&#31639;&#27861;&#20248;&#21183;&#65292;&#20294;&#32479;&#35745;&#20195;&#20215;&#21487;&#33021;&#24456;&#39640;&#65306;Koehler&#31561;&#20154;&#30340;&#26368;&#26032;&#24037;&#20316;&#34920;&#26126;&#65292;&#23545;&#20110;&#20855;&#26377;&#36739;&#24046;&#31561;&#21608;&#24615;&#36136;&#65288;&#36739;&#22823;&#30340;Poincare&#25110;&#23545;&#25968;Sobolev&#24120;&#25968;&#65289;&#30340;&#20998;&#24067;&#65292;&#24471;&#20998;&#21305;&#37197;&#30340;&#32479;&#35745;&#25928;&#29575;&#26126;&#26174;&#20302;&#20110;&#26497;&#22823;&#20284;&#28982;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#33258;&#28982;&#23454;&#38469;&#30340;&#20998;&#24067;&#65292;&#20363;&#22914;&#19968;&#32500;&#20013;&#30340;&#20004;&#20010;&#39640;&#26031;&#20998;&#24067;&#28151;&#21512;&#29289;&#31561;&#22810;&#23792;&#20998;&#24067;&#65292;&#20855;&#26377;&#36739;&#24046;&#30340;Poincar&#233;&#24120;&#25968;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20219;&#24847;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#30340;&#28151;&#21512;&#26102;&#38388;&#19982;&#35797;&#22270;&#25311;&#21512;$\frac{\mathcal{O} p}{p}$&#30340;&#24191;&#20041;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#20043;&#38388;&#30340;&#23494;&#20999;&#20851;&#31995;&#12290;&#22914;&#26524;$\mathcal{L}$&#30340;&#29305;&#24449;&#21521;&#37327;&#19981;&#20381;&#36182;&#20110;$p$&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#31639;&#27861;&#65292;&#20174;&#32780;&#23454;&#29616;&#30340;&#26679;&#26412;&#39640;&#25928;&#24191;&#20041;&#24471;&#20998;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score matching is an approach to learning probability distributions parametrized up to a constant of proportionality (e.g. Energy-Based Models). The idea is to fit the score of the distribution, rather than the likelihood, thus avoiding the need to evaluate the constant of proportionality. While there's a clear algorithmic benefit, the statistical "cost'' can be steep: recent work by Koehler et al. 2022 showed that for distributions that have poor isoperimetric properties (a large Poincar\'e or log-Sobolev constant), score matching is substantially statistically less efficient than maximum likelihood. However, many natural realistic distributions, e.g. multimodal distributions as simple as a mixture of two Gaussians in one dimension -- have a poor Poincar\'e constant.  In this paper, we show a close connection between the mixing time of an arbitrary Markov process with generator $\mathcal{L}$ and a generalized score matching loss that tries to fit $\frac{\mathcal{O} p}{p}$. If $\mathca
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#24322;&#26500;&#32676;&#20307;&#24378;&#21270;&#23398;&#20064;&#20013;&#32852;&#37030;Q&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20445;&#35777;&#65292;&#35752;&#35770;&#20102;&#21516;&#27493;&#21644;&#24322;&#27493;&#29256;&#26412;&#30340;&#32447;&#24615;&#21152;&#36895;&#65292;&#21516;&#26102;&#25506;&#31350;&#20102;&#31561;&#26435;&#37325;&#24179;&#22343;&#26412;&#22320;Q&#20272;&#35745;&#30340;&#32570;&#38519;&#12290;</title><link>http://arxiv.org/abs/2305.10697</link><description>&lt;p&gt;
&#24322;&#26500;&#32676;&#20307;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#31119;&#38899;&#65306;&#32447;&#24615;&#21152;&#36895;&#21644;&#26356;&#22810;&#21487;&#33021;
&lt;/p&gt;
&lt;p&gt;
The Blessing of Heterogeneity in Federated Q-learning: Linear Speedup and Beyond. (arXiv:2305.10697v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10697
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#24322;&#26500;&#32676;&#20307;&#24378;&#21270;&#23398;&#20064;&#20013;&#32852;&#37030;Q&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20445;&#35777;&#65292;&#35752;&#35770;&#20102;&#21516;&#27493;&#21644;&#24322;&#27493;&#29256;&#26412;&#30340;&#32447;&#24615;&#21152;&#36895;&#65292;&#21516;&#26102;&#25506;&#31350;&#20102;&#31561;&#26435;&#37325;&#24179;&#22343;&#26412;&#22320;Q&#20272;&#35745;&#30340;&#32570;&#38519;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#30340;&#25968;&#25454;&#30001;&#22810;&#20010;&#20195;&#29702;&#20197;&#20998;&#24067;&#24335;&#26041;&#24335;&#25910;&#38598;&#26102;&#65292;&#32852;&#37030;RL&#31639;&#27861;&#20801;&#35768;&#21327;&#20316;&#23398;&#20064;&#65292;&#26080;&#38656;&#20849;&#20139;&#26412;&#22320;&#25968;&#25454;&#12290;&#26412;&#25991;&#32771;&#34385;&#32852;&#37030;Q&#23398;&#20064;&#65292;&#20854;&#30446;&#30340;&#26159;&#36890;&#36807;&#23450;&#26399;&#32858;&#21512;&#20165;&#22312;&#26412;&#22320;&#25968;&#25454;&#19978;&#35757;&#32451;&#30340;&#26412;&#22320;Q&#20272;&#35745;&#26469;&#23398;&#20064;&#26368;&#20248;Q&#20989;&#25968;&#12290;&#38024;&#23545;&#26080;&#38480;&#26102;&#38388;&#33976;&#39311;&#26631;&#35760;&#20915;&#31574;&#36807;&#31243;&#65292;&#25105;&#20204;&#20026;&#21516;&#27493;&#21644;&#24322;&#27493;&#29256;&#26412;&#30340;&#32852;&#37030;Q&#23398;&#20064;&#25552;&#20379;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#20445;&#35777;&#12290;&#22312;&#20004;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#23637;&#31034;&#20102;&#19982;&#20195;&#29702;&#25968;&#37327;&#25104;&#32447;&#24615;&#21152;&#36895;&#20197;&#21450;&#20854;&#20182;&#26174;&#33879;&#38382;&#39064;&#21442;&#25968;&#30340;&#26356;&#23574;&#38160;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#30340;&#32852;&#37030;Q&#23398;&#20064;&#26041;&#27861;&#37319;&#29992;&#31561;&#26435;&#37325;&#24179;&#22343;&#26412;&#22320;Q&#20272;&#35745;&#65292;&#36825;&#22312;&#24322;&#27493;&#35774;&#32622;&#20013;&#21487;&#33021;&#20250;&#39640;&#24230;&#27425;&#20248;&#65292;&#22240;&#20026;&#30001;&#20110;&#19981;&#21516;&#30340;&#26412;&#22320;&#34892;&#20026;&#31574;&#30053;&#65292;&#26412;&#22320;&#36712;&#36857;&#21487;&#33021;&#39640;&#24230;&#24322;&#26500;&#12290;&#29616;&#26377;&#30340;&#26679;&#26412;&#26368;&#20248;&#21270;&#31574;&#30053;&#22312;&#24322;&#27493;&#35774;&#32622;&#20013;&#23384;&#22312;&#24040;&#22823;&#32570;&#38519;&#12290;
&lt;/p&gt;
&lt;p&gt;
When the data used for reinforcement learning (RL) are collected by multiple agents in a distributed manner, federated versions of RL algorithms allow collaborative learning without the need of sharing local data. In this paper, we consider federated Q-learning, which aims to learn an optimal Q-function by periodically aggregating local Q-estimates trained on local data alone. Focusing on infinite-horizon tabular Markov decision processes, we provide sample complexity guarantees for both the synchronous and asynchronous variants of federated Q-learning. In both cases, our bounds exhibit a linear speedup with respect to the number of agents and sharper dependencies on other salient problem parameters. Moreover, existing approaches to federated Q-learning adopt an equally-weighted averaging of local Q-estimates, which can be highly sub-optimal in the asynchronous setting since the local trajectories can be highly heterogeneous due to different local behavior policies. Existing sample com
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#24341;&#23548;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#37319;&#29992;&#24191;&#20041;&#36125;&#21494;&#26031;&#31639;&#27861;&#36827;&#34892;&#28151;&#21512;&#31227;&#21160;&#24179;&#22343;&#22330;&#24341;&#23548;&#30340;&#26102;&#31354;&#25968;&#25454;&#24314;&#27169;&#65292;&#21487;&#20197;&#36827;&#34892;&#22240;&#26524;&#26410;&#26469;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2301.00736</link><description>&lt;p&gt;
&#28151;&#21512;&#31227;&#21160;&#24179;&#22343;&#22330;&#24341;&#23548;&#30340;&#26102;&#31354;&#25968;&#25454;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Mixed moving average field guided learning for spatio-temporal data. (arXiv:2301.00736v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.00736
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#24341;&#23548;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#37319;&#29992;&#24191;&#20041;&#36125;&#21494;&#26031;&#31639;&#27861;&#36827;&#34892;&#28151;&#21512;&#31227;&#21160;&#24179;&#22343;&#22330;&#24341;&#23548;&#30340;&#26102;&#31354;&#25968;&#25454;&#24314;&#27169;&#65292;&#21487;&#20197;&#36827;&#34892;&#22240;&#26524;&#26410;&#26469;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#21040;&#28151;&#21512;&#31227;&#21160;&#24179;&#22343;&#22330;&#30340;&#24433;&#21709;&#65292;&#26102;&#31354;&#25968;&#25454;&#30340;&#24314;&#27169;&#26159;&#19968;&#20010;&#22810;&#21151;&#33021;&#30340;&#25216;&#24039;&#12290;&#20294;&#26159;&#65292;&#23427;&#20204;&#30340;&#39044;&#27979;&#20998;&#24067;&#36890;&#24120;&#19981;&#21487;&#35775;&#38382;&#12290;&#22312;&#36825;&#20010;&#24314;&#27169;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#23450;&#20041;&#20102;&#19968;&#31181;&#26032;&#30340;&#29702;&#35770;&#24341;&#23548;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#37319;&#29992;&#24191;&#20041;&#36125;&#21494;&#26031;&#31639;&#27861;&#36827;&#34892;&#39044;&#27979;&#12290;&#25105;&#20204;&#37319;&#29992;Lipschitz&#39044;&#27979;&#22120;&#65288;&#20363;&#22914;&#32447;&#24615;&#27169;&#22411;&#25110;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#65289;&#65292;&#24182;&#36890;&#36807;&#26368;&#23567;&#21270;&#27839;&#31354;&#38388;&#21644;&#26102;&#38388;&#32500;&#24230;&#20018;&#34892;&#30456;&#20851;&#30340;&#25968;&#25454;&#30340;&#26032;&#22411;PAC&#36125;&#21494;&#26031;&#30028;&#38480;&#26469;&#30830;&#23450;&#19968;&#20010;&#38543;&#26426;&#20272;&#35745;&#20540;&#12290;&#36827;&#34892;&#22240;&#26524;&#26410;&#26469;&#39044;&#27979;&#26159;&#25105;&#20204;&#26041;&#27861;&#30340;&#19968;&#20010;&#20142;&#28857;&#65292;&#22240;&#20026;&#23427;&#36866;&#29992;&#20110;&#20855;&#26377;&#30701;&#26399;&#21644;&#38271;&#26399;&#30456;&#20851;&#24615;&#30340;&#25968;&#25454;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#23637;&#31034;&#32447;&#24615;&#39044;&#27979;&#22120;&#21644;&#27169;&#25311;STOU&#36807;&#31243;&#30340;&#26102;&#31354;&#25968;&#25454;&#30340;&#31034;&#20363;&#26469;&#23637;&#31034;&#23398;&#20064;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Influenced mixed moving average fields are a versatile modeling class for spatio-temporal data. However, their predictive distribution is not generally accessible. Under this modeling assumption, we define a novel theory-guided machine learning approach that employs a generalized Bayesian algorithm to make predictions. We employ a Lipschitz predictor, for example, a linear model or a feed-forward neural network, and determine a randomized estimator by minimizing a novel PAC Bayesian bound for data serially correlated along a spatial and temporal dimension. Performing causal future predictions is a highlight of our methodology as its potential application to data with short and long-range dependence. We conclude by showing the performance of the learning methodology in an example with linear predictors and simulated spatio-temporal data from an STOU process.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#38543;&#26426;Kaczmarz&#31639;&#27861;&#65292;&#20351;&#29992;&#23567;&#25209;&#37327;&#21644;&#37325;&#29699;&#21160;&#37327;&#36827;&#34892;&#21152;&#36895;&#65292;&#22312;&#20108;&#27425;&#20248;&#21270;&#38382;&#39064;&#20013;&#20445;&#25345;&#24555;&#36895;&#25910;&#25947;&#29575;&#12290;</title><link>http://arxiv.org/abs/2206.07553</link><description>&lt;p&gt;
&#35770;&#23567;&#25209;&#37327;&#37325;&#29699;&#21160;&#37327;&#27861;&#30340;&#24555;&#36895;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the fast convergence of minibatch heavy ball momentum. (arXiv:2206.07553v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.07553
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#38543;&#26426;Kaczmarz&#31639;&#27861;&#65292;&#20351;&#29992;&#23567;&#25209;&#37327;&#21644;&#37325;&#29699;&#21160;&#37327;&#36827;&#34892;&#21152;&#36895;&#65292;&#22312;&#20108;&#27425;&#20248;&#21270;&#38382;&#39064;&#20013;&#20445;&#25345;&#24555;&#36895;&#25910;&#25947;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31616;&#21333;&#30340;&#38543;&#26426;&#21160;&#37327;&#26041;&#27861;&#34987;&#24191;&#27867;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#20248;&#21270;&#20013;&#65292;&#20294;&#30001;&#20110;&#36824;&#27809;&#26377;&#21152;&#36895;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#36825;&#19982;&#23427;&#20204;&#22312;&#23454;&#36341;&#20013;&#30340;&#33391;&#22909;&#24615;&#33021;&#24182;&#19981;&#30456;&#31526;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#23637;&#31034;&#65292;&#38543;&#26426;&#37325;&#29699;&#21160;&#37327;&#22312;&#20108;&#27425;&#26368;&#20248;&#21270;&#38382;&#39064;&#20013;&#20445;&#25345;&#65288;&#30830;&#23450;&#24615;&#65289;&#37325;&#29699;&#21160;&#37327;&#30340;&#24555;&#36895;&#32447;&#24615;&#29575;&#65292;&#33267;&#23569;&#22312;&#20351;&#29992;&#36275;&#22815;&#22823;&#30340;&#25209;&#37327;&#22823;&#23567;&#36827;&#34892;&#23567;&#25209;&#37327;&#22788;&#29702;&#26102;&#12290;&#25105;&#20204;&#25152;&#30740;&#31350;&#30340;&#31639;&#27861;&#21487;&#20197;&#34987;&#35299;&#37322;&#20026;&#24102;&#23567;&#25209;&#37327;&#22788;&#29702;&#21644;&#37325;&#29699;&#21160;&#37327;&#30340;&#21152;&#36895;&#38543;&#26426;Kaczmarz&#31639;&#27861;&#12290;&#35813;&#20998;&#26512;&#20381;&#36182;&#20110;&#20180;&#32454;&#20998;&#35299;&#21160;&#37327;&#36716;&#31227;&#30697;&#38453;&#65292;&#24182;&#20351;&#29992;&#26032;&#30340;&#29420;&#31435;&#38543;&#26426;&#30697;&#38453;&#20056;&#31215;&#30340;&#35889;&#33539;&#22260;&#38598;&#20013;&#30028;&#38480;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#25968;&#20540;&#28436;&#31034;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#30028;&#38480;&#30456;&#24403;&#23574;&#38160;&#12290;
&lt;/p&gt;
&lt;p&gt;
Simple stochastic momentum methods are widely used in machine learning optimization, but their good practical performance is at odds with an absence of theoretical guarantees of acceleration in the literature. In this work, we aim to close the gap between theory and practice by showing that stochastic heavy ball momentum retains the fast linear rate of (deterministic) heavy ball momentum on quadratic optimization problems, at least when minibatching with a sufficiently large batch size. The algorithm we study can be interpreted as an accelerated randomized Kaczmarz algorithm with minibatching and heavy ball momentum. The analysis relies on carefully decomposing the momentum transition matrix, and using new spectral norm concentration bounds for products of independent random matrices. We provide numerical illustrations demonstrating that our bounds are reasonably sharp.
&lt;/p&gt;</description></item></channel></rss>