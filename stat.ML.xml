<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#12298;&#26469;&#33258;&#24425;&#31080;&#31080;&#38598;&#25104;&#30340;&#31070;&#32463;&#35268;&#27169;&#23450;&#24459;&#12299;&#36890;&#36807;&#30740;&#31350;&#31070;&#32463;&#35268;&#27169;&#23450;&#24459;&#29616;&#35937;&#65292;&#21457;&#29616;&#20854;&#19982;&#24425;&#31080;&#31080;&#38598;&#25104;&#26377;&#20851;&#65292;&#20174;&#32780;&#24418;&#25104;&#20102;&#26032;&#30340;&#32553;&#25918;&#23450;&#24459;&#65292;&#20855;&#26377;&#28508;&#22312;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.02258</link><description>&lt;p&gt;
&#12298;&#26469;&#33258;&#24425;&#31080;&#31080;&#38598;&#25104;&#30340;&#31070;&#32463;&#35268;&#27169;&#23450;&#24459;&#12299;
&lt;/p&gt;
&lt;p&gt;
A Neural Scaling Law from Lottery Ticket Ensembling. (arXiv:2310.02258v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02258
&lt;/p&gt;
&lt;p&gt;
&#12298;&#26469;&#33258;&#24425;&#31080;&#31080;&#38598;&#25104;&#30340;&#31070;&#32463;&#35268;&#27169;&#23450;&#24459;&#12299;&#36890;&#36807;&#30740;&#31350;&#31070;&#32463;&#35268;&#27169;&#23450;&#24459;&#29616;&#35937;&#65292;&#21457;&#29616;&#20854;&#19982;&#24425;&#31080;&#31080;&#38598;&#25104;&#26377;&#20851;&#65292;&#20174;&#32780;&#24418;&#25104;&#20102;&#26032;&#30340;&#32553;&#25918;&#23450;&#24459;&#65292;&#20855;&#26377;&#28508;&#22312;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#35268;&#27169;&#23450;&#24459;&#65288;NSL&#65289;&#25351;&#30340;&#26159;&#27169;&#22411;&#24615;&#33021;&#38543;&#30528;&#35268;&#27169;&#22686;&#21152;&#32780;&#25552;&#39640;&#30340;&#29616;&#35937;&#12290;Sharma&#65286;Kaplan&#20351;&#29992;&#36817;&#20284;&#29702;&#35770;&#20998;&#26512;&#20102;NSL&#65292;&#24182;&#39044;&#27979;&#20102;MSE&#25439;&#22833;&#30340;&#34928;&#20943;&#26041;&#24335;&#20026;$N^{-\alpha}$&#65292;&#20854;&#20013;$\alpha=4/d$&#65292;$N$&#20026;&#27169;&#22411;&#21442;&#25968;&#25968;&#37327;&#65292;$d$&#20026;&#20869;&#22312;&#36755;&#20837;&#32500;&#24230;&#12290;&#23613;&#31649;&#20182;&#20204;&#30340;&#29702;&#35770;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#25928;&#26524;&#33391;&#22909;&#65288;&#20363;&#22914;ReLU&#32593;&#32476;&#65289;&#65292;&#20294;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#31616;&#21333;&#30340;1D&#38382;&#39064;$y=x^2$&#20013;&#65292;&#34920;&#29616;&#20986;&#20102;&#19982;&#20182;&#20204;&#39044;&#27979;&#19981;&#21516;&#30340;&#32553;&#25918;&#23450;&#24459;&#65288;$\alpha=1$&#32780;&#19981;&#26159;$\alpha=4$&#65289;&#12290;&#25105;&#20204;&#25171;&#24320;&#20102;&#31070;&#32463;&#32593;&#32476;&#24182;&#21457;&#29616;&#26032;&#30340;&#32553;&#25918;&#23450;&#24459;&#28304;&#20110;&#24425;&#31080;&#31080;&#38598;&#25104;&#65306;&#24179;&#22343;&#32780;&#35328;&#65292;&#26356;&#23485;&#30340;&#32593;&#32476;&#26377;&#26356;&#22810;&#30340;&#8220;&#24425;&#31080;&#31080;&#8221;&#65292;&#23427;&#20204;&#34987;&#38598;&#25104;&#26469;&#20943;&#23567;&#36755;&#20986;&#30340;&#26041;&#24046;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#21333;&#20010;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#26426;&#26800;&#35299;&#37322;&#20197;&#21450;&#23545;&#23427;&#20204;&#36827;&#34892;&#32479;&#35745;&#30740;&#31350;&#26469;&#25903;&#25345;&#38598;&#25104;&#26426;&#21046;&#12290;&#25105;&#20204;&#23558;$N^{-1}$&#30340;&#32553;&#25918;&#23450;&#24459;&#24402;&#22240;&#20110;&#8220;&#24425;&#31080;&#31080;&#30340;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#8221;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#23427;&#30340;&#28508;&#22312;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural scaling laws (NSL) refer to the phenomenon where model performance improves with scale. Sharma &amp; Kaplan analyzed NSL using approximation theory and predict that MSE losses decay as $N^{-\alpha}$, $\alpha=4/d$, where $N$ is the number of model parameters, and $d$ is the intrinsic input dimension. Although their theory works well for some cases (e.g., ReLU networks), we surprisingly find that a simple 1D problem $y=x^2$ manifests a different scaling law ($\alpha=1$) from their predictions ($\alpha=4$). We opened the neural networks and found that the new scaling law originates from lottery ticket ensembling: a wider network on average has more "lottery tickets", which are ensembled to reduce the variance of outputs. We support the ensembling mechanism by mechanistically interpreting single neural networks, as well as studying them statistically. We attribute the $N^{-1}$ scaling law to the "central limit theorem" of lottery tickets. Finally, we discuss its potential implications f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#19968;&#31995;&#21015;&#32447;&#24615;&#31995;&#32479;&#23454;&#20363;&#20013;&#35774;&#32622;&#27714;&#35299;&#22120;&#21442;&#25968;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#36873;&#25321;&#21442;&#25968;&#65292;&#21487;&#20197;&#25509;&#36817;&#26368;&#20339;&#24635;&#36845;&#20195;&#27425;&#25968;&#30340;&#24615;&#33021;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#39069;&#22806;&#30340;&#30697;&#38453;&#35745;&#31639;&#12290;</title><link>http://arxiv.org/abs/2310.02246</link><description>&lt;p&gt;
&#23398;&#20064;&#25918;&#26494;&#65306;&#22312;&#19968;&#31995;&#21015;&#32447;&#24615;&#31995;&#32479;&#23454;&#20363;&#20013;&#35774;&#32622;&#27714;&#35299;&#22120;&#21442;&#25968;
&lt;/p&gt;
&lt;p&gt;
Learning to Relax: Setting Solver Parameters Across a Sequence of Linear System Instances. (arXiv:2310.02246v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02246
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#19968;&#31995;&#21015;&#32447;&#24615;&#31995;&#32479;&#23454;&#20363;&#20013;&#35774;&#32622;&#27714;&#35299;&#22120;&#21442;&#25968;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#36873;&#25321;&#21442;&#25968;&#65292;&#21487;&#20197;&#25509;&#36817;&#26368;&#20339;&#24635;&#36845;&#20195;&#27425;&#25968;&#30340;&#24615;&#33021;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#39069;&#22806;&#30340;&#30697;&#38453;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#20915;&#32447;&#24615;&#31995;&#32479;$Ax=b$&#26159;&#19968;&#31181;&#22522;&#26412;&#30340;&#31185;&#23398;&#35745;&#31639;&#21407;&#29702;&#65292;&#24050;&#32463;&#24320;&#21457;&#20102;&#35768;&#22810;&#27714;&#35299;&#22120;&#21644;&#39044;&#22788;&#29702;&#22120;&#12290;&#23427;&#20204;&#24102;&#26377;&#21442;&#25968;&#65292;&#20854;&#26368;&#20339;&#20540;&#21462;&#20915;&#20110;&#35201;&#35299;&#20915;&#30340;&#31995;&#32479;&#65292;&#24182;&#19988;&#36890;&#24120;&#26080;&#27861;&#25110;&#25104;&#26412;&#36807;&#39640;&#20197;&#30830;&#23450;&#65307;&#22240;&#27492;&#22312;&#23454;&#36341;&#20013;&#20351;&#29992;&#27425;&#20248;&#21551;&#21457;&#24335;&#12290;&#25105;&#20204;&#32771;&#34385;&#22312;&#38656;&#35201;&#35299;&#20915;&#35768;&#22810;&#30456;&#20851;&#32447;&#24615;&#31995;&#32479;&#30340;&#24120;&#35265;&#24773;&#20917;&#19979;&#65292;&#20363;&#22914;&#22312;&#21333;&#20010;&#25968;&#20540;&#27169;&#25311;&#26399;&#38388;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#26159;&#21542;&#21487;&#20197;&#39034;&#24207;&#36873;&#25321;&#21442;&#25968;&#65292;&#20197;&#33719;&#24471;&#25509;&#36817;&#26368;&#20339;&#24635;&#36845;&#20195;&#27425;&#25968;&#30340;&#24615;&#33021;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#39069;&#22806;&#30340;&#30697;&#38453;&#35745;&#31639;&#65311;&#23545;&#20110;&#36807;&#24230;&#36731;&#26494;&#65288;SOR&#65289;&#36825;&#31181;&#26631;&#20934;&#27714;&#35299;&#22120;&#65292;&#25105;&#20204;&#22238;&#31572;&#32943;&#23450;&#30340;&#12290;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#20351;&#29992;&#20165;&#36845;&#20195;&#27425;&#25968;&#20316;&#20026;&#21453;&#39304;&#30340;&#36172;&#24466;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#36873;&#25321;&#24207;&#21015;&#23454;&#20363;&#30340;&#21442;&#25968;&#65292;&#20351;&#24471;&#24635;&#25104;&#26412;&#25509;&#36817;&#26368;&#20339;&#22266;&#23450;&#30340;&#969;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Solving a linear system $Ax=b$ is a fundamental scientific computing primitive for which numerous solvers and preconditioners have been developed. These come with parameters whose optimal values depend on the system being solved and are often impossible or too expensive to identify; thus in practice sub-optimal heuristics are used. We consider the common setting in which many related linear systems need to be solved, e.g. during a single numerical simulation. In this scenario, can we sequentially choose parameters that attain a near-optimal overall number of iterations, without extra matrix computations? We answer in the affirmative for Successive Over-Relaxation (SOR), a standard solver whose parameter $\omega$ has a strong impact on its runtime. For this method, we prove that a bandit online learning algorithm -- using only the number of iterations as feedback -- can select parameters for a sequence of instances such that the overall cost approaches that of the best fixed $\omega$ as
&lt;/p&gt;</description></item><item><title>&#24191;&#20041;&#34203;&#23450;&#35860;&#26725;&#21305;&#37197;&#26159;&#19968;&#31181;&#26032;&#30340;&#20998;&#24067;&#21305;&#37197;&#31639;&#27861;&#65292;&#36890;&#36807;&#23558;&#20219;&#21153;&#29305;&#23450;&#30340;&#29366;&#24577;&#25104;&#26412;&#32771;&#34385;&#22312;&#20869;&#65292;&#25512;&#24191;&#20102;&#29616;&#20195;&#20998;&#24067;&#21305;&#37197;&#31639;&#27861;&#65292;&#24182;&#21487;&#29992;&#20110;&#35299;&#20915;&#26465;&#20214;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.02233</link><description>&lt;p&gt;
&#24191;&#20041;&#34203;&#23450;&#35860;&#26725;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Generalized Schr\"odinger Bridge Matching. (arXiv:2310.02233v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02233
&lt;/p&gt;
&lt;p&gt;
&#24191;&#20041;&#34203;&#23450;&#35860;&#26725;&#21305;&#37197;&#26159;&#19968;&#31181;&#26032;&#30340;&#20998;&#24067;&#21305;&#37197;&#31639;&#27861;&#65292;&#36890;&#36807;&#23558;&#20219;&#21153;&#29305;&#23450;&#30340;&#29366;&#24577;&#25104;&#26412;&#32771;&#34385;&#22312;&#20869;&#65292;&#25512;&#24191;&#20102;&#29616;&#20195;&#20998;&#24067;&#21305;&#37197;&#31639;&#27861;&#65292;&#24182;&#21487;&#29992;&#20110;&#35299;&#20915;&#26465;&#20214;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#20998;&#24067;&#21305;&#37197;&#31639;&#27861;&#29992;&#20110;&#35757;&#32451;&#25193;&#25955;&#25110;&#27969;&#27169;&#22411;&#65292;&#30452;&#25509;&#35268;&#23450;&#20102;&#20004;&#20010;&#36793;&#30028;&#20998;&#24067;&#20043;&#38388;&#30340;&#36793;&#32536;&#20998;&#24067;&#30340;&#26102;&#38388;&#28436;&#21464;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#24191;&#20041;&#30340;&#20998;&#24067;&#21305;&#37197;&#35774;&#32622;&#65292;&#20854;&#20013;&#36825;&#20123;&#36793;&#32536;&#20998;&#24067;&#20165;&#20197;&#26576;&#20123;&#20219;&#21153;&#29305;&#23450;&#30446;&#26631;&#20989;&#25968;&#30340;&#35299;&#24418;&#24335;&#38544;&#21547;&#25551;&#36848;&#12290;&#36825;&#20010;&#38382;&#39064;&#35774;&#32622;&#34987;&#31216;&#20026;&#24191;&#20041;&#34203;&#23450;&#35860;&#26725;(GSB)&#65292;&#22312;&#35768;&#22810;&#31185;&#23398;&#39046;&#22495;&#20869;&#21644;&#26426;&#22120;&#23398;&#20064;&#20043;&#22806;&#24191;&#27867;&#20986;&#29616;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#24191;&#20041;&#34203;&#23450;&#35860;&#26725;&#21305;&#37197;(GSBM)&#65292;&#36825;&#26159;&#19968;&#31181;&#21463;&#26368;&#36817;&#36827;&#23637;&#21551;&#21457;&#30340;&#26032;&#30340;&#21305;&#37197;&#31639;&#27861;&#65292;&#23558;&#23427;&#20204;&#25512;&#24191;&#21040;&#21160;&#33021;&#26368;&#23567;&#21270;&#20043;&#22806;&#65292;&#24182;&#32771;&#34385;&#21040;&#20219;&#21153;&#29305;&#23450;&#30340;&#29366;&#24577;&#25104;&#26412;&#12290;&#25105;&#20204;&#35777;&#26126;&#36825;&#26679;&#30340;&#27867;&#21270;&#21487;&#20197;&#34987;&#24314;&#27169;&#20026;&#27714;&#35299;&#26465;&#20214;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#65292;&#20854;&#20013;&#21487;&#20197;&#20351;&#29992;&#39640;&#25928;&#30340;&#21464;&#20998;&#36817;&#20284;&#65292;&#24182;&#20511;&#21161;&#36335;&#24452;&#31215;&#20998;&#29702;&#35770;&#36827;&#19968;&#27493;&#21435;&#20559;&#24046;&#12290;&#19982;&#35299;&#20915;GSB&#38382;&#39064;&#30340;&#20808;&#21069;&#26041;&#27861;&#30456;&#27604;&#65292;
&lt;/p&gt;
&lt;p&gt;
Modern distribution matching algorithms for training diffusion or flow models directly prescribe the time evolution of the marginal distributions between two boundary distributions. In this work, we consider a generalized distribution matching setup, where these marginals are only implicitly described as a solution to some task-specific objective function. The problem setup, known as the Generalized Schr\"odinger Bridge (GSB), appears prevalently in many scientific areas both within and without machine learning. We propose Generalized Schr\"odinger Bridge Matching (GSBM), a new matching algorithm inspired by recent advances, generalizing them beyond kinetic energy minimization and to account for task-specific state costs. We show that such a generalization can be cast as solving conditional stochastic optimal control, for which efficient variational approximations can be used, and further debiased with the aid of path integral theory. Compared to prior methods for solving GSB problems,
&lt;/p&gt;</description></item><item><title>&#20998;&#22359;&#26159;&#36830;&#32493;&#23398;&#20064;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#21344;&#25454;&#23454;&#39564;&#20013;&#31163;&#32447;&#23398;&#20064;&#24615;&#33021;&#19979;&#38477;&#30340;&#32422;&#19968;&#21322;&#12290;&#24403;&#21069;&#30340;&#36830;&#32493;&#23398;&#20064;&#31639;&#27861;&#27809;&#26377;&#35299;&#20915;&#20998;&#22359;&#38382;&#39064;&#65292;&#21482;&#26377;&#22312;&#25968;&#25454;&#20998;&#24067;&#27809;&#26377;&#21464;&#21270;&#26102;&#34920;&#29616;&#19982;&#26222;&#36890;SGD&#35757;&#32451;&#30456;&#20223;&#12290;</title><link>http://arxiv.org/abs/2310.02206</link><description>&lt;p&gt;
&#20998;&#22359;&#65306;&#21363;&#20351;&#22312;&#19981;&#25913;&#21464;&#20219;&#21153;&#30340;&#24773;&#20917;&#19979;&#22312;&#36830;&#32493;&#23398;&#20064;&#20013;&#36951;&#24536;&#20063;&#24456;&#37325;&#35201;
&lt;/p&gt;
&lt;p&gt;
Chunking: Forgetting Matters in Continual Learning even without Changing Tasks. (arXiv:2310.02206v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02206
&lt;/p&gt;
&lt;p&gt;
&#20998;&#22359;&#26159;&#36830;&#32493;&#23398;&#20064;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#21344;&#25454;&#23454;&#39564;&#20013;&#31163;&#32447;&#23398;&#20064;&#24615;&#33021;&#19979;&#38477;&#30340;&#32422;&#19968;&#21322;&#12290;&#24403;&#21069;&#30340;&#36830;&#32493;&#23398;&#20064;&#31639;&#27861;&#27809;&#26377;&#35299;&#20915;&#20998;&#22359;&#38382;&#39064;&#65292;&#21482;&#26377;&#22312;&#25968;&#25454;&#20998;&#24067;&#27809;&#26377;&#21464;&#21270;&#26102;&#34920;&#29616;&#19982;&#26222;&#36890;SGD&#35757;&#32451;&#30456;&#20223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36830;&#32493;&#23398;&#20064;&#65288;CL&#65289;&#30340;&#30740;&#31350;&#20013;&#65292;&#20027;&#35201;&#20851;&#27880;&#21160;&#24577;&#21464;&#21270;&#30340;&#25968;&#25454;&#20998;&#24067;&#25152;&#24102;&#26469;&#30340;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;CL&#21487;&#20197;&#20998;&#35299;&#20026;&#20004;&#20010;&#23376;&#38382;&#39064;&#65306;&#65288;a&#65289;&#25968;&#25454;&#20998;&#24067;&#30340;&#21464;&#21270;&#65292;&#20197;&#21450;&#65288;b&#65289;&#22788;&#29702;&#25968;&#25454;&#34987;&#20998;&#25104;&#22359;&#30340;&#20107;&#23454;&#65292;&#22240;&#27492;&#22312;&#20219;&#20309;&#26102;&#38388;&#28857;&#19978;&#21482;&#26377;&#19968;&#37096;&#20998;&#25968;&#25454;&#21487;&#29992;&#20110;&#35757;&#32451;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20851;&#27880;&#21518;&#32773;&#30340;&#23376;&#38382;&#39064;--&#25968;&#25454;&#30340;&#20998;&#22359;--&#24182;&#27880;&#24847;&#21040;&#20197;&#21069;&#23545;CL&#25991;&#29486;&#20013;&#20851;&#20110;&#20998;&#22359;&#30340;&#20998;&#26512;&#24456;&#23569;&#12290;&#25105;&#20204;&#26174;&#31034;&#20986;&#20998;&#22359;&#26159;CL&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#21344;&#25454;&#20102;&#31163;&#32447;&#23398;&#20064;&#24615;&#33021;&#19979;&#38477;&#30340;&#32422;&#19968;&#21322;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;&#65292;&#24403;&#21069;&#30340;CL&#31639;&#27861;&#27809;&#26377;&#35299;&#20915;&#20998;&#22359;&#23376;&#38382;&#39064;&#65292;&#21482;&#26377;&#22312;&#25968;&#25454;&#20998;&#24067;&#27809;&#26377;&#21464;&#21270;&#26102;&#25165;&#33021;&#34920;&#29616;&#20986;&#19982;&#26222;&#36890;SGD&#35757;&#32451;&#19968;&#26679;&#30340;&#27700;&#24179;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#20026;&#20160;&#20040;&#22312;&#25968;&#25454;&#22359;&#19978;&#36827;&#34892;&#23398;&#20064;&#26102;&#24615;&#33021;&#20250;&#19979;&#38477;&#65292;&#24182;&#21457;&#29616;&#36951;&#24536;&#26159;&#19968;&#20010;&#32463;&#24120;&#34987;&#30475;&#20316;&#26159;&#38382;&#39064;&#30340;&#21407;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;
Work on continual learning (CL) has largely focused on the problems arising from the dynamically-changing data distribution. However, CL can be decomposed into two sub-problems: (a) shifts in the data distribution, and (b) dealing with the fact that the data is split into chunks and so only a part of the data is available to be trained on at any point in time. In this work, we look at the latter sub-problem -- the chunking of data -- and note that previous analysis of chunking in the CL literature is sparse. We show that chunking is an important part of CL, accounting for around half of the performance drop from offline learning in our experiments. Furthermore, our results reveal that current CL algorithms do not address the chunking sub-problem, only performing as well as plain SGD training when there is no shift in the data distribution. We analyse why performance drops when learning occurs on chunks of data, and find that forgetting, which is often seen to be a problem due to distri
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#23618;&#27010;&#24565;&#21457;&#29616;&#27169;&#22411;&#65292;&#36890;&#36807;&#21033;&#29992;&#22270;&#20687;&#25991;&#26412;&#27169;&#22411;&#21644;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#36125;&#21494;&#26031;&#21442;&#25968;&#65292;&#23454;&#29616;&#20102;&#22522;&#20110;&#20154;&#31867;&#21487;&#29702;&#35299;&#27010;&#24565;&#30340;&#39640;&#24230;&#21487;&#35299;&#37322;&#30340;&#20915;&#31574;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2310.02116</link><description>&lt;p&gt;
&#20998;&#23618;&#27010;&#24565;&#21457;&#29616;&#27169;&#22411;&#65306;&#19968;&#20010;&#27010;&#24565;&#37329;&#23383;&#22612;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Hierarchical Concept Discovery Models: A Concept Pyramid Scheme. (arXiv:2310.02116v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02116
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#23618;&#27010;&#24565;&#21457;&#29616;&#27169;&#22411;&#65292;&#36890;&#36807;&#21033;&#29992;&#22270;&#20687;&#25991;&#26412;&#27169;&#22411;&#21644;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#36125;&#21494;&#26031;&#21442;&#25968;&#65292;&#23454;&#29616;&#20102;&#22522;&#20110;&#20154;&#31867;&#21487;&#29702;&#35299;&#27010;&#24565;&#30340;&#39640;&#24230;&#21487;&#35299;&#37322;&#30340;&#20915;&#31574;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#22240;&#20854;&#21331;&#36234;&#30340;&#24615;&#33021;&#32780;&#24341;&#36215;&#20102;&#22823;&#37327;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#39640;&#22797;&#26434;&#24615;&#21644;&#19981;&#21487;&#35299;&#37322;&#30340;&#25805;&#20316;&#26041;&#24335;&#38459;&#30861;&#20102;&#23427;&#20204;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#23433;&#20840;&#20851;&#38190;&#20219;&#21153;&#20013;&#30340;&#33258;&#20449;&#37096;&#32626;&#12290;&#26412;&#30740;&#31350;&#38024;&#23545;&#30340;&#26159;ante hoc&#21487;&#35299;&#37322;&#24615;&#65292;&#20855;&#20307; &#35828;&#26159;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#65288;CBMs&#65289;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#35774;&#35745;&#19968;&#20010;&#26694;&#26550;&#65292;&#20197;&#22810;&#20010;&#23618;&#27425;&#31890;&#24230;&#19978;&#30340;&#20154;&#31867;&#21487;&#29702;&#35299;&#27010;&#24565;&#20026;&#22522;&#30784;&#65292;&#23454;&#29616;&#39640;&#24230;&#21487;&#35299;&#37322;&#30340;&#20915;&#31574;&#36807;&#31243;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#23618;&#27010;&#24565;&#21457;&#29616;&#26041;&#27861;&#65292;&#21033;&#29992;&#65306;&#65288;i&#65289;&#22270;&#20687;&#25991;&#26412;&#27169;&#22411;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#20197;&#21450;&#65288;ii&#65289;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#21644;&#31232;&#30095;&#35825;&#23548;&#30340;&#36125;&#21494;&#26031;&#21442;&#25968;&#36827;&#34892;&#22810;&#23618;&#27010;&#24565;&#36873;&#25321;&#30340;&#21019;&#26032;&#20844;&#24335;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#20013;&#65292;&#27010;&#24565;&#20449;&#24687;&#19981;&#20165;&#20165;&#20381;&#36182;&#20110;&#25972;&#20307;&#22270;&#20687;&#19982;&#19968;&#33324;&#38750;&#32467;&#26500;&#21270;&#27010;&#24565;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65307;&#30456;&#21453;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#27010;&#24565;&#23618;&#27425;&#30340;&#27010;&#24565;&#65292;&#20197;&#25581;&#31034;&#21644;&#21033;&#29992;&#26356;&#22810;&#30340;&#32454;&#33410;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Learning algorithms have recently gained significant attention due to their impressive performance. However, their high complexity and un-interpretable mode of operation hinders their confident deployment in real-world safety-critical tasks. This work targets ante hoc interpretability, and specifically Concept Bottleneck Models (CBMs). Our goal is to design a framework that admits a highly interpretable decision making process with respect to human understandable concepts, on multiple levels of granularity. To this end, we propose a novel hierarchical concept discovery formulation leveraging: (i) recent advances in image-text models, and (ii) an innovative formulation for multi-level concept selection via data-driven and sparsity inducing Bayesian arguments. Within this framework, concept information does not solely rely on the similarity between the whole image and general unstructured concepts; instead, we introduce the notion of concept hierarchy to uncover and exploit more gra
&lt;/p&gt;</description></item><item><title>fmeffects&#26159;&#31532;&#19968;&#20010;&#23454;&#29616;&#21069;&#21521;&#36793;&#38469;&#25928;&#24212;&#65288;FMEs&#65289;&#30340;R&#36719;&#20214;&#21253;&#12290;</title><link>http://arxiv.org/abs/2310.02008</link><description>&lt;p&gt;
fmeffects: &#19968;&#20010;&#29992;&#20110;&#21069;&#21521;&#36793;&#38469;&#25928;&#24212;&#30340;R&#36719;&#20214;&#21253;
&lt;/p&gt;
&lt;p&gt;
fmeffects: An R Package for Forward Marginal Effects. (arXiv:2310.02008v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02008
&lt;/p&gt;
&lt;p&gt;
fmeffects&#26159;&#31532;&#19968;&#20010;&#23454;&#29616;&#21069;&#21521;&#36793;&#38469;&#25928;&#24212;&#65288;FMEs&#65289;&#30340;R&#36719;&#20214;&#21253;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21069;&#21521;&#36793;&#38469;&#25928;&#24212;&#65288;FMEs&#65289;&#20316;&#20026;&#19968;&#31181;&#36890;&#29992;&#26377;&#25928;&#30340;&#27169;&#22411;&#19981;&#21487;&#30693;&#35299;&#37322;&#26041;&#27861;&#26368;&#36817;&#34987;&#24341;&#20837;&#12290;&#23427;&#20204;&#20197;&#8220;&#22914;&#26524;&#25105;&#20204;&#23558;$x$&#25913;&#21464;$h$&#65292;&#37027;&#20040;&#39044;&#27979;&#32467;&#26524;$\widehat{y}$&#20250;&#21457;&#29983;&#20160;&#20040;&#21464;&#21270;&#65311;&#8221;&#30340;&#24418;&#24335;&#25552;&#20379;&#26131;&#20110;&#29702;&#35299;&#21644;&#21487;&#25805;&#20316;&#30340;&#27169;&#22411;&#35299;&#37322;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;fmeffects&#36719;&#20214;&#21253;&#65292;&#36825;&#26159;FMEs&#30340;&#31532;&#19968;&#20010;&#36719;&#20214;&#23454;&#29616;&#12290;&#35752;&#35770;&#20102;&#30456;&#20851;&#30340;&#29702;&#35770;&#32972;&#26223;&#12289;&#36719;&#20214;&#21253;&#21151;&#33021;&#21644;&#22788;&#29702;&#26041;&#24335;&#65292;&#20197;&#21450;&#36719;&#20214;&#35774;&#35745;&#21644;&#26410;&#26469;&#25193;&#23637;&#30340;&#36873;&#39033;&#12290;
&lt;/p&gt;
&lt;p&gt;
Forward marginal effects (FMEs) have recently been introduced as a versatile and effective model-agnostic interpretation method. They provide comprehensible and actionable model explanations in the form of: If we change $x$ by an amount $h$, what is the change in predicted outcome $\widehat{y}$? We present the R package fmeffects, the first software implementation of FMEs. The relevant theoretical background, package functionality and handling, as well as the software design and options for future extensions are discussed in this paper.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21464;&#20998;&#39640;&#26031;&#36924;&#36817;&#30340;&#26041;&#27861;&#26469;&#36817;&#20284;&#35299;&#20915;Kushner&#26041;&#31243;&#65292;&#36890;&#36807;&#20256;&#25773;&#21644;&#36125;&#21494;&#26031;&#26356;&#26032;&#27010;&#29575;&#23494;&#24230;&#30456;&#20851;&#30340;&#20004;&#20010;&#25509;&#36817;&#25439;&#22833;&#65292;&#21033;&#29992;Wasserstein&#24230;&#37327;&#21644;Fisher&#24230;&#37327;&#65292;&#36890;&#36807;&#38544;&#24335;&#26356;&#26032;&#22343;&#20540;&#21644;&#21327;&#26041;&#24046;&#30697;&#38453;&#26469;&#35299;&#20915;&#26368;&#21518;&#30340;&#25509;&#36817;&#25439;&#22833;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#28385;&#36275;&#39640;&#26031;&#27969;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65292;&#25193;&#23637;&#20102;&#32447;&#24615;&#24773;&#20917;&#19979;&#30340;Kalman-Bucy&#21644;Riccati&#27969;&#12290;</title><link>http://arxiv.org/abs/2310.01859</link><description>&lt;p&gt;
&#21464;&#20998;&#39640;&#26031;&#36924;&#36817;Kushner&#26368;&#20248;&#28388;&#27874;&#22120;
&lt;/p&gt;
&lt;p&gt;
Variational Gaussian approximation of the Kushner optimal filter. (arXiv:2310.01859v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01859
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21464;&#20998;&#39640;&#26031;&#36924;&#36817;&#30340;&#26041;&#27861;&#26469;&#36817;&#20284;&#35299;&#20915;Kushner&#26041;&#31243;&#65292;&#36890;&#36807;&#20256;&#25773;&#21644;&#36125;&#21494;&#26031;&#26356;&#26032;&#27010;&#29575;&#23494;&#24230;&#30456;&#20851;&#30340;&#20004;&#20010;&#25509;&#36817;&#25439;&#22833;&#65292;&#21033;&#29992;Wasserstein&#24230;&#37327;&#21644;Fisher&#24230;&#37327;&#65292;&#36890;&#36807;&#38544;&#24335;&#26356;&#26032;&#22343;&#20540;&#21644;&#21327;&#26041;&#24046;&#30697;&#38453;&#26469;&#35299;&#20915;&#26368;&#21518;&#30340;&#25509;&#36817;&#25439;&#22833;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#28385;&#36275;&#39640;&#26031;&#27969;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65292;&#25193;&#23637;&#20102;&#32447;&#24615;&#24773;&#20917;&#19979;&#30340;Kalman-Bucy&#21644;Riccati&#27969;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20272;&#35745;&#29702;&#35770;&#20013;&#65292;Kushner&#26041;&#31243;&#25552;&#20379;&#20102;&#32473;&#23450;&#36830;&#32493;&#26102;&#38388;&#35266;&#27979;&#30340;&#21160;&#24577;&#31995;&#32479;&#29366;&#24577;&#30340;&#27010;&#29575;&#23494;&#24230;&#30340;&#28436;&#21270;&#12290;&#22312;&#25105;&#20204;&#26368;&#36817;&#30340;&#24037;&#20316;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21487;&#22788;&#29702;&#30340;&#21464;&#20998;&#39640;&#26031;&#36924;&#36817;&#26469;&#36817;&#20284;&#35299;&#20915;Kushner&#26041;&#31243;&#30340;&#26032;&#26041;&#27861;&#65292;&#20854;&#20013;&#28041;&#21450;&#21040;&#19982;&#27010;&#29575;&#23494;&#24230;&#30340;&#20256;&#25773;&#21644;&#36125;&#21494;&#26031;&#26356;&#26032;&#30456;&#20851;&#30340;&#20004;&#20010;&#25509;&#36817;&#36817;&#20284;&#25439;&#22833;&#12290;&#31532;&#19968;&#20010;&#26159;&#22522;&#20110;Wasserstein&#24230;&#37327;&#30340;&#25509;&#36817;&#25439;&#22833;&#65292;&#31532;&#20108;&#20010;&#26159;&#22522;&#20110;Fisher&#24230;&#37327;&#30340;&#25509;&#36817;&#25439;&#22833;&#12290;&#36825;&#20010;&#26368;&#21518;&#25509;&#36817;&#25439;&#22833;&#30340;&#35299;&#20915;&#26041;&#26696;&#30001;&#25105;&#20204;&#20043;&#21069;&#25552;&#20986;&#30340;&#22343;&#20540;&#21644;&#21327;&#26041;&#24046;&#30340;&#38544;&#24335;&#26356;&#26032;&#32473;&#20986;&#12290;&#36825;&#20004;&#20010;&#21464;&#20998;&#26356;&#26032;&#21487;&#20197;&#34701;&#21512;&#24182;&#35777;&#26126;&#28385;&#36275;&#39640;&#26031;&#22343;&#20540;&#21644;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#19968;&#32452;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#12290;&#36825;&#20010;&#39640;&#26031;&#27969;&#19982;&#32447;&#24615;&#24773;&#20917;&#19979;&#30340;Kalman-Bucy&#21644;Riccati&#27969;&#19968;&#33268;&#65292;&#24182;&#22312;&#38750;&#32447;&#24615;&#24773;&#20917;&#19979;&#25512;&#24191;&#20102;&#23427;&#20204;&#12290;
&lt;/p&gt;
&lt;p&gt;
In estimation theory, the Kushner equation provides the evolution of the probability density of the state of a dynamical system given continuous-time observations. Building upon our recent work, we propose a new way to approximate the solution of the Kushner equation through tractable variational Gaussian approximations of two proximal losses associated with the propagation and Bayesian update of the probability density. The first is a proximal loss based on the Wasserstein metric and the second is a proximal loss based on the Fisher metric. The solution to this last proximal loss is given by implicit updates on the mean and covariance that we proposed earlier. These two variational updates can be fused and shown to satisfy a set of stochastic differential equations on the Gaussian's mean and covariance matrix. This Gaussian flow is consistent with the Kalman-Bucy and Riccati flows in the linear case and generalize them in the nonlinear one.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35780;&#20272;&#20102;&#22522;&#20110;&#35780;&#20998;&#30340;&#25968;&#25454;&#21516;&#21270;&#26041;&#27861;&#22312;&#39640;&#32500;&#24230;&#30340;&#22320;&#29699;&#29289;&#29702;&#21160;&#21147;&#31995;&#32479;&#20013;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#24182;&#36890;&#36807;&#22312;&#21452;&#23618;&#25311;&#22320;&#36716;&#21160;&#27169;&#22411;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#33391;&#22909;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.01853</link><description>&lt;p&gt;
&#22522;&#20110;&#35780;&#20998;&#30340;&#25968;&#25454;&#21516;&#21270;&#22312;&#21452;&#23618;&#25311;&#22320;&#36716;&#21160;&#27169;&#22411;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Score-based Data Assimilation for a Two-Layer Quasi-Geostrophic Model. (arXiv:2310.01853v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01853
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35780;&#20272;&#20102;&#22522;&#20110;&#35780;&#20998;&#30340;&#25968;&#25454;&#21516;&#21270;&#26041;&#27861;&#22312;&#39640;&#32500;&#24230;&#30340;&#22320;&#29699;&#29289;&#29702;&#21160;&#21147;&#31995;&#32479;&#20013;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#24182;&#36890;&#36807;&#22312;&#21452;&#23618;&#25311;&#22320;&#36716;&#21160;&#27169;&#22411;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#33391;&#22909;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#21516;&#21270;&#35299;&#20915;&#20102;&#22312;&#32473;&#23450;&#22024;&#26434;&#25110;&#19981;&#23436;&#25972;&#35266;&#27979;&#24773;&#20917;&#19979;&#65292;&#30830;&#23450;&#21160;&#21147;&#31995;&#32479;&#21487;&#34892;&#29366;&#24577;&#36712;&#36857;&#30340;&#38382;&#39064;&#12290;&#22312;&#22320;&#29699;&#31185;&#23398;&#20013;&#65292;&#30001;&#20110;&#22320;&#29699;&#29289;&#29702;&#21160;&#21147;&#31995;&#32479;&#30340;&#39640;&#32500;&#24230;&#24615;&#65292;&#24448;&#24448;&#36229;&#36807;&#20102;&#25968;&#30334;&#19975;&#32500;&#24230;&#65292;&#22240;&#27492;&#23384;&#22312;&#25361;&#25112;&#12290;&#26412;&#25991;&#35780;&#20272;&#20102;&#22522;&#20110;&#35780;&#20998;&#30340;&#25968;&#25454;&#21516;&#21270;&#65288;SDA&#65289;&#36825;&#19968;&#26032;&#39062;&#30340;&#25968;&#25454;&#21516;&#21270;&#26041;&#27861;&#22312;&#27492;&#31867;&#31995;&#32479;&#20013;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#38024;&#23545;&#35780;&#20998;&#32593;&#32476;&#26550;&#26500;&#30340;&#20462;&#25913;&#65292;&#26088;&#22312;&#26174;&#33879;&#20943;&#23569;&#20869;&#23384;&#28040;&#32791;&#21644;&#25191;&#34892;&#26102;&#38388;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#21452;&#23618;&#25311;&#22320;&#36716;&#21160;&#27169;&#22411;&#20013;&#23637;&#31034;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data assimilation addresses the problem of identifying plausible state trajectories of dynamical systems given noisy or incomplete observations. In geosciences, it presents challenges due to the high-dimensionality of geophysical dynamical systems, often exceeding millions of dimensions. This work assesses the scalability of score-based data assimilation (SDA), a novel data assimilation method, in the context of such systems. We propose modifications to the score network architecture aimed at significantly reducing memory consumption and execution time. We demonstrate promising results for a two-layer quasi-geostrophic model.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24191;&#20041;Kullback-Leibler&#25955;&#24230;&#30340;&#20223;&#30495;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#32771;&#34385;&#38750;&#24402;&#19968;&#21270;&#20998;&#24067;&#20013;&#30340;&#24402;&#19968;&#21270;&#24120;&#25968;&#65292;&#23558;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#19982;&#31070;&#32463;&#27604;&#20540;&#20272;&#35745;&#32467;&#21512;&#20026;&#19968;&#20010;&#30446;&#26631;&#65292;&#24182;&#30740;&#31350;&#20102;&#19968;&#31181;&#28151;&#21512;&#27169;&#22411;&#26469;&#23454;&#29616;&#26368;&#20339;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.01808</link><description>&lt;p&gt;
&#22522;&#20110;&#24191;&#20041;Kullback-Leibler&#25955;&#24230;&#30340;&#20223;&#30495;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Simulation-based Inference with the Generalized Kullback-Leibler Divergence. (arXiv:2310.01808v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01808
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24191;&#20041;Kullback-Leibler&#25955;&#24230;&#30340;&#20223;&#30495;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#32771;&#34385;&#38750;&#24402;&#19968;&#21270;&#20998;&#24067;&#20013;&#30340;&#24402;&#19968;&#21270;&#24120;&#25968;&#65292;&#23558;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#19982;&#31070;&#32463;&#27604;&#20540;&#20272;&#35745;&#32467;&#21512;&#20026;&#19968;&#20010;&#30446;&#26631;&#65292;&#24182;&#30740;&#31350;&#20102;&#19968;&#31181;&#28151;&#21512;&#27169;&#22411;&#26469;&#23454;&#29616;&#26368;&#20339;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#20110;&#20223;&#30495;&#30340;&#25512;&#26029;&#20013;&#65292;&#30446;&#26631;&#26159;&#22312;&#20284;&#28982;&#20989;&#25968;&#21482;&#38544;&#24335;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#35299;&#20915;&#36870;&#38382;&#39064;&#12290;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#36890;&#24120;&#20351;&#29992;&#24402;&#19968;&#21270;&#23494;&#24230;&#20272;&#35745;&#22120;&#20316;&#20026;&#21518;&#39564;&#30340;&#20195;&#29702;&#27169;&#22411;&#12290;&#30001;&#20110;&#20248;&#21270;&#30340;&#26159;Kullback-Leibler&#25955;&#24230;&#65292;&#36825;&#31181;&#24418;&#24335;&#24456;&#38590;&#36866;&#24212;&#38750;&#24402;&#19968;&#21270;&#20195;&#29702;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20248;&#21270;&#24191;&#20041;Kullback-Leibler&#25955;&#24230;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#32771;&#34385;&#20102;&#38750;&#24402;&#19968;&#21270;&#20998;&#24067;&#20013;&#30340;&#24402;&#19968;&#21270;&#24120;&#25968;&#12290;&#24403;&#27169;&#22411;&#31867;&#34987;&#24402;&#19968;&#21270;&#26102;&#65292;&#35813;&#30446;&#26631;&#24674;&#22797;&#20102;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#65292;&#24182;&#23558;&#20854;&#32479;&#19968;&#21040;&#20102;&#31070;&#32463;&#27604;&#20540;&#20272;&#35745;&#20013;&#65292;&#23558;&#20004;&#32773;&#32467;&#21512;&#20026;&#19968;&#20010;&#30446;&#26631;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#28151;&#21512;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#24402;&#19968;&#21270;&#22522;&#30784;&#20998;&#24067;&#21644;&#23398;&#20064;&#27604;&#20540;&#26469;&#23454;&#29616;&#26368;&#20339;&#25928;&#26524;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#22522;&#20934;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In Simulation-based Inference, the goal is to solve the inverse problem when the likelihood is only known implicitly. Neural Posterior Estimation commonly fits a normalized density estimator as a surrogate model for the posterior. This formulation cannot easily fit unnormalized surrogates because it optimizes the Kullback-Leibler divergence. We propose to optimize a generalized Kullback-Leibler divergence that accounts for the normalization constant in unnormalized distributions. The objective recovers Neural Posterior Estimation when the model class is normalized and unifies it with Neural Ratio Estimation, combining both into a single objective. We investigate a hybrid model that offers the best of both worlds by learning a normalized base distribution and a learned ratio. We also present benchmark results.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#36807;&#21442;&#25968;&#21270;&#22914;&#20309;&#24433;&#21709;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#20013;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#34892;&#20026;&#65292;&#22312;&#23545;&#31216;&#21644;&#38750;&#23545;&#31216;&#35774;&#32622;&#19979;&#32473;&#20986;&#20102;&#19981;&#21516;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.01769</link><description>&lt;p&gt;
&#36807;&#21442;&#25968;&#21270;&#22914;&#20309;&#20943;&#32531;&#30697;&#38453;&#24863;&#30693;&#20013;&#30340;&#26799;&#24230;&#19979;&#38477;&#65306;&#23545;&#31216;&#24615;&#21644;&#21021;&#22987;&#21270;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
How Over-Parameterization Slows Down Gradient Descent in Matrix Sensing: The Curses of Symmetry and Initialization. (arXiv:2310.01769v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01769
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#36807;&#21442;&#25968;&#21270;&#22914;&#20309;&#24433;&#21709;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#20013;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#34892;&#20026;&#65292;&#22312;&#23545;&#31216;&#21644;&#38750;&#23545;&#31216;&#35774;&#32622;&#19979;&#32473;&#20986;&#20102;&#19981;&#21516;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35814;&#32454;&#38416;&#36848;&#20102;&#36807;&#21442;&#25968;&#21270;&#22914;&#20309;&#25913;&#21464;&#26799;&#24230;&#19979;&#38477;&#22312;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#20013;&#30340;&#25910;&#25947;&#34892;&#20026;&#12290;&#22312;&#23545;&#31216;&#35774;&#32622;&#20013;&#65292;&#36890;&#36807;&#23545;&#31216;&#21442;&#25968;&#21270;&#23398;&#20064;&#26410;&#30693;&#30340;&#21322;&#27491;&#23450;&#30697;&#38453;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#65288;$k&gt;r$&#65289;&#38543;&#26426;&#21021;&#22987;&#21270;&#26799;&#24230;&#19979;&#38477;&#30340;&#26032;&#22411;$\Omega (1/T^2)$&#19979;&#30028;&#65292;&#19982;&#31934;&#30830;&#21442;&#25968;&#21270;&#24773;&#20917;&#65288;$k=r$&#65289;&#30340;&#25910;&#25947;&#36895;&#24230;$\exp (-\Omega (T))$&#24418;&#25104;&#40092;&#26126;&#23545;&#27604;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19981;&#23545;&#31216;&#35774;&#32622;&#65292;&#20854;&#20013;$M^* \in \mathbb{R}^{n_1 \times n_2}$&#26159;&#26410;&#30693;&#30697;&#38453;&#65292;&#37319;&#29992;&#38750;&#23545;&#31216;&#21442;&#25968;&#21270;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper rigorously shows how over-parameterization changes the convergence behaviors of gradient descent (GD) for the matrix sensing problem, where the goal is to recover an unknown low-rank ground-truth matrix from near-isotropic linear measurements. First, we consider the symmetric setting with the symmetric parameterization where $M^* \in \mathbb{R}^{n \times n}$ is a positive semi-definite unknown matrix of rank $r \ll n$, and one uses a symmetric parameterization $XX^\top$ to learn $M^*$. Here $X \in \mathbb{R}^{n \times k}$ with $k &gt; r$ is the factor matrix. We give a novel $\Omega (1/T^2)$ lower bound of randomly initialized GD for the over-parameterized case ($k &gt;r$) where $T$ is the number of iterations. This is in stark contrast to the exact-parameterization scenario ($k=r$) where the convergence rate is $\exp (-\Omega (T))$. Next, we study asymmetric setting where $M^* \in \mathbb{R}^{n_1 \times n_2}$ is the unknown matrix of rank $r \ll \min\{n_1,n_2\}$, and one uses an 
&lt;/p&gt;</description></item><item><title>&#25913;&#36827;&#30340;&#31639;&#27861;&#29992;&#20110;&#35299;&#20915;&#23545;&#25239;&#24615;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#65292;&#26080;&#38656;&#20808;&#39564;&#30693;&#35782;&#65292;&#23454;&#29616;&#33258;&#36866;&#24212;&#19988;&#26080;&#38656;&#32479;&#19968;&#25506;&#32034;&#30340;&#36951;&#25022;&#30028;&#38480;&#65292;&#33021;&#22815;&#22788;&#29702;&#20219;&#24847;&#26080;&#30028;&#25439;&#22833;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.01756</link><description>&lt;p&gt;
&#25913;&#36827;&#30340;&#31639;&#27861;&#29992;&#20110;&#20855;&#26377;&#26080;&#30028;&#25439;&#22833;&#30340;&#23545;&#25239;&#24615;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Improved Algorithms for Adversarial Bandits with Unbounded Losses. (arXiv:2310.01756v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01756
&lt;/p&gt;
&lt;p&gt;
&#25913;&#36827;&#30340;&#31639;&#27861;&#29992;&#20110;&#35299;&#20915;&#23545;&#25239;&#24615;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#65292;&#26080;&#38656;&#20808;&#39564;&#30693;&#35782;&#65292;&#23454;&#29616;&#33258;&#36866;&#24212;&#19988;&#26080;&#38656;&#32479;&#19968;&#25506;&#32034;&#30340;&#36951;&#25022;&#30028;&#38480;&#65292;&#33021;&#22815;&#22788;&#29702;&#20219;&#24847;&#26080;&#30028;&#25439;&#22833;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20855;&#26377;&#26080;&#30028;&#25439;&#22833;&#30340;&#23545;&#25239;&#24615;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#65292;&#20854;&#20013;&#31639;&#27861;&#23545;&#25439;&#22833;&#30340;&#22823;&#23567;&#27809;&#26377;&#20808;&#39564;&#30693;&#35782;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;UMAB-NN&#21644;UMAB-G&#20004;&#31181;&#31639;&#27861;&#65292;&#20998;&#21035;&#29992;&#20110;&#38750;&#36127;&#21644;&#19968;&#33324;&#30340;&#26080;&#30028;&#25439;&#22833;&#12290;&#23545;&#20110;&#38750;&#36127;&#26080;&#30028;&#25439;&#22833;&#65292;UMAB-NN&#23454;&#29616;&#20102;&#31532;&#19968;&#20010;&#33258;&#36866;&#24212;&#19988;&#26080;&#38656;&#32479;&#19968;&#25506;&#32034;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#21457;&#23637;&#20102;UMAB-G&#65292;&#21487;&#20197;&#23398;&#20064;&#20219;&#24847;&#26080;&#30028;&#25439;&#22833;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;MAB&#38382;&#39064;&#20013;&#27491;&#36127;&#25439;&#22833;&#20043;&#38388;&#30340;&#19981;&#23545;&#31216;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#39069;&#22806;&#30340;&#35265;&#35299;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#22823;&#37327;&#23454;&#35777;&#35780;&#20272;&#26469;&#37197;&#21512;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#65292;&#26174;&#31034;&#20986;&#25105;&#20204;&#30340;&#31639;&#27861;&#22987;&#32456;&#20248;&#20110;&#25152;&#26377;&#22788;&#29702;&#26080;&#30028;&#25439;&#22833;&#30340;&#29616;&#26377;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the Adversarial Multi-Armed Bandits (MAB) problem with unbounded losses, where the algorithms have no prior knowledge on the sizes of the losses. We present UMAB-NN and UMAB-G, two algorithms for non-negative and general unbounded loss respectively. For non-negative unbounded loss, UMAB-NN achieves the first adaptive and scale free regret bound without uniform exploration. Built up on that, we further develop UMAB-G that can learn from arbitrary unbounded loss. Our analysis reveals the asymmetry between positive and negative losses in the MAB problem and provide additional insights. We also accompany our theoretical findings with extensive empirical evaluations, showing that our algorithms consistently out-performs all existing algorithms that handles unbounded losses.
&lt;/p&gt;</description></item><item><title>CausalTime&#24341;&#20837;&#20102;&#19968;&#31181;&#29983;&#25104;&#36924;&#30495;&#26102;&#38388;&#24207;&#21015;&#30340;&#27969;&#31243;&#65292;&#33021;&#22815;&#29983;&#25104;&#19982;&#30495;&#23454;&#25968;&#25454;&#26497;&#20854;&#30456;&#20284;&#19988;&#24102;&#26377;&#22522;&#20934;&#22240;&#26524;&#22270;&#30340;&#26102;&#38388;&#24207;&#21015;&#65292;&#29992;&#20110;&#23450;&#37327;&#24615;&#33021;&#35780;&#20272;&#12290;&#35813;&#27969;&#31243;&#21033;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#27491;&#24577;&#27969;&#25429;&#25417;&#36924;&#30495;&#30340;&#21160;&#24577;&#65292;&#25552;&#21462;&#20551;&#35774;&#30340;&#22240;&#26524;&#22270;&#65292;&#24182;&#29983;&#25104;&#36866;&#21512;&#31639;&#27861;&#35780;&#20272;&#30340;&#22810;&#26679;&#21270;&#26102;&#38388;&#24207;&#21015;&#12290;</title><link>http://arxiv.org/abs/2310.01753</link><description>&lt;p&gt;
CausalTime&#65306;&#29992;&#20110;&#22240;&#26524;&#21457;&#29616;&#22522;&#20934;&#27979;&#35797;&#30340;&#36924;&#30495;&#29983;&#25104;&#26102;&#38388;&#24207;&#21015;
&lt;/p&gt;
&lt;p&gt;
CausalTime: Realistically Generated Time-series for Benchmarking of Causal Discovery. (arXiv:2310.01753v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01753
&lt;/p&gt;
&lt;p&gt;
CausalTime&#24341;&#20837;&#20102;&#19968;&#31181;&#29983;&#25104;&#36924;&#30495;&#26102;&#38388;&#24207;&#21015;&#30340;&#27969;&#31243;&#65292;&#33021;&#22815;&#29983;&#25104;&#19982;&#30495;&#23454;&#25968;&#25454;&#26497;&#20854;&#30456;&#20284;&#19988;&#24102;&#26377;&#22522;&#20934;&#22240;&#26524;&#22270;&#30340;&#26102;&#38388;&#24207;&#21015;&#65292;&#29992;&#20110;&#23450;&#37327;&#24615;&#33021;&#35780;&#20272;&#12290;&#35813;&#27969;&#31243;&#21033;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#27491;&#24577;&#27969;&#25429;&#25417;&#36924;&#30495;&#30340;&#21160;&#24577;&#65292;&#25552;&#21462;&#20551;&#35774;&#30340;&#22240;&#26524;&#22270;&#65292;&#24182;&#29983;&#25104;&#36866;&#21512;&#31639;&#27861;&#35780;&#20272;&#30340;&#22810;&#26679;&#21270;&#26102;&#38388;&#24207;&#21015;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#24207;&#21015;&#22240;&#26524;&#21457;&#29616;&#65288;TSCD&#65289;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#26080;&#27861;&#27491;&#30830;&#35780;&#20272;&#25110;&#39044;&#27979;&#31639;&#27861;&#22312;&#30495;&#23454;&#25968;&#25454;&#19978;&#30340;&#24615;&#33021;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;CausalTime&#27969;&#31243;&#65292;&#29992;&#20110;&#29983;&#25104;&#39640;&#24230;&#31867;&#20284;&#30495;&#23454;&#25968;&#25454;&#19988;&#24102;&#26377;&#22522;&#20934;&#22240;&#26524;&#22270;&#30340;&#26102;&#38388;&#24207;&#21015;&#65292;&#20197;&#36827;&#34892;&#23450;&#37327;&#24615;&#33021;&#35780;&#20272;&#12290;&#35813;&#27969;&#31243;&#20174;&#29305;&#23450;&#22330;&#26223;&#30340;&#30495;&#23454;&#35266;&#27979;&#25968;&#25454;&#24320;&#22987;&#65292;&#29983;&#25104;&#30456;&#21305;&#37197;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#21033;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#27491;&#24577;&#27969;&#26469;&#20934;&#30830;&#25429;&#25417;&#36924;&#30495;&#30340;&#21160;&#24577;&#12290;&#20854;&#27425;&#65292;&#36890;&#36807;&#23545;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#37325;&#35201;&#24615;&#20998;&#26512;&#25110;&#21033;&#29992;&#20808;&#21069;&#30693;&#35782;&#65292;&#25552;&#21462;&#20551;&#35774;&#30340;&#22240;&#26524;&#22270;&#12290;&#31532;&#19977;&#65292;&#22312;&#22240;&#26524;&#27169;&#22411;&#20013;&#23558;&#22240;&#26524;&#39033;&#12289;&#27531;&#24046;&#39033;&#21644;&#22122;&#22768;&#39033;&#25286;&#20998;&#65292;&#24471;&#21040;&#22522;&#26412;&#30495;&#23454;&#30340;&#22240;&#26524;&#22270;&#12290;&#26368;&#21518;&#65292;&#21033;&#29992;&#25311;&#21512;&#30340;&#32593;&#32476;&#21644;&#27966;&#29983;&#30340;&#22240;&#26524;&#22270;&#65292;&#25105;&#20204;&#29983;&#25104;&#36866;&#21512;&#31639;&#27861;&#35780;&#20272;&#30340;&#22810;&#26679;&#21270;&#26102;&#38388;&#24207;&#21015;&#12290;
&lt;/p&gt;
&lt;p&gt;
Time-series causal discovery (TSCD) is a fundamental problem of machine learning. However, existing synthetic datasets cannot properly evaluate or predict the algorithms' performance on real data. This study introduces the CausalTime pipeline to generate time-series that highly resemble the real data and with ground truth causal graphs for quantitative performance evaluation. The pipeline starts from real observations in a specific scenario and produces a matching benchmark dataset. Firstly, we harness deep neural networks along with normalizing flow to accurately capture realistic dynamics. Secondly, we extract hypothesized causal graphs by performing importance analysis on the neural network or leveraging prior knowledge. Thirdly, we derive the ground truth causal graphs by splitting the causal model into causal term, residual term, and noise term. Lastly, using the fitted network and the derived causal graph, we generate corresponding versatile time-series proper for algorithm asses
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#8220;&#30697;&#38453;&#25277;&#26679;&#8221;&#30340;&#24555;&#36895;&#38543;&#26426;&#20302;&#31209;&#20998;&#35299;&#31639;&#27861;&#65292;&#29992;&#20110;&#22823;&#22411;&#30697;&#38453;&#30340;&#32500;&#24230;&#38477;&#20302;&#65292;&#20174;&#32780;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#21644;&#25968;&#25454;&#21033;&#29992;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.01739</link><description>&lt;p&gt;
&#20855;&#26377;&#32479;&#35745;&#20445;&#35777;&#30340;&#38543;&#26426;&#32500;&#24230;&#38477;&#20302;
&lt;/p&gt;
&lt;p&gt;
Randomized Dimension Reduction with Statistical Guarantees. (arXiv:2310.01739v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01739
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#8220;&#30697;&#38453;&#25277;&#26679;&#8221;&#30340;&#24555;&#36895;&#38543;&#26426;&#20302;&#31209;&#20998;&#35299;&#31639;&#27861;&#65292;&#29992;&#20110;&#22823;&#22411;&#30697;&#38453;&#30340;&#32500;&#24230;&#38477;&#20302;&#65292;&#20174;&#32780;&#25552;&#39640;&#35745;&#31639;&#25928;&#29575;&#21644;&#25968;&#25454;&#21033;&#29992;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#27169;&#22411;&#21644;&#24222;&#22823;&#25968;&#25454;&#26159;&#29616;&#20195;&#31639;&#27861;&#21462;&#24471;&#21069;&#25152;&#26410;&#26377;&#25104;&#21151;&#30340;&#20851;&#38190;&#39537;&#21160;&#21147;&#65292;&#23588;&#20854;&#26159;&#22312;&#31185;&#23398;&#35745;&#31639;&#21644;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#19981;&#26029;&#22686;&#38271;&#30340;&#32500;&#24230;&#21644;&#27169;&#22411;&#22797;&#26434;&#24615;&#20197;&#21450;&#25968;&#25454;&#39044;&#22788;&#29702;&#30340;&#24037;&#20316;&#37327;&#20063;&#32473;&#35745;&#31639;&#21644;&#25968;&#25454;&#32858;&#21512;&#24102;&#26469;&#20102;&#24040;&#22823;&#30340;&#25104;&#26412;&#12290;&#38543;&#30528;&#25705;&#23572;&#23450;&#24459;&#25918;&#32531;&#23548;&#33268;&#35745;&#31639;&#25104;&#26412;&#20174;&#30828;&#20214;&#23618;&#38754;&#38477;&#20302;&#30340;&#20943;&#36895;&#65292;&#24555;&#36895;&#22823;&#22411;&#32463;&#20856;&#20363;&#31243;&#30340;&#21551;&#21457;&#24335;&#31639;&#27861;&#21644;&#21033;&#29992;&#26377;&#38480;&#25968;&#25454;&#30340;&#39640;&#25928;&#31639;&#27861;&#23545;&#20110;&#25512;&#21160;&#31639;&#27861;&#28508;&#21147;&#30340;&#26497;&#38480;&#21464;&#24471;&#36234;&#26469;&#36234;&#19981;&#21487;&#25110;&#32570;&#12290;&#26412;&#35770;&#25991;&#25506;&#32034;&#20102;&#19968;&#20123;&#24555;&#36895;&#25191;&#34892;&#21644;&#39640;&#25928;&#21033;&#29992;&#25968;&#25454;&#30340;&#31639;&#27861;&#12290;&#20174;&#35745;&#31639;&#25928;&#29575;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#25105;&#20204;&#35774;&#35745;&#21644;&#20998;&#26512;&#20102;&#22522;&#20110;&#8220;&#30697;&#38453;&#25277;&#26679;&#8221;&#30340;&#22823;&#22411;&#30697;&#38453;&#30340;&#24555;&#36895;&#38543;&#26426;&#20302;&#31209;&#20998;&#35299;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#34987;&#35270;&#20026;&#19968;&#31181;&#32500;&#24230;&#38477;&#20302;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large models and enormous data are essential driving forces of the unprecedented successes achieved by modern algorithms, especially in scientific computing and machine learning. Nevertheless, the growing dimensionality and model complexity, as well as the non-negligible workload of data pre-processing, also bring formidable costs to such successes in both computation and data aggregation. As the deceleration of Moore's Law slackens the cost reduction of computation from the hardware level, fast heuristics for expensive classical routines and efficient algorithms for exploiting limited data are increasingly indispensable for pushing the limit of algorithm potency. This thesis explores some of such algorithms for fast execution and efficient data utilization.  From the computational efficiency perspective, we design and analyze fast randomized low-rank decomposition algorithms for large matrices based on "matrix sketching", which can be regarded as a dimension reduction strategy in the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34701;&#21512;&#27169;&#20223;&#23398;&#20064;&#21644;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#26681;&#25454;&#22312;&#32447;&#35780;&#20272;&#32467;&#26524;&#20132;&#26367;&#20351;&#29992;&#20108;&#32773;&#65292;&#20197;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#21644;&#23398;&#20064;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.01737</link><description>&lt;p&gt;
&#34701;&#21512;&#27169;&#20223;&#23398;&#20064;&#21644;&#24378;&#21270;&#23398;&#20064;&#20197;&#23454;&#29616;&#40065;&#26834;&#31574;&#30053;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
Blending Imitation and Reinforcement Learning for Robust Policy Improvement. (arXiv:2310.01737v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01737
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34701;&#21512;&#27169;&#20223;&#23398;&#20064;&#21644;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#26681;&#25454;&#22312;&#32447;&#35780;&#20272;&#32467;&#26524;&#20132;&#26367;&#20351;&#29992;&#20108;&#32773;&#65292;&#20197;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#21644;&#23398;&#20064;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#24378;&#21270;&#23398;&#20064;&#22312;&#24615;&#33021;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#20854;&#26679;&#26412;&#22797;&#26434;&#24230;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#22823;&#38556;&#30861;&#65292;&#38480;&#21046;&#20102;&#20854;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#24191;&#27867;&#24212;&#29992;&#12290;&#27169;&#20223;&#23398;&#20064;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#20248;&#21270;&#26679;&#26412;&#25928;&#29575;&#65292;&#20294;&#36890;&#24120;&#21463;&#21040;&#25152;&#20351;&#29992;&#30340;&#19987;&#23478;&#31034;&#33539;&#30340;&#36136;&#37327;&#38480;&#21046;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#34701;&#21512;&#27169;&#20223;&#23398;&#20064;&#21644;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26681;&#25454;&#22312;&#32447;&#35780;&#20272;&#32467;&#26524;&#20132;&#26367;&#20351;&#29992;&#20108;&#32773;&#65292;&#26377;&#25928;&#22320;&#25552;&#39640;&#20102;&#23398;&#20064;&#25928;&#29575;&#12290;&#36825;&#31181;&#31639;&#27861;&#33021;&#22815;&#20174;&#22810;&#31181;&#40657;&#30418;&#19987;&#23478;&#31034;&#33539;&#20013;&#23398;&#20064;&#21644;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
While reinforcement learning (RL) has shown promising performance, its sample complexity continues to be a substantial hurdle, restricting its broader application across a variety of domains. Imitation learning (IL) utilizes oracles to improve sample efficiency, yet it is often constrained by the quality of the oracles deployed. which actively interleaves between IL and RL based on an online estimate of their performance. RPI draws on the strengths of IL, using oracle queries to facilitate exploration, an aspect that is notably challenging in sparse-reward RL, particularly during the early stages of learning. As learning unfolds, RPI gradually transitions to RL, effectively treating the learned policy as an improved oracle. This algorithm is capable of learning from and improving upon a diverse set of black-box oracles. Integral to RPI are Robust Active Policy Selection (RAPS) and Robust Policy Gradient (RPG), both of which reason over whether to perform state-wise imitation from the o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22788;&#29702;&#26426;&#22120;&#23398;&#20064;&#20013;&#19981;&#36866;&#23450;&#23545;&#35282;&#21270;&#38382;&#39064;&#30340;&#36890;&#29992;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;&#25311;&#35889;&#29702;&#35770;&#30340;&#8220;&#25200;&#21160;&#28982;&#21518;&#23545;&#35282;&#21270;&#8221;&#65288;PTD&#65289;&#26041;&#27861;&#65292;&#25913;&#21892;&#20102;&#38271;&#24207;&#21015;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.01698</link><description>&lt;p&gt;
&#36890;&#36807;&#36817;&#20284;&#23545;&#35282;&#21270;&#25552;&#39640;&#38271;&#24207;&#21015;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Robustifying State-space Models for Long Sequences via Approximate Diagonalization. (arXiv:2310.01698v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01698
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22788;&#29702;&#26426;&#22120;&#23398;&#20064;&#20013;&#19981;&#36866;&#23450;&#23545;&#35282;&#21270;&#38382;&#39064;&#30340;&#36890;&#29992;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;&#25311;&#35889;&#29702;&#35770;&#30340;&#8220;&#25200;&#21160;&#28982;&#21518;&#23545;&#35282;&#21270;&#8221;&#65288;PTD&#65289;&#26041;&#27861;&#65292;&#25913;&#21892;&#20102;&#38271;&#24207;&#21015;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65288;SSM&#65289;&#20316;&#20026;&#23398;&#20064;&#38271;&#26399;&#24207;&#21015;&#20219;&#21153;&#30340;&#26694;&#26550;&#24050;&#32463;&#20986;&#29616;&#12290;&#19968;&#20010;&#20363;&#23376;&#26159;&#32467;&#26500;&#21270;&#29366;&#24577;&#31354;&#38388;&#24207;&#21015;&#65288;S4&#65289;&#23618;&#65292;&#23427;&#20351;&#29992;HiPPO&#21021;&#22987;&#21270;&#26694;&#26550;&#30340;&#23545;&#35282;&#21152;&#20302;&#31209;&#32467;&#26500;&#12290;&#28982;&#32780;&#65292;S4&#23618;&#30340;&#22797;&#26434;&#32467;&#26500;&#24102;&#26469;&#20102;&#25361;&#25112;&#65307;&#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#25361;&#25112;&#65292;&#27169;&#22411;&#22914;S4D&#21644;S5&#32771;&#34385;&#20102;&#32431;&#23545;&#35282;&#32467;&#26500;&#12290;&#36825;&#20010;&#36873;&#25321;&#31616;&#21270;&#20102;&#23454;&#29616;&#65292;&#25552;&#39640;&#20102;&#35745;&#31639;&#25928;&#29575;&#65292;&#24182;&#20801;&#35768;&#20449;&#36947;&#36890;&#20449;&#12290;&#28982;&#32780;&#65292;&#23545;HiPPO&#26694;&#26550;&#36827;&#34892;&#23545;&#35282;&#21270;&#26412;&#36523;&#23601;&#26159;&#19968;&#20010;&#19981;&#36866;&#23450;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#29992;&#20110;&#22788;&#29702;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#36825;&#31867;&#19981;&#36866;&#23450;&#23545;&#35282;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#12289;&#21518;&#21521;&#31283;&#23450;&#30340;&#8220;&#25200;&#21160;&#28982;&#21518;&#23545;&#35282;&#21270;&#8221;&#65288;PTD&#65289;&#26041;&#27861;&#65292;&#23427;&#22522;&#20110;&#38750;&#27491;&#24120;&#31639;&#23376;&#30340;&#25311;&#35889;&#29702;&#35770;&#65292;&#24182;&#21487;&#20197;&#34987;&#35299;&#37322;&#20026;&#38750;&#27491;&#24120;&#30697;&#38453;&#30340;&#36817;&#20284;&#23545;&#35282;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
State-space models (SSMs) have recently emerged as a framework for learning long-range sequence tasks. An example is the structured state-space sequence (S4) layer, which uses the diagonal-plus-low-rank structure of the HiPPO initialization framework. However, the complicated structure of the S4 layer poses challenges; and, in an effort to address these challenges, models such as S4D and S5 have considered a purely diagonal structure. This choice simplifies the implementation, improves computational efficiency, and allows channel communication. However, diagonalizing the HiPPO framework is itself an ill-posed problem. In this paper, we propose a general solution for this and related ill-posed diagonalization problems in machine learning. We introduce a generic, backward-stable "perturb-then-diagonalize" (PTD) methodology, which is based on the pseudospectral theory of non-normal operators, and which may be interpreted as the approximate diagonalization of the non-normal matrices defini
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23545;&#20108;&#27425;&#22238;&#24402;&#27169;&#22411;&#20013;&#26799;&#24230;&#19979;&#38477;&#30340;&#21160;&#21147;&#23398;&#36827;&#34892;&#20840;&#38754;&#30740;&#31350;&#65292;&#21457;&#29616;&#21160;&#21147;&#23398;&#21487;&#20197;&#29992;&#19968;&#20010;&#29305;&#23450;&#30340;&#31435;&#26041;&#26144;&#23556;&#26469;&#27010;&#25324;&#65292;&#24182;&#35814;&#32454;&#21010;&#20998;&#20102;&#20116;&#20010;&#35757;&#32451;&#38454;&#27573;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#23454;&#39564;&#20063;&#35777;&#26126;&#20102;&#36825;&#20123;&#38454;&#27573;&#30340;&#25512;&#24191;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.01687</link><description>&lt;p&gt;
&#20174;&#31283;&#23450;&#21040;&#28151;&#27788;&#65306;&#22312;&#20108;&#27425;&#22238;&#24402;&#20013;&#20998;&#26512;&#26799;&#24230;&#19979;&#38477;&#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
From Stability to Chaos: Analyzing Gradient Descent Dynamics in Quadratic Regression. (arXiv:2310.01687v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01687
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23545;&#20108;&#27425;&#22238;&#24402;&#27169;&#22411;&#20013;&#26799;&#24230;&#19979;&#38477;&#30340;&#21160;&#21147;&#23398;&#36827;&#34892;&#20840;&#38754;&#30740;&#31350;&#65292;&#21457;&#29616;&#21160;&#21147;&#23398;&#21487;&#20197;&#29992;&#19968;&#20010;&#29305;&#23450;&#30340;&#31435;&#26041;&#26144;&#23556;&#26469;&#27010;&#25324;&#65292;&#24182;&#35814;&#32454;&#21010;&#20998;&#20102;&#20116;&#20010;&#35757;&#32451;&#38454;&#27573;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#23454;&#39564;&#20063;&#35777;&#26126;&#20102;&#36825;&#20123;&#38454;&#27573;&#30340;&#25512;&#24191;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#20108;&#27425;&#22238;&#24402;&#27169;&#22411;&#30340;&#32972;&#26223;&#19979;&#65292;&#20351;&#29992;&#22823;&#38454;&#24658;&#23450;&#27493;&#38271;&#23545;&#26799;&#24230;&#19979;&#38477;&#30340;&#21160;&#21147;&#23398;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#30740;&#31350;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#21457;&#29616;&#21160;&#21147;&#23398;&#21487;&#20197;&#34987;&#19968;&#20010;&#29305;&#23450;&#30340;&#31435;&#26041;&#26144;&#23556;&#25152;&#27010;&#25324;&#65292;&#33258;&#28982;&#22320;&#30001;&#27493;&#38271;&#21442;&#25968;&#21270;&#12290;&#36890;&#36807;&#23545;&#27493;&#38271;&#21442;&#25968;&#36827;&#34892;&#32454;&#31890;&#24230;&#30340;&#20998;&#21449;&#20998;&#26512;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#20116;&#20010;&#19981;&#21516;&#30340;&#35757;&#32451;&#38454;&#27573;&#65306;&#65288;1&#65289;&#21333;&#35843;&#12289;&#65288;2&#65289;&#25243;&#29289;&#32447;&#12289;&#65288;3&#65289;&#21608;&#26399;&#24615;&#12289;&#65288;4&#65289;&#28151;&#27788;&#21644;&#65288;5&#65289;&#21457;&#25955;&#65292;&#31934;&#30830;&#22320;&#21010;&#23450;&#20102;&#27599;&#20010;&#38454;&#27573;&#30340;&#36793;&#30028;&#12290;&#20316;&#20026;&#31034;&#20363;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#28041;&#21450;&#30456;&#20301;&#24674;&#22797;&#21644;&#20351;&#29992;&#20108;&#27425;&#28608;&#27963;&#20989;&#25968;&#21644;&#24658;&#23450;&#22806;&#23618;&#30340;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#20363;&#23376;&#65292;&#21033;&#29992;&#27491;&#20132;&#35757;&#32451;&#25968;&#25454;&#12290;&#25105;&#20204;&#30340;&#27169;&#25311;&#34920;&#26126;&#65292;&#36825;&#20116;&#20010;&#38454;&#27573;&#20063;&#22312;&#19968;&#33324;&#30340;&#38750;&#27491;&#20132;&#25968;&#25454;&#20013;&#26174;&#29616;&#12290;&#25105;&#20204;&#36824;&#22312;&#21508;&#20010;&#38750;&#21333;&#35843;&#65288;&#38750;&#21457;&#25955;&#65289;&#38454;&#27573;&#36827;&#34892;&#20102;&#32463;&#39564;&#24615;&#30340;&#25512;&#24191;&#24615;&#33021;&#30740;&#31350;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#19981;&#21516;&#38454;&#27573;&#35757;&#32451;&#26102;&#30340;&#25512;&#24191;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We conduct a comprehensive investigation into the dynamics of gradient descent using large-order constant step-sizes in the context of quadratic regression models. Within this framework, we reveal that the dynamics can be encapsulated by a specific cubic map, naturally parameterized by the step-size. Through a fine-grained bifurcation analysis concerning the step-size parameter, we delineate five distinct training phases: (1) monotonic, (2) catapult, (3) periodic, (4) chaotic, and (5) divergent, precisely demarcating the boundaries of each phase. As illustrations, we provide examples involving phase retrieval and two-layer neural networks employing quadratic activation functions and constant outer-layers, utilizing orthogonal training data. Our simulations indicate that these five phases also manifest with generic non-orthogonal data. We also empirically investigate the generalization performance when training in the various non-monotonic (and non-divergent) phases. In particular, we o
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#23485;&#24230;&#21644;&#28145;&#24230;&#30340;&#21487;&#20132;&#25442;&#32553;&#25918;&#12290;&#36890;&#36807;&#20998;&#26512;&#31070;&#32463;&#20989;&#25968;&#30340;&#34892;&#20026;&#65292;&#24182;&#30830;&#23450;&#20102;&#23485;&#24230;&#21644;&#28145;&#24230;&#36235;&#36817;&#20110;&#26080;&#31351;&#22823;&#26102;&#30340;&#21487;&#20132;&#25442;&#24615;&#26465;&#20214;&#65292;&#24182;&#30740;&#31350;&#20102;&#31070;&#32463;&#21327;&#26041;&#24046;&#26680;&#30340;&#21487;&#20132;&#25442;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#20855;&#26377;&#36339;&#36291;&#36830;&#25509;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#24403;&#20998;&#25903;&#36866;&#24403;&#32553;&#25918;&#20197;&#36991;&#20813;&#29190;&#28856;&#34892;&#20026;&#26102;&#65292;&#23558;&#23485;&#24230;&#21644;&#28145;&#24230;&#36235;&#36817;&#20110;&#26080;&#31351;&#22823;&#20250;&#24471;&#21040;&#30456;&#21516;&#30340;&#21327;&#26041;&#24046;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2310.01683</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#21487;&#20132;&#25442;&#23485;&#24230;&#21644;&#28145;&#24230;&#32553;&#25918;
&lt;/p&gt;
&lt;p&gt;
Commutative Width and Depth Scaling in Deep Neural Networks. (arXiv:2310.01683v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01683
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#23485;&#24230;&#21644;&#28145;&#24230;&#30340;&#21487;&#20132;&#25442;&#32553;&#25918;&#12290;&#36890;&#36807;&#20998;&#26512;&#31070;&#32463;&#20989;&#25968;&#30340;&#34892;&#20026;&#65292;&#24182;&#30830;&#23450;&#20102;&#23485;&#24230;&#21644;&#28145;&#24230;&#36235;&#36817;&#20110;&#26080;&#31351;&#22823;&#26102;&#30340;&#21487;&#20132;&#25442;&#24615;&#26465;&#20214;&#65292;&#24182;&#30740;&#31350;&#20102;&#31070;&#32463;&#21327;&#26041;&#24046;&#26680;&#30340;&#21487;&#20132;&#25442;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#20855;&#26377;&#36339;&#36291;&#36830;&#25509;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#24403;&#20998;&#25903;&#36866;&#24403;&#32553;&#25918;&#20197;&#36991;&#20813;&#29190;&#28856;&#34892;&#20026;&#26102;&#65292;&#23558;&#23485;&#24230;&#21644;&#28145;&#24230;&#36235;&#36817;&#20110;&#26080;&#31351;&#22823;&#20250;&#24471;&#21040;&#30456;&#21516;&#30340;&#21327;&#26041;&#24046;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#26159;&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#20013;&#23485;&#24230;&#21644;&#28145;&#24230;&#30340;&#21487;&#20132;&#25442;&#32553;&#25918;&#30340;&#31995;&#21015;&#35770;&#25991;&#30340;&#31532;&#20108;&#31687;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#29702;&#35299;&#31070;&#32463;&#20989;&#25968;&#65288;&#20381;&#36182;&#20110;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#20989;&#25968;&#65289;&#22312;&#23485;&#24230;&#21644;&#28145;&#24230;&#36235;&#36817;&#20110;&#26080;&#31351;&#22823;&#26102;&#30340;&#34892;&#20026;&#65292;&#24182;&#26368;&#32456;&#30830;&#23450;&#22312;&#21738;&#20123;&#26465;&#20214;&#19979;&#21487;&#20132;&#25442;&#24615;&#25104;&#31435;&#65292;&#21363;&#26080;&#35770;&#22914;&#20309;&#21462;&#23485;&#24230;&#21644;&#28145;&#24230;&#30340;&#26497;&#38480;&#65292;&#31070;&#32463;&#20989;&#25968;&#37117;&#36235;&#21521;&#20110;&#30456;&#21516;&#30340;&#26497;&#38480;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#27491;&#24335;&#24341;&#20837;&#21644;&#23450;&#20041;&#20102;&#21487;&#20132;&#25442;&#24615;&#26694;&#26550;&#65292;&#24182;&#35752;&#35770;&#20102;&#23427;&#23545;&#31070;&#32463;&#32593;&#32476;&#35774;&#35745;&#21644;&#32553;&#25918;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#31070;&#32463;&#21327;&#26041;&#24046;&#26680;&#30340;&#21487;&#20132;&#25442;&#24615;&#65292;&#35813;&#26680;&#21453;&#26144;&#20102;&#32593;&#32476;&#23618;&#23545;&#25968;&#25454;&#30340;&#20998;&#31163;&#24773;&#20917;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#25193;&#23637;&#20102;&#20043;&#21069;&#22312;[55]&#20013;&#24314;&#31435;&#30340;&#32467;&#26524;&#65292;&#36890;&#36807;&#23637;&#31034;&#22312;&#20855;&#26377;&#36339;&#36291;&#36830;&#25509;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#24403;&#20998;&#25903;&#36866;&#24403;&#32553;&#25918;&#20197;&#36991;&#20813;&#29190;&#28856;&#34892;&#20026;&#26102;&#65292;&#23558;&#23485;&#24230;&#21644;&#28145;&#24230;&#36235;&#36817;&#20110;&#26080;&#31351;&#22823;&#20250;&#24471;&#21040;&#30456;&#21516;&#30340;&#21327;&#26041;&#24046;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is the second in the series Commutative Scaling of Width and Depth (WD) about commutativity of infinite width and depth limits in deep neural networks. Our aim is to understand the behaviour of neural functions (functions that depend on a neural network model) as width and depth go to infinity (in some sense), and eventually identify settings under which commutativity holds, i.e. the neural function tends to the same limit no matter how width and depth limits are taken. In this paper, we formally introduce and define the commutativity framework, and discuss its implications on neural network design and scaling. We study commutativity for the neural covariance kernel which reflects how network layers separate data. Our findings extend previous results established in [55] by showing that taking the width and depth to infinity in a deep neural network with skip connections, when branches are suitably scaled to avoid exploding behaviour, result in the same covariance structure n
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#21482;&#26377;&#26377;&#38480;&#21463;&#20445;&#25252;&#23646;&#24615;&#26631;&#31614;&#35775;&#38382;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#21644;&#20943;&#23569;&#20844;&#24179;&#36829;&#35268;&#34892;&#20026;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#20272;&#35745;&#29616;&#26377;&#27169;&#22411;&#30340;&#20844;&#24179;&#24230;&#37327;&#33539;&#22260;&#65292;&#24182;&#36890;&#36807;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#35757;&#32451;&#27169;&#22411;&#20197;&#38480;&#21046;&#20844;&#24179;&#36829;&#35268;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#20102;&#19978;&#19979;&#25991;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2310.01679</link><description>&lt;p&gt;
&#29992;&#27010;&#29575;&#20445;&#25252;&#29305;&#24449;&#20272;&#35745;&#21644;&#23454;&#29616;&#20256;&#32479;&#20844;&#24179;&#24230;&#37327;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Estimating and Implementing Conventional Fairness Metrics With Probabilistic Protected Features. (arXiv:2310.01679v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01679
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#21482;&#26377;&#26377;&#38480;&#21463;&#20445;&#25252;&#23646;&#24615;&#26631;&#31614;&#35775;&#38382;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#21644;&#20943;&#23569;&#20844;&#24179;&#36829;&#35268;&#34892;&#20026;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#20272;&#35745;&#29616;&#26377;&#27169;&#22411;&#30340;&#20844;&#24179;&#24230;&#37327;&#33539;&#22260;&#65292;&#24182;&#36890;&#36807;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#35757;&#32451;&#27169;&#22411;&#20197;&#38480;&#21046;&#20844;&#24179;&#36829;&#35268;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#20102;&#19978;&#19979;&#25991;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#35757;&#32451;&#20844;&#24179;&#27169;&#22411;&#30340;&#25216;&#26415;&#38656;&#35201;&#35775;&#38382;&#21463;&#20445;&#25252;&#23646;&#24615;&#65288;&#20363;&#22914;&#31181;&#26063;&#12289;&#24615;&#21035;&#65289;&#65292;&#26080;&#35770;&#26159;&#22312;&#35757;&#32451;&#26102;&#36824;&#26159;&#22312;&#29983;&#20135;&#20013;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#37325;&#35201;&#24212;&#29992;&#20013;&#36825;&#20123;&#20445;&#25252;&#23646;&#24615;&#22823;&#37096;&#20998;&#26159;&#19981;&#21487;&#33719;&#24471;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#26377;&#38480;&#21463;&#20445;&#25252;&#23646;&#24615;&#26631;&#31614;&#35775;&#38382;&#24773;&#20917;&#19979;&#24230;&#37327;&#21644;&#20943;&#23569;&#20844;&#24179;&#36829;&#35268;&#34892;&#20026;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20551;&#35774;&#23545;&#20110;&#24863;&#20852;&#36259;&#30340;&#25968;&#25454;&#38598;&#21482;&#33021;&#35775;&#38382;&#19968;&#23567;&#37096;&#20998;&#21463;&#20445;&#25252;&#23646;&#24615;&#26631;&#31614;&#65292;&#20294;&#23545;&#20110;&#20854;&#20313;&#25968;&#25454;&#38598;&#65292;&#21482;&#33021;&#36890;&#36807;&#27010;&#29575;&#20272;&#35745;&#21463;&#20445;&#25252;&#23646;&#24615;&#26631;&#31614;&#65288;&#20363;&#22914;&#36890;&#36807;&#36125;&#21494;&#26031;&#25913;&#36827;&#30340;&#22995;&#27663;&#22320;&#29702;&#32534;&#30721;&#65289;&#12290;&#22522;&#20110;&#36825;&#31181;&#35774;&#23450;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#20272;&#35745;&#29616;&#26377;&#27169;&#22411;&#30340;&#24120;&#35265;&#20844;&#24179;&#24230;&#37327;&#30340;&#33539;&#22260;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#36890;&#36807;&#35299;&#20915;&#32422;&#26463;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#26469;&#38480;&#21046;&#20844;&#24179;&#36829;&#35268;&#30340;&#27169;&#22411;&#35757;&#32451;&#26041;&#27861;&#12290;&#19982;&#31867;&#20284;&#30340;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20102;&#19978;&#19979;&#25991;&#20449;&#24687;&#65292;&#29305;&#21035;&#26159;&#20851;&#32852;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
The vast majority of techniques to train fair models require access to the protected attribute (e.g., race, gender), either at train time or in production. However, in many important applications this protected attribute is largely unavailable. In this paper, we develop methods for measuring and reducing fairness violations in a setting with limited access to protected attribute labels. Specifically, we assume access to protected attribute labels on a small subset of the dataset of interest, but only probabilistic estimates of protected attribute labels (e.g., via Bayesian Improved Surname Geocoding) for the rest of the dataset. With this setting in mind, we propose a method to estimate bounds on common fairness metrics for an existing model, as well as a method for training a model to limit fairness violations by solving a constrained non-convex optimization problem. Unlike similar existing approaches, our methods take advantage of contextual information -specifically, the relations
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23558;&#25439;&#22833;&#20989;&#25968;&#32435;&#20837;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65292;&#23545;&#23545;&#25239;&#24615;&#32447;&#24615;&#19978;&#19979;&#25991;&#22810;&#33218;&#36172;&#21338;&#30340;&#22312;&#32447;&#23398;&#20064;&#36827;&#34892;&#20102;&#20869;&#26680;&#21270;&#30740;&#31350;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#22810;&#31181;&#29305;&#24449;&#20540;&#34928;&#20943;&#20551;&#35774;&#19979;&#23454;&#29616;&#25509;&#36817;&#26368;&#20248;&#30340;&#36951;&#25022;&#20445;&#35777;&#12290;&#22312;&#22810;&#39033;&#24335;&#29305;&#24449;&#20540;&#34928;&#20943;&#21644;&#25351;&#25968;&#29305;&#24449;&#20540;&#34928;&#20943;&#30340;&#24773;&#20917;&#19979;&#65292;&#36951;&#25022;&#19978;&#30028;&#20998;&#21035;&#20026; $\widetilde{O}(KT^{\frac{1}{2}(1+\frac{1}{c})})$ &#21644; $\widetilde{O}(\sqrt{T})$&#12290;</title><link>http://arxiv.org/abs/2310.01609</link><description>&lt;p&gt;
&#23545;&#25239;&#24615;&#19978;&#19979;&#25991;&#22810;&#33218;&#36172;&#21338;&#36827;&#34892;&#20869;&#26680;&#21270;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Adversarial Contextual Bandits Go Kernelized. (arXiv:2310.01609v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01609
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23558;&#25439;&#22833;&#20989;&#25968;&#32435;&#20837;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65292;&#23545;&#23545;&#25239;&#24615;&#32447;&#24615;&#19978;&#19979;&#25991;&#22810;&#33218;&#36172;&#21338;&#30340;&#22312;&#32447;&#23398;&#20064;&#36827;&#34892;&#20102;&#20869;&#26680;&#21270;&#30740;&#31350;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#22810;&#31181;&#29305;&#24449;&#20540;&#34928;&#20943;&#20551;&#35774;&#19979;&#23454;&#29616;&#25509;&#36817;&#26368;&#20248;&#30340;&#36951;&#25022;&#20445;&#35777;&#12290;&#22312;&#22810;&#39033;&#24335;&#29305;&#24449;&#20540;&#34928;&#20943;&#21644;&#25351;&#25968;&#29305;&#24449;&#20540;&#34928;&#20943;&#30340;&#24773;&#20917;&#19979;&#65292;&#36951;&#25022;&#19978;&#30028;&#20998;&#21035;&#20026; $\widetilde{O}(KT^{\frac{1}{2}(1+\frac{1}{c})})$ &#21644; $\widetilde{O}(\sqrt{T})$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#23558;&#25439;&#22833;&#20989;&#25968;&#32435;&#20837;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65292;&#30740;&#31350;&#20102;&#23545;&#25239;&#24615;&#32447;&#24615;&#19978;&#19979;&#25991;&#22810;&#33218;&#36172;&#21338;&#30340;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#30340;&#19968;&#33324;&#21270;&#12290;&#36825;&#20801;&#35768;&#23545;&#22797;&#26434;&#30340;&#20915;&#31574;&#22330;&#26223;&#36827;&#34892;&#26356;&#28789;&#27963;&#30340;&#24314;&#27169;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#31639;&#27861;&#65292;&#21033;&#29992;&#26032;&#30340;&#20048;&#35266;&#20559;&#22909;&#20272;&#35745;&#22120;&#23545;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#20272;&#35745;&#65292;&#24182;&#22312;&#22522;&#20110;&#24213;&#23618;&#26680;&#30340;&#22810;&#31181;&#29305;&#24449;&#20540;&#34928;&#20943;&#20551;&#35774;&#19979;&#23454;&#29616;&#20102;&#25509;&#36817;&#26368;&#20248;&#30340;&#36951;&#25022;&#20445;&#35777;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#22312;&#22810;&#39033;&#24335;&#29305;&#24449;&#20540;&#34928;&#20943;&#25351;&#25968; $c&gt;1$ &#30340;&#20551;&#35774;&#19979;&#65292;&#36951;&#25022;&#20026; $\widetilde{O}(KT^{\frac{1}{2}(1+\frac{1}{c})})$&#65292;&#20854;&#20013; $T$ &#34920;&#31034;&#36718;&#25968;&#65292;$K$ &#34920;&#31034;&#21160;&#20316;&#25968;&#37327;&#12290;&#27492;&#22806;&#65292;&#24403;&#29305;&#24449;&#20540;&#34928;&#20943;&#36981;&#24490;&#25351;&#25968;&#27169;&#24335;&#26102;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#19968;&#20010;&#26356;&#21152;&#32039;&#23494;&#30340;&#36951;&#25022;&#30028; $\widetilde{O}(\sqrt{T})$&#12290;&#36825;&#20123;&#36895;&#24230;&#19982;&#24050;&#30693;&#30340;&#25152;&#26377;&#29305;&#27530;&#24773;&#20917;&#19979;&#30340;&#19979;&#30028;&#21305;&#37197;&#65292;&#24182;&#19982;&#24050;&#30693;&#30340;&#26368;&#20339;&#19978;&#30028;&#30456;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a generalization of the problem of online learning in adversarial linear contextual bandits by incorporating loss functions that belong to a reproducing kernel Hilbert space, which allows for a more flexible modeling of complex decision-making scenarios. We propose a computationally efficient algorithm that makes use of a new optimistically biased estimator for the loss functions and achieves near-optimal regret guarantees under a variety of eigenvalue decay assumptions made on the underlying kernel. Specifically, under the assumption of polynomial eigendecay with exponent $c&gt;1$, the regret is $\widetilde{O}(KT^{\frac{1}{2}(1+\frac{1}{c})})$, where $T$ denotes the number of rounds and $K$ the number of actions. Furthermore, when the eigendecay follows an exponential pattern, we achieve an even tighter regret bound of $\widetilde{O}(\sqrt{T})$. These rates match the lower bounds in all special cases where lower bounds are known at all, and match the best known upper bounds avai
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23545;&#27604;&#23398;&#20064;&#20013;&#30340;&#34920;&#31034;&#21644;&#20998;&#37197;&#20260;&#23475;&#38382;&#39064;&#65292;&#21457;&#29616;&#22312;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#65292;&#23545;&#27604;&#23398;&#20064;&#23481;&#26131;&#36896;&#25104;&#23569;&#25968;&#32676;&#20307;&#30340;&#34920;&#31034;&#21644;&#22810;&#25968;&#32676;&#20307;&#30340;&#34920;&#31034;&#21512;&#24182;&#65292;&#20174;&#32780;&#23548;&#33268;&#20998;&#37197;&#20260;&#23475;&#12290;&#36890;&#36807;&#22240;&#26524;&#20013;&#20171;&#20998;&#26512;&#21644;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#35299;&#37322;&#65292;&#24378;&#35843;&#20102;&#30740;&#31350;&#21644;&#32531;&#35299;&#36825;&#31181;&#34920;&#31034;&#20260;&#23475;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.01583</link><description>&lt;p&gt;
&#23545;&#27604;&#23398;&#20064;&#20013;&#30340;&#34920;&#31034;&#21644;&#20998;&#37197;&#20260;&#23475;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
An Investigation of Representation and Allocation Harms in Contrastive Learning. (arXiv:2310.01583v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01583
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23545;&#27604;&#23398;&#20064;&#20013;&#30340;&#34920;&#31034;&#21644;&#20998;&#37197;&#20260;&#23475;&#38382;&#39064;&#65292;&#21457;&#29616;&#22312;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#65292;&#23545;&#27604;&#23398;&#20064;&#23481;&#26131;&#36896;&#25104;&#23569;&#25968;&#32676;&#20307;&#30340;&#34920;&#31034;&#21644;&#22810;&#25968;&#32676;&#20307;&#30340;&#34920;&#31034;&#21512;&#24182;&#65292;&#20174;&#32780;&#23548;&#33268;&#20998;&#37197;&#20260;&#23475;&#12290;&#36890;&#36807;&#22240;&#26524;&#20013;&#20171;&#20998;&#26512;&#21644;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#35299;&#37322;&#65292;&#24378;&#35843;&#20102;&#30740;&#31350;&#21644;&#32531;&#35299;&#36825;&#31181;&#34920;&#31034;&#20260;&#23475;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26377;&#30417;&#30563;&#23398;&#20064;&#29615;&#22659;&#20013;&#65292;&#23569;&#25968;&#32676;&#20307;&#30340;&#20195;&#34920;&#19981;&#36275;&#23545;&#20854;&#34920;&#29616;&#30340;&#24433;&#21709;&#34987;&#35748;&#20026;&#26159;&#19968;&#20010;&#20005;&#37325;&#38382;&#39064;&#65292;&#28982;&#32780;&#65292;&#22312;&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#30340;&#32972;&#26223;&#19979;&#65292;&#23545;&#27492;&#38382;&#39064;&#30340;&#30740;&#31350;&#36824;&#19981;&#22815;&#20805;&#20998;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23545;&#27604;&#23398;&#20064;&#65288;CL&#65289;&#36825;&#19968;&#27969;&#34892;&#30340;SSL&#21464;&#20307;&#20250;&#20542;&#21521;&#20110;&#23558;&#23569;&#25968;&#32676;&#20307;&#30340;&#34920;&#31034;&#19982;&#26576;&#20123;&#22810;&#25968;&#32676;&#20307;&#30340;&#34920;&#31034;&#21512;&#24182;&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#29616;&#35937;&#31216;&#20026;&#34920;&#31034;&#20260;&#23475;&#65292;&#24182;&#22312;&#22270;&#20687;&#21644;&#25991;&#26412;&#25968;&#25454;&#38598;&#19978;&#20351;&#29992;&#30456;&#24212;&#30340;&#27969;&#34892;CL&#26041;&#27861;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;&#19979;&#28216;&#20998;&#31867;&#20219;&#21153;&#30340;&#20998;&#37197;&#20260;&#23475;&#36827;&#34892;&#20102;&#22240;&#26524;&#20013;&#20171;&#20998;&#26512;&#65292;&#32467;&#26524;&#34920;&#26126;&#34920;&#31034;&#20260;&#23475;&#22312;&#20854;&#20013;&#36215;&#21040;&#20102;&#19968;&#37096;&#20998;&#36131;&#20219;&#65292;&#20174;&#32780;&#24378;&#35843;&#20102;&#30740;&#31350;&#21644;&#32531;&#35299;&#34920;&#31034;&#20260;&#23475;&#30340;&#37325;&#35201;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#38543;&#26426;&#22359;&#27169;&#22411;&#23545;&#34920;&#31034;&#20260;&#23475;&#25552;&#20379;&#20102;&#29702;&#35770;&#35299;&#37322;&#65292;&#35813;&#27169;&#22411;&#23548;&#33268;&#23545;&#27604;&#23398;&#20064;&#29615;&#22659;&#19979;&#30340;&#34920;&#31034;&#31070;&#32463;&#32593;&#32476;&#23849;&#28291;&#12290;
&lt;/p&gt;
&lt;p&gt;
The effect of underrepresentation on the performance of minority groups is known to be a serious problem in supervised learning settings; however, it has been underexplored so far in the context of self-supervised learning (SSL). In this paper, we demonstrate that contrastive learning (CL), a popular variant of SSL, tends to collapse representations of minority groups with certain majority groups. We refer to this phenomenon as representation harm and demonstrate it on image and text datasets using the corresponding popular CL methods. Furthermore, our causal mediation analysis of allocation harm on a downstream classification task reveals that representation harm is partly responsible for it, thus emphasizing the importance of studying and mitigating representation harm. Finally, we provide a theoretical explanation for representation harm using a stochastic block model that leads to a representational neural collapse in a contrastive learning setting.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20026;&#25237;&#27880;&#32622;&#20449;&#21306;&#38388;&#30340;&#25913;&#36827;&#24615;&#33021;&#25552;&#20379;&#20102;&#29702;&#35770;&#35299;&#37322;&#65292;&#24182;&#27604;&#36739;&#20102;&#32463;&#20856;&#26041;&#27861;&#20013;&#30340;&#23485;&#24230;&#65292;&#21457;&#29616;&#25237;&#27880;&#32622;&#20449;&#21306;&#38388;&#20855;&#26377;&#36739;&#23567;&#30340;&#26497;&#38480;&#23485;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.01547</link><description>&lt;p&gt;
&#20851;&#20110;&#26377;&#30028;&#22343;&#20540;&#30340;&#25237;&#27880;&#32622;&#20449;&#21306;&#38388;&#30340;&#36817;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the near-optimality of betting confidence sets for bounded means. (arXiv:2310.01547v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01547
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20026;&#25237;&#27880;&#32622;&#20449;&#21306;&#38388;&#30340;&#25913;&#36827;&#24615;&#33021;&#25552;&#20379;&#20102;&#29702;&#35770;&#35299;&#37322;&#65292;&#24182;&#27604;&#36739;&#20102;&#32463;&#20856;&#26041;&#27861;&#20013;&#30340;&#23485;&#24230;&#65292;&#21457;&#29616;&#25237;&#27880;&#32622;&#20449;&#21306;&#38388;&#20855;&#26377;&#36739;&#23567;&#30340;&#26497;&#38480;&#23485;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32479;&#35745;&#23398;&#20013;&#65292;&#20174;&#29420;&#31435;&#21516;&#20998;&#24067;&#65288;i.i.d.&#65289;&#35266;&#27979;&#20013;&#26500;&#24314;&#19968;&#20803;&#20998;&#24067;&#30340;&#38750;&#28176;&#36817;&#32622;&#20449;&#21306;&#38388;&#65288;CI&#65289;&#26159;&#19968;&#39033;&#22522;&#26412;&#20219;&#21153;&#12290;&#23545;&#20110;&#26377;&#30028;&#35266;&#27979;&#20540;&#65292;&#32463;&#20856;&#30340;&#38750;&#21442;&#25968;&#26041;&#27861;&#36890;&#36807;&#21453;&#36716;&#26631;&#20934;&#27987;&#24230;&#30028;&#38480;&#65288;&#22914;Hoeffding&#25110;Bernstein&#19981;&#31561;&#24335;&#65289;&#26469;&#36827;&#34892;&#12290;&#26368;&#36817;&#65292;&#19968;&#31181;&#26367;&#20195;&#30340;&#22522;&#20110;&#25237;&#27880;&#30340;&#26041;&#27861;&#34987;&#29992;&#20110;&#23450;&#20041;CI&#21644;&#20854;&#26102;&#38388;&#19968;&#33268;&#21464;&#20307;&#65292;&#31216;&#20026;&#32622;&#20449;&#24207;&#21015;&#65288;CS&#65289;&#65292;&#24050;&#34987;&#35777;&#26126;&#22312;&#23454;&#35777;&#19978;&#20248;&#20110;&#32463;&#20856;&#26041;&#27861;&#12290;&#26412;&#25991;&#20026;&#36825;&#31181;&#25237;&#27880;CI&#21644;CS&#30340;&#25913;&#36827;&#32463;&#39564;&#24615;&#24615;&#33021;&#25552;&#20379;&#20102;&#29702;&#35770;&#19978;&#30340;&#35299;&#37322;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#22914;&#19979;&#65306;&#65288;i&#65289;&#25105;&#20204;&#39318;&#20808;&#27604;&#36739;CI&#65292;&#20351;&#29992;&#23427;&#20204;&#30340;&#19968;&#38454;&#28176;&#36817;&#23485;&#24230;&#30340;&#20540;&#65288;&#32463;&#36807;$\sqrt{n}$&#32553;&#25918;&#65289;&#65292;&#24182;&#19988;&#34920;&#26126;Waudby-Smith&#21644;Ramdas&#65288;2023&#65289;&#30340;&#25237;&#27880;CI&#27604;&#29616;&#26377;&#30340;&#32463;&#39564;Bernstein&#65288;EB&#65289;CI&#30340;&#26497;&#38480;&#23485;&#24230;&#26356;&#23567;&#12290;&#65288;ii&#65289;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#20004;&#20010;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
Constructing nonasymptotic confidence intervals (CIs) for the mean of a univariate distribution from independent and identically distributed (i.i.d.) observations is a fundamental task in statistics. For bounded observations, a classical nonparametric approach proceeds by inverting standard concentration bounds, such as Hoeffding's or Bernstein's inequalities. Recently, an alternative betting-based approach for defining CIs and their time-uniform variants called confidence sequences (CSs), has been shown to be empirically superior to the classical methods. In this paper, we provide theoretical justification for this improved empirical performance of betting CIs and CSs.  Our main contributions are as follows: (i) We first compare CIs using the values of their first-order asymptotic widths (scaled by $\sqrt{n}$), and show that the betting CI of Waudby-Smith and Ramdas (2023) has a smaller limiting width than existing empirical Bernstein (EB)-CIs. (ii) Next, we establish two lower bounds
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#27169;&#22411;&#26080;&#20851;&#30340;&#26102;&#38388;&#22495;&#27867;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#27010;&#24565;&#28418;&#31227;&#27169;&#25311;&#22120;&#26469;&#35299;&#20915;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#20013;&#30340;&#27010;&#24565;&#28418;&#31227;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.01508</link><description>&lt;p&gt;
CODA: &#36890;&#36807;&#27010;&#24565;&#28418;&#31227;&#27169;&#25311;&#22120;&#23454;&#29616;&#26102;&#38388;&#22495;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
CODA: Temporal Domain Generalization via Concept Drift Simulator. (arXiv:2310.01508v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01508
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#27169;&#22411;&#26080;&#20851;&#30340;&#26102;&#38388;&#22495;&#27867;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#27010;&#24565;&#28418;&#31227;&#27169;&#25311;&#22120;&#26469;&#35299;&#20915;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#20013;&#30340;&#27010;&#24565;&#28418;&#31227;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#20013;&#65292;&#30001;&#20110;&#24213;&#23618;&#26102;&#38388;&#36235;&#21183;&#24341;&#36215;&#30340;&#32852;&#21512;&#20998;&#24067;&#30340;&#21464;&#21270;&#65292;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#24448;&#24448;&#21464;&#24471;&#36807;&#26102;&#65292;&#36825;&#31181;&#29616;&#35937;&#34987;&#31216;&#20026;&#8220;&#27010;&#24565;&#28418;&#31227;&#8221;&#12290;&#29616;&#26377;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#27169;&#22411;&#29305;&#23450;&#30340;&#31574;&#30053;&#65292;&#23454;&#29616;&#22312;&#36817;&#26399;&#39046;&#22495;&#30340;&#26102;&#38388;&#27867;&#21270;&#12290;&#28982;&#32780;&#65292;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#30340;&#22810;&#26679;&#24615;&#35201;&#27714;&#23450;&#21046;&#21270;&#30340;&#39044;&#27979;&#27169;&#22411;&#20307;&#31995;&#32467;&#26500;&#12290;&#20026;&#27492;&#65292;&#36843;&#20999;&#38656;&#35201;&#19968;&#31181;&#27169;&#22411;&#26080;&#20851;&#30340;&#26102;&#38388;&#22495;&#27867;&#21270;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#19981;&#21516;&#30340;&#25968;&#25454;&#27169;&#24577;&#21644;&#20307;&#31995;&#32467;&#26500;&#20043;&#38388;&#20445;&#25345;&#26222;&#36941;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#20174;&#25968;&#25454;&#20013;&#24515;&#30340;&#35282;&#24230;&#35299;&#20915;&#27010;&#24565;&#28418;&#31227;&#38382;&#39064;&#65292;&#32469;&#36807;&#32771;&#34385;&#25968;&#25454;&#21644;&#27169;&#22411;&#20043;&#38388;&#30340;&#20132;&#20114;&#12290;&#24320;&#21457;&#36825;&#26679;&#30340;&#26694;&#26550;&#38754;&#20020;&#30528;&#37325;&#35201;&#30340;&#25361;&#25112;&#65306;(i)&#29616;&#26377;&#30340;&#29983;&#25104;&#27169;&#22411;&#38590;&#20197;&#29983;&#25104;&#36229;&#20986;&#20998;&#24067;&#20043;&#22806;&#30340;&#26410;&#26469;&#25968;&#25454;&#65292;(ii)&#20934;&#30830;&#25429;&#25417;&#27839;&#26102;&#38388;&#39034;&#24207;&#30340;&#32852;&#21512;&#20998;&#24067;&#30340;&#26102;&#38388;&#36235;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
In real-world applications, machine learning models often become obsolete due to shifts in the joint distribution arising from underlying temporal trends, a phenomenon known as the "concept drift". Existing works propose model-specific strategies to achieve temporal generalization in the near-future domain. However, the diverse characteristics of real-world datasets necessitate customized prediction model architectures. To this end, there is an urgent demand for a model-agnostic temporal domain generalization approach that maintains generality across diverse data modalities and architectures. In this work, we aim to address the concept drift problem from a data-centric perspective to bypass considering the interaction between data and model. Developing such a framework presents non-trivial challenges: (i) existing generative models struggle to generate out-of-distribution future data, and (ii) precisely capturing the temporal trends of joint distribution along chronological source doma
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#25512;&#23548;&#20219;&#24847;&#26377;&#38480;&#31209;&#26680;&#23725;&#22238;&#24402;&#27169;&#22411;&#30340;&#23574;&#38160;&#30340;&#38750;&#28176;&#36817;&#24615;&#19978;&#30028;&#21644;&#19979;&#30028;&#65292;&#22635;&#34917;&#20102;&#26377;&#38480;&#31209;&#26680;&#23725;&#22238;&#24402;&#20445;&#35777;&#30340;&#31354;&#30333;&#12290;</title><link>http://arxiv.org/abs/2310.00987</link><description>&lt;p&gt;
&#26377;&#38480;&#31209;&#26680;&#23725;&#22238;&#24402;&#30340;&#27979;&#35797;&#35823;&#24046;&#30340;&#29702;&#35770;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A Theoretical Analysis of the Test Error of Finite-Rank Kernel Ridge Regression. (arXiv:2310.00987v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00987
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#25512;&#23548;&#20219;&#24847;&#26377;&#38480;&#31209;&#26680;&#23725;&#22238;&#24402;&#27169;&#22411;&#30340;&#23574;&#38160;&#30340;&#38750;&#28176;&#36817;&#24615;&#19978;&#30028;&#21644;&#19979;&#30028;&#65292;&#22635;&#34917;&#20102;&#26377;&#38480;&#31209;&#26680;&#23725;&#22238;&#24402;&#20445;&#35777;&#30340;&#31354;&#30333;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#23545;&#20110;&#19968;&#33324;&#26680;&#22238;&#24402;&#27169;&#22411;&#30340;&#32479;&#35745;&#23398;&#23398;&#20064;&#20445;&#35777;&#22312;&#20351;&#29992;&#26377;&#38480;&#31209;&#26680;&#26102;&#24448;&#24448;&#20250;&#24471;&#21040;&#23485;&#26494;&#30340;&#36793;&#30028;&#12290;&#28982;&#32780;&#65292;&#22312;&#20960;&#20010;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#65292;&#22914;&#22312;&#25191;&#34892;&#36801;&#31227;&#23398;&#20064;&#26102;&#65292;&#23558;&#39044;&#35757;&#32451;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#21518;&#19968;&#23618;&#24494;&#35843;&#20197;&#36866;&#24212;&#26032;&#20219;&#21153;&#26102;&#65292;&#26377;&#38480;&#31209;&#26680;&#20250;&#33258;&#28982;&#22320;&#20986;&#29616;&#12290;&#26412;&#25991;&#36890;&#36807;&#25512;&#23548;&#20219;&#24847;&#26377;&#38480;&#31209;&#26680;&#23725;&#22238;&#24402;&#27169;&#22411;&#30340;&#23574;&#38160;&#30340;&#38750;&#28176;&#36817;&#24615;&#19978;&#30028;&#21644;&#19979;&#30028;&#65292;&#22635;&#34917;&#20102;&#26377;&#38480;&#31209;&#26680;&#23725;&#22238;&#24402;&#20445;&#35777;&#30340;&#31354;&#30333;&#12290;&#25105;&#20204;&#30340;&#36793;&#30028;&#27604;&#20043;&#21069;&#38024;&#23545;&#26377;&#38480;&#31209;&#26680;&#23725;&#22238;&#24402;&#27169;&#22411;&#25512;&#23548;&#30340;&#36793;&#30028;&#26356;&#32039;&#65292;&#24182;&#19988;&#19982;&#31867;&#20284;&#32467;&#26524;&#19981;&#21516;&#30340;&#26159;&#65292;&#23427;&#20204;&#20063;&#36866;&#29992;&#20110;&#20219;&#20309;&#27491;&#21017;&#21270;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing statistical learning guarantees for general kernel regressors often yield loose bounds when used with finite-rank kernels. Yet, finite-rank kernels naturally appear in several machine learning problems, e.g.\ when fine-tuning a pre-trained deep neural network's last layer to adapt it to a novel task when performing transfer learning. We address this gap for finite-rank kernel ridge regression (KRR) by deriving sharp non-asymptotic upper and lower bounds for the KRR test error of any finite-rank KRR. Our bounds are tighter than previously derived bounds on finite-rank KRR, and unlike comparable results, they also remain valid for any regularization parameters.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#29983;&#25104;&#27169;&#22411;&#22312;&#28151;&#21512;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#23545;&#31283;&#23450;&#24615;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#35777;&#26126;&#21021;&#22987;&#29983;&#25104;&#27169;&#22411;&#36275;&#22815;&#25509;&#36817;&#25968;&#25454;&#20998;&#24067;&#24182;&#19988;&#25968;&#25454;&#27604;&#20363;&#36866;&#24403;&#65292;&#36845;&#20195;&#35757;&#32451;&#26159;&#31283;&#23450;&#30340;&#12290;</title><link>http://arxiv.org/abs/2310.00429</link><description>&lt;p&gt;
&#20851;&#20110;&#29983;&#25104;&#27169;&#22411;&#22312;&#20854;&#33258;&#24049;&#30340;&#25968;&#25454;&#19978;&#36845;&#20195;&#35757;&#32451;&#30340;&#31283;&#23450;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Stability of Iterative Retraining of Generative Models on their own Data. (arXiv:2310.00429v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00429
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#29983;&#25104;&#27169;&#22411;&#22312;&#28151;&#21512;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#23545;&#31283;&#23450;&#24615;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#35777;&#26126;&#21021;&#22987;&#29983;&#25104;&#27169;&#22411;&#36275;&#22815;&#25509;&#36817;&#25968;&#25454;&#20998;&#24067;&#24182;&#19988;&#25968;&#25454;&#27604;&#20363;&#36866;&#24403;&#65292;&#36845;&#20195;&#35757;&#32451;&#26159;&#31283;&#23450;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#22312;&#24314;&#27169;&#22797;&#26434;&#25968;&#25454;&#26041;&#38754;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#36827;&#23637;&#65292;&#24448;&#24448;&#23637;&#29616;&#20986;&#36229;&#36807;&#20856;&#22411;&#20154;&#31867;&#33021;&#21147;&#30340;&#26679;&#26412;&#30495;&#23454;&#24615;&#36776;&#21035;&#33021;&#21147;&#12290;&#36825;&#19968;&#25104;&#21151;&#30340;&#20851;&#38190;&#39537;&#21160;&#21147;&#26080;&#30097;&#26159;&#36825;&#20123;&#27169;&#22411;&#28040;&#32791;&#28023;&#37327;&#32593;&#32476;&#35268;&#27169;&#25968;&#25454;&#30340;&#32467;&#26524;&#12290;&#30001;&#20110;&#36825;&#20123;&#27169;&#22411;&#24778;&#20154;&#30340;&#24615;&#33021;&#21644;&#26131;&#24471;&#24615;&#65292;&#32593;&#32476;&#19978;&#23558;&#19981;&#21487;&#36991;&#20813;&#22320;&#20986;&#29616;&#36234;&#26469;&#36234;&#22810;&#30340;&#21512;&#25104;&#20869;&#23481;&#12290;&#36825;&#20010;&#20107;&#23454;&#30452;&#25509;&#24847;&#21619;&#30528;&#29983;&#25104;&#27169;&#22411;&#30340;&#26410;&#26469;&#36845;&#20195;&#24517;&#39035;&#38754;&#23545;&#19968;&#20010;&#29616;&#23454;&#65306;&#23427;&#20204;&#30340;&#35757;&#32451;&#25968;&#25454;&#30001;&#28165;&#27905;&#25968;&#25454;&#21644;&#20808;&#21069;&#27169;&#22411;&#29983;&#25104;&#30340;&#20154;&#24037;&#25968;&#25454;&#32452;&#25104;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#26694;&#26550;&#26469;&#23545;&#28151;&#21512;&#25968;&#25454;&#38598;&#65288;&#21253;&#25324;&#30495;&#23454;&#25968;&#25454;&#21644;&#21512;&#25104;&#25968;&#25454;&#65289;&#19978;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#23545;&#31283;&#23450;&#24615;&#30340;&#24433;&#21709;&#36827;&#34892;&#20005;&#26684;&#30740;&#31350;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#22312;&#21021;&#22987;&#29983;&#25104;&#27169;&#22411;&#36275;&#22815;&#22909;&#22320;&#36817;&#20284;&#25968;&#25454;&#20998;&#24067;&#24182;&#19988;&#30495;&#23454;&#25968;&#25454;&#19982;&#21512;&#25104;&#25968;&#25454;&#30340;&#27604;&#20363;&#36866;&#24403;&#30340;&#24773;&#20917;&#19979;&#65292;&#36845;&#20195;&#35757;&#32451;&#30340;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep generative models have made tremendous progress in modeling complex data, often exhibiting generation quality that surpasses a typical human's ability to discern the authenticity of samples. Undeniably, a key driver of this success is enabled by the massive amounts of web-scale data consumed by these models. Due to these models' striking performance and ease of availability, the web will inevitably be increasingly populated with synthetic content. Such a fact directly implies that future iterations of generative models must contend with the reality that their training is curated from both clean data and artificially generated data from past models. In this paper, we develop a framework to rigorously study the impact of training generative models on mixed datasets (of real and synthetic data) on their stability. We first prove the stability of iterative training under the condition that the initial generative models approximate the data distribution well enough and the proportion o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#39640;&#32500;&#24230;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#20013;&#24322;&#26041;&#24046;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22522;&#20110;&#20998;&#21306;&#32463;&#39564;&#36125;&#21494;&#26031;ECM&#31639;&#27861;&#30340;&#24322;&#26041;&#24046;&#39640;&#32500;&#24230;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#26469;&#23454;&#29616;&#12290;&#36825;&#20010;&#27169;&#22411;&#21487;&#20197;&#22788;&#29702;&#27531;&#24046;&#26041;&#24046;&#19981;&#24658;&#23450;&#30340;&#24773;&#20917;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#25554;&#20540;&#30340;&#32463;&#39564;&#36125;&#21494;&#26031;&#20272;&#35745;&#36229;&#21442;&#25968;&#26469;&#28789;&#27963;&#22320;&#35843;&#25972;&#26041;&#24046;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2309.08783</link><description>&lt;p&gt;
&#39640;&#32500;&#24230;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#24322;&#26041;&#24046;&#38382;&#39064;&#21450;&#22522;&#20110;&#20998;&#21306;&#32463;&#39564;&#36125;&#21494;&#26031;ECM&#31639;&#27861;&#30340;&#35299;&#20915;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Heteroscedastic sparse high-dimensional linear regression with a partitioned empirical Bayes ECM algorithm. (arXiv:2309.08783v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08783
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#39640;&#32500;&#24230;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#20013;&#24322;&#26041;&#24046;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22522;&#20110;&#20998;&#21306;&#32463;&#39564;&#36125;&#21494;&#26031;ECM&#31639;&#27861;&#30340;&#24322;&#26041;&#24046;&#39640;&#32500;&#24230;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#26469;&#23454;&#29616;&#12290;&#36825;&#20010;&#27169;&#22411;&#21487;&#20197;&#22788;&#29702;&#27531;&#24046;&#26041;&#24046;&#19981;&#24658;&#23450;&#30340;&#24773;&#20917;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#25554;&#20540;&#30340;&#32463;&#39564;&#36125;&#21494;&#26031;&#20272;&#35745;&#36229;&#21442;&#25968;&#26469;&#28789;&#27963;&#22320;&#35843;&#25972;&#26041;&#24046;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#24230;&#25968;&#25454;&#30340;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#26041;&#27861;&#36890;&#24120;&#20551;&#35774;&#27531;&#24046;&#20855;&#26377;&#24120;&#25968;&#26041;&#24046;&#12290;&#24403;&#36825;&#19968;&#20551;&#35774;&#34987;&#36829;&#32972;&#26102;&#65292;&#20250;&#23548;&#33268;&#20272;&#35745;&#31995;&#25968;&#30340;&#20559;&#24046;&#65292;&#39044;&#27979;&#21306;&#38388;&#38271;&#24230;&#19981;&#21512;&#36866;&#20197;&#21450;&#22686;&#21152;I&#22411;&#38169;&#35823;&#12290;&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20998;&#21306;&#32463;&#39564;&#36125;&#21494;&#26031;&#26399;&#26395;&#26465;&#20214;&#26368;&#22823;&#21270;(H-PROBE)&#31639;&#27861;&#30340;&#24322;&#26041;&#24046;&#39640;&#32500;&#24230;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#12290;H-PROBE&#26159;&#19968;&#31181;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#26368;&#22823;&#21518;&#39564;&#20272;&#35745;&#26041;&#27861;&#65292;&#22522;&#20110;&#21442;&#25968;&#25193;&#23637;&#30340;&#26399;&#26395;&#26465;&#20214;&#26368;&#22823;&#21270;(PX-ECM)&#31639;&#27861;&#12290;&#23427;&#36890;&#36807;&#25554;&#20540;&#30340;&#32463;&#39564;&#36125;&#21494;&#26031;&#20272;&#35745;&#36229;&#21442;&#25968;&#65292;&#22312;&#22238;&#24402;&#21442;&#25968;&#19978;&#20551;&#35774;&#26368;&#23567;&#12290;&#26041;&#24046;&#27169;&#22411;&#20351;&#29992;&#20102;&#22810;&#20803;&#23545;&#25968;&#20285;&#39532;&#20998;&#24067;&#29702;&#35770;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24182;&#21487;&#20197;&#21253;&#21547;&#20551;&#35774;&#20250;&#24433;&#21709;&#24322;&#36136;&#24615;&#30340;&#21327;&#21464;&#37327;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#21160;&#26426;&#26159;&#36890;&#36807;T2&#39640;&#20998;&#36776;&#29575;&#31070;&#32463;&#24433;&#20687;&#30740;&#31350;&#19982;&#22833;&#35821;&#25351;&#25968;(AQ)&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse linear regression methods for high-dimensional data often assume that residuals have constant variance. When this assumption is violated, it can lead to bias in estimated coefficients, prediction intervals with improper length, and increased type I errors. This paper proposes a heteroscedastic (H) high-dimensional linear regression model through a partitioned empirical Bayes Expectation Conditional Maximization (H-PROBE) algorithm. H-PROBE is a computationally efficient maximum a posteriori (MAP) estimation approach based on a Parameter-Expanded Expectation-Conditional-Maximization (PX-ECM) algorithm. It requires minimal prior assumptions on the regression parameters through plug-in empirical Bayes estimates of hyperparameters. The variance model uses recent advances in multivariate log-Gamma distribution theory and can include covariates hypothesized to impact heterogeneity. The motivation of our approach is a study relating Aphasia Quotient (AQ) to high-resolution T2 neuroimag
&lt;/p&gt;</description></item><item><title>RCS-YOLO&#26159;&#19968;&#31181;&#24555;&#36895;&#19988;&#39640;&#20934;&#30830;&#24615;&#30340;&#33041;&#32959;&#30244;&#26816;&#27979;&#29289;&#20307;&#26816;&#27979;&#22120;&#65292;&#36890;&#36807;&#24341;&#20837;Reparameterized Convolution&#21644;RCS-OSA&#25216;&#26415;&#65292;&#25552;&#39640;&#20102;YOLO&#26694;&#26550;&#22312;&#22788;&#29702;&#33041;&#32959;&#30244;&#26816;&#27979;&#20013;&#30340;&#24615;&#33021;&#65292;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#27700;&#24179;&#12290;</title><link>http://arxiv.org/abs/2307.16412</link><description>&lt;p&gt;
RCS-YOLO: &#19968;&#31181;&#24555;&#36895;&#19988;&#39640;&#20934;&#30830;&#24615;&#30340;&#33041;&#32959;&#30244;&#26816;&#27979;&#29289;&#20307;&#26816;&#27979;&#22120;
&lt;/p&gt;
&lt;p&gt;
RCS-YOLO: A Fast and High-Accuracy Object Detector for Brain Tumor Detection. (arXiv:2307.16412v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16412
&lt;/p&gt;
&lt;p&gt;
RCS-YOLO&#26159;&#19968;&#31181;&#24555;&#36895;&#19988;&#39640;&#20934;&#30830;&#24615;&#30340;&#33041;&#32959;&#30244;&#26816;&#27979;&#29289;&#20307;&#26816;&#27979;&#22120;&#65292;&#36890;&#36807;&#24341;&#20837;Reparameterized Convolution&#21644;RCS-OSA&#25216;&#26415;&#65292;&#25552;&#39640;&#20102;YOLO&#26694;&#26550;&#22312;&#22788;&#29702;&#33041;&#32959;&#30244;&#26816;&#27979;&#20013;&#30340;&#24615;&#33021;&#65292;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#36895;&#24230;&#21644;&#20934;&#30830;&#24615;&#20043;&#38388;&#30340;&#20986;&#33394;&#24179;&#34913;&#65292;&#20808;&#36827;&#30340;YOLO&#26694;&#26550;&#24050;&#25104;&#20026;&#26368;&#39640;&#25928;&#30340;&#29289;&#20307;&#26816;&#27979;&#31639;&#27861;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#22312;&#33041;&#32959;&#30244;&#26816;&#27979;&#20013;&#65292;&#20351;&#29992;YOLO&#32593;&#32476;&#30340;&#24615;&#33021;&#24456;&#23569;&#21463;&#21040;&#30740;&#31350;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Reparameterized Convolution&#30340;RCS-YOLO&#30340;&#26032;&#22411;YOLO&#26550;&#26500;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;RCS&#21644;RCS&#30340;&#19968;&#27425;&#24615;&#32858;&#21512;(RCS-OSA)&#65292;&#23427;&#23558;&#29305;&#24449;&#32423;&#32852;&#21644;&#35745;&#31639;&#25928;&#29575;&#30456;&#32467;&#21512;&#65292;&#20197;&#25552;&#21462;&#26356;&#20016;&#23500;&#30340;&#20449;&#24687;&#24182;&#20943;&#23569;&#26102;&#38388;&#28040;&#32791;&#12290;&#22312;&#33041;&#32959;&#30244;&#25968;&#25454;&#38598;Br35H&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#22312;&#36895;&#24230;&#21644;&#20934;&#30830;&#24615;&#19978;&#36229;&#36807;&#20102;YOLOv6&#65292;YOLOv7&#21644;YOLOv8&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#19982;YOLOv7&#30456;&#27604;&#65292;RCS-YOLO&#30340;&#31934;&#24230;&#25552;&#39640;&#20102;2.6&#65285;&#65292;&#25512;&#26029;&#36895;&#24230;&#25552;&#39640;&#20102;60&#65285;&#65292;&#36798;&#21040;&#27599;&#31186;114.8&#24352;&#22270;&#20687;&#26816;&#27979;&#65288;FPS&#65289;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;RCS-YOLO&#22312;&#33041;&#32959;&#30244;&#26816;&#27979;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#20195;&#30721;&#21487;&#22312;https://github.com/mkang315/RCS-YOLO&#33719;&#21462;&#12290;
&lt;/p&gt;
&lt;p&gt;
With an excellent balance between speed and accuracy, cutting-edge YOLO frameworks have become one of the most efficient algorithms for object detection. However, the performance of using YOLO networks is scarcely investigated in brain tumor detection. We propose a novel YOLO architecture with Reparameterized Convolution based on channel Shuffle (RCS-YOLO). We present RCS and a One-Shot Aggregation of RCS (RCS-OSA), which link feature cascade and computation efficiency to extract richer information and reduce time consumption. Experimental results on the brain tumor dataset Br35H show that the proposed model surpasses YOLOv6, YOLOv7, and YOLOv8 in speed and accuracy. Notably, compared with YOLOv7, the precision of RCS-YOLO improves by 2.6%, and the inference speed by 60% at 114.8 images detected per second (FPS). Our proposed RCS-YOLO achieves state-of-the-art performance on the brain tumor detection task. The code is available at https://github.com/mkang315/RCS-YOLO.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#20855;&#26377;&#34987;&#31713;&#25913;&#30340;&#20108;&#36827;&#21046;&#20449;&#21495;&#30340;Lipschitz&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#33104;&#36133;&#40065;&#26834;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#22312;&#19981;&#21516;&#25439;&#22833;&#20989;&#25968;&#19979;&#23454;&#29616;&#20102;&#19981;&#21516;&#31243;&#24230;&#30340;&#21518;&#24724;&#12290;</title><link>http://arxiv.org/abs/2307.13903</link><description>&lt;p&gt;
&#33104;&#36133;&#40065;&#26834;&#30340;Lipschitz&#19978;&#19979;&#25991;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
Corruption-Robust Lipschitz Contextual Search. (arXiv:2307.13903v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13903
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#20855;&#26377;&#34987;&#31713;&#25913;&#30340;&#20108;&#36827;&#21046;&#20449;&#21495;&#30340;Lipschitz&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#33104;&#36133;&#40065;&#26834;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#22312;&#19981;&#21516;&#25439;&#22833;&#20989;&#25968;&#19979;&#23454;&#29616;&#20102;&#19981;&#21516;&#31243;&#24230;&#30340;&#21518;&#24724;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#30740;&#31350;&#20102;&#23398;&#20064;&#20855;&#26377;&#34987;&#31713;&#25913;&#30340;&#20108;&#36827;&#21046;&#20449;&#21495;&#30340;Lipschitz&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;&#23398;&#20064;&#32773;&#35797;&#22270;&#23398;&#20064;&#19968;&#20010;&#30001;&#23545;&#25163;&#36873;&#25321;&#30340;Lipschitz&#20989;&#25968;$f$&#12290;&#22312;&#27599;&#19968;&#36718;&#20013;&#65292;&#23545;&#25163;&#22312;&#36755;&#20837;&#31354;&#38388;&#20013;&#36873;&#25321;&#19968;&#20010;&#19978;&#19979;&#25991;&#21521;&#37327;$x_t$&#65292;&#23398;&#20064;&#32773;&#23545;&#30495;&#23454;&#20989;&#25968;&#20540;$f(x_t)$&#36827;&#34892;&#29468;&#27979;&#65292;&#24182;&#25509;&#25910;&#19968;&#20010;&#25351;&#31034;&#29468;&#27979;&#26159;&#39640;&#36824;&#26159;&#20302;&#30340;&#20108;&#36827;&#21046;&#20449;&#21495;&#12290;&#22312;&#24635;&#20849;$C$&#36718;&#20013;&#65292;&#20449;&#21495;&#21487;&#33021;&#34987;&#31713;&#25913;&#65292;&#20294;&#23398;&#20064;&#32773;&#19981;&#30693;&#36947;$C$&#30340;&#20540;&#12290;&#23398;&#20064;&#32773;&#30340;&#30446;&#26631;&#26159;&#36896;&#25104;&#23567;&#30340;&#32047;&#31215;&#25439;&#22833;&#12290;&#25105;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#28982;&#32780;&#24378;&#22823;&#30340;&#25216;&#26415;&#39564;&#35777;&#65292;&#23545;&#35774;&#35745;&#33104;&#36133;&#40065;&#26834;&#31639;&#27861;&#38750;&#24120;&#26377;&#29992;&#12290;&#25105;&#35774;&#35745;&#20102;&#19968;&#20123;&#31639;&#27861;&#65288;&#23558;Lipschitz&#21442;&#25968;$L$&#35270;&#20026;&#24120;&#25968;&#65289;&#65306;&#23545;&#20110;&#23545;&#31216;&#25439;&#22833;&#65292;&#23398;&#20064;&#32773;&#22312;$d=1$&#26102;&#36798;&#21040;&#21518;&#24724;$O(C\log T)$&#65292;&#22312;$d&gt;1$&#26102;&#36798;&#21040;&#21518;&#24724;$O_d(C\log T + T^{(d-1)/d})$&#65307;&#23545;&#20110;&#35745;&#20215;&#25439;&#22833;&#65292;&#23398;&#20064;&#32773;&#22312;$d/(d+1)$&#26102;&#36798;&#21040;&#21518;&#24724;$\widetilde{O}(T^{d/(d+1)} + C\cdot T^{1/(d+1)})$&#12290;
&lt;/p&gt;
&lt;p&gt;
I study the problem of learning a Lipschitz function with corrupted binary signals. The learner tries to learn a Lipschitz function $f$ that the adversary chooses. In each round, the adversary selects a context vector $x_t$ in the input space, and the learner makes a guess to the true function value $f(x_t)$ and receives a binary signal indicating whether the guess was high or low. In a total of $C$ rounds, the signal may be corrupted, though the value of $C$ is unknown to the learner. The learner's goal is to incur a small cumulative loss. I present a natural yet powerful technique sanity check, which proves useful in designing corruption-robust algorithms. I design algorithms which (treating the Lipschitz parameter $L$ as constant): for the symmetric loss, the learner achieves regret $O(C\log T)$ with $d = 1$ and $O_d(C\log T + T^{(d-1)/d})$ with $d &gt; 1$; for the pricing loss the learner achieves regret $\widetilde{O} (T^{d/(d+1)} + C\cdot T^{1/(d+1)})$.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;OpenDataVal&#30340;&#22522;&#20934;&#27979;&#35797;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#25972;&#21512;&#20102;&#22810;&#31181;&#25968;&#25454;&#38598;&#21644;&#20061;&#31181;&#26368;&#20808;&#36827;&#30340;&#25968;&#25454;&#20272;&#20540;&#31639;&#27861;&#23454;&#29616;&#65292;&#24182;&#25552;&#20379;&#20102;&#22235;&#20010;&#19979;&#28216;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#26469;&#35780;&#20272;&#25968;&#25454;&#20215;&#20540;&#30340;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2306.10577</link><description>&lt;p&gt;
OpenDataVal&#65306;&#19968;&#31181;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#30340;&#32479;&#19968;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
OpenDataVal: a Unified Benchmark for Data Valuation. (arXiv:2306.10577v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10577
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;OpenDataVal&#30340;&#22522;&#20934;&#27979;&#35797;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#25972;&#21512;&#20102;&#22810;&#31181;&#25968;&#25454;&#38598;&#21644;&#20061;&#31181;&#26368;&#20808;&#36827;&#30340;&#25968;&#25454;&#20272;&#20540;&#31639;&#27861;&#23454;&#29616;&#65292;&#24182;&#25552;&#20379;&#20102;&#22235;&#20010;&#19979;&#28216;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#26469;&#35780;&#20272;&#25968;&#25454;&#20215;&#20540;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#21333;&#20010;&#25968;&#25454;&#28857;&#30340;&#36136;&#37327;&#21644;&#24433;&#21709;&#23545;&#20110;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#21644;&#20943;&#36731;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#19981;&#33391;&#20559;&#24046;&#33267;&#20851;&#37325;&#35201;&#12290;&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#20102;&#20960;&#20010;&#25968;&#25454;&#20272;&#20540;&#31639;&#27861;&#26469;&#37327;&#21270;&#25968;&#25454;&#36136;&#37327;&#65292;&#20294;&#36824;&#32570;&#20047;&#19968;&#20010;&#31995;&#32479;&#21270;&#21644;&#26631;&#20934;&#21270;&#30340;&#25968;&#25454;&#20272;&#20540;&#22522;&#20934;&#27979;&#35797;&#31995;&#32479;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;OpenDataVal&#65292;&#19968;&#31181;&#26131;&#20110;&#20351;&#29992;&#21644;&#32479;&#19968;&#30340;&#22522;&#20934;&#27979;&#35797;&#26694;&#26550;&#65292;&#20351;&#30740;&#31350;&#20154;&#21592;&#21644;&#20174;&#19994;&#32773;&#33021;&#22815;&#24212;&#29992;&#21644;&#27604;&#36739;&#21508;&#31181;&#25968;&#25454;&#20272;&#20540;&#31639;&#27861;&#12290;OpenDataVal&#25552;&#20379;&#20102;&#19968;&#20010;&#32508;&#21512;&#29615;&#22659;&#65292;&#21253;&#25324;&#65288;i&#65289;&#21508;&#31181;&#22270;&#20687;&#65292;&#33258;&#28982;&#35821;&#35328;&#21644;&#34920;&#26684;&#25968;&#25454;&#38598;&#65292;&#65288;ii&#65289;&#20061;&#31181;&#19981;&#21516;&#30340;&#26368;&#20808;&#36827;&#30340;&#25968;&#25454;&#20272;&#20540;&#31639;&#27861;&#30340;&#23454;&#29616;&#65292;&#20197;&#21450;&#65288;iii&#65289;&#21487;&#20197;&#23548;&#20837;&#20219;&#20309;scikit-learn&#27169;&#22411;&#30340;&#39044;&#27979;&#27169;&#22411;API&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22235;&#20010;&#19979;&#28216;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#29992;&#20110;&#35780;&#20272;&#25968;&#25454;&#20540;&#30340;&#36136;&#37327;&#12290;&#25105;&#20204;&#20351;&#29992;OpenDataVal&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#20998;&#26512;&#65292;&#37327;&#21270;&#24182;&#27604;&#36739;&#19981;&#21516;&#25968;&#25454;&#20272;&#20540;&#31639;&#27861;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Assessing the quality and impact of individual data points is critical for improving model performance and mitigating undesirable biases within the training dataset. Several data valuation algorithms have been proposed to quantify data quality, however, there lacks a systemic and standardized benchmarking system for data valuation. In this paper, we introduce OpenDataVal, an easy-to-use and unified benchmark framework that empowers researchers and practitioners to apply and compare various data valuation algorithms. OpenDataVal provides an integrated environment that includes (i) a diverse collection of image, natural language, and tabular datasets, (ii) implementations of nine different state-of-the-art data valuation algorithms, and (iii) a prediction model API that can import any models in scikit-learn. Furthermore, we propose four downstream machine learning tasks for evaluating the quality of data values. We perform benchmarking analysis using OpenDataVal, quantifying and comparin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#34920;&#31034;&#30340;&#26032;&#22411;&#25955;&#24230;&#8212;&#8212;&#34920;&#31034;Jensen-Shannon&#25955;&#24230;&#65292;&#36890;&#36807;&#23558;&#25968;&#25454;&#20998;&#24067;&#23884;&#20837;&#21040;RKHS&#20013;&#65292;&#24182;&#21033;&#29992;&#34920;&#31034;&#30340;&#21327;&#26041;&#24046;&#31639;&#23376;&#30340;&#39057;&#35889;&#65292;&#23454;&#29616;&#23545;&#25968;&#25454;&#20998;&#24067;&#30340;&#20272;&#35745;&#65292;&#24182;&#25552;&#20379;&#20102;&#20855;&#26377;&#28789;&#27963;&#24615;&#65292;&#21487;&#25193;&#23637;&#24615;&#65292;&#21487;&#24494;&#20998;&#24615;&#30340;&#32463;&#39564;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#20989;&#25968;&#21644;&#22522;&#20110;&#26680;&#30697;&#38453;&#30340;&#20272;&#35745;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2305.16446</link><description>&lt;p&gt;
&#22522;&#20110;&#34920;&#31034;&#30340;Jensen-Shannon&#25955;&#24230;
&lt;/p&gt;
&lt;p&gt;
The Representation Jensen-Shannon Divergence. (arXiv:2305.16446v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16446
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#34920;&#31034;&#30340;&#26032;&#22411;&#25955;&#24230;&#8212;&#8212;&#34920;&#31034;Jensen-Shannon&#25955;&#24230;&#65292;&#36890;&#36807;&#23558;&#25968;&#25454;&#20998;&#24067;&#23884;&#20837;&#21040;RKHS&#20013;&#65292;&#24182;&#21033;&#29992;&#34920;&#31034;&#30340;&#21327;&#26041;&#24046;&#31639;&#23376;&#30340;&#39057;&#35889;&#65292;&#23454;&#29616;&#23545;&#25968;&#25454;&#20998;&#24067;&#30340;&#20272;&#35745;&#65292;&#24182;&#25552;&#20379;&#20102;&#20855;&#26377;&#28789;&#27963;&#24615;&#65292;&#21487;&#25193;&#23637;&#24615;&#65292;&#21487;&#24494;&#20998;&#24615;&#30340;&#32463;&#39564;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#20989;&#25968;&#21644;&#22522;&#20110;&#26680;&#30697;&#38453;&#30340;&#20272;&#35745;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32479;&#35745;&#25955;&#24230;&#37327;&#21270;&#27010;&#29575;&#20998;&#24067;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#31181;&#37325;&#35201;&#26041;&#27861;&#12290;&#20294;&#26159;&#65292;&#30001;&#20110;&#25968;&#25454;&#30340;&#24213;&#23618;&#20998;&#24067;&#36890;&#24120;&#26410;&#30693;&#65292;&#20174;&#32463;&#39564;&#26679;&#26412;&#20013;&#20272;&#35745;&#25955;&#24230;&#26159;&#19968;&#20010;&#22522;&#26412;&#38590;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;(RKHS)&#20013;&#21327;&#26041;&#24046;&#31639;&#23376;&#30340;&#26032;&#22411;&#25955;&#24230;&#8212;&#8212;&#34920;&#31034;Jensen-Shannon&#25955;&#24230;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#25968;&#25454;&#20998;&#24067;&#23884;&#20837;&#21040;RKHS&#20013;&#65292;&#24182;&#21033;&#29992;&#34920;&#31034;&#30340;&#21327;&#26041;&#24046;&#31639;&#23376;&#30340;&#39057;&#35889;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#20174;&#32463;&#39564;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#30340;&#20272;&#35745;&#20989;&#25968;&#65292;&#23427;&#36890;&#36807;&#20351;&#29992;Fourier&#29305;&#24449;&#23558;&#25968;&#25454;&#26144;&#23556;&#21040;RKHS&#20013;&#12290;&#27492;&#20272;&#35745;&#20989;&#25968;&#26159;&#28789;&#27963;&#12289;&#21487;&#25193;&#23637;&#12289;&#21487;&#24494;&#20998;&#30340;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#23567;&#25209;&#37327;&#20248;&#21270;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30697;&#38453;&#30340;&#20272;&#35745;&#20989;&#25968;&#65292;&#32780;&#19981;&#38656;&#35201;&#23545;RKHS&#36827;&#34892;&#26174;&#24335;&#26144;&#23556;&#12290;&#25105;&#20204;&#35777;&#26126;&#36825;&#20010;&#37327;&#26159;Jensen-Shannon&#25955;&#24230;&#30340;&#19968;&#20010;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
Statistical divergences quantify the difference between probability distributions finding multiple uses in machine-learning. However, a fundamental challenge is to estimate divergence from empirical samples since the underlying distributions of the data are usually unknown. In this work, we propose the representation Jensen-Shannon Divergence, a novel divergence based on covariance operators in reproducing kernel Hilbert spaces (RKHS). Our approach embeds the data distributions in an RKHS and exploits the spectrum of the covariance operators of the representations. We provide an estimator from empirical covariance matrices by explicitly mapping the data to an RKHS using Fourier features. This estimator is flexible, scalable, differentiable, and suitable for minibatch-based optimization problems. Additionally, we provide an estimator based on kernel matrices without having an explicit mapping to the RKHS. We show that this quantity is a lower bound on the Jensen-Shannon divergence, and 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;(LDMs)&#65292;&#36890;&#36807;&#39044;&#35757;&#32451;&#33258;&#32534;&#30721;&#22120;&#23558;&#39640;&#32500;&#20687;&#32032;&#31354;&#38388;&#36716;&#21464;&#20026;&#20302;&#32500;&#28508;&#22312;&#31354;&#38388;&#23454;&#29616;&#26356;&#39640;&#25928;&#24555;&#36895;&#30340;DMs&#35757;&#32451;&#65292;&#24182;&#19988;&#36890;&#36807;&#21482;&#24494;&#35843;&#27880;&#24847;&#21147;&#27169;&#22359;&#20943;&#23569;&#20102;&#21487;&#35757;&#32451;&#21442;&#25968;&#30340;&#25968;&#37327;&#12290;</title><link>http://arxiv.org/abs/2305.15759</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Latent Diffusion Models. (arXiv:2305.15759v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15759
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;(LDMs)&#65292;&#36890;&#36807;&#39044;&#35757;&#32451;&#33258;&#32534;&#30721;&#22120;&#23558;&#39640;&#32500;&#20687;&#32032;&#31354;&#38388;&#36716;&#21464;&#20026;&#20302;&#32500;&#28508;&#22312;&#31354;&#38388;&#23454;&#29616;&#26356;&#39640;&#25928;&#24555;&#36895;&#30340;DMs&#35757;&#32451;&#65292;&#24182;&#19988;&#36890;&#36807;&#21482;&#24494;&#35843;&#27880;&#24847;&#21147;&#27169;&#22359;&#20943;&#23569;&#20102;&#21487;&#35757;&#32451;&#21442;&#25968;&#30340;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;(DMs)&#34987;&#24191;&#27867;&#29992;&#20110;&#29983;&#25104;&#39640;&#36136;&#37327;&#22270;&#20687;&#25968;&#25454;&#38598;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23427;&#20204;&#30452;&#25509;&#22312;&#39640;&#32500;&#20687;&#32032;&#31354;&#38388;&#20013;&#36816;&#34892;&#65292;DMs&#30340;&#20248;&#21270;&#35745;&#31639;&#25104;&#26412;&#39640;&#65292;&#38656;&#35201;&#38271;&#26102;&#38388;&#30340;&#35757;&#32451;&#12290;&#36825;&#23548;&#33268;&#30001;&#20110;&#24046;&#20998;&#38544;&#31169;&#30340;&#21487;&#32452;&#21512;&#24615;&#23646;&#24615;&#65292;&#22823;&#37327;&#22122;&#38899;&#27880;&#20837;&#21040;&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;&#36807;&#31243;&#20013;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;(LDMs)&#12290;LDMs&#20351;&#29992;&#24378;&#22823;&#30340;&#39044;&#35757;&#32451;&#33258;&#32534;&#30721;&#22120;&#23558;&#39640;&#32500;&#20687;&#32032;&#31354;&#38388;&#20943;&#23569;&#21040;&#26356;&#20302;&#32500;&#30340;&#28508;&#22312;&#31354;&#38388;&#65292;&#20351;&#35757;&#32451;DMs&#26356;&#21152;&#39640;&#25928;&#21644;&#24555;&#36895;&#12290;&#19982;[Ghalebikesabi&#31561;&#20154;&#65292;2023]&#39044;&#20808;&#29992;&#20844;&#20849;&#25968;&#25454;&#39044;&#35757;&#32451;DMs&#65292;&#28982;&#21518;&#20877;&#29992;&#38544;&#31169;&#25968;&#25454;&#36827;&#34892;&#24494;&#35843;&#19981;&#21516;&#65292;&#25105;&#20204;&#20165;&#24494;&#35843;LDMs&#20013;&#19981;&#21516;&#23618;&#30340;&#27880;&#24847;&#21147;&#27169;&#22359;&#20197;&#33719;&#24471;&#38544;&#31169;&#25935;&#24863;&#25968;&#25454;&#65292;&#30456;&#23545;&#20110;&#25972;&#20010;DM&#24494;&#35843;&#65292;&#21487;&#20943;&#23569;&#22823;&#32422;96%&#30340;&#21487;&#35757;&#32451;&#21442;&#25968;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models (DMs) are widely used for generating high-quality image datasets. However, since they operate directly in the high-dimensional pixel space, optimization of DMs is computationally expensive, requiring long training times. This contributes to large amounts of noise being injected into the differentially private learning process, due to the composability property of differential privacy. To address this challenge, we propose training Latent Diffusion Models (LDMs) with differential privacy. LDMs use powerful pre-trained autoencoders to reduce the high-dimensional pixel space to a much lower-dimensional latent space, making training DMs more efficient and fast. Unlike [Ghalebikesabi et al., 2023] that pre-trains DMs with public data then fine-tunes them with private data, we fine-tune only the attention modules of LDMs at varying layers with privacy-sensitive data, reducing the number of trainable parameters by approximately 96% compared to fine-tuning the entire DM. We te
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#36716;&#31227;&#23398;&#20064;&#36712;&#36857;&#30340;&#31639;&#27861;&#65292;&#21487;&#23558;&#20043;&#21069;&#35757;&#32451;&#36807;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#36712;&#36857;&#24212;&#29992;&#22312;&#26032;&#30340;&#35757;&#32451;&#20013;&#65292;&#24182;&#33021;&#22312;&#20219;&#20309;&#30452;&#25509;&#35757;&#32451;&#20043;&#21069;&#23454;&#29616;&#38750;&#24179;&#20961;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.14122</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#36712;&#36857;&#30340;&#36716;&#31227;
&lt;/p&gt;
&lt;p&gt;
Transferring Learning Trajectories of Neural Networks. (arXiv:2305.14122v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14122
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#36716;&#31227;&#23398;&#20064;&#36712;&#36857;&#30340;&#31639;&#27861;&#65292;&#21487;&#23558;&#20043;&#21069;&#35757;&#32451;&#36807;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#36712;&#36857;&#24212;&#29992;&#22312;&#26032;&#30340;&#35757;&#32451;&#20013;&#65292;&#24182;&#33021;&#22312;&#20219;&#20309;&#30452;&#25509;&#35757;&#32451;&#20043;&#21069;&#23454;&#29616;&#38750;&#24179;&#20961;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#26159;&#35745;&#31639;&#23494;&#38598;&#22411;&#30340;&#65292;&#36825;&#22312;&#25191;&#34892;&#37325;&#22797;&#35757;&#32451;&#36816;&#34892;&#65288;&#20363;&#22914;&#27169;&#22411;&#38598;&#25104;&#25110;&#30693;&#35782;&#33976;&#39311;&#65289;&#26102;&#23588;&#20854;&#25104;&#38382;&#39064;&#12290;&#19968;&#26086;&#25105;&#20204;&#22312;&#26576;&#20010;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#20102;&#19968;&#20010;DNN&#65292;&#25105;&#20204;&#23601;&#25317;&#26377;&#20102;&#20854;&#23398;&#20064;&#36712;&#36857;&#65288;&#21363;&#35757;&#32451;&#26399;&#38388;&#30340;&#20013;&#38388;&#21442;&#25968;&#24207;&#21015;&#65289;&#65292;&#20854;&#20013;&#21487;&#33021;&#21253;&#21547;&#23398;&#20064;&#25968;&#25454;&#38598;&#30340;&#26377;&#29992;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#23578;&#26410;&#23581;&#35797;&#21033;&#29992;&#32473;&#23450;&#23398;&#20064;&#36712;&#36857;&#30340;&#36825;&#31181;&#20449;&#24687;&#36827;&#34892;&#21478;&#19968;&#31181;&#35757;&#32451;&#12290;&#26412;&#25991;&#23558;&#38382;&#39064;&#24418;&#24335;&#21270;&#20026;&#8220;&#36716;&#31227;&#8221;&#32473;&#23450;&#23398;&#20064;&#36712;&#36857;&#20174;&#19968;&#20010;&#21021;&#22987;&#21442;&#25968;&#21040;&#21478;&#19968;&#20010;&#21021;&#22987;&#21442;&#25968;&#65292;&#31216;&#20026;&#23398;&#20064;&#36716;&#31227;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#21305;&#37197;&#27839;&#36712;&#36857;&#36880;&#28176;&#24179;&#31227;&#23545;&#31216;&#24615;&#30340;&#26799;&#24230;&#23548;&#20986;&#20102;&#31532;&#19968;&#20010;&#31639;&#27861;&#65292;&#20197;&#36817;&#20284;&#35299;&#20915;&#23427;&#12290;&#25105;&#20204;&#32463;&#39564;&#35777;&#26126;&#65292;&#36716;&#31227;&#21442;&#25968;&#22312;&#20219;&#20309;&#30452;&#25509;&#35757;&#32451;&#20043;&#21069;&#23601;&#33021;&#36798;&#21040;&#38750;&#24179;&#20961;&#30340;&#20934;&#30830;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#36716;&#31227;&#21442;&#25968;&#30340;&#25439;&#22833;&#26223;&#35266;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training deep neural networks (DNNs) is computationally expensive, which is problematic especially when performing duplicated training runs, such as model ensemble or knowledge distillation. Once we have trained one DNN on some dataset, we have its learning trajectory (i.e., a sequence of intermediate parameters during training) which may potentially contain useful information for learning the dataset. However, there has been no attempt to utilize such information of a given learning trajectory for another training. In this paper, we formulate the problem of "transferring" a given learning trajectory from one initial parameter to another one, called learning transfer problem, and derive the first algorithm to approximately solve it by matching gradients successively along the trajectory via permutation symmetry. We empirically show that the transferred parameters achieve non-trivial accuracy before any direct training. Also, we analyze the loss landscape property of the transferred par
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26080;&#38480;&#32500;&#24230;&#20013;&#30452;&#25509;&#21046;&#23450;&#25193;&#25955;&#22522;&#20110;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;&#20808;&#31163;&#25955;&#21270;&#20877;&#24212;&#29992;&#25193;&#25955;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#36991;&#20813;&#21442;&#25968;&#32454;&#21270;&#23548;&#33268;&#31639;&#27861;&#24615;&#33021;&#19979;&#38477;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#32500;&#24230;&#26080;&#20851;&#30340;&#36317;&#31163;&#30028;&#38480;&#65292;&#20026;&#26080;&#38480;&#32500;&#25193;&#25955;&#27169;&#22411;&#35774;&#35745;&#25552;&#20379;&#20102;&#20934;&#21017;&#12290;</title><link>http://arxiv.org/abs/2302.10130</link><description>&lt;p&gt;
&#26080;&#38480;&#32500;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Infinite-Dimensional Diffusion Models. (arXiv:2302.10130v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10130
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26080;&#38480;&#32500;&#24230;&#20013;&#30452;&#25509;&#21046;&#23450;&#25193;&#25955;&#22522;&#20110;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;&#20808;&#31163;&#25955;&#21270;&#20877;&#24212;&#29992;&#25193;&#25955;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#36991;&#20813;&#21442;&#25968;&#32454;&#21270;&#23548;&#33268;&#31639;&#27861;&#24615;&#33021;&#19979;&#38477;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#32500;&#24230;&#26080;&#20851;&#30340;&#36317;&#31163;&#30028;&#38480;&#65292;&#20026;&#26080;&#38480;&#32500;&#25193;&#25955;&#27169;&#22411;&#35774;&#35745;&#25552;&#20379;&#20102;&#20934;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#23545;&#20110;&#35768;&#22810;&#24212;&#29992;&#39046;&#22495;&#37117;&#20135;&#29983;&#20102;&#28145;&#36828;&#30340;&#24433;&#21709;&#65292;&#21253;&#25324;&#37027;&#20123;&#25968;&#25454;&#26412;&#36136;&#19978;&#26159;&#26080;&#38480;&#32500;&#30340;&#39046;&#22495;&#65292;&#22914;&#22270;&#20687;&#25110;&#26102;&#38388;&#24207;&#21015;&#12290;&#26631;&#20934;&#26041;&#27861;&#26159;&#39318;&#20808;&#31163;&#25955;&#21270;&#25968;&#25454;&#65292;&#28982;&#21518;&#23558;&#25193;&#25955;&#27169;&#22411;&#24212;&#29992;&#20110;&#31163;&#25955;&#30340;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#32454;&#21270;&#31163;&#25955;&#21270;&#21442;&#25968;&#26102;&#36890;&#24120;&#20250;&#23548;&#33268;&#31639;&#27861;&#24615;&#33021;&#19979;&#38477;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30452;&#25509;&#22312;&#26080;&#38480;&#32500;&#24230;&#20013;&#21046;&#23450;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#20989;&#25968;&#30340;&#29983;&#25104;&#24314;&#27169;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#20844;&#24335;&#22312;&#26080;&#38480;&#32500;&#24230;&#29615;&#22659;&#20013;&#26159;&#33391;&#22909;&#23450;&#20041;&#30340;&#65292;&#24182;&#25552;&#20379;&#20102;&#20174;&#26679;&#26412;&#21040;&#30446;&#26631;&#27979;&#24230;&#30340;&#32500;&#24230;&#26080;&#20851;&#30340;&#36317;&#31163;&#30028;&#38480;&#12290;&#21033;&#29992;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#25105;&#20204;&#36824;&#21046;&#23450;&#20102;&#26080;&#38480;&#32500;&#25193;&#25955;&#27169;&#22411;&#35774;&#35745;&#30340;&#20934;&#21017;&#12290;&#23545;&#20110;&#22270;&#20687;&#20998;&#24067;&#65292;&#36825;&#20123;&#20934;&#21017;&#19982;&#24403;&#21069;&#29992;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#32463;&#20856;&#36873;&#25321;&#19968;&#33268;&#12290;&#23545;&#20110;&#20854;&#20182;&#20998;&#24067;...
&lt;/p&gt;
&lt;p&gt;
Diffusion models have had a profound impact on many application areas, including those where data are intrinsically infinite-dimensional, such as images or time series. The standard approach is first to discretize and then to apply diffusion models to the discretized data. While such approaches are practically appealing, the performance of the resulting algorithms typically deteriorates as discretization parameters are refined. In this paper, we instead directly formulate diffusion-based generative models in infinite dimensions and apply them to the generative modeling of functions. We prove that our formulations are well posed in the infinite-dimensional setting and provide dimension-independent distance bounds from the sample to the target measure. Using our theory, we also develop guidelines for the design of infinite-dimensional diffusion models. For image distributions, these guidelines are in line with the canonical choices currently made for diffusion models. For other distribut
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Koopman&#31639;&#23376;&#23545;&#20840;&#31209;&#31070;&#32463;&#32593;&#32476;&#26435;&#37325;&#36827;&#34892;&#27867;&#21270;&#30340;&#26032;&#30028;&#38480;&#65292;&#24403;&#26435;&#37325;&#30697;&#38453;&#30340;&#26465;&#20214;&#25968;&#36739;&#23567;&#26102;&#65292;&#35813;&#30028;&#38480;&#27604;&#29616;&#26377;&#22522;&#20110;&#33539;&#25968;&#30340;&#30028;&#38480;&#26356;&#32039;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#19981;&#19982;&#29616;&#26377;&#30028;&#38480;&#30456;&#30683;&#30462;&#65292;&#32780;&#26159;&#23545;&#29616;&#26377;&#30028;&#38480;&#36827;&#34892;&#30340;&#34917;&#20805;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#21487;&#20197;&#19982;&#29616;&#26377;&#30028;&#38480;&#32467;&#21512;&#20197;&#24471;&#21040;&#26356;&#32039;&#30340;&#30028;&#38480;&#12290;&#35813;&#30740;&#31350;&#32467;&#26524;&#20026;&#29702;&#35299;&#20840;&#31209;&#26435;&#37325;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#25552;&#20379;&#20102;&#26032;&#30340;&#35270;&#35282;&#65292;&#21516;&#26102;&#20063;&#20026;&#31639;&#23376;&#29702;&#35770;&#20998;&#26512;&#21644;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#20043;&#38388;&#25552;&#20379;&#20102;&#36830;&#25509;&#12290;</title><link>http://arxiv.org/abs/2302.05825</link><description>&lt;p&gt;
&#22522;&#20110;Koopman&#31639;&#23376;&#30340;&#20840;&#31209;&#26435;&#37325;&#30340;&#27867;&#21270;&#30028;&#38480;&#65306;&#26032;&#30340;&#35266;&#28857;
&lt;/p&gt;
&lt;p&gt;
Koopman-based generalization bound: New aspect for full-rank weights. (arXiv:2302.05825v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05825
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Koopman&#31639;&#23376;&#23545;&#20840;&#31209;&#31070;&#32463;&#32593;&#32476;&#26435;&#37325;&#36827;&#34892;&#27867;&#21270;&#30340;&#26032;&#30028;&#38480;&#65292;&#24403;&#26435;&#37325;&#30697;&#38453;&#30340;&#26465;&#20214;&#25968;&#36739;&#23567;&#26102;&#65292;&#35813;&#30028;&#38480;&#27604;&#29616;&#26377;&#22522;&#20110;&#33539;&#25968;&#30340;&#30028;&#38480;&#26356;&#32039;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#19981;&#19982;&#29616;&#26377;&#30028;&#38480;&#30456;&#30683;&#30462;&#65292;&#32780;&#26159;&#23545;&#29616;&#26377;&#30028;&#38480;&#36827;&#34892;&#30340;&#34917;&#20805;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#21487;&#20197;&#19982;&#29616;&#26377;&#30028;&#38480;&#32467;&#21512;&#20197;&#24471;&#21040;&#26356;&#32039;&#30340;&#30028;&#38480;&#12290;&#35813;&#30740;&#31350;&#32467;&#26524;&#20026;&#29702;&#35299;&#20840;&#31209;&#26435;&#37325;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#25552;&#20379;&#20102;&#26032;&#30340;&#35270;&#35282;&#65292;&#21516;&#26102;&#20063;&#20026;&#31639;&#23376;&#29702;&#35770;&#20998;&#26512;&#21644;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#20043;&#38388;&#25552;&#20379;&#20102;&#36830;&#25509;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Koopman&#31639;&#23376;&#23545;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#27867;&#21270;&#30340;&#26032;&#30028;&#38480;&#12290;&#22823;&#37096;&#20998;&#29616;&#26377;&#30740;&#31350;&#37117;&#38598;&#20013;&#22312;&#20302;&#31209;&#26435;&#37325;&#30697;&#38453;&#19978;&#65292;&#32780;&#25105;&#20204;&#19987;&#27880;&#20110;&#20840;&#31209;&#26435;&#37325;&#30697;&#38453;&#12290;&#24403;&#26435;&#37325;&#30697;&#38453;&#30340;&#26465;&#20214;&#25968;&#36739;&#23567;&#26102;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#27604;&#29616;&#26377;&#22522;&#20110;&#33539;&#25968;&#30340;&#30028;&#38480;&#26356;&#32039;&#12290;&#29305;&#21035;&#22320;&#65292;&#22914;&#26524;&#26435;&#37325;&#30697;&#38453;&#26159;&#27491;&#20132;&#30340;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#19982;&#32593;&#32476;&#30340;&#23485;&#24230;&#23436;&#20840;&#26080;&#20851;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#19981;&#19982;&#29616;&#26377;&#30028;&#38480;&#30456;&#30683;&#30462;&#65292;&#32780;&#26159;&#23545;&#29616;&#26377;&#30028;&#38480;&#36827;&#34892;&#30340;&#34917;&#20805;&#12290;&#30001;&#20960;&#20010;&#24050;&#26377;&#23454;&#39564;&#35777;&#26126;&#65292;&#20302;&#31209;&#24615;&#24182;&#19981;&#26159;&#27867;&#21270;&#30340;&#21807;&#19968;&#21407;&#22240;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#21487;&#20197;&#19982;&#29616;&#26377;&#30028;&#38480;&#32467;&#21512;&#20197;&#24471;&#21040;&#26356;&#32039;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20026;&#29702;&#35299;&#20855;&#26377;&#20840;&#31209;&#26435;&#37325;&#30697;&#38453;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#25552;&#20379;&#20102;&#26032;&#30340;&#35270;&#35282;&#65292;&#21516;&#26102;&#36824;&#20026;&#31639;&#23376;&#29702;&#35770;&#20998;&#26512;&#21644;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#20043;&#38388;&#25552;&#20379;&#20102;&#36830;&#25509;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new bound for generalization of neural networks using Koopman operators. Whereas most of existing works focus on low-rank weight matrices, we focus on full-rank weight matrices. Our bound is tighter than existing norm-based bounds when the condition numbers of weight matrices are small. Especially, it is completely independent of the width of the network if the weight matrices are orthogonal. Our bound does not contradict to the existing bounds but is a complement to the existing bounds. As supported by several existing empirical results, low-rankness is not the only reason for generalization. Furthermore, our bound can be combined with the existing bounds to obtain a tighter bound. Our result sheds new light on understanding generalization of neural networks with full-rank weight matrices, and it provides a connection between operator-theoretic analysis and generalization of neural networks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#31070;&#32463;&#28857;&#36807;&#31243;&#27169;&#22411;&#23545;2016-2017&#24180;&#38463;&#24429;&#23425;&#22320;&#38663;&#24207;&#21015;&#36827;&#34892;&#20102;&#39044;&#27979;&#65292;&#32467;&#26524;&#34920;&#26126;&#31070;&#32463;&#27169;&#22411;&#20248;&#20110;&#20256;&#32479;ETAS&#27169;&#22411;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#30701;&#26399;&#22320;&#38663;&#39044;&#25253;&#12290;</title><link>http://arxiv.org/abs/2301.09948</link><description>&lt;p&gt;
&#29992;&#31070;&#32463;&#28857;&#36807;&#31243;&#39044;&#27979;2016-2017&#24180;&#20013;&#22830;&#38463;&#24429;&#23425;&#22320;&#38663;&#24207;&#21015;
&lt;/p&gt;
&lt;p&gt;
Forecasting the 2016-2017 Central Apennines Earthquake Sequence with a Neural Point Process. (arXiv:2301.09948v2 [physics.geo-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.09948
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#31070;&#32463;&#28857;&#36807;&#31243;&#27169;&#22411;&#23545;2016-2017&#24180;&#38463;&#24429;&#23425;&#22320;&#38663;&#24207;&#21015;&#36827;&#34892;&#20102;&#39044;&#27979;&#65292;&#32467;&#26524;&#34920;&#26126;&#31070;&#32463;&#27169;&#22411;&#20248;&#20110;&#20256;&#32479;ETAS&#27169;&#22411;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#30701;&#26399;&#22320;&#38663;&#39044;&#25253;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#20960;&#21313;&#24180;&#26469;&#65292;&#28857;&#36807;&#31243;&#19968;&#30452;&#26159;&#22320;&#38663;&#27963;&#21160;&#28436;&#21270;&#24314;&#27169;&#39046;&#22495;&#30340;&#20027;&#27969;&#26041;&#27861;&#65292;&#20854;&#20013;Epidemic Type Aftershock Sequence (ETAS)&#27169;&#22411;&#26368;&#20026;&#27969;&#34892;&#12290;&#36817;&#24180;&#26469;&#65292;&#26426;&#22120;&#23398;&#20064;&#30340;&#19981;&#26029;&#21457;&#23637;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#26500;&#24314;&#39640;&#24230;&#28789;&#27963;&#30340;&#28857;&#36807;&#31243;&#27169;&#22411;&#20197;&#25913;&#36827;&#29616;&#26377;&#30340;&#21442;&#25968;&#27169;&#22411;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;&#29616;&#26377;&#30340;&#26102;&#38388;&#31070;&#32463;&#27169;&#22411;&#25193;&#23637;&#21040;&#38663;&#32423;&#39046;&#22495;&#65292;&#25506;&#31350;&#36825;&#20123;&#28789;&#27963;&#30340;&#28857;&#36807;&#31243;&#27169;&#22411;&#26159;&#21542;&#21487;&#20197;&#24212;&#29992;&#20110;&#30701;&#26399;&#22320;&#38663;&#39044;&#25253;&#65292;&#24182;&#23637;&#31034;&#27492;&#27169;&#22411;&#22914;&#20309;&#39044;&#27979;&#39640;&#20110;&#30446;&#26631;&#38663;&#32423;&#38408;&#20540;&#30340;&#22320;&#38663;&#12290;&#26412;&#25991;&#39318;&#20808;&#35777;&#26126;&#20102;&#31070;&#32463;&#27169;&#22411;&#21487;&#20197;&#25311;&#21512;ETAS&#21512;&#25104;&#25968;&#25454;&#65292;&#19988;&#38656;&#35201;&#36739;&#23569;&#30340;&#35745;&#31639;&#26102;&#38388;&#65292;&#22240;&#20026;&#23427;&#19981;&#20381;&#36182;&#20110;&#25972;&#20010;&#24207;&#21015;&#30340;&#23436;&#25972;&#21382;&#21490;&#12290;&#36890;&#36807;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#20013;&#27169;&#25311;&#30701;&#26399;&#20313;&#38663;&#19981;&#23436;&#25972;&#24615;&#65292;&#25105;&#20204;&#21457;&#29616;&#31070;&#32463;&#27169;&#22411;&#30340;&#34920;&#29616;&#20248;&#20110;ETAS&#12290;&#21033;&#29992;2016-2017&#24180;&#20013;&#22830;&#38463;&#24429;&#23425;&#22320;&#38663;&#24207;&#21015;&#30340;&#26032;&#22686;&#24378;&#30446;&#24405;&#65292;&#25105;&#20204;&#39044;&#27979;&#20102;&#26410;&#26469;&#30340;&#22320;&#38663;&#27963;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;
Point processes have been dominant in modeling the evolution of seismicity for decades, with the Epidemic Type Aftershock Sequence (ETAS) model being most popular. Recent advances in machine learning have constructed highly flexible point process models using neural networks to improve upon existing parametric models. We investigate whether these flexible point process models can be applied to short-term seismicity forecasting by extending an existing temporal neural model to the magnitude domain and we show how this model can forecast earthquakes above a target magnitude threshold. We first demonstrate that the neural model can fit synthetic ETAS data, however, requiring less computational time because it is not dependent on the full history of the sequence. By artificially emulating short-term aftershock incompleteness in the synthetic dataset, we find that the neural model outperforms ETAS. Using a new enhanced catalog from the 2016-2017 Central Apennines earthquake sequence, we inv
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#21152;&#26435;&#32452;&#31232;&#30095;&#21253;&#32476;&#27491;&#21017;&#21270;&#26041;&#27861;&#23398;&#20064;k&#32423;&#31232;&#30095;&#31070;&#32463;&#32593;&#32476;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#21516;&#26102;&#20445;&#35777;&#32593;&#32476;&#30340;&#30828;&#20214;&#21451;&#22909;&#30340;&#32467;&#26500;&#21270;&#31232;&#30095;&#24615;&#65292;&#21152;&#24555;&#32593;&#32476;&#35780;&#20272;&#36895;&#24230;&#65292;&#32780;&#19988;&#33021;&#22815;&#22312;&#35757;&#32451;&#20013;&#39044;&#23450;&#20041;&#31232;&#30095;&#24230;&#27700;&#24179;&#65292;&#21516;&#26102;&#20960;&#20046;&#19981;&#38477;&#20302;&#32593;&#32476;&#20934;&#30830;&#24230;&#29978;&#33267;&#26377;&#21487;&#33021;&#25552;&#39640;&#12290;</title><link>http://arxiv.org/abs/2212.12921</link><description>&lt;p&gt;
&#20351;&#29992;&#26032;&#30340;&#24191;&#20041;&#21152;&#26435;&#32452;&#31232;&#30095;&#21253;&#32476;&#27491;&#21017;&#21270;&#23398;&#20064;k&#32423;&#31232;&#30095;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Learning k-Level Sparse Neural Networks Using a New Generalized Weighted Group Sparse Envelope Regularization. (arXiv:2212.12921v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.12921
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#21152;&#26435;&#32452;&#31232;&#30095;&#21253;&#32476;&#27491;&#21017;&#21270;&#26041;&#27861;&#23398;&#20064;k&#32423;&#31232;&#30095;&#31070;&#32463;&#32593;&#32476;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#21516;&#26102;&#20445;&#35777;&#32593;&#32476;&#30340;&#30828;&#20214;&#21451;&#22909;&#30340;&#32467;&#26500;&#21270;&#31232;&#30095;&#24615;&#65292;&#21152;&#24555;&#32593;&#32476;&#35780;&#20272;&#36895;&#24230;&#65292;&#32780;&#19988;&#33021;&#22815;&#22312;&#35757;&#32451;&#20013;&#39044;&#23450;&#20041;&#31232;&#30095;&#24230;&#27700;&#24179;&#65292;&#21516;&#26102;&#20960;&#20046;&#19981;&#38477;&#20302;&#32593;&#32476;&#20934;&#30830;&#24230;&#29978;&#33267;&#26377;&#21487;&#33021;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#26041;&#27861;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#23398;&#20064;&#26080;&#32467;&#26500;&#21644;&#26377;&#32467;&#26500;&#31232;&#30095;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#21033;&#29992;&#19968;&#31181;&#31216;&#20026;"&#21152;&#26435;&#32452;&#31232;&#30095;&#21253;&#32476;&#20989;&#25968;" (WGSEF) &#30340;&#31232;&#30095;&#21253;&#32476;&#20989;&#25968;&#30340;&#26032;&#24191;&#20041;&#12290;WGSEF&#20316;&#20026;&#19968;&#20010;&#31070;&#32463;&#20803;&#32452;&#36873;&#25321;&#22120;&#65292;&#29992;&#20110;&#24341;&#23548;&#32467;&#26500;&#21270;&#31232;&#30095;&#24615;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#30830;&#20445;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476; (DNN) &#30340;&#30828;&#20214;&#21451;&#22909;&#30340;&#32467;&#26500;&#21270;&#31232;&#30095;&#24615;&#65292;&#20197;&#26377;&#25928;&#21152;&#36895;DNN&#30340;&#35780;&#20272;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#35813;&#26041;&#27861;&#26159;&#21487;&#36866;&#24212;&#30340;&#65292;&#20801;&#35768;&#20219;&#20309;&#30828;&#20214;&#25351;&#23450;&#32452;&#23450;&#20041;&#65292;&#22914;&#28388;&#27874;&#22120;&#12289;&#36890;&#36947;&#12289;&#28388;&#27874;&#22120;&#24418;&#29366;&#12289;&#23618;&#28145;&#24230;&#12289;&#21333;&#20010;&#21442;&#25968; (&#26080;&#32467;&#26500;)&#31561;&#12290;&#30001;&#20110;WGSEF&#30340;&#29305;&#24615;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#22312;&#35757;&#32451;&#25910;&#25947;&#26102;&#39044;&#23450;&#20041;&#31232;&#30095;&#24230;&#27700;&#24179;&#65292;&#21516;&#26102;&#20445;&#25345;&#32593;&#32476;&#20934;&#30830;&#24230;&#30340;&#26497;&#23567;&#38477;&#20302;&#29978;&#33267;&#25913;&#21892;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#25216;&#26415;&#26469;&#35745;&#31639;&#31934;&#30830;&#30340;...
&lt;/p&gt;
&lt;p&gt;
We propose an efficient method to learn both unstructured and structured sparse neural networks during training, utilizing a novel generalization of the sparse envelope function (SEF) used as a regularizer, termed {\itshape{weighted group sparse envelope function}} (WGSEF). The WGSEF acts as a neuron group selector, which is leveraged to induce structured sparsity. The method ensures a hardware-friendly structured sparsity of a deep neural network (DNN) to efficiently accelerate the DNN's evaluation. Notably, the method is adaptable, letting any hardware specify group definitions, such as filters, channels, filter shapes, layer depths, a single parameter (unstructured), etc. Owing to the WGSEF's properties, the proposed method allows to a pre-define sparsity level that would be achieved at the training convergence, while maintaining negligible network accuracy degradation or even improvement in the case of redundant parameters. We introduce an efficient technique to calculate the exact
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;AEnbMIMOCQR&#30340;&#26032;&#39062;&#31639;&#27861;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#38598;&#25104;&#30340;&#26041;&#24335;&#65292;&#22312;&#19981;&#38656;&#35201;&#25968;&#25454;&#25286;&#20998;&#30340;&#24773;&#20917;&#19979;&#65292;&#20197;&#20998;&#24067;&#26080;&#20851;&#30340;&#26041;&#24335;&#29983;&#25104;&#22810;&#27493;&#40077;&#22411;&#39044;&#27979;&#21306;&#38388;&#12290;&#35813;&#26041;&#27861;&#32771;&#34385;&#20102;&#24322;&#26041;&#24046;&#24615;&#65292;&#24182;&#23545;&#20998;&#24067;&#36716;&#21464;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#31454;&#20105;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2207.14219</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#22810;&#27493;&#40077;&#22411;&#33258;&#36866;&#24212;&#24322;&#26041;&#24046;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#36890;&#29992;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A general framework for multi-step ahead adaptive conformal heteroscedastic time series forecasting. (arXiv:2207.14219v7 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.14219
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;AEnbMIMOCQR&#30340;&#26032;&#39062;&#31639;&#27861;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#38598;&#25104;&#30340;&#26041;&#24335;&#65292;&#22312;&#19981;&#38656;&#35201;&#25968;&#25454;&#25286;&#20998;&#30340;&#24773;&#20917;&#19979;&#65292;&#20197;&#20998;&#24067;&#26080;&#20851;&#30340;&#26041;&#24335;&#29983;&#25104;&#22810;&#27493;&#40077;&#22411;&#39044;&#27979;&#21306;&#38388;&#12290;&#35813;&#26041;&#27861;&#32771;&#34385;&#20102;&#24322;&#26041;&#24046;&#24615;&#65292;&#24182;&#23545;&#20998;&#24067;&#36716;&#21464;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#31454;&#20105;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;&#26080;&#20851;&#31639;&#27861;&#65292;&#21517;&#20026;&#33258;&#36866;&#24212;&#38598;&#25104;&#25209;&#37327;&#22810;&#36755;&#20837;&#22810;&#36755;&#20986;&#40077;&#22411;&#20998;&#20301;&#25968;&#22238;&#24402;&#65288;AEnbMIMOCQR&#65289;&#65292;&#20351;&#24471;&#39044;&#27979;&#32773;&#33021;&#22815;&#20197;&#20998;&#24067;&#26080;&#20851;&#30340;&#26041;&#24335;&#29983;&#25104;&#22266;&#23450;&#39044;&#35774;&#22833;&#37197;&#29575;&#30340;&#22810;&#27493;&#40077;&#22411;&#39044;&#27979;&#21306;&#38388;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#40077;&#22411;&#39044;&#27979;&#21407;&#29702;&#65292;&#20294;&#19981;&#38656;&#35201;&#25968;&#25454;&#25286;&#20998;&#65292;&#24182;&#19988;&#21363;&#20351;&#22312;&#25968;&#25454;&#19981;&#21487;&#20114;&#25442;&#30340;&#24773;&#20917;&#19979;&#20063;&#33021;&#25552;&#20379;&#25509;&#36817;&#31934;&#30830;&#30340;&#35206;&#30422;&#29575;&#12290;&#27492;&#22806;&#65292;&#25152;&#24471;&#21040;&#30340;&#39044;&#27979;&#21306;&#38388;&#22312;&#39044;&#27979;&#26102;&#38388;&#33539;&#22260;&#20869;&#32463;&#39564;&#35777;&#26126;&#26377;&#25928;&#65292;&#24182;&#19988;&#32771;&#34385;&#20102;&#24322;&#26041;&#24046;&#24615;&#12290;AEnbMIMOCQR&#34987;&#35774;&#35745;&#25104;&#23545;&#20998;&#24067;&#36716;&#21464;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#36825;&#24847;&#21619;&#30528;&#20854;&#39044;&#27979;&#21306;&#38388;&#22312;&#26080;&#38480;&#30340;&#26102;&#38388;&#33539;&#22260;&#20869;&#20445;&#25345;&#21487;&#38752;&#65292;&#32780;&#26080;&#38656;&#37325;&#26032;&#35757;&#32451;&#25110;&#23545;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#36827;&#34892;&#19981;&#20999;&#23454;&#38469;&#30340;&#20005;&#26684;&#20551;&#35774;&#12290;&#36890;&#36807;&#31995;&#32479;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#40077;&#22411;&#39044;&#27979;&#20013;&#20248;&#20110;&#20854;&#20182;&#31454;&#20105;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a novel model-agnostic algorithm called adaptive ensemble batch multi-input multi-output conformalized quantile regression (AEnbMIMOCQR} that enables forecasters to generate multi-step ahead prediction intervals for a fixed pre-specified miscoverage rate in a distribution-free manner. Our method is grounded on conformal prediction principles, however, it does not require data splitting and provides close to exact coverage even when the data is not exchangeable. Moreover, the resulting prediction intervals, besides being empirically valid along the forecast horizon, do not neglect heteroscedasticity. AEnbMIMOCQR is designed to be robust to distribution shifts, which means that its prediction intervals remain reliable over an unlimited period of time, without entailing retraining or imposing unrealistic strict assumptions on the data-generating process. Through methodically experimentation, we demonstrate that our approach outperforms other competitive methods on bo
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#36890;&#36807;&#34920;&#38754;&#37325;&#24314;&#26469;&#33719;&#24471;&#22312;&#20809;&#28369;&#27425;&#27969;&#24418;&#19978;&#20272;&#35745;&#20869;&#22312;&#36317;&#31163;&#30340;&#26497;&#23567;&#26368;&#20248;&#24615;&#20197;&#21450;&#22312;&#31561;&#36317;&#38382;&#39064;&#20013;&#20351;&#29992;&#37325;&#24314;&#34920;&#38754;&#35745;&#31639;&#36317;&#31163;&#30340;Isomap&#21464;&#20307;&#30340;&#26497;&#23567;&#26368;&#20248;&#24615;&#12290;</title><link>http://arxiv.org/abs/2011.12478</link><description>&lt;p&gt;
&#34920;&#38754;&#19978;&#30340;&#26497;&#23567;&#20272;&#35745;&#36317;&#31163;&#21644;&#31561;&#36317;&#21040;&#20984;&#22788;&#29702;&#20013;&#30340;&#26497;&#23567;&#27969;&#24418;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Minimax Estimation of Distances on a Surface and Minimax Manifold Learning in the Isometric-to-Convex Setting. (arXiv:2011.12478v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2011.12478
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#36890;&#36807;&#34920;&#38754;&#37325;&#24314;&#26469;&#33719;&#24471;&#22312;&#20809;&#28369;&#27425;&#27969;&#24418;&#19978;&#20272;&#35745;&#20869;&#22312;&#36317;&#31163;&#30340;&#26497;&#23567;&#26368;&#20248;&#24615;&#20197;&#21450;&#22312;&#31561;&#36317;&#38382;&#39064;&#20013;&#20351;&#29992;&#37325;&#24314;&#34920;&#38754;&#35745;&#31639;&#36317;&#31163;&#30340;Isomap&#21464;&#20307;&#30340;&#26497;&#23567;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#39318;&#20808;&#32771;&#34385;&#20102;&#22312;&#20809;&#28369;&#27425;&#27969;&#24418;&#19978;&#20272;&#35745;&#20869;&#31104;&#36317;&#31163;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#23545;&#34920;&#38754;&#36827;&#34892;&#37325;&#24314;&#21487;&#20197;&#33719;&#24471;&#26497;&#23567;&#26368;&#20248;&#24615;&#65292;&#24182;&#35752;&#35770;&#20102;&#29992;&#20110;&#27492;&#30446;&#30340;&#30340;&#29305;&#23450;&#32593;&#26684;&#26500;&#36896;&#8212;&#8212;&#20999;&#28857;Delaunay&#22797;&#21512;&#20307;&#30340;&#20351;&#29992;&#12290;&#28982;&#21518;&#25105;&#20204;&#36716;&#21521;&#27969;&#24418;&#23398;&#20064;&#65292;&#24182;&#35748;&#20026;&#22312;&#37325;&#24314;&#30340;&#34920;&#38754;&#19978;&#35745;&#31639;&#36317;&#31163;&#30340;Isomap&#21464;&#20307;&#23545;&#20110;&#31561;&#36317;&#38382;&#39064;&#30340;&#26497;&#23567;&#26368;&#20248;&#24615;&#26159;&#21512;&#36866;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We start by considering the problem of estimating intrinsic distances on a smooth submanifold. We show that minimax optimality can be obtained via a reconstruction of the surface, and discuss the use of a particular mesh construction -- the tangential Delaunay complex -- for that purpose. We then turn to manifold learning and argue that a variant of Isomap where the distances are instead computed on a reconstructed surface is minimax optimal for the isometric variant of the problem.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#32508;&#36848;&#20102;&#24378;&#21270;&#23398;&#20064;&#22312;&#32452;&#21512;&#20248;&#21270;&#20013;&#30340;&#24212;&#29992;&#65292;&#29305;&#21035;&#20851;&#27880;&#20102;&#26053;&#34892;&#25512;&#38144;&#21592;&#38382;&#39064;&#12290;&#36890;&#36807;&#27604;&#36739;&#21644;&#24635;&#32467;&#29616;&#20195;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#21644;&#20256;&#32479;&#26041;&#27861;&#30340;&#24046;&#24322;&#65292;&#35770;&#25991;&#23637;&#31034;&#20102;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#20248;&#21183;&#65292;&#24182;&#24378;&#35843;&#20102;&#23558;&#28145;&#24230;&#23398;&#20064;&#26426;&#21046;&#19982;&#24378;&#21270;&#23398;&#20064;&#30456;&#32467;&#21512;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2008.12248</link><description>&lt;p&gt;
&#29992;&#20110;&#32452;&#21512;&#20248;&#21270;&#30340;&#24378;&#21270;&#23398;&#20064;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey on Reinforcement Learning for Combinatorial Optimization. (arXiv:2008.12248v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2008.12248
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#32508;&#36848;&#20102;&#24378;&#21270;&#23398;&#20064;&#22312;&#32452;&#21512;&#20248;&#21270;&#20013;&#30340;&#24212;&#29992;&#65292;&#29305;&#21035;&#20851;&#27880;&#20102;&#26053;&#34892;&#25512;&#38144;&#21592;&#38382;&#39064;&#12290;&#36890;&#36807;&#27604;&#36739;&#21644;&#24635;&#32467;&#29616;&#20195;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#21644;&#20256;&#32479;&#26041;&#27861;&#30340;&#24046;&#24322;&#65292;&#35770;&#25991;&#23637;&#31034;&#20102;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#20248;&#21183;&#65292;&#24182;&#24378;&#35843;&#20102;&#23558;&#28145;&#24230;&#23398;&#20064;&#26426;&#21046;&#19982;&#24378;&#21270;&#23398;&#20064;&#30456;&#32467;&#21512;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35814;&#32454;&#22238;&#39038;&#20102;&#24378;&#21270;&#23398;&#20064;&#22312;&#32452;&#21512;&#20248;&#21270;&#20013;&#30340;&#24212;&#29992;&#65292;&#20171;&#32461;&#20102;&#20174;1950&#24180;&#20195;&#24320;&#22987;&#30340;&#32452;&#21512;&#20248;&#21270;&#21382;&#21490;&#65292;&#24182;&#23558;&#20854;&#19982;&#36817;&#24180;&#26469;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#35770;&#25991;&#29305;&#21035;&#20851;&#27880;&#20102;&#33879;&#21517;&#30340;&#32452;&#21512;&#38382;&#39064;&#8212;&#8212;&#26053;&#34892;&#25512;&#38144;&#21592;&#38382;&#39064;&#65288;TSP&#65289;&#12290;&#23427;&#23558;&#29616;&#20195;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#22312;TSP&#19978;&#30340;&#26041;&#27861;&#19982;1970&#24180;&#20195;&#21457;&#34920;&#30340;&#19968;&#31181;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#36890;&#36807;&#27604;&#36739;&#36825;&#20123;&#26041;&#27861;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#21644;&#24046;&#24322;&#24615;&#65292;&#35770;&#25991;&#23637;&#31034;&#20102;&#30001;&#20110;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#21644;&#35745;&#31639;&#33021;&#21147;&#30340;&#36827;&#21270;&#65292;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#26159;&#22914;&#20309;&#36827;&#34892;&#20248;&#21270;&#30340;&#12290;&#35770;&#25991;&#38543;&#21518;&#31616;&#35201;&#20171;&#32461;&#20102;TSP&#20013;&#30340;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#21363;&#22522;&#20110;&#20256;&#32479;&#25968;&#23398;&#26694;&#26550;&#30340;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#12290;&#22312;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#24341;&#20837;&#20102;&#27880;&#24847;&#21147;&#21644;&#29305;&#24449;&#32534;&#30721;&#26426;&#21046;&#65292;&#20197;&#29983;&#25104;&#36817;&#20284;&#26368;&#20248;&#35299;&#12290;&#35843;&#26597;&#32467;&#26524;&#26174;&#31034;&#65292;&#23558;&#27880;&#24847;&#21147;&#31561;&#28145;&#24230;&#23398;&#20064;&#26426;&#21046;&#19982;&#24378;&#21270;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#36817;&#20284;&#35299;&#20915;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper gives a detailed review of reinforcement learning (RL) in combinatorial optimization, introduces the history of combinatorial optimization starting in the 1950s, and compares it with the RL algorithms of recent years. This paper explicitly looks at a famous combinatorial problem-traveling salesperson problem (TSP). It compares the approach of modern RL algorithms for the TSP with an approach published in the 1970s. By comparing the similarities and variances between these methodologies, the paper demonstrates how RL algorithms are optimized due to the evolution of machine learning techniques and computing power. The paper then briefly introduces the deep learning approach to the TSP named deep RL, which is an extension of the traditional mathematical framework. In deep RL, attention and feature encoding mechanisms are introduced to generate near-optimal solutions. The survey shows that integrating the deep learning mechanism, such as attention with RL, can effectively approx
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23558;&#30417;&#30563;&#23398;&#20064;&#21644;VAEs&#32479;&#19968;&#20110;&#22522;&#20110;&#27491;&#24577;&#27969;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20013;&#65292;&#23545;&#22825;&#25991;&#31890;&#23376;&#37325;&#24314;&#36827;&#34892;&#20102;&#35206;&#30422;&#12289;&#31995;&#32479;&#24615;&#21644;&#25311;&#21512;&#22909;&#22351;&#30340;&#30740;&#31350;&#65292;&#24182;&#36890;&#36807;KL&#25955;&#24230;&#30446;&#26631;&#23454;&#29616;&#20102;&#30417;&#30563;&#23398;&#20064;&#21644;VAEs&#30340;&#32479;&#19968;&#12290;&#21033;&#29992;&#26465;&#20214;&#27491;&#24577;&#21270;&#27969;&#30340;&#26041;&#27861;&#21487;&#20197;&#35745;&#31639;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#25311;&#21512;&#20248;&#24230;p&#20540;&#12290;</title><link>http://arxiv.org/abs/2008.05825</link><description>&lt;p&gt;
&#23558;&#30417;&#30563;&#23398;&#20064;&#21644;VAEs&#32479;&#19968;&#22312;&#22522;&#20110;&#27491;&#24577;&#27969;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20013;&#23545;&#22825;&#25991;&#31890;&#23376;&#37325;&#24314;&#36827;&#34892;&#35206;&#30422;&#12289;&#31995;&#32479;&#24615;&#21644;&#25311;&#21512;&#22909;&#22351;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Unifying supervised learning and VAEs -- coverage, systematics and goodness-of-fit in normalizing-flow based neural network models for astro-particle reconstructions. (arXiv:2008.05825v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2008.05825
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#30417;&#30563;&#23398;&#20064;&#21644;VAEs&#32479;&#19968;&#20110;&#22522;&#20110;&#27491;&#24577;&#27969;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20013;&#65292;&#23545;&#22825;&#25991;&#31890;&#23376;&#37325;&#24314;&#36827;&#34892;&#20102;&#35206;&#30422;&#12289;&#31995;&#32479;&#24615;&#21644;&#25311;&#21512;&#22909;&#22351;&#30340;&#30740;&#31350;&#65292;&#24182;&#36890;&#36807;KL&#25955;&#24230;&#30446;&#26631;&#23454;&#29616;&#20102;&#30417;&#30563;&#23398;&#20064;&#21644;VAEs&#30340;&#32479;&#19968;&#12290;&#21033;&#29992;&#26465;&#20214;&#27491;&#24577;&#21270;&#27969;&#30340;&#26041;&#27861;&#21487;&#20197;&#35745;&#31639;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#25311;&#21512;&#20248;&#24230;p&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22825;&#25991;&#31890;&#23376;&#29289;&#29702;&#23398;&#20013;&#65292;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#20107;&#20214;&#23646;&#24615;&#39044;&#27979;&#21464;&#24471;&#36234;&#26469;&#36234;&#24120;&#35265;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#32467;&#26524;&#21482;&#34987;&#29992;&#20316;&#28857;&#39044;&#27979;&#12290;&#32479;&#35745;&#19981;&#30830;&#23450;&#24615;&#21644;&#35206;&#30422;&#29575;(1)&#65292;&#31995;&#32479;&#19981;&#30830;&#23450;&#24615;(2)&#25110;&#25311;&#21512;&#20248;&#24230;&#24230;&#37327;(3)&#32463;&#24120;&#27809;&#26377;&#34987;&#35745;&#31639;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#31181;&#29305;&#23450;&#30340;&#35757;&#32451;&#21644;&#32593;&#32476;&#26550;&#26500;&#36873;&#25321;&#65292;&#21487;&#20197;&#23558;&#25152;&#26377;&#36825;&#20123;&#23646;&#24615;&#34701;&#20837;&#21040;&#19968;&#20010;&#21333;&#19968;&#30340;&#32593;&#32476;&#27169;&#22411;&#20013;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25968;&#25454;&#21644;&#26631;&#31614;&#32852;&#21512;&#20998;&#24067;&#30340;KL&#25955;&#24230;&#30446;&#26631;&#20351;&#24471;&#22312;&#38543;&#26426;&#21464;&#20998;&#25512;&#29702;&#30340;&#19968;&#31181;&#32479;&#19968;&#19979;&#23558;&#30417;&#30563;&#23398;&#20064;&#21644;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;(VAEs)&#32479;&#19968;&#36215;&#26469;&#12290;&#36825;&#31181;&#32479;&#19968;&#24615;&#28608;&#21457;&#20102;&#19968;&#31181;&#25193;&#23637;&#30340;&#30417;&#30563;&#23398;&#20064;&#26041;&#26696;&#65292;&#21487;&#20197;&#35745;&#31639;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#25311;&#21512;&#20248;&#24230;p&#20540;&#12290;&#22312;&#36825;&#31181;&#24314;&#35774;&#20013;&#65292;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#30340;&#26465;&#20214;&#27491;&#24577;&#21270;&#27969;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#23427;&#20204;&#22914;&#20309;&#20026;&#24050;&#23450;&#20041;&#30340;&#21518;&#39564;&#20998;&#24067;&#20005;&#26684;&#23450;&#20041;&#35206;&#30422;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural-network based predictions of event properties in astro-particle physics are getting more and more common. However, in many cases the result is just utilized as a point prediction. Statistical uncertainties and coverage (1), systematic uncertainties (2) or a goodness-of-fit measure (3) are often not calculated. Here we describe a certain choice of training and network architecture that allows to incorporate all these properties into a single network model. We show that a KL-divergence objective of the joint distribution of data and labels allows to unify supervised learning and variational autoencoders (VAEs) under one umbrella of stochastic variational inference. The unification motivates an extended supervised learning scheme which allows to calculate a goodness-of-fit p-value for the neural network model. Conditional normalizing flows amortized with a neural network are crucial in this construction. We discuss how they allow to rigorously define coverage for posteriors defined
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#20551;&#23450;&#32467;&#26500;&#30340;&#39640;&#38454;&#32858;&#31867;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#38480;&#21046;&#65292;&#30830;&#23450;&#20102;&#32858;&#31867;&#23384;&#22312;&#24615;&#21644;&#32858;&#31867;&#25903;&#25345;&#30340;&#20020;&#30028;&#20540;&#65292;&#24182;&#25552;&#20986;&#20102;&#30456;&#24212;&#30340;&#31639;&#27861;&#12290;&#22312;&#36229;&#22270;&#31181;&#26893;&#22242;&#38382;&#39064;&#21644;&#36229;&#22270;&#31181;&#26893;&#31264;&#23494;&#23376;&#22270;&#24674;&#22797;&#30340;&#35745;&#31639;&#22256;&#38590;&#29468;&#24819;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#29305;&#23450;&#20449;&#22122;&#27604;&#33539;&#22260;&#20869;&#26080;&#27861;&#20351;&#29992;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2005.10743</link><description>&lt;p&gt;
&#24102;&#26377;&#20551;&#23450;&#32467;&#26500;&#30340;&#24352;&#37327;&#32858;&#31867;&#65306;&#32479;&#35745;&#26368;&#20248;&#24615;&#21644;&#35745;&#31639;&#38480;&#21046;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Tensor Clustering with Planted Structures: Statistical Optimality and Computational Limits. (arXiv:2005.10743v4 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2005.10743
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#20551;&#23450;&#32467;&#26500;&#30340;&#39640;&#38454;&#32858;&#31867;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#38480;&#21046;&#65292;&#30830;&#23450;&#20102;&#32858;&#31867;&#23384;&#22312;&#24615;&#21644;&#32858;&#31867;&#25903;&#25345;&#30340;&#20020;&#30028;&#20540;&#65292;&#24182;&#25552;&#20986;&#20102;&#30456;&#24212;&#30340;&#31639;&#27861;&#12290;&#22312;&#36229;&#22270;&#31181;&#26893;&#22242;&#38382;&#39064;&#21644;&#36229;&#22270;&#31181;&#26893;&#31264;&#23494;&#23376;&#22270;&#24674;&#22797;&#30340;&#35745;&#31639;&#22256;&#38590;&#29468;&#24819;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#29305;&#23450;&#20449;&#22122;&#27604;&#33539;&#22260;&#20869;&#26080;&#27861;&#20351;&#29992;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#20551;&#23450;&#32467;&#26500;&#30340;&#39640;&#38454;&#32858;&#31867;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#38480;&#21046;&#12290;&#25105;&#20204;&#20851;&#27880;&#20004;&#31181;&#32858;&#31867;&#27169;&#22411;&#65292;&#24120;&#25968;&#39640;&#38454;&#32858;&#31867;&#65288;CHC&#65289;&#21644;&#31209;&#19968;&#39640;&#38454;&#32858;&#31867;&#65288;ROHC&#65289;&#65292;&#24182;&#30740;&#31350;&#20102;&#27979;&#35797;&#32858;&#31867;&#23384;&#22312;&#24615;&#65288;&#26816;&#27979;&#65289;&#21644;&#35782;&#21035;&#32858;&#31867;&#25903;&#25345;&#65288;&#24674;&#22797;&#65289;&#30340;&#26041;&#27861;&#21644;&#29702;&#35770;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#24403;&#20449;&#22122;&#27604;&#22788;&#20110;&#26576;&#20123;&#20020;&#30028;&#20540;&#26102;&#65292;CHC&#21644;ROHC&#30340;&#26816;&#27979;/&#24674;&#22797;&#26159;&#32479;&#35745;&#19978;&#21487;&#33021;&#30340;&#12290;&#25105;&#20204;&#36824;&#21457;&#23637;&#20102;&#32039;&#23494;&#30340;&#35745;&#31639;&#38408;&#20540;&#65306;&#24403;&#20449;&#22122;&#27604;&#20302;&#20110;&#36825;&#20123;&#38408;&#20540;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#36229;&#22270;&#31181;&#26893;&#22242;&#38382;&#39064;&#65288;HPC&#65289;&#26816;&#27979;&#21644;&#36229;&#22270;&#31181;&#26893;&#31264;&#23494;&#23376;&#22270;&#65288;HPDS&#65289;&#24674;&#22797;&#30340;&#35745;&#31639;&#22256;&#38590;&#29468;&#24819;&#19979;&#65292;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#26080;&#27861;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22810;&#39033;&#24335;&#26102;&#38388;&#30340;&#24352;&#37327;&#31639;&#27861;&#65292;&#22312;&#20449;&#22122;&#27604;&#39640;&#20110;&#36825;&#20123;&#38408;&#20540;&#26102;&#23454;&#29616;&#21487;&#38752;&#30340;&#26816;&#27979;&#21644;&#24674;&#22797;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#31232;&#30095;&#24615;&#21644;...
&lt;/p&gt;
&lt;p&gt;
This paper studies the statistical and computational limits of high-order clustering with planted structures. We focus on two clustering models, constant high-order clustering (CHC) and rank-one higher-order clustering (ROHC), and study the methods and theory for testing whether a cluster exists (detection) and identifying the support of cluster (recovery).  Specifically, we identify the sharp boundaries of signal-to-noise ratio for which CHC and ROHC detection/recovery are statistically possible. We also develop the tight computational thresholds: when the signal-to-noise ratio is below these thresholds, we prove that polynomial-time algorithms cannot solve these problems under the computational hardness conjectures of hypergraphic planted clique (HPC) detection and hypergraphic planted dense subgraph (HPDS) recovery. We also propose polynomial-time tensor algorithms that achieve reliable detection and recovery when the signal-to-noise ratio is above these thresholds. Both sparsity an
&lt;/p&gt;</description></item></channel></rss>