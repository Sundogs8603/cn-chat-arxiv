<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36825;&#20010;&#25945;&#31243;&#20171;&#32461;&#20102;&#31995;&#32479;&#35782;&#21035;&#20013;&#26368;&#36817;&#21457;&#23637;&#30340;&#38750;&#28176;&#36817;&#26041;&#27861;&#12289;&#24378;&#35843;&#20102;&#35206;&#30422;&#25216;&#26415;&#12289;Hanson-Wright&#19981;&#31561;&#24335;&#21644;&#33258;&#26631;&#20934;&#21270;&#39532;&#19969;&#26684;&#23572;&#27861;&#31561;&#24037;&#20855;&#30340;&#24212;&#29992;&#12289;&#24182;&#32473;&#20986;&#20102;&#21033;&#29992;&#36825;&#20123;&#24037;&#20855;&#31616;&#21270;&#35777;&#26126;&#30340;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#22312;&#33258;&#22238;&#24402;&#27169;&#22411;&#20013;&#21442;&#25968;&#35782;&#21035;&#20013;&#30340;&#24615;&#33021;&#12289;&#26368;&#21518;&#20171;&#32461;&#20102;&#23558;&#36825;&#20123;&#24605;&#24819;&#25193;&#23637;&#21040;&#26576;&#20123;&#38750;&#32447;&#24615;&#35782;&#21035;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.03873</link><description>&lt;p&gt;
&#31995;&#32479;&#35782;&#21035;&#30340;&#38750;&#28176;&#36817;&#29702;&#35770;&#25945;&#31243;
&lt;/p&gt;
&lt;p&gt;
A Tutorial on the Non-Asymptotic Theory of System Identification. (arXiv:2309.03873v1 [eess.SY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03873
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#25945;&#31243;&#20171;&#32461;&#20102;&#31995;&#32479;&#35782;&#21035;&#20013;&#26368;&#36817;&#21457;&#23637;&#30340;&#38750;&#28176;&#36817;&#26041;&#27861;&#12289;&#24378;&#35843;&#20102;&#35206;&#30422;&#25216;&#26415;&#12289;Hanson-Wright&#19981;&#31561;&#24335;&#21644;&#33258;&#26631;&#20934;&#21270;&#39532;&#19969;&#26684;&#23572;&#27861;&#31561;&#24037;&#20855;&#30340;&#24212;&#29992;&#12289;&#24182;&#32473;&#20986;&#20102;&#21033;&#29992;&#36825;&#20123;&#24037;&#20855;&#31616;&#21270;&#35777;&#26126;&#30340;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#22312;&#33258;&#22238;&#24402;&#27169;&#22411;&#20013;&#21442;&#25968;&#35782;&#21035;&#20013;&#30340;&#24615;&#33021;&#12289;&#26368;&#21518;&#20171;&#32461;&#20102;&#23558;&#36825;&#20123;&#24605;&#24819;&#25193;&#23637;&#21040;&#26576;&#20123;&#38750;&#32447;&#24615;&#35782;&#21035;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#25945;&#31243;&#20171;&#32461;&#26368;&#36817;&#21457;&#23637;&#30340;&#38750;&#28176;&#36817;&#26041;&#27861;&#22312;&#20027;&#35201;&#32447;&#24615;&#31995;&#32479;&#35782;&#21035;&#29702;&#35770;&#20013;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#24378;&#35843;&#19968;&#20123;&#22312;&#36825;&#20010;&#39046;&#22495;&#20013;&#29305;&#21035;&#26377;&#29992;&#30340;&#24037;&#20855;&#65292;&#22914;&#35206;&#30422;&#25216;&#26415;&#12289;Hanson-Wright&#19981;&#31561;&#24335;&#21644;&#33258;&#26631;&#20934;&#21270;&#39532;&#19969;&#26684;&#23572;&#27861;&#12290;&#28982;&#21518;&#25105;&#20204;&#21033;&#29992;&#36825;&#20123;&#24037;&#20855;&#26469;&#32473;&#20986;&#19968;&#20123;&#22522;&#20110;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#30340;&#24615;&#33021;&#30340;&#31616;&#21270;&#35777;&#26126;&#65292;&#29992;&#20110;&#35782;&#21035;&#33258;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#21442;&#25968;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#27010;&#36848;&#20102;&#22914;&#20309;&#23558;&#25152;&#21576;&#29616;&#30340;&#24605;&#24819;&#25193;&#23637;&#21040;&#26576;&#20123;&#38750;&#32447;&#24615;&#35782;&#21035;&#38382;&#39064;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
This tutorial serves as an introduction to recently developed non-asymptotic methods in the theory of -- mainly linear -- system identification. We emphasize tools we deem particularly useful for a range of problems in this domain, such as the covering technique, the Hanson-Wright Inequality and the method of self-normalized martingales. We then employ these tools to give streamlined proofs of the performance of various least-squares based estimators for identifying the parameters in autoregressive models. We conclude by sketching out how the ideas presented herein can be extended to certain nonlinear identification problems.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22810;&#39033;&#24335;&#25968;&#37327;&#30340;&#26679;&#26412;&#21644;&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#20197;&#20272;&#35745;&#39640;&#26031;&#28151;&#21512;&#29289;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20010;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#32780;&#26080;&#38656;&#23545;GMMs&#20570;&#20219;&#20309;&#32467;&#26500;&#24615;&#20551;&#35774;&#12290;</title><link>http://arxiv.org/abs/2309.03847</link><description>&lt;p&gt;
&#39640;&#26031;&#28151;&#21512;&#29289;&#21487;&#20197;&#36890;&#36807;&#22810;&#39033;&#24335;&#25968;&#37327;&#30340;&#26679;&#26412;&#36827;&#34892;&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Mixtures of Gaussians are Privately Learnable with a Polynomial Number of Samples. (arXiv:2309.03847v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03847
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22810;&#39033;&#24335;&#25968;&#37327;&#30340;&#26679;&#26412;&#21644;&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#20197;&#20272;&#35745;&#39640;&#26031;&#28151;&#21512;&#29289;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20010;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#32780;&#26080;&#38656;&#23545;GMMs&#20570;&#20219;&#20309;&#32467;&#26500;&#24615;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#24046;&#20998;&#38544;&#31169;(DP)&#32422;&#26463;&#19979;&#20272;&#35745;&#39640;&#26031;&#28151;&#21512;&#29289;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#65292;&#20351;&#29992;$\tilde{O}(k^2 d^4 \log(1/\delta) / \alpha^2 \varepsilon)$&#20010;&#26679;&#26412;&#21363;&#21487;&#22312;&#28385;&#36275;$(\varepsilon, \delta)$-DP&#30340;&#26465;&#20214;&#19979;&#20272;&#35745;$k$&#20010;&#39640;&#26031;&#28151;&#21512;&#29289;&#65292;&#20351;&#20854;&#36798;&#21040;&#24635;&#21464;&#24046;&#36317;&#31163;$\alpha$&#12290;&#36825;&#26159;&#35813;&#38382;&#39064;&#30340;&#31532;&#19968;&#20010;&#26377;&#38480;&#26679;&#26412;&#22797;&#26434;&#24615;&#19978;&#38480;&#65292;&#32780;&#26080;&#38656;&#23545;GMMs&#20570;&#20219;&#20309;&#32467;&#26500;&#24615;&#20551;&#35774;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#23545;&#20110;&#20854;&#20182;&#20219;&#21153;&#21487;&#33021;&#20063;&#26377;&#29992;&#12290;&#22312;&#39640;&#23618;&#27425;&#19978;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#26524;&#19968;&#20010;&#20998;&#24067;&#31867;&#65288;&#27604;&#22914;&#39640;&#26031;&#20998;&#24067;&#65289;&#26159;&#65288;1&#65289;&#21487;&#21015;&#34920;&#35793;&#30721;&#30340;&#24182;&#19988;&#65288;2&#65289;&#22312;&#24635;&#21464;&#24046;&#36317;&#31163;&#26041;&#38754;&#20855;&#26377;&#8220;&#23616;&#37096;&#23567;&#8221;&#35206;&#30422;[ BKSW19]&#65292;&#21017;&#20854;&#28151;&#21512;&#29289;&#31867;&#26159;&#31169;&#23494;&#21487;&#23398;&#20064;&#30340;&#12290;&#35777;&#26126;&#32469;&#36807;&#20102;&#19968;&#20010;&#24050;&#30693;&#38556;&#30861;&#65292;&#34920;&#26126;&#19982;&#39640;&#26031;&#20998;&#24067;&#19981;&#21516;&#65292;GMMs&#19981;&#20855;&#26377;&#23616;&#37096;&#23567;&#30340;&#35206;&#30422;[AAL21]&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of estimating mixtures of Gaussians under the constraint of differential privacy (DP). Our main result is that $\tilde{O}(k^2 d^4 \log(1/\delta) / \alpha^2 \varepsilon)$ samples are sufficient to estimate a mixture of $k$ Gaussians up to total variation distance $\alpha$ while satisfying $(\varepsilon, \delta)$-DP. This is the first finite sample complexity upper bound for the problem that does not make any structural assumptions on the GMMs.  To solve the problem, we devise a new framework which may be useful for other tasks. On a high level, we show that if a class of distributions (such as Gaussians) is (1) list decodable and (2) admits a "locally small'' cover [BKSW19] with respect to total variation distance, then the class of its mixtures is privately learnable. The proof circumvents a known barrier indicating that, unlike Gaussians, GMMs do not admit a locally small cover [AAL21].
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#26799;&#24230;&#30340;&#32467;&#26500;&#21270;&#25968;&#25454;&#29305;&#24449;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#21457;&#29616;&#20102;&#22312;&#38750;&#21508;&#21521;&#24322;&#24615;&#35774;&#32622;&#20013;&#65292;&#24120;&#29992;&#30340;&#29699;&#24418;&#26799;&#24230;&#21160;&#21147;&#23398;&#21487;&#33021;&#26080;&#27861;&#24674;&#22797;&#30495;&#23454;&#26041;&#21521;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#24403;&#30340;&#26435;&#37325;&#24402;&#19968;&#21270;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#36890;&#36807;&#21033;&#29992;&#36755;&#20837;&#21327;&#26041;&#24046;&#19982;&#30446;&#26631;&#20043;&#38388;&#30340;&#23545;&#40784;&#65292;&#21487;&#20197;&#33719;&#24471;&#27604;&#21508;&#21521;&#21516;&#24615;&#24773;&#20917;&#26356;&#22909;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2309.03843</link><description>&lt;p&gt;
&#22522;&#20110;&#26799;&#24230;&#30340;&#32467;&#26500;&#21270;&#25968;&#25454;&#29305;&#24449;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Gradient-Based Feature Learning under Structured Data. (arXiv:2309.03843v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03843
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#26799;&#24230;&#30340;&#32467;&#26500;&#21270;&#25968;&#25454;&#29305;&#24449;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#21457;&#29616;&#20102;&#22312;&#38750;&#21508;&#21521;&#24322;&#24615;&#35774;&#32622;&#20013;&#65292;&#24120;&#29992;&#30340;&#29699;&#24418;&#26799;&#24230;&#21160;&#21147;&#23398;&#21487;&#33021;&#26080;&#27861;&#24674;&#22797;&#30495;&#23454;&#26041;&#21521;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#24403;&#30340;&#26435;&#37325;&#24402;&#19968;&#21270;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#36890;&#36807;&#21033;&#29992;&#36755;&#20837;&#21327;&#26041;&#24046;&#19982;&#30446;&#26631;&#20043;&#38388;&#30340;&#23545;&#40784;&#65292;&#21487;&#20197;&#33719;&#24471;&#27604;&#21508;&#21521;&#21516;&#24615;&#24773;&#20917;&#26356;&#22909;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22522;&#20110;&#26799;&#24230;&#30340;&#21333;&#25351;&#25968;&#27169;&#22411;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#21462;&#20915;&#20110;&#23427;&#20204;&#30340;&#20449;&#24687;&#25351;&#25968;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#32467;&#26524;&#20165;&#28041;&#21450;&#21508;&#21521;&#21516;&#24615;&#25968;&#25454;&#65292;&#32780;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#36755;&#20837;&#24448;&#24448;&#21253;&#21547;&#39069;&#22806;&#30340;&#32467;&#26500;&#65292;&#21487;&#20197;&#38544;&#21547;&#22320;&#25351;&#23548;&#31639;&#27861;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#23574;&#23792;&#21327;&#26041;&#24046;&#32467;&#26500;&#30340;&#24433;&#21709;&#65292;&#24182;&#25581;&#31034;&#20102;&#19968;&#20123;&#26377;&#36259;&#30340;&#29616;&#35937;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#38750;&#21508;&#21521;&#24322;&#24615;&#35774;&#32622;&#20013;&#65292;&#24120;&#29992;&#30340;&#29699;&#24418;&#26799;&#24230;&#21160;&#21147;&#23398;&#21363;&#20351;&#22312;&#23574;&#23792;&#19982;&#30446;&#26631;&#26041;&#21521;&#23436;&#20840;&#23545;&#40784;&#26102;&#20063;&#21487;&#33021;&#26080;&#27861;&#24674;&#22797;&#30495;&#23454;&#26041;&#21521;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#36866;&#24403;&#30340;&#26435;&#37325;&#24402;&#19968;&#21270;&#26041;&#27861;&#65292;&#31867;&#20284;&#20110;&#25209;&#37327;&#24402;&#19968;&#21270;&#65292;&#21487;&#20197;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#21033;&#29992;&#65288;&#23574;&#23792;&#65289;&#36755;&#20837;&#21327;&#26041;&#24046;&#19982;&#30446;&#26631;&#20043;&#38388;&#30340;&#23545;&#40784;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#27604;&#21508;&#21521;&#21516;&#24615;&#24773;&#20917;&#26356;&#22909;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent works have demonstrated that the sample complexity of gradient-based learning of single index models, i.e. functions that depend on a 1-dimensional projection of the input data, is governed by their information exponent. However, these results are only concerned with isotropic data, while in practice the input often contains additional structure which can implicitly guide the algorithm. In this work, we investigate the effect of a spiked covariance structure and reveal several interesting phenomena. First, we show that in the anisotropic setting, the commonly used spherical gradient dynamics may fail to recover the true direction, even when the spike is perfectly aligned with the target direction. Next, we show that appropriate weight normalization that is reminiscent of batch normalization can alleviate this issue. Further, by exploiting the alignment between the (spiked) input covariance and the target, we obtain improved sample complexity compared to the isotropic case. In pa
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23450;&#21521;&#24322;&#24615;&#25193;&#25955;&#22270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25429;&#25417;&#20302;&#32500;&#27969;&#24418;&#20013;&#30340;&#28508;&#22312;&#28436;&#21270;&#21160;&#24577;&#65292;&#33021;&#22815;&#26377;&#25928;&#25552;&#21462;&#26089;&#26399;&#35686;&#25253;&#20449;&#21495;&#26469;&#26816;&#27979;&#22797;&#26434;&#31995;&#32479;&#25110;&#39640;&#32500;&#35266;&#27979;&#25968;&#25454;&#20013;&#30340;&#21160;&#21147;&#23398;&#36716;&#21464;&#65292;&#24182;&#22312;&#30495;&#23454;&#30340;&#33041;&#30005;&#22270;&#25968;&#25454;&#19978;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2309.03842</link><description>&lt;p&gt;
&#38544;&#24615;&#38543;&#26426;&#21160;&#21147;&#23398;&#31995;&#32479;&#20013;&#30340;&#36716;&#21521;&#39044;&#35686;
&lt;/p&gt;
&lt;p&gt;
Early warning via transitions in latent stochastic dynamical systems. (arXiv:2309.03842v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03842
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23450;&#21521;&#24322;&#24615;&#25193;&#25955;&#22270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25429;&#25417;&#20302;&#32500;&#27969;&#24418;&#20013;&#30340;&#28508;&#22312;&#28436;&#21270;&#21160;&#24577;&#65292;&#33021;&#22815;&#26377;&#25928;&#25552;&#21462;&#26089;&#26399;&#35686;&#25253;&#20449;&#21495;&#26469;&#26816;&#27979;&#22797;&#26434;&#31995;&#32479;&#25110;&#39640;&#32500;&#35266;&#27979;&#25968;&#25454;&#20013;&#30340;&#21160;&#21147;&#23398;&#36716;&#21464;&#65292;&#24182;&#22312;&#30495;&#23454;&#30340;&#33041;&#30005;&#22270;&#25968;&#25454;&#19978;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#22914;&#22522;&#22240;&#31361;&#21464;&#12289;&#33041;&#30142;&#30149;&#12289;&#33258;&#28982;&#28798;&#23475;&#12289;&#37329;&#34701;&#21361;&#26426;&#21644;&#24037;&#31243;&#21487;&#38752;&#24615;&#65292;&#23545;&#22797;&#26434;&#31995;&#32479;&#25110;&#39640;&#32500;&#35266;&#27979;&#25968;&#25454;&#20013;&#30340;&#21160;&#21147;&#23398;&#36716;&#21464;&#36827;&#34892;&#26089;&#26399;&#35686;&#25253;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#20026;&#20102;&#26377;&#25928;&#25552;&#21462;&#26089;&#26399;&#35686;&#25253;&#20449;&#21495;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65306;&#23450;&#21521;&#24322;&#24615;&#25193;&#25955;&#22270;&#65292;&#23427;&#25429;&#25417;&#20102;&#20302;&#32500;&#27969;&#24418;&#20013;&#30340;&#28508;&#22312;&#28436;&#21270;&#21160;&#24577;&#12290;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#30495;&#23454;&#30340;&#33041;&#30005;&#22270;&#65288;EEG&#65289;&#25968;&#25454;&#65292;&#25105;&#20204;&#25104;&#21151;&#25214;&#21040;&#20102;&#36866;&#24403;&#30340;&#26377;&#25928;&#22352;&#26631;&#65292;&#24182;&#25512;&#23548;&#20986;&#33021;&#22815;&#26816;&#27979;&#29366;&#24577;&#36716;&#21464;&#20013;&#20020;&#30028;&#28857;&#30340;&#26089;&#26399;&#35686;&#25253;&#20449;&#21495;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#28508;&#22312;&#21160;&#24577;&#19982;&#21407;&#22987;&#25968;&#25454;&#38598;&#32852;&#31995;&#36215;&#26469;&#12290;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26694;&#26550;&#22312;&#23494;&#24230;&#21644;&#36716;&#21464;&#27010;&#29575;&#31561;&#26041;&#38754;&#30340;&#20934;&#30830;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#31532;&#20108;&#20010;&#22352;&#26631;&#22312;&#21508;&#31181;&#35780;&#20272;&#25351;&#26631;&#20013;&#20445;&#25345;&#26377;&#24847;&#20041;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Early warnings for dynamical transitions in complex systems or high-dimensional observation data are essential in many real world applications, such as gene mutation, brain diseases, natural disasters, financial crises, and engineering reliability. To effectively extract early warning signals, we develop a novel approach: the directed anisotropic diffusion map that captures the latent evolutionary dynamics in low-dimensional manifold. Applying the methodology to authentic electroencephalogram (EEG) data, we successfully find the appropriate effective coordinates, and derive early warning signals capable of detecting the tipping point during the state transition. Our method bridges the latent dynamics with the original dataset. The framework is validated to be accurate and effective through numerical experiments, in terms of density and transition probability. It is shown that the second coordinate holds meaningful information for critical transition in various evaluation metrics.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#37325;&#23614;&#20998;&#24067;&#26465;&#20214;&#19979;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#39118;&#38505;&#20540;&#36873;&#25321;&#20248;&#21270;&#22120;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#24191;&#20041;&#36890;&#29992;&#38142;&#26041;&#27861;&#24314;&#31435;&#20102;&#36807;&#24230;&#39118;&#38505;&#30340;&#19978;&#30028;&#12290;&#25968;&#20540;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;Catoni&#39118;&#26684;&#20272;&#35745;&#30340;&#32463;&#39564;&#39118;&#38505;&#20248;&#21270;&#22120;&#27604;&#20854;&#20182;&#22522;&#20934;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2309.03818</link><description>&lt;p&gt;
&#26080;&#26041;&#24046;&#25439;&#22833;&#19979;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;
&lt;/p&gt;
&lt;p&gt;
Empirical Risk Minimization for Losses without Variance. (arXiv:2309.03818v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03818
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#37325;&#23614;&#20998;&#24067;&#26465;&#20214;&#19979;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#39118;&#38505;&#20540;&#36873;&#25321;&#20248;&#21270;&#22120;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#24191;&#20041;&#36890;&#29992;&#38142;&#26041;&#27861;&#24314;&#31435;&#20102;&#36807;&#24230;&#39118;&#38505;&#30340;&#19978;&#30028;&#12290;&#25968;&#20540;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;Catoni&#39118;&#26684;&#20272;&#35745;&#30340;&#32463;&#39564;&#39118;&#38505;&#20248;&#21270;&#22120;&#27604;&#20854;&#20182;&#22522;&#20934;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#22312;&#37325;&#23614;&#20998;&#24067;&#26465;&#20214;&#19979;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#25968;&#25454;&#27809;&#26377;&#26377;&#38480;&#26041;&#24046;&#65292;&#20294;&#21482;&#26377;$p$&#38454;&#30697;&#65292;&#20854;&#20013;$p \in (1,2)$&#12290;&#25105;&#20204;&#36873;&#25321;&#36890;&#36807;&#26368;&#23567;&#21270;&#39118;&#38505;&#20540;&#26469;&#36873;&#25321;&#20248;&#21270;&#22120;&#65292;&#32780;&#19981;&#26159;&#20351;&#29992;&#22522;&#20110;&#25130;&#26029;&#35266;&#27979;&#25968;&#25454;&#30340;&#20272;&#35745;&#36807;&#31243;&#12290;&#36825;&#20123;&#39118;&#38505;&#20540;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;Catoni&#30340;&#26174;&#33879;&#26041;&#27861;&#65288;Catoni, 2012&#65289;&#36827;&#34892;&#31283;&#20581;&#20272;&#35745;&#26469;&#24471;&#21040;&#12290;&#30001;&#20110;Catoni&#22411;&#24433;&#21709;&#20989;&#25968;&#30340;&#32467;&#26500;&#65292;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#20351;&#29992;&#24191;&#20041;&#30340;&#36890;&#29992;&#38142;&#26041;&#27861;&#24314;&#31435;&#36807;&#24230;&#39118;&#38505;&#30340;&#19978;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#35745;&#31639;&#38382;&#39064;&#12290;&#25105;&#20204;&#29305;&#21035;&#20174;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;&#20004;&#31181;&#31867;&#22411;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#21363;&#31283;&#20581;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#21644;&#22522;&#20110;&#32463;&#39564;&#39118;&#38505;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#25968;&#20540;&#30740;&#31350;&#65292;&#25105;&#20204;&#21457;&#29616;&#36890;&#36807;Catoni&#39118;&#26684;&#20272;&#35745;&#30340;&#32463;&#39564;&#39118;&#38505;&#20248;&#21270;&#22120;&#30830;&#23454;&#27604;&#20854;&#20182;&#22522;&#20934;&#34920;&#29616;&#26356;&#22909;&#12290;&#36825;&#34920;&#26126;&#30452;&#25509;&#22522;&#20110;&#25130;&#26029;&#25968;&#25454;&#30340;&#20272;&#35745;&#21487;&#33021;&#20250;&#23548;&#33268;&#36739;&#24046;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper considers an empirical risk minimization problem under heavy-tailed settings, where data does not have finite variance, but only has $p$-th moment with $p \in (1,2)$. Instead of using estimation procedure based on truncated observed data, we choose the optimizer by minimizing the risk value. Those risk values can be robustly estimated via using the remarkable Catoni's method (Catoni, 2012). Thanks to the structure of Catoni-type influence functions, we are able to establish excess risk upper bounds via using generalized generic chaining methods. Moreover, we take computational issues into consideration. We especially theoretically investigate two types of optimization methods, robust gradient descent algorithm and empirical risk-based methods. With an extensive numerical study, we find that the optimizer based on empirical risks via Catoni-style estimation indeed shows better performance than other baselines. It indicates that estimation directly based on truncated data may 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#35889;&#26041;&#27861;&#25913;&#36827;&#20102;&#25490;&#21517;&#32858;&#21512;&#38382;&#39064;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#36890;&#36807;&#30740;&#31350;&#22522;&#20110;&#26410;&#24402;&#19968;&#21270;&#21644;&#24402;&#19968;&#21270;&#25968;&#25454;&#30697;&#38453;&#30340;&#35889;&#25490;&#21517;&#31639;&#27861;&#65292;&#25552;&#20379;&#20102;&#26356;&#20934;&#30830;&#30340;&#25200;&#21160;&#35823;&#24046;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2309.03808</link><description>&lt;p&gt;
&#36890;&#36807;&#35889;&#26041;&#27861;&#25913;&#36827;&#20102;&#25490;&#21517;&#32858;&#21512;&#30340;&#29702;&#35770;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Improved theoretical guarantee for rank aggregation via spectral method. (arXiv:2309.03808v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03808
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#35889;&#26041;&#27861;&#25913;&#36827;&#20102;&#25490;&#21517;&#32858;&#21512;&#38382;&#39064;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#36890;&#36807;&#30740;&#31350;&#22522;&#20110;&#26410;&#24402;&#19968;&#21270;&#21644;&#24402;&#19968;&#21270;&#25968;&#25454;&#30697;&#38453;&#30340;&#35889;&#25490;&#21517;&#31639;&#27861;&#65292;&#25552;&#20379;&#20102;&#26356;&#20934;&#30830;&#30340;&#25200;&#21160;&#35823;&#24046;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32473;&#23450;&#22810;&#20010;&#39033;&#30446;&#20043;&#38388;&#30340;&#25104;&#23545;&#27604;&#36739;&#65292;&#22914;&#20309;&#23545;&#23427;&#20204;&#36827;&#34892;&#25490;&#21517;&#20197;&#20351;&#24471;&#25490;&#21517;&#19982;&#35266;&#23519;&#30456;&#21305;&#37197;&#65311;&#36825;&#20010;&#38382;&#39064;&#34987;&#31216;&#20026;&#25490;&#21517;&#32858;&#21512;&#65292;&#22312;&#20307;&#32946;&#12289;&#25512;&#33616;&#31995;&#32479;&#21644;&#20854;&#20182;&#32593;&#32476;&#24212;&#29992;&#20013;&#24050;&#32463;&#25214;&#21040;&#20102;&#35768;&#22810;&#24212;&#29992;&#12290;&#30001;&#20110;&#25214;&#21040;&#26368;&#23567;&#21270;&#19981;&#21305;&#37197;&#30340;&#20840;&#23616;&#25490;&#21517;&#36890;&#24120;&#26159;NP&#22256;&#38590;&#30340;&#65288;&#31216;&#20026;Kemeny&#20248;&#21270;&#65289;&#65292;&#25105;&#20204;&#23558;&#37325;&#28857;&#25918;&#22312;Erd\"os-R\'enyi&#31163;&#32676;&#28857;&#65288;ERO&#65289;&#27169;&#22411;&#19978;&#12290;&#22312;&#36825;&#20010;&#25490;&#21517;&#38382;&#39064;&#20013;&#65292;&#27599;&#20010;&#25104;&#23545;&#27604;&#36739;&#26159;&#30495;&#23454;&#20998;&#25968;&#24046;&#24322;&#30340;&#34987;&#25439;&#22351;&#21103;&#26412;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;&#26410;&#24402;&#19968;&#21270;&#21644;&#24402;&#19968;&#21270;&#25968;&#25454;&#30697;&#38453;&#30340;&#35889;&#25490;&#21517;&#31639;&#27861;&#12290;&#20851;&#38190;&#26159;&#29702;&#35299;&#23427;&#20204;&#22312;&#20174;&#35266;&#23519;&#25968;&#25454;&#20013;&#24674;&#22797;&#27599;&#20010;&#39033;&#30446;&#30340;&#28508;&#22312;&#20998;&#25968;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;&#36825;&#24402;&#32467;&#20026;&#25512;&#23548;&#26410;&#24402;&#19968;&#21270;/&#24402;&#19968;&#21270;&#25968;&#25454;&#30697;&#38453;&#30340;&#21069;&#20960;&#20010;&#29305;&#24449;&#21521;&#37327;&#21644;&#20854;&#24635;&#20307;&#23545;&#24212;&#29289;&#20043;&#38388;&#30340;&#36880;&#20010;&#39033;&#25200;&#21160;&#35823;&#24046;&#30028;&#38480;&#12290;&#36890;&#36807;&#20351;&#29992;&#30041;&#20986;&#25216;&#26415;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#26356;&#20934;&#30830;&#30340;$\ell_{\infty}$-norm&#25200;&#21160;&#35823;&#24046;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given pairwise comparisons between multiple items, how to rank them so that the ranking matches the observations? This problem, known as rank aggregation, has found many applications in sports, recommendation systems, and other web applications. As it is generally NP-hard to find a global ranking that minimizes the mismatch (known as the Kemeny optimization), we focus on the Erd\"os-R\'enyi outliers (ERO) model for this ranking problem. Here, each pairwise comparison is a corrupted copy of the true score difference. We investigate spectral ranking algorithms that are based on unnormalized and normalized data matrices. The key is to understand their performance in recovering the underlying scores of each item from the observed data. This reduces to deriving an entry-wise perturbation error bound between the top eigenvectors of the unnormalized/normalized data matrix and its population counterpart. By using the leave-one-out technique, we provide a sharper $\ell_{\infty}$-norm perturbati
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#35774;&#35745;&#20013;&#30340;&#24494;&#22937;&#36873;&#25321;&#65292;&#29305;&#21035;&#20851;&#27880;&#35745;&#31639;&#32479;&#35745;&#24046;&#36317;&#12290;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#39564;&#65292;&#21457;&#29616;&#31232;&#30095;&#21021;&#22987;&#21270;&#21644;&#22686;&#21152;&#32593;&#32476;&#23485;&#24230;&#21487;&#20197;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#65292;&#24182;&#19988;&#21512;&#25104;&#31232;&#30095;&#22855;&#20598;&#20219;&#21153;&#21487;&#20197;&#20316;&#20026;&#30495;&#23454;&#38382;&#39064;&#30340;&#20195;&#29702;&#12290;</title><link>http://arxiv.org/abs/2309.03800</link><description>&lt;p&gt;
&#31070;&#32463;&#29305;&#24449;&#23398;&#20064;&#20013;&#30340;&#24085;&#32047;&#25176;&#21069;&#27839;&#65306;&#25968;&#25454;&#12289;&#35745;&#31639;&#12289;&#23485;&#24230;&#21644;&#36816;&#27668;
&lt;/p&gt;
&lt;p&gt;
Pareto Frontiers in Neural Feature Learning: Data, Compute, Width, and Luck. (arXiv:2309.03800v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03800
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#35774;&#35745;&#20013;&#30340;&#24494;&#22937;&#36873;&#25321;&#65292;&#29305;&#21035;&#20851;&#27880;&#35745;&#31639;&#32479;&#35745;&#24046;&#36317;&#12290;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#39564;&#65292;&#21457;&#29616;&#31232;&#30095;&#21021;&#22987;&#21270;&#21644;&#22686;&#21152;&#32593;&#32476;&#23485;&#24230;&#21487;&#20197;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#65292;&#24182;&#19988;&#21512;&#25104;&#31232;&#30095;&#22855;&#20598;&#20219;&#21153;&#21487;&#20197;&#20316;&#20026;&#30495;&#23454;&#38382;&#39064;&#30340;&#20195;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#35745;&#31639;&#32479;&#35745;&#24046;&#36317;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#28145;&#24230;&#23398;&#20064;&#20013;&#24494;&#22937;&#30340;&#31639;&#27861;&#35774;&#35745;&#36873;&#25321;&#12290;&#25105;&#20204;&#39318;&#20808;&#32771;&#34385;&#20102;&#31163;&#32447;&#31232;&#30095;&#22855;&#20598;&#23398;&#20064;&#65292;&#36825;&#26159;&#19968;&#20010;&#26377;&#20851;&#22810;&#23618;&#24863;&#30693;&#22120;&#26799;&#24230;&#35757;&#32451;&#30340;&#30417;&#30563;&#20998;&#31867;&#38382;&#39064;&#65292;&#20854;&#20855;&#26377;&#32479;&#35745;&#26597;&#35810;&#19979;&#30028;&#12290;&#36825;&#20010;&#19979;&#30028;&#21487;&#20197;&#35299;&#37322;&#20026;&#22810;&#36164;&#28304;&#30340;&#26435;&#34913;&#21069;&#27839;&#65306;&#25104;&#21151;&#23398;&#20064;&#21482;&#26377;&#22312;&#19968;&#20010;&#36275;&#22815;&#20016;&#23500;&#65288;&#22823;&#22411;&#27169;&#22411;&#65289;&#12289;&#30693;&#35782;&#28170;&#21338;&#65288;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#65289;&#12289;&#32784;&#24515;&#65288;&#35757;&#32451;&#36845;&#20195;&#27425;&#25968;&#22810;&#65289;&#25110;&#24184;&#36816;&#65288;&#38543;&#26426;&#29468;&#27979;&#27425;&#25968;&#22810;&#65289;&#30340;&#24773;&#20917;&#19979;&#25165;&#33021;&#21457;&#29983;&#12290;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#39564;&#34920;&#26126;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#31232;&#30095;&#21021;&#22987;&#21270;&#21644;&#22686;&#21152;&#32593;&#32476;&#23485;&#24230;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#12290;&#22312;&#36825;&#37324;&#65292;&#23485;&#24230;&#36215;&#21040;&#20102;&#24182;&#34892;&#25628;&#32034;&#30340;&#20316;&#29992;&#65306;&#23427;&#22686;&#21152;&#20102;&#25214;&#21040;&#8220;&#24184;&#36816;&#31070;&#32463;&#20803;&#8221;&#30340;&#27010;&#29575;&#65292;&#36825;&#20123;&#31070;&#32463;&#20803;&#21487;&#20197;&#26356;&#39640;&#25928;&#22320;&#23398;&#20064;&#31232;&#30095;&#29305;&#24449;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#34920;&#26126;&#21512;&#25104;&#31232;&#30095;&#22855;&#20598;&#20219;&#21153;&#21487;&#20197;&#20316;&#20026;&#30495;&#23454;&#38382;&#39064;&#30340;&#20195;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work investigates the nuanced algorithm design choices for deep learning in the presence of computational-statistical gaps. We begin by considering offline sparse parity learning, a supervised classification problem which admits a statistical query lower bound for gradient-based training of a multilayer perceptron. This lower bound can be interpreted as a multi-resource tradeoff frontier: successful learning can only occur if one is sufficiently rich (large model), knowledgeable (large dataset), patient (many training iterations), or lucky (many random guesses). We show, theoretically and experimentally, that sparse initialization and increasing network width yield significant improvements in sample efficiency in this setting. Here, width plays the role of parallel search: it amplifies the probability of finding "lottery ticket" neurons, which learn sparse features more sample-efficiently. Finally, we show that the synthetic sparse parity task can be useful as a proxy for real pro
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;ARMOR_D&#26469;&#21152;&#24378;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#27491;&#21017;&#21270;&#24046;&#24322;&#65292;&#36890;&#36807;&#22312;&#20998;&#24067;&#30340;&#37051;&#22495;&#19978;&#36827;&#34892;&#26368;&#22823;&#21270;&#26399;&#26395;&#25439;&#22833;&#26469;&#23454;&#29616;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;ARMOR_D&#26041;&#27861;&#22312;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#21644;&#22270;&#20687;&#35782;&#21035;&#24212;&#29992;&#20013;&#33021;&#22815;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#22312;&#23545;&#25239;&#25915;&#20987;&#19979;&#30340;&#40065;&#26834;&#24615;&#26041;&#38754;&#20855;&#26377;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.03791</link><description>&lt;p&gt;
&#20351;&#29992;&#26368;&#20248;&#20256;&#36755;&#27491;&#21017;&#21270;&#24046;&#24322;&#26469;&#25552;&#39640;&#23545;&#25239;&#24615;&#40065;&#26834;&#28145;&#24230;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Adversarially Robust Deep Learning with Optimal-Transport-Regularized Divergences. (arXiv:2309.03791v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03791
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;ARMOR_D&#26469;&#21152;&#24378;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#27491;&#21017;&#21270;&#24046;&#24322;&#65292;&#36890;&#36807;&#22312;&#20998;&#24067;&#30340;&#37051;&#22495;&#19978;&#36827;&#34892;&#26368;&#22823;&#21270;&#26399;&#26395;&#25439;&#22833;&#26469;&#23454;&#29616;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;ARMOR_D&#26041;&#27861;&#22312;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#21644;&#22270;&#20687;&#35782;&#21035;&#24212;&#29992;&#20013;&#33021;&#22815;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#22312;&#23545;&#25239;&#25915;&#20987;&#19979;&#30340;&#40065;&#26834;&#24615;&#26041;&#38754;&#20855;&#26377;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;ARMOR_D&#26041;&#27861;&#20316;&#20026;&#22686;&#24378;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#30340;&#21019;&#26032;&#26041;&#27861;&#12290;&#36825;&#20123;&#26041;&#27861;&#22522;&#20110;&#19968;&#31181;&#26032;&#30340;&#26368;&#20248;&#20256;&#36755;&#27491;&#21017;&#21270;&#24046;&#24322;&#31867;&#65292;&#36890;&#36807;&#20449;&#24687;&#24046;&#24322;&#21644;&#26368;&#20248;&#20256;&#36755;&#25104;&#26412;&#20043;&#38388;&#30340;infimal&#21367;&#31215;&#26500;&#24314;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#20123;&#26041;&#27861;&#26469;&#22686;&#24378;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#65292;&#36890;&#36807;&#22312;&#20998;&#24067;&#30340;&#37051;&#22495;&#19978;&#26368;&#22823;&#21270;&#26399;&#26395;&#25439;&#22833;&#65292;&#36825;&#34987;&#31216;&#20026;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#25216;&#26415;&#12290;&#20316;&#20026;&#26500;&#24314;&#23545;&#25239;&#26679;&#26412;&#30340;&#24037;&#20855;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#26679;&#26412;&#26681;&#25454;&#26368;&#20248;&#20256;&#36755;&#25104;&#26412;&#36827;&#34892;&#20256;&#36755;&#65292;&#24182;&#26681;&#25454;&#20449;&#24687;&#24046;&#24322;&#36827;&#34892;&#37325;&#26032;&#21152;&#26435;&#12290;&#25105;&#20204;&#22312;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#21644;&#22270;&#20687;&#35782;&#21035;&#24212;&#29992;&#19978;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#21457;&#29616;&#22312;&#22686;&#24378;&#23545;&#25239;&#25915;&#20987;&#40065;&#26834;&#24615;&#26041;&#38754;&#65292;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#23427;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;ARMOR_D&#22312;FGSM&#25915;&#20987;&#19979;&#30340;robustified&#20934;&#30830;&#29575;&#36798;&#21040;98.29%&#65292;&#22312;&#20854;&#20182;&#25915;&#20987;&#19979;&#36798;&#21040;98.18%&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce the $ARMOR_D$ methods as novel approaches to enhancing the adversarial robustness of deep learning models. These methods are based on a new class of optimal-transport-regularized divergences, constructed via an infimal convolution between an information divergence and an optimal-transport (OT) cost. We use these as tools to enhance adversarial robustness by maximizing the expected loss over a neighborhood of distributions, a technique known as distributionally robust optimization. Viewed as a tool for constructing adversarial samples, our method allows samples to be both transported, according to the OT cost, and re-weighted, according to the information divergence. We demonstrate the effectiveness of our method on malware detection and image recognition applications and find that, to our knowledge, it outperforms existing methods at enhancing the robustness against adversarial attacks. $ARMOR_D$ yields the robustified accuracy of $98.29\%$ against $FGSM$ and $98.18\%$ aga
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#22871;&#32034;&#26041;&#27861;&#65292;&#23558;&#22871;&#32034;&#21644;&#31070;&#32463;&#32593;&#32476;&#30456;&#32467;&#21512;&#65292;&#36890;&#36807;&#27169;&#20223;&#32479;&#35745;&#26694;&#26550;&#36827;&#34892;&#20462;&#25913;&#30340;&#26041;&#24335;&#65292;&#22312;&#21464;&#37327;&#36873;&#25321;&#20013;&#25552;&#20379;&#26356;&#20934;&#30830;&#30340;&#21442;&#25968;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2309.03770</link><description>&lt;p&gt;
&#31070;&#32463;&#22871;&#32034;&#65306;&#19968;&#31181;&#23558;&#22871;&#32034;&#21644;&#31070;&#32463;&#32593;&#32476;&#30456;&#32467;&#21512;&#30340;&#32479;&#19968;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Neural lasso: a unifying approach of lasso and neural networks. (arXiv:2309.03770v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03770
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#22871;&#32034;&#26041;&#27861;&#65292;&#23558;&#22871;&#32034;&#21644;&#31070;&#32463;&#32593;&#32476;&#30456;&#32467;&#21512;&#65292;&#36890;&#36807;&#27169;&#20223;&#32479;&#35745;&#26694;&#26550;&#36827;&#34892;&#20462;&#25913;&#30340;&#26041;&#24335;&#65292;&#22312;&#21464;&#37327;&#36873;&#25321;&#20013;&#25552;&#20379;&#26356;&#20934;&#30830;&#30340;&#21442;&#25968;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#23558;&#32479;&#35745;&#21644;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30340;&#25216;&#26415;&#30456;&#32467;&#21512;&#20197;&#33719;&#24471;&#20004;&#31181;&#26041;&#27861;&#30340;&#20248;&#28857;&#24050;&#32463;&#25104;&#20026;&#30740;&#31350;&#28909;&#28857;&#12290;&#26412;&#25991;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#26469;&#34920;&#31034;&#21464;&#37327;&#36873;&#25321;&#30340;&#32479;&#35745;&#25216;&#26415;&#22871;&#32034;&#12290;&#35266;&#23519;&#21457;&#29616;&#65292;&#23613;&#31649;&#32479;&#35745;&#26041;&#27861;&#21644;&#31070;&#32463;&#32593;&#32476;&#29256;&#26412;&#20855;&#26377;&#30456;&#21516;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#20294;&#30001;&#20110;&#20248;&#21270;&#26041;&#27861;&#19981;&#21516;&#32780;&#23384;&#22312;&#24046;&#24322;&#12290;&#29305;&#21035;&#26159;&#65292;&#31070;&#32463;&#32593;&#32476;&#29256;&#26412;&#36890;&#24120;&#20351;&#29992;&#21333;&#20010;&#39564;&#35777;&#38598;&#36827;&#34892;&#19968;&#27493;&#20248;&#21270;&#65292;&#32780;&#32479;&#35745;&#23545;&#24212;&#26041;&#27861;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#36827;&#34892;&#20004;&#27493;&#20248;&#21270;&#12290;&#32479;&#35745;&#26041;&#27861;&#26356;&#20026;&#31934;&#32454;&#30340;&#20248;&#21270;&#23548;&#33268;&#26356;&#20934;&#30830;&#30340;&#21442;&#25968;&#20272;&#35745;&#65292;&#23588;&#20854;&#26159;&#22312;&#35757;&#32451;&#38598;&#36739;&#23567;&#30340;&#24773;&#20917;&#19979;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#26631;&#20934;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#26041;&#27861;&#30340;&#26041;&#27861;&#65292;&#27169;&#20223;&#32479;&#35745;&#26694;&#26550;&#12290;&#22312;&#24320;&#21457;&#19978;&#36848;&#20462;&#25913;&#30340;&#36807;&#31243;&#20013;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20248;&#21270;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, there is a growing interest in combining techniques attributed to the areas of Statistics and Machine Learning in order to obtain the benefits of both approaches. In this article, the statistical technique lasso for variable selection is represented through a neural network. It is observed that, although both the statistical approach and its neural version have the same objective function, they differ due to their optimization. In particular, the neural version is usually optimized in one-step using a single validation set, while the statistical counterpart uses a two-step optimization based on cross-validation. The more elaborated optimization of the statistical method results in more accurate parameter estimation, especially when the training set is small. For this reason, a modification of the standard approach for training neural networks, that mimics the statistical framework, is proposed. During the development of the above modification, a new optimization algori
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20855;&#26377;&#33258;&#21160;&#32858;&#31867;&#25968;&#37327;&#36873;&#25321;&#30340;&#20013;&#24515;&#36718;&#24275;&#32858;&#31867;&#31639;&#27861;&#65292;&#20854;&#20013;&#32467;&#21512;&#20102;&#21407;&#22987;&#36718;&#24275;&#31995;&#25968;&#21644;PAM&#31639;&#27861;&#30340;&#24605;&#24819;&#65292;&#24182;&#36890;&#36807;&#20004;&#31181;&#24555;&#36895;&#29256;&#26412;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#39564;&#39564;&#35777;&#65292;&#22312;&#23454;&#39564;&#20013;&#33719;&#24471;&#20102;&#26174;&#33879;&#30340;&#21152;&#36895;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.03751</link><description>&lt;p&gt;
&#20855;&#26377;&#33258;&#21160;&#32858;&#31867;&#25968;&#37327;&#36873;&#25321;&#30340;&#20013;&#24515;&#36718;&#24275;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Medoid Silhouette clustering with automatic cluster number selection. (arXiv:2309.03751v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03751
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20855;&#26377;&#33258;&#21160;&#32858;&#31867;&#25968;&#37327;&#36873;&#25321;&#30340;&#20013;&#24515;&#36718;&#24275;&#32858;&#31867;&#31639;&#27861;&#65292;&#20854;&#20013;&#32467;&#21512;&#20102;&#21407;&#22987;&#36718;&#24275;&#31995;&#25968;&#21644;PAM&#31639;&#27861;&#30340;&#24605;&#24819;&#65292;&#24182;&#36890;&#36807;&#20004;&#31181;&#24555;&#36895;&#29256;&#26412;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#39564;&#39564;&#35777;&#65292;&#22312;&#23454;&#39564;&#20013;&#33719;&#24471;&#20102;&#26174;&#33879;&#30340;&#21152;&#36895;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32858;&#31867;&#32467;&#26524;&#30340;&#35780;&#20272;&#26159;&#22256;&#38590;&#30340;&#65292;&#39640;&#24230;&#20381;&#36182;&#20110;&#35780;&#20272;&#30340;&#25968;&#25454;&#38598;&#21644;&#35266;&#23519;&#32773;&#30340;&#35266;&#28857;&#12290;&#26377;&#35768;&#22810;&#19981;&#21516;&#30340;&#32858;&#31867;&#36136;&#37327;&#24230;&#37327;&#65292;&#35797;&#22270;&#25552;&#20379;&#19968;&#20010;&#36890;&#29992;&#30340;&#24230;&#37327;&#26469;&#39564;&#35777;&#32858;&#31867;&#32467;&#26524;&#12290;&#19968;&#20010;&#38750;&#24120;&#27969;&#34892;&#30340;&#24230;&#37327;&#26159;&#36718;&#24275;&#31995;&#25968;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#39640;&#25928;&#30340;&#22522;&#20110;&#20013;&#24515;&#28857;&#30340;&#36718;&#24275;&#31995;&#25968;&#65292;&#23545;&#20854;&#23646;&#24615;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#25552;&#20379;&#20102;&#20004;&#20010;&#30452;&#25509;&#20248;&#21270;&#30340;&#24555;&#36895;&#29256;&#26412;&#65292;&#24182;&#35752;&#35770;&#20102;&#36873;&#25321;&#26368;&#20339;&#32858;&#31867;&#25968;&#37327;&#30340;&#20351;&#29992;&#12290;&#25105;&#20204;&#23558;&#21407;&#22987;&#36718;&#24275;&#31995;&#25968;&#21644;&#33879;&#21517;&#30340;PAM&#31639;&#27861;&#20197;&#21450;&#20854;&#26368;&#26032;&#25913;&#36827;FasterPAM&#30340;&#24605;&#24819;&#30456;&#32467;&#21512;&#12290;&#20854;&#20013;&#19968;&#20010;&#29256;&#26412;&#20445;&#35777;&#19982;&#21407;&#22987;&#29256;&#26412;&#30456;&#31561;&#30340;&#32467;&#26524;&#65292;&#24182;&#25552;&#20379;&#20102;$O(k^2)$&#30340;&#36816;&#34892;&#21152;&#36895;&#12290;&#22312;&#20855;&#26377;30000&#20010;&#26679;&#26412;&#21644;$k$=100&#30340;&#23454;&#38469;&#25968;&#25454;&#19978;&#65292;&#19982;&#21407;&#22987;&#30340;PAMMEDSIL&#31639;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#20102;10464&#20493;&#30340;&#21152;&#36895;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#30452;&#25509;&#36873;&#25321;&#26368;&#20339;&#32858;&#31867;&#25968;&#37327;&#30340;&#21464;&#31181;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The evaluation of clustering results is difficult, highly dependent on the evaluated data set and the perspective of the beholder. There are many different clustering quality measures, which try to provide a general measure to validate clustering results. A very popular measure is the Silhouette. We discuss the efficient medoid-based variant of the Silhouette, perform a theoretical analysis of its properties, provide two fast versions for the direct optimization, and discuss the use to choose the optimal number of clusters. We combine ideas from the original Silhouette with the well-known PAM algorithm and its latest improvements FasterPAM. One of the versions guarantees equal results to the original variant and provides a run speedup of $O(k^2)$. In experiments on real data with 30000 samples and $k$=100, we observed a 10464$\times$ speedup compared to the original PAMMEDSIL algorithm. Additionally, we provide a variant to choose the optimal number of clusters directly.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#26469;&#22686;&#24378;&#22522;&#20110;&#27969;&#27700;&#32447;&#30340;&#23545;&#35805;&#31995;&#32479;&#12290;&#22312;&#35774;&#35745;&#21644;&#24320;&#21457;&#38454;&#27573;&#65292;LLM&#21487;&#20197;&#24110;&#21161;&#29983;&#25104;&#35757;&#32451;&#25968;&#25454;&#12289;&#25552;&#21462;&#23454;&#20307;&#21644;&#21516;&#20041;&#35789;&#12289;&#26412;&#22320;&#21270;&#21644;&#35282;&#33394;&#35774;&#35745;&#12290;&#22312;&#36816;&#33829;&#38454;&#27573;&#65292;LLM&#21487;&#20197;&#36741;&#21161;&#19978;&#19979;&#25991;&#21270;&#12289;&#24847;&#22270;&#20998;&#31867;&#12289;&#33258;&#21160;&#32416;&#27491;&#35805;&#35821;&#12289;&#25913;&#20889;&#22238;&#22797;&#12289;&#25688;&#35201;&#21644;&#20351;&#38381;&#21512;&#38382;&#39064;&#22238;&#31572;&#33021;&#21147;&#12290;&#36890;&#36807;&#22312;&#31169;&#20154;&#38134;&#34892;&#39046;&#22495;&#30340;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#36825;&#20123;&#33021;&#21147;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.03748</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22686;&#24378;&#22522;&#20110;&#27969;&#27700;&#32447;&#30340;&#23545;&#35805;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Enhancing Pipeline-Based Conversational Agents with Large Language Models. (arXiv:2309.03748v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03748
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#26469;&#22686;&#24378;&#22522;&#20110;&#27969;&#27700;&#32447;&#30340;&#23545;&#35805;&#31995;&#32479;&#12290;&#22312;&#35774;&#35745;&#21644;&#24320;&#21457;&#38454;&#27573;&#65292;LLM&#21487;&#20197;&#24110;&#21161;&#29983;&#25104;&#35757;&#32451;&#25968;&#25454;&#12289;&#25552;&#21462;&#23454;&#20307;&#21644;&#21516;&#20041;&#35789;&#12289;&#26412;&#22320;&#21270;&#21644;&#35282;&#33394;&#35774;&#35745;&#12290;&#22312;&#36816;&#33829;&#38454;&#27573;&#65292;LLM&#21487;&#20197;&#36741;&#21161;&#19978;&#19979;&#25991;&#21270;&#12289;&#24847;&#22270;&#20998;&#31867;&#12289;&#33258;&#21160;&#32416;&#27491;&#35805;&#35821;&#12289;&#25913;&#20889;&#22238;&#22797;&#12289;&#25688;&#35201;&#21644;&#20351;&#38381;&#21512;&#38382;&#39064;&#22238;&#31572;&#33021;&#21147;&#12290;&#36890;&#36807;&#22312;&#31169;&#20154;&#38134;&#34892;&#39046;&#22495;&#30340;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#36825;&#20123;&#33021;&#21147;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
AI&#21644;&#28145;&#24230;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#20351;&#24471;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#20195;&#29702;&#22120;&#65288;&#22914;GPT-4&#65289;&#21462;&#24471;&#20102;&#31361;&#30772;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#21830;&#19994;&#21270;&#23545;&#35805;&#31995;&#32479;&#24320;&#21457;&#24037;&#20855;&#26159;&#22522;&#20110;&#27969;&#27700;&#32447;&#30340;&#65292;&#24182;&#19988;&#22312;&#36827;&#34892;&#20154;&#31867;&#23545;&#35805;&#26102;&#23384;&#22312;&#38480;&#21046;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;LLM&#22312;&#20197;&#19979;&#20004;&#20010;&#38454;&#27573;&#20013;&#22686;&#24378;&#22522;&#20110;&#27969;&#27700;&#32447;&#30340;&#23545;&#35805;&#31995;&#32479;&#30340;&#33021;&#21147;&#65306;1&#65289;&#35774;&#35745;&#21644;&#24320;&#21457;&#38454;&#27573;&#65307;2&#65289;&#36816;&#33829;&#38454;&#27573;&#12290;&#22312;1&#65289;&#20013;&#65292;LLM&#21487;&#20197;&#22312;&#29983;&#25104;&#35757;&#32451;&#25968;&#25454;&#12289;&#25552;&#21462;&#23454;&#20307;&#21644;&#21516;&#20041;&#35789;&#12289;&#26412;&#22320;&#21270;&#21644;&#35282;&#33394;&#35774;&#35745;&#26041;&#38754;&#25552;&#20379;&#24110;&#21161;&#12290;&#22312;2&#65289;&#20013;&#65292;LLM&#21487;&#20197;&#36741;&#21161;&#19978;&#19979;&#25991;&#21270;&#12289;&#24847;&#22270;&#20998;&#31867;&#20197;&#38450;&#27490;&#23545;&#35805;&#20013;&#26029;&#21644;&#22788;&#29702;&#36229;&#20986;&#33539;&#22260;&#30340;&#38382;&#39064;&#12289;&#33258;&#21160;&#32416;&#27491;&#35805;&#35821;&#12289;&#25913;&#20889;&#22238;&#22797;&#12289;&#21046;&#23450;&#28040;&#27495;&#38382;&#21477;&#12289;&#25688;&#35201;&#21644;&#20351;&#38381;&#21512;&#38382;&#39064;&#22238;&#31572;&#33021;&#21147;&#12290;&#25105;&#20204;&#22312;&#31169;&#20154;&#38134;&#34892;&#39046;&#22495;&#36827;&#34892;&#20102;&#20351;&#29992;GPT-4&#30340;&#38750;&#27491;&#24335;&#23454;&#39564;&#65292;&#20197;&#23454;&#38469;&#31034;&#20363;&#35777;&#26126;&#19978;&#36848;&#24773;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
The latest advancements in AI and deep learning have led to a breakthrough in large language model (LLM)-based agents such as GPT-4. However, many commercial conversational agent development tools are pipeline-based and have limitations in holding a human-like conversation. This paper investigates the capabilities of LLMs to enhance pipeline-based conversational agents during two phases: 1) in the design and development phase and 2) during operations. In 1) LLMs can aid in generating training data, extracting entities and synonyms, localization, and persona design. In 2) LLMs can assist in contextualization, intent classification to prevent conversational breakdown and handle out-of-scope questions, auto-correcting utterances, rephrasing responses, formulating disambiguation questions, summarization, and enabling closed question-answering capabilities. We conducted informal experiments with GPT-4 in the private banking domain to demonstrate the scenarios above with a practical example.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21464;&#20998;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#21322;&#30417;&#30563;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#21442;&#25968;&#21270;&#30340;&#19977;&#20803;&#39532;&#23572;&#31185;&#22827;&#38142;&#27169;&#22411;&#65292;&#24182;&#19988;&#33021;&#22815;&#38024;&#23545;&#21508;&#31181;&#29983;&#25104;&#27169;&#22411;&#25512;&#23548;&#20986;&#21322;&#30417;&#30563;&#31639;&#27861;&#65292;&#29992;&#20110;&#39034;&#24207;&#36125;&#21494;&#26031;&#20998;&#31867;&#12290;</title><link>http://arxiv.org/abs/2309.03707</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#19977;&#20803;&#39532;&#23572;&#31185;&#22827;&#38142;&#30340;&#27010;&#29575;&#21322;&#30417;&#30563;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Probabilistic Semi-Supervised Approach with Triplet Markov Chains. (arXiv:2309.03707v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03707
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21464;&#20998;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#21322;&#30417;&#30563;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#21442;&#25968;&#21270;&#30340;&#19977;&#20803;&#39532;&#23572;&#31185;&#22827;&#38142;&#27169;&#22411;&#65292;&#24182;&#19988;&#33021;&#22815;&#38024;&#23545;&#21508;&#31181;&#29983;&#25104;&#27169;&#22411;&#25512;&#23548;&#20986;&#21322;&#30417;&#30563;&#31639;&#27861;&#65292;&#29992;&#20110;&#39034;&#24207;&#36125;&#21494;&#26031;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19977;&#20803;&#39532;&#23572;&#31185;&#22827;&#38142;&#26159;&#29992;&#20110;&#39034;&#24207;&#25968;&#25454;&#30340;&#19968;&#31181;&#36890;&#29992;&#29983;&#25104;&#27169;&#22411;&#65292;&#32771;&#34385;&#20102;&#19977;&#31181;&#38543;&#26426;&#21464;&#37327;&#65306;&#65288;&#24102;&#22122;&#65289;&#35266;&#27979;&#20540;&#12289;&#23427;&#20204;&#30456;&#20851;&#30340;&#31163;&#25955;&#26631;&#31614;&#21644;&#26088;&#22312;&#22686;&#24378;&#35266;&#27979;&#20540;&#21450;&#20854;&#30456;&#20851;&#26631;&#31614;&#20998;&#24067;&#30340;&#28508;&#22312;&#21464;&#37327;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#27809;&#26377;&#25152;&#26377;&#19982;&#35266;&#27979;&#20540;&#30456;&#20851;&#30340;&#26631;&#31614;&#26469;&#20272;&#35745;&#36825;&#31181;&#27169;&#22411;&#30340;&#21442;&#25968;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21464;&#20998;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#21322;&#30417;&#30563;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#21442;&#25968;&#21270;&#30340;&#19977;&#20803;&#39532;&#23572;&#31185;&#22827;&#38142;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26222;&#36866;&#24615;&#20351;&#25105;&#20204;&#33021;&#22815;&#38024;&#23545;&#21508;&#31181;&#29983;&#25104;&#27169;&#22411;&#25512;&#23548;&#20986;&#21322;&#30417;&#30563;&#31639;&#27861;&#65292;&#29992;&#20110;&#39034;&#24207;&#36125;&#21494;&#26031;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
Triplet Markov chains are general generative models for sequential data which take into account three kinds of random variables: (noisy) observations, their associated discrete labels and latent variables which aim at strengthening the distribution of the observations and their associated labels. However, in practice, we do not have at our disposal all the labels associated to the observations to estimate the parameters of such models. In this paper, we propose a general framework based on a variational Bayesian inference to train parameterized triplet Markov chain models in a semi-supervised context. The generality of our approach enables us to derive semi-supervised algorithms for a variety of generative models for sequential Bayesian classification.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#19977;&#20540;&#20915;&#31574;&#26641;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#25913;&#21892;&#20915;&#31574;&#26641;&#22312;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#26102;&#30340;&#34920;&#29616;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#19981;&#21516;&#65292;&#35813;&#31639;&#27861;&#19981;&#20551;&#35774;&#32570;&#22833;&#20540;&#21253;&#21547;&#20219;&#20309;&#20851;&#20110;&#21709;&#24212;&#30340;&#20449;&#24687;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#29305;&#23450;&#32570;&#22833;&#25968;&#25454;&#22330;&#26223;&#19979;&#65292;&#19977;&#20540;&#20915;&#31574;&#26641;&#22312;MCAR&#35774;&#32622;&#20013;&#34920;&#29616;&#20248;&#24322;&#65292;&#22312;IM&#35774;&#32622;&#20013;&#30053;&#36874;&#19968;&#31609;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#23558;&#19977;&#20540;&#20915;&#31574;&#26641;&#19982;&#32570;&#22833;&#22312;&#23646;&#24615;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#33719;&#24471;&#26356;&#31283;&#20581;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;&#35757;&#32451;&#36895;&#24230;&#36739;&#24930;&#65292;&#20294;&#19977;&#20540;&#20915;&#31574;&#26641;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#21069;&#36884;&#19988;&#26356;&#20934;&#30830;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.03561</link><description>&lt;p&gt;
&#32570;&#22833;&#20540;&#22788;&#29702;&#30340;&#19977;&#20540;&#20915;&#31574;&#26641;
&lt;/p&gt;
&lt;p&gt;
Trinary Decision Trees for missing value handling. (arXiv:2309.03561v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03561
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#19977;&#20540;&#20915;&#31574;&#26641;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#25913;&#21892;&#20915;&#31574;&#26641;&#22312;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#26102;&#30340;&#34920;&#29616;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#19981;&#21516;&#65292;&#35813;&#31639;&#27861;&#19981;&#20551;&#35774;&#32570;&#22833;&#20540;&#21253;&#21547;&#20219;&#20309;&#20851;&#20110;&#21709;&#24212;&#30340;&#20449;&#24687;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#29305;&#23450;&#32570;&#22833;&#25968;&#25454;&#22330;&#26223;&#19979;&#65292;&#19977;&#20540;&#20915;&#31574;&#26641;&#22312;MCAR&#35774;&#32622;&#20013;&#34920;&#29616;&#20248;&#24322;&#65292;&#22312;IM&#35774;&#32622;&#20013;&#30053;&#36874;&#19968;&#31609;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#23558;&#19977;&#20540;&#20915;&#31574;&#26641;&#19982;&#32570;&#22833;&#22312;&#23646;&#24615;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#33719;&#24471;&#26356;&#31283;&#20581;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;&#35757;&#32451;&#36895;&#24230;&#36739;&#24930;&#65292;&#20294;&#19977;&#20540;&#20915;&#31574;&#26641;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#21069;&#36884;&#19988;&#26356;&#20934;&#30830;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19977;&#20540;&#20915;&#31574;&#26641;&#65292;&#36825;&#26159;&#19968;&#31181;&#26088;&#22312;&#25913;&#21892;&#20915;&#31574;&#26641;&#22238;&#24402;&#22120;&#21644;&#20998;&#31867;&#22120;&#20013;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#30340;&#31639;&#27861;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#19981;&#21516;&#65292;&#19977;&#20540;&#20915;&#31574;&#26641;&#19981;&#20551;&#35774;&#32570;&#22833;&#20540;&#21253;&#21547;&#26377;&#20851;&#21709;&#24212;&#30340;&#20219;&#20309;&#20449;&#24687;&#12290;&#26412;&#25991;&#36890;&#36807;&#29702;&#35770;&#35745;&#31639;&#21644;&#20351;&#29992;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#25968;&#20540;&#31034;&#20363;&#65292;&#27604;&#36739;&#20102;&#20854;&#22312;&#19981;&#21516;&#32570;&#22833;&#25968;&#25454;&#22330;&#26223;&#65288;&#23436;&#20840;&#38543;&#26426;&#32570;&#22833;&#65288;MCAR&#65289;&#21644;&#20449;&#24687;&#24615;&#32570;&#22833;&#65288;IM&#65289;&#65289;&#20013;&#19982;&#24050;&#24314;&#31435;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#22312;MCAR&#35774;&#32622;&#20013;&#65292;&#19977;&#20540;&#26641;&#22312;&#21482;&#26377;&#26679;&#26412;&#22806;&#32570;&#22833;&#25968;&#25454;&#26102;&#34920;&#29616;&#20248;&#20110;&#20854;&#21516;&#34892;&#65292;&#32780;&#22312;IM&#35774;&#32622;&#20013;&#33853;&#21518;&#12290;&#19968;&#20010;&#28151;&#21512;&#27169;&#22411;&#65292;&#21363;&#19977;&#20540;&#32570;&#22833;&#22312;&#23646;&#24615;&#65288;MIA&#65289;&#26041;&#27861;&#21644;&#19977;&#20540;&#26641;&#30456;&#32467;&#21512;&#30340;TrinaryMIA&#26641;&#65292;&#22312;&#25152;&#26377;&#32570;&#22833;&#31867;&#22411;&#20013;&#34920;&#29616;&#20986;&#24378;&#22823;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;&#35757;&#32451;&#36895;&#24230;&#36739;&#24930;&#21487;&#33021;&#26159;&#19968;&#20010;&#28508;&#22312;&#30340;&#32570;&#28857;&#65292;&#20294;&#19977;&#20540;&#20915;&#31574;&#26641;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#21069;&#36884;&#19988;&#26356;&#20934;&#30830;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces the Trinary decision tree, an algorithm designed to improve the handling of missing data in decision tree regressors and classifiers. Unlike other approaches, the Trinary decision tree does not assume that missing values contain any information about the response. Both theoretical calculations on estimator bias and numerical illustrations using real data sets are presented to compare its performance with established algorithms in different missing data scenarios (Missing Completely at Random (MCAR), and Informative Missingness (IM)). Notably, the Trinary tree outperforms its peers in MCAR settings, especially when data is only missing out-of-sample, while lacking behind in IM settings. A hybrid model, the TrinaryMIA tree, which combines the Trinary tree and the Missing In Attributes (MIA) approach, shows robust performance in all types of missingness. Despite the potential drawback of slower training speed, the Trinary tree offers a promising and more accurate met
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#38750;&#32447;&#24615;&#28388;&#27874;/&#23398;&#20064;&#21160;&#21147;&#23398;&#30340;&#22810;&#26234;&#33021;&#20307;&#32593;&#32476;&#31995;&#32479;&#30340;&#34892;&#20026;&#65292;&#24182;&#20171;&#32461;&#20102;&#22312;&#20998;&#24067;&#24335;&#21644;&#32852;&#37030;&#23398;&#20064;&#22330;&#26223;&#20013;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2309.03557</link><description>&lt;p&gt;
&#35770;&#22810;&#26234;&#33021;&#20307;&#38750;&#32447;&#24615;&#28388;&#27874;&#21644;&#23398;&#20064;&#30340;&#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
On the dynamics of multi agent nonlinear filtering and learning. (arXiv:2309.03557v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03557
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#38750;&#32447;&#24615;&#28388;&#27874;/&#23398;&#20064;&#21160;&#21147;&#23398;&#30340;&#22810;&#26234;&#33021;&#20307;&#32593;&#32476;&#31995;&#32479;&#30340;&#34892;&#20026;&#65292;&#24182;&#20171;&#32461;&#20102;&#22312;&#20998;&#24067;&#24335;&#21644;&#32852;&#37030;&#23398;&#20064;&#22330;&#26223;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#36890;&#36807;&#20998;&#25955;&#19968;&#33268;&#24615;&#23547;&#27714;&#21160;&#21147;&#23398;&#26469;&#23436;&#25104;&#39640;&#24230;&#22797;&#26434;&#30340;&#23398;&#20064;&#20219;&#21153;&#65292;&#20854;&#22312;&#20449;&#21495;&#22788;&#29702;&#21644;&#35745;&#31639;&#26234;&#33021;&#31038;&#21306;&#24341;&#36215;&#20102;&#26497;&#22823;&#20851;&#27880;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#38750;&#32447;&#24615;&#28388;&#27874;/&#23398;&#20064;&#21160;&#21147;&#23398;&#30340;&#22810;&#26234;&#33021;&#20307;&#32593;&#32476;&#31995;&#32479;&#30340;&#34892;&#20026;&#12290;&#20026;&#27492;&#65292;&#25552;&#20986;&#20102;&#22810;&#26234;&#33021;&#20307;&#32593;&#32476;&#31995;&#32479;&#20013;&#19968;&#20010;&#26234;&#33021;&#20307;&#30340;&#34892;&#21160;&#30340;&#19968;&#33324;&#34920;&#36848;&#65292;&#24182;&#32473;&#20986;&#20102;&#23454;&#29616;&#21327;&#21516;&#23398;&#20064;&#34892;&#20026;&#30340;&#26465;&#20214;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#36824;&#20171;&#32461;&#20102;&#35813;&#25512;&#23548;&#26694;&#26550;&#22312;&#20998;&#24067;&#24335;&#21644;&#32852;&#37030;&#23398;&#20064;&#22330;&#26223;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multiagent systems aim to accomplish highly complex learning tasks through decentralised consensus seeking dynamics and their use has garnered a great deal of attention in the signal processing and computational intelligence societies. This article examines the behaviour of multiagent networked systems with nonlinear filtering/learning dynamics. To this end, a general formulation for the actions of an agent in multiagent networked systems is presented and conditions for achieving a cohesive learning behaviour is given. Importantly, application of the so derived framework in distributed and federated learning scenarios are presented.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38598;&#25104;&#32447;&#24615;&#25554;&#20540;&#22120;&#22914;&#20309;&#31283;&#23450;&#21644;&#25552;&#21319;&#20010;&#20307;&#25554;&#20540;&#22120;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#24182;&#24341;&#20837;&#20102;&#22522;&#20110;&#20056;&#25968;&#33258;&#21161;&#27861;&#30340;&#34955;&#35013;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#12290;&#22312;&#27604;&#20363;&#21306;&#22495;&#20869;&#65292;&#30740;&#31350;&#20102;&#31616;&#21270;&#21644;&#34955;&#35013;&#30340;&#22806;&#26679;&#26412;&#39044;&#27979;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2309.03354</link><description>&lt;p&gt;
&#38598;&#25104;&#32447;&#24615;&#25554;&#20540;&#22120;: &#38598;&#25104;&#30340;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Ensemble linear interpolators: The role of ensembling. (arXiv:2309.03354v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03354
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38598;&#25104;&#32447;&#24615;&#25554;&#20540;&#22120;&#22914;&#20309;&#31283;&#23450;&#21644;&#25552;&#21319;&#20010;&#20307;&#25554;&#20540;&#22120;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#24182;&#24341;&#20837;&#20102;&#22522;&#20110;&#20056;&#25968;&#33258;&#21161;&#27861;&#30340;&#34955;&#35013;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#12290;&#22312;&#27604;&#20363;&#21306;&#22495;&#20869;&#65292;&#30740;&#31350;&#20102;&#31616;&#21270;&#21644;&#34955;&#35013;&#30340;&#22806;&#26679;&#26412;&#39044;&#27979;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25554;&#20540;&#22120;&#26159;&#19981;&#31283;&#23450;&#30340;&#12290;&#20363;&#22914;&#65292;&#24403;&#22788;&#29702;&#22122;&#22768;&#25968;&#25454;&#26102;&#65292;&#26368;&#23567;l2&#33539;&#25968;&#26368;&#23567;&#20108;&#20056;&#25554;&#20540;&#22120;&#30340;&#27979;&#35797;&#35823;&#24046;&#20250;&#26080;&#30028;&#22686;&#38271;&#12290;&#26412;&#25991;&#30740;&#31350;&#38598;&#25104;&#22914;&#20309;&#31283;&#23450;&#21644;&#25552;&#21319;&#20010;&#20307;&#25554;&#20540;&#22120;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#36890;&#36807;&#23545;&#22806;&#26679;&#26412;&#39044;&#27979;&#39118;&#38505;&#36827;&#34892;&#34913;&#37327;&#12290;&#25105;&#20204;&#20197;&#34955;&#35013;&#32447;&#24615;&#25554;&#20540;&#22120;&#20026;&#37325;&#28857;&#65292;&#22240;&#20026;&#34955;&#35013;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#22522;&#20110;&#38543;&#26426;&#21270;&#30340;&#38598;&#25104;&#26041;&#27861;&#65292;&#21487;&#20197;&#24182;&#34892;&#23454;&#29616;&#12290;&#25105;&#20204;&#24341;&#20837;&#22522;&#20110;&#20056;&#25968;&#33258;&#21161;&#27861;&#30340;&#34955;&#35013;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#65292;&#21487;&#20197;&#23558;&#20854;&#34920;&#36798;&#20026;&#31616;&#21270;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#30340;&#24179;&#22343;&#20540;&#12290;&#25152;&#25552;&#20986;&#30340;&#20056;&#25968;&#33258;&#21161;&#27861;&#21253;&#21547;&#20102;&#32463;&#20856;&#30340;&#26377;&#25918;&#22238;&#33258;&#21161;&#27861;&#20316;&#20026;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#65292;&#20197;&#21450;&#26356;&#26377;&#36259;&#30340;&#21464;&#20307;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#20271;&#21162;&#21033;&#33258;&#21161;&#27861;&#12290;&#22312;&#26679;&#26412;&#22823;&#23567;&#19982;&#29305;&#24449;&#32500;&#24230;&#25104;&#27491;&#27604;&#30340;&#27604;&#20363;&#21306;&#22495;&#20869;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#31616;&#21270;&#21644;&#34955;&#35013;&#30340;&#22806;&#26679;&#26412;&#39044;&#27979;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;
Interpolators are unstable. For example, the mininum $\ell_2$ norm least square interpolator exhibits unbounded test errors when dealing with noisy data. In this paper, we study how ensemble stabilizes and thus improves the generalization performance, measured by the out-of-sample prediction risk, of an individual interpolator. We focus on bagged linear interpolators, as bagging is a popular randomization-based ensemble method that can be implemented in parallel. We introduce the multiplier-bootstrap-based bagged least square estimator, which can then be formulated as an average of the sketched least square estimators. The proposed multiplier bootstrap encompasses the classical bootstrap with replacement as a special case, along with a more intriguing variant which we call the Bernoulli bootstrap.  Focusing on the proportional regime where the sample size scales proportionally with the feature dimensionality, we investigate the out-of-sample prediction risks of the sketched and bagged 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#23398;&#20064;&#30340;&#30693;&#35782;&#33976;&#39311;&#23618;&#65292;&#33021;&#22815;&#26126;&#30830;&#22320;&#23884;&#20837;&#25945;&#24072;&#30340;&#30693;&#35782;&#21040;&#23398;&#29983;&#30340;&#29305;&#24449;&#21464;&#25442;&#20013;&#65292;&#20174;&#32780;&#25913;&#36827;&#20102;&#30693;&#35782;&#33976;&#39311;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2309.02843</link><description>&lt;p&gt;
&#35753;&#23398;&#29983;&#20915;&#31574;&#30340;&#30693;&#35782;&#33976;&#39311;&#23618;
&lt;/p&gt;
&lt;p&gt;
Knowledge Distillation Layer that Lets the Student Decide. (arXiv:2309.02843v1 [cs.CV] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02843
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#23398;&#20064;&#30340;&#30693;&#35782;&#33976;&#39311;&#23618;&#65292;&#33021;&#22815;&#26126;&#30830;&#22320;&#23884;&#20837;&#25945;&#24072;&#30340;&#30693;&#35782;&#21040;&#23398;&#29983;&#30340;&#29305;&#24449;&#21464;&#25442;&#20013;&#65292;&#20174;&#32780;&#25913;&#36827;&#20102;&#30693;&#35782;&#33976;&#39311;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#33976;&#39311;&#65288;KD&#65289;&#20013;&#30340;&#20856;&#22411;&#25216;&#26415;&#26159;&#36890;&#36807;&#23558;&#23398;&#29983;&#30340;&#21709;&#24212;&#19982;&#24378;&#22823;&#27169;&#22411;&#65288;&#25945;&#24072;&#65289;&#30340;&#21709;&#24212;&#21305;&#37197;&#26469;&#35268;&#33539;&#23398;&#29983;&#30340;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#23427;&#23545;&#23398;&#29983;&#30340;&#29305;&#24449;&#21464;&#25442;&#30340;&#20316;&#29992;&#30456;&#23545;&#38544;&#21547;&#65292;&#38480;&#21046;&#20102;&#20854;&#22312;&#20013;&#38388;&#23618;&#30340;&#23454;&#36341;&#12290;&#20026;&#20102;&#26126;&#30830;&#22320;&#23884;&#20837;&#25945;&#24072;&#30340;&#30693;&#35782;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#23398;&#20064;&#30340;KD&#23618;&#65292;&#23427;&#36890;&#36807;&#20004;&#20010;&#19981;&#21516;&#30340;&#33021;&#21147;&#25913;&#36827;&#20102;KD&#65306;i&#65289;&#23398;&#20064;&#22914;&#20309;&#21033;&#29992;&#25945;&#24072;&#30340;&#30693;&#35782;&#65292;&#33021;&#22815;&#20002;&#24323;&#26080;&#20851;&#30340;&#20449;&#24687;&#65307;ii&#65289;&#23558;&#36716;&#31227;&#30340;&#30693;&#35782;&#21521;&#21069;&#20256;&#36882;&#24471;&#26356;&#28145;&#20837;&#12290;&#22240;&#27492;&#65292;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#65292;&#23398;&#29983;&#21487;&#20197;&#20139;&#21463;&#21040;&#25945;&#24072;&#30340;&#30693;&#35782;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#22312;&#35757;&#32451;&#20013;&#12290;&#27491;&#24335;&#22320;&#35828;&#65292;&#25105;&#20204;&#37325;&#26032;&#20998;&#37197;1x1-BN-ReLU-1x1&#21367;&#31215;&#22359;&#65292;&#26681;&#25454;&#23398;&#29983;&#23545;&#24212;&#21306;&#22495;&#19982;&#27169;&#26495;&#65288;&#30001;&#25945;&#24072;&#30417;&#30563;&#65289;&#30340;&#21305;&#37197;&#24773;&#20917;&#65292;&#20026;&#27599;&#20010;&#23616;&#37096;&#21306;&#22495;&#20998;&#37197;&#19968;&#20010;&#35821;&#20041;&#21521;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Typical technique in knowledge distillation (KD) is regularizing the learning of a limited capacity model (student) by pushing its responses to match a powerful model's (teacher). Albeit useful especially in the penultimate layer and beyond, its action on student's feature transform is rather implicit, limiting its practice in the intermediate layers. To explicitly embed the teacher's knowledge in feature transform, we propose a learnable KD layer for the student which improves KD with two distinct abilities: i) learning how to leverage the teacher's knowledge, enabling to discard nuisance information, and ii) feeding forward the transferred knowledge deeper. Thus, the student enjoys the teacher's knowledge during the inference besides training. Formally, we repurpose 1x1-BN-ReLU-1x1 convolution block to assign a semantic vector to each local region according to the template (supervised by the teacher) that the corresponding region of the student matches. To facilitate template learnin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22312;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#20013;&#20351;&#29992;&#22240;&#26524;&#24605;&#32500;&#36827;&#34892;&#20915;&#31574;&#30340;&#24517;&#35201;&#24615;&#21644;&#26041;&#27861;&#12290;&#36890;&#36807;&#27169;&#25311;&#38543;&#26426;&#35797;&#39564;&#26469;&#20010;&#24615;&#21270;&#20915;&#31574;&#65292;&#20197;&#20943;&#23569;&#25968;&#25454;&#20013;&#30340;&#20559;&#35265;&#12290;&#36825;&#23545;&#20110;&#20998;&#26512;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#25110;&#32034;&#36180;&#25968;&#25454;&#20197;&#24471;&#20986;&#22240;&#26524;&#32467;&#35770;&#30340;&#26368;&#37325;&#35201;&#38519;&#38449;&#21644;&#32771;&#34385;&#22240;&#32032;&#36827;&#34892;&#20102;&#37325;&#28857;&#24378;&#35843;&#12290;</title><link>http://arxiv.org/abs/2308.01605</link><description>&lt;p&gt;
&#29992;&#20110;&#20915;&#31574;&#30340;&#22240;&#26524;&#24605;&#32500;&#22312;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#20013;&#30340;&#24212;&#29992;&#65306;&#20026;&#20160;&#20040;&#20197;&#21450;&#22914;&#20309;
&lt;/p&gt;
&lt;p&gt;
Causal thinking for decision making on Electronic Health Records: why and how. (arXiv:2308.01605v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01605
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22312;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#20013;&#20351;&#29992;&#22240;&#26524;&#24605;&#32500;&#36827;&#34892;&#20915;&#31574;&#30340;&#24517;&#35201;&#24615;&#21644;&#26041;&#27861;&#12290;&#36890;&#36807;&#27169;&#25311;&#38543;&#26426;&#35797;&#39564;&#26469;&#20010;&#24615;&#21270;&#20915;&#31574;&#65292;&#20197;&#20943;&#23569;&#25968;&#25454;&#20013;&#30340;&#20559;&#35265;&#12290;&#36825;&#23545;&#20110;&#20998;&#26512;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#25110;&#32034;&#36180;&#25968;&#25454;&#20197;&#24471;&#20986;&#22240;&#26524;&#32467;&#35770;&#30340;&#26368;&#37325;&#35201;&#38519;&#38449;&#21644;&#32771;&#34385;&#22240;&#32032;&#36827;&#34892;&#20102;&#37325;&#28857;&#24378;&#35843;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20934;&#30830;&#30340;&#39044;&#27979;&#65292;&#22914;&#21516;&#26426;&#22120;&#23398;&#20064;&#19968;&#26679;&#65292;&#21487;&#33021;&#26080;&#27861;&#20026;&#27599;&#20010;&#24739;&#32773;&#25552;&#20379;&#26368;&#20339;&#21307;&#30103;&#20445;&#20581;&#12290;&#30830;&#23454;&#65292;&#39044;&#27979;&#21487;&#33021;&#21463;&#21040;&#25968;&#25454;&#20013;&#30340;&#25463;&#24452;&#65288;&#22914;&#31181;&#26063;&#20559;&#35265;&#65289;&#30340;&#39537;&#21160;&#12290;&#20026;&#25968;&#25454;&#39537;&#21160;&#30340;&#20915;&#31574;&#38656;&#35201;&#22240;&#26524;&#24605;&#32500;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20171;&#32461;&#20851;&#38190;&#35201;&#32032;&#65292;&#37325;&#28857;&#20851;&#27880;&#24120;&#35268;&#25910;&#38598;&#30340;&#25968;&#25454;&#65292;&#21363;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#65288;EHRs&#65289;&#21644;&#32034;&#36180;&#25968;&#25454;&#12290;&#20351;&#29992;&#36825;&#20123;&#25968;&#25454;&#35780;&#20272;&#24178;&#39044;&#30340;&#20215;&#20540;&#38656;&#35201;&#35880;&#24910;&#65306;&#26102;&#38388;&#20381;&#36182;&#24615;&#21644;&#29616;&#26377;&#23454;&#36341;&#24456;&#23481;&#26131;&#28151;&#28102;&#22240;&#26524;&#25928;&#24212;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#36880;&#27493;&#26694;&#26550;&#65292;&#24110;&#21161;&#20174;&#30495;&#23454;&#24739;&#32773;&#35760;&#24405;&#20013;&#26500;&#24314;&#26377;&#25928;&#30340;&#20915;&#31574;&#65292;&#36890;&#36807;&#27169;&#25311;&#38543;&#26426;&#35797;&#39564;&#26469;&#20010;&#24615;&#21270;&#20915;&#31574;&#65292;&#20363;&#22914;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#24378;&#35843;&#20102;&#20998;&#26512;EHRs&#25110;&#32034;&#36180;&#25968;&#25454;&#20197;&#24471;&#20986;&#22240;&#26524;&#32467;&#35770;&#26102;&#26368;&#37325;&#35201;&#30340;&#38519;&#38449;&#21644;&#32771;&#34385;&#22240;&#32032;&#12290;&#25105;&#20204;&#22312;&#29992;&#20110;&#37325;&#30151;&#21307;&#23398;&#20449;&#24687;&#24066;&#22330;&#20013;&#30340;&#32908;&#37200;&#23545;&#36133;&#34880;&#30151;&#27515;&#20129;&#29575;&#30340;&#24433;&#21709;&#30340;&#30740;&#31350;&#20013;&#35828;&#26126;&#20102;&#21508;&#31181;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
Accurate predictions, as with machine learning, may not suffice to provide optimal healthcare for every patient. Indeed, prediction can be driven by shortcuts in the data, such as racial biases. Causal thinking is needed for data-driven decisions. Here, we give an introduction to the key elements, focusing on routinely-collected data, electronic health records (EHRs) and claims data. Using such data to assess the value of an intervention requires care: temporal dependencies and existing practices easily confound the causal effect. We present a step-by-step framework to help build valid decision making from real-life patient records by emulating a randomized trial before individualizing decisions, eg with machine learning. Our framework highlights the most important pitfalls and considerations in analysing EHRs or claims data to draw causal conclusions. We illustrate the various choices in studying the effect of albumin on sepsis mortality in the Medical Information Mart for Intensive C
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#22810;&#31181;&#28608;&#27963;&#20989;&#25968;&#19979;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#35777;&#26126;&#20102;&#21487;&#20197;&#36890;&#36807;&#22312;&#26377;&#30028;&#38598;&#21512;&#19978;&#26500;&#24314;&#19968;&#20010;&#23485;&#24230;&#20026;6N&#12289;&#28145;&#24230;&#20026;2L&#30340;varrho&#28608;&#27963;&#32593;&#32476;&#26469;&#36924;&#36817;&#19968;&#20010;&#23485;&#24230;&#20026;N&#12289;&#28145;&#24230;&#20026;L&#30340;ReLU&#32593;&#32476;&#65292;&#20174;&#32780;&#23558;&#23545;ReLU&#32593;&#32476;&#30340;&#36924;&#36817;&#32467;&#26524;&#25512;&#24191;&#21040;&#20854;&#20182;&#28608;&#27963;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2307.06555</link><description>&lt;p&gt;
&#28145;&#24230;&#32593;&#32476;&#36924;&#36817;&#65306;&#20174;ReLU&#21040;&#22810;&#31181;&#28608;&#27963;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Deep Network Approximation: Beyond ReLU to Diverse Activation Functions. (arXiv:2307.06555v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06555
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#22810;&#31181;&#28608;&#27963;&#20989;&#25968;&#19979;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#35777;&#26126;&#20102;&#21487;&#20197;&#36890;&#36807;&#22312;&#26377;&#30028;&#38598;&#21512;&#19978;&#26500;&#24314;&#19968;&#20010;&#23485;&#24230;&#20026;6N&#12289;&#28145;&#24230;&#20026;2L&#30340;varrho&#28608;&#27963;&#32593;&#32476;&#26469;&#36924;&#36817;&#19968;&#20010;&#23485;&#24230;&#20026;N&#12289;&#28145;&#24230;&#20026;L&#30340;ReLU&#32593;&#32476;&#65292;&#20174;&#32780;&#23558;&#23545;ReLU&#32593;&#32476;&#30340;&#36924;&#36817;&#32467;&#26524;&#25512;&#24191;&#21040;&#20854;&#20182;&#28608;&#27963;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#22810;&#31181;&#28608;&#27963;&#20989;&#25968;&#19979;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;&#23450;&#20041;&#20102;&#19968;&#20010;&#28608;&#27963;&#20989;&#25968;&#38598;&#21512;A&#65292;&#21253;&#25324;&#22823;&#22810;&#25968;&#24120;&#29992;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#22914;ReLU&#12289;LeakyReLU&#12289;ReLU^2&#12289;ELU&#12289;SELU&#12289;Softplus&#12289;GELU&#12289;SiLU&#12289;Swish&#12289;Mish&#12289;Sigmoid&#12289;Tanh&#12289;Arctan&#12289;Softsign&#12289;dSiLU&#21644;SRS&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#20219;&#24847;&#28608;&#27963;&#20989;&#25968;varrho&#8712;A&#65292;&#21487;&#20197;&#36890;&#36807;&#19968;&#20010;&#23485;&#24230;&#20026;6N&#12289;&#28145;&#24230;&#20026;2L&#30340;varrho&#28608;&#27963;&#32593;&#32476;&#22312;&#26377;&#30028;&#38598;&#21512;&#19978;&#20197;&#20219;&#24847;&#31934;&#24230;&#36924;&#36817;&#19968;&#20010;&#23485;&#24230;&#20026;N&#12289;&#28145;&#24230;&#20026;L&#30340;ReLU&#32593;&#32476;&#12290;&#36825;&#19968;&#21457;&#29616;&#20351;&#24471;&#22823;&#37096;&#20998;&#23545;&#20110;ReLU&#32593;&#32476;&#30340;&#36924;&#36817;&#32467;&#26524;&#33021;&#22815;&#25512;&#24191;&#21040;&#20854;&#20182;&#28608;&#27963;&#20989;&#25968;&#65292;&#23613;&#31649;&#38656;&#35201;&#31245;&#22823;&#30340;&#24120;&#25968;&#20195;&#20215;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores the expressive power of deep neural networks for a diverse range of activation functions. An activation function set $\mathscr{A}$ is defined to encompass the majority of commonly used activation functions, such as $\mathtt{ReLU}$, $\mathtt{LeakyReLU}$, $\mathtt{ReLU}^2$, $\mathtt{ELU}$, $\mathtt{SELU}$, $\mathtt{Softplus}$, $\mathtt{GELU}$, $\mathtt{SiLU}$, $\mathtt{Swish}$, $\mathtt{Mish}$, $\mathtt{Sigmoid}$, $\mathtt{Tanh}$, $\mathtt{Arctan}$, $\mathtt{Softsign}$, $\mathtt{dSiLU}$, and $\mathtt{SRS}$. We demonstrate that for any activation function $\varrho\in \mathscr{A}$, a $\mathtt{ReLU}$ network of width $N$ and depth $L$ can be approximated to arbitrary precision by a $\varrho$-activated network of width $6N$ and depth $2L$ on any bounded set. This finding enables the extension of most approximation results achieved with $\mathtt{ReLU}$ networks to a wide variety of other activation functions, at the cost of slightly larger constants.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27169;&#22411;&#35299;&#37322;&#29305;&#24449;&#30340;&#36716;&#31227;&#24615;&#36136;&#26469;&#26816;&#27979;&#20998;&#24067;&#36716;&#31227;&#19979;&#23398;&#20064;&#27169;&#22411;&#30340;&#34892;&#20026;&#26159;&#21542;&#36234;&#30028;&#65292;&#22312;&#27604;&#36739;&#20013;&#21457;&#29616;&#20854;&#27604;&#26368;&#20808;&#36827;&#30340;&#25216;&#26415;&#26356;&#20026;&#20248;&#31168;&#65292;&#25552;&#20379;&#20102;&#31639;&#27861;&#26041;&#27861;&#24182;&#22312;&#23454;&#39564;&#20013;&#24471;&#21040;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2303.08081</link><description>&lt;p&gt;
&#35299;&#37322;&#20301;&#31227;&#65306;&#30740;&#31350;&#27169;&#22411;&#19982;&#36716;&#31227;&#25968;&#25454;&#20998;&#24067;&#30340;&#20132;&#20114;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Explanation Shift: Investigating Interactions between Models and Shifting Data Distributions. (arXiv:2303.08081v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08081
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27169;&#22411;&#35299;&#37322;&#29305;&#24449;&#30340;&#36716;&#31227;&#24615;&#36136;&#26469;&#26816;&#27979;&#20998;&#24067;&#36716;&#31227;&#19979;&#23398;&#20064;&#27169;&#22411;&#30340;&#34892;&#20026;&#26159;&#21542;&#36234;&#30028;&#65292;&#22312;&#27604;&#36739;&#20013;&#21457;&#29616;&#20854;&#27604;&#26368;&#20808;&#36827;&#30340;&#25216;&#26415;&#26356;&#20026;&#20248;&#31168;&#65292;&#25552;&#20379;&#20102;&#31639;&#27861;&#26041;&#27861;&#24182;&#22312;&#23454;&#39564;&#20013;&#24471;&#21040;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#36755;&#20837;&#25968;&#25454;&#20998;&#24067;&#21457;&#29983;&#21464;&#21270;&#26102;&#65292;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#24615;&#33021;&#24448;&#24448;&#20250;&#19979;&#38477;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#26032;&#30340;&#36755;&#20837;&#25968;&#25454;&#24448;&#24448;&#27809;&#26377;&#30446;&#26631;&#26631;&#31614;&#12290;&#22240;&#27492;&#65292;&#26368;&#20808;&#36827;&#30340;&#25216;&#26415;&#27169;&#22411;&#36755;&#20837;&#25968;&#25454;&#20998;&#24067;&#25110;&#27169;&#22411;&#39044;&#27979;&#20998;&#24067;&#65292;&#24182;&#35797;&#22270;&#29702;&#35299;&#23398;&#20064;&#27169;&#22411;&#21644;&#36716;&#31227;&#20998;&#24067;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#27169;&#22411;&#22914;&#20309;&#35299;&#37322;&#29305;&#24449;&#30340;&#36716;&#31227;&#24615;&#36136;&#21463;&#21040;&#20998;&#24067;&#36716;&#31227;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#35299;&#37322;&#20301;&#31227;&#30340;&#24314;&#27169;&#21487;&#20197;&#27604;&#26368;&#20808;&#36827;&#30340;&#25216;&#26415;&#26356;&#22909;&#22320;&#25351;&#31034;&#26816;&#27979;&#36229;&#20986;&#20998;&#24067;&#30340;&#27169;&#22411;&#34892;&#20026;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#20351;&#29992;&#21512;&#25104;&#31034;&#20363;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#19981;&#21516;&#31867;&#22411;&#30340;&#20998;&#24067;&#36716;&#31227;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#31639;&#27861;&#26041;&#27861;&#65292;&#20801;&#35768;&#25105;&#20204;&#26816;&#26597;&#25968;&#25454;&#38598;&#29305;&#24449;&#21644;&#23398;&#20064;&#27169;&#22411;&#20043;&#38388;&#30340;&#20132;&#20114;&#20316;&#29992;&#65292;&#24182;&#23558;&#20854;&#19982;&#26368;&#20808;&#36827;&#25216;&#26415;&#36827;&#34892;&#27604;&#36739;&#12290;&#25105;&#20204;&#22312;&#24320;&#28304;Python&#21253;&#20013;&#21457;&#24067;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#20197;&#21450;&#20351;&#29992;&#30340;&#20195;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
As input data distributions evolve, the predictive performance of machine learning models tends to deteriorate. In practice, new input data tend to come without target labels. Then, state-of-the-art techniques model input data distributions or model prediction distributions and try to understand issues regarding the interactions between learned models and shifting distributions. We suggest a novel approach that models how explanation characteristics shift when affected by distribution shifts. We find that the modeling of explanation shifts can be a better indicator for detecting out-of-distribution model behaviour than state-of-the-art techniques. We analyze different types of distribution shifts using synthetic examples and real-world data sets. We provide an algorithmic method that allows us to inspect the interaction between data set features and learned models and compare them to the state-of-the-art. We release our methods in an open-source Python package, as well as the code used
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23558;&#28145;&#24230;&#24230;&#37327;&#23398;&#20064;&#19982;&#26377;&#38480;&#26426;&#20250;&#32422;&#26463;&#30340;&#21487;&#34892;&#24615;&#38382;&#39064;&#30456;&#20851;&#32852;&#65292;&#35777;&#26126;&#20102;&#22522;&#20110;&#20195;&#29702;&#30340;DML&#30340;&#26368;&#23567;&#21270;&#32773;&#28385;&#36275;&#26426;&#20250;&#32422;&#26463;&#65292;&#24182;&#25552;&#20986;&#22810;&#20010;&#20195;&#29702;&#26377;&#21161;&#20110;&#24615;&#33021;&#25552;&#21319;&#65292;&#36890;&#36807;&#36845;&#20195;&#25237;&#24433;&#35299;&#20915;DML&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2209.09060</link><description>&lt;p&gt;
&#24102;&#26377;&#26426;&#20250;&#32422;&#26463;&#30340;&#28145;&#24230;&#24230;&#37327;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Deep Metric Learning with Chance Constraints. (arXiv:2209.09060v3 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.09060
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#28145;&#24230;&#24230;&#37327;&#23398;&#20064;&#19982;&#26377;&#38480;&#26426;&#20250;&#32422;&#26463;&#30340;&#21487;&#34892;&#24615;&#38382;&#39064;&#30456;&#20851;&#32852;&#65292;&#35777;&#26126;&#20102;&#22522;&#20110;&#20195;&#29702;&#30340;DML&#30340;&#26368;&#23567;&#21270;&#32773;&#28385;&#36275;&#26426;&#20250;&#32422;&#26463;&#65292;&#24182;&#25552;&#20986;&#22810;&#20010;&#20195;&#29702;&#26377;&#21161;&#20110;&#24615;&#33021;&#25552;&#21319;&#65292;&#36890;&#36807;&#36845;&#20195;&#25237;&#24433;&#35299;&#20915;DML&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24230;&#37327;&#23398;&#20064;&#65288;DML&#65289;&#26088;&#22312;&#26368;&#23567;&#21270;&#23884;&#20837;&#31354;&#38388;&#20013;&#25104;&#23545;&#20869;/&#38388;&#31867;&#36817;&#20284;&#36829;&#35268;&#30340;&#32463;&#39564;&#39044;&#26399;&#25439;&#22833;&#12290;&#25105;&#20204;&#23558;DML&#19982;&#26377;&#38480;&#26426;&#20250;&#32422;&#26463;&#30340;&#21487;&#34892;&#24615;&#38382;&#39064;&#30456;&#20851;&#32852;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22522;&#20110;&#20195;&#29702;&#30340;DML&#30340;&#26368;&#23567;&#21270;&#32773;&#28385;&#36275;&#26576;&#20123;&#26426;&#20250;&#32422;&#26463;&#65292;&#24182;&#19988;&#22522;&#20110;&#20195;&#29702;&#30340;&#26041;&#27861;&#30340;&#26368;&#22351;&#24773;&#20917;&#27867;&#21270;&#24615;&#33021;&#21487;&#20197;&#29992;&#35206;&#30422;&#23545;&#24212;&#31867;&#26679;&#26412;&#25972;&#20010;&#22495;&#30340;&#26368;&#23567;&#29699;&#30340;&#21322;&#24452;&#26469;&#25551;&#36848;&#65292;&#36825;&#34920;&#26126;&#27599;&#20010;&#31867;&#21035;&#20351;&#29992;&#22810;&#20010;&#20195;&#29702;&#26377;&#21161;&#20110;&#24615;&#33021;&#25552;&#21319;&#12290;&#20026;&#20102;&#25552;&#20379;&#21487;&#25193;&#23637;&#30340;&#31639;&#27861;&#24182;&#21033;&#29992;&#26356;&#22810;&#30340;&#20195;&#29702;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#22522;&#20110;&#20195;&#29702;&#30340;DML&#23454;&#20363;&#26368;&#23567;&#21270;&#32773;&#25152;&#34164;&#21547;&#30340;&#26426;&#20250;&#32422;&#26463;&#65292;&#24182;&#23558;DML&#37325;&#26032;&#21046;&#23450;&#20026;&#22312;&#36825;&#20123;&#32422;&#26463;&#20132;&#38598;&#20013;&#25214;&#21040;&#21487;&#34892;&#28857;&#30340;&#38382;&#39064;&#65292;&#20174;&#32780;&#24471;&#21040;&#19968;&#20010;&#36890;&#36807;&#36845;&#20195;&#25237;&#24433;&#26469;&#36817;&#20284;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#31616;&#32780;&#35328;&#20043;&#65292;&#25105;&#20204;&#21453;&#22797;&#35757;&#32451;&#27491;&#21017;&#21270;&#30340;&#22522;&#20110;&#20195;&#29702;&#30340;&#25439;&#22833;&#65292;&#24182;&#37325;&#26032;&#21021;&#22987;&#21270;&#23884;&#20837;&#30340;&#20195;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep metric learning (DML) aims to minimize empirical expected loss of the pairwise intra-/inter- class proximity violations in the embedding space. We relate DML to feasibility problem of finite chance constraints. We show that minimizer of proxy-based DML satisfies certain chance constraints, and that the worst case generalization performance of the proxy-based methods can be characterized by the radius of the smallest ball around a class proxy to cover the entire domain of the corresponding class samples, suggesting multiple proxies per class helps performance. To provide a scalable algorithm as well as exploiting more proxies, we consider the chance constraints implied by the minimizers of proxy-based DML instances and reformulate DML as finding a feasible point in intersection of such constraints, resulting in a problem to be approximately solved by iterative projections. Simply put, we repeatedly train a regularized proxy-based loss and re-initialize the proxies with the embeddin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21322;&#23450;&#35268;&#21010;&#30340;&#20840;&#23616;&#20248;&#21270;&#26041;&#27861;&#26469;&#35299;&#20915;&#24102;&#22522;&#25968;&#32422;&#26463;&#30340;&#26368;&#23567;&#24179;&#26041;&#21644;&#32858;&#31867;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;SDP&#26494;&#24347;&#26041;&#27861;&#21644;&#23450;&#21046;&#30340;&#20998;&#25903;&#31574;&#30053;&#26469;&#25913;&#21892;&#35299;&#30340;&#36136;&#37327;&#21644;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2209.08901</link><description>&lt;p&gt;
&#22522;&#20110;&#21322;&#23450;&#35268;&#21010;&#30340;&#24102;&#22522;&#25968;&#32422;&#26463;&#26368;&#23567;&#24179;&#26041;&#21644;&#32858;&#31867;&#30340;&#20840;&#23616;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Global Optimization for Cardinality-constrained Minimum Sum-of-Squares Clustering via Semidefinite Programming. (arXiv:2209.08901v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.08901
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21322;&#23450;&#35268;&#21010;&#30340;&#20840;&#23616;&#20248;&#21270;&#26041;&#27861;&#26469;&#35299;&#20915;&#24102;&#22522;&#25968;&#32422;&#26463;&#30340;&#26368;&#23567;&#24179;&#26041;&#21644;&#32858;&#31867;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;SDP&#26494;&#24347;&#26041;&#27861;&#21644;&#23450;&#21046;&#30340;&#20998;&#25903;&#31574;&#30053;&#26469;&#25913;&#21892;&#35299;&#30340;&#36136;&#37327;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#23567;&#24179;&#26041;&#21644;&#32858;&#31867;(MSSC)&#25110;k&#22343;&#20540;&#31867;&#22411;&#32858;&#31867;&#26368;&#36817;&#24050;&#32463;&#25193;&#23637;&#20197;&#21033;&#29992;&#23545;&#27599;&#20010;&#31751;&#22522;&#25968;&#30340;&#20808;&#39564;&#30693;&#35782;&#12290;&#36825;&#31181;&#30693;&#35782;&#34987;&#29992;&#20110;&#25552;&#39640;&#24615;&#33021;&#21644;&#35299;&#20915;&#26041;&#26696;&#36136;&#37327;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#25903;&#23450;&#30028;&#25216;&#26415;&#30340;&#20840;&#23616;&#20248;&#21270;&#26041;&#27861;&#26469;&#35299;&#20915;&#22522;&#25968;&#32422;&#26463;&#30340;MSSC&#38382;&#39064;&#12290;&#23545;&#20110;&#19979;&#30028;&#20363;&#31243;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;Rujeerapaiboon&#31561;&#20154;&#26368;&#36817;&#25552;&#20986;&#30340;&#21322;&#23450;&#35268;&#21010;(SDP)&#26494;&#24347;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#35813;&#26494;&#24347;&#26041;&#27861;&#21482;&#36866;&#29992;&#20110;&#23567;&#35268;&#27169;&#23454;&#20363;&#30340;&#20998;&#25903;&#23450;&#30028;&#26041;&#27861;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;SDP&#26494;&#24347;&#26041;&#27861;&#65292;&#23427;&#33021;&#26356;&#22909;&#22320;&#36866;&#24212;&#23454;&#20363;&#35268;&#27169;&#21644;&#31751;&#30340;&#25968;&#30446;&#12290;&#22312;&#20004;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#36890;&#36807;&#28155;&#21152;&#22810;&#38754;&#20307;&#21106;&#32447;&#26469;&#21152;&#24378;&#19979;&#30028;&#12290;&#36890;&#36807;&#23450;&#21046;&#30340;&#20998;&#25903;&#31574;&#30053;&#65292;&#25105;&#20204;&#23454;&#26045;&#20102;&#25104;&#23545;&#32422;&#26463;&#65292;&#20174;&#32780;&#20943;&#23569;&#20102;&#23376;&#33410;&#28857;&#20013;&#20986;&#29616;&#30340;&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#12290;&#23545;&#20110;&#19978;&#30028;&#65292;
&lt;/p&gt;
&lt;p&gt;
The minimum sum-of-squares clustering (MSSC), or k-means type clustering, has been recently extended to exploit prior knowledge on the cardinality of each cluster. Such knowledge is used to increase performance as well as solution quality. In this paper, we propose a global optimization approach based on the branch-and-cut technique to solve the cardinality-constrained MSSC. For the lower bound routine, we use the semidefinite programming (SDP) relaxation recently proposed by Rujeerapaiboon et al. [SIAM J. Optim. 29(2), 1211-1239, (2019)]. However, this relaxation can be used in a branch-and-cut method only for small-size instances. Therefore, we derive a new SDP relaxation that scales better with the instance size and the number of clusters. In both cases, we strengthen the bound by adding polyhedral cuts. Benefiting from a tailored branching strategy which enforces pairwise constraints, we reduce the complexity of the problems arising in the children nodes. For the upper bound, inste
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Auto-SDE&#30340;&#31639;&#27861;&#26469;&#23398;&#20064;&#24930;-&#24555;&#38543;&#26426;&#21160;&#21147;&#23398;&#31995;&#32479;&#30340;&#26377;&#25928;&#38477;&#32500;&#21160;&#21147;&#23398;&#65292;&#36890;&#36807;&#33258;&#21160;&#32534;&#30721;&#22120;&#31070;&#32463;&#32593;&#32476;&#21644;&#31163;&#25955;&#21270;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65292;&#25429;&#25417;&#20102;&#31995;&#32479;&#30340;&#28436;&#21270;&#29305;&#24615;&#65292;&#24182;&#22312;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#20934;&#30830;&#24615;&#12289;&#31283;&#23450;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2205.04151</link><description>&lt;p&gt;
Auto-SDE:&#20174;&#25968;&#25454;&#39537;&#21160;&#30340;&#38543;&#26426;&#21160;&#21147;&#23398;&#31995;&#32479;&#20013;&#23398;&#20064;&#26377;&#25928;&#30340;&#38477;&#32500;&#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
Auto-SDE: Learning effective reduced dynamics from data-driven stochastic dynamical systems. (arXiv:2205.04151v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.04151
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Auto-SDE&#30340;&#31639;&#27861;&#26469;&#23398;&#20064;&#24930;-&#24555;&#38543;&#26426;&#21160;&#21147;&#23398;&#31995;&#32479;&#30340;&#26377;&#25928;&#38477;&#32500;&#21160;&#21147;&#23398;&#65292;&#36890;&#36807;&#33258;&#21160;&#32534;&#30721;&#22120;&#31070;&#32463;&#32593;&#32476;&#21644;&#31163;&#25955;&#21270;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65292;&#25429;&#25417;&#20102;&#31995;&#32479;&#30340;&#28436;&#21270;&#29305;&#24615;&#65292;&#24182;&#22312;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#20934;&#30830;&#24615;&#12289;&#31283;&#23450;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#33021;&#22815;&#25551;&#32472;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#22797;&#26434;&#29616;&#35937;&#65292;&#22810;&#23610;&#24230;&#38543;&#26426;&#21160;&#21147;&#23398;&#31995;&#32479;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#31185;&#23398;&#21644;&#24037;&#31243;&#38382;&#39064;&#12290;&#26412;&#25991;&#33268;&#21147;&#20110;&#30740;&#31350;&#24930;-&#24555;&#38543;&#26426;&#21160;&#21147;&#23398;&#31995;&#32479;&#30340;&#26377;&#25928;&#38477;&#32500;&#21160;&#21147;&#23398;&#12290;&#32473;&#23450;&#28385;&#36275;&#26576;&#20123;&#26410;&#30693;&#24930;-&#24555;&#38543;&#26426;&#31995;&#32479;&#30340;&#30701;&#26399;&#35266;&#27979;&#25968;&#25454;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21253;&#25324;&#33258;&#21160;&#32534;&#30721;&#22120;&#31070;&#32463;&#32593;&#32476;Auto-SDE&#30340;&#26032;&#31639;&#27861;&#26469;&#23398;&#20064;&#19981;&#21464;&#30340;&#24930;&#27969;&#24418;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25429;&#25417;&#20102;&#19968;&#31995;&#21015;&#26102;&#38388;&#30456;&#20851;&#30340;&#33258;&#21160;&#32534;&#30721;&#22120;&#31070;&#32463;&#32593;&#32476;&#30340;&#28436;&#21270;&#29305;&#24615;&#65292;&#25439;&#22833;&#20989;&#25968;&#36890;&#36807;&#31163;&#25955;&#21270;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#26500;&#36896;&#12290;&#36890;&#36807;&#22312;&#21508;&#31181;&#35780;&#20272;&#25351;&#26631;&#19979;&#30340;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#20855;&#26377;&#20934;&#30830;&#24615;&#12289;&#31283;&#23450;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multiscale stochastic dynamical systems have been widely adopted to scientific and engineering problems due to their capability of depicting complex phenomena in many real world applications. This work is devoted to investigating the effective reduced dynamics for a slow-fast stochastic dynamical system. Given observation data on a short-term period satisfying some unknown slow-fast stochastic system, we propose a novel algorithm including a neural network called Auto-SDE to learn invariant slow manifold. Our approach captures the evolutionary nature of a series of time-dependent autoencoder neural networks with the loss constructed from a discretized stochastic differential equation. Our algorithm is also proved to be accurate, stable and effective through numerical experiments under various evaluation metrics.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#24555;&#26356;&#24265;&#20215;&#30340;&#25130;&#26029;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#26041;&#27861;&#65292;&#36890;&#36807;&#20174;&#38544;&#34255;&#22122;&#22768;&#25968;&#25454;&#20998;&#24067;&#24320;&#22987;&#29983;&#25104;&#25968;&#25454;&#65292;&#30456;&#36739;&#20110;&#20256;&#32479;&#30340;&#26041;&#27861;&#21487;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#24615;&#33021;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2202.09671</link><description>&lt;p&gt;
&#25130;&#26029;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#21644;&#22522;&#20110;&#25193;&#25955;&#30340;&#23545;&#25239;&#33258;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Truncated Diffusion Probabilistic Models and Diffusion-based Adversarial Auto-Encoders. (arXiv:2202.09671v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.09671
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#24555;&#26356;&#24265;&#20215;&#30340;&#25130;&#26029;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#26041;&#27861;&#65292;&#36890;&#36807;&#20174;&#38544;&#34255;&#22122;&#22768;&#25968;&#25454;&#20998;&#24067;&#24320;&#22987;&#29983;&#25104;&#25968;&#25454;&#65292;&#30456;&#36739;&#20110;&#20256;&#32479;&#30340;&#26041;&#27861;&#21487;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#24615;&#33021;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#22411;&#29983;&#25104;&#27169;&#22411;&#36890;&#36807;&#20351;&#29992;&#27491;&#21521;&#25193;&#25955;&#38142;&#36880;&#27493;&#23558;&#25968;&#25454;&#26144;&#23556;&#21040;&#22122;&#22768;&#20998;&#24067;&#65292;&#24182;&#36890;&#36807;&#25512;&#26029;&#21453;&#21521;&#25193;&#25955;&#38142;&#26469;&#23398;&#20064;&#22914;&#20309;&#29983;&#25104;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#36895;&#24230;&#24930;&#19988;&#25104;&#26412;&#39640;&#65292;&#22240;&#20026;&#38656;&#35201;&#35768;&#22810;&#27491;&#21521;&#21644;&#21453;&#21521;&#27493;&#39588;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#24555;&#26356;&#24265;&#20215;&#30340;&#26041;&#27861;&#65292;&#19981;&#26159;&#23558;&#22122;&#22768;&#28155;&#21152;&#21040;&#25968;&#25454;&#21464;&#20026;&#32431;&#38543;&#26426;&#22122;&#22768;&#65292;&#32780;&#26159;&#30452;&#21040;&#36798;&#21040;&#19968;&#20010;&#21487;&#20197;&#33258;&#20449;&#23398;&#20064;&#30340;&#38544;&#34255;&#22122;&#22768;&#25968;&#25454;&#20998;&#24067;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#36739;&#23569;&#30340;&#21453;&#21521;&#27493;&#39588;&#36890;&#36807;&#20174;&#36825;&#20010;&#38544;&#34255;&#20998;&#24067;&#24320;&#22987;&#29983;&#25104;&#31867;&#20284;&#20110;&#22122;&#22768;&#25968;&#25454;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#25581;&#31034;&#20102;&#35813;&#27169;&#22411;&#21487;&#20197;&#34987;&#35270;&#20026;&#19968;&#20010;&#36890;&#36807;&#25193;&#25955;&#36807;&#31243;&#21644;&#21487;&#23398;&#20064;&#30340;&#38544;&#21547;&#20808;&#39564;&#22686;&#24378;&#30340;&#23545;&#25239;&#24615;&#33258;&#32534;&#30721;&#22120;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#21363;&#20351;&#22312;&#36739;&#23569;&#30340;&#21453;&#21521;&#25193;&#25955;&#27493;&#39588;&#19979;&#65292;&#25152;&#25552;&#20986;&#30340;&#25130;&#26029;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#22312;&#24615;&#33021;&#26041;&#38754;&#20173;&#28982;&#21487;&#20197;&#30456;&#36739;&#20110;&#38750;&#25130;&#26029;&#27169;&#22411;&#25552;&#20379;&#19968;&#33268;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Employing a forward diffusion chain to gradually map the data to a noise distribution, diffusion-based generative models learn how to generate the data by inferring a reverse diffusion chain. However, this approach is slow and costly because it needs many forward and reverse steps. We propose a faster and cheaper approach that adds noise not until the data become pure random noise, but until they reach a hidden noisy data distribution that we can confidently learn. Then, we use fewer reverse steps to generate data by starting from this hidden distribution that is made similar to the noisy data. We reveal that the proposed model can be cast as an adversarial auto-encoder empowered by both the diffusion process and a learnable implicit prior. Experimental results show even with a significantly smaller number of reverse diffusion steps, the proposed truncated diffusion probabilistic models can provide consistent improvements over the non-truncated ones in terms of performance in both unco
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27604;&#36739;&#24207;&#36143;&#39044;&#27979;&#22120;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35774;&#35745;&#26032;&#30340;&#24207;&#36143;&#25512;&#26029;&#31243;&#24207;&#26469;&#20272;&#35745;&#39044;&#27979;&#24471;&#20998;&#30340;&#26102;&#21464;&#24046;&#24322;&#65292;&#36825;&#31181;&#26041;&#27861;&#36991;&#20813;&#20102;&#23545;&#39044;&#27979;&#21644;&#32467;&#26524;&#29983;&#25104;&#26041;&#24335;&#30340;&#19981;&#21487;&#39564;&#35777;&#20551;&#35774;&#12290;</title><link>http://arxiv.org/abs/2110.00115</link><description>&lt;p&gt;
&#27604;&#36739;&#24207;&#36143;&#39044;&#27979;&#22120;
&lt;/p&gt;
&lt;p&gt;
Comparing Sequential Forecasters. (arXiv:2110.00115v5 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.00115
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27604;&#36739;&#24207;&#36143;&#39044;&#27979;&#22120;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35774;&#35745;&#26032;&#30340;&#24207;&#36143;&#25512;&#26029;&#31243;&#24207;&#26469;&#20272;&#35745;&#39044;&#27979;&#24471;&#20998;&#30340;&#26102;&#21464;&#24046;&#24322;&#65292;&#36825;&#31181;&#26041;&#27861;&#36991;&#20813;&#20102;&#23545;&#39044;&#27979;&#21644;&#32467;&#26524;&#29983;&#25104;&#26041;&#24335;&#30340;&#19981;&#21487;&#39564;&#35777;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32771;&#34385;&#20004;&#20010;&#39044;&#27979;&#22120;&#65292;&#22312;&#19968;&#27573;&#26102;&#38388;&#20869;&#23545;&#19968;&#31995;&#21015;&#20107;&#20214;&#36827;&#34892;&#21333;&#27425;&#39044;&#27979;&#12290;&#25105;&#20204;&#25552;&#20986;&#19968;&#20010;&#30456;&#23545;&#22522;&#30784;&#30340;&#38382;&#39064;&#65306;&#22312;&#19981;&#20551;&#35774;&#39044;&#27979;&#21644;&#32467;&#26524;&#29983;&#25104;&#26041;&#24335;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#22914;&#20309;&#27604;&#36739;&#36825;&#20123;&#39044;&#27979;&#22120;&#65292;&#26080;&#35770;&#26159;&#22312;&#32447;&#36824;&#26159;&#20107;&#21518;&#27604;&#36739;&#65311;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#35774;&#35745;&#29992;&#20110;&#20272;&#35745;&#26102;&#21464;&#39044;&#27979;&#24471;&#20998;&#24046;&#24322;&#30340;&#26032;&#22411;&#24207;&#36143;&#25512;&#26029;&#31243;&#24207;&#65292;&#23545;&#36825;&#20010;&#38382;&#39064;&#32473;&#20986;&#20102;&#20005;&#26684;&#30340;&#31572;&#26696;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#37319;&#29992;&#32622;&#20449;&#24207;&#21015;&#65288;CS&#65289;&#65292;&#23427;&#26159;&#19968;&#31995;&#21015;&#32622;&#20449;&#21306;&#38388;&#65292;&#21487;&#20197;&#36830;&#32493;&#30417;&#27979;&#24182;&#22312;&#20219;&#24847;&#25968;&#25454;&#20381;&#36182;&#20572;&#26102;&#65288;&#8220;anytime-valid&#8221;&#65289;&#19979;&#26377;&#25928;&#12290;&#25105;&#20204;&#30340;&#32622;&#20449;&#24207;&#21015;&#30340;&#23485;&#24230;&#26159;&#33258;&#36866;&#24212;&#30340;&#65292;&#36866;&#24212;&#20102;&#24471;&#20998;&#24046;&#24322;&#30340;&#24213;&#23618;&#26041;&#24046;&#12290;&#23427;&#20204;&#30340;&#26500;&#24314;&#22522;&#20110;&#21338;&#24328;&#35770;&#32479;&#35745;&#26694;&#26550;&#65292;&#22312;&#36825;&#20010;&#26694;&#26550;&#20013;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#30830;&#23450;&#20102;&#29992;&#20110;&#39034;&#24207;&#26816;&#39564;&#24369;&#38646;&#20551;&#35774;&#30340;e&#36807;&#31243;&#21644;p&#36807;&#31243;&#65292;&#21363;&#19968;&#20010;&#39044;&#27979;&#22120;&#24179;&#22343;&#34920;&#29616;&#26159;&#21542;&#20248;&#20110;&#21478;&#19968;&#20010;&#39044;&#27979;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consider two forecasters, each making a single prediction for a sequence of events over time. We ask a relatively basic question: how might we compare these forecasters, either online or post-hoc, while avoiding unverifiable assumptions on how the forecasts and outcomes were generated? In this paper, we present a rigorous answer to this question by designing novel sequential inference procedures for estimating the time-varying difference in forecast scores. To do this, we employ confidence sequences (CS), which are sequences of confidence intervals that can be continuously monitored and are valid at arbitrary data-dependent stopping times ("anytime-valid"). The widths of our CSs are adaptive to the underlying variance of the score differences. Underlying their construction is a game-theoretic statistical framework, in which we further identify e-processes and p-processes for sequentially testing a weak null hypothesis -- whether one forecaster outperforms another on average (rather tha
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#38774;&#32593;&#32476;&#19982;&#21151;&#33021;&#27491;&#21017;&#21270;&#22312;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20316;&#29992;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#38774;&#32593;&#32476;&#20316;&#20026;&#38544;&#24335;&#27491;&#21017;&#21270;&#22120;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#26377;&#21033;&#65292;&#20294;&#19981;&#28789;&#27963;&#19988;&#21487;&#33021;&#23548;&#33268;&#19981;&#31283;&#23450;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#26126;&#30830;&#30340;&#21151;&#33021;&#27491;&#21017;&#21270;&#26367;&#20195;&#26041;&#27861;&#65292;&#24182;&#23545;&#20854;&#25910;&#25947;&#24615;&#36827;&#34892;&#20102;&#29702;&#35770;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2106.02613</link><description>&lt;p&gt;
&#26550;&#36215;&#38774;&#32593;&#32476;&#19982;&#21151;&#33021;&#27491;&#21017;&#21270;&#20043;&#38388;&#30340;&#40511;&#27807;
&lt;/p&gt;
&lt;p&gt;
Bridging the Gap Between Target Networks and Functional Regularization. (arXiv:2106.02613v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.02613
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#38774;&#32593;&#32476;&#19982;&#21151;&#33021;&#27491;&#21017;&#21270;&#22312;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20316;&#29992;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#38774;&#32593;&#32476;&#20316;&#20026;&#38544;&#24335;&#27491;&#21017;&#21270;&#22120;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#26377;&#21033;&#65292;&#20294;&#19981;&#28789;&#27963;&#19988;&#21487;&#33021;&#23548;&#33268;&#19981;&#31283;&#23450;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#26126;&#30830;&#30340;&#21151;&#33021;&#27491;&#21017;&#21270;&#26367;&#20195;&#26041;&#27861;&#65292;&#24182;&#23545;&#20854;&#25910;&#25947;&#24615;&#36827;&#34892;&#20102;&#29702;&#35770;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24341;&#23548;&#26159;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#25104;&#21151;&#30340;&#20851;&#38190;&#12290;&#28982;&#32780;&#65292;&#36890;&#36807;&#24341;&#23548;&#23398;&#20064;&#20540;&#20989;&#25968;&#24448;&#24448;&#23548;&#33268;&#35757;&#32451;&#19981;&#31283;&#23450;&#65292;&#21407;&#22240;&#26159;&#30446;&#26631;&#20540;&#24555;&#36895;&#21464;&#21270;&#12290;&#38774;&#32593;&#32476;&#36890;&#36807;&#20351;&#29992;&#39069;&#22806;&#30340;&#28382;&#21518;&#21442;&#25968;&#38598;&#21512;&#26469;&#20272;&#35745;&#30446;&#26631;&#20540;&#65292;&#20197;&#31283;&#23450;&#35757;&#32451;&#12290;&#23613;&#31649;&#38774;&#32593;&#32476;&#24456;&#21463;&#27426;&#36814;&#65292;&#20294;&#20854;&#23545;&#20248;&#21270;&#30340;&#24433;&#21709;&#20173;&#26410;&#34987;&#29702;&#35299;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#38774;&#32593;&#32476;&#20316;&#20026;&#19968;&#20010;&#38544;&#24335;&#27491;&#21017;&#21270;&#22120;&#30340;&#20316;&#29992;&#65292;&#23427;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#26159;&#26377;&#30410;&#30340;&#65292;&#20294;&#20063;&#23384;&#22312;&#19968;&#20123;&#32570;&#28857;&#65292;&#22914;&#19981;&#28789;&#27963;&#21644;&#21487;&#33021;&#23548;&#33268;&#19981;&#31283;&#23450;&#65292;&#21363;&#20351;&#39321;&#33609;TD(0)&#25910;&#25947;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26126;&#30830;&#30340;&#21151;&#33021;&#27491;&#21017;&#21270;&#26367;&#20195;&#26041;&#27861;&#65292;&#23427;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#26159;&#28789;&#27963;&#21644;&#20984;&#27491;&#21017;&#21270;&#22120;&#65292;&#24182;&#23545;&#20854;&#25910;&#25947;&#24615;&#36827;&#34892;&#20102;&#29702;&#35770;&#30740;&#31350;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#29615;&#22659;&#12289;&#25240;&#25187;&#22240;&#23376;&#21644;&#38750;&#38543;&#26426;&#25968;&#25454;&#25910;&#38598;&#19979;&#36827;&#34892;&#20102;&#23454;&#39564;&#30740;&#31350;&#65292;&#20197;&#35843;&#26597;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bootstrapping is behind much of the successes of deep Reinforcement Learning. However, learning the value function via bootstrapping often leads to unstable training due to fast-changing target values. Target Networks are employed to stabilize training by using an additional set of lagging parameters to estimate the target values. Despite the popularity of Target Networks, their effect on the optimization is still misunderstood. In this work, we show that they act as an implicit regularizer which can be beneficial in some cases, but also have disadvantages such as being inflexible and can result in instabilities, even when vanilla TD(0) converges. To overcome these issues, we propose an explicit Functional Regularization alternative that is flexible and a convex regularizer in function space and we theoretically study its convergence. We conduct an experimental study across a range of environments, discount factors, and off-policiness data collections to investigate the effectiveness o
&lt;/p&gt;</description></item><item><title>BoXHED2.0&#26159;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#21160;&#24577;&#29983;&#23384;&#20998;&#26512;&#25552;&#21319;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#21253;&#25324;&#37325;&#22797;&#20107;&#20214;&#21644;&#31454;&#20105;&#39118;&#38505;&#22312;&#20869;&#30340;&#22810;&#31181;&#29983;&#23384;&#29615;&#22659;&#65292;&#20855;&#26377;&#19982;&#21442;&#25968;&#21270;&#25552;&#21319;&#29983;&#23384;&#27169;&#22411;&#30456;&#23218;&#32654;&#30340;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2103.12591</link><description>&lt;p&gt;
BoXHED2.0&#65306;&#21487;&#25193;&#23637;&#30340;&#21160;&#24577;&#29983;&#23384;&#20998;&#26512;&#25552;&#21319;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
BoXHED2.0: Scalable boosting of dynamic survival analysis. (arXiv:2103.12591v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2103.12591
&lt;/p&gt;
&lt;p&gt;
BoXHED2.0&#26159;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#21160;&#24577;&#29983;&#23384;&#20998;&#26512;&#25552;&#21319;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#21253;&#25324;&#37325;&#22797;&#20107;&#20214;&#21644;&#31454;&#20105;&#39118;&#38505;&#22312;&#20869;&#30340;&#22810;&#31181;&#29983;&#23384;&#29615;&#22659;&#65292;&#20855;&#26377;&#19982;&#21442;&#25968;&#21270;&#25552;&#21319;&#29983;&#23384;&#27169;&#22411;&#30456;&#23218;&#32654;&#30340;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#29983;&#23384;&#20998;&#26512;&#30340;&#24212;&#29992;&#36234;&#26469;&#36234;&#22810;&#22320;&#28041;&#21450;&#21040;&#26102;&#38388;&#20381;&#36182;&#30340;&#21327;&#21464;&#37327;&#12290;Python&#36719;&#20214;&#21253;BoXHED2.0&#26159;&#19968;&#20010;&#23436;&#20840;&#38750;&#21442;&#25968;&#30340;&#26641;&#25552;&#21319;&#29983;&#23384;&#39118;&#38505;&#20272;&#35745;&#22120;&#65292;&#36866;&#29992;&#20110;&#27604;&#21491;&#25130;&#23614;&#26356;&#36890;&#29992;&#30340;&#29983;&#23384;&#29615;&#22659;&#65292;&#21253;&#25324;&#37325;&#22797;&#20107;&#20214;&#21644;&#31454;&#20105;&#39118;&#38505;&#12290;&#30001;&#20110;&#20854;&#26680;&#24515;&#26159;&#29992;C++&#32534;&#20889;&#30340;&#65292;&#36824;&#25903;&#25345;&#20351;&#29992;GPU&#21644;&#22810;&#26680;CPU&#65292;&#22240;&#27492;BoXHED2.0&#30340;&#21487;&#20280;&#32553;&#24615;&#21487;&#19982;&#21442;&#25968;&#21270;&#25552;&#21319;&#29983;&#23384;&#27169;&#22411;&#30456;&#23218;&#32654;&#12290;BoXHED2.0&#21487;&#20174;PyPI&#21644;www.github.com/BoXHED&#33719;&#21462;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern applications of survival analysis increasingly involve time-dependent covariates. The Python package BoXHED2.0 is a tree-boosted hazard estimator that is fully nonparametric, and is applicable to survival settings far more general than right-censoring, including recurring events and competing risks. BoXHED2.0 is also scalable to the point of being on the same order of speed as parametric boosted survival models, in part because its core is written in C++ and it also supports the use of GPUs and multicore CPUs. BoXHED2.0 is available from PyPI and also from www.github.com/BoXHED.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#35299;&#20915;&#36866;&#24403;&#23398;&#20064;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#38750;&#20132;&#25442;&#22810;&#39033;&#24335;&#20248;&#21270;&#65292;&#20445;&#35777;&#20102;&#25968;&#20540;&#35299;&#23545;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2002.01444</link><description>&lt;p&gt;
&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#36866;&#24403;&#23398;&#20064;&#20316;&#20026;&#38750;&#20132;&#25442;&#22810;&#39033;&#24335;&#20248;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Proper Learning of Linear Dynamical Systems as a Non-Commutative Polynomial Optimisation Problem. (arXiv:2002.01444v5 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2002.01444
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#35299;&#20915;&#36866;&#24403;&#23398;&#20064;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#38750;&#20132;&#25442;&#22810;&#39033;&#24335;&#20248;&#21270;&#65292;&#20445;&#35777;&#20102;&#25968;&#20540;&#35299;&#23545;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22312;&#39044;&#27979;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#65288;LDS&#65289;&#30340;&#19979;&#19968;&#20010;&#35266;&#27979;&#20540;&#65288;&#31216;&#20026;&#19981;&#36866;&#24403;&#23398;&#20064;&#65289;&#20197;&#21450;&#20272;&#35745;&#20854;&#31995;&#32479;&#30697;&#38453;&#65288;&#31216;&#20026;&#36866;&#24403;&#23398;&#20064;LDS&#65289;&#26041;&#38754;&#21462;&#24471;&#20102;&#24456;&#22823;&#36827;&#23637;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#24403;&#23398;&#20064;LDS&#30340;&#26041;&#27861;&#65292;&#23613;&#31649;&#38382;&#39064;&#38750;&#20984;&#65292;&#20294;&#33021;&#22815;&#20445;&#35777;&#25968;&#20540;&#35299;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#21040;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26377;&#24076;&#26395;&#30340;&#35745;&#31639;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
There has been much recent progress in forecasting the next observation of a linear dynamical system (LDS), which is known as the improper learning, as well as in the estimation of its system matrices, which is known as the proper learning of LDS. We present an approach to proper learning of LDS, which in spite of the non-convexity of the problem, guarantees global convergence of numerical solutions to a least-squares estimator. We present promising computational results.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35752;&#35770;&#20102;&#36890;&#36807;&#27010;&#29575;&#36923;&#36753;&#21644;&#20851;&#32852;Copula&#20989;&#25968;&#35299;&#20915;&#24322;&#25110;&#34920;&#31034;&#21644;&#36924;&#36817;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#27604;&#36739;&#19981;&#21516;&#28608;&#27963;&#20989;&#25968;&#19979;&#30340;&#35823;&#24046;&#38754;&#21160;&#24577;&#26469;&#35828;&#26126;&#20854;&#20248;&#21183;&#12290;&#36890;&#36807;&#23558;xor&#34920;&#31034;&#20174;&#24067;&#23572;&#20540;&#25193;&#23637;&#21040;&#23454;&#25968;&#20540;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#28436;&#31034;&#20132;&#21449;&#39564;&#35777;&#27010;&#24565;&#30340;&#26041;&#20415;&#26041;&#24335;&#12290;</title><link>http://arxiv.org/abs/1907.04483</link><description>&lt;p&gt;
Copula&#34920;&#31034;&#21644;&#35823;&#24046;&#38754;&#25237;&#24433;&#23545;&#20110;&#24322;&#25110;&#38382;&#39064;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Copula Representations and Error Surface Projections for the Exclusive Or Problem. (arXiv:1907.04483v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1907.04483
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35752;&#35770;&#20102;&#36890;&#36807;&#27010;&#29575;&#36923;&#36753;&#21644;&#20851;&#32852;Copula&#20989;&#25968;&#35299;&#20915;&#24322;&#25110;&#34920;&#31034;&#21644;&#36924;&#36817;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#27604;&#36739;&#19981;&#21516;&#28608;&#27963;&#20989;&#25968;&#19979;&#30340;&#35823;&#24046;&#38754;&#21160;&#24577;&#26469;&#35828;&#26126;&#20854;&#20248;&#21183;&#12290;&#36890;&#36807;&#23558;xor&#34920;&#31034;&#20174;&#24067;&#23572;&#20540;&#25193;&#23637;&#21040;&#23454;&#25968;&#20540;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#28436;&#31034;&#20132;&#21449;&#39564;&#35777;&#27010;&#24565;&#30340;&#26041;&#20415;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24322;&#25110;&#65288;xor&#65289;&#20989;&#25968;&#26159;&#23637;&#31034;&#20026;&#20160;&#20040;&#38750;&#32447;&#24615;&#21069;&#39304;&#32593;&#32476;&#22312;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#20248;&#20110;&#32447;&#24615;&#22238;&#24402;&#30340;&#26368;&#31616;&#21333;&#30340;&#31034;&#20363;&#20043;&#19968;&#12290;&#25105;&#20204;&#36890;&#36807;&#27010;&#29575;&#36923;&#36753;&#21644;&#20851;&#32852;Copula&#20989;&#25968;&#35752;&#35770;&#20102;xor&#34920;&#31034;&#21644;&#36924;&#36817;&#38382;&#39064;&#21450;&#20854;&#35299;&#20915;&#26041;&#26696;&#12290;&#22312;&#31616;&#35201;&#22238;&#39038;&#21069;&#39304;&#32593;&#32476;&#35268;&#33539;&#20043;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#32452;&#33394;&#24425;&#20016;&#23500;&#30340;&#19977;&#32500;&#22270;&#34920;&#27604;&#36739;&#20102;&#20351;&#29992;RELU&#21644;tanh&#31561;&#19981;&#21516;&#28608;&#27963;&#20989;&#25968;&#30340;&#23398;&#20064;&#35823;&#24046;&#38754;&#30340;&#21160;&#24577;&#12290;Copula&#34920;&#31034;&#23558;xor&#20174;&#24067;&#23572;&#20540;&#25193;&#23637;&#21040;&#23454;&#25968;&#20540;&#65292;&#20174;&#32780;&#25552;&#20379;&#20102;&#19968;&#31181;&#26041;&#20415;&#30340;&#26041;&#24335;&#26469;&#28436;&#31034;&#22312;&#26679;&#26412;&#20869;&#21644;&#26679;&#26412;&#22806;&#25968;&#25454;&#38598;&#19978;&#30340;&#20132;&#21449;&#39564;&#35777;&#30340;&#27010;&#24565;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#25945;&#23398;&#24615;&#30340;&#65292;&#26088;&#22312;&#25104;&#20026;&#26426;&#22120;&#23398;&#20064;&#23548;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
The exclusive or (xor) function is one of the simplest examples that illustrate why nonlinear feedforward networks are superior to linear regression for machine learning applications. We review the xor representation and approximation problems and discuss their solutions in terms of probabilistic logic and associative copula functions. After briefly reviewing the specification of feedforward networks, we compare the dynamics of learned error surfaces with different activation functions such as RELU and tanh through a set of colorful three-dimensional charts. The copula representations extend xor from Boolean to real values, thereby providing a convenient way to demonstrate the concept of cross-validation on in-sample and out-sample data sets. Our approach is pedagogical and is meant to be a machine learning prolegomenon.
&lt;/p&gt;</description></item></channel></rss>