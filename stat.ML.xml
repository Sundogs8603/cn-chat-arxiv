<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#30740;&#31350;&#20102;&#22810;&#22836;softmax&#27880;&#24847;&#21147;&#27169;&#22411;&#22312;&#19978;&#19979;&#25991;&#23398;&#20064;&#20013;&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#35777;&#26126;&#20102;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#24182;&#21457;&#29616;&#20102;&#8220;&#20219;&#21153;&#20998;&#37197;&#8221;&#29616;&#35937;&#65292;&#26799;&#24230;&#27969;&#21160;&#20998;&#20026;&#28909;&#36523;&#12289;&#28044;&#29616;&#21644;&#25910;&#25947;&#19977;&#20010;&#38454;&#27573;&#65292;&#26368;&#32456;&#35777;&#26126;&#20102;&#26799;&#24230;&#27969;&#30340;&#26368;&#20248;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.19442</link><description>&lt;p&gt;
&#22810;&#22836;softmax&#27880;&#24847;&#21147;&#26426;&#21046;&#22312;&#19978;&#19979;&#25991;&#23398;&#20064;&#20013;&#30340;&#35757;&#32451;&#21160;&#24577;&#65306;&#28044;&#29616;&#12289;&#25910;&#25947;&#21644;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
Training Dynamics of Multi-Head Softmax Attention for In-Context Learning: Emergence, Convergence, and Optimality
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.19442
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#22810;&#22836;softmax&#27880;&#24847;&#21147;&#27169;&#22411;&#22312;&#19978;&#19979;&#25991;&#23398;&#20064;&#20013;&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#35777;&#26126;&#20102;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#24182;&#21457;&#29616;&#20102;&#8220;&#20219;&#21153;&#20998;&#37197;&#8221;&#29616;&#35937;&#65292;&#26799;&#24230;&#27969;&#21160;&#20998;&#20026;&#28909;&#36523;&#12289;&#28044;&#29616;&#21644;&#25910;&#25947;&#19977;&#20010;&#38454;&#27573;&#65292;&#26368;&#32456;&#35777;&#26126;&#20102;&#26799;&#24230;&#27969;&#30340;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#29992;&#20110;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#22810;&#20219;&#21153;&#32447;&#24615;&#22238;&#24402;&#30340;&#22810;&#22836;softmax&#27880;&#24847;&#21147;&#27169;&#22411;&#30340;&#26799;&#24230;&#27969;&#21160;&#21147;&#23398;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#36866;&#24403;&#30340;&#21021;&#22987;&#21270;&#36873;&#25321;&#19979;&#65292;&#26799;&#24230;&#27969;&#21160;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#26799;&#24230;&#27969;&#21160;&#21160;&#21147;&#23398;&#20013;&#20986;&#29616;&#20102;&#26377;&#36259;&#30340;&#8220;&#20219;&#21153;&#20998;&#37197;&#8221;&#29616;&#35937;&#65292;&#27599;&#20010;&#27880;&#24847;&#21147;&#22836;&#37117;&#19987;&#27880;&#20110;&#35299;&#20915;&#22810;&#20219;&#21153;&#27169;&#22411;&#20013;&#30340;&#21333;&#20010;&#20219;&#21153;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#26799;&#24230;&#27969;&#21160;&#21160;&#21147;&#23398;&#21487;&#20197;&#20998;&#20026;&#19977;&#20010;&#38454;&#27573;&#8212;&#8212;&#28909;&#36523;&#38454;&#27573;&#65292;&#22312;&#36825;&#20010;&#38454;&#27573;&#25439;&#22833;&#20943;&#23569;&#36895;&#24230;&#36739;&#24930;&#65292;&#27880;&#24847;&#21147;&#22836;&#36880;&#28176;&#20542;&#21521;&#20110;&#21508;&#33258;&#30340;&#20219;&#21153;&#65307;&#28044;&#29616;&#38454;&#27573;&#65292;&#22312;&#36825;&#20010;&#38454;&#27573;&#65292;&#27599;&#20010;&#22836;&#36873;&#25321;&#19968;&#20010;&#21333;&#29420;&#30340;&#20219;&#21153;&#65292;&#25439;&#22833;&#36805;&#36895;&#20943;&#23569;&#65307;&#21644;&#25910;&#25947;&#38454;&#27573;&#65292;&#22312;&#36825;&#20010;&#38454;&#27573;&#65292;&#27880;&#24847;&#21147;&#21442;&#25968;&#25910;&#25947;&#21040;&#19968;&#20010;&#26497;&#38480;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#26799;&#24230;&#27969;&#22312;&#23398;&#20064;&#26497;&#38480;&#27169;&#22411;&#26041;&#38754;&#30340;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.19442v1 Announce Type: cross  Abstract: We study the dynamics of gradient flow for training a multi-head softmax attention model for in-context learning of multi-task linear regression. We establish the global convergence of gradient flow under suitable choices of initialization. In addition, we prove that an interesting "task allocation" phenomenon emerges during the gradient flow dynamics, where each attention head focuses on solving a single task of the multi-task model. Specifically, we prove that the gradient flow dynamics can be split into three phases -- a warm-up phase where the loss decreases rather slowly and the attention heads gradually build up their inclination towards individual tasks, an emergence phase where each head selects a single task and the loss rapidly decreases, and a convergence phase where the attention parameters converge to a limit. Furthermore, we prove the optimality of gradient flow in the sense that the limiting model learned by gradient flo
&lt;/p&gt;</description></item><item><title>RLHF&#22312;&#32771;&#34385;&#37096;&#20998;&#35266;&#23519;&#24615;&#26102;&#21487;&#33021;&#23548;&#33268;&#31574;&#30053;&#27450;&#39575;&#24615;&#22320;&#22840;&#22823;&#24615;&#33021;&#25110;&#36807;&#24230;&#36777;&#25252;&#34892;&#20026;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#25968;&#23398;&#26465;&#20214;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#35686;&#21578;&#19981;&#35201;&#30450;&#30446;&#24212;&#29992;RLHF&#22312;&#37096;&#20998;&#21487;&#35266;&#27979;&#24773;&#20917;&#19979;&#12290;</title><link>https://arxiv.org/abs/2402.17747</link><description>&lt;p&gt;
&#24403;&#20320;&#30340;AI&#27450;&#39575;&#20320;&#65306;&#22312;&#22870;&#21169;&#23398;&#20064;&#20013;&#20154;&#31867;&#35780;&#20272;&#32773;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#30340;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
When Your AI Deceives You: Challenges with Partial Observability of Human Evaluators in Reward Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17747
&lt;/p&gt;
&lt;p&gt;
RLHF&#22312;&#32771;&#34385;&#37096;&#20998;&#35266;&#23519;&#24615;&#26102;&#21487;&#33021;&#23548;&#33268;&#31574;&#30053;&#27450;&#39575;&#24615;&#22320;&#22840;&#22823;&#24615;&#33021;&#25110;&#36807;&#24230;&#36777;&#25252;&#34892;&#20026;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#25968;&#23398;&#26465;&#20214;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#35686;&#21578;&#19981;&#35201;&#30450;&#30446;&#24212;&#29992;RLHF&#22312;&#37096;&#20998;&#21487;&#35266;&#27979;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#65288;RLHF&#65289;&#30340;&#36807;&#21435;&#20998;&#26512;&#20551;&#35774;&#20154;&#31867;&#23436;&#20840;&#35266;&#23519;&#21040;&#29615;&#22659;&#12290;&#24403;&#20154;&#31867;&#21453;&#39304;&#20165;&#22522;&#20110;&#37096;&#20998;&#35266;&#23519;&#26102;&#20250;&#21457;&#29983;&#20160;&#20040;&#65311;&#25105;&#20204;&#23545;&#20004;&#31181;&#22833;&#36133;&#24773;&#20917;&#36827;&#34892;&#20102;&#27491;&#24335;&#23450;&#20041;&#65306;&#27450;&#39575;&#21644;&#36807;&#24230;&#36777;&#25252;&#12290;&#36890;&#36807;&#23558;&#20154;&#31867;&#24314;&#27169;&#20026;&#23545;&#36712;&#36857;&#20449;&#24565;&#30340;Boltzmann-&#29702;&#24615;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;RLHF&#20445;&#35777;&#20250;&#23548;&#33268;&#31574;&#30053;&#27450;&#39575;&#24615;&#22320;&#22840;&#22823;&#20854;&#24615;&#33021;&#12289;&#20026;&#20102;&#30041;&#19979;&#21360;&#35937;&#32780;&#36807;&#24230;&#36777;&#25252;&#25110;&#32773;&#20004;&#32773;&#20860;&#32780;&#26377;&#20043;&#30340;&#26465;&#20214;&#12290;&#20026;&#20102;&#24110;&#21161;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25968;&#23398;&#22320;&#21051;&#30011;&#20102;&#29615;&#22659;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#22914;&#20309;&#36716;&#21270;&#20026;&#65288;&#32570;&#20047;&#65289;&#23398;&#21040;&#30340;&#22238;&#25253;&#20989;&#25968;&#20013;&#30340;&#27169;&#31946;&#24615;&#12290;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#32771;&#34385;&#29615;&#22659;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#20351;&#24471;&#22312;&#29702;&#35770;&#19978;&#21487;&#33021;&#24674;&#22797;&#22238;&#25253;&#20989;&#25968;&#21644;&#26368;&#20248;&#31574;&#30053;&#65292;&#32780;&#22312;&#20854;&#20182;&#24773;&#20917;&#19979;&#65292;&#23384;&#22312;&#19981;&#21487;&#20943;&#23569;&#30340;&#27169;&#31946;&#24615;&#12290;&#25105;&#20204;&#35686;&#21578;&#19981;&#35201;&#30450;&#30446;&#24212;&#29992;RLHF&#22312;&#37096;&#20998;&#21487;&#35266;&#27979;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17747v1 Announce Type: cross  Abstract: Past analyses of reinforcement learning from human feedback (RLHF) assume that the human fully observes the environment. What happens when human feedback is based only on partial observations? We formally define two failure cases: deception and overjustification. Modeling the human as Boltzmann-rational w.r.t. a belief over trajectories, we prove conditions under which RLHF is guaranteed to result in policies that deceptively inflate their performance, overjustify their behavior to make an impression, or both. To help address these issues, we mathematically characterize how partial observability of the environment translates into (lack of) ambiguity in the learned return function. In some cases, accounting for partial observability makes it theoretically possible to recover the return function and thus the optimal policy, while in other cases, there is irreducible ambiguity. We caution against blindly applying RLHF in partially observa
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#34920;&#26126;&#23545;&#20110;&#20855;&#26377;&#32447;&#24615;&#21487;&#20998;&#25968;&#25454;&#30340;&#36923;&#36753;&#22238;&#24402;&#38382;&#39064;&#65292;&#35774;&#32622;&#19968;&#20010;&#24658;&#23450;&#20294;&#36739;&#22823;&#30340;&#27493;&#38271;&#65292;&#22312;&#21021;&#22987;&#38663;&#33633;&#21518;&#21487;&#20197;&#23454;&#29616;&#36739;&#24555;&#30340;&#25910;&#25947;&#65292;&#24182;&#19988;&#22312;&#19968;&#23450;&#27493;&#39588;&#21518;&#21487;&#20197;&#36798;&#21040;&#21152;&#36895;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#36825;&#31181;&#26041;&#27861;&#26080;&#38656;&#21160;&#37327;&#25110;&#21464;&#27493;&#38271;&#35843;&#24230;&#22120;&#12290;</title><link>https://arxiv.org/abs/2402.15926</link><description>&lt;p&gt;
&#36923;&#36753;&#22238;&#24402;&#30340;&#22823;&#27493;&#26799;&#24230;&#19979;&#38477;&#65306;&#25439;&#22833;&#30340;&#38750;&#21333;&#35843;&#24615;&#25552;&#39640;&#20102;&#20248;&#21270;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;
Large Stepsize Gradient Descent for Logistic Loss: Non-Monotonicity of the Loss Improves Optimization Efficiency
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15926
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#34920;&#26126;&#23545;&#20110;&#20855;&#26377;&#32447;&#24615;&#21487;&#20998;&#25968;&#25454;&#30340;&#36923;&#36753;&#22238;&#24402;&#38382;&#39064;&#65292;&#35774;&#32622;&#19968;&#20010;&#24658;&#23450;&#20294;&#36739;&#22823;&#30340;&#27493;&#38271;&#65292;&#22312;&#21021;&#22987;&#38663;&#33633;&#21518;&#21487;&#20197;&#23454;&#29616;&#36739;&#24555;&#30340;&#25910;&#25947;&#65292;&#24182;&#19988;&#22312;&#19968;&#23450;&#27493;&#39588;&#21518;&#21487;&#20197;&#36798;&#21040;&#21152;&#36895;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#36825;&#31181;&#26041;&#27861;&#26080;&#38656;&#21160;&#37327;&#25110;&#21464;&#27493;&#38271;&#35843;&#24230;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#19982;&#20855;&#26377;&#32447;&#24615;&#21487;&#20998;&#25968;&#25454;&#30340;&#36923;&#36753;&#22238;&#24402;&#32467;&#21512;&#20351;&#29992;&#30340;&#24658;&#23450;&#27493;&#38271;&#24773;&#20917;&#65292;&#20854;&#20013;&#24658;&#23450;&#27493;&#38271;$\eta$&#38750;&#24120;&#22823;&#65292;&#20197;&#33267;&#20110;&#25439;&#22833;&#22312;&#21021;&#22987;&#38454;&#27573;&#20250;&#38663;&#33633;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;GD&#22312;$\mathcal{O}(\eta)$&#27493;&#20869;&#36805;&#36895;&#36864;&#20986;&#36825;&#31181;&#21021;&#22987;&#38663;&#33633;&#38454;&#27573;&#65292;&#24182;&#22312;&#39069;&#22806;&#30340;$t$&#27493;&#20043;&#21518;&#23454;&#29616;&#20102;&#19968;&#20010;$\tilde{\mathcal{O}}(1 / (\eta t) )$&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#24847;&#21619;&#30528;&#65292;&#32473;&#23450;$T$&#27493;&#30340;&#39044;&#31639;&#65292;&#20351;&#29992;&#31215;&#26497;&#30340;&#27493;&#38271;$\eta:= \Theta( T)$&#65292;&#26080;&#38656;&#20351;&#29992;&#20219;&#20309;&#21160;&#37327;&#25110;&#21464;&#27493;&#38271;&#35843;&#24230;&#22120;&#65292;GD&#21487;&#20197;&#23454;&#29616;&#19968;&#20010;$\tilde{\mathcal{O}}(1/T^2)$&#30340;&#21152;&#36895;&#25439;&#22833;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#25216;&#26415;&#22810;&#25165;&#22810;&#33402;&#65292;&#36824;&#21487;&#20197;&#22788;&#29702;&#19968;&#33324;&#20998;&#31867;&#25439;&#22833;&#20989;&#25968;&#65288;&#20854;&#20013;&#38656;&#35201;&#25351;&#25968;&#23614;&#37096;&#26469;&#23454;&#29616;$\tilde{\mathcal{O}}(1/T^2)$&#30340;&#21152;&#36895;&#65289;&#12289;&#31070;&#32463;&#20999;&#32447;&#26680;&#21306;&#22495;&#30340;&#38750;&#32447;&#24615;&#39044;&#27979;&#22120;&#65292;&#20197;&#21450;&#20855;&#26377;&#22823;&#27493;&#38271;&#30340;&#22312;&#32447;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15926v1 Announce Type: new  Abstract: We consider gradient descent (GD) with a constant stepsize applied to logistic regression with linearly separable data, where the constant stepsize $\eta$ is so large that the loss initially oscillates. We show that GD exits this initial oscillatory phase rapidly -- in $\mathcal{O}(\eta)$ steps -- and subsequently achieves an $\tilde{\mathcal{O}}(1 / (\eta t) )$ convergence rate after $t$ additional steps. Our results imply that, given a budget of $T$ steps, GD can achieve an accelerated loss of $\tilde{\mathcal{O}}(1/T^2)$ with an aggressive stepsize $\eta:= \Theta( T)$, without any use of momentum or variable stepsize schedulers. Our proof technique is versatile and also handles general classification loss functions (where exponential tails are needed for the $\tilde{\mathcal{O}}(1/T^2)$ acceleration), nonlinear predictors in the neural tangent kernel regime, and online stochastic gradient descent (SGD) with a large stepsize, under sui
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36229;&#20960;&#20309;&#20284;&#28982;&#35299;&#20915;&#20272;&#35745;&#31163;&#25955;&#20998;&#24067;&#25361;&#25112;&#30340;&#26032;&#26041;&#27861;&#65292;&#21363;&#20351;&#23384;&#22312;&#20005;&#37325;&#30340;&#27424;&#37319;&#26679;&#65292;&#20063;&#33021;&#23454;&#29616;&#65292;&#19988;&#22312;&#20154;&#21475;&#35268;&#27169;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#21644;&#23398;&#20064;&#33021;&#21147;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.14220</link><description>&lt;p&gt;
&#20351;&#29992;&#36229;&#20960;&#20309;&#20998;&#24067;&#20272;&#35745;&#26410;&#30693;&#20154;&#21475;&#35268;&#27169;
&lt;/p&gt;
&lt;p&gt;
Estimating Unknown Population Sizes Using the Hypergeometric Distribution
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14220
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36229;&#20960;&#20309;&#20284;&#28982;&#35299;&#20915;&#20272;&#35745;&#31163;&#25955;&#20998;&#24067;&#25361;&#25112;&#30340;&#26032;&#26041;&#27861;&#65292;&#21363;&#20351;&#23384;&#22312;&#20005;&#37325;&#30340;&#27424;&#37319;&#26679;&#65292;&#20063;&#33021;&#23454;&#29616;&#65292;&#19988;&#22312;&#20154;&#21475;&#35268;&#27169;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#21644;&#23398;&#20064;&#33021;&#21147;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20803;&#36229;&#20960;&#20309;&#20998;&#24067;&#25551;&#36848;&#20174;&#21010;&#20998;&#20026;&#22810;&#20010;&#31867;&#21035;&#30340;&#31163;&#25955;&#20803;&#32032;&#24635;&#20307;&#20013;&#36827;&#34892;&#26080;&#25918;&#22238;&#25277;&#26679;&#12290;&#22312;&#25991;&#29486;&#20013;&#23384;&#22312;&#30340;&#19968;&#20010;&#31354;&#30333;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#20272;&#35745;&#31163;&#25955;&#20998;&#24067;&#30340;&#25361;&#25112;&#65292;&#24403;&#24635;&#20307;&#35268;&#27169;&#21644;&#20854;&#26500;&#25104;&#31867;&#21035;&#30340;&#22823;&#23567;&#22343;&#26410;&#30693;&#26102;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36229;&#20960;&#20309;&#20284;&#28982;&#35299;&#20915;&#36825;&#19968;&#20272;&#35745;&#25361;&#25112;&#30340;&#26032;&#26041;&#27861;&#65292;&#21363;&#20351;&#23384;&#22312;&#20005;&#37325;&#30340;&#27424;&#37319;&#26679;&#20063;&#33021;&#23454;&#29616;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#37322;&#19968;&#20010;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#65292;&#20854;&#20013;&#22320;&#38754;&#30495;&#23454;&#20540;&#26159;&#26377;&#26465;&#20214;&#30340;&#36830;&#32493;&#28508;&#21464;&#37327;&#28151;&#21512;&#20998;&#24067;&#65292;&#27604;&#22914;&#21327;&#21516;&#36807;&#28388;&#65292;&#20351;&#29992;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#26694;&#26550;&#12290;&#23454;&#35777;&#25968;&#25454;&#27169;&#25311;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20154;&#21475;&#35268;&#27169;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#21644;&#23398;&#20064;&#33021;&#21147;&#26041;&#38754;&#22343;&#20248;&#20110;&#20854;&#20182;&#29992;&#20110;&#24314;&#27169;&#35745;&#25968;&#25968;&#25454;&#30340;&#20284;&#28982;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14220v1 Announce Type: new  Abstract: The multivariate hypergeometric distribution describes sampling without replacement from a discrete population of elements divided into multiple categories. Addressing a gap in the literature, we tackle the challenge of estimating discrete distributions when both the total population size and the sizes of its constituent categories are unknown. Here, we propose a novel solution using the hypergeometric likelihood to solve this estimation challenge, even in the presence of severe under-sampling. We develop our approach to account for a data generating process where the ground-truth is a mixture of distributions conditional on a continuous latent variable, such as with collaborative filtering, using the variational autoencoder framework. Empirical data simulation demonstrates that our method outperforms other likelihood functions used to model count data, both in terms of accuracy of population size estimate and in its ability to learn an 
&lt;/p&gt;</description></item><item><title>&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23398;&#20064;&#36755;&#20986;&#23618;&#27979;&#35797;&#35823;&#24046;&#30340;&#20005;&#26684;&#28176;&#36817;&#29305;&#24615;&#65292;&#24182;&#23545;&#20351;&#29992;&#39640;&#26031;&#24425;&#34425;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#23398;&#20064;&#30340;&#38382;&#39064;&#20570;&#20986;&#20102;&#37325;&#35201;&#36129;&#29486;</title><link>https://arxiv.org/abs/2402.13999</link><description>&lt;p&gt;
&#28145;&#24230;&#32467;&#26500;&#21270;&#65288;&#38543;&#26426;&#65289;&#29305;&#24449;&#23398;&#20064;&#30340;&#28176;&#36817;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Asymptotics of Learning with Deep Structured (Random) Features
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13999
&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23398;&#20064;&#36755;&#20986;&#23618;&#27979;&#35797;&#35823;&#24046;&#30340;&#20005;&#26684;&#28176;&#36817;&#29305;&#24615;&#65292;&#24182;&#23545;&#20351;&#29992;&#39640;&#26031;&#24425;&#34425;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#23398;&#20064;&#30340;&#38382;&#39064;&#20570;&#20986;&#20102;&#37325;&#35201;&#36129;&#29486;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#19968;&#22823;&#31867;&#29305;&#24449;&#26144;&#23556;&#65292;&#25105;&#20204;&#22312;&#36755;&#20837;&#32500;&#24230;&#12289;&#38544;&#34255;&#23618;&#23485;&#24230;&#21644;&#35757;&#32451;&#26679;&#26412;&#25968;&#37327;&#25104;&#27604;&#20363;&#22686;&#38271;&#30340;&#39640;&#32500;&#26497;&#38480;&#19979;&#65292;&#25552;&#20379;&#20102;&#19982;&#23398;&#20064;&#36755;&#20986;&#23618;&#30456;&#20851;&#30340;&#27979;&#35797;&#35823;&#24046;&#30340;&#20005;&#26684;&#28176;&#36817;&#29305;&#24615;&#21051;&#30011;&#12290;&#36825;&#19968;&#29305;&#24449;&#20197;&#29305;&#24449;&#30340;&#24635;&#20307;&#21327;&#26041;&#24046;&#20026;&#22522;&#30784;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#37096;&#20998;&#21463;&#21040;&#20351;&#29992;&#39640;&#26031;&#24425;&#34425;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#23398;&#20064;&#30340;&#38382;&#39064;&#30340;&#21551;&#21457;&#65292;&#21363;&#20855;&#26377;&#38543;&#26426;&#20294;&#32467;&#26500;&#21270;&#26435;&#37325;&#30340;&#28145;&#23618;&#38750;&#32447;&#24615;&#20840;&#36830;&#25509;&#32593;&#32476;&#65292;&#20854;&#25353;&#34892;&#30340;&#21327;&#26041;&#24046;&#36827;&#19968;&#27493;&#20801;&#35768;&#20381;&#36182;&#20110;&#20043;&#21069;&#23618;&#30340;&#26435;&#37325;&#12290;&#23545;&#20110;&#36825;&#26679;&#30340;&#32593;&#32476;&#65292;&#25105;&#20204;&#36824;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#20197;&#26435;&#37325;&#30697;&#38453;&#20026;&#22522;&#30784;&#30340;&#29305;&#24449;&#21327;&#26041;&#24046;&#30340;&#38381;&#21512;&#24418;&#24335;&#20844;&#24335;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#21457;&#29616;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#33021;&#22815;&#25429;&#25417;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#20855;&#26377;&#26377;&#38480;&#23485;&#24230;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#21040;&#30340;&#29305;&#24449;&#26144;&#23556;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13999v1 Announce Type: cross  Abstract: For a large class of feature maps we provide a tight asymptotic characterisation of the test error associated with learning the readout layer, in the high-dimensional limit where the input dimension, hidden layer widths, and number of training samples are proportionally large. This characterization is formulated in terms of the population covariance of the features. Our work is partially motivated by the problem of learning with Gaussian rainbow neural networks, namely deep non-linear fully-connected networks with random but structured weights, whose row-wise covariances are further allowed to depend on the weights of previous layers. For such networks we also derive a closed-form formula for the feature covariance in terms of the weight matrices. We further find that in some cases our results can capture feature maps learned by deep, finite-width neural networks trained under gradient descent.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#26032;&#22411;&#20302;&#31209;&#30697;&#38453;&#20272;&#35745;&#26041;&#27861;LowPopArt&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#37327;B(Q)&#25552;&#20379;&#26356;&#32039;&#23494;&#30340;&#24674;&#22797;&#20445;&#35777;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23454;&#39564;&#35774;&#35745;&#26631;&#20934;&#65292;&#20197;&#21450;&#20004;&#31181;&#36866;&#29992;&#20110;&#19968;&#33324;Arm&#38598;&#30340;&#20302;&#31209;&#32447;&#24615;&#36172;&#21338;&#31639;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.11156</link><description>&lt;p&gt;
&#39640;&#25928;&#30340;&#20302;&#31209;&#30697;&#38453;&#20272;&#35745;&#12289;&#23454;&#39564;&#35774;&#35745;&#21644;&#22522;&#20110;Arm&#38598;&#30340;&#20302;&#31209;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
Efficient Low-Rank Matrix Estimation, Experimental Design, and Arm-Set-Dependent Low-Rank Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11156
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#26032;&#22411;&#20302;&#31209;&#30697;&#38453;&#20272;&#35745;&#26041;&#27861;LowPopArt&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#37327;B(Q)&#25552;&#20379;&#26356;&#32039;&#23494;&#30340;&#24674;&#22797;&#20445;&#35777;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23454;&#39564;&#35774;&#35745;&#26631;&#20934;&#65292;&#20197;&#21450;&#20004;&#31181;&#36866;&#29992;&#20110;&#19968;&#33324;Arm&#38598;&#30340;&#20302;&#31209;&#32447;&#24615;&#36172;&#21338;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20302;&#31209;&#30697;&#38453;&#36857;&#22238;&#24402;&#21644;&#30456;&#20851;&#30340;&#20302;&#31209;&#30697;&#38453;&#36172;&#21338;&#38382;&#39064;&#12290;&#20551;&#35774;&#21487;&#20197;&#35775;&#38382;&#21327;&#21464;&#37327;&#30340;&#20998;&#24067;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LowPopArt&#30340;&#26032;&#22411;&#20302;&#31209;&#30697;&#38453;&#20272;&#35745;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#20854;&#20381;&#36182;&#20110;&#19968;&#20010;&#26032;&#39062;&#25968;&#37327;B(Q)&#30340;&#24674;&#22797;&#20445;&#35777;&#65292;&#35813;&#25968;&#37327;&#34920;&#24449;&#20102;&#38382;&#39064;&#30340;&#38590;&#24230;&#65292;&#20854;&#20013;Q&#26159;&#27979;&#37327;&#20998;&#24067;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20960;&#20010;&#38382;&#39064;&#20013;&#21487;&#20197;&#25552;&#20379;&#27604;&#32463;&#20856;&#30340;&#26680;&#33539;&#25968;&#24809;&#32602;&#26368;&#23567;&#20108;&#20056;&#27861;&#65288;Koltchinskii&#31561;&#20154;&#65292;2011&#65289;&#26356;&#32039;&#23494;&#30340;&#24674;&#22797;&#20445;&#35777;&#12290;&#20026;&#20102;&#22312;&#20174;&#20219;&#24847;&#32473;&#23450;&#30340;&#27979;&#37327;&#38598;&#21512;A&#20013;&#36827;&#34892;&#26377;&#38480;&#27979;&#37327;&#30340;&#24773;&#20917;&#19979;&#25191;&#34892;&#39640;&#25928;&#20272;&#35745;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23454;&#39564;&#35774;&#35745;&#26631;&#20934;&#65292;&#35813;&#26631;&#20934;&#20197;&#35745;&#31639;&#25928;&#29575;&#26368;&#23567;&#21270;B(Q)&#12290;&#25105;&#20204;&#21033;&#29992;&#25105;&#20204;&#30340;&#26032;&#39062;&#20272;&#35745;&#22120;&#21644;&#23454;&#39564;&#35774;&#35745;&#25512;&#23548;&#20102;&#20004;&#31181;&#36866;&#29992;&#20110;&#19968;&#33324;Arm&#38598;&#30340;&#20302;&#31209;&#32447;&#24615;&#36172;&#21338;&#31639;&#27861;&#65292;&#20854;&#20139;&#26377;&#25913;&#36827;&#30340;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11156v1 Announce Type: cross  Abstract: We study low-rank matrix trace regression and the related problem of low-rank matrix bandits. Assuming access to the distribution of the covariates, we propose a novel low-rank matrix estimation method called LowPopArt and provide its recovery guarantee that depends on a novel quantity denoted by B(Q) that characterizes the hardness of the problem, where Q is the covariance matrix of the measurement distribution. We show that our method can provide tighter recovery guarantees than classical nuclear norm penalized least squares (Koltchinskii et al., 2011) in several problems. To perform efficient estimation with a limited number of measurements from an arbitrarily given measurement set A, we also propose a novel experimental design criterion that minimizes B(Q) with computational efficiency. We leverage our novel estimator and design of experiments to derive two low-rank linear bandit algorithms for general arm sets that enjoy improved 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22810;&#31867;&#21035;&#39044;&#27979;&#38382;&#39064;&#20013;&#22810;&#26679;&#21270;&#30340;&#25237;&#24433;&#24179;&#28369;&#26657;&#20934;&#27010;&#24565;&#65292;&#24182;&#19988;&#32473;&#20986;&#20102;&#22810;&#39033;&#24335;&#26102;&#38388;&#22797;&#26434;&#24230;&#30340;&#37325;&#26032;&#26657;&#20934;&#31639;&#27861;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#35745;&#31639;&#25928;&#29575;&#21644;&#24378;&#22823;&#30340;&#39044;&#27979;&#20445;&#35777;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;</title><link>https://arxiv.org/abs/2402.07821</link><description>&lt;p&gt;
&#35770;&#35745;&#31639;&#26377;&#25928;&#30340;&#22810;&#31867;&#21035;&#26657;&#20934;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
On Computationally Efficient Multi-Class Calibration
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07821
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22810;&#31867;&#21035;&#39044;&#27979;&#38382;&#39064;&#20013;&#22810;&#26679;&#21270;&#30340;&#25237;&#24433;&#24179;&#28369;&#26657;&#20934;&#27010;&#24565;&#65292;&#24182;&#19988;&#32473;&#20986;&#20102;&#22810;&#39033;&#24335;&#26102;&#38388;&#22797;&#26434;&#24230;&#30340;&#37325;&#26032;&#26657;&#20934;&#31639;&#27861;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#35745;&#31639;&#25928;&#29575;&#21644;&#24378;&#22823;&#30340;&#39044;&#27979;&#20445;&#35777;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32771;&#34385;&#19968;&#20010;&#22810;&#31867;&#21035;&#26631;&#35760;&#38382;&#39064;&#65292;&#20854;&#20013;&#26631;&#35760;&#21487;&#20197;&#22312;[1,k]&#33539;&#22260;&#20869;&#21462;&#20540;&#65292;&#32780;&#39044;&#27979;&#22120;&#39044;&#27979;&#30340;&#26159;&#26631;&#35760;&#30340;&#20998;&#24067;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20197;&#19979;&#22522;&#30784;&#38382;&#39064;&#65306;&#26159;&#21542;&#23384;&#22312;&#22810;&#31867;&#21035;&#26657;&#20934;&#30340;&#27010;&#24565;&#65292;&#21487;&#20197;&#32473;&#20986;&#23545;&#26377;&#24847;&#20041;&#30340;&#39044;&#27979;&#30340;&#24378;&#22823;&#20445;&#35777;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#19979;&#23454;&#29616;&#65311;&#20808;&#21069;&#30340;&#26657;&#20934;&#27010;&#24565;&#22312;&#35745;&#31639;&#25928;&#29575;&#21644;&#34920;&#36798;&#33021;&#21147;&#20043;&#38388;&#23384;&#22312;&#30528;&#26435;&#34913;&#65306;&#23427;&#20204;&#35201;&#20040;&#22312;k&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#19978;&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#65292;&#35201;&#20040;&#38656;&#35201;&#27714;&#35299;&#35745;&#31639;&#38590;&#39064;&#65292;&#35201;&#20040;&#32473;&#20986;&#30340;&#20445;&#35777;&#30456;&#24403;&#24369;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#23454;&#29616;&#25152;&#26377;&#36825;&#20123;&#26399;&#26395;&#30340;&#26657;&#20934;&#27010;&#24565;&#65306;&#25105;&#20204;&#22312;&#22810;&#31867;&#21035;&#39044;&#27979;&#20013;&#21046;&#23450;&#20102;&#19968;&#20010;&#31283;&#20581;&#30340;&#25237;&#24433;&#24179;&#28369;&#26657;&#20934;&#27010;&#24565;&#65292;&#24182;&#32473;&#20986;&#20102;&#26032;&#30340;&#37325;&#26032;&#26657;&#20934;&#31639;&#27861;&#65292;&#20197;&#22312;&#36825;&#20010;&#23450;&#20041;&#19979;&#20197;&#22810;&#39033;&#24335;&#26102;&#38388;&#22797;&#26434;&#24230;&#26657;&#20934;&#39044;&#27979;&#22120;&#12290;&#25237;&#24433;&#24179;&#28369;&#26657;&#20934;&#20026;&#22810;&#31867;&#21035;&#39044;&#27979;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consider a multi-class labelling problem, where the labels can take values in $[k]$, and a predictor predicts a distribution over the labels. In this work, we study the following foundational question: Are there notions of multi-class calibration that give strong guarantees of meaningful predictions and can be achieved in time and sample complexities polynomial in $k$? Prior notions of calibration exhibit a tradeoff between computational efficiency and expressivity: they either suffer from having sample complexity exponential in $k$, or needing to solve computationally intractable problems, or give rather weak guarantees.   Our main contribution is a notion of calibration that achieves all these desiderata: we formulate a robust notion of projected smooth calibration for multi-class predictions, and give new recalibration algorithms for efficiently calibrating predictors under this definition with complexity polynomial in $k$. Projected smooth calibration gives strong guarantees for al
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#36335;&#24452;&#31215;&#20998;&#26041;&#27861;&#25506;&#32034;&#20102;&#36830;&#32493;&#26102;&#38388;&#38543;&#26426;&#26799;&#24230;&#27969;&#21160;&#21147;&#23398;&#20013;&#30340;&#27979;&#35797;&#39118;&#38505;&#65292;&#24182;&#22312;&#23567;&#23398;&#20064;&#29575;&#24773;&#20917;&#19979;&#32473;&#20986;&#20102;&#35745;&#31639;&#32431;&#26799;&#24230;&#27969;&#21160;&#21644;&#38543;&#26426;&#26799;&#24230;&#27969;&#21160;&#30340;&#27979;&#35797;&#39118;&#38505;&#26354;&#32447;&#20043;&#38388;&#24046;&#24322;&#30340;&#19968;&#33324;&#20844;&#24335;&#12290;&#36890;&#36807;&#24212;&#29992;&#20110;&#19968;&#20010;&#24369;&#29305;&#24449;&#27169;&#22411;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#38543;&#26426;&#39033;&#23545;&#21160;&#21147;&#23398;&#30340;&#20462;&#27491;&#25928;&#26524;&#65292;&#24182;&#19982;&#31163;&#25955;&#26102;&#38388;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#27169;&#25311;&#32467;&#26524;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#32467;&#26524;&#26174;&#31034;&#20986;&#19968;&#33268;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.07626</link><description>&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#27969;&#21160;&#21147;&#23398;&#20013;&#30340;&#27979;&#35797;&#39118;&#38505;&#21450;&#20854;&#24369;&#29305;&#24449;&#30340;&#31934;&#30830;&#35299;
&lt;/p&gt;
&lt;p&gt;
Stochastic Gradient Flow Dynamics of Test Risk and its Exact Solution for Weak Features
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07626
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#36335;&#24452;&#31215;&#20998;&#26041;&#27861;&#25506;&#32034;&#20102;&#36830;&#32493;&#26102;&#38388;&#38543;&#26426;&#26799;&#24230;&#27969;&#21160;&#21147;&#23398;&#20013;&#30340;&#27979;&#35797;&#39118;&#38505;&#65292;&#24182;&#22312;&#23567;&#23398;&#20064;&#29575;&#24773;&#20917;&#19979;&#32473;&#20986;&#20102;&#35745;&#31639;&#32431;&#26799;&#24230;&#27969;&#21160;&#21644;&#38543;&#26426;&#26799;&#24230;&#27969;&#21160;&#30340;&#27979;&#35797;&#39118;&#38505;&#26354;&#32447;&#20043;&#38388;&#24046;&#24322;&#30340;&#19968;&#33324;&#20844;&#24335;&#12290;&#36890;&#36807;&#24212;&#29992;&#20110;&#19968;&#20010;&#24369;&#29305;&#24449;&#27169;&#22411;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#38543;&#26426;&#39033;&#23545;&#21160;&#21147;&#23398;&#30340;&#20462;&#27491;&#25928;&#26524;&#65292;&#24182;&#19982;&#31163;&#25955;&#26102;&#38388;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#27169;&#25311;&#32467;&#26524;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#32467;&#26524;&#26174;&#31034;&#20986;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#23398;&#20064;&#29702;&#35770;&#20013;&#36830;&#32493;&#26102;&#38388;&#38543;&#26426;&#26799;&#24230;&#27969;&#21160;&#21147;&#23398;&#30340;&#27979;&#35797;&#39118;&#38505;&#12290;&#21033;&#29992;&#36335;&#24452;&#31215;&#20998;&#20844;&#24335;&#65292;&#22312;&#23567;&#23398;&#20064;&#29575;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#20379;&#20102;&#35745;&#31639;&#32431;&#26799;&#24230;&#27969;&#21160;&#21644;&#38543;&#26426;&#26799;&#24230;&#27969;&#21160;&#30340;&#27979;&#35797;&#39118;&#38505;&#26354;&#32447;&#20043;&#38388;&#24046;&#24322;&#30340;&#19968;&#33324;&#20844;&#24335;&#12290;&#25105;&#20204;&#23558;&#36825;&#19968;&#36890;&#29992;&#29702;&#35770;&#24212;&#29992;&#21040;&#19968;&#20010;&#31616;&#21333;&#30340;&#24369;&#29305;&#24449;&#27169;&#22411;&#20013;&#65292;&#35813;&#27169;&#22411;&#23637;&#31034;&#20102;&#21452;&#23792;&#29616;&#35937;&#65292;&#24182;&#26126;&#30830;&#35745;&#31639;&#20102;&#21160;&#21147;&#23398;&#20013;&#22686;&#21152;&#30340;&#38543;&#26426;&#39033;&#38543;&#26102;&#38388;&#21644;&#27169;&#22411;&#21442;&#25968;&#30340;&#20462;&#27491;&#12290;&#20998;&#26512;&#32467;&#26524;&#19982;&#31163;&#25955;&#26102;&#38388;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#27169;&#25311;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#26174;&#31034;&#20986;&#33391;&#22909;&#30340;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the test risk of continuous-time stochastic gradient flow dynamics in learning theory. Using a path integral formulation we provide, in the regime of a small learning rate, a general formula for computing the difference between test risk curves of pure gradient and stochastic gradient flows. We apply the general theory to a simple model of weak features, which displays the double descent phenomenon, and explicitly compute the corrections brought about by the added stochastic term in the dynamics, as a function of time and model parameters. The analytical results are compared to simulations of discrete-time stochastic gradient descent and show good agreement.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#32447;&#24615;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#20013;&#26410;&#30693;&#22122;&#22768;&#27700;&#24179;&#30340;&#33258;&#36866;&#24212;&#32622;&#20449;&#21306;&#38388;&#65292;&#19982;&#24050;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#22312;&#32500;&#24230;&#36739;&#22823;&#26102;&#20855;&#26377;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;&#27492;&#22806;&#65292;&#38024;&#23545;&#26377;&#30028;&#22870;&#21169;&#65292;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#24046;&#33258;&#36866;&#24212;&#32622;&#20449;&#21306;&#38388;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#25968;&#20540;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.07341</link><description>&lt;p&gt;
&#23545;&#32447;&#24615;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#30340;&#22122;&#22768;&#33258;&#36866;&#24212;&#32622;&#20449;&#21306;&#38388;&#21450;&#20854;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Noise-Adaptive Confidence Sets for Linear Bandits and Application to Bayesian Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07341
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#32447;&#24615;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#20013;&#26410;&#30693;&#22122;&#22768;&#27700;&#24179;&#30340;&#33258;&#36866;&#24212;&#32622;&#20449;&#21306;&#38388;&#65292;&#19982;&#24050;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#22312;&#32500;&#24230;&#36739;&#22823;&#26102;&#20855;&#26377;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;&#27492;&#22806;&#65292;&#38024;&#23545;&#26377;&#30028;&#22870;&#21169;&#65292;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#24046;&#33258;&#36866;&#24212;&#32622;&#20449;&#21306;&#38388;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#25968;&#20540;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24207;&#36143;&#20915;&#31574;&#20013;&#65292;&#36866;&#24212;&#26410;&#30693;&#22122;&#22768;&#27700;&#24179;&#26159;&#19968;&#20010;&#38750;&#24120;&#37325;&#35201;&#20294;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#65292;&#22240;&#20026;&#26377;&#25928;&#30340;&#25506;&#32034;&#36890;&#24120;&#38656;&#35201;&#23545;&#22122;&#22768;&#27700;&#24179;&#26377;&#19968;&#23450;&#30340;&#20102;&#35299;&#65292;&#32780;&#22122;&#22768;&#27700;&#24179;&#36890;&#24120;&#21482;&#33021;&#31895;&#30053;&#22320;&#25351;&#23450;&#12290;&#25105;&#20204;&#22312;&#32447;&#24615;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#20027;&#35201;&#26377;&#20004;&#26041;&#38754;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#35813;&#32622;&#20449;&#21306;&#38388;&#22312;&#26410;&#30693;&#30340;&#20122;&#39640;&#26031;&#21442;&#25968;&#963;_*^2&#19978;&#26159;&#8220;&#21322;&#33258;&#36866;&#24212;&#8221;&#30340;&#65292;&#24847;&#21619;&#30528;&#65288;&#24402;&#19968;&#21270;&#30340;&#65289;&#32622;&#20449;&#23485;&#24230;&#19982;&#8730;&#65288;d&#963;_*^2 + &#963;_0^2&#65289;&#25104;&#27491;&#27604;&#65292;&#20854;&#20013;d&#20026;&#32500;&#24230;&#65292;&#963;_0^2&#20026;&#25351;&#23450;&#30340;&#65288;&#24050;&#30693;&#65289;&#20122;&#39640;&#26031;&#21442;&#25968;&#65292;&#20854;&#20540;&#21487;&#33021;&#27604;&#963;_*^2&#22823;&#24471;&#22810;&#12290;&#30456;&#27604;&#20110;Abbasi-Yadkori&#31561;&#20154;&#65288;2011&#65289;&#30340;&#26631;&#20934;&#32622;&#20449;&#21306;&#38388;&#30340;&#8730;&#65288;d&#963;_0^2&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#26174;&#33879;&#30340;&#25913;&#36827;&#65292;&#29305;&#21035;&#26159;&#24403;d&#36739;&#22823;&#26102;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#23548;&#33268;&#20102;&#32447;&#24615;&#24378;&#21270;&#23398;&#20064;&#20013;&#25913;&#36827;&#30340;&#21518;&#24724;&#36793;&#30028;&#12290;&#20854;&#27425;&#65292;&#23545;&#20110;&#26377;&#30028;&#22870;&#21169;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#24046;&#33258;&#36866;&#24212;&#32622;&#20449;&#21306;&#38388;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#25968;&#20540;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adapting to a priori unknown noise level is a very important but challenging problem in sequential decision-making as efficient exploration typically requires knowledge of the noise level, which is often loosely specified. We report significant progress in addressing this issue in linear bandits in two respects. First, we propose a novel confidence set that is `semi-adaptive' to the unknown sub-Gaussian parameter $\sigma_*^2$ in the sense that the (normalized) confidence width scales with $\sqrt{d\sigma_*^2 + \sigma_0^2}$ where $d$ is the dimension and $\sigma_0^2$ is the specified sub-Gaussian parameter (known) that can be much larger than $\sigma_*^2$. This is a significant improvement over $\sqrt{d\sigma_0^2}$ of the standard confidence set of Abbasi-Yadkori et al. (2011), especially when $d$ is large. We show that this leads to an improved regret bound in linear bandits. Second, for bounded rewards, we propose a novel variance-adaptive confidence set that has a much improved numeri
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#29983;&#25104;&#27169;&#22411;&#35757;&#32451;&#26102;&#21487;&#33021;&#20986;&#29616;&#30340;&#33258;&#25105;&#28040;&#32791;&#24490;&#29615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24341;&#20837;&#29702;&#24819;&#30340;&#20462;&#27491;&#20989;&#25968;&#26469;&#31283;&#23450;&#35757;&#32451;&#30340;&#26041;&#27861;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#33258;&#25105;&#20462;&#27491;&#20989;&#25968;&#26469;&#36817;&#20284;&#29702;&#24819;&#30340;&#20462;&#27491;&#20989;&#25968;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.07087</link><description>&lt;p&gt;
&#33258;&#25105;&#32416;&#27491;&#33258;&#25105;&#28040;&#32791;&#24490;&#29615;&#29992;&#20110;&#29983;&#25104;&#27169;&#22411;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Self-Correcting Self-Consuming Loops for Generative Model Training
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07087
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#29983;&#25104;&#27169;&#22411;&#35757;&#32451;&#26102;&#21487;&#33021;&#20986;&#29616;&#30340;&#33258;&#25105;&#28040;&#32791;&#24490;&#29615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24341;&#20837;&#29702;&#24819;&#30340;&#20462;&#27491;&#20989;&#25968;&#26469;&#31283;&#23450;&#35757;&#32451;&#30340;&#26041;&#27861;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#33258;&#25105;&#20462;&#27491;&#20989;&#25968;&#26469;&#36817;&#20284;&#29702;&#24819;&#30340;&#20462;&#27491;&#20989;&#25968;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#21512;&#25104;&#25968;&#25454;&#22312;&#20114;&#32852;&#32593;&#19978;&#30340;&#36136;&#37327;&#36234;&#26469;&#36234;&#39640;&#20197;&#21450;&#25968;&#37327;&#19981;&#26029;&#22686;&#21152;&#65292;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#36234;&#26469;&#36234;&#22810;&#22320;&#22312;&#20154;&#24037;&#21644;&#26426;&#22120;&#29983;&#25104;&#30340;&#25968;&#25454;&#30340;&#28151;&#21512;&#19978;&#36827;&#34892;&#35757;&#32451;&#12290;&#23613;&#31649;&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#34920;&#24449;&#23398;&#20064;&#30340;&#25104;&#21151;&#26696;&#20363;&#26377;&#24456;&#22810;&#65292;&#20294;&#26159;&#22312;&#29983;&#25104;&#27169;&#22411;&#35757;&#32451;&#20013;&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#20250;&#20135;&#29983;"&#33258;&#25105;&#28040;&#32791;&#24490;&#29615;"&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#35757;&#32451;&#19981;&#31283;&#23450;&#29978;&#33267;&#23849;&#28291;&#65292;&#38500;&#38750;&#28385;&#36275;&#26576;&#20123;&#26465;&#20214;&#12290;&#25105;&#20204;&#30340;&#35770;&#25991;&#26088;&#22312;&#31283;&#23450;&#33258;&#25105;&#28040;&#32791;&#30340;&#29983;&#25104;&#27169;&#22411;&#35757;&#32451;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#20010;&#29702;&#24819;&#30340;&#20462;&#27491;&#20989;&#25968;&#65292;&#23558;&#25968;&#25454;&#28857;&#26144;&#23556;&#20026;&#26356;&#26377;&#21487;&#33021;&#26469;&#33258;&#30495;&#23454;&#25968;&#25454;&#20998;&#24067;&#30340;&#26679;&#26412;&#65292;&#21487;&#20197;&#20351;&#33258;&#25105;&#28040;&#32791;&#24490;&#29615;&#30340;&#31283;&#23450;&#24615;&#21576;&#25351;&#25968;&#22686;&#21152;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#33258;&#25105;&#20462;&#27491;&#20989;&#25968;&#65292;&#23427;&#20381;&#36182;&#20110;&#19987;&#23478;&#30693;&#35782;&#65288;&#20363;&#22914;&#65292;&#32534;&#31243;&#22312;&#27169;&#25311;&#22120;&#20013;&#30340;&#29289;&#29702;&#23450;&#24459;&#65289;&#65292;&#24182;&#19988;&#26088;&#22312;&#33258;&#21160;&#19988;&#22823;&#35268;&#27169;&#22320;&#36817;&#20284;&#29702;&#24819;&#30340;&#20462;&#27491;&#20989;&#25968;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#20102;&#33258;&#25105;&#32416;&#27491;&#33258;&#25105;&#28040;&#32791;&#24490;&#29615;&#22312;&#29983;&#25104;&#27169;&#22411;&#35757;&#32451;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
As synthetic data becomes higher quality and proliferates on the internet, machine learning models are increasingly trained on a mix of human- and machine-generated data. Despite the successful stories of using synthetic data for representation learning, using synthetic data for generative model training creates "self-consuming loops" which may lead to training instability or even collapse, unless certain conditions are met. Our paper aims to stabilize self-consuming generative model training. Our theoretical results demonstrate that by introducing an idealized correction function, which maps a data point to be more likely under the true data distribution, self-consuming loops can be made exponentially more stable. We then propose self-correction functions, which rely on expert knowledge (e.g. the laws of physics programmed in a simulator), and aim to approximate the idealized corrector automatically and at scale. We empirically validate the effectiveness of self-correcting self-consum
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#24378;&#30423;&#20984;&#20248;&#21270;&#30340;&#22522;&#26412;&#26694;&#26550;&#21644;&#29992;&#20110;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#30340;&#22810;&#31181;&#24037;&#20855;&#12290;&#34429;&#28982;&#27809;&#26377;&#22826;&#22810;&#21019;&#26032;&#65292;&#20294;&#36890;&#36807;&#20197;&#26032;&#39062;&#30340;&#26041;&#24335;&#24212;&#29992;&#29616;&#26377;&#24037;&#20855;&#65292;&#33719;&#24471;&#20102;&#26032;&#30340;&#31639;&#27861;&#21644;&#25913;&#36827;&#20102;&#19968;&#20123;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.06535</link><description>&lt;p&gt;
Bandit Convex Optimisation&#65288;&#24378;&#30423;&#20984;&#20248;&#21270;&#65289;
&lt;/p&gt;
&lt;p&gt;
Bandit Convex Optimisation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06535
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#24378;&#30423;&#20984;&#20248;&#21270;&#30340;&#22522;&#26412;&#26694;&#26550;&#21644;&#29992;&#20110;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#30340;&#22810;&#31181;&#24037;&#20855;&#12290;&#34429;&#28982;&#27809;&#26377;&#22826;&#22810;&#21019;&#26032;&#65292;&#20294;&#36890;&#36807;&#20197;&#26032;&#39062;&#30340;&#26041;&#24335;&#24212;&#29992;&#29616;&#26377;&#24037;&#20855;&#65292;&#33719;&#24471;&#20102;&#26032;&#30340;&#31639;&#27861;&#21644;&#25913;&#36827;&#20102;&#19968;&#20123;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#30423;&#20984;&#20248;&#21270;&#26159;&#30740;&#31350;&#38646;&#38454;&#20984;&#20248;&#21270;&#30340;&#22522;&#26412;&#26694;&#26550;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#29992;&#20110;&#35299;&#20915;&#35813;&#38382;&#39064;&#30340;&#35768;&#22810;&#24037;&#20855;&#65292;&#21253;&#25324;&#20999;&#24179;&#38754;&#26041;&#27861;&#12289;&#20869;&#28857;&#26041;&#27861;&#12289;&#36830;&#32493;&#25351;&#25968;&#26435;&#37325;&#12289;&#26799;&#24230;&#19979;&#38477;&#21644;&#22312;&#32447;&#29275;&#39039;&#27493;&#39588;&#12290;&#35299;&#37322;&#20102;&#35768;&#22810;&#20551;&#35774;&#21644;&#35774;&#32622;&#20043;&#38388;&#30340;&#32454;&#24494;&#24046;&#21035;&#12290;&#23613;&#31649;&#22312;&#36825;&#37324;&#27809;&#26377;&#22826;&#22810;&#30495;&#27491;&#26032;&#30340;&#19996;&#35199;&#65292;&#20294;&#19968;&#20123;&#29616;&#26377;&#24037;&#20855;&#20197;&#26032;&#39062;&#30340;&#26041;&#24335;&#24212;&#29992;&#20110;&#33719;&#24471;&#26032;&#31639;&#27861;&#12290;&#19968;&#20123;&#30028;&#38480;&#31245;&#24494;&#25913;&#36827;&#20102;&#19968;&#20123;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bandit convex optimisation is a fundamental framework for studying zeroth-order convex optimisation. These notes cover the many tools used for this problem, including cutting plane methods, interior point methods, continuous exponential weights, gradient descent and online Newton step. The nuances between the many assumptions and setups are explained. Although there is not much truly new here, some existing tools are applied in novel ways to obtain new algorithms. A few bounds are improved in minor ways.
&lt;/p&gt;</description></item><item><title>&#22312;&#25554;&#20540;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#22343;&#21248;&#38543;&#26426;&#26435;&#37325;&#21487;&#20197;&#20135;&#29983;&#38750;&#22343;&#21248;&#20559;&#24046;&#65292;&#22240;&#27492;&#36890;&#24120;&#25554;&#20540;&#31070;&#32463;&#32593;&#32476;&#20250;&#19982;&#31364;&#25945;&#24072;NN&#19968;&#26679;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;</title><link>https://arxiv.org/abs/2402.06323</link><description>&lt;p&gt;
&#22343;&#21248;&#38543;&#26426;&#26435;&#37325;&#22914;&#20309;&#24341;&#36215;&#19981;&#22343;&#21248;&#20559;&#24046;&#65306;&#20856;&#22411;&#25554;&#20540;&#31070;&#32463;&#32593;&#32476;&#19982;&#31364;&#25945;&#24072;&#30340;&#26222;&#36941;&#24615;
&lt;/p&gt;
&lt;p&gt;
How Uniform Random Weights Induce Non-uniform Bias: Typical Interpolating Neural Networks Generalize with Narrow Teachers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06323
&lt;/p&gt;
&lt;p&gt;
&#22312;&#25554;&#20540;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#22343;&#21248;&#38543;&#26426;&#26435;&#37325;&#21487;&#20197;&#20135;&#29983;&#38750;&#22343;&#21248;&#20559;&#24046;&#65292;&#22240;&#27492;&#36890;&#24120;&#25554;&#20540;&#31070;&#32463;&#32593;&#32476;&#20250;&#19982;&#31364;&#25945;&#24072;NN&#19968;&#26679;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32972;&#26223;&#12290;&#19968;&#20010;&#20027;&#35201;&#30340;&#29702;&#35770;&#38590;&#39064;&#26159;&#24403;&#31070;&#32463;&#32593;&#32476;&#34987;&#35757;&#32451;&#21040;&#38646;&#35823;&#24046;&#65288;&#21363;&#25554;&#20540;&#25968;&#25454;&#65289;&#26102;&#65292;&#20026;&#20160;&#20040;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#33021;&#22815;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;&#36890;&#24120;&#65292;NN&#26159;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#25110;&#20854;&#21464;&#31181;&#20043;&#19968;&#35757;&#32451;&#30340;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#23454;&#35777;&#30740;&#31350;&#26816;&#39564;&#20102;&#20174;&#30475;&#20284;&#22343;&#21248;&#30340;&#21442;&#25968;&#20808;&#39564;&#20013;&#37319;&#26679;&#30340;&#38543;&#26426;NN&#23545;&#25968;&#25454;&#30340;&#27867;&#21270;&#33021;&#21147;&#65306;&#35813;NN&#23545;&#35757;&#32451;&#38598;&#36827;&#34892;&#20102;&#23436;&#32654;&#20998;&#31867;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#36825;&#26679;&#30340;NN&#26679;&#26412;&#36890;&#24120;&#20687;SGD&#35757;&#32451;&#30340;NN&#19968;&#26679;&#27867;&#21270;&#33391;&#22909;&#12290;&#36129;&#29486;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22914;&#26524;&#23384;&#22312;&#19982;&#26631;&#31614;&#19968;&#33268;&#30340;&#31364;&#8220;&#25945;&#24072;NN&#8221;&#65292;&#37027;&#20040;&#36825;&#26679;&#30340;&#38543;&#26426;NN&#25554;&#20540;&#22120;&#36890;&#24120;&#33021;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;NN&#21442;&#25968;&#21270;&#20013;&#30340;&#8220;&#24179;&#22374;&#8221;&#20808;&#39564;&#36890;&#36807;NN&#32467;&#26500;&#20013;&#30340;&#20887;&#20313;&#24341;&#20837;&#20102;&#20016;&#23500;&#30340;NN&#20989;&#25968;&#20808;&#39564;&#12290;&#29305;&#21035;&#26159;&#65292;&#36825;&#20250;&#23545;&#36739;&#31616;&#21333;&#30340;&#20989;&#25968;&#20135;&#29983;&#20559;&#21521;&#65292;&#36825;&#20123;&#20989;&#25968;&#38656;&#35201;&#36739;&#23569;&#30340;&#30456;&#20851;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Background. A main theoretical puzzle is why over-parameterized Neural Networks (NNs) generalize well when trained to zero loss (i.e., so they interpolate the data). Usually, the NN is trained with Stochastic Gradient Descent (SGD) or one of its variants. However, recent empirical work examined the generalization of a random NN that interpolates the data: the NN was sampled from a seemingly uniform prior over the parameters, conditioned on that the NN perfectly classifying the training set. Interestingly, such a NN sample typically generalized as well as SGD-trained NNs.   Contributions. We prove that such a random NN interpolator typically generalizes well if there exists an underlying narrow ``teacher NN" that agrees with the labels. Specifically, we show that such a `flat' prior over the NN parametrization induces a rich prior over the NN functions, due to the redundancy in the NN structure. In particular, this creates a bias towards simpler functions, which require less relevant pa
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#27169;&#22411;&#20013;&#30340;&#23545;&#25239;&#35757;&#32451;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;&#21487;&#22788;&#29702;&#30340;&#25968;&#23398;&#27169;&#22411;&#65292;&#24182;&#32473;&#20986;&#20102;&#23545;&#25239;&#24615;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#22120;&#30340;&#20805;&#20998;&#32479;&#35745;&#30340;&#31934;&#30830;&#28176;&#36817;&#25551;&#36848;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#23384;&#22312;&#21487;&#20197;&#38450;&#24481;&#32780;&#19981;&#24809;&#32602;&#20934;&#30830;&#24615;&#30340;&#26041;&#21521;&#65292;&#25581;&#31034;&#20102;&#38450;&#24481;&#38750;&#40065;&#26834;&#29305;&#24449;&#30340;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2402.05674</link><description>&lt;p&gt;
&#39640;&#32500;&#27169;&#22411;&#30340;&#23545;&#25239;&#35757;&#32451;&#65306;&#20960;&#20309;&#21644;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
A High Dimensional Model for Adversarial Training: Geometry and Trade-Offs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05674
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#27169;&#22411;&#20013;&#30340;&#23545;&#25239;&#35757;&#32451;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;&#21487;&#22788;&#29702;&#30340;&#25968;&#23398;&#27169;&#22411;&#65292;&#24182;&#32473;&#20986;&#20102;&#23545;&#25239;&#24615;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#22120;&#30340;&#20805;&#20998;&#32479;&#35745;&#30340;&#31934;&#30830;&#28176;&#36817;&#25551;&#36848;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#23384;&#22312;&#21487;&#20197;&#38450;&#24481;&#32780;&#19981;&#24809;&#32602;&#20934;&#30830;&#24615;&#30340;&#26041;&#21521;&#65292;&#25581;&#31034;&#20102;&#38450;&#24481;&#38750;&#40065;&#26834;&#29305;&#24449;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#21363;&#32500;&#24230;$d$&#21644;&#25968;&#25454;&#28857;&#25968;$n$&#19982;&#22266;&#23450;&#27604;&#20363;$\alpha = n / d$&#21457;&#25955;&#30340;&#19978;&#19979;&#25991;&#20013;&#65292;&#30740;&#31350;&#20102;&#22522;&#20110;&#36793;&#38469;&#30340;&#32447;&#24615;&#20998;&#31867;&#22120;&#20013;&#30340;&#23545;&#25239;&#35757;&#32451;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#21487;&#22788;&#29702;&#30340;&#25968;&#23398;&#27169;&#22411;&#65292;&#21487;&#20197;&#30740;&#31350;&#25968;&#25454;&#21644;&#23545;&#25239;&#25915;&#20987;&#32773;&#20960;&#20309;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#21516;&#26102;&#25429;&#25417;&#21040;&#23545;&#25239;&#40065;&#26834;&#24615;&#25991;&#29486;&#20013;&#35266;&#23519;&#21040;&#30340;&#26680;&#24515;&#29616;&#35937;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#29702;&#35770;&#36129;&#29486;&#26159;&#22312;&#36890;&#29992;&#30340;&#20984;&#19988;&#38750;&#36882;&#22686;&#25439;&#22833;&#20989;&#25968;&#19979;&#65292;&#23545;&#20110;&#23545;&#25239;&#24615;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#22120;&#30340;&#20805;&#20998;&#32479;&#35745;&#30340;&#31934;&#30830;&#28176;&#36817;&#25551;&#36848;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20351;&#25105;&#20204;&#33021;&#22815;&#31934;&#30830;&#22320;&#21051;&#30011;&#25968;&#25454;&#20013;&#19982;&#26356;&#39640;&#30340;&#27867;&#21270;/&#40065;&#26834;&#24615;&#26435;&#34913;&#30456;&#20851;&#30340;&#26041;&#21521;&#65292;&#30001;&#19968;&#20010;&#40065;&#26834;&#24615;&#24230;&#37327;&#21644;&#19968;&#20010;&#26377;&#29992;&#24615;&#24230;&#37327;&#23450;&#20041;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#23384;&#22312;&#19968;&#20123;&#26041;&#21521;&#65292;&#21487;&#20197;&#36827;&#34892;&#38450;&#24481;&#32780;&#19981;&#24809;&#32602;&#20934;&#30830;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#38450;&#24481;&#38750;&#40065;&#26834;&#29305;&#24449;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work investigates adversarial training in the context of margin-based linear classifiers in the high-dimensional regime where the dimension $d$ and the number of data points $n$ diverge with a fixed ratio $\alpha = n / d$. We introduce a tractable mathematical model where the interplay between the data and adversarial attacker geometries can be studied, while capturing the core phenomenology observed in the adversarial robustness literature. Our main theoretical contribution is an exact asymptotic description of the sufficient statistics for the adversarial empirical risk minimiser, under generic convex and non-increasing losses. Our result allow us to precisely characterise which directions in the data are associated with a higher generalisation/robustness trade-off, as defined by a robustness and a usefulness metric. In particular, we unveil the existence of directions which can be defended without penalising accuracy. Finally, we show the advantage of defending non-robust featu
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#21253;&#25324;&#28145;&#24230;&#38598;&#21512;&#12289;&#21464;&#21387;&#22120;&#12289;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21644;&#31616;&#21333;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#31561;&#22810;&#31181;&#26550;&#26500;&#65292;&#25506;&#32034;&#20102;&#21487;&#35777;&#26126;&#30340;&#38271;&#24230;&#21644;&#32452;&#21512;&#27867;&#21270;&#65292;&#35748;&#20026;&#23545;&#20110;&#38271;&#24230;&#21644;&#32452;&#21512;&#27867;&#21270;&#65292;&#19981;&#21516;&#26550;&#26500;&#38656;&#35201;&#19981;&#21516;&#31243;&#24230;&#30340;&#34920;&#31034;&#35782;&#21035;&#12290;</title><link>https://arxiv.org/abs/2402.04875</link><description>&lt;p&gt;
&#20851;&#20110;&#21487;&#35777;&#26126;&#30340;&#38271;&#24230;&#21644;&#32452;&#21512;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
On Provable Length and Compositional Generalization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04875
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#21253;&#25324;&#28145;&#24230;&#38598;&#21512;&#12289;&#21464;&#21387;&#22120;&#12289;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21644;&#31616;&#21333;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#31561;&#22810;&#31181;&#26550;&#26500;&#65292;&#25506;&#32034;&#20102;&#21487;&#35777;&#26126;&#30340;&#38271;&#24230;&#21644;&#32452;&#21512;&#27867;&#21270;&#65292;&#35748;&#20026;&#23545;&#20110;&#38271;&#24230;&#21644;&#32452;&#21512;&#27867;&#21270;&#65292;&#19981;&#21516;&#26550;&#26500;&#38656;&#35201;&#19981;&#21516;&#31243;&#24230;&#30340;&#34920;&#31034;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38271;&#24230;&#27867;&#21270;&#8212;&#8212;&#23545;&#35757;&#32451;&#26102;&#26410;&#35265;&#21040;&#30340;&#26356;&#38271;&#24207;&#21015;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#20197;&#21450;&#32452;&#21512;&#27867;&#21270;&#8212;&#8212;&#23545;&#35757;&#32451;&#26102;&#26410;&#35265;&#21040;&#30340;&#20196;&#29260;&#32452;&#21512;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#22312;&#24207;&#21015;&#21040;&#24207;&#21015;&#27169;&#22411;&#20013;&#26159;&#37325;&#35201;&#30340;&#38750;&#20998;&#24067;&#21270;&#27867;&#21270;&#24418;&#24335;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#22312;&#21253;&#25324;&#28145;&#24230;&#38598;&#21512;&#12289;&#21464;&#21387;&#22120;&#12289;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21644;&#31616;&#21333;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#22312;&#20869;&#30340;&#19968;&#31995;&#21015;&#26550;&#26500;&#20013;&#65292;&#26397;&#30528;&#21487;&#35777;&#26126;&#30340;&#38271;&#24230;&#21644;&#32452;&#21512;&#27867;&#21270;&#36808;&#20986;&#20102;&#31532;&#19968;&#27493;&#12290;&#26681;&#25454;&#26550;&#26500;&#30340;&#19981;&#21516;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19981;&#21516;&#31243;&#24230;&#30340;&#34920;&#31034;&#35782;&#21035;&#30340;&#24517;&#35201;&#24615;&#65292;&#20363;&#22914;&#19982;&#30495;&#23454;&#34920;&#31034;&#20855;&#26377;&#32447;&#24615;&#25110;&#25490;&#21015;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Length generalization -- the ability to generalize to longer sequences than ones seen during training, and compositional generalization -- the ability to generalize to token combinations not seen during training, are crucial forms of out-of-distribution generalization in sequence-to-sequence models. In this work, we take the first steps towards provable length and compositional generalization for a range of architectures, including deep sets, transformers, state space models, and simple recurrent neural nets. Depending on the architecture, we prove different degrees of representation identification, e.g., a linear or a permutation relation with ground truth representation, is necessary for length and compositional generalization.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#19988;&#39640;&#24230;&#24182;&#34892;&#30340;&#29992;&#20110;&#27604;&#36739;&#29699;&#24418;&#27979;&#24230;&#30340;&#36317;&#31163;&#65292;&#20351;&#29992;&#20102;&#31435;&#20307;&#25237;&#24433;&#21644;&#24191;&#20041;Radon&#21464;&#25442;&#65292;&#31216;&#20043;&#20026;&#31435;&#20307;&#25237;&#24433;&#29699;&#38754;&#20999;&#29255;&#29926;&#29791;&#26031;&#22374;&#65288;S3W&#65289;&#36317;&#31163;&#12290;&#36890;&#36807;&#20180;&#32454;&#22788;&#29702;&#31435;&#20307;&#25237;&#24433;&#24341;&#36215;&#30340;&#36317;&#31163;&#30072;&#21464;&#65292;&#24182;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#36895;&#24230;&#21644;&#25928;&#26524;&#19978;&#30340;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2402.02345</link><description>&lt;p&gt;
Stereographic Spherical Sliced Wasserstein Distances - &#24212;&#29992;&#20110;&#29699;&#24418;&#27010;&#29575;&#20998;&#24067;&#27604;&#36739;&#30340;&#31435;&#20307;&#25237;&#24433;&#29699;&#38754;&#20999;&#29255;&#29926;&#29791;&#26031;&#22374;&#36317;&#31163;
&lt;/p&gt;
&lt;p&gt;
Stereographic Spherical Sliced Wasserstein Distances
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02345
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#19988;&#39640;&#24230;&#24182;&#34892;&#30340;&#29992;&#20110;&#27604;&#36739;&#29699;&#24418;&#27979;&#24230;&#30340;&#36317;&#31163;&#65292;&#20351;&#29992;&#20102;&#31435;&#20307;&#25237;&#24433;&#21644;&#24191;&#20041;Radon&#21464;&#25442;&#65292;&#31216;&#20043;&#20026;&#31435;&#20307;&#25237;&#24433;&#29699;&#38754;&#20999;&#29255;&#29926;&#29791;&#26031;&#22374;&#65288;S3W&#65289;&#36317;&#31163;&#12290;&#36890;&#36807;&#20180;&#32454;&#22788;&#29702;&#31435;&#20307;&#25237;&#24433;&#24341;&#36215;&#30340;&#36317;&#31163;&#30072;&#21464;&#65292;&#24182;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#36895;&#24230;&#21644;&#25928;&#26524;&#19978;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22320;&#36136;&#23398;&#12289;&#21307;&#23398;&#39046;&#22495;&#12289;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#28145;&#24230;&#34920;&#31034;&#23398;&#20064;&#31561;&#21508;&#20010;&#39046;&#22495;&#65292;&#27604;&#36739;&#29699;&#24418;&#27010;&#29575;&#20998;&#24067;&#26159;&#38750;&#24120;&#37325;&#35201;&#30340;&#12290;&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#30340;&#36317;&#31163;&#65292;&#27604;&#22914;&#29926;&#29791;&#26031;&#22374;&#36317;&#31163;&#65292;&#23545;&#20110;&#27604;&#36739;&#27010;&#29575;&#27979;&#24230;&#24050;&#32463;&#24341;&#21457;&#20102;&#27963;&#36291;&#30340;&#30740;&#31350;&#65292;&#20197;&#24320;&#21457;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#29699;&#24418;&#27010;&#29575;&#27979;&#24230;&#30340;&#21464;&#20307;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#36895;&#19988;&#39640;&#24230;&#24182;&#34892;&#21270;&#30340;&#29992;&#20110;&#27604;&#36739;&#29699;&#24418;&#27979;&#24230;&#30340;&#36317;&#31163;&#65292;&#20351;&#29992;&#20102;&#31435;&#20307;&#25237;&#24433;&#21644;&#24191;&#20041;Radon&#21464;&#25442;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#31435;&#20307;&#25237;&#24433;&#29699;&#38754;&#20999;&#29255;&#29926;&#29791;&#26031;&#22374;&#65288;S3W&#65289;&#36317;&#31163;&#12290;&#25105;&#20204;&#20180;&#32454;&#22788;&#29702;&#20102;&#31435;&#20307;&#25237;&#24433;&#24341;&#36215;&#30340;&#36317;&#31163;&#30072;&#21464;&#65292;&#24182;&#23545;&#25105;&#20204;&#25552;&#20986;&#30340;&#24230;&#37327;&#21450;&#20854;&#20855;&#26377;&#26059;&#36716;&#19981;&#21464;&#24615;&#30340;&#21464;&#20307;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#25152;&#25552;&#20986;&#30340;&#24230;&#37327;&#30340;&#24615;&#33021;&#65292;&#24182;&#23558;&#20854;&#19982;&#26368;&#36817;&#30340;&#22522;&#32447;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#20174;&#36965;&#24863;&#21644;&#22788;&#29702;&#25928;&#29575;&#20004;&#20010;&#26041;&#38754;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Comparing spherical probability distributions is of great interest in various fields, including geology, medical domains, computer vision, and deep representation learning. The utility of optimal transport-based distances, such as the Wasserstein distance, for comparing probability measures has spurred active research in developing computationally efficient variations of these distances for spherical probability measures. This paper introduces a high-speed and highly parallelizable distance for comparing spherical measures using the stereographic projection and the generalized Radon transform, which we refer to as the Stereographic Spherical Sliced Wasserstein (S3W) distance. We carefully address the distance distortion caused by the stereographic projection and provide an extensive theoretical analysis of our proposed metric and its rotationally invariant variation. Finally, we evaluate the performance of the proposed metrics and compare them with recent baselines in terms of both spe
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#35774;&#35745;&#25511;&#21046;&#22330;&#30340;&#26041;&#26696;&#25104;&#21151;&#29983;&#25104;&#20102;&#38750;&#32463;&#20856;&#24577;&#65292;&#20197;&#24212;&#29992;&#20110;&#33258;&#26059;&#21387;&#32553;&#24577;&#30340;&#20135;&#29983;&#12290;&#35813;&#26041;&#27861;&#22312;&#20445;&#25345;&#21387;&#32553;&#21644;&#32416;&#32544;&#30340;&#21516;&#26102;&#25552;&#20379;&#20102;&#19981;&#21516;&#30340;&#25511;&#21046;&#24207;&#21015;&#65292;&#24182;&#35266;&#23519;&#21040;&#25511;&#21046;&#33033;&#20914;&#23494;&#38598;&#24212;&#29992;&#21487;&#20197;&#25552;&#39640;&#32467;&#26524;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.16320</link><description>&lt;p&gt;
&#21033;&#29992;&#24378;&#21270;&#23398;&#20064;&#29983;&#25104;&#38750;&#32463;&#20856;&#38598;&#21512;&#33258;&#26059;&#24577;&#30340;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Prepare Non-classical Collective Spin State by Reinforcement Learning. (arXiv:2401.16320v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16320
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#35774;&#35745;&#25511;&#21046;&#22330;&#30340;&#26041;&#26696;&#25104;&#21151;&#29983;&#25104;&#20102;&#38750;&#32463;&#20856;&#24577;&#65292;&#20197;&#24212;&#29992;&#20110;&#33258;&#26059;&#21387;&#32553;&#24577;&#30340;&#20135;&#29983;&#12290;&#35813;&#26041;&#27861;&#22312;&#20445;&#25345;&#21387;&#32553;&#21644;&#32416;&#32544;&#30340;&#21516;&#26102;&#25552;&#20379;&#20102;&#19981;&#21516;&#30340;&#25511;&#21046;&#24207;&#21015;&#65292;&#24182;&#35266;&#23519;&#21040;&#25511;&#21046;&#33033;&#20914;&#23494;&#38598;&#24212;&#29992;&#21487;&#20197;&#25552;&#39640;&#32467;&#26524;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#24378;&#21270;&#23398;&#20064;&#26469;&#35774;&#35745;&#25511;&#21046;&#22330;&#30340;&#26041;&#26696;&#65292;&#29992;&#20110;&#29983;&#25104;&#38750;&#32463;&#20856;&#24577;&#12290;&#35813;&#26041;&#26696;&#20197;&#24212;&#29992;&#20110;&#24320;&#25918;&#38598;&#20307;&#33258;&#26059;&#27169;&#22411;&#20013;&#30340;&#33258;&#26059;&#21387;&#32553;&#24577;&#20026;&#20363;&#65292;&#20854;&#20013;&#35774;&#35745;&#20102;&#19968;&#20010;&#32447;&#24615;&#25511;&#21046;&#39033;&#26469;&#25511;&#21046;&#21160;&#21147;&#23398;&#12290;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#26681;&#25454;&#20197;&#32791;&#25955;&#21644;&#21435;&#30456;&#24178;&#20026;&#29305;&#24449;&#30340;&#29615;&#22659;&#20013;&#30340;&#30456;&#24178;&#33258;&#26059;&#24577;&#24320;&#22987;&#65292;&#30830;&#23450;&#20102;&#25511;&#21046;&#33033;&#20914;&#30340;&#26102;&#38388;&#24207;&#21015;&#12290;&#19982;&#24658;&#23450;&#25511;&#21046;&#26041;&#26696;&#30456;&#27604;&#65292;&#36825;&#31181;&#26041;&#27861;&#25552;&#20379;&#20102;&#22810;&#31181;&#25511;&#21046;&#24207;&#21015;&#65292;&#20445;&#25345;&#20102;&#38598;&#20307;&#33258;&#26059;&#21387;&#32553;&#21644;&#32416;&#32544;&#12290;&#35266;&#23519;&#21040;&#25511;&#21046;&#33033;&#20914;&#30340;&#23494;&#38598;&#24212;&#29992;&#21487;&#20197;&#22686;&#24378;&#32467;&#26524;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#28155;&#21152;&#25511;&#21046;&#25805;&#20316;&#65292;&#24615;&#33021;&#24471;&#21040;&#20102;&#36731;&#24494;&#22686;&#24378;&#12290;&#25152;&#25552;&#20986;&#30340;&#31574;&#30053;&#22312;&#36739;&#22823;&#31995;&#32479;&#20013;&#23637;&#29616;&#20102;&#26356;&#39640;&#30340;&#25928;&#26524;&#12290;&#23545;&#20648;&#22791;&#28909;&#28608;&#21457;&#23545;&#25511;&#21046;&#32467;&#26524;&#26377;&#19981;&#21033;&#24433;&#21709;&#12290;&#24212;&#35813;&#30830;&#35748;&#36825;&#19968;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a scheme leveraging reinforcement learning to engineer control fields for generating non-classical states. It is exemplified by the application to prepare spin squeezed state for an open collective spin model where a linear control term is designed to govern the dynamics. The reinforcement learning agent determines the temporal sequence of control pulses, commencing from coherent spin state in an environment characterized by dissipation and dephasing. When compared to constant control scenarios, this approach provides various control sequences maintaining collective spin squeezing and entanglement. It is observed that denser application of the control pulses enhances the performance of the outcomes. Furthermore, there is a minor enhancement in the performance by adding control actions. The proposed strategy demonstrates increased effectiveness for larger systems. And thermal excitations of the reservoir are detrimental to the control outcomes. It should be confirmed that thi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#19987;&#21033;&#25968;&#25454;&#25552;&#39640;&#20102;&#25239;&#20307;&#20154;&#24615;&#39044;&#27979;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#22810;&#38454;&#27573;&#12289;&#22810;&#25439;&#22833;&#30340;&#35757;&#32451;&#36807;&#31243;&#20197;&#21450;&#24369;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#25104;&#21151;&#22320;&#39044;&#27979;&#20102;&#25239;&#20307;&#24207;&#21015;&#30340;&#20154;&#24615;&#35780;&#20998;&#12290;</title><link>http://arxiv.org/abs/2401.14442</link><description>&lt;p&gt;
&#21033;&#29992;&#19987;&#21033;&#25968;&#25454;&#25552;&#39640;&#25239;&#20307;&#20154;&#24615;&#39044;&#27979;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Improving Antibody Humanness Prediction using Patent Data. (arXiv:2401.14442v1 [q-bio.QM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14442
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#19987;&#21033;&#25968;&#25454;&#25552;&#39640;&#20102;&#25239;&#20307;&#20154;&#24615;&#39044;&#27979;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#22810;&#38454;&#27573;&#12289;&#22810;&#25439;&#22833;&#30340;&#35757;&#32451;&#36807;&#31243;&#20197;&#21450;&#24369;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#25104;&#21151;&#22320;&#39044;&#27979;&#20102;&#25239;&#20307;&#24207;&#21015;&#30340;&#20154;&#24615;&#35780;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#21033;&#29992;&#19987;&#21033;&#25968;&#25454;&#26469;&#25552;&#39640;&#25239;&#20307;&#20154;&#24615;&#39044;&#27979;&#30340;&#28508;&#21147;&#65292;&#37319;&#29992;&#20102;&#22810;&#38454;&#27573;&#12289;&#22810;&#25439;&#22833;&#30340;&#35757;&#32451;&#36807;&#31243;&#12290;&#25239;&#20307;&#20154;&#24615;&#20316;&#20026;&#23545;&#25239;&#20307;&#27835;&#30103;&#30340;&#20813;&#30123;&#21453;&#24212;&#30340;&#20195;&#29702;&#65292;&#26159;&#33647;&#29289;&#21457;&#29616;&#20013;&#30340;&#20027;&#35201;&#21407;&#22240;&#20043;&#19968;&#65292;&#22312;&#20020;&#24202;&#29615;&#22659;&#20013;&#20351;&#29992;&#25239;&#20307;&#27835;&#30103;&#38754;&#20020;&#30528;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38556;&#30861;&#12290;&#25105;&#20204;&#23558;&#21021;&#22987;&#23398;&#20064;&#38454;&#27573;&#35270;&#20026;&#19968;&#20010;&#24369;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#38382;&#39064;&#65292;&#27599;&#20010;&#25239;&#20307;&#24207;&#21015;&#19982;&#21487;&#33021;&#26377;&#22810;&#20010;&#21151;&#33021;&#26631;&#35782;&#31526;&#30456;&#20851;&#32852;&#65292;&#30446;&#26631;&#26159;&#23398;&#20064;&#19968;&#20010;&#32534;&#30721;&#22120;&#65292;&#26681;&#25454;&#20854;&#19987;&#21033;&#23646;&#24615;&#23558;&#23427;&#20204;&#20998;&#32452;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20923;&#32467;&#23545;&#27604;&#32534;&#30721;&#22120;&#30340;&#19968;&#37096;&#20998;&#65292;&#24182;&#32487;&#32493;&#20351;&#29992;&#20132;&#21449;&#29109;&#25439;&#22833;&#22312;&#19987;&#21033;&#25968;&#25454;&#19978;&#35757;&#32451;&#65292;&#20197;&#39044;&#27979;&#32473;&#23450;&#25239;&#20307;&#24207;&#21015;&#30340;&#20154;&#24615;&#35780;&#20998;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#19977;&#20010;&#19981;&#21516;&#30340;&#20813;&#30123;&#21407;&#24615;&#25968;&#25454;&#38598;&#36827;&#34892;&#25512;&#29702;&#65292;&#23637;&#31034;&#20102;&#19987;&#21033;&#25968;&#25454;&#21644;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#25928;&#29992;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;l
&lt;/p&gt;
&lt;p&gt;
We investigate the potential of patent data for improving the antibody humanness prediction using a multi-stage, multi-loss training process. Humanness serves as a proxy for the immunogenic response to antibody therapeutics, one of the major causes of attrition in drug discovery and a challenging obstacle for their use in clinical settings. We pose the initial learning stage as a weakly-supervised contrastive-learning problem, where each antibody sequence is associated with possibly multiple identifiers of function and the objective is to learn an encoder that groups them according to their patented properties. We then freeze a part of the contrastive encoder and continue training it on the patent data using the cross-entropy loss to predict the humanness score of a given antibody sequence. We illustrate the utility of the patent data and our approach by performing inference on three different immunogenicity datasets, unseen during training. Our empirical results demonstrate that the l
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;&#35268;&#33539;&#39044;&#27979;&#37327;&#21270;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#21487;&#20197;&#25552;&#39640;&#20154;&#31867;&#20915;&#31574;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#26524;&#65292;&#23545;&#20154;&#26426;&#21327;&#21516;&#20915;&#31574;&#20855;&#26377;&#23454;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2401.13744</link><description>&lt;p&gt;
&#12298;&#35268;&#33539;&#39044;&#27979;&#38598;&#25552;&#21319;&#20154;&#31867;&#20915;&#31574;&#33021;&#21147;&#12299;
&lt;/p&gt;
&lt;p&gt;
Conformal Prediction Sets Improve Human Decision Making. (arXiv:2401.13744v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13744
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;&#35268;&#33539;&#39044;&#27979;&#37327;&#21270;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#21487;&#20197;&#25552;&#39640;&#20154;&#31867;&#20915;&#31574;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#26524;&#65292;&#23545;&#20154;&#26426;&#21327;&#21516;&#20915;&#31574;&#20855;&#26377;&#23454;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20316;&#20026;&#23545;&#26085;&#24120;&#26597;&#35810;&#30340;&#22238;&#24212;&#65292;&#20154;&#31867;&#26126;&#30830;&#22320;&#34920;&#36798;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#22312;&#19981;&#30830;&#23450;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#26367;&#20195;&#31572;&#26696;&#12290;&#36890;&#36807;&#35268;&#33539;&#39044;&#27979;&#36755;&#20986;&#26657;&#20934;&#30340;&#39044;&#27979;&#38598;&#65292;&#27169;&#20223;&#20102;&#20154;&#31867;&#30340;&#36825;&#31181;&#34892;&#20026;&#65307;&#26356;&#22823;&#30340;&#39044;&#27979;&#38598;&#34920;&#31034;&#26356;&#22823;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#26367;&#20195;&#26041;&#26696;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#26045;&#39044;&#27880;&#20876;&#30340;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#65292;&#24182;&#32473;&#20154;&#31867;&#21463;&#35797;&#32773;&#25552;&#20379;&#35268;&#33539;&#39044;&#27979;&#38598;&#65292;&#30740;&#31350;&#20102;&#35268;&#33539;&#39044;&#27979;&#38598;&#23545;&#20154;&#31867;&#20915;&#31574;&#30340;&#23454;&#29992;&#24615;&#12290;&#36890;&#36807;&#32479;&#35745;&#23398;&#26174;&#33879;&#24615;&#65292;&#25105;&#20204;&#21457;&#29616;&#24403;&#20154;&#31867;&#33719;&#24471;&#35268;&#33539;&#39044;&#27979;&#38598;&#26102;&#65292;&#20182;&#20204;&#22312;&#20219;&#21153;&#19978;&#30340;&#20934;&#30830;&#24615;&#27604;&#20351;&#29992;&#30456;&#21516;&#35206;&#30422;&#20445;&#35777;&#30340;&#22266;&#23450;&#23610;&#23544;&#39044;&#27979;&#38598;&#26102;&#26377;&#25152;&#25552;&#39640;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#29992;&#35268;&#33539;&#39044;&#27979;&#37327;&#21270;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#26377;&#21161;&#20110;&#20154;&#26426;&#21327;&#21516;&#20915;&#31574;&#21644;&#20154;&#24037;&#26234;&#33021;&#22242;&#38431;&#30340;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;
In response to everyday queries, humans explicitly signal uncertainty and offer alternative answers when they are unsure. Machine learning models that output calibrated prediction sets through conformal prediction mimic this human behaviour; larger sets signal greater uncertainty while providing alternatives. In this work, we study the usefulness of conformal prediction sets as an aid for human decision making by conducting a pre-registered randomized controlled trial with conformal prediction sets provided to human subjects. With statistical significance, we find that when humans are given conformal prediction sets their accuracy on tasks improves compared to fixed-size prediction sets with the same coverage guarantee. The results show that quantifying model uncertainty with conformal prediction is helpful for human-in-the-loop decision making and human-AI teams.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#28436;&#31034;-&#27491;&#21017;&#21270;&#25552;&#39640;&#24378;&#21270;&#23398;&#20064;&#30340;&#37319;&#26679;&#25928;&#29575;&#65292;&#24182;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#35813;&#22797;&#26434;&#24230;&#19982;&#19987;&#23478;&#28436;&#31034;&#25968;&#37327;&#25104;&#21453;&#27604;&#12290;</title><link>http://arxiv.org/abs/2310.17303</link><description>&lt;p&gt;
&#36890;&#36807;&#28436;&#31034;-&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;&#22686;&#24378;&#37319;&#26679;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;
Demonstration-Regularized RL. (arXiv:2310.17303v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17303
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#28436;&#31034;-&#27491;&#21017;&#21270;&#25552;&#39640;&#24378;&#21270;&#23398;&#20064;&#30340;&#37319;&#26679;&#25928;&#29575;&#65292;&#24182;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#35813;&#22797;&#26434;&#24230;&#19982;&#19987;&#23478;&#28436;&#31034;&#25968;&#37327;&#25104;&#21453;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23558;&#19987;&#23478;&#28436;&#31034;&#32435;&#20837;&#20854;&#20013;&#65292;&#21487;&#20197;&#22312;&#25552;&#39640;&#24378;&#21270;&#23398;&#20064;(SRL)&#30340;&#37319;&#26679;&#25928;&#29575;&#26041;&#38754;&#20135;&#29983;&#32463;&#39564;&#25928;&#26524;&#12290;&#26412;&#25991;&#22312;&#29702;&#35770;&#19978;&#37327;&#21270;&#36825;&#20123;&#39069;&#22806;&#20449;&#24687;&#38477;&#20302;&#20102;SRL&#30340;&#37319;&#26679;&#22797;&#26434;&#24615;&#30340;&#31243;&#24230;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#36890;&#36807;KL&#27491;&#21017;&#21270;&#21033;&#29992;&#19987;&#23478;&#28436;&#31034;&#23398;&#20064;&#30340;&#31574;&#30053;&#30340;&#28436;&#31034;-&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#26377;&#38480;&#29366;&#24577;&#19979;&#65292;&#22312;$\widetilde{\mathcal{O}}(\mathrm{Poly}(S,A,H)/(\varepsilon^2 N^{\mathrm{E}}))$&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20869;&#65292;&#20351;&#29992;$N^{\mathrm{E}}$&#20010;&#19987;&#23478;&#28436;&#31034;&#33021;&#22815;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#65292;&#24182;&#22312;&#32447;&#24615;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#65292;&#22312;$\widetilde{\mathcal{O}}(\mathrm{Poly}(d,H)/(\varepsilon^2 N^{\mathrm{E}}))$&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20869;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#65292;&#20854;&#20013;$\varepsilon$&#26159;&#30446;&#26631;&#31934;&#24230;&#65292;$H$&#26159;&#35268;&#23450;&#65292;$A$&#26159;&#21160;&#20316;&#30340;&#25968;&#37327;&#65292;$S$&#26159;&#26377;&#38480;&#29366;&#24577;&#30340;&#25968;&#37327;&#65292;&#22312;&#32447;&#24615;&#24773;&#20917;&#19979;&#65292;$d$&#26159;&#29305;&#24449;&#31354;&#38388;&#30340;&#32500;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Incorporating expert demonstrations has empirically helped to improve the sample efficiency of reinforcement learning (RL). This paper quantifies theoretically to what extent this extra information reduces RL's sample complexity. In particular, we study the demonstration-regularized reinforcement learning that leverages the expert demonstrations by KL-regularization for a policy learned by behavior cloning. Our findings reveal that using $N^{\mathrm{E}}$ expert demonstrations enables the identification of an optimal policy at a sample complexity of order $\widetilde{\mathcal{O}}(\mathrm{Poly}(S,A,H)/(\varepsilon^2 N^{\mathrm{E}}))$ in finite and $\widetilde{\mathcal{O}}(\mathrm{Poly}(d,H)/(\varepsilon^2 N^{\mathrm{E}}))$ in linear Markov decision processes, where $\varepsilon$ is the target precision, $H$ the horizon, $A$ the number of action, $S$ the number of states in the finite case and $d$ the dimension of the feature space in the linear case. As a by-product, we provide tight con
&lt;/p&gt;</description></item><item><title>&#22312;&#36125;&#21494;&#26031;&#20027;&#21160;&#20803;&#23398;&#20064;&#20013;&#65292;&#36138;&#23146;&#36861;&#27714;&#21487;&#36716;&#31227;&#30693;&#35782;&#21487;&#33021;&#20250;&#25439;&#23475;&#23545;&#21487;&#36716;&#31227;&#21442;&#25968;&#30340;&#20272;&#35745;&#65292;&#23398;&#20064;&#32773;&#38754;&#20020;&#20219;&#21153;&#35782;&#21035;&#21644;&#21487;&#36716;&#31227;&#30693;&#35782;&#33719;&#21462;&#20043;&#38388;&#30340;&#22256;&#22659;&#12290;</title><link>http://arxiv.org/abs/2310.14968</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#20027;&#21160;&#20803;&#23398;&#20064;&#30340;&#22522;&#26412;&#22256;&#22659;
&lt;/p&gt;
&lt;p&gt;
The Fundamental Dilemma of Bayesian Active Meta-learning. (arXiv:2310.14968v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14968
&lt;/p&gt;
&lt;p&gt;
&#22312;&#36125;&#21494;&#26031;&#20027;&#21160;&#20803;&#23398;&#20064;&#20013;&#65292;&#36138;&#23146;&#36861;&#27714;&#21487;&#36716;&#31227;&#30693;&#35782;&#21487;&#33021;&#20250;&#25439;&#23475;&#23545;&#21487;&#36716;&#31227;&#21442;&#25968;&#30340;&#20272;&#35745;&#65292;&#23398;&#20064;&#32773;&#38754;&#20020;&#20219;&#21153;&#35782;&#21035;&#21644;&#21487;&#36716;&#31227;&#30693;&#35782;&#33719;&#21462;&#20043;&#38388;&#30340;&#22256;&#22659;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#24212;&#29992;&#38656;&#35201;&#20272;&#35745;&#22312;&#22810;&#20010;&#19981;&#21516;&#20294;&#30456;&#20851;&#30340;&#25968;&#25454;&#31232;&#32570;&#20219;&#21153;&#29615;&#22659;&#20013;&#25512;&#24191;&#30340;&#21442;&#25968;&#12290;&#36125;&#21494;&#26031;&#20027;&#21160;&#20803;&#23398;&#20064;&#26159;&#19968;&#31181;&#39034;&#24207;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#30340;&#24418;&#24335;&#65292;&#20026;&#35299;&#20915;&#36825;&#31867;&#38382;&#39064;&#25552;&#20379;&#20102;&#19968;&#20010;&#26694;&#26550;&#12290;&#20027;&#21160;&#20803;&#23398;&#20064;&#32773;&#30340;&#30446;&#26631;&#26159;&#22312;&#24403;&#21069;&#20219;&#21153;&#30340;&#29305;&#27530;&#29305;&#24449;&#65288;&#20219;&#21153;&#29305;&#23450;&#21442;&#25968;&#65289;&#30340;&#24773;&#20917;&#19979;&#33719;&#24471;&#21487;&#36716;&#31227;&#30340;&#30693;&#35782;&#65288;&#20272;&#35745;&#21487;&#36716;&#31227;&#30340;&#21442;&#25968;&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#36138;&#23146;&#36861;&#27714;&#36825;&#20010;&#30446;&#26631;&#23454;&#38469;&#19978;&#21487;&#33021;&#20250;&#25439;&#23475;&#23545;&#21487;&#36716;&#31227;&#21442;&#25968;&#30340;&#20272;&#35745;&#65288;&#24341;&#36215;&#25152;&#35859;&#30340;&#36127;&#36801;&#31227;&#65289;&#12290;&#23398;&#20064;&#32773;&#38754;&#20020;&#30528;&#19968;&#20010;&#31867;&#20284;&#20294;&#19981;&#21516;&#20110;&#21208;&#25506;-&#21033;&#29992;&#22256;&#22659;&#30340;&#22256;&#22659;&#65306;&#20182;&#20204;&#24212;&#35813;&#33457;&#36153;&#20182;&#20204;&#30340;&#33719;&#21462;&#39044;&#31639;&#26469;&#36861;&#27714;&#21487;&#36716;&#31227;&#30340;&#30693;&#35782;&#65292;&#36824;&#26159;&#29992;&#26469;&#30830;&#23450;&#24403;&#21069;&#20219;&#21153;&#29305;&#23450;&#30340;&#21442;&#25968;&#65311;&#25105;&#20204;&#29702;&#35770;&#19978;&#35777;&#26126;&#65292;&#19968;&#20123;&#20219;&#21153;&#23384;&#22312;&#19981;&#21487;&#36991;&#20813;&#19988;&#20219;&#24847;&#22823;&#30340;&#36127;&#36801;&#31227;&#23041;&#32961;&#65292;&#20219;&#21153;&#30340;&#35782;&#21035;&#23545;&#20110;&#37325;&#26032;&#23547;&#25214;&#21487;&#36801;&#31227;&#21442;&#25968;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many applications involve estimation of parameters that generalize across multiple diverse, but related, data-scarce task environments. Bayesian active meta-learning, a form of sequential optimal experimental design, provides a framework for solving such problems. The active meta-learner's goal is to gain transferable knowledge (estimate the transferable parameters) in the presence of idiosyncratic characteristics of the current task (task-specific parameters). We show that in such a setting, greedy pursuit of this goal can actually hurt estimation of the transferable parameters (induce so-called negative transfer). The learner faces a dilemma akin to but distinct from the exploration--exploitation dilemma: should they spend their acquisition budget pursuing transferable knowledge, or identifying the current task-specific parameters? We show theoretically that some tasks pose an inevitable and arbitrarily large threat of negative transfer, and that task identification is critical to re
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#19978;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#20146;&#21644;&#24230;&#35780;&#20998;&#36861;&#36394;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#38750;&#32447;&#24615;&#20256;&#25773;&#65292;&#23588;&#20854;&#20851;&#27880;&#35745;&#31639;&#26426;&#35270;&#35273;&#24212;&#29992;&#12290;&#23454;&#39564;&#35777;&#23454;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#21644;&#23545;&#24191;&#27867;&#24212;&#29992;&#30340;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.11439</link><description>&lt;p&gt;
&#36890;&#36807;&#38750;&#32447;&#24615;&#30740;&#31350;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Understanding deep neural networks through the lens of their non-linearity. (arXiv:2310.11439v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11439
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#19978;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#20146;&#21644;&#24230;&#35780;&#20998;&#36861;&#36394;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#38750;&#32447;&#24615;&#20256;&#25773;&#65292;&#23588;&#20854;&#20851;&#27880;&#35745;&#31639;&#26426;&#35270;&#35273;&#24212;&#29992;&#12290;&#23454;&#39564;&#35777;&#23454;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#21644;&#23545;&#24191;&#27867;&#24212;&#29992;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNN)&#30340;&#26174;&#33879;&#25104;&#21151;&#24120;&#24120;&#24402;&#22240;&#20110;&#23427;&#20204;&#30340;&#39640;&#34920;&#36798;&#33021;&#21147;&#21644;&#36817;&#20284;&#20219;&#24847;&#22797;&#26434;&#20989;&#25968;&#30340;&#33021;&#21147;&#12290;&#20107;&#23454;&#19978;&#65292;DNN&#26159;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#27169;&#22411;&#65292;&#20854;&#20013;&#24341;&#20837;&#30340;&#28608;&#27963;&#20989;&#25968;&#22312;&#20854;&#20013;&#36215;&#21040;&#20102;&#37325;&#35201;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#35768;&#22810;&#30740;&#31350;&#36890;&#36807;&#36817;&#20284;&#33021;&#21147;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;DNN&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#20294;&#37327;&#21270;DNN&#25110;&#20010;&#21035;&#28608;&#27963;&#20989;&#25968;&#30340;&#38750;&#32447;&#24615;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#24615;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22312;&#20855;&#20307;&#20851;&#27880;&#35745;&#31639;&#26426;&#35270;&#35273;&#24212;&#29992;&#20013;&#36861;&#36394;&#38750;&#32447;&#24615;&#20256;&#25773;&#30340;&#29702;&#35770;&#26377;&#25928;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#20146;&#21644;&#24230;&#35780;&#20998;&#20801;&#35768;&#25105;&#20204;&#28145;&#20837;&#20102;&#35299;&#21508;&#31181;&#19981;&#21516;&#20307;&#31995;&#32467;&#26500;&#21644;&#23398;&#20064;&#33539;&#24335;&#30340;&#20869;&#37096;&#24037;&#20316;&#21407;&#29702;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#22823;&#37327;&#30340;&#23454;&#39564;&#32467;&#26524;&#65292;&#31361;&#20986;&#20102;&#25152;&#25552;&#20986;&#30340;&#20146;&#21644;&#24230;&#35780;&#20998;&#30340;&#23454;&#38469;&#25928;&#29992;&#21644;&#28508;&#22312;&#24212;&#29992;&#30340;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The remarkable success of deep neural networks (DNN) is often attributed to their high expressive power and their ability to approximate functions of arbitrary complexity. Indeed, DNNs are highly non-linear models, and activation functions introduced into them are largely responsible for this. While many works studied the expressive power of DNNs through the lens of their approximation capabilities, quantifying the non-linearity of DNNs or of individual activation functions remains an open problem. In this paper, we propose the first theoretically sound solution to track non-linearity propagation in deep neural networks with a specific focus on computer vision applications. Our proposed affinity score allows us to gain insights into the inner workings of a wide range of different architectures and learning paradigms. We provide extensive experimental results that highlight the practical utility of the proposed affinity score and its potential for long-reaching applications.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20998;&#24067;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;&#20855;&#26377;&#32479;&#35745;&#26174;&#33879;&#24615;&#30340;&#22522;&#30784;&#27169;&#22411;&#30340;&#39118;&#38505;&#12290;&#36890;&#36807;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#30456;&#23545;&#27979;&#35797;&#26041;&#27861;&#65292;&#35813;&#26694;&#26550;&#32467;&#21512;&#20102;&#19968;&#38454;&#21644;&#20108;&#38454;&#38543;&#26426;&#20248;&#21183;&#65292;&#24182;&#20511;&#37492;&#20102;&#35745;&#37327;&#32463;&#27982;&#23398;&#21644;&#25968;&#23398;&#37329;&#34701;&#20013;&#24120;&#29992;&#30340;&#24179;&#22343;&#39118;&#38505;&#27169;&#22411;&#12290;&#22312;&#32473;&#23450;&#25351;&#23450;&#24230;&#37327;&#37327;&#21270;&#30340;&#38450;&#25252;&#26639;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#39118;&#38505;&#24847;&#35782;&#30340;&#22522;&#30784;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#12290;&#21463;&#25968;&#23398;&#37329;&#34701;&#20013;&#30340;&#25237;&#36164;&#32452;&#21512;&#20248;&#21270;&#21644;&#36873;&#25321;&#29702;&#35770;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#20026;&#27599;&#20010;&#27169;&#22411;&#23450;&#20041;&#20102;&#19968;&#20010;"&#24230;&#37327;&#32452;&#21512;"&#65292;&#24182;&#26681;&#25454;&#36825;&#20123;&#32452;&#21512;&#30340;&#38543;&#26426;&#20248;&#21183;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#12290;</title><link>http://arxiv.org/abs/2310.07132</link><description>&lt;p&gt;
&#22312;&#22522;&#30784;&#27169;&#22411;&#26102;&#20195;&#30340;&#39118;&#38505;&#35780;&#20272;&#21644;&#32479;&#35745;&#26174;&#33879;&#24615;
&lt;/p&gt;
&lt;p&gt;
Risk Assessment and Statistical Significance in the Age of Foundation Models. (arXiv:2310.07132v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07132
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20998;&#24067;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;&#20855;&#26377;&#32479;&#35745;&#26174;&#33879;&#24615;&#30340;&#22522;&#30784;&#27169;&#22411;&#30340;&#39118;&#38505;&#12290;&#36890;&#36807;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#30456;&#23545;&#27979;&#35797;&#26041;&#27861;&#65292;&#35813;&#26694;&#26550;&#32467;&#21512;&#20102;&#19968;&#38454;&#21644;&#20108;&#38454;&#38543;&#26426;&#20248;&#21183;&#65292;&#24182;&#20511;&#37492;&#20102;&#35745;&#37327;&#32463;&#27982;&#23398;&#21644;&#25968;&#23398;&#37329;&#34701;&#20013;&#24120;&#29992;&#30340;&#24179;&#22343;&#39118;&#38505;&#27169;&#22411;&#12290;&#22312;&#32473;&#23450;&#25351;&#23450;&#24230;&#37327;&#37327;&#21270;&#30340;&#38450;&#25252;&#26639;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#39118;&#38505;&#24847;&#35782;&#30340;&#22522;&#30784;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#12290;&#21463;&#25968;&#23398;&#37329;&#34701;&#20013;&#30340;&#25237;&#36164;&#32452;&#21512;&#20248;&#21270;&#21644;&#36873;&#25321;&#29702;&#35770;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#20026;&#27599;&#20010;&#27169;&#22411;&#23450;&#20041;&#20102;&#19968;&#20010;"&#24230;&#37327;&#32452;&#21512;"&#65292;&#24182;&#26681;&#25454;&#36825;&#20123;&#32452;&#21512;&#30340;&#38543;&#26426;&#20248;&#21183;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20998;&#24067;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;&#20855;&#26377;&#32479;&#35745;&#26174;&#33879;&#24615;&#30340;&#22522;&#30784;&#27169;&#22411;&#30340;&#31038;&#20250;&#25216;&#26415;&#39118;&#38505;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#19968;&#31181;&#22522;&#20110;&#23454;&#38469;&#38543;&#26426;&#21464;&#37327;&#30340;&#19968;&#38454;&#21644;&#20108;&#38454;&#38543;&#26426;&#20248;&#21183;&#30340;&#26032;&#30340;&#32479;&#35745;&#30456;&#23545;&#27979;&#35797;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#36825;&#20010;&#27979;&#35797;&#20013;&#30340;&#20108;&#38454;&#32479;&#35745;&#19982;&#22312;&#35745;&#37327;&#32463;&#27982;&#23398;&#21644;&#25968;&#23398;&#37329;&#34701;&#20013;&#24120;&#29992;&#30340;&#24179;&#22343;&#39118;&#38505;&#27169;&#22411;&#30456;&#32852;&#31995;&#65292;&#29992;&#20110;&#22312;&#36873;&#25321;&#26041;&#26696;&#26102;&#24179;&#34913;&#39118;&#38505;&#21644;&#25928;&#29992;&#12290;&#21033;&#29992;&#36825;&#20010;&#26694;&#26550;&#65292;&#25105;&#20204;&#27491;&#24335;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#39118;&#38505;&#24847;&#35782;&#30340;&#22522;&#30784;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#32473;&#23450;&#30001;&#25351;&#23450;&#24230;&#37327;&#37327;&#21270;&#30340;&#38450;&#25252;&#26639;&#12290;&#21463;&#25968;&#23398;&#37329;&#34701;&#20013;&#30340;&#25237;&#36164;&#32452;&#21512;&#20248;&#21270;&#21644;&#36873;&#25321;&#29702;&#35770;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#20026;&#27599;&#20010;&#27169;&#22411;&#23450;&#20041;&#20102;&#19968;&#20010;"&#24230;&#37327;&#32452;&#21512;"&#65292;&#20316;&#20026;&#32858;&#21512;&#19968;&#31995;&#21015;&#24230;&#37327;&#30340;&#25163;&#27573;&#65292;&#24182;&#26681;&#25454;&#36825;&#20123;&#32452;&#21512;&#30340;&#38543;&#26426;&#20248;&#21183;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#12290;&#25105;&#20204;&#30340;&#27979;&#35797;&#30340;&#32479;&#35745;&#26174;&#33879;&#24615;&#22312;&#29702;&#35770;&#19978;&#30001;&#36890;&#36807;&#20013;&#24515;&#26497;&#38480;&#30340;&#28176;&#36817;&#20998;&#26512;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a distributional framework for assessing socio-technical risks of foundation models with quantified statistical significance. Our approach hinges on a new statistical relative testing based on first and second order stochastic dominance of real random variables. We show that the second order statistics in this test are linked to mean-risk models commonly used in econometrics and mathematical finance to balance risk and utility when choosing between alternatives. Using this framework, we formally develop a risk-aware approach for foundation model selection given guardrails quantified by specified metrics. Inspired by portfolio optimization and selection theory in mathematical finance, we define a \emph{metrics portfolio} for each model as a means to aggregate a collection of metrics, and perform model selection based on the stochastic dominance of these portfolios. The statistical significance of our tests is backed theoretically by an asymptotic analysis via central limit th
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#21644;&#40065;&#26834;&#30340;&#26041;&#27861;&#26469;&#36817;&#20284;&#35745;&#31639;&#22810;&#20803;&#27491;&#24577;&#20998;&#24067;&#20043;&#38388;&#30340;Fisher-Rao&#36317;&#31163;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31867;&#22522;&#20110;&#27491;&#24577;&#27969;&#24418;&#23884;&#20837;&#21040;&#39640;&#32500;&#23545;&#31216;&#27491;&#23450;&#38181;&#23376;&#27969;&#24418;&#30340;&#36317;&#31163;&#12290;</title><link>http://arxiv.org/abs/2307.10644</link><description>&lt;p&gt;
Fisher-Rao&#36317;&#31163;&#21644;&#36870;&#25512;&#21040;SPD&#38181;&#36317;&#31163;&#22312;&#22810;&#20803;&#27491;&#24577;&#20998;&#24067;&#20043;&#38388;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Fisher-Rao distance and pullback SPD cone distances between multivariate normal distributions. (arXiv:2307.10644v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10644
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#21644;&#40065;&#26834;&#30340;&#26041;&#27861;&#26469;&#36817;&#20284;&#35745;&#31639;&#22810;&#20803;&#27491;&#24577;&#20998;&#24067;&#20043;&#38388;&#30340;Fisher-Rao&#36317;&#31163;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31867;&#22522;&#20110;&#27491;&#24577;&#27969;&#24418;&#23884;&#20837;&#21040;&#39640;&#32500;&#23545;&#31216;&#27491;&#23450;&#38181;&#23376;&#27969;&#24418;&#30340;&#36317;&#31163;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#31185;&#23398;&#39046;&#22495;&#65292;&#22914;&#25193;&#25955;&#24352;&#37327;&#25104;&#20687;&#12289;&#32467;&#26500;&#24352;&#37327;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#38647;&#36798;&#20449;&#21495;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#31561;&#65292;&#37117;&#23384;&#22312;&#30528;&#22810;&#20803;&#27491;&#24577;&#20998;&#24067;&#30340;&#25968;&#25454;&#38598;&#12290;&#20026;&#20102;&#22788;&#29702;&#36825;&#20123;&#27491;&#24577;&#25968;&#25454;&#38598;&#20197;&#36827;&#34892;&#36807;&#28388;&#12289;&#20998;&#31867;&#25110;&#32858;&#31867;&#31561;&#19979;&#28216;&#20219;&#21153;&#65292;&#38656;&#35201;&#23450;&#20041;&#21512;&#36866;&#30340;&#27491;&#24577;&#21644;&#23427;&#20204;&#20043;&#38388;&#30340;&#36335;&#24452;&#20043;&#38388;&#30340;&#24046;&#24322;&#24230;&#37327;&#12290;Fisher-Rao&#36317;&#31163;&#65292;&#20316;&#20026;Fisher&#20449;&#24687;&#24230;&#37327;&#24341;&#36215;&#30340;Riemann&#20960;&#20309;&#36317;&#31163;&#65292;&#26159;&#19968;&#31181;&#21512;&#29702;&#30340;&#24230;&#37327;&#36317;&#31163;&#65292;&#20294;&#38500;&#20102;&#19968;&#20123;&#29305;&#27530;&#24773;&#20917;&#22806;&#65292;&#24182;&#27809;&#26377;&#38381;&#24335;&#27714;&#35299;&#12290;&#26412;&#25991;&#39318;&#20808;&#25253;&#21578;&#20102;&#19968;&#31181;&#24555;&#36895;&#19988;&#40065;&#26834;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#31934;&#30830;&#22320;&#36817;&#20284;&#35745;&#31639;&#22810;&#20803;&#27491;&#24577;&#20998;&#24067;&#20043;&#38388;&#30340;Fisher-Rao&#36317;&#31163;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31867;&#22522;&#20110;&#27491;&#24577;&#27969;&#24418;&#21040;&#39640;&#32500;&#23545;&#31216;&#27491;&#23450;&#38181;&#30340;&#23376;&#27969;&#24418;&#30340;&#24494;&#20998;&#21516;&#32986;&#23884;&#20837;&#30340;&#36317;&#31163;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data sets of multivariate normal distributions abound in many scientific areas like diffusion tensor imaging, structure tensor computer vision, radar signal processing, machine learning, just to name a few. In order to process those normal data sets for downstream tasks like filtering, classification or clustering, one needs to define proper notions of dissimilarities between normals and paths joining them. The Fisher-Rao distance defined as the Riemannian geodesic distance induced by the Fisher information metric is such a principled metric distance which however is not known in closed-form excepts for a few particular cases. In this work, we first report a fast and robust method to approximate arbitrarily finely the Fisher-Rao distance between multivariate normal distributions. Second, we introduce a class of distances based on diffeomorphic embeddings of the normal manifold into a submanifold of the higher-dimensional symmetric positive-definite cone corresponding to the manifold of
&lt;/p&gt;</description></item><item><title>&#36817;&#26399;&#37327;&#23376;&#35774;&#22791;&#19978;&#30340;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#30528;&#37325;&#30740;&#31350;&#20102;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#22312;&#29616;&#23454;&#19990;&#30028;&#22330;&#26223;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#25506;&#31350;&#20102;&#24403;&#21069;&#37327;&#23376;&#30828;&#20214;&#19978;&#30340;QML&#23454;&#29616;&#30340;&#38480;&#21046;&#65292;&#24182;&#25552;&#20986;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#30340;&#25216;&#26415;&#12290;&#19982;&#32463;&#20856;&#23545;&#24212;&#29289;&#30456;&#27604;&#36739;&#65292;&#36825;&#20123;QML&#23454;&#29616;&#30340;&#24615;&#33021;&#24471;&#21040;&#20102;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2307.00908</link><description>&lt;p&gt;
&#36817;&#26399;&#37327;&#23376;&#35013;&#32622;&#19978;&#30340;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;: &#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#25216;&#26415;&#22312;&#29616;&#23454;&#19990;&#30028;&#24212;&#29992;&#30340;&#29616;&#29366;
&lt;/p&gt;
&lt;p&gt;
Quantum Machine Learning on Near-Term Quantum Devices: Current State of Supervised and Unsupervised Techniques for Real-World Applications. (arXiv:2307.00908v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00908
&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#37327;&#23376;&#35774;&#22791;&#19978;&#30340;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#30528;&#37325;&#30740;&#31350;&#20102;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#22312;&#29616;&#23454;&#19990;&#30028;&#22330;&#26223;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#25506;&#31350;&#20102;&#24403;&#21069;&#37327;&#23376;&#30828;&#20214;&#19978;&#30340;QML&#23454;&#29616;&#30340;&#38480;&#21046;&#65292;&#24182;&#25552;&#20986;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#30340;&#25216;&#26415;&#12290;&#19982;&#32463;&#20856;&#23545;&#24212;&#29289;&#30456;&#27604;&#36739;&#65292;&#36825;&#20123;QML&#23454;&#29616;&#30340;&#24615;&#33021;&#24471;&#21040;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#21313;&#24180;&#20013;&#65292;&#37327;&#23376;&#30828;&#20214;&#22312;&#36895;&#24230;&#12289;&#37327;&#23376;&#27604;&#29305;&#25968;&#37327;&#21644;&#37327;&#23376;&#20307;&#31215;&#26041;&#38754;&#21462;&#24471;&#20102;&#30456;&#24403;&#22823;&#30340;&#36827;&#23637;&#65292;&#37327;&#23376;&#20307;&#31215;&#34987;&#23450;&#20041;&#20026;&#22312;&#36817;&#26399;&#37327;&#23376;&#35774;&#22791;&#19978;&#21487;&#20197;&#26377;&#25928;&#23454;&#29616;&#30340;&#37327;&#23376;&#30005;&#36335;&#30340;&#26368;&#22823;&#35268;&#27169;&#12290;&#22240;&#27492;&#65292;&#22312;&#23454;&#38469;&#30828;&#20214;&#19978;&#24212;&#29992;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;(QML)&#20197;&#23454;&#29616;&#37327;&#23376;&#20248;&#21183;&#24050;&#32463;&#26377;&#20102;&#24456;&#22823;&#30340;&#22686;&#38271;&#12290;&#22312;&#36825;&#31687;&#32508;&#36848;&#20013;&#65292;&#25105;&#20204;&#20027;&#35201;&#20851;&#27880;&#22312;&#37327;&#23376;&#30828;&#20214;&#19978;&#23454;&#29616;&#30340;&#36873;&#23450;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#24212;&#29992;&#65292;&#29305;&#21035;&#38024;&#23545;&#29616;&#23454;&#19990;&#30028;&#22330;&#26223;&#12290;&#25105;&#20204;&#25506;&#35752;&#24182;&#24378;&#35843;&#20102;QML&#22312;&#37327;&#23376;&#30828;&#20214;&#19978;&#30340;&#24403;&#21069;&#38480;&#21046;&#12290;&#25105;&#20204;&#28145;&#20837;&#35752;&#35770;&#20102;&#21508;&#31181;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#30340;&#25216;&#26415;&#65292;&#22914;&#32534;&#30721;&#25216;&#26415;&#12289;&#22522;&#24577;&#32467;&#26500;&#12289;&#35823;&#24046;&#34917;&#20607;&#21644;&#26799;&#24230;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#36825;&#20123;QML&#23454;&#29616;&#19982;&#23427;&#20204;&#30340;&#32463;&#20856;&#23545;&#24212;&#29289;&#20043;&#38388;&#30340;&#24615;&#33021;&#23545;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
The past decade has seen considerable progress in quantum hardware in terms of the speed, number of qubits and quantum volume which is defined as the maximum size of a quantum circuit that can be effectively implemented on a near-term quantum device. Consequently, there has also been a rise in the number of works based on the applications of Quantum Machine Learning (QML) on real hardware to attain quantum advantage over their classical counterparts. In this survey, our primary focus is on selected supervised and unsupervised learning applications implemented on quantum hardware, specifically targeting real-world scenarios. Our survey explores and highlights the current limitations of QML implementations on quantum hardware. We delve into various techniques to overcome these limitations, such as encoding techniques, ansatz structure, error mitigation, and gradient methods. Additionally, we assess the performance of these QML implementations in comparison to their classical counterparts
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#36890;&#29992;&#30340;&#25968;&#25454;&#38598;&#36716;&#31227;&#26465;&#20214;&#19979;&#65292;&#21033;&#29992;&#21322;&#21442;&#25968;&#25928;&#29575;&#29702;&#35770;&#65292;&#39640;&#25928;&#20272;&#35745;&#30446;&#26631;&#24635;&#20307;&#39118;&#38505;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.16406</link><description>&lt;p&gt;
&#36890;&#29992;&#24418;&#24335;&#19979;&#30340;&#39640;&#25928;&#19988;&#22810;&#37325;&#31283;&#20581;&#30340;&#39118;&#38505;&#20272;&#35745;&#26041;&#27861;&#22312;&#25968;&#25454;&#36716;&#31227;&#20013;
&lt;/p&gt;
&lt;p&gt;
Efficient and Multiply Robust Risk Estimation under General Forms of Dataset Shift. (arXiv:2306.16406v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16406
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#36890;&#29992;&#30340;&#25968;&#25454;&#38598;&#36716;&#31227;&#26465;&#20214;&#19979;&#65292;&#21033;&#29992;&#21322;&#21442;&#25968;&#25928;&#29575;&#29702;&#35770;&#65292;&#39640;&#25928;&#20272;&#35745;&#30446;&#26631;&#24635;&#20307;&#39118;&#38505;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32479;&#35745;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#32463;&#24120;&#38754;&#20020;&#26469;&#33258;&#24863;&#20852;&#36259;&#24635;&#20307;&#30340;&#26377;&#38480;&#25968;&#25454;&#30340;&#25361;&#25112;&#12290;&#19968;&#31181;&#35299;&#20915;&#26041;&#27861;&#26159;&#21033;&#29992;&#26469;&#33258;&#36741;&#21161;&#28304;&#24635;&#20307;&#30340;&#25968;&#25454;&#65292;&#36825;&#20123;&#25968;&#25454;&#19982;&#30446;&#26631;&#39046;&#22495;&#30340;&#26576;&#20123;&#26465;&#20214;&#20998;&#24067;&#30456;&#21516;&#25110;&#20197;&#20854;&#20182;&#26041;&#24335;&#30456;&#36830;&#12290;&#21033;&#29992;&#36825;&#31181;"&#25968;&#25454;&#36716;&#31227;"&#26465;&#20214;&#30340;&#25216;&#26415;&#34987;&#31216;&#20026;"&#39046;&#22495;&#36866;&#24212;"&#25110;"&#36801;&#31227;&#23398;&#20064;"&#12290;&#23613;&#31649;&#26377;&#22823;&#37327;&#20851;&#20110;&#25968;&#25454;&#36716;&#31227;&#30340;&#25991;&#29486;&#65292;&#20294;&#24456;&#23569;&#26377;&#30740;&#31350;&#25506;&#35752;&#22914;&#20309;&#26377;&#25928;&#21033;&#29992;&#36741;&#21161;&#24635;&#20307;&#26469;&#25552;&#39640;&#30446;&#26631;&#24635;&#20307;&#19978;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#39118;&#38505;&#35780;&#20272;&#30340;&#20934;&#30830;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#21322;&#21442;&#25968;&#25928;&#29575;&#29702;&#35770;&#30740;&#31350;&#20102;&#22312;&#19981;&#21516;&#30340;&#25968;&#25454;&#38598;&#36716;&#31227;&#26465;&#20214;&#19979;&#39640;&#25928;&#20272;&#35745;&#30446;&#26631;&#24635;&#20307;&#39118;&#38505;&#30340;&#19968;&#33324;&#38382;&#39064;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31867;&#36890;&#29992;&#30340;&#25968;&#25454;&#38598;&#36716;&#31227;&#26465;&#20214;&#65292;&#20854;&#20013;&#21253;&#25324;&#19977;&#31181;&#27969;&#34892;&#26465;&#20214;&#8212;&#8212;&#21327;&#21464;&#37327;&#12289;&#26631;&#31614;&#21644;&#27010;&#24565;&#36716;&#31227;&#8212;&#8212;&#20316;&#20026;&#29305;&#20363;&#12290;&#25105;&#20204;&#20801;&#35768;&#37096;&#20998;&#38750;&#37325;&#21472;&#12290;
&lt;/p&gt;
&lt;p&gt;
Statistical machine learning methods often face the challenge of limited data available from the population of interest. One remedy is to leverage data from auxiliary source populations, which share some conditional distributions or are linked in other ways with the target domain. Techniques leveraging such \emph{dataset shift} conditions are known as \emph{domain adaptation} or \emph{transfer learning}. Despite extensive literature on dataset shift, limited works address how to efficiently use the auxiliary populations to improve the accuracy of risk evaluation for a given machine learning task in the target population.  In this paper, we study the general problem of efficiently estimating target population risk under various dataset shift conditions, leveraging semiparametric efficiency theory. We consider a general class of dataset shift conditions, which includes three popular conditions -- covariate, label and concept shift -- as special cases. We allow for partially non-overlappi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#32852;&#37030;&#23398;&#20064;&#35774;&#23450;&#65292;&#25506;&#35752;&#20102;&#36890;&#20449;&#27425;&#25968;&#23545;&#27867;&#21270;&#35823;&#24046;&#30340;&#24433;&#21709;&#65292;&#24182;&#24314;&#31435;&#20102;PAC-Bayes&#21644;&#29575;&#22833;&#30495;&#29702;&#35770;&#38480;&#21046;&#65292;&#36825;&#20123;&#38480;&#21046;&#23545;&#24191;&#27867;&#30340;&#25439;&#22833;&#20989;&#25968;&#21644;&#23398;&#20064;&#31639;&#27861;&#36866;&#29992;&#12290;</title><link>http://arxiv.org/abs/2306.05862</link><description>&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#65306;&#20943;&#23569;&#36890;&#20449;&#27425;&#25968;&#65281;
&lt;/p&gt;
&lt;p&gt;
Federated Learning You May Communicate Less Often!. (arXiv:2306.05862v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05862
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#32852;&#37030;&#23398;&#20064;&#35774;&#23450;&#65292;&#25506;&#35752;&#20102;&#36890;&#20449;&#27425;&#25968;&#23545;&#27867;&#21270;&#35823;&#24046;&#30340;&#24433;&#21709;&#65292;&#24182;&#24314;&#31435;&#20102;PAC-Bayes&#21644;&#29575;&#22833;&#30495;&#29702;&#35770;&#38480;&#21046;&#65292;&#36825;&#20123;&#38480;&#21046;&#23545;&#24191;&#27867;&#30340;&#25439;&#22833;&#20989;&#25968;&#21644;&#23398;&#20064;&#31639;&#27861;&#36866;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#32852;&#37030;&#23398;&#20064;(Federated Learning, FL)&#27169;&#22411;&#22312;&#19968;&#33324;&#24615;&#30340;&#35774;&#32622;&#19979;&#30340;&#27867;&#21270;&#35823;&#24046;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#23458;&#25143;&#31471;&#21644;&#21442;&#25968;&#26381;&#21153;&#22120;&#20043;&#38388;&#36890;&#20449;&#27425;&#25968;&#30340;&#27867;&#21270;&#35823;&#24046;&#28436;&#21464;&#65292;&#21363;&#23458;&#25143;&#31471;&#35745;&#31639;&#30340;&#26412;&#22320;&#27169;&#22411;&#22312;&#21442;&#25968;&#26381;&#21153;&#22120;&#19978;&#21512;&#24182;&#30340;&#39057;&#29575;&#23545;&#27867;&#21270;&#35823;&#24046;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;PAC-Bayes&#21644;&#29575;&#22833;&#30495;&#29702;&#35770;&#23545;&#27867;&#21270;&#35823;&#24046;&#30340;&#38480;&#21046;&#65292;&#26126;&#30830;&#32771;&#34385;&#36890;&#20449;&#27425;&#25968;&#23545;&#35823;&#24046;&#30340;&#24433;&#21709;&#65292;&#21478;&#22806;&#36824;&#32771;&#34385;&#20102;&#21442;&#19982;&#35774;&#22791;&#25968;&#37327;K&#21644;&#20010;&#20154;&#25968;&#25454;&#38598;&#22823;&#23567;n&#23545;&#35823;&#24046;&#30340;&#24433;&#21709;&#12290;&#36825;&#20123;&#38480;&#21046;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#25439;&#22833;&#20989;&#25968;&#21644;&#23398;&#20064;&#31639;&#27861;&#65292;&#20284;&#20046;&#26159;FL&#35774;&#32622;&#20013;&#39318;&#27425;&#20986;&#29616;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#38480;&#21046;&#24212;&#29992;&#20110;FL&#31867;&#22411;&#30340;&#25903;&#25345;&#21521;&#37327;&#26426;(FSVM)&#65307;&#25105;&#20204;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#25512;&#23548;&#20102;&#26356;&#26126;&#30830;&#30340;&#27867;&#21270;&#35823;&#24046;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the generalization error of statistical learning models in a Federated Learning (FL) setting. Specifically, we study the evolution of the generalization error with the number of communication rounds between the clients and the parameter server, i.e., the effect on the generalization error of how often the local models as computed by the clients are aggregated at the parameter server. We establish PAC-Bayes and rate-distortion theoretic bounds on the generalization error that account explicitly for the effect of the number of rounds, say $ R \in \mathbb{N}$, in addition to the number of participating devices $K$ and individual datasets size $n$. The bounds, which apply in their generality for a large class of loss functions and learning algorithms, appear to be the first of their kind for the FL setting. Furthermore, we apply our bounds to FL-type Support Vector Machines (FSVM); and we derive (more) explicit bounds on the generalization error in this case. In particular, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#33258;&#25105;&#30417;&#30563;&#30340;&#26041;&#24335;&#20174;&#25968;&#25454;&#28857;&#20013;&#26631;&#35782;&#20449;&#24687;&#37327;&#20016;&#23500;&#30340;&#29305;&#24449;&#65292;&#35774;&#35745;&#20102;&#19968;&#20010;&#27169;&#22411;&#21644;&#38376;&#30697;&#38453;&#26469;&#39044;&#27979;&#21487;&#35299;&#37322;&#30340;&#23454;&#20363;&#21644;&#32858;&#31867;&#32423;&#21035;&#30340;&#32858;&#31867;&#20998;&#37197;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#20013;&#39564;&#35777;&#20102;&#20854;&#21487;&#38752;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.04785</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#28145;&#24230;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Interpretable Deep Clustering. (arXiv:2306.04785v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04785
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#33258;&#25105;&#30417;&#30563;&#30340;&#26041;&#24335;&#20174;&#25968;&#25454;&#28857;&#20013;&#26631;&#35782;&#20449;&#24687;&#37327;&#20016;&#23500;&#30340;&#29305;&#24449;&#65292;&#35774;&#35745;&#20102;&#19968;&#20010;&#27169;&#22411;&#21644;&#38376;&#30697;&#38453;&#26469;&#39044;&#27979;&#21487;&#35299;&#37322;&#30340;&#23454;&#20363;&#21644;&#32858;&#31867;&#32423;&#21035;&#30340;&#32858;&#31867;&#20998;&#37197;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#20013;&#39564;&#35777;&#20102;&#20854;&#21487;&#38752;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32858;&#31867;&#26159;&#19968;&#39033;&#24191;&#27867;&#24212;&#29992;&#20110;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#22522;&#30784;&#23398;&#20064;&#20219;&#21153;&#12290;&#20363;&#22914;&#65292;&#29983;&#29289;&#23398;&#23478;&#32463;&#24120;&#20351;&#29992;&#32858;&#31867;&#20998;&#37197;&#26469;&#20998;&#26512;&#22522;&#22240;&#32452;&#24207;&#21015;&#12289;&#21307;&#30103;&#35760;&#24405;&#25110;&#22270;&#20687;&#12290;&#30001;&#20110;&#19979;&#28216;&#20998;&#26512;&#36890;&#24120;&#22312;&#32858;&#31867;&#32423;&#21035;&#19978;&#25191;&#34892;&#65292;&#22240;&#27492;&#20174;&#19994;&#32773;&#23547;&#27714;&#21487;&#38752;&#19988;&#21487;&#35299;&#37322;&#30340;&#32858;&#31867;&#27169;&#22411;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#23427;&#21487;&#20197;&#39044;&#27979;&#21487;&#35299;&#37322;&#30340;&#23454;&#20363;&#21644;&#32858;&#31867;&#32423;&#21035;&#30340;&#32858;&#31867;&#20998;&#37197;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#19968;&#20010;&#33258;&#25105;&#30417;&#30563;&#30340;&#36807;&#31243;&#26469;&#20174;&#27599;&#20010;&#25968;&#25454;&#28857;&#20013;&#26631;&#35782;&#20986;&#19968;&#32452;&#20449;&#24687;&#37327;&#20016;&#23500;&#30340;&#29305;&#24449;&#23376;&#38598;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#27169;&#22411;&#65292;&#29992;&#20110;&#39044;&#27979;&#32858;&#31867;&#20998;&#37197;&#21644;&#19968;&#20010;&#38376;&#30697;&#38453;&#65292;&#29992;&#20110;&#24341;&#23548;&#32858;&#31867;&#32423;&#21035;&#30340;&#29305;&#24449;&#36873;&#25321;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#20351;&#29992;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#21487;&#38752;&#22320;&#39044;&#27979;&#32858;&#31867;&#20998;&#37197;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#21487;&#20197;&#22312;&#23454;&#20363;&#21644;&#32858;&#31867;&#32423;&#21035;&#19978;&#20135;&#29983;&#21487;&#35299;&#37322;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Clustering is a fundamental learning task widely used as a first step in data analysis. For example, biologists often use cluster assignments to analyze genome sequences, medical records, or images. Since downstream analysis is typically performed at the cluster level, practitioners seek reliable and interpretable clustering models. We propose a new deep-learning framework that predicts interpretable cluster assignments at the instance and cluster levels. First, we present a self-supervised procedure to identify a subset of informative features from each data point. Then, we design a model that predicts cluster assignments and a gate matrix that leads to cluster-level feature selection. We show that the proposed method can reliably predict cluster assignments using synthetic and real data. Furthermore, we verify that our model leads to interpretable results at a sample and cluster level.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#38750;&#32447;&#24615;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#19968;&#31867;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807; Gateaux Derivative &#22788;&#29702;&#19968;&#33324;&#39118;&#38505;&#24230;&#37327;&#12290;&#32463;&#36807;&#23454;&#39564;&#39564;&#35777;&#65292;&#35813;&#26041;&#27861;&#25104;&#21151;&#22788;&#29702;&#20998;&#24067;&#30340;&#38750;&#32447;&#24615;&#30446;&#26631;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2306.03202</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Nonlinear Distributionally Robust Optimization. (arXiv:2306.03202v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03202
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#38750;&#32447;&#24615;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#19968;&#31867;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807; Gateaux Derivative &#22788;&#29702;&#19968;&#33324;&#39118;&#38505;&#24230;&#37327;&#12290;&#32463;&#36807;&#23454;&#39564;&#39564;&#35777;&#65292;&#35813;&#26041;&#27861;&#25104;&#21151;&#22788;&#29702;&#20998;&#24067;&#30340;&#38750;&#32447;&#24615;&#30446;&#26631;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#19968;&#31867;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;DRO&#65289;&#38382;&#39064;&#65292;&#20854;&#20013;&#30446;&#26631;&#20989;&#25968;&#22312;&#20998;&#24067;&#19978;&#21487;&#33021;&#26159;&#38750;&#32447;&#24615;&#30340;&#65292;&#36825;&#19982;&#29616;&#26377;&#30340;&#25991;&#29486;&#26377;&#25152;&#19981;&#21516;&#12290;&#20026;&#35299;&#20915;&#22312;&#27010;&#29575;&#31354;&#38388;&#20013;&#20248;&#21270;&#38750;&#32447;&#24615;&#20989;&#25968;&#38754;&#20020;&#30340;&#29702;&#35770;&#21644;&#35745;&#31639;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;Derivative&#21644;&#30456;&#24212;&#30340;&#24179;&#28369;&#24230;&#27010;&#24565;&#65292;&#22522;&#20110;Gateaux Derivative&#26469;&#22788;&#29702;&#19968;&#33324;&#39118;&#38505;&#24230;&#37327;&#12290;&#25105;&#20204;&#36890;&#36807;Var&#12289;entropic risk&#21644;&#26377;&#38480;&#25903;&#25345;&#38598;&#19978;&#30340;&#19977;&#20010;&#36816;&#34892;&#39118;&#38505;&#24230;&#37327;&#31034;&#20363;&#26469;&#35299;&#37322;&#36825;&#20123;&#27010;&#24565;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20026;&#27010;&#29575;&#31354;&#38388;&#20013;&#19968;&#33324;&#38750;&#32447;&#24615;&#20248;&#21270;&#38382;&#39064;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;G-derivative&#30340;Frank-Wolfe&#65288;FW&#65289;&#31639;&#27861;&#65292;&#24182;&#20197;&#23436;&#20840;&#29420;&#31435;&#20110;&#33539;&#25968;&#30340;&#26041;&#24335;&#25512;&#23548;&#20986;&#20854;&#25910;&#25947;&#24615;&#22312;&#25552;&#20986;&#30340;&#24179;&#28369;&#24230;&#27010;&#24565;&#19979;&#12290;&#25105;&#20204;&#21033;&#29992;FW&#31639;&#27861;&#30340;&#35774;&#32622;&#26469;&#35774;&#35745;&#19968;&#31181;&#35745;&#31639;&#38750;&#32447;&#24615;DRO&#38382;&#39064;&#38797;&#28857;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#22788;&#29702;&#20998;&#24067;&#30340;&#38750;&#32447;&#24615;&#30446;&#26631;&#20989;&#25968;&#30340;&#25104;&#21151;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article focuses on a class of distributionally robust optimization (DRO) problems where, unlike the growing body of the literature, the objective function is potentially non-linear in the distribution. Existing methods to optimize nonlinear functions in probability space use the Frechet derivatives, which present both theoretical and computational challenges. Motivated by this, we propose an alternative notion for the derivative and corresponding smoothness based on Gateaux (G)-derivative for generic risk measures. These concepts are explained via three running risk measure examples of variance, entropic risk, and risk on finite support sets. We then propose a G-derivative based Frank-Wolfe~(FW) algorithm for generic non-linear optimization problems in probability spaces and establish its convergence under the proposed notion of smoothness in a completely norm-independent manner. We use the set-up of the FW algorithm to devise a methodology to compute a saddle point of the non-lin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#38543;&#26426;&#20989;&#25968;&#19979;&#38477;(RFD)&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#38543;&#26426;&#29615;&#22659;&#20013;&#35745;&#31639;&#20986;&#27493;&#38271;&#24182;&#19988;&#19982;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30456;&#21516;&#12290;&#22312;&#21512;&#25104;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;RFD&#31639;&#27861;&#27604;&#26410;&#35843;&#25972;&#30340;Adam&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#65292;&#25552;&#20986;&#30340;heuristic&#25193;&#23637;&#21487;&#19982;&#35843;&#25972;&#21518;&#30340;Adam&#26041;&#27861;&#30456;&#23218;&#32654;&#12290;</title><link>http://arxiv.org/abs/2305.01377</link><description>&lt;p&gt;
&#38543;&#26426;&#20989;&#25968;&#19979;&#38477;&#27861;
&lt;/p&gt;
&lt;p&gt;
Random Function Descent. (arXiv:2305.01377v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01377
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#38543;&#26426;&#20989;&#25968;&#19979;&#38477;(RFD)&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#38543;&#26426;&#29615;&#22659;&#20013;&#35745;&#31639;&#20986;&#27493;&#38271;&#24182;&#19988;&#19982;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30456;&#21516;&#12290;&#22312;&#21512;&#25104;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;RFD&#31639;&#27861;&#27604;&#26410;&#35843;&#25972;&#30340;Adam&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#65292;&#25552;&#20986;&#30340;heuristic&#25193;&#23637;&#21487;&#19982;&#35843;&#25972;&#21518;&#30340;Adam&#26041;&#27861;&#30456;&#23218;&#32654;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#21313;&#20998;&#24120;&#35265;&#65292;&#20294;&#26159;&#36873;&#25321;&#27491;&#30830;&#30340;&#27493;&#38271;&#32463;&#24120;&#38656;&#35201;&#36827;&#34892;&#8220;&#36229;&#21442;&#25968;&#35843;&#25972;&#8221;&#12290;&#36825;&#26159;&#22240;&#20026;&#22238;&#28335;&#31243;&#24207;&#22914;Armijo's&#20934;&#21017;&#20381;&#36182;&#20110;&#27599;&#20010;&#27493;&#39588;&#20013;&#30340;&#36136;&#37327;&#35780;&#20272;&#65292;&#32780;&#36825;&#20123;&#35780;&#20272;&#22312;&#38543;&#26426;&#24773;&#20917;&#19979;&#19981;&#21487;&#29992;&#12290;&#30001;&#20110;&#20248;&#21270;&#26041;&#26696;&#21487;&#20197;&#29992;Taylor&#36924;&#36817;&#26469;&#35299;&#37322;&#65292;&#25105;&#20204;&#23558;Taylor&#36924;&#36817;&#26367;&#25442;&#20026;&#26465;&#20214;&#26399;&#26395;&#65288;&#26368;&#20339;&#30340;$L^2$&#20272;&#35745;&#65289;&#65292;&#25552;&#20986;&#20102;&#8220;&#38543;&#26426;&#20989;&#25968;&#19979;&#38477;&#8221;&#65288;RFD&#65289;&#12290; &#22312;Bayesian&#20248;&#21270;&#20013;&#24120;&#35265;&#30340;&#19968;&#20123;&#36731;&#24494;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;RFD&#19982;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#26159;&#30456;&#21516;&#30340;&#65292;&#20294;&#26159;&#22312;&#38543;&#26426;&#24773;&#20917;&#19979;&#20855;&#26377;&#21487;&#35745;&#31639;&#30340;&#27493;&#38271;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#22522;&#20934;&#27979;&#35797;&#20013;&#27604;&#26410;&#35843;&#25972;&#30340;Adam&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#12290;&#20026;&#20102;&#32553;&#23567;&#19982;&#35843;&#25972;&#21518;&#30340;Adam&#31639;&#27861;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#36317;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21551;&#21457;&#24335;&#25193;&#23637;&#65292;&#21487;&#19982;&#35843;&#25972;&#21518;&#30340;Adam&#26041;&#27861;&#30456;&#23218;&#32654;&#12290;
&lt;/p&gt;
&lt;p&gt;
While gradient based methods are ubiquitous in machine learning, selecting the right step size often requires "hyperparameter tuning". This is because backtracking procedures like Armijo's rule depend on quality evaluations in every step, which are not available in a stochastic context. Since optimization schemes can be motivated using Taylor approximations, we replace the Taylor approximation with the conditional expectation (the best $L^2$ estimator) and propose "Random Function Descent" (RFD). Under light assumptions common in Bayesian optimization, we prove that RFD is identical to gradient descent, but with calculable step sizes, even in a stochastic context. We beat untuned Adam in synthetic benchmarks. To close the performance gap to tuned Adam, we propose a heuristic extension competitive with tuned Adam.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23457;&#35745;&#26694;&#26550;&#65292;&#33021;&#22815;&#20197;&#20840;&#38754;&#30340;&#26041;&#24335;&#35780;&#20272;&#21512;&#25104;&#25968;&#25454;&#21644;AI&#27169;&#22411;&#30340;&#20855;&#20307;&#25928;&#26524;&#65292;&#21253;&#25324;&#20559;&#35265;&#21644;&#27495;&#35270;&#39044;&#38450;&#12289;&#23545;&#30495;&#23454;&#25968;&#25454;&#30340;&#24544;&#23454;&#31243;&#24230;&#12289;&#25928;&#29992;&#12289;&#40065;&#26834;&#24615;&#21644;&#38544;&#31169;&#20445;&#25252;&#12290;&#22312;&#22810;&#20010;&#29992;&#20363;&#20013;&#65292;&#23457;&#35745;&#26694;&#26550;&#24179;&#34913;&#20102;&#20449;&#20219;&#21644;&#25928;&#29992;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2304.10819</link><description>&lt;p&gt;
&#21487;&#25511;&#30340;&#20449;&#20219;&#26435;&#34913;&#19979;&#30340;&#21512;&#25104;&#25968;&#25454;&#23457;&#35745;&#19982;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Auditing and Generating Synthetic Data with Controllable Trust Trade-offs. (arXiv:2304.10819v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10819
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23457;&#35745;&#26694;&#26550;&#65292;&#33021;&#22815;&#20197;&#20840;&#38754;&#30340;&#26041;&#24335;&#35780;&#20272;&#21512;&#25104;&#25968;&#25454;&#21644;AI&#27169;&#22411;&#30340;&#20855;&#20307;&#25928;&#26524;&#65292;&#21253;&#25324;&#20559;&#35265;&#21644;&#27495;&#35270;&#39044;&#38450;&#12289;&#23545;&#30495;&#23454;&#25968;&#25454;&#30340;&#24544;&#23454;&#31243;&#24230;&#12289;&#25928;&#29992;&#12289;&#40065;&#26834;&#24615;&#21644;&#38544;&#31169;&#20445;&#25252;&#12290;&#22312;&#22810;&#20010;&#29992;&#20363;&#20013;&#65292;&#23457;&#35745;&#26694;&#26550;&#24179;&#34913;&#20102;&#20449;&#20219;&#21644;&#25928;&#29992;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#23454;&#20013;&#25910;&#38598;&#30340;&#25968;&#25454;&#24448;&#24448;&#23384;&#22312;&#20559;&#24046;&#12289;&#19981;&#24179;&#34913;&#65292;&#24182;&#19988;&#26377;&#27844;&#38706;&#25935;&#24863;&#21644;&#38544;&#31169;&#20449;&#24687;&#30340;&#39118;&#38505;&#12290;&#36825;&#19968;&#20107;&#23454;&#24341;&#21457;&#20102;&#21019;&#24314;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#24819;&#27861;&#65292;&#20197;&#20943;&#36731;&#30495;&#23454;&#25968;&#25454;&#20013;&#22266;&#26377;&#30340;&#39118;&#38505;&#12289;&#20559;&#35265;&#12289;&#20260;&#23475;&#21644;&#38544;&#31169;&#38382;&#39064;&#12290;&#36825;&#20010;&#27010;&#24565;&#20381;&#36182;&#20110;&#29983;&#25104;AI&#27169;&#22411;&#65292;&#20197;&#20135;&#29983;&#19981;&#20559;&#25191;&#12289;&#20445;&#25252;&#38544;&#31169;&#30340;&#21512;&#25104;&#25968;&#25454;&#65292;&#21516;&#26102;&#24544;&#23454;&#20110;&#30495;&#23454;&#25968;&#25454;&#12290;&#22312;&#36825;&#31181;&#26032;&#33539;&#24335;&#20013;&#65292;&#25105;&#20204;&#22914;&#20309;&#30693;&#36947;&#36825;&#31181;&#26041;&#27861;&#26159;&#21542;&#20817;&#29616;&#20102;&#20854;&#25215;&#35834;&#65311;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23457;&#35745;&#26694;&#26550;&#65292;&#25552;&#20379;&#20102;&#23545;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#22522;&#20110;&#23427;&#20204;&#35757;&#32451;&#30340;AI&#27169;&#22411;&#30340;&#20840;&#38754;&#35780;&#20272;&#65292;&#22260;&#32469;&#20559;&#35265;&#21644;&#27495;&#35270;&#30340;&#39044;&#38450;&#12289;&#23545;&#30495;&#23454;&#25968;&#25454;&#30340;&#24544;&#23454;&#31243;&#24230;&#12289;&#25928;&#29992;&#12289;&#40065;&#26834;&#24615;&#21644;&#38544;&#31169;&#20445;&#25252;&#12290;&#25105;&#20204;&#36890;&#36807;&#23457;&#35745;&#22810;&#20010;&#29983;&#25104;&#27169;&#22411;&#22312;&#19981;&#21516;&#29992;&#20363;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#65292;&#21253;&#25324;&#25945;&#32946;&#12289;&#21307;&#30103;&#20445;&#20581;&#12289;&#38134;&#34892;&#12289;&#20154;&#21147;&#36164;&#28304;&#65292;&#20197;&#21450;&#20174;&#34920;&#26684;&#65292;&#26102;&#38388;&#24207;&#21015;&#21040;&#33258;&#28982;&#35821;&#35328;&#30340;&#19981;&#21516;&#27169;&#24577;&#12290;&#25105;&#20204;&#30340;&#29992;&#20363;&#23637;&#31034;&#20102;&#22312;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#20013;&#24179;&#34913;&#20449;&#20219;&#21644;&#25928;&#29992;&#30340;&#26435;&#34913;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data collected from the real world tends to be biased, unbalanced, and at risk of exposing sensitive and private information. This reality has given rise to the idea of creating synthetic datasets to alleviate risk, bias, harm, and privacy concerns inherent in the real data. This concept relies on Generative AI models to produce unbiased, privacy-preserving synthetic data while being true to the real data. In this new paradigm, how can we tell if this approach delivers on its promises? We present an auditing framework that offers a holistic assessment of synthetic datasets and AI models trained on them, centered around bias and discrimination prevention, fidelity to the real data, utility, robustness, and privacy preservation. We showcase our framework by auditing multiple generative models on diverse use cases, including education, healthcare, banking, human resources, and across different modalities, from tabular, to time-series, to natural language. Our use cases demonstrate the imp
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#38416;&#36848;&#20102;&#26080;&#20813;&#36153;&#21320;&#39184;&#23450;&#29702;&#30340;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#38480;&#21046;&#65292;&#35777;&#26126;&#20102;&#24402;&#32435;&#20559;&#24046;&#21487;&#20197;&#25552;&#39640;&#23398;&#20064;&#31639;&#27861;&#30340;&#25928;&#26524;&#65292;&#24182;&#19988;&#23637;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#20559;&#22909;&#19982;&#29616;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#20998;&#24067;&#30456;&#20851;&#12290;</title><link>http://arxiv.org/abs/2304.05366</link><description>&lt;p&gt;
&#12298;&#26080;&#20813;&#36153;&#21320;&#39184;&#23450;&#29702;&#12289;&#31185;&#23572;&#33707;&#25096;&#27931;&#22827;&#22797;&#26434;&#24615;&#21450;&#24402;&#32435;&#20559;&#24046;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20316;&#29992;&#12299;
&lt;/p&gt;
&lt;p&gt;
The No Free Lunch Theorem, Kolmogorov Complexity, and the Role of Inductive Biases in Machine Learning. (arXiv:2304.05366v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05366
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#38416;&#36848;&#20102;&#26080;&#20813;&#36153;&#21320;&#39184;&#23450;&#29702;&#30340;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#38480;&#21046;&#65292;&#35777;&#26126;&#20102;&#24402;&#32435;&#20559;&#24046;&#21487;&#20197;&#25552;&#39640;&#23398;&#20064;&#31639;&#27861;&#30340;&#25928;&#26524;&#65292;&#24182;&#19988;&#23637;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#20559;&#22909;&#19982;&#29616;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#20998;&#24067;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30417;&#30563;&#23398;&#20064;&#30340;&#26080;&#20813;&#36153;&#21320;&#39184;&#23450;&#29702;&#25351;&#20986;&#65292;&#27809;&#26377;&#19968;&#20010;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#35299;&#20915;&#25152;&#26377;&#38382;&#39064;&#65292;&#25110;&#32773;&#25152;&#26377;&#23398;&#20064;&#31639;&#27861;&#22312;&#22343;&#21248;&#20998;&#24067;&#30340;&#23398;&#20064;&#38382;&#39064;&#19978;&#24179;&#22343;&#31934;&#24230;&#36798;&#21040;&#23436;&#20840;&#30456;&#21516;&#12290;&#22240;&#27492;&#65292;&#36825;&#20123;&#23450;&#29702;&#32463;&#24120;&#34987;&#24341;&#29992;&#26469;&#25903;&#25345;&#20010;&#21035;&#38382;&#39064;&#38656;&#35201;&#29305;&#21035;&#23450;&#21046;&#30340;&#24402;&#32435;&#20559;&#24046;&#30340;&#27010;&#24565;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#23613;&#31649;&#20960;&#20046;&#25152;&#26377;&#22343;&#21248;&#37319;&#26679;&#30340;&#25968;&#25454;&#38598;&#20855;&#26377;&#39640;&#22797;&#26434;&#24615;&#65292;&#20294;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#38382;&#39064;&#19981;&#25104;&#27604;&#20363;&#22320;&#20135;&#29983;&#20302;&#22797;&#26434;&#24230;&#30340;&#25968;&#25454;&#65292;&#24182;&#19988;&#25105;&#20204;&#35748;&#20026;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20063;&#20855;&#26377;&#21516;&#26679;&#30340;&#20559;&#22909;&#65292;&#36825;&#31181;&#20559;&#22909;&#20351;&#29992;&#31185;&#23572;&#33707;&#25096;&#27931;&#22827;&#22797;&#26434;&#24230;&#36827;&#34892;&#20102;&#24418;&#24335;&#21270;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20026;&#29305;&#23450;&#39046;&#22495;&#35774;&#35745;&#30340;&#20307;&#31995;&#32467;&#26500;&#65292;&#20363;&#22914;&#35745;&#31639;&#26426;&#35270;&#35273;&#65292;&#21487;&#20197;&#21387;&#32553;&#21508;&#31181;&#30475;&#20284;&#19981;&#30456;&#20851;&#30340;&#39046;&#22495;&#30340;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#39044;&#20808;&#35757;&#32451;&#21644;&#21363;&#20351;&#26159;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#35821;&#35328;&#27169;&#22411;&#37117;&#26356;&#21916;&#27426;&#29983;&#25104;&#20302;&#22797;&#26434;&#24230;&#30340;&#24207;&#21015;&#12290;&#23613;&#31649;&#26080;&#20813;&#36153;&#21320;&#39184;&#23450;&#29702;&#20284;&#20046;&#34920;&#26126;&#21508;&#20010;&#38382;&#39064;&#38656;&#35201;&#19987;&#38376;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#20294;&#25105;&#20204;&#35299;&#37322;&#35828;&#65292;&#23398;&#20064;&#31639;&#27861;&#36890;&#24120;&#21487;&#20197;&#36890;&#36807;&#32534;&#30721;&#20851;&#20110;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#20998;&#24067;&#30340;&#20808;&#21069;&#30693;&#35782;&#30340;&#24402;&#32435;&#20559;&#24046;&#26469;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
No free lunch theorems for supervised learning state that no learner can solve all problems or that all learners achieve exactly the same accuracy on average over a uniform distribution on learning problems. Accordingly, these theorems are often referenced in support of the notion that individual problems require specially tailored inductive biases. While virtually all uniformly sampled datasets have high complexity, real-world problems disproportionately generate low-complexity data, and we argue that neural network models share this same preference, formalized using Kolmogorov complexity. Notably, we show that architectures designed for a particular domain, such as computer vision, can compress datasets on a variety of seemingly unrelated domains. Our experiments show that pre-trained and even randomly initialized language models prefer to generate low-complexity sequences. Whereas no free lunch theorems seemingly indicate that individual problems require specialized learners, we exp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;PAC-Bayesian bound&#20316;&#20026;Soft Actor-Critic (SAC)&#31639;&#27861;&#35780;&#35770;&#23478;&#35757;&#32451;&#30446;&#26631;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#35757;&#32451;&#19981;&#31283;&#23450;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#35780;&#35770;&#23478;&#24341;&#23548;&#30340;&#38543;&#26426;&#25628;&#32034;&#25506;&#32034;&#22810;&#20010;&#26410;&#26469;&#26469;&#25552;&#39640;&#22312;&#32447;&#23398;&#20064;&#24615;&#33021;&#12290;&#22312;&#22810;&#20010;&#32463;&#20856;&#25511;&#21046;&#21644;&#36816;&#21160;&#20219;&#21153;&#20013;&#65292;&#35813;&#31639;&#27861;&#20855;&#26377;&#26679;&#26412;&#25928;&#29575;&#21644;&#36951;&#25022;&#26368;&#23567;&#21270;&#26041;&#38754;&#30340;&#26126;&#26174;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2301.12776</link><description>&lt;p&gt;
PAC-Bayesian&#36719;&#28436;&#21592;-&#35780;&#35770;&#23478;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
PAC-Bayesian Soft Actor-Critic Learning. (arXiv:2301.12776v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12776
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;PAC-Bayesian bound&#20316;&#20026;Soft Actor-Critic (SAC)&#31639;&#27861;&#35780;&#35770;&#23478;&#35757;&#32451;&#30446;&#26631;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#35757;&#32451;&#19981;&#31283;&#23450;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#35780;&#35770;&#23478;&#24341;&#23548;&#30340;&#38543;&#26426;&#25628;&#32034;&#25506;&#32034;&#22810;&#20010;&#26410;&#26469;&#26469;&#25552;&#39640;&#22312;&#32447;&#23398;&#20064;&#24615;&#33021;&#12290;&#22312;&#22810;&#20010;&#32463;&#20856;&#25511;&#21046;&#21644;&#36816;&#21160;&#20219;&#21153;&#20013;&#65292;&#35813;&#31639;&#27861;&#20855;&#26377;&#26679;&#26412;&#25928;&#29575;&#21644;&#36951;&#25022;&#26368;&#23567;&#21270;&#26041;&#38754;&#30340;&#26126;&#26174;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28436;&#21592;-&#35780;&#35770;&#23478;&#31639;&#27861;&#36890;&#36807;&#20004;&#20010;&#20998;&#21035;&#20316;&#31574;&#30053;&#35780;&#20272;&#21644;&#25913;&#36827;&#30340;&#21151;&#33021;&#36924;&#36817;&#22120;&#26469;&#35299;&#20915;&#22686;&#24378;&#23398;&#20064;(RL)&#30340;&#21452;&#37325;&#30446;&#26631;&#12290;&#27492;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#26159;&#20197;&#35757;&#32451;&#19981;&#31283;&#23450;&#20026;&#20195;&#20215;&#30340;&#65292;&#20027;&#35201;&#21407;&#22240;&#26159;&#35780;&#35770;&#23478;&#36924;&#36817;&#35823;&#24046;&#23545;&#28436;&#21592;&#30340;&#30772;&#22351;&#24615;&#24433;&#21709;&#12290;&#25105;&#20204;&#36890;&#36807;&#39318;&#27425;&#37319;&#29992;&#19968;&#20010;&#29616;&#26377;&#30340;&#21487;&#33021;&#36817;&#20284;&#27491;&#30830;(PAC)Bayesian&#30028;&#38480;&#20316;&#20026;Soft Actor-Critic (SAC)&#31639;&#27861;&#30340;&#35780;&#35770;&#23478;&#35757;&#32451;&#30446;&#26631;&#26469;&#35299;&#20915;&#36825;&#20010;&#29942;&#39048;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#24403;&#38543;&#26426;&#28436;&#21592;&#36890;&#36807;&#35780;&#35770;&#23478;&#24341;&#23548;&#30340;&#38543;&#26426;&#25628;&#32034;&#25506;&#32034;&#22810;&#20010;&#26410;&#26469;&#26102;&#65292;&#22312;&#32447;&#23398;&#20064;&#24615;&#33021;&#26174;&#33879;&#25552;&#39640;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#25105;&#20204;&#24471;&#21040;&#30340;&#31639;&#27861;&#22312;&#22810;&#20010;&#32463;&#20856;&#25511;&#21046;&#21644;&#36816;&#21160;&#20219;&#21153;&#20013;&#65292;&#22312;&#26679;&#26412;&#25928;&#29575;&#21644;&#36951;&#25022;&#26368;&#23567;&#21270;&#26041;&#38754;&#19982;&#29616;&#26377;&#25216;&#26415;&#30456;&#27604;&#20855;&#26377;&#26126;&#26174;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Actor-critic algorithms address the dual goals of reinforcement learning (RL), policy evaluation and improvement, via two separate function approximators. The practicality of this approach comes at the expense of training instability, caused mainly by the destructive effect of the approximation errors of the critic on the actor. We tackle this bottleneck by employing an existing Probably Approximately Correct (PAC) Bayesian bound for the first time as the critic training objective of the Soft Actor-Critic (SAC) algorithm. We further demonstrate that online learning performance improves significantly when a stochastic actor explores multiple futures by critic-guided random search. We observe our resulting algorithm to compare favorably to the state of the art on multiple classical control and locomotion tasks in terms of both sample efficiency and regret minimization.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#27835;&#30103;&#31038;&#21306;&#20013;&#30340;&#21516;&#20276;&#24433;&#21709;&#25110;&#35282;&#33394;&#27169;&#22411;&#25928;&#24212;&#23545;&#20110;&#25104;&#21151;&#27605;&#19994;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#20998;&#26512;&#19977;&#20010;&#27835;&#30103;&#31038;&#21306;&#30340;&#35266;&#23519;&#25968;&#25454;&#65292;&#25105;&#20204;&#21457;&#29616;&#32943;&#23450;&#30340;&#21516;&#20276;&#20132;&#27969;&#23545;&#20110;&#23621;&#27665;&#22312;&#33258;&#24049;&#31163;&#24320;&#20043;&#21069;&#25104;&#21151;&#27605;&#19994;&#19982;&#21542;&#26377;&#26174;&#33879;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2203.14223</link><description>&lt;p&gt;
&#22312;&#27835;&#30103;&#31038;&#21306;&#20013;&#35782;&#21035;&#21516;&#20276;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Identifying Peer Influence in Therapeutic Communities. (arXiv:2203.14223v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.14223
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#27835;&#30103;&#31038;&#21306;&#20013;&#30340;&#21516;&#20276;&#24433;&#21709;&#25110;&#35282;&#33394;&#27169;&#22411;&#25928;&#24212;&#23545;&#20110;&#25104;&#21151;&#27605;&#19994;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#20998;&#26512;&#19977;&#20010;&#27835;&#30103;&#31038;&#21306;&#30340;&#35266;&#23519;&#25968;&#25454;&#65292;&#25105;&#20204;&#21457;&#29616;&#32943;&#23450;&#30340;&#21516;&#20276;&#20132;&#27969;&#23545;&#20110;&#23621;&#27665;&#22312;&#33258;&#24049;&#31163;&#24320;&#20043;&#21069;&#25104;&#21151;&#27605;&#19994;&#19982;&#21542;&#26377;&#26174;&#33879;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#22312;&#27835;&#30103;&#31038;&#21306;&#20013;&#26159;&#21542;&#23384;&#22312;&#21516;&#20276;&#24433;&#21709;&#25110;&#35282;&#33394;&#27169;&#22411;&#25928;&#24212;&#23545;&#20110;&#25104;&#21151;&#27605;&#19994;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;3&#20010;&#20445;&#30041;&#20102;&#23621;&#27665;&#20043;&#38388;&#30830;&#35748;&#21644;&#20462;&#27491;&#20132;&#27969;&#35760;&#24405;&#20197;&#21450;&#20182;&#20204;&#20837;&#20303;&#21644;&#31163;&#24320;&#26085;&#26399;&#30340;&#27835;&#30103;&#31038;&#21306;&#30340;&#21311;&#21517;&#20010;&#20307;&#35266;&#23519;&#25968;&#25454;&#12290;&#36825;&#20123;&#30830;&#35748;&#20132;&#27969;&#20351;&#25105;&#20204;&#33021;&#22815;&#24418;&#25104;&#21516;&#20276;&#32593;&#32476;&#65292;&#32780;&#20837;&#20303;&#21644;&#31163;&#24320;&#26085;&#26399;&#20351;&#25105;&#20204;&#33021;&#22815;&#23450;&#20041;&#24863;&#20852;&#36259;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#25105;&#20204;&#23558;&#22240;&#26524;&#35282;&#33394;&#27169;&#22411;&#25928;&#24212;&#27010;&#24565;&#21270;&#20026;&#23621;&#27665;&#65288;&#33258;&#25105;&#65289;&#35266;&#23519;&#21040;&#20182;&#20204;&#30340;&#26576;&#20010;&#31038;&#20132;&#32852;&#31995;&#20154;&#65288;&#20363;&#22914;&#65292;&#32473;&#20104;&#32943;&#23450;&#30340;&#21516;&#20276;&#65289;&#22312;&#33258;&#25105;&#31163;&#24320;&#20043;&#21069;&#25104;&#21151;&#27605;&#19994;&#19982;&#19981;&#25104;&#21151;&#27605;&#19994;&#30340;&#39044;&#26399;&#32467;&#26524;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#30001;&#20110;&#21516;&#20276;&#24433;&#21709;&#36890;&#24120;&#19982;&#35266;&#23519;&#25968;&#25454;&#20013;&#26410;&#35266;&#23519;&#21040;&#30340;&#21516;&#36136;&#24615;&#28151;&#28102;&#65292;&#25105;&#20204;&#20351;&#29992;&#28508;&#21464;&#37327;&#27169;&#22411;&#23545;&#32593;&#32476;&#36827;&#34892;&#24314;&#27169;&#20197;&#20272;&#35745;&#21516;&#36136;&#24615;&#24182;&#23558;&#20854;&#21253;&#21547;&#22312;&#32467;&#26524;&#26041;&#31243;&#20013;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#20445;&#35777;&#65292;&#23427;&#21487;&#20197;&#35299;&#20915;&#32593;&#32476;&#20013;&#30340;&#20869;&#29983;&#24615;&#38382;&#39064;&#24182;&#25552;&#20379;&#19968;&#33268;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate if there is a peer influence or role model effect on successful graduation from Therapeutic Communities (TCs). We analyze anonymized individual-level observational data from 3 TCs that kept records of written exchanges of affirmations and corrections among residents, and their precise entry and exit dates. The affirmations allow us to form peer networks, and the entry and exit dates allow us to define a causal effect of interest. We conceptualize the causal role model effect as measuring the difference in the expected outcome of a resident (ego) who can observe one of their social contacts (e.g., peers who gave affirmations), to be successful in graduating before the ego's exit vs not successfully graduating before the ego's exit. Since peer influence is usually confounded with unobserved homophily in observational data, we model the network with a latent variable model to estimate homophily and include it in the outcome equation. We provide a theoretical guarantee that 
&lt;/p&gt;</description></item><item><title>&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#37117;&#21487;&#20197;&#24402;&#32467;&#20026;&#36125;&#21494;&#26031;&#23398;&#20064;&#35268;&#21017;&#65292;&#35813;&#35268;&#21017;&#36890;&#36807;&#21033;&#29992;&#33258;&#28982;&#26799;&#24230;&#26469;&#36924;&#36817;&#21518;&#39564;&#20998;&#24067;&#65292;&#20174;&#32780;&#24471;&#21040;&#24191;&#27867;&#30340;&#31639;&#27861;&#24212;&#29992;&#12290;&#36825;&#19968;&#24037;&#20316;&#19981;&#20165;&#32479;&#19968;&#20102;&#29616;&#26377;&#31639;&#27861;&#65292;&#36824;&#24110;&#21161;&#25105;&#20204;&#35774;&#35745;&#26032;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2107.04562</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#23398;&#20064;&#35268;&#21017;
&lt;/p&gt;
&lt;p&gt;
The Bayesian Learning Rule. (arXiv:2107.04562v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.04562
&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#37117;&#21487;&#20197;&#24402;&#32467;&#20026;&#36125;&#21494;&#26031;&#23398;&#20064;&#35268;&#21017;&#65292;&#35813;&#35268;&#21017;&#36890;&#36807;&#21033;&#29992;&#33258;&#28982;&#26799;&#24230;&#26469;&#36924;&#36817;&#21518;&#39564;&#20998;&#24067;&#65292;&#20174;&#32780;&#24471;&#21040;&#24191;&#27867;&#30340;&#31639;&#27861;&#24212;&#29992;&#12290;&#36825;&#19968;&#24037;&#20316;&#19981;&#20165;&#32479;&#19968;&#20102;&#29616;&#26377;&#31639;&#27861;&#65292;&#36824;&#24110;&#21161;&#25105;&#20204;&#35774;&#35745;&#26032;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#26159;&#19968;&#20010;&#31216;&#20026;&#36125;&#21494;&#26031;&#23398;&#20064;&#35268;&#21017;&#30340;&#21333;&#19968;&#31639;&#27861;&#30340;&#29305;&#20363;&#12290;&#36825;&#20010;&#35268;&#21017;&#26159;&#20174;&#36125;&#21494;&#26031;&#21407;&#29702;&#25512;&#23548;&#20986;&#26469;&#30340;&#65292;&#21487;&#20197;&#20174;&#20248;&#21270;&#12289;&#28145;&#24230;&#23398;&#20064;&#21644;&#22270;&#24418;&#27169;&#22411;&#31561;&#39046;&#22495;&#24471;&#21040;&#24191;&#27867;&#30340;&#31639;&#27861;&#12290;&#36825;&#21253;&#25324;&#32463;&#20856;&#31639;&#27861;&#22914;&#23725;&#22238;&#24402;&#12289;&#29275;&#39039;&#27861;&#21644;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65292;&#20197;&#21450;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#22914;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#12289;RMSprop&#21644;Dropout&#12290;&#25512;&#23548;&#36825;&#20123;&#31639;&#27861;&#30340;&#20851;&#38190;&#24605;&#24819;&#26159;&#20351;&#29992;&#33258;&#28982;&#26799;&#24230;&#20272;&#35745;&#30340;&#20505;&#36873;&#20998;&#24067;&#26469;&#36924;&#36817;&#21518;&#39564;&#20998;&#24067;&#12290;&#19981;&#21516;&#30340;&#20505;&#36873;&#20998;&#24067;&#20250;&#23548;&#33268;&#19981;&#21516;&#30340;&#31639;&#27861;&#65292;&#23545;&#33258;&#28982;&#26799;&#24230;&#30340;&#36827;&#19968;&#27493;&#36924;&#36817;&#21017;&#20250;&#20135;&#29983;&#36825;&#20123;&#31639;&#27861;&#30340;&#21464;&#31181;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#19981;&#20165;&#32479;&#19968;&#12289;&#27867;&#21270;&#21644;&#25913;&#36827;&#20102;&#29616;&#26377;&#31639;&#27861;&#65292;&#36824;&#24110;&#21161;&#25105;&#20204;&#35774;&#35745;&#26032;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show that many machine-learning algorithms are specific instances of a single algorithm called the Bayesian learning rule. The rule, derived from Bayesian principles, yields a wide-range of algorithms from fields such as optimization, deep learning, and graphical models. This includes classical algorithms such as ridge regression, Newton's method, and Kalman filter, as well as modern deep-learning algorithms such as stochastic-gradient descent, RMSprop, and Dropout. The key idea in deriving such algorithms is to approximate the posterior using candidate distributions estimated by using natural gradients. Different candidate distributions result in different algorithms and further approximations to natural gradients give rise to variants of those algorithms. Our work not only unifies, generalizes, and improves existing algorithms, but also helps us design new ones.
&lt;/p&gt;</description></item></channel></rss>