<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21521;&#38543;&#26426;Kaczmarz&#31639;&#27861;&#20013;&#28155;&#21152;&#20960;&#20309;&#24179;&#28369;&#21160;&#37327;&#30340;&#25928;&#26524;&#65292;&#24182;&#35777;&#26126;&#20102;&#20851;&#20110;&#26368;&#23567;&#20108;&#20056;&#25439;&#22833;&#30697;&#38453;&#22855;&#24322;&#21521;&#37327;&#26041;&#21521;&#19978;&#30340;&#26399;&#26395;&#35823;&#24046;&#12290;&#25968;&#20540;&#31034;&#20363;&#35777;&#26126;&#20102;&#32467;&#26524;&#30340;&#23454;&#29992;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#20960;&#20010;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.09415</link><description>&lt;p&gt;
&#20855;&#26377;&#20960;&#20309;&#24179;&#28369;&#21160;&#37327;&#30340;&#38543;&#26426;Kaczmarz&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Randomized Kaczmarz with geometrically smoothed momentum. (arXiv:2401.09415v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09415
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21521;&#38543;&#26426;Kaczmarz&#31639;&#27861;&#20013;&#28155;&#21152;&#20960;&#20309;&#24179;&#28369;&#21160;&#37327;&#30340;&#25928;&#26524;&#65292;&#24182;&#35777;&#26126;&#20102;&#20851;&#20110;&#26368;&#23567;&#20108;&#20056;&#25439;&#22833;&#30697;&#38453;&#22855;&#24322;&#21521;&#37327;&#26041;&#21521;&#19978;&#30340;&#26399;&#26395;&#35823;&#24046;&#12290;&#25968;&#20540;&#31034;&#20363;&#35777;&#26126;&#20102;&#32467;&#26524;&#30340;&#23454;&#29992;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#20960;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21521;&#38543;&#26426;Kaczmarz&#31639;&#27861;&#20013;&#28155;&#21152;&#20960;&#20309;&#24179;&#28369;&#21160;&#37327;&#30340;&#25928;&#26524;&#65292;&#35813;&#31639;&#27861;&#26159;&#32447;&#24615;&#26368;&#23567;&#20108;&#20056;&#25439;&#22833;&#20989;&#25968;&#19978;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#23454;&#20363;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20851;&#20110;&#23450;&#20041;&#26368;&#23567;&#20108;&#20056;&#25439;&#22833;&#30340;&#30697;&#38453;&#30340;&#22855;&#24322;&#21521;&#37327;&#26041;&#21521;&#19978;&#26399;&#26395;&#35823;&#24046;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#20960;&#20010;&#25968;&#20540;&#31034;&#20363;&#26469;&#35828;&#26126;&#25105;&#20204;&#32467;&#26524;&#30340;&#23454;&#29992;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#20960;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the effect of adding geometrically smoothed momentum to the randomized Kaczmarz algorithm, which is an instance of stochastic gradient descent on a linear least squares loss function. We prove a result about the expected error in the direction of singular vectors of the matrix defining the least squares loss. We present several numerical examples illustrating the utility of our result and pose several questions.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#36866;&#24212;Hui-Walter&#33539;&#24335;&#65292;&#23558;&#20256;&#32479;&#24212;&#29992;&#20110;&#27969;&#34892;&#30149;&#23398;&#21644;&#21307;&#23398;&#30340;&#26041;&#27861;&#24341;&#20837;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#65292;&#35299;&#20915;&#20102;&#35757;&#32451;&#21644;&#35780;&#20272;&#26102;&#26080;&#27861;&#33719;&#24471;&#26631;&#31614;&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#23558;&#25968;&#25454;&#21010;&#20998;&#20026;&#28508;&#22312;&#31867;&#21035;&#65292;&#24182;&#22312;&#22810;&#20010;&#27979;&#35797;&#20013;&#29420;&#31435;&#35757;&#32451;&#27169;&#22411;&#65292;&#33021;&#22815;&#22312;&#27809;&#26377;&#30495;&#23454;&#20540;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#20851;&#38190;&#24615;&#33021;&#25351;&#26631;&#65292;&#24182;&#22312;&#22788;&#29702;&#22312;&#32447;&#25968;&#25454;&#26102;&#25552;&#20379;&#20102;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.09376</link><description>&lt;p&gt;
&#35299;&#38145;&#26080;&#26631;&#31614;&#25968;&#25454;: Hui-Walter&#33539;&#24335;&#22312;&#22312;&#32447;&#21644;&#38745;&#24577;&#29615;&#22659;&#20013;&#30340;&#24615;&#33021;&#35780;&#20272;&#20013;&#30340;&#38598;&#25104;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Unlocking Unlabeled Data: Ensemble Learning with the Hui- Walter Paradigm for Performance Estimation in Online and Static Settings. (arXiv:2401.09376v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09376
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#36866;&#24212;Hui-Walter&#33539;&#24335;&#65292;&#23558;&#20256;&#32479;&#24212;&#29992;&#20110;&#27969;&#34892;&#30149;&#23398;&#21644;&#21307;&#23398;&#30340;&#26041;&#27861;&#24341;&#20837;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#65292;&#35299;&#20915;&#20102;&#35757;&#32451;&#21644;&#35780;&#20272;&#26102;&#26080;&#27861;&#33719;&#24471;&#26631;&#31614;&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#23558;&#25968;&#25454;&#21010;&#20998;&#20026;&#28508;&#22312;&#31867;&#21035;&#65292;&#24182;&#22312;&#22810;&#20010;&#27979;&#35797;&#20013;&#29420;&#31435;&#35757;&#32451;&#27169;&#22411;&#65292;&#33021;&#22815;&#22312;&#27809;&#26377;&#30495;&#23454;&#20540;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#20851;&#38190;&#24615;&#33021;&#25351;&#26631;&#65292;&#24182;&#22312;&#22788;&#29702;&#22312;&#32447;&#25968;&#25454;&#26102;&#25552;&#20379;&#20102;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#24314;&#27169;&#39046;&#22495;&#65292;&#20174;&#19994;&#20154;&#21592;&#24120;&#24120;&#22312;&#21487;&#35780;&#20272;&#21644;&#35757;&#32451;&#30340;&#20551;&#35774;&#19979;&#24037;&#20316;&#65292;&#21363;&#21487;&#35775;&#38382;&#30340;&#12289;&#38745;&#24577;&#30340;&#12289;&#24102;&#26377;&#26631;&#31614;&#30340;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#36825;&#20010;&#20551;&#35774;&#24448;&#24448;&#20559;&#31163;&#20102;&#29616;&#23454;&#65292;&#20854;&#20013;&#30340;&#25968;&#25454;&#21487;&#33021;&#26159;&#31169;&#26377;&#30340;&#12289;&#21152;&#23494;&#30340;&#12289;&#38590;&#20197;&#27979;&#37327;&#30340;&#25110;&#32773;&#27809;&#26377;&#26631;&#31614;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;&#20256;&#32479;&#24212;&#29992;&#20110;&#27969;&#34892;&#30149;&#23398;&#21644;&#21307;&#23398;&#30340;Hui-Walter&#33539;&#24335;&#35843;&#25972;&#21040;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#26469;&#24357;&#21512;&#36825;&#20010;&#24046;&#36317;&#12290;&#36825;&#31181;&#26041;&#27861;&#20351;&#25105;&#20204;&#33021;&#22815;&#22312;&#27809;&#26377;&#30495;&#23454;&#20540;&#21487;&#29992;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#20851;&#38190;&#24615;&#33021;&#25351;&#26631;&#65292;&#22914;&#20551;&#38451;&#24615;&#29575;&#12289;&#20551;&#38452;&#24615;&#29575;&#21644;&#20808;&#39564;&#27010;&#29575;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25193;&#23637;&#20102;&#36825;&#31181;&#33539;&#24335;&#26469;&#22788;&#29702;&#22312;&#32447;&#25968;&#25454;&#65292;&#24320;&#36767;&#20102;&#21160;&#24577;&#25968;&#25454;&#29615;&#22659;&#30340;&#26032;&#21487;&#33021;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#23558;&#25968;&#25454;&#21010;&#20998;&#20026;&#28508;&#22312;&#31867;&#21035;&#65292;&#20197;&#27169;&#25311;&#22810;&#20010;&#25968;&#25454;&#32676;&#20307;&#65288;&#22914;&#26524;&#27809;&#26377;&#33258;&#28982;&#32676;&#20307;&#21487;&#29992;&#65289;&#65292;&#24182;&#29420;&#31435;&#35757;&#32451;&#27169;&#22411;&#26469;&#22797;&#21046;&#22810;&#27425;&#27979;&#35797;&#12290;&#36890;&#36807;&#22312;&#19981;&#21516;&#25968;&#25454;&#23376;&#38598;&#20043;&#38388;&#20132;&#21449;&#21046;&#34920;&#65292;&#25105;&#20204;&#33021;&#22815;&#27604;&#36739;&#20108;&#20803;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the realm of machine learning and statistical modeling, practitioners often work under the assumption of accessible, static, labeled data for evaluation and training. However, this assumption often deviates from reality where data may be private, encrypted, difficult- to-measure, or unlabeled. In this paper, we bridge this gap by adapting the Hui-Walter paradigm, a method traditionally applied in epidemiology and medicine, to the field of machine learning. This approach enables us to estimate key performance metrics such as false positive rate, false negative rate, and priors in scenarios where no ground truth is available. We further extend this paradigm for handling online data, opening up new possibilities for dynamic data environments. Our methodology involves partitioning data into latent classes to simulate multiple data populations (if natural populations are unavailable) and independently training models to replicate multiple tests. By cross-tabulating binary outcomes across
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#24182;&#34892;&#38543;&#26426;&#20248;&#21270;&#23454;&#29616;&#39640;&#32622;&#20449;&#27700;&#24179;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23569;&#37327;&#29420;&#31435;&#22810;&#27425;&#36816;&#34892;&#33719;&#21462;&#20998;&#24067;&#20449;&#24687;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#65292;&#20960;&#20046;&#19981;&#38656;&#35201;&#39069;&#22806;&#35745;&#31639;&#21644;&#20869;&#23384;&#65292;&#20855;&#26377;&#39640;&#25928;&#35745;&#31639;&#21644;&#24555;&#36895;&#25910;&#25947;&#30340;&#29305;&#28857;&#12290;</title><link>http://arxiv.org/abs/2401.09346</link><description>&lt;p&gt;
&#20351;&#29992;&#24182;&#34892;&#38543;&#26426;&#20248;&#21270;&#20960;&#20046;&#20813;&#36153;&#23454;&#29616;&#39640;&#32622;&#20449;&#27700;&#24179;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
High Confidence Level Inference is Almost Free using Parallel Stochastic Optimization. (arXiv:2401.09346v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09346
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#24182;&#34892;&#38543;&#26426;&#20248;&#21270;&#23454;&#29616;&#39640;&#32622;&#20449;&#27700;&#24179;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23569;&#37327;&#29420;&#31435;&#22810;&#27425;&#36816;&#34892;&#33719;&#21462;&#20998;&#24067;&#20449;&#24687;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#65292;&#20960;&#20046;&#19981;&#38656;&#35201;&#39069;&#22806;&#35745;&#31639;&#21644;&#20869;&#23384;&#65292;&#20855;&#26377;&#39640;&#25928;&#35745;&#31639;&#21644;&#24555;&#36895;&#25910;&#25947;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22312;&#22312;&#32447;&#29615;&#22659;&#20013;&#36890;&#36807;&#38543;&#26426;&#20248;&#21270;&#35299;&#20915;&#26041;&#26696;&#36827;&#34892;&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#22791;&#21463;&#20851;&#27880;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25512;&#29702;&#26041;&#27861;&#65292;&#19987;&#27880;&#20110;&#26500;&#24314;&#20855;&#26377;&#39640;&#25928;&#35745;&#31639;&#21644;&#24555;&#36895;&#25910;&#25947;&#21040;&#21517;&#20041;&#27700;&#24179;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;&#23569;&#37327;&#29420;&#31435;&#30340;&#22810;&#27425;&#36816;&#34892;&#33719;&#21462;&#20998;&#24067;&#20449;&#24687;&#24182;&#26500;&#24314;&#22522;&#20110;t&#20998;&#24067;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#38500;&#20102;&#26631;&#20934;&#20272;&#35745;&#30340;&#26356;&#26032;&#20043;&#22806;&#65292;&#20960;&#20046;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#35745;&#31639;&#21644;&#20869;&#23384;&#65292;&#20351;&#25512;&#29702;&#36807;&#31243;&#20960;&#20046;&#20813;&#36153;&#12290;&#25105;&#20204;&#23545;&#32622;&#20449;&#21306;&#38388;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#35777;&#26126;&#20102;&#35206;&#30422;&#29575;&#20960;&#20046;&#30830;&#20999;&#65292;&#20855;&#26377;&#26126;&#30830;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#39640;&#32622;&#20449;&#27700;&#24179;&#30340;&#25512;&#26029;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#20026;&#22312;&#32447;&#20272;&#35745;&#22120;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#39640;&#26031;&#25311;&#21512;&#32467;&#26524;&#65292;&#20197;&#30456;&#23545;&#35823;&#24046;&#30340;&#26041;&#24335;&#34920;&#24449;&#20102;&#25105;&#20204;&#32622;&#20449;&#21306;&#38388;&#30340;&#35206;&#30422;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty quantification for estimation through stochastic optimization solutions in an online setting has gained popularity recently. This paper introduces a novel inference method focused on constructing confidence intervals with efficient computation and fast convergence to the nominal level. Specifically, we propose to use a small number of independent multi-runs to acquire distribution information and construct a t-based confidence interval. Our method requires minimal additional computation and memory beyond the standard updating of estimates, making the inference process almost cost-free. We provide a rigorous theoretical guarantee for the confidence interval, demonstrating that the coverage is approximately exact with an explicit convergence rate and allowing for high confidence level inference. In particular, a new Gaussian approximation result is developed for the online estimators to characterize the coverage properties of our confidence intervals in terms of relative erro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23545;&#20004;&#26102;&#38388;&#23610;&#24230;&#38543;&#26426;&#36924;&#36817;&#65288;TTSA&#65289;&#30340;&#24191;&#20041;&#20998;&#26512;&#65292;&#21033;&#29992;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65288;CLT&#65289;&#25581;&#31034;&#20102;TTSA&#21463;&#39532;&#23572;&#21487;&#22827;&#22122;&#22768;&#24433;&#21709;&#30340;&#32806;&#21512;&#21160;&#21147;&#23398;&#65292;&#20174;&#32780;&#25299;&#23637;&#20102;&#20256;&#32479;SGD&#30340;&#39640;&#25928;&#37319;&#26679;&#31574;&#30053;&#22312;&#20998;&#24067;&#24335;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#33539;&#22260;&#65292;&#21516;&#26102;&#30740;&#31350;&#20102;&#20855;&#26377;&#38750;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;GTD&#31639;&#27861;&#30340;&#32479;&#35745;&#29305;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.09339</link><description>&lt;p&gt;
&#20004;&#26102;&#38388;&#23610;&#24230;&#24102;&#39532;&#23572;&#21487;&#22827;&#22122;&#22768;&#30340;&#38543;&#26426;&#36924;&#36817;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65306;&#29702;&#35770;&#21644;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Central Limit Theorem for Two-Timescale Stochastic Approximation with Markovian Noise: Theory and Applications. (arXiv:2401.09339v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09339
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23545;&#20004;&#26102;&#38388;&#23610;&#24230;&#38543;&#26426;&#36924;&#36817;&#65288;TTSA&#65289;&#30340;&#24191;&#20041;&#20998;&#26512;&#65292;&#21033;&#29992;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65288;CLT&#65289;&#25581;&#31034;&#20102;TTSA&#21463;&#39532;&#23572;&#21487;&#22827;&#22122;&#22768;&#24433;&#21709;&#30340;&#32806;&#21512;&#21160;&#21147;&#23398;&#65292;&#20174;&#32780;&#25299;&#23637;&#20102;&#20256;&#32479;SGD&#30340;&#39640;&#25928;&#37319;&#26679;&#31574;&#30053;&#22312;&#20998;&#24067;&#24335;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#33539;&#22260;&#65292;&#21516;&#26102;&#30740;&#31350;&#20102;&#20855;&#26377;&#38750;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;GTD&#31639;&#27861;&#30340;&#32479;&#35745;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20004;&#26102;&#38388;&#23610;&#24230;&#38543;&#26426;&#36924;&#36817;&#65288;TTSA&#65289;&#26159;&#26368;&#36890;&#29992;&#30340;&#36845;&#20195;&#38543;&#26426;&#31639;&#27861;&#26694;&#26550;&#20043;&#19968;&#12290;&#36825;&#21253;&#25324;&#20102;&#20247;&#25152;&#21608;&#30693;&#30340;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#65292;&#22914;SGD&#21464;&#31181;&#21644;&#29992;&#20110;&#21452;&#23618;&#25110;&#26497;&#23567;&#21270;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#20197;&#21450;&#31867;&#20284;&#26799;&#24230;-based&#26102;&#24207;&#24046;&#24322;&#65288;GTD&#65289;&#31639;&#27861;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#12290;&#26412;&#25991;&#36890;&#36807;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65288;CLT&#65289;&#23545;&#24102;&#25511;&#21046;&#39532;&#23572;&#21487;&#22827;&#22122;&#22768;&#30340;TTSA&#36827;&#34892;&#20102;&#28145;&#20837;&#30340;&#28176;&#36817;&#20998;&#26512;&#65292;&#25581;&#31034;&#20102;TTSA&#21463;&#24213;&#23618;&#39532;&#23572;&#21487;&#22827;&#38142;&#24433;&#21709;&#30340;&#32806;&#21512;&#21160;&#21147;&#23398;&#65292;&#36825;&#22312;&#20197;&#21069;&#20165;&#32771;&#34385;&#38789;&#24046;&#24322;&#22122;&#22768;&#30340;TTSA&#30340;CLT&#32467;&#26524;&#20013;&#27809;&#26377;&#24471;&#21040;&#35299;&#20915;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;CLT&#65292;&#25105;&#20204;&#23558;&#39640;&#25928;&#37319;&#26679;&#31574;&#30053;&#30340;&#24212;&#29992;&#33539;&#22260;&#20174;&#20256;&#32479;SGD&#25193;&#23637;&#21040;&#20102;&#26356;&#24191;&#27867;&#30340;TTSA&#32972;&#26223;&#19979;&#30340;&#20998;&#24067;&#24335;&#23398;&#20064;&#65292;&#20174;&#32780;&#25193;&#22823;&#20102;&#32993;&#31561;&#20154;&#65288;2022&#65289;&#30340;&#30740;&#31350;&#33539;&#22260;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21033;&#29992;&#25105;&#20204;&#30340;CLT&#32467;&#26524;&#25512;&#23548;&#20102;&#20855;&#26377;&#38750;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;GTD&#31639;&#27861;&#30340;&#32479;&#35745;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Two-timescale stochastic approximation (TTSA) is among the most general frameworks for iterative stochastic algorithms. This includes well-known stochastic optimization methods such as SGD variants and those designed for bilevel or minimax problems, as well as reinforcement learning like the family of gradient-based temporal difference (GTD) algorithms. In this paper, we conduct an in-depth asymptotic analysis of TTSA under controlled Markovian noise via central limit theorem (CLT), uncovering the coupled dynamics of TTSA influenced by the underlying Markov chain, which has not been addressed by previous CLT results of TTSA only with Martingale difference noise. Building upon our CLT, we expand its application horizon of efficient sampling strategies from vanilla SGD to a wider TTSA context in distributed learning, thus broadening the scope of Hu et al. (2022). In addition, we leverage our CLT result to deduce the statistical properties of GTD algorithms with nonlinear function approxi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#22686;&#24378;&#30340;&#28151;&#21512;&#27169;&#25311;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#20999;&#32447;&#31354;&#38388;&#27491;&#21017;&#21270;&#20272;&#35745;&#22120;&#30340;&#26041;&#27861;&#26469;&#25511;&#21046;&#20998;&#24067;&#20559;&#31227;&#65292;&#20174;&#32780;&#25552;&#39640;&#27169;&#25311;&#32467;&#26524;&#30340;&#31934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.09259</link><description>&lt;p&gt;
&#32531;&#35299;&#26426;&#22120;&#23398;&#20064;&#22686;&#24378;&#30340;&#28151;&#21512;&#27169;&#25311;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;
&lt;/p&gt;
&lt;p&gt;
Mitigating distribution shift in machine learning-augmented hybrid simulation. (arXiv:2401.09259v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09259
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#22686;&#24378;&#30340;&#28151;&#21512;&#27169;&#25311;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#20999;&#32447;&#31354;&#38388;&#27491;&#21017;&#21270;&#20272;&#35745;&#22120;&#30340;&#26041;&#27861;&#26469;&#25511;&#21046;&#20998;&#24067;&#20559;&#31227;&#65292;&#20174;&#32780;&#25552;&#39640;&#27169;&#25311;&#32467;&#26524;&#30340;&#31934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#22686;&#24378;&#30340;&#28151;&#21512;&#27169;&#25311;&#20013;&#26222;&#36941;&#23384;&#22312;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#65292;&#20854;&#20013;&#27169;&#25311;&#31639;&#27861;&#30340;&#37096;&#20998;&#34987;&#25968;&#25454;&#39537;&#21160;&#30340;&#26367;&#20195;&#27169;&#22411;&#21462;&#20195;&#12290;&#25105;&#20204;&#39318;&#20808;&#24314;&#31435;&#20102;&#19968;&#20010;&#25968;&#23398;&#26694;&#26550;&#26469;&#29702;&#35299;&#26426;&#22120;&#23398;&#20064;&#22686;&#24378;&#30340;&#28151;&#21512;&#27169;&#25311;&#38382;&#39064;&#30340;&#32467;&#26500;&#65292;&#20197;&#21450;&#30456;&#20851;&#30340;&#20998;&#24067;&#20559;&#31227;&#30340;&#21407;&#22240;&#21644;&#24433;&#21709;&#12290;&#25105;&#20204;&#22312;&#25968;&#20540;&#21644;&#29702;&#35770;&#19978;&#23637;&#31034;&#20102;&#20998;&#24067;&#20559;&#31227;&#19982;&#27169;&#25311;&#35823;&#24046;&#30340;&#30456;&#20851;&#24615;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20999;&#32447;&#31354;&#38388;&#27491;&#21017;&#21270;&#20272;&#35745;&#22120;&#30340;&#31616;&#21333;&#26041;&#27861;&#26469;&#25511;&#21046;&#20998;&#24067;&#20559;&#31227;&#65292;&#20174;&#32780;&#25552;&#39640;&#27169;&#25311;&#32467;&#26524;&#30340;&#38271;&#26399;&#31934;&#30830;&#24615;&#12290;&#22312;&#32447;&#24615;&#21160;&#21147;&#23398;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#35814;&#23613;&#30340;&#29702;&#35770;&#20998;&#26512;&#26469;&#37327;&#21270;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#20960;&#20010;&#25968;&#20540;&#23454;&#39564;&#65292;&#21253;&#25324;&#27169;&#25311;&#37096;&#20998;&#24050;&#30693;&#30340;&#21453;&#24212;&#25193;&#25955;&#26041;&#31243;&#20197;&#21450;&#20351;&#29992;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#25237;&#24433;&#26041;&#27861;&#27714;&#35299;Navier-Stokes&#26041;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of distribution shift generally arising in machine-learning augmented hybrid simulation, where parts of simulation algorithms are replaced by data-driven surrogates. We first establish a mathematical framework to understand the structure of machine-learning augmented hybrid simulation problems, and the cause and effect of the associated distribution shift. We show correlations between distribution shift and simulation error both numerically and theoretically. Then, we propose a simple methodology based on tangent-space regularized estimator to control the distribution shift, thereby improving the long-term accuracy of the simulation results. In the linear dynamics case, we provide a thorough theoretical analysis to quantify the effectiveness of the proposed method. Moreover, we conduct several numerical experiments, including simulating a partially known reaction-diffusion equation and solving Navier-Stokes equations using the projection method with a data-driven p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#35745;&#31639;&#22810;&#31867;&#20998;&#31867;&#20013;&#23545;&#25239;&#35757;&#32451;&#19979;&#30028;&#30340;&#26368;&#20248;&#36755;&#36816;&#26041;&#27861;&#65292;&#24182;&#21033;&#29992;&#35813;&#26041;&#27861;&#25552;&#20986;&#20102;&#35745;&#31639;&#26368;&#20248;&#23545;&#25239;&#39118;&#38505;&#19979;&#30028;&#21644;&#30830;&#23450;&#26368;&#20248;&#20998;&#31867;&#22120;&#30340;&#31639;&#27861;&#12290;&#36890;&#36807;&#25130;&#26029;&#31867;&#20043;&#38388;&#30340;&#39640;&#38454;&#30456;&#20114;&#20316;&#29992;&#65292;&#36991;&#20813;&#20102;&#32452;&#21512;&#36816;&#34892;&#26102;&#38388;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.09191</link><description>&lt;p&gt;
&#19968;&#20010;&#29992;&#20110;&#35745;&#31639;&#22810;&#31867;&#20998;&#31867;&#20013;&#23545;&#25239;&#35757;&#32451;&#19979;&#30028;&#30340;&#26368;&#20248;&#36755;&#36816;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Optimal Transport Approach for Computing Adversarial Training Lower Bounds in Multiclass Classification. (arXiv:2401.09191v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09191
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#35745;&#31639;&#22810;&#31867;&#20998;&#31867;&#20013;&#23545;&#25239;&#35757;&#32451;&#19979;&#30028;&#30340;&#26368;&#20248;&#36755;&#36816;&#26041;&#27861;&#65292;&#24182;&#21033;&#29992;&#35813;&#26041;&#27861;&#25552;&#20986;&#20102;&#35745;&#31639;&#26368;&#20248;&#23545;&#25239;&#39118;&#38505;&#19979;&#30028;&#21644;&#30830;&#23450;&#26368;&#20248;&#20998;&#31867;&#22120;&#30340;&#31639;&#27861;&#12290;&#36890;&#36807;&#25130;&#26029;&#31867;&#20043;&#38388;&#30340;&#39640;&#38454;&#30456;&#20114;&#20316;&#29992;&#65292;&#36991;&#20813;&#20102;&#32452;&#21512;&#36816;&#34892;&#26102;&#38388;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#31639;&#27861;&#21462;&#24471;&#20102;&#24456;&#22823;&#30340;&#25104;&#21151;&#65292;&#20294;&#24191;&#20026;&#20154;&#30693;&#30340;&#26159;&#31070;&#32463;&#32593;&#32476;&#21487;&#33021;&#32570;&#20047;&#40065;&#26834;&#24615;&#12290;&#24378;&#21046;&#40065;&#26834;&#24615;&#30340;&#27969;&#34892;&#33539;&#24335;&#26159;&#23545;&#25239;&#35757;&#32451;&#65288;AT&#65289;&#65292;&#28982;&#32780;&#65292;&#36825;&#24341;&#20837;&#20102;&#35768;&#22810;&#35745;&#31639;&#21644;&#29702;&#35770;&#19978;&#30340;&#22256;&#38590;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#22312;&#22810;&#31867;&#20998;&#31867;&#35774;&#32622;&#21644;&#22810;&#36793;&#38469;&#26368;&#20248;&#36755;&#36816;&#65288;MOT&#65289;&#20043;&#38388;&#24314;&#31435;&#20102;&#32852;&#31995;&#65292;&#20026;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#25552;&#20379;&#20102;&#19968;&#22871;&#26032;&#30340;&#24037;&#20855;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;MOT&#30340;&#36830;&#25509;&#65292;&#25552;&#20986;&#20102;&#35745;&#31639;&#19978;&#26368;&#31616;&#20415;&#21487;&#34892;&#30340;&#25968;&#20540;&#31639;&#27861;&#26469;&#35745;&#31639;&#26368;&#20248;&#23545;&#25239;&#39118;&#38505;&#30340;&#26222;&#36941;&#19979;&#30028;&#65292;&#24182;&#30830;&#23450;&#26368;&#20248;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#22522;&#20110;&#32447;&#24615;&#35268;&#21010;&#65288;LP&#65289;&#21644;&#29109;&#27491;&#21017;&#21270;&#65288;Sinkhorn&#65289;&#25552;&#20986;&#20102;&#20004;&#20010;&#20027;&#35201;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#27934;&#23519;&#26159;&#21487;&#20197;&#26080;&#23475;&#22320;&#25130;&#26029;&#31867;&#20043;&#38388;&#30340;&#39640;&#38454;&#30456;&#20114;&#20316;&#29992;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#22312;MOT&#38382;&#39064;&#20013;&#36890;&#24120;&#36935;&#21040;&#30340;&#32452;&#21512;&#36816;&#34892;&#26102;&#38388;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;MNIST&#21644;CI &#19978;&#36827;&#34892;&#23454;&#39564;&#35777;&#23454;&#20102;&#36825;&#20123;&#32467;&#26524;
&lt;/p&gt;
&lt;p&gt;
Despite the success of deep learning-based algorithms, it is widely known that neural networks may fail to be robust. A popular paradigm to enforce robustness is adversarial training (AT), however, this introduces many computational and theoretical difficulties. Recent works have developed a connection between AT in the multiclass classification setting and multimarginal optimal transport (MOT), unlocking a new set of tools to study this problem. In this paper, we leverage the MOT connection to propose computationally tractable numerical algorithms for computing universal lower bounds on the optimal adversarial risk and identifying optimal classifiers. We propose two main algorithms based on linear programming (LP) and entropic regularization (Sinkhorn). Our key insight is that one can harmlessly truncate the higher order interactions between classes, preventing the combinatorial run times typically encountered in MOT problems. We validate these results with experiments on MNIST and CI
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#32479;&#35745;&#27169;&#22411;&#30340;&#26032;&#23481;&#37327;&#27979;&#37327;2sED&#65292;&#21487;&#20197;&#21487;&#38752;&#22320;&#38480;&#21046;&#27867;&#21270;&#35823;&#24046;&#65292;&#24182;&#19988;&#19982;&#35757;&#32451;&#35823;&#24046;&#20855;&#26377;&#24456;&#22909;&#30340;&#30456;&#20851;&#24615;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#36880;&#23618;&#36845;&#20195;&#30340;&#26041;&#27861;&#26377;&#25928;&#22320;&#36817;&#20284;2sED&#65292;&#20174;&#32780;&#22788;&#29702;&#22823;&#37327;&#21442;&#25968;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2401.09184</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#20004;&#23610;&#24230;&#22797;&#26434;&#24230;&#27979;&#37327;
&lt;/p&gt;
&lt;p&gt;
A Two-Scale Complexity Measure for Deep Learning Models. (arXiv:2401.09184v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09184
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#32479;&#35745;&#27169;&#22411;&#30340;&#26032;&#23481;&#37327;&#27979;&#37327;2sED&#65292;&#21487;&#20197;&#21487;&#38752;&#22320;&#38480;&#21046;&#27867;&#21270;&#35823;&#24046;&#65292;&#24182;&#19988;&#19982;&#35757;&#32451;&#35823;&#24046;&#20855;&#26377;&#24456;&#22909;&#30340;&#30456;&#20851;&#24615;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#36880;&#23618;&#36845;&#20195;&#30340;&#26041;&#27861;&#26377;&#25928;&#22320;&#36817;&#20284;2sED&#65292;&#20174;&#32780;&#22788;&#29702;&#22823;&#37327;&#21442;&#25968;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#26377;&#25928;&#32500;&#24230;&#30340;&#32479;&#35745;&#27169;&#22411;&#26032;&#23481;&#37327;&#27979;&#37327;2sED&#12290;&#36825;&#20010;&#26032;&#30340;&#25968;&#37327;&#22312;&#23545;&#27169;&#22411;&#36827;&#34892;&#28201;&#21644;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#21487;&#38752;&#22320;&#38480;&#21046;&#27867;&#21270;&#35823;&#24046;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#26631;&#20934;&#25968;&#25454;&#38598;&#21644;&#27969;&#34892;&#30340;&#27169;&#22411;&#26550;&#26500;&#30340;&#27169;&#25311;&#32467;&#26524;&#34920;&#26126;&#65292;2sED&#19982;&#35757;&#32451;&#35823;&#24046;&#20855;&#26377;&#24456;&#22909;&#30340;&#30456;&#20851;&#24615;&#12290;&#23545;&#20110;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#36880;&#23618;&#36845;&#20195;&#30340;&#26041;&#27861;&#26377;&#25928;&#22320;&#20174;&#19979;&#26041;&#36817;&#20284;2sED&#65292;&#20174;&#32780;&#35299;&#20915;&#20855;&#26377;&#22823;&#37327;&#21442;&#25968;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#12290;&#27169;&#25311;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#31181;&#36817;&#20284;&#23545;&#19981;&#21516;&#30340;&#31361;&#20986;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#37117;&#24456;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a novel capacity measure 2sED for statistical models based on the effective dimension. The new quantity provably bounds the generalization error under mild assumptions on the model. Furthermore, simulations on standard data sets and popular model architectures show that 2sED correlates well with the training error. For Markovian models, we show how to efficiently approximate 2sED from below through a layerwise iterative approach, which allows us to tackle deep learning models with a large number of parameters. Simulation results suggest that the approximation is good for different prominent models and data sets.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#25968;&#25454;&#39537;&#21160;&#30340;&#30417;&#25511;&#27969;&#31243;&#65292;&#29992;&#20110;&#30830;&#23450;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#20309;&#26102;&#38656;&#35201;&#37325;&#26032;&#35757;&#32451;&#65292;&#20197;&#30830;&#20445;&#20934;&#30830;&#31283;&#23450;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.09144</link><description>&lt;p&gt;
&#30417;&#25511;&#26426;&#22120;&#23398;&#20064;&#23545;&#24179;&#21488;&#25968;&#25454;&#27969;&#30340;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Monitoring Machine Learning Forecasts for Platform Data Streams. (arXiv:2401.09144v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09144
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#25968;&#25454;&#39537;&#21160;&#30340;&#30417;&#25511;&#27969;&#31243;&#65292;&#29992;&#20110;&#30830;&#23450;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#20309;&#26102;&#38656;&#35201;&#37325;&#26032;&#35757;&#32451;&#65292;&#20197;&#30830;&#20445;&#20934;&#30830;&#31283;&#23450;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#27969;&#39044;&#27979;&#23545;&#25968;&#23383;&#24179;&#21488;&#30340;&#20915;&#31574;&#33267;&#20851;&#37325;&#35201;&#12290;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#26159;&#29983;&#25104;&#36825;&#31181;&#39044;&#27979;&#30340;&#26377;&#21560;&#24341;&#21147;&#30340;&#20505;&#36873;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#25968;&#23383;&#24179;&#21488;&#38656;&#35201;&#19968;&#20010;&#22823;&#35268;&#27169;&#30340;&#39044;&#27979;&#26694;&#26550;&#65292;&#21487;&#20197;&#28789;&#27963;&#22320;&#24212;&#23545;&#31361;&#28982;&#30340;&#24615;&#33021;&#19979;&#38477;&#12290;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#20197;&#19982;&#26032;&#25968;&#25454;&#25209;&#27425;&#36755;&#20837;&#30340;&#36895;&#24230;&#30456;&#21516;&#30340;&#36895;&#24230;&#37325;&#26032;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#35745;&#31639;&#25104;&#26412;&#22826;&#39640;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#19981;&#39057;&#32321;&#30340;&#37325;&#26032;&#35757;&#32451;&#38656;&#35201;&#25351;&#23450;&#37325;&#26032;&#35757;&#32451;&#30340;&#39057;&#29575;&#65292;&#24182;&#19988;&#36890;&#24120;&#20250;&#23548;&#33268;&#39044;&#27979;&#25928;&#26524;&#30340;&#20005;&#37325;&#19979;&#38477;&#12290;&#20026;&#20102;&#30830;&#20445;&#20934;&#30830;&#31283;&#23450;&#30340;&#39044;&#27979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#25968;&#25454;&#39537;&#21160;&#30340;&#30417;&#25511;&#27969;&#31243;&#65292;&#26469;&#22238;&#31572;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#20309;&#26102;&#24212;&#35813;&#37325;&#26032;&#35757;&#32451;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#19981;&#26159;&#30740;&#31350;&#25968;&#25454;&#27969;&#30340;&#19981;&#31283;&#23450;&#24615;&#65292;&#32780;&#26159;&#27979;&#35797;&#20256;&#20837;&#30340;&#27969;&#24335;&#39044;&#27979;&#25439;&#22833;&#25209;&#27425;&#26159;&#21542;&#19982;&#19968;&#20010;&#26126;&#30830;&#23450;&#20041;&#30340;&#21442;&#32771;&#25209;&#27425;&#19981;&#21516;&#12290; &#20351;&#29992;&#19968;&#20010;&#30001;15&#20998;&#38047;&#39057;&#29575;&#30340;&#25968;&#25454;&#27969;&#32452;&#25104;&#30340;&#26032;&#25968;&#25454;&#38598;&#65292;&#35813;&#25968;&#25454;&#38598;&#26469;&#33258;&#20110;&#22312;&#20262;&#25958;&#36816;&#33829;&#30340;&#25353;&#38656;&#29289;&#27969;&#24179;&#21488;&#65292;&#25105;&#20204;&#24212;&#29992;&#20102;&#36825;&#20010;&#30417;&#25511;&#27969;&#31243;&#65292;
&lt;/p&gt;
&lt;p&gt;
Data stream forecasts are essential inputs for decision making at digital platforms. Machine learning algorithms are appealing candidates to produce such forecasts. Yet, digital platforms require a large-scale forecast framework that can flexibly respond to sudden performance drops. Re-training ML algorithms at the same speed as new data batches enter is usually computationally too costly. On the other hand, infrequent re-training requires specifying the re-training frequency and typically comes with a severe cost of forecast deterioration. To ensure accurate and stable forecasts, we propose a simple data-driven monitoring procedure to answer the question when the ML algorithm should be re-trained. Instead of investigating instability of the data streams, we test if the incoming streaming forecast loss batch differs from a well-defined reference batch. Using a novel dataset constituting 15-min frequency data streams from an on-demand logistics platform operating in London, we apply the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#30340;&#24322;&#36136;&#24615;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;HSBM&#65289;&#26469;&#25552;&#20379;&#23545;&#19981;&#21516;&#24322;&#36136;&#24615;&#27169;&#24335;&#23545;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#24433;&#21709;&#30340;&#29702;&#35770;&#29702;&#35299;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#24322;&#36136;&#24615;&#23545;&#20998;&#31867;&#30340;&#24433;&#21709;&#38656;&#35201;&#19982;&#24179;&#22343;&#33410;&#28857;&#24230;&#19968;&#36215;&#35780;&#20272;&#65292;&#24182;&#19988;&#25299;&#25169;&#22122;&#22768;&#23545;&#20998;&#31867;&#26377;&#36127;&#38754;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2401.09125</link><description>&lt;p&gt;
&#29702;&#35299;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#24322;&#36136;&#24615;
&lt;/p&gt;
&lt;p&gt;
Understanding Heterophily for Graph Neural Networks. (arXiv:2401.09125v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09125
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#30340;&#24322;&#36136;&#24615;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;HSBM&#65289;&#26469;&#25552;&#20379;&#23545;&#19981;&#21516;&#24322;&#36136;&#24615;&#27169;&#24335;&#23545;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#24433;&#21709;&#30340;&#29702;&#35770;&#29702;&#35299;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#24322;&#36136;&#24615;&#23545;&#20998;&#31867;&#30340;&#24433;&#21709;&#38656;&#35201;&#19982;&#24179;&#22343;&#33410;&#28857;&#24230;&#19968;&#36215;&#35780;&#20272;&#65292;&#24182;&#19988;&#25299;&#25169;&#22122;&#22768;&#23545;&#20998;&#31867;&#26377;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20855;&#26377;&#24322;&#36136;&#24615;&#30340;&#22270;&#34987;&#35748;&#20026;&#26159;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#38754;&#20020;&#25361;&#25112;&#30340;&#24773;&#26223;&#65292;&#20854;&#20013;&#33410;&#28857;&#36890;&#36807;&#21508;&#31181;&#27169;&#24335;&#19982;&#19981;&#21516;&#30340;&#37051;&#23621;&#30456;&#36830;&#25509;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;&#22270;&#21367;&#31215;&#65288;GC&#65289;&#25805;&#20316;&#21512;&#24182;&#21040;&#23436;&#20840;&#36830;&#25509;&#30340;&#32593;&#32476;&#20013;&#65292;&#36890;&#36807;&#25552;&#20986;&#30340;&#24322;&#36136;&#24615;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;HSBM&#65289;&#26469;&#25552;&#20379;&#23545;&#19981;&#21516;&#24322;&#36136;&#24615;&#27169;&#24335;&#23545;GNNs&#24433;&#21709;&#30340;&#29702;&#35770;&#29702;&#35299;&#65292;HSBM&#26159;&#19968;&#20010;&#21487;&#20197;&#23481;&#32435;&#22810;&#26679;&#30340;&#24322;&#36136;&#24615;&#27169;&#24335;&#30340;&#36890;&#29992;&#38543;&#26426;&#22270;&#27169;&#22411;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#24212;&#29992;GC&#25805;&#20316;&#65292;&#21487;&#20998;&#24615;&#22686;&#30410;&#21462;&#20915;&#20110;&#20004;&#20010;&#22240;&#32032;&#65292;&#21363;&#37051;&#22495;&#20998;&#24067;&#30340;&#27431;&#27663;&#36317;&#31163;&#21644;$\sqrt{\mathbb{E}\left[\operatorname{deg}\right]}$&#65292;&#20854;&#20013;$\mathbb{E}\left[\operatorname{deg}\right]$&#26159;&#24179;&#22343;&#33410;&#28857;&#24230;&#12290;&#23427;&#25581;&#31034;&#20102;&#24322;&#36136;&#24615;&#23545;&#20998;&#31867;&#30340;&#24433;&#21709;&#38656;&#35201;&#19982;&#24179;&#22343;&#33410;&#28857;&#24230;&#19968;&#36215;&#35780;&#20272;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25299;&#25169;&#22122;&#22768;&#20855;&#26377;&#36127;&#38754;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Graphs with heterophily have been regarded as challenging scenarios for Graph Neural Networks (GNNs), where nodes are connected with dissimilar neighbors through various patterns. In this paper, we present theoretical understandings of the impacts of different heterophily patterns for GNNs by incorporating the graph convolution (GC) operations into fully connected networks via the proposed Heterophilous Stochastic Block Models (HSBM), a general random graph model that can accommodate diverse heterophily patterns. Firstly, we show that by applying a GC operation, the separability gains are determined by two factors, i.e., the Euclidean distance of the neighborhood distributions and $\sqrt{\mathbb{E}\left[\operatorname{deg}\right]}$, where $\mathbb{E}\left[\operatorname{deg}\right]$ is the averaged node degree. It reveals that the impact of heterophily on classification needs to be evaluated alongside the averaged node degree. Secondly, we show that the topological noise has a detrimenta
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#19979;&#22266;&#23450;&#39044;&#31639;&#26465;&#20214;&#19979;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#28385;&#36275;&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#30340;&#31574;&#30053;DP-BAI&#65292;&#24182;&#24471;&#21040;&#20102;&#38169;&#35823;&#27010;&#29575;&#30340;&#19978;&#30028;&#21644;&#26368;&#23567;-&#26368;&#22823;&#19979;&#30028;&#30340;&#25351;&#25968;&#34928;&#20943;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2401.09073</link><description>&lt;p&gt;
&#22266;&#23450;&#39044;&#31639;&#24046;&#20998;&#38544;&#31169;&#26368;&#20339;&#33218;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Fixed-Budget Differentially Private Best Arm Identification. (arXiv:2401.09073v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09073
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#19979;&#22266;&#23450;&#39044;&#31639;&#26465;&#20214;&#19979;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#28385;&#36275;&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#30340;&#31574;&#30053;DP-BAI&#65292;&#24182;&#24471;&#21040;&#20102;&#38169;&#35823;&#27010;&#29575;&#30340;&#19978;&#30028;&#21644;&#26368;&#23567;-&#26368;&#22823;&#19979;&#30028;&#30340;&#25351;&#25968;&#34928;&#20943;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#19979;&#30740;&#31350;&#20102;&#32447;&#24615;&#36172;&#21338;&#26426;&#20013;&#22266;&#23450;&#39044;&#31639;&#26465;&#20214;&#19979;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#20854;&#20013;&#33218;&#30340;&#22870;&#21169;&#22312;&#21333;&#20301;&#21306;&#38388;&#19978;&#12290;&#32473;&#23450;&#19968;&#20010;&#26377;&#38480;&#30340;&#39044;&#31639;$T$&#21644;&#38544;&#31169;&#21442;&#25968;$\varepsilon&gt;0$&#65292;&#30446;&#26631;&#26159;&#22312;$T$&#20010;&#37319;&#26679;&#36718;&#21518;&#26368;&#23567;&#21270;&#23547;&#25214;&#24179;&#22343;&#20540;&#26368;&#22823;&#30340;&#33218;&#30340;&#38169;&#35823;&#27010;&#29575;&#65292;&#21516;&#26102;&#28385;&#36275;&#20915;&#31574;&#32773;&#31574;&#30053;&#28385;&#36275;&#29305;&#23450;&#30340;$\varepsilon$-&#24046;&#20998;&#38544;&#31169;($\varepsilon$-DP)&#32422;&#26463;&#26465;&#20214;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#8220;&#26368;&#22823;&#32477;&#23545;&#34892;&#21015;&#24335;&#8221;&#21407;&#21017;&#26500;&#24314;&#28385;&#36275;$\varepsilon$-DP&#32422;&#26463;&#30340;&#31574;&#30053;(&#31216;&#20026;DP-BAI)&#65292;&#24182;&#32473;&#20986;&#20854;&#38169;&#35823;&#27010;&#29575;&#30340;&#19978;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#38169;&#35823;&#27010;&#29575;&#30340;&#26368;&#23567;-&#26368;&#22823;&#19979;&#30028;&#65292;&#24182;&#35777;&#26126;&#36825;&#20004;&#20010;&#30028;&#22312;$T$&#19978;&#25353;&#25351;&#25968;&#34928;&#20943;&#65292;&#30028;&#20013;&#30340;&#25351;&#25968;&#19982;(a)&#33218;&#30340;&#27425;&#20248;&#38388;&#38553;&#65292;(b)$\varepsilon$&#21644;(c)&#20851;&#32852;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study best arm identification (BAI) in linear bandits in the fixed-budget regime under differential privacy constraints, when the arm rewards are supported on the unit interval. Given a finite budget $T$ and a privacy parameter $\varepsilon&gt;0$, the goal is to minimise the error probability in finding the arm with the largest mean after $T$ sampling rounds, subject to the constraint that the policy of the decision maker satisfies a certain {\em $\varepsilon$-differential privacy} ($\varepsilon$-DP) constraint. We construct a policy satisfying the $\varepsilon$-DP constraint (called {\sc DP-BAI}) by proposing the principle of {\em maximum absolute determinants}, and derive an upper bound on its error probability. Furthermore, we derive a minimax lower bound on the error probability, and demonstrate that the lower and the upper bounds decay exponentially in $T$, with exponents in the two bounds matching order-wise in (a) the sub-optimality gaps of the arms, (b) $\varepsilon$, and (c) t
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24182;&#34892;&#21270;Langevin&#31639;&#27861;&#21644;&#27424;&#38459;&#23612;&#30340;Langevin&#31639;&#27861;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#22312;&#31561;&#21608;&#23494;&#24230;&#19979;&#24182;&#34892;&#37319;&#26679;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20855;&#26377;TV&#36317;&#31163;&#20445;&#35777;&#65292;&#24182;&#22312;&#24635;&#26799;&#24230;&#35780;&#20272;&#27425;&#25968;&#19978;&#20855;&#26377;&#32447;&#24615;&#25110;&#32773;&#24179;&#26041;&#26681;&#32423;&#21035;&#30340;&#22797;&#26434;&#24230;&#12290;&#23545;&#20110;&#20027;&#35201;&#24212;&#29992;&#65292;&#22312;&#20445;&#35777;TV&#36317;&#31163;&#30340;&#21069;&#25552;&#19979;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#36229;&#31435;&#26041;&#20307;&#19978;&#31163;&#25955;&#20998;&#24067;&#26063;&#30340;RNC&#37319;&#26679;-&#35745;&#25968;&#32553;&#20943;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.09016</link><description>&lt;p&gt;
&#24555;&#36895;&#24182;&#34892;&#37319;&#26679;&#22312;&#31561;&#21608;&#23494;&#24230;&#19979;
&lt;/p&gt;
&lt;p&gt;
Fast parallel sampling under isoperimetry. (arXiv:2401.09016v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09016
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24182;&#34892;&#21270;Langevin&#31639;&#27861;&#21644;&#27424;&#38459;&#23612;&#30340;Langevin&#31639;&#27861;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#22312;&#31561;&#21608;&#23494;&#24230;&#19979;&#24182;&#34892;&#37319;&#26679;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20855;&#26377;TV&#36317;&#31163;&#20445;&#35777;&#65292;&#24182;&#22312;&#24635;&#26799;&#24230;&#35780;&#20272;&#27425;&#25968;&#19978;&#20855;&#26377;&#32447;&#24615;&#25110;&#32773;&#24179;&#26041;&#26681;&#32423;&#21035;&#30340;&#22797;&#26434;&#24230;&#12290;&#23545;&#20110;&#20027;&#35201;&#24212;&#29992;&#65292;&#22312;&#20445;&#35777;TV&#36317;&#31163;&#30340;&#21069;&#25552;&#19979;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#36229;&#31435;&#26041;&#20307;&#19978;&#31163;&#25955;&#20998;&#24067;&#26063;&#30340;RNC&#37319;&#26679;-&#35745;&#25968;&#32553;&#20943;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#24182;&#34892;&#21270;Langevin&#31639;&#27861;&#65288;&#25110;&#27424;&#38459;&#23612;&#30340;Langevin&#31639;&#27861;&#65289;&#20174;&#28385;&#36275;&#23545;&#25968;Sobolev&#19981;&#31561;&#24335;&#19988;&#20855;&#26377;&#24179;&#28369;&#30340;&#23545;&#25968;&#23494;&#24230;&#30340;&#20998;&#24067;&#960;&#20013;&#24182;&#34892;&#37319;&#26679;&#12290;&#25105;&#20204;&#35777;&#26126;&#25105;&#20204;&#30340;&#31639;&#27861;&#36755;&#20986;&#30340;&#26679;&#26412;&#36981;&#24490;Kullback-Leibler&#65288;KL&#65289;&#25955;&#24230;&#65288;&#25110;&#32773;&#24635;&#21464;&#24046;&#65288;TV&#65289;&#36317;&#31163;&#65289;&#25509;&#36817;&#960;&#30340;&#20998;&#24067;&#960;&#12290;&#21516;&#26102;&#25105;&#20204;&#30340;&#31639;&#27861;&#21482;&#20351;&#29992;O(log(d))&#20010;&#24182;&#34892;&#36718;&#27425;&#21644;O(d)&#65288;&#25110;O(&#8730;d)&#20010;&#65289;&#26799;&#24230;&#35780;&#20272;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#20855;&#26377;TV&#36317;&#31163;&#20445;&#35777;&#30340;&#24182;&#34892;&#37319;&#26679;&#31639;&#27861;&#12290;&#23545;&#20110;&#25105;&#20204;&#30340;&#20027;&#35201;&#24212;&#29992;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#25105;&#20204;&#31639;&#27861;&#30340;TV&#36317;&#31163;&#20445;&#35777;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;&#30456;&#32467;&#21512;&#65292;&#20174;&#32780;&#24471;&#21040;&#23545;&#20110;&#36229;&#31435;&#26041;&#20307;&#19978;&#30340;&#31163;&#25955;&#20998;&#24067;&#26063;&#30340;RNC&#37319;&#26679;-&#35745;&#25968;&#32553;&#20943;&#12290;&#36825;&#20123;&#20998;&#24067;&#26063;&#22312;&#25351;&#25968;&#20542;&#26012;&#19979;&#20445;&#25345;&#23553;&#38381;&#19988;&#26377;&#26377;&#30028;&#21327;&#26041;&#24046;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#19968;&#20010;&#29992;&#20110;&#26377;&#21521;&#27431;&#25289;&#36890;&#36335;&#21644;&#38750;&#23545;&#31216;&#30830;&#23450;&#30340;RNC&#37319;&#26679;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show how to sample in parallel from a distribution $\pi$ over $\mathbb R^d$ that satisfies a log-Sobolev inequality and has a smooth log-density, by parallelizing the Langevin (resp. underdamped Langevin) algorithms. We show that our algorithm outputs samples from a distribution $\hat\pi$ that is close to $\pi$ in Kullback--Leibler (KL) divergence (resp. total variation (TV) distance), while using only $\log(d)^{O(1)}$ parallel rounds and $\widetilde{O}(d)$ (resp. $\widetilde O(\sqrt d)$) gradient evaluations in total. This constitutes the first parallel sampling algorithms with TV distance guarantees.  For our main application, we show how to combine the TV distance guarantees of our algorithms with prior works and obtain RNC sampling-to-counting reductions for families of discrete distribution on the hypercube $\{\pm 1\}^n$ that are closed under exponential tilts and have bounded covariance. Consequently, we obtain an RNC sampler for directed Eulerian tours and asymmetric determin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#30028;&#38480;&#65292;&#35813;&#30028;&#38480;&#35206;&#30422;&#20102;&#29420;&#31435;&#21516;&#20998;&#24067;&#20197;&#21450;&#23384;&#22312;&#38271;&#26399;&#21644;&#30701;&#26399;&#20381;&#36182;&#30340;&#25968;&#25454;&#12290;&#20027;&#35201;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#38750;&#21442;&#25968;&#38382;&#39064;&#20013;&#65292;&#24213;&#23618;&#20989;&#25968;&#31867;&#30340;&#22797;&#26434;&#24615;&#21644;&#35266;&#27979;&#20043;&#38388;&#23384;&#22312;&#19968;&#31181;&#38750;&#24179;&#20961;&#30340;&#26435;&#34913;&#65292;&#20915;&#23450;&#20102;&#23398;&#20064;&#36895;&#29575;&#12290;&#36825;&#19968;&#26435;&#34913;&#25581;&#31034;&#20102;&#19968;&#31181;&#26032;&#29616;&#35937;&#65292;&#22312;&#38271;&#26399;&#20381;&#36182;&#30340;&#24773;&#20917;&#19979;&#65292;&#20063;&#21487;&#20197;&#36798;&#21040;&#19982;&#29420;&#31435;&#21516;&#20998;&#24067;&#35774;&#32622;&#30456;&#21516;&#30340;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2401.08978</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;&#23398;&#20064;&#20013;&#20381;&#36182;&#24615;&#21644;&#22797;&#26434;&#24615;&#30340;&#26435;&#34913; -- &#19968;&#31181;&#32463;&#39564;&#36807;&#31243;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Trade-off Between Dependence and Complexity for Nonparametric Learning -- an Empirical Process Approach. (arXiv:2401.08978v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08978
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#30028;&#38480;&#65292;&#35813;&#30028;&#38480;&#35206;&#30422;&#20102;&#29420;&#31435;&#21516;&#20998;&#24067;&#20197;&#21450;&#23384;&#22312;&#38271;&#26399;&#21644;&#30701;&#26399;&#20381;&#36182;&#30340;&#25968;&#25454;&#12290;&#20027;&#35201;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#38750;&#21442;&#25968;&#38382;&#39064;&#20013;&#65292;&#24213;&#23618;&#20989;&#25968;&#31867;&#30340;&#22797;&#26434;&#24615;&#21644;&#35266;&#27979;&#20043;&#38388;&#23384;&#22312;&#19968;&#31181;&#38750;&#24179;&#20961;&#30340;&#26435;&#34913;&#65292;&#20915;&#23450;&#20102;&#23398;&#20064;&#36895;&#29575;&#12290;&#36825;&#19968;&#26435;&#34913;&#25581;&#31034;&#20102;&#19968;&#31181;&#26032;&#29616;&#35937;&#65292;&#22312;&#38271;&#26399;&#20381;&#36182;&#30340;&#24773;&#20917;&#19979;&#65292;&#20063;&#21487;&#20197;&#36798;&#21040;&#19982;&#29420;&#31435;&#21516;&#20998;&#24067;&#35774;&#32622;&#30456;&#21516;&#30340;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32463;&#39564;&#36807;&#31243;&#29702;&#35770;&#24050;&#32463;&#25104;&#20026;&#29702;&#35299;&#21508;&#31181;&#32479;&#35745;&#38382;&#39064;&#27867;&#29992;&#24037;&#20855;&#30340;&#29420;&#29305;&#24037;&#20855;&#65292;&#23588;&#20854;&#36866;&#29992;&#20110;&#29420;&#31435;&#21516;&#20998;&#24067;&#35266;&#27979;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#25968;&#25454;&#21576;&#29616;&#26102;&#38388;&#20381;&#36182;&#24615;&#30340;&#24212;&#29992;&#20013;&#65288;&#22914;&#37329;&#34701;&#12289;&#21307;&#23398;&#24433;&#20687;&#12289;&#22825;&#27668;&#39044;&#25253;&#31561;&#65289;&#65292;&#30456;&#24212;&#30340;&#32463;&#39564;&#36807;&#31243;&#21017;&#20102;&#35299;&#24471;&#19981;&#22810;&#12290;&#21463;&#21040;&#36825;&#19968;&#35266;&#23519;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#26631;&#20934;&#30340;&#946;/&#961;&#28151;&#21512;&#20551;&#35774;&#19979;&#32463;&#39564;&#36807;&#31243;&#26399;&#26395;&#19978;&#30830;&#30028;&#30340;&#19968;&#33324;&#30028;&#38480;&#12290;&#19982;&#22823;&#22810;&#25968;&#29616;&#26377;&#24037;&#20316;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#28085;&#30422;&#20102;&#38271;&#26399;&#21644;&#30701;&#26399;&#20381;&#36182;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26174;&#31034;&#65292;&#22312;&#22823;&#31867;&#38750;&#21442;&#25968;&#38382;&#39064;&#20013;&#65292;&#24213;&#23618;&#20989;&#25968;&#31867;&#30340;&#22797;&#26434;&#24615;&#21644;&#35266;&#27979;&#20043;&#38388;&#30340;&#20381;&#36182;&#24615;&#20043;&#38388;&#23384;&#22312;&#19968;&#31181;&#38750;&#24179;&#20961;&#30340;&#26435;&#34913;&#65292;&#36825;&#19968;&#26435;&#34913;&#20915;&#23450;&#20102;&#23398;&#20064;&#36895;&#29575;&#12290;&#36825;&#31181;&#26435;&#34913;&#25581;&#31034;&#20102;&#19968;&#31181;&#26032;&#29616;&#35937;&#65292;&#21363;&#22312;&#38271;&#26399;&#20381;&#36182;&#24773;&#20917;&#19979;&#65292;&#20063;&#21487;&#20197;&#36798;&#21040;&#19982;&#29420;&#31435;&#21516;&#20998;&#24067;&#35774;&#32622;&#30456;&#21516;&#30340;&#36895;&#29575;&#65292;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Empirical process theory for i.i.d. observations has emerged as a ubiquitous tool for understanding the generalization properties of various statistical problems. However, in many applications where the data exhibit temporal dependencies (e.g., in finance, medical imaging, weather forecasting etc.), the corresponding empirical processes are much less understood. Motivated by this observation, we present a general bound on the expected supremum of empirical processes under standard $\beta/\rho$-mixing assumptions. Unlike most prior work, our results cover both the long and the short-range regimes of dependence. Our main result shows that a non-trivial trade-off between the complexity of the underlying function class and the dependence among the observations characterizes the learning rate in a large class of nonparametric problems. This trade-off reveals a new phenomenon, namely that even under long-range dependence, it is possible to attain the same rates as in the i.i.d. setting, prov
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#33258;&#28982;&#22270;&#20687;&#21644;&#21307;&#23398;&#22270;&#20687;&#39046;&#22495;&#23398;&#20064;&#26102;&#30340;&#24046;&#24322;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#19982;&#35757;&#32451;&#38598;&#32500;&#24230;&#26377;&#20851;&#30340;&#27867;&#21270;&#32553;&#25918;&#23450;&#24459;&#65292;&#24182;&#35748;&#20026;&#21307;&#23398;&#22270;&#20687;&#25968;&#25454;&#38598;&#26356;&#39640;&#30340;&#22266;&#26377;&#8220;&#26631;&#31614;&#38160;&#24230;&#8221;&#21487;&#33021;&#26159;&#20004;&#20010;&#39046;&#22495;&#20043;&#38388;&#26174;&#33879;&#24046;&#24322;&#30340;&#37096;&#20998;&#21407;&#22240;&#12290;</title><link>http://arxiv.org/abs/2401.08865</link><description>&lt;p&gt;
Intrinsic Dataset Properties&#23545;&#27867;&#21270;&#33021;&#21147;&#30340;&#24433;&#21709;&#65306;&#25581;&#31034;&#33258;&#28982;&#22270;&#20687;&#21644;&#21307;&#23398;&#22270;&#20687;&#20043;&#38388;&#30340;&#23398;&#20064;&#24046;&#24322;
&lt;/p&gt;
&lt;p&gt;
The Effect of Intrinsic Dataset Properties on Generalization: Unraveling Learning Differences Between Natural and Medical Images. (arXiv:2401.08865v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08865
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#33258;&#28982;&#22270;&#20687;&#21644;&#21307;&#23398;&#22270;&#20687;&#39046;&#22495;&#23398;&#20064;&#26102;&#30340;&#24046;&#24322;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#19982;&#35757;&#32451;&#38598;&#32500;&#24230;&#26377;&#20851;&#30340;&#27867;&#21270;&#32553;&#25918;&#23450;&#24459;&#65292;&#24182;&#35748;&#20026;&#21307;&#23398;&#22270;&#20687;&#25968;&#25454;&#38598;&#26356;&#39640;&#30340;&#22266;&#26377;&#8220;&#26631;&#31614;&#38160;&#24230;&#8221;&#21487;&#33021;&#26159;&#20004;&#20010;&#39046;&#22495;&#20043;&#38388;&#26174;&#33879;&#24046;&#24322;&#30340;&#37096;&#20998;&#21407;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#19981;&#21516;&#22270;&#20687;&#39046;&#22495;&#23398;&#20064;&#26102;&#30340;&#24046;&#24322;&#65292;&#36825;&#22312;&#20174;&#33258;&#28982;&#22270;&#20687;&#21040;&#20854;&#20182;&#19987;&#38376;&#39046;&#22495;&#65288;&#22914;&#21307;&#23398;&#22270;&#20687;&#65289;&#37319;&#29992;&#35745;&#31639;&#26426;&#35270;&#35273;&#25216;&#26415;&#26102;&#36890;&#24120;&#34987;&#24573;&#35270;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#35757;&#32451;&#38598;&#30340;&#22266;&#26377;&#32500;&#24230;($d_{data}$)&#19982;&#32593;&#32476;&#30340;&#27867;&#21270;&#38169;&#35823;&#19968;&#33324;&#20250;&#22686;&#21152;&#12290;&#28982;&#32780;&#65292;&#21307;&#23398;&#65288;&#25918;&#23556;&#23398;&#65289;&#21644;&#33258;&#28982;&#22270;&#20687;&#39046;&#22495;&#20043;&#38388;&#30340;&#36825;&#31181;&#20851;&#31995;&#30340;&#38497;&#23789;&#31243;&#24230;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#65292;&#19988;&#26080;&#29616;&#26377;&#30340;&#29702;&#35770;&#35299;&#37322;&#12290;&#25105;&#20204;&#36890;&#36807;&#24314;&#31435;&#24182;&#32463;&#39564;&#35777;&#19968;&#20010;&#19982;$d_{data}$&#30456;&#20851;&#30340;&#27867;&#21270;&#32553;&#25918;&#23450;&#24459;&#26469;&#35299;&#20915;&#36825;&#20010;&#30693;&#35782;&#31354;&#30333;&#65292;&#24182;&#25552;&#20986;&#32771;&#34385;&#21040;&#21307;&#23398;&#22270;&#20687;&#25968;&#25454;&#38598;&#26356;&#39640;&#30340;&#22266;&#26377;&#8220;&#26631;&#31614;&#38160;&#24230;&#8221;($K_F$)&#36825;&#19968;&#24230;&#37327;&#25351;&#26631;&#21487;&#20197;&#37096;&#20998;&#35299;&#37322;&#36825;&#20004;&#20010;&#39046;&#22495;&#20043;&#38388;&#30340;&#26174;&#33879;&#32553;&#25918;&#24046;&#24322;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21033;&#29992;&#27979;&#37327;&#36825;&#19968;&#25351;&#26631;&#21487;&#20197;&#25552;&#20379;&#30340;&#39069;&#22806;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates discrepancies in how neural networks learn from different imaging domains, which are commonly overlooked when adopting computer vision techniques from the domain of natural images to other specialized domains such as medical images. Recent works have found that the generalization error of a trained network typically increases with the intrinsic dimension ($d_{data}$) of its training set. Yet, the steepness of this relationship varies significantly between medical (radiological) and natural imaging domains, with no existing theoretical explanation. We address this gap in knowledge by establishing and empirically validating a generalization scaling law with respect to $d_{data}$, and propose that the substantial scaling discrepancy between the two considered domains may be at least partially attributed to the higher intrinsic "label sharpness" ($K_F$) of medical imaging datasets, a metric which we propose. Next, we demonstrate an additional benefit of measuring th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24046;&#24322;&#29305;&#24449;&#26410;&#25253;&#21578;&#23545;&#31639;&#27861;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#20998;&#26512;&#30340;&#27169;&#22411;&#36827;&#34892;&#21051;&#30011;&#12290;</title><link>http://arxiv.org/abs/2401.08788</link><description>&lt;p&gt;
&#24046;&#24322;&#29305;&#24449;&#26410;&#25253;&#21578;&#23545;&#31639;&#27861;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
The Impact of Differential Feature Under-reporting on Algorithmic Fairness. (arXiv:2401.08788v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08788
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24046;&#24322;&#29305;&#24449;&#26410;&#25253;&#21578;&#23545;&#31639;&#27861;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#20998;&#26512;&#30340;&#27169;&#22411;&#36827;&#34892;&#21051;&#30011;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20844;&#20849;&#37096;&#38376;&#30340;&#39044;&#27979;&#39118;&#38505;&#27169;&#22411;&#36890;&#24120;&#20351;&#29992;&#26356;&#23436;&#25972;&#30340;&#34892;&#25919;&#25968;&#25454;&#26469;&#24320;&#21457;&#65292;&#36825;&#20123;&#25968;&#25454;&#23545;&#20110;&#26356;&#22823;&#31243;&#24230;&#20381;&#36182;&#20844;&#20849;&#26381;&#21153;&#30340;&#20122;&#32676;&#20307;&#26356;&#20026;&#23436;&#25972;&#12290;&#20363;&#22914;&#65292;&#22312;&#32654;&#22269;&#65292;&#23545;&#20110;&#30001;&#21307;&#30103;&#34917;&#21161;&#21644;&#21307;&#30103;&#20445;&#38505;&#25903;&#25345;&#30340;&#20010;&#20154;&#65292;&#25919;&#24220;&#26426;&#26500;&#24120;&#24120;&#21487;&#20197;&#33719;&#24471;&#26377;&#20851;&#21307;&#30103;&#20445;&#20581;&#21033;&#29992;&#30340;&#20449;&#24687;&#65292;&#20294;&#23545;&#20110;&#31169;&#20154;&#20445;&#38505;&#30340;&#20154;&#21017;&#27809;&#26377;&#12290;&#23545;&#20844;&#20849;&#37096;&#38376;&#31639;&#27861;&#30340;&#25209;&#35780;&#25351;&#20986;&#65292;&#24046;&#24322;&#29305;&#24449;&#26410;&#25253;&#21578;&#23548;&#33268;&#31639;&#27861;&#20915;&#31574;&#20013;&#30340;&#19981;&#20844;&#24179;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#25968;&#25454;&#20559;&#35265;&#22312;&#25216;&#26415;&#35270;&#35282;&#19979;&#20173;&#28982;&#30740;&#31350;&#19981;&#36275;&#12290;&#34429;&#28982;&#20197;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#32771;&#23519;&#20102;&#28155;&#21152;&#29305;&#24449;&#22122;&#22768;&#21644;&#26126;&#30830;&#26631;&#35760;&#20026;&#32570;&#22833;&#30340;&#29305;&#24449;&#23545;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#65292;&#20294;&#32570;&#22833;&#25351;&#26631;&#30340;&#25968;&#25454;&#32570;&#22833;&#24773;&#20917;&#65288;&#21363;&#24046;&#24322;&#29305;&#24449;&#26410;&#25253;&#21578;&#65289;&#23578;&#26410;&#24471;&#21040;&#30740;&#31350;&#30340;&#20851;&#27880;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#20998;&#26512;&#30340;&#24046;&#24322;&#29305;&#24449;&#26410;&#25253;&#21578;&#27169;&#22411;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#29305;&#24449;&#26410;&#25253;&#21578;&#23545;&#31639;&#27861;&#20844;&#24179;&#24615;&#30340;&#21051;&#30011;&#12290;
&lt;/p&gt;
&lt;p&gt;
Predictive risk models in the public sector are commonly developed using administrative data that is more complete for subpopulations that more greatly rely on public services. In the United States, for instance, information on health care utilization is routinely available to government agencies for individuals supported by Medicaid and Medicare, but not for the privately insured. Critiques of public sector algorithms have identified such differential feature under-reporting as a driver of disparities in algorithmic decision-making. Yet this form of data bias remains understudied from a technical viewpoint. While prior work has examined the fairness impacts of additive feature noise and features that are clearly marked as missing, the setting of data missingness absent indicators (i.e. differential feature under-reporting) has been lacking in research attention. In this work, we present an analytically tractable model of differential feature under-reporting which we then use to charac
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#22312;&#38134;&#34892;&#19994;&#20013;&#35299;&#20915;&#20559;&#35265;&#20197;&#23454;&#29616;&#20844;&#24179;&#20915;&#31574;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#26080;&#32541;&#25972;&#21512;&#20844;&#24179;&#12289;&#21487;&#35299;&#37322;&#24615;&#21644;&#20154;&#31867;&#30417;&#30563;&#65292;&#26500;&#24314;&#36127;&#36131;&#20219;&#20154;&#24037;&#26234;&#33021;&#25991;&#21270;&#65292;&#20197;&#36981;&#23432;&#35268;&#23450;&#24182;&#31526;&#21512;&#20154;&#26435;&#26631;&#20934;&#12290;</title><link>http://arxiv.org/abs/2401.08691</link><description>&lt;p&gt;
&#22312;&#38134;&#34892;&#19994;&#23454;&#29616;&#36127;&#36131;&#20219;&#30340;&#20154;&#24037;&#26234;&#33021;&#65306;&#35299;&#20915;&#20559;&#35265;&#20197;&#23454;&#29616;&#20844;&#24179;&#20915;&#31574;
&lt;/p&gt;
&lt;p&gt;
Towards Responsible AI in Banking: Addressing Bias for Fair Decision-Making. (arXiv:2401.08691v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08691
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#22312;&#38134;&#34892;&#19994;&#20013;&#35299;&#20915;&#20559;&#35265;&#20197;&#23454;&#29616;&#20844;&#24179;&#20915;&#31574;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#26080;&#32541;&#25972;&#21512;&#20844;&#24179;&#12289;&#21487;&#35299;&#37322;&#24615;&#21644;&#20154;&#31867;&#30417;&#30563;&#65292;&#26500;&#24314;&#36127;&#36131;&#20219;&#20154;&#24037;&#26234;&#33021;&#25991;&#21270;&#65292;&#20197;&#36981;&#23432;&#35268;&#23450;&#24182;&#31526;&#21512;&#20154;&#26435;&#26631;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20154;&#24037;&#26234;&#33021;&#24191;&#27867;&#24212;&#29992;&#20110;&#21508;&#34892;&#21508;&#19994;&#30340;&#20915;&#31574;&#36807;&#31243;&#30340;&#26102;&#20195;&#65292;&#23545;&#20449;&#20219;&#30340;&#38656;&#27714;&#21464;&#24471;&#26356;&#21152;&#24378;&#28872;&#12290;&#26412;&#35770;&#25991;&#23545;&#20559;&#35265;&#21644;&#20844;&#24179;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#25506;&#35752;&#65292;&#29305;&#21035;&#20851;&#27880;&#23427;&#20204;&#22312;&#38134;&#34892;&#19994;&#20869;&#30340;&#24433;&#21709;&#65292;&#22240;&#20026;&#20197;&#20154;&#24037;&#26234;&#33021;&#39537;&#21160;&#30340;&#20915;&#31574;&#23545;&#31038;&#20250;&#20135;&#29983;&#20102;&#37325;&#22823;&#24433;&#21709;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#20844;&#24179;&#12289;&#21487;&#35299;&#37322;&#24615;&#21644;&#20154;&#31867;&#30417;&#30563;&#30340;&#26080;&#32541;&#25972;&#21512;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#65292;&#26368;&#32456;&#24418;&#25104;&#20102;&#25152;&#35859;&#30340;&#8220;&#36127;&#36131;&#20219;&#20154;&#24037;&#26234;&#33021;&#8221;&#12290;&#36825;&#24378;&#35843;&#20102;&#22312;&#24320;&#21457;&#31526;&#21512;&#20154;&#24037;&#26234;&#33021;&#35268;&#23450;&#21644;&#26222;&#19990;&#20154;&#26435;&#26631;&#20934;&#30340;&#20225;&#19994;&#25991;&#21270;&#26102;&#65292;&#35299;&#20915;&#20559;&#35265;&#30340;&#37325;&#35201;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#33258;&#21160;&#20915;&#31574;&#31995;&#32479;&#39046;&#22495;&#12290;&#22914;&#20170;&#65292;&#23558;&#20262;&#29702;&#21407;&#21017;&#34701;&#20837;&#21040;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#30340;&#24320;&#21457;&#12289;&#35757;&#32451;&#21644;&#37096;&#32626;&#20013;&#23545;&#20110;&#36981;&#23432;&#21363;&#23558;&#21040;&#26469;&#30340;&#35268;&#23450;&#38750;&#24120;&#20851;&#38190;&#12290;
&lt;/p&gt;
&lt;p&gt;
In an era characterized by the pervasive integration of artificial intelligence into decision-making processes across diverse industries, the demand for trust has never been more pronounced. This thesis embarks on a comprehensive exploration of bias and fairness, with a particular emphasis on their ramifications within the banking sector, where AI-driven decisions bear substantial societal consequences. In this context, the seamless integration of fairness, explainability, and human oversight is of utmost importance, culminating in the establishment of what is commonly referred to as "Responsible AI". This emphasizes the critical nature of addressing biases within the development of a corporate culture that aligns seamlessly with both AI regulations and universal human rights standards, particularly in the realm of automated decision-making systems. Nowadays, embedding ethical principles into the development, training, and deployment of AI models is crucial for compliance with forthcom
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#29992;&#20110;&#20855;&#26377;&#26410;&#35266;&#27979;&#21464;&#37327;&#30340;&#22240;&#26524;&#21487;&#21152;&#27169;&#22411;&#65288;CAM-UV&#65289;&#30340;&#26041;&#27861;&#65292;&#24182;&#25193;&#23637;&#20102;&#36825;&#20123;&#26041;&#27861;&#20197;&#24212;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#12290;&#36825;&#20123;&#26041;&#27861;&#21033;&#29992;&#20808;&#39564;&#30693;&#35782;&#36827;&#34892;&#39640;&#25928;&#22240;&#26524;&#21457;&#29616;&#65292;&#24182;&#20855;&#26377;&#23545;&#22240;&#26524;&#20851;&#31995;&#39034;&#24207;&#30340;&#29305;&#27530;&#22788;&#29702;&#12290;</title><link>http://arxiv.org/abs/2401.07231</link><description>&lt;p&gt;
&#21033;&#29992;&#20808;&#39564;&#30693;&#35782;&#21457;&#29616;&#20855;&#26377;&#26410;&#35266;&#27979;&#21464;&#37327;&#30340;&#22240;&#26524;&#21487;&#21152;&#27169;&#22411;&#21450;&#20854;&#22312;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Use of Prior Knowledge to Discover Causal Additive Models with Unobserved Variables and its Application to Time Series Data. (arXiv:2401.07231v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.07231
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#29992;&#20110;&#20855;&#26377;&#26410;&#35266;&#27979;&#21464;&#37327;&#30340;&#22240;&#26524;&#21487;&#21152;&#27169;&#22411;&#65288;CAM-UV&#65289;&#30340;&#26041;&#27861;&#65292;&#24182;&#25193;&#23637;&#20102;&#36825;&#20123;&#26041;&#27861;&#20197;&#24212;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#12290;&#36825;&#20123;&#26041;&#27861;&#21033;&#29992;&#20808;&#39564;&#30693;&#35782;&#36827;&#34892;&#39640;&#25928;&#22240;&#26524;&#21457;&#29616;&#65292;&#24182;&#20855;&#26377;&#23545;&#22240;&#26524;&#20851;&#31995;&#39034;&#24207;&#30340;&#29305;&#27530;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#29992;&#20110;&#20855;&#26377;&#26410;&#35266;&#27979;&#21464;&#37327;&#30340;&#22240;&#26524;&#21487;&#21152;&#27169;&#22411;&#65288;CAM-UV&#65289;&#30340;&#26041;&#27861;&#12290;CAM-UV&#20551;&#35774;&#22240;&#26524;&#20989;&#25968;&#37319;&#29992;&#24191;&#20041;&#21487;&#21152;&#27169;&#22411;&#30340;&#24418;&#24335;&#65292;&#24182;&#23384;&#22312;&#28508;&#22312;&#30340;&#28151;&#28102;&#21464;&#37327;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#20808;&#39564;&#30693;&#35782;&#36827;&#34892;&#39640;&#25928;&#22240;&#26524;&#21457;&#29616;&#30340;&#26041;&#27861;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#36825;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#25512;&#26029;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#22240;&#26524;&#20851;&#31995;&#12290;&#19982;&#20854;&#20182;&#29616;&#26377;&#30340;&#22240;&#26524;&#20989;&#25968;&#27169;&#22411;&#19981;&#21516;&#65292;&#21407;&#22987;&#30340;CAM-UV&#31639;&#27861;&#19981;&#23547;&#27714;&#35266;&#27979;&#21464;&#37327;&#20043;&#38388;&#30340;&#22240;&#26524;&#39034;&#24207;&#65292;&#32780;&#26159;&#26088;&#22312;&#30830;&#23450;&#27599;&#20010;&#35266;&#27979;&#21464;&#37327;&#30340;&#21407;&#22240;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#20013;&#25552;&#20986;&#30340;&#31532;&#19968;&#31181;&#26041;&#27861;&#21033;&#29992;&#20808;&#39564;&#30693;&#35782;&#65292;&#20363;&#22914;&#29702;&#35299;&#26576;&#20123;&#21464;&#37327;&#19981;&#33021;&#25104;&#20026;&#29305;&#23450;&#21464;&#37327;&#30340;&#21407;&#22240;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#34701;&#20837;&#22240;&#26524;&#22312;&#26102;&#38388;&#19978;&#30340;&#20808;&#39564;&#30693;&#35782;&#65292;&#25105;&#20204;&#23558;&#31532;&#19968;&#20010;&#31639;&#27861;&#25193;&#23637;&#20026;&#31532;&#20108;&#31181;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#30340;&#22240;&#26524;&#21457;&#29616;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#39564;&#35777;&#20102;&#31532;&#19968;&#20010;&#25552;&#20986;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes two methods for causal additive models with unobserved variables (CAM-UV). CAM-UV assumes that the causal functions take the form of generalized additive models and that latent confounders are present. First, we propose a method that leverages prior knowledge for efficient causal discovery. Then, we propose an extension of this method for inferring causality in time series data. The original CAM-UV algorithm differs from other existing causal function models in that it does not seek the causal order between observed variables, but rather aims to identify the causes for each observed variable. Therefore, the first proposed method in this paper utilizes prior knowledge, such as understanding that certain variables cannot be causes of specific others. Moreover, by incorporating the prior knowledge that causes precedes their effects in time, we extend the first algorithm to the second method for causal discovery in time series data. We validate the first proposed method
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#31639;&#23376;&#27969;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#36817;&#20284;&#26102;&#38388;&#30456;&#20851;&#31639;&#23376;&#65292;&#23454;&#29616;&#20102;&#22312;&#37327;&#23376;&#22330;&#35770;&#20013;&#20174;&#24213;&#23618;&#33258;&#30001;&#29702;&#35770;&#21040;&#30446;&#26631;&#29702;&#35770;&#30340;&#31163;&#25955;-&#36830;&#32493;&#24402;&#19968;&#21270;&#27969;&#12290;</title><link>http://arxiv.org/abs/2401.00828</link><description>&lt;p&gt;
&#22522;&#20110;&#31070;&#32463;&#31639;&#23376;&#27969;&#30340;&#37327;&#23376;&#22330;&#35770;&#22810;&#26684;&#37319;&#26679;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Multi-Lattice Sampling of Quantum Field Theories via Neural Operator-based Flows. (arXiv:2401.00828v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.00828
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#31639;&#23376;&#27969;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#36817;&#20284;&#26102;&#38388;&#30456;&#20851;&#31639;&#23376;&#65292;&#23454;&#29616;&#20102;&#22312;&#37327;&#23376;&#22330;&#35770;&#20013;&#20174;&#24213;&#23618;&#33258;&#30001;&#29702;&#35770;&#21040;&#30446;&#26631;&#29702;&#35770;&#30340;&#31163;&#25955;-&#36830;&#32493;&#24402;&#19968;&#21270;&#27969;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20174;&#29627;&#23572;&#20857;&#26364;&#20998;&#24067;&#20013;&#37319;&#26679;&#31163;&#25955;&#22330;&#37197;&#32622;$\phi$&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;$S$&#26159;&#26576;&#20010;&#37327;&#23376;&#22330;&#35770;&#36830;&#32493;&#27431;&#20960;&#37324;&#24471;&#20316;&#29992;$\mathcal S$&#30340;&#26684;&#28857;&#31163;&#25955;&#21270;&#12290;&#25105;&#20204;&#23558;&#35813;&#23494;&#24230;&#36817;&#20284;&#35270;&#20026;&#24213;&#23618;&#20989;&#25968;&#23494;&#24230;$[\mathcal D\phi(x)]\mathcal Z^{-1}e^{-\mathcal S[\phi(x)]}$&#30340;&#23398;&#20064;&#31639;&#23376;&#23454;&#20363;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36817;&#20284;&#26102;&#38388;&#30456;&#20851;&#31639;&#23376;$\mathcal V_t$&#30340;&#26041;&#27861;&#65292;&#20854;&#26102;&#38388;&#31215;&#20998;&#25552;&#20379;&#20102;&#33258;&#30001;&#29702;&#35770;$[\mathcal D\phi(x)]\mathcal Z_0^{-1}e^{-\mathcal S_{0}[\phi(x)]}$&#30340;&#20989;&#25968;&#20998;&#24067;&#19982;&#30446;&#26631;&#29702;&#35770;$[\mathcal D\phi(x)]\mathcal Z^{-1}e^{-\mathcal S[\phi(x)]}$&#20043;&#38388;&#30340;&#26144;&#23556;&#12290;&#24403;&#36873;&#25321;&#29305;&#23450;&#30340;&#26684;&#28857;&#26102;&#65292;&#31639;&#23376;$\mathcal V_t$&#21487;&#20197;&#31163;&#25955;&#21270;&#20026;&#26377;&#38480;&#32500;&#30340;&#26102;&#38388;&#30456;&#20851;&#30690;&#37327;&#22330;$V_t$&#65292;&#20174;&#32780;&#22312;&#31163;&#25955;&#26684;&#28857;&#19978;&#23454;&#29616;&#20102;&#36830;&#32493;&#30340;&#24402;&#19968;&#21270;&#27969;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of sampling discrete field configurations $\phi$ from the Boltzmann distribution $[d\phi] Z^{-1} e^{-S[\phi]}$, where $S$ is the lattice-discretization of the continuous Euclidean action $\mathcal S$ of some quantum field theory. Since such densities arise as the approximation of the underlying functional density $[\mathcal D\phi(x)] \mathcal Z^{-1} e^{-\mathcal S[\phi(x)]}$, we frame the task as an instance of operator learning. In particular, we propose to approximate a time-dependent operator $\mathcal V_t$ whose time integral provides a mapping between the functional distributions of the free theory $[\mathcal D\phi(x)] \mathcal Z_0^{-1} e^{-\mathcal S_{0}[\phi(x)]}$ and of the target theory $[\mathcal D\phi(x)]\mathcal Z^{-1}e^{-\mathcal S[\phi(x)]}$. Whenever a particular lattice is chosen, the operator $\mathcal V_t$ can be discretized to a finite dimensional, time-dependent vector field $V_t$ which in turn induces a continuous normalizing flow between fi
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#20248;&#21270;&#22312;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#19978;&#23450;&#20041;&#30340;&#38750;&#32447;&#24615;&#27867;&#20989;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#35757;&#32451;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#12289;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#26368;&#23567;&#21270;&#21644;&#26680;&#26031;&#22374;&#24046;&#24322;&#26368;&#23567;&#21270;&#38382;&#39064;&#12290;&#31639;&#27861;&#22522;&#20110;&#22343;&#22330;&#27424;&#38459;&#23612;&#26391;&#20043;&#19975;&#21160;&#21147;&#23398;&#30340;&#26032;&#39062;&#26102;&#31354;&#31163;&#25955;&#21270;&#65292;&#20855;&#26377;&#24555;&#36895;&#28151;&#21512;&#20445;&#35777;&#65292;&#24182;&#19988;&#22312;&#24635;&#21464;&#21270;&#36317;&#31163;&#19979;&#20840;&#23616;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2312.16360</link><description>&lt;p&gt;
&#22343;&#22330;&#27424;&#38459;&#23612;&#26391;&#20043;&#19975;&#21160;&#21147;&#23398;&#21450;&#20854;&#26102;&#31354;&#31163;&#25955;&#21270;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Mean-field underdamped Langevin dynamics and its spacetime discretization. (arXiv:2312.16360v3 [stat.CO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.16360
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#20248;&#21270;&#22312;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#19978;&#23450;&#20041;&#30340;&#38750;&#32447;&#24615;&#27867;&#20989;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#35757;&#32451;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#12289;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#26368;&#23567;&#21270;&#21644;&#26680;&#26031;&#22374;&#24046;&#24322;&#26368;&#23567;&#21270;&#38382;&#39064;&#12290;&#31639;&#27861;&#22522;&#20110;&#22343;&#22330;&#27424;&#38459;&#23612;&#26391;&#20043;&#19975;&#21160;&#21147;&#23398;&#30340;&#26032;&#39062;&#26102;&#31354;&#31163;&#25955;&#21270;&#65292;&#20855;&#26377;&#24555;&#36895;&#28151;&#21512;&#20445;&#35777;&#65292;&#24182;&#19988;&#22312;&#24635;&#21464;&#21270;&#36317;&#31163;&#19979;&#20840;&#23616;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;N&#31890;&#23376;&#27424;&#38459;&#23612;&#26391;&#20043;&#19975;&#31639;&#27861;&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#20248;&#21270;&#22312;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#19978;&#23450;&#20041;&#30340;&#19968;&#31867;&#38750;&#32447;&#24615;&#27867;&#20989;&#12290;&#36825;&#31181;&#20844;&#24335;&#30340;&#38382;&#39064;&#31034;&#20363;&#21253;&#25324;&#35757;&#32451;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#12289;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#26368;&#23567;&#21270;&#21644;&#26680;&#26031;&#22374;&#24046;&#24322;&#26368;&#23567;&#21270;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22522;&#20110;&#22343;&#22330;&#27424;&#38459;&#23612;&#26391;&#20043;&#19975;&#21160;&#21147;&#23398;&#30340;&#26032;&#39062;&#26102;&#31354;&#31163;&#25955;&#21270;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#24555;&#36895;&#28151;&#21512;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#24635;&#21464;&#21270;&#36317;&#31163;&#19979;&#20840;&#23616;&#25910;&#25947;&#65292;&#22635;&#34917;&#20102;&#21160;&#21147;&#23398;&#19982;&#23454;&#38469;&#23454;&#26045;&#20043;&#38388;&#30340;&#29702;&#35770;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new method called the N-particle underdamped Langevin algorithm for optimizing a special class of non-linear functionals defined over the space of probability measures. Examples of problems with this formulation include training mean-field neural networks, maximum mean discrepancy minimization and kernel Stein discrepancy minimization. Our algorithm is based on a novel spacetime discretization of the mean-field underdamped Langevin dynamics, for which we provide a new, fast mixing guarantee. In addition, we demonstrate that our algorithm converges globally in total variation distance, bridging the theoretical gap between the dynamics and its practical implementation.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#27604;&#36739;&#20102;&#19981;&#21464;&#21644;&#31561;&#21464;&#30340;&#32463;&#20856;&#21644;&#37327;&#23376;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#25506;&#35752;&#20102;&#23427;&#20204;&#22312;&#39640;&#33021;&#29289;&#29702;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;&#65292;&#20197;&#21450;&#22914;&#20309;&#21033;&#29992;&#37327;&#23376;&#35745;&#31639;&#25552;&#20379;&#24555;&#36895;&#32780;&#39640;&#25928;&#30340;&#35745;&#31639;&#33539;&#24335;&#12290;&#21516;&#26102;&#65292;&#30740;&#31350;&#36824;&#25351;&#20986;&#36890;&#36807;&#20351;&#29992;&#19981;&#21464;&#36755;&#20837;&#21644;&#31561;&#21464;&#23618;&#65292;&#21487;&#20197;&#22686;&#24378;&#28145;&#24230;&#32593;&#32476;&#30340;&#26377;&#25928;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.18672</link><description>&lt;p&gt;
&#19981;&#21464;&#21644;&#31561;&#21464;&#30340;&#32463;&#20856;&#21644;&#37327;&#23376;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
A Comparison Between Invariant and Equivariant Classical and Quantum Graph Neural Networks. (arXiv:2311.18672v2 [quant-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.18672
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#27604;&#36739;&#20102;&#19981;&#21464;&#21644;&#31561;&#21464;&#30340;&#32463;&#20856;&#21644;&#37327;&#23376;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#25506;&#35752;&#20102;&#23427;&#20204;&#22312;&#39640;&#33021;&#29289;&#29702;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;&#65292;&#20197;&#21450;&#22914;&#20309;&#21033;&#29992;&#37327;&#23376;&#35745;&#31639;&#25552;&#20379;&#24555;&#36895;&#32780;&#39640;&#25928;&#30340;&#35745;&#31639;&#33539;&#24335;&#12290;&#21516;&#26102;&#65292;&#30740;&#31350;&#36824;&#25351;&#20986;&#36890;&#36807;&#20351;&#29992;&#19981;&#21464;&#36755;&#20837;&#21644;&#31561;&#21464;&#23618;&#65292;&#21487;&#20197;&#22686;&#24378;&#28145;&#24230;&#32593;&#32476;&#30340;&#26377;&#25928;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#22312;&#29702;&#35299;CERN&#22823;&#22411;&#24378;&#23376;&#23545;&#25758;&#26426;(LHC)&#19978;&#20135;&#29983;&#30340;&#22823;&#37327;&#39640;&#33021;&#31890;&#23376;&#30896;&#25758;&#25968;&#25454;&#26102;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#36825;&#20123;&#30896;&#25758;&#20107;&#20214;&#30340;&#25968;&#25454;&#21487;&#20197;&#33258;&#28982;&#22320;&#29992;&#22270;&#32467;&#26500;&#34920;&#31034;&#12290;&#22240;&#27492;&#65292;&#28145;&#24230;&#20960;&#20309;&#26041;&#27861;&#65292;&#22914;&#22270;&#31070;&#32463;&#32593;&#32476;(GNNs)&#65292;&#24050;&#32463;&#22312;&#39640;&#33021;&#29289;&#29702;&#25968;&#25454;&#20998;&#26512;&#30340;&#21508;&#31181;&#20219;&#21153;&#20013;&#24471;&#21040;&#24212;&#29992;&#12290;&#19968;&#20010;&#20856;&#22411;&#30340;&#20219;&#21153;&#26159;&#21943;&#27880;&#26631;&#35760;&#65292;&#20854;&#20013;&#21943;&#27880;&#34987;&#35270;&#20026;&#20855;&#26377;&#19981;&#21516;&#29305;&#24449;&#21644;&#20854;&#32452;&#25104;&#31890;&#23376;&#20043;&#38388;&#30340;&#36793;&#36830;&#25509;&#30340;&#28857;&#20113;&#12290;LHC&#31890;&#23376;&#25968;&#25454;&#38598;&#30340;&#35268;&#27169;&#21644;&#22797;&#26434;&#24615;&#30340;&#22686;&#21152;&#65292;&#20197;&#21450;&#29992;&#20110;&#20854;&#20998;&#26512;&#30340;&#35745;&#31639;&#27169;&#22411;&#65292;&#22823;&#22823;&#20419;&#36827;&#20102;&#24320;&#21457;&#26367;&#20195;&#24555;&#36895;&#19988;&#39640;&#25928;&#30340;&#35745;&#31639;&#33539;&#24335;&#65292;&#22914;&#37327;&#23376;&#35745;&#31639;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#22686;&#24378;&#28145;&#24230;&#32593;&#32476;&#30340;&#26377;&#25928;&#24615;&#21644;&#40065;&#26834;&#24615;&#65292;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#19981;&#21464;&#36755;&#20837;&#21644;&#31561;&#21464;&#23618;&#26469;&#21033;&#29992;&#25968;&#25454;&#20013;&#23384;&#22312;&#30340;&#22522;&#26412;&#23545;&#31216;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning algorithms are heavily relied on to understand the vast amounts of data from high-energy particle collisions at the CERN Large Hadron Collider (LHC). The data from such collision events can naturally be represented with graph structures. Therefore, deep geometric methods, such as graph neural networks (GNNs), have been leveraged for various data analysis tasks in high-energy physics. One typical task is jet tagging, where jets are viewed as point clouds with distinct features and edge connections between their constituent particles. The increasing size and complexity of the LHC particle datasets, as well as the computational models used for their analysis, greatly motivate the development of alternative fast and efficient computational paradigms such as quantum computation. In addition, to enhance the validity and robustness of deep networks, one can leverage the fundamental symmetries present in the data through the use of invariant inputs and equivariant layers. In t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#26377;&#30028;&#22686;&#38271;&#21487;&#31215;&#20989;&#25968;&#31354;&#38388;&#30340;Hilbert&#25237;&#24433;&#24230;&#37327;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;&#26576;&#20123;&#26494;&#24347;&#38181;&#20307;&#20869;&#30340;&#20869;&#26680;&#31215;&#20998;&#31639;&#23376;&#20855;&#26377;&#21387;&#32553;&#26144;&#23556;&#30340;&#24615;&#36136;&#65292;&#24182;&#24212;&#29992;&#20110;&#29109;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#20013;&#65292;&#35777;&#26126;&#20102;Sinkhorn&#31639;&#27861;&#22312;&#36793;&#38469;&#20998;&#24067;&#30340;&#23614;&#37096;&#19982;&#25104;&#26412;&#20989;&#25968;&#22686;&#38271;&#36866;&#24403;&#26102;&#21576;&#25351;&#25968;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2311.04041</link><description>&lt;p&gt;
Hilbert&#30340;&#25237;&#24433;&#24230;&#37327;&#29992;&#20110;&#26377;&#30028;&#22686;&#38271;&#20989;&#25968;&#21644;Sinkhorn&#31639;&#27861;&#30340;&#25351;&#25968;&#25910;&#25947;
&lt;/p&gt;
&lt;p&gt;
Hilbert's projective metric for functions of bounded growth and exponential convergence of Sinkhorn's algorithm. (arXiv:2311.04041v2 [math.PR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.04041
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#26377;&#30028;&#22686;&#38271;&#21487;&#31215;&#20989;&#25968;&#31354;&#38388;&#30340;Hilbert&#25237;&#24433;&#24230;&#37327;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;&#26576;&#20123;&#26494;&#24347;&#38181;&#20307;&#20869;&#30340;&#20869;&#26680;&#31215;&#20998;&#31639;&#23376;&#20855;&#26377;&#21387;&#32553;&#26144;&#23556;&#30340;&#24615;&#36136;&#65292;&#24182;&#24212;&#29992;&#20110;&#29109;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#20013;&#65292;&#35777;&#26126;&#20102;Sinkhorn&#31639;&#27861;&#22312;&#36793;&#38469;&#20998;&#24067;&#30340;&#23614;&#37096;&#19982;&#25104;&#26412;&#20989;&#25968;&#22686;&#38271;&#36866;&#24403;&#26102;&#21576;&#25351;&#25968;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#26080;&#30028;&#29615;&#22659;&#20013;&#30340;&#29109;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26377;&#30028;&#22686;&#38271;&#21487;&#31215;&#20989;&#25968;&#31354;&#38388;&#30340;Hilbert&#25237;&#24433;&#24230;&#37327;&#29256;&#26412;&#12290;&#36825;&#20123;Hilbert&#24230;&#37327;&#29256;&#26412;&#28304;&#33258;&#38181;&#20307;&#65292;&#36825;&#20123;&#38181;&#20307;&#26159;&#25152;&#26377;&#38750;&#36127;&#20989;&#25968;&#30340;&#26494;&#24347;&#65292;&#21363;&#23427;&#20204;&#21253;&#25324;&#25152;&#26377;&#22312;&#19982;&#26576;&#20123;&#27979;&#35797;&#20989;&#25968;&#30456;&#20056;&#26102;&#20855;&#26377;&#38750;&#36127;&#31215;&#20998;&#20540;&#30340;&#20989;&#25968;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20869;&#26680;&#31215;&#20998;&#31639;&#23376;&#22312;&#36866;&#24403;&#30340;&#24230;&#37327;&#35268;&#33539;&#19979;&#26159;&#21387;&#32553;&#26144;&#23556;&#65292;&#21363;&#20351;&#20869;&#26680;&#27809;&#26377;&#19982;&#38646;&#38388;&#38548;&#65292;&#21069;&#25552;&#26159;&#20869;&#26680;&#36235;&#21521;&#20110;&#38646;&#21463;&#25511;&#21046;&#12290;&#20316;&#20026;&#29109;&#26368;&#20248;&#20256;&#36755;&#30340;&#24212;&#29992;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#36793;&#38469;&#20998;&#24067;&#30340;&#23614;&#37096;&#30456;&#23545;&#20110;&#25104;&#26412;&#20989;&#25968;&#30340;&#22686;&#38271;&#36275;&#22815;&#36731;&#26102;&#65292;Sinkhorn&#31639;&#27861;&#21576;&#25351;&#25968;&#25910;&#25947;&#30340;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by the entropic optimal transport problem in unbounded settings, we study versions of Hilbert's projective metric for spaces of integrable functions of bounded growth. These versions of Hilbert's metric originate from cones which are relaxations of the cone of all non-negative functions, in the sense that they include all functions having non-negative integral values when multiplied with certain test functions. We show that kernel integral operators are contractions with respect to suitable specifications of such metrics even for kernels which are not bounded away from zero, provided that the decay to zero of the kernel is controlled. As an application to entropic optimal transport, we show exponential convergence of Sinkhorn's algorithm in settings where the marginal distributions have sufficiently light tails compared to the growth of the cost function.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24191;&#20041;&#20302;&#31209;&#24352;&#37327;&#24773;&#22659;&#36172;&#21338;&#31639;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;G-LowTESTR&#31639;&#27861;&#26469;&#23454;&#29616;&#25506;&#32034;&#21644;&#21033;&#29992;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2311.01771</link><description>&lt;p&gt;
&#39640;&#25928;&#30340;&#24191;&#20041;&#20302;&#31209;&#24352;&#37327;&#24773;&#22659;&#36172;&#21338;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient Generalized Low-Rank Tensor Contextual Bandits. (arXiv:2311.01771v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01771
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24191;&#20041;&#20302;&#31209;&#24352;&#37327;&#24773;&#22659;&#36172;&#21338;&#31639;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;G-LowTESTR&#31639;&#27861;&#26469;&#23454;&#29616;&#25506;&#32034;&#21644;&#21033;&#29992;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#26500;&#24314;&#19968;&#31181;&#26032;&#39062;&#30340;&#36172;&#21338;&#31639;&#27861;&#65292;&#33021;&#22815;&#20805;&#20998;&#21033;&#29992;&#22810;&#32500;&#25968;&#25454;&#21644;&#22870;&#21169;&#20989;&#25968;&#30340;&#22266;&#26377;&#38750;&#32447;&#24615;&#29305;&#24615;&#65292;&#25552;&#20379;&#39640;&#21487;&#29992;&#21644;&#36127;&#36131;&#20219;&#30340;&#20915;&#31574;&#26381;&#21153;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#24191;&#20041;&#20302;&#31209;&#24352;&#37327;&#24773;&#22659;&#36172;&#21338;&#27169;&#22411;&#65292;&#20854;&#20013;&#19968;&#20010;&#21160;&#20316;&#30001;&#19977;&#20010;&#29305;&#24449;&#21521;&#37327;&#32452;&#25104;&#65292;&#22240;&#27492;&#21487;&#20197;&#29992;&#24352;&#37327;&#34920;&#31034;&#12290;&#22312;&#36825;&#20010;&#27169;&#22411;&#20013;&#65292;&#22870;&#21169;&#26159;&#36890;&#36807;&#23558;&#21160;&#20316;&#30340;&#29305;&#24449;&#24352;&#37327;&#19982;&#19968;&#20010;&#22266;&#23450;&#20294;&#26410;&#30693;&#30340;&#21442;&#25968;&#24352;&#37327;&#30340;&#20869;&#31215;&#24212;&#29992;&#20110;&#24191;&#20041;&#32447;&#24615;&#20989;&#25968;&#26469;&#30830;&#23450;&#30340;&#65292;&#32780;&#36825;&#20010;&#21442;&#25968;&#24352;&#37327;&#20855;&#26377;&#36739;&#20302;&#30340;&#31649;&#29366;&#31209;&#12290;&#20026;&#20102;&#23454;&#29616;&#25506;&#32034;&#21644;&#21033;&#29992;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#24191;&#20041;&#20302;&#31209;&#24352;&#37327;&#25506;&#32034;&#23376;&#31354;&#38388;&#28982;&#21518;&#32454;&#21270;&#8221;&#30340;&#26032;&#31639;&#27861;&#65288;G-LowTESTR&#65289;&#12290;&#35813;&#31639;&#27861;&#39318;&#20808;&#25910;&#38598;&#21407;&#22987;&#25968;&#25454;&#65292;&#20197;&#25506;&#32034;&#23884;&#20837;&#22312;&#20915;&#31574;&#24773;&#22659;&#20013;&#30340;&#26412;&#36136;&#20302;&#31209;&#24352;&#37327;&#23376;&#31354;&#38388;&#20449;&#24687;&#65292;&#28982;&#21518;&#23558;&#21407;&#22987;&#27010;&#29575;&#36716;&#25442;&#20026;&#21487;&#35299;&#37322;&#30340;&#32467;&#26500;&#21270;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we aim to build a novel bandits algorithm that is capable of fully harnessing the power of multi-dimensional data and the inherent non-linearity of reward functions to provide high-usable and accountable decision-making services. To this end, we introduce a generalized low-rank tensor contextual bandits model in which an action is formed from three feature vectors, and thus can be represented by a tensor. In this formulation, the reward is determined through a generalized linear function applied to the inner product of the action's feature tensor and a fixed but unknown parameter tensor with a low tubal rank. To effectively achieve the trade-off between exploration and exploitation, we introduce a novel algorithm called "Generalized Low-Rank Tensor Exploration Subspace then Refine" (G-LowTESTR). This algorithm first collects raw data to explore the intrinsic low-rank tensor subspace information embedded in the decision-making scenario, and then converts the original prob
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21518;&#39564;&#20559;&#24046;&#35780;&#20998;&#30340;&#26041;&#27861;&#65292;&#22312;&#28385;&#36275;&#20844;&#24179;&#24615;&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#20445;&#25345;&#39640;&#20934;&#30830;&#24615;&#65292;&#24182;&#32473;&#20986;&#20102;&#22522;&#20110;&#20559;&#24046;&#20998;&#25968;&#30340;&#20462;&#25913;&#35268;&#21017;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#21508;&#31181;&#31867;&#22411;&#30340;&#20844;&#24179;&#24615;&#32422;&#26463;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.05725</link><description>&lt;p&gt;
&#21518;&#39564;&#20559;&#24046;&#35780;&#20998;&#23545;&#20844;&#24179;&#20998;&#31867;&#26368;&#20248;
&lt;/p&gt;
&lt;p&gt;
Post-hoc Bias Scoring Is Optimal For Fair Classification. (arXiv:2310.05725v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05725
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21518;&#39564;&#20559;&#24046;&#35780;&#20998;&#30340;&#26041;&#27861;&#65292;&#22312;&#28385;&#36275;&#20844;&#24179;&#24615;&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#20445;&#25345;&#39640;&#20934;&#30830;&#24615;&#65292;&#24182;&#32473;&#20986;&#20102;&#22522;&#20110;&#20559;&#24046;&#20998;&#25968;&#30340;&#20462;&#25913;&#35268;&#21017;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#21508;&#31181;&#31867;&#22411;&#30340;&#20844;&#24179;&#24615;&#32422;&#26463;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#22312;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#19979;&#30340;&#20108;&#20803;&#20998;&#31867;&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#21487;&#20197;&#26159;&#20154;&#21475;&#32479;&#35745;&#23398;&#20844;&#24179;&#24615;&#65288;DP&#65289;&#65292;&#26426;&#20250;&#22343;&#31561;&#65288;EOp&#65289;&#25110;&#31561;&#27010;&#29575;&#65288;EO&#65289;&#20043;&#19968;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#20844;&#24179;&#24615;&#32422;&#26463;&#19979;&#36125;&#21494;&#26031;&#26368;&#20248;&#20998;&#31867;&#22120;&#30340;&#26126;&#30830;&#29305;&#24449;&#21270;&#65292;&#32467;&#26524;&#26159;&#19981;&#21463;&#32422;&#26463;&#20998;&#31867;&#22120;&#30340;&#31616;&#21333;&#20462;&#25913;&#35268;&#21017;&#12290;&#21363;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#23454;&#20363;&#32423;&#21035;&#30340;&#20559;&#24046;&#24230;&#37327;&#65292;&#31216;&#20026;&#20559;&#24046;&#20998;&#25968;&#65292;&#32780;&#20462;&#25913;&#35268;&#21017;&#21017;&#26159;&#22312;&#26377;&#38480;&#37327;&#30340;&#20559;&#24046;&#20998;&#25968;&#20043;&#19978;&#30340;&#31616;&#21333;&#32447;&#24615;&#35268;&#21017;&#12290;&#22522;&#20110;&#36825;&#20010;&#29305;&#24449;&#21270;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#21518;&#39564;&#26041;&#27861;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#36866;&#24212;&#20844;&#24179;&#24615;&#32422;&#26463;&#21516;&#26102;&#20445;&#25345;&#36739;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;&#22312;DP&#21644;EOp&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#65292;&#20462;&#25913;&#35268;&#21017;&#26159;&#22522;&#20110;&#21333;&#20010;&#20559;&#24046;&#20998;&#25968;&#30340;&#38408;&#20540;&#36873;&#25321;&#65292;&#32780;&#22312;EO&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#38656;&#35201;&#35843;&#25972;&#20855;&#26377;2&#20010;&#21442;&#25968;&#30340;&#32447;&#24615;&#20462;&#25913;&#35268;&#21017;&#12290;&#35813;&#26041;&#27861;&#36824;&#21487;&#20197;&#29992;&#20110;&#21253;&#21547;&#22810;&#20010;&#25935;&#24863;&#23646;&#24615;&#30340;&#22797;&#21512;&#32676;&#20307;&#20844;&#24179;&#24615;&#26631;&#20934;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a binary classification problem under group fairness constraints, which can be one of Demographic Parity (DP), Equalized Opportunity (EOp), or Equalized Odds (EO). We propose an explicit characterization of Bayes optimal classifier under the fairness constraints, which turns out to be a simple modification rule of the unconstrained classifier. Namely, we introduce a novel instance-level measure of bias, which we call bias score, and the modification rule is a simple linear rule on top of the finite amount of bias scores. Based on this characterization, we develop a post-hoc approach that allows us to adapt to fairness constraints while maintaining high accuracy. In the case of DP and EOp constraints, the modification rule is thresholding a single bias score, while in the case of EO constraints we are required to fit a linear modification rule with 2 parameters. The method can also be applied for composite group-fairness criteria, such as ones involving several sensitive att
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;RVGP&#26041;&#27861;&#65292;&#32467;&#21512;&#22522;&#20110;&#22270;&#30340;&#25968;&#25454;&#36924;&#36817;&#26041;&#27861;&#23545;&#28508;&#22312;&#27969;&#24418;&#19978;&#30340;&#21521;&#37327;&#20449;&#21495;&#36827;&#34892;&#23398;&#20064;&#65292;&#23454;&#29616;&#20102;&#36229;&#20998;&#36776;&#29575;&#21644;&#20462;&#22797;&#21521;&#37327;&#22330;&#65292;&#24182;&#19988;&#22312;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#20854;&#20855;&#26377;&#20840;&#23616;&#35268;&#24459;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.16746</link><description>&lt;p&gt;
&#38544;&#24615;&#39640;&#26031;&#36807;&#31243;&#34920;&#31034;&#20219;&#24847;&#28508;&#22312;&#27969;&#24418;&#19978;&#30340;&#21521;&#37327;&#22330;
&lt;/p&gt;
&lt;p&gt;
Implicit Gaussian process representation of vector fields over arbitrary latent manifolds. (arXiv:2309.16746v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16746
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;RVGP&#26041;&#27861;&#65292;&#32467;&#21512;&#22522;&#20110;&#22270;&#30340;&#25968;&#25454;&#36924;&#36817;&#26041;&#27861;&#23545;&#28508;&#22312;&#27969;&#24418;&#19978;&#30340;&#21521;&#37327;&#20449;&#21495;&#36827;&#34892;&#23398;&#20064;&#65292;&#23454;&#29616;&#20102;&#36229;&#20998;&#36776;&#29575;&#21644;&#20462;&#22797;&#21521;&#37327;&#22330;&#65292;&#24182;&#19988;&#22312;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#20854;&#20855;&#26377;&#20840;&#23616;&#35268;&#24459;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#65288;GPs&#65289;&#26159;&#29992;&#20110;&#23398;&#20064;&#26410;&#30693;&#20989;&#25968;&#21644;&#37327;&#21270;&#25968;&#25454;&#20013;&#30340;&#26102;&#31354;&#19981;&#30830;&#23450;&#24615;&#30340;&#27969;&#34892;&#38750;&#21442;&#25968;&#32479;&#35745;&#27169;&#22411;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#25193;&#23637;&#20102;GPs&#65292;&#29992;&#20110;&#24314;&#27169;&#20998;&#24067;&#22312;&#38750;&#27431;&#20960;&#37324;&#24471;&#22495;&#19978;&#30340;&#26631;&#37327;&#21644;&#21521;&#37327;&#25968;&#25454;&#65292;&#21253;&#25324;&#20986;&#29616;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#21160;&#21147;&#31995;&#32479;&#21644;&#31070;&#32463;&#31185;&#23398;&#31561;&#20247;&#22810;&#39046;&#22495;&#20013;&#30340;&#24179;&#28369;&#27969;&#24418;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#20551;&#35774;&#25968;&#25454;&#30340;&#28508;&#22312;&#27969;&#24418;&#26159;&#24050;&#30693;&#30340;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#23454;&#38469;&#25928;&#29992;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;RVGP&#65292;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#28508;&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#21521;&#37327;&#20449;&#21495;&#30340;GP&#30340;&#25512;&#24191;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#29992;&#19982;&#20999;&#21521;&#19995;&#20851;&#32852;&#30340;&#36830;&#25509;Laplacian&#30340;&#29305;&#24449;&#20989;&#25968;&#36827;&#34892;&#20301;&#32622;&#32534;&#30721;&#65292;&#36825;&#20123;&#29305;&#24449;&#20989;&#25968;&#21487;&#20197;&#20174;&#22522;&#20110;&#22270;&#30340;&#24120;&#35265;&#25968;&#25454;&#36817;&#20284;&#20013;&#36731;&#26494;&#25512;&#23548;&#20986;&#26469;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;RVGP&#22312;&#27969;&#24418;&#19978;&#20855;&#26377;&#20840;&#23616;&#35268;&#24459;&#24615;&#65292;&#20351;&#24471;&#20854;&#33021;&#22815;&#22312;&#20445;&#30041;&#22855;&#24322;&#24615;&#30340;&#21516;&#26102;&#36229;&#20998;&#36776;&#29575;&#21644;&#20462;&#22797;&#21521;&#37327;&#22330;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;RVGP&#26469;&#37325;&#26500;&#39640;&#23494;&#24230;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian processes (GPs) are popular nonparametric statistical models for learning unknown functions and quantifying the spatiotemporal uncertainty in data. Recent works have extended GPs to model scalar and vector quantities distributed over non-Euclidean domains, including smooth manifolds appearing in numerous fields such as computer vision, dynamical systems, and neuroscience. However, these approaches assume that the manifold underlying the data is known, limiting their practical utility. We introduce RVGP, a generalisation of GPs for learning vector signals over latent Riemannian manifolds. Our method uses positional encoding with eigenfunctions of the connection Laplacian, associated with the tangent bundle, readily derived from common graph-based approximation of data. We demonstrate that RVGP possesses global regularity over the manifold, which allows it to super-resolve and inpaint vector fields while preserving singularities. Furthermore, we use RVGP to reconstruct high-dens
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#22359;&#27880;&#24847;&#21147;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#30340;&#27969;&#24335;&#35821;&#38899;&#35782;&#21035;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#39044;&#23450;&#20041;&#30340;&#22266;&#23450;&#22823;&#23567;&#31383;&#21475;&#19978;&#25805;&#20316;&#65292;&#23454;&#29616;&#20102;&#27169;&#22411;&#30340;&#27969;&#24335;&#36816;&#34892;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#27169;&#22411;&#30456;&#27604;&#38750;&#27969;&#24335;&#21464;&#31181;&#20855;&#26377;&#30456;&#24403;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#22312;&#38271;&#31687;&#28436;&#35762;&#20013;&#20855;&#26377;&#24456;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2309.08436</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#22359;&#27880;&#24847;&#21147;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#30340;&#27969;&#24335;&#35821;&#38899;&#35782;&#21035;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Chunked Attention-based Encoder-Decoder Model for Streaming Speech Recognition. (arXiv:2309.08436v1 [eess.AS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08436
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#22359;&#27880;&#24847;&#21147;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#30340;&#27969;&#24335;&#35821;&#38899;&#35782;&#21035;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#39044;&#23450;&#20041;&#30340;&#22266;&#23450;&#22823;&#23567;&#31383;&#21475;&#19978;&#25805;&#20316;&#65292;&#23454;&#29616;&#20102;&#27169;&#22411;&#30340;&#27969;&#24335;&#36816;&#34892;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#27169;&#22411;&#30456;&#27604;&#38750;&#27969;&#24335;&#21464;&#31181;&#20855;&#26377;&#30456;&#24403;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#22312;&#38271;&#31687;&#28436;&#35762;&#20013;&#20855;&#26377;&#24456;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#21487;&#27969;&#24335;&#36816;&#34892;&#30340;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#65292;&#20854;&#20013;&#35299;&#30721;&#22120;&#25110;&#32534;&#30721;&#22120;&#21644;&#35299;&#30721;&#22120;&#37117;&#21487;&#20197;&#22312;&#39044;&#23450;&#20041;&#30340;&#22266;&#23450;&#22823;&#23567;&#30340;&#31383;&#21475;&#65288;&#31216;&#20026;&#22359;&#65289;&#19978;&#25805;&#20316;&#12290;&#19968;&#31181;&#29305;&#27530;&#30340;&#22359;&#32467;&#26463;&#31526;&#65288;EOC&#65289;&#31526;&#21495;&#20174;&#19968;&#20010;&#22359;&#36827;&#20837;&#21040;&#19979;&#19968;&#20010;&#22359;&#65292;&#26377;&#25928;&#22320;&#26367;&#20195;&#20102;&#20256;&#32479;&#30340;&#24207;&#21015;&#32467;&#26463;&#31526;&#12290;&#36825;&#20010;&#20462;&#25913;&#23558;&#25105;&#20204;&#30340;&#27169;&#22411;&#32622;&#20110;&#19968;&#20010;&#25805;&#20316;&#22359;&#32780;&#19981;&#26159;&#24103;&#30340;&#36716;&#25442;&#27169;&#22411;&#65292;&#20854;&#20013;EOC&#23545;&#24212;&#31354;&#30333;&#31526;&#21495;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25506;&#32034;&#20102;&#26631;&#20934;&#36716;&#25442;&#22120;&#27169;&#22411;&#21644;&#25105;&#20204;&#27169;&#22411;&#20043;&#38388;&#30340;&#20854;&#20182;&#24046;&#24322;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#38271;&#31687;&#28436;&#35762;&#30340;&#27867;&#21270;&#33021;&#21147;&#12289;&#26463;&#25628;&#32034;&#22823;&#23567;&#21644;&#38271;&#24230;&#35268;&#33539;&#21270;&#31561;&#30456;&#20851;&#26041;&#38754;&#12290;&#36890;&#36807;&#22312;Librispeech&#21644;TED-LIUM-v2&#19978;&#30340;&#23454;&#39564;&#65292;&#24182;&#36890;&#36807;&#36830;&#25509;&#36830;&#32493;&#30340;&#24207;&#21015;&#36827;&#34892;&#38271;&#31687;&#35797;&#39564;&#65292;&#25105;&#20204;&#21457;&#29616;&#25105;&#20204;&#30340;&#27969;&#24335;&#27169;&#22411;&#30456;&#27604;&#20110;&#38750;&#27969;&#24335;&#21464;&#31181;&#20855;&#26377;&#31454;&#20105;&#24615;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#23545;&#20110;&#38271;&#31687;&#28436;&#35762;&#38750;&#24120;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a streamable attention-based encoder-decoder model in which either the decoder, or both the encoder and decoder, operate on pre-defined, fixed-size windows called chunks. A special end-of-chunk (EOC) symbol advances from one chunk to the next chunk, effectively replacing the conventional end-of-sequence symbol. This modification, while minor, situates our model as equivalent to a transducer model that operates on chunks instead of frames, where EOC corresponds to the blank symbol. We further explore the remaining differences between a standard transducer and our model. Additionally, we examine relevant aspects such as long-form speech generalization, beam size, and length normalization. Through experiments on Librispeech and TED-LIUM-v2, and by concatenating consecutive sequences for long-form trials, we find that our streamable model maintains competitive performance compared to the non-streamable variant and generalizes very well to long-form speech.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36830;&#32493;&#26102;&#38388;&#32593;&#32476;&#34920;&#31034;&#23398;&#20064;&#26694;&#26550;&#65292;&#28085;&#30422;&#26680;&#24179;&#28369;&#30340;&#24378;&#24230;&#20989;&#25968;&#20272;&#35745;&#12289;&#26368;&#23567;&#21270;&#24378;&#24230;&#37325;&#26500;&#35823;&#24046;&#30340;&#25237;&#24433;&#23398;&#20064;&#21644;&#24402;&#32435;&#26500;&#36896;&#33410;&#28857;&#34920;&#31034;&#12290;&#36825;&#31181;&#34920;&#31034;&#20445;&#30041;&#20102;&#32593;&#32476;&#32467;&#26500;&#21644;&#26102;&#38388;&#19968;&#33268;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.06155</link><description>&lt;p&gt;
&#24378;&#24230;&#36718;&#24275;&#25237;&#24433;&#65306;&#29992;&#20110;&#21160;&#24577;&#32593;&#32476;&#30340;&#36830;&#32493;&#26102;&#38388;&#34920;&#31034;&#23398;&#20064;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Intensity Profile Projection: A Framework for Continuous-Time Representation Learning for Dynamic Networks. (arXiv:2306.06155v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06155
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36830;&#32493;&#26102;&#38388;&#32593;&#32476;&#34920;&#31034;&#23398;&#20064;&#26694;&#26550;&#65292;&#28085;&#30422;&#26680;&#24179;&#28369;&#30340;&#24378;&#24230;&#20989;&#25968;&#20272;&#35745;&#12289;&#26368;&#23567;&#21270;&#24378;&#24230;&#37325;&#26500;&#35823;&#24046;&#30340;&#25237;&#24433;&#23398;&#20064;&#21644;&#24402;&#32435;&#26500;&#36896;&#33410;&#28857;&#34920;&#31034;&#12290;&#36825;&#31181;&#34920;&#31034;&#20445;&#30041;&#20102;&#32593;&#32476;&#32467;&#26500;&#21644;&#26102;&#38388;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#24378;&#24230;&#36718;&#24275;&#25237;&#24433;&#8221;&#30340;&#26032;&#31639;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#23398;&#20064;&#21160;&#24577;&#32593;&#32476;&#33410;&#28857;&#30340;&#36830;&#32493;&#26102;&#38388;&#34920;&#31034;&#65292;&#35813;&#21160;&#24577;&#32593;&#32476;&#30001;&#33410;&#28857;&#38598;&#21644;&#22312;&#36830;&#32493;&#26102;&#38388;&#20869;&#21457;&#29983;&#30340;&#30636;&#26102;&#20132;&#20114;&#20107;&#20214;&#30340;&#38598;&#21512;&#25152;&#29305;&#24449;&#21270;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21253;&#25324;&#19977;&#20010;&#38454;&#27573;&#65306;&#36890;&#36807;&#26680;&#24179;&#28369;&#31561;&#26041;&#27861;&#20272;&#35745;&#33410;&#28857;&#23545;&#20043;&#38388;&#20132;&#20114;&#30340;&#24378;&#24230;&#20989;&#25968;&#65307;&#23398;&#20064;&#19968;&#20010;&#26368;&#23567;&#21270;&#26576;&#31181;&#24378;&#24230;&#37325;&#26500;&#35823;&#24046;&#30340;&#25237;&#24433;&#65307;&#36890;&#36807;&#23398;&#20064;&#30340;&#25237;&#24433;&#24402;&#32435;&#26500;&#36896;&#20986;&#19981;&#26029;&#21457;&#23637;&#30340;&#33410;&#28857;&#34920;&#31034;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#34920;&#31034;&#20445;&#30041;&#20102;&#32593;&#32476;&#30340;&#22522;&#26412;&#32467;&#26500;&#65292;&#24182;&#20855;&#26377;&#26102;&#38388;&#19968;&#33268;&#24615;&#65292;&#36825;&#24847;&#21619;&#30528;&#33410;&#28857;&#34920;&#31034;&#21487;&#20197;&#22312;&#19981;&#21516;&#30340;&#26102;&#38388;&#28857;&#19978;&#36827;&#34892;&#26377;&#24847;&#20041;&#30340;&#27604;&#36739;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#20063;&#26500;&#24314;&#20102;&#20272;&#35745;&#29702;&#35770;&#26469;&#38416;&#26126;&#24179;&#28369;&#20316;&#20026;&#20559;&#24046;&#26041;&#24046;&#25240;&#34935;&#30340;&#20316;&#29992;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#38543;&#30528;&#20449;&#22122;&#27604;&#30340;&#22686;&#21152;&#32780;&#20943;&#23569;&#24179;&#28369;&#31243;&#24230;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a new algorithmic framework, Intensity Profile Projection, for learning continuous-time representations of the nodes of a dynamic network, characterised by a node set and a collection of instantaneous interaction events which occur in continuous time. Our framework consists of three stages: estimating the intensity functions underlying the interactions between pairs of nodes, e.g. via kernel smoothing; learning a projection which minimises a notion of intensity reconstruction error; and inductively constructing evolving node representations via the learned projection. We show that our representations preserve the underlying structure of the network, and are temporally coherent, meaning that node representations can be meaningfully compared at different points in time. We develop estimation theory which elucidates the role of smoothing as a bias-variance trade-off, and shows how we can reduce smoothing as the signal-to-noise ratio increases on account of the algorithm `borrow
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#20013;&#38388;&#38382;&#39064;&#65306;&#22240;&#26524;&#25104;&#20998;&#20998;&#26512;(CauCA)&#65292;&#23427;&#26159;&#29420;&#31435;&#25104;&#20998;&#20998;&#26512;(ICA)&#21644;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;(CRL)&#30340;&#27867;&#21270;&#21644;&#29305;&#20363;&#65292;&#20854;&#30446;&#26631;&#26159;&#23398;&#20064;&#35299;&#28151;&#20989;&#25968;&#21644;&#22240;&#26524;&#26426;&#21046;&#65292;&#39044;&#35774;&#20102;&#22240;&#26524;&#22270;&#30340;&#30693;&#35782;&#12290;</title><link>http://arxiv.org/abs/2305.17225</link><description>&lt;p&gt;
&#22240;&#26524;&#25104;&#20998;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Causal Component Analysis. (arXiv:2305.17225v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17225
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#20013;&#38388;&#38382;&#39064;&#65306;&#22240;&#26524;&#25104;&#20998;&#20998;&#26512;(CauCA)&#65292;&#23427;&#26159;&#29420;&#31435;&#25104;&#20998;&#20998;&#26512;(ICA)&#21644;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;(CRL)&#30340;&#27867;&#21270;&#21644;&#29305;&#20363;&#65292;&#20854;&#30446;&#26631;&#26159;&#23398;&#20064;&#35299;&#28151;&#20989;&#25968;&#21644;&#22240;&#26524;&#26426;&#21046;&#65292;&#39044;&#35774;&#20102;&#22240;&#26524;&#22270;&#30340;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29420;&#31435;&#25104;&#20998;&#20998;&#26512;(ICA)&#30340;&#30446;&#26631;&#26159;&#20174;&#28151;&#21512;&#35266;&#27979;&#21040;&#30340;&#21464;&#37327;&#20013;&#24674;&#22797;&#29420;&#31435;&#30340;&#28508;&#22312;&#21464;&#37327;&#12290;&#32780;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;(CRL)&#30340;&#30446;&#26631;&#26159;&#25512;&#26029;&#22240;&#26524;&#20851;&#31995;&#24378;&#30456;&#20851;&#24615;&#30340;&#28508;&#22312;&#21464;&#37327;&#65292;&#20197;&#21450;&#32534;&#30721;&#23427;&#20204;&#30340;&#22240;&#26524;&#20851;&#31995;&#30340;&#26410;&#30693;&#22270;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20013;&#38388;&#38382;&#39064;&#65292;&#31216;&#20026;&#22240;&#26524;&#25104;&#20998;&#20998;&#26512;(CauCA)&#12290;CauCA&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;ICA&#30340;&#19968;&#31181;&#25512;&#24191;&#65292;&#23545;&#28508;&#22312;&#25104;&#20998;&#20043;&#38388;&#30340;&#22240;&#26524;&#20381;&#36182;&#24314;&#27169;&#65292;&#20063;&#26159;CRL&#30340;&#19968;&#20010;&#29305;&#20363;&#12290;&#19982;CRL&#19981;&#21516;&#30340;&#26159;&#65292;&#23427;&#39044;&#35774;&#20102;&#22240;&#26524;&#22270;&#30340;&#30693;&#35782;&#65292;&#20165;&#20851;&#27880;&#20110;&#23398;&#20064;&#35299;&#28151;&#20989;&#25968;&#21644;&#22240;&#26524;&#26426;&#21046;&#12290;&#25152;&#26377;&#20851;&#20110;CauCA&#22238;&#25910;&#22522;&#30784;&#30495;&#30456;&#30340;&#19981;&#21487;&#33021;&#32467;&#26524;&#20063;&#36866;&#29992;&#20110;CRL&#65292;&#32780;&#21487;&#33021;&#24615;&#32467;&#26524;&#21487;&#20197;&#20316;&#20026;&#25193;&#23637;CRL&#30340;&#22522;&#30784;&#12290;&#25105;&#20204;&#23558;&#20174;&#23545;&#28508;&#22312;&#22240;&#26524;&#21464;&#37327;&#23454;&#26045;&#19981;&#21516;&#31867;&#22411;&#24178;&#39044;&#30340;&#22810;&#20010;&#25968;&#25454;&#38598;&#20013;&#34920;&#24449;CauCA&#30340;&#21487;&#35782;&#21035;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Independent Component Analysis (ICA) aims to recover independent latent variables from observed mixtures thereof. Causal Representation Learning (CRL) aims instead to infer causally related (thus often statistically dependent) latent variables, together with the unknown graph encoding their causal relationships. We introduce an intermediate problem termed Causal Component Analysis (CauCA). CauCA can be viewed as a generalization of ICA, modelling the causal dependence among the latent components, and as a special case of CRL. In contrast to CRL, it presupposes knowledge of the causal graph, focusing solely on learning the unmixing function and the causal mechanisms. Any impossibility results regarding the recovery of the ground truth in CauCA also apply for CRL, while possibility results may serve as a stepping stone for extensions to CRL. We characterize CauCA identifiability from multiple datasets generated through different types of interventions on the latent causal variables. As a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25968;&#23398;&#20998;&#26512;&#35777;&#26126;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#24182;&#19981;&#33021;&#35299;&#20915;&#24179;&#28369;&#36807;&#24230;&#38382;&#39064;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#38656;&#35201;&#26356;&#22810;&#20851;&#27880;&#19981;&#23545;&#31216;&#12289;&#29366;&#24577;&#30456;&#20851;&#21644;&#26377;&#21521;&#22270;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2305.16102</link><description>&lt;p&gt;
&#25581;&#31034;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#24179;&#28369;&#36807;&#24230;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
Demystifying Oversmoothing in Attention-Based Graph Neural Networks. (arXiv:2305.16102v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16102
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25968;&#23398;&#20998;&#26512;&#35777;&#26126;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#24182;&#19981;&#33021;&#35299;&#20915;&#24179;&#28369;&#36807;&#24230;&#38382;&#39064;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#38656;&#35201;&#26356;&#22810;&#20851;&#27880;&#19981;&#23545;&#31216;&#12289;&#29366;&#24577;&#30456;&#20851;&#21644;&#26377;&#21521;&#22270;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#24179;&#28369;&#36807;&#24230;&#25351;&#30340;&#26159;&#22686;&#21152;&#32593;&#32476;&#28145;&#24230;&#23548;&#33268;&#33410;&#28857;&#34920;&#31034;&#21464;&#24471;&#30456;&#21516;&#30340;&#29616;&#35937;&#12290;&#23613;&#31649;&#20043;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#35777;&#23454;&#20102;&#22270;&#21367;&#31215;&#32593;&#32476;(GCN)&#20250;&#25351;&#25968;&#32423;&#22833;&#21435;&#34920;&#36798;&#33021;&#21147;&#65292;&#20294;&#26159;&#22270;&#27880;&#24847;&#21147;&#26426;&#21046;&#26159;&#21542;&#21487;&#20197;&#32531;&#35299;&#24179;&#28369;&#36807;&#24230;&#38382;&#39064;&#36824;&#23384;&#22312;&#20105;&#35758;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#35270;&#20026;&#38750;&#32447;&#24615;&#26102;&#21464;&#21160;&#24577;&#31995;&#32479;&#65292;&#24182;&#32467;&#21512;&#38750;&#40784;&#27425;&#30697;&#38453;&#20056;&#31215;&#21644;&#32852;&#21512;&#35889;&#21322;&#24452;&#29702;&#35770;&#30340;&#24037;&#20855;&#21644;&#25216;&#26415;&#65292;&#23545;&#36825;&#20010;&#38382;&#39064;&#36827;&#34892;&#20102;&#20005;&#26684;&#30340;&#25968;&#23398;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26126;&#30830;&#30340;&#31572;&#26696;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19982;&#27969;&#34892;&#35266;&#28857;&#30456;&#21453;&#65292;&#22270;&#27880;&#24847;&#21147;&#26426;&#21046;&#19981;&#33021;&#38450;&#27490;&#24179;&#28369;&#36807;&#24230;&#29616;&#35937;&#65292;&#24182;&#19988;&#21576;&#25351;&#25968;&#32423;&#22833;&#21435;&#34920;&#36798;&#33021;&#21147;&#12290;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#23558;&#23545;&#31216;GCN&#30340;&#24179;&#28369;&#36807;&#24230;&#38382;&#39064;&#25193;&#23637;&#21040;&#20102;&#26356;&#24191;&#27867;&#30340;GNN&#27169;&#22411;&#31867;&#21035;&#20013;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#32771;&#34385;&#20102;&#22312;&#29616;&#23454;&#24212;&#29992;&#20013;&#26222;&#36941;&#23384;&#22312;&#30340;&#19981;&#23545;&#31216;&#12289;&#29366;&#24577;&#30456;&#20851;&#21644;&#26377;&#21521;&#22270;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Oversmoothing in Graph Neural Networks (GNNs) refers to the phenomenon where increasing network depth leads to homogeneous node representations. While previous work has established that Graph Convolutional Networks (GCNs) exponentially lose expressive power, it remains controversial whether the graph attention mechanism can mitigate oversmoothing. In this work, we provide a definitive answer to this question through a rigorous mathematical analysis, by viewing attention-based GNNs as nonlinear time-varying dynamical systems and incorporating tools and techniques from the theory of products of inhomogeneous matrices and the joint spectral radius. We establish that, contrary to popular belief, the graph attention mechanism cannot prevent oversmoothing and loses expressive power exponentially. The proposed framework extends the existing results on oversmoothing for symmetric GCNs to a significantly broader class of GNN models. In particular, our analysis accounts for asymmetric, state-dep
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20248;&#21270;&#27169;&#22411;&#20449;&#24687;&#30340;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476; (MI-GAN) &#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#21487;&#20877;&#29983;&#33021;&#28304;&#19981;&#30830;&#23450;&#24615;&#23545;&#20248;&#21270;&#38382;&#39064;&#30340;&#24433;&#21709;&#65292;&#25552;&#39640;&#26368;&#20248;&#21151;&#29575;&#27969;&#38382;&#39064;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2206.01864</link><description>&lt;p&gt;
&#22522;&#20110;&#27169;&#22411;&#20449;&#24687;&#30340;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476; (MI-GAN) &#29992;&#20110;&#23398;&#20064;&#26368;&#20248;&#21151;&#29575;&#27969;
&lt;/p&gt;
&lt;p&gt;
Model-Informed Generative Adversarial Network (MI-GAN) for Learning Optimal Power Flow. (arXiv:2206.01864v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.01864
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20248;&#21270;&#27169;&#22411;&#20449;&#24687;&#30340;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476; (MI-GAN) &#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#21487;&#20877;&#29983;&#33021;&#28304;&#19981;&#30830;&#23450;&#24615;&#23545;&#20248;&#21270;&#38382;&#39064;&#30340;&#24433;&#21709;&#65292;&#25552;&#39640;&#26368;&#20248;&#21151;&#29575;&#27969;&#38382;&#39064;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20248;&#21151;&#29575;&#27969; (OPF) &#38382;&#39064;&#20316;&#20026;&#30005;&#21147;&#31995;&#32479;&#36816;&#33829;&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#65292;&#30001;&#20110;&#21487;&#20877;&#29983;&#33021;&#28304;&#30340;&#21464;&#24322;&#24615;&#12289;&#38388;&#27463;&#24615;&#21644;&#19981;&#21487;&#39044;&#27979;&#24615;&#32473;&#35299;&#20915;&#24102;&#26469;&#20102;&#36234;&#26469;&#36234;&#22823;&#30340;&#22256;&#38590;&#12290;&#34429;&#28982;&#20256;&#32479;&#30340;&#20248;&#21270;&#25216;&#26415;&#65292;&#22914;&#38543;&#26426;&#21270;&#21644;&#40065;&#26834;&#24615;&#20248;&#21270;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#26469;&#35299;&#20915;OPF&#38382;&#39064;&#65292;&#20294;&#38754;&#23545;&#21487;&#20877;&#29983;&#33021;&#28304;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#21363;&#20248;&#21270;&#27169;&#22411;&#20013;&#30340;&#21160;&#24577;&#31995;&#25968;&#65292;&#23427;&#20204;&#22312;&#22788;&#29702;&#22823;&#35268;&#27169;&#38382;&#39064;&#26041;&#38754;&#30340;&#25928;&#26524;&#20173;&#28982;&#26377;&#38480;&#12290;&#22240;&#27492;&#65292;&#36817;&#24180;&#26469;&#24050;&#32463;&#24320;&#21457;&#20986;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#65292;&#22914;&#31070;&#32463;&#32593;&#32476;&#65292;&#20197;&#25552;&#39640;&#21033;&#29992;&#25968;&#25454;&#35299;&#20915;OPF&#38382;&#39064;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#35299;&#20915;&#26041;&#26696;&#30340;&#21487;&#34892;&#24615;&#21644;&#26368;&#20248;&#24615;&#21487;&#33021;&#26080;&#27861;&#24471;&#21040;&#20445;&#35777;&#65292;&#31995;&#32479;&#21160;&#24577;&#20063;&#26080;&#27861;&#24471;&#21040;&#36866;&#24403;&#30340;&#22788;&#29702;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20248;&#21270;&#27169;&#22411;&#20449;&#24687;&#30340;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476; (MI-GAN) &#26694;&#26550;&#65292;&#20197;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
The optimal power flow (OPF) problem, as a critical component of power system operations, becomes increasingly difficult to solve due to the variability, intermittency, and unpredictability of renewable energy brought to the power system. Although traditional optimization techniques, such as stochastic and robust optimization approaches, could be leveraged to address the OPF problem, in the face of renewable energy uncertainty, i.e., the dynamic coefficients in the optimization model, their effectiveness in dealing with large-scale problems remains limited. As a result, deep learning techniques, such as neural networks, have recently been developed to improve computational efficiency in solving OPF problems with the utilization of data. However, the feasibility and optimality of the solution may not be guaranteed, and the system dynamics cannot be properly addressed as well. In this paper, we propose an optimization model-informed generative adversarial network (MI-GAN) framework to so
&lt;/p&gt;</description></item></channel></rss>