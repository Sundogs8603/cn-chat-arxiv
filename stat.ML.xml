<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#26631;&#31614;&#21015;&#34920;&#30340;&#22312;&#32447;&#39044;&#27979;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102; $b$-ary Littlestone &#32500;&#24230;&#21487;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#19988;&#22312;&#25077;&#25026;&#30340;&#24773;&#20917;&#19979;&#25506;&#32034;&#19981;&#21516;&#30340;&#24773;&#20917;&#12290;&#21487;&#20197;&#20351;&#29992;&#25913;&#32534;&#33258; Littlestone &#30340; SOA &#21644; Rosenblatt &#30340;&#24863;&#30693;&#22120;&#31561;&#31639;&#27861;&#36827;&#34892;&#39044;&#27979;&#65292;&#21516;&#26102;&#36824;&#24314;&#31435;&#20102;&#21015;&#34920;&#21487;&#23398;&#20064;&#30340;&#32452;&#21512;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2303.15383</link><description>&lt;p&gt;
&#22522;&#20110;&#21015;&#34920;&#30340;&#22312;&#32447;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
List Online Classification. (arXiv:2303.15383v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15383
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#26631;&#31614;&#21015;&#34920;&#30340;&#22312;&#32447;&#39044;&#27979;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102; $b$-ary Littlestone &#32500;&#24230;&#21487;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#19988;&#22312;&#25077;&#25026;&#30340;&#24773;&#20917;&#19979;&#25506;&#32034;&#19981;&#21516;&#30340;&#24773;&#20917;&#12290;&#21487;&#20197;&#20351;&#29992;&#25913;&#32534;&#33258; Littlestone &#30340; SOA &#21644; Rosenblatt &#30340;&#24863;&#30693;&#22120;&#31561;&#31639;&#27861;&#36827;&#34892;&#39044;&#27979;&#65292;&#21516;&#26102;&#36824;&#24314;&#31435;&#20102;&#21015;&#34920;&#21487;&#23398;&#20064;&#30340;&#32452;&#21512;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#22810;&#20998;&#31867;&#22312;&#32447;&#39044;&#27979;&#65292;&#20854;&#20013;&#23398;&#20064;&#32773;&#21487;&#20197;&#20351;&#29992;&#22810;&#20010;&#26631;&#31614;&#30340;&#21015;&#34920;&#36827;&#34892;&#39044;&#27979;&#65288;&#19982;&#20256;&#32479;&#35774;&#32622;&#20013;&#20165;&#20351;&#29992;&#19968;&#31181;&#26631;&#31614;&#19981;&#21516;&#65289;&#12290;&#25105;&#20204;&#20351;&#29992; $b$-ary Littlestone &#32500;&#24230;&#34920;&#24449;&#20102;&#35813;&#27169;&#22411;&#20013;&#30340;&#21487;&#23398;&#20064;&#24615;&#12290;&#35813;&#32500;&#24230;&#26159;&#32463;&#20856; Littlestone &#32500;&#24230;&#30340;&#21464;&#20307;&#65292;&#20854;&#20013;&#20108;&#36827;&#21046;&#38169;&#35823;&#26641;&#34987;&#26367;&#25442;&#20026; $(k+1)$-ary &#38169;&#35823;&#26641;&#65292;&#20854;&#20013; k &#26159;&#21015;&#34920;&#20013;&#26631;&#31614;&#30340;&#25968;&#37327;&#12290;&#22312;&#25077;&#25026;&#30340;&#22330;&#26223;&#20013;&#65292;&#25105;&#20204;&#26681;&#25454;&#27604;&#36739;&#31867;&#20013;&#26159;&#21542;&#21253;&#21547;&#21333;&#26631;&#31614;&#25110;&#22810;&#26631;&#31614;&#20989;&#25968;&#20197;&#21450;&#23427;&#19982;&#31639;&#27861;&#20351;&#29992;&#30340;&#21015;&#34920;&#22823;&#23567;&#20043;&#38388;&#30340;&#26435;&#34913;&#26469;&#25506;&#32034;&#19981;&#21516;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#21457;&#29616;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#21487;&#20197;&#23454;&#29616;&#36127;&#24724;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#20160;&#20040;&#24773;&#20917;&#19979;&#23454;&#29616;&#36127;&#24724;&#30340;&#23436;&#25972;&#29305;&#24615;&#21270;&#12290;&#20316;&#20026;&#25105;&#20204;&#24037;&#20316;&#30340;&#19968;&#37096;&#20998;&#65292;&#25105;&#20204;&#25913;&#32534;&#20102;&#32463;&#20856;&#31639;&#27861;&#65292;&#22914; Littlestone &#30340; SOA &#21644; Rosenblatt &#30340;&#24863;&#30693;&#22120;&#65292;&#20197;&#20351;&#29992;&#26631;&#31614;&#21015;&#34920;&#36827;&#34892;&#39044;&#27979;&#12290;&#25105;&#20204;&#36824;&#20026;&#21487;&#20197;&#36827;&#34892;&#21015;&#34920;&#23398;&#20064;&#30340;&#32452;&#21512;&#32467;&#26524;&#24314;&#31435;&#20102;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study multiclass online prediction where the learner can predict using a list of multiple labels (as opposed to just one label in the traditional setting). We characterize learnability in this model using the $b$-ary Littlestone dimension. This dimension is a variation of the classical Littlestone dimension with the difference that binary mistake trees are replaced with $(k+1)$-ary mistake trees, where $k$ is the number of labels in the list. In the agnostic setting, we explore different scenarios depending on whether the comparator class consists of single-labeled or multi-labeled functions and its tradeoff with the size of the lists the algorithm uses. We find that it is possible to achieve negative regret in some cases and provide a complete characterization of when this is possible. As part of our work, we adapt classical algorithms such as Littlestone's SOA and Rosenblatt's Perceptron to predict using lists of labels. We also establish combinatorial results for list-learnable c
&lt;/p&gt;</description></item><item><title>&#25193;&#25955;&#27169;&#22411;&#38656;&#35201;&#36827;&#34892;&#35745;&#31639;&#23494;&#38598;&#22411;&#30340;&#20174;&#22836;&#24320;&#22987;&#35757;&#32451;&#65292;&#22240;&#27492;&#25506;&#32034;&#22312;&#25968;&#25454;&#20998;&#24067;&#21457;&#29983;&#21464;&#21270;&#26102;&#37325;&#26032;&#20351;&#29992;&#35745;&#31639;&#30340;&#36845;&#20195;&#35757;&#32451;&#26159;&#26377;&#24517;&#35201;&#30340;&#12290;&#32463;&#39564;&#37325;&#25918;&#19982;&#20943;&#23569;&#25490;&#32451;&#31995;&#25968;&#30340;&#24615;&#33021;&#24378;&#22823;&#12290;&#20351;&#29992;&#27599;&#32500;&#27604;&#29305;&#25968;&#35780;&#20272;CL&#23384;&#22312;&#26576;&#20123;&#32570;&#38519;&#12290;</title><link>http://arxiv.org/abs/2303.15342</link><description>&lt;p&gt;
&#25506;&#32034;&#25193;&#25955;&#27169;&#22411;&#30340;&#25345;&#32493;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Exploring Continual Learning of Diffusion Models. (arXiv:2303.15342v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15342
&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#38656;&#35201;&#36827;&#34892;&#35745;&#31639;&#23494;&#38598;&#22411;&#30340;&#20174;&#22836;&#24320;&#22987;&#35757;&#32451;&#65292;&#22240;&#27492;&#25506;&#32034;&#22312;&#25968;&#25454;&#20998;&#24067;&#21457;&#29983;&#21464;&#21270;&#26102;&#37325;&#26032;&#20351;&#29992;&#35745;&#31639;&#30340;&#36845;&#20195;&#35757;&#32451;&#26159;&#26377;&#24517;&#35201;&#30340;&#12290;&#32463;&#39564;&#37325;&#25918;&#19982;&#20943;&#23569;&#25490;&#32451;&#31995;&#25968;&#30340;&#24615;&#33021;&#24378;&#22823;&#12290;&#20351;&#29992;&#27599;&#32500;&#27604;&#29305;&#25968;&#35780;&#20272;CL&#23384;&#22312;&#26576;&#20123;&#32570;&#38519;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20854;&#26032;&#39062;&#30340;&#35757;&#32451;&#31243;&#24207;&#24212;&#29992;&#20110;&#22823;&#37327;&#25968;&#25454;&#65292;&#25193;&#25955;&#27169;&#22411;&#22312;&#29983;&#25104;&#39640;&#36136;&#37327;&#22270;&#20687;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#20174;&#22836;&#24320;&#22987;&#35757;&#32451;&#25193;&#25955;&#27169;&#22411;&#26159;&#35745;&#31639;&#23494;&#38598;&#22411;&#30340;&#12290;&#36825;&#31361;&#20986;&#20102;&#38656;&#35201;&#30740;&#31350;&#22312;&#25968;&#25454;&#20998;&#24067;&#21457;&#29983;&#21464;&#21270;&#26102;&#37325;&#26032;&#20351;&#29992;&#35745;&#31639;&#30340;&#36845;&#20195;&#35757;&#32451;&#21487;&#33021;&#24615;&#12290;&#22312;&#27492;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#36808;&#20986;&#20102;&#36825;&#19968;&#26041;&#21521;&#30340;&#31532;&#19968;&#27493;&#65292;&#24182;&#35780;&#20272;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#25345;&#32493;&#23398;&#20064;&#65288;CL&#65289;&#23646;&#24615;&#12290;&#25105;&#20204;&#39318;&#20808;&#23545;&#24212;&#29992;&#20110;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DDPM&#65289;&#30340;&#26368;&#24120;&#35265;CL&#26041;&#27861;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#65292;&#20854;&#20013;&#25105;&#20204;&#27880;&#24847;&#21040;&#32463;&#39564;&#37325;&#25918;&#19982;&#20943;&#23569;&#25490;&#32451;&#31995;&#25968;&#30340;&#24615;&#33021;&#24378;&#22823;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#36951;&#24536;&#21160;&#24577;&#30340;&#35265;&#35299;&#65292;&#23427;&#20204;&#34920;&#29616;&#20986;&#25193;&#25955;&#26102;&#38388;&#27493;&#38271;&#30340;&#19981;&#21516;&#34892;&#20026;&#12290;&#25105;&#20204;&#36824;&#25581;&#31034;&#20102;&#20351;&#29992;&#27599;&#32500;&#27604;&#29305;&#25968;&#35780;&#20272;CL&#30340;&#26576;&#20123;&#32570;&#38519;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models have achieved remarkable success in generating high-quality images thanks to their novel training procedures applied to unprecedented amounts of data. However, training a diffusion model from scratch is computationally expensive. This highlights the need to investigate the possibility of training these models iteratively, reusing computation while the data distribution changes. In this study, we take the first step in this direction and evaluate the continual learning (CL) properties of diffusion models. We begin by benchmarking the most common CL methods applied to Denoising Diffusion Probabilistic Models (DDPMs), where we note the strong performance of the experience replay with the reduced rehearsal coefficient. Furthermore, we provide insights into the dynamics of forgetting, which exhibit diverse behavior across diffusion timesteps. We also uncover certain pitfalls of using the bits-per-dimension metric for evaluating CL.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#28151;&#21512;VAE&#27169;&#22411;&#23398;&#20064;&#27969;&#24418;&#30340;&#26041;&#27861;&#65292;&#24182;&#23558;&#20854;&#29992;&#20110;&#35299;&#20915;&#36870;&#38382;&#39064;&#65292;&#32467;&#26524;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#65292;&#21487;&#29992;&#20110;&#27169;&#31946;&#21644;&#30005;&#38459;&#25239;&#23618;&#26512;&#25104;&#20687;&#12290;</title><link>http://arxiv.org/abs/2303.15244</link><description>&lt;p&gt;
&#29992;&#28151;&#21512;VAE&#27169;&#22411;&#23398;&#20064;&#27969;&#24418;&#26469;&#35299;&#20915;&#36870;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Manifold Learning by Mixture Models of VAEs for Inverse Problems. (arXiv:2303.15244v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15244
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#28151;&#21512;VAE&#27169;&#22411;&#23398;&#20064;&#27969;&#24418;&#30340;&#26041;&#27861;&#65292;&#24182;&#23558;&#20854;&#29992;&#20110;&#35299;&#20915;&#36870;&#38382;&#39064;&#65292;&#32467;&#26524;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#65292;&#21487;&#29992;&#20110;&#27169;&#31946;&#21644;&#30005;&#38459;&#25239;&#23618;&#26512;&#25104;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#36341;&#20013;&#65292;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#34920;&#31034;&#39640;&#32500;&#25968;&#25454;&#30340;&#27969;&#24418;&#24050;&#34987;&#35777;&#26126;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#36825;&#35201;&#27714;&#25968;&#25454;&#27969;&#24418;&#20855;&#26377;&#20840;&#23616;&#21442;&#25968;&#21270;&#12290;&#20026;&#20102;&#34920;&#31034;&#20219;&#24847;&#25299;&#25169;&#30340;&#27969;&#24418;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23398;&#20064;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#28151;&#21512;&#27169;&#22411;&#12290;&#36825;&#37324;&#65292;&#27599;&#20010;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#23545;&#34920;&#31034;&#27969;&#24418;&#30340;&#19968;&#20010;&#22270;&#34920;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25439;&#22833;&#20989;&#25968;&#26469;&#26368;&#22823;&#21270;&#20284;&#28982;&#20272;&#35745;&#27169;&#22411;&#26435;&#37325;&#65292;&#24182;&#36873;&#25321;&#19968;&#20010;&#26550;&#26500;&#65292;&#20026;&#25105;&#20204;&#25552;&#20379;&#22270;&#34920;&#21450;&#20854;&#36870;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#12290;&#19968;&#26086;&#23398;&#20064;&#20102;&#27969;&#24418;&#65292;&#25105;&#20204;&#23558;&#20854;&#29992;&#20110;&#36890;&#36807;&#23558;&#25968;&#25454;&#25311;&#21512;&#39033;&#38480;&#21046;&#22312;&#23398;&#20064;&#30340;&#27969;&#24418;&#19978;&#26469;&#35299;&#20915;&#36870;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#25152;&#20135;&#29983;&#30340;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#25105;&#20204;&#22312;&#23398;&#20064;&#30340;&#27969;&#24418;&#19978;&#25552;&#20986;&#20102;&#19968;&#31181;&#40654;&#26364;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20302;&#32500;&#29609;&#20855;&#20363;&#23376;&#20197;&#21450;&#27169;&#31946;&#21644;&#30005;&#38459;&#25239;&#23618;&#26512;&#25104;&#20687;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Representing a manifold of very high-dimensional data with generative models has been shown to be computationally efficient in practice. However, this requires that the data manifold admits a global parameterization. In order to represent manifolds of arbitrary topology, we propose to learn a mixture model of variational autoencoders. Here, every encoder-decoder pair represents one chart of a manifold. We propose a loss function for maximum likelihood estimation of the model weights and choose an architecture that provides us the analytical expression of the charts and of their inverses. Once the manifold is learned, we use it for solving inverse problems by minimizing a data fidelity term restricted to the learned manifold. To solve the arising minimization problem we propose a Riemannian gradient descent algorithm on the learned manifold. We demonstrate the performance of our method for low-dimensional toy examples as well as for deblurring and electrical impedance tomography on cert
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#37096;&#20998;&#20849;&#20139;&#36890;&#20449;&#21407;&#29702;&#30340;&#36890;&#20449;&#39640;&#25928;&#24322;&#27493;&#22312;&#32447;&#32852;&#37030;&#23398;&#20064;&#65288;PAO-Fed&#65289;&#31574;&#30053;&#65292;&#33021;&#22815;&#22788;&#29702;&#24322;&#26500;&#21644;&#24310;&#36831;&#35774;&#22791;&#65292;&#23454;&#29616;&#21442;&#19982;&#23398;&#20064;&#20219;&#21153;&#30340;&#21487;&#35775;&#38382;&#24615;&#21644;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2303.15226</link><description>&lt;p&gt;
&#24102;&#26377;&#38477;&#20302;&#36890;&#20449;&#35201;&#27714;&#30340;&#24322;&#27493;&#22312;&#32447;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Asynchronous Online Federated Learning with Reduced Communication Requirements. (arXiv:2303.15226v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15226
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#37096;&#20998;&#20849;&#20139;&#36890;&#20449;&#21407;&#29702;&#30340;&#36890;&#20449;&#39640;&#25928;&#24322;&#27493;&#22312;&#32447;&#32852;&#37030;&#23398;&#20064;&#65288;PAO-Fed&#65289;&#31574;&#30053;&#65292;&#33021;&#22815;&#22788;&#29702;&#24322;&#26500;&#21644;&#24310;&#36831;&#35774;&#22791;&#65292;&#23454;&#29616;&#21442;&#19982;&#23398;&#20064;&#20219;&#21153;&#30340;&#21487;&#35775;&#38382;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#20351;&#24471;&#22320;&#29702;&#20998;&#24067;&#30340;&#35774;&#22791;&#21487;&#20197;&#20174;&#26412;&#22320;&#30340;&#27969;&#25968;&#25454;&#20013;&#23398;&#20064;&#21040;&#20840;&#23616;&#20849;&#20139;&#27169;&#22411;&#12290;&#22823;&#22810;&#25968;&#20851;&#20110;&#22312;&#32447;FL&#30340;&#25991;&#29486;&#37117;&#32771;&#34385;&#20102;&#26368;&#20339;&#24773;&#20917;&#19979;&#30340;&#21442;&#19982;&#23458;&#25143;&#31471;&#21644;&#36890;&#20449;&#28192;&#36947;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#20551;&#35774;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#36890;&#24120;&#26080;&#27861;&#28385;&#36275;&#12290;&#24322;&#27493;&#35774;&#32622;&#21487;&#20197;&#21453;&#26144;&#20986;&#26356;&#29616;&#23454;&#30340;&#29615;&#22659;&#65292;&#20363;&#22914;&#30001;&#20110;&#21487;&#29992;&#30340;&#35745;&#31639;&#33021;&#21147;&#21644;&#30005;&#27744;&#38480;&#21046;&#32780;&#21457;&#29983;&#30340;&#24322;&#26500;&#23458;&#25143;&#31471;&#21442;&#19982;&#65292;&#20197;&#21450;&#30001;&#36890;&#20449;&#28192;&#36947;&#25110;&#33853;&#21518;&#35774;&#22791;&#24341;&#36215;&#30340;&#24310;&#36831;&#12290;&#27492;&#22806;&#65292;&#22312;&#22823;&#22810;&#25968;&#24212;&#29992;&#20013;&#65292;&#24517;&#39035;&#32771;&#34385;&#33021;&#28304;&#25928;&#29575;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#37096;&#20998;&#20849;&#20139;&#36890;&#20449;&#21407;&#29702;&#30340;&#36890;&#20449;&#39640;&#25928;&#24322;&#27493;&#22312;&#32447;&#32852;&#37030;&#23398;&#20064;&#65288;PAO-Fed&#65289;&#31574;&#30053;&#65292;&#36890;&#36807;&#20943;&#23569;&#21442;&#19982;&#32773;&#30340;&#36890;&#20449;&#24320;&#38144;&#65292;&#25552;&#39640;&#20102;&#21442;&#19982;&#23398;&#20064;&#20219;&#21153;&#30340;&#21487;&#35775;&#38382;&#24615;&#21644;&#25928;&#29575;&#12290;&#27492;&#22806;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#22788;&#29702;&#24322;&#26500;&#21644;&#24310;&#36831;&#35774;&#22791;&#65292;&#20351;&#20854;&#26356;&#36866;&#29992;&#20110;&#23454;&#38469;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online federated learning (FL) enables geographically distributed devices to learn a global shared model from locally available streaming data. Most online FL literature considers a best-case scenario regarding the participating clients and the communication channels. However, these assumptions are often not met in real-world applications. Asynchronous settings can reflect a more realistic environment, such as heterogeneous client participation due to available computational power and battery constraints, as well as delays caused by communication channels or straggler devices. Further, in most applications, energy efficiency must be taken into consideration. Using the principles of partial-sharing-based communications, we propose a communication-efficient asynchronous online federated learning (PAO-Fed) strategy. By reducing the communication overhead of the participants, the proposed method renders participation in the learning task more accessible and efficient. In addition, the prop
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38416;&#26126;&#20102;$L_p$-&#19968;&#33268;&#24615;&#21644;&#39118;&#38505;&#19968;&#33268;&#24615;&#20043;&#38388;&#30340;&#23494;&#20999;&#20851;&#31995;&#65292;&#29305;&#21035;&#22312;&#31227;&#20301;&#25439;&#22833;&#20989;&#25968;&#20013;&#21457;&#29616;&#20102;&#26032;&#30340;&#35268;&#24459;&#65292;&#36825;&#23545;&#20110;&#27491;&#21017;&#21270;&#20869;&#26680;&#26041;&#27861;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2303.15210</link><description>&lt;p&gt;
$L_p$&#19982;&#39118;&#38505;&#19968;&#33268;&#24615;&#20043;&#38388;&#30340;&#32852;&#31995;&#21450;&#20854;&#23545;&#27491;&#21017;&#21270;&#20869;&#26680;&#26041;&#27861;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
On the Connection between $L_p$ and Risk Consistency and its Implications on Regularized Kernel Methods. (arXiv:2303.15210v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15210
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38416;&#26126;&#20102;$L_p$-&#19968;&#33268;&#24615;&#21644;&#39118;&#38505;&#19968;&#33268;&#24615;&#20043;&#38388;&#30340;&#23494;&#20999;&#20851;&#31995;&#65292;&#29305;&#21035;&#22312;&#31227;&#20301;&#25439;&#22833;&#20989;&#25968;&#20013;&#21457;&#29616;&#20102;&#26032;&#30340;&#35268;&#24459;&#65292;&#36825;&#23545;&#20110;&#27491;&#21017;&#21270;&#20869;&#26680;&#26041;&#27861;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#39044;&#27979;&#36136;&#37327;&#32463;&#24120;&#36890;&#36807;&#20854;&#39118;&#38505;&#36827;&#34892;&#35780;&#20272;&#65292;&#22240;&#27492;&#23558;&#39118;&#38505;&#19968;&#33268;&#24615;&#35270;&#20026;&#23398;&#20064;&#26041;&#27861;&#30340;&#29702;&#24819;&#24615;&#36136;&#26159;&#24456;&#33258;&#28982;&#30340;&#65292;&#30830;&#23454;&#24050;&#32463;&#35777;&#26126;&#20102;&#35768;&#22810;&#36825;&#26679;&#30340;&#26041;&#27861;&#20855;&#26377;&#39118;&#38505;&#19968;&#33268;&#24615;&#12290;&#26412;&#25991;&#30340;&#31532;&#19968;&#20010;&#30446;&#30340;&#26159;&#22312;&#27604;&#20197;&#21069;&#26356;&#24191;&#27867;&#30340;&#25439;&#22833;&#20989;&#25968;&#31867;&#21035;&#20013;&#24314;&#31435;$L_p$&#19968;&#33268;&#24615;&#19982;&#39118;&#38505;&#19968;&#33268;&#24615;&#20043;&#38388;&#30340;&#23494;&#20999;&#32852;&#31995;&#12290;&#23581;&#35797;&#23558;&#27492;&#32852;&#31995;&#36716;&#31227;&#21040;&#31227;&#20301;&#25439;&#22833;&#20989;&#25968;&#65292;&#24778;&#20154;&#22320;&#21457;&#29616;&#65292;&#19982;&#20854;&#20182;&#35768;&#22810;&#32467;&#26524;&#30456;&#27604;&#65292;&#36825;&#31181;&#31227;&#20301;&#24182;&#19981;&#33021;&#20943;&#23569;&#24517;&#39035;&#23545;&#22522;&#30784;&#27010;&#29575;&#24230;&#37327;&#20570;&#20986;&#30340;&#20551;&#35774;&#12290;&#32467;&#26524;&#24212;&#29992;&#20110;&#27491;&#21017;&#21270;&#20869;&#26680;&#26041;&#27861;&#65292;&#20363;&#22914;&#25903;&#25345;&#21521;&#37327;&#26426;&#12290;
&lt;/p&gt;
&lt;p&gt;
As a predictor's quality is often assessed by means of its risk, it is natural to regard risk consistency as a desirable property of learning methods, and many such methods have indeed been shown to be risk consistent. The first aim of this paper is to establish the close connection between risk consistency and $L_p$-consistency for a considerably wider class of loss functions than has been done before. The attempt to transfer this connection to shifted loss functions surprisingly reveals that this shift does not reduce the assumptions needed on the underlying probability measure to the same extent as it does for many other results. The results are applied to regularized kernel methods such as support vector machines.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32771;&#34385;&#22312;&#32473;&#23450;&#20984;&#32422;&#26463;&#19979;&#23398;&#20064;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#65292;&#36890;&#36807;&#35299;&#20986;&#21463;&#32422;&#26463;&#30340;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#65292;&#25552;&#20986;&#26032;&#30340;&#38750;&#28176;&#36827;&#35823;&#24046;&#30028;&#65292;&#24182;&#24212;&#29992;&#20110;&#31232;&#30095;&#30697;&#38453;&#31561;&#24773;&#22659;&#65292;&#25913;&#36827;&#20102;&#29616;&#26377;&#32479;&#35745;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2303.15121</link><description>&lt;p&gt;
&#22312;&#20984;&#32422;&#26463;&#19979;&#23398;&#20064;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Learning linear dynamical systems under convex constraints. (arXiv:2303.15121v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15121
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#32473;&#23450;&#20984;&#32422;&#26463;&#19979;&#23398;&#20064;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#65292;&#36890;&#36807;&#35299;&#20986;&#21463;&#32422;&#26463;&#30340;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#65292;&#25552;&#20986;&#26032;&#30340;&#38750;&#28176;&#36827;&#35823;&#24046;&#30028;&#65292;&#24182;&#24212;&#29992;&#20110;&#31232;&#30095;&#30697;&#38453;&#31561;&#24773;&#22659;&#65292;&#25913;&#36827;&#20102;&#29616;&#26377;&#32479;&#35745;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20174;&#21333;&#20010;&#36712;&#36857;&#20013;&#35782;&#21035;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#38382;&#39064;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;&#26410;&#23545;&#31995;&#32479;&#30697;&#38453; $A^* \in \mathbb{R}^{n \times n}$ &#36827;&#34892;&#32467;&#26500;&#20551;&#35774;&#30340;&#24773;&#20917;&#65292;&#24182;&#23545;&#26222;&#36890;&#26368;&#23567;&#20108;&#20056; (OLS) &#20272;&#35745;&#22120;&#36827;&#34892;&#20102;&#35814;&#32454;&#20998;&#26512;&#12290;&#25105;&#20204;&#20551;&#35774;&#21487;&#29992;&#20808;&#21069;&#30340; $A^*$ &#30340;&#32467;&#26500;&#20449;&#24687;&#65292;&#21487;&#20197;&#22312;&#21253;&#21547; $A^*$ &#30340;&#20984;&#38598; $\mathcal{K}$ &#20013;&#25429;&#33719;&#12290;&#23545;&#20110;&#38543;&#21518;&#30340;&#21463;&#32422;&#26463;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#30340;&#35299;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986; Frobenius &#33539;&#25968;&#19979;&#20381;&#36182;&#20110; $\mathcal{K}$ &#22312; $A^*$ &#22788;&#20999;&#38181;&#30340;&#23616;&#37096;&#22823;&#23567;&#30340;&#38750;&#28176;&#36827;&#35823;&#24046;&#30028;&#12290;&#20026;&#20102;&#35828;&#26126;&#36825;&#19968;&#32467;&#26524;&#30340;&#26377;&#29992;&#24615;&#65292;&#25105;&#20204;&#23558;&#20854;&#23454;&#20363;&#21270;&#20026;&#20197;&#19979;&#35774;&#32622;&#65306;(i) $\mathcal{K}$ &#26159; $\mathbb{R}^{n \times n}$ &#20013;&#30340; $d$ &#32500;&#23376;&#31354;&#38388;&#65292;&#25110;&#32773; (ii) $A^*$ &#26159; $k$ &#31232;&#30095;&#30340;&#65292;$\mathcal{K}$ &#26159;&#36866;&#24403;&#32553;&#25918;&#30340; $\ell_1$ &#29699;&#12290;&#22312; $d, k \ll n^2$ &#30340;&#21306;&#22495;&#20013;&#65292;&#25105;&#20204;&#30340;&#35823;&#24046;&#30028;&#23545;&#20110;&#30456;&#21516;&#30340;&#32479;&#35745;&#21644;&#22122;&#22768;&#20551;&#35774;&#27604; OLS &#20272;&#35745;&#22120;&#33719;&#24471;&#20102;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of identification of linear dynamical systems from a single trajectory. Recent results have predominantly focused on the setup where no structural assumption is made on the system matrix $A^* \in \mathbb{R}^{n \times n}$, and have consequently analyzed the ordinary least squares (OLS) estimator in detail. We assume prior structural information on $A^*$ is available, which can be captured in the form of a convex set $\mathcal{K}$ containing $A^*$. For the solution of the ensuing constrained least squares estimator, we derive non-asymptotic error bounds in the Frobenius norm which depend on the local size of the tangent cone of $\mathcal{K}$ at $A^*$. To illustrate the usefulness of this result, we instantiate it for the settings where, (i) $\mathcal{K}$ is a $d$ dimensional subspace of $\mathbb{R}^{n \times n}$, or (ii) $A^*$ is $k$-sparse and $\mathcal{K}$ is a suitably scaled $\ell_1$ ball. In the regimes where $d, k \ll n^2$, our bounds improve upon those obta
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#35745;&#23398;&#20064;&#27169;&#22411;&#65292;&#30740;&#31350;&#30896;&#25758;&#25968;&#25454;&#20449;&#24687;&#21040;&#36798;&#30340;&#27850;&#26494;&#36807;&#31243;&#24615;&#36136;&#65292;&#24182;&#33021;&#22815;&#22238;&#31572;&#21355;&#26143;&#36816;&#33829;&#21830;&#20851;&#24515;&#30340;&#20004;&#20010;&#38382;&#25552;&#65306;&#65288;1&#65289;&#19979;&#19968;&#20010;&#25351;&#23450;&#26102;&#38388;&#38388;&#38548;&#20869;&#26159;&#21542;&#20250;&#26377;&#26032;&#30340;&#28040;&#24687;&#65311;&#65288;2&#65289;&#19979;&#19968;&#20010;&#28040;&#24687;&#23558;&#22312;&#20309;&#26102;&#65292;&#24182;&#24102;&#26377;&#24590;&#26679;&#30340;&#19981;&#30830;&#23450;&#24615;&#65311;</title><link>http://arxiv.org/abs/2303.15074</link><description>&lt;p&gt;
&#31354;&#38388;&#30896;&#25758;&#20849;&#38754;&#25968;&#25454;&#20449;&#24687;&#30340;&#27850;&#26494;&#36807;&#31243;&#29305;&#24615;
&lt;/p&gt;
&lt;p&gt;
Conjunction Data Messages for Space Collision Behave as a Poisson Process. (arXiv:2303.15074v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15074
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#35745;&#23398;&#20064;&#27169;&#22411;&#65292;&#30740;&#31350;&#30896;&#25758;&#25968;&#25454;&#20449;&#24687;&#21040;&#36798;&#30340;&#27850;&#26494;&#36807;&#31243;&#24615;&#36136;&#65292;&#24182;&#33021;&#22815;&#22238;&#31572;&#21355;&#26143;&#36816;&#33829;&#21830;&#20851;&#24515;&#30340;&#20004;&#20010;&#38382;&#25552;&#65306;&#65288;1&#65289;&#19979;&#19968;&#20010;&#25351;&#23450;&#26102;&#38388;&#38388;&#38548;&#20869;&#26159;&#21542;&#20250;&#26377;&#26032;&#30340;&#28040;&#24687;&#65311;&#65288;2&#65289;&#19979;&#19968;&#20010;&#28040;&#24687;&#23558;&#22312;&#20309;&#26102;&#65292;&#24182;&#24102;&#26377;&#24590;&#26679;&#30340;&#19981;&#30830;&#23450;&#24615;&#65311;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31354;&#38388;&#30862;&#29255;&#26159;&#31354;&#38388;&#25506;&#32034;&#20013;&#30340;&#19968;&#20010;&#37325;&#22823;&#38382;&#39064;&#12290;&#22269;&#38469;&#26426;&#26500;&#19981;&#26029;&#30417;&#27979;&#22823;&#37327;&#30340;&#36712;&#36947;&#29289;&#20307;&#25968;&#25454;&#24211;&#24182;&#21457;&#20986;&#20849;&#38754;&#25968;&#25454;&#20449;&#24687;&#24418;&#24335;&#30340;&#35686;&#21578;&#12290;&#23545;&#20110;&#21355;&#26143;&#36816;&#33829;&#21830;&#26469;&#35828;&#65292;&#19968;&#20010;&#37325;&#35201;&#30340;&#38382;&#39064;&#26159;&#20272;&#35745;&#20309;&#26102;&#20250;&#26377;&#26032;&#30340;&#20449;&#24687;&#21040;&#36798;&#65292;&#20197;&#20415;&#20182;&#20204;&#21487;&#20197;&#21450;&#26102;&#32780;&#33410;&#20461;&#22320;&#36827;&#34892;&#21355;&#26143;&#26426;&#21160;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20449;&#24687;&#21040;&#36798;&#36807;&#31243;&#30340;&#32479;&#35745;&#23398;&#20064;&#27169;&#22411;&#65292;&#20801;&#35768;&#25105;&#20204;&#22238;&#31572;&#20004;&#20010;&#37325;&#35201;&#30340;&#38382;&#39064;&#65306;&#65288;1&#65289;&#19979;&#19968;&#20010;&#25351;&#23450;&#26102;&#38388;&#38388;&#38548;&#20869;&#26159;&#21542;&#20250;&#26377;&#26032;&#30340;&#28040;&#24687;&#65311;&#65288;2&#65289;&#19979;&#19968;&#20010;&#28040;&#24687;&#23558;&#22312;&#20309;&#26102;&#65292;&#24182;&#24102;&#26377;&#24590;&#26679;&#30340;&#19981;&#30830;&#23450;&#24615;&#65311;&#25105;&#20204;&#30340;&#36125;&#21494;&#26031;&#27850;&#26494;&#36807;&#31243;&#27169;&#22411;&#23545;&#20110;&#38382;&#39064;&#65288;2&#65289;&#30340;&#24179;&#22343;&#39044;&#27979;&#35823;&#24046;&#22312;&#19968;&#20010;&#21253;&#21547;50,000&#20010;&#32039;&#23494;&#30456;&#36935;&#20107;&#20214;&#27979;&#35797;&#38598;&#20013;&#27604;&#22522;&#32447;&#23567;&#20102;4&#20010;&#23567;&#26102;&#20197;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
Space debris is a major problem in space exploration. International bodies continuously monitor a large database of orbiting objects and emit warnings in the form of conjunction data messages. An important question for satellite operators is to estimate when fresh information will arrive so that they can react timely but sparingly with satellite maneuvers. We propose a statistical learning model of the message arrival process, allowing us to answer two important questions: (1) Will there be any new message in the next specified time interval? (2) When exactly and with what uncertainty will the next message arrive? The average prediction error for question (2) of our Bayesian Poisson process model is smaller than the baseline in more than 4 hours in a test set of 50k close encounter events.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24369;&#21442;&#25968;&#32467;&#26500;&#20551;&#35774;&#30340;&#40657;&#30418;&#31243;&#24207;&#65292;&#29992;&#20110;&#20272;&#35745;&#32479;&#35745;&#27169;&#22411;&#21442;&#25968;&#12290;&#35813;&#31243;&#24207;&#21487;&#20197;&#25104;&#21151;&#22320;&#20174;&#20855;&#26377;&#22797;&#26434;&#31354;&#38388;&#30456;&#20851;&#30340;&#38750;&#39640;&#26031;&#27169;&#22411;&#20013;&#20272;&#35745;&#21644;&#37327;&#21270;&#21442;&#25968;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.15041</link><description>&lt;p&gt;
&#26397;&#40657;&#30418;&#21442;&#25968;&#20272;&#35745;&#36808;&#36827;
&lt;/p&gt;
&lt;p&gt;
Towards black-box parameter estimation. (arXiv:2303.15041v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15041
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24369;&#21442;&#25968;&#32467;&#26500;&#20551;&#35774;&#30340;&#40657;&#30418;&#31243;&#24207;&#65292;&#29992;&#20110;&#20272;&#35745;&#32479;&#35745;&#27169;&#22411;&#21442;&#25968;&#12290;&#35813;&#31243;&#24207;&#21487;&#20197;&#25104;&#21151;&#22320;&#20174;&#20855;&#26377;&#22797;&#26434;&#31354;&#38388;&#30456;&#20851;&#30340;&#38750;&#39640;&#26031;&#27169;&#22411;&#20013;&#20272;&#35745;&#21644;&#37327;&#21270;&#21442;&#25968;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#26368;&#36817;&#24050;&#32463;&#34987;&#35777;&#26126;&#26159;&#20272;&#35745;&#32479;&#35745;&#27169;&#22411;&#21442;&#25968;&#30340;&#25104;&#21151;&#24037;&#20855;&#65292;&#27169;&#25311;&#23481;&#26131;&#20294;&#20284;&#28982;&#35745;&#31639;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20294;&#36825;&#20123;&#26041;&#27861;&#30340;&#25104;&#21151;&#21462;&#20915;&#20110;&#27169;&#25311;&#20986;&#21487;&#20197;&#20805;&#20998;&#22797;&#21046;&#35266;&#23519;&#25968;&#25454;&#30340;&#21442;&#25968;&#65292;&#24182;&#19988;&#30446;&#21069;&#32570;&#20047;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#20135;&#29983;&#36825;&#20123;&#27169;&#25311;&#25968;&#25454;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#22522;&#20110;&#24369;&#21442;&#25968;&#32467;&#26500;&#20551;&#35774;&#20272;&#35745;&#32479;&#35745;&#27169;&#22411;&#21442;&#25968;&#30340;&#26032;&#30340;&#40657;&#30418;&#31243;&#24207;&#12290;&#23545;&#20110;&#20284;&#28982;&#20989;&#25968;&#26377;&#36739;&#39057;&#32321;&#20986;&#29616;&#30340;&#33391;&#22909;&#32467;&#26500;&#30340;&#24773;&#20917;&#65292;&#22914;&#26102;&#38388;&#24207;&#21015;&#65292;&#36825;&#26159;&#36890;&#36807;&#22312;&#24191;&#27867;&#30340;&#27169;&#25311;&#25968;&#25454;&#24211;&#19978;&#39044;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26469;&#23454;&#29616;&#30340;&#65292;&#35813;&#25968;&#25454;&#24211;&#28085;&#30422;&#20102;&#21508;&#31181;&#25968;&#25454;&#22823;&#23567;&#30340;&#33539;&#22260;&#12290;&#23545;&#20110;&#20854;&#20182;&#31867;&#22411;&#30340;&#22797;&#26434;&#20381;&#36182;&#20851;&#31995;&#65292;&#21017;&#38656;&#35201;&#19968;&#20010;&#36845;&#20195;&#30340;&#31639;&#27861;&#26469;&#25351;&#23548;&#22810;&#36718;&#27491;&#30830;&#21442;&#25968;&#21306;&#22495;&#30340;&#27169;&#25311;&#12290;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#25104;&#21151;&#22320;&#20174;&#20855;&#26377;&#22797;&#26434;&#31354;&#38388;&#30456;&#20851;&#30340;&#38750;&#39640;&#26031;&#27169;&#22411;&#20013;&#20272;&#35745;&#21644;&#37327;&#21270;&#21442;&#25968;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning algorithms have recently shown to be a successful tool in estimating parameters of statistical models for which simulation is easy, but likelihood computation is challenging. But the success of these approaches depends on simulating parameters that sufficiently reproduce the observed data, and, at present, there is a lack of efficient methods to produce these simulations. We develop new black-box procedures to estimate parameters of statistical models based only on weak parameter structure assumptions. For well-structured likelihoods with frequent occurrences, such as in time series, this is achieved by pre-training a deep neural network on an extensive simulated database that covers a wide range of data sizes. For other types of complex dependencies, an iterative algorithm guides simulations to the correct parameter region in multiple rounds. These approaches can successfully estimate and quantify the uncertainty of parameters from non-Gaussian models with complex spatia
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27491;&#21017;&#21270;EM&#31639;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#20302;&#26679;&#26412;&#25903;&#25345;&#24773;&#20917;&#19979;GMM&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#26356;&#26032;&#38382;&#39064;&#65292;&#24182;&#19988;&#21487;&#20197;&#21033;&#29992;&#39044;&#20808;&#25552;&#20379;&#30340;&#20808;&#39564;&#30693;&#35782;&#26469;&#23454;&#29616;&#26356;&#39640;&#25928;&#30340;&#35745;&#31639;&#12290;</title><link>http://arxiv.org/abs/2303.14989</link><description>&lt;p&gt;
&#27491;&#21017;&#21270;EM&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Regularized EM algorithm. (arXiv:2303.14989v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14989
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27491;&#21017;&#21270;EM&#31639;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#20302;&#26679;&#26412;&#25903;&#25345;&#24773;&#20917;&#19979;GMM&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#26356;&#26032;&#38382;&#39064;&#65292;&#24182;&#19988;&#21487;&#20197;&#21033;&#29992;&#39044;&#20808;&#25552;&#20379;&#30340;&#20808;&#39564;&#30693;&#35782;&#26469;&#23454;&#29616;&#26356;&#39640;&#25928;&#30340;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26399;&#26395;&#26368;&#22823;&#21270;&#65288;EM&#65289;&#31639;&#27861;&#26159;&#19968;&#31181;&#24191;&#27867;&#29992;&#20110;&#35745;&#31639;&#23616;&#37096;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65288;MLE&#65289;&#30340;&#36845;&#20195;&#31639;&#27861;&#12290;&#23427;&#21487;&#20197;&#24212;&#29992;&#20110;&#24191;&#27867;&#30340;&#38382;&#39064;&#65292;&#21253;&#25324;&#22522;&#20110;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65288;GMM&#65289;&#36827;&#34892;&#25968;&#25454;&#32858;&#31867;&#12290;&#24403;&#26679;&#26412;&#22823;&#23567;&#19981;&#22823;&#20110;&#25968;&#25454;&#32500;&#25968;&#26102;&#65292;&#21487;&#33021;&#20250;&#20986;&#29616;&#25968;&#20540;&#19981;&#31283;&#23450;&#21644;&#25910;&#25947;&#38382;&#39064;&#12290;&#22312;&#36825;&#31181;&#20302;&#26679;&#26412;&#25903;&#25345;&#65288;LSS&#65289;&#35774;&#32622;&#19979;&#65292;EM-GMM&#31639;&#27861;&#20013;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#26356;&#26032;&#21487;&#33021;&#20250;&#21464;&#24471;&#22855;&#24322;&#25110;&#30149;&#24577;&#65292;&#20174;&#32780;&#23548;&#33268;&#31639;&#27861;&#23849;&#28291;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#22312;&#35768;&#22810;&#20449;&#21495;&#22788;&#29702;&#38382;&#39064;&#20013;&#65292;&#39044;&#20808;&#21487;&#29992;&#30340;&#20808;&#39564;&#20449;&#24687;&#21487;&#20197;&#25351;&#31034;&#19981;&#21516;&#32858;&#31867;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#26576;&#20123;&#32467;&#26500;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#27491;&#21017;&#21270;EM&#31639;&#27861;&#65292;&#29992;&#20110;GMM&#65292;&#21487;&#20197;&#26377;&#25928;&#21033;&#29992;&#36825;&#26679;&#30340;&#20808;&#39564;&#30693;&#35782;&#20197;&#21450;&#24212;&#23545;LSS&#24773;&#20917;&#12290;&#35813;&#26041;&#27861;&#26088;&#22312;&#26368;&#22823;&#21270;&#24809;&#32602;&#30340;GMM&#20284;&#28982;&#65292;&#20854;&#20013;&#21487;&#20197;&#20351;&#29992;&#27491;&#21017;&#21270;&#20272;&#35745;&#26469;&#30830;&#20445;&#27491;&#23450;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#12290;
&lt;/p&gt;
&lt;p&gt;
Expectation-Maximization (EM) algorithm is a widely used iterative algorithm for computing (local) maximum likelihood estimate (MLE). It can be used in an extensive range of problems, including the clustering of data based on the Gaussian mixture model (GMM). Numerical instability and convergence problems may arise in situations where the sample size is not much larger than the data dimensionality. In such low sample support (LSS) settings, the covariance matrix update in the EM-GMM algorithm may become singular or poorly conditioned, causing the algorithm to crash. On the other hand, in many signal processing problems, a priori information can be available indicating certain structures for different cluster covariance matrices. In this paper, we present a regularized EM algorithm for GMM-s that can make efficient use of such prior knowledge as well as cope with LSS situations. The method aims to maximize a penalized GMM likelihood where regularized estimation may be used to ensure pos
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25552;&#20986;&#20102;&#29992;&#30446;&#26631;&#26465;&#20214;&#30340;&#24378;&#21270;&#23398;&#20064;&#26469;&#23398;&#20064;&#29983;&#25104;&#27169;&#22411;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#22312;&#35757;&#32451;&#38598;&#20013;&#29983;&#25104;&#22810;&#26679;&#24615;&#21644;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#12290;</title><link>http://arxiv.org/abs/2303.14811</link><description>&lt;p&gt;
&#29992;&#30446;&#26631;&#26465;&#20214;&#30340;&#24378;&#21270;&#23398;&#20064;&#23398;&#20064;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning Generative Models with Goal-conditioned Reinforcement Learning. (arXiv:2303.14811v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14811
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25552;&#20986;&#20102;&#29992;&#30446;&#26631;&#26465;&#20214;&#30340;&#24378;&#21270;&#23398;&#20064;&#26469;&#23398;&#20064;&#29983;&#25104;&#27169;&#22411;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#22312;&#35757;&#32451;&#38598;&#20013;&#29983;&#25104;&#22810;&#26679;&#24615;&#21644;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#12289;&#29992;&#30446;&#26631;&#26465;&#20214;&#30340;&#24378;&#21270;&#23398;&#20064;&#26469;&#23398;&#20064;&#29983;&#25104;&#27169;&#22411;&#30340;&#26694;&#26550;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#20004;&#20010;&#20195;&#29702;&#65292;&#19968;&#20010;&#26159;&#30446;&#26631;&#26465;&#20214;&#20195;&#29702;&#65288;GC-agent&#65289;&#65292;&#21478;&#19968;&#20010;&#26159;&#30417;&#30563;&#20195;&#29702;&#65288;S-agent&#65289;&#12290;&#22312;&#32473;&#23450;&#29992;&#25143;&#36755;&#20837;&#30340;&#21021;&#22987;&#29366;&#24577;&#21518;&#65292;GC-agent&#23398;&#20064;&#37325;&#26500;&#35757;&#32451;&#38598;&#12290;&#22312;&#27492;&#24773;&#20917;&#19979;&#65292;&#35757;&#32451;&#38598;&#20013;&#30340;&#20803;&#32032;&#26159;&#30446;&#26631;&#12290;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;S-agent&#23398;&#20064;&#22312;&#19981;&#30693;&#36947;&#30446;&#26631;&#30340;&#24773;&#20917;&#19979;&#27169;&#20223;GC-agent&#12290;&#22312;&#25512;&#29702;&#38454;&#27573;&#65292;&#25105;&#20204;&#20351;&#29992;S-agent&#29983;&#25104;&#26032;&#30340;&#26679;&#26412;&#12290;&#31867;&#20284;&#20110;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65292;&#25105;&#20204;&#36890;&#36807;&#25512;&#23548;&#20986;&#19968;&#20010;&#19978;&#38480;&#26469;&#34913;&#37327;&#36127;&#23545;&#25968;&#20284;&#28982;&#65292;&#23427;&#30001;&#37325;&#26500;&#39033;&#21644;GC-agent&#31574;&#30053;&#19982;&#65288;&#30446;&#26631;&#26080;&#20851;&#30340;&#65289;S-agent&#31574;&#30053;&#20043;&#38388;&#30340;&#24046;&#24322;&#32452;&#25104;&#12290;&#25105;&#20204;&#22312;&#22270;&#20687;&#21512;&#25104;&#20219;&#21153;&#20013;&#32463;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#29983;&#25104;&#22810;&#26679;&#24615;&#21644;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel, alternative framework for learning generative models with goal-conditioned reinforcement learning. We define two agents, a goal conditioned agent (GC-agent) and a supervised agent (S-agent). Given a user-input initial state, the GC-agent learns to reconstruct the training set. In this context, elements in the training set are the goals. During training, the S-agent learns to imitate the GC-agent while remaining agnostic of the goals. At inference we generate new samples with the S-agent. Following a similar route as in variational auto-encoders, we derive an upper bound on the negative log-likelihood that consists of a reconstruction term and a divergence between the GC-agent policy and the (goal-agnostic) S-agent policy. We empirically demonstrate that our method is able to generate diverse and high quality samples in the task of image synthesis.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#36866;&#24212;&#26041;&#27861;FAStEN&#65292;&#29992;&#20110;&#22312;&#39640;&#32500;&#20989;&#25968;&#22238;&#24402;&#38382;&#39064;&#20013;&#25191;&#34892;&#29305;&#24449;&#36873;&#25321;&#21644;&#21442;&#25968;&#20272;&#35745;&#65292;&#36890;&#36807;&#21033;&#29992;&#20989;&#25968;&#20027;&#25104;&#20998;&#21644;&#23545;&#20598;&#22686;&#24191;Lagrangian&#38382;&#39064;&#30340;&#31232;&#30095;&#24615;&#36136;&#65292;&#20855;&#26377;&#26174;&#33879;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#36873;&#25321;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.14801</link><description>&lt;p&gt;
&#39640;&#32500;&#20989;&#25968;&#22238;&#24402;&#20013;&#29305;&#24449;&#36873;&#25321;&#21644;&#20272;&#35745;&#30340;&#19968;&#31181;&#39640;&#25928;&#33258;&#36866;&#24212;&#26041;&#27861;--FAStEN
&lt;/p&gt;
&lt;p&gt;
FAStEN: an efficient adaptive method for feature selection and estimation in high-dimensional functional regressions. (arXiv:2303.14801v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14801
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#36866;&#24212;&#26041;&#27861;FAStEN&#65292;&#29992;&#20110;&#22312;&#39640;&#32500;&#20989;&#25968;&#22238;&#24402;&#38382;&#39064;&#20013;&#25191;&#34892;&#29305;&#24449;&#36873;&#25321;&#21644;&#21442;&#25968;&#20272;&#35745;&#65292;&#36890;&#36807;&#21033;&#29992;&#20989;&#25968;&#20027;&#25104;&#20998;&#21644;&#23545;&#20598;&#22686;&#24191;Lagrangian&#38382;&#39064;&#30340;&#31232;&#30095;&#24615;&#36136;&#65292;&#20855;&#26377;&#26174;&#33879;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#36873;&#25321;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20989;&#25968;&#22238;&#24402;&#20998;&#26512;&#26159;&#35768;&#22810;&#24403;&#20195;&#31185;&#23398;&#24212;&#29992;&#30340;&#24050;&#24314;&#31435;&#24037;&#20855;&#12290;&#28041;&#21450;&#22823;&#35268;&#27169;&#21644;&#22797;&#26434;&#25968;&#25454;&#38598;&#30340;&#22238;&#24402;&#38382;&#39064;&#26159;&#26222;&#36941;&#23384;&#22312;&#30340;&#65292;&#29305;&#24449;&#36873;&#25321;&#23545;&#20110;&#36991;&#20813;&#36807;&#24230;&#25311;&#21512;&#21644;&#23454;&#29616;&#20934;&#30830;&#39044;&#27979;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#12289;&#28789;&#27963;&#30340;&#12289;&#36229;&#39640;&#25928;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#31232;&#30095;&#39640;&#32500;&#20989;&#25968;&#22238;&#24402;&#38382;&#39064;&#20013;&#25191;&#34892;&#29305;&#24449;&#36873;&#25321;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#20854;&#25193;&#23637;&#21040;&#26631;&#37327;&#23545;&#20989;&#25968;&#26694;&#26550;&#20013;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#20989;&#25968;&#25968;&#25454;&#12289;&#20248;&#21270;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#20197;&#21516;&#26102;&#25191;&#34892;&#29305;&#24449;&#36873;&#25321;&#21644;&#21442;&#25968;&#20272;&#35745;&#12290;&#25105;&#20204;&#21033;&#29992;&#20989;&#25968;&#20027;&#25104;&#20998;&#30340;&#29305;&#24615;&#20197;&#21450;&#23545;&#20598;&#22686;&#24191;Lagrangian&#38382;&#39064;&#30340;&#31232;&#30095;&#24615;&#36136;&#65292;&#26174;&#33879;&#38477;&#20302;&#20102;&#35745;&#31639;&#25104;&#26412;&#65292;&#24182;&#24341;&#20837;&#20102;&#33258;&#36866;&#24212;&#26041;&#26696;&#26469;&#25552;&#39640;&#36873;&#25321;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#27169;&#25311;&#30740;&#31350;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#26368;&#20339;&#29616;&#26377;&#31454;&#20105;&#23545;&#25163;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#65292;&#24182;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#39640;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Functional regression analysis is an established tool for many contemporary scientific applications. Regression problems involving large and complex data sets are ubiquitous, and feature selection is crucial for avoiding overfitting and achieving accurate predictions. We propose a new, flexible, and ultra-efficient approach to perform feature selection in a sparse high dimensional function-on-function regression problem, and we show how to extend it to the scalar-on-function framework. Our method combines functional data, optimization, and machine learning techniques to perform feature selection and parameter estimation simultaneously. We exploit the properties of Functional Principal Components, and the sparsity inherent to the Dual Augmented Lagrangian problem to significantly reduce computational cost, and we introduce an adaptive scheme to improve selection accuracy. Through an extensive simulation study, we benchmark our approach to the best existing competitors and demonstrate a 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#31639;&#27861;&#27867;&#21270;&#35823;&#24046;&#20449;&#24687;&#29702;&#35770;&#30028;&#38480;&#30340;&#32039;&#23494;&#24615;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;&#36866;&#24403;&#30340;&#20551;&#35774;&#65292;&#21487;&#20197;&#22312;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;&#19979;&#20351;&#29992;&#20449;&#24687;&#29702;&#35770;&#37327;$O(\lambda/n)$&#26469;&#19978;&#30028;&#20272;&#35745;&#27867;&#21270;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2303.14658</link><description>&lt;p&gt;
&#20851;&#20110;&#23398;&#20064;&#31639;&#27861;&#27867;&#21270;&#35823;&#24046;&#20449;&#24687;&#29702;&#35770;&#30028;&#38480;&#30340;&#32039;&#23494;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the tightness of information-theoretic bounds on generalization error of learning algorithms. (arXiv:2303.14658v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14658
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#31639;&#27861;&#27867;&#21270;&#35823;&#24046;&#20449;&#24687;&#29702;&#35770;&#30028;&#38480;&#30340;&#32039;&#23494;&#24615;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;&#36866;&#24403;&#30340;&#20551;&#35774;&#65292;&#21487;&#20197;&#22312;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;&#19979;&#20351;&#29992;&#20449;&#24687;&#29702;&#35770;&#37327;$O(\lambda/n)$&#26469;&#19978;&#30028;&#20272;&#35745;&#27867;&#21270;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Russo&#21644;Xu&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#35777;&#26126;&#23398;&#20064;&#31639;&#27861;&#30340;&#27867;&#21270;&#35823;&#24046;&#21487;&#20197;&#36890;&#36807;&#20449;&#24687;&#24230;&#37327;&#36827;&#34892;&#19978;&#30028;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#25910;&#25947;&#36895;&#24230;&#36890;&#24120;&#34987;&#35748;&#20026;&#26159;&#8220;&#24930;&#8221;&#30340;&#65292;&#22240;&#20026;&#23427;&#30340;&#26399;&#26395;&#25910;&#25947;&#36895;&#24230;&#30340;&#24418;&#24335;&#20026;$O(\sqrt{\lambda/n})$&#65292;&#20854;&#20013;$\lambda$&#26159;&#19968;&#20123;&#20449;&#24687;&#29702;&#35770;&#37327;&#12290;&#22312;&#26412;&#25991;&#20013;&#25105;&#20204;&#35777;&#26126;&#20102;&#26681;&#21495;&#24182;&#19981;&#19968;&#23450;&#24847;&#21619;&#30528;&#25910;&#25947;&#36895;&#24230;&#24930;&#65292;&#21487;&#20197;&#22312;&#36866;&#24403;&#30340;&#20551;&#35774;&#19979;&#20351;&#29992;&#36825;&#20010;&#30028;&#38480;&#26469;&#24471;&#21040;$O(\lambda/n)$&#30340;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#36798;&#21040;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;&#30340;&#20851;&#38190;&#26465;&#20214;&#65292;&#21363;&#25152;&#35859;&#30340;$(\eta,c)$-&#20013;&#24515;&#26465;&#20214;&#12290;&#22312;&#36825;&#20010;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#23398;&#20064;&#31639;&#27861;&#27867;&#21270;&#35823;&#24046;&#30340;&#20449;&#24687;&#29702;&#35770;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
A recent line of works, initiated by Russo and Xu, has shown that the generalization error of a learning algorithm can be upper bounded by information measures. In most of the relevant works, the convergence rate of the expected generalization error is in the form of $O(\sqrt{\lambda/n})$ where $\lambda$ is some information-theoretic quantities such as the mutual information or conditional mutual information between the data and the learned hypothesis. However, such a learning rate is typically considered to be ``slow", compared to a ``fast rate" of $O(\lambda/n)$ in many learning scenarios. In this work, we first show that the square root does not necessarily imply a slow rate, and a fast rate result can still be obtained using this bound under appropriate assumptions. Furthermore, we identify the critical conditions needed for the fast rate generalization error, which we call the $(\eta,c)$-central condition. Under this condition, we give information-theoretic bounds on the generaliz
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20195;&#29702;&#24314;&#27169;&#26469;&#35299;&#20915;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#36127;&#36801;&#31227;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#35782;&#21035;&#21738;&#20123;&#28304;&#20219;&#21153;&#30340;&#23376;&#38598;&#20250;&#23545;&#30446;&#26631;&#20219;&#21153;&#26377;&#24110;&#21161;&#12290;</title><link>http://arxiv.org/abs/2303.14582</link><description>&lt;p&gt;
&#21033;&#29992;&#20195;&#29702;&#27169;&#22411;&#35782;&#21035;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#30340;&#36127;&#36801;&#31227;
&lt;/p&gt;
&lt;p&gt;
Identification of Negative Transfers in Multitask Learning Using Surrogate Models. (arXiv:2303.14582v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14582
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20195;&#29702;&#24314;&#27169;&#26469;&#35299;&#20915;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#36127;&#36801;&#31227;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#35782;&#21035;&#21738;&#20123;&#28304;&#20219;&#21153;&#30340;&#23376;&#38598;&#20250;&#23545;&#30446;&#26631;&#20219;&#21153;&#26377;&#24110;&#21161;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20219;&#21153;&#23398;&#20064;&#24191;&#27867;&#24212;&#29992;&#20110;&#36890;&#36807;&#22686;&#21152;&#22810;&#20010;&#30456;&#20851;&#28304;&#20219;&#21153;&#26469;&#35757;&#32451;&#20302;&#36164;&#28304;&#30446;&#26631;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#23558;&#25152;&#26377;&#28304;&#20219;&#21153;&#19982;&#30446;&#26631;&#20219;&#21153;&#31616;&#21333;&#32452;&#21512;&#24182;&#19981;&#24635;&#26159;&#33021;&#25552;&#39640;&#30446;&#26631;&#20219;&#21153;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#22240;&#20026;&#20250;&#23384;&#22312;&#36127;&#36801;&#31227;&#12290;&#22240;&#27492;&#65292;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#26159;&#35782;&#21035;&#21738;&#20123;&#28304;&#20219;&#21153;&#30340;&#23376;&#38598;&#20250;&#23545;&#30446;&#26631;&#20219;&#21153;&#26377;&#30410;&#12290;&#36825;&#20010;&#38382;&#39064;&#22312;&#35745;&#31639;&#19978;&#24456;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#23376;&#38598;&#30340;&#25968;&#37327;&#38543;&#30528;&#28304;&#20219;&#21153;&#30340;&#25968;&#37327;&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#20195;&#29702;&#24314;&#27169;&#26469;&#35299;&#20915;&#27492;&#38382;&#39064;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;&#22312;&#20195;&#29702;&#24314;&#27169;&#20013;&#65292;&#25105;&#20204;&#23545;&#28304;&#20219;&#21153;&#36827;&#34892;&#37319;&#26679;&#65288;&#38543;&#26426;&#65289;&#65292;&#24182;&#39044;&#20808;&#35745;&#31639;&#23427;&#20204;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;&#34920;&#29616;&#65307;&#28982;&#21518;&#65292;&#25105;&#20204;&#29992;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#26469;&#36924;&#36817;&#39044;&#20808;&#35745;&#31639;&#30340;&#34920;&#29616;&#65292;&#35813;&#27169;&#22411;&#20063;&#21487;&#29992;&#20110;&#39044;&#27979;&#26410;&#37319;&#26679;&#30340;&#23376;&#38598;&#30340;&#34920;&#29616;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#21512;&#25104;&#31034;&#20363;&#21644;&#19968;&#20010;&#29616;&#23454;&#19990;&#30028;&#30340;&#22810;&#35821;&#35328;&#24773;&#24863;&#20998;&#26512;&#20219;&#21153;&#19978;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multitask learning is widely used in practice to train a low-resource target task by augmenting it with multiple related source tasks. Yet, naively combining all the source tasks with a target task does not always improve the prediction performance for the target task due to negative transfers. Thus, a critical problem in multitask learning is identifying subsets of source tasks that would benefit the target task. This problem is computationally challenging since the number of subsets grows exponentially with the number of source tasks; efficient heuristics for subset selection does not always capture the relationship between task subsets and multitask learning performances. In this paper, we introduce an efficient procedure to address this problem via surrogate modeling. In surrogate modeling, we sample (random) subsets of source tasks and precompute their multitask learning performances; Then, we approximate the precomputed performances with a linear regression model that can also be
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#30830;&#23450;&#24615;&#8221;&#21644;&#8220;&#19981;&#30830;&#23450;&#24615;&#8221;&#30340;&#24471;&#20998;&#26041;&#27861;&#26469;&#37327;&#21270;&#20998;&#31867;&#20915;&#31574;&#20013;&#39044;&#27979;&#30340;&#36136;&#37327;&#21644;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.14568</link><description>&lt;p&gt;
&#37327;&#21270;&#20998;&#31867;&#20915;&#31574;&#30340;&#30830;&#23450;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#27979;&#37327;
&lt;/p&gt;
&lt;p&gt;
Measuring Classification Decision Certainty and Doubt. (arXiv:2303.14568v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14568
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#30830;&#23450;&#24615;&#8221;&#21644;&#8220;&#19981;&#30830;&#23450;&#24615;&#8221;&#30340;&#24471;&#20998;&#26041;&#27861;&#26469;&#37327;&#21270;&#20998;&#31867;&#20915;&#31574;&#20013;&#39044;&#27979;&#30340;&#36136;&#37327;&#21644;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30830;&#23450;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#30340;&#23450;&#37327;&#34920;&#24449;&#21644;&#20272;&#35745;&#22312;&#20248;&#21270;&#21644;&#20915;&#31574;&#36807;&#31243;&#20013;&#20855;&#26377;&#22522;&#30784;&#37325;&#35201;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#30452;&#35266;&#30340;&#24471;&#20998;&#65292;&#31216;&#20026;&#8220;&#30830;&#23450;&#24615;&#8221;&#21644;&#8220;&#19981;&#30830;&#23450;&#24615;&#8221;&#65292;&#21487;&#22312;&#36125;&#21494;&#26031;&#21644;&#39057;&#29575;&#20027;&#20041;&#26694;&#26550;&#19979;&#29992;&#20110;&#35780;&#20272;&#21644;&#27604;&#36739;&#65288;&#22810;&#65289;&#20998;&#31867;&#20915;&#31574;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#30340;&#39044;&#27979;&#36136;&#37327;&#21644;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantitative characterizations and estimations of uncertainty are of fundamental importance in optimization and decision-making processes. Herein, we propose intuitive scores, which we call \textit{certainty} and \textit{doubt}, that can be used in both a Bayesian and frequentist framework to assess and compare the quality and uncertainty of predictions in (multi-)classification decision machine learning problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#26377;&#38480;&#21382;&#21490;&#35760;&#24518;&#30165;&#36857;&#22312;&#19979;&#19968;&#20195;&#27700;&#24211;&#35745;&#31639;&#26426;&#20013;&#23384;&#22312;&#30340;&#22266;&#26377;&#38480;&#21046;&#65292;&#24182;&#21457;&#29616;&#22312;&#39640;&#24230;&#38750;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#20013;&#65292;&#27969;&#34892;&#30340;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#36828;&#36828;&#26080;&#27861;&#23454;&#29616;&#26368;&#20339;&#39044;&#27979;&#36825;&#31181;&#22797;&#26434;&#36807;&#31243;&#30340;&#30446;&#26631;&#12290;&#36825;&#20123;&#32467;&#26524;&#20984;&#26174;&#20102;&#19968;&#31181;&#26032;&#19968;&#20195;&#20248;&#21270;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#30340;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2303.14553</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#30340;&#22797;&#26434;&#24615;&#26657;&#20934;&#22522;&#20934;&#25581;&#31034;&#20102;&#19979;&#19968;&#20195;&#27700;&#24211;&#35745;&#31639;&#26426;&#39044;&#27979;&#25104;&#21151;&#21644;&#35823;&#23548;&#30340;&#26102;&#26426;&#12290;
&lt;/p&gt;
&lt;p&gt;
Complexity-calibrated Benchmarks for Machine Learning Reveal When Next-Generation Reservoir Computer Predictions Succeed and Mislead. (arXiv:2303.14553v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14553
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#26377;&#38480;&#21382;&#21490;&#35760;&#24518;&#30165;&#36857;&#22312;&#19979;&#19968;&#20195;&#27700;&#24211;&#35745;&#31639;&#26426;&#20013;&#23384;&#22312;&#30340;&#22266;&#26377;&#38480;&#21046;&#65292;&#24182;&#21457;&#29616;&#22312;&#39640;&#24230;&#38750;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#20013;&#65292;&#27969;&#34892;&#30340;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#36828;&#36828;&#26080;&#27861;&#23454;&#29616;&#26368;&#20339;&#39044;&#27979;&#36825;&#31181;&#22797;&#26434;&#36807;&#31243;&#30340;&#30446;&#26631;&#12290;&#36825;&#20123;&#32467;&#26524;&#20984;&#26174;&#20102;&#19968;&#31181;&#26032;&#19968;&#20195;&#20248;&#21270;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#34987;&#29992;&#20110;&#39044;&#27979;&#37329;&#34701;&#12289;&#27668;&#20505;&#12289;&#35821;&#35328;&#21644;&#20854;&#20182;&#39046;&#22495;&#30340;&#26102;&#38388;&#24207;&#21015;&#12290;&#27700;&#24211;&#35745;&#31639;&#26426;&#26159;&#19968;&#31181;&#29305;&#21035;&#26131;&#20110;&#35757;&#32451;&#30340;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#24418;&#24335;&#12290;&#26368;&#36817;&#24341;&#20837;&#20102;&#8220;&#19979;&#19968;&#20195;&#8221;&#27700;&#24211;&#35745;&#31639;&#26426;&#65292;&#20854;&#20013;&#20869;&#23384;&#36319;&#36394;&#20165;&#28041;&#21450;&#26377;&#38480;&#25968;&#37327;&#30340;&#20808;&#21069;&#31526;&#21495;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#36825;&#31181;&#26377;&#36259;&#25552;&#35758;&#20013;&#26377;&#38480;&#21382;&#21490;&#35760;&#24518;&#30165;&#36857;&#30340;&#22266;&#26377;&#38480;&#21046;&#12290;&#20174;&#33539;&#35834;&#19981;&#31561;&#24335;&#30340;&#19979;&#30028;&#21487;&#20197;&#30475;&#20986;&#65292;&#22312;&#30001;&#22823;&#22411;&#27010;&#29575;&#29366;&#24577;&#26426;&#29983;&#25104;&#30340;&#39640;&#24230;&#38750;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#20013;&#65292;&#20855;&#26377;&#30456;&#24403;&#38271;&#23384;&#20648;&#30165;&#36857;&#30340;&#19979;&#19968;&#20195;&#27700;&#24211;&#35745;&#31639;&#26426;&#30340;&#38169;&#35823;&#27010;&#29575;&#27604;&#39044;&#27979;&#19979;&#19968;&#20010;&#35266;&#23519;&#30340;&#26368;&#23567;&#21487;&#36798;&#38169;&#35823;&#27010;&#29575;&#39640;&#33267;&#23569;~60%&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#20284;&#20046;&#27969;&#34892;&#30340;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#36828;&#36828;&#26080;&#27861;&#23454;&#29616;&#26368;&#20339;&#39044;&#27979;&#36825;&#31181;&#22797;&#26434;&#36807;&#31243;&#30340;&#30446;&#26631;&#12290;&#36825;&#20123;&#32467;&#26524;&#20984;&#26174;&#20102;&#19968;&#31181;&#26032;&#19968;&#20195;&#20248;&#21270;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recurrent neural networks are used to forecast time series in finance, climate, language, and from many other domains. Reservoir computers are a particularly easily trainable form of recurrent neural network. Recently, a "next-generation" reservoir computer was introduced in which the memory trace involves only a finite number of previous symbols. We explore the inherent limitations of finite-past memory traces in this intriguing proposal. A lower bound from Fano's inequality shows that, on highly non-Markovian processes generated by large probabilistic state machines, next-generation reservoir computers with reasonably long memory traces have an error probability that is at least ~ 60% higher than the minimal attainable error probability in predicting the next observation. More generally, it appears that popular recurrent neural networks fall far short of optimally predicting such complex processes. These results highlight the need for a new generation of optimized recurrent neural ne
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#35299;&#37322;&#32422;&#26463;&#19979;&#30340;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;EPAC&#27169;&#22411;&#65292;&#25506;&#35752;&#20102;&#20351;&#29992;&#36825;&#20123;&#35299;&#37322;&#26102;&#27169;&#22411;&#30340;&#30410;&#22788;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#21464;&#20998;&#36817;&#20284;&#30340;&#31639;&#27861;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2303.14496</link><description>&lt;p&gt;
&#35299;&#37322;&#32422;&#26463;&#19979;&#30340;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Learning with Explanation Constraints. (arXiv:2303.14496v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14496
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35299;&#37322;&#32422;&#26463;&#19979;&#30340;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;EPAC&#27169;&#22411;&#65292;&#25506;&#35752;&#20102;&#20351;&#29992;&#36825;&#20123;&#35299;&#37322;&#26102;&#27169;&#22411;&#30340;&#30410;&#22788;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#21464;&#20998;&#36817;&#20284;&#30340;&#31639;&#27861;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#30417;&#30563;&#23398;&#20064;&#20551;&#35774;&#23384;&#22312;&#26631;&#27880;&#25968;&#25454;&#65292;&#20294;&#25105;&#20204;&#21487;&#33021;&#26377;&#20851;&#20110;&#27169;&#22411;&#24212;&#22914;&#20309;&#36816;&#34892;&#30340;&#20808;&#39564;&#20449;&#24687;&#12290;&#26412;&#25991;&#23558;&#20854;&#24418;&#24335;&#21270;&#20026;&#20174;&#35299;&#37322;&#32422;&#26463;&#20013;&#23398;&#20064;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#23398;&#20064;&#29702;&#35770;&#26694;&#26550;&#65292;&#20998;&#26512;&#20102;&#36825;&#20123;&#35299;&#37322;&#22914;&#20309;&#25552;&#39640;&#27169;&#22411;&#30340;&#23398;&#20064;&#33021;&#21147;&#12290;&#26412;&#25991;&#30340;&#31532;&#19968;&#39033;&#20851;&#38190;&#36129;&#29486;&#26159;&#36890;&#36807;&#23450;&#20041;&#25105;&#20204;&#31216;&#20043;&#20026;EPAC&#27169;&#22411;&#65288;&#22312;&#26032;&#25968;&#25454;&#26399;&#26395;&#20013;&#28385;&#36275;&#36825;&#20123;&#32422;&#26463;&#30340;&#27169;&#22411;&#65289;&#26469;&#22238;&#31572;&#21738;&#20123;&#27169;&#22411;&#20250;&#21463;&#30410;&#20110;&#35299;&#37322;&#36825;&#19968;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#26631;&#20934;&#30340;&#23398;&#20064;&#29702;&#35770;&#24037;&#20855;&#20998;&#26512;&#20102;&#36825;&#31867;&#27169;&#22411;&#12290;&#31532;&#20108;&#20010;&#20851;&#38190;&#36129;&#29486;&#26159;&#23545;&#20110;&#30001;&#32447;&#24615;&#27169;&#22411;&#21644;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26799;&#24230;&#20449;&#24687;&#32473;&#20986;&#30340;&#35268;&#33539;&#35299;&#37322;&#30340;&#38480;&#21046;&#65288;&#20197;&#20854;Rademacher&#22797;&#26434;&#24230;&#20026;&#34913;&#37327;&#26631;&#20934;&#65289;&#36827;&#34892;&#20102;&#34920;&#24449;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#31181;&#21464;&#20998;&#36817;&#20284;&#25552;&#20379;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#30340;&#31639;&#27861;&#35299;&#20915;&#26041;&#26696;&#65292;&#23427;&#33021;&#22815;&#23454;&#29616;&#26356;&#22909;&#30340;&#24615;&#33021;&#24182;&#28385;&#36275;&#36825;&#20123;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;
While supervised learning assumes the presence of labeled data, we may have prior information about how models should behave. In this paper, we formalize this notion as learning from explanation constraints and provide a learning theoretic framework to analyze how such explanations can improve the learning of our models. For what models would explanations be helpful? Our first key contribution addresses this question via the definition of what we call EPAC models (models that satisfy these constraints in expectation over new data), and we analyze this class of models using standard learning theoretic tools. Our second key contribution is to characterize these restrictions (in terms of their Rademacher complexities) for a canonical class of explanations given by gradient information for linear models and two layer neural networks. Finally, we provide an algorithmic solution for our framework, via a variational approximation that achieves better performance and satisfies these constraint
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#33258;&#22238;&#24402;&#26465;&#20214;&#31070;&#32463;&#36807;&#31243;&#27169;&#22411;&#65292;&#33021;&#22815;&#24314;&#27169;&#39640;&#24230;&#30456;&#20851;&#30340;&#38750;&#39640;&#26031;&#39044;&#27979;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2303.14468</link><description>&lt;p&gt;
&#33258;&#22238;&#24402;&#26465;&#20214;&#31070;&#32463;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Autoregressive Conditional Neural Processes. (arXiv:2303.14468v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14468
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#33258;&#22238;&#24402;&#26465;&#20214;&#31070;&#32463;&#36807;&#31243;&#27169;&#22411;&#65292;&#33021;&#22815;&#24314;&#27169;&#39640;&#24230;&#30456;&#20851;&#30340;&#38750;&#39640;&#26031;&#39044;&#27979;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26377;&#26465;&#20214;&#30340;&#31070;&#32463;&#36807;&#31243;&#26159;&#19968;&#31181;&#26377;&#21560;&#24341;&#21147;&#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#33021;&#22815;&#20135;&#29983;&#33391;&#22909;&#26657;&#20934;&#30340;&#39044;&#27979;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#31616;&#21333;&#30340;&#26368;&#22823;&#20284;&#28982;&#36807;&#31243;&#36827;&#34892;&#35757;&#32451;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#21464;&#26377;&#26465;&#20214;&#30340;&#31070;&#32463;&#36807;&#31243;&#22312;&#27979;&#35797;&#26102;&#37096;&#32626;&#26041;&#24335;&#30340;&#26041;&#27861;&#65292;&#20174;&#32780;&#33021;&#22815;&#24314;&#27169;&#39640;&#24230;&#30456;&#20851;&#30340;&#38750;&#39640;&#26031;&#39044;&#27979;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conditional neural processes (CNPs; Garnelo et al., 2018a) are attractive meta-learning models which produce well-calibrated predictions and are trainable via a simple maximum likelihood procedure. Although CNPs have many advantages, they are unable to model dependencies in their predictions. Various works propose solutions to this, but these come at the cost of either requiring approximate inference or being limited to Gaussian predictions. In this work, we instead propose to change how CNPs are deployed at test time, without any modifications to the model or training procedure. Instead of making predictions independently for every target point, we autoregressively define a joint predictive distribution using the chain rule of probability, taking inspiration from the neural autoregressive density estimator (NADE) literature. We show that this simple procedure allows factorised Gaussian CNPs to model highly dependent, non-Gaussian predictive distributions. Perhaps surprisingly, in an e
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30446;&#26631;&#20989;&#25968;&#30340;&#28151;&#21512;&#27169;&#31946;-&#28165;&#26224;&#32858;&#31867;&#31639;&#27861;&#65292;&#33021;&#22815;&#35299;&#20915;&#20256;&#32479;&#27169;&#31946;C&#22343;&#20540;&#32858;&#31867;&#31639;&#27861;&#22312;&#32858;&#31867;&#22823;&#23567;&#24046;&#24322;&#24040;&#22823;&#26102;&#30340;&#19981;&#24179;&#34913;&#24433;&#21709;&#38382;&#39064;&#65292;&#21516;&#26102;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#32858;&#31867;&#36136;&#37327;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.14366</link><description>&lt;p&gt;
&#28151;&#21512;&#27169;&#31946;-&#28165;&#26224;&#32858;&#31867;&#31639;&#27861;&#65306;&#29702;&#35770;&#19982;&#23454;&#39564;
&lt;/p&gt;
&lt;p&gt;
Hybrid Fuzzy-Crisp Clustering Algorithm: Theory and Experiments. (arXiv:2303.14366v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14366
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30446;&#26631;&#20989;&#25968;&#30340;&#28151;&#21512;&#27169;&#31946;-&#28165;&#26224;&#32858;&#31867;&#31639;&#27861;&#65292;&#33021;&#22815;&#35299;&#20915;&#20256;&#32479;&#27169;&#31946;C&#22343;&#20540;&#32858;&#31867;&#31639;&#27861;&#22312;&#32858;&#31867;&#22823;&#23567;&#24046;&#24322;&#24040;&#22823;&#26102;&#30340;&#19981;&#24179;&#34913;&#24433;&#21709;&#38382;&#39064;&#65292;&#21516;&#26102;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#32858;&#31867;&#36136;&#37327;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20256;&#32479;&#27169;&#31946;C&#22343;&#20540;&#32858;&#31867;&#31639;&#27861;&#20013;&#65292;&#30001;&#20110;&#38582;&#23646;&#20989;&#25968;&#22987;&#32456;&#20026;&#27491;&#65292;&#24403;&#32858;&#31867;&#22823;&#23567;&#24046;&#24322;&#24040;&#22823;&#26102;&#65292;&#20250;&#23548;&#33268;&#19981;&#24179;&#34913;&#30340;&#24433;&#21709;&#12290;&#21363;&#65292;&#19968;&#20010;&#26126;&#26174;&#26356;&#22823;&#30340;&#32858;&#31867;&#23558;&#25152;&#26377;&#20854;&#20182;&#32858;&#31867;&#22352;&#26631;&#28857;&#21560;&#24341;&#21040;&#20854;&#20013;&#24515;&#65292;&#26080;&#35770;&#23427;&#20204;&#26377;&#22810;&#36828;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38582;&#23646;&#24230;&#20989;&#25968;&#32447;&#24615;&#21644;&#20108;&#27425;&#39033;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;&#28151;&#21512;&#27169;&#31946;-&#28165;&#26224;&#32858;&#31867;&#31639;&#27861;&#12290;&#22312;&#35813;&#31639;&#27861;&#20013;&#65292;&#22914;&#26524;&#25968;&#25454;&#28857;&#36317;&#31163;&#32858;&#31867;&#20013;&#24515;&#8220;&#36275;&#22815;&#8221;&#36828;&#65292;&#21017;&#23558;&#20854;&#38582;&#23646;&#24230;&#31934;&#30830;&#22320;&#35774;&#32622;&#20026;&#38646;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#28151;&#21512;&#27169;&#31946;-&#28165;&#26224;&#32858;&#31867;&#31639;&#27861;&#21450;&#20854;&#20960;&#20309;&#35299;&#37322;&#12290;&#35813;&#31639;&#27861;&#22312;&#20108;&#21313;&#20010;&#27169;&#25311;&#30340;&#25968;&#25454;&#38598;&#21644;&#20116;&#20010;&#26469;&#33258;UCI&#25968;&#25454;&#20179;&#24211;&#30340;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#24182;&#19982;&#20256;&#32479;&#30340;&#27169;&#31946;&#21644;&#28165;&#26224;&#32858;&#31867;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#32858;&#31867;&#36136;&#37327;&#21644;&#40065;&#26834;&#24615;&#26041;&#38754;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the membership function being strictly positive, the conventional fuzzy c-means clustering method sometimes causes imbalanced influence when clusters of vastly different sizes exist. That is, an outstandingly large cluster drags to its center all the other clusters, however far they are separated. To solve this problem, we propose a hybrid fuzzy-crisp clustering algorithm based on a target function combining linear and quadratic terms of the membership function. In this algorithm, the membership of a data point to a cluster is automatically set to exactly zero if the data point is ``sufficiently'' far from the cluster center. In this paper, we present a new algorithm for hybrid fuzzy-crisp clustering along with its geometric interpretation. The algorithm is tested on twenty simulated data generated and five real-world datasets from the UCI repository and compared with conventional fuzzy and crisp clustering methods. The proposed algorithm is demonstrated to outperform the conventi
&lt;/p&gt;</description></item><item><title>repliclust &#26159;&#19968;&#20010; Python &#21253;&#65292;&#29992;&#20110;&#29983;&#25104;&#20855;&#26377;&#32858;&#31867;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#65292;&#22522;&#20110;&#25968;&#25454;&#38598;&#30340;&#21407;&#22411;&#65292;&#25552;&#20379;&#20102;&#25918;&#32622;&#38598;&#32676;&#20013;&#24515;&#12289;&#37319;&#26679;&#38598;&#32676;&#24418;&#29366;&#12289;&#36873;&#25321;&#27599;&#20010;&#38598;&#32676;&#30340;&#25968;&#25454;&#28857;&#25968;&#37327;&#20197;&#21450;&#20026;&#38598;&#32676;&#20998;&#37197;&#27010;&#29575;&#20998;&#24067;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2303.14301</link><description>&lt;p&gt;
repliclust&#65306;&#32858;&#31867;&#20998;&#26512;&#30340;&#21512;&#25104;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
repliclust: Synthetic Data for Cluster Analysis. (arXiv:2303.14301v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14301
&lt;/p&gt;
&lt;p&gt;
repliclust &#26159;&#19968;&#20010; Python &#21253;&#65292;&#29992;&#20110;&#29983;&#25104;&#20855;&#26377;&#32858;&#31867;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#65292;&#22522;&#20110;&#25968;&#25454;&#38598;&#30340;&#21407;&#22411;&#65292;&#25552;&#20379;&#20102;&#25918;&#32622;&#38598;&#32676;&#20013;&#24515;&#12289;&#37319;&#26679;&#38598;&#32676;&#24418;&#29366;&#12289;&#36873;&#25321;&#27599;&#20010;&#38598;&#32676;&#30340;&#25968;&#25454;&#28857;&#25968;&#37327;&#20197;&#21450;&#20026;&#38598;&#32676;&#20998;&#37197;&#27010;&#29575;&#20998;&#24067;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102; repliclust&#65288;&#26469;&#33258;&#20110; repli-cate &#21644; clust-er&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#29983;&#25104;&#20855;&#26377;&#32858;&#31867;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340; Python &#21253;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#25968;&#25454;&#38598;&#30340;&#21407;&#22411;&#65292;&#21363;&#39640;&#32423;&#20960;&#20309;&#25551;&#36848;&#65292;&#29992;&#25143;&#21487;&#20197;&#20174;&#20013;&#21019;&#24314;&#35768;&#22810;&#19981;&#21516;&#30340;&#25968;&#25454;&#38598;&#65292;&#24182;&#20855;&#26377;&#25152;&#38656;&#30340;&#20960;&#20309;&#29305;&#24615;&#12290;&#25105;&#20204;&#36719;&#20214;&#30340;&#26550;&#26500;&#26159;&#27169;&#22359;&#21270;&#21644;&#38754;&#21521;&#23545;&#35937;&#30340;&#65292;&#23558;&#25968;&#25454;&#29983;&#25104;&#20998;&#35299;&#25104;&#25918;&#32622;&#38598;&#32676;&#20013;&#24515;&#30340;&#31639;&#27861;&#12289;&#37319;&#26679;&#38598;&#32676;&#24418;&#29366;&#30340;&#31639;&#27861;&#12289;&#36873;&#25321;&#27599;&#20010;&#38598;&#32676;&#30340;&#25968;&#25454;&#28857;&#25968;&#37327;&#30340;&#31639;&#27861;&#20197;&#21450;&#20026;&#38598;&#32676;&#20998;&#37197;&#27010;&#29575;&#20998;&#24067;&#30340;&#31639;&#27861;&#12290;repliclust.org &#39033;&#30446;&#32593;&#39029;&#25552;&#20379;&#20102;&#31616;&#26126;&#30340;&#29992;&#25143;&#25351;&#21335;&#21644;&#20840;&#38754;&#30340;&#25991;&#26723;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present repliclust (from repli-cate and clust-er), a Python package for generating synthetic data sets with clusters. Our approach is based on data set archetypes, high-level geometric descriptions from which the user can create many different data sets, each possessing the desired geometric characteristics. The architecture of our software is modular and object-oriented, decomposing data generation into algorithms for placing cluster centers, sampling cluster shapes, selecting the number of data points for each cluster, and assigning probability distributions to clusters. The project webpage, repliclust.org, provides a concise user guide and thorough documentation.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20840;&#23616;&#20248;&#21270;&#25216;&#26415;&#65292;&#36890;&#36807;&#39044;&#23450;&#30340;&#26597;&#35810;&#21019;&#24314;&#35268;&#21017;&#23454;&#29616;&#20102;&#23545;H&#246;lder&#36830;&#32493;&#22810;&#20803;&#20989;&#25968;&#30340;&#35745;&#31639;&#20248;&#21183;&#65292;&#21487;&#22312;&#32473;&#23450;&#26102;&#38388;&#27573;&#20869;&#33719;&#24471; minimax &#26368;&#20248;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2303.14293</link><description>&lt;p&gt;
&#38024;&#23545;H&#246;lder&#36830;&#32493;&#22810;&#20803;&#20989;&#25968;&#30340;&#39640;&#25928;Lipschitzian&#20840;&#23616;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient Lipschitzian Global Optimization of H\"older Continuous Multivariate Functions. (arXiv:2303.14293v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14293
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20840;&#23616;&#20248;&#21270;&#25216;&#26415;&#65292;&#36890;&#36807;&#39044;&#23450;&#30340;&#26597;&#35810;&#21019;&#24314;&#35268;&#21017;&#23454;&#29616;&#20102;&#23545;H&#246;lder&#36830;&#32493;&#22810;&#20803;&#20989;&#25968;&#30340;&#35745;&#31639;&#20248;&#21183;&#65292;&#21487;&#22312;&#32473;&#23450;&#26102;&#38388;&#27573;&#20869;&#33719;&#24471; minimax &#26368;&#20248;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#20840;&#23616;&#20248;&#21270;&#25216;&#26415;&#65292;&#19987;&#38376;&#38024;&#23545;H&#246;lder&#36830;&#32493;&#30340;&#22810;&#20803;&#20989;&#25968;&#12290;&#19982;&#26500;&#36896;&#19979;&#30028;&#20195;&#29702;&#20989;&#25968;&#30340;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#65292;&#36825;&#20010;&#31639;&#27861;&#37319;&#29992;&#20102;&#39044;&#23450;&#30340;&#26597;&#35810;&#21019;&#24314;&#35268;&#21017;&#65292;&#20351;&#20854;&#22312;&#35745;&#31639;&#19978;&#26356;&#20855;&#20248;&#21183;&#12290;&#31639;&#27861;&#30340;&#24615;&#33021;&#20351;&#29992;&#24179;&#22343;&#25110;&#32047;&#31215;&#36951;&#25022;&#36827;&#34892;&#35780;&#20272;&#65292;&#36825;&#20063;&#24847;&#21619;&#30528;&#31616;&#21333;&#36951;&#25022;&#30340;&#30028;&#38480;&#65292;&#21453;&#26144;&#20102;&#35813;&#26041;&#27861;&#30340;&#25972;&#20307;&#26377;&#25928;&#24615;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;&#36866;&#24403;&#30340;&#21442;&#25968;&#65292;&#31639;&#27861;&#22312;&#32473;&#23450;&#26102;&#38388;&#27573;$T$&#20869;&#38024;&#23545;H&#246;lder&#36830;&#32493;&#30340;H&#246;lder&#25351;&#25968;&#20026;$\alpha$&#30340;&#30446;&#26631;&#20989;&#25968;&#22312;$n$&#32500;&#31354;&#38388;&#20013;&#33719;&#24471;&#20102;$O(T^{-\frac{\alpha}{n}})$&#30340;&#24179;&#22343;&#36951;&#25022;&#30028;&#38480;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#19968;&#30028;&#38480;&#26159;&#26497;&#23567;&#21270;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study presents an effective global optimization technique designed for multivariate functions that are H\"older continuous. Unlike traditional methods that construct lower bounding proxy functions, this algorithm employs a predetermined query creation rule that makes it computationally superior. The algorithm's performance is assessed using the average or cumulative regret, which also implies a bound for the simple regret and reflects the overall effectiveness of the approach. The results show that with appropriate parameters the algorithm attains an average regret bound of $O(T^{-\frac{\alpha}{n}})$ for optimizing a H\"older continuous target function with H\"older exponent $\alpha$ in an $n$-dimensional space within a given time horizon $T$. We demonstrate that this bound is minimax optimal.
&lt;/p&gt;</description></item><item><title>&#39640;&#26031;&#36807;&#31243;&#26159;&#19968;&#31181;&#36866;&#21512;&#25311;&#21512;&#23569;&#37327;&#25968;&#25454;&#19988;&#20805;&#20998;&#32771;&#34385;&#19981;&#30830;&#23450;&#24615;&#30340;&#27169;&#22411;&#65292;&#21487;&#29992;&#20110;&#20174;&#20998;&#23376;&#21040;&#40657;&#27934;&#31561;&#22810;&#20010;&#39046;&#22495;&#30340;&#25968;&#25454;&#39044;&#27979;&#21644;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2303.14291</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#22312;&#26497;&#31471;&#38271;&#24230;&#23610;&#24230;&#19978;&#30340;&#24212;&#29992;&#65306;&#20174;&#20998;&#23376;&#21040;&#40657;&#27934;&#12290;
&lt;/p&gt;
&lt;p&gt;
Applications of Gaussian Processes at Extreme Lengthscales: From Molecules to Black Holes. (arXiv:2303.14291v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14291
&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#26159;&#19968;&#31181;&#36866;&#21512;&#25311;&#21512;&#23569;&#37327;&#25968;&#25454;&#19988;&#20805;&#20998;&#32771;&#34385;&#19981;&#30830;&#23450;&#24615;&#30340;&#27169;&#22411;&#65292;&#21487;&#29992;&#20110;&#20174;&#20998;&#23376;&#21040;&#40657;&#27934;&#31561;&#22810;&#20010;&#39046;&#22495;&#30340;&#25968;&#25454;&#39044;&#27979;&#21644;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#35266;&#27979;&#21644;&#23454;&#39564;&#31185;&#23398;&#39046;&#22495;&#65292;&#25968;&#25454;&#38750;&#24120;&#31232;&#32570;&#12290;&#22312;&#39640;&#33021;&#22825;&#20307;&#29289;&#29702;&#23398;&#20013;&#65292;&#21463;&#21040;&#22825;&#20307;&#36974;&#25377;&#21644;&#26377;&#38480;&#30340;&#26395;&#36828;&#38236;&#26102;&#38388;&#30340;&#24433;&#21709;&#65292;&#25968;&#25454;&#35266;&#27979;&#21463;&#21040;&#24178;&#25200;&#12290;&#32780;&#22312;&#21512;&#25104;&#21270;&#23398;&#21644;&#26448;&#26009;&#31185;&#23398;&#30340;&#23454;&#39564;&#23460;&#23454;&#39564;&#20013;&#24471;&#20986;&#30340;&#25968;&#25454;&#65292;&#32791;&#26102;&#21644;&#25104;&#26412;&#37117;&#38750;&#24120;&#39640;&#26114;&#12290;&#28982;&#32780;&#65292;&#22312;&#31185;&#23398;&#39046;&#22495;&#20013;&#36890;&#24120;&#21487;&#20197;&#33719;&#24471;&#26377;&#20851;&#25968;&#25454;&#20135;&#29983;&#26426;&#21046;&#30340;&#30693;&#35782;&#65292;&#20363;&#22914;&#23454;&#39564;&#35013;&#32622;&#30340;&#27979;&#37327;&#35823;&#24046;&#31561;&#12290;&#36825;&#20004;&#20010;&#29305;&#24449;&#65292;&#21363;&#25968;&#25454;&#37327;&#23567;&#21644;&#23545;&#22522;&#26412;&#29289;&#29702;&#21407;&#29702;&#30340;&#20102;&#35299;&#65292;&#20351;&#24471;&#39640;&#26031;&#36807;&#31243;&#65288;GPs&#65289;&#25104;&#20026;&#36866;&#21512;&#25311;&#21512;&#27492;&#31867;&#25968;&#25454;&#38598;&#30340;&#29702;&#24819;&#20505;&#36873;&#12290;GPs &#33021;&#22815;&#32771;&#34385;&#21040;&#19981;&#30830;&#23450;&#24615;&#65292;&#20363;&#22914;&#22312;&#20998;&#23376;&#21644;&#26448;&#26009;&#30340;&#34394;&#25311;&#31579;&#36873;&#20013;&#36827;&#34892;&#39044;&#27979;&#65292;&#24182;&#19988;&#36824;&#21487;&#20197;&#23545;&#19981;&#23436;&#25972;&#30340;&#25968;&#25454;&#36827;&#34892;&#25512;&#26029;&#65292;&#20363;&#22914;&#20174;&#40657;&#27934;&#21560;&#31215;&#30424;&#30340;&#28508;&#22312;&#21457;&#23556;&#29305;&#24449;&#12290;&#27492;&#22806;&#65292;GPs&#30446;&#21069;&#26159;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#24037;&#20316;&#27169;&#22411;&#65292;&#36825;&#26159;&#19968;&#31181;&#39044;&#35745;&#23558;&#25104;&#20026;&#24341;&#23548;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many areas of the observational and experimental sciences data is scarce. Data observation in high-energy astrophysics is disrupted by celestial occlusions and limited telescope time while data derived from laboratory experiments in synthetic chemistry and materials science is time and cost-intensive to collect. On the other hand, knowledge about the data-generation mechanism is often available in the sciences, such as the measurement error of a piece of laboratory apparatus. Both characteristics, small data and knowledge of the underlying physics, make Gaussian processes (GPs) ideal candidates for fitting such datasets. GPs can make predictions with consideration of uncertainty, for example in the virtual screening of molecules and materials, and can also make inferences about incomplete data such as the latent emission signature from a black hole accretion disc. Furthermore, GPs are currently the workhorse model for Bayesian optimisation, a methodology foreseen to be a guide for l
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#33609;&#22270;&#30340;&#36923;&#36753;&#22238;&#24402;coreset&#26500;&#24314;&#12289;&#29305;&#24449;&#36873;&#25321;&#21644;&#38477;&#32500;&#30340;&#26032;&#30028;&#38480;&#65292;&#24182;&#35299;&#20915;&#20102;&#20043;&#21069;&#24037;&#20316;&#20013;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#21487;&#25193;&#23637;&#21040;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#21069;&#21521;&#35823;&#24046;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2303.14284</link><description>&lt;p&gt;
&#36923;&#36753;&#22238;&#24402;&#29305;&#24449;&#31354;&#38388;&#33609;&#22270;
&lt;/p&gt;
&lt;p&gt;
Feature Space Sketching for Logistic Regression. (arXiv:2303.14284v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14284
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#33609;&#22270;&#30340;&#36923;&#36753;&#22238;&#24402;coreset&#26500;&#24314;&#12289;&#29305;&#24449;&#36873;&#25321;&#21644;&#38477;&#32500;&#30340;&#26032;&#30028;&#38480;&#65292;&#24182;&#35299;&#20915;&#20102;&#20043;&#21069;&#24037;&#20316;&#20013;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#21487;&#25193;&#23637;&#21040;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#21069;&#21521;&#35823;&#24046;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#38024;&#23545;&#36923;&#36753;&#22238;&#24402;&#30340;coreset&#26500;&#24314;&#12289;&#29305;&#24449;&#36873;&#25321;&#21644;&#38477;&#32500;&#30340;&#26032;&#30028;&#38480;&#12290;&#36825;&#19977;&#31181;&#26041;&#27861;&#37117;&#21487;&#20197;&#35270;&#20026;&#36923;&#36753;&#22238;&#24402;&#36755;&#20837;&#30340;&#33609;&#22270;&#12290;&#22312;coreset&#26500;&#24314;&#26041;&#38754;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#20043;&#21069;&#24037;&#20316;&#20013;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;coreset&#26500;&#36896;&#26041;&#27861;&#30340;&#22797;&#26434;&#24230;&#26032;&#30028;&#38480;&#12290;&#22312;&#29305;&#24449;&#36873;&#25321;&#21644;&#38477;&#32500;&#26041;&#38754;&#65292;&#25105;&#20204;&#24320;&#22987;&#30740;&#31350;&#36923;&#36753;&#22238;&#24402;&#30340;&#21069;&#21521;&#35823;&#24046;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#21487;&#20197;&#25910;&#32039;&#65292;&#30452;&#21040;&#30830;&#23450;&#30340;&#22240;&#32032;&#20026;&#27490;&#65292;&#24182;&#19988;&#21069;&#21521;&#35823;&#24046;&#30028;&#38480;&#21487;&#20197;&#25193;&#23637;&#21040;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present novel bounds for coreset construction, feature selection, and dimensionality reduction for logistic regression. All three approaches can be thought of as sketching the logistic regression inputs. On the coreset construction front, we resolve open problems from prior work and present novel bounds for the complexity of coreset construction methods. On the feature selection and dimensionality reduction front, we initiate the study of forward error bounds for logistic regression. Our bounds are tight up to constant factors and our forward error bounds can be extended to Generalized Linear Models.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24207;&#21015; Knockoffs (SEEK)&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#24378;&#21270;&#23398;&#20064;&#31995;&#32479;&#20013;&#23454;&#29616;&#21464;&#37327;&#36873;&#25321;&#65292;&#35813;&#31639;&#27861;&#20272;&#35745;&#20102;&#26368;&#23567;&#20805;&#20998;&#29366;&#24577;&#65292;&#30830;&#20445;&#23398;&#20064;&#36827;&#31243;&#33391;&#22909;&#32780;&#19981;&#20250;&#20943;&#32531;&#12290;</title><link>http://arxiv.org/abs/2303.14281</link><description>&lt;p&gt;
&#22522;&#20110;&#24207;&#21015; Knockoffs &#30340;&#24378;&#21270;&#23398;&#20064;&#21464;&#37327;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Sequential Knockoffs for Variable Selection in Reinforcement Learning. (arXiv:2303.14281v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14281
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24207;&#21015; Knockoffs (SEEK)&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#24378;&#21270;&#23398;&#20064;&#31995;&#32479;&#20013;&#23454;&#29616;&#21464;&#37327;&#36873;&#25321;&#65292;&#35813;&#31639;&#27861;&#20272;&#35745;&#20102;&#26368;&#23567;&#20805;&#20998;&#29366;&#24577;&#65292;&#30830;&#20445;&#23398;&#20064;&#36827;&#31243;&#33391;&#22909;&#32780;&#19981;&#20250;&#20943;&#32531;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#30340;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#36890;&#24120;&#24456;&#38590;&#33719;&#24471;&#19968;&#20010;&#26082;&#31616;&#27905;&#21448;&#28385;&#36275;&#39532;&#23572;&#21487;&#22827;&#23646;&#24615;&#30340;&#29366;&#24577;&#34920;&#31034;&#65292;&#32780;&#19981;&#38656;&#35201;&#20351;&#29992;&#20808;&#39564;&#30693;&#35782;&#12290;&#22240;&#27492;&#65292;&#24120;&#35268;&#20570;&#27861;&#26159;&#26500;&#36896;&#19968;&#20010;&#27604;&#24517;&#35201;&#30340;&#35201;&#22823;&#30340;&#29366;&#24577;&#65292;&#20363;&#22914;&#23558;&#36830;&#32493;&#26102;&#38388;&#28857;&#19978;&#30340;&#27979;&#37327;&#20018;&#32852;&#36215;&#26469;&#12290;&#28982;&#32780;&#65292;&#22686;&#21152;&#29366;&#24577;&#30340;&#32500;&#25968;&#21487;&#33021;&#20250;&#20943;&#32531;&#23398;&#20064;&#36827;&#31243;&#24182;&#20351;&#23398;&#20064;&#31574;&#30053;&#27169;&#31946;&#19981;&#28165;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#22312;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;(MDP)&#20013;&#30340;&#26368;&#23567;&#20805;&#20998;&#29366;&#24577;&#30340;&#27010;&#24565;&#65292;&#20316;&#20026;&#21407;&#22987;&#29366;&#24577;&#19979;&#26368;&#23567;&#30340;&#23376;&#21521;&#37327;&#65292;&#20351;&#35813;&#36807;&#31243;&#20173;&#28982;&#26159;MDP&#65292;&#24182;&#19988;&#19982;&#21407;&#22987;&#36807;&#31243;&#20849;&#20139;&#30456;&#21516;&#30340;&#26368;&#20248;&#31574;&#30053;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24207;&#21015; Knockoffs (SEEK)&#31639;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#39640;&#32500;&#22797;&#26434;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#31995;&#32479;&#20013;&#30340;&#26368;&#23567;&#20805;&#20998;&#29366;&#24577;&#12290;&#22312;&#22823;&#26679;&#26412;&#20013;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#25511;&#21046;&#20102;&#20551;&#21457;&#29616;&#29575;&#65292;&#24182;&#19988;&#36873;&#25321;&#25152;&#26377;&#20805;&#20998;&#30340;&#21464;&#37327;&#30340;&#27010;&#29575;&#36235;&#36817;&#20110;1&#12290;
&lt;/p&gt;
&lt;p&gt;
In real-world applications of reinforcement learning, it is often challenging to obtain a state representation that is parsimonious and satisfies the Markov property without prior knowledge. Consequently, it is common practice to construct a state which is larger than necessary, e.g., by concatenating measurements over contiguous time points. However, needlessly increasing the dimension of the state can slow learning and obfuscate the learned policy. We introduce the notion of a minimal sufficient state in a Markov decision process (MDP) as the smallest subvector of the original state under which the process remains an MDP and shares the same optimal policy as the original process. We propose a novel sequential knockoffs (SEEK) algorithm that estimates the minimal sufficient state in a system with high-dimensional complex nonlinear dynamics. In large samples, the proposed method controls the false discovery rate, and selects all sufficient variables with probability approaching one. As
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36807;&#21442;&#25968;&#21270;&#20302;&#31209;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#36890;&#36807;&#22240;&#23376;&#21270;&#26041;&#27861;&#35757;&#32451;&#30340;&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#21487;&#20197;&#25910;&#25947;&#65292;&#24182;&#19988;&#38544;&#24335;&#24179;&#34913;&#21644;&#27491;&#21017;&#21270;&#21487;&#20197;&#20419;&#36827;&#27867;&#21270;&#12290;</title><link>http://arxiv.org/abs/2303.14244</link><description>&lt;p&gt;
&#38544;&#24335;&#24179;&#34913;&#21644;&#27491;&#21017;&#21270;&#65306;&#36807;&#21442;&#25968;&#21270;&#38750;&#23545;&#31216;&#30697;&#38453;&#24863;&#30693;&#20013;&#30340;&#27867;&#21270;&#21644;&#25910;&#25947;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Implicit Balancing and Regularization: Generalization and Convergence Guarantees for Overparameterized Asymmetric Matrix Sensing. (arXiv:2303.14244v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14244
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36807;&#21442;&#25968;&#21270;&#20302;&#31209;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#36890;&#36807;&#22240;&#23376;&#21270;&#26041;&#27861;&#35757;&#32451;&#30340;&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#21487;&#20197;&#25910;&#25947;&#65292;&#24182;&#19988;&#38544;&#24335;&#24179;&#34913;&#21644;&#27491;&#21017;&#21270;&#21487;&#20197;&#20419;&#36827;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#23545;&#20110;&#35757;&#32451;&#36807;&#21442;&#25968;&#21270;&#23398;&#20064;&#27169;&#22411;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#26041;&#27861;&#30340;&#25910;&#25947;&#21644;&#27867;&#21270;&#23646;&#24615;&#26377;&#20102;&#37325;&#35201;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#20854;&#20013;&#35768;&#22810;&#26041;&#38754;&#65292;&#21253;&#25324;&#23567;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#35282;&#33394;&#20197;&#21450;&#27169;&#22411;&#30340;&#21508;&#31181;&#21442;&#25968;&#22312;&#26799;&#24230;&#26356;&#26032;&#20013;&#22914;&#20309;&#32806;&#21512;&#20197;&#20419;&#36827;&#33391;&#22909;&#30340;&#27867;&#21270;&#65292;&#20173;&#28982;&#26159;&#24456;&#31070;&#31192;&#30340;&#12290;&#26368;&#36817;&#19968;&#31995;&#21015;&#30340;&#35770;&#25991;&#24050;&#32463;&#24320;&#22987;&#30740;&#31350;&#38750;&#20984;&#23545;&#31216;&#21322;&#27491;&#23450;&#65288;PSD&#65289;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#30340;&#24418;&#24335;&#65292;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#38656;&#35201;&#20174;&#20960;&#20010;&#32447;&#24615;&#27979;&#37327;&#20013;&#37325;&#24314;&#19968;&#20010;&#20302;&#31209;PSD&#30697;&#38453;&#12290;&#36825;&#31181;&#24213;&#23618;&#30340;&#23545;&#31216;&#24615;/PSD&#24615;&#23545;&#20110;&#29616;&#26377;&#30340;&#36825;&#20010;&#38382;&#39064;&#30340;&#25910;&#25947;&#21644;&#27867;&#21270;&#20445;&#35777;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#19968;&#33324;&#30340;&#36807;&#21442;&#25968;&#21270;&#30340;&#20302;&#31209;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#65292;&#20854;&#20013;&#24076;&#26395;&#20174;&#23569;&#37327;&#30340;&#32447;&#24615;&#27979;&#37327;&#20013;&#37325;&#24314;&#19968;&#20010;&#38750;&#23545;&#31216;&#30697;&#24418;&#20302;&#31209;&#30697;&#38453;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36890;&#36807;&#22240;&#23376;&#21270;&#26469;&#35757;&#32451;&#30340;&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#22312;&#36825;&#20010;&#38382;&#39064;&#19978;&#21487;&#20197;&#25910;&#25947;&#65292;&#32780;&#38544;&#24335;&#24179;&#34913;&#21644;&#27491;&#21017;&#21270;&#21487;&#20197;&#20419;&#36827;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, there has been significant progress in understanding the convergence and generalization properties of gradient-based methods for training overparameterized learning models. However, many aspects including the role of small random initialization and how the various parameters of the model are coupled during gradient-based updates to facilitate good generalization remain largely mysterious. A series of recent papers have begun to study this role for non-convex formulations of symmetric Positive Semi-Definite (PSD) matrix sensing problems which involve reconstructing a low-rank PSD matrix from a few linear measurements. The underlying symmetry/PSDness is crucial to existing convergence and generalization guarantees for this problem. In this paper, we study a general overparameterized low-rank matrix sensing problem where one wishes to reconstruct an asymmetric rectangular low-rank matrix from a few linear measurements. We prove that an overparameterized model trained via factori
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32452;&#21512;&#24178;&#39044;&#19979;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#26045;&#21152;&#28508;&#22312;&#32467;&#26500;&#36328;&#36234;&#21333;&#20301;&#21644;&#32452;&#21512;&#65292;&#22312;&#38477;&#20302;&#23454;&#39564;&#25968;&#37327;&#21644;&#22788;&#29702;&#28151;&#26434;&#38382;&#39064;&#26041;&#38754;&#26377;&#30528;&#33391;&#22909;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2303.14226</link><description>&lt;p&gt;
&#32452;&#21512;&#24178;&#39044;&#30340;&#22240;&#26524;&#25512;&#26029;&#26694;&#26550;:&#21512;&#25104;&#32452;&#21512;
&lt;/p&gt;
&lt;p&gt;
Synthetic Combinations: A Causal Inference Framework for Combinatorial Interventions. (arXiv:2303.14226v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14226
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32452;&#21512;&#24178;&#39044;&#19979;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#26045;&#21152;&#28508;&#22312;&#32467;&#26500;&#36328;&#36234;&#21333;&#20301;&#21644;&#32452;&#21512;&#65292;&#22312;&#38477;&#20302;&#23454;&#39564;&#25968;&#37327;&#21644;&#22788;&#29702;&#28151;&#26434;&#38382;&#39064;&#26041;&#38754;&#26377;&#30528;&#33391;&#22909;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#19968;&#20010;&#21253;&#21547;N&#20010;&#24322;&#36136;&#21333;&#20301;&#21644;p&#20010;&#24178;&#39044;&#30340;&#35774;&#32622;&#12290; &#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#23398;&#20064;&#20219;&#24847;&#32452;&#21512;&#30340;&#21333;&#20301;&#29305;&#23450;&#28508;&#22312;&#32467;&#26524;&#65292;&#21363;N&#215;2 ^ p&#20010;&#22240;&#26524;&#21442;&#25968;&#12290;&#22312;&#35768;&#22810;&#24212;&#29992;&#31243;&#24207;&#20013;&#33258;&#28982;&#20986;&#29616;&#20102;&#36873;&#25321;&#24178;&#39044;&#32452;&#21512;&#30340;&#38382;&#39064;&#65292;&#20363;&#22914;&#22240;&#23376;&#35774;&#35745;&#35797;&#39564;&#65292;&#25512;&#33616;&#24341;&#25806;(&#20363;&#22914;&#65292;&#20026;&#29992;&#25143;&#26174;&#31034;&#26368;&#22823;&#31243;&#24230;&#30340;&#21442;&#19982;&#24230;&#30340;&#19968;&#32452;&#30005;&#24433;)&#65292;&#21307;&#23398;&#20013;&#30340;&#32452;&#21512;&#30103;&#27861;&#65292;&#36873;&#25321;ML&#27169;&#22411;&#30340;&#37325;&#35201;&#29305;&#24449;&#31561;&#31561;&#12290;&#24403;N&#21644;p&#22686;&#38271;&#26102;&#65292;&#36827;&#34892;N&#215;2 ^ p&#20010;&#23454;&#39564;&#26469;&#20272;&#35745;&#21508;&#31181;&#21442;&#25968;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#32780;&#19988;&#65292;&#35266;&#27979;&#25968;&#25454;&#24456;&#21487;&#33021;&#23384;&#22312;&#28151;&#26434;&#65292;&#21363;&#21333;&#20301;&#26159;&#21542;&#22312;&#32452;&#21512;&#19979;&#20986;&#29616;&#19982;&#20854;&#22312;&#35813;&#32452;&#21512;&#19979;&#30340;&#28508;&#22312;&#32467;&#26524;&#30456;&#20851;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;&#65292;&#23427;&#22312;&#21333;&#20301;&#21644;&#32452;&#21512;&#20043;&#38388;&#37117;&#26045;&#21152;&#20102;&#28508;&#22312;&#32467;&#26500;&#12290;&#25105;&#20204;&#20551;&#35774;&#21333;&#20301;&#20043;&#38388;&#23384;&#22312;&#28508;&#22312;&#30340;&#30456;&#20284;&#24615;(&#21363;&#31867;&#20284;&#21333;&#20301;&#30340;&#28508;&#22312;&#32467;&#26524;&#26159;&#30456;&#20284;&#30340;)&#65292;&#24182;&#19988;&#32452;&#21512;&#20043;&#38388;&#20063;&#23384;&#22312;&#28508;&#22312;&#30340;&#30456;&#20284;&#24615;(&#21363;&#31867;&#20284;&#32452;&#21512;&#30340;&#25928;&#26524;&#26159;&#30456;&#20284;&#30340;)&#12290;&#25105;&#20204;&#20351;&#29992;&#23618;&#27425;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#27169;&#22411;&#26469;&#24418;&#24335;&#21270;&#36825;&#19968;&#28857;&#65292;&#35813;&#27169;&#22411;&#32852;&#21512;&#32858;&#31867;&#21333;&#20803;&#21644;&#32452;&#21512;&#65292;&#24182;&#19988;&#36275;&#22815;&#28789;&#27963;&#65292;&#21487;&#20197;&#27169;&#25311;&#36830;&#32493;&#25110;&#31163;&#25955;&#32467;&#26524;&#12290;&#25105;&#20204;&#22312;&#27169;&#25311;&#21644;&#23454;&#38469;&#25968;&#25454;&#19978;&#28436;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#24182;&#34920;&#26126;&#23427;&#21487;&#20197;&#26174;&#30528;&#20943;&#23569;&#23398;&#20064;&#22240;&#26524;&#21442;&#25968;&#25152;&#38656;&#30340;&#23454;&#39564;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a setting with $N$ heterogeneous units and $p$ interventions. Our goal is to learn unit-specific potential outcomes for any combination of these $p$ interventions, i.e., $N \times 2^p$ causal parameters. Choosing combinations of interventions is a problem that naturally arises in many applications such as factorial design experiments, recommendation engines (e.g., showing a set of movies that maximizes engagement for users), combination therapies in medicine, selecting important features for ML models, etc. Running $N \times 2^p$ experiments to estimate the various parameters is infeasible as $N$ and $p$ grow. Further, with observational data there is likely confounding, i.e., whether or not a unit is seen under a combination is correlated with its potential outcome under that combination. To address these challenges, we propose a novel model that imposes latent structure across both units and combinations. We assume latent similarity across units (i.e., the potential outco
&lt;/p&gt;</description></item><item><title>&#35813;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#26631;&#20934;&#21270;&#27969;&#30340;&#39640;&#32500;&#32437;&#21521;&#25968;&#25454;&#29983;&#25104;&#27169;&#22411;&#65292;&#33021;&#22815;&#36827;&#34892;&#22909;&#30340;&#32570;&#22833;&#25968;&#25454;&#25554;&#34917;&#25805;&#20316;&#12290;</title><link>http://arxiv.org/abs/2303.14220</link><description>&lt;p&gt;
&#20351;&#29992;&#26631;&#20934;&#21270;&#27969;&#30340;&#21464;&#20998;&#25512;&#29702;&#22788;&#29702;&#32437;&#21521;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Variational Inference for Longitudinal Data Using Normalizing Flows. (arXiv:2303.14220v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14220
&lt;/p&gt;
&lt;p&gt;
&#35813;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#26631;&#20934;&#21270;&#27969;&#30340;&#39640;&#32500;&#32437;&#21521;&#25968;&#25454;&#29983;&#25104;&#27169;&#22411;&#65292;&#33021;&#22815;&#36827;&#34892;&#22909;&#30340;&#32570;&#22833;&#25968;&#25454;&#25554;&#34917;&#25805;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#28508;&#21464;&#37327;&#29983;&#25104;&#27169;&#22411;&#65292;&#33021;&#22815;&#22788;&#29702;&#39640;&#32500;&#32437;&#21521;&#25968;&#25454;&#65292;&#24182;&#20381;&#36182;&#20110;&#21464;&#20998;&#25512;&#29702;&#12290;&#20351;&#29992;&#26631;&#20934;&#21270;&#27969;&#26469;&#23545;&#30456;&#20851;&#30340;&#28508;&#21464;&#37327;&#30340;&#26102;&#38388;&#20381;&#36182;&#20851;&#31995;&#36827;&#34892;&#24314;&#27169;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#29983;&#25104;&#23436;&#20840;&#21512;&#25104;&#30340;&#32437;&#21521;&#24207;&#21015;&#65292;&#20063;&#21487;&#20197;&#29992;&#20110;&#29983;&#25104;&#22312;&#24207;&#21015;&#20013;&#19982;&#22810;&#20010;&#25968;&#25454;&#26377;&#20851;&#30340;&#36712;&#36857;&#65292;&#24182;&#19988;&#22312;&#32570;&#22833;&#25968;&#25454;&#26041;&#38754;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#22312;6&#20010;&#19981;&#21516;&#22797;&#26434;&#24230;&#30340;&#25968;&#25454;&#38598;&#19978;&#27979;&#35797;&#20102;&#35813;&#27169;&#22411;&#65292;&#24182;&#26174;&#31034;&#20986;&#23427;&#21487;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#20284;&#28982;&#20272;&#35745;&#65292;&#20197;&#21450;&#26356;&#21487;&#38752;&#30340;&#32570;&#22833;&#25968;&#25454;&#25554;&#34917;&#12290;&#20195;&#30721;&#21487;&#22312;\url{https://github.com/clementchadebec/variational_inference_for_longitudinal_data}&#19978;&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a new latent variable generative model able to handle high dimensional longitudinal data and relying on variational inference. The time dependency between the observations of an input sequence is modelled using normalizing flows over the associated latent variables. The proposed method can be used to generate either fully synthetic longitudinal sequences or trajectories that are conditioned on several data in a sequence and demonstrates good robustness properties to missing data. We test the model on 6 datasets of different complexity and show that it can achieve better likelihood estimates than some competitors as well as more reliable missing data imputation. A code is made available at \url{https://github.com/clementchadebec/variational_inference_for_longitudinal_data}.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#24102;&#26377;&#36164;&#28304;&#32447;&#24615;&#32422;&#26463;&#30340;&#19978;&#19979;&#25991;&#24184;&#23384;&#32773;&#38382;&#39064;&#30340;&#21464;&#31181;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#31616;&#21333;&#12289;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#21516;&#26102;&#33021;&#22815;&#23454;&#29616;&#36739;&#20302;&#30340;&#21518;&#24724;&#12290;&#27492;&#22806;&#65292;&#24403;&#26576;&#20123;&#32422;&#26463;&#34987;&#36829;&#21453;&#26102;&#65292;&#31639;&#27861;&#22312;&#32479;&#35745;&#19978;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2211.07484</link><description>&lt;p&gt;
&#24102;&#35013;&#36733;&#21644;&#35206;&#30422;&#32422;&#26463;&#30340;&#19978;&#19979;&#25991;&#24184;&#23384;&#32773;&#38382;&#39064;&#65306;&#22522;&#20110;&#22238;&#24402;&#30340;&#27169;&#22359;&#21270;Lagrangian&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Contextual Bandits with Packing and Covering Constraints: A Modular Lagrangian Approach via Regression. (arXiv:2211.07484v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.07484
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#24102;&#26377;&#36164;&#28304;&#32447;&#24615;&#32422;&#26463;&#30340;&#19978;&#19979;&#25991;&#24184;&#23384;&#32773;&#38382;&#39064;&#30340;&#21464;&#31181;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#31616;&#21333;&#12289;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#21516;&#26102;&#33021;&#22815;&#23454;&#29616;&#36739;&#20302;&#30340;&#21518;&#24724;&#12290;&#27492;&#22806;&#65292;&#24403;&#26576;&#20123;&#32422;&#26463;&#34987;&#36829;&#21453;&#26102;&#65292;&#31639;&#27861;&#22312;&#32479;&#35745;&#19978;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#19968;&#31181;&#19978;&#19979;&#25991;&#24184;&#23384;&#32773;&#38382;&#39064;&#30340;&#21464;&#31181;&#65292;&#20854;&#20013;&#31639;&#27861;&#22312;&#24635;&#28040;&#36153;&#30340;&#32447;&#24615;&#32422;&#26463;&#19979;&#20351;&#29992;&#22810;&#20010;&#36164;&#28304;&#12290;&#36825;&#20010;&#38382;&#39064;&#25512;&#24191;&#20102;&#24102;&#32972;&#21253;&#30340;&#19978;&#19979;&#25991;&#24184;&#23384;&#32773;&#38382;&#39064;(CBwK)&#65292;&#20801;&#35768;&#35013;&#36733;&#21644;&#35206;&#30422;&#32422;&#26463;&#65292;&#20197;&#21450;&#27491;&#36127;&#36164;&#28304;&#28040;&#32791;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#31616;&#21333;&#12289;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#33021;&#22815;&#23454;&#29616;&#36864;&#21270;&#30340;&#21518;&#24724;&#12290;&#24403;&#26576;&#20123;&#32422;&#26463;&#34987;&#36829;&#21453;&#26102;&#65292;&#23545;&#20110;CBwK&#65292;&#23427;&#22312;&#32479;&#35745;&#19978;&#26159;&#26368;&#20248;&#30340;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22522;&#20110;LagrangianBwK(Immorlica&#31561;&#20154;&#65292;FOCS 2019)&#65292;&#36825;&#26159;&#19968;&#31181;&#38754;&#21521;CBwK&#30340;Lagrangian&#25216;&#26415;&#65292;&#20197;&#21450;SquareCB(Foster&#21644;Rakhlin&#65292;ICML 2020)&#65292;&#36825;&#26159;&#19968;&#31181;&#38754;&#21521;&#19978;&#19979;&#25991;&#24184;&#23384;&#32773;&#30340;&#22238;&#24402;&#25216;&#26415;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#21033;&#29992;&#20102;&#20004;&#31181;&#25216;&#26415;&#26412;&#36136;&#19978;&#30340;&#27169;&#22359;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a variant of contextual bandits in which the algorithm consumes multiple resources subject to linear constraints on total consumption. This problem generalizes contextual bandits with knapsacks (CBwK), allowing for packing and covering constraints, as well as positive and negative resource consumption. We present a new algorithm that is simple, computationally efficient, and admits vanishing regret. It is statistically optimal for CBwK when an algorithm must stop once some constraint is violated. Our algorithm builds on LagrangeBwK (Immorlica et al., FOCS 2019) , a Lagrangian-based technique for CBwK, and SquareCB (Foster and Rakhlin, ICML 2020), a regression-based technique for contextual bandits. Our analysis leverages the inherent modularity of both techniques.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20302;&#27425;&#22810;&#39033;&#24335;&#24352;&#37327;&#20998;&#35299;&#38382;&#39064;&#30340;&#24179;&#22343;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#21457;&#29616;&#22312;$r \ll n^{3/2}$&#26102;&#23384;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#65292;&#20294;&#24403;$r \lesssim n^2$&#26102;&#65292;&#35813;&#38382;&#39064;&#21482;&#33021;&#22312;&#21407;&#21017;&#19978;&#24674;&#22797;&#31209;-1&#20998;&#37327;&#65292;&#26159;&#19968;&#20010;&#35745;&#31639;&#22256;&#38590;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2211.05274</link><description>&lt;p&gt;
&#20302;&#27425;&#22810;&#39033;&#24335;&#24352;&#37327;&#20998;&#35299;&#30340;&#24179;&#22343;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
Average-Case Complexity of Tensor Decomposition for Low-Degree Polynomials. (arXiv:2211.05274v2 [cs.CC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.05274
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20302;&#27425;&#22810;&#39033;&#24335;&#24352;&#37327;&#20998;&#35299;&#38382;&#39064;&#30340;&#24179;&#22343;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#21457;&#29616;&#22312;$r \ll n^{3/2}$&#26102;&#23384;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#65292;&#20294;&#24403;$r \lesssim n^2$&#26102;&#65292;&#35813;&#38382;&#39064;&#21482;&#33021;&#22312;&#21407;&#21017;&#19978;&#24674;&#22797;&#31209;-1&#20998;&#37327;&#65292;&#26159;&#19968;&#20010;&#35745;&#31639;&#22256;&#38590;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20551;&#35774;&#25105;&#20204;&#32473;&#23450;&#19968;&#20010;&#30001;$r$&#20010;&#38543;&#26426;&#31209;-1&#39033;&#32452;&#25104;&#30340;$n$&#32500;&#19977;&#38454;&#23545;&#31216;&#24352;&#37327;$T \in (\mathbb{R}^n)^{\otimes 3}$&#65292;&#21017;&#24403;$r \lesssim n^2$&#26102;&#65292;&#21487;&#20197;&#22312;&#21407;&#21017;&#19978;&#24674;&#22797;&#31209;-1&#20998;&#37327;&#65292;&#20294;&#26159;&#20165;&#22312;$r \ll n^{3/2}$&#30340;&#24773;&#20917;&#19979;&#25165;&#30693;&#36947;&#23384;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#12290;&#35768;&#22810;&#39640;&#32500;&#25512;&#26029;&#20219;&#21153;&#20013;&#23384;&#22312;&#31867;&#20284;&#30340;&#8220;&#32479;&#35745;&#35745;&#31639;&#24046;&#36317;&#8221;&#65292;&#36817;&#24180;&#26469;&#65292;&#30740;&#31350;&#20154;&#21592;&#36890;&#36807;&#38024;&#23545;&#32479;&#35745;&#26597;&#35810;&#65288;SQ&#65289;&#65292;&#24179;&#26041;&#21644;&#65288;SoS&#65289;&#21644;&#20302;&#27425;&#22810;&#39033;&#24335;&#65288;LDP&#65289;&#31561;&#21463;&#38480;&#65288;&#20294;&#24378;&#22823;&#65289;&#30340;&#35745;&#31639;&#27169;&#22411;&#35777;&#26126;&#19979;&#38480;&#65292;&#20197;&#35299;&#37322;&#36825;&#20123;&#38382;&#39064;&#30340;&#35745;&#31639;&#38590;&#24230;&#12290;&#28982;&#32780;&#65292;&#22312;&#24352;&#37327;&#20998;&#35299;&#20013;&#19981;&#23384;&#22312;&#31867;&#20284;&#8220;&#26893;&#20837;&#23545;&#31354;&#8221;&#30340;&#27979;&#35797;&#38382;&#39064;&#26469;&#35299;&#37322;&#20854;&#38590;&#24230;&#65292;&#36825;&#20063;&#26159;&#30446;&#21069;&#19981;&#23384;&#22312;&#20219;&#20309;&#27492;&#31867;&#24037;&#20316;&#30340;&#21407;&#22240;&#20043;&#19968;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#38543;&#26426;&#19977;&#38454;&#24352;&#37327;&#20998;&#35299;&#27169;&#22411;&#65292;&#20854;&#20013;&#19968;&#20010;&#20998;&#37327;&#30340;&#33539;&#25968;&#30053;&#22823;&#20110;&#20854;&#20313;&#20998;&#37327;&#65288;&#20197;&#30772;&#22351;&#23545;&#31216;&#24615;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Suppose we are given an $n$-dimensional order-3 symmetric tensor $T \in (\mathbb{R}^n)^{\otimes 3}$ that is the sum of $r$ random rank-1 terms. The problem of recovering the rank-1 components is possible in principle when $r \lesssim n^2$ but polynomial-time algorithms are only known in the regime $r \ll n^{3/2}$. Similar "statistical-computational gaps" occur in many high-dimensional inference tasks, and in recent years there has been a flurry of work on explaining the apparent computational hardness in these problems by proving lower bounds against restricted (yet powerful) models of computation such as statistical queries (SQ), sum-of-squares (SoS), and low-degree polynomials (LDP). However, no such prior work exists for tensor decomposition, largely because its hardness does not appear to be explained by a "planted versus null" testing problem.  We consider a model for random order-3 tensor decomposition where one component is slightly larger in norm than the rest (to break symmetr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;$k$-DS&#32500;&#24230;&#65292;&#23436;&#20840;&#34920;&#24449;&#20102;$k$-&#21015;&#34920;&#23398;&#20064;&#24615;&#65292;&#24182;&#25351;&#20986;&#24403;&#19988;&#20165;&#24403;&#35813;&#20551;&#35774;&#31867;&#30340;$k$-DS&#32500;&#24230;&#26377;&#38480;&#65292;&#35813;&#20551;&#35774;&#31867;&#25165;$k$-&#21015;&#34920;&#21487;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2211.04956</link><description>&lt;p&gt;
&#21015;&#34920;&#21487;&#23398;&#20064;&#24615;&#30340;&#34920;&#24449;
&lt;/p&gt;
&lt;p&gt;
A Characterization of List Learnability. (arXiv:2211.04956v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.04956
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;$k$-DS&#32500;&#24230;&#65292;&#23436;&#20840;&#34920;&#24449;&#20102;$k$-&#21015;&#34920;&#23398;&#20064;&#24615;&#65292;&#24182;&#25351;&#20986;&#24403;&#19988;&#20165;&#24403;&#35813;&#20551;&#35774;&#31867;&#30340;$k$-DS&#32500;&#24230;&#26377;&#38480;&#65292;&#35813;&#20551;&#35774;&#31867;&#25165;$k$-&#21015;&#34920;&#21487;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#19968;&#20010;&#32463;&#20856;&#32467;&#26524;&#34920;&#26126;&#65292;&#20108;&#20803;&#20551;&#35774;&#31867;&#30340;PAC&#21487;&#23398;&#20064;&#24615;&#19982;VC&#32500;&#24230;&#30340;&#26377;&#38480;&#24615;&#31561;&#25928;&#12290;&#23558;&#20854;&#25193;&#23637;&#21040;&#22810;&#31867;&#21035;&#35774;&#32622;&#26159;&#19968;&#20010;&#24453;&#35299;&#20915;&#30340;&#38382;&#39064;&#65292;&#36817;&#26399;&#36890;&#36807;&#26089;&#26399;&#30001;&#20025;&#23612;&#23572;&#21644;&#27801;&#21015;&#22827;-&#26045;&#29926;&#33576;&#24341;&#20837;&#30340;DS&#32500;&#24230;&#65292;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;&#26412;&#25991;&#32771;&#34385;&#21015;&#34920;PAC&#23398;&#20064;&#65292;&#20854;&#30446;&#26631;&#26159;&#36755;&#20986;k&#20010;&#39044;&#27979;&#32467;&#26524;&#12290;&#22312;&#22810;&#31181;&#35774;&#32622;&#19979;&#24050;&#32463;&#24320;&#21457;&#20102;&#21015;&#34920;&#23398;&#20064;&#31639;&#27861;&#65292;&#20107;&#23454;&#19978;&#65292;&#22312;&#26368;&#36817;&#30340;&#22810;&#31867;&#23398;&#20064;&#30340;&#34920;&#24449;&#20013;&#65292;&#21015;&#34920;&#23398;&#20064;&#25198;&#28436;&#20102;&#37325;&#35201;&#30340;&#35282;&#33394;&#12290;&#26412;&#25991;&#26088;&#22312;&#25506;&#35752;&#20197;&#19979;&#38382;&#39064;&#65306;&#20309;&#26102;&#21487;&#20197;&#29992;&#21015;&#34920;&#23398;&#20064;&#31639;&#27861;&#23398;&#20064;&#20551;&#35774;&#31867;&#65311;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#21517;&#20026;$k$-DS&#32500;&#24230;&#30340;DS&#32500;&#24230;&#27867;&#21270;&#23436;&#20840;&#34920;&#24449;$k$-&#21015;&#34920;&#23398;&#20064;&#24615;&#12290;&#36890;&#36807;&#23545;&#22810;&#31867;&#23398;&#20064;&#30340;&#26368;&#36817;&#34920;&#24449;&#36827;&#34892;&#27867;&#21270;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#20551;&#35774;&#31867;$k$-&#21015;&#34920;&#21487;&#23398;&#20064;&#65292;&#24403;&#19988;&#20165;&#24403;...
&lt;/p&gt;
&lt;p&gt;
A classical result in learning theory shows the equivalence of PAC learnability of binary hypothesis classes and the finiteness of VC dimension. Extending this to the multiclass setting was an open problem, which was settled in a recent breakthrough result characterizing multiclass PAC learnability via the DS dimension introduced earlier by Daniely and Shalev-Shwartz. In this work we consider list PAC learning where the goal is to output a list of $k$ predictions. List learning algorithms have been developed in several settings before and indeed, list learning played an important role in the recent characterization of multiclass learnability. In this work we ask: when is it possible to $k$-list learn a hypothesis class? We completely characterize $k$-list learnability in terms of a generalization of DS dimension that we call the $k$-DS dimension. Generalizing the recent characterization of multiclass learnability, we show that a hypothesis class is $k$-list learnable if and only if the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23618;&#20869;&#27491;&#20132;&#35757;&#32451;&#30340;&#26041;&#27861;(LOT)&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#20010;&#26080;&#38480;&#21046;&#30697;&#38453;&#26469;&#21442;&#25968;&#21270;&#27491;&#20132;&#30697;&#38453;&#26469;&#26377;&#25928;&#35757;&#32451;1-Lipschitz&#21367;&#31215;&#23618;&#65292;&#24182;&#35777;&#26126;&#20102;&#21322;&#30417;&#30563;&#35757;&#32451;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#21033;&#26222;&#24076;&#33576;&#32422;&#26463;&#27169;&#22411;&#30340;&#21487;&#35777;&#26126;&#40065;&#26834;&#24615;&#12290;&#22312;&#30830;&#23450;&#24615;l2&#21487;&#35777;&#26126;&#40065;&#26834;&#24615;&#26041;&#38754;&#65292;LOT&#26174;&#33879;&#20248;&#20110;&#22522;&#32447;&#65292;&#24182;&#33021;&#22815;&#25193;&#23637;&#21040;&#26356;&#28145;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;</title><link>http://arxiv.org/abs/2210.11620</link><description>&lt;p&gt;
LOT: &#22522;&#20110;&#23618;&#20869;&#27491;&#20132;&#35757;&#32451;&#26469;&#25552;&#39640;$\ell_2$ &#20445;&#25252;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
LOT: Layer-wise Orthogonal Training on Improving $\ell_2$ Certified Robustness. (arXiv:2210.11620v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.11620
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23618;&#20869;&#27491;&#20132;&#35757;&#32451;&#30340;&#26041;&#27861;(LOT)&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#20010;&#26080;&#38480;&#21046;&#30697;&#38453;&#26469;&#21442;&#25968;&#21270;&#27491;&#20132;&#30697;&#38453;&#26469;&#26377;&#25928;&#35757;&#32451;1-Lipschitz&#21367;&#31215;&#23618;&#65292;&#24182;&#35777;&#26126;&#20102;&#21322;&#30417;&#30563;&#35757;&#32451;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#21033;&#26222;&#24076;&#33576;&#32422;&#26463;&#27169;&#22411;&#30340;&#21487;&#35777;&#26126;&#40065;&#26834;&#24615;&#12290;&#22312;&#30830;&#23450;&#24615;l2&#21487;&#35777;&#26126;&#40065;&#26834;&#24615;&#26041;&#38754;&#65292;LOT&#26174;&#33879;&#20248;&#20110;&#22522;&#32447;&#65292;&#24182;&#33021;&#22815;&#25193;&#23637;&#21040;&#26356;&#28145;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#20351;&#29992;&#21033;&#26222;&#24076;&#33576;&#32422;&#26463;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#33021;&#22815;&#22686;&#24378;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#21644;&#20854;&#20182;&#27169;&#22411;&#29305;&#24615;&#65292;&#20363;&#22914;&#31283;&#23450;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23618;&#20869;&#27491;&#20132;&#35757;&#32451;&#26041;&#27861;&#65288;LOT&#65289;&#26469;&#26377;&#25928;&#35757;&#32451;1-Lipschitz&#21367;&#31215;&#23618;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#20010;&#26080;&#38480;&#21046;&#30697;&#38453;&#26469;&#21442;&#25968;&#21270;&#19968;&#20010;&#27491;&#20132;&#30697;&#38453;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#23558;&#36755;&#20837;&#22495;&#36716;&#25442;&#20026;&#20613;&#37324;&#21494;&#39057;&#22495;&#26469;&#39640;&#25928;&#35745;&#31639;&#21367;&#31215;&#26680;&#30340;&#24179;&#26041;&#26681;&#30340;&#36870;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#30001;&#20110;&#29616;&#26377;&#30740;&#31350;&#34920;&#26126;&#21322;&#30417;&#30563;&#35757;&#32451;&#26377;&#21161;&#20110;&#25552;&#39640;&#32463;&#39564;&#19978;&#30340;&#40065;&#26834;&#24615;&#65292;&#25105;&#20204;&#26088;&#22312;&#24357;&#21512;&#24046;&#36317;&#65292;&#24182;&#35777;&#26126;&#21322;&#30417;&#30563;&#23398;&#20064;&#20063;&#20250;&#25552;&#39640;&#21033;&#26222;&#24076;&#33576;&#32422;&#26463;&#27169;&#22411;&#30340;&#21487;&#35777;&#26126;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#22312;&#19981;&#21516;&#35774;&#32622;&#19979;&#23545;LOT&#36827;&#34892;&#20102;&#20840;&#38754;&#35780;&#20272;&#65292;&#24182;&#23637;&#31034;&#20102;LOT&#22312;&#30830;&#23450;&#24615;l2&#21487;&#35777;&#26126;&#40065;&#26834;&#24615;&#26041;&#38754;&#26174;&#33879;&#20248;&#20110;&#22522;&#32447;&#65292;&#24182;&#33021;&#22815;&#25193;&#23637;&#21040;&#26356;&#28145;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#22312;&#30417;&#30563;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#21457;&#29616;&#19982;&#32431;&#30417;&#30563;&#35757;&#32451;&#30456;&#27604;&#65292;&#21322;&#30417;&#30563;&#35757;&#32451;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#20445;&#25252;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent studies show that training deep neural networks (DNNs) with Lipschitz constraints are able to enhance adversarial robustness and other model properties such as stability. In this paper, we propose a layer-wise orthogonal training method (LOT) to effectively train 1-Lipschitz convolution layers via parametrizing an orthogonal matrix with an unconstrained matrix. We then efficiently compute the inverse square root of a convolution kernel by transforming the input domain to the Fourier frequency domain. On the other hand, as existing works show that semi-supervised training helps improve empirical robustness, we aim to bridge the gap and prove that semi-supervised learning also improves the certified robustness of Lipschitz-bounded models. We conduct comprehensive evaluations for LOT under different settings. We show that LOT significantly outperforms baselines regarding deterministic l2 certified robustness, and scales to deeper neural networks. Under the supervised scenario, we i
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;Krylov-Bellman Boosting (KBB)&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#19968;&#33324;&#29366;&#24577;&#31354;&#38388;&#20013;&#36827;&#34892;&#31574;&#30053;&#35780;&#20272;&#65292;&#35813;&#31639;&#27861;&#20855;&#26377;&#36229;&#32447;&#24615;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2210.11377</link><description>&lt;p&gt;
Krylov-Bellman&#25552;&#21319;&#65306;&#22312;&#19968;&#33324;&#29366;&#24577;&#31354;&#38388;&#20013;&#36229;&#32447;&#24615;&#31574;&#30053;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Krylov-Bellman boosting: Super-linear policy evaluation in general state spaces. (arXiv:2210.11377v1 [stat.ML] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.11377
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;Krylov-Bellman Boosting (KBB)&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#19968;&#33324;&#29366;&#24577;&#31354;&#38388;&#20013;&#36827;&#34892;&#31574;&#30053;&#35780;&#20272;&#65292;&#35813;&#31639;&#27861;&#20855;&#26377;&#36229;&#32447;&#24615;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#24182;&#20998;&#26512;&#20102;Krylov-Bellman Boosting&#65288;KBB&#65289;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#19968;&#33324;&#29366;&#24577;&#31354;&#38388;&#20013;&#36827;&#34892;&#31574;&#30053;&#35780;&#20272;&#12290;&#35813;&#31639;&#27861;&#20132;&#26367;&#20351;&#29992;&#38750;&#21442;&#25968;&#22238;&#24402;&#65288;&#22914;&#25552;&#21319;&#65289;&#25311;&#21512;Bellman&#27531;&#24046;&#65292;&#24182;&#20351;&#29992;&#38543;&#30528;&#26102;&#38388;&#22686;&#38271;&#32780;&#33258;&#36866;&#24212;&#22686;&#38271;&#30340;&#29305;&#24449;&#38598;&#21512;&#24212;&#29992;&#26368;&#23567;&#20108;&#20056;&#26102;&#24207;&#24046;&#20998;&#65288;LSTD&#65289;&#36807;&#31243;&#26469;&#20272;&#35745;&#20540;&#20989;&#25968;&#12290;&#36890;&#36807;&#21033;&#29992;&#19982;Krylov&#26041;&#27861;&#30340;&#32852;&#31995;&#65292;&#25105;&#20204;&#20026;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;&#20004;&#31181;&#26377;&#21560;&#24341;&#21147;&#30340;&#20445;&#35777;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#25910;&#25947;&#30028;&#38480;&#65292;&#20801;&#35768;&#22312;&#27531;&#24046;&#25311;&#21512;&#21644;LSTD&#35745;&#31639;&#20013;&#20998;&#21035;&#36827;&#34892;&#20272;&#35745;&#35823;&#24046;&#12290;&#19982;&#25105;&#20204;&#30340;&#25968;&#20540;&#23454;&#39564;&#19968;&#33268;&#65292;&#36825;&#20010;&#30028;&#38480;&#34920;&#26126;&#25910;&#25947;&#36895;&#24230;&#21462;&#20915;&#20110;&#21463;&#38480;&#35889;&#32467;&#26500;&#65292;&#36890;&#24120;&#26159;&#36229;&#32447;&#24615;&#30340;&#12290;&#20854;&#27425;&#65292;&#36890;&#36807;&#23558;&#36825;&#20010;&#20803;&#32467;&#26524;&#19982;&#27531;&#24046;&#25311;&#21512;&#21644;LSTD&#35745;&#31639;&#30340;&#26679;&#26412;&#22823;&#23567;&#20381;&#36182;&#20445;&#35777;&#30456;&#32467;&#21512;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#20381;&#36182;&#20110;&#26679;&#26412;&#22823;&#23567;&#20197;&#21450;&#20989;&#25968;&#31867;&#22797;&#26434;&#24230;&#30340;&#20855;&#20307;&#32479;&#35745;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present and analyze the Krylov-Bellman Boosting (KBB) algorithm for policy evaluation in general state spaces. It alternates between fitting the Bellman residual using non-parametric regression (as in boosting), and estimating the value function via the least-squares temporal difference (LSTD) procedure applied with a feature set that grows adaptively over time. By exploiting the connection to Krylov methods, we equip this method with two attractive guarantees. First, we provide a general convergence bound that allows for separate estimation errors in residual fitting and LSTD computation. Consistent with our numerical experiments, this bound shows that convergence rates depend on the restricted spectral structure, and are typically super-linear. Second, by combining this meta-result with sample-size dependent guarantees for residual fitting and LSTD computation, we obtain concrete statistical guarantees that depend on the sample size along with the complexity of the function class 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31867;&#26032;&#30340;&#20449;&#24687;&#35770;&#27867;&#21270;&#30028;&#38480;&#65292;&#36890;&#36807;&#36880;&#20010;&#26679;&#26412;&#35780;&#20272;&#30340;&#26465;&#20214;&#20114;&#20449;&#24687;&#65292;&#38480;&#21046;&#32852;&#21512;&#20984;&#20989;&#25968;&#19978;&#30028;&#65292;&#19982;&#20808;&#21069;&#30340;&#30028;&#38480;&#30456;&#27604;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#26356;&#32039;&#23494;&#22320;&#21051;&#30011;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#24635;&#20307;&#25439;&#22833;&#12290;</title><link>http://arxiv.org/abs/2210.06422</link><description>&lt;p&gt;
&#20351;&#29992;&#36880;&#20010;&#26679;&#26412;&#35780;&#20272;&#30340;&#26465;&#20214;&#20114;&#20449;&#24687;&#25552;&#20986;&#19968;&#31867;&#26032;&#30340;&#27867;&#21270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
A New Family of Generalization Bounds Using Samplewise Evaluated CMI. (arXiv:2210.06422v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.06422
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31867;&#26032;&#30340;&#20449;&#24687;&#35770;&#27867;&#21270;&#30028;&#38480;&#65292;&#36890;&#36807;&#36880;&#20010;&#26679;&#26412;&#35780;&#20272;&#30340;&#26465;&#20214;&#20114;&#20449;&#24687;&#65292;&#38480;&#21046;&#32852;&#21512;&#20984;&#20989;&#25968;&#19978;&#30028;&#65292;&#19982;&#20808;&#21069;&#30340;&#30028;&#38480;&#30456;&#27604;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#26356;&#32039;&#23494;&#22320;&#21051;&#30011;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#24635;&#20307;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31867;&#26032;&#30340;&#20449;&#24687;&#35770;&#27867;&#21270;&#30028;&#38480;&#65292;&#20854;&#20013;&#36890;&#36807;&#19968;&#20010;&#32852;&#21512;&#20984;&#20989;&#25968;&#27604;&#36739;&#35757;&#32451;&#25439;&#22833;&#21644;&#24635;&#20307;&#25439;&#22833;&#12290;&#36825;&#20010;&#20989;&#25968;&#30340;&#19978;&#30028;&#36890;&#36807;&#20998;&#35299;&#12289;&#36880;&#20010;&#26679;&#26412;&#35780;&#20272;&#30340;&#26465;&#20214;&#20114;&#20449;&#24687;&#65288;CMI&#65289;&#21152;&#20197;&#38480;&#21046;&#65292;&#36825;&#26159;&#19968;&#31181;&#19982;&#25152;&#36873;&#20551;&#35774;&#20135;&#29983;&#30340;&#25439;&#22833;&#26377;&#20851;&#32780;&#19981;&#26159;&#20551;&#35774;&#26412;&#36523;&#26377;&#20851;&#30340;&#20449;&#24687;&#24230;&#37327;&#65292;&#36825;&#22312;&#22823;&#22810;&#25968;&#36817;&#20284;&#27491;&#30830;&#24615;&#65288;PAC&#65289;- &#36125;&#21494;&#26031;&#32467;&#26524;&#20013;&#24456;&#24120;&#35265;&#12290;&#36890;&#36807;&#24674;&#22797;&#21644;&#25193;&#23637;&#20043;&#21069;&#24050;&#30693;&#30340;&#20449;&#24687;&#35770;&#30028;&#38480;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#26694;&#26550;&#30340;&#26222;&#36866;&#24615;&#12290;&#27492;&#22806;&#65292;&#20351;&#29992;&#35780;&#20272;&#30340;CMI&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;Seeger&#30340;PAC-Bayesian&#30028;&#38480;&#30340;&#36880;&#20010;&#26679;&#26412;&#30340;&#24179;&#22343;&#29256;&#26412;&#65292;&#20854;&#20013;&#20984;&#20989;&#25968;&#26159;&#20108;&#20803;KL&#25955;&#24230;&#12290;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#36825;&#31181;&#26032;&#30340;&#30028;&#38480;&#27604;&#20808;&#21069;&#30340;&#30028;&#38480;&#26356;&#32039;&#23494;&#22320;&#21051;&#30011;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#24635;&#20307;&#25439;&#22833;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;&#19968;&#20123;&#36825;&#20123;&#24179;&#22343;&#30028;&#38480;&#30340;&#39640;&#27010;&#29575;&#29256;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a new family of information-theoretic generalization bounds, in which the training loss and the population loss are compared through a jointly convex function. This function is upper-bounded in terms of the disintegrated, samplewise, evaluated conditional mutual information (CMI), an information measure that depends on the losses incurred by the selected hypothesis, rather than on the hypothesis itself, as is common in probably approximately correct (PAC)-Bayesian results. We demonstrate the generality of this framework by recovering and extending previously known information-theoretic bounds. Furthermore, using the evaluated CMI, we derive a samplewise, average version of Seeger's PAC-Bayesian bound, where the convex function is the binary KL divergence. In some scenarios, this novel bound results in a tighter characterization of the population loss of deep neural networks than previous bounds. Finally, we derive high-probability versions of some of these average bounds. We
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#31561;&#21464;&#26426;&#22120;&#23398;&#20064;&#65292;&#20854;&#20013;&#20989;&#25968;&#23558;&#19982;&#26576;&#20010;&#32676;&#20316;&#29992;&#30456;&#20851;&#65292;&#20351;&#29992;&#19981;&#21487;&#32422;&#34920;&#31034;&#25110;&#19981;&#21464;&#37327;&#29702;&#35770;&#26469;&#21442;&#25968;&#21270;&#36825;&#20123;&#20989;&#25968;&#30340;&#31354;&#38388;&#12290; Malgrange&#30340;&#19968;&#33324;&#36807;&#31243;&#29992;&#26469;&#34920;&#36798;&#32676;$G$&#20316;&#29992;&#19979;&#25152;&#26377;&#22810;&#39033;&#24335;&#26144;&#23556;&#12290;</title><link>http://arxiv.org/abs/2209.14991</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#19982;&#19981;&#21464;&#37327;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Machine learning and invariant theory. (arXiv:2209.14991v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.14991
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#31561;&#21464;&#26426;&#22120;&#23398;&#20064;&#65292;&#20854;&#20013;&#20989;&#25968;&#23558;&#19982;&#26576;&#20010;&#32676;&#20316;&#29992;&#30456;&#20851;&#65292;&#20351;&#29992;&#19981;&#21487;&#32422;&#34920;&#31034;&#25110;&#19981;&#21464;&#37327;&#29702;&#35770;&#26469;&#21442;&#25968;&#21270;&#36825;&#20123;&#20989;&#25968;&#30340;&#31354;&#38388;&#12290; Malgrange&#30340;&#19968;&#33324;&#36807;&#31243;&#29992;&#26469;&#34920;&#36798;&#32676;$G$&#20316;&#29992;&#19979;&#25152;&#26377;&#22810;&#39033;&#24335;&#26144;&#23556;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29289;&#29702;&#23450;&#24459;&#30340;&#21551;&#21457;&#19979;&#65292;&#31561;&#21464;&#26426;&#22120;&#23398;&#20064;&#23558;&#23398;&#20064;&#38480;&#21046;&#22312;&#20551;&#35774;&#31354;&#38388;&#20013;&#65292;&#20854;&#20013;&#25152;&#26377;&#20989;&#25968;&#37117;&#20851;&#20110;&#26576;&#20010;&#32676;&#20316;&#29992;&#31561;&#21464;&#12290;&#36890;&#24120;&#20351;&#29992;&#19981;&#21487;&#32422;&#34920;&#31034;&#25110;&#19981;&#21464;&#37327;&#29702;&#35770;&#26469;&#21442;&#25968;&#21270;&#36825;&#20123;&#20989;&#25968;&#30340;&#31354;&#38388;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#36825;&#19968;&#20027;&#39064;&#65292;&#24182;&#35299;&#37322;&#20102;&#19968;&#20123;&#29992;&#20110;&#26126;&#30830;&#21442;&#25968;&#21270;&#31561;&#21464;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#34987;&#20351;&#29992;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#35814;&#32454;&#35828;&#26126;&#20102;Malgrange&#30340;&#19968;&#33324;&#36807;&#31243;&#65292;&#32473;&#23450;&#36739;&#22823;&#31354;&#38388;&#19978;&#19981;&#21464;&#22810;&#39033;&#24335;&#30340;&#34920;&#24449;&#65292;&#34920;&#36798;&#32676;$G$&#20316;&#29992;&#19979;&#25152;&#26377;&#22810;&#39033;&#24335;&#26144;&#23556;&#65292;&#35813;&#26041;&#27861;&#36824;&#22312;$G$&#26159;&#32039;Lie&#32676;&#30340;&#24773;&#20917;&#19979;&#21442;&#25968;&#21270;&#20102;&#20809;&#39034;&#31561;&#21464;&#26144;&#23556;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inspired by constraints from physical law, equivariant machine learning restricts the learning to a hypothesis class where all the functions are equivariant with respect to some group action. Irreducible representations or invariant theory are typically used to parameterize the space of such functions. In this article, we introduce the topic and explain a couple of methods to explicitly parameterize equivariant functions that are being used in machine learning applications. In particular, we explicate a general procedure, attributed to Malgrange, to express all polynomial maps between linear spaces that are equivariant under the action of a group $G$, given a characterization of the invariant polynomials on a bigger space. The method also parametrizes smooth equivariant maps in the case that $G$ is a compact Lie group.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24102;&#19978;&#19979;&#25991;&#30340;&#39118;&#38505;&#24863;&#30693;&#32447;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20272;&#35745;&#39118;&#38505;&#24230;&#37327;&#30340;&#32622;&#20449;&#24207;&#21015;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20048;&#35266;&#30340;UCB&#31639;&#27861;&#20197;&#23398;&#20064;&#26368;&#20339;&#30340;&#39118;&#38505;&#24863;&#30693;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2209.07154</link><description>&lt;p&gt;
&#24102;&#20984;&#25439;&#22833;&#30340;&#39118;&#38505;&#24863;&#30693;&#32447;&#24615;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
Risk-aware linear bandits with convex loss. (arXiv:2209.07154v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.07154
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24102;&#19978;&#19979;&#25991;&#30340;&#39118;&#38505;&#24863;&#30693;&#32447;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20272;&#35745;&#39118;&#38505;&#24230;&#37327;&#30340;&#32622;&#20449;&#24207;&#21015;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20048;&#35266;&#30340;UCB&#31639;&#27861;&#20197;&#23398;&#20064;&#26368;&#20339;&#30340;&#39118;&#38505;&#24863;&#30693;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#33218;&#36172;&#21338;&#26426;&#31561;&#20915;&#31574;&#38382;&#39064;&#20013;&#65292;&#20195;&#29702;&#36890;&#36807;&#20248;&#21270;&#26576;&#31181;&#21453;&#39304;&#36827;&#34892;&#39034;&#24207;&#23398;&#20064;&#12290;&#34429;&#28982;&#24179;&#22343;&#22238;&#25253;&#26631;&#20934;&#24050;&#34987;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#21453;&#26144;&#23545;&#19981;&#33391;&#32467;&#26524;&#30340;&#21388;&#24694;&#30340;&#20854;&#20182;&#24230;&#37327;&#65292;&#20363;&#22914;&#26041;&#24046;&#12289;&#26465;&#20214;&#39118;&#38505;&#20215;&#20540;&#65288;CVaR&#65289;&#65292;&#21487;&#33021;&#23545;&#20851;&#38190;&#24212;&#29992;&#65288;&#21307;&#30103;&#20445;&#20581;&#12289;&#20892;&#19994;&#65289;&#26377;&#29992;&#12290;&#22312;&#27809;&#26377;&#19978;&#19979;&#25991;&#20449;&#24687;&#30340;&#36172;&#21338;&#21453;&#39304;&#19979;&#25552;&#20986;&#20102;&#29992;&#20110;&#27492;&#31867;&#39118;&#38505;&#24863;&#30693;&#24230;&#37327;&#30340;&#31639;&#27861;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#19978;&#19979;&#25991;&#30340;&#36172;&#24466;&#65292;&#22312;&#36825;&#20123;&#36172;&#21338;&#26426;&#21453;&#39304;&#19979;&#65292;&#21487;&#20197;&#36890;&#36807;&#20984;&#25439;&#22833;&#30340;&#26368;&#23567;&#21270;&#26469;&#25552;&#21462;&#36825;&#31181;&#39118;&#38505;&#24230;&#37327;&#20316;&#20026;&#19978;&#19979;&#25991;&#30340;&#32447;&#24615;&#20989;&#25968;&#12290;&#31526;&#21512;&#27492;&#26694;&#26550;&#30340;&#20856;&#22411;&#31034;&#20363;&#26159;expectile&#24230;&#37327;&#65292;&#23427;&#26159;&#36890;&#36807;&#19981;&#23545;&#31216;&#26368;&#23567;&#20108;&#20056;&#38382;&#39064;&#30340;&#35299;&#24471;&#21040;&#30340;&#12290;&#20351;&#29992;&#21345;&#26364;&#36229;&#34701;&#21512;&#26041;&#27861;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;&#29992;&#20110;&#20272;&#35745;&#27492;&#31867;&#39118;&#38505;&#24230;&#37327;&#30340;&#32622;&#20449;&#24207;&#21015;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20048;&#35266;&#30340;UCB&#31639;&#27861;&#65292;&#20197;&#23398;&#20064;&#26368;&#20339;&#30340;&#39118;&#38505;&#24863;&#30693;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
In decision-making problems such as the multi-armed bandit, an agent learns sequentially by optimizing a certain feedback. While the mean reward criterion has been extensively studied, other measures that reflect an aversion to adverse outcomes, such as mean-variance or conditional value-at-risk (CVaR), can be of interest for critical applications (healthcare, agriculture). Algorithms have been proposed for such risk-aware measures under bandit feedback without contextual information. In this work, we study contextual bandits where such risk measures can be elicited as linear functions of the contexts through the minimization of a convex loss. A typical example that fits within this framework is the expectile measure, which is obtained as the solution of an asymmetric least-square problem. Using the method of mixtures for supermartingales, we derive confidence sequences for the estimation of such risk measures. We then propose an optimistic UCB algorithm to learn optimal risk-aware act
&lt;/p&gt;</description></item><item><title>clusterBMA&#26159;&#19968;&#31181;&#32467;&#21512;&#22810;&#20010;&#38750;&#30417;&#30563;&#32858;&#31867;&#31639;&#27861;&#32467;&#26524;&#30340;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#27861;&#65292;&#25552;&#20379;&#20102;&#32452;&#21512;&#32858;&#31867;&#32467;&#26500;&#30340;&#27010;&#29575;&#35299;&#37322;&#21644;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;&#37327;&#21270;&#12290;</title><link>http://arxiv.org/abs/2209.04117</link><description>&lt;p&gt;
clusterBMA&#65306;&#29992;&#20110;&#32858;&#31867;&#30340;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#27861;
&lt;/p&gt;
&lt;p&gt;
clusterBMA: Bayesian model averaging for clustering. (arXiv:2209.04117v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.04117
&lt;/p&gt;
&lt;p&gt;
clusterBMA&#26159;&#19968;&#31181;&#32467;&#21512;&#22810;&#20010;&#38750;&#30417;&#30563;&#32858;&#31867;&#31639;&#27861;&#32467;&#26524;&#30340;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#27861;&#65292;&#25552;&#20379;&#20102;&#32452;&#21512;&#32858;&#31867;&#32467;&#26500;&#30340;&#27010;&#29575;&#35299;&#37322;&#21644;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32452;&#21512;&#32858;&#31867;&#25991;&#29486;&#20013;&#65292;&#24050;&#32463;&#24320;&#21457;&#20102;&#21508;&#31181;&#26041;&#27861;&#26469;&#32452;&#21512;&#36328;&#22810;&#20010;&#32467;&#26524;&#38598;&#30340;&#25512;&#26029;&#65292;&#20197;&#36827;&#34892;&#38750;&#30417;&#30563;&#32858;&#31867;&#12290;&#36890;&#36807;&#20174;&#22810;&#20010;&#20505;&#36873;&#32858;&#31867;&#27169;&#22411;&#20013;&#25253;&#21578;&#21333;&#20010;&#8220;&#26368;&#20339;&#8221;&#27169;&#22411;&#30340;&#32467;&#26524;&#30340;&#26041;&#27861;&#36890;&#24120;&#24573;&#30053;&#20102;&#30001;&#27169;&#22411;&#36873;&#25321;&#24102;&#26469;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#19988;&#20250;&#20135;&#29983;&#23545;&#29305;&#23450;&#27169;&#22411;&#21644;&#21442;&#25968;&#25935;&#24863;&#30340;&#25512;&#26029;&#12290;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#65288;BMA&#65289;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#22312;&#22810;&#20010;&#27169;&#22411;&#20043;&#38388;&#32452;&#21512;&#32467;&#26524;&#65292;&#24182;&#19988;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#25552;&#20379;&#20102;&#19968;&#20123;&#26377;&#21560;&#24341;&#21147;&#30340;&#20248;&#28857;&#65292;&#21253;&#25324;&#32452;&#21512;&#32858;&#31867;&#32467;&#26500;&#30340;&#27010;&#29575;&#35299;&#37322;&#21644;&#22522;&#20110;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#30340;&#37327;&#21270;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;clusterBMA&#65292;&#19968;&#31181;&#20351;&#22810;&#20010;&#38750;&#30417;&#30563;&#32858;&#31867;&#31639;&#27861;&#30340;&#32467;&#26524;&#36827;&#34892;&#21152;&#26435;&#27169;&#22411;&#24179;&#22343;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#20351;&#29992;&#32858;&#31867;&#20869;&#37096;&#39564;&#35777;&#26631;&#20934;&#24320;&#21457;&#20102;&#21518;&#39564;&#27169;&#22411;&#27010;&#29575;&#30340;&#36817;&#20284;&#65292;&#29992;&#20110;&#21152;&#26435;&#27599;&#20010;&#27169;&#22411;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Various methods have been developed to combine inference across multiple sets of results for unsupervised clustering, within the ensemble clustering literature. The approach of reporting results from one `best' model out of several candidate clustering models generally ignores the uncertainty that arises from model selection, and results in inferences that are sensitive to the particular model and parameters chosen. Bayesian model averaging (BMA) is a popular approach for combining results across multiple models that offers some attractive benefits in this setting, including probabilistic interpretation of the combined cluster structure and quantification of model-based uncertainty.  In this work we introduce clusterBMA, a method that enables weighted model averaging across results from multiple unsupervised clustering algorithms. We use clustering internal validation criteria to develop an approximation of the posterior model probability, used for weighting the results from each model
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30830;&#23450;&#20102;&#38543;&#26426;&#29305;&#24449;&#22238;&#24402;&#27169;&#22411;&#30340;&#26368;&#20339;&#28608;&#27963;&#20989;&#25968;&#12290;&#36825;&#20123;&#20989;&#25968;&#21487;&#33021;&#26159;&#32447;&#24615;&#30340;&#12289;&#39281;&#21644;&#32447;&#24615;&#20989;&#25968;&#25110;&#22522;&#20110;Hermite&#22810;&#39033;&#24335;&#30340;&#20989;&#25968;&#12290;&#20351;&#29992;&#26368;&#20339;&#28608;&#27963;&#20989;&#25968;&#20250;&#24433;&#21709;RFR&#27169;&#22411;&#30340;&#37325;&#35201;&#29305;&#24615;&#65292;&#22914;&#21452;&#23792;&#26354;&#32447;&#21644;&#26368;&#20339;&#27491;&#21017;&#21270;&#21442;&#25968;&#19982;&#22122;&#22768;&#27700;&#24179;&#30340;&#30456;&#20851;&#24615;&#12290;</title><link>http://arxiv.org/abs/2206.01332</link><description>&lt;p&gt;
&#38543;&#26426;&#29305;&#24449;&#22238;&#24402;&#27169;&#22411;&#30340;&#26368;&#20339;&#28608;&#27963;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Optimal Activation Functions for the Random Features Regression Model. (arXiv:2206.01332v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.01332
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30830;&#23450;&#20102;&#38543;&#26426;&#29305;&#24449;&#22238;&#24402;&#27169;&#22411;&#30340;&#26368;&#20339;&#28608;&#27963;&#20989;&#25968;&#12290;&#36825;&#20123;&#20989;&#25968;&#21487;&#33021;&#26159;&#32447;&#24615;&#30340;&#12289;&#39281;&#21644;&#32447;&#24615;&#20989;&#25968;&#25110;&#22522;&#20110;Hermite&#22810;&#39033;&#24335;&#30340;&#20989;&#25968;&#12290;&#20351;&#29992;&#26368;&#20339;&#28608;&#27963;&#20989;&#25968;&#20250;&#24433;&#21709;RFR&#27169;&#22411;&#30340;&#37325;&#35201;&#29305;&#24615;&#65292;&#22914;&#21452;&#23792;&#26354;&#32447;&#21644;&#26368;&#20339;&#27491;&#21017;&#21270;&#21442;&#25968;&#19982;&#22122;&#22768;&#27700;&#24179;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#24050;&#30740;&#31350;&#20102;&#38543;&#26426;&#29305;&#24449;&#22238;&#24402;&#27169;&#22411;(RFR)&#30340;&#28176;&#36817;&#22343;&#26041;&#27979;&#35797;&#35823;&#24046;&#21644;&#28789;&#25935;&#24230;&#12290;&#25105;&#20204;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#36890;&#36807;&#19981;&#21516;&#30340;&#20989;&#25968;&#31616;&#27905;&#27010;&#24565;&#65292;&#30830;&#23450;&#20102;&#22312;&#38381;&#21512;&#24418;&#24335;&#19979;&#26497;&#23567;&#21270;RFR&#27979;&#35797;&#35823;&#24046;&#21644;&#28789;&#25935;&#24230;&#32452;&#21512;&#30340;&#28608;&#27963;&#20989;&#25968;(AF)&#26063;&#32676;&#12290;&#25105;&#20204;&#21457;&#29616;&#22312;&#26576;&#20123;&#22330;&#26223;&#19979;&#65292;&#26368;&#20339;AF&#21487;&#20197;&#26159;&#32447;&#24615;&#30340;&#12289;&#39281;&#21644;&#32447;&#24615;&#20989;&#25968;&#25110;&#22522;&#20110;Hermite&#22810;&#39033;&#24335;&#34920;&#31034;&#30340;&#20989;&#25968;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#26368;&#20339;AF&#22914;&#20309;&#24433;&#21709;RFR&#27169;&#22411;&#30340;&#37325;&#35201;&#29305;&#24615;&#65292;&#27604;&#22914;&#21452;&#23792;&#26354;&#32447;&#21644;&#20854;&#26368;&#20339;&#27491;&#21017;&#21270;&#21442;&#25968;&#19982;&#35266;&#23519;&#22122;&#22768;&#27700;&#24179;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The asymptotic mean squared test error and sensitivity of the Random Features Regression model (RFR) have been recently studied. We build on this work and identify in closed-form the family of Activation Functions (AFs) that minimize a combination of the test error and sensitivity of the RFR under different notions of functional parsimony. We find scenarios under which the optimal AFs are linear, saturated linear functions, or expressible in terms of Hermite polynomials. Finally, we show how using optimal AFs impacts well-established properties of the RFR model, such as its double descent curve, and the dependency of its optimal regularization parameter on the observation noise level.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20449;&#24687;&#35770;&#26694;&#26550;&#65292;&#20998;&#26512;&#26426;&#22120;&#23398;&#20064;&#30340;&#25968;&#25454;&#38656;&#27714;&#65292;&#30740;&#31350;&#20102;&#30001;&#20855;&#26377;ReLU&#28608;&#27963;&#21333;&#20803;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#29983;&#25104;&#30340;&#25968;&#25454;&#30340;&#23398;&#20064;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#25552;&#20986;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#36793;&#30028;&#12290;</title><link>http://arxiv.org/abs/2203.00246</link><description>&lt;p&gt;
&#30417;&#30563;&#23398;&#20064;&#30340;&#20449;&#24687;&#35770;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
An Information-Theoretic Framework for Supervised Learning. (arXiv:2203.00246v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.00246
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20449;&#24687;&#35770;&#26694;&#26550;&#65292;&#20998;&#26512;&#26426;&#22120;&#23398;&#20064;&#30340;&#25968;&#25454;&#38656;&#27714;&#65292;&#30740;&#31350;&#20102;&#30001;&#20855;&#26377;ReLU&#28608;&#27963;&#21333;&#20803;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#29983;&#25104;&#30340;&#25968;&#25454;&#30340;&#23398;&#20064;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#25552;&#20986;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27599;&#24180;&#65292;&#28145;&#24230;&#23398;&#20064;&#23637;&#31034;&#20986;&#26356;&#21152;&#26032;&#39062;&#21644;&#20248;&#31168;&#30340;&#32463;&#39564;&#32467;&#26524;&#65292;&#20854;&#20013;&#37319;&#29992;&#26356;&#28145;&#21644;&#26356;&#24191;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#21516;&#26102;&#65292;&#21033;&#29992;&#29616;&#26377;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#20998;&#26512;&#36229;&#36807;&#20004;&#23618;&#30340;&#31070;&#32463;&#32593;&#32476;&#26159;&#22256;&#38590;&#30340;&#65292;&#38500;&#38750;&#35785;&#35832;&#20110;&#35745;&#25968;&#21442;&#25968;&#25110;&#36973;&#36935;&#28145;&#24230;&#25351;&#25968;&#26679;&#26412;&#22797;&#26434;&#24230;&#36793;&#30028;&#12290;&#22240;&#27492;&#65292;&#22312;&#19981;&#21516;&#30340;&#35282;&#24230;&#19979;&#20998;&#26512;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#21487;&#33021;&#26159;&#26377;&#25104;&#26524;&#30340;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20449;&#24687;&#35770;&#26694;&#26550;&#65292;&#20855;&#26377;&#33258;&#24049;&#30340;&#36951;&#25022;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#27010;&#24565;&#65292;&#29992;&#20110;&#20998;&#26512;&#26426;&#22120;&#23398;&#20064;&#30340;&#25968;&#25454;&#38656;&#27714;&#12290;&#25105;&#20204;&#39318;&#20808;&#36890;&#36807;&#19968;&#20123;&#32463;&#20856;&#26696;&#20363;&#65292;&#20363;&#22914;&#26631;&#37327;&#20272;&#35745;&#21644;&#32447;&#24615;&#22238;&#24402;&#65292;&#20351;&#29992;&#25105;&#20204;&#30340;&#26694;&#26550;&#24314;&#31435;&#30452;&#35273;&#21644;&#20171;&#32461;&#19968;&#33324;&#25216;&#26415;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#35813;&#26694;&#26550;&#30740;&#31350;&#20102;&#30001;&#20855;&#26377;ReLU&#28608;&#27963;&#21333;&#20803;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#29983;&#25104;&#30340;&#25968;&#25454;&#30340;&#23398;&#20064;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#23545;&#20110;&#26435;&#37325;&#30340;&#29305;&#23450;&#20808;&#39564;&#20998;&#24067;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
Each year, deep learning demonstrates new and improved empirical results with deeper and wider neural networks. Meanwhile, with existing theoretical frameworks, it is difficult to analyze networks deeper than two layers without resorting to counting parameters or encountering sample complexity bounds that are exponential in depth. Perhaps it may be fruitful to try to analyze modern machine learning under a different lens. In this paper, we propose a novel information-theoretic framework with its own notions of regret and sample complexity for analyzing the data requirements of machine learning. With our framework, we first work through some classical examples such as scalar estimation and linear regression to build intuition and introduce general techniques. Then, we use the framework to study the sample complexity of learning from data generated by deep neural networks with ReLU activation units. For a particular prior distribution on weights, we establish sample complexity bounds tha
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#38543;&#26426;&#22122;&#22768;&#30340;&#22312;&#32447;&#24191;&#20041;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#30340;&#26368;&#20248;&#35299;&#65292;&#33719;&#24471;&#20102;&#25509;&#36817;&#26368;&#20248;&#30340;&#36951;&#25022;&#19978;&#38480;&#12290;&#21516;&#26102;&#65292;&#38024;&#23545;&#20855;&#26377;&#24322;&#26041;&#24046;&#22122;&#22768;&#30340;&#24191;&#20041;&#32447;&#24615;Bandits&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;FTRL&#30340;&#31639;&#27861;&#23454;&#29616;&#31532;&#19968;&#20010;&#26041;&#24046;&#24863;&#30693;&#30340;&#36951;&#25022;&#19978;&#38480;&#12290;</title><link>http://arxiv.org/abs/2202.13603</link><description>&lt;p&gt;
&#20855;&#26377;&#38543;&#26426;&#22122;&#22768;&#30340;&#22312;&#32447;&#24191;&#20041;&#32447;&#24615;&#22238;&#24402;&#30340;&#26368;&#20248;&#35299;&#21450;&#20854;&#22312;&#24322;&#26041;&#24046;Bandits&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heteroscedastic Bandits. (arXiv:2202.13603v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.13603
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#38543;&#26426;&#22122;&#22768;&#30340;&#22312;&#32447;&#24191;&#20041;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#30340;&#26368;&#20248;&#35299;&#65292;&#33719;&#24471;&#20102;&#25509;&#36817;&#26368;&#20248;&#30340;&#36951;&#25022;&#19978;&#38480;&#12290;&#21516;&#26102;&#65292;&#38024;&#23545;&#20855;&#26377;&#24322;&#26041;&#24046;&#22122;&#22768;&#30340;&#24191;&#20041;&#32447;&#24615;Bandits&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;FTRL&#30340;&#31639;&#27861;&#23454;&#29616;&#31532;&#19968;&#20010;&#26041;&#24046;&#24863;&#30693;&#30340;&#36951;&#25022;&#19978;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#38543;&#26426;&#32972;&#26223;&#19979;&#22312;&#32447;&#24191;&#20041;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#65292;&#20854;&#20013;&#26631;&#31614;&#26159;&#30001;&#21487;&#33021;&#20855;&#26377;&#26080;&#30028;&#21152;&#24615;&#22122;&#22768;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#29983;&#25104;&#30340;&#12290;&#25105;&#20204;&#23545;&#32463;&#20856;&#30340;&#36319;&#38543;&#27491;&#21017;&#21270;&#39046;&#34966;&#65288;FTRL&#65289;&#31639;&#27861;&#36827;&#34892;&#20102;&#23574;&#38160;&#30340;&#20998;&#26512;&#65292;&#20197;&#24212;&#23545;&#26631;&#31614;&#22122;&#22768;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#23545;&#20110;$\sigma$-&#23376;&#39640;&#26031;&#26631;&#31614;&#22122;&#22768;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#25552;&#20379;&#20102;&#19968;&#20010;&#36951;&#25022;&#30340;&#19978;&#38480;$O(\sigma^2 d \log T) + o(\log T)$&#65292;&#20854;&#20013;$d$&#26159;&#36755;&#20837;&#21521;&#37327;&#30340;&#32500;&#25968;, $T$ &#26159;&#24635;&#22238;&#21512;&#25968;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#38543;&#26426;&#22312;&#32447;&#32447;&#24615;&#22238;&#24402;&#30340;$\Omega(\sigma^2d\log(T/d))$&#19979;&#38480;&#65292;&#36825;&#34920;&#26126;&#25105;&#20204;&#30340;&#19978;&#38480;&#20960;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#20998;&#26512;&#25193;&#23637;&#21040;&#20102;&#26356;&#31934;&#32454;&#30340;&#20271;&#24681;&#26031;&#22374;&#22122;&#22768;&#26465;&#20214;&#12290;&#20316;&#20026;&#19968;&#20010;&#24212;&#29992;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#24322;&#26041;&#24046;&#22122;&#22768;&#30340;&#24191;&#20041;&#32447;&#24615;Bandits&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;FTRL&#30340;&#31639;&#27861;&#23454;&#29616;&#31532;&#19968;&#20010;&#26041;&#24046;&#24863;&#30693;&#30340;&#36951;&#25022;&#19978;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of online generalized linear regression in the stochastic setting, where the label is generated from a generalized linear model with possibly unbounded additive noise. We provide a sharp analysis of the classical follow-the-regularized-leader (FTRL) algorithm to cope with the label noise. More specifically, for $\sigma$-sub-Gaussian label noise, our analysis provides a regret upper bound of $O(\sigma^2 d \log T) + o(\log T)$, where $d$ is the dimension of the input vector, $T$ is the total number of rounds. We also prove a $\Omega(\sigma^2d\log(T/d))$ lower bound for stochastic online linear regression, which indicates that our upper bound is nearly optimal. In addition, we extend our analysis to a more refined Bernstein noise condition. As an application, we study generalized linear bandits with heteroscedastic noise and propose an algorithm based on FTRL to achieve the first variance-aware regret bound.
&lt;/p&gt;</description></item><item><title>PGMax&#26159;&#19968;&#20010;&#29992;&#20110;&#31163;&#25955;&#27010;&#29575;&#22270;&#27169;&#22411;&#30340;&#22240;&#23376;&#22270;&#24037;&#20855;&#65292;&#21487;&#20197;&#22312;JAX&#20013;&#33258;&#21160;&#36816;&#34892;&#39640;&#25928;&#19988;&#21487;&#25193;&#23637;&#30340;&#24490;&#29615;&#32622;&#20449;&#20256;&#25773;&#65292;&#19982;&#29616;&#26377;&#26367;&#20195;&#26041;&#26696;&#30456;&#27604;&#65292;PGMax&#33719;&#24471;&#20102;&#26356;&#39640;&#36136;&#37327;&#30340;&#25512;&#29702;&#32467;&#26524;&#65292;&#25512;&#29702;&#26102;&#38388;&#21152;&#36895;&#39640;&#36798;&#19977;&#20010;&#25968;&#37327;&#32423;&#12290;</title><link>http://arxiv.org/abs/2202.04110</link><description>&lt;p&gt;
PGMax: &#29992;&#20110;&#31163;&#25955;&#27010;&#29575;&#22270;&#27169;&#22411;&#21644;JAX&#20013;&#30340;&#24490;&#29615;&#32622;&#20449;&#20256;&#25773;&#30340;&#22240;&#23376;&#22270;
&lt;/p&gt;
&lt;p&gt;
PGMax: Factor Graphs for Discrete Probabilistic Graphical Models and Loopy Belief Propagation in JAX. (arXiv:2202.04110v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.04110
&lt;/p&gt;
&lt;p&gt;
PGMax&#26159;&#19968;&#20010;&#29992;&#20110;&#31163;&#25955;&#27010;&#29575;&#22270;&#27169;&#22411;&#30340;&#22240;&#23376;&#22270;&#24037;&#20855;&#65292;&#21487;&#20197;&#22312;JAX&#20013;&#33258;&#21160;&#36816;&#34892;&#39640;&#25928;&#19988;&#21487;&#25193;&#23637;&#30340;&#24490;&#29615;&#32622;&#20449;&#20256;&#25773;&#65292;&#19982;&#29616;&#26377;&#26367;&#20195;&#26041;&#26696;&#30456;&#27604;&#65292;PGMax&#33719;&#24471;&#20102;&#26356;&#39640;&#36136;&#37327;&#30340;&#25512;&#29702;&#32467;&#26524;&#65292;&#25512;&#29702;&#26102;&#38388;&#21152;&#36895;&#39640;&#36798;&#19977;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;
PGMax is a factor graph tool for discrete probabilistic graphical models that automatically runs efficient and scalable loopy belief propagation in JAX. Compared with existing alternatives, PGMax obtains higher-quality inference results with up to three orders-of-magnitude inference time speedups.
&lt;/p&gt;
&lt;p&gt;
PGMax&#26159;&#19968;&#20010;&#24320;&#28304;&#30340;Python&#21253;&#65292;&#29992;&#20110;&#36731;&#26494;&#25351;&#23450;&#31163;&#25955;&#27010;&#29575;&#22270;&#27169;&#22411;&#65288;PGMs&#65289;&#20316;&#20026;&#22240;&#23376;&#22270;&#65292;&#24182;&#22312;JAX&#20013;&#33258;&#21160;&#36816;&#34892;&#39640;&#25928;&#19988;&#21487;&#25193;&#23637;&#30340;&#24490;&#29615;&#32622;&#20449;&#20256;&#25773;&#65288;LBP&#65289;&#12290;PGMax&#25903;&#25345;&#20855;&#26377;&#21487;&#22788;&#29702;&#22240;&#23376;&#30340;&#19968;&#33324;&#22240;&#23376;&#22270;&#65292;&#24182;&#21033;&#29992;&#29616;&#20195;&#21152;&#36895;&#22120;&#65288;&#22914;GPU&#65289;&#36827;&#34892;&#25512;&#29702;&#12290;&#19982;&#29616;&#26377;&#26367;&#20195;&#26041;&#26696;&#30456;&#27604;&#65292;PGMax&#33719;&#24471;&#20102;&#26356;&#39640;&#36136;&#37327;&#30340;&#25512;&#29702;&#32467;&#26524;&#65292;&#25512;&#29702;&#26102;&#38388;&#21152;&#36895;&#39640;&#36798;&#19977;&#20010;&#25968;&#37327;&#32423;&#12290;PGMax&#36824;&#19982;&#24555;&#36895;&#22686;&#38271;&#30340;JAX&#29983;&#24577;&#31995;&#32479;&#26080;&#32541;&#20132;&#20114;&#65292;&#24320;&#21551;&#20102;&#26032;&#30340;&#30740;&#31350;&#21487;&#33021;&#24615;&#12290;&#25105;&#20204;&#30340;&#28304;&#20195;&#30721;&#12289;&#31034;&#20363;&#21644;&#25991;&#26723;&#21487;&#22312;https://github.com/deepmind/PGMax&#19978;&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
PGMax is an open-source Python package for (a) easily specifying discrete Probabilistic Graphical Models (PGMs) as factor graphs; and (b) automatically running efficient and scalable loopy belief propagation (LBP) in JAX. PGMax supports general factor graphs with tractable factors, and leverages modern accelerators like GPUs for inference. Compared with existing alternatives, PGMax obtains higher-quality inference results with up to three orders-of-magnitude inference time speedups. PGMax additionally interacts seamlessly with the rapidly growing JAX ecosystem, opening up new research possibilities. Our source code, examples and documentation are available at https://github.com/deepmind/PGMax.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21457;&#29616;&#65292;&#22312;&#19968;&#20123;&#30446;&#26631;&#20989;&#25968;&#20013;&#65292;&#25239;&#30456;&#20851;&#22122;&#22768;&#30340;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#27604;&#20256;&#32479;&#30340;&#26799;&#24230;&#19979;&#38477;&#21644;&#24120;&#35268;&#25200;&#21160;&#26799;&#24230;&#19979;&#38477;&#26377;&#26356;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#29702;&#35770;&#20998;&#26512;&#35777;&#26126;&#20102;&#36825;&#26159;&#22240;&#20026; Anti-PGD &#33021;&#22815;&#31227;&#21160;&#21040;&#26356;&#23485;&#30340;&#26368;&#23567;&#20540;&#28857;&#65292;&#32780; GD &#21644; PGD &#20250;&#20572;&#28382;&#22312;&#27425;&#20248;&#21306;&#22495;&#29978;&#33267;&#21457;&#25955;&#12290;</title><link>http://arxiv.org/abs/2202.02831</link><description>&lt;p&gt;
&#25239;&#30456;&#20851;&#22122;&#22768;&#27880;&#20837;&#29992;&#20110;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Anticorrelated Noise Injection for Improved Generalization. (arXiv:2202.02831v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.02831
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21457;&#29616;&#65292;&#22312;&#19968;&#20123;&#30446;&#26631;&#20989;&#25968;&#20013;&#65292;&#25239;&#30456;&#20851;&#22122;&#22768;&#30340;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#27604;&#20256;&#32479;&#30340;&#26799;&#24230;&#19979;&#38477;&#21644;&#24120;&#35268;&#25200;&#21160;&#26799;&#24230;&#19979;&#38477;&#26377;&#26356;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#29702;&#35770;&#20998;&#26512;&#35777;&#26126;&#20102;&#36825;&#26159;&#22240;&#20026; Anti-PGD &#33021;&#22815;&#31227;&#21160;&#21040;&#26356;&#23485;&#30340;&#26368;&#23567;&#20540;&#28857;&#65292;&#32780; GD &#21644; PGD &#20250;&#20572;&#28382;&#22312;&#27425;&#20248;&#21306;&#22495;&#29978;&#33267;&#21457;&#25955;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#20154;&#24037;&#22122;&#22768;&#27880;&#20837;&#26799;&#24230;&#19979;&#38477;&#24120;&#24120;&#34987;&#29992;&#20110;&#25913;&#21892;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#36890;&#24120;&#65292;&#36825;&#31181;&#25200;&#21160;&#30340;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#20351;&#29992;&#30340;&#26159;&#19981;&#30456;&#20851;&#30340;&#22122;&#22768;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23578;&#19981;&#28165;&#26970;&#26159;&#21542;&#20351;&#29992;&#19981;&#21516;&#31867;&#22411;&#30340;&#22122;&#22768;&#33021;&#22815;&#25552;&#20379;&#26356;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#26412;&#25991;&#32858;&#28966;&#20110;&#30456;&#20851;&#30340;&#25200;&#21160;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#21508;&#31181;&#30446;&#26631;&#20989;&#25968;&#65292;&#21457;&#29616;&#24102;&#26377;&#25239;&#30456;&#20851;&#25200;&#21160;&#30340;&#26799;&#24230;&#19979;&#38477;&#65288;"Anti-PGD"&#65289;&#27604;&#20256;&#32479;&#30340;&#26799;&#24230;&#19979;&#38477;&#21644;&#24120;&#35268;&#30340;&#65288;&#19981;&#30456;&#20851;&#30340;&#65289;&#25200;&#21160;&#26799;&#24230;&#19979;&#38477;&#26377;&#30528;&#26356;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#20026;&#20102;&#25903;&#25345;&#36825;&#20123;&#23454;&#39564;&#32467;&#26524;&#65292;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102; Anti-PGD &#33021;&#22815;&#31227;&#21160;&#21040;&#26356;&#23485;&#30340;&#26368;&#23567;&#20540;&#28857;&#65292;&#32780; GD &#21644; PGD &#20250;&#20572;&#28382;&#22312;&#27425;&#20248;&#21306;&#22495;&#29978;&#33267;&#21457;&#25955;&#12290;&#36825;&#19968;&#26032;&#39062;&#30340;&#25239;&#30456;&#20851;&#22122;&#22768;&#19982;&#27867;&#21270;&#24615;&#33021;&#30340;&#32852;&#31995;&#20026;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#25552;&#20379;&#20102;&#26032;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Injecting artificial noise into gradient descent (GD) is commonly employed to improve the performance of machine learning models. Usually, uncorrelated noise is used in such perturbed gradient descent (PGD) methods. It is, however, not known if this is optimal or whether other types of noise could provide better generalization performance. In this paper, we zoom in on the problem of correlating the perturbations of consecutive PGD steps. We consider a variety of objective functions for which we find that GD with anticorrelated perturbations ("Anti-PGD") generalizes significantly better than GD and standard (uncorrelated) PGD. To support these experimental findings, we also derive a theoretical analysis that demonstrates that Anti-PGD moves to wider minima, while GD and PGD remain stuck in suboptimal regions or even diverge. This new connection between anticorrelated noise and generalization opens the field to novel ways to exploit noise for training machine learning models.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#22810;&#31867;&#36923;&#36753;&#22238;&#24402;&#30340;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#26041;&#27861;&#65292;&#22312;&#28145;&#24230;&#22270;&#20687;&#20998;&#31867;&#22120;&#20013;&#24471;&#21040;&#20102;&#24212;&#29992;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20351;&#22270;&#20687;&#20998;&#31867;&#22120;&#23545;&#38543;&#26426;&#21644;&#23545;&#25239;&#25915;&#20987;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#22312;&#20351;&#29992;MNIST&#21644;CIFAR-10&#25968;&#25454;&#38598;&#26102;&#65292;&#30456;&#27604;&#20110;&#22522;&#20934;&#26041;&#27861;&#65292;&#36890;&#36807;&#37319;&#29992;&#26032;&#30340;&#38543;&#26426;&#35757;&#32451;&#26041;&#27861;&#65292;&#27979;&#35797;&#38169;&#35823;&#29575;&#30340;&#38477;&#20302;&#39640;&#36798;83.5%&#65292;&#25439;&#22833;&#38477;&#20302;&#39640;&#36798;91.3%&#12290;</title><link>http://arxiv.org/abs/2109.12772</link><description>&lt;p&gt;
&#20998;&#24067;&#40065;&#26834;&#30340;&#22810;&#31867;&#20998;&#31867;&#21450;&#20854;&#22312;&#28145;&#24230;&#22270;&#20687;&#20998;&#31867;&#22120;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Distributionally Robust Multiclass Classification and Applications in Deep Image Classifiers. (arXiv:2109.12772v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.12772
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#22810;&#31867;&#36923;&#36753;&#22238;&#24402;&#30340;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#26041;&#27861;&#65292;&#22312;&#28145;&#24230;&#22270;&#20687;&#20998;&#31867;&#22120;&#20013;&#24471;&#21040;&#20102;&#24212;&#29992;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20351;&#22270;&#20687;&#20998;&#31867;&#22120;&#23545;&#38543;&#26426;&#21644;&#23545;&#25239;&#25915;&#20987;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#22312;&#20351;&#29992;MNIST&#21644;CIFAR-10&#25968;&#25454;&#38598;&#26102;&#65292;&#30456;&#27604;&#20110;&#22522;&#20934;&#26041;&#27861;&#65292;&#36890;&#36807;&#37319;&#29992;&#26032;&#30340;&#38543;&#26426;&#35757;&#32451;&#26041;&#27861;&#65292;&#27979;&#35797;&#38169;&#35823;&#29575;&#30340;&#38477;&#20302;&#39640;&#36798;83.5%&#65292;&#25439;&#22833;&#38477;&#20302;&#39640;&#36798;91.3%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#22810;&#31867;&#36923;&#36753;&#22238;&#24402;&#30340;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;DRO&#65289;&#26041;&#27861;&#65292;&#21487;&#20197;&#23481;&#24525;&#25968;&#25454;&#21463;&#21040;&#31163;&#32676;&#20540;&#30340;&#24178;&#25200;&#12290;&#35813;DRO&#26694;&#26550;&#20351;&#29992;&#20855;&#26377;&#25509;&#36817;Wasserstein&#36317;&#31163;&#24847;&#20041;&#19979;&#30340;&#32463;&#39564;&#20998;&#24067;&#30340;&#20998;&#24067;&#29699;&#30340;&#27010;&#29575;&#27169;&#31946;&#38598;&#26469;&#23450;&#20041;&#12290;&#25105;&#20204;&#23558;DRO&#24418;&#24335;&#21270;&#31616;&#20026;&#19968;&#20010;&#27491;&#21017;&#21270;&#30340;&#23398;&#20064;&#38382;&#39064;&#65292;&#20854;&#20013;&#27491;&#21017;&#21270;&#39033;&#26159;&#31995;&#25968;&#30697;&#38453;&#30340;&#33539;&#25968;&#12290;&#25105;&#20204;&#20026;&#25105;&#20204;&#27169;&#22411;&#30340;&#35299;&#20915;&#26041;&#26696;&#24314;&#31435;&#20102;&#26679;&#22806;&#24615;&#33021;&#20445;&#35777;&#65292;&#20026;&#25105;&#20204;&#25511;&#21046;&#39044;&#27979;&#35823;&#24046;&#30340;&#27491;&#21017;&#21270;&#22120;&#30340;&#20316;&#29992;&#25552;&#20379;&#20102;&#35265;&#35299;&#12290;&#25105;&#20204;&#23558;&#25552;&#20986;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#20351;&#22522;&#20110;&#28145;&#24230;Vision Transformer&#65288;ViT&#65289;&#30340;&#22270;&#20687;&#20998;&#31867;&#22120;&#23545;&#38543;&#26426;&#21644;&#23545;&#25239;&#25915;&#20987;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20351;&#29992;MNIST&#21644;CIFAR-10&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#37319;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#38543;&#26426;&#35757;&#32451;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#27979;&#35797;&#38169;&#35823;&#29575;&#38477;&#20302;&#20102;&#39640;&#36798;83.5%&#65292;&#25439;&#22833;&#38477;&#20302;&#20102;&#39640;&#36798;91.3%&#19982;&#22522;&#32447;&#26041;&#27861;&#30456;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a Distributionally Robust Optimization (DRO) formulation for Multiclass Logistic Regression (MLR), which could tolerate data contaminated by outliers. The DRO framework uses a probabilistic ambiguity set defined as a ball of distributions that are close to the empirical distribution of the training set in the sense of the Wasserstein metric. We relax the DRO formulation into a regularized learning problem whose regularizer is a norm of the coefficient matrix. We establish out-of-sample performance guarantees for the solutions to our model, offering insights on the role of the regularizer in controlling the prediction error. We apply the proposed method in rendering deep Vision Transformer (ViT)-based image classifiers robust to random and adversarial attacks. Specifically, using the MNIST and CIFAR-10 datasets, we demonstrate reductions in test error rate by up to 83.5% and loss by up to 91.3% compared with baseline methods, by adopting a novel random training method.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#30697;&#38453;&#20998;&#35299;&#26469;&#36827;&#34892;&#30697;&#38453;&#35745;&#31639;&#30340;&#26041;&#24046;&#32553;&#20943;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#26576;&#20123;&#38382;&#39064;&#19978;&#21487;&#20197;&#23454;&#29616;&#20219;&#24847;&#26356;&#22909;&#30340;&#38543;&#26426;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#25552;&#20986;&#30340;&#30697;&#38453;&#20056;&#31215;&#36857;&#30340;&#20998;&#35299;&#20272;&#35745;&#22120;&#19982;&#23545;&#21322;&#27491;&#23450;&#30697;&#38453;&#34892;&#21015;&#24335;&#30340;&#23545;&#25968;&#20272;&#35745;&#22120;&#22343;&#26377;&#26174;&#33879;&#30340;&#25928;&#29575;&#25552;&#39640;&#65292;&#21487;&#20197;&#22312;&#23454;&#38469;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#38382;&#39064;&#20013;&#24471;&#21040;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2106.14565</link><description>&lt;p&gt;
&#30697;&#38453;&#35745;&#31639;&#30340;&#26041;&#24046;&#32553;&#20943;&#21450;&#20854;&#22312;&#39640;&#26031;&#36807;&#31243;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Variance Reduction for Matrix Computations with Applications to Gaussian Processes. (arXiv:2106.14565v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.14565
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#30697;&#38453;&#20998;&#35299;&#26469;&#36827;&#34892;&#30697;&#38453;&#35745;&#31639;&#30340;&#26041;&#24046;&#32553;&#20943;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#26576;&#20123;&#38382;&#39064;&#19978;&#21487;&#20197;&#23454;&#29616;&#20219;&#24847;&#26356;&#22909;&#30340;&#38543;&#26426;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#25552;&#20986;&#30340;&#30697;&#38453;&#20056;&#31215;&#36857;&#30340;&#20998;&#35299;&#20272;&#35745;&#22120;&#19982;&#23545;&#21322;&#27491;&#23450;&#30697;&#38453;&#34892;&#21015;&#24335;&#30340;&#23545;&#25968;&#20272;&#35745;&#22120;&#22343;&#26377;&#26174;&#33879;&#30340;&#25928;&#29575;&#25552;&#39640;&#65292;&#21487;&#20197;&#22312;&#23454;&#38469;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#38382;&#39064;&#20013;&#24471;&#21040;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#35745;&#31639;&#36895;&#24230;&#21644;&#20869;&#23384;&#23481;&#37327;&#30340;&#19981;&#26029;&#25552;&#39640;&#65292;&#26041;&#27861;&#23398;&#19978;&#30340;&#36827;&#27493;&#20063;&#20026;&#38543;&#26426;&#27169;&#25311;&#30340;&#24615;&#33021;&#24102;&#26469;&#20102;&#26174;&#33879;&#25552;&#39640;&#12290;&#26412;&#25991;&#32858;&#28966;&#20110;&#36890;&#36807;&#30697;&#38453;&#20998;&#35299;&#26469;&#36827;&#34892;&#30697;&#38453;&#35745;&#31639;&#30340;&#26041;&#24046;&#32553;&#20943;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29616;&#26377;&#26041;&#24046;&#32553;&#20943;&#26041;&#27861;&#22312;&#20272;&#35745;&#22823;&#22411;&#30697;&#38453;&#20803;&#32032;&#26102;&#26410;&#33021;&#21033;&#29992;&#30697;&#38453;&#20998;&#35299;&#25152;&#24102;&#26469;&#30340;&#26041;&#24046;&#32553;&#20943;&#65292;&#32780;&#22914;&#20309;&#36890;&#36807;&#35745;&#31639;&#30697;&#38453;&#30340;&#24179;&#26041;&#26681;&#20998;&#35299;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#33021;&#22815;&#23454;&#29616;&#20219;&#24847;&#26356;&#22909;&#30340;&#38543;&#26426;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#30697;&#38453;&#20056;&#31215;&#36857;&#30340;&#20998;&#35299;&#20272;&#35745;&#22120;&#65292;&#24182;&#22312;&#25968;&#20540;&#19978;&#35777;&#26126;&#65292;&#22312;&#26576;&#20123;&#39640;&#26031;&#36807;&#31243;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#20272;&#35745;&#30340;&#38382;&#39064;&#19978;&#65292;&#35813;&#20272;&#35745;&#22120;&#30340;&#25928;&#29575;&#21487;&#20197;&#25552;&#39640;1000&#20493;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#23545;&#21322;&#27491;&#23450;&#30697;&#38453;&#34892;&#21015;&#24335;&#30340;&#23545;&#25968;&#20272;&#35745;&#22120;&#65292;&#20854;&#26041;&#24046;&#27604;&#25991;&#29486;&#20013;&#20351;&#29992;&#30340;&#26631;&#20934;&#20272;&#35745;&#22120;&#24555;&#36895;&#34928;&#20943;&#12290;&#25105;&#20204;&#22312;&#23454;&#38469;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#38382;&#39064;&#20013;&#35828;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In addition to recent developments in computing speed and memory, methodological advances have contributed to significant gains in the performance of stochastic simulation. In this paper, we focus on variance reduction for matrix computations via matrix factorization. We provide insights into existing variance reduction methods for estimating the entries of large matrices. Popular methods do not exploit the reduction in variance that is possible when the matrix is factorized. We show how computing the square root factorization of the matrix can achieve in some important cases arbitrarily better stochastic performance. In addition, we propose a factorized estimator for the trace of a product of matrices and numerically demonstrate that the estimator can be up to 1,000 times more efficient on certain problems of estimating the log-likelihood of a Gaussian process. Additionally, we provide a new estimator of the log-determinant of a positive semi-definite matrix where the log-determinant 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#20272;&#35745;&#30830;&#23450;&#24615;&#22270;&#20687;&#20998;&#31867;&#22120;&#22312;&#32473;&#23450;&#36755;&#20837;&#25968;&#25454;&#19978;&#32467;&#26524;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#23450;&#20041;&#20102;&#24800;&#28789;&#39039;&#21518;&#39564;&#20316;&#20026;&#20998;&#24067;&#20197;&#34920;&#26126;&#21487;&#33021;&#30001;&#29983;&#25104;&#32473;&#23450;&#22270;&#20687;&#30340;&#30456;&#21516;&#22330;&#26223;&#29983;&#25104;&#30340;&#25968;&#25454;&#30340;&#21709;&#24212;&#12290;</title><link>http://arxiv.org/abs/2106.13870</link><description>&lt;p&gt;
&#22330;&#26223;&#19981;&#30830;&#23450;&#24615;&#19982;&#30830;&#23450;&#24615;&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#24800;&#28789;&#39039;&#21518;&#39564;
&lt;/p&gt;
&lt;p&gt;
Scene Uncertainty and the Wellington Posterior of Deterministic Image Classifiers. (arXiv:2106.13870v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.13870
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#20272;&#35745;&#30830;&#23450;&#24615;&#22270;&#20687;&#20998;&#31867;&#22120;&#22312;&#32473;&#23450;&#36755;&#20837;&#25968;&#25454;&#19978;&#32467;&#26524;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#23450;&#20041;&#20102;&#24800;&#28789;&#39039;&#21518;&#39564;&#20316;&#20026;&#20998;&#24067;&#20197;&#34920;&#26126;&#21487;&#33021;&#30001;&#29983;&#25104;&#32473;&#23450;&#22270;&#20687;&#30340;&#30456;&#21516;&#22330;&#26223;&#29983;&#25104;&#30340;&#25968;&#25454;&#30340;&#21709;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#20272;&#35745;&#22312;&#32473;&#23450;&#36755;&#20837;&#25968;&#25454;&#19978;&#22270;&#20687;&#20998;&#31867;&#22120;&#32467;&#26524;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#29992;&#20110;&#22270;&#20687;&#20998;&#31867;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26159;&#20174;&#36755;&#20837;&#22270;&#20687;&#21040;&#36755;&#20986;&#31867;&#21035;&#30340;&#30830;&#23450;&#24615;&#26144;&#23556;&#12290;&#22240;&#27492;&#65292;&#23427;&#20204;&#22312;&#32473;&#23450;&#25968;&#25454;&#19978;&#30340;&#32467;&#26524;&#19981;&#28041;&#21450;&#19981;&#30830;&#23450;&#24615;&#65292;&#22240;&#27492;&#24517;&#39035;&#22312;&#23450;&#20041;&#12289;&#27979;&#37327;&#21644;&#35299;&#37322;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#23558;&#8220;&#32622;&#20449;&#24230;&#8221;&#24402;&#22240;&#20110;&#32467;&#26524;&#26102;&#25351;&#23450;&#25152;&#24341;&#29992;&#30340;&#21464;&#21270;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#24800;&#28789;&#39039;&#21518;&#39564;&#65292;&#23427;&#26159;&#22312;&#21487;&#33021;&#30001;&#29983;&#25104;&#32473;&#23450;&#22270;&#20687;&#30340;&#30456;&#21516;&#22330;&#26223;&#29983;&#25104;&#30340;&#25968;&#25454;&#30340;&#21709;&#24212;&#20013;&#33719;&#24471;&#30340;&#32467;&#26524;&#20998;&#24067;&#12290;&#30001;&#20110;&#21487;&#20197;&#29983;&#25104;&#20219;&#20309;&#32473;&#23450;&#22270;&#20687;&#30340;&#26080;&#38480;&#22810;&#20010;&#22330;&#26223;&#65292;&#22240;&#27492;&#24800;&#28789;&#39039;&#21518;&#39564;&#28041;&#21450;&#26469;&#33258;&#38500;&#25152;&#25551;&#32472;&#30340;&#22330;&#26223;&#20043;&#22806;&#30340;&#22330;&#26223;&#30340;&#24402;&#32435;&#20256;&#36882;&#12290;&#25105;&#20204;&#25506;&#32034;&#20102;&#20351;&#29992;&#25968;&#25454;&#22686;&#24378;&#12289;&#20002;&#24323;&#12289;&#38598;&#25104;&#12289;&#21333;&#35270;&#22270;&#37325;&#24314;&#21644;&#27169;&#22411;&#32447;&#24615;&#21270;&#26469;&#35745;&#31639;&#24800;&#28789;&#39039;&#21518;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a method to estimate the uncertainty of the outcome of an image classifier on a given input datum. Deep neural networks commonly used for image classification are deterministic maps from an input image to an output class. As such, their outcome on a given datum involves no uncertainty, so we must specify what variability we are referring to when defining, measuring and interpreting uncertainty, and attributing "confidence" to the outcome. To this end, we introduce the Wellington Posterior, which is the distribution of outcomes that would have been obtained in response to data that could have been generated by the same scene that produced the given image. Since there are infinitely many scenes that could have generated any given image, the Wellington Posterior involves inductive transfer from scenes other than the one portrayed. We explore the use of data augmentation, dropout, ensembling, single-view reconstruction, and model linearization to compute a Wellington Posterior. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19982;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65288;MMD&#65289;&#30456;&#20851;&#30340;&#22522;&#20110;&#26680;&#30340;&#21452;&#26679;&#26412;&#26816;&#39564;&#32479;&#35745;&#37327;&#22312;&#27979;&#37327;&#27969;&#24418;&#25968;&#25454;&#26102;&#30340;&#24212;&#29992;&#12290;&#25991;&#31456;&#23637;&#31034;&#20102;&#26816;&#39564;&#27700;&#24179;&#21644;&#21151;&#29575;&#19982;&#26680;&#24102;&#23485;&#12289;&#26679;&#26412;&#25968;&#37327;&#21644;&#27969;&#24418;&#20869;&#22312;&#32500;&#24230;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#24314;&#31435;&#20102;&#27979;&#35797;&#21151;&#29575;&#19979;&#30028;&#12290;</title><link>http://arxiv.org/abs/2105.03425</link><description>&lt;p&gt;
&#27979;&#37327;&#27969;&#24418;&#25968;&#25454;&#30340;&#26680;&#21452;&#26679;&#26412;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Kernel Two-Sample Tests for Manifold Data. (arXiv:2105.03425v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.03425
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19982;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65288;MMD&#65289;&#30456;&#20851;&#30340;&#22522;&#20110;&#26680;&#30340;&#21452;&#26679;&#26412;&#26816;&#39564;&#32479;&#35745;&#37327;&#22312;&#27979;&#37327;&#27969;&#24418;&#25968;&#25454;&#26102;&#30340;&#24212;&#29992;&#12290;&#25991;&#31456;&#23637;&#31034;&#20102;&#26816;&#39564;&#27700;&#24179;&#21644;&#21151;&#29575;&#19982;&#26680;&#24102;&#23485;&#12289;&#26679;&#26412;&#25968;&#37327;&#21644;&#27969;&#24418;&#20869;&#22312;&#32500;&#24230;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#24314;&#31435;&#20102;&#27979;&#35797;&#21151;&#29575;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#27969;&#24418;&#25968;&#25454;&#35774;&#32622;&#19979;&#30740;&#31350;&#20102;&#19982;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65288;MMD&#65289;&#30456;&#20851;&#30340;&#22522;&#20110;&#26680;&#30340;&#21452;&#26679;&#26412;&#26816;&#39564;&#32479;&#35745;&#37327;&#65292;&#20551;&#35774;&#39640;&#32500;&#35266;&#27979;&#25968;&#25454;&#25509;&#36817;&#20110;&#20302;&#32500;&#27969;&#24418;&#12290;&#25105;&#20204;&#34920;&#24449;&#20102;&#27979;&#35797;&#27700;&#24179;&#21644;&#21151;&#29575;&#19982;&#26680;&#24102;&#23485;&#12289;&#26679;&#26412;&#25968;&#37327;&#21644;&#27969;&#24418;&#30340;&#20869;&#22312;&#32500;&#24230;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#24403;&#25968;&#25454;&#23494;&#24230;&#25903;&#25345;&#22312;&#19968;&#20010;&#23884;&#20837;&#21040;$m$&#32500;&#31354;&#38388;&#20013;&#30340;$d$&#32500;&#23376;&#27969;&#24418;$\mathcal{M}$&#19978;&#26102;&#65292;&#20174;&#26381;&#20174;&#20110;&#19968;&#23545;&#20998;&#24067;$p$&#21644;$q$&#25277;&#21462;&#30340;&#25968;&#25454;&#36827;&#34892;&#26680;&#21452;&#26679;&#26412;&#26816;&#39564;&#65292;&#36825;&#23545;&#20998;&#24067;$ p $&#21644;$q$&#26159;&#20855;&#26377;H\"older&#38454;$\beta$&#65288;&#26368;&#39640;2&#65289;&#65292;&#26679;&#26412;&#25968;&#37327;$n$&#36275;&#22815;&#22823;&#65292;&#20351;&#24471;$\Delta_2\gtrsim n^{- {2\beta/(d+4\beta)}}$&#65292;&#20854;&#20013;$\Delta_2$&#26159;&#27969;&#24418;&#19978;$p$&#21644;$q$&#20043;&#38388;&#30340;&#24179;&#26041;$L^2$-&#24046;&#24322;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#36275;&#22815;&#22823;&#19988;&#26377;&#38480;$n$&#30340;&#27979;&#35797;&#21151;&#29575;&#19979;&#30028;&#65292;&#20854;&#20013;&#26680;&#24102;&#23485;&#21442;&#25968;$\gamma$&#30340;&#27604;&#20363;&#23610;&#24230;&#20026;$n^ {-1/(d+4\beta)}$&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a study of a kernel-based two-sample test statistic related to the Maximum Mean Discrepancy (MMD) in the manifold data setting, assuming that high-dimensional observations are close to a low-dimensional manifold. We characterize the test level and power in relation to the kernel bandwidth, the number of samples, and the intrinsic dimensionality of the manifold. Specifically, we show that when data densities are supported on a $d$-dimensional sub-manifold $\mathcal{M}$ embedded in an $m$-dimensional space, the kernel two-sample test for data sampled from a pair of distributions $p$ and $q$ that are H\"older with order $\beta$ (up to 2) is powerful when the number of samples $n$ is large such that $\Delta_2 \gtrsim n^{- { 2 \beta/( d + 4 \beta ) }}$, where $\Delta_2$ is the squared $L^2$-divergence between $p$ and $q$ on manifold. We establish a lower bound on the test power for finite $n$ that is sufficiently large, where the kernel bandwidth parameter $\gamma$ scales as $n^{
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#12289;&#19981;&#38656;&#35201;&#35843;&#25972;&#25351;&#25968;&#21442;&#25968;&#30340;MNL-Contextual Bandit&#38382;&#39064;&#30340;&#31616;&#20415;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#12290;&#31639;&#27861;&#20855;&#26377;&#19982;&#35813;&#38382;&#39064;&#30340;&#26368;&#20339;&#29702;&#35770;&#30028;&#38480;&#21305;&#37197;&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2011.14033</link><description>&lt;p&gt;
MNL&#19978;&#19979;&#25991;Bandit&#38382;&#39064;&#30340;&#31616;&#20415;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Tractable Online Learning Algorithm for the Multinomial Logit Contextual Bandit. (arXiv:2011.14033v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2011.14033
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#12289;&#19981;&#38656;&#35201;&#35843;&#25972;&#25351;&#25968;&#21442;&#25968;&#30340;MNL-Contextual Bandit&#38382;&#39064;&#30340;&#31616;&#20415;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#12290;&#31639;&#27861;&#20855;&#26377;&#19982;&#35813;&#38382;&#39064;&#30340;&#26368;&#20339;&#29702;&#35770;&#30028;&#38480;&#21305;&#37197;&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;MNL-Bandit&#38382;&#39064;&#30340;&#19978;&#19979;&#25991;&#21464;&#20307;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#21160;&#24577;&#38598;&#21512;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#20915;&#31574;&#32773;&#21521;&#28040;&#36153;&#32773;&#25552;&#20379;&#19968;&#32452;&#20135;&#21697;&#65288;&#36141;&#29289;&#28165;&#21333;&#65289;&#65292;&#24182;&#22312;&#27599;&#20010;&#22238;&#21512;&#35266;&#23519;&#21709;&#24212;&#12290;&#28040;&#36153;&#32773;&#36141;&#20080;&#20135;&#21697;&#20197;&#26368;&#22823;&#21270;&#20182;&#20204;&#30340;&#25928;&#29992;&#12290;&#25105;&#20204;&#20551;&#35774;&#19968;&#32452;&#23646;&#24615;&#25551;&#36848;&#20102;&#20135;&#21697;&#65292;&#20135;&#21697;&#30340;&#24179;&#22343;&#25928;&#29992;&#19982;&#36825;&#20123;&#23646;&#24615;&#30340;&#20540;&#21576;&#32447;&#24615;&#20851;&#31995;&#12290;&#25105;&#20204;&#20351;&#29992;&#24191;&#27867;&#20351;&#29992;&#30340;Multinomial Logit&#65288;MNL&#65289;&#27169;&#22411;&#24314;&#27169;&#28040;&#36153;&#32773;&#36873;&#25321;&#34892;&#20026;&#65292;&#24182;&#32771;&#34385;&#22312;&#20248;&#21270;&#38144;&#21806;&#21608;&#26399;$T$&#20869;&#32047;&#31215;&#25910;&#30410;&#30340;&#21516;&#26102;&#21160;&#24577;&#23398;&#20064;&#27169;&#22411;&#21442;&#25968;&#30340;&#20915;&#31574;&#32773;&#38382;&#39064;&#12290;&#23613;&#31649;&#36825;&#20010;&#38382;&#39064;&#36817;&#26469;&#24341;&#36215;&#20102;&#30456;&#24403;&#22823;&#30340;&#20851;&#27880;&#65292;&#20294;&#35768;&#22810;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#28041;&#21450;&#35299;&#20915;&#19968;&#20010;&#38590;&#20197;&#22788;&#29702;&#30340;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#20182;&#20204;&#30340;&#29702;&#35770;&#24615;&#33021;&#20445;&#35777;&#21462;&#20915;&#20110;&#19968;&#20010;&#21487;&#33021;&#38750;&#24120;&#22823;&#30340;&#38382;&#39064;&#30456;&#20851;&#21442;&#25968;&#12290;&#29305;&#21035;&#22320;&#65292;&#29616;&#26377;&#26041;&#27861;&#38656;&#35201;&#35843;&#25972;&#38543;&#30528;&#23646;&#24615;&#38598;&#35268;&#27169;&#25351;&#25968;&#22686;&#38271;&#30340;&#35843;&#25972;&#21442;&#25968;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;MNL-Contextual Bandit&#38382;&#39064;&#30340;&#31616;&#20415;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#23427;&#19981;&#38656;&#35201;&#35843;&#25972;&#27492;&#31867;&#25351;&#25968;&#21442;&#25968;&#12290;&#25105;&#20204;&#23637;&#31034;&#25105;&#20204;&#30340;&#31639;&#27861;&#20855;&#26377;&#19982;&#35813;&#38382;&#39064;&#30340;&#26368;&#20339;&#29702;&#35770;&#30028;&#38480;&#21305;&#37197;&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#27169;&#25311;&#21644;&#30495;&#23454;&#19990;&#30028;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider the contextual variant of the MNL-Bandit problem. More specifically, we consider a dynamic set optimization problem, where a decision-maker offers a subset (assortment) of products to a consumer and observes the response in every round. Consumers purchase products to maximize their utility. We assume that a set of attributes describe the products, and the mean utility of a product is linear in the values of these attributes. We model consumer choice behavior using the widely used Multinomial Logit (MNL) model and consider the decision maker problem of dynamically learning the model parameters while optimizing cumulative revenue over the selling horizon $T$. Though this problem has attracted considerable attention in recent times, many existing methods often involve solving an intractable non-convex optimization problem. Their theoretical performance guarantees depend on a problem-dependent parameter which could be prohibitively large. In particular, existing 
&lt;/p&gt;</description></item><item><title>DeepTopPush&#26159;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;Accuracy at the Top&#38382;&#39064;&#30340;&#31616;&#21333;&#32780;&#21487;&#25193;&#23637;&#30340;&#26041;&#27861;&#65292;&#33021;&#26377;&#25928;&#22320;&#36873;&#25321;&#23569;&#37327;&#37325;&#35201;&#30340;&#26679;&#26412;&#65292;&#24182;&#22312;&#19981;&#21516;&#39046;&#22495;&#21462;&#24471;&#20102;&#20248;&#24322;&#30340;&#24615;&#33021;&#34920;&#29616;</title><link>http://arxiv.org/abs/2006.12293</link><description>&lt;p&gt;
DeepTopPush: &#19968;&#31181;&#31616;&#21333;&#21487;&#25193;&#23637;&#30340;Accuracy at the Top&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
DeepTopPush: Simple and Scalable Method for Accuracy at the Top. (arXiv:2006.12293v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.12293
&lt;/p&gt;
&lt;p&gt;
DeepTopPush&#26159;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;Accuracy at the Top&#38382;&#39064;&#30340;&#31616;&#21333;&#32780;&#21487;&#25193;&#23637;&#30340;&#26041;&#27861;&#65292;&#33021;&#26377;&#25928;&#22320;&#36873;&#25321;&#23569;&#37327;&#37325;&#35201;&#30340;&#26679;&#26412;&#65292;&#24182;&#22312;&#19981;&#21516;&#39046;&#22495;&#21462;&#24471;&#20102;&#20248;&#24322;&#30340;&#24615;&#33021;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Accuracy at the top&#26159;&#19968;&#31867;&#29305;&#27530;&#30340;&#20108;&#20998;&#31867;&#38382;&#39064;&#65292;&#20854;&#24615;&#33021;&#20165;&#22312;&#23569;&#25968;&#30456;&#20851;&#65288;&#39030;&#37096;&#65289;&#26679;&#26412;&#19978;&#35780;&#20272;&#12290;&#24212;&#29992;&#21253;&#25324;&#20449;&#24687;&#26816;&#32034;&#31995;&#32479;&#25110;&#38656;&#35201;&#25163;&#21160;&#65288;&#26114;&#36149;&#65289;&#21518;&#22788;&#29702;&#30340;&#24037;&#33402;&#12290;&#36825;&#23548;&#33268;&#26368;&#23567;&#21270;&#36229;&#36807;&#38408;&#20540;&#30340;&#26080;&#20851;&#26679;&#26412;&#25968;&#37327;&#12290;&#25105;&#20204;&#32771;&#34385;&#20197;&#20219;&#24847;&#65288;&#28145;&#24230;&#65289;&#32593;&#32476;&#30340;&#24418;&#24335;&#26500;&#24314;&#20998;&#31867;&#22120;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;DeepTopPush&#26041;&#27861;&#26469;&#26368;&#23567;&#21270;&#39030;&#37096;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;&#30001;&#20110;&#38408;&#20540;&#21462;&#20915;&#20110;&#25152;&#26377;&#26679;&#26412;&#65292;&#22240;&#27492;&#38382;&#39064;&#26159;&#19981;&#21487;&#20998;&#35299;&#30340;&#12290;&#25105;&#20204;&#20462;&#25913;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20197;&#22788;&#29702;&#38750;&#21487;&#20998;&#35299;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#24403;&#21069;&#36855;&#20320;&#25209;&#27425;&#20540;&#21644;&#19968;&#20010;&#24310;&#36831;&#20540;&#20272;&#35745;&#38408;&#20540;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;DeepTopPush&#22312;&#35270;&#35273;&#35782;&#21035;&#25968;&#25454;&#38598;&#21644;&#20004;&#20010;&#30495;&#23454;&#24212;&#29992;&#20013;&#30340;&#20248;&#24322;&#24615;&#33021;&#12290;&#31532;&#19968;&#20010;&#24212;&#29992;&#31243;&#24207;&#36873;&#25321;&#23569;&#37327;&#20998;&#23376;&#36827;&#34892;&#36827;&#19968;&#27493;&#30340;&#33647;&#29289;&#27979;&#35797;&#12290;&#31532;&#20108;&#20010;&#24212;&#29992;&#31243;&#24207;&#20351;&#29992;&#20102;
&lt;/p&gt;
&lt;p&gt;
Accuracy at the top is a special class of binary classification problems where the performance is evaluated only on a small number of relevant (top) samples. Applications include information retrieval systems or processes with manual (expensive) postprocessing. This leads to minimizing the number of irrelevant samples above a threshold. We consider classifiers in the form of an arbitrary (deep) network and propose a new method DeepTopPush for minimizing the loss function at the top. Since the threshold depends on all samples, the problem is non-decomposable. We modify the stochastic gradient descent to handle the non-decomposability in an end-to-end training manner and propose a way to estimate the threshold only from values on the current minibatch and one delayed value. We demonstrate the excellent performance of DeepTopPush on visual recognition datasets and two real-world applications. The first one selects a small number of molecules for further drug testing. The second one uses r
&lt;/p&gt;</description></item></channel></rss>