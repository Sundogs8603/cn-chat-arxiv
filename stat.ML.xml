<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36825;&#39033;&#30740;&#31350;&#24341;&#20837;&#20102;&#38887;&#24615;&#22810;&#36873;&#23398;&#20064;&#65288;rMCL&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;Voronoi tessellations&#30340;&#25968;&#23398;&#26694;&#26550;&#21644;&#23398;&#20064;&#35780;&#20998;&#26041;&#26696;&#65292;&#22312;&#22238;&#24402;&#35774;&#32622;&#20013;&#23454;&#29616;&#20102;&#23545;&#20110;&#27599;&#20010;&#35757;&#32451;&#36755;&#20837;&#21487;&#33021;&#37319;&#26679;&#22810;&#20010;&#30446;&#26631;&#30340;&#26465;&#20214;&#20998;&#24067;&#20272;&#35745;&#12290;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#22768;&#28304;&#23450;&#20301;&#38382;&#39064;&#19978;&#24471;&#21040;&#20102;&#23454;&#35777;&#39564;&#35777;&#21644;&#36827;&#19968;&#27493;&#35780;&#20272;&#65292;&#23637;&#31034;&#20102;&#20854;&#23454;&#38469;&#30340;&#26377;&#29992;&#24615;&#21644;&#35299;&#37322;&#30340;&#30456;&#20851;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.01052</link><description>&lt;p&gt;
&#38887;&#24615;&#22810;&#36873;&#23398;&#20064;&#65306;&#29992;&#20110;&#38899;&#39057;&#22330;&#26223;&#20998;&#26512;&#30340;&#23398;&#20064;&#35780;&#20998;&#26041;&#26696;&#30340;&#24341;&#20837;
&lt;/p&gt;
&lt;p&gt;
Resilient Multiple Choice Learning: A learned scoring scheme with application to audio scene analysis. (arXiv:2311.01052v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01052
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#24341;&#20837;&#20102;&#38887;&#24615;&#22810;&#36873;&#23398;&#20064;&#65288;rMCL&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;Voronoi tessellations&#30340;&#25968;&#23398;&#26694;&#26550;&#21644;&#23398;&#20064;&#35780;&#20998;&#26041;&#26696;&#65292;&#22312;&#22238;&#24402;&#35774;&#32622;&#20013;&#23454;&#29616;&#20102;&#23545;&#20110;&#27599;&#20010;&#35757;&#32451;&#36755;&#20837;&#21487;&#33021;&#37319;&#26679;&#22810;&#20010;&#30446;&#26631;&#30340;&#26465;&#20214;&#20998;&#24067;&#20272;&#35745;&#12290;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#22768;&#28304;&#23450;&#20301;&#38382;&#39064;&#19978;&#24471;&#21040;&#20102;&#23454;&#35777;&#39564;&#35777;&#21644;&#36827;&#19968;&#27493;&#35780;&#20272;&#65292;&#23637;&#31034;&#20102;&#20854;&#23454;&#38469;&#30340;&#26377;&#29992;&#24615;&#21644;&#35299;&#37322;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#38887;&#24615;&#22810;&#36873;&#23398;&#20064;&#65288;rMCL&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#23545;&#20110;&#27599;&#20010;&#35757;&#32451;&#36755;&#20837;&#21487;&#33021;&#37319;&#26679;&#22810;&#20010;&#30446;&#26631;&#30340;&#22238;&#24402;&#35774;&#32622;&#19979;&#26465;&#20214;&#20998;&#24067;&#20272;&#35745;&#30340;MCL&#26041;&#27861;&#30340;&#25193;&#23637;&#12290;&#22810;&#36873;&#23398;&#20064;&#26159;&#19968;&#20010;&#31616;&#21333;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22788;&#29702;&#22810;&#27169;&#24577;&#23494;&#24230;&#20272;&#35745;&#65292;&#20351;&#29992;&#20102;&#19968;&#32452;&#20551;&#35774;&#30340;&#32988;&#32773;&#20840;&#25343;&#65288;WTA&#65289;&#25439;&#22833;&#12290;&#22312;&#22238;&#24402;&#35774;&#32622;&#20013;&#65292;&#29616;&#26377;&#30340;MCL&#21464;&#20307;&#20027;&#35201;&#38598;&#20013;&#22312;&#21512;&#24182;&#20551;&#35774;&#19978;&#65292;&#20174;&#32780;&#26368;&#32456;&#29306;&#29298;&#20102;&#39044;&#27979;&#30340;&#22810;&#26679;&#24615;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#19968;&#20010;&#22522;&#20110;Voronoi tessellations&#30340;&#36755;&#20986;&#31354;&#38388;&#30340;&#25968;&#23398;&#26694;&#26550;&#25903;&#25345;&#30340;&#26032;&#39062;&#30340;&#23398;&#20064;&#35780;&#20998;&#26041;&#26696;&#65292;&#25105;&#20204;&#21487;&#20197;&#20174;&#20013;&#24471;&#20986;&#27010;&#29575;&#35299;&#37322;&#12290;&#22312;&#23545;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#23454;&#35777;&#39564;&#35777;&#21518;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35780;&#20272;&#20102;rMCL&#22312;&#22768;&#28304;&#23450;&#20301;&#38382;&#39064;&#19978;&#30340;&#20248;&#28857;&#65292;&#23637;&#31034;&#20102;&#20854;&#23454;&#38469;&#30340;&#26377;&#29992;&#24615;&#21644;&#35299;&#37322;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce Resilient Multiple Choice Learning (rMCL), an extension of the MCL approach for conditional distribution estimation in regression settings where multiple targets may be sampled for each training input. Multiple Choice Learning is a simple framework to tackle multimodal density estimation, using the Winner-Takes-All (WTA) loss for a set of hypotheses. In regression settings, the existing MCL variants focus on merging the hypotheses, thereby eventually sacrificing the diversity of the predictions. In contrast, our method relies on a novel learned scoring scheme underpinned by a mathematical framework based on Voronoi tessellations of the output space, from which we can derive a probabilistic interpretation. After empirically validating rMCL with experiments on synthetic data, we further assess its merits on the sound source localization problem, demonstrating its practical usefulness and the relevance of its interpretation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;DP-SGD&#20998;&#26512;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#23545;&#35768;&#22810;&#25968;&#25454;&#28857;&#30340;&#38544;&#31169;&#27844;&#28431;&#36827;&#34892;&#26356;&#20934;&#30830;&#30340;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2307.00310</link><description>&lt;p&gt;
&#26799;&#24230;&#30456;&#20284;&#65306;&#25935;&#24863;&#24230;&#32463;&#24120;&#34987;&#36807;&#39640;&#20272;&#35745;&#22312;DP-SGD&#20013;
&lt;/p&gt;
&lt;p&gt;
Gradients Look Alike: Sensitivity is Often Overestimated in DP-SGD. (arXiv:2307.00310v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00310
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;DP-SGD&#20998;&#26512;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#23545;&#35768;&#22810;&#25968;&#25454;&#28857;&#30340;&#38544;&#31169;&#27844;&#28431;&#36827;&#34892;&#26356;&#20934;&#30830;&#30340;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;DP-SGD&#65289;&#26159;&#31169;&#26377;&#28145;&#24230;&#23398;&#20064;&#30340;&#26631;&#20934;&#31639;&#27861;&#12290;&#34429;&#28982;&#24050;&#30693;&#20854;&#38544;&#31169;&#20998;&#26512;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#26159;&#32039;&#23494;&#30340;&#65292;&#20294;&#26159;&#19968;&#20123;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#24120;&#35265;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#26102;&#65292;&#25152;&#24471;&#21040;&#30340;&#27169;&#22411;&#23545;&#35768;&#22810;&#25968;&#25454;&#28857;&#30340;&#38544;&#31169;&#27844;&#28431;&#26174;&#33879;&#20943;&#23569;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20026;DP-SGD&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#26512;&#26041;&#27861;&#65292;&#25429;&#25417;&#21040;&#22312;&#25968;&#25454;&#38598;&#20013;&#20855;&#26377;&#30456;&#20284;&#37051;&#23621;&#30340;&#28857;&#20139;&#21463;&#26356;&#22909;&#38544;&#31169;&#24615;&#30340;&#30452;&#35273;&#12290;&#24418;&#24335;&#19978;&#26469;&#35828;&#65292;&#36825;&#26159;&#36890;&#36807;&#20462;&#25913;&#20174;&#35757;&#32451;&#25968;&#25454;&#38598;&#35745;&#31639;&#24471;&#21040;&#30340;&#27169;&#22411;&#26356;&#26032;&#30340;&#27599;&#27493;&#38544;&#31169;&#24615;&#20998;&#26512;&#26469;&#23454;&#29616;&#30340;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#24320;&#21457;&#20102;&#19968;&#20010;&#26032;&#30340;&#32452;&#21512;&#23450;&#29702;&#65292;&#20197;&#26377;&#25928;&#22320;&#21033;&#29992;&#36825;&#20010;&#26032;&#30340;&#27599;&#27493;&#20998;&#26512;&#26469;&#25512;&#29702;&#25972;&#20010;&#35757;&#32451;&#36807;&#31243;&#12290;&#24635;&#32780;&#35328;&#20043;&#65292;&#25105;&#20204;&#30340;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#31181;&#26032;&#39062;&#30340;DP-SGD&#20998;&#26512;&#20351;&#25105;&#20204;&#33021;&#22815;&#27491;&#24335;&#22320;&#26174;&#31034;DP-SGD&#23545;&#35768;&#22810;&#25968;&#25454;&#28857;&#30340;&#38544;&#31169;&#27844;&#28431;&#26174;&#33879;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differentially private stochastic gradient descent (DP-SGD) is the canonical algorithm for private deep learning. While it is known that its privacy analysis is tight in the worst-case, several empirical results suggest that when training on common benchmark datasets, the models obtained leak significantly less privacy for many datapoints. In this paper, we develop a new analysis for DP-SGD that captures the intuition that points with similar neighbors in the dataset enjoy better privacy than outliers. Formally, this is done by modifying the per-step privacy analysis of DP-SGD to introduce a dependence on the distribution of model updates computed from a training dataset. We further develop a new composition theorem to effectively use this new per-step analysis to reason about an entire training run. Put all together, our evaluation shows that this novel DP-SGD analysis allows us to now formally show that DP-SGD leaks significantly less privacy for many datapoints. In particular, we ob
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#31454;&#20105;&#29615;&#22659;&#19979;&#30340;&#34892;&#20026;&#65292;&#21457;&#29616;&#25552;&#39640;&#25968;&#25454;&#34920;&#31034;&#36136;&#37327;&#21487;&#33021;&#20250;&#23548;&#33268;&#20379;&#24212;&#21830;&#25972;&#20307;&#39044;&#27979;&#20934;&#30830;&#24615;&#38477;&#20302;&#65292;&#20174;&#32780;&#38477;&#20302;&#31038;&#20250;&#31119;&#21033;&#12290;</title><link>http://arxiv.org/abs/2306.14670</link><description>&lt;p&gt;
&#31454;&#20105;&#29615;&#22659;&#19979;&#36125;&#21494;&#26031;&#39118;&#38505;&#30340;&#25552;&#39640;&#21487;&#33021;&#23548;&#33268;&#31038;&#20250;&#31119;&#21033;&#30340;&#38477;&#20302;
&lt;/p&gt;
&lt;p&gt;
Improved Bayes Risk Can Yield Reduced Social Welfare Under Competition. (arXiv:2306.14670v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14670
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#31454;&#20105;&#29615;&#22659;&#19979;&#30340;&#34892;&#20026;&#65292;&#21457;&#29616;&#25552;&#39640;&#25968;&#25454;&#34920;&#31034;&#36136;&#37327;&#21487;&#33021;&#20250;&#23548;&#33268;&#20379;&#24212;&#21830;&#25972;&#20307;&#39044;&#27979;&#20934;&#30830;&#24615;&#38477;&#20302;&#65292;&#20174;&#32780;&#38477;&#20302;&#31038;&#20250;&#31119;&#21033;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#35268;&#27169;&#30340;&#22686;&#38271;&#65292;&#32553;&#25918;&#23450;&#24459;&#31561;&#36235;&#21183;&#39044;&#35745;&#20250;&#23548;&#33268;&#39044;&#27979;&#20934;&#30830;&#24615;&#30340;&#25345;&#32493;&#25913;&#36827;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#36235;&#21183;&#21482;&#32771;&#34385;&#20102;&#21333;&#20010;&#27169;&#22411;&#20379;&#24212;&#21830;&#30340;&#35270;&#35282;&#65292;&#32780;&#23454;&#38469;&#19978;&#20379;&#24212;&#21830;&#20043;&#38388;&#24120;&#24120;&#31454;&#20105;&#29992;&#25143;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;&#31454;&#20105;&#21487;&#20197;&#20174;&#26681;&#26412;&#19978;&#25913;&#21464;&#36825;&#20123;&#32553;&#25918;&#36235;&#21183;&#30340;&#34892;&#20026;&#65292;&#29978;&#33267;&#21487;&#33021;&#36896;&#25104;&#25972;&#20307;&#39044;&#27979;&#20934;&#30830;&#24615;&#38543;&#30528;&#35268;&#27169;&#30340;&#22686;&#22823;&#32780;&#38750;&#21333;&#35843;&#25110;&#38477;&#20302;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#19968;&#20010;&#20998;&#31867;&#20219;&#21153;&#30340;&#31454;&#20105;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;&#25968;&#25454;&#34920;&#31034;&#20316;&#20026;&#30740;&#31350;&#35268;&#27169;&#22686;&#21152;&#30340;&#24433;&#21709;&#30340;&#38236;&#22836;&#12290;&#25105;&#20204;&#21457;&#29616;&#22312;&#19968;&#23478;&#24066;&#22330;&#19978;&#65292;&#25913;&#21892;&#25968;&#25454;&#34920;&#31034;&#36136;&#37327;&#65288;&#25353;&#36125;&#21494;&#26031;&#39118;&#38505;&#35745;&#37327;&#65289;&#21487;&#33021;&#20250;&#38477;&#20302;&#31454;&#20105;&#27169;&#22411;&#20379;&#24212;&#21830;&#30340;&#25972;&#20307;&#39044;&#27979;&#20934;&#30830;&#24615;&#65288;&#21363;&#31038;&#20250;&#31119;&#21033;&#65289;&#12290;&#25105;&#20204;&#30340;&#20363;&#23376;&#28085;&#30422;&#20102;&#31616;&#21333;&#35774;&#32622;&#20013;&#30340;&#23553;&#38381;&#24335;&#20844;&#24335;&#21040;&#39044;&#35757;&#32451;&#30340; CIFAR-10 &#27169;&#25311;&#12290;
&lt;/p&gt;
&lt;p&gt;
As the scale of machine learning models increases, trends such as scaling laws anticipate consistent downstream improvements in predictive accuracy. However, these trends take the perspective of a single model-provider in isolation, while in reality providers often compete with each other for users. In this work, we demonstrate that competition can fundamentally alter the behavior of these scaling trends, even causing overall predictive accuracy across users to be non-monotonic or decreasing with scale. We define a model of competition for classification tasks, and use data representations as a lens for studying the impact of increases in scale. We find many settings where improving data representation quality (as measured by Bayes risk) decreases the overall predictive accuracy across users (i.e., social welfare) for a marketplace of competing model-providers. Our examples range from closed-form formulas in simple settings to simulations with pretrained representations on CIFAR-10. At
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#27979;&#24230;&#19978;&#32534;&#20889;&#21464;&#20998;&#30446;&#26631;&#30340;&#21160;&#26426;&#65292;&#25552;&#20986;&#36890;&#36807;&#27492;&#31867;&#30446;&#26631;&#25512;&#23548;&#23454;&#29992;&#31639;&#27861;&#65292;&#20197;&#35299;&#20915;&#36229;&#20986;&#20998;&#24067;&#30340;&#27867;&#21270;&#21644;&#24369;&#30417;&#30563;&#23398;&#20064;&#31561;&#38382;&#39064;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.11928</link><description>&lt;p&gt;
&#24320;&#25918;&#38382;&#39064;&#65306;&#22522;&#20110;&#21464;&#20998;&#30446;&#26631;&#30340;&#27979;&#24230;&#23398;&#20064; (arXiv:2306.11928v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
Open Problem: Learning with Variational Objectives on Measures. (arXiv:2306.11928v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11928
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#27979;&#24230;&#19978;&#32534;&#20889;&#21464;&#20998;&#30446;&#26631;&#30340;&#21160;&#26426;&#65292;&#25552;&#20986;&#36890;&#36807;&#27492;&#31867;&#30446;&#26631;&#25512;&#23548;&#23454;&#29992;&#31639;&#27861;&#65292;&#20197;&#35299;&#20915;&#36229;&#20986;&#20998;&#24067;&#30340;&#27867;&#21270;&#21644;&#24369;&#30417;&#30563;&#23398;&#20064;&#31561;&#38382;&#39064;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#20851;&#27880;&#30340;&#26159;&#22522;&#20110;&#20989;&#25968;&#30340;&#21464;&#20998;&#30446;&#26631;&#12290;&#26412;&#25991;&#35752;&#35770;&#20102;&#22312;&#27979;&#24230;&#19978;&#32534;&#20889;&#31867;&#20284;&#30446;&#26631;&#30340;&#21160;&#26426;&#65292;&#29305;&#21035;&#26159;&#35752;&#35770;&#20102;&#36229;&#20986;&#20998;&#24067;&#30340;&#27867;&#21270;&#21644;&#24369;&#30417;&#30563;&#23398;&#20064;&#12290;&#36825;&#24341;&#21457;&#20102;&#19968;&#20010;&#33258;&#28982;&#30340;&#38382;&#39064;&#65306;&#33021;&#21542;&#23558;&#36890;&#24120;&#30340;&#32479;&#35745;&#23398;&#20064;&#32467;&#26524;&#36716;&#21270;&#20026;&#22522;&#20110;&#27979;&#37327;&#34920;&#36798;&#30340;&#30446;&#26631;&#65311;&#32467;&#26524;&#26500;&#24314;&#26159;&#21542;&#20250;&#23548;&#33268;&#26032;&#30340;&#23454;&#29992;&#31639;&#27861;&#65311;
&lt;/p&gt;
&lt;p&gt;
The theory of statistical learning has focused on variational objectives expressed on functions. In this note, we discuss motivations to write similar objectives on measures, in particular to discuss out-of-distribution generalization and weakly-supervised learning. It raises a natural question: can one cast usual statistical learning results to objectives expressed on measures? Does the resulting construction lead to new algorithms of practical interest?
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20026;&#35299;&#20915;&#39640;&#26031;&#22270;&#27169;&#22411;&#20013;&#21464;&#37327;&#30340;&#26465;&#20214;&#29420;&#31435;&#32467;&#26500;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#31934;&#24230;&#30697;&#38453;&#30340;$l_p$&#27491;&#21017;&#21270;&#30340;&#26041;&#27861;&#65292;&#24182;&#23558;&#39057;&#29575;&#23398;&#27966;&#21644;&#36125;&#21494;&#26031;&#23398;&#27966;&#30340;&#20248;&#28857;&#34701;&#21512;&#22312;&#21464;&#20998;&#25512;&#29702;&#20013;&#65292;&#24182;&#24341;&#20837;&#20102;&#30697;&#38453;&#21464;&#37327;&#26631;&#20934;&#21270;&#27969;&#31243;&#26469;&#36924;&#36817;&#21518;&#39564;&#12290;</title><link>http://arxiv.org/abs/2306.07255</link><description>&lt;p&gt;
&#38024;&#23545;&#39640;&#26031;&#22270;&#27169;&#22411;&#30340;&#26465;&#20214;&#30697;&#38453;&#27969;
&lt;/p&gt;
&lt;p&gt;
Conditional Matrix Flows for Gaussian Graphical Models. (arXiv:2306.07255v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07255
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20026;&#35299;&#20915;&#39640;&#26031;&#22270;&#27169;&#22411;&#20013;&#21464;&#37327;&#30340;&#26465;&#20214;&#29420;&#31435;&#32467;&#26500;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#31934;&#24230;&#30697;&#38453;&#30340;$l_p$&#27491;&#21017;&#21270;&#30340;&#26041;&#27861;&#65292;&#24182;&#23558;&#39057;&#29575;&#23398;&#27966;&#21644;&#36125;&#21494;&#26031;&#23398;&#27966;&#30340;&#20248;&#28857;&#34701;&#21512;&#22312;&#21464;&#20998;&#25512;&#29702;&#20013;&#65292;&#24182;&#24341;&#20837;&#20102;&#30697;&#38453;&#21464;&#37327;&#26631;&#20934;&#21270;&#27969;&#31243;&#26469;&#36924;&#36817;&#21518;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23569;&#25968;&#35266;&#27979;&#21464;&#37327;&#20013;&#30740;&#31350;&#35768;&#22810;&#21464;&#37327;&#20043;&#38388;&#30340;&#26465;&#20214;&#29420;&#31435;&#32467;&#26500;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#39640;&#26031;&#22270;&#27169;&#22411;&#36890;&#36807;&#22312;$l_p$&#27491;&#21017;&#21270;&#20013;&#40723;&#21169;&#31934;&#24230;&#30697;&#38453;&#30340;&#31232;&#30095;&#24615;&#26469;&#35299;&#20915;&#27492;&#38382;&#39064;&#65292;&#20854;&#20013;$p \leq1$&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20122;-$l_1$&#20266;&#33539;&#25968;&#20351;&#30446;&#26631;&#39640;&#24230;&#38750;&#20984;&#65292;&#22240;&#27492;&#22823;&#22810;&#25968;&#26041;&#27861;&#20381;&#36182;&#20110;$l_1$&#33539;&#25968;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#39057;&#29575;&#23398;&#27966;&#26041;&#27861;&#20801;&#35768;&#20248;&#38597;&#22320;&#35745;&#31639;&#20316;&#20026;&#25910;&#32553;&#21442;&#25968;$\lambda$&#20989;&#25968;&#30340;&#35299;&#20915;&#26041;&#26696;&#36335;&#24452;&#12290;&#36125;&#21494;&#26031;&#20844;&#24335;&#20026;&#31934;&#24230;&#30697;&#38453;&#24341;&#20837;&#20102;&#25289;&#26222;&#25289;&#26031;&#20808;&#39564;&#65292;&#20294;&#26159;&#19981;&#21516;$\lambda$&#20540;&#30340;&#21518;&#39564;&#25512;&#26029;&#38656;&#35201;&#22810;&#27425;&#36816;&#34892;&#26114;&#36149;&#30340;&#21513;&#24067;&#26031;&#37319;&#26679;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#24120;&#36890;&#29992;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;GGM&#30340;&#21464;&#20998;&#25512;&#29702;&#65292;&#23427;&#32479;&#19968;&#20102;&#39057;&#29575;&#23398;&#27966;&#21644;&#36125;&#21494;&#26031;&#23398;&#27966;&#30340;&#20248;&#28857;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24314;&#35758;&#29992;&#23450;&#20041;&#22312;s&#31354;&#38388;&#19978;&#30340;&#30697;&#38453;&#21464;&#37327;&#26631;&#20934;&#21270;&#27969;&#31243;&#26469;&#36924;&#36817;&#21518;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Studying conditional independence structure among many variables with few observations is a challenging task. Gaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through an $l_p$ regularization with $p\leq1$. However, since the objective is highly non-convex for sub-$l_1$ pseudo-norms, most approaches rely on the $l_1$ norm. In this case frequentist approaches allow to elegantly compute the solution path as a function of the shrinkage parameter $\lambda$. Instead of optimizing the penalized likelihood, the Bayesian formulation introduces a Laplace prior on the precision matrix. However, posterior inference for different $\lambda$ values requires repeated runs of expensive Gibbs samplers. We propose a very general framework for variational inference in GGMs that unifies the benefits of frequentist and Bayesian frameworks. Specifically, we propose to approximate the posterior with a matrix-variate Normalizing Flow defined on the space of s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;transformer&#30340;&#34920;&#31034;&#33021;&#21147;&#65292;&#27491;&#38754;&#35828;&#26126;&#20102;transformer&#22312;&#31232;&#30095;&#24179;&#22343;&#20219;&#21153;&#20013;&#30340;&#25928;&#29575;&#27604;&#24490;&#29615;&#32593;&#32476;&#21644;&#21069;&#39304;&#32593;&#32476;&#26356;&#39640;&#65292;&#24182;&#23637;&#31034;&#20102;&#22823;&#23884;&#20837;&#32500;&#24230;&#22312;transformer&#20013;&#30340;&#24517;&#35201;&#24615;&#21644;&#20316;&#29992;&#65307;&#36127;&#38754;&#35828;&#26126;&#20102;&#27880;&#24847;&#21147;&#23618;&#30340;&#22797;&#26434;&#24230;&#38543;&#36755;&#20837;&#22823;&#23567;&#32447;&#24615;&#32553;&#25918;&#65292;&#20294;&#36825;&#31181;&#24773;&#20917;&#22312;&#23454;&#36341;&#20013;&#24456;&#23569;&#21457;&#29983;&#65292;&#21487;&#20197;&#20351;&#29992;&#26367;&#20195;&#30340;&#21464;&#20307;&#12290;</title><link>http://arxiv.org/abs/2306.02896</link><description>&lt;p&gt;
Transformer&#30340;&#20195;&#34920;&#24615;&#20248;&#21183;&#21644;&#23616;&#38480;&#24615;
&lt;/p&gt;
&lt;p&gt;
Representational Strengths and Limitations of Transformers. (arXiv:2306.02896v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02896
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;transformer&#30340;&#34920;&#31034;&#33021;&#21147;&#65292;&#27491;&#38754;&#35828;&#26126;&#20102;transformer&#22312;&#31232;&#30095;&#24179;&#22343;&#20219;&#21153;&#20013;&#30340;&#25928;&#29575;&#27604;&#24490;&#29615;&#32593;&#32476;&#21644;&#21069;&#39304;&#32593;&#32476;&#26356;&#39640;&#65292;&#24182;&#23637;&#31034;&#20102;&#22823;&#23884;&#20837;&#32500;&#24230;&#22312;transformer&#20013;&#30340;&#24517;&#35201;&#24615;&#21644;&#20316;&#29992;&#65307;&#36127;&#38754;&#35828;&#26126;&#20102;&#27880;&#24847;&#21147;&#23618;&#30340;&#22797;&#26434;&#24230;&#38543;&#36755;&#20837;&#22823;&#23567;&#32447;&#24615;&#32553;&#25918;&#65292;&#20294;&#36825;&#31181;&#24773;&#20917;&#22312;&#23454;&#36341;&#20013;&#24456;&#23569;&#21457;&#29983;&#65292;&#21487;&#20197;&#20351;&#29992;&#26367;&#20195;&#30340;&#21464;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27880;&#24847;&#21147;&#23618;&#24120;&#29992;&#20110;transformer&#20013;&#65292;&#26159;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#30340;&#25903;&#26609;&#20043;&#19968;&#65292;&#20294;&#19982;&#20854;&#20182;&#32593;&#32476;&#32467;&#26500;&#30456;&#27604;&#65292;&#23427;&#20204;&#30340;&#22909;&#22788;&#21644;&#32570;&#38519;&#27809;&#26377;&#25968;&#23398;&#25551;&#36848;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23545;&#27880;&#24847;&#21147;&#23618;&#30340;&#34920;&#31034;&#33021;&#21147;&#36827;&#34892;&#20102;&#27491;&#38754;&#21644;&#36127;&#38754;&#30340;&#30740;&#31350;&#65292;&#24182;&#32858;&#28966;&#20110;&#20869;&#22312;&#22797;&#26434;&#24230;&#21442;&#25968;&#65292;&#22914;&#23485;&#24230;&#12289;&#28145;&#24230;&#21644;&#23884;&#20837;&#32500;&#24230;&#12290;&#22312;&#27491;&#38754;&#26041;&#38754;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#39033;&#31232;&#30095;&#24179;&#22343;&#20219;&#21153;&#65292;&#20854;&#20013;&#24490;&#29615;&#32593;&#32476;&#21644;&#21069;&#39304;&#32593;&#32476;&#30340;&#22797;&#26434;&#24230;&#37117;&#38543;&#36755;&#20837;&#22823;&#23567;&#21576;&#22810;&#39033;&#24335;&#32553;&#25918;&#65292;&#32780;transformer&#20165;&#21576;&#23545;&#25968;&#32553;&#25918;&#65307;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;&#30456;&#21516;&#30340;&#26500;&#36896;&#26469;&#23637;&#31034;transformer&#20013;&#22823;&#23884;&#20837;&#32500;&#24230;&#30340;&#24517;&#35201;&#24615;&#21644;&#20316;&#29992;&#12290;&#22312;&#36127;&#38754;&#26041;&#38754;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#19977;&#20803;&#26816;&#27979;&#20219;&#21153;&#65292;&#20854;&#20013;&#27880;&#24847;&#21147;&#23618;&#30340;&#22797;&#26434;&#24230;&#38543;&#36755;&#20837;&#22823;&#23567;&#21576;&#32447;&#24615;&#32553;&#25918;&#65307;&#30001;&#20110;&#36825;&#31181;&#24773;&#20917;&#22312;&#23454;&#36341;&#20013;&#20284;&#20046;&#24456;&#23569;&#21457;&#29983;&#65292;&#22240;&#27492;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#21487;&#20197;&#26367;&#20195;&#30340;&#21464;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;
Attention layers, as commonly used in transformers, form the backbone of modern deep learning, yet there is no mathematical description of their benefits and deficiencies as compared with other architectures. In this work we establish both positive and negative results on the representation power of attention layers, with a focus on intrinsic complexity parameters such as width, depth, and embedding dimension. On the positive side, we present a sparse averaging task, where recurrent networks and feedforward networks all have complexity scaling polynomially in the input size, whereas transformers scale merely logarithmically in the input size; furthermore, we use the same construction to show the necessity and role of a large embedding dimension in a transformer. On the negative side, we present a triple detection task, where attention layers in turn have complexity scaling linearly in the input size; as this scenario seems rare in practice, we also present natural variants that can be 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#38543;&#26426;Lp&#33539;&#25968;&#22833;&#30495;&#23545;&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#36827;&#34892;&#22686;&#24378;&#65292;&#24182;&#35780;&#20272;&#27169;&#22411;&#23545;&#19981;&#21487;&#24863;&#30693;&#38543;&#26426;&#22833;&#30495;&#30340;&#31283;&#20581;&#24615;&#65292;&#21457;&#29616;&#31283;&#20581;&#24615;&#21487;&#33021;&#20250;&#25552;&#39640;&#27169;&#22411;&#22312;&#38543;&#26426;&#22833;&#30495;&#26041;&#38754;&#30340;&#24615;&#33021;&#65292;&#20294;&#20063;&#21487;&#33021;&#20250;&#25439;&#23475;L&#8734;&#33539;&#25968;&#30340;&#31283;&#20581;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.05400</link><description>&lt;p&gt;
&#20351;&#29992;&#38543;&#26426;Lp&#33539;&#25968;&#22833;&#30495;&#25506;&#31350;&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#33104;&#36133;&#31283;&#20581;&#24615;
&lt;/p&gt;
&lt;p&gt;
Investigating the Corruption Robustness of Image Classifiers with Random Lp-norm Corruptions. (arXiv:2305.05400v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05400
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#38543;&#26426;Lp&#33539;&#25968;&#22833;&#30495;&#23545;&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#36827;&#34892;&#22686;&#24378;&#65292;&#24182;&#35780;&#20272;&#27169;&#22411;&#23545;&#19981;&#21487;&#24863;&#30693;&#38543;&#26426;&#22833;&#30495;&#30340;&#31283;&#20581;&#24615;&#65292;&#21457;&#29616;&#31283;&#20581;&#24615;&#21487;&#33021;&#20250;&#25552;&#39640;&#27169;&#22411;&#22312;&#38543;&#26426;&#22833;&#30495;&#26041;&#38754;&#30340;&#24615;&#33021;&#65292;&#20294;&#20063;&#21487;&#33021;&#20250;&#25439;&#23475;L&#8734;&#33539;&#25968;&#30340;&#31283;&#20581;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31283;&#20581;&#24615;&#26159;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#22120;&#23454;&#29616;&#23433;&#20840;&#21644;&#21487;&#38752;&#30340;&#22522;&#26412;&#23646;&#24615;&#12290;&#22312;&#23545;&#22270;&#20687;&#20998;&#31867;&#27169;&#22411;&#30340;&#23545;&#25239;&#31283;&#20581;&#24615;&#21644;&#24418;&#24335;&#31283;&#20581;&#24615;&#39564;&#35777;&#39046;&#22495;&#20013;&#65292;&#31283;&#20581;&#24615;&#36890;&#24120;&#34987;&#23450;&#20041;&#20026;&#22312;Lp&#33539;&#25968;&#36317;&#31163;&#20869;&#23545;&#25152;&#26377;&#36755;&#20837;&#21464;&#21270;&#30340;&#31283;&#23450;&#24615;&#12290;&#28982;&#32780;&#65292;&#23545;&#38543;&#26426;&#22833;&#30495;&#30340;&#31283;&#20581;&#24615;&#36890;&#24120;&#36890;&#36807;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#35266;&#23519;&#21040;&#30340;&#21464;&#21270;&#26469;&#25913;&#36827;&#21644;&#35780;&#20272;&#65292;&#32780;&#24456;&#23569;&#32771;&#34385;&#25968;&#23398;&#23450;&#20041;&#30340;Lp&#33539;&#25968;&#22833;&#30495;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#38543;&#26426;Lp&#33539;&#25968;&#22833;&#30495;&#26469;&#22686;&#24378;&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#12290;&#25105;&#20204;&#20511;&#37492;&#20102;&#23545;&#25239;&#31283;&#20581;&#24615;&#39046;&#22495;&#30340;&#26041;&#27861;&#26469;&#35780;&#20272;&#27169;&#22411;&#23545;&#19981;&#21487;&#24863;&#30693;&#38543;&#26426;&#22833;&#30495;&#30340;&#31283;&#20581;&#24615;&#12290;&#25105;&#20204;&#23454;&#35777;&#21644;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;&#22312;&#19981;&#21516;Lp&#33539;&#25968;&#20043;&#38388;&#31283;&#20581;&#24615;&#26159;&#21542;&#21487;&#36716;&#31227;&#65292;&#24182;&#24471;&#20986;&#32467;&#35770;&#65292;&#21738;&#20123;Lp&#33539;&#25968;&#30340;&#22833;&#30495;&#24212;&#35813;&#29992;&#26469;&#35757;&#32451;&#21644;&#35780;&#20272;&#27169;&#22411;&#12290;&#25105;&#20204;&#21457;&#29616;&#35757;&#32451;&#25968;&#25454;&#22686;&#24378;&#21487;&#33021;&#20250;&#25552;&#39640;&#27169;&#22411;&#22312;&#38543;&#26426;&#22833;&#30495;&#26041;&#38754;&#30340;&#24615;&#33021;&#65292;&#20294;&#20063;&#21487;&#33021;&#20250;&#25439;&#23475;L&#8734;&#33539;&#25968;&#30340;&#31283;&#20581;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Robustness is a fundamental property of machine learning classifiers to achieve safety and reliability. In the fields of adversarial robustness and formal robustness verification of image classification models, robustness is commonly defined as the stability to all input variations within an Lp-norm distance. However, robustness to random corruptions is usually improved and evaluated using variations observed in the real-world, while mathematically defined Lp-norm corruptions are rarely considered. This study investigates the use of random Lp-norm corruptions to augment the training and test data of image classifiers. We adapt an approach from the field of adversarial robustness to assess the model robustness to imperceptible random corruptions. We empirically and theoretically investigate whether robustness is transferable across different Lp-norms and derive conclusions on which Lp-norm corruptions a model should be trained and evaluated on. We find that training data augmentation wi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#20010;&#35797;&#39564;&#20013;&#21033;&#29992;&#25968;&#25454;&#20272;&#35745;&#20010;&#20307;&#21270;&#27835;&#30103;&#25928;&#24212;&#30340;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#27169;&#25311;&#34920;&#26126;&#30452;&#25509;&#20801;&#35768;&#35797;&#39564;&#38388;&#27835;&#30103;&#25928;&#24212;&#30340;&#24322;&#36136;&#24615;&#30340;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#65292;&#21333;&#19968;&#30740;&#31350;&#26041;&#27861;&#30340;&#36873;&#25321;&#21462;&#20915;&#20110;&#27835;&#30103;&#25928;&#24212;&#30340;&#21151;&#33021;&#24418;&#24335;&#12290;</title><link>http://arxiv.org/abs/2303.16299</link><description>&lt;p&gt;
&#32467;&#21512;&#22810;&#20010;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#25968;&#25454;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#27604;&#36739;&#24322;&#36136;&#24615;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Comparing Machine Learning Methods for Estimating Heterogeneous Treatment Effects by Combining Data from Multiple Randomized Controlled Trials. (arXiv:2303.16299v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16299
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#20010;&#35797;&#39564;&#20013;&#21033;&#29992;&#25968;&#25454;&#20272;&#35745;&#20010;&#20307;&#21270;&#27835;&#30103;&#25928;&#24212;&#30340;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#27169;&#25311;&#34920;&#26126;&#30452;&#25509;&#20801;&#35768;&#35797;&#39564;&#38388;&#27835;&#30103;&#25928;&#24212;&#30340;&#24322;&#36136;&#24615;&#30340;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#65292;&#21333;&#19968;&#30740;&#31350;&#26041;&#27861;&#30340;&#36873;&#25321;&#21462;&#20915;&#20110;&#27835;&#30103;&#25928;&#24212;&#30340;&#21151;&#33021;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#30340;&#27835;&#30103;&#20915;&#31574;&#21487;&#20197;&#25913;&#21892;&#20581;&#24247;&#32467;&#26524;&#65292;&#20294;&#26159;&#20351;&#29992;&#25968;&#25454;&#20197;&#21487;&#38752;&#12289;&#31934;&#30830;&#21644;&#26377;&#26222;&#36941;&#24847;&#20041;&#30340;&#26041;&#24335;&#36827;&#34892;&#36825;&#20123;&#20915;&#31574;&#22312;&#19968;&#20010;&#21333;&#19968;&#25968;&#25454;&#38598;&#20013;&#26159;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#21033;&#29992;&#22810;&#20010;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#21487;&#20197;&#32452;&#21512;&#20855;&#26377;&#38750;&#28151;&#26434;&#24615;&#27835;&#30103;&#20998;&#37197;&#30340;&#25968;&#25454;&#38598;&#65292;&#25552;&#39640;&#20272;&#35745;&#24322;&#36136;&#24615;&#27835;&#30103;&#25928;&#24212;&#30340;&#33021;&#21147;&#12290;&#26412;&#25991;&#35752;&#35770;&#20102;&#20960;&#31181;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#29992;&#20110;&#21033;&#29992;&#22810;&#20010;&#35797;&#39564;&#30340;&#25968;&#25454;&#20272;&#35745;&#24322;&#36136;&#24615;&#27835;&#30103;&#25928;&#24212;&#12290;&#25105;&#20204;&#23558;&#21333;&#19968;&#30740;&#31350;&#30340;&#26041;&#27861;&#25193;&#23637;&#21040;&#22810;&#20010;&#35797;&#39564;&#30340;&#22330;&#26223;&#20013;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#25506;&#35752;&#23427;&#20204;&#30340;&#24615;&#33021;&#65292;&#25968;&#25454;&#29983;&#25104;&#24773;&#26223;&#20855;&#26377;&#19981;&#21516;&#27700;&#24179;&#30340;&#36328;&#35797;&#39564;&#24322;&#36136;&#24615;&#12290;&#27169;&#25311;&#34920;&#26126;&#65292;&#30452;&#25509;&#20801;&#35768;&#35797;&#39564;&#38388;&#27835;&#30103;&#25928;&#24212;&#30340;&#24322;&#36136;&#24615;&#30340;&#26041;&#27861;&#27604;&#19981;&#20801;&#35768;&#30340;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#65292;&#24182;&#19988;&#21333;&#19968;&#30740;&#31350;&#26041;&#27861;&#30340;&#36873;&#25321;&#21462;&#20915;&#20110;&#27835;&#30103;&#25928;&#24212;&#30340;&#21151;&#33021;&#24418;&#24335;&#12290;&#26368;&#21518;&#65292;&#36890;&#36807;&#23545;&#20943;&#23569;&#20303;&#38498;&#37325;&#26032;&#20837;&#38498;&#24178;&#39044;&#30340;&#32593;&#32476;&#33631;&#33795;&#20998;&#26512;&#25968;&#25454;&#30340;&#24212;&#29992;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#23454;&#36341;&#20013;&#30340;&#26041;&#27861;&#65292;&#24182;&#35752;&#35770;&#20102;&#23545;&#26410;&#26469;&#30740;&#31350;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Individualized treatment decisions can improve health outcomes, but using data to make these decisions in a reliable, precise, and generalizable way is challenging with a single dataset. Leveraging multiple randomized controlled trials allows for the combination of datasets with unconfounded treatment assignment to improve the power to estimate heterogeneous treatment effects. This paper discusses several non-parametric approaches for estimating heterogeneous treatment effects using data from multiple trials. We extend single-study methods to a scenario with multiple trials and explore their performance through a simulation study, with data generation scenarios that have differing levels of cross-trial heterogeneity. The simulations demonstrate that methods that directly allow for heterogeneity of the treatment effect across trials perform better than methods that do not, and that the choice of single-study method matters based on the functional form of the treatment effect. Finally, w
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;SSBM&#65292;&#23427;&#21482;&#38656;&#35201;&#20108;&#36827;&#21046;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#65292;&#24182;&#25506;&#32034;&#20102;&#20174;&#19981;&#23436;&#25972;&#30340;&#20108;&#36827;&#21046;&#35266;&#23519;&#20013;&#23398;&#20064;&#30340;&#26497;&#31471;&#24773;&#20917;&#12290;&#36825;&#20026;&#20174;&#20108;&#36827;&#21046;&#27979;&#37327;&#20013;&#24674;&#22797;&#20449;&#21495;&#25552;&#20379;&#20102;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#22312;&#19968;&#31995;&#21015;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;SSBM&#30340;&#21331;&#36234;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2303.08691</link><description>&lt;p&gt;
&#20174;&#20108;&#36827;&#21046;&#27979;&#37327;&#20013;&#23398;&#20064;&#20449;&#21495;&#37325;&#26500;
&lt;/p&gt;
&lt;p&gt;
Learning to Reconstruct Signals From Binary Measurements. (arXiv:2303.08691v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08691
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;SSBM&#65292;&#23427;&#21482;&#38656;&#35201;&#20108;&#36827;&#21046;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#65292;&#24182;&#25506;&#32034;&#20102;&#20174;&#19981;&#23436;&#25972;&#30340;&#20108;&#36827;&#21046;&#35266;&#23519;&#20013;&#23398;&#20064;&#30340;&#26497;&#31471;&#24773;&#20917;&#12290;&#36825;&#20026;&#20174;&#20108;&#36827;&#21046;&#27979;&#37327;&#20013;&#24674;&#22797;&#20449;&#21495;&#25552;&#20379;&#20102;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#22312;&#19968;&#31995;&#21015;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;SSBM&#30340;&#21331;&#36234;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#31361;&#20986;&#20102;&#20165;&#20174;&#22122;&#22768;&#21644;&#19981;&#23436;&#25972;&#30340;&#32447;&#24615;&#27979;&#37327;&#20013;&#23398;&#20064;&#20449;&#21495;&#37325;&#26500;&#30340;&#21487;&#33021;&#24615;&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#21307;&#23398;&#21644;&#31185;&#23398;&#25104;&#20687;&#20197;&#21450;&#20256;&#24863;&#20013;&#36215;&#21040;&#20851;&#38190;&#20316;&#29992;&#65292;&#20854;&#20013;&#22320;&#38754;&#30495;&#23454;&#25968;&#25454;&#32463;&#24120;&#31232;&#32570;&#25110;&#38590;&#20197;&#33719;&#24471;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#27979;&#37327;&#19981;&#20165;&#22122;&#22768;&#21644;&#19981;&#23436;&#25972;&#65292;&#32780;&#19988;&#36824;&#34987;&#37327;&#21270;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25506;&#32034;&#20174;&#20108;&#36827;&#21046;&#35266;&#23519;&#20013;&#23398;&#20064;&#30340;&#26497;&#31471;&#24773;&#20917;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#20174;&#19981;&#23436;&#25972;&#20108;&#36827;&#21046;&#25968;&#25454;&#20013;&#35782;&#21035;&#19968;&#32452;&#20449;&#21495;&#25152;&#38656;&#30340;&#27979;&#37327;&#25968;&#37327;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26159;&#23545;&#20174;&#20108;&#36827;&#21046;&#27979;&#37327;&#20013;&#20449;&#21495;&#24674;&#22797;&#29616;&#26377;&#30028;&#38480;&#30340;&#34917;&#20805;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#25105;&#20204;&#23558;&#20854;&#21629;&#21517;&#20026;&#8220;SSBM&#8221;&#65292;&#23427;&#20165;&#38656;&#35201;&#20108;&#36827;&#21046;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;SSBM&#19982;&#30417;&#30563;&#23398;&#20064;&#30456;&#24403;&#65292;&#24182;&#20248;&#20110;&#31232;&#30095;&#37325;&#26500;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advances in unsupervised learning have highlighted the possibility of learning to reconstruct signals from noisy and incomplete linear measurements alone. These methods play a key role in medical and scientific imaging and sensing, where ground truth data is often scarce or difficult to obtain. However, in practice, measurements are not only noisy and incomplete but also quantized. Here we explore the extreme case of learning from binary observations and provide necessary and sufficient conditions on the number of measurements required for identifying a set of signals from incomplete binary data. Our results are complementary to existing bounds on signal recovery from binary measurements. Furthermore, we introduce a novel self-supervised learning approach, which we name SSBM, that only requires binary data for training. We demonstrate in a series of experiments with real datasets that SSBM performs on par with supervised learning and outperforms sparse reconstruction methods wit
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;Q-&#25351;&#25968;&#36807;&#31243;&#30340;&#36125;&#21494;&#26031;&#23398;&#20064;&#65292;&#36890;&#36807;&#25512;&#24191;Q-&#25351;&#25968;&#20998;&#24067;&#20026;Q-&#25351;&#25968;&#36807;&#31243;&#65292;&#26469;&#23545;&#20989;&#25968;&#30340;L_q&#27491;&#21017;&#21270;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#36873;&#25321;&#19968;&#33268;&#30340;&#22810;&#20803;q-&#25351;&#25968;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2210.07987</link><description>&lt;p&gt;
&#22522;&#20110;Q-&#25351;&#25968;&#36807;&#31243;&#30340;&#36125;&#21494;&#26031;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Bayesian Learning via Q-Exponential Process. (arXiv:2210.07987v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.07987
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;Q-&#25351;&#25968;&#36807;&#31243;&#30340;&#36125;&#21494;&#26031;&#23398;&#20064;&#65292;&#36890;&#36807;&#25512;&#24191;Q-&#25351;&#25968;&#20998;&#24067;&#20026;Q-&#25351;&#25968;&#36807;&#31243;&#65292;&#26469;&#23545;&#20989;&#25968;&#30340;L_q&#27491;&#21017;&#21270;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#36873;&#25321;&#19968;&#33268;&#30340;&#22810;&#20803;q-&#25351;&#25968;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27491;&#21017;&#21270;&#26159;&#20248;&#21270;&#12289;&#32479;&#35745;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#22522;&#30784;&#30340;&#20027;&#39064;&#20043;&#19968;&#12290;&#20026;&#20102;&#22312;&#20272;&#35745;&#21442;&#25968;$u\in\mbR^d$&#26102;&#33719;&#24471;&#31232;&#30095;&#24615;&#65292;&#22312;&#30446;&#26631;&#20989;&#25968;&#20013;&#36890;&#24120;&#20250;&#28155;&#21152;$\ell_q$&#24809;&#32602;&#39033;&#65292;&#21363;$\Vert u\Vert_q$&#12290;&#36825;&#26679;&#30340;$\ell_q$&#24809;&#32602;&#23545;&#24212;&#30340;&#27010;&#29575;&#20998;&#24067;&#26159;&#20160;&#20040;&#65311;&#24403;&#25105;&#20204;&#23545;&#20989;&#25968;$u\in L^q$&#24314;&#27169;&#26102;&#65292;$\Vert u\Vert_q$&#23545;&#24212;&#30340;&#27491;&#30830;&#38543;&#26426;&#36807;&#31243;&#26159;&#20160;&#20040;&#65311;&#36825;&#23545;&#20110;&#32479;&#35745;&#24314;&#27169;&#22823;&#32500;&#24230;&#23545;&#35937;&#65288;&#20363;&#22914;&#22270;&#20687;&#65289;&#24182;&#20445;&#30041;&#30830;&#23450;&#24615;&#29305;&#24615;&#65288;&#20363;&#22914;&#22270;&#20687;&#36793;&#32536;&#65289;&#30340;&#24809;&#32602;&#38750;&#24120;&#37325;&#35201;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;$Q$-&#25351;&#25968;&#20998;&#24067;&#65288;&#23494;&#24230;&#27491;&#27604;&#20110;$\exp{(- \half|u|^q)}$&#65289;&#25512;&#24191;&#20026;&#19968;&#31181;&#31216;&#20026;\emph{$Q$-&#25351;&#25968;&#65288;Q-EP&#65289;&#36807;&#31243;}&#30340;&#38543;&#26426;&#36807;&#31243;&#65292;&#23427;&#23545;&#24212;&#20110;&#20989;&#25968;&#30340;$L_q$&#27491;&#21017;&#21270;&#12290;&#20851;&#38190;&#27493;&#39588;&#26159;&#36890;&#36807;&#20174;&#22823;&#22411;&#26925;&#22278;&#36718;&#24275;&#20998;&#24067;&#26063;&#20013;&#36873;&#25321;&#26469;&#25351;&#23450;&#19968;&#33268;&#30340;&#22810;&#20803;$q$-&#25351;&#25968;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
Regularization is one of the most fundamental topics in optimization, statistics and machine learning. To get sparsity in estimating a parameter $u\in\mbR^d$, an $\ell_q$ penalty term, $\Vert u\Vert_q$, is usually added to the objective function. What is the probabilistic distribution corresponding to such $\ell_q$ penalty? What is the correct stochastic process corresponding to $\Vert u\Vert_q$ when we model functions $u\in L^q$? This is important for statistically modeling large dimensional objects, e.g. images, with penalty to preserve certainty properties, e.g. edges in the image. In this work, we generalize the $q$-exponential distribution (with density proportional to) $\exp{(- \half|u|^q)}$ to a stochastic process named \emph{$Q$-exponential (Q-EP) process} that corresponds to the $L_q$ regularization of functions. The key step is to specify consistent multivariate $q$-exponential distributions by choosing from a large family of elliptic contour distributions. The work is closel
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#19968;&#31867;&#21452;&#23618;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#26080;&#38656;warm-start&#20063;&#21487;&#23454;&#29616;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2202.03397</link><description>&lt;p&gt;
&#26377;&#19979;&#23618;&#21387;&#32553;&#30340;&#21452;&#23618;&#20248;&#21270;: &#26080;warm-start&#24773;&#20917;&#19979;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Bilevel Optimization with a Lower-level Contraction: Optimal Sample Complexity without Warm-Start. (arXiv:2202.03397v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.03397
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#19968;&#31867;&#21452;&#23618;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#26080;&#38656;warm-start&#20063;&#21487;&#23454;&#29616;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#19968;&#31867;&#19968;&#33324;&#30340;&#21452;&#23618;&#38382;&#39064;&#65292;&#20854;&#20013;&#19978;&#23618;&#38382;&#39064;&#26159;&#23558;&#19968;&#20809;&#28369;&#30446;&#26631;&#20989;&#25968;&#26368;&#23567;&#21270;&#65292;&#19979;&#23618;&#38382;&#39064;&#26159;&#23547;&#25214;&#19968;&#20809;&#28369;&#25910;&#32553;&#26144;&#23556;&#30340;&#19981;&#21160;&#28857;&#12290;&#36825;&#31867;&#38382;&#39064;&#21253;&#25324;&#20803;&#23398;&#20064;&#12289;&#22343;&#34913;&#27169;&#22411;&#12289;&#36229;&#21442;&#25968;&#20248;&#21270;&#21644;&#25968;&#25454;&#27745;&#26579;&#23545;&#25239;&#25915;&#20987;&#30340;&#23454;&#20363;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#65292;&#21363;&#20351;&#27809;&#26377;warm-start&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#22914;&#20803;&#23398;&#20064;&#21644;&#22343;&#34913;&#27169;&#22411;&#65292;&#20173;&#28982;&#21487;&#20197;&#23454;&#29616;&#39034;&#24207;&#26368;&#20248;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyse a general class of bilevel problems, in which the upper-level problem consists in the minimization of a smooth objective function and the lower-level problem is to find the fixed point of a smooth contraction map. This type of problems include instances of meta-learning, equilibrium models, hyperparameter optimization and data poisoning adversarial attacks. Several recent works have proposed algorithms which warm-start the lower-level problem, i.e. they use the previous lower-level approximate solution as a staring point for the lower-level solver. This warm-start procedure allows one to improve the sample complexity in both the stochastic and deterministic settings, achieving in some cases the order-wise optimal sample complexity. However, there are situations, e.g., meta learning and equilibrium models, in which the warm-start procedure is not well-suited or ineffective. In this work we show that without warm-start, it is still possible to achieve order-wise (near) optimal
&lt;/p&gt;</description></item></channel></rss>