<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>AdaSub&#26159;&#19968;&#31181;&#20351;&#29992;&#20302;&#32500;&#23376;&#31354;&#38388;&#20013;&#30340;&#20108;&#38454;&#20449;&#24687;&#36827;&#34892;&#38543;&#26426;&#20248;&#21270;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#25628;&#32034;&#30340;&#23376;&#31354;&#38388;&#32500;&#24230;&#26469;&#31649;&#29702;&#35745;&#31639;&#24320;&#38144;&#21644;&#31639;&#27861;&#25928;&#29575;&#12290;&#21021;&#27493;&#25968;&#20540;&#32467;&#26524;&#26174;&#31034;&#65292;AdaSub&#22312;&#26102;&#38388;&#21644;&#36845;&#20195;&#27425;&#25968;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#38543;&#26426;&#20248;&#21270;&#22120;&#12290;</title><link>http://arxiv.org/abs/2310.20060</link><description>&lt;p&gt;
AdaSub&#65306;&#20351;&#29992;&#20302;&#32500;&#23376;&#31354;&#38388;&#20013;&#30340;&#20108;&#38454;&#20449;&#24687;&#36827;&#34892;&#38543;&#26426;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
AdaSub: Stochastic Optimization Using Second-Order Information in Low-Dimensional Subspaces. (arXiv:2310.20060v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20060
&lt;/p&gt;
&lt;p&gt;
AdaSub&#26159;&#19968;&#31181;&#20351;&#29992;&#20302;&#32500;&#23376;&#31354;&#38388;&#20013;&#30340;&#20108;&#38454;&#20449;&#24687;&#36827;&#34892;&#38543;&#26426;&#20248;&#21270;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#25628;&#32034;&#30340;&#23376;&#31354;&#38388;&#32500;&#24230;&#26469;&#31649;&#29702;&#35745;&#31639;&#24320;&#38144;&#21644;&#31639;&#27861;&#25928;&#29575;&#12290;&#21021;&#27493;&#25968;&#20540;&#32467;&#26524;&#26174;&#31034;&#65292;AdaSub&#22312;&#26102;&#38388;&#21644;&#36845;&#20195;&#27425;&#25968;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#38543;&#26426;&#20248;&#21270;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;AdaSub&#65292;&#19968;&#31181;&#22522;&#20110;&#20302;&#32500;&#33258;&#36866;&#24212;&#23450;&#20041;&#30340;&#20108;&#38454;&#20449;&#24687;&#30340;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#12290;&#19982;&#19968;&#38454;&#26041;&#27861;&#30456;&#27604;&#65292;&#20108;&#38454;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#25910;&#25947;&#29305;&#24615;&#65292;&#20294;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#35745;&#31639;Hessian&#30697;&#38453;&#20250;&#23548;&#33268;&#36807;&#39640;&#30340;&#35745;&#31639;&#24320;&#38144;&#65292;&#20351;&#20854;&#19981;&#23454;&#29992;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#36873;&#25321;&#25628;&#32034;&#30340;&#23376;&#31354;&#38388;&#32500;&#24230;&#26469;&#31649;&#29702;&#35745;&#31639;&#24320;&#38144;&#21644;&#31639;&#27861;&#25928;&#29575;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#22312;GitHub&#19978;&#20813;&#36153;&#25552;&#20379;&#65292;&#25105;&#20204;&#30340;&#21021;&#27493;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#65292;AdaSub&#22312;&#36798;&#21040;&#32473;&#23450;&#31934;&#24230;&#25152;&#38656;&#30340;&#26102;&#38388;&#21644;&#36845;&#20195;&#27425;&#25968;&#26041;&#38754;&#36229;&#36807;&#20102;&#27969;&#34892;&#30340;&#38543;&#26426;&#20248;&#21270;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce AdaSub, a stochastic optimization algorithm that computes a search direction based on second-order information in a low-dimensional subspace that is defined adaptively based on available current and past information. Compared to first-order methods, second-order methods exhibit better convergence characteristics, but the need to compute the Hessian matrix at each iteration results in excessive computational expenses, making them impractical. To address this issue, our approach enables the management of computational expenses and algorithm efficiency by enabling the selection of the subspace dimension for the search. Our code is freely available on GitHub, and our preliminary numerical results demonstrate that AdaSub surpasses popular stochastic optimizers in terms of time and number of iterations required to reach a given accuracy.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;FlowDRO&#30340;&#35745;&#31639;&#39640;&#25928;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#22522;&#20110;&#27969;&#30340;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#20351;&#29992;&#27969;&#27169;&#22411;&#21644;Wasserstein&#36817;&#31471;&#26799;&#24230;&#27969;&#31867;&#22411;&#30340;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#20855;&#26377;&#26356;&#22823;&#26679;&#26412;&#22823;&#23567;&#30340;&#38382;&#39064;&#30340;&#21487;&#25193;&#23637;&#24615;&#21644;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.19253</link><description>&lt;p&gt;
&#22522;&#20110;&#27969;&#30340;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Flow-based Distributionally Robust Optimization. (arXiv:2310.19253v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19253
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;FlowDRO&#30340;&#35745;&#31639;&#39640;&#25928;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#22522;&#20110;&#27969;&#30340;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#20351;&#29992;&#27969;&#27169;&#22411;&#21644;Wasserstein&#36817;&#31471;&#26799;&#24230;&#27969;&#31867;&#22411;&#30340;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#20855;&#26377;&#26356;&#22823;&#26679;&#26412;&#22823;&#23567;&#30340;&#38382;&#39064;&#30340;&#21487;&#25193;&#23637;&#24615;&#21644;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;FlowDRO&#30340;&#35745;&#31639;&#39640;&#25928;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#22522;&#20110;&#27969;&#30340;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;DRO&#65289;&#38382;&#39064;&#65292;&#20854;&#20013;&#35201;&#27714;&#26368;&#22351;&#24773;&#20917;&#20998;&#24067;&#65288;&#20063;&#31216;&#20026;&#26368;&#19981;&#21033;&#20998;&#24067;&#65292;LFD&#65289;&#26159;&#36830;&#32493;&#30340;&#65292;&#20174;&#32780;&#20351;&#24471;&#31639;&#27861;&#33021;&#22815;&#21487;&#25193;&#23637;&#21040;&#20855;&#26377;&#26356;&#22823;&#26679;&#26412;&#22823;&#23567;&#30340;&#38382;&#39064;&#65292;&#24182;&#23454;&#29616;&#23545;&#35825;&#23548;&#30340;&#40065;&#26834;&#31639;&#27861;&#30340;&#26356;&#22909;&#27867;&#21270;&#33021;&#21147;&#12290;&#20026;&#20102;&#35299;&#20915;&#35745;&#31639;&#19978;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#26080;&#38480;&#32500;&#20248;&#21270;&#38382;&#39064;&#65292;&#25105;&#20204;&#21033;&#29992;&#22522;&#20110;&#27969;&#30340;&#27169;&#22411;&#65292;&#22312;&#25968;&#25454;&#20998;&#24067;&#21644;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;&#36827;&#34892;&#36830;&#32493;&#26102;&#38388;&#21487;&#36870;&#20256;&#36755;&#26144;&#23556;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;Wasserstein&#36817;&#31471;&#26799;&#24230;&#27969;&#31867;&#22411;&#30340;&#31639;&#27861;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#36880;&#27493;&#35757;&#32451;&#22359;&#20869;&#30340;&#31070;&#32463;&#32593;&#32476;&#24207;&#21015;&#26469;&#21442;&#25968;&#21270;&#20256;&#36755;&#26144;&#23556;&#12290;&#25105;&#20204;&#30340;&#35745;&#31639;&#26694;&#26550;&#36890;&#29992;&#65292;&#33021;&#22815;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#21644;&#22823;&#26679;&#26412;&#22823;&#23567;&#65292;&#24182;&#21487;&#29992;&#20110;&#21508;&#31181;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a computationally efficient framework, called \texttt{FlowDRO}, for solving flow-based distributionally robust optimization (DRO) problems with Wasserstein uncertainty sets, when requiring the worst-case distribution (also called the Least Favorable Distribution, LFD) to be continuous so that the algorithm can be scalable to problems with larger sample sizes and achieve better generalization capability for the induced robust algorithms. To tackle the computationally challenging infinitely dimensional optimization problem, we leverage flow-based models, continuous-time invertible transport maps between the data distribution and the target distribution, and develop a Wasserstein proximal gradient flow type of algorithm. In practice, we parameterize the transport maps by a sequence of neural networks progressively trained in blocks by gradient descent. Our computational framework is general, can handle high-dimensional data with large sample sizes, and can be useful for various
&lt;/p&gt;</description></item><item><title>&#21327;&#20316;&#21644;&#21487;&#35299;&#37322;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26694;&#26550;(CoExBO)&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#24341;&#20837;&#20102;&#24490;&#29615;&#65292;&#24179;&#34913;&#20102;&#20154;&#24037;&#26234;&#33021;&#21644;&#20154;&#31867;&#30340;&#21512;&#20316;&#20851;&#31995;&#12290;&#23427;&#21033;&#29992;&#20559;&#22909;&#23398;&#20064;&#23558;&#29992;&#25143;&#35265;&#35299;&#34701;&#21512;&#21040;&#20248;&#21270;&#20013;&#65292;&#35299;&#37322;&#27599;&#27425;&#36845;&#20195;&#30340;&#20505;&#36873;&#36873;&#25321;&#65292;&#20174;&#32780;&#22686;&#24378;&#29992;&#25143;&#23545;&#20248;&#21270;&#36807;&#31243;&#30340;&#20449;&#20219;&#65292;&#24182;&#25552;&#20379;&#26080;&#23475;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2310.17273</link><description>&lt;p&gt;
&#23558;&#24490;&#29615;&#24341;&#20837;&#20154;&#31867;&#65306;&#21327;&#20316;&#21644;&#21487;&#35299;&#37322;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Looping in the Human: Collaborative and Explainable Bayesian Optimization. (arXiv:2310.17273v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17273
&lt;/p&gt;
&lt;p&gt;
&#21327;&#20316;&#21644;&#21487;&#35299;&#37322;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26694;&#26550;(CoExBO)&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#24341;&#20837;&#20102;&#24490;&#29615;&#65292;&#24179;&#34913;&#20102;&#20154;&#24037;&#26234;&#33021;&#21644;&#20154;&#31867;&#30340;&#21512;&#20316;&#20851;&#31995;&#12290;&#23427;&#21033;&#29992;&#20559;&#22909;&#23398;&#20064;&#23558;&#29992;&#25143;&#35265;&#35299;&#34701;&#21512;&#21040;&#20248;&#21270;&#20013;&#65292;&#35299;&#37322;&#27599;&#27425;&#36845;&#20195;&#30340;&#20505;&#36873;&#36873;&#25321;&#65292;&#20174;&#32780;&#22686;&#24378;&#29992;&#25143;&#23545;&#20248;&#21270;&#36807;&#31243;&#30340;&#20449;&#20219;&#65292;&#24182;&#25552;&#20379;&#26080;&#23475;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20687;&#35768;&#22810;&#20248;&#21270;&#22120;&#19968;&#26679;&#65292;&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#33719;&#24471;&#29992;&#25143;&#20449;&#20219;&#26041;&#38754;&#24120;&#24120;&#23384;&#22312;&#19981;&#36275;&#65292;&#22240;&#20026;&#20854;&#19981;&#36879;&#26126;&#24615;&#12290;&#34429;&#28982;&#24050;&#32463;&#23581;&#35797;&#24320;&#21457;&#38754;&#21521;&#20154;&#31867;&#30340;&#20248;&#21270;&#22120;&#65292;&#20294;&#23427;&#20204;&#36890;&#24120;&#20551;&#35774;&#29992;&#25143;&#30693;&#35782;&#26159;&#26126;&#30830;&#19988;&#26080;&#35823;&#30340;&#65292;&#24182;&#20027;&#35201;&#23558;&#29992;&#25143;&#20316;&#20026;&#20248;&#21270;&#36807;&#31243;&#30340;&#30417;&#30563;&#32773;&#12290;&#25105;&#20204;&#25918;&#23485;&#20102;&#36825;&#20123;&#20551;&#35774;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#24179;&#34913;&#30340;&#20154;&#24037;&#26234;&#33021;&#21644;&#20154;&#31867;&#21512;&#20316;&#20249;&#20276;&#20851;&#31995;&#65292;&#21363;&#25105;&#20204;&#30340;&#21327;&#20316;&#21644;&#21487;&#35299;&#37322;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;CoExBO&#65289;&#26694;&#26550;&#12290;CoExBO&#20351;&#29992;&#20559;&#22909;&#23398;&#20064;&#26469;&#26080;&#32541;&#22320;&#23558;&#20154;&#31867;&#35265;&#35299;&#25972;&#21512;&#21040;&#20248;&#21270;&#20013;&#65292;&#20174;&#32780;&#20135;&#29983;&#19982;&#29992;&#25143;&#20351;&#29992;&#20559;&#22909;&#19968;&#33268;&#30340;&#31639;&#27861;&#24314;&#35758;&#12290;CoExBO&#35299;&#37322;&#20854;&#27599;&#27425;&#36845;&#20195;&#30340;&#20505;&#36873;&#36873;&#25321;&#65292;&#20197;&#22521;&#20859;&#20449;&#20219;&#65292;&#20351;&#29992;&#25143;&#26356;&#28165;&#26970;&#22320;&#25484;&#25569;&#20248;&#21270;&#30340;&#36807;&#31243;&#12290;&#27492;&#22806;&#65292;CoExBO&#25552;&#20379;&#26080;&#23475;&#20445;&#35777;&#65292;&#20801;&#35768;&#29992;&#25143;&#29359;&#38169;&#35823;&#65307;&#21363;&#20351;&#22312;&#26497;&#31471;&#23545;&#25239;&#24615;&#24178;&#25200;&#19979;&#65292;&#31639;&#27861;&#20063;&#20250;&#28176;&#36827;&#22320;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;
Like many optimizers, Bayesian optimization often falls short of gaining user trust due to opacity. While attempts have been made to develop human-centric optimizers, they typically assume user knowledge is well-specified and error-free, employing users mainly as supervisors of the optimization process. We relax these assumptions and propose a more balanced human-AI partnership with our Collaborative and Explainable Bayesian Optimization (CoExBO) framework. Instead of explicitly requiring a user to provide a knowledge model, CoExBO employs preference learning to seamlessly integrate human insights into the optimization, resulting in algorithmic suggestions that resonate with user preference. CoExBO explains its candidate selection every iteration to foster trust, empowering users with a clearer grasp of the optimization. Furthermore, CoExBO offers a no-harm guarantee, allowing users to make mistakes; even with extreme adversarial interventions, the algorithm converges asymptotically to
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#22686;&#24378;&#23398;&#20064;&#26041;&#27861;&#22312;&#35299;&#20915;&#32452;&#21512;&#38382;&#39064;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#25552;&#20379;&#20102;&#32943;&#23450;&#30340;&#31572;&#26696;&#12290;&#36825;&#20010;&#26694;&#26550;&#23545;&#20110;&#35299;&#20915;&#21253;&#25324;&#26368;&#22823;&#21106;&#21644;&#26368;&#23567;&#21106;&#12289;&#26368;&#22823;$k$&#32422;&#26463;&#38382;&#39064;&#12289;&#26368;&#22823;&#26435;&#37325;&#20108;&#20998;&#22270;&#21305;&#37197;&#21644;&#26053;&#34892;&#21830;&#38382;&#39064;&#22312;&#20869;&#30340;&#24191;&#27867;&#30340;&#32452;&#21512;&#38382;&#39064;&#26377;&#37325;&#35201;&#30340;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2310.05309</link><description>&lt;p&gt;
&#20248;&#21270;&#32452;&#21512;&#38382;&#39064;&#30340;&#35299;&#37319;&#26679;&#22120;&#65306;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#30340;&#26799;&#24230;&#26041;&#21521;
&lt;/p&gt;
&lt;p&gt;
Optimizing Solution-Samplers for Combinatorial Problems: The Landscape of Policy-Gradient Methods. (arXiv:2310.05309v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05309
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#22686;&#24378;&#23398;&#20064;&#26041;&#27861;&#22312;&#35299;&#20915;&#32452;&#21512;&#38382;&#39064;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#25552;&#20379;&#20102;&#32943;&#23450;&#30340;&#31572;&#26696;&#12290;&#36825;&#20010;&#26694;&#26550;&#23545;&#20110;&#35299;&#20915;&#21253;&#25324;&#26368;&#22823;&#21106;&#21644;&#26368;&#23567;&#21106;&#12289;&#26368;&#22823;$k$&#32422;&#26463;&#38382;&#39064;&#12289;&#26368;&#22823;&#26435;&#37325;&#20108;&#20998;&#22270;&#21305;&#37197;&#21644;&#26053;&#34892;&#21830;&#38382;&#39064;&#22312;&#20869;&#30340;&#24191;&#27867;&#30340;&#32452;&#21512;&#38382;&#39064;&#26377;&#37325;&#35201;&#30340;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#22686;&#24378;&#23398;&#20064;&#26041;&#27861;&#22312;&#35299;&#20915;&#22797;&#26434;&#30340;&#32452;&#21512;&#38382;&#39064;&#26041;&#38754;&#20855;&#26377;&#24456;&#39640;&#30340;&#23454;&#29992;&#20215;&#20540;&#12290;&#22312;&#36825;&#20123;&#26041;&#27861;&#20013;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#34987;&#29992;&#20316;&#35299;&#20915;&#26041;&#26696;&#29983;&#25104;&#22120;&#65292;&#28982;&#21518;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#31561;&#26041;&#27861;&#36827;&#34892;&#35757;&#32451;&#65292;&#20197;&#36880;&#27493;&#33719;&#24471;&#26356;&#22909;&#30340;&#35299;&#20915;&#26041;&#26696;&#20998;&#24067;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29702;&#35770;&#26694;&#26550;&#26469;&#20998;&#26512;&#36825;&#20123;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#23545;&#36825;&#20010;&#38382;&#39064;&#30340;&#31215;&#26497;&#22238;&#31572;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#21253;&#25324;&#26368;&#22823;&#21106;&#21644;&#26368;&#23567;&#21106;&#12289;&#26368;&#22823;$k$&#32422;&#26463;&#38382;&#39064;&#12289;&#26368;&#22823;&#26435;&#37325;&#20108;&#20998;&#22270;&#21305;&#37197;&#21644;&#26053;&#34892;&#21830;&#38382;&#39064;&#22312;&#20869;&#30340;&#24191;&#27867;&#30340;&#32452;&#21512;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Neural Networks and Reinforcement Learning methods have empirically shown great promise in tackling challenging combinatorial problems. In those methods a deep neural network is used as a solution generator which is then trained by gradient-based methods (e.g., policy gradient) to successively obtain better solution distributions. In this work we introduce a novel theoretical framework for analyzing the effectiveness of such methods. We ask whether there exist generative models that (i) are expressive enough to generate approximately optimal solutions; (ii) have a tractable, i.e, polynomial in the size of the input, number of parameters; (iii) their optimization landscape is benign in the sense that it does not contain sub-optimal stationary points. Our main contribution is a positive answer to this question. Our result holds for a broad class of combinatorial problems including Max- and Min-Cut, Max-$k$-CSP, Maximum-Weight-Bipartite-Matching, and the Traveling Salesman Problem. A
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20462;&#27491;&#30340;&#26399;&#26395;&#25913;&#21892;&#37319;&#38598;&#20989;&#25968;&#65292;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#35299;&#20915;&#20102;&#23545;&#20110;&#26377;&#22122;&#22768;&#35266;&#27979;&#30340;&#24773;&#20917;&#19979;&#24573;&#30053;&#20505;&#36873;&#35299;&#19981;&#30830;&#23450;&#24615;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.05166</link><description>&lt;p&gt;
&#19968;&#20010;&#22312;&#26377;&#22122;&#22768;&#35266;&#27979;&#19979;&#20462;&#27491;&#30340;&#26399;&#26395;&#25913;&#21892;&#37319;&#38598;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
A Corrected Expected Improvement Acquisition Function Under Noisy Observations. (arXiv:2310.05166v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05166
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20462;&#27491;&#30340;&#26399;&#26395;&#25913;&#21892;&#37319;&#38598;&#20989;&#25968;&#65292;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#35299;&#20915;&#20102;&#23545;&#20110;&#26377;&#22122;&#22768;&#35266;&#27979;&#30340;&#24773;&#20917;&#19979;&#24573;&#30053;&#20505;&#36873;&#35299;&#19981;&#30830;&#23450;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24207;&#21015;&#26368;&#22823;&#21270;&#26399;&#26395;&#25913;&#21892;(EI)&#26159;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#26368;&#24120;&#29992;&#30340;&#31574;&#30053;&#20043;&#19968;&#65292;&#22240;&#20854;&#31616;&#21333;&#24615;&#21644;&#22788;&#29702;&#22122;&#22768;&#35266;&#27979;&#30340;&#33021;&#21147;&#32780;&#24191;&#27867;&#24212;&#29992;&#12290;&#29305;&#21035;&#26159;&#65292;&#22312;&#22122;&#22768;&#29615;&#22659;&#20013;&#65292;&#25913;&#21892;&#20989;&#25968;&#36890;&#24120;&#20351;&#29992;&#26368;&#20339;&#21518;&#39564;&#22343;&#20540;&#20316;&#20026;&#26368;&#20339;&#20505;&#36873;&#35299;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#35299;&#26512;&#30340;EI&#31867;&#22411;&#26041;&#27861;&#20013;&#65292;&#24120;&#24120;&#24573;&#30053;&#19982;&#20505;&#36873;&#35299;&#30456;&#20851;&#30340;&#19981;&#30830;&#23450;&#24615;&#65306;&#22312;&#26080;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#23548;&#20986;&#20102;&#19968;&#20010;&#38381;&#21512;&#24418;&#24335;&#30340;&#37319;&#38598;&#20989;&#25968;&#65292;&#28982;&#21518;&#24212;&#29992;&#20110;&#26377;&#22122;&#22768;&#35266;&#27979;&#30340;&#24773;&#20917;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#27491;EI&#30340;&#26041;&#27861;&#65292;&#23558;&#39640;&#26031;&#36807;&#31243;(GP)&#27169;&#22411;&#25552;&#20379;&#30340;&#21327;&#26041;&#24046;&#20449;&#24687;&#32435;&#20837;&#20854;&#38381;&#21512;&#24418;&#24335;&#34920;&#36798;&#24335;&#20013;&#12290;&#36825;&#20010;&#37319;&#38598;&#20989;&#25968;&#19982;&#32463;&#20856;&#30340;&#26080;&#22122;&#22768;&#32467;&#26524;&#30456;&#21563;&#21512;&#65292;&#25105;&#20204;&#35748;&#20026;&#23427;&#24212;&#35813;&#21462;&#20195;&#36125;&#21494;&#26031;&#20248;&#21270;&#36719;&#20214;&#21253;&#12289;&#25945;&#31243;&#21644;&#25945;&#26448;&#20013;&#30340;&#37027;&#20010;&#20844;&#24335;&#12290;&#36825;&#20010;&#25913;&#36827;&#30340;&#37319;&#38598;&#20989;&#25968;&#20026;&#26377;&#22122;&#22768;&#21644;&#26080;&#22122;&#22768;&#30340;&#35299;&#25552;&#20379;&#20102;&#33391;&#22909;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential maximization of expected improvement (EI) is one of the most widely used policies in Bayesian optimization because of its simplicity and ability to handle noisy observations. In particular, the improvement function often uses the best posterior mean as the best incumbent in noisy settings. However, the uncertainty associated with the incumbent solution is often neglected in many analytic EI-type methods: a closed-form acquisition function is derived in the noise-free setting, but then applied to the setting with noisy observations. To address this limitation, we propose a modification of EI that corrects its closed-form expression by incorporating the covariance information provided by the Gaussian Process (GP) model. This acquisition function specializes to the classical noise-free result, and we argue should replace that formula in Bayesian optimization software packages, tutorials, and textbooks. This enhanced acquisition provides good generality for noisy and noiseless s
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#39640;&#33021;&#30005;&#23376;-&#27491;&#30005;&#23376;&#30896;&#25758;&#20013;&#30340;&#31890;&#23376;&#27969;&#37325;&#24314;&#65292;&#20351;&#29992;&#21487;&#25193;&#23637;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#36229;&#21442;&#25968;&#35843;&#20248;&#21644;&#30828;&#20214;&#22788;&#29702;&#22120;&#30340;&#39640;&#24230;&#21487;&#31227;&#26893;&#24615;&#65292;&#21462;&#24471;&#20102;&#30495;&#23454;&#19988;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#29289;&#29702;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.06782</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#21644;&#21315;&#20806;&#32423;&#25968;&#25454;&#38598;&#29992;&#20110;&#31890;&#23376;&#27969;&#37325;&#24314;
&lt;/p&gt;
&lt;p&gt;
Scalable neural network models and terascale datasets for particle-flow reconstruction. (arXiv:2309.06782v1 [physics.data-an])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06782
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#39640;&#33021;&#30005;&#23376;-&#27491;&#30005;&#23376;&#30896;&#25758;&#20013;&#30340;&#31890;&#23376;&#27969;&#37325;&#24314;&#65292;&#20351;&#29992;&#21487;&#25193;&#23637;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#36229;&#21442;&#25968;&#35843;&#20248;&#21644;&#30828;&#20214;&#22788;&#29702;&#22120;&#30340;&#39640;&#24230;&#21487;&#31227;&#26893;&#24615;&#65292;&#21462;&#24471;&#20102;&#30495;&#23454;&#19988;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#29289;&#29702;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#39640;&#33021;&#30005;&#23376;-&#27491;&#30005;&#23376;&#30896;&#25758;&#20013;&#22522;&#20110;&#39640;&#24230;&#31890;&#24230;&#25506;&#27979;&#22120;&#27169;&#25311;&#30340;&#23436;&#25972;&#20107;&#20214;&#37325;&#24314;&#65292;&#30740;&#31350;&#20102;&#21487;&#25193;&#23637;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;&#31890;&#23376;&#27969;&#65288;PF&#65289;&#37325;&#24314;&#21487;&#36890;&#36807;&#36319;&#36394;&#21644;&#37327;&#33021;&#22120;&#22242;&#31751;&#25110;&#20987;&#20013;&#26469;&#26500;&#24314;&#30417;&#30563;&#23398;&#20064;&#20219;&#21153;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#21644;&#22522;&#20110;&#20869;&#26680;&#30340;&#21464;&#25442;&#22120;&#65292;&#24182;&#35777;&#26126;&#20004;&#32773;&#37117;&#36991;&#20813;&#20102;&#20108;&#27425;&#20869;&#23384;&#20998;&#37197;&#21644;&#35745;&#31639;&#25104;&#26412;&#65292;&#21516;&#26102;&#23454;&#29616;&#20102;&#30495;&#23454;&#30340;&#31890;&#23376;&#27969;&#37325;&#24314;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#36229;&#32423;&#35745;&#31639;&#26426;&#19978;&#36827;&#34892;&#30340;&#36229;&#21442;&#25968;&#35843;&#20248;&#26174;&#33879;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#29289;&#29702;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#25152;&#24471;&#27169;&#22411;&#22312;&#30828;&#20214;&#22788;&#29702;&#22120;&#19978;&#20855;&#26377;&#39640;&#24230;&#21487;&#31227;&#26893;&#24615;&#65292;&#25903;&#25345;NVIDIA, AMD&#21644;&#33521;&#29305;&#23572; Habana&#21345;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#27169;&#22411;&#21487;&#20197;&#22312;&#30001;&#36319;&#36394;&#21644;&#37327;&#33021;&#22120;&#20987;&#20013;&#32452;&#25104;&#30340;&#39640;&#31890;&#24230;&#36755;&#20837;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#20174;&#32780;&#33719;&#24471;&#19982;&#22522;&#20934;&#30456;&#31454;&#20105;&#30340;&#29289;&#29702;&#24615;&#33021;&#12290;&#26377;&#20851;&#22797;&#29616;&#30740;&#31350;&#30340;&#25968;&#25454;&#38598;&#21644;&#36719;&#20214;&#24050;&#21457;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study scalable machine learning models for full event reconstruction in high-energy electron-positron collisions based on a highly granular detector simulation. Particle-flow (PF) reconstruction can be formulated as a supervised learning task using tracks and calorimeter clusters or hits. We compare a graph neural network and kernel-based transformer and demonstrate that both avoid quadratic memory allocation and computational cost while achieving realistic PF reconstruction. We show that hyperparameter tuning on a supercomputer significantly improves the physics performance of the models. We also demonstrate that the resulting model is highly portable across hardware processors, supporting Nvidia, AMD, and Intel Habana cards. Finally, we demonstrate that the model can be trained on highly granular inputs consisting of tracks and calorimeter hits, resulting in a competitive physics performance with the baseline. Datasets and software to reproduce the studies are published following 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23558;&#26368;&#22823;&#22343;&#24046;&#30456;&#20284;&#24230;&#24212;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Radon-Kolmogorov-Smirnov&#65288;RKS&#65289;&#26816;&#39564;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#23558;&#26679;&#26412;&#22343;&#20540;&#24046;&#24322;&#26368;&#22823;&#21270;&#30340;&#38382;&#39064;&#25512;&#24191;&#21040;&#22810;&#32500;&#31354;&#38388;&#21644;&#26356;&#39640;&#24179;&#28369;&#24230;&#39034;&#24207;&#65292;&#21516;&#26102;&#19982;&#31070;&#32463;&#32593;&#32476;&#23494;&#20999;&#30456;&#20851;&#12290;</title><link>http://arxiv.org/abs/2309.02422</link><description>&lt;p&gt;
&#26368;&#22823;&#22343;&#24046;&#30456;&#20284;&#24230;&#36935;&#19978;&#31070;&#32463;&#32593;&#32476;&#65306;Radon-Kolmogorov-Smirnov&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Maximum Mean Discrepancy Meets Neural Networks: The Radon-Kolmogorov-Smirnov Test. (arXiv:2309.02422v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02422
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#26368;&#22823;&#22343;&#24046;&#30456;&#20284;&#24230;&#24212;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Radon-Kolmogorov-Smirnov&#65288;RKS&#65289;&#26816;&#39564;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#23558;&#26679;&#26412;&#22343;&#20540;&#24046;&#24322;&#26368;&#22823;&#21270;&#30340;&#38382;&#39064;&#25512;&#24191;&#21040;&#22810;&#32500;&#31354;&#38388;&#21644;&#26356;&#39640;&#24179;&#28369;&#24230;&#39034;&#24207;&#65292;&#21516;&#26102;&#19982;&#31070;&#32463;&#32593;&#32476;&#23494;&#20999;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#22823;&#22343;&#24046;&#30456;&#20284;&#24230;&#65288;MMD&#65289;&#26159;&#19968;&#31867;&#22522;&#20110;&#26368;&#22823;&#21270;&#20004;&#20010;&#20998;&#24067;$P$&#21644;$Q$&#20043;&#38388;&#26679;&#26412;&#22343;&#20540;&#24046;&#24322;&#30340;&#38750;&#21442;&#25968;&#21452;&#26679;&#26412;&#26816;&#39564;&#65292;&#20854;&#20013;&#32771;&#34385;&#20102;&#25152;&#26377;&#22312;&#26576;&#20010;&#20989;&#25968;&#31354;&#38388;$\mathcal{F}$&#20013;&#30340;&#25968;&#25454;&#21464;&#25442;$f$&#30340;&#36873;&#25321;&#12290;&#21463;&#21040;&#26368;&#36817;&#23558;&#25152;&#35859;&#30340;Radon&#26377;&#30028;&#21464;&#24046;&#20989;&#25968;&#65288;RBV&#65289;&#21644;&#31070;&#32463;&#32593;&#32476;&#32852;&#31995;&#36215;&#26469;&#30340;&#24037;&#20316;&#30340;&#21551;&#21457;&#65288;Parhi&#21644;Nowak, 2021, 2023&#65289;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#23558;$\mathcal{F}$&#21462;&#20026;&#32473;&#23450;&#24179;&#28369;&#24230;&#39034;&#24207;$k \geq 0$&#19979;&#30340;RBV&#31354;&#38388;&#20013;&#30340;&#21333;&#20301;&#29699;&#30340;MMD&#12290;&#36825;&#20010;&#26816;&#39564;&#34987;&#31216;&#20026;Radon-Kolmogorov-Smirnov&#65288;RKS&#65289;&#26816;&#39564;&#65292;&#21487;&#20197;&#30475;&#20316;&#26159;&#23545;&#22810;&#32500;&#31354;&#38388;&#21644;&#26356;&#39640;&#24179;&#28369;&#24230;&#39034;&#24207;&#30340;&#32463;&#20856;Kolmogorov-Smirnov&#65288;KS&#65289;&#26816;&#39564;&#30340;&#19968;&#33324;&#21270;&#12290;&#23427;&#36824;&#19982;&#31070;&#32463;&#32593;&#32476;&#23494;&#20999;&#30456;&#20851;&#65306;&#25105;&#20204;&#35777;&#26126;RKS&#26816;&#39564;&#20013;&#30340;&#35777;&#25454;&#20989;&#25968;$f$&#65292;&#21363;&#36798;&#21040;&#26368;&#22823;&#22343;&#24046;&#30340;&#20989;&#25968;&#65292;&#24635;&#26159;&#19968;&#20010;&#20108;&#27425;&#26679;&#26465;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Maximum mean discrepancy (MMD) refers to a general class of nonparametric two-sample tests that are based on maximizing the mean difference over samples from one distribution $P$ versus another $Q$, over all choices of data transformations $f$ living in some function space $\mathcal{F}$. Inspired by recent work that connects what are known as functions of $\textit{Radon bounded variation}$ (RBV) and neural networks (Parhi and Nowak, 2021, 2023), we study the MMD defined by taking $\mathcal{F}$ to be the unit ball in the RBV space of a given smoothness order $k \geq 0$. This test, which we refer to as the $\textit{Radon-Kolmogorov-Smirnov}$ (RKS) test, can be viewed as a generalization of the well-known and classical Kolmogorov-Smirnov (KS) test to multiple dimensions and higher orders of smoothness. It is also intimately connected to neural networks: we prove that the witness in the RKS test -- the function $f$ achieving the maximum mean difference -- is always a ridge spline of degree
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#22312;&#23384;&#22312;&#27169;&#22411;EMA&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20248;&#21270;&#30340;&#32553;&#25918;&#35268;&#21017;&#65292;&#20197;&#20445;&#25345;&#35757;&#32451;&#21160;&#24577;&#30340;&#19968;&#33268;&#24615;&#12290;&#36825;&#23545;&#20110;&#23454;&#38469;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#26435;&#34913;&#25209;&#37327;&#22823;&#23567;&#21644;&#22681;&#38047;&#26102;&#38388;&#38750;&#24120;&#37325;&#35201;&#12290;&#27169;&#22411;EMA&#33021;&#22815;&#25552;&#39640;&#27169;&#22411;&#30340;&#24615;&#33021;&#20197;&#21450;&#31283;&#23450;&#35757;&#32451;&#36807;&#31243;&#65292;&#24182;&#20026;&#33258;&#30417;&#30563;&#23398;&#20064;&#25552;&#20379;&#23398;&#20064;&#20449;&#21495;&#12290;</title><link>http://arxiv.org/abs/2307.13813</link><description>&lt;p&gt;
&#22914;&#20309;&#25193;&#23637;&#24744;&#30340;EMA&#65288;arXiv:2307.13813v1 [stat.ML]&#65289;
&lt;/p&gt;
&lt;p&gt;
How to Scale Your EMA. (arXiv:2307.13813v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13813
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#22312;&#23384;&#22312;&#27169;&#22411;EMA&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20248;&#21270;&#30340;&#32553;&#25918;&#35268;&#21017;&#65292;&#20197;&#20445;&#25345;&#35757;&#32451;&#21160;&#24577;&#30340;&#19968;&#33268;&#24615;&#12290;&#36825;&#23545;&#20110;&#23454;&#38469;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#26435;&#34913;&#25209;&#37327;&#22823;&#23567;&#21644;&#22681;&#38047;&#26102;&#38388;&#38750;&#24120;&#37325;&#35201;&#12290;&#27169;&#22411;EMA&#33021;&#22815;&#25552;&#39640;&#27169;&#22411;&#30340;&#24615;&#33021;&#20197;&#21450;&#31283;&#23450;&#35757;&#32451;&#36807;&#31243;&#65292;&#24182;&#20026;&#33258;&#30417;&#30563;&#23398;&#20064;&#25552;&#20379;&#23398;&#20064;&#20449;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#20445;&#25345;&#35757;&#32451;&#21160;&#24577;&#22312;&#25209;&#37327;&#22823;&#23567;&#20043;&#38388;&#30340;&#19968;&#33268;&#24615;&#26159;&#19968;&#31181;&#37325;&#35201;&#24037;&#20855;&#65292;&#23427;&#33021;&#22815;&#22312;&#25209;&#37327;&#22823;&#23567;&#21644;&#22681;&#38047;&#26102;&#38388;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#12290;&#36825;&#31181;&#26435;&#34913;&#36890;&#24120;&#36890;&#36807;&#19968;&#20010;&#32553;&#25918;&#35268;&#21017;&#26469;&#23454;&#29616;&#65292;&#20363;&#22914;&#65292;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20013;&#65292;&#24212;&#35813;&#23558;&#23398;&#20064;&#29575;&#19982;&#25209;&#37327;&#22823;&#23567;&#21576;&#32447;&#24615;&#20851;&#31995;&#12290;&#21478;&#19968;&#20010;&#23454;&#38469;&#26426;&#22120;&#23398;&#20064;&#30340;&#37325;&#35201;&#24037;&#20855;&#26159;&#27169;&#22411;&#25351;&#25968;&#31227;&#21160;&#24179;&#22343;&#65288;EMA&#65289;&#65292;&#23427;&#26159;&#19968;&#20010;&#19981;&#25509;&#25910;&#26799;&#24230;&#20449;&#24687;&#30340;&#27169;&#22411;&#21103;&#26412;&#65292;&#32780;&#26159;&#20197;&#19968;&#23450;&#30340;&#21160;&#37327;&#36319;&#38543;&#20854;&#30446;&#26631;&#27169;&#22411;&#12290;&#36825;&#20010;&#27169;&#22411;EMA&#21487;&#20197;&#25552;&#39640;&#30417;&#30563;&#23398;&#20064;&#30340;&#31283;&#20581;&#24615;&#21644;&#27867;&#21270;&#24615;&#33021;&#65292;&#31283;&#23450;&#20266;&#26631;&#35760;&#65292;&#20026;&#33258;&#30417;&#30563;&#23398;&#20064;&#25552;&#20379;&#23398;&#20064;&#20449;&#21495;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#23558;&#27169;&#22411;EMA&#19982;&#20248;&#21270;&#20998;&#24320;&#22788;&#29702;&#65292;&#23548;&#33268;&#25209;&#37327;&#22823;&#23567;&#20043;&#38388;&#23384;&#22312;&#19981;&#21516;&#30340;&#35757;&#32451;&#21160;&#24577;&#21644;&#36739;&#20302;&#30340;&#27169;&#22411;&#24615;&#33021;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#22312;&#23384;&#22312;&#27169;&#22411;EMA&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20248;&#21270;&#30340;&#32553;&#25918;&#35268;&#21017;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Preserving training dynamics across batch sizes is an important tool for practical machine learning as it enables the trade-off between batch size and wall-clock time. This trade-off is typically enabled by a scaling rule, for example, in stochastic gradient descent, one should scale the learning rate linearly with the batch size. Another important tool for practical machine learning is the model Exponential Moving Average (EMA), which is a model copy that does not receive gradient information, but instead follows its target model with some momentum. This model EMA can improve the robustness and generalization properties of supervised learning, stabilize pseudo-labeling, and provide a learning signal for Self-Supervised Learning (SSL). Prior works have treated the model EMA separately from optimization, leading to different training dynamics across batch sizes and lower model performance. In this work, we provide a scaling rule for optimization in the presence of model EMAs and demonst
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#20351;&#29992;&#32479;&#35745;&#29289;&#29702;&#23398;&#30340;&#27010;&#24565;&#65292;&#30740;&#31350;&#20102;&#26102;&#38388;&#24046;&#20998;&#23398;&#20064;&#22312;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#22120;&#19979;&#30340;&#20856;&#22411;&#23398;&#20064;&#26354;&#32447;&#12290;&#25105;&#20204;&#21457;&#29616;&#30001;&#20110;&#23376;&#37319;&#26679;&#21487;&#33021;&#30340;&#36712;&#36857;&#31354;&#38388;&#32780;&#20135;&#29983;&#30340;&#38543;&#26426;&#21322;&#26799;&#24230;&#22122;&#22768;&#20250;&#23548;&#33268;&#20540;&#35823;&#24046;&#20986;&#29616;&#26174;&#33879;&#30340;&#24179;&#21488;&#12290;</title><link>http://arxiv.org/abs/2307.04841</link><description>&lt;p&gt;
&#26102;&#38388;&#24046;&#20998;&#24378;&#21270;&#23398;&#20064;&#30340;&#21160;&#24577;
&lt;/p&gt;
&lt;p&gt;
Dynamics of Temporal Difference Reinforcement Learning. (arXiv:2307.04841v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04841
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20351;&#29992;&#32479;&#35745;&#29289;&#29702;&#23398;&#30340;&#27010;&#24565;&#65292;&#30740;&#31350;&#20102;&#26102;&#38388;&#24046;&#20998;&#23398;&#20064;&#22312;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#22120;&#19979;&#30340;&#20856;&#22411;&#23398;&#20064;&#26354;&#32447;&#12290;&#25105;&#20204;&#21457;&#29616;&#30001;&#20110;&#23376;&#37319;&#26679;&#21487;&#33021;&#30340;&#36712;&#36857;&#31354;&#38388;&#32780;&#20135;&#29983;&#30340;&#38543;&#26426;&#21322;&#26799;&#24230;&#22122;&#22768;&#20250;&#23548;&#33268;&#20540;&#35823;&#24046;&#20986;&#29616;&#26174;&#33879;&#30340;&#24179;&#21488;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#22312;&#38656;&#35201;&#23398;&#20064;&#22312;&#21453;&#39304;&#26377;&#38480;&#30340;&#29615;&#22659;&#20013;&#34892;&#21160;&#30340;&#22810;&#20010;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#26377;&#36825;&#31181;&#32463;&#39564;&#19978;&#30340;&#25104;&#21151;&#65292;&#20173;&#28982;&#27809;&#26377;&#23545;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#30340;&#21442;&#25968;&#21644;&#29992;&#20110;&#34920;&#31034;&#29366;&#24577;&#30340;&#29305;&#24449;&#22914;&#20309;&#30456;&#20114;&#20316;&#29992;&#25511;&#21046;&#23398;&#20064;&#21160;&#24577;&#30340;&#29702;&#35770;&#29702;&#35299;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#32479;&#35745;&#29289;&#29702;&#23398;&#30340;&#27010;&#24565;&#65292;&#30740;&#31350;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#22120;&#19979;&#26102;&#38388;&#24046;&#20998;&#23398;&#20064;&#20215;&#20540;&#20989;&#25968;&#30340;&#20856;&#22411;&#23398;&#20064;&#26354;&#32447;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#26159;&#22312;&#19968;&#20010;&#39640;&#26031;&#31561;&#25928;&#20551;&#35774;&#19979;&#25512;&#23548;&#20986;&#26469;&#30340;&#65292;&#20854;&#20013;&#23545;&#38543;&#26426;&#36712;&#36857;&#30340;&#24179;&#22343;&#20540;&#34987;&#26367;&#25442;&#20026;&#26102;&#24577;&#30456;&#20851;&#30340;&#39640;&#26031;&#29305;&#24449;&#24179;&#22343;&#20540;&#65292;&#24182;&#19988;&#25105;&#20204;&#22312;&#23567;&#35268;&#27169;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#19978;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#20551;&#35774;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#30001;&#20110;&#23545;&#21487;&#33021;&#30340;&#36712;&#36857;&#31354;&#38388;&#36827;&#34892;&#23376;&#37319;&#26679;&#32780;&#20135;&#29983;&#30340;&#38543;&#26426;&#21322;&#26799;&#24230;&#22122;&#22768;&#23548;&#33268;&#20540;&#35823;&#24046;&#20986;&#29616;&#26174;&#33879;&#30340;&#24179;&#21488;&#65292;&#36825;&#19982;&#20256;&#32479;&#30340;&#26799;&#24230;&#19979;&#38477;&#19981;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning has been successful across several applications in which agents have to learn to act in environments with sparse feedback. However, despite this empirical success there is still a lack of theoretical understanding of how the parameters of reinforcement learning models and the features used to represent states interact to control the dynamics of learning. In this work, we use concepts from statistical physics, to study the typical case learning curves for temporal difference learning of a value function with linear function approximators. Our theory is derived under a Gaussian equivalence hypothesis where averages over the random trajectories are replaced with temporally correlated Gaussian feature averages and we validate our assumptions on small scale Markov Decision Processes. We find that the stochastic semi-gradient noise due to subsampling the space of possible episodes leads to significant plateaus in the value error, unlike in traditional gradient descent 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#20248;&#36816;&#36755;&#21644;&#21464;&#20998;&#25512;&#26029;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36335;&#24452;&#31354;&#38388;&#25955;&#24230;&#30340;&#37319;&#26679;&#21644;&#29983;&#25104;&#24314;&#27169;&#26694;&#26550;&#12290;&#36890;&#36807;&#24320;&#21457;&#26032;&#39062;&#30340;&#22522;&#20110;&#24471;&#20998;&#30340;&#22238;&#28779;&#27969;&#25216;&#26415;&#21644;&#27491;&#21017;&#21270;&#30340;&#36845;&#20195;&#27604;&#20363;&#25311;&#21512;&#30446;&#26631;&#65292;&#26412;&#25991;&#23637;&#31034;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.01050</link><description>&lt;p&gt;
&#36816;&#36755;&#12289;&#21464;&#20998;&#25512;&#26029;&#21644;&#25193;&#25955;&#65306;&#24212;&#29992;&#20110;&#22238;&#28779;&#27969;&#21644;&#34203;&#23450;&#35860;&#26725;&#30340;&#35770;&#25991;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Transport, Variational Inference and Diffusions: with Applications to Annealed Flows and Schr\"odinger Bridges. (arXiv:2307.01050v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01050
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#20248;&#36816;&#36755;&#21644;&#21464;&#20998;&#25512;&#26029;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36335;&#24452;&#31354;&#38388;&#25955;&#24230;&#30340;&#37319;&#26679;&#21644;&#29983;&#25104;&#24314;&#27169;&#26694;&#26550;&#12290;&#36890;&#36807;&#24320;&#21457;&#26032;&#39062;&#30340;&#22522;&#20110;&#24471;&#20998;&#30340;&#22238;&#28779;&#27969;&#25216;&#26415;&#21644;&#27491;&#21017;&#21270;&#30340;&#36845;&#20195;&#27604;&#20363;&#25311;&#21512;&#30446;&#26631;&#65292;&#26412;&#25991;&#23637;&#31034;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#26368;&#20248;&#36816;&#36755;&#19982;&#21464;&#20998;&#25512;&#26029;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#37325;&#28857;&#30740;&#31350;&#20102;&#27491;&#21521;&#21644;&#21453;&#21521;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20197;&#21450;Girsanov&#21464;&#25442;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36335;&#24452;&#31354;&#38388;&#25955;&#24230;&#30340;&#37319;&#26679;&#21644;&#29983;&#25104;&#24314;&#27169;&#30340;&#21407;&#21017;&#24615;&#21644;&#31995;&#32479;&#24615;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#26368;&#32456;&#21457;&#23637;&#20986;&#19968;&#20010;&#26032;&#39062;&#30340;&#22522;&#20110;&#24471;&#20998;&#30340;&#22238;&#28779;&#27969;&#25216;&#26415;&#65288;&#19982;&#32479;&#35745;&#29289;&#29702;&#20013;&#30340;Jarzynski&#21644;Crooks&#24658;&#31561;&#24335;&#26377;&#20851;&#65289;&#21644;&#19968;&#20010;&#27491;&#21017;&#21270;&#30340;&#36845;&#20195;&#27604;&#20363;&#25311;&#21512;&#65288;IPF&#65289;&#22411;&#30446;&#26631;&#65292;&#19981;&#21516;&#20110;&#26631;&#20934;IPF&#30340;&#39034;&#24207;&#24615;&#12290;&#36890;&#36807;&#19968;&#31995;&#21015;&#30340;&#29983;&#25104;&#24314;&#27169;&#31034;&#20363;&#21644;&#22522;&#20110;&#21452;&#20117;&#30340;&#31232;&#26377;&#20107;&#20214;&#20219;&#21153;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores the connections between optimal transport and variational inference, with a focus on forward and reverse time stochastic differential equations and Girsanov transformations.We present a principled and systematic framework for sampling and generative modelling centred around divergences on path space. Our work culminates in the development of a novel score-based annealed flow technique (with connections to Jarzynski and Crooks identities from statistical physics) and a regularised iterative proportional fitting (IPF)-type objective, departing from the sequential nature of standard IPF. Through a series of generative modelling examples and a double-well-based rare event task, we showcase the potential of the proposed methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27604;&#36739;&#20102;&#22240;&#26524;&#26694;&#26550;&#20013;&#30340;&#28508;&#22312;&#32467;&#26524;&#27169;&#22411;(RCM)&#21644;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;(SCM)&#65292;&#24182;&#38416;&#26126;&#20102;RCM&#25104;&#20026;SCM&#21487;&#34920;&#36798;&#30340;&#26465;&#20214;&#65292;&#20197;&#21450;&#27599;&#20010;RCM&#20316;&#20026;&#26576;&#20123;&#21487;&#34920;&#36798;&#30340;RCM&#30340;&#25277;&#35937;&#12290;&#20316;&#32773;&#20171;&#32461;&#20102;SCM&#21407;&#21017;&#22312;RCM&#32463;&#20856;&#24212;&#29992;&#20013;&#30340;&#37325;&#35201;&#20316;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#30001;&#22270;&#34920;&#31034;&#30340;&#20195;&#25968;&#32422;&#26463;&#30340;&#29305;&#24449;&#65292;&#26377;&#21161;&#20110;&#36827;&#19968;&#27493;&#27604;&#36739;&#20004;&#20010;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2306.14351</link><description>&lt;p&gt;
&#27604;&#36739;&#22240;&#26524;&#26694;&#26550;&#65306;&#28508;&#22312;&#32467;&#26524;&#12289;&#32467;&#26500;&#27169;&#22411;&#12289;&#22270;&#21644;&#25277;&#35937;
&lt;/p&gt;
&lt;p&gt;
Comparing Causal Frameworks: Potential Outcomes, Structural Models, Graphs, and Abstractions. (arXiv:2306.14351v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14351
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27604;&#36739;&#20102;&#22240;&#26524;&#26694;&#26550;&#20013;&#30340;&#28508;&#22312;&#32467;&#26524;&#27169;&#22411;(RCM)&#21644;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;(SCM)&#65292;&#24182;&#38416;&#26126;&#20102;RCM&#25104;&#20026;SCM&#21487;&#34920;&#36798;&#30340;&#26465;&#20214;&#65292;&#20197;&#21450;&#27599;&#20010;RCM&#20316;&#20026;&#26576;&#20123;&#21487;&#34920;&#36798;&#30340;RCM&#30340;&#25277;&#35937;&#12290;&#20316;&#32773;&#20171;&#32461;&#20102;SCM&#21407;&#21017;&#22312;RCM&#32463;&#20856;&#24212;&#29992;&#20013;&#30340;&#37325;&#35201;&#20316;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#30001;&#22270;&#34920;&#31034;&#30340;&#20195;&#25968;&#32422;&#26463;&#30340;&#29305;&#24449;&#65292;&#26377;&#21161;&#20110;&#36827;&#19968;&#27493;&#27604;&#36739;&#20004;&#20010;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#38416;&#26126;&#28508;&#22312;&#32467;&#26524;&#27169;&#22411;&#65288;RCM&#65289;&#19982;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#65288;SCM&#65289;&#26694;&#26550;&#22312;&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#20851;&#31995;&#12290;&#37319;&#29992;&#20013;&#31435;&#30340;&#36923;&#36753;&#35270;&#35282;&#65292;&#20511;&#37492;&#20197;&#21069;&#30340;&#30740;&#31350;&#25104;&#26524;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;RCM&#25104;&#20026;SCM&#21487;&#34920;&#36798;&#30340;&#26465;&#20214;&#12290;&#19968;&#20010;&#20851;&#38190;&#32467;&#26524;&#26174;&#31034;&#65292;&#27599;&#20010;RCM -- &#21253;&#25324;&#37027;&#20123;&#36829;&#21453;SCM&#26694;&#26550;&#20013;&#26263;&#31034;&#30340;&#20195;&#25968;&#21407;&#21017;&#30340;RCM -- &#20316;&#20026;&#26576;&#20123;&#21487;&#34920;&#36798;&#30340;RCM&#30340;&#25277;&#35937;&#32780;&#20986;&#29616;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#20934;&#30830;&#23450;&#20301;SCM&#21407;&#21017;&#22312;RCM&#32463;&#20856;&#24212;&#29992;&#20013;&#30340;&#37325;&#35201;&#20316;&#29992;&#65292;&#38416;&#26126;&#20102;&#36825;&#31181;&#25913;&#36827;&#24615;&#35270;&#35282;&#30340;&#20248;&#21183;&#65307;&#21453;&#20043;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#30001;&#22270;&#34920;&#31034;&#30340;&#20195;&#25968;&#32422;&#26463;&#30340;&#29305;&#24449;&#65292;&#26377;&#21161;&#20110;&#36827;&#19968;&#27493;&#27604;&#36739;&#20004;&#20010;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
The aim of this paper is to make clear and precise the relationship between the Rubin causal model (RCM) and structural causal model (SCM) frameworks for causal inference. Adopting a neutral logical perspective, and drawing on previous work, we show what is required for an RCM to be representable by an SCM. A key result then shows that every RCM -- including those that violate algebraic principles implied by the SCM framework -- emerges as an abstraction of some representable RCM. Finally, we illustrate the power of this ameliorative perspective by pinpointing an important role for SCM principles in classic applications of RCMs; conversely, we offer a characterization of the algebraic constraints implied by a graph, helping to substantiate further comparisons between the two frameworks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#38454;&#30456;&#20114;&#20316;&#29992;&#30340;&#27979;&#37327;&#26041;&#27861;&#21644;&#22522;&#20110;&#26680;&#30340;&#27979;&#35797;&#26041;&#27861;&#65292;&#24182;&#19982;&#26684;&#29702;&#35770;&#24314;&#31435;&#20102;&#25968;&#23398;&#32852;&#31995;&#65292;&#20026;&#22686;&#24378;&#30456;&#20114;&#20316;&#29992;&#27169;&#22411;&#25552;&#20379;&#20102;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.00904</link><description>&lt;p&gt;
&#30456;&#20114;&#20316;&#29992;&#27979;&#37327;&#65292;&#20998;&#21306;&#26684;&#21644;&#26680;&#27979;&#35797;&#29992;&#20110;&#39640;&#38454;&#30456;&#20114;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Interaction Measures, Partition Lattices and Kernel Tests for High-Order Interactions. (arXiv:2306.00904v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00904
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#38454;&#30456;&#20114;&#20316;&#29992;&#30340;&#27979;&#37327;&#26041;&#27861;&#21644;&#22522;&#20110;&#26680;&#30340;&#27979;&#35797;&#26041;&#27861;&#65292;&#24182;&#19982;&#26684;&#29702;&#35770;&#24314;&#31435;&#20102;&#25968;&#23398;&#32852;&#31995;&#65292;&#20026;&#22686;&#24378;&#30456;&#20114;&#20316;&#29992;&#27169;&#22411;&#25552;&#20379;&#20102;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20165;&#20381;&#36182;&#20110;&#25104;&#23545;&#20851;&#31995;&#30340;&#27169;&#22411;&#24448;&#24448;&#26080;&#27861;&#25429;&#25417;&#21040;&#21508;&#31181;&#39046;&#22495;&#65288;&#22914;&#31038;&#20250;&#32463;&#27982;&#12289;&#29983;&#24577;&#25110;&#29983;&#29289;&#21307;&#23398;&#31995;&#32479;&#65289;&#20013;&#25214;&#21040;&#30340;&#22797;&#26434;&#22810;&#21464;&#37327;&#25968;&#25454;&#30340;&#23436;&#25972;&#32479;&#35745;&#32467;&#26500;&#12290;&#20004;&#20010;&#20197;&#19978;&#21464;&#37327;&#32452;&#20043;&#38388;&#30340;&#38750;&#24179;&#20961;&#20381;&#36182;&#20851;&#31995;&#22312;&#36825;&#20123;&#31995;&#32479;&#30340;&#20998;&#26512;&#21644;&#24314;&#27169;&#20013;&#21487;&#20197;&#21457;&#25381;&#37325;&#35201;&#20316;&#29992;&#65292;&#20294;&#20174;&#25968;&#25454;&#20013;&#25552;&#21462;&#36825;&#26679;&#30340;&#39640;&#38454;&#30456;&#20114;&#20316;&#29992;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31995;&#21015;$d$-order ($d \geq 2$)&#30456;&#20114;&#20316;&#29992;&#27979;&#37327;&#65292;&#20381;&#27425;&#21253;&#25324;&#21487;&#33021;&#30340;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#20998;&#35299;&#65292;&#24182;&#23450;&#20041;&#20102;&#38750;&#21442;&#25968;&#12289;&#22522;&#20110;&#26680;&#30340;&#27979;&#35797;&#65292;&#20197;&#31995;&#32479;&#22320;&#30830;&#23450;$d$-order&#30456;&#20114;&#20316;&#29992;&#30340;&#32479;&#35745;&#26174;&#30528;&#24615;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19982;&#26684;&#29702;&#35770;&#30340;&#25968;&#23398;&#32852;&#31995;&#65292;&#38416;&#26126;&#20102;&#30456;&#20114;&#20316;&#29992;&#24230;&#37327;&#30340;&#23548;&#20986;&#21450;&#20854;&#22797;&#21512;&#25490;&#21015;&#27979;&#35797;&#30340;&#28085;&#20041;&#65307;&#28548;&#28165;&#20102;&#21333;&#32431;&#22797;&#21512;&#20307;&#19982;&#26680;&#30697;&#38453;&#20013;&#24515;&#21270;&#30340;&#32852;&#31995;&#65307;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#22686;&#24378;&#30456;&#20114;&#20316;&#29992;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Models that rely solely on pairwise relationships often fail to capture the complete statistical structure of the complex multivariate data found in diverse domains, such as socio-economic, ecological, or biomedical systems. Non-trivial dependencies between groups of more than two variables can play a significant role in the analysis and modelling of such systems, yet extracting such high-order interactions from data remains challenging. Here, we introduce a hierarchy of $d$-order ($d \geq 2$) interaction measures, increasingly inclusive of possible factorisations of the joint probability distribution, and define non-parametric, kernel-based tests to establish systematically the statistical significance of $d$-order interactions. We also establish mathematical links with lattice theory, which elucidate the derivation of the interaction measures and their composite permutation tests; clarify the connection of simplicial complexes with kernel matrix centring; and provide a means to enhan
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;transformers&#22914;&#20309;&#24179;&#34913;&#20840;&#23616;&#20998;&#24067;&#21644;&#19978;&#19979;&#25991;&#29305;&#23450;&#20998;&#24067;&#30340;&#20004;&#31181;&#30693;&#35782;&#31867;&#22411;&#65292;&#24182;&#25552;&#20379;&#20102;&#26377;&#20851;&#26435;&#20540;&#30697;&#38453;&#20316;&#20026;&#32852;&#24819;&#35760;&#24518;&#30340;&#20316;&#29992;&#21450;&#26799;&#24230;&#22914;&#20309;&#23454;&#29616;&#26435;&#37325;&#23398;&#20064;&#30340;&#29702;&#35770;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2306.00802</link><description>&lt;p&gt;
&#19968;&#31181;&#35760;&#24518;&#35270;&#35282;&#19979;&#30340;Transformer&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Birth of a Transformer: A Memory Viewpoint. (arXiv:2306.00802v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00802
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;transformers&#22914;&#20309;&#24179;&#34913;&#20840;&#23616;&#20998;&#24067;&#21644;&#19978;&#19979;&#25991;&#29305;&#23450;&#20998;&#24067;&#30340;&#20004;&#31181;&#30693;&#35782;&#31867;&#22411;&#65292;&#24182;&#25552;&#20379;&#20102;&#26377;&#20851;&#26435;&#20540;&#30697;&#38453;&#20316;&#20026;&#32852;&#24819;&#35760;&#24518;&#30340;&#20316;&#29992;&#21450;&#26799;&#24230;&#22914;&#20309;&#23454;&#29616;&#26435;&#37325;&#23398;&#20064;&#30340;&#29702;&#35770;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;Transformer&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#23454;&#35777;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#23427;&#20204;&#34987;&#24191;&#27867;&#37096;&#32626;&#65292;&#36234;&#26469;&#36234;&#38656;&#35201;&#26356;&#22909;&#22320;&#29702;&#35299;&#23427;&#20204;&#30340;&#20869;&#37096;&#26426;&#21046;&#20197;&#20351;&#23427;&#20204;&#26356;&#21152;&#21487;&#38752;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;transformers&#22914;&#20309;&#36890;&#36807;&#32771;&#34385;&#19968;&#20010;&#21512;&#25104;&#30340;&#35774;&#32622;&#26469;&#24179;&#34913;&#23384;&#20648;&#20110;&#23427;&#20204;&#20043;&#20013;&#30340;&#20004;&#31181;&#30693;&#35782;&#31867;&#22411;&#8212;&#8212;&#20840;&#23616;&#20998;&#24067;&#21644;&#19978;&#19979;&#25991;&#29305;&#23450;&#30340;&#20108;&#20803;&#20998;&#24067;&#12290;&#36890;&#36807;&#23545;&#31616;&#21270;&#30340;&#20004;&#23618;Transformer&#30340;&#35757;&#32451;&#36807;&#31243;&#36827;&#34892;&#20180;&#32454;&#30340;&#23454;&#35777;&#20998;&#26512;&#65292;&#25105;&#20204;&#38416;&#36848;&#20102;&#23545;&#20840;&#23616;&#20108;&#20803;&#20998;&#24067;&#30340;&#24555;&#36895;&#23398;&#20064;&#20197;&#21450;&#23545;&#19978;&#19979;&#25991;&#20013;&#30340;&#20108;&#20803;&#20998;&#24067;&#30340;"&#24402;&#32435;&#22836;"&#26426;&#21046;&#30340;&#36739;&#24930;&#21457;&#23637;&#12290;&#25105;&#20204;&#24378;&#35843;&#20102;&#26435;&#20540;&#30697;&#38453;&#20316;&#20026;&#32852;&#24819;&#35760;&#24518;&#30340;&#20316;&#29992;&#65292;&#25552;&#20379;&#20102;&#29702;&#35770;&#19978;&#30340;&#35265;&#35299;&#65292;&#35828;&#26126;&#20102;&#26799;&#24230;&#22914;&#20309;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#23454;&#29616;&#26435;&#37325;&#30340;&#23398;&#20064;&#65292;&#24182;&#30740;&#31350;&#20102;&#25968;&#25454;&#20998;&#24067;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models based on transformers have achieved great empirical successes. However, as they are deployed more widely, there is a growing need to better understand their internal mechanisms in order to make them more reliable. These models appear to store vast amounts of knowledge from their training data, and to adapt quickly to new information provided in their context or prompt. We study how transformers balance these two types of knowledge by considering a synthetic setup where tokens are generated from either global or context-specific bigram distributions. By a careful empirical analysis of the training process on a simplified two-layer transformer, we illustrate the fast learning of global bigrams and the slower development of an "induction head" mechanism for the in-context bigrams. We highlight the role of weight matrices as associative memories, provide theoretical insights on how gradients enable their learning during training, and study the role of data-distributio
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#31934;&#30830;&#25512;&#29702;&#31163;&#25955;&#32479;&#35745;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#25903;&#25345;&#31163;&#25955;&#37319;&#26679;&#12289;&#36830;&#32493;&#37319;&#26679;&#12289;&#31163;&#25955;&#35266;&#27979;&#12289;&#20223;&#23556;&#20989;&#25968;&#12289;&#65288;&#38543;&#26426;&#65289;&#20998;&#25903;&#21644;&#20107;&#20214;&#26465;&#20214;&#12290;&#36890;&#36807;&#27010;&#29575;&#29983;&#25104;&#20989;&#25968;&#23454;&#29616;&#21518;&#39564;&#27010;&#29575;&#12289;&#26399;&#26395;&#12289;&#26041;&#24046;&#21644;&#39640;&#38454;&#30697;&#30340;&#31934;&#30830;&#35745;&#31639;&#12290;&#35813;&#26041;&#27861;&#24615;&#33021;&#20248;&#20110;&#36817;&#20284;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#65292;&#24182;&#36991;&#20813;&#20102;&#36817;&#20284;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2305.17058</link><description>&lt;p&gt;
&#36890;&#36807;&#27010;&#29575;&#29983;&#25104;&#20989;&#25968;&#30340;&#36125;&#21494;&#26031;&#31163;&#25955;&#27169;&#22411;&#31934;&#30830;&#25512;&#29702;&#65306;&#27010;&#29575;&#32534;&#31243;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Exact Bayesian Inference on Discrete Models via Probability Generating Functions: A Probabilistic Programming Approach. (arXiv:2305.17058v1 [cs.PL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17058
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#31934;&#30830;&#25512;&#29702;&#31163;&#25955;&#32479;&#35745;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#25903;&#25345;&#31163;&#25955;&#37319;&#26679;&#12289;&#36830;&#32493;&#37319;&#26679;&#12289;&#31163;&#25955;&#35266;&#27979;&#12289;&#20223;&#23556;&#20989;&#25968;&#12289;&#65288;&#38543;&#26426;&#65289;&#20998;&#25903;&#21644;&#20107;&#20214;&#26465;&#20214;&#12290;&#36890;&#36807;&#27010;&#29575;&#29983;&#25104;&#20989;&#25968;&#23454;&#29616;&#21518;&#39564;&#27010;&#29575;&#12289;&#26399;&#26395;&#12289;&#26041;&#24046;&#21644;&#39640;&#38454;&#30697;&#30340;&#31934;&#30830;&#35745;&#31639;&#12290;&#35813;&#26041;&#27861;&#24615;&#33021;&#20248;&#20110;&#36817;&#20284;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#65292;&#24182;&#36991;&#20813;&#20102;&#36817;&#20284;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31163;&#25955;&#32479;&#35745;&#27169;&#22411;&#30340;&#31934;&#30830;&#36125;&#21494;&#26031;&#25512;&#29702;&#26041;&#27861;&#65292;&#21363;&#20351;&#26159;&#23545;&#20110;&#26080;&#38480;&#25903;&#25345;&#21644;&#36830;&#32493;&#20808;&#39564;&#20063;&#21487;&#20197;&#25214;&#21040;&#20934;&#30830;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#20026;&#20102;&#34920;&#36798;&#36825;&#26679;&#30340;&#27169;&#22411;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#25903;&#25345;&#31163;&#25955;&#21644;&#36830;&#32493;&#37319;&#26679;&#12289;&#31163;&#25955;&#35266;&#27979;&#12289;&#20223;&#23556;&#20989;&#25968;&#12289;&#65288;&#38543;&#26426;&#65289;&#20998;&#25903;&#21644;&#20107;&#20214;&#26465;&#20214;&#30340;&#27010;&#29575;&#32534;&#31243;&#35821;&#35328;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#24037;&#20855;&#26159;&#27010;&#29575;&#29983;&#25104;&#20989;&#25968;&#65306;&#23427;&#20204;&#25552;&#20379;&#20102;&#23450;&#20041;&#31243;&#24207;&#30340;&#20998;&#24067;&#30340;&#32039;&#20945;&#38381;&#21512;&#24418;&#24335;&#34920;&#31034;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#21518;&#39564;&#27010;&#29575;&#12289;&#26399;&#26395;&#12289;&#26041;&#24046;&#21644;&#39640;&#38454;&#30697;&#30340;&#31934;&#30830;&#35745;&#31639;&#12290;&#25105;&#20204;&#30340;&#25512;&#29702;&#26041;&#27861;&#26159;&#21487;&#35777;&#26126;&#27491;&#30830;&#30340;&#12289;&#23436;&#20840;&#33258;&#21160;&#21270;&#30340;&#65292;&#20351;&#29992;&#33258;&#21160;&#24494;&#20998;&#65288;&#29305;&#21035;&#26159;&#27888;&#21202;&#22810;&#39033;&#24335;&#65289;&#65292;&#20294;&#19981;&#38656;&#35201;&#35745;&#31639;&#26426;&#20195;&#25968;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#23427;&#22312;&#19968;&#31995;&#21015;&#30495;&#23454;&#19990;&#30028;&#30340;&#20363;&#23376;&#20013;&#30340;&#24615;&#33021;&#19982;&#36817;&#20284;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#31454;&#20105;&#65292;&#21516;&#26102;&#36991;&#20813;&#20102;&#36817;&#20284;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present an exact Bayesian inference method for discrete statistical models, which can find exact solutions to many discrete inference problems, even with infinite support and continuous priors. To express such models, we introduce a probabilistic programming language that supports discrete and continuous sampling, discrete observations, affine functions, (stochastic) branching, and conditioning on events. Our key tool is probability generating functions: they provide a compact closed-form representation of distributions that are definable by programs, thus enabling the exact computation of posterior probabilities, expectation, variance, and higher moments. Our inference method is provably correct, fully automated and uses automatic differentiation (specifically, Taylor polynomials), but does not require computer algebra. Our experiments show that its performance on a range of real-world examples is competitive with approximate Monte Carlo methods, while avoiding approximation errors
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#22343;&#20540;&#28418;&#31227;&#31639;&#27861;&#30340;&#27169;&#20272;&#35745;&#24207;&#21015;&#30340;&#25910;&#25947;&#20445;&#35777;&#65292;&#24182;&#25193;&#23637;&#20102;&#29616;&#26377;&#30340;&#28085;&#30422;&#35299;&#26512;&#26680;&#21644;Epanechnikov&#26680;&#30340;&#21457;&#29616;&#65292;&#24847;&#20041;&#22312;&#20110;&#28085;&#30422;&#20102;&#22312;&#22522;&#20110;KDE&#30340;&#27169;&#20272;&#35745;&#30340;&#28176;&#36817;&#32479;&#35745;&#25928;&#29575;&#26041;&#38754;&#26368;&#20248;&#30340;&#38750;&#36127;&#26680;&#8212;&#8212;&#21452;&#37325;&#26680;&#12290;</title><link>http://arxiv.org/abs/2305.08463</link><description>&lt;p&gt;
&#22343;&#20540;&#28418;&#31227;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Convergence Analysis of Mean Shift. (arXiv:2305.08463v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08463
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#22343;&#20540;&#28418;&#31227;&#31639;&#27861;&#30340;&#27169;&#20272;&#35745;&#24207;&#21015;&#30340;&#25910;&#25947;&#20445;&#35777;&#65292;&#24182;&#25193;&#23637;&#20102;&#29616;&#26377;&#30340;&#28085;&#30422;&#35299;&#26512;&#26680;&#21644;Epanechnikov&#26680;&#30340;&#21457;&#29616;&#65292;&#24847;&#20041;&#22312;&#20110;&#28085;&#30422;&#20102;&#22312;&#22522;&#20110;KDE&#30340;&#27169;&#20272;&#35745;&#30340;&#28176;&#36817;&#32479;&#35745;&#25928;&#29575;&#26041;&#38754;&#26368;&#20248;&#30340;&#38750;&#36127;&#26680;&#8212;&#8212;&#21452;&#37325;&#26680;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22343;&#20540;&#28418;&#31227;&#65288;MS&#65289;&#31639;&#27861;&#23547;&#25214;&#26680;&#23494;&#24230;&#20272;&#35745;&#65288;KDE&#65289;&#30340;&#27169;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#30001;MS&#31639;&#27861;&#20135;&#29983;&#30340;&#27169;&#20272;&#35745;&#24207;&#21015;&#30340;&#25910;&#25947;&#20445;&#35777;&#65292;&#24182;&#22312;&#30456;&#24403;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#65292;&#20511;&#21161;&#20110;&#20851;&#20110;{\L}ojasiewicz&#19981;&#31561;&#24335;&#30340;&#35770;&#35777;&#65292;&#35780;&#20272;&#20102;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#25193;&#23637;&#20102;&#29616;&#26377;&#30340;&#28085;&#30422;&#35299;&#26512;&#26680;&#21644;Epanechnikov&#26680;&#30340;&#21457;&#29616;&#65292;&#24847;&#20041;&#22312;&#20110;&#28085;&#30422;&#20102;&#22312;&#22522;&#20110;KDE&#30340;&#27169;&#20272;&#35745;&#30340;&#28176;&#36817;&#32479;&#35745;&#25928;&#29575;&#26041;&#38754;&#26368;&#20248;&#30340;&#38750;&#36127;&#26680;&#8212;&#8212;&#21452;&#37325;&#26680;&#12290;
&lt;/p&gt;
&lt;p&gt;
The mean shift (MS) algorithm seeks a mode of the kernel density estimate (KDE). This study presents a convergence guarantee of the mode estimate sequence generated by the MS algorithm and an evaluation of the convergence rate, under fairly mild conditions, with the help of the argument concerning the {\L}ojasiewicz inequality. Our findings, which extend existing ones covering analytic kernels and the Epanechnikov kernel, are significant in that they cover the biweight kernel that is optimal among non-negative kernels in terms of the asymptotic statistical efficiency for the KDE-based mode estimation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;Adam&#31639;&#27861;&#20570;&#20102;&#26032;&#30340;&#20551;&#35774;&#24182;&#36827;&#34892;&#20102;&#35777;&#26126;&#65292;&#35777;&#26126;&#20102;&#22312;&#26356;&#21152;&#29616;&#23454;&#30340;&#26465;&#20214;&#19979;&#65292;Adam&#33021;&#22815;&#20197;&#36739;&#23567;&#30340;&#26799;&#24230;&#22797;&#26434;&#24230;&#36798;&#21040;&#31283;&#23450;&#28857;&#12290;</title><link>http://arxiv.org/abs/2304.13972</link><description>&lt;p&gt;
&#26494;&#24347;&#20551;&#35774;&#19979;Adam&#25910;&#25947;&#24615;&#30340;&#35777;&#26126;
&lt;/p&gt;
&lt;p&gt;
Convergence of Adam Under Relaxed Assumptions. (arXiv:2304.13972v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13972
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;Adam&#31639;&#27861;&#20570;&#20102;&#26032;&#30340;&#20551;&#35774;&#24182;&#36827;&#34892;&#20102;&#35777;&#26126;&#65292;&#35777;&#26126;&#20102;&#22312;&#26356;&#21152;&#29616;&#23454;&#30340;&#26465;&#20214;&#19979;&#65292;Adam&#33021;&#22815;&#20197;&#36739;&#23567;&#30340;&#26799;&#24230;&#22797;&#26434;&#24230;&#36798;&#21040;&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#19968;&#31867;&#24191;&#27867;&#30340;&#20248;&#21270;&#30446;&#26631;&#65292;&#23545;&#33258;&#36866;&#24212;&#30697;&#20272;&#35745;&#65288;Adam&#65289;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#36827;&#34892;&#20102;&#20005;&#26684;&#35777;&#26126;&#12290;&#34429;&#28982;Adam&#31639;&#27861;&#22312;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#27969;&#34892;&#24230;&#21644;&#25928;&#29575;&#24456;&#39640;&#65292;&#20294;&#20854;&#29702;&#35770;&#24615;&#36136;&#23578;&#26410;&#23436;&#20840;&#29702;&#35299;&#65292;&#29616;&#26377;&#30340;&#25910;&#25947;&#24615;&#35777;&#26126;&#38656;&#35201;&#36807;&#20110;&#24378;&#30340;&#20551;&#35774;&#65292;&#22914;&#20840;&#23616;&#26799;&#24230;&#26377;&#30028;&#65292;&#20197;&#35777;&#26126;&#25910;&#25947;&#21040;&#31283;&#23450;&#28857;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;&#22312;&#26356;&#20026;&#29616;&#23454;&#30340;&#26465;&#20214;&#19979;&#65292;Adam&#33021;&#20197;$\mathcal{O}(\epsilon^{-4})$&#26799;&#24230;&#22797;&#26434;&#24230;&#25910;&#25947;&#21040;$\epsilon$-&#31283;&#23450;&#28857;&#12290;&#25105;&#20204;&#20998;&#26512;&#30340;&#20851;&#38190;&#26159;&#26681;&#25454;&#19968;&#31181;&#24191;&#20041;&#20809;&#28369;&#24615;&#20551;&#35774;&#32473;&#20986;&#30340;&#65292;&#27839;&#30528;&#20248;&#21270;&#36712;&#36857;&#30340;&#26799;&#24230;&#26377;&#30028;&#30340;&#26032;&#35777;&#26126;&#12290;&#26681;&#25454;&#35813;&#20551;&#35774;&#65292;&#23616;&#37096;&#20809;&#28369;&#24615;(&#21363;&#23384;&#22312;&#26102;&#30340;Hessian norm)&#21463;&#26799;&#24230;&#33539;&#25968;&#30340;&#27425;&#24179;&#26041;&#20989;&#25968;&#38480;&#21046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#24046;&#32422;&#20943;&#29256;&#26412;&#30340;Adam&#19982;&#21152;&#36895;Gradient&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we provide a rigorous proof of convergence of the Adaptive Moment Estimate (Adam) algorithm for a wide class of optimization objectives. Despite the popularity and efficiency of the Adam algorithm in training deep neural networks, its theoretical properties are not yet fully understood, and existing convergence proofs require unrealistically strong assumptions, such as globally bounded gradients, to show the convergence to stationary points. In this paper, we show that Adam provably converges to $\epsilon$-stationary points with $\mathcal{O}(\epsilon^{-4})$ gradient complexity under far more realistic conditions. The key to our analysis is a new proof of boundedness of gradients along the optimization trajectory, under a generalized smoothness assumption according to which the local smoothness (i.e., Hessian norm when it exists) is bounded by a sub-quadratic function of the gradient norm. Moreover, we propose a variance-reduced version of Adam with an accelerated gradien
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#23485;&#20294;&#26377;&#38480;&#30340;&#29305;&#24449;&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#20013;&#26377;&#38480;&#23485;&#24230;&#25928;&#24212;&#30340;&#21160;&#21147;&#23398;&#65292;&#25552;&#20379;&#20102;&#23545;&#32593;&#32476;&#26435;&#37325;&#38543;&#26426;&#21021;&#22987;&#21270;&#19979;DMFT&#24207;&#21442;&#25968;&#27874;&#21160;&#30340;&#34920;&#24449;&#20197;&#21450;&#29305;&#24449;&#23398;&#20064;&#22914;&#20309;&#21160;&#24577;&#22320;&#20943;&#23569;&#26368;&#32456;NTK&#21644;&#26368;&#32456;&#32593;&#32476;&#39044;&#27979;&#30340;&#26041;&#24046;&#12290;</title><link>http://arxiv.org/abs/2304.03408</link><description>&lt;p&gt;
&#26377;&#38480;&#23485;&#24230;&#26680;&#21644;&#24179;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#39044;&#27979;&#27874;&#21160;&#21160;&#21147;&#23398;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Dynamics of Finite Width Kernel and Prediction Fluctuations in Mean Field Neural Networks. (arXiv:2304.03408v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03408
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#23485;&#20294;&#26377;&#38480;&#30340;&#29305;&#24449;&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#20013;&#26377;&#38480;&#23485;&#24230;&#25928;&#24212;&#30340;&#21160;&#21147;&#23398;&#65292;&#25552;&#20379;&#20102;&#23545;&#32593;&#32476;&#26435;&#37325;&#38543;&#26426;&#21021;&#22987;&#21270;&#19979;DMFT&#24207;&#21442;&#25968;&#27874;&#21160;&#30340;&#34920;&#24449;&#20197;&#21450;&#29305;&#24449;&#23398;&#20064;&#22914;&#20309;&#21160;&#24577;&#22320;&#20943;&#23569;&#26368;&#32456;NTK&#21644;&#26368;&#32456;&#32593;&#32476;&#39044;&#27979;&#30340;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20998;&#26512;&#20102;&#23485;&#20294;&#26377;&#38480;&#30340;&#29305;&#24449;&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#20013;&#26377;&#38480;&#23485;&#24230;&#25928;&#24212;&#30340;&#21160;&#21147;&#23398;&#12290;&#19982;&#35768;&#22810;&#20808;&#21069;&#30340;&#20998;&#26512;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#26159;&#38024;&#23545;&#29305;&#24449;&#23398;&#20064;&#24378;&#24230;&#30340;&#38750;&#24494;&#25200;&#26377;&#38480;&#23485;&#24230;&#30340;&#32467;&#26524;&#12290;&#20174;&#26080;&#38480;&#23485;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26680;&#21644;&#39044;&#27979;&#21160;&#21147;&#23398;&#30340;&#21160;&#21147;&#23398;&#24179;&#22343;&#22330;&#29702;&#35770;&#65288;DMFT&#65289;&#25551;&#36848;&#24320;&#22987;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#32593;&#32476;&#26435;&#37325;&#30340;&#38543;&#26426;&#21021;&#22987;&#21270;&#19979;DMFT&#24207;&#21442;&#25968;$\mathcal{O}(1/\sqrt{\text{width}})$&#27874;&#21160;&#30340;&#34920;&#24449;&#12290;&#22312;&#32593;&#32476;&#35757;&#32451;&#30340;&#25042;&#24816;&#26497;&#38480;&#20013;&#65292;&#25152;&#26377;&#26680;&#37117;&#26159;&#38543;&#26426;&#30340;&#20294;&#22312;&#26102;&#38388;&#19978;&#38745;&#27490;&#30340;&#65292;&#39044;&#27979;&#26041;&#24046;&#20855;&#26377;&#36890;&#29992;&#24418;&#24335;&#12290;&#28982;&#32780;&#65292;&#22312;&#23500;&#26377;&#29305;&#24449;&#23398;&#20064;&#30340;&#21306;&#22495;&#65292;&#26680;&#21644;&#39044;&#27979;&#30340;&#27874;&#21160;&#26159;&#21160;&#24577;&#32806;&#21512;&#19988;&#26041;&#24046;&#21487;&#20197;&#34987;&#33258;&#27965;&#35745;&#31639;&#12290;&#22312;&#20004;&#23618;&#32593;&#32476;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#29305;&#24449;&#23398;&#20064;&#22914;&#20309;&#21160;&#24577;&#22320;&#20943;&#23569;&#26368;&#32456;NTK&#21644;&#26368;&#32456;&#32593;&#32476;&#39044;&#27979;&#30340;&#26041;&#24046;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#36827;&#34892;&#21021;&#22987;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyze the dynamics of finite width effects in wide but finite feature learning neural networks. Unlike many prior analyses, our results, while perturbative in width, are non-perturbative in the strength of feature learning. Starting from a dynamical mean field theory (DMFT) description of infinite width deep neural network kernel and prediction dynamics, we provide a characterization of the $\mathcal{O}(1/\sqrt{\text{width}})$ fluctuations of the DMFT order parameters over random initialization of the network weights. In the lazy limit of network training, all kernels are random but static in time and the prediction variance has a universal form. However, in the rich, feature learning regime, the fluctuations of the kernels and predictions are dynamically coupled with variance that can be computed self-consistently. In two layer networks, we show how feature learning can dynamically reduce the variance of the final NTK and final network predictions. We also show how initialization
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#26410;&#30693;&#20855;&#26377;&#28508;&#22312;&#29366;&#24577;&#31995;&#32479;&#30340;&#23398;&#20064;&#20248;&#21270;&#25511;&#21046;&#26041;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#27010;&#29575;&#24615;&#33021;&#20445;&#35777;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#39564;&#35777;&#20219;&#24847;&#25511;&#21046;&#24459;&#24615;&#33021;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2303.17963</link><description>&lt;p&gt;
&#38754;&#21521;&#26410;&#30693;&#20855;&#26377;&#28508;&#22312;&#29366;&#24577;&#31995;&#32479;&#30340;&#23398;&#20064;&#20248;&#21270;&#25511;&#21046;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Learning-Based Optimal Control with Performance Guarantees for Unknown Systems with Latent States. (arXiv:2303.17963v1 [eess.SY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17963
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#26410;&#30693;&#20855;&#26377;&#28508;&#22312;&#29366;&#24577;&#31995;&#32479;&#30340;&#23398;&#20064;&#20248;&#21270;&#25511;&#21046;&#26041;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#27010;&#29575;&#24615;&#33021;&#20445;&#35777;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#39564;&#35777;&#20219;&#24847;&#25511;&#21046;&#24459;&#24615;&#33021;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#25511;&#21046;&#24037;&#31243;&#26041;&#27861;&#24212;&#29992;&#20110;&#36234;&#26469;&#36234;&#22797;&#26434;&#30340;&#31995;&#32479;&#65292;&#25968;&#25454;&#39537;&#21160;&#30340;&#31995;&#32479;&#36776;&#35782;&#26041;&#27861;&#25104;&#20026;&#29289;&#29702;&#24314;&#27169;&#30340;&#26377;&#24076;&#26395;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#36825;&#20123;&#26041;&#27861;&#20381;&#36182;&#20110;&#29366;&#24577;&#27979;&#37327;&#30340;&#21487;&#29992;&#24615;&#65292;&#32780;&#22797;&#26434;&#31995;&#32479;&#30340;&#29366;&#24577;&#36890;&#24120;&#19981;&#26159;&#30452;&#25509;&#21487;&#27979;&#37327;&#30340;&#12290;&#22240;&#27492;&#65292;&#21487;&#33021;&#38656;&#35201;&#21516;&#26102;&#20272;&#35745;&#21160;&#21147;&#23398;&#21644;&#28508;&#22312;&#29366;&#24577;&#65292;&#20174;&#32780;&#26356;&#21152;&#20855;&#26377;&#25361;&#25112;&#24615;&#22320;&#35774;&#35745;&#20855;&#26377;&#24615;&#33021;&#20445;&#35777;&#30340;&#25511;&#21046;&#22120;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#35745;&#31639;&#20855;&#26377;&#28508;&#22312;&#29366;&#24577;&#30340;&#26410;&#30693;&#38750;&#32447;&#24615;&#31995;&#32479;&#30340;&#26368;&#20248;&#36755;&#20837;&#36712;&#36857;&#12290;&#23545;&#32467;&#26524;&#36755;&#20837;&#36712;&#36857;&#36827;&#34892;&#20102;&#27010;&#29575;&#24615;&#33021;&#20445;&#35777;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#39564;&#35777;&#20219;&#24847;&#25511;&#21046;&#24459;&#24615;&#33021;&#30340;&#26041;&#27861;&#12290;&#26412;&#25991;&#22312;&#25968;&#20540;&#27169;&#25311;&#20013;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
As control engineering methods are applied to increasingly complex systems, data-driven approaches for system identification appear as a promising alternative to physics-based modeling. While many of these approaches rely on the availability of state measurements, the states of a complex system are often not directly measurable. It may then be necessary to jointly estimate the dynamics and a latent state, making it considerably more challenging to design controllers with performance guarantees. This paper proposes a novel method for the computation of an optimal input trajectory for unknown nonlinear systems with latent states. Probabilistic performance guarantees are derived for the resulting input trajectory, and an approach to validate the performance of arbitrary control laws is presented. The effectiveness of the proposed method is demonstrated in a numerical simulation.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#33268;&#21147;&#20110;&#35299;&#20915;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#28151;&#28102;&#21464;&#37327;&#23548;&#33268;&#31574;&#30053;&#35780;&#20272;&#21644;&#20248;&#21270;&#23384;&#22312;&#25361;&#25112;&#30340;&#38382;&#39064;&#65292;&#21253;&#25324;&#26080;&#27861;&#33719;&#24471;&#19968;&#33268;&#20215;&#20540;&#20272;&#35745;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#20445;&#35777;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#20855;&#26377;&#20445;&#35777;&#30340;&#19979;&#38480;&#31639;&#27861;&#21644;&#23616;&#37096;&#25910;&#25947;&#30340;&#25913;&#36827;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2211.16583</link><description>&lt;p&gt;
&#22312;&#28151;&#28102;&#19979;&#30340;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#21644;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Offline Policy Evaluation and Optimization under Confounding. (arXiv:2211.16583v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.16583
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#33268;&#21147;&#20110;&#35299;&#20915;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#28151;&#28102;&#21464;&#37327;&#23548;&#33268;&#31574;&#30053;&#35780;&#20272;&#21644;&#20248;&#21270;&#23384;&#22312;&#25361;&#25112;&#30340;&#38382;&#39064;&#65292;&#21253;&#25324;&#26080;&#27861;&#33719;&#24471;&#19968;&#33268;&#20215;&#20540;&#20272;&#35745;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#20445;&#35777;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#20855;&#26377;&#20445;&#35777;&#30340;&#19979;&#38480;&#31639;&#27861;&#21644;&#23616;&#37096;&#25910;&#25947;&#30340;&#25913;&#36827;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#35780;&#20272;&#21644;&#20248;&#21270;&#31574;&#30053;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#21464;&#37327;&#26102;&#26159;&#19968;&#20010;&#22791;&#21463;&#20851;&#27880;&#30340;&#38382;&#39064;&#12290;&#20351;&#29992;&#20256;&#32479;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#26469;&#22788;&#29702;&#28151;&#28102;&#38382;&#39064;&#19981;&#20165;&#21487;&#33021;&#23548;&#33268;&#31967;&#31957;&#30340;&#20915;&#31574;&#21644;&#31574;&#30053;&#65292;&#32780;&#19988;&#22312;&#20851;&#38190;&#24212;&#29992;&#39046;&#22495;&#22914;&#21307;&#30103;&#21644;&#25945;&#32946;&#20013;&#21487;&#33021;&#20250;&#20135;&#29983;&#28798;&#38590;&#24615;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#21246;&#21202;&#20102;&#28151;&#28102;&#30340; MDP &#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#30340;&#38754;&#35980;&#65292;&#24182;&#26681;&#25454;&#28151;&#28102;&#23545;&#25968;&#25454;&#25910;&#38598;&#31574;&#30053;&#30340;&#26102;&#38388;&#28436;&#21464;&#21644;&#24433;&#21709;&#26469;&#21306;&#20998;&#28151;&#28102;&#30340;&#20551;&#35774;&#12290;&#22312;&#19968;&#20123;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#19968;&#20123;&#26080;&#27861;&#33719;&#24471;&#19968;&#33268;&#20215;&#20540;&#20272;&#35745;&#30340;&#24773;&#20917;&#65292;&#24182;&#25552;&#20379;&#21644;&#35752;&#35770;&#20102;&#35745;&#31639;&#20855;&#26377;&#20445;&#35777;&#30340;&#19979;&#38480;&#30340;&#31639;&#27861;&#12290;&#24403;&#19968;&#33268;&#30340;&#20272;&#35745;&#21487;&#34892;&#26102;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#20445;&#35777;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#26032;&#30340;&#31163;&#32447;&#31574;&#30053;&#25913;&#36827;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#23616;&#37096;&#25910;&#25947;&#30340;&#20445;&#35777;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22312;&#26684;&#23376;&#19990;&#30028;&#21644;&#27169;&#25311;&#21307;&#30103;&#22330;&#26223;&#20013;&#23545;&#31639;&#27861;&#36827;&#34892;&#20102;&#23454;&#39564;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Evaluating and optimizing policies in the presence of unobserved confounders is a problem of growing interest in offline reinforcement learning. Using conventional methods for offline RL in the presence of confounding can not only lead to poor decisions and poor policies, but can also have disastrous effects in critical applications such as healthcare and education. We map out the landscape of offline policy evaluation for confounded MDPs, distinguishing assumptions on confounding based on their time-evolution and effect on the data-collection policies. We determine when consistent value estimates are not achievable, providing and discussing algorithms to estimate lower bounds with guarantees in those cases. When consistent estimates are achievable, we provide sample complexity guarantees. We also present new algorithms for offline policy improvement and prove local convergence guarantees. Finally, we experimentally evaluate our algorithms on gridworld and a simulated healthcare settin
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#38750;&#20984;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#30340;&#22359;&#20027;&#23548;&#26497;&#23567;&#21270;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#20351;&#29992;&#24378;&#20984;&#26367;&#20195;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#22312;&#19968;&#23450;&#36845;&#20195;&#27425;&#25968;&#20869;&#25910;&#25947;&#21040;&#19968;&#20010;&#31283;&#23450;&#28857;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#20449;&#20219;&#22495;&#21464;&#20307;&#65292;&#21487;&#20197;&#22788;&#29702;&#21482;&#20855;&#22791;&#20984;&#24615;&#30340;&#26367;&#20195;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2012.03503</link><description>&lt;p&gt;
&#24102;&#26377;&#36882;&#20943;&#21322;&#24452;&#30340;&#22359;&#20027;&#23548;&#26497;&#23567;&#21270;&#26041;&#27861;&#29992;&#20110;&#32422;&#26463;&#38750;&#20984;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Block majorization-minimization with diminishing radius for constrained nonconvex optimization. (arXiv:2012.03503v4 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2012.03503
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#38750;&#20984;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#30340;&#22359;&#20027;&#23548;&#26497;&#23567;&#21270;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#20351;&#29992;&#24378;&#20984;&#26367;&#20195;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#22312;&#19968;&#23450;&#36845;&#20195;&#27425;&#25968;&#20869;&#25910;&#25947;&#21040;&#19968;&#20010;&#31283;&#23450;&#28857;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#20449;&#20219;&#22495;&#21464;&#20307;&#65292;&#21487;&#20197;&#22788;&#29702;&#21482;&#20855;&#22791;&#20984;&#24615;&#30340;&#26367;&#20195;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22359;&#20027;&#23548;&#26497;&#23567;&#21270;&#65288;BMM&#65289;&#26159;&#19968;&#31181;&#31616;&#21333;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#29992;&#20110;&#38750;&#20984;&#32422;&#26463;&#20248;&#21270;&#65292;&#22312;&#27599;&#20010;&#22359;&#22352;&#26631;&#19978;&#39034;&#24207;&#26368;&#23567;&#21270;&#30446;&#26631;&#20989;&#25968;&#30340;&#20027;&#23548;&#26367;&#20195;&#20989;&#25968;&#65292;&#32780;&#20854;&#20182;&#22352;&#26631;&#20445;&#25345;&#22266;&#23450;&#12290;BMM&#21253;&#25324;&#19968;&#22823;&#31867;&#20248;&#21270;&#31639;&#27861;&#65292;&#22914;&#22359;&#22352;&#26631;&#19979;&#38477;&#21450;&#20854;&#36817;&#31471;&#28857;&#21464;&#20307;&#65292;&#26399;&#26395;&#26368;&#22823;&#21270;&#21644;&#22359;&#25237;&#24433;&#26799;&#24230;&#19979;&#38477;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#23545;&#20110;&#19968;&#33324;&#32422;&#26463;&#38750;&#20984;&#20248;&#21270;&#65292;&#20351;&#29992;&#24378;&#20984;&#26367;&#20195;&#20989;&#25968;&#30340;BMM&#21487;&#20197;&#22312;$O(\epsilon^{-2}(\log \epsilon^{-1})^{2})$&#27425;&#36845;&#20195;&#20013;&#20135;&#29983;&#19968;&#20010;$\epsilon$-&#31283;&#23450;&#28857;&#65292;&#24182;&#28176;&#36817;&#25910;&#25947;&#20110;&#31283;&#23450;&#28857;&#38598;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20449;&#20219;&#22495;&#21464;&#20307;&#30340;BMM&#65292;&#21487;&#20197;&#22788;&#29702;&#21482;&#20855;&#22791;&#20984;&#24615;&#30340;&#26367;&#20195;&#20989;&#25968;&#65292;&#24182;&#20173;&#28982;&#33719;&#24471;&#30456;&#21516;&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#21644;&#28176;&#36817;&#31283;&#23450;&#24615;&#12290;&#36825;&#20123;&#32467;&#26524;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#21363;&#20351;&#20984;&#23376;&#38382;&#39064;&#30340;&#27714;&#35299;&#26159;&#38750;&#31934;&#30830;&#30340;&#65292;&#21482;&#35201;&#26368;&#20248;&#38388;&#38553;&#28385;&#36275;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Block majorization-minimization (BMM) is a simple iterative algorithm for nonconvex constrained optimization that sequentially minimizes majorizing surrogates of the objective function in each block coordinate while the other coordinates are held fixed. BMM entails a large class of optimization algorithms such as block coordinate descent and its proximal-point variant, expectation-minimization, and block projected gradient descent. We establish that for general constrained nonconvex optimization, BMM with strongly convex surrogates can produce an $\epsilon$-stationary point within $O(\epsilon^{-2}(\log \epsilon^{-1})^{2})$ iterations and asymptotically converges to the set of stationary points. Furthermore, we propose a trust-region variant of BMM that can handle surrogates that are only convex and still obtain the same iteration complexity and asymptotic stationarity. These results hold robustly even when the convex sub-problems are inexactly solved as long as the optimality gaps are 
&lt;/p&gt;</description></item></channel></rss>