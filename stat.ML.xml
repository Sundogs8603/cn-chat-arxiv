<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;XGBoost&#31639;&#27861;&#30340;&#21333;&#35843;&#26641;&#24418;GAMI&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#36866;&#29992;&#20110;&#25311;&#21512;&#20855;&#26377;&#37325;&#35201;&#20132;&#20114;&#20316;&#29992;&#30340;&#20302;&#38454;&#20989;&#25968;ANOVA&#27169;&#22411;&#65292;&#24182;&#20855;&#26377;&#30452;&#35266;&#30340;&#35299;&#37322;&#21644;&#21487;&#35270;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2309.02426</link><description>&lt;p&gt;
&#22522;&#20110;XGBoost&#30340;&#21333;&#35843;&#26641;&#24418;GAMI&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Monotone Tree-Based GAMI Models by Adapting XGBoost. (arXiv:2309.02426v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02426
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;XGBoost&#31639;&#27861;&#30340;&#21333;&#35843;&#26641;&#24418;GAMI&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#36866;&#29992;&#20110;&#25311;&#21512;&#20855;&#26377;&#37325;&#35201;&#20132;&#20114;&#20316;&#29992;&#30340;&#20302;&#38454;&#20989;&#25968;ANOVA&#27169;&#22411;&#65292;&#24182;&#20855;&#26377;&#30452;&#35266;&#30340;&#35299;&#37322;&#21644;&#21487;&#35270;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#35770;&#25991;&#37319;&#29992;&#26426;&#22120;&#23398;&#20064;&#32467;&#26500;&#26469;&#25311;&#21512;&#20302;&#38454;&#20989;&#25968;ANOVA&#27169;&#22411;&#65292;&#20854;&#20013;&#21253;&#25324;&#20027;&#25928;&#24212;&#21644;&#20108;&#38454;&#20132;&#20114;&#20316;&#29992;&#12290;&#36825;&#20123;GAMI&#65288;GAM + Interaction&#65289;&#27169;&#22411;&#21487;&#20197;&#30452;&#25509;&#35299;&#37322;&#65292;&#22240;&#20026;&#20989;&#25968;&#30340;&#20027;&#25928;&#24212;&#21644;&#20132;&#20114;&#20316;&#29992;&#21487;&#20197;&#36731;&#26494;&#32472;&#21046;&#21644;&#21487;&#35270;&#21270;&#12290;&#28982;&#32780;&#65292;&#23558;&#21333;&#35843;&#24615;&#35201;&#27714;&#24341;&#20837;&#29616;&#26377;&#30340;&#22522;&#20110;&#25552;&#21319;&#26641;&#30340;GAMI&#27169;&#22411;&#65288;&#22914;EBM&#21644;GAMI-Lin-T&#65289;&#24182;&#19981;&#23481;&#26131;&#12290;&#26412;&#25991;&#32771;&#34385;&#24418;&#24335;&#20026;$f(x)=\sum_{j,k}f_{j,k}(x_j, x_k)$&#30340;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#25913;&#36827;XGBoost&#31639;&#27861;&#24320;&#21457;&#20102;&#21333;&#35843;&#26641;&#24418;GAMI&#27169;&#22411;&#65292;&#31216;&#20026;&#21333;&#35843;GAMI-Tree&#12290;&#20351;&#29992;XGBoost&#30340;&#36873;&#39033;&#23558;&#21333;&#35843;&#27169;&#22411;&#25311;&#21512;&#21040;$f(x)$&#26159;&#30452;&#35266;&#30340;&#12290;&#28982;&#32780;&#65292;&#25311;&#21512;&#30340;&#27169;&#22411;&#20173;&#28982;&#26159;&#19968;&#20010;&#40657;&#30418;&#23376;&#12290;&#25105;&#20204;&#37319;&#21462;&#20102;&#19981;&#21516;&#30340;&#26041;&#27861;&#65306;i&#65289;&#20351;&#29992;&#36807;&#28388;&#25216;&#26415;&#30830;&#23450;&#37325;&#35201;&#30340;&#20132;&#20114;&#20316;&#29992;&#65292;ii&#65289;&#22312;&#36873;&#25321;&#30340;&#20132;&#20114;&#20316;&#29992;&#19978;&#25311;&#21512;&#21333;&#35843;XGBoost&#31639;&#27861;&#65292;&#26368;&#21518;iii&#65289;&#35299;&#26512;&#21644;p
&lt;/p&gt;
&lt;p&gt;
Recent papers have used machine learning architecture to fit low-order functional ANOVA models with main effects and second-order interactions. These GAMI (GAM + Interaction) models are directly interpretable as the functional main effects and interactions can be easily plotted and visualized. Unfortunately, it is not easy to incorporate the monotonicity requirement into the existing GAMI models based on boosted trees, such as EBM (Lou et al. 2013) and GAMI-Lin-T (Hu et al. 2022). This paper considers models of the form $f(x)=\sum_{j,k}f_{j,k}(x_j, x_k)$ and develops monotone tree-based GAMI models, called monotone GAMI-Tree, by adapting the XGBoost algorithm. It is straightforward to fit a monotone model to $f(x)$ using the options in XGBoost. However, the fitted model is still a black box. We take a different approach: i) use a filtering technique to determine the important interactions, ii) fit a monotone XGBoost algorithm with the selected interactions, and finally iii) parse and p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#25490;&#21517;&#20013;&#30340;&#26368;&#23567;&#26497;&#22823;&#21518;&#24724;&#38382;&#39064;&#19982;Top-k&#21453;&#39304;&#65292;&#24182;&#36890;&#36807;&#25552;&#20379;&#19968;&#20010;&#20840;&#38754;&#30340;&#26497;&#22823;&#21518;&#24724;&#29575;&#21051;&#30011;&#65292;&#35299;&#20915;&#20102;Chaudhuri&#21644;Tewari [2017]&#25152;&#25552;&#20986;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.02425</link><description>&lt;p&gt;
&#22312;&#22312;&#32447;&#25490;&#21517;&#20013;&#30340;&#26368;&#23567;&#26497;&#22823;&#21518;&#24724;&#38382;&#39064;&#19982;Top-k&#21453;&#39304;
&lt;/p&gt;
&lt;p&gt;
On the Minimax Regret in Online Ranking with Top-k Feedback. (arXiv:2309.02425v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02425
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#25490;&#21517;&#20013;&#30340;&#26368;&#23567;&#26497;&#22823;&#21518;&#24724;&#38382;&#39064;&#19982;Top-k&#21453;&#39304;&#65292;&#24182;&#36890;&#36807;&#25552;&#20379;&#19968;&#20010;&#20840;&#38754;&#30340;&#26497;&#22823;&#21518;&#24724;&#29575;&#21051;&#30011;&#65292;&#35299;&#20915;&#20102;Chaudhuri&#21644;Tewari [2017]&#25152;&#25552;&#20986;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22312;&#32447;&#25490;&#21517;&#20013;&#65292;&#23398;&#20064;&#31639;&#27861;&#25353;&#39034;&#24207;&#23545;&#19968;&#32452;&#39033;&#30446;&#36827;&#34892;&#25490;&#21517;&#65292;&#24182;&#20197;&#30456;&#20851;&#24615;&#24471;&#20998;&#30340;&#24418;&#24335;&#25509;&#25910;&#21453;&#39304;&#12290;&#30001;&#20110;&#33719;&#24471;&#30456;&#20851;&#24615;&#24471;&#20998;&#36890;&#24120;&#28041;&#21450;&#20154;&#24037;&#27880;&#37322;&#65292;&#22240;&#27492;&#32771;&#34385;&#20165;&#23545;&#25490;&#21517;&#20013;&#30340;&#21069;k&#20010;&#39033;&#30446;&#38480;&#21046;&#21453;&#39304;&#30340;&#37096;&#20998;&#21453;&#39304;&#35774;&#32622;&#20855;&#26377;&#26497;&#22823;&#30340;&#20852;&#36259;&#12290;Chaudhuri&#21644;Tewari [2017]&#24320;&#21457;&#20102;&#19968;&#20010;&#26694;&#26550;&#26469;&#20998;&#26512;&#24102;&#26377;Top $k$&#21453;&#39304;&#30340;&#22312;&#32447;&#25490;&#21517;&#31639;&#27861;&#12290;&#20182;&#20204;&#24037;&#20316;&#30340;&#20851;&#38190;&#35201;&#32032;&#26159;&#20351;&#29992;&#20102;&#37096;&#20998;&#30417;&#25511;&#25216;&#26415;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#30740;&#31350;&#20102;&#20855;&#26377;Top $k$&#21453;&#39304;&#30340;&#22312;&#32447;&#25490;&#21517;&#65292;&#24182;&#35299;&#20915;&#20102;Chaudhuri&#21644;Tewari [2017]&#25552;&#20986;&#30340;&#19968;&#20123;&#24320;&#25918;&#24615;&#38382;&#39064;&#12290;&#25105;&#20204;&#23545;&#25152;&#26377;$k$&#21644;&#20197;&#19979;&#25490;&#21517;&#24615;&#33021;&#24230;&#37327;&#65288;Pairwise Loss&#65292;Discounted Cumulative Gain&#21644;Precision@n&#65289;&#30340;Top $k$&#21453;&#39304;&#27169;&#22411;&#36827;&#34892;&#20102;&#26368;&#23567;&#26497;&#22823;&#21518;&#24724;&#29575;&#30340;&#23436;&#20840;&#21051;&#30011;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#23454;&#29616;&#20102;Precision@n&#30340;&#26368;&#23567;&#26497;&#22823;&#21518;&#24724;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
In online ranking, a learning algorithm sequentially ranks a set of items and receives feedback on its ranking in the form of relevance scores. Since obtaining relevance scores typically involves human annotation, it is of great interest to consider a partial feedback setting where feedback is restricted to the top-$k$ items in the rankings. Chaudhuri and Tewari [2017] developed a framework to analyze online ranking algorithms with top $k$ feedback. A key element in their work was the use of techniques from partial monitoring. In this paper, we further investigate online ranking with top $k$ feedback and solve some open problems posed by Chaudhuri and Tewari [2017]. We provide a full characterization of minimax regret rates with the top $k$ feedback model for all $k$ and for the following ranking performance measures: Pairwise Loss, Discounted Cumulative Gain, and Precision@n. In addition, we give an efficient algorithm that achieves the minimax regret rate for Precision@n.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23558;&#26368;&#22823;&#22343;&#24046;&#30456;&#20284;&#24230;&#24212;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Radon-Kolmogorov-Smirnov&#65288;RKS&#65289;&#26816;&#39564;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#23558;&#26679;&#26412;&#22343;&#20540;&#24046;&#24322;&#26368;&#22823;&#21270;&#30340;&#38382;&#39064;&#25512;&#24191;&#21040;&#22810;&#32500;&#31354;&#38388;&#21644;&#26356;&#39640;&#24179;&#28369;&#24230;&#39034;&#24207;&#65292;&#21516;&#26102;&#19982;&#31070;&#32463;&#32593;&#32476;&#23494;&#20999;&#30456;&#20851;&#12290;</title><link>http://arxiv.org/abs/2309.02422</link><description>&lt;p&gt;
&#26368;&#22823;&#22343;&#24046;&#30456;&#20284;&#24230;&#36935;&#19978;&#31070;&#32463;&#32593;&#32476;&#65306;Radon-Kolmogorov-Smirnov&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Maximum Mean Discrepancy Meets Neural Networks: The Radon-Kolmogorov-Smirnov Test. (arXiv:2309.02422v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02422
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#26368;&#22823;&#22343;&#24046;&#30456;&#20284;&#24230;&#24212;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Radon-Kolmogorov-Smirnov&#65288;RKS&#65289;&#26816;&#39564;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#23558;&#26679;&#26412;&#22343;&#20540;&#24046;&#24322;&#26368;&#22823;&#21270;&#30340;&#38382;&#39064;&#25512;&#24191;&#21040;&#22810;&#32500;&#31354;&#38388;&#21644;&#26356;&#39640;&#24179;&#28369;&#24230;&#39034;&#24207;&#65292;&#21516;&#26102;&#19982;&#31070;&#32463;&#32593;&#32476;&#23494;&#20999;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#22823;&#22343;&#24046;&#30456;&#20284;&#24230;&#65288;MMD&#65289;&#26159;&#19968;&#31867;&#22522;&#20110;&#26368;&#22823;&#21270;&#20004;&#20010;&#20998;&#24067;$P$&#21644;$Q$&#20043;&#38388;&#26679;&#26412;&#22343;&#20540;&#24046;&#24322;&#30340;&#38750;&#21442;&#25968;&#21452;&#26679;&#26412;&#26816;&#39564;&#65292;&#20854;&#20013;&#32771;&#34385;&#20102;&#25152;&#26377;&#22312;&#26576;&#20010;&#20989;&#25968;&#31354;&#38388;$\mathcal{F}$&#20013;&#30340;&#25968;&#25454;&#21464;&#25442;$f$&#30340;&#36873;&#25321;&#12290;&#21463;&#21040;&#26368;&#36817;&#23558;&#25152;&#35859;&#30340;Radon&#26377;&#30028;&#21464;&#24046;&#20989;&#25968;&#65288;RBV&#65289;&#21644;&#31070;&#32463;&#32593;&#32476;&#32852;&#31995;&#36215;&#26469;&#30340;&#24037;&#20316;&#30340;&#21551;&#21457;&#65288;Parhi&#21644;Nowak, 2021, 2023&#65289;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#23558;$\mathcal{F}$&#21462;&#20026;&#32473;&#23450;&#24179;&#28369;&#24230;&#39034;&#24207;$k \geq 0$&#19979;&#30340;RBV&#31354;&#38388;&#20013;&#30340;&#21333;&#20301;&#29699;&#30340;MMD&#12290;&#36825;&#20010;&#26816;&#39564;&#34987;&#31216;&#20026;Radon-Kolmogorov-Smirnov&#65288;RKS&#65289;&#26816;&#39564;&#65292;&#21487;&#20197;&#30475;&#20316;&#26159;&#23545;&#22810;&#32500;&#31354;&#38388;&#21644;&#26356;&#39640;&#24179;&#28369;&#24230;&#39034;&#24207;&#30340;&#32463;&#20856;Kolmogorov-Smirnov&#65288;KS&#65289;&#26816;&#39564;&#30340;&#19968;&#33324;&#21270;&#12290;&#23427;&#36824;&#19982;&#31070;&#32463;&#32593;&#32476;&#23494;&#20999;&#30456;&#20851;&#65306;&#25105;&#20204;&#35777;&#26126;RKS&#26816;&#39564;&#20013;&#30340;&#35777;&#25454;&#20989;&#25968;$f$&#65292;&#21363;&#36798;&#21040;&#26368;&#22823;&#22343;&#24046;&#30340;&#20989;&#25968;&#65292;&#24635;&#26159;&#19968;&#20010;&#20108;&#27425;&#26679;&#26465;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Maximum mean discrepancy (MMD) refers to a general class of nonparametric two-sample tests that are based on maximizing the mean difference over samples from one distribution $P$ versus another $Q$, over all choices of data transformations $f$ living in some function space $\mathcal{F}$. Inspired by recent work that connects what are known as functions of $\textit{Radon bounded variation}$ (RBV) and neural networks (Parhi and Nowak, 2021, 2023), we study the MMD defined by taking $\mathcal{F}$ to be the unit ball in the RBV space of a given smoothness order $k \geq 0$. This test, which we refer to as the $\textit{Radon-Kolmogorov-Smirnov}$ (RKS) test, can be viewed as a generalization of the well-known and classical Kolmogorov-Smirnov (KS) test to multiple dimensions and higher orders of smoothness. It is also intimately connected to neural networks: we prove that the witness in the RKS test -- the function $f$ achieving the maximum mean difference -- is always a ridge spline of degree
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#39640;&#25928;&#35745;&#31639;SHAP&#30340;&#26041;&#27861;&#65292;&#23545;&#20110;&#28385;&#36275;&#21487;&#21152;&#24615;&#21644;&#34394;&#25311;&#20551;&#35774;&#30340;SHAP&#23450;&#20041;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19981;&#21516;&#31574;&#30053;&#26469;&#22788;&#29702;&#19981;&#21516;&#27169;&#22411;&#32467;&#26500;&#20449;&#24687;&#30340;&#24773;&#20917;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#23545;&#20110;&#24050;&#30693;&#21151;&#33021;&#20998;&#35299;&#30340;&#24773;&#20917;&#65292;&#25105;&#20204;&#28436;&#31034;&#20102;&#19968;&#31181;&#21487;&#21152;&#24615;&#23646;&#24615;&#21644;&#20174;&#36739;&#20302;&#38454;&#21151;&#33021;&#32452;&#20214;&#35745;&#31639;SHAP&#30340;&#26041;&#27861;&#65307;&#23545;&#20110;&#24050;&#30693;&#27169;&#22411;&#39034;&#24207;&#30340;&#24773;&#20917;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#33021;&#22815;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#35745;&#31639;SHAP&#30340;&#20844;&#24335;&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#23454;&#39564;&#20013;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2309.02417</link><description>&lt;p&gt;
&#20351;&#29992;&#27169;&#22411;&#32467;&#26500;&#20449;&#24687;&#39640;&#25928;&#35745;&#31639;SHAP
&lt;/p&gt;
&lt;p&gt;
Computing SHAP Efficiently Using Model Structure Information. (arXiv:2309.02417v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02417
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#39640;&#25928;&#35745;&#31639;SHAP&#30340;&#26041;&#27861;&#65292;&#23545;&#20110;&#28385;&#36275;&#21487;&#21152;&#24615;&#21644;&#34394;&#25311;&#20551;&#35774;&#30340;SHAP&#23450;&#20041;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19981;&#21516;&#31574;&#30053;&#26469;&#22788;&#29702;&#19981;&#21516;&#27169;&#22411;&#32467;&#26500;&#20449;&#24687;&#30340;&#24773;&#20917;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#23545;&#20110;&#24050;&#30693;&#21151;&#33021;&#20998;&#35299;&#30340;&#24773;&#20917;&#65292;&#25105;&#20204;&#28436;&#31034;&#20102;&#19968;&#31181;&#21487;&#21152;&#24615;&#23646;&#24615;&#21644;&#20174;&#36739;&#20302;&#38454;&#21151;&#33021;&#32452;&#20214;&#35745;&#31639;SHAP&#30340;&#26041;&#27861;&#65307;&#23545;&#20110;&#24050;&#30693;&#27169;&#22411;&#39034;&#24207;&#30340;&#24773;&#20917;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#33021;&#22815;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#35745;&#31639;SHAP&#30340;&#20844;&#24335;&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#23454;&#39564;&#20013;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
SHAP&#65288;SHapley&#21152;&#24615;&#35299;&#37322;&#65289;&#24050;&#25104;&#20026;&#19968;&#31181;&#27969;&#34892;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#23558;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#23545;&#36755;&#20837;&#30340;&#39044;&#27979;&#24402;&#22240;&#20110;&#20854;&#29305;&#24449;&#12290;SHAP&#30340;&#20027;&#35201;&#25361;&#25112;&#20043;&#19968;&#26159;&#35745;&#31639;&#26102;&#38388;&#12290;&#31934;&#30830;&#35745;&#31639;Shapley&#20540;&#38656;&#35201;&#25351;&#25968;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;&#22240;&#27492;&#65292;&#25991;&#29486;&#20013;&#25552;&#20986;&#20102;&#35768;&#22810;&#36817;&#20284;&#26041;&#27861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#33021;&#22815;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#25110;&#29978;&#33267;&#26356;&#24555;&#22320;&#35745;&#31639;&#20986;&#28385;&#36275;&#21487;&#21152;&#24615;&#21644;&#34394;&#25311;&#20551;&#35774;&#65288;&#20363;&#22914;&#65292;&#26680;&#24515;SHAP&#21644;&#22522;&#32447;SHAP&#65289;&#23450;&#20041;&#30340;SHAP&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#38024;&#23545;&#20855;&#26377;&#19981;&#21516;&#27169;&#22411;&#32467;&#26500;&#20449;&#24687;&#27700;&#24179;&#30340;&#27169;&#22411;&#24320;&#21457;&#20102;&#19981;&#21516;&#30340;&#31574;&#30053;&#65306;&#24050;&#30693;&#21151;&#33021;&#20998;&#35299;&#30340;&#24773;&#20917;&#12289;&#24050;&#30693;&#27169;&#22411;&#39034;&#24207;&#65288;&#23450;&#20041;&#20026;&#27169;&#22411;&#20013;&#26368;&#39640;&#20132;&#20114;&#20316;&#29992;&#30340;&#39034;&#24207;&#65289;&#30340;&#24773;&#20917;&#65292;&#25110;&#26410;&#30693;&#39034;&#24207;&#30340;&#24773;&#20917;&#12290;&#23545;&#20110;&#31532;&#19968;&#31181;&#24773;&#20917;&#65292;&#25105;&#20204;&#28436;&#31034;&#20102;&#21487;&#21152;&#24615;&#23646;&#24615;&#21644;&#20174;&#36739;&#20302;&#38454;&#21151;&#33021;&#32452;&#20214;&#35745;&#31639;SHAP&#30340;&#26041;&#27861;&#12290;&#23545;&#20110;&#31532;&#20108;&#31181;&#24773;&#20917;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#33021;&#22815;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#35745;&#31639;SHAP&#30340;&#20844;&#24335;&#12290;&#20004;&#31181;&#26041;&#27861;&#37117;&#22312;&#23454;&#39564;&#20013;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
SHAP (SHapley Additive exPlanations) has become a popular method to attribute the prediction of a machine learning model on an input to its features. One main challenge of SHAP is the computation time. An exact computation of Shapley values requires exponential time complexity. Therefore, many approximation methods are proposed in the literature. In this paper, we propose methods that can compute SHAP exactly in polynomial time or even faster for SHAP definitions that satisfy our additivity and dummy assumptions (eg, kernal SHAP and baseline SHAP). We develop different strategies for models with different levels of model structure information: known functional decomposition, known order of model (defined as highest order of interaction in the model), or unknown order. For the first case, we demonstrate an additive property and a way to compute SHAP from the lower-order functional components. For the second case, we derive formulas that can compute SHAP in polynomial time. Both methods 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#36830;&#32493;&#26102;&#38388;&#39640;&#26031;&#36807;&#31243;&#21160;&#21147;&#23398;&#36827;&#34892;&#31934;&#30830;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#22312;&#31163;&#25955;&#26102;&#38388;&#19979;&#36827;&#34892;&#39044;&#27979;&#21487;&#33021;&#24102;&#26469;&#30340;&#38382;&#39064;&#65292;&#24182;&#21033;&#29992;&#39640;&#38454;&#25968;&#20540;&#31215;&#20998;&#22120;&#36827;&#34892;&#21160;&#21147;&#23398;&#20989;&#25968;&#30340;&#31163;&#25955;&#21270;&#65292;&#36991;&#20813;&#20102;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#36817;&#20284;&#25512;&#26029;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2309.02351</link><description>&lt;p&gt;
&#36830;&#32493;&#26102;&#38388;&#39640;&#26031;&#36807;&#31243;&#21160;&#21147;&#23398;&#30340;&#31934;&#30830;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Exact Inference for Continuous-Time Gaussian Process Dynamics. (arXiv:2309.02351v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02351
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#36830;&#32493;&#26102;&#38388;&#39640;&#26031;&#36807;&#31243;&#21160;&#21147;&#23398;&#36827;&#34892;&#31934;&#30830;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#22312;&#31163;&#25955;&#26102;&#38388;&#19979;&#36827;&#34892;&#39044;&#27979;&#21487;&#33021;&#24102;&#26469;&#30340;&#38382;&#39064;&#65292;&#24182;&#21033;&#29992;&#39640;&#38454;&#25968;&#20540;&#31215;&#20998;&#22120;&#36827;&#34892;&#21160;&#21147;&#23398;&#20989;&#25968;&#30340;&#31163;&#25955;&#21270;&#65292;&#36991;&#20813;&#20102;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#36817;&#20284;&#25512;&#26029;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#38469;&#29289;&#29702;&#31995;&#32479;&#36890;&#24120;&#21487;&#20197;&#36890;&#36807;&#36830;&#32493;&#26102;&#38388;&#21160;&#21147;&#31995;&#32479;&#26469;&#25551;&#36848;&#12290;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#30495;&#23454;&#31995;&#32479;&#36890;&#24120;&#26159;&#26410;&#30693;&#30340;&#65292;&#38656;&#35201;&#20174;&#27979;&#37327;&#25968;&#25454;&#20013;&#23398;&#20064;&#12290;&#30001;&#20110;&#25968;&#25454;&#36890;&#24120;&#20197;&#31163;&#25955;&#26102;&#38388;&#25910;&#38598;&#65292;&#20363;&#22914;&#36890;&#36807;&#20256;&#24863;&#22120;&#65292;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#21160;&#21147;&#27169;&#22411;&#23398;&#20064;&#20013;&#30340;&#22823;&#22810;&#25968;&#26041;&#27861;&#37117;&#26159;&#38024;&#23545;&#19968;&#27493;&#39044;&#27979;&#36827;&#34892;&#35757;&#32451;&#30340;&#12290;&#22312;&#19968;&#20123;&#22330;&#26223;&#20013;&#65292;&#36825;&#21487;&#33021;&#20250;&#23548;&#33268;&#38382;&#39064;&#65292;&#20363;&#22914;&#22914;&#26524;&#27979;&#37327;&#32467;&#26524;&#20197;&#19981;&#35268;&#21017;&#30340;&#26102;&#38388;&#27493;&#38271;&#25552;&#20379;&#65292;&#25110;&#32773;&#29289;&#29702;&#31995;&#32479;&#23646;&#24615;&#38656;&#35201;&#20445;&#25345;&#19981;&#21464;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#24314;&#31435;&#23545;&#30495;&#23454;&#36830;&#32493;&#26102;&#38388;&#21160;&#21147;&#23398;&#30340;GP&#27169;&#22411;&#12290;&#39640;&#38454;&#25968;&#20540;&#31215;&#20998;&#22120;&#25552;&#20379;&#20102;&#36890;&#36807;&#20219;&#24847;&#31934;&#24230;&#31163;&#25955;&#21270;&#21160;&#21147;&#23398;&#20989;&#25968;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#24037;&#20855;&#12290;&#35768;&#22810;&#39640;&#38454;&#31215;&#20998;&#22120;&#38656;&#35201;&#22312;&#20013;&#38388;&#26102;&#38388;&#27493;&#39588;&#36827;&#34892;&#21160;&#21147;&#23398;&#35780;&#20272;&#65292;&#36825;&#20351;&#24471;&#31934;&#30830;&#30340;GP&#25512;&#26029;&#21464;&#24471;&#38590;&#20197;&#22788;&#29702;&#12290;&#22312;&#20808;&#21069;&#30340;&#24037;&#20316;&#20013;&#65292;&#36890;&#24120;&#36890;&#36807;&#20351;&#29992;&#21464;&#20998;&#25512;&#26029;&#26469;&#36817;&#20284;GP&#21518;&#39564;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#31934;&#30830;&#30340;GP&#25512;&#26029;&#26159;&#24456;&#22256;&#38590;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Physical systems can often be described via a continuous-time dynamical system. In practice, the true system is often unknown and has to be learned from measurement data. Since data is typically collected in discrete time, e.g. by sensors, most methods in Gaussian process (GP) dynamics model learning are trained on one-step ahead predictions. This can become problematic in several scenarios, e.g. if measurements are provided at irregularly-sampled time steps or physical system properties have to be conserved. Thus, we aim for a GP model of the true continuous-time dynamics. Higher-order numerical integrators provide the necessary tools to address this problem by discretizing the dynamics function with arbitrary accuracy. Many higher-order integrators require dynamics evaluations at intermediate time steps making exact GP inference intractable. In previous work, this problem is often tackled by approximating the GP posterior with variational inference. However, exact GP inference is pre
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PolyLUT&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#22312;FPGA&#19978;&#36827;&#34892;&#37096;&#32626;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#22810;&#21464;&#37327;&#22810;&#39033;&#24335;&#20316;&#20026;&#22522;&#26412;&#27169;&#22359;&#65292;&#24182;&#21033;&#29992;&#36719;&#36923;&#36753;&#23558;&#22810;&#39033;&#24335;&#35780;&#20272;&#38544;&#34255;&#22312;FPGA&#30340;&#26597;&#25214;&#34920;&#20013;&#65292;&#20174;&#32780;&#23454;&#29616;&#36229;&#20302;&#24310;&#36831;&#25512;&#29702;&#65292;&#24182;&#20943;&#23569;&#20102;&#36719;&#20214;&#36923;&#36753;&#30340;&#23618;&#25968;&#12290;</title><link>http://arxiv.org/abs/2309.02334</link><description>&lt;p&gt;
PolyLUT: &#29992;&#20110;&#36229;&#20302;&#24310;&#36831;FPGA&#22522;&#20110;&#26597;&#25214;&#34920;&#25512;&#29702;&#30340;&#20998;&#27573;&#22810;&#39033;&#24335;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
PolyLUT: Learning Piecewise Polynomials for Ultra-Low Latency FPGA LUT-based Inference. (arXiv:2309.02334v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02334
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PolyLUT&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#22312;FPGA&#19978;&#36827;&#34892;&#37096;&#32626;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#22810;&#21464;&#37327;&#22810;&#39033;&#24335;&#20316;&#20026;&#22522;&#26412;&#27169;&#22359;&#65292;&#24182;&#21033;&#29992;&#36719;&#36923;&#36753;&#23558;&#22810;&#39033;&#24335;&#35780;&#20272;&#38544;&#34255;&#22312;FPGA&#30340;&#26597;&#25214;&#34920;&#20013;&#65292;&#20174;&#32780;&#23454;&#29616;&#36229;&#20302;&#24310;&#36831;&#25512;&#29702;&#65292;&#24182;&#20943;&#23569;&#20102;&#36719;&#20214;&#36923;&#36753;&#30340;&#23618;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#32534;&#31243;&#38376;&#38453;&#21015;&#65288;FPGA&#65289;&#34987;&#24191;&#27867;&#29992;&#20110;&#23454;&#29616;&#28145;&#24230;&#23398;&#20064;&#25512;&#29702;&#12290;&#26631;&#20934;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25512;&#29702;&#28041;&#21450;&#20132;&#38169;&#32447;&#24615;&#26144;&#23556;&#21644;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#30340;&#35745;&#31639;&#12290;&#20197;&#24448;&#30340;&#36229;&#20302;&#24310;&#36831;&#23454;&#29616;&#24037;&#20316;&#22312;FPGA&#26597;&#25214;&#34920;&#65288;LUT&#65289;&#20013;&#30828;&#32534;&#30721;&#20102;&#32447;&#24615;&#26144;&#23556;&#21644;&#38750;&#32447;&#24615;&#28608;&#27963;&#30340;&#32452;&#21512;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#21463;&#21040;&#36825;&#20010;&#24819;&#27861;&#30340;&#21551;&#21457;&#65292;&#21363;FPGA&#20013;&#30340;LUT&#21487;&#20197;&#29992;&#26469;&#23454;&#29616;&#27604;&#36825;&#26356;&#22810;&#26679;&#21270;&#30340;&#20989;&#25968;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#35757;&#32451;&#29992;&#20110;FPGA&#37096;&#32626;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#20197;&#22810;&#21464;&#37327;&#22810;&#39033;&#24335;&#20316;&#20026;&#22522;&#26412;&#27169;&#22359;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#36719;&#20214;&#36923;&#36753;&#25552;&#20379;&#30340;&#28789;&#27963;&#24615;&#65292;&#23558;&#22810;&#39033;&#24335;&#35780;&#20272;&#38544;&#34255;&#22312;LUT&#20013;&#19988;&#27809;&#26377;&#20219;&#20309;&#24320;&#38144;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#36890;&#36807;&#20351;&#29992;&#22810;&#39033;&#24335;&#27169;&#22359;&#65292;&#25105;&#20204;&#21487;&#20197;&#23454;&#29616;&#30456;&#21516;&#30340;&#20934;&#30830;&#24230;&#65292;&#32780;&#20351;&#29992;&#30340;&#36719;&#20214;&#36923;&#36753;&#23618;&#25968;&#35201;&#27604;&#20351;&#29992;&#32447;&#24615;&#20989;&#25968;&#35201;&#23569;&#24471;&#22810;&#65292;&#20174;&#32780;&#24102;&#26469;&#26174;&#33879;&#30340;&#24310;&#36831;&#21644;&#38754;&#31215;&#30340;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
Field-programmable gate arrays (FPGAs) are widely used to implement deep learning inference. Standard deep neural network inference involves the computation of interleaved linear maps and nonlinear activation functions. Prior work for ultra-low latency implementations has hardcoded the combination of linear maps and nonlinear activations inside FPGA lookup tables (LUTs). Our work is motivated by the idea that the LUTs in an FPGA can be used to implement a much greater variety of functions than this. In this paper, we propose a novel approach to training neural networks for FPGA deployment using multivariate polynomials as the basic building block. Our method takes advantage of the flexibility offered by the soft logic, hiding the polynomial evaluation inside the LUTs with zero overhead. We show that by using polynomial building blocks, we can achieve the same accuracy using considerably fewer layers of soft logic than by using linear functions, leading to significant latency and area i
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;NUMERLA&#30340;&#31639;&#27861;&#65292;&#21033;&#29992;&#31070;&#32463;&#31526;&#21495;&#20803;-&#24378;&#21270;&#21069;&#30651;&#23398;&#20064;&#65292;&#23454;&#29616;&#20102;&#38750;&#31283;&#24577;&#29615;&#22659;&#19979;&#30340;&#23433;&#20840;&#33258;&#21160;&#39550;&#39542;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21069;&#30651;&#26356;&#26032;&#26426;&#21046;&#26469;&#30830;&#20445;&#23433;&#20840;&#21644;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2309.02328</link><description>&lt;p&gt;
&#31070;&#32463;&#31526;&#21495;&#20803;-&#24378;&#21270;&#21069;&#30651;&#23398;&#20064;&#22312;&#38750;&#31283;&#24577;&#29615;&#22659;&#19979;&#23454;&#29616;&#23433;&#20840;&#33258;&#21160;&#39550;&#39542;
&lt;/p&gt;
&lt;p&gt;
Neurosymbolic Meta-Reinforcement Lookahead Learning Achieves Safe Self-Driving in Non-Stationary Environments. (arXiv:2309.02328v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02328
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;NUMERLA&#30340;&#31639;&#27861;&#65292;&#21033;&#29992;&#31070;&#32463;&#31526;&#21495;&#20803;-&#24378;&#21270;&#21069;&#30651;&#23398;&#20064;&#65292;&#23454;&#29616;&#20102;&#38750;&#31283;&#24577;&#29615;&#22659;&#19979;&#30340;&#23433;&#20840;&#33258;&#21160;&#39550;&#39542;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21069;&#30651;&#26356;&#26032;&#26426;&#21046;&#26469;&#30830;&#20445;&#23433;&#20840;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23398;&#20064;&#39537;&#21160;&#30340;&#20154;&#24037;&#26234;&#33021;&#36827;&#23637;&#39046;&#22495;&#20013;&#65292;&#23558;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#19982;&#33258;&#21160;&#39550;&#39542;&#65288;SD&#65289;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#26159;&#19968;&#39033;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#24037;&#31243;&#22766;&#20030;&#12290;&#28982;&#32780;&#65292;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#20013;&#65292;&#36229;&#36234;&#21463;&#25511;&#23454;&#39564;&#23460;&#22330;&#26223;&#30340;&#38480;&#21046;&#65292;&#33258;&#21160;&#39550;&#39542;&#25216;&#26415;&#30340;&#37096;&#32626;&#25215;&#25285;&#30528;&#20851;&#20046;&#29983;&#21629;&#23433;&#20840;&#30340;&#35282;&#33394;&#65292;&#36825;&#23601;&#35201;&#27714;&#30740;&#31350;&#20154;&#21592;&#26356;&#21152;&#20851;&#27880;&#23433;&#20840;&#21644;&#25928;&#29575;&#12290;&#24403;&#33258;&#21160;&#39550;&#39542;&#27169;&#22411;&#22312;&#23454;&#26102;&#25191;&#34892;&#20013;&#36935;&#21040;&#38476;&#29983;&#29615;&#22659;&#26102;&#65292;&#28966;&#28857;&#19981;&#33021;&#20165;&#20165;&#38598;&#20013;&#22312;&#25552;&#39640;&#20854;&#39044;&#26399;&#24615;&#33021;&#19978;&#65307;&#21516;&#26679;&#37325;&#35201;&#30340;&#26159;&#30830;&#20445;&#20854;&#25191;&#34892;&#25110;&#23454;&#26102;&#35843;&#25972;&#33021;&#22815;&#20445;&#25345;&#24517;&#35201;&#30340;&#23433;&#20840;&#27700;&#24179;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;&#32447;&#20803;-&#24378;&#21270;&#23398;&#20064;&#30340;&#31639;&#27861;&#65292;&#37319;&#29992;&#22522;&#20110;&#8220;&#31070;&#32463;&#31526;&#21495;&#20803;-&#24378;&#21270;&#21069;&#30651;&#23398;&#20064;&#8221;&#65288;NUMERLA&#65289;&#30340;&#21069;&#30651;&#31526;&#21495;&#32422;&#26463;&#12290;NUMERLA&#25552;&#20986;&#20102;&#19968;&#31181;&#21069;&#30651;&#26356;&#26032;&#26426;&#21046;&#65292;&#21487;&#20197;&#21327;&#35843;&#23398;&#20064;&#21644;&#35268;&#21010;&#65292;&#22312;&#38750;&#31283;&#24577;&#29615;&#22659;&#20013;&#23454;&#29616;&#23433;&#20840;&#33258;&#21160;&#39550;&#39542;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the area of learning-driven artificial intelligence advancement, the integration of machine learning (ML) into self-driving (SD) technology stands as an impressive engineering feat. Yet, in real-world applications outside the confines of controlled laboratory scenarios, the deployment of self-driving technology assumes a life-critical role, necessitating heightened attention from researchers towards both safety and efficiency. To illustrate, when a self-driving model encounters an unfamiliar environment in real-time execution, the focus must not solely revolve around enhancing its anticipated performance; equal consideration must be given to ensuring its execution or real-time adaptation maintains a requisite level of safety. This study introduces an algorithm for online meta-reinforcement learning, employing lookahead symbolic constraints based on \emph{Neurosymbolic Meta-Reinforcement Lookahead Learning} (NUMERLA). NUMERLA proposes a lookahead updating mechanism that harmonizes th
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#20013;&#22797;&#26434;&#21160;&#24577;&#31995;&#32479;&#21644;&#22823;&#29366;&#24577;&#31354;&#38388;&#38382;&#39064;&#30340;&#20998;&#24067;&#40065;&#26834;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#21644;&#26368;&#22823;&#26041;&#24046;&#32553;&#20943;&#31639;&#27861;&#36827;&#34892;&#39640;&#25928;&#23398;&#20064;&#65292;&#24182;&#22312;&#19981;&#21516;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#19979;&#23637;&#31034;&#20102;&#32479;&#35745;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2309.02236</link><description>&lt;p&gt;
&#20855;&#26377;&#22823;&#29366;&#24577;&#31354;&#38388;&#30340;&#20998;&#24067;&#40065;&#26834;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Distributionally Robust Model-based Reinforcement Learning with Large State Spaces. (arXiv:2309.02236v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02236
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#20013;&#22797;&#26434;&#21160;&#24577;&#31995;&#32479;&#21644;&#22823;&#29366;&#24577;&#31354;&#38388;&#38382;&#39064;&#30340;&#20998;&#24067;&#40065;&#26834;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#21644;&#26368;&#22823;&#26041;&#24046;&#32553;&#20943;&#31639;&#27861;&#36827;&#34892;&#39640;&#25928;&#23398;&#20064;&#65292;&#24182;&#22312;&#19981;&#21516;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#19979;&#23637;&#31034;&#20102;&#32479;&#35745;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#38754;&#20020;&#30528;&#22797;&#26434;&#30340;&#21160;&#24577;&#31995;&#32479;&#21644;&#22823;&#29366;&#24577;&#31354;&#38388;&#30340;&#25361;&#25112;&#65292;&#20197;&#21450;&#26114;&#36149;&#30340;&#25968;&#25454;&#25910;&#38598;&#36807;&#31243;&#20197;&#21450;&#30495;&#23454;&#19990;&#30028;&#21160;&#21147;&#23398;&#19982;&#35757;&#32451;&#29615;&#22659;&#37096;&#32626;&#30340;&#20559;&#24046;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#24191;&#27867;&#20351;&#29992;&#30340;Kullback-Leibler&#12289;&#21345;&#26041;&#21644;&#24635;&#21464;&#24046;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#19979;&#20855;&#26377;&#36830;&#32493;&#29366;&#24577;&#31354;&#38388;&#30340;&#20998;&#24067;&#40065;&#26834;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#21644;&#26368;&#22823;&#26041;&#24046;&#32553;&#20943;&#31639;&#27861;&#26469;&#39640;&#25928;&#23398;&#20064;&#22810;&#36755;&#20986;&#30340;&#21517;&#20041;&#36716;&#31227;&#21160;&#24577;&#65292;&#24182;&#21033;&#29992;&#29983;&#25104;&#27169;&#22411;&#65288;&#21363;&#27169;&#25311;&#22120;&#65289;&#30340;&#35775;&#38382;&#26435;&#38480;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22312;&#19981;&#21516;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#19979;&#30340;&#32479;&#35745;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#36825;&#20123;&#22797;&#26434;&#24230;&#30028;&#19981;&#20381;&#36182;&#20110;&#29366;&#24577;&#25968;&#37327;&#65292;&#24182;&#19988;&#36229;&#36234;&#32447;&#24615;&#21160;&#24577;&#65292;&#30830;&#20445;&#20102;&#25105;&#20204;&#26041;&#27861;&#22312;&#35782;&#21035;&#25509;&#36817;&#26368;&#20248;&#30340;&#20998;&#24067;&#40065;&#26834;&#31574;&#30053;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Three major challenges in reinforcement learning are the complex dynamical systems with large state spaces, the costly data acquisition processes, and the deviation of real-world dynamics from the training environment deployment. To overcome these issues, we study distributionally robust Markov decision processes with continuous state spaces under the widely used Kullback-Leibler, chi-square, and total variation uncertainty sets. We propose a model-based approach that utilizes Gaussian Processes and the maximum variance reduction algorithm to efficiently learn multi-output nominal transition dynamics, leveraging access to a generative model (i.e., simulator). We further demonstrate the statistical sample complexity of the proposed method for different uncertainty sets. These complexity bounds are independent of the number of states and extend beyond linear dynamics, ensuring the effectiveness of our approach in identifying near-optimal distributionally-robust policies. The proposed met
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#28304;&#25968;&#25454;&#30340;&#20998;&#24067;&#40065;&#26834;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#32452;&#20998;&#24067;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#26469;&#25552;&#39640;&#20855;&#26377;&#20998;&#24067;&#20559;&#31227;&#30340;&#30446;&#26631;&#20154;&#32676;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.02211</link><description>&lt;p&gt;
&#22522;&#20110;&#22810;&#28304;&#25968;&#25454;&#30340;&#20998;&#24067;&#40065;&#26834;&#26426;&#22120;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Distributionally Robust Machine Learning with Multi-source Data. (arXiv:2309.02211v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02211
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#28304;&#25968;&#25454;&#30340;&#20998;&#24067;&#40065;&#26834;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#32452;&#20998;&#24067;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#26469;&#25552;&#39640;&#20855;&#26377;&#20998;&#24067;&#20559;&#31227;&#30340;&#30446;&#26631;&#20154;&#32676;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#30446;&#26631;&#20998;&#24067;&#19982;&#28304;&#25968;&#25454;&#38598;&#19981;&#21516;&#26102;&#65292;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#36739;&#24046;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#26412;&#25991;&#21033;&#29992;&#22810;&#20010;&#25968;&#25454;&#28304;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#32452;&#20998;&#24067;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#26469;&#20248;&#21270;&#20851;&#20110;&#30446;&#26631;&#20998;&#24067;&#31867;&#30340;&#21487;&#35299;&#37322;&#26041;&#24046;&#30340;&#23545;&#25239;&#24615;&#22870;&#21169;&#12290;&#19982;&#20256;&#32479;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30456;&#27604;&#65292;&#25152;&#25552;&#20986;&#30340;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#25913;&#21892;&#20102;&#20855;&#26377;&#20998;&#24067;&#20559;&#31227;&#30340;&#30446;&#26631;&#20154;&#32676;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#32452;&#20998;&#24067;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#26159;&#28304;&#25968;&#25454;&#38598;&#26465;&#20214;&#32467;&#26524;&#27169;&#22411;&#30340;&#21152;&#26435;&#24179;&#22343;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#19968;&#20851;&#38190;&#37492;&#21035;&#32467;&#26524;&#26469;&#25552;&#39640;&#20219;&#24847;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#40065;&#26834;&#24615;&#65292;&#21253;&#25324;&#38543;&#26426;&#26862;&#26519;&#21644;&#31070;&#32463;&#32593;&#32476;&#31561;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#20559;&#24046;&#26657;&#27491;&#20272;&#35745;&#22120;&#26469;&#20272;&#35745;&#36890;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#26368;&#20248;&#32858;&#21512;&#26435;&#37325;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;c&#26041;&#38754;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Classical machine learning methods may lead to poor prediction performance when the target distribution differs from the source populations. This paper utilizes data from multiple sources and introduces a group distributionally robust prediction model defined to optimize an adversarial reward about explained variance with respect to a class of target distributions. Compared to classical empirical risk minimization, the proposed robust prediction model improves the prediction accuracy for target populations with distribution shifts. We show that our group distributionally robust prediction model is a weighted average of the source populations' conditional outcome models. We leverage this key identification result to robustify arbitrary machine learning algorithms, including, for example, random forests and neural networks. We devise a novel bias-corrected estimator to estimate the optimal aggregation weight for general machine-learning algorithms and demonstrate its improvement in the c
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#949;-&#20840;&#23616;&#24046;&#20998;&#38544;&#31169;&#19979;&#30340;&#22266;&#23450;&#32622;&#20449;&#24230;&#19979;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#25105;&#20204;&#24471;&#21040;&#20102;&#28385;&#36275;&#949;-&#20840;&#23616;&#24046;&#20998;&#38544;&#31169;&#30340;&#20219;&#20309;&#948;-&#27491;&#30830;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#31639;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#19979;&#30028;&#65292;&#24182;&#21457;&#29616;&#20102;&#39640;&#38544;&#31169;&#21306;&#22495;&#21644;&#20302;&#38544;&#31169;&#21306;&#22495;&#20004;&#31181;&#38544;&#31169;&#24773;&#20917;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26368;&#20339;&#33218;&#35782;&#21035;&#31639;&#27861;AdaP-TT&#65292;&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#20449;&#24687;&#35770;&#29305;&#24615;&#26102;&#38388;&#26469;&#24179;&#34913;&#38544;&#31169;&#21644;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.02202</link><description>&lt;p&gt;
&#20851;&#20110;&#22266;&#23450;&#32622;&#20449;&#24230;&#19979;&#24046;&#20998;&#38544;&#31169;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Complexity of Differentially Private Best-Arm Identification with Fixed Confidence. (arXiv:2309.02202v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02202
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#949;-&#20840;&#23616;&#24046;&#20998;&#38544;&#31169;&#19979;&#30340;&#22266;&#23450;&#32622;&#20449;&#24230;&#19979;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#25105;&#20204;&#24471;&#21040;&#20102;&#28385;&#36275;&#949;-&#20840;&#23616;&#24046;&#20998;&#38544;&#31169;&#30340;&#20219;&#20309;&#948;-&#27491;&#30830;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#31639;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#19979;&#30028;&#65292;&#24182;&#21457;&#29616;&#20102;&#39640;&#38544;&#31169;&#21306;&#22495;&#21644;&#20302;&#38544;&#31169;&#21306;&#22495;&#20004;&#31181;&#38544;&#31169;&#24773;&#20917;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26368;&#20339;&#33218;&#35782;&#21035;&#31639;&#27861;AdaP-TT&#65292;&#36890;&#36807;&#21160;&#24577;&#35843;&#25972;&#20449;&#24687;&#35770;&#29305;&#24615;&#26102;&#38388;&#26469;&#24179;&#34913;&#38544;&#31169;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#34987;&#36880;&#28176;&#24212;&#29992;&#20110;&#25968;&#25454;&#25935;&#24863;&#30340;&#24212;&#29992;&#65292;&#20363;&#22914;&#35774;&#35745;&#33258;&#36866;&#24212;&#20020;&#24202;&#35797;&#39564;&#12289;&#35843;&#25972;&#36229;&#21442;&#25968;&#21644;&#36827;&#34892;&#29992;&#25143;&#30740;&#31350;&#31561;&#12290;&#22522;&#20110;&#36825;&#20123;&#24212;&#29992;&#24341;&#21457;&#30340;&#25968;&#25454;&#38544;&#31169;&#38382;&#39064;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#949;-&#20840;&#23616;&#24046;&#20998;&#38544;&#31169;&#19979;&#30340;&#22266;&#23450;&#32622;&#20449;&#24230;&#19979;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#39318;&#20808;&#65292;&#20026;&#20102;&#34913;&#37327;&#38544;&#31169;&#24320;&#38144;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#28385;&#36275;&#949;-&#20840;&#23616;&#24046;&#20998;&#38544;&#31169;&#30340;&#20219;&#20309;&#948;-&#27491;&#30830;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#31639;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#19979;&#30028;&#12290;&#25105;&#20204;&#30340;&#19979;&#30028;&#34920;&#26126;&#23384;&#22312;&#20004;&#31181;&#38544;&#31169;&#21306;&#22495;&#65292;&#21462;&#20915;&#20110;&#38544;&#31169;&#39044;&#31639;&#949;&#12290;&#22312;&#39640;&#38544;&#31169;&#21306;&#22495;&#65288;&#23567;&#949;&#65289;&#20013;&#65292;&#22256;&#38590;&#31243;&#24230;&#21462;&#20915;&#20110;&#38544;&#31169;&#21644;&#19968;&#31181;&#26032;&#39062;&#30340;&#20449;&#24687;&#35770;&#25968;&#37327;&#65292;&#31216;&#20026;&#24635;&#21464;&#24046;&#29305;&#24449;&#26102;&#38388;&#30340;&#32806;&#21512;&#25928;&#24212;&#12290;&#22312;&#20302;&#38544;&#31169;&#21306;&#22495;&#65288;&#22823;&#949;&#65289;&#20013;&#65292;&#26679;&#26412;&#22797;&#26434;&#24615;&#19979;&#30028;&#38477;&#20302;&#21040;&#32463;&#20856;&#30340;&#38750;&#38544;&#31169;&#19979;&#30028;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;AdaP-TT&#65292;&#19968;&#31181;&#949;-&#20840;&#23616;&#24046;&#20998;&#38544;&#31169;&#19979;&#30340;&#33258;&#36866;&#24212;&#26368;&#20339;&#33218;&#35782;&#21035;&#31639;&#27861;&#65292;&#36890;&#36807;&#32771;&#34385;&#20449;&#24687;&#35770;&#29305;&#24615;&#26102;&#38388;&#30340;&#21160;&#24577;&#35843;&#25972;&#26469;&#24179;&#34913;&#38544;&#31169;&#19982;&#24615;&#33021;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
Best Arm Identification (BAI) problems are progressively used for data-sensitive applications, such as designing adaptive clinical trials, tuning hyper-parameters, and conducting user studies to name a few. Motivated by the data privacy concerns invoked by these applications, we study the problem of BAI with fixed confidence under $\epsilon$-global Differential Privacy (DP). First, to quantify the cost of privacy, we derive a lower bound on the sample complexity of any $\delta$-correct BAI algorithm satisfying $\epsilon$-global DP. Our lower bound suggests the existence of two privacy regimes depending on the privacy budget $\epsilon$. In the high-privacy regime (small $\epsilon$), the hardness depends on a coupled effect of privacy and a novel information-theoretic quantity, called the Total Variation Characteristic Time. In the low-privacy regime (large $\epsilon$), the sample complexity lower bound reduces to the classical non-private lower bound. Second, we propose AdaP-TT, an $\ep
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#31070;&#32463;&#32593;&#32476;&#20174;&#26435;&#37325;&#31354;&#38388;&#36716;&#25442;&#20026;&#20989;&#25968;&#31354;&#38388;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#31232;&#30095;&#34920;&#31034;&#25429;&#25417;&#25972;&#20010;&#25968;&#25454;&#38598;&#30340;&#20449;&#24687;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#32570;&#20047;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#21644;&#34701;&#20837;&#26032;&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.02195</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#30340;&#31232;&#30095;&#20989;&#25968;&#31354;&#38388;&#34920;&#31034;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sparse Function-space Representation of Neural Networks. (arXiv:2309.02195v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02195
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#31070;&#32463;&#32593;&#32476;&#20174;&#26435;&#37325;&#31354;&#38388;&#36716;&#25442;&#20026;&#20989;&#25968;&#31354;&#38388;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#31232;&#30095;&#34920;&#31034;&#25429;&#25417;&#25972;&#20010;&#25968;&#25454;&#38598;&#30340;&#20449;&#24687;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#32570;&#20047;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#21644;&#34701;&#20837;&#26032;&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24050;&#30693;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;NNs&#65289;&#32570;&#20047;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#24182;&#19988;&#38590;&#20197;&#34701;&#20837;&#26032;&#25968;&#25454;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#21452;&#37325;&#21442;&#25968;&#21270;&#23558;NNs&#20174;&#26435;&#37325;&#31354;&#38388;&#36716;&#25442;&#20026;&#20989;&#25968;&#31354;&#38388;&#65292;&#20197;&#20943;&#36731;&#36825;&#20123;&#38382;&#39064;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#21452;&#37325;&#21442;&#25968;&#21270;&#20351;&#25105;&#20204;&#33021;&#22815;&#21046;&#23450;&#20986;&#25429;&#25417;&#25972;&#20010;&#25968;&#25454;&#38598;&#20449;&#24687;&#30340;&#31232;&#30095;&#34920;&#31034;&#12290;&#36825;&#25552;&#20379;&#20102;&#19968;&#31181;&#32039;&#20945;&#19988;&#21407;&#21017;&#24615;&#30340;&#26041;&#27861;&#26469;&#25429;&#25417;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#20351;&#25105;&#20204;&#33021;&#22815;&#22312;&#19981;&#37325;&#26032;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#34701;&#20837;&#26032;&#25968;&#25454;&#65292;&#24182;&#20445;&#25345;&#39044;&#27979;&#24615;&#33021;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;UCI&#22522;&#20934;&#20219;&#21153;&#19978;&#20351;&#29992;&#35813;&#26041;&#27861;&#36827;&#34892;&#35777;&#26126;&#24615;&#28436;&#31034;&#65292;&#26469;&#37327;&#21270;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks (NNs) are known to lack uncertainty estimates and struggle to incorporate new data. We present a method that mitigates these issues by converting NNs from weight space to function space, via a dual parameterization. Importantly, the dual parameterization enables us to formulate a sparse representation that captures information from the entire data set. This offers a compact and principled way of capturing uncertainty and enables us to incorporate new data without retraining whilst retaining predictive performance. We provide proof-of-concept demonstrations with the proposed approach for quantifying uncertainty in supervised learning on UCI benchmark tasks.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#20559;&#35265;&#20256;&#25773;&#29616;&#35937;&#65292;&#23569;&#25968;&#23545;&#20110;&#36739;&#23569;&#20195;&#34920;&#30340;&#32676;&#20307;&#30340;&#20559;&#35265;&#21487;&#20197;&#36890;&#36807;&#32593;&#32476;&#20256;&#25773;&#21040;&#25152;&#26377;&#21442;&#19982;&#32773;&#65292;&#24182;&#19988;&#36825;&#31181;&#20559;&#35265;&#31243;&#24230;&#39640;&#20110;&#38598;&#20013;&#24335;&#35757;&#32451;&#12290;&#35813;&#30740;&#31350;&#21628;&#21505;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#23457;&#35745;&#32676;&#20307;&#20844;&#24179;&#24615;&#24182;&#35774;&#35745;&#30456;&#24212;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.02160</link><description>&lt;p&gt;
&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#20559;&#35265;&#20256;&#25773;
&lt;/p&gt;
&lt;p&gt;
Bias Propagation in Federated Learning. (arXiv:2309.02160v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02160
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#20559;&#35265;&#20256;&#25773;&#29616;&#35937;&#65292;&#23569;&#25968;&#23545;&#20110;&#36739;&#23569;&#20195;&#34920;&#30340;&#32676;&#20307;&#30340;&#20559;&#35265;&#21487;&#20197;&#36890;&#36807;&#32593;&#32476;&#20256;&#25773;&#21040;&#25152;&#26377;&#21442;&#19982;&#32773;&#65292;&#24182;&#19988;&#36825;&#31181;&#20559;&#35265;&#31243;&#24230;&#39640;&#20110;&#38598;&#20013;&#24335;&#35757;&#32451;&#12290;&#35813;&#30740;&#31350;&#21628;&#21505;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#23457;&#35745;&#32676;&#20307;&#20844;&#24179;&#24615;&#24182;&#35774;&#35745;&#30456;&#24212;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#21442;&#19982;&#32852;&#37030;&#23398;&#20064;&#21487;&#33021;&#23545;&#32676;&#20307;&#20844;&#24179;&#24615;&#26377;&#23475;&#12290;&#20107;&#23454;&#19978;&#65292;&#23569;&#25968;&#21442;&#19982;&#32773;&#23545;&#20110;&#34987;&#36739;&#23569;&#20195;&#34920;&#30340;&#32676;&#20307;&#65288;&#22914;&#24615;&#21035;&#25110;&#31181;&#26063;&#31561;&#25935;&#24863;&#23646;&#24615;&#30830;&#23450;&#30340;&#32676;&#20307;&#65289;&#30340;&#20559;&#35265;&#21487;&#20197;&#36890;&#36807;&#32593;&#32476;&#20256;&#25773;&#21040;&#25152;&#26377;&#21442;&#19982;&#32773;&#12290;&#25105;&#20204;&#22312;&#33258;&#28982;&#20998;&#21306;&#30340;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#20998;&#26512;&#21644;&#35299;&#37322;&#20102;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#20559;&#35265;&#20256;&#25773;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;&#20855;&#26377;&#20559;&#35265;&#30340;&#21442;&#19982;&#32773;&#26080;&#24847;&#20013;&#20294;&#31192;&#23494;&#22320;&#23558;&#20854;&#20559;&#35265;&#32534;&#30721;&#21040;&#23569;&#25968;&#27169;&#22411;&#21442;&#25968;&#20013;&#65292;&#24182;&#19988;&#22312;&#25972;&#20010;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#23427;&#20204;&#31283;&#27493;&#22686;&#21152;&#20102;&#20840;&#23616;&#27169;&#22411;&#23545;&#25935;&#24863;&#23646;&#24615;&#30340;&#20381;&#36182;&#12290;&#37325;&#35201;&#30340;&#26159;&#35201;&#24378;&#35843;&#30340;&#26159;&#65292;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#32463;&#21382;&#30340;&#20559;&#35265;&#27604;&#21442;&#19982;&#32773;&#22312;&#35757;&#32451;&#22312;&#25152;&#26377;&#25968;&#25454;&#30340;&#32852;&#21512;&#19978;&#30340;&#38598;&#20013;&#24335;&#35757;&#32451;&#20013;&#36935;&#21040;&#30340;&#35201;&#39640;&#12290;&#36825;&#34920;&#26126;&#20559;&#35265;&#26159;&#30001;&#31639;&#27861;&#36896;&#25104;&#30340;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#21628;&#21505;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#36827;&#34892;&#32676;&#20307;&#20844;&#24179;&#24615;&#23457;&#35745;&#21644;&#35774;&#35745;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show that participating in federated learning can be detrimental to group fairness. In fact, the bias of a few parties against under-represented groups (identified by sensitive attributes such as gender or race) can propagate through the network to all the parties in the network. We analyze and explain bias propagation in federated learning on naturally partitioned real-world datasets. Our analysis reveals that biased parties unintentionally yet stealthily encode their bias in a small number of model parameters, and throughout the training, they steadily increase the dependence of the global model on sensitive attributes. What is important to highlight is that the experienced bias in federated learning is higher than what parties would otherwise encounter in centralized training with a model trained on the union of all their data. This indicates that the bias is due to the algorithm. Our work calls for auditing group fairness in federated learning and designing learning algorithms t
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35823;&#24046;&#20998;&#26512;&#26469;&#25506;&#31350;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#23450;&#24615;&#34892;&#20026;&#30340;&#26041;&#27861;&#65292;&#20197;&#38543;&#26426;&#22352;&#26631;&#19979;&#38477;&#20026;&#20363;&#65292;&#30740;&#31350;&#20102;&#20462;&#25913;&#21518;&#24494;&#20998;&#26041;&#31243;&#30340;&#22343;&#26041;&#31283;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.02082</link><description>&lt;p&gt;
&#36890;&#36807;&#35823;&#24046;&#20998;&#26512;&#25506;&#31350;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#30340;&#23450;&#24615;&#34892;&#20026;&#65306;&#20197;&#38543;&#26426;&#22352;&#26631;&#19979;&#38477;&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
Backward error analysis and the qualitative behaviour of stochastic optimization algorithms: Application to stochastic coordinate descent. (arXiv:2309.02082v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02082
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35823;&#24046;&#20998;&#26512;&#26469;&#25506;&#31350;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#23450;&#24615;&#34892;&#20026;&#30340;&#26041;&#27861;&#65292;&#20197;&#38543;&#26426;&#22352;&#26631;&#19979;&#38477;&#20026;&#20363;&#65292;&#30740;&#31350;&#20102;&#20462;&#25913;&#21518;&#24494;&#20998;&#26041;&#31243;&#30340;&#22343;&#26041;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#22312;&#35299;&#20915;&#22823;&#35268;&#27169;&#20248;&#21270;&#38382;&#39064;&#26102;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#36991;&#20813;&#35745;&#31639;&#20840;&#37096;&#26799;&#24230;&#25152;&#24102;&#26469;&#30340;&#35745;&#31639;&#38590;&#39064;&#12290;&#20351;&#29992;&#25968;&#20540;&#31215;&#20998;&#22120;&#30340;&#25913;&#36827;&#26041;&#31243;&#29702;&#35770;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31867;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65292;&#26356;&#20934;&#30830;&#22320;&#36817;&#20284;&#20102;&#19968;&#33324;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#30340;&#21160;&#21147;&#23398;&#29305;&#24615;&#65292;&#36229;&#36807;&#20102;&#21407;&#22987;&#30340;&#26799;&#24230;&#27969;&#12290;&#20998;&#26512;&#20462;&#25913;&#36807;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#21487;&#20197;&#25581;&#31034;&#19982;&#20248;&#21270;&#26041;&#27861;&#30456;&#20851;&#30340;&#23450;&#24615;&#35265;&#35299;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38543;&#26426;&#22352;&#26631;&#19979;&#38477;&#26041;&#27861;&#20013;&#20462;&#25913;&#21518;&#30340;&#24494;&#20998;&#26041;&#31243;&#30340;&#22343;&#26041;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic optimization methods have been hugely successful in making large-scale optimization problems feasible when computing the full gradient is computationally prohibitive. Using the theory of modified equations for numerical integrators, we propose a class of stochastic differential equations that approximate the dynamics of general stochastic optimization methods more closely than the original gradient flow. Analyzing a modified stochastic differential equation can reveal qualitative insights about the associated optimization method. Here, we study mean-square stability of the modified equation in the case of stochastic coordinate descent.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#23545;&#29615;&#22659;&#21487;&#25345;&#32493;&#20154;&#24037;&#26234;&#33021;&#25552;&#20986;&#20102;&#25209;&#21028;&#24615;&#35270;&#35282;&#65292;&#35748;&#20026;&#20165;&#20165;&#25552;&#39640;&#25928;&#29575;&#36824;&#19981;&#36275;&#20197;&#20351;&#26426;&#22120;&#23398;&#20064;&#25104;&#20026;&#19968;&#31181;&#29615;&#22659;&#21487;&#25345;&#32493;&#30340;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2309.02065</link><description>&lt;p&gt;
&#25928;&#29575;&#19981;&#26159;&#21807;&#19968;&#26631;&#20934;&#65306;&#23545;&#29615;&#22659;&#21487;&#25345;&#32493;&#20154;&#24037;&#26234;&#33021;&#30340;&#25209;&#21028;&#24615;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Efficiency is Not Enough: A Critical Perspective of Environmentally Sustainable AI. (arXiv:2309.02065v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02065
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#23545;&#29615;&#22659;&#21487;&#25345;&#32493;&#20154;&#24037;&#26234;&#33021;&#25552;&#20986;&#20102;&#25209;&#21028;&#24615;&#35270;&#35282;&#65292;&#35748;&#20026;&#20165;&#20165;&#25552;&#39640;&#25928;&#29575;&#36824;&#19981;&#36275;&#20197;&#20351;&#26426;&#22120;&#23398;&#20064;&#25104;&#20026;&#19968;&#31181;&#29615;&#22659;&#21487;&#25345;&#32493;&#30340;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#30446;&#21069;&#30001;&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#31561;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#26041;&#27861;&#25512;&#21160;&#65292;&#36825;&#20123;&#26041;&#27861;&#21152;&#36895;&#20102;&#22312;&#35768;&#22810;&#21407;&#26412;&#34987;&#35748;&#20026;&#36229;&#20986;AI&#33539;&#22260;&#30340;&#20219;&#21153;&#19978;&#30340;&#36827;&#23637;&#12290;&#36825;&#20123;ML&#26041;&#27861;&#36890;&#24120;&#38656;&#35201;&#22823;&#37327;&#35745;&#31639;&#36164;&#28304;&#12289;&#33021;&#28304;&#28040;&#32791;&#22823;&#65292;&#24182;&#23548;&#33268;&#22823;&#37327;&#30340;&#30899;&#25490;&#25918;&#65292;&#36825;&#26159;&#20154;&#20026;&#27668;&#20505;&#21464;&#21270;&#30340;&#19968;&#20010;&#24050;&#30693;&#39537;&#21160;&#22240;&#32032;&#12290;&#27492;&#22806;&#65292;ML&#31995;&#32479;&#36816;&#34892;&#30340;&#24179;&#21488;&#19982;&#29615;&#22659;&#24433;&#21709;&#26377;&#20851;&#65292;&#21253;&#25324;&#30899;&#25490;&#25918;&#20043;&#22806;&#30340;&#20854;&#20182;&#26041;&#38754;&#12290;&#24037;&#19994;&#30028;&#21644;ML&#31038;&#21306;&#24191;&#27867;&#25512;&#23815;&#30340;&#25552;&#39640;ML&#31995;&#32479;&#22312;&#35745;&#31639;&#21644;&#33021;&#28304;&#28040;&#32791;&#26041;&#38754;&#30340;&#25928;&#29575;&#26469;&#25913;&#21892;&#29615;&#22659;&#21487;&#25345;&#32493;&#24615;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#25105;&#20204;&#35748;&#20026;&#20165;&#20165;&#20381;&#38752;&#25928;&#29575;&#36824;&#19981;&#36275;&#20197;&#20351;ML&#20316;&#20026;&#19968;&#31181;&#29615;&#22659;&#21487;&#25345;&#32493;&#30340;&#25216;&#26415;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#19977;&#20010;&#39640;&#23618;&#27425;&#30340;&#24046;&#24322;&#26469;&#38416;&#36848;&#32771;&#34385;&#20247;&#22810;&#21464;&#37327;&#23545;ML&#29615;&#22659;&#21487;&#25345;&#32493;&#24615;&#24433;&#21709;&#26102;&#65292;&#20165;&#20381;&#38752;&#25928;&#29575;&#26159;&#19981;&#22815;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Artificial Intelligence (AI) is currently spearheaded by machine learning (ML) methods such as deep learning (DL) which have accelerated progress on many tasks thought to be out of reach of AI. These ML methods can often be compute hungry, energy intensive, and result in significant carbon emissions, a known driver of anthropogenic climate change. Additionally, the platforms on which ML systems run are associated with environmental impacts including and beyond carbon emissions. The solution lionized by both industry and the ML community to improve the environmental sustainability of ML is to increase the efficiency with which ML systems operate in terms of both compute and energy consumption. In this perspective, we argue that efficiency alone is not enough to make ML as a technology environmentally sustainable. We do so by presenting three high level discrepancies between the effect of efficiency on the environmental sustainability of ML when considering the many variables which it in
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27010;&#29575;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;ProSMIN&#65292;&#36890;&#36807;&#35780;&#20998;&#35268;&#21017;&#26368;&#23567;&#21270;&#26469;&#25552;&#21319;&#34920;&#31034;&#36136;&#37327;&#21644;&#32531;&#35299;&#23849;&#28291;&#34920;&#31034;&#12290;&#26041;&#27861;&#36890;&#36807;&#20004;&#20010;&#31070;&#32463;&#32593;&#32476;&#21327;&#21516;&#23398;&#20064;&#22810;&#26679;&#20998;&#24067;&#30340;&#34920;&#31034;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;ProSMIN&#25910;&#25947;&#24615;&#30340;&#29702;&#35770;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2309.02048</link><description>&lt;p&gt;
&#36890;&#36807;&#35780;&#20998;&#35268;&#21017;&#26368;&#23567;&#21270;&#36827;&#34892;&#27010;&#29575;&#33258;&#30417;&#30563;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Self-supervised Learning via Scoring Rules Minimization. (arXiv:2309.02048v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02048
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27010;&#29575;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;ProSMIN&#65292;&#36890;&#36807;&#35780;&#20998;&#35268;&#21017;&#26368;&#23567;&#21270;&#26469;&#25552;&#21319;&#34920;&#31034;&#36136;&#37327;&#21644;&#32531;&#35299;&#23849;&#28291;&#34920;&#31034;&#12290;&#26041;&#27861;&#36890;&#36807;&#20004;&#20010;&#31070;&#32463;&#32593;&#32476;&#21327;&#21516;&#23398;&#20064;&#22810;&#26679;&#20998;&#24067;&#30340;&#34920;&#31034;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;ProSMIN&#25910;&#25947;&#24615;&#30340;&#29702;&#35770;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27010;&#29575;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;ProSMIN&#65292;&#36890;&#36807;&#35780;&#20998;&#35268;&#21017;&#26368;&#23567;&#21270;&#26469;&#25552;&#21319;&#34920;&#31034;&#36136;&#37327;&#21644;&#32531;&#35299;&#23849;&#28291;&#34920;&#31034;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#20004;&#20010;&#31070;&#32463;&#32593;&#32476;&#65306;&#22312;&#32447;&#32593;&#32476;&#21644;&#30446;&#26631;&#32593;&#32476;&#65292;&#23427;&#20204;&#36890;&#36807;&#30693;&#35782;&#33976;&#39311;&#30456;&#20114;&#21327;&#20316;&#23398;&#20064;&#34920;&#31034;&#30340;&#22810;&#26679;&#20998;&#24067;&#12290;&#36890;&#36807;&#23558;&#36755;&#20837;&#26679;&#26412;&#20197;&#20004;&#31181;&#22686;&#24378;&#26684;&#24335;&#21576;&#29616;&#65292;&#35757;&#32451;&#22312;&#32447;&#32593;&#32476;&#26469;&#39044;&#27979;&#19981;&#21516;&#22686;&#24378;&#35270;&#22270;&#19979;&#30340;&#30446;&#26631;&#32593;&#32476;&#34920;&#31034;&#30340;&#30456;&#21516;&#26679;&#26412;&#12290;&#36890;&#36807;&#22522;&#20110;&#36866;&#24403;&#30340;&#35780;&#20998;&#35268;&#21017;&#30340;&#26032;&#25439;&#22833;&#20989;&#25968;&#35757;&#32451;&#36825;&#20004;&#20010;&#32593;&#32476;&#12290;&#25105;&#20204;&#23545;ProSMIN&#30340;&#25910;&#25947;&#24615;&#25552;&#20379;&#20102;&#29702;&#35770;&#35777;&#26126;&#65292;&#35777;&#26126;&#20102;&#20854;&#20462;&#25913;&#21518;&#30340;&#35780;&#20998;&#35268;&#21017;&#30340;&#20005;&#26684;&#36866;&#29992;&#24615;&#12290;&#36825;&#19968;&#35748;&#35782;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#21270;&#36807;&#31243;&#24182;&#26377;&#21161;&#20110;&#20854;&#22312;&#25552;&#21319;&#34920;&#31034;&#36136;&#37327;&#26041;&#38754;&#30340;&#31283;&#20581;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a novel probabilistic self-supervised learning via Scoring Rule Minimization (ProSMIN), which leverages the power of probabilistic models to enhance representation quality and mitigate collapsing representations. Our proposed approach involves two neural networks; the online network and the target network, which collaborate and learn the diverse distribution of representations from each other through knowledge distillation. By presenting the input samples in two augmented formats, the online network is trained to predict the target network representation of the same sample under a different augmented view. The two networks are trained via our new loss function based on proper scoring rules. We provide a theoretical justification for ProSMIN's convergence, demonstrating the strict propriety of its modified scoring rule. This insight validates the method's optimization process and contributes to its robustness and effectiveness in improving representation qualit
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#32447;&#24615;&#22238;&#24402;&#30340;&#26032;&#39062;&#26799;&#24230;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#21516;&#23376;&#32452;&#30340;&#24322;&#26500;&#25968;&#25454;&#25209;&#27425;&#20013;&#36827;&#34892;&#23398;&#20064;&#65292;&#24182;&#19988;&#19981;&#20877;&#38656;&#35201;&#20551;&#35774;&#36755;&#20837;&#20998;&#24067;&#20026;&#39640;&#26031;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2309.01973</link><description>&lt;p&gt;
&#20351;&#29992;&#24322;&#26500;&#25968;&#25454;&#25209;&#27425;&#30340;&#32447;&#24615;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Linear Regression using Heterogeneous Data Batches. (arXiv:2309.01973v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01973
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#32447;&#24615;&#22238;&#24402;&#30340;&#26032;&#39062;&#26799;&#24230;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#21516;&#23376;&#32452;&#30340;&#24322;&#26500;&#25968;&#25454;&#25209;&#27425;&#20013;&#36827;&#34892;&#23398;&#20064;&#65292;&#24182;&#19988;&#19981;&#20877;&#38656;&#35201;&#20551;&#35774;&#36755;&#20837;&#20998;&#24067;&#20026;&#39640;&#26031;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#23398;&#20064;&#24212;&#29992;&#20013;&#65292;&#25968;&#25454;&#26159;&#20174;&#22810;&#20010;&#26469;&#28304;&#25910;&#38598;&#30340;&#65292;&#27599;&#20010;&#26469;&#28304;&#37117;&#25552;&#20379;&#19968;&#25209;&#26679;&#26412;&#65292;&#21333;&#29420;&#30340;&#26679;&#26412;&#26159;&#19981;&#36275;&#20197;&#23398;&#20064;&#20854;&#36755;&#20837;-&#36755;&#20986;&#20851;&#31995;&#30340;&#12290;&#19968;&#31181;&#24120;&#35265;&#30340;&#26041;&#27861;&#26159;&#20551;&#35774;&#36825;&#20123;&#26469;&#28304;&#23646;&#20110;&#25968;&#20010;&#26410;&#30693;&#30340;&#23376;&#32452;&#65292;&#27599;&#20010;&#23376;&#32452;&#20855;&#26377;&#26410;&#30693;&#30340;&#36755;&#20837;&#20998;&#24067;&#21644;&#36755;&#20837;-&#36755;&#20986;&#20851;&#31995;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#36825;&#31181;&#35774;&#32622;&#26368;&#22522;&#26412;&#21644;&#37325;&#35201;&#30340;&#34920;&#29616;&#20043;&#19968;&#65292;&#21363;&#36755;&#20986;&#26159;&#36755;&#20837;&#30340;&#22122;&#22768;&#32447;&#24615;&#32452;&#21512;&#65292;&#24182;&#19988;&#26377; $k$ &#20010;&#23376;&#32452;&#65292;&#27599;&#20010;&#23376;&#32452;&#37117;&#26377;&#33258;&#24049;&#30340;&#22238;&#24402;&#21521;&#37327;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;[1]&#34920;&#26126;&#65292;&#36890;&#36807;&#20016;&#23500;&#30340;&#23567;&#25209;&#37327;&#65292;&#21487;&#20197;&#29992;&#23569;&#25968;&#20013;&#31561;&#22823;&#23567;&#30340;&#25209;&#27425;&#26469;&#23398;&#20064;&#22238;&#24402;&#21521;&#37327;&#65292;&#27599;&#20010;&#25209;&#27425;&#26377; $\tilde\Omega( k^{3/2})$ &#20010;&#26679;&#26412;&#12290;&#28982;&#32780;&#65292;&#35813;&#35770;&#25991;&#35201;&#27714;&#25152;&#26377; $k$ &#20010;&#23376;&#32452;&#30340;&#36755;&#20837;&#20998;&#24067;&#26159;&#21508;&#21521;&#21516;&#24615;&#30340;&#39640;&#26031;&#20998;&#24067;&#65292;&#24182;&#34920;&#31034;&#21435;&#38500;&#36825;&#19968;&#20551;&#35774;&#26159;&#19968;&#20010;&#8220;&#26377;&#36259;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#8221;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#31639;&#27861;&#65292;&#23427;&#21487;&#20197;:
&lt;/p&gt;
&lt;p&gt;
In many learning applications, data are collected from multiple sources, each providing a \emph{batch} of samples that by itself is insufficient to learn its input-output relationship. A common approach assumes that the sources fall in one of several unknown subgroups, each with an unknown input distribution and input-output relationship. We consider one of this setup's most fundamental and important manifestations where the output is a noisy linear combination of the inputs, and there are $k$ subgroups, each with its own regression vector. Prior work~\cite{kong2020meta} showed that with abundant small-batches, the regression vectors can be learned with only few, $\tilde\Omega( k^{3/2})$, batches of medium-size with $\tilde\Omega(\sqrt k)$ samples each. However, the paper requires that the input distribution for all $k$ subgroups be isotropic Gaussian, and states that removing this assumption is an ``interesting and challenging problem". We propose a novel gradient-based algorithm that
&lt;/p&gt;</description></item><item><title>QuantEase&#26159;&#19968;&#31181;&#22522;&#20110;&#20248;&#21270;&#30340;&#35821;&#35328;&#27169;&#22411;&#37327;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#36880;&#23618;&#37327;&#21270;&#21644;&#22522;&#20110;&#22352;&#26631;&#19979;&#38477;&#30340;&#31639;&#27861;&#65292;&#39640;&#36136;&#37327;&#22320;&#35299;&#20915;&#20102;&#22797;&#26434;&#30340;&#38750;&#20984;&#37327;&#21270;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#23545;&#24322;&#24120;&#20540;&#25935;&#24863;&#30340;&#21464;&#31181;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.01885</link><description>&lt;p&gt;
QuantEase: &#22522;&#20110;&#20248;&#21270;&#30340;&#35821;&#35328;&#27169;&#22411;&#37327;&#21270;--&#19968;&#31181;&#39640;&#25928;&#32780;&#30452;&#35266;&#30340;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
QuantEase: Optimization-based Quantization for Language Models -- An Efficient and Intuitive Algorithm. (arXiv:2309.01885v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01885
&lt;/p&gt;
&lt;p&gt;
QuantEase&#26159;&#19968;&#31181;&#22522;&#20110;&#20248;&#21270;&#30340;&#35821;&#35328;&#27169;&#22411;&#37327;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#36880;&#23618;&#37327;&#21270;&#21644;&#22522;&#20110;&#22352;&#26631;&#19979;&#38477;&#30340;&#31639;&#27861;&#65292;&#39640;&#36136;&#37327;&#22320;&#35299;&#20915;&#20102;&#22797;&#26434;&#30340;&#38750;&#20984;&#37327;&#21270;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#23545;&#24322;&#24120;&#20540;&#25935;&#24863;&#30340;&#21464;&#31181;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#26222;&#21450;&#65292;&#23545;&#20110;&#33021;&#22815;&#23454;&#29616;&#20854;&#39640;&#25928;&#37096;&#32626;&#30340;&#21387;&#32553;&#25216;&#26415;&#30340;&#20852;&#36259;&#26085;&#30410;&#22686;&#21152;&#12290;&#26412;&#30740;&#31350;&#20391;&#37325;&#20110;LLM&#30340;&#21518;&#35757;&#32451;&#37327;&#21270;&#65288;PTQ&#65289;&#12290;&#20511;&#37492;&#26368;&#36817;&#30340;&#36827;&#23637;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#24341;&#20837;&#20102;QuantEase&#65292;&#19968;&#20010;&#36880;&#23618;&#37327;&#21270;&#26694;&#26550;&#65292;&#20854;&#20013;&#21508;&#20010;&#23618;&#38754;&#32463;&#36807;&#21333;&#29420;&#30340;&#37327;&#21270;&#12290;&#35813;&#38382;&#39064;&#34987;&#35270;&#20026;&#31163;&#25955;&#32467;&#26500;&#21270;&#30340;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#20419;&#20351;&#25105;&#20204;&#24320;&#21457;&#20102;&#22522;&#20110;&#22352;&#26631;&#19979;&#38477;&#65288;CD&#65289;&#25216;&#26415;&#30340;&#31639;&#27861;&#12290;&#36825;&#20123;&#22522;&#20110;CD&#30340;&#26041;&#27861;&#20026;&#22797;&#26434;&#30340;&#38750;&#20984;&#36880;&#23618;&#37327;&#21270;&#38382;&#39064;&#25552;&#20379;&#20102;&#39640;&#36136;&#37327;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;CD&#26041;&#27861;&#20855;&#26377;&#31616;&#21333;&#30340;&#26356;&#26032;&#27493;&#39588;&#65292;&#20165;&#20381;&#36182;&#20110;&#30697;&#38453;&#21644;&#21521;&#37327;&#36816;&#31639;&#65292;&#36991;&#20813;&#20102;&#30697;&#38453;&#27714;&#36870;&#25110;&#20998;&#35299;&#30340;&#38656;&#35201;&#12290;&#25105;&#20204;&#36824;&#25506;&#32034;&#20102;&#19968;&#31181;&#23545;&#24322;&#24120;&#20540;&#25935;&#24863;&#30340;&#21464;&#31181;&#26041;&#27861;&#65292;&#20801;&#35768;&#20445;&#30041;&#20855;&#26377;&#23436;&#20840;&#31934;&#24230;&#30340;&#37325;&#35201;&#26435;&#37325;&#65288;&#24322;&#24120;&#20540;&#65289;&#12290;&#25105;&#20204;&#30340;&#25552;&#35758;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#29366;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the rising popularity of Large Language Models (LLMs), there has been an increasing interest in compression techniques that enable their efficient deployment. This study focuses on the Post-Training Quantization (PTQ) of LLMs. Drawing from recent advances, our work introduces QuantEase, a layer-wise quantization framework where individual layers undergo separate quantization. The problem is framed as a discrete-structured non-convex optimization, prompting the development of algorithms rooted in Coordinate Descent (CD) techniques. These CD-based methods provide high-quality solutions to the complex non-convex layer-wise quantization problems. Notably, our CD-based approach features straightforward updates, relying solely on matrix and vector operations, circumventing the need for matrix inversion or decomposition. We also explore an outlier-aware variant of our approach, allowing for retaining significant weights (outliers) with complete precision. Our proposal attains state-of-th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#28176;&#36817;&#36924;&#36817;&#26041;&#27861;&#65292;&#29992;&#20110;&#35745;&#31639;&#22810;&#39033;&#24335;&#27010;&#29575;&#26435;&#37325;&#30340;&#32622;&#20449;&#21306;&#38388;&#21644;&#32047;&#31215;&#20998;&#24067;&#20989;&#25968;&#27604;&#36739;&#65292;&#24182;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#31163;&#25955;&#20998;&#24067;&#30340;&#36127;&#29109;&#32622;&#20449;&#21306;&#38388;&#30340;&#35745;&#31639;&#12290;</title><link>http://arxiv.org/abs/2309.01882</link><description>&lt;p&gt;
Pearson&#30340;&#21345;&#26041;&#32479;&#35745;&#30340;&#38750;&#28176;&#36817;&#36924;&#36817;&#21450;&#20854;&#22312;&#31163;&#25955;&#20998;&#24067;&#27010;&#29575;&#26435;&#37325;&#30340;&#20005;&#26684;&#20984;&#20989;&#25968;&#32622;&#20449;&#21306;&#38388;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Non-asymptotic approximations for Pearson's chi-square statistic and its application to confidence intervals for strictly convex functions of the probability weights of discrete distributions. (arXiv:2309.01882v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01882
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#28176;&#36817;&#36924;&#36817;&#26041;&#27861;&#65292;&#29992;&#20110;&#35745;&#31639;&#22810;&#39033;&#24335;&#27010;&#29575;&#26435;&#37325;&#30340;&#32622;&#20449;&#21306;&#38388;&#21644;&#32047;&#31215;&#20998;&#24067;&#20989;&#25968;&#27604;&#36739;&#65292;&#24182;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#31163;&#25955;&#20998;&#24067;&#30340;&#36127;&#29109;&#32622;&#20449;&#21306;&#38388;&#30340;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#22810;&#39033;&#24335;&#27010;&#29575;&#26435;&#37325;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#28176;&#36817;&#23616;&#37096;&#27491;&#24577;&#36924;&#36817;&#26041;&#27861;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#20351;&#29992;&#35813;&#26041;&#27861;&#25214;&#21040;&#20102;&#22343;&#21248;&#25238;&#21160;&#22810;&#39033;&#24335;&#21644;&#20855;&#26377;&#30456;&#21516;&#22343;&#20540;&#21644;&#21327;&#26041;&#24046;&#30340;&#22810;&#20803;&#27491;&#24577;&#20998;&#24067;&#25152;&#24341;&#36215;&#30340;&#24230;&#37327;&#20043;&#38388;&#30340;&#38750;&#28176;&#36817;&#24635;&#21464;&#24046;&#30028;&#38480;&#12290;&#26681;&#25454;&#24635;&#21464;&#24046;&#30028;&#38480;&#65292;&#25105;&#20204;&#36824;&#24471;&#21040;&#20102;Pearson&#30340;&#21345;&#26041;&#32479;&#35745;&#37327;&#65288;&#34920;&#31034;&#20026;&#22810;&#39033;&#24335;&#21521;&#37327;&#30340;&#24402;&#19968;&#21270;&#20108;&#27425;&#22411;&#65289;&#21644;&#20854;&#22810;&#20803;&#27491;&#24577;&#20998;&#26512;&#30340;&#32047;&#31215;&#20998;&#24067;&#20989;&#25968;&#30340;&#27604;&#36739;&#20197;&#21450;&#20998;&#20301;&#25968;&#32806;&#21512;&#19981;&#31561;&#24335;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#32467;&#26524;&#24212;&#29992;&#20110;&#27714;&#35299;&#31163;&#25955;&#20998;&#24067;&#30340;&#36127;&#29109;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#26356;&#26222;&#36941;&#22320;&#24212;&#29992;&#20110;&#27714;&#35299;&#31163;&#25955;&#20998;&#24067;&#26435;&#37325;&#30340;&#20005;&#26684;&#20984;&#20989;&#25968;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we develop a non-asymptotic local normal approximation for multinomial probabilities. First, we use it to find non-asymptotic total variation bounds between the measures induced by uniformly jittered multinomials and the multivariate normals with the same means and covariances. From the total variation bounds, we also derive a comparison of the cumulative distribution functions and quantile coupling inequalities between Pearson's chi-square statistic (written as the normalized quadratic form of a multinomial vector) and its multivariate normal analogue. We apply our results to find confidence intervals for the negative entropy of discrete distributions. Our method can be applied more generally to find confidence intervals for strictly convex functions of the weights of discrete distributions.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#22312;&#20998;&#25955;&#26426;&#22120;&#23398;&#20064;&#29983;&#24577;&#31995;&#32479;&#20013;&#30740;&#31350;&#20102;&#22996;&#25176;&#30340;&#25968;&#25454;&#25910;&#38598;&#38382;&#39064;&#65292;&#36890;&#36807;&#35774;&#35745;&#26368;&#20248;&#22865;&#32422;&#35299;&#20915;&#20102;&#27169;&#22411;&#36136;&#37327;&#35780;&#20272;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#23545;&#26368;&#20248;&#24615;&#33021;&#32570;&#20047;&#39044;&#20808;&#30693;&#35782;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2309.01837</link><description>&lt;p&gt;
&#22996;&#25176;&#20998;&#25955;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#25968;&#25454;&#25910;&#38598;
&lt;/p&gt;
&lt;p&gt;
Delegating Data Collection in Decentralized Machine Learning. (arXiv:2309.01837v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01837
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#22312;&#20998;&#25955;&#26426;&#22120;&#23398;&#20064;&#29983;&#24577;&#31995;&#32479;&#20013;&#30740;&#31350;&#20102;&#22996;&#25176;&#30340;&#25968;&#25454;&#25910;&#38598;&#38382;&#39064;&#65292;&#36890;&#36807;&#35774;&#35745;&#26368;&#20248;&#22865;&#32422;&#35299;&#20915;&#20102;&#27169;&#22411;&#36136;&#37327;&#35780;&#20272;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#23545;&#26368;&#20248;&#24615;&#33021;&#32570;&#20047;&#39044;&#20808;&#30693;&#35782;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#20998;&#25955;&#26426;&#22120;&#23398;&#20064;&#29983;&#24577;&#31995;&#32479;&#30340;&#20986;&#29616;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#25968;&#25454;&#25910;&#38598;&#30340;&#22996;&#25176;&#38382;&#39064;&#12290;&#20197;&#22865;&#32422;&#29702;&#35770;&#20026;&#20986;&#21457;&#28857;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#35299;&#20915;&#20004;&#20010;&#22522;&#26412;&#26426;&#22120;&#23398;&#20064;&#25361;&#25112;&#30340;&#26368;&#20248;&#21644;&#36817;&#20284;&#26368;&#20248;&#22865;&#32422;&#65306;&#27169;&#22411;&#36136;&#37327;&#35780;&#20272;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#23545;&#20219;&#20309;&#27169;&#22411;&#26368;&#20248;&#24615;&#33021;&#30340;&#32570;&#20047;&#30693;&#35782;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#36890;&#36807;&#31616;&#21333;&#30340;&#32447;&#24615;&#22865;&#32422;&#21487;&#20197;&#35299;&#20915;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;&#21363;&#20351;&#22996;&#25176;&#20154;&#21482;&#26377;&#19968;&#20010;&#23567;&#30340;&#27979;&#35797;&#38598;&#65292;&#20063;&#33021;&#23454;&#29616;1-1/e&#30340;&#19968;&#31561;&#25928;&#29992;&#27700;&#24179;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#22996;&#25176;&#20154;&#27979;&#35797;&#38598;&#22823;&#23567;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#21487;&#20197;&#36798;&#21040;&#23545;&#26368;&#20248;&#25928;&#29992;&#30340;&#36924;&#36817;&#12290;&#20026;&#20102;&#35299;&#20915;&#23545;&#26368;&#20248;&#24615;&#33021;&#32570;&#20047;&#39044;&#20808;&#30693;&#35782;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20984;&#38382;&#39064;&#65292;&#21487;&#20197;&#33258;&#36866;&#24212;&#21644;&#39640;&#25928;&#22320;&#35745;&#31639;&#26368;&#20248;&#22865;&#32422;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by the emergence of decentralized machine learning ecosystems, we study the delegation of data collection. Taking the field of contract theory as our starting point, we design optimal and near-optimal contracts that deal with two fundamental machine learning challenges: lack of certainty in the assessment of model quality and lack of knowledge regarding the optimal performance of any model. We show that lack of certainty can be dealt with via simple linear contracts that achieve 1-1/e fraction of the first-best utility, even if the principal has a small test set. Furthermore, we give sufficient conditions on the size of the principal's test set that achieves a vanishing additive approximation to the optimal utility. To address the lack of a priori knowledge regarding the optimal performance, we give a convex program that can adaptively and efficiently compute the optimal contract.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#65292;&#36890;&#36807;&#23567;&#30340;&#38543;&#26426;&#21021;&#22987;&#21270;&#24212;&#29992;&#22240;&#24335;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#26469;&#37325;&#24314;&#20302;&#31209;&#30697;&#38453;&#12290;&#29305;&#21035;&#22320;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;&#36830;&#32493;&#24494;&#20998;&#26041;&#31243;&#65292;&#31216;&#20026;&#8220;&#25200;&#21160;&#26799;&#24230;&#27969;&#8221;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#25200;&#21160;&#34987;&#38480;&#21046;&#22312;&#19968;&#23450;&#33539;&#22260;&#20869;&#26102;&#65292;&#25200;&#21160;&#26799;&#24230;&#27969;&#33021;&#22815;&#24555;&#36895;&#25910;&#25947;&#21040;&#30495;&#23454;&#30340;&#30446;&#26631;&#30697;&#38453;&#12290;</title><link>http://arxiv.org/abs/2309.01796</link><description>&lt;p&gt;
&#29992;&#23567;&#30340;&#38543;&#26426;&#21021;&#22987;&#21270;&#26799;&#24230;&#19979;&#38477;&#36827;&#34892;&#38750;&#23545;&#31216;&#30697;&#38453;&#24863;&#30693;
&lt;/p&gt;
&lt;p&gt;
Asymmetric matrix sensing by gradient descent with small random initialization. (arXiv:2309.01796v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01796
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#65292;&#36890;&#36807;&#23567;&#30340;&#38543;&#26426;&#21021;&#22987;&#21270;&#24212;&#29992;&#22240;&#24335;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#26469;&#37325;&#24314;&#20302;&#31209;&#30697;&#38453;&#12290;&#29305;&#21035;&#22320;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;&#36830;&#32493;&#24494;&#20998;&#26041;&#31243;&#65292;&#31216;&#20026;&#8220;&#25200;&#21160;&#26799;&#24230;&#27969;&#8221;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#25200;&#21160;&#34987;&#38480;&#21046;&#22312;&#19968;&#23450;&#33539;&#22260;&#20869;&#26102;&#65292;&#25200;&#21160;&#26799;&#24230;&#27969;&#33021;&#22815;&#24555;&#36895;&#25910;&#25947;&#21040;&#30495;&#23454;&#30340;&#30446;&#26631;&#30697;&#38453;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#30697;&#38453;&#24863;&#30693;&#65292;&#21363;&#20174;&#23569;&#37327;&#32447;&#24615;&#27979;&#37327;&#20013;&#37325;&#24314;&#20302;&#31209;&#30697;&#38453;&#30340;&#38382;&#39064;&#12290;&#23427;&#21487;&#20197;&#34987;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#36807;&#21442;&#25968;&#21270;&#22238;&#24402;&#38382;&#39064;&#65292;&#21487;&#20197;&#36890;&#36807;&#22240;&#24335;&#20998;&#35299;&#30340;&#26799;&#24230;&#19979;&#38477;&#35299;&#20915;&#65292;&#24403;&#20174;&#19968;&#20010;&#23567;&#30340;&#38543;&#26426;&#21021;&#22987;&#21270;&#24320;&#22987;&#12290;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#65292;&#29305;&#21035;&#26159;&#36890;&#36807;&#22240;&#24335;&#26799;&#24230;&#19979;&#38477;&#36827;&#34892;&#30697;&#38453;&#24863;&#30693;&#65292;&#20316;&#20026;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#20013;&#38750;&#20984;&#38382;&#39064;&#30340;&#20856;&#22411;&#27169;&#22411;&#65292;&#21487;&#20197;&#23558;&#22797;&#26434;&#29616;&#35937;&#35299;&#24320;&#24182;&#35814;&#32454;&#30740;&#31350;&#12290;&#35768;&#22810;&#30740;&#31350;&#33268;&#21147;&#20110;&#30740;&#31350;&#38750;&#23545;&#31216;&#30697;&#38453;&#24863;&#30693;&#30340;&#29305;&#27530;&#24773;&#20917;&#65292;&#20363;&#22914;&#38750;&#23545;&#31216;&#30697;&#38453;&#22240;&#24335;&#20998;&#35299;&#21644;&#23545;&#31216;&#21322;&#27491;&#23450;&#30697;&#38453;&#24863;&#30693;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#36129;&#29486;&#26159;&#24341;&#20837;&#20102;&#19968;&#20010;&#36830;&#32493;&#24494;&#20998;&#26041;&#31243;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#8220;&#25200;&#21160;&#26799;&#24230;&#27969;&#8221;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#25200;&#21160;&#34987;&#38480;&#21046;&#22312;&#36275;&#22815;&#33539;&#22260;&#20869;&#26102;&#65292;&#25200;&#21160;&#26799;&#24230;&#27969;&#33021;&#22815;&#24555;&#36895;&#25910;&#25947;&#21040;&#30495;&#23454;&#30340;&#30446;&#26631;&#30697;&#38453;&#12290;&#26799;&#24230;&#19979;&#38477;&#23545;&#30697;&#38453;&#30340;&#21160;&#24577;
&lt;/p&gt;
&lt;p&gt;
We study matrix sensing, which is the problem of reconstructing a low-rank matrix from a few linear measurements. It can be formulated as an overparameterized regression problem, which can be solved by factorized gradient descent when starting from a small random initialization.  Linear neural networks, and in particular matrix sensing by factorized gradient descent, serve as prototypical models of non-convex problems in modern machine learning, where complex phenomena can be disentangled and studied in detail. Much research has been devoted to studying special cases of asymmetric matrix sensing, such as asymmetric matrix factorization and symmetric positive semi-definite matrix sensing.  Our key contribution is introducing a continuous differential equation that we call the $\textit{perturbed gradient flow}$. We prove that the perturbed gradient flow converges quickly to the true target matrix whenever the perturbation is sufficiently bounded. The dynamics of gradient descent for matr
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#35780;&#20998;&#20989;&#25968;CONFIDERAI&#65292;&#23427;&#23558;&#19968;&#33268;&#24615;&#39044;&#27979;&#19982;&#35268;&#21017;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#21033;&#29992;&#35268;&#21017;&#30340;&#39044;&#27979;&#33021;&#21147;&#21644;&#28857;&#30340;&#20960;&#20309;&#20301;&#32622;&#65292;&#22312;&#29305;&#24449;&#31354;&#38388;&#20013;&#23450;&#20041;&#28385;&#36275;&#19968;&#33268;&#24615;&#20445;&#35777;&#30340;&#21306;&#22495;&#12290;</title><link>http://arxiv.org/abs/2309.01778</link><description>&lt;p&gt;
CONFIDERAI&#65306;&#19968;&#31181;&#26032;&#39062;&#30340;CONFIRMAL&#21487;&#35299;&#37322;&#35774;&#35745;&#35780;&#20998;&#20989;&#25968;&#65292;&#29992;&#20110;&#21487;&#35299;&#37322;&#21644;&#21487;&#38752;&#30340;&#20154;&#24037;&#26234;&#33021;
&lt;/p&gt;
&lt;p&gt;
CONFIDERAI: a novel CONFormal Interpretable-by-Design score function forExplainable and Reliable Artificial Intelligence. (arXiv:2309.01778v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01778
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#35780;&#20998;&#20989;&#25968;CONFIDERAI&#65292;&#23427;&#23558;&#19968;&#33268;&#24615;&#39044;&#27979;&#19982;&#35268;&#21017;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#21033;&#29992;&#35268;&#21017;&#30340;&#39044;&#27979;&#33021;&#21147;&#21644;&#28857;&#30340;&#20960;&#20309;&#20301;&#32622;&#65292;&#22312;&#29305;&#24449;&#31354;&#38388;&#20013;&#23450;&#20041;&#28385;&#36275;&#19968;&#33268;&#24615;&#20445;&#35777;&#30340;&#21306;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27599;&#22825;&#30340;&#29983;&#27963;&#36234;&#26469;&#36234;&#21463;&#20154;&#24037;&#26234;&#33021;&#30340;&#24433;&#21709;&#65292;&#27627;&#26080;&#30097;&#38382;&#65292;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#24517;&#39035;&#20026;&#25152;&#26377;&#20154;&#35774;&#35745;&#25104;&#21487;&#38752;&#21644;&#20540;&#24471;&#20449;&#36182;&#30340;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#22914;&#26524;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#28385;&#36275;&#35299;&#37322;&#24615;&#12289;&#20581;&#22766;&#24615;&#12289;&#36879;&#26126;&#24615;&#12289;&#20844;&#24179;&#24615;&#21644;&#38544;&#31169;&#24615;&#36825;&#20116;&#20010;&#26041;&#38754;&#65292;&#35745;&#31639;&#26426;&#31185;&#23398;&#23478;&#35748;&#20026;&#23427;&#26159;&#23433;&#20840;&#21644;&#21487;&#20449;&#36182;&#30340;&#12290;&#38500;&#20102;&#36825;&#20116;&#20010;&#26041;&#38754;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#20845;&#20010;&#22522;&#26412;&#26041;&#38754;&#65306;&#19968;&#33268;&#24615;&#65292;&#21363;&#26426;&#22120;&#23398;&#20064;&#32773;&#23545;&#31995;&#32479;&#34892;&#20026;&#30340;&#27010;&#29575;&#24615;&#20445;&#35777;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#23450;&#20041;CONFIDERAI&#65292;&#19968;&#31181;&#22522;&#20110;&#35268;&#21017;&#30340;&#27169;&#22411;&#30340;&#26032;&#35780;&#20998;&#20989;&#25968;&#65292;&#23558;&#19968;&#33268;&#24615;&#39044;&#27979;&#19982;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#21033;&#29992;&#35268;&#21017;&#30340;&#39044;&#27979;&#33021;&#21147;&#21644;&#28857;&#22312;&#35268;&#21017;&#36793;&#30028;&#20869;&#30340;&#20960;&#20309;&#20301;&#32622;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#21033;&#29992;&#25511;&#21046;&#38750;&#19968;&#33268;&#24615;&#30340;&#25968;&#37327;&#30340;&#25216;&#26415;&#26469;&#35299;&#20915;&#22312;&#29305;&#24449;&#31354;&#38388;&#20013;&#23450;&#20041;&#28385;&#36275;&#19968;&#33268;&#24615;&#20445;&#35777;&#30340;&#21306;&#22495;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Everyday life is increasingly influenced by artificial intelligence, and there is no question that machine learning algorithms must be designed to be reliable and trustworthy for everyone. Specifically, computer scientists consider an artificial intelligence system safe and trustworthy if it fulfills five pillars: explainability, robustness, transparency, fairness, and privacy. In addition to these five, we propose a sixth fundamental aspect: conformity, that is, the probabilistic assurance that the system will behave as the machine learner expects. In this paper, we propose a methodology to link conformal prediction with explainable machine learning by defining CONFIDERAI, a new score function for rule-based models that leverages both rules predictive ability and points geometrical position within rules boundaries. We also address the problem of defining regions in the feature space where conformal guarantees are satisfied by exploiting techniques to control the number of non-conforma
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24191;&#20041;&#20449;&#24687;&#20934;&#21017;(GIC)&#65292;&#29992;&#20110;&#22312;&#39640;&#32500;&#24773;&#26223;&#19979;&#24674;&#22797;&#20302;&#32500;&#27169;&#22411;&#30340;&#32467;&#26500;&#31232;&#30095;&#27169;&#22411;&#12290;&#35813;&#20934;&#21017;&#32771;&#34385;&#20102;&#25152;&#38656;&#24674;&#22797;&#30340;&#31232;&#30095;&#27169;&#24335;&#65292;&#24182;&#25552;&#20379;&#20102;&#38750;&#28176;&#36827;&#30340;&#27169;&#22411;&#36873;&#25321;&#30028;&#38480;&#21644;&#19968;&#33268;&#24615;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2309.01764</link><description>&lt;p&gt;
&#32467;&#26500;&#31232;&#30095;&#27169;&#22411;&#30340;&#24191;&#20041;&#20449;&#24687;&#20934;&#21017;
&lt;/p&gt;
&lt;p&gt;
Generalized Information Criteria for Structured Sparse Models. (arXiv:2309.01764v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01764
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24191;&#20041;&#20449;&#24687;&#20934;&#21017;(GIC)&#65292;&#29992;&#20110;&#22312;&#39640;&#32500;&#24773;&#26223;&#19979;&#24674;&#22797;&#20302;&#32500;&#27169;&#22411;&#30340;&#32467;&#26500;&#31232;&#30095;&#27169;&#22411;&#12290;&#35813;&#20934;&#21017;&#32771;&#34385;&#20102;&#25152;&#38656;&#24674;&#22797;&#30340;&#31232;&#30095;&#27169;&#24335;&#65292;&#24182;&#25552;&#20379;&#20102;&#38750;&#28176;&#36827;&#30340;&#27169;&#22411;&#36873;&#25321;&#30028;&#38480;&#21644;&#19968;&#33268;&#24615;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27491;&#21017;&#21270;&#30340;m-&#20272;&#35745;&#22120;&#30001;&#20110;&#33021;&#22815;&#22312;&#39640;&#32500;&#24773;&#26223;&#19979;&#24674;&#22797;&#20302;&#32500;&#27169;&#22411;&#32780;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#35813;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#24314;&#31435;&#22885;&#20811;&#23572;&#30028;&#38480;&#30340;&#32479;&#19968;&#26694;&#26550;&#21644;&#25512;&#23548;&#25903;&#25345;&#24674;&#22797;&#30340;&#26465;&#20214;&#19978;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32771;&#34385;&#25152;&#38656;&#24674;&#22797;&#30340;&#31232;&#30095;&#27169;&#24335;&#30340;&#24191;&#20041;&#20449;&#24687;&#20934;&#21017;(GIC)&#12290;&#25105;&#20204;&#24471;&#21040;&#20102;&#38750;&#28176;&#36827;&#30340;&#27169;&#22411;&#36873;&#25321;&#30028;&#38480;&#65292;&#20197;&#21450;GIC&#27169;&#22411;&#36873;&#25321;&#19968;&#33268;&#24615;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#34920;&#26126;GIC&#20063;&#21487;&#20197;&#22312;&#35268;&#21017;&#21270;&#30340;$ m $-&#20272;&#35745;&#26694;&#26550;&#20013;&#29992;&#20110;&#36873;&#25321;&#27491;&#21017;&#21270;&#21442;&#25968;&#65292;&#20174;&#32780;&#22312;&#39640;&#32500;&#24773;&#26223;&#20013;&#23454;&#38469;&#20351;&#29992;GIC&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#12290;&#25105;&#20204;&#20197;&#24191;&#20041;&#32447;&#24615;&#22238;&#24402;&#21644;&#20302;&#31209;&#30697;&#38453;&#22238;&#24402;&#20013;&#30340;&#20998;&#32452;LASSO&#20026;&#20363;&#36827;&#34892;&#35828;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Regularized m-estimators are widely used due to their ability of recovering a low-dimensional model in high-dimensional scenarios. Some recent efforts on this subject focused on creating a unified framework for establishing oracle bounds, and deriving conditions for support recovery. Under this same framework, we propose a new Generalized Information Criteria (GIC) that takes into consideration the sparsity pattern one wishes to recover. We obtain non-asymptotic model selection bounds and sufficient conditions for model selection consistency of the GIC. Furthermore, we show that the GIC can also be used for selecting the regularization parameter within a regularized $m$-estimation framework, which allows practical use of the GIC for model selection in high-dimensional scenarios. We provide examples of group LASSO in the context of generalized linear regression and low rank matrix regression.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#40065;&#26834;&#32602;&#26368;&#23567;&#20108;&#20056;&#28145;&#24230;&#20462;&#21098;&#27531;&#24046;&#22238;&#24402;&#26041;&#27861;&#65292;&#38024;&#23545;&#39640;&#32500;&#25968;&#25454;&#30340;&#25361;&#25112;&#36827;&#34892;&#20102;&#28145;&#20837;&#30740;&#31350;&#65292;&#24182;&#25351;&#20986;&#22823;&#22810;&#25968;&#20256;&#32479;&#26041;&#27861;&#22312;&#22788;&#29702;&#24322;&#24120;&#20540;&#21644;&#27745;&#26579;&#28857;&#26102;&#19981;&#22815;&#31283;&#20581;&#12290;</title><link>http://arxiv.org/abs/2309.01666</link><description>&lt;p&gt;
&#39640;&#32500;&#25968;&#25454;&#30340;&#40065;&#26834;&#32602;&#26368;&#23567;&#20108;&#20056;&#28145;&#24230;&#20462;&#21098;&#27531;&#24046;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Robust penalized least squares of depth trimmed residuals regression for high-dimensional data. (arXiv:2309.01666v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01666
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#40065;&#26834;&#32602;&#26368;&#23567;&#20108;&#20056;&#28145;&#24230;&#20462;&#21098;&#27531;&#24046;&#22238;&#24402;&#26041;&#27861;&#65292;&#38024;&#23545;&#39640;&#32500;&#25968;&#25454;&#30340;&#25361;&#25112;&#36827;&#34892;&#20102;&#28145;&#20837;&#30740;&#31350;&#65292;&#24182;&#25351;&#20986;&#22823;&#22810;&#25968;&#20256;&#32479;&#26041;&#27861;&#22312;&#22788;&#29702;&#24322;&#24120;&#20540;&#21644;&#27745;&#26579;&#28857;&#26102;&#19981;&#22815;&#31283;&#20581;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#25968;&#25454;&#26102;&#20195;&#30340;&#25361;&#25112;&#21253;&#25324;&#65306;(i) &#32500;&#25968;p&#24448;&#24448;&#22823;&#20110;&#26679;&#26412;&#37327;n (ii) &#24322;&#24120;&#20540;&#25110;&#27745;&#26579;&#28857;&#32463;&#24120;&#34987;&#38544;&#34255;&#36215;&#26469;&#19988;&#26356;&#38590;&#26816;&#27979;&#12290;&#25361;&#25112;(i)&#20351;&#24471;&#22823;&#22810;&#25968;&#20256;&#32479;&#26041;&#27861;&#19981;&#36866;&#29992;&#65292;&#22240;&#27492;&#23427;&#21560;&#24341;&#20102;&#32479;&#35745;&#23398;&#12289;&#35745;&#31639;&#26426;&#31185;&#23398;&#21644;&#29983;&#29289;&#21307;&#23398;&#30028;&#30340;&#24191;&#27867;&#20851;&#27880;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#22823;&#37327;&#24809;&#32602;&#22238;&#24402;&#26041;&#27861;&#20316;&#20026;&#20998;&#26512;&#39640;&#32500;&#25968;&#25454;&#30340;&#29616;&#20195;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#20851;&#27880;&#20102;&#25361;&#25112;(ii)&#65292;&#20294;&#22823;&#22810;&#25968;&#26041;&#27861;&#22312;&#38754;&#23545;&#21333;&#20010;&#24322;&#24120;&#20540;&#25110;&#27745;&#26579;&#28857;&#26102;&#37117;&#20250;&#23849;&#28291;&#12290;
&lt;/p&gt;
&lt;p&gt;
Challenges with data in the big-data era include (i) the dimension $p$ is often larger than the sample size $n$ (ii) outliers or contaminated points are frequently hidden and more difficult to detect. Challenge (i) renders most conventional methods inapplicable. Thus, it attracts tremendous attention from statistics, computer science, and bio-medical communities. Numerous penalized regression methods have been introduced as modern methods for analyzing high-dimensional data. Disproportionate attention has been paid to the challenge (ii) though. Penalized regression methods can do their job very well and are expected to handle the challenge (ii) simultaneously. Most of them, however, can break down by a single outlier (or single adversary contaminated point) as revealed in this article.  The latter systematically examines leading penalized regression methods in the literature in terms of their robustness, provides quantitative assessment, and reveals that most of them can break down by 
&lt;/p&gt;</description></item><item><title>&#36825;&#26159;&#19968;&#31181;&#23616;&#37096;&#24179;&#31283;&#22270;&#24418;&#36807;&#31243;&#27169;&#22411;&#65292;&#26088;&#22312;&#23558;&#23616;&#37096;&#24179;&#31283;&#27010;&#24565;&#25193;&#23637;&#21040;&#19981;&#35268;&#21017;&#30340;&#22270;&#22495;&#19978;&#12290;&#23427;&#36890;&#36807;&#23558;&#25972;&#20010;&#36807;&#31243;&#34920;&#31034;&#20026;&#19968;&#32452;&#32452;&#25104;&#37096;&#20998;&#36807;&#31243;&#30340;&#32452;&#21512;&#26469;&#34920;&#24449;&#23616;&#37096;&#24179;&#31283;&#24615;&#65292;&#20197;&#20351;&#36807;&#31243;&#22312;&#22270;&#19978;&#25353;&#29031;&#27599;&#20010;&#32452;&#25104;&#37096;&#20998;&#30340;&#35201;&#27714;&#21464;&#21270;&#24471;&#26356;&#21152;&#24179;&#28369;&#12290;</title><link>http://arxiv.org/abs/2309.01657</link><description>&lt;p&gt;
&#23616;&#37096;&#24179;&#31283;&#22270;&#24418;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Locally Stationary Graph Processes. (arXiv:2309.01657v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01657
&lt;/p&gt;
&lt;p&gt;
&#36825;&#26159;&#19968;&#31181;&#23616;&#37096;&#24179;&#31283;&#22270;&#24418;&#36807;&#31243;&#27169;&#22411;&#65292;&#26088;&#22312;&#23558;&#23616;&#37096;&#24179;&#31283;&#27010;&#24565;&#25193;&#23637;&#21040;&#19981;&#35268;&#21017;&#30340;&#22270;&#22495;&#19978;&#12290;&#23427;&#36890;&#36807;&#23558;&#25972;&#20010;&#36807;&#31243;&#34920;&#31034;&#20026;&#19968;&#32452;&#32452;&#25104;&#37096;&#20998;&#36807;&#31243;&#30340;&#32452;&#21512;&#26469;&#34920;&#24449;&#23616;&#37096;&#24179;&#31283;&#24615;&#65292;&#20197;&#20351;&#36807;&#31243;&#22312;&#22270;&#19978;&#25353;&#29031;&#27599;&#20010;&#32452;&#25104;&#37096;&#20998;&#30340;&#35201;&#27714;&#21464;&#21270;&#24471;&#26356;&#21152;&#24179;&#28369;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19981;&#35268;&#21017;&#30340;&#32593;&#32476;&#25299;&#25169;&#19978;&#25910;&#38598;&#30340;&#25968;&#25454;&#38598;&#30340;&#20998;&#26512;&#21644;&#25512;&#29702;&#20013;&#65292;&#24120;&#24120;&#20250;&#20351;&#29992;&#24179;&#31283;&#22270;&#24418;&#36807;&#31243;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#20351;&#29992;&#21333;&#19968;&#30340;&#20840;&#23616;&#26377;&#25928;&#30340;&#24179;&#31283;&#36807;&#31243;&#27169;&#22411;&#34920;&#31034;&#22270;&#24418;&#20449;&#21495;&#65292;&#20294;&#22312;&#35768;&#22810;&#23454;&#38469;&#38382;&#39064;&#20013;&#65292;&#36807;&#31243;&#30340;&#29305;&#24615;&#21487;&#33021;&#20250;&#22312;&#22270;&#30340;&#19981;&#21516;&#21306;&#22495;&#21457;&#29983;&#23616;&#37096;&#21464;&#21270;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23616;&#37096;&#24179;&#31283;&#22270;&#24418;&#36807;&#31243;&#65288;LSGP&#65289;&#27169;&#22411;&#65292;&#26088;&#22312;&#23558;&#32463;&#20856;&#30340;&#23616;&#37096;&#24179;&#31283;&#27010;&#24565;&#25193;&#23637;&#21040;&#19981;&#35268;&#21017;&#30340;&#22270;&#22495;&#19978;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#25972;&#20010;&#36807;&#31243;&#34920;&#31034;&#20026;&#19968;&#32452;&#32452;&#25104;&#37096;&#20998;&#36807;&#31243;&#30340;&#32452;&#21512;&#26469;&#34920;&#24449;&#23616;&#37096;&#24179;&#31283;&#24615;&#65292;&#20197;&#20351;&#36807;&#31243;&#22312;&#22270;&#19978;&#25353;&#29031;&#27599;&#20010;&#32452;&#25104;&#37096;&#20998;&#30340;&#35201;&#27714;&#21464;&#21270;&#24471;&#26356;&#21152;&#24179;&#28369;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;LSGP&#27169;&#22411;&#30340;&#31639;&#27861;&#65292;&#24182;&#30740;&#31350;&#20102;&#29992;WSS&#36807;&#31243;&#23545;LSGP&#36827;&#34892;&#23616;&#37096;&#36817;&#20284;&#12290;&#22312;&#20449;&#21495;&#20869;&#25554;&#38382;&#39064;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#34920;&#26126;
&lt;/p&gt;
&lt;p&gt;
Stationary graph process models are commonly used in the analysis and inference of data sets collected on irregular network topologies. While most of the existing methods represent graph signals with a single stationary process model that is globally valid on the entire graph, in many practical problems, the characteristics of the process may be subject to local variations in different regions of the graph. In this work, we propose a locally stationary graph process (LSGP) model that aims to extend the classical concept of local stationarity to irregular graph domains. We characterize local stationarity by expressing the overall process as the combination of a set of component processes such that the extent to which the process adheres to each component varies smoothly over the graph. We propose an algorithm for computing LSGP models from realizations of the process, and also study the approximation of LSGPs locally with WSS processes. Experiments on signal interpolation problems show 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26399;&#26395;&#20256;&#25773;&#31639;&#27861;&#26469;&#25512;&#29702;&#21160;&#24577;probit&#27169;&#22411;&#20013;&#30340;&#24179;&#28369;&#20998;&#24067;&#65292;&#36890;&#36807;&#37329;&#34701;&#23454;&#20363;&#34920;&#26126;&#20102;&#20854;&#30456;&#23545;&#20110;&#29616;&#26377;&#31639;&#27861;&#30340;&#20934;&#30830;&#24230;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2309.01641</link><description>&lt;p&gt;
&#21160;&#24577;probit&#27169;&#22411;&#20013;&#24179;&#28369;&#20998;&#24067;&#30340;&#26399;&#26395;&#20256;&#25773;
&lt;/p&gt;
&lt;p&gt;
Expectation propagation for the smoothing distribution in dynamic probit. (arXiv:2309.01641v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01641
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26399;&#26395;&#20256;&#25773;&#31639;&#27861;&#26469;&#25512;&#29702;&#21160;&#24577;probit&#27169;&#22411;&#20013;&#30340;&#24179;&#28369;&#20998;&#24067;&#65292;&#36890;&#36807;&#37329;&#34701;&#23454;&#20363;&#34920;&#26126;&#20102;&#20854;&#30456;&#23545;&#20110;&#29616;&#26377;&#31639;&#27861;&#30340;&#20934;&#30830;&#24230;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#35777;&#26126;&#20102;&#20855;&#26377;&#39640;&#26031;&#29366;&#24577;&#21160;&#21147;&#23398;&#30340;&#21160;&#24577;probit&#27169;&#22411;&#30340;&#24179;&#28369;&#20998;&#24067;&#23646;&#20110;&#32479;&#19968;&#30340;&#20559;&#27491;&#24577;&#23478;&#26063;&#12290;&#23613;&#31649;&#22312;&#23567;&#21040;&#20013;&#31561;&#35268;&#27169;&#30340;&#35774;&#32622;&#20013;&#36825;&#26159;&#21487;&#35745;&#31639;&#30340;&#65292;&#20294;&#22312;&#26356;&#39640;&#32500;&#24230;&#19978;&#21487;&#33021;&#21464;&#24471;&#35745;&#31639;&#19981;&#21487;&#34892;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#19968;&#31181;&#26356;&#36890;&#29992;&#30340;&#26399;&#26395;&#20256;&#25773;&#31639;&#27861;&#31867;&#21035;&#65292;&#25512;&#23548;&#20986;&#19968;&#31181;&#26377;&#25928;&#30340;&#26399;&#26395;&#20256;&#25773;&#20363;&#31243;&#26469;&#36827;&#34892;&#36825;&#31181;&#20998;&#24067;&#30340;&#25512;&#29702;&#12290;&#25105;&#20204;&#36890;&#36807;&#37329;&#34701;&#23454;&#20363;&#34920;&#26126;&#25152;&#25552;&#20986;&#30340;&#36817;&#20284;&#26041;&#27861;&#30456;&#23545;&#20110;&#29616;&#26377;&#30340;&#36817;&#20284;&#31639;&#27861;&#20855;&#26377;&#20934;&#30830;&#24230;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
The smoothing distribution of dynamic probit models with Gaussian state dynamics was recently proved to belong to the unified skew-normal family. Although this is computationally tractable in small-to-moderate settings, it may become computationally impractical in higher dimensions. In this work, adapting a recent more general class of expectation propagation (EP) algorithms, we derive an efficient EP routine to perform inference for such a distribution. We show that the proposed approximation leads to accuracy gains over available approximate algorithms in a financial illustration.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#26399;&#26395;&#20256;&#25773;&#26041;&#27861;&#22312;&#36125;&#21494;&#26031;probit&#27169;&#22411;&#20013;&#39640;&#25928;&#35745;&#31639;&#39044;&#27979;&#27010;&#29575;&#65292;&#24182;&#23637;&#31034;&#20102;&#19982;&#26368;&#20808;&#36827;&#26041;&#27861;&#30456;&#27604;&#30340;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2309.01630</link><description>&lt;p&gt;
&#36890;&#36807;&#26399;&#26395;&#20256;&#25773;&#22312;probit&#27169;&#22411;&#20013;&#39640;&#25928;&#35745;&#31639;&#39044;&#27979;&#27010;&#29575;
&lt;/p&gt;
&lt;p&gt;
Efficient computation of predictive probabilities in probit models via expectation propagation. (arXiv:2309.01630v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01630
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#26399;&#26395;&#20256;&#25773;&#26041;&#27861;&#22312;&#36125;&#21494;&#26031;probit&#27169;&#22411;&#20013;&#39640;&#25928;&#35745;&#31639;&#39044;&#27979;&#27010;&#29575;&#65292;&#24182;&#23637;&#31034;&#20102;&#19982;&#26368;&#20808;&#36827;&#26041;&#27861;&#30456;&#27604;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20108;&#20803;&#22238;&#24402;&#27169;&#22411;&#26159;&#20108;&#20998;&#31867;&#30340;&#27969;&#34892;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290;&#22312;&#36125;&#21494;&#26031;&#26694;&#26550;&#20013;&#65292;&#21518;&#39564;&#20998;&#24067;&#30340;&#35745;&#31639;&#25361;&#25112;&#20419;&#20351;&#20102;&#20173;&#22312;&#36827;&#34892;&#30340;&#26377;&#30410;&#30740;&#31350;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20851;&#27880;&#36890;&#36807;&#26399;&#26395;&#20256;&#25773;&#65288;EP&#65289;&#22312;&#36125;&#21494;&#26031;probit&#27169;&#22411;&#20013;&#35745;&#31639;&#39044;&#27979;&#27010;&#29575;&#12290;&#21033;&#29992;&#26368;&#36817;&#25991;&#29486;&#20013;&#30340;&#26356;&#19968;&#33324;&#32467;&#26524;&#65292;&#25105;&#20204;&#23637;&#31034;&#36825;&#31181;&#39044;&#27979;&#27010;&#29575;&#21487;&#20197;&#24471;&#21040;&#19968;&#20010;&#38381;&#24335;&#34920;&#36798;&#24335;&#12290;&#22312;&#27169;&#25311;&#30740;&#31350;&#20013;&#23637;&#31034;&#20102;&#19982;&#26368;&#20808;&#36827;&#26041;&#27861;&#30456;&#27604;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Binary regression models represent a popular model-based approach for binary classification. In the Bayesian framework, computational challenges in the form of the posterior distribution motivate still-ongoing fruitful research. Here, we focus on the computation of predictive probabilities in Bayesian probit models via expectation propagation (EP). Leveraging more general results in recent literature, we show that such predictive probabilities admit a closed-form expression. Improvements over state-of-the-art approaches are shown in a simulation study.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#39640;&#32500;Probit&#27169;&#22411;&#20013;&#29992;&#20110;&#21518;&#39564;&#36817;&#20284;&#30340;&#39640;&#25928;&#26399;&#26395;&#20256;&#25773;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#25193;&#23637;&#22810;&#20803;&#20559;&#24577;&#27491;&#24577;&#20998;&#24067;&#30340;&#32467;&#26524;&#65292;&#23454;&#29616;&#20102;&#21487;&#35745;&#31639;&#24615;&#65292;&#24182;&#22312;&#35814;&#32454;&#30340;&#27169;&#25311;&#30740;&#31350;&#20013;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.01619</link><description>&lt;p&gt;
&#22312;&#39640;&#32500;Probit&#27169;&#22411;&#20013;&#65292;&#29992;&#20110;&#21518;&#39564;&#36817;&#20284;&#30340;&#39640;&#25928;&#26399;&#26395;&#20256;&#25773;
&lt;/p&gt;
&lt;p&gt;
Efficient expectation propagation for posterior approximation in high-dimensional probit models. (arXiv:2309.01619v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01619
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#39640;&#32500;Probit&#27169;&#22411;&#20013;&#29992;&#20110;&#21518;&#39564;&#36817;&#20284;&#30340;&#39640;&#25928;&#26399;&#26395;&#20256;&#25773;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#25193;&#23637;&#22810;&#20803;&#20559;&#24577;&#27491;&#24577;&#20998;&#24067;&#30340;&#32467;&#26524;&#65292;&#23454;&#29616;&#20102;&#21487;&#35745;&#31639;&#24615;&#65292;&#24182;&#22312;&#35814;&#32454;&#30340;&#27169;&#25311;&#30740;&#31350;&#20013;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20108;&#20803;&#22238;&#24402;&#26159;&#19968;&#20010;&#32321;&#33635;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#30001;&#20110;&#24403;&#21069;&#21487;&#29992;&#26041;&#27861;&#22312;&#39640;&#32500;&#35774;&#32622;&#12289;&#22823;&#25968;&#25454;&#38598;&#25110;&#20004;&#32773;&#37117;&#36935;&#21040;&#30340;&#35745;&#31639;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20851;&#27880;&#20110;&#36125;&#21494;&#26031;probit&#22238;&#24402;&#20013;&#21518;&#39564;&#20998;&#24067;&#30340;&#26399;&#26395;&#20256;&#25773;&#65288;EP&#65289;&#36817;&#20284;&#65292;&#20854;&#22312;&#22810;&#20803;&#39640;&#26031;&#20808;&#39564;&#20998;&#24067;&#19979;&#12290;&#36890;&#36807;&#35843;&#25972;Anceschi&#31561;&#20154;&#65288;2023&#65289;&#30340;&#26356;&#19968;&#33324;&#30340;&#25512;&#23548;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#25193;&#23637;&#22810;&#20803;&#20559;&#24577;&#27491;&#24577;&#20998;&#24067;&#30340;&#32467;&#26524;&#65292;&#25512;&#23548;&#20986;EP&#20363;&#31243;&#30340;&#39640;&#25928;&#23454;&#29616;&#65292;&#20854;&#27599;&#27425;&#36845;&#20195;&#30340;&#35745;&#31639;&#25104;&#26412;&#19982;&#21327;&#21464;&#37327;&#30340;&#25968;&#37327;&#25104;&#32447;&#24615;&#27604;&#20363;&#12290;&#36825;&#20351;&#24471;EP&#22312;&#25361;&#25112;&#24615;&#30340;&#39640;&#32500;&#35774;&#32622;&#20013;&#20063;&#20855;&#26377;&#21487;&#35745;&#31639;&#24615;&#65292;&#27491;&#22914;&#35814;&#32454;&#30340;&#27169;&#25311;&#30740;&#31350;&#25152;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian binary regression is a prosperous area of research due to the computational challenges encountered by currently available methods either for high-dimensional settings or large datasets, or both. In the present work, we focus on the expectation propagation (EP) approximation of the posterior distribution in Bayesian probit regression under a multivariate Gaussian prior distribution. Adapting more general derivations in Anceschi et al. (2023), we show how to leverage results on the extended multivariate skew-normal distribution to derive an efficient implementation of the EP routine having a per-iteration cost that scales linearly in the number of covariates. This makes EP computationally feasible also in challenging high-dimensional settings, as shown in a detailed simulation study.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20027;&#35201;&#20197;&#26080;&#31351;&#23485;&#24230;&#21644;&#22823;&#23485;&#24230;&#33539;&#22260;&#20869;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20026;&#30740;&#31350;&#23545;&#35937;&#65292;&#35752;&#35770;&#20102;&#36825;&#20123;&#32593;&#32476;&#30340;&#21508;&#31181;&#32479;&#35745;&#21644;&#21160;&#21147;&#23398;&#29305;&#24615;&#65292;&#21253;&#25324;&#38543;&#26426;&#32593;&#32476;&#30340;&#24615;&#36136;&#12289;&#35757;&#32451;&#21518;&#30340;&#32593;&#32476;&#19982;&#32447;&#24615;&#27169;&#22411;&#12289;&#26680;&#20989;&#25968;&#21644;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#20197;&#21450;&#23545;&#22823;&#20294;&#26377;&#38480;&#23485;&#24230;&#32593;&#32476;&#22312;&#21021;&#22987;&#21270;&#21644;&#35757;&#32451;&#21518;&#30340;&#25668;&#21160;&#21644;&#38750;&#25668;&#21160;&#22788;&#29702;&#12290;</title><link>http://arxiv.org/abs/2309.01592</link><description>&lt;p&gt;
&#22823;&#23610;&#24230;&#21644;&#26080;&#31351;&#23485;&#24230;&#19979;&#30340;&#28145;&#24230;&#23398;&#20064;&#21202;&#35753;&#28436;&#35762;
&lt;/p&gt;
&lt;p&gt;
Les Houches Lectures on Deep Learning at Large &amp; Infinite Width. (arXiv:2309.01592v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01592
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20027;&#35201;&#20197;&#26080;&#31351;&#23485;&#24230;&#21644;&#22823;&#23485;&#24230;&#33539;&#22260;&#20869;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20026;&#30740;&#31350;&#23545;&#35937;&#65292;&#35752;&#35770;&#20102;&#36825;&#20123;&#32593;&#32476;&#30340;&#21508;&#31181;&#32479;&#35745;&#21644;&#21160;&#21147;&#23398;&#29305;&#24615;&#65292;&#21253;&#25324;&#38543;&#26426;&#32593;&#32476;&#30340;&#24615;&#36136;&#12289;&#35757;&#32451;&#21518;&#30340;&#32593;&#32476;&#19982;&#32447;&#24615;&#27169;&#22411;&#12289;&#26680;&#20989;&#25968;&#21644;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#20197;&#21450;&#23545;&#22823;&#20294;&#26377;&#38480;&#23485;&#24230;&#32593;&#32476;&#22312;&#21021;&#22987;&#21270;&#21644;&#35757;&#32451;&#21518;&#30340;&#25668;&#21160;&#21644;&#38750;&#25668;&#21160;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#20123;&#28436;&#35762;&#26159;&#22312;2022&#24180;&#21202;&#35753;&#22799;&#23395;&#23398;&#26657;&#32479;&#35745;&#29289;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#35838;&#31243;&#19978;&#23637;&#31034;&#30340;&#65292;&#30528;&#37325;&#25506;&#35752;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#26080;&#38480;&#23485;&#24230;&#21644;&#22823;&#23485;&#24230;&#33539;&#22260;&#20869;&#30340;&#24773;&#20917;&#12290;&#28085;&#30422;&#30340;&#20027;&#39064;&#21253;&#25324;&#36825;&#20123;&#32593;&#32476;&#30340;&#21508;&#31181;&#32479;&#35745;&#21644;&#21160;&#21147;&#23398;&#29305;&#24615;&#12290;&#29305;&#21035;&#26159;&#65292;&#35762;&#24072;&#20204;&#35752;&#35770;&#20102;&#38543;&#26426;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#29305;&#24615;&#65307;&#35757;&#32451;&#36807;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#32447;&#24615;&#27169;&#22411;&#65292;&#26680;&#20989;&#25968;&#21644;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#36825;&#20123;&#32852;&#31995;&#22312;&#26080;&#31351;&#23485;&#24230;&#30340;&#26497;&#38480;&#19979;&#20986;&#29616;&#65307;&#20197;&#21450;&#22312;&#21021;&#22987;&#21270;&#21644;&#35757;&#32451;&#21518;&#23545;&#22823;&#20294;&#26377;&#38480;&#23485;&#24230;&#32593;&#32476;&#30340;&#25668;&#21160;&#21644;&#38750;&#25668;&#21160;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
These lectures, presented at the 2022 Les Houches Summer School on Statistical Physics and Machine Learning, focus on the infinite-width limit and large-width regime of deep neural networks. Topics covered include various statistical and dynamical properties of these networks. In particular, the lecturers discuss properties of random deep neural networks; connections between trained deep neural networks, linear models, kernels, and Gaussian processes that arise in the infinite-width limit; and perturbative and non-perturbative treatments of large but finite-width networks, at initialization and after training.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;Metropolis-Hastings&#31639;&#27861;&#19982;&#25193;&#25955;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#21152;&#36895;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#65292;&#20174;&#32780;&#26377;&#25928;&#22320;&#25506;&#32034;&#39640;&#32500;&#24230;&#21644;/&#25110;&#22810;&#27169;&#24335;&#30340;&#21518;&#39564;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2309.01454</link><description>&lt;p&gt;
&#21152;&#36895;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#30340;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Accelerating Markov Chain Monte Carlo sampling with diffusion models. (arXiv:2309.01454v1 [hep-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01454
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;Metropolis-Hastings&#31639;&#27861;&#19982;&#25193;&#25955;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#21152;&#36895;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#65292;&#20174;&#32780;&#26377;&#25928;&#22320;&#25506;&#32034;&#39640;&#32500;&#24230;&#21644;/&#25110;&#22810;&#27169;&#24335;&#30340;&#21518;&#39564;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29289;&#29702;&#27169;&#22411;&#30340;&#20840;&#23616;&#25311;&#21512;&#38656;&#35201;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#25506;&#32034;&#39640;&#32500;&#24230;&#21644;/&#25110;&#22810;&#27169;&#24335;&#30340;&#21518;&#39564;&#20989;&#25968;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;Metropolis-Hastings&#31639;&#27861;&#19982;&#25193;&#25955;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#32472;&#21046;&#20840;&#23616;&#26679;&#26412;&#65292;&#20197;&#36817;&#20284;&#21518;&#39564;&#20998;&#24067;&#12290;&#25105;&#20204;&#31616;&#35201;&#22238;&#39038;&#20102;&#22270;&#20687;&#21512;&#25104;&#20013;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#28982;&#21518;&#25552;&#20379;&#20102;&#19968;&#31181;&#38024;&#23545;&#20302;&#32500;&#25968;&#25454;&#25968;&#32452;&#30340;&#31616;&#21270;&#25193;&#25955;&#27169;&#22411;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#25105;&#20204;&#25913;&#36827;&#30340;Metropolis-Hastings&#31639;&#27861;&#65292;&#23427;&#23558;&#23616;&#37096;&#25552;&#26696;&#19982;&#20174;&#23450;&#26399;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#20013;&#33719;&#21462;&#30340;&#20840;&#23616;&#25552;&#26696;&#32467;&#21512;&#22312;&#19968;&#36215;&#65292;&#35813;&#27169;&#22411;&#26159;&#22312;MCMC&#36816;&#34892;&#26399;&#38388;&#20135;&#29983;&#30340;&#26679;&#26412;&#19978;&#36827;&#34892;&#35757;&#32451;&#30340;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23548;&#33268;&#22312;&#20960;&#20010;&#20998;&#26512;&#20989;&#25968;&#20197;&#21450;&#22522;&#20110;&#37096;&#20998;&#23376;&#20998;&#26512;&#30340;&#29289;&#29702;&#31034;&#20363;&#20013;&#33719;&#24471;&#20102;&#20934;&#30830;&#34920;&#31034;&#36125;&#21494;&#26031;&#21518;&#39564;&#25152;&#38656;&#30340;&#20284;&#28982;&#35780;&#20272;&#25968;&#37327;&#30340;&#26174;&#30528;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
Global fits of physics models require efficient methods for exploring high-dimensional and/or multimodal posterior functions. We introduce a novel method for accelerating Markov Chain Monte Carlo (MCMC) sampling by pairing a Metropolis-Hastings algorithm with a diffusion model that can draw global samples with the aim of approximating the posterior. We briefly review diffusion models in the context of image synthesis before providing a streamlined diffusion model tailored towards low-dimensional data arrays. We then present our adapted Metropolis-Hastings algorithm which combines local proposals with global proposals taken from a diffusion model that is regularly trained on the samples produced during the MCMC run. Our approach leads to a significant reduction in the number of likelihood evaluations required to obtain an accurate representation of the Bayesian posterior across several analytic functions, as well as for a physical example based on a global analysis of parton distributio
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#36125;&#21494;&#26031;&#32467;&#26500;&#23398;&#20064;&#20013;&#20005;&#26684;&#32422;&#26463;&#22270;&#30340;&#26080;&#29615;&#24615;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#36890;&#36807;&#25972;&#21512;&#25299;&#25169;&#25490;&#24207;&#30693;&#35782;&#65292;&#33021;&#22815;&#20943;&#23569;&#25512;&#29702;&#22797;&#26434;&#24615;&#65292;&#24182;&#30830;&#20445;&#29983;&#25104;&#30340;&#22270;&#30340;&#32467;&#26500;&#26159;&#26080;&#29615;&#30340;&#12290;&#23454;&#35777;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#32988;&#36807;&#30456;&#20851;&#30340;&#36125;&#21494;&#26031;&#22522;&#20110;&#24471;&#20998;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.01392</link><description>&lt;p&gt;
&#19981;&#21516;iable&#30340;&#36125;&#21494;&#26031;&#32467;&#26500;&#23398;&#20064;&#20013;&#30340;&#25299;&#25169;&#25490;&#24207;&#19982;&#20445;&#35777;&#26080;&#29615;&#24615;&#30340;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;
Topological Ordering in Differentiable Bayesian Structure Learning with Guaranteed Acyclicity Constraint. (arXiv:2309.01392v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01392
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#36125;&#21494;&#26031;&#32467;&#26500;&#23398;&#20064;&#20013;&#20005;&#26684;&#32422;&#26463;&#22270;&#30340;&#26080;&#29615;&#24615;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#36890;&#36807;&#25972;&#21512;&#25299;&#25169;&#25490;&#24207;&#30693;&#35782;&#65292;&#33021;&#22815;&#20943;&#23569;&#25512;&#29702;&#22797;&#26434;&#24615;&#65292;&#24182;&#30830;&#20445;&#29983;&#25104;&#30340;&#22270;&#30340;&#32467;&#26500;&#26159;&#26080;&#29615;&#30340;&#12290;&#23454;&#35777;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#32988;&#36807;&#30456;&#20851;&#30340;&#36125;&#21494;&#26031;&#22522;&#20110;&#24471;&#20998;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#24471;&#20998;&#30340;&#32467;&#26500;&#23398;&#20064;&#26041;&#27861;&#22240;&#20854;&#21487;&#25193;&#23637;&#24615;&#32780;&#34028;&#21187;&#21457;&#23637;&#12290;&#36830;&#32493;&#26494;&#24347;&#26159;&#36825;&#19968;&#36827;&#23637;&#30340;&#20851;&#38190;&#21407;&#22240;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#65292;&#20294;&#22823;&#22810;&#25968;&#26041;&#27861;&#20173;&#28982;&#22312;&#36890;&#36807;&#26368;&#23567;&#21270;&#23450;&#20041;&#30340;&#24471;&#20998;&#26469;&#30830;&#20445;&#20174;&#28508;&#22312;&#31354;&#38388;&#29983;&#25104;&#30340;&#22270;&#26159;&#26080;&#29615;&#30340;&#26041;&#38754;&#36935;&#21040;&#22256;&#38590;&#12290;&#36824;&#23384;&#22312;&#21478;&#19968;&#31181;&#22522;&#20110;&#32622;&#25442;&#30340;&#26041;&#27861;&#65292;&#20851;&#27880;&#30340;&#26159;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#20013;&#21464;&#37327;&#30340;&#25299;&#25169;&#25490;&#24207;&#30340;&#25628;&#32034;&#65292;&#20197;&#38480;&#21046;&#22270;&#30340;&#25628;&#32034;&#31354;&#38388;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#25299;&#25169;&#25490;&#24207;&#30693;&#35782;&#26469;&#20005;&#26684;&#38480;&#21046;&#22270;&#30340;&#26080;&#29615;&#24615;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20943;&#23569;&#25512;&#29702;&#22797;&#26434;&#24615;&#65292;&#21516;&#26102;&#30830;&#20445;&#29983;&#25104;&#30340;&#22270;&#30340;&#32467;&#26500;&#26159;&#26080;&#29615;&#30340;&#12290;&#25105;&#20204;&#23545;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#36827;&#34892;&#30340;&#23454;&#35777;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#32988;&#36807;&#30456;&#20851;&#30340;&#36125;&#21494;&#26031;&#22522;&#20110;&#24471;&#20998;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score-based approaches in the structure learning task are thriving because of their scalability. Continuous relaxation has been the key reason for this advancement. Despite achieving promising outcomes, most of these methods are still struggling to ensure that the graphs generated from the latent space are acyclic by minimizing a defined score. There has also been another trend of permutation-based approaches, which concern the search for the topological ordering of the variables in the directed acyclic graph (DAG) in order to limit the search space of the graph. In this study, we propose an alternative approach for strictly constraining the acyclicty of the graphs with an integration of the knowledge from the topological orderings. Our approach can reduce inference complexity while ensuring the structures of the generated graphs to be acyclic. Our empirical experiments with simulated and real-world data show that our approach can outperform related Bayesian score-based approaches.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#19968;&#31181;&#38024;&#23545;&#37051;&#25509;&#30697;&#38453;&#30340;&#38543;&#26426;&#25237;&#24433;&#26041;&#27861;&#65292;&#21457;&#29616;&#36825;&#31181;&#26041;&#27861;&#22312;&#34920;&#31034;&#31232;&#30095;&#22270;&#26102;&#20855;&#26377;&#23454;&#29992;&#24615;&#12290;&#36890;&#36807;&#20445;&#30041;&#37051;&#25509;&#30697;&#38453;&#30340;&#21151;&#33021;&#24182;&#20855;&#26377;&#39069;&#22806;&#23646;&#24615;&#65292;&#36825;&#31181;&#26041;&#27861;&#20855;&#26377;&#21560;&#24341;&#21147;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#25237;&#24433;&#22823;&#23567;&#21487;&#20197;&#25353;&#32447;&#24615;&#27604;&#20363;&#32553;&#25918;&#65292;&#21516;&#26102;&#20445;&#30041;&#20934;&#30830;&#30340;&#19968;&#38454;&#22270;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2309.01360</link><description>&lt;p&gt;
&#31232;&#30095;&#37051;&#25509;&#30697;&#38453;&#30340;&#38543;&#26426;&#25237;&#24433;
&lt;/p&gt;
&lt;p&gt;
Random Projections of Sparse Adjacency Matrices. (arXiv:2309.01360v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01360
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#19968;&#31181;&#38024;&#23545;&#37051;&#25509;&#30697;&#38453;&#30340;&#38543;&#26426;&#25237;&#24433;&#26041;&#27861;&#65292;&#21457;&#29616;&#36825;&#31181;&#26041;&#27861;&#22312;&#34920;&#31034;&#31232;&#30095;&#22270;&#26102;&#20855;&#26377;&#23454;&#29992;&#24615;&#12290;&#36890;&#36807;&#20445;&#30041;&#37051;&#25509;&#30697;&#38453;&#30340;&#21151;&#33021;&#24182;&#20855;&#26377;&#39069;&#22806;&#23646;&#24615;&#65292;&#36825;&#31181;&#26041;&#27861;&#20855;&#26377;&#21560;&#24341;&#21147;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#25237;&#24433;&#22823;&#23567;&#21487;&#20197;&#25353;&#32447;&#24615;&#27604;&#20363;&#32553;&#25918;&#65292;&#21516;&#26102;&#20445;&#30041;&#20934;&#30830;&#30340;&#19968;&#38454;&#22270;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20998;&#26512;&#20102;&#19968;&#31181;&#38024;&#23545;&#37051;&#25509;&#30697;&#38453;&#30340;&#38543;&#26426;&#25237;&#24433;&#26041;&#27861;&#65292;&#30740;&#31350;&#20854;&#22312;&#34920;&#31034;&#31232;&#30095;&#22270;&#20013;&#30340;&#23454;&#29992;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#38543;&#26426;&#25237;&#24433;&#20445;&#30041;&#20102;&#24213;&#23618;&#37051;&#25509;&#30697;&#38453;&#30340;&#21151;&#33021;&#65292;&#21516;&#26102;&#20855;&#26377;&#39069;&#22806;&#30340;&#23646;&#24615;&#65292;&#20351;&#23427;&#20204;&#20316;&#20026;&#21160;&#24577;&#22270;&#34920;&#31034;&#20855;&#26377;&#21560;&#24341;&#21147;&#12290;&#29305;&#21035;&#22320;&#65292;&#23427;&#20204;&#21487;&#20197;&#22312;&#30456;&#21516;&#30340;&#31354;&#38388;&#20013;&#34920;&#31034;&#19981;&#21516;&#22823;&#23567;&#21644;&#39030;&#28857;&#38598;&#21512;&#30340;&#22270;&#65292;&#20174;&#32780;&#23454;&#29616;&#22270;&#30340;&#32858;&#21512;&#21644;&#25805;&#20316;&#30340;&#32479;&#19968;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#20851;&#20110;&#20445;&#30041;&#20934;&#30830;&#22270;&#25805;&#20316;&#25152;&#38656;&#30340;&#25237;&#24433;&#22823;&#23567;&#22914;&#20309;&#25353;&#27604;&#20363;&#32553;&#25918;&#30340;&#32467;&#26524;&#65292;&#34920;&#26126;&#25237;&#24433;&#22823;&#23567;&#21487;&#20197;&#19982;&#39030;&#28857;&#25968;&#37327;&#32447;&#24615;&#32553;&#25918;&#65292;&#21516;&#26102;&#20934;&#30830;&#20445;&#30041;&#19968;&#38454;&#22270;&#20449;&#24687;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#38543;&#26426;&#25237;&#24433;&#34920;&#24449;&#20026;&#20445;&#25345;&#36317;&#31163;&#30340;&#37051;&#25509;&#30697;&#38453;&#26144;&#23556;&#65292;&#31867;&#20284;&#20110;&#20256;&#32479;&#30340;Johnson-Lindenstrauss&#26144;&#23556;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyze a random projection method for adjacency matrices, studying its utility in representing sparse graphs. We show that these random projections retain the functionality of their underlying adjacency matrices while having extra properties that make them attractive as dynamic graph representations. In particular, they can represent graphs of different sizes and vertex sets in the same space, allowing for the aggregation and manipulation of graphs in a unified manner. We also provide results on how the size of the projections need to scale in order to preserve accurate graph operations, showing that the size of the projections can scale linearly with the number of vertices while accurately retaining first-order graph information. We conclude by characterizing our random projection as a distance-preserving map of adjacency matrices analogous to the usual Johnson-Lindenstrauss map.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31038;&#20132;&#32593;&#32476;&#20013;&#23618;&#27425;&#32858;&#31867;&#30340;&#32479;&#35745;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#27169;&#22411;$\mathbb{T}$-&#38543;&#26426;&#22270;&#65292;&#29992;&#20110;&#35299;&#20915;&#29616;&#26377;&#26041;&#27861;&#20013;&#23384;&#22312;&#30340;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.01301</link><description>&lt;p&gt;
$\mathbb{T}$-&#38543;&#26426;&#22270;
&lt;/p&gt;
&lt;p&gt;
$\mathbb{T}$-Stochastic Graphs. (arXiv:2309.01301v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01301
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31038;&#20132;&#32593;&#32476;&#20013;&#23618;&#27425;&#32858;&#31867;&#30340;&#32479;&#35745;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#27169;&#22411;$\mathbb{T}$-&#38543;&#26426;&#22270;&#65292;&#29992;&#20110;&#35299;&#20915;&#29616;&#26377;&#26041;&#27861;&#20013;&#23384;&#22312;&#30340;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#30340;&#31038;&#20132;&#32593;&#32476;&#20998;&#26512;&#20013;&#20851;&#20110;&#23618;&#27425;&#32858;&#31867;&#30340;&#32479;&#35745;&#26041;&#27861;&#37117;&#26500;&#24314;&#20102;&#19968;&#20010;&#8220;&#36229;&#24230;&#37327;&#8221;&#30340;&#23618;&#27425;&#32467;&#26500;&#12290;&#34429;&#28982;&#36229;&#24230;&#37327;&#24615;&#30340;&#20551;&#35774;&#22312;&#31995;&#32479;&#21457;&#29983;&#23398;&#25991;&#29486;&#20013;&#24050;&#32463;&#24471;&#21040;&#20102;&#35752;&#35770;&#21644;&#30740;&#31350;&#65292;&#20294;&#22312;&#31038;&#20132;&#32593;&#32476;&#25991;&#29486;&#20013;&#23578;&#26410;&#24471;&#21040;&#25215;&#35748;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#32593;&#32476;&#20013;&#30340;&#8220;&#38750;&#36229;&#24230;&#37327;&#32467;&#26500;&#8221;&#24341;&#20837;&#20102;&#29616;&#26377;&#33258;&#19978;&#32780;&#19979;&#24674;&#22797;&#31639;&#27861;&#30340;&#26174;&#33879;&#19981;&#31283;&#23450;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#19981;&#31283;&#23450;&#24615;&#35786;&#26029;&#22270;&#24182;&#20351;&#29992;&#23427;&#26469;&#26816;&#26597;&#19968;&#31995;&#21015;&#32463;&#39564;&#32593;&#32476;&#12290;&#36825;&#20123;&#32593;&#32476;&#20284;&#20046;&#36829;&#21453;&#20102;&#8220;&#36229;&#24230;&#37327;&#8221;&#20551;&#35774;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#30475;&#20284;&#31616;&#21333;&#20294;&#21448;&#24456;&#36890;&#29992;&#30340;&#27010;&#29575;&#27169;&#22411;&#31867;&#65292;&#31216;&#20026;$\mathbb{T}$-&#38543;&#26426;&#22270;&#65292;&#23427;&#23545;&#28508;&#22312;&#23618;&#27425;&#32467;&#26500;&#19981;&#26045;&#21152;&#25299;&#25169;&#38480;&#21046;&#12290;&#20026;&#20102;&#35828;&#26126;&#36825;&#20010;&#27169;&#22411;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20845;&#31181;&#26367;&#20195;&#24615;&#30340;&#23618;&#27425;&#32593;&#32476;&#27169;&#22411;&#65292;&#28982;&#21518;&#35777;&#26126;&#20102;&#25152;&#26377;&#20845;&#31181;&#27169;&#22411;&#37117;&#31561;&#20215;&#20110;$\mathbb{T}$-&#38543;&#26426;&#22270;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Previous statistical approaches to hierarchical clustering for social network analysis all construct an "ultrametric" hierarchy. While the assumption of ultrametricity has been discussed and studied in the phylogenetics literature, it has not yet been acknowledged in the social network literature. We show that "non-ultrametric structure" in the network introduces significant instabilities in the existing top-down recovery algorithms. To address this issue, we introduce an instability diagnostic plot and use it to examine a collection of empirical networks. These networks appear to violate the "ultrametric" assumption. We propose a deceptively simple and yet general class of probabilistic models called $\mathbb{T}$-Stochastic Graphs which impose no topological restrictions on the latent hierarchy. To illustrate this model, we propose six alternative forms of hierarchical network models and then show that all six are equivalent to the $\mathbb{T}$-Stochastic Graph model. These alternativ
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24314;&#31435;&#20102;&#28145;&#24230;&#27531;&#24046;&#32593;&#32476;&#21521;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#65292;&#36890;&#36807;&#23545;&#29992;&#26799;&#24230;&#27969;&#35757;&#32451;&#30340;&#38750;&#32447;&#24615;&#32593;&#32476;&#30340;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#22312;&#32593;&#32476;&#20197;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#31163;&#25955;&#21270;&#24418;&#24335;&#21021;&#22987;&#21270;&#21518;&#65292;&#36825;&#31181;&#31163;&#25955;&#21270;&#23558;&#22312;&#25972;&#20010;&#35757;&#32451;&#36807;&#31243;&#20013;&#20445;&#25345;&#19981;&#21464;&#65292;&#24182;&#25552;&#20379;&#20102;&#25910;&#25947;&#24615;&#30340;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2309.01213</link><description>&lt;p&gt;
&#28145;&#24230;&#27531;&#24046;&#32593;&#32476;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#19982;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#20851;&#32852;
&lt;/p&gt;
&lt;p&gt;
Implicit regularization of deep residual networks towards neural ODEs. (arXiv:2309.01213v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01213
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24314;&#31435;&#20102;&#28145;&#24230;&#27531;&#24046;&#32593;&#32476;&#21521;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#65292;&#36890;&#36807;&#23545;&#29992;&#26799;&#24230;&#27969;&#35757;&#32451;&#30340;&#38750;&#32447;&#24615;&#32593;&#32476;&#30340;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#22312;&#32593;&#32476;&#20197;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#31163;&#25955;&#21270;&#24418;&#24335;&#21021;&#22987;&#21270;&#21518;&#65292;&#36825;&#31181;&#31163;&#25955;&#21270;&#23558;&#22312;&#25972;&#20010;&#35757;&#32451;&#36807;&#31243;&#20013;&#20445;&#25345;&#19981;&#21464;&#65292;&#24182;&#25552;&#20379;&#20102;&#25910;&#25947;&#24615;&#30340;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27531;&#24046;&#31070;&#32463;&#32593;&#32476;&#26159;&#20808;&#36827;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#12290;&#23427;&#20204;&#30340;&#36830;&#32493;&#28145;&#24230;&#27169;&#25311;&#31216;&#20026;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#65292;&#20063;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#23613;&#31649;&#23427;&#20204;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#31163;&#25955;&#27169;&#22411;&#19982;&#36830;&#32493;&#27169;&#22411;&#20043;&#38388;&#30340;&#32852;&#31995;&#20173;&#32570;&#20047;&#22362;&#23454;&#30340;&#25968;&#23398;&#22522;&#30784;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#24314;&#31435;&#19968;&#20010;&#38024;&#23545;&#29992;&#26799;&#24230;&#27969;&#35757;&#32451;&#30340;&#38750;&#32447;&#24615;&#32593;&#32476;&#30340;&#28145;&#24230;&#27531;&#24046;&#32593;&#32476;&#21521;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#26469;&#26397;&#30528;&#36825;&#20010;&#26041;&#21521;&#36808;&#20986;&#20102;&#19968;&#27493;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22914;&#26524;&#32593;&#32476;&#30340;&#21021;&#22987;&#21270;&#26159;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#31163;&#25955;&#21270;&#65292;&#21017;&#36825;&#31181;&#31163;&#25955;&#21270;&#22312;&#25972;&#20010;&#35757;&#32451;&#36807;&#31243;&#20013;&#20445;&#25345;&#19981;&#21464;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#23545;&#20110;&#26377;&#38480;&#30340;&#35757;&#32451;&#26102;&#38388;&#21644;&#35757;&#32451;&#26102;&#38388;&#36235;&#20110;&#26080;&#31351;&#22823;&#37117;&#25104;&#31435;&#65292;&#21482;&#35201;&#32593;&#32476;&#28385;&#36275;Polyak-Lojasiewicz&#26465;&#20214;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#36825;&#20010;&#26465;&#20214;&#36866;&#29992;&#20110;&#19968;&#20010;&#27531;&#24046;&#32593;&#32476;&#23478;&#26063;&#65292;&#20854;&#20013;&#27531;&#24046;&#26159;&#20004;&#23618;&#24863;&#30693;&#26426;&#65292;&#22312;&#23485;&#24230;&#19978;&#21482;&#26159;&#32447;&#24615;&#36229;&#21442;&#25968;&#21270;&#65292;&#24182;&#19988;&#26263;&#31034;&#20102;&#26799;&#24230;&#27969;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Residual neural networks are state-of-the-art deep learning models. Their continuous-depth analog, neural ordinary differential equations (ODEs), are also widely used. Despite their success, the link between the discrete and continuous models still lacks a solid mathematical foundation. In this article, we take a step in this direction by establishing an implicit regularization of deep residual networks towards neural ODEs, for nonlinear networks trained with gradient flow. We prove that if the network is initialized as a discretization of a neural ODE, then such a discretization holds throughout training. Our results are valid for a finite training time, and also as the training time tends to infinity provided that the network satisfies a Polyak-Lojasiewicz condition. Importantly, this condition holds for a family of residual networks where the residuals are two-layer perceptrons with an overparameterization in width that is only linear, and implies the convergence of gradient flow to
&lt;/p&gt;</description></item><item><title>TML&#36719;&#20214;&#21253;&#26159;&#31532;&#19968;&#20010;&#21253;&#21547;&#19968;&#22871;&#20840;&#38754;&#24037;&#20855;&#21644;&#26041;&#27861;&#30340;R&#36719;&#20214;&#21253;&#65292;&#29992;&#20110;&#22788;&#29702;&#19982;&#28909;&#24102;&#20984;&#24615;&#30456;&#20851;&#30340;&#22522;&#26412;&#35745;&#31639;&#21644;&#21487;&#35270;&#21270;&#65292;&#20197;&#21450;&#20351;&#29992;&#28909;&#24102;&#24230;&#37327;&#36827;&#34892;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#30340;&#32479;&#35745;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2309.01082</link><description>&lt;p&gt;
&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#28909;&#24102;&#20960;&#20309;&#24037;&#20855;&#65306;TML&#36719;&#20214;&#21253;
&lt;/p&gt;
&lt;p&gt;
Tropical Geometric Tools for Machine Learning: the TML package. (arXiv:2309.01082v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01082
&lt;/p&gt;
&lt;p&gt;
TML&#36719;&#20214;&#21253;&#26159;&#31532;&#19968;&#20010;&#21253;&#21547;&#19968;&#22871;&#20840;&#38754;&#24037;&#20855;&#21644;&#26041;&#27861;&#30340;R&#36719;&#20214;&#21253;&#65292;&#29992;&#20110;&#22788;&#29702;&#19982;&#28909;&#24102;&#20984;&#24615;&#30456;&#20851;&#30340;&#22522;&#26412;&#35745;&#31639;&#21644;&#21487;&#35270;&#21270;&#65292;&#20197;&#21450;&#20351;&#29992;&#28909;&#24102;&#24230;&#37327;&#36827;&#34892;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#30340;&#32479;&#35745;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#20013;&#65292;&#28909;&#24102;&#20960;&#20309;&#23398;&#30340;&#21457;&#23637;&#25552;&#20379;&#20102;&#35768;&#22810;&#30452;&#25509;&#24212;&#29992;&#20110;&#32479;&#35745;&#23398;&#20064;&#38382;&#39064;&#30340;&#24037;&#20855;&#12290;TML&#36719;&#20214;&#21253;&#26159;&#31532;&#19968;&#20010;&#21253;&#21547;&#19968;&#22871;&#20840;&#38754;&#30340;&#24037;&#20855;&#21644;&#26041;&#27861;&#30340;R&#36719;&#20214;&#21253;&#65292;&#29992;&#20110;&#22788;&#29702;&#19982;&#28909;&#24102;&#20984;&#24615;&#30456;&#20851;&#30340;&#22522;&#26412;&#35745;&#31639;&#12289;&#28909;&#24102;&#20984;&#38598;&#30340;&#21487;&#35270;&#21270;&#65292;&#20197;&#21450;&#20351;&#29992;&#28909;&#24102;&#24230;&#37327;&#21644;&#28909;&#24102;&#25237;&#24433;&#29615;&#19978;&#30340;max-plus&#20195;&#25968;&#36827;&#34892;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#12290;&#20027;&#35201;&#30340;&#65292;TML&#36719;&#20214;&#21253;&#20351;&#29992;Hit and Run Markov chain Monte Carlo&#37319;&#26679;&#22120;&#19982;&#28909;&#24102;&#24230;&#37327;&#20316;&#20026;&#32479;&#35745;&#25512;&#26029;&#30340;&#20027;&#35201;&#24037;&#20855;&#12290;&#38500;&#20102;&#22522;&#26412;&#35745;&#31639;&#21644;&#28909;&#24102;HAR&#37319;&#26679;&#22120;&#30340;&#21508;&#31181;&#24212;&#29992;&#20043;&#22806;&#65292;&#25105;&#20204;&#36824;&#20851;&#27880;TML&#36719;&#20214;&#21253;&#20013;&#21253;&#21547;&#30340;&#20960;&#31181;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#26041;&#27861;&#65292;&#21253;&#25324;&#28909;&#24102;&#20027;&#25104;&#20998;&#20998;&#26512;&#12289;&#28909;&#24102;&#36923;&#36753;&#22238;&#24402;&#21644;&#28909;&#24102;&#26680;&#23494;&#24230;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the last decade, developments in tropical geometry have provided a number of uses directly applicable to problems in statistical learning. The TML package is the first R package which contains a comprehensive set of tools and methods used for basic computations related to tropical convexity, visualization of tropically convex sets, as well as supervised and unsupervised learning models using the tropical metric under the max-plus algebra over the tropical projective torus. Primarily, the TML package employs a Hit and Run Markov chain Monte Carlo sampler in conjunction with the tropical metric as its main tool for statistical inference. In addition to basic computation and various applications of the tropical HAR sampler, we also focus on several supervised and unsupervised methods incorporated in the TML package including tropical principal component analysis, tropical logistic regression and tropical kernel density estimation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20351;&#29992;&#31070;&#32463;&#24494;&#20998;&#26041;&#31243;&#36827;&#34892;&#20998;&#24067;&#23398;&#20064;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#30456;&#24212;&#30340;&#38750;&#21442;&#25968;&#32479;&#35745;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2309.01043</link><description>&lt;p&gt;
&#36890;&#36807;&#31070;&#32463;&#24494;&#20998;&#26041;&#31243;&#36827;&#34892;&#20998;&#24067;&#23398;&#20064;&#65306;&#19968;&#31181;&#38750;&#21442;&#25968;&#32479;&#35745;&#35282;&#24230;
&lt;/p&gt;
&lt;p&gt;
Distribution learning via neural differential equations: a nonparametric statistical perspective. (arXiv:2309.01043v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01043
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20351;&#29992;&#31070;&#32463;&#24494;&#20998;&#26041;&#31243;&#36827;&#34892;&#20998;&#24067;&#23398;&#20064;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#30456;&#24212;&#30340;&#38750;&#21442;&#25968;&#32479;&#35745;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26222;&#36890;&#24494;&#20998;&#26041;&#31243;&#65288;ODEs&#65289;&#36890;&#36807;&#20854;&#24341;&#23548;&#30340;&#27969;&#26144;&#23556;&#65292;&#20026;&#34920;&#31034;&#22797;&#26434;&#27010;&#29575;&#20998;&#24067;&#30340;&#21487;&#36870;&#21464;&#25442;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#26694;&#26550;&#12290;&#23613;&#31649;&#36825;&#20123;&#27169;&#22411;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#29983;&#25104;&#24314;&#27169;&#21644;&#23494;&#24230;&#20272;&#35745;&#65292;&#20294;&#23545;&#23427;&#20204;&#30340;&#32479;&#35745;&#24615;&#36136;&#30693;&#20043;&#29978;&#23569;&#12290;&#26412;&#25991;&#24314;&#31435;&#20102;&#36890;&#36807;&#26368;&#22823;&#20284;&#28982;&#35757;&#32451;&#30340;ODE&#27169;&#22411;&#30340;&#20998;&#24067;&#23398;&#20064;&#30340;&#31532;&#19968;&#20010;&#19968;&#33324;&#38750;&#21442;&#25968;&#32479;&#35745;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#36866;&#29992;&#20110;&#28385;&#36275;&#19968;&#23450;&#31616;&#21333;&#36793;&#30028;&#32422;&#26463;&#30340;&#20219;&#24847;&#36895;&#24230;&#22330;&#31867;$\mathcal{F}$&#30340;&#25910;&#25947;&#23450;&#29702;&#12290;&#36825;&#20010;&#19968;&#33324;&#32467;&#26524;&#25429;&#25417;&#20102;&#36924;&#36817;&#35823;&#24046;&#65288;'&#20559;&#24046;'&#65289;&#21644;ODE&#27169;&#22411;&#30340;&#22797;&#26434;&#24615;&#65288;'&#26041;&#24046;'&#65289;&#20043;&#38388;&#30340;&#24179;&#34913;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36890;&#36807;$\mathcal F$&#31867;&#30340;$C^1$-&#24230;&#37327;&#29109;&#21487;&#20197;&#37327;&#21270;&#21518;&#32773;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#36890;&#29992;&#26694;&#26550;&#24212;&#29992;&#20110;$C^k$-smoot&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ordinary differential equations (ODEs), via their induced flow maps, provide a powerful framework to parameterize invertible transformations for the purpose of representing complex probability distributions. While such models have achieved enormous success in machine learning, particularly for generative modeling and density estimation, little is known about their statistical properties. This work establishes the first general nonparametric statistical convergence analysis for distribution learning via ODE models trained through likelihood maximization. We first prove a convergence theorem applicable to arbitrary velocity field classes $\mathcal{F}$ satisfying certain simple boundary constraints. This general result captures the trade-off between approximation error (`bias') and the complexity of the ODE model (`variance'). We show that the latter can be quantified via the $C^1$-metric entropy of the class $\mathcal F$. We then apply this general framework to the setting of $C^k$-smoot
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#28145;&#24230;&#36816;&#31639;&#31526;&#32593;&#32476;&#30340;&#26032;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#35757;&#32451;&#20219;&#21153;&#20998;&#35299;&#20026;&#20004;&#20010;&#38477;&#20302;&#22797;&#26434;&#24615;&#30340;&#23376;&#20219;&#21153;&#65292;&#24182;&#24341;&#20837;&#27491;&#20132;&#21270;&#36807;&#31243;&#26469;&#25552;&#39640;&#32593;&#32476;&#30340;&#31283;&#23450;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2309.01020</link><description>&lt;p&gt;
&#20851;&#20110;&#28145;&#24230;&#36816;&#31639;&#31526;&#32593;&#32476;&#30340;&#35757;&#32451;&#21644;&#27867;&#21270;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the training and generalization of deep operator networks. (arXiv:2309.01020v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01020
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#28145;&#24230;&#36816;&#31639;&#31526;&#32593;&#32476;&#30340;&#26032;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#35757;&#32451;&#20219;&#21153;&#20998;&#35299;&#20026;&#20004;&#20010;&#38477;&#20302;&#22797;&#26434;&#24615;&#30340;&#23376;&#20219;&#21153;&#65292;&#24182;&#24341;&#20837;&#27491;&#20132;&#21270;&#36807;&#31243;&#26469;&#25552;&#39640;&#32593;&#32476;&#30340;&#31283;&#23450;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#29992;&#20110;&#28145;&#24230;&#36816;&#31639;&#31526;&#32593;&#32476;&#65288;DeepONets&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26368;&#27969;&#34892;&#30340;&#29992;&#20110;&#36816;&#31639;&#31526;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#12290;DeepONets&#30001;&#20004;&#20010;&#23376;&#32593;&#32476;&#26500;&#25104;&#65292;&#20998;&#21035;&#26159;&#20998;&#25903;&#32593;&#32476;&#21644;&#20027;&#24178;&#32593;&#32476;&#12290;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#36825;&#20004;&#20010;&#23376;&#32593;&#32476;&#21516;&#26102;&#36827;&#34892;&#35757;&#32451;&#65292;&#36825;&#30456;&#24403;&#20110;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#35299;&#20915;&#19968;&#20010;&#22797;&#26434;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#38750;&#20984;&#21644;&#38750;&#32447;&#24615;&#24615;&#36136;&#20351;&#24471;&#35757;&#32451;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#31181;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#27493;&#35757;&#32451;&#26041;&#27861;&#65292;&#39318;&#20808;&#35757;&#32451;&#20027;&#24178;&#32593;&#32476;&#65292;&#28982;&#21518;&#39034;&#24207;&#35757;&#32451;&#20998;&#25903;&#32593;&#32476;&#12290;&#26680;&#24515;&#26426;&#21046;&#21463;&#21040;&#20998;&#32780;&#27835;&#20043;&#30340;&#21551;&#21457;&#65292;&#23558;&#25972;&#20010;&#22797;&#26434;&#35757;&#32451;&#20219;&#21153;&#20998;&#35299;&#20026;&#20004;&#20010;&#20855;&#26377;&#38477;&#20302;&#22797;&#26434;&#24615;&#30340;&#23376;&#20219;&#21153;&#12290;&#20854;&#20013;&#24341;&#20837;&#20102;&#26684;&#25289;&#22982;-&#26045;&#23494;&#29305;&#27491;&#20132;&#21270;&#36807;&#31243;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#31283;&#23450;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#22312;&#29702;&#35770;&#26041;&#38754;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#20851;&#20110;&#35757;&#32451;&#26679;&#26412;&#25968;&#30340;&#27867;&#21270;&#35823;&#24046;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel training method for deep operator networks (DeepONets), one of the most popular neural network models for operators. DeepONets are constructed by two sub-networks, namely the branch and trunk networks. Typically, the two sub-networks are trained simultaneously, which amounts to solving a complex optimization problem in a high dimensional space. In addition, the nonconvex and nonlinear nature makes training very challenging. To tackle such a challenge, we propose a two-step training method that trains the trunk network first and then sequentially trains the branch network. The core mechanism is motivated by the divide-and-conquer paradigm and is the decomposition of the entire complex training task into two subtasks with reduced complexity. Therein the Gram-Schmidt orthonormalization process is introduced which significantly improves stability and generalization ability. On the theoretical side, we establish a generalization error estimate in terms of the number of tr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#23383;&#20856;&#23398;&#20064;&#21644;&#32534;&#30721;&#26041;&#27861;&#65292;&#36890;&#36807;&#21387;&#32553;&#23376;&#23383;&#20856;&#21644;&#24341;&#20837;&#24314;&#27169;&#35823;&#24046;&#26469;&#25913;&#36827;&#23383;&#20856;&#21305;&#37197;&#36807;&#31243;&#65292;&#24182;&#37319;&#29992;&#25968;&#25454;&#39537;&#21160;&#30340;&#31232;&#30095;&#32534;&#30721;&#25216;&#26415;&#35782;&#21035;&#19981;&#30456;&#20851;&#30340;&#23376;&#23383;&#20856;&#12290;</title><link>http://arxiv.org/abs/2309.00999</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#31232;&#30095;&#24615;&#21644;&#31867;&#21035;&#31232;&#30095;&#24615;&#20808;&#39564;&#20110;&#23383;&#20856;&#23398;&#20064;&#21644;&#32534;&#30721;
&lt;/p&gt;
&lt;p&gt;
Bayesian sparsity and class sparsity priors for dictionary learning and coding. (arXiv:2309.00999v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00999
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#23383;&#20856;&#23398;&#20064;&#21644;&#32534;&#30721;&#26041;&#27861;&#65292;&#36890;&#36807;&#21387;&#32553;&#23376;&#23383;&#20856;&#21644;&#24341;&#20837;&#24314;&#27169;&#35823;&#24046;&#26469;&#25913;&#36827;&#23383;&#20856;&#21305;&#37197;&#36807;&#31243;&#65292;&#24182;&#37319;&#29992;&#25968;&#25454;&#39537;&#21160;&#30340;&#31232;&#30095;&#32534;&#30721;&#25216;&#26415;&#35782;&#21035;&#19981;&#30456;&#20851;&#30340;&#23376;&#23383;&#20856;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23383;&#20856;&#23398;&#20064;&#26041;&#27861;&#22312;&#35299;&#20915;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#36870;&#38382;&#39064;&#20013;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#22312;&#23383;&#20856;&#23398;&#20064;&#26041;&#27861;&#20013;&#65292;&#35745;&#31639;&#27491;&#21521;&#27169;&#22411;&#34987;&#19968;&#20010;&#21253;&#21547;&#21487;&#33021;&#32467;&#26524;&#30340;&#22823;&#22411;&#23383;&#20856;&#26367;&#20195;&#65292;&#38382;&#39064;&#26159;&#35782;&#21035;&#26368;&#33021;&#21305;&#37197;&#25968;&#25454;&#30340;&#23383;&#20856;&#26465;&#30446;&#65292;&#31867;&#20284;&#20110;&#20256;&#32479;&#25628;&#32034;&#24341;&#25806;&#20013;&#30340;&#26597;&#35810;&#21305;&#37197;&#12290;&#31232;&#30095;&#32534;&#30721;&#25216;&#26415;&#29992;&#20110;&#30830;&#20445;&#23383;&#20856;&#21305;&#37197;&#21482;&#35782;&#21035;&#20986;&#23569;&#25968;&#23383;&#20856;&#26465;&#30446;&#65292;&#24182;&#19988;&#23383;&#20856;&#21387;&#32553;&#26041;&#27861;&#29992;&#20110;&#20943;&#23569;&#21305;&#37197;&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24037;&#20316;&#27969;&#31243;&#26469;&#20419;&#36827;&#23383;&#20856;&#21305;&#37197;&#36807;&#31243;&#12290;&#39318;&#20808;&#65292;&#23558;&#23436;&#25972;&#23383;&#20856;&#20998;&#25104;&#21333;&#29420;&#21387;&#32553;&#30340;&#23376;&#23383;&#20856;&#12290;&#23383;&#20856;&#21387;&#32553;&#24341;&#20837;&#30340;&#35823;&#24046;&#22312;&#36125;&#21494;&#26031;&#26694;&#26550;&#20013;&#34987;&#22788;&#29702;&#20026;&#24314;&#27169;&#35823;&#24046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#36125;&#21494;&#26031;&#30340;&#25968;&#25454;&#39537;&#21160;&#32452;&#31232;&#30095;&#32534;&#30721;&#26041;&#27861;&#65292;&#20197;&#24110;&#21161;&#35782;&#21035;&#19981;&#30456;&#20851;&#30340;&#23376;&#23383;&#20856;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dictionary learning methods continue to gain popularity for the solution of challenging inverse problems. In the dictionary learning approach, the computational forward model is replaced by a large dictionary of possible outcomes, and the problem is to identify the dictionary entries that best match the data, akin to traditional query matching in search engines. Sparse coding techniques are used to guarantee that the dictionary matching identifies only few of the dictionary entries, and dictionary compression methods are used to reduce the complexity of the matching problem. In this article, we propose a work flow to facilitate the dictionary matching process. First, the full dictionary is divided into subdictionaries that are separately compressed. The error introduced by the dictionary compression is handled in the Bayesian framework as a modeling error. Furthermore, we propose a new Bayesian data-driven group sparsity coding method to help identify subdictionaries that are not relev
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38598;&#25104;&#35780;&#20998;&#28388;&#27874;&#22120;&#65288;EnSF&#65289;&#65292;&#22312;&#22788;&#29702;&#39640;&#32500;&#38750;&#32447;&#24615;&#28388;&#27874;&#38382;&#39064;&#26102;&#20855;&#26377;&#21331;&#36234;&#30340;&#20934;&#30830;&#24615;&#12290;EnSF&#21033;&#29992;&#35780;&#20998;&#27169;&#22411;&#22312;&#20266;&#26102;&#22495;&#20013;&#25551;&#36848;&#28388;&#27874;&#23494;&#24230;&#30340;&#28436;&#21270;&#65292;&#24182;&#36890;&#36807;&#35780;&#20998;&#20989;&#25968;&#23384;&#20648;&#20449;&#24687;&#65292;&#30456;&#27604;&#20110;&#20351;&#29992;&#33945;&#29305;&#21345;&#32599;&#26679;&#26412;&#30340;&#31890;&#23376;&#28388;&#27874;&#22120;&#21644;&#38598;&#25104;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#20855;&#26377;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.00983</link><description>&lt;p&gt;
&#29992;&#20110;&#36319;&#36394;&#39640;&#32500;&#38750;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#30340;&#38598;&#25104;&#35780;&#20998;&#28388;&#27874;&#22120;
&lt;/p&gt;
&lt;p&gt;
An Ensemble Score Filter for Tracking High-Dimensional Nonlinear Dynamical Systems. (arXiv:2309.00983v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00983
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38598;&#25104;&#35780;&#20998;&#28388;&#27874;&#22120;&#65288;EnSF&#65289;&#65292;&#22312;&#22788;&#29702;&#39640;&#32500;&#38750;&#32447;&#24615;&#28388;&#27874;&#38382;&#39064;&#26102;&#20855;&#26377;&#21331;&#36234;&#30340;&#20934;&#30830;&#24615;&#12290;EnSF&#21033;&#29992;&#35780;&#20998;&#27169;&#22411;&#22312;&#20266;&#26102;&#22495;&#20013;&#25551;&#36848;&#28388;&#27874;&#23494;&#24230;&#30340;&#28436;&#21270;&#65292;&#24182;&#36890;&#36807;&#35780;&#20998;&#20989;&#25968;&#23384;&#20648;&#20449;&#24687;&#65292;&#30456;&#27604;&#20110;&#20351;&#29992;&#33945;&#29305;&#21345;&#32599;&#26679;&#26412;&#30340;&#31890;&#23376;&#28388;&#27874;&#22120;&#21644;&#38598;&#25104;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#20855;&#26377;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38598;&#25104;&#35780;&#20998;&#28388;&#27874;&#22120;&#65288;EnSF&#65289;&#26469;&#35299;&#20915;&#39640;&#32500;&#38750;&#32447;&#24615;&#28388;&#27874;&#38382;&#39064;&#65292;&#24182;&#20855;&#26377;&#21331;&#36234;&#30340;&#20934;&#30830;&#24615;&#12290;&#29616;&#26377;&#30340;&#28388;&#27874;&#26041;&#27861;&#65288;&#22914;&#31890;&#23376;&#28388;&#27874;&#22120;&#25110;&#38598;&#25104;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65289;&#22312;&#22788;&#29702;&#39640;&#32500;&#21644;&#39640;&#24230;&#38750;&#32447;&#24615;&#38382;&#39064;&#26102;&#23384;&#22312;&#20302;&#20934;&#30830;&#24615;&#30340;&#20027;&#35201;&#32570;&#38519;&#12290;EnSF&#36890;&#36807;&#21033;&#29992;&#22522;&#20110;&#35780;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#22312;&#20266;&#26102;&#22495;&#20013;&#23450;&#20041;&#65292;&#26469;&#25551;&#36848;&#28388;&#27874;&#23494;&#24230;&#30340;&#28436;&#21270;&#65292;&#20174;&#32780;&#25915;&#20811;&#20102;&#36825;&#19968;&#25361;&#25112;&#12290;EnSF&#22312;&#35780;&#20998;&#20989;&#25968;&#20013;&#23384;&#20648;&#20102;&#36882;&#24402;&#26356;&#26032;&#30340;&#28388;&#27874;&#23494;&#24230;&#20989;&#25968;&#30340;&#20449;&#24687;&#65292;&#32780;&#19981;&#26159;&#22312;&#19968;&#32452;&#26377;&#38480;&#30340;&#33945;&#29305;&#21345;&#32599;&#26679;&#26412;&#20013;&#23384;&#20648;&#20449;&#24687;&#65288;&#29992;&#20110;&#31890;&#23376;&#28388;&#27874;&#22120;&#21644;&#38598;&#25104;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65289;&#12290;&#19982;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26469;&#36817;&#20284;&#35780;&#20998;&#20989;&#25968;&#30340;&#29616;&#26377;&#25193;&#25955;&#27169;&#22411;&#19981;&#21516;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26080;&#38656;&#35757;&#32451;&#30340;&#35780;&#20998;&#20272;&#35745;&#26041;&#27861;&#65292;&#20351;&#29992;&#22522;&#20110;&#23567;&#25209;&#37327;&#30340;&#33945;&#29305;&#21345;&#32599;&#20272;&#35745;&#22120;&#26469;&#30452;&#25509;&#36817;&#20284;&#20219;&#20309;&#20266;&#31354;&#38388;-&#26102;&#38388;&#20301;&#32622;&#22788;&#30340;&#35780;&#20998;&#20989;&#25968;&#65292;&#20174;&#32780;&#25552;&#20379;&#20102;&#36275;&#22815;&#20934;&#30830;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose an ensemble score filter (EnSF) for solving high-dimensional nonlinear filtering problems with superior accuracy. A major drawback of existing filtering methods, e.g., particle filters or ensemble Kalman filters, is the low accuracy in handling high-dimensional and highly nonlinear problems. EnSF attacks this challenge by exploiting the score-based diffusion model, defined in a pseudo-temporal domain, to characterizing the evolution of the filtering density. EnSF stores the information of the recursively updated filtering density function in the score function, in stead of storing the information in a set of finite Monte Carlo samples (used in particle filters and ensemble Kalman filters). Unlike existing diffusion models that train neural networks to approximate the score function, we develop a training-free score estimation that uses mini-batch-based Monte Carlo estimator to directly approximate the score function at any pseudo-spatial-temporal location, which provides suf
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32469;&#36807;&#27169;&#25311;&#22120;&#30340;&#23545;&#25239;&#32447;&#24615;&#24773;&#22659;&#33218;&#24102;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#27599;&#36718;&#34892;&#21160;&#38598;&#36739;&#23567;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;$\widetilde{O}(\sqrt{T})$&#30340;&#36951;&#25022;&#24230;&#12290;&#36825;&#20010;&#31639;&#27861;&#36824;&#33021;&#22815;&#22788;&#29702;&#25439;&#22833;&#32447;&#24615;&#36817;&#20284;&#20197;&#21450;&#23545;&#25239;&#24615;&#25439;&#22833;&#21644;&#38543;&#26426;&#33218;&#21487;&#29992;&#24615;&#30340;&#29305;&#27530;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2309.00814</link><description>&lt;p&gt;
&#32469;&#36807;&#27169;&#25311;&#22120;: &#36817;&#20284;&#26368;&#20248;&#30340;&#23545;&#25239;&#32447;&#24615;&#24773;&#22659;&#33218;&#24102;
&lt;/p&gt;
&lt;p&gt;
Bypassing the Simulator: Near-Optimal Adversarial Linear Contextual Bandits. (arXiv:2309.00814v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00814
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32469;&#36807;&#27169;&#25311;&#22120;&#30340;&#23545;&#25239;&#32447;&#24615;&#24773;&#22659;&#33218;&#24102;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#27599;&#36718;&#34892;&#21160;&#38598;&#36739;&#23567;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;$\widetilde{O}(\sqrt{T})$&#30340;&#36951;&#25022;&#24230;&#12290;&#36825;&#20010;&#31639;&#27861;&#36824;&#33021;&#22815;&#22788;&#29702;&#25439;&#22833;&#32447;&#24615;&#36817;&#20284;&#20197;&#21450;&#23545;&#25239;&#24615;&#25439;&#22833;&#21644;&#38543;&#26426;&#33218;&#21487;&#29992;&#24615;&#30340;&#29305;&#27530;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#23545;&#25239;&#24615;&#32447;&#24615;&#24773;&#22659;&#33218;&#24102;&#38382;&#39064;&#65292;&#20854;&#20013;&#25439;&#22833;&#21521;&#37327;&#23436;&#20840;&#34987;&#23545;&#25239;&#22320;&#36873;&#25321;&#65292;&#27599;&#36718;&#34892;&#21160;&#38598;&#65288;&#21363;&#24773;&#22659;&#65289;&#20174;&#22266;&#23450;&#20998;&#24067;&#20013;&#25277;&#26679;&#12290;&#29616;&#26377;&#38024;&#23545;&#35813;&#38382;&#39064;&#30340;&#26041;&#27861;&#35201;&#20040;&#38656;&#35201;&#35775;&#38382;&#27169;&#25311;&#22120;&#29983;&#25104;&#33258;&#30001;&#30340;i.i.d.&#24773;&#22659;&#65292;&#35201;&#20040;&#22312;&#26368;&#20248;&#36951;&#25022;&#26041;&#38754;&#21482;&#33021;&#36798;&#21040;&#27425;&#20248;&#32467;&#26524;&#65292;&#19981;&#22909;&#20110;$\widetilde{O}(T^{\frac{5}{6}})$&#65292;&#25110;&#32773;&#35745;&#31639;&#25928;&#29575;&#20302;&#19979;&#12290;&#25105;&#20204;&#36890;&#36807;&#19981;&#20351;&#29992;&#27169;&#25311;&#22120;&#65292;&#21516;&#26102;&#20445;&#25345;&#22312;&#27599;&#36718;&#34892;&#21160;&#38598;&#36739;&#23567;&#30340;&#24773;&#20917;&#19979;&#35745;&#31639;&#25928;&#29575;&#65292;&#22823;&#22823;&#25913;&#21892;&#20102;&#36825;&#20123;&#32467;&#26524;&#65292;&#20351;&#24471;&#36951;&#25022;&#24230;&#36798;&#21040;$\widetilde{O}(\sqrt{T})$&#12290;&#23545;&#20110;&#20855;&#26377;&#23545;&#25239;&#24615;&#25439;&#22833;&#21644;&#38543;&#26426;&#33218;&#21487;&#29992;&#24615;&#30340;&#30561;&#30496;&#33218;&#24102;&#29305;&#20363;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#32943;&#23450;&#22320;&#22238;&#31572;&#20102;Saha&#31561;&#20154;&#25152;&#25552;&#20986;&#30340;&#20851;&#20110;&#26159;&#21542;&#23384;&#22312;&#20855;&#26377;$poly(d)\sqrt{T}$&#36951;&#25022;&#24230;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#33258;&#28982;&#22320;&#22788;&#29702;&#20102;&#25439;&#22833;&#36817;&#20284;&#20026;&#32447;&#24615;&#30340;&#24773;&#20917;&#65292;&#21516;&#26102;&#25105;&#20204;&#30340;&#36951;&#25022;&#24230;&#25509;&#36817;&#26368;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the adversarial linear contextual bandit problem, where the loss vectors are selected fully adversarially and the per-round action set (i.e. the context) is drawn from a fixed distribution. Existing methods for this problem either require access to a simulator to generate free i.i.d. contexts, achieve a sub-optimal regret no better than $\widetilde{O}(T^{\frac{5}{6}})$, or are computationally inefficient. We greatly improve these results by achieving a regret of $\widetilde{O}(\sqrt{T})$ without a simulator, while maintaining computational efficiency when the action set in each round is small. In the special case of sleeping bandits with adversarial loss and stochastic arm availability, our result answers affirmatively the open question by Saha et al. [2020] on whether there exists a polynomial-time algorithm with $poly(d)\sqrt{T}$ regret. Our approach naturally handles the case where the loss is linear up to an additive misspecification error, and our regret shows near-opt
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#26500;&#21270;&#24452;&#21521;&#22522;&#20989;&#25968;&#32593;&#32476;&#65292;&#29992;&#20110;&#35299;&#20915;&#22810;&#27169;&#24577;&#22238;&#24402;&#38382;&#39064;&#12290;&#35813;&#32593;&#32476;&#33021;&#22815;&#26377;&#25928;&#22320;&#32452;&#21512;&#22810;&#20010;&#20551;&#35774;&#39044;&#27979;&#22120;&#65292;&#24182;&#36890;&#36807;&#25554;&#20540;&#36924;&#36817;&#22810;&#20010;&#20551;&#35774;&#30446;&#26631;&#20998;&#24067;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.00781</link><description>&lt;p&gt;
&#32467;&#26500;&#21270;&#24452;&#21521;&#22522;&#20989;&#25968;&#32593;&#32476;&#65306;&#29992;&#20110;&#22810;&#20551;&#35774;&#39044;&#27979;&#30340;&#22810;&#26679;&#24615;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Structured Radial Basis Function Network: Modelling Diversity for Multiple Hypotheses Prediction. (arXiv:2309.00781v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00781
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#26500;&#21270;&#24452;&#21521;&#22522;&#20989;&#25968;&#32593;&#32476;&#65292;&#29992;&#20110;&#35299;&#20915;&#22810;&#27169;&#24577;&#22238;&#24402;&#38382;&#39064;&#12290;&#35813;&#32593;&#32476;&#33021;&#22815;&#26377;&#25928;&#22320;&#32452;&#21512;&#22810;&#20010;&#20551;&#35774;&#39044;&#27979;&#22120;&#65292;&#24182;&#36890;&#36807;&#25554;&#20540;&#36924;&#36817;&#22810;&#20010;&#20551;&#35774;&#30446;&#26631;&#20998;&#24067;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#22238;&#24402;&#23545;&#20110;&#39044;&#27979;&#38750;&#24179;&#31283;&#36807;&#31243;&#25110;&#20855;&#26377;&#22797;&#26434;&#20998;&#24067;&#30340;&#38382;&#39064;&#38750;&#24120;&#37325;&#35201;&#12290;&#21487;&#20197;&#36890;&#36807;&#22810;&#20551;&#35774;&#26694;&#26550;&#26469;&#22788;&#29702;&#65292;&#20294;&#22312;&#23398;&#20064;&#27169;&#22411;&#20013;&#26377;&#25928;&#22320;&#32452;&#21512;&#23427;&#20204;&#26159;&#26377;&#22256;&#38590;&#30340;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#26500;&#21270;&#24452;&#21521;&#22522;&#20989;&#25968;&#32593;&#32476;&#65292;&#20316;&#20026;&#22810;&#20551;&#35774;&#39044;&#27979;&#22120;&#30340;&#38598;&#21512;&#65292;&#29992;&#20110;&#22238;&#24402;&#38382;&#39064;&#12290;&#36825;&#20123;&#39044;&#27979;&#22120;&#26159;&#20219;&#20309;&#31867;&#22411;&#30340;&#22238;&#24402;&#27169;&#22411;&#65292;&#21487;&#20197;&#24418;&#25104;&#20197;&#23427;&#20204;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#25439;&#22833;&#20026;&#20989;&#25968;&#30340;&#37325;&#24515;&#32500;&#35834;&#22270;&#20998;&#21106;&#12290;&#35777;&#26126;&#20102;&#36825;&#20010;&#32467;&#26500;&#21270;&#27169;&#22411;&#33021;&#22815;&#26377;&#25928;&#22320;&#25554;&#20540;&#36825;&#20010;&#20998;&#21106;&#65292;&#24182;&#19988;&#36924;&#36817;&#22810;&#20010;&#20551;&#35774;&#30446;&#26631;&#20998;&#24067;&#65292;&#24182;&#19988;&#31561;&#20215;&#20110;&#25554;&#20540;&#39044;&#27979;&#22120;&#30340;&#20803;&#25439;&#22833;&#65292;&#25439;&#22833;&#26159;&#25554;&#20540;&#35823;&#24046;&#30340;&#38646;&#38598;&#12290;&#35813;&#27169;&#22411;&#22312;&#39044;&#27979;&#22120;&#21644;&#22522;&#20989;&#25968;&#20013;&#24515;&#20043;&#38388;&#20855;&#26377;&#22266;&#23450;&#28857;&#36845;&#20195;&#31639;&#27861;&#12290;&#21487;&#20197;&#36890;&#36807;&#25130;&#26029;&#20998;&#21106;&#26684;&#24335;&#26469;&#21442;&#25968;&#21270;&#22320;&#25511;&#21046;&#23398;&#20064;&#20013;&#30340;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-modal regression is important in forecasting nonstationary processes or with a complex mixture of distributions. It can be tackled with multiple hypotheses frameworks but with the difficulty of combining them efficiently in a learning model. A Structured Radial Basis Function Network is presented as an ensemble of multiple hypotheses predictors for regression problems. The predictors are regression models of any type that can form centroidal Voronoi tessellations which are a function of their losses during training. It is proved that this structured model can efficiently interpolate this tessellation and approximate the multiple hypotheses target distribution and is equivalent to interpolating the meta-loss of the predictors, the loss being a zero set of the interpolation error. This model has a fixed-point iteration algorithm between the predictors and the centers of the basis functions. Diversity in learning can be controlled parametrically by truncating the tessellation format
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#26041;&#27861;&#26469;&#35780;&#20272;&#22312;&#38169;&#35823;&#25351;&#23450;&#27169;&#22411;&#19979;&#22522;&#20110;&#25915;&#20987;&#24615;&#25439;&#22833;&#30340;&#40065;&#26834;&#20272;&#35745;&#22120;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#25915;&#20987;&#24615;&#36807;&#21097;&#39118;&#38505;&#65292;&#24182;&#24314;&#31435;&#20102;&#19982;&#21033;&#26222;&#35199;&#33576;&#25439;&#22833;&#20989;&#25968;&#30456;&#20851;&#30340;&#38750;&#28176;&#36817;&#19978;&#30028;&#12290;&#22312;&#20108;&#27425;&#25439;&#22833;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25915;&#20987;&#24615;&#36807;&#21097;&#39118;&#38505;&#30028;&#38480;&#20248;&#20110;&#19968;&#33324;&#25439;&#22833;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.00771</link><description>&lt;p&gt;
&#25915;&#20987;&#24615;&#36807;&#21097;&#39118;&#38505;&#22312;&#38169;&#35823;&#25351;&#23450;&#27169;&#22411;&#19979;&#30340;&#38750;&#28176;&#36817;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Non-Asymptotic Bounds for Adversarial Excess Risk under Misspecified Models. (arXiv:2309.00771v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00771
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#26041;&#27861;&#26469;&#35780;&#20272;&#22312;&#38169;&#35823;&#25351;&#23450;&#27169;&#22411;&#19979;&#22522;&#20110;&#25915;&#20987;&#24615;&#25439;&#22833;&#30340;&#40065;&#26834;&#20272;&#35745;&#22120;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#25915;&#20987;&#24615;&#36807;&#21097;&#39118;&#38505;&#65292;&#24182;&#24314;&#31435;&#20102;&#19982;&#21033;&#26222;&#35199;&#33576;&#25439;&#22833;&#20989;&#25968;&#30456;&#20851;&#30340;&#38750;&#28176;&#36817;&#19978;&#30028;&#12290;&#22312;&#20108;&#27425;&#25439;&#22833;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25915;&#20987;&#24615;&#36807;&#21097;&#39118;&#38505;&#30028;&#38480;&#20248;&#20110;&#19968;&#33324;&#25439;&#22833;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35780;&#20272;&#22522;&#20110;&#38169;&#35823;&#25351;&#23450;&#27169;&#22411;&#19979;&#30340;&#40065;&#26834;&#20272;&#35745;&#22120;&#24615;&#33021;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#25915;&#20987;&#24615;&#25439;&#22833;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#22312;&#19968;&#23450;&#30340;&#24179;&#28369;&#26465;&#20214;&#19979;&#65292;&#25915;&#20987;&#24615;&#39118;&#38505;&#31561;&#21516;&#20110;&#30001;&#20998;&#24067;&#25915;&#20987;&#23548;&#33268;&#30340;&#39118;&#38505;&#65292;&#36825;&#30830;&#20445;&#20102;&#25915;&#20987;&#24615;&#35757;&#32451;&#36807;&#31243;&#30340;&#33391;&#22909;&#23450;&#20041;&#24615;&#12290;&#20026;&#20102;&#35780;&#20272;&#25915;&#20987;&#24615;&#20272;&#35745;&#22120;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#25915;&#20987;&#24615;&#36807;&#21097;&#39118;&#38505;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#20998;&#26512;&#26041;&#27861;&#21253;&#25324;&#23545;&#27867;&#21270;&#35823;&#24046;&#21644;&#36924;&#36817;&#35823;&#24046;&#30340;&#35843;&#26597;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19982;&#21033;&#26222;&#35199;&#33576;&#25439;&#22833;&#20989;&#25968;&#30456;&#20851;&#30340;&#25915;&#20987;&#24615;&#36807;&#21097;&#39118;&#38505;&#30340;&#38750;&#28176;&#36817;&#19978;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#36890;&#29992;&#32467;&#26524;&#24212;&#29992;&#20110;&#20998;&#31867;&#21644;&#22238;&#24402;&#38382;&#39064;&#30340;&#25915;&#20987;&#24615;&#35757;&#32451;&#12290;&#23545;&#20110;&#38750;&#21442;&#25968;&#22238;&#24402;&#20013;&#30340;&#20108;&#27425;&#25439;&#22833;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25915;&#20987;&#24615;&#36807;&#21097;&#39118;&#38505;&#30028;&#38480;&#21487;&#20197;&#20248;&#20110;&#19968;&#33324;&#25439;&#22833;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a general approach to evaluating the performance of robust estimators based on adversarial losses under misspecified models. We first show that adversarial risk is equivalent to the risk induced by a distributional adversarial attack under certain smoothness conditions. This ensures that the adversarial training procedure is well-defined. To evaluate the generalization performance of the adversarial estimator, we study the adversarial excess risk. Our proposed analysis method includes investigations on both generalization error and approximation error. We then establish non-asymptotic upper bounds for the adversarial excess risk associated with Lipschitz loss functions. In addition, we apply our general results to adversarial training for classification and regression problems. For the quadratic loss in nonparametric regression, we show that the adversarial excess risk bound can be improved over those for a general loss.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#37327;&#21270;&#35780;&#20272;&#20998;&#31867;&#38543;&#26426;&#26862;&#26519;&#30340;&#35823;&#24046;&#20272;&#35745;&#26041;&#27861;&#65292;&#21457;&#29616;&#38543;&#26426;&#26862;&#26519;&#30340;&#39044;&#27979;&#35823;&#24046;&#20272;&#35745;&#27604;&#24179;&#22343;&#39044;&#27979;&#35823;&#24046;&#26356;&#25509;&#36817;&#30495;&#23454;&#35823;&#24046;&#29575;&#65292;&#24182;&#19988;&#36825;&#19968;&#32467;&#26524;&#36866;&#29992;&#20110;&#19981;&#21516;&#30340;&#35823;&#24046;&#20272;&#35745;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2309.00736</link><description>&lt;p&gt;
&#38543;&#26426;&#26862;&#26519;&#20013;&#30340;&#39044;&#27979;&#35823;&#24046;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Prediction Error Estimation in Random Forests. (arXiv:2309.00736v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00736
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#37327;&#21270;&#35780;&#20272;&#20998;&#31867;&#38543;&#26426;&#26862;&#26519;&#30340;&#35823;&#24046;&#20272;&#35745;&#26041;&#27861;&#65292;&#21457;&#29616;&#38543;&#26426;&#26862;&#26519;&#30340;&#39044;&#27979;&#35823;&#24046;&#20272;&#35745;&#27604;&#24179;&#22343;&#39044;&#27979;&#35823;&#24046;&#26356;&#25509;&#36817;&#30495;&#23454;&#35823;&#24046;&#29575;&#65292;&#24182;&#19988;&#36825;&#19968;&#32467;&#26524;&#36866;&#29992;&#20110;&#19981;&#21516;&#30340;&#35823;&#24046;&#20272;&#35745;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23450;&#37327;&#35780;&#20272;&#20102;&#20998;&#31867;&#38543;&#26426;&#26862;&#26519;&#30340;&#35823;&#24046;&#20272;&#35745;&#12290;&#22312;Bates&#31561;&#20154;&#65288;2023&#24180;&#65289;&#24314;&#31435;&#30340;&#21021;&#27493;&#29702;&#35770;&#26694;&#26550;&#30340;&#22522;&#30784;&#19978;&#65292;&#20174;&#29702;&#35770;&#21644;&#32463;&#39564;&#35282;&#24230;&#25506;&#35752;&#20102;&#38543;&#26426;&#26862;&#26519;&#20013;&#24120;&#35265;&#30340;&#21508;&#31181;&#35823;&#24046;&#20272;&#35745;&#26041;&#27861;&#22312;&#30495;&#23454;&#35823;&#24046;&#29575;&#21644;&#26399;&#26395;&#35823;&#24046;&#29575;&#26041;&#38754;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#20998;&#31867;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#26862;&#26519;&#30340;&#39044;&#27979;&#35823;&#24046;&#20272;&#35745;&#24179;&#22343;&#26356;&#25509;&#36817;&#30495;&#23454;&#35823;&#24046;&#29575;&#65292;&#32780;&#19981;&#26159;&#24179;&#22343;&#39044;&#27979;&#35823;&#24046;&#12290;&#19982;Bates&#31561;&#20154;&#65288;2023&#24180;&#65289;&#23545;&#36923;&#36753;&#22238;&#24402;&#30340;&#30740;&#31350;&#32467;&#26524;&#30456;&#21453;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#65292;&#36825;&#20010;&#32467;&#26524;&#36866;&#29992;&#20110;&#20132;&#21449;&#39564;&#35777;&#12289;&#33258;&#20030;&#21644;&#25968;&#25454;&#21010;&#20998;&#31561;&#19981;&#21516;&#30340;&#35823;&#24046;&#20272;&#35745;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, error estimates of classification Random Forests are quantitatively assessed. Based on the initial theoretical framework built by Bates et al. (2023), the true error rate and expected error rate are theoretically and empirically investigated in the context of a variety of error estimation methods common to Random Forests. We show that in the classification case, Random Forests' estimates of prediction error is closer on average to the true error rate instead of the average prediction error. This is opposite the findings of Bates et al. (2023) which were given for logistic regression. We further show that this result holds across different error estimation strategies such as cross-validation, bagging, and data splitting.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38646;&#21644;&#19981;&#23436;&#20840;&#20449;&#24687;&#21338;&#24328;&#20013;&#23398;&#20064;&#949;-&#26368;&#20248;&#31574;&#30053;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#22266;&#23450;&#37319;&#26679;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#33258;&#36866;&#24212;&#30340;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#36827;&#34892;&#23616;&#37096;&#26356;&#26032;&#65292;&#25105;&#20204;&#21462;&#24471;&#20102;&#25910;&#25947;&#36895;&#24230;&#20026;$\tilde{\mathcal{O}}(T^{-1/2})$&#30340;&#32467;&#26524;&#65292;&#24182;&#22312;&#26368;&#20339;&#31574;&#30053;&#19979;&#23545;&#28216;&#25103;&#21442;&#25968;&#20855;&#26377;&#36817;&#20046;&#26368;&#20248;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2309.00656</link><description>&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22312;&#24102;&#26377;&#36712;&#36857;&#21453;&#39304;&#30340;&#38646;&#21644;&#19981;&#23436;&#20840;&#20449;&#24687;&#21338;&#24328;&#20013;&#22914;&#20309;&#23398;&#20064;&#949;-&#26368;&#20248;&#31574;&#30053;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#29609;&#23478;&#26681;&#25454;&#20182;&#20204;&#22312;&#22266;&#23450;&#25968;&#37327;&#30340;&#22238;&#21512;&#20013;&#35266;&#23519;&#21040;&#30340;&#20449;&#24687;&#20381;&#27425;&#26356;&#26032;&#31574;&#30053;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#30001;&#20110;&#20351;&#29992;&#20102;&#37325;&#35201;&#24615;&#37319;&#26679;&#26469;&#23545;&#21160;&#20316;&#24207;&#21015;&#36827;&#34892;&#20272;&#35745;&#65292;&#23548;&#33268;&#26041;&#24046;&#36739;&#39640;&#12290;&#20026;&#20102;&#20943;&#23567;&#36825;&#31181;&#26041;&#24046;&#65292;&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#19968;&#31181;&#22266;&#23450;&#37319;&#26679;&#26041;&#27861;&#65292;&#21363;&#29609;&#23478;&#22312;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#26356;&#26032;&#31574;&#30053;&#65292;&#20294;&#35266;&#23519;&#21040;&#30340;&#20449;&#24687;&#26159;&#36890;&#36807;&#32473;&#23450;&#30340;&#22266;&#23450;&#37319;&#26679;&#31574;&#30053;&#33719;&#24471;&#30340;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#19968;&#31181;&#33258;&#36866;&#24212;&#30340;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#65288;OMD&#65289;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#23558;OMD&#24212;&#29992;&#20110;&#27599;&#20010;&#20449;&#24687;&#38598;&#65292;&#20351;&#29992;&#36880;&#28176;&#20943;&#23567;&#30340;&#23398;&#20064;&#29575;&#21644;&#27491;&#21017;&#21270;&#25439;&#22833;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#22312;&#39640;&#27010;&#29575;&#19979;&#20855;&#26377;&#25910;&#25947;&#36895;&#24230;&#20026;$\tilde{\mathcal{O}}(T^{-1/2})$&#65292;&#24182;&#22312;&#24212;&#29992;&#26368;&#20339;&#31574;&#30053;&#26102;&#23545;&#28216;&#25103;&#21442;&#25968;&#20855;&#26377;&#36817;&#20046;&#26368;&#20248;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Local and adaptive mirror descents in extensive-form games. (arXiv:2309.00656v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00656
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38646;&#21644;&#19981;&#23436;&#20840;&#20449;&#24687;&#21338;&#24328;&#20013;&#23398;&#20064;&#949;-&#26368;&#20248;&#31574;&#30053;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#22266;&#23450;&#37319;&#26679;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#33258;&#36866;&#24212;&#30340;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#36827;&#34892;&#23616;&#37096;&#26356;&#26032;&#65292;&#25105;&#20204;&#21462;&#24471;&#20102;&#25910;&#25947;&#36895;&#24230;&#20026;$\tilde{\mathcal{O}}(T^{-1/2})$&#30340;&#32467;&#26524;&#65292;&#24182;&#22312;&#26368;&#20339;&#31574;&#30053;&#19979;&#23545;&#28216;&#25103;&#21442;&#25968;&#20855;&#26377;&#36817;&#20046;&#26368;&#20248;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22312;&#24102;&#26377;&#36712;&#36857;&#21453;&#39304;&#30340;&#38646;&#21644;&#19981;&#23436;&#20840;&#20449;&#24687;&#21338;&#24328;&#20013;&#23398;&#20064;&#949;-&#26368;&#20248;&#31574;&#30053;&#30340;&#38382;&#39064;&#12290;&#29616;&#26377;&#26041;&#27861;&#30001;&#20110;&#20351;&#29992;&#20102;&#37325;&#35201;&#24615;&#37319;&#26679;&#65292;&#23384;&#22312;&#26041;&#24046;&#36739;&#39640;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#20943;&#23567;&#26041;&#24046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22266;&#23450;&#37319;&#26679;&#26041;&#27861;&#65292;&#20351;&#29992;&#22266;&#23450;&#37319;&#26679;&#31574;&#30053;&#26469;&#35266;&#23519;&#20449;&#24687;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#33258;&#36866;&#24212;&#30340;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#65292;&#23545;&#27599;&#20010;&#20449;&#24687;&#38598;&#36827;&#34892;&#23616;&#37096;&#26356;&#26032;&#65292;&#24182;&#20351;&#29992;&#36880;&#28176;&#20943;&#23567;&#30340;&#23398;&#20064;&#29575;&#21644;&#27491;&#21017;&#21270;&#25439;&#22833;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#39640;&#27010;&#29575;&#19979;&#20855;&#26377;&#25910;&#25947;&#36895;&#24230;&#20026;$\tilde{\mathcal{O}}(T^{-1/2})$&#65292;&#24182;&#22312;&#26368;&#20339;&#31574;&#30053;&#19979;&#23545;&#28216;&#25103;&#21442;&#25968;&#20855;&#26377;&#36817;&#20046;&#26368;&#20248;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study how to learn $\epsilon$-optimal strategies in zero-sum imperfect information games (IIG) with trajectory feedback. In this setting, players update their policies sequentially based on their observations over a fixed number of episodes, denoted by $T$. Existing procedures suffer from high variance due to the use of importance sampling over sequences of actions (Steinberger et al., 2020; McAleer et al., 2022). To reduce this variance, we consider a fixed sampling approach, where players still update their policies over time, but with observations obtained through a given fixed sampling policy. Our approach is based on an adaptive Online Mirror Descent (OMD) algorithm that applies OMD locally to each information set, using individually decreasing learning rates and a regularized loss. We show that this approach guarantees a convergence rate of $\tilde{\mathcal{O}}(T^{-1/2})$ with high probability and has a near-optimal dependence on the game parameters when applied with the best 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#34880;&#28165;&#20998;&#31867;&#30340;&#25216;&#26415;&#65292;&#21487;&#20197;&#22312;&#22810;&#32500;&#21644;&#26377;&#26434;&#36136;&#30340;&#35757;&#32451;&#25968;&#25454;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#23545;&#26679;&#26412;&#30340;&#20998;&#31867;&#21644;&#20272;&#35745;&#24739;&#30149;&#29575;&#26469;&#20943;&#23569;&#35823;&#24046;&#12290;&#35813;&#26041;&#27861;&#19981;&#38656;&#35201;&#30452;&#25509;&#35775;&#38382;&#26465;&#20214;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#65292;&#32780;&#26159;&#23558;&#25968;&#25454;&#23884;&#20837;&#21442;&#25968;&#21270;&#30340;&#26354;&#32447;&#31354;&#38388;&#65292;&#24182;&#36890;&#36807;&#26368;&#23567;&#21270;&#32463;&#39564;&#35823;&#24046;&#26469;&#20248;&#21270;&#31354;&#38388;&#12290;</title><link>http://arxiv.org/abs/2309.00645</link><description>&lt;p&gt;
&#23545;&#20110;&#22810;&#32500;&#21644;&#26434;&#36136;&#35757;&#32451;&#25968;&#25454;&#30340;&#26368;&#20248;&#34880;&#28165;&#20998;&#31867;&#30340;&#26368;&#23567;&#20551;&#35774;&#65306;&#29702;&#35770;&#21644;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Minimal Assumptions for Optimal Serology Classification: Theory and Implications for Multidimensional Settings and Impure Training Data. (arXiv:2309.00645v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00645
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#34880;&#28165;&#20998;&#31867;&#30340;&#25216;&#26415;&#65292;&#21487;&#20197;&#22312;&#22810;&#32500;&#21644;&#26377;&#26434;&#36136;&#30340;&#35757;&#32451;&#25968;&#25454;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#23545;&#26679;&#26412;&#30340;&#20998;&#31867;&#21644;&#20272;&#35745;&#24739;&#30149;&#29575;&#26469;&#20943;&#23569;&#35823;&#24046;&#12290;&#35813;&#26041;&#27861;&#19981;&#38656;&#35201;&#30452;&#25509;&#35775;&#38382;&#26465;&#20214;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#65292;&#32780;&#26159;&#23558;&#25968;&#25454;&#23884;&#20837;&#21442;&#25968;&#21270;&#30340;&#26354;&#32447;&#31354;&#38388;&#65292;&#24182;&#36890;&#36807;&#26368;&#23567;&#21270;&#32463;&#39564;&#35823;&#24046;&#26469;&#20248;&#21270;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#34880;&#28165;&#23398;&#20013;&#65292;&#20943;&#23569;&#20559;&#24046;&#20272;&#35745;&#21644;&#35786;&#26029;&#20998;&#31867;&#22120;&#20173;&#28982;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#29702;&#35770;&#19978;&#65292;&#36825;&#20123;&#38382;&#39064;&#21487;&#20197;&#36716;&#21270;&#20026;&#24314;&#27169;&#27979;&#37327;&#32467;&#26524;&#30340;&#31867;&#21035;-&#26465;&#20214;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#65288;PDFs&#65289;&#65292;&#23427;&#20204;&#25511;&#21046;&#25152;&#26377;&#21518;&#32493;&#20998;&#26512;&#12290;&#28982;&#32780;&#65292;&#21363;&#20351;&#23545;&#20110;&#20165;&#20855;&#26377;&#23569;&#25968;&#32500;&#24230;&#65288;&#20363;&#22914;&#30446;&#26631;&#25239;&#21407;&#65289;&#30340;&#27979;&#37327;&#36755;&#20986;&#65292;&#36825;&#20010;&#20219;&#21153;&#20063;&#24456;&#24555;&#21463;&#21040;&#32500;&#24230;&#35781;&#21650;&#30340;&#24433;&#21709;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25216;&#26415;&#65292;&#21033;&#29992;&#32463;&#39564;&#35757;&#32451;&#25968;&#25454;&#22312;&#20219;&#24847;&#32500;&#24230;&#19978;&#20998;&#31867;&#26679;&#26412;&#21644;&#20272;&#35745;&#24739;&#30149;&#29575;&#65292;&#32780;&#19981;&#38656;&#35201;&#30452;&#25509;&#35775;&#38382;&#26465;&#20214;PDFs&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#24341;&#29702;&#26469;&#35299;&#37322;&#36825;&#20010;&#26041;&#27861;&#65292;&#35813;&#24341;&#29702;&#23558;&#30456;&#23545;&#26465;&#20214;&#27010;&#29575;&#19982;&#26368;&#23567;&#35823;&#24046;&#20998;&#31867;&#36793;&#30028;&#32852;&#31995;&#36215;&#26469;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#21046;&#23450;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#65306;&#65288;i&#65289;&#23558;&#25968;&#25454;&#23884;&#20837;&#21442;&#25968;&#21270;&#30340;&#26354;&#32447;&#31354;&#38388;&#65307;&#65288;ii&#65289;&#26681;&#25454;&#26679;&#26412;&#30456;&#23545;&#20110;&#22352;&#26631;&#36724;&#30340;&#20301;&#32622;&#23545;&#26679;&#26412;&#36827;&#34892;&#20998;&#31867;&#65307;&#65288;iii&#65289;&#36890;&#36807;&#26368;&#23567;&#21270;&#32463;&#39564;
&lt;/p&gt;
&lt;p&gt;
Minimizing error in prevalence estimates and diagnostic classifiers remains a challenging task in serology. In theory, these problems can be reduced to modeling class-conditional probability densities (PDFs) of measurement outcomes, which control all downstream analyses. However, this task quickly succumbs to the curse of dimensionality, even for assay outputs with only a few dimensions (e.g. target antigens). To address this problem, we propose a technique that uses empirical training data to classify samples and estimate prevalence in arbitrary dimension without direct access to the conditional PDFs. We motivate this method via a lemma that relates relative conditional probabilities to minimum-error classification boundaries. This leads us to formulate an optimization problem that: (i) embeds the data in a parameterized, curved space; (ii) classifies samples based on their position relative to a coordinate axis; and (iii) subsequently optimizes the space by minimizing the empirical c
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#26680;&#23398;&#20064;&#30340;&#25903;&#25345;&#21521;&#37327;&#26426;&#26694;&#26550;(MKL-$L_{0/1}$-SVM)&#65292;&#36890;&#36807;&#24320;&#21457;&#24555;&#36895;&#30340;ADMM&#27714;&#35299;&#22120;&#22788;&#29702;&#38750;&#20984;&#38750;&#20809;&#28369;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#19982;&#39046;&#20808;&#26041;&#27861;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.12016</link><description>&lt;p&gt;
MKL-$L_{0/1}$-SVM: &#19968;&#31181;&#22810;&#26680;&#23398;&#20064;&#30340;&#25903;&#25345;&#21521;&#37327;&#26426;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
MKL-$L_{0/1}$-SVM. (arXiv:2308.12016v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12016
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#26680;&#23398;&#20064;&#30340;&#25903;&#25345;&#21521;&#37327;&#26426;&#26694;&#26550;(MKL-$L_{0/1}$-SVM)&#65292;&#36890;&#36807;&#24320;&#21457;&#24555;&#36895;&#30340;ADMM&#27714;&#35299;&#22120;&#22788;&#29702;&#38750;&#20984;&#38750;&#20809;&#28369;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#19982;&#39046;&#20808;&#26041;&#27861;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;$(0, 1)$&#25439;&#22833;&#20989;&#25968;&#30340;&#25903;&#25345;&#21521;&#37327;&#26426;&#30340;&#22810;&#26680;&#23398;&#20064;&#65288;MKL&#65289;&#26694;&#26550;&#12290;&#39318;&#20808;&#32473;&#20986;&#20102;&#19968;&#38454;&#26368;&#20248;&#24615;&#26465;&#20214;&#65292;&#28982;&#21518;&#21033;&#29992;&#23427;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#24555;&#36895;&#30340;ADMM&#27714;&#35299;&#22120;&#26469;&#22788;&#29702;&#38750;&#20984;&#38750;&#20809;&#28369;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#35814;&#32454;&#30340;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;MKL-$L_{0/1}$-SVM&#30340;&#24615;&#33021;&#19982;&#19968;&#31181;&#21517;&#20026;SimpleMKL&#30340;&#39046;&#20808;&#26041;&#27861;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a Multiple Kernel Learning (abbreviated as MKL) framework for the Support Vector Machine (SVM) with the $(0, 1)$ loss function. Some first-order optimality conditions are given and then exploited to develop a fast ADMM solver to deal with the nonconvex and nonsmooth optimization problem. Extensive numerical experiments on synthetic and real datasets show that the performance of our MKL-$L_{0/1}$-SVM is comparable with the one of the leading approaches called SimpleMKL developed by Rakotomamonjy, Bach, Canu, and Grandvalet [Journal of Machine Learning Research, vol. 9, pp. 2491-2521, 2008].
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#39044;&#31639;&#30340;&#38543;&#26426;&#20108;&#33218;&#36172;&#21338;&#26426;&#20013;&#36827;&#34892;&#26368;&#20339;&#33218;&#36873;&#25321;&#30340;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#19981;&#23384;&#22312;&#27604;&#31561;&#27010;&#29575;&#37319;&#26679;&#31639;&#27861;&#26356;&#22909;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#33268;&#31283;&#23450;&#31639;&#27861;&#30340;&#27010;&#24565;&#65292;&#24182;&#35777;&#26126;&#20219;&#20309;&#22312;&#25152;&#26377;&#24773;&#20917;&#19979;&#19982;&#31561;&#27010;&#29575;&#37319;&#26679;&#31639;&#27861;&#34920;&#29616;&#19968;&#26679;&#22909;&#30340;&#31639;&#27861;&#24517;&#39035;&#23646;&#20110;&#36825;&#20010;&#31867;&#21035;&#12290;&#36825;&#19968;&#32467;&#26524;&#35299;&#20915;&#20102;&#20043;&#21069;&#30340;&#20004;&#20010;&#26410;&#35299;&#20043;&#35868;&#12290;</title><link>http://arxiv.org/abs/2308.12000</link><description>&lt;p&gt;
&#26377;&#20851;&#22312;&#26377;&#38480;&#39044;&#31639;&#20108;&#33218;&#36172;&#21338;&#26426;&#20013;&#36827;&#34892;&#26368;&#20339;&#33218;&#36873;&#25321;&#30340;&#32479;&#19968;&#26368;&#20248;&#31639;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Uniformly Optimal Algorithms for Best Arm Identification in Two-Armed Bandits with Fixed Budget. (arXiv:2308.12000v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12000
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#39044;&#31639;&#30340;&#38543;&#26426;&#20108;&#33218;&#36172;&#21338;&#26426;&#20013;&#36827;&#34892;&#26368;&#20339;&#33218;&#36873;&#25321;&#30340;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#19981;&#23384;&#22312;&#27604;&#31561;&#27010;&#29575;&#37319;&#26679;&#31639;&#27861;&#26356;&#22909;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#33268;&#31283;&#23450;&#31639;&#27861;&#30340;&#27010;&#24565;&#65292;&#24182;&#35777;&#26126;&#20219;&#20309;&#22312;&#25152;&#26377;&#24773;&#20917;&#19979;&#19982;&#31561;&#27010;&#29575;&#37319;&#26679;&#31639;&#27861;&#34920;&#29616;&#19968;&#26679;&#22909;&#30340;&#31639;&#27861;&#24517;&#39035;&#23646;&#20110;&#36825;&#20010;&#31867;&#21035;&#12290;&#36825;&#19968;&#32467;&#26524;&#35299;&#20915;&#20102;&#20043;&#21069;&#30340;&#20004;&#20010;&#26410;&#35299;&#20043;&#35868;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20855;&#26377;&#20271;&#21162;&#21033;&#22870;&#21169;&#30340;&#38543;&#26426;&#20108;&#33218;&#36172;&#21338;&#26426;&#20013;&#65292;&#20351;&#29992;&#26377;&#38480;&#39044;&#31639;&#36827;&#34892;&#26368;&#20339;&#33218;&#36873;&#25321;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#19981;&#23384;&#22312;&#19968;&#20010;&#31639;&#27861;&#21487;&#20197;&#22312;&#25152;&#26377;&#24773;&#20917;&#19979;&#19982;&#31561;&#27010;&#29575;&#37319;&#26679;&#31639;&#27861;&#34920;&#29616;&#19968;&#26679;&#22909;&#65288;&#35813;&#31639;&#27861;&#34987;&#31216;&#20026;&#8220;&#22343;&#21248;&#37319;&#26679;&#8221;&#31639;&#27861;&#65289;&#65292;&#24182;&#19988;&#22312;&#33267;&#23569;&#19968;&#20010;&#24773;&#20917;&#19979;&#26126;&#26174;&#20248;&#20110;&#35813;&#31639;&#27861;&#12290;&#31616;&#32780;&#35328;&#20043;&#65292;&#19981;&#23384;&#22312;&#27604;&#22343;&#21248;&#37319;&#26679;&#31639;&#27861;&#26356;&#22909;&#30340;&#31639;&#27861;&#12290;&#20026;&#20102;&#35777;&#26126;&#36825;&#19968;&#32467;&#26524;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#8220;&#19968;&#33268;&#8221;&#21644;&#8220;&#31283;&#23450;&#8221;&#31639;&#27861;&#30340;&#33258;&#28982;&#31867;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#20219;&#20309;&#31639;&#27861;&#35201;&#22312;&#25152;&#26377;&#24773;&#20917;&#19979;&#19982;&#22343;&#21248;&#37319;&#26679;&#31639;&#27861;&#34920;&#29616;&#19968;&#26679;&#22909;&#65292;&#24517;&#39035;&#23646;&#20110;&#36825;&#20010;&#31867;&#21035;&#12290;&#36890;&#36807;&#23548;&#20986;&#28385;&#36275;&#20219;&#20309;&#19968;&#33268;&#19988;&#31283;&#23450;&#31639;&#27861;&#30340;&#38169;&#35823;&#29575;&#30340;&#19979;&#30028;&#65292;&#24182;&#35777;&#26126;&#22343;&#21248;&#37319;&#26679;&#31639;&#27861;&#19982;&#27492;&#19979;&#30028;&#30456;&#21305;&#37197;&#65292;&#25105;&#20204;&#23436;&#25104;&#20102;&#35777;&#26126;&#36807;&#31243;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#35299;&#20915;&#20102;\cite{qin2022open}&#20013;&#25552;&#20986;&#30340;&#20004;&#20010;&#26410;&#35299;&#20043;&#35868;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of best-arm identification with fixed budget in stochastic two-arm bandits with Bernoulli rewards. We prove that surprisingly, there is no algorithm that (i) performs as well as the algorithm sampling each arm equally (this algorithm is referred to as the {\it uniform sampling} algorithm) on all instances, and that (ii) strictly outperforms this algorithm on at least one instance. In short, there is no algorithm better than the uniform sampling algorithm. Towards this result, we introduce the natural class of {\it consistent} and {\it stable} algorithms, and show that any algorithm that performs as well as the uniform sampling algorithm on all instances belongs to this class. The proof is completed by deriving a lower bound on the error rate satisfied by any consistent and stable algorithm, and by showing that the uniform sampling algorithm matches this lower bound. Our results provide a solution to the two open problems presented in \cite{qin2022open}.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20851;&#27880;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#30340;&#20027;&#21160;&#23545;&#31216;&#24615;&#65292;&#36890;&#36807;&#32771;&#34385;&#20449;&#21495;&#22312;&#22266;&#23450;&#22270;&#19978;&#30340;&#23398;&#20064;&#35774;&#32622;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#30340;&#23545;&#31216;&#24615;&#27010;&#24565;&#65292;&#36890;&#36807;&#22270;&#31895;&#21270;&#23454;&#29616;&#12290;&#36825;&#31687;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#20010;&#20559;&#24046;-&#26041;&#24046;&#20844;&#24335;&#26469;&#34913;&#37327;&#36817;&#20284;&#23545;&#31216;&#24615;...</title><link>http://arxiv.org/abs/2308.10436</link><description>&lt;p&gt;
&#36817;&#20284;&#31561;&#21464;&#22270;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Approximately Equivariant Graph Networks. (arXiv:2308.10436v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10436
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#30340;&#20027;&#21160;&#23545;&#31216;&#24615;&#65292;&#36890;&#36807;&#32771;&#34385;&#20449;&#21495;&#22312;&#22266;&#23450;&#22270;&#19978;&#30340;&#23398;&#20064;&#35774;&#32622;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#30340;&#23545;&#31216;&#24615;&#27010;&#24565;&#65292;&#36890;&#36807;&#22270;&#31895;&#21270;&#23454;&#29616;&#12290;&#36825;&#31687;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#20010;&#20559;&#24046;-&#26041;&#24046;&#20844;&#24335;&#26469;&#34913;&#37327;&#36817;&#20284;&#23545;&#31216;&#24615;...
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#36890;&#24120;&#34987;&#25551;&#36848;&#20026;&#23545;&#22270;&#20013;&#30340;&#33410;&#28857;&#37325;&#26032;&#25490;&#24207;&#20855;&#26377;&#32622;&#25442;&#31561;&#21464;&#24615;&#12290;GNNs&#30340;&#36825;&#31181;&#23545;&#31216;&#24615;&#24120;&#34987;&#19982;&#27431;&#20960;&#37324;&#24471;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNNs&#65289;&#30340;&#24179;&#31227;&#31561;&#21464;&#24615;&#27604;&#36739;&#12290;&#28982;&#32780;&#65292;&#36825;&#20004;&#31181;&#23545;&#31216;&#24615;&#26412;&#36136;&#19978;&#26159;&#19981;&#21516;&#30340;&#65306;CNNs&#30340;&#24179;&#31227;&#31561;&#21464;&#24615;&#23545;&#24212;&#20110;&#20316;&#29992;&#20110;&#22270;&#20687;&#20449;&#21495;&#30340;&#22266;&#23450;&#22495;&#30340;&#23545;&#31216;&#24615;&#65288;&#26377;&#26102;&#31216;&#20026;&#20027;&#21160;&#23545;&#31216;&#24615;&#65289;&#65292;&#32780;&#22312;GNNs&#20013;&#65292;&#20219;&#20309;&#32622;&#25442;&#37117;&#20316;&#29992;&#20110;&#22270;&#20449;&#21495;&#21644;&#22270;&#22495;&#65288;&#26377;&#26102;&#25551;&#36848;&#20026;&#34987;&#21160;&#23545;&#31216;&#24615;&#65289;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32858;&#28966;&#20110;GNNs&#30340;&#20027;&#21160;&#23545;&#31216;&#24615;&#65292;&#32771;&#34385;&#20449;&#21495;&#22312;&#19968;&#20010;&#22266;&#23450;&#22270;&#19978;&#36827;&#34892;&#23398;&#20064;&#30340;&#24773;&#20917;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;GNNs&#30340;&#33258;&#28982;&#23545;&#31216;&#24615;&#26159;&#22270;&#30340;&#33258;&#21516;&#26500;&#12290;&#30001;&#20110;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#22270;&#24448;&#24448;&#26159;&#38750;&#23545;&#31216;&#30340;&#65292;&#25105;&#20204;&#36890;&#36807;&#24418;&#24335;&#21270;&#22270;&#31895;&#21270;&#26469;&#25918;&#26494;&#23545;&#31216;&#24615;&#30340;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#20559;&#24046;-&#26041;&#24046;&#20844;&#24335;&#26469;&#34913;&#37327;...
&lt;/p&gt;
&lt;p&gt;
Graph neural networks (GNNs) are commonly described as being permutation equivariant with respect to node relabeling in the graph. This symmetry of GNNs is often compared to the translation equivariance symmetry of Euclidean convolution neural networks (CNNs). However, these two symmetries are fundamentally different: The translation equivariance of CNNs corresponds to symmetries of the fixed domain acting on the image signal (sometimes known as active symmetries), whereas in GNNs any permutation acts on both the graph signals and the graph domain (sometimes described as passive symmetries). In this work, we focus on the active symmetries of GNNs, by considering a learning setting where signals are supported on a fixed graph. In this case, the natural symmetries of GNNs are the automorphisms of the graph. Since real-world graphs tend to be asymmetric, we relax the notion of symmetries by formalizing approximate symmetries via graph coarsening. We present a bias-variance formula that qu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#24179;&#28369;&#38750;&#20984;&#20248;&#21270;&#20013;&#38543;&#26426;&#27425;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#36136;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#21333;&#26102;&#38388;&#23610;&#24230;&#21644;&#21452;&#26102;&#38388;&#23610;&#24230;&#24773;&#20917;&#19979;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#21253;&#25324;&#20102;&#22810;&#31181;&#24050;&#30693;&#30340;SGD&#31867;&#22411;&#26041;&#27861;&#12290;&#23545;&#20110;&#26377;&#38480;&#21644;&#24418;&#24335;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#35777;&#26126;&#20102;&#36825;&#20123;&#26041;&#27861;&#33021;&#22815;&#22312;&#38543;&#26426;&#36873;&#25321;&#30340;&#27493;&#38271;&#21644;&#21021;&#22987;&#28857;&#19978;&#25214;&#21040;Clarke&#31283;&#23450;&#28857;&#12290;</title><link>http://arxiv.org/abs/2307.10053</link><description>&lt;p&gt;
&#38750;&#24179;&#28369;&#38750;&#20984;&#20248;&#21270;&#20013;&#38543;&#26426;&#27425;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Convergence Guarantees for Stochastic Subgradient Methods in Nonsmooth Nonconvex Optimization. (arXiv:2307.10053v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10053
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#24179;&#28369;&#38750;&#20984;&#20248;&#21270;&#20013;&#38543;&#26426;&#27425;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#36136;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#21333;&#26102;&#38388;&#23610;&#24230;&#21644;&#21452;&#26102;&#38388;&#23610;&#24230;&#24773;&#20917;&#19979;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#21253;&#25324;&#20102;&#22810;&#31181;&#24050;&#30693;&#30340;SGD&#31867;&#22411;&#26041;&#27861;&#12290;&#23545;&#20110;&#26377;&#38480;&#21644;&#24418;&#24335;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#35777;&#26126;&#20102;&#36825;&#20123;&#26041;&#27861;&#33021;&#22815;&#22312;&#38543;&#26426;&#36873;&#25321;&#30340;&#27493;&#38271;&#21644;&#21021;&#22987;&#28857;&#19978;&#25214;&#21040;Clarke&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#26041;&#27861;&#21450;&#20854;&#21464;&#31181;&#22312;&#35757;&#32451;&#30001;&#38750;&#24179;&#28369;&#28608;&#27963;&#20989;&#25968;&#26500;&#24314;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#25910;&#25947;&#24615;&#36136;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#20026;&#26356;&#26032;&#21160;&#37327;&#39033;&#21644;&#21464;&#37327;&#30340;&#27493;&#38271;&#20998;&#37197;&#20102;&#19981;&#21516;&#30340;&#26102;&#38388;&#23610;&#24230;&#12290;&#22312;&#19968;&#20123;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#22312;&#21333;&#26102;&#38388;&#23610;&#24230;&#21644;&#21452;&#26102;&#38388;&#23610;&#24230;&#24773;&#20917;&#19979;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#21253;&#21547;&#20102;&#24456;&#22810;&#24050;&#30693;&#30340;SGD&#31867;&#22411;&#26041;&#27861;&#65292;&#21253;&#25324;heavy-ball SGD&#12289;SignSGD&#12289;Lion&#12289;normalized SGD&#21644;clipped SGD&#12290;&#27492;&#22806;&#65292;&#24403;&#30446;&#26631;&#20989;&#25968;&#37319;&#29992;&#26377;&#38480;&#21644;&#24418;&#24335;&#26102;&#65292;&#25105;&#20204;&#22522;&#20110;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#35777;&#26126;&#20102;&#36825;&#20123;SGD&#31867;&#22411;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#36136;&#12290;&#29305;&#21035;&#22320;&#65292;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;SGD&#31867;&#22411;&#26041;&#27861;&#22312;&#38543;&#26426;&#36873;&#25321;&#30340;&#27493;&#38271;&#21644;&#21021;&#22987;&#28857;&#19978;&#33021;&#22815;&#25214;&#21040;&#30446;&#26631;&#20989;&#25968;&#30340;Clarke&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we investigate the convergence properties of the stochastic gradient descent (SGD) method and its variants, especially in training neural networks built from nonsmooth activation functions. We develop a novel framework that assigns different timescales to stepsizes for updating the momentum terms and variables, respectively. Under mild conditions, we prove the global convergence of our proposed framework in both single-timescale and two-timescale cases. We show that our proposed framework encompasses a wide range of well-known SGD-type methods, including heavy-ball SGD, SignSGD, Lion, normalized SGD and clipped SGD. Furthermore, when the objective function adopts a finite-sum formulation, we prove the convergence properties for these SGD-type methods based on our proposed framework. In particular, we prove that these SGD-type methods find the Clarke stationary points of the objective function with randomly chosen stepsizes and initial points under mild assumptions. Preli
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#22810;&#31181;&#28608;&#27963;&#20989;&#25968;&#19979;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#35777;&#26126;&#20102;&#21487;&#20197;&#36890;&#36807;&#22312;&#26377;&#30028;&#38598;&#21512;&#19978;&#26500;&#24314;&#19968;&#20010;&#23485;&#24230;&#20026;6N&#12289;&#28145;&#24230;&#20026;2L&#30340;varrho&#28608;&#27963;&#32593;&#32476;&#26469;&#36924;&#36817;&#19968;&#20010;&#23485;&#24230;&#20026;N&#12289;&#28145;&#24230;&#20026;L&#30340;ReLU&#32593;&#32476;&#65292;&#20174;&#32780;&#23558;&#23545;ReLU&#32593;&#32476;&#30340;&#36924;&#36817;&#32467;&#26524;&#25512;&#24191;&#21040;&#20854;&#20182;&#28608;&#27963;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2307.06555</link><description>&lt;p&gt;
&#28145;&#24230;&#32593;&#32476;&#36924;&#36817;&#65306;&#20174;ReLU&#21040;&#22810;&#31181;&#28608;&#27963;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Deep Network Approximation: Beyond ReLU to Diverse Activation Functions. (arXiv:2307.06555v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06555
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#22810;&#31181;&#28608;&#27963;&#20989;&#25968;&#19979;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#35777;&#26126;&#20102;&#21487;&#20197;&#36890;&#36807;&#22312;&#26377;&#30028;&#38598;&#21512;&#19978;&#26500;&#24314;&#19968;&#20010;&#23485;&#24230;&#20026;6N&#12289;&#28145;&#24230;&#20026;2L&#30340;varrho&#28608;&#27963;&#32593;&#32476;&#26469;&#36924;&#36817;&#19968;&#20010;&#23485;&#24230;&#20026;N&#12289;&#28145;&#24230;&#20026;L&#30340;ReLU&#32593;&#32476;&#65292;&#20174;&#32780;&#23558;&#23545;ReLU&#32593;&#32476;&#30340;&#36924;&#36817;&#32467;&#26524;&#25512;&#24191;&#21040;&#20854;&#20182;&#28608;&#27963;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#22810;&#31181;&#28608;&#27963;&#20989;&#25968;&#19979;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;&#23450;&#20041;&#20102;&#19968;&#20010;&#28608;&#27963;&#20989;&#25968;&#38598;&#21512;A&#65292;&#21253;&#25324;&#22823;&#22810;&#25968;&#24120;&#29992;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#22914;ReLU&#12289;LeakyReLU&#12289;ReLU^2&#12289;ELU&#12289;SELU&#12289;Softplus&#12289;GELU&#12289;SiLU&#12289;Swish&#12289;Mish&#12289;Sigmoid&#12289;Tanh&#12289;Arctan&#12289;Softsign&#12289;dSiLU&#21644;SRS&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#20219;&#24847;&#28608;&#27963;&#20989;&#25968;varrho&#8712;A&#65292;&#21487;&#20197;&#36890;&#36807;&#19968;&#20010;&#23485;&#24230;&#20026;6N&#12289;&#28145;&#24230;&#20026;2L&#30340;varrho&#28608;&#27963;&#32593;&#32476;&#22312;&#26377;&#30028;&#38598;&#21512;&#19978;&#20197;&#20219;&#24847;&#31934;&#24230;&#36924;&#36817;&#19968;&#20010;&#23485;&#24230;&#20026;N&#12289;&#28145;&#24230;&#20026;L&#30340;ReLU&#32593;&#32476;&#12290;&#36825;&#19968;&#21457;&#29616;&#20351;&#24471;&#22823;&#37096;&#20998;&#23545;&#20110;ReLU&#32593;&#32476;&#30340;&#36924;&#36817;&#32467;&#26524;&#33021;&#22815;&#25512;&#24191;&#21040;&#20854;&#20182;&#28608;&#27963;&#20989;&#25968;&#65292;&#23613;&#31649;&#38656;&#35201;&#31245;&#22823;&#30340;&#24120;&#25968;&#20195;&#20215;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores the expressive power of deep neural networks for a diverse range of activation functions. An activation function set $\mathscr{A}$ is defined to encompass the majority of commonly used activation functions, such as $\mathtt{ReLU}$, $\mathtt{LeakyReLU}$, $\mathtt{ReLU}^2$, $\mathtt{ELU}$, $\mathtt{SELU}$, $\mathtt{Softplus}$, $\mathtt{GELU}$, $\mathtt{SiLU}$, $\mathtt{Swish}$, $\mathtt{Mish}$, $\mathtt{Sigmoid}$, $\mathtt{Tanh}$, $\mathtt{Arctan}$, $\mathtt{Softsign}$, $\mathtt{dSiLU}$, and $\mathtt{SRS}$. We demonstrate that for any activation function $\varrho\in \mathscr{A}$, a $\mathtt{ReLU}$ network of width $N$ and depth $L$ can be approximated to arbitrary precision by a $\varrho$-activated network of width $6N$ and depth $2L$ on any bounded set. This finding enables the extension of most approximation results achieved with $\mathtt{ReLU}$ networks to a wide variety of other activation functions, at the cost of slightly larger constants.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20869;&#26680;&#38543;&#26426;&#25237;&#24433;&#28145;&#24230;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#25968;&#25454;&#20113;&#20013;&#30340;&#22810;&#27169;&#24335;&#21644;&#38750;&#20984;&#24615;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2306.07056</link><description>&lt;p&gt;
&#20869;&#26680;&#38543;&#26426;&#25237;&#24433;&#28145;&#24230;&#29992;&#20110;&#31163;&#32676;&#28857;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Kernel Random Projection Depth for Outlier Detection. (arXiv:2306.07056v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07056
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20869;&#26680;&#38543;&#26426;&#25237;&#24433;&#28145;&#24230;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#25968;&#25454;&#20113;&#20013;&#30340;&#22810;&#27169;&#24335;&#21644;&#38750;&#20984;&#24615;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#30340;&#38543;&#26426;&#25237;&#24433;&#28145;&#24230;&#65288;RPD&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#25968;&#25454;&#20113;&#20013;&#30340;&#22810;&#27169;&#24335;&#21644;&#38750;&#20984;&#24615;&#12290;&#22312;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#26694;&#26550;&#20013;&#65292;RPD&#22312;&#20877;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#35745;&#31639;&#12290;&#20511;&#21161;&#20869;&#26680;&#20027;&#25104;&#20998;&#20998;&#26512;&#65292;&#25105;&#20204;&#26399;&#26395;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#22788;&#29702;&#19978;&#36848;&#22810;&#31181;&#27169;&#24335;&#21644;&#38750;&#20984;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20248;&#20110;RPD&#65292;&#24182;&#21487;&#19982;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#29616;&#26377;&#30340;&#26816;&#27979;&#27169;&#22411;&#30456;&#23218;&#32654;&#65292;&#20851;&#20110;&#25509;&#25910;&#25805;&#20316;&#29305;&#24449;&#26354;&#32447;&#65288;ROC&#65289;&#19979;&#30340;&#26354;&#32447;&#19979;&#38754;&#31215;&#65288;AUC&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes an extension of Random Projection Depth (RPD) to cope with multiple modalities and non-convexity on data clouds. In the framework of the proposed method, the RPD is computed in a reproducing kernel Hilbert space. With the help of kernel principal component analysis, we expect that the proposed method can cope with the above multiple modalities and non-convexity. The experimental results demonstrate that the proposed method outperforms RPD and is comparable to other existing detection models on benchmark datasets regarding Area Under the Curves (AUCs) of Receiver Operating Characteristic (ROC).
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#34394;&#25311;&#31890;&#23376;&#38543;&#26426;&#36924;&#36817;&#30340;&#21487;&#35777;&#36895;&#38480;&#21046;&#21464;&#31181;&#30340;SVGD&#31639;&#27861;&#65292;&#20855;&#26377;&#21487;&#35777;&#36895;&#30340;&#26377;&#38480;&#31890;&#23376;&#25910;&#25947;&#29575;&#12290;</title><link>http://arxiv.org/abs/2305.17558</link><description>&lt;p&gt;
&#22522;&#20110;&#34394;&#25311;&#31890;&#23376;&#38543;&#26426;&#36924;&#36817;&#30340;&#21487;&#35777;&#36895;&#38480;&#21046;&#21464;&#31181;&#30340;SVGD&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Provably Fast Finite Particle Variants of SVGD via Virtual Particle Stochastic Approximation. (arXiv:2305.17558v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17558
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#34394;&#25311;&#31890;&#23376;&#38543;&#26426;&#36924;&#36817;&#30340;&#21487;&#35777;&#36895;&#38480;&#21046;&#21464;&#31181;&#30340;SVGD&#31639;&#27861;&#65292;&#20855;&#26377;&#21487;&#35777;&#36895;&#30340;&#26377;&#38480;&#31890;&#23376;&#25910;&#25947;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Stein&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#65288;SVGD&#65289;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#23427;&#27169;&#25311;&#30456;&#20114;&#20316;&#29992;&#30340;&#31890;&#23376;&#31995;&#32479;&#20197;&#36817;&#20284;&#20174;&#30446;&#26631;&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#20855;&#26377;&#21508;&#31181;&#39046;&#22495;&#30340;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#32463;&#39564;&#24615;&#33021;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#23427;&#30340;&#32676;&#20307;&#65288;&#21363;&#65292;&#26080;&#38480;&#31890;&#23376;&#65289;&#26497;&#38480;&#21160;&#21147;&#23398;&#24050;&#32463;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#30740;&#31350;&#65292;&#20294;&#26159;SVGD&#22312;&#26377;&#38480;&#31890;&#23376;&#20307;&#21046;&#19979;&#30340;&#34892;&#20026;&#21017;&#19981;&#22826;&#28165;&#26970;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#31181;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;SVGD&#21464;&#20307;&#65292;&#21363;VP-SVGD&#65288;&#20174;&#27010;&#24565;&#19978;&#35762;&#24456;&#20248;&#38597;&#65289;&#21644;GB-SVGD&#65288;&#20174;&#32463;&#39564;&#19978;&#30475;&#24456;&#26377;&#25928;&#65289;&#65292;&#20855;&#26377;&#21487;&#35777;&#36895;&#30340;&#26377;&#38480;&#31890;&#23376;&#25910;&#25947;&#29575;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#8220;&#34394;&#25311;&#31890;&#23376;&#8221;&#30340;&#27010;&#24565;&#65292;&#24182;&#22312;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#20013;&#24320;&#21457;&#20102;&#20154;&#21475;&#26497;&#38480;SVGD&#21160;&#21147;&#23398;&#30340;&#26032;&#22411;&#38543;&#26426;&#36924;&#36817;&#26041;&#27861;&#65292;&#23427;&#20204;&#21487;&#20197;&#20351;&#29992;&#26377;&#38480;&#25968;&#37327;&#30340;&#31890;&#23376;&#31934;&#30830;&#23454;&#29616;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#20197;&#30475;&#20316;&#26159;SVGD&#30340;&#29305;&#23450;&#38543;&#26426;&#25209;&#22788;&#29702;&#36924;&#36817;&#65292;&#27604;&#26222;&#36890;&#26041;&#27861;&#26356;&#20855;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stein Variational Gradient Descent (SVGD) is a popular variational inference algorithm which simulates an interacting particle system to approximately sample from a target distribution, with impressive empirical performance across various domains. Theoretically, its population (i.e, infinite-particle) limit dynamics is well studied but the behavior of SVGD in the finite-particle regime is much less understood. In this work, we design two computationally efficient variants of SVGD, namely VP-SVGD (which is conceptually elegant) and GB-SVGD (which is empirically effective), with provably fast finite-particle convergence rates. We introduce the notion of \emph{virtual particles} and develop novel stochastic approximations of population-limit SVGD dynamics in the space of probability measures, which are exactly implementable using a finite number of particles. Our algorithms can be viewed as specific random-batch approximations of SVGD, which are computationally more efficient than ordinar
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#25439;&#22833;&#40657;&#22622;&#30697;&#38453;&#21644;&#36755;&#20837;-&#36755;&#20986;&#38597;&#20811;&#27604;&#30697;&#38453;&#32852;&#31995;&#36215;&#26469;&#30340;&#20551;&#35774;&#65292;&#37327;&#21270;&#20102;&#27169;&#22411;&#30340;&#36755;&#20837;-&#36755;&#20986;&#38597;&#20811;&#27604;&#30697;&#38453;&#36817;&#20284;&#20854;&#22312;&#25968;&#25454;&#20998;&#24067;&#19978;&#30340;&#21033;&#26222;&#35199;&#33576;&#33539;&#25968;&#30340;&#31243;&#24230;&#65292;&#24182;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#32463;&#39564;&#38597;&#20811;&#27604;&#30697;&#38453;&#30340;&#26032;&#30340;&#27867;&#21270;&#30028;&#65292;&#32473;&#20986;&#20102;&#20851;&#20110;&#36827;&#21270;&#30952;&#38155;&#21644;&#24179;&#22374;&#26497;&#23567;&#30340;&#27867;&#21270;&#24615;&#36136;&#30340;&#26032;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2305.14683</link><description>&lt;p&gt;
&#35770;&#36827;&#21270;&#30952;&#38155;&#12289;&#24179;&#22374;&#26497;&#23567;&#21644;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
On progressive sharpening, flat minima and generalisation. (arXiv:2305.14683v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14683
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#25439;&#22833;&#40657;&#22622;&#30697;&#38453;&#21644;&#36755;&#20837;-&#36755;&#20986;&#38597;&#20811;&#27604;&#30697;&#38453;&#32852;&#31995;&#36215;&#26469;&#30340;&#20551;&#35774;&#65292;&#37327;&#21270;&#20102;&#27169;&#22411;&#30340;&#36755;&#20837;-&#36755;&#20986;&#38597;&#20811;&#27604;&#30697;&#38453;&#36817;&#20284;&#20854;&#22312;&#25968;&#25454;&#20998;&#24067;&#19978;&#30340;&#21033;&#26222;&#35199;&#33576;&#33539;&#25968;&#30340;&#31243;&#24230;&#65292;&#24182;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#32463;&#39564;&#38597;&#20811;&#27604;&#30697;&#38453;&#30340;&#26032;&#30340;&#27867;&#21270;&#30028;&#65292;&#32473;&#20986;&#20102;&#20851;&#20110;&#36827;&#21270;&#30952;&#38155;&#21644;&#24179;&#22374;&#26497;&#23567;&#30340;&#27867;&#21270;&#24615;&#36136;&#30340;&#26032;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#29702;&#35299;&#28145;&#24230;&#23398;&#20064;&#20013;&#25439;&#22833;&#26354;&#29575;&#19982;&#27867;&#21270;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#21033;&#29992;&#29616;&#26377;&#30340;&#28145;&#24230;&#32593;&#32476;&#25439;&#22833;&#40657;&#22622;&#30697;&#38453;&#39057;&#35889;&#32463;&#39564;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#23558;&#25439;&#22833;&#40657;&#22622;&#30697;&#38453;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20837;-&#36755;&#20986;&#38597;&#20811;&#27604;&#30697;&#38453;&#32852;&#31995;&#36215;&#26469;&#30340;&#20551;&#35774;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#31995;&#21015;&#29702;&#35770;&#32467;&#26524;&#65292;&#37327;&#21270;&#20102;&#27169;&#22411;&#30340;&#36755;&#20837;-&#36755;&#20986;&#38597;&#20811;&#27604;&#30697;&#38453;&#36817;&#20284;&#20854;&#22312;&#25968;&#25454;&#20998;&#24067;&#19978;&#30340;&#21033;&#26222;&#35199;&#33576;&#33539;&#25968;&#30340;&#31243;&#24230;&#65292;&#24182;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#32463;&#39564;&#38597;&#20811;&#27604;&#30697;&#38453;&#30340;&#26032;&#30340;&#27867;&#21270;&#30028;&#12290;&#25105;&#20204;&#21033;&#29992;&#25105;&#20204;&#30340;&#20551;&#35774;&#21644;&#29702;&#35770;&#32467;&#26524;&#65292;&#32473;&#20986;&#20102;&#20851;&#20110;&#26368;&#36817;&#35266;&#23519;&#21040;&#30340;&#36827;&#21270;&#30952;&#38155;&#29616;&#35937;&#20197;&#21450;&#24179;&#22374;&#26497;&#23567;&#30340;&#27867;&#21270;&#24615;&#36136;&#30340;&#26032;&#25551;&#36848;&#12290;&#23454;&#39564;&#35777;&#25454;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#20027;&#24352;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a new approach to understanding the relationship between loss curvature and generalisation in deep learning. Specifically, we use existing empirical analyses of the spectrum of deep network loss Hessians to ground an ansatz tying together the loss Hessian and the input-output Jacobian of a deep neural network. We then prove a series of theoretical results which quantify the degree to which the input-output Jacobian of a model approximates its Lipschitz norm over a data distribution, and deduce a novel generalisation bound in terms of the empirical Jacobian. We use our ansatz, together with our theoretical results, to give a new account of the recently observed progressive sharpening phenomenon, as well as the generalisation properties of flat minima. Experimental evidence is provided to validate our claims.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#24037;&#31243;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#36125;&#21494;&#26031;&#24314;&#27169;&#65292;&#20351;&#29992;&#38543;&#26426;PDE&#34920;&#31034;&#26469;&#24320;&#21457;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#26694;&#26550;&#65292;&#20174;&#32780;&#21487;&#20197;&#22312;&#20960;&#20309;&#22797;&#26434;&#30340;&#22495;&#19978;&#36827;&#34892;&#22823;&#35268;&#27169;&#30340;&#32479;&#35745;&#26377;&#38480;&#20803;&#20998;&#26512;&#21644;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#12290;</title><link>http://arxiv.org/abs/2305.13879</link><description>&lt;p&gt;
&#38024;&#23545;&#22823;&#35268;&#27169;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#21644;&#32479;&#35745;&#26377;&#38480;&#20803;&#20998;&#26512;&#30340;&#38543;&#26426;PDE&#34920;&#31034;&#38543;&#26426;&#22330;
&lt;/p&gt;
&lt;p&gt;
Stochastic PDE representation of random fields for large-scale Gaussian process regression and statistical finite element analysis. (arXiv:2305.13879v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13879
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#24037;&#31243;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#36125;&#21494;&#26031;&#24314;&#27169;&#65292;&#20351;&#29992;&#38543;&#26426;PDE&#34920;&#31034;&#26469;&#24320;&#21457;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#26694;&#26550;&#65292;&#20174;&#32780;&#21487;&#20197;&#22312;&#20960;&#20309;&#22797;&#26434;&#30340;&#22495;&#19978;&#36827;&#34892;&#22823;&#35268;&#27169;&#30340;&#32479;&#35745;&#26377;&#38480;&#20803;&#20998;&#26512;&#21644;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24037;&#31243;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#30340;&#36125;&#21494;&#26031;&#24314;&#27169;&#20013;&#65292;&#26377;&#25928;&#34920;&#31034;&#20960;&#20309;&#22797;&#26434;&#22495;&#19978;&#30340;&#38543;&#26426;&#22330;&#33267;&#20851;&#37325;&#35201;&#12290;&#24403;&#21069;&#26222;&#36941;&#20351;&#29992;&#30340;&#38543;&#26426;&#22330;&#34920;&#31034;&#20165;&#38480;&#20110;&#26080;&#30028;&#22495;&#25110;&#22312;&#21487;&#33021;&#30340;&#22330;&#23646;&#24615;&#26041;&#38754;&#36807;&#20110;&#21463;&#38480;&#12290;&#22240;&#27492;&#65292;&#21033;&#29992;&#38543;&#26426;PDE&#19982;&#38543;&#26426;&#22330;&#20043;&#38388;&#30340;&#21382;&#21490;&#32852;&#31995;&#30340;&#26032;&#25216;&#26415;&#23545;&#20110;&#20855;&#26377;&#22797;&#26434;&#20960;&#20309;&#24418;&#29366;&#21644;&#23384;&#22312;&#26377;&#38480;&#20803;&#31163;&#25955;&#21270;&#29992;&#20110;&#27714;&#35299;&#29289;&#29702;&#23432;&#24658;&#26041;&#31243;&#30340;&#24037;&#31243;&#24212;&#29992;&#23588;&#20026;&#21560;&#24341;&#20154;&#12290;&#19982;&#38543;&#26426;&#22330;&#30340;&#23494;&#38598;&#21327;&#26041;&#24046;&#30697;&#38453;&#19981;&#21516;&#65292;&#20854;&#36870;&#30697;&#38453;--&#31934;&#24230;&#30697;&#38453;&#36890;&#24120;&#26159;&#31232;&#30095;&#30340;&#65292;&#24182;&#31561;&#20110;&#31867;&#20284;Helmholtz&#30340;&#38543;&#26426;PDE&#30340;&#21018;&#24230;&#30697;&#38453;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;SPDE&#34920;&#31034;&#26469;&#24320;&#21457;&#21487;&#25193;&#23637;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#20960;&#20309;&#22797;&#26434;&#22495;&#19978;&#36827;&#34892;&#22823;&#35268;&#27169;&#30340;&#32479;&#35745;&#26377;&#38480;&#20803;&#20998;&#26512;&#65288;StatFEM&#65289;&#21644;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#22238;&#24402;&#12290;&#25105;&#20204;&#20351;&#29992;SPDE&#20844;&#24335;
&lt;/p&gt;
&lt;p&gt;
The efficient representation of random fields on geometrically complex domains is crucial for Bayesian modelling in engineering and machine learning. Today's prevalent random field representations are restricted to unbounded domains or are too restrictive in terms of possible field properties. As a result, new techniques leveraging the historically established link between stochastic PDEs (SPDEs) and random fields are especially appealing for engineering applications with complex geometries which already have a finite element discretisation for solving the physical conservation equations. Unlike the dense covariance matrix of a random field, its inverse, the precision matrix, is usually sparse and equal to the stiffness matrix of a Helmholtz-like SPDE. In this paper, we use the SPDE representation to develop a scalable framework for large-scale statistical finite element analysis (statFEM) and Gaussian process (GP) regression on geometrically complex domains. We use the SPDE formulatio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#38543;&#26426;&#25628;&#32034;&#21450;&#20854;&#24615;&#33021;&#65292;&#24341;&#20837;&#20102;&#8220;&#25955;&#23556;&#32500;&#24230;&#8221;&#30340;&#27010;&#24565;&#65292;&#25551;&#36848;&#20102;&#24213;&#23618;&#20989;&#25968;&#30340;&#29366;&#24577;&#65292;&#37327;&#21270;&#20102;&#38543;&#26426;&#25628;&#32034;&#30340;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#26080;&#22122;&#22768;&#21644;&#26377;&#30028;&#22122;&#22768;&#24773;&#20917;&#19979;&#30340;&#36755;&#20986;&#20998;&#21035;&#20197;&#19968;&#23450;&#27010;&#29575;&#25910;&#25947;&#21040;&#26368;&#20248;&#20540;&#12290;</title><link>http://arxiv.org/abs/2305.11509</link><description>&lt;p&gt;
&#20174;&#38543;&#26426;&#25628;&#32034;&#21040;&#24230;&#37327;&#27979;&#24230;&#31354;&#38388;&#20013;&#30340;&#36172;&#21338;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
From Random Search to Bandit Learning in Metric Measure Spaces. (arXiv:2305.11509v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11509
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#38543;&#26426;&#25628;&#32034;&#21450;&#20854;&#24615;&#33021;&#65292;&#24341;&#20837;&#20102;&#8220;&#25955;&#23556;&#32500;&#24230;&#8221;&#30340;&#27010;&#24565;&#65292;&#25551;&#36848;&#20102;&#24213;&#23618;&#20989;&#25968;&#30340;&#29366;&#24577;&#65292;&#37327;&#21270;&#20102;&#38543;&#26426;&#25628;&#32034;&#30340;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#26080;&#22122;&#22768;&#21644;&#26377;&#30028;&#22122;&#22768;&#24773;&#20917;&#19979;&#30340;&#36755;&#20986;&#20998;&#21035;&#20197;&#19968;&#23450;&#27010;&#29575;&#25910;&#25947;&#21040;&#26368;&#20248;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#25628;&#32034;&#26159;&#36229;&#21442;&#25968;&#20248;&#21270;&#20013;&#26368;&#24120;&#29992;&#30340;&#26041;&#27861;&#20043;&#19968;&#65292;&#23545;&#20110;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#25104;&#21151;&#33267;&#20851;&#37325;&#35201;&#12290;&#23613;&#31649;&#20854;&#24615;&#33021;&#20196;&#20154;&#24778;&#21497;&#65292;&#20294;&#24456;&#23569;&#26377;&#38750;&#21551;&#21457;&#24335;&#30340;&#29702;&#35770;&#29992;&#20110;&#25551;&#36848;&#20854;&#24037;&#20316;&#26426;&#21046;&#12290;&#26412;&#25991;&#32473;&#20986;&#20102;&#20851;&#20110;&#38543;&#26426;&#25628;&#32034;&#30340;&#29702;&#35770;&#35299;&#37322;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#8220;&#25955;&#23556;&#32500;&#24230;&#8221;&#30340;&#27010;&#24565;&#65292;&#25551;&#36848;&#20102;&#24213;&#23618;&#20989;&#25968;&#30340;&#29366;&#24577;&#65292;&#24182;&#37327;&#21270;&#20102;&#38543;&#26426;&#25628;&#32034;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#24403;&#29615;&#22659;&#27809;&#26377;&#22122;&#22768;&#26102;&#65292;&#38543;&#26426;&#25628;&#32034;&#30340;&#36755;&#20986;&#20197;&#27010;&#29575;&#25910;&#25947;&#21040;&#26368;&#20248;&#20540;&#65292;&#20854;&#36895;&#29575;&#20026;$ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{1}{d_s} } \right) $&#65292;&#20854;&#20013;$ d_s \ge 0 $&#26159;&#24213;&#23618;&#20989;&#25968;&#30340;&#25955;&#23556;&#32500;&#24230;&#12290;&#24403;&#35266;&#23519;&#21040;&#30340;&#20989;&#25968;&#20540;&#21463;&#21040;&#26377;&#30028;&#30340;&#29420;&#31435;&#21516;&#20998;&#24067;&#22122;&#22768;&#24433;&#21709;&#26102;&#65292;&#38543;&#26426;&#25628;&#32034;&#30340;&#36755;&#20986;&#20197;&#27010;&#29575;&#25910;&#25947;&#21040;&#26368;&#20248;&#20540;&#65292;&#36895;&#29575;&#20026;$ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{2}{2+d_s} } \right) $&#12290;
&lt;/p&gt;
&lt;p&gt;
Random Search is one of the most widely-used method for Hyperparameter Optimization, and is critical to the success of deep learning models. Despite its astonishing performance, little non-heuristic theory has been developed to describe the underlying working mechanism. This paper gives a theoretical accounting of Random Search. We introduce the concept of \emph{scattering dimension} that describes the landscape of the underlying function, and quantifies the performance of random search. We show that, when the environment is noise-free, the output of random search converges to the optimal value in probability at rate $ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{1}{d_s} } \right) $, where $ d_s \ge 0 $ is the scattering dimension of the underlying function. When the observed function values are corrupted by bounded $iid$ noise, the output of random search converges to the optimal value in probability at rate $ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \rig
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27604;&#36739;&#20102;&#19981;&#21516;&#30340;&#32570;&#22833;&#25968;&#25454;&#22788;&#29702;&#26041;&#27861;&#23545;&#30456;&#20851;&#22270;&#30340;&#24433;&#21709;&#65292;&#24314;&#35758;&#20351;&#29992;&#30452;&#25509;&#21442;&#25968;&#20272;&#35745;&#27861;(DPER)&#26469;&#32472;&#21046;&#30456;&#20851;&#22270;</title><link>http://arxiv.org/abs/2305.06044</link><description>&lt;p&gt;
&#32570;&#22833;&#20540;&#19979;&#30340;&#30456;&#20851;&#24615;&#21487;&#35270;&#21270;&#65306;&#22635;&#20805;&#27861;&#21644;&#30452;&#25509;&#21442;&#25968;&#20272;&#35745;&#27861;&#30340;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Correlation visualization under missing values: a comparison between imputation and direct parameter estimation methods. (arXiv:2305.06044v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06044
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27604;&#36739;&#20102;&#19981;&#21516;&#30340;&#32570;&#22833;&#25968;&#25454;&#22788;&#29702;&#26041;&#27861;&#23545;&#30456;&#20851;&#22270;&#30340;&#24433;&#21709;&#65292;&#24314;&#35758;&#20351;&#29992;&#30452;&#25509;&#21442;&#25968;&#20272;&#35745;&#27861;(DPER)&#26469;&#32472;&#21046;&#30456;&#20851;&#22270;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30456;&#20851;&#30697;&#38453;&#21487;&#35270;&#21270;&#23545;&#20110;&#29702;&#35299;&#25968;&#25454;&#38598;&#20013;&#21464;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#26159;&#32570;&#22833;&#25968;&#25454;&#20250;&#23545;&#30456;&#20851;&#31995;&#25968;&#30340;&#20272;&#35745;&#20135;&#29983;&#26174;&#33879;&#25361;&#25112;&#12290;&#26412;&#25991;&#27604;&#36739;&#20102;&#19981;&#21516;&#30340;&#32570;&#22833;&#25968;&#25454;&#22788;&#29702;&#26041;&#27861;&#23545;&#30456;&#20851;&#22270;&#30340;&#24433;&#21709;&#65292;&#37325;&#28857;&#20851;&#27880;&#20004;&#31181;&#24120;&#35265;&#30340;&#32570;&#22833;&#27169;&#24335;&#65306;&#38543;&#26426;&#21644;&#21333;&#35843;&#12290;&#25105;&#20204;&#26088;&#22312;&#20026;&#30740;&#31350;&#20154;&#21592;&#21644;&#23454;&#36341;&#32773;&#25552;&#20379;&#23454;&#29992;&#30340;&#31574;&#30053;&#21644;&#24314;&#35758;&#65292;&#20197;&#21019;&#24314;&#21644;&#20998;&#26512;&#30456;&#20851;&#22270;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#34429;&#28982;&#22635;&#20805;&#27861;&#36890;&#24120;&#29992;&#20110;&#32570;&#22833;&#25968;&#25454;&#65292;&#20294;&#20351;&#29992;&#22635;&#20805;&#30340;&#25968;&#25454;&#26469;&#29983;&#25104;&#30456;&#20851;&#30697;&#38453;&#22270;&#21487;&#33021;&#20250;&#23548;&#33268;&#23545;&#29305;&#24449;&#20043;&#38388;&#20851;&#31995;&#30340;&#35823;&#23548;&#24615;&#25512;&#26029;&#12290;&#25105;&#20204;&#24314;&#35758;&#22522;&#20110;&#20854;&#22312;&#23454;&#39564;&#20013;&#30340;&#34920;&#29616;&#65292;&#20351;&#29992;DPER&#65292;&#19968;&#31181;&#30452;&#25509;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#32472;&#21046;&#30456;&#20851;&#30697;&#38453;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Correlation matrix visualization is essential for understanding the relationships between variables in a dataset, but missing data can pose a significant challenge in estimating correlation coefficients. In this paper, we compare the effects of various missing data methods on the correlation plot, focusing on two common missing patterns: random and monotone. We aim to provide practical strategies and recommendations for researchers and practitioners in creating and analyzing the correlation plot. Our experimental results suggest that while imputation is commonly used for missing data, using imputed data for plotting the correlation matrix may lead to a significantly misleading inference of the relation between the features. We recommend using DPER, a direct parameter estimation approach, for plotting the correlation matrix based on its performance in the experiments.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27010;&#25324;&#20102;&#26080;&#30417;&#30563;&#28145;&#24230;&#23398;&#20064;&#20013;&#22522;&#20110;&#29420;&#31435;&#25104;&#20998;&#20998;&#26512;&#26041;&#27861;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#35299;&#20915;&#38750;&#32447;&#24615;&#24773;&#20917;&#19979;&#21807;&#19968;&#24615;&#38382;&#39064;&#25552;&#20986;&#20102;&#21487;&#35782;&#21035;&#30340;&#25193;&#23637;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2303.16535</link><description>&lt;p&gt;
&#26080;&#30417;&#30563;&#28145;&#24230;&#23398;&#20064;&#20013;&#22522;&#20110;&#38750;&#32447;&#24615;&#29420;&#31435;&#25104;&#20998;&#20998;&#26512;&#30340;&#21407;&#21017;&#20998;&#31163;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Nonlinear Independent Component Analysis for Principled Disentanglement in Unsupervised Deep Learning. (arXiv:2303.16535v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16535
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27010;&#25324;&#20102;&#26080;&#30417;&#30563;&#28145;&#24230;&#23398;&#20064;&#20013;&#22522;&#20110;&#29420;&#31435;&#25104;&#20998;&#20998;&#26512;&#26041;&#27861;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#35299;&#20915;&#38750;&#32447;&#24615;&#24773;&#20917;&#19979;&#21807;&#19968;&#24615;&#38382;&#39064;&#25552;&#20986;&#20102;&#21487;&#35782;&#21035;&#30340;&#25193;&#23637;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26080;&#30417;&#30563;&#28145;&#24230;&#23398;&#20064;&#20013;&#65292;&#22914;&#20309;&#25214;&#21040;&#26377;&#29992;&#30340;&#39640;&#32500;&#25968;&#25454;&#34920;&#31034;&#65292;&#21363;&#25152;&#35859;&#30340;&#8220;&#20998;&#31163;&#8221;&#38382;&#39064;&#33267;&#20851;&#37325;&#35201;&#12290;&#22823;&#22810;&#25968;&#26041;&#27861;&#37117;&#26159;&#21551;&#21457;&#24335;&#30340;&#65292;&#32570;&#20047;&#36866;&#24403;&#30340;&#29702;&#35770;&#22522;&#30784;&#12290;&#22312;&#32447;&#24615;&#34920;&#31034;&#23398;&#20064;&#20013;&#65292;&#29420;&#31435;&#25104;&#20998;&#20998;&#26512;&#65288;ICA&#65289;&#22312;&#35768;&#22810;&#24212;&#29992;&#39046;&#22495;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#24182;&#19988;&#20855;&#26377;&#22522;&#20110;&#33391;&#23450;&#20041;&#30340;&#27010;&#29575;&#27169;&#22411;&#30340;&#21407;&#21017;&#24615;&#12290; &#28982;&#32780;&#65292;&#23558;ICA&#25193;&#23637;&#21040;&#38750;&#32447;&#24615;&#24773;&#20917;&#24050;&#32463;&#25104;&#20026;&#19968;&#20010;&#26840;&#25163;&#30340;&#38382;&#39064;&#65292;&#36825;&#26159;&#30001;&#20110;&#32570;&#20047;&#21487;&#35782;&#21035;&#24615;&#65292;&#21363;&#34920;&#31034;&#30340;&#21807;&#19968;&#24615;&#12290;&#26368;&#36817;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#20351;&#29992;&#26102;&#38388;&#32467;&#26500;&#25110;&#26576;&#20123;&#36741;&#21161;&#20449;&#24687;&#30340;&#38750;&#32447;&#24615;&#25193;&#23637;&#12290;&#36825;&#20123;&#27169;&#22411;&#23454;&#38469;&#19978;&#26159;&#21487;&#35782;&#21035;&#30340;&#65292;&#22240;&#27492;&#24050;&#32463;&#24320;&#21457;&#20986;&#36234;&#26469;&#36234;&#22810;&#30340;&#31639;&#27861;&#12290;&#29305;&#21035;&#26159;&#19968;&#20123;&#33258;&#30417;&#30563;&#31639;&#27861;&#21487;&#20197;&#26174;&#31034;&#20986;&#20272;&#35745;&#38750;&#32447;&#24615;ICA&#65292;&#21363;&#20351;&#26368;&#21021;&#26159;&#20174;&#21551;&#21457;&#24335;&#35282;&#24230;&#25552;&#20986;&#30340;&#12290;&#26412;&#25991;&#24635;&#32467;&#20102;&#38750;&#32447;&#24615;ICA&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
A central problem in unsupervised deep learning is how to find useful representations of high-dimensional data, sometimes called "disentanglement". Most approaches are heuristic and lack a proper theoretical foundation. In linear representation learning, independent component analysis (ICA) has been successful in many applications areas, and it is principled, i.e. based on a well-defined probabilistic model. However, extension of ICA to the nonlinear case has been problematic due to the lack of identifiability, i.e. uniqueness of the representation. Recently, nonlinear extensions that utilize temporal structure or some auxiliary information have been proposed. Such models are in fact identifiable, and consequently, an increasing number of algorithms have been developed. In particular, some self-supervised algorithms can be shown to estimate nonlinear ICA, even though they have initially been proposed from heuristic perspectives. This paper reviews the state-of-the-art of nonlinear ICA 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#36866;&#24212;&#26041;&#27861;FAStEN&#65292;&#29992;&#20110;&#22312;&#39640;&#32500;&#20989;&#25968;&#22238;&#24402;&#38382;&#39064;&#20013;&#25191;&#34892;&#29305;&#24449;&#36873;&#25321;&#21644;&#21442;&#25968;&#20272;&#35745;&#65292;&#36890;&#36807;&#21033;&#29992;&#20989;&#25968;&#20027;&#25104;&#20998;&#21644;&#23545;&#20598;&#22686;&#24191;Lagrangian&#38382;&#39064;&#30340;&#31232;&#30095;&#24615;&#36136;&#65292;&#20855;&#26377;&#26174;&#33879;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#36873;&#25321;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.14801</link><description>&lt;p&gt;
&#39640;&#32500;&#20989;&#25968;&#22238;&#24402;&#20013;&#29305;&#24449;&#36873;&#25321;&#21644;&#20272;&#35745;&#30340;&#19968;&#31181;&#39640;&#25928;&#33258;&#36866;&#24212;&#26041;&#27861;--FAStEN
&lt;/p&gt;
&lt;p&gt;
FAStEN: an efficient adaptive method for feature selection and estimation in high-dimensional functional regressions. (arXiv:2303.14801v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14801
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#36866;&#24212;&#26041;&#27861;FAStEN&#65292;&#29992;&#20110;&#22312;&#39640;&#32500;&#20989;&#25968;&#22238;&#24402;&#38382;&#39064;&#20013;&#25191;&#34892;&#29305;&#24449;&#36873;&#25321;&#21644;&#21442;&#25968;&#20272;&#35745;&#65292;&#36890;&#36807;&#21033;&#29992;&#20989;&#25968;&#20027;&#25104;&#20998;&#21644;&#23545;&#20598;&#22686;&#24191;Lagrangian&#38382;&#39064;&#30340;&#31232;&#30095;&#24615;&#36136;&#65292;&#20855;&#26377;&#26174;&#33879;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#36873;&#25321;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20989;&#25968;&#22238;&#24402;&#20998;&#26512;&#26159;&#35768;&#22810;&#24403;&#20195;&#31185;&#23398;&#24212;&#29992;&#30340;&#24050;&#24314;&#31435;&#24037;&#20855;&#12290;&#28041;&#21450;&#22823;&#35268;&#27169;&#21644;&#22797;&#26434;&#25968;&#25454;&#38598;&#30340;&#22238;&#24402;&#38382;&#39064;&#26159;&#26222;&#36941;&#23384;&#22312;&#30340;&#65292;&#29305;&#24449;&#36873;&#25321;&#23545;&#20110;&#36991;&#20813;&#36807;&#24230;&#25311;&#21512;&#21644;&#23454;&#29616;&#20934;&#30830;&#39044;&#27979;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#12289;&#28789;&#27963;&#30340;&#12289;&#36229;&#39640;&#25928;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#31232;&#30095;&#39640;&#32500;&#20989;&#25968;&#22238;&#24402;&#38382;&#39064;&#20013;&#25191;&#34892;&#29305;&#24449;&#36873;&#25321;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#20854;&#25193;&#23637;&#21040;&#26631;&#37327;&#23545;&#20989;&#25968;&#26694;&#26550;&#20013;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#20989;&#25968;&#25968;&#25454;&#12289;&#20248;&#21270;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#20197;&#21516;&#26102;&#25191;&#34892;&#29305;&#24449;&#36873;&#25321;&#21644;&#21442;&#25968;&#20272;&#35745;&#12290;&#25105;&#20204;&#21033;&#29992;&#20989;&#25968;&#20027;&#25104;&#20998;&#30340;&#29305;&#24615;&#20197;&#21450;&#23545;&#20598;&#22686;&#24191;Lagrangian&#38382;&#39064;&#30340;&#31232;&#30095;&#24615;&#36136;&#65292;&#26174;&#33879;&#38477;&#20302;&#20102;&#35745;&#31639;&#25104;&#26412;&#65292;&#24182;&#24341;&#20837;&#20102;&#33258;&#36866;&#24212;&#26041;&#26696;&#26469;&#25552;&#39640;&#36873;&#25321;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#27169;&#25311;&#30740;&#31350;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#26368;&#20339;&#29616;&#26377;&#31454;&#20105;&#23545;&#25163;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#65292;&#24182;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#39640;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Functional regression analysis is an established tool for many contemporary scientific applications. Regression problems involving large and complex data sets are ubiquitous, and feature selection is crucial for avoiding overfitting and achieving accurate predictions. We propose a new, flexible, and ultra-efficient approach to perform feature selection in a sparse high dimensional function-on-function regression problem, and we show how to extend it to the scalar-on-function framework. Our method combines functional data, optimization, and machine learning techniques to perform feature selection and parameter estimation simultaneously. We exploit the properties of Functional Principal Components, and the sparsity inherent to the Dual Augmented Lagrangian problem to significantly reduce computational cost, and we introduce an adaptive scheme to improve selection accuracy. Through an extensive simulation study, we benchmark our approach to the best existing competitors and demonstrate a 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35777;&#26126;&#25910;&#25947;&#30340;PnP&#26041;&#27861;&#65292;&#20351;&#29992;&#25311;&#29275;&#39039;&#27493;&#39588;&#20197;&#21152;&#36895;&#25910;&#25947;&#65292;&#30456;&#23545;&#20110;&#29616;&#26377;&#30340;PnP&#26041;&#27861;&#23545;&#21435;&#22122;&#22120;&#25110;&#20445;&#30495;&#24230;&#20989;&#25968;&#26045;&#21152;&#20102;&#36739;&#36731;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2303.07271</link><description>&lt;p&gt;
&#21487;&#35777;&#25910;&#25947;&#30340;&#21363;&#25554;&#21363;&#29992;&#25311;&#29275;&#39039;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Provably Convergent Plug-and-Play Quasi-Newton Methods. (arXiv:2303.07271v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.07271
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35777;&#26126;&#25910;&#25947;&#30340;PnP&#26041;&#27861;&#65292;&#20351;&#29992;&#25311;&#29275;&#39039;&#27493;&#39588;&#20197;&#21152;&#36895;&#25910;&#25947;&#65292;&#30456;&#23545;&#20110;&#29616;&#26377;&#30340;PnP&#26041;&#27861;&#23545;&#21435;&#22122;&#22120;&#25110;&#20445;&#30495;&#24230;&#20989;&#25968;&#26045;&#21152;&#20102;&#36739;&#36731;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21363;&#25554;&#21363;&#29992;&#65288;PnP&#65289;&#26041;&#27861;&#26159;&#19968;&#31867;&#39640;&#25928;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#26088;&#22312;&#21033;&#29992;&#32463;&#20856;&#20248;&#21270;&#31639;&#27861;&#65288;&#22914;ISTA&#25110;ADMM&#65289;&#65292;&#23558;&#25968;&#25454;&#20445;&#30495;&#24230;&#39033;&#21644;&#28145;&#24230;&#21435;&#22122;&#22120;&#30456;&#32467;&#21512;&#12290;&#29616;&#26377;&#30340;&#21487;&#35777;&#26126;&#30340;PnP&#26041;&#27861;&#23545;&#21435;&#22122;&#22120;&#25110;&#20445;&#30495;&#24230;&#20989;&#25968;&#26045;&#21152;&#20102;&#20005;&#26684;&#30340;&#38480;&#21046;&#65292;&#22914;&#38750;&#25193;&#24352;&#24615;&#25110;&#20005;&#26684;&#20984;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35777;&#26126;&#30340;PnP&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#36817;&#31471;&#21435;&#22122;&#22120;&#26045;&#21152;&#30456;&#23545;&#36739;&#36731;&#30340;&#26465;&#20214;&#65292;&#24182;&#24341;&#20837;&#20102;&#25311;&#29275;&#39039;&#27493;&#39588;&#20197;&#22823;&#22823;&#21152;&#36895;&#25910;&#25947;&#12290;&#36890;&#36807;&#23558;&#28145;&#24230;&#21435;&#22122;&#22120;&#29305;&#21035;&#21442;&#25968;&#21270;&#20026;&#26799;&#24230;&#27493;&#39588;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;&#25311;&#29275;&#39039;PnP&#31639;&#27861;&#30340;&#22266;&#23450;&#28857;&#34920;&#24449;&#20026;&#21487;&#33021;&#38750;&#20984;&#20989;&#25968;&#30340;&#20020;&#30028;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Plug-and-Play (PnP) methods are a class of efficient iterative methods that aim to combine data fidelity terms and deep denoisers using classical optimization algorithms, such as ISTA or ADMM. Existing provable PnP methods impose heavy restrictions on the denoiser or fidelity function, such as nonexpansiveness or strict convexity. In this work, we propose a provable PnP method that imposes relatively light conditions based on proximal denoisers, and introduce a quasi-Newton step to greatly accelerate convergence. By specially parameterizing the deep denoiser as a gradient step, we further characterize the fixed-points of the quasi-Newton PnP algorithm as critical points of a possibly non-convex function.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;Rashomon&#30340;&#22235;&#37325;&#22863;&#65292;&#36825;&#26159;&#19968;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#26469;&#33258;&#19981;&#21516;&#31867;&#21035;&#30340;&#22235;&#20010;&#27169;&#22411;&#20855;&#26377;&#20960;&#20046;&#30456;&#21516;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#21516;&#26102;&#20854;&#21487;&#35270;&#21270;&#25581;&#31034;&#20102;&#26497;&#20854;&#19981;&#21516;&#30340;&#26041;&#27861;&#26469;&#29702;&#35299;&#25968;&#25454;&#20013;&#30340;&#30456;&#20851;&#24615;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2302.13356</link><description>&lt;p&gt;
&#34920;&#29616;&#19981;&#36275;&#20197;&#20026;&#30408;&#65292;&#28145;&#31350;Rashomon&#30340;&#22235;&#37325;&#22863;
&lt;/p&gt;
&lt;p&gt;
Performance is not enough: a story of the Rashomon's quartet. (arXiv:2302.13356v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.13356
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;Rashomon&#30340;&#22235;&#37325;&#22863;&#65292;&#36825;&#26159;&#19968;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#26469;&#33258;&#19981;&#21516;&#31867;&#21035;&#30340;&#22235;&#20010;&#27169;&#22411;&#20855;&#26377;&#20960;&#20046;&#30456;&#21516;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#21516;&#26102;&#20854;&#21487;&#35270;&#21270;&#25581;&#31034;&#20102;&#26497;&#20854;&#19981;&#21516;&#30340;&#26041;&#27861;&#26469;&#29702;&#35299;&#25968;&#25454;&#20013;&#30340;&#30456;&#20851;&#24615;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#24314;&#27169;&#36890;&#24120;&#34987;&#31616;&#21270;&#20026;&#23547;&#25214;&#26368;&#20248;&#27169;&#22411;&#26469;&#20248;&#21270;&#36873;&#23450;&#30340;&#24615;&#33021;&#24230;&#37327;&#12290;&#20294;&#22914;&#26524;&#31532;&#20108;&#20248;&#27169;&#22411;&#33021;&#22815;&#20197;&#23436;&#20840;&#19981;&#21516;&#30340;&#26041;&#24335;&#21516;&#26679;&#25551;&#36848;&#25968;&#25454;&#21602;&#65311;&#31532;&#19977;&#20010;&#27169;&#22411;&#21602;&#65311;&#26368;&#26377;&#25928;&#30340;&#27169;&#22411;&#20250;&#23398;&#21040;&#23436;&#20840;&#19981;&#21516;&#30340;&#25968;&#25454;&#20851;&#31995;&#21527;&#65311;&#21463;&#21040;Anscombe&#22235;&#37325;&#22863;&#30340;&#21551;&#21457;&#65292;&#26412;&#25991;&#20171;&#32461;&#20102;Rashomon&#30340;&#22235;&#37325;&#22863;&#65292;&#36825;&#26159;&#19968;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#26469;&#33258;&#19981;&#21516;&#31867;&#21035;&#30340;&#22235;&#20010;&#27169;&#22411;&#20855;&#26377;&#20960;&#20046;&#30456;&#21516;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#21487;&#35270;&#21270;&#25581;&#31034;&#20102;&#26497;&#20854;&#19981;&#21516;&#30340;&#26041;&#27861;&#26469;&#29702;&#35299;&#25968;&#25454;&#20013;&#30340;&#30456;&#20851;&#24615;&#32467;&#26500;&#12290;&#24341;&#20837;&#30340;&#31616;&#21333;&#31034;&#20363;&#26088;&#22312;&#36827;&#19968;&#27493;&#20419;&#36827;&#21487;&#35270;&#21270;&#20316;&#20026;&#27604;&#36739;&#39044;&#27979;&#27169;&#22411;&#36229;&#36234;&#24615;&#33021;&#30340;&#24517;&#35201;&#24037;&#20855;&#12290;&#25105;&#20204;&#38656;&#35201;&#24320;&#21457;&#23500;&#26377;&#27934;&#23519;&#21147;&#30340;&#25216;&#26415;&#26469;&#35299;&#37322;&#27169;&#22411;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Predictive modelling is often reduced to finding the best model that optimizes a selected performance measure. But what if the second-best model describes the data equally well but in a completely different way? What about the third? Is it possible that the most effective models learn completely different relationships in the data? Inspired by Anscombe's quartet, this paper introduces Rashomon's quartet, a synthetic dataset for which four models from different classes have practically identical predictive performance. However, their visualization reveals drastically distinct ways of understanding the correlation structure in data. The introduced simple illustrative example aims to further facilitate visualization as a mandatory tool to compare predictive models beyond their performance. We need to develop insightful techniques for the explanatory analysis of model sets.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#22312;&#20855;&#26377;&#37325;&#23614;&#22122;&#22768;&#30340;&#38750;&#20984;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#20013;&#65292;&#25913;&#36827;&#20102;Cutkosky&#21644;Mehta&#30340;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#36817;&#20046;&#26368;&#20248;&#30340;&#25910;&#25947;&#20445;&#35777;&#65292;&#32780;&#26080;&#38656;&#23545;&#38543;&#26426;&#26799;&#24230;&#30340;&#30697;&#26465;&#20214;&#36827;&#34892;&#39069;&#22806;&#30340;&#20551;&#35774;&#12290;</title><link>http://arxiv.org/abs/2302.06763</link><description>&lt;p&gt;
&#20197;(&#23567;)&#32467;&#26500;&#31361;&#30772;&#19979;&#30028;&#65306;&#20855;&#26377;&#37325;&#23614;&#22122;&#22768;&#30340;&#38750;&#20984;&#38543;&#26426;&#20248;&#21270;&#20013;&#30340;&#21152;&#36895;&#12290;(arXiv:2302.06763v2 [cs.LG] &#26356;&#26032;)
&lt;/p&gt;
&lt;p&gt;
Breaking the Lower Bound with (Little) Structure: Acceleration in Non-Convex Stochastic Optimization with Heavy-Tailed Noise. (arXiv:2302.06763v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06763
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#22312;&#20855;&#26377;&#37325;&#23614;&#22122;&#22768;&#30340;&#38750;&#20984;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#20013;&#65292;&#25913;&#36827;&#20102;Cutkosky&#21644;Mehta&#30340;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#36817;&#20046;&#26368;&#20248;&#30340;&#25910;&#25947;&#20445;&#35777;&#65292;&#32780;&#26080;&#38656;&#23545;&#38543;&#26426;&#26799;&#24230;&#30340;&#30697;&#26465;&#20214;&#36827;&#34892;&#39069;&#22806;&#30340;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#37325;&#23614;&#22122;&#22768;&#21306;&#22495;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20855;&#26377;&#24179;&#28369;&#20294;&#19981;&#19968;&#23450;&#26159;&#20984;&#30446;&#26631;&#30340;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#20551;&#35774;&#38543;&#26426;&#26799;&#24230;&#30340;&#22122;&#22768;&#20855;&#26377;&#26377;&#30028;&#30340;$p$&#38454;&#30697;($p\in(1,2]$)&#12290;Zhang&#31561;&#20154;(2020)&#39318;&#27425;&#35777;&#26126;&#20102;&#25910;&#25947;&#30340;$\Omega(T^{\frac{1-p}{3p-2}})$&#19979;&#30028;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#21098;&#20999;&#31639;&#27861;&#65292;&#20197;&#21305;&#37197;&#36825;&#20010;&#26368;&#20248;&#36895;&#29575;&#12290;Cutkosky&#21644;Mehta(2021)&#25552;&#20986;&#20102;&#21478;&#19968;&#31181;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#34987;&#35777;&#26126;&#33021;&#22815;&#23454;&#29616;&#36817;&#20046;&#26368;&#20248;&#30340;&#39640;&#27010;&#29575;&#25910;&#25947;&#20445;&#35777;$O(\log(T/\delta)T^{\frac{1-p}{3p-2}})$&#65292;&#20854;&#20013;$\delta$&#26159;&#22833;&#36133;&#30340;&#27010;&#29575;&#12290;&#28982;&#32780;&#65292;&#36825;&#20010;&#29702;&#24819;&#30340;&#20445;&#35777;&#21482;&#22312;&#38468;&#21152;&#30340;&#20551;&#35774;&#19979;&#25104;&#31435;&#65292;&#21363;&#38543;&#26426;&#26799;&#24230;&#26412;&#36523;&#22312;$p$&#38454;&#30697;&#19978;&#26377;&#30028;&#65292;&#32780;&#21363;&#20351;&#23545;&#20110;&#20108;&#27425;&#30446;&#26631;&#21644;&#20013;&#24515;&#21270;&#30340;&#39640;&#26031;&#22122;&#22768;&#65292;&#36825;&#20010;&#20551;&#35774;&#20063;&#19981;&#25104;&#31435;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#25913;&#36827;&#20102;Cutkosky&#21644;Mehta(2021)&#20013;&#31639;&#27861;&#30340;&#20998;&#26512;&#65292;&#20197;&#33719;&#24471;&#30456;&#21516;&#30340;&#36817;&#20046;&#26368;&#20248;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the stochastic optimization problem with smooth but not necessarily convex objectives in the heavy-tailed noise regime, where the stochastic gradient's noise is assumed to have bounded $p$th moment ($p\in(1,2]$). Zhang et al. (2020) is the first to prove the $\Omega(T^{\frac{1-p}{3p-2}})$ lower bound for convergence (in expectation) and provides a simple clipping algorithm that matches this optimal rate. Cutkosky and Mehta (2021) proposes another algorithm, which is shown to achieve the nearly optimal high-probability convergence guarantee $O(\log(T/\delta)T^{\frac{1-p}{3p-2}})$, where $\delta$ is the probability of failure. However, this desirable guarantee is only established under the additional assumption that the stochastic gradient itself is bounded in $p$th moment, which fails to hold even for quadratic objectives and centered Gaussian noise.  In this work, we first improve the analysis of the algorithm in Cutkosky and Mehta (2021) to obtain the same nearly optimal h
&lt;/p&gt;</description></item><item><title>Distributional Random Forests&#31639;&#27861;&#36890;&#36807;&#23545;&#26465;&#20214;&#20998;&#24067;&#36827;&#34892;&#20272;&#35745;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#37327;&#21270;&#26631;&#20934;&#35823;&#24046;&#21644;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#30340;&#25512;&#29702;&#24037;&#20855;&#65292;&#29992;&#20110;&#20272;&#35745;&#22810;&#21464;&#37327;&#26465;&#20214;&#20998;&#24067;&#21644;&#27979;&#35797;&#19981;&#21516;&#32676;&#20307;&#20043;&#38388;&#30340;&#20998;&#24067;&#24046;&#24322;&#12290;</title><link>http://arxiv.org/abs/2302.05761</link><description>&lt;p&gt;
Distributional Random Forests &#30340;&#32622;&#20449;&#24230;&#21644;&#19981;&#30830;&#23450;&#24615;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Confidence and Uncertainty Assessment for Distributional Random Forests. (arXiv:2302.05761v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05761
&lt;/p&gt;
&lt;p&gt;
Distributional Random Forests&#31639;&#27861;&#36890;&#36807;&#23545;&#26465;&#20214;&#20998;&#24067;&#36827;&#34892;&#20272;&#35745;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#37327;&#21270;&#26631;&#20934;&#35823;&#24046;&#21644;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#30340;&#25512;&#29702;&#24037;&#20855;&#65292;&#29992;&#20110;&#20272;&#35745;&#22810;&#21464;&#37327;&#26465;&#20214;&#20998;&#24067;&#21644;&#27979;&#35797;&#19981;&#21516;&#32676;&#20307;&#20043;&#38388;&#30340;&#20998;&#24067;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Distributional Random Forest (DRF) &#26159;&#19968;&#31181;&#26368;&#36817;&#24341;&#20837;&#30340;&#38543;&#26426;&#26862;&#26519;&#31639;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#22810;&#21464;&#37327;&#26465;&#20214;&#20998;&#24067;&#12290;&#30001;&#20110;&#20854;&#36890;&#29992;&#30340;&#20272;&#35745;&#36807;&#31243;&#65292;&#21487;&#20197;&#29992;&#26469;&#20272;&#35745;&#21508;&#31181;&#30446;&#26631;&#65292;&#22914;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#12289;&#26465;&#20214;&#20998;&#20301;&#25968;&#21644;&#26465;&#20214;&#30456;&#20851;&#24615;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#21482;&#26377;&#20851;&#20110;DRF&#39044;&#27979;&#30340;&#19968;&#33268;&#24615;&#21644;&#25910;&#25947;&#36895;&#29575;&#30340;&#32467;&#26524;&#21487;&#29992;&#12290;&#25105;&#20204;&#23545;DRF&#30340;&#28176;&#36817;&#20998;&#24067;&#36827;&#34892;&#20102;&#34920;&#24449;&#65292;&#24182;&#24320;&#21457;&#20102;&#20854;&#30340;&#33258;&#21161;&#27861;&#36817;&#20284;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#25512;&#23548;&#20986;&#29992;&#20110;&#37327;&#21270;&#26631;&#20934;&#35823;&#24046;&#21644;&#26500;&#24314;&#28176;&#36827;&#35206;&#30422;&#20445;&#35777;&#30340;&#32622;&#20449;&#21306;&#38388;&#30340;&#25512;&#29702;&#24037;&#20855;&#12290;&#22312;&#27169;&#25311;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#32463;&#39564;&#35777;&#26126;&#20102;&#35813;&#29702;&#35770;&#23545;&#20110;&#20302;&#32500;&#30446;&#26631;&#30340;&#25512;&#29702;&#21644;&#27979;&#35797;&#20004;&#20010;&#32676;&#20307;&#20043;&#38388;&#30340;&#20998;&#24067;&#24046;&#24322;&#26159;&#26377;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Distributional Random Forest (DRF) is a recently introduced Random Forest algorithm to estimate multivariate conditional distributions. Due to its general estimation procedure, it can be employed to estimate a wide range of targets such as conditional average treatment effects, conditional quantiles, and conditional correlations. However, only results about the consistency and convergence rate of the DRF prediction are available so far. We characterize the asymptotic distribution of DRF and develop a bootstrap approximation of it. This allows us to derive inferential tools for quantifying standard errors and the construction of confidence regions that have asymptotic coverage guarantees. In simulation studies, we empirically validate the developed theory for inference of low-dimensional targets and for testing distributional differences between two populations.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#39318;&#27425;&#35780;&#20272;&#20102;&#22312;&#26080;&#38480;&#26102;&#38388;&#33539;&#22260;&#20869;&#30340;&#21160;&#24577;&#20013;&#20171;&#25928;&#24212;&#65292;&#24182;&#24320;&#21457;&#20102;&#40065;&#26834;&#21644;&#21322;&#21442;&#25968;&#26377;&#25928;&#30340;&#20272;&#35745;&#26041;&#27861;&#26469;&#25512;&#26029;&#36825;&#20123;&#22240;&#26524;&#25928;&#24212;&#12290;</title><link>http://arxiv.org/abs/2301.13348</link><description>&lt;p&gt;
&#19968;&#20010;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#29992;&#20110;&#21160;&#24577;&#20013;&#20171;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A Reinforcement Learning Framework for Dynamic Mediation Analysis. (arXiv:2301.13348v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13348
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#39318;&#27425;&#35780;&#20272;&#20102;&#22312;&#26080;&#38480;&#26102;&#38388;&#33539;&#22260;&#20869;&#30340;&#21160;&#24577;&#20013;&#20171;&#25928;&#24212;&#65292;&#24182;&#24320;&#21457;&#20102;&#40065;&#26834;&#21644;&#21322;&#21442;&#25968;&#26377;&#25928;&#30340;&#20272;&#35745;&#26041;&#27861;&#26469;&#25512;&#26029;&#36825;&#20123;&#22240;&#26524;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20013;&#20171;&#20998;&#26512;&#36890;&#36807;&#23398;&#20064;&#20171;&#23548;&#21464;&#37327;&#22312;&#27835;&#30103;&#21644;&#32467;&#26524;&#20043;&#38388;&#20256;&#36882;&#30340;&#22240;&#26524;&#25928;&#24212;&#65292;&#22312;&#21508;&#20010;&#31185;&#23398;&#39046;&#22495;&#20013;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#65292;&#20197;&#38416;&#26126;&#22240;&#26524;&#20851;&#31995;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#30740;&#31350;&#38598;&#20013;&#22312;&#28857;&#26292;&#38706;&#30740;&#31350;&#20013;&#65292;&#20854;&#20013;&#27599;&#20010;&#21463;&#35797;&#32773;&#21482;&#22312;&#19968;&#20010;&#26102;&#38388;&#28857;&#25509;&#21463;&#19968;&#31181;&#27835;&#30103;&#12290;&#28982;&#32780;&#65292;&#26377;&#35768;&#22810;&#24212;&#29992;&#65288;&#20363;&#22914;&#31227;&#21160;&#20581;&#24247;&#65289;&#22312;&#36825;&#20123;&#24212;&#29992;&#20013;&#65292;&#27835;&#30103;&#26159;&#25353;&#39034;&#24207;&#20998;&#37197;&#30340;&#65292;&#21160;&#24577;&#20013;&#20171;&#25928;&#24212;&#26159;&#20027;&#35201;&#20851;&#27880;&#30340;&#23545;&#35937;&#12290;&#36890;&#36807;&#25552;&#20986;&#19968;&#20010;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#26694;&#26550;&#65292;&#25105;&#20204;&#39318;&#27425;&#35780;&#20272;&#22312;&#26080;&#38480;&#26102;&#38388;&#33539;&#22260;&#20869;&#30340;&#21160;&#24577;&#20013;&#20171;&#25928;&#24212;&#12290;&#25105;&#20204;&#23558;&#24179;&#22343;&#27835;&#30103;&#25928;&#24212;&#20998;&#35299;&#20026;&#30452;&#25509;&#25928;&#24212;&#12289;&#20013;&#20171;&#25928;&#24212;&#12289;&#24310;&#36831;&#30452;&#25509;&#25928;&#24212;&#21644;&#24310;&#36831;&#20013;&#20171;&#25928;&#24212;&#12290;&#22312;&#30830;&#23450;&#27599;&#20010;&#25928;&#24212;&#25104;&#20998;&#21518;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#22312;RL&#26694;&#26550;&#19979;&#24320;&#21457;&#40065;&#26834;&#21644;&#21322;&#21442;&#25968;&#26377;&#25928;&#30340;&#20272;&#35745;&#22120;&#26469;&#25512;&#26029;&#36825;&#20123;&#22240;&#26524;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mediation analysis learns the causal effect transmitted via mediator variables between treatments and outcomes and receives increasing attention in various scientific domains to elucidate causal relations. Most existing works focus on point-exposure studies where each subject only receives one treatment at a single time point. However, there are a number of applications (e.g., mobile health) where the treatments are sequentially assigned over time and the dynamic mediation effects are of primary interest. Proposing a reinforcement learning (RL) framework, we are the first to evaluate dynamic mediation effects in settings with infinite horizons. We decompose the average treatment effect into an immediate direct effect, an immediate mediation effect, a delayed direct effect, and a delayed mediation effect. Upon the identification of each effect component, we further develop robust and semi-parametrically efficient estimators under the RL framework to infer these causal effects. The super
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#27979;&#35797;&#23545;&#25968;&#20284;&#28982;&#36827;&#34892;&#27604;&#36739;&#21487;&#33021;&#19982;&#20854;&#20182;&#25351;&#26631;&#30456;&#30683;&#30462;&#65292;&#24182;&#19988;&#39640;&#27979;&#35797;&#23545;&#25968;&#20284;&#28982;&#19981;&#24847;&#21619;&#30528;&#26356;&#20934;&#30830;&#30340;&#21518;&#39564;&#36817;&#20284;&#12290;</title><link>http://arxiv.org/abs/2212.00219</link><description>&lt;p&gt;
&#20320;&#26159;&#21542;&#27491;&#30830;&#20351;&#29992;&#20102;&#27979;&#35797;&#23545;&#25968;&#20284;&#28982;&#65311;
&lt;/p&gt;
&lt;p&gt;
Are you using test log-likelihood correctly?. (arXiv:2212.00219v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.00219
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#27979;&#35797;&#23545;&#25968;&#20284;&#28982;&#36827;&#34892;&#27604;&#36739;&#21487;&#33021;&#19982;&#20854;&#20182;&#25351;&#26631;&#30456;&#30683;&#30462;&#65292;&#24182;&#19988;&#39640;&#27979;&#35797;&#23545;&#25968;&#20284;&#28982;&#19981;&#24847;&#21619;&#30528;&#26356;&#20934;&#30830;&#30340;&#21518;&#39564;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27979;&#35797;&#23545;&#25968;&#20284;&#28982;&#24120;&#34987;&#29992;&#26469;&#27604;&#36739;&#19981;&#21516;&#27169;&#22411;&#30340;&#21516;&#19968;&#25968;&#25454;&#65292;&#25110;&#32773;&#27604;&#36739;&#25311;&#21512;&#21516;&#19968;&#27010;&#29575;&#27169;&#22411;&#30340;&#19981;&#21516;&#36817;&#20284;&#25512;&#26029;&#31639;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#31616;&#21333;&#30340;&#20363;&#23376;&#23637;&#31034;&#20102;&#22914;&#20309;&#22522;&#20110;&#27979;&#35797;&#23545;&#25968;&#20284;&#28982;&#30340;&#27604;&#36739;&#21487;&#33021;&#19982;&#20854;&#20182;&#30446;&#26631;&#30456;&#30683;&#30462;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#20363;&#23376;&#34920;&#26126;&#65306;&#65288;i&#65289;&#36798;&#21040;&#26356;&#39640;&#27979;&#35797;&#23545;&#25968;&#20284;&#28982;&#30340;&#36817;&#20284;&#36125;&#21494;&#26031;&#25512;&#26029;&#31639;&#27861;&#19981;&#24517;&#24847;&#21619;&#30528;&#33021;&#22815;&#20135;&#29983;&#26356;&#20934;&#30830;&#30340;&#21518;&#39564;&#36817;&#20284;&#65292;&#65288;ii&#65289;&#22522;&#20110;&#27979;&#35797;&#23545;&#25968;&#20284;&#28982;&#27604;&#36739;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#32467;&#35770;&#21487;&#33021;&#19982;&#22522;&#20110;&#22343;&#26041;&#26681;&#35823;&#24046;&#30340;&#32467;&#35770;&#19981;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
Test log-likelihood is commonly used to compare different models of the same data or different approximate inference algorithms for fitting the same probabilistic model. We present simple examples demonstrating how comparisons based on test log-likelihood can contradict comparisons according to other objectives. Specifically, our examples show that (i) approximate Bayesian inference algorithms that attain higher test log-likelihoods need not also yield more accurate posterior approximations and (ii) conclusions about forecast accuracy based on test log-likelihood comparisons may not agree with conclusions based on root mean squared error.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;PAC&#39564;&#35777;&#30340;&#27010;&#24565;&#65292;&#24182;&#22312;&#19977;&#20010;&#26041;&#38754;&#36827;&#34892;&#20102;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#65306;&#23545;&#20110;VC&#32500;&#24230;&#20026;$d$&#30340;&#20551;&#35774;&#31867;&#65292;PAC&#39564;&#35777;&#38656;&#35201;$\Omega\left(\sqrt{d}/\varepsilon^2\right)$&#20010;i.i.d.&#26679;&#26412;&#30340;&#19979;&#30028;&#65307;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39564;&#35777;&#23454;&#25968;&#21306;&#38388;&#30340;&#24182;&#38598;&#30340;&#21327;&#35758;&#65292;&#24182;&#19982;&#19979;&#30028;&#23545;$d$&#30340;&#20381;&#36182;&#30456;&#21305;&#37197;&#65307;&#23558;PAC&#39564;&#35777;&#30340;&#23450;&#20041;&#25512;&#24191;&#21040;&#23545;&#19968;&#33324;&#32479;&#35745;&#31639;&#27861;&#30340;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2211.17096</link><description>&lt;p&gt;
&#32479;&#35745;&#31639;&#27861;&#30340;PAC&#39564;&#35777;
&lt;/p&gt;
&lt;p&gt;
PAC Verification of Statistical Algorithms. (arXiv:2211.17096v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.17096
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;PAC&#39564;&#35777;&#30340;&#27010;&#24565;&#65292;&#24182;&#22312;&#19977;&#20010;&#26041;&#38754;&#36827;&#34892;&#20102;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#65306;&#23545;&#20110;VC&#32500;&#24230;&#20026;$d$&#30340;&#20551;&#35774;&#31867;&#65292;PAC&#39564;&#35777;&#38656;&#35201;$\Omega\left(\sqrt{d}/\varepsilon^2\right)$&#20010;i.i.d.&#26679;&#26412;&#30340;&#19979;&#30028;&#65307;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39564;&#35777;&#23454;&#25968;&#21306;&#38388;&#30340;&#24182;&#38598;&#30340;&#21327;&#35758;&#65292;&#24182;&#19982;&#19979;&#30028;&#23545;$d$&#30340;&#20381;&#36182;&#30456;&#21305;&#37197;&#65307;&#23558;PAC&#39564;&#35777;&#30340;&#23450;&#20041;&#25512;&#24191;&#21040;&#23545;&#19968;&#33324;&#32479;&#35745;&#31639;&#27861;&#30340;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Goldwasser&#31561;&#20154;&#65288;2021&#65289;&#26368;&#36817;&#25552;&#20986;&#20102;PAC&#39564;&#35777;&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;&#20351;&#29992;&#20132;&#20114;&#24335;&#35777;&#26126;&#26469;&#39564;&#35777;&#20551;&#35774;&#65288;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65289;&#65292;&#35813;&#27169;&#22411;&#22768;&#31216;&#28385;&#36275;&#26080;&#30693;PAC&#23398;&#20064;&#30446;&#26631;&#12290;&#26412;&#25991;&#22312;&#22810;&#20010;&#26041;&#38754;&#36827;&#19968;&#27493;&#21457;&#23637;&#20102;&#36825;&#20010;&#27010;&#24565;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;VC&#32500;&#24230;&#20026;$d$&#30340;&#20551;&#35774;&#31867;&#65292;PAC&#39564;&#35777;&#38656;&#35201;$\Omega\left(\sqrt{d}/\varepsilon^2\right)$&#20010;i.i.d.&#26679;&#26412;&#30340;&#19979;&#30028;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;PAC&#39564;&#35777;&#23454;&#25968;&#21306;&#38388;&#30340;&#24182;&#38598;&#30340;&#21327;&#35758;&#65292;&#35813;&#21327;&#35758;&#25913;&#36827;&#20102;&#20182;&#20204;&#25552;&#20986;&#30340;&#21327;&#35758;&#65292;&#24182;&#19982;&#25105;&#20204;&#30340;&#19979;&#30028;&#23545;$d$&#30340;&#20381;&#36182;&#30456;&#21305;&#37197;&#12290;&#31532;&#19977;&#65292;&#25105;&#20204;&#23558;&#20182;&#20204;&#30340;&#23450;&#20041;&#33258;&#28982;&#25512;&#24191;&#21040;&#20102;&#23545;&#19968;&#33324;&#32479;&#35745;&#31639;&#27861;&#30340;&#39564;&#35777;&#65292;&#36825;&#36866;&#29992;&#20110;&#26356;&#24191;&#27867;&#30340;&#39046;&#22495;&#65292;&#36229;&#20986;&#20102;&#26080;&#30693;PAC&#23398;&#20064;&#30340;&#33539;&#30068;&#12290;&#36890;&#36807;&#23637;&#31034;&#25105;&#20204;&#25552;&#20986;&#30340;&#23450;&#20041;&#65292;&#25105;&#20204;&#30340;&#26368;&#32456;&#32467;&#26524;&#26159;&#19968;&#31181;&#39564;&#35777;&#20855;&#26377;&#32452;&#21512;&#32422;&#26463;&#30340;&#32479;&#35745;&#26597;&#35810;&#31639;&#27861;&#30340;&#21327;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
Goldwasser et al. (2021) recently proposed the setting of PAC verification, where a hypothesis (machine learning model) that purportedly satisfies the agnostic PAC learning objective is verified using an interactive proof. In this paper we develop this notion further in a number of ways. First, we prove a lower bound of $\Omega\left(\sqrt{d}/\varepsilon^2\right)$ i.i.d.\ samples for PAC verification of hypothesis classes of VC dimension $d$. Second, we present a protocol for PAC verification of unions of intervals over $\mathbb{R}$ that improves upon their proposed protocol for that task, and matches our lower bound's dependence on $d$. Third, we introduce a natural generalization of their definition to verification of general statistical algorithms, which is applicable to a wider variety of settings beyond agnostic PAC learning. Showcasing our proposed definition, our final result is a protocol for the verification of statistical query algorithms that satisfy a combinatorial constrain
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#24212;&#29992;&#26426;&#22120;&#23398;&#20064;&#23545;&#33647;&#29289;&#21160;&#21147;&#23398;&#26354;&#32447;&#36827;&#34892;&#32858;&#31867;&#30340;&#26041;&#27861;&#65292;&#21457;&#29616;&#32858;&#31867;&#33021;&#22815;&#26377;&#25928;&#22320;&#35782;&#21035;&#30456;&#20284;&#24418;&#29366;&#30340;&#33647;&#29289;&#21160;&#21147;&#23398;&#26354;&#32447;&#24182;&#29702;&#35299;&#27599;&#20010;&#32858;&#31867;&#20013;&#30340;&#27169;&#24335;&#65292;&#20026;&#33647;&#29289;&#30740;&#21457;&#21644;&#33647;&#29289;&#27835;&#30103;&#36807;&#31243;&#25552;&#20379;&#20102;&#26032;&#30340;&#25216;&#26415;&#25903;&#25345;&#12290;</title><link>http://arxiv.org/abs/2210.13310</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#22312;&#33647;&#29289;&#22522;&#22240;&#32452;&#23398;&#20013;&#30340;&#24212;&#29992;&#65306;&#34880;&#27974;&#27987;&#24230;-&#26102;&#38388;&#26354;&#32447;&#30340;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Applications of Machine Learning in Pharmacogenomics: Clustering Plasma Concentration-Time Curves. (arXiv:2210.13310v2 [stat.AP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.13310
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#24212;&#29992;&#26426;&#22120;&#23398;&#20064;&#23545;&#33647;&#29289;&#21160;&#21147;&#23398;&#26354;&#32447;&#36827;&#34892;&#32858;&#31867;&#30340;&#26041;&#27861;&#65292;&#21457;&#29616;&#32858;&#31867;&#33021;&#22815;&#26377;&#25928;&#22320;&#35782;&#21035;&#30456;&#20284;&#24418;&#29366;&#30340;&#33647;&#29289;&#21160;&#21147;&#23398;&#26354;&#32447;&#24182;&#29702;&#35299;&#27599;&#20010;&#32858;&#31867;&#20013;&#30340;&#27169;&#24335;&#65292;&#20026;&#33647;&#29289;&#30740;&#21457;&#21644;&#33647;&#29289;&#27835;&#30103;&#36807;&#31243;&#25552;&#20379;&#20102;&#26032;&#30340;&#25216;&#26415;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21046;&#33647;&#30740;&#31350;&#20154;&#21592;&#19981;&#26029;&#23547;&#27714;&#25216;&#26415;&#25913;&#36827;&#33647;&#29289;&#24320;&#21457;&#36807;&#31243;&#21644;&#24739;&#32773;&#39044;&#21518;&#30340;&#26041;&#27861;&#12290;&#26368;&#36817;&#19968;&#20010;&#21463;&#21040;&#20851;&#27880;&#30340;&#39046;&#22495;&#26159;&#26426;&#22120;&#23398;&#20064;&#22312;&#33647;&#29702;&#23398;&#20013;&#30340;&#28508;&#22312;&#24212;&#29992;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#22914;&#20309;&#36890;&#36807;&#30456;&#20284;&#24615;&#23545;&#34880;&#27974;&#27987;&#24230;-&#26102;&#38388;&#26354;&#32447;&#65288;&#33647;&#29289;&#21160;&#21147;&#23398;&#26354;&#32447;&#65289;&#36827;&#34892;&#32858;&#31867;&#30340;&#21457;&#29616;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#21457;&#29616;&#32858;&#31867;&#23545;&#20110;&#35782;&#21035;&#30456;&#20284;&#24418;&#29366;&#30340;&#33647;&#29289;&#21160;&#21147;&#23398;&#26354;&#32447;&#20197;&#21450;&#29702;&#35299;&#27599;&#20010;&#32858;&#31867;&#20869;&#30340;&#27169;&#24335;&#38750;&#24120;&#26377;&#25928;&#12290;&#30001;&#20110;&#33647;&#29289;&#21160;&#21147;&#23398;&#26354;&#32447;&#26159;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#23545;&#35937;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20102;&#19982;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#32858;&#31867;&#30456;&#20851;&#30340;&#22823;&#37327;&#30740;&#31350;&#20316;&#20026;&#36215;&#28857;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#26816;&#26597;&#20102;&#35768;&#22810;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#23545;&#35937;&#20043;&#38388;&#30340;&#19981;&#30456;&#20284;&#24230;&#24230;&#37327;&#65292;&#20197;&#25214;&#21040;&#26368;&#36866;&#21512;&#33647;&#29289;&#21160;&#21147;&#23398;&#26354;&#32447;&#30340;&#24230;&#37327;&#12290;&#25105;&#20204;&#30830;&#23450;&#27431;&#20960;&#37324;&#24503;&#36317;&#31163;&#36890;&#24120;&#26159;&#26368;&#36866;&#21512;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pharmaceutical researchers are continually searching for techniques to improve both drug development processes and patient outcomes. An area of recent interest is the potential for machine learning (ML) applications within pharmacology. One such application not yet given close study is the unsupervised clustering of plasma concentration-time curves, hereafter, pharmacokinetic (PK) curves. In this paper, we present our findings on how to cluster PK curves by their similarity. Specifically, we find clustering to be effective at identifying similar-shaped PK curves and informative for understanding patterns within each cluster of PK curves. Because PK curves are time series data objects, our approach utilizes the extensive body of research related to the clustering of time series data as a starting point. As such, we examine many dissimilarity measures between time series data objects to find those most suitable for PK curves. We identify Euclidean distance as generally most appropriate f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24322;&#24120;&#40065;&#26834;&#31232;&#30095;&#20272;&#35745;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#32447;&#24615;&#22238;&#24402;&#31995;&#25968;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#24050;&#30693;&#25110;&#26410;&#30693;&#30340;&#24773;&#20917;&#19979;&#65292;&#20855;&#26377;&#36739;&#23574;&#38160;&#30340;&#35823;&#24046;&#30028;&#65292;&#36866;&#29992;&#20110;&#37319;&#26679;&#33258;$\mathfrak{L}$-subGaussian&#20998;&#24067;&#21644;&#37325;&#23614;&#20998;&#24067;&#30340;&#21327;&#21464;&#37327;&#21521;&#37327;&#21644;&#22122;&#22768;&#12290;</title><link>http://arxiv.org/abs/2208.11592</link><description>&lt;p&gt;
&#32447;&#24615;&#22238;&#24402;&#31995;&#25968;&#30340;&#24322;&#24120;&#40065;&#26834;&#31232;&#30095;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Outlier Robust and Sparse Estimation of Linear Regression Coefficients. (arXiv:2208.11592v3 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.11592
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#24322;&#24120;&#40065;&#26834;&#31232;&#30095;&#20272;&#35745;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#32447;&#24615;&#22238;&#24402;&#31995;&#25968;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#24050;&#30693;&#25110;&#26410;&#30693;&#30340;&#24773;&#20917;&#19979;&#65292;&#20855;&#26377;&#36739;&#23574;&#38160;&#30340;&#35823;&#24046;&#30028;&#65292;&#36866;&#29992;&#20110;&#37319;&#26679;&#33258;$\mathfrak{L}$-subGaussian&#20998;&#24067;&#21644;&#37325;&#23614;&#20998;&#24067;&#30340;&#21327;&#21464;&#37327;&#21521;&#37327;&#21644;&#22122;&#22768;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#24403;&#21327;&#21464;&#37327;&#21521;&#37327;&#21644;&#22122;&#22768;&#20998;&#21035;&#20174;$\mathfrak{L}$-subGaussian&#20998;&#24067;&#21644;&#37325;&#23614;&#20998;&#24067;&#20013;&#38543;&#26426;&#37319;&#26679;&#26102;&#65292;&#23545;&#32447;&#24615;&#22238;&#24402;&#31995;&#25968;&#36827;&#34892;&#24322;&#24120;&#40065;&#26834;&#31232;&#30095;&#20272;&#35745;&#12290;&#27492;&#22806;&#65292;&#21327;&#21464;&#37327;&#21521;&#37327;&#21644;&#22122;&#22768;&#21463;&#21040;&#23545;&#25239;&#24615;&#24322;&#24120;&#20540;&#30340;&#27745;&#26579;&#12290;&#25105;&#20204;&#22788;&#29702;&#20004;&#31181;&#24773;&#20917;&#65306;&#21327;&#21464;&#37327;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#24050;&#30693;&#25110;&#26410;&#30693;&#12290;&#29305;&#21035;&#22320;&#65292;&#22312;&#24050;&#30693;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#21487;&#20197;&#36798;&#21040;&#36817;&#20284;&#20449;&#24687;&#29702;&#35770;&#26368;&#20248;&#30340;&#35823;&#24046;&#30028;&#65292;&#19988;&#25105;&#20204;&#30340;&#35823;&#24046;&#30028;&#27604;&#26089;&#26399;&#22788;&#29702;&#31867;&#20284;&#24773;&#20917;&#30340;&#30740;&#31350;&#26356;&#21152;&#23574;&#38160;&#12290;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#20998;&#26512;&#22312;&#25512;&#23548;&#23574;&#38160;&#30340;&#35823;&#24046;&#30028;&#26041;&#38754;&#20005;&#37325;&#20381;&#36182;&#20110;&#36890;&#29992;&#38142;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider outlier-robust and sparse estimation of linear regression coefficients, when covariate vectors and noises are sampled, respectively, from an $\mathfrak{L}$-subGaussian distribution and a heavy-tailed distribution. Additionally, the covariate vectors and noises are contaminated by adversarial outliers. We deal with two cases: the covariance matrix of the covariates is known or unknown. Particularly, in the known case, our estimator can attain a nearly information theoretical optimal error bound, and our error bound is sharper than those of earlier studies dealing with similar situations. Our estimator analysis relies heavily on generic chaining to derive sharp error bounds.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#24320;&#21457;&#20102;&#22686;&#24191;&#36870;&#27010;&#29575;&#21152;&#26435;&#65288;AIPW&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#20351;&#29992;&#35266;&#27979;&#32593;&#32476;&#25968;&#25454;&#20272;&#35745;&#21644;&#25512;&#26029;&#20855;&#26377;&#28322;&#20986;&#25928;&#24212;&#30340;&#27835;&#30103;&#30340;&#30452;&#25509;&#25928;&#24212;&#12290;&#26041;&#27861;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#21644;&#26679;&#26412;&#20998;&#21106;&#65292;&#24471;&#21040;&#25910;&#25947;&#36895;&#24230;&#36739;&#24555;&#19988;&#26381;&#20174;&#39640;&#26031;&#20998;&#24067;&#30340;&#21322;&#21442;&#25968;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#22120;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#32771;&#34385;&#23398;&#29983;&#31038;&#20132;&#32593;&#32476;&#30340;&#24773;&#20917;&#19979;&#65292;&#23398;&#20064;&#26102;&#38388;&#23545;&#32771;&#35797;&#25104;&#32489;&#26377;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2206.14591</link><description>&lt;p&gt;
&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#22788;&#29702;&#35266;&#27979;&#32593;&#32476;&#25968;&#25454;&#30340;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Treatment Effect Estimation with Observational Network Data using Machine Learning. (arXiv:2206.14591v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.14591
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#24320;&#21457;&#20102;&#22686;&#24191;&#36870;&#27010;&#29575;&#21152;&#26435;&#65288;AIPW&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#20351;&#29992;&#35266;&#27979;&#32593;&#32476;&#25968;&#25454;&#20272;&#35745;&#21644;&#25512;&#26029;&#20855;&#26377;&#28322;&#20986;&#25928;&#24212;&#30340;&#27835;&#30103;&#30340;&#30452;&#25509;&#25928;&#24212;&#12290;&#26041;&#27861;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#21644;&#26679;&#26412;&#20998;&#21106;&#65292;&#24471;&#21040;&#25910;&#25947;&#36895;&#24230;&#36739;&#24555;&#19988;&#26381;&#20174;&#39640;&#26031;&#20998;&#24067;&#30340;&#21322;&#21442;&#25968;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#22120;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#32771;&#34385;&#23398;&#29983;&#31038;&#20132;&#32593;&#32476;&#30340;&#24773;&#20917;&#19979;&#65292;&#23398;&#20064;&#26102;&#38388;&#23545;&#32771;&#35797;&#25104;&#32489;&#26377;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#36890;&#24120;&#20551;&#35774;&#29420;&#31435;&#21333;&#20803;&#26469;&#36827;&#34892;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#20551;&#35774;&#32463;&#24120;&#26159;&#26377;&#38382;&#39064;&#30340;&#65292;&#22240;&#20026;&#21333;&#20803;&#20043;&#38388;&#21487;&#33021;&#20250;&#30456;&#20114;&#20316;&#29992;&#65292;&#23548;&#33268;&#21333;&#20803;&#20043;&#38388;&#30340;&#28322;&#20986;&#25928;&#24212;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#22686;&#24191;&#36870;&#27010;&#29575;&#21152;&#26435;&#65288;AIPW&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#20351;&#29992;&#20855;&#26377;&#28322;&#20986;&#25928;&#24212;&#30340;&#21333;&#20010;&#65288;&#31038;&#20132;&#65289;&#32593;&#32476;&#30340;&#35266;&#27979;&#25968;&#25454;&#23545;&#27835;&#30103;&#30340;&#30452;&#25509;&#25928;&#24212;&#36827;&#34892;&#20272;&#35745;&#21644;&#25512;&#26029;&#12290;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#25554;&#20214;&#30340;&#26426;&#22120;&#23398;&#20064;&#21644;&#26679;&#26412;&#20998;&#21106;&#26041;&#27861;&#65292;&#24471;&#21040;&#19968;&#20010;&#21322;&#21442;&#25968;&#30340;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#22120;&#65292;&#20854;&#28176;&#36817;&#25910;&#25947;&#20110;&#21442;&#25968;&#36895;&#29575;&#65292;&#24182;&#19988;&#22312;&#28176;&#36817;&#24773;&#20917;&#19979;&#26381;&#20174;&#39640;&#26031;&#20998;&#24067;&#12290;&#25105;&#20204;&#23558;AIPW&#26041;&#27861;&#24212;&#29992;&#20110;&#29790;&#22763;&#23398;&#29983;&#20154;&#29983;&#30740;&#31350;&#25968;&#25454;&#65292;&#20197;&#30740;&#31350;&#23398;&#20064;&#26102;&#38388;&#23545;&#32771;&#35797;&#25104;&#32489;&#30340;&#24433;&#21709;&#65292;&#32771;&#34385;&#21040;&#23398;&#29983;&#30340;&#31038;&#20132;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal inference methods for treatment effect estimation usually assume independent units. However, this assumption is often questionable because units may interact, resulting in spillover effects between units. We develop augmented inverse probability weighting (AIPW) for estimation and inference of the direct effect of the treatment with observational data from a single (social) network with spillover effects. We use plugin machine learning and sample splitting to obtain a semiparametric treatment effect estimator that converges at the parametric rate and asymptotically follows a Gaussian distribution. We apply our AIPW method to the Swiss StudentLife Study data to investigate the effect of hours spent studying on exam performance accounting for the students' social network.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#27169;&#22411;&#23545;&#20010;&#20307;&#31034;&#20363;&#30340;&#38544;&#31169;&#20445;&#35777;&#65292;&#24182;&#21457;&#29616;&#22823;&#22810;&#25968;&#31034;&#20363;&#20139;&#26377;&#36739;&#24378;&#30340;&#38544;&#31169;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21457;&#29616;&#35757;&#32451;&#25439;&#22833;&#21644;&#31034;&#20363;&#30340;&#38544;&#31169;&#21442;&#25968;&#23384;&#22312;&#24456;&#24378;&#30340;&#30456;&#20851;&#24615;&#12290;&#26368;&#20302;&#20934;&#30830;&#29575;&#31867;&#21035;&#30340;&#24179;&#22343;&#38544;&#31169;&#21442;&#25968;&#27604;&#26368;&#39640;&#20934;&#30830;&#29575;&#31867;&#21035;&#39640;44.2%&#12290;</title><link>http://arxiv.org/abs/2206.02617</link><description>&lt;p&gt;
&#20010;&#20307;&#38544;&#31169;&#20250;&#35745;&#23545;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Individual Privacy Accounting for Differentially Private Stochastic Gradient Descent. (arXiv:2206.02617v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.02617
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#27169;&#22411;&#23545;&#20010;&#20307;&#31034;&#20363;&#30340;&#38544;&#31169;&#20445;&#35777;&#65292;&#24182;&#21457;&#29616;&#22823;&#22810;&#25968;&#31034;&#20363;&#20139;&#26377;&#36739;&#24378;&#30340;&#38544;&#31169;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21457;&#29616;&#35757;&#32451;&#25439;&#22833;&#21644;&#31034;&#20363;&#30340;&#38544;&#31169;&#21442;&#25968;&#23384;&#22312;&#24456;&#24378;&#30340;&#30456;&#20851;&#24615;&#12290;&#26368;&#20302;&#20934;&#30830;&#29575;&#31867;&#21035;&#30340;&#24179;&#22343;&#38544;&#31169;&#21442;&#25968;&#27604;&#26368;&#39640;&#20934;&#30830;&#29575;&#31867;&#21035;&#39640;44.2%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26159;&#26368;&#36817;&#31169;&#26377;&#28145;&#24230;&#23398;&#20064;&#30340;&#21069;&#27839;&#31639;&#27861;&#12290;&#23427;&#20026;&#25968;&#25454;&#38598;&#20013;&#30340;&#25152;&#26377;&#25968;&#25454;&#28857;&#25552;&#20379;&#20102;&#21333;&#19968;&#30340;&#38544;&#31169;&#20445;&#35777;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#38024;&#23545;&#20010;&#20363;&#30340;&#36755;&#20986;&#29305;&#23450;$(\varepsilon,\delta)$-DP&#65292;&#20197;&#21051;&#30011;&#36890;&#36807;DP-SGD&#35757;&#32451;&#30340;&#27169;&#22411;&#23545;&#20010;&#21035;&#31034;&#20363;&#30340;&#38544;&#31169;&#20445;&#35777;&#12290;&#25105;&#20204;&#36824;&#35774;&#35745;&#20102;&#19968;&#31181;&#39640;&#25928;&#31639;&#27861;&#26469;&#30740;&#31350;&#36328;&#22810;&#20010;&#25968;&#25454;&#38598;&#30340;&#20010;&#20307;&#38544;&#31169;&#12290;&#25105;&#20204;&#21457;&#29616;&#22823;&#22810;&#25968;&#31034;&#20363;&#37117;&#20139;&#26377;&#27604;&#26368;&#22351;&#24773;&#20917;&#36793;&#30028;&#26356;&#24378;&#30340;&#38544;&#31169;&#20445;&#35777;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#21457;&#29616;&#35757;&#32451;&#25439;&#22833;&#21644;&#31034;&#20363;&#30340;&#38544;&#31169;&#21442;&#25968;&#20043;&#38388;&#23384;&#22312;&#24456;&#24378;&#30340;&#30456;&#20851;&#24615;&#12290;&#36825;&#24847;&#21619;&#30528;&#22312;&#27169;&#22411;&#25928;&#29992;&#26041;&#38754;&#21463;&#21040;&#19981;&#36275;&#30340;&#32676;&#20307;&#21516;&#26102;&#32463;&#21382;&#36739;&#24369;&#30340;&#38544;&#31169;&#20445;&#35777;&#12290;&#20363;&#22914;&#65292;&#22312;CIFAR-10&#19978;&#65292;&#26368;&#20302;&#27979;&#35797;&#20934;&#30830;&#29575;&#31867;&#21035;&#30340;&#24179;&#22343;$\varepsilon$&#27604;&#26368;&#39640;&#20934;&#30830;&#29575;&#31867;&#21035;&#39640;44.2%&#12290;
&lt;/p&gt;
&lt;p&gt;
Differentially private stochastic gradient descent (DP-SGD) is the workhorse algorithm for recent advances in private deep learning. It provides a single privacy guarantee to all datapoints in the dataset. We propose output-specific $(\varepsilon,\delta)$-DP to characterize privacy guarantees for individual examples when releasing models trained by DP-SGD. We also design an efficient algorithm to investigate individual privacy across a number of datasets. We find that most examples enjoy stronger privacy guarantees than the worst-case bound. We further discover that the training loss and the privacy parameter of an example are well-correlated. This implies groups that are underserved in terms of model utility simultaneously experience weaker privacy guarantees. For example, on CIFAR-10, the average $\varepsilon$ of the class with the lowest test accuracy is 44.2\% higher than that of the class with the highest accuracy.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29983;&#25104;&#32593;&#32476;&#30340;&#38477;&#38454;&#27169;&#22411;&#65292;&#29992;&#20110;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#36870;&#38382;&#39064;&#12290;&#36890;&#36807;&#20351;&#29992;&#26080;&#26465;&#20214;&#27169;&#25311;&#36827;&#34892;&#35757;&#32451;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#26377;&#25928;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#20934;&#30830;&#21305;&#37197;&#27979;&#37327;&#25968;&#25454;&#21644;&#40644;&#37329;&#26631;&#20934;&#12290;</title><link>http://arxiv.org/abs/2105.13859</link><description>&lt;p&gt;
&#22522;&#20110;&#29983;&#25104;&#32593;&#32476;&#30340;&#38477;&#38454;&#27169;&#22411;&#29992;&#20110;&#39044;&#27979;&#12289;&#25968;&#25454;&#21516;&#21270;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Generative Network-Based Reduced-Order Model for Prediction, Data Assimilation and Uncertainty Quantification. (arXiv:2105.13859v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.13859
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29983;&#25104;&#32593;&#32476;&#30340;&#38477;&#38454;&#27169;&#22411;&#65292;&#29992;&#20110;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#36870;&#38382;&#39064;&#12290;&#36890;&#36807;&#20351;&#29992;&#26080;&#26465;&#20214;&#27169;&#25311;&#36827;&#34892;&#35757;&#32451;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#26377;&#25928;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#20934;&#30830;&#21305;&#37197;&#27979;&#37327;&#25968;&#25454;&#21644;&#40644;&#37329;&#26631;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#23558;&#29983;&#25104;&#32593;&#32476;&#65288;GN&#65289;&#25972;&#21512;&#21040;&#38477;&#38454;&#27169;&#22411;&#65288;ROM&#65289;&#26694;&#26550;&#20013;&#65292;&#29992;&#20110;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDE&#65289;&#30340;&#36870;&#38382;&#39064;&#12290;&#30446;&#26631;&#26159;&#21305;&#37197;&#21487;&#29992;&#30340;&#27979;&#37327;&#25968;&#25454;&#65292;&#24182;&#20272;&#35745;&#25968;&#20540;&#29289;&#29702;&#27169;&#25311;&#30340;&#29366;&#24577;&#21644;&#21442;&#25968;&#30340;&#30456;&#24212;&#19981;&#30830;&#23450;&#24615;&#12290;GN&#20165;&#20351;&#29992;&#31163;&#25955;&#21270;&#30340;PDE&#27169;&#22411;&#30340;&#26080;&#26465;&#20214;&#27169;&#25311;&#36827;&#34892;&#35757;&#32451;&#12290;&#25105;&#20204;&#23558;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#19982;&#40644;&#37329;&#26631;&#20934;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#25105;&#20204;&#23558;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#27969;&#34892;&#30149;&#23398;&#20013;&#30340;&#26102;&#31354;&#38548;&#23460;&#27169;&#22411;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#22522;&#20110;GN&#30340;&#38477;&#38454;&#27169;&#22411;&#33021;&#22815;&#26377;&#25928;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#19988;&#20165;&#20351;&#29992;&#23569;&#37327;&#26080;&#26465;&#20214;&#27169;&#25311;&#30340;&#20840;&#38454;&#25968;&#20540;PDE&#27169;&#22411;&#21363;&#21487;&#20934;&#30830;&#21305;&#37197;&#27979;&#37327;&#25968;&#25454;&#21644;&#40644;&#37329;&#26631;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new method in which a generative network (GN) integrate into a reduced-order model (ROM) framework is used to solve inverse problems for partial differential equations (PDE). The aim is to match available measurements and estimate the corresponding uncertainties associated with the states and parameters of a numerical physical simulation. The GN is trained using only unconditional simulations of the discretized PDE model. We compare the proposed method with the golden standard Markov chain Monte Carlo. We apply the proposed approaches to a spatio-temporal compartmental model in epidemiology. The results show that the proposed GN-based ROM can efficiently quantify uncertainty and accurately match the measurements and the golden standard, using only a few unconditional simulations of the full-order numerical PDE model.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#30340;&#26694;&#26550;&#26469;&#30740;&#31350;&#24322;&#27493;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#26377;&#38480;&#26679;&#26412;&#25910;&#25947;&#20445;&#35777;&#65292;&#24182;&#22522;&#20110;Lyapunov&#20998;&#26512;&#24314;&#31435;&#20102;&#24322;&#27493;RL&#31639;&#27861;&#30340;&#22343;&#26041;&#35823;&#24046;&#30028;&#38480;&#12290;&#36890;&#36807;&#23545;n&#27493;TD&#21644;TD&#65288;&#955;&#65289;&#30340;&#25910;&#25947;&#30028;&#38480;&#30340;&#20998;&#26512;&#65292;&#25581;&#31034;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#24341;&#23548;&#25216;&#24039;&#25928;&#29575;&#30340;&#29702;&#35770;&#27934;&#35265;&#12290;</title><link>http://arxiv.org/abs/2102.01567</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#24322;&#27493;Q&#23398;&#20064;&#21644;TD&#23398;&#20064;&#21464;&#31181;&#30340;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#30340;Lyapunov&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
A Lyapunov Theory for Finite-Sample Guarantees of Asynchronous Q-Learning and TD-Learning Variants. (arXiv:2102.01567v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.01567
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#30340;&#26694;&#26550;&#26469;&#30740;&#31350;&#24322;&#27493;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#26377;&#38480;&#26679;&#26412;&#25910;&#25947;&#20445;&#35777;&#65292;&#24182;&#22522;&#20110;Lyapunov&#20998;&#26512;&#24314;&#31435;&#20102;&#24322;&#27493;RL&#31639;&#27861;&#30340;&#22343;&#26041;&#35823;&#24046;&#30028;&#38480;&#12290;&#36890;&#36807;&#23545;n&#27493;TD&#21644;TD&#65288;&#955;&#65289;&#30340;&#25910;&#25947;&#30028;&#38480;&#30340;&#20998;&#26512;&#65292;&#25581;&#31034;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#24341;&#23548;&#25216;&#24039;&#25928;&#29575;&#30340;&#29702;&#35770;&#27934;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#39318;&#20808;&#23558;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#37325;&#26032;&#34920;&#36848;&#20026;&#35299;&#20915;&#22266;&#23450;&#28857;&#26041;&#31243;&#30340;"Markovian Stochastic Approximation"(SA)&#31639;&#27861;&#65292;&#21457;&#23637;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#26469;&#30740;&#31350;&#22522;&#20110;&#20540;&#30340;&#24322;&#27493;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#26377;&#38480;&#26679;&#26412;&#25910;&#25947;&#20445;&#35777;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;Lyapunov&#20998;&#26512;&#25512;&#23548;&#20986;Markovian SA&#30340;&#22343;&#26041;&#35823;&#24046;&#30028;&#38480;&#65292;&#22522;&#20110;&#27492;&#32467;&#26524;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#24322;&#27493;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65288;&#22914;Q&#23398;&#20064;&#65292;n&#27493;TD&#65292;TD&#65288;&#955;&#65289;&#21644;&#21253;&#25324;V-trace&#30340;&#31163;&#31574;&#30053;TD&#31639;&#27861;&#65289;&#30340;&#26377;&#38480;&#26679;&#26412;&#22343;&#26041;&#25910;&#25947;&#30028;&#38480;&#12290;&#20316;&#20026;&#21103;&#20135;&#21697;&#65292;&#36890;&#36807;&#20998;&#26512;n&#27493;TD&#21644;TD&#65288;&#955;&#65289;&#30340;&#25910;&#25947;&#30028;&#38480;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#24378;&#21270;&#23398;&#20064;&#20013;&#24341;&#23548;&#25216;&#24039;&#25928;&#29575;&#65288;&#21363;&#20559;&#24046;-&#26041;&#24046;&#26435;&#34913;&#65289;&#30340;&#29702;&#35770;&#27934;&#35265;&#65292;&#36825;&#26159;(Sutton, 1999)&#20013;&#39318;&#27425;&#25552;&#20986;&#30340;&#19968;&#20010;&#24320;&#25918;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper develops an unified framework to study finite-sample convergence guarantees of a large class of value-based asynchronous reinforcement learning (RL) algorithms. We do this by first reformulating the RL algorithms as \textit{Markovian Stochastic Approximation} (SA) algorithms to solve fixed-point equations. We then develop a Lyapunov analysis and derive mean-square error bounds on the convergence of the Markovian SA. Based on this result, we establish finite-sample mean-square convergence bounds for asynchronous RL algorithms such as $Q$-learning, $n$-step TD, TD$(\lambda)$, and off-policy TD algorithms including V-trace. As a by-product, by analyzing the convergence bounds of $n$-step TD and TD$(\lambda)$, we provide theoretical insights into the bias-variance trade-off, i.e., efficiency of bootstrapping in RL. This was first posed as an open problem in (Sutton, 1999).
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#21463;&#38480;Laplacian&#22270;&#27169;&#22411;&#19979;&#23398;&#20064;&#31232;&#30095;&#22270;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#21457;&#29616;&#32463;&#20856;&#30340;$\ell_1$-&#33539;&#25968;&#27491;&#21017;&#21270;&#26080;&#27861;&#26377;&#25928;&#23454;&#29616;&#31232;&#30095;&#35299;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#20984;&#31232;&#30095;&#24809;&#32602;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2006.14925</link><description>&lt;p&gt;
$\ell_1$-&#33539;&#25968;&#26159;&#21542;&#33021;&#22815;&#22312;&#21463;&#38480;Laplacian&#22270;&#27169;&#22411;&#19979;&#23398;&#20064;&#31232;&#30095;&#22270;&#24418;&#65311;
&lt;/p&gt;
&lt;p&gt;
Does the $\ell_1$-norm Learn a Sparse Graph under Laplacian Constrained Graphical Models?. (arXiv:2006.14925v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.14925
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#21463;&#38480;Laplacian&#22270;&#27169;&#22411;&#19979;&#23398;&#20064;&#31232;&#30095;&#22270;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#21457;&#29616;&#32463;&#20856;&#30340;$\ell_1$-&#33539;&#25968;&#27491;&#21017;&#21270;&#26080;&#27861;&#26377;&#25928;&#23454;&#29616;&#31232;&#30095;&#35299;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#20984;&#31232;&#30095;&#24809;&#32602;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#21463;&#38480;Laplacian&#39640;&#26031;&#22270;&#27169;&#22411;&#19979;&#23398;&#20064;&#31232;&#30095;&#22270;&#30340;&#38382;&#39064;&#12290;&#35813;&#38382;&#39064;&#21487;&#20197;&#34987;&#34920;&#31034;&#20026;&#25289;&#26222;&#25289;&#26031;&#32422;&#26463;&#19979;&#30340;&#31934;&#24230;&#30697;&#38453;&#30340;&#24809;&#32602;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#12290;&#19982;&#32463;&#20856;&#30340;&#22270;&#24418;&#22871;&#32034;&#38382;&#39064;&#31867;&#20284;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#21033;&#29992;&#20102;$\ell_1$-&#33539;&#25968;&#27491;&#21017;&#21270;&#26469;&#20419;&#36827;&#22312;&#25289;&#26222;&#25289;&#26031;&#32422;&#26463;&#31934;&#24230;&#30697;&#38453;&#20272;&#35745;&#20013;&#30340;&#31232;&#30095;&#24615;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#24191;&#27867;&#24212;&#29992;&#30340;$\ell_1$-&#33539;&#25968;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#26080;&#27861;&#26377;&#25928;&#22320;&#23454;&#29616;&#31232;&#30095;&#35299;&#12290;&#36890;&#36807;&#32463;&#39564;&#35777;&#25454;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#38750;&#38646;&#22270;&#26435;&#37325;&#30340;&#25968;&#37327;&#38543;&#30528;&#27491;&#21017;&#21270;&#21442;&#25968;&#30340;&#22686;&#21152;&#32780;&#22686;&#21152;&#12290;&#20174;&#29702;&#35770;&#19978;&#26469;&#30475;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36739;&#22823;&#30340;&#27491;&#21017;&#21270;&#21442;&#25968;&#23558;&#24341;&#21457;&#19968;&#20010;&#24847;&#22806;&#30340;&#23436;&#20840;&#22270;&#65292;&#21363;&#27599;&#23545;&#39030;&#28857;&#20043;&#38388;&#37117;&#29992;&#36793;&#36830;&#25509;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#38750;&#20984;&#31232;&#30095;&#24809;&#32602;&#65292;&#24182;&#36890;&#36807;&#27714;&#35299;&#19968;&#31995;&#21015;&#21152;&#26435;$\ell_1$-&#33539;&#25968;&#24471;&#21040;&#20102;&#19968;&#20010;&#26032;&#30340;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning a sparse graph under the Laplacian constrained Gaussian graphical models. This problem can be formulated as a penalized maximum likelihood estimation of the Laplacian constrained precision matrix. Like in the classical graphical lasso problem, recent works made use of the $\ell_1$-norm regularization with the goal of promoting sparsity in Laplacian constrained precision matrix estimation. However, we find that the widely used $\ell_1$-norm is not effective in imposing a sparse solution in this problem. Through empirical evidence, we observe that the number of nonzero graph weights grows with the increase of the regularization parameter. From a theoretical perspective, we prove that a large regularization parameter will surprisingly lead to a complete graph, i.e., every pair of vertices is connected by an edge. To address this issue, we introduce the nonconvex sparsity penalty, and propose a new estimator by solving a sequence of weighted $\ell_1$-nor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36873;&#25321;&#24615;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#21322;&#21442;&#25968;&#38382;&#39064;&#20013;&#36873;&#25321;&#21487;&#33021;&#39640;&#32500;&#30340;&#24178;&#25200;&#21442;&#25968;&#65292;&#24182;&#23545;&#21452;&#37325;&#40065;&#26834;&#24615;&#20989;&#25968;&#36827;&#34892;&#25512;&#26029;&#12290;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#36873;&#25321;&#26631;&#20934;&#21644;&#20266;&#39118;&#38505;&#23450;&#20041;&#65292;&#38477;&#20302;&#20102;&#20272;&#35745;&#25152;&#25552;&#20989;&#25968;&#20013;&#30340;&#20559;&#24046;&#65292;&#24182;&#19988;&#20855;&#26377;&#29702;&#24819;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/1911.02029</link><description>&lt;p&gt;
&#21452;&#37325;&#40065;&#26834;&#24615;&#20989;&#25968;&#30340;&#36873;&#25321;&#24615;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Selective machine learning of doubly robust functionals. (arXiv:1911.02029v6 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1911.02029
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36873;&#25321;&#24615;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#21322;&#21442;&#25968;&#38382;&#39064;&#20013;&#36873;&#25321;&#21487;&#33021;&#39640;&#32500;&#30340;&#24178;&#25200;&#21442;&#25968;&#65292;&#24182;&#23545;&#21452;&#37325;&#40065;&#26834;&#24615;&#20989;&#25968;&#36827;&#34892;&#25512;&#26029;&#12290;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#36873;&#25321;&#26631;&#20934;&#21644;&#20266;&#39118;&#38505;&#23450;&#20041;&#65292;&#38477;&#20302;&#20102;&#20272;&#35745;&#25152;&#25552;&#20989;&#25968;&#20013;&#30340;&#20559;&#24046;&#65292;&#24182;&#19988;&#20855;&#26377;&#29702;&#24819;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#21442;&#25968;&#21644;&#38750;&#21442;&#25968;&#22238;&#24402;&#25110;&#23494;&#24230;&#20272;&#35745;&#20013;&#30340;&#27169;&#22411;&#36873;&#25321;&#26159;&#19968;&#20010;&#30740;&#31350;&#20805;&#20998;&#30340;&#20027;&#39064;&#65292;&#20294;&#22312;&#21322;&#21442;&#25968;&#38382;&#39064;&#20013;&#36873;&#25321;&#21487;&#33021;&#39640;&#32500;&#30340;&#24178;&#25200;&#21442;&#25968;&#21017;&#36739;&#23569;&#30740;&#31350;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36873;&#25321;&#24615;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#23545;&#19968;&#20010;&#21322;&#21442;&#25968;&#27169;&#22411;&#19978;&#23450;&#20041;&#30340;&#26377;&#38480;&#32500;&#20989;&#25968;&#36827;&#34892;&#25512;&#26029;&#65292;&#24403;&#21518;&#32773;&#20855;&#26377;&#21452;&#37325;&#40065;&#26834;&#30340;&#20272;&#35745;&#20989;&#25968;&#65292;&#24182;&#26377;&#22810;&#20010;&#20505;&#36873;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21487;&#29992;&#20110;&#20272;&#35745;&#24178;&#25200;&#21442;&#25968;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#36873;&#25321;&#26631;&#20934;&#65292;&#26088;&#22312;&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#20266;&#39118;&#38505;&#23450;&#20041;&#26469;&#38477;&#20302;&#20272;&#35745;&#25152;&#25552;&#20989;&#25968;&#20013;&#30340;&#20559;&#24046;&#65292;&#35813;&#23450;&#20041;&#21463;&#21040;&#21452;&#37325;&#40065;&#26834;&#24615;&#36136;&#30340;&#21551;&#21457;&#12290;&#30452;&#35266;&#22320;&#35828;&#65292;&#25152;&#25552;&#20986;&#30340;&#26631;&#20934;&#36873;&#25321;&#20102;&#20855;&#26377;&#26368;&#23567;&#20266;&#39118;&#38505;&#30340;&#19968;&#23545;&#23398;&#20064;&#22120;&#65292;&#20197;&#20351;&#20272;&#35745;&#30340;&#20989;&#25968;&#23545;&#24178;&#25200;&#21442;&#25968;&#30340;&#25200;&#21160;&#26368;&#19981;&#25935;&#24863;&#12290;&#25105;&#20204;&#20026;&#22810;&#37325;&#20132;&#21449;&#39564;&#35777;&#29256;&#26412;&#30340;&#26041;&#27861;&#35777;&#26126;&#20102;&#29702;&#24819;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
While model selection is a well-studied topic in parametric and nonparametric regression or density estimation, selection of possibly high-dimensional nuisance parameters in semiparametric problems is far less developed. In this paper, we propose a selective machine learning framework for making inferences about a finite-dimensional functional defined on a semiparametric model, when the latter admits a doubly robust estimating function and several candidate machine learning algorithms are available for estimating the nuisance parameters. We introduce a new selection criterion aimed at bias reduction in estimating the functional of interest based on a novel definition of pseudo-risk inspired by the double robustness property. Intuitively, the proposed criterion selects a pair of learners with the smallest pseudo-risk, so that the estimated functional is least sensitive to perturbations of a nuisance parameter. We establish an oracle property for a multi-fold cross-validation version of 
&lt;/p&gt;</description></item></channel></rss>