<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#22270;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30446;&#21069;&#20027;&#35201;&#38598;&#20013;&#22312;&#39044;&#27979;&#20998;&#23376;&#21644;&#26448;&#26009;&#30340;&#30446;&#26631;&#29305;&#24615;&#65292;&#32780;&#23578;&#26410;&#36798;&#21040;&#29983;&#25104;&#33021;&#21147;&#19982;&#20854;&#20182;&#39046;&#22495;&#30340;&#27700;&#24179;&#12290;</title><link>https://arxiv.org/abs/2402.13221</link><description>&lt;p&gt;
CHILI: &#29992;&#20110;&#25512;&#36827;&#22270;&#26426;&#22120;&#23398;&#20064;&#30340;&#21270;&#23398;&#20449;&#24687;&#30340;&#22823;&#22411;&#26080;&#26426;&#32435;&#31859;&#26448;&#26009;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
CHILI: Chemically-Informed Large-scale Inorganic Nanomaterials Dataset for Advancing Graph Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13221
&lt;/p&gt;
&lt;p&gt;
&#22270;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30446;&#21069;&#20027;&#35201;&#38598;&#20013;&#22312;&#39044;&#27979;&#20998;&#23376;&#21644;&#26448;&#26009;&#30340;&#30446;&#26631;&#29305;&#24615;&#65292;&#32780;&#23578;&#26410;&#36798;&#21040;&#29983;&#25104;&#33021;&#21147;&#19982;&#20854;&#20182;&#39046;&#22495;&#30340;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#26426;&#22120;&#23398;&#20064;&#30340;&#36827;&#23637;&#20027;&#35201;&#21463;&#21270;&#23398;&#24212;&#29992;&#30340;&#39537;&#21160;&#65292;&#22240;&#20026;&#22270;&#19968;&#30452;&#26159;&#20998;&#23376;&#26368;&#20855;&#34920;&#29616;&#21147;&#30340;&#34920;&#31034;&#24418;&#24335;&#12290;&#34429;&#28982;&#26089;&#26399;&#30340;&#22270;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#23567;&#26377;&#26426;&#20998;&#23376;&#19978;&#65292;&#20294;&#26368;&#36817;&#65292;&#22270;&#26426;&#22120;&#23398;&#20064;&#30340;&#33539;&#22260;&#24050;&#32463;&#25193;&#23637;&#21040;&#21253;&#25324;&#26080;&#26426;&#26448;&#26009;&#12290;&#24314;&#27169;&#26080;&#26426;&#26230;&#20307;&#26448;&#26009;&#30340;&#21608;&#26399;&#24615;&#21644;&#23545;&#31216;&#24615;&#24102;&#26469;&#29420;&#29305;&#25361;&#25112;&#65292;&#29616;&#26377;&#30340;&#22270;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#26080;&#27861;&#35299;&#20915;&#12290;&#36716;&#21521;&#26080;&#26426;&#32435;&#31859;&#26448;&#26009;&#20250;&#22686;&#21152;&#22797;&#26434;&#24615;&#65292;&#22240;&#20026;&#27599;&#20010;&#22270;&#20013;&#33410;&#28857;&#25968;&#37327;&#30340;&#33539;&#22260;&#21487;&#33021;&#24456;&#24191;&#65288;$10$&#21040;$10^5$&#65289;&#12290;&#29616;&#26377;&#22270;&#26426;&#22120;&#23398;&#20064;&#30340;&#20027;&#35201;&#37325;&#28857;&#26159;&#36890;&#36807;&#22270;&#20316;&#20026;&#36755;&#20837;&#26469;&#39044;&#27979;&#30446;&#26631;&#29305;&#24615;&#65292;&#26469;&#34920;&#24449;&#20998;&#23376;&#21644;&#26448;&#26009;&#12290;&#20294;&#26159;&#65292;&#22270;&#26426;&#22120;&#23398;&#20064;&#26368;&#28608;&#21160;&#20154;&#24515;&#30340;&#24212;&#29992;&#23558;&#22312;&#20854;&#29983;&#25104;&#33021;&#21147;&#26041;&#38754;&#65292;&#30446;&#21069;&#19982;&#22270;&#20687;&#25110;&#25991;&#26412;&#31561;&#20854;&#20182;&#39046;&#22495;&#36824;&#19981;&#22312;&#21516;&#19968;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13221v1 Announce Type: new  Abstract: Advances in graph machine learning (ML) have been driven by applications in chemistry as graphs have remained the most expressive representations of molecules. While early graph ML methods focused primarily on small organic molecules, recently, the scope of graph ML has expanded to include inorganic materials. Modelling the periodicity and symmetry of inorganic crystalline materials poses unique challenges, which existing graph ML methods are unable to address. Moving to inorganic nanomaterials increases complexity as the scale of number of nodes within each graph can be broad ($10$ to $10^5$). The bulk of existing graph ML focuses on characterising molecules and materials by predicting target properties with graphs as input. However, the most exciting applications of graph ML will be in their generative capabilities, which is currently not at par with other domains such as images or text.   We invite the graph ML community to address th
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#23646;&#24615;&#27979;&#35797;&#31639;&#27861;&#26041;&#38754;&#30340;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36817;&#20284;&#32447;&#24615;&#35268;&#21010;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#20449;&#24687;&#29702;&#35770;&#19978;&#26368;&#20248;&#22320;&#35299;&#20915;&#26657;&#20934;&#24615;&#27979;&#35797;&#38382;&#39064;&#65288;&#26368;&#22810;&#19968;&#20010;&#24120;&#25968;&#20493;&#25968;&#65289;&#12290;</title><link>https://arxiv.org/abs/2402.13187</link><description>&lt;p&gt;
&#22312;&#27425;&#32447;&#24615;&#26102;&#38388;&#20869;&#27979;&#35797;&#26657;&#20934;&#24615;
&lt;/p&gt;
&lt;p&gt;
Testing Calibration in Subquadratic Time
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13187
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#23646;&#24615;&#27979;&#35797;&#31639;&#27861;&#26041;&#38754;&#30340;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36817;&#20284;&#32447;&#24615;&#35268;&#21010;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#20449;&#24687;&#29702;&#35770;&#19978;&#26368;&#20248;&#22320;&#35299;&#20915;&#26657;&#20934;&#24615;&#27979;&#35797;&#38382;&#39064;&#65288;&#26368;&#22810;&#19968;&#20010;&#24120;&#25968;&#20493;&#25968;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26368;&#36817;&#30340;&#26426;&#22120;&#23398;&#20064;&#21644;&#20915;&#31574;&#21046;&#23450;&#25991;&#29486;&#20013;&#65292;&#26657;&#20934;&#24615;&#24050;&#32463;&#25104;&#20026;&#20108;&#20803;&#39044;&#27979;&#27169;&#22411;&#36755;&#20986;&#30340;&#19968;&#20010;&#20540;&#24471;&#26399;&#26395;&#21644;&#24191;&#27867;&#30740;&#31350;&#30340;&#32479;&#35745;&#24615;&#36136;&#12290;&#28982;&#32780;&#65292;&#27979;&#37327;&#27169;&#22411;&#26657;&#20934;&#24615;&#30340;&#31639;&#27861;&#26041;&#38754;&#20173;&#28982;&#30456;&#23545;&#36739;&#23569;&#34987;&#25506;&#32034;&#12290;&#22312;&#35770;&#25991; [BGHN23] &#30340;&#21551;&#21457;&#19979;&#65292;&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20005;&#26684;&#30340;&#26694;&#26550;&#26469;&#34913;&#37327;&#21040;&#26657;&#20934;&#24615;&#30340;&#36317;&#31163;&#65292;&#25105;&#20204;&#36890;&#36807;&#23646;&#24615;&#27979;&#35797;&#30340;&#35270;&#35282;&#24341;&#20837;&#20102;&#26657;&#20934;&#24615;&#30740;&#31350;&#30340;&#31639;&#27861;&#26041;&#38754;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#20174;&#26679;&#26412;&#20013;&#36827;&#34892;&#26657;&#20934;&#24615;&#27979;&#35797;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#20174;&#20998;&#24067; $\mathcal{D}$&#65288;&#39044;&#27979;&#65292;&#20108;&#20803;&#32467;&#26524;&#65289;&#20013;&#32473;&#20986; $n$ &#27425;&#25277;&#26679;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#21306;&#20998; $\mathcal{D}$ &#23436;&#20840;&#26657;&#20934;&#21644; $\mathcal{D}$ &#36317;&#31163;&#26657;&#20934;&#24615;&#20026; $\varepsilon$ &#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13187v1 Announce Type: new  Abstract: In the recent literature on machine learning and decision making, calibration has emerged as a desirable and widely-studied statistical property of the outputs of binary prediction models. However, the algorithmic aspects of measuring model calibration have remained relatively less well-explored. Motivated by [BGHN23], which proposed a rigorous framework for measuring distances to calibration, we initiate the algorithmic study of calibration through the lens of property testing. We define the problem of calibration testing from samples where given $n$ draws from a distribution $\mathcal{D}$ on (predictions, binary outcomes), our goal is to distinguish between the case where $\mathcal{D}$ is perfectly calibrated, and the case where $\mathcal{D}$ is $\varepsilon$-far from calibration.   We design an algorithm based on approximate linear programming, which solves calibration testing information-theoretically optimally (up to constant factor
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#20998;&#24067;&#24335;&#26680;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#23454;&#29616;&#20102;&#26368;&#20248;&#27425;&#24207;&#36951;&#25022;&#65292;&#24182;&#19988;&#36890;&#20449;&#25104;&#26412;&#23545;&#20110;&#20195;&#29702;&#25968;&#37327;&#21644;&#26102;&#38388;&#37117;&#26159;&#20122;&#32447;&#24615;&#30340;&#12290;</title><link>https://arxiv.org/abs/2402.13182</link><description>&lt;p&gt;
&#20351;&#29992;&#20849;&#20139;&#38543;&#26426;&#24615;&#30340;&#22343;&#21248;&#37319;&#26679;&#23454;&#29616;&#20998;&#24067;&#24335;&#26680;&#36172;&#21338;&#26426;&#20013;&#30340;&#26368;&#20248;&#27425;&#24207;&#36951;&#25022;
&lt;/p&gt;
&lt;p&gt;
Order-Optimal Regret in Distributed Kernel Bandits using Uniform Sampling with Shared Randomness
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13182
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#20998;&#24067;&#24335;&#26680;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#23454;&#29616;&#20102;&#26368;&#20248;&#27425;&#24207;&#36951;&#25022;&#65292;&#24182;&#19988;&#36890;&#20449;&#25104;&#26412;&#23545;&#20110;&#20195;&#29702;&#25968;&#37327;&#21644;&#26102;&#38388;&#37117;&#26159;&#20122;&#32447;&#24615;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20998;&#24067;&#24335;&#26680;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#20854;&#20013;$N$&#20010;&#20195;&#29702;&#26088;&#22312;&#21327;&#21516;&#26368;&#22823;&#21270;&#23384;&#22312;&#20110;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#26410;&#30693;&#22870;&#21169;&#20989;&#25968;&#12290;&#27599;&#20010;&#20195;&#29702;&#20381;&#27425;&#26597;&#35810;&#35813;&#20989;&#25968;&#65292;&#20197;&#22312;&#26597;&#35810;&#28857;&#22788;&#33719;&#24471;&#22024;&#26434;&#30340;&#35266;&#27979;&#20540;&#12290;&#20195;&#29702;&#21487;&#20197;&#36890;&#36807;&#20013;&#22830;&#26381;&#21153;&#22120;&#20849;&#20139;&#20449;&#24687;&#65292;&#30446;&#30340;&#26159;&#26368;&#23567;&#21270;&#38543;&#30528;&#26102;&#38388;$T$&#32047;&#31215;&#24182;&#27719;&#24635;&#22312;&#20195;&#29702;&#20043;&#38388;&#30340;&#36951;&#25022;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#31532;&#19968;&#20010;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#23454;&#29616;&#20102;&#22312;&#36890;&#20449;&#25104;&#26412;&#23545;$N$&#21644;$T$&#22343;&#20026;&#20122;&#32447;&#24615;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#26368;&#20248;&#36951;&#25022;&#27425;&#24207;&#65288;&#30001;&#38598;&#20013;&#24335;&#23398;&#20064;&#23450;&#20041;&#65289;&#12290;&#25152;&#25552;&#20986;&#31639;&#27861;&#30340;&#20851;&#38190;&#29305;&#28857;&#26159;&#23616;&#37096;&#20195;&#29702;&#30340;&#22343;&#21248;&#25506;&#32034;&#21644;&#19982;&#20013;&#22830;&#26381;&#21153;&#22120;&#30340;&#20849;&#20139;&#38543;&#26426;&#24615;&#12290;&#19982;GP&#27169;&#22411;&#30340;&#31232;&#30095;&#36924;&#36817;&#19968;&#36215;&#24037;&#20316;&#65292;&#36825;&#20004;&#20010;&#20851;&#38190;&#32452;&#20214;&#20351;&#24471;&#33021;&#22815;&#20197;&#36890;&#20449;&#30340;&#34928;&#20943;&#36895;&#29575;&#20445;&#25345;&#20013;&#22830;&#35774;&#32622;&#30340;&#23398;&#20064;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13182v1 Announce Type: new  Abstract: We consider distributed kernel bandits where $N$ agents aim to collaboratively maximize an unknown reward function that lies in a reproducing kernel Hilbert space. Each agent sequentially queries the function to obtain noisy observations at the query points. Agents can share information through a central server, with the objective of minimizing regret that is accumulating over time $T$ and aggregating over agents. We develop the first algorithm that achieves the optimal regret order (as defined by centralized learning) with a communication cost that is sublinear in both $N$ and $T$. The key features of the proposed algorithm are the uniform exploration at the local agents and shared randomness with the central server. Working together with the sparse approximation of the GP model, these two key components make it possible to preserve the learning rate of the centralized setting at a diminishing rate of communication.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#21463;&#22797;&#21512;&#39640;&#26031;&#20808;&#39564;&#21551;&#21457;&#30340;&#23637;&#24320;DNN&#65292;&#25552;&#20986;&#20102;&#26032;&#39062;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#65292;&#36825;&#20123;&#32593;&#32476;&#22312;&#21387;&#32553;&#24863;&#30693;&#21644;&#23618;&#26512;&#25104;&#20687;&#38382;&#39064;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>https://arxiv.org/abs/2402.13106</link><description>&lt;p&gt;
&#20851;&#20110;&#28145;&#24230;&#22797;&#21512;&#39640;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
On Generalization Bounds for Deep Compound Gaussian Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13106
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#21463;&#22797;&#21512;&#39640;&#26031;&#20808;&#39564;&#21551;&#21457;&#30340;&#23637;&#24320;DNN&#65292;&#25552;&#20986;&#20102;&#26032;&#39062;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#65292;&#36825;&#20123;&#32593;&#32476;&#22312;&#21387;&#32553;&#24863;&#30693;&#21644;&#23618;&#26512;&#25104;&#20687;&#38382;&#39064;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31639;&#27861;&#23637;&#24320;&#25110;&#28378;&#21160;&#26159;&#19968;&#31181;&#20174;&#36845;&#20195;&#31639;&#27861;&#26500;&#24314;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#30340;&#25216;&#26415;&#12290;&#23637;&#24320;&#30340;DNN&#22312;&#20449;&#21495;&#20272;&#35745;&#20219;&#21153;&#20013;&#36890;&#24120;&#27604;&#26631;&#20934;DNN&#25552;&#20379;&#26356;&#22909;&#30340;&#21487;&#35299;&#37322;&#24615;&#21644;&#26356;&#20248;&#36234;&#30340;&#32463;&#39564;&#24615;&#33021;&#12290;&#19968;&#20010;&#37325;&#35201;&#30340;&#29702;&#35770;&#38382;&#39064;&#26159;&#26368;&#36817;&#25165;&#24341;&#36215;&#20851;&#27880;&#30340;&#26159;&#20026;&#23637;&#24320;&#30340;DNN&#24320;&#21457;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#12290;&#36825;&#20123;&#30028;&#38480;&#25552;&#20379;&#20102;&#29702;&#35770;&#21644;&#23454;&#38469;&#27934;&#23519;&#65292;&#35828;&#26126;&#20102;DNN&#22312;&#19982;&#29983;&#25104;DNN&#35757;&#32451;&#25968;&#25454;&#30340;&#27010;&#29575;&#23494;&#24230;&#19981;&#21516;&#20294;&#37319;&#26679;&#33258;&#20854;&#20013;&#30340;&#32463;&#39564;&#25968;&#25454;&#38598;&#19978;&#30340;&#34920;&#29616;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20026;&#19968;&#31867;&#21463;&#22797;&#21512;&#39640;&#26031;&#20808;&#39564;&#21551;&#21457;&#30340;&#23637;&#24320;DNN&#24320;&#21457;&#20102;&#26032;&#39062;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#12290;&#24050;&#32463;&#26174;&#31034;&#36825;&#20123;&#22797;&#21512;&#39640;&#26031;&#32593;&#32476;&#22312;&#21387;&#32553;&#24863;&#30693;&#21644;&#23618;&#26512;&#25104;&#20687;&#38382;&#39064;&#20013;&#20248;&#20110;&#27604;&#36739;&#30340;&#26631;&#20934;&#21644;&#23637;&#24320;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13106v1 Announce Type: cross  Abstract: Algorithm unfolding or unrolling is the technique of constructing a deep neural network (DNN) from an iterative algorithm. Unrolled DNNs often provide better interpretability and superior empirical performance over standard DNNs in signal estimation tasks. An important theoretical question, which has only recently received attention, is the development of generalization error bounds for unrolled DNNs. These bounds deliver theoretical and practical insights into the performance of a DNN on empirical datasets that are distinct from, but sampled from, the probability density generating the DNN training data. In this paper, we develop novel generalization error bounds for a class of unrolled DNNs that are informed by a compound Gaussian prior. These compound Gaussian networks have been shown to outperform comparative standard and unfolded deep neural networks in compressive sensing and tomographic imaging problems. The generalization error
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27169;&#24577;&#20272;&#35745;&#20013;&#21033;&#29992;&#37096;&#20998;&#21453;&#39304;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#29109;&#32534;&#30721;&#23454;&#29616;&#26368;&#20248;&#20449;&#24687;&#33719;&#21462;&#65292;&#24320;&#21457;&#20102;&#31895;&#31961;&#30340;&#20805;&#20998;&#32479;&#35745;&#29992;&#20110;&#27169;&#24577;&#35782;&#21035;&#65292;&#24182;&#23558;&#36172;&#21338;&#31639;&#27861;&#35843;&#25972;&#20026;&#26032;&#35774;&#32622;&#65292;&#26368;&#32456;&#25552;&#20986;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;&#38382;&#39064;&#35299;&#20915;&#26041;&#26696;</title><link>https://arxiv.org/abs/2402.13079</link><description>&lt;p&gt;
&#20855;&#26377;&#37096;&#20998;&#21453;&#39304;&#30340;&#27169;&#24577;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Mode Estimation with Partial Feedback
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13079
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27169;&#24577;&#20272;&#35745;&#20013;&#21033;&#29992;&#37096;&#20998;&#21453;&#39304;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#29109;&#32534;&#30721;&#23454;&#29616;&#26368;&#20248;&#20449;&#24687;&#33719;&#21462;&#65292;&#24320;&#21457;&#20102;&#31895;&#31961;&#30340;&#20805;&#20998;&#32479;&#35745;&#29992;&#20110;&#27169;&#24577;&#35782;&#21035;&#65292;&#24182;&#23558;&#36172;&#21338;&#31639;&#27861;&#35843;&#25972;&#20026;&#26032;&#35774;&#32622;&#65292;&#26368;&#32456;&#25552;&#20986;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;&#38382;&#39064;&#35299;&#20915;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13079v1 &#36890;&#21578;&#31867;&#22411;: &#20132;&#21449;&#25688;&#35201;: &#26368;&#36817;&#20154;&#24037;&#26234;&#33021;&#21457;&#23637;&#20013;&#65292;&#36731;&#24230;&#30417;&#30563;&#30340;&#39044;&#35757;&#32451;&#21644;&#22312;&#32447;&#24494;&#35843;&#30340;&#32452;&#21512;&#22312;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#36825;&#20123;&#26032;&#30340;&#23398;&#20064;&#27969;&#31243;&#38656;&#35201;&#26032;&#30340;&#29702;&#35770;&#26694;&#26550;&#12290;&#26412;&#25991;&#36890;&#36807;&#19968;&#20010;&#31616;&#21333;&#38382;&#39064;&#65292;&#24418;&#24335;&#21270;&#24369;&#30417;&#30563;&#21644;&#20027;&#21160;&#23398;&#20064;&#30340;&#26680;&#24515;&#26041;&#38754;&#65306;&#20351;&#29992;&#37096;&#20998;&#21453;&#39304;&#20272;&#35745;&#20998;&#24067;&#30340;&#27169;&#24577;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#29109;&#32534;&#30721;&#20174;&#37096;&#20998;&#21453;&#39304;&#20013;&#23454;&#29616;&#26368;&#20248;&#20449;&#24687;&#33719;&#21462;&#65292;&#20026;&#27169;&#24577;&#35782;&#21035;&#24320;&#21457;&#20102;&#31895;&#31961;&#30340;&#20805;&#20998;&#32479;&#35745;&#65292;&#24182;&#23558;&#36172;&#21338;&#31639;&#27861;&#35843;&#25972;&#20026;&#25105;&#20204;&#30340;&#26032;&#35774;&#32622;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#36129;&#29486;&#32467;&#21512;&#36215;&#26469;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#32479;&#35745;&#19978;&#21644;&#35745;&#31639;&#19978;&#39640;&#25928;&#30340;&#38382;&#39064;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13079v1 Announce Type: cross  Abstract: The combination of lightly supervised pre-training and online fine-tuning has played a key role in recent AI developments. These new learning pipelines call for new theoretical frameworks. In this paper, we formalize core aspects of weakly supervised and active learning with a simple problem: the estimation of the mode of a distribution using partial feedback. We show how entropy coding allows for optimal information acquisition from partial feedback, develop coarse sufficient statistics for mode identification, and adapt bandit algorithms to our new setting. Finally, we combine those contributions into a statistically and computationally efficient solution to our problem.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#24212;&#20219;&#20309;&#21327;&#21464;&#37327;&#20449;&#24687;&#23376;&#38598;&#30340;&#35843;&#25972;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#32467;&#26524;&#24341;&#20837;&#20102;Debiased Outcome-adapted Propensity Estimator&#65288;DOPE&#65289;&#20197;&#23454;&#29616;&#26377;&#25928;&#35843;&#25972;&#12290;</title><link>https://arxiv.org/abs/2402.12980</link><description>&lt;p&gt;
&#22797;&#26434;&#21327;&#21464;&#37327;&#30340;&#26377;&#25928;&#35843;&#25972;&#65306;&#21033;&#29992;DOPE&#25552;&#39640;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;
Efficient adjustment for complex covariates: Gaining efficiency with DOPE
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12980
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#24212;&#20219;&#20309;&#21327;&#21464;&#37327;&#20449;&#24687;&#23376;&#38598;&#30340;&#35843;&#25972;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#32467;&#26524;&#24341;&#20837;&#20102;Debiased Outcome-adapted Propensity Estimator&#65288;DOPE&#65289;&#20197;&#23454;&#29616;&#26377;&#25928;&#35843;&#25972;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21327;&#21464;&#37327;&#35843;&#25972;&#26159;&#19968;&#31181;&#29992;&#20110;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#20272;&#35745;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATE&#65289;&#30340;&#26222;&#36941;&#26041;&#27861;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#32467;&#26524;&#20551;&#35774;&#25968;&#25454;&#29983;&#25104;&#27169;&#22411;&#30340;&#22270;&#32467;&#26500;&#24050;&#30693;&#65292;&#32473;&#20986;&#20102;&#29992;&#20110;&#26368;&#20339;&#35843;&#25972;&#30340;&#22270;&#24418;&#26631;&#20934;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;ATE&#30340;&#26377;&#25928;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#39640;&#32500;&#21644;&#22797;&#26434;&#25968;&#25454;&#65292;&#22270;&#24418;&#26041;&#27861;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#24182;&#19988;&#35201;&#25351;&#23450;&#38750;&#27431;&#20960;&#37324;&#24471;&#25968;&#25454;&#65288;&#22914;&#25991;&#26412;&#65289;&#30340;&#26377;&#24847;&#20041;&#22270;&#24418;&#27169;&#22411;&#24182;&#19981;&#31616;&#21333;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#21487;&#36866;&#24212;&#30001;&#21327;&#21464;&#37327;&#34920;&#36798;&#30340;&#20219;&#20309;&#20449;&#24687;&#23376;&#38598;&#30340;&#35843;&#25972;&#12290;&#25105;&#20204;&#25512;&#24191;&#20102;&#20808;&#21069;&#30340;&#24037;&#20316;&#65292;&#24182;&#21033;&#29992;&#36825;&#20123;&#32467;&#26524;&#35782;&#21035;&#20102;&#29992;&#20110;&#26377;&#25928;&#35843;&#25972;&#30340;&#26368;&#20339;&#21327;&#21464;&#37327;&#20449;&#24687;&#12290;&#36825;&#20123;&#20449;&#24687;&#22312;&#32473;&#23450;&#22788;&#29702;&#26465;&#20214;&#19979;&#23545;&#32467;&#26524;&#30340;&#39044;&#27979;&#26159;&#26368;&#23567;&#20805;&#20998;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12980v1 Announce Type: cross  Abstract: Covariate adjustment is a ubiquitous method used to estimate the average treatment effect (ATE) from observational data. Assuming a known graphical structure of the data generating model, recent results give graphical criteria for optimal adjustment, which enables efficient estimation of the ATE. However, graphical approaches are challenging for high-dimensional and complex data, and it is not straightforward to specify a meaningful graphical model of non-Euclidean data such as texts. We propose an general framework that accommodates adjustment for any subset of information expressed by the covariates. We generalize prior works and leverage these results to identify the optimal covariate information for efficient adjustment. This information is minimally sufficient for prediction of the outcome conditionally on treatment.   Based on our theoretical results, we propose the Debiased Outcome-adapted Propensity Estimator (DOPE) for efficie
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#23545;&#20110;&#26680;&#23725;&#22238;&#24402;&#30340;&#20302;&#31209;&#36817;&#20284;&#21644;&#26367;&#20195;&#26041;&#27861;&#20013;&#65292;&#20851;&#20110;&#20302;&#32500;&#36817;&#20284;&#31209;&#30340;&#19968;&#20010;&#19979;&#30028;&#65292;&#20174;&#32780;&#20445;&#35777;&#21487;&#38752;&#30340;&#39044;&#27979;&#33021;&#21147;&#65292;&#24182;&#23558;&#26377;&#25928;&#32500;&#24230;&#19982;&#26368;&#22823;&#32479;&#35745;&#26464;&#26438;&#24471;&#20998;&#32852;&#31995;&#36215;&#26469;&#12290;</title><link>https://arxiv.org/abs/2402.12885</link><description>&lt;p&gt;
&#23545;&#26368;&#22823;&#36793;&#38469;&#33258;&#30001;&#24230;&#30340;&#19968;&#20010;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
A Bound on the Maximal Marginal Degrees of Freedom
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12885
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#23545;&#20110;&#26680;&#23725;&#22238;&#24402;&#30340;&#20302;&#31209;&#36817;&#20284;&#21644;&#26367;&#20195;&#26041;&#27861;&#20013;&#65292;&#20851;&#20110;&#20302;&#32500;&#36817;&#20284;&#31209;&#30340;&#19968;&#20010;&#19979;&#30028;&#65292;&#20174;&#32780;&#20445;&#35777;&#21487;&#38752;&#30340;&#39044;&#27979;&#33021;&#21147;&#65292;&#24182;&#23558;&#26377;&#25928;&#32500;&#24230;&#19982;&#26368;&#22823;&#32479;&#35745;&#26464;&#26438;&#24471;&#20998;&#32852;&#31995;&#36215;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12885v1 &#20844;&#21578;&#31867;&#22411;: &#20132;&#21449;&#25688;&#35201;: &#36890;&#29992;&#26680;&#23725;&#22238;&#24402;&#22312;&#20869;&#23384;&#20998;&#37197;&#21644;&#35745;&#31639;&#26102;&#38388;&#19978;&#25104;&#26412;&#39640;&#26114;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#26680;&#23725;&#22238;&#24402;&#30340;&#20302;&#31209;&#36817;&#20284;&#21644;&#26367;&#20195;&#26041;&#27861;&#65292;&#20197;&#24212;&#23545;&#36825;&#20123;&#22256;&#38590;&#12290;&#26412;&#25991;&#30340;&#22522;&#26412;&#36129;&#29486;&#22312;&#20110;&#23545;&#20302;&#32500;&#36817;&#20284;&#30340;&#31209;&#25552;&#20986;&#20102;&#19968;&#20010;&#19979;&#30028;&#65292;&#35201;&#27714;&#20854;&#20445;&#25345;&#21487;&#38752;&#30340;&#39044;&#27979;&#33021;&#21147;&#12290;&#35813;&#30028;&#38480;&#23558;&#26377;&#25928;&#32500;&#24230;&#19982;&#26368;&#22823;&#32479;&#35745;&#26464;&#26438;&#24471;&#20998;&#32852;&#31995;&#36215;&#26469;&#12290;&#25105;&#20204;&#36890;&#36807;&#28041;&#21450;&#26680;&#30340;&#27491;&#21017;&#24615;&#26469;&#34920;&#24449;&#26377;&#25928;&#32500;&#24230;&#21450;&#20854;&#38543;&#27491;&#21017;&#21270;&#21442;&#25968;&#30340;&#22686;&#38271;&#34892;&#20026;&#12290;&#23545;&#20110;&#36866;&#24403;&#36873;&#25321;&#30340;&#26680;&#65292;&#36825;&#31181;&#22686;&#38271;&#34987;&#35777;&#26126;&#26159;&#23545;&#25968;&#28176;&#36817;&#30340;&#65292;&#20174;&#32780;&#35777;&#26126;&#20102;&#20302;&#31209;&#36817;&#20284;&#20316;&#20026;Nystro&#776;m&#26041;&#27861;&#30340;&#21512;&#29702;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12885v1 Announce Type: cross  Abstract: Common kernel ridge regression is expensive in memory allocation and computation time. This paper addresses low rank approximations and surrogates for kernel ridge regression, which bridge these difficulties. The fundamental contribution of the paper is a lower bound on the rank of the low dimensional approximation, which is required such that the prediction power remains reliable. The bound relates the effective dimension with the largest statistical leverage score. We characterize the effective dimension and its growth behavior with respect to the regularization parameter by involving the regularity of the kernel. This growth is demonstrated to be asymptotically logarithmic for suitably chosen kernels, justifying low-rank approximations as the Nystr\"om method.
&lt;/p&gt;</description></item><item><title>&#24605;&#32500;&#38142;&#36171;&#20104;&#21464;&#21387;&#22120;&#27169;&#22411;&#25191;&#34892;&#22266;&#26377;&#20018;&#34892;&#35745;&#31639;&#30340;&#33021;&#21147;&#65292;&#25552;&#39640;&#20102;&#21464;&#21387;&#22120;&#22312;&#31639;&#26415;&#21644;&#31526;&#21495;&#25512;&#29702;&#20219;&#21153;&#20013;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.12875</link><description>&lt;p&gt;
&#24605;&#32500;&#38142;&#28608;&#21457;&#21464;&#21387;&#22120;&#35299;&#20915;&#22266;&#26377;&#20018;&#34892;&#38382;&#39064;&#30340;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Chain of Thought Empowers Transformers to Solve Inherently Serial Problems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12875
&lt;/p&gt;
&lt;p&gt;
&#24605;&#32500;&#38142;&#36171;&#20104;&#21464;&#21387;&#22120;&#27169;&#22411;&#25191;&#34892;&#22266;&#26377;&#20018;&#34892;&#35745;&#31639;&#30340;&#33021;&#21147;&#65292;&#25552;&#39640;&#20102;&#21464;&#21387;&#22120;&#22312;&#31639;&#26415;&#21644;&#31526;&#21495;&#25512;&#29702;&#20219;&#21153;&#20013;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25351;&#23548;&#27169;&#22411;&#29983;&#25104;&#19968;&#31995;&#21015;&#20013;&#38388;&#27493;&#39588;&#65292;&#21363;&#24605;&#32500;&#38142;&#65288;CoT&#65289;&#65292;&#26159;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#31639;&#26415;&#21644;&#31526;&#21495;&#25512;&#29702;&#20219;&#21153;&#19978;&#20934;&#30830;&#24615;&#30340;&#39640;&#25928;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;CoT&#32972;&#21518;&#30340;&#26426;&#21046;&#20173;&#19981;&#28165;&#26970;&#12290;&#36825;&#39033;&#24037;&#20316;&#36890;&#36807;&#34920;&#36798;&#24615;&#30340;&#35270;&#35282;&#25552;&#20379;&#20102;&#23545;&#35299;&#30721;&#22120;&#19987;&#29992;&#21464;&#21387;&#22120;&#30340;CoT&#33021;&#21147;&#30340;&#29702;&#35770;&#29702;&#35299;&#12290;&#22312;&#27010;&#24565;&#19978;&#65292;CoT&#36171;&#20104;&#27169;&#22411;&#25191;&#34892;&#22266;&#26377;&#20018;&#34892;&#35745;&#31639;&#30340;&#33021;&#21147;&#65292;&#32780;&#36825;&#31181;&#33021;&#21147;&#22312;&#21464;&#21387;&#22120;&#20013;&#32570;&#20047;&#65292;&#29305;&#21035;&#26159;&#24403;&#28145;&#24230;&#36739;&#20302;&#26102;&#12290;&#20808;&#21069;&#30340;&#20316;&#21697;&#24050;&#32463;&#34920;&#26126;&#65292;&#22312;&#27809;&#26377;CoT&#30340;&#24773;&#20917;&#19979;&#65292;&#20855;&#26377;&#26377;&#38480;&#31934;&#24230;$\mathsf{poly}(n)$&#23884;&#20837;&#23610;&#23544;&#30340;&#24658;&#23450;&#28145;&#24230;&#21464;&#21387;&#22120;&#21482;&#33021;&#22312;$\mathsf{TC}^0$&#20013;&#35299;&#20915;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#20855;&#26377;&#24120;&#25968;&#20301;&#31934;&#24230;&#30340;&#24658;&#23450;&#28145;&#24230;&#21464;&#21387;&#22120;&#30340;&#26356;&#32039;&#23494;&#30340;&#34920;&#36798;&#24615;&#19978;&#30028;&#65292;&#23427;&#21482;&#33021;&#35299;&#20915;$\mathsf{AC}^0$&#20013;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12875v1 Announce Type: new  Abstract: Instructing the model to generate a sequence of intermediate steps, a.k.a., a chain of thought (CoT), is a highly effective method to improve the accuracy of large language models (LLMs) on arithmetics and symbolic reasoning tasks. However, the mechanism behind CoT remains unclear. This work provides a theoretical understanding of the power of CoT for decoder-only transformers through the lens of expressiveness. Conceptually, CoT empowers the model with the ability to perform inherently serial computation, which is otherwise lacking in transformers, especially when depth is low. Given input length $n$, previous works have shown that constant-depth transformers with finite precision $\mathsf{poly}(n)$ embedding size can only solve problems in $\mathsf{TC}^0$ without CoT. We first show an even tighter expressiveness upper bound for constant-depth transformers with constant-bit precision, which can only solve problems in $\mathsf{AC}^0$, a 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#26512;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21487;&#34892;&#38598;&#30340;&#26354;&#29575;&#65292;&#22312;&#22312;&#32447;&#20984;&#20248;&#21270;&#20013;&#23454;&#29616;&#20102;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.12868</link><description>&lt;p&gt;
&#36890;&#36807;&#21033;&#29992;&#21487;&#34892;&#38598;&#30340;&#26354;&#29575;&#65292;&#22312;&#22312;&#32447;&#20984;&#20248;&#21270;&#20013;&#23454;&#29616;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;
&lt;/p&gt;
&lt;p&gt;
Fast Rates in Online Convex Optimization by Exploiting the Curvature of Feasible Sets
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12868
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#26512;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21487;&#34892;&#38598;&#30340;&#26354;&#29575;&#65292;&#22312;&#22312;&#32447;&#20984;&#20248;&#21270;&#20013;&#23454;&#29616;&#20102;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#22312;&#32447;&#20984;&#20248;&#21270;&#65288;OCO&#65289;&#65292;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#21033;&#29992;&#21487;&#34892;&#38598;&#30340;&#26354;&#29575;&#25552;&#20379;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;&#30340;&#26032;&#20998;&#26512;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#65292;&#22914;&#26524;&#26368;&#20248;&#20915;&#31574;&#20301;&#20110;&#21487;&#34892;&#38598;&#30340;&#36793;&#30028;&#19978;&#19988;&#22522;&#30784;&#25439;&#22833;&#20989;&#25968;&#30340;&#26799;&#24230;&#38750;&#38646;&#65292;&#21017;&#31639;&#27861;&#22312;&#38543;&#26426;&#29615;&#22659;&#20013;&#21487;&#20197;&#36798;&#21040;$O(\rho \log T)$&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;&#20854;&#20013;&#65292;$\rho &gt; 0$&#26159;&#21253;&#21547;&#26368;&#20248;&#20915;&#31574;&#24182;&#22260;&#32469;&#21487;&#34892;&#38598;&#30340;&#26368;&#23567;&#29699;&#20307;&#30340;&#21322;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12868v1 Announce Type: new  Abstract: In this paper, we explore online convex optimization (OCO) and introduce a new analysis that provides fast rates by exploiting the curvature of feasible sets. In online linear optimization, it is known that if the average gradient of loss functions is larger than a certain value, the curvature of feasible sets can be exploited by the follow-the-leader (FTL) algorithm to achieve a logarithmic regret. This paper reveals that algorithms adaptive to the curvature of loss functions can also leverage the curvature of feasible sets. We first prove that if an optimal decision is on the boundary of a feasible set and the gradient of an underlying loss function is non-zero, then the algorithm achieves a regret upper bound of $O(\rho \log T)$ in stochastic environments. Here, $\rho &gt; 0$ is the radius of the smallest sphere that includes the optimal decision and encloses the feasible set. Our approach, unlike existing ones, can work directly with co
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20013;&#20540;&#20272;&#35745;&#30340;&#31283;&#20581;&#26799;&#24230;&#20272;&#35745;&#26041;&#27861;&#65292;&#38024;&#23545;&#21253;&#25324;&#37325;&#23614;&#22122;&#22768;&#22312;&#20869;&#30340;&#22810;&#31181;&#24212;&#29992;&#22330;&#26223;&#36827;&#34892;&#20102;&#25506;&#35752;&#65292;&#25581;&#31034;&#20102;&#19981;&#21516;&#24418;&#24335;&#30340;&#21098;&#20999;&#26041;&#27861;&#23454;&#38469;&#19978;&#26159;&#35813;&#26041;&#27861;&#30340;&#29305;&#20363;&#12290;</title><link>https://arxiv.org/abs/2402.12828</link><description>&lt;p&gt;
SGD&#26799;&#24230;&#21098;&#20999;&#26041;&#27861;&#26263;&#20013;&#20272;&#35745;&#20013;&#20540;&#26799;&#24230;
&lt;/p&gt;
&lt;p&gt;
SGD with Clipping is Secretly Estimating the Median Gradient
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12828
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20013;&#20540;&#20272;&#35745;&#30340;&#31283;&#20581;&#26799;&#24230;&#20272;&#35745;&#26041;&#27861;&#65292;&#38024;&#23545;&#21253;&#25324;&#37325;&#23614;&#22122;&#22768;&#22312;&#20869;&#30340;&#22810;&#31181;&#24212;&#29992;&#22330;&#26223;&#36827;&#34892;&#20102;&#25506;&#35752;&#65292;&#25581;&#31034;&#20102;&#19981;&#21516;&#24418;&#24335;&#30340;&#21098;&#20999;&#26041;&#27861;&#23454;&#38469;&#19978;&#26159;&#35813;&#26041;&#27861;&#30340;&#29305;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26377;&#20960;&#31181;&#38543;&#26426;&#20248;&#21270;&#30340;&#24212;&#29992;&#22330;&#26223;&#21487;&#20197;&#21463;&#30410;&#20110;&#23545;&#26799;&#24230;&#30340;&#31283;&#20581;&#20272;&#35745;&#12290;&#20363;&#22914;&#65292;&#22312;&#20855;&#26377;&#25439;&#22351;&#33410;&#28857;&#30340;&#20998;&#24067;&#24335;&#23398;&#20064;&#39046;&#22495;&#12289;&#35757;&#32451;&#25968;&#25454;&#20013;&#23384;&#22312;&#22823;&#30340;&#24322;&#24120;&#20540;&#12289;&#22312;&#38544;&#31169;&#32422;&#26463;&#19979;&#23398;&#20064;&#65292;&#29978;&#33267;&#30001;&#20110;&#31639;&#27861;&#21160;&#24577;&#26412;&#36523;&#30340;&#37325;&#23614;&#22122;&#22768;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20013;&#20540;&#20272;&#35745;&#30340;&#31283;&#20581;&#26799;&#24230;&#20272;&#35745;&#30340;SGD&#12290;&#39318;&#20808;&#32771;&#34385;&#36328;&#26679;&#26412;&#35745;&#31639;&#20013;&#20540;&#26799;&#24230;&#65292;&#32467;&#26524;&#34920;&#26126;&#21363;&#20351;&#22312;&#37325;&#23614;&#12289;&#29366;&#24577;&#30456;&#20851;&#22122;&#22768;&#19979;&#65292;&#35813;&#26041;&#27861;&#20063;&#33021;&#25910;&#25947;&#12290;&#28982;&#21518;&#25105;&#20204;&#25512;&#23548;&#20102;&#22522;&#20110;&#38543;&#26426;&#36817;&#31471;&#28857;&#26041;&#27861;&#30340;&#36845;&#20195;&#26041;&#27861;&#65292;&#29992;&#20110;&#35745;&#31639;&#20960;&#20309;&#20013;&#20540;&#21644;&#20854;&#25512;&#24191;&#24418;&#24335;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#36845;&#20195;&#38388;&#30340;&#20013;&#20540;&#26799;&#24230;&#65292;&#24182;&#21457;&#29616;&#20960;&#31181;&#20247;&#25152;&#21608;&#30693;&#30340;&#26041;&#27861; - &#29305;&#21035;&#26159;&#19981;&#21516;&#24418;&#24335;&#30340;&#21098;&#20999; - &#26159;&#36825;&#19968;&#26694;&#26550;&#30340;&#29305;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12828v1 Announce Type: cross  Abstract: There are several applications of stochastic optimization where one can benefit from a robust estimate of the gradient. For example, domains such as distributed learning with corrupted nodes, the presence of large outliers in the training data, learning under privacy constraints, or even heavy-tailed noise due to the dynamics of the algorithm itself. Here we study SGD with robust gradient estimators based on estimating the median. We first consider computing the median gradient across samples, and show that the resulting method can converge even under heavy-tailed, state-dependent noise. We then derive iterative methods based on the stochastic proximal point method for computing the geometric median and generalizations thereof. Finally we propose an algorithm estimating the median gradient across iterations, and find that several well known methods - in particular different forms of clipping - are particular cases of this framework.
&lt;/p&gt;</description></item><item><title>PIP-Net&#26159;&#19968;&#20010;&#26032;&#22411;&#26694;&#26550;&#65292;&#36890;&#36807;&#32508;&#21512;&#21033;&#29992;&#21160;&#24577;&#23398;&#25968;&#25454;&#21644;&#22330;&#26223;&#31354;&#38388;&#29305;&#24449;&#65292;&#37319;&#29992;&#24490;&#29615;&#21644;&#26102;&#38388;&#27880;&#24847;&#21147;&#26426;&#21046;&#35299;&#20915;&#26041;&#26696;&#65292;&#25104;&#21151;&#39044;&#27979;&#34892;&#20154;&#36890;&#36807;&#39532;&#36335;&#30340;&#24847;&#22270;&#65292;&#24615;&#33021;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;</title><link>https://arxiv.org/abs/2402.12810</link><description>&lt;p&gt;
PIP-Net&#65306;&#22478;&#24066;&#20013;&#34892;&#20154;&#24847;&#22270;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
PIP-Net: Pedestrian Intention Prediction in the Wild
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12810
&lt;/p&gt;
&lt;p&gt;
PIP-Net&#26159;&#19968;&#20010;&#26032;&#22411;&#26694;&#26550;&#65292;&#36890;&#36807;&#32508;&#21512;&#21033;&#29992;&#21160;&#24577;&#23398;&#25968;&#25454;&#21644;&#22330;&#26223;&#31354;&#38388;&#29305;&#24449;&#65292;&#37319;&#29992;&#24490;&#29615;&#21644;&#26102;&#38388;&#27880;&#24847;&#21147;&#26426;&#21046;&#35299;&#20915;&#26041;&#26696;&#65292;&#25104;&#21151;&#39044;&#27979;&#34892;&#20154;&#36890;&#36807;&#39532;&#36335;&#30340;&#24847;&#22270;&#65292;&#24615;&#33021;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31934;&#20934;&#30340;&#33258;&#21160;&#39550;&#39542;&#36710;&#36742;&#65288;AVs&#65289;&#23545;&#34892;&#20154;&#24847;&#22270;&#30340;&#39044;&#27979;&#26159;&#24403;&#21069;&#35813;&#39046;&#22495;&#30340;&#19968;&#39033;&#30740;&#31350;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;PIP-Net&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#26088;&#22312;&#39044;&#27979;AVs&#22312;&#29616;&#23454;&#19990;&#30028;&#22478;&#24066;&#22330;&#26223;&#20013;&#30340;&#34892;&#20154;&#36807;&#39532;&#36335;&#24847;&#22270;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#31181;&#38024;&#23545;&#19981;&#21516;&#25668;&#20687;&#22836;&#23433;&#35013;&#21644;&#35774;&#32622;&#35774;&#35745;&#30340;PIP-Net&#21464;&#31181;&#12290;&#21033;&#29992;&#26469;&#33258;&#34892;&#39542;&#22330;&#26223;&#30340;&#21160;&#21147;&#23398;&#25968;&#25454;&#21644;&#31354;&#38388;&#29305;&#24449;&#65292;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#37319;&#29992;&#24490;&#29615;&#21644;&#26102;&#38388;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#24615;&#33021;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;&#20026;&#20102;&#22686;&#24378;&#36947;&#36335;&#29992;&#25143;&#30340;&#35270;&#35273;&#34920;&#31034;&#21450;&#20854;&#19982;&#33258;&#36710;&#30340;&#30456;&#20851;&#24615;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20998;&#31867;&#28145;&#24230;&#29305;&#24449;&#22270;&#65292;&#32467;&#21512;&#23616;&#37096;&#36816;&#21160;&#27969;&#29305;&#24449;&#65292;&#20026;&#22330;&#26223;&#21160;&#24577;&#25552;&#20379;&#20016;&#23500;&#30340;&#27934;&#23519;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#23558;&#25668;&#20687;&#22836;&#30340;&#35270;&#37326;&#20174;&#19968;&#20010;&#25193;&#23637;&#21040;&#22260;&#32469;&#33258;&#36710;&#30340;&#19977;&#20010;&#25668;&#20687;&#22836;&#30340;&#24433;&#21709;&#65292;&#20197;&#25552;&#21319;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12810v1 Announce Type: cross  Abstract: Accurate pedestrian intention prediction (PIP) by Autonomous Vehicles (AVs) is one of the current research challenges in this field. In this article, we introduce PIP-Net, a novel framework designed to predict pedestrian crossing intentions by AVs in real-world urban scenarios. We offer two variants of PIP-Net designed for different camera mounts and setups. Leveraging both kinematic data and spatial features from the driving scene, the proposed model employs a recurrent and temporal attention-based solution, outperforming state-of-the-art performance. To enhance the visual representation of road users and their proximity to the ego vehicle, we introduce a categorical depth feature map, combined with a local motion flow feature, providing rich insights into the scene dynamics. Additionally, we explore the impact of expanding the camera's field of view, from one to three cameras surrounding the ego vehicle, leading to enhancement in the
&lt;/p&gt;</description></item><item><title>&#23558;NHPPs&#30340;&#20272;&#35745;&#38382;&#39064;&#36716;&#21270;&#20026;&#23398;&#20064;&#27867;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#27491;&#21017;&#21270;&#23398;&#20064;NHPPs&#30340;&#26694;&#26550;&#19982;&#20004;&#31181;&#26032;&#30340;&#33258;&#36866;&#24212;&#21644;&#25968;&#25454;&#39537;&#21160;&#30340;&#20998;&#31665;&#26041;&#27861;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#25968;&#25454;&#37327;&#26377;&#38480;&#26102;&#36807;&#25311;&#21512;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.12808</link><description>&lt;p&gt;
&#23398;&#20064;&#38750;&#40784;&#27425;&#26102;&#38388;&#27850;&#26494;&#36807;&#31243;&#30340;&#27867;&#21270;&#21644;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Learning Generalization and Regularization of Nonhomogeneous Temporal Poisson Processes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12808
&lt;/p&gt;
&lt;p&gt;
&#23558;NHPPs&#30340;&#20272;&#35745;&#38382;&#39064;&#36716;&#21270;&#20026;&#23398;&#20064;&#27867;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#27491;&#21017;&#21270;&#23398;&#20064;NHPPs&#30340;&#26694;&#26550;&#19982;&#20004;&#31181;&#26032;&#30340;&#33258;&#36866;&#24212;&#21644;&#25968;&#25454;&#39537;&#21160;&#30340;&#20998;&#31665;&#26041;&#27861;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#25968;&#25454;&#37327;&#26377;&#38480;&#26102;&#36807;&#25311;&#21512;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27850;&#26494;&#36807;&#31243;&#65292;&#23588;&#20854;&#26159;&#38750;&#40784;&#27425;&#27850;&#26494;&#36807;&#31243;(NHPP)&#65292;&#26159;&#19968;&#31181;&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#38750;&#24120;&#37325;&#35201;&#30340;&#35745;&#25968;&#36807;&#31243;&#12290;&#30446;&#21069;&#65292;&#25991;&#29486;&#20013;&#20960;&#20046;&#25152;&#26377;&#30340;&#24037;&#20316;&#37117;&#33268;&#21147;&#20110;&#20351;&#29992;&#38750;&#25968;&#25454;&#39537;&#21160;&#30340;&#20998;&#31665;&#26041;&#27861;&#23545;&#20855;&#26377;&#26080;&#31351;&#25968;&#25454;&#30340;NHPP&#36827;&#34892;&#20272;&#35745;&#12290;&#26412;&#25991;&#23558;&#26377;&#38480;&#21644;&#26377;&#38480;&#25968;&#25454;&#19979;&#30340;NHPP&#20272;&#35745;&#38382;&#39064;&#20844;&#24335;&#21270;&#20026;&#19968;&#20010;&#23398;&#20064;&#27867;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#22312;&#25968;&#23398;&#19978;&#35777;&#26126;&#65292;&#23613;&#31649;&#20998;&#31665;&#26041;&#27861;&#23545;&#20110;&#20272;&#35745;NHPPs&#24456;&#37325;&#35201;&#65292;&#20294;&#22312;&#25968;&#25454;&#37327;&#26377;&#38480;&#26102;&#20250;&#24102;&#26469;&#36807;&#25311;&#21512;&#30340;&#39118;&#38505;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#27491;&#21017;&#21270;&#23398;&#20064;NHPPs&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;&#21253;&#25324;&#20004;&#31181;&#26032;&#30340;&#33258;&#36866;&#24212;&#21644;&#25968;&#25454;&#39537;&#21160;&#30340;&#20998;&#31665;&#26041;&#27861;&#65292;&#24110;&#21161;&#28040;&#38500;&#20998;&#31665;&#21442;&#25968;&#30340;&#21363;&#20852;&#35843;&#25972;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12808v1 Announce Type: new  Abstract: The Poisson process, especially the nonhomogeneous Poisson process (NHPP), is an essentially important counting process with numerous real-world applications. Up to date, almost all works in the literature have been on the estimation of NHPPs with infinite data using non-data driven binning methods. In this paper, we formulate the problem of estimation of NHPPs from finite and limited data as a learning generalization problem. We mathematically show that while binning methods are essential for the estimation of NHPPs, they pose a threat of overfitting when the amount of data is limited. We propose a framework for regularized learning of NHPPs with two new adaptive and data-driven binning methods that help to remove the ad-hoc tuning of binning parameters. Our methods are experimentally tested on synthetic and real-world datasets and the results show their effectiveness.
&lt;/p&gt;</description></item><item><title>LS&#20449;&#24687;&#20934;&#21017;&#26088;&#22312;&#22686;&#24378;WBIC&#21644;sBIC&#30340;&#21151;&#33021;&#65292;&#26377;&#25928;&#22788;&#29702;&#38750;&#27491;&#21017;&#24773;&#20917;&#65292;&#20855;&#26377;&#31283;&#23450;&#24615;&#65292;&#20026;&#22855;&#24322;&#24773;&#20917;&#19979;&#30340;&#20449;&#24687;&#20934;&#21017;&#25552;&#20379;&#20102;&#26032;&#30340;&#26041;&#27861;</title><link>https://arxiv.org/abs/2402.12762</link><description>&lt;p&gt;
&#22312;&#22855;&#24322;&#24615;&#19979;&#30340;&#23398;&#20064;&#65306;&#25913;&#36827;WBIC&#21644;sBIC&#30340;&#20449;&#24687;&#20934;&#21017;
&lt;/p&gt;
&lt;p&gt;
Learning under Singularity: An Information Criterion improving WBIC and sBIC
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12762
&lt;/p&gt;
&lt;p&gt;
LS&#20449;&#24687;&#20934;&#21017;&#26088;&#22312;&#22686;&#24378;WBIC&#21644;sBIC&#30340;&#21151;&#33021;&#65292;&#26377;&#25928;&#22788;&#29702;&#38750;&#27491;&#21017;&#24773;&#20917;&#65292;&#20855;&#26377;&#31283;&#23450;&#24615;&#65292;&#20026;&#22855;&#24322;&#24773;&#20917;&#19979;&#30340;&#20449;&#24687;&#20934;&#21017;&#25552;&#20379;&#20102;&#26032;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20449;&#24687;&#20934;&#21017;&#65288;IC&#65289;&#65292;&#31216;&#20026;&#22312;&#22855;&#24322;&#24615;&#19979;&#30340;&#23398;&#20064;&#65288;LS&#65289;&#65292;&#26088;&#22312;&#22686;&#24378;&#24191;&#27867;&#36866;&#29992;&#30340;&#36125;&#21494;&#26031;&#20449;&#24687;&#20934;&#21017;&#65288;WBIC&#65289;&#21644;&#22855;&#24322;&#36125;&#21494;&#26031;&#20449;&#24687;&#20934;&#21017;&#65288;sBIC&#65289;&#30340;&#21151;&#33021;&#12290; LS&#22312;&#27809;&#26377;&#27491;&#21017;&#24615;&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#26159;&#26377;&#25928;&#30340;&#65292;&#24182;&#34920;&#29616;&#20986;&#31283;&#23450;&#24615;&#12290;Watanabe&#23450;&#20041;&#20102;&#19968;&#20010;&#32479;&#35745;&#27169;&#22411;&#25110;&#23398;&#20064;&#26426;&#22120;&#20026;&#27491;&#21017;&#65292;&#22914;&#26524;&#20174;&#21442;&#25968;&#21040;&#27010;&#29575;&#20998;&#24067;&#30340;&#26144;&#23556;&#26159;&#19968;&#23545;&#19968;&#30340;&#65292;&#24182;&#19988;&#20854;Fisher&#20449;&#24687;&#30697;&#38453;&#26159;&#27491;&#23450;&#30340;&#12290;&#30456;&#21453;&#65292;&#19981;&#31526;&#21512;&#36825;&#20123;&#26465;&#20214;&#30340;&#27169;&#22411;&#34987;&#31216;&#20026;&#22855;&#24322;&#12290; &#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#20013;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#20960;&#31181;&#22855;&#24322;&#24773;&#20917;&#19979;&#30340;&#20449;&#24687;&#20934;&#21017;&#65292;&#21253;&#25324;WBIC&#21644;sBIC&#12290; WBIC&#36866;&#29992;&#20110;&#38750;&#27491;&#21017;&#24773;&#20917;&#65292;&#20294;&#22312;&#26679;&#26412;&#37327;&#24456;&#22823;&#19988;&#24050;&#30693;&#23398;&#20064;&#31995;&#25968;&#20272;&#35745;&#20887;&#20313;&#26102;&#38754;&#20020;&#25361;&#25112;&#12290; &#30456;&#21453;&#65292;sBIC&#22312;&#24191;&#27867;&#24212;&#29992;&#26041;&#38754;&#23384;&#22312;&#38480;&#21046;&#65292;&#22240;&#20026;&#23427;&#20381;&#36182;&#20110;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12762v1 Announce Type: cross  Abstract: We introduce a novel Information Criterion (IC), termed Learning under Singularity (LS), designed to enhance the functionality of the Widely Applicable Bayes Information Criterion (WBIC) and the Singular Bayesian Information Criterion (sBIC). LS is effective without regularity constraints and demonstrates stability. Watanabe defined a statistical model or a learning machine as regular if the mapping from a parameter to a probability distribution is one-to-one and its Fisher information matrix is positive definite. In contrast, models not meeting these conditions are termed singular. Over the past decade, several information criteria for singular cases have been proposed, including WBIC and sBIC. WBIC is applicable in non-regular scenarios but faces challenges with large sample sizes and redundant estimation of known learning coefficients. Conversely, sBIC is limited in its broader application due to its dependence on maximum likelihood
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#35777;&#26126;&#20102;&#21518;&#39564;&#25277;&#26679;&#22312;&#35745;&#31639;&#19978;&#26159;&#38590;&#20197;&#35299;&#20915;&#30340;&#65306;&#22312;&#21152;&#23494;&#23398;&#20013;&#26368;&#22522;&#26412;&#30340;&#20551;&#35774;&#19979;&#8212;&#8212;&#21333;&#21521;&#20989;&#25968;&#23384;&#22312;&#30340;&#20551;&#35774;&#19979;&#65292;&#23384;&#22312;&#19968;&#20123;&#23454;&#20363;&#65292;&#23545;&#20110;&#36825;&#20123;&#23454;&#20363;&#65292;&#27599;&#20010;&#31639;&#27861;&#37117;&#38656;&#35201;&#36229;&#22810;&#39033;&#24335;&#26102;&#38388;&#65292;&#21363;&#20351;&#26080;&#26465;&#20214;&#25277;&#26679;&#21487;&#20197;&#35777;&#26126;&#26159;&#24555;&#36895;&#30340;&#12290;</title><link>https://arxiv.org/abs/2402.12727</link><description>&lt;p&gt;
&#25193;&#25955;&#21518;&#39564;&#25277;&#26679;&#22312;&#35745;&#31639;&#19978;&#26159;&#38590;&#20197;&#35299;&#20915;&#30340;
&lt;/p&gt;
&lt;p&gt;
Diffusion Posterior Sampling is Computationally Intractable
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12727
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;&#21518;&#39564;&#25277;&#26679;&#22312;&#35745;&#31639;&#19978;&#26159;&#38590;&#20197;&#35299;&#20915;&#30340;&#65306;&#22312;&#21152;&#23494;&#23398;&#20013;&#26368;&#22522;&#26412;&#30340;&#20551;&#35774;&#19979;&#8212;&#8212;&#21333;&#21521;&#20989;&#25968;&#23384;&#22312;&#30340;&#20551;&#35774;&#19979;&#65292;&#23384;&#22312;&#19968;&#20123;&#23454;&#20363;&#65292;&#23545;&#20110;&#36825;&#20123;&#23454;&#20363;&#65292;&#27599;&#20010;&#31639;&#27861;&#37117;&#38656;&#35201;&#36229;&#22810;&#39033;&#24335;&#26102;&#38388;&#65292;&#21363;&#20351;&#26080;&#26465;&#20214;&#25277;&#26679;&#21487;&#20197;&#35777;&#26126;&#26159;&#24555;&#36895;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#26159;&#23398;&#20064;&#21644;&#20174;&#20998;&#24067;$p(x)$&#20013;&#25277;&#26679;&#30340;&#19968;&#31181;&#38750;&#24120;&#26377;&#25928;&#30340;&#26041;&#27861;&#12290;&#22312;&#21518;&#39564;&#25277;&#26679;&#20013;&#65292;&#20154;&#20204;&#36824;&#20250;&#32473;&#20986;&#19968;&#20010;&#27979;&#37327;&#27169;&#22411;$p(y \mid x)$&#21644;&#19968;&#20010;&#27979;&#37327;$y$&#65292;&#24076;&#26395;&#20174;$p(x \mid y)$&#20013;&#25277;&#26679;&#12290;&#21518;&#39564;&#25277;&#26679;&#23545;&#20110;&#35832;&#22914;&#20462;&#34917;&#12289;&#36229;&#20998;&#36776;&#29575;&#21644;MRI&#37325;&#24314;&#31561;&#20219;&#21153;&#38750;&#24120;&#26377;&#29992;&#65292;&#22240;&#27492;&#19968;&#20123;&#26368;&#36817;&#30340;&#24037;&#20316;&#24050;&#32463;&#32473;&#20986;&#20102;&#21551;&#21457;&#24335;&#36817;&#20284;&#31639;&#27861;&#65307;&#20294;&#27809;&#26377;&#19968;&#20010;&#24050;&#30693;&#33021;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#25910;&#25947;&#21040;&#27491;&#30830;&#30340;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12727v1 Announce Type: cross  Abstract: Diffusion models are a remarkably effective way of learning and sampling from a distribution $p(x)$. In posterior sampling, one is also given a measurement model $p(y \mid x)$ and a measurement $y$, and would like to sample from $p(x \mid y)$. Posterior sampling is useful for tasks such as inpainting, super-resolution, and MRI reconstruction, so a number of recent works have given algorithms to heuristically approximate it; but none are known to converge to the correct distribution in polynomial time.   In this paper we show that posterior sampling is \emph{computationally intractable}: under the most basic assumption in cryptography -- that one-way functions exist -- there are instances for which \emph{every} algorithm takes superpolynomial time, even though \emph{unconditional} sampling is provably fast. We also show that the exponential-time rejection sampling algorithm is essentially optimal under the stronger plausible assumption 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#32479;&#19968;&#26368;&#21518;&#36845;&#20195;(ULI)&#20445;&#35777;&#36825;&#19968;&#26356;&#24378;&#30340;&#24615;&#33021;&#24230;&#37327;&#65292;&#21516;&#26102;&#35777;&#26126;&#25509;&#36817;&#26368;&#20248;&#30340;ULI&#20445;&#35777;&#30452;&#25509;&#23548;&#33268;&#20102;&#22312;&#21508;&#31181;&#24615;&#33021;&#24230;&#37327;&#19978;&#25509;&#36817;&#26368;&#20248;&#30340;&#32047;&#31215;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.12711</link><description>&lt;p&gt;
&#20855;&#26377;&#32479;&#19968;&#26368;&#21518;&#36845;&#20195;&#20445;&#35777;&#30340;&#36172;&#21338;&#31639;&#27861;&#23454;&#29616;&#25509;&#36817;&#26368;&#20248;&#36951;&#25022;
&lt;/p&gt;
&lt;p&gt;
Achieving Near-Optimal Regret for Bandit Algorithms with Uniform Last-Iterate Guarantee
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12711
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#32479;&#19968;&#26368;&#21518;&#36845;&#20195;(ULI)&#20445;&#35777;&#36825;&#19968;&#26356;&#24378;&#30340;&#24615;&#33021;&#24230;&#37327;&#65292;&#21516;&#26102;&#35777;&#26126;&#25509;&#36817;&#26368;&#20248;&#30340;ULI&#20445;&#35777;&#30452;&#25509;&#23548;&#33268;&#20102;&#22312;&#21508;&#31181;&#24615;&#33021;&#24230;&#37327;&#19978;&#25509;&#36817;&#26368;&#20248;&#30340;&#32047;&#31215;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#36172;&#21338;&#31639;&#27861;&#24615;&#33021;&#24230;&#37327;&#65292;&#22914;&#36951;&#25022;&#12289;PAC&#30028;&#38480;&#25110;&#32479;&#19968;PAC(Dann&#31561;&#20154;&#65292;2017)&#65292;&#36890;&#24120;&#35780;&#20272;&#32047;&#31215;&#24615;&#33021;&#65292;&#21516;&#26102;&#20801;&#35768;&#22312;&#20219;&#24847;&#26377;&#38480;&#26102;&#38388;t&#20869;&#29609;&#24369;&#21155;&#30340;&#33218;&#12290;&#36825;&#31181;&#34892;&#20026;&#22312;&#39640;&#39118;&#38505;&#24212;&#29992;&#20013;&#21487;&#33021;&#36896;&#25104;&#20005;&#37325;&#25439;&#22833;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26356;&#24378;&#30340;&#24615;&#33021;&#24230;&#37327;&#65292;&#32479;&#19968;&#26368;&#21518;&#36845;&#20195;(ULI)&#20445;&#35777;&#65292;&#25429;&#25417;&#36172;&#21338;&#31639;&#27861;&#30340;&#32047;&#31215;&#21644;&#30636;&#26102;&#24615;&#33021;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;ULI&#34920;&#24449;&#20102;&#30636;&#26102;&#24615;&#33021;&#65292;&#22240;&#20026;&#23427;&#30830;&#20445;&#25152;&#29609;&#24369;&#21155;&#33218;&#30340;&#27599;&#36718;&#36951;&#25022;&#21463;&#21040;&#19968;&#20010;&#20989;&#25968;&#30340;&#38480;&#21046;&#65292;&#35813;&#20989;&#25968;&#38543;&#30528;&#65288;&#22823;&#65289;&#36718;&#27425;t&#21333;&#35843;&#36882;&#20943;&#65292;&#22312;&#26377;&#36275;&#22815;&#26679;&#26412;&#21487;&#29992;&#26102;&#38450;&#27490;&#37325;&#22797;&#35775;&#38382;&#21155;&#36136;&#33218;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#25509;&#36817;&#26368;&#20248;&#30340;ULI&#20445;&#35777;&#30452;&#25509;&#24847;&#21619;&#30528;&#22312;&#19978;&#36848;&#24615;&#33021;&#24230;&#37327;&#20013;&#23454;&#29616;&#25509;&#36817;&#26368;&#20248;&#30340;&#32047;&#31215;&#24615;&#33021;&#12290;&#20026;&#20102;&#30740;&#31350;ULI&#22312;&#26377;&#38480;&#33218;&#38598;&#19978;&#30340;&#21487;&#36798;&#24615;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12711v1 Announce Type: new  Abstract: Existing performance measures for bandit algorithms such as regret, PAC bounds, or uniform-PAC (Dann et al., 2017), typically evaluate the cumulative performance, while allowing the play of an arbitrarily bad arm at any finite time t. Such a behavior can be highly detrimental in high-stakes applications. This paper introduces a stronger performance measure, the uniform last-iterate (ULI) guarantee, capturing both cumulative and instantaneous performance of bandit algorithms. Specifically, ULI characterizes the instantaneous performance since it ensures that the per-round regret of the played arm is bounded by a function, monotonically decreasing w.r.t. (large) round t, preventing revisits to bad arms when sufficient samples are available. We demonstrate that a near-optimal ULI guarantee directly implies near-optimal cumulative performance across aforementioned performance measures. To examine the achievability of ULI in the finite arm se
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;ACI&#65292;&#19987;&#27880;&#20110;&#22312;&#32593;&#32476;&#24178;&#25200;&#21644;&#38750;&#38543;&#26426;&#22788;&#29702;&#20998;&#37197;&#24773;&#20917;&#19979;&#20272;&#35745;&#30452;&#25509;&#21644;&#28322;&#20986;&#22788;&#29702;&#25928;&#24212;&#12290;</title><link>https://arxiv.org/abs/2402.12710</link><description>&lt;p&gt;
&#22312;&#22240;&#26524;&#25512;&#26029;&#20013;&#25972;&#21512;&#24178;&#39044;&#23398;&#20064;&#65306;&#22312;&#32447;&#23454;&#39564;&#20013;&#19968;&#31181;&#26032;&#39062;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Integrating Active Learning in Causal Inference with Interference: A Novel Approach in Online Experiments
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12710
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;ACI&#65292;&#19987;&#27880;&#20110;&#22312;&#32593;&#32476;&#24178;&#25200;&#21644;&#38750;&#38543;&#26426;&#22788;&#29702;&#20998;&#37197;&#24773;&#20917;&#19979;&#20272;&#35745;&#30452;&#25509;&#21644;&#28322;&#20986;&#22788;&#29702;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22240;&#26524;&#25512;&#26029;&#30740;&#31350;&#39046;&#22495;&#20013;&#65292;&#26222;&#36941;&#30340;&#28508;&#22312;&#32467;&#26524;&#26694;&#26550;&#65292;&#23588;&#20854;&#26159;&#40065;&#23486;&#22240;&#26524;&#27169;&#22411;&#65288;RCM&#65289;&#65292;&#36890;&#24120;&#24573;&#35270;&#20010;&#20307;&#24178;&#25200;&#24182;&#20551;&#35774;&#29420;&#31435;&#22788;&#29702;&#25928;&#24212;&#12290;&#28982;&#32780;&#65292;&#36825;&#19968;&#20551;&#35774;&#32463;&#24120;&#19982;&#29616;&#23454;&#19990;&#30028;&#22330;&#26223;&#30340;&#22797;&#26434;&#29616;&#23454;&#19981;&#31526;&#65292;&#24178;&#25200;&#19981;&#20165;&#20165;&#26159;&#21487;&#33021;&#24615;&#65292;&#32780;&#19988;&#26159;&#24120;&#35265;&#29616;&#35937;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#19987;&#27880;&#20110;&#22312;&#20004;&#31181;&#20551;&#35774;&#19979;&#20272;&#35745;&#30452;&#25509;&#21644;&#28322;&#20986;&#22788;&#29702;&#25928;&#24212;&#26469;&#35299;&#20915;&#36825;&#19968;&#24046;&#24322;&#65306;&#65288;1&#65289;&#22522;&#20110;&#32593;&#32476;&#30340;&#24178;&#25200;&#65292;&#20854;&#20013;&#36830;&#25509;&#32593;&#32476;&#20869;&#37051;&#23621;&#30340;&#22788;&#29702;&#20250;&#24433;&#21709;&#19968;&#20010;&#20154;&#30340;&#32467;&#26524;&#65292;&#20197;&#21450;&#65288;2&#65289;&#21463;&#28151;&#26434;&#22240;&#32032;&#24433;&#21709;&#30340;&#38750;&#38543;&#26426;&#22788;&#29702;&#20998;&#37197;&#12290;&#20026;&#20102;&#25552;&#39640;&#20272;&#35745;&#21487;&#33021;&#22797;&#26434;&#25928;&#26524;&#20989;&#25968;&#30340;&#25928;&#29575;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;: &#20132;&#20114;&#24178;&#39044;&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#20027;&#21160;&#23398;&#20064;&#65288;ACI&#65289;&#12290;&#36825;&#31181;&#26041;&#27861;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#28789;&#27963;&#22320;mo
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12710v1 Announce Type: cross  Abstract: In the domain of causal inference research, the prevalent potential outcomes framework, notably the Rubin Causal Model (RCM), often overlooks individual interference and assumes independent treatment effects. This assumption, however, is frequently misaligned with the intricate realities of real-world scenarios, where interference is not merely a possibility but a common occurrence. Our research endeavors to address this discrepancy by focusing on the estimation of direct and spillover treatment effects under two assumptions: (1) network-based interference, where treatments on neighbors within connected networks affect one's outcomes, and (2) non-random treatment assignments influenced by confounders. To improve the efficiency of estimating potentially complex effects functions, we introduce an novel active learning approach: Active Learning in Causal Inference with Interference (ACI). This approach uses Gaussian process to flexibly mo
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#27969;&#24418;&#23398;&#20064;&#30340;&#22312;&#27969;&#24418;&#19978;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#19968;&#27425;&#24615;&#26500;&#36896;&#33719;&#24471;&#26368;&#20339;&#35823;&#24046;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.12687</link><description>&lt;p&gt;
&#22312;&#27969;&#24418;&#19978;&#23398;&#20064;&#32780;&#26080;&#38656;&#27969;&#24418;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Learning on manifolds without manifold learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12687
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#27969;&#24418;&#23398;&#20064;&#30340;&#22312;&#27969;&#24418;&#19978;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#19968;&#27425;&#24615;&#26500;&#36896;&#33719;&#24471;&#26368;&#20339;&#35823;&#24046;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#26410;&#30693;&#20998;&#24067;&#38543;&#26426;&#25277;&#26679;&#30340;&#25968;&#25454;&#36827;&#34892;&#20989;&#25968;&#36924;&#36817;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#12290;&#19982;&#36890;&#36807;&#26368;&#23567;&#21270;&#25439;&#22833;&#20989;&#25968;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#30427;&#34892;&#33539;&#24335;&#30456;&#21453;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#31181;&#30452;&#25509;&#30340;&#19968;&#27425;&#24615;&#26500;&#36896;&#26041;&#27861;&#65292;&#24182;&#22312;&#27969;&#24418;&#20551;&#35774;&#19979;&#32473;&#20986;&#20102;&#26368;&#20339;&#35823;&#24046;&#30028;&#38480;&#65307;&#21363;&#20551;&#35774;&#25968;&#25454;&#26159;&#20174;&#39640;&#32500;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#30340;&#26410;&#30693;&#23376;&#27969;&#24418;&#20013;&#25277;&#26679;&#24471;&#21040;&#30340;&#12290; Neural Networks 132:253268, 2020 &#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#19968;&#27425;&#24615;&#30452;&#25509;&#26041;&#27861;&#26469;&#23454;&#29616;&#20989;&#25968;&#36924;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12687v1 Announce Type: new  Abstract: Function approximation based on data drawn randomly from an unknown distribution is an important problem in machine learning. In contrast to the prevalent paradigm of solving this problem by minimizing a loss functional, we have given a direct one-shot construction together with optimal error bounds under the manifold assumption; i.e., one assumes that the data is sampled from an unknown sub-manifold of a high dimensional Euclidean space. A great deal of research deals with obtaining information about this manifold, such as the eigendecomposition of the Laplace-Beltrami operator or coordinate charts, and using this information for function approximation. This two step approach implies some extra errors in the approximation stemming from basic quantities of the data in addition to the errors inherent in function approximation. In Neural Networks, 132:253268, 2020, we have proposed a one-shot direct method to achieve function approximation
&lt;/p&gt;</description></item><item><title>&#38543;&#26426;&#26862;&#26519;&#30456;&#23545;&#20110;&#35013;&#34955;&#27861;&#20855;&#26377;&#20943;&#23569;&#20559;&#24046;&#30340;&#33021;&#21147;&#65292;&#22312;&#25581;&#31034;&#25968;&#25454;&#27169;&#24335;&#21644;&#39640;&#20449;&#22122;&#27604;&#24773;&#20917;&#19979;&#34920;&#29616;&#26356;&#22909;&#30340;&#29305;&#28857;&#65292;&#20026;&#38543;&#26426;&#26862;&#26519;&#22312;&#19981;&#21516;&#20449;&#22122;&#27604;&#29615;&#22659;&#19979;&#30340;&#25104;&#21151;&#25552;&#20379;&#20102;&#35299;&#37322;&#21644;&#23454;&#29992;&#35265;&#35299;&#12290;</title><link>https://arxiv.org/abs/2402.12668</link><description>&lt;p&gt;
&#38543;&#26426;&#21270;&#26082;&#21487;&#20197;&#20943;&#23569;&#20559;&#24046;&#21448;&#21487;&#20197;&#20943;&#23569;&#26041;&#24046;&#65306;&#38543;&#26426;&#26862;&#26519;&#30340;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Randomization Can Reduce Both Bias and Variance: A Case Study in Random Forests
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12668
&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26862;&#26519;&#30456;&#23545;&#20110;&#35013;&#34955;&#27861;&#20855;&#26377;&#20943;&#23569;&#20559;&#24046;&#30340;&#33021;&#21147;&#65292;&#22312;&#25581;&#31034;&#25968;&#25454;&#27169;&#24335;&#21644;&#39640;&#20449;&#22122;&#27604;&#24773;&#20917;&#19979;&#34920;&#29616;&#26356;&#22909;&#30340;&#29305;&#28857;&#65292;&#20026;&#38543;&#26426;&#26862;&#26519;&#22312;&#19981;&#21516;&#20449;&#22122;&#27604;&#29615;&#22659;&#19979;&#30340;&#25104;&#21151;&#25552;&#20379;&#20102;&#35299;&#37322;&#21644;&#23454;&#29992;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#24448;&#24448;&#34987;&#24573;&#35270;&#30340;&#29616;&#35937;&#65292;&#39318;&#27425;&#22312;\cite{breiman2001random}&#20013;&#25351;&#20986;&#65292;&#21363;&#38543;&#26426;&#26862;&#26519;&#20284;&#20046;&#27604;&#35013;&#34955;&#27861;&#20943;&#23569;&#20102;&#20559;&#24046;&#12290;&#21463;\cite{mentch2020randomization}&#19968;&#31687;&#26377;&#36259;&#30340;&#35770;&#25991;&#30340;&#21551;&#21457;&#65292;&#20854;&#20013;&#20316;&#32773;&#35748;&#20026;&#38543;&#26426;&#26862;&#26519;&#20943;&#23569;&#20102;&#26377;&#25928;&#33258;&#30001;&#24230;&#65292;&#24182;&#19988;&#21482;&#26377;&#22312;&#20302;&#20449;&#22122;&#27604;&#65288;SNR&#65289;&#29615;&#22659;&#19979;&#25165;&#33021;&#32988;&#36807;&#35013;&#34955;&#38598;&#25104;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#38543;&#26426;&#26862;&#26519;&#22914;&#20309;&#33021;&#22815;&#25581;&#31034;&#34987;&#35013;&#34955;&#27861;&#24573;&#35270;&#30340;&#25968;&#25454;&#27169;&#24335;&#12290;&#25105;&#20204;&#22312;&#23454;&#35777;&#20013;&#35777;&#26126;&#65292;&#22312;&#23384;&#22312;&#36825;&#31181;&#27169;&#24335;&#30340;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#26862;&#26519;&#19981;&#20165;&#21487;&#20197;&#20943;&#23567;&#20559;&#24046;&#36824;&#33021;&#20943;&#23567;&#26041;&#24046;&#65292;&#24182;&#19988;&#24403;&#20449;&#22122;&#27604;&#39640;&#26102;&#38543;&#26426;&#26862;&#26519;&#30340;&#34920;&#29616;&#24840;&#21457;&#22909;&#20110;&#35013;&#34955;&#38598;&#25104;&#12290;&#25105;&#20204;&#30340;&#35266;&#23519;&#20026;&#35299;&#37322;&#38543;&#26426;&#26862;&#26519;&#22312;&#21508;&#31181;&#20449;&#22122;&#27604;&#24773;&#20917;&#19979;&#30340;&#30495;&#23454;&#19990;&#30028;&#25104;&#21151;&#25552;&#20379;&#20102;&#35265;&#35299;&#65292;&#24182;&#22686;&#36827;&#20102;&#25105;&#20204;&#23545;&#38543;&#26426;&#26862;&#26519;&#19982;&#35013;&#34955;&#38598;&#25104;&#22312;&#27599;&#27425;&#20998;&#21106;&#27880;&#20837;&#30340;&#38543;&#26426;&#21270;&#26041;&#38754;&#30340;&#24046;&#24322;&#30340;&#29702;&#35299;&#12290;&#25105;&#20204;&#30340;&#35843;&#26597;&#32467;&#26524;&#36824;&#25552;&#20379;&#20102;&#23454;&#29992;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12668v1 Announce Type: cross  Abstract: We study the often overlooked phenomenon, first noted in \cite{breiman2001random}, that random forests appear to reduce bias compared to bagging. Motivated by an interesting paper by \cite{mentch2020randomization}, where the authors argue that random forests reduce effective degrees of freedom and only outperform bagging ensembles in low signal-to-noise ratio (SNR) settings, we explore how random forests can uncover patterns in the data missed by bagging. We empirically demonstrate that in the presence of such patterns, random forests reduce bias along with variance and increasingly outperform bagging ensembles when SNR is high. Our observations offer insights into the real-world success of random forests across a range of SNRs and enhance our understanding of the difference between random forests and bagging ensembles with respect to the randomization injected into each split. Our investigations also yield practical insights into the 
&lt;/p&gt;</description></item><item><title>FAST&#26694;&#26550;&#36890;&#36807;&#24555;&#36895;&#20998;&#27573;&#24418;&#29366;&#20989;&#25968;&#30340;&#20248;&#21270;&#21644;&#26032;&#30340;&#29305;&#24449;&#36873;&#25321;&#31639;&#27861;&#65292;&#20351;&#24471;&#36879;&#26126;&#30340;&#38468;&#21152;&#27169;&#22411;&#30340;&#25311;&#21512;&#36895;&#24230;&#27604;&#29616;&#26377;&#26041;&#27861;&#24555;2&#20010;&#25968;&#37327;&#32423;&#12290;</title><link>https://arxiv.org/abs/2402.12630</link><description>&lt;p&gt;
FAST: &#19968;&#31181;&#29992;&#20110;&#24555;&#36895;&#36879;&#26126;&#26426;&#22120;&#23398;&#20064;&#20013;&#24555;&#36895;&#38468;&#21152;&#20998;&#21106;&#30340;&#20248;&#21270;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
FAST: An Optimization Framework for Fast Additive Segmentation in Transparent ML
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12630
&lt;/p&gt;
&lt;p&gt;
FAST&#26694;&#26550;&#36890;&#36807;&#24555;&#36895;&#20998;&#27573;&#24418;&#29366;&#20989;&#25968;&#30340;&#20248;&#21270;&#21644;&#26032;&#30340;&#29305;&#24449;&#36873;&#25321;&#31639;&#27861;&#65292;&#20351;&#24471;&#36879;&#26126;&#30340;&#38468;&#21152;&#27169;&#22411;&#30340;&#25311;&#21512;&#36895;&#24230;&#27604;&#29616;&#26377;&#26041;&#27861;&#24555;2&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;FAST&#65292;&#19968;&#31181;&#29992;&#20110;&#24555;&#36895;&#38468;&#21152;&#20998;&#21106;&#30340;&#20248;&#21270;&#26694;&#26550;&#12290;FAST&#20026;&#25968;&#25454;&#38598;&#20013;&#30340;&#27599;&#20010;&#29305;&#24449;&#20998;&#27573;&#24120;&#25968;&#24418;&#29366;&#20989;&#25968;&#65292;&#20197;&#20135;&#29983;&#36879;&#26126;&#30340;&#38468;&#21152;&#27169;&#22411;&#12290;&#35813;&#26694;&#26550;&#21033;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#20248;&#21270;&#36807;&#31243;&#36866;&#37197;&#36825;&#20123;&#27169;&#22411;&#65292;&#36895;&#24230;&#27604;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#65292;&#22914;&#21487;&#35299;&#37322;&#24615;&#22686;&#24378;&#26426;&#22120; \citep{nori2019interpretml}&#65292;&#24555;&#32422;2&#20010;&#25968;&#37327;&#32423;&#12290;&#25105;&#20204;&#36824;&#22312;FAST&#26694;&#26550;&#20013;&#24320;&#21457;&#20102;&#26032;&#30340;&#29305;&#24449;&#36873;&#25321;&#31639;&#27861;&#65292;&#20197;&#36866;&#37197;&#24615;&#33021;&#33391;&#22909;&#30340;&#31616;&#32422;&#27169;&#22411;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;FAST&#25552;&#39640;&#20102;&#38468;&#21152;&#27169;&#22411;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12630v1 Announce Type: cross  Abstract: We present FAST, an optimization framework for fast additive segmentation. FAST segments piecewise constant shape functions for each feature in a dataset to produce transparent additive models. The framework leverages a novel optimization procedure to fit these models $\sim$2 orders of magnitude faster than existing state-of-the-art methods, such as explainable boosting machines \citep{nori2019interpretml}. We also develop new feature selection algorithms in the FAST framework to fit parsimonious models that perform well. Through experiments and case studies, we show that FAST improves the computational efficiency and interpretability of additive models.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#31070;&#32463;&#32593;&#32476;&#21644;&#20449;&#21495;&#26102;&#38388;&#36923;&#36753;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22810;&#31867;&#21035;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#20998;&#31867;&#65292;&#20851;&#38190;&#36129;&#29486;&#21253;&#25324;&#24341;&#20837;&#36793;&#30028;&#27010;&#24565;&#21644;&#21033;&#29992;STL&#23646;&#24615;&#22686;&#24378;&#32467;&#26524;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.12397</link><description>&lt;p&gt;
&#22810;&#31867;&#21035;&#26102;&#38388;&#36923;&#36753;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Multi-class Temporal Logic Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12397
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#31070;&#32463;&#32593;&#32476;&#21644;&#20449;&#21495;&#26102;&#38388;&#36923;&#36753;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22810;&#31867;&#21035;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#20998;&#31867;&#65292;&#20851;&#38190;&#36129;&#29486;&#21253;&#25324;&#24341;&#20837;&#36793;&#30028;&#27010;&#24565;&#21644;&#21033;&#29992;STL&#23646;&#24615;&#22686;&#24378;&#32467;&#26524;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#21487;&#20197;&#20195;&#34920;&#26080;&#20154;&#31995;&#32479;&#65288;&#22914;&#26080;&#20154;&#26426;&#21644;&#33258;&#21160;&#39550;&#39542;&#27773;&#36710;&#65289;&#30340;&#34892;&#20026;&#12290;&#22312;&#36825;&#19968;&#39046;&#22495;&#65292;&#20108;&#20803;&#21644;&#22810;&#31867;&#21035;&#20998;&#31867;&#38382;&#39064;&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#31070;&#32463;&#32593;&#32476;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#20998;&#31867;&#25968;&#25454;&#30340;&#26041;&#27861;&#65307;&#28982;&#32780;&#65292;&#23427;&#20204;&#32570;&#20047;&#21487;&#35299;&#37322;&#24615;&#65292;&#36825;&#22312;&#20174;&#20013;&#25552;&#21462;&#26377;&#24847;&#20041;&#30340;&#20449;&#24687;&#26041;&#38754;&#26500;&#25104;&#20102;&#37325;&#35201;&#25361;&#25112;&#12290;&#20449;&#21495;&#26102;&#38388;&#36923;&#36753;&#65288;STL&#65289;&#26159;&#19968;&#31181;&#25551;&#36848;&#23450;&#26102;&#34892;&#20026;&#23646;&#24615;&#30340;&#24418;&#24335;&#21270;&#35821;&#35328;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#25152;&#26377;&#36825;&#20123;&#20803;&#32032;&#32467;&#21512;&#22312;&#19968;&#36215;&#30340;&#26041;&#27861;&#65306;&#20351;&#29992;&#34920;&#31034;STL&#35268;&#33539;&#30340;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#22810;&#31867;&#21035;&#20998;&#31867;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#20010;&#20851;&#38190;&#36129;&#29486;&#65306;1&#65289;&#25105;&#20204;&#24341;&#20837;&#20102;&#22810;&#31867;&#21035;&#20998;&#31867;&#30340;&#36793;&#30028;&#27010;&#24565;&#65292;2&#65289;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;STL&#30340;&#23646;&#24615;&#26469;&#22686;&#24378;&#32467;&#26524;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#24182;&#19982;&#26368;&#20808;&#36827;&#30340;&#22522;&#20934;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12397v1 Announce Type: cross  Abstract: Time-series data can represent the behaviors of autonomous systems, such as drones and self-driving cars. The problem of binary and multi-class classification has received a lot of attention in this field. Neural networks represent a popular approach to classifying data; However, they lack interpretability, which poses a significant challenge in extracting meaningful information from them. Signal Temporal Logic (STL) is a formalism to describe the properties of timed behaviors. We propose a method that combines all of the above: neural networks that represent STL specifications for multi-class classification of time-series data. We offer two key contributions: 1) We introduce a notion of margin for multi-class classification, and 2) we introduce the use of STL-based attributes for enhancing the interpretability of the results. We evaluate our method on two datasets and compare with state-of-the-art baselines.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#20351;&#29992;&#19981;&#21516;&#26631;&#27880;&#20989;&#25968;&#30340;&#21327;&#20316;&#23398;&#20064;&#20013;&#65292;&#22522;&#20110;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31639;&#27861;&#22312;&#22686;&#24378;&#20551;&#35774;&#31867;&#19978;&#30340;&#39640;&#25928;&#23398;&#20064;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.10445</link><description>&lt;p&gt;
&#20351;&#29992;&#19981;&#21516;&#26631;&#27880;&#20989;&#25968;&#30340;&#21327;&#20316;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Collaborative Learning with Different Labeling Functions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10445
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#20351;&#29992;&#19981;&#21516;&#26631;&#27880;&#20989;&#25968;&#30340;&#21327;&#20316;&#23398;&#20064;&#20013;&#65292;&#22522;&#20110;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31639;&#27861;&#22312;&#22686;&#24378;&#20551;&#35774;&#31867;&#19978;&#30340;&#39640;&#25928;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181; Collaborative PAC Learning &#30340;&#21464;&#20307;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#26088;&#22312;&#23398;&#20064;&#27599;&#20010;$n$&#20010;&#25968;&#25454;&#20998;&#24067;&#30340;&#20934;&#30830;&#20998;&#31867;&#22120;&#65292;&#21516;&#26102;&#26368;&#23567;&#21270;&#20174;&#23427;&#20204;&#24635;&#20849;&#25277;&#21462;&#30340;&#26679;&#26412;&#25968;&#37327;&#12290;&#19982;&#36890;&#24120;&#30340;&#21327;&#20316;&#23398;&#20064;&#35774;&#32622;&#19981;&#21516;&#65292;&#19981;&#20551;&#35774;&#23384;&#22312;&#19968;&#20010;&#21516;&#26102;&#23545;&#25152;&#26377;&#20998;&#24067;&#20934;&#30830;&#30340;&#21333;&#19968;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#24403;&#25968;&#25454;&#20998;&#24067;&#28385;&#36275;&#36739;&#24369;&#30340;&#21487;&#23454;&#29616;&#24615;&#20551;&#35774;&#26102;&#65292;&#20173;&#28982;&#21487;&#20197;&#23454;&#29616;&#39640;&#25928;&#30340;&#23398;&#20064;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;(ERM)&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#24212;&#29992;&#20110;&#20551;&#35774;&#31867;&#30340;&#19968;&#20010;&#33258;&#28982;&#22686;&#24378;&#65292;&#20998;&#26512;&#20381;&#36182;&#20110;&#23545;&#35813;&#22686;&#24378;&#31867;&#30340;VC&#32500;&#30340;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10445v1 Announce Type: new  Abstract: We study a variant of Collaborative PAC Learning, in which we aim to learn an accurate classifier for each of the $n$ data distributions, while minimizing the number of samples drawn from them in total. Unlike in the usual collaborative learning setup, it is not assumed that there exists a single classifier that is simultaneously accurate for all distributions.   We show that, when the data distributions satisfy a weaker realizability assumption, sample-efficient learning is still feasible. We give a learning algorithm based on Empirical Risk Minimization (ERM) on a natural augmentation of the hypothesis class, and the analysis relies on an upper bound on the VC dimension of this augmented class.   In terms of the computational efficiency, we show that ERM on the augmented hypothesis class is NP-hard, which gives evidence against the existence of computationally efficient learners in general. On the positive side, for two special cases, 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#25552;&#31034;&#23398;&#20064;&#20013;&#32771;&#34385;&#26377;&#38480;&#39044;&#31639;&#32422;&#26463;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24314;&#31435;&#25552;&#31034;&#23398;&#20064;&#21644;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;TRIPLE&#65292;&#36890;&#36807;&#21033;&#29992;&#32858;&#31867;&#21644;&#23884;&#20837;&#24605;&#24819;&#23454;&#29616;&#20102;&#20004;&#20010;&#22686;&#24378;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.09723</link><description>&lt;p&gt;
&#26377;&#38480;&#39044;&#31639;&#19979;&#30340;&#36805;&#36895;&#23398;&#20064;&#26368;&#20339;&#33218;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Best Arm Identification for Prompt Learning under a Limited Budget
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09723
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#25552;&#31034;&#23398;&#20064;&#20013;&#32771;&#34385;&#26377;&#38480;&#39044;&#31639;&#32422;&#26463;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24314;&#31435;&#25552;&#31034;&#23398;&#20064;&#21644;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;TRIPLE&#65292;&#36890;&#36807;&#21033;&#29992;&#32858;&#31867;&#21644;&#23884;&#20837;&#24605;&#24819;&#23454;&#29616;&#20102;&#20004;&#20010;&#22686;&#24378;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#26174;&#33879;&#25351;&#20196;&#36319;&#38543;&#33021;&#21147;&#24341;&#21457;&#20102;&#23545;&#33258;&#21160;&#23398;&#20064;&#21512;&#36866;&#25552;&#31034;&#30340;&#20852;&#36259;&#12290;&#28982;&#32780;&#65292;&#34429;&#28982;&#25552;&#20986;&#20102;&#35768;&#22810;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#20294;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#20135;&#29983;&#30340;&#25104;&#26412;&#65288;&#20363;&#22914;&#35775;&#38382;LLM&#21644;&#35780;&#20272;&#21709;&#24212;&#65289;&#23578;&#26410;&#24471;&#21040;&#32771;&#34385;&#12290;&#20026;&#20811;&#26381;&#36825;&#20010;&#38480;&#21046;&#65292;&#26412;&#24037;&#20316;&#22312;&#25552;&#31034;&#23398;&#20064;&#20013;&#26126;&#30830;&#24341;&#20837;&#20102;&#26377;&#38480;&#39044;&#31639;&#32422;&#26463;&#12290;&#20026;&#20102;&#24320;&#21457;&#26377;&#21407;&#21017;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#26412;&#30740;&#31350;&#22312;&#25552;&#31034;&#23398;&#20064;&#21644;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#65288;BAI-FB&#65289;&#20043;&#38388;&#24314;&#31435;&#20102;&#19968;&#31181;&#26032;&#30340;&#32852;&#31995;&#12290;&#22522;&#20110;&#36825;&#31181;&#32852;&#31995;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;TRIPLE&#65288;&#29992;&#20110;&#25552;&#31034;&#23398;&#20064;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#65289;&#65292;&#20197;&#31995;&#32479;&#22320;&#21033;&#29992;BAI-FB&#22312;&#25552;&#31034;&#23398;&#20064;&#20013;&#30340;&#21147;&#37327;&#12290;&#25552;&#31034;&#23398;&#20064;&#30340;&#29420;&#29305;&#29305;&#28857;&#36827;&#19968;&#27493;&#36890;&#36807;&#21033;&#29992;&#32858;&#31867;&#21644;&#23884;&#20837;&#24605;&#24819;&#25552;&#20986;&#20102;TRIPLE&#30340;&#20004;&#20010;&#22522;&#20110;&#23884;&#20837;&#30340;&#22686;&#24378;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09723v1 Announce Type: cross  Abstract: The remarkable instruction-following capability of large language models (LLMs) has sparked a growing interest in automatically learning suitable prompts. However, while many effective methods have been proposed, the cost incurred during the learning process (e.g., accessing LLM and evaluating the responses) has not been considered. To overcome this limitation, this work explicitly incorporates a finite budget constraint into prompt learning. Towards developing principled solutions, a novel connection is established between prompt learning and fixed-budget best arm identification (BAI-FB) in multi-armed bandits (MAB). Based on this connection, a general framework TRIPLE (besT aRm Identification for Prompt LEarning) is proposed to harness the power of BAI-FB in prompt learning systematically. Unique characteristics of prompt learning further lead to two embedding-based enhancements of TRIPLE by exploiting the ideas of clustering and fun
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#34701;&#21512;&#27425;&#35201;&#32467;&#26524;&#26469;&#23398;&#20064;&#20010;&#20307;&#21270;&#27835;&#30103;&#35268;&#21017;(ITR)&#65292;&#26082;&#26368;&#22823;&#21270;&#20027;&#35201;&#32467;&#26524;&#30340;&#20215;&#20540;&#20989;&#25968;&#65292;&#21448;&#23613;&#21487;&#33021;&#25509;&#36817;&#27425;&#35201;&#32467;&#26524;&#30340;&#26368;&#20248;&#35268;&#21017;&#12290;</title><link>https://arxiv.org/abs/2402.08828</link><description>&lt;p&gt;
&#20351;&#29992;&#27425;&#35201;&#32467;&#26524;&#34701;&#21512;&#20010;&#20307;&#21270;&#27835;&#30103;&#35268;&#21017;
&lt;/p&gt;
&lt;p&gt;
Fusing Individualized Treatment Rules Using Secondary Outcomes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08828
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#34701;&#21512;&#27425;&#35201;&#32467;&#26524;&#26469;&#23398;&#20064;&#20010;&#20307;&#21270;&#27835;&#30103;&#35268;&#21017;(ITR)&#65292;&#26082;&#26368;&#22823;&#21270;&#20027;&#35201;&#32467;&#26524;&#30340;&#20215;&#20540;&#20989;&#25968;&#65292;&#21448;&#23613;&#21487;&#33021;&#25509;&#36817;&#27425;&#35201;&#32467;&#26524;&#30340;&#26368;&#20248;&#35268;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#20307;&#21270;&#27835;&#30103;&#35268;&#21017;(ITR)&#26159;&#26681;&#25454;&#24739;&#32773;&#20010;&#20307;&#29305;&#24449;&#21464;&#37327;&#25512;&#33616;&#27835;&#30103;&#26041;&#26696;&#30340;&#20915;&#31574;&#35268;&#21017;&#12290;&#22312;&#35768;&#22810;&#23454;&#36341;&#20013;&#65292;&#29702;&#24819;&#30340;&#20027;&#35201;&#32467;&#26524;&#30340;ITR&#36824;&#39044;&#35745;&#23545;&#20854;&#20182;&#27425;&#35201;&#32467;&#26524;&#36896;&#25104;&#26368;&#23567;&#30340;&#21361;&#23475;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#23398;&#20064;&#19968;&#31181;ITR&#65292;&#23427;&#19981;&#20165;&#26368;&#22823;&#21270;&#20027;&#35201;&#32467;&#26524;&#30340;&#20215;&#20540;&#20989;&#25968;&#65292;&#36824;&#23613;&#21487;&#33021;&#22320;&#25509;&#36817;&#27425;&#35201;&#32467;&#26524;&#30340;&#26368;&#20248;&#35268;&#21017;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#34701;&#21512;&#24809;&#32602;&#65292;&#40723;&#21169;&#22522;&#20110;&#19981;&#21516;&#32467;&#26524;&#30340;ITR&#20135;&#29983;&#31867;&#20284;&#30340;&#25512;&#33616;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#20351;&#29992;&#26367;&#20195;&#25439;&#22833;&#20989;&#25968;&#20272;&#35745;ITR&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20027;&#35201;&#32467;&#26524;&#30340;&#20272;&#35745;ITR&#19982;&#27425;&#35201;&#32467;&#26524;&#30340;&#26368;&#20248;ITR&#20043;&#38388;&#30340;&#19968;&#33268;&#29575;&#25910;&#25947;&#27604;&#27809;&#26377;&#32771;&#34385;&#27425;&#35201;&#32467;&#26524;&#26102;&#26356;&#24555;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08828v1 Announce Type: cross Abstract: An individualized treatment rule (ITR) is a decision rule that recommends treatments for patients based on their individual feature variables. In many practices, the ideal ITR for the primary outcome is also expected to cause minimal harm to other secondary outcomes. Therefore, our objective is to learn an ITR that not only maximizes the value function for the primary outcome, but also approximates the optimal rule for the secondary outcomes as closely as possible. To achieve this goal, we introduce a fusion penalty to encourage the ITRs based on different outcomes to yield similar recommendations. Two algorithms are proposed to estimate the ITR using surrogate loss functions. We prove that the agreement rate between the estimated ITR of the primary outcome and the optimal ITRs of the secondary outcomes converges to the true agreement rate faster than if the secondary outcomes are not taken into consideration. Furthermore, we derive the
&lt;/p&gt;</description></item><item><title>Stein Boltzmann&#25277;&#26679;&#65288;SBS&#65289;&#26159;&#19968;&#31181;&#20840;&#23616;&#20248;&#21270;&#30340;&#21464;&#20998;&#26041;&#27861;&#65292;&#36890;&#36807;&#20174;Boltzmann&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#30001;Stein Variational Gradient Descent&#31639;&#27861;&#23454;&#29616;&#65292;&#20855;&#26377;&#28176;&#36817;&#25910;&#25947;&#24615;&#65292;&#24182;&#22312;&#21508;&#31181;&#22522;&#20934;&#20989;&#25968;&#19978;&#27604;&#36739;&#20102;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;&#20840;&#23616;&#20248;&#21270;&#31639;&#27861;&#65292;&#23588;&#20854;&#36866;&#21512;&#20316;&#20026;&#39640;&#25928;&#20840;&#23616;&#20248;&#21270;&#26041;&#27861;&#30340;&#24310;&#32493;&#65292;&#33021;&#22815;&#20135;&#29983;&#26356;&#22909;&#30340;&#35299;&#20915;&#26041;&#26696;&#24182;&#26377;&#25928;&#21033;&#29992;&#39044;&#31639;&#12290;</title><link>https://arxiv.org/abs/2402.04689</link><description>&lt;p&gt;
Stein Boltzmann&#25277;&#26679;&#65306;&#19968;&#31181;&#20840;&#23616;&#20248;&#21270;&#30340;&#21464;&#20998;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Stein Boltzmann Sampling: A Variational Approach for Global Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04689
&lt;/p&gt;
&lt;p&gt;
Stein Boltzmann&#25277;&#26679;&#65288;SBS&#65289;&#26159;&#19968;&#31181;&#20840;&#23616;&#20248;&#21270;&#30340;&#21464;&#20998;&#26041;&#27861;&#65292;&#36890;&#36807;&#20174;Boltzmann&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#30001;Stein Variational Gradient Descent&#31639;&#27861;&#23454;&#29616;&#65292;&#20855;&#26377;&#28176;&#36817;&#25910;&#25947;&#24615;&#65292;&#24182;&#22312;&#21508;&#31181;&#22522;&#20934;&#20989;&#25968;&#19978;&#27604;&#36739;&#20102;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;&#20840;&#23616;&#20248;&#21270;&#31639;&#27861;&#65292;&#23588;&#20854;&#36866;&#21512;&#20316;&#20026;&#39640;&#25928;&#20840;&#23616;&#20248;&#21270;&#26041;&#27861;&#30340;&#24310;&#32493;&#65292;&#33021;&#22815;&#20135;&#29983;&#26356;&#22909;&#30340;&#35299;&#20915;&#26041;&#26696;&#24182;&#26377;&#25928;&#21033;&#29992;&#39044;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#27969;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;Lipschitz&#20989;&#25968;&#30340;&#20840;&#23616;&#20248;&#21270;&#65292;&#31216;&#20026;Stein Boltzmann&#25277;&#26679;&#65288;SBS&#65289;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20174;Boltzmann&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#35813;&#20998;&#24067;&#22312;&#20248;&#21270;&#20989;&#25968;&#30340;&#26368;&#23567;&#20540;&#38598;&#21512;&#19978;&#28176;&#36817;&#22343;&#21248;&#12290;&#20505;&#36873;&#35299;&#36890;&#36807;Stein Variational Gradient Descent&#31639;&#27861;&#36827;&#34892;&#37319;&#26679;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#28176;&#36817;&#25910;&#25947;&#24615;&#65292;&#24341;&#20837;&#20102;&#20004;&#31181;SBS&#21464;&#20307;&#65292;&#24182;&#22312;&#21508;&#31181;&#22522;&#20934;&#20989;&#25968;&#19978;&#19982;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;&#20840;&#23616;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#35814;&#32454;&#27604;&#36739;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#35774;&#35745;&#12289;&#29702;&#35770;&#32467;&#26524;&#21644;&#23454;&#39564;&#34920;&#26126;&#65292;SBS&#29305;&#21035;&#36866;&#21512;&#20316;&#20026;&#39640;&#25928;&#20840;&#23616;&#20248;&#21270;&#26041;&#27861;&#30340;&#24310;&#32493;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#22312;&#24456;&#22909;&#22320;&#21033;&#29992;&#39044;&#31639;&#30340;&#21516;&#26102;&#20135;&#29983;&#26356;&#22909;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce a new flow-based method for global optimization of Lipschitz functions, called Stein Boltzmann Sampling (SBS). Our method samples from the Boltzmann distribution that becomes asymptotically uniform over the set of the minimizers of the function to be optimized. Candidate solutions are sampled via the \emph{Stein Variational Gradient Descent} algorithm. We prove the asymptotic convergence of our method, introduce two SBS variants, and provide a detailed comparison with several state-of-the-art global optimization algorithms on various benchmark functions. The design of our method, the theoretical results, and our experiments, suggest that SBS is particularly well-suited to be used as a continuation of efficient global optimization methods as it can produce better solutions while making a good use of the budget.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#29702;&#35770;&#65292;&#29992;&#20110;&#23545;&#20960;&#20046;&#25152;&#26377;&#24120;&#35265;&#21644;&#29616;&#23454;&#35774;&#32622;&#19979;&#30340;&#26680;&#22238;&#24402;&#30340;&#36229;&#20986;&#39118;&#38505;&#36827;&#34892;&#19978;&#38480;&#32422;&#26463;&#65292;&#24182;&#25581;&#31034;&#20102;&#26680;&#20998;&#35299;&#20013;&#23384;&#22312;&#30340;&#33258;&#25105;&#27491;&#21017;&#21270;&#29616;&#35937;&#12290;</title><link>https://arxiv.org/abs/2312.15995</link><description>&lt;p&gt;
&#22312;&#29616;&#23454;&#20551;&#35774;&#19979;&#30340;&#26680;&#22238;&#24402;&#20013;&#30340;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Generalization in Kernel Regression Under Realistic Assumptions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.15995
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#29702;&#35770;&#65292;&#29992;&#20110;&#23545;&#20960;&#20046;&#25152;&#26377;&#24120;&#35265;&#21644;&#29616;&#23454;&#35774;&#32622;&#19979;&#30340;&#26680;&#22238;&#24402;&#30340;&#36229;&#20986;&#39118;&#38505;&#36827;&#34892;&#19978;&#38480;&#32422;&#26463;&#65292;&#24182;&#25581;&#31034;&#20102;&#26680;&#20998;&#35299;&#20013;&#23384;&#22312;&#30340;&#33258;&#25105;&#27491;&#21017;&#21270;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#22312;&#24050;&#32463;&#30830;&#31435;&#30340;&#20107;&#23454;&#26159;&#65292;&#29616;&#20195;&#36807;&#24230;&#21442;&#25968;&#21270;&#27169;&#22411;&#20284;&#20046;&#33021;&#22815;&#36867;&#36991;&#20559;&#24046;-&#26041;&#24046;&#26435;&#34913;&#65292;&#22312;&#36807;&#24230;&#25311;&#21512;&#22122;&#38899;&#30340;&#24773;&#20917;&#19979;&#27867;&#21270;&#33391;&#22909;&#12290;&#35768;&#22810;&#26368;&#36817;&#30340;&#30740;&#31350;&#23581;&#35797;&#20998;&#26512;&#36825;&#19968;&#29616;&#35937;&#22312;&#26680;&#22238;&#24402;&#30456;&#23545;&#26131;&#22788;&#29702;&#30340;&#35774;&#32622;&#20013;&#12290;&#28982;&#32780;&#65292;&#27491;&#22914;&#25105;&#20204;&#35814;&#32454;&#35752;&#35770;&#30340;&#37027;&#26679;&#65292;&#22823;&#22810;&#25968;&#20851;&#20110;&#36825;&#20010;&#20027;&#39064;&#30340;&#36807;&#21435;&#30340;&#30740;&#31350;&#35201;&#20040;&#20570;&#20986;&#20102;&#19981;&#20999;&#23454;&#38469;&#30340;&#20551;&#35774;&#65292;&#35201;&#20040;&#19987;&#27880;&#20110;&#19968;&#20010;&#29421;&#31364;&#30340;&#38382;&#39064;&#35774;&#32622;&#12290;&#26412;&#25991;&#26088;&#22312;&#25552;&#20379;&#19968;&#20010;&#32479;&#19968;&#30340;&#29702;&#35770;&#26469;&#38480;&#21046;&#20960;&#20046;&#25152;&#26377;&#24120;&#35265;&#21644;&#29616;&#23454;&#35774;&#32622;&#19979;&#26680;&#22238;&#24402;&#30340;&#36229;&#20986;&#39118;&#38505;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#20110;&#24120;&#35265;&#26680;&#20989;&#25968;&#20197;&#21450;&#20219;&#24847;&#30340;&#27491;&#21017;&#21270;&#37327;&#12289;&#22122;&#22768;&#12289;&#20219;&#24847;&#36755;&#20837;&#32500;&#24230;&#21644;&#20219;&#24847;&#26679;&#26412;&#25968;&#37117;&#25104;&#31435;&#30340;&#20005;&#26684;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#20026;&#26680;&#30697;&#38453;&#30340;&#29305;&#24449;&#20540;&#25552;&#20379;&#20102;&#30456;&#23545;&#25200;&#21160;&#30028;&#38480;&#65292;&#36825;&#21487;&#33021;&#20855;&#26377;&#29420;&#31435;&#30340;&#37325;&#35201;&#24615;&#12290;&#36825;&#20123;&#30028;&#38480;&#25581;&#31034;&#20102;&#19968;&#31181;&#33258;&#25105;&#27491;&#21017;&#21270;&#29616;&#35937;&#65292;&#21363;&#26680;&#20998;&#35299;&#30340;&#29305;&#24449;&#20540;&#20013;&#23384;&#22312;&#37325;&#23614;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.15995v2 Announce Type: replace-cross  Abstract: It is by now well-established that modern over-parameterized models seem to elude the bias-variance tradeoff and generalize well despite overfitting noise. Many recent works attempt to analyze this phenomenon in the relatively tractable setting of kernel regression. However, as we argue in detail, most past works on this topic either make unrealistic assumptions, or focus on a narrow problem setup. This work aims to provide a unified theory to upper bound the excess risk of kernel regression for nearly all common and realistic settings. Specifically, we provide rigorous bounds that hold for common kernels and for any amount of regularization, noise, any input dimension, and any number of samples. Furthermore, we provide relative perturbation bounds for the eigenvalues of kernel matrices, which may be of independent interest. These reveal a self-regularization phenomenon, whereby a heavy tail in the eigendecomposition of the ker
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#24314;&#31435;&#32463;&#39564;&#27604;&#20363;&#21644;&#32463;&#39564;&#33218;&#22870;&#21169;&#20043;&#38388;&#30340;&#36830;&#25509;&#65292;&#25552;&#39640;&#20102;&#19968;&#20123;&#29616;&#26377;&#31639;&#27861;&#30340;&#38169;&#35823;&#27010;&#29575;&#19978;&#30028;&#12290;</title><link>https://arxiv.org/abs/2312.12137</link><description>&lt;p&gt;
&#24102;&#26377;&#22266;&#23450;&#39044;&#31639;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#65306;&#22823;&#20559;&#24046;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Best Arm Identification with Fixed Budget: A Large Deviation Perspective
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.12137
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#24314;&#31435;&#32463;&#39564;&#27604;&#20363;&#21644;&#32463;&#39564;&#33218;&#22870;&#21169;&#20043;&#38388;&#30340;&#36830;&#25509;&#65292;&#25552;&#39640;&#20102;&#19968;&#20123;&#29616;&#26377;&#31639;&#27861;&#30340;&#38169;&#35823;&#27010;&#29575;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#22266;&#23450;&#25277;&#26679;&#39044;&#31639;&#22312;&#38543;&#26426;&#22810;&#33218;&#32769;&#34382;&#26426;(MABs)&#20013;&#35782;&#21035;&#26368;&#20339;&#33218;&#30340;&#38382;&#39064;&#12290;&#34920;&#24449;&#35813;&#38382;&#39064;&#30340;&#26368;&#23567;&#29305;&#23450;&#23454;&#20363;&#35823;&#24046;&#27010;&#29575;&#26500;&#25104;MABs&#20013;&#19968;&#30452;&#23384;&#22312;&#30340;&#37325;&#35201;&#24320;&#25918;&#38382;&#39064;&#20043;&#19968;&#12290;&#24403;&#20351;&#29992;&#38745;&#24577;&#25277;&#26679;&#31574;&#30053;&#36873;&#25321;&#33218;&#26102;&#65292;&#38169;&#35823;&#27010;&#29575;&#38543;&#30528;&#26679;&#26412;&#25968;&#21576;&#25351;&#25968;&#34928;&#20943;&#65292;&#20854;&#36895;&#29575;&#21487;&#20197;&#36890;&#36807;&#22823;&#20559;&#24046;&#25216;&#26415;&#26126;&#30830;&#25512;&#23548;&#12290;&#28982;&#32780;&#65292;&#20998;&#26512;&#20855;&#26377;&#33258;&#36866;&#24212;&#25277;&#26679;&#31574;&#30053;&#30340;&#31639;&#27861;&#30340;&#24615;&#33021;&#35201;&#22256;&#38590;&#24471;&#22810;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#36890;&#36807;&#32463;&#39564;&#27604;&#20363;&#28385;&#36275;&#30340;&#22823;&#20559;&#24046;&#21407;&#29702;(LDP)&#21644;&#36890;&#36807;&#32463;&#39564;&#33218;&#22870;&#21169;&#28385;&#36275;&#30340;LDP&#20043;&#38388;&#30340;&#36830;&#25509;&#12290;&#36825;&#31181;&#36830;&#25509;&#36866;&#29992;&#20110;&#20219;&#20309;&#33258;&#36866;&#24212;&#31639;&#27861;&#65292;&#24182;&#34987;&#21033;&#29992;&#26469;( i ) &#25552;&#39640;&#26576;&#20123;&#29616;&#26377;&#31639;&#27861;&#30340;&#38169;&#35823;&#27010;&#29575;&#19978;&#30028;&#65292;&#20363;&#22914;&#33879;&#21517;&#30340;\sr (Successive Re
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.12137v2 Announce Type: replace  Abstract: We consider the problem of identifying the best arm in stochastic Multi-Armed Bandits (MABs) using a fixed sampling budget. Characterizing the minimal instance-specific error probability for this problem constitutes one of the important remaining open problems in MABs. When arms are selected using a static sampling strategy, the error probability decays exponentially with the number of samples at a rate that can be explicitly derived via Large Deviation techniques. Analyzing the performance of algorithms with adaptive sampling strategies is however much more challenging. In this paper, we establish a connection between the Large Deviation Principle (LDP) satisfied by the empirical proportions of arm draws and that satisfied by the empirical arm rewards. This connection holds for any adaptive algorithm, and is leveraged (i) to improve error probability upper bounds of some existing algorithms, such as the celebrated \sr (Successive Re
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#24046;&#20998;&#38544;&#31169;&#30340;&#28155;&#21152;-&#21024;&#38500;&#27169;&#22411;&#20013;&#30340;&#19968;&#32500;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#31639;&#27861;&#65292;&#35777;&#26126;&#20854;&#22312;&#22343;&#26041;&#35823;&#24046;&#20013;&#36798;&#21040;&#26368;&#20339;&#24120;&#25968;&#65292;&#35813;&#24120;&#25968;&#19982;&#20132;&#25442;&#27169;&#22411;&#19979;&#30340;&#26368;&#20248;&#31639;&#27861;&#30456;&#21516;&#12290;</title><link>https://arxiv.org/abs/2312.06658</link><description>&lt;p&gt;
&#22312;&#24046;&#20998;&#38544;&#31169;&#30340;&#28155;&#21152;-&#21024;&#38500;&#27169;&#22411;&#20013;&#30340;&#22343;&#20540;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Mean estimation in the add-remove model of differential privacy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.06658
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#24046;&#20998;&#38544;&#31169;&#30340;&#28155;&#21152;-&#21024;&#38500;&#27169;&#22411;&#20013;&#30340;&#19968;&#32500;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#31639;&#27861;&#65292;&#35777;&#26126;&#20854;&#22312;&#22343;&#26041;&#35823;&#24046;&#20013;&#36798;&#21040;&#26368;&#20339;&#24120;&#25968;&#65292;&#35813;&#24120;&#25968;&#19982;&#20132;&#25442;&#27169;&#22411;&#19979;&#30340;&#26368;&#20248;&#31639;&#27861;&#30456;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#36890;&#24120;&#22312;&#20004;&#31181;&#19981;&#21516;&#30340;&#30456;&#37051;&#25968;&#25454;&#38598;&#27169;&#22411;&#19979;&#30740;&#31350;&#65306;&#28155;&#21152;-&#21024;&#38500;&#27169;&#22411;&#21644;&#20132;&#25442;&#27169;&#22411;&#12290;&#34429;&#28982;&#20132;&#25442;&#27169;&#22411;&#32463;&#24120;&#22312;&#23398;&#26415;&#25991;&#29486;&#20013;&#29992;&#20110;&#31616;&#21270;&#20998;&#26512;&#65292;&#20294;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20381;&#36182;&#26356;&#20445;&#23432;&#30340;&#28155;&#21152;-&#21024;&#38500;&#27169;&#22411;&#65292;&#20854;&#20013;&#33719;&#24471;&#32039;&#23494;&#32467;&#26524;&#21487;&#33021;&#24456;&#22256;&#38590;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#28155;&#21152;-&#21024;&#38500;&#27169;&#22411;&#19979;&#30340;&#19968;&#32500;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#24182;&#34920;&#26126;&#23427;&#26159;&#26368;&#23567;-&#26368;&#22823;&#26368;&#20248;&#30340;&#65292;&#22312;&#25152;&#26377;$\epsilon$&#30340;&#22343;&#26041;&#35823;&#24046;&#30340;&#20027;&#23548;&#39033;&#20013;&#23454;&#29616;&#20102;&#26368;&#20339;&#24120;&#25968;&#65292;&#32780;&#19988;&#36825;&#20010;&#24120;&#25968;&#19982;&#20132;&#25442;&#27169;&#22411;&#19979;&#30340;&#26368;&#20248;&#31639;&#27861;&#26159;&#30456;&#21516;&#30340;&#12290;&#36825;&#20123;&#32467;&#26524;&#34920;&#26126;&#65292;&#28155;&#21152;-&#21024;&#38500;&#27169;&#22411;&#21644;&#20132;&#25442;&#27169;&#22411;&#23545;&#20110;&#22343;&#20540;&#20272;&#35745;&#32473;&#20986;&#20102;&#20960;&#20046;&#30456;&#21516;&#30340;&#35823;&#24046;&#65292;&#23613;&#31649;&#28155;&#21152;-&#21024;&#38500;&#27169;&#22411;&#26080;&#27861;&#22788;&#29702;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#20316;&#20026;&#20844;&#20849;&#20449;&#24687;&#12290;&#25105;&#20204;&#36824;&#32463;&#39564;&#24615;&#22320;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.06658v2 Announce Type: replace-cross  Abstract: Differential privacy is often studied under two different models of neighboring datasets: the add-remove model and the swap model. While the swap model is frequently used in the academic literature to simplify analysis, many practical applications rely on the more conservative add-remove model, where obtaining tight results can be difficult. Here, we study the problem of one-dimensional mean estimation under the add-remove model. We propose a new algorithm and show that it is min-max optimal, achieving the best possible constant in the leading term of the mean squared error for all $\epsilon$, and that this constant is the same as the optimal algorithm under the swap model. These results show that the add-remove and swap models give nearly identical errors for mean estimation, even though the add-remove model cannot treat the size of the dataset as public information. We also demonstrate empirically that our proposed algorithm 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20174;&#29702;&#35770;&#35282;&#24230;&#23545;&#29983;&#25104;&#24314;&#27169;&#20013;&#30340;&#22810;&#31181;&#37319;&#26679;&#26041;&#27861;&#36827;&#34892;&#20102;&#23457;&#35270;&#21644;&#32452;&#32455;&#65292;&#24110;&#21161;&#20811;&#26381;&#37319;&#26679;&#20013;&#30340;&#19968;&#20123;&#25361;&#25112;&#65292;&#27604;&#22914;&#25512;&#29702;&#26102;&#38388;&#38271;&#21644;&#29983;&#25104;&#26679;&#26412;&#32570;&#20047;&#22810;&#26679;&#24615;&#12290;</title><link>https://arxiv.org/abs/2311.13845</link><description>&lt;p&gt;
&#20351;&#29992;&#25512;&#21069;&#26144;&#23556;&#36827;&#34892;&#21508;&#22320;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Touring sampling with pushforward maps
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.13845
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20174;&#29702;&#35770;&#35282;&#24230;&#23545;&#29983;&#25104;&#24314;&#27169;&#20013;&#30340;&#22810;&#31181;&#37319;&#26679;&#26041;&#27861;&#36827;&#34892;&#20102;&#23457;&#35270;&#21644;&#32452;&#32455;&#65292;&#24110;&#21161;&#20811;&#26381;&#37319;&#26679;&#20013;&#30340;&#19968;&#20123;&#25361;&#25112;&#65292;&#27604;&#22914;&#25512;&#29702;&#26102;&#38388;&#38271;&#21644;&#29983;&#25104;&#26679;&#26412;&#32570;&#20047;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#19968;&#20010;&#24076;&#26395;&#23558;&#24378;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#24212;&#29992;&#20110;&#29305;&#23450;&#38382;&#39064;&#30340;&#20174;&#19994;&#32773;&#26469;&#35828;&#65292;&#37319;&#26679;&#26041;&#27861;&#30340;&#25968;&#37327;&#21487;&#33021;&#20196;&#20154;&#29983;&#30031;&#12290;&#26412;&#25991;&#20174;&#29702;&#35770;&#35282;&#24230;&#20986;&#21457;&#65292;&#23545;&#22312;&#8220;&#29983;&#25104;&#24314;&#27169;&#8221;&#35774;&#32622;&#20013;&#35768;&#22810;&#37319;&#26679;&#26041;&#27861;&#36827;&#34892;&#20102;&#23457;&#35270;&#21644;&#32452;&#32455;&#65292;&#20854;&#20013;&#24076;&#26395;&#29983;&#25104;&#19982;&#19968;&#20123;&#35757;&#32451;&#26679;&#26412;&#31867;&#20284;&#30340;&#26032;&#25968;&#25454;&#12290;&#36890;&#36807;&#25581;&#31034;&#29616;&#26377;&#26041;&#27861;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#21487;&#33021;&#26377;&#21161;&#20110;&#20811;&#26381;&#19982;&#25193;&#25955;&#27169;&#22411;&#37319;&#26679;&#30456;&#20851;&#30340;&#19968;&#20123;&#24403;&#21069;&#25361;&#25112;&#65292;&#27604;&#22914;&#30001;&#20110;&#25193;&#25955;&#27169;&#25311;&#32780;&#23548;&#33268;&#30340;&#38271;&#25512;&#29702;&#26102;&#38388;&#65292;&#25110;&#32773;&#29983;&#25104;&#26679;&#26412;&#32570;&#20047;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.13845v2 Announce Type: replace-cross  Abstract: The number of sampling methods could be daunting for a practitioner looking to cast powerful machine learning methods to their specific problem. This paper takes a theoretical stance to review and organize many sampling approaches in the ``generative modeling'' setting, where one wants to generate new data that are similar to some training examples. By revealing links between existing methods, it might prove useful to overcome some of the current challenges in sampling with diffusion models, such as long inference time due to diffusion simulation, or the lack of diversity in generated samples.
&lt;/p&gt;</description></item><item><title>&#22312;&#33258;&#22238;&#24402;&#36807;&#31243;&#25511;&#21046;&#30340;&#22870;&#21169;&#19979;&#65292;&#25552;&#20986;&#20102;&#33258;&#22238;&#24402;&#36172;&#21338;&#26426;&#65288;ARBs&#65289;&#22312;&#32447;&#23398;&#20064;&#35774;&#32622;&#65292;&#24182;&#35774;&#35745;&#20102;AutoRegressive Upper Confidence Bound (AR-UCB)&#31639;&#27861;&#65292;&#21487;&#20197;&#26041;&#20415;&#35745;&#31639;&#26368;&#20248;&#31574;&#30053;&#24182;&#20855;&#26377;&#27425;&#32447;&#24615;&#36951;&#25022;&#12290;</title><link>https://arxiv.org/abs/2212.06251</link><description>&lt;p&gt;
&#33258;&#22238;&#24402;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
Autoregressive Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2212.06251
&lt;/p&gt;
&lt;p&gt;
&#22312;&#33258;&#22238;&#24402;&#36807;&#31243;&#25511;&#21046;&#30340;&#22870;&#21169;&#19979;&#65292;&#25552;&#20986;&#20102;&#33258;&#22238;&#24402;&#36172;&#21338;&#26426;&#65288;ARBs&#65289;&#22312;&#32447;&#23398;&#20064;&#35774;&#32622;&#65292;&#24182;&#35774;&#35745;&#20102;AutoRegressive Upper Confidence Bound (AR-UCB)&#31639;&#27861;&#65292;&#21487;&#20197;&#26041;&#20415;&#35745;&#31639;&#26368;&#20248;&#31574;&#30053;&#24182;&#20855;&#26377;&#27425;&#32447;&#24615;&#36951;&#25022;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#22238;&#24402;&#36807;&#31243;&#22312;&#32929;&#31080;&#24066;&#22330;&#12289;&#38144;&#21806;&#39044;&#27979;&#12289;&#22825;&#27668;&#39044;&#27979;&#12289;&#24191;&#21578;&#21644;&#23450;&#20215;&#31561;&#21508;&#31181;&#23454;&#38469;&#22330;&#26223;&#20013;&#33258;&#28982;&#32780;&#28982;&#22320;&#20986;&#29616;&#12290;&#22312;&#38754;&#23545;&#36825;&#26679;&#30340;&#24207;&#36143;&#20915;&#31574;&#38382;&#39064;&#26102;&#65292;&#24212;&#35813;&#27491;&#30830;&#32771;&#34385;&#36830;&#32493;&#35266;&#27979;&#20043;&#38388;&#30340;&#26102;&#38388;&#20381;&#36182;&#24615;&#65292;&#20197;&#20445;&#35777;&#25910;&#25947;&#21040;&#26368;&#20248;&#31574;&#30053;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22312;&#32447;&#23398;&#20064;&#35774;&#32622;&#65292;&#21363;&#33258;&#22238;&#24402;&#36172;&#21338;&#26426;&#65288;ARBs&#65289;&#65292;&#20854;&#20013;&#35266;&#27979;&#21040;&#30340;&#22870;&#21169;&#30001;&#19968;&#20010;&#38454;&#25968;&#20026;$k$&#30340;&#33258;&#22238;&#24402;&#36807;&#31243;&#25511;&#21046;&#65292;&#20854;&#21442;&#25968;&#21462;&#20915;&#20110;&#36873;&#25321;&#30340;&#21160;&#20316;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#23545;&#22870;&#21169;&#36807;&#31243;&#36827;&#34892;&#28201;&#21644;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#20248;&#31574;&#30053;&#21487;&#20197;&#26041;&#20415;&#22320;&#35745;&#31639;&#20986;&#26469;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#20048;&#35266;&#36951;&#25022;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#21363;&#33258;&#22238;&#24402;&#19978;&#32622;&#20449;&#30028;&#65288;AR-UCB&#65289;&#65292;&#20854;&#36951;&#25022;&#21576;&#29616;&#20986;&#27425;&#32447;&#24615;&#30340;&#38454;&#25968;$\widetilde{\mathcal{O}} \left( \frac{(k+1)^{3/2}\sqrt{nT}}{(1-\Gamma)^
&lt;/p&gt;
&lt;p&gt;
arXiv:2212.06251v2 Announce Type: replace  Abstract: Autoregressive processes naturally arise in a large variety of real-world scenarios, including stock markets, sales forecasting, weather prediction, advertising, and pricing. When facing a sequential decision-making problem in such a context, the temporal dependence between consecutive observations should be properly accounted for guaranteeing convergence to the optimal policy. In this work, we propose a novel online learning setting, namely, Autoregressive Bandits (ARBs), in which the observed reward is governed by an autoregressive process of order $k$, whose parameters depend on the chosen action. We show that, under mild assumptions on the reward process, the optimal policy can be conveniently computed. Then, we devise a new optimistic regret minimization algorithm, namely, AutoRegressive Upper Confidence Bound (AR-UCB), that suffers sublinear regret of order $\widetilde{\mathcal{O}} \left( \frac{(k+1)^{3/2}\sqrt{nT}}{(1-\Gamma)^
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#25968;&#23398;&#26694;&#26550;&#65292;&#25506;&#35752;&#20102;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#19978;&#31639;&#27861;&#36807;&#28388;&#30340;&#19981;&#33391;&#24433;&#21709;&#20197;&#21450;&#30417;&#31649;&#22797;&#26434;&#24615;&#12290;</title><link>https://arxiv.org/abs/2209.05550</link><description>&lt;p&gt;
&#22312;&#32447;&#31038;&#20132;&#23186;&#20307;&#23457;&#35745;&#30340;&#25968;&#23398;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Mathematical Framework for Online Social Media Auditing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2209.05550
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#25968;&#23398;&#26694;&#26550;&#65292;&#25506;&#35752;&#20102;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#19978;&#31639;&#27861;&#36807;&#28388;&#30340;&#19981;&#33391;&#24433;&#21709;&#20197;&#21450;&#30417;&#31649;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#65288;SMPs&#65289;&#21033;&#29992;&#31639;&#27861;&#36807;&#28388;&#65288;AF&#65289;&#26469;&#36873;&#25321;&#26500;&#25104;&#29992;&#25143;&#20449;&#24687;&#27969;&#30340;&#20869;&#23481;&#65292;&#26088;&#22312;&#26368;&#22823;&#21270;&#22870;&#21169;&#12290;&#26377;&#36873;&#25321;&#22320;&#36873;&#25321;&#35201;&#26174;&#31034;&#22312;&#29992;&#25143;&#20449;&#24687;&#27969;&#20013;&#30340;&#20869;&#23481;&#21487;&#33021;&#20250;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#65292;&#26080;&#35770;&#26159;&#36739;&#23567;&#36824;&#26159;&#36739;&#22823;&#65292;&#23545;&#29992;&#25143;&#30340;&#20915;&#31574;&#20135;&#29983;&#24433;&#21709;&#65292;&#19982;&#22312;&#33258;&#28982;/&#20844;&#24179;&#20869;&#23481;&#36873;&#25321;&#19979;&#20250;&#20135;&#29983;&#30340;&#24433;&#21709;&#30456;&#27604;&#12290;&#27491;&#22914;&#25105;&#20204;&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#20013;&#25152;&#35265;&#65292;&#31639;&#27861;&#36807;&#28388;&#21487;&#33021;&#23548;&#33268;&#26377;&#23475;&#30340;&#21103;&#20316;&#29992;&#65292;&#20174;&#20559;&#35265;&#20010;&#20154;&#20915;&#23450;&#21040;&#22609;&#36896;&#25972;&#20010;&#31038;&#20250;&#30340;&#20915;&#23450;&#65292;&#20363;&#22914;&#65292;&#23558;&#29992;&#25143;&#27880;&#24847;&#21147;&#20174;&#26159;&#21542;&#25509;&#31181;COVID-19&#30123;&#33495;&#36716;&#31227;&#25110;&#35825;&#20351;&#20844;&#20247;&#36873;&#25321;&#24635;&#32479;&#20505;&#36873;&#20154;&#12290;&#25919;&#24220;&#24120;&#24120;&#35797;&#22270;&#30417;&#31649;AF&#30340;&#19981;&#33391;&#24433;&#21709;&#65292;&#20294;&#24448;&#24448;&#22240;&#23448;&#20698;&#20027;&#20041;&#12289;&#27861;&#24459;&#20107;&#21153;&#21644;&#36130;&#21153;&#32771;&#34385;&#32780;&#21464;&#24471;&#22797;&#26434;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;SMPs&#23547;&#27714;&#30417;&#27979;&#20182;&#20204;&#33258;&#24049;&#30340;&#31639;
&lt;/p&gt;
&lt;p&gt;
arXiv:2209.05550v2 Announce Type: replace  Abstract: Social media platforms (SMPs) leverage algorithmic filtering (AF) as a means of selecting the content that constitutes a user's feed with the aim of maximizing their rewards. Selectively choosing the contents to be shown on the user's feed may yield a certain extent of influence, either minor or major, on the user's decision-making, compared to what it would have been under a natural/fair content selection. As we have witnessed over the past decade, algorithmic filtering can cause detrimental side effects, ranging from biasing individual decisions to shaping those of society as a whole, for example, diverting users' attention from whether to get the COVID-19 vaccine or inducing the public to choose a presidential candidate. The government's constant attempts to regulate the adverse effects of AF are often complicated, due to bureaucracy, legal affairs, and financial considerations. On the other hand SMPs seek to monitor their own alg
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;KL&#32422;&#26463;&#19979;&#30340;&#21453;&#39304;&#24378;&#21270;&#23398;&#20064;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#26377;&#25928;&#30340;&#31639;&#27861;&#21644;&#23454;&#36341;&#12290;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;&#35813;&#26694;&#26550;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23545;&#40784;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2312.11456</link><description>&lt;p&gt;
&#20154;&#31867;&#21453;&#39304;&#30340;&#36845;&#20195;&#20559;&#22909;&#23398;&#20064;&#65306;&#22312;KL&#32422;&#26463;&#19979;&#23558;&#29702;&#35770;&#19982;&#23454;&#36341;&#32852;&#31995;&#36215;&#26469;&#30340;RLHF
&lt;/p&gt;
&lt;p&gt;
Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint. (arXiv:2312.11456v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.11456
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;KL&#32422;&#26463;&#19979;&#30340;&#21453;&#39304;&#24378;&#21270;&#23398;&#20064;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#26377;&#25928;&#30340;&#31639;&#27861;&#21644;&#23454;&#36341;&#12290;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;&#35813;&#26694;&#26550;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23545;&#40784;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#29983;&#25104;&#27169;&#22411;&#19982;&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#30340;&#23545;&#40784;&#36807;&#31243;&#30340;&#29702;&#35770;&#26694;&#26550;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#26631;&#20934;&#30340;&#25968;&#23398;&#34920;&#36798;&#24335;&#65292;&#21363;&#21453;&#21521;KL&#27491;&#21017;&#21270;&#30340;&#19978;&#19979;&#25991;&#22810;&#33218;&#36172;&#21338;&#26426;&#29992;&#20110;RLHF&#12290;&#23613;&#31649;&#23427;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#23454;&#38469;&#24212;&#29992;&#65292;&#20294;&#23545;&#36825;&#20010;&#20844;&#24335;&#30340;&#20005;&#26684;&#29702;&#35770;&#20998;&#26512;&#20173;&#28982;&#24456;&#24320;&#25918;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#23427;&#22312;&#31163;&#32447;&#12289;&#22312;&#32447;&#21644;&#28151;&#21512;&#19977;&#31181;&#19981;&#21516;&#22330;&#26223;&#19979;&#30340;&#34892;&#20026;&#65292;&#24182;&#25552;&#20986;&#20102;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#29702;&#35770;&#20445;&#35777;&#30340;&#39640;&#25928;&#31639;&#27861;&#12290;&#26397;&#30528;&#23454;&#38469;&#24212;&#29992;&#30340;&#26041;&#21521;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#36890;&#36807;&#23545;&#20449;&#24687;&#29702;&#35770;&#31574;&#30053;&#25913;&#36827;&#39044;&#35328;&#30340;&#31283;&#20581;&#36817;&#20284;&#65292;&#33258;&#28982;&#22320;&#20135;&#29983;&#20102;&#20960;&#31181;&#26032;&#39062;&#30340;RLHF&#31639;&#27861;&#12290;&#36825;&#21253;&#25324;&#22312;&#32447;&#22330;&#26223;&#20013;&#30340;&#36845;&#20195;&#29256;&#26412;&#30340;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;(DPO)&#31639;&#27861;&#65292;&#20197;&#21450;&#31163;&#32447;&#24773;&#26223;&#19979;&#30340;&#22810;&#27493;&#25298;&#32477;&#25277;&#26679;&#31574;&#30053;&#12290;&#25105;&#20204;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#30495;&#23454;&#23545;&#40784;&#23454;&#39564;&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the theoretical framework of the alignment process of generative models with Reinforcement Learning from Human Feedback (RLHF). We consider a standard mathematical formulation, the reverse-KL regularized contextual bandit for RLHF. Despite its widespread practical application, a rigorous theoretical analysis of this formulation remains open. We investigate its behavior in three distinct settings -- offline, online, and hybrid -- and propose efficient algorithms with finite-sample theoretical guarantees.  Moving towards practical applications, our framework, with a robust approximation of the information-theoretical policy improvement oracle, naturally gives rise to several novel RLHF algorithms. This includes an iterative version of the Direct Preference Optimization (DPO) algorithm for online settings, and a multi-step rejection sampling strategy for offline scenarios. Our empirical evaluations on real-world alignment experiment of large language model demonstrate t
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27010;&#29575;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#30340;&#26102;&#38388;&#28857;&#36807;&#31243;&#27169;&#22411;&#65292;&#30456;&#27604;&#20110;&#29616;&#26377;&#30340;&#26041;&#27861;&#65292;&#35813;&#27169;&#22411;&#22312;&#39044;&#27979;&#26041;&#38754;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#24615;&#33021;&#65292;&#23545;&#20855;&#26377;&#31163;&#25955;&#21644;&#36830;&#32493;&#25104;&#20998;&#30340;&#25968;&#25454;&#20855;&#26377;&#22788;&#29702;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2311.01139</link><description>&lt;p&gt;
&#28155;&#21152;&#21644;&#31232;&#30095;&#65306;&#19968;&#31181;&#29992;&#20110;&#26102;&#38388;&#28857;&#36807;&#31243;&#30340;&#25193;&#25955;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Add and Thin: Diffusion for Temporal Point Processes. (arXiv:2311.01139v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01139
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27010;&#29575;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#30340;&#26102;&#38388;&#28857;&#36807;&#31243;&#27169;&#22411;&#65292;&#30456;&#27604;&#20110;&#29616;&#26377;&#30340;&#26041;&#27861;&#65292;&#35813;&#27169;&#22411;&#22312;&#39044;&#27979;&#26041;&#38754;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#24615;&#33021;&#65292;&#23545;&#20855;&#26377;&#31163;&#25955;&#21644;&#36830;&#32493;&#25104;&#20998;&#30340;&#25968;&#25454;&#20855;&#26377;&#22788;&#29702;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26102;&#38388;&#28857;&#36807;&#31243;&#65288;TPP&#65289;&#26694;&#26550;&#20869;&#65292;&#33258;&#22238;&#24402;&#31070;&#32463;&#32593;&#32476;&#24050;&#25104;&#20026;&#24314;&#27169;&#36830;&#32493;&#26102;&#38388;&#20107;&#20214;&#25968;&#25454;&#30340;&#26631;&#20934;&#12290;&#23613;&#31649;&#36825;&#20123;&#27169;&#22411;&#21487;&#20197;&#20197;&#19968;&#27493;&#39044;&#27979;&#30340;&#26041;&#24335;&#31934;&#30830;&#22320;&#25429;&#25417;&#20107;&#20214;&#24207;&#21015;&#65292;&#20294;&#30001;&#20110;&#20854;&#39034;&#24207;&#24615;&#36136;&#24341;&#36215;&#30340;&#35823;&#24046;&#31215;&#32047;&#65292;&#23427;&#20204;&#22312;&#38271;&#26399;&#39044;&#27979;&#24212;&#29992;&#20013;&#20855;&#26377;&#22266;&#26377;&#30340;&#23616;&#38480;&#24615;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;ADD-THIN&#65292;&#19968;&#31181;&#38754;&#21521;&#25972;&#20010;&#20107;&#20214;&#24207;&#21015;&#24037;&#20316;&#30340;&#22522;&#20110;&#27010;&#29575;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#65292;&#23427;&#33258;&#28982;&#22320;&#22788;&#29702;&#20855;&#26377;&#31163;&#25955;&#21644;&#36830;&#32493;&#25104;&#20998;&#30340;&#25968;&#25454;&#12290;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#23494;&#24230;&#20272;&#35745;&#26041;&#38754;&#19982;&#26368;&#20808;&#36827;&#30340;TPP&#27169;&#22411;&#30456;&#21305;&#37197;&#65292;&#24182;&#22312;&#39044;&#27979;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;
Autoregressive neural networks within the temporal point process (TPP) framework have become the standard for modeling continuous-time event data. Even though these models can expressively capture event sequences in a one-step-ahead fashion, they are inherently limited for long-term forecasting applications due to the accumulation of errors caused by their sequential nature. To overcome these limitations, we derive ADD-THIN, a principled probabilistic denoising diffusion model for TPPs that operates on entire event sequences. Unlike existing diffusion approaches, ADD-THIN naturally handles data with discrete and continuous components. In experiments on synthetic and real-world datasets, our model matches the state-of-the-art TPP models in density estimation and strongly outperforms them in forecasting.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20849;&#24418;&#24402;&#19968;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#32593;&#26684;&#32454;&#32990;&#22312;2D&#29289;&#29702;&#31354;&#38388;&#20013;&#30340;&#33258;&#25105;&#20301;&#32622;&#20449;&#24687;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26174;&#33879;&#20943;&#23567;&#20301;&#32622;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2310.19192</link><description>&lt;p&gt;
&#32593;&#26684;&#32454;&#32990;&#20013;&#30340;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20849;&#24418;&#24402;&#19968;&#21270;
&lt;/p&gt;
&lt;p&gt;
Conformal Normalization in Recurrent Neural Network of Grid Cells. (arXiv:2310.19192v1 [q-bio.NC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19192
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20849;&#24418;&#24402;&#19968;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#32593;&#26684;&#32454;&#32990;&#22312;2D&#29289;&#29702;&#31354;&#38388;&#20013;&#30340;&#33258;&#25105;&#20301;&#32622;&#20449;&#24687;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26174;&#33879;&#20943;&#23567;&#20301;&#32622;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21754;&#20083;&#21160;&#29289;&#22823;&#33041;&#20013;&#39070;&#21494;&#30382;&#23618;&#30340;&#32593;&#26684;&#32454;&#32990;&#22312;2D&#24320;&#25918;&#29615;&#22659;&#20013;&#20197;&#24778;&#20154;&#30340;&#20845;&#35282;&#24418;&#21457;&#23556;&#27169;&#24335;&#23637;&#31034;&#20986;&#21453;&#24212;&#22270;&#12290;&#32593;&#26684;&#32454;&#32990;&#32676;&#20307;&#30340;&#21453;&#24212;&#22312;&#39640;&#32500;&#31070;&#32463;&#27963;&#21160;&#31354;&#38388;&#20013;&#24418;&#25104;&#19968;&#20010;&#21521;&#37327;&#65292;&#36825;&#20010;&#21521;&#37327;&#34920;&#31034;&#20195;&#29702;&#22312;2D&#29289;&#29702;&#31354;&#38388;&#20013;&#30340;&#33258;&#25105;&#20301;&#32622;&#12290;&#24403;&#20195;&#29702;&#31227;&#21160;&#26102;&#65292;&#36825;&#20010;&#21521;&#37327;&#34987;&#19968;&#20010;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#36716;&#25442;&#65292;&#35813;&#32593;&#32476;&#23558;&#20195;&#29702;&#30340;&#36895;&#24230;&#20316;&#20026;&#36755;&#20837;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#36755;&#20837;&#36895;&#24230;&#36827;&#34892;&#31616;&#21333;&#32780;&#36890;&#29992;&#30340;&#20849;&#24418;&#24402;&#19968;&#21270;&#65292;&#20351;&#24471;&#39640;&#32500;&#31070;&#32463;&#31354;&#38388;&#20013;&#20301;&#32622;&#21521;&#37327;&#30340;&#23616;&#37096;&#20301;&#31227;&#19982;2D&#29289;&#29702;&#31354;&#38388;&#20013;&#20195;&#29702;&#30340;&#23616;&#37096;&#20301;&#31227;&#25104;&#27604;&#20363;&#65292;&#26080;&#35770;&#36755;&#20837;&#36895;&#24230;&#30340;&#26041;&#21521;&#22914;&#20309;&#12290;&#25105;&#20204;&#22312;&#26368;&#31616;&#21333;&#30340;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#24490;&#29615;&#32593;&#32476;&#19978;&#36827;&#34892;&#20102;&#25968;&#20540;&#23454;&#39564;&#65292;&#32467;&#26524;&#26174;&#31034;&#20849;&#24418;&#24402;&#19968;&#21270;&#23548;&#33268;&#25968;&#37327;&#32423;&#36739;&#23567;&#30340;&#20301;&#32622;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Grid cells in the entorhinal cortex of the mammalian brain exhibit striking hexagon firing patterns in their response maps as the animal (e.g., a rat) navigates in a 2D open environment. The responses of the population of grid cells collectively form a vector in a high-dimensional neural activity space, and this vector represents the self-position of the agent in the 2D physical space. As the agent moves, the vector is transformed by a recurrent neural network that takes the velocity of the agent as input. In this paper, we propose a simple and general conformal normalization of the input velocity for the recurrent neural network, so that the local displacement of the position vector in the high-dimensional neural space is proportional to the local displacement of the agent in the 2D physical space, regardless of the direction of the input velocity. Our numerical experiments on the minimally simple linear and non-linear recurrent networks show that conformal normalization leads to the 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19978;&#19979;&#25991;&#23450;&#21521;&#26080;&#29615;&#22270;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#23558;&#19978;&#19979;&#25991;&#29305;&#24449;&#26144;&#23556;&#21040;DAG&#65292;&#21033;&#29992;&#31232;&#30095;&#30340;&#21152;&#26435;&#37051;&#25509;&#30697;&#38453;&#34920;&#31034;&#22270;&#32467;&#26500;&#65292;&#24182;&#36890;&#36807;&#26032;&#39062;&#30340;&#25237;&#24433;&#23618;&#28385;&#36275;&#26080;&#29615;&#24615;&#30340;&#29305;&#28857;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#33021;&#22815;&#25104;&#21151;&#24674;&#22797;&#20986;&#30495;&#23454;&#30340;&#19978;&#19979;&#25991;&#29305;&#23450;&#22270;&#12290;</title><link>http://arxiv.org/abs/2310.15627</link><description>&lt;p&gt;
&#19978;&#19979;&#25991;&#23450;&#21521;&#26080;&#29615;&#22270;
&lt;/p&gt;
&lt;p&gt;
Contextual directed acyclic graphs. (arXiv:2310.15627v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15627
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19978;&#19979;&#25991;&#23450;&#21521;&#26080;&#29615;&#22270;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#23558;&#19978;&#19979;&#25991;&#29305;&#24449;&#26144;&#23556;&#21040;DAG&#65292;&#21033;&#29992;&#31232;&#30095;&#30340;&#21152;&#26435;&#37051;&#25509;&#30697;&#38453;&#34920;&#31034;&#22270;&#32467;&#26500;&#65292;&#24182;&#36890;&#36807;&#26032;&#39062;&#30340;&#25237;&#24433;&#23618;&#28385;&#36275;&#26080;&#29615;&#24615;&#30340;&#29305;&#28857;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#33021;&#22815;&#25104;&#21151;&#24674;&#22797;&#20986;&#30495;&#23454;&#30340;&#19978;&#19979;&#25991;&#29305;&#23450;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#20272;&#35745;&#23450;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#30340;&#32467;&#26500;&#20173;&#28982;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#12290;&#36825;&#20010;&#39046;&#22495;&#30340;&#22823;&#37096;&#20998;&#30740;&#31350;&#38598;&#20013;&#22312;&#20026;&#25972;&#20010;&#20154;&#21475;&#23398;&#20064;&#21333;&#20010;DAG&#19978;&#12290;&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#20010;&#26367;&#20195;&#24615;&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;&#22270;&#32467;&#26500;&#22522;&#20110;&#21487;&#29992;&#30340;&#8220;&#19978;&#19979;&#25991;&#8221;&#29305;&#24449;&#32780;&#22240;&#20154;&#32780;&#24322;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#23558;&#19978;&#19979;&#25991;&#29305;&#24449;&#26144;&#23556;&#21040;DAG&#30340;&#31070;&#32463;&#32593;&#32476;&#26469;&#35299;&#20915;&#36825;&#20010;&#19978;&#19979;&#25991;DAG&#38382;&#39064;&#65292;DAG&#20197;&#21152;&#26435;&#37051;&#25509;&#30697;&#38453;&#34920;&#31034;&#12290;&#31070;&#32463;&#32593;&#32476;&#37197;&#22791;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#25237;&#24433;&#23618;&#65292;&#30830;&#20445;&#36755;&#20986;&#30697;&#38453;&#26159;&#31232;&#30095;&#30340;&#65292;&#24182;&#28385;&#36275;&#26368;&#36817;&#21457;&#23637;&#30340;&#26080;&#29615;&#24615;&#30340;&#29305;&#28857;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#35745;&#31639;&#26694;&#26550;&#26469;&#23398;&#20064;&#19978;&#19979;&#25991;DAG&#65292;&#24182;&#25552;&#20379;&#20102;&#25910;&#25947;&#20445;&#35777;&#21644;&#36890;&#36807;&#25237;&#24433;&#23618;&#21453;&#21521;&#20256;&#25773;&#30340;&#20998;&#26512;&#26799;&#24230;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#31181;&#26032;&#26041;&#27861;&#21487;&#20197;&#24674;&#22797;&#20986;&#30495;&#23454;&#30340;&#19978;&#19979;&#25991;&#29305;&#23450;&#22270;&#65292;&#32780;&#29616;&#26377;&#26041;&#27861;&#21017;&#22833;&#36133;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating the structure of directed acyclic graphs (DAGs) from observational data remains a significant challenge in machine learning. Most research in this area concentrates on learning a single DAG for the entire population. This paper considers an alternative setting where the graph structure varies across individuals based on available "contextual" features. We tackle this contextual DAG problem via a neural network that maps the contextual features to a DAG, represented as a weighted adjacency matrix. The neural network is equipped with a novel projection layer that ensures the output matrices are sparse and satisfy a recently developed characterization of acyclicity. We devise a scalable computational framework for learning contextual DAGs and provide a convergence guarantee and an analytical gradient for backpropagating through the projection layer. Our experiments suggest that the new approach can recover the true context-specific graph where existing approaches fail.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22312;&#33258;&#21160;&#39550;&#39542;&#22330;&#26223;&#20013;&#20351;&#29992;&#37096;&#20998;&#21487;&#35266;&#27979;&#31995;&#32479;&#65292;&#36890;&#36807;&#37096;&#32626;&#21644;&#27979;&#35797;&#22810;&#31181;&#25216;&#26415;&#26469;&#24179;&#34913;&#25506;&#32034;&#21644;&#21033;&#29992;&#30340;&#26435;&#34913;&#65292;&#20197;&#39044;&#27979;&#26041;&#21521;&#30424;&#25805;&#20316;&#12290;</title><link>http://arxiv.org/abs/2310.08331</link><description>&lt;p&gt;
&#22810;&#33218;&#36172;&#21338;&#31574;&#30053;&#23545;&#28145;&#24230;&#24490;&#29615;&#24378;&#21270;&#23398;&#20064;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Impact of multi-armed bandit strategies on deep recurrent reinforcement learning. (arXiv:2310.08331v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08331
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#33258;&#21160;&#39550;&#39542;&#22330;&#26223;&#20013;&#20351;&#29992;&#37096;&#20998;&#21487;&#35266;&#27979;&#31995;&#32479;&#65292;&#36890;&#36807;&#37096;&#32626;&#21644;&#27979;&#35797;&#22810;&#31181;&#25216;&#26415;&#26469;&#24179;&#34913;&#25506;&#32034;&#21644;&#21033;&#29992;&#30340;&#26435;&#34913;&#65292;&#20197;&#39044;&#27979;&#26041;&#21521;&#30424;&#25805;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#29615;&#22659;&#30340;&#19981;&#23436;&#20840;&#20102;&#35299;&#23548;&#33268;&#26234;&#33021;&#20307;&#22312;&#19981;&#30830;&#23450;&#24615;&#19979;&#20570;&#20986;&#20915;&#31574;&#12290;&#24378;&#21270;&#23398;&#20064;&#20013;&#19968;&#20010;&#37325;&#35201;&#30340;&#22256;&#22659;&#26159;&#65292;&#22312;&#20570;&#20986;&#20915;&#31574;&#26102;&#65292;&#26234;&#33021;&#20307;&#38656;&#35201;&#22312;&#21033;&#29992;&#24403;&#21069;&#29615;&#22659;&#30693;&#35782;&#26368;&#22823;&#21270;&#32047;&#31215;&#22870;&#21169;&#21644;&#25506;&#32034;&#34892;&#21160;&#20197;&#25552;&#39640;&#29615;&#22659;&#30693;&#35782;&#30340;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#65288;&#25506;&#32034;-&#21033;&#29992;&#30340;&#24179;&#34913;&#65289;&#12290;&#21516;&#26102;&#65292;&#21478;&#19968;&#20010;&#30456;&#20851;&#38382;&#39064;&#26159;&#29366;&#24577;&#30340;&#23436;&#20840;&#21487;&#35266;&#27979;&#24615;&#65292;&#19981;&#26159;&#25152;&#26377;&#24212;&#29992;&#37117;&#33021;&#20551;&#23450;&#12290;&#20363;&#22914;&#65292;&#24403;&#21482;&#23558;2D&#22270;&#20687;&#20316;&#20026;&#36755;&#20837;&#29992;&#20110;&#22312;3D&#27169;&#25311;&#29615;&#22659;&#20013;&#25214;&#21040;&#26368;&#20339;&#34892;&#21160;&#26102;&#65292;&#23601;&#23384;&#22312;&#36825;&#20010;&#38382;&#39064;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#37096;&#32626;&#21644;&#27979;&#35797;&#22810;&#31181;&#25216;&#26415;&#26469;&#35299;&#20915;&#37096;&#20998;&#21487;&#35266;&#27979;&#31995;&#32479;&#20013;&#25506;&#32034;&#21644;&#21033;&#29992;&#30340;&#24179;&#34913;&#38382;&#39064;&#65292;&#20197;&#39044;&#27979;&#33258;&#21160;&#39550;&#39542;&#22330;&#26223;&#20013;&#30340;&#26041;&#21521;&#30424;&#25805;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
Incomplete knowledge of the environment leads an agent to make decisions under uncertainty. One of the major dilemmas in Reinforcement Learning (RL) where an autonomous agent has to balance two contrasting needs in making its decisions is: exploiting the current knowledge of the environment to maximize the cumulative reward as well as exploring actions that allow improving the knowledge of the environment, hopefully leading to higher reward values (exploration-exploitation trade-off). Concurrently, another relevant issue regards the full observability of the states, which may not be assumed in all applications. Such as when only 2D images are considered as input in a RL approach used for finding the optimal action within a 3D simulation environment. In this work, we address these issues by deploying and testing several techniques to balance exploration and exploitation trade-off on partially observable systems for predicting steering wheels in autonomous driving scenario. More precisel
&lt;/p&gt;</description></item><item><title>SWoTTeD&#26159;&#19968;&#31181;&#25193;&#23637;&#30340;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;&#65292;&#29992;&#20110;&#21457;&#29616;&#22797;&#26434;&#26102;&#38388;&#27169;&#24335;&#19979;&#30340;&#38544;&#34255;&#34920;&#24449;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;SWoTTeD&#19981;&#20165;&#33021;&#19982;&#26368;&#26032;&#30340;&#22522;&#20110;&#24352;&#37327;&#20998;&#35299;&#30340;&#26041;&#27861;&#19968;&#26679;&#20934;&#30830;&#22320;&#37325;&#24314;&#25968;&#25454;&#65292;&#36824;&#33021;&#25552;&#21462;&#20986;&#23545;&#20020;&#24202;&#21307;&#29983;&#26377;&#24847;&#20041;&#30340;&#26102;&#38388;&#34920;&#24449;&#12290;</title><link>http://arxiv.org/abs/2310.01201</link><description>&lt;p&gt;
SWoTTeD:&#24352;&#37327;&#20998;&#35299;&#22312;&#26102;&#38388;&#34920;&#24449;&#20013;&#30340;&#25193;&#23637;
&lt;/p&gt;
&lt;p&gt;
SWoTTeD: An Extension of Tensor Decomposition to Temporal Phenotyping. (arXiv:2310.01201v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01201
&lt;/p&gt;
&lt;p&gt;
SWoTTeD&#26159;&#19968;&#31181;&#25193;&#23637;&#30340;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;&#65292;&#29992;&#20110;&#21457;&#29616;&#22797;&#26434;&#26102;&#38388;&#27169;&#24335;&#19979;&#30340;&#38544;&#34255;&#34920;&#24449;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;SWoTTeD&#19981;&#20165;&#33021;&#19982;&#26368;&#26032;&#30340;&#22522;&#20110;&#24352;&#37327;&#20998;&#35299;&#30340;&#26041;&#27861;&#19968;&#26679;&#20934;&#30830;&#22320;&#37325;&#24314;&#25968;&#25454;&#65292;&#36824;&#33021;&#25552;&#21462;&#20986;&#23545;&#20020;&#24202;&#21307;&#29983;&#26377;&#24847;&#20041;&#30340;&#26102;&#38388;&#34920;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24352;&#37327;&#20998;&#35299;&#26368;&#36817;&#22312;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#23545;&#20110;&#20010;&#20307;&#36861;&#36394;&#25968;&#25454;&#30340;&#20998;&#26512;&#65292;&#22914;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;(EHR)&#65292;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#24403;&#25968;&#25454;&#36981;&#24490;&#22797;&#26434;&#30340;&#26102;&#38388;&#27169;&#24335;&#26102;&#65292;&#36825;&#20010;&#20219;&#21153;&#21464;&#24471;&#26356;&#21152;&#22256;&#38590;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#26102;&#38388;&#34920;&#24449;&#30340;&#27010;&#24565;&#65292;&#21363;&#19968;&#32452;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#29305;&#24449;&#65292;&#24182;&#25552;&#20986;&#20102;SWoTTeD (Sliding Window for Temporal Tensor Decomposition)&#26041;&#27861;&#65292;&#19968;&#31181;&#21457;&#29616;&#38544;&#34255;&#26102;&#38388;&#27169;&#24335;&#30340;&#26032;&#26041;&#27861;&#12290;SWoTTeD&#38598;&#25104;&#20102;&#22810;&#31181;&#32422;&#26463;&#21644;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#20197;&#22686;&#24378;&#25552;&#21462;&#21040;&#30340;&#34920;&#24449;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#36827;&#34892;&#39564;&#35777;&#65292;&#24182;&#25552;&#20379;&#20102;&#20351;&#29992;&#24052;&#40654;&#22823;&#23398;&#21307;&#38498;&#30340;&#25968;&#25454;&#30340;&#21407;&#22987;&#29992;&#20363;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;SWoTTeD&#33021;&#22815;&#33267;&#23569;&#19982;&#26368;&#26032;&#30340;&#22522;&#20110;&#24352;&#37327;&#20998;&#35299;&#30340;&#27169;&#22411;&#19968;&#26679;&#20934;&#30830;&#22320;&#37325;&#24314;&#25968;&#25454;&#65292;&#24182;&#25552;&#21462;&#21040;&#23545;&#20020;&#24202;&#21307;&#29983;&#26377;&#24847;&#20041;&#30340;&#26102;&#38388;&#34920;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tensor decomposition has recently been gaining attention in the machine learning community for the analysis of individual traces, such as Electronic Health Records (EHR). However, this task becomes significantly more difficult when the data follows complex temporal patterns. This paper introduces the notion of a temporal phenotype as an arrangement of features over time and it proposes SWoTTeD (Sliding Window for Temporal Tensor Decomposition), a novel method to discover hidden temporal patterns. SWoTTeD integrates several constraints and regularizations to enhance the interpretability of the extracted phenotypes. We validate our proposal using both synthetic and real-world datasets, and we present an original usecase using data from the Greater Paris University Hospital. The results show that SWoTTeD achieves at least as accurate reconstruction as recent state-of-the-art tensor decomposition models, and extracts temporal phenotypes that are meaningful for clinicians.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35843;&#26597;&#20102;&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#20998;&#23376;&#22270;&#29983;&#25104;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#33021;&#21147;&#65292;&#24182;&#36890;&#36807;&#26367;&#25442;&#22270;&#29983;&#25104;&#27169;&#22411;&#30340;&#22522;&#30784;GNN&#26469;&#36827;&#34892;&#23454;&#39564;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#20351;&#29992;&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;GNN&#21487;&#20197;&#25913;&#21892;&#29983;&#25104;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.11978</link><description>&lt;p&gt;
&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#29983;&#25104;&#20219;&#21153;&#20013;&#26159;&#21542;&#26356;&#22909;&#65311;
&lt;/p&gt;
&lt;p&gt;
Will More Expressive Graph Neural Networks do Better on Generative Tasks?. (arXiv:2308.11978v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11978
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35843;&#26597;&#20102;&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#20998;&#23376;&#22270;&#29983;&#25104;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#33021;&#21147;&#65292;&#24182;&#36890;&#36807;&#26367;&#25442;&#22270;&#29983;&#25104;&#27169;&#22411;&#30340;&#22522;&#30784;GNN&#26469;&#36827;&#34892;&#23454;&#39564;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#20351;&#29992;&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;GNN&#21487;&#20197;&#25913;&#21892;&#29983;&#25104;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#29983;&#25104;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#25361;&#25112;&#65292;&#23427;&#28041;&#21450;&#26681;&#25454;&#32473;&#23450;&#30340;&#26631;&#31614;&#39044;&#27979;&#19968;&#20010;&#23436;&#25972;&#30340;&#20855;&#26377;&#22810;&#20010;&#33410;&#28857;&#21644;&#36793;&#30340;&#22270;&#12290;&#36825;&#20010;&#20219;&#21153;&#23545;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#38750;&#24120;&#37325;&#35201;&#65292;&#21253;&#25324;&#33647;&#29289;&#21644;&#20998;&#23376;&#35774;&#35745;&#12290;&#36817;&#24180;&#26469;&#65292;&#22312;&#22270;&#29983;&#25104;&#39046;&#22495;&#20986;&#29616;&#20102;&#20960;&#31181;&#25104;&#21151;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#23384;&#22312;&#20004;&#20010;&#37325;&#22823;&#38382;&#39064;&#65306;(1) &#36825;&#20123;&#26041;&#27861;&#20013;&#20351;&#29992;&#30340;&#22522;&#30784;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#26550;&#26500;&#24448;&#24448;&#26410;&#32463;&#28145;&#20837;&#25506;&#32034;&#65307;(2) &#36825;&#20123;&#26041;&#27861;&#24448;&#24448;&#21482;&#22312;&#26377;&#38480;&#30340;&#25351;&#26631;&#19978;&#36827;&#34892;&#35780;&#20272;&#12290;&#20026;&#22635;&#34917;&#36825;&#20010;&#31354;&#30333;&#65292;&#25105;&#20204;&#36890;&#36807;&#23558;&#22270;&#29983;&#25104;&#27169;&#22411;&#30340;&#22522;&#30784;GNN&#26367;&#25442;&#20026;&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;GNN&#65292;&#30740;&#31350;&#20102;GNN&#22312;&#20998;&#23376;&#22270;&#29983;&#25104;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#33021;&#21147;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#20004;&#31181;&#19981;&#21516;&#29983;&#25104;&#26694;&#26550;&#65288;GCPN&#21644;GraphAF&#65289;&#20013;&#20845;&#31181;GNN&#22312;&#20845;&#20010;&#19981;&#21516;&#30340;&#20998;&#23376;&#29983;&#25104;&#30446;&#26631;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph generation poses a significant challenge as it involves predicting a complete graph with multiple nodes and edges based on simply a given label. This task also carries fundamental importance to numerous real-world applications, including de-novo drug and molecular design. In recent years, several successful methods have emerged in the field of graph generation. However, these approaches suffer from two significant shortcomings: (1) the underlying Graph Neural Network (GNN) architectures used in these methods are often underexplored; and (2) these methods are often evaluated on only a limited number of metrics. To fill this gap, we investigate the expressiveness of GNNs under the context of the molecular graph generation task, by replacing the underlying GNNs of graph generative models with more expressive GNNs. Specifically, we analyse the performance of six GNNs in two different generative frameworks (GCPN and GraphAF), on six different molecular generative objectives on the ZIN
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#32771;&#34385;&#20102;&#20855;&#26377;&#26410;&#35266;&#27979;&#28151;&#28102;&#22240;&#32032;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#38382;&#39064;&#65292;&#22312;&#32467;&#26524;&#26159;&#30830;&#23450;&#24615;&#29983;&#25104;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21333;&#19968;&#20195;&#29702;&#21464;&#37327;&#30340;&#20869;&#26680;&#26041;&#27861;&#65292;&#36890;&#36807;&#20004;&#38454;&#27573;&#22238;&#24402;&#21644;&#26368;&#22823;&#30697;&#32422;&#26463;&#30340;&#26041;&#27861;&#21487;&#20197;&#19968;&#33268;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#25104;&#21151;&#24674;&#22797;&#20102;&#22240;&#26524;&#25928;&#24212;&#12290;</title><link>http://arxiv.org/abs/2308.04585</link><description>&lt;p&gt;
&#20915;&#23450;&#24615;&#28151;&#28102;&#19979;&#30340;&#20869;&#26680;&#21333;&#19968;&#20195;&#29702;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Kernel Single Proxy Control for Deterministic Confounding. (arXiv:2308.04585v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04585
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#32771;&#34385;&#20102;&#20855;&#26377;&#26410;&#35266;&#27979;&#28151;&#28102;&#22240;&#32032;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#38382;&#39064;&#65292;&#22312;&#32467;&#26524;&#26159;&#30830;&#23450;&#24615;&#29983;&#25104;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21333;&#19968;&#20195;&#29702;&#21464;&#37327;&#30340;&#20869;&#26680;&#26041;&#27861;&#65292;&#36890;&#36807;&#20004;&#38454;&#27573;&#22238;&#24402;&#21644;&#26368;&#22823;&#30697;&#32422;&#26463;&#30340;&#26041;&#27861;&#21487;&#20197;&#19968;&#33268;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#25104;&#21151;&#24674;&#22797;&#20102;&#22240;&#26524;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20855;&#26377;&#26410;&#35266;&#27979;&#28151;&#28102;&#22240;&#32032;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#38382;&#39064;&#65292;&#20854;&#20013;&#25105;&#20204;&#35266;&#27979;&#21040;&#19982;&#28151;&#28102;&#22240;&#32032;&#30456;&#20851;&#30340;&#20195;&#29702;&#21464;&#37327;&#12290;&#23613;&#31649;&#20195;&#29702;&#22240;&#26524;&#23398;&#20064;&#65288;PCL&#65289;&#20351;&#29992;&#20004;&#20010;&#20195;&#29702;&#21464;&#37327;&#26469;&#24674;&#22797;&#30495;&#23454;&#30340;&#22240;&#26524;&#25928;&#24212;&#65292;&#25105;&#20204;&#35777;&#26126;&#22914;&#26524;&#32467;&#26524;&#26159;&#30830;&#23450;&#24615;&#29983;&#25104;&#30340;&#65292;&#21017;&#20351;&#29992;&#21333;&#20010;&#20195;&#29702;&#21464;&#37327;&#23601;&#36275;&#20197;&#36827;&#34892;&#22240;&#26524;&#20272;&#35745;&#65292;&#24182;&#27010;&#25324;&#20102;&#25511;&#21046;&#32467;&#26524;&#26657;&#20934;&#27861;&#65288;COCA&#65289;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#20869;&#26680;&#30340;&#26041;&#27861;&#65306;&#19968;&#31181;&#22522;&#20110;&#20004;&#38454;&#27573;&#22238;&#24402;&#26041;&#27861;&#65292;&#21478;&#19968;&#31181;&#22522;&#20110;&#26368;&#22823;&#30697;&#32422;&#26463;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#21487;&#20197;&#19968;&#33268;&#22320;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#36890;&#36807;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#23454;&#35777;&#23454;&#39564;&#25104;&#21151;&#22320;&#24674;&#22797;&#20102;&#22240;&#26524;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of causal effect estimation with an unobserved confounder, where we observe a proxy variable that is associated with the confounder. Although Proxy Causal Learning (PCL) uses two proxy variables to recover the true causal effect, we show that a single proxy variable is sufficient for causal estimation if the outcome is generated deterministically, generalizing Control Outcome Calibration Approach (COCA). We propose two kernel-based methods for this setting: the first based on the two-stage regression approach, and the second based on a maximum moment restriction approach. We prove that both approaches can consistently estimate the causal effect, and we empirically demonstrate that we can successfully recover the causal effect on a synthetic dataset.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#23376;&#39640;&#26031;&#28151;&#21512;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#29992;&#20110;&#22810;&#23610;&#24230;&#32858;&#31867;&#21644;&#28304;&#20998;&#31163;&#65292;&#36890;&#36807;&#21033;&#29992;&#23567;&#27874;&#25955;&#23556;&#21327;&#26041;&#24046;&#26469;&#25552;&#20379;&#38543;&#26426;&#36807;&#31243;&#30340;&#20302;&#32500;&#34920;&#31034;&#65292;&#33021;&#22815;&#21306;&#20998;&#19981;&#21516;&#30340;&#38750;&#39640;&#26031;&#38543;&#26426;&#36807;&#31243;&#65292;&#24182;&#22312;MRO&#25968;&#25454;&#38598;&#19978;&#23637;&#29616;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.16189</link><description>&lt;p&gt;
&#28779;&#26143;&#26102;&#38388;&#24207;&#21015;&#20998;&#35299;&#65306;&#19968;&#31181;&#22810;&#23610;&#24230;&#23884;&#22871;&#26041;&#27861;&#20013;&#30340;&#22240;&#23376;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Martian time-series unraveled: A multi-scale nested approach with factorial variational autoencoders. (arXiv:2305.16189v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16189
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#23376;&#39640;&#26031;&#28151;&#21512;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#29992;&#20110;&#22810;&#23610;&#24230;&#32858;&#31867;&#21644;&#28304;&#20998;&#31163;&#65292;&#36890;&#36807;&#21033;&#29992;&#23567;&#27874;&#25955;&#23556;&#21327;&#26041;&#24046;&#26469;&#25552;&#20379;&#38543;&#26426;&#36807;&#31243;&#30340;&#20302;&#32500;&#34920;&#31034;&#65292;&#33021;&#22815;&#21306;&#20998;&#19981;&#21516;&#30340;&#38750;&#39640;&#26031;&#38543;&#26426;&#36807;&#31243;&#65292;&#24182;&#22312;MRO&#25968;&#25454;&#38598;&#19978;&#23637;&#29616;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#30340;&#28304;&#20998;&#31163;&#28041;&#21450;&#36890;&#36807;&#28151;&#21512;&#25805;&#20316;&#35760;&#24405;&#30340;&#26410;&#30693;&#28304;&#20449;&#21495;&#30340;&#20998;&#35299;&#65292;&#20854;&#20013;&#23545;&#28304;&#30340;&#20808;&#39564;&#30693;&#35782;&#26377;&#38480;&#65292;&#20165;&#21487;&#20197;&#35775;&#38382;&#20449;&#21495;&#28151;&#21512;&#25968;&#25454;&#38598;&#12290;&#36825;&#20010;&#38382;&#39064;&#26412;&#36136;&#19978;&#26159;&#19981;&#36866;&#29992;&#30340;&#65292;&#24182;&#19988;&#36827;&#19968;&#27493;&#21463;&#21040;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#28304;&#23637;&#29616;&#20986;&#30340;&#22810;&#31181;&#26102;&#38388;&#23610;&#24230;&#30340;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#30340;&#22810;&#23610;&#24230;&#32858;&#31867;&#21644;&#28304;&#20998;&#31163;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#23567;&#27874;&#25955;&#23556;&#21327;&#26041;&#24046;&#26469;&#25552;&#20379;&#38543;&#26426;&#36807;&#31243;&#30340;&#20302;&#32500;&#34920;&#31034;&#65292;&#33021;&#22815;&#21306;&#20998;&#19981;&#21516;&#30340;&#38750;&#39640;&#26031;&#38543;&#26426;&#36807;&#31243;&#12290;&#22312;&#36825;&#20010;&#34920;&#31034;&#31354;&#38388;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#22240;&#23376;&#39640;&#26031;&#28151;&#21512;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#23427;&#34987;&#35757;&#32451;&#29992;&#20110;(1)&#27010;&#29575;&#22320;&#23545;&#19981;&#21516;&#26102;&#38388;&#23610;&#24230;&#19978;&#30340;&#28304;&#36827;&#34892;&#32858;&#31867;&#21644;&#36880;&#23618;&#38750;&#30417;&#30563;&#28304;&#20998;&#31163;&#65292;(2)&#22312;&#27599;&#20010;&#26102;&#38388;&#23610;&#24230;&#19978;&#25552;&#21462;&#20302;&#32500;&#34920;&#31034;&#65292;(3)&#23398;&#20064;&#28304;&#20449;&#21495;&#30340;&#22240;&#23376;&#34920;&#31034;&#65292;(4)&#22312;&#34920;&#31034;&#31354;&#38388;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#20197;&#29983;&#25104;&#26410;&#30693;&#28304;&#20449;&#21495;&#12290;&#25105;&#20204;&#22312;MRO&#19978;&#30340;&#19977;&#20010;&#39057;&#36947;&#30340;&#21487;&#35265;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#32467;&#26524;&#34920;&#26126;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#27604;&#30446;&#21069;&#26368;&#20808;&#36827;&#30340;&#25216;&#26415;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unsupervised source separation involves unraveling an unknown set of source signals recorded through a mixing operator, with limited prior knowledge about the sources, and only access to a dataset of signal mixtures. This problem is inherently ill-posed and is further challenged by the variety of time-scales exhibited by sources in time series data. Existing methods typically rely on a preselected window size that limits their capacity to handle multi-scale sources. To address this issue, instead of operating in the time domain, we propose an unsupervised multi-scale clustering and source separation framework by leveraging wavelet scattering covariances that provide a low-dimensional representation of stochastic processes, capable of distinguishing between different non-Gaussian stochastic processes. Nested within this representation space, we develop a factorial Gaussian-mixture variational autoencoder that is trained to (1) probabilistically cluster sources at different time-scales a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;Riesz&#26680;&#23637;&#31034;&#20102;&#29983;&#25104;&#24335;&#20998;&#21106;MMD&#27969;&#30340;&#39640;&#25928;&#35745;&#31639;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#22823;&#35268;&#27169;&#24212;&#29992;&#20013;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2305.11463</link><description>&lt;p&gt;
&#21033;&#29992;Riesz&#26680;&#30340;&#29983;&#25104;&#24335;&#20998;&#21106;MMD&#27969;
&lt;/p&gt;
&lt;p&gt;
Generative Sliced MMD Flows with Riesz Kernels. (arXiv:2305.11463v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11463
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;Riesz&#26680;&#23637;&#31034;&#20102;&#29983;&#25104;&#24335;&#20998;&#21106;MMD&#27969;&#30340;&#39640;&#25928;&#35745;&#31639;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#22823;&#35268;&#27169;&#24212;&#29992;&#20013;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#35268;&#27169;&#35745;&#31639;&#20013;&#65292;&#26368;&#22823;&#24179;&#22343;&#24046;&#24322;&#24230;(MMD)&#27969;&#30340;&#35745;&#31639;&#25104;&#26412;&#24456;&#39640;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;Riesz&#26680;$K(x,y)=-\|x-y\|^r$&#65292;$r \in (0,2)$&#30340;MMD&#27969;&#20855;&#26377;&#26480;&#20986;&#30340;&#24615;&#36136;&#65292;&#21487;&#20801;&#35768;&#20854;&#36827;&#34892;&#39640;&#25928;&#35745;&#31639;&#12290;&#39318;&#20808;&#65292;Riesz&#26680;&#30340;MMD&#19982;&#20854;&#20998;&#21106;&#29256;&#26412;&#30340;MMD&#37325;&#21512;&#12290;&#22240;&#27492;&#65292;&#21487;&#20197;&#22312;&#19968;&#32500;&#35774;&#32622;&#20013;&#36827;&#34892;MMD&#26799;&#24230;&#30340;&#35745;&#31639;&#12290;&#22312;&#27492;&#22788;&#65292;&#23545;&#20110;$r=1$&#65292;&#21487;&#20197;&#24212;&#29992;&#31616;&#21333;&#30340;&#25490;&#24207;&#31639;&#27861;&#23558;&#20004;&#20010;&#32463;&#39564;&#24230;&#37327;&#30340;&#22797;&#26434;&#24230;&#20174;$O(MN+N^2)$&#38477;&#20302;&#21040;$O((M+N)\log(M+N))$&#65292;&#20854;&#20013;$M$&#21644;$N$&#26159;&#25903;&#25345;&#28857;&#12290;&#23545;&#20110;&#23454;&#29616;&#65292;&#25105;&#20204;&#36890;&#36807;&#20165;&#20351;&#29992;&#26377;&#38480;&#25968;&#37327;&#30340;$P$&#20010;&#20999;&#29255;&#26469;&#36817;&#20284;&#20998;&#21106;MMD&#30340;&#26799;&#24230;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#30001;&#27492;&#20135;&#29983;&#30340;&#35823;&#24046;&#20855;&#26377;$O(\sqrt{d/P})$&#30340;&#22797;&#26434;&#24230;&#65292;&#20854;&#20013;$d$&#26159;&#25968;&#25454;&#32500;&#24230;&#12290;&#36825;&#20123;&#32467;&#26524;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;MMD&#26799;&#24230;&#27969;&#26469;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#65292;&#29978;&#33267;&#29992;&#20110;&#22823;&#35268;&#27169;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Maximum mean discrepancy (MMD) flows suffer from high computational costs in large scale computations. In this paper, we show that MMD flows with Riesz kernels $K(x,y) = - \|x-y\|^r$, $r \in (0,2)$ have exceptional properties which allow for their efficient computation. First, the MMD of Riesz kernels coincides with the MMD of their sliced version. As a consequence, the computation of gradients of MMDs can be performed in the one-dimensional setting. Here, for $r=1$, a simple sorting algorithm can be applied to reduce the complexity from $O(MN+N^2)$ to $O((M+N)\log(M+N))$ for two empirical measures with $M$ and $N$ support points. For the implementations we approximate the gradient of the sliced MMD by using only a finite number $P$ of slices. We show that the resulting error has complexity $O(\sqrt{d/P})$, where $d$ is the data dimension. These results enable us to train generative models by approximating MMD gradient flows by neural networks even for large scale applications. We demo
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#23618;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#20351;&#29992;&#30340;&#26799;&#24230;&#35745;&#31639;&#27425;&#25968; $O((n+m)^{\frac{1}{2}}\varepsilon^{-1})$&#65292;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#26041;&#38754;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2302.08766</link><description>&lt;p&gt;
&#19968;&#31181;&#21452;&#23618;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31639;&#27861;&#30340;&#19979;&#30028;&#21644;&#36817;&#20284;&#26368;&#20248;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Lower Bound and a Near-Optimal Algorithm for Bilevel Empirical Risk Minimization. (arXiv:2302.08766v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08766
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#23618;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#20351;&#29992;&#30340;&#26799;&#24230;&#35745;&#31639;&#27425;&#25968; $O((n+m)^{\frac{1}{2}}\varepsilon^{-1})$&#65292;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#26041;&#38754;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21452;&#23618;&#26368;&#20248;&#21270;&#38382;&#39064;&#36234;&#26469;&#36234;&#22810;&#22320;&#24212;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#20013;&#12290;&#22312;&#35768;&#22810;&#23454;&#38469;&#24773;&#20917;&#19979;&#65292;&#19978;&#23618;&#21644;&#19979;&#23618;&#30446;&#26631;&#23545;&#24212;&#20110;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#24182;&#22240;&#27492;&#20855;&#26377;&#24635;&#21644;&#32467;&#26500;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#33879;&#21517;&#30340;SARAH&#31639;&#27861;&#30340;&#21452;&#23618;&#25193;&#23637;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#38656;&#35201;$\mathcal {O}((n+m)^{\frac{1}{2}}\varepsilon ^{-1})$&#27425;&#26799;&#24230;&#35745;&#31639;&#25165;&#33021;&#23454;&#29616;$\varepsilon$&#31283;&#23450;&#24615;&#65292;&#20854;&#20013;$n+m$&#26159;&#26679;&#26412;&#24635;&#25968;&#65292;&#36825;&#27604;&#20808;&#21069;&#25152;&#26377;&#30340;&#21452;&#23618;&#31639;&#27861;&#37117;&#35201;&#22909;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#19979;&#30028;&#65292;&#29992;&#20110;&#24471;&#21040;&#21452;&#23618;&#38382;&#39064;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;&#36817;&#20284;&#31283;&#23450;&#28857;&#25152;&#38656;&#30340;oracle&#35843;&#29992;&#27425;&#25968;&#12290;&#36825;&#20010;&#19979;&#30028;&#27491;&#26159;&#25105;&#20204;&#30340;&#31639;&#27861;&#25152;&#36798;&#21040;&#30340;&#65292;&#22240;&#27492;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#26041;&#38754;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bilevel optimization problems, which are problems where two optimization problems are nested, have more and more applications in machine learning. In many practical cases, the upper and the lower objectives correspond to empirical risk minimization problems and therefore have a sum structure. In this context, we propose a bilevel extension of the celebrated SARAH algorithm. We demonstrate that the algorithm requires $\mathcal{O}((n+m)^{\frac12}\varepsilon^{-1})$ gradient computations to achieve $\varepsilon$-stationarity with $n+m$ the total number of samples, which improves over all previous bilevel algorithms. Moreover, we provide a lower bound on the number of oracle calls required to get an approximate stationary point of the objective function of the bilevel problem. This lower bound is attained by our algorithm, which is therefore optimal in terms of sample complexity.
&lt;/p&gt;</description></item><item><title>Survival Kernets &#26159;&#19968;&#31181;&#21487;&#25193;&#23637;&#19988;&#21487;&#35299;&#37322;&#30340;&#28145;&#24230;&#26680;&#29983;&#23384;&#20998;&#26512;&#27169;&#22411;&#65292;&#33021;&#22815;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#27169;&#22411;&#35299;&#37322;&#21644;&#29702;&#35770;&#20998;&#26512;&#12290;&#23427;&#21033;&#29992;&#26680;&#20989;&#25968;&#20272;&#35745;&#20010;&#20307;&#30340;&#29983;&#23384;&#20998;&#24067;&#65292;&#36890;&#36807;&#35757;&#32451;&#38598;&#21387;&#32553;&#26041;&#26696;&#36827;&#34892;&#25968;&#25454;&#20998;&#31751;&#65292;&#22240;&#27492;&#20855;&#26377;&#36739;&#39640;&#30340;&#21487;&#35270;&#21270;&#33021;&#21147;&#21644;&#39044;&#27979;&#20934;&#30830;&#24615;&#20445;&#35777;&#12290;&#35813;&#27169;&#22411;&#22312;&#29305;&#23450;&#24773;&#20917;&#19979;&#30340;&#39044;&#27979;&#29983;&#23384;&#20998;&#24067;&#35823;&#24046;&#30028;&#38480;&#26368;&#20248;&#65292;&#19988;&#22312;&#27979;&#35797;&#26102;&#20855;&#26377;&#21487;&#25193;&#23637;&#24615;&#12290;</title><link>http://arxiv.org/abs/2206.10477</link><description>&lt;p&gt;
Survival Kernets: &#21487;&#25193;&#23637;&#19988;&#21487;&#35299;&#37322;&#30340;&#28145;&#24230;&#26680;&#29983;&#23384;&#20998;&#26512;&#27169;&#22411;&#65292;&#24182;&#20855;&#26377;&#20934;&#30830;&#24615;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Survival Kernets: Scalable and Interpretable Deep Kernel Survival Analysis with an Accuracy Guarantee. (arXiv:2206.10477v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.10477
&lt;/p&gt;
&lt;p&gt;
Survival Kernets &#26159;&#19968;&#31181;&#21487;&#25193;&#23637;&#19988;&#21487;&#35299;&#37322;&#30340;&#28145;&#24230;&#26680;&#29983;&#23384;&#20998;&#26512;&#27169;&#22411;&#65292;&#33021;&#22815;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#27169;&#22411;&#35299;&#37322;&#21644;&#29702;&#35770;&#20998;&#26512;&#12290;&#23427;&#21033;&#29992;&#26680;&#20989;&#25968;&#20272;&#35745;&#20010;&#20307;&#30340;&#29983;&#23384;&#20998;&#24067;&#65292;&#36890;&#36807;&#35757;&#32451;&#38598;&#21387;&#32553;&#26041;&#26696;&#36827;&#34892;&#25968;&#25454;&#20998;&#31751;&#65292;&#22240;&#27492;&#20855;&#26377;&#36739;&#39640;&#30340;&#21487;&#35270;&#21270;&#33021;&#21147;&#21644;&#39044;&#27979;&#20934;&#30830;&#24615;&#20445;&#35777;&#12290;&#35813;&#27169;&#22411;&#22312;&#29305;&#23450;&#24773;&#20917;&#19979;&#30340;&#39044;&#27979;&#29983;&#23384;&#20998;&#24067;&#35823;&#24046;&#30028;&#38480;&#26368;&#20248;&#65292;&#19988;&#22312;&#27979;&#35797;&#26102;&#20855;&#26377;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#29983;&#23384;&#20998;&#26512;&#27169;&#22411;&#36890;&#36807;&#26680;&#20989;&#25968;&#26469;&#20272;&#35745;&#20010;&#20307;&#30340;&#29983;&#23384;&#20998;&#24067;&#65292;&#26680;&#20989;&#25968;&#24230;&#37327;&#20219;&#24847;&#20004;&#20010;&#25968;&#25454;&#28857;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28145;&#24230;&#26680;&#29983;&#23384;&#27169;&#22411;&#8212;&#8212;&#29983;&#23384;kernet&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#65292;&#24182;&#19988;&#26131;&#20110;&#35299;&#37322;&#21644;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35757;&#32451;&#25968;&#25454;&#26681;&#25454;&#19968;&#31181;&#26368;&#36817;&#21457;&#23637;&#30340;&#29992;&#20110;&#20998;&#31867;&#21644;&#22238;&#24402;&#30340;&#35757;&#32451;&#38598;&#21387;&#32553;&#26041;&#26696;&#65288;&#31216;&#20026;&#26680;&#32676;&#65289;&#36827;&#34892;&#20998;&#31751;&#12290;&#22312;&#27979;&#35797;&#26102;&#65292;&#27599;&#20010;&#25968;&#25454;&#28857;&#34987;&#34920;&#31034;&#20026;&#36825;&#20123;&#31751;&#30340;&#21152;&#26435;&#32452;&#21512;&#65292;&#27599;&#20010;&#31751;&#21487;&#20197;&#36827;&#34892;&#21487;&#35270;&#21270;&#23637;&#31034;&#12290;&#23545;&#20110;&#29983;&#23384;kernet&#30340;&#19968;&#20010;&#29305;&#27530;&#24773;&#20917;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#26377;&#38480;&#26679;&#26412;&#35823;&#24046;&#30028;&#38480;&#65292;&#39044;&#27979;&#30340;&#29983;&#23384;&#20998;&#24067;&#22312;&#35813;&#30028;&#38480;&#19979;&#26159;&#26368;&#20248;&#30340;&#65288;&#38500;&#21435;&#19968;&#20010;&#23545;&#25968;&#22240;&#23376;&#65289;&#12290;&#22312;&#27979;&#35797;&#26102;&#20855;&#26377;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernel survival analysis models estimate individual survival distributions with the help of a kernel function, which measures the similarity between any two data points. Such a kernel function can be learned using deep kernel survival models. In this paper, we present a new deep kernel survival model called a survival kernet, which scales to large datasets in a manner that is amenable to model interpretation and also theoretical analysis. Specifically, the training data are partitioned into clusters based on a recently developed training set compression scheme for classification and regression called kernel netting that we extend to the survival analysis setting. At test time, each data point is represented as a weighted combination of these clusters, and each such cluster can be visualized. For a special case of survival kernets, we establish a finite-sample error bound on predicted survival distributions that is, up to a log factor, optimal. Whereas scalability at test time is achiev
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25209;&#37327;&#24322;&#27493;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#65292;&#23427;&#21487;&#20197;&#22312;&#20869;&#23384;&#38656;&#27714;&#21644;&#26102;&#38388;&#22797;&#26434;&#24230;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#21487;&#20197;&#20351;&#29992;&#36739;&#24369;&#20551;&#35774;&#35777;&#26126;&#25910;&#25947;&#30340;&#19968;&#33324;&#26041;&#27861;&#65307;&#22312;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#65292;&#25105;&#20204;&#20351;&#29992;&#27492;&#26041;&#27861;&#35777;&#26126;&#20102;SARSA&#31639;&#27861;&#30340;&#25209;&#37327;&#24322;&#27493;&#29256;&#26412;&#30340;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2109.03445</link><description>&lt;p&gt;
&#25209;&#37327;&#24322;&#27493;&#38543;&#26426;&#36924;&#36817;&#30340;&#25910;&#25947;&#24615;&#21450;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Convergence of Batch Asynchronous Stochastic Approximation With Applications to Reinforcement Learning. (arXiv:2109.03445v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.03445
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25209;&#37327;&#24322;&#27493;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#65292;&#23427;&#21487;&#20197;&#22312;&#20869;&#23384;&#38656;&#27714;&#21644;&#26102;&#38388;&#22797;&#26434;&#24230;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#21487;&#20197;&#20351;&#29992;&#36739;&#24369;&#20551;&#35774;&#35777;&#26126;&#25910;&#25947;&#30340;&#19968;&#33324;&#26041;&#27861;&#65307;&#22312;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#65292;&#25105;&#20204;&#20351;&#29992;&#27492;&#26041;&#27861;&#35777;&#26126;&#20102;SARSA&#31639;&#27861;&#30340;&#25209;&#37327;&#24322;&#27493;&#29256;&#26412;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#36924;&#36817;&#65288;SA&#65289;&#31639;&#27861;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#27010;&#29575;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20165;&#21487;&#29992;&#20989;&#25968;&#30340;&#26377;&#22122;&#27979;&#37327;&#24773;&#20917;&#19979;&#25214;&#21040;&#38646;&#28857;&#25110;&#22266;&#23450;&#28857;&#12290;&#30446;&#21069;&#30340;&#25991;&#29486;&#20013;&#65292;&#21306;&#20998;&#8220;&#21516;&#27493;&#8221;&#26356;&#26032;&#21644;&#8220;&#24322;&#27493;&#8221;&#26356;&#26032;&#65292;&#22312;&#8220;&#21516;&#27493;&#8221;&#26356;&#26032;&#20013;&#65292;&#27599;&#20010;&#29468;&#27979;&#30340;&#32452;&#20214;&#37117;&#20250;&#22312;&#27599;&#20010;&#26102;&#38388;&#26356;&#26032;&#65292;&#32780;&#22312;&#8220;&#24322;&#27493;&#8221;&#26356;&#26032;&#20013;&#65292;&#20165;&#26356;&#26032;&#19968;&#20010;&#32452;&#20214;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#20013;&#38388;&#24773;&#20917;&#65292;&#31216;&#20026;&#8220;&#25209;&#37327;&#24322;&#27493;&#38543;&#26426;&#36924;&#36817;&#8221;&#65288;BASA&#65289;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#27599;&#20010;&#26102;&#38388;&#28857;&#20165;&#26356;&#26032;&#8220;&#24403;&#21069;&#20272;&#35745;&#35299;&#8221;&#30340;&#19968;&#20123;&#20294;&#19981;&#26159;&#20840;&#37096;&#30340;&#32452;&#20214;&#12290;BASA&#20801;&#35768;&#29992;&#25143;&#22312;&#20869;&#23384;&#38656;&#27714;&#21644;&#26102;&#38388;&#22797;&#26434;&#24230;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#36890;&#29992;&#26041;&#27861;&#65292;&#35777;&#26126;&#27492;&#31867;&#31639;&#27861;&#25910;&#25947;&#20110;&#25152;&#30740;&#31350;&#26144;&#23556;&#30340;&#22266;&#23450;&#28857;&#12290;&#36825;&#20123;&#25910;&#25947;&#35777;&#26126;&#20351;&#29992;&#27604;&#29616;&#26377;&#32467;&#26524;&#26356;&#24369;&#30340;&#20551;&#35774;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#29616;&#26377;&#30340;&#25910;&#25947;&#35777;&#26126;&#35201;&#27714;&#27493;&#38271;&#21442;&#25968;&#20197;&#36866;&#24403;&#30340;&#36895;&#29575;&#19979;&#38477;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#20165;&#35201;&#27714;&#27599;&#20010;&#32452;&#20214;&#20855;&#26377;&#36275;&#22815;&#30340;&#26356;&#26032;&#39057;&#29575;&#12290;&#25105;&#20204;&#22312;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#29992;&#24615;&#65292;&#35777;&#26126;&#20102;&#24191;&#27867;&#20351;&#29992;&#30340;SARSA&#31639;&#27861;&#30340;&#25209;&#37327;&#24322;&#27493;&#29256;&#26412;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The stochastic approximation (SA) algorithm is a widely used probabilistic method for finding a zero or a fixed point of a vector-valued funtion, when only noisy measurements of the function are available. In the literature to date, one makes a distinction between ``synchronous'' updating, whereby every component of the current guess is updated at each time, and ``asynchronous'' updating, whereby only one component is updated. In this paper, we study an intermediate situation that we call ``batch asynchronous stochastic approximation'' (BASA), in which, at each time instant, \textit{some but not all} components of the current estimated solution are updated. BASA allows the user to trade off memory requirements against time complexity. We develop a general methodology for proving that such algorithms converge to the fixed point of the map under study. These convergence proofs make use of weaker hypotheses than existing results. Specifically, existing convergence proofs require that the 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#20195;&#29702;&#22240;&#26524;&#23398;&#20064;&#65288;PCL&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#23384;&#22312;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#27835;&#30103;&#23545;&#32467;&#26524;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#36890;&#36807;&#26500;&#24314;&#27835;&#30103;&#21644;&#20195;&#29702;&#20043;&#38388;&#30340;&#27169;&#22411;&#65292;&#24182;&#21033;&#29992;&#35813;&#27169;&#22411;&#22312;&#32473;&#23450;&#20195;&#29702;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#27835;&#30103;&#23545;&#32467;&#26524;&#30340;&#24433;&#21709;&#65292;PCL&#21487;&#20197;&#20445;&#35777;&#24674;&#22797;&#30495;&#23454;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#20316;&#32773;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28145;&#24230;&#29305;&#24449;&#20195;&#29702;&#21464;&#37327;&#26041;&#27861;&#65288;DFPV&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#39640;&#32500;&#21644;&#38750;&#32447;&#24615;&#22797;&#26434;&#20851;&#31995;&#30340;&#24773;&#20917;&#65292;&#24182;&#34920;&#26126;DFPV&#22312;&#21512;&#25104;&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;&#24615;&#33021;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;PCL&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2106.03907</link><description>&lt;p&gt;
&#28145;&#24230;&#20195;&#29702;&#22240;&#26524;&#23398;&#20064;&#21450;&#20854;&#22312;&#28151;&#28102;&#36172;&#21338;&#31574;&#30053;&#35780;&#20272;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Deep Proxy Causal Learning and its Application to Confounded Bandit Policy Evaluation. (arXiv:2106.03907v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.03907
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#20195;&#29702;&#22240;&#26524;&#23398;&#20064;&#65288;PCL&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#23384;&#22312;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#27835;&#30103;&#23545;&#32467;&#26524;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#36890;&#36807;&#26500;&#24314;&#27835;&#30103;&#21644;&#20195;&#29702;&#20043;&#38388;&#30340;&#27169;&#22411;&#65292;&#24182;&#21033;&#29992;&#35813;&#27169;&#22411;&#22312;&#32473;&#23450;&#20195;&#29702;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#27835;&#30103;&#23545;&#32467;&#26524;&#30340;&#24433;&#21709;&#65292;PCL&#21487;&#20197;&#20445;&#35777;&#24674;&#22797;&#30495;&#23454;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#20316;&#32773;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28145;&#24230;&#29305;&#24449;&#20195;&#29702;&#21464;&#37327;&#26041;&#27861;&#65288;DFPV&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#39640;&#32500;&#21644;&#38750;&#32447;&#24615;&#22797;&#26434;&#20851;&#31995;&#30340;&#24773;&#20917;&#65292;&#24182;&#34920;&#26126;DFPV&#22312;&#21512;&#25104;&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;&#24615;&#33021;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;PCL&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20195;&#29702;&#22240;&#26524;&#23398;&#20064;&#65288;PCL&#65289;&#26159;&#19968;&#31181;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#26102;&#65292;&#21033;&#29992;&#20195;&#29702;&#65288;&#32467;&#26500;&#21270;&#20391;&#38754;&#20449;&#24687;&#65289;&#20272;&#35745;&#27835;&#30103;&#23545;&#32467;&#26524;&#30340;&#22240;&#26524;&#25928;&#24212;&#30340;&#26041;&#27861;&#12290;&#36825;&#26159;&#36890;&#36807;&#20004;&#38454;&#27573;&#22238;&#24402;&#23454;&#29616;&#30340;&#65306;&#22312;&#31532;&#19968;&#38454;&#27573;&#65292;&#25105;&#20204;&#24314;&#27169;&#27835;&#30103;&#21644;&#20195;&#29702;&#20043;&#38388;&#30340;&#20851;&#31995;&#65307;&#22312;&#31532;&#20108;&#38454;&#27573;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#20010;&#27169;&#22411;&#26469;&#23398;&#20064;&#22312;&#32473;&#23450;&#20195;&#29702;&#25552;&#20379;&#30340;&#19978;&#19979;&#25991;&#19979;&#65292;&#27835;&#30103;&#23545;&#32467;&#26524;&#30340;&#24433;&#21709;&#12290;PCL&#22312;&#21487;&#35782;&#21035;&#26465;&#20214;&#19979;&#20445;&#35777;&#24674;&#22797;&#30495;&#23454;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;PCL&#26041;&#27861;&#65292;&#28145;&#24230;&#29305;&#24449;&#20195;&#29702;&#21464;&#37327;&#26041;&#27861;&#65288;DFPV&#65289;&#65292;&#20197;&#35299;&#20915;&#20195;&#29702;&#12289;&#27835;&#30103;&#21644;&#32467;&#26524;&#20026;&#39640;&#32500;&#19988;&#20855;&#26377;&#38750;&#32447;&#24615;&#22797;&#26434;&#20851;&#31995;&#30340;&#24773;&#20917;&#65292;&#22914;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#29305;&#24449;&#34920;&#31034;&#12290;&#25105;&#20204;&#34920;&#26126;DFPV&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#21512;&#25104;&#22522;&#20934;&#27979;&#35797;&#20013;&#20248;&#20110;&#26368;&#36817;&#30340;&#26368;&#20808;&#36827;&#30340;PCL&#26041;&#27861;&#65292;&#21253;&#25324;&#28041;&#21450;&#39640;&#32500;&#22270;&#20687;&#25968;&#25454;&#30340;&#35774;&#32622;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;PCL&#30340;&#24212;&#29992;...
&lt;/p&gt;
&lt;p&gt;
Proxy causal learning (PCL) is a method for estimating the causal effect of treatments on outcomes in the presence of unobserved confounding, using proxies (structured side information) for the confounder. This is achieved via two-stage regression: in the first stage, we model relations among the treatment and proxies; in the second stage, we use this model to learn the effect of treatment on the outcome, given the context provided by the proxies. PCL guarantees recovery of the true causal effect, subject to identifiability conditions. We propose a novel method for PCL, the deep feature proxy variable method (DFPV), to address the case where the proxies, treatments, and outcomes are high-dimensional and have nonlinear complex relationships, as represented by deep neural network features. We show that DFPV outperforms recent state-of-the-art PCL methods on challenging synthetic benchmarks, including settings involving high dimensional image data. Furthermore, we show that PCL can be app
&lt;/p&gt;</description></item></channel></rss>