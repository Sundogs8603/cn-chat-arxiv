<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#27867;&#21270;&#23646;&#24615;&#36827;&#34892;&#20102;&#29702;&#35770;&#30740;&#31350;&#65292;&#24314;&#31435;&#20102;&#22522;&#20110;&#35780;&#20998;&#27861;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#35757;&#32451;&#21160;&#24577;&#20013;&#27867;&#21270;&#24046;&#36317;&#30340;&#29702;&#35770;&#20272;&#35745;&#65292;&#24182;&#22312;&#20572;&#27490;&#35757;&#32451;&#26102;&#21487;&#20197;&#36991;&#20813;&#32500;&#24230;&#35781;&#21650;&#12290;&#36827;&#19968;&#27493;&#23558;&#23450;&#37327;&#20998;&#26512;&#25193;&#23637;&#21040;&#20102;&#25968;&#25454;&#20381;&#36182;&#30340;&#24773;&#26223;&#12290;</title><link>http://arxiv.org/abs/2311.01797</link><description>&lt;p&gt;
&#20851;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#27867;&#21270;&#23646;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Generalization Properties of Diffusion Models. (arXiv:2311.01797v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01797
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#27867;&#21270;&#23646;&#24615;&#36827;&#34892;&#20102;&#29702;&#35770;&#30740;&#31350;&#65292;&#24314;&#31435;&#20102;&#22522;&#20110;&#35780;&#20998;&#27861;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#35757;&#32451;&#21160;&#24577;&#20013;&#27867;&#21270;&#24046;&#36317;&#30340;&#29702;&#35770;&#20272;&#35745;&#65292;&#24182;&#22312;&#20572;&#27490;&#35757;&#32451;&#26102;&#21487;&#20197;&#36991;&#20813;&#32500;&#24230;&#35781;&#21650;&#12290;&#36827;&#19968;&#27493;&#23558;&#23450;&#37327;&#20998;&#26512;&#25193;&#23637;&#21040;&#20102;&#25968;&#25454;&#20381;&#36182;&#30340;&#24773;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#26159;&#19968;&#31867;&#29983;&#25104;&#27169;&#22411;&#65292;&#29992;&#20110;&#24314;&#31435;&#19968;&#20010;&#38543;&#26426;&#20256;&#36755;&#26144;&#23556;&#65292;&#23558;&#32463;&#39564;&#35266;&#27979;&#21040;&#30340;&#20294;&#26410;&#30693;&#30340;&#30446;&#26631;&#20998;&#24067;&#19982;&#24050;&#30693;&#30340;&#20808;&#39564;&#20998;&#24067;&#32852;&#31995;&#36215;&#26469;&#12290;&#23613;&#31649;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#65292;&#20294;&#23545;&#20854;&#27867;&#21270;&#33021;&#21147;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#26410;&#20805;&#20998;&#21457;&#23637;&#12290;&#26412;&#25991;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#27867;&#21270;&#23646;&#24615;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#29702;&#35770;&#30740;&#31350;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#22522;&#20110;&#35780;&#20998;&#27861;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#35757;&#32451;&#21160;&#24577;&#20013;&#27867;&#21270;&#24046;&#36317;&#30340;&#29702;&#35770;&#20272;&#35745;&#65292;&#34920;&#26126;&#22312;&#26679;&#26412;&#22823;&#23567;$n$&#21644;&#27169;&#22411;&#23481;&#37327;$m$&#19978;&#37117;&#23384;&#22312;&#22810;&#39033;&#24335;&#23567;&#30340;&#27867;&#21270;&#35823;&#24046;($O(n^{-2/5}+m^{-4/5})$)&#65292;&#22312;&#20572;&#27490;&#35757;&#32451;&#26102;&#21487;&#20197;&#36991;&#20813;&#32500;&#24230;&#35781;&#21650;&#65288;&#21363;&#25968;&#25454;&#32500;&#24230;&#19981;&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#65289;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#23450;&#37327;&#20998;&#26512;&#25193;&#23637;&#21040;&#20102;&#19968;&#20010;&#25968;&#25454;&#20381;&#36182;&#30340;&#24773;&#26223;&#65292;&#20854;&#20013;&#30446;&#26631;&#20998;&#24067;&#34987;&#25551;&#32472;&#20026;&#19968;&#31995;&#21015;&#30340;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models are a class of generative models that serve to establish a stochastic transport map between an empirically observed, yet unknown, target distribution and a known prior. Despite their remarkable success in real-world applications, a theoretical understanding of their generalization capabilities remains underdeveloped. This work embarks on a comprehensive theoretical exploration of the generalization attributes of diffusion models. We establish theoretical estimates of the generalization gap that evolves in tandem with the training dynamics of score-based diffusion models, suggesting a polynomially small generalization error ($O(n^{-2/5}+m^{-4/5})$) on both the sample size $n$ and the model capacity $m$, evading the curse of dimensionality (i.e., not exponentially large in the data dimension) when early-stopped. Furthermore, we extend our quantitative analysis to a data-dependent scenario, wherein target distributions are portrayed as a succession of densities with progr
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#19968;&#31867;&#38750;&#32447;&#24615;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#30340;&#39640;&#27010;&#29575;&#25910;&#25947;&#36793;&#30028;&#12290;&#23545;&#20110;&#20855;&#26377;Lipschitz&#36830;&#32493;&#26799;&#24230;&#30340;&#24378;&#20984;&#25439;&#22833;&#20989;&#25968;&#65292;&#21363;&#20351;&#22122;&#22768;&#26159;&#37325;&#23614;&#30340;&#65292;&#32467;&#26524;&#35777;&#26126;&#20102;&#23545;&#22833;&#36133;&#27010;&#29575;&#30340;&#23545;&#25968;&#20381;&#36182;&#12290;&#36825;&#20123;&#32467;&#26524;&#36866;&#29992;&#20110;&#21098;&#20999;&#12289;&#24402;&#19968;&#21270;&#21644;&#37327;&#21270;&#31561;&#20219;&#20309;&#20855;&#26377;&#26377;&#30028;&#36755;&#20986;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2310.18784</link><description>&lt;p&gt;
&#39640;&#27010;&#29575;&#25910;&#25947;&#36793;&#30028;&#19979;&#30340;&#38750;&#32447;&#24615;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#22312;&#37325;&#23614;&#22122;&#22768;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
High-probability Convergence Bounds for Nonlinear Stochastic Gradient Descent Under Heavy-tailed Noise. (arXiv:2310.18784v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18784
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#19968;&#31867;&#38750;&#32447;&#24615;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#30340;&#39640;&#27010;&#29575;&#25910;&#25947;&#36793;&#30028;&#12290;&#23545;&#20110;&#20855;&#26377;Lipschitz&#36830;&#32493;&#26799;&#24230;&#30340;&#24378;&#20984;&#25439;&#22833;&#20989;&#25968;&#65292;&#21363;&#20351;&#22122;&#22768;&#26159;&#37325;&#23614;&#30340;&#65292;&#32467;&#26524;&#35777;&#26126;&#20102;&#23545;&#22833;&#36133;&#27010;&#29575;&#30340;&#23545;&#25968;&#20381;&#36182;&#12290;&#36825;&#20123;&#32467;&#26524;&#36866;&#29992;&#20110;&#21098;&#20999;&#12289;&#24402;&#19968;&#21270;&#21644;&#37327;&#21270;&#31561;&#20219;&#20309;&#20855;&#26377;&#26377;&#30028;&#36755;&#20986;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20960;&#20010;&#30740;&#31350;&#24037;&#20316;&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#21450;&#20854;&#21098;&#20999;&#21464;&#20307;&#30340;&#39640;&#27010;&#29575;&#25910;&#25947;&#12290;&#19982;&#26222;&#36890;&#30340;SGD&#30456;&#27604;&#65292;&#21098;&#20999;SGD&#22312;&#23454;&#38469;&#20013;&#26356;&#21152;&#31283;&#23450;&#65292;&#24182;&#19988;&#22312;&#29702;&#35770;&#19978;&#26377;&#23545;&#25968;&#20381;&#36182;&#20110;&#22833;&#36133;&#27010;&#29575;&#30340;&#39069;&#22806;&#22909;&#22788;&#12290;&#28982;&#32780;&#65292;&#20854;&#20182;&#23454;&#38469;&#38750;&#32447;&#24615;SGD&#21464;&#20307;&#65288;&#22914;&#31526;&#21495;SGD&#12289;&#37327;&#21270;SGD&#21644;&#24402;&#19968;&#21270;SGD&#65289;&#30340;&#25910;&#25947;&#24615;&#29702;&#35299;&#35201;&#23569;&#24471;&#22810;&#65292;&#36825;&#20123;&#26041;&#27861;&#23454;&#29616;&#20102;&#25913;&#36827;&#30340;&#36890;&#20449;&#25928;&#29575;&#25110;&#21152;&#36895;&#25910;&#25947;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31867;&#24191;&#20041;&#38750;&#32447;&#24615;SGD&#26041;&#27861;&#30340;&#39640;&#27010;&#29575;&#25910;&#25947;&#36793;&#30028;&#12290;&#23545;&#20110;&#20855;&#26377;Lipschitz&#36830;&#32493;&#26799;&#24230;&#30340;&#24378;&#20984;&#25439;&#22833;&#20989;&#25968;&#65292;&#21363;&#20351;&#22122;&#22768;&#26159;&#37325;&#23614;&#30340;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#22833;&#36133;&#27010;&#29575;&#30340;&#23545;&#25968;&#20381;&#36182;&#12290;&#19982;&#21098;&#20999;SGD&#30340;&#32467;&#26524;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#26356;&#20026;&#19968;&#33324;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#26377;&#30028;&#36755;&#20986;&#30340;&#20219;&#20309;&#38750;&#32447;&#24615;&#20989;&#25968;&#65292;&#22914;&#21098;&#20999;&#12289;&#24402;&#19968;&#21270;&#21644;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several recent works have studied the convergence \textit{in high probability} of stochastic gradient descent (SGD) and its clipped variant. Compared to vanilla SGD, clipped SGD is practically more stable and has the additional theoretical benefit of logarithmic dependence on the failure probability. However, the convergence of other practical nonlinear variants of SGD, e.g., sign SGD, quantized SGD and normalized SGD, that achieve improved communication efficiency or accelerated convergence is much less understood. In this work, we study the convergence bounds \textit{in high probability} of a broad class of nonlinear SGD methods. For strongly convex loss functions with Lipschitz continuous gradients, we prove a logarithmic dependence on the failure probability, even when the noise is heavy-tailed. Strictly more general than the results for clipped SGD, our results hold for any nonlinearity with bounded (component-wise or joint) outputs, such as clipping, normalization, and quantizati
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38024;&#23545;AI&#20998;&#31867;&#22120;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#24230;&#37327;&#30340;&#23384;&#22312;&#24615;&#12289;&#21807;&#19968;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#65292;&#25552;&#20986;&#20102;&#21487;&#20197;&#39564;&#35777;&#30340;&#25968;&#23398;&#26465;&#20214;&#65292;&#24182;&#22312;&#21512;&#25104;&#22522;&#20934;&#27979;&#35797;&#21644;&#29983;&#29289;&#21307;&#23398;&#24212;&#29992;&#20013;&#36827;&#34892;&#20102;&#23454;&#38469;&#35745;&#31639;&#21644;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2310.14421</link><description>&lt;p&gt;
&#23545;AI&#20998;&#31867;&#22120;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#24230;&#37327;&#30340;&#23384;&#22312;&#24615;&#65292;&#21807;&#19968;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On existence, uniqueness and scalability of adversarial robustness measures for AI classifiers. (arXiv:2310.14421v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14421
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38024;&#23545;AI&#20998;&#31867;&#22120;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#24230;&#37327;&#30340;&#23384;&#22312;&#24615;&#12289;&#21807;&#19968;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#65292;&#25552;&#20986;&#20102;&#21487;&#20197;&#39564;&#35777;&#30340;&#25968;&#23398;&#26465;&#20214;&#65292;&#24182;&#22312;&#21512;&#25104;&#22522;&#20934;&#27979;&#35797;&#21644;&#29983;&#29289;&#21307;&#23398;&#24212;&#29992;&#20013;&#36827;&#34892;&#20102;&#23454;&#38469;&#35745;&#31639;&#21644;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#24182;&#35777;&#26126;&#20102;&#38024;&#23545;&#65288;&#23616;&#37096;&#65289;&#21807;&#19968;&#21487;&#36870;&#20998;&#31867;&#22120;&#12289;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65288;GLM&#65289;&#21644;&#29109;AI&#65288;EAI&#65289;&#20855;&#26377;&#26368;&#23567;&#23545;&#25239;&#36335;&#24452;&#65288;MAP&#65289;&#21644;&#26368;&#23567;&#23545;&#25239;&#36317;&#31163;&#65288;MAD&#65289;&#30340;&#23384;&#22312;&#24615;&#12289;&#21807;&#19968;&#24615;&#21644;&#26126;&#30830;&#30340;&#20998;&#26512;&#35745;&#31639;&#30340;&#31616;&#21333;&#21487;&#39564;&#35777;&#30340;&#25968;&#23398;&#26465;&#20214;&#12290;&#22312;&#24120;&#35265;&#30340;&#21512;&#25104;&#22522;&#20934;&#27979;&#35797;&#25968;&#25454;&#38598;&#19978;&#65292;&#38024;&#23545;&#31070;&#32463;&#32593;&#32476;&#12289;&#25552;&#21319;&#38543;&#26426;&#26862;&#26519;&#12289;GLM&#21644;EAI&#31561;&#21508;&#31867;AI&#24037;&#20855;&#36827;&#34892;MAP&#21644;MAD&#30340;&#23454;&#38469;&#35745;&#31639;&#12289;&#27604;&#36739;&#21644;&#35299;&#37322;&#65292;&#21253;&#25324;&#21452;&#21367;&#29366;&#34746;&#26059;&#32447;&#21450;&#20854;&#25193;&#23637;&#20197;&#21450;&#20004;&#20010;&#29983;&#29289;&#21307;&#23398;&#25968;&#25454;&#38382;&#39064;&#65288;&#29992;&#20110;&#20581;&#24247;&#20445;&#38505;&#29702;&#36180;&#39044;&#27979;&#21644;&#24515;&#33039;&#30149;&#21457;&#20316;&#33268;&#27515;&#29575;&#20998;&#31867;&#65289;&#12290;&#22312;&#29983;&#29289;&#21307;&#23398;&#24212;&#29992;&#20013;&#65292;&#23637;&#31034;&#20102;MAP&#22914;&#20309;&#22312;&#39044;&#23450;&#20041;&#30340;&#21487;&#35775;&#38382;&#25511;&#21046;&#21464;&#37327;&#23376;&#38598;&#20013;&#25552;&#20379;&#21807;&#19968;&#30340;&#26368;&#23567;&#24739;&#32773;&#29305;&#23450;&#39118;&#38505;&#32531;&#35299;&#24178;&#39044;&#25514;&#26045;&#12290;
&lt;/p&gt;
&lt;p&gt;
Simply-verifiable mathematical conditions for existence, uniqueness and explicit analytical computation of minimal adversarial paths (MAP) and minimal adversarial distances (MAD) for (locally) uniquely-invertible classifiers, for generalized linear models (GLM), and for entropic AI (EAI) are formulated and proven. Practical computation of MAP and MAD, their comparison and interpretations for various classes of AI tools (for neuronal networks, boosted random forests, GLM and EAI) are demonstrated on the common synthetic benchmarks: on a double Swiss roll spiral and its extensions, as well as on the two biomedical data problems (for the health insurance claim predictions, and for the heart attack lethality classification). On biomedical applications it is demonstrated how MAP provides unique minimal patient-specific risk-mitigating interventions in the predefined subsets of accessible control variables.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#39046;&#22495;&#20013;&#20174;&#25945;&#24072;&#21040;&#23398;&#29983;&#20998;&#31867;&#22120;&#36827;&#34892;&#30693;&#35782;&#20256;&#36882;&#30340;&#32479;&#35745;&#25928;&#29575;&#65292;&#21457;&#29616;&#29305;&#26435;&#20449;&#24687;&#20250;&#21152;&#36895;&#20256;&#36882;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#25439;&#22833;&#20989;&#25968;&#36798;&#21040;&#20102;&#30693;&#35782;&#20256;&#36882;&#30340;&#22522;&#26412;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2310.07838</link><description>&lt;p&gt;
&#25506;&#32034;&#26377;&#38480;&#39046;&#22495;&#30693;&#35782;&#20256;&#36882;&#30340;&#22522;&#26412;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
Towards the Fundamental Limits of Knowledge Transfer over Finite Domains. (arXiv:2310.07838v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07838
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#39046;&#22495;&#20013;&#20174;&#25945;&#24072;&#21040;&#23398;&#29983;&#20998;&#31867;&#22120;&#36827;&#34892;&#30693;&#35782;&#20256;&#36882;&#30340;&#32479;&#35745;&#25928;&#29575;&#65292;&#21457;&#29616;&#29305;&#26435;&#20449;&#24687;&#20250;&#21152;&#36895;&#20256;&#36882;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#25439;&#22833;&#20989;&#25968;&#36798;&#21040;&#20102;&#30693;&#35782;&#20256;&#36882;&#30340;&#22522;&#26412;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;&#36890;&#36807;&#20174;&#25945;&#24072;&#21040;&#27010;&#29575;&#21270;&#23398;&#29983;&#20998;&#31867;&#22120;&#30340;n&#20010;&#26679;&#26412;&#36827;&#34892;&#30693;&#35782;&#20256;&#36882;&#30340;&#32479;&#35745;&#25928;&#29575;&#36827;&#34892;&#20102;&#34920;&#24449;&#65292;&#20854;&#20013;&#36755;&#20837;&#31354;&#38388;S&#21644;&#26631;&#31614;A&#20026;&#26377;&#38480;&#22495;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#19977;&#20010;&#28176;&#36827;&#32423;&#21035;&#19978;&#30340;&#29305;&#26435;&#20449;&#24687;&#21487;&#20197;&#21152;&#24555;&#20256;&#36882;&#30340;&#36895;&#24230;&#12290;&#22312;&#31532;&#19968;&#32423;&#21035;&#19978;&#65292;&#21482;&#26377;&#20855;&#26377;&#22256;&#38590;&#26631;&#31614;&#30340;&#26679;&#26412;&#26159;&#24050;&#30693;&#30340;&#65292;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#33021;&#22815;&#36798;&#21040;&#26368;&#23567;&#21270;&#36895;&#29575;sqrt(|S||A|/n)&#12290;&#31532;&#20108;&#32423;&#21035;&#19978;&#65292;&#38500;&#20102;&#24050;&#30693;&#30340;&#22256;&#38590;&#26631;&#31614;&#26679;&#26412;&#22806;&#65292;&#36824;&#26377;&#37319;&#26679;&#26631;&#31614;&#30340;&#25945;&#24072;&#27010;&#29575;&#21487;&#29992;&#65292;&#36825;&#23558;&#25910;&#25947;&#36895;&#24230;&#30340;&#19979;&#30028;&#25552;&#39640;&#21040;|S||A|/n&#12290;&#28982;&#32780;&#65292;&#22312;&#31532;&#20108;&#20010;&#25968;&#25454;&#37319;&#38598;&#21327;&#35758;&#19979;&#65292;&#26368;&#23567;&#21270;&#20132;&#21449;&#29109;&#25439;&#22833;&#30340;&#26420;&#32032;&#36866;&#24212;&#20250;&#23548;&#33268;&#28176;&#36817;&#20559;&#24046;&#30340;&#23398;&#29983;&#12290;&#25105;&#20204;&#20811;&#26381;&#20102;&#36825;&#20010;&#38480;&#21046;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#32463;&#39564;&#21464;&#20307;&#30340;&#24179;&#26041;&#35823;&#24046;&#36923;&#36753;&#25439;&#22833;&#26469;&#23454;&#29616;&#20102;&#22522;&#26412;&#38480;&#21046;&#12290;&#31532;&#19977;&#32423;&#21035;&#36827;&#19968;&#27493;&#36171;&#20104;&#23398;&#29983;&#36719;&#26631;&#31614;&#12290;
&lt;/p&gt;
&lt;p&gt;
We characterize the statistical efficiency of knowledge transfer through $n$ samples from a teacher to a probabilistic student classifier with input space $\mathcal S$ over labels $\mathcal A$. We show that privileged information at three progressive levels accelerates the transfer. At the first level, only samples with hard labels are known, via which the maximum likelihood estimator attains the minimax rate $\sqrt{{|{\mathcal S}||{\mathcal A}|}/{n}}$. The second level has the teacher probabilities of sampled labels available in addition, which turns out to boost the convergence rate lower bound to ${{|{\mathcal S}||{\mathcal A}|}/{n}}$. However, under this second data acquisition protocol, minimizing a naive adaptation of the cross-entropy loss results in an asymptotically biased student. We overcome this limitation and achieve the fundamental limit by using a novel empirical variant of the squared error logit loss. The third level further equips the student with the soft labels (com
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20462;&#27491;&#30340;&#26399;&#26395;&#25913;&#21892;&#37319;&#38598;&#20989;&#25968;&#65292;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#35299;&#20915;&#20102;&#23545;&#20110;&#26377;&#22122;&#22768;&#35266;&#27979;&#30340;&#24773;&#20917;&#19979;&#24573;&#30053;&#20505;&#36873;&#35299;&#19981;&#30830;&#23450;&#24615;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.05166</link><description>&lt;p&gt;
&#19968;&#20010;&#22312;&#26377;&#22122;&#22768;&#35266;&#27979;&#19979;&#20462;&#27491;&#30340;&#26399;&#26395;&#25913;&#21892;&#37319;&#38598;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
A Corrected Expected Improvement Acquisition Function Under Noisy Observations. (arXiv:2310.05166v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05166
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20462;&#27491;&#30340;&#26399;&#26395;&#25913;&#21892;&#37319;&#38598;&#20989;&#25968;&#65292;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#35299;&#20915;&#20102;&#23545;&#20110;&#26377;&#22122;&#22768;&#35266;&#27979;&#30340;&#24773;&#20917;&#19979;&#24573;&#30053;&#20505;&#36873;&#35299;&#19981;&#30830;&#23450;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24207;&#21015;&#26368;&#22823;&#21270;&#26399;&#26395;&#25913;&#21892;(EI)&#26159;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#26368;&#24120;&#29992;&#30340;&#31574;&#30053;&#20043;&#19968;&#65292;&#22240;&#20854;&#31616;&#21333;&#24615;&#21644;&#22788;&#29702;&#22122;&#22768;&#35266;&#27979;&#30340;&#33021;&#21147;&#32780;&#24191;&#27867;&#24212;&#29992;&#12290;&#29305;&#21035;&#26159;&#65292;&#22312;&#22122;&#22768;&#29615;&#22659;&#20013;&#65292;&#25913;&#21892;&#20989;&#25968;&#36890;&#24120;&#20351;&#29992;&#26368;&#20339;&#21518;&#39564;&#22343;&#20540;&#20316;&#20026;&#26368;&#20339;&#20505;&#36873;&#35299;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#35299;&#26512;&#30340;EI&#31867;&#22411;&#26041;&#27861;&#20013;&#65292;&#24120;&#24120;&#24573;&#30053;&#19982;&#20505;&#36873;&#35299;&#30456;&#20851;&#30340;&#19981;&#30830;&#23450;&#24615;&#65306;&#22312;&#26080;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#23548;&#20986;&#20102;&#19968;&#20010;&#38381;&#21512;&#24418;&#24335;&#30340;&#37319;&#38598;&#20989;&#25968;&#65292;&#28982;&#21518;&#24212;&#29992;&#20110;&#26377;&#22122;&#22768;&#35266;&#27979;&#30340;&#24773;&#20917;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#27491;EI&#30340;&#26041;&#27861;&#65292;&#23558;&#39640;&#26031;&#36807;&#31243;(GP)&#27169;&#22411;&#25552;&#20379;&#30340;&#21327;&#26041;&#24046;&#20449;&#24687;&#32435;&#20837;&#20854;&#38381;&#21512;&#24418;&#24335;&#34920;&#36798;&#24335;&#20013;&#12290;&#36825;&#20010;&#37319;&#38598;&#20989;&#25968;&#19982;&#32463;&#20856;&#30340;&#26080;&#22122;&#22768;&#32467;&#26524;&#30456;&#21563;&#21512;&#65292;&#25105;&#20204;&#35748;&#20026;&#23427;&#24212;&#35813;&#21462;&#20195;&#36125;&#21494;&#26031;&#20248;&#21270;&#36719;&#20214;&#21253;&#12289;&#25945;&#31243;&#21644;&#25945;&#26448;&#20013;&#30340;&#37027;&#20010;&#20844;&#24335;&#12290;&#36825;&#20010;&#25913;&#36827;&#30340;&#37319;&#38598;&#20989;&#25968;&#20026;&#26377;&#22122;&#22768;&#21644;&#26080;&#22122;&#22768;&#30340;&#35299;&#25552;&#20379;&#20102;&#33391;&#22909;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential maximization of expected improvement (EI) is one of the most widely used policies in Bayesian optimization because of its simplicity and ability to handle noisy observations. In particular, the improvement function often uses the best posterior mean as the best incumbent in noisy settings. However, the uncertainty associated with the incumbent solution is often neglected in many analytic EI-type methods: a closed-form acquisition function is derived in the noise-free setting, but then applied to the setting with noisy observations. To address this limitation, we propose a modification of EI that corrects its closed-form expression by incorporating the covariance information provided by the Gaussian Process (GP) model. This acquisition function specializes to the classical noise-free result, and we argue should replace that formula in Bayesian optimization software packages, tutorials, and textbooks. This enhanced acquisition provides good generality for noisy and noiseless s
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#32467;&#26500;&#21270;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;&#22270;&#20687;&#27169;&#22411;&#30340;&#32467;&#26500;&#21644;&#21487;&#35299;&#37322;&#24615;&#20197;&#21450;&#28145;&#24230;&#23398;&#20064;&#30340;&#36866;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#30340;&#28789;&#27963;&#20284;&#28982;&#65292;&#32467;&#21512;&#20004;&#31181;&#26694;&#26550;&#30340;&#20248;&#21183;&#12290;&#21516;&#26102;&#65292;&#35813;&#35770;&#25991;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;SVAE&#30340;&#26032;&#31639;&#27861;&#65292;&#19982;&#27492;&#21516;&#26102;&#65292;&#25512;&#23548;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#33258;&#28982;&#26799;&#24230;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#20248;&#21270;&#21019;&#26032;&#20351;&#24471;SVAE&#39318;&#27425;&#33021;&#19982;&#26368;&#20808;&#36827;&#30340;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#36827;&#34892;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2306.08230</link><description>&lt;p&gt;
&#32467;&#26500;&#21270;&#31163;&#25955;&#34920;&#31034;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#26080;&#20559;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Unbiased Learning of Deep Generative Models with Structured Discrete Representations. (arXiv:2306.08230v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08230
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#32467;&#26500;&#21270;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;&#22270;&#20687;&#27169;&#22411;&#30340;&#32467;&#26500;&#21644;&#21487;&#35299;&#37322;&#24615;&#20197;&#21450;&#28145;&#24230;&#23398;&#20064;&#30340;&#36866;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#30340;&#28789;&#27963;&#20284;&#28982;&#65292;&#32467;&#21512;&#20004;&#31181;&#26694;&#26550;&#30340;&#20248;&#21183;&#12290;&#21516;&#26102;&#65292;&#35813;&#35770;&#25991;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;SVAE&#30340;&#26032;&#31639;&#27861;&#65292;&#19982;&#27492;&#21516;&#26102;&#65292;&#25512;&#23548;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#33258;&#28982;&#26799;&#24230;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#20248;&#21270;&#21019;&#26032;&#20351;&#24471;SVAE&#39318;&#27425;&#33021;&#19982;&#26368;&#20808;&#36827;&#30340;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23558;&#22270;&#24418;&#27169;&#22411;&#19982;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#32452;&#21512;&#65292;&#25105;&#20204;&#23398;&#20064;&#20855;&#26377;&#20004;&#31181;&#26694;&#26550;&#20248;&#21183;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290; &#32467;&#26500;&#21270;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;SVAE&#65289;&#20174;&#22270;&#24418;&#27169;&#22411;&#32487;&#25215;&#32467;&#26500;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#20174;&#28145;&#24230;&#23398;&#20064;&#20013;&#32487;&#25215;&#20102;&#36866;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#30340;&#28789;&#27963;&#20284;&#28982;&#65292;&#20294;&#26159;&#20250;&#24102;&#26469;&#30456;&#24403;&#22823;&#30340;&#20248;&#21270;&#25361;&#25112;&#12290; &#25105;&#20204;&#25552;&#20986;&#20102;&#23398;&#20064;SVAE&#30340;&#26032;&#31639;&#27861;&#65292;&#24182;&#19988;&#39318;&#27425;&#35777;&#26126;&#20102;SVAE&#22312;&#21547;&#26377;&#32570;&#22833;&#25968;&#25454;&#19988;&#21253;&#21547;&#31163;&#25955;&#28508;&#21464;&#37327;&#26102;&#22788;&#29702;&#22810;&#27169;&#24577;&#19981;&#30830;&#23450;&#24615;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#20869;&#23384;&#39640;&#25928;&#38544;&#24335;&#24494;&#20998;&#26041;&#26696;&#20351;&#24471;SVAE&#21487;&#20197;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#26469;&#23398;&#20064;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#40065;&#26834;&#24615;&#12290;&#20026;&#20102;&#26356;&#24555;&#22320;&#23398;&#20064;&#20934;&#30830;&#30340;&#22270;&#24418;&#27169;&#22411;&#21442;&#25968;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#31181;&#35745;&#31639;&#33258;&#28982;&#26799;&#24230;&#30340;&#26041;&#27861;&#65292;&#32780;&#19981;&#38656;&#35201;&#25163;&#21160;&#36827;&#34892;&#23548;&#20986;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#20808;&#21069;&#24037;&#20316;&#20013;&#21457;&#29616;&#30340;&#20559;&#24046;&#12290;&#36825;&#20123;&#20248;&#21270;&#21019;&#26032;&#20351;&#24471;&#39318;&#27425;&#33021;&#22815;&#23558;SVAE&#19982;&#26368;&#20808;&#36827;&#30340;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
By composing graphical models with deep learning architectures, we learn generative models with the strengths of both frameworks. The structured variational autoencoder (SVAE) inherits structure and interpretability from graphical models, and flexible likelihoods for high-dimensional data from deep learning, but poses substantial optimization challenges. We propose novel algorithms for learning SVAEs, and are the first to demonstrate the SVAE's ability to handle multimodal uncertainty when data is missing by incorporating discrete latent variables. Our memory-efficient implicit differentiation scheme makes the SVAE tractable to learn via gradient descent, while demonstrating robustness to incomplete optimization. To more rapidly learn accurate graphical model parameters, we derive a method for computing natural gradients without manual derivations, which avoids biases found in prior work. These optimization innovations enable the first comparisons of the SVAE to state-of-the-art time s
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#31616;&#21333;&#21644;&#28165;&#26224;&#30340;&#22240;&#26524;&#29702;&#35770;&#65292;&#23427;&#19981;&#38656;&#35201;&#20351;&#29992;&#20219;&#20309;&#24314;&#27169;&#20551;&#35774;&#65292;&#21253;&#25324;&#22823;&#22810;&#25968;&#20855;&#26377;&#28508;&#22312;&#21464;&#37327;&#21644;&#22240;&#26524;&#24490;&#29615;&#30340;&#24773;&#20917;&#65292;&#24182;&#19988;&#19981;&#20551;&#23450;&#23384;&#22312;&#24213;&#23618;&#30495;&#27491;&#30340;&#22240;&#26524;&#22270;-&#20107;&#23454;&#19978;&#65292;&#23427;&#26159;&#22240;&#26524;&#22270;&#30340;&#21103;&#20135;&#21697;&#12290;</title><link>http://arxiv.org/abs/2305.04479</link><description>&lt;p&gt;
&#24178;&#39044;&#27010;&#29575;&#20998;&#24067;&#30340;&#20844;&#29702;&#21270;
&lt;/p&gt;
&lt;p&gt;
Axiomatization of Interventional Probability Distributions. (arXiv:2305.04479v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04479
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#31616;&#21333;&#21644;&#28165;&#26224;&#30340;&#22240;&#26524;&#29702;&#35770;&#65292;&#23427;&#19981;&#38656;&#35201;&#20351;&#29992;&#20219;&#20309;&#24314;&#27169;&#20551;&#35774;&#65292;&#21253;&#25324;&#22823;&#22810;&#25968;&#20855;&#26377;&#28508;&#22312;&#21464;&#37327;&#21644;&#22240;&#26524;&#24490;&#29615;&#30340;&#24773;&#20917;&#65292;&#24182;&#19988;&#19981;&#20551;&#23450;&#23384;&#22312;&#24213;&#23618;&#30495;&#27491;&#30340;&#22240;&#26524;&#22270;-&#20107;&#23454;&#19978;&#65292;&#23427;&#26159;&#22240;&#26524;&#22270;&#30340;&#21103;&#20135;&#21697;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#24178;&#39044;&#26159;&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#22522;&#26412;&#24037;&#20855;&#12290;&#22312;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#23427;&#34987;&#20844;&#29702;&#21270;&#20026;do-&#28436;&#31639;&#35268;&#21017;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#20844;&#29702;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#21306;&#20998;&#19981;&#21516;&#31867;&#22411;&#30340;&#24178;&#39044;&#20998;&#24067;&#30340;&#27010;&#29575;&#20998;&#24067;&#26063;&#12290;&#25105;&#20204;&#30340;&#20844;&#29702;&#21270;&#26041;&#27861;&#25972;&#27905;&#22320;&#23548;&#33268;&#20102;&#19968;&#31181;&#31616;&#21333;&#21644;&#28165;&#26224;&#30340;&#22240;&#26524;&#29702;&#35770;&#65292;&#20855;&#26377;&#20960;&#20010;&#20248;&#28857;&#65306;&#23427;&#19981;&#38656;&#35201;&#20351;&#29992;&#20219;&#20309;&#24314;&#27169;&#20551;&#35774;&#65292;&#20363;&#22914;&#32467;&#26500;&#24615;&#22240;&#26524;&#27169;&#22411;&#25152;&#24378;&#21152;&#30340;&#20551;&#35774;&#65307;&#23427;&#21482;&#20381;&#36182;&#20110;&#21333;&#20010;&#21464;&#37327;&#30340;&#24178;&#39044;&#65307;&#23427;&#21253;&#25324;&#22823;&#22810;&#25968;&#20855;&#26377;&#28508;&#22312;&#21464;&#37327;&#21644;&#22240;&#26524;&#24490;&#29615;&#30340;&#24773;&#20917;&#65307;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#23427;&#19981;&#20551;&#23450;&#23384;&#22312;&#24213;&#23618;&#30495;&#27491;&#30340;&#22240;&#26524;&#22270;--&#20107;&#23454;&#19978;&#65292;&#22240;&#26524;&#22270;&#26159;&#25105;&#20204;&#29702;&#35770;&#30340;&#21103;&#20135;&#21697;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#65292;&#22312;&#25105;&#20204;&#30340;&#20844;&#29702;&#21270;&#26041;&#27861;&#19979;&#65292;&#24178;&#39044;&#20998;&#24067;&#23545;&#20110;&#23450;&#20041;&#30340;&#24178;&#39044;&#22240;&#26524;&#22270;&#26159;&#39532;&#23572;&#21487;&#22827;&#30340;&#65292;&#24182;&#19988;&#35266;&#23519;&#21040;&#30340;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#23545;&#20110;&#33719;&#24471;&#30340;&#22240;&#26524;&#22270;&#26159;&#39532;&#23572;&#21487;&#22827;&#30340;&#65307;&#36825;&#20123;&#32467;&#26524;&#26159;&#19968;&#33268;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal intervention is an essential tool in causal inference. It is axiomatized under the rules of do-calculus in the case of structure causal models. We provide simple axiomatizations for families of probability distributions to be different types of interventional distributions. Our axiomatizations neatly lead to a simple and clear theory of causality that has several advantages: it does not need to make use of any modeling assumptions such as those imposed by structural causal models; it only relies on interventions on single variables; it includes most cases with latent variables and causal cycles; and more importantly, it does not assume the existence of an underlying true causal graph--in fact, a causal graph is a by-product of our theory. We show that, under our axiomatizations, the intervened distributions are Markovian to the defined intervened causal graphs, and an observed joint probability distribution is Markovian to the obtained causal graph; these results are consistent 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#24191;&#20041;&#30340;&#20957;&#32858;&#27010;&#24565;&#65292;&#26500;&#24314;&#22312;&#20998;&#21306;&#23616;&#37096;&#28145;&#24230;&#30340;&#25216;&#26415;&#22522;&#30784;&#19978;&#65292;&#25193;&#23637;&#20102;&#26089;&#26399;&#32467;&#26524;&#24182;&#24212;&#29992;&#20110;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#25968;&#25454;&#30340;&#31038;&#21306;&#21457;&#29616;&#20013;&#12290;</title><link>http://arxiv.org/abs/2303.10167</link><description>&lt;p&gt;
&#24191;&#20041;&#21010;&#20998;&#23616;&#37096;&#28145;&#24230;
&lt;/p&gt;
&lt;p&gt;
Generalized partitioned local depth. (arXiv:2303.10167v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10167
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#24191;&#20041;&#30340;&#20957;&#32858;&#27010;&#24565;&#65292;&#26500;&#24314;&#22312;&#20998;&#21306;&#23616;&#37096;&#28145;&#24230;&#30340;&#25216;&#26415;&#22522;&#30784;&#19978;&#65292;&#25193;&#23637;&#20102;&#26089;&#26399;&#32467;&#26524;&#24182;&#24212;&#29992;&#20110;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#25968;&#25454;&#30340;&#31038;&#21306;&#21457;&#29616;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#26368;&#36817;&#30001;Berenhaut&#12289;Moore&#21644;Melvin [Proccedings of the National Academy of Sciences, 119 (4) (2022)]&#25552;&#20986;&#30340;&#20957;&#32858;&#27010;&#24565;&#30340;&#27010;&#25324;&#12290;&#25152;&#25552;&#20986;&#30340;&#34920;&#36848;&#22522;&#20110;&#20998;&#21306;&#23616;&#37096;&#28145;&#24230;&#30340;&#25216;&#26415;&#24182;&#25552;&#28860;&#20102;&#20004;&#20010;&#20851;&#38190;&#27010;&#29575;&#27010;&#24565;&#65306;&#23616;&#37096;&#30456;&#20851;&#24615;&#21644;&#25903;&#25345;&#20998;&#21106;&#12290;&#26089;&#26399;&#32467;&#26524;&#22312;&#26032;&#30340;&#32972;&#26223;&#19979;&#24471;&#21040;&#25193;&#23637;&#65292;&#24182;&#21253;&#25324;&#22312;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#25968;&#25454;&#20013;&#25581;&#31034;&#31038;&#21306;&#30340;&#24212;&#29992;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we provide a generalization of the concept of cohesion as introduced recently by Berenhaut, Moore and Melvin [Proceedings of the National Academy of Sciences, 119 (4) (2022)]. The formulation presented builds on the technique of partitioned local depth by distilling two key probabilistic concepts: local relevance and support division. Earlier results are extended within the new context, and examples of applications to revealing communities in data with uncertainty are included.
&lt;/p&gt;</description></item><item><title>&#23558;PAC-Bayesian&#29702;&#35770;&#25193;&#23637;&#21040;&#29983;&#25104;&#27169;&#22411;&#65292;&#20026;&#22522;&#20110;Wasserstein&#36317;&#31163;&#21644;&#24635;&#21464;&#24046;&#36317;&#31163;&#30340;&#27169;&#22411;&#25552;&#20379;&#20102;&#27867;&#21270;&#30028;&#65292;&#20026;Wasserstein GAN&#21644;Energy-Based GAN&#25552;&#20379;&#20102;&#26032;&#30340;&#35757;&#32451;&#30446;&#26631;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20986;&#38750;&#34394;&#31354;&#27867;&#21270;&#30028;&#12290;</title><link>http://arxiv.org/abs/2302.08942</link><description>&lt;p&gt;
&#38754;&#21521;&#23545;&#25239;&#29983;&#25104;&#27169;&#22411;&#30340;PAC-Bayesian&#27867;&#21270;&#30028;
&lt;/p&gt;
&lt;p&gt;
PAC-Bayesian Generalization Bounds for Adversarial Generative Models. (arXiv:2302.08942v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08942
&lt;/p&gt;
&lt;p&gt;
&#23558;PAC-Bayesian&#29702;&#35770;&#25193;&#23637;&#21040;&#29983;&#25104;&#27169;&#22411;&#65292;&#20026;&#22522;&#20110;Wasserstein&#36317;&#31163;&#21644;&#24635;&#21464;&#24046;&#36317;&#31163;&#30340;&#27169;&#22411;&#25552;&#20379;&#20102;&#27867;&#21270;&#30028;&#65292;&#20026;Wasserstein GAN&#21644;Energy-Based GAN&#25552;&#20379;&#20102;&#26032;&#30340;&#35757;&#32451;&#30446;&#26631;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20986;&#38750;&#34394;&#31354;&#27867;&#21270;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;PAC-Bayesian&#29702;&#35770;&#25193;&#23637;&#21040;&#29983;&#25104;&#27169;&#22411;&#65292;&#24182;&#20026;&#22522;&#20110;Wasserstein&#36317;&#31163;&#21644;&#24635;&#21464;&#24046;&#36317;&#31163;&#30340;&#27169;&#22411;&#24320;&#21457;&#20102;&#27867;&#21270;&#30028;&#12290;&#25105;&#20204;&#31532;&#19968;&#20010;&#20851;&#20110;Wasserstein&#36317;&#31163;&#30340;&#32467;&#26524;&#20551;&#35774;&#23454;&#20363;&#31354;&#38388;&#26159;&#26377;&#30028;&#30340;&#65292;&#32780;&#25105;&#20204;&#30340;&#31532;&#20108;&#20010;&#32467;&#26524;&#21033;&#29992;&#20102;&#38477;&#32500;&#30340;&#20248;&#21183;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#33258;&#28982;&#36866;&#29992;&#20110;Wasserstein GAN&#21644;Energy-Based GAN&#65292;&#32780;&#25105;&#20204;&#30340;&#30028;&#38480;&#20026;&#36825;&#20004;&#31181;GAN&#25552;&#20379;&#20102;&#26032;&#30340;&#35757;&#32451;&#30446;&#26631;&#12290;&#23613;&#31649;&#25105;&#20204;&#30340;&#24037;&#20316;&#20027;&#35201;&#26159;&#29702;&#35770;&#24615;&#30340;&#65292;&#20294;&#25105;&#20204;&#36827;&#34892;&#20102;&#25968;&#20540;&#23454;&#39564;&#65292;&#23637;&#31034;&#20102;Wasserstein GAN&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#30340;&#38750;&#34394;&#31354;&#27867;&#21270;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We extend PAC-Bayesian theory to generative models and develop generalization bounds for models based on the Wasserstein distance and the total variation distance. Our first result on the Wasserstein distance assumes the instance space is bounded, while our second result takes advantage of dimensionality reduction. Our results naturally apply to Wasserstein GANs and Energy-Based GANs, and our bounds provide new training objectives for these two. Although our work is mainly theoretical, we perform numerical experiments showing non-vacuous generalization bounds for Wasserstein GANs on synthetic datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#31532;&#19968;&#20221;&#23545;&#20110;&#27973;&#23618;ViT&#36827;&#34892;&#35757;&#32451;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#20351;&#29992;SGD&#35757;&#32451;&#20250;&#20135;&#29983;&#31232;&#30095;&#30340;&#27880;&#24847;&#21147;&#22270;&#65292;&#30446;&#21069;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#19982;&#26631;&#35760;&#30456;&#20851;&#20196;&#29260;&#30340;&#20998;&#25968;&#20498;&#25968;&#12289;&#26631;&#35760;&#32423;&#21035;&#30340;&#20196;&#29260;&#22122;&#22768;&#27700;&#24179;&#21644;&#21021;&#22987;&#27169;&#22411;&#38169;&#35823;&#21576;&#27491;&#30456;&#20851;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2302.06015</link><description>&lt;p&gt;
&#27973;&#23618;&#35270;&#35273;Transformer&#30340;&#29702;&#35770;&#29702;&#35299;&#65306;&#23398;&#20064;&#12289;&#27867;&#21270;&#21644;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A Theoretical Understanding of Shallow Vision Transformers: Learning, Generalization, and Sample Complexity. (arXiv:2302.06015v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06015
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#31532;&#19968;&#20221;&#23545;&#20110;&#27973;&#23618;ViT&#36827;&#34892;&#35757;&#32451;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#20351;&#29992;SGD&#35757;&#32451;&#20250;&#20135;&#29983;&#31232;&#30095;&#30340;&#27880;&#24847;&#21147;&#22270;&#65292;&#30446;&#21069;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#19982;&#26631;&#35760;&#30456;&#20851;&#20196;&#29260;&#30340;&#20998;&#25968;&#20498;&#25968;&#12289;&#26631;&#35760;&#32423;&#21035;&#30340;&#20196;&#29260;&#22122;&#22768;&#27700;&#24179;&#21644;&#21021;&#22987;&#27169;&#22411;&#38169;&#35823;&#21576;&#27491;&#30456;&#20851;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#20855;&#26377;&#33258;&#25105;&#27880;&#24847;&#26426;&#21046;&#30340;&#35270;&#35273;Transformer&#65288;ViTs&#65289;&#22312;&#35768;&#22810;&#35270;&#35273;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#23454;&#35777;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23618;&#38388;&#30340;&#38750;&#20984;&#20132;&#20114;&#65292;&#29702;&#35770;&#19978;&#30340;&#23398;&#20064;&#21644;&#27867;&#21270;&#20998;&#26512;&#22823;&#22810;&#26159;&#38590;&#20197;&#29702;&#35299;&#30340;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#20110;&#19968;&#39033;&#20998;&#31867;&#20219;&#21153;&#65292;&#20351;&#29992;&#19968;&#20010;&#33258;&#25105;&#27880;&#24847;&#23618;&#21644;&#20004;&#23618;&#24863;&#30693;&#26426;&#30340;&#27973;&#23618;ViT&#36827;&#34892;&#35757;&#32451;&#30340;&#31532;&#19968;&#31687;&#29702;&#35770;&#20998;&#26512;&#65292;&#24314;&#31435;&#20102;&#23545;&#20110;&#25968;&#25454;&#27169;&#22411;&#30340;&#25551;&#36848;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#21516;&#26102;&#34920;&#24449;&#26631;&#35760;&#30456;&#20851;&#21644;&#26631;&#35760;&#19981;&#30456;&#20851;&#30340;&#20196;&#29260;&#12290;&#25105;&#20204;&#30028;&#23450;&#20102;&#36798;&#21040;&#38646;&#27867;&#21270;&#35823;&#24046;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#38480;&#21046;&#19982;&#26631;&#35760;&#30456;&#20851;&#20196;&#29260;&#30340;&#37096;&#20998;&#20498;&#25968;&#12289;&#26631;&#35760;&#32423;&#21035;&#30340;&#20196;&#29260;&#22122;&#22768;&#27700;&#24179;&#21644;&#21021;&#22987;&#27169;&#22411;&#35823;&#24046;&#21576;&#27491;&#30456;&#20851;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;SGD&#65288;stochastic gradient descent&#65289;&#36827;&#34892;&#35757;&#32451;&#36807;&#31243;&#20250;&#23548;&#33268;&#31232;&#30095;&#30340;&#27880;&#24847;&#21147;&#22270;&#65292;&#36825;&#26159;&#23545;&#20110;&#27880;&#24847;&#21147;&#25104;&#21151;&#30340;&#19968;&#31181;&#24418;&#24335;&#35777;&#26126;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#25351;&#20986;&#65292;&#36866;&#24403;&#30340;&#20196;&#29260;&#30830;&#23450;&#26159;&#30830;&#20445;&#23454;&#29616;&#26368;&#20248;&#24615;&#33021;&#30340;&#20851;&#38190;&#12290;
&lt;/p&gt;
&lt;p&gt;
Vision Transformers (ViTs) with self-attention modules have recently achieved great empirical success in many vision tasks. Due to non-convex interactions across layers, however, theoretical learning and generalization analysis is mostly elusive. Based on a data model characterizing both label-relevant and label-irrelevant tokens, this paper provides the first theoretical analysis of training a shallow ViT, i.e., one self-attention layer followed by a two-layer perceptron, for a classification task. We characterize the sample complexity to achieve a zero generalization error. Our sample complexity bound is positively correlated with the inverse of the fraction of label-relevant tokens, the token noise level, and the initial model error. We also prove that a training process using stochastic gradient descent (SGD) leads to a sparse attention map, which is a formal verification of the general intuition about the success of attention. Moreover, this paper indicates that a proper token spa
&lt;/p&gt;</description></item></channel></rss>