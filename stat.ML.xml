<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#26377;&#25928;&#22320;&#20272;&#35745;&#22788;&#29702;&#25928;&#24212;&#30340;&#27963;&#36291;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#21327;&#21464;&#37327;&#23494;&#24230;&#21644;&#20542;&#21521;&#24471;&#20998;&#26469;&#38477;&#20302;&#28176;&#36817;&#26041;&#24046;&#12290;</title><link>https://arxiv.org/abs/2403.03589</link><description>&lt;p&gt;
&#29992;&#20110;&#22788;&#29702;&#22240;&#21464;&#37327;&#36873;&#25321;&#30340;&#27963;&#36291;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;&#30340;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Active Adaptive Experimental Design for Treatment Effect Estimation with Covariate Choices
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03589
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#26377;&#25928;&#22320;&#20272;&#35745;&#22788;&#29702;&#25928;&#24212;&#30340;&#27963;&#36291;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#21327;&#21464;&#37327;&#23494;&#24230;&#21644;&#20542;&#21521;&#24471;&#20998;&#26469;&#38477;&#20302;&#28176;&#36817;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#35774;&#35745;&#20102;&#19968;&#20010;&#33258;&#36866;&#24212;&#23454;&#39564;&#65292;&#29992;&#20110;&#39640;&#25928;&#22320;&#20272;&#35745;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATEs&#65289;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#33258;&#36866;&#24212;&#23454;&#39564;&#65292;&#20854;&#20013;&#23454;&#39564;&#32773;&#25353;&#39034;&#24207;&#20174;&#30001;&#23454;&#39564;&#32773;&#20915;&#23450;&#30340;&#21327;&#21464;&#37327;&#23494;&#24230;&#20013;&#25277;&#26679;&#19968;&#20010;&#23454;&#39564;&#21333;&#20803;&#65292;&#24182;&#20998;&#37197;&#19968;&#31181;&#22788;&#29702;&#12290;&#22312;&#20998;&#37197;&#22788;&#29702;&#21518;&#65292;&#23454;&#39564;&#32773;&#31435;&#21363;&#35266;&#23519;&#30456;&#24212;&#30340;&#32467;&#26524;&#12290;&#22312;&#23454;&#39564;&#32467;&#26463;&#26102;&#65292;&#23454;&#39564;&#32773;&#21033;&#29992;&#25910;&#38598;&#30340;&#26679;&#26412;&#20272;&#31639;&#20986;&#19968;&#20010;ATE&#12290;&#23454;&#39564;&#32773;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#36739;&#23567;&#30340;&#28176;&#36817;&#26041;&#24046;&#20272;&#35745;ATE&#12290;&#29616;&#26377;&#30740;&#31350;&#24050;&#32463;&#35774;&#35745;&#20102;&#19968;&#20123;&#33021;&#22815;&#33258;&#36866;&#24212;&#20248;&#21270;&#20542;&#21521;&#24471;&#20998;&#65288;&#22788;&#29702;&#20998;&#37197;&#27010;&#29575;&#65289;&#30340;&#23454;&#39564;&#12290;&#20316;&#20026;&#36825;&#31181;&#26041;&#27861;&#30340;&#19968;&#20010;&#27010;&#25324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#19979;&#23454;&#39564;&#32773;&#20248;&#21270;&#21327;&#21464;&#37327;&#23494;&#24230;&#20197;&#21450;&#20542;&#21521;&#24471;&#20998;&#65292;&#24182;&#21457;&#29616;&#20248;&#21270;&#21327;&#21464;&#37327;&#23494;&#24230;&#21644;&#20542;&#21521;&#24471;&#20998;&#27604;&#20165;&#20248;&#21270;&#20542;&#21521;&#24471;&#20998;&#21487;&#20197;&#20943;&#23569;&#28176;&#36817;&#26041;&#24046;&#26356;&#22810;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03589v1 Announce Type: cross  Abstract: This study designs an adaptive experiment for efficiently estimating average treatment effect (ATEs). We consider an adaptive experiment where an experimenter sequentially samples an experimental unit from a covariate density decided by the experimenter and assigns a treatment. After assigning a treatment, the experimenter observes the corresponding outcome immediately. At the end of the experiment, the experimenter estimates an ATE using gathered samples. The objective of the experimenter is to estimate the ATE with a smaller asymptotic variance. Existing studies have designed experiments that adaptively optimize the propensity score (treatment-assignment probability). As a generalization of such an approach, we propose a framework under which an experimenter optimizes the covariate density, as well as the propensity score, and find that optimizing both covariate density and propensity score reduces the asymptotic variance more than o
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;NAS&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#19968;&#20010;&#25628;&#32034;&#36816;&#34892;&#20013;&#32534;&#30721;&#29992;&#25143;&#23545;&#24615;&#33021;&#21644;&#30828;&#20214;&#25351;&#26631;&#20043;&#38388;&#30340;&#26435;&#34913;&#20559;&#22909;&#65292;&#29983;&#25104;&#31934;&#24515;&#36873;&#25321;&#30340;&#22810;&#35774;&#22791;&#26550;&#26500;&#12290;</title><link>https://arxiv.org/abs/2402.18213</link><description>&lt;p&gt;
&#22810;&#30446;&#26631;&#21487;&#24494;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
Multi-objective Differentiable Neural Architecture Search
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18213
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;NAS&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#19968;&#20010;&#25628;&#32034;&#36816;&#34892;&#20013;&#32534;&#30721;&#29992;&#25143;&#23545;&#24615;&#33021;&#21644;&#30828;&#20214;&#25351;&#26631;&#20043;&#38388;&#30340;&#26435;&#34913;&#20559;&#22909;&#65292;&#29983;&#25104;&#31934;&#24515;&#36873;&#25321;&#30340;&#22810;&#35774;&#22791;&#26550;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#30446;&#26631;&#20248;&#21270;&#65288;MOO&#65289;&#20013;&#30340;Pareto&#21069;&#27839;&#36718;&#24275;&#21078;&#26512;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#23588;&#20854;&#26159;&#22312;&#20687;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#36825;&#26679;&#30340;&#26114;&#36149;&#30446;&#26631;&#20013;&#12290; &#30456;&#23545;&#20110;&#20256;&#32479;&#30340;NAS&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;NAS&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#19968;&#20010;&#25628;&#32034;&#36816;&#34892;&#20013;&#32534;&#30721;&#29992;&#25143;&#23545;&#24615;&#33021;&#21644;&#30828;&#20214;&#25351;&#26631;&#20043;&#38388;&#30340;&#26435;&#34913;&#20559;&#22909;&#65292;&#24182;&#29983;&#25104;&#31934;&#24515;&#36873;&#25321;&#30340;&#22810;&#35774;&#22791;&#26550;&#26500;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#36229;&#32593;&#32476;&#21442;&#25968;&#21270;&#36328;&#22810;&#20010;&#35774;&#22791;&#21644;&#22810;&#20010;&#30446;&#26631;&#30340;&#32852;&#21512;&#26550;&#26500;&#20998;&#24067;&#65292;&#36229;&#32593;&#32476;&#21487;&#20197;&#26681;&#25454;&#30828;&#20214;&#29305;&#24449;&#21644;&#20559;&#22909;&#21521;&#37327;&#36827;&#34892;&#26465;&#20214;&#21270;&#65292;&#23454;&#29616;&#38646;&#27425;&#25628;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18213v1 Announce Type: new  Abstract: Pareto front profiling in multi-objective optimization (MOO), i.e. finding a diverse set of Pareto optimal solutions, is challenging, especially with expensive objectives like neural network training. Typically, in MOO neural architecture search (NAS), we aim to balance performance and hardware metrics across devices. Prior NAS approaches simplify this task by incorporating hardware constraints into the objective function, but profiling the Pareto front necessitates a search for each constraint. In this work, we propose a novel NAS algorithm that encodes user preferences for the trade-off between performance and hardware metrics, and yields representative and diverse architectures across multiple devices in just one search run. To this end, we parameterize the joint architectural distribution across devices and multiple objectives via a hypernetwork that can be conditioned on hardware features and preference vectors, enabling zero-shot t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#21644;&#25506;&#35752;&#20102;&#38236;&#20687;&#24433;&#21709;&#20551;&#35774;&#65292;&#31361;&#20986;&#20102;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#20043;&#38388;&#24433;&#21709;&#30340;&#30456;&#20114;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#23427;&#25351;&#20986;&#65292;&#35780;&#20272;&#35757;&#32451;&#25968;&#25454;&#23545;&#27979;&#35797;&#39044;&#27979;&#30340;&#24433;&#21709;&#21487;&#20197;&#37325;&#26032;&#34920;&#36848;&#20026;&#19968;&#20010;&#31561;&#25928;&#20294;&#30456;&#21453;&#30340;&#38382;&#39064;&#65306;&#35780;&#20272;&#22914;&#26524;&#27169;&#22411;&#22312;&#29305;&#23450;&#30340;&#27979;&#35797;&#26679;&#26412;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#23545;&#35757;&#32451;&#26679;&#26412;&#30340;&#39044;&#27979;&#23558;&#22914;&#20309;&#25913;&#21464;&#12290;&#36890;&#36807;&#23454;&#35777;&#21644;&#29702;&#35770;&#39564;&#35777;&#65292;&#25105;&#20204;&#28436;&#31034;&#20102;&#36825;&#19968;&#20551;&#35774;&#30340;&#27491;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.08922</link><description>&lt;p&gt;
&#38236;&#20687;&#24433;&#21709;&#20551;&#35774;&#65306;&#36890;&#36807;&#21033;&#29992;&#21069;&#21521;&#20256;&#36882;&#23454;&#29616;&#39640;&#25928;&#30340;&#25968;&#25454;&#24433;&#21709;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
The Mirrored Influence Hypothesis: Efficient Data Influence Estimation by Harnessing Forward Passes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08922
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#21644;&#25506;&#35752;&#20102;&#38236;&#20687;&#24433;&#21709;&#20551;&#35774;&#65292;&#31361;&#20986;&#20102;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#20043;&#38388;&#24433;&#21709;&#30340;&#30456;&#20114;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#23427;&#25351;&#20986;&#65292;&#35780;&#20272;&#35757;&#32451;&#25968;&#25454;&#23545;&#27979;&#35797;&#39044;&#27979;&#30340;&#24433;&#21709;&#21487;&#20197;&#37325;&#26032;&#34920;&#36848;&#20026;&#19968;&#20010;&#31561;&#25928;&#20294;&#30456;&#21453;&#30340;&#38382;&#39064;&#65306;&#35780;&#20272;&#22914;&#26524;&#27169;&#22411;&#22312;&#29305;&#23450;&#30340;&#27979;&#35797;&#26679;&#26412;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#23545;&#35757;&#32451;&#26679;&#26412;&#30340;&#39044;&#27979;&#23558;&#22914;&#20309;&#25913;&#21464;&#12290;&#36890;&#36807;&#23454;&#35777;&#21644;&#29702;&#35770;&#39564;&#35777;&#65292;&#25105;&#20204;&#28436;&#31034;&#20102;&#36825;&#19968;&#20551;&#35774;&#30340;&#27491;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#40657;&#30418;&#27169;&#22411;&#24050;&#32463;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#21464;&#24471;&#26080;&#22788;&#19981;&#22312;&#12290;&#20102;&#35299;&#20010;&#21035;&#35757;&#32451;&#25968;&#25454;&#28304;&#23545;&#36825;&#20123;&#27169;&#22411;&#25152;&#20570;&#39044;&#27979;&#30340;&#24433;&#21709;&#23545;&#20110;&#25913;&#21892;&#20854;&#21487;&#20449;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#24403;&#21069;&#30340;&#24433;&#21709;&#35780;&#20272;&#25216;&#26415;&#28041;&#21450;&#35745;&#31639;&#27599;&#20010;&#35757;&#32451;&#28857;&#30340;&#26799;&#24230;&#25110;&#22312;&#19981;&#21516;&#23376;&#38598;&#19978;&#37325;&#22797;&#35757;&#32451;&#12290;&#24403;&#25193;&#23637;&#21040;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#26102;&#65292;&#36825;&#20123;&#26041;&#27861;&#38754;&#20020;&#26126;&#26174;&#30340;&#35745;&#31639;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08922v1 Announce Type: new Abstract: Large-scale black-box models have become ubiquitous across numerous applications. Understanding the influence of individual training data sources on predictions made by these models is crucial for improving their trustworthiness. Current influence estimation techniques involve computing gradients for every training point or repeated training on different subsets. These approaches face obvious computational challenges when scaled up to large datasets and models.   In this paper, we introduce and explore the Mirrored Influence Hypothesis, highlighting a reciprocal nature of influence between training and test data. Specifically, it suggests that evaluating the influence of training data on test predictions can be reformulated as an equivalent, yet inverse problem: assessing how the predictions for training samples would be altered if the model were trained on specific test samples. Through both empirical and theoretical validations, we demo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#20855;&#26377;&#21333;&#35843;&#23545;&#25163;&#30340;Top-K&#25490;&#21517;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;(MLE)&#65292;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#26041;&#38754;&#25509;&#36817;&#26368;&#20248;&#12290;&#31639;&#27861;&#21019;&#26032;&#21253;&#25324;&#20102;&#23545;&#21152;&#26435;MLE&#30340;&#31934;&#30830;&#19988;&#32039;&#23494;&#30340;$\ell_\infty$&#35823;&#24046;&#20998;&#26512;&#65292;&#24182;&#19982;&#21152;&#26435;&#27604;&#36739;&#22270;&#30340;&#35889;&#29305;&#24615;&#30456;&#20851;&#32852;&#12290;</title><link>https://arxiv.org/abs/2402.07445</link><description>&lt;p&gt;
&#20855;&#26377;&#21333;&#35843;&#23545;&#25163;&#30340;Top-K&#25490;&#21517;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Top-$K$ ranking with a monotone adversary
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07445
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#20855;&#26377;&#21333;&#35843;&#23545;&#25163;&#30340;Top-K&#25490;&#21517;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;(MLE)&#65292;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#26041;&#38754;&#25509;&#36817;&#26368;&#20248;&#12290;&#31639;&#27861;&#21019;&#26032;&#21253;&#25324;&#20102;&#23545;&#21152;&#26435;MLE&#30340;&#31934;&#30830;&#19988;&#32039;&#23494;&#30340;$\ell_\infty$&#35823;&#24046;&#20998;&#26512;&#65292;&#24182;&#19982;&#21152;&#26435;&#27604;&#36739;&#22270;&#30340;&#35889;&#29305;&#24615;&#30456;&#20851;&#32852;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#20855;&#26377;&#21333;&#35843;&#23545;&#25163;&#30340;Top-K&#25490;&#21517;&#38382;&#39064;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#27604;&#36739;&#22270;&#34987;&#38543;&#26426;&#29983;&#25104;&#19988;&#23545;&#25163;&#21487;&#20197;&#28155;&#21152;&#20219;&#24847;&#36793;&#30340;&#24773;&#20917;&#12290;&#32479;&#35745;&#23398;&#23478;&#30340;&#30446;&#26631;&#26159;&#26681;&#25454;&#20174;&#36825;&#20010;&#21322;&#38543;&#26426;&#27604;&#36739;&#22270;&#23548;&#20986;&#30340;&#20004;&#20004;&#27604;&#36739;&#20934;&#30830;&#22320;&#35782;&#21035;&#20986;Top-K&#30340;&#39318;&#36873;&#39033;&#12290;&#26412;&#25991;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#24320;&#21457;&#20986;&#19968;&#31181;&#21152;&#26435;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;(MLE)&#65292;&#23427;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#26041;&#38754;&#36798;&#21040;&#20102;&#36817;&#20284;&#26368;&#20248;&#65292;&#26368;&#22810;&#24046;&#19968;&#20010;$log^2(n)$&#30340;&#22240;&#23376;&#65292;&#20854;&#20013;n&#34920;&#31034;&#27604;&#36739;&#39033;&#30340;&#25968;&#37327;&#12290;&#36825;&#24471;&#30410;&#20110;&#20998;&#26512;&#21644;&#31639;&#27861;&#21019;&#26032;&#30340;&#32467;&#21512;&#12290;&#22312;&#20998;&#26512;&#26041;&#38754;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26356;&#26126;&#30830;&#12289;&#26356;&#32039;&#23494;&#30340;&#21152;&#26435;MLE&#30340;$\ell_\infty$&#35823;&#24046;&#20998;&#26512;&#65292;&#23427;&#19982;&#21152;&#26435;&#27604;&#36739;&#22270;&#30340;&#35889;&#29305;&#24615;&#30456;&#20851;&#12290;&#21463;&#27492;&#21551;&#21457;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#21019;&#26032;&#28041;&#21450;&#21040;&#20102;
&lt;/p&gt;
&lt;p&gt;
In this paper, we address the top-$K$ ranking problem with a monotone adversary. We consider the scenario where a comparison graph is randomly generated and the adversary is allowed to add arbitrary edges. The statistician's goal is then to accurately identify the top-$K$ preferred items based on pairwise comparisons derived from this semi-random comparison graph. The main contribution of this paper is to develop a weighted maximum likelihood estimator (MLE) that achieves near-optimal sample complexity, up to a $\log^2(n)$ factor, where n denotes the number of items under comparison. This is made possible through a combination of analytical and algorithmic innovations. On the analytical front, we provide a refined $\ell_\infty$ error analysis of the weighted MLE that is more explicit and tighter than existing analyses. It relates the $\ell_\infty$ error with the spectral properties of the weighted comparison graph. Motivated by this, our algorithmic innovation involves the development 
&lt;/p&gt;</description></item><item><title>&#20102;&#35299;&#31070;&#32463;&#32593;&#32476;&#20174;&#36755;&#20837;-&#26631;&#31614;&#23545;&#20013;&#25552;&#21462;&#32479;&#35745;&#20449;&#24687;&#30340;&#26426;&#21046;&#26159;&#30417;&#30563;&#23398;&#20064;&#20013;&#26368;&#37325;&#35201;&#30340;&#26410;&#35299;&#20915;&#38382;&#39064;&#20043;&#19968;&#12290;&#21069;&#20154;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#26435;&#37325;&#30340;&#26684;&#25289;&#22982;&#30697;&#38453;&#19982;&#27169;&#22411;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#25104;&#27491;&#27604;&#65292;&#36825;&#34987;&#31216;&#20026;&#31070;&#32463;&#29305;&#24449;&#20998;&#26512;&#65288;NFA&#65289;&#12290;&#26412;&#30740;&#31350;&#35299;&#37322;&#20102;&#36825;&#31181;&#30456;&#20851;&#24615;&#30340;&#20986;&#29616;&#65292;&#24182;&#21457;&#29616;NFA&#31561;&#20215;&#20110;&#26435;&#37325;&#30697;&#38453;&#30340;&#24038;&#22855;&#24322;&#32467;&#26500;&#19982;&#19982;&#36825;&#20123;&#26435;&#37325;&#30456;&#20851;&#30340;&#32463;&#39564;&#31070;&#32463;&#20999;&#32447;&#26680;&#30340;&#26174;&#33879;&#25104;&#20998;&#20043;&#38388;&#30340;&#23545;&#40784;&#12290;&#22312;&#26089;&#26399;&#35757;&#32451;&#38454;&#27573;&#65292;&#21487;&#20197;&#36890;&#36807;&#35299;&#26512;&#30340;&#26041;&#24335;&#39044;&#27979;NFA&#30340;&#21457;&#23637;&#36895;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.05271</link><description>&lt;p&gt;
&#26799;&#24230;&#19979;&#38477;&#24341;&#21457;&#20102;&#28145;&#24230;&#38750;&#32447;&#24615;&#32593;&#32476;&#26435;&#37325;&#19982;&#32463;&#39564;NTK&#20043;&#38388;&#30340;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Gradient descent induces alignment between weights and the empirical NTK for deep non-linear networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05271
&lt;/p&gt;
&lt;p&gt;
&#20102;&#35299;&#31070;&#32463;&#32593;&#32476;&#20174;&#36755;&#20837;-&#26631;&#31614;&#23545;&#20013;&#25552;&#21462;&#32479;&#35745;&#20449;&#24687;&#30340;&#26426;&#21046;&#26159;&#30417;&#30563;&#23398;&#20064;&#20013;&#26368;&#37325;&#35201;&#30340;&#26410;&#35299;&#20915;&#38382;&#39064;&#20043;&#19968;&#12290;&#21069;&#20154;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#26435;&#37325;&#30340;&#26684;&#25289;&#22982;&#30697;&#38453;&#19982;&#27169;&#22411;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#25104;&#27491;&#27604;&#65292;&#36825;&#34987;&#31216;&#20026;&#31070;&#32463;&#29305;&#24449;&#20998;&#26512;&#65288;NFA&#65289;&#12290;&#26412;&#30740;&#31350;&#35299;&#37322;&#20102;&#36825;&#31181;&#30456;&#20851;&#24615;&#30340;&#20986;&#29616;&#65292;&#24182;&#21457;&#29616;NFA&#31561;&#20215;&#20110;&#26435;&#37325;&#30697;&#38453;&#30340;&#24038;&#22855;&#24322;&#32467;&#26500;&#19982;&#19982;&#36825;&#20123;&#26435;&#37325;&#30456;&#20851;&#30340;&#32463;&#39564;&#31070;&#32463;&#20999;&#32447;&#26680;&#30340;&#26174;&#33879;&#25104;&#20998;&#20043;&#38388;&#30340;&#23545;&#40784;&#12290;&#22312;&#26089;&#26399;&#35757;&#32451;&#38454;&#27573;&#65292;&#21487;&#20197;&#36890;&#36807;&#35299;&#26512;&#30340;&#26041;&#24335;&#39044;&#27979;NFA&#30340;&#21457;&#23637;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#20174;&#36755;&#20837;-&#26631;&#31614;&#23545;&#20013;&#25552;&#21462;&#32479;&#35745;&#20449;&#24687;&#30340;&#26426;&#21046;&#26159;&#30417;&#30563;&#23398;&#20064;&#20013;&#26368;&#37325;&#35201;&#30340;&#26410;&#35299;&#20915;&#38382;&#39064;&#20043;&#19968;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#30830;&#23450;&#65292;&#22312;&#19968;&#33324;&#32467;&#26500;&#30340;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#26435;&#37325;&#30340;&#26684;&#25289;&#22982;&#30697;&#38453;&#19982;&#27169;&#22411;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#25104;&#27491;&#27604;&#65292;&#36825;&#20010;&#35828;&#27861;&#34987;&#31216;&#20026;&#31070;&#32463;&#29305;&#24449;&#20998;&#26512;&#65288;NFA&#65289;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#25968;&#37327;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#22914;&#20309;&#30456;&#20851;&#23578;&#19981;&#28165;&#26970;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35299;&#37322;&#20102;&#36825;&#31181;&#30456;&#20851;&#24615;&#30340;&#20986;&#29616;&#12290;&#25105;&#20204;&#21457;&#29616;NFA&#31561;&#20215;&#20110;&#26435;&#37325;&#30697;&#38453;&#30340;&#24038;&#22855;&#24322;&#32467;&#26500;&#19982;&#19982;&#36825;&#20123;&#26435;&#37325;&#30456;&#20851;&#30340;&#32463;&#39564;&#31070;&#32463;&#20999;&#32447;&#26680;&#30340;&#26174;&#33879;&#25104;&#20998;&#20043;&#38388;&#30340;&#23545;&#40784;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20808;&#21069;&#30740;&#31350;&#20013;&#24341;&#20837;&#30340;NFA&#26159;&#30001;&#38548;&#31163;&#36825;&#31181;&#23545;&#40784;&#30340;&#20013;&#24515;&#21270;NFA&#39537;&#21160;&#30340;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22312;&#26089;&#26399;&#35757;&#32451;&#38454;&#27573;&#65292;&#21487;&#20197;&#36890;&#36807;&#35299;&#26512;&#30340;&#26041;&#24335;&#39044;&#27979;NFA&#30340;&#21457;&#23637;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding the mechanisms through which neural networks extract statistics from input-label pairs is one of the most important unsolved problems in supervised learning. Prior works have identified that the gram matrices of the weights in trained neural networks of general architectures are proportional to the average gradient outer product of the model, in a statement known as the Neural Feature Ansatz (NFA). However, the reason these quantities become correlated during training is poorly understood. In this work, we explain the emergence of this correlation. We identify that the NFA is equivalent to alignment between the left singular structure of the weight matrices and a significant component of the empirical neural tangent kernels associated with those weights. We establish that the NFA introduced in prior works is driven by a centered NFA that isolates this alignment. We show that the speed of NFA development can be predicted analytically at early training times in terms of sim
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#20998;&#21106;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#30340;&#35299;&#21078;&#21487;&#25511;&#21307;&#23398;&#22270;&#20687;&#29983;&#25104;&#26041;&#27861;&#65292;&#36890;&#36807;&#38543;&#26426;&#25513;&#27169;&#28040;&#34701;&#35757;&#32451;&#31639;&#27861;&#23454;&#29616;&#23545;&#35299;&#21078;&#32422;&#26463;&#30340;&#26465;&#20214;&#21270;&#65292;&#21516;&#26102;&#25552;&#39640;&#20102;&#32593;&#32476;&#23545;&#35299;&#21078;&#30495;&#23454;&#24615;&#30340;&#23398;&#20064;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.05210</link><description>&lt;p&gt;
&#37319;&#29992;&#20998;&#21106;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#30340;&#35299;&#21078;&#21487;&#25511;&#21307;&#23398;&#22270;&#20687;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Anatomically-Controllable Medical Image Generation with Segmentation-Guided Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05210
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#20998;&#21106;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#30340;&#35299;&#21078;&#21487;&#25511;&#21307;&#23398;&#22270;&#20687;&#29983;&#25104;&#26041;&#27861;&#65292;&#36890;&#36807;&#38543;&#26426;&#25513;&#27169;&#28040;&#34701;&#35757;&#32451;&#31639;&#27861;&#23454;&#29616;&#23545;&#35299;&#21078;&#32422;&#26463;&#30340;&#26465;&#20214;&#21270;&#65292;&#21516;&#26102;&#25552;&#39640;&#20102;&#32593;&#32476;&#23545;&#35299;&#21078;&#30495;&#23454;&#24615;&#30340;&#23398;&#20064;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#24050;&#32463;&#23454;&#29616;&#20102;&#38750;&#24120;&#39640;&#36136;&#37327;&#30340;&#21307;&#23398;&#22270;&#20687;&#29983;&#25104;&#65292;&#21487;&#20197;&#36890;&#36807;&#20026;&#23567;&#22411;&#25110;&#19981;&#24179;&#34913;&#30340;&#25968;&#25454;&#38598;&#25552;&#20379;&#34917;&#20805;&#65292;&#20174;&#32780;&#24110;&#21161;&#20943;&#36731;&#33719;&#21462;&#21644;&#27880;&#37322;&#26032;&#22270;&#20687;&#30340;&#36153;&#29992;&#65292;&#21516;&#26102;&#36824;&#21487;&#20197;&#24212;&#29992;&#20110;&#20854;&#20182;&#26041;&#38754;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#22312;&#29983;&#25104;&#22270;&#20687;&#26102;&#38754;&#20020;&#30528;&#20840;&#23616;&#35299;&#21078;&#30495;&#23454;&#24615;&#30340;&#25361;&#25112;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#21078;&#21487;&#25511;&#30340;&#21307;&#23398;&#22270;&#20687;&#29983;&#25104;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#27599;&#20010;&#37319;&#26679;&#27493;&#39588;&#20013;&#36981;&#24490;&#22810;&#31867;&#35299;&#21078;&#20998;&#21106;&#25513;&#27169;&#65292;&#24182;&#37319;&#29992;&#38543;&#26426;&#25513;&#27169;&#28040;&#34701;&#35757;&#32451;&#31639;&#27861;&#65292;&#20197;&#23454;&#29616;&#23545;&#25152;&#36873;&#35299;&#21078;&#32422;&#26463;&#30340;&#26465;&#20214;&#21270;&#65292;&#21516;&#26102;&#20801;&#35768;&#20854;&#20182;&#35299;&#21078;&#21306;&#22495;&#30340;&#28789;&#27963;&#24615;&#12290;&#36825;&#20063;&#25913;&#21892;&#20102;&#32593;&#32476;&#22312;&#23436;&#20840;&#26080;&#26465;&#20214;&#65288;&#26080;&#32422;&#26463;&#29983;&#25104;&#65289;&#24773;&#20917;&#19979;&#23545;&#35299;&#21078;&#30495;&#23454;&#24615;&#30340;&#23398;&#20064;&#12290;&#36890;&#36807;&#23545;&#20083;&#33146;MRI&#21644;&#33145;&#37096;/&#39048;&#37096;&#21040;&#30406;&#33108;CT&#25968;&#25454;&#38598;&#30340;&#27604;&#36739;&#35780;&#20272;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#27169;&#22411;&#22312;&#35299;&#21078;&#30495;&#23454;&#24615;&#21644;&#36755;&#20837;&#25513;&#27169;&#20445;&#30495;&#24230;&#26041;&#38754;&#20855;&#26377;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models have enabled remarkably high-quality medical image generation, which can help mitigate the expenses of acquiring and annotating new images by supplementing small or imbalanced datasets, along with other applications. However, these are hampered by the challenge of enforcing global anatomical realism in generated images. To this end, we propose a diffusion model for anatomically-controlled medical image generation. Our model follows a multi-class anatomical segmentation mask at each sampling step and incorporates a \textit{random mask ablation} training algorithm, to enable conditioning on a selected combination of anatomical constraints while allowing flexibility in other anatomical areas. This also improves the network's learning of anatomical realism for the completely unconditional (unconstrained generation) case. Comparative evaluation on breast MRI and abdominal/neck-to-pelvis CT datasets demonstrates superior anatomical realism and input mask faithfulness over st
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25240;&#25187;&#33258;&#36866;&#24212;&#22312;&#32447;&#39044;&#27979;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36866;&#24212;&#20110;&#22797;&#26434;&#30340;&#25439;&#22833;&#24207;&#21015;&#21644;&#27604;&#36739;&#22120;&#65292;&#24182;&#25913;&#36827;&#20102;&#38750;&#33258;&#36866;&#24212;&#31639;&#27861;&#12290;&#31639;&#27861;&#20855;&#26377;&#26080;&#38656;&#32467;&#26500;&#24615;&#20551;&#35774;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#19988;&#22312;&#36229;&#21442;&#25968;&#35843;&#25972;&#26041;&#38754;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#36890;&#36807;&#22312;&#32447;&#31526;&#21512;&#39044;&#27979;&#20219;&#21153;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#22909;&#22788;&#12290;</title><link>https://arxiv.org/abs/2402.02720</link><description>&lt;p&gt;
&#25240;&#25187;&#33258;&#36866;&#24212;&#22312;&#32447;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Discounted Adaptive Online Prediction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02720
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25240;&#25187;&#33258;&#36866;&#24212;&#22312;&#32447;&#39044;&#27979;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36866;&#24212;&#20110;&#22797;&#26434;&#30340;&#25439;&#22833;&#24207;&#21015;&#21644;&#27604;&#36739;&#22120;&#65292;&#24182;&#25913;&#36827;&#20102;&#38750;&#33258;&#36866;&#24212;&#31639;&#27861;&#12290;&#31639;&#27861;&#20855;&#26377;&#26080;&#38656;&#32467;&#26500;&#24615;&#20551;&#35774;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#19988;&#22312;&#36229;&#21442;&#25968;&#35843;&#25972;&#26041;&#38754;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#36890;&#36807;&#22312;&#32447;&#31526;&#21512;&#39044;&#27979;&#20219;&#21153;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#23398;&#20064;&#24182;&#19981;&#24635;&#26159;&#35201;&#35760;&#20303;&#19968;&#20999;&#12290;&#30001;&#20110;&#26410;&#26469;&#22312;&#32479;&#35745;&#19978;&#21487;&#33021;&#19982;&#36807;&#21435;&#26377;&#24456;&#22823;&#30340;&#19981;&#21516;&#65292;&#19968;&#20010;&#20851;&#38190;&#30340;&#25361;&#25112;&#26159;&#22312;&#26032;&#25968;&#25454;&#21040;&#26469;&#26102;&#20248;&#38597;&#22320;&#24536;&#35760;&#21382;&#21490;&#12290;&#20026;&#20102;&#24418;&#24335;&#21270;&#36825;&#31181;&#30452;&#35273;&#65292;&#25105;&#20204;&#36816;&#29992;&#26368;&#36817;&#21457;&#23637;&#30340;&#33258;&#36866;&#24212;&#22312;&#32447;&#23398;&#20064;&#25216;&#26415;&#37325;&#26032;&#24605;&#32771;&#20102;&#32463;&#20856;&#30340;&#25240;&#25187;&#36951;&#25022;&#27010;&#24565;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#19968;&#20010;&#26032;&#30340;&#31639;&#27861;&#65292;&#23427;&#36866;&#24212;&#20110;&#25439;&#22833;&#24207;&#21015;&#21644;&#27604;&#36739;&#22120;&#30340;&#22797;&#26434;&#24615;&#65292;&#25913;&#36827;&#20102;&#24191;&#27867;&#20351;&#29992;&#30340;&#38750;&#33258;&#36866;&#24212;&#31639;&#27861;-&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#19988;&#20855;&#26377;&#24658;&#23450;&#30340;&#23398;&#20064;&#29575;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30340;&#29702;&#35770;&#20445;&#35777;&#19981;&#38656;&#35201;&#20219;&#20309;&#32467;&#26500;&#24615;&#20551;&#35774;&#65292;&#21482;&#35201;&#27714;&#20984;&#24615;&#65292;&#24182;&#19988;&#35813;&#31639;&#27861;&#32463;&#36807;&#35777;&#26126;&#23545;&#27425;&#20248;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#36890;&#36807;&#22312;&#32447;&#31526;&#21512;&#39044;&#27979;&#26469;&#23637;&#31034;&#36825;&#20123;&#22909;&#22788;&#65292;&#32780;&#22312;&#32447;&#31526;&#21512;&#39044;&#27979;&#26159;&#19968;&#20010;&#24102;&#26377;&#38598;&#21512;&#25104;&#21592;&#20915;&#31574;&#30340;&#19979;&#28216;&#22312;&#32447;&#23398;&#20064;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online learning is not always about memorizing everything. Since the future can be statistically very different from the past, a critical challenge is to gracefully forget the history while new data comes in. To formalize this intuition, we revisit the classical notion of discounted regret using recently developed techniques in adaptive online learning. Our main result is a new algorithm that adapts to the complexity of both the loss sequence and the comparator, improving the widespread non-adaptive algorithm - gradient descent with a constant learning rate. In particular, our theoretical guarantee does not require any structural assumption beyond convexity, and the algorithm is provably robust to suboptimal hyperparameter tuning. We further demonstrate such benefits through online conformal prediction, a downstream online learning task with set-membership decisions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#35821;&#35328;&#27169;&#22411;&#26356;&#26032;&#20013;&#30340;&#36951;&#24536;&#29616;&#35937;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#27979;&#19978;&#28216;&#23454;&#20363;&#36951;&#24536;&#30340;&#26041;&#27861;&#65292;&#20197;&#25913;&#36827;&#37325;&#25773;&#36807;&#31243;&#30340;&#21487;&#25511;&#24615;&#21644;&#35299;&#37322;&#24615;&#12290;&#26681;&#25454;&#39044;&#35757;&#32451;&#23454;&#20363;&#30340;&#39044;-softmax&#23545;&#25968;&#20960;&#29575;&#20998;&#25968;&#21464;&#21270;&#19982;&#22312;&#32447;&#23398;&#20064;&#23454;&#20363;&#30340;&#30456;&#20284;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#37096;&#20998;&#21487;&#35299;&#37322;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#22312;BART&#27169;&#22411;&#19978;&#34920;&#29616;&#33391;&#22909;&#20294;&#22312;T5&#27169;&#22411;&#19978;&#22833;&#36133;&#12290;&#27492;&#22806;&#65292;&#36824;&#23637;&#31034;&#20102;&#22522;&#20110;&#20869;&#31215;&#30340;&#40657;&#30418;&#20998;&#31867;&#22120;&#12290;</title><link>https://arxiv.org/abs/2402.01865</link><description>&lt;p&gt;
&#25105;&#30340;&#27169;&#22411;&#20250;&#24536;&#35760;&#20160;&#20040;&#65311;&#35821;&#35328;&#27169;&#22411;&#25913;&#36827;&#20013;&#30340;&#34987;&#36951;&#24536;&#23454;&#20363;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
What Will My Model Forget? Forecasting Forgotten Examples in Language Model Refinement
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01865
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35821;&#35328;&#27169;&#22411;&#26356;&#26032;&#20013;&#30340;&#36951;&#24536;&#29616;&#35937;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#27979;&#19978;&#28216;&#23454;&#20363;&#36951;&#24536;&#30340;&#26041;&#27861;&#65292;&#20197;&#25913;&#36827;&#37325;&#25773;&#36807;&#31243;&#30340;&#21487;&#25511;&#24615;&#21644;&#35299;&#37322;&#24615;&#12290;&#26681;&#25454;&#39044;&#35757;&#32451;&#23454;&#20363;&#30340;&#39044;-softmax&#23545;&#25968;&#20960;&#29575;&#20998;&#25968;&#21464;&#21270;&#19982;&#22312;&#32447;&#23398;&#20064;&#23454;&#20363;&#30340;&#30456;&#20284;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#37096;&#20998;&#21487;&#35299;&#37322;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#22312;BART&#27169;&#22411;&#19978;&#34920;&#29616;&#33391;&#22909;&#20294;&#22312;T5&#27169;&#22411;&#19978;&#22833;&#36133;&#12290;&#27492;&#22806;&#65292;&#36824;&#23637;&#31034;&#20102;&#22522;&#20110;&#20869;&#31215;&#30340;&#40657;&#30418;&#20998;&#31867;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#35821;&#35328;&#27169;&#22411;&#20250;&#20986;&#29616;&#38169;&#35823;&#12290;&#28982;&#32780;&#65292;&#20165;&#20165;&#36890;&#36807;&#23558;&#27169;&#22411;&#26356;&#26032;&#20026;&#32416;&#27491;&#38169;&#35823;&#23454;&#20363;&#65292;&#20250;&#23548;&#33268;&#28798;&#38590;&#24615;&#30340;&#36951;&#24536;&#65292;&#26356;&#26032;&#21518;&#30340;&#27169;&#22411;&#22312;&#25351;&#23548;&#24494;&#35843;&#25110;&#19978;&#28216;&#35757;&#32451;&#38454;&#27573;&#20013;&#23398;&#21040;&#30340;&#23454;&#20363;&#19978;&#20986;&#29616;&#38169;&#35823;&#12290;&#38543;&#26426;&#37325;&#25773;&#19978;&#28216;&#25968;&#25454;&#30340;&#25928;&#26524;&#19981;&#20196;&#20154;&#28385;&#24847;&#65292;&#24448;&#24448;&#20276;&#38543;&#30528;&#36739;&#39640;&#30340;&#26041;&#24046;&#21644;&#36739;&#24046;&#30340;&#21487;&#25511;&#24615;&#12290;&#20026;&#20102;&#25913;&#21892;&#37325;&#25773;&#36807;&#31243;&#30340;&#21487;&#25511;&#24615;&#21644;&#35299;&#37322;&#24615;&#65292;&#25105;&#20204;&#35797;&#22270;&#39044;&#27979;&#30001;&#20110;&#27169;&#22411;&#26356;&#26032;&#32780;&#36951;&#24536;&#30340;&#19978;&#28216;&#23454;&#20363;&#12290;&#25105;&#20204;&#26681;&#25454;&#19968;&#32452;&#22312;&#32447;&#23398;&#20064;&#30340;&#23454;&#20363;&#21644;&#30456;&#24212;&#34987;&#36951;&#24536;&#30340;&#19978;&#28216;&#39044;&#35757;&#32451;&#23454;&#20363;&#35757;&#32451;&#39044;&#27979;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#37096;&#20998;&#21487;&#35299;&#37322;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22522;&#20110;&#36825;&#26679;&#30340;&#35266;&#23519;&#32467;&#26524;&#65306;&#39044;&#35757;&#32451;&#23454;&#20363;&#30340;&#39044;-softmax&#23545;&#25968;&#20960;&#29575;&#20998;&#25968;&#30340;&#21464;&#21270;&#31867;&#20284;&#20110;&#22312;&#32447;&#23398;&#20064;&#23454;&#20363;&#30340;&#21464;&#21270;&#65292;&#36825;&#22312;BART&#27169;&#22411;&#19978;&#34920;&#29616;&#20986;&#19981;&#38169;&#30340;&#25928;&#26524;&#65292;&#20294;&#22312;T5&#27169;&#22411;&#19978;&#22833;&#36133;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#22522;&#20110;&#20869;&#31215;&#30340;&#40657;&#30418;&#20998;&#31867;&#22120;
&lt;/p&gt;
&lt;p&gt;
Language models deployed in the wild make errors. However, simply updating the model with the corrected error instances causes catastrophic forgetting -- the updated model makes errors on instances learned during the instruction tuning or upstream training phase. Randomly replaying upstream data yields unsatisfactory performance and often comes with high variance and poor controllability. To this end, we try to forecast upstream examples that will be forgotten due to a model update for improved controllability of the replay process and interpretability. We train forecasting models given a collection of online learned examples and corresponding forgotten upstream pre-training examples. We propose a partially interpretable forecasting model based on the observation that changes in pre-softmax logit scores of pretraining examples resemble that of online learned examples, which performs decently on BART but fails on T5 models. We further show a black-box classifier based on inner products 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25193;&#23637;&#35270;&#39057;&#25193;&#25955;&#27169;&#22411;&#33267;&#38477;&#27700;&#36229;&#20998;&#36776;&#29575;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#30830;&#23450;&#24615;&#38477;&#23610;&#24230;&#22120;&#21644;&#26242;&#26102;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#26469;&#25429;&#25417;&#22122;&#22768;&#29305;&#24449;&#21644;&#39640;&#39057;&#29575;&#27169;&#24335;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2312.06071</link><description>&lt;p&gt;
&#20855;&#26377;&#26102;&#31354;&#35270;&#39057;&#25193;&#25955;&#30340;&#38477;&#27700;&#38477;&#23610;&#24230;
&lt;/p&gt;
&lt;p&gt;
Precipitation Downscaling with Spatiotemporal Video Diffusion
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.06071
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25193;&#23637;&#35270;&#39057;&#25193;&#25955;&#27169;&#22411;&#33267;&#38477;&#27700;&#36229;&#20998;&#36776;&#29575;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#30830;&#23450;&#24615;&#38477;&#23610;&#24230;&#22120;&#21644;&#26242;&#26102;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#26469;&#25429;&#25417;&#22122;&#22768;&#29305;&#24449;&#21644;&#39640;&#39057;&#29575;&#27169;&#24335;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#27668;&#20505;&#31185;&#23398;&#21644;&#27668;&#35937;&#23398;&#39046;&#22495;&#65292;&#39640;&#20998;&#36776;&#29575;&#30340;&#23616;&#37096;&#38477;&#27700;&#65288;&#38632;&#38634;&#65289;&#39044;&#27979;&#21463;&#21040;&#22522;&#20110;&#27169;&#25311;&#26041;&#27861;&#30340;&#35745;&#31639;&#25104;&#26412;&#38480;&#21046;&#12290;&#32479;&#35745;&#38477;&#23610;&#24230;&#65292;&#25110;&#32773;&#31216;&#20026;&#36229;&#20998;&#36776;&#29575;&#65292;&#26159;&#19968;&#31181;&#24120;&#35265;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#20854;&#20013;&#20302;&#20998;&#36776;&#29575;&#39044;&#27979;&#36890;&#36807;&#32479;&#35745;&#26041;&#27861;&#24471;&#21040;&#25913;&#36827;&#12290;&#19982;&#20256;&#32479;&#35745;&#31639;&#26426;&#35270;&#35273;&#20219;&#21153;&#19981;&#21516;&#65292;&#22825;&#27668;&#21644;&#27668;&#20505;&#24212;&#29992;&#38656;&#35201;&#25429;&#25417;&#32473;&#23450;&#20302;&#20998;&#36776;&#29575;&#27169;&#24335;&#30340;&#39640;&#20998;&#36776;&#29575;&#30340;&#20934;&#30830;&#26465;&#20214;&#20998;&#24067;&#65292;&#20197;&#30830;&#20445;&#21487;&#38752;&#30340;&#38598;&#21512;&#24179;&#22343;&#21644;&#26497;&#31471;&#20107;&#20214;&#65288;&#22914;&#26292;&#38632;&#65289;&#30340;&#26080;&#20559;&#20272;&#35745;&#12290;&#26412;&#30740;&#31350;&#23558;&#26368;&#26032;&#30340;&#35270;&#39057;&#25193;&#25955;&#27169;&#22411;&#25193;&#23637;&#21040;&#38477;&#27700;&#36229;&#20998;&#36776;&#29575;&#65292;&#20351;&#29992;&#30830;&#23450;&#24615;&#38477;&#23610;&#24230;&#22120;&#65292;&#28982;&#21518;&#26159;&#26242;&#26102;&#26465;&#20214;&#30340;&#25193;&#25955;&#27169;&#22411;&#26469;&#25429;&#25417;&#22122;&#22768;&#29305;&#24449;&#21644;&#39640;&#39057;&#29575;&#27169;&#24335;&#12290;&#25105;&#20204;&#22312;FV3GFS&#36755;&#20986;&#19978;&#27979;&#35797;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#36825;&#26159;&#19968;&#20010;&#24050;&#24314;&#31435;&#30340;&#22823;&#35268;&#27169;&#20840;&#29699;&#22823;&#27668;&#27169;&#22411;&#65292;&#24182;&#23558;&#20854;&#19982;&#20854;&#20182;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.06071v2 Announce Type: replace-cross  Abstract: In climate science and meteorology, high-resolution local precipitation (rain and snowfall) predictions are limited by the computational costs of simulation-based methods. Statistical downscaling, or super-resolution, is a common workaround where a low-resolution prediction is improved using statistical approaches. Unlike traditional computer vision tasks, weather and climate applications require capturing the accurate conditional distribution of high-resolution given low-resolution patterns to assure reliable ensemble averages and unbiased estimates of extreme events, such as heavy rain. This work extends recent video diffusion models to precipitation super-resolution, employing a deterministic downscaler followed by a temporally-conditioned diffusion model to capture noise characteristics and high-frequency patterns. We test our approach on FV3GFS output, an established large-scale global atmosphere model, and compare it agai
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#22312;&#36807;&#21442;&#25968;&#21270;&#26465;&#20214;&#19979;&#30340;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#26041;&#27861;&#12290;&#36890;&#36807;&#23454;&#35777;&#21644;&#29702;&#35770;&#32467;&#26524;&#65292;&#21457;&#29616;&#36807;&#21442;&#25968;&#21270;&#23545;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#24182;&#19988;&#22312;&#36807;&#21442;&#25968;&#21270;&#22686;&#21152;&#30340;&#24773;&#20917;&#19979;&#65292;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#20173;&#28982;&#21463;&#30410;&#12290;</title><link>https://arxiv.org/abs/2311.17539</link><description>&lt;p&gt;
&#22312;&#36807;&#21442;&#25968;&#21270;&#19979;&#20998;&#26512;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;
&lt;/p&gt;
&lt;p&gt;
Analyzing Sharpness-aware Minimization under Overparameterization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.17539
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#22312;&#36807;&#21442;&#25968;&#21270;&#26465;&#20214;&#19979;&#30340;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#26041;&#27861;&#12290;&#36890;&#36807;&#23454;&#35777;&#21644;&#29702;&#35770;&#32467;&#26524;&#65292;&#21457;&#29616;&#36807;&#21442;&#25968;&#21270;&#23545;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#24182;&#19988;&#22312;&#36807;&#21442;&#25968;&#21270;&#22686;&#21152;&#30340;&#24773;&#20917;&#19979;&#65292;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#20173;&#28982;&#21463;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35757;&#32451;&#36807;&#21442;&#25968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#26102;&#65292;&#23613;&#31649;&#35757;&#32451;&#25439;&#22833;&#30456;&#21516;&#65292;&#20294;&#21487;&#20197;&#24471;&#21040;&#20855;&#26377;&#19981;&#21516;&#27867;&#21270;&#33021;&#21147;&#30340;&#26497;&#23567;&#20540;&#12290;&#26377;&#35777;&#25454;&#34920;&#26126;&#65292;&#26497;&#23567;&#20540;&#30340;&#38160;&#24230;&#19982;&#20854;&#27867;&#21270;&#35823;&#24046;&#20043;&#38388;&#23384;&#22312;&#30456;&#20851;&#24615;&#65292;&#22240;&#27492;&#24050;&#32463;&#20570;&#20986;&#20102;&#26356;&#22810;&#21162;&#21147;&#24320;&#21457;&#19968;&#31181;&#20248;&#21270;&#26041;&#27861;&#65292;&#20197;&#26174;&#24335;&#22320;&#25214;&#21040;&#25153;&#24179;&#26497;&#23567;&#20540;&#20316;&#20026;&#26356;&#20855;&#26377;&#27867;&#21270;&#33021;&#21147;&#30340;&#35299;&#12290;&#28982;&#32780;&#65292;&#33267;&#20170;&#20026;&#27490;&#65292;&#20851;&#20110;&#36807;&#21442;&#25968;&#21270;&#23545;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#65288;SAM&#65289;&#31574;&#30053;&#30340;&#24433;&#21709;&#30340;&#30740;&#31350;&#36824;&#19981;&#22810;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#22312;&#19981;&#21516;&#31243;&#24230;&#30340;&#36807;&#21442;&#25968;&#21270;&#19979;&#30340;SAM&#65292;&#24182;&#25552;&#20986;&#20102;&#23454;&#35777;&#21644;&#29702;&#35770;&#32467;&#26524;&#65292;&#34920;&#26126;&#36807;&#21442;&#25968;&#21270;&#23545;SAM&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#25968;&#20540;&#23454;&#39564;&#65292;&#28085;&#30422;&#20102;&#21508;&#20010;&#39046;&#22495;&#65292;&#24182;&#34920;&#26126;&#23384;&#22312;&#19968;&#31181;&#19968;&#33268;&#30340;&#36235;&#21183;&#65292;&#21363;SAM&#22312;&#36807;&#21442;&#25968;&#21270;&#22686;&#21152;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#21463;&#30410;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#20102;&#19968;&#20123;&#20196;&#20154;&#20449;&#26381;&#30340;&#26696;&#20363;&#65292;&#35828;&#26126;&#20102;&#36807;&#21442;&#25968;&#21270;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training an overparameterized neural network can yield minimizers of different generalization capabilities despite the same level of training loss. With evidence that suggests a correlation between sharpness of minima and their generalization errors, increasing efforts have been made to develop an optimization method to explicitly find flat minima as more generalizable solutions. However, this sharpness-aware minimization (SAM) strategy has not been studied much yet as to whether and how it is affected by overparameterization.   In this work, we analyze SAM under overparameterization of varying degrees and present both empirical and theoretical results that indicate a critical influence of overparameterization on SAM. Specifically, we conduct extensive numerical experiments across various domains, and show that there exists a consistent trend that SAM continues to benefit from increasing overparameterization. We also discover compelling cases where the effect of overparameterization is
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;The Attention Patch&#65288;TAP&#65289;&#31070;&#32463;&#32593;&#32476;&#38468;&#21152;&#32452;&#20214;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#19988;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#20801;&#35768;&#20174;&#26410;&#26631;&#35760;&#30340;&#27425;&#35201;&#27169;&#24577;&#23454;&#29616;&#36328;&#27169;&#24577;&#30340;&#25968;&#25454;&#32423;&#30693;&#35782;&#20256;&#36882;&#12290;</title><link>https://arxiv.org/abs/2302.02224</link><description>&lt;p&gt;
TAP: &#36328;&#27169;&#24577;&#30693;&#35782;&#20256;&#36882;&#20013;&#30340;&#27880;&#24847;&#21147;&#34917;&#19969;
&lt;/p&gt;
&lt;p&gt;
TAP: The Attention Patch for Cross-Modal Knowledge Transfer from Unlabeled Modality
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2302.02224
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;The Attention Patch&#65288;TAP&#65289;&#31070;&#32463;&#32593;&#32476;&#38468;&#21152;&#32452;&#20214;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#19988;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#20801;&#35768;&#20174;&#26410;&#26631;&#35760;&#30340;&#27425;&#35201;&#27169;&#24577;&#23454;&#29616;&#36328;&#27169;&#24577;&#30340;&#25968;&#25454;&#32423;&#30693;&#35782;&#20256;&#36882;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#36328;&#27169;&#24577;&#23398;&#20064;&#26694;&#26550;&#65292;&#20854;&#30446;&#26631;&#26159;&#36890;&#36807;&#26410;&#26631;&#35760;&#12289;&#19981;&#37197;&#23545;&#30340;&#27425;&#35201;&#27169;&#24577;&#65292;&#22686;&#24378;&#20027;&#35201;&#27169;&#24577;&#20013;&#30417;&#30563;&#23398;&#20064;&#30340;&#24615;&#33021;&#12290;&#37319;&#29992;&#27010;&#29575;&#26041;&#27861;&#36827;&#34892;&#32570;&#22833;&#20449;&#24687;&#20272;&#35745;&#65292;&#25105;&#20204;&#34920;&#26126;&#27425;&#35201;&#27169;&#24577;&#20013;&#21253;&#21547;&#30340;&#39069;&#22806;&#20449;&#24687;&#21487;&#20197;&#36890;&#36807;Nadaraya-Watson&#65288;NW&#65289;&#26680;&#22238;&#24402;&#36827;&#34892;&#20272;&#35745;&#65292;&#20854;&#21487;&#20197;&#36827;&#19968;&#27493;&#34920;&#31034;&#20026;&#32463;&#36807;&#32447;&#24615;&#21464;&#25442;&#30340;&#26680;&#20132;&#21449;&#27880;&#24847;&#21147;&#27169;&#22359;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20026;&#24341;&#20837;The Attention Patch&#65288;TAP&#65289;&#22880;&#23450;&#20102;&#22522;&#30784;&#65292;&#36825;&#26159;&#19968;&#20010;&#31616;&#21333;&#30340;&#31070;&#32463;&#32593;&#32476;&#38468;&#21152;&#32452;&#20214;&#65292;&#20801;&#35768;&#20174;&#26410;&#26631;&#35760;&#30340;&#27169;&#24577;&#36827;&#34892;&#25968;&#25454;&#32423;&#30693;&#35782;&#20256;&#36882;&#12290;&#25105;&#20204;&#20351;&#29992;&#22235;&#20010;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#22823;&#37327;&#25968;&#20540;&#27169;&#25311;&#65292;&#32467;&#26524;&#34920;&#26126;TAP&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#36328;&#19981;&#21516;&#39046;&#22495;&#21644;&#19981;&#21516;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#21033;&#29992;&#30475;&#20284;&#26080;&#29992;&#30340;&#26410;&#26631;&#35760;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2302.02224v2 Announce Type: replace  Abstract: This paper addresses a cross-modal learning framework, where the objective is to enhance the performance of supervised learning in the primary modality using an unlabeled, unpaired secondary modality. Taking a probabilistic approach for missing information estimation, we show that the extra information contained in the secondary modality can be estimated via Nadaraya-Watson (NW) kernel regression, which can further be expressed as a kernelized cross-attention module (under linear transformation). Our results lay the foundations for introducing The Attention Patch (TAP), a simple neural network add-on that allows data-level knowledge transfer from the unlabeled modality. We provide extensive numerical simulations using four real-world datasets to show that TAP can provide statistically significant improvement in generalization across different domains and different neural network architectures, making use of seemingly unusable unlabel
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#33529;&#26524;&#21697;&#23581;&#30340;&#21487;&#23398;&#20064;&#24615;&#65292;&#20174;&#32452;&#21512;&#35282;&#24230;&#30740;&#31350;&#20102;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;&#12290;&#20316;&#32773;&#36890;&#36807;&#24341;&#20837;Effective width&#21442;&#25968;&#65292;&#32039;&#23494;&#37327;&#21270;&#20102;&#22312;&#21487;&#23454;&#29616;&#35774;&#32622;&#20013;&#30340;&#26497;&#23567;&#26399;&#26395;&#38169;&#35823;&#65292;&#24182;&#22312;&#21487;&#23454;&#29616;&#35774;&#32622;&#20013;&#24314;&#31435;&#20102;&#26497;&#23567;&#26399;&#26395;&#38169;&#35823;&#25968;&#37327;&#30340;&#19977;&#20998;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.19064</link><description>&lt;p&gt;
&#37325;&#26032;&#23457;&#35270;&#33529;&#26524;&#21697;&#23581;&#30340;&#21487;&#23398;&#20064;&#24615;
&lt;/p&gt;
&lt;p&gt;
Revisiting the Learnability of Apple Tasting. (arXiv:2310.19064v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19064
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#33529;&#26524;&#21697;&#23581;&#30340;&#21487;&#23398;&#20064;&#24615;&#65292;&#20174;&#32452;&#21512;&#35282;&#24230;&#30740;&#31350;&#20102;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;&#12290;&#20316;&#32773;&#36890;&#36807;&#24341;&#20837;Effective width&#21442;&#25968;&#65292;&#32039;&#23494;&#37327;&#21270;&#20102;&#22312;&#21487;&#23454;&#29616;&#35774;&#32622;&#20013;&#30340;&#26497;&#23567;&#26399;&#26395;&#38169;&#35823;&#65292;&#24182;&#22312;&#21487;&#23454;&#29616;&#35774;&#32622;&#20013;&#24314;&#31435;&#20102;&#26497;&#23567;&#26399;&#26395;&#38169;&#35823;&#25968;&#37327;&#30340;&#19977;&#20998;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22312;&#32447;&#20108;&#20803;&#20998;&#31867;&#20013;&#65292;&#23398;&#20064;&#32773;&#21482;&#26377;&#22312;&#39044;&#27979;&#20026;"1"&#26102;&#35266;&#23519;&#21040;&#30495;&#23454;&#26631;&#31614;&#12290;&#26412;&#25991;&#37325;&#26032;&#30740;&#31350;&#20102;&#36825;&#31181;&#32463;&#20856;&#30340;&#37096;&#20998;&#21453;&#39304;&#35774;&#32622;&#65292;&#24182;&#20174;&#32452;&#21512;&#35282;&#24230;&#30740;&#31350;&#20102;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19981;&#21487;&#30693;&#35774;&#32622;&#19979;&#65292;Littlestone&#32500;&#24230;&#20173;&#28982;&#26159;&#33529;&#26524;&#21697;&#23581;&#30340;&#32039;&#23494;&#23450;&#37327;&#21051;&#30011;&#65292;&#35299;&#20915;&#20102;\cite{helmbold2000apple}&#25552;&#20986;&#30340;&#19968;&#20010;&#24748;&#32780;&#26410;&#20915;&#30340;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#32452;&#21512;&#21442;&#25968;&#65292;&#31216;&#20026;&#26377;&#25928;&#23485;&#24230;&#65292;&#32039;&#23494;&#37327;&#21270;&#20102;&#22312;&#21487;&#23454;&#29616;&#35774;&#32622;&#20013;&#30340;&#26497;&#23567;&#26399;&#26395;&#38169;&#35823;&#12290;&#20316;&#20026;&#25512;&#35770;&#65292;&#25105;&#20204;&#20351;&#29992;&#26377;&#25928;&#23485;&#24230;&#22312;&#21487;&#23454;&#29616;&#35774;&#32622;&#20013;&#24314;&#31435;&#20102;&#26497;&#23567;&#26399;&#26395;&#38169;&#35823;&#25968;&#37327;&#30340;&#19977;&#20998;&#27861;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#21487;&#23454;&#29616;&#35774;&#32622;&#20013;&#65292;&#20219;&#20309;&#23398;&#20064;&#32773;&#22312;&#33529;&#26524;&#21697;&#23581;&#21453;&#39304;&#19979;&#30340;&#26399;&#26395;&#38169;&#35823;&#25968;&#37327;&#21482;&#33021;&#26159;$\Theta(1), \Theta(\sqrt{T})$, &#25110; $\Theta(T)$&#12290;
&lt;/p&gt;
&lt;p&gt;
In online binary classification under \textit{apple tasting} feedback, the learner only observes the true label if it predicts "1". First studied by \cite{helmbold2000apple}, we revisit this classical partial-feedback setting and study online learnability from a combinatorial perspective. We show that the Littlestone dimension continues to prove a tight quantitative characterization of apple tasting in the agnostic setting, closing an open question posed by \cite{helmbold2000apple}. In addition, we give a new combinatorial parameter, called the Effective width, that tightly quantifies the minimax expected mistakes in the realizable setting. As a corollary, we use the Effective width to establish a \textit{trichotomy} of the minimax expected number of mistakes in the realizable setting. In particular, we show that in the realizable setting, the expected number of mistakes for any learner under apple tasting feedback can only be $\Theta(1), \Theta(\sqrt{T})$, or $\Theta(T)$.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#22312;&#29983;&#25104;&#24615;&#25193;&#25955;&#27169;&#22411;&#20013;&#24212;&#29992;&#24179;&#34913;&#32479;&#35745;&#21147;&#23398;&#30340;&#24037;&#20855;&#65292;&#25581;&#31034;&#20102;&#36825;&#20123;&#27169;&#22411;&#20013;&#30340;&#20108;&#38454;&#30456;&#21464;&#29616;&#35937;&#65292;&#24182;&#19988;&#35748;&#20026;&#36825;&#31181;&#31283;&#23450;&#24615;&#24418;&#24335;&#26159;&#29983;&#25104;&#33021;&#21147;&#30340;&#20851;&#38190;&#12290;</title><link>http://arxiv.org/abs/2310.17467</link><description>&lt;p&gt;
&#29983;&#25104;&#24615;&#25193;&#25955;&#27169;&#22411;&#30340;&#32479;&#35745;&#28909;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
The statistical thermodynamics of generative diffusion models. (arXiv:2310.17467v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17467
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#22312;&#29983;&#25104;&#24615;&#25193;&#25955;&#27169;&#22411;&#20013;&#24212;&#29992;&#24179;&#34913;&#32479;&#35745;&#21147;&#23398;&#30340;&#24037;&#20855;&#65292;&#25581;&#31034;&#20102;&#36825;&#20123;&#27169;&#22411;&#20013;&#30340;&#20108;&#38454;&#30456;&#21464;&#29616;&#35937;&#65292;&#24182;&#19988;&#35748;&#20026;&#36825;&#31181;&#31283;&#23450;&#24615;&#24418;&#24335;&#26159;&#29983;&#25104;&#33021;&#21147;&#30340;&#20851;&#38190;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24615;&#25193;&#25955;&#27169;&#22411;&#22312;&#29983;&#25104;&#24314;&#27169;&#30340;&#35768;&#22810;&#39046;&#22495;&#21462;&#24471;&#20102;&#24778;&#20154;&#30340;&#34920;&#29616;&#12290;&#34429;&#28982;&#36825;&#20123;&#27169;&#22411;&#30340;&#22522;&#26412;&#24605;&#24819;&#26469;&#33258;&#38750;&#24179;&#34913;&#29289;&#29702;&#23398;&#65292;&#20294;&#26412;&#25991;&#20013;&#25105;&#20204;&#34920;&#26126;&#65292;&#21487;&#20197;&#29992;&#24179;&#34913;&#32479;&#35745;&#21147;&#23398;&#30340;&#24037;&#20855;&#26469;&#29702;&#35299;&#36825;&#20123;&#27169;&#22411;&#30340;&#35768;&#22810;&#26041;&#38754;&#12290;&#21033;&#29992;&#36825;&#31181;&#37325;&#26500;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#29983;&#25104;&#24615;&#25193;&#25955;&#27169;&#22411;&#32463;&#21382;&#20102;&#19982;&#23545;&#31216;&#24615;&#30772;&#32570;&#29616;&#35937;&#30456;&#23545;&#24212;&#30340;&#20108;&#38454;&#30456;&#21464;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#36825;&#23548;&#33268;&#20102;&#19968;&#31181;&#31283;&#23450;&#24615;&#24418;&#24335;&#65292;&#23427;&#26159;&#29983;&#25104;&#33021;&#21147;&#30340;&#26680;&#24515;&#65292;&#24182;&#21487;&#20197;&#29992;&#19968;&#32452;&#24179;&#22343;&#22330;&#20020;&#30028;&#25351;&#25968;&#26469;&#25551;&#36848;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#26681;&#25454;&#28909;&#21147;&#23398;&#30340;&#20844;&#24335;&#20998;&#26512;&#20102;&#23558;&#25193;&#25955;&#27169;&#22411;&#19982;&#20851;&#32852;&#35760;&#24518;&#32593;&#32476;&#36830;&#25509;&#30340;&#26368;&#36817;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative diffusion models have achieved spectacular performance in many areas of generative modeling. While the fundamental ideas behind these models come from non-equilibrium physics, in this paper we show that many aspects of these models can be understood using the tools of equilibrium statistical mechanics. Using this reformulation, we show that generative diffusion models undergo second-order phase transitions corresponding to symmetry breaking phenomena. We argue that this lead to a form of instability that lies at the heart of their generative capabilities and that can be described by a set of mean field critical exponents. We conclude by analyzing recent work connecting diffusion models and associative memory networks in view of the thermodynamic formulations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20266;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#24182;&#36890;&#36807;&#30740;&#31350;&#26368;&#23567;&#35201;&#27714;&#30340;&#20844;&#29702;&#26694;&#26550;&#65292;&#26500;&#24314;&#20102;&#33021;&#30830;&#20445;&#40657;&#30418;&#20248;&#21270;&#25910;&#25947;&#24615;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.09766</link><description>&lt;p&gt;
&#20266;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Pseudo-Bayesian Optimization. (arXiv:2310.09766v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09766
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20266;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#24182;&#36890;&#36807;&#30740;&#31350;&#26368;&#23567;&#35201;&#27714;&#30340;&#20844;&#29702;&#26694;&#26550;&#65292;&#26500;&#24314;&#20102;&#33021;&#30830;&#20445;&#40657;&#30418;&#20248;&#21270;&#25910;&#25947;&#24615;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31181;&#20248;&#21270;&#26114;&#36149;&#40657;&#30418;&#20989;&#25968;&#30340;&#27969;&#34892;&#26041;&#27861;&#12290;&#20854;&#20851;&#38190;&#24605;&#24819;&#26159;&#20351;&#29992;&#19968;&#20010;&#26367;&#20195;&#27169;&#22411;&#26469;&#36817;&#20284;&#30446;&#26631;&#65292;&#24182;&#19988;&#37325;&#35201;&#30340;&#26159;&#37327;&#21270;&#30456;&#20851;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#20174;&#32780;&#23454;&#29616;&#25506;&#32034;&#21644;&#24320;&#21457;&#20043;&#38388;&#30340;&#24179;&#34913;&#30340;&#39034;&#24207;&#25628;&#32034;&#12290;&#39640;&#26031;&#36807;&#31243;(GP)&#19968;&#30452;&#26159;&#26367;&#20195;&#27169;&#22411;&#30340;&#39318;&#36873;&#65292;&#22240;&#20026;&#23427;&#20855;&#26377;&#36125;&#21494;&#26031;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#33021;&#21147;&#21644;&#24314;&#27169;&#28789;&#27963;&#24615;&#12290;&#28982;&#32780;&#65292;&#23427;&#30340;&#25361;&#25112;&#20063;&#24341;&#21457;&#20102;&#19968;&#31995;&#21015;&#25910;&#25947;&#24615;&#26356;&#26174;&#24471;&#19981;&#26126;&#26174;&#30340;&#22791;&#36873;&#26041;&#26696;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#30740;&#31350;&#24341;&#20986;&#26368;&#23567;&#35201;&#27714;&#30340;&#20844;&#29702;&#26694;&#26550;&#26469;&#30830;&#20445;&#40657;&#30418;&#20248;&#21270;&#30340;&#25910;&#25947;&#24615;&#65292;&#20197;&#24212;&#29992;&#20110;&#38500;&#20102;GP&#30456;&#20851;&#26041;&#27861;&#20043;&#22806;&#30340;&#24773;&#20917;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21033;&#29992;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#30340;&#35774;&#35745;&#33258;&#30001;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#20266;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#26469;&#26500;&#24314;&#32463;&#39564;&#19978;&#26356;&#20248;&#30340;&#31639;&#27861;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#31616;&#21333;&#30340;&#23616;&#37096;&#22238;&#24402;&#21644;&#19968;&#20010;&#36866;&#24212;&#38382;&#39064;&#29305;&#24615;&#30340;&#20195;&#29702;&#27169;&#22411;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian Optimization is a popular approach for optimizing expensive black-box functions. Its key idea is to use a surrogate model to approximate the objective and, importantly, quantify the associated uncertainty that allows a sequential search of query points that balance exploitation-exploration. Gaussian process (GP) has been a primary candidate for the surrogate model, thanks to its Bayesian-principled uncertainty quantification power and modeling flexibility. However, its challenges have also spurred an array of alternatives whose convergence properties could be more opaque. Motivated by these, we study in this paper an axiomatic framework that elicits the minimal requirements to guarantee black-box optimization convergence that could apply beyond GP-related methods. Moreover, we leverage the design freedom in our framework, which we call Pseudo-Bayesian Optimization, to construct empirically superior algorithms. In particular, we show how using simple local regression, and a sui
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22810;&#20803;&#23431;&#23449;&#20998;&#26512;&#35780;&#20272;&#27169;&#22411;&#35774;&#35745;&#20915;&#31574;&#23545;&#31639;&#27861;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#65292;&#21487;&#20197;&#25581;&#31034;&#31639;&#27861;&#20915;&#31574;&#31995;&#32479;&#20013;&#35774;&#35745;&#20915;&#31574;&#30340;&#20851;&#38190;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2308.16681</link><description>&lt;p&gt;
&#36890;&#36807;&#22810;&#20803;&#23431;&#23449;&#20998;&#26512;&#35780;&#20272;&#27169;&#22411;&#35774;&#35745;&#20915;&#31574;&#23545;&#31639;&#27861;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#65306;&#19968;&#20999;&#65292;&#26080;&#22788;&#19981;&#22312;&#65292;&#20840;&#26041;&#20301;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Everything, Everywhere All in One Evaluation: Using Multiverse Analysis to Evaluate the Influence of Model Design Decisions on Algorithmic Fairness. (arXiv:2308.16681v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16681
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22810;&#20803;&#23431;&#23449;&#20998;&#26512;&#35780;&#20272;&#27169;&#22411;&#35774;&#35745;&#20915;&#31574;&#23545;&#31639;&#27861;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#65292;&#21487;&#20197;&#25581;&#31034;&#31639;&#27861;&#20915;&#31574;&#31995;&#32479;&#20013;&#35774;&#35745;&#20915;&#31574;&#30340;&#20851;&#38190;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20840;&#29699;&#33539;&#22260;&#20869;&#30340;&#35768;&#22810;&#31995;&#32479;&#37117;&#21033;&#29992;&#31639;&#27861;&#20915;&#31574;&#26469;&#65288;&#37096;&#20998;&#65289;&#33258;&#21160;&#21270;&#20197;&#21069;&#30001;&#20154;&#31867;&#36827;&#34892;&#30340;&#20915;&#31574;&#12290;&#24403;&#35774;&#35745;&#33391;&#22909;&#26102;&#65292;&#36825;&#20123;&#31995;&#32479;&#25215;&#35834;&#26356;&#23458;&#35266;&#30340;&#20915;&#31574;&#65292;&#21516;&#26102;&#33410;&#30465;&#22823;&#37327;&#36164;&#28304;&#65292;&#33410;&#32422;&#20154;&#21147;&#12290;&#28982;&#32780;&#65292;&#24403;&#31639;&#27861;&#20915;&#31574;&#31995;&#32479;&#35774;&#35745;&#19981;&#33391;&#26102;&#65292;&#21487;&#33021;&#20250;&#23548;&#33268;&#23545;&#31038;&#20250;&#32676;&#20307;&#36827;&#34892;&#27495;&#35270;&#30340;&#19981;&#20844;&#24179;&#20915;&#31574;&#12290;&#31639;&#27861;&#20915;&#31574;&#31995;&#32479;&#30340;&#19979;&#28216;&#25928;&#24212;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#21462;&#20915;&#20110;&#31995;&#32479;&#35774;&#35745;&#21644;&#23454;&#26045;&#36807;&#31243;&#20013;&#30340;&#20915;&#31574;&#65292;&#22240;&#20026;&#25968;&#25454;&#20013;&#30340;&#20559;&#35265;&#21487;&#33021;&#20250;&#22312;&#24314;&#27169;&#36807;&#31243;&#20013;&#32531;&#35299;&#25110;&#21152;&#24378;&#12290;&#35768;&#22810;&#36825;&#20123;&#35774;&#35745;&#20915;&#31574;&#26159;&#38544;&#21547;&#36827;&#34892;&#30340;&#65292;&#19981;&#30693;&#36947;&#23427;&#20204;&#30830;&#20999;&#22320;&#22914;&#20309;&#24433;&#21709;&#26368;&#32456;&#31995;&#32479;&#12290;&#22240;&#27492;&#65292;&#26126;&#30830;&#31639;&#27861;&#20915;&#31574;&#31995;&#32479;&#35774;&#35745;&#20013;&#30340;&#20915;&#31574;&#24182;&#20102;&#35299;&#36825;&#20123;&#20915;&#31574;&#22914;&#20309;&#24433;&#21709;&#32467;&#26524;&#31995;&#32479;&#30340;&#20844;&#24179;&#24615;&#38750;&#24120;&#37325;&#35201;&#12290;&#20026;&#20102;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20511;&#37492;&#20102;&#24515;&#29702;&#23398;&#39046;&#22495;&#30340;&#35265;&#35299;&#65292;&#24182;&#24341;&#20837;&#20102;&#22810;&#20803;&#23431;&#23449;&#20998;&#26512;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
A vast number of systems across the world use algorithmic decision making (ADM) to (partially) automate decisions that have previously been made by humans. When designed well, these systems promise more objective decisions while saving large amounts of resources and freeing up human time. However, when ADM systems are not designed well, they can lead to unfair decisions which discriminate against societal groups. The downstream effects of ADMs critically depend on the decisions made during the systems' design and implementation, as biases in data can be mitigated or reinforced along the modeling pipeline. Many of these design decisions are made implicitly, without knowing exactly how they will influence the final system. It is therefore important to make explicit the decisions made during the design of ADM systems and understand how these decisions affect the fairness of the resulting system.  To study this issue, we draw on insights from the field of psychology and introduce the metho
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#20869;&#31215;&#26469;&#20272;&#35745;&#22810;&#20803;&#21644;&#22810;&#32500;&#20989;&#25968;&#25968;&#25454;&#38598;&#30340;&#29305;&#24449;&#21521;&#37327;&#65292;&#20026;&#20989;&#25968;&#20027;&#25104;&#20998;&#20998;&#26512;&#25552;&#20379;&#20102;&#26032;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.12949</link><description>&lt;p&gt;
&#20851;&#20110;&#20351;&#29992;&#26684;&#25289;&#22982;&#30697;&#38453;&#36827;&#34892;&#22810;&#20803;&#20989;&#25968;&#20027;&#25104;&#20998;&#20998;&#26512;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the use of the Gram matrix for multivariate functional principal components analysis. (arXiv:2306.12949v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12949
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#20869;&#31215;&#26469;&#20272;&#35745;&#22810;&#20803;&#21644;&#22810;&#32500;&#20989;&#25968;&#25968;&#25454;&#38598;&#30340;&#29305;&#24449;&#21521;&#37327;&#65292;&#20026;&#20989;&#25968;&#20027;&#25104;&#20998;&#20998;&#26512;&#25552;&#20379;&#20102;&#26032;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#20013;&#65292;&#38477;&#32500;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#38477;&#32500;&#30340;&#20851;&#38190;&#24037;&#20855;&#26159;&#20989;&#25968;&#20027;&#25104;&#20998;&#20998;&#26512;&#12290;&#29616;&#26377;&#30340;&#20989;&#25968;&#20027;&#25104;&#20998;&#20998;&#26512;&#26041;&#27861;&#36890;&#24120;&#28041;&#21450;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#23545;&#35282;&#21270;&#12290;&#38543;&#30528;&#20989;&#25968;&#25968;&#25454;&#38598;&#30340;&#35268;&#27169;&#21644;&#22797;&#26434;&#24615;&#22686;&#21152;&#65292;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20272;&#35745;&#21464;&#24471;&#26356;&#21152;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22240;&#27492;&#65292;&#38656;&#35201;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#29305;&#24449;&#21521;&#37327;&#12290;&#22522;&#20110;&#35266;&#27979;&#31354;&#38388;&#21644;&#20989;&#25968;&#29305;&#24449;&#31354;&#38388;&#30340;&#23545;&#20598;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#26354;&#32447;&#20043;&#38388;&#30340;&#20869;&#31215;&#26469;&#20272;&#35745;&#22810;&#20803;&#21644;&#22810;&#32500;&#20989;&#25968;&#25968;&#25454;&#38598;&#30340;&#29305;&#24449;&#21521;&#37327;&#12290;&#24314;&#31435;&#20102;&#21327;&#26041;&#24046;&#30697;&#38453;&#29305;&#24449;&#21521;&#37327;&#21644;&#20869;&#31215;&#30697;&#38453;&#29305;&#24449;&#21521;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#36825;&#20123;&#26041;&#27861;&#22312;&#20960;&#20010;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#35774;&#32622;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#25552;&#20379;&#20102;&#23427;&#20204;&#30340;&#36890;&#29992;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dimension reduction is crucial in functional data analysis (FDA). The key tool to reduce the dimension of the data is functional principal component analysis. Existing approaches for functional principal component analysis usually involve the diagonalization of the covariance operator. With the increasing size and complexity of functional datasets, estimating the covariance operator has become more challenging. Therefore, there is a growing need for efficient methodologies to estimate the eigencomponents. Using the duality of the space of observations and the space of functional features, we propose to use the inner-product between the curves to estimate the eigenelements of multivariate and multidimensional functional datasets. The relationship between the eigenelements of the covariance operator and those of the inner-product matrix is established. We explore the application of these methodologies in several FDA settings and provide general guidance on their usability.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#22312;&#32447;&#22810;&#31867;&#20998;&#31867;&#30340;&#21464;&#20307;&#65292;&#20854;&#20013;&#20351;&#29992;&#38598;&#21512;&#22411;&#21453;&#39304;&#12290;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#32452;&#21512;&#32500;&#24230;&#65292;&#35813;&#35770;&#25991;&#34920;&#26126;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#24615;&#30340;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;&#22312;&#23454;&#29616;&#35774;&#32622;&#19979;&#19981;&#31561;&#20215;&#65292;&#24182;&#23558;&#22312;&#32447;&#22810;&#26631;&#31614;&#25490;&#21517;&#21644;&#22312;&#32447;&#22810;&#26631;&#31614;&#20998;&#31867;&#31561;&#23454;&#38469;&#23398;&#20064;&#35774;&#32622;&#20316;&#20026;&#20854;&#29305;&#23450;&#23454;&#20363;&#12290;</title><link>http://arxiv.org/abs/2306.06247</link><description>&lt;p&gt;
&#20351;&#29992;&#38598;&#21512;&#22411;&#21453;&#39304;&#30340;&#22312;&#32447;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Online Learning with Set-Valued Feedback. (arXiv:2306.06247v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06247
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#22312;&#32447;&#22810;&#31867;&#20998;&#31867;&#30340;&#21464;&#20307;&#65292;&#20854;&#20013;&#20351;&#29992;&#38598;&#21512;&#22411;&#21453;&#39304;&#12290;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#32452;&#21512;&#32500;&#24230;&#65292;&#35813;&#35770;&#25991;&#34920;&#26126;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#24615;&#30340;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;&#22312;&#23454;&#29616;&#35774;&#32622;&#19979;&#19981;&#31561;&#20215;&#65292;&#24182;&#23558;&#22312;&#32447;&#22810;&#26631;&#31614;&#25490;&#21517;&#21644;&#22312;&#32447;&#22810;&#26631;&#31614;&#20998;&#31867;&#31561;&#23454;&#38469;&#23398;&#20064;&#35774;&#32622;&#20316;&#20026;&#20854;&#29305;&#23450;&#23454;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#22810;&#31867;&#20998;&#31867;&#30340;&#19968;&#31181;&#21464;&#20307;&#65292;&#20854;&#20013;&#23398;&#20064;&#22120;&#39044;&#27979;&#21333;&#20010;&#26631;&#31614;&#65292;&#20294;&#25509;&#25910;&#21040;&#19968;&#20010;&#26631;&#31614;&#30340;&#38598;&#21512;&#20316;&#20026;&#21453;&#39304;&#12290;&#22312;&#35813;&#27169;&#22411;&#20013;&#65292;&#22914;&#26524;&#23398;&#20064;&#22120;&#27809;&#26377;&#36755;&#20986;&#21253;&#21547;&#22312;&#21453;&#39304;&#38598;&#21512;&#20013;&#30340;&#26631;&#31614;&#65292;&#21017;&#20250;&#21463;&#21040;&#24809;&#32602;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#19982;&#20855;&#26377;&#21333;&#26631;&#31614;&#21453;&#39304;&#30340;&#22312;&#32447;&#22810;&#31867;&#23398;&#20064;&#19981;&#21516;&#65292;&#22312;&#23454;&#29616;&#35774;&#32622;&#20013;&#20351;&#29992;&#38598;&#21512;&#22411;&#21453;&#39304;&#26102;&#65292;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#21270;&#30340;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;\textit{&#19981;&#31561;&#20215;}&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#20010;&#26032;&#30340;&#32452;&#21512;&#32500;&#24230;&#65292;&#20998;&#21035;&#21629;&#21517;&#20026;&#38598;&#21512;&#23567;&#30707;&#21644;&#24230;&#37327;&#30772;&#35010;&#32500;&#24230;&#65292;&#20005;&#26684;&#25551;&#36848;&#20102;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#21270;&#30340;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#34920;&#26126;&#24230;&#37327;&#30772;&#35010;&#32500;&#24230;&#22312;&#24735;&#24615;&#35774;&#32622;&#19979;&#20005;&#26684;&#25551;&#36848;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#32447;&#22810;&#26631;&#31614;&#25490;&#21517;&#21644;&#22312;&#32447;&#22810;&#26631;&#31614;&#20998;&#31867;&#31561;&#23454;&#38469;&#23398;&#20064;&#35774;&#32622;&#26159;&#25105;&#20204;&#36890;&#29992;&#22312;&#32447;&#23398;&#20064;&#26694;&#26550;&#30340;&#20855;&#20307;&#23454;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a variant of online multiclass classification where the learner predicts a single label but receives a \textit{set of labels} as feedback. In this model, the learner is penalized for not outputting a label contained in the revealed set. We show that unlike online multiclass learning with single-label feedback, deterministic and randomized online learnability are \textit{not equivalent} even in the realizable setting with set-valued feedback. Accordingly, we give two new combinatorial dimensions, named the Set Littlestone and Measure Shattering dimension, that tightly characterize deterministic and randomized online learnability respectively in the realizable setting. In addition, we show that the Measure Shattering dimension tightly characterizes online learnability in the agnostic setting. Finally, we show that practical learning settings like online multilabel ranking and online multilabel classification are specific instances of our general online learning framework.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#22312;&#23384;&#22312;&#38750;&#39640;&#26031;&#22122;&#22768;&#24773;&#20917;&#19979;&#22833;&#25928;&#30340;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#21363;&#36890;&#36807;&#21516;&#26102;&#35757;&#32451;&#19968;&#20010;&#33021;&#37327;&#27169;&#22411;&#26469;&#23398;&#20064;&#27491;&#30830;&#30340;&#22122;&#22768;&#20998;&#24067;&#12290;&#36890;&#36807;&#22810;&#20010;&#20363;&#23376;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#25913;&#36827;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2211.15498</link><description>&lt;p&gt;
&#20855;&#26377;&#26410;&#30693;&#27979;&#37327;&#22122;&#22768;&#30340;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Physics-informed neural networks with unknown measurement noise. (arXiv:2211.15498v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.15498
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#22312;&#23384;&#22312;&#38750;&#39640;&#26031;&#22122;&#22768;&#24773;&#20917;&#19979;&#22833;&#25928;&#30340;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#21363;&#36890;&#36807;&#21516;&#26102;&#35757;&#32451;&#19968;&#20010;&#33021;&#37327;&#27169;&#22411;&#26469;&#23398;&#20064;&#27491;&#30830;&#30340;&#22122;&#22768;&#20998;&#24067;&#12290;&#36890;&#36807;&#22810;&#20010;&#20363;&#23376;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#25913;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;(PINNs)&#26159;&#19968;&#31181;&#26082;&#33021;&#25214;&#21040;&#35299;&#20915;&#26041;&#26696;&#21448;&#33021;&#35782;&#21035;&#20559;&#24494;&#20998;&#26041;&#31243;&#21442;&#25968;&#30340;&#28789;&#27963;&#26041;&#27861;&#12290;&#22823;&#22810;&#25968;&#30456;&#20851;&#30340;&#30740;&#31350;&#37117;&#20551;&#35774;&#25968;&#25454;&#26159;&#26080;&#22122;&#22768;&#30340;&#65292;&#25110;&#32773;&#26159;&#21463;&#24369;&#39640;&#26031;&#22122;&#22768;&#27745;&#26579;&#30340;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26631;&#20934;PINN&#26694;&#26550;&#22312;&#38750;&#39640;&#26031;&#22122;&#22768;&#24773;&#20917;&#19979;&#22833;&#25928;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#36825;&#20010;&#26681;&#26412;&#24615;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#21363;&#21516;&#26102;&#35757;&#32451;&#19968;&#20010;&#33021;&#37327;&#27169;&#22411;(Energy-Based Model, EBM)&#26469;&#23398;&#20064;&#27491;&#30830;&#30340;&#22122;&#22768;&#20998;&#24067;&#12290;&#25105;&#20204;&#36890;&#36807;&#22810;&#20010;&#20363;&#23376;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#25913;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Physics-informed neural networks (PINNs) constitute a flexible approach to both finding solutions and identifying parameters of partial differential equations. Most works on the topic assume noiseless data, or data contaminated by weak Gaussian noise. We show that the standard PINN framework breaks down in case of non-Gaussian noise. We give a way of resolving this fundamental issue and we propose to jointly train an energy-based model (EBM) to learn the correct noise distribution. We illustrate the improved performance of our approach using multiple examples.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;StaPLR&#31639;&#27861;&#30340;&#26032;&#30340;&#22810;&#35270;&#35282;&#25968;&#25454;&#25554;&#34917;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#38477;&#32500;&#31354;&#38388;&#20013;&#25191;&#34892;&#25554;&#34917;&#20197;&#35299;&#20915;&#35745;&#31639;&#25361;&#25112;&#65292;&#24182;&#22312;&#27169;&#25311;&#25968;&#25454;&#38598;&#20013;&#24471;&#21040;&#20102;&#31454;&#20105;&#24615;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2210.14484</link><description>&lt;p&gt;
&#22810;&#35270;&#35282;&#25968;&#25454;&#20013;&#32570;&#22833;&#20540;&#30340;&#25554;&#34917;&#38382;&#39064;&#35299;&#20915;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Imputation of missing values in multi-view data. (arXiv:2210.14484v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.14484
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;StaPLR&#31639;&#27861;&#30340;&#26032;&#30340;&#22810;&#35270;&#35282;&#25968;&#25454;&#25554;&#34917;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#38477;&#32500;&#31354;&#38388;&#20013;&#25191;&#34892;&#25554;&#34917;&#20197;&#35299;&#20915;&#35745;&#31639;&#25361;&#25112;&#65292;&#24182;&#22312;&#27169;&#25311;&#25968;&#25454;&#38598;&#20013;&#24471;&#21040;&#20102;&#31454;&#20105;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#35270;&#35282;&#25968;&#25454;&#26159;&#25351;&#30001;&#22810;&#20010;&#19981;&#21516;&#29305;&#24449;&#38598;&#25551;&#36848;&#30340;&#25968;&#25454;&#12290;&#22312;&#22788;&#29702;&#22810;&#35270;&#35282;&#25968;&#25454;&#26102;&#65292;&#33509;&#20986;&#29616;&#32570;&#22833;&#20540;&#65292;&#21017;&#19968;&#20010;&#35270;&#35282;&#20013;&#30340;&#25152;&#26377;&#29305;&#24449;&#26497;&#26377;&#21487;&#33021;&#21516;&#26102;&#32570;&#22833;&#65292;&#22240;&#32780;&#23548;&#33268;&#38750;&#24120;&#22823;&#37327;&#30340;&#32570;&#22833;&#25968;&#25454;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22810;&#35270;&#35282;&#23398;&#20064;&#31639;&#27861;&#20013;&#30340;&#25554;&#34917;&#26041;&#27861;&#65292;&#23427;&#22522;&#20110;&#22534;&#21472;&#24809;&#32602;&#36923;&#36753;&#22238;&#24402;(StaPLR)&#31639;&#27861;&#65292;&#22312;&#38477;&#32500;&#31354;&#38388;&#20013;&#25191;&#34892;&#25554;&#34917;&#65292;&#20197;&#35299;&#20915;&#22266;&#26377;&#30340;&#22810;&#35270;&#35282;&#35745;&#31639;&#25361;&#25112;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#27169;&#25311;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#31454;&#20105;&#24615;&#32467;&#26524;&#65292;&#32780;&#19988;&#20855;&#26377;&#26356;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#65292;&#20174;&#32780;&#21487;&#20197;&#20351;&#29992;&#20808;&#36827;&#30340;&#25554;&#34917;&#31639;&#27861;&#65292;&#20363;&#22914;missForest&#12290;
&lt;/p&gt;
&lt;p&gt;
Data for which a set of objects is described by multiple distinct feature sets (called views) is known as multi-view data. When missing values occur in multi-view data, all features in a view are likely to be missing simultaneously. This leads to very large quantities of missing data which, especially when combined with high-dimensionality, makes the application of conditional imputation methods computationally infeasible. We introduce a new imputation method based on the existing stacked penalized logistic regression (StaPLR) algorithm for multi-view learning. It performs imputation in a dimension-reduced space to address computational challenges inherent to the multi-view context. We compare the performance of the new imputation method with several existing imputation algorithms in simulated data sets. The results show that the new imputation method leads to competitive results at a much lower computational cost, and makes the use of advanced imputation algorithms such as missForest 
&lt;/p&gt;</description></item></channel></rss>