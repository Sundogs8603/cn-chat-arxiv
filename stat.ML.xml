<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#22823;&#37327;&#21512;&#25104;&#32593;&#32476;&#25968;&#25454;&#19978;&#35757;&#32451;&#20998;&#31867;&#22120;&#65292;&#35774;&#35745;&#20986;&#26131;&#20110;&#35745;&#31639;&#12289;&#35299;&#26512;&#21487;&#22788;&#29702;&#19988;&#20855;&#26377;&#35299;&#37322;&#24615;&#30340;&#21160;&#24577;&#29305;&#24449;&#31867;&#22411;&#65292;&#23454;&#29616;&#20102;&#20960;&#20046;&#23436;&#32654;&#30340;&#32593;&#32476;&#20998;&#31867;&#65292;&#36229;&#36807;&#20102;&#30446;&#21069;&#25216;&#26415;&#27700;&#24179;&#12290;</title><link>https://arxiv.org/abs/2404.00793</link><description>&lt;p&gt;
&#23398;&#20064;&#32593;&#32476;&#22686;&#38271;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Learning the mechanisms of network growth
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00793
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#22823;&#37327;&#21512;&#25104;&#32593;&#32476;&#25968;&#25454;&#19978;&#35757;&#32451;&#20998;&#31867;&#22120;&#65292;&#35774;&#35745;&#20986;&#26131;&#20110;&#35745;&#31639;&#12289;&#35299;&#26512;&#21487;&#22788;&#29702;&#19988;&#20855;&#26377;&#35299;&#37322;&#24615;&#30340;&#21160;&#24577;&#29305;&#24449;&#31867;&#22411;&#65292;&#23454;&#29616;&#20102;&#20960;&#20046;&#23436;&#32654;&#30340;&#32593;&#32476;&#20998;&#31867;&#65292;&#36229;&#36807;&#20102;&#30446;&#21069;&#25216;&#26415;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#21160;&#24577;&#30495;&#23454;&#32593;&#32476;&#30340;&#26032;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#22312;&#22823;&#37327;&#21512;&#25104;&#32593;&#32476;&#25968;&#25454;&#19978;&#35757;&#32451;&#20998;&#31867;&#22120;&#12290;&#25968;&#25454;&#26159;&#36890;&#36807;&#27169;&#25311;&#21160;&#24577;&#32593;&#32476;&#30340;&#20061;&#31181;&#26368;&#20808;&#36827;&#30340;&#38543;&#26426;&#22270;&#27169;&#22411;&#29983;&#25104;&#30340;&#65292;&#36873;&#23450;&#21442;&#25968;&#33539;&#22260;&#20197;&#30830;&#20445;&#32593;&#32476;&#35268;&#27169;&#38543;&#26102;&#38388;&#21576;&#25351;&#25968;&#22686;&#38271;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#27010;&#24565;&#19978;&#26032;&#39062;&#30340;&#21160;&#24577;&#29305;&#24449;&#31867;&#22411;&#65292;&#23427;&#35745;&#31639;&#22312;&#29305;&#23450;&#26102;&#38388;&#38388;&#38548;&#20869;&#19968;&#32452;&#39030;&#28857;&#25910;&#21040;&#30340;&#26032;&#38142;&#25509;&#25968;&#12290;&#25152;&#25552;&#20986;&#30340;&#29305;&#24449;&#26131;&#20110;&#35745;&#31639;&#65292;&#35299;&#26512;&#19978;&#21487;&#22788;&#29702;&#65292;&#24182;&#20855;&#26377;&#35299;&#37322;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23454;&#29616;&#20102;&#23545;&#21512;&#25104;&#32593;&#32476;&#30340;&#20960;&#20046;&#23436;&#32654;&#20998;&#31867;&#65292;&#36229;&#36807;&#24403;&#21069;&#25216;&#26415;&#27700;&#24179;&#12290;&#23558;&#25105;&#20204;&#30340;&#20998;&#31867;&#26041;&#27861;&#24212;&#29992;&#20110;&#30495;&#23454;&#19990;&#30028;&#30340;&#24341;&#25991;&#32593;&#32476;&#65292;&#23545;&#25991;&#29486;&#20013;&#22768;&#31216;&#30340;&#20855;&#26377;&#20248;&#20808;&#38468;&#30528;&#12289;&#36866;&#24212;&#24615;&#21644;&#32769;&#21270;&#30340;&#27169;&#22411;&#26368;&#22909;&#22320;&#36866;&#24212;&#30495;&#23454;&#19990;&#30028;&#30340;&#24341;&#25991;&#32593;&#32476;&#30340;&#35828;&#27861;&#20855;&#26377;&#21487;&#38752;&#24615;&#65292;&#23613;&#31649;&#26377;&#26102;&#65292;&#39044;&#27979;&#21487;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00793v1 Announce Type: cross  Abstract: We propose a novel model-selection method for dynamic real-life networks. Our approach involves training a classifier on a large body of synthetic network data. The data is generated by simulating nine state-of-the-art random graph models for dynamic networks, with parameter range chosen to ensure exponential growth of the network size in time. We design a conceptually novel type of dynamic features that count new links received by a group of vertices in a particular time interval. The proposed features are easy to compute, analytically tractable, and interpretable. Our approach achieves a near-perfect classification of synthetic networks, exceeding the state-of-the-art by a large margin. Applying our classification method to real-world citation networks gives credibility to the claims in the literature that models with preferential attachment, fitness and aging fit real-world citation networks best, although sometimes, the predicted m
&lt;/p&gt;</description></item><item><title>&#37325;&#26032;&#24605;&#32771;&#23545;&#25239;&#36870;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#31574;&#30053;&#27169;&#20223;&#21644;&#21487;&#36716;&#31227;&#22870;&#21169;&#24674;&#22797;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#28151;&#21512;&#26694;&#26550;PPO-AIRL + SAC&#20197;&#35299;&#20915;SAC&#31639;&#27861;&#22312;AIRL&#35757;&#32451;&#20013;&#26080;&#27861;&#20840;&#38754;&#35299;&#24320;&#22870;&#21169;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.14593</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#23545;&#25239;&#36870;&#24378;&#21270;&#23398;&#20064;&#65306;&#20174;&#31574;&#30053;&#27169;&#20223;&#21644;&#21487;&#36716;&#31227;&#22870;&#21169;&#24674;&#22797;&#30340;&#35282;&#24230;
&lt;/p&gt;
&lt;p&gt;
Rethinking Adversarial Inverse Reinforcement Learning: From the Angles of Policy Imitation and Transferable Reward Recovery
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14593
&lt;/p&gt;
&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#23545;&#25239;&#36870;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#31574;&#30053;&#27169;&#20223;&#21644;&#21487;&#36716;&#31227;&#22870;&#21169;&#24674;&#22797;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#28151;&#21512;&#26694;&#26550;PPO-AIRL + SAC&#20197;&#35299;&#20915;SAC&#31639;&#27861;&#22312;AIRL&#35757;&#32451;&#20013;&#26080;&#27861;&#20840;&#38754;&#35299;&#24320;&#22870;&#21169;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#36870;&#24378;&#21270;&#23398;&#20064;&#65288;AIRL&#65289;&#20316;&#20026;&#27169;&#20223;&#23398;&#20064;&#20013;&#30340;&#22522;&#30707;&#26041;&#27861;&#12290;&#26412;&#25991;&#37325;&#26032;&#24605;&#32771;&#20102;AIRL&#30340;&#20004;&#20010;&#19981;&#21516;&#35282;&#24230;&#65306;&#31574;&#30053;&#27169;&#20223;&#21644;&#21487;&#36716;&#31227;&#22870;&#21169;&#24674;&#22797;&#12290;&#25105;&#20204;&#20174;&#29992;Soft Actor-Critic&#65288;SAC&#65289;&#26367;&#25442;AIRL&#20013;&#30340;&#20869;&#32622;&#31639;&#27861;&#24320;&#22987;&#65292;&#20197;&#22686;&#24378;&#26679;&#26412;&#25928;&#29575;&#65292;&#36825;&#35201;&#24402;&#21151;&#20110;SAC&#30340;&#31163;&#31574;&#30053;&#24418;&#24335;&#21644;&#30456;&#23545;&#20110;AIRL&#32780;&#35328;&#21487;&#35782;&#21035;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#27169;&#22411;&#12290;&#36825;&#30830;&#23454;&#22312;&#31574;&#30053;&#27169;&#20223;&#26041;&#38754;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#25913;&#36827;&#65292;&#20294;&#19981;&#24910;&#32473;&#21487;&#36716;&#31227;&#22870;&#21169;&#24674;&#22797;&#24102;&#26469;&#20102;&#32570;&#28857;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#38416;&#36848;&#20102;SAC&#31639;&#27861;&#26412;&#36523;&#22312;AIRL&#35757;&#32451;&#36807;&#31243;&#20013;&#26080;&#27861;&#20840;&#38754;&#35299;&#24320;&#22870;&#21169;&#20989;&#25968;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#28151;&#21512;&#26694;&#26550;&#65292;PPO-AIRL + SAC&#65292;&#20197;&#33719;&#24471;&#20196;&#20154;&#28385;&#24847;&#30340;&#36716;&#31227;&#25928;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#29615;&#22659;&#25552;&#21462;&#35299;&#24320;&#30340;&#22870;&#21169;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14593v1 Announce Type: new  Abstract: Adversarial inverse reinforcement learning (AIRL) stands as a cornerstone approach in imitation learning. This paper rethinks the two different angles of AIRL: policy imitation and transferable reward recovery. We begin with substituting the built-in algorithm in AIRL with soft actor-critic (SAC) during the policy optimization process to enhance sample efficiency, thanks to the off-policy formulation of SAC and identifiable Markov decision process (MDP) models with respect to AIRL. It indeed exhibits a significant improvement in policy imitation but accidentally brings drawbacks to transferable reward recovery. To learn this issue, we illustrate that the SAC algorithm itself is not feasible to disentangle the reward function comprehensively during the AIRL training process, and propose a hybrid framework, PPO-AIRL + SAC, for satisfactory transfer effect. Additionally, we analyze the capability of environments to extract disentangled rewa
&lt;/p&gt;</description></item><item><title>&#37325;&#35201;&#24615;&#21152;&#26435;&#26159;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#22522;&#26412;&#31243;&#24207;&#65292;&#36890;&#36807;&#23545;&#30446;&#26631;&#20989;&#25968;&#25110;&#27010;&#29575;&#20998;&#24067;&#36827;&#34892;&#21152;&#26435;&#65292;&#21487;&#20197;&#20445;&#35777;&#30417;&#30563;&#23398;&#20064;&#22312;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#20043;&#38388;&#24046;&#24322;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#32479;&#35745;&#19978;&#26399;&#26395;&#30340;&#24615;&#36136;</title><link>https://arxiv.org/abs/2403.10175</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#37325;&#35201;&#24615;&#21152;&#26435;&#31616;&#35201;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
A Short Survey on Importance Weighting for Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10175
&lt;/p&gt;
&lt;p&gt;
&#37325;&#35201;&#24615;&#21152;&#26435;&#26159;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#22522;&#26412;&#31243;&#24207;&#65292;&#36890;&#36807;&#23545;&#30446;&#26631;&#20989;&#25968;&#25110;&#27010;&#29575;&#20998;&#24067;&#36827;&#34892;&#21152;&#26435;&#65292;&#21487;&#20197;&#20445;&#35777;&#30417;&#30563;&#23398;&#20064;&#22312;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#20043;&#38388;&#24046;&#24322;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#32479;&#35745;&#19978;&#26399;&#26395;&#30340;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37325;&#35201;&#24615;&#21152;&#26435;&#26159;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#39033;&#22522;&#26412;&#31243;&#24207;&#65292;&#26681;&#25454;&#26576;&#31181;&#24847;&#20041;&#19978;&#23454;&#20363;&#30340;&#37325;&#35201;&#24615;&#23545;&#30446;&#26631;&#20989;&#25968;&#25110;&#27010;&#29575;&#20998;&#24067;&#36827;&#34892;&#21152;&#26435;&#12290;&#36825;&#19968;&#31616;&#21333;&#32780;&#26377;&#29992;&#30340;&#24605;&#24819;&#30340;&#24191;&#27867;&#24212;&#29992;&#23548;&#33268;&#20102;&#35768;&#22810;&#37325;&#35201;&#24615;&#21152;&#26435;&#30340;&#24212;&#29992;&#12290;&#20363;&#22914;&#65292;&#25454;&#30693;&#65292;&#22312;&#20851;&#20110;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#20043;&#38388;&#24046;&#24322;&#30340;&#20551;&#35774;&#19979;&#30340;&#30417;&#30563;&#23398;&#20064;&#65292;&#36890;&#36807;&#23494;&#24230;&#27604;&#30340;&#37325;&#35201;&#24615;&#21152;&#26435;&#21487;&#20197;&#20445;&#35777;&#32479;&#35745;&#19978;&#26399;&#26395;&#30340;&#24615;&#36136;&#12290;&#36825;&#39033;&#35843;&#26597;&#24635;&#32467;&#20102;&#26426;&#22120;&#23398;&#20064;&#21644;&#30456;&#20851;&#30740;&#31350;&#20013;&#37325;&#35201;&#24615;&#21152;&#26435;&#30340;&#24191;&#27867;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10175v1 Announce Type: cross  Abstract: Importance weighting is a fundamental procedure in statistics and machine learning that weights the objective function or probability distribution based on the importance of the instance in some sense. The simplicity and usefulness of the idea has led to many applications of importance weighting. For example, it is known that supervised learning under an assumption about the difference between the training and test distributions, called distribution shift, can guarantee statistically desirable properties through importance weighting by their density ratio. This survey summarizes the broad applications of importance weighting in machine learning and related research.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;"&#20934;&#21017;&#23849;&#28291;"&#30340;&#27010;&#24565;&#65292;&#21363;&#20248;&#21270;&#19968;&#20010;&#24230;&#37327;&#25351;&#26631;&#24847;&#21619;&#30528;&#21478;&#19968;&#20010;&#24230;&#37327;&#25351;&#26631;&#30340;&#26368;&#20248;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#21457;&#29616;&#65292;&#23545;&#20110;&#25439;&#22833;&#30340;&#20271;&#21162;&#21033;&#20998;&#24067;&#65292;CVaR&#21644;DRO&#30340;&#32467;&#26524;&#36828;&#36229;&#20986;&#29616;&#26377;&#30740;&#31350;&#65292;&#21516;&#26102;&#21457;&#29616;&#20102;&#19968;&#20123;&#29305;&#23450;&#26465;&#20214;&#19979;&#65292;&#21333;&#35843;&#20934;&#21017;&#22914;&#20542;&#26012;ERM&#26080;&#27861;&#36991;&#20813;&#23849;&#28291;&#65292;&#32780;&#38750;&#21333;&#35843;&#30340;&#26367;&#20195;&#26041;&#26696;&#21487;&#20197;&#12290;</title><link>https://arxiv.org/abs/2402.09802</link><description>&lt;p&gt;
&#20934;&#21017;&#23849;&#28291;&#21644;&#25439;&#22833;&#20998;&#24067;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Criterion collapse and loss distribution control
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09802
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;"&#20934;&#21017;&#23849;&#28291;"&#30340;&#27010;&#24565;&#65292;&#21363;&#20248;&#21270;&#19968;&#20010;&#24230;&#37327;&#25351;&#26631;&#24847;&#21619;&#30528;&#21478;&#19968;&#20010;&#24230;&#37327;&#25351;&#26631;&#30340;&#26368;&#20248;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#21457;&#29616;&#65292;&#23545;&#20110;&#25439;&#22833;&#30340;&#20271;&#21162;&#21033;&#20998;&#24067;&#65292;CVaR&#21644;DRO&#30340;&#32467;&#26524;&#36828;&#36229;&#20986;&#29616;&#26377;&#30740;&#31350;&#65292;&#21516;&#26102;&#21457;&#29616;&#20102;&#19968;&#20123;&#29305;&#23450;&#26465;&#20214;&#19979;&#65292;&#21333;&#35843;&#20934;&#21017;&#22914;&#20542;&#26012;ERM&#26080;&#27861;&#36991;&#20813;&#23849;&#28291;&#65292;&#32780;&#38750;&#21333;&#35843;&#30340;&#26367;&#20195;&#26041;&#26696;&#21487;&#20197;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;"&#20934;&#21017;&#23849;&#28291;"&#30340;&#27010;&#24565;&#65292;&#21363;&#20248;&#21270;&#19968;&#20010;&#24230;&#37327;&#25351;&#26631;&#24847;&#21619;&#30528;&#21478;&#19968;&#20010;&#24230;&#37327;&#25351;&#26631;&#30340;&#26368;&#20248;&#24615;&#65292;&#29305;&#21035;&#20851;&#27880;&#21508;&#31181;&#23398;&#20064;&#20934;&#21017;&#19979;&#23849;&#28291;&#25104;&#35823;&#24046;&#27010;&#29575;&#26368;&#23567;&#21270;&#22120;&#30340;&#26465;&#20214;&#65292;&#20174;DRO&#21644;OCE&#39118;&#38505;&#65288;CVaR&#12289;&#20542;&#26012;ERM&#65289;&#21040;&#25991;&#29486;&#20013;&#25506;&#32034;&#30340;&#26368;&#26032;&#19978;&#21319;-&#19979;&#38477;&#31639;&#27861;&#30340;&#38750;&#21333;&#35843;&#20934;&#21017;&#65288;&#27946;&#27700;&#12289;SoftAD&#65289;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#20271;&#21162;&#21033;&#20998;&#24067;&#25439;&#22833;&#30340;&#32972;&#26223;&#19979;&#65292;CVaR&#21644;DRO&#30340;&#29616;&#26377;&#32467;&#26524;&#36828;&#36828;&#36229;&#36234;&#20102;&#23849;&#28291;&#30340;&#33539;&#22260;&#65292;&#28982;&#21518;&#25193;&#22823;&#20102;&#25105;&#20204;&#30340;&#33539;&#22260;&#65292;&#21253;&#25324;&#20195;&#29702;&#25439;&#22833;&#65292;&#23637;&#31034;&#20102;&#20687;&#20542;&#26012;ERM&#36825;&#26679;&#30340;&#21333;&#35843;&#20934;&#21017;&#26080;&#27861;&#36991;&#20813;&#23849;&#28291;&#30340;&#26465;&#20214;&#65292;&#32780;&#38750;&#21333;&#35843;&#30340;&#26367;&#20195;&#26041;&#26696;&#21487;&#20197;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09802v1 Announce Type: cross  Abstract: In this work, we consider the notion of "criterion collapse," in which optimization of one metric implies optimality in another, with a particular focus on conditions for collapse into error probability minimizers under a wide variety of learning criteria, ranging from DRO and OCE risks (CVaR, tilted ERM) to non-monotonic criteria underlying recent ascent-descent algorithms explored in the literature (Flooding, SoftAD). We show how collapse in the context of losses with a Bernoulli distribution goes far beyond existing results for CVaR and DRO, then expand our scope to include surrogate losses, showing conditions where monotonic criteria such as tilted ERM cannot avoid collapse, whereas non-monotonic alternatives can.
&lt;/p&gt;</description></item><item><title>&#36825;&#26159;&#19968;&#31687;&#20851;&#20110;&#22312;&#32447;&#20984;&#20248;&#21270;&#30340;&#35770;&#25991;&#65292;&#20316;&#32773;&#20998;&#26512;&#20102;&#19981;&#21516;&#29615;&#22659;&#19979;&#30340;&#38382;&#39064;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#36716;&#21270;&#20026;&#30456;&#24212;&#30340;&#32447;&#24615;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#21487;&#20197;&#22312;&#38754;&#23545;&#19981;&#21516;&#31867;&#22411;&#23545;&#25163;&#26102;&#33719;&#24471;&#21487;&#27604;&#36739;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.08621</link><description>&lt;p&gt;
&#19968;&#31181;&#24191;&#20041;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Generalized Approach to Online Convex Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08621
&lt;/p&gt;
&lt;p&gt;
&#36825;&#26159;&#19968;&#31687;&#20851;&#20110;&#22312;&#32447;&#20984;&#20248;&#21270;&#30340;&#35770;&#25991;&#65292;&#20316;&#32773;&#20998;&#26512;&#20102;&#19981;&#21516;&#29615;&#22659;&#19979;&#30340;&#38382;&#39064;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#36716;&#21270;&#20026;&#30456;&#24212;&#30340;&#32447;&#24615;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#21487;&#20197;&#22312;&#38754;&#23545;&#19981;&#21516;&#31867;&#22411;&#23545;&#25163;&#26102;&#33719;&#24471;&#21487;&#27604;&#36739;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#19981;&#21516;&#29615;&#22659;&#19979;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20219;&#20309;&#29992;&#20110;&#20855;&#26377;&#23436;&#20840;&#33258;&#36866;&#24212;&#23545;&#25163;&#30340;&#22312;&#32447;&#32447;&#24615;&#20248;&#21270;&#30340;&#31639;&#27861;&#37117;&#26159;&#29992;&#20110;&#22312;&#32447;&#20984;&#20248;&#21270;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#20219;&#20309;&#38656;&#35201;&#20840;&#20449;&#24687;&#21453;&#39304;&#30340;&#31639;&#27861;&#37117;&#21487;&#20197;&#36716;&#21270;&#20026;&#20855;&#26377;&#21487;&#27604;&#36739;&#30340;&#36951;&#25022;&#30028;&#38480;&#30340;&#21322;&#21305;&#37197;&#21453;&#39304;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#20351;&#29992;&#30830;&#23450;&#24615;&#21322;&#21305;&#37197;&#21453;&#39304;&#30340;&#20840;&#33258;&#36866;&#24212;&#23545;&#25163;&#35774;&#35745;&#30340;&#31639;&#27861;&#22312;&#38754;&#23545;&#26080;&#30693;&#23545;&#25163;&#26102;&#21487;&#20197;&#20351;&#29992;&#21482;&#26377;&#38543;&#26426;&#21322;&#21305;&#37197;&#21453;&#39304;&#30340;&#31639;&#27861;&#33719;&#24471;&#30456;&#20284;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#19968;&#32467;&#26524;&#25551;&#36848;&#20102;&#23558;&#19968;&#38454;&#31639;&#27861;&#36716;&#21270;&#20026;&#38646;&#38454;&#31639;&#27861;&#30340;&#36890;&#29992;&#20803;&#31639;&#27861;&#65292;&#36825;&#20123;&#31639;&#27861;&#20855;&#26377;&#21487;&#27604;&#36739;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#20351;&#25105;&#20204;&#33021;&#22815;&#20998;&#26512;&#21508;&#31181;&#35774;&#32622;&#20013;&#30340;&#22312;&#32447;&#20248;&#21270;&#38382;&#39064;&#65292;&#21253;&#25324;&#20840;&#20449;&#24687;&#21453;&#39304;&#12289;&#21322;&#21305;&#37197;&#21453;&#39304;&#12289;&#38543;&#26426;&#36951;&#25022;&#12289;&#23545;&#25239;&#36951;&#25022;&#21644;&#21508;&#31181;&#24418;&#24335;&#30340;&#38750;&#24179;&#31283;&#36951;&#25022;&#12290;&#21033;&#29992;&#25105;&#20204;&#30340;&#20998;&#26512;&#32467;&#26524;&#65292;
&lt;/p&gt;
&lt;p&gt;
In this paper, we analyze the problem of online convex optimization in different settings. We show that any algorithm for online linear optimization with fully adaptive adversaries is an algorithm for online convex optimization. We also show that any such algorithm that requires full-information feedback may be transformed to an algorithm with semi-bandit feedback with comparable regret bound. We further show that algorithms that are designed for fully adaptive adversaries using deterministic semi-bandit feedback can obtain similar bounds using only stochastic semi-bandit feedback when facing oblivious adversaries. We use this to describe general meta-algorithms to convert first order algorithms to zeroth order algorithms with comparable regret bounds. Our framework allows us to analyze online optimization in various settings, such full-information feedback, bandit feedback, stochastic regret, adversarial regret and various forms of non-stationary regret. Using our analysis, we provide
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#32467;&#26500;&#22238;&#24402;&#26041;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#27169;&#22411;&#22312;&#19981;&#21516;&#20132;&#21449;&#23376;&#32676;&#20307;&#38388;&#30340;&#24615;&#33021;&#12290;&#23427;&#21487;&#20197;&#25552;&#20379;&#21487;&#38752;&#30340;&#31995;&#32479;&#24615;&#33021;&#20272;&#35745;&#65292;&#21363;&#20351;&#23545;&#20110;&#24456;&#23567;&#30340;&#23376;&#32676;&#20307;&#12290;</title><link>http://arxiv.org/abs/2401.14893</link><description>&lt;p&gt;
&#35780;&#20272;&#27169;&#22411;&#22312;&#20132;&#21449;&#23376;&#32676;&#20307;&#38388;&#24615;&#33021;&#30340;&#32467;&#26500;&#22238;&#24402;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A structured regression approach for evaluating model performance across intersectional subgroups. (arXiv:2401.14893v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14893
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#32467;&#26500;&#22238;&#24402;&#26041;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#27169;&#22411;&#22312;&#19981;&#21516;&#20132;&#21449;&#23376;&#32676;&#20307;&#38388;&#30340;&#24615;&#33021;&#12290;&#23427;&#21487;&#20197;&#25552;&#20379;&#21487;&#38752;&#30340;&#31995;&#32479;&#24615;&#33021;&#20272;&#35745;&#65292;&#21363;&#20351;&#23545;&#20110;&#24456;&#23567;&#30340;&#23376;&#32676;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20154;&#24037;&#26234;&#33021;&#20844;&#24179;&#24615;&#35780;&#20272;&#20013;&#65292;&#20998;&#35299;&#24335;&#35780;&#20272;&#26159;&#19968;&#39033;&#26680;&#24515;&#20219;&#21153;&#65292;&#30446;&#26631;&#26159;&#34913;&#37327;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#22312;&#30001;&#20154;&#21475;&#32479;&#35745;&#23398;&#25110;&#20854;&#20182;&#25935;&#24863;&#23646;&#24615;&#32452;&#21512;&#23450;&#20041;&#30340;&#19981;&#21516;&#23376;&#32676;&#20307;&#20013;&#30340;&#24615;&#33021;&#12290;&#26631;&#20934;&#26041;&#27861;&#26159;&#23558;&#35780;&#20272;&#25968;&#25454;&#20998;&#23618;&#21040;&#23376;&#32676;&#20307;&#20013;&#65292;&#24182;&#20998;&#21035;&#35745;&#31639;&#27599;&#20010;&#32452;&#30340;&#24615;&#33021;&#25351;&#26631;&#12290;&#28982;&#32780;&#65292;&#21363;&#20351;&#23545;&#20110;&#20013;&#31561;&#35268;&#27169;&#30340;&#35780;&#20272;&#25968;&#25454;&#38598;&#26469;&#35828;&#65292;&#22312;&#32771;&#34385;&#21040;&#20132;&#21449;&#23376;&#32676;&#20307;&#26102;&#26679;&#26412;&#25968;&#37327;&#20063;&#20250;&#36805;&#36895;&#21464;&#23567;&#65292;&#36825;&#22823;&#22823;&#38480;&#21046;&#20102;&#35768;&#22810;&#20998;&#35299;&#35780;&#20272;&#20013;&#23545;&#20132;&#21449;&#32676;&#20307;&#30340;&#32771;&#34385;&#31243;&#24230;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#32467;&#26500;&#22238;&#24402;&#26041;&#27861;&#26469;&#36827;&#34892;&#20998;&#35299;&#35780;&#20272;&#65292;&#25105;&#20204;&#35777;&#26126;&#21363;&#20351;&#23545;&#20110;&#38750;&#24120;&#23567;&#30340;&#23376;&#32676;&#20307;&#65292;&#35813;&#26041;&#27861;&#20063;&#33021;&#20135;&#29983;&#21487;&#38752;&#30340;&#31995;&#32479;&#24615;&#33021;&#20272;&#35745;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#30456;&#24212;&#30340;&#25512;&#26029;&#31574;&#30053;&#26469;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#65292;&#24182;&#25506;&#32034;&#20102;&#25311;&#21512;&#20248;&#24230;&#27979;&#35797;&#22914;&#20309;&#25581;&#31034;&#20132;&#21449;&#23376;&#32676;&#20307;&#25152;&#32463;&#21382;&#30340;&#19982;&#20844;&#24179;&#30456;&#20851;&#30340;&#20260;&#23475;&#30340;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Disaggregated evaluation is a central task in AI fairness assessment, with the goal to measure an AI system's performance across different subgroups defined by combinations of demographic or other sensitive attributes. The standard approach is to stratify the evaluation data across subgroups and compute performance metrics separately for each group. However, even for moderately-sized evaluation datasets, sample sizes quickly get small once considering intersectional subgroups, which greatly limits the extent to which intersectional groups are considered in many disaggregated evaluations. In this work, we introduce a structured regression approach to disaggregated evaluation that we demonstrate can yield reliable system performance estimates even for very small subgroups. We also provide corresponding inference strategies for constructing confidence intervals and explore how goodness-of-fit testing can yield insight into the structure of fairness-related harms experienced by intersectio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#8220;e-process&#8221;&#21644;&#32622;&#20449;&#24207;&#21015;&#26041;&#27861;&#65292;&#20998;&#21035;&#36890;&#36807;&#26367;&#25442;Lai&#30340;&#28151;&#21512;&#26041;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#25152;&#24471;&#32467;&#26524;&#30340;&#23485;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.03722</link><description>&lt;p&gt;
&#26410;&#30693;&#26041;&#24046;&#19979;&#30340;&#39640;&#26031;&#22343;&#20540;&#30340;&#20219;&#24847;&#26377;&#25928;T&#26816;&#39564;&#21644;&#32622;&#20449;&#24207;&#21015;
&lt;/p&gt;
&lt;p&gt;
Anytime-valid t-tests and confidence sequences for Gaussian means with unknown variance. (arXiv:2310.03722v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03722
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#8220;e-process&#8221;&#21644;&#32622;&#20449;&#24207;&#21015;&#26041;&#27861;&#65292;&#20998;&#21035;&#36890;&#36807;&#26367;&#25442;Lai&#30340;&#28151;&#21512;&#26041;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#25152;&#24471;&#32467;&#26524;&#30340;&#23485;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;1976&#24180;&#65292;Lai&#26500;&#36896;&#20102;&#19968;&#20010;&#38750;&#24179;&#20961;&#30340;&#22343;&#20540;$\mu$&#30340;&#39640;&#26031;&#20998;&#24067;&#30340;&#32622;&#20449;&#24207;&#21015;&#65292;&#35813;&#20998;&#24067;&#30340;&#26041;&#24046;$\sigma$&#26159;&#26410;&#30693;&#30340;&#12290;&#20182;&#20351;&#29992;&#20102;&#20851;&#20110;$\sigma$&#30340;&#19981;&#36866;&#24403;&#65288;&#21491;Haar&#65289;&#28151;&#21512;&#21644;&#20851;&#20110;$\mu$&#30340;&#19981;&#36866;&#24403;&#65288;&#24179;&#22374;&#65289;&#28151;&#21512;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35814;&#32454;&#35828;&#26126;&#20102;&#20182;&#26500;&#24314;&#30340;&#32454;&#33410;&#65292;&#20854;&#20013;&#20351;&#29992;&#20102;&#24191;&#20041;&#30340;&#19981;&#21487;&#31215;&#20998;&#38789;&#21644;&#25193;&#23637;&#30340;&#32500;&#23572;&#19981;&#31561;&#24335;&#12290;&#23613;&#31649;&#36825;&#30830;&#23454;&#20135;&#29983;&#20102;&#19968;&#20010;&#39034;&#24207;T&#26816;&#39564;&#65292;&#20294;&#30001;&#20110;&#20182;&#30340;&#38789;&#19981;&#21487;&#31215;&#20998;&#65292;&#23427;&#24182;&#27809;&#26377;&#20135;&#29983;&#19968;&#20010;&#8220;e-process&#8221;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20026;&#30456;&#21516;&#30340;&#35774;&#32622;&#24320;&#21457;&#20102;&#20004;&#20010;&#26032;&#30340;&#8220;e-process&#8221;&#21644;&#32622;&#20449;&#24207;&#21015;&#65306;&#19968;&#20010;&#26159;&#22312;&#32553;&#20943;&#28388;&#27874;&#22120;&#20013;&#30340;&#27979;&#35797;&#38789;&#65292;&#21478;&#19968;&#20010;&#26159;&#22312;&#35268;&#33539;&#25968;&#25454;&#28388;&#27874;&#22120;&#20013;&#30340;&#8220;e-process&#8221;&#12290;&#36825;&#20123;&#20998;&#21035;&#26159;&#36890;&#36807;&#23558;Lai&#30340;&#24179;&#22374;&#28151;&#21512;&#26367;&#25442;&#20026;&#39640;&#26031;&#28151;&#21512;&#65292;&#24182;&#23558;&#23545;$\sigma$&#30340;&#21491;Haar&#28151;&#21512;&#26367;&#25442;&#20026;&#22312;&#38646;&#31354;&#38388;&#19979;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65292;&#23601;&#20687;&#22312;&#36890;&#29992;&#25512;&#26029;&#20013;&#19968;&#26679;&#12290;&#25105;&#20204;&#36824;&#20998;&#26512;&#20102;&#25152;&#24471;&#32467;&#26524;&#30340;&#23485;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
In 1976, Lai constructed a nontrivial confidence sequence for the mean $\mu$ of a Gaussian distribution with unknown variance $\sigma$. Curiously, he employed both an improper (right Haar) mixture over $\sigma$ and an improper (flat) mixture over $\mu$. Here, we elaborate carefully on the details of his construction, which use generalized nonintegrable martingales and an extended Ville's inequality. While this does yield a sequential t-test, it does not yield an ``e-process'' (due to the nonintegrability of his martingale). In this paper, we develop two new e-processes and confidence sequences for the same setting: one is a test martingale in a reduced filtration, while the other is an e-process in the canonical data filtration. These are respectively obtained by swapping Lai's flat mixture for a Gaussian mixture, and swapping the right Haar mixture over $\sigma$ with the maximum likelihood estimate under the null, as done in universal inference. We also analyze the width of resulting 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#24179;&#28369;&#38750;&#20984;&#20248;&#21270;&#20013;&#38543;&#26426;&#27425;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#36136;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#21333;&#26102;&#38388;&#23610;&#24230;&#21644;&#21452;&#26102;&#38388;&#23610;&#24230;&#24773;&#20917;&#19979;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#21253;&#25324;&#20102;&#22810;&#31181;&#24050;&#30693;&#30340;SGD&#31867;&#22411;&#26041;&#27861;&#12290;&#23545;&#20110;&#26377;&#38480;&#21644;&#24418;&#24335;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#35777;&#26126;&#20102;&#36825;&#20123;&#26041;&#27861;&#33021;&#22815;&#22312;&#38543;&#26426;&#36873;&#25321;&#30340;&#27493;&#38271;&#21644;&#21021;&#22987;&#28857;&#19978;&#25214;&#21040;Clarke&#31283;&#23450;&#28857;&#12290;</title><link>http://arxiv.org/abs/2307.10053</link><description>&lt;p&gt;
&#38750;&#24179;&#28369;&#38750;&#20984;&#20248;&#21270;&#20013;&#38543;&#26426;&#27425;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Convergence Guarantees for Stochastic Subgradient Methods in Nonsmooth Nonconvex Optimization. (arXiv:2307.10053v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10053
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#24179;&#28369;&#38750;&#20984;&#20248;&#21270;&#20013;&#38543;&#26426;&#27425;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#36136;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#21333;&#26102;&#38388;&#23610;&#24230;&#21644;&#21452;&#26102;&#38388;&#23610;&#24230;&#24773;&#20917;&#19979;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#21253;&#25324;&#20102;&#22810;&#31181;&#24050;&#30693;&#30340;SGD&#31867;&#22411;&#26041;&#27861;&#12290;&#23545;&#20110;&#26377;&#38480;&#21644;&#24418;&#24335;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#35777;&#26126;&#20102;&#36825;&#20123;&#26041;&#27861;&#33021;&#22815;&#22312;&#38543;&#26426;&#36873;&#25321;&#30340;&#27493;&#38271;&#21644;&#21021;&#22987;&#28857;&#19978;&#25214;&#21040;Clarke&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#26041;&#27861;&#21450;&#20854;&#21464;&#31181;&#22312;&#35757;&#32451;&#30001;&#38750;&#24179;&#28369;&#28608;&#27963;&#20989;&#25968;&#26500;&#24314;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#25910;&#25947;&#24615;&#36136;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#20026;&#26356;&#26032;&#21160;&#37327;&#39033;&#21644;&#21464;&#37327;&#30340;&#27493;&#38271;&#20998;&#37197;&#20102;&#19981;&#21516;&#30340;&#26102;&#38388;&#23610;&#24230;&#12290;&#22312;&#19968;&#20123;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#22312;&#21333;&#26102;&#38388;&#23610;&#24230;&#21644;&#21452;&#26102;&#38388;&#23610;&#24230;&#24773;&#20917;&#19979;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#21253;&#21547;&#20102;&#24456;&#22810;&#24050;&#30693;&#30340;SGD&#31867;&#22411;&#26041;&#27861;&#65292;&#21253;&#25324;heavy-ball SGD&#12289;SignSGD&#12289;Lion&#12289;normalized SGD&#21644;clipped SGD&#12290;&#27492;&#22806;&#65292;&#24403;&#30446;&#26631;&#20989;&#25968;&#37319;&#29992;&#26377;&#38480;&#21644;&#24418;&#24335;&#26102;&#65292;&#25105;&#20204;&#22522;&#20110;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#35777;&#26126;&#20102;&#36825;&#20123;SGD&#31867;&#22411;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#36136;&#12290;&#29305;&#21035;&#22320;&#65292;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;SGD&#31867;&#22411;&#26041;&#27861;&#22312;&#38543;&#26426;&#36873;&#25321;&#30340;&#27493;&#38271;&#21644;&#21021;&#22987;&#28857;&#19978;&#33021;&#22815;&#25214;&#21040;&#30446;&#26631;&#20989;&#25968;&#30340;Clarke&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we investigate the convergence properties of the stochastic gradient descent (SGD) method and its variants, especially in training neural networks built from nonsmooth activation functions. We develop a novel framework that assigns different timescales to stepsizes for updating the momentum terms and variables, respectively. Under mild conditions, we prove the global convergence of our proposed framework in both single-timescale and two-timescale cases. We show that our proposed framework encompasses a wide range of well-known SGD-type methods, including heavy-ball SGD, SignSGD, Lion, normalized SGD and clipped SGD. Furthermore, when the objective function adopts a finite-sum formulation, we prove the convergence properties for these SGD-type methods based on our proposed framework. In particular, we prove that these SGD-type methods find the Clarke stationary points of the objective function with randomly chosen stepsizes and initial points under mild assumptions. Preli
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23558;&#38543;&#26426;Polyak&#27493;&#38271;&#26041;&#27861;&#25193;&#23637;&#21040;&#32852;&#37030;&#23398;&#20064;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#23616;&#37096;&#33258;&#36866;&#24212;&#21644;&#20960;&#20046;&#26080;&#38656;&#35843;&#21442;&#30340;FedSPS&#21644;FedDecSPS&#21464;&#20307;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#25554;&#20540;&#26465;&#20214;&#28385;&#36275;&#26102;&#65292;FedSPS&#20197;&#32447;&#24615;&#36895;&#24230;&#25910;&#25947;&#65292;&#19968;&#33324;&#24773;&#20917;&#19979;&#25910;&#25947;&#21040;&#35299;&#30340;&#37051;&#22495;&#12290;</title><link>http://arxiv.org/abs/2307.06306</link><description>&lt;p&gt;
&#36890;&#36807;&#38543;&#26426;Polyak&#27493;&#38271;&#30340;&#23616;&#37096;&#33258;&#36866;&#24212;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Locally Adaptive Federated Learning via Stochastic Polyak Stepsizes. (arXiv:2307.06306v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06306
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#38543;&#26426;Polyak&#27493;&#38271;&#26041;&#27861;&#25193;&#23637;&#21040;&#32852;&#37030;&#23398;&#20064;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#23616;&#37096;&#33258;&#36866;&#24212;&#21644;&#20960;&#20046;&#26080;&#38656;&#35843;&#21442;&#30340;FedSPS&#21644;FedDecSPS&#21464;&#20307;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#25554;&#20540;&#26465;&#20214;&#28385;&#36275;&#26102;&#65292;FedSPS&#20197;&#32447;&#24615;&#36895;&#24230;&#25910;&#25947;&#65292;&#19968;&#33324;&#24773;&#20917;&#19979;&#25910;&#25947;&#21040;&#35299;&#30340;&#37051;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20808;&#36827;&#30340;&#32852;&#37030;&#23398;&#20064;&#31639;&#27861;&#65292;&#22914;FedAvg&#65292;&#38656;&#35201;&#31934;&#24515;&#35843;&#25972;&#30340;&#27493;&#38271;&#25165;&#33021;&#36798;&#21040;&#26368;&#20339;&#24615;&#33021;&#12290;&#29616;&#26377;&#33258;&#36866;&#24212;&#32852;&#37030;&#26041;&#27861;&#25552;&#20986;&#30340;&#25913;&#36827;&#20165;&#28041;&#21450;&#39069;&#22806;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#22914;&#21160;&#37327;&#21442;&#25968;&#65292;&#24182;&#19988;&#20165;&#32771;&#34385;&#22312;&#26381;&#21153;&#22120;&#32858;&#21512;&#36718;&#27425;&#20013;&#30340;&#36866;&#24212;&#24615;&#65292;&#32780;&#19981;&#26159;&#23616;&#37096;&#30340;&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#35768;&#22810;&#23454;&#38469;&#22330;&#26223;&#19979;&#25928;&#29575;&#20302;&#19979;&#65292;&#22240;&#20026;&#23427;&#20204;&#38656;&#35201;&#36807;&#22810;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#24182;&#19988;&#19981;&#33021;&#25429;&#25417;&#23616;&#37096;&#20960;&#20309;&#20449;&#24687;&#12290;&#26412;&#25991;&#23558;&#26368;&#36817;&#25552;&#20986;&#30340;&#38543;&#26426;Polyak&#27493;&#38271;&#26041;&#27861;&#25193;&#23637;&#21040;&#32852;&#37030;&#23398;&#20064;&#29615;&#22659;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#23616;&#37096;&#33258;&#36866;&#24212;&#21644;&#20960;&#20046;&#26080;&#38656;&#35843;&#21442;&#30340;&#20998;&#24067;&#24335;SPS&#21464;&#20307;&#65288;FedSPS&#21644;FedDecSPS&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#24403;&#25554;&#20540;&#26465;&#20214;&#65288;&#36807;&#21442;&#25968;&#21270;&#65289;&#28385;&#36275;&#26102;&#65292;FedSPS&#22312;&#24378;&#20984;&#21644;&#20984;&#35774;&#32622;&#20013;&#20197;&#32447;&#24615;&#36895;&#24230;&#25910;&#25947;&#65292;&#19968;&#33324;&#24773;&#20917;&#19979;&#25910;&#25947;&#21040;&#35299;&#30340;&#37051;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
State-of-the-art federated learning algorithms such as FedAvg require carefully tuned stepsizes to achieve their best performance. The improvements proposed by existing adaptive federated methods involve tuning of additional hyperparameters such as momentum parameters, and consider adaptivity only in the server aggregation round, but not locally. These methods can be inefficient in many practical scenarios because they require excessive tuning of hyperparameters and do not capture local geometric information. In this work, we extend the recently proposed stochastic Polyak stepsize (SPS) to the federated learning setting, and propose new locally adaptive and nearly parameter-free distributed SPS variants (FedSPS and FedDecSPS). We prove that FedSPS converges linearly in strongly convex and sublinearly in convex settings when the interpolation condition (overparametrization) is satisfied, and converges to a neighborhood of the solution in the general case. We extend our proposed method t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#31350;&#20102;&#19968;&#31181;&#21333;&#27425;&#29983;&#25104;&#27169;&#22411;&#30340;&#22810;&#26679;&#24615;&#65292;&#20027;&#35201;&#32858;&#28966;&#20110;&#23376;&#24207;&#21015;&#30456;&#20284;&#24615;&#22914;&#20309;&#24433;&#21709;&#25972;&#20010;&#24207;&#21015;&#30456;&#20284;&#24615;&#65292;&#24182;&#36890;&#36807;&#29983;&#25104;&#23376;&#24207;&#21015;&#30456;&#20284;&#30340;&#24207;&#21015;&#26469;&#22686;&#24378;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2301.08403</link><description>&lt;p&gt;
&#36890;&#36807;&#23376;&#24207;&#21015;&#30456;&#20284;&#24615;&#29983;&#25104;&#24207;&#21015;&#65306;&#29702;&#35770;&#21450;&#20854;&#22312;&#26080;&#20154;&#26426;&#35782;&#21035;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Sequence Generation via Subsequence Similarity: Theory and Application to UAV Identification. (arXiv:2301.08403v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.08403
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#31350;&#20102;&#19968;&#31181;&#21333;&#27425;&#29983;&#25104;&#27169;&#22411;&#30340;&#22810;&#26679;&#24615;&#65292;&#20027;&#35201;&#32858;&#28966;&#20110;&#23376;&#24207;&#21015;&#30456;&#20284;&#24615;&#22914;&#20309;&#24433;&#21709;&#25972;&#20010;&#24207;&#21015;&#30456;&#20284;&#24615;&#65292;&#24182;&#36890;&#36807;&#29983;&#25104;&#23376;&#24207;&#21015;&#30456;&#20284;&#30340;&#24207;&#21015;&#26469;&#22686;&#24378;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#20154;&#24037;&#21512;&#25104;&#24207;&#21015;&#30340;&#33021;&#21147;&#22312;&#24191;&#27867;&#30340;&#24212;&#29992;&#20013;&#33267;&#20851;&#37325;&#35201;&#65292;&#32780;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#21644;&#29983;&#25104;&#26694;&#26550;&#30340;&#26368;&#26032;&#36827;&#23637;&#24050;&#32463;&#26497;&#22823;&#22320;&#20419;&#36827;&#20102;&#36825;&#19968;&#36807;&#31243;&#12290;&#26412;&#25991;&#20351;&#29992;&#19968;&#31181;&#21333;&#27425;&#29983;&#25104;&#27169;&#22411;&#26469;&#37319;&#26679;&#65292;&#36890;&#36807;&#30456;&#20284;&#24615;&#29983;&#25104;&#23376;&#24207;&#21015;&#65292;&#24182;&#35777;&#26126;&#20102;&#23376;&#24207;&#21015;&#30456;&#20284;&#24615;&#23545;&#25972;&#20010;&#24207;&#21015;&#30456;&#20284;&#24615;&#30340;&#24433;&#21709;&#65292;&#32473;&#20986;&#20102;&#30456;&#24212;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#31181;&#19968;&#27425;&#24615;&#29983;&#25104;&#27169;&#22411;&#26469;&#20174;&#21333;&#20010;&#24207;&#21015;&#30340;&#33539;&#22260;&#20869;&#21462;&#26679;&#65292;&#24182;&#29983;&#25104;&#23376;&#24207;&#21015;&#30456;&#20284;&#30340;&#24207;&#21015;&#65292;&#35777;&#26126;&#20102;&#25968;&#25454;&#38598;&#22686;&#24378;&#26041;&#38754;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The ability to generate synthetic sequences is crucial for a wide range of applications, and recent advances in deep learning architectures and generative frameworks have greatly facilitated this process. Particularly, unconditional one-shot generative models constitute an attractive line of research that focuses on capturing the internal information of a single image or video to generate samples with similar contents. Since many of those one-shot models are shifting toward efficient non-deep and non-adversarial approaches, we examine the versatility of a one-shot generative model for augmenting whole datasets. In this work, we focus on how similarity at the subsequence level affects similarity at the sequence level, and derive bounds on the optimal transport of real and generated sequences based on that of corresponding subsequences. We use a one-shot generative model to sample from the vicinity of individual sequences and generate subsequence-similar ones and demonstrate the improvem
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#25968;&#25454;&#32452;&#21512;&#35299;&#20915;&#20102;&#38271;&#26399;&#27835;&#30103;&#25928;&#26524;&#35782;&#21035;&#21644;&#20272;&#35745;&#20013;&#30340;&#25345;&#32493;&#26410;&#27979;&#37327;&#28151;&#28102;&#22240;&#32032;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#19977;&#31181;&#26032;&#30340;&#35782;&#21035;&#31574;&#30053;&#21644;&#20272;&#35745;&#22120;&#12290;</title><link>http://arxiv.org/abs/2202.07234</link><description>&lt;p&gt;
&#38271;&#26399;&#25345;&#32493;&#28151;&#28102;&#24773;&#20917;&#19979;&#30340;&#22240;&#26524;&#25512;&#26029;&#19982;&#25968;&#25454;&#32452;&#21512;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Long-term Causal Inference Under Persistent Confounding via Data Combination. (arXiv:2202.07234v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.07234
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#25968;&#25454;&#32452;&#21512;&#35299;&#20915;&#20102;&#38271;&#26399;&#27835;&#30103;&#25928;&#26524;&#35782;&#21035;&#21644;&#20272;&#35745;&#20013;&#30340;&#25345;&#32493;&#26410;&#27979;&#37327;&#28151;&#28102;&#22240;&#32032;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#19977;&#31181;&#26032;&#30340;&#35782;&#21035;&#31574;&#30053;&#21644;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#24403;&#23454;&#39564;&#25968;&#25454;&#21644;&#35266;&#23519;&#25968;&#25454;&#21516;&#26102;&#23384;&#22312;&#26102;&#65292;&#38271;&#26399;&#27835;&#30103;&#25928;&#26524;&#30340;&#35782;&#21035;&#21644;&#20272;&#35745;&#38382;&#39064;&#12290;&#30001;&#20110;&#38271;&#26399;&#32467;&#26524;&#20165;&#22312;&#38271;&#26102;&#38388;&#24310;&#36831;&#21518;&#25165;&#35266;&#23519;&#21040;&#65292;&#22312;&#23454;&#39564;&#25968;&#25454;&#20013;&#26080;&#27861;&#27979;&#37327;&#65292;&#20294;&#22312;&#35266;&#23519;&#25968;&#25454;&#20013;&#26377;&#35760;&#24405;&#12290;&#28982;&#32780;&#65292;&#36825;&#20004;&#31181;&#31867;&#22411;&#30340;&#25968;&#25454;&#37117;&#21253;&#21547;&#23545;&#19968;&#20123;&#30701;&#26399;&#32467;&#26524;&#30340;&#35266;&#23519;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#29420;&#29305;&#22320;&#35299;&#20915;&#20102;&#25345;&#32493;&#26410;&#27979;&#37327;&#28151;&#28102;&#22240;&#32032;&#30340;&#25361;&#25112;&#65292;&#21363;&#19968;&#20123;&#26410;&#27979;&#37327;&#28151;&#28102;&#22240;&#32032;&#21487;&#20197;&#21516;&#26102;&#24433;&#21709;&#27835;&#30103;&#12289;&#30701;&#26399;&#32467;&#26524;&#21644;&#38271;&#26399;&#32467;&#26524;&#65292;&#32780;&#36825;&#20250;&#20351;&#24471;&#20043;&#21069;&#25991;&#29486;&#20013;&#30340;&#35782;&#21035;&#31574;&#30053;&#26080;&#25928;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#21033;&#29992;&#22810;&#20010;&#30701;&#26399;&#32467;&#26524;&#30340;&#36830;&#32493;&#32467;&#26500;&#65292;&#20026;&#24179;&#22343;&#38271;&#26399;&#27835;&#30103;&#25928;&#26524;&#25552;&#20986;&#20102;&#19977;&#31181;&#26032;&#30340;&#35782;&#21035;&#31574;&#30053;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19977;&#31181;&#23545;&#24212;&#30340;&#20272;&#35745;&#22120;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#28176;&#36817;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#20272;&#35745;&#38271;&#26399;&#27835;&#30103;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the identification and estimation of long-term treatment effects when both experimental and observational data are available. Since the long-term outcome is observed only after a long delay, it is not measured in the experimental data, but only recorded in the observational data. However, both types of data include observations of some short-term outcomes. In this paper, we uniquely tackle the challenge of persistent unmeasured confounders, i.e., some unmeasured confounders that can simultaneously affect the treatment, short-term outcomes and the long-term outcome, noting that they invalidate identification strategies in previous literature. To address this challenge, we exploit the sequential structure of multiple short-term outcomes, and develop three novel identification strategies for the average long-term treatment effect. We further propose three corresponding estimators and prove their asymptotic consistency and asymptotic normality. We finally apply our methods to esti
&lt;/p&gt;</description></item></channel></rss>