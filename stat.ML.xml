<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#30028;&#21327;&#26041;&#24046;&#24773;&#20917;&#19979;&#23398;&#20064;&#20998;&#31163;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#20351;&#29992;SQ&#31639;&#27861;&#30340;&#22797;&#26434;&#24230;&#19979;&#38480;&#20026;$d^{\Omega(1/\epsilon)}$&#12290;</title><link>http://arxiv.org/abs/2306.13057</link><description>&lt;p&gt;
&#29992;&#20110;&#23398;&#20064;&#26377;&#30028;&#21327;&#26041;&#24046;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;SQ&#19979;&#38480;
&lt;/p&gt;
&lt;p&gt;
SQ Lower Bounds for Learning Bounded Covariance GMMs. (arXiv:2306.13057v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13057
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#30028;&#21327;&#26041;&#24046;&#24773;&#20917;&#19979;&#23398;&#20064;&#20998;&#31163;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#20351;&#29992;SQ&#31639;&#27861;&#30340;&#22797;&#26434;&#24230;&#19979;&#38480;&#20026;$d^{\Omega(1/\epsilon)}$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#30456;&#21516;&#26410;&#30693;&#26377;&#30028;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20998;&#31163;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#22797;&#26434;&#24615;&#12290; &#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#20851;&#27880;&#24418;&#24335;&#20026;$P = \sum_{i=1}^k w_i \mathcal{N}(\boldsymbol \mu_i,\mathbf \Sigma_i)$&#30340;$\mathbb{R}^d$&#19978;&#30340;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65288;GMMs&#65289;&#65292;&#20854;&#20013;$\mathbf \Sigma_i = \mathbf \Sigma \preceq \mathbf I$&#19988;$\min_{i \neq j} \| \boldsymbol \mu_i \boldsymbol \mu_j\|_2 \geq k^\epsilon$&#23545;&#20110;&#26576;&#20123;$\epsilon&gt; 0$&#12290;&#24050;&#30693;&#30340;&#23398;&#20064;&#31639;&#27861;&#30340;&#22797;&#26434;&#24230;&#20026;$(dk)^{O(1/\epsilon)}$&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20219;&#20309;&#29992;&#20110;&#27492;&#38382;&#39064;&#30340;&#32479;&#35745;&#26597;&#35810;&#65288;SQ&#65289;&#31639;&#27861;&#30340;&#22797;&#26434;&#24230;&#33267;&#23569;&#38656;&#35201;$d^{\Omega(1/\epsilon)}$&#12290;&#24403;&#20998;&#31163;&#22312;$k^{1/2}$&#25968;&#37327;&#32423;&#19978;&#26102;&#65292;&#25105;&#20204;&#21478;&#22806;&#33719;&#24471;&#20102;&#20855;&#26377;&#27491;&#30830;&#25351;&#25968;&#30340;&#32454;&#31890;&#24230;SQ&#19979;&#38480;&#12290;&#25105;&#20204;&#30340;SQ&#19979;&#38480;&#24847;&#21619;&#30528;&#20302;&#27425;&#22810;&#39033;&#24335;&#27979;&#35797;&#30340;&#31867;&#20284;&#19979;&#38480;&#12290;&#20174;&#27010;&#24565;&#19978;&#35762;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#24050;&#30693;&#31639;&#27861;&#20960;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the complexity of learning mixtures of separated Gaussians with common unknown bounded covariance matrix. Specifically, we focus on learning Gaussian mixture models (GMMs) on $\mathbb{R}^d$ of the form $P= \sum_{i=1}^k w_i \mathcal{N}(\boldsymbol \mu_i,\mathbf \Sigma_i)$, where $\mathbf \Sigma_i = \mathbf \Sigma \preceq \mathbf I$ and $\min_{i \neq j} \| \boldsymbol \mu_i \boldsymbol \mu_j\|_2 \geq k^\epsilon$ for some $\epsilon&gt;0$. Known learning algorithms for this family of GMMs have complexity $(dk)^{O(1/\epsilon)}$. In this work, we prove that any Statistical Query (SQ) algorithm for this problem requires complexity at least $d^{\Omega(1/\epsilon)}$. In the special case where the separation is on the order of $k^{1/2}$, we additionally obtain fine-grained SQ lower bounds with the correct exponent. Our SQ lower bounds imply similar lower bounds for low-degree polynomial tests. Conceptually, our results provide evidence that known algorithms for this problem are nearly be
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#20108;&#20998;&#29420;&#31435;&#24615;&#65292;&#21033;&#29992;i.i.d.&#27491;&#24577;&#20998;&#24067;&#25968;&#25454;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;&#26368;&#31934;&#32454;&#30340;&#20114;&#30456;&#29420;&#31435;&#27169;&#24335;&#65292;&#24182;&#22312;&#27169;&#25311;&#25968;&#25454;&#21644;&#23454;&#39564;&#25968;&#25454;&#19978;&#36827;&#34892;&#27979;&#35797;&#12290;</title><link>http://arxiv.org/abs/2306.12984</link><description>&lt;p&gt;
&#20174;&#25968;&#25454;&#20013;&#25512;&#26029;&#26368;&#31934;&#32454;&#30340;&#20114;&#30456;&#29420;&#31435;&#27169;&#24335;
&lt;/p&gt;
&lt;p&gt;
Inferring the finest pattern of mutual independence from data. (arXiv:2306.12984v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12984
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#20108;&#20998;&#29420;&#31435;&#24615;&#65292;&#21033;&#29992;i.i.d.&#27491;&#24577;&#20998;&#24067;&#25968;&#25454;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;&#26368;&#31934;&#32454;&#30340;&#20114;&#30456;&#29420;&#31435;&#27169;&#24335;&#65292;&#24182;&#22312;&#27169;&#25311;&#25968;&#25454;&#21644;&#23454;&#39564;&#25968;&#25454;&#19978;&#36827;&#34892;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#38543;&#26426;&#21464;&#37327;X&#65292;&#25105;&#20204;&#23545;&#20854;&#26368;&#31934;&#32454;&#30340;&#20114;&#30456;&#29420;&#31435;&#27169;&#24335;&#956;(X)&#30340;&#30450;&#30446;&#25552;&#21462;&#24863;&#20852;&#36259;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#29305;&#23450;&#30340;&#29420;&#31435;&#24615;&#65292;&#31216;&#20026;&#20108;&#20998;&#30340;&#29420;&#31435;&#24615;&#12290;&#22914;&#26524;&#916;(X)&#20195;&#34920;&#25152;&#26377;&#36866;&#29992;&#20110;X&#30340;&#20108;&#20998;&#29420;&#31435;&#24615;&#27169;&#24335;&#38598;&#65292;&#21017;&#25105;&#20204;&#35777;&#26126;&#956;(X)&#21487;&#20197;&#20316;&#20026;&#916;(X)&#30340;&#25152;&#26377;&#20803;&#32032;&#30340;&#20132;&#38598;&#26469;&#33719;&#24471;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22312;&#25968;&#25454;&#29420;&#31435;&#19988;&#26381;&#20174;&#22810;&#20803;&#27491;&#24577;&#20998;&#24067;&#30340;&#26465;&#20214;&#19979;&#65292;&#20272;&#35745;&#916;(X)&#12290;&#22914;&#26524;^&#916;(X)&#26159;&#26377;&#25928;&#30340;&#20108;&#20998;&#29420;&#31435;&#27169;&#24335;&#30340;&#20272;&#35745;&#38598;&#65292;&#21017;&#25105;&#20204;&#23558;&#956;(X)&#20272;&#35745;&#20026;^&#916;(X)&#30340;&#25152;&#26377;&#27169;&#24335;&#30340;&#20132;&#38598;&#12290;&#35813;&#26041;&#27861;&#22312;&#27169;&#25311;&#25968;&#25454;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#34920;&#26126;&#20102;&#20854;&#20248;&#28857;&#21644;&#23616;&#38480;&#24615;&#12290;&#25105;&#20204;&#36824;&#32771;&#34385;&#20102;&#19968;&#20010;&#29609;&#20855;&#20363;&#23376;&#21644;&#23454;&#39564;&#25968;&#25454;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
For a random variable $X$, we are interested in the blind extraction of its finest mutual independence pattern $\mu ( X )$. We introduce a specific kind of independence that we call dichotomic. If $\Delta ( X )$ stands for the set of all patterns of dichotomic independence that hold for $X$, we show that $\mu ( X )$ can be obtained as the intersection of all elements of $\Delta ( X )$. We then propose a method to estimate $\Delta ( X )$ when the data are independent and identically (i.i.d.) realizations of a multivariate normal distribution. If $\hat{\Delta} ( X )$ is the estimated set of valid patterns of dichotomic independence, we estimate $\mu ( X )$ as the intersection of all patterns of $\hat{\Delta} ( X )$. The method is tested on simulated data, showing its advantages and limits. We also consider an application to a toy example as well as to experimental data.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21517;&#20026;&#23454;&#20363;&#33258;&#36866;&#24212;&#32858;&#31867;&#65288;IAC&#65289;&#65292;&#23427;&#33021;&#22815;&#22312;&#26631;&#35760;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;LSBM&#65289;&#20013;&#24674;&#22797;&#38544;&#34255;&#30340;&#32676;&#38598;&#12290;IAC&#21253;&#25324;&#19968;&#27425;&#35889;&#32858;&#31867;&#21644;&#19968;&#20010;&#36845;&#20195;&#30340;&#22522;&#20110;&#20284;&#28982;&#30340;&#31751;&#20998;&#37197;&#25913;&#36827;&#65292;&#19981;&#38656;&#35201;&#20219;&#20309;&#27169;&#22411;&#21442;&#25968;&#65292;&#26159;&#39640;&#25928;&#30340;&#12290;</title><link>http://arxiv.org/abs/2306.12968</link><description>&lt;p&gt;
&#26631;&#35760;&#38543;&#26426;&#22359;&#27169;&#22411;&#20013;&#30340;&#26368;&#20248;&#31751;&#24674;&#22797;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Instance-Optimal Cluster Recovery in the Labeled Stochastic Block Model. (arXiv:2306.12968v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12968
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21517;&#20026;&#23454;&#20363;&#33258;&#36866;&#24212;&#32858;&#31867;&#65288;IAC&#65289;&#65292;&#23427;&#33021;&#22815;&#22312;&#26631;&#35760;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;LSBM&#65289;&#20013;&#24674;&#22797;&#38544;&#34255;&#30340;&#32676;&#38598;&#12290;IAC&#21253;&#25324;&#19968;&#27425;&#35889;&#32858;&#31867;&#21644;&#19968;&#20010;&#36845;&#20195;&#30340;&#22522;&#20110;&#20284;&#28982;&#30340;&#31751;&#20998;&#37197;&#25913;&#36827;&#65292;&#19981;&#38656;&#35201;&#20219;&#20309;&#27169;&#22411;&#21442;&#25968;&#65292;&#26159;&#39640;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#26377;&#38480;&#25968;&#37327;&#30340;&#31751;&#30340;&#24773;&#20917;&#19979;&#65292;&#29992;&#26631;&#35760;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;LSBM&#65289;&#24674;&#22797;&#38544;&#34255;&#30340;&#31038;&#32676;&#65292;&#20854;&#20013;&#31751;&#22823;&#23567;&#38543;&#30528;&#29289;&#21697;&#24635;&#25968;$n$&#30340;&#22686;&#38271;&#32780;&#32447;&#24615;&#22686;&#38271;&#12290;&#22312;LSBM&#20013;&#65292;&#20026;&#27599;&#23545;&#29289;&#21697;&#65288;&#29420;&#31435;&#22320;&#65289;&#35266;&#27979;&#21040;&#19968;&#20010;&#26631;&#31614;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#35774;&#35745;&#19968;&#31181;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#21033;&#29992;&#35266;&#27979;&#21040;&#30340;&#26631;&#31614;&#26469;&#24674;&#22797;&#31751;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#20851;&#20110;&#26399;&#26395;&#34987;&#20219;&#20309;&#32858;&#31867;&#31639;&#27861;&#35823;&#20998;&#31867;&#30340;&#29289;&#21697;&#25968;&#37327;&#30340;&#23454;&#20363;&#29305;&#23450;&#19979;&#30028;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#23454;&#20363;&#33258;&#36866;&#24212;&#32858;&#31867;&#65288;IAC&#65289;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#26399;&#26395;&#21644;&#39640;&#27010;&#29575;&#19979;&#37117;&#33021;&#21305;&#37197;&#36825;&#20123;&#19979;&#30028;&#34920;&#29616;&#30340;&#31639;&#27861;&#12290;IAC&#30001;&#19968;&#27425;&#35889;&#32858;&#31867;&#31639;&#27861;&#21644;&#19968;&#20010;&#36845;&#20195;&#30340;&#22522;&#20110;&#20284;&#28982;&#30340;&#31751;&#20998;&#37197;&#25913;&#36827;&#32452;&#25104;&#12290;&#36825;&#31181;&#26041;&#27861;&#22522;&#20110;&#23454;&#20363;&#29305;&#23450;&#30340;&#19979;&#30028;&#65292;&#19981;&#38656;&#35201;&#20219;&#20309;&#27169;&#22411;&#21442;&#25968;&#65292;&#21253;&#25324;&#31751;&#30340;&#25968;&#37327;&#12290;&#36890;&#36807;&#20165;&#25191;&#34892;&#19968;&#27425;&#35889;&#32858;&#31867;&#65292;IAC&#22312;&#35745;&#31639;&#21644;&#23384;&#20648;&#26041;&#38754;&#37117;&#26159;&#39640;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of recovering hidden communities in the Labeled Stochastic Block Model (LSBM) with a finite number of clusters, where cluster sizes grow linearly with the total number $n$ of items. In the LSBM, a label is (independently) observed for each pair of items. Our objective is to devise an efficient algorithm that recovers clusters using the observed labels. To this end, we revisit instance-specific lower bounds on the expected number of misclassified items satisfied by any clustering algorithm. We present Instance-Adaptive Clustering (IAC), the first algorithm whose performance matches these lower bounds both in expectation and with high probability. IAC consists of a one-time spectral clustering algorithm followed by an iterative likelihood-based cluster assignment improvement. This approach is based on the instance-specific lower bound and does not require any model parameters, including the number of clusters. By performing the spectral clustering only once, IAC m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#20869;&#31215;&#26469;&#20272;&#35745;&#22810;&#20803;&#21644;&#22810;&#32500;&#20989;&#25968;&#25968;&#25454;&#38598;&#30340;&#29305;&#24449;&#21521;&#37327;&#65292;&#20026;&#20989;&#25968;&#20027;&#25104;&#20998;&#20998;&#26512;&#25552;&#20379;&#20102;&#26032;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.12949</link><description>&lt;p&gt;
&#20851;&#20110;&#20351;&#29992;&#26684;&#25289;&#22982;&#30697;&#38453;&#36827;&#34892;&#22810;&#20803;&#20989;&#25968;&#20027;&#25104;&#20998;&#20998;&#26512;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the use of the Gram matrix for multivariate functional principal components analysis. (arXiv:2306.12949v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12949
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#20869;&#31215;&#26469;&#20272;&#35745;&#22810;&#20803;&#21644;&#22810;&#32500;&#20989;&#25968;&#25968;&#25454;&#38598;&#30340;&#29305;&#24449;&#21521;&#37327;&#65292;&#20026;&#20989;&#25968;&#20027;&#25104;&#20998;&#20998;&#26512;&#25552;&#20379;&#20102;&#26032;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#20013;&#65292;&#38477;&#32500;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#38477;&#32500;&#30340;&#20851;&#38190;&#24037;&#20855;&#26159;&#20989;&#25968;&#20027;&#25104;&#20998;&#20998;&#26512;&#12290;&#29616;&#26377;&#30340;&#20989;&#25968;&#20027;&#25104;&#20998;&#20998;&#26512;&#26041;&#27861;&#36890;&#24120;&#28041;&#21450;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#23545;&#35282;&#21270;&#12290;&#38543;&#30528;&#20989;&#25968;&#25968;&#25454;&#38598;&#30340;&#35268;&#27169;&#21644;&#22797;&#26434;&#24615;&#22686;&#21152;&#65292;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20272;&#35745;&#21464;&#24471;&#26356;&#21152;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22240;&#27492;&#65292;&#38656;&#35201;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#29305;&#24449;&#21521;&#37327;&#12290;&#22522;&#20110;&#35266;&#27979;&#31354;&#38388;&#21644;&#20989;&#25968;&#29305;&#24449;&#31354;&#38388;&#30340;&#23545;&#20598;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#26354;&#32447;&#20043;&#38388;&#30340;&#20869;&#31215;&#26469;&#20272;&#35745;&#22810;&#20803;&#21644;&#22810;&#32500;&#20989;&#25968;&#25968;&#25454;&#38598;&#30340;&#29305;&#24449;&#21521;&#37327;&#12290;&#24314;&#31435;&#20102;&#21327;&#26041;&#24046;&#30697;&#38453;&#29305;&#24449;&#21521;&#37327;&#21644;&#20869;&#31215;&#30697;&#38453;&#29305;&#24449;&#21521;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#36825;&#20123;&#26041;&#27861;&#22312;&#20960;&#20010;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#35774;&#32622;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#25552;&#20379;&#20102;&#23427;&#20204;&#30340;&#36890;&#29992;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dimension reduction is crucial in functional data analysis (FDA). The key tool to reduce the dimension of the data is functional principal component analysis. Existing approaches for functional principal component analysis usually involve the diagonalization of the covariance operator. With the increasing size and complexity of functional datasets, estimating the covariance operator has become more challenging. Therefore, there is a growing need for efficient methodologies to estimate the eigencomponents. Using the duality of the space of observations and the space of functional features, we propose to use the inner-product between the curves to estimate the eigenelements of multivariate and multidimensional functional datasets. The relationship between the eigenelements of the covariance operator and those of the inner-product matrix is established. We explore the application of these methodologies in several FDA settings and provide general guidance on their usability.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36827;&#21270;&#35745;&#31639;&#22270;&#31639;&#27861;&#65288;ECGs&#65289;&#65292;&#29992;&#20110;&#25552;&#39640;&#38024;&#23545;&#24322;&#36136;&#24615;&#25968;&#25454;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#24615;&#33021;&#65292;&#36890;&#36807;&#37325;&#36830;GNN&#30340;&#35745;&#31639;&#22270;&#22686;&#21152;&#36830;&#25509;&#21516;&#19968;&#31867;&#33410;&#28857;&#30340;&#36793;&#32536;&#20197;&#25552;&#21319;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.12943</link><description>&lt;p&gt;
&#36827;&#21270;&#35745;&#31639;&#22270;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Evolving Computation Graphs. (arXiv:2306.12943v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12943
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36827;&#21270;&#35745;&#31639;&#22270;&#31639;&#27861;&#65288;ECGs&#65289;&#65292;&#29992;&#20110;&#25552;&#39640;&#38024;&#23545;&#24322;&#36136;&#24615;&#25968;&#25454;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#24615;&#33021;&#65292;&#36890;&#36807;&#37325;&#36830;GNN&#30340;&#35745;&#31639;&#22270;&#22686;&#21152;&#36830;&#25509;&#21516;&#19968;&#31867;&#33410;&#28857;&#30340;&#36793;&#32536;&#20197;&#25552;&#21319;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20851;&#31995;&#25968;&#25454;&#24314;&#27169;&#26041;&#38754;&#65292;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#24050;&#32463;&#23637;&#29616;&#20986;&#20102;&#25104;&#21151;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#37027;&#20123;&#34920;&#29616;&#20986;&#21516;&#36136;&#24615;&#30340;&#25968;&#25454;&#65306;&#24403;&#33410;&#28857;&#20043;&#38388;&#30340;&#36830;&#25509;&#24448;&#24448;&#26263;&#31034;&#23427;&#20204;&#23646;&#20110;&#21516;&#19968;&#31867;&#26102;&#65292;&#36825;&#19968;&#28857;&#26356;&#20026;&#26126;&#26174;&#12290;&#28982;&#32780;&#65292;&#34429;&#28982;&#36825;&#20010;&#20551;&#35774;&#22312;&#35768;&#22810;&#30456;&#20851;&#24773;&#20917;&#19979;&#26159;&#25104;&#31435;&#30340;&#65292;&#20294;&#22312;&#37325;&#35201;&#30340;&#29616;&#23454;&#22330;&#26223;&#20013;&#20063;&#26377;&#36829;&#21453;&#36825;&#20010;&#20551;&#35774;&#30340;&#24773;&#20917;&#65292;&#36825;&#20419;&#36827;&#20102;&#23545;GNN&#22312;&#36825;&#20123;&#24773;&#20917;&#19979;&#36827;&#34892;&#25913;&#36827;&#30340;&#30740;&#31350;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#8212;&#8212;&#36827;&#21270;&#35745;&#31639;&#22270;&#31639;&#27861;&#65288;ECGs&#65289;&#65292;&#29992;&#20110;&#22686;&#24378;&#38024;&#23545;&#24322;&#36136;&#24615;&#25968;&#25454;&#30340;GNN&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#24314;&#31435;&#22312;&#20808;&#21069;&#30340;&#29702;&#35770;&#27934;&#35265;&#20043;&#19978;&#65292;&#23558;&#33410;&#28857;&#24230;&#12289;&#39640;&#21516;&#36136;&#24615;&#21644;&#20869;&#37096;&#19982;&#31867;&#38388;&#23884;&#20837;&#30456;&#20284;&#24615;&#32852;&#31995;&#22312;&#19968;&#36215;&#65292;&#36890;&#36807;&#37325;&#36830;GNN&#30340;&#35745;&#31639;&#22270;&#26469;&#22686;&#21152;&#36830;&#25509;&#21516;&#19968;&#31867;&#33410;&#28857;&#30340;&#36793;&#32536;&#12290;&#25105;&#20204;&#21033;&#29992;&#36739;&#24369;&#30340;&#20998;&#31867;&#22120;&#26469;&#35782;&#21035;&#36825;&#20123;&#36793;&#32536;&#65292;&#20174;&#32780;&#26368;&#32456;&#25552;&#39640;&#20102;GNN&#23545;&#38750;&#21516;&#36136;&#24615;&#25968;&#25454;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#35780;&#20272;ECGs&#22312;&#19968;&#32452;&#22810;&#26679;&#21270;&#30340;&#26368;&#36817;&#25552;&#20986;&#30340;&#24322;&#36136;&#25968;&#25454;&#38598;&#19978;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks (GNNs) have demonstrated success in modeling relational data, especially for data that exhibits homophily: when a connection between nodes tends to imply that they belong to the same class. However, while this assumption is true in many relevant situations, there are important real-world scenarios that violate this assumption, and this has spurred research into improving GNNs for these cases. In this work, we propose Evolving Computation Graphs (ECGs), a novel method for enhancing GNNs on heterophilic datasets. Our approach builds on prior theoretical insights linking node degree, high homophily, and inter vs intra-class embedding similarity by rewiring the GNNs' computation graph towards adding edges that connect nodes that are likely to be in the same class. We utilise weaker classifiers to identify these edges, ultimately improving GNN performance on non-homophilic data as a result. We evaluate ECGs on a diverse set of recently-proposed heterophilous datasets a
&lt;/p&gt;</description></item><item><title>AudioPaLM&#26159;&#19968;&#27454;&#33021;&#22815;&#26356;&#22909;&#22320;&#22788;&#29702;&#35821;&#38899;&#20219;&#21153;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#23427;&#32487;&#25215;&#20102;AudioLM&#30340;&#35821;&#38899;&#36523;&#20221;&#21644;&#35821;&#35843;&#20449;&#24687;&#20445;&#30041;&#33021;&#21147;&#20197;&#21450;PaLM-2&#30340;&#35821;&#35328;&#30693;&#35782;&#65292;&#21487;&#29992;&#20110;&#35821;&#38899;&#35782;&#21035;&#12289;&#35821;&#38899;&#32763;&#35793;&#31561;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2306.12925</link><description>&lt;p&gt;
AudioPaLM&#65306;&#19968;&#27454;&#33021;&#35828;&#20250;&#21548;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
AudioPaLM: A Large Language Model That Can Speak and Listen. (arXiv:2306.12925v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12925
&lt;/p&gt;
&lt;p&gt;
AudioPaLM&#26159;&#19968;&#27454;&#33021;&#22815;&#26356;&#22909;&#22320;&#22788;&#29702;&#35821;&#38899;&#20219;&#21153;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#23427;&#32487;&#25215;&#20102;AudioLM&#30340;&#35821;&#38899;&#36523;&#20221;&#21644;&#35821;&#35843;&#20449;&#24687;&#20445;&#30041;&#33021;&#21147;&#20197;&#21450;PaLM-2&#30340;&#35821;&#35328;&#30693;&#35782;&#65292;&#21487;&#29992;&#20110;&#35821;&#38899;&#35782;&#21035;&#12289;&#35821;&#38899;&#32763;&#35793;&#31561;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#35821;&#38899;&#29702;&#35299;&#21644;&#29983;&#25104;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#8212;&#8212;AudioPaLM&#12290;&#23427;&#23558;&#22522;&#20110;&#25991;&#26412;&#30340;&#35821;&#35328;&#27169;&#22411;PaLM-2[Anil&#31561;&#20154;&#65292;2023]&#21644;&#22522;&#20110;&#38899;&#39057;&#30340;&#35821;&#35328;&#27169;&#22411;AudioLM[Borsos&#31561;&#20154;&#65292;2022]&#32467;&#21512;&#25104;&#19968;&#20010;&#32479;&#19968;&#30340;&#22810;&#27169;&#24577;&#32467;&#26500;&#65292;&#21487;&#20197;&#22788;&#29702;&#21644;&#29983;&#25104;&#25991;&#26412;&#21644;&#35821;&#38899;&#65292;&#21253;&#25324;&#35821;&#38899;&#35782;&#21035;&#21644;&#35821;&#38899;&#32763;&#35793;&#31561;&#24212;&#29992;&#12290;AudioPaLM&#32487;&#25215;&#20102;&#20174;AudioLM&#20013;&#20445;&#30041;&#35821;&#38899;&#21457;&#38899;&#32773;&#36523;&#20221;&#21644;&#35821;&#35843;&#31561;&#30340;&#33021;&#21147;&#65292;&#20197;&#21450;&#21482;&#23384;&#22312;&#20110;&#25991;&#26412;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;PaLM-2&#20013;&#30340;&#35821;&#35328;&#30693;&#35782;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#36890;&#36807;&#20351;&#29992;&#25991;&#26412;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26435;&#37325;&#36827;&#34892;&#21021;&#22987;&#21270;&#65292;&#21487;&#20197;&#25913;&#21892;&#35821;&#38899;&#22788;&#29702;&#65292;&#25104;&#21151;&#22320;&#21033;&#29992;&#20102;&#39044;&#35757;&#32451;&#20013;&#20351;&#29992;&#30340;&#26356;&#22823;&#37327;&#30340;&#25991;&#26412;&#35757;&#32451;&#25968;&#25454;&#26469;&#21327;&#21161;&#35821;&#38899;&#20219;&#21153;&#12290;&#26368;&#32456;&#24471;&#21040;&#30340;&#27169;&#22411;&#22312;&#35821;&#38899;&#32763;&#35793;&#20219;&#21153;&#20013;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#31995;&#32479;&#65292;&#24182;&#19988;&#20855;&#26377;&#36827;&#34892;&#38646;-shot&#35328;&#35821;&#25991;&#26412;&#36716;&#25442;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce AudioPaLM, a large language model for speech understanding and generation. AudioPaLM fuses text-based and speech-based language models, PaLM-2 [Anil et al., 2023] and AudioLM [Borsos et al., 2022], into a unified multimodal architecture that can process and generate text and speech with applications including speech recognition and speech-to-speech translation. AudioPaLM inherits the capability to preserve paralinguistic information such as speaker identity and intonation from AudioLM and the linguistic knowledge present only in text large language models such as PaLM-2. We demonstrate that initializing AudioPaLM with the weights of a text-only large language model improves speech processing, successfully leveraging the larger quantity of text training data used in pretraining to assist with the speech tasks. The resulting model significantly outperforms existing systems for speech translation tasks and has the ability to perform zero-shot speech-to-text translation for ma
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#20445;&#38505;&#19994;&#20381;&#36182;&#20010;&#20154;&#25935;&#24863;&#29305;&#24449;&#39044;&#27979;&#39118;&#38505;&#23481;&#26131;&#36896;&#25104;&#27495;&#35270;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20351;&#29992;Wasserstein&#37325;&#24515;&#32531;&#35299;&#20559;&#35265;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.12912</link><description>&lt;p&gt;
&#20351;&#29992;Wasserstein&#37325;&#24515;&#32531;&#35299;&#20445;&#38505;&#20013;&#30340;&#27495;&#35270;
&lt;/p&gt;
&lt;p&gt;
Mitigating Discrimination in Insurance with Wasserstein Barycenters. (arXiv:2306.12912v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12912
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#20445;&#38505;&#19994;&#20381;&#36182;&#20010;&#20154;&#25935;&#24863;&#29305;&#24449;&#39044;&#27979;&#39118;&#38505;&#23481;&#26131;&#36896;&#25104;&#27495;&#35270;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20351;&#29992;Wasserstein&#37325;&#24515;&#32531;&#35299;&#20559;&#35265;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20445;&#38505;&#19994;&#20005;&#37325;&#20381;&#36182;&#20110;&#26681;&#25454;&#28508;&#22312;&#23458;&#25143;&#30340;&#29305;&#24449;&#39044;&#27979;&#39118;&#38505;&#30340;&#27169;&#22411;&#12290;&#34429;&#28982;&#36825;&#26679;&#30340;&#27169;&#22411;&#24456;&#24120;&#35265;&#65292;&#20294;&#30740;&#31350;&#20154;&#21592;&#38271;&#26399;&#20197;&#26469;&#19968;&#30452;&#25351;&#20986;&#65292;&#36825;&#31181;&#20570;&#27861;&#20250;&#22240;&#22522;&#20110;&#25935;&#24863;&#29305;&#24449;&#65288;&#22914;&#24615;&#21035;&#25110;&#31181;&#26063;&#65289;&#32780;&#20135;&#29983;&#27495;&#35270;&#12290;&#37492;&#20110;&#36825;&#31181;&#27495;&#35270;&#36890;&#24120;&#21487;&#20197;&#24402;&#22240;&#20110;&#21382;&#21490;&#25968;&#25454;&#20559;&#35265;&#65292;&#22240;&#27492;&#28040;&#38500;&#25110;&#33267;&#23569;&#32531;&#35299;&#27495;&#35270;&#26159;&#21487;&#21462;&#30340;&#12290;&#38543;&#30528;&#20174;&#26356;&#20256;&#32479;&#30340;&#27169;&#22411;&#36716;&#21521;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#39044;&#27979;&#65292;&#23545;&#26356;&#22823;&#30340;&#32531;&#35299;&#21628;&#22768;&#20063;&#22312;&#22686;&#21152;&#65292;&#22240;&#20026;&#20165;&#20165;&#25490;&#38500;&#20215;&#26684;&#36807;&#31243;&#20013;&#30340;&#25935;&#24863;&#21464;&#37327;&#34987;&#35777;&#26126;&#26159;&#26080;&#25928;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#30740;&#31350;&#20026;&#20160;&#20040;&#39044;&#27979;&#22312;&#34892;&#19994;&#20869;&#26159;&#24517;&#35201;&#30340;&#65292;&#20197;&#21450;&#20026;&#20160;&#20040;&#32416;&#27491;&#20559;&#35265;&#24182;&#19981;&#20687;&#31616;&#21333;&#22320;&#35782;&#21035;&#25935;&#24863;&#21464;&#37327;&#37027;&#20040;&#30452;&#25509;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;Wasserstein&#37325;&#24515;&#26469;&#32531;&#35299;&#20559;&#35265;&#65292;&#32780;&#19981;&#26159;&#31616;&#21333;&#22320;&#32553;&#25918;&#12290;&#20026;&#20102;&#23637;&#31034;&#36825;&#31181;&#26041;&#27861;&#30340;&#25928;&#26524;&#21644;&#26377;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;
The insurance industry is heavily reliant on predictions of risks based on characteristics of potential customers. Although the use of said models is common, researchers have long pointed out that such practices perpetuate discrimination based on sensitive features such as gender or race. Given that such discrimination can often be attributed to historical data biases, an elimination or at least mitigation is desirable. With the shift from more traditional models to machine-learning based predictions, calls for greater mitigation have grown anew, as simply excluding sensitive variables in the pricing process can be shown to be ineffective. In this article, we first investigate why predictions are a necessity within the industry and why correcting biases is not as straightforward as simply identifying a sensitive variable. We then propose to ease the biases through the use of Wasserstein barycenters instead of simple scaling. To demonstrate the effects and effectiveness of the approach 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#23545;&#20110;&#20855;&#26377;&#23616;&#37096;&#21487;&#21464;&#27979;&#37327;&#23610;&#24230;&#30340;&#38543;&#26426;&#21464;&#37327;&#30340;&#24191;&#20041;&#38543;&#26426;&#20248;&#21183;&#65288;GSD&#65289;&#39034;&#24207;&#65292;&#24182;&#36890;&#36807;&#32447;&#24615;&#20248;&#21270;&#21644;&#19981;&#31934;&#30830;&#27010;&#29575;&#27169;&#22411;&#25552;&#20986;&#20102;&#27491;&#21017;&#21270;&#30340;&#32479;&#35745;&#26816;&#39564;&#65292;&#35299;&#20915;&#20102;&#22312;&#36825;&#20123;&#38750;&#26631;&#20934;&#31354;&#38388;&#20013;&#22914;&#20309;&#27491;&#30830;&#21033;&#29992;&#20840;&#37096;&#20449;&#24687;&#26469;&#36827;&#34892;&#27604;&#36739;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.12803</link><description>&lt;p&gt;
&#20855;&#26377;&#23616;&#37096;&#21487;&#21464;&#27979;&#37327;&#23610;&#24230;&#30340;&#38543;&#26426;&#21464;&#37327;&#30340;&#40065;&#26834;&#32479;&#35745;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Robust Statistical Comparison of Random Variables with Locally Varying Scale of Measurement. (arXiv:2306.12803v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12803
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#23545;&#20110;&#20855;&#26377;&#23616;&#37096;&#21487;&#21464;&#27979;&#37327;&#23610;&#24230;&#30340;&#38543;&#26426;&#21464;&#37327;&#30340;&#24191;&#20041;&#38543;&#26426;&#20248;&#21183;&#65288;GSD&#65289;&#39034;&#24207;&#65292;&#24182;&#36890;&#36807;&#32447;&#24615;&#20248;&#21270;&#21644;&#19981;&#31934;&#30830;&#27010;&#29575;&#27169;&#22411;&#25552;&#20986;&#20102;&#27491;&#21017;&#21270;&#30340;&#32479;&#35745;&#26816;&#39564;&#65292;&#35299;&#20915;&#20102;&#22312;&#36825;&#20123;&#38750;&#26631;&#20934;&#31354;&#38388;&#20013;&#22914;&#20309;&#27491;&#30830;&#21033;&#29992;&#20840;&#37096;&#20449;&#24687;&#26469;&#36827;&#34892;&#27604;&#36739;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20855;&#26377;&#23616;&#37096;&#21487;&#21464;&#27979;&#37327;&#23610;&#24230;&#30340;&#31354;&#38388;&#65292;&#22312;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#26159;&#30456;&#24403;&#26222;&#36941;&#30340;&#65292;&#27604;&#22914;&#35828;&#65292;&#20855;&#26377;&#19981;&#21516;&#32553;&#25918;&#32500;&#24230;&#30340;&#22810;&#32500;&#32467;&#26500;&#12290;&#28982;&#32780;&#65292;&#22914;&#20309;&#27491;&#30830;&#22320;&#21033;&#29992;&#36825;&#20123;&#31354;&#38388;&#20013;&#32534;&#30721;&#30340;&#20840;&#37096;&#20449;&#24687;&#65292;&#20173;&#28982;&#34987;&#35748;&#20026;&#26159;&#19968;&#20010;&#24320;&#25918;&#24615;&#38382;&#39064;&#12290;&#25105;&#20204;&#36890;&#36807;&#32771;&#34385;&#19968;&#20010;&#22522;&#20110;&#38543;&#26426;&#21464;&#37327;&#26399;&#26395;&#30340;&#65288;&#38598;&#21512;&#65289;&#20559;&#24207;&#20851;&#31995;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#36825;&#20123;&#38543;&#26426;&#21464;&#37327;&#26144;&#23556;&#21040;&#36825;&#20123;&#38750;&#26631;&#20934;&#31354;&#38388;&#20013;&#12290;&#24403;&#27809;&#26377;&#25110;&#23436;&#20840;&#30340;&#22522;&#25968;&#32467;&#26500;&#26102;&#65292;&#36825;&#20010;&#20559;&#24207;&#20851;&#31995;&#21253;&#21547;&#38543;&#26426;&#20248;&#21183;&#21644;&#26399;&#26395;&#39034;&#24207;&#20316;&#20026;&#26497;&#31471;&#24773;&#20917;&#12290;&#25105;&#20204;&#36890;&#36807;&#32447;&#24615;&#20248;&#21270;&#23548;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#25105;&#20204;&#25552;&#20986;&#30340;&#24191;&#20041;&#38543;&#26426;&#20248;&#21183;&#65288;GSD&#65289;&#39034;&#24207;&#30340;&#65288;&#27491;&#21017;&#21270;&#30340;&#65289;&#32479;&#35745;&#26816;&#39564;&#65292;&#24182;&#36890;&#36807;&#19981;&#31934;&#30830;&#27010;&#29575;&#27169;&#22411;&#20351;&#20854;&#26356;&#20026;&#40065;&#26834;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#29992;&#22810;&#32500;&#36139;&#22256;&#24230;&#37327;&#12289;&#37329;&#34701;&#21644;&#21307;&#23398;&#25968;&#25454;&#36827;&#34892;&#35828;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Spaces with locally varying scale of measurement, like multidimensional structures with differently scaled dimensions, are pretty common in statistics and machine learning. Nevertheless, it is still understood as an open question how to exploit the entire information encoded in them properly. We address this problem by considering an order based on (sets of) expectations of random variables mapping into such non-standard spaces. This order contains stochastic dominance and expectation order as extreme cases when no, or respectively perfect, cardinal structure is given. We derive a (regularized) statistical test for our proposed generalized stochastic dominance (GSD) order, operationalize it by linear optimization, and robustify it by imprecise probability models. Our findings are illustrated with data from multidimensional poverty measurement, finance, and medicine.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#21452;&#22240;&#26524;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#30340;&#25311;&#21512;&#20540;&#36845;&#20195;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#20445;&#35777;&#31934;&#24230;&#30340;&#21516;&#26102;&#20855;&#26377;&#33391;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#25968;&#20540;&#23454;&#39564;&#32467;&#26524;&#20063;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.12658</link><description>&lt;p&gt;
&#25311;&#21512;&#20540;&#36845;&#20195;&#26041;&#27861;&#27714;&#35299;&#36866;&#24212;&#32467;&#26500;&#21452;&#22240;&#26524;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Fitted Value Iteration Methods for Bicausal Optimal Transport. (arXiv:2306.12658v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12658
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#21452;&#22240;&#26524;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#30340;&#25311;&#21512;&#20540;&#36845;&#20195;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#20445;&#35777;&#31934;&#24230;&#30340;&#21516;&#26102;&#20855;&#26377;&#33391;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#25968;&#20540;&#23454;&#39564;&#32467;&#26524;&#20063;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#25311;&#21512;&#20540;&#36845;&#20195;&#26041;&#27861;(FVI)&#29992;&#20110;&#35745;&#31639;&#20855;&#26377;&#36866;&#24212;&#32467;&#26500;&#30340;&#21452;&#22240;&#26524;&#26368;&#20248;&#20256;&#36755;(OT)&#12290;&#22522;&#20110;&#21160;&#24577;&#35268;&#21010;&#30340;&#24418;&#24335;&#21270;&#34920;&#36848;&#65292;FVI&#37319;&#29992;&#20989;&#25968;&#31867;&#29992;&#20110;&#36817;&#20284;&#21452;&#22240;&#26524;OT&#20013;&#30340;&#20540;&#20989;&#25968;&#12290;&#22312;&#21487;&#38598;&#20013;&#26465;&#20214;&#21644;&#36817;&#20284;&#23436;&#22791;&#24615;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#20351;&#29992;&#65288;&#23616;&#37096;&#65289;Rademacher&#22797;&#26434;&#24230;&#35777;&#26126;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#28145;&#24230;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#36866;&#24403;&#32467;&#26500;&#65292;&#28385;&#36275;&#26679;&#26412;&#22797;&#26434;&#24230;&#35777;&#26126;&#25152;&#38656;&#30340;&#20851;&#38190;&#20551;&#35774;&#26465;&#20214;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;FVI&#22312;&#26102;&#38388;&#36328;&#24230;&#22686;&#21152;&#26102;&#20248;&#20110;&#32447;&#24615;&#35268;&#21010;&#21644;&#36866;&#24212;&#24615;Sinkhorn&#26041;&#27861;&#65292;&#22312;&#20445;&#25345;&#21487;&#25509;&#21463;&#31934;&#24230;&#30340;&#21516;&#26102;&#20855;&#26377;&#24456;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a fitted value iteration (FVI) method to compute bicausal optimal transport (OT) where couplings have an adapted structure. Based on the dynamic programming formulation, FVI adopts a function class to approximate the value functions in bicausal OT. Under the concentrability condition and approximate completeness assumption, we prove the sample complexity using (local) Rademacher complexity. Furthermore, we demonstrate that multilayer neural networks with appropriate structures satisfy the crucial assumptions required in sample complexity proofs. Numerical experiments reveal that FVI outperforms linear programming and adapted Sinkhorn methods in scalability as the time horizon increases, while still maintaining acceptable accuracy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22312;&#33258;&#32534;&#30721;&#22120;&#30340;&#25439;&#22833;&#20989;&#25968;&#20013;&#28155;&#21152;&#19968;&#20010;&#36731;&#37327;&#32423;&#30340;&#32422;&#26463;&#39033;&#65292;&#29992;&#20110;&#35299;&#20915;&#20256;&#32479;&#33258;&#32534;&#30721;&#22120;&#22312;&#24322;&#24120;&#26816;&#27979;&#20013;&#30340;&#19981;&#36275;&#65292;&#24182;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.12627</link><description>&lt;p&gt;
&#38024;&#23545;&#24322;&#24120;&#26816;&#27979;&#30340;&#30446;&#26631;&#22604;&#32553;&#27491;&#21017;&#21270;&#33258;&#32534;&#30721;&#22120;&#65306;&#20013;&#24515;&#30340;&#40657;&#27934;
&lt;/p&gt;
&lt;p&gt;
Targeted collapse regularized autoencoder for anomaly detection: black hole at the center. (arXiv:2306.12627v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12627
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22312;&#33258;&#32534;&#30721;&#22120;&#30340;&#25439;&#22833;&#20989;&#25968;&#20013;&#28155;&#21152;&#19968;&#20010;&#36731;&#37327;&#32423;&#30340;&#32422;&#26463;&#39033;&#65292;&#29992;&#20110;&#35299;&#20915;&#20256;&#32479;&#33258;&#32534;&#30721;&#22120;&#22312;&#24322;&#24120;&#26816;&#27979;&#20013;&#30340;&#19981;&#36275;&#65292;&#24182;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#32534;&#30721;&#22120;&#24050;&#24191;&#27867;&#29992;&#20110;&#26368;&#36817;&#30340;&#24322;&#24120;&#26816;&#27979;&#25216;&#26415;&#24320;&#21457;&#20013;&#12290;&#23427;&#20204;&#30340;&#24212;&#29992;&#21069;&#25552;&#26159;&#22312;&#27491;&#24120;&#35757;&#32451;&#25968;&#25454;&#19978;&#35757;&#32451;&#33258;&#32534;&#30721;&#22120;&#21518;&#65292;&#24322;&#24120;&#36755;&#20837;&#23558;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#37325;&#26500;&#35823;&#24046;&#12290;&#22240;&#27492;&#65292;&#36825;&#20351;&#24471;&#27491;&#24120;&#21644;&#24322;&#24120;&#26679;&#26412;&#20043;&#38388;&#26377;&#20102;&#26126;&#26174;&#30340;&#21306;&#21035;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#35266;&#23519;&#21040;&#65292;&#33258;&#32534;&#30721;&#22120;&#21487;&#20197;&#19968;&#23450;&#31243;&#24230;&#19978;&#27867;&#21270;&#21040;&#27491;&#24120;&#31867;&#20043;&#22806;&#65292;&#24182;&#22312;&#19968;&#20123;&#24322;&#24120;&#26679;&#26412;&#19978;&#23454;&#29616;&#36739;&#23567;&#30340;&#37325;&#26500;&#35823;&#24046;&#12290;&#20026;&#20102;&#25913;&#21892;&#24615;&#33021;&#65292;&#21508;&#31181;&#25216;&#26415;&#25552;&#20986;&#20102;&#20854;&#20182;&#32452;&#20214;&#21644;&#26356;&#22797;&#26434;&#30340;&#35757;&#32451;&#31243;&#24207;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#24120;&#31616;&#21333;&#30340;&#26367;&#20195;&#26041;&#27861;&#65306;&#19981;&#26159;&#28155;&#21152;&#31070;&#32463;&#32593;&#32476;&#32452;&#20214;&#12289;&#28041;&#21450;&#35745;&#31639;&#21644;&#32321;&#29712;&#30340;&#35757;&#32451;&#65292;&#32780;&#26159;&#36890;&#36807;&#22312;&#28508;&#22312;&#31354;&#38388;&#20013;&#35843;&#33410;&#34920;&#31034;&#30340;&#33539;&#25968;&#65292;&#29992;&#19968;&#20010;&#35745;&#31639;&#31616;&#21333;&#30340;&#39033;&#26469;&#34917;&#20805;&#37325;&#26500;&#25439;&#22833;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#31616;&#21333;&#24615;&#26368;&#23567;&#21270;&#20102;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Autoencoders have been extensively used in the development of recent anomaly detection techniques. The premise of their application is based on the notion that after training the autoencoder on normal training data, anomalous inputs will exhibit a significant reconstruction error. Consequently, this enables a clear differentiation between normal and anomalous samples. In practice, however, it is observed that autoencoders can generalize beyond the normal class and achieve a small reconstruction error on some of the anomalous samples. To improve the performance, various techniques propose additional components and more sophisticated training procedures. In this work, we propose a remarkably straightforward alternative: instead of adding neural network components, involved computations, and cumbersome training, we complement the reconstruction loss with a computationally light term that regulates the norm of representations in the latent space. The simplicity of our approach minimizes th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#37325;&#35201;&#24615;&#25277;&#26679;&#23454;&#29616;&#26377;&#25928;&#36890;&#20449;&#30340;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#65292;&#22823;&#22823;&#38477;&#20302;&#20102;&#21457;&#36865;&#27169;&#22411;&#26356;&#26032;&#30340;&#39640;&#36890;&#20449;&#25104;&#26412;&#65292;&#21033;&#29992;&#26381;&#21153;&#22120;&#31471;&#23458;&#25143;&#31471;&#20998;&#24067;&#21644;&#38468;&#21152;&#20449;&#24687;&#30340;&#25509;&#36817;&#20851;&#31995;&#65292;&#21482;&#38656;&#35201;&#36739;&#23569;&#30340;&#36890;&#20449;&#37327;&#21363;&#21487;&#23454;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.12625</link><description>&lt;p&gt;
&#36890;&#36807;&#37325;&#35201;&#24615;&#25277;&#26679;&#23454;&#29616;&#26377;&#25928;&#36890;&#20449;&#30340;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Communication-Efficient Federated Learning through Importance Sampling. (arXiv:2306.12625v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12625
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#37325;&#35201;&#24615;&#25277;&#26679;&#23454;&#29616;&#26377;&#25928;&#36890;&#20449;&#30340;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#65292;&#22823;&#22823;&#38477;&#20302;&#20102;&#21457;&#36865;&#27169;&#22411;&#26356;&#26032;&#30340;&#39640;&#36890;&#20449;&#25104;&#26412;&#65292;&#21033;&#29992;&#26381;&#21153;&#22120;&#31471;&#23458;&#25143;&#31471;&#20998;&#24067;&#21644;&#38468;&#21152;&#20449;&#24687;&#30340;&#25509;&#36817;&#20851;&#31995;&#65292;&#21482;&#38656;&#35201;&#36739;&#23569;&#30340;&#36890;&#20449;&#37327;&#21363;&#21487;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23458;&#25143;&#31471;&#21521;&#26381;&#21153;&#22120;&#21457;&#36865;&#27169;&#22411;&#26356;&#26032;&#30340;&#39640;&#36890;&#20449;&#25104;&#26412;&#26159;&#21487;&#25193;&#23637;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#30340;&#37325;&#35201;&#29942;&#39048;&#12290;&#29616;&#26377;&#26041;&#27861;&#20013;&#65292;&#20351;&#29992;&#38543;&#26426;&#21387;&#32553;&#26041;&#27861;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#27604;&#29305;&#29575;-&#20934;&#30830;&#24615;&#25240;&#34935;&#8212;&#8212;&#20854;&#20013;&#23458;&#25143;&#31471;n&#21457;&#36865;&#26469;&#33258;&#20165;&#20026;&#35813;&#23458;&#25143;&#31471;&#30340;&#27010;&#29575;&#20998;&#24067;q&#966;&#65288;n&#65289;&#30340;&#26679;&#26412;&#65292;&#26381;&#21153;&#22120;&#20351;&#29992;&#36825;&#20123;&#26679;&#26412;&#20272;&#35745;&#23458;&#25143;&#31471;&#20998;&#24067;&#30340;&#24179;&#22343;&#20540;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#27809;&#26377;&#20805;&#20998;&#21033;&#29992;FL&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;&#26381;&#21153;&#22120;&#22312;&#25972;&#20010;&#35757;&#32451;&#36807;&#31243;&#20013;&#20855;&#26377;&#39044;&#25968;&#25454;&#20998;&#24067;p&#952;&#30340;&#38468;&#21152;&#20449;&#24687;&#65292;&#35813;&#20998;&#24067;&#19982;&#23458;&#25143;&#31471;&#20998;&#24067;q&#966;&#65288;n&#65289;&#22312;Kullback-Leibler&#65288;KL&#65289;&#21457;&#25955;&#26041;&#38754;&#25509;&#36817;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#26381;&#21153;&#22120;&#31471;&#23458;&#25143;&#31471;&#20998;&#24067;q&#966;&#65288;n)&#19982;&#38468;&#21152;&#20449;&#24687;p&#952;&#20043;&#38388;&#30340;&#36825;&#31181;&#25509;&#36817;&#20851;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#38656;&#35201;&#22823;&#32422;Dkl&#65288;q&#966;&#65288;n&#65289;|| p&#952;&#65289;&#20301;&#30340;&#36890;&#20449;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
The high communication cost of sending model updates from the clients to the server is a significant bottleneck for scalable federated learning (FL). Among existing approaches, state-of-the-art bitrate-accuracy tradeoffs have been achieved using stochastic compression methods -- in which the client $n$ sends a sample from a client-only probability distribution $q_{\phi^{(n)}}$, and the server estimates the mean of the clients' distributions using these samples. However, such methods do not take full advantage of the FL setup where the server, throughout the training process, has side information in the form of a pre-data distribution $p_{\theta}$ that is close to the client's distribution $q_{\phi^{(n)}}$ in Kullback-Leibler (KL) divergence. In this work, we exploit this closeness between the clients' distributions $q_{\phi^{(n)}}$'s and the side information $p_{\theta}$ at the server, and propose a framework that requires approximately $D_{KL}(q_{\phi^{(n)}}|| p_{\theta})$ bits of com
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#23618;&#32423;&#31070;&#32463;&#27169;&#25311;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#20284;&#28982;&#20989;&#25968;&#19981;&#21487;&#35745;&#31639;&#20294;&#21487;&#20197;&#36890;&#36807;&#21069;&#21521;&#27169;&#25311;&#23454;&#29616;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#25972;&#20010;&#25968;&#25454;&#38598;&#36827;&#34892;&#26368;&#20248;&#27010;&#29575;&#25512;&#26029;&#65292;&#30528;&#37325;&#32771;&#34385;&#20102;&#27169;&#22411;&#30340;&#23618;&#32423;&#32467;&#26500;&#65292;&#21487;&#20197;&#23548;&#33268;&#26356;&#32039;&#20945;&#30340;&#21442;&#25968;&#32422;&#26463;&#12290;</title><link>http://arxiv.org/abs/2306.12584</link><description>&lt;p&gt;
&#22522;&#20110;&#23618;&#32423;&#31070;&#32463;&#27169;&#25311;&#30340;&#20107;&#20214;&#38598;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Hierarchical Neural Simulation-Based Inference Over Event Ensembles. (arXiv:2306.12584v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12584
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#23618;&#32423;&#31070;&#32463;&#27169;&#25311;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#20284;&#28982;&#20989;&#25968;&#19981;&#21487;&#35745;&#31639;&#20294;&#21487;&#20197;&#36890;&#36807;&#21069;&#21521;&#27169;&#25311;&#23454;&#29616;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#25972;&#20010;&#25968;&#25454;&#38598;&#36827;&#34892;&#26368;&#20248;&#27010;&#29575;&#25512;&#26029;&#65292;&#30528;&#37325;&#32771;&#34385;&#20102;&#27169;&#22411;&#30340;&#23618;&#32423;&#32467;&#26500;&#65292;&#21487;&#20197;&#23548;&#33268;&#26356;&#32039;&#20945;&#30340;&#21442;&#25968;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#25968;&#25454;&#20998;&#26512;&#20013;&#65292;&#20107;&#20214;&#38598;&#26159;&#24120;&#35265;&#30340;&#35266;&#27979;&#20540;&#38598;&#21512;&#65292;&#23427;&#20204;&#20849;&#21516;&#32422;&#26463;&#20102;&#24863;&#20852;&#36259;&#30340;&#27169;&#22411;&#21442;&#25968;&#12290;&#36825;&#20123;&#27169;&#22411;&#36890;&#24120;&#20855;&#26377;&#23618;&#32423;&#32467;&#26500;&#65292;&#20854;&#20013;&#8220;&#23616;&#37096;&#8221;&#21442;&#25968;&#24433;&#21709;&#21333;&#20010;&#20107;&#20214;&#65292;&#8220;&#20840;&#23616;&#8221;&#21442;&#25968;&#24433;&#21709;&#25972;&#20010;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#23454;&#29992;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#20284;&#28982;&#20989;&#25968;&#19981;&#21487;&#35745;&#31639;&#20294;&#21487;&#20197;&#36890;&#36807;&#21069;&#21521;&#27169;&#25311;&#23454;&#29616;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#25972;&#20010;&#25968;&#25454;&#38598;&#36827;&#34892;&#26368;&#20248;&#27010;&#29575;&#25512;&#26029;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#20284;&#28982;&#20989;&#25968;&#65288;&#27604;&#65289;&#25110;&#21518;&#39564;&#27010;&#29575;&#30340;&#31070;&#32463;&#20272;&#35745;&#22120;&#65292;&#24182;&#23637;&#31034;&#20102;&#26126;&#30830;&#32771;&#34385;&#27169;&#22411;&#23618;&#32423;&#32467;&#26500;&#21487;&#20197;&#23548;&#33268;&#26356;&#32039;&#20945;&#30340;&#21442;&#25968;&#32422;&#26463;&#12290;&#25105;&#20204;&#20197;&#29289;&#29702;&#31185;&#23398;&#20026;&#20363;&#30740;&#31350;&#20102;&#26412;&#25991;&#35752;&#35770;&#30340;&#20869;&#23481;&#65292;&#30528;&#37325;&#20110;&#31890;&#23376;&#29289;&#29702;&#23398;&#65288;&#31890;&#23376;&#23545;&#25758;&#26426;&#25968;&#25454;&#65289;&#21644;&#22825;&#20307;&#29289;&#29702;&#23398;&#65288;&#24378;&#24341;&#21147;&#36879;&#38236;&#35266;&#27979;&#65289;&#30340;&#26696;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
When analyzing real-world data it is common to work with event ensembles, which comprise sets of observations that collectively constrain the parameters of an underlying model of interest. Such models often have a hierarchical structure, where "local" parameters impact individual events and "global" parameters influence the entire dataset. We introduce practical approaches for optimal dataset-wide probabilistic inference in cases where the likelihood is intractable, but simulations can be realized via forward modeling. We construct neural estimators for the likelihood(-ratio) or posterior and show that explicitly accounting for the model's hierarchical structure can lead to tighter parameter constraints. We ground our discussion using case studies from the physical sciences, focusing on examples from particle physics (particle collider data) and astrophysics (strong gravitational lensing observations).
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#22238;&#24402;&#20013;&#23558;&#29983;&#25104;&#25968;&#25454;&#19982;&#23545;&#25239;&#35757;&#32451;&#30456;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#21457;&#29616;&#35813;&#26041;&#27861;&#21487;&#36890;&#36807;&#20004;&#38454;&#27573;&#35757;&#32451;&#23454;&#29616;&#26356;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.12582</link><description>&lt;p&gt;
&#29983;&#25104;&#25968;&#25454;&#22312;&#39640;&#32500;&#22238;&#24402;&#20013;&#30340;&#23545;&#25239;&#35757;&#32451;&#65306;&#19968;&#39033;&#28176;&#36817;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Adversarial Training with Generated Data in High-Dimensional Regression: An Asymptotic Study. (arXiv:2306.12582v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12582
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#22238;&#24402;&#20013;&#23558;&#29983;&#25104;&#25968;&#25454;&#19982;&#23545;&#25239;&#35757;&#32451;&#30456;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#21457;&#29616;&#35813;&#26041;&#27861;&#21487;&#36890;&#36807;&#20004;&#38454;&#27573;&#35757;&#32451;&#23454;&#29616;&#26356;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#35768;&#22810;&#30740;&#31350;&#65288;&#20363;&#22914;\cite{carmon2019unlabeled,gowal2021improving,xing2022artificial}&#65289;&#34920;&#26126;&#36890;&#36807;&#20004;&#38454;&#27573;&#35757;&#32451;&#26041;&#27861;&#65292;&#22312;&#23545;&#25239;&#35757;&#32451;&#20013;&#21152;&#20837;&#24102;&#20266;&#26631;&#31614;&#30340;&#39069;&#22806;&#30495;&#23454;&#25110;&#29983;&#25104;&#25968;&#25454;&#21487;&#20197;&#22686;&#24378;&#27169;&#22411;&#24615;&#33021;&#12290;&#26412;&#25991;&#22312;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#23545;&#35813;&#26041;&#27861;&#30340;&#28176;&#36817;&#34892;&#20026;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#34429;&#28982;&#22312;&#26080;&#23725;&#35757;&#32451;&#20013;&#23384;&#22312;&#21452;&#23792;&#29616;&#35937;&#65292;&#20294;&#22312;&#36866;&#24403;&#30340;$\mathcal{L}_2$&#27491;&#21017;&#21270;&#20013;&#65292;&#20004;&#38454;&#27573;&#23545;&#25239;&#35757;&#32451;&#21487;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;&#19968;&#20010;&#29305;&#21035;&#38024;&#23545;&#20004;&#38454;&#27573;&#35757;&#32451;&#26041;&#27861;&#30340;&#24555;&#36895;&#20132;&#21449;&#39564;&#35777;&#20844;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, studies such as \cite{carmon2019unlabeled,gowal2021improving,xing2022artificial} have demonstrated that incorporating additional real or generated data with pseudo-labels can enhance adversarial training through a two-stage training approach. In this paper, we perform a theoretical analysis of the asymptotic behavior of this method in high-dimensional linear regression. While a double-descent phenomenon can be observed in ridgeless training, with an appropriate $\mathcal{L}_2$ regularization, the two-stage adversarial training achieves a better performance. Finally, we derive a shortcut cross-validation formula specifically tailored for the two-stage training method.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#38480;&#26102;&#38388;&#26446;&#38597;&#26222;&#35834;&#22827;&#25351;&#25968;&#65292;&#21457;&#29616;&#27491;&#25351;&#25968;&#30340;&#33034;&#32447;&#23558;&#36755;&#20837;&#31354;&#38388;&#20998;&#25104;&#19981;&#21516;&#21306;&#22495;&#65292;&#24182;&#25581;&#31034;&#20102;&#28145;&#24230;&#32593;&#32476;&#23398;&#20064;&#33021;&#21147;&#30340;&#26426;&#21046;&#12290;</title><link>http://arxiv.org/abs/2306.12548</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#38480;&#26102;&#38388;&#26446;&#38597;&#26222;&#35834;&#22827;&#25351;&#25968;
&lt;/p&gt;
&lt;p&gt;
Finite-time Lyapunov exponents of deep neural networks. (arXiv:2306.12548v1 [cond-mat.dis-nn])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12548
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#38480;&#26102;&#38388;&#26446;&#38597;&#26222;&#35834;&#22827;&#25351;&#25968;&#65292;&#21457;&#29616;&#27491;&#25351;&#25968;&#30340;&#33034;&#32447;&#23558;&#36755;&#20837;&#31354;&#38388;&#20998;&#25104;&#19981;&#21516;&#21306;&#22495;&#65292;&#24182;&#25581;&#31034;&#20102;&#28145;&#24230;&#32593;&#32476;&#23398;&#20064;&#33021;&#21147;&#30340;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35745;&#31639;&#20102;&#23567;&#30340;&#36755;&#20837;&#25200;&#21160;&#22914;&#20309;&#24433;&#21709;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20986;&#65292;&#25506;&#32034;&#28145;&#24230;&#32593;&#32476;&#19982;&#21160;&#21147;&#31995;&#32479;&#20043;&#38388;&#30340;&#31867;&#27604;&#65292;&#20854;&#20013;&#23616;&#37096;&#25200;&#21160;&#30340;&#22686;&#38271;&#25110;&#34928;&#20943;&#30001;&#26377;&#38480;&#26102;&#38388;&#26446;&#38597;&#26222;&#35834;&#22827;&#25351;&#25968;&#26469;&#25551;&#36848;&#12290;&#25105;&#20204;&#26174;&#31034;&#26368;&#22823;&#25351;&#25968;&#22312;&#36755;&#20837;&#31354;&#38388;&#20013;&#24418;&#25104;&#20960;&#20309;&#32467;&#26500;&#65292;&#31867;&#20284;&#20110;&#21160;&#21147;&#31995;&#32479;&#20013;&#30340;&#30456;&#24178;&#32467;&#26500;&#12290;&#22823;&#27491;&#25351;&#25968;&#30340;&#33034;&#32447;&#23558;&#36755;&#20837;&#31354;&#38388;&#20998;&#25104;&#32593;&#32476;&#23558;&#20854;&#19982;&#19981;&#21516;&#31867;&#21035;&#30456;&#20851;&#32852;&#30340;&#19981;&#21516;&#21306;&#22495;&#12290;&#36825;&#20123;&#33034;&#32447;&#21487;&#35270;&#21270;&#28145;&#24230;&#32593;&#32476;&#22312;&#36755;&#20837;&#31354;&#38388;&#20013;&#26500;&#24314;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#25581;&#31034;&#20102;&#20854;&#23398;&#20064;&#33021;&#21147;&#32972;&#21518;&#30340;&#22522;&#26412;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
We compute how small input perturbations affect the output of deep neural networks, exploring an analogy between deep networks and dynamical systems, where the growth or decay of local perturbations is characterised by finite-time Lyapunov exponents. We show that the maximal exponent forms geometrical structures in input space, akin to coherent structures in dynamical systems. Ridges of large positive exponents divide input space into different regions that the network associates with different classes. These ridges visualise the geometry that deep networks construct in input space, shedding light on the fundamental mechanisms underlying their learning capabilities.
&lt;/p&gt;</description></item><item><title>&#38543;&#26426;&#20984;&#20248;&#21270;&#38656;&#35201;&#22312;&#20869;&#23384;&#21644;&#26597;&#35810;&#20043;&#38388;&#26435;&#34913;&#65292;&#20351;&#29992; $\tilde{O}(d^2)$ &#27604;&#29305;&#20869;&#23384;&#21644; $\tilde{O}(d)$ &#27425;&#26597;&#35810;&#30340;&#21106;&#24179;&#38754;&#26041;&#27861;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2306.12534</link><description>&lt;p&gt;
&#38543;&#26426;&#20984;&#20248;&#21270;&#30340;&#20869;&#23384;&#21644;&#26597;&#35810;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
Memory-Query Tradeoffs for Randomized Convex Optimization. (arXiv:2306.12534v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12534
&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#20984;&#20248;&#21270;&#38656;&#35201;&#22312;&#20869;&#23384;&#21644;&#26597;&#35810;&#20043;&#38388;&#26435;&#34913;&#65292;&#20351;&#29992; $\tilde{O}(d^2)$ &#27604;&#29305;&#20869;&#23384;&#21644; $\tilde{O}(d)$ &#27425;&#26597;&#35810;&#30340;&#21106;&#24179;&#38754;&#26041;&#27861;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;&#20219;&#20309;&#38543;&#26426;&#19968;&#38454;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#21333;&#20301;&#29699;&#19978;&#26368;&#23567;&#21270;&#19968;&#20010; $d$ &#32500;&#12289;$1$-Lipschitz &#20984;&#20989;&#25968;&#65292;&#24517;&#39035;&#20351;&#29992; $\Omega(d^{2-\delta})$ &#27604;&#29305;&#30340;&#20869;&#23384;&#25110;&#32773;&#36827;&#34892; $\Omega(d^{1+\delta/6-o(1)})$ &#27425;&#26597;&#35810;&#65292;&#20854;&#20013; $\delta\in (0,1)$ &#26159;&#20219;&#24847;&#24120;&#25968;&#65292;&#31934;&#24230; $\epsilon$ &#22312; $d$ &#20013;&#26159;&#20934;&#22810;&#39033;&#24335;&#23567;&#30340;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#24847;&#21619;&#30528;&#65292;&#20351;&#29992; $\tilde{O}(d^2)$ &#27604;&#29305;&#20869;&#23384;&#21644; $\tilde{O}(d)$ &#27425;&#26597;&#35810;&#30340;&#21106;&#24179;&#38754;&#26041;&#27861;&#65292;&#22312;&#38543;&#26426;&#19968;&#38454;&#31639;&#27861;&#20013;&#26159;&#24085;&#32047;&#25176;&#26368;&#20248;&#65292;&#32780;&#23545;&#20110;&#20984;&#20248;&#21270;&#65292;&#38656;&#35201;&#20108;&#27425;&#20869;&#23384;&#25165;&#33021;&#23454;&#29616;&#26368;&#20339;&#26597;&#35810;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show that any randomized first-order algorithm which minimizes a $d$-dimensional, $1$-Lipschitz convex function over the unit ball must either use $\Omega(d^{2-\delta})$ bits of memory or make $\Omega(d^{1+\delta/6-o(1)})$ queries, for any constant $\delta\in (0,1)$ and when the precision $\epsilon$ is quasipolynomially small in $d$. Our result implies that cutting plane methods, which use $\tilde{O}(d^2)$ bits of memory and $\tilde{O}(d)$ queries, are Pareto-optimal among randomized first-order algorithms, and quadratic memory is required to achieve optimal query complexity for convex optimization.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#26102;&#38388;&#30456;&#20851;&#30340;Cox&#27169;&#22411;&#20013;&#36827;&#34892;&#21464;&#37327;&#36873;&#25321;&#65292;&#24182;&#36866;&#24212;&#21508;&#31181;&#22797;&#26434;&#30340;&#20998;&#32452;&#32467;&#26500;&#65292;&#20855;&#26377;&#36739;&#20302;&#30340;&#35823;&#35686;&#29575;&#21644;&#24555;&#36895;&#30340;&#35745;&#31639;&#12290;</title><link>http://arxiv.org/abs/2306.12528</link><description>&lt;p&gt;
&#26102;&#38388;&#30456;&#20851;&#30340;Cox&#27169;&#22411;&#20013;&#30340;&#32467;&#26500;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Structured Learning in Time-dependent Cox Models. (arXiv:2306.12528v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12528
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#26102;&#38388;&#30456;&#20851;&#30340;Cox&#27169;&#22411;&#20013;&#36827;&#34892;&#21464;&#37327;&#36873;&#25321;&#65292;&#24182;&#36866;&#24212;&#21508;&#31181;&#22797;&#26434;&#30340;&#20998;&#32452;&#32467;&#26500;&#65292;&#20855;&#26377;&#36739;&#20302;&#30340;&#35823;&#35686;&#29575;&#21644;&#24555;&#36895;&#30340;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20855;&#26377;&#26102;&#38388;&#30456;&#20851;&#31995;&#25968;&#21644;&#21327;&#21464;&#37327;&#30340;Cox&#27169;&#22411;&#22312;&#29983;&#23384;&#20998;&#26512;&#20013;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#12290;&#22312;&#39640;&#32500;&#29615;&#22659;&#20013;&#65292;&#37319;&#29992;&#31232;&#30095;&#27491;&#21017;&#21270;&#25216;&#26415;&#36827;&#34892;&#21464;&#37327;&#36873;&#25321;&#65292;&#20294;&#29616;&#26377;&#30340;&#26102;&#38388;&#30456;&#20851;&#30340;Cox&#27169;&#22411;&#26041;&#27861;&#32570;&#20047;&#22312;&#24378;&#21046;&#29305;&#23450;&#31232;&#30095;&#27169;&#24335;&#65288;&#21363;&#21327;&#21464;&#37327;&#32467;&#26500;&#65289;&#26041;&#38754;&#30340;&#28789;&#27963;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#26102;&#38388;&#30456;&#20851;&#30340;Cox&#27169;&#22411;&#20013;&#36827;&#34892;&#21464;&#37327;&#36873;&#25321;&#65292;&#21487;&#36866;&#24212;&#22797;&#26434;&#30340;&#36873;&#25321;&#35268;&#21017;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#36866;&#24212;&#20219;&#24847;&#20998;&#32452;&#32467;&#26500;&#65292;&#21253;&#25324;&#20132;&#20114;&#36873;&#25321;&#65292;&#26102;&#38388;&#24615;&#65292;&#31354;&#38388;&#24615;&#65292;&#26641;&#21644;&#26377;&#21521;&#26080;&#29615;&#22270;&#32467;&#26500;&#12290;&#23427;&#21487;&#20197;&#36890;&#36807;&#38477;&#20302;&#35823;&#35686;&#29575;&#23454;&#29616;&#20934;&#30830;&#30340;&#20272;&#35745;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;sox&#36719;&#20214;&#21253;&#65292;&#23454;&#29616;&#20102;&#19968;&#31181;&#32593;&#32476;&#27969;&#31639;&#27861;&#65292;&#29992;&#20110;&#39640;&#25928;&#22320;&#35299;&#20915;&#20855;&#26377;&#22797;&#26434;&#21327;&#21464;&#37327;&#32467;&#26500;&#30340;&#27169;&#22411;&#12290;Sox&#25552;&#20379;&#20102;&#19968;&#20010;&#29992;&#25143;&#21451;&#22909;&#30340;&#25509;&#21475;&#65292;&#29992;&#20110;&#25351;&#23450;&#20998;&#32452;&#32467;&#26500;&#65292;&#24182;&#25552;&#20379;&#24555;&#36895;&#30340;&#35745;&#31639;&#12290;&#36890;&#36807;&#26696;&#20363;&#30740;&#31350;&#65292;&#21253;&#25324;&#19968;&#20010;&#29992;&#20110;&#30830;&#23450;&#25152;&#26377;&#33268;&#27515;&#26102;&#38388;&#39044;&#27979;&#22240;&#32032;&#30340;&#26696;&#20363;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cox models with time-dependent coefficients and covariates are widely used in survival analysis. In high-dimensional settings, sparse regularization techniques are employed for variable selection, but existing methods for time-dependent Cox models lack flexibility in enforcing specific sparsity patterns (i.e., covariate structures). We propose a flexible framework for variable selection in time-dependent Cox models, accommodating complex selection rules. Our method can adapt to arbitrary grouping structures, including interaction selection, temporal, spatial, tree, and directed acyclic graph structures. It achieves accurate estimation with low false alarm rates. We develop the sox package, implementing a network flow algorithm for efficiently solving models with complex covariate structures. Sox offers a user-friendly interface for specifying grouping structures and delivers fast computation. Through examples, including a case study on identifying predictors of time to all-cause death 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#38543;&#26426;&#38646;&#38454;&#20248;&#21270;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20108;&#27425;&#22411;&#30446;&#26631;&#20989;&#25968;&#21450;&#20854;&#23616;&#37096;&#20960;&#20309;&#32467;&#26500;&#30340;&#26368;&#20248;Hessian&#30456;&#20851;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#20174;&#20449;&#24687;&#35770;&#35282;&#24230;&#25552;&#20379;Hessian&#30456;&#20851;&#22797;&#26434;&#24230;&#30340;&#19979;&#30028;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;Hessian&#26080;&#20851;&#30340;&#31639;&#27861;&#21487;&#26222;&#36941;&#23454;&#29616;&#25152;&#26377;Hessian&#23454;&#20363;&#30340;&#28176;&#36817;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.12383</link><description>&lt;p&gt;
&#20108;&#27425;&#22411;&#36172;&#33218;&#26426;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65306;Hessian&#30456;&#20851;&#24615;&#30028;&#38480;&#21644;&#26368;&#20248;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sample Complexity for Quadratic Bandits: Hessian Dependent Bounds and Optimal Algorithms. (arXiv:2306.12383v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12383
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#38543;&#26426;&#38646;&#38454;&#20248;&#21270;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20108;&#27425;&#22411;&#30446;&#26631;&#20989;&#25968;&#21450;&#20854;&#23616;&#37096;&#20960;&#20309;&#32467;&#26500;&#30340;&#26368;&#20248;Hessian&#30456;&#20851;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#20174;&#20449;&#24687;&#35770;&#35282;&#24230;&#25552;&#20379;Hessian&#30456;&#20851;&#22797;&#26434;&#24230;&#30340;&#19979;&#30028;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;Hessian&#26080;&#20851;&#30340;&#31639;&#27861;&#21487;&#26222;&#36941;&#23454;&#29616;&#25152;&#26377;Hessian&#23454;&#20363;&#30340;&#28176;&#36817;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#38543;&#26426;&#38646;&#38454;&#20248;&#21270;&#20013;&#65292;&#20102;&#35299;&#22914;&#20309;&#20805;&#20998;&#21033;&#29992;&#24213;&#23618;&#30446;&#26631;&#20989;&#25968;&#30340;&#23616;&#37096;&#20960;&#20309;&#32467;&#26500;&#26159;&#19968;&#20010;&#23454;&#38469;&#30456;&#20851;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#32771;&#34385;&#19968;&#31181;&#22522;&#26412;&#24773;&#20917;&#65292;&#21363;&#30446;&#26631;&#20989;&#25968;&#26159;&#20108;&#27425;&#22411;&#30340;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#26368;&#20248;Hessian&#30456;&#20851;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#31532;&#19968;&#20010;&#32039;&#23494;&#21051;&#30011;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#20855;&#26377;&#21452;&#37325;&#24615;&#36136;&#12290;&#39318;&#20808;&#65292;&#20174;&#20449;&#24687;&#35770;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#31216;&#20026;&#33021;&#37327;&#20998;&#37197;&#30340;&#27010;&#24565;&#26469;&#25429;&#25417;&#25628;&#32034;&#31639;&#27861;&#21644;&#30446;&#26631;&#20989;&#25968;&#20960;&#20309;&#32467;&#26500;&#20043;&#38388;&#30340;&#20132;&#20114;&#65292;&#35777;&#26126;&#20102;Hessian&#30456;&#20851;&#22797;&#26434;&#24230;&#30340;&#32039;&#23494;&#19979;&#30028;&#12290;&#36890;&#36807;&#35299;&#20915;&#26368;&#20248;&#33021;&#37327;&#35889;&#65292;&#24471;&#21040;&#20102;&#37197;&#22871;&#30340;&#19978;&#38480;&#12290;&#20854;&#27425;&#65292;&#31639;&#27861;&#26041;&#38754;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23384;&#22312;&#19968;&#31181;Hessian&#26080;&#20851;&#30340;&#31639;&#27861;&#65292;&#33021;&#22815;&#26222;&#36941;&#23454;&#29616;&#25152;&#26377;Hessian&#23454;&#20363;&#30340;&#28176;&#36817;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#31639;&#27861;&#33021;&#22815;&#23454;&#29616;&#30340;&#28176;&#36817;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#23545;&#20110;&#37325;&#23614;&#22122;&#22768;&#20998;&#24067;&#20173;&#28982;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
In stochastic zeroth-order optimization, a problem of practical relevance is understanding how to fully exploit the local geometry of the underlying objective function. We consider a fundamental setting in which the objective function is quadratic, and provide the first tight characterization of the optimal Hessian-dependent sample complexity. Our contribution is twofold. First, from an information-theoretic point of view, we prove tight lower bounds on Hessian-dependent complexities by introducing a concept called energy allocation, which captures the interaction between the searching algorithm and the geometry of objective functions. A matching upper bound is obtained by solving the optimal energy spectrum. Then, algorithmically, we show the existence of a Hessian-independent algorithm that universally achieves the asymptotic optimal sample complexities for all Hessian instances. The optimal sample complexities achieved by our algorithm remain valid for heavy-tailed noise distributio
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#31163;&#25955;&#25193;&#25955;&#26680;&#22914;&#20309;&#24433;&#21709;&#22270;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#32467;&#26524;&#34920;&#26126;&#36873;&#25321;&#27491;&#30830;&#30340;&#25910;&#25947;&#20808;&#39564;&#23545;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#29983;&#25104;&#24615;&#33021;&#33267;&#20851;&#37325;&#35201;&#12290;</title><link>http://arxiv.org/abs/2306.02957</link><description>&lt;p&gt;
&#31163;&#25955;&#22270;&#25193;&#25955;&#20013;&#19981;&#21516;&#25910;&#25947;&#20808;&#39564;&#30340;&#22797;&#26434;&#20559;&#22909;
&lt;/p&gt;
&lt;p&gt;
Complex Preferences for Different Convergent Priors in Discrete Graph Diffusion. (arXiv:2306.02957v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02957
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#31163;&#25955;&#25193;&#25955;&#26680;&#22914;&#20309;&#24433;&#21709;&#22270;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#32467;&#26524;&#34920;&#26126;&#36873;&#25321;&#27491;&#30830;&#30340;&#25910;&#25947;&#20808;&#39564;&#23545;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#29983;&#25104;&#24615;&#33021;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#24050;&#32463;&#21462;&#24471;&#20102;&#22312;&#29983;&#25104;&#35768;&#22810;&#19981;&#21516;&#31867;&#22411;&#30340;&#25968;&#25454;&#65292;&#21253;&#25324;&#22270;&#20687;&#12289;&#25991;&#26412;&#21644;&#35270;&#39057;&#26041;&#38754;&#30340;&#26368;&#20808;&#36827;&#34920;&#29616;&#12290;&#23613;&#31649;&#23427;&#20204;&#24456;&#25104;&#21151;&#65292;&#20294;&#23545;&#20110;&#22522;&#30784;&#25193;&#25955;&#36807;&#31243;&#21644;&#26368;&#32456;&#25910;&#25947;&#20808;&#39564;&#22914;&#20309;&#24433;&#21709;&#29983;&#25104;&#30340;&#24615;&#33021;&#36827;&#34892;&#30340;&#30740;&#31350;&#26377;&#38480;&#65307;&#27492;&#30740;&#31350;&#20063;&#20165;&#38480;&#20110;&#36830;&#32493;&#25968;&#25454;&#31867;&#22411;&#21644;&#22522;&#20110;&#20998;&#25968;&#30340;&#25193;&#25955;&#26694;&#26550;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#19981;&#21516;&#31163;&#25955;&#25193;&#25955;&#26680;&#65288;&#25910;&#25947;&#21040;&#19981;&#21516;&#30340;&#20808;&#39564;&#20998;&#24067;&#65289;&#22914;&#20309;&#24433;&#21709;&#22270;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#31163;&#25955;&#25193;&#25955;&#26680;&#31995;&#21015;&#20844;&#24335;&#65292;&#21487;&#20197;&#36731;&#26494;&#35843;&#25972;&#20197;&#25910;&#25947;&#21040;&#19981;&#21516;&#30340;&#20271;&#21162;&#21033;&#20808;&#39564;&#65292;&#24182;&#30740;&#31350;&#36825;&#20123;&#19981;&#21516;&#30340;&#26680;&#23545;&#29983;&#25104;&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#29983;&#25104;&#30340;&#22270;&#30340;&#36136;&#37327;&#23545;&#20351;&#29992;&#30340;&#20808;&#39564;&#24456;&#25935;&#24863;&#65292;&#26368;&#20248;&#36873;&#25321;&#19981;&#33021;&#29992;&#26126;&#26174;&#30340;&#32479;&#35745;&#25968;&#25454;&#25110;&#25351;&#26631;&#26469;&#35299;&#37322;&#65292;&#36825;&#25361;&#25112;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#30452;&#35273;&#20551;&#35774;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#31163;&#25955;&#25968;&#25454;&#19978;&#65292;&#36873;&#25321;&#27491;&#30830;&#30340;&#25910;&#25947;&#20808;&#39564;&#23545;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#29983;&#25104;&#24615;&#33021;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models have achieved state-of-the-art performance in generating many different kinds of data, including images, text, and videos. Despite their success, there has been limited research on how the underlying diffusion process and the final convergent prior can affect generative performance; this research has also been limited to continuous data types and a score-based diffusion framework. To fill this gap, we explore how different discrete diffusion kernels (which converge to different prior distributions) affect the performance of diffusion models for graphs. To this end, we developed a novel formulation of a family of discrete diffusion kernels which are easily adjustable to converge to different Bernoulli priors, and we study the effect of these different kernels on generative performance. We show that the quality of generated graphs is sensitive to the prior used, and that the optimal choice cannot be explained by obvious statistics or metrics, which challenges the intuiti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#20195;&#25968;&#35780;&#20272;&#22120;&#26469;&#20272;&#35745;&#26410;&#26631;&#35760;&#25968;&#25454;&#20013;&#26377;&#22122;&#22768;&#20108;&#20803;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#12290;&#20854;&#20013;&#65292;&#31532;&#20108;&#31181;&#35780;&#20272;&#22120;&#30340;&#27491;&#30830;&#24615;&#34987;&#20445;&#35777;&#12290;&#20316;&#32773;&#36890;&#36807;&#21033;&#29992;&#29420;&#31435;&#35780;&#20272;&#22120;&#26080;&#27861;&#36820;&#22238;&#21512;&#29702;&#20272;&#35745;&#30340;&#22833;&#36133;&#65292;&#32531;&#35299;&#20102;&#22996;&#25176;/&#20195;&#29702;&#30417;&#25511;&#24726;&#35770;&#65292;&#24182;&#36890;&#36807;&#25628;&#32034;&#26469;&#23547;&#25214;&#20960;&#20046;&#26080;&#35823;&#24046;&#30340;&#19977;&#20803;&#32452;&#12290;</title><link>http://arxiv.org/abs/2306.01726</link><description>&lt;p&gt;
&#35780;&#20272;&#26377;&#22122;&#22768;&#21028;&#21035;&#22120;&#23545;&#26410;&#26631;&#35760;&#25968;&#25454;&#30340;&#27969;&#24335;&#31639;&#27861; -- &#20108;&#20803;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Streaming algorithms for evaluating noisy judges on unlabeled data -- binary classification. (arXiv:2306.01726v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01726
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#20195;&#25968;&#35780;&#20272;&#22120;&#26469;&#20272;&#35745;&#26410;&#26631;&#35760;&#25968;&#25454;&#20013;&#26377;&#22122;&#22768;&#20108;&#20803;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#12290;&#20854;&#20013;&#65292;&#31532;&#20108;&#31181;&#35780;&#20272;&#22120;&#30340;&#27491;&#30830;&#24615;&#34987;&#20445;&#35777;&#12290;&#20316;&#32773;&#36890;&#36807;&#21033;&#29992;&#29420;&#31435;&#35780;&#20272;&#22120;&#26080;&#27861;&#36820;&#22238;&#21512;&#29702;&#20272;&#35745;&#30340;&#22833;&#36133;&#65292;&#32531;&#35299;&#20102;&#22996;&#25176;/&#20195;&#29702;&#30417;&#25511;&#24726;&#35770;&#65292;&#24182;&#36890;&#36807;&#25628;&#32034;&#26469;&#23547;&#25214;&#20960;&#20046;&#26080;&#35823;&#24046;&#30340;&#19977;&#20803;&#32452;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#23545;&#26410;&#26631;&#35760;&#25968;&#25454;&#20013;&#30340;&#26377;&#22122;&#22768;&#20108;&#20803;&#20998;&#31867;&#22120;&#30340;&#35780;&#20272;&#20316;&#20026;&#27969;&#24335;&#20219;&#21153;&#36827;&#34892;&#30740;&#31350;: &#32473;&#23450;&#19968;&#20010;&#20998;&#31867;&#22120;&#20915;&#31574;&#30340;&#25968;&#25454;&#33609;&#22270;&#65292;&#20272;&#35745;&#26631;&#31614;&#30340;&#30495;&#23454;&#27969;&#34892;&#24230;&#20197;&#21450;&#27599;&#20010;&#20998;&#31867;&#22120;&#23545;&#23427;&#20204;&#30340;&#20934;&#30830;&#24230;&#12290;&#26412;&#25991;&#26500;&#24314;&#20102;&#20004;&#31181;&#23436;&#20840;&#20195;&#25968;&#21270;&#30340;&#35780;&#20272;&#22120;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#12290;&#20004;&#31181;&#35780;&#20272;&#22120;&#37117;&#22522;&#20110;&#20998;&#31867;&#22120;&#20135;&#29983;&#29420;&#31435;&#38169;&#35823;&#30340;&#20551;&#35774;&#12290;&#31532;&#19968;&#31181;&#26159;&#22522;&#20110;&#22810;&#25968;&#25237;&#31080;&#30340;&#12290;&#32780;&#31532;&#20108;&#31181;&#21017;&#26159;&#26412;&#25991;&#30340;&#20027;&#35201;&#36129;&#29486;&#65292;&#24182;&#34987;&#20445;&#35777;&#26159;&#27491;&#30830;&#30340;&#12290;&#20294;&#26159;&#22914;&#20309;&#30830;&#20445;&#20998;&#31867;&#22120;&#22312;&#20219;&#20309;&#32473;&#23450;&#30340;&#27979;&#35797;&#20013;&#26159;&#29420;&#31435;&#30340;&#21602;&#65311;&#26412;&#25991;&#36890;&#36807;&#21033;&#29992;&#29420;&#31435;&#35780;&#20272;&#22120;&#26080;&#27861;&#36820;&#22238;&#21512;&#29702;&#20272;&#35745;&#30340;&#22833;&#36133;&#26469;&#32531;&#35299;&#36825;&#20010;&#22996;&#25176;/&#20195;&#29702;&#30417;&#25511;&#24726;&#35770;&#12290;&#36890;&#36807;&#21033;&#29992;&#20195;&#25968;&#25925;&#38556;&#27169;&#24335;&#26469;&#25298;&#32477;&#22826;&#30456;&#20851;&#30340;&#35780;&#20272;&#38598;&#21512;&#65292;&#20351;&#29992; \texttt{adult}&#65292;\texttt{mushroom} &#21644; \texttt{two-norm} &#25968;&#25454;&#38598;&#23545;&#19968;&#32452;&#20960;&#20046;&#26080;&#35823;&#24046;&#19977;&#20803;&#32452;&#36827;&#34892;&#20102;&#23454;&#35777;&#25628;&#32034;&#12290;&#36825;&#20123;&#25628;&#32034;&#36890;&#36807;&#26500;&#24314;&#35780;&#20272;&#31354;&#38388;&#20013;&#30340;&#34920;&#38754;&#26469;&#36827;&#34892;&#31934;&#32454;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
The evaluation of noisy binary classifiers on unlabeled data is treated as a streaming task: given a data sketch of the decisions by an ensemble, estimate the true prevalence of the labels as well as each classifier's accuracy on them. Two fully algebraic evaluators are constructed to do this. Both are based on the assumption that the classifiers make independent errors. The first is based on majority voting. The second, the main contribution of the paper, is guaranteed to be correct. But how do we know the classifiers are independent on any given test? This principal/agent monitoring paradox is ameliorated by exploiting the failures of the independent evaluator to return sensible estimates. A search for nearly error independent trios is empirically carried out on the \texttt{adult}, \texttt{mushroom}, and \texttt{two-norm} datasets by using the algebraic failure modes to reject evaluation ensembles as too correlated. The searches are refined by constructing a surface in evaluation spa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#33021;&#37327;&#22522;&#27169;&#22411;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#20351;&#29992;&#24402;&#19968;&#21270;&#27969;&#36827;&#34892;&#37319;&#26679;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#32479;&#35745;&#31934;&#24230;&#21644;&#29983;&#25104;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.00684</link><description>&lt;p&gt;
&#20351;&#29992;&#33258;&#36866;&#24212;&#27969;&#37319;&#26679;&#24179;&#34913;&#35757;&#32451;&#33021;&#37327;&#22522;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Balanced Training of Energy-Based Models with Adaptive Flow Sampling. (arXiv:2306.00684v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00684
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#33021;&#37327;&#22522;&#27169;&#22411;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#20351;&#29992;&#24402;&#19968;&#21270;&#27969;&#36827;&#34892;&#37319;&#26679;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#32479;&#35745;&#31934;&#24230;&#21644;&#29983;&#25104;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#37327;&#22522;&#27169;&#22411; (EBM) &#26159;&#19968;&#31181;&#30452;&#25509;&#21442;&#25968;&#21270;&#26410;&#26631;&#20934;&#21270;&#23545;&#25968;&#23494;&#24230;&#30340;&#22810;&#21151;&#33021;&#23494;&#24230;&#20272;&#35745;&#27169;&#22411;&#12290;EBM &#38750;&#24120;&#28789;&#27963;&#65292;&#20294;&#32570;&#20047;&#27169;&#22411;&#30340;&#35268;&#33539;&#21270;&#24120;&#37327;&#65292;&#20351;&#27169;&#22411;&#30340;&#20284;&#28982;&#20989;&#25968;&#35745;&#31639;&#19981;&#21487;&#34892;&#12290;&#36817;&#24180;&#26469;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#36817;&#20284;&#37319;&#26679;&#22120;&#21644;&#21464;&#20998;&#25512;&#29702;&#25216;&#26415;&#26469;&#20272;&#35745;&#20284;&#28982;&#20989;&#25968;&#26799;&#24230;&#36827;&#34892;&#35757;&#32451;&#12290;&#36825;&#20123;&#25216;&#26415;&#22312;&#29983;&#25104;&#26679;&#26412;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#23545;&#20110;&#20272;&#35745;&#23494;&#24230;&#30340;&#32479;&#35745;&#31934;&#24230;&#65292;&#20363;&#22914;&#30830;&#23450;&#25968;&#25454;&#38598;&#20013;&#19981;&#21516;&#31867;&#30340;&#30456;&#23545;&#37325;&#35201;&#24615;&#65292;&#21364;&#20184;&#20986;&#20102;&#24456;&#23569;&#30340;&#20851;&#27880;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26368;&#22823;&#20284;&#28982;&#35757;&#32451;&#31639;&#27861;&#65292;&#20351;&#29992;&#19968;&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#24402;&#19968;&#21270;&#27969; (NF)&#65292;&#36825;&#31181;&#27169;&#22411;&#26368;&#36817;&#34987;&#25552;&#20986;&#20197;&#20415;&#20110;&#37319;&#26679;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#23558; NF &#25311;&#21512;&#21040; EBM &#19978;&#65292;&#20197;&#20415; NF &#36741;&#21161;&#19979;&#30340;&#37319;&#26679;&#26041;&#26696;&#33021;&#22815;&#22987;&#32456;&#20026; EBM &#25552;&#20379;&#20934;&#30830;&#30340;&#26799;&#24230;&#65292;&#26368;&#32456;&#25552;&#39640;&#27169;&#22411;&#30340;&#32479;&#35745;&#31934;&#24230;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#20256;&#32479; EBM &#35757;&#32451;&#25216;&#26415;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20135;&#29983;&#20102;&#26356;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#21644;&#26356;&#22909;&#30340;&#29983;&#25104;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Energy-based models (EBMs) are versatile density estimation models that directly parameterize an unnormalized log density. Although very flexible, EBMs lack a specified normalization constant of the model, making the likelihood of the model computationally intractable. Several approximate samplers and variational inference techniques have been proposed to estimate the likelihood gradients for training. These techniques have shown promising results in generating samples, but little attention has been paid to the statistical accuracy of the estimated density, such as determining the relative importance of different classes in a dataset. In this work, we propose a new maximum likelihood training algorithm for EBMs that uses a different type of generative model, normalizing flows (NF), which have recently been proposed to facilitate sampling. Our method fits an NF to an EBM during training so that an NF-assisted sampling scheme provides an accurate gradient for the EBMs at all times, ultim
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21327;&#21464;&#37327;&#36716;&#31227;&#30340;&#20998;&#31867;&#26641;&#21098;&#26525;&#26041;&#27861;&#65292;&#21487;&#20197;&#35775;&#38382;&#22823;&#37096;&#20998;&#26469;&#33258;&#20998;&#24067; $P_{X&#65292;Y}$ &#30340;&#25968;&#25454;&#65292;&#20294;&#26159;&#21482;&#33021;&#33719;&#24471;&#26469;&#33258;&#25317;&#26377;&#19981;&#21516; $X$-&#36793;&#32536;&#30340;&#30446;&#26631;&#20998;&#24067; $Q_{X&#65292;Y}$ &#30340;&#23569;&#37327;&#25968;&#25454;&#12290;&#20351;&#29992;&#30340;&#20248;&#21270;&#26631;&#20934;&#26159;&#19968;&#20010;&#20851;&#20110;&#20998;&#24067; $P_{X} \to Q_{X}$ &#30340; \emph{&#24179;&#22343;&#24046;&#24322;}&#65292;&#35813;&#26631;&#20934;&#21487;&#20197;&#26174;&#33879;&#25918;&#23485;&#26368;&#36817;&#25552;&#20986;&#30340; \emph{&#36716;&#31227;&#25351;&#25968;}&#65292;&#26368;&#32456;&#21487;&#20197;&#24471;&#21040;&#26368;&#20248;&#30340;&#21098;&#26525;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.04335</link><description>&lt;p&gt;
&#22522;&#20110;&#21327;&#21464;&#37327;&#36716;&#31227;&#30340;&#20998;&#31867;&#26641;&#21098;&#26525;
&lt;/p&gt;
&lt;p&gt;
Classification Tree Pruning Under Covariate Shift. (arXiv:2305.04335v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04335
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21327;&#21464;&#37327;&#36716;&#31227;&#30340;&#20998;&#31867;&#26641;&#21098;&#26525;&#26041;&#27861;&#65292;&#21487;&#20197;&#35775;&#38382;&#22823;&#37096;&#20998;&#26469;&#33258;&#20998;&#24067; $P_{X&#65292;Y}$ &#30340;&#25968;&#25454;&#65292;&#20294;&#26159;&#21482;&#33021;&#33719;&#24471;&#26469;&#33258;&#25317;&#26377;&#19981;&#21516; $X$-&#36793;&#32536;&#30340;&#30446;&#26631;&#20998;&#24067; $Q_{X&#65292;Y}$ &#30340;&#23569;&#37327;&#25968;&#25454;&#12290;&#20351;&#29992;&#30340;&#20248;&#21270;&#26631;&#20934;&#26159;&#19968;&#20010;&#20851;&#20110;&#20998;&#24067; $P_{X} \to Q_{X}$ &#30340; \emph{&#24179;&#22343;&#24046;&#24322;}&#65292;&#35813;&#26631;&#20934;&#21487;&#20197;&#26174;&#33879;&#25918;&#23485;&#26368;&#36817;&#25552;&#20986;&#30340; \emph{&#36716;&#31227;&#25351;&#25968;}&#65292;&#26368;&#32456;&#21487;&#20197;&#24471;&#21040;&#26368;&#20248;&#30340;&#21098;&#26525;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#35757;&#32451;&#25968;&#25454;&#19981;&#22343;&#21248;&#30340;&#24773;&#20917;&#19979;&#65292;&#36873;&#25321;&#36866;&#24403;&#30340;&#23376;&#26641;&#20197;&#24179;&#34913;&#20559;&#24046;&#21644;&#26041;&#24046;&#30340;&#20998;&#31867;&#26641;&#21098;&#26525;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#36825;&#31181;&#24773;&#20917;&#30340;&#26368;&#20248;&#21098;&#26525;&#30340;&#39640;&#25928;&#31243;&#24207;&#65292;&#35813;&#31243;&#24207;&#21487;&#20197;&#35775;&#38382;&#22823;&#37096;&#20998;&#26469;&#33258;&#20998;&#24067; $P_{X&#65292;Y}$ &#30340;&#25968;&#25454;&#65292;&#20294;&#26159;&#21482;&#33021;&#33719;&#24471;&#26469;&#33258;&#25317;&#26377;&#19981;&#21516; $X$-&#36793;&#32536;&#30340;&#30446;&#26631;&#20998;&#24067; $Q_{X&#65292;Y}$ &#30340;&#23569;&#37327;&#25968;&#25454;&#12290;&#22312;&#22522;&#26412;&#20132;&#21449;&#39564;&#35777;&#21644;&#20854;&#20182;&#36827;&#34892;&#24809;&#32602;&#30340;&#21464;&#20307;&#65292;&#22914;&#22522;&#20110;&#20449;&#24687;&#24230;&#37327;&#30340;&#21098;&#26525;&#26041;&#27861;&#38750;&#24120;&#19981;&#29702;&#24819;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26368;&#20248;&#21098;&#26525;&#30340;&#26041;&#27861;&#12290;&#20351;&#29992;&#30340;&#20248;&#21270;&#26631;&#20934;&#26159;&#19968;&#20010;&#20851;&#20110;&#20998;&#24067; $P_{X} \to Q_{X}$ &#30340; \emph{&#24179;&#22343;&#24046;&#24322;}&#65288;&#22312; $X$ &#31354;&#38388;&#19978;&#24179;&#22343;&#65289;&#65292;&#35813;&#26631;&#20934;&#21487;&#20197;&#26174;&#33879;&#25918;&#23485;&#26368;&#36817;&#25552;&#20986;&#30340; \emph{&#36716;&#31227;&#25351;&#25968;} &#36825;&#19968;&#32479;&#35745;&#23398;&#27010;&#24565;&#65292;&#35813;&#27010;&#24565;&#34987;&#35777;&#26126;&#33021;&#22815;&#32039;&#23494;&#22320;&#25429;&#25417;&#36825;&#31181;&#20998;&#24067;&#36716;&#31227;&#24773;&#20917;&#19979;&#20998;&#31867;&#30340;&#26497;&#38480;&#38480;&#21046;&#12290;&#25105;&#20204;&#25918;&#23485;&#30340;&#26631;&#20934;&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#20998;&#24067;&#20043;&#38388;&#30340;\emph{&#30456;&#23545;&#32500;&#24230;}&#24230;&#37327;&#65292;&#22240;&#20026;&#23427;&#28041;&#21450;&#21040;&#20449;&#24687;&#30340;&#29616;&#26377;&#24230;&#37327;&#27010;&#24565;&#65292;&#20363;&#22914;&#38389;&#21487;&#22827;&#26031;&#22522;&#21644;R&#233;nyi&#32500;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of \emph{pruning} a classification tree, that is, selecting a suitable subtree that balances bias and variance, in common situations with inhomogeneous training data. Namely, assuming access to mostly data from a distribution $P_{X, Y}$, but little data from a desired distribution $Q_{X, Y}$ with different $X$-marginals, we present the first efficient procedure for optimal pruning in such situations, when cross-validation and other penalized variants are grossly inadequate. Optimality is derived with respect to a notion of \emph{average discrepancy} $P_{X} \to Q_{X}$ (averaged over $X$ space) which significantly relaxes a recent notion -- termed \emph{transfer-exponent} -- shown to tightly capture the limits of classification under such a distribution shift. Our relaxed notion can be viewed as a measure of \emph{relative dimension} between distributions, as it relates to existing notions of information such as the Minkowski and Renyi dimensions.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#25104;&#23545;&#27604;&#36739;&#35774;&#35745;&#30340;&#38543;&#26426;&#26679;&#26412;&#30340;&#32447;&#24615;&#22238;&#24402;&#30340;&#23545;&#31216;&#28151;&#21512;&#65292;&#36890;&#36807;&#20998;&#26512;EM&#31639;&#27861;&#30340;&#24207;&#21015;&#25910;&#25947;&#24615;&#21644;&#26497;&#38480;&#20540;&#65292;&#24471;&#20986;&#20102;$\ell_\infty$&#33539;&#25968;&#21644;$\ell_2$&#33539;&#25968;&#20013;&#30340;&#20272;&#35745;&#23574;&#38160;&#24230;&#12290;&#30740;&#31350;&#34920;&#26126;EM&#31639;&#27861;&#21487;&#20197;&#23637;&#29616;&#20986;&#22810;&#20010;&#29420;&#29305;&#30340;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2302.10066</link><description>&lt;p&gt;
&#23398;&#20064;&#25104;&#23545;&#24046;&#20998;&#28151;&#21512;&#30340;EM&#31639;&#27861;&#30340;&#23574;&#38160;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sharp analysis of EM for learning mixtures of pairwise differences. (arXiv:2302.10066v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10066
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#25104;&#23545;&#27604;&#36739;&#35774;&#35745;&#30340;&#38543;&#26426;&#26679;&#26412;&#30340;&#32447;&#24615;&#22238;&#24402;&#30340;&#23545;&#31216;&#28151;&#21512;&#65292;&#36890;&#36807;&#20998;&#26512;EM&#31639;&#27861;&#30340;&#24207;&#21015;&#25910;&#25947;&#24615;&#21644;&#26497;&#38480;&#20540;&#65292;&#24471;&#20986;&#20102;$\ell_\infty$&#33539;&#25968;&#21644;$\ell_2$&#33539;&#25968;&#20013;&#30340;&#20272;&#35745;&#23574;&#38160;&#24230;&#12290;&#30740;&#31350;&#34920;&#26126;EM&#31639;&#27861;&#21487;&#20197;&#23637;&#29616;&#20986;&#22810;&#20010;&#29420;&#29305;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#25104;&#23545;&#27604;&#36739;&#35774;&#35745;&#30340;&#38543;&#26426;&#26679;&#26412;&#30340;&#32447;&#24615;&#22238;&#24402;&#30340;&#23545;&#31216;&#28151;&#21512;&#65292;&#36825;&#21487;&#20197;&#30475;&#20316;&#26159;&#19968;&#31181;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#20960;&#20309;&#38382;&#39064;&#30340;&#22122;&#22768;&#29256;&#26412;&#12290;&#25105;&#20204;&#22312;&#30495;&#23454;&#20540;&#21608;&#22260;&#23616;&#37096;&#20998;&#26512;&#26399;&#26395;&#26368;&#22823;&#21270;&#65288;EM&#65289;&#31639;&#27861;&#65292;&#24182;&#24314;&#31435;&#36215;&#23427;&#30340;&#24207;&#21015;&#32447;&#24615;&#25910;&#25947;&#24615;&#65292;&#20174;&#32780;&#20026;&#36845;&#20195;&#20272;&#35745;&#35823;&#24046;&#25552;&#20379;&#19968;&#20010;$\ell_\infty$-&#33539;&#25968;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;EM&#24207;&#21015;&#30340;&#26497;&#38480;&#23454;&#29616;&#20102;&#22312;$\ell_2$-&#33539;&#25968;&#20013;&#30340;&#20272;&#35745;&#23574;&#38160;&#24230;&#65292;&#21305;&#37197;&#20449;&#24687;&#29702;&#35770;&#19978;&#26368;&#20248;&#30340;&#24120;&#25968;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#27169;&#25311;&#35770;&#35777;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20174;&#38543;&#26426;&#21021;&#22987;&#21270;&#25910;&#25947;&#30340;&#38382;&#39064;&#26356;&#20026;&#24494;&#22937;&#65292;&#36890;&#24120;&#19981;&#20250;&#21457;&#29983;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#24403;&#21327;&#21464;&#37327;&#20998;&#24067;&#34987;&#36866;&#24403;&#22320;&#32467;&#26500;&#21270;&#26102;&#65292;EM&#31639;&#27861;&#21487;&#20197;&#34920;&#29616;&#20986;&#20960;&#20010;&#29420;&#29305;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a symmetric mixture of linear regressions with random samples from the pairwise comparison design, which can be seen as a noisy version of a type of Euclidean distance geometry problem. We analyze the expectation-maximization (EM) algorithm locally around the ground truth and establish that the sequence converges linearly, providing an $\ell_\infty$-norm guarantee on the estimation error of the iterates. Furthermore, we show that the limit of the EM sequence achieves the sharp rate of estimation in the $\ell_2$-norm, matching the information-theoretically optimal constant. We also argue through simulation that convergence from a random initialization is much more delicate in this setting, and does not appear to occur in general. Our results show that the EM algorithm can exhibit several unique behaviors when the covariate distribution is suitably structured.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#21333;&#26102;&#38388;&#35268;&#27169;&#30340;&#31639;&#27861;&#65306;Prox-DASA&#21644;Prox-DASA-GT&#65292;&#23427;&#20204;&#21487;&#20197;&#29992;&#24120;&#37327;&#25209;&#37327;&#22823;&#23567;&#25214;&#21040;&#22797;&#21512;&#30446;&#26631;&#20989;&#25968;&#30340;$\epsilon$-&#38745;&#27490;&#28857;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#22823;&#25209;&#37327;&#22823;&#23567;&#12289;&#26356;&#22797;&#26434;&#30340;&#25805;&#20316;&#25110;&#26356;&#24378;&#30340;&#20551;&#35774;&#12290;</title><link>http://arxiv.org/abs/2302.09766</link><description>&lt;p&gt;
&#19968;&#31181;&#21333;&#26679;&#26412;&#21435;&#20013;&#24515;&#21270;&#36817;&#31471;&#31639;&#27861;&#29992;&#20110;&#38750;&#20984;&#38543;&#26426;&#22797;&#21512;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
A One-Sample Decentralized Proximal Algorithm for Non-Convex Stochastic Composite Optimization. (arXiv:2302.09766v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09766
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#21333;&#26102;&#38388;&#35268;&#27169;&#30340;&#31639;&#27861;&#65306;Prox-DASA&#21644;Prox-DASA-GT&#65292;&#23427;&#20204;&#21487;&#20197;&#29992;&#24120;&#37327;&#25209;&#37327;&#22823;&#23567;&#25214;&#21040;&#22797;&#21512;&#30446;&#26631;&#20989;&#25968;&#30340;$\epsilon$-&#38745;&#27490;&#28857;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#22823;&#25209;&#37327;&#22823;&#23567;&#12289;&#26356;&#22797;&#26434;&#30340;&#25805;&#20316;&#25110;&#26356;&#24378;&#30340;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21435;&#20013;&#24515;&#21270;&#38543;&#26426;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;$n$&#20010;&#20195;&#29702;&#20849;&#21516;&#20248;&#21270;&#30001;&#20809;&#28369;&#39033;&#21644;&#38750;&#20809;&#28369;&#20984;&#39033;&#30456;&#21152;&#30340;&#22797;&#21512;&#30446;&#26631;&#20989;&#25968;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#21333;&#26102;&#38388;&#35268;&#27169;&#31639;&#27861;&#65306;Prox-DASA&#21644;Prox-DASA-GT&#12290;&#36825;&#20123;&#31639;&#27861;&#21487;&#20197;&#20351;&#29992;&#24120;&#37327;&#25209;&#37327;&#22823;&#23567;&#65288;&#21363;$\mathcal{O}(1)$&#65289;&#22312;$\mathcal{O}(n^{-1}\epsilon^{-2})$&#27425;&#36845;&#20195;&#20013;&#25214;&#21040;$\epsilon$-&#38745;&#27490;&#28857;&#12290;&#19982;&#20197;&#21069;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#19981;&#38656;&#35201;&#22823;&#25209;&#37327;&#22823;&#23567;&#12289;&#26356;&#22797;&#26434;&#30340;&#27599;&#27425;&#36845;&#20195;&#25805;&#20316;&#65288;&#22914;&#21452;&#37325;&#24490;&#29615;&#65289;&#25110;&#26356;&#24378;&#30340;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#21487;&#27604;&#25311;&#30340;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#24471;&#21040;&#20102;&#24191;&#27867;&#30340;&#25968;&#20540;&#23454;&#39564;&#25903;&#25345;&#65292;&#36825;&#20123;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#20248;&#20110;&#20197;&#21069;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#21487;&#22312;https://github.com/xuxingc/ProxDASA&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
We focus on decentralized stochastic non-convex optimization, where $n$ agents work together to optimize a composite objective function which is a sum of a smooth term and a non-smooth convex term. To solve this problem, we propose two single-time scale algorithms: Prox-DASA and Prox-DASA-GT. These algorithms can find $\epsilon$-stationary points in $\mathcal{O}(n^{-1}\epsilon^{-2})$ iterations using constant batch sizes (i.e., $\mathcal{O}(1)$). Unlike prior work, our algorithms achieve comparable complexity without requiring large batch sizes, more complex per-iteration operations (such as double loops), or stronger assumptions. Our theoretical findings are supported by extensive numerical experiments, which demonstrate the superiority of our algorithms over previous approaches. Our code is available at https://github.com/xuxingc/ProxDASA.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29420;&#31435;&#32447;&#24615;Markov&#21338;&#24328;&#27169;&#22411;&#65292;&#38024;&#23545;&#22810;&#26234;&#20307;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#22823;&#29366;&#24577;&#31354;&#38388;&#21644;&#22823;&#37327;&#20195;&#29702;&#38382;&#39064;&#65292;&#35774;&#35745;&#20102;&#26032;&#31639;&#27861;&#20197;&#23398;&#20064;Markov&#31895;&#30053;&#30456;&#20851;&#22343;&#34913;&#21644;Markov&#30456;&#20851;&#22343;&#34913;&#12290;&#30456;&#27604;&#20110;&#29616;&#26377;&#30340;Markov&#21338;&#24328;&#20989;&#25968;&#36924;&#36817;&#25216;&#26415;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#22823;&#22823;&#38477;&#20302;&#26679;&#26412;&#22797;&#26434;&#24230;&#24182;&#21462;&#24471;&#26356;&#39640;&#30340;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2302.03673</link><description>&lt;p&gt;
&#22312;&#22823;&#29366;&#24577;&#31354;&#38388;&#20013;&#25171;&#30772;&#22810;&#26234;&#20307;&#30340;&#35781;&#21650;&#65306;&#24102;&#29420;&#31435;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;Markov&#21338;&#24328;&#20013;&#30340;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Breaking the Curse of Multiagents in a Large State Space: RL in Markov Games with Independent Linear Function Approximation. (arXiv:2302.03673v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03673
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29420;&#31435;&#32447;&#24615;Markov&#21338;&#24328;&#27169;&#22411;&#65292;&#38024;&#23545;&#22810;&#26234;&#20307;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#22823;&#29366;&#24577;&#31354;&#38388;&#21644;&#22823;&#37327;&#20195;&#29702;&#38382;&#39064;&#65292;&#35774;&#35745;&#20102;&#26032;&#31639;&#27861;&#20197;&#23398;&#20064;Markov&#31895;&#30053;&#30456;&#20851;&#22343;&#34913;&#21644;Markov&#30456;&#20851;&#22343;&#34913;&#12290;&#30456;&#27604;&#20110;&#29616;&#26377;&#30340;Markov&#21338;&#24328;&#20989;&#25968;&#36924;&#36817;&#25216;&#26415;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#22823;&#22823;&#38477;&#20302;&#26679;&#26412;&#22797;&#26434;&#24230;&#24182;&#21462;&#24471;&#26356;&#39640;&#30340;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;&#8212;&#8212;&#29420;&#31435;&#32447;&#24615;Markov&#21338;&#24328;&#65292;&#29992;&#20110;&#20855;&#26377;&#22823;&#29366;&#24577;&#31354;&#38388;&#21644;&#22823;&#37327;&#20195;&#29702;&#30340;&#22810;&#26234;&#20307;&#24378;&#21270;&#23398;&#20064;&#12290;&#36825;&#26159;&#19968;&#31867;&#24102;&#26377;&#29420;&#31435;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;Markov&#21338;&#24328;&#65292;&#27599;&#20010;&#20195;&#29702;&#37117;&#26377;&#33258;&#24049;&#30340;&#20989;&#25968;&#36924;&#36817;&#65292;&#29992;&#20110;&#34987;&#20854;&#20182;&#29609;&#23478;&#30340;&#31574;&#30053;&#36793;&#32536;&#21270;&#30340;&#29366;&#24577;-&#21160;&#20316;&#20540;&#20989;&#25968;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#23398;&#20064;Markov&#31895;&#30053;&#30456;&#20851;&#22343;&#34913;&#21644;Markov&#30456;&#20851;&#22343;&#34913;&#30340;&#26032;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#20165;&#19982;&#27599;&#20010;&#20195;&#29702;&#33258;&#24049;&#30340;&#20989;&#25968;&#31867;&#22797;&#26434;&#24230;&#25104;&#22810;&#39033;&#24335;&#27604;&#20363;&#65292;&#20174;&#32780;&#25171;&#30772;&#20102;&#22810;&#26234;&#20307;&#30340;&#35781;&#21650;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#29616;&#26377;&#30340;&#29992;&#20110;&#20989;&#25968;&#36924;&#36817;&#30340;Markov&#21338;&#24328;&#30340;&#30740;&#31350;&#65292;&#22312;&#29305;&#21270;&#20110;&#26631;&#20934;&#34920;&#26684;&#29366;&#20917;&#30340;Markov&#21338;&#24328;&#35774;&#32622;&#26102;&#65292;&#20854;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#20250;&#38543;&#30528;\emph{&#32852;&#21512;&#34892;&#21160;&#31354;&#38388;}&#30340;&#22823;&#23567;&#25104;&#25351;&#25968;&#32423;&#22686;&#38271;&#65292;&#32780;&#35813;&#32852;&#21512;&#34892;&#21160;&#31354;&#38388;&#22312;&#20195;&#29702;&#30340;&#25968;&#37327;&#19978;&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20381;&#36182;&#20110;&#20004;&#20010;&#20851;&#38190;&#30340;&#25216;&#26415;&#21019;&#26032;&#65306;(1) &#21033;&#29992;&#31574;&#30053;&#37325;&#25918;&#26469;&#38477;&#20302;&#26679;&#26412;&#22797;&#26434;&#24230;&#65307;(2) &#21033;&#29992;&#29420;&#31435;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#26469;&#33719;&#24471;&#35745;&#31639;&#19978;&#30340;&#26377;&#25928;&#24615;&#21644;&#32479;&#35745;&#19978;&#30340;&#39640;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new model, independent linear Markov game, for multi-agent reinforcement learning with a large state space and a large number of agents. This is a class of Markov games with independent linear function approximation, where each agent has its own function approximation for the state-action value functions that are marginalized by other players' policies. We design new algorithms for learning the Markov coarse correlated equilibria (CCE) and Markov correlated equilibria (CE) with sample complexity bounds that only scale polynomially with each agent's own function class complexity, thus breaking the curse of multiagents. In contrast, existing works for Markov games with function approximation have sample complexity bounds scale with the size of the \emph{joint action space} when specialized to the canonical tabular Markov game setting, which is exponentially large in the number of agents. Our algorithms rely on two key technical innovations: (1) utilizing policy replay to tac
&lt;/p&gt;</description></item><item><title>scikit-fda&#26159;&#19968;&#20010;&#29992;&#20110;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#30340;Python&#21253;&#65292;&#25552;&#20379;&#20102;&#20840;&#38754;&#30340;&#24037;&#20855;&#65292;&#24182;&#20110;scikit-learn&#20860;&#23481;&#65292;&#37319;&#29992;&#19977;&#26465;&#27454;BSD&#35768;&#21487;&#35777;&#21457;&#24067;&#65292;&#23545;FDA&#31038;&#21306;&#36129;&#29486;&#24320;&#25918;&#12290;</title><link>http://arxiv.org/abs/2211.02566</link><description>&lt;p&gt;
scikit-fda&#65306;&#29992;&#20110;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#30340;Python&#21253;
&lt;/p&gt;
&lt;p&gt;
scikit-fda: A Python Package for Functional Data Analysis. (arXiv:2211.02566v2 [stat.CO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.02566
&lt;/p&gt;
&lt;p&gt;
scikit-fda&#26159;&#19968;&#20010;&#29992;&#20110;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#30340;Python&#21253;&#65292;&#25552;&#20379;&#20102;&#20840;&#38754;&#30340;&#24037;&#20855;&#65292;&#24182;&#20110;scikit-learn&#20860;&#23481;&#65292;&#37319;&#29992;&#19977;&#26465;&#27454;BSD&#35768;&#21487;&#35777;&#21457;&#24067;&#65292;&#23545;FDA&#31038;&#21306;&#36129;&#29486;&#24320;&#25918;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24211;scikit-fda&#26159;&#29992;&#20110;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#65288;FDA&#65289;&#30340;Python&#36719;&#20214;&#21253;&#12290;&#23427;&#25552;&#20379;&#20102;&#19968;&#22871;&#20840;&#38754;&#30340;&#24037;&#20855;&#65292;&#29992;&#20110;&#20989;&#25968;&#25968;&#25454;&#30340;&#34920;&#31034;&#12289;&#39044;&#22788;&#29702;&#21644;&#25506;&#32034;&#24615;&#20998;&#26512;&#12290;&#35813;&#24211;&#24314;&#31435;&#22312;Python&#31185;&#23398;&#35745;&#31639;&#29983;&#24577;&#31995;&#32479;&#20043;&#19978;&#65292;&#29305;&#21035;&#26159;&#37319;&#29992;&#20102;scikit-learn&#24212;&#29992;&#31243;&#24207;&#25509;&#21475;&#65292;&#20197;&#21033;&#29992;&#35813;&#36719;&#20214;&#21253;&#25552;&#20379;&#30340;&#26426;&#22120;&#23398;&#20064;&#21151;&#33021;&#65306;&#21253;&#25324;&#31649;&#36947;&#12289;&#27169;&#22411;&#36873;&#25321;&#21644;&#36229;&#21442;&#25968;&#35843;&#25972;&#31561;&#12290;&#36825;&#20010;scikit-fda&#36719;&#20214;&#21253;&#24050;&#32463;&#20197;&#19977;&#26465;&#27454;BSD&#35768;&#21487;&#35777;&#30340;&#24418;&#24335;&#21457;&#24067;&#20026;&#33258;&#30001;&#21644;&#24320;&#28304;&#36719;&#20214;&#65292;&#24182;&#23545;FDA&#31038;&#21306;&#30340;&#36129;&#29486;&#25345;&#24320;&#25918;&#24577;&#24230;&#12290;&#35813;&#24211;&#30340;&#24191;&#27867;&#25991;&#26723;&#21253;&#25324;&#36880;&#27493;&#25945;&#31243;&#21644;&#35814;&#32454;&#30340;&#20351;&#29992;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
The library scikit-fda is a Python package for Functional Data Analysis (FDA). It provides a comprehensive set of tools for representation, preprocessing, and exploratory analysis of functional data. The library is built upon and integrated in Python's scientific ecosystem. In particular, it conforms to the scikit-learn application programming interface so as to take advantage of the functionality for machine learning provided by this package: pipelines, model selection, and hyperparameter tuning, among others. The scikit-fda package has been released as free and open-source software under a 3-Clause BSD license and is open to contributions from the FDA community. The library's extensive documentation includes step-by-step tutorials and detailed examples of use.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;Dirichlet&#24418;&#24335;&#30340;Mosco&#25910;&#25947;&#24615;&#20998;&#26512;&#20102;&#22312;&#22823;&#22270;&#19978;&#30340;&#38543;&#26426;&#28216;&#36208;Metropolis&#65288;RWM&#65289;&#31639;&#27861;&#65292;&#35777;&#26126;&#20102;RWM&#31639;&#27861;&#30340;&#26368;&#20248;&#27604;&#20363;&#32553;&#25918;&#20855;&#26377;&#25910;&#25947;&#24615;&#65292;&#23558;&#24050;&#30693;&#30340;&#20960;&#20010;&#32467;&#26524;&#25512;&#24191;&#21040;&#20102;&#22823;&#22270;&#19978;&#30340;&#20381;&#36182;&#30446;&#26631;&#20998;&#24067;&#30340;&#24773;&#20917;&#65292;&#24182;&#20026;&#22823;&#22270;&#19978;&#30340;MCMC&#31639;&#27861;&#24320;&#36767;&#20102;&#35768;&#22810;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;</title><link>http://arxiv.org/abs/2210.17042</link><description>&lt;p&gt;
&#20381;&#36182;&#20110;&#22823;&#22270;&#30340;MCMC&#26368;&#20248;&#27604;&#20363;&#32553;&#25918;&#30340;Dirichlet&#24418;&#24335;&#30340;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Convergence of Dirichlet Forms for MCMC Optimal Scaling with Dependent Target Distributions on Large Graphs. (arXiv:2210.17042v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.17042
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;Dirichlet&#24418;&#24335;&#30340;Mosco&#25910;&#25947;&#24615;&#20998;&#26512;&#20102;&#22312;&#22823;&#22270;&#19978;&#30340;&#38543;&#26426;&#28216;&#36208;Metropolis&#65288;RWM&#65289;&#31639;&#27861;&#65292;&#35777;&#26126;&#20102;RWM&#31639;&#27861;&#30340;&#26368;&#20248;&#27604;&#20363;&#32553;&#25918;&#20855;&#26377;&#25910;&#25947;&#24615;&#65292;&#23558;&#24050;&#30693;&#30340;&#20960;&#20010;&#32467;&#26524;&#25512;&#24191;&#21040;&#20102;&#22823;&#22270;&#19978;&#30340;&#20381;&#36182;&#30446;&#26631;&#20998;&#24067;&#30340;&#24773;&#20917;&#65292;&#24182;&#20026;&#22823;&#22270;&#19978;&#30340;MCMC&#31639;&#27861;&#24320;&#36767;&#20102;&#35768;&#22810;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Markov Chain Monte Carlo (MCMC)&#31639;&#27861;&#22312;&#32479;&#35745;&#23398;&#12289;&#29289;&#29702;&#23398;&#12289;&#26426;&#22120;&#23398;&#20064;&#31561;&#26041;&#38754;&#21457;&#25381;&#20102;&#37325;&#35201;&#20316;&#29992;&#65292;&#24182;&#19988;&#23545;&#20110;&#19968;&#20123;&#39640;&#32500;&#38382;&#39064;&#65292;&#23427;&#20204;&#26159;&#21807;&#19968;&#24050;&#30693;&#30340;&#36890;&#29992;&#21644;&#26377;&#25928;&#30340;&#26041;&#27861;&#12290;&#26412;&#25991;&#21033;&#29992;Dirichlet&#24418;&#24335;&#30340;Mosco&#25910;&#25947;&#24615;&#20998;&#26512;&#20102;&#22312;&#22823;&#22270;&#19978;&#30340;&#38543;&#26426;&#28216;&#36208;Metropolis&#65288;RWM&#65289;&#31639;&#27861;&#65292;&#20854;&#30446;&#26631;&#20998;&#24067;&#26159;&#21253;&#25324;&#20219;&#20309;&#28385;&#36275;Markov&#24615;&#36136;&#30340;&#27010;&#29575;&#27979;&#24230;&#30340;Gibbs&#27979;&#24230;&#12290;Dirichlet&#24418;&#24335;&#30340;&#25277;&#35937;&#19988;&#24378;&#22823;&#30340;&#29702;&#35770;&#20351;&#25105;&#20204;&#33021;&#22815;&#30452;&#25509;&#21644;&#33258;&#28982;&#22320;&#22312;&#26080;&#38480;&#32500;&#31354;&#38388;&#19978;&#24037;&#20316;&#65292;&#25105;&#20204;&#30340;Mosco&#25910;&#25947;&#24615;&#27010;&#24565;&#20801;&#35768;&#19982;RWM&#38142;&#30456;&#20851;&#32852;&#30340;Dirichlet&#24418;&#24335;&#20301;&#20110;&#21464;&#21270;&#30340;&#22270;&#24207;&#21015;&#19978;&#65292;&#20854;&#20013;&#22270;&#30340;&#22823;&#23567;&#21487;&#20197;&#26159;&#26080;&#30028;&#30340;&#65292;&#22270;&#21487;&#20197;&#26159;&#30456;&#20851;&#30340;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#24378;&#31354;&#38388;&#20381;&#36182;&#24615;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;RWM&#31639;&#27861;&#30340;&#26368;&#20248;&#27604;&#20363;&#32553;&#25918;&#20855;&#26377;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#23558;&#24050;&#30693;&#30340;&#20960;&#20010;&#32467;&#26524;&#25512;&#24191;&#21040;&#20102;&#22823;&#22270;&#19978;&#30340;&#20381;&#36182;&#30446;&#26631;&#20998;&#24067;&#30340;&#24773;&#20917;&#65292;&#24182;&#20026;&#22823;&#22270;&#19978;&#30340;MCMC&#31639;&#27861;&#24320;&#36767;&#20102;&#35768;&#22810;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Markov chain Monte Carlo (MCMC) algorithms have played a significant role in statistics, physics, machine learning and others, and they are the only known general and efficient approach for some high-dimensional problems. The random walk Metropolis (RWM) algorithm as the most classical MCMC algorithm, has had a great influence on the development and practice of science and engineering. The behavior of the RWM algorithm in high-dimensional problems is typically investigated through a weak convergence result of diffusion processes. In this paper, we utilize the Mosco convergence of Dirichlet forms in analyzing the RWM algorithm on large graphs, whose target distribution is the Gibbs measure that includes any probability measure satisfying a Markov property. The abstract and powerful theory of Dirichlet forms allows us to work directly and naturally on the infinite-dimensional space, and our notion of Mosco convergence allows Dirichlet forms associated with the RWM chains to lie on changi
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#20851;&#20110;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;(XAI)&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#25552;&#20986;&#20102;&#29305;&#24449;&#37325;&#35201;&#24615;&#30340;&#23458;&#35266;&#21021;&#27493;&#23450;&#20041;&#65292;&#20197;&#36991;&#20813;&#30001;&#20110;&#26041;&#27861;&#30340;&#34892;&#20026;&#24341;&#36215;&#30340;&#38169;&#35823;&#35299;&#35835;&#12290;</title><link>http://arxiv.org/abs/2111.07473</link><description>&lt;p&gt;
&#21033;&#29992;&#25233;&#21046;&#21464;&#37327;&#30340;&#32447;&#24615;&#22522;&#30784;&#25968;&#25454;&#23457;&#26597;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;(XAI)
&lt;/p&gt;
&lt;p&gt;
Scrutinizing XAI using linear ground-truth data with suppressor variables. (arXiv:2111.07473v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.07473
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#20851;&#20110;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;(XAI)&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#25552;&#20986;&#20102;&#29305;&#24449;&#37325;&#35201;&#24615;&#30340;&#23458;&#35266;&#21021;&#27493;&#23450;&#20041;&#65292;&#20197;&#36991;&#20813;&#30001;&#20110;&#26041;&#27861;&#30340;&#34892;&#20026;&#24341;&#36215;&#30340;&#38169;&#35823;&#35299;&#35835;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;(ML)&#36234;&#26469;&#36234;&#24120;&#29992;&#20110;&#39640;&#39118;&#38505;&#20915;&#31574;&#20013;&#12290;&#30001;&#20110;&#22797;&#26434;&#30340;ML&#27169;&#22411;(&#22914;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;)&#36890;&#24120;&#34987;&#35748;&#20026;&#26159;&#40657;&#21283;&#23376;&#65292;&#22240;&#27492;&#24050;&#32463;&#24320;&#21457;&#20986;&#22823;&#37327;&#31243;&#24207;&#26469;&#38416;&#26126;&#20854;&#20869;&#37096;&#36816;&#20316;&#21644;&#39044;&#27979;&#26041;&#24335;&#65292;&#23450;&#20041;&#20102;"&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;"(XAI)&#39046;&#22495;&#12290;&#26174;&#33879;&#24615;&#26041;&#27861;&#26681;&#25454;&#26576;&#31181;"&#37325;&#35201;&#24615;"&#24230;&#37327;&#23545;&#36755;&#20837;&#29305;&#24449;&#36827;&#34892;&#25490;&#24207;&#12290;&#30001;&#20110;&#36804;&#20170;&#20026;&#27490;&#32570;&#20047;&#29305;&#24449;&#37325;&#35201;&#24615;&#30340;&#27491;&#24335;&#23450;&#20041;&#65292;&#36825;&#20123;&#26041;&#27861;&#24456;&#38590;&#39564;&#35777;&#12290;&#24050;&#32463;&#35777;&#23454;&#65292;&#19968;&#20123;&#26174;&#33879;&#24615;&#26041;&#27861;&#21487;&#20197;&#31361;&#20986;&#26174;&#31034;&#19982;&#39044;&#27979;&#30446;&#26631;&#27809;&#26377;&#32479;&#35745;&#32852;&#31995;&#30340;&#29305;&#24449;(&#25233;&#21046;&#21464;&#37327;)&#12290;&#20026;&#20102;&#36991;&#20813;&#30001;&#20110;&#36825;&#31181;&#34892;&#20026;&#24341;&#36215;&#30340;&#38169;&#35823;&#35299;&#35835;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#30830;&#20445;&#27492;&#31867;&#32852;&#31995;&#23384;&#22312;&#26159;&#29305;&#24449;&#37325;&#35201;&#24615;&#30340;&#24517;&#35201;&#26465;&#20214;&#21644;&#23458;&#35266;&#21021;&#27493;&#23450;&#20041;&#12290;&#25105;&#20204;&#31934;&#24515;&#21046;&#20316;&#20102;&#19968;&#20010;&#22522;&#30784;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#25152;&#26377;&#32479;&#35745;&#20381;&#36182;&#20851;&#31995;&#37117;&#26159;&#26126;&#30830;&#23450;&#20041;&#30340;&#21644;&#32447;&#24615;&#30340;&#65292;
&lt;/p&gt;
&lt;p&gt;
Machine learning (ML) is increasingly often used to inform high-stakes decisions. As complex ML models (e.g., deep neural networks) are often considered black boxes, a wealth of procedures has been developed to shed light on their inner workings and the ways in which their predictions come about, defining the field of 'explainable AI' (XAI). Saliency methods rank input features according to some measure of 'importance'. Such methods are difficult to validate since a formal definition of feature importance is, thus far, lacking. It has been demonstrated that some saliency methods can highlight features that have no statistical association with the prediction target (suppressor variables). To avoid misinterpretations due to such behavior, we propose the actual presence of such an association as a necessary condition and objective preliminary definition for feature importance. We carefully crafted a ground-truth dataset in which all statistical dependencies are well-defined and linear, se
&lt;/p&gt;</description></item></channel></rss>