<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#22312;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#20013;&#65292;&#24222;&#22823;&#30340;&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#36890;&#36807;&#22686;&#21152;&#27169;&#22411;&#22797;&#26434;&#24230;&#26469;&#38477;&#20302;&#27979;&#35797;&#35823;&#24046;&#65292;&#36825;&#23601;&#26159;&#21452;&#19979;&#38477;&#29616;&#35937;&#12290;</title><link>https://arxiv.org/abs/2403.10459</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#21452;&#19979;&#38477;&#29616;&#35937;&#25506;&#31350;
&lt;/p&gt;
&lt;p&gt;
Understanding the Double Descent Phenomenon in Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10459
&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#20013;&#65292;&#24222;&#22823;&#30340;&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#36890;&#36807;&#22686;&#21152;&#27169;&#22411;&#22797;&#26434;&#24230;&#26469;&#38477;&#20302;&#27979;&#35797;&#35823;&#24046;&#65292;&#36825;&#23601;&#26159;&#21452;&#19979;&#38477;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#19982;&#23481;&#37327;&#25511;&#21046;&#30456;&#32467;&#21512;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#32463;&#20856;&#30340;&#31574;&#30053;&#65292;&#29992;&#20110;&#25511;&#21046;&#27867;&#21270;&#24046;&#36317;&#24182;&#36991;&#20813;&#36807;&#25311;&#21512;&#65292;&#22240;&#20026;&#27169;&#22411;&#31867;&#23481;&#37327;&#21464;&#22823;&#12290;&#28982;&#32780;&#65292;&#22312;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#23454;&#36341;&#20013;&#65292;&#38750;&#24120;&#24222;&#22823;&#30340;&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#65288;&#22914;&#31070;&#32463;&#32593;&#32476;&#65289;&#34987;&#20248;&#21270;&#20197;&#23436;&#32654;&#25311;&#21512;&#35757;&#32451;&#25968;&#25454;&#65292;&#24182;&#19988;&#20173;&#28982;&#21487;&#20197;&#33719;&#24471;&#33391;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#36229;&#36234;&#25554;&#20540;&#28857;&#21518;&#65292;&#22686;&#21152;&#27169;&#22411;&#22797;&#26434;&#24230;&#20284;&#20046;&#23454;&#38469;&#19978;&#20250;&#38477;&#20302;&#27979;&#35797;&#35823;&#24046;&#12290;&#22312;&#26412;&#25945;&#31243;&#20013;&#65292;&#25105;&#20204;&#35299;&#37322;&#20102;&#21452;&#19979;&#38477;&#30340;&#27010;&#24565;&#21450;&#20854;&#26426;&#21046;&#12290;&#31532;&#19968;&#37096;&#20998;&#24314;&#31435;&#20102;&#32463;&#20856;&#30340;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#24182;&#20171;&#32461;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#12290;&#36890;&#36807;&#35266;&#23519;&#22810;&#20010;&#31034;&#20363;&#65292;&#31532;&#20108;&#37096;&#20998;&#20171;&#32461;&#20102;&#24402;&#32435;&#20559;&#24046;&#65292;&#22312;&#21452;&#19979;&#38477;&#20013;&#36873;&#25321;&#24179;&#28369;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#22120;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#26368;&#21518;&#65292;&#31532;&#19977;&#37096;&#20998;&#25506;&#35752;&#20102;t
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10459v1 Announce Type: new  Abstract: Combining empirical risk minimization with capacity control is a classical strategy in machine learning when trying to control the generalization gap and avoid overfitting, as the model class capacity gets larger. Yet, in modern deep learning practice, very large over-parameterized models (e.g. neural networks) are optimized to fit perfectly the training data and still obtain great generalization performance. Past the interpolation point, increasing model complexity seems to actually lower the test error.   In this tutorial, we explain the concept of double descent and its mechanisms. The first section sets the classical statistical learning framework and introduces the double descent phenomenon. By looking at a number of examples, section 2 introduces inductive biases that appear to have a key role in double descent by selecting, among the multiple interpolating solutions, a smooth empirical risk minimizer. Finally, section 3 explores t
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#20855;&#26377;&#21333;&#19968;&#25968;&#23398;&#30446;&#26631;&#30340;&#35780;&#20272;&#26694;&#26550;&#65292;&#29992;&#20110;&#30830;&#23450;&#21512;&#25104;&#25968;&#25454;&#24212;&#35813;&#20174;&#19982;&#35266;&#27979;&#25968;&#25454;&#30456;&#21516;&#30340;&#20998;&#24067;&#20013;&#25552;&#21462;&#65292;&#24182;&#19988;&#25512;&#29702;&#20102;&#20219;&#20309;&#19968;&#32452;&#25351;&#26631;&#30340;&#23436;&#25972;&#24615;&#65292;&#32479;&#19968;&#20102;&#29616;&#26377;&#30340;&#25351;&#26631;&#65292;&#24182;&#40723;&#21169;&#26032;&#30340;&#27169;&#22411;&#26080;&#20851;&#22522;&#32447;&#21644;&#25351;&#26631;&#12290;</title><link>https://arxiv.org/abs/2403.10424</link><description>&lt;p&gt;
&#32467;&#26500;&#21270;&#35780;&#20272;&#21512;&#25104;&#34920;&#26684;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Structured Evaluation of Synthetic Tabular Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10424
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#20855;&#26377;&#21333;&#19968;&#25968;&#23398;&#30446;&#26631;&#30340;&#35780;&#20272;&#26694;&#26550;&#65292;&#29992;&#20110;&#30830;&#23450;&#21512;&#25104;&#25968;&#25454;&#24212;&#35813;&#20174;&#19982;&#35266;&#27979;&#25968;&#25454;&#30456;&#21516;&#30340;&#20998;&#24067;&#20013;&#25552;&#21462;&#65292;&#24182;&#19988;&#25512;&#29702;&#20102;&#20219;&#20309;&#19968;&#32452;&#25351;&#26631;&#30340;&#23436;&#25972;&#24615;&#65292;&#32479;&#19968;&#20102;&#29616;&#26377;&#30340;&#25351;&#26631;&#65292;&#24182;&#40723;&#21169;&#26032;&#30340;&#27169;&#22411;&#26080;&#20851;&#22522;&#32447;&#21644;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34920;&#26684;&#25968;&#25454;&#36890;&#24120;&#23384;&#22312;&#20294;&#24448;&#24448;&#19981;&#23436;&#25972;&#65292;&#25968;&#25454;&#37327;&#36739;&#23567;&#65292;&#24182;&#19988;&#30001;&#20110;&#38544;&#31169;&#21407;&#22240;&#21463;&#38480;&#20110;&#35775;&#38382;&#12290;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#25552;&#20379;&#20102;&#28508;&#22312;&#35299;&#20915;&#26041;&#26696;&#12290;&#23384;&#22312;&#35768;&#22810;&#29992;&#20110;&#35780;&#20272;&#21512;&#25104;&#34920;&#26684;&#24335;&#25968;&#25454;&#36136;&#37327;&#30340;&#25351;&#26631;&#65307;&#28982;&#32780;&#65292;&#25105;&#20204;&#32570;&#20047;&#23545;&#36825;&#20123;&#25351;&#26631;&#30340;&#23458;&#35266;&#12289;&#36830;&#36143;&#30340;&#35299;&#37322;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20855;&#26377;&#21333;&#19968;&#25968;&#23398;&#30446;&#26631;&#30340;&#35780;&#20272;&#26694;&#26550;&#65292;&#35748;&#20026;&#21512;&#25104;&#25968;&#25454;&#24212;&#35813;&#20174;&#19982;&#35266;&#27979;&#25968;&#25454;&#30456;&#21516;&#30340;&#20998;&#24067;&#20013;&#25552;&#21462;&#12290;&#36890;&#36807;&#23545;&#30446;&#26631;&#30340;&#21508;&#31181;&#32467;&#26500;&#20998;&#35299;&#65292;&#35813;&#26694;&#26550;&#39318;&#27425;&#20801;&#35768;&#25105;&#20204;&#25512;&#29702;&#20219;&#20309;&#19968;&#32452;&#25351;&#26631;&#30340;&#23436;&#25972;&#24615;&#65292;&#24182;&#32479;&#19968;&#29616;&#26377;&#30340;&#25351;&#26631;&#65292;&#21253;&#25324;&#28304;&#33258;&#24544;&#23454;&#24615;&#32771;&#34385;&#12289;&#19979;&#28216;&#24212;&#29992;&#21644;&#22522;&#20110;&#27169;&#22411;&#26041;&#27861;&#30340;&#25351;&#26631;&#12290;&#27492;&#22806;&#65292;&#35813;&#26694;&#26550;&#28608;&#21169;&#20102;&#26080;&#27169;&#22411;&#22522;&#32447;&#21644;&#19968;&#31995;&#21015;&#26032;&#30340;&#25351;&#26631;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#32467;&#26500;&#21270;&#20449;&#24687;&#21512;&#25104;&#22120;&#21644;&#21512;&#25104;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10424v1 Announce Type: new  Abstract: Tabular data is common yet typically incomplete, small in volume, and access-restricted due to privacy concerns. Synthetic data generation offers potential solutions. Many metrics exist for evaluating the quality of synthetic tabular data; however, we lack an objective, coherent interpretation of the many metrics. To address this issue, we propose an evaluation framework with a single, mathematical objective that posits that the synthetic data should be drawn from the same distribution as the observed data. Through various structural decomposition of the objective, this framework allows us to reason for the first time the completeness of any set of metrics, as well as unifies existing metrics, including those that stem from fidelity considerations, downstream application, and model-based approaches. Moreover, the framework motivates model-free baselines and a new spectrum of metrics. We evaluate structurally informed synthesizers and syn
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;Huber&#27745;&#26579;&#27169;&#22411;&#19979;&#36827;&#34892;&#39640;&#26031;&#31232;&#30095;&#20272;&#35745;&#20219;&#21153;&#30340;&#40065;&#26834;&#20272;&#35745;&#22120;&#65292;&#20026;&#22343;&#20540;&#20272;&#35745;&#12289;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;&#32447;&#24615;&#22238;&#24402;&#25552;&#20379;&#20102;&#20855;&#26377;&#26368;&#20248;&#35823;&#24046;&#20445;&#35777;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#21516;&#26102;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#32500;&#28388;&#27874;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.10416</link><description>&lt;p&gt;
&#22312;Huber&#27745;&#26579;&#27169;&#22411;&#19979;&#20855;&#26377;&#26368;&#20248;&#35823;&#24046;&#30340;&#39640;&#26031;&#31232;&#30095;&#20272;&#35745;&#30340;&#40065;&#26834;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Robust Sparse Estimation for Gaussians with Optimal Error under Huber Contamination
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10416
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;Huber&#27745;&#26579;&#27169;&#22411;&#19979;&#36827;&#34892;&#39640;&#26031;&#31232;&#30095;&#20272;&#35745;&#20219;&#21153;&#30340;&#40065;&#26834;&#20272;&#35745;&#22120;&#65292;&#20026;&#22343;&#20540;&#20272;&#35745;&#12289;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;&#32447;&#24615;&#22238;&#24402;&#25552;&#20379;&#20102;&#20855;&#26377;&#26368;&#20248;&#35823;&#24046;&#20445;&#35777;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#21516;&#26102;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#32500;&#28388;&#27874;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;Huber&#30340;&#27745;&#26579;&#27169;&#22411;&#20013;&#30740;&#31350;&#20102;&#39640;&#26031;&#31232;&#30095;&#20272;&#35745;&#20219;&#21153;&#65292;&#37325;&#28857;&#20851;&#27880;&#22343;&#20540;&#20272;&#35745;&#12289;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;&#32447;&#24615;&#22238;&#24402;&#12290;&#38024;&#23545;&#36825;&#20123;&#20219;&#21153;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#26679;&#26412;&#21644;&#35745;&#31639;&#39640;&#25928;&#30340;&#40065;&#26834;&#20272;&#35745;&#22120;&#65292;&#20855;&#26377;&#26368;&#20248;&#30340;&#35823;&#24046;&#20445;&#35777;&#65292;&#19988;&#22312;&#24120;&#25968;&#22240;&#23376;&#20869;&#12290;&#25152;&#26377;&#20808;&#21069;&#29992;&#20110;&#36825;&#20123;&#20219;&#21153;&#30340;&#39640;&#25928;&#31639;&#27861;&#37117;&#23548;&#33268;&#37327;&#21270;&#30340;&#27425;&#20248;&#35823;&#24046;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#23545;&#20110;&#22312;$\mathbb{R}^d$&#19978;&#24102;&#26377;&#27745;&#26579;&#29575;$\epsilon&gt;0$&#30340;&#39640;&#26031;&#31283;&#20581;$k$-&#31232;&#30095;&#22343;&#20540;&#20272;&#35745;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#20855;&#26377;&#26679;&#26412;&#22797;&#26434;&#24230;$(k^2/\epsilon^2)\mathrm{polylog}(d/\epsilon)$&#65292;&#22312;&#26679;&#26412;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#36816;&#34892;&#65292;&#24182;&#22312;$\ell_2$-&#35823;&#24046;&#20026;$O(\epsilon)$&#30340;&#24773;&#20917;&#19979;&#36924;&#36817;&#30446;&#26631;&#22343;&#20540;&#12290;&#20808;&#21069;&#30340;&#39640;&#25928;&#31639;&#27861;&#22266;&#26377;&#22320;&#20135;&#29983;&#35823;&#24046;&#20026;$\Omega(\epsilon \sqrt{\log(1/\epsilon)})$&#12290;&#22312;&#25216;&#26415;&#23618;&#38754;&#19978;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22312;&#31232;&#30095;&#39046;&#22495;&#20013;&#21487;&#33021;&#20855;&#26377;&#20854;&#20182;&#24212;&#29992;&#30340;&#26032;&#39062;&#30340;&#22810;&#32500;&#28388;&#27874;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10416v1 Announce Type: new  Abstract: We study Gaussian sparse estimation tasks in Huber's contamination model with a focus on mean estimation, PCA, and linear regression. For each of these tasks, we give the first sample and computationally efficient robust estimators with optimal error guarantees, within constant factors. All prior efficient algorithms for these tasks incur quantitatively suboptimal error. Concretely, for Gaussian robust $k$-sparse mean estimation on $\mathbb{R}^d$ with corruption rate $\epsilon&gt;0$, our algorithm has sample complexity $(k^2/\epsilon^2)\mathrm{polylog}(d/\epsilon)$, runs in sample polynomial time, and approximates the target mean within $\ell_2$-error $O(\epsilon)$. Previous efficient algorithms inherently incur error $\Omega(\epsilon \sqrt{\log(1/\epsilon)})$. At the technical level, we develop a novel multidimensional filtering method in the sparse regime that may find other applications.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#24471;&#20998;&#20989;&#25968;&#21644;&#23450;&#20041;&#36866;&#24212;&#24615;&#23433;&#20840;&#38598;&#65292;&#23558;&#21487;&#25193;&#23637;&#20998;&#31867;&#22120;&#21644;&#36866;&#24212;&#24615;&#39044;&#27979;&#30456;&#32467;&#21512;&#65292;&#23450;&#20041;&#20102;&#19968;&#31181;&#21487;&#38752;&#30340;&#23398;&#20064;&#26694;&#26550;&#65292;&#33021;&#22815;&#22312;&#35774;&#35745;&#21021;&#26399;&#23601;&#20026;&#20998;&#31867;&#25552;&#20379;&#31283;&#20581;&#30340;&#31639;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.10368</link><description>&lt;p&gt;
&#38754;&#21521;&#27010;&#29575;&#40065;&#26834;&#21487;&#25193;&#23637;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#30340;&#36866;&#24212;&#24615;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Conformal Predictions for Probabilistically Robust Scalable Machine Learning Classification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10368
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#24471;&#20998;&#20989;&#25968;&#21644;&#23450;&#20041;&#36866;&#24212;&#24615;&#23433;&#20840;&#38598;&#65292;&#23558;&#21487;&#25193;&#23637;&#20998;&#31867;&#22120;&#21644;&#36866;&#24212;&#24615;&#39044;&#27979;&#30456;&#32467;&#21512;&#65292;&#23450;&#20041;&#20102;&#19968;&#31181;&#21487;&#38752;&#30340;&#23398;&#20064;&#26694;&#26550;&#65292;&#33021;&#22815;&#22312;&#35774;&#35745;&#21021;&#26399;&#23601;&#20026;&#20998;&#31867;&#25552;&#20379;&#31283;&#20581;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36866;&#24212;&#24615;&#39044;&#27979;&#21487;&#20197;&#23450;&#20041;&#21487;&#38752;&#19988;&#31283;&#20581;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#20174;&#35774;&#35745;&#21021;&#26399;&#23601;&#20026;&#20998;&#31867;&#23450;&#20041;&#20102;&#21487;&#38752;&#30340;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#21487;&#25193;&#23637;&#20998;&#31867;&#22120;&#30340;&#27010;&#24565;&#19982;&#32479;&#35745;&#25490;&#24207;&#29702;&#35770;&#21644;&#27010;&#29575;&#23398;&#20064;&#29702;&#35770;&#32852;&#31995;&#36215;&#26469;&#12290;&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#24471;&#20998;&#20989;&#25968;&#30340;&#26032;&#23450;&#20041;&#21644;&#23450;&#20041;&#19968;&#32452;&#29305;&#27530;&#30340;&#36755;&#20837;&#21464;&#37327;&#65292;&#21363;&#36866;&#24212;&#24615;&#23433;&#20840;&#38598;&#65292;&#26469;&#20998;&#26512;&#21487;&#25193;&#23637;&#20998;&#31867;&#22120;&#21644;&#36866;&#24212;&#24615;&#39044;&#27979;&#20043;&#38388;&#30340;&#30456;&#20284;&#20043;&#22788;&#65292;&#35813;&#23433;&#20840;&#38598;&#33021;&#22815;&#35782;&#21035;&#22312;&#36755;&#20837;&#31354;&#38388;&#20013;&#28385;&#36275;&#35823;&#24046;&#35206;&#30422;&#20445;&#35777;&#30340;&#27169;&#24335;&#65292;&#21363;&#23545;&#20110;&#23646;&#20110;&#35813;&#38598;&#21512;&#30340;&#28857;&#35266;&#23519;&#21040;&#38169;&#35823;&#65288;&#21487;&#33021;&#19981;&#23433;&#20840;&#65289;&#26631;&#31614;&#30340;&#27010;&#29575;&#21463;&#21040;&#39044;&#23450;&#20041;&#30340;$\varepsilon$&#38169;&#35823;&#27700;&#24179;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10368v1 Announce Type: cross  Abstract: Conformal predictions make it possible to define reliable and robust learning algorithms. But they are essentially a method for evaluating whether an algorithm is good enough to be used in practice. To define a reliable learning framework for classification from the very beginning of its design, the concept of scalable classifier was introduced to generalize the concept of classical classifier by linking it to statistical order theory and probabilistic learning theory. In this paper, we analyze the similarities between scalable classifiers and conformal predictions by introducing a new definition of a score function and defining a special set of input variables, the conformal safety set, which can identify patterns in the input space that satisfy the error coverage guarantee, i.e., that the probability of observing the wrong (possibly unsafe) label for points belonging to this set is bounded by a predefined $\varepsilon$ error level. W
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#31895;&#31961;Transformer&#65292;&#29992;&#20110;&#22312;&#36830;&#32493;&#26102;&#38388;&#34920;&#31034;&#30340;&#36755;&#20837;&#24207;&#21015;&#19978;&#36827;&#34892;&#25805;&#20316;&#65292;&#22823;&#22823;&#38477;&#20302;&#20102;&#35745;&#31639;&#25104;&#26412;&#65292;&#23545;&#20110;&#22788;&#29702;&#21307;&#30103;&#24773;&#22659;&#20013;&#30340;&#38271;&#31243;&#20381;&#36182;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;</title><link>https://arxiv.org/abs/2403.10288</link><description>&lt;p&gt;
&#29992;&#20110;&#36830;&#32493;&#21644;&#39640;&#25928;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#30340;&#31895;&#31961;Transformer
&lt;/p&gt;
&lt;p&gt;
Rough Transformers for Continuous and Efficient Time-Series Modelling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10288
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#31895;&#31961;Transformer&#65292;&#29992;&#20110;&#22312;&#36830;&#32493;&#26102;&#38388;&#34920;&#31034;&#30340;&#36755;&#20837;&#24207;&#21015;&#19978;&#36827;&#34892;&#25805;&#20316;&#65292;&#22823;&#22823;&#38477;&#20302;&#20102;&#35745;&#31639;&#25104;&#26412;&#65292;&#23545;&#20110;&#22788;&#29702;&#21307;&#30103;&#24773;&#22659;&#20013;&#30340;&#38271;&#31243;&#20381;&#36182;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#21307;&#30103;&#29615;&#22659;&#20013;&#65292;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#36890;&#24120;&#34920;&#29616;&#20986;&#38271;&#31243;&#20381;&#36182;&#24615;&#65292;&#24182;&#19988;&#20197;&#19981;&#22343;&#21248;&#38388;&#38548;&#35266;&#23519;&#21040;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20256;&#32479;&#30340;&#22522;&#20110;&#24207;&#21015;&#30340;&#24490;&#29615;&#27169;&#22411;&#24456;&#38590;&#22788;&#29702;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#19968;&#38382;&#39064;&#65292;&#30740;&#31350;&#20154;&#21592;&#29992;&#22522;&#20110;&#31070;&#32463;ODE&#30340;&#27169;&#22411;&#26367;&#25442;&#24490;&#29615;&#26550;&#26500;&#26469;&#24314;&#27169;&#38750;&#22343;&#21248;&#37319;&#26679;&#30340;&#25968;&#25454;&#65292;&#24182;&#20351;&#29992;Transformer&#26550;&#26500;&#26469;&#32771;&#34385;&#38271;&#31243;&#20381;&#36182;&#12290;&#23613;&#31649;&#36825;&#20004;&#31181;&#26041;&#27861;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#23545;&#20110;&#20013;&#31561;&#38271;&#24230;&#21450;&#26356;&#38271;&#36755;&#20837;&#24207;&#21015;&#65292;&#20004;&#32773;&#37117;&#38656;&#35201;&#38750;&#24120;&#39640;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31895;&#31961;Transformer&#65292;&#36825;&#26159;Transformer&#27169;&#22411;&#30340;&#19968;&#31181;&#21464;&#20307;&#65292;&#20854;&#22312;&#36755;&#20837;&#24207;&#21015;&#30340;&#36830;&#32493;&#26102;&#38388;&#34920;&#31034;&#19978;&#36816;&#34892;&#65292;&#24182;&#19988;&#20943;&#23569;&#20102;&#35745;&#31639;&#25104;&#26412;&#65292;&#23545;&#20110;&#22788;&#29702;&#21307;&#30103;&#24773;&#22659;&#20013;&#24120;&#35265;&#30340;&#38271;&#31243;&#20381;&#36182;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22810;&#35270;&#22270;&#31614;&#21517;&#27880;&#24847;&#21147;&#65292;&#21033;&#29992;&#36335;&#24452;&#31614;&#21517;&#26469;&#22686;&#24378;&#20256;&#32479;&#30340;&#27880;&#24847;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10288v1 Announce Type: cross  Abstract: Time-series data in real-world medical settings typically exhibit long-range dependencies and are observed at non-uniform intervals. In such contexts, traditional sequence-based recurrent models struggle. To overcome this, researchers replace recurrent architectures with Neural ODE-based models to model irregularly sampled data and use Transformer-based architectures to account for long-range dependencies. Despite the success of these two approaches, both incur very high computational costs for input sequences of moderate lengths and greater. To mitigate this, we introduce the Rough Transformer, a variation of the Transformer model which operates on continuous-time representations of input sequences and incurs significantly reduced computational costs, critical for addressing long-range dependencies common in medical contexts. In particular, we propose multi-view signature attention, which uses path signatures to augment vanilla attent
&lt;/p&gt;</description></item><item><title>&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#22312;&#29983;&#23384;&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;&#20419;&#36827;&#20102;&#36879;&#26126;&#24230;&#21644;&#20844;&#24179;&#24615;&#65292;&#25581;&#31034;&#20102;&#27169;&#22411;&#30340;&#28508;&#22312;&#20559;&#35265;&#21644;&#38480;&#21046;&#65292;&#24182;&#25552;&#20379;&#20102;&#26356;&#31526;&#21512;&#25968;&#23398;&#21407;&#29702;&#30340;&#29305;&#24449;&#24433;&#21709;&#21644;&#39118;&#38505;&#22240;&#32032;&#39044;&#27979;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.10250</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#29992;&#20110;&#29983;&#23384;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Interpretable Machine Learning for Survival Analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10250
&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#22312;&#29983;&#23384;&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;&#20419;&#36827;&#20102;&#36879;&#26126;&#24230;&#21644;&#20844;&#24179;&#24615;&#65292;&#25581;&#31034;&#20102;&#27169;&#22411;&#30340;&#28508;&#22312;&#20559;&#35265;&#21644;&#38480;&#21046;&#65292;&#24182;&#25552;&#20379;&#20102;&#26356;&#31526;&#21512;&#25968;&#23398;&#21407;&#29702;&#30340;&#29305;&#24449;&#24433;&#21709;&#21644;&#39118;&#38505;&#22240;&#32032;&#39044;&#27979;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#40657;&#30418;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20256;&#25773;&#21644;&#24555;&#36895;&#36827;&#27493;&#65292;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;IML&#65289;&#39046;&#22495;&#25110;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#22312;&#36807;&#21435;&#21313;&#24180;&#20013;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290; &#36825;&#22312;&#29983;&#23384;&#20998;&#26512;&#39046;&#22495;&#23588;&#20026;&#37325;&#35201;&#65292;&#20854;&#20013;&#37319;&#29992;IML&#25216;&#26415;&#20419;&#36827;&#20102;&#36879;&#26126;&#24230;&#12289;&#38382;&#36131;&#21046;&#21644;&#20844;&#24179;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#20020;&#24202;&#20915;&#31574;&#36807;&#31243;&#12289;&#26377;&#38024;&#23545;&#24615;&#30103;&#27861;&#30340;&#24320;&#21457;&#12289;&#24178;&#39044;&#25110;&#20854;&#20182;&#21307;&#23398;&#25110;&#19982;&#21307;&#30103;&#20445;&#20581;&#30456;&#20851;&#30340;&#29615;&#22659;&#20013;&#12290; &#20855;&#20307;&#26469;&#35828;&#65292;&#21487;&#35299;&#37322;&#24615;&#21487;&#20197;&#25581;&#31034;&#29983;&#23384;&#27169;&#22411;&#30340;&#28508;&#22312;&#20559;&#35265;&#21644;&#23616;&#38480;&#24615;&#65292;&#24182;&#25552;&#20379;&#26356;&#31526;&#21512;&#25968;&#23398;&#21407;&#29702;&#30340;&#26041;&#27861;&#26469;&#29702;&#35299;&#21738;&#20123;&#29305;&#24449;&#23545;&#39044;&#27979;&#26377;&#24433;&#21709;&#25110;&#26500;&#25104;&#39118;&#38505;&#22240;&#32032;&#12290; &#28982;&#32780;&#65292;&#32570;&#20047;&#21363;&#26102;&#21487;&#29992;&#30340;IML&#26041;&#27861;&#21487;&#33021;&#24050;&#32463;&#38459;&#30861;&#20102;&#21307;&#23398;&#20174;&#19994;&#32773;&#21644;&#20844;&#20849;&#21355;&#29983;&#25919;&#31574;&#21046;&#23450;&#32773;&#20805;&#20998;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10250v1 Announce Type: cross  Abstract: With the spread and rapid advancement of black box machine learning models, the field of interpretable machine learning (IML) or explainable artificial intelligence (XAI) has become increasingly important over the last decade. This is particularly relevant for survival analysis, where the adoption of IML techniques promotes transparency, accountability and fairness in sensitive areas, such as clinical decision making processes, the development of targeted therapies, interventions or in other medical or healthcare related contexts. More specifically, explainability can uncover a survival model's potential biases and limitations and provide more mathematically sound ways to understand how and which features are influential for prediction or constitute risk factors. However, the lack of readily available IML methods may have deterred medical practitioners and policy makers in public health from leveraging the full potential of machine lea
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#22312;&#24037;&#19994;&#38646;&#37096;&#20214;&#20998;&#31867;&#20013;&#25506;&#35752;&#20102;&#21033;&#29992;&#26356;&#20415;&#23452;&#30340;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#23454;&#29616;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#26041;&#27861;</title><link>https://arxiv.org/abs/2403.10182</link><description>&lt;p&gt;
&#29992;&#26356;&#20415;&#23452;&#30340;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#23454;&#29616;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#65306;&#24037;&#19994;&#38646;&#37096;&#20214;&#20998;&#31867;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Reliable uncertainty with cheaper neural network ensembles: a case study in industrial parts classification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10182
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#22312;&#24037;&#19994;&#38646;&#37096;&#20214;&#20998;&#31867;&#20013;&#25506;&#35752;&#20102;&#21033;&#29992;&#26356;&#20415;&#23452;&#30340;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#23454;&#29616;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36816;&#31609;&#23398;(OR)&#20013;&#65292;&#39044;&#27979;&#27169;&#22411;&#32463;&#24120;&#20250;&#36935;&#21040;&#25968;&#25454;&#20998;&#24067;&#19982;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#19981;&#21516;&#30340;&#22330;&#26223;&#12290;&#36817;&#24180;&#26469;&#65292;&#31070;&#32463;&#32593;&#32476;(NNs)&#22312;&#22270;&#20687;&#20998;&#31867;&#31561;&#39046;&#22495;&#30340;&#20986;&#33394;&#24615;&#33021;&#20351;&#20854;&#22312;OR&#20013;&#22791;&#21463;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#24403;&#38754;&#23545;OOD&#25968;&#25454;&#26102;&#65292;NNs&#24448;&#24448;&#20250;&#20570;&#20986;&#33258;&#20449;&#20294;&#19981;&#27491;&#30830;&#30340;&#39044;&#27979;&#12290;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#20026;&#33258;&#20449;&#30340;&#27169;&#22411;&#25552;&#20379;&#20102;&#19968;&#20010;&#35299;&#20915;&#26041;&#26696;&#65292;&#24403;&#36755;&#20986;&#24212;(&#19981;&#24212;)&#34987;&#20449;&#20219;&#26102;&#36827;&#34892;&#36890;&#20449;&#12290;&#22240;&#27492;&#65292;&#22312;OR&#39046;&#22495;&#20013;&#65292;NNs&#20013;&#30340;&#21487;&#38752;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#33267;&#20851;&#37325;&#35201;&#12290;&#30001;&#22810;&#20010;&#29420;&#31435;NNs&#32452;&#25104;&#30340;&#28145;&#24230;&#38598;&#21512;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#26041;&#27861;&#65292;&#19981;&#20165;&#25552;&#20379;&#24378;&#22823;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#65292;&#36824;&#33021;&#21487;&#38752;&#22320;&#20272;&#35745;&#19981;&#30830;&#23450;&#24615;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#37096;&#32626;&#30001;&#20110;&#36739;&#22823;&#30340;&#35745;&#31639;&#38656;&#27714;&#32780;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26368;&#36817;&#30340;&#22522;&#30784;&#30740;&#31350;&#25552;&#20986;&#20102;&#26356;&#39640;&#25928;&#30340;NN&#38598;&#25104;&#65292;&#21363;sna
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10182v1 Announce Type: new  Abstract: In operations research (OR), predictive models often encounter out-of-distribution (OOD) scenarios where the data distribution differs from the training data distribution. In recent years, neural networks (NNs) are gaining traction in OR for their exceptional performance in fields such as image classification. However, NNs tend to make confident yet incorrect predictions when confronted with OOD data. Uncertainty estimation offers a solution to overconfident models, communicating when the output should (not) be trusted. Hence, reliable uncertainty quantification in NNs is crucial in the OR domain. Deep ensembles, composed of multiple independent NNs, have emerged as a promising approach, offering not only strong predictive accuracy but also reliable uncertainty estimation. However, their deployment is challenging due to substantial computational demands. Recent fundamental research has proposed more efficient NN ensembles, namely the sna
&lt;/p&gt;</description></item><item><title>&#37325;&#35201;&#24615;&#21152;&#26435;&#26159;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#22522;&#26412;&#31243;&#24207;&#65292;&#36890;&#36807;&#23545;&#30446;&#26631;&#20989;&#25968;&#25110;&#27010;&#29575;&#20998;&#24067;&#36827;&#34892;&#21152;&#26435;&#65292;&#21487;&#20197;&#20445;&#35777;&#30417;&#30563;&#23398;&#20064;&#22312;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#20043;&#38388;&#24046;&#24322;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#32479;&#35745;&#19978;&#26399;&#26395;&#30340;&#24615;&#36136;</title><link>https://arxiv.org/abs/2403.10175</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#37325;&#35201;&#24615;&#21152;&#26435;&#31616;&#35201;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
A Short Survey on Importance Weighting for Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10175
&lt;/p&gt;
&lt;p&gt;
&#37325;&#35201;&#24615;&#21152;&#26435;&#26159;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#22522;&#26412;&#31243;&#24207;&#65292;&#36890;&#36807;&#23545;&#30446;&#26631;&#20989;&#25968;&#25110;&#27010;&#29575;&#20998;&#24067;&#36827;&#34892;&#21152;&#26435;&#65292;&#21487;&#20197;&#20445;&#35777;&#30417;&#30563;&#23398;&#20064;&#22312;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#20043;&#38388;&#24046;&#24322;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#32479;&#35745;&#19978;&#26399;&#26395;&#30340;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37325;&#35201;&#24615;&#21152;&#26435;&#26159;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#39033;&#22522;&#26412;&#31243;&#24207;&#65292;&#26681;&#25454;&#26576;&#31181;&#24847;&#20041;&#19978;&#23454;&#20363;&#30340;&#37325;&#35201;&#24615;&#23545;&#30446;&#26631;&#20989;&#25968;&#25110;&#27010;&#29575;&#20998;&#24067;&#36827;&#34892;&#21152;&#26435;&#12290;&#36825;&#19968;&#31616;&#21333;&#32780;&#26377;&#29992;&#30340;&#24605;&#24819;&#30340;&#24191;&#27867;&#24212;&#29992;&#23548;&#33268;&#20102;&#35768;&#22810;&#37325;&#35201;&#24615;&#21152;&#26435;&#30340;&#24212;&#29992;&#12290;&#20363;&#22914;&#65292;&#25454;&#30693;&#65292;&#22312;&#20851;&#20110;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#20043;&#38388;&#24046;&#24322;&#30340;&#20551;&#35774;&#19979;&#30340;&#30417;&#30563;&#23398;&#20064;&#65292;&#36890;&#36807;&#23494;&#24230;&#27604;&#30340;&#37325;&#35201;&#24615;&#21152;&#26435;&#21487;&#20197;&#20445;&#35777;&#32479;&#35745;&#19978;&#26399;&#26395;&#30340;&#24615;&#36136;&#12290;&#36825;&#39033;&#35843;&#26597;&#24635;&#32467;&#20102;&#26426;&#22120;&#23398;&#20064;&#21644;&#30456;&#20851;&#30740;&#31350;&#20013;&#37325;&#35201;&#24615;&#21152;&#26435;&#30340;&#24191;&#27867;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10175v1 Announce Type: cross  Abstract: Importance weighting is a fundamental procedure in statistics and machine learning that weights the objective function or probability distribution based on the importance of the instance in some sense. The simplicity and usefulness of the idea has led to many applications of importance weighting. For example, it is known that supervised learning under an assumption about the difference between the training and test distributions, called distribution shift, can guarantee statistically desirable properties through importance weighting by their density ratio. This survey summarizes the broad applications of importance weighting in machine learning and related research.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#19981;&#30830;&#23450;&#24615;&#26694;&#26550;&#65292;&#23558;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#23450;&#20301;&#20026;XAI&#25216;&#26415;&#65292;&#24182;&#25552;&#20379;&#20102;&#35299;&#37322;&#36755;&#20986;&#32467;&#26524;&#26102;&#26159;&#21542;&#24212;&#35813;&#20449;&#20219;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.10168</link><description>&lt;p&gt;
&#36890;&#36807;&#19981;&#30830;&#23450;&#24615;&#23454;&#29616;&#21487;&#35299;&#37322;&#24615;&#65306;&#31070;&#32463;&#32593;&#32476;&#20013;&#21487;&#20449;&#36182;&#30340;&#20915;&#31574;&#21046;&#23450;
&lt;/p&gt;
&lt;p&gt;
Explainability through uncertainty: Trustworthy decision-making with neural networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10168
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#19981;&#30830;&#23450;&#24615;&#26694;&#26550;&#65292;&#23558;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#23450;&#20301;&#20026;XAI&#25216;&#26415;&#65292;&#24182;&#25552;&#20379;&#20102;&#35299;&#37322;&#36755;&#20986;&#32467;&#26524;&#26102;&#26159;&#21542;&#24212;&#35813;&#20449;&#20219;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#26159;&#20219;&#20309;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#19968;&#20010;&#20851;&#38190;&#29305;&#24449;&#65292;&#23588;&#20854;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#23588;&#20026;&#37325;&#35201;&#65292;&#22240;&#20026;&#31070;&#32463;&#32593;&#32476;&#24448;&#24448;&#36807;&#20110;&#33258;&#20449;&#12290;&#19981;&#30830;&#23450;&#24615;&#22312;&#25968;&#25454;&#20998;&#24067;&#21457;&#29983;&#21464;&#21270;&#26102;&#23588;&#20026;&#20196;&#20154;&#25285;&#24551;&#65292;&#24403;&#25968;&#25454;&#20998;&#24067;&#20559;&#31163;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#26102;&#65292;&#27169;&#22411;&#24615;&#33021;&#20250;&#24708;&#26080;&#22768;&#24687;&#22320;&#19979;&#38477;&#12290;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#25552;&#20379;&#20102;&#35299;&#20915;&#36807;&#20110;&#33258;&#20449;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#25351;&#31034;&#20309;&#26102;&#24212;&#35813;&#65288;&#19981;&#24212;&#35813;&#65289;&#20449;&#20219;&#36755;&#20986;&#32467;&#26524;&#12290;&#34429;&#28982;&#20851;&#20110;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#26041;&#27861;&#24050;&#32463;&#24471;&#21040;&#21457;&#23637;&#65292;&#20294;&#23578;&#26410;&#26126;&#30830;&#23450;&#20041;&#19982;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#39046;&#22495;&#30340;&#20851;&#31995;&#12290;&#27492;&#22806;&#65292;&#36816;&#31609;&#23398;&#39046;&#22495;&#30340;&#25991;&#29486;&#24573;&#30053;&#20102;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#21487;&#25805;&#20316;&#24615;&#32452;&#25104;&#37096;&#20998;&#65292;&#24182;&#19988;&#26410;&#32771;&#34385;&#21040;&#25968;&#25454;&#20998;&#24067;&#30340;&#21464;&#21270;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#19981;&#30830;&#23450;&#24615;&#26694;&#26550;&#65292;&#36129;&#29486;&#20027;&#35201;&#20307;&#29616;&#22312;&#19977;&#20010;&#26041;&#38754;&#65306;&#65288;i&#65289;&#23558;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#23450;&#20301;&#20026;XAI&#25216;&#26415;&#65292;&#25552;&#20379;&#23616;&#37096;&#30340;&#65292;&#27169;&#22411;&#29305;&#23450;&#30340;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10168v1 Announce Type: new  Abstract: Uncertainty is a key feature of any machine learning model and is particularly important in neural networks, which tend to be overconfident. This overconfidence is worrying under distribution shifts, where the model performance silently degrades as the data distribution diverges from the training data distribution. Uncertainty estimation offers a solution to overconfident models, communicating when the output should (not) be trusted. Although methods for uncertainty estimation have been developed, they have not been explicitly linked to the field of explainable artificial intelligence (XAI). Furthermore, literature in operations research ignores the actionability component of uncertainty estimation and does not consider distribution shifts. This work proposes a general uncertainty framework, with contributions being threefold: (i) uncertainty estimation in ML models is positioned as an XAI technique, giving local and model-specific expla
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20445;&#32467;&#26500;&#30340;&#26680;&#23725;&#22238;&#24402;&#26041;&#27861;&#65292;&#21487;&#20197;&#20174;&#22122;&#22768;&#35266;&#27979;&#25968;&#25454;&#20013;&#24674;&#22797;&#21704;&#23494;&#39039;&#20989;&#25968;&#65292;&#25299;&#23637;&#20102;&#26680;&#22238;&#24402;&#26041;&#27861;&#65292;&#24182;&#20855;&#26377;&#20986;&#33394;&#30340;&#25968;&#20540;&#24615;&#33021;&#21644;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>https://arxiv.org/abs/2403.10070</link><description>&lt;p&gt;
&#29992;&#20110;&#23398;&#20064;&#21704;&#23494;&#39039;&#31995;&#32479;&#30340;&#20445;&#32467;&#26500;&#26680;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Structure-Preserving Kernel Method for Learning Hamiltonian Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10070
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20445;&#32467;&#26500;&#30340;&#26680;&#23725;&#22238;&#24402;&#26041;&#27861;&#65292;&#21487;&#20197;&#20174;&#22122;&#22768;&#35266;&#27979;&#25968;&#25454;&#20013;&#24674;&#22797;&#21704;&#23494;&#39039;&#20989;&#25968;&#65292;&#25299;&#23637;&#20102;&#26680;&#22238;&#24402;&#26041;&#27861;&#65292;&#24182;&#20855;&#26377;&#20986;&#33394;&#30340;&#25968;&#20540;&#24615;&#33021;&#21644;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20445;&#32467;&#26500;&#30340;&#26680;&#23725;&#22238;&#24402;&#26041;&#27861;&#65292;&#20801;&#35768;&#20174;&#21253;&#21547;&#21704;&#23494;&#39039;&#21521;&#37327;&#22330;&#30340;&#22122;&#22768;&#35266;&#27979;&#25968;&#25454;&#38598;&#20013;&#24674;&#22797;&#28508;&#22312;&#30340;&#39640;&#32500;&#38750;&#32447;&#24615;&#21704;&#23494;&#39039;&#20989;&#25968;&#12290;&#35813;&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#20010;&#38381;&#24335;&#35299;&#65292;&#22312;&#36825;&#19968;&#35774;&#32622;&#20013;&#34920;&#29616;&#20986;&#20248;&#31168;&#30340;&#25968;&#20540;&#24615;&#33021;&#65292;&#36229;&#36234;&#20102;&#25991;&#29486;&#20013;&#25552;&#20986;&#30340;&#20854;&#20182;&#25216;&#26415;&#12290;&#20174;&#26041;&#27861;&#35770;&#30340;&#35282;&#24230;&#30475;&#65292;&#35813;&#35770;&#25991;&#25193;&#23637;&#20102;&#26680;&#22238;&#24402;&#26041;&#27861;&#65292;&#35299;&#20915;&#38656;&#35201;&#21253;&#21547;&#26799;&#24230;&#32447;&#24615;&#20989;&#25968;&#30340;&#25439;&#22833;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#29305;&#21035;&#22320;&#65292;&#22312;&#36825;&#19968;&#32972;&#26223;&#19979;&#35777;&#26126;&#20102;&#24494;&#20998;&#20877;&#29616;&#23646;&#24615;&#21644;&#34920;&#31034;&#23450;&#29702;&#12290;&#20998;&#26512;&#20102;&#20445;&#32467;&#26500;&#26680;&#20272;&#35745;&#22120;&#21644;&#39640;&#26031;&#21518;&#39564;&#22343;&#20540;&#20272;&#35745;&#22120;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#36827;&#34892;&#20102;&#23436;&#25972;&#30340;&#35823;&#24046;&#20998;&#26512;&#65292;&#25552;&#20379;&#20351;&#29992;&#22266;&#23450;&#21644;&#33258;&#36866;&#24212;&#27491;&#21017;&#21270;&#21442;&#25968;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#20248;&#33391;&#24615;&#33021;&#24471;&#21040;&#20102;&#30830;&#35748;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10070v1 Announce Type: cross  Abstract: A structure-preserving kernel ridge regression method is presented that allows the recovery of potentially high-dimensional and nonlinear Hamiltonian functions out of datasets made of noisy observations of Hamiltonian vector fields. The method proposes a closed-form solution that yields excellent numerical performances that surpass other techniques proposed in the literature in this setup. From the methodological point of view, the paper extends kernel regression methods to problems in which loss functions involving linear functions of gradients are required and, in particular, a differential reproducing property and a Representer Theorem are proved in this context. The relation between the structure-preserving kernel estimator and the Gaussian posterior mean estimator is analyzed. A full error analysis is conducted that provides convergence rates using fixed and adaptive regularization parameters. The good performance of the proposed 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#22522;&#20110;&#21306;&#22495;&#31283;&#23450;&#24615;&#30340;&#26041;&#27861;&#65292;&#25512;&#23548;&#20986;&#20102;&#38543;&#26426;&#26862;&#26519;&#39044;&#27979;&#30340;&#39640;&#26031;&#36924;&#36817;&#30028;&#38480;&#65292;&#24182;&#24314;&#31435;&#20102;&#36866;&#29992;&#20110;&#21508;&#31181;&#30456;&#20851;&#32479;&#35745;&#38382;&#39064;&#30340;&#27010;&#29575;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.09960</link><description>&lt;p&gt;
&#36890;&#36807;&#22522;&#20110;&#21306;&#22495;&#31283;&#23450;&#24615;&#30340;&#22810;&#20803;&#39640;&#26031;&#36924;&#36817;&#25913;&#36827;&#38543;&#26426;&#26862;&#26519;
&lt;/p&gt;
&lt;p&gt;
Multivariate Gaussian Approximation for Random Forest via Region-based Stabilization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09960
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#22522;&#20110;&#21306;&#22495;&#31283;&#23450;&#24615;&#30340;&#26041;&#27861;&#65292;&#25512;&#23548;&#20986;&#20102;&#38543;&#26426;&#26862;&#26519;&#39044;&#27979;&#30340;&#39640;&#26031;&#36924;&#36817;&#30028;&#38480;&#65292;&#24182;&#24314;&#31435;&#20102;&#36866;&#29992;&#20110;&#21508;&#31181;&#30456;&#20851;&#32479;&#35745;&#38382;&#39064;&#30340;&#27010;&#29575;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#32473;&#23450;&#30001;&#27850;&#26494;&#36807;&#31243;&#20135;&#29983;&#30340;&#19968;&#32452;&#35757;&#32451;&#28857;&#30340;&#24773;&#20917;&#19979;&#65292;&#25512;&#23548;&#20102;&#38543;&#26426;&#26862;&#26519;&#39044;&#27979;&#30340;&#39640;&#26031;&#36924;&#36817;&#30028;&#38480;&#65292;&#20551;&#35774;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#23384;&#22312;&#30456;&#24403;&#28201;&#21644;&#30340;&#27491;&#21017;&#24615;&#20551;&#35774;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#19968;&#20010;&#20851;&#38190;&#35266;&#23519;&#65306;&#38543;&#26426;&#26862;&#26519;&#30340;&#39044;&#27979;&#28385;&#36275;&#19968;&#23450;&#30340;&#31216;&#20026;&#22522;&#20110;&#21306;&#22495;&#31283;&#23450;&#24615;&#30340;&#20960;&#20309;&#23646;&#24615;&#12290;&#22312;&#20026;&#38543;&#26426;&#26862;&#26519;&#24320;&#21457;&#32467;&#26524;&#30340;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#36824;&#20026;&#22522;&#20110;&#21306;&#22495;&#31283;&#23450;&#30340;&#27850;&#26494;&#36807;&#31243;&#30340;&#19968;&#33324;&#27867;&#20989;&#24314;&#31435;&#20102;&#19968;&#20010;&#27010;&#29575;&#32467;&#26524;&#65292;&#36825;&#21487;&#33021;&#26159;&#29420;&#31435;&#24863;&#20852;&#36259;&#30340;&#12290;&#36825;&#19968;&#26222;&#36941;&#32467;&#26524;&#21033;&#29992;&#20102;Malliavin-Stein&#26041;&#27861;&#65292;&#24182;&#19988;&#21487;&#33021;&#36866;&#29992;&#20110;&#21508;&#31181;&#30456;&#20851;&#30340;&#32479;&#35745;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09960v1 Announce Type: cross  Abstract: We derive Gaussian approximation bounds for random forest predictions based on a set of training points given by a Poisson process, under fairly mild regularity assumptions on the data generating process. Our approach is based on the key observation that the random forest predictions satisfy a certain geometric property called region-based stabilization. In the process of developing our results for the random forest, we also establish a probabilistic result, which might be of independent interest, on multivariate Gaussian approximation bounds for general functionals of Poisson process that are region-based stabilizing. This general result makes use of the Malliavin-Stein method, and is potentially applicable to various related statistical problems.
&lt;/p&gt;</description></item><item><title>&#24320;&#21457;&#20102;&#19968;&#26063;&#32452;&#24863;&#30693;&#20808;&#39564;&#20998;&#24067;&#65292;&#21487;&#20197;&#25913;&#36827;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#22312;&#25968;&#25454;&#20998;&#24067;&#30340;&#20122;&#32676;&#20307;&#20559;&#31227;&#19979;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#24182;&#23637;&#31034;&#20102;&#21363;&#20351;&#21482;&#37325;&#26032;&#35757;&#32451;&#38750;&#40065;&#26834;&#27169;&#22411;&#30340;&#26368;&#21518;&#19968;&#23618;&#65292;&#20351;&#29992;&#36825;&#31181;&#20808;&#39564;&#36827;&#34892;&#35757;&#32451;&#20063;&#33021;&#33719;&#24471;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.09869</link><description>&lt;p&gt;
&#23545;&#20122;&#32676;&#20307;&#20559;&#31227;&#30340;&#40065;&#26834;&#24615;&#25913;&#36827;&#65306;&#20351;&#29992;&#32452;&#24863;&#30693;&#20808;&#39564;
&lt;/p&gt;
&lt;p&gt;
Mind the GAP: Improving Robustness to Subpopulation Shifts with Group-Aware Priors
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09869
&lt;/p&gt;
&lt;p&gt;
&#24320;&#21457;&#20102;&#19968;&#26063;&#32452;&#24863;&#30693;&#20808;&#39564;&#20998;&#24067;&#65292;&#21487;&#20197;&#25913;&#36827;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#22312;&#25968;&#25454;&#20998;&#24067;&#30340;&#20122;&#32676;&#20307;&#20559;&#31227;&#19979;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#24182;&#23637;&#31034;&#20102;&#21363;&#20351;&#21482;&#37325;&#26032;&#35757;&#32451;&#38750;&#40065;&#26834;&#27169;&#22411;&#30340;&#26368;&#21518;&#19968;&#23618;&#65292;&#20351;&#29992;&#36825;&#31181;&#20808;&#39564;&#36827;&#34892;&#35757;&#32451;&#20063;&#33021;&#33719;&#24471;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#25968;&#25454;&#20998;&#24067;&#30340;&#20122;&#32676;&#20307;&#20559;&#31227;&#19979;&#24448;&#24448;&#34920;&#29616;&#19981;&#20339;&#12290;&#24320;&#21457;&#33021;&#22815;&#35753;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26356;&#22909;&#22320;&#27867;&#21270;&#21040;&#36825;&#31181;&#20559;&#31227;&#30340;&#26041;&#27861;&#23545;&#20110;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#23433;&#20840;&#37096;&#32626;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#26063;&#38024;&#23545;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#30340;&#32452;&#24863;&#30693;&#20808;&#39564;&#65288;GAP&#65289;&#20998;&#24067;&#65292;&#26126;&#30830;&#25903;&#25345;&#22312;&#25968;&#25454;&#20998;&#24067;&#30340;&#20122;&#32676;&#20307;&#20559;&#31227;&#19979;&#27867;&#21270;&#33391;&#22909;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#32452;&#24863;&#30693;&#20808;&#39564;&#65292;&#21482;&#38656;&#35201;&#35775;&#38382;&#19968;&#23567;&#37096;&#20998;&#21253;&#21547;&#32452;&#20449;&#24687;&#30340;&#25968;&#25454;&#65292;&#35777;&#26126;&#20102;&#22312;&#27492;&#20808;&#39564;&#19979;&#35757;&#32451;&#20250;&#33719;&#24471;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#8212;&#8212;&#21363;&#20351;&#21482;&#37325;&#26032;&#35757;&#32451;&#20808;&#21069;&#35757;&#32451;&#30340;&#38750;&#40065;&#26834;&#27169;&#22411;&#30340;&#26368;&#21518;&#19968;&#23618;&#12290;&#32452;&#24863;&#30693;&#20808;&#39564;&#22312;&#27010;&#24565;&#19978;&#31616;&#21333;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#65288;&#22914;&#23646;&#24615;&#20266;&#26631;&#35760;&#21644;&#25968;&#25454;&#37325;&#26032;&#21152;&#26435;&#65289;&#20114;&#34917;&#65292;&#20026;&#21033;&#29992;&#36125;&#21494;&#26031;&#25512;&#26029;&#20197;&#23454;&#29616;&#23545;&#20122;&#32676;&#20307;&#20559;&#31227;&#30340;&#40065;&#26834;&#24615;&#24320;&#36767;&#20102;&#26377;&#21069;&#26223;&#30340;&#26032;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09869v1 Announce Type: cross  Abstract: Machine learning models often perform poorly under subpopulation shifts in the data distribution. Developing methods that allow machine learning models to better generalize to such shifts is crucial for safe deployment in real-world settings. In this paper, we develop a family of group-aware prior (GAP) distributions over neural network parameters that explicitly favor models that generalize well under subpopulation shifts. We design a simple group-aware prior that only requires access to a small set of data with group information and demonstrate that training with this prior yields state-of-the-art performance -- even when only retraining the final layer of a previously trained non-robust model. Group aware-priors are conceptually simple, complementary to existing approaches, such as attribute pseudo labeling and data reweighting, and open up promising new avenues for harnessing Bayesian inference to enable robustness to subpopulation
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20272;&#35745;&#38543;&#26426;&#36882;&#24402;&#26641;&#20013;&#39030;&#28857;&#21040;&#36798;&#39034;&#24207;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;Jordan&#20013;&#24515;&#24615;&#24230;&#37327;&#30340;&#39034;&#24207;&#20272;&#35745;&#22120;&#65292;&#24182;&#35777;&#26126;&#20854;&#20960;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>https://arxiv.org/abs/2403.09755</link><description>&lt;p&gt;
&#20272;&#35745;&#38543;&#26426;&#36882;&#24402;&#26641;&#30340;&#21382;&#21490;
&lt;/p&gt;
&lt;p&gt;
Estimating the history of a random recursive tree
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09755
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20272;&#35745;&#38543;&#26426;&#36882;&#24402;&#26641;&#20013;&#39030;&#28857;&#21040;&#36798;&#39034;&#24207;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;Jordan&#20013;&#24515;&#24615;&#24230;&#37327;&#30340;&#39034;&#24207;&#20272;&#35745;&#22120;&#65292;&#24182;&#35777;&#26126;&#20854;&#20960;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20272;&#35745;&#38543;&#26426;&#36882;&#24402;&#26641;&#20013;&#39030;&#28857;&#21040;&#36798;&#39034;&#24207;&#30340;&#38382;&#39064;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#20010;&#22522;&#26412;&#27169;&#22411;&#65306;&#22343;&#21248;&#36830;&#25509;&#27169;&#22411;&#21644;&#32447;&#24615;&#20248;&#20808;&#36830;&#25509;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Jordan&#20013;&#24515;&#24615;&#24230;&#37327;&#30340;&#39034;&#24207;&#20272;&#35745;&#22120;&#65292;&#24182;&#23450;&#20041;&#20102;&#19968;&#26063;&#39118;&#38505;&#24230;&#37327;&#26469;&#37327;&#21270;&#25490;&#24207;&#36807;&#31243;&#30340;&#36136;&#37327;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20026;&#36825;&#20010;&#38382;&#39064;&#24314;&#31435;&#20102;&#26497;&#23567;-&#26368;&#22823;&#19979;&#30028;&#65292;&#24182;&#35777;&#26126;&#25152;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#20960;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#25152;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#20248;&#20110;&#22522;&#20110;&#24230;&#25968;&#21644;&#35889;&#25490;&#24207;&#31243;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09755v1 Announce Type: cross  Abstract: This paper studies the problem of estimating the order of arrival of the vertices in a random recursive tree. Specifically, we study two fundamental models: the uniform attachment model and the linear preferential attachment model. We propose an order estimator based on the Jordan centrality measure and define a family of risk measures to quantify the quality of the ordering procedure. Moreover, we establish a minimax lower bound for this problem, and prove that the proposed estimator is nearly optimal. Finally, we numerically demonstrate that the proposed estimator outperforms degree-based and spectral ordering procedures.
&lt;/p&gt;</description></item><item><title>&#28151;&#21512;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#20013;&#65292;&#36890;&#36807;&#23558;&#31163;&#32447;&#25968;&#25454;&#38598;&#21253;&#21547;&#22312;&#22312;&#32447;&#31639;&#27861;&#30340;&#32463;&#39564;&#37325;&#25918;&#32531;&#20914;&#21306;&#20013;&#36827;&#34892;&#21551;&#21160;&#65292;&#21487;&#20197;&#23454;&#29616;&#31867;&#20284;&#20110;&#22522;&#20110;&#31163;&#32447;&#25968;&#25454;&#20998;&#24067;&#24341;&#23548;&#22312;&#32447;&#25506;&#32034;&#30340;&#21487;&#35777;&#26126;&#25910;&#30410;&#65292;&#21363;&#20351;&#31163;&#32447;&#25968;&#25454;&#38598;&#27809;&#26377;&#21333;&#19968;&#31574;&#30053;&#21487;&#38598;&#20013;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.09701</link><description>&lt;p&gt;
&#19968;&#31181;&#23545;&#26377;&#38480;&#35206;&#30422;&#30340;&#28151;&#21512;RL&#22312;&#32447;&#31639;&#27861;&#30340;&#33258;&#28982;&#25193;&#23637;
&lt;/p&gt;
&lt;p&gt;
A Natural Extension To Online Algorithms For Hybrid RL With Limited Coverage
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09701
&lt;/p&gt;
&lt;p&gt;
&#28151;&#21512;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#20013;&#65292;&#36890;&#36807;&#23558;&#31163;&#32447;&#25968;&#25454;&#38598;&#21253;&#21547;&#22312;&#22312;&#32447;&#31639;&#27861;&#30340;&#32463;&#39564;&#37325;&#25918;&#32531;&#20914;&#21306;&#20013;&#36827;&#34892;&#21551;&#21160;&#65292;&#21487;&#20197;&#23454;&#29616;&#31867;&#20284;&#20110;&#22522;&#20110;&#31163;&#32447;&#25968;&#25454;&#20998;&#24067;&#24341;&#23548;&#22312;&#32447;&#25506;&#32034;&#30340;&#21487;&#35777;&#26126;&#25910;&#30410;&#65292;&#21363;&#20351;&#31163;&#32447;&#25968;&#25454;&#38598;&#27809;&#26377;&#21333;&#19968;&#31574;&#30053;&#21487;&#38598;&#20013;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28151;&#21512;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#32467;&#21512;&#22312;&#32447;&#21644;&#31163;&#32447;&#25968;&#25454;&#65292;&#36817;&#24180;&#26469;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#20294;&#20851;&#20110;&#20854;&#21487;&#35777;&#26126;&#30410;&#22788;&#30340;&#30740;&#31350;&#20173;&#28982;&#24456;&#23569;&#12290;&#35768;&#22810;&#29616;&#26377;&#30340;&#28151;&#21512;RL&#31639;&#27861;&#23545;&#31163;&#32447;&#25968;&#25454;&#38598;&#26045;&#21152;&#35206;&#30422;&#20551;&#35774;&#65292;&#20294;&#25105;&#20204;&#34920;&#26126;&#36825;&#26159;&#19981;&#24517;&#35201;&#30340;&#12290;&#19968;&#20010;&#35774;&#35745;&#33391;&#22909;&#30340;&#22312;&#32447;&#31639;&#27861;&#24212;&#35813;&#22312;&#31163;&#32447;&#25968;&#25454;&#38598;&#20013;&#8220;&#22635;&#34917;&#31354;&#30333;&#8221;&#65292;&#25506;&#32034;&#34892;&#20026;&#31574;&#30053;&#26410;&#25506;&#32034;&#30340;&#29366;&#24577;&#21644;&#21160;&#20316;&#12290;&#19982;&#20808;&#21069;&#20391;&#37325;&#20110;&#20272;&#35745;&#31163;&#32447;&#25968;&#25454;&#20998;&#24067;&#20197;&#24341;&#23548;&#22312;&#32447;&#25506;&#32034;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#34920;&#26126;&#23545;&#26631;&#20934;&#20048;&#35266;&#22312;&#32447;&#31639;&#27861;&#30340;&#19968;&#20010;&#33258;&#28982;&#25193;&#23637;&#8212;&#8212;&#36890;&#36807;&#23558;&#31163;&#32447;&#25968;&#25454;&#38598;&#21253;&#21547;&#22312;&#32463;&#39564;&#37325;&#25918;&#32531;&#20914;&#21306;&#20013;&#26469;&#21551;&#21160;&#23427;&#20204;&#8212;&#8212;&#21363;&#20351;&#31163;&#32447;&#25968;&#25454;&#38598;&#27809;&#26377;&#21333;&#19968;&#31574;&#30053;&#21487;&#38598;&#20013;&#24615;&#65292;&#20063;&#21487;&#23454;&#29616;&#28151;&#21512;&#25968;&#25454;&#30340;&#31867;&#20284;&#21487;&#35777;&#26126;&#25910;&#30410;&#12290;&#25105;&#20204;&#23436;&#25104;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09701v1 Announce Type: new  Abstract: Hybrid Reinforcement Learning (RL), leveraging both online and offline data, has garnered recent interest, yet research on its provable benefits remains sparse. Additionally, many existing hybrid RL algorithms (Song et al., 2023; Nakamoto et al., 2023; Amortila et al., 2024) impose coverage assumptions on the offline dataset, but we show that this is unnecessary. A well-designed online algorithm should "fill in the gaps" in the offline dataset, exploring states and actions that the behavior policy did not explore. Unlike previous approaches that focus on estimating the offline data distribution to guide online exploration (Li et al., 2023b), we show that a natural extension to standard optimistic online algorithms -- warm-starting them by including the offline dataset in the experience replay buffer -- achieves similar provable gains from hybrid data even when the offline dataset does not have single-policy concentrability. We accomplish
&lt;/p&gt;</description></item><item><title>VISA&#26041;&#27861;&#36890;&#36807;&#39034;&#24207;&#26679;&#26412;&#22343;&#20540;&#36924;&#36817;&#22312;&#35745;&#31639;&#23494;&#38598;&#22411;&#27169;&#22411;&#20013;&#23454;&#29616;&#36817;&#20284;&#25512;&#26029;&#65292;&#33021;&#22815;&#22312;&#20445;&#23432;&#36873;&#25321;&#23398;&#20064;&#29575;&#30340;&#24773;&#20917;&#19979;&#20197;&#36739;&#23567;&#30340;&#35745;&#31639;&#25104;&#26412;&#36798;&#21040;&#19982;&#26631;&#20934;&#26041;&#27861;&#30456;&#24403;&#30340;&#36924;&#36817;&#31934;&#24230;&#12290;</title><link>https://arxiv.org/abs/2403.09429</link><description>&lt;p&gt;
&#20855;&#26377;&#39034;&#24207;&#26679;&#26412;&#22343;&#20540;&#36924;&#36817;&#30340;&#21464;&#20998;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Variational Inference with Sequential Sample-Average Approximations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09429
&lt;/p&gt;
&lt;p&gt;
VISA&#26041;&#27861;&#36890;&#36807;&#39034;&#24207;&#26679;&#26412;&#22343;&#20540;&#36924;&#36817;&#22312;&#35745;&#31639;&#23494;&#38598;&#22411;&#27169;&#22411;&#20013;&#23454;&#29616;&#36817;&#20284;&#25512;&#26029;&#65292;&#33021;&#22815;&#22312;&#20445;&#23432;&#36873;&#25321;&#23398;&#20064;&#29575;&#30340;&#24773;&#20917;&#19979;&#20197;&#36739;&#23567;&#30340;&#35745;&#31639;&#25104;&#26412;&#36798;&#21040;&#19982;&#26631;&#20934;&#26041;&#27861;&#30456;&#24403;&#30340;&#36924;&#36817;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#39034;&#24207;&#26679;&#26412;&#22343;&#20540;&#36924;&#36817;&#65288;VISA&#65289;&#30340;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#35745;&#31639;&#23494;&#38598;&#22411;&#27169;&#22411;&#20013;&#36827;&#34892;&#36817;&#20284;&#25512;&#26029;&#65292;&#20363;&#22914;&#22522;&#20110;&#25968;&#20540;&#27169;&#25311;&#30340;&#27169;&#22411;&#12290;VISA&#36890;&#36807;&#37319;&#29992;&#19968;&#31995;&#21015;&#26679;&#26412;&#22343;&#20540;&#36924;&#36817;&#26469;&#25193;&#23637;&#37325;&#35201;&#24615;&#21152;&#26435;&#30340;&#21069;&#21521;KL&#21464;&#20998;&#25512;&#26029;&#65292;&#36825;&#20123;&#36924;&#36817;&#22312;&#20449;&#20219;&#21306;&#22495;&#20869;&#34987;&#35270;&#20026;&#26377;&#25928;&#12290;&#36825;&#20351;&#24471;&#21487;&#20197;&#22312;&#22810;&#20010;&#26799;&#24230;&#27493;&#39588;&#20013;&#37325;&#22797;&#20351;&#29992;&#27169;&#22411;&#35780;&#20272;&#65292;&#20174;&#32780;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#12290;&#25105;&#20204;&#22312;&#39640;&#32500;&#39640;&#26031;&#20998;&#24067;&#12289;Lotka-Volterra&#21160;&#21147;&#23398;&#21644;Pickover&#21560;&#24341;&#23376;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;VISA&#21487;&#20197;&#22312;&#36873;&#25321;&#20445;&#23432;&#30340;&#23398;&#20064;&#29575;&#30340;&#24773;&#20917;&#19979;&#65292;&#20197;&#20004;&#20493;&#25110;&#26356;&#39640;&#30340;&#35745;&#31639;&#33410;&#32422;&#36798;&#21040;&#19982;&#26631;&#20934;&#37325;&#35201;&#24615;&#21152;&#26435;&#21069;&#21521;KL&#21464;&#20998;&#25512;&#26029;&#30456;&#24403;&#30340;&#36924;&#36817;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09429v1 Announce Type: cross  Abstract: We present variational inference with sequential sample-average approximation (VISA), a method for approximate inference in computationally intensive models, such as those based on numerical simulations. VISA extends importance-weighted forward-KL variational inference by employing a sequence of sample-average approximations, which are considered valid inside a trust region. This makes it possible to reuse model evaluations across multiple gradient steps, thereby reducing computational cost. We perform experiments on high-dimensional Gaussians, Lotka-Volterra dynamics, and a Pickover attractor, which demonstrate that VISA can achieve comparable approximation accuracy to standard importance-weighted forward-KL variational inference with computational savings of a factor two or more for conservatively chosen learning rates.
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#30456;&#21516;&#25216;&#26415;&#33719;&#24471;&#20102;&#32039;&#25903;&#25745;&#23545;&#31216;&#27010;&#29575;&#27979;&#24230;&#19982;&#20854;&#23545;&#31216;&#32463;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#26399;&#26395;&#26368;&#22823;&#20999;&#29255;2-&#29926;&#22622;&#26031;&#22374;&#36317;&#31163;&#30340;&#19978;&#30028;</title><link>https://arxiv.org/abs/2403.02142</link><description>&lt;p&gt;
&#26368;&#22823;&#20999;&#29255;2-&#29926;&#22622;&#26031;&#22374;&#36317;&#31163;
&lt;/p&gt;
&lt;p&gt;
Max-sliced 2-Wasserstein distance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02142
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#30456;&#21516;&#25216;&#26415;&#33719;&#24471;&#20102;&#32039;&#25903;&#25745;&#23545;&#31216;&#27010;&#29575;&#27979;&#24230;&#19982;&#20854;&#23545;&#31216;&#32463;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#26399;&#26395;&#26368;&#22823;&#20999;&#29255;2-&#29926;&#22622;&#26031;&#22374;&#36317;&#31163;&#30340;&#19978;&#30028;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#31508;&#35760;&#26159;&#20316;&#32773;&#22312;&#8220;&#26368;&#22823;&#20999;&#29255;&#29926;&#22622;&#26031;&#22374;&#36317;&#31163;&#30340;&#23574;&#38160;&#30028;&#38480;&#8221;&#26041;&#38754;&#20043;&#21069;&#24037;&#20316;&#30340;&#24310;&#32493;&#12290;&#25105;&#20204;&#20351;&#29992;&#30456;&#21516;&#30340;&#25216;&#26415;&#33719;&#24471;&#32039;&#25903;&#25745;&#23545;&#31216;&#27010;&#29575;&#27979;&#24230;&#19982;&#20854;&#23545;&#31216;&#32463;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#26399;&#26395;&#26368;&#22823;&#20999;&#29255;2-&#29926;&#22622;&#26031;&#22374;&#36317;&#31163;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02142v1 Announce Type: cross  Abstract: This note is a continuation of the author's previous work on ``Sharp bounds for the max-sliced Wasserstein distance." We use the same technique to obtain an upper bound for the expected max-sliced 2-Wasserstein distance between a compactly supported symmetric probability measure on a Euclidean space and its symmetrized empirical distribution.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19977;&#20010;&#26032;&#30340;&#36317;&#31163;&#24230;&#37327;&#25351;&#26631;&#65288;s/c&#36317;&#31163;&#12289;&#39532;&#23572;&#31185;&#22827;&#36317;&#31163;&#21644;&#24544;&#23454;&#24230;&#36317;&#31163;&#65289;&#65292;&#29992;&#20110;&#35780;&#20272;&#22240;&#26524;&#25512;&#26029;&#31639;&#27861;&#30340;&#36755;&#20986;&#22270;&#19982;&#30495;&#23454;&#24773;&#20917;&#30340;&#20998;&#31163;/&#36830;&#25509;&#31243;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.04952</link><description>&lt;p&gt;
&#35780;&#20272;&#22240;&#26524;&#25512;&#26029;&#31639;&#27861;&#30340;&#39532;&#23572;&#31185;&#22827;&#31561;&#20215;&#31867;&#25351;&#26631;
&lt;/p&gt;
&lt;p&gt;
Metrics on Markov Equivalence Classes for Evaluating Causal Discovery Algorithms
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04952
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19977;&#20010;&#26032;&#30340;&#36317;&#31163;&#24230;&#37327;&#25351;&#26631;&#65288;s/c&#36317;&#31163;&#12289;&#39532;&#23572;&#31185;&#22827;&#36317;&#31163;&#21644;&#24544;&#23454;&#24230;&#36317;&#31163;&#65289;&#65292;&#29992;&#20110;&#35780;&#20272;&#22240;&#26524;&#25512;&#26029;&#31639;&#27861;&#30340;&#36755;&#20986;&#22270;&#19982;&#30495;&#23454;&#24773;&#20917;&#30340;&#20998;&#31163;/&#36830;&#25509;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#26368;&#20808;&#36827;&#30340;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#26088;&#22312;&#29983;&#25104;&#19968;&#20010;&#36755;&#20986;&#22270;&#65292;&#35813;&#22270;&#32534;&#30721;&#20102;&#29983;&#25104;&#25968;&#25454;&#36807;&#31243;&#30340;&#22240;&#26524;&#22270;&#30340;&#22270;&#24418;&#20998;&#31163;&#21644;&#36830;&#25509;&#38472;&#36848;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35748;&#20026;&#65292;&#23545;&#21512;&#25104;&#25968;&#25454;&#30340;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#36827;&#34892;&#35780;&#20272;&#24212;&#35813;&#21253;&#25324;&#20998;&#26512;&#35813;&#26041;&#27861;&#30340;&#36755;&#20986;&#19982;&#30495;&#23454;&#24773;&#20917;&#30340;&#20998;&#31163;/&#36830;&#25509;&#31243;&#24230;&#65292;&#20197;&#34913;&#37327;&#36825;&#19968;&#26126;&#30830;&#30446;&#26631;&#30340;&#23454;&#29616;&#24773;&#20917;&#12290;&#25105;&#20204;&#35777;&#26126;&#29616;&#26377;&#30340;&#35780;&#20272;&#25351;&#26631;&#19981;&#33021;&#20934;&#30830;&#25429;&#25417;&#21040;&#20004;&#20010;&#22240;&#26524;&#22270;&#30340;&#20998;&#31163;/&#36830;&#25509;&#24046;&#24322;&#65292;&#24182;&#24341;&#20837;&#20102;&#19977;&#20010;&#26032;&#30340;&#36317;&#31163;&#24230;&#37327;&#25351;&#26631;&#65292;&#21363;s/c&#36317;&#31163;&#12289;&#39532;&#23572;&#31185;&#22827;&#36317;&#31163;&#21644;&#24544;&#23454;&#24230;&#36317;&#31163;&#65292;&#20197;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#36890;&#36807;&#29609;&#20855;&#31034;&#20363;&#12289;&#23454;&#35777;&#23454;&#39564;&#21644;&#20266;&#20195;&#30721;&#26469;&#34917;&#20805;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many state-of-the-art causal discovery methods aim to generate an output graph that encodes the graphical separation and connection statements of the causal graph that underlies the data-generating process. In this work, we argue that an evaluation of a causal discovery method against synthetic data should include an analysis of how well this explicit goal is achieved by measuring how closely the separations/connections of the method's output align with those of the ground truth. We show that established evaluation measures do not accurately capture the difference in separations/connections of two causal graphs, and we introduce three new measures of distance called s/c-distance, Markov distance and Faithfulness distance that address this shortcoming. We complement our theoretical analysis with toy examples, empirical experiments and pseudocode.
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#19968;&#32452;&#26032;&#39062;&#26465;&#20214;&#65292;&#35777;&#26126;&#20102;&#23398;&#20064;&#39532;&#23572;&#21487;&#22827;&#25277;&#35937;&#29366;&#24577;&#34920;&#31034;&#30340;&#20805;&#20998;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#32467;&#21512;&#36870;&#27169;&#22411;&#20272;&#35745;&#21644;&#26102;&#38388;&#23545;&#27604;&#23398;&#20064;&#30340;&#23454;&#29992;&#35757;&#32451;&#36807;&#31243;&#65292;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#22312;&#32447;&#21644;&#31163;&#32447;&#35757;&#32451;&#65292;&#19981;&#20381;&#36182;&#22870;&#21169;&#20449;&#21495;&#20294;&#21487;&#20197;&#21033;&#29992;&#22870;&#21169;&#20449;&#24687;&#12290;</title><link>https://arxiv.org/abs/2106.04379</link><description>&lt;p&gt;
&#23398;&#20064;&#39532;&#23572;&#21487;&#22827;&#29366;&#24577;&#25277;&#35937;&#20197;&#29992;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Learning Markov State Abstractions for Deep Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2106.04379
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#19968;&#32452;&#26032;&#39062;&#26465;&#20214;&#65292;&#35777;&#26126;&#20102;&#23398;&#20064;&#39532;&#23572;&#21487;&#22827;&#25277;&#35937;&#29366;&#24577;&#34920;&#31034;&#30340;&#20805;&#20998;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#32467;&#21512;&#36870;&#27169;&#22411;&#20272;&#35745;&#21644;&#26102;&#38388;&#23545;&#27604;&#23398;&#20064;&#30340;&#23454;&#29992;&#35757;&#32451;&#36807;&#31243;&#65292;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#22312;&#32447;&#21644;&#31163;&#32447;&#35757;&#32451;&#65292;&#19981;&#20381;&#36182;&#22870;&#21169;&#20449;&#21495;&#20294;&#21487;&#20197;&#21033;&#29992;&#22870;&#21169;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#22312;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#20551;&#35774;&#26159;&#65292;&#30456;&#20851;&#30340;&#20915;&#31574;&#36807;&#31243;&#23454;&#38469;&#19978;&#26159;&#39532;&#23572;&#21487;&#22827;&#30340;&#12290;&#28982;&#32780;&#65292;&#24403;MDPs&#20855;&#26377;&#20016;&#23500;&#30340;&#35266;&#27979;&#26102;&#65292;&#20195;&#29702;&#36890;&#24120;&#36890;&#36807;&#25277;&#35937;&#29366;&#24577;&#34920;&#31034;&#23398;&#20064;&#65292;&#36825;&#31181;&#34920;&#31034;&#26410;&#24517;&#33021;&#20445;&#25345;&#39532;&#23572;&#21487;&#22827;&#24615;&#36136;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#32452;&#26032;&#39062;&#30340;&#26465;&#20214;&#65292;&#24182;&#35777;&#26126;&#23427;&#20204;&#36275;&#20197;&#23398;&#20064;&#39532;&#23572;&#21487;&#22827;&#25277;&#35937;&#29366;&#24577;&#34920;&#31034;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#20010;&#23454;&#29992;&#30340;&#35757;&#32451;&#36807;&#31243;&#65292;&#32467;&#21512;&#20102;&#36870;&#27169;&#22411;&#20272;&#35745;&#21644;&#26102;&#38388;&#23545;&#27604;&#23398;&#20064;&#65292;&#20197;&#23398;&#20064;&#19968;&#20010;&#36817;&#20284;&#28385;&#36275;&#36825;&#20123;&#26465;&#20214;&#30340;&#25277;&#35937;&#12290;&#25105;&#20204;&#30340;&#26032;&#39062;&#35757;&#32451;&#30446;&#26631;&#36866;&#29992;&#20110;&#22312;&#32447;&#21644;&#31163;&#32447;&#35757;&#32451;&#65306;&#23427;&#19981;&#38656;&#35201;&#22870;&#21169;&#20449;&#21495;&#65292;&#20294;&#24403;&#21487;&#29992;&#26102;&#65292;&#20195;&#29702;&#21487;&#20197;&#21033;&#29992;&#22870;&#21169;&#20449;&#24687;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#35270;&#35273;&#26684;&#23376;&#19990;&#30028;&#22495;&#21644;&#19968;&#32452;&#36830;&#32493;&#25511;&#21046;&#22522;&#20934;&#20219;&#21153;&#19978;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2106.04379v4 Announce Type: replace-cross  Abstract: A fundamental assumption of reinforcement learning in Markov decision processes (MDPs) is that the relevant decision process is, in fact, Markov. However, when MDPs have rich observations, agents typically learn by way of an abstract state representation, and such representations are not guaranteed to preserve the Markov property. We introduce a novel set of conditions and prove that they are sufficient for learning a Markov abstract state representation. We then describe a practical training procedure that combines inverse model estimation and temporal contrastive learning to learn an abstraction that approximately satisfies these conditions. Our novel training objective is compatible with both online and offline training: it does not require a reward signal, but agents can capitalize on reward information when available. We empirically evaluate our approach on a visual gridworld domain and a set of continuous control benchmar
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#27169;&#22411;&#36866;&#24212;&#26469;&#26816;&#27979;&#21644;&#20943;&#36731;&#35821;&#35328;&#27169;&#22411;&#20013;&#24615;&#21035;&#20559;&#35265;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#33021;&#22815;&#26174;&#33879;&#20943;&#23569;&#20559;&#35265;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.18913</link><description>&lt;p&gt;
&#36890;&#36807;&#27169;&#22411;&#36866;&#24212;&#26469;&#21435;&#38500;&#20559;&#35265;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Debiasing Algorithm through Model Adaptation. (arXiv:2310.18913v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18913
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#27169;&#22411;&#36866;&#24212;&#26469;&#26816;&#27979;&#21644;&#20943;&#36731;&#35821;&#35328;&#27169;&#22411;&#20013;&#24615;&#21035;&#20559;&#35265;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#33021;&#22815;&#26174;&#33879;&#20943;&#23569;&#20559;&#35265;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27491;&#22312;&#25104;&#20026;&#21508;&#31181;&#35821;&#35328;&#20219;&#21153;&#30340;&#39318;&#36873;&#35299;&#20915;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#23481;&#37327;&#30340;&#22686;&#38271;&#65292;&#27169;&#22411;&#24456;&#23481;&#26131;&#20381;&#36182;&#35757;&#32451;&#25968;&#25454;&#20013;&#23384;&#22312;&#30340;&#20559;&#35265;&#21644;&#21051;&#26495;&#21360;&#35937;&#25152;&#20135;&#29983;&#30340;&#34394;&#20551;&#30456;&#20851;&#24615;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#26816;&#27979;&#21644;&#20943;&#36731;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#24615;&#21035;&#20559;&#35265;&#12290;&#25105;&#20204;&#36827;&#34892;&#22240;&#26524;&#20998;&#26512;&#65292;&#20197;&#35782;&#21035;&#38382;&#39064;&#27169;&#22411;&#32452;&#20214;&#65292;&#24182;&#21457;&#29616;&#20013;&#19978;&#23618;&#21069;&#39304;&#23618;&#26368;&#23481;&#26131;&#20256;&#36882;&#20559;&#35265;&#12290;&#26681;&#25454;&#20998;&#26512;&#32467;&#26524;&#65292;&#25105;&#20204;&#36890;&#36807;&#32447;&#24615;&#25237;&#24433;&#23558;&#36825;&#20123;&#23618;&#20056;&#20197;&#27169;&#22411;&#36827;&#34892;&#36866;&#24212;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;DAMA&#36890;&#36807;&#21508;&#31181;&#24230;&#37327;&#25351;&#26631;&#26126;&#26174;&#20943;&#23569;&#20102;&#20559;&#35265;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#22312;&#21518;&#32493;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#21457;&#24067;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21644;&#27169;&#22411;&#30340;&#20195;&#30721;&#65292;&#36890;&#36807;&#37325;&#26032;&#35757;&#32451;&#65292;&#20445;&#25345;&#20102;LLaMA&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#65292;&#21516;&#26102;&#20559;&#35265;&#26174;&#33879;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models are becoming the go-to solution for various language tasks. However, with growing capacity, models are prone to rely on spurious correlations stemming from biases and stereotypes present in the training data. This work proposes a novel method for detecting and mitigating gender bias in language models. We perform causal analysis to identify problematic model components and discover that mid-upper feed-forward layers are most prone to convey biases. Based on the analysis results, we adapt the model by multiplying these layers by a linear projection. Our titular method, DAMA, significantly decreases bias as measured by diverse metrics while maintaining the model's performance on downstream tasks. We release code for our method and models, which retrain LLaMA's state-of-the-art performance while being significantly less biased.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#65292;&#24182;&#21457;&#29616;&#26377;&#25928;&#30340;&#39044;&#35757;&#32451;&#21482;&#38656;&#35201;&#23569;&#37327;&#29420;&#31435;&#20219;&#21153;&#65292;&#39044;&#35757;&#32451;&#27169;&#22411;&#19982;&#36125;&#21494;&#26031;&#26368;&#20248;&#31639;&#27861;&#25509;&#36817;&#12290;&#36825;&#20123;&#29702;&#35770;&#21457;&#29616;&#23545;ICL&#30340;&#32479;&#35745;&#22522;&#30784;&#25552;&#20379;&#20102;&#21551;&#31034;&#12290;</title><link>http://arxiv.org/abs/2310.08391</link><description>&lt;p&gt;
&#22810;&#23569;&#20010;&#39044;&#35757;&#32451;&#20219;&#21153;&#38656;&#35201;&#29992;&#20110;&#32447;&#24615;&#22238;&#24402;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#65311;
&lt;/p&gt;
&lt;p&gt;
How Many Pretraining Tasks Are Needed for In-Context Learning of Linear Regression?. (arXiv:2310.08391v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08391
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#65292;&#24182;&#21457;&#29616;&#26377;&#25928;&#30340;&#39044;&#35757;&#32451;&#21482;&#38656;&#35201;&#23569;&#37327;&#29420;&#31435;&#20219;&#21153;&#65292;&#39044;&#35757;&#32451;&#27169;&#22411;&#19982;&#36125;&#21494;&#26031;&#26368;&#20248;&#31639;&#27861;&#25509;&#36817;&#12290;&#36825;&#20123;&#29702;&#35770;&#21457;&#29616;&#23545;ICL&#30340;&#32479;&#35745;&#22522;&#30784;&#25552;&#20379;&#20102;&#21551;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#26679;&#20219;&#21153;&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#30340;Transformer&#23637;&#29616;&#20102;&#38750;&#20961;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#65288;ICL&#65289;&#33021;&#21147;&#65292;&#20351;&#20854;&#33021;&#22815;&#20165;&#22522;&#20110;&#36755;&#20837;&#19978;&#19979;&#25991;&#35299;&#20915;&#26410;&#35265;&#20219;&#21153;&#65292;&#32780;&#26080;&#38656;&#35843;&#25972;&#27169;&#22411;&#21442;&#25968;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20854;&#20013;&#26368;&#31616;&#21333;&#35774;&#32622;&#30340;ICL&#65306;&#39044;&#35757;&#32451;&#32447;&#24615;&#21442;&#25968;&#21270;&#30340;&#21333;&#23618;&#32447;&#24615;&#27880;&#24847;&#21147;&#27169;&#22411;&#65292;&#29992;&#20110;&#20855;&#26377;&#39640;&#26031;&#20808;&#39564;&#30340;&#32447;&#24615;&#22238;&#24402;&#12290;&#25105;&#20204;&#20026;&#27880;&#24847;&#21147;&#27169;&#22411;&#39044;&#35757;&#32451;&#24314;&#31435;&#20102;&#19968;&#20010;&#32479;&#35745;&#20219;&#21153;&#22797;&#26434;&#24230;&#30028;&#65292;&#34920;&#26126;&#26377;&#25928;&#30340;&#39044;&#35757;&#32451;&#21482;&#38656;&#35201;&#23569;&#37327;&#29420;&#31435;&#20219;&#21153;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#39044;&#35757;&#32451;&#27169;&#22411;&#19982;&#36125;&#21494;&#26031;&#26368;&#20248;&#31639;&#27861;&#38750;&#24120;&#25509;&#36817;&#65292;&#21363;&#20960;&#20046;&#23454;&#29616;&#20102;&#22266;&#23450;&#19978;&#19979;&#25991;&#38271;&#24230;&#19979;&#26410;&#35265;&#20219;&#21153;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#39118;&#38505;&#12290;&#36825;&#20123;&#29702;&#35770;&#21457;&#29616;&#23545;&#20043;&#21069;&#30340;&#23454;&#39564;&#30740;&#31350;&#36827;&#34892;&#20102;&#34917;&#20805;&#65292;&#24182;&#20026;ICL&#30340;&#32479;&#35745;&#22522;&#30784;&#25552;&#20379;&#20102;&#21551;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformers pretrained on diverse tasks exhibit remarkable in-context learning (ICL) capabilities, enabling them to solve unseen tasks solely based on input contexts without adjusting model parameters. In this paper, we study ICL in one of its simplest setups: pretraining a linearly parameterized single-layer linear attention model for linear regression with a Gaussian prior. We establish a statistical task complexity bound for the attention model pretraining, showing that effective pretraining only requires a small number of independent tasks. Furthermore, we prove that the pretrained model closely matches the Bayes optimal algorithm, i.e., optimally tuned ridge regression, by achieving nearly Bayes optimal risk on unseen tasks under a fixed context length. These theoretical findings complement prior experimental research and shed light on the statistical foundations of ICL.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21518;&#39564;&#20559;&#24046;&#35780;&#20998;&#30340;&#26041;&#27861;&#65292;&#22312;&#28385;&#36275;&#20844;&#24179;&#24615;&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#20445;&#25345;&#39640;&#20934;&#30830;&#24615;&#65292;&#24182;&#32473;&#20986;&#20102;&#22522;&#20110;&#20559;&#24046;&#20998;&#25968;&#30340;&#20462;&#25913;&#35268;&#21017;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#21508;&#31181;&#31867;&#22411;&#30340;&#20844;&#24179;&#24615;&#32422;&#26463;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.05725</link><description>&lt;p&gt;
&#21518;&#39564;&#20559;&#24046;&#35780;&#20998;&#23545;&#20844;&#24179;&#20998;&#31867;&#26368;&#20248;
&lt;/p&gt;
&lt;p&gt;
Post-hoc Bias Scoring Is Optimal For Fair Classification. (arXiv:2310.05725v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05725
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21518;&#39564;&#20559;&#24046;&#35780;&#20998;&#30340;&#26041;&#27861;&#65292;&#22312;&#28385;&#36275;&#20844;&#24179;&#24615;&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#20445;&#25345;&#39640;&#20934;&#30830;&#24615;&#65292;&#24182;&#32473;&#20986;&#20102;&#22522;&#20110;&#20559;&#24046;&#20998;&#25968;&#30340;&#20462;&#25913;&#35268;&#21017;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#21508;&#31181;&#31867;&#22411;&#30340;&#20844;&#24179;&#24615;&#32422;&#26463;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#22312;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#19979;&#30340;&#20108;&#20803;&#20998;&#31867;&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#21487;&#20197;&#26159;&#20154;&#21475;&#32479;&#35745;&#23398;&#20844;&#24179;&#24615;&#65288;DP&#65289;&#65292;&#26426;&#20250;&#22343;&#31561;&#65288;EOp&#65289;&#25110;&#31561;&#27010;&#29575;&#65288;EO&#65289;&#20043;&#19968;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#20844;&#24179;&#24615;&#32422;&#26463;&#19979;&#36125;&#21494;&#26031;&#26368;&#20248;&#20998;&#31867;&#22120;&#30340;&#26126;&#30830;&#29305;&#24449;&#21270;&#65292;&#32467;&#26524;&#26159;&#19981;&#21463;&#32422;&#26463;&#20998;&#31867;&#22120;&#30340;&#31616;&#21333;&#20462;&#25913;&#35268;&#21017;&#12290;&#21363;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#23454;&#20363;&#32423;&#21035;&#30340;&#20559;&#24046;&#24230;&#37327;&#65292;&#31216;&#20026;&#20559;&#24046;&#20998;&#25968;&#65292;&#32780;&#20462;&#25913;&#35268;&#21017;&#21017;&#26159;&#22312;&#26377;&#38480;&#37327;&#30340;&#20559;&#24046;&#20998;&#25968;&#20043;&#19978;&#30340;&#31616;&#21333;&#32447;&#24615;&#35268;&#21017;&#12290;&#22522;&#20110;&#36825;&#20010;&#29305;&#24449;&#21270;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#21518;&#39564;&#26041;&#27861;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#36866;&#24212;&#20844;&#24179;&#24615;&#32422;&#26463;&#21516;&#26102;&#20445;&#25345;&#36739;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;&#22312;DP&#21644;EOp&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#65292;&#20462;&#25913;&#35268;&#21017;&#26159;&#22522;&#20110;&#21333;&#20010;&#20559;&#24046;&#20998;&#25968;&#30340;&#38408;&#20540;&#36873;&#25321;&#65292;&#32780;&#22312;EO&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#38656;&#35201;&#35843;&#25972;&#20855;&#26377;2&#20010;&#21442;&#25968;&#30340;&#32447;&#24615;&#20462;&#25913;&#35268;&#21017;&#12290;&#35813;&#26041;&#27861;&#36824;&#21487;&#20197;&#29992;&#20110;&#21253;&#21547;&#22810;&#20010;&#25935;&#24863;&#23646;&#24615;&#30340;&#22797;&#21512;&#32676;&#20307;&#20844;&#24179;&#24615;&#26631;&#20934;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a binary classification problem under group fairness constraints, which can be one of Demographic Parity (DP), Equalized Opportunity (EOp), or Equalized Odds (EO). We propose an explicit characterization of Bayes optimal classifier under the fairness constraints, which turns out to be a simple modification rule of the unconstrained classifier. Namely, we introduce a novel instance-level measure of bias, which we call bias score, and the modification rule is a simple linear rule on top of the finite amount of bias scores. Based on this characterization, we develop a post-hoc approach that allows us to adapt to fairness constraints while maintaining high accuracy. In the case of DP and EOp constraints, the modification rule is thresholding a single bias score, while in the case of EO constraints we are required to fit a linear modification rule with 2 parameters. The method can also be applied for composite group-fairness criteria, such as ones involving several sensitive att
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27809;&#26377;&#22522;&#20934;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#35780;&#20272;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#19981;&#21516;&#21464;&#37327;&#23376;&#38598;&#19978;&#23398;&#20064;&#30340;&#22240;&#26524;&#22270;&#20043;&#38388;&#30340;&#20860;&#23481;&#24615;&#26816;&#27979;&#65292;&#26469;&#20266;&#35777;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#26029;&#27491;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.09552</link><description>&lt;p&gt;
&#33258;&#25105;&#20860;&#23481;&#24615;&#65306;&#22312;&#27809;&#26377;&#22522;&#20934;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#35780;&#20272;&#22240;&#26524;&#21457;&#29616;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-Compatibility: Evaluating Causal Discovery without Ground Truth. (arXiv:2307.09552v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09552
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27809;&#26377;&#22522;&#20934;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#35780;&#20272;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#19981;&#21516;&#21464;&#37327;&#23376;&#38598;&#19978;&#23398;&#20064;&#30340;&#22240;&#26524;&#22270;&#20043;&#38388;&#30340;&#20860;&#23481;&#24615;&#26816;&#27979;&#65292;&#26469;&#20266;&#35777;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#26029;&#27491;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#22240;&#26524;&#22522;&#26412;&#20107;&#23454;&#38750;&#24120;&#32597;&#35265;&#65292;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#36890;&#24120;&#21482;&#22312;&#27169;&#25311;&#25968;&#25454;&#19978;&#36827;&#34892;&#35780;&#20272;&#12290;&#36825;&#20196;&#20154;&#25285;&#24551;&#65292;&#22240;&#20026;&#27169;&#25311;&#21453;&#26144;&#20102;&#20851;&#20110;&#22122;&#22768;&#20998;&#24067;&#12289;&#27169;&#22411;&#31867;&#21035;&#31561;&#29983;&#25104;&#36807;&#31243;&#30340;&#24120;&#35265;&#20551;&#35774;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#27809;&#26377;&#22522;&#20934;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#23545;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#30340;&#36755;&#20986;&#36827;&#34892;&#20266;&#35777;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#35265;&#35299;&#26159;&#65292;&#23613;&#31649;&#32479;&#35745;&#23398;&#20064;&#23547;&#27714;&#25968;&#25454;&#28857;&#23376;&#38598;&#20043;&#38388;&#30340;&#31283;&#23450;&#24615;&#65292;&#20294;&#22240;&#26524;&#23398;&#20064;&#24212;&#35813;&#23547;&#27714;&#21464;&#37327;&#23376;&#38598;&#20043;&#38388;&#30340;&#31283;&#23450;&#24615;&#12290;&#22522;&#20110;&#36825;&#20010;&#35265;&#35299;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#22312;&#19981;&#21516;&#21464;&#37327;&#23376;&#38598;&#19978;&#23398;&#20064;&#30340;&#22240;&#26524;&#22270;&#20043;&#38388;&#30340;&#20860;&#23481;&#24615;&#27010;&#24565;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#26816;&#27979;&#19981;&#20860;&#23481;&#24615;&#21487;&#20197;&#20266;&#35777;&#22240;&#26524;&#20851;&#31995;&#34987;&#38169;&#35823;&#25512;&#26029;&#30340;&#21407;&#22240;&#65292;&#36825;&#26159;&#22240;&#20026;&#20551;&#35774;&#36829;&#21453;&#25110;&#26377;&#38480;&#26679;&#26412;&#25928;&#24212;&#24102;&#26469;&#30340;&#38169;&#35823;&#12290;&#34429;&#28982;&#36890;&#36807;&#36825;&#31181;&#20860;&#23481;&#24615;&#27979;&#35797;&#21482;&#26159;&#23545;&#33391;&#22909;&#24615;&#33021;&#30340;&#24517;&#35201;&#26465;&#20214;&#65292;&#20294;&#25105;&#20204;&#35748;&#20026;&#23427;&#25552;&#20379;&#20102;&#24378;&#26377;&#21147;&#30340;&#35777;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
As causal ground truth is incredibly rare, causal discovery algorithms are commonly only evaluated on simulated data. This is concerning, given that simulations reflect common preconceptions about generating processes regarding noise distributions, model classes, and more. In this work, we propose a novel method for falsifying the output of a causal discovery algorithm in the absence of ground truth. Our key insight is that while statistical learning seeks stability across subsets of data points, causal learning should seek stability across subsets of variables. Motivated by this insight, our method relies on a notion of compatibility between causal graphs learned on different subsets of variables. We prove that detecting incompatibilities can falsify wrongly inferred causal relations due to violation of assumptions or errors from finite sample effects. Although passing such compatibility tests is only a necessary criterion for good performance, we argue that it provides strong evidenc
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#26469;&#35843;&#25972;&#35757;&#32451;&#38598;&#20013;&#30340;&#38543;&#26426;&#26679;&#26412;&#65292;&#20197;&#20351;PDE&#35299;&#30340;&#27531;&#20313;&#22312;&#26368;&#23567;&#21270;&#26102;&#33021;&#20445;&#25345;&#24179;&#28369;&#30340;&#36718;&#24275;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#23545;&#25239;&#24615;&#25439;&#22833;&#39033;&#20248;&#21270;PINN&#27169;&#22411;&#65292;&#20174;&#32780;&#20351;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#31283;&#23450;&#30340;&#35299;&#12290;&#21516;&#26102;&#26412;&#25991;&#36824;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#21487;&#20197;&#25193;&#23637;&#21040;&#32435;&#20837;&#26368;&#20248;&#20256;&#36755;&#32422;&#26463;&#65292;&#20174;&#32780;&#24418;&#25104;&#20102;&#23558;PINN&#21644;&#26368;&#20248;&#20256;&#36755;&#30340;&#20248;&#28857;&#32467;&#21512;&#36215;&#26469;&#30340;&#32479;&#19968;&#26694;&#26550;&#65292;&#29992;&#20110;PDE&#36817;&#20284;&#12290;</title><link>http://arxiv.org/abs/2305.18702</link><description>&lt;p&gt;
&#23545;&#25239;&#24335;&#33258;&#36866;&#24212;&#37319;&#26679;&#65306;&#23558;PINN&#21644;&#26368;&#20248;&#20256;&#36755;&#32479;&#19968;&#29992;&#20110;PDE&#36817;&#20284;
&lt;/p&gt;
&lt;p&gt;
Adversarial Adaptive Sampling: Unify PINN and Optimal Transport for the Approximation of PDEs. (arXiv:2305.18702v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18702
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#26469;&#35843;&#25972;&#35757;&#32451;&#38598;&#20013;&#30340;&#38543;&#26426;&#26679;&#26412;&#65292;&#20197;&#20351;PDE&#35299;&#30340;&#27531;&#20313;&#22312;&#26368;&#23567;&#21270;&#26102;&#33021;&#20445;&#25345;&#24179;&#28369;&#30340;&#36718;&#24275;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#23545;&#25239;&#24615;&#25439;&#22833;&#39033;&#20248;&#21270;PINN&#27169;&#22411;&#65292;&#20174;&#32780;&#20351;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#31283;&#23450;&#30340;&#35299;&#12290;&#21516;&#26102;&#26412;&#25991;&#36824;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#21487;&#20197;&#25193;&#23637;&#21040;&#32435;&#20837;&#26368;&#20248;&#20256;&#36755;&#32422;&#26463;&#65292;&#20174;&#32780;&#24418;&#25104;&#20102;&#23558;PINN&#21644;&#26368;&#20248;&#20256;&#36755;&#30340;&#20248;&#28857;&#32467;&#21512;&#36215;&#26469;&#30340;&#32479;&#19968;&#26694;&#26550;&#65292;&#29992;&#20110;PDE&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27714;&#35299;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDE&#65289;&#26159;&#31185;&#23398;&#35745;&#31639;&#30340;&#19968;&#20010;&#26680;&#24515;&#20219;&#21153;&#12290;&#36817;&#24180;&#26469;&#65292;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;PDE&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#65292;&#20855;&#26377;&#26080;&#32593;&#26684;&#31163;&#25955;&#30340;&#28789;&#27963;&#24615;&#21644;&#35299;&#20915;&#39640;&#32500;&#38382;&#39064;&#30340;&#28508;&#21147;&#12290;&#19968;&#20010;&#22522;&#26412;&#30340;&#35745;&#31639;&#22256;&#38590;&#26159;&#35757;&#32451;&#38598;&#20013;&#30340;&#38543;&#26426;&#26679;&#26412;&#24341;&#20837;&#20102;&#32479;&#35745;&#38169;&#35823;&#65292;&#21487;&#33021;&#25104;&#20026;&#26368;&#32456;&#36924;&#36817;&#20013;&#21344;&#20027;&#23548;&#30340;&#35823;&#24046;&#65292;&#20174;&#32780;&#25513;&#30422;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#24314;&#27169;&#33021;&#21147;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;minmax&#20844;&#24335;&#65292;&#21516;&#26102;&#20248;&#21270;&#36817;&#20284;&#30340;&#35299;&#21644;&#30001;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#25552;&#20379;&#30340;&#35757;&#32451;&#38598;&#20013;&#30340;&#38543;&#26426;&#26679;&#26412;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#35843;&#25972;&#35757;&#32451;&#38598;&#20013;&#30340;&#38543;&#26426;&#26679;&#26412;&#65292;&#20351;&#36817;&#20284;PDE&#35299;&#24341;&#36215;&#30340;&#27531;&#20313;&#22312;&#26368;&#23567;&#21270;&#26102;&#33021;&#20445;&#25345;&#24179;&#28369;&#30340;&#36718;&#24275;&#12290;&#36825;&#31181;&#24819;&#27861;&#26159;&#36890;&#36807;&#22312;PINN&#20248;&#21270;&#36807;&#31243;&#20013;&#24341;&#20837;&#23545;&#25239;&#24615;&#25439;&#22833;&#39033;&#26469;&#23454;&#29616;&#30340;&#65292;&#35813;&#25439;&#22833;&#39033;&#40723;&#21169;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#31283;&#23450;&#30340;&#35299;&#65292;&#21363;&#20351;&#35757;&#32451;&#38598;&#20013;&#30340;&#26679;&#26412;&#26377;&#38480;&#25110;&#36755;&#20837;&#21547;&#22122;&#22768;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#33258;&#28982;&#22320;&#25193;&#23637;&#21040;&#32435;&#20837;&#26368;&#20248;&#20256;&#36755;&#32422;&#26463;&#65292;&#20174;&#32780;&#24418;&#25104;&#23558;PINN&#21644;&#26368;&#20248;&#20256;&#36755;&#30340;&#20248;&#28857;&#32467;&#21512;&#36215;&#26469;&#30340;&#32479;&#19968;&#26694;&#26550;&#65292;&#29992;&#20110;PDE&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;
Solving partial differential equations (PDEs) is a central task in scientific computing. Recently, neural network approximation of PDEs has received increasing attention due to its flexible meshless discretization and its potential for high-dimensional problems. One fundamental numerical difficulty is that random samples in the training set introduce statistical errors into the discretization of loss functional which may become the dominant error in the final approximation, and therefore overshadow the modeling capability of the neural network. In this work, we propose a new minmax formulation to optimize simultaneously the approximate solution, given by a neural network model, and the random samples in the training set, provided by a deep generative model. The key idea is to use a deep generative model to adjust random samples in the training set such that the residual induced by the approximate PDE solution can maintain a smooth profile when it is being minimized. Such an idea is ach
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20302;&#31209;&#32467;&#26500;&#20294;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#30340;&#24773;&#20917;&#65292;&#22312;&#20998;&#31163;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#30340;&#20551;&#35774;&#19979;&#65292;&#35299;&#20915;&#20102;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#20998;&#24067;&#20559;&#31227;&#30340;&#24773;&#20917;&#19979;&#65292;&#26412;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;&#27867;&#21270;&#35823;&#24046;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.17297</link><description>&lt;p&gt;
&#26080;&#29420;&#31435;&#24615;&#30340;&#27867;&#21270;&#35823;&#24046;&#65306;&#21435;&#22122;&#12289;&#32447;&#24615;&#22238;&#24402;&#21644;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Generalization Error without Independence: Denoising, Linear Regression, and Transfer Learning. (arXiv:2305.17297v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17297
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20302;&#31209;&#32467;&#26500;&#20294;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#30340;&#24773;&#20917;&#65292;&#22312;&#20998;&#31163;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#30340;&#20551;&#35774;&#19979;&#65292;&#35299;&#20915;&#20102;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#20998;&#24067;&#20559;&#31227;&#30340;&#24773;&#20917;&#19979;&#65292;&#26412;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;&#27867;&#21270;&#35823;&#24046;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#32447;&#24615;&#27169;&#22411;&#22312;&#30495;&#23454;&#25968;&#25454;&#20013;&#30340;&#27867;&#21270;&#33021;&#21147;&#26159;&#32479;&#35745;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#12290;&#20808;&#21069;&#30340;&#19968;&#20123;&#37325;&#35201;&#24037;&#20316;&#39564;&#35777;&#20102;&#29702;&#35770;&#24037;&#20316;&#19982;&#30495;&#23454;&#25968;&#25454;&#30340;&#30456;&#20851;&#24615;&#65292;&#20294;&#36825;&#20123;&#24037;&#20316;&#30001;&#20110;&#25216;&#26415;&#20551;&#35774;&#23384;&#22312;&#38480;&#21046;&#65292;&#36825;&#20123;&#20551;&#35774;&#21253;&#25324;&#20855;&#26377;&#33391;&#22909;&#26465;&#20214;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#20197;&#21450;&#20855;&#26377;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#65292;&#36825;&#20123;&#20551;&#35774;&#22312;&#30495;&#23454;&#25968;&#25454;&#20013;&#24182;&#19981;&#19968;&#23450;&#25104;&#31435;&#12290;&#27492;&#22806;&#65292;&#20197;&#21069;&#30340;&#19968;&#20123;&#20851;&#20110;&#20998;&#24067;&#20559;&#31227;&#30340;&#24037;&#20316;&#36890;&#24120;&#23545;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#30340;&#32852;&#21512;&#20998;&#24067;&#36827;&#34892;&#25216;&#26415;&#20551;&#35774;&#65292;&#24182;&#19988;&#19981;&#22312;&#30495;&#23454;&#25968;&#25454;&#19978;&#36827;&#34892;&#27979;&#35797;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#24182;&#26356;&#22909;&#22320;&#23545;&#30495;&#23454;&#25968;&#25454;&#36827;&#34892;&#24314;&#27169;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#20302;&#31209;&#32467;&#26500;&#20294;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#30340;&#24773;&#20917;&#65292;&#21516;&#26102;&#36890;&#36807;&#20998;&#31163;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#30340;&#20551;&#35774;&#26469;&#35299;&#20915;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;&#25105;&#20204;&#36824;&#22312;&#36825;&#20123;&#26494;&#24347;&#30340;&#20551;&#35774;&#19979;&#65292;&#30740;&#31350;&#20102;&#21435;&#22122;&#38382;&#39064;&#12289;&#32447;&#24615;&#22238;&#24402;&#21644;&#36801;&#31227;&#23398;&#20064;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#30456;&#27604;&#20197;&#21069;&#30340;&#26041;&#27861;&#65292;&#22312;&#20998;&#24067;&#20559;&#31227;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;&#27867;&#21270;&#35823;&#24046;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Studying the generalization abilities of linear models with real data is a central question in statistical learning. While there exist a limited number of prior important works (Loureiro et al. (2021A, 2021B), Wei et al. 2022) that do validate theoretical work with real data, these works have limitations due to technical assumptions. These assumptions include having a well-conditioned covariance matrix and having independent and identically distributed data. These assumptions are not necessarily valid for real data. Additionally, prior works that do address distributional shifts usually make technical assumptions on the joint distribution of the train and test data (Tripuraneni et al. 2021, Wu and Xu 2020), and do not test on real data.  In an attempt to address these issues and better model real data, we look at data that is not I.I.D. but has a low-rank structure. Further, we address distributional shift by decoupling assumptions on the training and test distribution. We provide anal
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;Neyman-Pearson&#26816;&#39564;&#22312;&#25311;&#21512;&#20248;&#24230;&#30740;&#31350;&#20013;&#30340;&#24212;&#29992;&#65292;&#23454;&#29616;&#20102;&#19968;&#31181;&#21517;&#20026;NPLM&#30340;&#23454;&#29992;&#23454;&#29616;&#12290;&#21644;&#22522;&#20110;&#20998;&#31867;&#22120;&#26041;&#27861;&#30456;&#27604;&#65292;&#22312;&#25506;&#27979;&#21040;&#25968;&#25454;&#19982;&#26399;&#26395;&#20998;&#24067;&#30340;&#23567;&#20559;&#24046;&#26102;&#65292;NPLM&#26356;&#28789;&#25935;&#19988;&#19981;&#20250;&#20559;&#21521;&#20219;&#20309;&#31867;&#22411;&#30340;&#24322;&#24120;&#65292;&#27604;&#36739;&#36866;&#29992;&#20110;&#23545;&#25758;&#26426;&#23454;&#39564;&#20013;&#23545;&#20110;&#26032;&#29289;&#29702;&#30340;&#19981;&#21487;&#30693;&#25628;&#32034;&#12290; future work &#38656;&#35201;&#30740;&#31350;&#23427;&#22312;&#20854;&#20182;&#29615;&#22659;&#20013;&#30340;&#20351;&#29992;&#12290;</title><link>http://arxiv.org/abs/2305.14137</link><description>&lt;p&gt;
Neyman-Pearson&#26816;&#39564;&#30340;&#25311;&#21512;&#20248;&#24230;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Goodness of fit by Neyman-Pearson testing. (arXiv:2305.14137v1 [hep-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14137
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;Neyman-Pearson&#26816;&#39564;&#22312;&#25311;&#21512;&#20248;&#24230;&#30740;&#31350;&#20013;&#30340;&#24212;&#29992;&#65292;&#23454;&#29616;&#20102;&#19968;&#31181;&#21517;&#20026;NPLM&#30340;&#23454;&#29992;&#23454;&#29616;&#12290;&#21644;&#22522;&#20110;&#20998;&#31867;&#22120;&#26041;&#27861;&#30456;&#27604;&#65292;&#22312;&#25506;&#27979;&#21040;&#25968;&#25454;&#19982;&#26399;&#26395;&#20998;&#24067;&#30340;&#23567;&#20559;&#24046;&#26102;&#65292;NPLM&#26356;&#28789;&#25935;&#19988;&#19981;&#20250;&#20559;&#21521;&#20219;&#20309;&#31867;&#22411;&#30340;&#24322;&#24120;&#65292;&#27604;&#36739;&#36866;&#29992;&#20110;&#23545;&#25758;&#26426;&#23454;&#39564;&#20013;&#23545;&#20110;&#26032;&#29289;&#29702;&#30340;&#19981;&#21487;&#30693;&#25628;&#32034;&#12290; future work &#38656;&#35201;&#30740;&#31350;&#23427;&#22312;&#20854;&#20182;&#29615;&#22659;&#20013;&#30340;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#22791;&#36873;&#20551;&#35774;$H_1$&#36275;&#22815;&#36890;&#29992;&#65292;&#26082;&#19981;&#24341;&#20837;&#37325;&#22823;&#20559;&#24046;&#21448;&#36991;&#20813;&#36807;&#24230;&#25311;&#21512;&#26102;&#65292;Neyman-Pearson&#31574;&#30053;&#21487;&#20197;&#29992;&#20110;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;&#12290;&#22312;&#39640;&#33021;&#29289;&#29702;&#30340;&#32972;&#26223;&#19979;&#65292;&#19968;&#31181;&#21517;&#20026;NPLM&#30340;&#23454;&#29992;&#23454;&#29616;&#24050;&#34987;&#24320;&#21457;&#65292;&#26088;&#22312;&#25506;&#27979;&#26631;&#20934;&#27169;&#22411;&#26410;&#39044;&#26009;&#21040;&#30340;&#26032;&#29289;&#29702;&#25928;&#24212;&#65292;&#25105;&#20204;&#22312;&#26412;&#25991;&#20013;&#23558;&#35813;&#26041;&#27861;&#19982;&#20854;&#20182;&#25311;&#21512;&#20248;&#24230;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Neyman-Pearson strategy for hypothesis testing can be employed for goodness of fit if the alternative hypothesis $\rm H_1$ is generic enough not to introduce a significant bias while at the same time avoiding overfitting. A practical implementation of this idea (dubbed NPLM) has been developed in the context of high energy physics, targeting the detection in collider data of new physical effects not foreseen by the Standard Model. In this paper we initiate a comparison of this methodology with other approaches to goodness of fit, and in particular with classifier-based strategies that share strong similarities with NPLM. NPLM emerges from our comparison as more sensitive to small departures of the data from the expected distribution and not biased towards detecting specific types of anomalies while being blind to others. These features make it more suited for agnostic searches for new physics at collider experiments. Its deployment in other contexts should be investigated.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#28982;lasso&#21464;&#20307;&#30340;MARS&#26041;&#27861;&#65292;&#36890;&#36807;&#20943;&#23569;&#23545;&#32500;&#24230;&#30340;&#20381;&#36182;&#26469;&#33719;&#24471;&#25910;&#25947;&#29575;&#65292;&#24182;&#19982;&#20351;&#29992;&#24179;&#28369;&#24615;&#32422;&#26463;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;&#25216;&#26415;&#32852;&#31995;&#22312;&#19968;&#36215;&#12290;</title><link>http://arxiv.org/abs/2111.11694</link><description>&lt;p&gt;
MARS via LASSO.&#65288;arXiv:2111.11694v2 [math.ST] &#24050;&#26356;&#26032;&#65289;
&lt;/p&gt;
&lt;p&gt;
MARS via LASSO. (arXiv:2111.11694v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.11694
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#28982;lasso&#21464;&#20307;&#30340;MARS&#26041;&#27861;&#65292;&#36890;&#36807;&#20943;&#23569;&#23545;&#32500;&#24230;&#30340;&#20381;&#36182;&#26469;&#33719;&#24471;&#25910;&#25947;&#29575;&#65292;&#24182;&#19982;&#20351;&#29992;&#24179;&#28369;&#24615;&#32422;&#26463;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;&#25216;&#26415;&#32852;&#31995;&#22312;&#19968;&#36215;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20803;&#33258;&#36866;&#24212;&#22238;&#24402;&#26679;&#26465;&#65288;Multivariate Adaptive Regression Splines&#65292;MARS&#65289;&#26159;Friedman&#22312;1991&#24180;&#25552;&#20986;&#30340;&#19968;&#31181;&#38750;&#21442;&#25968;&#22238;&#24402;&#26041;&#27861;&#12290;MARS&#23558;&#31616;&#21333;&#30340;&#38750;&#32447;&#24615;&#21644;&#38750;&#21152;&#24615;&#20989;&#25968;&#25311;&#21512;&#21040;&#22238;&#24402;&#25968;&#25454;&#19978;&#12290;&#26412;&#25991;&#25552;&#20986;&#24182;&#30740;&#31350;&#20102;MARS&#26041;&#27861;&#30340;&#19968;&#31181;&#33258;&#28982;lasso&#21464;&#20307;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#22522;&#20110;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#65292;&#36890;&#36807;&#32771;&#34385;MARS&#22522;&#30784;&#20989;&#25968;&#30340;&#26080;&#38480;&#32500;&#32447;&#24615;&#32452;&#21512;&#24182;&#24378;&#21152;&#22522;&#20110;&#21464;&#20998;&#30340;&#22797;&#26434;&#24230;&#32422;&#26463;&#26465;&#20214;&#26469;&#33719;&#24471;&#20989;&#25968;&#30340;&#20984;&#31867;&#12290;&#34429;&#28982;&#25105;&#20204;&#30340;&#20272;&#35745;&#26159;&#23450;&#20041;&#20026;&#26080;&#38480;&#32500;&#20248;&#21270;&#38382;&#39064;&#30340;&#35299;&#65292;&#20294;&#20854;&#21487;&#20197;&#36890;&#36807;&#26377;&#38480;&#32500;&#20984;&#20248;&#21270;&#26469;&#35745;&#31639;&#12290;&#22312;&#19968;&#20123;&#26631;&#20934;&#35774;&#35745;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#20165;&#22312;&#32500;&#24230;&#19978;&#23545;&#25968;&#25910;&#25947;&#65292;&#22240;&#27492;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#36991;&#20813;&#20102;&#36890;&#24120;&#30340;&#32500;&#24230;&#28798;&#38590;&#12290;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33258;&#28982;&#22320;&#19982;&#22522;&#20110;&#24179;&#28369;&#24615;&#32422;&#26463;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;&#25216;&#26415;&#30456;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multivariate adaptive regression splines (MARS) is a popular method for nonparametric regression introduced by Friedman in 1991. MARS fits simple nonlinear and non-additive functions to regression data. We propose and study a natural lasso variant of the MARS method. Our method is based on least squares estimation over a convex class of functions obtained by considering infinite-dimensional linear combinations of functions in the MARS basis and imposing a variation based complexity constraint. Our estimator can be computed via finite-dimensional convex optimization, although it is defined as a solution to an infinite-dimensional optimization problem. Under a few standard design assumptions, we prove that our estimator achieves a rate of convergence that depends only logarithmically on dimension and thus avoids the usual curse of dimensionality to some extent. We also show that our method is naturally connected to nonparametric estimation techniques based on smoothness constraints. We i
&lt;/p&gt;</description></item></channel></rss>