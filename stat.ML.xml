<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#25913;&#36827;&#20102;&#21463;&#32602;&#22522;&#32447;&#26657;&#27491;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#20808;&#39564;&#20998;&#26512;&#29289;&#27987;&#24230;&#26469;&#25913;&#21892;&#20809;&#35889;&#39044;&#27979;&#24615;&#33021;&#65292;&#24182;&#22312;&#20004;&#20010;&#36817;&#32418;&#22806;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2310.18306</link><description>&lt;p&gt;
&#30417;&#30563;&#21644;&#21463;&#32602;&#22522;&#32447;&#26657;&#27491;
&lt;/p&gt;
&lt;p&gt;
Supervised and Penalized Baseline Correction. (arXiv:2310.18306v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18306
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25913;&#36827;&#20102;&#21463;&#32602;&#22522;&#32447;&#26657;&#27491;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#20808;&#39564;&#20998;&#26512;&#29289;&#27987;&#24230;&#26469;&#25913;&#21892;&#20809;&#35889;&#39044;&#27979;&#24615;&#33021;&#65292;&#24182;&#22312;&#20004;&#20010;&#36817;&#32418;&#22806;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20809;&#35889;&#27979;&#37327;&#21487;&#20197;&#26174;&#31034;&#30001;&#21560;&#25910;&#21644;&#25955;&#23556;&#25104;&#20998;&#28151;&#21512;&#24341;&#36215;&#30340;&#25197;&#26354;&#20809;&#35889;&#24418;&#29366;&#12290;&#36825;&#20123;&#25197;&#26354;&#65288;&#25110;&#22522;&#32447;&#65289;&#36890;&#24120;&#34920;&#29616;&#20026;&#38750;&#24658;&#23450;&#20559;&#31227;&#25110;&#20302;&#39057;&#25391;&#33633;&#12290;&#22240;&#27492;&#65292;&#36825;&#20123;&#22522;&#32447;&#21487;&#33021;&#23545;&#20998;&#26512;&#21644;&#23450;&#37327;&#32467;&#26524;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#12290;&#22522;&#32447;&#26657;&#27491;&#26159;&#19968;&#20010;&#28085;&#30422;&#20102;&#39044;&#22788;&#29702;&#26041;&#27861;&#30340;&#24635;&#31216;&#65292;&#36890;&#36807;&#33719;&#21462;&#22522;&#32447;&#20809;&#35889;&#65288;&#19981;&#38656;&#35201;&#30340;&#25197;&#26354;&#65289;&#24182;&#36890;&#36807;&#24046;&#24322;&#21270;&#21435;&#38500;&#25197;&#26354;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#22522;&#32447;&#26657;&#27491;&#26041;&#27861;&#21363;&#20351;&#21487;&#29992;&#20998;&#26512;&#29289;&#27987;&#24230;&#25110;&#32773;&#23427;&#20204;&#23545;&#35266;&#23519;&#21040;&#30340;&#20809;&#35889;&#21464;&#24322;&#26377;&#37325;&#35201;&#36129;&#29486;&#65292;&#20063;&#27809;&#26377;&#21033;&#29992;&#23427;&#20204;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31867;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#65288;&#21463;&#32602;&#22522;&#32447;&#26657;&#27491;&#65289;&#24182;&#23545;&#20854;&#36827;&#34892;&#20462;&#25913;&#65292;&#20351;&#20854;&#33021;&#22815;&#36866;&#24212;&#20808;&#39564;&#20998;&#26512;&#29289;&#27987;&#24230;&#65292;&#20174;&#32780;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#12290;&#23558;&#22312;&#20004;&#20010;&#36817;&#32418;&#22806;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#24615;&#33021;&#65292;&#21253;&#25324;&#32463;&#20856;&#21463;&#32602;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Spectroscopic measurements can show distorted spectra shapes arising from a mixture of absorbing and scattering contributions. These distortions (or baselines) often manifest themselves as non-constant offsets or low-frequency oscillations. As a result, these baselines can adversely affect analytical and quantitative results. Baseline correction is an umbrella term where one applies pre-processing methods to obtain baseline spectra (the unwanted distortions) and then remove the distortions by differencing. However, current state-of-the art baseline correction methods do not utilize analyte concentrations even if they are available, or even if they contribute significantly to the observed spectral variability. We examine a class of state-of-the-art methods (penalized baseline correction) and modify them such that they can accommodate a priori analyte concentration such that prediction can be enhanced. Performance will be access on two near infra-red data sets across both classical penal
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#38750;&#31283;&#24577;&#29615;&#22659;&#30340;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#24212;&#29992;&#31283;&#23450;&#24615;&#21407;&#21017;&#36873;&#25321;&#22238;&#28335;&#31383;&#21475;&#26469;&#26368;&#22823;&#21270;&#21382;&#21490;&#25968;&#25454;&#21033;&#29992;&#65292;&#24182;&#20445;&#25345;&#32047;&#31215;&#20559;&#24046;&#22312;&#21487;&#25509;&#21463;&#33539;&#22260;&#20869;&#12290;&#35813;&#26041;&#27861;&#23637;&#31034;&#20102;&#23545;&#26410;&#30693;&#38750;&#31283;&#24577;&#30340;&#36866;&#24212;&#24615;&#65292;&#36951;&#25022;&#30028;&#22312;&#24378;&#20984;&#25110;&#28385;&#36275;Lipschitz&#26465;&#20214;&#19979;&#26159;&#26497;&#23567;&#21270;&#30340;&#26368;&#20248;&#35299;&#12290;&#35813;&#30740;&#31350;&#30340;&#21019;&#26032;&#28857;&#26159;&#20989;&#25968;&#30456;&#20284;&#24230;&#24230;&#37327;&#21644;&#38750;&#31283;&#24577;&#25968;&#25454;&#24207;&#21015;&#21010;&#20998;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2310.18304</link><description>&lt;p&gt;
&#23398;&#20064;&#38750;&#31283;&#24577;&#26465;&#20214;&#19979;&#30340;&#31283;&#23450;&#24615;&#21407;&#21017;
&lt;/p&gt;
&lt;p&gt;
A Stability Principle for Learning under Non-Stationarity. (arXiv:2310.18304v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18304
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#38750;&#31283;&#24577;&#29615;&#22659;&#30340;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#24212;&#29992;&#31283;&#23450;&#24615;&#21407;&#21017;&#36873;&#25321;&#22238;&#28335;&#31383;&#21475;&#26469;&#26368;&#22823;&#21270;&#21382;&#21490;&#25968;&#25454;&#21033;&#29992;&#65292;&#24182;&#20445;&#25345;&#32047;&#31215;&#20559;&#24046;&#22312;&#21487;&#25509;&#21463;&#33539;&#22260;&#20869;&#12290;&#35813;&#26041;&#27861;&#23637;&#31034;&#20102;&#23545;&#26410;&#30693;&#38750;&#31283;&#24577;&#30340;&#36866;&#24212;&#24615;&#65292;&#36951;&#25022;&#30028;&#22312;&#24378;&#20984;&#25110;&#28385;&#36275;Lipschitz&#26465;&#20214;&#19979;&#26159;&#26497;&#23567;&#21270;&#30340;&#26368;&#20248;&#35299;&#12290;&#35813;&#30740;&#31350;&#30340;&#21019;&#26032;&#28857;&#26159;&#20989;&#25968;&#30456;&#20284;&#24230;&#24230;&#37327;&#21644;&#38750;&#31283;&#24577;&#25968;&#25454;&#24207;&#21015;&#21010;&#20998;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#38750;&#31283;&#23450;&#29615;&#22659;&#20013;&#24320;&#21457;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#12290;&#22312;&#27599;&#20010;&#26102;&#38388;&#27573;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#31283;&#23450;&#24615;&#21407;&#21017;&#26469;&#36873;&#25321;&#19968;&#20010;&#22238;&#28335;&#31383;&#21475;&#65292;&#26368;&#22823;&#38480;&#24230;&#22320;&#21033;&#29992;&#21382;&#21490;&#25968;&#25454;&#65292;&#21516;&#26102;&#23558;&#32047;&#31215;&#20559;&#24046;&#20445;&#25345;&#22312;&#19982;&#38543;&#26426;&#35823;&#24046;&#30456;&#23545;&#21487;&#25509;&#21463;&#30340;&#33539;&#22260;&#20869;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#23545;&#26410;&#30693;&#38750;&#31283;&#23450;&#24615;&#30340;&#36866;&#24212;&#24615;&#12290;&#24403;&#20154;&#21475;&#25439;&#22833;&#20989;&#25968;&#24378;&#20984;&#25110;&#20165;&#28385;&#36275;Lipschitz&#26465;&#20214;&#26102;&#65292;&#36951;&#25022;&#30028;&#26159;&#26497;&#23567;&#21270;&#30340;&#26368;&#20248;&#35299;&#65292;&#20165;&#21463;&#23545;&#25968;&#22240;&#23376;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#26680;&#24515;&#26159;&#20004;&#20010;&#26032;&#39062;&#30340;&#32452;&#25104;&#37096;&#20998;&#65306;&#20989;&#25968;&#20043;&#38388;&#30340;&#30456;&#20284;&#24230;&#24230;&#37327;&#21644;&#23558;&#38750;&#31283;&#24577;&#25968;&#25454;&#24207;&#21015;&#21010;&#20998;&#20026;&#20934;&#31283;&#24577;&#29255;&#27573;&#30340;&#20998;&#21106;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a versatile framework for statistical learning in non-stationary environments. In each time period, our approach applies a stability principle to select a look-back window that maximizes the utilization of historical data while keeping the cumulative bias within an acceptable range relative to the stochastic error. Our theory showcases the adaptability of this approach to unknown non-stationarity. The regret bound is minimax optimal up to logarithmic factors when the population losses are strongly convex, or Lipschitz only. At the heart of our analysis lie two novel components: a measure of similarity between functions and a segmentation technique for dividing the non-stationary data sequence into quasi-stationary pieces.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#20351;&#29992;&#21487;&#35843;&#30340;&#20998;&#31867;&#25439;&#22833;&#35299;&#20915;&#20102;GAN&#35757;&#32451;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;CPE&#25439;&#22833;GAN&#21644;&#26368;&#23567;&#21270;f-&#25955;&#24230;&#30340;f-GAN&#20043;&#38388;&#30340;&#21452;&#21521;&#23545;&#24212;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2310.18291</link><description>&lt;p&gt;
&#36890;&#36807;&#21487;&#35843;&#30340;&#20998;&#31867;&#25439;&#22833;&#35299;&#20915; GAN &#35757;&#32451;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Addressing GAN Training Instabilities via Tunable Classification Losses. (arXiv:2310.18291v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18291
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#20351;&#29992;&#21487;&#35843;&#30340;&#20998;&#31867;&#25439;&#22833;&#35299;&#20915;&#20102;GAN&#35757;&#32451;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;CPE&#25439;&#22833;GAN&#21644;&#26368;&#23567;&#21270;f-&#25955;&#24230;&#30340;f-GAN&#20043;&#38388;&#30340;&#21452;&#21521;&#23545;&#24212;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#20316;&#20026;&#29983;&#25104;&#22120;&#65288;G&#65289;&#21644;&#37492;&#21035;&#22120;&#65288;D&#65289;&#20043;&#38388;&#30340;&#38646;&#21644;&#21338;&#24328;&#27169;&#22411;&#65292;&#20801;&#35768;&#20197;&#24418;&#24335;&#20445;&#35777;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#31867;&#27010;&#29575;&#20272;&#35745;&#65288;CPE&#65289;&#25439;&#22833;&#26469;&#37325;&#26032;&#23450;&#20041;GAN&#30340;&#20215;&#20540;&#20989;&#25968;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;CPE&#25439;&#22833;GAN&#21644;&#26368;&#23567;&#21270;f-&#25955;&#24230;&#30340;f-GAN&#20043;&#38388;&#23384;&#22312;&#21452;&#21521;&#23545;&#24212;&#20851;&#31995;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#25152;&#26377;&#23545;&#31216;f-&#25955;&#24230;&#22312;&#25910;&#25947;&#24615;&#19978;&#31561;&#20215;&#12290;&#22312;&#26377;&#38480;&#26679;&#26412;&#21644;&#27169;&#22411;&#23481;&#37327;&#35774;&#23450;&#19979;&#65292;&#25105;&#20204;&#23450;&#20041;&#24182;&#33719;&#24471;&#20102;&#20851;&#20110;&#20272;&#35745;&#21644;&#27867;&#21270;&#35823;&#24046;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#32467;&#26524;&#29305;&#21270;&#21040;&#20351;&#29992;&#945;-loss&#23450;&#20041;&#30340;&#945;-GAN&#65292;&#23427;&#26159;&#19968;&#20010;&#30001;&#945;&#65288;0&#65292;&#8734;]&#21442;&#25968;&#21270;&#30340;&#21487;&#35843;CPE&#25439;&#22833;&#30340;&#23478;&#26063;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31867;&#21452;&#30446;&#26631;GAN&#26469;&#35299;&#20915;GAN&#30340;&#35757;&#32451;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;&#65292;&#36890;&#36807;&#20351;&#29992;&#945;-loss&#26469;&#23545;&#27599;&#20010;&#29609;&#23478;&#30340;&#30446;&#26631;&#24314;&#27169;&#65292;&#20197;&#33719;&#24471;(&#945;_D&#65292;&#945;_G)-GAN&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20135;&#29983;&#30340;&#38750;&#38646;&#21644;&#28216;&#25103;&#31616;&#21270;&#20026;&#26368;&#23567;&#21270;f-&#25955;&#24230;&#30340;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative adversarial networks (GANs), modeled as a zero-sum game between a generator (G) and a discriminator (D), allow generating synthetic data with formal guarantees. Noting that D is a classifier, we begin by reformulating the GAN value function using class probability estimation (CPE) losses. We prove a two-way correspondence between CPE loss GANs and $f$-GANs which minimize $f$-divergences. We also show that all symmetric $f$-divergences are equivalent in convergence. In the finite sample and model capacity setting, we define and obtain bounds on estimation and generalization errors. We specialize these results to $\alpha$-GANs, defined using $\alpha$-loss, a tunable CPE loss family parametrized by $\alpha\in(0,\infty]$. We next introduce a class of dual-objective GANs to address training instabilities of GANs by modeling each player's objective using $\alpha$-loss to obtain $(\alpha_D,\alpha_G)$-GANs. We show that the resulting non-zero sum game simplifies to minimizing an $f$
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#21517;&#20026;ESCFR&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#36816;&#29992;&#26368;&#20248;&#36816;&#36755;&#22312;&#22240;&#26524;&#24615;&#32972;&#26223;&#19979;&#35299;&#20915;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#20013;&#30340;&#23567;&#25209;&#37327;&#37319;&#26679;&#25928;&#24212;&#21644;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#26434;&#21464;&#37327;&#25928;&#24212;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.18286</link><description>&lt;p&gt;
&#29992;&#20110;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#30340;&#26368;&#20248;&#36816;&#36755;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Optimal Transport for Treatment Effect Estimation. (arXiv:2310.18286v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18286
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#21517;&#20026;ESCFR&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#36816;&#29992;&#26368;&#20248;&#36816;&#36755;&#22312;&#22240;&#26524;&#24615;&#32972;&#26223;&#19979;&#35299;&#20915;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#20013;&#30340;&#23567;&#25209;&#37327;&#37319;&#26679;&#25928;&#24212;&#21644;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#26434;&#21464;&#37327;&#25928;&#24212;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#23384;&#22312;&#27835;&#30103;&#36873;&#25321;&#20559;&#24046;&#65292;&#20174;&#35266;&#23519;&#25968;&#25454;&#20013;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#26159;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#36890;&#36807;&#22312;&#28508;&#22312;&#31354;&#38388;&#20013;&#23545;&#19981;&#21516;&#22788;&#29702;&#32452;&#30340;&#20998;&#24067;&#36827;&#34892;&#23545;&#40784;&#26469;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#26410;&#33021;&#35299;&#20915;&#20004;&#20010;&#20851;&#38190;&#38382;&#39064;&#65306;&#65288;1&#65289;&#23567;&#25209;&#37327;&#37319;&#26679;&#25928;&#24212;&#65288;MSE&#65289;&#65292;&#21363;&#22312;&#20855;&#26377;&#19981;&#24179;&#34913;&#32467;&#26524;&#21644;&#24322;&#24120;&#20540;&#30340;&#38750;&#29702;&#24819;&#23567;&#25209;&#37327;&#20013;&#23548;&#33268;&#38169;&#35823;&#23545;&#40784;&#65307;&#65288;2&#65289;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#26434;&#21464;&#37327;&#25928;&#24212;&#65288;UCE&#65289;&#65292;&#21363;&#30001;&#20110;&#24573;&#30053;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#26434;&#21464;&#37327;&#32780;&#23548;&#33268;&#30340;&#19981;&#20934;&#30830;&#24046;&#24322;&#35745;&#31639;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#25972;&#20307;&#31354;&#38388;&#21453;&#20107;&#23454;&#22238;&#24402;&#65288;ESCFR&#65289;&#30340;&#21407;&#21017;&#24615;&#26041;&#27861;&#65292;&#23427;&#26159;&#22312;&#22240;&#26524;&#24615;&#32972;&#26223;&#19979;&#36816;&#29992;&#26368;&#20248;&#36816;&#36755;&#30340;&#26032;&#26041;&#27861;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#22522;&#20110;&#38543;&#26426;&#26368;&#20248;&#36816;&#36755;&#30340;&#26694;&#26550;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26494;&#24347;&#30340;&#20445;&#25345;&#36136;&#37327;&#30340;&#27491;&#21017;&#21270;&#39033;&#26469;&#35299;&#20915;MSE&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#22788;&#29702;UCE&#30340;&#36817;&#22240;&#20107;&#23454;&#32467;&#26524;&#27491;&#21017;&#21270;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating conditional average treatment effect from observational data is highly challenging due to the existence of treatment selection bias. Prevalent methods mitigate this issue by aligning distributions of different treatment groups in the latent space. However, there are two critical problems that these methods fail to address: (1) mini-batch sampling effects (MSE), which causes misalignment in non-ideal mini-batches with outcome imbalance and outliers; (2) unobserved confounder effects (UCE), which results in inaccurate discrepancy calculation due to the neglect of unobserved confounders. To tackle these problems, we propose a principled approach named Entire Space CounterFactual Regression (ESCFR), which is a new take on optimal transport in the context of causality. Specifically, based on the framework of stochastic optimal transport, we propose a relaxed mass-preserving regularizer to address the MSE issue and design a proximal factual outcome regularizer to handle the UCE is
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#32467;&#21512;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#21644;&#22823;&#35268;&#27169;&#30340;&#35757;&#32451;&#38598;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#21487;&#20256;&#36882;&#30340;&#31895;&#31890;&#21270;&#27169;&#22411;&#65292;&#33021;&#22815;&#24555;&#36895;&#19988;&#20934;&#30830;&#22320;&#39044;&#27979;&#34507;&#30333;&#36136;&#30340;&#32467;&#26500;&#21644;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2310.18278</link><description>&lt;p&gt;
&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#30340;&#21487;&#20256;&#36882;&#30340;&#31895;&#31890;&#21270;&#27169;&#22411;&#23548;&#33322;&#34507;&#30333;&#36136;&#31354;&#38388;&#26223;&#35266;
&lt;/p&gt;
&lt;p&gt;
Navigating protein landscapes with a machine-learned transferable coarse-grained model. (arXiv:2310.18278v1 [q-bio.BM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18278
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#32467;&#21512;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#21644;&#22823;&#35268;&#27169;&#30340;&#35757;&#32451;&#38598;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#21487;&#20256;&#36882;&#30340;&#31895;&#31890;&#21270;&#27169;&#22411;&#65292;&#33021;&#22815;&#24555;&#36895;&#19988;&#20934;&#30830;&#22320;&#39044;&#27979;&#34507;&#30333;&#36136;&#30340;&#32467;&#26500;&#21644;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#21463;&#27426;&#36814;&#19988;&#20855;&#26377;&#26222;&#36941;&#39044;&#27979;&#33021;&#21147;&#30340;&#34507;&#30333;&#36136;&#27169;&#25311;&#27169;&#22411;&#37319;&#29992;&#20840;&#21407;&#23376;&#20998;&#23376;&#21160;&#21147;&#23398;&#65288;MD&#65289;&#65292;&#20294;&#23427;&#20204;&#30340;&#35745;&#31639;&#25104;&#26412;&#26497;&#39640;&#12290;&#24320;&#21457;&#19968;&#20010;&#20855;&#26377;&#31867;&#20284;&#39044;&#27979;&#24615;&#33021;&#30340;&#36890;&#29992;&#12289;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#31895;&#31890;&#21270;&#65288;CG&#65289;&#27169;&#22411;&#19968;&#30452;&#26159;&#19968;&#20010;&#38271;&#26399;&#23384;&#22312;&#30340;&#25361;&#25112;&#12290;&#36890;&#36807;&#23558;&#26368;&#36817;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#19982;&#22823;&#37327;&#22810;&#26679;&#30340;&#20840;&#21407;&#23376;&#34507;&#30333;&#36136;&#27169;&#25311;&#35757;&#32451;&#38598;&#30456;&#32467;&#21512;&#65292;&#25105;&#20204;&#22312;&#27492;&#24320;&#21457;&#20102;&#19968;&#31181;&#33258;&#24213;&#21521;&#19978;&#30340;&#20855;&#26377;&#21270;&#23398;&#21487;&#20256;&#36882;&#24615;&#30340;CG&#21147;&#22330;&#27169;&#22411;&#65292;&#21487;&#29992;&#20110;&#23545;&#26410;&#22312;&#27169;&#22411;&#21442;&#25968;&#21270;&#26399;&#38388;&#20351;&#29992;&#30340;&#26032;&#24207;&#21015;&#36827;&#34892;&#22806;&#25512;&#20998;&#23376;&#21160;&#21147;&#23398;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#27169;&#22411;&#25104;&#21151;&#39044;&#27979;&#20102;&#25240;&#21472;&#32467;&#26500;&#12289;&#20013;&#38388;&#20307;&#12289;&#20122;&#31283;&#23450;&#30340;&#25240;&#21472;&#21644;&#26410;&#25240;&#21472;&#30406;&#22320;&#20197;&#21450;&#26080;&#24207;&#34507;&#30333;&#36136;&#30340;&#27874;&#21160;&#65292;&#21516;&#26102;&#36895;&#24230;&#27604;&#20840;&#21407;&#23376;&#27169;&#22411;&#24555;&#20960;&#20010;&#25968;&#37327;&#32423;&#12290;&#36825;&#23637;&#31034;&#20102;&#19968;&#31181;&#38024;&#23545;&#34507;&#30333;&#36136;&#30340;&#36890;&#29992;&#19988;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#26426;&#22120;&#23398;&#20064;CG&#27169;&#22411;&#30340;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The most popular and universally predictive protein simulation models employ all-atom molecular dynamics (MD), but they come at extreme computational cost. The development of a universal, computationally efficient coarse-grained (CG) model with similar prediction performance has been a long-standing challenge. By combining recent deep learning methods with a large and diverse training set of all-atom protein simulations, we here develop a bottom-up CG force field with chemical transferability, which can be used for extrapolative molecular dynamics on new sequences not used during model parametrization. We demonstrate that the model successfully predicts folded structures, intermediates, metastable folded and unfolded basins, and the fluctuations of intrinsically disordered proteins while it is several orders of magnitude faster than an all-atom model. This showcases the feasibility of a universal and computationally efficient machine-learned CG model for proteins.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#23547;&#25214;&#36817;&#20284;&#26368;&#20248;&#30340;&#39044;&#22788;&#29702;&#22120;&#26469;&#35299;&#20915;&#32447;&#24615;&#31995;&#32479;&#65292;&#24182;&#25552;&#20379;&#20102;&#25913;&#36827;&#30340;&#23545;&#35282;&#39044;&#22788;&#29702;&#32467;&#26524;&#65292;&#20248;&#20110;&#20808;&#21069;&#30340;&#36890;&#29992;&#21322;/shear programming&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.18265</link><description>&lt;p&gt;
&#32467;&#26500;&#21270;&#21322;&#23450;&#35268;&#21010;&#29992;&#20110;&#24674;&#22797;&#32467;&#26500;&#21270;&#39044;&#22788;&#29702;&#22120;
&lt;/p&gt;
&lt;p&gt;
Structured Semidefinite Programming for Recovering Structured Preconditioners. (arXiv:2310.18265v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18265
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#23547;&#25214;&#36817;&#20284;&#26368;&#20248;&#30340;&#39044;&#22788;&#29702;&#22120;&#26469;&#35299;&#20915;&#32447;&#24615;&#31995;&#32479;&#65292;&#24182;&#25552;&#20379;&#20102;&#25913;&#36827;&#30340;&#23545;&#35282;&#39044;&#22788;&#29702;&#32467;&#26524;&#65292;&#20248;&#20110;&#20808;&#21069;&#30340;&#36890;&#29992;&#21322;/shear programming&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#23547;&#25214;&#36817;&#20284;&#26368;&#20248;&#30340;&#39044;&#22788;&#29702;&#22120;&#26469;&#35299;&#20915;&#32447;&#24615;&#31995;&#32479;&#12290;&#21033;&#29992;&#36825;&#20010;&#26694;&#26550;&#65292;&#25105;&#20204;&#25913;&#36827;&#20102;&#22522;&#26412;&#39044;&#22788;&#29702;&#21644;&#32447;&#24615;&#31995;&#32479;&#27714;&#35299;&#38382;&#39064;&#30340;&#36816;&#34892;&#26102;&#38388;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#31639;&#27861;&#65292;&#32473;&#23450;&#27491;&#23450;&#30697;&#38453;$\mathbf{K} \in \mathbb{R}^{d \times d}$&#65292;&#20854;&#20013;$\mathrm{nnz}(\mathbf{K})$&#20026;&#38750;&#38646;&#20803;&#32032;&#30340;&#25968;&#37327;&#65292;&#23427;&#21487;&#20197;&#22312;&#26102;&#38388;&#22797;&#26434;&#24230;$\widetilde{O}(\mathrm{nnz}(\mathbf{K}) \cdot \mathrm{poly}(\kappa^\star,\epsilon^{-1}))$&#20869;&#35745;&#31639;$\epsilon$-&#26368;&#20248;&#30340;&#23545;&#35282;&#39044;&#22788;&#29702;&#22120;&#65292;&#20854;&#20013;$\kappa^\star$&#26159;&#32553;&#25918;&#21518;&#30697;&#38453;&#30340;&#26368;&#20248;&#26465;&#20214;&#25968;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#31639;&#27861;&#65292;&#32473;&#23450;$\mathbf{M} \in \mathbb{R}^{d \times d}$&#65292;&#23427;&#26159;&#19968;&#20010;&#22270;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#30340;&#20266;&#36870;&#30697;&#38453;&#25110;&#32773;&#19968;&#20010;&#24120;&#25968;&#35889;&#36924;&#36817;&#65292;&#21487;&#20197;&#22312;$\widetilde{O}(d^2)$&#30340;&#26102;&#38388;&#20869;&#27714;&#35299;&#22312;$\mathbf{M}$&#19978;&#30340;&#32447;&#24615;&#31995;&#32479;&#12290;&#25105;&#20204;&#30340;&#23545;&#35282;&#39044;&#22788;&#29702;&#32467;&#26524;&#25913;&#36827;&#20102;&#36890;&#36807;&#36890;&#29992;&#21322;/shear programming&#26041;&#27861;&#33719;&#24471;&#30340;$\Omega(d^{3.5})$&#30340;&#26368;&#20808;&#36827;&#36816;&#34892;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a general framework for finding approximately-optimal preconditioners for solving linear systems. Leveraging this framework we obtain improved runtimes for fundamental preconditioning and linear system solving problems including the following. We give an algorithm which, given positive definite $\mathbf{K} \in \mathbb{R}^{d \times d}$ with $\mathrm{nnz}(\mathbf{K})$ nonzero entries, computes an $\epsilon$-optimal diagonal preconditioner in time $\widetilde{O}(\mathrm{nnz}(\mathbf{K}) \cdot \mathrm{poly}(\kappa^\star,\epsilon^{-1}))$, where $\kappa^\star$ is the optimal condition number of the rescaled matrix. We give an algorithm which, given $\mathbf{M} \in \mathbb{R}^{d \times d}$ that is either the pseudoinverse of a graph Laplacian matrix or a constant spectral approximation of one, solves linear systems in $\mathbf{M}$ in $\widetilde{O}(d^2)$ time. Our diagonal preconditioning results improve state-of-the-art runtimes of $\Omega(d^{3.5})$ attained by general-purpose sem
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#38750;&#24573;&#30053;&#32570;&#22833;&#25968;&#25454;&#30340;&#26631;&#31614;&#20559;&#31227;&#20272;&#35745;&#22120;&#65292;&#21033;&#29992;&#39640;&#32500;&#21327;&#21464;&#37327;&#32780;&#26080;&#38656;&#29983;&#25104;&#27169;&#22411;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#22312;&#19981;&#32771;&#34385;&#38750;&#24573;&#30053;&#32570;&#22833;&#24615;&#30340;&#24773;&#20917;&#19979;&#21487;&#33021;&#20250;&#26377;&#37325;&#22823;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.18261</link><description>&lt;p&gt;
&#38750;&#24573;&#30053;&#32570;&#22833;&#25968;&#25454;&#30340;&#26631;&#31614;&#20559;&#31227;&#20272;&#35745;&#22120;
&lt;/p&gt;
&lt;p&gt;
Label Shift Estimators for Non-Ignorable Missing Data. (arXiv:2310.18261v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18261
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#38750;&#24573;&#30053;&#32570;&#22833;&#25968;&#25454;&#30340;&#26631;&#31614;&#20559;&#31227;&#20272;&#35745;&#22120;&#65292;&#21033;&#29992;&#39640;&#32500;&#21327;&#21464;&#37327;&#32780;&#26080;&#38656;&#29983;&#25104;&#27169;&#22411;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#22312;&#19981;&#32771;&#34385;&#38750;&#24573;&#30053;&#32570;&#22833;&#24615;&#30340;&#24773;&#20917;&#19979;&#21487;&#33021;&#20250;&#26377;&#37325;&#22823;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#38750;&#24573;&#30053;&#32570;&#22833;&#24773;&#20917;&#19979;&#20272;&#35745;&#19968;&#20010;&#38543;&#26426;&#21464;&#37327;Y&#30340;&#22343;&#20540;&#30340;&#38382;&#39064;&#65292;&#21363;&#32570;&#22833;&#26426;&#21046;&#21462;&#20915;&#20110;Y&#12290;&#25105;&#20204;&#23558;&#38750;&#24573;&#30053;&#32570;&#22833;&#30340;&#36741;&#21161;&#20195;&#29702;&#21464;&#37327;&#26694;&#26550;(West and Little, 2013)&#19982;&#26631;&#31614;&#20559;&#31227;&#35774;&#32622;(Saerens et al., 2002)&#30456;&#36830;&#25509;&#12290;&#21033;&#29992;&#36825;&#20010;&#36830;&#25509;&#65292;&#25105;&#20204;&#26500;&#36896;&#20102;&#19968;&#20010;&#19981;&#38656;&#35201;&#29983;&#25104;&#27169;&#22411;&#30340;&#38750;&#24573;&#30053;&#32570;&#22833;&#25968;&#25454;&#20272;&#35745;&#22120;&#65292;&#23427;&#20351;&#29992;&#39640;&#32500;&#21327;&#21464;&#37327;&#65288;&#25110;&#20195;&#29702;&#21464;&#37327;&#65289;&#12290;&#22312;&#21512;&#25104;&#21644;&#21322;&#21512;&#25104;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#25152;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#30340;&#34892;&#20026;&#65292;&#24182;&#23558;&#20854;&#19982;&#24120;&#29992;&#30340;&#21487;&#24573;&#30053;&#20272;&#35745;&#22120;&#22312;&#36866;&#24403;&#21644;&#38169;&#35823;&#35774;&#23450;&#19979;&#36827;&#34892;&#27604;&#36739;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#35780;&#20272;&#25968;&#25454;&#19982;&#26631;&#31614;&#20559;&#31227;&#20551;&#35774;&#19968;&#33268;&#24615;&#30340;&#24471;&#20998;&#12290;&#25105;&#20204;&#20351;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#30142;&#30149;&#24739;&#30149;&#29575;&#65292;&#27604;&#36739;&#21487;&#24573;&#30053;&#21644;&#19981;&#21487;&#24573;&#30053;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22914;&#26524;&#19981;&#33021;&#32771;&#34385;&#38750;&#24573;&#30053;&#32570;&#22833;&#24615;&#65292;&#21487;&#33021;&#20250;&#20135;&#29983;&#28145;&#36828;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of estimating the mean of a random variable Y subject to non-ignorable missingness, i.e., where the missingness mechanism depends on Y . We connect the auxiliary proxy variable framework for non-ignorable missingness (West and Little, 2013) to the label shift setting (Saerens et al., 2002). Exploiting this connection, we construct an estimator for non-ignorable missing data that uses high-dimensional covariates (or proxies) without the need for a generative model. In synthetic and semi-synthetic experiments, we study the behavior of the proposed estimator, comparing it to commonly used ignorable estimators in both well-specified and misspecified settings. Additionally, we develop a score to assess how consistent the data are with the label shift assumption. We use our approach to estimate disease prevalence using a large health survey, comparing ignorable and non-ignorable approaches. We show that failing to account for non-ignorable missingness can have profoun
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28145;&#24230;&#36716;&#25442;&#39640;&#26031;&#36807;&#31243;&#65288;DTGPs&#65289;&#30340;&#36716;&#25442;&#39640;&#26031;&#36807;&#31243;&#65288;TGPs&#65289;&#30340;&#25512;&#24191;&#65292;&#35813;&#27169;&#22411;&#37319;&#29992;&#20018;&#32852;&#23618;&#32423;&#30340;&#38543;&#26426;&#36807;&#31243;&#65292;&#24182;&#23454;&#29616;&#20102;&#30456;&#23545;&#20110;TGPs&#21644;DGPs&#30340;&#28789;&#27963;&#24615;&#22686;&#24378;&#12290;&#36890;&#36807;&#20351;&#29992;&#21464;&#20998;&#25512;&#29702;&#65292;&#21487;&#20197;&#36817;&#20284;&#25152;&#38656;&#30340;&#35745;&#31639;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#31616;&#21333;&#30452;&#25509;&#30340;&#25512;&#29702;&#31639;&#27861;&#25193;&#23637;&#12290;</title><link>http://arxiv.org/abs/2310.18230</link><description>&lt;p&gt;
&#28145;&#24230;&#36716;&#25442;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Deep Transformed Gaussian Processes. (arXiv:2310.18230v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18230
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28145;&#24230;&#36716;&#25442;&#39640;&#26031;&#36807;&#31243;&#65288;DTGPs&#65289;&#30340;&#36716;&#25442;&#39640;&#26031;&#36807;&#31243;&#65288;TGPs&#65289;&#30340;&#25512;&#24191;&#65292;&#35813;&#27169;&#22411;&#37319;&#29992;&#20018;&#32852;&#23618;&#32423;&#30340;&#38543;&#26426;&#36807;&#31243;&#65292;&#24182;&#23454;&#29616;&#20102;&#30456;&#23545;&#20110;TGPs&#21644;DGPs&#30340;&#28789;&#27963;&#24615;&#22686;&#24378;&#12290;&#36890;&#36807;&#20351;&#29992;&#21464;&#20998;&#25512;&#29702;&#65292;&#21487;&#20197;&#36817;&#20284;&#25152;&#38656;&#30340;&#35745;&#31639;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#31616;&#21333;&#30452;&#25509;&#30340;&#25512;&#29702;&#31639;&#27861;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36716;&#25442;&#39640;&#26031;&#36807;&#31243;&#65288;TGPs&#65289;&#26159;&#36890;&#36807;&#20351;&#29992;&#21487;&#36870;&#36716;&#25442;&#20174;&#20808;&#39564;&#36807;&#31243;&#65288;&#36890;&#24120;&#26159;&#39640;&#26031;&#36807;&#31243;&#65289;&#20013;&#36716;&#25442;&#26679;&#26412;&#26469;&#25351;&#23450;&#30340;&#38543;&#26426;&#36807;&#31243;&#65292;&#20174;&#32780;&#22686;&#21152;&#20102;&#22522;&#26412;&#36807;&#31243;&#30340;&#28789;&#27963;&#24615;&#12290;&#27492;&#22806;&#65292;&#19982;&#36890;&#36807;&#39640;&#26031;&#36807;&#31243;&#30340;&#23618;&#32423;&#20018;&#32852;&#26500;&#36896;&#30340;&#28145;&#24230;&#39640;&#26031;&#36807;&#31243;&#65288;DGPs&#65289;&#30456;&#27604;&#65292;TGPs&#23454;&#29616;&#20102;&#31454;&#20105;&#24615;&#32467;&#26524;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28145;&#24230;&#36716;&#25442;&#39640;&#26031;&#36807;&#31243;&#65288;DTGPs&#65289;&#30340;TGP&#25512;&#24191;&#65292;&#23427;&#36981;&#24490;&#20018;&#32852;&#38543;&#26426;&#36807;&#31243;&#23618;&#30340;&#36235;&#21183;&#12290;&#26356;&#20934;&#30830;&#22320;&#35828;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#19968;&#20010;&#22810;&#23618;&#27169;&#22411;&#65292;&#20854;&#20013;&#27599;&#19968;&#23618;&#37117;&#26159;&#19968;&#20010;TGP&#12290;&#36825;&#31181;&#25512;&#24191;&#24847;&#21619;&#30528;&#30456;&#23545;&#20110;TGPs&#21644;DGPs&#37117;&#25552;&#39640;&#20102;&#28789;&#27963;&#24615;&#12290;&#22312;&#36825;&#26679;&#30340;&#27169;&#22411;&#20013;&#36827;&#34892;&#31934;&#30830;&#25512;&#29702;&#26159;&#22256;&#38590;&#30340;&#12290;&#20294;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#20351;&#29992;&#21464;&#20998;&#25512;&#29702;&#26469;&#36817;&#20284;&#25152;&#38656;&#30340;&#35745;&#31639;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#27969;&#34892;&#30340;DSVI&#25512;&#29702;&#31639;&#27861;&#30340;&#30452;&#25509;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformed Gaussian Processes (TGPs) are stochastic processes specified by transforming samples from the joint distribution from a prior process (typically a GP) using an invertible transformation; increasing the flexibility of the base process.  Furthermore, they achieve competitive results compared with Deep Gaussian Processes (DGPs), which are another generalization constructed by a hierarchical concatenation of GPs. In this work, we propose a generalization of TGPs named Deep Transformed Gaussian Processes (DTGPs), which follows the trend of concatenating layers of stochastic processes. More precisely, we obtain a multi-layer model in which each layer is a TGP. This generalization implies an increment of flexibility with respect to both TGPs and DGPs. Exact inference in such a model is intractable. However, we show that one can use variational inference to approximate the required computations yielding a straightforward extension of the popular DSVI inference algorithm Salimbeni e
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38543;&#26426;&#21270;&#26080;&#27169;&#22411;&#31639;&#27861;RandQL&#65292;&#29992;&#20110;&#20943;&#23567;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#36951;&#25022;&#12290;RandQL&#36890;&#36807;&#23398;&#20064;&#29575;&#38543;&#26426;&#21270;&#23454;&#29616;&#20048;&#35266;&#25506;&#32034;&#65292;&#24182;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>http://arxiv.org/abs/2310.18186</link><description>&lt;p&gt;
&#26080;&#27169;&#22411;&#21518;&#39564;&#37319;&#26679;&#30340;&#27169;&#22411;&#33258;&#30001;&#38543;&#26426;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Model-free Posterior Sampling via Learning Rate Randomization. (arXiv:2310.18186v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18186
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38543;&#26426;&#21270;&#26080;&#27169;&#22411;&#31639;&#27861;RandQL&#65292;&#29992;&#20110;&#20943;&#23567;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#36951;&#25022;&#12290;RandQL&#36890;&#36807;&#23398;&#20064;&#29575;&#38543;&#26426;&#21270;&#23454;&#29616;&#20048;&#35266;&#25506;&#32034;&#65292;&#24182;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38543;&#26426;&#21270;&#26080;&#27169;&#22411;&#31639;&#27861;&#65292;Randomized Q-learning&#65288;&#31616;&#31216;RandQL&#65289;&#65292;&#29992;&#20110;&#20943;&#23567;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#20013;&#30340;&#36951;&#25022;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;RandQL&#26159;&#31532;&#19968;&#20010;&#21487;&#34892;&#30340;&#27169;&#22411;&#33258;&#30001;&#21518;&#39564;&#37319;&#26679;&#31639;&#27861;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;RandQL&#22312;&#34920;&#26684;&#21644;&#38750;&#34920;&#26684;&#24230;&#37327;&#31354;&#38388;&#35774;&#32622;&#19979;&#30340;&#24615;&#33021;&#12290;&#22312;&#34920;&#26684;MDPs&#20013;&#65292;RandQL&#23454;&#29616;&#20102;&#19968;&#20010;&#36951;&#25022;&#30028;&#30340;&#39034;&#24207;&#20026;$\widetilde{\mathcal{O}}(\sqrt{H^{5}SAT})$&#65292;&#20854;&#20013;$H$&#26159;&#35745;&#21010;&#30340;&#26102;&#38388;&#38271;&#24230;&#65292;$S$&#26159;&#29366;&#24577;&#25968;&#65292;$A$&#26159;&#21160;&#20316;&#25968;&#65292;$T$&#26159;&#22238;&#21512;&#25968;&#12290;&#23545;&#20110;&#24230;&#37327;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#65292;RandQL&#23454;&#29616;&#20102;&#19968;&#20010;&#36951;&#25022;&#30028;&#30340;&#39034;&#24207;&#20026;$\widetilde{\mathcal{O}}(H^{5/2} T^{(d_z+1)/(d_z+2)})$&#65292;&#20854;&#20013;$d_z$&#34920;&#31034;&#32553;&#25918;&#32500;&#24230;&#12290;&#38656;&#35201;&#27880;&#24847;&#30340;&#26159;&#65292;RandQL&#23454;&#29616;&#20102;&#20048;&#35266;&#25506;&#32034;&#65292;&#32780;&#19981;&#20351;&#29992;&#22870;&#21169;&#65292;&#32780;&#26159;&#20381;&#36182;&#20110;&#23398;&#20064;&#29575;&#38543;&#26426;&#21270;&#30340;&#26032;&#24605;&#24819;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;RandQL&#22312;&#22522;&#32447;&#25506;&#32034;&#19978;&#32988;&#36807;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce Randomized Q-learning (RandQL), a novel randomized model-free algorithm for regret minimization in episodic Markov Decision Processes (MDPs). To the best of our knowledge, RandQL is the first tractable model-free posterior sampling-based algorithm. We analyze the performance of RandQL in both tabular and non-tabular metric space settings. In tabular MDPs, RandQL achieves a regret bound of order $\widetilde{\mathcal{O}}(\sqrt{H^{5}SAT})$, where $H$ is the planning horizon, $S$ is the number of states, $A$ is the number of actions, and $T$ is the number of episodes. For a metric state-action space, RandQL enjoys a regret bound of order $\widetilde{\mathcal{O}}(H^{5/2} T^{(d_z+1)/(d_z+2)})$, where $d_z$ denotes the zooming dimension. Notably, RandQL achieves optimistic exploration without using bonuses, relying instead on a novel idea of learning rate randomization. Our empirical study shows that RandQL outperforms existing approaches on baseline exploration en
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#35757;&#32451;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#20102;&#23545;score-matching&#30340;&#20934;&#30830;&#20272;&#35745;&#65292;&#24182;&#22312;&#22240;&#26524;&#21457;&#29616;&#21644;&#29983;&#25104;&#24314;&#27169;&#39046;&#22495;&#20013;&#25552;&#20379;&#20102;&#32479;&#35745;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2310.18123</link><description>&lt;p&gt;
score-matching&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#65306;&#22240;&#26524;&#21457;&#29616;&#21644;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Sample Complexity Bounds for Score-Matching: Causal Discovery and Generative Modeling. (arXiv:2310.18123v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18123
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#35757;&#32451;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#20102;&#23545;score-matching&#30340;&#20934;&#30830;&#20272;&#35745;&#65292;&#24182;&#22312;&#22240;&#26524;&#21457;&#29616;&#21644;&#29983;&#25104;&#24314;&#27169;&#39046;&#22495;&#20013;&#25552;&#20379;&#20102;&#32479;&#35745;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;score-matching&#21450;&#20854;&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#30340;&#24212;&#29992;&#30340;&#32479;&#35745;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#12290;&#25105;&#20204;&#35777;&#26126;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#26631;&#20934;&#30340;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#23454;&#29616;&#23545;&#20998;&#25968;&#20989;&#25968;&#30340;&#20934;&#30830;&#20272;&#35745;&#12290;&#22312;&#20551;&#23450;&#20998;&#25968;&#20989;&#25968;&#30340;&#20272;&#35745;&#36275;&#22815;&#22909;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23545;&#20351;&#29992;&#22522;&#20110;score-matching&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#30340;&#24674;&#22797;&#22240;&#26524;&#20851;&#31995;&#30340;&#38169;&#35823;&#29575;&#24314;&#31435;&#20102;&#30028;&#38480;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#24314;&#27169;&#20013;&#30340;score-matching&#20272;&#35745;&#30340;&#19978;&#30028;&#65292;&#35813;&#26041;&#27861;&#19981;&#20165;&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#24212;&#29992;&#24191;&#27867;&#65292;&#20063;&#22312;&#29983;&#25104;&#27169;&#22411;&#39046;&#22495;&#20855;&#26377;&#29420;&#31435;&#30340;&#30740;&#31350;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper provides statistical sample complexity bounds for score-matching and its applications in causal discovery. We demonstrate that accurate estimation of the score function is achievable by training a standard deep ReLU neural network using stochastic gradient descent. We establish bounds on the error rate of recovering causal relationships using the score-matching-based causal discovery method of Rolland et al. [2022], assuming a sufficiently good estimation of the score function. Finally, we analyze the upper bound of score-matching estimation within the score-based generative modeling, which has been applied for causal discovery but is also of independent interest within the domain of generative models.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#20808;&#39564;&#21644;&#38750;&#32447;&#24615;&#24322;&#24120;&#20998;&#25968;&#30340;&#23545;&#25239;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#12290;&#36890;&#36807;&#32467;&#21512;$\beta$-VAE&#30340;&#29983;&#25104;&#31283;&#23450;&#24615;&#21644;GAN&#30340;&#21028;&#21035;&#33021;&#21147;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;$\beta$-VAEGAN&#65292;&#24182;&#23545;&#24322;&#24120;&#20998;&#25968;&#30340;&#32452;&#21512;&#26041;&#27861;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#36890;&#36807;&#35757;&#32451;&#26680;&#21270;SVM&#65292;&#32771;&#34385;&#20102;&#38750;&#32447;&#24615;&#20851;&#31995;&#65292;&#21516;&#26102;&#21033;&#29992;$\beta$-VAEGAN&#23545;&#39640;&#26031;&#20808;&#39564;&#30340;&#20559;&#24046;&#24418;&#25104;&#20102;&#26032;&#30340;&#24322;&#24120;&#20998;&#25968;&#32452;&#20214;&#12290;&#30456;&#27604;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#24322;&#24120;&#26816;&#27979;&#24615;&#33021;&#19978;&#26377;&#25152;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2310.18091</link><description>&lt;p&gt;
&#22522;&#20110;&#39640;&#26031;&#20808;&#39564;&#21644;&#38750;&#32447;&#24615;&#24322;&#24120;&#20998;&#25968;&#30340;&#23545;&#25239;&#24322;&#24120;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Adversarial Anomaly Detection using Gaussian Priors and Nonlinear Anomaly Scores. (arXiv:2310.18091v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18091
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#20808;&#39564;&#21644;&#38750;&#32447;&#24615;&#24322;&#24120;&#20998;&#25968;&#30340;&#23545;&#25239;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#12290;&#36890;&#36807;&#32467;&#21512;$\beta$-VAE&#30340;&#29983;&#25104;&#31283;&#23450;&#24615;&#21644;GAN&#30340;&#21028;&#21035;&#33021;&#21147;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;$\beta$-VAEGAN&#65292;&#24182;&#23545;&#24322;&#24120;&#20998;&#25968;&#30340;&#32452;&#21512;&#26041;&#27861;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#36890;&#36807;&#35757;&#32451;&#26680;&#21270;SVM&#65292;&#32771;&#34385;&#20102;&#38750;&#32447;&#24615;&#20851;&#31995;&#65292;&#21516;&#26102;&#21033;&#29992;$\beta$-VAEGAN&#23545;&#39640;&#26031;&#20808;&#39564;&#30340;&#20559;&#24046;&#24418;&#25104;&#20102;&#26032;&#30340;&#24322;&#24120;&#20998;&#25968;&#32452;&#20214;&#12290;&#30456;&#27604;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#24322;&#24120;&#26816;&#27979;&#24615;&#33021;&#19978;&#26377;&#25152;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#20013;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#26159;&#19968;&#20010;&#39057;&#32321;&#19988;&#20851;&#38190;&#30340;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#22312;&#21307;&#30103;&#39046;&#22495;&#65292;&#33719;&#21462;&#21644;&#26631;&#35760;&#24322;&#24120;&#36890;&#24120;&#26159;&#26114;&#36149;&#30340;&#12290;&#23558;$\beta$&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#30340;&#29983;&#25104;&#31283;&#23450;&#24615;&#19982;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#30340;&#21028;&#21035;&#33021;&#21147;&#30456;&#32467;&#21512;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;$\beta$-VAEGAN&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;&#25105;&#20204;&#27169;&#22411;&#30340;&#21028;&#21035;&#33021;&#21147;&#21644;&#37325;&#26500;&#33021;&#21147;&#30340;&#24322;&#24120;&#20998;&#25968;&#30340;&#32452;&#21512;&#26041;&#27861;&#12290;&#29616;&#26377;&#24037;&#20316;&#38598;&#20013;&#20110;&#32447;&#24615;&#32452;&#21512;&#36825;&#20123;&#32452;&#20214;&#26469;&#30830;&#23450;&#25968;&#25454;&#26159;&#21542;&#24322;&#24120;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#30456;&#24212;&#30340;&#38169;&#35823;&#32452;&#20214;&#19978;&#35757;&#32451;&#26680;&#21270;&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#65292;&#36827;&#19968;&#27493;&#25913;&#36827;&#20102;&#29616;&#26377;&#24037;&#20316;&#65292;&#24182;&#32771;&#34385;&#20102;&#38750;&#32447;&#24615;&#20851;&#31995;&#12290;&#36825;&#25552;&#39640;&#20102;&#24322;&#24120;&#26816;&#27979;&#24615;&#33021;&#65292;&#21516;&#26102;&#20801;&#35768;&#26356;&#24555;&#30340;&#20248;&#21270;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;$\beta$-VAEGAN&#23545;&#20110;&#39640;&#26031;&#20808;&#39564;&#30340;&#20559;&#24046;&#24418;&#25104;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#24322;&#24120;&#20998;&#25968;&#32452;&#20214;&#12290;&#19982;&#26368;&#20808;&#36827;&#30340;&#24037;&#20316;&#30456;&#27604;&#65292;&#25105;&#20204;&#25913;&#36827;&#20102;&#24322;&#24120;&#26816;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Anomaly detection in imbalanced datasets is a frequent and crucial problem, especially in the medical domain where retrieving and labeling irregularities is often expensive. By combining the generative stability of a $\beta$-variational autoencoder (VAE) with the discriminative strengths of generative adversarial networks (GANs), we propose a novel model, $\beta$-VAEGAN. We investigate methods for composing anomaly scores based on the discriminative and reconstructive capabilities of our model. Existing work focuses on linear combinations of these components to determine if data is anomalous. We advance existing work by training a kernelized support vector machine (SVM) on the respective error components to also consider nonlinear relationships. This improves anomaly detection performance, while allowing faster optimization. Lastly, we use the deviations from the Gaussian prior of $\beta$-VAEGAN to form a novel anomaly score component. In comparison to state-of-the-art work, we improve
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#22823;&#35268;&#27169;&#38382;&#39064;&#20013;&#30340;&#22343;&#22330;&#26497;&#38480;&#19979;&#30340;&#26680;&#32479;&#35745;&#23398;&#20064;&#65292;&#21253;&#25324;&#26680;&#30340;&#22343;&#22330;&#26497;&#38480;&#30340;&#29702;&#35770;&#23436;&#21892;&#12289;&#36924;&#36817;&#20197;&#21450;&#25903;&#25345;&#21521;&#37327;&#26426;&#31561;&#30340;&#24212;&#29992;&#12290;&#30740;&#31350;&#32467;&#26524;&#20026;&#22823;&#35268;&#27169;&#38382;&#39064;&#25552;&#20379;&#20102;&#26032;&#30340;&#29702;&#35770;&#24037;&#20855;&#21644;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2310.18074</link><description>&lt;p&gt;
&#20851;&#20110;&#22343;&#22330;&#26497;&#38480;&#20013;&#22522;&#20110;&#26680;&#30340;&#32479;&#35745;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
On kernel-based statistical learning in the mean field limit. (arXiv:2310.18074v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18074
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#22823;&#35268;&#27169;&#38382;&#39064;&#20013;&#30340;&#22343;&#22330;&#26497;&#38480;&#19979;&#30340;&#26680;&#32479;&#35745;&#23398;&#20064;&#65292;&#21253;&#25324;&#26680;&#30340;&#22343;&#22330;&#26497;&#38480;&#30340;&#29702;&#35770;&#23436;&#21892;&#12289;&#36924;&#36817;&#20197;&#21450;&#25903;&#25345;&#21521;&#37327;&#26426;&#31561;&#30340;&#24212;&#29992;&#12290;&#30740;&#31350;&#32467;&#26524;&#20026;&#22823;&#35268;&#27169;&#38382;&#39064;&#25552;&#20379;&#20102;&#26032;&#30340;&#29702;&#35770;&#24037;&#20855;&#21644;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#65292;&#32771;&#34385;&#20102;&#22823;&#37327;&#30340;&#21464;&#37327;&#12290;&#21463;&#20132;&#20114;&#31890;&#23376;&#31995;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#21551;&#21457;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#36755;&#20837;&#21464;&#37327;&#25968;&#37327;&#36235;&#20110;&#26080;&#31351;&#22823;&#30340;&#24773;&#20917;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#30740;&#31350;&#20102;&#26680;&#21450;&#20854;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;&#22343;&#22330;&#26497;&#38480;&#65292;&#23436;&#21892;&#20102;&#29616;&#26377;&#29702;&#35770;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19982;&#22343;&#22330;&#26497;&#38480;&#19979;&#36825;&#20123;&#26680;&#30340;&#36924;&#36817;&#30456;&#20851;&#30340;&#32467;&#26524;&#65292;&#21253;&#25324;&#19968;&#20010;&#34920;&#29616;&#23450;&#29702;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#26680;&#24212;&#29992;&#20110;&#22312;&#22343;&#22330;&#26497;&#38480;&#20013;&#30340;&#32479;&#35745;&#23398;&#20064;&#65292;&#37325;&#28857;&#20851;&#27880;&#25903;&#25345;&#21521;&#37327;&#26426;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#32463;&#39564;&#21644;&#26080;&#31351;&#26679;&#26412;&#35299;&#30340;&#22343;&#22330;&#25910;&#25947;&#20197;&#21450;&#30456;&#24212;&#39118;&#38505;&#30340;&#25910;&#25947;&#12290;&#19968;&#26041;&#38754;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#22312;&#26680;&#26041;&#27861;&#30340;&#32972;&#26223;&#19979;&#24314;&#31435;&#20102;&#20005;&#26684;&#30340;&#22343;&#22330;&#26497;&#38480;&#65292;&#20026;&#22823;&#35268;&#27169;&#38382;&#39064;&#25552;&#20379;&#20102;&#26032;&#30340;&#29702;&#35770;&#24037;&#20855;&#21644;&#35265;&#35299;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#25105;&#20204;&#30340;&#35774;&#32622;&#23545;&#24212;&#20110;...
&lt;/p&gt;
&lt;p&gt;
In many applications of machine learning, a large number of variables are considered. Motivated by machine learning of interacting particle systems, we consider the situation when the number of input variables goes to infinity. First, we continue the recent investigation of the mean field limit of kernels and their reproducing kernel Hilbert spaces, completing the existing theory. Next, we provide results relevant for approximation with such kernels in the mean field limit, including a representer theorem. Finally, we use these kernels in the context of statistical learning in the mean field limit, focusing on Support Vector Machines. In particular, we show mean field convergence of empirical and infinite-sample solutions as well as the convergence of the corresponding risks. On the one hand, our results establish rigorous mean field limits in the context of kernel methods, providing new theoretical tools and insights for large-scale problems. On the other hand, our setting corresponds
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#39044;&#21518;&#21327;&#21464;&#37327;&#35843;&#25972;&#26041;&#27861;&#65292;&#32467;&#21512;&#20102;&#21327;&#21464;&#37327;&#35843;&#25972;&#21644;&#21382;&#21490;&#23545;&#29031;&#20449;&#24687;&#21033;&#29992;&#30340;&#31574;&#30053;&#65292;&#22312;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#20013;&#29992;&#20110;&#26377;&#25928;&#21644;&#24555;&#36895;&#20915;&#31574;&#12290;&#36890;&#36807;&#29983;&#25104;&#22411;&#20154;&#24037;&#26234;&#33021;&#31639;&#27861;&#26500;&#24314;&#25968;&#23383;&#23402;&#29983;&#29983;&#25104;&#22120;&#65292;&#21033;&#29992;&#21382;&#21490;&#23545;&#29031;&#25968;&#25454;&#20135;&#29983;&#25968;&#23383;&#23402;&#29983;&#27010;&#29575;&#20998;&#24067;&#65292;&#20174;&#32780;&#36827;&#34892;&#21333;&#19968;&#21327;&#21464;&#37327;&#35843;&#25972;&#12290;</title><link>http://arxiv.org/abs/2310.18027</link><description>&lt;p&gt;
&#20855;&#26377;&#21472;&#21152;&#28151;&#21512;&#20808;&#39564;&#30340;&#36125;&#21494;&#26031;&#39044;&#21518;&#21327;&#21464;&#37327;&#35843;&#25972;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Bayesian Prognostic Covariate Adjustment With Additive Mixture Priors. (arXiv:2310.18027v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18027
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#39044;&#21518;&#21327;&#21464;&#37327;&#35843;&#25972;&#26041;&#27861;&#65292;&#32467;&#21512;&#20102;&#21327;&#21464;&#37327;&#35843;&#25972;&#21644;&#21382;&#21490;&#23545;&#29031;&#20449;&#24687;&#21033;&#29992;&#30340;&#31574;&#30053;&#65292;&#22312;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#20013;&#29992;&#20110;&#26377;&#25928;&#21644;&#24555;&#36895;&#20915;&#31574;&#12290;&#36890;&#36807;&#29983;&#25104;&#22411;&#20154;&#24037;&#26234;&#33021;&#31639;&#27861;&#26500;&#24314;&#25968;&#23383;&#23402;&#29983;&#29983;&#25104;&#22120;&#65292;&#21033;&#29992;&#21382;&#21490;&#23545;&#29031;&#25968;&#25454;&#20135;&#29983;&#25968;&#23383;&#23402;&#29983;&#27010;&#29575;&#20998;&#24067;&#65292;&#20174;&#32780;&#36827;&#34892;&#21333;&#19968;&#21327;&#21464;&#37327;&#35843;&#25972;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#65288;RCTs&#65289;&#20013;&#36827;&#34892;&#26377;&#25928;&#21644;&#24555;&#36895;&#30340;&#20915;&#31574;&#38656;&#35201;&#26080;&#20559;&#21644;&#20934;&#30830;&#30340;&#27835;&#30103;&#25928;&#26524;&#25512;&#26029;&#12290;&#20026;&#20102;&#28385;&#36275;&#36825;&#19968;&#35201;&#27714;&#65292;&#26377;&#20004;&#31181;&#31574;&#30053;&#65306;&#35843;&#25972;&#19982;&#32467;&#26524;&#39640;&#24230;&#30456;&#20851;&#30340;&#21327;&#21464;&#37327;&#65292;&#20197;&#21450;&#36890;&#36807;&#36125;&#21494;&#26031;&#23450;&#29702;&#21033;&#29992;&#21382;&#21490;&#23545;&#29031;&#20449;&#24687;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#39044;&#21518;&#21327;&#21464;&#37327;&#35843;&#25972;&#26041;&#27861;&#65292;&#31216;&#20026;&#36125;&#21494;&#26031;PROCOVA&#65292;&#23558;&#36825;&#20004;&#31181;&#31574;&#30053;&#32467;&#21512;&#36215;&#26469;&#12290;&#21327;&#21464;&#37327;&#35843;&#25972;&#22522;&#20110;&#29983;&#25104;&#22411;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#31639;&#27861;&#65292;&#26500;&#24314;&#20102;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#21442;&#19982;&#32773;&#30340;&#25968;&#23383;&#23402;&#29983;&#29983;&#25104;&#22120;&#65288;DTG&#65289;&#12290;DTG&#36890;&#36807;&#21382;&#21490;&#23545;&#29031;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#65292;&#20026;&#27599;&#20010;&#21442;&#19982;&#32773;&#30340;&#23545;&#29031;&#32467;&#26524;&#20135;&#29983;&#20102;&#19968;&#20010;&#25968;&#23383;&#23402;&#29983;&#65288;DT&#65289;&#27010;&#29575;&#20998;&#24067;&#12290;DT&#20998;&#24067;&#30340;&#26399;&#26395;&#23450;&#20041;&#20102;&#29992;&#20110;&#35843;&#25972;&#30340;&#21333;&#19968;&#21327;&#21464;&#37327;&#12290;&#21382;&#21490;&#23545;&#29031;&#20449;&#24687;&#36890;&#36807;&#20855;&#26377;&#20004;&#20010;&#32452;&#25104;&#37096;&#20998;&#30340;&#21472;&#21152;&#28151;&#21512;&#20808;&#39564;&#36827;&#34892;&#21033;&#29992;&#65306;&#22522;&#20110;&#20808;&#39564;&#20449;&#24687;&#30830;&#23450;&#30340;&#19968;&#20010;&#20449;&#24687;&#20808;&#39564;&#27010;&#29575;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
Effective and rapid decision-making from randomized controlled trials (RCTs) requires unbiased and precise treatment effect inferences. Two strategies to address this requirement are to adjust for covariates that are highly correlated with the outcome, and to leverage historical control information via Bayes' theorem. We propose a new Bayesian prognostic covariate adjustment methodology, referred to as Bayesian PROCOVA, that combines these two strategies. Covariate adjustment is based on generative artificial intelligence (AI) algorithms that construct a digital twin generator (DTG) for RCT participants. The DTG is trained on historical control data and yields a digital twin (DT) probability distribution for each participant's control outcome. The expectation of the DT distribution defines the single covariate for adjustment. Historical control information are leveraged via an additive mixture prior with two components: an informative prior probability distribution specified based on h
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25913;&#36827;&#20102;&#30693;&#35782;&#26799;&#24230;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#30693;&#35782;&#26799;&#24230;&#65288;iKG&#65289;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#35299;&#20915;&#20102;&#30693;&#35782;&#26799;&#24230;&#31639;&#27861;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#19988;&#22312;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#20013;&#20855;&#26377;&#28176;&#36817;&#26368;&#20248;&#24615;&#12290;&#27492;&#22806;&#65292;&#30456;&#27604;&#30693;&#35782;&#26799;&#24230;&#65288;KG&#65289;&#65292;iKG&#26356;&#23481;&#26131;&#25193;&#23637;&#21040;&#20854;&#20182;BAI&#38382;&#39064;&#65292;&#19988;&#22312;&#36825;&#20123;&#38382;&#39064;&#19978;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.17901</link><description>&lt;p&gt;
&#25913;&#36827;&#30693;&#35782;&#26799;&#24230;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Improving the Knowledge Gradient Algorithm. (arXiv:2310.17901v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17901
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25913;&#36827;&#20102;&#30693;&#35782;&#26799;&#24230;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#30693;&#35782;&#26799;&#24230;&#65288;iKG&#65289;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#35299;&#20915;&#20102;&#30693;&#35782;&#26799;&#24230;&#31639;&#27861;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#19988;&#22312;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#20013;&#20855;&#26377;&#28176;&#36817;&#26368;&#20248;&#24615;&#12290;&#27492;&#22806;&#65292;&#30456;&#27604;&#30693;&#35782;&#26799;&#24230;&#65288;KG&#65289;&#65292;iKG&#26356;&#23481;&#26131;&#25193;&#23637;&#21040;&#20854;&#20182;BAI&#38382;&#39064;&#65292;&#19988;&#22312;&#36825;&#20123;&#38382;&#39064;&#19978;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#26799;&#24230;&#65288;KG&#65289;&#31639;&#27861;&#26159;&#19968;&#31181;&#29992;&#20110;&#26368;&#20339;&#33218;&#35782;&#21035;&#65288;BAI&#65289;&#38382;&#39064;&#30340;&#27969;&#34892;&#31574;&#30053;&#12290;&#23427;&#24314;&#31435;&#22312;&#19968;&#31181;&#31616;&#21333;&#30340;&#24605;&#24819;&#19978;&#65292;&#21363;&#22987;&#32456;&#36873;&#25321;&#20135;&#29983;&#23545;&#33218;&#30340;&#26368;&#20339;&#22343;&#20540;&#20272;&#35745;&#39044;&#26399;&#19968;&#27493;&#25913;&#36827;&#26368;&#22823;&#30340;&#27979;&#37327;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#36825;&#31181;&#31574;&#30053;&#23384;&#22312;&#23616;&#38480;&#24615;&#65292;&#23548;&#33268;&#31639;&#27861;&#22312;&#28176;&#36817;&#19978;&#19981;&#26159;&#26368;&#20248;&#30340;&#12290;&#25105;&#20204;&#25509;&#19979;&#26469;&#25552;&#20379;&#20102;&#19968;&#31181;&#25913;&#36827;&#26041;&#27861;&#65292;&#36890;&#36807;&#36981;&#24490;KG&#30340;&#19968;&#27493;&#21069;&#30651;&#26041;&#24335;&#65292;&#20294;&#36873;&#25321;&#20135;&#29983;&#23545;&#36873;&#25321;&#26368;&#20339;&#33218;&#30340;&#27010;&#29575;&#26368;&#22823;&#30340;&#19968;&#27493;&#25913;&#36827;&#30340;&#27979;&#37327;&#12290;&#26032;&#30340;&#31574;&#30053;&#31216;&#20026;&#25913;&#36827;&#30340;&#30693;&#35782;&#26799;&#24230;&#65288;iKG&#65289;&#12290;&#21487;&#20197;&#35777;&#26126;iKG&#22312;&#28176;&#36817;&#19978;&#26159;&#26368;&#20248;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#19982;KG&#30456;&#27604;&#65292;&#26356;&#23481;&#26131;&#23558;iKG&#25193;&#23637;&#21040;BAI&#30340;&#19981;&#21516;&#38382;&#39064;&#65292;&#20854;&#20013;&#21253;&#25324;&#949;-&#22909;&#33218;&#35782;&#21035;&#21644;&#21487;&#34892;&#33218;&#35782;&#21035;&#20004;&#20010;&#20363;&#23376;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#25968;&#20540;&#23454;&#20363;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;iKG&#22312;&#36825;&#20123;&#38382;&#39064;&#19978;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The knowledge gradient (KG) algorithm is a popular policy for the best arm identification (BAI) problem. It is built on the simple idea of always choosing the measurement that yields the greatest expected one-step improvement in the estimate of the best mean of the arms. In this research, we show that this policy has limitations, causing the algorithm not asymptotically optimal. We next provide a remedy for it, by following the manner of one-step look ahead of KG, but instead choosing the measurement that yields the greatest one-step improvement in the probability of selecting the best arm. The new policy is called improved knowledge gradient (iKG). iKG can be shown to be asymptotically optimal. In addition, we show that compared to KG, it is easier to extend iKG to variant problems of BAI, with the $\epsilon$-good arm identification and feasible arm identification as two examples. The superior performances of iKG on these problems are further demonstrated using numerical examples.
&lt;/p&gt;</description></item><item><title>&#22810;&#23454;&#20363;&#23398;&#20064;&#20013;&#30340;&#20116;&#20010;&#28145;&#24230;&#27169;&#22411;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#36829;&#21453;&#20102;&#26631;&#20934;&#30340;MIL&#20551;&#35774;&#65292;&#23548;&#33268;&#33021;&#22815;&#23398;&#20064;&#21453;&#30456;&#20851;&#30340;&#23454;&#20363;&#12290;&#36825;&#19968;&#38382;&#39064;&#38656;&#35201;&#36890;&#36807;&#25913;&#36827;&#21644;&#20854;&#20182;&#31574;&#30053;&#26469;&#35299;&#20915;&#12290;</title><link>http://arxiv.org/abs/2310.17867</link><description>&lt;p&gt;
&#22810;&#23454;&#20363;&#23398;&#20064;&#20013;&#30340;&#21487;&#37325;&#29616;&#24615;: &#31639;&#27861;&#21333;&#20803;&#27979;&#35797;&#30340;&#26696;&#20363;
&lt;/p&gt;
&lt;p&gt;
Reproducibility in Multiple Instance Learning: A Case For Algorithmic Unit Tests. (arXiv:2310.17867v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17867
&lt;/p&gt;
&lt;p&gt;
&#22810;&#23454;&#20363;&#23398;&#20064;&#20013;&#30340;&#20116;&#20010;&#28145;&#24230;&#27169;&#22411;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#36829;&#21453;&#20102;&#26631;&#20934;&#30340;MIL&#20551;&#35774;&#65292;&#23548;&#33268;&#33021;&#22815;&#23398;&#20064;&#21453;&#30456;&#20851;&#30340;&#23454;&#20363;&#12290;&#36825;&#19968;&#38382;&#39064;&#38656;&#35201;&#36890;&#36807;&#25913;&#36827;&#21644;&#20854;&#20182;&#31574;&#30053;&#26469;&#35299;&#20915;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#23454;&#20363;&#23398;&#20064;(MIL)&#26159;&#20998;&#31867;&#38382;&#39064;&#30340;&#19968;&#20010;&#23376;&#39046;&#22495;&#65292;&#20854;&#20013;&#26377;&#27491;&#36127;&#26631;&#31614;&#21644;&#19968;&#20010;&#36755;&#20837;&#30340;&#8220;&#21253;&#8221;&#65292;&#24403;&#19988;&#20165;&#24403;&#21253;&#20013;&#21253;&#21547;&#19968;&#20010;&#27491;&#20803;&#32032;&#26102;&#65292;&#26631;&#31614;&#20026;&#27491;&#65292;&#21542;&#21017;&#20026;&#36127;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#35757;&#32451;&#38656;&#35201;&#23558;&#21253;&#32423;&#26631;&#31614;&#19982;&#23454;&#20363;&#32423;&#20449;&#24687;&#20851;&#32852;&#36215;&#26469;&#65292;&#24182;&#38544;&#21547;&#30528;&#19968;&#20010;&#22240;&#26524;&#20551;&#35774;&#21644;&#20219;&#21153;&#30340;&#19981;&#23545;&#31216;&#24615;&#65288;&#21363;&#65292;&#26080;&#27861;&#20132;&#25442;&#26631;&#31614;&#32780;&#19981;&#25913;&#21464;&#35821;&#20041;&#65289;&#12290;MIL&#38382;&#39064;&#20986;&#29616;&#22312;&#21307;&#30103;&#20445;&#20581;&#65288;&#19968;&#20010;&#24694;&#24615;&#32454;&#32990;&#34920;&#31034;&#30284;&#30151;&#65289;&#65292;&#32593;&#32476;&#23433;&#20840;&#65288;&#19968;&#20010;&#24694;&#24847;&#21487;&#25191;&#34892;&#25991;&#20214;&#20250;&#24863;&#26579;&#35745;&#31639;&#26426;&#65289;&#31561;&#35768;&#22810;&#20219;&#21153;&#20013;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#26816;&#26597;&#20102;&#26368;&#33879;&#21517;&#30340;&#20116;&#20010;&#28145;&#24230;MIL&#27169;&#22411;&#65292;&#24182;&#21457;&#29616;&#23427;&#20204;&#37117;&#19981;&#31526;&#21512;&#26631;&#20934;&#30340;MIL&#20551;&#35774;&#12290;&#23427;&#20204;&#33021;&#22815;&#23398;&#20064;&#21453;&#30456;&#20851;&#30340;&#23454;&#20363;&#65292;&#21363;&#22312;&#30475;&#21040;&#36127;&#30340;&#21453;&#20363;&#20043;&#21069;&#40664;&#35748;&#20026;&#8220;&#27491;&#8221;&#26631;&#31614;&#65292;&#36825;&#23545;&#20110;&#19968;&#20010;&#27491;&#30830;&#30340;MIL&#27169;&#22411;&#26469;&#35828;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#25105;&#20204;&#24576;&#30097;&#25913;&#36827;&#21644;&#20854;&#20182;&#31574;&#30053;&#21487;&#33021;&#20250;&#25913;&#21892;&#36825;&#19968;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multiple Instance Learning (MIL) is a sub-domain of classification problems with positive and negative labels and a "bag" of inputs, where the label is positive if and only if a positive element is contained within the bag, and otherwise is negative. Training in this context requires associating the bag-wide label to instance-level information, and implicitly contains a causal assumption and asymmetry to the task (i.e., you can't swap the labels without changing the semantics). MIL problems occur in healthcare (one malignant cell indicates cancer), cyber security (one malicious executable makes an infected computer), and many other tasks. In this work, we examine five of the most prominent deep-MIL models and find that none of them respects the standard MIL assumption. They are able to learn anti-correlated instances, i.e., defaulting to "positive" labels until seeing a negative counter-example, which should not be possible for a correct MIL model. We suspect that enhancements and othe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#26694;&#26550;&#26469;&#25552;&#21319;&#25968;&#25454;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#22312;&#27492;&#26041;&#27861;&#20013;&#65292;&#20351;&#29992;&#20808;&#36827;&#27169;&#22411;&#29983;&#25104;&#39640;&#36924;&#30495;&#24230;&#30340;&#21512;&#25104;&#25968;&#25454;&#65292;&#24182;&#37319;&#29992;&#32479;&#35745;&#26041;&#27861;&#36827;&#34892;&#20998;&#26512;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#30340;&#32479;&#35745;&#26041;&#27861;&#38169;&#35823;&#38543;&#30528;&#21512;&#25104;&#25968;&#25454;&#30340;&#22686;&#21152;&#32780;&#20943;&#23569;&#65292;&#20294;&#26368;&#32456;&#21487;&#33021;&#20250;&#22686;&#21152;&#25110;&#20572;&#28382;&#12290;</title><link>http://arxiv.org/abs/2310.17848</link><description>&lt;p&gt;
&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#25193;&#23637;&#25552;&#21319;&#25968;&#25454;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Boosting Data Analytics With Synthetic Volume Expansion. (arXiv:2310.17848v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17848
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#26694;&#26550;&#26469;&#25552;&#21319;&#25968;&#25454;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#22312;&#27492;&#26041;&#27861;&#20013;&#65292;&#20351;&#29992;&#20808;&#36827;&#27169;&#22411;&#29983;&#25104;&#39640;&#36924;&#30495;&#24230;&#30340;&#21512;&#25104;&#25968;&#25454;&#65292;&#24182;&#37319;&#29992;&#32479;&#35745;&#26041;&#27861;&#36827;&#34892;&#20998;&#26512;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#30340;&#32479;&#35745;&#26041;&#27861;&#38169;&#35823;&#38543;&#30528;&#21512;&#25104;&#25968;&#25454;&#30340;&#22686;&#21152;&#32780;&#20943;&#23569;&#65292;&#20294;&#26368;&#32456;&#21487;&#33021;&#20250;&#22686;&#21152;&#25110;&#20572;&#28382;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#20316;&#20026;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#30340;&#22522;&#30707;&#65292;&#22312;&#35299;&#20915;&#25968;&#25454;&#31232;&#32570;&#21644;&#38544;&#31169;&#38382;&#39064;&#30340;&#21516;&#26102;&#65292;&#23454;&#29616;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#24615;&#33021;&#12290;&#38543;&#30528;&#21512;&#25104;&#25968;&#25454;&#30340;&#26085;&#30410;&#37325;&#35201;&#65292;&#20154;&#20204;&#24320;&#22987;&#20851;&#27880;&#32479;&#35745;&#26041;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#19982;&#21407;&#22987;&#25968;&#25454;&#19978;&#30340;&#20934;&#30830;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#29992;&#20110;&#20998;&#26512;&#30340;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#26694;&#26550;&#12290;&#35813;&#26694;&#26550;&#20351;&#29992;&#39640;&#36924;&#30495;&#24230;&#30340;&#21512;&#25104;&#25968;&#25454;&#65292;&#36890;&#36807;&#20808;&#36827;&#27169;&#22411;&#22914;&#34920;&#26684;&#25193;&#25955;&#21644;&#29983;&#25104;&#24335;&#39044;&#35757;&#32451;&#36716;&#25442;&#22120;&#27169;&#22411;&#29983;&#25104;&#65292;&#24182;&#32467;&#21512;&#30456;&#20851;&#30740;&#31350;&#27934;&#23519;&#36827;&#19968;&#27493;&#22686;&#24378;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#21457;&#29616;&#26159;&#29983;&#25104;&#25928;&#24212;&#65306;&#32479;&#35745;&#26041;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#30340;&#38169;&#35823;&#38543;&#30528;&#21512;&#25104;&#25968;&#25454;&#30340;&#22686;&#21152;&#19968;&#24320;&#22987;&#20943;&#23569;&#65292;&#20294;&#26368;&#32456;&#21487;&#33021;&#20250;&#22686;&#21152;&#25110;&#20572;&#28382;&#12290;&#36825;&#20010;&#29616;&#35937;&#26681;&#28304;&#20110;&#22797;&#21046;&#21407;&#22987;&#25968;&#25454;&#20998;&#24067;&#30340;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Synthetic data generation, a cornerstone of Generative Artificial Intelligence, signifies a paradigm shift in data science by addressing data scarcity and privacy while enabling unprecedented performance. As synthetic data gains prominence, questions arise concerning the accuracy of statistical methods when applied to synthetic data compared to raw data. In this article, we introduce the Synthetic Data Generation for Analytics framework. This framework employs statistical methods on high-fidelity synthetic data generated by advanced models such as tabular diffusion and Generative Pre-trained Transformer models. These models, trained on raw data, are further enhanced with insights from pertinent studies. A significant discovery within this framework is the generational effect: the error of a statistical method on synthetic data initially diminishes with added synthetic data but may eventually increase or plateau. This phenomenon, rooted in the complexities of replicating raw data distri
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#25805;&#20316;&#21592;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#36138;&#23146;&#31639;&#27861;&#36873;&#25321;&#33258;&#36866;&#24212;&#28857;&#23545;&#39044;&#35757;&#32451;&#30340;&#36817;&#20284;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#65292;&#36880;&#28176;&#20943;&#23569;&#24314;&#27169;&#35823;&#24046;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#22312;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#65292;&#26377;&#21161;&#20110;&#26377;&#25928;&#35299;&#20915;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;&#20013;&#30340;&#35745;&#31639;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.17844</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#25805;&#20316;&#21592;&#23398;&#20064;&#29992;&#20110;&#26080;&#38480;&#32500;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Adaptive operator learning for infinite-dimensional Bayesian inverse problems. (arXiv:2310.17844v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17844
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#25805;&#20316;&#21592;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#36138;&#23146;&#31639;&#27861;&#36873;&#25321;&#33258;&#36866;&#24212;&#28857;&#23545;&#39044;&#35757;&#32451;&#30340;&#36817;&#20284;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#65292;&#36880;&#28176;&#20943;&#23569;&#24314;&#27169;&#35823;&#24046;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#22312;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#65292;&#26377;&#21161;&#20110;&#26377;&#25928;&#35299;&#20915;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;&#20013;&#30340;&#35745;&#31639;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;(BIPs)&#20013;&#30340;&#22522;&#26412;&#35745;&#31639;&#38382;&#39064;&#28304;&#20110;&#38656;&#35201;&#37325;&#22797;&#36827;&#34892;&#27491;&#21521;&#27169;&#22411;&#35780;&#20272;&#30340;&#35201;&#27714;&#12290;&#20943;&#23569;&#36825;&#31181;&#25104;&#26412;&#30340;&#19968;&#31181;&#24120;&#35265;&#31574;&#30053;&#26159;&#36890;&#36807;&#25805;&#20316;&#21592;&#23398;&#20064;&#20351;&#29992;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#36817;&#20284;&#26041;&#27861;&#26367;&#20195;&#26114;&#36149;&#30340;&#27169;&#22411;&#27169;&#25311;&#65292;&#36825;&#21463;&#21040;&#20102;&#28145;&#24230;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#30340;&#21551;&#21457;&#12290;&#28982;&#32780;&#65292;&#30452;&#25509;&#20351;&#29992;&#36817;&#20284;&#27169;&#22411;&#21487;&#33021;&#24341;&#20837;&#24314;&#27169;&#35823;&#24046;&#65292;&#21152;&#21095;&#20102;&#36870;&#38382;&#39064;&#24050;&#32463;&#23384;&#22312;&#30340;&#30149;&#24577;&#24615;&#12290;&#22240;&#27492;&#65292;&#22312;&#26377;&#25928;&#23454;&#26045;&#36825;&#20123;&#26041;&#27861;&#20013;&#65292;&#24179;&#34913;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#33258;&#36866;&#24212;&#25805;&#20316;&#21592;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#20197;&#36890;&#36807;&#24378;&#21046;&#22312;&#23616;&#37096;&#21306;&#22495;&#20013;&#20934;&#30830;&#25311;&#21512;&#30340;&#20195;&#29702;&#36880;&#28176;&#20943;&#23569;&#24314;&#27169;&#35823;&#24046;&#12290;&#36825;&#26159;&#36890;&#36807;&#20351;&#29992;&#36138;&#23146;&#31639;&#27861;&#36873;&#25321;&#30340;&#33258;&#36866;&#24212;&#28857;&#22312;&#21453;&#28436;&#36807;&#31243;&#20013;&#23545;&#39044;&#35757;&#32451;&#30340;&#36817;&#20284;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#26469;&#23454;&#29616;&#30340;&#65292;&#35813;&#31639;&#27861;&#21482;&#38656;&#35201;&#23569;&#37327;&#30340;&#27491;&#21521;&#27169;&#22411;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
The fundamental computational issues in Bayesian inverse problems (BIPs) governed by partial differential equations (PDEs) stem from the requirement of repeated forward model evaluations. A popular strategy to reduce such cost is to replace expensive model simulations by computationally efficient approximations using operator learning, motivated by recent progresses in deep learning. However, using the approximated model directly may introduce a modeling error, exacerbating the already ill-posedness of inverse problems. Thus, balancing between accuracy and efficiency is essential for the effective implementation of such approaches. To this end, we develop an adaptive operator learning framework that can reduce modeling error gradually by forcing the surrogate to be accurate in local areas. This is accomplished by fine-tuning the pre-trained approximate model during the inversion process with adaptive points selected by a greedy algorithm, which requires only a few forward model evaluat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#36125;&#21494;&#26031;EM&#31639;&#27861;&#65292;&#29992;&#20110;&#20174;&#20108;&#20803;&#21644;&#26377;&#24207;&#39033;&#30446;&#21709;&#24212;&#20013;&#20272;&#35745;&#31232;&#30095;&#22240;&#23376;&#36733;&#33655;&#65292;&#24182;&#36890;&#36807;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#35299;&#20915;&#20102;&#26410;&#30693;&#28508;&#22312;&#22240;&#23376;&#32500;&#24230;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.17820</link><description>&lt;p&gt;
&#31232;&#30095;&#36125;&#21494;&#26031;&#22810;&#32500;&#39033;&#30446;&#21453;&#24212;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Sparse Bayesian Multidimensional Item Response Theory. (arXiv:2310.17820v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17820
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#36125;&#21494;&#26031;EM&#31639;&#27861;&#65292;&#29992;&#20110;&#20174;&#20108;&#20803;&#21644;&#26377;&#24207;&#39033;&#30446;&#21709;&#24212;&#20013;&#20272;&#35745;&#31232;&#30095;&#22240;&#23376;&#36733;&#33655;&#65292;&#24182;&#36890;&#36807;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#35299;&#20915;&#20102;&#26410;&#30693;&#28508;&#22312;&#22240;&#23376;&#32500;&#24230;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#21464;&#37327;&#39033;&#30446;&#21453;&#24212;&#29702;&#35770;&#65288;MIRT&#65289;&#34987;&#24212;&#29992;&#30740;&#31350;&#20154;&#21592;&#24191;&#27867;&#20351;&#29992;&#65292;&#20197;&#23547;&#25214;&#38382;&#21367;&#25968;&#25454;&#20013;&#21709;&#24212;&#27169;&#24335;&#32972;&#21518;&#30340;&#21487;&#35299;&#37322;&#65288;&#31232;&#30095;&#65289;&#35299;&#37322;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#23545;&#20110;&#36825;&#31181;&#31232;&#30095;&#24615;&#21457;&#29616;&#24037;&#20855;&#30340;&#38656;&#27714;&#23578;&#26410;&#24471;&#21040;&#28385;&#36275;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20108;&#20803;&#21644;&#26377;&#24207;&#39033;&#30446;MIRT&#30340;&#36125;&#21494;&#26031;&#24179;&#21488;&#65292;&#20854;&#38656;&#35201;&#26368;&#23569;&#30340;&#35843;&#25972;&#65292;&#24182;&#19988;&#30001;&#20110;&#20854;&#21487;&#24182;&#34892;&#21270;&#30340;&#29305;&#24615;&#65292;&#22312;&#30456;&#23545;&#36739;&#22823;&#30340;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#33391;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;MIRT&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#20256;&#32479;&#19978;&#20381;&#36182;&#20110;MCMC&#27169;&#25311;&#65292;&#22312;&#23454;&#36341;&#20013;&#21487;&#33021;&#26082;&#36153;&#26102;&#21448;&#38590;&#20197;&#36890;&#36807;&#39069;&#22806;&#30340;&#38408;&#20540;&#35774;&#23450;&#23454;&#29616;&#31934;&#30830;&#30340;&#31232;&#30095;&#24674;&#22797;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#36125;&#21494;&#26031;EM&#31639;&#27861;&#65292;&#29992;&#20110;&#20174;&#20108;&#20803;&#21644;&#26377;&#24207;&#39033;&#30446;&#21709;&#24212;&#20013;&#20272;&#35745;&#31232;&#30095;&#22240;&#23376;&#36733;&#33655;&#12290;&#25105;&#20204;&#21033;&#29992;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#35299;&#20915;&#20102;&#26410;&#30693;&#28508;&#22312;&#22240;&#23376;&#32500;&#24230;&#30340;&#30475;&#20284;&#19981;&#21487;&#36926;&#36234;&#30340;&#38382;&#39064;&#65292;&#20174;&#32780;&#20351;&#24471;&#21487;&#20197;&#20272;&#35745;&#22240;&#23376;&#30340;&#25968;&#37327;&#12290;&#36890;&#36807;&#26059;&#36716;&#21487;&#20197;&#23454;&#29616;&#31232;&#30095;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multivariate Item Response Theory (MIRT) is sought-after widely by applied researchers looking for interpretable (sparse) explanations underlying response patterns in questionnaire data. There is, however, an unmet demand for such sparsity discovery tools in practice. Our paper develops a Bayesian platform for binary and ordinal item MIRT which requires minimal tuning and scales well on relatively large datasets due to its parallelizable features. Bayesian methodology for MIRT models has traditionally relied on MCMC simulation, which cannot only be slow in practice, but also often renders exact sparsity recovery impossible without additional thresholding. In this work, we develop a scalable Bayesian EM algorithm to estimate sparse factor loadings from binary and ordinal item responses. We address the seemingly insurmountable problem of unknown latent factor dimensionality with tools from Bayesian nonparametrics which enable estimating the number of factors. Rotations to sparsity throug
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#28145;&#24230;&#29983;&#25104;&#20808;&#39564;&#65292;SA-Roundtrip&#65292;&#21487;&#20197;&#36827;&#34892;&#21487;&#25511;&#30340;&#37319;&#26679;&#29983;&#25104;&#65292;&#24182;&#35782;&#21035;&#25968;&#25454;&#30340;&#20869;&#22312;&#32500;&#24230;&#12290;&#22522;&#20110;&#35813;&#20808;&#39564;&#65292;&#32467;&#21512;Hamiltonian Monte Carlo&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#36125;&#21494;&#26031;&#25104;&#20687;&#36870;&#38382;&#39064;&#65292;&#22312;&#35745;&#31639;&#26426;&#26029;&#23618;&#25195;&#25551;&#37325;&#24314;&#20219;&#21153;&#19978;&#36229;&#36807;&#20102;&#26368;&#20808;&#36827;&#30340;&#23545;&#27604;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.17817</link><description>&lt;p&gt;
Bayesian&#25104;&#20687;&#36870;&#38382;&#39064;&#20013;&#30340;SA-Roundtrip&#20808;&#39564;&#21450;HMC-pCN&#37319;&#26679;&#22120;
&lt;/p&gt;
&lt;p&gt;
Bayesian imaging inverse problem with SA-Roundtrip prior via HMC-pCN sampler. (arXiv:2310.17817v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17817
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#28145;&#24230;&#29983;&#25104;&#20808;&#39564;&#65292;SA-Roundtrip&#65292;&#21487;&#20197;&#36827;&#34892;&#21487;&#25511;&#30340;&#37319;&#26679;&#29983;&#25104;&#65292;&#24182;&#35782;&#21035;&#25968;&#25454;&#30340;&#20869;&#22312;&#32500;&#24230;&#12290;&#22522;&#20110;&#35813;&#20808;&#39564;&#65292;&#32467;&#21512;Hamiltonian Monte Carlo&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#36125;&#21494;&#26031;&#25104;&#20687;&#36870;&#38382;&#39064;&#65292;&#22312;&#35745;&#31639;&#26426;&#26029;&#23618;&#25195;&#25551;&#37325;&#24314;&#20219;&#21153;&#19978;&#36229;&#36807;&#20102;&#26368;&#20808;&#36827;&#30340;&#23545;&#27604;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#25512;&#26029;&#19982;&#28145;&#24230;&#29983;&#25104;&#20808;&#39564;&#22312;&#35768;&#22810;&#31185;&#23398;&#21644;&#24037;&#31243;&#39046;&#22495;&#30340;&#25104;&#20687;&#36870;&#38382;&#39064;&#27714;&#35299;&#20013;&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#20808;&#39564;&#20998;&#24067;&#30340;&#36873;&#25321;&#26159;&#20174;&#21487;&#29992;&#20808;&#39564;&#27979;&#37327;&#20013;&#23398;&#20064;&#30340;&#65292;&#22240;&#27492;&#26159;&#20851;&#20110;&#21487;&#29992;&#20808;&#39564;&#27979;&#37327;&#30340;&#37325;&#35201;&#34920;&#31034;&#23398;&#20064;&#12290;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#29983;&#25104;&#20808;&#39564;SA-Roundtrip&#65292;&#20197;&#23454;&#29616;&#21487;&#25511;&#30340;&#37319;&#26679;&#29983;&#25104;&#65292;&#24182;&#35782;&#21035;&#20986;&#25968;&#25454;&#30340;&#20869;&#22312;&#32500;&#24230;&#12290;&#35813;&#20808;&#39564;&#22312;&#21452;&#21521;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#20013;&#23884;&#20837;&#20102;&#33258;&#27880;&#24847;&#21147;&#32467;&#26500;&#12290;&#38543;&#21518;&#65292;&#23558;&#36125;&#21494;&#26031;&#25512;&#26029;&#24212;&#29992;&#20110;&#20302;&#32500;&#28508;&#22312;&#31354;&#38388;&#20013;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#20351;&#29992;&#20855;&#26377;&#39044;&#26465;&#20214;Crank-Nicolson&#31639;&#27861;&#30340;Hamiltonian Monte Carlo (HMC-pCN)&#12290;&#35813;&#31639;&#27861;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#34987;&#35777;&#26126;&#20855;&#26377;&#36941;&#21382;&#24615;&#12290;&#23545;MNIST&#21644;TomoPhantom&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#35745;&#31639;&#26426;&#26029;&#23618;&#25195;&#25551;&#37325;&#24314;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#23545;&#27604;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian inference with deep generative prior has received considerable interest for solving imaging inverse problems in many scientific and engineering fields. The selection of the prior distribution is learned from, and therefore an important representation learning of, available prior measurements. The SA-Roundtrip, a novel deep generative prior, is introduced to enable controlled sampling generation and identify the data's intrinsic dimension. This prior incorporates a self-attention structure within a bidirectional generative adversarial network. Subsequently, Bayesian inference is applied to the posterior distribution in the low-dimensional latent space using the Hamiltonian Monte Carlo with preconditioned Crank-Nicolson (HMC-pCN) algorithm, which is proven to be ergodic under specific conditions. Experiments conducted on computed tomography (CT) reconstruction with the MNIST and TomoPhantom datasets reveal that the proposed method outperforms state-of-the-art comparisons, consis
&lt;/p&gt;</description></item><item><title>&#22312;&#26377;&#38480;&#20808;&#39564;&#30693;&#35782;&#19979;&#65292;&#36890;&#36807;&#23616;&#37096;&#20998;&#21306;&#21457;&#29616;&#31639;&#27861;&#65288;LDP&#65289;&#65292;&#35813;&#30740;&#31350;&#35299;&#20915;&#20102;&#33258;&#21160;&#21464;&#37327;&#36873;&#25321;&#30340;&#38382;&#39064;&#12290;LDP&#26681;&#25454;&#19982;&#26333;&#20809;-&#32467;&#26524;&#23545;{X,Y}&#30456;&#20851;&#30340;&#23376;&#38598;&#23558;&#21464;&#37327;&#38598;&#21512;Z&#36827;&#34892;&#20998;&#21306;&#65292;&#24182;&#21306;&#20998;&#28151;&#28102;&#22240;&#32032;&#21644;&#20854;&#20182;&#21464;&#37327;&#31867;&#22411;&#12290;&#35813;&#31639;&#27861;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#22312;&#23454;&#36341;&#20013;&#35266;&#23519;&#21040;&#27425;&#20108;&#27425;&#30340;&#36816;&#34892;&#26102;&#38388;&#12290;</title><link>http://arxiv.org/abs/2310.17816</link><description>&lt;p&gt;
Local Discovery by Partitioning: &#22312;&#26377;&#38480;&#20808;&#39564;&#30693;&#35782;&#19979;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Local Discovery by Partitioning: Polynomial-Time Causal Discovery Around Exposure-Outcome Pairs. (arXiv:2310.17816v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17816
&lt;/p&gt;
&lt;p&gt;
&#22312;&#26377;&#38480;&#20808;&#39564;&#30693;&#35782;&#19979;&#65292;&#36890;&#36807;&#23616;&#37096;&#20998;&#21306;&#21457;&#29616;&#31639;&#27861;&#65288;LDP&#65289;&#65292;&#35813;&#30740;&#31350;&#35299;&#20915;&#20102;&#33258;&#21160;&#21464;&#37327;&#36873;&#25321;&#30340;&#38382;&#39064;&#12290;LDP&#26681;&#25454;&#19982;&#26333;&#20809;-&#32467;&#26524;&#23545;{X,Y}&#30456;&#20851;&#30340;&#23376;&#38598;&#23558;&#21464;&#37327;&#38598;&#21512;Z&#36827;&#34892;&#20998;&#21306;&#65292;&#24182;&#21306;&#20998;&#28151;&#28102;&#22240;&#32032;&#21644;&#20854;&#20182;&#21464;&#37327;&#31867;&#22411;&#12290;&#35813;&#31639;&#27861;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#22312;&#23454;&#36341;&#20013;&#35266;&#23519;&#21040;&#27425;&#20108;&#27425;&#30340;&#36816;&#34892;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#35299;&#20915;&#20102;&#22312;&#26377;&#38480;&#20808;&#39564;&#30693;&#35782;&#19979;&#33258;&#21160;&#21464;&#37327;&#36873;&#25321;&#30340;&#38382;&#39064;&#12290;&#32473;&#23450;&#19968;&#20010;{X,Y}&#30340;&#26333;&#20809;-&#32467;&#26524;&#23545;&#21644;&#19968;&#20010;&#26410;&#30693;&#22240;&#26524;&#32467;&#26500;&#30340;&#21464;&#37327;&#38598;&#21512;Z&#65292;&#23616;&#37096;&#20998;&#21306;&#21457;&#29616;&#65288;LDP&#65289;&#31639;&#27861;&#23558;Z&#21010;&#20998;&#25104;&#19982;{X,Y}&#30456;&#20851;&#30340;&#23376;&#38598;&#12290;&#25105;&#20204;&#21015;&#20030;&#20102;&#20219;&#24847;Z&#30340;8&#20010;&#31351;&#20030;&#19988;&#20114;&#19981;&#37325;&#22797;&#30340;&#20998;&#21306;&#65292;&#24182;&#21033;&#29992;&#36825;&#20010;&#20998;&#31867;&#27861;&#21306;&#20998;&#28151;&#28102;&#22240;&#32032;&#21644;&#20854;&#20182;&#21464;&#37327;&#31867;&#22411;&#12290;LDP&#30340;&#21160;&#26426;&#26159;&#26377;&#25928;&#30340;&#35843;&#25972;&#38598;&#35782;&#21035;&#65292;&#20294;&#36991;&#20813;&#20102;&#33258;&#21160;&#21464;&#37327;&#36873;&#25321;&#26041;&#27861;&#20013;&#24120;&#35265;&#30340;&#39044;&#22788;&#29702;&#20551;&#35774;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#65292;LDP&#23545;&#20110;&#28385;&#36275;&#36275;&#22815;&#22270;&#24418;&#26465;&#20214;&#30340;&#20219;&#20309;Z&#37117;&#36820;&#22238;&#19968;&#20010;&#26377;&#25928;&#30340;&#35843;&#25972;&#38598;&#12290;&#22312;&#26356;&#24378;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20998;&#21306;&#26631;&#31614;&#30340;&#28176;&#36817;&#27491;&#30830;&#24615;&#12290;&#24635;&#29420;&#31435;&#24615;&#27979;&#35797;&#22312;|Z|&#30340;&#26368;&#22351;&#24773;&#20917;&#19979;&#26159;&#20108;&#27425;&#30340;&#65292;&#32463;&#39564;&#19978;&#35266;&#23519;&#21040;&#27425;&#20108;&#27425;&#30340;&#36816;&#34892;&#26102;&#38388;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#23545;&#29702;&#35770;&#20445;&#35777;&#36827;&#34892;&#20102;&#25968;&#20540;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work addresses the problem of automated covariate selection under limited prior knowledge. Given an exposure-outcome pair {X,Y} and a variable set Z of unknown causal structure, the Local Discovery by Partitioning (LDP) algorithm partitions Z into subsets defined by their relation to {X,Y}. We enumerate eight exhaustive and mutually exclusive partitions of any arbitrary Z and leverage this taxonomy to differentiate confounders from other variable types. LDP is motivated by valid adjustment set identification, but avoids the pretreatment assumption commonly made by automated covariate selection methods. We provide theoretical guarantees that LDP returns a valid adjustment set for any Z that meets sufficient graphical conditions. Under stronger conditions, we prove that partition labels are asymptotically correct. Total independence tests is worst-case quadratic in |Z|, with sub-quadratic runtimes observed empirically. We numerically validate our theoretical guarantees on synthetic 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#23545;&#20998;&#24067;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#26368;&#20248;&#20998;&#31867;&#26641;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#28151;&#21512;&#25972;&#25968;&#40065;&#26834;&#20248;&#21270;&#25216;&#26415;&#23558;&#35813;&#38382;&#39064;&#36716;&#21270;&#20026;&#21333;&#38454;&#27573;&#28151;&#21512;&#25972;&#25968;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20102;&#22522;&#20110;&#32422;&#26463;&#29983;&#25104;&#30340;&#35299;&#20915;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2310.17772</link><description>&lt;p&gt;
&#23398;&#20064;&#23545;&#20998;&#24067;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#26368;&#20248;&#20998;&#31867;&#26641;
&lt;/p&gt;
&lt;p&gt;
Learning Optimal Classification Trees Robust to Distribution Shifts. (arXiv:2310.17772v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17772
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#23545;&#20998;&#24067;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#26368;&#20248;&#20998;&#31867;&#26641;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#28151;&#21512;&#25972;&#25968;&#40065;&#26834;&#20248;&#21270;&#25216;&#26415;&#23558;&#35813;&#38382;&#39064;&#36716;&#21270;&#20026;&#21333;&#38454;&#27573;&#28151;&#21512;&#25972;&#25968;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20102;&#22522;&#20110;&#32422;&#26463;&#29983;&#25104;&#30340;&#35299;&#20915;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#23398;&#20064;&#23545;&#35757;&#32451;&#21644;&#27979;&#35797;/&#37096;&#32626;&#25968;&#25454;&#20043;&#38388;&#30340;&#20998;&#24067;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#20998;&#31867;&#26641;&#30340;&#38382;&#39064;&#12290;&#36825;&#20010;&#38382;&#39064;&#32463;&#24120;&#22312;&#39640;&#39118;&#38505;&#29615;&#22659;&#20013;&#20986;&#29616;&#65292;&#20363;&#22914;&#20844;&#20849;&#21355;&#29983;&#21644;&#31038;&#20250;&#24037;&#20316;&#65292;&#20854;&#20013;&#25968;&#25454;&#36890;&#24120;&#26159;&#36890;&#36807;&#33258;&#25105;&#25253;&#21578;&#30340;&#35843;&#26597;&#25910;&#38598;&#30340;&#65292;&#36825;&#20123;&#35843;&#26597;&#23545;&#38382;&#39064;&#30340;&#34920;&#36848;&#26041;&#24335;&#12289;&#35843;&#26597;&#36827;&#34892;&#30340;&#26102;&#38388;&#21644;&#22320;&#28857;&#12289;&#20197;&#21450;&#21463;&#35775;&#32773;&#19982;&#35843;&#26597;&#21592;&#20998;&#20139;&#20449;&#24687;&#30340;&#33298;&#36866;&#31243;&#24230;&#38750;&#24120;&#25935;&#24863;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28151;&#21512;&#25972;&#25968;&#40065;&#26834;&#20248;&#21270;&#25216;&#26415;&#30340;&#23398;&#20064;&#26368;&#20248;&#40065;&#26834;&#20998;&#31867;&#26641;&#30340;&#26041;&#27861;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#23398;&#20064;&#26368;&#20248;&#40065;&#26834;&#26641;&#30340;&#38382;&#39064;&#21487;&#20197;&#31561;&#20215;&#22320;&#34920;&#36798;&#20026;&#19968;&#20010;&#20855;&#26377;&#39640;&#24230;&#38750;&#32447;&#24615;&#21644;&#19981;&#36830;&#32493;&#30446;&#26631;&#30340;&#21333;&#38454;&#27573;&#28151;&#21512;&#25972;&#25968;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#38382;&#39064;&#31561;&#20215;&#22320;&#37325;&#26032;&#34920;&#36848;&#20026;&#19968;&#20010;&#20004;&#38454;&#27573;&#32447;&#24615;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#20026;&#27492;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#22522;&#20110;&#32422;&#26463;&#29983;&#25104;&#30340;&#23450;&#21046;&#35299;&#20915;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning classification trees that are robust to distribution shifts between training and testing/deployment data. This problem arises frequently in high stakes settings such as public health and social work where data is often collected using self-reported surveys which are highly sensitive to e.g., the framing of the questions, the time when and place where the survey is conducted, and the level of comfort the interviewee has in sharing information with the interviewer. We propose a method for learning optimal robust classification trees based on mixed-integer robust optimization technology. In particular, we demonstrate that the problem of learning an optimal robust tree can be cast as a single-stage mixed-integer robust optimization problem with a highly nonlinear and discontinuous objective. We reformulate this problem equivalently as a two-stage linear robust optimization problem for which we devise a tailored solution procedure based on constraint gene
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#20984;&#20248;&#21270;&#20013;&#31639;&#27861;&#30340;&#21487;&#37325;&#29616;&#24615;&#21644;&#26799;&#24230;&#22797;&#26434;&#24230;&#38382;&#39064;&#12290;&#20182;&#20204;&#25361;&#25112;&#20102;&#20043;&#21069;&#30340;&#35266;&#28857;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#24179;&#28369;&#20984;&#20248;&#21270;&#21644;&#24179;&#28369;&#20984;&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#21487;&#20197;&#23454;&#29616;&#26368;&#20248;&#30340;&#21487;&#37325;&#29616;&#24615;&#21644;&#25509;&#36817;&#26368;&#20248;&#30340;&#25910;&#25947;&#20445;&#35777;&#12290;&#20182;&#20204;&#36824;&#35777;&#26126;&#20102;&#22312;&#19981;&#21516;&#30340;oracle&#35774;&#32622;&#19979;&#65292;&#19982;&#19981;&#21516;&#31867;&#22411;&#30340;oracle&#30456;&#21305;&#37197;&#30340;&#31639;&#27861;&#36798;&#21040;&#20102;&#26368;&#20248;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.17759</link><description>&lt;p&gt;
&#22312;&#20984;&#20248;&#21270;&#20013;&#30340;&#31639;&#27861;&#21487;&#37325;&#29616;&#24615;&#21644;&#26799;&#24230;&#22797;&#26434;&#24230;&#30340;&#26368;&#20248;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Optimal Guarantees for Algorithmic Reproducibility and Gradient Complexity in Convex Optimization. (arXiv:2310.17759v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17759
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#20984;&#20248;&#21270;&#20013;&#31639;&#27861;&#30340;&#21487;&#37325;&#29616;&#24615;&#21644;&#26799;&#24230;&#22797;&#26434;&#24230;&#38382;&#39064;&#12290;&#20182;&#20204;&#25361;&#25112;&#20102;&#20043;&#21069;&#30340;&#35266;&#28857;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#24179;&#28369;&#20984;&#20248;&#21270;&#21644;&#24179;&#28369;&#20984;&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#21487;&#20197;&#23454;&#29616;&#26368;&#20248;&#30340;&#21487;&#37325;&#29616;&#24615;&#21644;&#25509;&#36817;&#26368;&#20248;&#30340;&#25910;&#25947;&#20445;&#35777;&#12290;&#20182;&#20204;&#36824;&#35777;&#26126;&#20102;&#22312;&#19981;&#21516;&#30340;oracle&#35774;&#32622;&#19979;&#65292;&#19982;&#19981;&#21516;&#31867;&#22411;&#30340;oracle&#30456;&#21305;&#37197;&#30340;&#31639;&#27861;&#36798;&#21040;&#20102;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31639;&#27861;&#21487;&#37325;&#29616;&#24615;&#34913;&#37327;&#20102;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#31245;&#24494;&#25913;&#21464;&#26102;&#36755;&#20986;&#30340;&#20559;&#24046;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#19968;&#38454;&#26041;&#27861;&#38656;&#35201;&#22312;&#25910;&#25947;&#36895;&#24230;&#65288;&#26799;&#24230;&#22797;&#26434;&#24230;&#65289;&#21644;&#26356;&#22909;&#30340;&#21487;&#37325;&#29616;&#24615;&#20043;&#38388;&#20570;&#20986;&#26435;&#34913;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25361;&#25112;&#20102;&#36825;&#31181;&#30475;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#21508;&#31181;&#23481;&#26131;&#20986;&#38169;&#30340;oracle&#35774;&#32622;&#19979;&#65292;&#23545;&#20110;&#24179;&#28369;&#20984;&#20248;&#21270;&#21644;&#24179;&#28369;&#20984;&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#21487;&#20197;&#23454;&#29616;&#26368;&#20248;&#30340;&#21487;&#37325;&#29616;&#24615;&#21644;&#25509;&#36817;&#26368;&#20248;&#30340;&#25910;&#25947;&#20445;&#35777;&#12290;&#23588;&#20854;&#26159;&#65292;&#22312;&#19981;&#31934;&#30830;&#30340;&#21021;&#22987;&#21270;oracle&#32473;&#23450;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#22522;&#20110;&#27491;&#21017;&#21270;&#30340;&#31639;&#27861;&#23454;&#29616;&#20102;&#26368;&#20248;&#30340;&#21487;&#37325;&#29616;&#24615;&#21644;&#25509;&#36817;&#26368;&#20248;&#30340;&#26799;&#24230;&#22797;&#26434;&#24230;-&#23545;&#20110;&#26368;&#23567;&#21270;&#21644;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#12290;&#23545;&#20110;&#19981;&#31934;&#30830;&#30340;&#26799;&#24230;oracle&#65292;&#25509;&#36817;&#26368;&#20248;&#30340;&#20445;&#35777;&#20063;&#36866;&#29992;&#20110;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#38543;&#26426;&#26799;&#24230;oracle&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#19978;&#21319;&#22312;&#21487;&#37325;&#29616;&#24615;&#21644;&#25910;&#25947;&#36895;&#24230;&#26041;&#38754;&#37117;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithmic reproducibility measures the deviation in outputs of machine learning algorithms upon minor changes in the training process. Previous work suggests that first-order methods would need to trade-off convergence rate (gradient complexity) for better reproducibility. In this work, we challenge this perception and demonstrate that both optimal reproducibility and near-optimal convergence guarantees can be achieved for smooth convex minimization and smooth convex-concave minimax problems under various error-prone oracle settings. Particularly, given the inexact initialization oracle, our regularization-based algorithms achieve the best of both worlds optimal reproducibility and near-optimal gradient complexity - for minimization and minimax optimization. With the inexact gradient oracle, the near-optimal guarantees also hold for minimax optimization. Additionally, with the stochastic gradient oracle, we show that stochastic gradient descent ascent is optimal in terms of both re
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#30340;&#35270;&#35282;&#65292;&#23558;&#32479;&#35745;&#21644;&#21442;&#25968;&#21270;&#23398;&#20064;&#33539;&#20363;&#30456;&#32467;&#21512;&#65292;&#25506;&#32034;&#20102;&#20174;&#35780;&#20272;oracle&#20013;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#26080;&#26465;&#20214;&#30340;&#19979;&#30028;&#21644;&#26597;&#35810;&#22797;&#26434;&#24230;&#21051;&#30011;&#12290;&#35813;&#26694;&#26550;&#36866;&#29992;&#20110;QSQ&#35774;&#32622;&#21644;&#22522;&#20110;&#25439;&#22833;&#20989;&#25968;&#20248;&#21270;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.17716</link><description>&lt;p&gt;
&#32479;&#19968;&#65288;&#37327;&#23376;&#65289;&#32479;&#35745;&#21644;&#21442;&#25968;&#21270;&#65288;&#37327;&#23376;&#65289;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Unifying (Quantum) Statistical and Parametrized (Quantum) Algorithms. (arXiv:2310.17716v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17716
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#30340;&#35270;&#35282;&#65292;&#23558;&#32479;&#35745;&#21644;&#21442;&#25968;&#21270;&#23398;&#20064;&#33539;&#20363;&#30456;&#32467;&#21512;&#65292;&#25506;&#32034;&#20102;&#20174;&#35780;&#20272;oracle&#20013;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#26080;&#26465;&#20214;&#30340;&#19979;&#30028;&#21644;&#26597;&#35810;&#22797;&#26434;&#24230;&#21051;&#30011;&#12290;&#35813;&#26694;&#26550;&#36866;&#29992;&#20110;QSQ&#35774;&#32622;&#21644;&#22522;&#20110;&#25439;&#22833;&#20989;&#25968;&#20248;&#21270;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Kearns&#30340;&#32479;&#35745;&#26597;&#35810;&#65288;SQ&#65289;oracle&#65288;STOC'93&#65289;&#20026;&#22823;&#22810;&#25968;&#32463;&#20856;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#35270;&#35282;&#12290;&#28982;&#32780;&#22312;&#37327;&#23376;&#23398;&#20064;&#20013;&#36825;&#19968;&#28857;&#19981;&#20877;&#25104;&#31435;&#65292;&#22240;&#20026;&#35768;&#22810;&#35774;&#32622;&#26082;&#27809;&#26377;SQ&#30340;&#31867;&#27604;&#65292;&#20063;&#27809;&#26377;&#37327;&#23376;&#32479;&#35745;&#26597;&#35810;&#65288;QSQ&#65289;&#30340;&#31867;&#27604;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20511;&#37492;&#20102;Kearns&#30340;SQ oracle&#21644;Valiant&#30340;&#24369;&#35780;&#20272;oracle&#65288;TOCT'14&#65289;&#65292;&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#24335;&#24314;&#31435;&#20102;&#32479;&#35745;&#21644;&#21442;&#25968;&#21270;&#23398;&#20064;&#33539;&#20363;&#20043;&#38388;&#30340;&#32479;&#19968;&#35270;&#35282;&#12290;&#25105;&#20204;&#25506;&#32034;&#20102;&#20174;&#35780;&#20272;oracle&#20013;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#35813;oracle&#25552;&#20379;&#20102;&#20989;&#25968;&#20540;&#30340;&#20272;&#35745;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#24191;&#27867;&#32780;&#30452;&#35266;&#30340;&#26694;&#26550;&#65292;&#20026;&#20174;&#35780;&#20272;&#26597;&#35810;&#20013;&#23398;&#20064;&#25552;&#20379;&#20102;&#26080;&#26465;&#20214;&#30340;&#19979;&#30028;&#65292;&#24182;&#19988;&#23545;&#20110;&#23398;&#20064;&#32447;&#24615;&#20989;&#25968;&#31867;&#30340;&#26597;&#35810;&#22797;&#26434;&#24230;&#36827;&#34892;&#20102;&#21051;&#30011;&#12290;&#35813;&#26694;&#26550;&#30452;&#25509;&#36866;&#29992;&#20110;QSQ&#35774;&#32622;&#20197;&#21450;&#25152;&#26377;&#22522;&#20110;&#25439;&#22833;&#20989;&#25968;&#20248;&#21270;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#31532;&#19968;&#20010;&#24212;&#29992;&#26159;&#25193;&#23637;&#20808;&#21069;&#20851;&#20110;&#36755;&#20986;&#21487;&#23398;&#24615;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kearns' statistical query (SQ) oracle (STOC'93) lends a unifying perspective for most classical machine learning algorithms. This ceases to be true in quantum learning, where many settings do not admit, neither an SQ analog nor a quantum statistical query (QSQ) analog. In this work, we take inspiration from Kearns' SQ oracle and Valiant's weak evaluation oracle (TOCT'14) and establish a unified perspective bridging the statistical and parametrized learning paradigms in a novel way. We explore the problem of learning from an evaluation oracle, which provides an estimate of function values, and introduce an extensive yet intuitive framework that yields unconditional lower bounds for learning from evaluation queries and characterizes the query complexity for learning linear function classes. The framework is directly applicable to the QSQ setting and virtually all algorithms based on loss function optimization.  Our first application is to extend prior results on the learnability of outpu
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20998;&#26512;Node2Vec&#23398;&#20064;&#21040;&#30340;&#23884;&#20837;&#30340;&#29702;&#35770;&#23646;&#24615;&#65292;&#35777;&#26126;&#20102;&#22312;&#65288;&#32463;&#36807;&#24230;&#20462;&#27491;&#30340;&#65289;&#38543;&#26426;&#22359;&#27169;&#22411;&#20013;&#65292;&#20351;&#29992;k-means&#32858;&#31867;&#26041;&#27861;&#23545;&#36825;&#20123;&#23884;&#20837;&#36827;&#34892;&#31038;&#21306;&#24674;&#22797;&#26159;&#24369;&#19968;&#33268;&#30340;&#12290;&#23454;&#39564;&#35777;&#26126;&#36825;&#19968;&#32467;&#26524;&#65292;&#24182;&#25506;&#35752;&#20102;&#23884;&#20837;&#22312;&#33410;&#28857;&#21644;&#38142;&#25509;&#39044;&#27979;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2310.17712</link><description>&lt;p&gt;
&#20351;&#29992;Node2Vec&#23398;&#20064;&#21040;&#30340;&#23884;&#20837;&#36827;&#34892;&#31038;&#21306;&#26816;&#27979;&#21644;&#20998;&#31867;&#30340;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Community Detection and Classification Guarantees Using Embeddings Learned by Node2Vec. (arXiv:2310.17712v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17712
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20998;&#26512;Node2Vec&#23398;&#20064;&#21040;&#30340;&#23884;&#20837;&#30340;&#29702;&#35770;&#23646;&#24615;&#65292;&#35777;&#26126;&#20102;&#22312;&#65288;&#32463;&#36807;&#24230;&#20462;&#27491;&#30340;&#65289;&#38543;&#26426;&#22359;&#27169;&#22411;&#20013;&#65292;&#20351;&#29992;k-means&#32858;&#31867;&#26041;&#27861;&#23545;&#36825;&#20123;&#23884;&#20837;&#36827;&#34892;&#31038;&#21306;&#24674;&#22797;&#26159;&#24369;&#19968;&#33268;&#30340;&#12290;&#23454;&#39564;&#35777;&#26126;&#36825;&#19968;&#32467;&#26524;&#65292;&#24182;&#25506;&#35752;&#20102;&#23884;&#20837;&#22312;&#33410;&#28857;&#21644;&#38142;&#25509;&#39044;&#27979;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#22823;&#22411;&#32593;&#32476;&#30340;&#33410;&#28857;&#23884;&#20837;&#21040;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#26159;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24120;&#35265;&#30446;&#26631;&#65292;&#26377;&#21508;&#31181;&#24037;&#20855;&#21487;&#29992;&#12290;&#36825;&#20123;&#23884;&#20837;&#21487;&#20197;&#29992;&#20316;&#31038;&#21306;&#26816;&#27979;/&#33410;&#28857;&#32858;&#31867;&#25110;&#38142;&#25509;&#39044;&#27979;&#31561;&#20219;&#21153;&#30340;&#29305;&#24449;&#65292;&#20854;&#24615;&#33021;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#27700;&#24179;&#12290;&#38500;&#20102;&#35889;&#32858;&#31867;&#26041;&#27861;&#20043;&#22806;&#65292;&#23545;&#20110;&#20854;&#20182;&#24120;&#29992;&#30340;&#23398;&#20064;&#23884;&#20837;&#26041;&#27861;&#65292;&#32570;&#20047;&#29702;&#35770;&#19978;&#30340;&#29702;&#35299;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#23519;&#20102;&#30001;node2vec&#23398;&#20064;&#21040;&#30340;&#23884;&#20837;&#30340;&#29702;&#35770;&#23646;&#24615;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#34920;&#26126;&#65292;&#23545;node2vec&#29983;&#25104;&#30340;&#23884;&#20837;&#21521;&#37327;&#24212;&#29992;k-means&#32858;&#31867;&#21487;&#20197;&#23545;&#65288;&#32463;&#36807;&#24230;&#20462;&#27491;&#30340;&#65289;&#38543;&#26426;&#22359;&#27169;&#22411;&#20013;&#30340;&#33410;&#28857;&#36827;&#34892;&#24369;&#19968;&#33268;&#30340;&#31038;&#21306;&#24674;&#22797;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#36825;&#20123;&#23884;&#20837;&#22312;&#33410;&#28857;&#21644;&#38142;&#25509;&#39044;&#27979;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20010;&#32467;&#26524;&#65292;&#24182;&#30740;&#31350;&#20102;&#23427;&#19982;&#32593;&#32476;&#25968;&#25454;&#30340;&#20854;&#20182;&#23884;&#20837;&#24037;&#20855;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Embedding the nodes of a large network into an Euclidean space is a common objective in modern machine learning, with a variety of tools available. These embeddings can then be used as features for tasks such as community detection/node clustering or link prediction, where they achieve state of the art performance. With the exception of spectral clustering methods, there is little theoretical understanding for other commonly used approaches to learning embeddings. In this work we examine the theoretical properties of the embeddings learned by node2vec. Our main result shows that the use of k-means clustering on the embedding vectors produced by node2vec gives weakly consistent community recovery for the nodes in (degree corrected) stochastic block models. We also discuss the use of these embeddings for node and link prediction tasks. We demonstrate this result empirically, and examine how this relates to other embedding tools for network data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#20302;&#31209;&#36866;&#24212;&#65288;LoRA&#65289;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#65292;&#24403;LoRA-rank&#8805;&#65288;f&#30340;&#23485;&#24230;&#65289;&#215;&#65288;&#30446;&#26631;&#27169;&#22411;&#30340;&#28145;&#24230;/ f&#30340;&#28145;&#24230;&#65289;&#26102;&#65292;LoRA&#21487;&#20197;&#20351;&#20219;&#20309;&#27169;&#22411;f&#20934;&#30830;&#34920;&#31034;&#20219;&#20309;&#36739;&#23567;&#30340;&#30446;&#26631;&#27169;&#22411;f&#12290;&#23545;&#20110;Transformer&#32593;&#32476;&#65292;&#36890;&#36807;rank-&#65288;&#23884;&#20837;&#22823;&#23567;/ 2&#65289;&#30340;LoRA&#36866;&#37197;&#22120;&#21487;&#20197;&#20351;&#20219;&#20309;&#27169;&#22411;&#36866;&#24212;&#20110;&#30456;&#21516;&#22823;&#23567;&#30340;&#30446;&#26631;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2310.17513</link><description>&lt;p&gt;
&#12298;&#20302;&#31209;&#36866;&#24212;&#30340;&#34920;&#36798;&#33021;&#21147;&#12299;
&lt;/p&gt;
&lt;p&gt;
The Expressive Power of Low-Rank Adaptation. (arXiv:2310.17513v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17513
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#20302;&#31209;&#36866;&#24212;&#65288;LoRA&#65289;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#65292;&#24403;LoRA-rank&#8805;&#65288;f&#30340;&#23485;&#24230;&#65289;&#215;&#65288;&#30446;&#26631;&#27169;&#22411;&#30340;&#28145;&#24230;/ f&#30340;&#28145;&#24230;&#65289;&#26102;&#65292;LoRA&#21487;&#20197;&#20351;&#20219;&#20309;&#27169;&#22411;f&#20934;&#30830;&#34920;&#31034;&#20219;&#20309;&#36739;&#23567;&#30340;&#30446;&#26631;&#27169;&#22411;f&#12290;&#23545;&#20110;Transformer&#32593;&#32476;&#65292;&#36890;&#36807;rank-&#65288;&#23884;&#20837;&#22823;&#23567;/ 2&#65289;&#30340;LoRA&#36866;&#37197;&#22120;&#21487;&#20197;&#20351;&#20219;&#20309;&#27169;&#22411;&#36866;&#24212;&#20110;&#30456;&#21516;&#22823;&#23567;&#30340;&#30446;&#26631;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#31209;&#36866;&#24212;&#65288;LoRA&#65289;&#26159;&#19968;&#31181;&#21442;&#25968;&#39640;&#25928;&#30340;&#24494;&#35843;&#26041;&#27861;&#65292;&#21033;&#29992;&#30697;&#38453;&#30340;&#20302;&#31209;&#36866;&#24212;&#24615;&#65292;&#22312;&#24494;&#35843;&#39044;&#35757;&#32451;&#27169;&#22411;&#65288;&#22914;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#25193;&#25955;&#27169;&#22411;&#65289;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#24212;&#29992;&#12290;&#23613;&#31649;&#22312;&#23454;&#36341;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#65292;&#20294;&#26159;LoRA&#30340;&#29702;&#35770;&#22522;&#30784;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#23578;&#26410;&#24471;&#21040;&#25506;&#32034;&#12290;&#26412;&#25991;&#36890;&#36807;&#20174;&#29702;&#35770;&#35282;&#24230;&#20998;&#26512;LoRA&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#39318;&#27425;&#23581;&#35797;&#24357;&#21512;&#36825;&#19968;&#24046;&#36317;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#65292;&#22914;&#26524;LoRA-rank&#8805;&#65288;f&#30340;&#23485;&#24230;&#65289;&#215;&#65288;&#30446;&#26631;&#27169;&#22411;&#30340;&#28145;&#24230;/ f&#30340;&#28145;&#24230;&#65289;&#65292;&#21017;LoRA&#21487;&#20197;&#20351;&#20219;&#20309;&#27169;&#22411;f&#20934;&#30830;&#34920;&#31034;&#20219;&#20309;&#36739;&#23567;&#30340;&#30446;&#26631;&#27169;&#22411;f&#12290;&#24403;LoRA-rank&#20302;&#20110;&#38408;&#20540;&#26102;&#65292;&#25105;&#20204;&#36824;&#37327;&#21270;&#20102;&#36924;&#36817;&#35823;&#24046;&#12290;&#23545;&#20110;Transformer&#32593;&#32476;&#65292;&#25105;&#20204;&#35777;&#26126;&#20219;&#20309;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;rank-&#65288;&#23884;&#20837;&#22823;&#23567;/ 2&#65289;&#30340;LoRA&#36866;&#37197;&#22120;&#36866;&#24212;&#20110;&#30456;&#21516;&#22823;&#23567;&#30340;&#30446;&#26631;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Low-Rank Adaptation (LoRA), a parameter-efficient fine-tuning method that leverages low-rank adaptation of weight matrices, has emerged as a prevalent technique for fine-tuning pre-trained models such as large language models and diffusion models. Despite its huge success in practice, the theoretical underpinnings of LoRA have largely remained unexplored. This paper takes the first step to bridge this gap by theoretically analyzing the expressive power of LoRA. We prove that, for fully connected neural networks, LoRA can adapt any model $f$ to accurately represent any smaller target model $\overline{f}$ if LoRA-rank $\geq(\text{width of }f) \times \frac{\text{depth of }\overline{f}}{\text{depth of }f}$. We also quantify the approximation error when LoRA-rank is lower than the threshold. For Transformer networks, we show any model can be adapted to a target model of the same size with rank-$(\frac{\text{embedding size}}{2})$ LoRA adapters.
&lt;/p&gt;</description></item><item><title>&#21327;&#20316;&#21644;&#21487;&#35299;&#37322;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26694;&#26550;(CoExBO)&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#24341;&#20837;&#20102;&#24490;&#29615;&#65292;&#24179;&#34913;&#20102;&#20154;&#24037;&#26234;&#33021;&#21644;&#20154;&#31867;&#30340;&#21512;&#20316;&#20851;&#31995;&#12290;&#23427;&#21033;&#29992;&#20559;&#22909;&#23398;&#20064;&#23558;&#29992;&#25143;&#35265;&#35299;&#34701;&#21512;&#21040;&#20248;&#21270;&#20013;&#65292;&#35299;&#37322;&#27599;&#27425;&#36845;&#20195;&#30340;&#20505;&#36873;&#36873;&#25321;&#65292;&#20174;&#32780;&#22686;&#24378;&#29992;&#25143;&#23545;&#20248;&#21270;&#36807;&#31243;&#30340;&#20449;&#20219;&#65292;&#24182;&#25552;&#20379;&#26080;&#23475;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2310.17273</link><description>&lt;p&gt;
&#23558;&#24490;&#29615;&#24341;&#20837;&#20154;&#31867;&#65306;&#21327;&#20316;&#21644;&#21487;&#35299;&#37322;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Looping in the Human: Collaborative and Explainable Bayesian Optimization. (arXiv:2310.17273v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17273
&lt;/p&gt;
&lt;p&gt;
&#21327;&#20316;&#21644;&#21487;&#35299;&#37322;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26694;&#26550;(CoExBO)&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#24341;&#20837;&#20102;&#24490;&#29615;&#65292;&#24179;&#34913;&#20102;&#20154;&#24037;&#26234;&#33021;&#21644;&#20154;&#31867;&#30340;&#21512;&#20316;&#20851;&#31995;&#12290;&#23427;&#21033;&#29992;&#20559;&#22909;&#23398;&#20064;&#23558;&#29992;&#25143;&#35265;&#35299;&#34701;&#21512;&#21040;&#20248;&#21270;&#20013;&#65292;&#35299;&#37322;&#27599;&#27425;&#36845;&#20195;&#30340;&#20505;&#36873;&#36873;&#25321;&#65292;&#20174;&#32780;&#22686;&#24378;&#29992;&#25143;&#23545;&#20248;&#21270;&#36807;&#31243;&#30340;&#20449;&#20219;&#65292;&#24182;&#25552;&#20379;&#26080;&#23475;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20687;&#35768;&#22810;&#20248;&#21270;&#22120;&#19968;&#26679;&#65292;&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#33719;&#24471;&#29992;&#25143;&#20449;&#20219;&#26041;&#38754;&#24120;&#24120;&#23384;&#22312;&#19981;&#36275;&#65292;&#22240;&#20026;&#20854;&#19981;&#36879;&#26126;&#24615;&#12290;&#34429;&#28982;&#24050;&#32463;&#23581;&#35797;&#24320;&#21457;&#38754;&#21521;&#20154;&#31867;&#30340;&#20248;&#21270;&#22120;&#65292;&#20294;&#23427;&#20204;&#36890;&#24120;&#20551;&#35774;&#29992;&#25143;&#30693;&#35782;&#26159;&#26126;&#30830;&#19988;&#26080;&#35823;&#30340;&#65292;&#24182;&#20027;&#35201;&#23558;&#29992;&#25143;&#20316;&#20026;&#20248;&#21270;&#36807;&#31243;&#30340;&#30417;&#30563;&#32773;&#12290;&#25105;&#20204;&#25918;&#23485;&#20102;&#36825;&#20123;&#20551;&#35774;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#24179;&#34913;&#30340;&#20154;&#24037;&#26234;&#33021;&#21644;&#20154;&#31867;&#21512;&#20316;&#20249;&#20276;&#20851;&#31995;&#65292;&#21363;&#25105;&#20204;&#30340;&#21327;&#20316;&#21644;&#21487;&#35299;&#37322;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;CoExBO&#65289;&#26694;&#26550;&#12290;CoExBO&#20351;&#29992;&#20559;&#22909;&#23398;&#20064;&#26469;&#26080;&#32541;&#22320;&#23558;&#20154;&#31867;&#35265;&#35299;&#25972;&#21512;&#21040;&#20248;&#21270;&#20013;&#65292;&#20174;&#32780;&#20135;&#29983;&#19982;&#29992;&#25143;&#20351;&#29992;&#20559;&#22909;&#19968;&#33268;&#30340;&#31639;&#27861;&#24314;&#35758;&#12290;CoExBO&#35299;&#37322;&#20854;&#27599;&#27425;&#36845;&#20195;&#30340;&#20505;&#36873;&#36873;&#25321;&#65292;&#20197;&#22521;&#20859;&#20449;&#20219;&#65292;&#20351;&#29992;&#25143;&#26356;&#28165;&#26970;&#22320;&#25484;&#25569;&#20248;&#21270;&#30340;&#36807;&#31243;&#12290;&#27492;&#22806;&#65292;CoExBO&#25552;&#20379;&#26080;&#23475;&#20445;&#35777;&#65292;&#20801;&#35768;&#29992;&#25143;&#29359;&#38169;&#35823;&#65307;&#21363;&#20351;&#22312;&#26497;&#31471;&#23545;&#25239;&#24615;&#24178;&#25200;&#19979;&#65292;&#31639;&#27861;&#20063;&#20250;&#28176;&#36827;&#22320;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;
Like many optimizers, Bayesian optimization often falls short of gaining user trust due to opacity. While attempts have been made to develop human-centric optimizers, they typically assume user knowledge is well-specified and error-free, employing users mainly as supervisors of the optimization process. We relax these assumptions and propose a more balanced human-AI partnership with our Collaborative and Explainable Bayesian Optimization (CoExBO) framework. Instead of explicitly requiring a user to provide a knowledge model, CoExBO employs preference learning to seamlessly integrate human insights into the optimization, resulting in algorithmic suggestions that resonate with user preference. CoExBO explains its candidate selection every iteration to foster trust, empowering users with a clearer grasp of the optimization. Furthermore, CoExBO offers a no-harm guarantee, allowing users to make mistakes; even with extreme adversarial interventions, the algorithm converges asymptotically to
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#23610;&#24230;&#25193;&#25955;&#21435;&#22122;&#24179;&#28369;&#30340;&#20934;&#30830;&#24230;&#21644;&#35748;&#35777;&#40065;&#26834;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#20849;&#20139;&#25193;&#25955;&#27169;&#22411;&#19978;&#35843;&#25972;&#20197;&#23454;&#29616;&#24179;&#28369;&#20998;&#31867;&#22120;&#40065;&#26834;&#24615;&#30340;&#26032;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.16779</link><description>&lt;p&gt;
&#22810;&#23610;&#24230;&#25193;&#25955;&#21435;&#22122;&#24179;&#28369;
&lt;/p&gt;
&lt;p&gt;
Multi-scale Diffusion Denoised Smoothing. (arXiv:2310.16779v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16779
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#23610;&#24230;&#25193;&#25955;&#21435;&#22122;&#24179;&#28369;&#30340;&#20934;&#30830;&#24230;&#21644;&#35748;&#35777;&#40065;&#26834;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#20849;&#20139;&#25193;&#25955;&#27169;&#22411;&#19978;&#35843;&#25972;&#20197;&#23454;&#29616;&#24179;&#28369;&#20998;&#31867;&#22120;&#40065;&#26834;&#24615;&#30340;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#26368;&#36817;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#38543;&#26426;&#24179;&#28369;&#24050;&#25104;&#20026;&#23569;&#25968;&#20960;&#20010;&#20999;&#23454;&#21487;&#34892;&#30340;&#26041;&#27861;&#20043;&#19968;&#65292;&#20026;&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#27169;&#22411;&#25552;&#20379;&#23545;&#25239;&#40065;&#26834;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#21487;&#20197;&#36890;&#36807;&#31616;&#21333;&#30340;&#8220;&#21435;&#22122;&#21644;&#20998;&#31867;&#8221;&#27969;&#31243;&#65292;&#21363;&#25152;&#35859;&#30340;&#21435;&#22122;&#24179;&#28369;&#65292;&#22312;&#20219;&#20309;&#20998;&#31867;&#22120;&#19978;&#25191;&#34892;&#38543;&#26426;&#24179;&#28369;&#65292;&#21069;&#25552;&#26159;&#26377;&#19968;&#20010;&#20934;&#30830;&#30340;&#21435;&#22122;&#22120;&#21487;&#29992;&#65292;&#27604;&#22914;&#25193;&#25955;&#27169;&#22411;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#21435;&#22122;&#24179;&#28369;&#30340;&#20934;&#30830;&#24230;&#21644;&#35748;&#35777;&#40065;&#26834;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65306;&#20363;&#22914;&#65292;&#25105;&#20204;&#36136;&#30097;&#21738;&#31181;&#25193;&#25955;&#27169;&#22411;&#30340;&#34920;&#31034;&#24418;&#24335;&#33021;&#22815;&#26368;&#22823;&#21270;&#21435;&#22122;&#24179;&#28369;&#30340;&#35748;&#35777;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#26032;&#30340;&#30446;&#26631;&#65292;&#26088;&#22312;&#23454;&#29616;&#20849;&#21516;&#22122;&#22768;&#27700;&#24179;&#19979;&#24179;&#28369;&#20998;&#31867;&#22120;&#30340;&#40065;&#26834;&#24615;&#65292;&#22312;&#20849;&#20139;&#25193;&#25955;&#27169;&#22411;&#19978;&#36827;&#34892;&#31934;&#32454;&#35843;&#25972;&#65292;&#21516;&#26102;&#20063;&#20026;&#20854;&#35748;&#35777;&#40065;&#26834;&#24615;&#34917;&#20607;&#20934;&#30830;&#24230;&#30340;&#25104;&#26412;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;
Along with recent diffusion models, randomized smoothing has become one of a few tangible approaches that offers adversarial robustness to models at scale, e.g., those of large pre-trained models. Specifically, one can perform randomized smoothing on any classifier via a simple "denoise-and-classify" pipeline, so-called denoised smoothing, given that an accurate denoiser is available - such as diffusion model. In this paper, we investigate the trade-off between accuracy and certified robustness of denoised smoothing: for example, we question on which representation of diffusion model would maximize the certified robustness of denoised smoothing. We consider a new objective that aims collective robustness of smoothed classifiers across multiple noise levels at a shared diffusion model, which also suggests a new way to compensate the cost of accuracy in randomized smoothing for its certified robustness. This objective motivates us to fine-tune diffusion model (a) to perform consistent de
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26679;&#26412;&#36873;&#25321;&#20559;&#24046;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#21033;&#29992;&#38598;&#25104;&#22810;&#26679;&#24615;&#36827;&#34892;&#40065;&#26834;&#30340;&#33258;&#35757;&#32451;&#30340;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#20449;&#24230;&#24230;&#37327;&#26041;&#27861;-$\mathcal{T}$-&#30456;&#20284;&#24230;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#19977;&#31181;&#19981;&#21516;&#20266;&#26631;&#31614;&#31574;&#30053;&#19979;&#20855;&#26377;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.14814</link><description>&lt;p&gt;
&#22312;&#26679;&#26412;&#36873;&#25321;&#20559;&#24046;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#21033;&#29992;&#38598;&#25104;&#22810;&#26679;&#24615;&#36827;&#34892;&#40065;&#26834;&#30340;&#33258;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Leveraging Ensemble Diversity for Robust Self-Training in the Presence of Sample Selection Bias. (arXiv:2310.14814v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14814
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26679;&#26412;&#36873;&#25321;&#20559;&#24046;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#21033;&#29992;&#38598;&#25104;&#22810;&#26679;&#24615;&#36827;&#34892;&#40065;&#26834;&#30340;&#33258;&#35757;&#32451;&#30340;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#20449;&#24230;&#24230;&#37327;&#26041;&#27861;-$\mathcal{T}$-&#30456;&#20284;&#24230;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#19977;&#31181;&#19981;&#21516;&#20266;&#26631;&#31614;&#31574;&#30053;&#19979;&#20855;&#26377;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#35757;&#32451;&#26159;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#19968;&#31181;&#20247;&#25152;&#21608;&#30693;&#30340;&#26041;&#27861;&#12290;&#23427;&#21253;&#25324;&#23545;&#27169;&#22411;&#33258;&#20449;&#24230;&#39640;&#30340;&#26410;&#26631;&#35760;&#25968;&#25454;&#36827;&#34892;&#20266;&#26631;&#31614;&#20998;&#37197;&#65292;&#24182;&#23558;&#20854;&#35270;&#20026;&#26631;&#35760;&#26679;&#26412;&#36827;&#34892;&#22788;&#29702;&#12290;&#23545;&#20110;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#24120;&#20351;&#29992;softmax&#39044;&#27979;&#27010;&#29575;&#20316;&#20026;&#33258;&#20449;&#24230;&#24230;&#37327;&#65292;&#23613;&#31649;&#24050;&#30693;&#23427;&#20204;&#23545;&#38169;&#35823;&#39044;&#27979;&#20063;&#36807;&#20110;&#33258;&#20449;&#12290;&#24403;&#25968;&#25454;&#26631;&#27880;&#21463;&#21040;&#26576;&#31181;&#32422;&#26463;&#26102;&#65292;&#36825;&#31181;&#29616;&#35937;&#23588;&#20026;&#26126;&#26174;&#65292;&#21363;&#26679;&#26412;&#36873;&#25321;&#20559;&#24046;&#23384;&#22312;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#20449;&#24230;&#24230;&#37327;&#26041;&#27861;&#65292;&#31216;&#20026;$\mathcal{T}$-&#30456;&#20284;&#24230;&#65292;&#23427;&#22522;&#20110;&#32447;&#24615;&#20998;&#31867;&#22120;&#30340;&#38598;&#25104;&#39044;&#27979;&#22810;&#26679;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#30740;&#31350;&#31283;&#23450;&#28857;&#24182;&#25551;&#36848;&#21333;&#20010;&#25104;&#21592;&#30340;&#22810;&#26679;&#24615;&#19982;&#20854;&#24615;&#33021;&#20043;&#38388;&#30340;&#20851;&#31995;&#26469;&#25552;&#20379;&#25105;&#20204;&#26041;&#27861;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#19977;&#31181;&#19981;&#21516;&#20266;&#26631;&#31614;&#31574;&#30053;&#30340;&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#33258;&#20449;&#24230;&#24230;&#37327;&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-training is a well-known approach for semi-supervised learning. It consists of iteratively assigning pseudo-labels to unlabeled data for which the model is confident and treating them as labeled examples. For neural networks, softmax prediction probabilities are often used as a confidence measure, despite the fact that they are known to be overconfident, even for wrong predictions. This phenomenon is particularly intensified in the presence of sample selection bias, i.e., when data labeling is subject to some constraint. To address this issue, we propose a novel confidence measure, called $\mathcal{T}$-similarity, built upon the prediction diversity of an ensemble of linear classifiers. We provide the theoretical analysis of our approach by studying stationary points and describing the relationship between the diversity of the individual members and their performance. We empirically demonstrate the benefit of our confidence measure for three different pseudo-labeling policies on c
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19978;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#21253;&#25324;&#25512;&#23548;&#20102;&#25928;&#26524;&#21644;&#25104;&#21151;&#29575;&#30340;&#32479;&#35745;&#37327;&#65292;&#24182;&#25552;&#20379;&#20102;&#20960;&#31181;&#24773;&#20917;&#19979;&#30340;&#30028;&#38480;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#26681;&#25454;&#26679;&#26412;&#25968;&#37327;&#21644;&#20854;&#20182;&#32467;&#26500;&#21442;&#25968;&#25512;&#26029;&#28508;&#22312;&#25915;&#20987;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.13786</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#30340;&#22522;&#26412;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
Fundamental Limits of Membership Inference Attacks on Machine Learning Models. (arXiv:2310.13786v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13786
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19978;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#21253;&#25324;&#25512;&#23548;&#20102;&#25928;&#26524;&#21644;&#25104;&#21151;&#29575;&#30340;&#32479;&#35745;&#37327;&#65292;&#24182;&#25552;&#20379;&#20102;&#20960;&#31181;&#24773;&#20917;&#19979;&#30340;&#30028;&#38480;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#26681;&#25454;&#26679;&#26412;&#25968;&#37327;&#21644;&#20854;&#20182;&#32467;&#26500;&#21442;&#25968;&#25512;&#26029;&#28508;&#22312;&#25915;&#20987;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#65288;MIA&#65289;&#21487;&#20197;&#25581;&#31034;&#29305;&#23450;&#25968;&#25454;&#28857;&#26159;&#21542;&#26159;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#19968;&#37096;&#20998;&#65292;&#21487;&#33021;&#26292;&#38706;&#20010;&#20154;&#30340;&#25935;&#24863;&#20449;&#24687;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#20851;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19978;MIA&#30340;&#22522;&#26412;&#32479;&#35745;&#38480;&#21046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#25512;&#23548;&#20102;&#32479;&#35745;&#37327;&#65292;&#35813;&#32479;&#35745;&#37327;&#20915;&#23450;&#20102;&#36825;&#31181;&#25915;&#20987;&#30340;&#26377;&#25928;&#24615;&#21644;&#25104;&#21151;&#29575;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20960;&#31181;&#24773;&#20917;&#65292;&#24182;&#23545;&#36825;&#20010;&#24863;&#20852;&#36259;&#30340;&#32479;&#35745;&#37327;&#25552;&#20379;&#20102;&#30028;&#38480;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#26681;&#25454;&#26679;&#26412;&#25968;&#37327;&#21644;&#23398;&#20064;&#27169;&#22411;&#30340;&#20854;&#20182;&#32467;&#26500;&#21442;&#25968;&#25512;&#26029;&#28508;&#22312;&#25915;&#20987;&#30340;&#20934;&#30830;&#24615;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#21487;&#20197;&#30452;&#25509;&#20174;&#25968;&#25454;&#38598;&#20013;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Membership inference attacks (MIA) can reveal whether a particular data point was part of the training dataset, potentially exposing sensitive information about individuals. This article explores the fundamental statistical limitations associated with MIAs on machine learning models. More precisely, we first derive the statistical quantity that governs the effectiveness and success of such attacks. Then, we investigate several situations for which we provide bounds on this quantity of interest. This allows us to infer the accuracy of potential attacks as a function of the number of samples and other structural parameters of learning models, which in some cases can be directly estimated from the dataset.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#35757;&#32451;&#39640;&#36136;&#37327;AI&#21161;&#25163;&#30340;&#25216;&#26415;&#65292;&#21457;&#29616;&#36825;&#31181;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#22312;&#22238;&#31572;&#38382;&#39064;&#26102;&#36807;&#20110;&#35844;&#23194;&#65292;&#32780;&#19981;&#26159;&#22374;&#35802;&#65292;&#36890;&#36807;&#20998;&#26512;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#24471;&#20986;&#20102;&#36825;&#19968;&#32467;&#35770;&#12290;</title><link>http://arxiv.org/abs/2310.13548</link><description>&lt;p&gt;
&#25506;&#32034;&#35821;&#35328;&#27169;&#22411;&#20013;&#35844;&#23194;&#34892;&#20026;&#30340;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Towards Understanding Sycophancy in Language Models. (arXiv:2310.13548v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13548
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#35757;&#32451;&#39640;&#36136;&#37327;AI&#21161;&#25163;&#30340;&#25216;&#26415;&#65292;&#21457;&#29616;&#36825;&#31181;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#22312;&#22238;&#31572;&#38382;&#39064;&#26102;&#36807;&#20110;&#35844;&#23194;&#65292;&#32780;&#19981;&#26159;&#22374;&#35802;&#65292;&#36890;&#36807;&#20998;&#26512;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#24471;&#20986;&#20102;&#36825;&#19968;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#12300;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#36827;&#34892;&#24378;&#21270;&#23398;&#20064;&#65288;RLHF&#65289;&#12301;&#26159;&#35757;&#32451;&#39640;&#36136;&#37327;AI&#21161;&#25163;&#30340;&#19968;&#31181;&#27969;&#34892;&#25216;&#26415;&#12290;&#28982;&#32780;&#65292;RLHF&#21487;&#33021;&#20250;&#40723;&#21169;&#27169;&#22411;&#36890;&#36807;&#19982;&#29992;&#25143;&#20449;&#24565;&#30456;&#31526;&#30340;&#22238;&#31572;&#26469;&#20195;&#26367;&#30495;&#23454;&#22238;&#31572;&#65292;&#36825;&#31181;&#34892;&#20026;&#34987;&#31216;&#20026;&#35844;&#23194;&#34892;&#20026;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;RLHF&#35757;&#32451;&#27169;&#22411;&#20013;&#35844;&#23194;&#34892;&#20026;&#30340;&#26222;&#36941;&#24615;&#20197;&#21450;&#20154;&#31867;&#20559;&#22909;&#21028;&#26029;&#26159;&#21542;&#36215;&#21040;&#20102;&#20316;&#29992;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20116;&#20010;&#26368;&#20808;&#36827;&#30340;AI&#21161;&#25163;&#22312;&#22235;&#20010;&#19981;&#21516;&#30340;&#33258;&#30001;&#25991;&#26412;&#29983;&#25104;&#20219;&#21153;&#20013;&#19968;&#36143;&#34920;&#29616;&#20986;&#35844;&#23194;&#34892;&#20026;&#12290;&#20026;&#20102;&#29702;&#35299;&#20154;&#31867;&#20559;&#22909;&#26159;&#21542;&#39537;&#21160;&#20102;RLHF&#27169;&#22411;&#30340;&#36825;&#31181;&#24191;&#27867;&#34892;&#20026;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#29616;&#26377;&#30340;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#24403;&#22238;&#31572;&#19982;&#29992;&#25143;&#30340;&#35266;&#28857;&#30456;&#31526;&#26102;&#65292;&#23427;&#26356;&#26377;&#21487;&#33021;&#34987;&#36873;&#20013;&#12290;&#27492;&#22806;&#65292;&#20154;&#31867;&#21644;&#20559;&#22909;&#27169;&#22411;&#65288;PMs&#65289;&#23558;&#26377;&#35828;&#26381;&#21147;&#30340;&#35844;&#23194;&#22238;&#31572;&#19982;&#27491;&#30830;&#22238;&#31572;&#30456;&#27604;&#65292;&#26377;&#26102;&#20960;&#20046;&#21487;&#20197;&#24573;&#30053;&#19981;&#35745;&#22320;&#36873;&#25321;&#20102;&#35844;&#23194;&#22238;&#31572;&#12290;&#20248;&#21270;&#27169;&#22411;&#36755;&#20986;&#20197;&#28385;&#36275;PMs&#26377;&#26102;&#20063;&#20250;&#22312;&#30495;&#23454;&#24615;&#21644;&#35844;&#23194;&#34892;&#20026;&#20043;&#38388;&#20570;&#20986;&#21462;&#33293;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning from human feedback (RLHF) is a popular technique for training high-quality AI assistants. However, RLHF may also encourage model responses that match user beliefs over truthful responses, a behavior known as sycophancy. We investigate the prevalence of sycophancy in RLHF-trained models and whether human preference judgements are responsible. We first demonstrate that five state-of-the-art AI assistants consistently exhibit sycophantic behavior across four varied free-form text-generation tasks. To understand if human preferences drive this broadly observed behavior of RLHF models, we analyze existing human preference data. We find that when a response matches a user's views, it is more likely to be preferred. Moreover, both humans and preference models (PMs) prefer convincingly-written sycophantic responses over correct ones a negligible fraction of the time. Optimizing model outputs against PMs also sometimes sacrifices truthfulness in favor of sycophancy. Over
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#36125;&#21494;&#26031;&#27169;&#22411;&#32553;&#20943;&#20316;&#20026;&#19968;&#31181;&#26356;&#39640;&#25928;&#30340;&#26367;&#20195;&#26041;&#27861;&#26469;&#20462;&#21098;&#27169;&#22411;&#26435;&#37325;&#65292;&#20197;&#25552;&#39640;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2309.12095</link><description>&lt;p&gt;
&#20855;&#26377;&#36125;&#21494;&#26031;&#27169;&#22411;&#32553;&#20943;&#30340;&#36125;&#21494;&#26031;&#31232;&#30095;&#24615;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Bayesian sparsification for deep neural networks with Bayesian model reduction. (arXiv:2309.12095v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12095
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#36125;&#21494;&#26031;&#27169;&#22411;&#32553;&#20943;&#20316;&#20026;&#19968;&#31181;&#26356;&#39640;&#25928;&#30340;&#26367;&#20195;&#26041;&#27861;&#26469;&#20462;&#21098;&#27169;&#22411;&#26435;&#37325;&#65292;&#20197;&#25552;&#39640;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#24040;&#22823;&#33021;&#21147;&#24120;&#24120;&#21463;&#21040;&#20854;&#27169;&#22411;&#22797;&#26434;&#24615;&#30340;&#38480;&#21046;&#65292;&#22240;&#27492;&#23545;&#20110;&#26377;&#25928;&#30340;&#31232;&#30095;&#25216;&#26415;&#30340;&#38656;&#27714;&#19981;&#26029;&#22686;&#21152;&#12290;&#36125;&#21494;&#26031;&#31232;&#30095;&#24615;&#23545;&#20110;&#28145;&#24230;&#23398;&#20064;&#32780;&#35328;&#26159;&#19968;&#31181;&#20851;&#38190;&#26041;&#27861;&#65292;&#21487;&#20197;&#20419;&#36827;&#22312;&#21508;&#31181;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#20013;&#35774;&#35745;&#26082;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#21448;&#20855;&#26377;&#31454;&#20105;&#24615;&#33021;&#30340;&#27169;&#22411;&#12290;&#30446;&#21069;&#65292;&#36125;&#21494;&#26031;&#31232;&#30095;&#21270;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#26032;&#25216;&#26415;&#26159;&#23558;&#32467;&#26500;&#25910;&#32553;&#20808;&#39564;&#24212;&#29992;&#20110;&#27169;&#22411;&#26435;&#37325;&#65292;&#24182;&#32467;&#21512;&#22522;&#20110;&#40657;&#30418;&#38543;&#26426;&#21464;&#20998;&#25512;&#26029;&#30340;&#36817;&#20284;&#25512;&#26029;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#19982;&#26631;&#20934;&#30340;&#28145;&#24230;&#23398;&#20064;&#28857;&#20272;&#35745;&#30456;&#27604;&#65292;&#23436;&#25972;&#29983;&#25104;&#27169;&#22411;&#30340;&#27169;&#22411;&#21453;&#28436;&#22312;&#35745;&#31639;&#26041;&#38754;&#38750;&#24120;&#32791;&#36153;&#26102;&#38388;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20513;&#20351;&#29992;&#36125;&#21494;&#26031;&#27169;&#22411;&#32553;&#20943;&#65288;BMR&#65289;&#20316;&#20026;&#27169;&#22411;&#26435;&#37325;&#20462;&#21098;&#30340;&#26356;&#39640;&#25928;&#26367;&#20195;&#26041;&#27861;&#12290;&#20316;&#20026;&#20915;&#31574;&#29575;&#30340;&#25512;&#24191;&#65292;BMR&#20801;&#35768;&#23545;&#27169;&#22411;&#26435;&#37325;&#36827;&#34892;&#20107;&#21518;&#28040;&#38500;
&lt;/p&gt;
&lt;p&gt;
Deep learning's immense capabilities are often constrained by the complexity of its models, leading to an increasing demand for effective sparsification techniques. Bayesian sparsification for deep learning emerges as a crucial approach, facilitating the design of models that are both computationally efficient and competitive in terms of performance across various deep learning applications. The state-of-the-art -- in Bayesian sparsification of deep neural networks -- combines structural shrinkage priors on model weights with an approximate inference scheme based on black-box stochastic variational inference. However, model inversion of the full generative model is exceptionally computationally demanding, especially when compared to standard deep learning of point estimates. In this context, we advocate for the use of Bayesian model reduction (BMR) as a more efficient alternative for pruning of model weights. As a generalization of the Savage-Dickey ratio, BMR allows a post-hoc elimina
&lt;/p&gt;</description></item><item><title>beta&#25193;&#25955;&#26159;&#19968;&#31181;&#26032;&#22411;&#29983;&#25104;&#27169;&#22411;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#21435;&#25513;&#30422;&#21644;&#21435;&#22122;&#30340;&#25216;&#26415;&#65292;&#21033;&#29992;&#32553;&#25918;&#21644;&#20559;&#31227;&#30340;beta&#20998;&#24067;&#36827;&#34892;&#20056;&#27861;&#36716;&#25442;&#65292;&#23454;&#29616;&#22312;&#26377;&#30028;&#33539;&#22260;&#20869;&#29983;&#25104;&#25968;&#25454;&#12290;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;KL&#25955;&#24230;&#19978;&#30028;&#36827;&#34892;&#20248;&#21270;&#65292;&#35777;&#26126;&#20102;&#25928;&#26524;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2309.07867</link><description>&lt;p&gt;
Beta Diffusion. (arXiv:2309.07867v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
Beta Diffusion. (arXiv:2309.07867v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07867
&lt;/p&gt;
&lt;p&gt;
beta&#25193;&#25955;&#26159;&#19968;&#31181;&#26032;&#22411;&#29983;&#25104;&#27169;&#22411;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#21435;&#25513;&#30422;&#21644;&#21435;&#22122;&#30340;&#25216;&#26415;&#65292;&#21033;&#29992;&#32553;&#25918;&#21644;&#20559;&#31227;&#30340;beta&#20998;&#24067;&#36827;&#34892;&#20056;&#27861;&#36716;&#25442;&#65292;&#23454;&#29616;&#22312;&#26377;&#30028;&#33539;&#22260;&#20869;&#29983;&#25104;&#25968;&#25454;&#12290;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;KL&#25955;&#24230;&#19978;&#30028;&#36827;&#34892;&#20248;&#21270;&#65292;&#35777;&#26126;&#20102;&#25928;&#26524;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;beta&#25193;&#25955;&#65292;&#19968;&#31181;&#23558;&#21435;&#25513;&#30422;&#21644;&#21435;&#22122;&#38598;&#25104;&#21040;&#19968;&#36215;&#30340;&#26032;&#22411;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#26377;&#30028;&#33539;&#22260;&#20869;&#29983;&#25104;&#25968;&#25454;&#12290;&#20351;&#29992;&#20102;&#32553;&#25918;&#21644;&#20559;&#31227;&#30340;beta&#20998;&#24067;&#65292;beta&#25193;&#25955;&#21033;&#29992;&#20102;&#38543;&#26102;&#38388;&#30340;&#20056;&#27861;&#36716;&#25442;&#26469;&#21019;&#24314;&#27491;&#21521;&#21644;&#21453;&#21521;&#30340;&#25193;&#25955;&#36807;&#31243;&#65292;&#21516;&#26102;&#32500;&#25345;&#30528;&#27491;&#21521;&#36793;&#32536;&#20998;&#24067;&#21644;&#21453;&#21521;&#26465;&#20214;&#20998;&#24067;&#65292;&#32473;&#23450;&#20219;&#24847;&#26102;&#38388;&#28857;&#30340;&#25968;&#25454;&#12290;&#19982;&#20256;&#32479;&#30340;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#19981;&#21516;&#65292;&#20256;&#32479;&#27169;&#22411;&#20381;&#36182;&#20110;&#21152;&#24615;&#39640;&#26031;&#22122;&#22768;&#21644;&#37325;&#26032;&#21152;&#26435;&#30340;&#35777;&#25454;&#19979;&#30028;&#65288;ELBO&#65289;&#65292;beta&#25193;&#25955;&#26159;&#20056;&#27861;&#30340;&#65292;&#24182;&#19988;&#36890;&#36807;&#20174;KL&#25955;&#24230;&#30340;&#20984;&#24615;&#25512;&#23548;&#20986;&#26469;&#30340;KL&#25955;&#24230;&#19978;&#30028;&#65288;KLUB&#65289;&#36827;&#34892;&#20248;&#21270;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;KLUB&#30456;&#23545;&#20110;&#36127;ELBO&#26469;&#35828;&#23545;&#20110;&#20248;&#21270;beta&#25193;&#25955;&#26356;&#21152;&#26377;&#25928;&#65292;&#36127;ELBO&#20063;&#21487;&#20197;&#20316;&#20026;&#30456;&#21516;KL&#25955;&#24230;&#30340;KLUB&#65292;&#21482;&#26159;&#20854;&#20004;&#20010;&#21442;&#25968;&#20132;&#25442;&#20102;&#20301;&#32622;&#12290;beta&#25193;&#25955;&#30340;&#25439;&#22833;&#20989;&#25968;&#20197;Bregman&#25955;&#24230;&#20026;&#25351;&#26631;&#26469;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce beta diffusion, a novel generative modeling method that integrates demasking and denoising to generate data within bounded ranges. Using scaled and shifted beta distributions, beta diffusion utilizes multiplicative transitions over time to create both forward and reverse diffusion processes, maintaining beta distributions in both the forward marginals and the reverse conditionals, given the data at any point in time. Unlike traditional diffusion-based generative models relying on additive Gaussian noise and reweighted evidence lower bounds (ELBOs), beta diffusion is multiplicative and optimized with KL-divergence upper bounds (KLUBs) derived from the convexity of the KL divergence. We demonstrate that the proposed KLUBs are more effective for optimizing beta diffusion compared to negative ELBOs, which can also be derived as the KLUBs of the same KL divergence with its two arguments swapped. The loss function of beta diffusion, expressed in terms of Bregman divergence, furt
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#31070;&#32463;&#28508;&#22312;&#20960;&#20309;&#25628;&#32034;(NLGS)&#30340;&#27010;&#24565;&#65292;&#26088;&#22312;&#36890;&#36807;&#26684;&#32599;&#33707;&#22827;-&#35946;&#26031;&#22810;&#22827;&#36317;&#31163;&#26469;&#33258;&#21160;&#35782;&#21035;&#19979;&#28216;&#20219;&#21153;&#30340;&#26368;&#20339;&#28508;&#22312;&#20960;&#20309;&#32467;&#26500;&#65292;&#20197;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.04810</link><description>&lt;p&gt;
&#31070;&#32463;&#28508;&#22312;&#20960;&#20309;&#25628;&#32034;&#65306;&#36890;&#36807;&#26684;&#32599;&#33707;&#22827;-&#35946;&#26031;&#22810;&#22827;&#20449;&#24687;&#39537;&#21160;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26469;&#36827;&#34892;&#20056;&#31215;&#27969;&#24418;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Neural Latent Geometry Search: Product Manifold Inference via Gromov-Hausdorff-Informed Bayesian Optimization. (arXiv:2309.04810v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04810
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#31070;&#32463;&#28508;&#22312;&#20960;&#20309;&#25628;&#32034;(NLGS)&#30340;&#27010;&#24565;&#65292;&#26088;&#22312;&#36890;&#36807;&#26684;&#32599;&#33707;&#22827;-&#35946;&#26031;&#22810;&#22827;&#36317;&#31163;&#26469;&#33258;&#21160;&#35782;&#21035;&#19979;&#28216;&#20219;&#21153;&#30340;&#26368;&#20339;&#28508;&#22312;&#20960;&#20309;&#32467;&#26500;&#65292;&#20197;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;&#23558;&#28508;&#22312;&#31354;&#38388;&#30340;&#20960;&#20309;&#32467;&#26500;&#19982;&#24213;&#23618;&#25968;&#25454;&#32467;&#26500;&#23545;&#40784;&#65292;&#21487;&#20197;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#30740;&#31350;&#20154;&#21592;&#25552;&#20986;&#20351;&#29992;&#20855;&#26377;&#24658;&#23450;&#26354;&#29575;&#30340;&#21452;&#26354;&#21644;&#29699;&#24418;&#31354;&#38388;&#65292;&#25110;&#32773;&#23427;&#20204;&#30340;&#32452;&#21512;&#65292;&#26469;&#26356;&#22909;&#22320;&#24314;&#27169;&#28508;&#22312;&#31354;&#38388;&#24182;&#22686;&#24378;&#27169;&#22411;&#24615;&#33021;&#65292;&#32780;&#19981;&#20165;&#20165;&#20381;&#36182;&#20110;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23545;&#33258;&#21160;&#35782;&#21035;&#19979;&#28216;&#20219;&#21153;&#30340;&#26368;&#20339;&#28508;&#22312;&#20960;&#20309;&#32467;&#26500;&#38382;&#39064;&#36824;&#27809;&#26377;&#32473;&#20104;&#36275;&#22815;&#20851;&#27880;&#12290;&#25105;&#20204;&#22312;&#25968;&#23398;&#19978;&#23450;&#20041;&#20102;&#36825;&#20010;&#26032;&#39062;&#30340;&#38382;&#39064;&#65292;&#24182;&#23558;&#20854;&#31216;&#20026;&#31070;&#32463;&#28508;&#22312;&#20960;&#20309;&#25628;&#32034;(NLGS)&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#26684;&#32599;&#33707;&#22827;-&#35946;&#26031;&#22810;&#22827;&#36317;&#31163;&#30340;&#20505;&#36873;&#28508;&#22312;&#20960;&#20309;&#32467;&#26500;&#20043;&#38388;&#30340;&#26032;&#27010;&#24565;&#36317;&#31163;&#65292;&#20197;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#12290;&#20026;&#20102;&#35745;&#31639;&#26684;&#32599;&#33707;&#22827;-&#35946;&#26031;&#22810;&#22827;&#36317;&#31163;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26368;&#23567;&#26597;&#35810;&#35780;&#20272;&#25628;&#32034;&#30001;&#24658;&#23450;&#26354;&#29575;&#27169;&#22411;&#31354;&#38388;&#20056;&#31215;&#32452;&#25104;&#30340;&#28508;&#22312;&#20960;&#20309;&#32467;&#26500;&#30340;&#21407;&#21017;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent research indicates that the performance of machine learning models can be improved by aligning the geometry of the latent space with the underlying data structure. Rather than relying solely on Euclidean space, researchers have proposed using hyperbolic and spherical spaces with constant curvature, or combinations thereof, to better model the latent space and enhance model performance. However, little attention has been given to the problem of automatically identifying the optimal latent geometry for the downstream task. We mathematically define this novel formulation and coin it as neural latent geometry search (NLGS). More specifically, we introduce a principled method that searches for a latent geometry composed of a product of constant curvature model spaces with minimal query evaluations. To accomplish this, we propose a novel notion of distance between candidate latent geometries based on the Gromov-Hausdorff distance from metric geometry. In order to compute the Gromov-Ha
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; ROBAI &#30340;&#31639;&#27861;&#65292;&#26088;&#22312;&#24555;&#36895;&#35782;&#21035;&#24182;&#36873;&#25321;&#26368;&#20339;&#33218;&#65292;&#24182;&#22312;&#19968;&#31995;&#21015;&#36830;&#32493;&#22238;&#21512;&#20013;&#26368;&#22823;&#21270;&#22870;&#21169;&#12290;&#35813;&#31639;&#27861;&#22312;&#39044;&#23450;&#20572;&#27490;&#26102;&#38388;&#21644;&#33258;&#36866;&#24212;&#20572;&#27490;&#26102;&#38388;&#35201;&#27714;&#19979;&#22343;&#23454;&#29616;&#20102;&#28176;&#36827;&#26368;&#20248;&#36951;&#25022;&#65292;&#24182;&#19988;&#22312;&#39044;&#23450;&#20572;&#27490;&#26102;&#38388;&#19979;&#20165;&#38656; $\mathcal{O}(\log T)$ &#22238;&#21512;&#21363;&#21487;&#36873;&#25321;&#26368;&#20339;&#33218;&#65292;&#22312;&#33258;&#36866;&#24212;&#20572;&#27490;&#26102;&#38388;&#19979;&#20165;&#38656; $\mathcal{O}(\log^2 T)$ &#22238;&#21512;&#21363;&#21487;&#36873;&#25321;&#26368;&#20339;&#33218;&#12290;</title><link>http://arxiv.org/abs/2309.00591</link><description>&lt;p&gt;
&#24555;&#36895;&#21644;&#36951;&#25022;&#26368;&#23567;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#65306;&#22522;&#26412;&#38480;&#21046;&#21644;&#20302;&#22797;&#26434;&#24230;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Fast and Regret Optimal Best Arm Identification: Fundamental Limits and Low-Complexity Algorithms. (arXiv:2309.00591v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00591
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; ROBAI &#30340;&#31639;&#27861;&#65292;&#26088;&#22312;&#24555;&#36895;&#35782;&#21035;&#24182;&#36873;&#25321;&#26368;&#20339;&#33218;&#65292;&#24182;&#22312;&#19968;&#31995;&#21015;&#36830;&#32493;&#22238;&#21512;&#20013;&#26368;&#22823;&#21270;&#22870;&#21169;&#12290;&#35813;&#31639;&#27861;&#22312;&#39044;&#23450;&#20572;&#27490;&#26102;&#38388;&#21644;&#33258;&#36866;&#24212;&#20572;&#27490;&#26102;&#38388;&#35201;&#27714;&#19979;&#22343;&#23454;&#29616;&#20102;&#28176;&#36827;&#26368;&#20248;&#36951;&#25022;&#65292;&#24182;&#19988;&#22312;&#39044;&#23450;&#20572;&#27490;&#26102;&#38388;&#19979;&#20165;&#38656; $\mathcal{O}(\log T)$ &#22238;&#21512;&#21363;&#21487;&#36873;&#25321;&#26368;&#20339;&#33218;&#65292;&#22312;&#33258;&#36866;&#24212;&#20572;&#27490;&#26102;&#38388;&#19979;&#20165;&#38656; $\mathcal{O}(\log^2 T)$ &#22238;&#21512;&#21363;&#21487;&#36873;&#25321;&#26368;&#20339;&#33218;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20855;&#26377;&#21452;&#37325;&#30446;&#26631;&#30340;&#38543;&#26426;&#22810;&#33218;&#32769;&#34382;&#26426;(MAB)&#38382;&#39064;&#65306;(i) &#24555;&#36895;&#35782;&#21035;&#24182;&#36873;&#25321;&#26368;&#20339;&#33218;&#65292;&#20197;&#21450;(ii) &#22312;&#19968;&#31995;&#21015;T&#20010;&#36830;&#32493;&#22238;&#21512;&#20013;&#26368;&#22823;&#21270;&#22870;&#21169;&#12290;&#23613;&#31649;&#27599;&#20010;&#30446;&#26631;&#37117;&#24050;&#32463;&#24471;&#21040;&#20102;&#29420;&#31435;&#30340;&#28145;&#20837;&#30740;&#31350;&#65292;&#21363;(i)&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#21644;(ii)&#30340;&#36951;&#25022;&#26368;&#23567;&#21270;&#65292;&#20294;&#26159;&#21516;&#26102;&#23454;&#29616;&#36825;&#20004;&#20010;&#30446;&#26631;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#30340;&#38382;&#39064;&#65292;&#23613;&#31649;&#23427;&#22312;&#23454;&#36341;&#20013;&#38750;&#24120;&#37325;&#35201;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#8220;&#36951;&#25022;&#26368;&#23567;&#21270;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#8221;(ROBAI)&#65292;&#26088;&#22312;&#23454;&#29616;&#36825;&#20004;&#20010;&#21452;&#37325;&#30446;&#26631;&#12290;&#20026;&#20102;&#35299;&#20915;&#20855;&#26377;&#39044;&#23450;&#20572;&#27490;&#26102;&#38388;&#21644;&#33258;&#36866;&#24212;&#20572;&#27490;&#26102;&#38388;&#35201;&#27714;&#30340;ROBAI&#65292;&#25105;&#20204;&#20998;&#21035;&#25552;&#20986;&#20102;$\mathsf{EOCP}$&#31639;&#27861;&#21450;&#20854;&#21464;&#20307;&#65292;&#19981;&#20165;&#22312;&#39640;&#26031;&#32769;&#34382;&#26426;&#21644;&#19968;&#33324;&#32769;&#34382;&#26426;&#20013;&#36798;&#21040;&#20102;&#28176;&#36827;&#26368;&#20248;&#36951;&#25022;&#65292;&#32780;&#19988;&#22312;&#39044;&#23450;&#20572;&#27490;&#26102;&#38388;&#19979;&#65292;&#22312;$\mathcal{O}(\log T)$&#22238;&#21512;&#20869;&#36873;&#25321;&#20102;&#26368;&#20339;&#33218;&#65292;&#22312;&#33258;&#36866;&#24212;&#20572;&#27490;&#26102;&#38388;&#19979;&#65292;&#36873;&#25321;&#20102;&#26368;&#20339;&#33218;&#22312;$\mathcal{O}(\log^2 T)$&#22238;&#21512;&#20869;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper considers a stochastic multi-armed bandit (MAB) problem with dual objectives: (i) quick identification and commitment to the optimal arm, and (ii) reward maximization throughout a sequence of $T$ consecutive rounds. Though each objective has been individually well-studied, i.e., best arm identification for (i) and regret minimization for (ii), the simultaneous realization of both objectives remains an open problem, despite its practical importance. This paper introduces \emph{Regret Optimal Best Arm Identification} (ROBAI) which aims to achieve these dual objectives. To solve ROBAI with both pre-determined stopping time and adaptive stopping time requirements, we present the $\mathsf{EOCP}$ algorithm and its variants respectively, which not only achieve asymptotic optimal regret in both Gaussian and general bandits, but also commit to the optimal arm in $\mathcal{O}(\log T)$ rounds with pre-determined stopping time and $\mathcal{O}(\log^2 T)$ rounds with adaptive stopping ti
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#32771;&#34385;&#20102;&#20855;&#26377;&#26410;&#35266;&#27979;&#28151;&#28102;&#22240;&#32032;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#38382;&#39064;&#65292;&#22312;&#32467;&#26524;&#26159;&#30830;&#23450;&#24615;&#29983;&#25104;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21333;&#19968;&#20195;&#29702;&#21464;&#37327;&#30340;&#20869;&#26680;&#26041;&#27861;&#65292;&#36890;&#36807;&#20004;&#38454;&#27573;&#22238;&#24402;&#21644;&#26368;&#22823;&#30697;&#32422;&#26463;&#30340;&#26041;&#27861;&#21487;&#20197;&#19968;&#33268;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#25104;&#21151;&#24674;&#22797;&#20102;&#22240;&#26524;&#25928;&#24212;&#12290;</title><link>http://arxiv.org/abs/2308.04585</link><description>&lt;p&gt;
&#20915;&#23450;&#24615;&#28151;&#28102;&#19979;&#30340;&#20869;&#26680;&#21333;&#19968;&#20195;&#29702;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Kernel Single Proxy Control for Deterministic Confounding. (arXiv:2308.04585v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04585
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#32771;&#34385;&#20102;&#20855;&#26377;&#26410;&#35266;&#27979;&#28151;&#28102;&#22240;&#32032;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#38382;&#39064;&#65292;&#22312;&#32467;&#26524;&#26159;&#30830;&#23450;&#24615;&#29983;&#25104;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21333;&#19968;&#20195;&#29702;&#21464;&#37327;&#30340;&#20869;&#26680;&#26041;&#27861;&#65292;&#36890;&#36807;&#20004;&#38454;&#27573;&#22238;&#24402;&#21644;&#26368;&#22823;&#30697;&#32422;&#26463;&#30340;&#26041;&#27861;&#21487;&#20197;&#19968;&#33268;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#25104;&#21151;&#24674;&#22797;&#20102;&#22240;&#26524;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20855;&#26377;&#26410;&#35266;&#27979;&#28151;&#28102;&#22240;&#32032;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#38382;&#39064;&#65292;&#20854;&#20013;&#25105;&#20204;&#35266;&#27979;&#21040;&#19982;&#28151;&#28102;&#22240;&#32032;&#30456;&#20851;&#30340;&#20195;&#29702;&#21464;&#37327;&#12290;&#23613;&#31649;&#20195;&#29702;&#22240;&#26524;&#23398;&#20064;&#65288;PCL&#65289;&#20351;&#29992;&#20004;&#20010;&#20195;&#29702;&#21464;&#37327;&#26469;&#24674;&#22797;&#30495;&#23454;&#30340;&#22240;&#26524;&#25928;&#24212;&#65292;&#25105;&#20204;&#35777;&#26126;&#22914;&#26524;&#32467;&#26524;&#26159;&#30830;&#23450;&#24615;&#29983;&#25104;&#30340;&#65292;&#21017;&#20351;&#29992;&#21333;&#20010;&#20195;&#29702;&#21464;&#37327;&#23601;&#36275;&#20197;&#36827;&#34892;&#22240;&#26524;&#20272;&#35745;&#65292;&#24182;&#27010;&#25324;&#20102;&#25511;&#21046;&#32467;&#26524;&#26657;&#20934;&#27861;&#65288;COCA&#65289;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#20869;&#26680;&#30340;&#26041;&#27861;&#65306;&#19968;&#31181;&#22522;&#20110;&#20004;&#38454;&#27573;&#22238;&#24402;&#26041;&#27861;&#65292;&#21478;&#19968;&#31181;&#22522;&#20110;&#26368;&#22823;&#30697;&#32422;&#26463;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#21487;&#20197;&#19968;&#33268;&#22320;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#36890;&#36807;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#23454;&#35777;&#23454;&#39564;&#25104;&#21151;&#22320;&#24674;&#22797;&#20102;&#22240;&#26524;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of causal effect estimation with an unobserved confounder, where we observe a proxy variable that is associated with the confounder. Although Proxy Causal Learning (PCL) uses two proxy variables to recover the true causal effect, we show that a single proxy variable is sufficient for causal estimation if the outcome is generated deterministically, generalizing Control Outcome Calibration Approach (COCA). We propose two kernel-based methods for this setting: the first based on the two-stage regression approach, and the second based on a maximum moment restriction approach. We prove that both approaches can consistently estimate the causal effect, and we empirically demonstrate that we can successfully recover the causal effect on a synthetic dataset.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;Pareto Optimal&#33258;&#30417;&#30563;&#26694;&#26550;&#65292;&#21033;&#29992;&#21487;&#29992;&#30340;&#32534;&#31243;&#30417;&#30563;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#30340;&#21709;&#24212;&#36827;&#34892;&#31995;&#32479;&#26657;&#20934;&#65292;&#36890;&#36807;&#20026;&#27599;&#20010;&#21709;&#24212;&#29983;&#25104;&#39118;&#38505;&#35780;&#20998;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#30340;&#25163;&#21160;&#24037;&#20316;&#12290;</title><link>http://arxiv.org/abs/2306.16564</link><description>&lt;p&gt;
&#36890;&#36807;Pareto Optimal&#33258;&#30417;&#30563;&#23454;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33258;&#21160;&#26657;&#20934;&#21644;&#38169;&#35823;&#20462;&#27491;
&lt;/p&gt;
&lt;p&gt;
Automatic Calibration and Error Correction for Large Language Models via Pareto Optimal Self-Supervision. (arXiv:2306.16564v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16564
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;Pareto Optimal&#33258;&#30417;&#30563;&#26694;&#26550;&#65292;&#21033;&#29992;&#21487;&#29992;&#30340;&#32534;&#31243;&#30417;&#30563;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#30340;&#21709;&#24212;&#36827;&#34892;&#31995;&#32479;&#26657;&#20934;&#65292;&#36890;&#36807;&#20026;&#27599;&#20010;&#21709;&#24212;&#29983;&#25104;&#39118;&#38505;&#35780;&#20998;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#30340;&#25163;&#21160;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#24050;&#32463;&#23637;&#29616;&#20102;&#20986;&#33394;&#30340;&#33021;&#21147;&#65292;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#24212;&#29992;&#39046;&#22495;&#65292;&#20294;&#26159;&#20934;&#30830;&#24615;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#22686;&#38271;&#39046;&#22495;&#65292;&#29305;&#21035;&#26159;&#22312;&#29983;&#29289;&#21307;&#23398;&#31561;&#20851;&#38190;&#39046;&#22495;&#12290;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26657;&#20934;LLM&#21709;&#24212;&#30340;&#32622;&#20449;&#27700;&#24179;&#65292;&#23545;&#20110;&#33258;&#21160;&#26816;&#27979;&#38169;&#35823;&#24182;&#20419;&#36827;&#20154;&#26426;&#21327;&#20316;&#39564;&#35777;&#33267;&#20851;&#37325;&#35201;&#12290;&#19968;&#20010;&#37325;&#35201;&#30340;&#26657;&#20934;&#20449;&#21495;&#26469;&#28304;&#26159;&#19987;&#23478;&#25351;&#23450;&#30340;&#32534;&#31243;&#30417;&#30563;&#65292;&#36890;&#24120;&#20855;&#26377;&#36739;&#20302;&#30340;&#25104;&#26412;&#65292;&#20294;&#20063;&#26377;&#20854;&#33258;&#36523;&#30340;&#23616;&#38480;&#24615;&#65292;&#22914;&#22122;&#22768;&#21644;&#35206;&#30422;&#33539;&#22260;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;Pareto Optimal&#33258;&#30417;&#30563;&#26694;&#26550;&#65292;&#21487;&#20197;&#21033;&#29992;&#21487;&#29992;&#30340;&#32534;&#31243;&#30417;&#30563;&#26469;&#31995;&#32479;&#22320;&#26657;&#20934;LLM&#21709;&#24212;&#65292;&#36890;&#36807;&#20026;&#27599;&#20010;&#21709;&#24212;&#29983;&#25104;&#39118;&#38505;&#35780;&#20998;&#65292;&#32780;&#19981;&#38656;&#35201;&#20219;&#20309;&#39069;&#22806;&#30340;&#25163;&#21160;&#24037;&#20316;&#12290;&#36825;&#36890;&#36807;&#23398;&#20064;&#19968;&#20010;&#35843;&#21644;&#27169;&#22411;&#26469;&#23454;&#29616;&#65292;&#23558;LLM&#36755;&#20986;&#19982;&#20854;&#20182;&#21487;&#29992;&#30340;&#30417;&#30563;&#26469;&#28304;&#30456;&#21327;&#35843;&#65292;&#23558;&#26356;&#19981;&#30830;&#23450;&#30340;&#21709;&#24212;&#20998;&#37197;&#26356;&#39640;&#30340;&#39118;&#38505;&#35780;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have demonstrated remarkable capabilities out of box for a wide range of applications, yet accuracy still remains a major growth area, especially in mission-critical domains such as biomedicine. An effective method to calibrate the confidence level on LLM responses is essential to automatically detect errors and facilitate human-in-the-loop verification. An important source of calibration signals stems from expert-stipulated programmatic supervision, which is often available at low cost but has its own limitations such as noise and coverage. In this paper, we introduce a Pareto optimal self-supervision framework that can leverage available programmatic supervision to systematically calibrate LLM responses by producing a risk score for every response, without any additional manual efforts. This is accomplished by learning a harmonizer model to align LLM output with other available supervision sources, which would assign higher risk scores to more uncertain L
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;LeanDojo&#65292;&#35813;&#24037;&#20855;&#36890;&#36807;&#25552;&#21462;Lean&#30340;&#25968;&#25454;&#65292;&#20026;&#23450;&#29702;&#35777;&#26126;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#20010;&#24320;&#25918;&#28304;&#20195;&#30721;&#30340;&#24179;&#21488;&#12290;&#21033;&#29992;LeanDojo&#30340;&#25968;&#25454;&#65292;&#24320;&#21457;&#20102;ReProver&#65292;&#23427;&#26159;&#31532;&#19968;&#20010;&#20351;&#29992;&#26816;&#32034;&#22686;&#24378;&#30340;&#35821;&#35328;&#27169;&#22411;&#30340;&#35777;&#26126;&#22120;&#65292;&#21487;&#20197;&#20174;&#24222;&#22823;&#30340;&#25968;&#23398;&#24211;&#20013;&#36873;&#25321;&#21629;&#39064;&#65292;&#35757;&#32451;&#25104;&#26412;&#20302;&#65292;&#24182;&#19988;&#21482;&#38656;&#35201;&#19968;&#21608;&#30340;GPU&#35757;&#32451;&#26102;&#38388;&#12290;</title><link>http://arxiv.org/abs/2306.15626</link><description>&lt;p&gt;
LeanDojo: &#26816;&#32034;&#22686;&#24378;&#35821;&#35328;&#27169;&#22411;&#30340;&#23450;&#29702;&#35777;&#26126;
&lt;/p&gt;
&lt;p&gt;
LeanDojo: Theorem Proving with Retrieval-Augmented Language Models. (arXiv:2306.15626v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15626
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;LeanDojo&#65292;&#35813;&#24037;&#20855;&#36890;&#36807;&#25552;&#21462;Lean&#30340;&#25968;&#25454;&#65292;&#20026;&#23450;&#29702;&#35777;&#26126;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#20010;&#24320;&#25918;&#28304;&#20195;&#30721;&#30340;&#24179;&#21488;&#12290;&#21033;&#29992;LeanDojo&#30340;&#25968;&#25454;&#65292;&#24320;&#21457;&#20102;ReProver&#65292;&#23427;&#26159;&#31532;&#19968;&#20010;&#20351;&#29992;&#26816;&#32034;&#22686;&#24378;&#30340;&#35821;&#35328;&#27169;&#22411;&#30340;&#35777;&#26126;&#22120;&#65292;&#21487;&#20197;&#20174;&#24222;&#22823;&#30340;&#25968;&#23398;&#24211;&#20013;&#36873;&#25321;&#21629;&#39064;&#65292;&#35757;&#32451;&#25104;&#26412;&#20302;&#65292;&#24182;&#19988;&#21482;&#38656;&#35201;&#19968;&#21608;&#30340;GPU&#35757;&#32451;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24050;&#32463;&#26174;&#31034;&#20986;&#22312;&#20351;&#29992;Lean&#31561;&#35777;&#26126;&#21161;&#25163;&#35777;&#26126;&#24418;&#24335;&#23450;&#29702;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#31169;&#26377;&#20195;&#30721;&#12289;&#25968;&#25454;&#21644;&#22823;&#37327;&#35745;&#31639;&#35201;&#27714;&#65292;&#29616;&#26377;&#30340;&#26041;&#27861;&#24456;&#38590;&#22797;&#21046;&#25110;&#24314;&#31435;&#22312;&#20854;&#22522;&#30784;&#19978;&#65292;&#36825;&#32473;&#23450;&#29702;&#35777;&#26126;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#30740;&#31350;&#24102;&#26469;&#20102;&#24040;&#22823;&#30340;&#38556;&#30861;&#12290;&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;LeanDojo&#26469;&#28040;&#38500;&#36825;&#20123;&#38556;&#30861;&#65306;&#19968;&#20010;&#21253;&#21547;&#24037;&#20855;&#21253;&#12289;&#25968;&#25454;&#12289;&#27169;&#22411;&#21644;&#22522;&#20934;&#27979;&#35797;&#30340;&#24320;&#25918;&#28304;&#20195;&#30721;&#30340;Lean&#28216;&#20048;&#22330;&#12290;LeanDojo&#20174;Lean&#20013;&#25552;&#21462;&#25968;&#25454;&#65292;&#24182;&#20351;&#24471;&#21487;&#20197;&#36890;&#36807;&#32534;&#31243;&#19982;&#35777;&#26126;&#29615;&#22659;&#36827;&#34892;&#20132;&#20114;&#12290;&#23427;&#21253;&#21547;&#35777;&#26126;&#20013;&#21629;&#39064;&#30340;&#32454;&#31890;&#24230;&#27880;&#37322;&#65292;&#20026;&#21629;&#39064;&#36873;&#25321;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#25968;&#25454;&#65306;&#36825;&#26159;&#23450;&#29702;&#35777;&#26126;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#29942;&#39048;&#12290;&#21033;&#29992;&#36825;&#20123;&#25968;&#25454;&#65292;&#25105;&#20204;&#24320;&#21457;&#20986;&#20102;ReProver&#65288;&#26816;&#32034;&#22686;&#24378;&#30340;&#35777;&#26126;&#22120;&#65289;&#65306;&#23427;&#26159;&#31532;&#19968;&#20010;&#20351;&#29992;LLM&#30340;&#35777;&#26126;&#22120;&#65292;&#36890;&#36807;&#26816;&#32034;&#20174;&#24222;&#22823;&#30340;&#25968;&#23398;&#24211;&#20013;&#36873;&#25321;&#21629;&#39064;&#12290;&#23427;&#25104;&#26412;&#20302;&#24265;&#65292;&#21482;&#38656;&#35201;&#19968;&#21608;&#30340;GPU&#35757;&#32451;&#26102;&#38388;&#12290;&#25105;&#20204;&#30340;&#26816;&#32034;&#22120;&#21033;&#29992;&#20102;LeanDojo&#30340;pro&#30456;&#20851;&#21151;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have shown promise in proving formal theorems using proof assistants such as Lean. However, existing methods are difficult to reproduce or build on, due to private code, data, and large compute requirements. This has created substantial barriers to research on machine learning methods for theorem proving. This paper removes these barriers by introducing LeanDojo: an open-source Lean playground consisting of toolkits, data, models, and benchmarks. LeanDojo extracts data from Lean and enables interaction with the proof environment programmatically. It contains fine-grained annotations of premises in proofs, providing valuable data for premise selection: a key bottleneck in theorem proving. Using this data, we develop ReProver (Retrieval-Augmented Prover): the first LLM-based prover that is augmented with retrieval for selecting premises from a vast math library. It is inexpensive and needs only one GPU week of training. Our retriever leverages LeanDojo's prog
&lt;/p&gt;</description></item><item><title>&#25299;&#25169;&#35270;&#24046;&#26159;&#19968;&#31181;&#27604;&#36739;&#35757;&#32451;&#27169;&#22411;&#21644;&#21442;&#32771;&#25968;&#25454;&#38598;&#22810;&#23610;&#24230;&#20960;&#20309;&#32467;&#26500;&#30456;&#20284;&#24615;&#30340;&#29702;&#35770;&#21644;&#35745;&#31639;&#24037;&#20855;&#65292;&#23427;&#21487;&#20197;&#20272;&#35745;&#27169;&#22411;&#20013;&#30340;&#25299;&#25169;&#29305;&#24449;&#65292;&#26377;&#21161;&#20110;&#29702;&#35299;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#34892;&#20026;&#21644;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.11835</link><description>&lt;p&gt;
&#25299;&#25169;&#35270;&#24046;&#65306;&#28145;&#24230;&#24863;&#30693;&#27169;&#22411;&#30340;&#20960;&#20309;&#35268;&#33539;&#35828;&#26126;
&lt;/p&gt;
&lt;p&gt;
Topological Parallax: A Geometric Specification for Deep Perception Models. (arXiv:2306.11835v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11835
&lt;/p&gt;
&lt;p&gt;
&#25299;&#25169;&#35270;&#24046;&#26159;&#19968;&#31181;&#27604;&#36739;&#35757;&#32451;&#27169;&#22411;&#21644;&#21442;&#32771;&#25968;&#25454;&#38598;&#22810;&#23610;&#24230;&#20960;&#20309;&#32467;&#26500;&#30456;&#20284;&#24615;&#30340;&#29702;&#35770;&#21644;&#35745;&#31639;&#24037;&#20855;&#65292;&#23427;&#21487;&#20197;&#20272;&#35745;&#27169;&#22411;&#20013;&#30340;&#25299;&#25169;&#29305;&#24449;&#65292;&#26377;&#21161;&#20110;&#29702;&#35299;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#34892;&#20026;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#20445;&#35777;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#30340;&#23433;&#20840;&#24615;&#21644;&#40065;&#26834;&#24615;&#65292;&#25105;&#20204;&#24341;&#20837;&#25299;&#25169;&#35270;&#24046;&#20316;&#20026;&#27604;&#36739;&#24050;&#35757;&#32451;&#27169;&#22411;&#21644;&#21442;&#32771;&#25968;&#25454;&#38598;&#30340;&#22810;&#23610;&#24230;&#20960;&#20309;&#32467;&#26500;&#30456;&#20284;&#24615;&#30340;&#29702;&#35770;&#21644;&#35745;&#31639;&#24037;&#20855;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#21644;&#20363;&#23376;&#34920;&#26126;&#65292;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#20043;&#38388;&#30340;&#36825;&#31181;&#20960;&#20309;&#30456;&#20284;&#24615;&#23545;&#20110;&#21487;&#20449;&#30340;&#25554;&#20540;&#21644;&#25200;&#21160;&#33267;&#20851;&#37325;&#35201;&#65292;&#24182;&#19988;&#25105;&#20204;&#29468;&#27979;&#65292;&#36825;&#20010;&#26032;&#27010;&#24565;&#23558;&#20026;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#20013;&#36807;&#25311;&#21512;&#21644;&#27867;&#21270;&#20043;&#38388;&#19981;&#26126;&#30830;&#30340;&#20851;&#31995;&#30340;&#24403;&#21069;&#35752;&#35770;&#22686;&#28155;&#20215;&#20540;&#12290;&#22312;&#20856;&#22411;&#30340;DNN&#24212;&#29992;&#20013;&#65292;&#27169;&#22411;&#30340;&#26174;&#24335;&#20960;&#20309;&#25551;&#36848;&#26159;&#19981;&#21487;&#33021;&#30340;&#65292;&#20294;&#35270;&#24046;&#21487;&#20197;&#36890;&#36807;&#26816;&#26597;&#20351;&#29992;&#21442;&#32771;&#25968;&#25454;&#38598;&#30340;&#27979;&#22320;&#30072;&#21464;&#23545;Rips&#22797;&#21512;&#20307;&#30340;&#24433;&#21709;&#26469;&#20272;&#35745;&#27169;&#22411;&#20013;&#30340;&#25299;&#25169;&#29305;&#24449;&#65288;&#32452;&#20214;&#12289;&#21608;&#26399;&#12289;&#31354;&#27934;&#31561;&#65289;&#12290;&#22240;&#27492;&#65292;&#35270;&#24046;&#25351;&#31034;&#27169;&#22411;&#19982;&#25968;&#25454;&#38598;&#26159;&#21542;&#20849;&#20139;&#31867;&#20284;&#30340;&#22810;&#23610;&#24230;&#20960;&#20309;&#29305;&#24449;&#12290;&#35270;&#24046;&#36890;&#36807;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#29702;&#35770;&#65292;&#25552;&#20379;&#20102;&#20174;&#19981;&#21516;&#35282;&#24230;&#35266;&#23519;&#25968;&#25454;&#30340;&#30452;&#35266;&#27010;&#24565;&#65292;&#24182;&#20026;&#29702;&#35299;&#28145;&#24230;&#24863;&#30693;&#27169;&#22411;&#30340;&#34892;&#20026;&#21644;&#24615;&#33021;&#25552;&#20379;&#20102;&#26032;&#30340;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;
For safety and robustness of AI systems, we introduce topological parallax as a theoretical and computational tool that compares a trained model to a reference dataset to determine whether they have similar multiscale geometric structure. Our proofs and examples show that this geometric similarity between dataset and model is essential to trustworthy interpolation and perturbation, and we conjecture that this new concept will add value to the current debate regarding the unclear relationship between overfitting and generalization in applications of deep-learning. In typical DNN applications, an explicit geometric description of the model is impossible, but parallax can estimate topological features (components, cycles, voids, etc.) in the model by examining the effect on the Rips complex of geodesic distortions using the reference dataset. Thus, parallax indicates whether the model shares similar multiscale geometric features with the dataset. Parallax presents theoretically via topolo
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25581;&#31034;&#20102;&#23454;&#29992;&#30340;&#38160;&#24230;&#24863;&#30693;&#20248;&#21270;&#31639;&#27861;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#19981;&#33021;&#22815;&#20840;&#31243;&#21521;&#26368;&#20248;&#28857;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2306.09850</link><description>&lt;p&gt;
&#23454;&#29992;&#30340;&#38160;&#24230;&#24863;&#30693;&#20248;&#21270;&#31639;&#27861;&#19981;&#33021;&#20840;&#31243;&#21521;&#26368;&#20248;&#28857;&#25910;&#25947;
&lt;/p&gt;
&lt;p&gt;
Practical Sharpness-Aware Minimization Cannot Converge All the Way to Optima. (arXiv:2306.09850v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09850
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25581;&#31034;&#20102;&#23454;&#29992;&#30340;&#38160;&#24230;&#24863;&#30693;&#20248;&#21270;&#31639;&#27861;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#19981;&#33021;&#22815;&#20840;&#31243;&#21521;&#26368;&#20248;&#28857;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38160;&#24230;&#24863;&#30693;&#20248;&#21270;(SAM)&#26159;&#19968;&#31181;&#20248;&#21270;&#22120;&#65292;&#23427;&#22522;&#20110;&#24403;&#21069;&#28857;$x_t$&#30340;&#26799;&#24230;&#65292;&#22312;&#25200;&#21160;$y_t=x_t+\rho\frac{\nabla f(x_t)}{\lVert\nabla f(x_t)\rVert}$&#22788;&#36827;&#34892;&#19979;&#38477;&#12290;&#29616;&#26377;&#30740;&#31350;&#35777;&#26126;&#20102;SAM&#23545;&#20110;&#24179;&#28369;&#20989;&#25968;&#30340;&#25910;&#25947;&#24615;&#65292;&#20294;&#26159;&#23427;&#20204;&#20551;&#35774;&#25200;&#21160;&#30340;&#22823;&#23567;$\rho$&#36880;&#28176;&#34928;&#20943;&#21644;/&#25110;&#22312;$y_t$&#20013;&#27809;&#26377;&#26799;&#24230;&#24402;&#19968;&#21270;&#65292;&#36825;&#19982;&#23454;&#36341;&#19981;&#31526;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#23454;&#29992;&#37197;&#32622;&#65288;&#21363;&#24120;&#25968;$\rho$&#21644;$y_t$&#20013;&#30340;&#26799;&#24230;&#24402;&#19968;&#21270;&#65289;&#30340;&#30830;&#23450;&#24615;/&#38543;&#26426;&#29256;&#26412;&#30340;SAM&#65292;&#24182;&#25506;&#35752;&#20102;&#23427;&#20204;&#22312;&#20855;&#26377;&#65288;&#38750;&#65289;&#20984;&#24615;&#20551;&#35774;&#30340;&#24179;&#28369;&#20989;&#25968;&#19978;&#30340;&#25910;&#25947;&#24615;&#36136;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#21457;&#29616;SAM&#22312;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#23567;&#20540;&#25110;&#31283;&#23450;&#28857;&#26041;&#38754;&#20855;&#26377;&#26377;&#38480;&#30340;&#33021;&#21147;&#12290;&#23545;&#20110;&#24179;&#28369;&#24378;&#20984;&#20989;&#25968;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#30830;&#23450;&#24615;SAM&#20855;&#26377;&#20005;&#26684;&#30340;&#20840;&#23616;&#25910;&#25947;&#29575;&#20026;$\tilde\Theta(\frac{1}{T^2})$&#65292;&#32780;&#38543;&#26426;SAM&#30340;&#25910;&#25947;&#30028;&#21017;&#21463;&#21040;&#22122;&#22768;&#27700;&#24179;&#38477;&#20302;&#30340;&#24433;&#21709;&#65292;&#36825;&#34920;&#26126;&#20102;&#24179;&#38754;&#30446;&#26631;&#34920;&#38754;&#30340;&#23574;&#38160;&#24230;&#21644;&#24179;&#32531;&#24615;&#20043;&#38388;&#24179;&#34913;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sharpness-Aware Minimization (SAM) is an optimizer that takes a descent step based on the gradient at a perturbation $y_t = x_t + \rho \frac{\nabla f(x_t)}{\lVert \nabla f(x_t) \rVert}$ of the current point $x_t$. Existing studies prove convergence of SAM for smooth functions, but they do so by assuming decaying perturbation size $\rho$ and/or no gradient normalization in $y_t$, which is detached from practice. To address this gap, we study deterministic/stochastic versions of SAM with practical configurations (i.e., constant $\rho$ and gradient normalization in $y_t$) and explore their convergence properties on smooth functions with (non)convexity assumptions. Perhaps surprisingly, in many scenarios, we find out that SAM has limited capability to converge to global minima or stationary points. For smooth strongly convex functions, we show that while deterministic SAM enjoys tight global convergence rates of $\tilde \Theta(\frac{1}{T^2})$, the convergence bound of stochastic SAM suffer
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35299;&#20915;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#24403;&#22870;&#21169;&#21576;&#8220;&#37325;&#23614;&#8221;&#20998;&#24067;&#26102;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#31532;&#19968;&#31181;&#22788;&#29702;&#36825;&#31181;&#24773;&#20917;&#30340;&#23454;&#20363;&#30456;&#20851;&#31639;&#27861;&#65292;&#24182;&#24471;&#21040;&#20102;&#26497;&#23567;&#26368;&#22823;&#21270;&#30340;&#36951;&#25022;&#30028;&#12290;</title><link>http://arxiv.org/abs/2306.06836</link><description>&lt;p&gt;
&#29992;&#20989;&#25968;&#36924;&#36817;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#20013;&#37325;&#23614;&#22870;&#21169;&#38382;&#39064;&#30340;&#26497;&#23567;&#26368;&#22823;&#21270;&#31639;&#27861;&#21644;&#23454;&#20363;&#30456;&#20851;&#36951;&#25022;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
Tackling Heavy-Tailed Rewards in Reinforcement Learning with Function Approximation: Minimax Optimal and Instance-Dependent Regret Bounds. (arXiv:2306.06836v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06836
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#24403;&#22870;&#21169;&#21576;&#8220;&#37325;&#23614;&#8221;&#20998;&#24067;&#26102;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#31532;&#19968;&#31181;&#22788;&#29702;&#36825;&#31181;&#24773;&#20917;&#30340;&#23454;&#20363;&#30456;&#20851;&#31639;&#27861;&#65292;&#24182;&#24471;&#21040;&#20102;&#26497;&#23567;&#26368;&#22823;&#21270;&#30340;&#36951;&#25022;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#26377;&#35768;&#22810;&#24037;&#20316;&#37117;&#19987;&#27880;&#20110;&#20026;&#26377;&#30028;&#22870;&#21169;&#30340;&#24378;&#21270;&#23398;&#20064;&#35774;&#35745;&#26377;&#25928;&#31639;&#27861;&#65292;&#20294;&#24403;&#22870;&#21169;&#21576;&#29616;&#8220;&#37325;&#23614;&#8221;&#20998;&#24067;&#26102;&#8212;&#8212;&#21363;&#23384;&#22312;&#26576;&#20010; $\epsilon\in(0,1]$ &#20351;&#24471;&#20165;&#26377;&#26377;&#38480;&#30340;$(1+\epsilon)$-&#38454;&#30697;&#8212;&#8212;&#26159;&#21542;&#23384;&#22312;&#23545;&#22823;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#36827;&#34892;&#37319;&#26679;&#25110;&#26102;&#25928;&#24615;&#31639;&#27861;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290; &#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#20855;&#26377;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340; RL &#20013;&#30340;&#36825;&#31181;&#22870;&#21169;&#26426;&#21046;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#39318;&#20808;&#20026;&#37325;&#23614;&#32447;&#24615;&#36172;&#33218;&#35774;&#35745;&#20102;&#19968;&#31181;&#31639;&#27861;&#8212;&#8212;\textsc{Heavy-OFUL}&#65292;&#20854;&#23454;&#29616;&#20102;&#19968;&#31181;&#23454;&#20363;&#30456;&#20851;&#30340; $T$-round &#36951;&#25022;&#24230;&#37327;&#65292;&#20026; $\tilde{O}\big(d T^{\frac{1-\epsilon}{2(1+\epsilon)}} \sqrt{\sum_{t=1}^T \nu_t^2} + d T^{\frac{1-\epsilon}{2(1+\epsilon)}}\big)$&#65292;&#36825;&#26159;&#36825;&#31181;&#31867;&#22411;&#30340;\emph{&#31532;&#19968;&#31687;}&#25991;&#31456;&#12290;$\nu_t^{1+\epsilon}$&#26159;&#31532; $t$ &#36718;&#22870;&#21169;&#30340; $(1+\epsilon)$-&#38454;&#20013;&#24515;&#30697;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#22312;&#24212;&#29992;&#20110; st &#30340;&#26368;&#22351;&#24773;&#20917;&#26102;&#65292;&#19978;&#36848;&#30028;&#26159;&#26497;&#23567;&#20540;&#30340;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
While numerous works have focused on devising efficient algorithms for reinforcement learning (RL) with uniformly bounded rewards, it remains an open question whether sample or time-efficient algorithms for RL with large state-action space exist when the rewards are \emph{heavy-tailed}, i.e., with only finite $(1+\epsilon)$-th moments for some $\epsilon\in(0,1]$. In this work, we address the challenge of such rewards in RL with linear function approximation. We first design an algorithm, \textsc{Heavy-OFUL}, for heavy-tailed linear bandits, achieving an \emph{instance-dependent} $T$-round regret of $\tilde{O}\big(d T^{\frac{1-\epsilon}{2(1+\epsilon)}} \sqrt{\sum_{t=1}^T \nu_t^2} + d T^{\frac{1-\epsilon}{2(1+\epsilon)}}\big)$, the \emph{first} of this kind. Here, $d$ is the feature dimension, and $\nu_t^{1+\epsilon}$ is the $(1+\epsilon)$-th central moment of the reward at the $t$-th round. We further show the above bound is minimax optimal when applied to the worst-case instances in st
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#22522;&#20110;Wasserstein&#36317;&#31163;&#30340;PAC-Bayesian&#27867;&#21270;&#30028;&#38480;&#30340;&#26032;&#39062;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#31639;&#27861;&#26694;&#26550;&#65292;&#35813;&#30028;&#38480;&#26174;&#33879;&#25193;&#23637;&#20102;PAC-Bayesian&#30028;&#38480;&#30340;&#33539;&#22260;&#65292;&#24182;&#22312;&#32463;&#20856;&#30340;&#23398;&#20064;&#38382;&#39064;&#20013;&#23637;&#29616;&#20102;&#25913;&#36827;&#30340;&#27867;&#21270;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2306.04375</link><description>&lt;p&gt;
&#22522;&#20110;Wasserstein&#30340;&#39640;&#27010;&#29575;&#27867;&#21270;&#30028;&#38480;&#19979;&#30340;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Learning via Wasserstein-Based High Probability Generalisation Bounds. (arXiv:2306.04375v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04375
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#22522;&#20110;Wasserstein&#36317;&#31163;&#30340;PAC-Bayesian&#27867;&#21270;&#30028;&#38480;&#30340;&#26032;&#39062;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#31639;&#27861;&#26694;&#26550;&#65292;&#35813;&#30028;&#38480;&#26174;&#33879;&#25193;&#23637;&#20102;PAC-Bayesian&#30028;&#38480;&#30340;&#33539;&#22260;&#65292;&#24182;&#22312;&#32463;&#20856;&#30340;&#23398;&#20064;&#38382;&#39064;&#20013;&#23637;&#29616;&#20102;&#25913;&#36827;&#30340;&#27867;&#21270;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32467;&#26500;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;SRM&#65289;&#20013;&#65292;&#26368;&#23567;&#21270;&#24635;&#20307;&#39118;&#38505;&#25110;&#27867;&#21270;&#24046;&#36317;&#19978;&#38480;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#36825;&#23588;&#20854;&#26159;PAC-Bayesian&#23398;&#20064;&#30340;&#26680;&#24515;&#12290;&#23613;&#31649;&#36817;&#24180;&#26469;&#20854;&#21462;&#24471;&#20102;&#25104;&#21151;&#24182;&#21560;&#24341;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#65292;&#20294;PAC-Bayesian&#26694;&#26550;&#30340;&#23616;&#38480;&#26159;&#22823;&#22810;&#25968;&#30028;&#38480;&#28041;&#21450;Kullback-Leibler&#65288;KL&#65289;&#25955;&#24230;&#39033;&#65288;&#25110;&#20854;&#21464;&#21270;&#65289;&#65292;&#36825;&#21487;&#33021;&#34920;&#29616;&#20986;&#19981;&#35268;&#21017;&#34892;&#20026;&#24182;&#26080;&#27861;&#25429;&#25417;&#23398;&#20064;&#38382;&#39064;&#30340;&#24213;&#23618;&#20960;&#20309;&#32467;&#26500;&#65292;&#22240;&#27492;&#38480;&#21046;&#20102;&#20854;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#20351;&#29992;&#12290;&#26368;&#36817;&#30340;&#19968;&#20123;&#30740;&#31350;&#20225;&#22270;&#29992;Wasserstein&#36317;&#31163;&#26367;&#25442;PAC-Bayesian&#30028;&#38480;&#20013;&#30340;KL&#25955;&#24230;&#12290;&#21363;&#20351;&#36825;&#20123;&#30028;&#38480;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#32531;&#35299;&#20102;&#19978;&#36848;&#38382;&#39064;&#65292;&#20294;&#23427;&#20204;&#35201;&#20040;&#20445;&#25345;&#26399;&#26395;&#65292;&#35201;&#20040;&#23545;&#26377;&#30028;&#25439;&#22833;&#26377;&#25928;&#65292;&#35201;&#20040;&#38590;&#20197;&#22312;SRM&#26694;&#26550;&#20013;&#26368;&#23567;&#21270;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20026;&#36825;&#19968;&#30740;&#31350;&#26041;&#21521;&#20570;&#20986;&#20102;&#36129;&#29486;&#65292;&#35777;&#26126;&#20102;&#22522;&#20110;Wasserstein&#36317;&#31163;&#30340;PAC-Bayesian&#27867;&#21270;&#30028;&#38480;&#30340;&#26032;&#39062;&#24615;&#65292;&#24182;&#19988;&#25105;&#20204;&#30340;&#30028;&#38480;&#20197;&#26174;&#33879;&#24615;&#22320;&#25193;&#23637;&#20102;PAC-Bayesian&#30028;&#38480;&#30340;&#33539;&#22260;&#65292;&#24182;&#22312;&#20960;&#31181;&#32463;&#20856;&#30340;&#23398;&#20064;&#38382;&#39064;&#20013;&#23637;&#29616;&#20102;&#25913;&#36827;&#30340;&#27867;&#21270;&#35823;&#24046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#23398;&#20064;&#26032;&#30340;&#30028;&#38480;&#65292;&#24182;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#26377;&#21069;&#36884;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Minimising upper bounds on the population risk or the generalisation gap has been widely used in structural risk minimisation (SRM) - this is in particular at the core of PAC-Bayesian learning. Despite its successes and unfailing surge of interest in recent years, a limitation of the PAC-Bayesian framework is that most bounds involve a Kullback-Leibler (KL) divergence term (or its variations), which might exhibit erratic behavior and fail to capture the underlying geometric structure of the learning problem - hence restricting its use in practical applications. As a remedy, recent studies have attempted to replace the KL divergence in the PAC-Bayesian bounds with the Wasserstein distance. Even though these bounds alleviated the aforementioned issues to a certain extent, they either hold in expectation, are for bounded losses, or are nontrivial to minimize in an SRM framework. In this work, we contribute to this line of research and prove novel Wasserstein distance-based PAC-Bayesian ge
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#27604;&#36739;&#21644;&#23545;&#27604;&#20102;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#21644;&#26368;&#22823;&#21518;&#39564;&#20272;&#35745;&#30340;&#39118;&#38505;&#65292;&#37325;&#28857;&#20851;&#27880;&#20102;&#27169;&#22411;&#32500;&#24230;&#22686;&#38271;&#36895;&#24230;&#22823;&#20110;&#20219;&#20309;&#24120;&#25968;&#20493;&#30340;&#26679;&#26412;&#25968;&#26102;&#23427;&#20204;&#20043;&#38388;&#30340;&#28176;&#36817;&#19968;&#33268;&#24615;&#12290;&#25968;&#20540;&#27169;&#25311;&#34920;&#26126;&#36825;&#20004;&#20010;&#25968;&#37327;&#22312;&#38480;&#23450;&#32500;&#24230;&#19978;&#20855;&#26377;&#39640;&#26031;&#27874;&#21160;&#65292;&#24182;&#34920;&#29616;&#20986;&#30456;&#20284;&#30340;&#23646;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.03783</link><description>&lt;p&gt;
&#38543;&#26426;&#29305;&#24449;&#22238;&#24402;&#20013;&#36125;&#21494;&#26031;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#28176;&#36817;&#24615;
&lt;/p&gt;
&lt;p&gt;
Asymptotics of Bayesian Uncertainty Estimation in Random Features Regression. (arXiv:2306.03783v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03783
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#27604;&#36739;&#21644;&#23545;&#27604;&#20102;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#21644;&#26368;&#22823;&#21518;&#39564;&#20272;&#35745;&#30340;&#39118;&#38505;&#65292;&#37325;&#28857;&#20851;&#27880;&#20102;&#27169;&#22411;&#32500;&#24230;&#22686;&#38271;&#36895;&#24230;&#22823;&#20110;&#20219;&#20309;&#24120;&#25968;&#20493;&#30340;&#26679;&#26412;&#25968;&#26102;&#23427;&#20204;&#20043;&#38388;&#30340;&#28176;&#36817;&#19968;&#33268;&#24615;&#12290;&#25968;&#20540;&#27169;&#25311;&#34920;&#26126;&#36825;&#20004;&#20010;&#25968;&#37327;&#22312;&#38480;&#23450;&#32500;&#24230;&#19978;&#20855;&#26377;&#39640;&#26031;&#27874;&#21160;&#65292;&#24182;&#34920;&#29616;&#20986;&#30456;&#20284;&#30340;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27604;&#36739;&#21644;&#23545;&#27604;&#20102;&#36125;&#21494;&#26031;&#22238;&#24402;&#27169;&#22411;&#20013;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#21644;&#26368;&#22823;&#21518;&#39564;&#20272;&#35745;&#65288;MAP&#65289;&#39118;&#38505;&#22312;&#36229;&#21442;&#25968;&#21270;&#21306;&#22495;&#20013;&#30340;&#34892;&#20026;&#12290;&#25105;&#20204;&#23558;&#37325;&#28857;&#20851;&#27880;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#65288;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#65289;&#30340;&#26041;&#24046;&#65292;&#24182;&#23558;&#20854;&#28176;&#36817;&#24615;&#19982;MAP&#20272;&#35745;&#22120;&#30340;&#39118;&#38505;&#36827;&#34892;&#27604;&#36739;&#12290;&#24403;&#27169;&#22411;&#32500;&#24230;&#22686;&#38271;&#36895;&#24230;&#22823;&#20110;&#20219;&#20309;&#24120;&#25968;&#20493;&#30340;&#26679;&#26412;&#25968;&#26102;&#65292;&#23427;&#20204;&#20043;&#38388;&#30340;&#28176;&#36817;&#19968;&#33268;&#24615;&#21463;&#21040;&#20449;&#22122;&#27604;&#30340;&#30456;&#21464;&#30340;&#25511;&#21046;&#12290;&#24403;&#26679;&#26412;&#25968;&#22686;&#38271;&#36895;&#24230;&#22823;&#20110;&#20219;&#20309;&#24120;&#25968;&#20493;&#30340;&#27169;&#22411;&#32500;&#24230;&#26102;&#65292;&#23427;&#20204;&#20063;&#20250;&#28176;&#36817;&#19968;&#33268;&#12290;&#25968;&#20540;&#27169;&#25311;&#35828;&#26126;&#20102;&#20004;&#20010;&#25968;&#37327;&#30340;&#26377;&#38480;&#32500;&#20998;&#24067;&#24615;&#36136;&#12290;&#25105;&#20204;&#25512;&#27979;&#23427;&#20204;&#20855;&#26377;&#39640;&#26031;&#27874;&#21160;&#65292;&#24182;&#34920;&#29616;&#20986;&#19982;&#20043;&#21069;&#22312;&#39640;&#26031;&#24207;&#21015;&#27169;&#22411;&#20013;&#21457;&#29616;&#30340;&#31867;&#20284;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we compare and contrast the behavior of the posterior predictive distribution to the risk of the maximum a posteriori estimator for the random features regression model in the overparameterized regime. We will focus on the variance of the posterior predictive distribution (Bayesian model average) and compare its asymptotics to that of the risk of the MAP estimator. In the regime where the model dimensions grow faster than any constant multiple of the number of samples, asymptotic agreement between these two quantities is governed by the phase transition in the signal-to-noise ratio. They also asymptotically agree with each other when the number of samples grow faster than any constant multiple of model dimensions. Numerical simulations illustrate finer distributional properties of the two quantities for finite dimensions. We conjecture they have Gaussian fluctuations and exhibit similar properties as found by previous authors in a Gaussian sequence model, which is of inde
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;$(k, t)$-FWL&#21644;$k$-FWL+&#20004;&#31181;&#26041;&#27861;&#65292;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#23427;&#20204;&#21487;&#20197;&#22312;$O(n^2)$&#30340;&#31354;&#38388;&#22797;&#26434;&#24230;&#19979;&#65292;&#35299;&#20915;&#22270;&#21516;&#26500;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.03266</link><description>&lt;p&gt;
&#36890;&#36807;&#37325;&#26032;&#24605;&#32771;&#27665;&#38388;&#23041;&#26031;&#36153;&#21202;-&#33713;&#26364;&#31639;&#27861;&#65292;&#23454;&#29616;$O(n^2)$&#31354;&#38388;&#20869;&#20219;&#24847;&#34920;&#36798;&#33021;&#21147;&#30340;GNNs
&lt;/p&gt;
&lt;p&gt;
Towards Arbitrarily Expressive GNNs in $O(n^2)$ Space by Rethinking Folklore Weisfeiler-Lehman. (arXiv:2306.03266v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03266
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;$(k, t)$-FWL&#21644;$k$-FWL+&#20004;&#31181;&#26041;&#27861;&#65292;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#23427;&#20204;&#21487;&#20197;&#22312;$O(n^2)$&#30340;&#31354;&#38388;&#22797;&#26434;&#24230;&#19979;&#65292;&#35299;&#20915;&#22270;&#21516;&#26500;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#28040;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#65288;MPNNs&#65289;&#24050;&#25104;&#20026;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#20013;&#26368;&#21463;&#27426;&#36814;&#30340;&#26694;&#26550;&#12290;&#28982;&#32780;&#65292;&#20854;&#34920;&#36798;&#33021;&#21147;&#21463;&#21040;&#19968;&#32500;&#23041;&#26031;&#36153;&#21202;-&#33713;&#26364;&#65288;1-WL&#65289;&#27979;&#35797;&#30340;&#38480;&#21046;&#12290;&#19968;&#20123;&#30740;&#31350;&#21463;&#21040;$k$-WL/FWL&#65288;&#27665;&#38388;WL&#65289;&#30340;&#21551;&#21457;&#24182;&#35774;&#35745;&#20854;&#30456;&#24212;&#30340;&#31070;&#32463;&#29256;&#26412;&#12290;&#23613;&#31649;&#20855;&#26377;&#24456;&#39640;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#20294;&#36825;&#19968;&#30740;&#31350;&#26041;&#21521;&#23384;&#22312;&#20005;&#37325;&#23616;&#38480;&#24615;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;$(k, t)$-FWL&#21644;$k$-FWL+&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Message passing neural networks (MPNNs) have emerged as the most popular framework of graph neural networks (GNNs) in recent years. However, their expressive power is limited by the 1-dimensional Weisfeiler-Lehman (1-WL) test. Some works are inspired by $k$-WL/FWL (Folklore WL) and design the corresponding neural versions. Despite the high expressive power, there are serious limitations in this line of research. In particular, (1) $k$-WL/FWL requires at least $O(n^k)$ space complexity, which is impractical for large graphs even when $k=3$; (2) The design space of $k$-WL/FWL is rigid, with the only adjustable hyper-parameter being $k$. To tackle the first limitation, we propose an extension, $(k, t)$-FWL. We theoretically prove that even if we fix the space complexity to $O(n^2)$ in $(k, t)$-FWL, we can construct an expressiveness hierarchy up to solving the graph isomorphism problem. To tackle the second problem, we propose $k$-FWL+, which considers any equivariant set as neighbors ins
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36830;&#32493;&#24615;&#32467;&#26524;&#30340;&#37096;&#20998;&#21453;&#20107;&#23454;&#35782;&#21035;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25935;&#24863;&#24615;&#27169;&#22411;&#8212;&#8212;&#26354;&#29575;&#25935;&#24863;&#27169;&#22411;&#65292;&#36890;&#36807;&#38480;&#21046;&#20989;&#25968;&#32423;&#38598;&#30340;&#26354;&#29575;&#26469;&#33719;&#24471;&#20449;&#24687;&#36793;&#30028;&#12290;</title><link>http://arxiv.org/abs/2306.01424</link><description>&lt;p&gt;
&#24102;&#26354;&#29575;&#25935;&#24863;&#27169;&#22411;&#30340;&#36830;&#32493;&#24615;&#32467;&#26524;&#30340;&#37096;&#20998;&#21453;&#20107;&#23454;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Partial Counterfactual Identification of Continuous Outcomes with a Curvature Sensitivity Model. (arXiv:2306.01424v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01424
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36830;&#32493;&#24615;&#32467;&#26524;&#30340;&#37096;&#20998;&#21453;&#20107;&#23454;&#35782;&#21035;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25935;&#24863;&#24615;&#27169;&#22411;&#8212;&#8212;&#26354;&#29575;&#25935;&#24863;&#27169;&#22411;&#65292;&#36890;&#36807;&#38480;&#21046;&#20989;&#25968;&#32423;&#38598;&#30340;&#26354;&#29575;&#26469;&#33719;&#24471;&#20449;&#24687;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#20107;&#23454;&#25512;&#26029;&#26088;&#22312;&#22238;&#31572;&#8220;&#22914;&#26524;&#8221;&#38382;&#39064;&#65292;&#22240;&#27492;&#23646;&#20110;Pearl&#22240;&#26524;&#20851;&#31995;&#38454;&#26799;&#20013;&#26368;&#31934;&#32454;&#30340;&#25512;&#29702;&#31867;&#22411;&#12290;&#29616;&#26377;&#30340;&#38024;&#23545;&#20855;&#26377;&#36830;&#32493;&#32467;&#26524;&#30340;&#21453;&#20107;&#23454;&#25512;&#26029;&#26041;&#27861;&#26088;&#22312;&#36827;&#34892;&#28857;&#35782;&#21035;&#65292;&#22240;&#27492;&#23545;&#22522;&#30784;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#36827;&#34892;&#20102;&#24378;&#26377;&#21147;&#19988;&#19981;&#33258;&#28982;&#30340;&#20551;&#35774;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25918;&#23485;&#20102;&#36825;&#20123;&#20551;&#35774;&#65292;&#26088;&#22312;&#36827;&#34892;&#36830;&#32493;&#32467;&#26524;&#30340;&#37096;&#20998;&#21453;&#20107;&#23454;&#35782;&#21035;&#65292;&#21363;&#24403;&#21453;&#20107;&#23454;&#26597;&#35810;&#23384;&#22312;&#20855;&#26377;&#20449;&#24687;&#36793;&#30028;&#30340;&#26080;&#30693;&#21306;&#38388;&#20013;&#26102;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#65292;&#21363;&#20351;&#26159;&#36830;&#32493;&#21487;&#24494;&#30340;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#20989;&#25968;&#30340;&#32423;&#38598;&#30340;&#26354;&#29575;&#20063;&#26159;&#38750;&#20449;&#24687;&#30340;&#65292;&#21453;&#20107;&#23454;&#26597;&#35810;&#30340;&#26080;&#30693;&#21306;&#38388;&#20063;&#26159;&#38750;&#20449;&#24687;&#30340;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25935;&#24863;&#24615;&#27169;&#22411;&#31216;&#20026;&#26354;&#29575;&#25935;&#24863;&#27169;&#22411;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#23427;&#20801;&#35768;&#25105;&#20204;&#36890;&#36807;&#38480;&#21046;&#20989;&#25968;&#32423;&#38598;&#30340;&#26354;&#29575;&#26469;&#33719;&#24471;&#20449;&#24687;&#36793;&#30028;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#29616;&#26377;&#30340;&#28857;&#21453;&#20107;&#23454;&#35782;&#21035;&#26041;&#27861;&#21487;&#20197;&#35270;&#20026;&#25105;&#20204;&#25552;&#20986;&#26694;&#26550;&#30340;&#29305;&#23450;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counterfactual inference aims to answer retrospective ''what if'' questions and thus belongs to the most fine-grained type of inference in Pearl's causality ladder. Existing methods for counterfactual inference with continuous outcomes aim at point identification and thus make strong and unnatural assumptions about the underlying structural causal model. In this paper, we relax these assumptions and aim at partial counterfactual identification of continuous outcomes, i.e., when the counterfactual query resides in an ignorance interval with informative bounds. We prove that, in general, the ignorance interval of the counterfactual queries has non-informative bounds, already when functions of structural causal models are continuously differentiable. As a remedy, we propose a novel sensitivity model called Curvature Sensitivity Model. This allows us to obtain informative bounds by bounding the curvature of level sets of the functions. We further show that existing point counterfactual ide
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#19968;&#31181;&#21487;&#33021;&#8220;&#35268;&#33539;&#19981;&#27491;&#30830;&#8221;&#27169;&#22411;&#30340;&#36890;&#29992;&#21327;&#35758;&#65292;&#8220;&#25554;&#20214;&#24335;&#34920;&#29616;&#20248;&#21270;&#8221;&#12290;</title><link>http://arxiv.org/abs/2305.18728</link><description>&lt;p&gt;
&#25554;&#20214;&#21270;&#34920;&#29616;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Plug-in Performative Optimization. (arXiv:2305.18728v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18728
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#19968;&#31181;&#21487;&#33021;&#8220;&#35268;&#33539;&#19981;&#27491;&#30830;&#8221;&#27169;&#22411;&#30340;&#36890;&#29992;&#21327;&#35758;&#65292;&#8220;&#25554;&#20214;&#24335;&#34920;&#29616;&#20248;&#21270;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#39044;&#27979;&#20855;&#26377;&#34920;&#29616;&#24615;&#26102;&#65292;&#36873;&#25321;&#21738;&#20010;&#39044;&#27979;&#22120;&#37096;&#32626;&#23558;&#24433;&#21709;&#26410;&#26469;&#35266;&#27979;&#30340;&#20998;&#24067;&#12290;&#22312;&#34920;&#29616;&#24615;&#23398;&#20064;&#20013;&#65292;&#24635;&#20307;&#30446;&#26631;&#26159;&#25214;&#21040;&#20855;&#26377;&#20302;&#8220;&#34920;&#29616;&#24615;&#39118;&#38505;&#8221;&#30340;&#39044;&#27979;&#22120;&#65292;&#21363;&#22312;&#20854;&#24341;&#23548;&#30340;&#20998;&#24067;&#19978;&#34920;&#29616;&#33391;&#22909;&#12290;&#26368;&#20248;&#21270;&#34920;&#29616;&#24615;&#39118;&#38505;&#30340;&#19968;&#31995;&#21015;&#35299;&#20915;&#26041;&#26696;&#65292;&#21253;&#25324;&#36172;&#24466;&#31639;&#27861;&#21644;&#20854;&#20182;&#26080;&#23548;&#25968;&#26041;&#27861;&#65292;&#22312;&#34920;&#29616;&#24615;&#21453;&#39304;&#20013;&#19981;&#30693;&#36947;&#20219;&#20309;&#32467;&#26500;&#65292;&#23548;&#33268;&#25910;&#25947;&#36895;&#24230;&#26497;&#24930;&#12290;&#34917;&#20805;&#30340;&#19968;&#31995;&#21015;&#35299;&#20915;&#26041;&#26696;&#21033;&#29992;&#21453;&#39304;&#20013;&#30340;&#26174;&#24335;&#8220;&#27169;&#22411;&#8221;&#65292;&#20363;&#22914;&#25112;&#30053;&#20998;&#31867;&#20013;&#30340;&#26368;&#20339;&#21709;&#24212;&#27169;&#22411;&#65292;&#21487;&#20197;&#23454;&#29616;&#26356;&#24555;&#30340;&#36895;&#29575;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#36895;&#29575;&#20851;&#38190;&#20381;&#36182;&#20110;&#21453;&#39304;&#27169;&#22411;&#30340;&#35268;&#33539;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#21551;&#21160;&#20102;&#23545;&#22312;&#34920;&#29616;&#24615;&#39044;&#27979;&#20013;&#20351;&#29992;&#21487;&#33021;&#30340;&#8220;&#35268;&#33539;&#19981;&#27491;&#30830;&#8221;&#27169;&#22411;&#30340;&#30740;&#31350;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#20351;&#29992;&#27169;&#22411;&#30340;&#36890;&#29992;&#21327;&#35758;&#65292;&#31216;&#20026;&#8220;&#25554;&#20214;&#24335;&#34920;&#29616;&#20248;&#21270;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;
When predictions are performative, the choice of which predictor to deploy influences the distribution of future observations. The overarching goal in learning under performativity is to find a predictor that has low \emph{performative risk}, that is, good performance on its induced distribution. One family of solutions for optimizing the performative risk, including bandits and other derivative-free methods, is agnostic to any structure in the performative feedback, leading to exceedingly slow convergence rates. A complementary family of solutions makes use of explicit \emph{models} for the feedback, such as best-response models in strategic classification, enabling significantly faster rates. However, these rates critically rely on the feedback model being well-specified. In this work we initiate a study of the use of possibly \emph{misspecified} models in performative prediction. We study a general protocol for making use of models, called \emph{plug-in performative optimization}, a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#20849;&#26354;&#25233;&#21046;&#27491;&#21017;&#21270;&#22120;&#65292;&#29992;&#20110;&#24212;&#23545;&#24191;&#20041;&#21152;&#24615;&#27169;&#22411;&#26131;&#21463;&#20849;&#38169;&#24615;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#24809;&#32602;&#38750;&#32447;&#24615;&#36716;&#25442;&#30340;&#29305;&#24449;&#21464;&#37327;&#30340;&#25104;&#23545;&#30456;&#20851;&#24615;&#65292;&#22686;&#24378;&#20102;&#27169;&#22411;&#30340;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.11475</link><description>&lt;p&gt;
&#26354;&#32447;&#19978;&#25196;&#65306;&#22312;&#21487;&#24494;&#24191;&#20041;&#21152;&#24615;&#27169;&#22411;&#20013;&#30340;&#20849;&#26354;&#25233;&#21046;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Curve Your Enthusiasm: Concurvity Regularization in Differentiable Generalized Additive Models. (arXiv:2305.11475v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11475
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#20849;&#26354;&#25233;&#21046;&#27491;&#21017;&#21270;&#22120;&#65292;&#29992;&#20110;&#24212;&#23545;&#24191;&#20041;&#21152;&#24615;&#27169;&#22411;&#26131;&#21463;&#20849;&#38169;&#24615;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#24809;&#32602;&#38750;&#32447;&#24615;&#36716;&#25442;&#30340;&#29305;&#24449;&#21464;&#37327;&#30340;&#25104;&#23545;&#30456;&#20851;&#24615;&#65292;&#22686;&#24378;&#20102;&#27169;&#22411;&#30340;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#30001;&#20110;&#24191;&#20041;&#21152;&#24615;&#27169;&#22411;&#65288;GAM&#65289;&#21487;&#34920;&#36798;&#30446;&#26631;&#21464;&#37327;&#20026;&#29305;&#24449;&#30340;&#38750;&#32447;&#24615;&#21464;&#25442;&#21644;&#35299;&#37322;&#24615;&#65292;&#20854;&#20877;&#27425;&#21463;&#21040;&#27426;&#36814;&#12290;&#23613;&#31649;GAM&#30446;&#21069;&#22791;&#21463;&#28909;&#25447;&#65292;&#20294;&#20854;&#26131;&#21463;&#20849;&#38169;&#24615;&#65292;&#21363;&#29305;&#24449;&#20043;&#38388;&#30340;&#65288;&#21487;&#33021;&#26159;&#38750;&#32447;&#24615;&#30340;&#65289;&#20381;&#36182;&#24615;&#36804;&#20170;&#20026;&#27490;&#22823;&#22810;&#34987;&#24573;&#35270;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20849;&#38169;&#24615;&#22914;&#20309;&#20005;&#37325;&#30772;&#22351;GAM&#30340;&#35299;&#37322;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#35299;&#20915;&#26041;&#27861;&#65306;&#19968;&#20010;&#22312;&#38750;&#32447;&#24615;&#36716;&#25442;&#30340;&#29305;&#24449;&#21464;&#37327;&#30340;&#25104;&#23545;&#30456;&#20851;&#24615;&#19978;&#36827;&#34892;&#24809;&#32602;&#30340;&#27010;&#24565;&#31616;&#21333;&#20294;&#26377;&#25928;&#30340;&#27491;&#21017;&#21270;&#22120;&#12290;&#35813;&#36807;&#31243;&#36866;&#29992;&#20110;&#20219;&#20309;&#21487;&#24494;&#30340;&#21152;&#24615;&#27169;&#22411;&#65292;&#22914;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#25110;&#31070;&#32463;&#39044;&#35328;&#12290;&#24182;&#19988;&#36890;&#36807;&#28040;&#38500;&#33258;&#25105;&#25269;&#28040;&#30340;&#29305;&#24449;&#36129;&#29486;&#30340;&#27495;&#20041;&#65292;&#22686;&#24378;&#20102;&#35299;&#37322;&#24615;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#26102;&#38388;&#24207;&#21015;&#21644;&#34920;&#26684;&#25968;&#25454;&#38598;&#19978;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#27491;&#21017;&#21270;&#22120;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generalized Additive Models (GAMs) have recently experienced a resurgence in popularity due to their interpretability, which arises from expressing the target value as a sum of non-linear transformations of the features. Despite the current enthusiasm for GAMs, their susceptibility to concurvity - i.e., (possibly non-linear) dependencies between the features - has hitherto been largely overlooked. Here, we demonstrate how concurvity can severly impair the interpretability of GAMs and propose a remedy: a conceptually simple, yet effective regularizer which penalizes pairwise correlations of the non-linearly transformed feature variables. This procedure is applicable to any differentiable additive model, such as Neural Additive Models or NeuralProphet, and enhances interpretability by eliminating ambiguities due to self-canceling feature contributions. We validate the effectiveness of our regularizer in experiments on synthetic as well as real-world datasets for time-series and tabular d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20381;&#36182;&#25968;&#25454;&#30340;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#22122;&#22768;&#27700;&#24179;&#65292;&#25552;&#20986;&#20102;&#19978;&#38480;&#30028;&#38480;&#65292;&#24182;&#22312;&#35823;&#24046;&#35268;&#33539;&#19979;&#34920;&#29616;&#20986;&#20248;&#38597;&#30340;&#38477;&#20302;&#12290;</title><link>http://arxiv.org/abs/2305.11165</link><description>&lt;p&gt;
&#32447;&#24615;&#22238;&#24402;&#20013;&#20381;&#36182;&#25968;&#25454;&#30340;&#22122;&#22768;&#27700;&#24179;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
The noise level in linear regression with dependent data. (arXiv:2305.11165v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11165
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20381;&#36182;&#25968;&#25454;&#30340;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#22122;&#22768;&#27700;&#24179;&#65292;&#25552;&#20986;&#20102;&#19978;&#38480;&#30028;&#38480;&#65292;&#24182;&#22312;&#35823;&#24046;&#35268;&#33539;&#19979;&#34920;&#29616;&#20986;&#20248;&#38597;&#30340;&#38477;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20174;&#26410;&#20570;&#20219;&#20309;&#23454;&#29616;&#20551;&#35774;&#20986;&#21457;&#65292;&#23545;&#20110;&#20855;&#26377;&#20381;&#36182;($\beta$-mixing)&#25968;&#25454;&#30340;&#38543;&#26426;&#35774;&#35745;&#32447;&#24615;&#22238;&#24402;&#65292;&#25512;&#23548;&#20102;&#20854;&#19978;&#38480;&#30028;&#38480;&#12290;&#19982;&#20165;&#22312;&#21487;&#23454;&#29616;&#30340;&#38789;&#22122;&#22768;&#33539;&#22260;&#20869;&#19981;&#21487;&#29992;&#23574;&#38160;&#30340;&#23454;&#20363;&#26368;&#20248;&#38750;&#28176;&#36817;&#24615;&#30456;&#27604;&#65292;&#25991;&#29486;&#20013;&#27809;&#26377;&#21487;&#29992;&#30340;&#19978;&#38480;&#30028;&#38480;&#12290;&#22312;&#24688;&#24403;&#30340;&#24120;&#25968;&#22240;&#32032;&#19979;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#27491;&#30830;&#22320;&#22238;&#24402;&#20102;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#39044;&#27979;&#30340;&#26041;&#24046;&#39033; - &#38382;&#39064;&#30340;&#22122;&#22768;&#27700;&#24179; - &#24182;&#22240;&#27492;&#22312;&#24341;&#20837;&#38169;&#35823;&#35268;&#33539;&#26102;&#34920;&#29616;&#20986;&#36880;&#28176;&#38477;&#20302;&#30340;&#20248;&#38597;&#24615;&#12290;&#22312;&#39044;&#29123;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#22312;&#20013;&#24230;&#20559;&#24046;&#33539;&#22260;&#20869;&#26159;&#23574;&#38160;&#30340;&#65292;&#29305;&#21035;&#26159;&#19981;&#20250;&#33192;&#32960;&#24341;&#39046;&#39033;&#26399;&#38480;&#19982;&#28151;&#21512;&#26102;&#38388;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;
We derive upper bounds for random design linear regression with dependent ($\beta$-mixing) data absent any realizability assumptions. In contrast to the strictly realizable martingale noise regime, no sharp instance-optimal non-asymptotics are available in the literature. Up to constant factors, our analysis correctly recovers the variance term predicted by the Central Limit Theorem -- the noise level of the problem -- and thus exhibits graceful degradation as we introduce misspecification. Past a burn-in, our result is sharp in the moderate deviations regime, and in particular does not inflate the leading order term by mixing time factors.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21512;&#25104;&#32463;&#39564;&#22238;&#25918;&#26041;&#27861;&#35299;&#20915;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#25968;&#25454;&#21294;&#20047;&#38382;&#39064;&#65292;&#36890;&#36807;&#24039;&#22937;&#24212;&#29992;&#29983;&#25104;&#24314;&#27169;&#25216;&#26415;&#26469;&#25193;&#20805;&#25968;&#25454;&#25928;&#26524;&#26174;&#33879;&#12290;</title><link>http://arxiv.org/abs/2303.06614</link><description>&lt;p&gt;
&#21512;&#25104;&#32463;&#39564;&#22238;&#25918;&#65306;&#26088;&#22312;&#29992;&#25193;&#20805;&#25968;&#25454;&#26469;&#25552;&#39640;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#25928;&#26524;
&lt;/p&gt;
&lt;p&gt;
Synthetic Experience Replay. (arXiv:2303.06614v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06614
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21512;&#25104;&#32463;&#39564;&#22238;&#25918;&#26041;&#27861;&#35299;&#20915;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#25968;&#25454;&#21294;&#20047;&#38382;&#39064;&#65292;&#36890;&#36807;&#24039;&#22937;&#24212;&#29992;&#29983;&#25104;&#24314;&#27169;&#25216;&#26415;&#26469;&#25193;&#20805;&#25968;&#25454;&#25928;&#26524;&#26174;&#33879;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#21435;&#21313;&#24180;&#30340;&#19968;&#20010;&#20851;&#38190;&#20027;&#39064;&#26159;&#65292;&#24403;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#21644;&#22823;&#22411;&#25968;&#25454;&#38598;&#30456;&#32467;&#21512;&#26102;&#65292;&#23427;&#20204;&#21487;&#20197;&#20135;&#29983;&#20196;&#20154;&#24778;&#24322;&#30340;&#32467;&#26524;&#12290;&#22312;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#36825;&#31181;&#33539;&#24335;&#36890;&#24120;&#36890;&#36807;&#32463;&#39564;&#22238;&#25918;&#23454;&#29616;&#65292;&#20854;&#20013;&#36807;&#21435;&#30340;&#32463;&#39564;&#25968;&#25454;&#38598;&#29992;&#20110;&#35757;&#32451;&#31574;&#30053;&#25110;&#20540;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#19982;&#30417;&#30563;&#23398;&#20064;&#25110;&#33258;&#30417;&#30563;&#23398;&#20064;&#19981;&#21516;&#65292;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#24517;&#39035;&#25910;&#38598;&#33258;&#24049;&#30340;&#25968;&#25454;&#65292;&#36825;&#36890;&#24120;&#26159;&#26377;&#38480;&#30340;&#12290;&#22240;&#27492;&#65292;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#30340;&#22909;&#22788;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#21363;&#20351;&#26159;&#23567;&#22411;&#31070;&#32463;&#32593;&#32476;&#22312;&#35757;&#32451;&#24320;&#22987;&#26102;&#20063;&#21487;&#33021;&#20986;&#29616;&#36807;&#25311;&#21512;&#29616;&#35937;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#20102;&#29983;&#25104;&#24314;&#27169;&#30340;&#24040;&#22823;&#36827;&#27493;&#65292;&#24182;&#25552;&#20986;&#20102;&#21512;&#25104;&#32463;&#39564;&#22238;&#25918;&#65288;SynthER&#65289;&#65292;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#30340;&#26041;&#27861;&#26469;&#28789;&#27963;&#22320;&#19978;&#37319;&#26679;&#20195;&#29702;&#25910;&#38598;&#30340;&#32463;&#39564;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;SynthER&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#31163;&#32447;&#21644;&#22312;&#32447;&#35774;&#32622;&#19979;&#35757;&#32451;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#65292;&#26080;&#35770;&#26159;&#22312;&#24863;&#30693;&#29615;&#22659;&#36824;&#26159;&#22312;&#20687;&#32032;&#29615;&#22659;&#20013;&#12290;&#22312;&#31163;&#32447;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#20102;&#26174;&#30528;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
A key theme in the past decade has been that when large neural networks and large datasets combine they can produce remarkable results. In deep reinforcement learning (RL), this paradigm is commonly made possible through experience replay, whereby a dataset of past experiences is used to train a policy or value function. However, unlike in supervised or self-supervised learning, an RL agent has to collect its own data, which is often limited. Thus, it is challenging to reap the benefits of deep learning, and even small neural networks can overfit at the start of training. In this work, we leverage the tremendous recent progress in generative modeling and propose Synthetic Experience Replay (SynthER), a diffusion-based approach to flexibly upsample an agent's collected experience. We show that SynthER is an effective method for training RL agents across offline and online settings, in both proprioceptive and pixel-based environments. In offline settings, we observe drastic improvements 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24322;&#36136;&#20998;&#24067;&#20559;&#31227;&#19979;&#30340;&#32479;&#35745;&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#30740;&#31350;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;(ERM)&#22312;&#19981;&#21516;&#31867;&#21035;&#30340;&#22797;&#26434;&#24615;&#19979;&#30340;&#34920;&#29616;&#65292;&#25105;&#20204;&#21457;&#29616;&#24403;&#31867;&#21035;$F$&#30456;&#27604;&#31867;&#21035;$G$&#26356;&#8220;&#31616;&#21333;&#8221;&#26102;&#65292;&#25105;&#20204;&#30340;&#39044;&#27979;&#22120;&#23545;&#20110;&#21327;&#21464;&#37327;&#20559;&#31227;&#20855;&#26377;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#65292;&#23588;&#20854;&#22312;$\textbf{y}$&#30340;&#20559;&#31227;&#36828;&#23567;&#20110;$\textbf{x}$&#30340;&#24773;&#20917;&#19979;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#21457;&#29616;ERM&#30340;&#34892;&#20026;&#19982;&#27491;&#20132;&#26426;&#22120;&#23398;&#20064;&#20855;&#26377;&#31867;&#20284;&#30340;&#29305;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.13934</link><description>&lt;p&gt;
&#24322;&#36136;&#20998;&#24067;&#20559;&#31227;&#19979;&#30340;&#32479;&#35745;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Statistical Learning under Heterogenous Distribution Shift. (arXiv:2302.13934v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.13934
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24322;&#36136;&#20998;&#24067;&#20559;&#31227;&#19979;&#30340;&#32479;&#35745;&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#30740;&#31350;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;(ERM)&#22312;&#19981;&#21516;&#31867;&#21035;&#30340;&#22797;&#26434;&#24615;&#19979;&#30340;&#34920;&#29616;&#65292;&#25105;&#20204;&#21457;&#29616;&#24403;&#31867;&#21035;$F$&#30456;&#27604;&#31867;&#21035;$G$&#26356;&#8220;&#31616;&#21333;&#8221;&#26102;&#65292;&#25105;&#20204;&#30340;&#39044;&#27979;&#22120;&#23545;&#20110;&#21327;&#21464;&#37327;&#20559;&#31227;&#20855;&#26377;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#65292;&#23588;&#20854;&#22312;$\textbf{y}$&#30340;&#20559;&#31227;&#36828;&#23567;&#20110;$\textbf{x}$&#30340;&#24773;&#20917;&#19979;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#21457;&#29616;ERM&#30340;&#34892;&#20026;&#19982;&#27491;&#20132;&#26426;&#22120;&#23398;&#20064;&#20855;&#26377;&#31867;&#20284;&#30340;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#38543;&#26426;&#21464;&#37327;&#23545;$(\mathbf{x},\mathbf{y})$&#20013;&#39044;&#27979;&#30446;&#26631;$\mathbf{z}$, &#20854;&#20013;&#30495;&#23454;&#30340;&#39044;&#27979;&#22120;&#26159;&#21152;&#27861;&#30340;$\mathbb{E}[\mathbf{z} \mid \mathbf{x},\mathbf{y}] = f_\star(\mathbf{x}) +g_{\star}(\mathbf{y})$&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32473;&#23450;&#35757;&#32451;&#20998;&#24067;&#19978;&#25311;&#21512;&#30340;&#20989;&#25968;$f+g$, $f \in F$&#21644;$g \in G$&#19978;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;(ERM)&#22312;&#34920;&#29616;&#19978;&#30340;&#24046;&#24322;&#65292;&#20294;&#22312;&#27979;&#35797;&#20998;&#24067;&#19978;&#24471;&#21040;&#35780;&#20272;&#26102;&#20250;&#26174;&#31034;&#20986;&#21327;&#21464;&#37327;&#20559;&#31227;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#24403;&#31867;&#21035;$F$&#27604;$G$&#26356;&#8220;&#31616;&#21333;&#8221;&#65288;&#20363;&#22914;&#65292;&#20197;&#24230;&#37327;&#29109;&#20026;&#34913;&#37327;&#26631;&#20934;&#65289;&#26102;&#65292;&#25105;&#20204;&#30340;&#39044;&#27979;&#22120;&#23545;&#20110;&#21327;&#21464;&#37327;&#20559;&#31227;&#30340;&#25239;&#24178;&#25200;&#33021;&#21147;&#26356;&#24378;&#65292;&#20854;&#20013;$\textbf{y}$&#30340;&#20559;&#31227;&#35201;&#36828;&#23567;&#20110;$\textbf{x}$&#30340;&#20559;&#31227;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;ERM&#30340;&#34892;&#20026;&#19982;&#27491;&#20132;&#26426;&#22120;&#23398;&#20064;$\textbf{ qualitatively similarly}$&#65306;ERM&#24674;&#22797;&#39044;&#27979;&#22120;&#20013;&#30340;$f$&#25104;&#20998;&#30340;&#36895;&#29575;&#20165;&#23545;&#20110;&#31867;&#21035;$G$&#30340;&#22797;&#26434;&#24615;&#20855;&#26377;&#36739;&#20302;&#38454;&#30340;&#20381;&#36182;&#24615;&#65292;&#35843;&#25972;&#21518;...
&lt;/p&gt;
&lt;p&gt;
This paper studies the prediction of a target $\mathbf{z}$ from a pair of random variables $(\mathbf{x},\mathbf{y})$, where the ground-truth predictor is additive $\mathbb{E}[\mathbf{z} \mid \mathbf{x},\mathbf{y}] = f_\star(\mathbf{x}) +g_{\star}(\mathbf{y})$. We study the performance of empirical risk minimization (ERM) over functions $f+g$, $f \in F$ and $g \in G$, fit on a given training distribution, but evaluated on a test distribution which exhibits covariate shift. We show that, when the class $F$ is "simpler" than $G$ (measured, e.g., in terms of its metric entropy), our predictor is more resilient to $\textbf{heterogenous covariate shifts}$ in which the shift in $\mathbf{x}$ is much greater than that in $\mathbf{y}$. Our analysis proceeds by demonstrating that ERM behaves $\textbf{qualitatively similarly to orthogonal machine learning}$: the rate at which ERM recovers the $f$-component of the predictor has only a lower-order dependence on the complexity of the class $G$, adjus
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#25193;&#23637;&#20102;VAE&#27169;&#22411;&#23481;&#37327;&#65292;&#37319;&#29992;&#26080;&#38480;&#28151;&#21512;&#30340;&#38750;&#23545;&#31216;&#25289;&#26222;&#25289;&#26031;&#20998;&#24067;&#20316;&#20026;&#35299;&#30721;&#22120;&#65292;&#20855;&#26377;&#20998;&#24067;&#25311;&#21512;&#33021;&#21147;&#21644;&#35843;&#25972;&#25968;&#25454;&#38544;&#31169;&#32423;&#21035;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.11294</link><description>&lt;p&gt;
&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#20998;&#24067;&#24335;&#23398;&#20064;&#65306;&#22312;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Distributional Learning of Variational AutoEncoder: Application to Synthetic Data Generation. (arXiv:2302.11294v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.11294
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#25193;&#23637;&#20102;VAE&#27169;&#22411;&#23481;&#37327;&#65292;&#37319;&#29992;&#26080;&#38480;&#28151;&#21512;&#30340;&#38750;&#23545;&#31216;&#25289;&#26222;&#25289;&#26031;&#20998;&#24067;&#20316;&#20026;&#35299;&#30721;&#22120;&#65292;&#20855;&#26377;&#20998;&#24067;&#25311;&#21512;&#33021;&#21147;&#21644;&#35843;&#25972;&#25968;&#25454;&#38544;&#31169;&#32423;&#21035;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#22312;&#35745;&#31639;&#24314;&#27169;&#26041;&#38754;&#24456;&#39640;&#25928;&#65292;&#20294;&#39640;&#26031;&#20551;&#35774;&#19968;&#30452;&#34987;&#35748;&#20026;&#26159;&#23427;&#30340;&#20027;&#35201;&#23616;&#38480;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;&#27169;&#22411;&#23481;&#37327;&#65288;&#21363;&#20998;&#24067;&#26063;&#30340;&#34920;&#36798;&#33021;&#21147;&#65289;&#65292;&#32780;&#19981;&#20250;&#29306;&#29298;VAE&#26694;&#26550;&#30340;&#35745;&#31639;&#20248;&#21183;&#12290;&#25105;&#20204;&#30340;VAE&#27169;&#22411;&#30340;&#35299;&#30721;&#22120;&#30001;&#26080;&#38480;&#32452;&#21512;&#30340;&#38750;&#23545;&#31216;&#25289;&#26222;&#25289;&#26031;&#20998;&#24067;&#26500;&#25104;&#65292;&#20855;&#26377;&#36830;&#32493;&#21464;&#37327;&#30340;&#20998;&#24067;&#25311;&#21512;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#30001;&#20272;&#35745;&#19968;&#33324;&#20998;&#20301;&#20989;&#25968;&#30340;&#38750;&#21442;&#25968;M-estimator&#30340;&#29305;&#27530;&#24418;&#24335;&#34920;&#31034;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#24314;&#31435;&#20102;&#25152;&#25552;&#20986;&#27169;&#22411;&#19982;&#20998;&#20301;&#25968;&#20272;&#35745;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#23558;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#24212;&#29992;&#20110;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#65292;&#29305;&#21035;&#26159;&#22312;&#36731;&#26494;&#35843;&#25972;&#25968;&#25454;&#38544;&#31169;&#32423;&#21035;&#26041;&#38754;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#23637;&#29616;&#20102;&#20854;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Gaussianity assumption has been consistently criticized as a main limitation of the Variational Autoencoder (VAE), despite its efficiency in computational modeling. In this paper, we propose a new approach that expands the model capacity (i.e., expressive power of distributional family) without sacrificing the computational advantages of the VAE framework. Our VAE model's decoder is composed of an infinite mixture of asymmetric Laplacian distribution, which possesses general distribution fitting capabilities for continuous variables. Our model is represented by a special form of a nonparametric M-estimator for estimating general quantile functions, and we theoretically establish the relevance between the proposed model and quantile estimation. We apply the proposed model to synthetic data generation, and particularly, our model demonstrates superiority in easily adjusting the level of data privacy.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#26410;&#37197;&#23545;&#30340;&#22810;&#39046;&#22495;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#65292;&#25552;&#20986;&#20102;&#32447;&#24615;&#27169;&#22411;&#19979;&#32852;&#21512;&#20998;&#24067;&#21644;&#20849;&#20139;&#22240;&#26524;&#22270;&#30340;&#21487;&#35782;&#21035;&#26465;&#20214;&#65292;&#24182;&#23558;&#20854;&#36716;&#21270;&#20026;&#19968;&#31181;&#23454;&#29992;&#26041;&#27861;&#20197;&#24674;&#22797;&#20849;&#20139;&#30340;&#28508;&#22312;&#22240;&#26524;&#22270;&#12290;</title><link>http://arxiv.org/abs/2302.00993</link><description>&lt;p&gt;
&#26410;&#37197;&#23545;&#30340;&#22810;&#39046;&#22495;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Unpaired Multi-Domain Causal Representation Learning. (arXiv:2302.00993v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00993
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#26410;&#37197;&#23545;&#30340;&#22810;&#39046;&#22495;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#65292;&#25552;&#20986;&#20102;&#32447;&#24615;&#27169;&#22411;&#19979;&#32852;&#21512;&#20998;&#24067;&#21644;&#20849;&#20139;&#22240;&#26524;&#22270;&#30340;&#21487;&#35782;&#21035;&#26465;&#20214;&#65292;&#24182;&#23558;&#20854;&#36716;&#21270;&#20026;&#19968;&#31181;&#23454;&#29992;&#26041;&#27861;&#20197;&#24674;&#22797;&#20849;&#20139;&#30340;&#28508;&#22312;&#22240;&#26524;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#30340;&#30446;&#26631;&#26159;&#25214;&#21040;&#30001;&#22240;&#26524;&#30456;&#20851;&#30340;&#28508;&#22312;&#21464;&#37327;&#32452;&#25104;&#30340;&#25968;&#25454;&#34920;&#31034;&#12290;&#25105;&#20204;&#32771;&#34385;&#19968;&#20010;&#24773;&#26223;&#65292;&#20854;&#20013;&#25105;&#20204;&#21487;&#20197;&#35775;&#38382;&#26469;&#33258;&#21487;&#33021;&#20849;&#20139;&#22240;&#26524;&#34920;&#31034;&#30340;&#22810;&#20010;&#39046;&#22495;&#30340;&#25968;&#25454;&#12290;&#20851;&#38190;&#22312;&#20110;&#65292;&#20551;&#35774;&#19981;&#21516;&#39046;&#22495;&#30340;&#35266;&#27979;&#32467;&#26524;&#26159;&#26410;&#37197;&#23545;&#30340;&#65292;&#20063;&#23601;&#26159;&#35828;&#65292;&#25105;&#20204;&#21482;&#35266;&#23519;&#27599;&#20010;&#39046;&#22495;&#30340;&#36793;&#32536;&#20998;&#24067;&#65292;&#32780;&#19981;&#26159;&#23427;&#20204;&#30340;&#32852;&#21512;&#20998;&#24067;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#32447;&#24615;&#27169;&#22411;&#19979;&#32852;&#21512;&#20998;&#24067;&#21644;&#20849;&#20139;&#22240;&#26524;&#22270;&#21487;&#35782;&#21035;&#24615;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#21482;&#35201;&#25105;&#20204;&#33021;&#22815;&#20174;&#27599;&#20010;&#39046;&#22495;&#30340;&#36793;&#32536;&#20998;&#24067;&#20013;&#21807;&#19968;&#24674;&#22797;&#32852;&#21512;&#20998;&#24067;&#21644;&#20849;&#20139;&#22240;&#26524;&#34920;&#31034;&#65292;&#21487;&#35782;&#21035;&#24615;&#23601;&#33021;&#22815;&#25104;&#31435;&#12290;&#25105;&#20204;&#23558;&#35782;&#21035;&#24615;&#32467;&#26524;&#36716;&#21270;&#20026;&#19968;&#31181;&#23454;&#29992;&#26041;&#27861;&#65292;&#29992;&#20110;&#24674;&#22797;&#20849;&#20139;&#30340;&#28508;&#22312;&#22240;&#26524;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;
The goal of causal representation learning is to find a representation of data that consists of causally related latent variables. We consider a setup where one has access to data from multiple domains that potentially share a causal representation. Crucially, observations in different domains are assumed to be unpaired, that is, we only observe the marginal distribution in each domain but not their joint distribution. In this paper, we give sufficient conditions for identifiability of the joint distribution and the shared causal graph in a linear setup. Identifiability holds if we can uniquely recover the joint distribution and the shared causal representation from the marginal distributions in each domain. We transform our identifiability results into a practical method to recover the shared latent causal graph.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;ReSQue&#30340;&#24037;&#20855;&#65292;&#29992;&#20110;&#22788;&#29702;&#38543;&#26426;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#36890;&#36807;&#23558;ReSQue&#19982;&#26368;&#26032;&#30340;&#29699;&#39044;&#35328;&#21152;&#36895;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#22312;&#24182;&#34892;&#21644;&#31169;&#23494;&#29615;&#22659;&#19979;&#36798;&#21040;&#26368;&#20808;&#36827;&#22797;&#26434;&#24230;&#30340;&#31639;&#27861;&#12290;&#23545;&#20110;&#22312;&#21333;&#20301;&#29699;&#20013;&#30340;&#20984;&#20248;&#21270;&#30446;&#26631;&#65292;&#20316;&#32773;&#30340;&#31639;&#27861;&#33021;&#22815;&#22312;&#31526;&#21512;&#19968;&#23450;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20248;&#21270;&#35823;&#24046;&#65292;&#21516;&#26102;&#20445;&#25345;&#26368;&#20339;&#24635;&#20307;&#24037;&#20316;&#37327;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2301.00457</link><description>&lt;p&gt;
ReSQue&#30340;&#24182;&#34892;&#21644;&#31169;&#23494;&#38543;&#26426;&#20984;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
ReSQueing Parallel and Private Stochastic Convex Optimization. (arXiv:2301.00457v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.00457
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;ReSQue&#30340;&#24037;&#20855;&#65292;&#29992;&#20110;&#22788;&#29702;&#38543;&#26426;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#36890;&#36807;&#23558;ReSQue&#19982;&#26368;&#26032;&#30340;&#29699;&#39044;&#35328;&#21152;&#36895;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#22312;&#24182;&#34892;&#21644;&#31169;&#23494;&#29615;&#22659;&#19979;&#36798;&#21040;&#26368;&#20808;&#36827;&#22797;&#26434;&#24230;&#30340;&#31639;&#27861;&#12290;&#23545;&#20110;&#22312;&#21333;&#20301;&#29699;&#20013;&#30340;&#20984;&#20248;&#21270;&#30446;&#26631;&#65292;&#20316;&#32773;&#30340;&#31639;&#27861;&#33021;&#22815;&#22312;&#31526;&#21512;&#19968;&#23450;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20248;&#21270;&#35823;&#24046;&#65292;&#21516;&#26102;&#20445;&#25345;&#26368;&#20339;&#24635;&#20307;&#24037;&#20316;&#37327;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#20984;&#20248;&#21270;&#65288;SCO&#65289;&#24037;&#20855;&#65306;&#19968;&#31181;&#22522;&#20110;&#37325;&#21152;&#26435;&#38543;&#26426;&#26597;&#35810;&#65288;ReSQue&#65289;&#30340;&#26799;&#24230;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#19982;&#65288;&#39640;&#26031;&#65289;&#27010;&#29575;&#23494;&#24230;&#21367;&#31215;&#30340;&#20989;&#25968;&#30340;&#26799;&#24230;&#12290;&#23558;ReSQue&#19982;&#26368;&#26032;&#30340;&#29699;&#39044;&#35328;&#21152;&#36895;&#25216;&#26415;&#30456;&#32467;&#21512;[CJJJLST20, ACJJS21]&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#22312;&#24182;&#34892;&#21644;&#31169;&#23494;&#29615;&#22659;&#19979;&#23454;&#29616;SCO&#30340;&#31639;&#27861;&#65292;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#22797;&#26434;&#24230;&#12290;&#23545;&#20110;$\mathbb{R}^d$&#20013;&#34987;&#21333;&#20301;&#29699;&#32422;&#26463;&#30340;SCO&#30446;&#26631;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#20197;&#19979;&#32467;&#26524;&#65288;&#22810;&#23545;&#25968;&#22240;&#23376;&#65289;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#24182;&#34892;&#31639;&#27861;&#65292;&#36890;&#36807;$d^{1/3}\epsilon_{\text{opt}}^{-2/3}$&#26799;&#24230;&#39044;&#35328;&#26597;&#35810;&#28145;&#24230;&#21644;$d^{1/3}\epsilon_{\text{opt}}^{-2/3} + \epsilon_{\text{opt}}^{-2}$&#24635;&#26799;&#24230;&#26597;&#35810;&#25968;&#65292;&#20197; $\epsilon_{\text{opt}}$ &#33719;&#24471;&#20248;&#21270;&#35823;&#24046;&#65292;&#20551;&#35774;&#21487;&#20197;&#35775;&#38382;&#19968;&#20010;&#26377;&#30028;&#26041;&#24046;&#30340;&#38543;&#26426;&#26799;&#24230;&#20272;&#35745;&#22120;&#12290;&#23545;&#20110;$\epsilon_{\text{opt}} \in [d^{-1}, d^{-1/4}]$&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#19982;[BJLLS19]&#30340;&#26368;&#20808;&#36827;&#39044;&#35328;&#28145;&#24230;&#30456;&#21305;&#37197;&#65292;&#21516;&#26102;&#20445;&#25345;&#26368;&#20339;&#24635;&#20307;&#24037;&#20316;&#37327;
&lt;/p&gt;
&lt;p&gt;
We introduce a new tool for stochastic convex optimization (SCO): a Reweighted Stochastic Query (ReSQue) estimator for the gradient of a function convolved with a (Gaussian) probability density. Combining ReSQue with recent advances in ball oracle acceleration [CJJJLST20, ACJJS21], we develop algorithms achieving state-of-the-art complexities for SCO in parallel and private settings. For a SCO objective constrained to the unit ball in $\mathbb{R}^d$, we obtain the following results (up to polylogarithmic factors). We give a parallel algorithm obtaining optimization error $\epsilon_{\text{opt}}$ with $d^{1/3}\epsilon_{\text{opt}}^{-2/3}$ gradient oracle query depth and $d^{1/3}\epsilon_{\text{opt}}^{-2/3} + \epsilon_{\text{opt}}^{-2}$ gradient queries in total, assuming access to a bounded-variance stochastic gradient estimator. For $\epsilon_{\text{opt}} \in [d^{-1}, d^{-1/4}]$, our algorithm matches the state-of-the-art oracle depth of [BJLLS19] while maintaining the optimal total wor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20943;&#23567;&#20559;&#24046;&#21644;&#20135;&#29983;&#26356;&#20934;&#30830;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#36817;&#20284;&#21518;&#39564;&#35843;&#25972;&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#36817;&#20284;&#21518;&#39564;&#30340;&#21464;&#25442;&#26469;&#26368;&#22823;&#21270;&#24471;&#20998;&#35268;&#21017;&#12290;&#36825;&#31181;&#26041;&#27861;&#21482;&#38656;&#35201;&#36827;&#34892;&#23569;&#37327;&#22797;&#26434;&#27169;&#22411;&#27169;&#25311;&#65292;&#19988;&#20855;&#26377;&#25968;&#20540;&#31283;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2211.05357</link><description>&lt;p&gt;
&#36866;&#29992;&#20110;&#36817;&#20284;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#24471;&#20998;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Bayesian score calibration for approximate models. (arXiv:2211.05357v4 [stat.CO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.05357
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20943;&#23567;&#20559;&#24046;&#21644;&#20135;&#29983;&#26356;&#20934;&#30830;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#36817;&#20284;&#21518;&#39564;&#35843;&#25972;&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#36817;&#20284;&#21518;&#39564;&#30340;&#21464;&#25442;&#26469;&#26368;&#22823;&#21270;&#24471;&#20998;&#35268;&#21017;&#12290;&#36825;&#31181;&#26041;&#27861;&#21482;&#38656;&#35201;&#36827;&#34892;&#23569;&#37327;&#22797;&#26434;&#27169;&#22411;&#27169;&#25311;&#65292;&#19988;&#20855;&#26377;&#25968;&#20540;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31185;&#23398;&#23478;&#20204;&#19981;&#26029;&#21457;&#23637;&#36234;&#26469;&#36234;&#22797;&#26434;&#30340;&#26426;&#26800;&#27169;&#22411;&#65292;&#20197;&#26356;&#30495;&#23454;&#22320;&#21453;&#26144;&#20182;&#20204;&#30340;&#30693;&#35782;&#12290;&#20351;&#29992;&#36825;&#20123;&#27169;&#22411;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#30456;&#24212;&#30340;&#20284;&#28982;&#20989;&#25968;&#36890;&#24120;&#38590;&#20197;&#22788;&#29702;&#65292;&#24182;&#19988;&#27169;&#22411;&#27169;&#25311;&#21487;&#33021;&#24102;&#26469;&#35745;&#31639;&#36127;&#25285;&#12290;&#24184;&#36816;&#30340;&#26159;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#37319;&#29992;&#26367;&#20195;&#27169;&#22411;&#25110;&#36817;&#20284;&#20284;&#28982;&#20989;&#25968;&#12290;&#30452;&#25509;&#20351;&#29992;&#26367;&#20195;&#20284;&#28982;&#20989;&#25968;&#36827;&#34892;&#36125;&#21494;&#26031;&#25512;&#26029;&#21487;&#33021;&#24456;&#26041;&#20415;&#65292;&#20294;&#21487;&#33021;&#23548;&#33268;&#20559;&#24046;&#21644;&#19981;&#20934;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#36817;&#20284;&#21518;&#39564;&#30340;&#21464;&#25442;&#26469;&#26368;&#22823;&#21270;&#24471;&#20998;&#35268;&#21017;&#65292;&#20174;&#32780;&#20943;&#23567;&#20559;&#24046;&#24182;&#20135;&#29983;&#26356;&#20934;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21482;&#38656;&#35201;&#36827;&#34892;&#65288;&#22266;&#23450;&#30340;&#65289;&#23569;&#37327;&#22797;&#26434;&#27169;&#22411;&#27169;&#25311;&#65292;&#19988;&#20855;&#26377;&#25968;&#20540;&#31283;&#23450;&#24615;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#19981;&#26029;&#22686;&#21152;&#30340;&#31034;&#20363;&#19978;&#23637;&#31034;&#20102;&#26032;&#26041;&#27861;&#30340;&#33391;&#22909;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Scientists continue to develop increasingly complex mechanistic models to reflect their knowledge more realistically. Statistical inference using these models can be challenging since the corresponding likelihood function is often intractable and model simulation may be computationally burdensome. Fortunately, in many of these situations, it is possible to adopt a surrogate model or approximate likelihood function. It may be convenient to conduct Bayesian inference directly with the surrogate, but this can result in bias and poor uncertainty quantification. In this paper we propose a new method for adjusting approximate posterior samples to reduce bias and produce more accurate uncertainty quantification. We do this by optimizing a transform of the approximate posterior that maximizes a scoring rule. Our approach requires only a (fixed) small number of complex model simulations and is numerically stable. We demonstrate good performance of the new method on several examples of increasin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411; (dlglm) &#21450;&#20854;&#22312;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#20013;&#30340;&#24212;&#29992;&#65292;&#20854;&#20013;&#30340;&#26041;&#27861;&#33021;&#22815;&#28789;&#27963;&#22320;&#22788;&#29702;&#36755;&#20837;&#29305;&#24449;&#21644;&#21709;&#24212;&#30340;&#21487;&#24573;&#30053;&#21644;&#19981;&#21487;&#24573;&#30053;&#30340;&#32570;&#22833;&#27169;&#24335;&#12290;&#25105;&#20204;&#36890;&#36807;&#32479;&#35745;&#27169;&#25311;&#35777;&#26126;&#65292;&#22312;&#32570;&#22833;&#25968;&#25454;&#19981;&#38543;&#26426;&#30340;&#24773;&#20917;&#19979;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#29983;&#29289;&#21307;&#23398;&#31185;&#23398;&#31561;&#39046;&#22495;&#20013;&#12290;</title><link>http://arxiv.org/abs/2207.08911</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#21450;&#20854;&#22312;&#32570;&#22833;&#25968;&#25454;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Deeply-Learned Generalized Linear Models with Missing Data. (arXiv:2207.08911v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.08911
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411; (dlglm) &#21450;&#20854;&#22312;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#20013;&#30340;&#24212;&#29992;&#65292;&#20854;&#20013;&#30340;&#26041;&#27861;&#33021;&#22815;&#28789;&#27963;&#22320;&#22788;&#29702;&#36755;&#20837;&#29305;&#24449;&#21644;&#21709;&#24212;&#30340;&#21487;&#24573;&#30053;&#21644;&#19981;&#21487;&#24573;&#30053;&#30340;&#32570;&#22833;&#27169;&#24335;&#12290;&#25105;&#20204;&#36890;&#36807;&#32479;&#35745;&#27169;&#25311;&#35777;&#26126;&#65292;&#22312;&#32570;&#22833;&#25968;&#25454;&#19981;&#38543;&#26426;&#30340;&#24773;&#20917;&#19979;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#29983;&#29289;&#21307;&#23398;&#31185;&#23398;&#31561;&#39046;&#22495;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#22312;&#36807;&#21435;&#20960;&#24180;&#20013;&#22312;&#29983;&#29289;&#21307;&#23398;&#31185;&#23398;&#30340;&#30417;&#30563;&#23398;&#20064;&#38382;&#39064;&#20013;&#24471;&#21040;&#20102;&#26174;&#33879;&#24212;&#29992;&#65292;&#20294;&#29616;&#20195;&#29983;&#29289;&#21307;&#23398;&#25968;&#25454;&#38598;&#20013;&#32570;&#22833;&#25968;&#25454;&#30340;&#26356;&#21152;&#26222;&#36941;&#21644;&#22797;&#26434;&#24615;&#32473;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#24102;&#26469;&#20102;&#37325;&#22823;&#25361;&#25112;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;(dlglm)&#30340;&#27491;&#24335;&#22788;&#29702;&#26041;&#27861;&#65292;&#22312;&#35757;&#32451;&#26102;&#33021;&#22815;&#28789;&#27963;&#22320;&#22788;&#29702;&#36755;&#20837;&#29305;&#24449;&#21644;&#21709;&#24212;&#30340;&#21487;&#24573;&#30053;&#21644;&#19981;&#21487;&#24573;&#30053;&#30340;&#32570;&#22833;&#27169;&#24335;&#12290;&#25105;&#20204;&#36890;&#36807;&#32479;&#35745;&#27169;&#25311;&#35777;&#26126;&#65292;&#22312;&#32570;&#22833;&#25968;&#25454;&#19981;&#38543;&#26426;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20197;UCI&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#38134;&#34892;&#33829;&#38144;&#25968;&#25454;&#38598;&#20026;&#20363;&#36827;&#34892;&#20102;&#26696;&#20363;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Learning (DL) methods have dramatically increased in popularity in recent years, with significant growth in their application to supervised learning problems in the biomedical sciences. However, the greater prevalence and complexity of missing data in modern biomedical datasets present significant challenges for DL methods. Here, we provide a formal treatment of missing data in the context of deeply learned generalized linear models, a supervised DL architecture for regression and classification problems. We propose a new architecture, \textit{dlglm}, that is one of the first to be able to flexibly account for both ignorable and non-ignorable patterns of missingness in input features and response at training time. We demonstrate through statistical simulation that our method outperforms existing approaches for supervised learning tasks in the presence of missing not at random (MNAR) missingness. We conclude with a case study of a Bank Marketing dataset from the UCI Machine Learnin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;"&#32463;&#39564;&#24615;X&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;EXM&#65289;"&#30340;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#20248;&#21270;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#35299;&#20915;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#20248;&#21270;&#19981;&#21487;&#20998;&#35299;&#30446;&#26631;&#30340;&#22256;&#38590;&#65292;&#24182;&#25552;&#20379;&#20102;&#31639;&#27861;&#22522;&#30784;&#30340;&#35814;&#32454;&#35752;&#35770;&#12290;</title><link>http://arxiv.org/abs/2206.00439</link><description>&lt;p&gt;
&#31639;&#27861;&#22522;&#30784;&#30340;&#32463;&#39564;&#24615;X&#39118;&#38505;&#26368;&#23567;&#21270;
&lt;/p&gt;
&lt;p&gt;
Algorithmic Foundations of Empirical X-risk Minimization. (arXiv:2206.00439v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.00439
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;"&#32463;&#39564;&#24615;X&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;EXM&#65289;"&#30340;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#20248;&#21270;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#35299;&#20915;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#20248;&#21270;&#19981;&#21487;&#20998;&#35299;&#30446;&#26631;&#30340;&#22256;&#38590;&#65292;&#24182;&#25552;&#20379;&#20102;&#31639;&#27861;&#22522;&#30784;&#30340;&#35814;&#32454;&#35752;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;"&#32463;&#39564;&#24615;X&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;EXM&#65289;"&#30340;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#20248;&#21270;&#26694;&#26550;&#12290;X&#39118;&#38505;&#26159;&#19968;&#20010;&#29992;&#20110;&#34920;&#31034;&#19968;&#31867;&#32452;&#21512;&#24230;&#37327;&#25110;&#30446;&#26631;&#30340;&#26415;&#35821;&#65292;&#22312;&#20854;&#20013;&#65292;&#23558;&#27599;&#20010;&#25968;&#25454;&#28857;&#19982;&#22823;&#37327;&#30340;&#26126;&#30830;&#25110;&#38544;&#21547;&#30340;&#39033;&#30446;&#36827;&#34892;&#27604;&#36739;&#26469;&#23450;&#20041;&#39118;&#38505;&#20989;&#25968;&#12290;&#23427;&#21253;&#25324;&#35768;&#22810;&#24191;&#27867;&#20351;&#29992;&#30340;&#20195;&#29702;&#30446;&#26631;&#21644;&#19981;&#21487;&#20998;&#35299;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#20363;&#22914;AUROC&#12289;AUPRC&#12289;&#37096;&#20998;AUROC&#12289;NDCG&#12289;MAP&#12289;&#22312;&#21069;K&#20010;&#20301;&#32622;&#30340;&#31934;&#30830;&#24230;/&#21484;&#22238;&#29575;&#12289;&#22312;&#29305;&#23450;&#21484;&#22238;&#29575;&#27700;&#24179;&#19978;&#30340;&#31934;&#30830;&#24230;&#12289;&#21015;&#34920;&#25439;&#22833;&#12289;p&#33539;&#25968;&#25512;&#23548;&#12289;&#39030;&#37096;&#25512;&#23548;&#12289;&#20840;&#23616;&#23545;&#27604;&#25439;&#22833;&#31561;&#12290;&#34429;&#28982;&#36825;&#20123;&#19981;&#21487;&#20998;&#35299;&#30340;&#30446;&#26631;&#21450;&#20854;&#20248;&#21270;&#31639;&#27861;&#22312;&#26426;&#22120;&#23398;&#20064;&#12289;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#20449;&#24687;&#26816;&#32034;&#31561;&#39046;&#22495;&#30340;&#25991;&#29486;&#20013;&#24050;&#32463;&#24471;&#21040;&#20102;&#30740;&#31350;&#65292;&#20294;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#20248;&#21270;&#36825;&#20123;&#30446;&#26631;&#38754;&#20020;&#30528;&#19968;&#20123;&#29420;&#29305;&#30340;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#37325;&#28857;&#20171;&#32461;&#20102;EXM&#30340;&#31639;&#27861;&#22522;&#30784;&#65292;&#24182;&#25552;&#20379;&#20102;&#26368;&#36817;&#30340;&#20005;&#26684;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
This manuscript introduces a new optimization framework for machine learning and AI, named {\bf empirical X-risk minimization (EXM)}. X-risk is a term introduced to represent a family of compositional measures or objectives, in which each data point is compared with a large number of items explicitly or implicitly for defining a risk function. It includes surrogate objectives of many widely used measures and non-decomposable losses, e.g., AUROC, AUPRC, partial AUROC, NDCG, MAP, precision/recall at top $K$ positions, precision at a certain recall level, listwise losses, p-norm push, top push, global contrastive losses, etc. While these non-decomposable objectives and their optimization algorithms have been studied in the literature of machine learning, computer vision, information retrieval, and etc, optimizing these objectives has encountered some unique challenges for deep learning. In this paper, we present recent rigorous efforts for EXM with a focus on its algorithmic foundations a
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#24314;&#31435;&#20102;&#24102;&#32422;&#26463;&#23398;&#20064;&#30340;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;&#30340;&#26041;&#27861;&#35770;&#22522;&#30784;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31471;&#21040;&#31471;&#30340;&#25968;&#25454;&#39537;&#21160;&#20915;&#31574;&#21046;&#23450;&#27969;&#31243;&#65292;&#24182;&#21033;&#29992;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;&#21487;&#34920;&#31034;&#24615;&#25429;&#25417;&#20915;&#31574;&#12289;&#19978;&#19979;&#25991;&#21464;&#37327;&#21644;&#32467;&#26524;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#21516;&#26102;&#65292;&#24341;&#20837;&#20102;&#22788;&#29702;&#23398;&#20064;&#25968;&#25454;&#20013;&#19981;&#30830;&#23450;&#24615;&#30340;&#20004;&#31181;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2111.04469</link><description>&lt;p&gt;
&#24102;&#32422;&#26463;&#23398;&#20064;&#30340;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Mixed-Integer Optimization with Constraint Learning. (arXiv:2111.04469v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.04469
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#24314;&#31435;&#20102;&#24102;&#32422;&#26463;&#23398;&#20064;&#30340;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;&#30340;&#26041;&#27861;&#35770;&#22522;&#30784;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31471;&#21040;&#31471;&#30340;&#25968;&#25454;&#39537;&#21160;&#20915;&#31574;&#21046;&#23450;&#27969;&#31243;&#65292;&#24182;&#21033;&#29992;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;&#21487;&#34920;&#31034;&#24615;&#25429;&#25417;&#20915;&#31574;&#12289;&#19978;&#19979;&#25991;&#21464;&#37327;&#21644;&#32467;&#26524;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#21516;&#26102;&#65292;&#24341;&#20837;&#20102;&#22788;&#29702;&#23398;&#20064;&#25968;&#25454;&#20013;&#19981;&#30830;&#23450;&#24615;&#30340;&#20004;&#31181;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#24191;&#27867;&#30340;&#26041;&#27861;&#35770;&#22522;&#30784;&#65292;&#29992;&#20110;&#24102;&#32422;&#26463;&#23398;&#20064;&#30340;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31471;&#21040;&#31471;&#30340;&#25968;&#25454;&#39537;&#21160;&#20915;&#31574;&#21046;&#23450;&#27969;&#31243;&#65292;&#20854;&#20013;&#32422;&#26463;&#21644;&#30446;&#26631;&#30452;&#25509;&#20174;&#25968;&#25454;&#20013;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#36827;&#34892;&#23398;&#20064;&#65292;&#24182;&#23558;&#35757;&#32451;&#22909;&#30340;&#27169;&#22411;&#23884;&#20837;&#21040;&#20248;&#21270;&#20844;&#24335;&#20013;&#12290;&#25105;&#20204;&#21033;&#29992;&#20102;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65288;&#21253;&#25324;&#32447;&#24615;&#27169;&#22411;&#12289;&#20915;&#31574;&#26641;&#12289;&#38598;&#25104;&#21644;&#22810;&#23618;&#24863;&#30693;&#22120;&#65289;&#30340;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;&#21487;&#34920;&#31034;&#24615;&#65292;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#25429;&#25417;&#20915;&#31574;&#12289;&#19978;&#19979;&#25991;&#21464;&#37327;&#21644;&#32467;&#26524;&#20043;&#38388;&#30340;&#21508;&#31181;&#28508;&#22312;&#20851;&#31995;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#20004;&#31181;&#22788;&#29702;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#30340;&#22266;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#26041;&#27861;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#36890;&#36807;&#35266;&#27979;&#20540;&#30340;&#20984;&#21253;&#26469;&#34920;&#24449;&#20915;&#31574;&#30340;&#20449;&#20219;&#21306;&#22495;&#65292;&#20197;&#30830;&#20445;&#21487;&#38752;&#30340;&#25512;&#33616;&#24182;&#36991;&#20813;&#22806;&#25512;&#12290;&#25105;&#20204;&#20351;&#29992;&#21015;&#29983;&#25104;&#26041;&#27861;&#26377;&#25928;&#22320;&#23558;&#36825;&#31181;&#34920;&#31034;&#21152;&#20837;&#21040;&#20248;&#21270;&#20844;&#24335;&#20013;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#28789;&#27963;&#30340;&#20844;&#24335;&#26469;&#22788;&#29702;&#20302;&#23494;&#24230;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
We establish a broad methodological foundation for mixed-integer optimization with learned constraints. We propose an end-to-end pipeline for data-driven decision making in which constraints and objectives are directly learned from data using machine learning, and the trained models are embedded in an optimization formulation. We exploit the mixed-integer optimization-representability of many machine learning methods, including linear models, decision trees, ensembles, and multi-layer perceptrons, which allows us to capture various underlying relationships between decisions, contextual variables, and outcomes. We also introduce two approaches for handling the inherent uncertainty of learning from data. First, we characterize a decision trust region using the convex hull of the observations, to ensure credible recommendations and avoid extrapolation. We efficiently incorporate this representation using column generation and propose a more flexible formulation to deal with low-density re
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;Eigenlearning&#26694;&#26550;&#65292;&#36890;&#36807;&#38480;&#21046;&#26680;&#22238;&#24402;&#22312;&#23398;&#20064;&#27491;&#20132;&#22522;&#20989;&#25968;&#26041;&#38754;&#30340;&#33021;&#21147;&#24182;&#21033;&#29992;&#23432;&#24658;&#23450;&#24459;&#26469;&#35299;&#37322;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#21516;&#26102;&#36824;&#20026;Nakkiran&#31561;&#20154;&#30340;&#8220;&#28145;&#24230;&#24341;&#23548;&#8221;&#29616;&#35937;&#65292;&#32463;&#20856;&#22855;&#20598;&#38382;&#39064;&#38590;&#24230;&#21644;&#23545;&#25239;&#40065;&#26834;&#24615;&#25552;&#20379;&#20102;&#29702;&#35770;&#25903;&#25345;&#65292;&#24182;&#19982;&#32479;&#35745;&#29289;&#29702;&#23398;&#20013;&#30340;&#19968;&#20010;&#31995;&#32479;&#36827;&#34892;&#20102;&#31867;&#27604;&#12290;</title><link>http://arxiv.org/abs/2110.03922</link><description>&lt;p&gt;
Eigenlearning&#26694;&#26550;&#65306;&#26680;&#22238;&#24402;&#21644;&#23485;&#31070;&#32463;&#32593;&#32476;&#30340;&#23432;&#24658;&#23450;&#24459;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
The Eigenlearning Framework: A Conservation Law Perspective on Kernel Regression and Wide Neural Networks. (arXiv:2110.03922v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.03922
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;Eigenlearning&#26694;&#26550;&#65292;&#36890;&#36807;&#38480;&#21046;&#26680;&#22238;&#24402;&#22312;&#23398;&#20064;&#27491;&#20132;&#22522;&#20989;&#25968;&#26041;&#38754;&#30340;&#33021;&#21147;&#24182;&#21033;&#29992;&#23432;&#24658;&#23450;&#24459;&#26469;&#35299;&#37322;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#21516;&#26102;&#36824;&#20026;Nakkiran&#31561;&#20154;&#30340;&#8220;&#28145;&#24230;&#24341;&#23548;&#8221;&#29616;&#35937;&#65292;&#32463;&#20856;&#22855;&#20598;&#38382;&#39064;&#38590;&#24230;&#21644;&#23545;&#25239;&#40065;&#26834;&#24615;&#25552;&#20379;&#20102;&#29702;&#35770;&#25903;&#25345;&#65292;&#24182;&#19982;&#32479;&#35745;&#29289;&#29702;&#23398;&#20013;&#30340;&#19968;&#20010;&#31995;&#32479;&#36827;&#34892;&#20102;&#31867;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#38024;&#23545;&#26680;&#23725;&#22238;&#24402;&#65288;KRR&#65289;&#30340;&#27979;&#35797;&#39118;&#38505;&#21644;&#20854;&#20182;&#27867;&#21270;&#25351;&#26631;&#23548;&#20986;&#20102;&#31616;&#21333;&#30340;&#38381;&#24335;&#20272;&#35745;&#12290;&#30456;&#23545;&#20110;&#20197;&#21069;&#30340;&#24037;&#20316;&#65292;&#25105;&#20204;&#30340;&#25512;&#23548;&#22823;&#22823;&#31616;&#21270;&#65292;&#26368;&#32456;&#34920;&#36798;&#24335;&#26356;&#26131;&#20110;&#35299;&#37322;&#12290;&#36825;&#20123;&#25913;&#36827;&#24471;&#30410;&#20110;&#25105;&#20204;&#35782;&#21035;&#20986;&#30340;&#19968;&#20010;&#23574;&#38160;&#30340;&#23432;&#24658;&#23450;&#24459;&#65292;&#23427;&#38480;&#21046;&#20102;KRR&#23398;&#20064;&#20219;&#20309;&#27491;&#20132;&#22522;&#20989;&#25968;&#30340;&#33021;&#21147;&#12290;&#27979;&#35797;&#39118;&#38505;&#21644;&#20854;&#20182;&#24863;&#20852;&#36259;&#30340;&#23545;&#35937;&#21487;&#20197;&#36879;&#26126;&#22320;&#29992;&#20110;&#25105;&#20204;&#22312;&#26680;&#29305;&#24449;&#22522;&#20013;&#35780;&#20272;&#30340;&#23432;&#24658;&#37327;&#26469;&#34920;&#31034;&#12290;&#25105;&#20204;&#20351;&#29992;&#25913;&#36827;&#30340;&#26694;&#26550;&#26469;&#65306;i&#65289;&#20026;Nakkiran&#31561;&#20154;&#65288;2020&#65289;&#30340;&#8220;&#28145;&#24230;&#24341;&#23548;&#8221;&#25552;&#20379;&#29702;&#35770;&#35299;&#37322;&#65292;ii&#65289;&#25512;&#24191;&#20808;&#21069;&#20851;&#20110;&#32463;&#20856;&#22855;&#20598;&#38382;&#39064;&#38590;&#24230;&#30340;&#32467;&#26524;&#65292;iii&#65289;&#20026;&#23545;&#25239;&#40065;&#26834;&#24615;&#30340;&#30740;&#31350;&#25552;&#20379;&#29702;&#35770;&#24037;&#20855;&#65292;&#24182;iv&#65289;&#22312;&#32479;&#35745;&#29289;&#29702;&#23398;&#20013;&#30740;&#31350;&#26680;&#23725;&#22238;&#24402;&#21644;&#29087;&#30693;&#31995;&#32479;&#20043;&#38388;&#30340;&#20005;&#23494;&#31867;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
We derive simple closed-form estimates for the test risk and other generalization metrics of kernel ridge regression (KRR). Relative to prior work, our derivations are greatly simplified and our final expressions are more readily interpreted. These improvements are enabled by our identification of a sharp conservation law which limits the ability of KRR to learn any orthonormal basis of functions. Test risk and other objects of interest are expressed transparently in terms of our conserved quantity evaluated in the kernel eigenbasis. We use our improved framework to: i) provide a theoretical explanation for the "deep bootstrap" of Nakkiran et al (2020), ii) generalize a previous result regarding the hardness of the classic parity problem, iii) fashion a theoretical tool for the study of adversarial robustness, and iv) draw a tight analogy between KRR and a well-studied system in statistical physics.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#19981;&#30830;&#23450;&#24615;&#23545;&#19981;&#21516;&#20154;&#32676;&#30340;&#24433;&#21709;&#26159;&#19981;&#24179;&#31561;&#30340;&#65292;&#34429;&#28982;&#23427;&#20250;&#22312;&#25152;&#26377;&#20154;&#21475;&#32676;&#20307;&#20013;&#20135;&#29983;&#35823;&#24046;&#65292;&#20294;&#35823;&#24046;&#30340;&#31867;&#22411;&#20250;&#26377;&#31995;&#32479;&#24615;&#30340;&#21464;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#24179;&#26435;&#20449;&#24687;&#30340;&#31574;&#30053;&#65292;&#21487;&#20197;&#28040;&#38500;&#36825;&#31181;&#24046;&#24322;&#24182;&#25193;&#22823;&#26426;&#20250;&#30340;&#33719;&#21462;&#65292;&#36825;&#21487;&#20197;&#20316;&#20026;&#24179;&#26435;&#34892;&#21160;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2102.10019</link><description>&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#30340;&#19981;&#24179;&#31561;&#24433;&#21709;&#65306;&#24179;&#26435;&#34892;&#21160;&#19982;&#24179;&#26435;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
The Disparate Impact of Uncertainty: Affirmative Action vs. Affirmative Information. (arXiv:2102.10019v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.10019
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#19981;&#30830;&#23450;&#24615;&#23545;&#19981;&#21516;&#20154;&#32676;&#30340;&#24433;&#21709;&#26159;&#19981;&#24179;&#31561;&#30340;&#65292;&#34429;&#28982;&#23427;&#20250;&#22312;&#25152;&#26377;&#20154;&#21475;&#32676;&#20307;&#20013;&#20135;&#29983;&#35823;&#24046;&#65292;&#20294;&#35823;&#24046;&#30340;&#31867;&#22411;&#20250;&#26377;&#31995;&#32479;&#24615;&#30340;&#21464;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#24179;&#26435;&#20449;&#24687;&#30340;&#31574;&#30053;&#65292;&#21487;&#20197;&#28040;&#38500;&#36825;&#31181;&#24046;&#24322;&#24182;&#25193;&#22823;&#26426;&#20250;&#30340;&#33719;&#21462;&#65292;&#36825;&#21487;&#20197;&#20316;&#20026;&#24179;&#26435;&#34892;&#21160;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proves that uncertainty has a disparate impact on different demographic groups, with varying types of errors. The proposed strategy, called Affirmative Information, can eliminate this disparity and broaden access to opportunity, serving as an alternative to Affirmative Action.
&lt;/p&gt;
&lt;p&gt;
&#20687;&#36151;&#27454;&#25209;&#20934;&#12289;&#21307;&#30103;&#24178;&#39044;&#21644;&#22823;&#23398;&#24405;&#21462;&#36825;&#26679;&#30340;&#20851;&#38190;&#20915;&#31574;&#26159;&#22312;&#23384;&#22312;&#19981;&#30830;&#23450;&#24615;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#39044;&#27979;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19981;&#30830;&#23450;&#24615;&#20855;&#26377;&#19981;&#24179;&#31561;&#30340;&#24433;&#21709;&#12290;&#34429;&#28982;&#23427;&#20250;&#22312;&#25152;&#26377;&#20154;&#21475;&#32676;&#20307;&#20013;&#20135;&#29983;&#35823;&#24046;&#65292;&#20294;&#35823;&#24046;&#30340;&#31867;&#22411;&#20250;&#26377;&#31995;&#32479;&#24615;&#30340;&#21464;&#21270;&#65306;&#24179;&#22343;&#32467;&#26524;&#36739;&#39640;&#30340;&#32676;&#20307;&#36890;&#24120;&#34987;&#20998;&#37197;&#26356;&#39640;&#30340;&#20551;&#38451;&#24615;&#29575;&#65292;&#32780;&#24179;&#22343;&#32467;&#26524;&#36739;&#20302;&#30340;&#32676;&#20307;&#21017;&#34987;&#20998;&#37197;&#26356;&#39640;&#30340;&#20551;&#38452;&#24615;&#29575;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#39069;&#22806;&#30340;&#25968;&#25454;&#33719;&#21462;&#21487;&#20197;&#28040;&#38500;&#36825;&#31181;&#24046;&#24322;&#24182;&#25193;&#22823;&#26426;&#20250;&#30340;&#33719;&#21462;&#12290;&#25105;&#20204;&#31216;&#20043;&#20026;&#24179;&#26435;&#20449;&#24687;&#30340;&#31574;&#30053;&#21487;&#20197;&#20316;&#20026;&#24179;&#26435;&#34892;&#21160;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Critical decisions like loan approvals, medical interventions, and college admissions are guided by predictions made in the presence of uncertainty. In this paper, we prove that uncertainty has a disparate impact. While it imparts errors across all demographic groups, the types of errors vary systematically: Groups with higher average outcomes are typically assigned higher false positive rates, while those with lower average outcomes are assigned higher false negative rates. We show that additional data acquisition can eliminate the disparity and broaden access to opportunity. The strategy, which we call Affirmative Information, could stand as an alternative to Affirmative Action.
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31070;&#32463;&#35745;&#31639;&#26694;&#26550;&#19979;&#30340;&#24847;&#35782;&#29702;&#35770;&#65292;&#31216;&#20026;&#8220;&#30446;&#26631;&#23545;&#40784;&#30340;&#20869;&#37096;&#34920;&#31034;&#25805;&#20316;&#8221;&#65288;GARIM&#65289;&#12290;&#35813;&#29702;&#35770;&#35748;&#20026;&#24847;&#35782;&#25903;&#25345;&#23545;&#30446;&#26631;&#30456;&#20851;&#30340;&#20869;&#37096;&#34920;&#31034;&#36827;&#34892;&#20027;&#21160;&#25805;&#20316;&#65292;&#20351;&#20854;&#19982;&#36861;&#27714;&#30340;&#30446;&#26631;&#26356;&#21152;&#23545;&#40784;&#65292;&#20174;&#32780;&#22686;&#21152;&#30446;&#26631;&#23548;&#21521;&#34892;&#20026;&#30340;&#28789;&#27963;&#24615;&#12290;</title><link>http://arxiv.org/abs/1912.13490</link><description>&lt;p&gt;
&#24847;&#35782;&#30340;&#31070;&#32463;&#35745;&#31639;&#27169;&#22411;&#65306;&#30446;&#26631;&#23545;&#40784;&#30340;&#20869;&#37096;&#34920;&#31034;&#25805;&#20316;&#29702;&#35770;&#65288;GARIM&#65289;
&lt;/p&gt;
&lt;p&gt;
A Neurocomputational Account of Consciousness: The Goal-Aligning Representation Internal Manipulation Theory (GARIM). (arXiv:1912.13490v3 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1912.13490
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31070;&#32463;&#35745;&#31639;&#26694;&#26550;&#19979;&#30340;&#24847;&#35782;&#29702;&#35770;&#65292;&#31216;&#20026;&#8220;&#30446;&#26631;&#23545;&#40784;&#30340;&#20869;&#37096;&#34920;&#31034;&#25805;&#20316;&#8221;&#65288;GARIM&#65289;&#12290;&#35813;&#29702;&#35770;&#35748;&#20026;&#24847;&#35782;&#25903;&#25345;&#23545;&#30446;&#26631;&#30456;&#20851;&#30340;&#20869;&#37096;&#34920;&#31034;&#36827;&#34892;&#20027;&#21160;&#25805;&#20316;&#65292;&#20351;&#20854;&#19982;&#36861;&#27714;&#30340;&#30446;&#26631;&#26356;&#21152;&#23545;&#40784;&#65292;&#20174;&#32780;&#22686;&#21152;&#30446;&#26631;&#23548;&#21521;&#34892;&#20026;&#30340;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24847;&#35782;&#20316;&#20026;&#20154;&#31867;&#35748;&#30693;&#30340;&#26680;&#24515;&#35201;&#32032;&#65292;&#24050;&#32463;&#36890;&#36807;&#31070;&#32463;&#31185;&#23398;&#12289;&#24515;&#29702;&#23398;&#12289;&#20154;&#24037;&#26234;&#33021;&#21644;&#26426;&#22120;&#20154;&#25216;&#26415;&#31561;&#22810;&#31181;&#31185;&#23398;&#26041;&#27861;&#36827;&#34892;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#39046;&#22495;&#20043;&#38388;&#30340;&#19981;&#33391;&#25972;&#21512;&#38480;&#21046;&#20102;&#23545;&#24847;&#35782;&#30340;&#23436;&#25972;&#21644;&#28165;&#26224;&#29702;&#35299;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#19968;&#20010;&#31070;&#32463;&#35745;&#31639;&#26694;&#26550;&#19979;&#30340;&#8220;&#30446;&#26631;&#23545;&#40784;&#30340;&#20869;&#37096;&#34920;&#31034;&#25805;&#20316;&#8221;&#65288;GARIM&#65289;&#24847;&#35782;&#29702;&#35770;&#65292;&#20026;&#25913;&#21892;&#36825;&#31181;&#25972;&#21512;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;GARIM&#29702;&#35770;&#30340;&#26680;&#24515;&#24605;&#24819;&#26159;&#65292;&#24847;&#35782;&#25903;&#25345;&#23545;&#30446;&#26631;&#30456;&#20851;&#30340;&#20869;&#37096;&#34920;&#31034;&#65288;&#22914;&#19990;&#30028;&#29366;&#24577;&#12289;&#23545;&#35937;&#21644;&#34892;&#20026;&#24207;&#21015;&#65289;&#36827;&#34892;&#20027;&#21160;&#25805;&#20316;&#65292;&#20351;&#23427;&#20204;&#19982;&#36861;&#27714;&#30340;&#30446;&#26631;&#26356;&#21152;&#23545;&#40784;&#12290;&#36825;&#20123;&#25805;&#20316;&#20351;&#24471;&#24847;&#35782;&#20195;&#29702;&#33021;&#22815;&#22312;&#20869;&#37096;&#20135;&#29983;&#20854;&#25152;&#32570;&#20047;&#30340;&#30693;&#35782;&#65292;&#20197;&#24212;&#23545;&#26032;&#26465;&#20214;&#21644;&#30446;&#26631;&#65292;&#20174;&#32780;&#22686;&#21152;&#30446;&#26631;&#23548;&#21521;&#34892;&#20026;&#30340;&#28789;&#27963;&#24615;&#12290;&#34920;&#31034;&#30340;&#25805;&#20316;&#30001;&#22235;&#20010;&#31070;&#32463;&#21151;&#33021;&#23439;&#31995;&#32479;&#65288;Hierarc...
&lt;/p&gt;
&lt;p&gt;
Consciousness, a central element of human cognition, has been studied with multiple scientific approaches spanning neuroscience, psychology, artificial intelligence and robotics. Unfortunately, poor integration between these fields limits a full and clear understanding of consciousness. Here we contribute to improving this integration by proposing, within a neurocomputational framework, the `Goal-Aligning Representations Internal Manipulation' (GARIM) theory of consciousness. The central idea of the GARIM theory is that consciousness supports the active manipulation of goal-relevant internal representations (e.g., world states, objects, and action sequences), making them more aligned with the goals pursued. These manipulations allow the conscious agent to internally produce the knowledge it lacks to cope with novel conditions and goals, increasing the flexibility of goal-directed behaviour. The manipulation of representations is supported by four neuro-functional macro-systems (hierarc
&lt;/p&gt;</description></item></channel></rss>