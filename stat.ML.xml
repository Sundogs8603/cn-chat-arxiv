<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;ODE&#30340;&#29983;&#25104;&#27169;&#22411;&#20013;&#65292;&#20351;&#29992;Transformer&#23454;&#29616;&#27969;&#21305;&#37197;&#22312;&#28508;&#31354;&#38388;&#20013;&#30340;&#29702;&#35770;&#25910;&#25947;&#24615;&#20445;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#20272;&#35745;ODE&#27969;&#29983;&#25104;&#26679;&#26412;&#20998;&#24067;&#26102;&#30340;&#26377;&#25928;&#24615;&#65292;&#21516;&#26102;&#36824;&#35777;&#26126;&#20102;&#20855;&#26377;&#21033;&#26222;&#24076;&#33576;&#36830;&#32493;&#24615;&#30340;Transformer&#32593;&#32476;&#21487;&#20197;&#26377;&#25928;&#36924;&#36817;&#20219;&#24847;&#20809;&#28369;&#20989;&#25968;&#12290;</title><link>https://arxiv.org/abs/2404.02538</link><description>&lt;p&gt;
&#27969;&#21305;&#37197;&#22312;&#28508;&#31354;&#38388;&#20013;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#19982;Transformer
&lt;/p&gt;
&lt;p&gt;
Convergence Analysis of Flow Matching in Latent Space with Transformers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02538
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;ODE&#30340;&#29983;&#25104;&#27169;&#22411;&#20013;&#65292;&#20351;&#29992;Transformer&#23454;&#29616;&#27969;&#21305;&#37197;&#22312;&#28508;&#31354;&#38388;&#20013;&#30340;&#29702;&#35770;&#25910;&#25947;&#24615;&#20445;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#20272;&#35745;ODE&#27969;&#29983;&#25104;&#26679;&#26412;&#20998;&#24067;&#26102;&#30340;&#26377;&#25928;&#24615;&#65292;&#21516;&#26102;&#36824;&#35777;&#26126;&#20102;&#20855;&#26377;&#21033;&#26222;&#24076;&#33576;&#36830;&#32493;&#24615;&#30340;Transformer&#32593;&#32476;&#21487;&#20197;&#26377;&#25928;&#36924;&#36817;&#20219;&#24847;&#20809;&#28369;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;ODE-based&#29983;&#25104;&#27169;&#22411;&#65292;&#29305;&#21035;&#26159;&#27969;&#21305;&#37197;&#30340;&#29702;&#35770;&#25910;&#25947;&#24615;&#20445;&#35777;&#12290;&#25105;&#20204;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#33258;&#32534;&#30721;&#22120;&#32593;&#32476;&#23558;&#39640;&#32500;&#21407;&#22987;&#36755;&#20837;&#26144;&#23556;&#21040;&#20302;&#32500;&#28508;&#31354;&#38388;&#65292;&#20854;&#20013;&#19968;&#20010;Transformer&#32593;&#32476;&#34987;&#35757;&#32451;&#26469;&#39044;&#27979;&#20174;&#26631;&#20934;&#27491;&#24577;&#20998;&#24067;&#21040;&#30446;&#26631;&#28508;&#31354;&#38388;&#20998;&#24067;&#30340;&#21464;&#25442;&#36895;&#24230;&#22330;&#12290;&#25105;&#20204;&#30340;&#35823;&#24046;&#20998;&#26512;&#23637;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#34920;&#26126;&#36890;&#36807;&#20272;&#35745;&#30340;ODE&#27969;&#29983;&#25104;&#26679;&#26412;&#30340;&#20998;&#24067;&#22312;&#28201;&#26031;&#22374;-2&#36317;&#31163;&#19979;&#25910;&#25947;&#21040;&#30446;&#26631;&#20998;&#24067;&#65292;&#36825;&#22312;&#28201;&#21644;&#19988;&#23454;&#38469;&#30340;&#20551;&#35774;&#19979;&#25104;&#31435;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20855;&#26377;&#21033;&#26222;&#24076;&#33576;&#36830;&#32493;&#24615;&#30340;Transformer&#32593;&#32476;&#21487;&#20197;&#26377;&#25928;&#22320;&#36924;&#36817;&#20219;&#24847;&#20809;&#28369;&#20989;&#25968;&#65292;&#36825;&#21487;&#33021;&#26159;&#29420;&#31435;&#24863;&#20852;&#36259;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02538v1 Announce Type: cross  Abstract: We present theoretical convergence guarantees for ODE-based generative models, specifically flow matching. We use a pre-trained autoencoder network to map high-dimensional original inputs to a low-dimensional latent space, where a transformer network is trained to predict the velocity field of the transformation from a standard normal distribution to the target latent distribution. Our error analysis demonstrates the effectiveness of this approach, showing that the distribution of samples generated via estimated ODE flow converges to the target distribution in the Wasserstein-2 distance under mild and practical assumptions. Furthermore, we show that arbitrary smooth functions can be effectively approximated by transformer networks with Lipschitz continuity, which may be of independent interest.
&lt;/p&gt;</description></item><item><title>&#40654;&#26364;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#30340;&#26032;&#26041;&#27861;&#21033;&#29992;Fisher&#24230;&#37327;&#25552;&#20379;&#26356;&#20016;&#23500;&#30340;&#36924;&#36817;&#26063;&#65292;&#35299;&#20915;&#20102;&#22312;&#26080;&#38480;&#25968;&#25454;&#26497;&#38480;&#19979;&#20808;&#21069;&#26041;&#27861;&#24230;&#37327;&#36873;&#25321;&#19981;&#24403;&#23548;&#33268;&#36924;&#36817;&#36807;&#20110;&#29421;&#31364;&#21644;&#26377;&#20559;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2311.02766</link><description>&lt;p&gt;
&#20855;&#26377;Fisher&#24230;&#37327;&#30340;&#40654;&#26364;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Riemannian Laplace Approximation with the Fisher Metric
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.02766
&lt;/p&gt;
&lt;p&gt;
&#40654;&#26364;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#30340;&#26032;&#26041;&#27861;&#21033;&#29992;Fisher&#24230;&#37327;&#25552;&#20379;&#26356;&#20016;&#23500;&#30340;&#36924;&#36817;&#26063;&#65292;&#35299;&#20915;&#20102;&#22312;&#26080;&#38480;&#25968;&#25454;&#26497;&#38480;&#19979;&#20808;&#21069;&#26041;&#27861;&#24230;&#37327;&#36873;&#25321;&#19981;&#24403;&#23548;&#33268;&#36924;&#36817;&#36807;&#20110;&#29421;&#31364;&#21644;&#26377;&#20559;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Laplace&#26041;&#27861;&#29992;&#39640;&#26031;&#20998;&#24067;&#22312;&#20854;&#27169;&#24335;&#22788;&#23545;&#30446;&#26631;&#23494;&#24230;&#36827;&#34892;&#36817;&#20284;&#12290;&#22522;&#20110;Bernstein-von Mises&#23450;&#29702;&#65292;&#23427;&#22312;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#26159;&#35745;&#31639;&#25928;&#29575;&#39640;&#19988;&#28176;&#36817;&#20934;&#30830;&#30340;&#65292;&#20294;&#23545;&#20110;&#22797;&#26434;&#30340;&#30446;&#26631;&#21644;&#26377;&#38480;&#25968;&#25454;&#21518;&#39564;&#65292;&#23427;&#24448;&#24448;&#26159;&#19968;&#31181;&#36807;&#20110;&#31895;&#31961;&#30340;&#36817;&#20284;&#12290;&#26368;&#36817;&#23545;Laplace&#36924;&#36817;&#30340;&#19968;&#33324;&#21270;&#26159;&#26681;&#25454;&#36873;&#25321;&#30340;&#40654;&#26364;&#20960;&#20309;&#23545;&#39640;&#26031;&#36817;&#20284;&#36827;&#34892;&#36716;&#25442;&#65292;&#25552;&#20379;&#20102;&#26356;&#20016;&#23500;&#30340;&#36817;&#20284;&#26063;&#65292;&#21516;&#26102;&#20445;&#25345;&#35745;&#31639;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#27491;&#22914;&#26412;&#25991;&#25152;&#31034;&#65292;&#20854;&#24615;&#36136;&#20005;&#37325;&#20381;&#36182;&#20110;&#25152;&#36873;&#25321;&#30340;&#24230;&#37327;&#65292;&#23454;&#38469;&#19978;&#65292;&#22312;&#20808;&#21069;&#30740;&#31350;&#20013;&#37319;&#29992;&#30340;&#24230;&#37327;&#23548;&#33268;&#30340;&#36924;&#36817;&#21363;&#20351;&#22312;&#26080;&#38480;&#25968;&#25454;&#37327;&#30340;&#26497;&#38480;&#19979;&#20063;&#36807;&#20110;&#29421;&#31364;&#19988;&#23384;&#22312;&#20559;&#24046;&#12290;&#25105;&#20204;&#36890;&#36807;&#36827;&#19968;&#27493;&#21457;&#23637;&#36924;&#36817;&#26063;&#65292;&#25512;&#23548;&#20986;&#20004;&#31181;&#22312;&#26080;&#38480;&#25968;&#25454;&#26497;&#38480;&#19979;&#31934;&#30830;&#30340;&#26367;&#20195;&#21464;&#31181;&#65292;&#25193;&#23637;&#20102;&#29702;&#35770;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.02766v3 Announce Type: replace  Abstract: Laplace's method approximates a target density with a Gaussian distribution at its mode. It is computationally efficient and asymptotically exact for Bayesian inference due to the Bernstein-von Mises theorem, but for complex targets and finite-data posteriors it is often too crude an approximation. A recent generalization of the Laplace Approximation transforms the Gaussian approximation according to a chosen Riemannian geometry providing a richer approximation family, while still retaining computational efficiency. However, as shown here, its properties depend heavily on the chosen metric, indeed the metric adopted in previous work results in approximations that are overly narrow as well as being biased even at the limit of infinite data. We correct this shortcoming by developing the approximation family further, deriving two alternative variants that are exact at the limit of infinite data, extending the theoretical analysis of the
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#29992;&#20110;&#20855;&#26377;&#32806;&#21512;&#32447;&#24615;&#32422;&#26463;&#30340;&#38750;&#20809;&#28369;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#20004;&#31181;&#31639;&#27861;&#65292;&#20998;&#21035;&#20855;&#26377;&#36845;&#20195;&#22797;&#26434;&#24230;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2212.04672</link><description>&lt;p&gt;
Primal Dual Alternating Proximal Gradient&#31639;&#27861;&#29992;&#20110;&#20855;&#26377;&#32806;&#21512;&#32447;&#24615;&#32422;&#26463;&#30340;&#38750;&#20809;&#28369;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Primal Dual Alternating Proximal Gradient Algorithms for Nonsmooth Nonconvex Minimax Problems with Coupled Linear Constraints
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2212.04672
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#29992;&#20110;&#20855;&#26377;&#32806;&#21512;&#32447;&#24615;&#32422;&#26463;&#30340;&#38750;&#20809;&#28369;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#20004;&#31181;&#31639;&#27861;&#65292;&#20998;&#21035;&#20855;&#26377;&#36845;&#20195;&#22797;&#26434;&#24230;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#36817;&#24180;&#26469;&#22312;&#26426;&#22120;&#23398;&#20064;&#12289;&#20449;&#21495;&#22788;&#29702;&#21644;&#35768;&#22810;&#20854;&#20182;&#39046;&#22495;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#38750;&#20809;&#28369;&#38750;&#20984;&#65288;&#24378;&#65289;&#20985;&#21644;&#38750;&#20984;&#32447;&#24615;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#21407;&#22987;&#23545;&#20598;&#20132;&#26367;&#36817;&#31471;&#26799;&#24230;&#65288;PDAPG&#65289;&#31639;&#27861;&#21644;&#21407;&#22987;&#23545;&#20598;&#36817;&#31471;&#26799;&#24230;&#65288;PDPG-L&#65289;&#31639;&#27861;&#65292;&#20998;&#21035;&#29992;&#20110;&#20855;&#26377;&#32806;&#21512;&#32447;&#24615;&#32422;&#26463;&#30340;&#24773;&#20917;&#12290;&#36825;&#20004;&#31181;&#31639;&#27861;&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#35777;&#26126;&#20026; $\mathcal{O}\left( \varepsilon ^{-2} \right)$ &#65288;&#23545;&#24212; $\mathcal{O}\left( \varepsilon ^{-4} \right)$&#65289;&#22312;&#38750;&#20984;&#24378;&#20985; &#65288;&#23545;&#24212;&#38750;&#20984;&#20985;&#65289;&#24773;&#20917;&#19979;&#65292;&#20197;&#21450; $\mathcal{O}\left( \varepsilon ^{-3} \right)$ &#22312;&#38750;&#20984;&#32447;&#24615;&#24773;&#20917;&#19979;&#65292;&#20998;&#21035;&#36798;&#21040; $\varepsilon$-&#31283;&#24577;&#28857;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#23427;&#20204;&#26159;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#32806;&#21512;&#32447;&#24615;&#32422;&#26463;&#30340;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#31532;&#19968;&#25209;&#20855;&#26377;&#36845;&#20195;&#22797;&#26434;&#24230;&#20445;&#35777;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2212.04672v3 Announce Type: replace-cross  Abstract: Nonconvex minimax problems have attracted wide attention in machine learning, signal processing and many other fields in recent years. In this paper, we propose a primal-dual alternating proximal gradient (PDAPG) algorithm and a primal-dual proximal gradient (PDPG-L) algorithm for solving nonsmooth nonconvex-(strongly) concave and nonconvex-linear minimax problems with coupled linear constraints, respectively. The iteration complexity of the two algorithms are proved to be $\mathcal{O}\left( \varepsilon ^{-2} \right)$ (resp. $\mathcal{O}\left( \varepsilon ^{-4} \right)$) under nonconvex-strongly concave (resp. nonconvex-concave) setting and $\mathcal{O}\left( \varepsilon ^{-3} \right)$ under nonconvex-linear setting to reach an $\varepsilon$-stationary point, respectively. To our knowledge, they are the first two algorithms with iteration complexity guarantees for solving the nonconvex minimax problems with coupled linear const
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#35774;&#35745;&#25511;&#21046;&#22330;&#30340;&#26041;&#26696;&#25104;&#21151;&#29983;&#25104;&#20102;&#38750;&#32463;&#20856;&#24577;&#65292;&#20197;&#24212;&#29992;&#20110;&#33258;&#26059;&#21387;&#32553;&#24577;&#30340;&#20135;&#29983;&#12290;&#35813;&#26041;&#27861;&#22312;&#20445;&#25345;&#21387;&#32553;&#21644;&#32416;&#32544;&#30340;&#21516;&#26102;&#25552;&#20379;&#20102;&#19981;&#21516;&#30340;&#25511;&#21046;&#24207;&#21015;&#65292;&#24182;&#35266;&#23519;&#21040;&#25511;&#21046;&#33033;&#20914;&#23494;&#38598;&#24212;&#29992;&#21487;&#20197;&#25552;&#39640;&#32467;&#26524;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.16320</link><description>&lt;p&gt;
&#21033;&#29992;&#24378;&#21270;&#23398;&#20064;&#29983;&#25104;&#38750;&#32463;&#20856;&#38598;&#21512;&#33258;&#26059;&#24577;&#30340;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Prepare Non-classical Collective Spin State by Reinforcement Learning. (arXiv:2401.16320v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16320
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#35774;&#35745;&#25511;&#21046;&#22330;&#30340;&#26041;&#26696;&#25104;&#21151;&#29983;&#25104;&#20102;&#38750;&#32463;&#20856;&#24577;&#65292;&#20197;&#24212;&#29992;&#20110;&#33258;&#26059;&#21387;&#32553;&#24577;&#30340;&#20135;&#29983;&#12290;&#35813;&#26041;&#27861;&#22312;&#20445;&#25345;&#21387;&#32553;&#21644;&#32416;&#32544;&#30340;&#21516;&#26102;&#25552;&#20379;&#20102;&#19981;&#21516;&#30340;&#25511;&#21046;&#24207;&#21015;&#65292;&#24182;&#35266;&#23519;&#21040;&#25511;&#21046;&#33033;&#20914;&#23494;&#38598;&#24212;&#29992;&#21487;&#20197;&#25552;&#39640;&#32467;&#26524;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#24378;&#21270;&#23398;&#20064;&#26469;&#35774;&#35745;&#25511;&#21046;&#22330;&#30340;&#26041;&#26696;&#65292;&#29992;&#20110;&#29983;&#25104;&#38750;&#32463;&#20856;&#24577;&#12290;&#35813;&#26041;&#26696;&#20197;&#24212;&#29992;&#20110;&#24320;&#25918;&#38598;&#20307;&#33258;&#26059;&#27169;&#22411;&#20013;&#30340;&#33258;&#26059;&#21387;&#32553;&#24577;&#20026;&#20363;&#65292;&#20854;&#20013;&#35774;&#35745;&#20102;&#19968;&#20010;&#32447;&#24615;&#25511;&#21046;&#39033;&#26469;&#25511;&#21046;&#21160;&#21147;&#23398;&#12290;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#26681;&#25454;&#20197;&#32791;&#25955;&#21644;&#21435;&#30456;&#24178;&#20026;&#29305;&#24449;&#30340;&#29615;&#22659;&#20013;&#30340;&#30456;&#24178;&#33258;&#26059;&#24577;&#24320;&#22987;&#65292;&#30830;&#23450;&#20102;&#25511;&#21046;&#33033;&#20914;&#30340;&#26102;&#38388;&#24207;&#21015;&#12290;&#19982;&#24658;&#23450;&#25511;&#21046;&#26041;&#26696;&#30456;&#27604;&#65292;&#36825;&#31181;&#26041;&#27861;&#25552;&#20379;&#20102;&#22810;&#31181;&#25511;&#21046;&#24207;&#21015;&#65292;&#20445;&#25345;&#20102;&#38598;&#20307;&#33258;&#26059;&#21387;&#32553;&#21644;&#32416;&#32544;&#12290;&#35266;&#23519;&#21040;&#25511;&#21046;&#33033;&#20914;&#30340;&#23494;&#38598;&#24212;&#29992;&#21487;&#20197;&#22686;&#24378;&#32467;&#26524;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#28155;&#21152;&#25511;&#21046;&#25805;&#20316;&#65292;&#24615;&#33021;&#24471;&#21040;&#20102;&#36731;&#24494;&#22686;&#24378;&#12290;&#25152;&#25552;&#20986;&#30340;&#31574;&#30053;&#22312;&#36739;&#22823;&#31995;&#32479;&#20013;&#23637;&#29616;&#20102;&#26356;&#39640;&#30340;&#25928;&#26524;&#12290;&#23545;&#20648;&#22791;&#28909;&#28608;&#21457;&#23545;&#25511;&#21046;&#32467;&#26524;&#26377;&#19981;&#21033;&#24433;&#21709;&#12290;&#24212;&#35813;&#30830;&#35748;&#36825;&#19968;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a scheme leveraging reinforcement learning to engineer control fields for generating non-classical states. It is exemplified by the application to prepare spin squeezed state for an open collective spin model where a linear control term is designed to govern the dynamics. The reinforcement learning agent determines the temporal sequence of control pulses, commencing from coherent spin state in an environment characterized by dissipation and dephasing. When compared to constant control scenarios, this approach provides various control sequences maintaining collective spin squeezing and entanglement. It is observed that denser application of the control pulses enhances the performance of the outcomes. Furthermore, there is a minor enhancement in the performance by adding control actions. The proposed strategy demonstrates increased effectiveness for larger systems. And thermal excitations of the reservoir are detrimental to the control outcomes. It should be confirmed that thi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#20248;&#21270;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#29305;&#23450;&#30340;&#38543;&#26426;&#23545;&#20598;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#26631;&#20934;&#22238;&#24402;&#22522;&#20934;&#21644;&#36125;&#21494;&#26031;&#20248;&#21270;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#24456;&#39640;&#30340;&#31454;&#20105;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.20581</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#27491;&#30830;&#23454;&#29616;
&lt;/p&gt;
&lt;p&gt;
Stochastic Gradient Descent for Gaussian Processes Done Right. (arXiv:2310.20581v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20581
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#20248;&#21270;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#29305;&#23450;&#30340;&#38543;&#26426;&#23545;&#20598;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#26631;&#20934;&#22238;&#24402;&#22522;&#20934;&#21644;&#36125;&#21494;&#26031;&#20248;&#21270;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#24456;&#39640;&#30340;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#24179;&#26041;&#25439;&#22833;&#20989;&#25968;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#30446;&#21069;&#65292;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#26368;&#24120;&#35265;&#26041;&#27861;&#26159;&#24212;&#29992;&#31934;&#30830;&#27714;&#35299;&#22120;&#65292;&#27604;&#22914;&#20849;&#36717;&#26799;&#24230;&#19979;&#38477;&#65292;&#35201;&#20040;&#30452;&#25509;&#24212;&#29992;&#65292;&#35201;&#20040;&#24212;&#29992;&#20110;&#38382;&#39064;&#30340;&#38477;&#38454;&#29256;&#26412;&#12290;&#26368;&#36817;&#65292;&#22312;&#28145;&#24230;&#23398;&#20064;&#30340;&#25104;&#21151;&#25512;&#21160;&#19979;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20316;&#20026;&#19968;&#31181;&#26367;&#20195;&#26041;&#27861;&#33719;&#24471;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#26412;&#25991;&#23637;&#31034;&#20102;&#24403;&#27491;&#30830;&#20351;&#29992;&#26102;&#65288;&#25105;&#20204;&#25351;&#30340;&#26159;&#21033;&#29992;&#20248;&#21270;&#21644;&#26680;&#20989;&#25968;&#39046;&#22495;&#30340;&#29305;&#23450;&#35265;&#35299;&#65289;&#65292;&#36825;&#31181;&#26041;&#27861;&#26159;&#38750;&#24120;&#26377;&#25928;&#30340;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#29305;&#23450;&#30340;&#38543;&#26426;&#23545;&#20598;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#21487;&#20197;&#20351;&#29992;&#20219;&#20309;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#30340;&#20960;&#34892;&#20195;&#30721;&#23454;&#29616;&#12290;&#25105;&#20204;&#36890;&#36807;&#28040;&#34701;&#23454;&#39564;&#35299;&#37322;&#20102;&#25105;&#20204;&#30340;&#35774;&#35745;&#20915;&#31574;&#30340;&#20248;&#21183;&#65292;&#24182;&#34920;&#26126;&#26032;&#26041;&#27861;&#20855;&#26377;&#24456;&#39640;&#30340;&#31454;&#20105;&#21147;&#12290;&#25105;&#20204;&#23545;&#26631;&#20934;&#22238;&#24402;&#22522;&#20934;&#21644;&#36125;&#21494;&#26031;&#20248;&#21270;&#20219;&#21153;&#36827;&#34892;&#35780;&#20272;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the optimisation problem associated with Gaussian process regression using squared loss. The most common approach to this problem is to apply an exact solver, such as conjugate gradient descent, either directly, or to a reduced-order version of the problem. Recently, driven by successes in deep learning, stochastic gradient descent has gained traction as an alternative. In this paper, we show that when done right$\unicode{x2014}$by which we mean using specific insights from the optimisation and kernel communities$\unicode{x2014}$this approach is highly effective. We thus introduce a particular stochastic dual gradient descent algorithm, that may be implemented with a few lines of code using any deep learning framework. We explain our design decisions by illustrating their advantage against alternatives with ablation studies and show that the new method is highly competitive. Our evaluations on standard regression benchmarks and a Bayesian optimisation task set our approach apa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32771;&#34385;&#20102;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#22312;&#21521;&#37327;&#20540;&#20869;&#26680;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;&#25910;&#25947;&#24615;&#33021;&#65292;&#35777;&#26126;&#20102;&#22312;RKHS&#33539;&#25968;&#20013;&#30340;&#26399;&#26395;&#24179;&#26041;&#35823;&#24046;&#21487;&#20197;&#34987;&#19968;&#20010;&#29305;&#23450;&#20844;&#24335;&#25152;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2309.07779</link><description>&lt;p&gt;
&#22312;&#21521;&#37327;&#20540;&#20869;&#26680;&#22238;&#24402;&#30340;&#22312;&#32447;&#31639;&#27861;&#30340;&#25910;&#25947;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Convergence analysis of online algorithms for vector-valued kernel regression. (arXiv:2309.07779v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07779
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#22312;&#21521;&#37327;&#20540;&#20869;&#26680;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;&#25910;&#25947;&#24615;&#33021;&#65292;&#35777;&#26126;&#20102;&#22312;RKHS&#33539;&#25968;&#20013;&#30340;&#26399;&#26395;&#24179;&#26041;&#35823;&#24046;&#21487;&#20197;&#34987;&#19968;&#20010;&#29305;&#23450;&#20844;&#24335;&#25152;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#36866;&#24403;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#20316;&#20026;&#20808;&#39564;&#65292;&#36890;&#36807;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#20174;&#22122;&#22768;&#21521;&#37327;&#20540;&#25968;&#25454;&#20013;&#36924;&#36817;&#22238;&#24402;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;&#22312;&#22312;&#32447;&#31639;&#27861;&#20013;&#65292;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#26679;&#26412;&#36890;&#36807;&#38543;&#26426;&#36807;&#31243;&#36880;&#20010;&#21487;&#29992;&#65292;&#24182;&#20381;&#27425;&#22788;&#29702;&#20197;&#26500;&#24314;&#23545;&#22238;&#24402;&#20989;&#25968;&#30340;&#36817;&#20284;&#12290;&#25105;&#20204;&#20851;&#27880;&#36825;&#31181;&#22312;&#32447;&#36924;&#36817;&#31639;&#27861;&#30340;&#28176;&#36817;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;RKHS&#33539;&#25968;&#20013;&#30340;&#26399;&#26395;&#24179;&#26041;&#35823;&#24046;&#21487;&#20197;&#34987;$C^2(m+1)^{-s/(2+s)}$&#32465;&#23450;&#65292;&#20854;&#20013;$m$&#20026;&#24403;&#19979;&#22788;&#29702;&#30340;&#25968;&#25454;&#25968;&#37327;&#65292;&#21442;&#25968;$0&lt;s\leq 1$&#34920;&#31034;&#23545;&#22238;&#24402;&#20989;&#25968;&#30340;&#39069;&#22806;&#20809;&#28369;&#24615;&#20551;&#35774;&#65292;&#24120;&#25968;$C$&#21462;&#20915;&#20110;&#36755;&#20837;&#22122;&#22768;&#30340;&#26041;&#24046;&#12289;&#22238;&#24402;&#20989;&#25968;&#30340;&#20809;&#28369;&#24615;&#20197;&#21450;&#31639;&#27861;&#30340;&#20854;&#20182;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of approximating the regression function from noisy vector-valued data by an online learning algorithm using an appropriate reproducing kernel Hilbert space (RKHS) as prior. In an online algorithm, i.i.d. samples become available one by one by a random process and are successively processed to build approximations to the regression function. We are interested in the asymptotic performance of such online approximation algorithms and show that the expected squared error in the RKHS norm can be bounded by $C^2 (m+1)^{-s/(2+s)}$, where $m$ is the current number of processed data, the parameter $0&lt;s\leq 1$ expresses an additional smoothness assumption on the regression function and the constant $C$ depends on the variance of the input noise, the smoothness of the regression function and further parameters of the algorithm.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65288;PINN&#65289;&#12290;&#35813;&#26041;&#27861;&#37319;&#29992;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#36890;&#36807;&#35745;&#31639;&#35777;&#25454;&#26469;&#20248;&#21270;&#27169;&#22411;&#24182;&#35299;&#20915;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.13222</link><description>&lt;p&gt;
&#29992;&#20110;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#30340;&#36125;&#21494;&#26031;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Bayesian Reasoning for Physics Informed Neural Networks. (arXiv:2308.13222v1 [physics.comp-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13222
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65288;PINN&#65289;&#12290;&#35813;&#26041;&#27861;&#37319;&#29992;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#36890;&#36807;&#35745;&#31639;&#35777;&#25454;&#26469;&#20248;&#21270;&#27169;&#22411;&#24182;&#35299;&#20915;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#20844;&#24335;&#30340;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#65288;PINN&#65289;&#26041;&#27861;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;MacKay&#22312;Neural Computation&#65288;1992&#24180;&#65289;&#20013;&#25552;&#20986;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#12290;&#36890;&#36807;&#25289;&#26222;&#25289;&#26031;&#36817;&#20284;&#27861;&#65292;&#24471;&#21040;&#21518;&#39564;&#23494;&#24230;&#12290;&#23545;&#20110;&#27599;&#20010;&#27169;&#22411;&#65288;&#25311;&#21512;&#65289;&#65292;&#35745;&#31639;&#25152;&#35859;&#30340;&#35777;&#25454;&#12290;&#23427;&#26159;&#19968;&#31181;&#20998;&#31867;&#20551;&#35774;&#30340;&#24230;&#37327;&#12290;&#26368;&#20248;&#35299;&#20855;&#26377;&#26368;&#22823;&#30340;&#35777;&#25454;&#20540;&#12290;&#36125;&#21494;&#26031;&#26694;&#26550;&#20351;&#25105;&#20204;&#33021;&#22815;&#25511;&#21046;&#36793;&#30028;&#23545;&#24635;&#25439;&#22833;&#30340;&#24433;&#21709;&#12290;&#20107;&#23454;&#19978;&#65292;&#36125;&#21494;&#26031;&#31639;&#27861;&#36890;&#36807;&#24494;&#35843;&#25439;&#22833;&#32452;&#20214;&#30340;&#30456;&#23545;&#26435;&#37325;&#12290;&#25105;&#20204;&#35299;&#20915;&#20102;&#28909;&#21147;&#23398;&#12289;&#27874;&#21160;&#21644;Burger&#26041;&#31243;&#12290;&#25152;&#24471;&#32467;&#26524;&#19982;&#31934;&#30830;&#35299;&#22522;&#26412;&#19968;&#33268;&#12290;&#25152;&#26377;&#35299;&#37117;&#25552;&#20379;&#20102;&#22312;&#36125;&#21494;&#26031;&#26694;&#26550;&#20869;&#35745;&#31639;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Physics informed neural network (PINN) approach in Bayesian formulation is presented. We adopt the Bayesian neural network framework formulated by MacKay (Neural Computation 4 (3) (1992) 448). The posterior densities are obtained from Laplace approximation. For each model (fit), the so-called evidence is computed. It is a measure that classifies the hypothesis. The most optimal solution has the maximal value of the evidence. The Bayesian framework allows us to control the impact of the boundary contribution to the total loss. Indeed, the relative weights of loss components are fine-tuned by the Bayesian algorithm. We solve heat, wave, and Burger's equations. The obtained results are in good agreement with the exact solutions. All solutions are provided with the uncertainties computed within the Bayesian framework.
&lt;/p&gt;</description></item><item><title>&#28145;&#23618;&#25805;&#20316;&#31526;&#32593;&#32476;&#65288;DeepONet&#65289;&#20316;&#20026;&#19968;&#31181;&#24378;&#22823;&#30340;&#26367;&#20195;&#24314;&#27169;&#26041;&#27861;&#65292;&#22312;&#26680;&#31995;&#32479;&#25968;&#23383;&#23402;&#29983;&#25216;&#26415;&#20013;&#23637;&#31034;&#20986;&#20102;&#26174;&#33879;&#30340;&#39044;&#27979;&#31934;&#24230;&#21644;&#35745;&#31639;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#25361;&#25112;&#20173;&#28982;&#23384;&#22312;&#65292;&#21253;&#25324;&#26368;&#20339;&#20256;&#24863;&#22120;&#25918;&#32622;&#21644;&#27169;&#22411;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2308.07523</link><description>&lt;p&gt;
&#28145;&#23618;&#25805;&#20316;&#31526;&#32593;&#32476;&#22312;&#26680;&#31995;&#32479;&#25968;&#23383;&#23402;&#29983;&#25216;&#26415;&#20013;&#30340;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;
Potential of Deep Operator Networks in Digital Twin-enabling Technology for Nuclear System. (arXiv:2308.07523v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07523
&lt;/p&gt;
&lt;p&gt;
&#28145;&#23618;&#25805;&#20316;&#31526;&#32593;&#32476;&#65288;DeepONet&#65289;&#20316;&#20026;&#19968;&#31181;&#24378;&#22823;&#30340;&#26367;&#20195;&#24314;&#27169;&#26041;&#27861;&#65292;&#22312;&#26680;&#31995;&#32479;&#25968;&#23383;&#23402;&#29983;&#25216;&#26415;&#20013;&#23637;&#31034;&#20986;&#20102;&#26174;&#33879;&#30340;&#39044;&#27979;&#31934;&#24230;&#21644;&#35745;&#31639;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#25361;&#25112;&#20173;&#28982;&#23384;&#22312;&#65292;&#21253;&#25324;&#26368;&#20339;&#20256;&#24863;&#22120;&#25918;&#32622;&#21644;&#27169;&#22411;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#26680;&#24037;&#31243;&#30340;&#25968;&#23383;&#23402;&#29983;&#31995;&#32479;&#20013;&#24341;&#20837;&#20102;&#28145;&#23618;&#25805;&#20316;&#31526;&#32593;&#32476;&#65288;DeepONet&#65289;&#20316;&#20026;&#19968;&#31181;&#24378;&#22823;&#30340;&#26367;&#20195;&#24314;&#27169;&#26041;&#27861;&#12290;&#38543;&#30528;&#26680;&#33021;&#20316;&#20026;&#19968;&#31181;&#30899;&#20013;&#21644;&#35299;&#20915;&#26041;&#26696;&#30340;&#37325;&#35201;&#24615;&#19981;&#26029;&#22686;&#21152;&#65292;&#37319;&#29992;&#25968;&#23383;&#23402;&#29983;&#25216;&#26415;&#23545;&#20110;&#25552;&#39640;&#26680;&#24037;&#31243;&#24212;&#29992;&#20013;&#30340;&#36816;&#33829;&#25928;&#29575;&#12289;&#23433;&#20840;&#24615;&#21644;&#39044;&#27979;&#33021;&#21147;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;DeepONet&#20855;&#26377;&#26174;&#33879;&#30340;&#39044;&#27979;&#31934;&#24230;&#65292;&#20248;&#20110;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#22522;&#20934;&#27979;&#35797;&#21644;&#35780;&#20272;&#65292;&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;DeepONet&#22312;&#35299;&#20915;&#22797;&#26434;&#31890;&#23376;&#20256;&#36755;&#38382;&#39064;&#20013;&#30340;&#21487;&#25193;&#23637;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#12290;&#36890;&#36807;&#23558;&#20989;&#25968;&#20316;&#20026;&#36755;&#20837;&#25968;&#25454;&#24182;&#20351;&#29992;&#35757;&#32451;&#25968;&#25454;&#26500;&#24314;&#25805;&#20316;&#31526;G&#65292;DeepONet&#33021;&#22815;&#26377;&#25928;&#22788;&#29702;&#22810;&#26679;&#21270;&#21644;&#22797;&#26434;&#30340;&#22330;&#26223;&#12290;&#28982;&#32780;&#65292;DeepONet&#30340;&#24212;&#29992;&#20063;&#25581;&#31034;&#20102;&#19982;&#26368;&#20339;&#20256;&#24863;&#22120;&#25918;&#32622;&#21644;&#27169;&#22411;&#35780;&#20272;&#30456;&#20851;&#30340;&#25361;&#25112;&#65292;&#36825;&#26159;&#23454;&#38469;&#23454;&#26045;&#20013;&#30340;&#20851;&#38190;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This research introduces the Deep Operator Network (DeepONet) as a robust surrogate modeling method within the context of digital twin (DT) systems for nuclear engineering. With the increasing importance of nuclear energy as a carbon-neutral solution, adopting DT technology has become crucial to enhancing operational efficiencies, safety, and predictive capabilities in nuclear engineering applications. DeepONet exhibits remarkable prediction accuracy, outperforming traditional ML methods. Through extensive benchmarking and evaluation, this study showcases the scalability and computational efficiency of DeepONet in solving a challenging particle transport problem. By taking functions as input data and constructing the operator $G$ from training data, DeepONet can handle diverse and complex scenarios effectively. However, the application of DeepONet also reveals challenges related to optimal sensor placement and model evaluation, critical aspects of real-world implementation. Addressing 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#23545;&#31070;&#32463;&#31639;&#27861;&#25512;&#29702;&#22120;&#20013;&#25191;&#34892;&#31639;&#27861;&#26102;&#20135;&#29983;&#30340;&#28508;&#22312;&#31354;&#38388;&#32467;&#26500;&#36827;&#34892;&#20102;&#35814;&#32454;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#20102;&#35299;&#20915;&#20004;&#31181;&#25925;&#38556;&#27169;&#24335;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;softmax&#32858;&#21512;&#22120;&#35299;&#20915;&#20998;&#36776;&#29575;&#20007;&#22833;&#38382;&#39064;&#65292;&#20197;&#21450;&#34928;&#20943;&#28508;&#22312;&#31354;&#38388;&#26469;&#22788;&#29702;&#36229;&#20986;&#33539;&#22260;&#30340;&#20540;&#65292;&#36825;&#20123;&#25913;&#21464;&#22312;&#26631;&#20934;CLRS-30&#22522;&#20934;&#27979;&#35797;&#20013;&#22823;&#22810;&#25968;&#31639;&#27861;&#19978;&#23454;&#29616;&#20102;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2307.08874</link><description>&lt;p&gt;
&#31070;&#32463;&#31639;&#27861;&#25512;&#29702;&#22120;&#30340;&#28508;&#22312;&#31354;&#38388;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Latent Space Representations of Neural Algorithmic Reasoners. (arXiv:2307.08874v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08874
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#23545;&#31070;&#32463;&#31639;&#27861;&#25512;&#29702;&#22120;&#20013;&#25191;&#34892;&#31639;&#27861;&#26102;&#20135;&#29983;&#30340;&#28508;&#22312;&#31354;&#38388;&#32467;&#26500;&#36827;&#34892;&#20102;&#35814;&#32454;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#20102;&#35299;&#20915;&#20004;&#31181;&#25925;&#38556;&#27169;&#24335;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;softmax&#32858;&#21512;&#22120;&#35299;&#20915;&#20998;&#36776;&#29575;&#20007;&#22833;&#38382;&#39064;&#65292;&#20197;&#21450;&#34928;&#20943;&#28508;&#22312;&#31354;&#38388;&#26469;&#22788;&#29702;&#36229;&#20986;&#33539;&#22260;&#30340;&#20540;&#65292;&#36825;&#20123;&#25913;&#21464;&#22312;&#26631;&#20934;CLRS-30&#22522;&#20934;&#27979;&#35797;&#20013;&#22823;&#22810;&#25968;&#31639;&#27861;&#19978;&#23454;&#29616;&#20102;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#31639;&#27861;&#25512;&#29702;&#65288;NAR&#65289;&#26159;&#19968;&#20010;&#30740;&#31350;&#39046;&#22495;&#65292;&#19987;&#27880;&#20110;&#35774;&#35745;&#33021;&#22815;&#21487;&#38752;&#22320;&#25429;&#25417;&#32463;&#20856;&#35745;&#31639;&#30340;&#31070;&#32463;&#26550;&#26500;&#65292;&#36890;&#24120;&#36890;&#36807;&#23398;&#20064;&#25191;&#34892;&#31639;&#27861;&#26469;&#23454;&#29616;&#12290;&#20856;&#22411;&#30340;&#26041;&#27861;&#26159;&#20381;&#36182;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#26550;&#26500;&#65292;&#23427;&#20204;&#23558;&#36755;&#20837;&#32534;&#30721;&#20026;&#39640;&#32500;&#28508;&#22312;&#31354;&#38388;&#65292;&#22312;&#31639;&#27861;&#25191;&#34892;&#26399;&#38388;&#21453;&#22797;&#36716;&#25442;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23545;GNN&#22312;&#25191;&#34892;&#31639;&#27861;&#26102;&#23548;&#33268;&#30340;&#28508;&#22312;&#31354;&#38388;&#32467;&#26500;&#36827;&#34892;&#20102;&#35814;&#32454;&#20998;&#26512;&#12290;&#25105;&#20204;&#21457;&#29616;&#20102;&#20004;&#31181;&#21487;&#33021;&#30340;&#25925;&#38556;&#27169;&#24335;&#65306;&#65288;i&#65289;&#20998;&#36776;&#29575;&#20007;&#22833;&#65292;&#20351;&#24471;&#38590;&#20197;&#21306;&#20998;&#30456;&#20284;&#30340;&#20540;&#65307;&#65288;ii&#65289;&#26080;&#27861;&#22788;&#29702;&#35757;&#32451;&#26399;&#38388;&#26410;&#35266;&#23519;&#21040;&#30340;&#20540;&#33539;&#22260;&#20043;&#22806;&#30340;&#20540;&#12290;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#20381;&#36182;softmax&#32858;&#21512;&#22120;&#26469;&#35299;&#20915;&#31532;&#19968;&#20010;&#38382;&#39064;&#65292;&#24182;&#24314;&#35758;&#34928;&#20943;&#28508;&#22312;&#31354;&#38388;&#20197;&#22788;&#29702;&#36229;&#20986;&#33539;&#22260;&#30340;&#20540;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#21464;&#21270;&#22312;&#20351;&#29992;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#26102;&#65292;&#22312;&#26631;&#20934;CLRS-30&#22522;&#20934;&#27979;&#35797;&#20013;&#22823;&#22810;&#25968;&#31639;&#27861;&#19978;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural Algorithmic Reasoning (NAR) is a research area focused on designing neural architectures that can reliably capture classical computation, usually by learning to execute algorithms. A typical approach is to rely on Graph Neural Network (GNN) architectures, which encode inputs in high-dimensional latent spaces that are repeatedly transformed during the execution of the algorithm. In this work we perform a detailed analysis of the structure of the latent space induced by the GNN when executing algorithms. We identify two possible failure modes: (i) loss of resolution, making it hard to distinguish similar values; (ii) inability to deal with values outside the range observed during training. We propose to solve the first issue by relying on a softmax aggregator, and propose to decay the latent space in order to deal with out-of-range values. We show that these changes lead to improvements on the majority of algorithms in the standard CLRS-30 benchmark when using the state-of-the-art
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#29992;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#31232;&#30095;&#27491;&#21017;&#21270;&#20013;&#36827;&#34892;&#24179;&#28369;&#20248;&#21270;&#65292;&#19982;&#20027;&#27969;&#30340;&#19968;&#38454;&#20248;&#21270;&#26041;&#27861;&#20860;&#23481;&#65292;&#24182;&#19988;&#33021;&#22815;&#24471;&#21040;&#21305;&#37197;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#21644;&#31561;&#20215;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;</title><link>http://arxiv.org/abs/2307.03571</link><description>&lt;p&gt;
&#24179;&#28369;&#36793;&#32536;&#65306;&#21033;&#29992;Hadamard&#36229;&#21442;&#25968;&#21270;&#22312;&#31232;&#30095;&#27491;&#21017;&#21270;&#30340;&#24179;&#28369;&#20248;&#21270;&#20013;&#30340;&#19968;&#33324;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Smoothing the Edges: A General Framework for Smooth Optimization in Sparse Regularization using Hadamard Overparametrization. (arXiv:2307.03571v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03571
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#29992;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#31232;&#30095;&#27491;&#21017;&#21270;&#20013;&#36827;&#34892;&#24179;&#28369;&#20248;&#21270;&#65292;&#19982;&#20027;&#27969;&#30340;&#19968;&#38454;&#20248;&#21270;&#26041;&#27861;&#20860;&#23481;&#65292;&#24182;&#19988;&#33021;&#22815;&#24471;&#21040;&#21305;&#37197;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#21644;&#31561;&#20215;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#65288;&#32467;&#26500;&#21270;&#65289;&#31232;&#30095;&#27491;&#21017;&#21270;&#38382;&#39064;&#20013;&#30340;$\ell_q$&#21644;$\ell_{p,q}$&#27491;&#21017;&#21270;&#30340;&#24179;&#28369;&#26041;&#27861;&#12290;&#36825;&#20123;&#38750;&#24179;&#28369;&#19988;&#21487;&#33021;&#38750;&#20984;&#30340;&#38382;&#39064;&#30340;&#20248;&#21270;&#36890;&#24120;&#20381;&#36182;&#20110;&#19987;&#38376;&#30340;&#36807;&#31243;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#25105;&#20204;&#30340;&#19968;&#33324;&#26694;&#26550;&#19982;&#20027;&#27969;&#30340;&#19968;&#38454;&#20248;&#21270;&#26041;&#27861;&#65288;&#22914;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#21644;&#21152;&#36895;&#21464;&#20307;&#65289;&#20860;&#23481;&#65292;&#26080;&#38656;&#20219;&#20309;&#20462;&#25913;&#12290;&#36825;&#26159;&#36890;&#36807;&#24179;&#28369;&#20248;&#21270;&#36716;&#31227;&#23454;&#29616;&#30340;&#65292;&#20854;&#20013;&#36873;&#23450;&#27169;&#22411;&#21442;&#25968;&#30340;&#36229;&#21442;&#25968;&#21270;&#20351;&#29992;Hadamard&#20056;&#31215;&#21644;&#24809;&#32602;&#30340;&#25913;&#21464;&#12290;&#22312;&#36229;&#21442;&#25968;&#38382;&#39064;&#20013;&#65292;&#36890;&#36807;&#29992;&#26367;&#20195;&#21442;&#25968;&#36827;&#34892;&#24179;&#28369;&#21644;&#20984;&#24615;&#30340;$\ell_2$&#27491;&#21017;&#21270;&#65292;&#33021;&#22815;&#22312;&#21407;&#22987;&#21442;&#25968;&#21270;&#20013;&#24341;&#20837;&#38750;&#24179;&#28369;&#21644;&#38750;&#20984;&#24615;&#30340;$\ell_q$&#25110;$\ell_{p,q}$&#27491;&#21017;&#21270;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#20165;&#33021;&#22815;&#24471;&#21040;&#21305;&#37197;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#65292;&#36824;&#33021;&#24471;&#21040;&#31561;&#20215;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;&#36825;&#22312;&#38750;&#20984;&#31232;&#30095;&#27491;&#21017;&#21270;&#20013;&#23588;&#20854;&#26377;&#29992;&#65292;&#22240;&#20026;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#25214;&#21040;&#20840;&#23616;&#26368;&#23567;&#20540;&#38750;&#24120;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a smooth method for (structured) sparsity in $\ell_q$ and $\ell_{p,q}$ regularized optimization problems. Optimization of these non-smooth and possibly non-convex problems typically relies on specialized procedures. In contrast, our general framework is compatible with prevalent first-order optimization methods like Stochastic Gradient Descent and accelerated variants without any required modifications. This is accomplished through a smooth optimization transfer, comprising an overparametrization of selected model parameters using Hadamard products and a change of penalties. In the overparametrized problem, smooth and convex $\ell_2$ regularization of the surrogate parameters induces non-smooth and non-convex $\ell_q$ or $\ell_{p,q}$ regularization in the original parametrization. We show that our approach yields not only matching global minima but also equivalent local minima. This is particularly useful in non-convex sparse regularization, where finding global m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#22823;&#20559;&#24046;&#29702;&#35770;&#65292;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20989;&#25968;&#30340;&#24179;&#28369;&#27169;&#22411;&#29305;&#24449;&#25551;&#36848;&#26041;&#27861;&#65292;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#19968;&#20123;&#25554;&#20540;&#22120;&#26377;&#24456;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#20197;&#21450;&#29616;&#20195;&#23398;&#20064;&#25216;&#26415;&#20026;&#20160;&#20040;&#33021;&#22815;&#25214;&#21040;&#23427;&#20204;&#12290;</title><link>http://arxiv.org/abs/2306.10947</link><description>&lt;p&gt;
&#20351;&#29992;&#36895;&#29575;&#20989;&#25968;&#29702;&#35299;&#25554;&#20540;&#21306;&#38388;&#30340;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Understanding Generalization in the Interpolation Regime using the Rate Function. (arXiv:2306.10947v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10947
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#22823;&#20559;&#24046;&#29702;&#35770;&#65292;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20989;&#25968;&#30340;&#24179;&#28369;&#27169;&#22411;&#29305;&#24449;&#25551;&#36848;&#26041;&#27861;&#65292;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#19968;&#20123;&#25554;&#20540;&#22120;&#26377;&#24456;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#20197;&#21450;&#29616;&#20195;&#23398;&#20064;&#25216;&#26415;&#20026;&#20160;&#20040;&#33021;&#22815;&#25214;&#21040;&#23427;&#20204;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22522;&#20110;&#22823;&#20559;&#24046;&#29702;&#35770;&#30340;&#22522;&#26412;&#21407;&#29702;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#24179;&#28369;&#24230;&#30340;&#26032;&#29305;&#24449;&#25551;&#36848;&#26041;&#27861;&#12290;&#19982;&#20197;&#24448;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#20197;&#24448;&#30340;&#24037;&#20316;&#36890;&#24120;&#29992;&#23454;&#25968;&#20540;&#65288;&#22914;&#26435;&#37325;&#33539;&#25968;&#65289;&#26469;&#34920;&#24449;&#27169;&#22411;&#30340;&#24179;&#28369;&#24230;&#65292;&#25105;&#20204;&#34920;&#26126;&#21487;&#20197;&#29992;&#31616;&#21333;&#30340;&#23454;&#20540;&#20989;&#25968;&#26469;&#25551;&#36848;&#24179;&#28369;&#24230;&#12290;&#22522;&#20110;&#27169;&#22411;&#24179;&#28369;&#24230;&#30340;&#36825;&#19968;&#27010;&#24565;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#29702;&#35770;&#35299;&#37322;&#65292;&#20026;&#20160;&#20040;&#19968;&#20123;&#25554;&#20540;&#22120;&#34920;&#29616;&#20986;&#38750;&#24120;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#20197;&#21450;&#20026;&#20160;&#20040;&#24191;&#27867;&#20351;&#29992;&#30340;&#29616;&#20195;&#23398;&#20064;&#25216;&#26415;&#65288;&#22914;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65292;$\ell_2$-&#35268;&#33539;&#21270;&#65292;&#25968;&#25454;&#22686;&#24378;&#65292;&#19981;&#21464;&#30340;&#26550;&#26500;&#21644;&#36229;&#21442;&#25968;&#21270;&#65289;&#33021;&#22815;&#25214;&#21040;&#23427;&#20204;&#12290;&#25105;&#20204;&#24471;&#20986;&#30340;&#32467;&#35770;&#26159;&#65292;&#25152;&#26377;&#36825;&#20123;&#26041;&#27861;&#37117;&#25552;&#20379;&#20102;&#20114;&#34917;&#30340;&#36807;&#31243;&#65292;&#36825;&#20123;&#36807;&#31243;&#20351;&#20248;&#21270;&#22120;&#20559;&#21521;&#20110;&#26356;&#24179;&#28369;&#30340;&#25554;&#20540;&#22120;&#65292;&#32780;&#26681;&#25454;&#36825;&#31181;&#29702;&#35770;&#20998;&#26512;&#65292;&#26356;&#24179;&#28369;&#30340;&#25554;&#20540;&#22120;&#26159;&#20855;&#26377;&#26356;&#22909;&#30340;&#27867;&#21270;&#35823;&#24046;&#30340;&#25554;&#20540;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present a novel characterization of the smoothness of a model based on basic principles of Large Deviation Theory. In contrast to prior work, where the smoothness of a model is normally characterized by a real value (e.g., the weights' norm), we show that smoothness can be described by a simple real-valued function. Based on this concept of smoothness, we propose an unifying theoretical explanation of why some interpolators generalize remarkably well and why a wide range of modern learning techniques (i.e., stochastic gradient descent, $\ell_2$-norm regularization, data augmentation, invariant architectures, and overparameterization) are able to find them. The emergent conclusion is that all these methods provide complimentary procedures that bias the optimizer to smoother interpolators, which, according to this theoretical analysis, are the ones with better generalization error.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#26368;&#20248;&#23545;&#25239;&#39044;&#27979;&#22120;&#30340;&#21508;&#31181;&#22522;&#26412;&#29305;&#24615;&#65292;&#24182;&#32467;&#21512;&#26032;&#30340;Rademacher&#22797;&#26434;&#24230;&#30028;&#38480;&#35777;&#26126;&#20102;&#65292;&#22312;&#27973;&#23618;&#32593;&#32476;&#19978;&#36827;&#34892;&#23545;&#25239;&#35757;&#32451;&#65292;&#37319;&#29992;&#26089;&#20572;&#21644;&#29702;&#24819;&#30340;&#26368;&#20248;&#23545;&#25163;&#65292;&#33021;&#22815;&#23454;&#29616;&#26368;&#20248;&#23545;&#25239;&#27979;&#35797;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2306.07544</link><description>&lt;p&gt;
&#20851;&#20110;&#23454;&#29616;&#26368;&#20248;&#23545;&#25239;&#27979;&#35797;&#35823;&#24046;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Achieving Optimal Adversarial Test Error. (arXiv:2306.07544v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07544
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#26368;&#20248;&#23545;&#25239;&#39044;&#27979;&#22120;&#30340;&#21508;&#31181;&#22522;&#26412;&#29305;&#24615;&#65292;&#24182;&#32467;&#21512;&#26032;&#30340;Rademacher&#22797;&#26434;&#24230;&#30028;&#38480;&#35777;&#26126;&#20102;&#65292;&#22312;&#27973;&#23618;&#32593;&#32476;&#19978;&#36827;&#34892;&#23545;&#25239;&#35757;&#32451;&#65292;&#37319;&#29992;&#26089;&#20572;&#21644;&#29702;&#24819;&#30340;&#26368;&#20248;&#23545;&#25163;&#65292;&#33021;&#22815;&#23454;&#29616;&#26368;&#20248;&#23545;&#25239;&#27979;&#35797;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#20808;&#38416;&#36848;&#20102;&#26368;&#20248;&#23545;&#25239;&#39044;&#27979;&#22120;&#30340;&#21508;&#31181;&#22522;&#26412;&#29305;&#24615;&#65306;&#26368;&#20248;&#23545;&#25239;&#20984;&#39044;&#27979;&#22120;&#30340;&#32467;&#26500;&#12289;&#23558;&#23545;&#25239;&#20984;&#25439;&#22833;&#19982;&#23545;&#25239;0-1&#25439;&#22833;&#30456;&#20851;&#32852;&#30340;&#30028;&#38480;&#20197;&#21450;&#36830;&#32493;&#39044;&#27979;&#22120;&#21487;&#20197;&#22312;&#20984;&#21644;0-1&#25439;&#22833;&#19979;&#26080;&#38480;&#25509;&#36817;&#26368;&#20248;&#23545;&#25239;&#35823;&#24046;&#12290;&#26412;&#25991;&#36824;&#23558;&#36825;&#20123;&#32467;&#26524;&#19982;&#23545;&#25239;&#35757;&#32451;&#22312;&#21021;&#22987;&#21270;&#38468;&#36817;&#30340;&#26032;Rademacher&#22797;&#26434;&#24230;&#30028;&#38480;&#30456;&#32467;&#21512;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#19968;&#33324;&#30340;&#25968;&#25454;&#20998;&#24067;&#21644;&#25200;&#21160;&#38598;&#65292;&#22312;&#27973;&#23618;&#32593;&#32476;&#19978;&#36827;&#34892;&#23545;&#25239;&#35757;&#32451;&#65292;&#37319;&#29992;&#26089;&#20572;&#21644;&#29702;&#24819;&#30340;&#26368;&#20248;&#23545;&#25163;&#65292;&#33021;&#22815;&#23454;&#29616;&#26368;&#20248;&#23545;&#25239;&#27979;&#35797;&#35823;&#24046;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#20808;&#21069;&#30340;&#29702;&#35770;&#24037;&#20316;&#21482;&#32771;&#34385;&#20102;&#29305;&#23450;&#30340;&#25968;&#25454;&#20998;&#24067;&#25110;&#20165;&#25552;&#20379;&#20102;&#35757;&#32451;&#35823;&#24046;&#30340;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We first elucidate various fundamental properties of optimal adversarial predictors: the structure of optimal adversarial convex predictors in terms of optimal adversarial zero-one predictors, bounds relating the adversarial convex loss to the adversarial zero-one loss, and the fact that continuous predictors can get arbitrarily close to the optimal adversarial error for both convex and zero-one losses. Applying these results along with new Rademacher complexity bounds for adversarial training near initialization, we prove that for general data distributions and perturbation sets, adversarial training on shallow networks with early stopping and an idealized optimal adversary is able to achieve optimal adversarial test error. By contrast, prior theoretical work either considered specialized data distributions or only provided training error guarantees.
&lt;/p&gt;</description></item><item><title>&#35813;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;Bayesian&#38750;&#21442;&#25968;&#23398;&#20064;&#26694;&#26550;&#65292;&#23545;&#20110;&#27979;&#37327;&#35823;&#24046;&#20855;&#26377;&#24378;&#40065;&#26834;&#24615;&#65292;&#19981;&#38656;&#35201;&#30693;&#36947;&#35823;&#24046;&#20998;&#24067;&#21644;&#21327;&#21464;&#37327;&#21487;&#37325;&#22797;&#27979;&#37327;&#30340;&#20551;&#35774;&#65292;&#24182;&#33021;&#22815;&#21560;&#25910;&#20808;&#39564;&#20449;&#24565;&#65292;&#36825;&#33021;&#20135;&#29983;&#20004;&#31181;&#36890;&#36807;&#19981;&#21516;&#25439;&#22833;&#20989;&#25968;&#30340;&#27979;&#37327;&#35823;&#24046;&#24378;&#40065;&#26834;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.01468</link><description>&lt;p&gt;
&#27979;&#37327;&#35823;&#24046;&#27169;&#22411;&#30340;&#24378;&#40065;&#26834;&#24615;Bayesian&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Robust Bayesian Inference for Measurement Error Models. (arXiv:2306.01468v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01468
&lt;/p&gt;
&lt;p&gt;
&#35813;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;Bayesian&#38750;&#21442;&#25968;&#23398;&#20064;&#26694;&#26550;&#65292;&#23545;&#20110;&#27979;&#37327;&#35823;&#24046;&#20855;&#26377;&#24378;&#40065;&#26834;&#24615;&#65292;&#19981;&#38656;&#35201;&#30693;&#36947;&#35823;&#24046;&#20998;&#24067;&#21644;&#21327;&#21464;&#37327;&#21487;&#37325;&#22797;&#27979;&#37327;&#30340;&#20551;&#35774;&#65292;&#24182;&#33021;&#22815;&#21560;&#25910;&#20808;&#39564;&#20449;&#24565;&#65292;&#36825;&#33021;&#20135;&#29983;&#20004;&#31181;&#36890;&#36807;&#19981;&#21516;&#25439;&#22833;&#20989;&#25968;&#30340;&#27979;&#37327;&#35823;&#24046;&#24378;&#40065;&#26834;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27979;&#37327;&#35823;&#24046;&#26159;&#25351;&#24433;&#21709;&#21709;&#24212;&#21464;&#37327;&#30340;&#21327;&#21464;&#37327;&#21463;&#21040;&#22122;&#22768;&#24178;&#25200;&#12290;&#36825;&#21487;&#33021;&#20250;&#23548;&#33268;&#35823;&#23548;&#24615;&#30340;&#25512;&#26029;&#32467;&#26524;&#65292;&#23588;&#20854;&#26159;&#22312;&#20272;&#35745;&#21327;&#21464;&#37327;&#21644;&#21709;&#24212;&#21464;&#37327;&#20043;&#38388;&#20851;&#31995;&#30340;&#20934;&#30830;&#24615;&#33267;&#20851;&#37325;&#35201;&#30340;&#38382;&#39064;&#20013;&#65292;&#22914;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#38382;&#39064;&#20013;&#12290;&#29616;&#26377;&#30340;&#22788;&#29702;&#27979;&#37327;&#35823;&#24046;&#30340;&#26041;&#27861;&#36890;&#24120;&#20381;&#36182;&#20110;&#24378;&#20551;&#35774;&#65292;&#20363;&#22914;&#23545;&#35823;&#24046;&#20998;&#24067;&#25110;&#20854;&#26041;&#24046;&#30340;&#30693;&#35782;&#21644;&#21327;&#21464;&#37327;&#21487;&#37325;&#22797;&#27979;&#37327;&#30340;&#21487;&#29992;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;Bayesian&#38750;&#21442;&#25968;&#23398;&#20064;&#26694;&#26550;&#65292;&#23427;&#23545;&#20110;&#27979;&#37327;&#35823;&#24046;&#20855;&#26377;&#24378;&#40065;&#26834;&#24615;&#65292;&#19981;&#38656;&#35201;&#19978;&#36848;&#20551;&#35774;&#65292;&#24182;&#33021;&#22815;&#21560;&#25910;&#20851;&#20110;&#30495;&#23454;&#35823;&#24046;&#20998;&#24067;&#30340;&#20808;&#39564;&#20449;&#24565;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20135;&#29983;&#20102;&#20004;&#31181;&#36890;&#36807;&#19981;&#21516;&#25439;&#22833;&#20989;&#25968;&#30340;&#27979;&#37327;&#35823;&#24046;&#24378;&#40065;&#26834;&#26041;&#27861;&#65306;&#19968;&#31181;&#22522;&#20110;&#24635;&#26368;&#23567;&#20108;&#20056;&#30446;&#26631;&#65292;&#21478;&#19968;&#31181;&#22522;&#20110;&#26368;&#22823;&#24179;&#22343;&#20559;&#24046;&#65288;MMD&#65289;&#12290;&#21518;&#32773;&#20801;&#35768;&#25512;&#24191;&#21040;&#38750;&#39640;&#26031;&#20998;&#24067;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Measurement error occurs when a set of covariates influencing a response variable are corrupted by noise. This can lead to misleading inference outcomes, particularly in problems where accurately estimating the relationship between covariates and response variables is crucial, such as causal effect estimation. Existing methods for dealing with measurement error often rely on strong assumptions such as knowledge of the error distribution or its variance and availability of replicated measurements of the covariates. We propose a Bayesian Nonparametric Learning framework which is robust to mismeasured covariates, does not require the preceding assumptions, and is able to incorporate prior beliefs about the true error distribution. Our approach gives rise to two methods that are robust to measurement error via different loss functions: one based on the Total Least Squares objective and the other based on Maximum Mean Discrepancy (MMD). The latter allows for generalisation to non-Gaussian d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22238;&#39038;&#20102;&#26500;&#24314;&#21305;&#37197;&#20219;&#21153;&#35823;&#24046;&#29575;&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#65292;&#30740;&#31350;&#20854;&#32479;&#35745;&#29305;&#24615;&#24182;&#25552;&#20379;&#20102;&#26368;&#20339;&#23454;&#36341;&#24314;&#35758;&#12290;</title><link>http://arxiv.org/abs/2306.01198</link><description>&lt;p&gt;
&#21305;&#37197;&#20219;&#21153;&#30340;&#35823;&#24046;&#29575;&#32622;&#20449;&#21306;&#38388;&#65306;&#20851;&#38190;&#32508;&#36848;&#19982;&#24314;&#35758;
&lt;/p&gt;
&lt;p&gt;
Confidence Intervals for Error Rates in Matching Tasks: Critical Review and Recommendations. (arXiv:2306.01198v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01198
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22238;&#39038;&#20102;&#26500;&#24314;&#21305;&#37197;&#20219;&#21153;&#35823;&#24046;&#29575;&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#65292;&#30740;&#31350;&#20854;&#32479;&#35745;&#29305;&#24615;&#24182;&#25552;&#20379;&#20102;&#26368;&#20339;&#23454;&#36341;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21305;&#37197;&#31639;&#27861;&#36890;&#24120;&#29992;&#20110;&#39044;&#27979;&#25910;&#38598;&#20013;&#39033;&#30446;&#20043;&#38388;&#30340;&#21305;&#37197;&#12290;&#20363;&#22914;&#65292;&#22312;1&#65306;1&#30340;&#20154;&#33080;&#39564;&#35777;&#20013;&#65292;&#21305;&#37197;&#31639;&#27861;&#39044;&#27979;&#20004;&#24352;&#20154;&#33080;&#22270;&#20687;&#26159;&#21542;&#25551;&#32472;&#21516;&#19968;&#20010;&#20154;&#12290;&#24403;&#25968;&#25454;&#30456;&#20851;&#19988;&#35823;&#24046;&#29575;&#20302;&#26102;&#65292;&#20934;&#30830;&#35780;&#20272;&#27492;&#31867;&#31639;&#27861;&#35823;&#24046;&#29575;&#30340;&#19981;&#30830;&#23450;&#24615;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#36825;&#26159;&#25991;&#29486;&#20013;&#32463;&#24120;&#34987;&#24573;&#30053;&#30340;&#20004;&#20010;&#26041;&#38754;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22238;&#39038;&#20102;&#26500;&#24314;1:1&#20154;&#33080;&#39564;&#35777;&#31561;&#21305;&#37197;&#20219;&#21153;&#35823;&#24046;&#29575;&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#25512;&#23548;&#21644;&#26816;&#39564;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#32479;&#35745;&#23646;&#24615;&#65292;&#24182;&#20351;&#29992;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#28436;&#31034;&#20102;&#35206;&#30422;&#29575;&#21644;&#21306;&#38388;&#23485;&#24230;&#22914;&#20309;&#38543;&#30528;&#26679;&#26412;&#37327;&#12289;&#35823;&#24046;&#29575;&#21644;&#25968;&#25454;&#30456;&#20851;&#31243;&#24230;&#21464;&#21270;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;&#21457;&#29616;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#26500;&#24314;&#21305;&#37197;&#20219;&#21153;&#35823;&#24046;&#29575;&#32622;&#20449;&#21306;&#38388;&#26368;&#20339;&#23454;&#36341;&#30340;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
Matching algorithms are commonly used to predict matches between items in a collection. For example, in 1:1 face verification, a matching algorithm predicts whether two face images depict the same person. Accurately assessing the uncertainty of the error rates of such algorithms can be challenging when data are dependent and error rates are low, two aspects that have been often overlooked in the literature. In this work, we review methods for constructing confidence intervals for error rates in matching tasks such as 1:1 face verification. We derive and examine the statistical properties of these methods and demonstrate how coverage and interval width vary with sample size, error rates, and degree of data dependence using both synthetic and real-world datasets. Based on our findings, we provide recommendations for best practices for constructing confidence intervals for error rates in matching tasks.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#20998;&#26512;&#20102;&#38543;&#26426;&#26799;&#24230; Langevin &#21160;&#21147;&#23398;&#22312;&#22823;&#22411;&#25968;&#25454;&#29615;&#22659;&#19979;&#20351;&#29992;&#23376;&#37319;&#26679;&#20135;&#29983;&#30340;&#35823;&#24046;&#12290;&#30740;&#31350;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36830;&#32493;&#26102;&#38388;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#65292;&#35813;&#36807;&#31243;&#20999;&#25442;&#25968;&#25454;&#23376;&#38598;&#24182;&#21487;&#29992;&#20110;&#25193;&#25955;&#23376;&#37319;&#26679; MCMC &#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.13882</link><description>&lt;p&gt;
&#38543;&#26426;&#26799;&#24230; Langevin &#25193;&#25955;&#20013;&#30340;&#23376;&#37319;&#26679;&#35823;&#24046;
&lt;/p&gt;
&lt;p&gt;
Subsampling Error in Stochastic Gradient Langevin Diffusions. (arXiv:2305.13882v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13882
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#20998;&#26512;&#20102;&#38543;&#26426;&#26799;&#24230; Langevin &#21160;&#21147;&#23398;&#22312;&#22823;&#22411;&#25968;&#25454;&#29615;&#22659;&#19979;&#20351;&#29992;&#23376;&#37319;&#26679;&#20135;&#29983;&#30340;&#35823;&#24046;&#12290;&#30740;&#31350;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36830;&#32493;&#26102;&#38388;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#65292;&#35813;&#36807;&#31243;&#20999;&#25442;&#25968;&#25454;&#23376;&#38598;&#24182;&#21487;&#29992;&#20110;&#25193;&#25955;&#23376;&#37319;&#26679; MCMC &#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230; Langevin &#21160;&#21147;&#23398; (SGLD) &#36890;&#24120;&#29992;&#20110;&#22823;&#35268;&#27169;&#25968;&#25454;&#30340;&#32479;&#35745;&#23398;&#20064;&#20013;&#36817;&#20284;&#36125;&#21494;&#26031;&#21518;&#39564;&#20998;&#24067;&#12290;&#19982;&#35768;&#22810;&#24120;&#35268;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599; (MCMC) &#31639;&#27861;&#19981;&#21516;&#65292;SGLD &#23545;&#20110;&#21518;&#39564;&#20998;&#24067;&#19981;&#26159;&#31283;&#23450;&#30340;&#12290;&#23427;&#26377;&#20004;&#20010;&#38169;&#35823;&#26469;&#28304;&#65306;&#31532;&#19968;&#20010;&#38169;&#35823;&#26159;&#30001; Euler-Maruyama &#31163;&#25955;&#21270; Langevin &#25193;&#25955;&#36807;&#31243;&#24341;&#20837;&#30340;&#65292;&#31532;&#20108;&#20010;&#38169;&#35823;&#26469;&#33258;&#20110;&#25968;&#25454;&#23376;&#37319;&#26679;&#65292;&#36825;&#20351;&#24471;&#23427;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#25968;&#25454;&#29615;&#22659;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102; SGLD &#30340;&#29702;&#24819;&#21270;&#29256;&#26412;&#65292;&#20197;&#20998;&#26512;&#35813;&#26041;&#27861;&#30340;&#32431;&#23376;&#37319;&#26679;&#35823;&#24046;&#65292;&#25105;&#20204;&#21487;&#20197;&#23558;&#20854;&#35270;&#20026;&#22522;&#20110;&#25193;&#25955;&#30340;&#23376;&#37319;&#26679; MCMC &#26041;&#27861;&#30340;&#26368;&#20339;&#24773;&#20917;&#35823;&#24046;&#12290;&#20107;&#23454;&#19978;&#65292;&#25105;&#20204;&#24341;&#20837;&#24182;&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230; Langevin &#25193;&#25955; (SGLDiff)&#65292;&#36825;&#26159;&#19968;&#20010;&#36830;&#32493;&#26102;&#38388;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#65292;&#23427;&#36981;&#24490;&#19982;&#25968;&#25454;&#23376;&#38598;&#30456;&#24212;&#30340; Langevin &#25193;&#25955;&#65292;&#24182;&#22312;&#25351;&#25968;&#31561;&#24453;&#26102;&#38388;&#21518;&#20999;&#25442;&#35813;&#25968;&#25454;&#23376;&#38598;&#12290;&#22312;&#27492;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#29926;&#29791;&#26031;&#22374;&#36317;&#31163; (Was)
&lt;/p&gt;
&lt;p&gt;
The Stochastic Gradient Langevin Dynamics (SGLD) are popularly used to approximate Bayesian posterior distributions in statistical learning procedures with large-scale data. As opposed to many usual Markov chain Monte Carlo (MCMC) algorithms, SGLD is not stationary with respect to the posterior distribution; two sources of error appear: The first error is introduced by an Euler--Maruyama discretisation of a Langevin diffusion process, the second error comes from the data subsampling that enables its use in large-scale data settings. In this work, we consider an idealised version of SGLD to analyse the method's pure subsampling error that we then see as a best-case error for diffusion-based subsampling MCMC methods. Indeed, we introduce and study the Stochastic Gradient Langevin Diffusion (SGLDiff), a continuous-time Markov process that follows the Langevin diffusion corresponding to a data subset and switches this data subset after exponential waiting times. There, we show that the Was
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102; ELBO &#25910;&#25947;&#21040;&#29109;&#21644;&#30340;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#19968;&#31867;&#24191;&#27867;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;ELBO &#22312;&#25152;&#26377;&#23398;&#20064;&#30340;&#31283;&#23450;&#28857;&#22788;&#37117;&#31561;&#20110;&#19968;&#31995;&#21015;&#29109;&#30340;&#21644;&#65292;&#20026;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#23398;&#20064;&#31639;&#27861;&#30340;&#22522;&#26412;&#23646;&#24615;&#25552;&#20379;&#20102;&#28145;&#20837;&#30340;&#27934;&#23519;&#12290;</title><link>http://arxiv.org/abs/2209.03077</link><description>&lt;p&gt;
&#20851;&#20110;ELBO&#25910;&#25947;&#21040;&#29109;&#21644;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Convergence of the ELBO to Entropy Sums. (arXiv:2209.03077v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.03077
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102; ELBO &#25910;&#25947;&#21040;&#29109;&#21644;&#30340;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#19968;&#31867;&#24191;&#27867;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;ELBO &#22312;&#25152;&#26377;&#23398;&#20064;&#30340;&#31283;&#23450;&#28857;&#22788;&#37117;&#31561;&#20110;&#19968;&#31995;&#21015;&#29109;&#30340;&#21644;&#65292;&#20026;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#23398;&#20064;&#31639;&#27861;&#30340;&#22522;&#26412;&#23646;&#24615;&#25552;&#20379;&#20102;&#28145;&#20837;&#30340;&#27934;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#19979;&#30028;&#65288;&#21448;&#31216;ELBO&#25110;&#33258;&#30001;&#33021;&#65289;&#26159;&#35768;&#22810;&#32463;&#20856;&#21644;&#26032;&#39062;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#31639;&#27861;&#30340;&#26680;&#24515;&#30446;&#26631;&#12290;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#25913;&#21464;&#27169;&#22411;&#21442;&#25968;&#65292;&#20351;&#21464;&#20998;&#19979;&#30028;&#22686;&#21152;&#12290;&#36890;&#24120;&#65292;&#23398;&#20064;&#36827;&#34892;&#21040;&#21442;&#25968;&#25910;&#25947;&#21040;&#25509;&#36817;&#23398;&#20064;&#21160;&#24577;&#30340;&#31283;&#23450;&#28857;&#20540;&#12290;&#22312;&#26412;&#25991;&#30340;&#29702;&#35770;&#36129;&#29486;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#65288;&#23545;&#20110;&#19968;&#31867;&#38750;&#24120;&#24191;&#27867;&#30340;&#29983;&#25104;&#27169;&#22411;&#65289;&#65292;&#21464;&#20998;&#19979;&#30028;&#22312;&#25152;&#26377;&#23398;&#20064;&#30340;&#31283;&#23450;&#28857;&#22788;&#22343;&#31561;&#20110;&#19968;&#31995;&#21015;&#29109;&#30340;&#21644;&#12290;&#23545;&#20110;&#20855;&#26377;&#19968;&#32452;&#28508;&#22312;&#21464;&#37327;&#21644;&#19968;&#32452;&#35266;&#27979;&#21464;&#37327;&#30340;&#26631;&#20934;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#36825;&#20010;&#21644;&#21253;&#25324;&#19977;&#20010;&#29109;: (A) &#21464;&#20998;&#20998;&#24067;&#30340;&#29109;&#65288;&#24179;&#22343;&#29109;&#65289;&#65292;(B) &#27169;&#22411;&#20808;&#39564;&#20998;&#24067;&#30340;&#36127;&#29109;&#21644; (C) &#21487;&#35266;&#27979;&#20998;&#24067;&#30340;&#65288;&#26399;&#26395;&#65289;&#36127;&#29109;&#12290;&#25152;&#24471;&#21040;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#21253;&#25324;&#65306;&#26377;&#38480;&#25968;&#37327;&#30340;&#25968;&#25454;&#28857;&#65292;&#22312;&#23398;&#20064;&#30340;&#20219;&#24847;&#38454;&#27573;&#21644;&#21508;&#31181;&#19981;&#21516;&#30340;&#29983;&#25104;&#27169;&#22411;&#31561;&#30495;&#23454;&#26465;&#20214;&#12290;&#26412;&#30740;&#31350;&#20026;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#23398;&#20064;&#31639;&#27861;&#30340;&#22522;&#26412;&#23646;&#24615;&#25552;&#20379;&#20102;&#28145;&#20837;&#27934;&#23519;&#65292;&#26159;&#23545;&#20248;&#21270;&#25512;&#29702;&#21644;&#23398;&#20064;&#30340;&#29702;&#35770;&#20998;&#26512;&#30340;&#31532;&#19968;&#27493;&#12290;
&lt;/p&gt;
&lt;p&gt;
The variational lower bound (a.k.a. ELBO or free energy) is the central objective for many established as well as many novel algorithms for unsupervised learning. Learning algorithms change model parameters such that the variational lower bound increases. Learning usually proceeds until parameters have converged to values close to a stationary point of the learning dynamics. In this purely theoretical contribution, we show that (for a very large class of generative models) the variational lower bound is at all stationary points of learning equal to a sum of entropies. For standard machine learning models with one set of latents and one set observed variables, the sum consists of three entropies: (A) the (average) entropy of the variational distributions, (B) the negative entropy of the model's prior distribution, and (C) the (expected) negative entropy of the observable distributions. The obtained result applies under realistic conditions including: finite numbers of data points, at an
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#30740;&#31350;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#26381;&#21153;&#30340;&#21442;&#19982;&#21644;&#37325;&#26032;&#35757;&#32451;&#21160;&#24577;&#65292;&#21457;&#29616;&#24403;&#23398;&#20064;&#32773;&#21644;&#29992;&#25143;&#23376;&#32676;&#20855;&#26377;&#39118;&#38505;&#20943;&#23569;&#24615;&#36136;&#26102;&#65292;&#21807;&#19968;&#30340;&#31283;&#23450;&#22343;&#34913;&#26159;&#32454;&#20998;&#30340;&#65292;&#23558;&#23376;&#32676;&#20998;&#37197;&#32473;&#21333;&#20010;&#23398;&#20064;&#32773;&#12290;&#21151;&#21033;&#20027;&#20041;&#31038;&#20250;&#26368;&#20248;&#26159;&#19968;&#20010;&#31283;&#23450;&#22343;&#34913;&#12290;</title><link>http://arxiv.org/abs/2206.02667</link><description>&lt;p&gt;
&#20174;&#21442;&#19982;&#24230;&#21160;&#24577;&#21644;&#22810;&#23398;&#20064;&#32773;&#37325;&#26032;&#35757;&#32451;&#20013;&#20135;&#29983;&#30340;&#32039;&#24613;&#32454;&#20998;
&lt;/p&gt;
&lt;p&gt;
Emergent segmentation from participation dynamics and multi-learner retraining. (arXiv:2206.02667v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.02667
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#30740;&#31350;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#26381;&#21153;&#30340;&#21442;&#19982;&#21644;&#37325;&#26032;&#35757;&#32451;&#21160;&#24577;&#65292;&#21457;&#29616;&#24403;&#23398;&#20064;&#32773;&#21644;&#29992;&#25143;&#23376;&#32676;&#20855;&#26377;&#39118;&#38505;&#20943;&#23569;&#24615;&#36136;&#26102;&#65292;&#21807;&#19968;&#30340;&#31283;&#23450;&#22343;&#34913;&#26159;&#32454;&#20998;&#30340;&#65292;&#23558;&#23376;&#32676;&#20998;&#37197;&#32473;&#21333;&#20010;&#23398;&#20064;&#32773;&#12290;&#21151;&#21033;&#20027;&#20041;&#31038;&#20250;&#26368;&#20248;&#26159;&#19968;&#20010;&#31283;&#23450;&#22343;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#26381;&#21153;&#20013;&#36873;&#25321;&#21442;&#19982;&#65292;&#24448;&#24448;&#22522;&#20110;&#35813;&#26381;&#21153;&#30340;&#36136;&#37327;&#65292;&#24433;&#21709;&#20102;&#26381;&#21153;&#23398;&#20064;&#21644;&#25913;&#36827;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#24403;&#23398;&#20064;&#32773;&#21644;&#29992;&#25143;&#23376;&#32676;&#37117;&#20855;&#26377;&#39118;&#38505;&#20943;&#23569;&#24615;&#36136;&#26102;&#65292;&#21442;&#19982;&#21644;&#37325;&#26032;&#35757;&#32451;&#30340;&#21160;&#24577;&#29983;&#25104;&#30340;&#24773;&#20917;&#65292;&#20854;&#20013;&#21253;&#25324;&#20102;&#26799;&#24230;&#19979;&#38477;&#12289;&#20056;&#27861;&#26435;&#37325;&#31561;&#24191;&#27867;&#30340;&#26356;&#26032;&#26041;&#27861;&#12290;&#20030;&#20010;&#20363;&#23376;&#65292;&#20551;&#35774;&#20010;&#20307;&#36873;&#25321;&#22312;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#19978;&#33457;&#36153;&#26102;&#38388;&#30340;&#27604;&#20363;&#19982;&#27599;&#20010;&#24179;&#21488;&#23545;&#20182;&#20204;&#30340;&#24037;&#20316;&#25928;&#26524;&#25104;&#27604;&#20363;&#12290;&#27599;&#20010;&#24179;&#21488;&#36824;&#20250;&#25910;&#38598;&#20854;&#27963;&#36291;&#29992;&#25143;&#30340;&#25968;&#25454;&#65292;&#24182;&#29992;&#26799;&#24230;&#27493;&#39588;&#26356;&#26032;&#21442;&#25968;&#12290;&#23545;&#20110;&#36825;&#20010;&#20363;&#23376;&#21644;&#25105;&#20204;&#30340;&#19968;&#33324;&#21160;&#24577;&#31867;&#21035;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21807;&#19968;&#30340;&#28176;&#36817;&#31283;&#23450;&#22343;&#34913;&#26159;&#32454;&#20998;&#30340;&#65292;&#23558;&#23376;&#32676;&#20998;&#37197;&#32473;&#21333;&#20010;&#23398;&#20064;&#32773;&#12290;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#21151;&#21033;&#20027;&#20041;&#31038;&#20250;&#26368;&#20248;&#26159;&#19968;&#20010;&#31283;&#23450;&#22343;&#34913;&#12290;&#19982;&#20808;&#21069;&#30340;&#24037;&#20316;&#30456;&#21453;&#65292;&#20808;&#21069;&#30340;&#24037;&#20316;&#26174;&#31034;&#37325;&#22797;&#30340;&#39118;&#38505;&#26368;&#23567;&#21270;&#21487;&#33021;&#19981;&#20250;&#23545;&#38887;&#24615;&#21644;&#21033;&#30410;&#36827;&#34892;&#20219;&#20309;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
The choice to participate in a data-driven service, often made on the basis of quality of that service, influences the ability of the service to learn and improve. We study the participation and retraining dynamics that arise when both the learners and sub-populations of users are \emph{risk-reducing}, which cover a broad class of updates including gradient descent, multiplicative weights, etc. Suppose, for example, that individuals choose to spend their time amongst social media platforms proportionally to how well each platform works for them. Each platform also gathers data about its active users, which it uses to update parameters with a gradient step. For this example and for our general class of dynamics, we show that the only asymptotically stable equilibria are segmented, with sub-populations allocated to a single learner. Under mild assumptions, the utilitarian social optimum is a stable equilibrium. In contrast to previous work, which shows that repeated risk minimization can
&lt;/p&gt;</description></item></channel></rss>