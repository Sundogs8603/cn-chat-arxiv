<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#38024;&#23545;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#21644;&#20998;&#31867;&#25552;&#20986;&#20102;&#25968;&#25454;&#20013;&#24515;&#26041;&#27861;&#21644;&#20998;&#24067;&#20013;&#24515;&#26041;&#27861;&#65292;&#20998;&#26512;&#21518;&#21457;&#29616;&#20854;&#19982;&#20869;&#26680;&#23725;&#22238;&#24402;&#33258;&#25105;&#33976;&#39311;&#21644;&#26222;&#36890;GPR&#23545;&#24212;&#12290;&#20854;&#20013;GPC&#30340;&#20998;&#24067;&#20013;&#24515;&#26041;&#27861;&#36817;&#20284;&#23545;&#24212;&#20110;&#25968;&#25454;&#22797;&#21046;&#21644;&#21327;&#26041;&#24046;&#30340;&#29305;&#23450;&#32553;&#25918;&#12290;</title><link>http://arxiv.org/abs/2304.02641</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#21644;&#20998;&#31867;&#30340;&#33258;&#25105;&#33976;&#39311;
&lt;/p&gt;
&lt;p&gt;
Self-Distillation for Gaussian Process Regression and Classification. (arXiv:2304.02641v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02641
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#21644;&#20998;&#31867;&#25552;&#20986;&#20102;&#25968;&#25454;&#20013;&#24515;&#26041;&#27861;&#21644;&#20998;&#24067;&#20013;&#24515;&#26041;&#27861;&#65292;&#20998;&#26512;&#21518;&#21457;&#29616;&#20854;&#19982;&#20869;&#26680;&#23725;&#22238;&#24402;&#33258;&#25105;&#33976;&#39311;&#21644;&#26222;&#36890;GPR&#23545;&#24212;&#12290;&#20854;&#20013;GPC&#30340;&#20998;&#24067;&#20013;&#24515;&#26041;&#27861;&#36817;&#20284;&#23545;&#24212;&#20110;&#25968;&#25454;&#22797;&#21046;&#21644;&#21327;&#26041;&#24046;&#30340;&#29305;&#23450;&#32553;&#25918;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#23558;&#30693;&#35782;&#33976;&#39311;&#30340;&#27010;&#24565;&#25193;&#23637;&#21040;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#65288;GPR&#65289;&#21644;&#39640;&#26031;&#36807;&#31243;&#20998;&#31867;&#65288;GPC&#65289;&#20013;&#65307;&#25968;&#25454;&#20013;&#24515;&#26041;&#27861;&#21644;&#20998;&#24067;&#20013;&#24515;&#26041;&#27861;&#12290;&#25968;&#25454;&#20013;&#24515;&#26041;&#27861;&#26368;&#20687;&#30446;&#21069;&#26426;&#22120;&#23398;&#20064;&#30340;&#22823;&#22810;&#25968;&#33976;&#39311;&#25216;&#26415;&#65292;&#23427;&#22312;&#25945;&#24072;&#30340;&#30830;&#23450;&#24615;&#39044;&#27979;&#19978;&#37325;&#26032;&#36866;&#21512;&#19968;&#20010;&#27169;&#22411;&#65292;&#32780;&#20998;&#24067;&#20013;&#24515;&#26041;&#27861;&#21017;&#37325;&#26032;&#20351;&#29992;&#23436;&#25972;&#27010;&#29575;&#21518;&#39564;&#36827;&#34892;&#19979;&#19968;&#27425;&#36845;&#20195;&#12290;&#36890;&#36807;&#20998;&#26512;&#36825;&#20123;&#26041;&#27861;&#30340;&#29305;&#24615;&#65292;&#25105;&#20204;&#34920;&#26126;GPR&#30340;&#25968;&#25454;&#20013;&#24515;&#26041;&#27861;&#19982;&#24050;&#30693;&#30340;&#20869;&#26680;&#23725;&#22238;&#24402;&#33258;&#25105;&#33976;&#39311;&#32467;&#26524;&#23494;&#20999;&#30456;&#20851;&#65292;&#32780;GPR&#30340;&#20998;&#24067;&#20013;&#24515;&#26041;&#27861;&#19982;&#20855;&#26377;&#29305;&#23450;&#36229;&#21442;&#25968;&#36873;&#25321;&#30340;&#26222;&#36890;GPR&#30456;&#23545;&#24212;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#28436;&#31034;&#20102;GPC&#30340;&#20998;&#24067;&#20013;&#24515;&#26041;&#27861;&#36817;&#20284;&#23545;&#24212;&#20110;&#25968;&#25454;&#22797;&#21046;&#21644;&#21327;&#26041;&#24046;&#30340;&#29305;&#23450;&#32553;&#25918;&#65292;&#32780;GPC&#30340;&#25968;&#25454;&#20013;&#24515;&#26041;&#27861;&#38656;&#35201;&#37325;&#26032;&#23450;&#20041;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose two approaches to extend the notion of knowledge distillation to Gaussian Process Regression (GPR) and Gaussian Process Classification (GPC); data-centric and distribution-centric. The data-centric approach resembles most current distillation techniques for machine learning, and refits a model on deterministic predictions from the teacher, while the distribution-centric approach, re-uses the full probabilistic posterior for the next iteration. By analyzing the properties of these approaches, we show that the data-centric approach for GPR closely relates to known results for self-distillation of kernel ridge regression and that the distribution-centric approach for GPR corresponds to ordinary GPR with a very particular choice of hyperparameters. Furthermore, we demonstrate that the distribution-centric approach for GPC approximately corresponds to data duplication and a particular scaling of the covariance and that the data-centric approach for GPC requires redefining the mod
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23545;&#25968;&#20985;&#37319;&#26679;&#30340;&#26597;&#35810;&#19979;&#30028;&#65292;&#22312;&#24378;&#23545;&#25968;&#20985;&#21644;&#23545;&#25968;&#20809;&#28369;&#20998;&#24067;&#20013;&#37319;&#26679;&#38656;&#35201; $\Omega(\log \kappa)$ &#26597;&#35810;&#65292;&#22312;&#37319;&#26679;&#39640;&#26031;&#20998;&#24067;&#20013;&#38656;&#35201; $\widetilde \Omega(\min(\sqrt\kappa \log d, d))$ &#26597;&#35810;&#12290;</title><link>http://arxiv.org/abs/2304.02599</link><description>&lt;p&gt;
&#23545;&#25968;&#20985;&#37319;&#26679;&#30340;&#26597;&#35810;&#19979;&#30028;
&lt;/p&gt;
&lt;p&gt;
Query lower bounds for log-concave sampling. (arXiv:2304.02599v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02599
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23545;&#25968;&#20985;&#37319;&#26679;&#30340;&#26597;&#35810;&#19979;&#30028;&#65292;&#22312;&#24378;&#23545;&#25968;&#20985;&#21644;&#23545;&#25968;&#20809;&#28369;&#20998;&#24067;&#20013;&#37319;&#26679;&#38656;&#35201; $\Omega(\log \kappa)$ &#26597;&#35810;&#65292;&#22312;&#37319;&#26679;&#39640;&#26031;&#20998;&#24067;&#20013;&#38656;&#35201; $\widetilde \Omega(\min(\sqrt\kappa \log d, d))$ &#26597;&#35810;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20960;&#24180;&#65292;&#23545;&#25968;&#20985;&#37319;&#26679;&#22312;&#31639;&#27861;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#36827;&#23637;&#65292;&#20294;&#30456;&#24212;&#30340;&#35777;&#26126;&#27492;&#20219;&#21153;&#30340;&#19979;&#30028;&#30340;&#38382;&#39064;&#20173;&#28982;&#24456;&#38590;&#65292;&#20197;&#21069;&#21482;&#30693;&#36947;&#22312;&#19968;&#32500;&#20013;&#23384;&#22312;&#36739;&#23567;&#30340;&#19979;&#30028;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#20197;&#19979;&#26597;&#35810;&#19979;&#30028;&#65306;&#65288;1&#65289;&#22312;&#32500;&#24230; $d\ge 2$&#20013;&#20174;&#24378;&#23545;&#25968;&#20985;&#21644;&#23545;&#25968;&#20809;&#28369;&#20998;&#24067;&#20013;&#37319;&#26679;&#38656;&#35201; $\Omega(\log \kappa)$ &#26597;&#35810;&#65292;&#36825;&#22312;&#20219;&#20309;&#22266;&#23450;&#32500;&#24230;&#19978;&#37117;&#26159;&#26368;&#20248;&#30340;&#65292;&#65288;2&#65289;&#20174;&#39640;&#26031;&#20998;&#24067;&#20013;&#37319;&#26679;&#38656;&#35201; $\widetilde \Omega(\min(\sqrt\kappa \log d, d))$ &#26597;&#35810;&#65288;&#22240;&#27492;&#20063;&#36866;&#29992;&#20110;&#22312;&#32500;&#25968; $d$ &#20013;&#37319;&#26679;&#19968;&#33324;&#30340;&#23545;&#25968;&#20985;&#21644;&#20809;&#28369;&#20998;&#24067;&#65289;&#65292;&#36825;&#23545;&#20110;&#39640;&#26031;&#31867;&#20960;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;&#36825;&#37324; $\kappa$ &#26159;&#30446;&#26631;&#20998;&#24067;&#30340;&#26465;&#20214;&#25968;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#20381;&#36182;&#20110;&#65288;1&#65289;&#19968;&#31181;&#22810;&#23610;&#24230;&#26500;&#36896;&#65292;&#21463;&#21040;&#20102;&#20851;&#20110;&#35856;&#25391;&#20998;&#26512;&#20013;&#30340;Kakeya&#29468;&#24819;&#30340;&#24037;&#20316;&#30340;&#21551;&#21457;&#65292;&#20197;&#21450;&#65288;2&#65289;&#19968;&#31181;&#26032;&#39062;&#30340;&#32422;&#31616;&#65292;&#35777;&#26126;&#20102;&#22359;Krylov&#31639;&#27861;&#22312;&#27492;&#38382;&#39064;&#20013;&#26159;&#26368;&#20339;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Log-concave sampling has witnessed remarkable algorithmic advances in recent years, but the corresponding problem of proving lower bounds for this task has remained elusive, with lower bounds previously known only in dimension one. In this work, we establish the following query lower bounds: (1) sampling from strongly log-concave and log-smooth distributions in dimension $d\ge 2$ requires $\Omega(\log \kappa)$ queries, which is sharp in any constant dimension, and (2) sampling from Gaussians in dimension $d$ (hence also from general log-concave and log-smooth distributions in dimension $d$) requires $\widetilde \Omega(\min(\sqrt\kappa \log d, d))$ queries, which is nearly sharp for the class of Gaussians. Here $\kappa$ denotes the condition number of the target distribution. Our proofs rely upon (1) a multiscale construction inspired by work on the Kakeya conjecture in harmonic analysis, and (2) a novel reduction that demonstrates that block Krylov algorithms are optimal for this probl
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#22522;&#20110;Python&#30340;&#25945;&#31243;&#65292;&#20171;&#32461;&#20102;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;MCMC&#26041;&#27861;&#24212;&#29992;&#65292;&#36890;&#36807;&#25945;&#31243;&#20351;&#24471;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#32773;&#33021;&#22815;&#26356;&#22909;&#22320;&#24212;&#29992;&#36125;&#21494;&#26031;&#25512;&#26029;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;</title><link>http://arxiv.org/abs/2304.02595</link><description>&lt;p&gt;
&#22522;&#20110;MCMC&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65306;&#22522;&#20110;Python&#30340;&#25945;&#31243;
&lt;/p&gt;
&lt;p&gt;
Bayesian neural networks via MCMC: a Python-based tutorial. (arXiv:2304.02595v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02595
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#22522;&#20110;Python&#30340;&#25945;&#31243;&#65292;&#20171;&#32461;&#20102;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;MCMC&#26041;&#27861;&#24212;&#29992;&#65292;&#36890;&#36807;&#25945;&#31243;&#20351;&#24471;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#32773;&#33021;&#22815;&#26356;&#22909;&#22320;&#24212;&#29992;&#36125;&#21494;&#26031;&#25512;&#26029;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#25512;&#26029;&#20026;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#25552;&#20379;&#20102;&#21442;&#25968;&#20272;&#35745;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#26041;&#27861;&#12290;&#21464;&#20998;&#25512;&#26029;&#21644;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#65288;MCMC&#65289;&#37319;&#26679;&#25216;&#26415;&#29992;&#20110;&#23454;&#29616;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;&#22312;&#36807;&#21435;&#19977;&#21313;&#24180;&#20013;&#65292;MCMC&#26041;&#27861;&#22312;&#36866;&#24212;&#26356;&#22823;&#30340;&#27169;&#22411;&#65288;&#22914;&#28145;&#24230;&#23398;&#20064;&#65289;&#21644;&#22823;&#25968;&#25454;&#38382;&#39064;&#26041;&#38754;&#38754;&#20020;&#20102;&#35768;&#22810;&#25361;&#25112;&#12290;&#21253;&#25324;&#26799;&#24230;&#30340;&#39640;&#32423;&#25552;&#35758;&#65288;&#20363;&#22914;Langevin&#25552;&#35758;&#20998;&#24067;&#65289;&#25552;&#20379;&#20102;&#19968;&#31181;&#35299;&#20915;MCMC&#37319;&#26679;&#20013;&#30340;&#19968;&#20123;&#38480;&#21046;&#30340;&#26041;&#27861;&#65292;&#27492;&#22806;&#65292;MCMC&#26041;&#27861;&#36890;&#24120;&#34987;&#38480;&#21046;&#22312;&#32479;&#35745;&#23398;&#23478;&#30340;&#20351;&#29992;&#33539;&#22260;&#20869;&#65292;&#24182;&#19988;&#20173;&#19981;&#26159;&#28145;&#24230;&#23398;&#20064;&#30740;&#31350;&#20154;&#21592;&#30340;&#20027;&#27969;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;MCMC&#26041;&#27861;&#30340;&#25945;&#31243;&#65292;&#28085;&#30422;&#20102;&#31616;&#21333;&#30340;&#36125;&#21494;&#26031;&#32447;&#24615;&#21644;&#36923;&#36753;&#27169;&#22411;&#65292;&#20197;&#21450;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#12290;&#36825;&#20010;&#25945;&#31243;&#30340;&#30446;&#30340;&#26159;&#36890;&#36807;&#32534;&#30721;&#26469;&#24357;&#21512;&#29702;&#35770;&#21644;&#23454;&#29616;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#37492;&#20110;&#24403;&#21069;MCMC&#26041;&#27861;&#30340;&#26222;&#21450;&#31243;&#24230;&#20173;&#28982;&#36739;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian inference provides a methodology for parameter estimation and uncertainty quantification in machine learning and deep learning methods. Variational inference and Markov Chain Monte-Carlo (MCMC) sampling techniques are used to implement Bayesian inference. In the past three decades, MCMC methods have faced a number of challenges in being adapted to larger models (such as in deep learning) and big data problems. Advanced proposals that incorporate gradients, such as a Langevin proposal distribution, provide a means to address some of the limitations of MCMC sampling for Bayesian neural networks. Furthermore, MCMC methods have typically been constrained to use by statisticians and are still not prominent among deep learning researchers. We present a tutorial for MCMC methods that covers simple Bayesian linear and logistic models, and Bayesian neural networks. The aim of this tutorial is to bridge the gap between theory and implementation via coding, given a general sparsity of li
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#30417;&#30563;&#26041;&#27861;&#65292;&#21517;&#20026;SidAE&#65292;&#23427;&#32467;&#21512;&#20102;&#23402;&#29983;&#26550;&#26500;&#21644;&#21435;&#22122;&#33258;&#32534;&#30721;&#22120;&#30340;&#20248;&#28857;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#25552;&#21462;&#36755;&#20837;&#25968;&#25454;&#30340;&#29305;&#24449;&#65292;&#20197;&#22312;&#22810;&#20010;&#19979;&#28216;&#20219;&#21153;&#20013;&#33719;&#24471;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.02549</link><description>&lt;p&gt;
&#33258;&#30417;&#30563;&#30340;&#23402;&#29983;&#33258;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Self-Supervised Siamese Autoencoders. (arXiv:2304.02549v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02549
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#30417;&#30563;&#26041;&#27861;&#65292;&#21517;&#20026;SidAE&#65292;&#23427;&#32467;&#21512;&#20102;&#23402;&#29983;&#26550;&#26500;&#21644;&#21435;&#22122;&#33258;&#32534;&#30721;&#22120;&#30340;&#20248;&#28857;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#25552;&#21462;&#36755;&#20837;&#25968;&#25454;&#30340;&#29305;&#24449;&#65292;&#20197;&#22312;&#22810;&#20010;&#19979;&#28216;&#20219;&#21153;&#20013;&#33719;&#24471;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23436;&#20840;&#30417;&#30563;&#30340;&#27169;&#22411;&#36890;&#24120;&#38656;&#35201;&#22823;&#37327;&#30340;&#26631;&#35760;&#35757;&#32451;&#25968;&#25454;&#65292;&#36825;&#24448;&#24448;&#26159;&#26114;&#36149;&#19988;&#38590;&#20197;&#33719;&#24471;&#30340;&#12290;&#30456;&#21453;&#65292;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#20943;&#23569;&#20102;&#23454;&#29616;&#30456;&#21516;&#25110;&#26356;&#39640;&#19979;&#28216;&#24615;&#33021;&#25152;&#38656;&#30340;&#26631;&#35760;&#25968;&#25454;&#37327;&#12290;&#30446;&#26631;&#26159;&#22312;&#33258;&#30417;&#30563;&#20219;&#21153;&#19978;&#39044;&#20808;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#20197;&#20415;&#32593;&#32476;&#33021;&#22815;&#20174;&#21407;&#22987;&#36755;&#20837;&#25968;&#25454;&#20013;&#25552;&#21462;&#26377;&#24847;&#20041;&#30340;&#29305;&#24449;&#12290;&#28982;&#21518;&#65292;&#23558;&#36825;&#20123;&#29305;&#24449;&#29992;&#20316;&#19979;&#28216;&#20219;&#21153;&#65288;&#22914;&#22270;&#20687;&#20998;&#31867;&#65289;&#20013;&#30340;&#36755;&#20837;&#12290;&#22312;&#20808;&#21069;&#30340;&#30740;&#31350;&#20013;&#65292;&#33258;&#32534;&#30721;&#22120;&#21644;&#23402;&#29983;&#32593;&#32476;&#65288;&#22914;SimSiam&#65289;&#24050;&#25104;&#21151;&#24212;&#29992;&#20110;&#36825;&#20123;&#20219;&#21153;&#20013;&#12290;&#28982;&#32780;&#65292;&#20173;&#28982;&#23384;&#22312;&#19968;&#20123;&#25361;&#25112;&#65292;&#20363;&#22914;&#23558;&#29305;&#24449;&#30340;&#29305;&#24615;&#65288;&#20363;&#22914;&#65292;&#32454;&#33410;&#32423;&#21035;&#65289;&#19982;&#32473;&#23450;&#30340;&#20219;&#21153;&#21644;&#25968;&#25454;&#38598;&#21305;&#37197;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#20102;&#23402;&#29983;&#26550;&#26500;&#21644;&#21435;&#22122;&#33258;&#32534;&#30721;&#22120;&#20248;&#21183;&#30340;&#26032;&#33258;&#30417;&#30563;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#65292;&#21517;&#20026;SidAE&#65288;&#23402;&#29983;&#21435;&#22122;&#33258;&#32534;&#30721;&#22120;&#65289;&#65292;&#22312;&#22810;&#20010;&#19979;&#28216;&#20219;&#21153;&#19978;&#32988;&#36807;&#20102;&#20004;&#20010;&#33258;&#30417;&#30563;&#26368;&#26032;&#22522;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fully supervised models often require large amounts of labeled training data, which tends to be costly and hard to acquire. In contrast, self-supervised representation learning reduces the amount of labeled data needed for achieving the same or even higher downstream performance. The goal is to pre-train deep neural networks on a self-supervised task such that afterwards the networks are able to extract meaningful features from raw input data. These features are then used as inputs in downstream tasks, such as image classification. Previously, autoencoders and Siamese networks such as SimSiam have been successfully employed in those tasks. Yet, challenges remain, such as matching characteristics of the features (e.g., level of detail) to the given task and data set. In this paper, we present a new self-supervised method that combines the benefits of Siamese architectures and denoising autoencoders. We show that our model, called SidAE (Siamese denoising autoencoder), outperforms two se
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#30340;&#26368;&#20248;&#33609;&#22270;&#30028;&#38480;&#65292;&#34920;&#26126;&#31232;&#30095;&#24674;&#22797;&#27604;&#31232;&#30095;&#22238;&#24402;&#26356;&#23481;&#26131;&#33609;&#22270;&#65292;&#23545;&#20110;&#31232;&#30095;l_p&#22238;&#24402;&#65292;&#20854;&#19978;&#30028;&#21253;&#25324;l_2&#30340;&#39069;&#22806;&#28155;&#21152;&#39033;&#12290;</title><link>http://arxiv.org/abs/2304.02261</link><description>&lt;p&gt;
&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#30340;&#26368;&#20248;&#33609;&#22270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Optimal Sketching Bounds for Sparse Linear Regression. (arXiv:2304.02261v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02261
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#30340;&#26368;&#20248;&#33609;&#22270;&#30028;&#38480;&#65292;&#34920;&#26126;&#31232;&#30095;&#24674;&#22797;&#27604;&#31232;&#30095;&#22238;&#24402;&#26356;&#23481;&#26131;&#33609;&#22270;&#65292;&#23545;&#20110;&#31232;&#30095;l_p&#22238;&#24402;&#65292;&#20854;&#19978;&#30028;&#21253;&#25324;l_2&#30340;&#39069;&#22806;&#28155;&#21152;&#39033;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21508;&#31181;&#25439;&#22833;&#20989;&#25968;&#19979;k-&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#30340;&#36951;&#24536;&#33609;&#22270;&#65292;&#22914;l_p&#33539;&#25968;&#25110;&#24191;&#27867;&#30340;hinge-like&#25439;&#22833;&#20989;&#25968;&#31867;&#65292;&#20854;&#20013;&#21253;&#25324;logistic&#21644;ReLU&#25439;&#22833;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#23545;&#20110;&#31232;&#30095;l_2&#33539;&#25968;&#22238;&#24402;&#65292;&#23384;&#22312;&#19968;&#20010;&#36951;&#24536;&#33609;&#22270;&#20998;&#24067;&#65292;&#20855;&#26377;&#920;(klog(d/k)/&#949;^2)&#25490;&#65292;&#36825;&#26159;&#32039;&#30340;&#65292;&#30452;&#21040;&#19968;&#20010;&#24120;&#25968;&#22240;&#23376;&#12290;&#36825;&#25193;&#23637;&#21040;l_p&#25439;&#22833;&#65292;&#19978;&#30028;&#36824;&#26377;&#19968;&#20010;&#38468;&#21152;&#30340;O(klog(k/&#949;)/&#949;^2)&#39033;&#12290;&#36825;&#24314;&#31435;&#20102;&#19982;&#30456;&#20851;&#30340;&#31232;&#30095;&#24674;&#22797;&#38382;&#39064;&#30340;&#20986;&#20154;&#24847;&#26009;&#30340;&#20998;&#31163;&#65292;&#36825;&#26159;&#31232;&#30095;&#22238;&#24402;&#30340;&#19968;&#20010;&#37325;&#35201;&#29305;&#20363;&#12290;&#23545;&#20110;&#36825;&#20010;&#38382;&#39064;&#65292;&#22312;l_2&#33539;&#25968;&#19979;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#19968;&#20010;O(klog(d)/&#949;+klog(k/&#949;)/&#949;^2)&#34892;&#30340;&#19978;&#30028;&#65292;&#34920;&#26126;&#31232;&#30095;&#24674;&#22797;&#27604;&#31232;&#30095;&#22238;&#24402;&#26356;&#23481;&#26131;&#33609;&#22270;&#12290;&#23545;&#20110;&#21253;&#25324;&#31232;&#30095;logistic&#21644;&#31232;&#30095;ReLU&#22238;&#24402;&#22312;&#20869;&#30340;hinge-like&#25439;&#22833;&#20989;&#25968;&#19979;&#30340;&#31232;&#30095;&#22238;&#24402;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19982;&#20043;&#23545;&#24212;&#30340;&#26368;&#20248;&#33609;&#22270;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study oblivious sketching for $k$-sparse linear regression under various loss functions such as an $\ell_p$ norm, or from a broad class of hinge-like loss functions, which includes the logistic and ReLU losses. We show that for sparse $\ell_2$ norm regression, there is a distribution over oblivious sketches with $\Theta(k\log(d/k)/\varepsilon^2)$ rows, which is tight up to a constant factor. This extends to $\ell_p$ loss with an additional additive $O(k\log(k/\varepsilon)/\varepsilon^2)$ term in the upper bound. This establishes a surprising separation from the related sparse recovery problem, which is an important special case of sparse regression. For this problem, under the $\ell_2$ norm, we observe an upper bound of $O(k \log (d)/\varepsilon + k\log(k/\varepsilon)/\varepsilon^2)$ rows, showing that sparse recovery is strictly easier to sketch than sparse regression. For sparse regression under hinge-like loss functions including sparse logistic and sparse ReLU regression, we giv
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36817;&#20284;&#28040;&#24687;&#20256;&#36882;&#31639;&#27861;&#26469;&#35299;&#20915;&#22312;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;&#22238;&#24402;&#38382;&#39064;&#65292;&#35813;&#31639;&#27861;&#36866;&#29992;&#20110;&#28151;&#21512;&#32447;&#24615;&#22238;&#24402;&#12289;&#26368;&#22823;&#20223;&#23556;&#22238;&#24402;&#21644;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#31561;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2304.02229</link><description>&lt;p&gt;
&#36890;&#36807;&#36817;&#20284;&#28040;&#24687;&#20256;&#36882;&#30340;&#28151;&#21512;&#22238;&#24402;&#65288;Mixed Regression via Approximate Message Passing&#65289;
&lt;/p&gt;
&lt;p&gt;
Mixed Regression via Approximate Message Passing. (arXiv:2304.02229v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02229
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36817;&#20284;&#28040;&#24687;&#20256;&#36882;&#31639;&#27861;&#26469;&#35299;&#20915;&#22312;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;&#22238;&#24402;&#38382;&#39064;&#65292;&#35813;&#31639;&#27861;&#36866;&#29992;&#20110;&#28151;&#21512;&#32447;&#24615;&#22238;&#24402;&#12289;&#26368;&#22823;&#20223;&#23556;&#22238;&#24402;&#21644;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#31561;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65288;GLM&#65289;&#20013;&#20855;&#26377;&#22810;&#20010;&#20449;&#21495;&#21644;&#28508;&#21464;&#37327;&#30340;&#22238;&#24402;&#38382;&#39064;&#12290;&#35813;&#27169;&#22411;&#34987;&#31216;&#20026;&#30697;&#38453;GLM&#65292;&#28085;&#30422;&#20102;&#35768;&#22810;&#22312;&#32479;&#35745;&#23398;&#20064;&#20013;&#24191;&#27867;&#30740;&#31350;&#30340;&#38382;&#39064;&#65292;&#21253;&#25324;&#28151;&#21512;&#32447;&#24615;&#22238;&#24402;&#12289;&#26368;&#22823;&#20223;&#23556;&#22238;&#24402;&#21644;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#31561;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36817;&#20284;&#28040;&#24687;&#20256;&#36882;&#65288;AMP&#65289;&#31639;&#27861;&#26469;&#20272;&#35745;&#30697;&#38453;GLM&#20013;&#30340;&#20449;&#21495;&#21644;&#28508;&#21464;&#37327;&#65292;&#24182;&#22312;&#39640;&#32500;&#26497;&#38480;&#20013;&#23545;&#20854;&#24615;&#33021;&#36827;&#34892;&#20102;&#20005;&#26684;&#30340;&#34920;&#24449;&#12290;&#35813;&#34920;&#24449;&#26159;&#36890;&#36807;&#29366;&#24577;&#28436;&#21270;&#36882;&#24402;&#26469;&#35745;&#31639;&#30340;&#65292;&#20174;&#32780;&#21487;&#20197;&#31934;&#30830;&#35745;&#31639;&#28176;&#36817;&#24615;&#33021;&#24230;&#37327;&#65292;&#20363;&#22914;&#20449;&#22122;&#27604;&#19979;&#38477;&#38408;&#20540;&#65288;threshold&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of regression in a generalized linear model (GLM) with multiple signals and latent variables. This model, which we call a matrix GLM, covers many widely studied problems in statistical learning, including mixed linear regression, max-affine regression, and mixture-of-experts. In mixed linear regression, each observation comes from one of $L$ signal vectors (regressors), but we do not know which one; in max-affine regression, each observation comes from the maximum of $L$ affine functions, each defined via a different signal vector. The goal in all these problems is to estimate the signals, and possibly some of the latent variables, from the observations. We propose a novel approximate message passing (AMP) algorithm for estimation in a matrix GLM and rigorously characterize its performance in the high-dimensional limit. This characterization is in terms of a state evolution recursion, which allows us to precisely compute performance measures such as the asymptotic 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#24452;&#21521;&#22522;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;&#31867;&#21035;&#65292;&#35777;&#26126;&#36825;&#20123;&#32593;&#32476;&#33021;&#22815;&#36924;&#36817;&#20219;&#20309;&#36830;&#32493;&#22810;&#20803;&#20989;&#25968;&#65292;&#36824;&#35752;&#35770;&#20102;&#26377;&#38480;&#20010;&#22266;&#23450;&#20013;&#24515;&#30340;RBF&#32593;&#32476;&#30340;&#36924;&#36817;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2304.02220</link><description>&lt;p&gt;
&#20851;&#20110;&#24452;&#21521;&#22522;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;&#26222;&#36866;&#36924;&#36817;&#24615;&#36136;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the universal approximation property of radial basis function neural networks. (arXiv:2304.02220v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02220
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#24452;&#21521;&#22522;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;&#31867;&#21035;&#65292;&#35777;&#26126;&#36825;&#20123;&#32593;&#32476;&#33021;&#22815;&#36924;&#36817;&#20219;&#20309;&#36830;&#32493;&#22810;&#20803;&#20989;&#25968;&#65292;&#36824;&#35752;&#35770;&#20102;&#26377;&#38480;&#20010;&#22266;&#23450;&#20013;&#24515;&#30340;RBF&#32593;&#32476;&#30340;&#36924;&#36817;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#24452;&#21521;&#22522;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;&#31867;&#21035;&#65292;&#20854;&#20013;&#24179;&#28369;&#22240;&#23376;&#34987;&#26367;&#25442;&#20026;&#20301;&#31227;&#12290;&#25105;&#20204;&#22312;&#28608;&#27963;&#20989;&#25968;&#30340;&#19968;&#23450;&#26465;&#20214;&#19979;&#35777;&#26126;&#20102;&#36825;&#20123;&#32593;&#32476;&#33021;&#22815;&#36924;&#36817;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;d&#32500;&#32039;&#33268;&#23376;&#38598;&#19978;&#30340;&#20219;&#20309;&#36830;&#32493;&#22810;&#20803;&#20989;&#25968;&#12290;&#23545;&#20110;&#26377;&#38480;&#20010;&#22266;&#23450;&#20013;&#24515;&#30340;RBF&#32593;&#32476;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#20445;&#35777;&#20219;&#24847;&#31934;&#24230;&#36924;&#36817;&#30340;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we consider a new class of RBF (Radial Basis Function) neural networks, in which smoothing factors are replaced with shifts. We prove under certain conditions on the activation function that these networks are capable of approximating any continuous multivariate function on any compact subset of the $d$-dimensional Euclidean space. For RBF networks with finitely many fixed centroids we describe conditions guaranteeing approximation with arbitrary precision.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#36830;&#32493;&#20248;&#21270;&#22312;&#26377;&#21521;&#26080;&#29615;&#22270;&#32467;&#26500;&#23398;&#20064;&#20013;&#30340;&#20248;&#28857;&#21644;&#32570;&#28857;&#65292;&#20998;&#26512;&#20102;&#19981;&#30456;&#31561;&#22122;&#22768;&#26041;&#24046;&#20844;&#24335;&#20013;&#30340;&#38750;&#20984;&#24615;&#38382;&#39064;&#65292;&#24182;&#24314;&#35758;&#26410;&#26469;&#30740;&#31350;&#23558;&#26356;&#22810;&#22320;&#32771;&#34385;&#20808;&#39564;&#30693;&#35782;&#21644;&#24050;&#30693;&#32467;&#26500;&#65292;&#20197;&#23454;&#29616;&#26356;&#20581;&#22766;&#30340;&#20248;&#21270;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.02146</link><description>&lt;p&gt;
&#24102;&#36830;&#32493;&#20248;&#21270;&#30340;&#32467;&#26500;&#23398;&#20064;&#65306;&#23457;&#24910;&#35266;&#23519;&#21450;&#20854;&#21457;&#23637;
&lt;/p&gt;
&lt;p&gt;
Structure Learning with Continuous Optimization: A Sober Look and Beyond. (arXiv:2304.02146v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02146
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#36830;&#32493;&#20248;&#21270;&#22312;&#26377;&#21521;&#26080;&#29615;&#22270;&#32467;&#26500;&#23398;&#20064;&#20013;&#30340;&#20248;&#28857;&#21644;&#32570;&#28857;&#65292;&#20998;&#26512;&#20102;&#19981;&#30456;&#31561;&#22122;&#22768;&#26041;&#24046;&#20844;&#24335;&#20013;&#30340;&#38750;&#20984;&#24615;&#38382;&#39064;&#65292;&#24182;&#24314;&#35758;&#26410;&#26469;&#30740;&#31350;&#23558;&#26356;&#22810;&#22320;&#32771;&#34385;&#20808;&#39564;&#30693;&#35782;&#21644;&#24050;&#30693;&#32467;&#26500;&#65292;&#20197;&#23454;&#29616;&#26356;&#20581;&#22766;&#30340;&#20248;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#36830;&#32493;&#20248;&#21270;&#22312;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#32467;&#26500;&#23398;&#20064;&#20013;&#30340;&#34920;&#29616;&#22909;&#22351;&#21450;&#20854;&#21407;&#22240;&#65292;&#24182;&#25552;&#20986;&#20102;&#21487;&#33021;&#20351;&#25628;&#32034;&#36807;&#31243;&#26356;&#21487;&#38752;&#30340;&#26041;&#21521;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#36830;&#32493;&#26041;&#27861;&#22312;&#20551;&#35774;&#22122;&#22768;&#26041;&#24046;&#30456;&#31561;&#21644;&#19981;&#30456;&#31561;&#30340;&#24773;&#20917;&#19979;&#30340;&#29616;&#35937;&#65292;&#24182;&#36890;&#36807;&#25552;&#20379;&#21453;&#20363;&#12289;&#29702;&#35770;&#35777;&#26126;&#21644;&#21487;&#33021;&#30340;&#26367;&#20195;&#35299;&#37322;&#26469;&#34920;&#26126;&#36825;&#31181;&#38472;&#36848;&#22312;&#20219;&#19968;&#24773;&#20917;&#19979;&#37117;&#21487;&#33021;&#19981;&#25104;&#31435;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#23545;&#20110;&#38750;&#30456;&#31561;&#22122;&#22768;&#26041;&#24046;&#20844;&#24335;&#65292;&#38750;&#20984;&#24615;&#21487;&#33021;&#26159;&#20027;&#35201;&#38382;&#39064;&#65292;&#32780;&#36830;&#32493;&#32467;&#26500;&#23398;&#20064;&#26041;&#38754;&#30340;&#26368;&#26032;&#36827;&#23637;&#21017;&#26080;&#27861;&#22312;&#23398;&#20064;&#36895;&#24230;&#21644;&#23454;&#29616;&#24471;&#20998;&#26041;&#38754;&#20248;&#20110;&#36138;&#24515;&#25628;&#32034;&#65292;&#24182;&#24314;&#35758;&#34701;&#21512;&#20808;&#39564;&#30693;&#35782;&#25110;&#24050;&#30693;&#32467;&#26500;&#30340;&#26356;&#20581;&#22766;&#30340;&#20248;&#21270;&#26041;&#27861;&#26159;&#26410;&#26469;&#30740;&#31350;&#30340;&#19968;&#20010;&#26377;&#24076;&#26395;&#30340;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates in which cases continuous optimization for directed acyclic graph (DAG) structure learning can and cannot perform well and why this happens, and suggests possible directions to make the search procedure more reliable. Reisach et al. (2021) suggested that the remarkable performance of several continuous structure learning approaches is primarily driven by a high agreement between the order of increasing marginal variances and the topological order, and demonstrated that these approaches do not perform well after data standardization. We analyze this phenomenon for continuous approaches assuming equal and non-equal noise variances, and show that the statement may not hold in either case by providing counterexamples, justifications, and possible alternative explanations. We further demonstrate that nonconvexity may be a main concern especially for the non-equal noise variances formulation, while recent advances in continuous structure learning fail to achieve impro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32447;&#24615;&#23545;&#25968;&#26102;&#38388;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#21333;&#21464;&#37327;&#23398;&#20064;&#27169;&#22411;&#22312;&#32447;&#24615;&#25439;&#22833;&#20989;&#25968;&#19979;&#24471;&#20998;&#36755;&#20986;&#30340;&#26368;&#20248;&#21333;&#23792;&#36716;&#25442;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2304.02141</link><description>&lt;p&gt;
&#32447;&#24615;&#25439;&#22833;&#19979;&#30340;&#26368;&#20248;&#21333;&#23792;&#25311;&#21512;&#38382;&#39064;&#30340;&#32447;&#24615;&#23545;&#25968;&#26102;&#38388;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sequential Linearithmic Time Optimal Unimodal Fitting When Minimizing Univariate Linear Losses. (arXiv:2304.02141v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02141
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32447;&#24615;&#23545;&#25968;&#26102;&#38388;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#21333;&#21464;&#37327;&#23398;&#20064;&#27169;&#22411;&#22312;&#32447;&#24615;&#25439;&#22833;&#20989;&#25968;&#19979;&#24471;&#20998;&#36755;&#20986;&#30340;&#26368;&#20248;&#21333;&#23792;&#36716;&#25442;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#20110;&#21333;&#21464;&#37327;&#23398;&#20064;&#27169;&#22411;&#22312;&#32447;&#24615;&#25439;&#22833;&#20989;&#25968;&#19979;&#24471;&#20998;&#36755;&#20986;&#30340;&#26368;&#20248;&#21333;&#23792;&#36716;&#25442;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20998;&#25968;&#38754;&#20540;&#21644;&#30446;&#26631;&#21306;&#22495;&#20043;&#38388;&#30340;&#26368;&#20339;&#26144;&#23556;&#26159;&#19968;&#20010;&#30697;&#24418;&#20989;&#25968;&#12290;&#20026;&#20102;&#33719;&#24471;&#35266;&#27979;&#26679;&#26412;&#30340;&#26368;&#20248;&#30697;&#24418;&#25311;&#21512;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39034;&#24207;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#27599;&#20010;&#26032;&#26679;&#26412;&#21040;&#26469;&#26102;&#36827;&#34892;&#20272;&#35745;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#27599;&#27425;&#36845;&#20195;&#20855;&#26377;&#23545;&#25968;&#26102;&#38388;&#22797;&#26434;&#24230;&#65292;&#24182;&#19988;&#20855;&#26377;&#26368;&#20248;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper focuses on optimal unimodal transformation of the score outputs of a univariate learning model under linear loss functions. We demonstrate that the optimal mapping between score values and the target region is a rectangular function. To produce this optimal rectangular fit for the observed samples, we propose a sequential approach that can its estimation with each incoming new sample. Our approach has logarithmic time complexity per iteration and is optimally efficient.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20449;&#24687;&#35770;&#24037;&#20855;&#30340;&#20351;&#29992;&#65292;&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#28304;&#22495;&#33258;&#36866;&#24212;&#34920;&#31034;&#23398;&#20064;&#20013;&#30340;&#32852;&#21512;&#20998;&#24067;&#23545;&#40784;&#65292;&#25552;&#20986;&#20102;&#31639;&#27861;&#30456;&#20851;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#30446;&#26631;&#20559;&#31227;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2304.02064</link><description>&lt;p&gt;
&#31639;&#27861;&#30456;&#20851;&#30340;&#30028;&#38480;&#23545;&#22810;&#28304;&#22495;&#33258;&#36866;&#24212;&#34920;&#31034;&#23398;&#20064;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Algorithm-Dependent Bounds for Representation Learning of Multi-Source Domain Adaptation. (arXiv:2304.02064v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02064
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20449;&#24687;&#35770;&#24037;&#20855;&#30340;&#20351;&#29992;&#65292;&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#28304;&#22495;&#33258;&#36866;&#24212;&#34920;&#31034;&#23398;&#20064;&#20013;&#30340;&#32852;&#21512;&#20998;&#24067;&#23545;&#40784;&#65292;&#25552;&#20986;&#20102;&#31639;&#27861;&#30456;&#20851;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#30446;&#26631;&#20559;&#31227;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20351;&#29992;&#20449;&#24687;&#35770;&#24037;&#20855;&#20174;&#34920;&#31034;&#23398;&#20064;&#30340;&#35282;&#24230;&#23545;&#22810;&#28304;&#22495;&#33258;&#36866;&#24212;&#36827;&#34892;&#20102;&#26032;&#39062;&#30340;&#20998;&#26512;&#65292;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26377;&#23569;&#37327;&#30446;&#26631;&#26631;&#31614;&#30340;&#30417;&#30563; MDA &#21644;&#24102;&#26377;&#20266;&#26631;&#31614;&#30340;&#26080;&#30417;&#30563; MDA &#30340;&#32852;&#21512;&#20998;&#24067;&#23545;&#40784;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#38024;&#23545;&#36825;&#20004;&#31181;&#24773;&#20917;&#25552;&#20379;&#20102;&#31639;&#27861;&#30456;&#20851;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#20854;&#20013;&#27867;&#21270;&#30001;&#21442;&#25968;&#19982;&#25968;&#25454;&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#26469;&#25551;&#36848;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230; MDA &#31639;&#27861;&#65292;&#36890;&#36807;&#32852;&#21512;&#23545;&#40784;&#38544;&#21547;&#22320;&#35299;&#20915;&#20102;&#30446;&#26631;&#20559;&#31227;&#38382;&#39064;&#12290;&#26368;&#21518;&#65292;&#36825;&#20123;&#20114;&#20449;&#24687;&#30028;&#38480;&#25193;&#23637;&#21040;&#27492;&#31639;&#27861;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#38750;&#24179;&#24248;&#30340;&#26799;&#24230;&#33539;&#25968;&#20272;&#35745;&#12290;&#35813;&#31639;&#27861;&#22312;&#25913;&#36827;&#20869;&#23384;&#25928;&#29575;&#30340;&#21516;&#26102;&#65292;&#22312;&#30446;&#26631;&#20559;&#31227; MDA &#22522;&#20934;&#27979;&#35797;&#20013;&#20855;&#26377;&#21487;&#27604;&#36739;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We use information-theoretic tools to derive a novel analysis of Multi-source Domain Adaptation (MDA) from the representation learning perspective. Concretely, we study joint distribution alignment for supervised MDA with few target labels and unsupervised MDA with pseudo labels, where the latter is relatively hard and less commonly studied. We further provide algorithm-dependent generalization bounds for these two settings, where the generalization is characterized by the mutual information between the parameters and the data. Then we propose a novel deep MDA algorithm, implicitly addressing the target shift through joint alignment. Finally, the mutual information bounds are extended to this algorithm providing a non-vacuous gradient-norm estimation. The proposed algorithm has comparable performance to the state-of-the-art on target-shifted MDA benchmark with improved memory efficiency.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#23485;&#19988;&#28145;&#30340;Transformer&#20013;&#30340;&#21069;&#21521;&#21644;&#21518;&#21521;&#20449;&#21495;&#20256;&#25773;&#65292;&#25552;&#20986;&#20102;&#29305;&#23450;&#30340;&#21021;&#22987;&#21270;&#21644;&#35757;&#32451;&#36229;&#21442;&#25968;&#23485;&#24230;&#32553;&#25918;&#24314;&#35758;&#65292;&#24182;&#22312;&#23454;&#38469;&#35774;&#32622;&#20013;&#39564;&#35777;&#20102;&#36825;&#20123;&#24314;&#35758;&#12290;</title><link>http://arxiv.org/abs/2304.02034</link><description>&lt;p&gt;
&#21021;&#22987;&#21270;&#26102;Transformer&#30340;&#26377;&#25928;&#29702;&#35770;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Effective Theory of Transformers at Initialization. (arXiv:2304.02034v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02034
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#23485;&#19988;&#28145;&#30340;Transformer&#20013;&#30340;&#21069;&#21521;&#21644;&#21518;&#21521;&#20449;&#21495;&#20256;&#25773;&#65292;&#25552;&#20986;&#20102;&#29305;&#23450;&#30340;&#21021;&#22987;&#21270;&#21644;&#35757;&#32451;&#36229;&#21442;&#25968;&#23485;&#24230;&#32553;&#25918;&#24314;&#35758;&#65292;&#24182;&#22312;&#23454;&#38469;&#35774;&#32622;&#20013;&#39564;&#35777;&#20102;&#36825;&#20123;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;&#23485;&#19988;&#28145;&#30340;Transformer&#65288;&#21363;&#20351;&#29992;&#22810;&#22836;&#33258;&#27880;&#24847;&#22359;&#21644;&#22810;&#23618;&#24863;&#30693;&#26426;&#22359;&#30340;&#27531;&#24046;&#31070;&#32463;&#32593;&#32476;&#65289;&#20013;&#30340;&#21069;&#21521;&#21644;&#21518;&#21521;&#20449;&#21495;&#20256;&#25773;&#36827;&#34892;&#20102;&#26377;&#25928;&#29702;&#35770;&#20998;&#26512;&#12290;&#35813;&#20998;&#26512;&#24314;&#35758;&#36825;&#20123;&#27169;&#22411;&#30340;&#21021;&#22987;&#21270;&#21644;&#35757;&#32451;&#36229;&#21442;&#25968;&#37319;&#29992;&#29305;&#23450;&#30340;&#23485;&#24230;&#32553;&#25918;&#12290;&#25105;&#20204;&#38543;&#21518;&#37319;&#29992;&#36825;&#20123;&#24314;&#35758;&#65292;&#22312;&#23454;&#38469;&#35774;&#32622;&#20013;&#23545;&#35270;&#35273;&#21644;&#35821;&#35328;Transformer&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
We perform an effective-theory analysis of forward-backward signal propagation in wide and deep Transformers, i.e., residual neural networks with multi-head self-attention blocks and multilayer perceptron blocks. This analysis suggests particular width scalings of initialization and training hyperparameters for these models. We then take up such suggestions, training Vision and Language Transformers in practical setups.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#22240;&#26524;&#36793;&#38469;&#38382;&#39064;&#65292;&#38480;&#23450;&#22240;&#26524;&#27010;&#29575;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22823;&#22823;&#32553;&#23567;&#29616;&#26377;&#30340;&#22240;&#26524;&#27010;&#29575;&#33539;&#22260;&#12290;</title><link>http://arxiv.org/abs/2304.02023</link><description>&lt;p&gt;
&#36890;&#36807;&#22240;&#26524;&#36793;&#38469;&#38382;&#39064;&#38480;&#23450;&#22240;&#26524;&#27010;&#29575;&#30340;&#33539;&#22260;
&lt;/p&gt;
&lt;p&gt;
Bounding probabilities of causation through the causal marginal problem. (arXiv:2304.02023v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02023
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#22240;&#26524;&#36793;&#38469;&#38382;&#39064;&#65292;&#38480;&#23450;&#22240;&#26524;&#27010;&#29575;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22823;&#22823;&#32553;&#23567;&#29616;&#26377;&#30340;&#22240;&#26524;&#27010;&#29575;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#27010;&#29575;&#22312;&#27861;&#24459;&#12289;&#21307;&#30103;&#21644;&#20844;&#20849;&#25919;&#31574;&#20013;&#23545;&#20915;&#31574;&#36215;&#30528;&#22522;&#30784;&#24615;&#30340;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#20854;&#20934;&#30830;&#23450;&#20301;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#38656;&#35201;&#19968;&#20123;&#24378;&#20551;&#35774;&#65292;&#27604;&#22914;&#21333;&#35843;&#24615;&#12290;&#22312;&#27809;&#26377;&#36825;&#26679;&#30340;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#29616;&#26377;&#30340;&#24037;&#20316;&#38656;&#35201;&#21253;&#21547;&#30456;&#21516;&#22788;&#29702;&#21644;&#32467;&#26524;&#21464;&#37327;&#30340;&#25968;&#25454;&#38598;&#30340;&#22810;&#20010;&#35266;&#27979;&#65292;&#20197;&#20415;&#23545;&#36825;&#20123;&#27010;&#29575;&#36827;&#34892;&#36793;&#30028;&#32422;&#26463;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#20020;&#24202;&#35797;&#39564;&#21644;&#20844;&#20849;&#25919;&#31574;&#35780;&#20272;&#20013;&#65292;&#23384;&#22312;&#29420;&#31435;&#30340;&#25968;&#25454;&#38598;&#65292;&#36825;&#20123;&#25968;&#25454;&#38598;&#26816;&#26597;&#20102;&#19981;&#21516;&#27835;&#30103;&#26041;&#24335;&#23545;&#21516;&#19968;&#32467;&#26524;&#21464;&#37327;&#30340;&#24433;&#21709;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#22914;&#20309;&#36890;&#36807;&#24378;&#21046;&#29420;&#31435;&#25968;&#25454;&#38598;&#20013;&#26500;&#36896;&#30340;SCM&#65288;&#8220;&#22240;&#26524;&#36793;&#38469;&#38382;&#39064;&#8221;&#65289;&#30340;&#21453;&#20107;&#23454;&#19968;&#33268;&#24615;&#65292;&#20174;&#32780;&#22823;&#22823;&#32553;&#23567;&#29616;&#26377;&#30340;&#22240;&#26524;&#27010;&#29575;&#33539;&#22260;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#31181;&#26032;&#30340;&#20449;&#24687;&#29702;&#35770;&#26041;&#27861;&#65292;&#29992;&#20110;&#36890;&#36807;&#20351;&#29992;&#26465;&#20214;&#20114;&#20449;&#24687;&#37327;&#21270;&#21453;&#20107;&#23454;&#24433;&#21709;&#26469;&#35777;&#26126;&#22240;&#26524;&#27010;&#29575;&#30340;&#34394;&#20551;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Probabilities of Causation play a fundamental role in decision making in law, health care and public policy. Nevertheless, their point identification is challenging, requiring strong assumptions such as monotonicity. In the absence of such assumptions, existing work requires multiple observations of datasets that contain the same treatment and outcome variables, in order to establish bounds on these probabilities. However, in many clinical trials and public policy evaluation cases, there exist independent datasets that examine the effect of a different treatment each on the same outcome variable. Here, we outline how to significantly tighten existing bounds on the probabilities of causation, by imposing counterfactual consistency between SCMs constructed from such independent datasets ('causal marginal problem'). Next, we describe a new information theoretic approach on falsification of counterfactual probabilities, using conditional mutual information to quantify counterfactual influe
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#65292;&#35777;&#26126;&#20102;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#30340;Bayesian&#33258;&#30001;&#33021;&#26159;&#26377;&#30028;&#30340;&#65292;&#35828;&#26126;Bayesian&#24191;&#20041;&#35823;&#24046;&#19981;&#20250;&#22686;&#21152;&#12290;</title><link>http://arxiv.org/abs/2303.15739</link><description>&lt;p&gt;
&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#22312;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#30340;&#36125;&#21494;&#26031;&#33258;&#30001;&#33021;
&lt;/p&gt;
&lt;p&gt;
Bayesian Free Energy of Deep ReLU Neural Network in Overparametrized Cases. (arXiv:2303.15739v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15739
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#65292;&#35777;&#26126;&#20102;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#30340;Bayesian&#33258;&#30001;&#33021;&#26159;&#26377;&#30028;&#30340;&#65292;&#35828;&#26126;Bayesian&#24191;&#20041;&#35823;&#24046;&#19981;&#20250;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20154;&#24037;&#26234;&#33021;&#30340;&#35768;&#22810;&#30740;&#31350;&#39046;&#22495;&#20013;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#24050;&#34987;&#35777;&#26126;&#21487;&#29992;&#20110;&#20272;&#35745;&#39640;&#32500;&#36755;&#20837;&#31354;&#38388;&#20013;&#30340;&#26410;&#30693;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#27867;&#21270;&#24615;&#33021;&#23578;&#26410;&#20174;&#29702;&#35770;&#35282;&#24230;&#23436;&#20840;&#28548;&#28165;&#65292;&#22240;&#20026;&#23427;&#20204;&#26159;&#19981;&#21487;&#35782;&#21035;&#30340;&#21644;&#22855;&#24322;&#30340;&#23398;&#20064;&#26426;&#22120;&#12290;&#27492;&#22806;&#65292;ReLU&#20989;&#25968;&#19981;&#21487;&#24494;&#65292;&#22855;&#24322;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#20195;&#25968;&#25110;&#35299;&#26512;&#26041;&#27861;&#26080;&#27861;&#24212;&#29992;&#20110;&#23427;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#30340;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#35777;&#26126;&#20102;Bayesian&#33258;&#30001;&#33021;&#26159;&#26377;&#30028;&#30340;&#65292;&#21363;&#20351;&#23618;&#25968;&#27604;&#20272;&#35745;&#26410;&#30693;&#25968;&#25454;&#29983;&#25104;&#20989;&#25968;&#25152;&#24517;&#38656;&#30340;&#23618;&#25968;&#26356;&#22810;&#12290;&#30001;&#20110;Bayesian&#24191;&#20041;&#35823;&#24046;&#31561;&#20110;&#26679;&#26412;&#22823;&#23567;&#30340;&#33258;&#30001;&#33021;&#22686;&#21152;&#65292;&#22240;&#27492;&#25105;&#20204;&#30340;&#32467;&#26524;&#20063;&#34920;&#26126;&#65292;Bayesian&#24191;&#20041;&#35823;&#24046;&#19981;&#20250;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many research fields in artificial intelligence, it has been shown that deep neural networks are useful to estimate unknown functions on high dimensional input spaces. However, their generalization performance is not yet completely clarified from the theoretical point of view because they are nonidentifiable and singular learning machines. Moreover, a ReLU function is not differentiable, to which algebraic or analytic methods in singular learning theory cannot be applied. In this paper, we study a deep ReLU neural network in overparametrized cases and prove that the Bayesian free energy, which is equal to the minus log marginal likelihoodor the Bayesian stochastic complexity, is bounded even if the number of layers are larger than necessary to estimate an unknown data-generating function. Since the Bayesian generalization error is equal to the increase of the free energy as a function of a sample size, our result also shows that the Bayesian generalization error does not increase ev
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25910;&#25947;&#25554;&#20837;&#25773;&#25918;&#31639;&#27861;&#65292;&#20351;&#29992;&#19968;&#20010;&#26494;&#24347;&#30340;&#36817;&#31471;&#21435;&#22122;&#22120;&#21644;&#19968;&#20010;&#26494;&#24347;&#30340;PGD&#31639;&#27861;&#65292;&#33021;&#22815;&#25910;&#25947;&#20110;&#26356;&#24191;&#27867;&#30340;&#27491;&#21017;&#21270;&#21442;&#25968;&#33539;&#22260;&#20869;&#12290;</title><link>http://arxiv.org/abs/2301.13731</link><description>&lt;p&gt;
&#19968;&#31181;&#26494;&#24347;&#30340;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#29992;&#20110;&#24102;&#26377;&#36817;&#31471;&#21435;&#22122;&#22120;&#30340;&#25910;&#25947;&#25554;&#20837;-&#25773;&#25918;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A relaxed proximal gradient descent algorithm for convergent plug-and-play with proximal denoiser. (arXiv:2301.13731v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13731
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25910;&#25947;&#25554;&#20837;&#25773;&#25918;&#31639;&#27861;&#65292;&#20351;&#29992;&#19968;&#20010;&#26494;&#24347;&#30340;&#36817;&#31471;&#21435;&#22122;&#22120;&#21644;&#19968;&#20010;&#26494;&#24347;&#30340;PGD&#31639;&#27861;&#65292;&#33021;&#22815;&#25910;&#25947;&#20110;&#26356;&#24191;&#27867;&#30340;&#27491;&#21017;&#21270;&#21442;&#25968;&#33539;&#22260;&#20869;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25910;&#25947;&#25554;&#20837;&#25773;&#25918;&#31639;&#27861;&#12290;&#25554;&#20837;&#25773;&#25918;&#26041;&#27861;&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#34987;&#34920;&#36848;&#20026;&#25968;&#25454;&#36866;&#24212;&#39033;&#21644;&#27491;&#21017;&#21270;&#39033;&#20043;&#21644;&#30340;&#22270;&#20687;&#21453;&#38382;&#39064;&#30340;&#26368;&#23567;&#21270;&#38382;&#39064;&#12290;&#25554;&#20837;&#25773;&#25918;&#26041;&#27861;&#36890;&#36807;&#22312;&#36817;&#31471;&#31639;&#27861;&#65288;&#22914;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#65289;&#20013;&#25554;&#20837;&#19968;&#20010;&#39044;&#20808;&#35757;&#32451;&#22909;&#30340;&#21435;&#22122;&#22120;&#26469;&#25191;&#34892;&#27491;&#21017;&#21270;&#12290;&#20026;&#30830;&#20445;PnP&#26041;&#26696;&#30340;&#25910;&#25947;&#65292;&#35768;&#22810;&#24037;&#20316;&#30740;&#31350;&#28145;&#24230;&#21435;&#22122;&#22120;&#30340;&#29305;&#23450;&#21442;&#25968;&#21270;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#32467;&#26524;&#35201;&#20040;&#38656;&#35201;&#26080;&#27861;&#39564;&#35777;&#30340;&#20551;&#35774;&#25110;&#27425;&#20248;&#20551;&#35774;&#65292;&#35201;&#20040;&#22312;&#36870;&#38382;&#39064;&#30340;&#21442;&#25968;&#19978;&#20551;&#35774;&#38480;&#21046;&#24615;&#26465;&#20214;&#12290;&#35266;&#23519;&#21040;&#36825;&#20123;&#38480;&#21046;&#21487;&#33021;&#26159;&#30001;&#20110;&#20351;&#29992;&#30340;&#36817;&#31471;&#31639;&#27861;&#65292;&#22240;&#27492;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#26494;&#24347;&#29256;&#26412;&#30340;PGD&#31639;&#27861;&#65288;&#29992;&#20110;&#26368;&#23567;&#21270;&#20984;&#20989;&#25968;&#21644;&#24369;&#20984;&#20989;&#25968;&#20043;&#21644;&#65289;&#12290;&#24403;&#19982;&#19968;&#20010;&#26494;&#24347;&#30340;&#36817;&#31471;&#21435;&#22122;&#22120;&#25554;&#20837;&#26102;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;PnP-$\alpha$PGD&#31639;&#27861;&#33021;&#22815;&#25910;&#25947;&#20110;&#26356;&#24191;&#27867;&#30340;&#27491;&#21017;&#21270;&#21442;&#25968;&#33539;&#22260;&#20869;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a new convergent Plug-and-Play (PnP) algorithm. PnP methods are efficient iterative algorithms for solving image inverse problems formulated as the minimization of the sum of a data-fidelity term and a regularization term. PnP methods perform regularization by plugging a pre-trained denoiser in a proximal algorithm, such as Proximal Gradient Descent (PGD). To ensure convergence of PnP schemes, many works study specific parametrizations of deep denoisers. However, existing results require either unverifiable or suboptimal hypotheses on the denoiser, or assume restrictive conditions on the parameters of the inverse problem. Observing that these limitations can be due to the proximal algorithm in use, we study a relaxed version of the PGD algorithm for minimizing the sum of a convex function and a weakly convex one. When plugged with a relaxed proximal denoiser, we show that the proposed PnP-$\alpha$PGD algorithm converges for a wider range of regularization parameters
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#39321;&#33609;&#25193;&#25955;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#20998;&#31867;&#22120;&#36827;&#34892;&#32852;&#21512;&#31471;&#21040;&#31471;&#35757;&#32451;&#65292;&#20197;&#25552;&#39640;&#20998;&#31867;&#21644;&#29983;&#25104;&#25968;&#25454;&#30340;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2301.13622</link><description>&lt;p&gt;
&#20351;&#29992;&#32852;&#21512;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#25968;&#25454;&#34920;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Learning Data Representations with Joint Diffusion Models. (arXiv:2301.13622v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13622
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#39321;&#33609;&#25193;&#25955;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#20998;&#31867;&#22120;&#36827;&#34892;&#32852;&#21512;&#31471;&#21040;&#31471;&#35757;&#32451;&#65292;&#20197;&#25552;&#39640;&#20998;&#31867;&#21644;&#29983;&#25104;&#25968;&#25454;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#21512;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#36890;&#24120;&#20801;&#35768;&#21512;&#25104;&#21644;&#20998;&#31867;&#25968;&#25454;&#65292;&#20294;&#24120;&#24120;&#22312;&#36825;&#20123;&#20219;&#21153;&#20043;&#38388;&#34920;&#29616;&#19981;&#24179;&#34913;&#65292;&#25110;&#32773;&#19981;&#31283;&#23450;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#25193;&#23637;&#39321;&#33609;&#25193;&#25955;&#27169;&#22411;&#20197;&#20351;&#29992;&#20998;&#31867;&#22120;&#36827;&#34892;&#31283;&#23450;&#30340;&#32852;&#21512;&#31471;&#21040;&#31471;&#35757;&#32451;&#30340;&#26041;&#27861;&#12290;&#35813;&#27169;&#22411;&#22312;&#25152;&#26377;&#35780;&#20272;&#22522;&#20934;&#27979;&#35797;&#20013;&#22312;&#20998;&#31867;&#21644;&#29983;&#25104;&#36136;&#37327;&#26041;&#38754;&#22343;&#20248;&#20110;&#26368;&#26032;&#30340;&#28151;&#21512;&#26041;&#27861;&#12290;&#22312;&#25105;&#20204;&#30340;&#32852;&#21512;&#35757;&#32451;&#26041;&#27861;&#19978;&#65292;&#26412;&#25991;&#36824;&#20171;&#32461;&#20102;&#22914;&#20309;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#26041;&#27861;&#36827;&#34892;&#30452;&#25509;&#30410;&#22788;&#20849;&#20139;&#29983;&#25104;&#21644;&#37492;&#21035;&#34920;&#31034;&#65292;&#20197;&#25552;&#20379;&#35270;&#35273;&#21453;&#20107;&#23454;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Joint machine learning models that allow synthesizing and classifying data often offer uneven performance between those tasks or are unstable to train. In this work, we depart from a set of empirical observations that indicate the usefulness of internal representations built by contemporary deep diffusion-based generative models not only for generating but also predicting. We then propose to extend the vanilla diffusion model with a classifier that allows for stable joint end-to-end training with shared parameterization between those objectives. The resulting joint diffusion model outperforms recent state-of-the-art hybrid methods in terms of both classification and generation quality on all evaluated benchmarks. On top of our joint training approach, we present how we can directly benefit from shared generative and discriminative representations by introducing a method for visual counterfactual explanations.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#36755;&#20986;&#20989;&#25968;&#31867;&#30340;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22810;&#36755;&#20986;&#20989;&#25968;&#31867;&#23398;&#20064;&#30340;&#29305;&#24449;&#21270;&#21028;&#21035;&#26631;&#20934;&#65292;&#21363;&#27599;&#20010;&#21333;&#36755;&#20986;&#23376;&#31867;&#21487;&#23398;&#20064;&#26102;&#22810;&#36755;&#20986;&#20989;&#25968;&#31867;&#25165;&#21487;&#23398;&#20064;&#65292;&#22312;&#22810;&#26631;&#35760;&#20998;&#31867;&#21644;&#22810;&#36755;&#20986;&#22238;&#24402;&#39046;&#22495;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#12290;</title><link>http://arxiv.org/abs/2301.02729</link><description>&lt;p&gt;
&#22810;&#36755;&#20986;&#21487;&#23398;&#20064;&#24615;&#30340;&#29305;&#24449;&#21270;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Characterization of Multioutput Learnability. (arXiv:2301.02729v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.02729
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#36755;&#20986;&#20989;&#25968;&#31867;&#30340;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22810;&#36755;&#20986;&#20989;&#25968;&#31867;&#23398;&#20064;&#30340;&#29305;&#24449;&#21270;&#21028;&#21035;&#26631;&#20934;&#65292;&#21363;&#27599;&#20010;&#21333;&#36755;&#20986;&#23376;&#31867;&#21487;&#23398;&#20064;&#26102;&#22810;&#36755;&#20986;&#20989;&#25968;&#31867;&#25165;&#21487;&#23398;&#20064;&#65292;&#22312;&#22810;&#26631;&#35760;&#20998;&#31867;&#21644;&#22810;&#36755;&#20986;&#22238;&#24402;&#39046;&#22495;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#25209;&#22788;&#29702;&#21644;&#22312;&#32447;&#23398;&#20064;&#20013;&#30340;&#22810;&#36755;&#20986;&#20989;&#25968;&#31867;&#23398;&#20064;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#24403;&#19988;&#20165;&#24403;&#20989;&#25968;&#31867;&#30340;&#27599;&#20010;&#21333;&#36755;&#20986;&#23376;&#31867;&#37117;&#21487;&#23398;&#20064;&#26102;&#65292;&#22810;&#36755;&#20986;&#20989;&#25968;&#31867;&#25165;&#26159;&#21487;&#23398;&#20064;&#30340;&#12290;&#36825;&#25552;&#20379;&#20102;&#22810;&#26631;&#35760;&#20998;&#31867;&#21644;&#22810;&#36755;&#20986;&#22238;&#24402;&#22312;&#25209;&#22788;&#29702;&#21644;&#22312;&#32447;&#23398;&#20064;&#20013;&#21487;&#23398;&#20064;&#24615;&#30340;&#23436;&#25972;&#29305;&#24449;&#21270;&#12290;&#20316;&#20026;&#25193;&#23637;&#65292;&#25105;&#20204;&#36824;&#32771;&#34385;&#20102;&#22312;&#36172;&#21338;&#21453;&#39304;&#29615;&#22659;&#19979;&#30340;&#22810;&#26631;&#35760;&#23398;&#20064;&#65292;&#24182;&#23637;&#31034;&#20102;&#19982;&#23436;&#20840;&#21453;&#39304;&#29615;&#22659;&#19979;&#31867;&#20284;&#30340;&#29305;&#24449;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning multioutput function classes in batch and online settings. In both settings, we show that a multioutput function class is learnable if and only if each single-output restriction of the function class is learnable. This provides a complete characterization of the learnability of multilabel classification and multioutput regression in both batch and online settings. As an extension, we also consider multilabel learnability in the bandit feedback setting and show a similar characterization as in the full-feedback setting.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;PAC-Bayesian&#27867;&#21270;&#30028;&#38480;&#65292;&#36866;&#29992;&#20110;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#25110;&#36830;&#32493;&#26799;&#24230;&#27969;&#35757;&#32451;&#27169;&#22411;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#19988;&#26080;&#38656;&#38543;&#26426;&#21270;&#12290;</title><link>http://arxiv.org/abs/2209.02525</link><description>&lt;p&gt;
&#22522;&#20110;&#30830;&#23450;&#24615;PAC-Bayes&#30340;&#26799;&#24230;&#19979;&#38477;&#19979;&#30340;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Generalisation under gradient descent via deterministic PAC-Bayes. (arXiv:2209.02525v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.02525
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;PAC-Bayesian&#27867;&#21270;&#30028;&#38480;&#65292;&#36866;&#29992;&#20110;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#25110;&#36830;&#32493;&#26799;&#24230;&#27969;&#35757;&#32451;&#27169;&#22411;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#19988;&#26080;&#38656;&#38543;&#26426;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20026;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#25110;&#36830;&#32493;&#26799;&#24230;&#27969;&#35757;&#32451;&#27169;&#22411;&#24314;&#31435;&#20102;&#32454;&#20998;&#30340;PAC-Bayesian&#27867;&#21270;&#30028;&#38480;&#12290;&#19982;PAC-Bayes&#35774;&#23450;&#20013;&#30340;&#26631;&#20934;&#20570;&#27861;&#30456;&#21453;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#30830;&#23450;&#24615;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#32780;&#19981;&#38656;&#35201;&#20219;&#20309;&#21435;&#38543;&#26426;&#21270;&#30340;&#27493;&#39588;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#26159;&#23436;&#20840;&#21487;&#35745;&#31639;&#30340;&#65292;&#21462;&#20915;&#20110;&#21021;&#22987;&#20998;&#24067;&#30340;&#23494;&#24230;&#21644;&#36712;&#36857;&#19978;&#35757;&#32451;&#30446;&#26631;&#30340;&#28023;&#26862;&#30697;&#38453;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#24212;&#29992;&#20110;&#21508;&#31181;&#36845;&#20195;&#20248;&#21270;&#31639;&#27861;&#65292;&#21253;&#25324;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#12289;&#21160;&#37327;&#31639;&#27861;&#21644;&#38459;&#23612;&#21704;&#23494;&#39039;&#21160;&#21147;&#23398;&#12290;
&lt;/p&gt;
&lt;p&gt;
We establish disintegrated PAC-Bayesian generalisation bounds for models trained with gradient descent methods or continuous gradient flows. Contrary to standard practice in the PAC-Bayesian setting, our result applies to optimisation algorithms that are deterministic, without requiring any de-randomisation step. Our bounds are fully computable, depending on the density of the initial distribution and the Hessian of the training objective over the trajectory. We show that our framework can be applied to a variety of iterative optimisation algorithms, including stochastic gradient descent (SGD), momentum-based schemes, and damped Hamiltonian dynamics.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35748;&#20026;Sinkhorn&#31639;&#27861;&#30340;&#21021;&#22987;&#21270;&#22791;&#21463;&#24573;&#35270;&#65292;&#20294;&#25968;&#25454;&#30456;&#20851;&#30340;&#21021;&#22987;&#21270;&#21487;&#20197;&#25552;&#39640;&#31639;&#27861;&#24615;&#33021;&#65292;&#24182;&#36866;&#29992;&#20110;&#31471;&#21040;&#31471;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2206.07630</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;Sinkhorn&#31639;&#27861;&#30340;&#21021;&#22987;&#21270;
&lt;/p&gt;
&lt;p&gt;
Rethinking Initialization of the Sinkhorn Algorithm. (arXiv:2206.07630v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.07630
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35748;&#20026;Sinkhorn&#31639;&#27861;&#30340;&#21021;&#22987;&#21270;&#22791;&#21463;&#24573;&#35270;&#65292;&#20294;&#25968;&#25454;&#30456;&#20851;&#30340;&#21021;&#22987;&#21270;&#21487;&#20197;&#25552;&#39640;&#31639;&#27861;&#24615;&#33021;&#65292;&#24182;&#36866;&#29992;&#20110;&#31471;&#21040;&#31471;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#26368;&#21021;&#34987;&#21046;&#23450;&#20026;&#32447;&#24615;&#35268;&#21010;&#65292;&#20294;&#28155;&#21152;&#29109;&#27491;&#21017;&#21270;&#24050;&#34987;&#35777;&#26126;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#20855;&#26377;&#20248;&#36234;&#30340;&#35745;&#31639;&#21644;&#32479;&#35745;&#25928;&#26524;&#12290;Sinkhorn&#31639;&#27861;&#26159;&#35299;&#20915;&#36825;&#20010;&#27491;&#21017;&#21270;&#38382;&#39064;&#30340;&#26368;&#24120;&#29992;&#26041;&#27861;&#65292;&#24182;&#19988;&#24050;&#32463;&#26377;&#22810;&#27425;&#23581;&#35797;&#36890;&#36807;&#20351;&#29992;&#22914;&#27491;&#21017;&#21270;&#21442;&#25968;&#36864;&#28779;&#12289;&#21160;&#37327;&#25110;&#21152;&#36895;&#24230;&#26469;&#20943;&#23569;&#20854;&#36816;&#34892;&#26102;&#38388;&#12290;&#26412;&#25991;&#30340;&#21069;&#25552;&#26159;Sinkhorn&#31639;&#27861;&#30340;&#21021;&#22987;&#21270;&#30456;&#23545;&#36739;&#23569;&#21463;&#21040;&#20851;&#27880;&#65292;&#21487;&#33021;&#26159;&#30001;&#20110;&#20004;&#31181;&#20808;&#20837;&#20026;&#20027;&#30340;&#35266;&#24565;:&#30001;&#20110;&#27491;&#21017;&#21270;&#30340;OT&#38382;&#39064;&#26159;&#20984;&#38382;&#39064;&#65292;&#22240;&#27492;&#21487;&#33021;&#19981;&#20540;&#24471;&#35774;&#35745;&#33391;&#22909;&#30340;&#21021;&#22987;&#21270;&#65292;&#22240;&#20026;&#20219;&#20309;&#21021;&#22987;&#21270;&#37117;&#26159;&#21487;&#34892;&#30340;&#65307;&#20854;&#27425;&#65292;&#22240;&#20026;Sinkhorn&#31639;&#27861;&#30340;&#36755;&#20986;&#36890;&#24120;&#22312;&#31471;&#21040;&#31471;&#31649;&#36947;&#20013;&#23637;&#24320;&#65292;&#25152;&#20197;&#25968;&#25454;&#30456;&#20851;&#30340;&#21021;&#22987;&#21270;&#20250;&#23545;&#38597;&#21508;&#27604;&#35745;&#31639;&#36896;&#25104;&#20559;&#24046;&#12290;&#25105;&#20204;&#25361;&#25112;&#36825;&#31181;&#20256;&#32479;&#26234;&#24935;&#65292;&#24182;&#23637;&#31034;&#20102;&#25968;&#25454;&#30456;&#20851;&#30340;&#21021;&#22987;&#21270;&#21487;&#20197;&#25552;&#39640;Sinkhorn&#31639;&#27861;&#30340;&#24615;&#33021;&#65292;&#24182;&#36866;&#29992;&#20110;&#31471;&#21040;&#31471;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
While the optimal transport (OT) problem was originally formulated as a linear program, the addition of entropic regularization has proven beneficial both computationally and statistically, for many applications. The Sinkhorn fixed-point algorithm is the most popular approach to solve this regularized problem, and, as a result, multiple attempts have been made to reduce its runtime using, e.g., annealing in the regularization parameter, momentum or acceleration. The premise of this work is that initialization of the Sinkhorn algorithm has received comparatively little attention, possibly due to two preconceptions: since the regularized OT problem is convex, it may not be worth crafting a good initialization, since any is guaranteed to work; secondly, because the outputs of the Sinkhorn algorithm are often unrolled in end-to-end pipelines, a data-dependent initialization would bias Jacobian computations. We challenge this conventional wisdom, and show that data-dependent initializers re
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Diffusion SB (DSB) &#30340;&#36924;&#36817;&#36845;&#20195;&#27604;&#20363;&#25311;&#21512;&#31243;&#24207;&#65292;&#29992;&#20110;&#35299;&#20915;Schr&#246;dinger Bridge&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#21487;&#20197;&#20135;&#29983;&#20174;&#25968;&#25454;&#20998;&#24067;&#20013;&#29983;&#25104;&#26679;&#26412;&#30340;&#25193;&#25955;&#36807;&#31243;&#65292;&#32780;&#26377;&#38480;&#26102;&#38388;&#20869;&#23436;&#25104;&#12290;</title><link>http://arxiv.org/abs/2106.01357</link><description>&lt;p&gt;
&#24212;&#29992;&#20110;&#22522;&#20110;&#24471;&#20998;&#27169;&#22411;&#30340;&#25193;&#25955;Schr&#246;dinger&#26725;
&lt;/p&gt;
&lt;p&gt;
Diffusion Schr\"odinger Bridge with Applications to Score-Based Generative Modeling. (arXiv:2106.01357v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.01357
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Diffusion SB (DSB) &#30340;&#36924;&#36817;&#36845;&#20195;&#27604;&#20363;&#25311;&#21512;&#31243;&#24207;&#65292;&#29992;&#20110;&#35299;&#20915;Schr&#246;dinger Bridge&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#21487;&#20197;&#20135;&#29983;&#20174;&#25968;&#25454;&#20998;&#24067;&#20013;&#29983;&#25104;&#26679;&#26412;&#30340;&#25193;&#25955;&#36807;&#31243;&#65292;&#32780;&#26377;&#38480;&#26102;&#38388;&#20869;&#23436;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36880;&#27493;&#24212;&#29992;&#39640;&#26031;&#22122;&#22768;&#21487;&#20197;&#23558;&#22797;&#26434;&#30340;&#25968;&#25454;&#20998;&#24067;&#36716;&#21270;&#20026;&#36817;&#20284;&#39640;&#26031;&#20998;&#24067;&#12290;&#21453;&#21521;&#23450;&#20041;&#20102;&#19968;&#31181;&#29983;&#25104;&#27169;&#22411;&#12290;&#24403;&#27491;&#21521;&#22122;&#22768;&#36807;&#31243;&#30001;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#32473;&#20986;&#26102;&#65292;Song&#31561;&#20154;&#65288;2021&#65289;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#24471;&#20998;&#21305;&#37197;&#20272;&#35745;&#30456;&#24212;&#26102;&#38388;&#19981;&#22343;&#21248;&#28418;&#31227;&#30340;&#21453;&#21521;&#26102;&#38388;SDE&#12290;&#36825;&#31181;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#26159;&#38656;&#35201;&#36816;&#34892;&#36275;&#22815;&#38271;&#26102;&#38388;&#30340;&#27491;&#21521;&#26102;&#38388;SDE&#65292;&#25165;&#33021;&#20351;&#26368;&#32456;&#20998;&#24067;&#36817;&#20284;&#20026;&#39640;&#26031;&#20998;&#24067;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#35299;&#20915;Schr&#246;dinger&#26725;&#38382;&#39064;(SB)&#65292;&#21363;&#22312;&#36335;&#24452;&#31354;&#38388;&#19978;&#30340;&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#65292;&#21487;&#20197;&#20135;&#29983;&#20174;&#25968;&#25454;&#20998;&#24067;&#20013;&#29983;&#25104;&#26679;&#26412;&#30340;&#25193;&#25955;&#36807;&#31243;&#65292;&#32780;&#26377;&#38480;&#26102;&#38388;&#20869;&#23436;&#25104;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#25193;&#25955;SB&#65288;DSB&#65289;&#65292;&#19968;&#20010;&#35299;&#20915;SB&#38382;&#39064;&#30340;&#21407;&#22987;&#36817;&#20284;&#36845;&#20195;&#27604;&#20363;&#25311;&#21512;&#65288;IPF&#65289;&#31243;&#24207;&#65292;&#24182;&#25552;&#20379;&#29702;&#35770;&#20998;&#26512;&#21644;&#29983;&#25104;&#24314;&#27169;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Progressively applying Gaussian noise transforms complex data distributions to approximately Gaussian. Reversing this dynamic defines a generative model. When the forward noising process is given by a Stochastic Differential Equation (SDE), Song et al. (2021) demonstrate how the time inhomogeneous drift of the associated reverse-time SDE may be estimated using score-matching. A limitation of this approach is that the forward-time SDE must be run for a sufficiently long time for the final distribution to be approximately Gaussian. In contrast, solving the Schr\"odinger Bridge problem (SB), i.e. an entropy-regularized optimal transport problem on path spaces, yields diffusions which generate samples from the data distribution in finite time. We present Diffusion SB (DSB), an original approximation of the Iterative Proportional Fitting (IPF) procedure to solve the SB problem, and provide theoretical analysis along with generative modeling experiments. The first DSB iteration recovers the 
&lt;/p&gt;</description></item><item><title>&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#26159;&#19968;&#31181;&#23398;&#20064;&#22797;&#26434;&#39640;&#32500;&#27010;&#29575;&#20998;&#24067;&#30340;&#26032;&#22411;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#20294;&#20854;&#35757;&#32451;&#23384;&#22312;&#30528;&#35832;&#22810;&#25361;&#25112;&#65292;&#22914;&#27169;&#24335;&#23849;&#28291;&#12289;&#19981;&#25910;&#25947;&#21450;&#19981;&#31283;&#23450;&#24615;&#12290;&#26368;&#36817;&#65292;&#38024;&#23545;&#36825;&#20123;&#25361;&#25112;&#65292;&#25552;&#20986;&#20102;&#22810;&#31181;GANs&#30340;&#35774;&#35745;&#21644;&#20248;&#21270;&#26041;&#26696;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2005.00065</link><description>&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#32508;&#36848;&#65306;&#25361;&#25112;&#65292;&#35299;&#20915;&#26041;&#26696;&#21644;&#26410;&#26469;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative Adversarial Networks (GANs Survey): Challenges, Solutions, and Future Directions. (arXiv:2005.00065v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2005.00065
&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#26159;&#19968;&#31181;&#23398;&#20064;&#22797;&#26434;&#39640;&#32500;&#27010;&#29575;&#20998;&#24067;&#30340;&#26032;&#22411;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#20294;&#20854;&#35757;&#32451;&#23384;&#22312;&#30528;&#35832;&#22810;&#25361;&#25112;&#65292;&#22914;&#27169;&#24335;&#23849;&#28291;&#12289;&#19981;&#25910;&#25947;&#21450;&#19981;&#31283;&#23450;&#24615;&#12290;&#26368;&#36817;&#65292;&#38024;&#23545;&#36825;&#20123;&#25361;&#25112;&#65292;&#25552;&#20986;&#20102;&#22810;&#31181;GANs&#30340;&#35774;&#35745;&#21644;&#20248;&#21270;&#26041;&#26696;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#26159;&#19968;&#31181;&#26032;&#22411;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#26368;&#36817;&#24341;&#36215;&#20102;&#30456;&#24403;&#22810;&#30340;&#20851;&#27880;&#12290;GANs&#21487;&#20197;&#38544;&#24335;&#22320;&#23398;&#20064;&#22270;&#20687;&#65292;&#38899;&#39057;&#21644;&#25968;&#25454;&#20013;&#30340;&#22797;&#26434;&#39640;&#32500;&#20998;&#24067;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#32593;&#32476;&#32467;&#26500;&#30340;&#19981;&#24403;&#35774;&#35745;&#65292;&#30446;&#26631;&#20989;&#25968;&#30340;&#20351;&#29992;&#21644;&#20248;&#21270;&#31639;&#27861;&#30340;&#36873;&#25321;&#65292;GANs&#30340;&#35757;&#32451;&#23384;&#22312;&#30528;&#20027;&#35201;&#30340;&#25361;&#25112;&#65292;&#22914;&#27169;&#24335;&#23849;&#28291;&#65292;&#19981;&#25910;&#25947;&#21644;&#19981;&#31283;&#23450;&#24615;&#12290;&#26368;&#36817;&#65292;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#22522;&#20110;&#37325;&#26032;&#35774;&#35745;&#30340;&#32593;&#32476;&#26550;&#26500;&#65292;&#26032;&#30340;&#30446;&#26631;&#20989;&#25968;&#21644;&#26367;&#20195;&#20248;&#21270;&#31639;&#27861;&#30340;&#25216;&#26415;&#65292;&#25552;&#20986;&#20102;&#20960;&#31181;&#26356;&#22909;&#30340;GANs&#35774;&#35745;&#21644;&#20248;&#21270;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#30446;&#21069;&#36824;&#27809;&#26377;&#19968;&#31687;&#19987;&#38376;&#20851;&#27880;&#36825;&#20123;&#35299;&#20915;&#26041;&#26696;&#30340;&#24191;&#27867;&#21644;&#31995;&#32479;&#30340;&#32508;&#36848;&#30740;&#31350;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23545;GANs&#35774;&#35745;&#21644;&#20248;&#21270;&#35299;&#20915;&#26041;&#26696;&#30340;&#21457;&#23637;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#35843;&#26597;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative Adversarial Networks (GANs) is a novel class of deep generative models which has recently gained significant attention. GANs learns complex and high-dimensional distributions implicitly over images, audio, and data. However, there exists major challenges in training of GANs, i.e., mode collapse, non-convergence and instability, due to inappropriate design of network architecture, use of objective function and selection of optimization algorithm. Recently, to address these challenges, several solutions for better design and optimization of GANs have been investigated based on techniques of re-engineered network architectures, new objective functions and alternative optimization algorithms. To the best of our knowledge, there is no existing survey that has particularly focused on broad and systematic developments of these solutions. In this study, we perform a comprehensive survey of the advancements in GANs design and optimization solutions proposed to handle GANs challenges.
&lt;/p&gt;</description></item></channel></rss>