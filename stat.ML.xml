<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#25216;&#26415;&#65292;&#31216;&#20026;&#33258;&#25105;&#23545;&#25239;&#24494;&#35843;&#25193;&#25955;&#27169;&#22411;&#65288;SPIN-Diffusion&#65289;&#65292;&#36890;&#36807;&#25193;&#25955;&#27169;&#22411;&#19982;&#20854;&#20808;&#21069;&#29256;&#26412;&#30340;&#31454;&#20105;&#65292;&#23454;&#29616;&#20102;&#36880;&#27493;&#33258;&#25105;&#25913;&#36827;&#36807;&#31243;&#12290;</title><link>https://arxiv.org/abs/2402.10210</link><description>&lt;p&gt;
&#33258;&#25105;&#23545;&#25239;&#24494;&#35843;&#25193;&#25955;&#27169;&#22411;&#29992;&#20110;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Self-Play Fine-Tuning of Diffusion Models for Text-to-Image Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10210
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#25216;&#26415;&#65292;&#31216;&#20026;&#33258;&#25105;&#23545;&#25239;&#24494;&#35843;&#25193;&#25955;&#27169;&#22411;&#65288;SPIN-Diffusion&#65289;&#65292;&#36890;&#36807;&#25193;&#25955;&#27169;&#22411;&#19982;&#20854;&#20808;&#21069;&#29256;&#26412;&#30340;&#31454;&#20105;&#65292;&#23454;&#29616;&#20102;&#36880;&#27493;&#33258;&#25105;&#25913;&#36827;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24494;&#35843;&#25193;&#25955;&#27169;&#22411;&#22312;&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#34987;&#20805;&#20998;&#25506;&#32034;&#30340;&#21069;&#27839;&#65292;&#23588;&#20854;&#26159;&#19982;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24494;&#35843;&#26041;&#38754;&#21462;&#24471;&#30340;&#26174;&#33879;&#36827;&#23637;&#30456;&#27604;&#12290;&#23613;&#31649;&#29616;&#22312;&#30340;&#20808;&#36827;&#25193;&#25955;&#27169;&#22411;&#22914;&#31283;&#23450;&#25193;&#25955;&#65288;SD&#65289;&#21644;SDXL&#20381;&#36182;&#20110;&#30417;&#30563;&#24494;&#35843;&#65292;&#20294;&#23427;&#20204;&#30340;&#24615;&#33021;&#22312;&#35266;&#23519;&#21040;&#19968;&#23450;&#25968;&#37327;&#30340;&#25968;&#25454;&#21518;&#24517;&#28982;&#20250;&#36798;&#21040;&#29942;&#39048;&#12290;&#26368;&#36817;&#65292;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#34987;&#24212;&#29992;&#20110;&#36890;&#36807;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#23545;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#65292;&#20294;&#27599;&#20010;&#25991;&#26412;&#25552;&#31034;&#38656;&#35201;&#33267;&#23569;&#20004;&#20010;&#22270;&#20687;&#65288;&#8220;&#33719;&#32988;&#32773;&#8221;&#21644;&#8220;&#22833;&#36133;&#32773;&#8221;&#22270;&#20687;&#65289;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#25216;&#26415;&#65292;&#31216;&#20026;&#33258;&#25105;&#23545;&#25239;&#24494;&#35843;&#25193;&#25955;&#27169;&#22411;&#65288;SPIN-Diffusion&#65289;&#65292;&#20854;&#20013;&#25193;&#25955;&#27169;&#22411;&#19982;&#20854;&#20808;&#21069;&#29256;&#26412;&#36827;&#34892;&#31454;&#20105;&#65292;&#20419;&#36827;&#20102;&#19968;&#20010;&#36845;&#20195;&#30340;&#33258;&#25105;&#25913;&#36827;&#36807;&#31243;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#26367;&#20195;&#20256;&#32479;&#30417;&#30563;&#24494;&#35843;&#21644;RL&#31574;&#30053;&#30340;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10210v1 Announce Type: cross  Abstract: Fine-tuning Diffusion Models remains an underexplored frontier in generative artificial intelligence (GenAI), especially when compared with the remarkable progress made in fine-tuning Large Language Models (LLMs). While cutting-edge diffusion models such as Stable Diffusion (SD) and SDXL rely on supervised fine-tuning, their performance inevitably plateaus after seeing a certain volume of data. Recently, reinforcement learning (RL) has been employed to fine-tune diffusion models with human preference data, but it requires at least two images ("winner" and "loser" images) for each text prompt. In this paper, we introduce an innovative technique called self-play fine-tuning for diffusion models (SPIN-Diffusion), where the diffusion model engages in competition with its earlier versions, facilitating an iterative self-improvement process. Our approach offers an alternative to conventional supervised fine-tuning and RL strategies, signific
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Transformer&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#23616;&#38480;&#24615;&#65292;&#21457;&#29616;&#20854;&#27880;&#24847;&#21147;&#26426;&#21046;&#26159;&#27867;&#21270;&#33021;&#21147;&#19981;&#36275;&#30340;&#21407;&#22240;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#27973;&#23618;&#36731;&#37327;&#32423;&#30340;Transformer&#27169;&#22411;SAMformer&#65292;&#36890;&#36807;&#38160;&#24230;&#24863;&#30693;&#20248;&#21270;&#36991;&#20813;&#20102;&#38519;&#20837;&#22351;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#65292;&#24182;&#22312;&#24120;&#29992;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#19978;&#36229;&#36807;&#20102;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;TSMixer&#12290;</title><link>https://arxiv.org/abs/2402.10198</link><description>&lt;p&gt;
&#20351;&#29992;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#21644;&#36890;&#36947;&#27880;&#24847;&#21147;&#35299;&#38145;Transformer&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;
Unlocking the Potential of Transformers in Time Series Forecasting with Sharpness-Aware Minimization and Channel-Wise Attention
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10198
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Transformer&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#23616;&#38480;&#24615;&#65292;&#21457;&#29616;&#20854;&#27880;&#24847;&#21147;&#26426;&#21046;&#26159;&#27867;&#21270;&#33021;&#21147;&#19981;&#36275;&#30340;&#21407;&#22240;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#27973;&#23618;&#36731;&#37327;&#32423;&#30340;Transformer&#27169;&#22411;SAMformer&#65292;&#36890;&#36807;&#38160;&#24230;&#24863;&#30693;&#20248;&#21270;&#36991;&#20813;&#20102;&#38519;&#20837;&#22351;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#65292;&#24182;&#22312;&#24120;&#29992;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#19978;&#36229;&#36807;&#20102;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;TSMixer&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer&#26550;&#26500;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#35745;&#31639;&#26426;&#35270;&#35273;&#20013;&#21462;&#24471;&#20102;&#31361;&#30772;&#24615;&#30340;&#24615;&#33021;&#65292;&#20294;&#22312;&#22810;&#20803;&#38271;&#26399;&#39044;&#27979;&#26041;&#38754;&#65292;&#23427;&#20204;&#20173;&#28982;&#19981;&#22914;&#26356;&#31616;&#21333;&#30340;&#32447;&#24615;&#22522;&#32447;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;&#36825;&#19968;&#29616;&#35937;&#65292;&#25105;&#20204;&#39318;&#20808;&#30740;&#31350;&#20102;&#19968;&#20010;&#29609;&#20855;&#32447;&#24615;&#39044;&#27979;&#38382;&#39064;&#65292;&#23637;&#31034;&#20102;&#23613;&#31649;Transformer&#20855;&#26377;&#39640;&#34920;&#36798;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#26080;&#27861;&#25910;&#25947;&#21040;&#30495;&#27491;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#30830;&#23450;Transformer&#30340;&#27880;&#24847;&#21147;&#26159;&#36896;&#25104;&#20854;&#20302;&#27867;&#21270;&#33021;&#21147;&#30340;&#21407;&#22240;&#12290;&#22522;&#20110;&#36825;&#19968;&#35748;&#35782;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#27973;&#23618;&#36731;&#37327;&#32423;&#30340;Transformer&#27169;&#22411;&#65292;&#22312;&#38160;&#24230;&#24863;&#30693;&#20248;&#21270;&#30340;&#24773;&#20917;&#19979;&#25104;&#21151;&#36991;&#20813;&#20102;&#22351;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#20010;&#32467;&#26524;&#36866;&#29992;&#20110;&#25152;&#26377;&#24120;&#29992;&#30340;&#23454;&#38469;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#12290;&#29305;&#21035;&#26159;&#65292;&#30456;&#27604;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;TSMixer&#65292;SAMformer&#30340;&#24179;&#22343;&#24615;&#33021;&#25552;&#39640;&#20102;14.33%&#65292;&#24182;&#19988;&#21442;&#25968;&#25968;&#37327;&#20943;&#23569;&#20102;&#32422;4&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10198v1 Announce Type: new  Abstract: Transformer-based architectures achieved breakthrough performance in natural language processing and computer vision, yet they remain inferior to simpler linear baselines in multivariate long-term forecasting. To better understand this phenomenon, we start by studying a toy linear forecasting problem for which we show that transformers are incapable of converging to their true solution despite their high expressive power. We further identify the attention of transformers as being responsible for this low generalization capacity. Building upon this insight, we propose a shallow lightweight transformer model that successfully escapes bad local minima when optimized with sharpness-aware optimization. We empirically demonstrate that this result extends to all commonly used real-world multivariate time series datasets. In particular, SAMformer surpasses the current state-of-the-art model TSMixer by 14.33% on average, while having ~4 times few
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#38750;&#32447;&#24615;&#23574;&#23792;&#21327;&#26041;&#24046;&#30697;&#38453;&#19982;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20449;&#21495;&#20256;&#25773;&#12290;&#36890;&#36807;&#23545;&#23574;&#23792;&#29305;&#24449;&#32467;&#26500;&#30340;&#23450;&#37327;&#25551;&#36848;&#65292;&#25581;&#31034;&#20102;&#36755;&#20837;&#25968;&#25454;&#20013;&#30340;&#20302;&#32500;&#20449;&#21495;&#32467;&#26500;&#22914;&#20309;&#32463;&#36807;&#31070;&#32463;&#32593;&#32476;&#30340;&#38544;&#34255;&#23618;&#20256;&#25773;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#20102;&#19968;&#31181;&#34920;&#31034;&#23398;&#20064;&#30340;&#31616;&#21333;&#24773;&#22659;&#65292;&#20854;&#20013;&#26435;&#37325;&#30697;&#38453;&#21457;&#23637;&#20986;&#19968;&#20010;&#31209;&#20026;&#19968;&#30340;&#20449;&#21495;&#20998;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.10127</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#23574;&#23792;&#21327;&#26041;&#24046;&#30697;&#38453;&#19982;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20449;&#21495;&#20256;&#25773;
&lt;/p&gt;
&lt;p&gt;
Nonlinear spiked covariance matrices and signal propagation in deep neural networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10127
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#38750;&#32447;&#24615;&#23574;&#23792;&#21327;&#26041;&#24046;&#30697;&#38453;&#19982;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20449;&#21495;&#20256;&#25773;&#12290;&#36890;&#36807;&#23545;&#23574;&#23792;&#29305;&#24449;&#32467;&#26500;&#30340;&#23450;&#37327;&#25551;&#36848;&#65292;&#25581;&#31034;&#20102;&#36755;&#20837;&#25968;&#25454;&#20013;&#30340;&#20302;&#32500;&#20449;&#21495;&#32467;&#26500;&#22914;&#20309;&#32463;&#36807;&#31070;&#32463;&#32593;&#32476;&#30340;&#38544;&#34255;&#23618;&#20256;&#25773;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#20102;&#19968;&#31181;&#34920;&#31034;&#23398;&#20064;&#30340;&#31616;&#21333;&#24773;&#22659;&#65292;&#20854;&#20013;&#26435;&#37325;&#30697;&#38453;&#21457;&#23637;&#20986;&#19968;&#20010;&#31209;&#20026;&#19968;&#30340;&#20449;&#21495;&#20998;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#26368;&#36817;&#30340;&#30740;&#31350;&#37117;&#30740;&#31350;&#20102;&#30001;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#32447;&#24615;&#29305;&#24449;&#26144;&#23556;&#23450;&#20041;&#30340;&#20849;&#36717;&#26680;&#65288;CK&#65289;&#30340;&#29305;&#24449;&#20540;&#35889;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#32467;&#26524;&#21482;&#33021;&#24314;&#31435;&#32463;&#39564;&#29305;&#24449;&#20540;&#20998;&#24067;&#30340;&#24369;&#25910;&#25947;&#24615;&#65292;&#24182;&#27809;&#26377;&#25552;&#20379;&#23545;&#36890;&#24120;&#25429;&#25417;&#23398;&#20064;&#38382;&#39064;&#30340;&#20302;&#32500;&#20449;&#21495;&#32467;&#26500;&#30340;&#8220;&#23574;&#23792;&#8221;&#29305;&#24449;&#20540;&#21644;&#29305;&#24449;&#21521;&#37327;&#30340;&#31934;&#30830;&#23450;&#37327;&#25551;&#36848;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23545;&#38750;&#32447;&#24615;&#29256;&#26412;&#30340;&#23574;&#23792;&#21327;&#26041;&#24046;&#27169;&#22411;&#65288;&#21253;&#25324;CK&#20316;&#20026;&#29305;&#20363;&#65289;&#36827;&#34892;&#20102;&#36825;&#20123;&#20449;&#21495;&#29305;&#24449;&#20540;&#21644;&#29305;&#24449;&#21521;&#37327;&#30340;&#34920;&#24449;&#12290;&#21033;&#29992;&#36825;&#20010;&#19968;&#33324;&#32467;&#26524;&#65292;&#25105;&#20204;&#23450;&#37327;&#25551;&#36848;&#20102;&#36755;&#20837;&#25968;&#25454;&#20013;&#30340;&#23574;&#23792;&#29305;&#24449;&#32467;&#26500;&#22914;&#20309;&#36890;&#36807;&#20855;&#26377;&#38543;&#26426;&#26435;&#37325;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#38544;&#34255;&#23618;&#20256;&#25773;&#12290;&#20316;&#20026;&#31532;&#20108;&#20010;&#24212;&#29992;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#34920;&#31034;&#23398;&#20064;&#30340;&#19968;&#20010;&#31616;&#21333;&#24773;&#22659;&#65292;&#20854;&#20013;&#26435;&#37325;&#30697;&#38453;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#21457;&#23637;&#20986;&#19968;&#20010;&#31209;&#20026;&#19968;&#30340;&#20449;&#21495;&#20998;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10127v1 Announce Type: cross  Abstract: Many recent works have studied the eigenvalue spectrum of the Conjugate Kernel (CK) defined by the nonlinear feature map of a feedforward neural network. However, existing results only establish weak convergence of the empirical eigenvalue distribution, and fall short of providing precise quantitative characterizations of the ''spike'' eigenvalues and eigenvectors that often capture the low-dimensional signal structure of the learning problem. In this work, we characterize these signal eigenvalues and eigenvectors for a nonlinear version of the spiked covariance model, including the CK as a special case. Using this general result, we give a quantitative description of how spiked eigenstructure in the input data propagates through the hidden layers of a neural network with random weights. As a second application, we study a simple regime of representation learning where the weight matrix develops a rank-one signal component over trainin
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#27599;&#20010;&#25968;&#25454;&#28857;&#30340;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#65292;&#37327;&#21270;&#20102;&#27599;&#20010;&#25968;&#25454;&#28857;&#30340;&#25104;&#21592;&#27844;&#38706;&#65292;&#24182;&#35780;&#20272;&#20102;&#20004;&#31181;&#38544;&#31169;&#38450;&#24481;&#25514;&#26045;&#30340;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.10065</link><description>&lt;p&gt;
&#27599;&#20010;&#25968;&#25454;&#28857;&#27844;&#38706;&#24744;&#38544;&#31169;&#30340;&#31243;&#24230;&#26377;&#22810;&#22823;&#65311;&#37327;&#21270;&#27599;&#20010;&#25968;&#25454;&#28857;&#30340;&#25104;&#21592;&#27844;&#38706;
&lt;/p&gt;
&lt;p&gt;
How Much Does Each Datapoint Leak Your Privacy? Quantifying the Per-datum Membership Leakage
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10065
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#27599;&#20010;&#25968;&#25454;&#28857;&#30340;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#65292;&#37327;&#21270;&#20102;&#27599;&#20010;&#25968;&#25454;&#28857;&#30340;&#25104;&#21592;&#27844;&#38706;&#65292;&#24182;&#35780;&#20272;&#20102;&#20004;&#31181;&#38544;&#31169;&#38450;&#24481;&#25514;&#26045;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#27599;&#20010;&#25968;&#25454;&#28857;&#30340;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#65288;MIAs&#65289;&#65292;&#20854;&#20013;&#25915;&#20987;&#32773;&#26088;&#22312;&#25512;&#26029;&#20986;&#19968;&#20010;&#22266;&#23450;&#30446;&#26631;&#25968;&#25454;&#26159;&#21542;&#24050;&#21253;&#21547;&#22312;&#31639;&#27861;&#30340;&#36755;&#20837;&#25968;&#25454;&#38598;&#20013;&#65292;&#20174;&#32780;&#20405;&#29359;&#38544;&#31169;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23450;&#20041;&#27599;&#20010;&#25968;&#25454;&#28857;&#30340;&#25104;&#21592;&#27844;&#38706;&#20026;&#26368;&#20248;&#23545;&#25163;&#36776;&#35782;&#23427;&#30340;&#20248;&#21183;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#37327;&#21270;&#20102;&#32463;&#39564;&#22343;&#20540;&#30340;&#27599;&#20010;&#25968;&#25454;&#28857;&#30340;&#25104;&#21592;&#27844;&#38706;&#65292;&#24182;&#34920;&#26126;&#23427;&#21462;&#20915;&#20110;&#30446;&#26631;&#25968;&#25454;&#28857;&#21644;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#20043;&#38388;&#30340;&#39532;&#27663;&#36317;&#31163;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35780;&#20272;&#20102;&#20004;&#31181;&#38544;&#31169;&#38450;&#24481;&#25514;&#26045;&#30340;&#25928;&#26524;&#65292;&#21363;&#28155;&#21152;&#39640;&#26031;&#22122;&#22768;&#21644;&#23376;&#37319;&#26679;&#12290;&#25105;&#20204;&#20934;&#30830;&#22320;&#37327;&#21270;&#20102;&#23427;&#20204;&#37117;&#22914;&#20309;&#38477;&#20302;&#27599;&#20010;&#25968;&#25454;&#28857;&#30340;&#25104;&#21592;&#27844;&#38706;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#24314;&#31435;&#22312;&#19968;&#20010;&#32467;&#21512;&#20102;&#20284;&#28982;&#27604;&#26816;&#39564;&#30340;Edgeworth&#23637;&#24320;&#21644;Lindeberg-Feller&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#30340;&#26032;&#22411;&#35777;&#26126;&#25216;&#26415;&#19978;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#36830;&#25509;&#20102;&#29616;&#26377;&#30340;&#20284;&#28982;&#27604;&#21644;&#26631;&#37327;&#20056;&#31215;&#25915;&#20987;&#65292;&#24182;&#23545;&#36825;&#20123;&#25915;&#20987;&#36827;&#34892;&#20102;&#35770;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10065v1 Announce Type: new  Abstract: We study the per-datum Membership Inference Attacks (MIAs), where an attacker aims to infer whether a fixed target datum has been included in the input dataset of an algorithm and thus, violates privacy. First, we define the membership leakage of a datum as the advantage of the optimal adversary targeting to identify it. Then, we quantify the per-datum membership leakage for the empirical mean, and show that it depends on the Mahalanobis distance between the target datum and the data-generating distribution. We further assess the effect of two privacy defences, i.e. adding Gaussian noise and sub-sampling. We quantify exactly how both of them decrease the per-datum membership leakage. Our analysis builds on a novel proof technique that combines an Edgeworth expansion of the likelihood ratio test and a Lindeberg-Feller central limit theorem. Our analysis connects the existing likelihood ratio and scalar product attacks, and also justifies 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35782;&#21035;&#26410;&#30693;&#20998;&#24067;&#30340;&#26368;&#20248;&#21442;&#25968;&#21644;&#31070;&#32463;&#20803;&#21098;&#26525;&#26041;&#27861;&#65288;OPNP&#65289;&#65292;&#36890;&#36807;&#35780;&#20272;&#27169;&#22411;&#21442;&#25968;&#21644;&#31070;&#32463;&#20803;&#30340;&#25935;&#24863;&#24615;&#26469;&#35299;&#20915;OOD&#26816;&#27979;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.10062</link><description>&lt;p&gt;
&#29992;&#20110;&#35782;&#21035;&#26410;&#30693;&#20998;&#24067;&#30340;&#26368;&#20248;&#21442;&#25968;&#21644;&#31070;&#32463;&#20803;&#21098;&#26525;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Optimal Parameter and Neuron Pruning for Out-of-Distribution Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10062
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35782;&#21035;&#26410;&#30693;&#20998;&#24067;&#30340;&#26368;&#20248;&#21442;&#25968;&#21644;&#31070;&#32463;&#20803;&#21098;&#26525;&#26041;&#27861;&#65288;OPNP&#65289;&#65292;&#36890;&#36807;&#35780;&#20272;&#27169;&#22411;&#21442;&#25968;&#21644;&#31070;&#32463;&#20803;&#30340;&#25935;&#24863;&#24615;&#26469;&#35299;&#20915;OOD&#26816;&#27979;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#22312;&#29616;&#23454;&#22330;&#26223;&#20013;&#37096;&#32626;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#35782;&#21035;&#26410;&#30693;&#20998;&#24067;&#65288;OOD&#65289;&#26679;&#26412;&#30340;&#33021;&#21147;&#26159;&#19981;&#21487;&#25110;&#32570;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#22823;&#22810;&#25968;&#24050;&#26377;&#30340;OOD&#26816;&#27979;&#26041;&#27861;&#20851;&#27880;&#20110;&#25506;&#32034;&#39640;&#32423;&#35757;&#32451;&#25216;&#24039;&#25110;&#35757;&#32451;&#26080;&#20851;&#30340;&#25216;&#24039;&#65292;&#20197;&#38450;&#27490;&#27169;&#22411;&#23545;&#26410;&#30693;&#26679;&#26412;&#20135;&#29983;&#36807;&#20110;&#33258;&#20449;&#30340;&#32622;&#20449;&#24230;&#20998;&#25968;&#12290;&#22522;&#20110;&#35757;&#32451;&#30340;&#26041;&#27861;&#38656;&#35201;&#26114;&#36149;&#30340;&#35757;&#32451;&#25104;&#26412;&#65292;&#24182;&#19988;&#20381;&#36182;&#20110;&#24182;&#38750;&#22987;&#32456;&#21487;&#29992;&#30340;OOD&#26679;&#26412;&#65292;&#32780;&#22823;&#22810;&#25968;&#22522;&#20110;&#35757;&#32451;&#26080;&#20851;&#30340;&#26041;&#27861;&#26080;&#27861;&#26377;&#25928;&#21033;&#29992;&#35757;&#32451;&#25968;&#25454;&#30340;&#20808;&#39564;&#20449;&#24687;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;OPNP&#65288;Optimal Parameter and Neuron Pruning&#65289;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#35782;&#21035;&#24182;&#21024;&#38500;&#23548;&#33268;&#36807;&#24230;&#25311;&#21512;&#30340;&#21442;&#25968;&#21644;&#31070;&#32463;&#20803;&#12290;&#20027;&#35201;&#26041;&#27861;&#20998;&#20026;&#20004;&#20010;&#27493;&#39588;&#12290;&#22312;&#31532;&#19968;&#27493;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#23545;&#25152;&#26377;&#35757;&#32451;&#26679;&#26412;&#36827;&#34892;&#26799;&#24230;&#24179;&#22343;&#26469;&#35780;&#20272;&#27169;&#22411;&#21442;&#25968;&#21644;&#31070;&#32463;&#20803;&#30340;&#25935;&#24863;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10062v1 Announce Type: new  Abstract: For a machine learning model deployed in real world scenarios, the ability of detecting out-of-distribution (OOD) samples is indispensable and challenging. Most existing OOD detection methods focused on exploring advanced training skills or training-free tricks to prevent the model from yielding overconfident confidence score for unknown samples. The training-based methods require expensive training cost and rely on OOD samples which are not always available, while most training-free methods can not efficiently utilize the prior information from the training data. In this work, we propose an \textbf{O}ptimal \textbf{P}arameter and \textbf{N}euron \textbf{P}runing (\textbf{OPNP}) approach, which aims to identify and remove those parameters and neurons that lead to over-fitting. The main method is divided into two steps. In the first step, we evaluate the sensitivity of the model parameters and neurons by averaging gradients over all train
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#39564;&#35777;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#20219;&#21153;&#24179;&#22343;&#26657;&#20934;&#24615;&#30340;&#26041;&#27861;&#65292;&#23558;&#26657;&#20934;&#35823;&#24046;&#19982;&#24179;&#22343;&#32477;&#23545;&#35823;&#24046;&#20043;&#38388;&#30340;&#24046;&#20540;&#21644;&#23558;&#24179;&#22343;&#24179;&#26041;z-&#20998;&#25968;&#19982;1&#36827;&#34892;&#27604;&#36739;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#21069;&#32773;&#23545;&#19981;&#30830;&#23450;&#24615;&#20998;&#24067;&#25935;&#24863;&#65292;&#32780;&#21518;&#32773;&#22312;&#35813;&#26041;&#38754;&#25552;&#20379;&#20102;&#26368;&#21487;&#38752;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.10043</link><description>&lt;p&gt;
&#22914;&#20309;&#39564;&#35777;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#20219;&#21153;&#30340;&#24179;&#22343;&#26657;&#20934;&#24615;&#65311;
&lt;/p&gt;
&lt;p&gt;
How to validate average calibration for machine learning regression tasks ?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10043
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#39564;&#35777;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#20219;&#21153;&#24179;&#22343;&#26657;&#20934;&#24615;&#30340;&#26041;&#27861;&#65292;&#23558;&#26657;&#20934;&#35823;&#24046;&#19982;&#24179;&#22343;&#32477;&#23545;&#35823;&#24046;&#20043;&#38388;&#30340;&#24046;&#20540;&#21644;&#23558;&#24179;&#22343;&#24179;&#26041;z-&#20998;&#25968;&#19982;1&#36827;&#34892;&#27604;&#36739;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#21069;&#32773;&#23545;&#19981;&#30830;&#23450;&#24615;&#20998;&#24067;&#25935;&#24863;&#65292;&#32780;&#21518;&#32773;&#22312;&#35813;&#26041;&#38754;&#25552;&#20379;&#20102;&#26368;&#21487;&#38752;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#20219;&#21153;&#30340;&#24179;&#22343;&#26657;&#20934;&#24615;&#21487;&#20197;&#36890;&#36807;&#20004;&#31181;&#26041;&#24335;&#36827;&#34892;&#27979;&#35797;&#12290;&#19968;&#31181;&#26041;&#24335;&#26159;&#23558;&#26657;&#20934;&#35823;&#24046;&#65288;CE&#65289;&#20272;&#35745;&#20026;&#24179;&#22343;&#32477;&#23545;&#35823;&#24046;&#65288;MSE&#65289;&#19982;&#24179;&#22343;&#26041;&#24046;&#65288;MV&#65289;&#25110;&#24179;&#22343;&#24179;&#26041;&#19981;&#30830;&#23450;&#24615;&#20043;&#38388;&#30340;&#24046;&#20540;&#12290;&#21478;&#19968;&#31181;&#26041;&#24335;&#26159;&#23558;&#24179;&#22343;&#24179;&#26041;z-&#20998;&#25968;&#25110;&#32553;&#25918;&#35823;&#24046;&#65288;ZMS&#65289;&#19982;1&#36827;&#34892;&#27604;&#36739;&#12290;&#20004;&#31181;&#26041;&#27861;&#21487;&#33021;&#24471;&#20986;&#19981;&#21516;&#30340;&#32467;&#35770;&#65292;&#27491;&#22914;&#26469;&#33258;&#26368;&#36817;&#30340;&#26426;&#22120;&#23398;&#20064;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#25991;&#29486;&#20013;&#30340;&#25968;&#25454;&#38598;&#38598;&#21512;&#25152;&#31034;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;CE&#23545;&#19981;&#30830;&#23450;&#24615;&#20998;&#24067;&#38750;&#24120;&#25935;&#24863;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#31163;&#32676;&#19981;&#30830;&#23450;&#24615;&#30340;&#23384;&#22312;&#65292;&#22240;&#27492;&#26080;&#27861;&#21487;&#38752;&#22320;&#29992;&#20110;&#26657;&#20934;&#27979;&#35797;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;ZMS&#32479;&#35745;&#37327;&#19981;&#20855;&#26377;&#36825;&#31181;&#25935;&#24863;&#24615;&#38382;&#39064;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#25552;&#20379;&#20102;&#26368;&#21487;&#38752;&#30340;&#26041;&#27861;&#12290;&#25991;&#31456;&#36824;&#35752;&#35770;&#20102;&#23545;&#26465;&#20214;&#26657;&#20934;&#39564;&#35777;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10043v1 Announce Type: cross  Abstract: Average calibration of the uncertainties of machine learning regression tasks can be tested in two ways. One way is to estimate the calibration error (CE) as the difference between the mean absolute error (MSE) and the mean variance (MV) or mean squared uncertainty. The alternative is to compare the mean squared z-scores or scaled errors (ZMS) to 1. Both approaches might lead to different conclusion, as illustrated on an ensemble of datasets from the recent machine learning uncertainty quantification literature. It is shown here that the CE is very sensitive to the distribution of uncertainties, and notably to the presence of outlying uncertainties, and that it cannot be used reliably for calibration testing. By contrast, the ZMS statistic does not present this sensitivity issue and offers the most reliable approach in this context. Implications for the validation of conditional calibration are discussed.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#31181;&#21033;&#29992;&#39044;&#35757;&#32451;&#25193;&#25955;&#27169;&#22411;&#30340;&#25193;&#25955;&#27748;&#26222;&#26862;&#37319;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22823;&#21160;&#20316;&#31354;&#38388;&#19979;&#36827;&#34892;&#39640;&#25928;&#30340;&#24773;&#22659;&#24378;&#21270;&#23398;&#20064;&#25506;&#32034;&#12290;&#23454;&#35777;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.10028</link><description>&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#19982;&#22823;&#21160;&#20316;&#31354;&#38388;&#24773;&#22659;&#24378;&#21270;&#23398;&#20064;&#30340;&#32467;&#21512;
&lt;/p&gt;
&lt;p&gt;
Diffusion Models Meet Contextual Bandits with Large Action Spaces
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10028
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#31181;&#21033;&#29992;&#39044;&#35757;&#32451;&#25193;&#25955;&#27169;&#22411;&#30340;&#25193;&#25955;&#27748;&#26222;&#26862;&#37319;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22823;&#21160;&#20316;&#31354;&#38388;&#19979;&#36827;&#34892;&#39640;&#25928;&#30340;&#24773;&#22659;&#24378;&#21270;&#23398;&#20064;&#25506;&#32034;&#12290;&#23454;&#35777;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#21160;&#20316;&#31354;&#38388;&#36739;&#22823;&#65292;&#26377;&#25928;&#30340;&#25506;&#32034;&#26159;&#24773;&#22659;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#12290;&#26412;&#25991;&#36890;&#36807;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#26469;&#25429;&#25417;&#21160;&#20316;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#35774;&#35745;&#20102;&#25193;&#25955;&#27748;&#26222;&#26862;&#37319;&#26679;&#65288;dTS&#65289;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#25506;&#32034;&#12290;&#25105;&#20204;&#20026;dTS&#26041;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#21644;&#31639;&#27861;&#22522;&#30784;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#35780;&#20272;&#23637;&#31034;&#20102;&#23427;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10028v1 Announce Type: cross  Abstract: Efficient exploration is a key challenge in contextual bandits due to the large size of their action space, where uninformed exploration can result in computational and statistical inefficiencies. Fortunately, the rewards of actions are often correlated and this can be leveraged to explore them efficiently. In this work, we capture such correlations using pre-trained diffusion models; upon which we design diffusion Thompson sampling (dTS). Both theoretical and algorithmic foundations are developed for dTS, and empirical evaluation also shows its favorable performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24182;&#34892;&#21270;&#33258;&#22238;&#24402;&#36807;&#31243;&#26469;&#21152;&#36895;&#25193;&#25955;&#27169;&#22411;&#30340;&#37319;&#26679;&#30340;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;ParaTAA&#65292;&#19968;&#31181;&#36890;&#29992;&#30340;&#24182;&#34892;&#37319;&#26679;&#31639;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#25512;&#29702;&#27493;&#39588;&#12290;</title><link>https://arxiv.org/abs/2402.09970</link><description>&lt;p&gt;
&#21152;&#36895;&#24182;&#34892;&#37319;&#26679;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Accelerating Parallel Sampling of Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09970
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24182;&#34892;&#21270;&#33258;&#22238;&#24402;&#36807;&#31243;&#26469;&#21152;&#36895;&#25193;&#25955;&#27169;&#22411;&#30340;&#37319;&#26679;&#30340;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;ParaTAA&#65292;&#19968;&#31181;&#36890;&#29992;&#30340;&#24182;&#34892;&#37319;&#26679;&#31639;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#25512;&#29702;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#24050;&#32463;&#25104;&#20026;&#22270;&#20687;&#29983;&#25104;&#30340;&#26368;&#20808;&#36827;&#29983;&#25104;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20854;&#37319;&#26679;&#36807;&#31243;&#20013;&#22266;&#26377;&#30340;&#33258;&#22238;&#24402;&#24615;&#36136;&#65292;&#20174;&#25193;&#25955;&#27169;&#22411;&#20013;&#36827;&#34892;&#37319;&#26679;&#36890;&#24120;&#32791;&#26102;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24182;&#34892;&#21270;&#33258;&#22238;&#24402;&#36807;&#31243;&#26469;&#21152;&#36895;&#25193;&#25955;&#27169;&#22411;&#30340;&#37319;&#26679;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23558;&#37319;&#26679;&#36807;&#31243;&#37325;&#26032;&#26500;&#24314;&#20026;&#36890;&#36807;&#22266;&#23450;&#28857;&#36845;&#20195;&#35299;&#20915;&#19977;&#35282;&#38750;&#32447;&#24615;&#26041;&#31243;&#32452;&#30340;&#36807;&#31243;&#12290;&#36890;&#36807;&#36825;&#31181;&#21019;&#26032;&#30340;&#20844;&#24335;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#19968;&#20123;&#31995;&#32479;&#21270;&#30340;&#25216;&#26415;&#65292;&#36827;&#19968;&#27493;&#20943;&#23569;&#20102;&#27714;&#35299;&#36807;&#31243;&#25152;&#38656;&#30340;&#36845;&#20195;&#27493;&#39588;&#12290;&#24212;&#29992;&#36825;&#20123;&#25216;&#26415;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;ParaTAA&#65292;&#19968;&#31181;&#36890;&#29992;&#30340;&#12289;&#26080;&#38656;&#35757;&#32451;&#30340;&#24182;&#34892;&#37319;&#26679;&#31639;&#27861;&#65292;&#21487;&#20197;&#21033;&#29992;&#39069;&#22806;&#30340;&#35745;&#31639;&#21644;&#20869;&#23384;&#36164;&#28304;&#26469;&#22686;&#21152;&#37319;&#26679;&#36895;&#24230;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;ParaTAA&#21487;&#20197;&#20943;&#23569;&#24120;&#35265;&#30340;&#39034;&#24207;&#37319;&#26679;&#25152;&#38656;&#30340;&#25512;&#29702;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09970v1 Announce Type: new  Abstract: Diffusion models have emerged as state-of-the-art generative models for image generation. However, sampling from diffusion models is usually time-consuming due to the inherent autoregressive nature of their sampling process. In this work, we propose a novel approach that accelerates the sampling of diffusion models by parallelizing the autoregressive process. Specifically, we reformulate the sampling process as solving a system of triangular nonlinear equations through fixed-point iteration. With this innovative formulation, we explore several systematic techniques to further reduce the iteration steps required by the solving process. Applying these techniques, we introduce ParaTAA, a universal and training-free parallel sampling algorithm that can leverage extra computational and memory resources to increase the sampling speed. Our experiments demonstrate that ParaTAA can decrease the inference steps required by common sequential sampli
&lt;/p&gt;</description></item><item><title>FedLion&#26159;&#19968;&#31181;&#33258;&#36866;&#24212;&#32852;&#37030;&#20248;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#38598;&#20013;&#24335;&#33258;&#36866;&#24212;&#31639;&#27861;Lion&#30340;&#20851;&#38190;&#20803;&#32032;&#65292;&#23454;&#29616;&#20102;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#26356;&#23569;&#30340;&#36890;&#20449;&#25104;&#26412;&#12290;&#32463;&#36807;&#24191;&#27867;&#35780;&#20272;&#65292;FedLion&#20248;&#20110;&#20043;&#21069;&#30340;&#26368;&#20808;&#36827;&#33258;&#36866;&#24212;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#26377;&#31526;&#21495;&#26799;&#24230;&#22312;&#26412;&#22320;&#35757;&#32451;&#20013;&#20943;&#23569;&#25968;&#25454;&#20256;&#36755;&#35201;&#27714;&#12290;</title><link>https://arxiv.org/abs/2402.09941</link><description>&lt;p&gt;
FedLion: &#26356;&#24555;&#30340;&#33258;&#36866;&#24212;&#32852;&#37030;&#20248;&#21270;&#31639;&#27861;&#65292;&#36890;&#20449;&#26356;&#23569;
&lt;/p&gt;
&lt;p&gt;
FedLion: Faster Adaptive Federated Optimization with Fewer Communication
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09941
&lt;/p&gt;
&lt;p&gt;
FedLion&#26159;&#19968;&#31181;&#33258;&#36866;&#24212;&#32852;&#37030;&#20248;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#38598;&#20013;&#24335;&#33258;&#36866;&#24212;&#31639;&#27861;Lion&#30340;&#20851;&#38190;&#20803;&#32032;&#65292;&#23454;&#29616;&#20102;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#26356;&#23569;&#30340;&#36890;&#20449;&#25104;&#26412;&#12290;&#32463;&#36807;&#24191;&#27867;&#35780;&#20272;&#65292;FedLion&#20248;&#20110;&#20043;&#21069;&#30340;&#26368;&#20808;&#36827;&#33258;&#36866;&#24212;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#26377;&#31526;&#21495;&#26799;&#24230;&#22312;&#26412;&#22320;&#35757;&#32451;&#20013;&#20943;&#23569;&#25968;&#25454;&#20256;&#36755;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#20013;&#65292;&#19968;&#31181;&#36328;&#20998;&#24067;&#24335;&#25968;&#25454;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#26694;&#26550;&#20013;&#65292;&#20687;FedAvg&#36825;&#26679;&#30340;&#30693;&#21517;&#31639;&#27861;&#24448;&#24448;&#20855;&#26377;&#36739;&#24930;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#23548;&#33268;&#39640;&#36890;&#20449;&#25104;&#26412;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;FedLion&#65292;&#19968;&#31181;&#33258;&#36866;&#24212;&#32852;&#37030;&#20248;&#21270;&#31639;&#27861;&#65292;&#26080;&#32541;&#22320;&#23558;&#26368;&#36817;&#25552;&#20986;&#30340;&#38598;&#20013;&#24335;&#33258;&#36866;&#24212;&#31639;&#27861;Lion&#65288;Chen et al. 2023&#65289;&#30340;&#20851;&#38190;&#20803;&#32032;&#34701;&#20837;&#21040;FL&#26694;&#26550;&#20013;&#12290;&#36890;&#36807;&#23545;&#20004;&#20010;&#24191;&#27867;&#37319;&#29992;&#30340;FL&#22522;&#20934;&#36827;&#34892;&#20840;&#38754;&#35780;&#20272;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;FedLion&#20248;&#20110;&#20043;&#21069;&#30340;&#26368;&#20808;&#36827;&#33258;&#36866;&#24212;&#31639;&#27861;&#65292;&#21253;&#25324;FAFED&#65288;Wu et al. 2023&#65289;&#21644;FedDA&#12290;&#27492;&#22806;&#65292;&#30001;&#20110;&#22312;&#26412;&#22320;&#35757;&#32451;&#20013;&#20351;&#29992;&#20102;&#26377;&#31526;&#21495;&#26799;&#24230;&#65292;&#19982;&#29616;&#26377;&#30340;&#33258;&#36866;&#24212;&#31639;&#27861;&#30456;&#27604;&#65292;FedLion&#22312;&#19978;&#34892;&#36890;&#20449;&#36807;&#31243;&#20013;&#22823;&#22823;&#38477;&#20302;&#20102;&#25968;&#25454;&#20256;&#36755;&#35201;&#27714;&#65292;&#36827;&#19968;&#27493;&#38477;&#20302;&#20102;&#36890;&#20449;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09941v1 Announce Type: cross  Abstract: In Federated Learning (FL), a framework to train machine learning models across distributed data, well-known algorithms like FedAvg tend to have slow convergence rates, resulting in high communication costs during training. To address this challenge, we introduce FedLion, an adaptive federated optimization algorithm that seamlessly incorporates key elements from the recently proposed centralized adaptive algorithm, Lion (Chen et al. 2o23), into the FL framework. Through comprehensive evaluations on two widely adopted FL benchmarks, we demonstrate that FedLion outperforms previous state-of-the-art adaptive algorithms, including FAFED (Wu et al. 2023) and FedDA. Moreover, thanks to the use of signed gradients in local training, FedLion substantially reduces data transmission requirements during uplink communication when compared to existing adaptive algorithms, further reducing communication costs. Last but not least, this work also incl
&lt;/p&gt;</description></item><item><title>&#22240;&#26524;&#29305;&#24449;&#19981;&#33021;&#26356;&#22909;&#22320;&#25512;&#24191;&#21040;&#26032;&#39046;&#22495;&#65292;&#39044;&#27979;&#22120;&#20351;&#29992;&#25152;&#26377;&#29305;&#24449;&#30340;&#25928;&#26524;&#26356;&#22909;&#12290;</title><link>https://arxiv.org/abs/2402.09891</link><description>&lt;p&gt;
&#39044;&#27979;&#22240;&#26524;&#29305;&#24449;&#19981;&#33021;&#26356;&#22909;&#22320;&#25512;&#24191;&#21040;&#26032;&#39046;&#22495;
&lt;/p&gt;
&lt;p&gt;
Predictors from causal features do not generalize better to new domains
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09891
&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#29305;&#24449;&#19981;&#33021;&#26356;&#22909;&#22320;&#25512;&#24191;&#21040;&#26032;&#39046;&#22495;&#65292;&#39044;&#27979;&#22120;&#20351;&#29992;&#25152;&#26377;&#29305;&#24449;&#30340;&#25928;&#26524;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#19981;&#21516;&#39046;&#22495;&#20013;&#65292;&#22522;&#20110;&#22240;&#26524;&#29305;&#24449;&#35757;&#32451;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#27867;&#21270;&#25928;&#26524;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#28085;&#30422;&#20581;&#24247;&#12289;&#23601;&#19994;&#12289;&#25945;&#32946;&#12289;&#31038;&#20250;&#31119;&#21033;&#21644;&#25919;&#27835;&#31561;&#24212;&#29992;&#30340;16&#20010;&#34920;&#26684;&#25968;&#25454;&#38598;&#30340;&#39044;&#27979;&#20219;&#21153;&#12290;&#27599;&#20010;&#25968;&#25454;&#38598;&#37117;&#26377;&#22810;&#20010;&#39046;&#22495;&#65292;&#25105;&#20204;&#21487;&#20197;&#27979;&#35797;&#19968;&#20010;&#22312;&#19968;&#20010;&#39046;&#22495;&#35757;&#32451;&#30340;&#27169;&#22411;&#22312;&#21478;&#19968;&#20010;&#39046;&#22495;&#30340;&#34920;&#29616;&#12290;&#23545;&#20110;&#27599;&#20010;&#39044;&#27979;&#20219;&#21153;&#65292;&#25105;&#20204;&#36873;&#25321;&#23545;&#39044;&#27979;&#30446;&#26631;&#26377;&#22240;&#26524;&#24433;&#21709;&#30340;&#29305;&#24449;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#27979;&#35797;&#22522;&#20110;&#22240;&#26524;&#29305;&#24449;&#35757;&#32451;&#30340;&#27169;&#22411;&#26159;&#21542;&#22312;&#19981;&#21516;&#39046;&#22495;&#20013;&#26356;&#22909;&#22320;&#27867;&#21270;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#26080;&#35770;&#26159;&#21542;&#20855;&#26377;&#22240;&#26524;&#20851;&#31995;&#65292;&#20351;&#29992;&#25152;&#26377;&#21487;&#29992;&#29305;&#24449;&#30340;&#39044;&#27979;&#22120;&#37117;&#27604;&#20351;&#29992;&#22240;&#26524;&#29305;&#24449;&#30340;&#39044;&#27979;&#22120;&#22312;&#39046;&#22495;&#20869;&#22806;&#30340;&#20934;&#30830;&#24615;&#26356;&#39640;&#12290;&#32780;&#19988;&#65292;&#21363;&#20351;&#26159;&#20174;&#19968;&#20010;&#39046;&#22495;&#21040;&#21478;&#19968;&#20010;&#39046;&#22495;&#30340;&#20934;&#30830;&#24615;&#32477;&#23545;&#19979;&#38477;&#23545;&#20110;&#22240;&#26524;&#39044;&#27979;&#22120;&#26469;&#35828;&#20063;&#19981;&#27604;&#20351;&#29992;&#25152;&#26377;&#29305;&#24449;&#30340;&#27169;&#22411;&#26356;&#22909;&#12290;&#22914;&#26524;&#30446;&#26631;&#26159;&#22312;&#26032;&#39046;&#22495;&#20013;&#27867;&#21270;&#65292;&#23454;&#36341;&#20013;&#20351;&#29992;&#25152;&#26377;&#29305;&#24449;&#30340;&#39044;&#27979;&#22120;&#25928;&#26524;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09891v1 Announce Type: new  Abstract: We study how well machine learning models trained on causal features generalize across domains. We consider 16 prediction tasks on tabular datasets covering applications in health, employment, education, social benefits, and politics. Each dataset comes with multiple domains, allowing us to test how well a model trained in one domain performs in another. For each prediction task, we select features that have a causal influence on the target of prediction. Our goal is to test the hypothesis that models trained on causal features generalize better across domains. Without exception, we find that predictors using all available features, regardless of causality, have better in-domain and out-of-domain accuracy than predictors using causal features. Moreover, even the absolute drop in accuracy from one domain to the other is no better for causal predictors than for models that use all features. If the goal is to generalize to new domains, prac
&lt;/p&gt;</description></item><item><title>&#23545;&#20110;&#22522;&#20934;&#32447;&#21644;&#22522;&#20934;&#27979;&#35797;&#36817;&#20284;&#39640;&#26031;&#36807;&#31243;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#27604;&#26041;&#27861;&#30340;&#24314;&#35758;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#35757;&#32451;&#31243;&#24207;&#65292;&#35813;&#31243;&#24207;&#19981;&#38656;&#35201;&#29992;&#25143;&#36873;&#25321;&#65292;&#24182;&#19988;&#35777;&#26126;&#36825;&#26159;&#19968;&#20010;&#31526;&#21512;&#35201;&#27714;&#30340;&#24378;&#22823;&#22522;&#20934;&#12290;</title><link>https://arxiv.org/abs/2402.09849</link><description>&lt;p&gt;
&#23545;&#20110;&#22522;&#20934;&#32447;&#21644;&#22522;&#20934;&#27979;&#35797;&#36817;&#20284;&#39640;&#26031;&#36807;&#31243;&#30340;&#24314;&#35758;
&lt;/p&gt;
&lt;p&gt;
Recommendations for Baselines and Benchmarking Approximate Gaussian Processes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09849
&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#22522;&#20934;&#32447;&#21644;&#22522;&#20934;&#27979;&#35797;&#36817;&#20284;&#39640;&#26031;&#36807;&#31243;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#27604;&#26041;&#27861;&#30340;&#24314;&#35758;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#35757;&#32451;&#31243;&#24207;&#65292;&#35813;&#31243;&#24207;&#19981;&#38656;&#35201;&#29992;&#25143;&#36873;&#25321;&#65292;&#24182;&#19988;&#35777;&#26126;&#36825;&#26159;&#19968;&#20010;&#31526;&#21512;&#35201;&#27714;&#30340;&#24378;&#22823;&#22522;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Gaussian processes (GPs)&#26159;&#26426;&#22120;&#23398;&#20064;&#24037;&#20855;&#31665;&#20013;&#25104;&#29087;&#19988;&#24191;&#27867;&#20351;&#29992;&#30340;&#32452;&#20214;&#12290;&#23427;&#20204;&#20855;&#26377;&#33258;&#21160;&#36229;&#21442;&#25968;&#36873;&#25321;&#30340;&#20248;&#28857;&#65292;&#21487;&#20197;&#23454;&#29616;&#26080;&#38656;&#29992;&#25143;&#24178;&#39044;&#30340;&#35757;&#32451;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#29616;&#23454;&#24773;&#20917;&#19979;&#65292;&#36890;&#24120;&#38656;&#35201;&#20351;&#29992;&#36817;&#20284;&#26041;&#27861;&#65292;&#32780;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#38656;&#35201;&#35843;&#25972;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#36825;&#31181;&#35843;&#25972;&#35201;&#27714;&#20351;&#24471;&#35780;&#20272;&#21464;&#24471;&#22797;&#26434;&#65292;&#36825;&#23548;&#33268;&#32570;&#20047;&#23545;&#22312;&#21738;&#31181;&#24773;&#20917;&#19979;&#20351;&#29992;&#21738;&#31181;&#26041;&#27861;&#30340;&#26126;&#30830;&#24314;&#35758;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#27604;GP&#36817;&#20284;&#26041;&#27861;&#30340;&#24314;&#35758;&#65292;&#22522;&#20110;&#29992;&#25143;&#23545;&#26041;&#27861;&#30340;&#26399;&#26395;&#30340;&#35268;&#33539;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#35757;&#32451;&#31243;&#24207;&#65292;&#29992;&#20110;Titsias [2009]&#30340;&#21464;&#20998;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#19981;&#38656;&#35201;&#29992;&#25143;&#36873;&#25321;&#65292;&#24182;&#19988;&#35777;&#26126;&#36825;&#26159;&#31526;&#21512;&#25105;&#20204;&#35268;&#33539;&#30340;&#19968;&#20010;&#24378;&#22823;&#22522;&#20934;&#12290;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65292;&#25353;&#29031;&#25105;&#20204;&#30340;&#24314;&#35758;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#21487;&#20197;&#26356;&#28165;&#26224;&#22320;&#20102;&#35299;&#24403;&#21069;&#39046;&#22495;&#30340;&#29366;&#24577;&#65292;&#24182;&#21457;&#29616;&#8230;&#8230;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09849v1 Announce Type: new  Abstract: Gaussian processes (GPs) are a mature and widely-used component of the ML toolbox. One of their desirable qualities is automatic hyperparameter selection, which allows for training without user intervention. However, in many realistic settings, approximations are typically needed, which typically do require tuning. We argue that this requirement for tuning complicates evaluation, which has led to a lack of a clear recommendations on which method should be used in which situation. To address this, we make recommendations for comparing GP approximations based on a specification of what a user should expect from a method. In addition, we develop a training procedure for the variational method of Titsias [2009] that leaves no choices to the user, and show that this is a strong baseline that meets our specification. We conclude that benchmarking according to our suggestions gives a clearer view of the current state of the field, and uncovers 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#20449;&#36182;&#22495;&#31867;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#38750;&#20984;&#24378;&#20985;&#26368;&#23567;&#26368;&#22823;&#38382;&#39064;&#65292;&#24182;&#21487;&#20197;&#22312;&#36845;&#20195;&#27425;&#25968;&#20026;$\mathcal{O}(\epsilon^{-1.5})$&#20869;&#25214;&#21040;&#20108;&#38454;&#31283;&#23450;&#28857;&#12290;</title><link>https://arxiv.org/abs/2402.09807</link><description>&lt;p&gt;
&#35299;&#20915;&#38750;&#20984;&#24378;&#20985;&#26368;&#23567;&#26368;&#22823;&#38382;&#39064;&#30340;&#20004;&#31181;&#20449;&#36182;&#22495;&#31867;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Two trust region type algorithms for solving nonconvex-strongly concave minimax problems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09807
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#20449;&#36182;&#22495;&#31867;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#38750;&#20984;&#24378;&#20985;&#26368;&#23567;&#26368;&#22823;&#38382;&#39064;&#65292;&#24182;&#21487;&#20197;&#22312;&#36845;&#20195;&#27425;&#25968;&#20026;$\mathcal{O}(\epsilon^{-1.5})$&#20869;&#25214;&#21040;&#20108;&#38454;&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35299;&#20915;&#38750;&#20984;&#24378;&#20985;&#26368;&#23567;&#26368;&#22823;&#38382;&#39064;&#30340;&#26368;&#23567;&#26368;&#22823;&#20449;&#36182;&#22495;&#65288;MINIMAX-TR&#65289;&#31639;&#27861;&#21644;&#20855;&#26377;&#25910;&#32553;&#21644;&#25193;&#24352;&#30340;&#26368;&#23567;&#26368;&#22823;&#20449;&#36182;&#22495;&#31639;&#27861;&#65288;MINIMAX-TRACE&#65289;&#12290;&#36825;&#20004;&#31181;&#31639;&#27861;&#21487;&#20197;&#22312;$\mathcal{O}(\epsilon^{-1.5})$&#27425;&#36845;&#20195;&#20869;&#25214;&#21040;$(\epsilon, \sqrt{\epsilon})$-&#20108;&#38454;&#31283;&#23450;&#28857;(SSP)&#65292;&#36825;&#19982;&#24050;&#30693;&#26368;&#22909;&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#30456;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09807v1 Announce Type: cross  Abstract: In this paper, we propose a Minimax Trust Region (MINIMAX-TR) algorithm and a Minimax Trust Region Algorithm with Contractions and Expansions(MINIMAX-TRACE) algorithm for solving nonconvex-strongly concave minimax problems. Both algorithms can find an $(\epsilon, \sqrt{\epsilon})$-second order stationary point(SSP) within $\mathcal{O}(\epsilon^{-1.5})$ iterations, which matches the best well known iteration complexity.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;"&#20934;&#21017;&#23849;&#28291;"&#30340;&#27010;&#24565;&#65292;&#21363;&#20248;&#21270;&#19968;&#20010;&#24230;&#37327;&#25351;&#26631;&#24847;&#21619;&#30528;&#21478;&#19968;&#20010;&#24230;&#37327;&#25351;&#26631;&#30340;&#26368;&#20248;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#21457;&#29616;&#65292;&#23545;&#20110;&#25439;&#22833;&#30340;&#20271;&#21162;&#21033;&#20998;&#24067;&#65292;CVaR&#21644;DRO&#30340;&#32467;&#26524;&#36828;&#36229;&#20986;&#29616;&#26377;&#30740;&#31350;&#65292;&#21516;&#26102;&#21457;&#29616;&#20102;&#19968;&#20123;&#29305;&#23450;&#26465;&#20214;&#19979;&#65292;&#21333;&#35843;&#20934;&#21017;&#22914;&#20542;&#26012;ERM&#26080;&#27861;&#36991;&#20813;&#23849;&#28291;&#65292;&#32780;&#38750;&#21333;&#35843;&#30340;&#26367;&#20195;&#26041;&#26696;&#21487;&#20197;&#12290;</title><link>https://arxiv.org/abs/2402.09802</link><description>&lt;p&gt;
&#20934;&#21017;&#23849;&#28291;&#21644;&#25439;&#22833;&#20998;&#24067;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Criterion collapse and loss distribution control
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09802
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;"&#20934;&#21017;&#23849;&#28291;"&#30340;&#27010;&#24565;&#65292;&#21363;&#20248;&#21270;&#19968;&#20010;&#24230;&#37327;&#25351;&#26631;&#24847;&#21619;&#30528;&#21478;&#19968;&#20010;&#24230;&#37327;&#25351;&#26631;&#30340;&#26368;&#20248;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#21457;&#29616;&#65292;&#23545;&#20110;&#25439;&#22833;&#30340;&#20271;&#21162;&#21033;&#20998;&#24067;&#65292;CVaR&#21644;DRO&#30340;&#32467;&#26524;&#36828;&#36229;&#20986;&#29616;&#26377;&#30740;&#31350;&#65292;&#21516;&#26102;&#21457;&#29616;&#20102;&#19968;&#20123;&#29305;&#23450;&#26465;&#20214;&#19979;&#65292;&#21333;&#35843;&#20934;&#21017;&#22914;&#20542;&#26012;ERM&#26080;&#27861;&#36991;&#20813;&#23849;&#28291;&#65292;&#32780;&#38750;&#21333;&#35843;&#30340;&#26367;&#20195;&#26041;&#26696;&#21487;&#20197;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;"&#20934;&#21017;&#23849;&#28291;"&#30340;&#27010;&#24565;&#65292;&#21363;&#20248;&#21270;&#19968;&#20010;&#24230;&#37327;&#25351;&#26631;&#24847;&#21619;&#30528;&#21478;&#19968;&#20010;&#24230;&#37327;&#25351;&#26631;&#30340;&#26368;&#20248;&#24615;&#65292;&#29305;&#21035;&#20851;&#27880;&#21508;&#31181;&#23398;&#20064;&#20934;&#21017;&#19979;&#23849;&#28291;&#25104;&#35823;&#24046;&#27010;&#29575;&#26368;&#23567;&#21270;&#22120;&#30340;&#26465;&#20214;&#65292;&#20174;DRO&#21644;OCE&#39118;&#38505;&#65288;CVaR&#12289;&#20542;&#26012;ERM&#65289;&#21040;&#25991;&#29486;&#20013;&#25506;&#32034;&#30340;&#26368;&#26032;&#19978;&#21319;-&#19979;&#38477;&#31639;&#27861;&#30340;&#38750;&#21333;&#35843;&#20934;&#21017;&#65288;&#27946;&#27700;&#12289;SoftAD&#65289;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#20271;&#21162;&#21033;&#20998;&#24067;&#25439;&#22833;&#30340;&#32972;&#26223;&#19979;&#65292;CVaR&#21644;DRO&#30340;&#29616;&#26377;&#32467;&#26524;&#36828;&#36828;&#36229;&#36234;&#20102;&#23849;&#28291;&#30340;&#33539;&#22260;&#65292;&#28982;&#21518;&#25193;&#22823;&#20102;&#25105;&#20204;&#30340;&#33539;&#22260;&#65292;&#21253;&#25324;&#20195;&#29702;&#25439;&#22833;&#65292;&#23637;&#31034;&#20102;&#20687;&#20542;&#26012;ERM&#36825;&#26679;&#30340;&#21333;&#35843;&#20934;&#21017;&#26080;&#27861;&#36991;&#20813;&#23849;&#28291;&#30340;&#26465;&#20214;&#65292;&#32780;&#38750;&#21333;&#35843;&#30340;&#26367;&#20195;&#26041;&#26696;&#21487;&#20197;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09802v1 Announce Type: cross  Abstract: In this work, we consider the notion of "criterion collapse," in which optimization of one metric implies optimality in another, with a particular focus on conditions for collapse into error probability minimizers under a wide variety of learning criteria, ranging from DRO and OCE risks (CVaR, tilted ERM) to non-monotonic criteria underlying recent ascent-descent algorithms explored in the literature (Flooding, SoftAD). We show how collapse in the context of losses with a Bernoulli distribution goes far beyond existing results for CVaR and DRO, then expand our scope to include surrogate losses, showing conditions where monotonic criteria such as tilted ERM cannot avoid collapse, whereas non-monotonic alternatives can.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;PSD&#27169;&#22411;&#30340;&#26032;&#22411;&#28388;&#27874;&#22120;&#65292;&#21487;&#20197;&#22312;&#36716;&#25442;&#21644;&#35266;&#27979;&#37117;&#26159;&#39640;&#26031;PSD&#27169;&#22411;&#26102;&#20197;&#38381;&#24335;&#24418;&#24335;&#39640;&#25928;&#22320;&#36827;&#34892;&#28388;&#27874;&#65292;&#24182;&#19988;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#20855;&#26377;&#24378;&#22823;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#36866;&#24212;&#36716;&#25442;&#27010;&#29575;&#30340;&#27491;&#21017;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.09796</link><description>&lt;p&gt;
&#38381;&#24335;&#28388;&#27874;&#22120;&#22312;&#38750;&#32447;&#24615;&#31995;&#32479;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Closed-form Filtering for Non-linear Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09796
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;PSD&#27169;&#22411;&#30340;&#26032;&#22411;&#28388;&#27874;&#22120;&#65292;&#21487;&#20197;&#22312;&#36716;&#25442;&#21644;&#35266;&#27979;&#37117;&#26159;&#39640;&#26031;PSD&#27169;&#22411;&#26102;&#20197;&#38381;&#24335;&#24418;&#24335;&#39640;&#25928;&#22320;&#36827;&#34892;&#28388;&#27874;&#65292;&#24182;&#19988;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#20855;&#26377;&#24378;&#22823;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#36866;&#24212;&#36716;&#25442;&#27010;&#29575;&#30340;&#27491;&#21017;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39034;&#24207;&#36125;&#21494;&#26031;&#28388;&#27874;&#26088;&#22312;&#20272;&#35745;&#38544;&#34255;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#30340;&#24403;&#21069;&#29366;&#24577;&#20998;&#24067;&#65292;&#32473;&#23450;&#36807;&#21435;&#30340;&#35266;&#27979;&#20540;&#12290;&#23545;&#20110;&#22823;&#22810;&#25968;&#24212;&#29992;&#39046;&#22495;&#26469;&#35828;&#65292;&#36825;&#20010;&#38382;&#39064;&#26159;&#38590;&#20197;&#35299;&#20915;&#30340;&#65292;&#38500;&#20102;&#20687;&#34920;&#26684;&#35774;&#32622;&#25110;&#20855;&#26377;&#39640;&#26031;&#22122;&#22768;&#30340;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#36825;&#26679;&#30340;&#26126;&#26174;&#24773;&#20917;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;PSD&#27169;&#22411;&#30340;&#26032;&#22411;&#28388;&#27874;&#22120;&#65292;&#23427;&#22312;&#23494;&#24230;&#36817;&#20284;&#21644;&#35745;&#31639;&#25928;&#29575;&#26041;&#38754;&#20855;&#26377;&#22810;&#20010;&#20248;&#21183;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#36716;&#25442;&#21644;&#35266;&#27979;&#37117;&#26159;&#39640;&#26031;PSD&#27169;&#22411;&#26102;&#65292;&#28388;&#27874;&#21487;&#20197;&#20197;&#38381;&#24335;&#24418;&#24335;&#39640;&#25928;&#22320;&#36827;&#34892;&#12290;&#24403;&#36716;&#25442;&#21644;&#35266;&#27979;&#34987;&#39640;&#26031;PSD&#27169;&#22411;&#36817;&#20284;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#20855;&#26377;&#24378;&#22823;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#20272;&#35745;&#35823;&#24046;&#21462;&#20915;&#20110;&#36817;&#20284;&#30340;&#36136;&#37327;&#65292;&#24182;&#19988;&#36866;&#24212;&#36716;&#25442;&#27010;&#29575;&#30340;&#27491;&#21017;&#24615;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#30340;&#36866;&#29992;&#33539;&#22260;&#65292;&#20854;&#20013;&#25105;&#20204;&#21487;&#20197;&#20197;&#38381;&#24335;&#24418;&#24335;&#39640;&#25928;&#22320;&#36827;&#34892;&#28388;&#27874;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09796v1 Announce Type: cross  Abstract: Sequential Bayesian Filtering aims to estimate the current state distribution of a Hidden Markov Model, given the past observations. The problem is well-known to be intractable for most application domains, except in notable cases such as the tabular setting or for linear dynamical systems with gaussian noise. In this work, we propose a new class of filters based on Gaussian PSD Models, which offer several advantages in terms of density approximation and computational efficiency. We show that filtering can be efficiently performed in closed form when transitions and observations are Gaussian PSD Models. When the transition and observations are approximated by Gaussian PSD Models, we show that our proposed estimator enjoys strong theoretical guarantees, with estimation error that depends on the quality of the approximation and is adaptive to the regularity of the transition probabilities. In particular, we identify regimes in which our 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#32771;&#34385;&#22806;&#25512;&#30340;&#38750;&#21442;&#25968;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31867;&#22806;&#25512;&#20551;&#35774;&#65292;&#32467;&#21512;&#29616;&#26377;&#25512;&#26029;&#25216;&#26415;&#21487;&#20197;&#24471;&#20986;&#21463;&#22806;&#25512;&#24433;&#21709;&#30340;&#32467;&#35770;&#12290;</title><link>https://arxiv.org/abs/2402.09758</link><description>&lt;p&gt;
&#32771;&#34385;&#22806;&#25512;&#30340;&#38750;&#21442;&#25968;&#32479;&#35745;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Extrapolation-Aware Nonparametric Statistical Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09758
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#32771;&#34385;&#22806;&#25512;&#30340;&#38750;&#21442;&#25968;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31867;&#22806;&#25512;&#20551;&#35774;&#65292;&#32467;&#21512;&#29616;&#26377;&#25512;&#26029;&#25216;&#26415;&#21487;&#20197;&#24471;&#20986;&#21463;&#22806;&#25512;&#24433;&#21709;&#30340;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;&#22806;&#25512;&#23450;&#20041;&#20026;&#23545;&#36229;&#20986;&#26465;&#20214;&#21464;&#37327;&#25903;&#25345;&#33539;&#22260;&#30340;&#26465;&#20214;&#20989;&#25968;&#65288;&#20363;&#22914;&#26465;&#20214;&#26399;&#26395;&#25110;&#26465;&#20214;&#20998;&#20301;&#25968;&#65289;&#36827;&#34892;&#30340;&#20219;&#20309;&#31867;&#22411;&#30340;&#32479;&#35745;&#25512;&#26029;&#12290;&#36825;&#31181;&#22806;&#25512;&#31867;&#22411;&#22312;&#35768;&#22810;&#25968;&#25454;&#20998;&#26512;&#24212;&#29992;&#20013;&#37117;&#20986;&#29616;&#65292;&#24182;&#19988;&#22914;&#26524;&#19981;&#32771;&#34385;&#23427;&#20204;&#21487;&#33021;&#20250;&#20351;&#24471;&#32467;&#26524;&#30340;&#32467;&#35770;&#22833;&#25928;&#12290;&#23613;&#31649;&#22312;&#21442;&#25968;&#27169;&#22411;&#20013;&#22806;&#25512;&#26159;&#30452;&#25509;&#30340;&#65292;&#20294;&#22312;&#38750;&#21442;&#25968;&#27169;&#22411;&#20013;&#21364;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;&#38750;&#21442;&#25968;&#32479;&#35745;&#27169;&#22411;&#25193;&#23637;&#21040;&#26126;&#30830;&#20801;&#35768;&#22806;&#25512;&#65292;&#24182;&#24341;&#20837;&#19968;&#31867;&#21487;&#20197;&#19982;&#29616;&#26377;&#25512;&#26029;&#25216;&#26415;&#32467;&#21512;&#20351;&#29992;&#30340;&#22806;&#25512;&#20551;&#35774;&#65292;&#20197;&#24471;&#20986;&#21463;&#22806;&#25512;&#24433;&#21709;&#30340;&#32467;&#35770;&#12290;&#25552;&#20986;&#30340;&#22806;&#25512;&#20551;&#35774;&#31867;&#35268;&#23450;&#65292;&#26465;&#20214;&#20989;&#25968;&#22312;&#35266;&#23519;&#21040;&#30340;&#25903;&#25345;&#33539;&#22260;&#20869;&#30340;&#27599;&#20010;&#26041;&#21521;&#19978;&#37117;&#36798;&#21040;&#20854;&#26368;&#23567;&#21644;&#26368;&#22823;&#26041;&#21521;&#23548;&#25968;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;&#35813;&#26694;&#26550;&#22914;&#20309;&#24212;&#29992;&#20110;&#20960;&#20010;&#23454;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09758v1 Announce Type: cross  Abstract: We define extrapolation as any type of statistical inference on a conditional function (e.g., a conditional expectation or conditional quantile) evaluated outside of the support of the conditioning variable. This type of extrapolation occurs in many data analysis applications and can invalidate the resulting conclusions if not taken into account. While extrapolating is straightforward in parametric models, it becomes challenging in nonparametric models. In this work, we extend the nonparametric statistical model to explicitly allow for extrapolation and introduce a class of extrapolation assumptions that can be combined with existing inference techniques to draw extrapolation-aware conclusions. The proposed class of extrapolation assumptions stipulate that the conditional function attains its minimal and maximal directional derivative, in each direction, within the observed support. We illustrate how the framework applies to several st
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#29699;&#24418;&#21333;&#20301;&#27491;&#21017;&#21270;SVD&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#29992;&#20110;&#40065;&#26834;&#30340;SVD&#36924;&#36817;&#65292;&#35813;&#31639;&#27861;&#19981;&#21463;&#24322;&#24120;&#20540;&#24178;&#25200;&#65292;&#35745;&#31639;&#21487;&#20280;&#32553;&#65292;&#24182;&#33021;&#25552;&#20379;&#20934;&#30830;&#30340;&#22855;&#24322;&#21521;&#37327;&#36924;&#36817;&#12290;&#30456;&#27604;&#31454;&#20105;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20165;&#20351;&#29992;&#26631;&#20934;&#38477;&#31209;SVD&#31639;&#27861;&#20004;&#27425;&#24212;&#29992;&#20110;&#36866;&#24403;&#32553;&#25918;&#30340;&#25968;&#25454;&#65292;&#20855;&#26377;&#26174;&#33879;&#30340;&#35745;&#31639;&#36895;&#24230;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2402.09754</link><description>&lt;p&gt;
Robust SVD&#21464;&#24471;&#31616;&#21333;&#65306;&#19968;&#31181;&#29992;&#20110;&#22823;&#35268;&#27169;&#25968;&#25454;&#20998;&#26512;&#30340;&#24555;&#36895;&#21487;&#38752;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Robust SVD Made Easy: A fast and reliable algorithm for large-scale data analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09754
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#29699;&#24418;&#21333;&#20301;&#27491;&#21017;&#21270;SVD&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#29992;&#20110;&#40065;&#26834;&#30340;SVD&#36924;&#36817;&#65292;&#35813;&#31639;&#27861;&#19981;&#21463;&#24322;&#24120;&#20540;&#24178;&#25200;&#65292;&#35745;&#31639;&#21487;&#20280;&#32553;&#65292;&#24182;&#33021;&#25552;&#20379;&#20934;&#30830;&#30340;&#22855;&#24322;&#21521;&#37327;&#36924;&#36817;&#12290;&#30456;&#27604;&#31454;&#20105;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20165;&#20351;&#29992;&#26631;&#20934;&#38477;&#31209;SVD&#31639;&#27861;&#20004;&#27425;&#24212;&#29992;&#20110;&#36866;&#24403;&#32553;&#25918;&#30340;&#25968;&#25454;&#65292;&#20855;&#26377;&#26174;&#33879;&#30340;&#35745;&#31639;&#36895;&#24230;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22855;&#24322;&#20540;&#20998;&#35299;&#65288;SVD&#65289;&#26159;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#37325;&#35201;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#23427;&#23545;&#25968;&#25454;&#30697;&#38453;&#20013;&#30340;&#24322;&#24120;&#20540;&#38750;&#24120;&#25935;&#24863;&#12290;&#29616;&#26377;&#30340;&#40065;&#26834;SVD&#31639;&#27861;&#24448;&#24448;&#22312;&#20445;&#35777;&#40065;&#26834;&#24615;&#26041;&#38754;&#29306;&#29298;&#20102;&#36895;&#24230;&#65292;&#25110;&#32773;&#22312;&#21482;&#26377;&#23569;&#25968;&#24322;&#24120;&#20540;&#23384;&#22312;&#26102;&#22833;&#25928;&#12290;&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#24230;&#19981;&#21463;&#24322;&#24120;&#20540;&#24178;&#25200;&#65292;&#35745;&#31639;&#21487;&#20280;&#32553;&#19988;&#25552;&#20379;&#20934;&#30830;&#22855;&#24322;&#21521;&#37327;&#36924;&#36817;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#31216;&#20026;&#29699;&#24418;&#21333;&#20301;&#27491;&#21017;&#21270;SVD&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#20165;&#20351;&#29992;&#26631;&#20934;&#38477;&#31209;SVD&#31639;&#27861;&#30340;&#20004;&#20010;&#24212;&#29992;&#20110;&#36866;&#24403;&#32553;&#25918;&#30340;&#25968;&#25454;&#65292;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#35745;&#31639;&#36895;&#24230;&#20248;&#21183;&#65292;&#26126;&#26174;&#20248;&#20110;&#31454;&#20105;&#31639;&#27861;&#30340;&#35745;&#31639;&#26102;&#38388;&#12290;&#20026;&#20102;&#35780;&#20272;&#36924;&#36817;&#22855;&#24322;&#21521;&#37327;&#21450;&#20854;&#23376;&#31354;&#38388;&#30340;&#25239;&#25968;&#25454;&#27745;&#26579;&#33021;&#21147;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#30697;&#38453;&#20540;&#36755;&#20837;&#30340;&#26032;&#30340;&#22833;&#25928;&#28857;&#27010;&#24565;&#65292;&#21253;&#25324;&#36880;&#34892;&#65292;c
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09754v1 Announce Type: new  Abstract: The singular value decomposition (SVD) is a crucial tool in machine learning and statistical data analysis. However, it is highly susceptible to outliers in the data matrix. Existing robust SVD algorithms often sacrifice speed for robustness or fail in the presence of only a few outliers. This study introduces an efficient algorithm, called Spherically Normalized SVD, for robust SVD approximation that is highly insensitive to outliers, computationally scalable, and provides accurate approximations of singular vectors. The proposed algorithm achieves remarkable speed by utilizing only two applications of a standard reduced-rank SVD algorithm to appropriately scaled data, significantly outperforming competing algorithms in computation times. To assess the robustness of the approximated singular vectors and their subspaces against data contamination, we introduce new notions of breakdown points for matrix-valued input, including row-wise, c
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#25552;&#31034;&#23398;&#20064;&#20013;&#32771;&#34385;&#26377;&#38480;&#39044;&#31639;&#32422;&#26463;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24314;&#31435;&#25552;&#31034;&#23398;&#20064;&#21644;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;TRIPLE&#65292;&#36890;&#36807;&#21033;&#29992;&#32858;&#31867;&#21644;&#23884;&#20837;&#24605;&#24819;&#23454;&#29616;&#20102;&#20004;&#20010;&#22686;&#24378;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.09723</link><description>&lt;p&gt;
&#26377;&#38480;&#39044;&#31639;&#19979;&#30340;&#36805;&#36895;&#23398;&#20064;&#26368;&#20339;&#33218;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Best Arm Identification for Prompt Learning under a Limited Budget
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09723
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#25552;&#31034;&#23398;&#20064;&#20013;&#32771;&#34385;&#26377;&#38480;&#39044;&#31639;&#32422;&#26463;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24314;&#31435;&#25552;&#31034;&#23398;&#20064;&#21644;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;TRIPLE&#65292;&#36890;&#36807;&#21033;&#29992;&#32858;&#31867;&#21644;&#23884;&#20837;&#24605;&#24819;&#23454;&#29616;&#20102;&#20004;&#20010;&#22686;&#24378;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#26174;&#33879;&#25351;&#20196;&#36319;&#38543;&#33021;&#21147;&#24341;&#21457;&#20102;&#23545;&#33258;&#21160;&#23398;&#20064;&#21512;&#36866;&#25552;&#31034;&#30340;&#20852;&#36259;&#12290;&#28982;&#32780;&#65292;&#34429;&#28982;&#25552;&#20986;&#20102;&#35768;&#22810;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#20294;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#20135;&#29983;&#30340;&#25104;&#26412;&#65288;&#20363;&#22914;&#35775;&#38382;LLM&#21644;&#35780;&#20272;&#21709;&#24212;&#65289;&#23578;&#26410;&#24471;&#21040;&#32771;&#34385;&#12290;&#20026;&#20811;&#26381;&#36825;&#20010;&#38480;&#21046;&#65292;&#26412;&#24037;&#20316;&#22312;&#25552;&#31034;&#23398;&#20064;&#20013;&#26126;&#30830;&#24341;&#20837;&#20102;&#26377;&#38480;&#39044;&#31639;&#32422;&#26463;&#12290;&#20026;&#20102;&#24320;&#21457;&#26377;&#21407;&#21017;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#26412;&#30740;&#31350;&#22312;&#25552;&#31034;&#23398;&#20064;&#21644;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#65288;BAI-FB&#65289;&#20043;&#38388;&#24314;&#31435;&#20102;&#19968;&#31181;&#26032;&#30340;&#32852;&#31995;&#12290;&#22522;&#20110;&#36825;&#31181;&#32852;&#31995;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;TRIPLE&#65288;&#29992;&#20110;&#25552;&#31034;&#23398;&#20064;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#65289;&#65292;&#20197;&#31995;&#32479;&#22320;&#21033;&#29992;BAI-FB&#22312;&#25552;&#31034;&#23398;&#20064;&#20013;&#30340;&#21147;&#37327;&#12290;&#25552;&#31034;&#23398;&#20064;&#30340;&#29420;&#29305;&#29305;&#28857;&#36827;&#19968;&#27493;&#36890;&#36807;&#21033;&#29992;&#32858;&#31867;&#21644;&#23884;&#20837;&#24605;&#24819;&#25552;&#20986;&#20102;TRIPLE&#30340;&#20004;&#20010;&#22522;&#20110;&#23884;&#20837;&#30340;&#22686;&#24378;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09723v1 Announce Type: cross  Abstract: The remarkable instruction-following capability of large language models (LLMs) has sparked a growing interest in automatically learning suitable prompts. However, while many effective methods have been proposed, the cost incurred during the learning process (e.g., accessing LLM and evaluating the responses) has not been considered. To overcome this limitation, this work explicitly incorporates a finite budget constraint into prompt learning. Towards developing principled solutions, a novel connection is established between prompt learning and fixed-budget best arm identification (BAI-FB) in multi-armed bandits (MAB). Based on this connection, a general framework TRIPLE (besT aRm Identification for Prompt LEarning) is proposed to harness the power of BAI-FB in prompt learning systematically. Unique characteristics of prompt learning further lead to two embedding-based enhancements of TRIPLE by exploiting the ideas of clustering and fun
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#31232;&#30095;&#35299;&#37322;&#20540;(SEV)&#65292;&#29992;&#20110;&#34913;&#37327;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20915;&#31574;&#31232;&#30095;&#24615;&#12290;&#21363;&#20351;&#27169;&#22411;&#19981;&#26159;&#31232;&#30095;&#30340;&#65292;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;SEV&#30340;&#34913;&#37327;&#19979;&#20173;&#20855;&#26377;&#20302;&#20915;&#31574;&#31232;&#30095;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.09702</link><description>&lt;p&gt;
&#26080;&#38656;&#31232;&#30095;&#27169;&#22411;&#30340;&#31232;&#30095;&#19988;&#20934;&#30830;&#30340;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Sparse and Faithful Explanations Without Sparse Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09702
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#31232;&#30095;&#35299;&#37322;&#20540;(SEV)&#65292;&#29992;&#20110;&#34913;&#37327;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20915;&#31574;&#31232;&#30095;&#24615;&#12290;&#21363;&#20351;&#27169;&#22411;&#19981;&#26159;&#31232;&#30095;&#30340;&#65292;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;SEV&#30340;&#34913;&#37327;&#19979;&#20173;&#20855;&#26377;&#20302;&#20915;&#31574;&#31232;&#30095;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21363;&#20351;&#27169;&#22411;&#19981;&#28385;&#36275;&#20840;&#23616;&#30340;&#31232;&#30095;&#24615;&#65292;&#20915;&#31574;&#20173;&#28982;&#21487;&#20197;&#29992;&#23569;&#37327;&#30340;&#29305;&#24449;&#20934;&#30830;&#22320;&#25551;&#36848;&#12290;&#20363;&#22914;&#65292;&#23545;&#20110;&#26576;&#20154;&#32780;&#35328;&#65292;&#23613;&#31649;&#27809;&#26377;&#20449;&#29992;&#21382;&#21490;&#65292;&#20294;&#30003;&#35831;&#22823;&#31508;&#36151;&#27454;&#21487;&#33021;&#20250;&#34987;&#25298;&#32477;&#65292;&#36825;&#23601;&#24573;&#35270;&#20102;&#19982;&#20854;&#20449;&#29992;&#20215;&#20540;&#30456;&#20851;&#30340;&#20219;&#20309;&#35777;&#25454;&#12290;&#22312;&#26412;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31232;&#30095;&#35299;&#37322;&#20540;&#65288;SEV&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#34913;&#37327;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#31232;&#30095;&#24615;&#30340;&#26032;&#26041;&#27861;&#12290;&#22312;&#20197;&#19978;&#36151;&#27454;&#25298;&#32477;&#30340;&#20363;&#23376;&#20013;&#65292;SEV&#20026;1&#65292;&#22240;&#20026;&#21482;&#38656;&#35201;&#19968;&#20010;&#22240;&#32032;&#26469;&#35299;&#37322;&#20026;&#20160;&#20040;&#36151;&#27454;&#34987;&#25298;&#32477;&#12290;SEV&#26159;&#23545;&#20915;&#31574;&#31232;&#30095;&#24615;&#30340;&#34913;&#37327;&#65292;&#32780;&#19981;&#26159;&#23545;&#25972;&#20307;&#27169;&#22411;&#31232;&#30095;&#24615;&#30340;&#34913;&#37327;&#65292;&#24182;&#19988;&#25105;&#20204;&#33021;&#22815;&#35777;&#26126;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#8212;&#8212;&#21363;&#20351;&#23427;&#20204;&#19981;&#26159;&#31232;&#30095;&#30340;&#8212;&#8212;&#23454;&#38469;&#19978;&#22312;SEV&#30340;&#34913;&#37327;&#19979;&#20855;&#26377;&#20302;&#20915;&#31574;&#31232;&#30095;&#24615;&#12290;SEV&#20351;&#29992;&#36229;&#31435;&#26041;&#20307;&#19978;&#30340;&#31227;&#21160;&#36827;&#34892;&#23450;&#20041;&#65292;&#20351;&#24471;SEV&#33021;&#22815;&#22312;&#21508;&#31181;&#27169;&#22411;&#31867;&#21035;&#19978;&#19968;&#33268;&#22320;&#23450;&#20041;&#65292;&#20854;&#20013;&#31227;&#21160;&#38480;&#21046;&#21453;&#26144;&#20102;&#27169;&#22411;&#30340;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09702v1 Announce Type: new  Abstract: Even if a model is not globally sparse, it is possible for decisions made from that model to be accurately and faithfully described by a small number of features. For instance, an application for a large loan might be denied to someone because they have no credit history, which overwhelms any evidence towards their creditworthiness. In this work, we introduce the Sparse Explanation Value (SEV), a new way of measuring sparsity in machine learning models. In the loan denial example above, the SEV is 1 because only one factor is needed to explain why the loan was denied. SEV is a measure of decision sparsity rather than overall model sparsity, and we are able to show that many machine learning models -- even if they are not sparse -- actually have low decision sparsity, as measured by SEV. SEV is defined using movements over a hypercube, allowing SEV to be defined consistently over various model classes, with movement restrictions reflectin
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#21512;&#24182;&#20351;&#29992;&#19981;&#21516;&#36807;&#28388;&#22120;&#35745;&#31639;&#30340;e&#36827;&#31243;&#30340;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#20854;&#22312;&#39034;&#24207;&#25512;&#29702;&#20013;&#30340;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.09698</link><description>&lt;p&gt;
&#21512;&#24182;&#19981;&#21516;&#36807;&#28388;&#22120;&#20013;&#30340;&#35777;&#25454;
&lt;/p&gt;
&lt;p&gt;
Combining Evidence Across Filtrations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09698
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#21512;&#24182;&#20351;&#29992;&#19981;&#21516;&#36807;&#28388;&#22120;&#35745;&#31639;&#30340;e&#36827;&#31243;&#30340;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#20854;&#22312;&#39034;&#24207;&#25512;&#29702;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20219;&#20309;&#26102;&#21051;&#26377;&#25928;&#30340;&#39034;&#24207;&#25512;&#29702;&#20013;&#65292;&#24050;&#30693;&#20219;&#20309;&#21487;&#25509;&#21463;&#30340;&#25512;&#29702;&#26041;&#27861;&#24517;&#39035;&#22522;&#20110;&#27979;&#35797;&#38789;&#21644;&#23427;&#20204;&#30340;&#32452;&#21512;&#24191;&#20041;&#21270;&#65292;&#31216;&#20026;e&#36827;&#31243;&#65292;&#23427;&#20204;&#26159;&#38750;&#36127;&#36827;&#31243;&#65292;&#20854;&#22312;&#20219;&#20309;&#20219;&#24847;&#20572;&#26102;&#30340;&#26399;&#26395;&#19978;&#30028;&#19981;&#36229;&#36807;&#19968;&#12290;e&#36827;&#31243;&#37327;&#21270;&#20102;&#38024;&#23545;&#22797;&#21512;&#38646;&#20551;&#35774;&#30340;&#19968;&#31995;&#21015;&#32467;&#26524;&#30340;&#32047;&#31215;&#35777;&#25454;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#19981;&#21516;&#20449;&#24687;&#38598;&#65288;&#21363;&#36807;&#28388;&#22120;&#65289;&#35745;&#31639;&#30340;e&#36827;&#31243;&#30340;&#21512;&#24182;&#26041;&#27861;&#65292;&#38024;&#23545;&#19968;&#20010;&#38646;&#20551;&#35774;&#12290;&#23613;&#31649;&#22312;&#30456;&#21516;&#36807;&#28388;&#22120;&#19978;&#26500;&#24314;&#30340;e&#36827;&#31243;&#21487;&#20197;&#36731;&#26494;&#22320;&#21512;&#24182;&#65288;&#20363;&#22914;&#65292;&#36890;&#36807;&#24179;&#22343;&#65289;&#65292;&#20294;&#22312;&#19981;&#21516;&#36807;&#28388;&#22120;&#19978;&#26500;&#24314;&#30340;e&#36827;&#31243;&#19981;&#33021;&#37027;&#20040;&#23481;&#26131;&#22320;&#21512;&#24182;&#65292;&#22240;&#20026;&#23427;&#20204;&#22312;&#36739;&#31895;&#30340;&#36807;&#28388;&#22120;&#20013;&#30340;&#26377;&#25928;&#24615;&#19981;&#33021;&#36716;&#25442;&#20026;&#22312;&#26356;&#32454;&#30340;&#36807;&#28388;&#22120;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#25991;&#29486;&#20013;&#19977;&#20010;&#20855;&#20307;&#20363;&#23376;&#65306;&#21487;&#20132;&#25442;&#24615;&#27979;&#35797;&#65292;&#29420;&#31435;&#24615;&#27979;&#35797;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09698v1 Announce Type: cross  Abstract: In anytime-valid sequential inference, it is known that any admissible inference procedure must be based on test martingales and their composite generalization, called e-processes, which are nonnegative processes whose expectation at any arbitrary stopping time is upper-bounded by one. An e-process quantifies the accumulated evidence against a composite null hypothesis over a sequence of outcomes. This paper studies methods for combining e-processes that are computed using different information sets, i.e., filtrations, for a null hypothesis. Even though e-processes constructed on the same filtration can be combined effortlessly (e.g., by averaging), e-processes constructed on different filtrations cannot be combined as easily because their validity in a coarser filtration does not translate to validity in a finer filtration. We discuss three concrete examples of such e-processes in the literature: exchangeability tests, independence te
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31526;&#21512;&#24615;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#22312;&#32447;&#31526;&#21512;&#24615;&#39044;&#27979;&#25216;&#26415;&#21644;&#35299;&#20915;&#22238;&#24402;&#20013;&#24322;&#26041;&#24046;&#24615;&#30340;&#26041;&#27861;&#65292;&#29983;&#25104;&#20102;&#21516;&#26102;&#39044;&#27979;&#36793;&#30028;&#65292;&#24182;&#33021;&#22815;&#21487;&#38752;&#22320;&#35206;&#30422;&#26032;&#38543;&#26426;&#36712;&#36857;&#30340;&#25972;&#20010;&#36335;&#24452;&#12290;&#36825;&#31181;&#26041;&#27861;&#19981;&#20165;&#26377;&#31934;&#30830;&#30340;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#65292;&#32780;&#19988;&#24448;&#24448;&#27604;&#20043;&#21069;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#20016;&#23500;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.09623</link><description>&lt;p&gt;
&#22810;&#20803;&#36712;&#36857;&#30340;&#31526;&#21512;&#24615;&#33258;&#36866;&#24212;&#39044;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Conformalized Adaptive Forecasting of Heterogeneous Trajectories
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09623
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31526;&#21512;&#24615;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#22312;&#32447;&#31526;&#21512;&#24615;&#39044;&#27979;&#25216;&#26415;&#21644;&#35299;&#20915;&#22238;&#24402;&#20013;&#24322;&#26041;&#24046;&#24615;&#30340;&#26041;&#27861;&#65292;&#29983;&#25104;&#20102;&#21516;&#26102;&#39044;&#27979;&#36793;&#30028;&#65292;&#24182;&#33021;&#22815;&#21487;&#38752;&#22320;&#35206;&#30422;&#26032;&#38543;&#26426;&#36712;&#36857;&#30340;&#25972;&#20010;&#36335;&#24452;&#12290;&#36825;&#31181;&#26041;&#27861;&#19981;&#20165;&#26377;&#31934;&#30830;&#30340;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#65292;&#32780;&#19988;&#24448;&#24448;&#27604;&#20043;&#21069;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#20016;&#23500;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31526;&#21512;&#24615;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#21516;&#26102;&#39044;&#27979;&#36793;&#30028;&#65292;&#20197;&#20855;&#26377;&#36275;&#22815;&#39640;&#30340;&#27010;&#29575;&#35206;&#30422;&#26032;&#38543;&#26426;&#36712;&#36857;&#30340;&#25972;&#20010;&#36335;&#24452;&#12290;&#37492;&#20110;&#22312;&#36816;&#21160;&#35268;&#21010;&#24212;&#29992;&#20013;&#38656;&#35201;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#20854;&#20013;&#19981;&#21516;&#29289;&#20307;&#30340;&#34892;&#20026;&#21487;&#33021;&#26356;&#25110;&#26356;&#23569;&#21487;&#39044;&#27979;&#65292;&#25105;&#20204;&#23558;&#26469;&#33258;&#21333;&#20010;&#21644;&#22810;&#20010;&#26102;&#38388;&#24207;&#21015;&#30340;&#22312;&#32447;&#31526;&#21512;&#24615;&#39044;&#27979;&#25216;&#26415;&#65292;&#20197;&#21450;&#35299;&#20915;&#22238;&#24402;&#20013;&#30340;&#24322;&#26041;&#24046;&#24615;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#34701;&#21512;&#12290;&#35813;&#35299;&#20915;&#26041;&#26696;&#26082;&#26377;&#21407;&#21017;&#24615;&#65292;&#25552;&#20379;&#20102;&#31934;&#30830;&#30340;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#65292;&#21448;&#26377;&#25928;&#65292;&#36890;&#24120;&#27604;&#20808;&#21069;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#20016;&#23500;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09623v1 Announce Type: cross  Abstract: This paper presents a new conformal method for generating simultaneous forecasting bands guaranteed to cover the entire path of a new random trajectory with sufficiently high probability. Prompted by the need for dependable uncertainty estimates in motion planning applications where the behavior of diverse objects may be more or less unpredictable, we blend different techniques from online conformal prediction of single and multiple time series, as well as ideas for addressing heteroscedasticity in regression. This solution is both principled, providing precise finite-sample guarantees, and effective, often leading to more informative predictions than prior methods.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;&#24179;&#26041;&#31070;&#32463;&#32593;&#32476;&#26063;&#30340;&#31934;&#30830;&#12289;&#24555;&#36895;&#21644;&#34920;&#36798;&#24615;&#27850;&#26494;&#28857;&#36807;&#31243;&#12290;&#36890;&#36807;&#21033;&#29992;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#24179;&#26041;&#33539;&#25968;&#26469;&#21442;&#25968;&#21270;&#24378;&#24230;&#20989;&#25968;&#65292;&#21487;&#20197;&#33719;&#24471;&#26356;&#28789;&#27963;&#21644;&#39640;&#25928;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#22312;&#35745;&#31639;&#31215;&#20998;&#24378;&#24230;&#20989;&#25968;&#26102;&#20855;&#26377;&#23553;&#38381;&#24418;&#24335;&#21644;&#20108;&#27425;&#26102;&#38388;&#22797;&#26434;&#24230;&#65292;&#24182;&#19988;&#30456;&#27604;&#20110;&#20256;&#32479;&#26041;&#27861;&#26356;&#33410;&#32422;&#20869;&#23384;&#21644;&#26102;&#38388;&#12290;&#36890;&#36807;&#35299;&#20915;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#21487;&#20197;&#33719;&#24471;&#23545;&#24378;&#24230;&#20989;&#25968;&#26368;&#32456;&#23618;&#30340;&#21442;&#25968;&#21270;&#37325;&#21442;&#25968;&#21270;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#21644;&#26368;&#22823;&#21518;&#39564;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2402.09608</link><description>&lt;p&gt;
&#20351;&#29992;&#24179;&#26041;&#31070;&#32463;&#32593;&#32476;&#26063;&#30340;&#31934;&#30830;&#12289;&#24555;&#36895;&#21644;&#34920;&#36798;&#24615;&#27850;&#26494;&#28857;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Exact, Fast and Expressive Poisson Point Processes via Squared Neural Families
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09608
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;&#24179;&#26041;&#31070;&#32463;&#32593;&#32476;&#26063;&#30340;&#31934;&#30830;&#12289;&#24555;&#36895;&#21644;&#34920;&#36798;&#24615;&#27850;&#26494;&#28857;&#36807;&#31243;&#12290;&#36890;&#36807;&#21033;&#29992;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#24179;&#26041;&#33539;&#25968;&#26469;&#21442;&#25968;&#21270;&#24378;&#24230;&#20989;&#25968;&#65292;&#21487;&#20197;&#33719;&#24471;&#26356;&#28789;&#27963;&#21644;&#39640;&#25928;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#22312;&#35745;&#31639;&#31215;&#20998;&#24378;&#24230;&#20989;&#25968;&#26102;&#20855;&#26377;&#23553;&#38381;&#24418;&#24335;&#21644;&#20108;&#27425;&#26102;&#38388;&#22797;&#26434;&#24230;&#65292;&#24182;&#19988;&#30456;&#27604;&#20110;&#20256;&#32479;&#26041;&#27861;&#26356;&#33410;&#32422;&#20869;&#23384;&#21644;&#26102;&#38388;&#12290;&#36890;&#36807;&#35299;&#20915;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#21487;&#20197;&#33719;&#24471;&#23545;&#24378;&#24230;&#20989;&#25968;&#26368;&#32456;&#23618;&#30340;&#21442;&#25968;&#21270;&#37325;&#21442;&#25968;&#21270;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#21644;&#26368;&#22823;&#21518;&#39564;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#23558;&#24378;&#24230;&#20989;&#25968;&#30340;&#21442;&#25968;&#21270;&#20026;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#24179;&#26041;&#33539;&#25968;&#24341;&#20837;&#20102;&#24179;&#26041;&#31070;&#32463;&#27850;&#26494;&#28857;&#36807;&#31243;&#65288;SNEPPPs&#65289;&#12290;&#24403;&#38544;&#34255;&#23618;&#34987;&#22266;&#23450;&#19988;&#31532;&#20108;&#23618;&#21482;&#26377;&#19968;&#20010;&#31070;&#32463;&#20803;&#26102;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#31867;&#20284;&#20110;&#20043;&#21069;&#20351;&#29992;&#24179;&#26041;&#39640;&#26031;&#36807;&#31243;&#25110;&#26680;&#26041;&#27861;&#65292;&#20294;&#20801;&#35768;&#38544;&#34255;&#23618;&#23398;&#20064;&#33021;&#22815;&#25552;&#20379;&#39069;&#22806;&#30340;&#28789;&#27963;&#24615;&#12290;&#22312;&#35768;&#22810;&#24863;&#20852;&#36259;&#30340;&#24773;&#20917;&#19979;&#65292;&#31215;&#20998;&#24378;&#24230;&#20989;&#25968;&#21487;&#20197;&#24471;&#21040;&#23553;&#38381;&#24418;&#24335;&#65292;&#24182;&#19988;&#21487;&#20197;&#20197;&#20108;&#27425;&#26102;&#38388;&#30456;&#23545;&#20110;&#38544;&#34255;&#31070;&#32463;&#20803;&#30340;&#25968;&#37327;&#36827;&#34892;&#35745;&#31639;&#12290;&#25105;&#20204;&#21015;&#20030;&#20102;&#27604;&#20197;&#21069;&#35752;&#35770;&#36807;&#30340;&#26356;&#22810;&#36825;&#26679;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#27604;&#31616;&#21333;&#23454;&#29616;&#24179;&#26041;&#25110;&#25351;&#25968;&#26680;&#26041;&#27861;&#25110;&#39640;&#26031;&#36807;&#31243;&#26356;&#33410;&#32422;&#20869;&#23384;&#21644;&#26102;&#38388;&#12290;&#26368;&#22823;&#20284;&#28982;&#21644;&#26368;&#22823;&#21518;&#39564;&#20272;&#35745;&#21487;&#20197;&#36890;&#36807;&#35299;&#20915;&#65288;&#20005;&#26684;&#65289;&#20984;&#20248;&#21270;&#38382;&#39064;&#26469;&#33719;&#24471;&#24378;&#24230;&#20989;&#25968;&#26368;&#32456;&#23618;&#30340;&#21442;&#25968;&#21270;&#37325;&#21442;&#25968;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09608v1 Announce Type: new  Abstract: We introduce squared neural Poisson point processes (SNEPPPs) by parameterising the intensity function by the squared norm of a two layer neural network. When the hidden layer is fixed and the second layer has a single neuron, our approach resembles previous uses of squared Gaussian process or kernel methods, but allowing the hidden layer to be learnt allows for additional flexibility. In many cases of interest, the integrated intensity function admits a closed form and can be computed in quadratic time in the number of hidden neurons. We enumerate a far more extensive number of such cases than has previously been discussed. Our approach is more memory and time efficient than naive implementations of squared or exponentiated kernel methods or Gaussian processes. Maximum likelihood and maximum a posteriori estimates in a reparameterisation of the final layer of the intensity function can be obtained by solving a (strongly) convex optimisa
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#19988;&#40065;&#26834;&#30340;&#20302;&#31209;&#22270;&#23545;&#27604;&#23398;&#20064;&#65288;LR-GCL&#65289;&#31639;&#27861;&#65292;&#24212;&#29992;&#20110;&#36716;&#23548;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#20302;&#31209;&#27491;&#35268;&#21270;&#30340;&#23545;&#27604;&#23398;&#20064;&#35757;&#32451;&#19968;&#20010;&#32534;&#30721;&#22120;&#65292;&#24182;&#20351;&#29992;&#29983;&#25104;&#30340;&#29305;&#24449;&#36827;&#34892;&#32447;&#24615;&#36716;&#23548;&#20998;&#31867;&#12290;</title><link>https://arxiv.org/abs/2402.09600</link><description>&lt;p&gt;
&#20302;&#31209;&#22270;&#23545;&#27604;&#23398;&#20064;&#29992;&#20110;&#33410;&#28857;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Low-Rank Graph Contrastive Learning for Node Classification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09600
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#19988;&#40065;&#26834;&#30340;&#20302;&#31209;&#22270;&#23545;&#27604;&#23398;&#20064;&#65288;LR-GCL&#65289;&#31639;&#27861;&#65292;&#24212;&#29992;&#20110;&#36716;&#23548;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#20302;&#31209;&#27491;&#35268;&#21270;&#30340;&#23545;&#27604;&#23398;&#20064;&#35757;&#32451;&#19968;&#20010;&#32534;&#30721;&#22120;&#65292;&#24182;&#20351;&#29992;&#29983;&#25104;&#30340;&#29305;&#24449;&#36827;&#34892;&#32447;&#24615;&#36716;&#23548;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#24191;&#27867;&#24212;&#29992;&#20110;&#23398;&#20064;&#33410;&#28857;&#34920;&#31034;&#65292;&#24182;&#22312;&#33410;&#28857;&#20998;&#31867;&#31561;&#21508;&#31181;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#22270;&#25968;&#25454;&#20013;&#19981;&#21487;&#36991;&#20813;&#22320;&#23384;&#22312;&#22122;&#22768;&#65292;&#36825;&#20250;&#20005;&#37325;&#38477;&#20302;GNNs&#30340;&#24615;&#33021;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#19988;&#40065;&#26834;&#30340;GNN&#32534;&#30721;&#22120;&#65292;&#21363;&#20302;&#31209;&#22270;&#23545;&#27604;&#23398;&#20064;&#65288;LR-GCL&#65289;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#20004;&#20010;&#27493;&#39588;&#36827;&#34892;&#36716;&#23548;&#33410;&#28857;&#20998;&#31867;&#12290;&#39318;&#20808;&#65292;&#36890;&#36807;&#20302;&#31209;&#27491;&#24120;&#23545;&#27604;&#23398;&#20064;&#35757;&#32451;&#19968;&#20010;&#21517;&#20026;LR-GCL&#30340;&#20302;&#31209;GCL&#32534;&#30721;&#22120;&#12290;&#28982;&#21518;&#65292;&#20351;&#29992;LR-GCL&#29983;&#25104;&#30340;&#29305;&#24449;&#65292;&#20351;&#29992;&#32447;&#24615;&#36716;&#23548;&#20998;&#31867;&#31639;&#27861;&#23545;&#22270;&#20013;&#30340;&#26410;&#26631;&#35760;&#33410;&#28857;&#36827;&#34892;&#20998;&#31867;&#12290;&#25105;&#20204;&#30340;LR-GCL&#21463;&#21040;&#22270;&#25968;&#25454;&#21644;&#20854;&#26631;&#31614;&#30340;&#20302;&#39057;&#24615;&#36136;&#30340;&#21551;&#31034;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#21463;&#21040;&#25105;&#20204;&#20851;&#20110;&#36716;&#23548;&#23398;&#20064;&#30340;&#23574;&#38160;&#27867;&#21270;&#30028;&#38480;&#30340;&#25512;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09600v1 Announce Type: new  Abstract: Graph Neural Networks (GNNs) have been widely used to learn node representations and with outstanding performance on various tasks such as node classification. However, noise, which inevitably exists in real-world graph data, would considerably degrade the performance of GNNs revealed by recent studies. In this work, we propose a novel and robust GNN encoder, Low-Rank Graph Contrastive Learning (LR-GCL). Our method performs transductive node classification in two steps. First, a low-rank GCL encoder named LR-GCL is trained by prototypical contrastive learning with low-rank regularization. Next, using the features produced by LR-GCL, a linear transductive classification algorithm is used to classify the unlabeled nodes in the graph. Our LR-GCL is inspired by the low frequency property of the graph data and its labels, and it is also theoretically motivated by our sharp generalization bound for transductive learning. To the best of our kno
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#26088;&#22312;&#32479;&#19968;&#35299;&#20915;MCMC&#21644;&#26426;&#22120;&#23398;&#20064;&#20132;&#21449;&#39046;&#22495;&#30340;&#21508;&#31181;&#38382;&#39064;&#65292;&#21253;&#25324;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#12289;&#33258;&#36866;&#24212;MCMC&#12289;&#27491;&#35268;&#27969;&#26500;&#24314;&#21644;&#20256;&#36755;&#36741;&#21161;MCMC&#12289;&#26367;&#20195;&#20284;&#28982;MCMC&#12289;&#22823;&#25968;&#25454;&#30340;MCMC&#26680;&#24515;&#38598;&#26500;&#24314;&#31561;&#65292;&#24182;&#25552;&#20986;&#19968;&#20010;&#36890;&#29992;&#30340;&#26694;&#26550;&#12290;</title><link>https://arxiv.org/abs/2402.09598</link><description>&lt;p&gt;
&#22522;&#20110;MCMC&#30340;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
MCMC-driven learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09598
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#26088;&#22312;&#32479;&#19968;&#35299;&#20915;MCMC&#21644;&#26426;&#22120;&#23398;&#20064;&#20132;&#21449;&#39046;&#22495;&#30340;&#21508;&#31181;&#38382;&#39064;&#65292;&#21253;&#25324;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#12289;&#33258;&#36866;&#24212;MCMC&#12289;&#27491;&#35268;&#27969;&#26500;&#24314;&#21644;&#20256;&#36755;&#36741;&#21161;MCMC&#12289;&#26367;&#20195;&#20284;&#28982;MCMC&#12289;&#22823;&#25968;&#25454;&#30340;MCMC&#26680;&#24515;&#38598;&#26500;&#24314;&#31561;&#65292;&#24182;&#25552;&#20986;&#19968;&#20010;&#36890;&#29992;&#30340;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#26088;&#22312;&#20316;&#20026;&#12298;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#25163;&#20876;&#12299;&#30340;&#19968;&#31456;&#20986;&#29616;&#12290;&#35813;&#31456;&#30340;&#30446;&#26631;&#26159;&#22312;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#65288;MCMC&#65289;&#21644;&#26426;&#22120;&#23398;&#20064;&#20043;&#38388;&#30340;&#20132;&#21449;&#28857;&#19978;&#32479;&#19968;&#21508;&#31181;&#38382;&#39064;&#65292;&#20854;&#20013;&#21253;&#25324;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#12289;&#33258;&#36866;&#24212;MCMC&#12289;&#27491;&#35268;&#27969;&#26500;&#24314;&#21644;&#20256;&#36755;&#36741;&#21161;MCMC&#12289;&#26367;&#20195;&#20284;&#28982;MCMC&#12289;&#29992;&#20110;&#22823;&#25968;&#25454;&#30340;MCMC&#26680;&#24515;&#38598;&#26500;&#24314;&#12289;&#39532;&#23572;&#31185;&#22827;&#38142;&#26799;&#24230;&#19979;&#38477;&#12289;&#39532;&#23572;&#31185;&#22827;&#24471;&#20998;&#25856;&#29228;&#31561;&#12290;&#36890;&#36807;&#36825;&#26679;&#20570;&#65292;&#21487;&#20197;&#23558;&#20026;&#27599;&#20010;&#38382;&#39064;&#24320;&#21457;&#30340;&#29702;&#35770;&#21644;&#26041;&#27861;&#36827;&#34892;&#32763;&#35793;&#21644;&#25512;&#24191;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09598v1 Announce Type: cross  Abstract: This paper is intended to appear as a chapter for the Handbook of Markov Chain Monte Carlo. The goal of this chapter is to unify various problems at the intersection of Markov chain Monte Carlo (MCMC) and machine learning$\unicode{x2014}$which includes black-box variational inference, adaptive MCMC, normalizing flow construction and transport-assisted MCMC, surrogate-likelihood MCMC, coreset construction for MCMC with big data, Markov chain gradient descent, Markovian score climbing, and more$\unicode{x2014}$within one common framework. By doing so, the theory and methods developed for each may be translated and generalized.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#20851;&#20110;Neyman-Pearson&#20998;&#31867;&#20013;&#26080;&#20998;&#24067;&#29575;&#30340;&#23436;&#25972;&#29305;&#24449;&#65292;&#36890;&#36807;&#31616;&#21333;&#30340;&#20960;&#20309;&#26465;&#20214;&#65292;&#21363;&#19977;&#28857;&#20998;&#31163;&#26465;&#20214;&#65292;&#21051;&#30011;&#20102;&#30828;&#20998;&#31867;&#22120;&#21644;&#31616;&#21333;&#20998;&#31867;&#22120;&#20043;&#38388;&#30340;&#20108;&#20998;&#26465;&#20214;&#12290;</title><link>https://arxiv.org/abs/2402.09560</link><description>&lt;p&gt;
Neyman-Pearson&#20998;&#31867;&#20013;&#30340;&#26080;&#20998;&#24067;&#29575;
&lt;/p&gt;
&lt;p&gt;
Distribution-Free Rates in Neyman-Pearson Classification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09560
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#20851;&#20110;Neyman-Pearson&#20998;&#31867;&#20013;&#26080;&#20998;&#24067;&#29575;&#30340;&#23436;&#25972;&#29305;&#24449;&#65292;&#36890;&#36807;&#31616;&#21333;&#30340;&#20960;&#20309;&#26465;&#20214;&#65292;&#21363;&#19977;&#28857;&#20998;&#31163;&#26465;&#20214;&#65292;&#21051;&#30011;&#20102;&#30828;&#20998;&#31867;&#22120;&#21644;&#31616;&#21333;&#20998;&#31867;&#22120;&#20043;&#38388;&#30340;&#20108;&#20998;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;Neyman-Pearson&#20998;&#31867;&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#27169;&#25311;&#20102;&#19981;&#24179;&#34913;&#20998;&#31867;&#35774;&#32622;&#65292;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#65292;&#26368;&#23567;&#21270;&#19982;&#20998;&#24067;$\mu_1$&#30456;&#20851;&#30340;&#38169;&#35823;&#65292;&#21516;&#26102;&#20445;&#35777;&#19982;&#21478;&#19968;&#20010;&#20998;&#24067;$\mu_0$&#30456;&#20851;&#30340;&#38169;&#35823;&#36739;&#20302;&#12290;&#32473;&#23450;&#19968;&#20010;&#22266;&#23450;&#30340;VC&#20998;&#31867;&#22120;&#31867;$\mathcal{H}$&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#21487;&#33021;&#30340;&#26080;&#20998;&#24067;&#29575;&#30340;&#23436;&#25972;&#29305;&#24449;&#65292;&#21363;&#25152;&#26377;&#37197;&#23545;$(\mu_0, \mu_1)$&#30340;&#26497;&#23567;&#21270;&#29575;&#12290;&#36825;&#20123;&#36895;&#29575;&#28041;&#21450;&#21040;&#20102;&#30828;&#20998;&#31867;&#22120;&#21644;&#31616;&#21333;&#20998;&#31867;&#22120;&#20043;&#38388;&#30340;&#20108;&#20998;&#26465;&#20214;&#65292;&#23427;&#20204;&#26159;&#26681;&#25454;&#19968;&#20010;&#31616;&#21333;&#30340;&#20960;&#20309;&#26465;&#20214;&#65292;&#21363;&#19977;&#28857;&#20998;&#31163;&#26465;&#20214;&#26469;&#21051;&#30011;&#30340;&#65292;&#19982;VC&#32500;&#24230;&#30053;&#26377;&#20851;&#32852;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09560v1 Announce Type: new  Abstract: We consider the problem of Neyman-Pearson classification which models unbalanced classification settings where error w.r.t. a distribution $\mu_1$ is to be minimized subject to low error w.r.t. a different distribution $\mu_0$. Given a fixed VC class $\mathcal{H}$ of classifiers to be minimized over, we provide a full characterization of possible distribution-free rates, i.e., minimax rates over the space of all pairs $(\mu_0, \mu_1)$. The rates involve a dichotomy between hard and easy classes $\mathcal{H}$ as characterized by a simple geometric condition, a three-points-separation condition, loosely related to VC dimension.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#31995;&#32479;&#22320;&#24320;&#21457;&#20102;&#19968;&#31181;&#29992;&#20110;&#39044;&#27979;&#21152;&#25343;&#22823;&#22467;&#24503;&#33945;&#39039;&#24066;&#19981;&#21516;&#31867;&#22411;&#32039;&#24613;&#20107;&#20214;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#24182;&#20998;&#26512;&#20102;&#20107;&#20214;&#31867;&#22411;&#19982;&#37051;&#22495;&#23618;&#38754;&#30340;&#31038;&#20250;&#32463;&#27982;&#21644;&#20154;&#21475;&#32479;&#35745;&#25968;&#25454;&#30340;&#20851;&#32852;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.09553</link><description>&lt;p&gt;
&#32479;&#35745;&#19982;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#29992;&#20110;&#39044;&#27979;&#28779;&#28798;&#21644;&#20854;&#20182;&#32039;&#24613;&#20107;&#20214;
&lt;/p&gt;
&lt;p&gt;
Statistical and Machine Learning Models for Predicting Fire and Other Emergency Events
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09553
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#31995;&#32479;&#22320;&#24320;&#21457;&#20102;&#19968;&#31181;&#29992;&#20110;&#39044;&#27979;&#21152;&#25343;&#22823;&#22467;&#24503;&#33945;&#39039;&#24066;&#19981;&#21516;&#31867;&#22411;&#32039;&#24613;&#20107;&#20214;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#24182;&#20998;&#26512;&#20102;&#20107;&#20214;&#31867;&#22411;&#19982;&#37051;&#22495;&#23618;&#38754;&#30340;&#31038;&#20250;&#32463;&#27982;&#21644;&#20154;&#21475;&#32479;&#35745;&#25968;&#25454;&#30340;&#20851;&#32852;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22478;&#24066;&#20013;&#30340;&#32039;&#24613;&#20107;&#20214;&#32473;&#20010;&#20154;&#12289;&#23478;&#24237;&#21644;&#31038;&#21306;&#37117;&#24102;&#26469;&#20102;&#30456;&#24403;&#22823;&#30340;&#32463;&#27982;&#25439;&#22833;&#12290;&#20934;&#30830;&#21644;&#21450;&#26102;&#22320;&#39044;&#27979;&#20107;&#20214;&#21487;&#20197;&#24110;&#21161;&#24212;&#24613;&#28040;&#38450;&#21644;&#25937;&#25588;&#37096;&#38376;&#20026;&#21644;&#20943;&#36731;&#32039;&#24613;&#20107;&#20214;&#30340;&#21518;&#26524;&#20570;&#22909;&#20934;&#22791;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#31995;&#32479;&#22320;&#24320;&#21457;&#20102;&#19968;&#31181;&#38024;&#23545;&#21152;&#25343;&#22823;&#22467;&#24503;&#33945;&#39039;&#24066;&#19981;&#21516;&#31867;&#22411;&#32039;&#24613;&#20107;&#20214;&#30340;&#39044;&#27979;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20197;&#19979;&#26041;&#27861;&#65306;&#65288;i&#65289;&#25968;&#25454;&#25910;&#38598;&#21644;&#25968;&#25454;&#38598;&#24320;&#21457;&#65307;&#65288;ii&#65289;&#23545;&#19981;&#21516;&#26102;&#31354;&#32423;&#21035;&#30340;&#27599;&#31181;&#20107;&#20214;&#31867;&#22411;&#21450;&#20854;&#29305;&#24449;&#36827;&#34892;&#25551;&#36848;&#24615;&#20998;&#26512;&#65307;&#65288;iii&#65289;&#22522;&#20110;&#30456;&#20851;&#31995;&#25968;&#20998;&#26512;&#21644;&#29305;&#24449;&#37325;&#35201;&#24615;&#20998;&#26512;&#30340;&#29305;&#24449;&#20998;&#26512;&#21644;&#36873;&#25321;&#65307;&#65288;iv&#65289;&#38024;&#23545;&#19981;&#21516;&#26102;&#31354;&#20998;&#36776;&#29575;&#24320;&#21457;&#27599;&#31181;&#20107;&#20214;&#31867;&#22411;&#21457;&#29983;&#21487;&#33021;&#24615;&#30340;&#39044;&#27979;&#27169;&#22411;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#20107;&#20214;&#31867;&#22411;&#19982;&#37051;&#22495;&#23618;&#38754;&#30340;&#31038;&#20250;&#32463;&#27982;&#21644;&#20154;&#21475;&#32479;&#35745;&#25968;&#25454;&#30340;&#20851;&#32852;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09553v1 Announce Type: new  Abstract: Emergency events in a city cause considerable economic loss to individuals, their families, and the community. Accurate and timely prediction of events can help the emergency fire and rescue services in preparing for and mitigating the consequences of emergency events. In this paper, we present a systematic development of predictive models for various types of emergency events in the City of Edmonton, Canada. We present methods for (i) data collection and dataset development; (ii) descriptive analysis of each event type and its characteristics at different spatiotemporal levels; (iii) feature analysis and selection based on correlation coefficient analysis and feature importance analysis; and (iv) development of prediction models for the likelihood of occurrence of each event type at different temporal and spatial resolutions. We analyze the association of event types with socioeconomic and demographic data at the neighborhood level, ide
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20844;&#20849;&#25968;&#25454;&#30340;&#35745;&#31639;&#39640;&#25928;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#28385;&#36275;&#24046;&#20998;&#38544;&#31169;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#31169;&#26377;&#25968;&#25454;&#65292;&#20197;&#25552;&#39640;&#23398;&#20064;&#31639;&#27861;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.09483</link><description>&lt;p&gt;
&#20855;&#26377;&#20844;&#20849;&#25968;&#25454;&#30340;Oracle-Efficient&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Oracle-Efficient Differentially Private Learning with Public Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09483
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20844;&#20849;&#25968;&#25454;&#30340;&#35745;&#31639;&#39640;&#25928;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#28385;&#36275;&#24046;&#20998;&#38544;&#31169;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#31169;&#26377;&#25968;&#25454;&#65292;&#20197;&#25552;&#39640;&#23398;&#20064;&#31639;&#27861;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#22312;&#38544;&#31169;&#32422;&#26463;&#19979;&#35768;&#22810;&#20989;&#25968;&#31867;&#30340;&#21487;&#23398;&#20064;&#24615;&#30340;&#32479;&#35745;&#19979;&#38480;&#65292;&#26368;&#36817;&#20986;&#29616;&#20102;&#21033;&#29992;&#20844;&#20849;&#25968;&#25454;&#25552;&#39640;&#31169;&#26377;&#23398;&#20064;&#31639;&#27861;&#24615;&#33021;&#30340;&#20852;&#36259;&#12290;&#22312;&#36825;&#31181;&#27169;&#22411;&#20013;&#65292;&#31639;&#27861;&#24517;&#39035;&#22987;&#32456;&#20445;&#35777;&#30456;&#23545;&#20110;&#31169;&#26377;&#26679;&#26412;&#30340;&#24046;&#20998;&#38544;&#31169;&#65292;&#24182;&#22312;&#31169;&#26377;&#25968;&#25454;&#20998;&#24067;&#19982;&#20844;&#20849;&#25968;&#25454;&#20998;&#24067;&#36275;&#22815;&#25509;&#36817;&#26102;&#30830;&#20445;&#23398;&#20064;&#20445;&#35777;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#24403;&#26377;&#36275;&#22815;&#30340;&#20844;&#20849;&#38750;&#26631;&#35760;&#25968;&#25454;&#26102;&#65292;&#21487;&#20197;&#20351;&#31169;&#26377;&#23398;&#20064;&#22312;&#32479;&#35745;&#19978;&#21487;&#20197;&#22788;&#29702;&#65292;&#20294;&#24471;&#21040;&#30340;&#31639;&#27861;&#37117;&#26159;&#35745;&#31639;&#25928;&#29575;&#20302;&#19979;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#31181;&#21487;&#35745;&#31639;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#20989;&#25968;&#31867;&#21487;&#38750;&#31169;&#26377;&#23398;&#20064;&#26102;&#26126;&#30830;&#21033;&#29992;&#20844;&#20849;&#25968;&#25454;&#36827;&#34892;&#31169;&#26377;&#23398;&#20064;&#65292;&#20854;&#20013;&#25105;&#20204;&#23545;&#35745;&#31639;&#25928;&#29575;&#30340;&#27010;&#24565;&#26159;&#30456;&#23545;&#20110;&#20248;&#21270;&#35843;&#29992;&#27425;&#25968;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09483v1 Announce Type: cross  Abstract: Due to statistical lower bounds on the learnability of many function classes under privacy constraints, there has been recent interest in leveraging public data to improve the performance of private learning algorithms. In this model, algorithms must always guarantee differential privacy with respect to the private samples while also ensuring learning guarantees when the private data distribution is sufficiently close to that of the public data. Previous work has demonstrated that when sufficient public, unlabelled data is available, private learning can be made statistically tractable, but the resulting algorithms have all been computationally inefficient. In this work, we present the first computationally efficient, algorithms to provably leverage public data to learn privately whenever a function class is learnable non-privately, where our notion of computational efficiency is with respect to the number of calls to an optimization o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21015;&#29983;&#25104;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#19968;&#23545;&#22810;&#21453;&#20107;&#23454;&#35299;&#37322;&#30340;&#38382;&#39064;&#12290;&#26694;&#26550;&#36890;&#36807;&#38480;&#21046;&#27599;&#20010;&#35299;&#37322;&#20013;&#21487;&#38598;&#20307;&#25913;&#21464;&#30340;&#29305;&#24449;&#25968;&#37327;&#65292;&#26088;&#22312;&#23613;&#21487;&#33021;&#23569;&#22320;&#20351;&#29992;&#35299;&#37322;&#26469;&#35299;&#37322;&#25152;&#26377;&#23454;&#20363;&#12290;&#30456;&#27604;&#20110;&#29616;&#26377;&#30340;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#26041;&#27861;&#65292;&#35813;&#26694;&#26550;&#22312;&#21487;&#25193;&#23637;&#24615;&#12289;&#35745;&#31639;&#24615;&#33021;&#21644;&#35299;&#20915;&#26041;&#26696;&#36136;&#37327;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2402.09473</link><description>&lt;p&gt;
&#21015;&#29983;&#25104;&#30340;&#19968;&#23545;&#22810;&#21453;&#20107;&#23454;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
One-for-many Counterfactual Explanations by Column Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09473
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21015;&#29983;&#25104;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#19968;&#23545;&#22810;&#21453;&#20107;&#23454;&#35299;&#37322;&#30340;&#38382;&#39064;&#12290;&#26694;&#26550;&#36890;&#36807;&#38480;&#21046;&#27599;&#20010;&#35299;&#37322;&#20013;&#21487;&#38598;&#20307;&#25913;&#21464;&#30340;&#29305;&#24449;&#25968;&#37327;&#65292;&#26088;&#22312;&#23613;&#21487;&#33021;&#23569;&#22320;&#20351;&#29992;&#35299;&#37322;&#26469;&#35299;&#37322;&#25152;&#26377;&#23454;&#20363;&#12290;&#30456;&#27604;&#20110;&#29616;&#26377;&#30340;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#26041;&#27861;&#65292;&#35813;&#26694;&#26550;&#22312;&#21487;&#25193;&#23637;&#24615;&#12289;&#35745;&#31639;&#24615;&#33021;&#21644;&#35299;&#20915;&#26041;&#26696;&#36136;&#37327;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#38382;&#39064;&#65292;&#21363;&#22914;&#20309;&#29983;&#25104;&#19968;&#32452;&#38024;&#23545;&#19968;&#32452;&#23454;&#20363;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#65292;&#37319;&#29992;&#19968;&#23545;&#22810;&#20998;&#37197;&#35268;&#21017;&#65292;&#20854;&#20013;&#19968;&#20010;&#35299;&#37322;&#34987;&#20998;&#37197;&#32473;&#19968;&#20010;&#23454;&#20363;&#23376;&#32452;&#12290;&#25105;&#20204;&#39318;&#27425;&#35299;&#20915;&#20102;&#22312;&#32771;&#34385;&#31232;&#30095;&#24615;&#30340;&#24773;&#20917;&#19979;&#26368;&#23567;&#21270;&#35299;&#37322;&#25152;&#38656;&#25968;&#37327;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#38480;&#21046;&#27599;&#20010;&#35299;&#37322;&#20013;&#20801;&#35768;&#38598;&#20307;&#25913;&#21464;&#30340;&#29305;&#24449;&#25968;&#37327;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#21015;&#29983;&#25104;&#26694;&#26550;&#65292;&#29992;&#20110;&#39640;&#25928;&#25628;&#32034;&#35299;&#37322;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#24212;&#29992;&#20110;&#20219;&#20309;&#40657;&#30418;&#20998;&#31867;&#22120;&#65292;&#22914;&#31070;&#32463;&#32593;&#32476;&#12290;&#19982;&#25991;&#29486;&#20013;&#30340;&#31616;&#21333;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#20844;&#24335;&#30340;&#31616;&#21333;&#36866;&#24212;&#30456;&#27604;&#65292;&#21015;&#29983;&#25104;&#26694;&#26550;&#22312;&#21487;&#25193;&#23637;&#24615;&#12289;&#35745;&#31639;&#24615;&#33021;&#21644;&#35299;&#20915;&#26041;&#26696;&#30340;&#36136;&#37327;&#26041;&#38754;&#21344;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09473v1 Announce Type: new  Abstract: In this paper, we consider the problem of generating a set of counterfactual explanations for a group of instances, with the one-for-many allocation rule, where one explanation is allocated to a subgroup of the instances. For the first time, we solve the problem of minimizing the number of explanations needed to explain all the instances, while considering sparsity by limiting the number of features allowed to be changed collectively in each explanation. A novel column generation framework is developed to efficiently search for the explanations. Our framework can be applied to any black-box classifier, like neural networks. Compared with a simple adaptation of a mixed-integer programming formulation from the literature, the column generation framework dominates in terms of scalability, computational performance and quality of the solutions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#28378;&#21160;&#25193;&#25955;&#27169;&#22411;&#65292;&#29992;&#20110;&#22788;&#29702;&#26102;&#38388;&#25968;&#25454;&#65292;&#36890;&#36807;&#28369;&#21160;&#31383;&#21475;&#21435;&#22122;&#24182;&#26681;&#25454;&#24103;&#22312;&#24207;&#21015;&#20013;&#30340;&#26102;&#38388;&#20808;&#21518;&#20998;&#37197;&#19981;&#21516;&#30340;&#22122;&#22768;&#37327;&#65292;&#26356;&#22909;&#22320;&#25429;&#25417;&#21040;&#22797;&#26434;&#30340;&#26102;&#38388;&#21160;&#24577;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#35270;&#39057;&#39044;&#27979;&#21644;&#28151;&#27788;&#27969;&#20307;&#21160;&#21147;&#23398;&#39044;&#27979;&#20219;&#21153;&#20013;&#65292;&#35813;&#27169;&#22411;&#20248;&#20110;&#20256;&#32479;&#25193;&#25955;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.09470</link><description>&lt;p&gt;
&#28378;&#21160;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Rolling Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09470
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#28378;&#21160;&#25193;&#25955;&#27169;&#22411;&#65292;&#29992;&#20110;&#22788;&#29702;&#26102;&#38388;&#25968;&#25454;&#65292;&#36890;&#36807;&#28369;&#21160;&#31383;&#21475;&#21435;&#22122;&#24182;&#26681;&#25454;&#24103;&#22312;&#24207;&#21015;&#20013;&#30340;&#26102;&#38388;&#20808;&#21518;&#20998;&#37197;&#19981;&#21516;&#30340;&#22122;&#22768;&#37327;&#65292;&#26356;&#22909;&#22320;&#25429;&#25417;&#21040;&#22797;&#26434;&#30340;&#26102;&#38388;&#21160;&#24577;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#35270;&#39057;&#39044;&#27979;&#21644;&#28151;&#27788;&#27969;&#20307;&#21160;&#21147;&#23398;&#39044;&#27979;&#20219;&#21153;&#20013;&#65292;&#35813;&#27169;&#22411;&#20248;&#20110;&#20256;&#32479;&#25193;&#25955;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#25193;&#25955;&#27169;&#22411;&#36234;&#26469;&#36234;&#22810;&#22320;&#24212;&#29992;&#20110;&#26102;&#38388;&#25968;&#25454;&#65292;&#22914;&#35270;&#39057;&#12289;&#27969;&#20307;&#21147;&#23398;&#27169;&#25311;&#25110;&#27668;&#20505;&#25968;&#25454;&#12290;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#23558;&#21518;&#32493;&#24103;&#22312;&#25193;&#25955;&#36807;&#31243;&#20013;&#30340;&#22122;&#22768;&#37327;&#35270;&#20026;&#30456;&#31561;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#28378;&#21160;&#25193;&#25955;&#65306;&#19968;&#31181;&#20351;&#29992;&#28369;&#21160;&#31383;&#21475;&#21435;&#22122;&#30340;&#26032;&#26041;&#27861;&#12290;&#23427;&#30830;&#20445;&#25193;&#25955;&#36807;&#31243;&#36880;&#28176;&#36890;&#36807;&#26102;&#38388;&#36827;&#34892;&#30772;&#22351;&#65292;&#36890;&#36807;&#23558;&#26356;&#22810;&#30340;&#22122;&#22768;&#20998;&#37197;&#32473;&#24207;&#21015;&#20013;&#20986;&#29616;&#36739;&#26202;&#30340;&#24103;&#65292;&#21453;&#26144;&#20986;&#38543;&#30528;&#29983;&#25104;&#36807;&#31243;&#30340;&#23637;&#24320;&#65292;&#23545;&#26410;&#26469;&#30340;&#19981;&#30830;&#23450;&#24615;&#36234;&#26469;&#36234;&#22823;&#12290;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#65292;&#25105;&#20204;&#34920;&#26126;&#24403;&#26102;&#38388;&#21160;&#24577;&#22797;&#26434;&#26102;&#65292;&#28378;&#21160;&#25193;&#25955;&#20248;&#20110;&#26631;&#20934;&#25193;&#25955;&#12290;&#29305;&#21035;&#26159;&#22312;&#20351;&#29992;Kinetics-600&#35270;&#39057;&#25968;&#25454;&#38598;&#36827;&#34892;&#35270;&#39057;&#39044;&#27979;&#20219;&#21153;&#21644;&#28151;&#27788;&#27969;&#20307;&#21160;&#21147;&#23398;&#39044;&#27979;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#36825;&#19968;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09470v1 Announce Type: new  Abstract: Diffusion models have recently been increasingly applied to temporal data such as video, fluid mechanics simulations, or climate data. These methods generally treat subsequent frames equally regarding the amount of noise in the diffusion process. This paper explores Rolling Diffusion: a new approach that uses a sliding window denoising process. It ensures that the diffusion process progressively corrupts through time by assigning more noise to frames that appear later in a sequence, reflecting greater uncertainty about the future as the generation process unfolds. Empirically, we show that when the temporal dynamics are complex, Rolling Diffusion is superior to standard diffusion. In particular, this result is demonstrated in a video prediction task using the Kinetics-600 video dataset and in a chaotic fluid dynamics forecasting experiment.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#31070;&#32463;&#32593;&#32476;&#21644;Transformer&#22312;&#25968;&#23398;&#25512;&#29702;&#21644;&#27169;&#36816;&#31639;&#20013;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#21644;&#21333;&#23618;Transformer&#22312;&#35299;&#20915;&#22797;&#26434;&#20195;&#25968;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#29305;&#24449;&#12290;&#38416;&#26126;&#20102;&#36793;&#32536;&#26368;&#22823;&#21270;&#21407;&#21017;&#23545;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.09469</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20613;&#31435;&#21494;&#30005;&#36335;&#65306;&#35299;&#38145;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#22312;&#25968;&#23398;&#25512;&#29702;&#21644;&#27169;&#36816;&#31639;&#20013;&#30340;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;
Fourier Circuits in Neural Networks: Unlocking the Potential of Large Language Models in Mathematical Reasoning and Modular Arithmetic
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09469
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#31070;&#32463;&#32593;&#32476;&#21644;Transformer&#22312;&#25968;&#23398;&#25512;&#29702;&#21644;&#27169;&#36816;&#31639;&#20013;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#21644;&#21333;&#23618;Transformer&#22312;&#35299;&#20915;&#22797;&#26434;&#20195;&#25968;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#29305;&#24449;&#12290;&#38416;&#26126;&#20102;&#36793;&#32536;&#26368;&#22823;&#21270;&#21407;&#21017;&#23545;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#19981;&#26029;&#21457;&#23637;&#30340;&#32972;&#26223;&#19979;&#65292;&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#21644;Transformer&#25152;&#21033;&#29992;&#30340;&#20869;&#37096;&#34920;&#31034;&#26159;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#12290;&#26412;&#30740;&#31350;&#22312;&#36817;&#26399;&#30340;&#30740;&#31350;&#22522;&#30784;&#19978;&#65292;&#23545;&#32593;&#32476;&#37319;&#29992;&#29305;&#23450;&#35745;&#31639;&#31574;&#30053;&#32972;&#21518;&#30340;&#21407;&#22240;&#36827;&#34892;&#20102;&#25506;&#32034;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32858;&#28966;&#20110;&#28041;&#21450;k&#20010;&#36755;&#20837;&#30340;&#22797;&#26434;&#20195;&#25968;&#23398;&#20064;&#20219;&#21153;&#65292;&#21363;&#27169;&#36816;&#31639;&#30340;&#21152;&#27861;&#12290;&#25105;&#20204;&#23545;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#21644;&#21333;&#23618;Transformer&#22312;&#35299;&#20915;&#36825;&#19968;&#20219;&#21153;&#20013;&#23398;&#21040;&#30340;&#29305;&#24449;&#36827;&#34892;&#20102;&#28145;&#20837;&#30340;&#20998;&#26512;&#12290;&#25105;&#20204;&#29702;&#35770;&#26694;&#26550;&#30340;&#19968;&#20010;&#20851;&#38190;&#26159;&#38416;&#26126;&#36793;&#32536;&#26368;&#22823;&#21270;&#21407;&#21017;&#23545;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#37319;&#29992;&#30340;&#29305;&#24449;&#30340;&#24433;&#21709;&#12290;&#20854;&#20013;&#65292;p&#34920;&#31034;&#27169;&#25968;&#65292;Dp&#34920;&#31034;k&#20010;&#36755;&#20837;&#30340;&#27169;&#36816;&#31639;&#25968;&#25454;&#38598;&#65292;m&#34920;&#31034;&#32593;&#32476;&#36755;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09469v1 Announce Type: new  Abstract: In the evolving landscape of machine learning, a pivotal challenge lies in deciphering the internal representations harnessed by neural networks and Transformers. Building on recent progress toward comprehending how networks execute distinct target functions, our study embarks on an exploration of the underlying reasons behind networks adopting specific computational strategies. We direct our focus to the complex algebraic learning task of modular addition involving $k$ inputs. Our research presents a thorough analytical characterization of the features learned by stylized one-hidden layer neural networks and one-layer Transformers in addressing this task.   A cornerstone of our theoretical framework is the elucidation of how the principle of margin maximization shapes the features adopted by one-hidden layer neural networks. Let $p$ denote the modulus, $D_p$ denote the dataset of modular arithmetic with $k$ inputs and $m$ denote the net
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#22266;&#23450;&#32622;&#20449;&#24230;&#30340;&#38543;&#26426;&#32447;&#24615;&#36172;&#21338;&#26426;&#30340;&#949;-&#38408;&#20540;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#28176;&#36817;&#24847;&#20041;&#19978;&#26159;&#26368;&#20248;&#30340;&#31639;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.09467</link><description>&lt;p&gt;
&#26368;&#20248;&#38408;&#20540;&#32447;&#24615;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
Optimal Thresholding Linear Bandit
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09467
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#22266;&#23450;&#32622;&#20449;&#24230;&#30340;&#38543;&#26426;&#32447;&#24615;&#36172;&#21338;&#26426;&#30340;&#949;-&#38408;&#20540;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#28176;&#36817;&#24847;&#20041;&#19978;&#26159;&#26368;&#20248;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#32431;&#25506;&#32034;&#38382;&#39064;&#65306;&#20855;&#26377;&#22266;&#23450;&#32622;&#20449;&#24230;&#30340;&#38543;&#26426;&#32447;&#24615;&#36172;&#21338;&#26426;&#30340;&#949;-&#38408;&#20540;&#36172;&#21338;&#26426;&#38382;&#39064;(TBP)&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#19979;&#30028;&#65292;&#24182;&#23558;&#35774;&#35745;&#29992;&#20110;&#32447;&#24615;&#24773;&#20917;&#19979;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#31639;&#27861;&#25193;&#23637;&#21040;&#20102;TBP&#65292;&#35813;&#31639;&#27861;&#22312;&#28176;&#36817;&#24847;&#20041;&#19978;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09467v1 Announce Type: cross  Abstract: We study a novel pure exploration problem: the $\epsilon$-Thresholding Bandit Problem (TBP) with fixed confidence in stochastic linear bandits. We prove a lower bound for the sample complexity and extend an algorithm designed for Best Arm Identification in the linear case to TBP that is asymptotically optimal.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26410;&#30693;&#21338;&#24328;&#20013;&#36827;&#34892;&#26080;&#36951;&#25022;&#23398;&#20064;&#30340;&#20048;&#35266;&#30340;&#27748;&#26222;&#26862;&#25277;&#26679;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#23545;&#25163;&#30340;&#34892;&#21160;&#21644;&#22870;&#21169;&#32467;&#26500;&#20449;&#24687;&#65292;&#26174;&#33879;&#20943;&#23569;&#20102;&#23454;&#39564;&#39044;&#31639;&#65292;&#25104;&#21151;&#22320;&#32531;&#35299;&#20102;&#22810;&#26426;&#26500;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#24341;&#20837;&#20102;&#20048;&#35266;-&#26080;&#36951;&#25022;&#26694;&#26550;&#65292;&#23558;&#29616;&#26377;&#31639;&#27861;&#19982;&#25552;&#20986;&#30340;&#26041;&#27861;&#30456;&#32467;&#21512;&#12290;</title><link>https://arxiv.org/abs/2402.09456</link><description>&lt;p&gt;
&#26410;&#30693;&#21338;&#24328;&#20013;&#20048;&#35266;&#30340;&#27748;&#26222;&#26862;&#25277;&#26679;&#26041;&#27861;&#29992;&#20110;&#26080;&#36951;&#25022;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Optimistic Thompson Sampling for No-Regret Learning in Unknown Games
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09456
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26410;&#30693;&#21338;&#24328;&#20013;&#36827;&#34892;&#26080;&#36951;&#25022;&#23398;&#20064;&#30340;&#20048;&#35266;&#30340;&#27748;&#26222;&#26862;&#25277;&#26679;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#23545;&#25163;&#30340;&#34892;&#21160;&#21644;&#22870;&#21169;&#32467;&#26500;&#20449;&#24687;&#65292;&#26174;&#33879;&#20943;&#23569;&#20102;&#23454;&#39564;&#39044;&#31639;&#65292;&#25104;&#21151;&#22320;&#32531;&#35299;&#20102;&#22810;&#26426;&#26500;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#24341;&#20837;&#20102;&#20048;&#35266;-&#26080;&#36951;&#25022;&#26694;&#26550;&#65292;&#23558;&#29616;&#26377;&#31639;&#27861;&#19982;&#25552;&#20986;&#30340;&#26041;&#27861;&#30456;&#32467;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#28041;&#21450;&#22810;&#20010;&#20915;&#31574;&#32773;&#30340;&#30495;&#23454;&#19990;&#30028;&#38382;&#39064;&#21487;&#20197;&#24314;&#27169;&#20026;&#19968;&#20010;&#20855;&#26377;&#37096;&#20998;&#35266;&#27979;&#30340;&#26410;&#30693;&#21338;&#24328;&#12290;&#20026;&#20102;&#35299;&#20915;&#37096;&#20998;&#20449;&#24687;&#21644;&#22810;&#26426;&#26500;&#30340;&#25361;&#25112;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#27748;&#26222;&#26862;&#25277;&#26679;&#31867;&#22411;&#30340;&#31639;&#27861;&#65292;&#21033;&#29992;&#23545;&#25163;&#30340;&#34892;&#21160;&#21644;&#22870;&#21169;&#32467;&#26500;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#22914;&#20132;&#36890;&#36335;&#30001;&#21644;&#38647;&#36798;&#24863;&#30693;&#20013;&#65292;&#26174;&#33879;&#20943;&#23569;&#20102;&#23454;&#39564;&#39044;&#31639;&#65292;&#19982;&#22522;&#20934;&#31639;&#27861;&#30456;&#27604;&#65292;&#20943;&#23569;&#20102;&#21313;&#20493;&#20197;&#19978;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#23545;&#22870;&#21169;&#32467;&#26500;&#26377;&#19968;&#23450;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#36951;&#25022;&#30028;&#38480;&#20165;&#23545;&#24635;&#34892;&#21160;&#31354;&#38388;&#22823;&#23567;&#21576;&#23545;&#25968;&#20381;&#36182;&#65292;&#26377;&#25928;&#32531;&#35299;&#20102;&#22810;&#26426;&#26500;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#20048;&#35266;-&#26080;&#36951;&#25022;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#23558;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#21644;&#39046;&#22495;&#20869;&#29616;&#26377;&#30340;&#31639;&#27861;&#30456;&#32467;&#21512;&#65292;&#26159;&#19968;&#39033;&#26032;&#30340;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09456v1 Announce Type: cross  Abstract: Many real-world problems involving multiple decision-makers can be modeled as an unknown game characterized by partial observations. Addressing the challenges posed by partial information and the curse of multi-agency, we developed Thompson sampling-type algorithms, leveraging information about opponent's action and reward structures. Our approach significantly reduces experimental budgets, achieving a more than tenfold reduction compared to baseline algorithms in practical applications like traffic routing and radar sensing. We demonstrate that, under certain assumptions about the reward structure, the regret bound exhibits merely a logarithmic dependence on the total action space size, effectively mitigating the curse of multi-agency. Additionally, this research introduces the Optimism-then-NoRegret framework, a novel contribution that integrates both our proposed methodologies and existing algorithms in the field.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#23545;&#25239;&#24615;&#20581;&#22766;&#30340;&#20048;&#35266;MLE&#65288;CR-OMLE&#65289;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#27169;&#22411;&#39537;&#21160;&#24378;&#21270;&#23398;&#20064;&#20013;&#23545;&#25239;&#24615;&#30772;&#22351;&#30340;&#25361;&#25112;&#65292;&#23454;&#29616;&#20102;&#23545;&#36716;&#31227;&#27169;&#22411;&#30340;&#20581;&#22766;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2402.08991</link><description>&lt;p&gt;
&#38754;&#21521;&#23545;&#25239;&#24615;&#30772;&#22351;&#30340;&#20581;&#22766;&#27169;&#22411;&#39537;&#21160;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Towards Robust Model-Based Reinforcement Learning Against Adversarial Corruption
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08991
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#23545;&#25239;&#24615;&#20581;&#22766;&#30340;&#20048;&#35266;MLE&#65288;CR-OMLE&#65289;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#27169;&#22411;&#39537;&#21160;&#24378;&#21270;&#23398;&#20064;&#20013;&#23545;&#25239;&#24615;&#30772;&#22351;&#30340;&#25361;&#25112;&#65292;&#23454;&#29616;&#20102;&#23545;&#36716;&#31227;&#27169;&#22411;&#30340;&#20581;&#22766;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35299;&#20915;&#20102;&#27169;&#22411;&#39537;&#21160;&#24378;&#21270;&#23398;&#20064;&#20013;&#23545;&#25239;&#24615;&#30772;&#22351;&#30340;&#25361;&#25112;&#65292;&#20854;&#20013;&#36716;&#31227;&#21160;&#21147;&#23398;&#21487;&#20197;&#34987;&#23545;&#25163;&#30772;&#22351;&#12290;&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#27169;&#22411;&#26080;&#20851;&#24378;&#21270;&#23398;&#20064;&#30340;&#24773;&#26223;&#19979;&#65292;&#36890;&#24120;&#37319;&#29992;&#20581;&#22766;&#30340;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#26469;&#36827;&#34892;&#20540;&#20989;&#25968;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#25216;&#26415;&#19981;&#33021;&#30452;&#25509;&#24212;&#29992;&#20110;&#27169;&#22411;&#39537;&#21160;&#30340;&#24378;&#21270;&#23398;&#20064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#27169;&#22411;&#39537;&#21160;&#30340;&#24378;&#21270;&#23398;&#20064;&#65292;&#24182;&#37319;&#29992;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65288;MLE&#65289;&#26041;&#27861;&#26469;&#23398;&#20064;&#36716;&#31227;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#28085;&#30422;&#20102;&#22312;&#32447;&#21644;&#31163;&#32447;&#20004;&#31181;&#24773;&#20917;&#12290;&#22312;&#22312;&#32447;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;&#23545;&#25239;&#24615;&#20581;&#22766;&#30340;&#20048;&#35266;MLE&#65288;CR-OMLE&#65289;&#30340;&#31639;&#27861;&#65292;&#23427;&#21033;&#29992;&#22522;&#20110;&#24635;&#21464;&#24046;&#65288;TV&#65289;&#30340;&#20449;&#24687;&#27604;&#29575;&#20316;&#20026;MLE&#30340;&#19981;&#30830;&#23450;&#26435;&#37325;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;CR-OMLE&#30340;&#36951;&#25022;&#24230;&#20026;$ \tilde {\mathcal {O}}&#65288;\sqrt {T} + C&#65289;$&#65292;&#20854;&#20013;$ C $&#34920;&#31034;&#32463;&#36807;$ T $&#20010;&#22238;&#21512;&#21518;&#30340;&#32047;&#35745;&#30772;&#22351;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08991v1 Announce Type: cross Abstract: This study tackles the challenges of adversarial corruption in model-based reinforcement learning (RL), where the transition dynamics can be corrupted by an adversary. Existing studies on corruption-robust RL mostly focus on the setting of model-free RL, where robust least-square regression is often employed for value function estimation. However, these techniques cannot be directly applied to model-based RL. In this paper, we focus on model-based RL and take the maximum likelihood estimation (MLE) approach to learn transition model. Our work encompasses both online and offline settings. In the online setting, we introduce an algorithm called corruption-robust optimistic MLE (CR-OMLE), which leverages total-variation (TV)-based information ratios as uncertainty weights for MLE. We prove that CR-OMLE achieves a regret of $\tilde{\mathcal{O}}(\sqrt{T} + C)$, where $C$ denotes the cumulative corruption level after $T$ episodes. We also pro
&lt;/p&gt;</description></item><item><title>&#20462;&#27491;&#20102;&#12298;&#23545;&#20110;&#25968;&#20540;&#36924;&#36817;&#36941;&#21382;SDE&#30340;&#20998;&#24067;&#30340;Wasserstein&#36317;&#31163;&#20272;&#35745;&#12299;&#20013;&#30340;&#38169;&#35823;&#23616;&#37096;&#35823;&#24046;&#20272;&#35745;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#20998;&#26512;&#25968;&#20540;&#31163;&#25955;&#36941;&#21382;SDE&#30340;Wasserstein-2&#36317;&#31163;&#30340;&#38750;&#28176;&#36817;&#20445;&#35777;&#65292;&#24182;&#35299;&#20915;&#20102;&#23454;&#36341;&#20013;&#32500;&#24230;&#20381;&#36182;&#24615;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.08711</link><description>&lt;p&gt;
&#12298;&#23545;&#20110;&#25968;&#20540;&#36924;&#36817;&#36941;&#21382;SDE&#30340;&#20998;&#24067;&#30340;Wasserstein&#36317;&#31163;&#20272;&#35745;&#12299;&#20462;&#27491;
&lt;/p&gt;
&lt;p&gt;
Correction to "Wasserstein distance estimates for the distributions of numerical approximations to ergodic stochastic differential equations"
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08711
&lt;/p&gt;
&lt;p&gt;
&#20462;&#27491;&#20102;&#12298;&#23545;&#20110;&#25968;&#20540;&#36924;&#36817;&#36941;&#21382;SDE&#30340;&#20998;&#24067;&#30340;Wasserstein&#36317;&#31163;&#20272;&#35745;&#12299;&#20013;&#30340;&#38169;&#35823;&#23616;&#37096;&#35823;&#24046;&#20272;&#35745;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#20998;&#26512;&#25968;&#20540;&#31163;&#25955;&#36941;&#21382;SDE&#30340;Wasserstein-2&#36317;&#31163;&#30340;&#38750;&#28176;&#36817;&#20445;&#35777;&#65292;&#24182;&#35299;&#20915;&#20102;&#23454;&#36341;&#20013;&#32500;&#24230;&#20381;&#36182;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;San-Serna&#21644;Zygalakis&#30340;&#12298;&#23545;&#20110;&#25968;&#20540;&#36924;&#36817;&#36941;&#21382;SDE&#30340;&#20998;&#24067;&#30340;Wasserstein&#36317;&#31163;&#20272;&#35745;&#12299;&#20013;&#30340;&#38750;&#28176;&#36817;&#20445;&#35777;&#25968;&#20540;&#31163;&#25955;&#20998;&#26512;&#26041;&#27861;&#36827;&#34892;&#20102;&#20462;&#27491;&#12290;&#20182;&#20204;&#20998;&#26512;&#20102;UBU&#31215;&#20998;&#22120;&#65292;&#35813;&#31215;&#20998;&#22120;&#26159;&#20108;&#38454;&#24378;&#22411;&#30340;&#65292;&#24182;&#19988;&#27599;&#20010;&#27493;&#39588;&#21482;&#38656;&#35201;&#19968;&#27425;&#26799;&#24230;&#35780;&#20272;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#29702;&#24819;&#30340;&#38750;&#28176;&#36817;&#20445;&#35777;&#65292;&#29305;&#21035;&#26159;&#22312;Wasserstein-2&#36317;&#31163;&#20013;&#21040;&#36798;&#31163;&#30446;&#26631;&#20998;&#24067; $\epsilon &gt; 0$ &#30340;&#36317;&#31163;&#20165;&#38656; $\mathcal{O}(d^{1/4}\epsilon^{-1/2})$ &#27493;&#12290;&#28982;&#32780;&#65292;Sanz-Serna&#21644;Zygalakis (2021)&#20013;&#30340;&#23616;&#37096;&#35823;&#24046;&#20272;&#35745;&#23384;&#22312;&#38169;&#35823;&#65292;&#22312;&#23454;&#36341;&#20013;&#38656;&#35201;&#26356;&#24378;&#30340;&#20551;&#35774;&#25165;&#33021;&#23454;&#29616;&#36825;&#20123;&#22797;&#26434;&#24230;&#20272;&#35745;&#12290;&#26412;&#25991;&#35299;&#20915;&#20102;&#29702;&#35770;&#19982;&#23454;&#36341;&#20013;&#35266;&#23519;&#21040;&#30340;&#35768;&#22810;&#24212;&#29992;&#22330;&#26223;&#20013;&#30340;&#32500;&#24230;&#20381;&#36182;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08711v1 Announce Type: cross Abstract: A method for analyzing non-asymptotic guarantees of numerical discretizations of ergodic SDEs in Wasserstein-2 distance is presented by Sanz-Serna and Zygalakis in ``Wasserstein distance estimates for the distributions of numerical approximations to ergodic stochastic differential equations". They analyze the UBU integrator which is strong order two and only requires one gradient evaluation per step, resulting in desirable non-asymptotic guarantees, in particular $\mathcal{O}(d^{1/4}\epsilon^{-1/2})$ steps to reach a distance of $\epsilon &gt; 0$ in Wasserstein-2 distance away from the target distribution. However, there is a mistake in the local error estimates in Sanz-Serna and Zygalakis (2021), in particular, a stronger assumption is needed to achieve these complexity estimates. This note reconciles the theory with the dimension dependence observed in practice in many applications of interest.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;SeqRF&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#36890;&#36807;&#30452;&#32447;&#21270;&#27010;&#29575;&#27969;&#26469;&#20943;&#23567;&#20840;&#23616;&#25130;&#26029;&#35823;&#24046;&#65292;&#24182;&#20197;&#27492;&#21152;&#36895;&#21462;&#26679;&#21644;&#25552;&#39640;&#32508;&#21512;&#36136;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.06461</link><description>&lt;p&gt;
&#39034;&#24207;&#27969;&#21305;&#37197;&#29992;&#20110;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Sequential Flow Matching for Generative Modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06461
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;SeqRF&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#36890;&#36807;&#30452;&#32447;&#21270;&#27010;&#29575;&#27969;&#26469;&#20943;&#23567;&#20840;&#23616;&#25130;&#26029;&#35823;&#24046;&#65292;&#24182;&#20197;&#27492;&#21152;&#36895;&#21462;&#26679;&#21644;&#25552;&#39640;&#32508;&#21512;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30452;&#25509;&#24341;&#23548;&#36830;&#32493;&#26102;&#38388;&#29983;&#25104;&#27169;&#22411;&#65288;&#20363;&#22914;&#25193;&#25955;&#27169;&#22411;&#25110;&#22522;&#20110;&#27969;&#30340;&#27169;&#22411;&#65289;&#30340;&#27010;&#29575;&#27969;&#26159;&#36890;&#36807;&#25968;&#20540;&#35299;&#31639;&#22120;&#24555;&#36895;&#21462;&#26679;&#30340;&#20851;&#38190;&#12290;&#29616;&#26377;&#26041;&#27861;&#36890;&#36807;&#30452;&#25509;&#29983;&#25104;&#22122;&#22768;&#21644;&#25968;&#25454;&#20998;&#24067;&#20043;&#38388;&#30340;&#32852;&#21512;&#20998;&#24067;&#30340;&#27010;&#29575;&#36335;&#24452;&#26469;&#23398;&#20064;&#32447;&#24615;&#36335;&#24452;&#12290;ODE&#27169;&#22411;&#30340;&#20223;&#30495;&#36895;&#24230;&#24930;&#30340;&#19968;&#20010;&#37325;&#35201;&#21407;&#22240;&#26159;ODE&#36712;&#36857;&#30340;&#39640;&#26354;&#29575;&#23548;&#33268;&#30340;ODE&#27714;&#35299;&#22120;&#30340;&#20840;&#23616;&#25130;&#26029;&#35823;&#24046;&#65292;&#36825;&#20250;&#22312;&#20302;NFE&#33539;&#22260;&#20869;&#25918;&#22823;&#25968;&#20540;&#35299;&#31639;&#22120;&#30340;&#25130;&#26029;&#35823;&#24046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;SeqRF&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#26159;&#19968;&#31181;&#23398;&#20064;&#25216;&#26415;&#65292;&#29992;&#20110;&#30452;&#32447;&#21270;&#27010;&#29575;&#27969;&#20197;&#20943;&#23567;&#20840;&#23616;&#25130;&#26029;&#35823;&#24046;&#65292;&#20174;&#32780;&#21152;&#36895;&#21462;&#26679;&#24182;&#25552;&#39640;&#32508;&#21512;&#36136;&#37327;&#12290;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#35777;&#30740;&#31350;&#65292;&#25105;&#20204;&#39318;&#20808;&#35266;&#23519;&#21040;&#20102;SeqRF&#30340;&#30452;&#32447;&#21270;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Straightening the probability flow of the continuous-time generative models, such as diffusion models or flow-based models, is the key to fast sampling through the numerical solvers, existing methods learn a linear path by directly generating the probability path the joint distribution between the noise and data distribution. One key reason for the slow sampling speed of the ODE-based solvers that simulate these generative models is the global truncation error of the ODE solver, caused by the high curvature of the ODE trajectory, which explodes the truncation error of the numerical solvers in the low-NFE regime. To address this challenge, We propose a novel method called SeqRF, a learning technique that straightens the probability flow to reduce the global truncation error and hence enable acceleration of sampling and improve the synthesis quality. In both theoretical and empirical studies, we first observe the straightening property of our SeqRF. Through empirical evaluations via SeqR
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#32454;&#31890;&#24230;&#22797;&#26434;&#24615;&#20998;&#26512;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#29616;&#20195;Hopfield&#27169;&#22411;&#30340;&#35760;&#24518;&#26816;&#32034;&#35745;&#31639;&#38480;&#21046;&#65292;&#21457;&#29616;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#24335;&#33539;&#25968;&#30340;&#30456;&#21464;&#34892;&#20026;&#65292;&#24182;&#19988;&#24314;&#31435;&#20102;&#26377;&#25928;&#21464;&#20307;&#30340;&#19978;&#30028;&#26465;&#20214;&#12290;&#20351;&#29992;&#20302;&#31209;&#36924;&#36817;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#26377;&#25928;&#26500;&#36896;&#30340;&#31034;&#20363;&#65292;&#21516;&#26102;&#35777;&#26126;&#20102;&#35745;&#31639;&#26102;&#38388;&#19979;&#30028;&#12289;&#35760;&#24518;&#26816;&#32034;&#35823;&#24046;&#30028;&#21644;&#25351;&#25968;&#35760;&#24518;&#23481;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.04520</link><description>&lt;p&gt;
&#20851;&#20110;&#29616;&#20195;Hopfield&#27169;&#22411;&#35745;&#31639;&#38480;&#21046;&#30340;&#19968;&#20010;&#32454;&#31890;&#24230;&#22797;&#26434;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04520
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#32454;&#31890;&#24230;&#22797;&#26434;&#24615;&#20998;&#26512;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#29616;&#20195;Hopfield&#27169;&#22411;&#30340;&#35760;&#24518;&#26816;&#32034;&#35745;&#31639;&#38480;&#21046;&#65292;&#21457;&#29616;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#24335;&#33539;&#25968;&#30340;&#30456;&#21464;&#34892;&#20026;&#65292;&#24182;&#19988;&#24314;&#31435;&#20102;&#26377;&#25928;&#21464;&#20307;&#30340;&#19978;&#30028;&#26465;&#20214;&#12290;&#20351;&#29992;&#20302;&#31209;&#36924;&#36817;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#26377;&#25928;&#26500;&#36896;&#30340;&#31034;&#20363;&#65292;&#21516;&#26102;&#35777;&#26126;&#20102;&#35745;&#31639;&#26102;&#38388;&#19979;&#30028;&#12289;&#35760;&#24518;&#26816;&#32034;&#35823;&#24046;&#30028;&#21644;&#25351;&#25968;&#35760;&#24518;&#23481;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20174;&#32454;&#31890;&#24230;&#22797;&#26434;&#24615;&#20998;&#26512;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#29616;&#20195;Hopfield&#27169;&#22411;&#30340;&#35760;&#24518;&#26816;&#32034;&#21160;&#21147;&#23398;&#30340;&#35745;&#31639;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#22522;&#20110;&#27169;&#24335;&#30340;&#33539;&#25968;&#23545;&#25152;&#26377;&#21487;&#33021;&#30340;&#29616;&#20195;Hopfield&#27169;&#22411;&#30340;&#25928;&#29575;&#36827;&#34892;&#30456;&#21464;&#34892;&#20026;&#30340;&#21051;&#30011;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#23545;&#36755;&#20837;&#26597;&#35810;&#27169;&#24335;&#21644;&#35760;&#24518;&#27169;&#24335;&#30340;&#33539;&#25968;&#30340;&#19978;&#30028;&#26631;&#20934;&#12290;&#20165;&#22312;&#36825;&#20010;&#26631;&#20934;&#20043;&#19979;&#65292;&#20551;&#35774;&#28385;&#36275;Strong Exponential Time Hypothesis (SETH)&#65292;&#23384;&#22312;&#23376;&#20108;&#27425;&#65288;&#39640;&#25928;&#65289;&#21464;&#20307;&#30340;&#29616;&#20195;Hopfield&#27169;&#22411;&#12290;&#20026;&#20102;&#23637;&#31034;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#24403;&#26377;&#25928;&#26631;&#20934;&#25104;&#31435;&#26102;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#29616;&#20195;Hopfield&#27169;&#22411;&#20351;&#29992;&#20302;&#31209;&#36924;&#36817;&#30340;&#26377;&#25928;&#26500;&#36896;&#30340;&#27491;&#24335;&#31034;&#20363;&#12290;&#36825;&#21253;&#25324;&#19968;&#20010;&#35745;&#31639;&#26102;&#38388;&#30340;&#19979;&#30028;&#23548;&#20986;&#65292;&#19982;$\Max\{$&#23384;&#20648;&#30340;&#35760;&#24518;&#27169;&#24335;&#25968;&#37327;&#65292;&#36755;&#20837;&#26597;&#35810;&#24207;&#21015;&#30340;&#38271;&#24230;$\}$&#32447;&#24615;&#32553;&#25918;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35760;&#24518;&#26816;&#32034;&#35823;&#24046;&#30028;&#21644;&#25351;&#25968;&#35760;&#24518;&#23481;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the computational limits of the memory retrieval dynamics of modern Hopfield models from the fine-grained complexity analysis. Our key contribution is the characterization of a phase transition behavior in the efficiency of all possible modern Hopfield models based on the norm of patterns. Specifically, we establish an upper bound criterion for the norm of input query patterns and memory patterns. Only below this criterion, sub-quadratic (efficient) variants of the modern Hopfield model exist, assuming the Strong Exponential Time Hypothesis (SETH). To showcase our theory, we provide a formal example of efficient constructions of modern Hopfield models using low-rank approximation when the efficient criterion holds. This includes a derivation of a lower bound on the computational time, scaling linearly with $\Max\{$# of stored memory patterns, length of input query sequence$\}$. In addition, we prove its memory retrieval error bound and exponential memory capacity.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#27604;&#22522;&#20934;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#65292;&#23454;&#35777;&#27604;&#36739;&#20102;&#31361;&#21464;&#39564;&#35777;&#65288;MV&#65289;&#21644;&#20132;&#21449;&#39564;&#35777;&#65288;CV&#65289;&#22312;&#27169;&#22411;&#36873;&#25321;&#20013;&#30340;&#34920;&#29616;&#12290;&#32467;&#26524;&#21457;&#29616;&#65292;MV&#21644;CV&#22312;&#36873;&#25321;&#27169;&#22411;&#30340;&#27867;&#21270;&#24615;&#33021;&#26041;&#38754;&#22522;&#26412;&#31561;&#25928;&#65292;&#20294;MV&#22312;&#36873;&#25321;&#31616;&#21333;&#27169;&#22411;&#21644;&#35745;&#31639;&#25104;&#26412;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2311.14079</link><description>&lt;p&gt;
&#20132;&#21449;&#39564;&#35777;&#21644;&#31361;&#21464;&#39564;&#35777;&#22312;&#27169;&#22411;&#36873;&#25321;&#20013;&#30340;&#23454;&#35777;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Empirical Comparison between Cross-Validation and Mutation-Validation in Model Selection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.14079
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#27604;&#22522;&#20934;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#65292;&#23454;&#35777;&#27604;&#36739;&#20102;&#31361;&#21464;&#39564;&#35777;&#65288;MV&#65289;&#21644;&#20132;&#21449;&#39564;&#35777;&#65288;CV&#65289;&#22312;&#27169;&#22411;&#36873;&#25321;&#20013;&#30340;&#34920;&#29616;&#12290;&#32467;&#26524;&#21457;&#29616;&#65292;MV&#21644;CV&#22312;&#36873;&#25321;&#27169;&#22411;&#30340;&#27867;&#21270;&#24615;&#33021;&#26041;&#38754;&#22522;&#26412;&#31561;&#25928;&#65292;&#20294;MV&#22312;&#36873;&#25321;&#31616;&#21333;&#27169;&#22411;&#21644;&#35745;&#31639;&#25104;&#26412;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31361;&#21464;&#39564;&#35777;&#65288;MV&#65289;&#26159;&#19968;&#31181;&#36817;&#26399;&#25552;&#20986;&#30340;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#22240;&#20854;&#29420;&#29305;&#29305;&#24615;&#21644;&#28508;&#22312;&#30410;&#22788;&#32780;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#65292;&#19982;&#24191;&#27867;&#20351;&#29992;&#30340;&#20132;&#21449;&#39564;&#35777;&#65288;CV&#65289;&#26041;&#27861;&#30456;&#27604;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23545;MV&#21644;k&#25240;&#20132;&#21449;&#39564;&#35777;&#65288;CV&#65289;&#36827;&#34892;&#20102;&#22522;&#20934;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#30340;&#23454;&#35777;&#27604;&#36739;&#12290;&#36890;&#36807;&#20351;&#29992;&#36125;&#21494;&#26031;&#27979;&#35797;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#20135;&#29983;&#19977;&#20010;&#21518;&#39564;&#27010;&#29575;&#30340;&#27867;&#21270;&#20272;&#35745;&#65306;&#23454;&#38469;&#31561;&#25928;&#24615;&#12289;CV&#20248;&#21183;&#21644;MV&#20248;&#21183;&#12290;&#25105;&#20204;&#36824;&#35780;&#20272;&#20102;&#25152;&#36873;&#27169;&#22411;&#30340;&#33021;&#21147;&#24046;&#24322;&#21644;&#35745;&#31639;&#25928;&#29575;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21644;&#22823;&#22810;&#25968;&#22522;&#20934;&#25968;&#25454;&#38598;&#20013;&#65292;MV&#21644;CV&#37117;&#36873;&#25321;&#20855;&#26377;&#23454;&#38469;&#31561;&#25928;&#27867;&#21270;&#24615;&#33021;&#30340;&#27169;&#22411;&#12290;MV&#22312;&#36873;&#25321;&#36739;&#31616;&#21333;&#27169;&#22411;&#21644;&#36739;&#20302;&#35745;&#31639;&#25104;&#26412;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;&#28982;&#32780;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;MV&#36873;&#25321;&#36807;&#20110;&#31616;&#21333;&#30340;&#27169;&#22411;&#23548;&#33268;&#27424;&#25311;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.14079v2 Announce Type: replace  Abstract: Mutation validation (MV) is a recently proposed approach for model selection, garnering significant interest due to its unique characteristics and potential benefits compared to the widely used cross-validation (CV) method. In this study, we empirically compared MV and $k$-fold CV using benchmark and real-world datasets. By employing Bayesian tests, we compared generalization estimates yielding three posterior probabilities: practical equivalence, CV superiority, and MV superiority. We also evaluated the differences in the capacity of the selected models and computational efficiency. We found that both MV and CV select models with practically equivalent generalization performance across various machine learning algorithms and the majority of benchmark datasets. MV exhibited advantages in terms of selecting simpler models and lower computational costs. However, in some cases MV selected overly simplistic models leading to underfitting
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25935;&#24863;&#24615;&#26377;&#30028;&#30340;&#20010;&#24615;&#21270;PageRank&#31639;&#27861;&#65292;&#33021;&#22815;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#12290;&#35813;&#31639;&#27861;&#22312;&#20445;&#25345;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#65292;&#23454;&#29616;&#20102;&#24046;&#20998;&#38544;&#31169;&#22270;&#23398;&#20064;&#30340;&#20960;&#31181;&#24037;&#20855;&#12290;</title><link>https://arxiv.org/abs/2207.06944</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#22270;&#23398;&#20064;&#30340;&#25935;&#24863;&#24615;&#26377;&#30028;&#20010;&#24615;&#21270;PageRank&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Graph Learning via Sensitivity-Bounded Personalized PageRank
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2207.06944
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25935;&#24863;&#24615;&#26377;&#30028;&#30340;&#20010;&#24615;&#21270;PageRank&#31639;&#27861;&#65292;&#33021;&#22815;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#12290;&#35813;&#31639;&#27861;&#22312;&#20445;&#25345;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#65292;&#23454;&#29616;&#20102;&#24046;&#20998;&#38544;&#31169;&#22270;&#23398;&#20064;&#30340;&#20960;&#31181;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;PageRank(PPR)&#26159;&#19968;&#31181;&#22522;&#26412;&#24037;&#20855;&#65292;&#29992;&#20110;&#26080;&#30417;&#30563;&#23398;&#20064;&#22270;&#34920;&#31034;&#65292;&#22914;&#33410;&#28857;&#25490;&#24207;&#12289;&#26631;&#27880;&#21644;&#22270;&#23884;&#20837;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#25968;&#25454;&#38544;&#31169;&#25104;&#20026;&#26368;&#36817;&#26368;&#37325;&#35201;&#30340;&#20851;&#27880;&#28857;&#20043;&#19968;&#65292;&#29616;&#26377;&#30340;PPR&#31639;&#27861;&#24182;&#26410;&#35774;&#35745;&#29992;&#20110;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#12290;PPR&#23545;&#36755;&#20837;&#22270;&#30340;&#36793;&#38750;&#24120;&#25935;&#24863;&#65306;&#20165;&#24046;&#19968;&#20010;&#36793;&#30340;&#24046;&#24322;&#21487;&#33021;&#20250;&#23548;&#33268;PPR&#21521;&#37327;&#21457;&#29983;&#24040;&#22823;&#25913;&#21464;&#65292;&#20174;&#32780;&#21487;&#33021;&#27844;&#28431;&#29992;&#25143;&#31169;&#23494;&#25968;&#25454;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36755;&#20986;&#36817;&#20284;PPR&#65292;&#24182;&#23545;&#36755;&#20837;&#36793;&#20855;&#26377;&#21487;&#35777;&#26126;&#30340;&#25935;&#24863;&#24615;&#36793;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#36755;&#20837;&#22270;&#20855;&#26377;&#22823;&#24230;&#25968;&#26102;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#36798;&#21040;&#19982;&#38750;&#31169;&#23494;&#31639;&#27861;&#30456;&#20284;&#30340;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#25935;&#24863;&#24615;&#26377;&#30028;PPR&#30452;&#25509;&#24847;&#21619;&#30528;&#22270;&#23398;&#20064;&#30340;&#20960;&#31181;&#31169;&#23494;&#31639;&#27861;&#65292;&#22914;&#24046;&#20998;&#38544;&#31169;(DP)PPR&#25490;&#24207;&#12289;DP&#33410;&#28857;&#20998;&#31867;&#21644;DP&#33410;&#28857;&#23884;&#20837;&#12290;&#20026;&#20102;&#34917;&#20805;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#36824;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#23454;&#38469;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Personalized PageRank (PPR) is a fundamental tool in unsupervised learning of graph representations such as node ranking, labeling, and graph embedding. However, while data privacy is one of the most important recent concerns, existing PPR algorithms are not designed to protect user privacy. PPR is highly sensitive to the input graph edges: the difference of only one edge may cause a big change in the PPR vector, potentially leaking private user data.   In this work, we propose an algorithm which outputs an approximate PPR and has provably bounded sensitivity to input edges. In addition, we prove that our algorithm achieves similar accuracy to non-private algorithms when the input graph has large degrees. Our sensitivity-bounded PPR directly implies private algorithms for several tools of graph learning, such as, differentially private (DP) PPR ranking, DP node classification, and DP node embedding. To complement our theoretical analysis, we also empirically verify the practical perfor
&lt;/p&gt;</description></item><item><title>CLASSIX&#26159;&#19968;&#31181;&#24555;&#36895;&#21487;&#35299;&#37322;&#30340;&#32858;&#31867;&#31639;&#27861;&#65292;&#23427;&#36890;&#36807;&#25490;&#24207;&#21518;&#30340;&#25968;&#25454;&#30340;&#36138;&#23146;&#32858;&#21512;&#21644;&#32676;&#32452;&#21512;&#24182;&#26469;&#36827;&#34892;&#32858;&#31867;&#12290;&#35813;&#31639;&#27861;&#20855;&#26377;&#19982;&#26368;&#20808;&#36827;&#30340;&#32858;&#31867;&#31639;&#27861;&#30456;&#23218;&#32654;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#20855;&#26377;&#32447;&#24615;&#31354;&#38388;&#22797;&#26434;&#24615;&#21644;&#36817;&#32447;&#24615;&#26102;&#38388;&#22797;&#26434;&#24615;&#12290;</title><link>https://arxiv.org/abs/2202.01456</link><description>&lt;p&gt;
&#22522;&#20110;&#25490;&#24207;&#30340;&#24555;&#36895;&#21487;&#35299;&#37322;&#32858;&#31867;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Fast and explainable clustering based on sorting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2202.01456
&lt;/p&gt;
&lt;p&gt;
CLASSIX&#26159;&#19968;&#31181;&#24555;&#36895;&#21487;&#35299;&#37322;&#30340;&#32858;&#31867;&#31639;&#27861;&#65292;&#23427;&#36890;&#36807;&#25490;&#24207;&#21518;&#30340;&#25968;&#25454;&#30340;&#36138;&#23146;&#32858;&#21512;&#21644;&#32676;&#32452;&#21512;&#24182;&#26469;&#36827;&#34892;&#32858;&#31867;&#12290;&#35813;&#31639;&#27861;&#20855;&#26377;&#19982;&#26368;&#20808;&#36827;&#30340;&#32858;&#31867;&#31639;&#27861;&#30456;&#23218;&#32654;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#20855;&#26377;&#32447;&#24615;&#31354;&#38388;&#22797;&#26434;&#24615;&#21644;&#36817;&#32447;&#24615;&#26102;&#38388;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#24555;&#36895;&#21487;&#35299;&#37322;&#30340;&#32858;&#31867;&#26041;&#27861;&#65292;&#31216;&#20026;CLASSIX&#12290;&#23427;&#30001;&#20004;&#20010;&#38454;&#27573;&#32452;&#25104;&#65292;&#21363;&#23558;&#25490;&#24207;&#21518;&#30340;&#25968;&#25454;&#32858;&#21512;&#25104;&#38468;&#36817;&#25968;&#25454;&#28857;&#32452;&#25104;&#30340;&#32676;&#32452;&#30340;&#36138;&#23146;&#32858;&#21512;&#38454;&#27573;&#65292;&#28982;&#21518;&#23558;&#32676;&#32452;&#21512;&#24182;&#25104;&#32858;&#31867;&#12290;&#35813;&#31639;&#27861;&#30001;&#20004;&#20010;&#26631;&#37327;&#21442;&#25968;&#25511;&#21046;&#65292;&#19968;&#20010;&#26159;&#32858;&#21512;&#30340;&#36317;&#31163;&#21442;&#25968;&#65292;&#21478;&#19968;&#20010;&#26159;&#25511;&#21046;&#26368;&#23567;&#32858;&#31867;&#22823;&#23567;&#30340;&#21442;&#25968;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#39564;&#65292;&#23545;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#32858;&#31867;&#24615;&#33021;&#36827;&#34892;&#20102;&#20840;&#38754;&#35780;&#20272;&#65292;&#28085;&#30422;&#20102;&#21508;&#31181;&#32858;&#31867;&#24418;&#29366;&#21644;&#20302;&#21040;&#39640;&#30340;&#29305;&#24449;&#32500;&#24230;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;CLASSIX&#21487;&#20197;&#19982;&#26368;&#20808;&#36827;&#30340;&#32858;&#31867;&#31639;&#27861;&#31454;&#20105;&#12290;&#35813;&#31639;&#27861;&#20855;&#26377;&#32447;&#24615;&#31354;&#38388;&#22797;&#26434;&#24615;&#65292;&#22312;&#24191;&#27867;&#30340;&#38382;&#39064;&#33539;&#22260;&#20869;&#23454;&#29616;&#20102;&#25509;&#36817;&#32447;&#24615;&#30340;&#26102;&#38388;&#22797;&#26434;&#24615;&#12290;&#20854;&#22266;&#26377;&#30340;&#31616;&#21333;&#24615;&#20351;&#24471;&#21487;&#20197;&#29983;&#25104;&#23545;&#35745;&#31639;&#30340;&#32858;&#31867;&#30340;&#30452;&#35266;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2202.01456v2 Announce Type: replace  Abstract: We introduce a fast and explainable clustering method called CLASSIX. It consists of two phases, namely a greedy aggregation phase of the sorted data into groups of nearby data points, followed by the merging of groups into clusters. The algorithm is controlled by two scalar parameters, namely a distance parameter for the aggregation and another parameter controlling the minimal cluster size. Extensive experiments are conducted to give a comprehensive evaluation of the clustering performance on synthetic and real-world datasets, with various cluster shapes and low to high feature dimensionality. Our experiments demonstrate that CLASSIX competes with state-of-the-art clustering algorithms. The algorithm has linear space complexity and achieves near linear time complexity on a wide range of problems. Its inherent simplicity allows for the generation of intuitive explanations of the computed clusters.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#25105;&#30417;&#30563;&#30340;&#32467;&#26500;&#21270;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#20351;&#29992;&#26080;&#38656;&#27491;&#21017;&#21270;&#30340;&#33258;&#21160;&#32534;&#30721;&#22120;&#26550;&#26500;&#12290;&#36890;&#36807;&#20381;&#36182;&#28508;&#21464;&#37327;&#30340;&#29420;&#31435;&#24615;&#36827;&#34892;&#37319;&#26679;&#65292;&#25105;&#20204;&#36991;&#20813;&#20102;&#37325;&#26500;&#36136;&#37327;&#21644;&#29983;&#25104;&#24615;&#33021;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#33021;&#22815;&#23398;&#20064;&#20986;&#19968;&#31181;&#26377;&#24207;&#30340;&#32467;&#26500;&#21270;&#34920;&#31034;&#65292;&#25913;&#21892;&#20102;&#29983;&#25104;&#12289;&#35299;&#32544;&#21644;&#22806;&#25512;&#31561;&#22810;&#20010;&#19979;&#28216;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2006.07796</link><description>&lt;p&gt;
&#32467;&#26500;&#36890;&#36807;&#26550;&#26500;&#65306;&#26080;&#38656;&#27491;&#21017;&#21270;&#30340;&#32467;&#26500;&#21270;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Structure by Architecture: Structured Representations without Regularization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2006.07796
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#25105;&#30417;&#30563;&#30340;&#32467;&#26500;&#21270;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#20351;&#29992;&#26080;&#38656;&#27491;&#21017;&#21270;&#30340;&#33258;&#21160;&#32534;&#30721;&#22120;&#26550;&#26500;&#12290;&#36890;&#36807;&#20381;&#36182;&#28508;&#21464;&#37327;&#30340;&#29420;&#31435;&#24615;&#36827;&#34892;&#37319;&#26679;&#65292;&#25105;&#20204;&#36991;&#20813;&#20102;&#37325;&#26500;&#36136;&#37327;&#21644;&#29983;&#25104;&#24615;&#33021;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#33021;&#22815;&#23398;&#20064;&#20986;&#19968;&#31181;&#26377;&#24207;&#30340;&#32467;&#26500;&#21270;&#34920;&#31034;&#65292;&#25913;&#21892;&#20102;&#29983;&#25104;&#12289;&#35299;&#32544;&#21644;&#22806;&#25512;&#31561;&#22810;&#20010;&#19979;&#28216;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#33258;&#25105;&#30417;&#30563;&#32467;&#26500;&#21270;&#34920;&#31034;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#20351;&#29992;&#33258;&#21160;&#32534;&#30721;&#22120;&#36827;&#34892;&#19979;&#28216;&#20219;&#21153;&#65292;&#22914;&#29983;&#25104;&#27169;&#22411;&#12290;&#19982;&#22823;&#22810;&#25968;&#26041;&#27861;&#20381;&#36182;&#20110;&#21305;&#37197;&#20219;&#24847;&#30340;&#12289;&#30456;&#23545;&#38750;&#32467;&#26500;&#21270;&#30340;&#20808;&#39564;&#20998;&#24067;&#36827;&#34892;&#37319;&#26679;&#30340;&#24773;&#20917;&#19981;&#21516;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20165;&#20165;&#20381;&#36182;&#20110;&#28508;&#21464;&#37327;&#30340;&#29420;&#31435;&#24615;&#30340;&#37319;&#26679;&#25216;&#26415;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#22312;VAE&#20013;&#36890;&#24120;&#35266;&#23519;&#21040;&#30340;&#37325;&#26500;&#36136;&#37327;&#21644;&#29983;&#25104;&#24615;&#33021;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#33258;&#21160;&#32534;&#30721;&#22120;&#26550;&#26500;&#65292;&#33021;&#22815;&#23398;&#20064;&#20986;&#19968;&#31181;&#26080;&#38656;&#36807;&#24230;&#27491;&#21017;&#21270;&#30340;&#32467;&#26500;&#21270;&#34920;&#31034;&#12290;&#25105;&#20204;&#30340;&#32467;&#26500;&#35299;&#30721;&#22120;&#23398;&#20064;&#20102;&#19968;&#20010;&#23618;&#27425;&#30340;&#28508;&#21464;&#37327;&#65292;&#20174;&#32780;&#26080;&#38656;&#39069;&#22806;&#30340;&#27491;&#21017;&#21270;&#25110;&#30417;&#30563;&#26469;&#23545;&#20449;&#24687;&#36827;&#34892;&#25490;&#24207;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;&#36825;&#20123;&#27169;&#22411;&#22914;&#20309;&#23398;&#20064;&#20986;&#25913;&#21892;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#30340;&#34920;&#31034;&#65292;&#21253;&#25324;&#29983;&#25104;&#12289;&#35299;&#32544;&#21644;&#22806;&#25512;&#65292;&#20351;&#29992;&#20102;&#20960;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2006.07796v4 Announce Type: replace  Abstract: We study the problem of self-supervised structured representation learning using autoencoders for downstream tasks such as generative modeling. Unlike most methods which rely on matching an arbitrary, relatively unstructured, prior distribution for sampling, we propose a sampling technique that relies solely on the independence of latent variables, thereby avoiding the trade-off between reconstruction quality and generative performance typically observed in VAEs. We design a novel autoencoder architecture capable of learning a structured representation without the need for aggressive regularization. Our structural decoders learn a hierarchy of latent variables, thereby ordering the information without any additional regularization or supervision. We demonstrate how these models learn a representation that improves results in a variety of downstream tasks including generation, disentanglement, and extrapolation using several challengi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22240;&#26524;&#30456;&#20284;&#24615;&#30340;&#20998;&#23618;&#36125;&#21494;&#26031;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#22914;&#20309;&#20174;&#20855;&#26377;&#30456;&#20284;&#22240;&#26524;&#26426;&#21046;&#30340;&#35757;&#32451;&#20219;&#21153;&#20013;&#27719;&#38598;&#25968;&#25454;&#26469;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#23545;&#26032;&#20219;&#21153;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.12595</link><description>&lt;p&gt;
&#22522;&#20110;&#22240;&#26524;&#30456;&#20284;&#24615;&#30340;&#20998;&#23618;&#36125;&#21494;&#26031;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Causal Similarity-Based Hierarchical Bayesian Models. (arXiv:2310.12595v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12595
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22240;&#26524;&#30456;&#20284;&#24615;&#30340;&#20998;&#23618;&#36125;&#21494;&#26031;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#22914;&#20309;&#20174;&#20855;&#26377;&#30456;&#20284;&#22240;&#26524;&#26426;&#21046;&#30340;&#35757;&#32451;&#20219;&#21153;&#20013;&#27719;&#38598;&#25968;&#25454;&#26469;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#23545;&#26032;&#20219;&#21153;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#30340;&#20851;&#38190;&#25361;&#25112;&#26159;&#23545;&#26032;&#25968;&#25454;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#23545;&#30001;&#30456;&#20851;&#20219;&#21153;&#32452;&#25104;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#27867;&#21270;&#30340;&#38382;&#39064;&#65292;&#36825;&#20123;&#20219;&#21153;&#21487;&#33021;&#22312;&#22240;&#26524;&#26426;&#21046;&#19978;&#23384;&#22312;&#24046;&#24322;&#12290;&#20363;&#22914;&#65292;&#22797;&#26434;&#30142;&#30149;&#30340;&#35266;&#23519;&#24615;&#21307;&#23398;&#25968;&#25454;&#22312;&#19981;&#21516;&#24739;&#32773;&#38388;&#20855;&#26377;&#30142;&#30149;&#22240;&#26524;&#26426;&#21046;&#30340;&#24322;&#36136;&#24615;&#65292;&#36825;&#32473;&#38656;&#35201;&#23545;&#35757;&#32451;&#25968;&#25454;&#38598;&#20043;&#22806;&#30340;&#26032;&#24739;&#32773;&#36827;&#34892;&#27867;&#21270;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#24102;&#26469;&#20102;&#25361;&#25112;&#12290;&#24120;&#29992;&#30340;&#22788;&#29702;&#24322;&#36136;&#24615;&#25968;&#25454;&#38598;&#30340;&#26041;&#27861;&#21253;&#25324;&#20026;&#25972;&#20010;&#25968;&#25454;&#38598;&#23398;&#20064;&#19968;&#20010;&#20840;&#23616;&#27169;&#22411;&#65292;&#20026;&#27599;&#20010;&#20219;&#21153;&#30340;&#25968;&#25454;&#23398;&#20064;&#26412;&#22320;&#27169;&#22411;&#65292;&#25110;&#32773;&#21033;&#29992;&#20998;&#23618;&#12289;&#20803;&#23398;&#20064;&#21644;&#22810;&#20219;&#21153;&#23398;&#20064;&#26041;&#27861;&#20174;&#27719;&#38598;&#30340;&#22810;&#20010;&#20219;&#21153;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#27867;&#21270;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#22240;&#26524;&#30456;&#20284;&#24615;&#30340;&#20998;&#23618;&#36125;&#21494;&#26031;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#22914;&#20309;&#20174;&#20855;&#26377;&#30456;&#20284;&#22240;&#26524;&#26426;&#21046;&#30340;&#35757;&#32451;&#20219;&#21153;&#20013;&#27719;&#38598;&#25968;&#25454;&#26469;&#25552;&#39640;&#23545;&#26032;&#20219;&#21153;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#24212;&#29992;&#36825;&#31181;&#36890;&#29992;&#24314;&#27169;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
The key challenge underlying machine learning is generalisation to new data. This work studies generalisation for datasets consisting of related tasks that may differ in causal mechanisms. For example, observational medical data for complex diseases suffers from heterogeneity in causal mechanisms of disease across patients, creating challenges for machine learning algorithms that need to generalise to new patients outside of the training dataset. Common approaches for learning supervised models with heterogeneous datasets include learning a global model for the entire dataset, learning local models for each tasks' data, or utilising hierarchical, meta-learning and multi-task learning approaches to learn how to generalise from data pooled across multiple tasks. In this paper we propose causal similarity-based hierarchical Bayesian models to improve generalisation to new tasks by learning how to pool data from training tasks with similar causal mechanisms. We apply this general modelling
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#23558;&#26080;&#26631;&#35760;&#30340;&#22495;&#22806;&#25968;&#25454;&#32435;&#20837;&#21322;&#30417;&#30563;&#20998;&#31867;&#38382;&#39064;&#65292;&#20174;&#32780;&#25913;&#21892;&#27867;&#21270;&#33021;&#21147;&#12290;&#35813;&#26694;&#26550;&#32467;&#21512;&#20102;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#19982;&#33258;&#30417;&#30563;&#35757;&#32451;&#65292;&#24182;&#21033;&#29992;&#20102;&#39640;&#25928;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#35813;&#26694;&#26550;&#22312;&#39640;&#26031;&#28151;&#21512;&#20998;&#31867;&#38382;&#39064;&#20013;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2310.00027</link><description>&lt;p&gt;
&#26080;&#26631;&#35760;&#30340;&#22495;&#22806;&#25968;&#25454;&#25913;&#21892;&#20102;&#27867;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Unlabeled Out-Of-Domain Data Improves Generalization. (arXiv:2310.00027v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00027
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#23558;&#26080;&#26631;&#35760;&#30340;&#22495;&#22806;&#25968;&#25454;&#32435;&#20837;&#21322;&#30417;&#30563;&#20998;&#31867;&#38382;&#39064;&#65292;&#20174;&#32780;&#25913;&#21892;&#27867;&#21270;&#33021;&#21147;&#12290;&#35813;&#26694;&#26550;&#32467;&#21512;&#20102;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#19982;&#33258;&#30417;&#30563;&#35757;&#32451;&#65292;&#24182;&#21033;&#29992;&#20102;&#39640;&#25928;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#35813;&#26694;&#26550;&#22312;&#39640;&#26031;&#28151;&#21512;&#20998;&#31867;&#38382;&#39064;&#20013;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#26080;&#26631;&#35760;&#25968;&#25454;&#32435;&#20837;&#21322;&#30417;&#30563;&#20998;&#31867;&#38382;&#39064;&#30340;&#26032;&#26694;&#26550;&#65292;&#20854;&#20013;&#32771;&#34385;&#20102;&#26368;&#23567;&#21270;&#40065;&#26834;&#24615;&#25439;&#22833;&#20989;&#25968;&#25110;&#38750;&#40065;&#26834;&#24615;&#25439;&#22833;&#20989;&#25968;&#30340;&#24773;&#26223;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#20801;&#35768;&#26080;&#26631;&#35760;&#26679;&#26412;&#22312;&#24635;&#21464;&#24046;&#24847;&#20041;&#19978;&#30053;&#24494;&#20559;&#31163;&#22495;&#20869;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#30340;&#26680;&#24515;&#24605;&#24819;&#26159;&#23558;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;DRO&#65289;&#19982;&#33258;&#30417;&#30563;&#35757;&#32451;&#30456;&#32467;&#21512;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#36824;&#21033;&#29992;&#20102;&#35757;&#32451;&#38454;&#27573;&#30340;&#39640;&#25928;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#12290;&#20174;&#29702;&#35770;&#19978;&#35762;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26694;&#26550;&#24212;&#29992;&#20110;&#22312;$\mathbb{R}^d$&#20013;&#30340;&#20004;&#20010;&#39640;&#26031;&#28151;&#21512;&#20998;&#31867;&#38382;&#39064;&#65292;&#38500;&#20102;&#26469;&#33258;&#30495;&#23454;&#20998;&#24067;&#30340;$m$&#20010;&#29420;&#31435;&#26631;&#35760;&#26679;&#26412;&#20043;&#22806;&#65292;&#36824;&#32473;&#20986;&#20102;&#19968;&#32452;$n$&#20010;&#65288;&#36890;&#24120;$n\gg m$&#65289;&#22495;&#22806;&#21644;&#26080;&#26631;&#35760;&#26679;&#26412;&#12290;&#24050;&#30693;&#20165;&#20351;&#29992;&#26631;&#35760;&#25968;&#25454;&#65292;&#27867;&#21270;&#35823;&#24046;&#21487;&#20197;&#36890;&#36807;$\propto\left(d/m\right)$&#36827;&#34892;&#30028;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel framework for incorporating unlabeled data into semi-supervised classification problems, where scenarios involving the minimization of either i) adversarially robust or ii) non-robust loss functions have been considered. Notably, we allow the unlabeled samples to deviate slightly (in total variation sense) from the in-domain distribution. The core idea behind our framework is to combine Distributionally Robust Optimization (DRO) with self-supervised training. As a result, we also leverage efficient polynomial-time algorithms for the training stage. From a theoretical standpoint, we apply our framework on the classification problem of a mixture of two Gaussians in $\mathbb{R}^d$, where in addition to the $m$ independent and labeled samples from the true distribution, a set of $n$ (usually with $n\gg m$) out of domain and unlabeled samples are gievn as well. Using only the labeled data, it is known that the generalization error can be bounded by $\propto\left(d/m\right
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20132;&#20114;&#23398;&#20064;&#21644;&#25512;&#33616;&#31995;&#32479;&#20013;&#38544;&#31169;&#20445;&#25252;&#30340;Bandit&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#38598;&#20013;&#24046;&#20998;&#38544;&#31169;&#30340;&#27010;&#24565;&#12290;&#36890;&#36807;&#25552;&#20379;&#20851;&#20110;&#26377;&#38480;&#33218;&#21644;&#32447;&#24615;Bandit&#38382;&#39064;&#36951;&#25022;&#30340;&#19979;&#30028;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#19981;&#21516;&#38544;&#31169;&#39044;&#31639;&#19979;&#30340;&#38590;&#24230;&#21306;&#22495;&#65292;&#24182;&#21457;&#29616;&#38598;&#20013;&#24046;&#20998;&#38544;&#31169;&#21487;&#20197;&#27604;&#20840;&#23616;&#24046;&#20998;&#38544;&#31169;&#26356;&#26377;&#25928;&#22320;&#20445;&#25252;&#38544;&#31169;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#30456;&#24212;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.00557</link><description>&lt;p&gt;
&#20132;&#20114;&#24335;&#21644;&#38598;&#20013;&#24335;&#24046;&#20998;&#38544;&#31169;&#22312;Bandit&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Interactive and Concentrated Differential Privacy for Bandits. (arXiv:2309.00557v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00557
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20132;&#20114;&#23398;&#20064;&#21644;&#25512;&#33616;&#31995;&#32479;&#20013;&#38544;&#31169;&#20445;&#25252;&#30340;Bandit&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#38598;&#20013;&#24046;&#20998;&#38544;&#31169;&#30340;&#27010;&#24565;&#12290;&#36890;&#36807;&#25552;&#20379;&#20851;&#20110;&#26377;&#38480;&#33218;&#21644;&#32447;&#24615;Bandit&#38382;&#39064;&#36951;&#25022;&#30340;&#19979;&#30028;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#19981;&#21516;&#38544;&#31169;&#39044;&#31639;&#19979;&#30340;&#38590;&#24230;&#21306;&#22495;&#65292;&#24182;&#21457;&#29616;&#38598;&#20013;&#24046;&#20998;&#38544;&#31169;&#21487;&#20197;&#27604;&#20840;&#23616;&#24046;&#20998;&#38544;&#31169;&#26356;&#26377;&#25928;&#22320;&#20445;&#25252;&#38544;&#31169;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#30456;&#24212;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Bandit&#38382;&#39064;&#22312;&#20132;&#20114;&#24335;&#23398;&#20064;&#26041;&#26696;&#21644;&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#20013;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31995;&#32479;&#36890;&#24120;&#20381;&#36182;&#20110;&#25935;&#24863;&#30340;&#29992;&#25143;&#25968;&#25454;&#65292;&#22240;&#27492;&#38544;&#31169;&#26159;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#12290;&#26412;&#25991;&#36890;&#36807;&#20132;&#20114;&#24335;&#24046;&#20998;&#38544;&#31169;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#22522;&#20110;&#21487;&#20449;&#38598;&#20013;&#24335;&#20915;&#31574;&#32773;&#30340;Bandit&#38382;&#39064;&#30340;&#38544;&#31169;&#24615;&#12290;&#34429;&#28982;&#24050;&#32463;&#23545;&#32431;&#949;-&#20840;&#23616;&#24046;&#20998;&#38544;&#31169;&#30340;Bandit&#38382;&#39064;&#36827;&#34892;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#25105;&#20204;&#22312;&#29702;&#35299;&#38646;&#38598;&#20013;&#24046;&#20998;&#38544;&#31169;(zCDP)&#30340;Bandit&#38382;&#39064;&#26041;&#38754;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;&#38024;&#23545;&#26377;&#38480;&#33218;&#21644;&#32447;&#24615;Bandit&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#36951;&#25022;&#30340;&#26368;&#23567;&#26368;&#22823;&#21644;&#38382;&#39064;&#30456;&#20851;&#19979;&#30028;&#65292;&#20174;&#32780;&#37327;&#21270;&#20102;&#36825;&#20123;&#24773;&#20917;&#19979;&#961;-&#20840;&#23616;zCDP&#30340;&#20195;&#20215;&#12290;&#36825;&#20123;&#19979;&#30028;&#25581;&#31034;&#20102;&#22522;&#20110;&#38544;&#31169;&#39044;&#31639;&#961;&#30340;&#20004;&#20010;&#22256;&#38590;&#21306;&#22495;&#65292;&#24182;&#34920;&#26126;&#961;-&#20840;&#23616;zCDP&#27604;&#32431;&#949;-&#20840;&#23616;&#24046;&#20998;&#38544;&#31169;&#20135;&#29983;&#30340;&#36951;&#25022;&#26356;&#23567;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26377;&#38480;&#33218;&#21644;&#32447;&#24615;Bandit&#38382;&#39064;&#30340;&#961;-&#20840;&#23616;zCDP&#31639;&#27861;&#65292;&#21363;AdaC-UCB&#21644;AdaC-GOPE&#12290;&#36825;&#20004;&#20010;&#31639;&#27861;&#37117;&#20351;&#29992;&#20102;&#39640;&#26031;&#26426;&#21046;&#30340;&#20849;&#21516;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bandits play a crucial role in interactive learning schemes and modern recommender systems. However, these systems often rely on sensitive user data, making privacy a critical concern. This paper investigates privacy in bandits with a trusted centralized decision-maker through the lens of interactive Differential Privacy (DP). While bandits under pure $\epsilon$-global DP have been well-studied, we contribute to the understanding of bandits under zero Concentrated DP (zCDP). We provide minimax and problem-dependent lower bounds on regret for finite-armed and linear bandits, which quantify the cost of $\rho$-global zCDP in these settings. These lower bounds reveal two hardness regimes based on the privacy budget $\rho$ and suggest that $\rho$-global zCDP incurs less regret than pure $\epsilon$-global DP. We propose two $\rho$-global zCDP bandit algorithms, AdaC-UCB and AdaC-GOPE, for finite-armed and linear bandits respectively. Both algorithms use a common recipe of Gaussian mechanism 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25581;&#31034;&#20102;&#23618;&#24402;&#19968;&#21270;&#21644;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#26631;&#31614;&#20559;&#31227;&#38382;&#39064;&#20043;&#38388;&#30340;&#28145;&#21051;&#32852;&#31995;&#65292;&#36890;&#36807;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#24212;&#29992;&#29305;&#24449;&#24402;&#19968;&#21270;&#65292;&#20351;&#24471;&#23545;&#20005;&#37325;&#20542;&#26012;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#21152;&#36895;&#20840;&#23616;&#35757;&#32451;&#65292;&#20174;&#32780;&#22312;&#26497;&#31471;&#26631;&#31614;&#20559;&#31227;&#19979;&#33719;&#24471;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2308.09565</link><description>&lt;p&gt;
&#35268;&#33539;&#21270;&#23601;&#26159;&#20320;&#25152;&#38656;&#35201;&#30340;&#65306;&#29702;&#35299;&#26497;&#31471;&#26631;&#31614;&#20559;&#31227;&#19979;&#30340;&#23618;&#24402;&#19968;&#21270;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Normalization Is All You Need: Understanding Layer-Normalized Federated Learning under Extreme Label Shift. (arXiv:2308.09565v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09565
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25581;&#31034;&#20102;&#23618;&#24402;&#19968;&#21270;&#21644;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#26631;&#31614;&#20559;&#31227;&#38382;&#39064;&#20043;&#38388;&#30340;&#28145;&#21051;&#32852;&#31995;&#65292;&#36890;&#36807;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#24212;&#29992;&#29305;&#24449;&#24402;&#19968;&#21270;&#65292;&#20351;&#24471;&#23545;&#20005;&#37325;&#20542;&#26012;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#21152;&#36895;&#20840;&#23616;&#35757;&#32451;&#65292;&#20174;&#32780;&#22312;&#26497;&#31471;&#26631;&#31614;&#20559;&#31227;&#19979;&#33719;&#24471;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23618;&#24402;&#19968;&#21270;&#65288;LN&#65289;&#26159;&#19968;&#20010;&#24191;&#27867;&#37319;&#29992;&#30340;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#65292;&#29305;&#21035;&#22312;&#22522;&#30784;&#27169;&#22411;&#30340;&#26102;&#20195;&#12290;&#26368;&#36817;&#65292;&#24050;&#32463;&#35777;&#26126;LN&#22312;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#19978;&#30340;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#20013;&#38750;&#24120;&#26377;&#25928;&#12290;&#28982;&#32780;&#65292;&#23427;&#20026;&#20160;&#20040;&#20197;&#21450;&#22914;&#20309;&#36215;&#20316;&#29992;&#20173;&#28982;&#26159;&#20010;&#35868;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#23618;&#24402;&#19968;&#21270;&#21644;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#26631;&#31614;&#20559;&#31227;&#38382;&#39064;&#20043;&#38388;&#30340;&#28145;&#21051;&#32852;&#31995;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;FL&#20013;&#30340;&#23618;&#24402;&#19968;&#21270;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#35268;&#33539;&#21270;&#26041;&#27861;&#22312;FL&#20013;&#30340;&#20851;&#38190;&#36129;&#29486;&#26426;&#21046;&#65292;&#31216;&#20043;&#20026;&#29305;&#24449;&#24402;&#19968;&#21270;&#65288;FN&#65289;&#65292;&#23427;&#22312;&#20998;&#31867;&#22120;&#22836;&#20043;&#21069;&#23558;&#24402;&#19968;&#21270;&#24212;&#29992;&#20110;&#28508;&#22312;&#29305;&#24449;&#34920;&#31034;&#12290;&#34429;&#28982;LN&#21644;FN&#19981;&#20250;&#25552;&#39640;&#34920;&#36798;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#25511;&#21046;&#29305;&#24449;&#23849;&#28291;&#21644;&#23616;&#37096;&#36807;&#25311;&#21512;&#65292;&#20351;&#24471;&#23545;&#20005;&#37325;&#20542;&#26012;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#21152;&#36895;&#20840;&#23616;&#35757;&#32451;&#12290;&#32463;&#39564;&#35777;&#26126;&#65292;&#35268;&#33539;&#21270;&#22312;&#26497;&#31471;&#26631;&#31614;&#20559;&#31227;&#19979;&#21487;&#20197;&#24341;&#36215;&#26631;&#20934;&#22522;&#20934;&#30340;&#26174;&#33879;&#25913;&#36827;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#22823;&#37327;&#30340;&#21106;&#38500;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Layer normalization (LN) is a widely adopted deep learning technique especially in the era of foundation models. Recently, LN has been shown to be surprisingly effective in federated learning (FL) with non-i.i.d. data. However, exactly why and how it works remains mysterious. In this work, we reveal the profound connection between layer normalization and the label shift problem in federated learning. To understand layer normalization better in FL, we identify the key contributing mechanism of normalization methods in FL, called feature normalization (FN), which applies normalization to the latent feature representation before the classifier head. Although LN and FN do not improve expressive power, they control feature collapse and local overfitting to heavily skewed datasets, and thus accelerates global training. Empirically, we show that normalization leads to drastic improvements on standard benchmarks under extreme label shift. Moreover, we conduct extensive ablation studies to unde
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38750;&#31283;&#24577;&#29615;&#22659;&#20013;&#30340;&#32447;&#24615;&#36172;&#21338;&#26426;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#20174;&#19968;&#20010;G-&#26368;&#20248;&#35774;&#35745;&#20013;&#38543;&#26426;&#36873;&#25321;&#33218;&#26469;&#23454;&#29616;&#26368;&#20339;&#33218;&#30340;&#40065;&#26834;&#35782;&#21035;&#12290;</title><link>http://arxiv.org/abs/2307.15154</link><description>&lt;p&gt;
A/B&#27979;&#35797;&#21644;&#20855;&#26377;&#38750;&#31283;&#24577;&#40065;&#26834;&#24615;&#30340;&#32447;&#24615;&#36172;&#21338;&#26426;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
A/B Testing and Best-arm Identification for Linear Bandits with Robustness to Non-stationarity. (arXiv:2307.15154v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15154
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38750;&#31283;&#24577;&#29615;&#22659;&#20013;&#30340;&#32447;&#24615;&#36172;&#21338;&#26426;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#20174;&#19968;&#20010;G-&#26368;&#20248;&#35774;&#35745;&#20013;&#38543;&#26426;&#36873;&#25321;&#33218;&#26469;&#23454;&#29616;&#26368;&#20339;&#33218;&#30340;&#40065;&#26834;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#21487;&#33021;&#23384;&#22312;&#38750;&#31283;&#24577;&#29615;&#22659;&#19979;&#30340;&#32447;&#24615;&#36172;&#21338;&#26426;&#20013;&#30340;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#32473;&#23450;&#26377;&#38480;&#33218;&#38598;&#21512;X&#65292;&#22266;&#23450;&#39044;&#31639;T&#20197;&#21450;&#19981;&#21487;&#39044;&#27979;&#30340;&#21442;&#25968;&#24207;&#21015;&#952;&#65292;&#31639;&#27861;&#30340;&#30446;&#26631;&#26159;&#20197;&#23613;&#21487;&#33021;&#39640;&#30340;&#27010;&#29575;&#27491;&#30830;&#35782;&#21035;&#26368;&#20339;&#33218;x*&#12290;&#20043;&#21069;&#30340;&#24037;&#20316;&#24050;&#32463;&#22312;&#31283;&#24577;&#35774;&#32622;&#19979;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#38169;&#35823;&#27010;&#29575;&#38543;&#30528;&#39044;&#31639;&#30340;&#22686;&#21152;&#32780;&#25351;&#25968;&#19979;&#38477;&#12290;&#20294;&#22312;&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#30340;A/B/n&#22810;&#21464;&#37327;&#27979;&#35797;&#22330;&#26223;&#20013;&#65292;&#29615;&#22659;&#26159;&#38750;&#31283;&#24577;&#30340;&#65292;&#32780;&#19968;&#20010;&#26399;&#26395;&#31283;&#24577;&#30340;&#31639;&#27861;&#24456;&#23481;&#26131;&#22833;&#36133;&#12290;&#20026;&#20102;&#20855;&#26377;&#40065;&#26834;&#30340;&#35782;&#21035;&#33021;&#21147;&#65292;&#20247;&#25152;&#21608;&#30693;&#65292;&#22914;&#26524;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#20174;X&#30340;&#19968;&#20010;G-&#26368;&#20248;&#35774;&#35745;&#20013;&#20197;&#38543;&#26426;&#21644;&#38750;&#33258;&#36866;&#24212;&#30340;&#26041;&#24335;&#36873;&#25321;&#33218;&#65292;&#37027;&#20040;&#21487;&#20197;&#23454;&#29616;&#26368;&#20339;&#33218;&#30340;&#40065;&#26834;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the fixed-budget best-arm identification (BAI) problem for linear bandits in a potentially non-stationary environment. Given a finite arm set $\mathcal{X}\subset\mathbb{R}^d$, a fixed budget $T$, and an unpredictable sequence of parameters $\left\lbrace\theta_t\right\rbrace_{t=1}^{T}$, an algorithm will aim to correctly identify the best arm $x^* := \arg\max_{x\in\mathcal{X}}x^\top\sum_{t=1}^{T}\theta_t$ with probability as high as possible. Prior work has addressed the stationary setting where $\theta_t = \theta_1$ for all $t$ and demonstrated that the error probability decreases as $\exp(-T /\rho^*)$ for a problem-dependent constant $\rho^*$. But in many real-world $A/B/n$ multivariate testing scenarios that motivate our work, the environment is non-stationary and an algorithm expecting a stationary setting can easily fail. For robust identification, it is well-known that if arms are chosen randomly and non-adaptively from a G-optimal design over $\mathcal{X}$ at each 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#37325;&#35201;&#24615;&#37319;&#26679;&#36827;&#34892;&#38544;&#31169;&#25918;&#22823;&#65292;&#21487;&#20197;&#21516;&#26102;&#22686;&#24378;&#38544;&#31169;&#20445;&#25252;&#21644;&#25552;&#39640;&#25928;&#29992;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#19968;&#33324;&#30340;&#32467;&#26524;&#26469;&#37327;&#21270;&#36873;&#25321;&#27010;&#29575;&#26435;&#37325;&#23545;&#38544;&#31169;&#25918;&#22823;&#30340;&#24433;&#21709;&#65292;&#24182;&#23637;&#31034;&#20102;&#24322;&#36136;&#37319;&#26679;&#27010;&#29575;&#21487;&#20197;&#22312;&#20445;&#25345;&#23376;&#37319;&#26679;&#22823;&#23567;&#19981;&#21464;&#30340;&#24773;&#20917;&#19979;&#33719;&#24471;&#26356;&#22909;&#30340;&#38544;&#31169;&#21644;&#25928;&#29992;&#12290;</title><link>http://arxiv.org/abs/2307.10187</link><description>&lt;p&gt;
&#38544;&#31169;&#25918;&#22823;&#36890;&#36807;&#37325;&#35201;&#24615;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Privacy Amplification via Importance Sampling. (arXiv:2307.10187v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10187
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#37325;&#35201;&#24615;&#37319;&#26679;&#36827;&#34892;&#38544;&#31169;&#25918;&#22823;&#65292;&#21487;&#20197;&#21516;&#26102;&#22686;&#24378;&#38544;&#31169;&#20445;&#25252;&#21644;&#25552;&#39640;&#25928;&#29992;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#19968;&#33324;&#30340;&#32467;&#26524;&#26469;&#37327;&#21270;&#36873;&#25321;&#27010;&#29575;&#26435;&#37325;&#23545;&#38544;&#31169;&#25918;&#22823;&#30340;&#24433;&#21709;&#65292;&#24182;&#23637;&#31034;&#20102;&#24322;&#36136;&#37319;&#26679;&#27010;&#29575;&#21487;&#20197;&#22312;&#20445;&#25345;&#23376;&#37319;&#26679;&#22823;&#23567;&#19981;&#21464;&#30340;&#24773;&#20917;&#19979;&#33719;&#24471;&#26356;&#22909;&#30340;&#38544;&#31169;&#21644;&#25928;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#36890;&#36807;&#37325;&#35201;&#24615;&#37319;&#26679;&#23545;&#25968;&#25454;&#38598;&#36827;&#34892;&#23376;&#37319;&#26679;&#20316;&#20026;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#30340;&#39044;&#22788;&#29702;&#27493;&#39588;&#26469;&#22686;&#24378;&#38544;&#31169;&#20445;&#25252;&#30340;&#24615;&#36136;&#12290;&#36825;&#25193;&#23637;&#20102;&#24050;&#26377;&#30340;&#36890;&#36807;&#23376;&#37319;&#26679;&#36827;&#34892;&#38544;&#31169;&#25918;&#22823;&#30340;&#32467;&#26524;&#21040;&#37325;&#35201;&#24615;&#37319;&#26679;&#65292;&#20854;&#20013;&#27599;&#20010;&#25968;&#25454;&#28857;&#30340;&#26435;&#37325;&#20026;&#20854;&#34987;&#36873;&#25321;&#27010;&#29575;&#30340;&#20498;&#25968;&#12290;&#27599;&#20010;&#28857;&#30340;&#36873;&#25321;&#27010;&#29575;&#30340;&#26435;&#37325;&#23545;&#38544;&#31169;&#30340;&#24433;&#21709;&#24182;&#19981;&#26126;&#26174;&#12290;&#19968;&#26041;&#38754;&#65292;&#36739;&#20302;&#30340;&#36873;&#25321;&#27010;&#29575;&#20250;&#23548;&#33268;&#26356;&#24378;&#30340;&#38544;&#31169;&#25918;&#22823;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#26435;&#37325;&#36234;&#39640;&#65292;&#22312;&#28857;&#34987;&#36873;&#25321;&#26102;&#65292;&#28857;&#23545;&#26426;&#21046;&#36755;&#20986;&#30340;&#24433;&#21709;&#23601;&#36234;&#24378;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#19968;&#33324;&#30340;&#32467;&#26524;&#26469;&#37327;&#21270;&#36825;&#20004;&#20010;&#24433;&#21709;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24322;&#36136;&#37319;&#26679;&#27010;&#29575;&#21487;&#20197;&#21516;&#26102;&#27604;&#22343;&#21248;&#23376;&#37319;&#26679;&#20855;&#26377;&#26356;&#24378;&#30340;&#38544;&#31169;&#21644;&#26356;&#22909;&#30340;&#25928;&#29992;&#65292;&#24182;&#20445;&#25345;&#23376;&#37319;&#26679;&#22823;&#23567;&#19981;&#21464;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#21046;&#23450;&#21644;&#35299;&#20915;&#20102;&#38544;&#31169;&#20248;&#21270;&#37319;&#26679;&#30340;&#38382;&#39064;&#65292;&#21363;&#23547;&#25214;...
&lt;/p&gt;
&lt;p&gt;
We examine the privacy-enhancing properties of subsampling a data set via importance sampling as a pre-processing step for differentially private mechanisms. This extends the established privacy amplification by subsampling result to importance sampling where each data point is weighted by the reciprocal of its selection probability. The implications for privacy of weighting each point are not obvious. On the one hand, a lower selection probability leads to a stronger privacy amplification. On the other hand, the higher the weight, the stronger the influence of the point on the output of the mechanism in the event that the point does get selected. We provide a general result that quantifies the trade-off between these two effects. We show that heterogeneous sampling probabilities can lead to both stronger privacy and better utility than uniform subsampling while retaining the subsample size. In particular, we formulate and solve the problem of privacy-optimal sampling, that is, finding
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31283;&#23450;&#31070;&#32463;&#24494;&#20998;&#26041;&#31243;&#65288;SNDEs&#65289;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#24378;&#21046;&#20351;&#29992;&#20219;&#24847;&#27969;&#24418;&#32422;&#26463;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#28155;&#21152;&#31283;&#23450;&#39033;&#20351;&#32422;&#26463;&#27969;&#24418;&#25104;&#20026;&#28176;&#36827;&#31283;&#23450;&#30340;&#65292;&#24182;&#19988;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.09739</link><description>&lt;p&gt;
&#23398;&#20064;&#21463;&#38480;&#21160;&#21147;&#23398;&#30340;&#31283;&#23450;&#31070;&#32463;&#24494;&#20998;&#26041;&#31243;
&lt;/p&gt;
&lt;p&gt;
Stabilized Neural Differential Equations for Learning Constrained Dynamics. (arXiv:2306.09739v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09739
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31283;&#23450;&#31070;&#32463;&#24494;&#20998;&#26041;&#31243;&#65288;SNDEs&#65289;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#24378;&#21046;&#20351;&#29992;&#20219;&#24847;&#27969;&#24418;&#32422;&#26463;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#28155;&#21152;&#31283;&#23450;&#39033;&#20351;&#32422;&#26463;&#27969;&#24418;&#25104;&#20026;&#28176;&#36827;&#31283;&#23450;&#30340;&#65292;&#24182;&#19988;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20986;&#29616;&#20102;&#35768;&#22810;&#25104;&#21151;&#30340;&#20174;&#25968;&#25454;&#23398;&#20064;&#21160;&#24577;&#31995;&#32479;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#30830;&#20445;&#25512;&#26029;&#20986;&#30340;&#21160;&#24577;&#31995;&#32479;&#20445;&#30041;&#24050;&#30693;&#32422;&#26463;&#26465;&#20214;&#65288;&#20363;&#22914;&#23432;&#24658;&#23450;&#24459;&#25110;&#23545;&#20801;&#35768;&#30340;&#31995;&#32479;&#29366;&#24577;&#30340;&#38480;&#21046;&#65289;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#31283;&#23450;&#31070;&#32463;&#24494;&#20998;&#26041;&#31243;&#65288;SNDEs&#65289;&#30340;&#26041;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#31070;&#32463;&#24494;&#20998;&#26041;&#31243;&#24378;&#21046;&#20351;&#29992;&#20219;&#24847;&#27969;&#24418;&#32422;&#26463;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#19968;&#20010;&#31283;&#23450;&#39033;&#65292;&#24403;&#28155;&#21152;&#21040;&#21407;&#22987;&#21160;&#24577;&#31995;&#32479;&#20013;&#26102;&#65292;&#21487;&#20197;&#23558;&#32422;&#26463;&#27969;&#24418;&#25104;&#20026;&#28176;&#36827;&#31283;&#23450;&#30340;&#12290;&#30001;&#20110;&#20854;&#31616;&#21333;&#24615;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#25152;&#26377;&#24120;&#35265;&#30340;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;NODE&#65289;&#27169;&#22411;&#20860;&#23481;&#24182;&#24191;&#27867;&#36866;&#29992;&#12290;&#22312;&#24191;&#27867;&#30340;&#32463;&#39564;&#35780;&#20272;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;SNDE&#22312;&#25193;&#23637;&#21487;&#32435;&#20837;NODE&#35757;&#32451;&#30340;&#32422;&#26463;&#31867;&#22411;&#26041;&#38754;&#32988;&#36807;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many successful methods to learn dynamical systems from data have recently been introduced. However, assuring that the inferred dynamics preserve known constraints, such as conservation laws or restrictions on the allowed system states, remains challenging. We propose stabilized neural differential equations (SNDEs), a method to enforce arbitrary manifold constraints for neural differential equations. Our approach is based on a stabilization term that, when added to the original dynamics, renders the constraint manifold provably asymptotically stable. Due to its simplicity, our method is compatible with all common neural ordinary differential equation (NODE) models and broadly applicable. In extensive empirical evaluations, we demonstrate that SNDEs outperform existing methods while extending the scope of which types of constraints can be incorporated into NODE training.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#26032;&#30340;&#31639;&#27861;&#31283;&#23450;&#24615;&#29702;&#35770;&#26469;&#25913;&#36827;&#20998;&#24067;&#24335;SGD&#31639;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#20998;&#26512;&#65292;&#25512;&#32763;&#20102;&#29616;&#26377;&#25216;&#26415;&#23545;&#36890;&#20449;&#22270;&#36127;&#38754;&#24433;&#21709;&#30340;&#35266;&#28857;&#65292;&#24182;&#23637;&#31034;&#20102;D-SGD&#22312;&#20984;&#35774;&#32622;&#20013;&#19982;&#32463;&#20856;SGD&#31639;&#27861;&#27867;&#21270;&#30028;&#30456;&#21516;&#12290;</title><link>http://arxiv.org/abs/2306.02939</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;SGD&#31639;&#27861;&#30340;&#31283;&#23450;&#24615;&#19982;&#27867;&#21270;&#20998;&#26512;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
Improved Stability and Generalization Analysis of the Decentralized SGD Algorithm. (arXiv:2306.02939v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02939
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#26032;&#30340;&#31639;&#27861;&#31283;&#23450;&#24615;&#29702;&#35770;&#26469;&#25913;&#36827;&#20998;&#24067;&#24335;SGD&#31639;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#20998;&#26512;&#65292;&#25512;&#32763;&#20102;&#29616;&#26377;&#25216;&#26415;&#23545;&#36890;&#20449;&#22270;&#36127;&#38754;&#24433;&#21709;&#30340;&#35266;&#28857;&#65292;&#24182;&#23637;&#31034;&#20102;D-SGD&#22312;&#20984;&#35774;&#32622;&#20013;&#19982;&#32463;&#20856;SGD&#31639;&#27861;&#27867;&#21270;&#30028;&#30456;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22522;&#20110;&#31639;&#27861;&#31283;&#23450;&#24615;&#65292;&#25552;&#20986;&#20102;&#20998;&#24067;&#24335;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;(D-SGD)&#31639;&#27861;&#30340;&#26032;&#30340;&#27867;&#21270;&#35823;&#24046;&#20998;&#26512;&#26041;&#27861;&#12290;&#24471;&#21040;&#30340;&#32467;&#26524;&#22823;&#22823;&#25913;&#36827;&#20102;&#29616;&#26377;&#25216;&#26415;&#65292;&#24182;&#25512;&#32763;&#20102;&#23427;&#20204;&#20851;&#20110;&#36890;&#20449;&#22270;&#23545;&#27867;&#21270;&#30340;&#36127;&#38754;&#24433;&#21709;&#30340;&#35266;&#28857;&#12290;&#20363;&#22914;&#65292;&#22312;&#20984;&#35774;&#32622;&#20013;&#65292;&#26080;&#35770;&#22270;&#30340;&#36873;&#25321;&#22914;&#20309;&#65292;D-SGD&#20855;&#26377;&#19982;&#32463;&#20856;SGD&#31639;&#27861;&#30456;&#21516;&#30340;&#27867;&#21270;&#30028;&#12290;&#25105;&#20204;&#21457;&#29616;&#36825;&#31181;&#21453;&#30452;&#35273;&#30340;&#32467;&#26524;&#26469;&#33258;&#20110;&#32771;&#34385;&#26412;&#22320;&#21442;&#25968;&#30340;&#24179;&#22343;&#20540;&#65292;&#36825;&#20250;&#38544;&#34255;&#19968;&#20010;&#19982;&#20998;&#24067;&#24335;&#22330;&#26223;&#19981;&#20860;&#23481;&#30340;&#26368;&#32456;&#20840;&#23616;&#24179;&#22343;&#21270;&#27493;&#39588;&#12290;&#32771;&#34385;&#21040;&#36825;&#19968;&#35266;&#23519;&#32467;&#26524;&#65292;&#25105;&#20204;&#20513;&#23548;&#20998;&#26512;&#26412;&#22320;&#21442;&#25968;&#30340;&#19978;&#30830;&#30028;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#22270;&#30830;&#23454;&#23545;&#27867;&#21270;&#20135;&#29983;&#24433;&#21709;&#12290;&#19982;&#20043;&#21069;&#30340;&#32467;&#26524;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#21363;&#20351;&#23545;&#20110;&#38750;&#36830;&#25509;&#22270;&#20063;&#33021;&#20135;&#29983;&#38750;&#24179;&#20961;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a new generalization error analysis for the Decentralized Stochastic Gradient Descent (D-SGD) algorithm based on algorithmic stability. The obtained results largely improve upon state-of-the-art results, and even invalidate their claims that the communication graph has a detrimental effect on generalization. For instance, we show that in convex settings, D-SGD has the same generalization bounds as the classical SGD algorithm, no matter the choice of graph. We exhibit that this counter-intuitive result comes from considering the average of local parameters, which hides a final global averaging step incompatible with the decentralized scenario. In light of this observation, we advocate to analyze the supremum over local parameters and show that in this case, the graph does have an impact on the generalization. Unlike prior results, our analysis yields non-vacuous bounds even for non-connected graphs.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;SAL&#21644;SCoreBO&#20004;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#25552;&#39640;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#36229;&#21442;&#25968;&#36873;&#25321;&#21644;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2304.11005</link><description>&lt;p&gt;
&#36890;&#36807;&#36125;&#21494;&#26031;&#20027;&#21160;&#23398;&#20064;&#23454;&#29616;&#33258;&#26657;&#27491;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Self-Correcting Bayesian Optimization through Bayesian Active Learning. (arXiv:2304.11005v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11005
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;SAL&#21644;SCoreBO&#20004;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#25552;&#39640;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#36229;&#21442;&#25968;&#36873;&#25321;&#21644;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#24050;&#25104;&#20026;&#36125;&#21494;&#26031;&#20248;&#21270;&#21644;&#20027;&#21160;&#23398;&#20064;&#20013;&#30340;&#39318;&#36873;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#39640;&#26031;&#36807;&#31243;&#30340;&#23436;&#20840;&#21457;&#25381;&#38656;&#35201;&#24039;&#22937;&#36873;&#25321;&#36229;&#21442;&#25968;&#65292;&#32780;&#22312;&#25991;&#29486;&#20013;&#24456;&#23569;&#26377;&#20851;&#20110;&#25214;&#21040;&#27491;&#30830;&#36229;&#21442;&#25968;&#30340;&#21162;&#21147;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;&#36873;&#25321;&#22909;&#30340;&#36229;&#21442;&#25968;&#23545;&#20110;&#39640;&#26031;&#36807;&#31243;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#26126;&#30830;&#20248;&#20808;&#32771;&#34385;&#27492;&#30446;&#26631;&#30340;&#25910;&#36141;&#20989;&#25968;&#12290;&#32479;&#35745;&#36317;&#31163;&#20027;&#21160;&#23398;&#20064;&#65288;SAL&#65289;&#32771;&#34385;&#21518;&#39564;&#26679;&#26412;&#30340;&#24179;&#22343;&#19981;&#19968;&#33268;&#24615;&#65292;&#30001;&#32479;&#35745;&#36317;&#31163;&#27979;&#37327;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#22312;&#35768;&#22810;&#27979;&#35797;&#20989;&#25968;&#19978;&#65292;&#23427;&#32988;&#36807;&#20102;&#36125;&#21494;&#26031;&#20027;&#21160;&#23398;&#20064;&#30340;&#26368;&#26032;&#32467;&#26524;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#33258;&#26657;&#27491;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;SCoreBO&#65289;&#65292;&#23427;&#23558;SAL&#25193;&#23637;&#21040;&#21516;&#26102;&#25191;&#34892;&#36125;&#21494;&#26031;&#20248;&#21270;&#21644;&#20027;&#21160;&#36229;&#21442;&#25968;&#23398;&#20064;&#12290;&#30456;&#27604;&#20256;&#32479;BO&#65292;SCoreBO&#20197;&#25913;&#36827;&#30340;&#36895;&#24230;&#23398;&#20064;&#27169;&#22411;&#36229;&#21442;&#25968;&#65292;&#21516;&#26102;&#22312;&#26368;&#26032;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#25628;&#32034;&#20013;&#21462;&#24471;&#26356;&#22909;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian processes are cemented as the model of choice in Bayesian optimization and active learning. Yet, they are severely dependent on cleverly chosen hyperparameters to reach their full potential, and little effort is devoted to finding the right hyperparameters in the literature. We demonstrate the impact of selecting good hyperparameters for GPs and present two acquisition functions that explicitly prioritize this goal. Statistical distance-based Active Learning (SAL) considers the average disagreement among samples from the posterior, as measured by a statistical distance. It is shown to outperform the state-of-the-art in Bayesian active learning on a number of test functions. We then introduce Self-Correcting Bayesian Optimization (SCoreBO), which extends SAL to perform Bayesian optimization and active hyperparameter learning simultaneously. SCoreBO learns the model hyperparameters at improved rates compared to vanilla BO, while outperforming the latest Bayesian optimization met
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;P300 BCI&#38382;&#39064;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;GLASS&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#30452;&#25509;&#35299;&#20915;&#20102;&#33041;&#26426;&#25509;&#21475;&#24212;&#29992;&#20013;&#25968;&#25454;&#38598;&#19981;&#24179;&#34913;&#38382;&#39064;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#20998;&#31867;&#24615;&#33021;&#21644;&#26131;&#20110;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.07401</link><description>&lt;p&gt;
&#22522;&#20110;GLASS&#27169;&#22411;&#30340;&#33041;&#26426;&#25509;&#21475;&#36125;&#21494;&#26031;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Bayesian inference on Brain-Computer Interface using the GLASS Model. (arXiv:2304.07401v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07401
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;P300 BCI&#38382;&#39064;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;GLASS&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#30452;&#25509;&#35299;&#20915;&#20102;&#33041;&#26426;&#25509;&#21475;&#24212;&#29992;&#20013;&#25968;&#25454;&#38598;&#19981;&#24179;&#34913;&#38382;&#39064;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#20998;&#31867;&#24615;&#33021;&#21644;&#26131;&#20110;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33041;&#26426;&#25509;&#21475;&#65288;BCI&#65289;&#20351;&#37325;&#24230;&#27531;&#30142;&#20154;&#22763;&#19982;&#19990;&#30028;&#36827;&#34892;&#20132;&#27969;&#12290;BCI&#23558;&#23454;&#26102;&#30340;&#33041;&#27963;&#21160;&#36716;&#21270;&#20026;&#35745;&#31639;&#26426;&#25351;&#20196;&#65292;&#36890;&#24120;&#34987;&#35748;&#20026;&#26159;&#19968;&#20010;&#20998;&#31867;&#38382;&#39064;&#65292;&#35745;&#31639;&#31070;&#32463;&#31185;&#23398;&#25552;&#20379;&#20102;&#26426;&#36935;&#21644;&#25361;&#25112;&#12290;&#26412;&#25991;&#38598;&#20013;&#22312;&#20351;&#29992;&#20107;&#20214;&#30456;&#20851;&#30005;&#20301;&#65288;ERP&#65289;BCI&#35774;&#35745;&#30340;P300 BCI&#19978;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20855;&#26377;&#31232;&#30095;&#26102;&#21464;&#25928;&#24212;&#30340;&#39640;&#26031;&#28508;&#22312;&#32452;&#27169;&#22411;&#65288;GLASS&#65289;&#65292;&#29992;&#20110;&#22312;P300 BCI&#19978;&#36827;&#34892;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;GLASS&#37319;&#29992;&#22810;&#39033;&#24335;&#22238;&#24402;&#26694;&#26550;&#65292;&#30452;&#25509;&#35299;&#20915;&#20102;BCI&#24212;&#29992;&#20013;&#30340;&#25968;&#25454;&#38598;&#19981;&#24179;&#34913;&#38382;&#39064;&#12290;&#20808;&#39564;&#35268;&#33539;&#20419;&#36827;&#20102;i&#65289;&#20351;&#29992;&#36719;&#38408;&#20540;&#36827;&#34892;&#29305;&#24449;&#36873;&#25321;&#21644;&#22122;&#22768;&#38477;&#20302;&#65292;ii&#65289;&#20351;&#29992;&#20840;&#23616;&#25910;&#32553;&#23545;&#26102;&#21464;&#25928;&#24212;&#36827;&#34892;&#24179;&#28369;&#22788;&#29702;&#65292;iii&#65289;&#23545;&#28508;&#22312;&#32452;&#36827;&#34892;&#32858;&#31867;&#65292;&#20197;&#20943;&#36731;EEG&#25968;&#25454;&#30340;&#39640;&#31354;&#38388;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#22270;&#27169;&#22411;&#31639;&#27861;&#65292;&#29992;&#20110;&#21518;&#39564;&#35745;&#31639;&#21644;&#27169;&#22411;&#36873;&#25321;&#12290;&#25152;&#25552;&#20986;&#30340;GLASS&#27169;&#22411;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#31454;&#20105;&#24615;&#30340;&#20998;&#31867;&#24615;&#33021;&#65292;&#24182;&#25552;&#20379;&#20102;&#25152;&#25512;&#26029;&#30340;&#26465;&#20214;&#30456;&#20851;&#26102;&#31354;&#27169;&#24335;&#30340;&#26131;&#20110;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The brain-computer interface (BCI) enables individuals with severe physical impairments to communicate with the world. BCIs offer computational neuroscience opportunities and challenges in converting real-time brain activities to computer commands and are typically framed as a classification problem. This article focuses on the P300 BCI that uses the event-related potential (ERP) BCI design, where the primary challenge is classifying target/non-target stimuli. We develop a novel Gaussian latent group model with sparse time-varying effects (GLASS) for making Bayesian inferences on the P300 BCI. GLASS adopts a multinomial regression framework that directly addresses the dataset imbalance in BCI applications. The prior specifications facilitate i) feature selection and noise reduction using soft-thresholding, ii) smoothing of the time-varying effects using global shrinkage, and iii) clustering of latent groups to alleviate high spatial correlations of EEG data. We develop an efficient gra
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#36870;&#21487;&#35299;&#24615;&#21644;&#23433;&#20840;&#24615;&#30340;&#27010;&#24565;&#65292;&#20197;&#21450;&#20854;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;&#35770;&#25991;&#25552;&#20379;&#20102;&#27169;&#22411;&#31034;&#20363;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#22686;&#21152;&#29992;&#25143;&#25968;&#37327;&#26469;&#22686;&#21152;&#21487;&#35299;&#24615;&#21644;&#23433;&#20840;&#24615;&#12290;</title><link>http://arxiv.org/abs/2211.14115</link><description>&lt;p&gt;
&#36870;&#21487;&#35299;&#24615;&#21644;&#23433;&#20840;&#24615;&#21450;&#20854;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Inverse Solvability and Security with Applications to Federated Learning. (arXiv:2211.14115v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.14115
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#36870;&#21487;&#35299;&#24615;&#21644;&#23433;&#20840;&#24615;&#30340;&#27010;&#24565;&#65292;&#20197;&#21450;&#20854;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;&#35770;&#25991;&#25552;&#20379;&#20102;&#27169;&#22411;&#31034;&#20363;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#22686;&#21152;&#29992;&#25143;&#25968;&#37327;&#26469;&#22686;&#21152;&#21487;&#35299;&#24615;&#21644;&#23433;&#20840;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#36870;&#21487;&#35299;&#24615;&#21644;&#23433;&#20840;&#24615;&#30340;&#27010;&#24565;&#65292;&#36866;&#29992;&#20110;&#19968;&#33324;&#32447;&#24615;&#21069;&#21521;&#27169;&#22411;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#20854;&#24212;&#29992;&#20110;&#32852;&#37030;&#23398;&#20064;&#20013;&#20351;&#29992;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#36825;&#26679;&#30340;&#27169;&#22411;&#30340;&#31034;&#20363;&#65292;&#20854;&#36870;&#21487;&#35299;&#24615;&#21644;&#23433;&#20840;&#24615;&#22312;&#26412;&#25991;&#20013;&#24471;&#21040;&#23450;&#20041;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#21442;&#19982;&#32473;&#23450;&#36845;&#20195;&#30340;&#22823;&#37327;&#29992;&#25143;&#26469;&#22686;&#21152;&#21487;&#35299;&#24615;&#21644;&#23433;&#20840;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#25152;&#25552;&#20986;&#27010;&#24565;&#30340;&#21487;&#33021;&#25193;&#23637;&#65292;&#21253;&#25324;&#38750;&#32447;&#24615;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce the concepts of inverse solvability and security for a generic linear forward model and demonstrate how they can be applied to models used in federated learning. We provide examples of such models which differ in the resulting inverse solvability and security as defined in this paper. We also show how the large number of users participating in a given iteration of federated learning can be leveraged to increase both solvability and security. Finally, we discuss possible extensions of the presented concepts including the nonlinear case.
&lt;/p&gt;</description></item></channel></rss>