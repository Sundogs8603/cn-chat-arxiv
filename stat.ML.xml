<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#22240;&#23376;&#27169;&#22411;&#21644;&#25910;&#32553;&#30340;&#26041;&#27861;&#39044;&#27979;&#22823;&#22411;&#23454;&#29616;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#27169;&#22411;&#12290;&#36825;&#31181;&#26041;&#27861;&#36890;&#36807;&#20998;&#35299;&#22238;&#25253;&#21327;&#26041;&#24046;&#30697;&#38453;&#24182;&#20351;&#29992;&#21521;&#37327;&#24322;&#36136;&#33258;&#22238;&#24402;&#27169;&#22411;&#36827;&#34892;&#20272;&#35745;&#65292;&#30456;&#23545;&#20110;&#26631;&#20934;&#22522;&#20934;&#25552;&#39640;&#20102;&#39044;&#27979;&#31934;&#24230;&#65292;&#24182;&#23548;&#33268;&#23545;&#26368;&#23567;&#26041;&#24046;&#32452;&#21512;&#30340;&#26356;&#22909;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2303.16151</link><description>&lt;p&gt;
&#39044;&#27979;&#22823;&#22411;&#23454;&#29616;&#21327;&#26041;&#24046;&#30697;&#38453;:&#22240;&#23376;&#27169;&#22411;&#21644;&#25910;&#32553;&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
Forecasting Large Realized Covariance Matrices: The Benefits of Factor Models and Shrinkage. (arXiv:2303.16151v1 [q-fin.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16151
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#22240;&#23376;&#27169;&#22411;&#21644;&#25910;&#32553;&#30340;&#26041;&#27861;&#39044;&#27979;&#22823;&#22411;&#23454;&#29616;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#27169;&#22411;&#12290;&#36825;&#31181;&#26041;&#27861;&#36890;&#36807;&#20998;&#35299;&#22238;&#25253;&#21327;&#26041;&#24046;&#30697;&#38453;&#24182;&#20351;&#29992;&#21521;&#37327;&#24322;&#36136;&#33258;&#22238;&#24402;&#27169;&#22411;&#36827;&#34892;&#20272;&#35745;&#65292;&#30456;&#23545;&#20110;&#26631;&#20934;&#22522;&#20934;&#25552;&#39640;&#20102;&#39044;&#27979;&#31934;&#24230;&#65292;&#24182;&#23548;&#33268;&#23545;&#26368;&#23567;&#26041;&#24046;&#32452;&#21512;&#30340;&#26356;&#22909;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#26469;&#39044;&#27979;&#25910;&#30410;&#30340;&#22823;&#22411;&#23454;&#29616;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#24182;&#23545;S&amp;P 500&#30340;&#25104;&#20998;&#32929;&#36827;&#34892;&#20102;&#24212;&#29992;&#12290;&#20026;&#20102;&#35299;&#20915;&#32500;&#25968;&#28798;&#38590;&#65292;&#25105;&#20204;&#20351;&#29992;&#26631;&#20934;&#20225;&#19994;&#32423;&#21035;&#22240;&#23376;&#65288;&#22914;&#22823;&#23567;&#12289;&#20215;&#20540;&#21644;&#30408;&#21033;&#33021;&#21147;&#65289;&#20998;&#35299;&#22238;&#25253;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#24182;&#22312;&#27531;&#24046;&#21327;&#26041;&#24046;&#30697;&#38453;&#20013;&#20351;&#29992;&#37096;&#38376;&#38480;&#21046;&#12290;&#28982;&#21518;&#65292;&#20351;&#29992;&#26368;&#23567;&#32477;&#23545;&#25910;&#32553;&#21644;&#36873;&#25321;&#36816;&#31639;&#31526;&#65288;LASSO&#65289;&#30340;&#21521;&#37327;&#24322;&#36136;&#33258;&#22238;&#24402;&#65288;VHAR&#65289;&#27169;&#22411;&#23545;&#35813;&#38480;&#21046;&#27169;&#22411;&#36827;&#34892;&#20272;&#35745;&#12290;&#30456;&#23545;&#20110;&#26631;&#20934;&#22522;&#20934;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#39640;&#20102;&#39044;&#27979;&#31934;&#24230;&#65292;&#24182;&#23548;&#33268;&#23545;&#26368;&#23567;&#26041;&#24046;&#32452;&#21512;&#30340;&#26356;&#22909;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a model to forecast large realized covariance matrices of returns, applying it to the constituents of the S\&amp;P 500 daily. To address the curse of dimensionality, we decompose the return covariance matrix using standard firm-level factors (e.g., size, value, and profitability) and use sectoral restrictions in the residual covariance matrix. This restricted model is then estimated using vector heterogeneous autoregressive (VHAR) models with the least absolute shrinkage and selection operator (LASSO). Our methodology improves forecasting precision relative to standard benchmarks and leads to better estimates of minimum variance portfolios.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#26377;&#25928;&#32780;&#20934;&#30830;&#22320;&#36817;&#20284;&#31232;&#30095;&#24191;&#20041;&#21487;&#21152;&#27169;&#22411;&#65288;GAMs&#65289;&#30340;Rashomon&#38598;&#30340;&#25216;&#26415;&#65292;&#24182;&#20351;&#29992;&#36825;&#20123;&#36817;&#20284;&#27169;&#22411;&#26469;&#35299;&#20915;&#23454;&#38469;&#24212;&#29992;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2303.16047</link><description>&lt;p&gt;
&#29702;&#35299;&#21644;&#25506;&#32034;&#31232;&#30095;&#24191;&#20041;&#21487;&#21152;&#27169;&#22411;&#30340;&#25972;&#20010;&#20248;&#31168;&#38598;&#21512;
&lt;/p&gt;
&lt;p&gt;
Understanding and Exploring the Whole Set of Good Sparse Generalized Additive Models. (arXiv:2303.16047v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16047
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#26377;&#25928;&#32780;&#20934;&#30830;&#22320;&#36817;&#20284;&#31232;&#30095;&#24191;&#20041;&#21487;&#21152;&#27169;&#22411;&#65288;GAMs&#65289;&#30340;Rashomon&#38598;&#30340;&#25216;&#26415;&#65292;&#24182;&#20351;&#29992;&#36825;&#20123;&#36817;&#20284;&#27169;&#22411;&#26469;&#35299;&#20915;&#23454;&#38469;&#24212;&#29992;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19982;&#39046;&#22495;&#19987;&#23478;&#20043;&#38388;&#30340;&#20132;&#20114;&#33267;&#20851;&#37325;&#35201;&#65307;&#28982;&#32780;&#65292;&#36890;&#24120;&#21482;&#29983;&#25104;&#21333;&#20010;&#27169;&#22411;&#30340;&#32463;&#20856;&#26426;&#22120;&#23398;&#20064;&#33539;&#24335;&#19981;&#21033;&#20110;&#27492;&#31867;&#20132;&#20114;&#12290;&#36817;&#20284;&#21644;&#25506;&#32034;Rashomon&#38598;&#65292;&#21363;&#25152;&#26377;&#36817;&#20046;&#26368;&#20248;&#27169;&#22411;&#30340;&#38598;&#21512;&#65292;&#36890;&#36807;&#25552;&#20379;&#29992;&#25143;&#21487;&#25628;&#32034;&#30340;&#31354;&#38388;&#21253;&#21547;&#22810;&#26679;&#24615;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#36825;&#19968;&#23454;&#38469;&#25361;&#25112;&#65292;&#39046;&#22495;&#19987;&#23478;&#21487;&#20197;&#20174;&#20013;&#36873;&#25321;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#32780;&#20934;&#30830;&#22320;&#36817;&#20284;&#31232;&#30095;&#24191;&#20041;&#21487;&#21152;&#27169;&#22411;&#65288;GAMs&#65289;&#30340;Rashomon&#38598;&#30340;&#25216;&#26415;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29992;&#20110;&#36817;&#20284;&#20855;&#26377;&#22266;&#23450;&#25903;&#25345;&#38598;&#30340;GAMs&#30340;Rashomon&#38598;&#30340;&#26925;&#29699;&#24418;&#31639;&#27861;&#65292;&#24182;&#20351;&#29992;&#36825;&#20123;&#26925;&#29699;&#24418;&#36817;&#20284;&#20102;&#35768;&#22810;&#19981;&#21516;&#25903;&#25345;&#38598;&#30340;Rashomon&#38598;&#12290;&#36817;&#20284;&#30340;Rashomon&#38598;&#20026;&#35299;&#20915;&#23454;&#38469;&#25361;&#25112;&#65292;&#20363;&#22914;&#65288;1&#65289;&#30740;&#31350;&#27169;&#22411;&#31867;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#65307;&#65288;2&#65289;&#22312;&#29992;&#25143;&#25351;&#23450;&#32422;&#26463;&#26465;&#20214;&#19979;&#26597;&#25214;&#27169;&#22411;&#65292;&#25552;&#20379;&#20102;&#37325;&#35201;&#30340;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
In real applications, interaction between machine learning model and domain experts is critical; however, the classical machine learning paradigm that usually produces only a single model does not facilitate such interaction. Approximating and exploring the Rashomon set, i.e., the set of all near-optimal models, addresses this practical challenge by providing the user with a searchable space containing a diverse set of models from which domain experts can choose. We present a technique to efficiently and accurately approximate the Rashomon set of sparse, generalized additive models (GAMs). We present algorithms to approximate the Rashomon set of GAMs with ellipsoids for fixed support sets and use these ellipsoids to approximate Rashomon sets for many different support sets. The approximated Rashomon set serves as a cornerstone to solve practical challenges such as (1) studying the variable importance for the model class; (2) finding models under user-specified constraints (monotonicity
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#35745;&#31639;&#26426;&#32593;&#32476;&#30417;&#27979;&#20013;&#23384;&#22312;&#30340;&#23395;&#33410;&#24615;&#21464;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#28304;&#20998;&#31163;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#36827;&#34892;&#24314;&#27169;&#21644;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2303.15950</link><description>&lt;p&gt;
&#35745;&#31639;&#26426;&#32593;&#32476;&#30340;&#26102;&#38388;&#22270;&#20998;&#31163;&#24314;&#27169;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A source separation approach to temporal graph modelling for computer networks. (arXiv:2303.15950v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15950
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#35745;&#31639;&#26426;&#32593;&#32476;&#30417;&#27979;&#20013;&#23384;&#22312;&#30340;&#23395;&#33410;&#24615;&#21464;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#28304;&#20998;&#31163;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#36827;&#34892;&#24314;&#27169;&#21644;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#20225;&#19994;&#35745;&#31639;&#26426;&#32593;&#32476;&#20013;&#30340;&#24694;&#24847;&#27963;&#21160;&#26816;&#27979;&#35270;&#20026;&#19968;&#39033;&#26102;&#38388;&#38142;&#25509;&#39044;&#27979;&#20219;&#21153;&#65306;&#32473;&#23450;&#19968;&#31995;&#21015;&#20195;&#34920;&#20027;&#26426;&#20043;&#38388;&#36890;&#20449;&#30340;&#22270;&#34920;&#65292;&#30446;&#26631;&#26159;&#39044;&#27979;&#26410;&#26469;&#24212;&#35813;&#25110;&#19981;&#24212;&#35813;&#21457;&#29983;&#30340;&#36793;&#32536;&#12290;&#28982;&#32780;&#65292;&#26631;&#20934;&#30340;&#26102;&#38388;&#38142;&#25509;&#39044;&#27979;&#31639;&#27861;&#19981;&#36866;&#29992;&#20110;&#35745;&#31639;&#26426;&#32593;&#32476;&#30417;&#27979;&#65292;&#22240;&#20026;&#23427;&#20204;&#27809;&#26377;&#32771;&#34385;&#35745;&#31639;&#26426;&#32593;&#32476;&#27963;&#21160;&#30340;&#30701;&#26399;&#21160;&#24577;&#29305;&#24615;&#65292;&#36825;&#20123;&#29305;&#24615;&#34920;&#29616;&#20986;&#26126;&#26174;&#30340;&#23395;&#33410;&#24615;&#21464;&#21270;&#12290;&#20026;&#20102;&#24314;&#31435;&#19968;&#20010;&#26356;&#22909;&#30340;&#27169;&#22411;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#28304;&#20998;&#31163;&#21551;&#21457;&#30340;&#35745;&#31639;&#26426;&#32593;&#32476;&#27963;&#21160;&#25551;&#36848;&#26041;&#27861;&#65306;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#65292;&#35266;&#23519;&#21040;&#30340;&#22270;&#26159;&#34920;&#31034;&#21508;&#31181;&#27963;&#21160;&#26469;&#28304;&#30340;&#23376;&#22270;&#30340;&#28151;&#21512;&#29289;&#65292;&#24182;&#19988;&#30701;&#26399;&#21160;&#24577;&#26159;&#30001;&#20110;&#28151;&#21512;&#31995;&#25968;&#30340;&#21464;&#21270;&#32780;&#20135;&#29983;&#30340;&#12290;&#23450;&#37327;&#21644;&#23450;&#24615;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Detecting malicious activity within an enterprise computer network can be framed as a temporal link prediction task: given a sequence of graphs representing communications between hosts over time, the goal is to predict which edges should--or should not--occur in the future. However, standard temporal link prediction algorithms are ill-suited for computer network monitoring as they do not take account of the peculiar short-term dynamics of computer network activity, which exhibits sharp seasonal variations. In order to build a better model, we propose a source separation-inspired description of computer network activity: at each time step, the observed graph is a mixture of subgraphs representing various sources of activity, and short-term dynamics result from changes in the mixing coefficients. Both qualitative and quantitative experiments demonstrate the validity of our approach.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#24102;&#29699;&#35856;&#29305;&#24449;&#30340;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26680;&#20989;&#25968;&#65292;&#22312;&#36830;&#32493;&#28145;&#24230;&#30340;&#28145;&#24230;&#27169;&#22411;&#20013;&#20351;&#29992;&#65292;&#20854;&#20013;&#28145;&#24230;&#21487;&#20197;&#36890;&#36807;&#20248;&#21270;&#35777;&#25454;&#19979;&#30028;&#26469;&#20272;&#35745;&#20026;&#26680;&#36229;&#21442;&#25968;&#12290;&#27492;&#22806;&#65292;&#21464;&#20998;&#23398;&#20064;&#29699;&#35856;&#30456;&#20301;&#24341;&#20837;&#20102;&#26412;&#24449;&#22522;&#30784;&#30340;&#31232;&#30095;&#24615;&#65292;&#20351;&#24471;&#21487;&#20197;&#22788;&#29702;&#27604;&#20197;&#21069;&#26356;&#22823;&#30340;&#36755;&#20837;&#32500;&#24230;&#65292;&#24182;&#20801;&#35768;&#23398;&#20064;&#39640;&#39057;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2303.15948</link><description>&lt;p&gt;
&#24102;&#29699;&#35856;&#29305;&#24449;&#30340;&#31232;&#30095;&#39640;&#26031;&#36807;&#31243;&#30340;&#20877;&#25506;&#35752;
&lt;/p&gt;
&lt;p&gt;
Sparse Gaussian Processes with Spherical Harmonic Features Revisited. (arXiv:2303.15948v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15948
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#24102;&#29699;&#35856;&#29305;&#24449;&#30340;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26680;&#20989;&#25968;&#65292;&#22312;&#36830;&#32493;&#28145;&#24230;&#30340;&#28145;&#24230;&#27169;&#22411;&#20013;&#20351;&#29992;&#65292;&#20854;&#20013;&#28145;&#24230;&#21487;&#20197;&#36890;&#36807;&#20248;&#21270;&#35777;&#25454;&#19979;&#30028;&#26469;&#20272;&#35745;&#20026;&#26680;&#36229;&#21442;&#25968;&#12290;&#27492;&#22806;&#65292;&#21464;&#20998;&#23398;&#20064;&#29699;&#35856;&#30456;&#20301;&#24341;&#20837;&#20102;&#26412;&#24449;&#22522;&#30784;&#30340;&#31232;&#30095;&#24615;&#65292;&#20351;&#24471;&#21487;&#20197;&#22788;&#29702;&#27604;&#20197;&#21069;&#26356;&#22823;&#30340;&#36755;&#20837;&#32500;&#24230;&#65292;&#24182;&#20801;&#35768;&#23398;&#20064;&#39640;&#39057;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#24102;&#26377;&#29699;&#35856;&#29305;&#24449;&#30340;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#24182;&#30740;&#31350;&#20102;&#19982;&#20854;&#30456;&#20851;&#30340;RKHS&#12289;&#20854;&#29305;&#24449;&#20540;&#32467;&#26500;&#20197;&#21450;&#28145;&#24230;&#27169;&#22411;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;&#22522;&#20110;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31867;&#26032;&#30340;&#26680;&#20989;&#25968;&#65292;&#23427;&#23545;&#24212;&#20110;&#20855;&#26377;&#36830;&#32493;&#28145;&#24230;&#30340;&#28145;&#24230;&#27169;&#22411;&#12290;&#22312;&#25105;&#20204;&#30340;&#20844;&#24335;&#20013;&#65292;&#28145;&#24230;&#21487;&#20197;&#36890;&#36807;&#20248;&#21270;&#35777;&#25454;&#19979;&#30028;&#26469;&#20272;&#35745;&#20026;&#26680;&#36229;&#21442;&#25968;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#21464;&#20998;&#23398;&#20064;&#29699;&#35856;&#30456;&#20301;&#24341;&#20837;&#20102;&#26412;&#24449;&#22522;&#30784;&#30340;&#31232;&#30095;&#24615;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#21487;&#20197;&#22788;&#29702;&#27604;&#20197;&#21069;&#26356;&#22823;&#30340;&#36755;&#20837;&#32500;&#24230;&#65292;&#24182;&#19988;&#20801;&#35768;&#23398;&#20064;&#39640;&#39057;&#21464;&#21270;&#12290;&#25105;&#20204;&#22312;&#26426;&#22120;&#23398;&#20064;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We revisit the Gaussian process model with spherical harmonic features and study connections between the associated RKHS, its eigenstructure and deep models. Based on this, we introduce a new class of kernels which correspond to deep models of continuous depth. In our formulation, depth can be estimated as a kernel hyper-parameter by optimizing the evidence lower bound. Further, we introduce sparseness in the eigenbasis by variational learning of the spherical harmonic phases. This enables scaling to larger input dimensions than previously, while also allowing for learning of high frequency variations. We validate our approach on machine learning benchmark datasets.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;PDExplain&#65292;&#19968;&#31181;&#35299;&#37322;&#24615;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#35813;&#31639;&#27861;&#33021;&#22815;&#36890;&#36807;&#25552;&#20379;&#23569;&#37327;&#26679;&#26412;&#30340;&#26041;&#24335;&#65292;&#39044;&#27979;&#26410;&#26469;&#26102;&#38388;&#27493;&#30340;PDE&#35299;&#65292;&#26497;&#22823;&#22320;&#21327;&#21161;&#20102;&#24314;&#31435;&#29289;&#29702;&#31185;&#23398;&#20013;&#22522;&#20110;&#25968;&#25454;&#30340;&#29616;&#35937;&#24314;&#27169;&#12290;</title><link>http://arxiv.org/abs/2303.15827</link><description>&lt;p&gt;
PDExplain&#65306;PDEs &#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#24773;&#22659;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
PDExplain: Contextual Modeling of PDEs in the Wild. (arXiv:2303.15827v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15827
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;PDExplain&#65292;&#19968;&#31181;&#35299;&#37322;&#24615;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#35813;&#31639;&#27861;&#33021;&#22815;&#36890;&#36807;&#25552;&#20379;&#23569;&#37327;&#26679;&#26412;&#30340;&#26041;&#24335;&#65292;&#39044;&#27979;&#26410;&#26469;&#26102;&#38388;&#27493;&#30340;PDE&#35299;&#65292;&#26497;&#22823;&#22320;&#21327;&#21161;&#20102;&#24314;&#31435;&#29289;&#29702;&#31185;&#23398;&#20013;&#22522;&#20110;&#25968;&#25454;&#30340;&#29616;&#35937;&#24314;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#37322;&#24615;&#30340;&#26041;&#27861;PDExplain&#29992;&#20110;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#22312;&#35757;&#32451;&#38454;&#27573;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#19968;&#20010;&#25805;&#20316;&#21592;&#23450;&#20041;&#30340;PDE&#23478;&#26063;&#30340;&#25968;&#25454;&#20197;&#21450;&#36825;&#20010;&#23478;&#26063;&#30340;&#19968;&#33324;&#24418;&#24335;&#36827;&#34892;&#39304;&#36865;&#12290;&#22312;&#25512;&#26029;&#38454;&#27573;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#20174;&#29616;&#35937;&#20013;&#25910;&#38598;&#21040;&#30340;&#26368;&#23567;&#26679;&#26412;&#65292;&#20854;&#20013;&#26679;&#26412;&#19982; PDE &#23478;&#26063;&#30456;&#20851;&#65292;&#20294;&#19981;&#19968;&#23450;&#23646;&#20110;&#35757;&#32451;&#38454;&#27573;&#30475;&#21040;&#30340;&#20855;&#20307; PDE &#38598;&#21512;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#31639;&#27861;&#22914;&#20309;&#39044;&#27979;&#26410;&#26469;&#26102;&#38388;&#27493;&#30340;PDE&#35299;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;PDE&#30340;&#21487;&#35299;&#37322;&#24418;&#24335;&#65292;&#36825;&#31181;&#29305;&#24449;&#21487;&#20197;&#21327;&#21161;&#36890;&#36807;&#29289;&#29702;&#31185;&#23398;&#25968;&#25454;&#26469;&#23545;&#29616;&#35937;&#36827;&#34892;&#24314;&#27169;&#12290;&#20026;&#20102;&#39564;&#35777;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#32771;&#23519;&#20102;&#20854;&#22312;&#39044;&#27979;&#35823;&#24046;&#21644;&#21487;&#35299;&#37322;&#24615;&#26041;&#38754;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose an explainable method for solving Partial Differential Equations by using a contextual scheme called PDExplain. During the training phase, our method is fed with data collected from an operator-defined family of PDEs accompanied by the general form of this family. In the inference phase, a minimal sample collected from a phenomenon is provided, where the sample is related to the PDE family but not necessarily to the set of specific PDEs seen in the training phase. We show how our algorithm can predict the PDE solution for future timesteps. Moreover, our method provides an explainable form of the PDE, a trait that can assist in modelling phenomena based on data in physical sciences. To verify our method, we conduct extensive experimentation, examining its quality both in terms of prediction error and explainability.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#29992;&#20110;&#20248;&#21270;&#20559;&#22909;&#21453;&#39304;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#20989;&#25968;qEUBO&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22312;&#35768;&#22810;&#35774;&#32622;&#20013;&#20248;&#20110;&#29616;&#26377;&#30340;&#37319;&#38598;&#20989;&#25968;&#12290;&#22312;&#20805;&#20998;&#30340;&#26465;&#20214;&#19979;&#65292;qEUBO&#30340;&#36951;&#25022;&#25910;&#25947;&#36895;&#24230;&#24555;&#20110;&#29616;&#26377;&#37319;&#38598;&#20989;&#25968;qEI&#12290;</title><link>http://arxiv.org/abs/2303.15746</link><description>&lt;p&gt;
qEUBO: &#22522;&#20110;&#20915;&#31574;&#29702;&#35770;&#30340;&#12289;&#29992;&#20110;&#20248;&#21270;&#20559;&#22909;&#21453;&#39304;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
qEUBO: A Decision-Theoretic Acquisition Function for Preferential Bayesian Optimization. (arXiv:2303.15746v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15746
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#29992;&#20110;&#20248;&#21270;&#20559;&#22909;&#21453;&#39304;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#20989;&#25968;qEUBO&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22312;&#35768;&#22810;&#35774;&#32622;&#20013;&#20248;&#20110;&#29616;&#26377;&#30340;&#37319;&#38598;&#20989;&#25968;&#12290;&#22312;&#20805;&#20998;&#30340;&#26465;&#20214;&#19979;&#65292;qEUBO&#30340;&#36951;&#25022;&#25910;&#25947;&#36895;&#24230;&#24555;&#20110;&#29616;&#26377;&#37319;&#38598;&#20989;&#25968;qEI&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20559;&#22909;&#36125;&#21494;&#26031;&#20248;&#21270;(PBO)&#26159;&#19968;&#31181;&#29992;&#20110;&#20351;&#29992;&#20559;&#22909;&#21453;&#39304;&#20248;&#21270;&#20915;&#31574;&#21046;&#23450;&#32773;&#28508;&#22312;&#25928;&#29992;&#20989;&#25968;&#30340;&#26694;&#26550;&#12290;&#26412;&#25991;&#23558;&#26368;&#22909;&#36873;&#39033;&#30340;&#39044;&#26399;&#25928;&#29992;(qEUBO)&#24341;&#20837;PBO&#20316;&#20026;&#19968;&#31181;&#26032;&#30340;&#37319;&#38598;&#20989;&#25968;&#12290;&#24403;&#20915;&#31574;&#21046;&#23450;&#32773;&#30340;&#21709;&#24212;&#26080;&#22122;&#22768;&#26102;&#65292;&#25105;&#20204;&#23637;&#31034;qEUBO&#26159;&#19968;&#27493;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#65292;&#24182;&#19988;&#19982;&#27969;&#34892;&#30340;&#30693;&#35782;&#26799;&#24230;&#37319;&#38598;&#20989;&#25968;&#31561;&#25928;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#65292;&#24403;&#20915;&#31574;&#21046;&#23450;&#32773;&#30340;&#21709;&#24212;&#21463;&#21040;&#22122;&#22768;&#27745;&#26579;&#26102;&#65292;qEUBO&#22312;&#19968;&#27493;&#36125;&#21494;&#26031;&#26368;&#20248;&#31574;&#30053;&#19978;&#20139;&#26377;&#38468;&#21152;&#30340;&#36817;&#20284;&#20445;&#35777;&#12290;&#25105;&#20204;&#23545;qEUBO&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#35780;&#20272;&#65292;&#24182;&#35777;&#26126;&#22312;&#35768;&#22810;&#35774;&#32622;&#20013;&#65292;&#23427;&#20248;&#20110;PBO&#30340;&#26368;&#20808;&#36827;&#37319;&#38598;&#20989;&#25968;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#65292;&#22312;&#20805;&#20998;&#30340;&#27491;&#21017;&#21270;&#26465;&#20214;&#19979;&#65292;qEUBO&#30340;&#36125;&#21494;&#26031;&#31616;&#21333;&#36951;&#25022;&#23558;&#20197;$O(1/n)$&#30340;&#36895;&#24230;&#36235;&#36817;&#20110;&#38646;&#65292;&#20854;&#20013;$n$&#26159;&#26597;&#35810;&#25968;&#37327;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23545;&#20110;&#27969;&#34892;&#30340;PBO&#37319;&#38598;&#20989;&#25968;qEI&#65292;&#31616;&#21333;&#36951;&#25022;&#25910;&#25947;&#36895;&#24230;&#36739;&#24930;&#65292;&#20026;$O(1/\sqrt{n})$&#12290;
&lt;/p&gt;
&lt;p&gt;
Preferential Bayesian optimization (PBO) is a framework for optimizing a decision maker's latent utility function using preference feedback. This work introduces the expected utility of the best option (qEUBO) as a novel acquisition function for PBO. When the decision maker's responses are noise-free, we show that qEUBO is one-step Bayes optimal and thus equivalent to the popular knowledge gradient acquisition function. We also show that qEUBO enjoys an additive constant approximation guarantee to the one-step Bayes-optimal policy when the decision maker's responses are corrupted by noise. We provide an extensive evaluation of qEUBO and demonstrate that it outperforms the state-of-the-art acquisition functions for PBO across many settings. Finally, we show that, under sufficient regularity conditions, qEUBO's Bayesian simple regret converges to zero at a rate $o(1/n)$ as the number of queries, $n$, goes to infinity. In contrast, we show that simple regret under qEI, a popular acquisiti
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#65292;&#35777;&#26126;&#20102;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#30340;Bayesian&#33258;&#30001;&#33021;&#26159;&#26377;&#30028;&#30340;&#65292;&#35828;&#26126;Bayesian&#24191;&#20041;&#35823;&#24046;&#19981;&#20250;&#22686;&#21152;&#12290;</title><link>http://arxiv.org/abs/2303.15739</link><description>&lt;p&gt;
&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#22312;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#30340;&#36125;&#21494;&#26031;&#33258;&#30001;&#33021;
&lt;/p&gt;
&lt;p&gt;
Bayesian Free Energy of Deep ReLU Neural Network in Overparametrized Cases. (arXiv:2303.15739v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15739
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#65292;&#35777;&#26126;&#20102;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#30340;Bayesian&#33258;&#30001;&#33021;&#26159;&#26377;&#30028;&#30340;&#65292;&#35828;&#26126;Bayesian&#24191;&#20041;&#35823;&#24046;&#19981;&#20250;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20154;&#24037;&#26234;&#33021;&#30340;&#35768;&#22810;&#30740;&#31350;&#39046;&#22495;&#20013;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#24050;&#34987;&#35777;&#26126;&#21487;&#29992;&#20110;&#20272;&#35745;&#39640;&#32500;&#36755;&#20837;&#31354;&#38388;&#20013;&#30340;&#26410;&#30693;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#27867;&#21270;&#24615;&#33021;&#23578;&#26410;&#20174;&#29702;&#35770;&#35282;&#24230;&#23436;&#20840;&#28548;&#28165;&#65292;&#22240;&#20026;&#23427;&#20204;&#26159;&#19981;&#21487;&#35782;&#21035;&#30340;&#21644;&#22855;&#24322;&#30340;&#23398;&#20064;&#26426;&#22120;&#12290;&#27492;&#22806;&#65292;ReLU&#20989;&#25968;&#19981;&#21487;&#24494;&#65292;&#22855;&#24322;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#20195;&#25968;&#25110;&#35299;&#26512;&#26041;&#27861;&#26080;&#27861;&#24212;&#29992;&#20110;&#23427;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#30340;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#35777;&#26126;&#20102;Bayesian&#33258;&#30001;&#33021;&#26159;&#26377;&#30028;&#30340;&#65292;&#21363;&#20351;&#23618;&#25968;&#27604;&#20272;&#35745;&#26410;&#30693;&#25968;&#25454;&#29983;&#25104;&#20989;&#25968;&#25152;&#24517;&#38656;&#30340;&#23618;&#25968;&#26356;&#22810;&#12290;&#30001;&#20110;Bayesian&#24191;&#20041;&#35823;&#24046;&#31561;&#20110;&#26679;&#26412;&#22823;&#23567;&#30340;&#33258;&#30001;&#33021;&#22686;&#21152;&#65292;&#22240;&#27492;&#25105;&#20204;&#30340;&#32467;&#26524;&#20063;&#34920;&#26126;&#65292;Bayesian&#24191;&#20041;&#35823;&#24046;&#19981;&#20250;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many research fields in artificial intelligence, it has been shown that deep neural networks are useful to estimate unknown functions on high dimensional input spaces. However, their generalization performance is not yet completely clarified from the theoretical point of view because they are nonidentifiable and singular learning machines. Moreover, a ReLU function is not differentiable, to which algebraic or analytic methods in singular learning theory cannot be applied. In this paper, we study a deep ReLU neural network in overparametrized cases and prove that the Bayesian free energy, which is equal to the minus log marginal likelihoodor the Bayesian stochastic complexity, is bounded even if the number of layers are larger than necessary to estimate an unknown data-generating function. Since the Bayesian generalization error is equal to the increase of the free energy as a function of a sample size, our result also shows that the Bayesian generalization error does not increase ev
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#36895;&#29575;&#34920;&#65292;&#20197;&#22312;&#25968;&#25454;&#20998;&#24067;&#21457;&#29983;&#21464;&#21270;&#26102;&#26368;&#23567;&#21270;SGD&#22312;&#32447;&#23398;&#20064;&#30340;&#21518;&#24724;&#65292;&#33021;&#22815;&#23545;&#20998;&#24067;&#36716;&#31227;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#21516;&#26102;&#36866;&#29992;&#20110;&#20984;&#25439;&#22833;&#20989;&#25968;&#21644;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#12290;&#26368;&#20248;&#23398;&#20064;&#36895;&#29575;&#34920;&#36890;&#24120;&#20250;&#22312;&#25968;&#25454;&#20998;&#24067;&#36716;&#31227;&#30340;&#24773;&#20917;&#19979;&#22686;&#21152;&#65292;&#33021;&#22815;&#29992;&#20110;&#39640;&#32500;&#22238;&#24402;&#27169;&#22411;&#21644;&#31070;&#32463;&#32593;&#32476;&#12290;</title><link>http://arxiv.org/abs/2303.15634</link><description>&lt;p&gt;
&#23398;&#20064;&#36895;&#29575;&#34920;&#22312;&#20998;&#24067;&#36716;&#31227;&#26465;&#20214;&#19979;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Learning Rate Schedules in the Presence of Distribution Shift. (arXiv:2303.15634v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15634
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#36895;&#29575;&#34920;&#65292;&#20197;&#22312;&#25968;&#25454;&#20998;&#24067;&#21457;&#29983;&#21464;&#21270;&#26102;&#26368;&#23567;&#21270;SGD&#22312;&#32447;&#23398;&#20064;&#30340;&#21518;&#24724;&#65292;&#33021;&#22815;&#23545;&#20998;&#24067;&#36716;&#31227;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#21516;&#26102;&#36866;&#29992;&#20110;&#20984;&#25439;&#22833;&#20989;&#25968;&#21644;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#12290;&#26368;&#20248;&#23398;&#20064;&#36895;&#29575;&#34920;&#36890;&#24120;&#20250;&#22312;&#25968;&#25454;&#20998;&#24067;&#36716;&#31227;&#30340;&#24773;&#20917;&#19979;&#22686;&#21152;&#65292;&#33021;&#22815;&#29992;&#20110;&#39640;&#32500;&#22238;&#24402;&#27169;&#22411;&#21644;&#31070;&#32463;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35774;&#35745;&#20102;&#23398;&#20064;&#36895;&#29575;&#34920;&#65292;&#20197;&#22312;&#25968;&#25454;&#20998;&#24067;&#21457;&#29983;&#21464;&#21270;&#26102;&#26368;&#23567;&#21270;SGD&#22312;&#32447;&#23398;&#20064;&#30340;&#21518;&#24724;&#12290;&#25105;&#20204;&#36890;&#36807;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#26032;&#39062;&#20998;&#26512;&#65292;&#23436;&#20840;&#34920;&#24449;&#20102;&#22312;&#32447;&#32447;&#24615;&#22238;&#24402;&#30340;&#26368;&#20248;&#23398;&#20064;&#36895;&#29575;&#34920;&#12290;&#23545;&#20110;&#19968;&#33324;&#30340;&#20984;&#25439;&#22833;&#20989;&#25968;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#23398;&#20064;&#36895;&#29575;&#34920;&#65292;&#23545;&#20998;&#24067;&#36716;&#31227;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#21482;&#26377;&#24120;&#25968;&#24046;&#24322;&#30340;&#21518;&#24724;&#19978;&#19979;&#30028;&#12290;&#23545;&#20110;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#65292;&#25105;&#20204;&#22522;&#20110;&#20272;&#35745;&#27169;&#22411;&#30340;&#26799;&#24230;&#33539;&#25968;&#23450;&#20041;&#20102;&#19968;&#31181;&#21518;&#24724;&#27010;&#24565;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#26102;&#38388;&#34920;&#65292;&#20197;&#26368;&#23567;&#21270;&#24635;&#39044;&#26399;&#21518;&#24724;&#30340;&#19978;&#38480;&#12290;&#30452;&#35266;&#22320;&#35828;&#65292;&#25105;&#20204;&#39044;&#35745;&#25439;&#22833;&#39046;&#22495;&#30340;&#21464;&#21270;&#38656;&#35201;&#26356;&#22810;&#30340;&#25506;&#32034;&#65292;&#25105;&#20204;&#35777;&#23454;&#20102;&#26368;&#20248;&#23398;&#20064;&#36895;&#29575;&#34920;&#36890;&#24120;&#20250;&#22312;&#25968;&#25454;&#20998;&#24067;&#36716;&#31227;&#30340;&#24773;&#20917;&#19979;&#22686;&#21152;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#38024;&#23545;&#39640;&#32500;&#22238;&#24402;&#27169;&#22411;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#23454;&#39564;&#65292;&#20197;&#35828;&#26126;&#36825;&#20123;&#23398;&#20064;&#36895;&#29575;&#34920;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We design learning rate schedules that minimize regret for SGD-based online learning in the presence of a changing data distribution. We fully characterize the optimal learning rate schedule for online linear regression via a novel analysis with stochastic differential equations. For general convex loss functions, we propose new learning rate schedules that are robust to distribution shift, and we give upper and lower bounds for the regret that only differ by constants. For non-convex loss functions, we define a notion of regret based on the gradient norm of the estimated models and propose a learning schedule that minimizes an upper bound on the total expected regret. Intuitively, one expects changing loss landscapes to require more exploration, and we confirm that optimal learning rate schedules typically increase in the presence of distribution shift. Finally, we provide experiments for high-dimensional regression models and neural networks to illustrate these learning rate schedule
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#23398;&#20064;&#31649;&#29702;&#38656;&#27714;&#21709;&#24212;&#65288;DR&#65289;&#36164;&#28304;&#20013;&#28040;&#36153;&#32773;&#22522;&#20934;&#20272;&#35745;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#26368;&#23567;&#20108;&#20056;&#36827;&#34892;&#20272;&#35745;&#30340;&#22312;&#32447;&#23398;&#20064;&#26041;&#26696;&#65292;&#20877;&#36890;&#36807;&#24341;&#20837;&#28608;&#21169;&#20215;&#26684;&#19978;&#30340;&#25200;&#21160;&#23454;&#29616;&#21208;&#25506;&#21644;&#24320;&#21457;&#30340;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2303.15617</link><description>&lt;p&gt;
&#38024;&#23545;&#22522;&#20110;&#28608;&#21169;&#30340;&#38656;&#27714;&#21709;&#24212;&#30340;&#22312;&#32447;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Online Learning for Incentive-Based Demand Response. (arXiv:2303.15617v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15617
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#23398;&#20064;&#31649;&#29702;&#38656;&#27714;&#21709;&#24212;&#65288;DR&#65289;&#36164;&#28304;&#20013;&#28040;&#36153;&#32773;&#22522;&#20934;&#20272;&#35745;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#26368;&#23567;&#20108;&#20056;&#36827;&#34892;&#20272;&#35745;&#30340;&#22312;&#32447;&#23398;&#20064;&#26041;&#26696;&#65292;&#20877;&#36890;&#36807;&#24341;&#20837;&#28608;&#21169;&#20215;&#26684;&#19978;&#30340;&#25200;&#21160;&#23454;&#29616;&#21208;&#25506;&#21644;&#24320;&#21457;&#30340;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#23398;&#20064;&#31649;&#29702;&#38656;&#27714;&#21709;&#24212;&#65288;DR&#65289;&#36164;&#28304;&#30340;&#38382;&#39064;&#12290;&#20856;&#22411;DR&#26426;&#21046;&#35201;&#27714;DR&#32463;&#29702;&#20026;&#21442;&#19982;&#30340;&#28040;&#36153;&#32773;&#20998;&#37197;&#19968;&#20010;&#22522;&#20934;&#65292;&#20854;&#20013;&#22522;&#20934;&#26159;&#28040;&#36153;&#32773;&#35745;&#25968;&#20107;&#23454;&#28040;&#32791;&#30340;&#20272;&#35745;&#65292;&#22914;&#26524;&#19981;&#21483;&#28040;&#36153;&#32773;&#25552;&#20379;DR&#26381;&#21153;&#65292;&#37027;&#20040;&#22522;&#20934;&#23601;&#26159;&#35745;&#25968;&#30340;&#29702;&#35770;&#28040;&#32791;&#12290;&#20272;&#31639;&#22522;&#20934;&#30340;&#25361;&#25112;&#22312;&#20110;&#28040;&#36153;&#32773;&#26377;&#40723;&#21169;&#33192;&#32960;&#22522;&#20934;&#20272;&#35745;&#30340;&#21160;&#26426;&#12290;&#25105;&#20204;&#32771;&#34385;&#23398;&#20064;&#22312;&#32447;&#20272;&#31639;&#22522;&#32447;&#21644;&#22312;&#36825;&#26679;&#30340;&#28608;&#21169;&#19979;&#20248;&#21270;&#19968;&#27573;&#26102;&#38388;&#30340;&#25805;&#20316;&#25104;&#26412;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#23398;&#20064;&#26041;&#26696;&#65292;&#23427;&#37319;&#29992;&#26368;&#23567;&#20108;&#20056;&#36827;&#34892;&#20272;&#35745;&#65292;&#21516;&#26102;&#22312;DR&#26381;&#21153;&#25110;&#36127;&#33655;&#35009;&#21098;&#30340;&#28608;&#21169;&#20215;&#26684;&#19978;&#24341;&#20837;&#25200;&#21160;&#65292;&#26088;&#22312;&#24179;&#34913;&#22312;&#32447;&#23398;&#20064;&#20013;&#20986;&#29616;&#30340;&#21208;&#25506;&#21644;&#24320;&#21457;&#30340;&#25240;&#34935;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#25105;&#20204;&#30340;&#25552;&#35758;&#26041;&#26696;&#33021;&#22815;&#23454;&#29616;&#19982;&#26368;&#20248;&#25805;&#20316;&#30456;&#27604;&#38750;&#24120;&#20302;&#30340;&#36951;&#25022;&#24230;&#65288;$ \mathcal {O} \left((\log {T})^2\right)$&#65289;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider the problem of learning online to manage Demand Response (DR) resources. A typical DR mechanism requires the DR manager to assign a baseline to the participating consumer, where the baseline is an estimate of the counterfactual consumption of the consumer had it not been called to provide the DR service. A challenge in estimating baseline is the incentive the consumer has to inflate the baseline estimate. We consider the problem of learning online to estimate the baseline and to optimize the operating costs over a period of time under such incentives. We propose an online learning scheme that employs least-squares for estimation with a perturbation to the reward price (for the DR services or load curtailment) that is designed to balance the exploration and exploitation trade-off that arises with online learning. We show that, our proposed scheme is able to achieve a very low regret of $\mathcal{O}\left((\log{T})^2\right)$ with respect to the optimal operating
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#23398;&#20064;&#20013;&#30340;&#35843;&#25972;Wasserstein&#20998;&#24067;&#40065;&#26834;&#20272;&#35745;&#26041;&#27861;&#65292;&#33021;&#22815;&#25552;&#39640;&#20272;&#35745;&#30340;&#32479;&#35745;&#24615;&#33021;&#65292;&#20445;&#25345;&#26679;&#26412;&#22806;&#24615;&#33021;&#20445;&#35777;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2303.15579</link><description>&lt;p&gt;
&#32479;&#35745;&#23398;&#20064;&#20013;&#30340;&#35843;&#25972;Wasserstein&#20998;&#24067;&#40065;&#26834;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Adjusted Wasserstein Distributionally Robust Estimator in Statistical Learning. (arXiv:2303.15579v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15579
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#23398;&#20064;&#20013;&#30340;&#35843;&#25972;Wasserstein&#20998;&#24067;&#40065;&#26834;&#20272;&#35745;&#26041;&#27861;&#65292;&#33021;&#22815;&#25552;&#39640;&#20272;&#35745;&#30340;&#32479;&#35745;&#24615;&#33021;&#65292;&#20445;&#25345;&#26679;&#26412;&#22806;&#24615;&#33021;&#20445;&#35777;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#32479;&#35745;&#23398;&#20064;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#35843;&#25972;&#30340;Wasserstein&#20998;&#24067;&#40065;&#26834;&#20272;&#35745;&#8212;&#8212;&#22522;&#20110;Wasserstein&#20998;&#24067;&#40065;&#26834;&#20272;&#35745;&#65288;WDRO&#65289;&#30340;&#38750;&#32447;&#24615;&#36716;&#25442;&#12290;&#36825;&#31181;&#36716;&#25442;&#23558;&#25552;&#39640;WDRO&#30340;&#32479;&#35745;&#24615;&#33021;&#65292;&#22240;&#20026;&#35843;&#25972;&#21518;&#30340;WDRO&#20272;&#35745;&#22120;&#28176;&#36827;&#26080;&#20559;&#24182;&#19988;&#22343;&#26041;&#35823;&#24046;&#36235;&#36817;&#20110;&#38646;&#12290;&#35843;&#25972;&#21518;&#30340;WDRO&#19981;&#20250;&#21066;&#24369;WDRO&#30340;&#26679;&#26412;&#22806;&#24615;&#33021;&#20445;&#35777;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#35843;&#25972;WDRO&#20272;&#35745;&#22120;&#30340;&#23384;&#22312;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#32473;&#20986;&#20102;&#35745;&#31639;&#35843;&#25972;WDRO&#20272;&#35745;&#22120;&#30340;&#36807;&#31243;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23558;&#23637;&#31034;&#22914;&#20309;&#22312;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#24320;&#21457;&#35843;&#25972;WDRO&#20272;&#35745;&#22120;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#35843;&#25972;&#21518;&#30340;&#20272;&#35745;&#22120;&#27604;&#32463;&#20856;&#20272;&#35745;&#22120;&#20855;&#26377;&#26356;&#22909;&#30340;&#23454;&#38469;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose an adjusted Wasserstein distributionally robust estimator -- based on a nonlinear transformation of the Wasserstein distributionally robust (WDRO) estimator in statistical learning. This transformation will improve the statistical performance of WDRO because the adjusted WDRO estimator is asymptotically unbiased and has an asymptotically smaller mean squared error. The adjusted WDRO will not mitigate the out-of-sample performance guarantee of WDRO. Sufficient conditions for the existence of the adjusted WDRO estimator are presented, and the procedure for the computation of the adjusted WDRO estimator is given. Specifically, we will show how the adjusted WDRO estimator is developed in the generalized linear model. Numerical experiments demonstrate the favorable practical performance of the adjusted estimator over the classic one.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24635;&#32467;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#28041;&#21450;&#22521;&#35757;&#12289;&#25512;&#29702;&#12289;&#19968;&#33324;&#21270;&#36793;&#30028;&#21644;&#20248;&#21270;&#38382;&#39064;&#30340;&#19968;&#32452;&#25968;&#23398;&#25361;&#25112;&#65292;&#20026;&#25968;&#23398;&#23478;&#12289;&#32479;&#35745;&#23398;&#23478;&#21644;&#29702;&#35770;&#35745;&#31639;&#26426;&#31185;&#23398;&#23478;&#25552;&#20379;&#20102;&#19982;&#28145;&#24230;&#23398;&#20064;&#39046;&#22495;&#20132;&#27969;&#30340;&#24418;&#24335;&#21270;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2303.15464</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#25968;&#23398;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
Mathematical Challenges in Deep Learning. (arXiv:2303.15464v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15464
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24635;&#32467;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#28041;&#21450;&#22521;&#35757;&#12289;&#25512;&#29702;&#12289;&#19968;&#33324;&#21270;&#36793;&#30028;&#21644;&#20248;&#21270;&#38382;&#39064;&#30340;&#19968;&#32452;&#25968;&#23398;&#25361;&#25112;&#65292;&#20026;&#25968;&#23398;&#23478;&#12289;&#32479;&#35745;&#23398;&#23478;&#21644;&#29702;&#35770;&#35745;&#31639;&#26426;&#31185;&#23398;&#23478;&#25552;&#20379;&#20102;&#19982;&#28145;&#24230;&#23398;&#20064;&#39046;&#22495;&#20132;&#27969;&#30340;&#24418;&#24335;&#21270;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#20174;2012&#24180;&#30340;ImageNet&#25361;&#25112;&#20197;&#26469;&#65292;&#28145;&#24230;&#27169;&#22411;&#24050;&#32463;&#20027;&#23472;&#20102;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#12290;&#28145;&#24230;&#27169;&#22411;&#30340;&#22823;&#23567;&#20174;&#37027;&#26102;&#36215;&#19968;&#30452;&#22312;&#22686;&#21152;&#65292;&#36825;&#32473;&#22312;&#25163;&#26426;&#12289;&#20010;&#20154;&#30005;&#33041;&#12289;&#33258;&#21160;&#39550;&#39542;&#36710;&#36742;&#21644;&#26080;&#32447;&#22522;&#31449;&#31561;&#39046;&#22495;&#24212;&#29992;&#30340;&#36825;&#19968;&#39046;&#22495;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#21015;&#20986;&#20102;&#19968;&#32452;&#38382;&#39064;&#65292;&#28085;&#30422;&#22521;&#35757;&#12289;&#25512;&#29702;&#12289;&#19968;&#33324;&#21270;&#36793;&#30028;&#21644;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#29992;&#19968;&#20123;&#24418;&#24335;&#21270;&#35821;&#35328;&#26469;&#19982;&#25968;&#23398;&#23478;&#12289;&#32479;&#35745;&#23398;&#23478;&#21644;&#29702;&#35770;&#35745;&#31639;&#26426;&#31185;&#23398;&#23478;&#20132;&#27969;&#36825;&#20123;&#25361;&#25112;&#12290;&#36825;&#26159;&#23545;&#28145;&#24230;&#23398;&#20064;&#30740;&#31350;&#38382;&#39064;&#30340;&#20027;&#35266;&#30475;&#27861;&#65292;&#23427;&#26377;&#30410;&#20110;&#38271;&#26399;&#30340;&#25216;&#26415;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep models are dominating the artificial intelligence (AI) industry since the ImageNet challenge in 2012. The size of deep models is increasing ever since, which brings new challenges to this field with applications in cell phones, personal computers, autonomous cars, and wireless base stations. Here we list a set of problems, ranging from training, inference, generalization bound, and optimization with some formalism to communicate these challenges with mathematicians, statisticians, and theoretical computer scientists. This is a subjective view of the research questions in deep learning that benefits the tech industry in long run.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31354;&#38388;&#20809;&#35843;&#21046;&#30340;SPBM&#35745;&#31639;&#27169;&#22411;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35299;&#20915;&#20219;&#20309;&#20234;&#36763;&#38382;&#39064;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#20855;&#26377;&#20302;&#31209;&#30456;&#20114;&#20316;&#29992;&#30697;&#38453;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#20855;&#26377;&#23398;&#20064;&#12289;&#20998;&#31867;&#21644;&#37319;&#26679;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2303.14993</link><description>&lt;p&gt;
&#31354;&#38388;-&#20809;&#23376;Boltzmann&#26426;&#65306;&#21033;&#29992;&#31354;&#38388;&#20809;&#35843;&#21046;&#36827;&#34892;&#20302;&#31209;&#32452;&#21512;&#20248;&#21270;&#21644;&#32479;&#35745;&#23398;&#20064;&#65288;arXiv:2303.14993v1 [cond-mat.dis-nn] CROSS LISTED&#65289;
&lt;/p&gt;
&lt;p&gt;
Spatial-photonic Boltzmann machines: low-rank combinatorial optimization and statistical learning by spatial light modulation. (arXiv:2303.14993v1 [cond-mat.dis-nn] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14993
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31354;&#38388;&#20809;&#35843;&#21046;&#30340;SPBM&#35745;&#31639;&#27169;&#22411;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35299;&#20915;&#20219;&#20309;&#20234;&#36763;&#38382;&#39064;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#20855;&#26377;&#20302;&#31209;&#30456;&#20114;&#20316;&#29992;&#30697;&#38453;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#20855;&#26377;&#23398;&#20064;&#12289;&#20998;&#31867;&#21644;&#37319;&#26679;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31354;&#38388;-&#20809;&#23376;&#20234;&#36763;&#26426;&#65288;SPIM&#65289;[D. Pierangeli et al., Phys. Rev. Lett. 122, 213902 (2019)]&#26159;&#19968;&#31181;&#20351;&#29992;&#31354;&#38388;&#20809;&#35843;&#21046;&#26377;&#25928;&#35299;&#20915;&#22823;&#35268;&#27169;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#30340;&#20809;&#23398;&#26550;&#26500;&#12290;&#28982;&#32780;&#65292;SPIM&#20165;&#33021;&#23481;&#32435;&#20855;&#26377;&#31209;&#20026;&#19968;&#30340;&#30456;&#20114;&#20316;&#29992;&#30697;&#38453;&#30340;&#20234;&#36763;&#38382;&#39064;&#65292;&#36825;&#38480;&#21046;&#20102;&#20854;&#22312;&#21508;&#31181;&#23454;&#38469;&#38382;&#39064;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;SPIM&#35745;&#31639;&#27169;&#22411;&#65292;&#21487;&#20197;&#22312;&#19981;&#25913;&#21464;&#20854;&#20809;&#23398;&#23454;&#29616;&#30340;&#24773;&#20917;&#19979;&#23481;&#32435;&#20219;&#20309;&#20234;&#36763;&#38382;&#39064;&#12290;&#35813;&#27169;&#22411;&#23545;&#20110;&#20855;&#26377;&#20302;&#31209;&#30456;&#20114;&#20316;&#29992;&#30697;&#38453;&#30340;&#20234;&#36763;&#38382;&#39064;&#65288;&#22914;&#32972;&#21253;&#38382;&#39064;&#65289;&#29305;&#21035;&#26377;&#25928;&#12290;&#27492;&#22806;&#65292;&#35813;&#27169;&#22411;&#20855;&#26377;&#23398;&#20064;&#33021;&#21147;&#65292;&#22240;&#27492;&#21487;&#20197;&#34987;&#31216;&#20026;&#31354;&#38388;&#20809;&#23376;Boltzmann&#26426;&#65288;SPBM&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20351;&#29992;&#20855;&#26377;&#20302;&#31209;&#30456;&#20114;&#20316;&#29992;&#30340;SPBM&#26377;&#25928;&#22320;&#23454;&#29616;&#20102;MNIST&#25163;&#20889;&#25968;&#23383;&#22270;&#20687;&#30340;&#23398;&#20064;&#12289;&#20998;&#31867;&#21644;&#37319;&#26679;&#12290;&#22240;&#27492;&#65292;&#25152;&#25552;&#20986;&#30340;SPBM&#27169;&#22411;&#34920;&#29616;&#20986;&#26356;&#39640;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The spatial-photonic Ising machine (SPIM) [D. Pierangeli et al., Phys. Rev. Lett. 122, 213902 (2019)] is a promising optical architecture utilizing spatial light modulation for solving large-scale combinatorial optimization problems efficiently. However, the SPIM can accommodate Ising problems with only rank-one interaction matrices, which limits its applicability to various real-world problems. In this Letter, we propose a new computing model for the SPIM that can accommodate any Ising problem without changing its optical implementation. The proposed model is particularly efficient for Ising problems with low-rank interaction matrices, such as knapsack problems. Moreover, the model acquires learning ability and can thus be termed a spatial-photonic Boltzmann machine (SPBM). We demonstrate that learning, classification, and sampling of the MNIST handwritten digit images are achieved efficiently using SPBMs with low-rank interactions. Thus, the proposed SPBM model exhibits higher practi
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#30830;&#23450;&#24615;&#8221;&#21644;&#8220;&#19981;&#30830;&#23450;&#24615;&#8221;&#30340;&#24471;&#20998;&#26041;&#27861;&#26469;&#37327;&#21270;&#20998;&#31867;&#20915;&#31574;&#20013;&#39044;&#27979;&#30340;&#36136;&#37327;&#21644;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.14568</link><description>&lt;p&gt;
&#37327;&#21270;&#20998;&#31867;&#20915;&#31574;&#30340;&#30830;&#23450;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#27979;&#37327;
&lt;/p&gt;
&lt;p&gt;
Measuring Classification Decision Certainty and Doubt. (arXiv:2303.14568v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14568
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#30830;&#23450;&#24615;&#8221;&#21644;&#8220;&#19981;&#30830;&#23450;&#24615;&#8221;&#30340;&#24471;&#20998;&#26041;&#27861;&#26469;&#37327;&#21270;&#20998;&#31867;&#20915;&#31574;&#20013;&#39044;&#27979;&#30340;&#36136;&#37327;&#21644;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30830;&#23450;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#30340;&#23450;&#37327;&#34920;&#24449;&#21644;&#20272;&#35745;&#22312;&#20248;&#21270;&#21644;&#20915;&#31574;&#36807;&#31243;&#20013;&#20855;&#26377;&#22522;&#30784;&#37325;&#35201;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#30452;&#35266;&#30340;&#24471;&#20998;&#65292;&#31216;&#20026;&#8220;&#30830;&#23450;&#24615;&#8221;&#21644;&#8220;&#19981;&#30830;&#23450;&#24615;&#8221;&#65292;&#21487;&#22312;&#36125;&#21494;&#26031;&#21644;&#39057;&#29575;&#20027;&#20041;&#26694;&#26550;&#19979;&#29992;&#20110;&#35780;&#20272;&#21644;&#27604;&#36739;&#65288;&#22810;&#65289;&#20998;&#31867;&#20915;&#31574;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#30340;&#39044;&#27979;&#36136;&#37327;&#21644;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantitative characterizations and estimations of uncertainty are of fundamental importance in optimization and decision-making processes. Herein, we propose intuitive scores, which we call \textit{certainty} and \textit{doubt}, that can be used in both a Bayesian and frequentist framework to assess and compare the quality and uncertainty of predictions in (multi-)classification decision machine learning problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110; mini-batch SGD &#20272;&#35745;&#22120;&#36827;&#34892; $\varphi$-&#28151;&#21512;&#25968;&#25454;&#32479;&#35745;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#26222;&#36890;&#26041;&#27861;&#22312;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#26102;&#38754;&#20020;&#30340;&#30456;&#20851;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2302.12717</link><description>&lt;p&gt;
&#22522;&#20110; $\varphi$-&#28151;&#21512;&#25968;&#25454;&#30340;&#38543;&#26426;&#26799;&#24230;&#26041;&#27861;&#22312;&#32479;&#35745;&#25512;&#26029;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Statistical Inference with Stochastic Gradient Methods under $\phi$-mixing Data. (arXiv:2302.12717v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.12717
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110; mini-batch SGD &#20272;&#35745;&#22120;&#36827;&#34892; $\varphi$-&#28151;&#21512;&#25968;&#25454;&#32479;&#35745;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#26222;&#36890;&#26041;&#27861;&#22312;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#26102;&#38754;&#20020;&#30340;&#30456;&#20851;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#26159;&#19968;&#31181;&#21487;&#25193;&#23637;&#19988;&#20869;&#23384;&#25928;&#29575;&#39640;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#36866;&#29992;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#21644;&#27969;&#24335;&#25968;&#25454;&#30340;&#22788;&#29702;&#65292;&#22240;&#27492;&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#21644;&#27426;&#36814;&#12290;SGD &#22522;&#20110;&#30340;&#20272;&#35745;&#22120;&#22312;&#32479;&#35745;&#25512;&#26029;&#20013;&#30340;&#24212;&#29992;&#65292;&#22914;&#21306;&#38388;&#20272;&#35745;&#65292;&#20063;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#30456;&#20851;&#24037;&#20316;&#37117;&#26159;&#22522;&#20110;&#29420;&#31435;&#21516;&#20998;&#24067;&#35266;&#27979;&#25110;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#12290;&#24403;&#35266;&#27979;&#25968;&#25454;&#26469;&#33258;&#19968;&#20010;&#28151;&#21512;&#26102;&#38388;&#24207;&#21015;&#26102;&#65292;&#22914;&#20309;&#36827;&#34892;&#26377;&#25928;&#30340;&#32479;&#35745;&#25512;&#26029;&#23578;&#26410;&#30740;&#31350;&#12290;&#20107;&#23454;&#19978;&#65292;&#35266;&#27979;&#25968;&#25454;&#20043;&#38388;&#30340;&#19968;&#33324;&#30456;&#20851;&#24615;&#32473;&#21306;&#38388;&#20272;&#35745;&#24102;&#26469;&#20102;&#25361;&#25112;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#21487;&#33021;&#20250;&#24573;&#30053;&#36825;&#31181;&#30456;&#20851;&#24615;&#24182;&#23548;&#33268;&#26080;&#25928;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110; mini-batch SGD &#20272;&#35745;&#22120;&#36827;&#34892; $\varphi$-&#28151;&#21512;&#25968;&#25454;&#32479;&#35745;&#25512;&#26029;&#30340;&#26041;&#27861;&#12290;&#32622;&#20449;&#21306;&#38388;&#26159;&#20351;&#29992;&#30456;&#20851;&#30340; mini-batch bootstrap SGD &#31243;&#24207;&#26500;&#24314;&#30340;&#12290;&#36890;&#36807;&#20351;&#29992; \cite{yu1994rates} &#20013;&#30340; &#8220;&#29420;&#31435;&#22359;&#8221; &#25216;&#24039;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic gradient descent (SGD) is a scalable and memory-efficient optimization algorithm for large datasets and stream data, which has drawn a great deal of attention and popularity. The applications of SGD-based estimators to statistical inference such as interval estimation have also achieved great success. However, most of the related works are based on i.i.d. observations or Markov chains. When the observations come from a mixing time series, how to conduct valid statistical inference remains unexplored. As a matter of fact, the general correlation among observations imposes a challenge on interval estimation. Most existing methods may ignore this correlation and lead to invalid confidence intervals. In this paper, we propose a mini-batch SGD estimator for statistical inference when the data is $\phi$-mixing. The confidence intervals are constructed using an associated mini-batch bootstrap SGD procedure. Using ``independent block'' trick from \cite{yu1994rates}, we show that the
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20998;&#24067;&#24335;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#39640;&#32500;&#31232;&#30095;Cox&#27604;&#20363;&#39118;&#38505;&#27169;&#22411;&#20013;&#20272;&#35745;&#21644;&#25512;&#26029;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#24046;&#26041;&#27861;&#65292;&#25105;&#20204;&#21487;&#20197;&#20135;&#29983;&#28176;&#36817;&#26377;&#25928;&#30340;&#20998;&#24067;&#24335;&#32622;&#20449;&#21306;&#38388;&#65292;&#24182;&#25552;&#20379;&#20102;&#26377;&#25928;&#30340;&#20998;&#24067;&#24335;&#20551;&#35774;&#26816;&#39564;&#12290;</title><link>http://arxiv.org/abs/2302.12111</link><description>&lt;p&gt;
&#38754;&#21521;Cox&#27169;&#22411;&#30340;&#39640;&#25928;&#36890;&#20449;&#24335;&#20998;&#24067;&#24335;&#20272;&#35745;&#21644;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Communication-Efficient Distributed Estimation and Inference for Cox's Model. (arXiv:2302.12111v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.12111
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20998;&#24067;&#24335;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#39640;&#32500;&#31232;&#30095;Cox&#27604;&#20363;&#39118;&#38505;&#27169;&#22411;&#20013;&#20272;&#35745;&#21644;&#25512;&#26029;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#24046;&#26041;&#27861;&#65292;&#25105;&#20204;&#21487;&#20197;&#20135;&#29983;&#28176;&#36817;&#26377;&#25928;&#30340;&#20998;&#24067;&#24335;&#32622;&#20449;&#21306;&#38388;&#65292;&#24182;&#25552;&#20379;&#20102;&#26377;&#25928;&#30340;&#20998;&#24067;&#24335;&#20551;&#35774;&#26816;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#22240;&#38544;&#31169;&#21644;&#25152;&#26377;&#26435;&#38382;&#39064;&#26080;&#27861;&#20849;&#20139;&#20010;&#20307;&#25968;&#25454;&#30340;&#22810;&#20013;&#24515;&#29983;&#29289;&#21307;&#23398;&#30740;&#31350;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#39640;&#32500;&#31232;&#30095;Cox&#27604;&#20363;&#39118;&#38505;&#27169;&#22411;&#30340;&#36890;&#20449;&#39640;&#25928;&#36845;&#20195;&#20998;&#24067;&#24335;&#31639;&#27861;&#29992;&#20110;&#20272;&#35745;&#21644;&#25512;&#26029;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#21363;&#20351;&#36827;&#34892;&#20102;&#30456;&#23545;&#36739;&#23569;&#30340;&#36845;&#20195;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#20540;&#22312;&#38750;&#24120;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#21487;&#20197;&#36798;&#21040;&#19982;&#29702;&#24819;&#20840;&#26679;&#26412;&#20272;&#35745;&#20540;&#30456;&#21516;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#20026;&#20102;&#26500;&#24314;&#39640;&#32500;&#21361;&#38505;&#22238;&#24402;&#31995;&#25968;&#30340;&#32447;&#24615;&#32452;&#21512;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#24046;&#26041;&#27861;&#65292;&#24314;&#31435;&#20102;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#33268;&#30340;&#26041;&#24046;&#20272;&#35745;&#65292;&#21487;&#20197;&#20135;&#29983;&#28176;&#36817;&#26377;&#25928;&#30340;&#20998;&#24067;&#24335;&#32622;&#20449;&#21306;&#38388;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#22522;&#20110;&#35013;&#39280;&#20998;&#25968;&#26816;&#39564;&#30340;&#20219;&#24847;&#22352;&#26631;&#20803;&#32032;&#30340;&#26377;&#25928;&#21644;&#24378;&#22823;&#30340;&#20998;&#24067;&#24335;&#20551;&#35774;&#26816;&#39564;&#12290;&#25105;&#20204;&#36824;&#20801;&#35768;&#26102;&#38388;&#20381;&#36182;&#21327;&#21464;&#37327;&#20197;&#21450;&#34987;&#23457;&#26597;&#30340;&#29983;&#23384;&#26102;&#38388;&#12290;&#22312;&#22810;&#31181;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#25968;&#23383;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by multi-center biomedical studies that cannot share individual data due to privacy and ownership concerns, we develop communication-efficient iterative distributed algorithms for estimation and inference in the high-dimensional sparse Cox proportional hazards model. We demonstrate that our estimator, even with a relatively small number of iterations, achieves the same convergence rate as the ideal full-sample estimator under very mild conditions. To construct confidence intervals for linear combinations of high-dimensional hazard regression coefficients, we introduce a novel debiased method, establish central limit theorems, and provide consistent variance estimators that yield asymptotically valid distributed confidence intervals. In addition, we provide valid and powerful distributed hypothesis tests for any coordinate element based on a decorrelated score test. We allow time-dependent covariates as well as censored survival times. Extensive numerical experiments on both s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#30340;&#25968;&#25454;&#22686;&#24378;&#26694;&#26550;&#65292;&#29992;&#20110;&#23398;&#20064;&#21040;&#21487;&#20197;&#27867;&#21270;&#22320;&#20248;&#21270;&#22120;&#21644;&#20248;&#21270;&#23545;&#35937;&#12290;&#35813;&#26694;&#26550;&#21487;&#20197;&#36731;&#26494;&#22320;&#19982;&#29616;&#26377;&#30340; L2O &#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#24182;&#22312;&#20248;&#21270;&#22120;&#21644;&#20248;&#21270;&#23545;&#35937;&#30340;&#19968;&#33324;&#21270;&#24615;&#33021;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20248;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2302.11085</link><description>&lt;p&gt;
&#22312;&#12300;&#23398;&#20064;&#20248;&#21270;&#12301;&#20013;&#23398;&#20064;&#19968;&#33324;&#21270;&#30340;&#20445;&#35777;&#65288;Learning to Generalize Provably in Learning to Optimize&#65289;
&lt;/p&gt;
&lt;p&gt;
Learning to Generalize Provably in Learning to Optimize. (arXiv:2302.11085v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.11085
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#30340;&#25968;&#25454;&#22686;&#24378;&#26694;&#26550;&#65292;&#29992;&#20110;&#23398;&#20064;&#21040;&#21487;&#20197;&#27867;&#21270;&#22320;&#20248;&#21270;&#22120;&#21644;&#20248;&#21270;&#23545;&#35937;&#12290;&#35813;&#26694;&#26550;&#21487;&#20197;&#36731;&#26494;&#22320;&#19982;&#29616;&#26377;&#30340; L2O &#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#24182;&#22312;&#20248;&#21270;&#22120;&#21644;&#20248;&#21270;&#23545;&#35937;&#30340;&#19968;&#33324;&#21270;&#24615;&#33021;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20248;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#12300;&#23398;&#20064;&#20248;&#21270;&#12301;&#65288;Learning to optimize&#65292;L2O&#65289;&#24050;&#32463;&#21464;&#24471;&#36234;&#26469;&#36234;&#27969;&#34892;&#65292;&#36890;&#36807;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#33258;&#21160;&#21270;&#35774;&#35745;&#20248;&#21270;&#22120;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340; L2O &#26041;&#27861;&#22312;&#33267;&#23569;&#20004;&#20010;&#26041;&#38754;&#34920;&#29616;&#19981;&#20339;&#65306;&#65288;i&#65289;&#23558; L2O &#35774;&#35745;&#30340;&#20248;&#21270;&#22120;&#24212;&#29992;&#20110;&#26410;&#35265;&#36807;&#30340;&#20248;&#21270;&#23545;&#35937;&#26102;&#38477;&#20302;&#20854;&#25439;&#22833;&#20989;&#25968;&#20540;&#65288;&#20248;&#21270;&#22120;&#19968;&#33324;&#21270;&#25110;&#8220;&#21487;&#27867;&#21270;&#30340;&#20248;&#21270;&#22120;&#23398;&#20064;&#8221;&#65289;&#65307;&#20197;&#21450;&#65288;ii&#65289;&#30001;&#20248;&#21270;&#22120;&#35757;&#32451;&#30340;&#20248;&#21270;&#23545;&#35937;&#65288;&#26412;&#36523;&#20026;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65289;&#22312;&#20934;&#30830;&#24615;&#19978;&#38754;&#23545;&#26410;&#35265;&#36807;&#30340;&#25968;&#25454;&#34920;&#29616;&#30340;&#27979;&#35797;&#24615;&#33021;&#65288;&#20248;&#21270;&#23545;&#35937;&#19968;&#33324;&#21270;&#25110;&#8220;&#23398;&#20064;&#19968;&#33324;&#21270;&#8221;&#65289;&#12290;&#34429;&#28982;&#20248;&#21270;&#22120;&#19968;&#33324;&#21270;&#26368;&#36817;&#24050;&#34987;&#30740;&#31350;&#65292;&#20294;&#20248;&#21270;&#23545;&#35937;&#19968;&#33324;&#21270;&#22312; L2O &#19978;&#23578;&#26410;&#24471;&#21040;&#20005;&#26684;&#30740;&#31350;&#65292;&#36825;&#26159;&#26412;&#25991;&#30340;&#30446;&#30340;&#12290;&#25105;&#20204;&#39318;&#20808;&#29702;&#35770;&#19978;&#24314;&#31435;&#20102;&#23616;&#37096;&#29109;&#19982; Hessian &#20043;&#38388;&#30340;&#38544;&#24335;&#32852;&#31995;&#65292;&#20174;&#32780;&#32479;&#19968;&#20102;&#23427;&#20204;&#22312;&#36890;&#29992;&#20248;&#21270;&#25216;&#26415;&#30340;&#25163;&#24037;&#35774;&#35745;&#20013;&#30340;&#20316;&#29992;&#12290;&#22522;&#20110;&#36825;&#31181;&#32852;&#31995;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340; &#8220;&#25968;&#25454;&#22686;&#24378;&#26694;&#26550;" &#26469;&#23398;&#20064; L2O &#30340;&#19968;&#33324;&#21270;&#23454;&#29616;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#30001;&#20004;&#37096;&#20998;&#32452;&#25104;&#65306;&#19968;&#37096;&#20998;&#26159; GO &#27169;&#22359;&#65292;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#26368;&#22823;&#21270;&#36890;&#29992;&#21270;&#30446;&#26631;&#23398;&#20064;&#19968;&#20010;&#36890;&#29992;&#21270;&#31639;&#27861;&#65307;&#21478;&#19968;&#37096;&#20998;&#26159;&#20248;&#21270;&#23545;&#35937;&#27169;&#22359;&#65292;&#36890;&#36807;&#21487;&#24494;&#20998;&#20248;&#21270;&#22120;&#21644;&#26631;&#20934;&#20132;&#21449;&#29109;&#25439;&#22833;&#20989;&#25968;&#23398;&#20064;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#36731;&#26494;&#19982;&#29616;&#26377;&#30340; L2O &#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#24182;&#22312;&#20248;&#21270;&#22120;&#21644;&#20248;&#21270;&#23545;&#35937;&#30340;&#19968;&#33324;&#21270;&#24615;&#33021;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20248;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning to optimize (L2O) has gained increasing popularity, which automates the design of optimizers by data-driven approaches. However, current L2O methods often suffer from poor generalization performance in at least two folds: (i) applying the L2O-learned optimizer to unseen optimizees, in terms of lowering their loss function values (optimizer generalization, or ``generalizable learning of optimizers"); and (ii) the test performance of an optimizee (itself as a machine learning model), trained by the optimizer, in terms of the accuracy over unseen data (optimizee generalization, or ``learning to generalize"). While the optimizer generalization has been recently studied, the optimizee generalization (or learning to generalize) has not been rigorously studied in the L2O context, which is the aim of this paper. We first theoretically establish an implicit connection between the local entropy and the Hessian, and hence unify their roles in the handcrafted design of generalizable optim
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102; JANA &#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#22797;&#26434;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#36817;&#20284;&#35745;&#31639;&#12290;&#36890;&#36807;&#31471;&#21040;&#31471;&#35757;&#32451;&#19977;&#20010;&#31070;&#32463;&#32593;&#32476;&#26469;&#23454;&#29616;&#20998;&#25674;&#30340;&#36817;&#20284;&#21518;&#39564;&#21644;&#20284;&#28982;&#65292;&#20026;&#36125;&#21494;&#26031;&#24037;&#20316;&#27969;&#31243;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#36884;&#24452;&#12290;&#27492;&#26041;&#27861;&#22312;&#22810;&#31181;&#27169;&#25311;&#27169;&#22411;&#20013;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#21512;&#26657;&#20934;&#35786;&#26029;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2302.09125</link><description>&lt;p&gt;
JANA&#65306;&#22797;&#26434;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#32852;&#21512;&#20998;&#25674;&#36817;&#20284;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
JANA: Jointly Amortized Neural Approximation of Complex Bayesian Models. (arXiv:2302.09125v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09125
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102; JANA &#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#22797;&#26434;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#36817;&#20284;&#35745;&#31639;&#12290;&#36890;&#36807;&#31471;&#21040;&#31471;&#35757;&#32451;&#19977;&#20010;&#31070;&#32463;&#32593;&#32476;&#26469;&#23454;&#29616;&#20998;&#25674;&#30340;&#36817;&#20284;&#21518;&#39564;&#21644;&#20284;&#28982;&#65292;&#20026;&#36125;&#21494;&#26031;&#24037;&#20316;&#27969;&#31243;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#36884;&#24452;&#12290;&#27492;&#26041;&#27861;&#22312;&#22810;&#31181;&#27169;&#25311;&#27169;&#22411;&#20013;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#21512;&#26657;&#20934;&#35786;&#26029;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#8220;&#32852;&#21512;&#20998;&#25674;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;&#8221;&#65288;JANA&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#36125;&#21494;&#26031;&#20195;&#29702;&#24314;&#27169;&#21644;&#22522;&#20110;&#27169;&#25311;&#30340;&#25512;&#29702;&#20013;&#20986;&#29616;&#30340;&#38590;&#20197;&#35745;&#31639;&#30340;&#20284;&#28982;&#20989;&#25968;&#21644;&#21518;&#39564;&#23494;&#24230;&#12290;&#25105;&#20204;&#20197;&#31471;&#21040;&#31471;&#30340;&#26041;&#24335;&#35757;&#32451;&#19977;&#20010;&#30456;&#20114;&#34917;&#20805;&#30340;&#31070;&#32463;&#32593;&#32476;&#65306;1&#65289;&#19968;&#20010;&#24635;&#32467;&#32593;&#32476;&#65292;&#23558;&#20010;&#21035;&#25968;&#25454;&#28857;&#12289;&#38598;&#21512;&#25110;&#26102;&#38388;&#24207;&#21015;&#21387;&#32553;&#25104;&#20449;&#24687;&#23884;&#20837;&#21521;&#37327;&#65307;2&#65289;&#19968;&#20010;&#21518;&#39564;&#32593;&#32476;&#65292;&#23398;&#20064;&#20998;&#25674;&#30340;&#36817;&#20284;&#21518;&#39564;&#65307;3&#65289;&#19968;&#20010;&#20284;&#28982;&#32593;&#32476;&#65292;&#23398;&#20064;&#20998;&#25674;&#30340;&#36817;&#20284;&#20284;&#28982;&#12290;&#23427;&#20204;&#30340;&#20132;&#20114;&#20026;&#20998;&#25674;&#36793;&#32536;&#20284;&#28982;&#21644;&#21518;&#39564;&#39044;&#27979;&#20272;&#35745;&#25552;&#20379;&#20102;&#26032;&#30340;&#36884;&#24452;&#65292;&#36825;&#26159;&#36125;&#21494;&#26031;&#24037;&#20316;&#27969;&#31243;&#30340;&#20004;&#20010;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#24120;&#24120;&#23545;&#20110;&#26631;&#20934;&#26041;&#27861;&#26469;&#35828;&#22826;&#26114;&#36149;&#20102;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#27169;&#25311;&#27169;&#22411;&#20013;&#23545;JANA&#30340;&#20445;&#30495;&#24230;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#65292;&#19982;&#26368;&#20808;&#36827;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#24378;&#22823;&#32780;&#21487;&#35299;&#37322;&#30340;&#32852;&#21512;&#26657;&#20934;&#35786;&#26029;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#24490;&#29615;&#20284;&#28982;&#32593;&#32476;&#27169;&#25311;&#22797;&#26434;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work proposes ''jointly amortized neural approximation'' (JANA) of intractable likelihood functions and posterior densities arising in Bayesian surrogate modeling and simulation-based inference. We train three complementary networks in an end-to-end fashion: 1) a summary network to compress individual data points, sets, or time series into informative embedding vectors; 2) a posterior network to learn an amortized approximate posterior; and 3) a likelihood network to learn an amortized approximate likelihood. Their interaction opens a new route to amortized marginal likelihood and posterior predictive estimation -- two important ingredients of Bayesian workflows that are often too expensive for standard methods. We benchmark the fidelity of JANA on a variety of simulation models against state-of-the-art Bayesian methods and propose a powerful and interpretable diagnostic for joint calibration. In addition, we investigate the ability of recurrent likelihood networks to emulate comp
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#28145;&#24230;&#40654;&#26364;&#32593;&#32476;&#23545;EEG&#30340;&#24212;&#29992;&#65292;&#25506;&#35752;&#20102;&#32593;&#32476;&#22823;&#23567;&#12289;&#31471;&#21040;&#31471;&#33021;&#21147;&#12289;&#27169;&#22411;&#35757;&#32451;&#23545;&#27169;&#22411;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#27604;&#36739;&#20102;&#20854;&#19982;&#22522;&#20110;&#40654;&#26364;&#20960;&#20309;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2212.10426</link><description>&lt;p&gt;
EEG&#35299;&#30721;&#30340;&#28145;&#24230;&#40654;&#26364;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Deep Riemannian Networks for EEG Decoding. (arXiv:2212.10426v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.10426
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#28145;&#24230;&#40654;&#26364;&#32593;&#32476;&#23545;EEG&#30340;&#24212;&#29992;&#65292;&#25506;&#35752;&#20102;&#32593;&#32476;&#22823;&#23567;&#12289;&#31471;&#21040;&#31471;&#33021;&#21147;&#12289;&#27169;&#22411;&#35757;&#32451;&#23545;&#27169;&#22411;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#27604;&#36739;&#20102;&#20854;&#19982;&#22522;&#20110;&#40654;&#26364;&#20960;&#20309;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#22312;&#30005;&#33041;&#33041;&#30005;&#22270;&#65288;EEG&#65289;&#35299;&#30721;&#20219;&#21153;&#20013;&#65292;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#36890;&#24120;&#26159;&#30001;&#28145;&#24230;&#23398;&#20064;&#25110;&#22522;&#20110;&#40654;&#26364;&#20960;&#20309;&#30340;&#35299;&#30721;&#22120;&#23454;&#29616;&#30340;&#12290;&#26368;&#36817;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#20154;&#23545;&#28145;&#24230;&#40654;&#26364;&#32593;&#32476;&#65288;DRNs&#65289;&#20135;&#29983;&#20102;&#20852;&#36259;&#65292;&#21487;&#33021;&#32467;&#21512;&#20102;&#20043;&#21069;&#20004;&#31867;&#26041;&#27861;&#30340;&#20248;&#28857;&#12290;&#28982;&#32780;&#65292;&#36824;&#26377;&#19968;&#31995;&#21015;&#38382;&#39064;&#38656;&#35201;&#36827;&#19968;&#27493;&#27934;&#23519;&#65292;&#20197;&#38138;&#24179;DRNs&#22312;EEG&#20013;&#26356;&#24191;&#27867;&#24212;&#29992;&#30340;&#36947;&#36335;&#12290;&#36825;&#20123;&#38382;&#39064;&#21253;&#25324;&#26550;&#26500;&#35774;&#35745;&#38382;&#39064;&#65292;&#22914;&#32593;&#32476;&#22823;&#23567;&#21644;&#31471;&#21040;&#31471;&#33021;&#21147;&#65292;&#20197;&#21450;&#27169;&#22411;&#35757;&#32451;&#38382;&#39064;&#12290;&#36825;&#20123;&#22240;&#32032;&#22914;&#20309;&#24433;&#21709;&#27169;&#22411;&#24615;&#33021;&#23578;&#26410;&#34987;&#25506;&#32034;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#32593;&#32476;&#20013;&#30340;&#25968;&#25454;&#22914;&#20309;&#36716;&#25442;&#65292;&#20197;&#21450;&#26159;&#21542;&#19982;&#20256;&#32479;&#30340;EEG&#35299;&#30721;&#30456;&#20851;&#20063;&#19981;&#28165;&#26970;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#20998;&#26512;&#20855;&#26377;&#24191;&#27867;&#36229;&#21442;&#25968;&#30340;DRNs&#26469;&#22880;&#23450;&#36825;&#20123;&#20027;&#39064;&#39046;&#22495;&#30340;&#22522;&#30784;&#12290;&#20351;&#29992;&#20004;&#20010;&#20844;&#20849;EEG&#25968;&#25454;&#38598;&#27979;&#35797;&#20102;&#32593;&#32476;&#65292;&#24182;&#19982;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;&#40654;&#26364;&#20960;&#20309;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
State-of-the-art performance in electroencephalography (EEG) decoding tasks is currently often achieved with either Deep-Learning or Riemannian-Geometry-based decoders. Recently, there is growing interest in Deep Riemannian Networks (DRNs) possibly combining the advantages of both previous classes of methods. However, there are still a range of topics where additional insight is needed to pave the way for a more widespread application of DRNs in EEG. These include architecture design questions such as network size and end-to-end ability as well as model training questions. How these factors affect model performance has not been explored. Additionally, it is not clear how the data within these networks is transformed, and whether this would correlate with traditional EEG decoding. Our study aims to lay the groundwork in the area of these topics through the analysis of DRNs for EEG with a wide range of hyperparameters. Networks were tested on two public EEG datasets and compared with sta
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#39640;&#26031;&#27169;&#22411;&#20272;&#35745;&#29305;&#24449;&#20998;&#24067;&#21442;&#25968;&#36827;&#34892;&#39044;&#27979;&#27867;&#21270;&#35823;&#24046;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35745;&#31639;&#31867;&#26465;&#20214;&#23494;&#24230;&#36317;&#31163;&#20272;&#35745;&#21487;&#20197;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#20934;&#30830;&#24230;&#12290;</title><link>http://arxiv.org/abs/2212.06461</link><description>&lt;p&gt;
&#19968;&#31181;&#39044;&#27979;Few-Shot&#20998;&#31867;&#27867;&#21270;&#30340;&#32479;&#35745;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Statistical Model for Predicting Generalization in Few-Shot Classification. (arXiv:2212.06461v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.06461
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#39640;&#26031;&#27169;&#22411;&#20272;&#35745;&#29305;&#24449;&#20998;&#24067;&#21442;&#25968;&#36827;&#34892;&#39044;&#27979;&#27867;&#21270;&#35823;&#24046;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35745;&#31639;&#31867;&#26465;&#20214;&#23494;&#24230;&#36317;&#31163;&#20272;&#35745;&#21487;&#20197;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#20934;&#30830;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#31867;&#22120;&#27867;&#21270;&#35823;&#24046;&#30340;&#20272;&#35745;&#36890;&#24120;&#20381;&#36182;&#20110;&#39564;&#35777;&#38598;&#12290;&#28982;&#32780;&#65292;&#22312;Few-Shot&#23398;&#20064;&#22330;&#26223;&#20013;&#65292;&#24456;&#38590;&#33719;&#24471;&#36825;&#26679;&#30340;&#39564;&#35777;&#38598;&#65292;&#36825;&#26159;&#35813;&#39046;&#22495;&#20013;&#19968;&#20010;&#39640;&#24230;&#34987;&#24573;&#35270;&#30340;&#32570;&#28857;&#12290;&#22240;&#27492;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#29305;&#24449;&#20998;&#24067;&#30340;&#39640;&#26031;&#27169;&#22411;&#65292;&#36890;&#36807;&#20272;&#35745;&#36825;&#20010;&#27169;&#22411;&#30340;&#21442;&#25968;&#65292;&#25105;&#20204;&#33021;&#22815;&#39044;&#27979;&#22312;&#26032;&#30340;Few-Shot&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#20998;&#31867;&#24615;&#33021;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#31867;&#26465;&#20214;&#23494;&#24230;&#20043;&#38388;&#20934;&#30830;&#30340;&#36317;&#31163;&#20272;&#35745;&#26159;&#20934;&#30830;&#35780;&#20272;&#27867;&#21270;&#24615;&#33021;&#30340;&#20851;&#38190;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#20559;&#20272;&#35745;&#22120;&#26469;&#35745;&#31639;&#36825;&#20123;&#36317;&#31163;&#65292;&#24182;&#23558;&#20854;&#38598;&#25104;&#21040;&#25105;&#20204;&#30340;&#25968;&#20540;&#20998;&#26512;&#20013;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#32988;&#36807;&#20102;&#20854;&#20182;&#26041;&#27861;&#65292;&#20363;&#22914;&#30041;&#19968;&#27861;-Cross Validation &#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
The estimation of the generalization error of classifiers often relies on a validation set. Such a set is hardly available in few-shot learning scenarios, a highly disregarded shortcoming in the field. In these scenarios, it is common to rely on features extracted from pre-trained neural networks combined with distance-based classifiers such as nearest class mean. In this work, we introduce a Gaussian model of the feature distribution. By estimating the parameters of this model, we are able to predict the generalization error on new classification tasks with few samples. We observe that accurate distance estimates between class-conditional densities are the key to accurate estimates of the generalization performance. Therefore, we propose an unbiased estimator for these distances and integrate it in our numerical analysis. We empirically show that our approach outperforms alternatives such as the leave-one-out cross-validation strategy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#35889;&#26041;&#27861;SPORADIC&#65292;&#22312;&#20960;&#20046;&#32447;&#24615;&#31232;&#30095;&#24230;&#19979;&#30340;&#23383;&#20856;&#23398;&#20064;&#38382;&#39064;&#20013;&#21487;&#20197;&#24674;&#22797;&#36229;&#23436;&#22791;&#23383;&#20856;&#12290;</title><link>http://arxiv.org/abs/2210.10855</link><description>&lt;p&gt;
&#20960;&#20046;&#32447;&#24615;&#31232;&#30095;&#24230;&#19979;&#30340;&#23383;&#20856;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Dictionary Learning for the Almost-Linear Sparsity Regime. (arXiv:2210.10855v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.10855
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#35889;&#26041;&#27861;SPORADIC&#65292;&#22312;&#20960;&#20046;&#32447;&#24615;&#31232;&#30095;&#24230;&#19979;&#30340;&#23383;&#20856;&#23398;&#20064;&#38382;&#39064;&#20013;&#21487;&#20197;&#24674;&#22797;&#36229;&#23436;&#22791;&#23383;&#20856;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23383;&#20856;&#23398;&#20064;&#25351;&#30340;&#26159;&#20174;&#24418;&#22914;$\mathbf{y}_i = \mathbf{D}\mathbf{x}_i$&#30340;&#26679;&#26412;&#20013;&#24674;&#22797;&#19968;&#20010;&#30697;&#38453;$\mathbf{D} \in \mathbb{R}^{M \times K}$&#21644;$N$&#20010;$s$-&#31232;&#30095;&#21521;&#37327;$\mathbf{x}_i \in \mathbb{R}^{K}$&#30340;&#38382;&#39064;&#12290;&#22312;&#23383;&#20856;&#24050;&#30693;&#30340;&#24773;&#20917;&#19979;&#65292;&#21363;&#20351;&#31232;&#30095;&#24230;&#32447;&#24615;&#22686;&#38271;&#21040;&#23610;&#23544;$M$&#65292;&#20063;&#21487;&#20197;&#24674;&#22797;$x_i$&#65292;&#20294;&#36804;&#20170;&#20026;&#27490;&#65292;&#21807;&#19968;&#33021;&#22312;&#32447;&#24615;&#31232;&#30095;&#24230;&#33539;&#22260;&#20869;&#26377;&#20445;&#35777;&#25104;&#21151;&#30340;&#31639;&#27861;&#26159;&#40654;&#26364;&#20449;&#36182;&#21306;&#22495;&#26041;&#27861;&#65292;&#36825;&#31181;&#26041;&#27861;&#20165;&#36866;&#29992;&#20110;&#27491;&#20132;&#23383;&#20856;&#65292;&#24182;&#19988;&#22522;&#20110;&#24179;&#26041;&#21644;&#23618;&#27425;&#30340;&#26041;&#27861;&#38656;&#35201;&#36229;&#22810;&#39033;&#24335;&#26102;&#38388;&#25165;&#33021;&#33719;&#24471;&#22312;$M$&#20013;&#34928;&#20943;&#30340;&#35823;&#24046;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;SPORADIC&#65288;SPectral ORAcle DICtionary Learning&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#19968;&#31995;&#21015;&#21152;&#26435;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#39640;&#25928;&#35889;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#36275;&#22815;&#39640;&#30340;&#32500;&#24230;&#19979;&#65292;SPORADIC&#21487;&#20197;&#24674;&#22797;&#28385;&#36275;$K&gt;M$&#30340;&#36229;&#23436;&#22791;&#23383;&#20856;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dictionary learning, the problem of recovering a sparsely used matrix $\mathbf{D} \in \mathbb{R}^{M \times K}$ and $N$ $s$-sparse vectors $\mathbf{x}_i \in \mathbb{R}^{K}$ from samples of the form $\mathbf{y}_i = \mathbf{D}\mathbf{x}_i$, is of increasing importance to applications in signal processing and data science. When the dictionary is known, recovery of $\mathbf{x}_i$ is possible even for sparsity linear in dimension $M$, yet to date, the only algorithms which provably succeed in the linear sparsity regime are Riemannian trust-region methods, which are limited to orthogonal dictionaries, and methods based on the sum-of-squares hierarchy, which requires super-polynomial time in order to obtain an error which decays in $M$. In this work, we introduce SPORADIC (SPectral ORAcle DICtionary Learning), an efficient spectral method on family of reweighted covariance matrices. We prove that in high enough dimensions, SPORADIC can recover overcomplete ($K &gt; M$) dictionaries satisfying the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;Transformer&#30340;&#20998;&#23376;&#27169;&#22411;&#65292;&#21517;&#20026;Transformer-M&#65292;&#21487;&#20197;&#22788;&#29702;2D&#21644;3D&#26684;&#24335;&#30340;&#20998;&#23376;&#25968;&#25454;&#24182;&#29983;&#25104;&#26377;&#24847;&#20041;&#30340;&#35821;&#20041;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2210.01765</link><description>&lt;p&gt;
&#19968;&#20010;Transformer&#27169;&#22411;&#21487;&#21516;&#26102;&#22788;&#29702;2D&#21644;3D&#20998;&#23376;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
One Transformer Can Understand Both 2D &amp; 3D Molecular Data. (arXiv:2210.01765v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.01765
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;Transformer&#30340;&#20998;&#23376;&#27169;&#22411;&#65292;&#21517;&#20026;Transformer-M&#65292;&#21487;&#20197;&#22788;&#29702;2D&#21644;3D&#26684;&#24335;&#30340;&#20998;&#23376;&#25968;&#25454;&#24182;&#29983;&#25104;&#26377;&#24847;&#20041;&#30340;&#35821;&#20041;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19982;&#36890;&#24120;&#26377;&#21807;&#19968;&#26684;&#24335;&#30340;&#35270;&#35273;&#21644;&#35821;&#35328;&#25968;&#25454;&#19981;&#21516;&#65292;&#20998;&#23376;&#21487;&#20197;&#33258;&#28982;&#22320;&#29992;&#19981;&#21516;&#30340;&#21270;&#23398;&#20844;&#24335;&#36827;&#34892;&#34920;&#24449;&#12290;&#23545;&#20110;&#20998;&#23376;&#34920;&#31034;&#23398;&#20064;&#65292;&#22823;&#22810;&#25968;&#20808;&#21069;&#30340;&#24037;&#20316;&#21482;&#35774;&#35745;&#20102;&#38024;&#23545;&#29305;&#23450;&#25968;&#25454;&#26684;&#24335;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#20351;&#24471;&#23398;&#20064;&#30340;&#27169;&#22411;&#21487;&#33021;&#26080;&#27861;&#22788;&#29702;&#20854;&#20182;&#25968;&#25454;&#26684;&#24335;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#21270;&#23398;&#30340;&#36890;&#29992;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#24212;&#33021;&#22815;&#22788;&#29702;&#36328;&#25968;&#25454;&#27169;&#24577;&#30340;&#20998;&#23376;&#20219;&#21153;&#12290;&#20026;&#23454;&#29616;&#27492;&#30446;&#26631;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#22522;&#20110;Transformer&#30340;&#20998;&#23376;&#27169;&#22411;&#65292;&#31216;&#20026;Transformer-M&#65292;&#23427;&#21487;&#20197;&#23558;2D&#25110;3D&#26684;&#24335;&#30340;&#20998;&#23376;&#25968;&#25454;&#20316;&#20026;&#36755;&#20837;&#24182;&#29983;&#25104;&#26377;&#24847;&#20041;&#30340;&#35821;&#20041;&#34920;&#31034;&#12290;&#20351;&#29992;&#26631;&#20934;Transformer&#20316;&#20026;&#39592;&#24178;&#26550;&#26500;&#65292;Transformer-M&#24320;&#21457;&#20102;&#20004;&#20010;&#20998;&#31163;&#30340;&#36890;&#36947;&#26469;&#32534;&#30721;2D&#21644;3D&#32467;&#26500;&#20449;&#24687;&#65292;&#24182;&#23558;&#23427;&#20204;&#19982;&#32593;&#32476;&#27169;&#22359;&#20013;&#30340;&#21407;&#23376;&#29305;&#24449;&#32467;&#21512;&#36215;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unlike vision and language data which usually has a unique format, molecules can naturally be characterized using different chemical formulations. One can view a molecule as a 2D graph or define it as a collection of atoms located in a 3D space. For molecular representation learning, most previous works designed neural networks only for a particular data format, making the learned models likely to fail for other data formats. We believe a general-purpose neural network model for chemistry should be able to handle molecular tasks across data modalities. To achieve this goal, in this work, we develop a novel Transformer-based Molecular model called Transformer-M, which can take molecular data of 2D or 3D formats as input and generate meaningful semantic representations. Using the standard Transformer as the backbone architecture, Transformer-M develops two separated channels to encode 2D and 3D structural information and incorporate them with the atom features in the network modules. Whe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#38024;&#23545;&#39640;&#26031;&#20998;&#24067;&#38544;&#31169;&#21327;&#26041;&#24046;&#20272;&#35745;&#21644;&#26377;&#30028;&#21327;&#26041;&#24046;&#20998;&#24067;&#30340;&#22343;&#20540;&#20272;&#35745;&#30340;&#26032;&#19979;&#30028;&#65292;&#36890;&#36807;&#24191;&#20041;&#21270;&#25351;&#32441;&#27861;&#21040;&#25351;&#25968;&#23478;&#26063;&#26469;&#35777;&#26126;&#36825;&#20123;&#19979;&#30028;&#30340;&#27491;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2205.08532</link><description>&lt;p&gt;
&#38544;&#31169;&#20272;&#35745;&#30340;&#26032;&#19979;&#30028;&#21644;&#24191;&#20041;&#25351;&#32441;&#24341;&#29702;
&lt;/p&gt;
&lt;p&gt;
New Lower Bounds for Private Estimation and a Generalized Fingerprinting Lemma. (arXiv:2205.08532v4 [cs.DS] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.08532
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#38024;&#23545;&#39640;&#26031;&#20998;&#24067;&#38544;&#31169;&#21327;&#26041;&#24046;&#20272;&#35745;&#21644;&#26377;&#30028;&#21327;&#26041;&#24046;&#20998;&#24067;&#30340;&#22343;&#20540;&#20272;&#35745;&#30340;&#26032;&#19979;&#30028;&#65292;&#36890;&#36807;&#24191;&#20041;&#21270;&#25351;&#32441;&#27861;&#21040;&#25351;&#25968;&#23478;&#26063;&#26469;&#35777;&#26126;&#36825;&#20123;&#19979;&#30028;&#30340;&#27491;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;$(\varepsilon, \delta)$-&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#19979;&#32479;&#35745;&#20272;&#35745;&#20219;&#21153;&#30340;&#26032;&#30340;&#19979;&#30028;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#39640;&#26031;&#20998;&#24067;&#38544;&#31169;&#21327;&#26041;&#24046;&#20272;&#35745;&#30340;&#20005;&#26684;&#19979;&#30028;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;Frobenius&#33539;&#25968;&#19979;&#20272;&#35745;&#21327;&#26041;&#24046;&#30697;&#38453;&#38656;&#35201;$\Omega(d^2)$&#20010;&#26679;&#26412;&#65292;&#22312;&#35889;&#33539;&#25968;&#19979;&#38656;&#35201;$\Omega(d^{3/2})$&#20010;&#26679;&#26412;&#65292;&#20004;&#32773;&#37117;&#21305;&#37197;&#19978;&#30028;&#65292;&#38500;&#20102;&#23545;&#25968;&#22240;&#23376;&#12290;&#21518;&#19968;&#39033;&#19979;&#30028;&#39564;&#35777;&#20102;&#19968;&#20010;&#20851;&#20110;&#39640;&#26031;&#21327;&#26041;&#24046;&#35889;&#20272;&#35745;&#30340;&#38544;&#31169;&#21644;&#38750;&#38544;&#31169;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#29468;&#24819;&#32479;&#35745;&#24046;&#36317;&#30340;&#23384;&#22312;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#25351;&#32441;&#26041;&#27861;&#24191;&#20041;&#21270;&#21040;&#25351;&#25968;&#23478;&#26063;&#26469;&#35777;&#26126;&#36825;&#20123;&#19979;&#30028;&#26159;&#27491;&#30830;&#30340;&#25216;&#26415;&#36129;&#29486;&#12290;&#27492;&#22806;&#65292;&#20351;&#29992;Acharya&#65292;Sun&#21644;Zhang&#25552;&#20986;&#30340;&#24046;&#20998;&#38544;&#31169;Assouad&#26041;&#27861;&#65292;&#25105;&#20204;&#22312;$\ell_2$-&#36317;&#31163;&#19979;&#34920;&#26126;&#20102;&#22312;&#26377;&#30028;&#21327;&#26041;&#24046;&#20998;&#24067;&#30340;&#22343;&#20540;&#20272;&#35745;&#20013;&#65292;&#21040;$\alpha$&#35823;&#24046;&#30340;&#20005;&#26684;$\Omega(d/(\alpha^2 \varepsilon))$&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We prove new lower bounds for statistical estimation tasks under the constraint of $(\varepsilon, \delta)$-differential privacy. First, we provide tight lower bounds for private covariance estimation of Gaussian distributions. We show that estimating the covariance matrix in Frobenius norm requires $\Omega(d^2)$ samples, and in spectral norm requires $\Omega(d^{3/2})$ samples, both matching upper bounds up to logarithmic factors. The latter bound verifies the existence of a conjectured statistical gap between the private and the non-private sample complexities for spectral estimation of Gaussian covariances. We prove these bounds via our main technical contribution, a broad generalization of the fingerprinting method to exponential families. Additionally, using the private Assouad method of Acharya, Sun, and Zhang, we show a tight $\Omega(d/(\alpha^2 \varepsilon))$ lower bound for estimating the mean of a distribution with bounded covariance to $\alpha$-error in $\ell_2$-distance. Prio
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#22522;&#20110;&#26143;&#24418;&#32454;&#32990;&#20316;&#29992;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#31361;&#35302;&#30340;&#31454;&#20105;&#21644;&#24378;&#24230;&#24179;&#34913;&#23454;&#29616;&#29616;&#26377;&#21644;&#35760;&#24518;&#24615;&#30340;&#22823;&#33041;&#21487;&#22609;&#24615;&#21644;&#31361;&#35302;&#24418;&#25104;&#65292;&#24182;&#25506;&#35752;&#20102;&#19982;&#20851;&#38190;&#26399;&#30456;&#20851;&#30340;&#31070;&#32463;&#32010;&#20081;&#21644;&#36127;&#38754;&#21644;&#27491;&#38754;&#35760;&#24518;&#30340;&#25345;&#20037;&#24615;&#23545;&#31361;&#35302;&#28608;&#27963;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2203.11740</link><description>&lt;p&gt;
&#22522;&#20110;&#26143;&#24418;&#32454;&#32990;&#23545;&#20851;&#38190;&#26399;&#30340;&#31070;&#32463;&#21487;&#22609;&#24615;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#29616;&#26377;&#21644;&#35760;&#24518;&#24615;&#30340;&#22823;&#33041;&#21487;&#22609;&#24615;&#21644;&#31361;&#35302;&#24418;&#25104;&#23454;&#29616;&#31361;&#35302;&#31454;&#20105;&#21644;&#24378;&#24230;&#24179;&#34913;&#12290;&#65288;arXiv: 2203.11740v12 [cs.NE] UPDATED&#65289;
&lt;/p&gt;
&lt;p&gt;
Plasticity Neural Network Based on Astrocytic effects at Critical Period, Synaptic Competition and Strength Rebalance by Current and Mnemonic Brain Plasticity and Synapse Formation. (arXiv:2203.11740v12 [cs.NE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.11740
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#22522;&#20110;&#26143;&#24418;&#32454;&#32990;&#20316;&#29992;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#31361;&#35302;&#30340;&#31454;&#20105;&#21644;&#24378;&#24230;&#24179;&#34913;&#23454;&#29616;&#29616;&#26377;&#21644;&#35760;&#24518;&#24615;&#30340;&#22823;&#33041;&#21487;&#22609;&#24615;&#21644;&#31361;&#35302;&#24418;&#25104;&#65292;&#24182;&#25506;&#35752;&#20102;&#19982;&#20851;&#38190;&#26399;&#30456;&#20851;&#30340;&#31070;&#32463;&#32010;&#20081;&#21644;&#36127;&#38754;&#21644;&#27491;&#38754;&#35760;&#24518;&#30340;&#25345;&#20037;&#24615;&#23545;&#31361;&#35302;&#28608;&#27963;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38500;&#20102;&#31361;&#35302;&#20849;&#20139;&#36830;&#25509;&#26435;&#37325;&#20043;&#22806;&#65292;PNN&#36824;&#21253;&#25324;&#31361;&#35302;&#26377;&#25928;&#33539;&#22260;&#30340;&#26435;&#37325;[14-25]&#12290;PNN&#32771;&#34385;&#31361;&#35302;&#24378;&#24230;&#24179;&#34913;&#22312;&#31361;&#35302;&#21534;&#22124;&#30340;&#21160;&#24577;&#21644;&#38271;&#24230;&#24120;&#25968;&#20043;&#21644;&#30340;&#38745;&#24577;&#20013;[14]&#65292;&#24182;&#21253;&#21547;&#20102;&#40060;&#32676;&#34892;&#20026;&#30340;&#20808;&#23548;&#34892;&#20026;&#12290;&#31361;&#35302;&#24418;&#25104;&#22312;&#23454;&#39564;&#21644;&#27169;&#25311;&#20013;&#20250;&#25233;&#21046;&#26641;&#31361;&#29983;&#25104;[15]&#12290;&#31867;&#20284;&#20110;Spring Boot&#20013;&#30340;&#24378;&#21046;&#38887;&#24615;&#65292;&#21453;&#21521;&#22238;&#36335;&#30340;&#35760;&#24518;&#25345;&#20037;&#24230;&#26799;&#24230;&#20063;&#23384;&#22312;&#12290;&#30456;&#23545;&#36739;&#22909;&#21644;&#36739;&#24046;&#30340;&#26799;&#24230;&#20449;&#24687;&#23384;&#20648;&#22312;&#31867;&#20284;&#20110;&#33041;&#35126;&#30340;&#35760;&#24518;&#30165;&#36857;&#32454;&#32990;&#20013;&#65292;&#22312;&#21453;&#21521;&#22238;&#36335;&#30340;&#31361;&#35302;&#24418;&#25104;&#20013;&#12290;&#20105;&#35758;&#35748;&#20026;&#20154;&#31867;&#28023;&#39532;&#31070;&#32463;&#20803;&#30340;&#20877;&#29983;&#33021;&#21147;&#26159;&#21542;&#25345;&#32493;&#21040;&#32769;&#24180;&#65292;&#24182;&#21487;&#33021;&#22312;&#21518;&#26399;&#36845;&#20195;&#20013;&#24418;&#25104;&#26032;&#30340;&#26356;&#38271;&#30340;&#22238;&#36335;[17,18]&#12290;&#20851;&#38381;&#20851;&#38190;&#26399;&#20250;&#23548;&#33268;&#31070;&#32463;&#32010;&#20081;&#22312;&#23454;&#39564;&#21644;&#27169;&#25311;&#20013;[19]&#12290;&#32771;&#34385;&#21040;&#36127;&#38754;&#21644;&#27491;&#38754;&#35760;&#24518;&#30340;&#25345;&#20037;&#24615;&#65292;&#26377;&#21161;&#20110;&#26356;&#22909;&#22320;&#28608;&#27963;&#31361;&#35302;&#12290;
&lt;/p&gt;
&lt;p&gt;
In addition to the weights of synaptic shared connections, PNN includes weights of synaptic effective ranges [14-25]. PNN considers synaptic strength balance in dynamic of phagocytosing of synapses and static of constant sum of synapses length [14], and includes the lead behavior of the school of fish. Synapse formation will inhibit dendrites generation in experiments and simulations [15]. The memory persistence gradient of retrograde circuit similar to the Enforcing Resilience in a Spring Boot. The relatively good and inferior gradient information stored in memory engram cells in synapse formation of retrograde circuit like the folds in brain [16]. The controversy was claimed if human hippocampal neurogenesis persists throughout aging, may have a new and longer circuit in late iteration [17,18]. Closing the critical period will cause neurological disorder in experiments and simulations [19]. Considering both negative and positive memories persistence help activate synapse better than 
&lt;/p&gt;</description></item><item><title>&#23545;&#20110;&#23384;&#22312;&#27169;&#22411;&#35268;&#26684;&#19981;&#20934;&#30830;&#21644;&#24322;&#24120;&#20540;&#24773;&#20917;&#19979;&#30340;&#38598;&#25104;&#23398;&#20064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#40065;&#26834;&#33258;&#30001;&#33021;&#37327;&#20934;&#21017;&#65292;&#36890;&#36807;&#23558;&#24191;&#20041;&#23545;&#25968;&#24471;&#20998;&#20989;&#25968;&#19982;PAC$^m$&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2203.01859</link><description>&lt;p&gt;
&#40065;&#26834;PAC$^m$: &#22312;&#27169;&#22411;&#35268;&#26684;&#19981;&#20934;&#30830;&#21644;&#23384;&#22312;&#24322;&#24120;&#20540;&#24773;&#20917;&#19979;&#35757;&#32451;&#38598;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Robust PAC$^m$: Training Ensemble Models Under Model Misspecification and Outliers. (arXiv:2203.01859v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.01859
&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#23384;&#22312;&#27169;&#22411;&#35268;&#26684;&#19981;&#20934;&#30830;&#21644;&#24322;&#24120;&#20540;&#24773;&#20917;&#19979;&#30340;&#38598;&#25104;&#23398;&#20064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#40065;&#26834;&#33258;&#30001;&#33021;&#37327;&#20934;&#21017;&#65292;&#36890;&#36807;&#23558;&#24191;&#20041;&#23545;&#25968;&#24471;&#20998;&#20989;&#25968;&#19982;PAC$^m$&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#36125;&#21494;&#26031;&#23398;&#20064;&#22312;&#27169;&#22411;&#35268;&#26684;&#19981;&#20934;&#30830;&#21644;&#23384;&#22312;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#24050;&#30693;&#23384;&#22312;&#27867;&#21270;&#33021;&#21147;&#30340;&#19981;&#36275;&#12290;PAC-Bayes&#29702;&#35770;&#35777;&#26126;&#20102;&#36125;&#21494;&#26031;&#23398;&#20064;&#25152;&#26368;&#23567;&#21270;&#30340;&#33258;&#30001;&#33021;&#37327;&#20934;&#21017;&#26159;&#22312;&#20551;&#35774;&#26410;&#34987;&#24322;&#24120;&#20540;&#27745;&#26579;&#30340;&#37319;&#26679;&#20998;&#24067;&#19979;&#65292;&#23545;Gibbs&#39044;&#27979;&#22120;&#65288;&#21363;&#20174;&#21518;&#39564;&#38543;&#26426;&#25277;&#21462;&#30340;&#21333;&#20010;&#27169;&#22411;&#65289;&#30340;&#27867;&#21270;&#35823;&#24046;&#30340;&#19968;&#20010;&#19978;&#30028;&#12290;&#35813;&#35266;&#28857;&#25552;&#20379;&#20102;&#36125;&#21494;&#26031;&#23398;&#20064;&#22312;&#27169;&#22411;&#35268;&#26684;&#19981;&#20934;&#30830;&#19988;&#38656;&#35201;&#38598;&#25104;&#65292;&#20197;&#21450;&#25968;&#25454;&#21463;&#21040;&#24322;&#24120;&#20540;&#24433;&#21709;&#26102;&#30340;&#23616;&#38480;&#24615;&#30340;&#35777;&#26126;&#12290;&#26368;&#36817;&#30340;&#24037;&#20316;&#20013;&#65292;&#25512;&#23548;&#20986;&#20102;PAC-Bayes&#19978;&#30028; - &#31216;&#20026;PAC$^m$ - &#24341;&#20837;&#20102;&#33258;&#30001;&#33021;&#37327;&#24230;&#37327;&#65292;&#21487;&#32771;&#34385;&#38598;&#21512;&#39044;&#27979;&#22120;&#30340;&#24615;&#33021;&#65292;&#20174;&#32780;&#33719;&#24471;&#22312;&#27169;&#22411;&#19981;&#20934;&#30830;&#30340;&#24773;&#20917;&#19979;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#40065;&#26834;&#33258;&#30001;&#33021;&#37327;&#20934;&#21017;&#65292;&#23558;&#24191;&#20041;&#23545;&#25968;&#24471;&#20998;&#20989;&#25968;&#19982;PAC$^m$&#38598;&#25104;&#19978;&#30028;&#30456;&#32467;&#21512;&#12290;&#24314;&#35758;&#30340;&#33258;&#30001;&#33021;&#37327;&#35757;&#32451;...&#65288;&#25688;&#35201;&#26410;&#23436;&#65292;&#35814;&#24773;&#35831;&#26597;&#30475;&#21407;&#25991;&#65289;
&lt;/p&gt;
&lt;p&gt;
Standard Bayesian learning is known to have suboptimal generalization capabilities under model misspecification and in the presence of outliers. PAC-Bayes theory demonstrates that the free energy criterion minimized by Bayesian learning is a bound on the generalization error for Gibbs predictors (i.e., for single models drawn at random from the posterior) under the assumption of sampling distributions uncontaminated by outliers. This viewpoint provides a justification for the limitations of Bayesian learning when the model is misspecified, requiring ensembling, and when data is affected by outliers. In recent work, PAC-Bayes bounds - referred to as PAC$^m$ - were derived to introduce free energy metrics that account for the performance of ensemble predictors, obtaining enhanced performance under misspecification. This work presents a novel robust free energy criterion that combines the generalized logarithm score function with PAC$^m$ ensemble bounds. The proposed free energy training 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22312;&#28145;&#24230;&#38598;&#25104;&#30340;&#26356;&#26032;&#35268;&#21017;&#20013;&#24341;&#20837;&#26680;&#21270;&#25490;&#26021;&#39033;&#65292;&#21487;&#20197;&#24378;&#21046;&#24182;&#32500;&#25252;&#25104;&#21592;&#20043;&#38388;&#30340;&#22810;&#26679;&#24615;&#65292;&#24182;&#20351;&#38598;&#25104;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#21644;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2106.11642</link><description>&lt;p&gt;
&#25298;&#32477;&#24615;&#28145;&#24230;&#38598;&#25104;&#26159;&#36125;&#21494;&#26031;&#30340;
&lt;/p&gt;
&lt;p&gt;
Repulsive Deep Ensembles are Bayesian. (arXiv:2106.11642v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.11642
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22312;&#28145;&#24230;&#38598;&#25104;&#30340;&#26356;&#26032;&#35268;&#21017;&#20013;&#24341;&#20837;&#26680;&#21270;&#25490;&#26021;&#39033;&#65292;&#21487;&#20197;&#24378;&#21046;&#24182;&#32500;&#25252;&#25104;&#21592;&#20043;&#38388;&#30340;&#22810;&#26679;&#24615;&#65292;&#24182;&#20351;&#38598;&#25104;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#21644;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#38598;&#25104;&#22240;&#20854;&#27010;&#24565;&#19978;&#30340;&#31616;&#21333;&#21644;&#39640;&#25928;&#32780;&#21463;&#21040;&#28145;&#24230;&#23398;&#20064;&#30028;&#30340;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#29420;&#31435;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#38598;&#25104;&#25104;&#21592;&#20043;&#38388;&#30340;&#21151;&#33021;&#22810;&#26679;&#24615;&#30340;&#32500;&#25252;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#36825;&#21487;&#33021;&#20250;&#23548;&#33268;&#28155;&#21152;&#26356;&#22810;&#38598;&#25104;&#25104;&#21592;&#26102;&#20986;&#29616;&#30149;&#24577;&#65292;&#20363;&#22914;&#38598;&#25104;&#24615;&#33021;&#30340;&#39281;&#21644;&#65292;&#23427;&#20250;&#25910;&#25947;&#21040;&#21333;&#20010;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#36825;&#19981;&#20165;&#24433;&#21709;&#20854;&#39044;&#27979;&#30340;&#36136;&#37327;&#65292;&#32780;&#19988;&#26356;&#21152;&#24433;&#21709;&#38598;&#25104;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#20174;&#32780;&#24433;&#21709;&#20854;&#22312;&#36229;&#20986;&#20998;&#24067;&#25968;&#25454;&#19978;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#20551;&#35774;&#36825;&#31181;&#38480;&#21046;&#21487;&#20197;&#36890;&#36807;&#38459;&#27490;&#19981;&#21516;&#38598;&#25104;&#25104;&#21592;&#22349;&#22604;&#21040;&#30456;&#21516;&#21151;&#33021;&#26469;&#20811;&#26381;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#22312;&#28145;&#24230;&#38598;&#25104;&#30340;&#26356;&#26032;&#35268;&#21017;&#20013;&#24341;&#20837;&#20102;&#19968;&#20010;&#26680;&#21270;&#30340;&#25490;&#26021;&#26415;&#35821;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#36825;&#20010;&#31616;&#21333;&#30340;&#20462;&#25913;&#19981;&#20165;&#24378;&#21046;&#24182;&#32500;&#25252;&#25104;&#21592;&#20043;&#38388;&#30340;&#22810;&#26679;&#24615;&#65292;&#32780;&#19988;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#23558;&#26368;&#22823;&#30340;&#21518;&#39564;&#20540;&#36716;&#21270;&#20026;...&#65288;&#21407;&#25991;&#25130;&#27490;&#27492;&#22788;&#65289;
&lt;/p&gt;
&lt;p&gt;
Deep ensembles have recently gained popularity in the deep learning community for their conceptual simplicity and efficiency. However, maintaining functional diversity between ensemble members that are independently trained with gradient descent is challenging. This can lead to pathologies when adding more ensemble members, such as a saturation of the ensemble performance, which converges to the performance of a single model. Moreover, this does not only affect the quality of its predictions, but even more so the uncertainty estimates of the ensemble, and thus its performance on out-of-distribution data. We hypothesize that this limitation can be overcome by discouraging different ensemble members from collapsing to the same function. To this end, we introduce a kernelized repulsive term in the update rule of the deep ensembles. We show that this simple modification not only enforces and maintains diversity among the members but, even more importantly, transforms the maximum a posterio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#22855;&#24322;&#20998;&#24067;&#38750;&#21442;&#25968;&#20272;&#35745;&#30340;&#32479;&#35745;&#23398;&#24615;&#36136;&#65292;&#25552;&#20986;&#20102;&#36890;&#36807;&#26679;&#26412;&#22122;&#22768;&#23545;&#25968;&#25454;&#36827;&#34892;&#25200;&#21160;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545;&#28508;&#22312;&#20998;&#24067;&#30340;&#19968;&#33268;&#20272;&#35745;&#21644;&#33391;&#22909;&#25910;&#25947;&#29575;&#12290;</title><link>http://arxiv.org/abs/2105.04046</link><description>&lt;p&gt;
&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#20284;&#28982;&#26041;&#27861;&#36827;&#34892;&#22855;&#24322;&#20998;&#24067;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
A likelihood approach to nonparametric estimation of a singular distribution using deep generative models. (arXiv:2105.04046v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.04046
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#22855;&#24322;&#20998;&#24067;&#38750;&#21442;&#25968;&#20272;&#35745;&#30340;&#32479;&#35745;&#23398;&#24615;&#36136;&#65292;&#25552;&#20986;&#20102;&#36890;&#36807;&#26679;&#26412;&#22122;&#22768;&#23545;&#25968;&#25454;&#36827;&#34892;&#25200;&#21160;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545;&#28508;&#22312;&#20998;&#24067;&#30340;&#19968;&#33268;&#20272;&#35745;&#21644;&#33391;&#22909;&#25910;&#25947;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#22855;&#24322;&#20998;&#24067;&#38750;&#21442;&#25968;&#20272;&#35745;&#30340;&#32479;&#35745;&#23398;&#24615;&#36136;&#12290;&#22312;&#32771;&#34385;&#30340;&#27169;&#22411;&#20013;&#65292;&#21033;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#24314;&#27169;&#39640;&#32500;&#25968;&#25454;&#65292;&#24182;&#20551;&#35774;&#25968;&#25454;&#38598;&#20013;&#22312;&#19968;&#20123;&#20302;&#32500;&#32467;&#26500;&#21608;&#22260;&#12290;&#30001;&#20110;&#25903;&#25745;&#20302;&#32500;&#32467;&#26500;&#30340;&#20998;&#24067;&#22312;&#29615;&#22659;&#31354;&#38388;&#20013;&#23545;&#21202;&#36125;&#26684;&#27979;&#24230;&#20855;&#26377;&#22855;&#24322;&#24615;&#65292;&#22240;&#27492;&#29992;&#36890;&#24120;&#30340;&#20284;&#28982;&#26041;&#27861;&#26469;&#20272;&#35745;&#30446;&#26631;&#20998;&#24067;&#21487;&#33021;&#26080;&#27861;&#36798;&#21040;&#19968;&#33268;&#24615;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;&#20351;&#29992;&#26679;&#26412;&#22122;&#22768;&#23545;&#25968;&#25454;&#36827;&#34892;&#25200;&#21160;&#21487;&#20197;&#24471;&#21040;&#26032;&#39062;&#32780;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545;&#28508;&#22312;&#20998;&#24067;&#30340;&#19968;&#33268;&#20272;&#35745;&#21644;&#33391;&#22909;&#25910;&#25947;&#29575;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#36824;&#34920;&#24449;&#20102;&#21487;&#20197;&#36890;&#36807;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#26377;&#25928;&#20272;&#35745;&#30340;&#20998;&#24067;&#31867;&#12290;&#36825;&#20010;&#31867;&#36275;&#22815;&#26222;&#36941;&#65292;&#21487;&#20197;&#23481;&#32435;&#21508;&#31181;&#31867;&#22411;&#30340;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate statistical properties of a likelihood approach to nonparametric estimation of a singular distribution using deep generative models. More specifically, a deep generative model is used to model high-dimensional data that are assumed to concentrate around some low-dimensional structure. Estimating the distribution supported on this low-dimensional structure, such as a low-dimensional manifold, is challenging due to its singularity with respect to the Lebesgue measure in the ambient space. In the considered model, a usual likelihood approach can fail to estimate the target distribution consistently due to the singularity. We prove that a novel and effective solution exists by perturbing the data with an instance noise, which leads to consistent estimation of the underlying distribution with desirable convergence rates. We also characterize the class of distributions that can be efficiently estimated via deep generative models. This class is sufficiently general to contain v
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#21270; SVM &#30340;&#38750;&#32447;&#24615;&#20998;&#31867;&#22120;&#65292;&#29992;&#20110;&#35299;&#20915;&#26368;&#39640;&#30456;&#20851;&#24615;&#26679;&#26412;&#30340;&#25490;&#21517;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2002.11436</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;&#21270; SVM &#30340;&#25490;&#21517;&#38382;&#39064;&#38750;&#32447;&#24615;&#20998;&#31867;&#22120;
&lt;/p&gt;
&lt;p&gt;
Nonlinear classifiers for ranking problems based on kernelized SVM. (arXiv:2002.11436v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2002.11436
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#21270; SVM &#30340;&#38750;&#32447;&#24615;&#20998;&#31867;&#22120;&#65292;&#29992;&#20110;&#35299;&#20915;&#26368;&#39640;&#30456;&#20851;&#24615;&#26679;&#26412;&#30340;&#25490;&#21517;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#20998;&#31867;&#38382;&#39064;&#20165;&#20851;&#27880;&#26368;&#20855;&#30456;&#20851;&#24615;&#30340;&#26679;&#26412;&#30340;&#24615;&#33021;&#32780;&#38750;&#25152;&#26377;&#26679;&#26412;&#12290;&#20363;&#22914;&#65292;&#25490;&#21517;&#38382;&#39064;&#12289;&#39030;&#37096;&#20934;&#30830;&#24230;&#25110;&#25628;&#32034;&#24341;&#25806;&#20165;&#20851;&#27880;&#21069;&#20960;&#20010;&#26597;&#35810;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#20043;&#21069;&#24050;&#32463;&#25512;&#23548;&#20986;&#21253;&#25324;&#22810;&#20010;&#32447;&#24615;&#20998;&#31867;&#38382;&#39064;&#31867;&#21035;&#30340;&#36890;&#29992;&#26694;&#26550;&#12290;&#26412;&#25991;&#23558;&#35813;&#26694;&#26550;&#25193;&#23637;&#21040;&#38750;&#32447;&#24615;&#20998;&#31867;&#22120;&#12290;&#21033;&#29992; SVM &#30340;&#30456;&#20284;&#24615;&#65292;&#25105;&#20204;&#23545;&#38382;&#39064;&#36827;&#34892;&#23545;&#20598;&#21270;&#22788;&#29702;&#65292;&#28155;&#21152;&#20102;&#26680;&#20989;&#25968;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#20998;&#37327;&#23545;&#20598;&#19978;&#21319;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many classification problems focus on maximizing the performance only on the samples with the highest relevance instead of all samples. As an example, we can mention ranking problems, accuracy at the top or search engines where only the top few queries matter. In our previous work, we derived a general framework including several classes of these linear classification problems. In this paper, we extend the framework to nonlinear classifiers. Utilizing a similarity to SVM, we dualize the problems, add kernels and propose a componentwise dual ascent method.
&lt;/p&gt;</description></item></channel></rss>