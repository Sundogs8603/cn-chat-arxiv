<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>Transformer&#22312;&#36924;&#36817;&#36830;&#32493;&#20989;&#25968;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#65292;&#26159;&#21542;&#30495;&#27491;&#26159;&#36890;&#29992;&#20989;&#25968;&#36924;&#36817;&#22120;&#20173;&#26377;&#24453;&#32771;&#35777;</title><link>https://arxiv.org/abs/2402.15478</link><description>&lt;p&gt;
Transformer&#26159;&#34920;&#29616;&#21147;&#24378;&#22823;&#30340;&#65292;&#20294;&#26159;&#23545;&#20110;&#22238;&#24402;&#20219;&#21153;&#26469;&#35828;&#34920;&#29616;&#21147;&#36275;&#22815;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Transformers are Expressive, But Are They Expressive Enough for Regression?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15478
&lt;/p&gt;
&lt;p&gt;
Transformer&#22312;&#36924;&#36817;&#36830;&#32493;&#20989;&#25968;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#65292;&#26159;&#21542;&#30495;&#27491;&#26159;&#36890;&#29992;&#20989;&#25968;&#36924;&#36817;&#22120;&#20173;&#26377;&#24453;&#32771;&#35777;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer&#24050;&#25104;&#20026;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#33267;&#20851;&#37325;&#35201;&#30340;&#25216;&#26415;&#65292;&#22312;&#26426;&#22120;&#32763;&#35793;&#21644;&#25688;&#35201;&#31561;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;&#38543;&#30528;&#23427;&#20204;&#30340;&#24191;&#27867;&#24212;&#29992;&#65292;&#19968;&#20123;&#30740;&#31350;&#23581;&#35797;&#20998;&#26512;Transformer&#30340;&#34920;&#29616;&#21147;&#12290;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#29616;&#21147;&#25351;&#30340;&#26159;&#23427;&#33021;&#22815;&#36924;&#36817;&#30340;&#20989;&#25968;&#31867;&#12290;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#26159;&#23436;&#20840;&#34920;&#29616;&#21147;&#30340;&#65292;&#22914;&#26524;&#23427;&#21487;&#20197;&#20805;&#24403;&#36890;&#29992;&#20989;&#25968;&#36924;&#36817;&#22120;&#12290;&#25105;&#20204;&#23581;&#35797;&#20998;&#26512;Transformer&#30340;&#34920;&#29616;&#21147;&#12290;&#19982;&#29616;&#26377;&#35266;&#28857;&#30456;&#21453;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;Transformer&#22312;&#21487;&#38752;&#36924;&#36817;&#36830;&#32493;&#20989;&#25968;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#65292;&#20381;&#36182;&#20110;&#20855;&#26377;&#21487;&#35266;&#21306;&#38388;&#30340;&#20998;&#27573;&#24120;&#25968;&#36924;&#36817;&#12290;&#20851;&#38190;&#38382;&#39064;&#26159;&#65306;&#8220;Transformer&#26159;&#21542;&#30495;&#27491;&#26159;&#36890;&#29992;&#20989;&#25968;&#36924;&#36817;&#22120;&#65311;&#8221;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#24443;&#24213;&#30340;&#35843;&#26597;&#65292;&#36890;&#36807;&#23454;&#39564;&#25552;&#20379;&#29702;&#35770;&#35265;&#35299;&#21644;&#25903;&#25345;&#35777;&#25454;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#21253;&#25324;&#20102;&#19968;&#20010;&#29702;&#35770;&#20998;&#26512;&#8230;&#8230;&#65288;&#25688;&#35201;&#26410;&#23436;&#25972;&#65289;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15478v1 Announce Type: new  Abstract: Transformers have become pivotal in Natural Language Processing, demonstrating remarkable success in applications like Machine Translation and Summarization. Given their widespread adoption, several works have attempted to analyze the expressivity of Transformers. Expressivity of a neural network is the class of functions it can approximate. A neural network is fully expressive if it can act as a universal function approximator. We attempt to analyze the same for Transformers. Contrary to existing claims, our findings reveal that Transformers struggle to reliably approximate continuous functions, relying on piecewise constant approximations with sizable intervals. The central question emerges as: "\textit{Are Transformers truly Universal Function Approximators}?" To address this, we conduct a thorough investigation, providing theoretical insights and supporting evidence through experiments. Our contributions include a theoretical analysi
&lt;/p&gt;</description></item><item><title>GROS&#26159;&#19968;&#31181;&#26032;&#30340;&#31283;&#20581;&#31243;&#24207;&#65292;&#29992;&#20110;&#22312;&#24230;&#37327;&#31354;&#38388;&#20013;&#32452;&#21512;&#20272;&#35745;&#37327;&#65292;&#20855;&#26377;&#27425;&#39640;&#26031;&#29305;&#24615;&#65292;&#36890;&#36807;&#22312;&#26679;&#26412;&#19978;&#36827;&#34892;&#26368;&#23567;&#21270;&#21487;&#22312;&#23454;&#36341;&#20013;&#23454;&#29616;&#12290;</title><link>https://arxiv.org/abs/2402.15442</link><description>&lt;p&gt;
GROS: &#19968;&#20010;&#36890;&#29992;&#30340;&#31283;&#20581;&#32858;&#21512;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
GROS: A General Robust Aggregation Strategy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15442
&lt;/p&gt;
&lt;p&gt;
GROS&#26159;&#19968;&#31181;&#26032;&#30340;&#31283;&#20581;&#31243;&#24207;&#65292;&#29992;&#20110;&#22312;&#24230;&#37327;&#31354;&#38388;&#20013;&#32452;&#21512;&#20272;&#35745;&#37327;&#65292;&#20855;&#26377;&#27425;&#39640;&#26031;&#29305;&#24615;&#65292;&#36890;&#36807;&#22312;&#26679;&#26412;&#19978;&#36827;&#34892;&#26368;&#23567;&#21270;&#21487;&#22312;&#23454;&#36341;&#20013;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#24120;&#36890;&#29992;&#30340;&#31283;&#20581;&#31243;&#24207;&#65292;&#29992;&#20110;&#22312;&#24230;&#37327;&#31354;&#38388;&#20013;&#32452;&#21512;&#20272;&#35745;&#37327;&#65292;&#31216;&#20026;GROS&#12290;&#35813;&#26041;&#27861;&#31867;&#20284;&#20110;&#20247;&#25152;&#21608;&#30693;&#30340;&#22343;&#20540;&#20013;&#20301;&#25968;&#26041;&#27861;&#65292;&#22312;&#25991;&#29486;\cite{devroye2016sub}&#20013;&#26377;&#25551;&#36848;&#12290;&#39318;&#20808;&#65292;&#26679;&#26412;&#34987;&#20998;&#25104;$K$&#32452;&#12290;&#38543;&#21518;&#65292;&#20026;&#27599;&#20010;&#32452;&#35745;&#31639;&#19968;&#20010;&#20272;&#35745;&#37327;&#12290;&#26368;&#21518;&#65292;&#21033;&#29992;&#31283;&#20581;&#31243;&#24207;&#32452;&#21512;&#36825;$K$&#20010;&#20272;&#35745;&#37327;&#12290;&#25105;&#20204;&#35777;&#26126;&#36825;&#20010;&#20272;&#35745;&#37327;&#26159;&#27425;&#39640;&#26031;&#30340;&#65292;&#24182;&#24471;&#21040;&#23427;&#30340;&#30772;&#35010;&#28857;&#65292;&#21363;Donoho&#30340;&#24847;&#20041;&#19979;&#12290;&#31283;&#20581;&#31243;&#24207;&#28041;&#21450;&#19968;&#20010;&#22312;&#19968;&#33324;&#24230;&#37327;&#31354;&#38388;&#19978;&#30340;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#20294;&#25105;&#20204;&#34920;&#26126;&#65292;&#22914;&#26524;&#26368;&#23567;&#21270;&#22312;&#26679;&#26412;&#19978;&#36827;&#34892;&#65292;&#37027;&#20040;&#23558;&#33719;&#24471;&#30456;&#21516;&#65288;&#32463;&#24120;&#25968;&#30456;&#24046;&#65289;&#30340;&#27425;&#39640;&#26031;&#24615;&#65292;&#20351;&#24471;GROS&#22312;&#23454;&#36341;&#20013;&#21487;&#34892;&#12290;&#36890;&#36807;&#20116;&#20010;&#27169;&#25311;&#30740;&#31350;&#35780;&#20272;&#20102;GROS&#30340;&#24615;&#33021;&#65306;&#31532;&#19968;&#20010;&#30740;&#31350;&#30528;&#37325;&#20110;&#20351;&#29992;$k$-means&#36827;&#34892;&#20998;&#31867;&#65292;&#31532;&#20108;&#20010;&#30740;&#31350;&#30528;&#37325;&#20110;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#65292;&#31532;&#19977;&#20010;&#30740;&#31350;&#30528;&#37325;&#20110;&#22238;&#24402;&#38382;&#39064;&#12290;&#31532;&#22235;&#20010;&#26159;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15442v1 Announce Type: cross  Abstract: A new, very general, robust procedure for combining estimators in metric spaces is introduced GROS. The method is reminiscent of the well-known median of means, as described in \cite{devroye2016sub}. Initially, the sample is divided into $K$ groups. Subsequently, an estimator is computed for each group. Finally, these $K$ estimators are combined using a robust procedure. We prove that this estimator is sub-Gaussian and we get its break-down point, in the sense of Donoho. The robust procedure involves a minimization problem on a general metric space, but we show that the same (up to a constant) sub-Gaussianity is obtained if the minimization is taken over the sample, making GROS feasible in practice. The performance of GROS is evaluated through five simulation studies: the first one focuses on classification using $k$-means, the second one on the multi-armed bandit problem, the third one on the regression problem. The fourth one is the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#28151;&#21512;&#27169;&#22411;&#20013;&#24314;&#31435;&#20102;&#19968;&#20010;&#36890;&#29992;&#19979;&#30028;&#65292;&#36890;&#36807;Chernoff&#25955;&#24230;&#26469;&#34920;&#36798;&#65292;&#23558;&#20854;&#25299;&#23637;&#21040;&#20855;&#26377;&#27425;&#25351;&#25968;&#23614;&#37096;&#30340;&#28151;&#21512;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#36845;&#20195;&#31639;&#27861;&#22312;&#36825;&#20123;&#28151;&#21512;&#27169;&#22411;&#20013;&#23454;&#29616;&#20102;&#26368;&#20339;&#35823;&#24046;&#29575;</title><link>https://arxiv.org/abs/2402.15432</link><description>&lt;p&gt;
&#22312;&#27425;&#25351;&#25968;&#28151;&#21512;&#27169;&#22411;&#20013;&#23454;&#29616;&#26497;&#23567;&#21270;&#32858;&#31867;&#35823;&#24046;&#65306;&#36890;&#29992;&#19979;&#30028;&#21644;&#26368;&#20339;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Universal Lower Bounds and Optimal Rates: Achieving Minimax Clustering Error in Sub-Exponential Mixture Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15432
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#28151;&#21512;&#27169;&#22411;&#20013;&#24314;&#31435;&#20102;&#19968;&#20010;&#36890;&#29992;&#19979;&#30028;&#65292;&#36890;&#36807;Chernoff&#25955;&#24230;&#26469;&#34920;&#36798;&#65292;&#23558;&#20854;&#25299;&#23637;&#21040;&#20855;&#26377;&#27425;&#25351;&#25968;&#23614;&#37096;&#30340;&#28151;&#21512;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#36845;&#20195;&#31639;&#27861;&#22312;&#36825;&#20123;&#28151;&#21512;&#27169;&#22411;&#20013;&#23454;&#29616;&#20102;&#26368;&#20339;&#35823;&#24046;&#29575;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32858;&#31867;&#26159;&#26080;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#65292;&#36890;&#24120;&#36890;&#36807;&#28151;&#21512;&#27169;&#22411;&#30340;&#35270;&#35282;&#26469;&#30740;&#31350;&#12290;&#22312;&#39640;&#26031;&#21644;&#27425;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20013;&#24674;&#22797;&#32858;&#31867;&#26631;&#31614;&#30340;&#26368;&#20339;&#35823;&#24046;&#29575;&#28041;&#21450;&#21040;&#29305;&#23450;&#30340;&#20449;&#22122;&#27604;&#12290;&#31616;&#21333;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#22914;Lloyd&#31639;&#27861;&#65292;&#21487;&#20197;&#36798;&#21040;&#36825;&#20010;&#26368;&#20339;&#35823;&#24046;&#29575;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#20026;&#20219;&#20309;&#28151;&#21512;&#27169;&#22411;&#20013;&#30340;&#35823;&#24046;&#29575;&#24314;&#31435;&#20102;&#19968;&#20010;&#36890;&#29992;&#19979;&#30028;&#65292;&#36890;&#36807;Chernoff&#25955;&#24230;&#26469;&#34920;&#36798;&#65292;&#36825;&#26159;&#19968;&#20010;&#27604;&#20449;&#22122;&#27604;&#26356;&#36890;&#29992;&#30340;&#27169;&#22411;&#20449;&#24687;&#24230;&#37327;&#12290;&#28982;&#21518;&#25105;&#20204;&#35777;&#26126;&#20102;&#36845;&#20195;&#31639;&#27861;&#22312;&#28151;&#21512;&#27169;&#22411;&#20013;&#23454;&#29616;&#20102;&#36825;&#20010;&#19979;&#30028;&#65292;&#29305;&#21035;&#24378;&#35843;&#20102;&#20855;&#26377;&#25289;&#26222;&#25289;&#26031;&#20998;&#24067;&#35823;&#24046;&#30340;&#20301;&#32622;-&#23610;&#24230;&#28151;&#21512;&#12290;&#27492;&#22806;&#65292;&#38024;&#23545;&#26356;&#36866;&#21512;&#30001;&#27850;&#26494;&#25110;&#36127;&#20108;&#39033;&#28151;&#21512;&#27169;&#22411;&#24314;&#27169;&#30340;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20854;&#20998;&#24067;&#23646;&#20110;&#25351;&#25968;&#26063;&#30340;&#28151;&#21512;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15432v1 Announce Type: cross  Abstract: Clustering is a pivotal challenge in unsupervised machine learning and is often investigated through the lens of mixture models. The optimal error rate for recovering cluster labels in Gaussian and sub-Gaussian mixture models involves ad hoc signal-to-noise ratios. Simple iterative algorithms, such as Lloyd's algorithm, attain this optimal error rate. In this paper, we first establish a universal lower bound for the error rate in clustering any mixture model, expressed through a Chernoff divergence, a more versatile measure of model information than signal-to-noise ratios. We then demonstrate that iterative algorithms attain this lower bound in mixture models with sub-exponential tails, notably emphasizing location-scale mixtures featuring Laplace-distributed errors. Additionally, for datasets better modelled by Poisson or Negative Binomial mixtures, we study mixture models whose distributions belong to an exponential family. In such m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#36716;&#25442;&#22120;&#25968;&#23398;&#26694;&#26550;&#25506;&#35752;&#20102;LoRA&#31639;&#27861;&#23545;Token&#32858;&#31867;&#32467;&#26500;&#21160;&#24577;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#22312;&#19981;&#21516;&#21442;&#25968;&#19979;&#65292;&#20462;&#25913;&#21518;&#30340;&#27880;&#24847;&#21147;&#30697;&#38453;&#21160;&#24577;&#30340;&#32858;&#31867;&#34920;&#29616;&#20986;&#36739;&#38271;&#26102;&#38388;&#30340;&#26174;&#33879;&#24046;&#24322;&#65292;&#20294;&#20173;&#22312;&#30701;&#26102;&#38388;&#20869;&#20445;&#25345;&#23494;&#20999;&#30456;&#20284;&#12290;</title><link>https://arxiv.org/abs/2402.15415</link><description>&lt;p&gt;
LoRA&#23545;&#36716;&#25442;&#22120;&#20013;&#32858;&#31867;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
The Impact of LoRA on the Emergence of Clusters in Transformers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15415
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#36716;&#25442;&#22120;&#25968;&#23398;&#26694;&#26550;&#25506;&#35752;&#20102;LoRA&#31639;&#27861;&#23545;Token&#32858;&#31867;&#32467;&#26500;&#21160;&#24577;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#22312;&#19981;&#21516;&#21442;&#25968;&#19979;&#65292;&#20462;&#25913;&#21518;&#30340;&#27880;&#24847;&#21147;&#30697;&#38453;&#21160;&#24577;&#30340;&#32858;&#31867;&#34920;&#29616;&#20986;&#36739;&#38271;&#26102;&#38388;&#30340;&#26174;&#33879;&#24046;&#24322;&#65292;&#20294;&#20173;&#22312;&#30701;&#26102;&#38388;&#20869;&#20445;&#25345;&#23494;&#20999;&#30456;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;\citet{sander2022sinkformers,geshkovski2023emergence,geshkovski2023mathematical}&#25552;&#20986;&#30340;&#36716;&#25442;&#22120;&#25968;&#23398;&#26694;&#26550;&#65292;&#25506;&#35752;&#27880;&#24847;&#21147;&#21442;&#25968;&#21644;&#21021;&#22987;&#26631;&#35760;&#20540;&#30340;&#21464;&#21270;&#22914;&#20309;&#24433;&#21709;&#26631;&#35760;&#32858;&#31867;&#30340;&#32467;&#26500;&#21160;&#24577;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#34429;&#28982;&#20462;&#25913;&#21518;&#30340;&#27880;&#24847;&#21147;&#30697;&#38453;&#21160;&#24577;&#20013;&#30340;&#32858;&#31867;&#21487;&#33021;&#22312;&#36739;&#38271;&#26102;&#38388;&#20869;&#19982;&#21407;&#22987;&#32858;&#31867;&#24046;&#24322;&#26174;&#33879;&#65292;&#20294;&#22312;&#36739;&#30701;&#26102;&#38388;&#38388;&#38548;&#20869;&#65292;&#23427;&#20204;&#22312;&#21442;&#25968;&#24046;&#24322;&#30340;&#24433;&#21709;&#19979;&#20173;&#20445;&#25345;&#23494;&#20999;&#30456;&#20284;&#12290;&#36825;&#39033;&#24037;&#20316;&#36890;&#36807;LoRA&#31639;&#27861;\cite{hu2021lora,peft}&#30340;&#23454;&#38469;&#24212;&#29992;&#65292;&#20026;&#24494;&#35843;&#39046;&#22495;&#20570;&#20986;&#20102;&#36129;&#29486;&#65292;&#22686;&#36827;&#20102;&#25105;&#20204;&#23545;LoRA&#22686;&#24378;&#30340;Transformer&#27169;&#22411;&#34892;&#20026;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15415v1 Announce Type: new  Abstract: In this paper, we employ the mathematical framework on Transformers developed by \citet{sander2022sinkformers,geshkovski2023emergence,geshkovski2023mathematical} to explore how variations in attention parameters and initial token values impact the structural dynamics of token clusters. Our analysis demonstrates that while the clusters within a modified attention matrix dynamics can exhibit significant divergence from the original over extended periods, they maintain close similarities over shorter intervals, depending on the parameter differences. This work contributes to the fine-tuning field through practical applications to the LoRA algorithm \cite{hu2021lora,peft}, enhancing our understanding of the behavior of LoRA-enhanced Transformer models.
&lt;/p&gt;</description></item><item><title>&#22312;&#22788;&#29702;&#25317;&#26377;&#28508;&#22312;&#21464;&#37327;&#30340;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#26102;&#65292;&#36890;&#36807;&#23545;&#21327;&#21464;&#37327;&#36827;&#34892;&#24322;&#36136;&#32553;&#25918;&#65292;Lasso&#26041;&#27861;&#21487;&#20197;&#33719;&#24471;&#24378;&#26377;&#21147;&#30340;&#20272;&#35745;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2402.15409</link><description>&lt;p&gt;
&#25317;&#26377;&#28508;&#22312;&#21464;&#37327;&#30340;Lasso&#65306;&#39640;&#25928;&#20272;&#35745;&#12289;&#21327;&#21464;&#37327;&#37325;&#26032;&#32553;&#25918;&#21644;&#35745;&#31639;&#32479;&#35745;&#24046;&#36317;
&lt;/p&gt;
&lt;p&gt;
Lasso with Latents: Efficient Estimation, Covariate Rescaling, and Computational-Statistical Gaps
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15409
&lt;/p&gt;
&lt;p&gt;
&#22312;&#22788;&#29702;&#25317;&#26377;&#28508;&#22312;&#21464;&#37327;&#30340;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#26102;&#65292;&#36890;&#36807;&#23545;&#21327;&#21464;&#37327;&#36827;&#34892;&#24322;&#36136;&#32553;&#25918;&#65292;Lasso&#26041;&#27861;&#21487;&#20197;&#33719;&#24471;&#24378;&#26377;&#21147;&#30340;&#20272;&#35745;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#24403;&#24863;&#20852;&#36259;&#30340;&#21327;&#21464;&#37327;&#20043;&#38388;&#23384;&#22312;&#24378;&#30456;&#20851;&#24615;&#26102;&#65292;Lasso&#30340;&#32479;&#35745;&#24615;&#33021;&#20250;&#26174;&#33879;&#19979;&#38477;&#12290;&#29305;&#21035;&#26159;&#65292;&#19982;&#35745;&#31639;&#25928;&#29575;&#20302;&#19979;&#30340;&#22791;&#36873;&#26041;&#26696;&#22914;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#30456;&#27604;&#65292;Lasso&#30340;&#39044;&#27979;&#35823;&#24046;&#20250;&#21464;&#24471;&#20005;&#37325;&#20005;&#37325;&#12290;&#30001;&#20110;&#22312;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#20013;&#23384;&#22312;&#19968;&#20010;&#34987;&#26222;&#36941;&#29468;&#27979;&#30340;&#35745;&#31639;&#32479;&#35745;&#26435;&#34913;&#65292;&#36890;&#24120;&#19981;&#21487;&#33021;&#19968;&#33324;&#24615;&#22320;&#20943;&#23567;&#36825;&#19968;&#24046;&#36317;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#28982;&#30340;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#35774;&#32622;&#65292;&#20854;&#20013;&#21327;&#21464;&#37327;&#20043;&#38388;&#30340;&#24378;&#30456;&#20851;&#24615;&#26469;&#33258;&#26410;&#35266;&#23519;&#21040;&#30340;&#28508;&#22312;&#21464;&#37327;&#12290;&#22312;&#36825;&#31181;&#35774;&#23450;&#19979;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#30001;&#24378;&#30456;&#20851;&#24615;&#24341;&#36215;&#30340;&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#20196;&#20154;&#24778;&#35766;&#22320;&#31616;&#21333;&#30340;&#20462;&#22797;&#26041;&#27861;&#12290;&#34429;&#28982;&#26631;&#20934;&#21270;&#21327;&#21464;&#37327;&#30340;Lasso&#22833;&#36133;&#20102;&#65292;&#20294;&#26377;&#19968;&#31181;&#24322;&#36136;&#32553;&#25918;&#30340;&#21327;&#21464;&#37327;&#65292;Lasso&#23558;&#31361;&#28982;&#33719;&#24471;&#23545;&#20272;&#35745;&#30340;&#24378;&#26377;&#21147;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#39640;&#25928;&#30340;&#31243;&#24207;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15409v1 Announce Type: cross  Abstract: It is well-known that the statistical performance of Lasso can suffer significantly when the covariates of interest have strong correlations. In particular, the prediction error of Lasso becomes much worse than computationally inefficient alternatives like Best Subset Selection. Due to a large conjectured computational-statistical tradeoff in the problem of sparse linear regression, it may be impossible to close this gap in general.   In this work, we propose a natural sparse linear regression setting where strong correlations between covariates arise from unobserved latent variables. In this setting, we analyze the problem caused by strong correlations and design a surprisingly simple fix. While Lasso with standard normalization of covariates fails, there exists a heterogeneous scaling of the covariates with which Lasso will suddenly obtain strong provable guarantees for estimation. Moreover, we design a simple, efficient procedure fo
&lt;/p&gt;</description></item><item><title>&#38024;&#23545;&#30149;&#20363;-&#23545;&#29031;&#30740;&#31350;&#30340;&#36923;&#36753;&#22238;&#24402;&#21322;&#30417;&#30563;&#25512;&#26029;&#65292;&#21033;&#29992;&#26410;&#26631;&#35760;&#25968;&#25454;&#21487;&#20197;&#35782;&#21035;&#25130;&#36317;&#21442;&#25968;&#65292;&#35299;&#20915;&#20102;&#25130;&#36317;&#21442;&#25968;&#22312;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#19981;&#21487;&#36776;&#35782;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.15365</link><description>&lt;p&gt;
&#38024;&#23545;&#30149;&#20363;-&#23545;&#29031;&#30740;&#31350;&#30340;&#36923;&#36753;&#22238;&#24402;&#21322;&#30417;&#30563;&#25512;&#26029;&#30340;&#39640;&#25928;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient semi-supervised inference for logistic regression under case-control studies
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15365
&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#30149;&#20363;-&#23545;&#29031;&#30740;&#31350;&#30340;&#36923;&#36753;&#22238;&#24402;&#21322;&#30417;&#30563;&#25512;&#26029;&#65292;&#21033;&#29992;&#26410;&#26631;&#35760;&#25968;&#25454;&#21487;&#20197;&#35782;&#21035;&#25130;&#36317;&#21442;&#25968;&#65292;&#35299;&#20915;&#20102;&#25130;&#36317;&#21442;&#25968;&#22312;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#19981;&#21487;&#36776;&#35782;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21322;&#30417;&#30563;&#23398;&#20064;&#22312;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#36234;&#26469;&#36234;&#21463;&#21040;&#20851;&#27880;&#12290;&#22312;&#21322;&#30417;&#30563;&#23398;&#20064;&#35774;&#32622;&#20013;&#65292;&#25910;&#38598;&#20102;&#19968;&#20010;&#24102;&#26377;&#32467;&#26524;&#21644;&#21327;&#21464;&#37327;&#30340;&#26631;&#35760;&#25968;&#25454;&#38598;&#65292;&#20197;&#21450;&#19968;&#20010;&#20165;&#21253;&#21547;&#21327;&#21464;&#37327;&#30340;&#26410;&#26631;&#35760;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#22312;&#21322;&#30417;&#30563;&#35774;&#32622;&#20013;&#30340;&#25512;&#26029;&#38382;&#39064;&#65292;&#22312;&#36825;&#31181;&#35774;&#32622;&#19979;&#65292;&#26631;&#35760;&#25968;&#25454;&#20013;&#30340;&#32467;&#26524;&#26159;&#20108;&#36827;&#21046;&#30340;&#65292;&#32463;&#36807;&#30149;&#20363;-&#23545;&#29031;&#25277;&#26679;&#30340;&#26041;&#24335;&#25910;&#38598;&#26631;&#35760;&#25968;&#25454;&#12290;&#30149;&#20363;-&#23545;&#29031;&#25277;&#26679;&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#25277;&#26679;&#26041;&#26696;&#65292;&#21487;&#20943;&#36731;&#20108;&#36827;&#21046;&#25968;&#25454;&#20013;&#30340;&#19981;&#24179;&#34913;&#32467;&#26500;&#12290;&#22312;&#36923;&#36753;&#27169;&#22411;&#20551;&#35774;&#19979;&#65292;&#30149;&#20363;-&#23545;&#29031;&#25968;&#25454;&#20173;&#28982;&#21487;&#20197;&#20026;&#22238;&#24402;&#27169;&#22411;&#30340;&#26012;&#29575;&#21442;&#25968;&#25552;&#20379;&#19968;&#33268;&#30340;&#20272;&#35745;&#37327;&#12290;&#28982;&#32780;&#65292;&#25130;&#36317;&#21442;&#25968;&#26159;&#19981;&#21487;&#36776;&#35782;&#30340;&#12290;&#22240;&#27492;&#65292;&#19981;&#33021;&#20174;&#30149;&#20363;-&#23545;&#29031;&#25968;&#25454;&#20013;&#20272;&#35745;&#36793;&#38469;&#27604;&#20363;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#26377;&#26410;&#26631;&#35760;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#22312;&#21322;&#30417;&#30563;&#23398;&#20064;&#35774;&#32622;&#20013;&#35782;&#21035;&#25130;&#36317;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15365v1 Announce Type: cross  Abstract: Semi-supervised learning has received increasingly attention in statistics and machine learning. In semi-supervised learning settings, a labeled data set with both outcomes and covariates and an unlabeled data set with covariates only are collected. We consider an inference problem in semi-supervised settings where the outcome in the labeled data is binary and the labeled data is collected by case-control sampling. Case-control sampling is an effective sampling scheme for alleviating imbalance structure in binary data. Under the logistic model assumption, case-control data can still provide consistent estimator for the slope parameter of the regression model. However, the intercept parameter is not identifiable. Consequently, the marginal case proportion cannot be estimated from case-control data. We find out that with the availability of the unlabeled data, the intercept parameter can be identified in semi-supervised learning setting.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#31216;&#20026;&#36125;&#21494;&#26031;-SINDy&#65292;&#29992;&#20110;&#20174;&#26377;&#38480;&#19988;&#22024;&#26434;&#25968;&#25454;&#20013;&#23398;&#20064;&#27491;&#30830;&#30340;&#27169;&#22411;&#26041;&#31243;&#65292;&#24182;&#19988;&#23545;&#21442;&#25968;&#20272;&#35745;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#37327;&#21270;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#29983;&#29289;&#25968;&#25454;&#21644;&#23454;&#26102;&#31995;&#32479;&#35782;&#21035;&#12290;</title><link>https://arxiv.org/abs/2402.15357</link><description>&lt;p&gt;
&#20174;&#31232;&#30095;&#19988;&#22024;&#26434;&#25968;&#25454;&#20013;&#24555;&#36895;&#35782;&#21035;&#31232;&#30095;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Rapid Bayesian identification of sparse nonlinear dynamics from scarce and noisy data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15357
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#31216;&#20026;&#36125;&#21494;&#26031;-SINDy&#65292;&#29992;&#20110;&#20174;&#26377;&#38480;&#19988;&#22024;&#26434;&#25968;&#25454;&#20013;&#23398;&#20064;&#27491;&#30830;&#30340;&#27169;&#22411;&#26041;&#31243;&#65292;&#24182;&#19988;&#23545;&#21442;&#25968;&#20272;&#35745;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#37327;&#21270;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#29983;&#29289;&#25968;&#25454;&#21644;&#23454;&#26102;&#31995;&#32479;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#24555;&#36895;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#29992;&#20110;&#35782;&#21035;&#25511;&#21046;&#35266;&#27979;&#25968;&#25454;&#21160;&#24577;&#30340;&#24494;&#20998;&#26041;&#31243;&#12290;&#25105;&#20204;&#23558;SINDy&#26041;&#27861;&#37325;&#26032;&#26500;&#24314;&#21040;&#36125;&#21494;&#26031;&#26694;&#26550;&#20013;&#65292;&#24182;&#20351;&#29992;&#39640;&#26031;&#36924;&#36817;&#26469;&#21152;&#36895;&#35745;&#31639;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#26041;&#27861;&#65292;&#36125;&#21494;&#26031;-SINDy&#65292;&#19981;&#20165;&#37327;&#21270;&#20102;&#21442;&#25968;&#20272;&#35745;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#32780;&#19988;&#22312;&#20174;&#26377;&#38480;&#19988;&#22024;&#26434;&#25968;&#25454;&#20013;&#23398;&#20064;&#27491;&#30830;&#27169;&#22411;&#26102;&#26356;&#21152;&#31283;&#20581;&#12290;&#36890;&#36807;&#20351;&#29992;&#21512;&#25104;&#21644;&#30495;&#23454;&#20363;&#23376;&#65292;&#22914;&#29470;&#29441;-&#37326;&#20820;&#31181;&#32676;&#21160;&#24577;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26032;&#26694;&#26550;&#22312;&#23398;&#20064;&#27491;&#30830;&#27169;&#22411;&#26041;&#31243;&#20013;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#27604;&#36739;&#20102;&#20854;&#19982;&#29616;&#26377;&#26041;&#27861;&#30340;&#35745;&#31639;&#21644;&#25968;&#25454;&#25928;&#29575;&#12290;&#30001;&#20110;&#36125;&#21494;&#26031;-SINDy&#21487;&#20197;&#24555;&#36895;&#21560;&#25910;&#25968;&#25454;&#24182;&#23545;&#22122;&#22768;&#20855;&#26377;&#31283;&#20581;&#24615;&#65292;&#22240;&#27492;&#29305;&#21035;&#36866;&#29992;&#20110;&#29983;&#29289;&#25968;&#25454;&#21644;&#25511;&#21046;&#20013;&#30340;&#23454;&#26102;&#31995;&#32479;&#35782;&#21035;&#12290;&#20854;&#27010;&#29575;&#26694;&#26550;&#36824;&#20351;&#24471;&#21487;&#20197;&#35745;&#31639;&#20449;&#24687;&#29109;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15357v1 Announce Type: cross  Abstract: We propose a fast probabilistic framework for identifying differential equations governing the dynamics of observed data. We recast the SINDy method within a Bayesian framework and use Gaussian approximations for the prior and likelihood to speed up computation. The resulting method, Bayesian-SINDy, not only quantifies uncertainty in the parameters estimated but also is more robust when learning the correct model from limited and noisy data. Using both synthetic and real-life examples such as Lynx-Hare population dynamics, we demonstrate the effectiveness of the new framework in learning correct model equations and compare its computational and data efficiency with existing methods. Because Bayesian-SINDy can quickly assimilate data and is robust against noise, it is particularly suitable for biological data and real-time system identification in control. Its probabilistic framework also enables the calculation of information entropy, 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20449;&#24687;&#35770;&#23433;&#20840;&#25506;&#32034;&#20934;&#21017;&#65292;&#32467;&#21512;&#36125;&#21494;&#26031;&#20248;&#21270;&#25910;&#30410;&#20989;&#25968;&#65292;&#24418;&#25104;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23433;&#20840;&#36125;&#21494;&#26031;&#20248;&#21270;&#36873;&#25321;&#20934;&#21017;&#12290;</title><link>https://arxiv.org/abs/2402.15347</link><description>&lt;p&gt;
&#20449;&#24687;&#35770;&#23433;&#20840;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Information-Theoretic Safe Bayesian Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15347
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20449;&#24687;&#35770;&#23433;&#20840;&#25506;&#32034;&#20934;&#21017;&#65292;&#32467;&#21512;&#36125;&#21494;&#26031;&#20248;&#21270;&#25910;&#30410;&#20989;&#25968;&#65292;&#24418;&#25104;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23433;&#20840;&#36125;&#21494;&#26031;&#20248;&#21270;&#36873;&#25321;&#20934;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#39034;&#24207;&#20915;&#31574;&#20219;&#21153;&#65292;&#20854;&#30446;&#26631;&#26159;&#22312;&#19981;&#35780;&#20272;&#36829;&#21453;&#20808;&#39564;&#26410;&#30693;&#65288;&#23433;&#20840;&#65289;&#32422;&#26463;&#30340;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#20248;&#21270;&#26410;&#30693;&#20989;&#25968;&#12290;&#19968;&#20010;&#24120;&#35265;&#30340;&#26041;&#27861;&#26159;&#22312;&#26410;&#30693;&#20989;&#25968;&#19978;&#25918;&#32622;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#65292;&#24182;&#19988;&#20165;&#20801;&#35768;&#22312;&#39640;&#27010;&#29575;&#23433;&#20840;&#21306;&#22495;&#20869;&#36827;&#34892;&#35780;&#20272;&#12290;&#22823;&#22810;&#25968;&#24403;&#21069;&#26041;&#27861;&#20381;&#36182;&#20110;&#23545;&#22495;&#30340;&#31163;&#25955;&#21270;&#65292;&#24182;&#19988;&#19981;&#33021;&#30452;&#25509;&#25193;&#23637;&#21040;&#36830;&#32493;&#24773;&#20917;&#12290;&#27492;&#22806;&#65292;&#23427;&#20204;&#21033;&#29992;&#32422;&#26463;&#30340;&#35268;&#21017;&#20551;&#35774;&#30340;&#26041;&#24335;&#24341;&#20837;&#20102;&#19968;&#20010;&#39069;&#22806;&#30340;&#20851;&#38190;&#36229;&#21442;&#25968;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20449;&#24687;&#35770;&#23433;&#20840;&#25506;&#32034;&#20934;&#21017;&#65292;&#35813;&#20934;&#21017;&#30452;&#25509;&#21033;&#29992;GP&#21518;&#39564;&#26469;&#35782;&#21035;&#26368;&#20855;&#20449;&#24687;&#30340;&#23433;&#20840;&#21442;&#25968;&#36827;&#34892;&#35780;&#20272;&#12290;&#23558;&#36825;&#19968;&#25506;&#32034;&#20934;&#21017;&#19982;&#20247;&#25152;&#21608;&#30693;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#25910;&#30410;&#20989;&#25968;&#32467;&#21512;&#36215;&#26469;&#65292;&#20135;&#29983;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23433;&#20840;&#36125;&#21494;&#26031;&#20248;&#21270;&#36873;&#25321;&#20934;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15347v1 Announce Type: cross  Abstract: We consider a sequential decision making task, where the goal is to optimize an unknown function without evaluating parameters that violate an a~priori unknown (safety) constraint. A common approach is to place a Gaussian process prior on the unknown functions and allow evaluations only in regions that are safe with high probability. Most current methods rely on a discretization of the domain and cannot be directly extended to the continuous case. Moreover, the way in which they exploit regularity assumptions about the constraint introduces an additional critical hyperparameter. In this paper, we propose an information-theoretic safe exploration criterion that directly exploits the GP posterior to identify the most informative safe parameters to evaluate. The combination of this exploration criterion with a well known Bayesian optimization acquisition function yields a novel safe Bayesian optimization selection criterion. Our approach 
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#21463;&#38480;Fourier&#22522;&#30340;&#36731;&#37327;&#32423;&#12289;&#28789;&#27963;&#19988;&#31471;&#21040;&#31471;&#21487;&#35757;&#32451;&#30340;&#27010;&#29575;&#23494;&#24230;&#27169;&#22411;&#65292;&#33021;&#22815;&#26377;&#25928;&#36924;&#36817;&#21508;&#31181;&#22810;&#27169;&#24577;1&#32500;&#23494;&#24230;&#65292;&#34920;&#29616;&#20248;&#20110;&#20256;&#32479;&#30340;&#28145;&#24230;&#22240;&#24335;&#27169;&#22411;&#65292;&#21516;&#26102;&#22312;&#23398;&#20064;&#21387;&#32553;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#20854;&#23454;&#29992;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.15345</link><description>&lt;p&gt;
Fourier&#22522;&#23494;&#24230;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Fourier Basis Density Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15345
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#21463;&#38480;Fourier&#22522;&#30340;&#36731;&#37327;&#32423;&#12289;&#28789;&#27963;&#19988;&#31471;&#21040;&#31471;&#21487;&#35757;&#32451;&#30340;&#27010;&#29575;&#23494;&#24230;&#27169;&#22411;&#65292;&#33021;&#22815;&#26377;&#25928;&#36924;&#36817;&#21508;&#31181;&#22810;&#27169;&#24577;1&#32500;&#23494;&#24230;&#65292;&#34920;&#29616;&#20248;&#20110;&#20256;&#32479;&#30340;&#28145;&#24230;&#22240;&#24335;&#27169;&#22411;&#65292;&#21516;&#26102;&#22312;&#23398;&#20064;&#21387;&#32553;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#20854;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#36731;&#37327;&#32423;&#12289;&#28789;&#27963;&#19988;&#31471;&#21040;&#31471;&#21487;&#35757;&#32451;&#30340;&#27010;&#29575;&#23494;&#24230;&#27169;&#22411;&#65292;&#20854;&#30001;&#19968;&#20010;&#21463;&#38480;&#30340;Fourier&#22522;&#21442;&#25968;&#21270;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#35813;&#27169;&#22411;&#22312;&#36924;&#36817;&#19968;&#31995;&#21015;&#22810;&#27169;&#24577;1&#32500;&#23494;&#24230;&#26041;&#38754;&#30340;&#34920;&#29616;&#65292;&#36825;&#20123;&#23494;&#24230;&#36890;&#24120;&#24456;&#38590;&#25311;&#21512;&#12290;&#19982;[1]&#20013;&#24341;&#20837;&#30340;&#28145;&#24230;&#22240;&#24335;&#27169;&#22411;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#31867;&#20284;&#30340;&#35745;&#31639;&#39044;&#31639;&#19979;&#23454;&#29616;&#20102;&#26356;&#20302;&#30340;&#20132;&#21449;&#29109;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#22312;&#19968;&#20010;&#29609;&#20855;&#21387;&#32553;&#20219;&#21153;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#23637;&#31034;&#20102;&#20854;&#22312;&#23398;&#20064;&#21387;&#32553;&#20013;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15345v1 Announce Type: new  Abstract: We introduce a lightweight, flexible and end-to-end trainable probability density model parameterized by a constrained Fourier basis. We assess its performance at approximating a range of multi-modal 1D densities, which are generally difficult to fit. In comparison to the deep factorized model introduced in [1], our model achieves a lower cross entropy at a similar computational budget. In addition, we also evaluate our method on a toy compression task, demonstrating its utility in learned compression.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#20351;&#29992;&#22266;&#23450;&#25110;&#36882;&#20943;&#23398;&#20064;&#29575;&#30340;SGD&#36827;&#34892;&#38750;&#20984;&#20248;&#21270;&#26102;&#65292;&#25209;&#37327;&#22823;&#23567;&#19982;&#36845;&#20195;&#21644;SFO&#22797;&#26434;&#24230;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#25351;&#20986;&#20351;&#29992;&#20851;&#38190;&#25209;&#37327;&#22823;&#23567;&#30340;SGD&#21487;&#20197;&#26368;&#23567;&#21270;SFO&#22797;&#26434;&#24230;</title><link>https://arxiv.org/abs/2402.15344</link><description>&lt;p&gt;
&#20351;&#29992;&#22266;&#23450;&#21644;&#36882;&#20943;&#23398;&#20064;&#29575;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#36845;&#20195;&#21644;&#38543;&#26426;&#19968;&#38454;&#39044;&#35328;&#32773;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
Iteration and Stochastic First-order Oracle Complexities of Stochastic Gradient Descent using Constant and Decaying Learning Rates
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15344
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#20351;&#29992;&#22266;&#23450;&#25110;&#36882;&#20943;&#23398;&#20064;&#29575;&#30340;SGD&#36827;&#34892;&#38750;&#20984;&#20248;&#21270;&#26102;&#65292;&#25209;&#37327;&#22823;&#23567;&#19982;&#36845;&#20195;&#21644;SFO&#22797;&#26434;&#24230;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#25351;&#20986;&#20351;&#29992;&#20851;&#38190;&#25209;&#37327;&#22823;&#23567;&#30340;SGD&#21487;&#20197;&#26368;&#23567;&#21270;SFO&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#24615;&#33021;&#21462;&#20915;&#20110;&#23398;&#20064;&#29575;&#21644;&#25209;&#37327;&#22823;&#23567;&#65292;&#24433;&#21709;&#35757;&#32451;&#25152;&#38656;&#30340;&#36845;&#20195;&#27425;&#25968;&#21644;&#38543;&#26426;&#19968;&#38454;&#39044;&#35328;&#32773;&#65288;SFO&#65289;&#22797;&#26434;&#24230;&#12290;&#20808;&#21069;&#30340;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#65292;&#23545;&#20110;&#20351;&#29992;&#22266;&#23450;&#23398;&#20064;&#29575;&#30340;SGD&#65292;&#38543;&#30528;&#25209;&#37327;&#22823;&#23567;&#30340;&#22686;&#21152;&#65292;&#35757;&#32451;&#25152;&#38656;&#30340;&#36845;&#20195;&#27425;&#25968;&#20943;&#23569;&#65292;&#24182;&#19988;SFO&#22797;&#26434;&#24230;&#22312;&#20851;&#38190;&#25209;&#37327;&#22823;&#23567;&#26102;&#26368;&#23567;&#21270;&#65292;&#19968;&#26086;&#25209;&#37327;&#22823;&#23567;&#36229;&#36807;&#35813;&#22823;&#23567;&#21518;&#22686;&#21152;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#20351;&#29992;&#22266;&#23450;&#25110;&#36882;&#20943;&#23398;&#20064;&#29575;&#30340;SGD&#36827;&#34892;&#38750;&#20984;&#20248;&#21270;&#26102;&#65292;&#25209;&#37327;&#22823;&#23567;&#19982;&#25152;&#38656;&#36845;&#20195;&#21644;SFO&#22797;&#26434;&#24230;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#34920;&#26126;&#20351;&#29992;&#20851;&#38190;&#25209;&#37327;&#22823;&#23567;&#30340;SGD&#21487;&#20197;&#26368;&#23567;&#21270;SFO&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15344v1 Announce Type: cross  Abstract: The performance of stochastic gradient descent (SGD), which is the simplest first-order optimizer for training deep neural networks, depends on not only the learning rate but also the batch size. They both affect the number of iterations and the stochastic first-order oracle (SFO) complexity needed for training. In particular, the previous numerical results indicated that, for SGD using a constant learning rate, the number of iterations needed for training decreases when the batch size increases, and the SFO complexity needed for training is minimized at a critical batch size and that it increases once the batch size exceeds that size. Here, we study the relationship between batch size and the iteration and SFO complexities needed for nonconvex optimization in deep learning with SGD using constant or decaying learning rates and show that SGD using the critical batch size minimizes the SFO complexity. We also provide numerical compariso
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#20110;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#30340;&#20195;&#25968;&#29702;&#35770;&#65292;&#24212;&#29992;&#33539;&#30068;&#35770;&#26500;&#24314;&#20102;&#19968;&#20010;&#26725;&#26753;&#65292;&#26377;&#25928;&#22320;&#28085;&#30422;&#20102;&#31070;&#32463;&#32593;&#32476;&#35774;&#35745;&#30340;&#19981;&#21516;&#39118;&#26684;&#65292;&#21516;&#26102;&#33258;&#28982;&#22320;&#32534;&#30721;&#20102;&#35745;&#31639;&#26426;&#31185;&#23398;&#21644;&#33258;&#21160;&#26426;&#29702;&#35770;&#20013;&#30340;&#35768;&#22810;&#26631;&#20934;&#32467;&#26500;&#12290;</title><link>https://arxiv.org/abs/2402.15332</link><description>&lt;p&gt;
&#20998;&#31867;&#28145;&#24230;&#23398;&#20064;&#65306;&#19968;&#31181;&#20851;&#20110;&#26550;&#26500;&#30340;&#20195;&#25968;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Categorical Deep Learning: An Algebraic Theory of Architectures
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15332
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#20110;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#30340;&#20195;&#25968;&#29702;&#35770;&#65292;&#24212;&#29992;&#33539;&#30068;&#35770;&#26500;&#24314;&#20102;&#19968;&#20010;&#26725;&#26753;&#65292;&#26377;&#25928;&#22320;&#28085;&#30422;&#20102;&#31070;&#32463;&#32593;&#32476;&#35774;&#35745;&#30340;&#19981;&#21516;&#39118;&#26684;&#65292;&#21516;&#26102;&#33258;&#28982;&#22320;&#32534;&#30721;&#20102;&#35745;&#31639;&#26426;&#31185;&#23398;&#21644;&#33258;&#21160;&#26426;&#29702;&#35770;&#20013;&#30340;&#35768;&#22810;&#26631;&#20934;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20851;&#20110;&#25351;&#23450;&#21644;&#30740;&#31350;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#30340;&#36890;&#29992;&#26694;&#26550;&#30340;&#31435;&#22330;&#12290;&#25105;&#20204;&#35748;&#20026;&#21040;&#30446;&#21069;&#20026;&#27490;&#20851;&#20110;&#36825;&#19968;&#39046;&#22495;&#30340;&#20851;&#38190;&#23581;&#35797;&#32570;&#20047;&#19968;&#31181;&#19968;&#33268;&#30340;&#26725;&#26753;&#65292;&#33021;&#22815;&#25351;&#23450;&#27169;&#22411;&#24517;&#39035;&#28385;&#36275;&#30340;&#32422;&#26463;&#24182;&#35268;&#23450;&#23427;&#20204;&#30340;&#23454;&#29616;&#26041;&#24335;&#12290;&#19987;&#27880;&#20110;&#26500;&#24314;&#36825;&#26679;&#19968;&#20010;&#26725;&#26753;&#65292;&#25105;&#20204;&#24314;&#35758;&#24212;&#29992;&#33539;&#30068;&#35770;&#8212;&#8212;&#20934;&#30830;&#22320;&#35828;&#65292;&#21333;&#23376;&#20540;&#20110;&#21442;&#25968;&#26144;&#23556;&#30340;&#20108;&#33539;&#30068;&#30340;&#36890;&#29992;&#20195;&#25968;&#8212;&#8212;&#20316;&#20026;&#19968;&#31181;&#21333;&#19968;&#29702;&#35770;&#65292;&#20248;&#38597;&#22320;&#21253;&#21547;&#20102;&#31070;&#32463;&#32593;&#32476;&#35774;&#35745;&#30340;&#36825;&#20004;&#31181;&#39118;&#26684;&#12290;&#20026;&#20102;&#25903;&#25345;&#25105;&#20204;&#30340;&#35266;&#28857;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#19968;&#29702;&#35770;&#22914;&#20309;&#24674;&#22797;&#30001;&#20960;&#20309;&#28145;&#24230;&#23398;&#20064;&#23548;&#33268;&#30340;&#32422;&#26463;&#65292;&#20197;&#21450;&#20174;&#31070;&#32463;&#32593;&#32476;&#19981;&#21516;&#39046;&#22495;&#30340;&#22810;&#31181;&#26550;&#26500;&#65288;&#22914;RNNs&#65289;&#30340;&#23454;&#29616;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#36825;&#19968;&#29702;&#35770;&#22914;&#20309;&#33258;&#28982;&#22320;&#32534;&#30721;&#20102;&#35745;&#31639;&#26426;&#31185;&#23398;&#21644;&#33258;&#21160;&#26426;&#29702;&#35770;&#20013;&#30340;&#35768;&#22810;&#26631;&#20934;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15332v1 Announce Type: cross  Abstract: We present our position on the elusive quest for a general-purpose framework for specifying and studying deep learning architectures. Our opinion is that the key attempts made so far lack a coherent bridge between specifying constraints which models must satisfy and specifying their implementations. Focusing on building a such a bridge, we propose to apply category theory -- precisely, the universal algebra of monads valued in a 2-category of parametric maps -- as a single theory elegantly subsuming both of these flavours of neural network design. To defend our position, we show how this theory recovers constraints induced by geometric deep learning, as well as implementations of many architectures drawn from the diverse landscape of neural networks, such as RNNs. We also illustrate how the theory naturally encodes many standard constructs in computer science and automata theory.
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#24352;&#37327;&#30697;&#38453;&#36924;&#36817;&#21704;&#23494;&#23572;&#39039;-&#38597;&#21508;&#27604;-&#36125;&#23572;&#26364;&#26041;&#31243;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#29983;&#25104;&#24314;&#27169;&#20013;&#35299;&#20915;HJB&#26041;&#31243;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26080;&#38656;&#26679;&#26412;&#65292;&#19981;&#20381;&#36182;&#20110;&#24402;&#19968;&#21270;&#24120;&#25968;&#65292;&#24182;&#33021;&#36991;&#20813;&#32500;&#25968;&#28798;&#38590;&#12290;</title><link>https://arxiv.org/abs/2402.15285</link><description>&lt;p&gt;
&#20351;&#29992;&#24352;&#37327;&#30697;&#38453;&#36924;&#36817;&#21704;&#23494;&#23572;&#39039;-&#38597;&#21508;&#27604;-&#36125;&#23572;&#26364;&#26041;&#31243;&#30340;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Generative Modelling with Tensor Train approximations of Hamilton--Jacobi--Bellman equations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15285
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#24352;&#37327;&#30697;&#38453;&#36924;&#36817;&#21704;&#23494;&#23572;&#39039;-&#38597;&#21508;&#27604;-&#36125;&#23572;&#26364;&#26041;&#31243;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#29983;&#25104;&#24314;&#27169;&#20013;&#35299;&#20915;HJB&#26041;&#31243;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26080;&#38656;&#26679;&#26412;&#65292;&#19981;&#20381;&#36182;&#20110;&#24402;&#19968;&#21270;&#24120;&#25968;&#65292;&#24182;&#33021;&#36991;&#20813;&#32500;&#25968;&#28798;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#27010;&#29575;&#23494;&#24230;&#20013;&#36827;&#34892;&#37319;&#26679;&#22312;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65288;UQ&#65289;&#21644;&#29983;&#25104;&#24314;&#27169;&#65288;GM&#65289;&#31561;&#39046;&#22495;&#20013;&#26159;&#19968;&#39033;&#24120;&#35265;&#25361;&#25112;&#12290; &#22312;GM&#20013;&#65292;&#29305;&#21035;&#27969;&#34892;&#30340;&#37319;&#26679;&#24037;&#20855;&#26159;&#20381;&#36182;&#20110;Ornstein-Uhlenbeck&#27491;&#21521;&#36807;&#31243;&#30340;&#23545;&#25968;&#23494;&#24230;&#30340;&#36870;&#26102;&#38388;&#25193;&#25955;&#36807;&#31243;&#12290; &#22312;Berner&#31561;&#20154;[2022]&#20013;&#65292;&#20316;&#32773;&#25351;&#20986;&#36825;&#20123;&#23545;&#25968;&#23494;&#24230;&#21487;&#20197;&#36890;&#36807;&#35299;&#20915;&#28304;&#33258;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#30340;&#21704;&#23494;&#23572;&#39039;-&#38597;&#21508;&#27604;-&#36125;&#23572;&#26364;&#65288;HJB&#65289;&#26041;&#31243;&#26469;&#33719;&#24471;&#12290; &#34429;&#28982;&#36825;&#20010;HJB&#26041;&#31243;&#36890;&#24120;&#20351;&#29992;&#38388;&#25509;&#26041;&#27861;&#26469;&#22788;&#29702;&#65292;&#27604;&#22914;&#25919;&#31574;&#36845;&#20195;&#21644;&#23545;&#31070;&#32463;&#32593;&#32476;&#36825;&#26679;&#30340;&#40657;&#21283;&#23376;&#26550;&#26500;&#36827;&#34892;&#26080;&#30417;&#30563;&#35757;&#32451;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#30452;&#25509;&#26102;&#38388;&#31215;&#20998;&#26469;&#35299;&#20915;HJB&#26041;&#31243;&#65292;&#20351;&#29992;&#24352;&#37327;&#30697;&#38453;&#65288;TT&#65289;&#26684;&#24335;&#30340;&#21387;&#32553;&#22810;&#39033;&#24335;&#36827;&#34892;&#31354;&#38388;&#31163;&#25955;&#21270;&#12290; &#36825;&#31181;&#26041;&#27861;&#27809;&#26377;&#26679;&#26412;&#38656;&#27714;&#65292;&#19981;&#20381;&#36182;&#20110;&#24402;&#19968;&#21270;&#24120;&#25968;&#65292;&#24182;&#19988;&#21487;&#20197;&#36991;&#20813;&#32500;&#25968;&#28798;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15285v1 Announce Type: cross  Abstract: Sampling from probability densities is a common challenge in fields such as Uncertainty Quantification (UQ) and Generative Modelling (GM). In GM in particular, the use of reverse-time diffusion processes depending on the log-densities of Ornstein-Uhlenbeck forward processes are a popular sampling tool. In Berner et al. [2022] the authors point out that these log-densities can be obtained by solution of a \textit{Hamilton-Jacobi-Bellman} (HJB) equation known from stochastic optimal control. While this HJB equation is usually treated with indirect methods such as policy iteration and unsupervised training of black-box architectures like Neural Networks, we propose instead to solve the HJB equation by direct time integration, using compressed polynomials represented in the Tensor Train (TT) format for spatial discretization. Crucially, this method is sample-free, agnostic to normalization constants and can avoid the curse of dimensionalit
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#23556;&#30005;&#21644;&#32418;&#22806;&#22270;&#20687;&#65292;&#32467;&#21512;20,000&#24352;&#22270;&#20687;&#25968;&#25454;&#38598;&#36827;&#34892;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#65292;&#23454;&#29616;&#23545;&#38134;&#27827;&#24179;&#38754;&#20013;&#32039;&#20945;&#23556;&#30005;&#28304;&#30340;&#20998;&#31867;&#12290;</title><link>https://arxiv.org/abs/2402.15232</link><description>&lt;p&gt;
&#29992;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#23545;&#38134;&#27827;&#24179;&#38754;&#30340;&#32039;&#20945;&#23556;&#30005;&#28304;&#36827;&#34892;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Classification of compact radio sources in the Galactic plane with supervised machine learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15232
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#23556;&#30005;&#21644;&#32418;&#22806;&#22270;&#20687;&#65292;&#32467;&#21512;20,000&#24352;&#22270;&#20687;&#25968;&#25454;&#38598;&#36827;&#34892;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#65292;&#23454;&#29616;&#23545;&#38134;&#27827;&#24179;&#38754;&#20013;&#32039;&#20945;&#23556;&#30005;&#28304;&#30340;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#22788;&#29702;&#36807;&#30340;&#25968;&#25454;&#20135;&#21697;&#20013;&#29983;&#25104;&#31185;&#23398;&#20934;&#22791;&#23601;&#32490;&#30340;&#25968;&#25454;&#26159;&#26410;&#26469;Square Kilometre Array&#65288;SKA&#65289;&#21450;&#20854;&#21069;&#36523;&#23556;&#30005;&#36830;&#32493;&#27874;&#26222;&#26597;&#38754;&#20020;&#30340;&#20027;&#35201;&#25361;&#25112;&#20043;&#19968;&#65292;&#36825;&#26159;&#30001;&#20110;&#39044;&#26399;&#30340;&#25968;&#25454;&#37327;&#21644;&#23454;&#29616;&#39640;&#24230;&#33258;&#21160;&#21270;&#22788;&#29702;&#30340;&#38656;&#27714;&#12290;&#26412;&#25991;&#30528;&#37325;&#20110;&#20351;&#29992;&#23556;&#30005;&#21644;&#32418;&#22806;&#22270;&#20687;&#23545;&#38134;&#27827;&#24179;&#38754;&#20013;&#30340;&#32039;&#20945;&#23556;&#30005;&#28304;&#36827;&#34892;&#20998;&#31867;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#20135;&#29983;&#20102;&#19968;&#20010;&#21253;&#21547;&#32422;20,000&#24352;&#26469;&#33258;&#36807;&#21435;&#23556;&#30005;&#21644;&#32418;&#22806;&#35843;&#26597;&#20197;&#21450;&#20351;&#29992;&#28595;&#22823;&#21033;&#20122;SKA Pathfinder&#65288;ASKAP&#65289;&#36827;&#34892;&#30340;&#35797;&#39564;&#35843;&#26597;&#30340;&#19981;&#21516;&#22825;&#25991;&#31867;&#21035;&#30340;&#32039;&#20945;&#28304;&#22270;&#20687;&#30340;&#31574;&#21010;&#25968;&#25454;&#38598;&#12290;&#36824;&#33719;&#24471;&#20102;&#37096;&#20998;&#25968;&#25454;&#30340;&#23556;&#30005;&#35889;&#25351;&#25968;&#20449;&#24687;&#12290;&#28982;&#21518;&#22312;&#20135;&#29983;&#30340;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#20102;&#20004;&#20010;&#19981;&#21516;&#30340;&#20998;&#31867;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15232v1 Announce Type: cross  Abstract: Generation of science-ready data from processed data products is one of the major challenges in next-generation radio continuum surveys with the Square Kilometre Array (SKA) and its precursors, due to the expected data volume and the need to achieve a high degree of automated processing. Source extraction, characterization, and classification are the major stages involved in this process. In this work we focus on the classification of compact radio sources in the Galactic plane using both radio and infrared images as inputs. To this aim, we produced a curated dataset of ~20,000 images of compact sources of different astronomical classes, obtained from past radio and infrared surveys, and novel radio data from pilot surveys carried out with the Australian SKA Pathfinder (ASKAP). Radio spectral index information was also obtained for a subset of the data. We then trained two different classifiers on the produced dataset. The first model 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#32479;&#35745;&#26080;&#20851;&#22320;&#35780;&#20272;&#20102;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292;&#24182;&#35780;&#20272;&#20102;ML&#20272;&#35745;&#22312;&#26816;&#27979;&#26041;&#38754;&#30340;&#34920;&#29616;&#12290;</title><link>https://arxiv.org/abs/2402.15213</link><description>&lt;p&gt;
&#32479;&#35745;&#26080;&#20559;&#22238;&#24402;&#65306;&#19968;&#31181;&#29992;&#20110;&#39564;&#35777;&#22238;&#24402;&#27169;&#22411;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Statistical Agnostic Regression: a machine learning method to validate regression models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15213
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#32479;&#35745;&#26080;&#20851;&#22320;&#35780;&#20272;&#20102;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292;&#24182;&#35780;&#20272;&#20102;ML&#20272;&#35745;&#22312;&#26816;&#27979;&#26041;&#38754;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22238;&#24402;&#20998;&#26512;&#26159;&#32479;&#35745;&#24314;&#27169;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#20027;&#39064;&#65292;&#26088;&#22312;&#20272;&#35745;&#22240;&#21464;&#37327;&#65288;&#36890;&#24120;&#31216;&#20026;&#21709;&#24212;&#21464;&#37327;&#65289;&#19982;&#19968;&#20010;&#25110;&#22810;&#20010;&#33258;&#21464;&#37327;&#65288;&#21363;&#35299;&#37322;&#21464;&#37327;&#65289;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#32447;&#24615;&#22238;&#24402;&#26159;&#36804;&#20170;&#20026;&#27490;&#22312;&#39044;&#27979;&#12289;&#39044;&#27979;&#25110;&#22240;&#26524;&#25512;&#26029;&#31561;&#22810;&#20010;&#30740;&#31350;&#39046;&#22495;&#25191;&#34892;&#27492;&#20219;&#21153;&#30340;&#26368;&#27969;&#34892;&#26041;&#27861;&#12290;&#38500;&#20102;&#35299;&#20915;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#30340;&#21508;&#31181;&#20256;&#32479;&#26041;&#27861;&#22806;&#65292;&#22914;&#26222;&#36890;&#26368;&#23567;&#20108;&#20056;&#27861;&#12289;&#23725;&#22238;&#24402;&#25110;&#22871;&#32034;&#22238;&#24402;&#8212;&#8212;&#36825;&#20123;&#26041;&#27861;&#24448;&#24448;&#26159;&#26356;&#39640;&#32423;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#25216;&#26415;&#30340;&#22522;&#30784;&#8212;&#8212;&#21518;&#32773;&#24050;&#25104;&#21151;&#22320;&#24212;&#29992;&#22312;&#36825;&#31181;&#22330;&#26223;&#20013;&#65292;&#20294;&#27809;&#26377;&#23545;&#32479;&#35745;&#26174;&#33879;&#24615;&#36827;&#34892;&#27491;&#24335;&#23450;&#20041;&#12290;&#26368;&#22810;&#65292;&#22522;&#20110;&#32463;&#39564;&#27979;&#37327;&#65288;&#22914;&#27531;&#24046;&#25110;&#20934;&#30830;&#24230;&#65289;&#36827;&#34892;&#32622;&#25442;&#25110;&#22522;&#20110;&#32463;&#20856;&#20998;&#26512;&#65292;&#20197;&#21453;&#26144;ML&#20272;&#35745;&#23545;&#26816;&#27979;&#30340;&#26356;&#39640;&#33021;&#21147;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#32479;&#35745;&#26080;&#20851;&#22320;&#35780;&#20272;&#20102;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292;&#24182;&#23545;ML&#20272;&#35745;&#22312;&#26816;&#27979;&#26041;&#38754;&#30340;&#34920;&#29616;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15213v1 Announce Type: cross  Abstract: Regression analysis is a central topic in statistical modeling, aiming to estimate the relationships between a dependent variable, commonly referred to as the response variable, and one or more independent variables, i.e., explanatory variables. Linear regression is by far the most popular method for performing this task in several fields of research, such as prediction, forecasting, or causal inference. Beyond various classical methods to solve linear regression problems, such as Ordinary Least Squares, Ridge, or Lasso regressions - which are often the foundation for more advanced machine learning (ML) techniques - the latter have been successfully applied in this scenario without a formal definition of statistical significance. At most, permutation or classical analyses based on empirical measures (e.g., residuals or accuracy) have been conducted to reflect the greater ability of ML estimations for detection. In this paper, we introd
&lt;/p&gt;</description></item><item><title>&#25193;&#25955;&#27169;&#22411;&#30340;&#24494;&#35843;&#26041;&#27861;&#21487;&#20197;&#36890;&#36807;&#26368;&#22823;&#21270;&#22870;&#21169;&#20989;&#25968;&#30340;&#20215;&#20540;&#26469;&#20197;&#30446;&#26631;&#23548;&#21521;&#26041;&#24335;&#36827;&#34892;&#24494;&#35843;&#65292;&#20294;&#21487;&#33021;&#20250;&#38754;&#20020;&#22870;&#21169;&#23849;&#28291;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.15194</link><description>&lt;p&gt;
&#36830;&#32493;&#26102;&#38388;&#25193;&#25955;&#27169;&#22411;&#30340;&#24494;&#35843;&#20316;&#20026;&#29109;&#27491;&#21017;&#21270;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Fine-Tuning of Continuous-Time Diffusion Models as Entropy-Regularized Control
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15194
&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#30340;&#24494;&#35843;&#26041;&#27861;&#21487;&#20197;&#36890;&#36807;&#26368;&#22823;&#21270;&#22870;&#21169;&#20989;&#25968;&#30340;&#20215;&#20540;&#26469;&#20197;&#30446;&#26631;&#23548;&#21521;&#26041;&#24335;&#36827;&#34892;&#24494;&#35843;&#65292;&#20294;&#21487;&#33021;&#20250;&#38754;&#20020;&#22870;&#21169;&#23849;&#28291;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#22312;&#25429;&#25417;&#22797;&#26434;&#25968;&#25454;&#20998;&#24067;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20363;&#22914;&#33258;&#28982;&#22270;&#20687;&#21644;&#34507;&#30333;&#36136;&#30340;&#20998;&#24067;&#12290;&#34429;&#28982;&#25193;&#25955;&#27169;&#22411;&#32463;&#36807;&#35757;&#32451;&#21487;&#20195;&#34920;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#30340;&#20998;&#24067;&#65292;&#20294;&#25105;&#20204;&#36890;&#24120;&#26356;&#20851;&#27880;&#20854;&#20182;&#23646;&#24615;&#65292;&#20363;&#22914;&#29983;&#25104;&#22270;&#20687;&#30340;&#32654;&#23398;&#36136;&#37327;&#25110;&#29983;&#25104;&#34507;&#30333;&#36136;&#30340;&#21151;&#33021;&#23646;&#24615;&#12290;&#25193;&#25955;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#26368;&#22823;&#21270;&#26576;&#20123;&#22870;&#21169;&#20989;&#25968;&#30340;&#20215;&#20540;&#65288;&#20363;&#22914;&#22270;&#20687;&#30340;&#32654;&#23398;&#36136;&#37327;&#65289;&#20197;&#30446;&#26631;&#23548;&#21521;&#30340;&#26041;&#24335;&#36827;&#34892;&#24494;&#35843;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#21487;&#33021;&#20250;&#23548;&#33268;&#26679;&#26412;&#22810;&#26679;&#24615;&#20943;&#23569;&#65292;&#19982;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#20986;&#29616;&#26174;&#33879;&#20559;&#24046;&#65292;&#29978;&#33267;&#30001;&#20110;&#21033;&#29992;&#19981;&#23436;&#32654;&#30340;&#22870;&#21169;&#20989;&#25968;&#32780;&#23548;&#33268;&#26679;&#26412;&#36136;&#37327;&#36739;&#24046;&#12290;&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#22870;&#21169;&#20989;&#25968;&#26159;&#29992;&#20110;&#36817;&#20284;&#30495;&#23454;&#8220;&#30495;&#23454;&#8221;&#22870;&#21169;&#30340;&#23398;&#20064;&#27169;&#22411;&#26102;&#65292;&#26368;&#21518;&#19968;&#20010;&#38382;&#39064;&#32463;&#24120;&#20250;&#20135;&#29983;&#12290;&#36825;&#20123;&#25361;&#25112;&#24635;&#31216;&#20026;&#8220;&#22870;&#21169;&#23849;&#28291;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15194v1 Announce Type: cross  Abstract: Diffusion models excel at capturing complex data distributions, such as those of natural images and proteins. While diffusion models are trained to represent the distribution in the training dataset, we often are more concerned with other properties, such as the aesthetic quality of the generated images or the functional properties of generated proteins. Diffusion models can be finetuned in a goal-directed way by maximizing the value of some reward function (e.g., the aesthetic quality of an image). However, these approaches may lead to reduced sample diversity, significant deviations from the training data distribution, and even poor sample quality due to the exploitation of an imperfect reward function. The last issue often occurs when the reward function is a learned model meant to approximate a ground-truth "genuine" reward, as is the case in many practical applications. These challenges, collectively termed "reward collapse," pose
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21327;&#26041;&#24046;&#33258;&#36866;&#24212;&#30340;&#26368;&#23567;&#20108;&#20056;&#31639;&#27861;&#65292;&#21033;&#29992;&#22312;&#32447;&#20272;&#35745;&#21327;&#26041;&#24046;&#32467;&#26500;&#65292;&#30456;&#23545;&#20110;&#22522;&#20110;&#20195;&#29702;&#26041;&#24046;&#30340;&#31639;&#27861;&#33719;&#24471;&#25913;&#36827;&#30340;&#36951;&#25022;&#19978;&#30028;&#65292;&#29305;&#21035;&#22312;&#21327;&#26041;&#24046;&#31995;&#25968;&#20840;&#20026;&#38750;&#36127;&#26102;&#65292;&#33021;&#26377;&#25928;&#22320;&#21033;&#29992;&#21322;&#33218;&#21453;&#39304;&#65292;&#24182;&#22312;&#21508;&#31181;&#21442;&#25968;&#35774;&#32622;&#19979;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>https://arxiv.org/abs/2402.15171</link><description>&lt;p&gt;
&#29992;&#20110;&#38543;&#26426;&#32452;&#21512;&#21322;&#33218;&#32769;&#34382;&#26426;&#30340;&#21327;&#26041;&#24046;&#33258;&#36866;&#24212;&#26368;&#23567;&#20108;&#20056;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Covariance-Adaptive Least-Squares Algorithm for Stochastic Combinatorial Semi-Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15171
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21327;&#26041;&#24046;&#33258;&#36866;&#24212;&#30340;&#26368;&#23567;&#20108;&#20056;&#31639;&#27861;&#65292;&#21033;&#29992;&#22312;&#32447;&#20272;&#35745;&#21327;&#26041;&#24046;&#32467;&#26500;&#65292;&#30456;&#23545;&#20110;&#22522;&#20110;&#20195;&#29702;&#26041;&#24046;&#30340;&#31639;&#27861;&#33719;&#24471;&#25913;&#36827;&#30340;&#36951;&#25022;&#19978;&#30028;&#65292;&#29305;&#21035;&#22312;&#21327;&#26041;&#24046;&#31995;&#25968;&#20840;&#20026;&#38750;&#36127;&#26102;&#65292;&#33021;&#26377;&#25928;&#22320;&#21033;&#29992;&#21322;&#33218;&#21453;&#39304;&#65292;&#24182;&#22312;&#21508;&#31181;&#21442;&#25968;&#35774;&#32622;&#19979;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35299;&#20915;&#20102;&#38543;&#26426;&#32452;&#21512;&#21322;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#65292;&#20854;&#20013;&#29609;&#23478;&#21487;&#20197;&#20174;&#21253;&#21547;d&#20010;&#22522;&#26412;&#39033;&#30340;P&#20010;&#23376;&#38598;&#20013;&#36827;&#34892;&#36873;&#25321;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#31639;&#27861;&#65288;&#22914;CUCB&#12289;ESCB&#12289;OLS-UCB&#65289;&#38656;&#35201;&#23545;&#22870;&#21169;&#20998;&#24067;&#26377;&#20808;&#39564;&#30693;&#35782;&#65292;&#27604;&#22914;&#23376;&#39640;&#26031;&#20195;&#29702;-&#26041;&#24046;&#30340;&#19978;&#30028;&#65292;&#36825;&#24456;&#38590;&#20934;&#30830;&#20272;&#35745;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;OLS-UCB&#30340;&#26041;&#24046;&#33258;&#36866;&#24212;&#29256;&#26412;&#65292;&#20381;&#36182;&#20110;&#21327;&#26041;&#24046;&#32467;&#26500;&#30340;&#22312;&#32447;&#20272;&#35745;&#12290;&#22312;&#23454;&#38469;&#35774;&#32622;&#20013;&#65292;&#20272;&#35745;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#31995;&#25968;&#35201;&#23481;&#26131;&#24471;&#22810;&#65292;&#24182;&#19988;&#30456;&#23545;&#20110;&#22522;&#20110;&#20195;&#29702;&#26041;&#24046;&#30340;&#31639;&#27861;&#65292;&#23548;&#33268;&#25913;&#36827;&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;&#24403;&#21327;&#26041;&#24046;&#31995;&#25968;&#20840;&#20026;&#38750;&#36127;&#26102;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#26377;&#25928;&#22320;&#21033;&#29992;&#20102;&#21322;&#33218;&#21453;&#39304;&#65292;&#24182;&#19988;&#21487;&#20197;&#26126;&#26174;&#20248;&#20110;&#32769;&#34382;&#26426;&#21453;&#39304;&#26041;&#27861;&#65292;&#22312;&#25351;&#25968;&#32423;&#21035;P&#8811;d&#20197;&#21450;P&#8804;d&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#19968;&#28857;&#24182;&#19981;&#26469;&#33258;&#22823;&#22810;&#25968;&#29616;&#26377;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15171v1 Announce Type: new  Abstract: We address the problem of stochastic combinatorial semi-bandits, where a player can select from P subsets of a set containing d base items. Most existing algorithms (e.g. CUCB, ESCB, OLS-UCB) require prior knowledge on the reward distribution, like an upper bound on a sub-Gaussian proxy-variance, which is hard to estimate tightly. In this work, we design a variance-adaptive version of OLS-UCB, relying on an online estimation of the covariance structure. Estimating the coefficients of a covariance matrix is much more manageable in practical settings and results in improved regret upper bounds compared to proxy variance-based algorithms. When covariance coefficients are all non-negative, we show that our approach efficiently leverages the semi-bandit feedback and provably outperforms bandit feedback approaches, not only in exponential regimes where P $\gg$ d but also when P $\le$ d, which is not straightforward from most existing analyses.
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#36890;&#36807;&#32771;&#34385;&#25130;&#23614;&#29616;&#35937;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20934;&#27979;&#35797;&#26041;&#27861;&#65292;&#29992;&#20110;&#35266;&#27979;&#30740;&#31350;&#19982;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#20013;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#30340;&#31561;&#20215;&#24615;&#27979;&#35797;&#65292;&#20174;&#32780;&#39564;&#35777;&#26377;&#25928;&#24615;&#20551;&#35774;&#26159;&#21542;&#25104;&#31435;&#12290;</title><link>https://arxiv.org/abs/2402.15137</link><description>&lt;p&gt;
&#20351;&#29992;&#21463;&#21491;&#25130;&#23614;&#24433;&#21709;&#30340;&#23454;&#39564;&#25968;&#25454;&#23545;&#35266;&#27979;&#30740;&#31350;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Benchmarking Observational Studies with Experimental Data under Right-Censoring
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15137
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#36890;&#36807;&#32771;&#34385;&#25130;&#23614;&#29616;&#35937;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20934;&#27979;&#35797;&#26041;&#27861;&#65292;&#29992;&#20110;&#35266;&#27979;&#30740;&#31350;&#19982;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#20013;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#30340;&#31561;&#20215;&#24615;&#27979;&#35797;&#65292;&#20174;&#32780;&#39564;&#35777;&#26377;&#25928;&#24615;&#20551;&#35774;&#26159;&#21542;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#27979;&#30740;&#31350;&#20013;&#25512;&#26029;&#22240;&#26524;&#20851;&#31995;&#38656;&#35201;&#36827;&#34892;&#26080;&#27861;&#39564;&#35777;&#30340;&#26377;&#25928;&#24615;&#20551;&#35774;&#65307;&#28982;&#32780;&#65292;&#21487;&#20197;&#36890;&#36807;&#23558;&#35266;&#27979;&#30740;&#31350;&#19982;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#65288;RCT&#65289;&#20013;&#30340;&#23454;&#39564;&#25968;&#25454;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#26469;&#39564;&#35777;&#36825;&#20123;&#20551;&#35774;&#12290;&#29616;&#26377;&#31243;&#24207;&#30340;&#19968;&#20010;&#20027;&#35201;&#38480;&#21046;&#26159;&#26410;&#32771;&#34385;&#21040;&#25130;&#23614;&#29616;&#35937;&#65292;&#23613;&#31649;&#26377;&#22823;&#37327;&#30340;RCT&#21644;&#25253;&#21578;&#21491;&#25130;&#23614;&#26102;&#38388;&#38388;&#38548;&#20107;&#20214;&#32467;&#26524;&#30340;&#35266;&#27979;&#30740;&#31350;&#12290;&#25105;&#20204;&#32771;&#34385;&#20004;&#31181;&#24773;&#20917;&#65292;&#20854;&#20013;&#25130;&#23614;&#26102;&#38388;&#65288;1&#65289;&#29420;&#31435;&#20110;&#26102;&#38388;&#38388;&#38548;&#20107;&#20214;&#65292;&#20197;&#21450;&#65288;2&#65289;&#22312;&#35266;&#27979;&#30740;&#31350;&#21644;RCT&#20013;&#20197;&#30456;&#21516;&#26041;&#24335;&#21462;&#20915;&#20110;&#26102;&#38388;&#33267;&#20107;&#20214;&#12290;&#23545;&#20110;&#21069;&#32773;&#65292;&#25105;&#20204;&#37319;&#29992;&#19968;&#31181;&#25130;&#26029;-&#21452;&#37325;&#40065;&#26834;&#20449;&#21495;&#65292;&#29992;&#20110;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;CATE&#65289;&#30340;&#31561;&#20215;&#24615;&#27979;&#35797;&#65292;&#20197;&#20419;&#36827;OS&#21644;RCT&#20013;CATE&#30340;&#31561;&#20215;&#24615;&#27979;&#35797;&#65292;&#36825;&#30456;&#24403;&#20110;&#27979;&#35797;&#26377;&#25928;&#24615;&#30340;&#20551;&#35774;&#26159;&#21542;&#25104;&#31435;&#12290;&#23545;&#20110;&#21518;&#32773;&#65292;&#25105;&#20204;&#21457;&#29616;&#23613;&#31649;&#21487;&#33021;&#26080;&#27861;&#36827;&#34892;&#26080;&#20559;CATE&#20272;&#35745;&#65292;&#20294;&#20173;&#28982;&#21487;&#20197;&#20351;&#29992;&#30456;&#21516;&#30340;&#27979;&#35797;&#12290;&#25105;&#20204;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#32771;&#34385;&#25130;&#23614;&#30340;&#27979;&#35797;&#30340;&#26377;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15137v1 Announce Type: cross  Abstract: Drawing causal inferences from observational studies (OS) requires unverifiable validity assumptions; however, one can falsify those assumptions by benchmarking the OS with experimental data from a randomized controlled trial (RCT). A major limitation of existing procedures is not accounting for censoring, despite the abundance of RCTs and OSes that report right-censored time-to-event outcomes. We consider two cases where censoring time (1) is independent of time-to-event and (2) depends on time-to-event the same way in OS and RCT. For the former, we adopt a censoring-doubly-robust signal for the conditional average treatment effect (CATE) to facilitate an equivalence test of CATEs in OS and RCT, which serves as a proxy for testing if the validity assumptions hold. For the latter, we show that the same test can still be used even though unbiased CATE estimation may not be possible. We verify the effectiveness of our censoring-aware tes
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#25193;&#23637;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;&#24323;&#26435;&#36873;&#39033;&#65292;&#24182;&#25104;&#21151;&#35774;&#35745;&#21644;&#20998;&#26512;&#20102;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#28176;&#36817;&#21644;&#31859;&#36855;&#35834;&#19979;&#26368;&#20248;&#12290;</title><link>https://arxiv.org/abs/2402.15127</link><description>&lt;p&gt;
&#20855;&#26377;&#24323;&#26435;&#36873;&#39033;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Multi-Armed Bandits with Abstention
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15127
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#25193;&#23637;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;&#24323;&#26435;&#36873;&#39033;&#65292;&#24182;&#25104;&#21151;&#35774;&#35745;&#21644;&#20998;&#26512;&#20102;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#28176;&#36817;&#21644;&#31859;&#36855;&#35834;&#19979;&#26368;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#25193;&#23637;&#65292;&#20854;&#20013;&#21253;&#21547;&#20102;&#39069;&#22806;&#30340;&#25112;&#30053;&#20803;&#32032;&#65306;&#24323;&#26435;&#36873;&#39033;&#12290;&#22312;&#36825;&#20010;&#22686;&#24378;&#26694;&#26550;&#20013;&#65292;&#20195;&#29702;&#19981;&#20165;&#38656;&#35201;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#36873;&#25321;&#19968;&#20010;&#33218;&#65292;&#36824;&#21487;&#20197;&#36873;&#25321;&#22312;&#35266;&#23519;&#20043;&#21069;&#25918;&#24323;&#25509;&#21463;&#38543;&#26426;&#30636;&#26102;&#22870;&#21169;&#12290;&#24403;&#36873;&#25321;&#24323;&#26435;&#26102;&#65292;&#20195;&#29702;&#35201;&#20040;&#36973;&#21463;&#22266;&#23450;&#30340;&#21518;&#24724;&#65292;&#35201;&#20040;&#33719;&#24471;&#19968;&#23450;&#30340;&#22870;&#21169;&#20445;&#35777;&#12290;&#37492;&#20110;&#36825;&#31181;&#39069;&#22806;&#30340;&#22797;&#26434;&#24615;&#65292;&#25105;&#20204;&#25506;&#35752;&#26159;&#21542;&#21487;&#20197;&#24320;&#21457;&#20986;&#26082;&#28176;&#36817;&#21448;&#31859;&#36855;&#35834;&#19979;&#26368;&#20248;&#30340;&#26377;&#25928;&#31639;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#35774;&#35745;&#21644;&#20998;&#26512;&#31639;&#27861;&#26469;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#65292;&#36825;&#20123;&#31639;&#27861;&#30340;&#21518;&#24724;&#28385;&#36275;&#30456;&#24212;&#30340;&#20449;&#24687;&#29702;&#35770;&#19979;&#38480;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#20026;&#24323;&#26435;&#36873;&#39033;&#30340;&#22909;&#22788;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#25968;&#37327;&#21270;&#35265;&#35299;&#65292;&#20026;&#22312;&#20854;&#20182;&#20855;&#26377;&#36825;&#31181;&#36873;&#39033;&#30340;&#22312;&#32447;&#20915;&#31574;&#38382;&#39064;&#20013;&#36827;&#19968;&#27493;&#25506;&#32034;&#22880;&#23450;&#20102;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15127v1 Announce Type: new  Abstract: We introduce a novel extension of the canonical multi-armed bandit problem that incorporates an additional strategic element: abstention. In this enhanced framework, the agent is not only tasked with selecting an arm at each time step, but also has the option to abstain from accepting the stochastic instantaneous reward before observing it. When opting for abstention, the agent either suffers a fixed regret or gains a guaranteed reward. Given this added layer of complexity, we ask whether we can develop efficient algorithms that are both asymptotically and minimax optimal. We answer this question affirmatively by designing and analyzing algorithms whose regrets meet their corresponding information-theoretic lower bounds. Our results offer valuable quantitative insights into the benefits of the abstention option, laying the groundwork for further exploration in other online decision-making problems with such an option. Numerical results f
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#28145;&#24230;&#23637;&#24320;&#25216;&#26415;&#65292;&#26412;&#25991;&#25552;&#20986;&#30340;&#21487;&#35757;&#32451;SVGD&#31639;&#27861;&#21152;&#36895;&#20102;&#20854;&#25910;&#25947;&#36895;&#24230;&#65292;&#30456;&#27604;&#20256;&#32479;SVGD&#21464;&#20307;&#34920;&#29616;&#20986;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.15125</link><description>&lt;p&gt;
&#36890;&#36807;&#28145;&#24230;&#23637;&#24320;&#21152;&#36895;&#26031;&#22374;&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#36895;&#24230;
&lt;/p&gt;
&lt;p&gt;
Accelerating Convergence of Stein Variational Gradient Descent via Deep Unfolding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15125
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#28145;&#24230;&#23637;&#24320;&#25216;&#26415;&#65292;&#26412;&#25991;&#25552;&#20986;&#30340;&#21487;&#35757;&#32451;SVGD&#31639;&#27861;&#21152;&#36895;&#20102;&#20854;&#25910;&#25947;&#36895;&#24230;&#65292;&#30456;&#27604;&#20256;&#32479;SVGD&#21464;&#20307;&#34920;&#29616;&#20986;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Stein&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#65288;SVGD&#65289;&#26159;&#19968;&#31181;&#33879;&#21517;&#30340;&#22522;&#20110;&#31890;&#23376;&#30340;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#65292;&#29992;&#20110;&#23545;&#30446;&#26631;&#20998;&#24067;&#36827;&#34892;&#37319;&#26679;&#12290;SVGD&#24050;&#32463;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20852;&#36259;&#65292;&#24212;&#29992;&#20110;&#36125;&#21494;&#26031;&#25512;&#29702;&#31561;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#23558;&#19968;&#31181;&#21517;&#20026;&#28145;&#24230;&#23637;&#24320;&#30340;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#34701;&#20837;SVGD&#30340;&#26032;&#22411;&#21487;&#35757;&#32451;&#31639;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#20419;&#36827;&#20102;&#23545;SVGD&#30340;&#20869;&#37096;&#21442;&#25968;&#36827;&#34892;&#23398;&#20064;&#65292;&#20174;&#32780;&#21152;&#36895;&#20102;&#20854;&#25910;&#25947;&#36895;&#24230;&#12290;&#20026;&#20102;&#35780;&#20272;&#25152;&#25552;&#20986;&#30340;&#21487;&#35757;&#32451;SVGD&#31639;&#27861;&#65292;&#25105;&#20204;&#23545;&#19977;&#39033;&#20219;&#21153;&#36827;&#34892;&#20102;&#25968;&#20540;&#27169;&#25311;&#65306;&#23545;&#19968;&#32500;&#39640;&#26031;&#28151;&#21512;&#36827;&#34892;&#37319;&#26679;&#65292;&#36827;&#34892;&#36125;&#21494;&#26031;&#36923;&#36753;&#22238;&#24402;&#20197;&#21450;&#23398;&#20064;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#27604;SVGD&#30340;&#20256;&#32479;&#21464;&#20307;&#34920;&#29616;&#20986;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15125v1 Announce Type: new  Abstract: Stein variational gradient descent (SVGD) is a prominent particle-based variational inference method used for sampling a target distribution. SVGD has attracted interest for application in machine-learning techniques such as Bayesian inference. In this paper, we propose novel trainable algorithms that incorporate a deep-learning technique called deep unfolding,into SVGD. This approach facilitates the learning of the internal parameters of SVGD, thereby accelerating its convergence speed. To evaluate the proposed trainable SVGD algorithms, we conducted numerical simulations of three tasks: sampling a one-dimensional Gaussian mixture, performing Bayesian logistic regression, and learning Bayesian neural networks. The results show that our proposed algorithms exhibit faster convergence than the conventional variants of SVGD.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#29289;&#29702;&#32422;&#26463;&#30340;&#22810;&#39033;&#24335;&#28151;&#27788;&#23637;&#24320;&#26041;&#27861;&#65292;&#23558;&#31185;&#23398;&#26426;&#22120;&#23398;&#20064;&#19982;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26080;&#32541;&#38598;&#25104;&#65292;&#26377;&#25928;&#22320;&#23454;&#29616;SciML&#20219;&#21153;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#22312;UQ&#20219;&#21153;&#20013;&#21033;&#29992;SciML&#25552;&#39640;&#19981;&#30830;&#23450;&#24615;&#35780;&#20272;&#12290;</title><link>https://arxiv.org/abs/2402.15115</link><description>&lt;p&gt;
&#29289;&#29702;&#32422;&#26463;&#30340;&#22810;&#39033;&#24335;&#28151;&#27788;&#23637;&#24320;&#29992;&#20110;&#31185;&#23398;&#26426;&#22120;&#23398;&#20064;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Physics-constrained polynomial chaos expansion for scientific machine learning and uncertainty quantification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15115
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#29289;&#29702;&#32422;&#26463;&#30340;&#22810;&#39033;&#24335;&#28151;&#27788;&#23637;&#24320;&#26041;&#27861;&#65292;&#23558;&#31185;&#23398;&#26426;&#22120;&#23398;&#20064;&#19982;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26080;&#32541;&#38598;&#25104;&#65292;&#26377;&#25928;&#22320;&#23454;&#29616;SciML&#20219;&#21153;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#22312;UQ&#20219;&#21153;&#20013;&#21033;&#29992;SciML&#25552;&#39640;&#19981;&#30830;&#23450;&#24615;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29289;&#29702;&#32422;&#26463;&#30340;&#22810;&#39033;&#24335;&#28151;&#27788;&#23637;&#24320;&#20316;&#20026;&#19968;&#31181;&#26367;&#20195;&#24314;&#27169;&#26041;&#27861;&#65292;&#33021;&#22815;&#25191;&#34892;&#31185;&#23398;&#26426;&#22120;&#23398;&#20064;&#65288;SciML&#65289;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65288;UQ&#65289;&#20219;&#21153;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20855;&#26377;&#29420;&#29305;&#30340;&#33021;&#21147;&#65306;&#23558;SciML&#19982;UQ&#26080;&#32541;&#38598;&#25104;&#65292;&#20174;&#32780;&#33021;&#22815;&#26377;&#25928;&#22320;&#37327;&#21270;SciML&#20219;&#21153;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#21033;&#29992;SciML&#26469;&#25913;&#21892;UQ&#30456;&#20851;&#20219;&#21153;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#35780;&#20272;&#12290;&#35813;&#26367;&#20195;&#27169;&#22411;&#21487;&#20197;&#26377;&#25928;&#22320;&#32435;&#20837;&#22810;&#31181;&#29289;&#29702;&#32422;&#26463;&#65292;&#22914;&#25903;&#37197;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDEs&#65289;&#21450;&#20854;&#30456;&#20851;&#30340;&#21021;&#22987;&#21644;&#36793;&#30028;&#26465;&#20214;&#32422;&#26463;&#65292;&#19981;&#31561;&#24335;&#22411;&#32422;&#26463;&#65288;&#22914;&#21333;&#35843;&#24615;&#65292;&#20984;&#24615;&#65292;&#38750;&#36127;&#24615;&#31561;&#65289;&#65292;&#20197;&#21450;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#28155;&#21152;&#39069;&#22806;&#20808;&#39564;&#20449;&#24687;&#20197;&#36741;&#21161;&#26377;&#38480;&#25968;&#25454;&#12290;&#36825;&#30830;&#20445;&#20102;&#29289;&#29702;&#19978;&#21512;&#29702;&#30340;&#39044;&#27979;&#65292;&#24182;&#26174;&#33879;&#20943;&#23569;&#20102;&#26114;&#36149;&#35745;&#31639;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15115v1 Announce Type: cross  Abstract: We present a novel physics-constrained polynomial chaos expansion as a surrogate modeling method capable of performing both scientific machine learning (SciML) and uncertainty quantification (UQ) tasks. The proposed method possesses a unique capability: it seamlessly integrates SciML into UQ and vice versa, which allows it to quantify the uncertainties in SciML tasks effectively and leverage SciML for improved uncertainty assessment during UQ-related tasks. The proposed surrogate model can effectively incorporate a variety of physical constraints, such as governing partial differential equations (PDEs) with associated initial and boundary conditions constraints, inequality-type constraints (e.g., monotonicity, convexity, non-negativity, among others), and additional a priori information in the training process to supplement limited data. This ensures physically realistic predictions and significantly reduces the need for expensive comp
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#23545;&#25968;Sobolev&#19981;&#31561;&#24335;&#26500;&#36896;&#30340;MI&#19979;&#38480;&#30340;&#36138;&#23146;&#26041;&#27861;&#22312;&#38750;&#32447;&#24615;&#27169;&#22411;&#20248;&#21270;&#35774;&#35745;&#20013;&#34920;&#29616;&#20986;&#33394;</title><link>https://arxiv.org/abs/2402.15053</link><description>&lt;p&gt;
&#20351;&#29992;&#23545;&#25968;Sobolev&#19981;&#31561;&#24335;&#30340;&#38750;&#32447;&#24615;&#36125;&#21494;&#26031;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Nonlinear Bayesian optimal experimental design using logarithmic Sobolev inequalities
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15053
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#23545;&#25968;Sobolev&#19981;&#31561;&#24335;&#26500;&#36896;&#30340;MI&#19979;&#38480;&#30340;&#36138;&#23146;&#26041;&#27861;&#22312;&#38750;&#32447;&#24615;&#27169;&#22411;&#20248;&#21270;&#35774;&#35745;&#20013;&#34920;&#29616;&#20986;&#33394;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20174;&#19968;&#20010;&#36739;&#22823;&#30340;&#20505;&#36873;&#27744;&#20013;&#36873;&#25321;$k$&#20010;&#23454;&#39564;&#30340;&#38382;&#39064;&#65292;&#30446;&#26631;&#26159;&#26368;&#22823;&#21270;&#25152;&#36873;&#23376;&#38598;&#19982;&#22522;&#30784;&#21442;&#25968;&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#65288;MI&#65289;&#12290;&#30001;&#20110;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#20197;&#21450;&#22312;&#38750;&#32447;&#24615;/&#38750;&#39640;&#26031;&#35774;&#32622;&#20013;&#35780;&#20272;MI&#30340;&#22256;&#38590;&#24615;&#65292;&#25214;&#21040;&#30830;&#20999;&#35299;&#20915;&#26041;&#26696;&#22312;&#35745;&#31639;&#19978;&#26159;&#26114;&#36149;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#36890;&#36807;&#23545;&#25968;Sobolev&#19981;&#31561;&#24335;&#26500;&#36896;&#30340;&#26032;&#30340;&#35745;&#31639;&#24265;&#20215;&#30340;MI&#19979;&#38480;&#30340;&#36138;&#23146;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#21253;&#25324;&#20855;&#26377;&#38750;&#21152;&#24615;&#22122;&#22768;&#30340;&#38750;&#32447;&#24615;&#27169;&#22411;&#30340;&#26368;&#20248;&#35774;&#35745;&#22312;&#20869;&#30340;&#21508;&#31181;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#38543;&#26426;&#36873;&#25321;&#31574;&#30053;&#12289;&#39640;&#26031;&#36924;&#36817;&#21644;&#23884;&#22871;&#33945;&#29305;&#21345;&#27931;&#65288;NMC&#65289;MI&#20272;&#31639;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15053v1 Announce Type: cross  Abstract: We study the problem of selecting $k$ experiments from a larger candidate pool, where the goal is to maximize mutual information (MI) between the selected subset and the underlying parameters. Finding the exact solution is to this combinatorial optimization problem is computationally costly, not only due to the complexity of the combinatorial search but also the difficulty of evaluating MI in nonlinear/non-Gaussian settings. We propose greedy approaches based on new computationally inexpensive lower bounds for MI, constructed via log-Sobolev inequalities. We demonstrate that our method outperforms random selection strategies, Gaussian approximations, and nested Monte Carlo (NMC) estimators of MI in various settings, including optimal design for nonlinear models with non-additive noise.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19968;&#33268;&#24615;&#24341;&#23548;&#28201;&#24230;&#32553;&#25918;&#65288;CTS&#65289;&#31574;&#30053;&#65292;&#36890;&#36807;&#25552;&#20379;&#28304;&#22495;&#25968;&#25454;&#26679;&#26412;&#20043;&#38388;&#30340;&#30456;&#20114;&#30417;&#30563;&#65292;&#26174;&#33879;&#22686;&#24378;&#20102;&#22495;&#22806;&#65288;OOD&#65289;&#26657;&#20934;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.15019</link><description>&lt;p&gt;
&#20351;&#29992;&#26679;&#24335;&#21644;&#20869;&#23481;&#20449;&#24687;&#30340;&#19968;&#33268;&#24615;&#24341;&#23548;&#28201;&#24230;&#32553;&#25918;&#29992;&#20110;&#22495;&#22806;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Consistency-Guided Temperature Scaling Using Style and Content Information for Out-of-Domain Calibration
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15019
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19968;&#33268;&#24615;&#24341;&#23548;&#28201;&#24230;&#32553;&#25918;&#65288;CTS&#65289;&#31574;&#30053;&#65292;&#36890;&#36807;&#25552;&#20379;&#28304;&#22495;&#25968;&#25454;&#26679;&#26412;&#20043;&#38388;&#30340;&#30456;&#20114;&#30417;&#30563;&#65292;&#26174;&#33879;&#22686;&#24378;&#20102;&#22495;&#22806;&#65288;OOD&#65289;&#26657;&#20934;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#20851;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23545;&#39046;&#22495;&#36716;&#31227;&#30340;&#40065;&#26834;&#24615;&#36234;&#26469;&#36234;&#21463;&#21040;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30740;&#31350;&#37117;&#38598;&#20013;&#22312;&#25552;&#39640;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#19978;&#65292;&#32780;&#19981;&#26159;&#26657;&#20934;&#24615;&#33021;&#65292;&#32780;&#21518;&#32773;&#26159;&#20540;&#24471;&#20449;&#36182;&#30340;AI&#31995;&#32479;&#30340;&#21478;&#19968;&#20010;&#37325;&#35201;&#35201;&#27714;&#12290;&#28201;&#24230;&#32553;&#25918;&#65288;TS&#65289;&#20316;&#20026;&#19968;&#31181;&#21487;&#20197;&#20445;&#25345;&#20934;&#30830;&#24615;&#30340;&#20107;&#21518;&#26657;&#20934;&#26041;&#27861;&#65292;&#22312;&#39046;&#22495;&#20869;&#29615;&#22659;&#20013;&#24050;&#34987;&#35777;&#26126;&#26159;&#26377;&#25928;&#30340;&#65292;&#20294;&#22312;&#39046;&#22495;&#22806;&#65288;OOD&#65289;&#21364;&#19981;&#26159;&#65292;&#22240;&#20026;&#20107;&#20808;&#24456;&#38590;&#33719;&#21462;&#26410;&#35265;&#39046;&#22495;&#30340;&#39564;&#35777;&#38598;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28201;&#24230;&#32553;&#25918;&#31574;&#30053;&#65292;&#19968;&#33268;&#24615;&#24341;&#23548;&#28201;&#24230;&#32553;&#25918;&#65288;CTS&#65289;&#65292;&#36890;&#36807;&#25552;&#20379;&#28304;&#22495;&#25968;&#25454;&#26679;&#26412;&#20043;&#38388;&#30340;&#30456;&#20114;&#30417;&#30563;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;OOD&#26657;&#20934;&#24615;&#33021;&#12290;&#21463;&#21040;&#25105;&#20204;&#30340;&#35266;&#23519;&#21040;&#30340;&#21457;&#29616;&#65292;&#30001;&#20110;&#19981;&#19968;&#33268;&#30340;&#26679;&#26412;&#39044;&#27979;&#23548;&#33268;&#30340;&#36807;&#24230;&#33258;&#20449;&#26159;OOD&#26657;&#20934;&#30340;&#20027;&#35201;&#38556;&#30861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26657;&#20934;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15019v1 Announce Type: cross  Abstract: Research interests in the robustness of deep neural networks against domain shifts have been rapidly increasing in recent years. Most existing works, however, focus on improving the accuracy of the model, not the calibration performance which is another important requirement for trustworthy AI systems. Temperature scaling (TS), an accuracy-preserving post-hoc calibration method, has been proven to be effective in in-domain settings, but not in out-of-domain (OOD) due to the difficulty in obtaining a validation set for the unseen domain beforehand. In this paper, we propose consistency-guided temperature scaling (CTS), a new temperature scaling strategy that can significantly enhance the OOD calibration performance by providing mutual supervision among data samples in the source domains. Motivated by our observation that over-confidence stemming from inconsistent sample predictions is the main obstacle to OOD calibration, we propose to 
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#36890;&#36807;&#24343;&#33713;&#26126;&#27721;&#22982;&#24515;&#33039;&#30149;&#25968;&#25454;&#20316;&#20026;&#26696;&#20363;&#30740;&#31350;&#65292;&#27604;&#36739;&#20102;&#20843;&#31181;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#31639;&#27861;&#22312;&#19981;&#21516;&#35757;&#32451;/&#27979;&#35797;&#22330;&#26223;&#19979;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#21457;&#29616;&#26497;&#31471;&#26799;&#24230;&#25552;&#21319;&#21644;&#25903;&#25345;&#21521;&#37327;&#26426;&#22312;&#35757;&#32451;&#19981;&#24179;&#34913;&#25968;&#25454;&#26102;&#23384;&#22312;&#32570;&#38519;&#12290;</title><link>https://arxiv.org/abs/2402.15005</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#31639;&#27861;&#30340;&#27604;&#36739;&#21450;&#20854;&#22312;&#24343;&#33713;&#26126;&#27721;&#22982;&#24515;&#33039;&#30740;&#31350;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Comparison of Machine Learning Classification Algorithms and Application to the Framingham Heart Study
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15005
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#36890;&#36807;&#24343;&#33713;&#26126;&#27721;&#22982;&#24515;&#33039;&#30149;&#25968;&#25454;&#20316;&#20026;&#26696;&#20363;&#30740;&#31350;&#65292;&#27604;&#36739;&#20102;&#20843;&#31181;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#31639;&#27861;&#22312;&#19981;&#21516;&#35757;&#32451;/&#27979;&#35797;&#22330;&#26223;&#19979;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#21457;&#29616;&#26497;&#31471;&#26799;&#24230;&#25552;&#21319;&#21644;&#25903;&#25345;&#21521;&#37327;&#26426;&#22312;&#35757;&#32451;&#19981;&#24179;&#34913;&#25968;&#25454;&#26102;&#23384;&#22312;&#32570;&#38519;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21307;&#30103;&#20445;&#20581;&#20013;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21487;&#33021;&#20250;&#25918;&#22823;&#31038;&#20250;&#19981;&#20844;&#27491;&#21644;&#20581;&#24247;&#19981;&#24179;&#31561;&#12290;&#26412;&#30740;&#31350;&#38024;&#23545;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#31639;&#27861;&#22312;&#24320;&#21457;&#21644;&#37096;&#32626;&#36807;&#31243;&#20013;&#20986;&#29616;&#30340;&#19968;&#20123;&#19968;&#33324;&#21270;&#38556;&#30861;&#65292;&#20351;&#29992;&#24343;&#33713;&#26126;&#27721;&#22982;&#20896;&#24515;&#30149;&#25968;&#25454;&#20316;&#20026;&#26696;&#20363;&#30740;&#31350;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#26377;&#25928;&#22320;&#36873;&#25321;&#27010;&#29575;&#25130;&#26029;&#20197;&#23558;&#22238;&#24402;&#27169;&#22411;&#36716;&#25442;&#20026;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#20843;&#31181;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#31639;&#27861;&#22312;&#22235;&#31181;&#35757;&#32451;/&#27979;&#35797;&#22330;&#26223;&#19979;&#30340;&#39044;&#27979;&#24615;&#33021;&#30340;&#25277;&#26679;&#20998;&#24067;&#65292;&#20197;&#27979;&#35797;&#23427;&#20204;&#30340;&#19968;&#33324;&#21270;&#33021;&#21147;&#21644;&#24310;&#32493;&#20559;&#35265;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#26497;&#31471;&#26799;&#24230;&#25552;&#21319;&#21644;&#25903;&#25345;&#21521;&#37327;&#26426;&#22312;&#35757;&#32451;&#19981;&#24179;&#34913;&#25968;&#25454;&#26102;&#23384;&#22312;&#32570;&#38519;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15005v1 Announce Type: new  Abstract: The use of machine learning algorithms in healthcare can amplify social injustices and health inequities. While the exacerbation of biases can occur and compound during the problem selection, data collection, and outcome definition, this research pertains to some generalizability impediments that occur during the development and the post-deployment of machine learning classification algorithms. Using the Framingham coronary heart disease data as a case study, we show how to effectively select a probability cutoff to convert a regression model for a dichotomous variable into a classifier. We then compare the sampling distribution of the predictive performance of eight machine learning classification algorithms under four training/testing scenarios to test their generalizability and their potential to perpetuate biases. We show that both the Extreme Gradient Boosting, and Support Vector Machine are flawed when trained on an unbalanced data
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20943;&#23569;&#35780;&#20272;LLMs&#24615;&#33021;&#25152;&#38656;&#30340;&#35780;&#20272;&#27425;&#25968;&#30340;&#31574;&#30053;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#23567;&#35268;&#27169;&#31034;&#20363;&#19978;&#21487;&#20197;&#20934;&#30830;&#20272;&#35745;LLMs&#22312;&#22810;&#31181;&#22522;&#20934;&#27979;&#35797;&#19978;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.14992</link><description>&lt;p&gt;
&#23567;&#22411;&#22522;&#20934;&#27979;&#35797;&#65306;&#29992;&#26356;&#23569;&#30340;&#31034;&#20363;&#35780;&#20272;LLM
&lt;/p&gt;
&lt;p&gt;
tinyBenchmarks: evaluating LLMs with fewer examples
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14992
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20943;&#23569;&#35780;&#20272;LLMs&#24615;&#33021;&#25152;&#38656;&#30340;&#35780;&#20272;&#27425;&#25968;&#30340;&#31574;&#30053;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#23567;&#35268;&#27169;&#31034;&#20363;&#19978;&#21487;&#20197;&#20934;&#30830;&#20272;&#35745;LLMs&#22312;&#22810;&#31181;&#22522;&#20934;&#27979;&#35797;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#22810;&#21151;&#33021;&#24615;&#23548;&#33268;&#21019;&#24314;&#20102;&#22810;&#31181;&#22522;&#20934;&#27979;&#35797;&#65292;&#24443;&#24213;&#27979;&#35797;&#21508;&#31181;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;&#36825;&#20123;&#22522;&#20934;&#27979;&#35797;&#21253;&#21547;&#25104;&#21315;&#19978;&#19975;&#20010;&#31034;&#20363;&#65292;&#20351;&#24471;&#35780;&#20272;LLMs&#38750;&#24120;&#26114;&#36149;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20943;&#23569;&#35780;&#20272;LLMs&#24615;&#33021;&#25152;&#38656;&#30340;&#35780;&#20272;&#27425;&#25968;&#30340;&#31574;&#30053;&#12290;&#20363;&#22914;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35201;&#20934;&#30830;&#20272;&#35745;LLMs&#22312;MMLU&#19978;&#30340;&#24615;&#33021;&#65288;&#19968;&#20010;&#21253;&#21547;14K&#20010;&#31034;&#20363;&#30340;&#27969;&#34892;&#22810;&#36873;&#38382;&#31572;&#22522;&#20934;&#27979;&#35797;&#65289;&#65292;&#21482;&#38656;&#35201;&#22312;100&#20010;&#31934;&#24515;&#25361;&#36873;&#30340;&#31034;&#20363;&#19978;&#35780;&#20272;&#36825;&#20010;LLMs&#12290;&#25105;&#20204;&#21457;&#24067;&#20102;&#35780;&#20272;&#24037;&#20855;&#21644;&#27969;&#34892;&#22522;&#20934;&#27979;&#35797;&#30340;&#24494;&#22411;&#29256;&#26412;&#65306;Open LLM Leaderboard&#12289;MMLU&#12289;HELM&#21644;AlpacaEval 2.0&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#20998;&#26512;&#34920;&#26126;&#65292;&#36825;&#20123;&#24037;&#20855;&#21644;&#24494;&#22411;&#22522;&#20934;&#27979;&#35797;&#36275;&#20197;&#21487;&#38752;&#19988;&#39640;&#25928;&#22320;&#37325;&#29616;&#21407;&#22987;&#35780;&#20272;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14992v1 Announce Type: cross  Abstract: The versatility of large language models (LLMs) led to the creation of diverse benchmarks that thoroughly test a variety of language models' abilities. These benchmarks consist of tens of thousands of examples making evaluation of LLMs very expensive. In this paper, we investigate strategies to reduce the number of evaluations needed to assess the performance of an LLM on several key benchmarks. For example, we show that to accurately estimate the performance of an LLM on MMLU, a popular multiple-choice QA benchmark consisting of 14K examples, it is sufficient to evaluate this LLM on 100 curated examples. We release evaluation tools and tiny versions of popular benchmarks: Open LLM Leaderboard, MMLU, HELM, and AlpacaEval 2.0. Our empirical analysis demonstrates that these tools and tiny benchmarks are sufficient to reliably and efficiently reproduce the original evaluation results.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23558;&#21487;&#39564;&#35777;&#23398;&#20064;&#20174;&#22522;&#26412;&#38598;&#25104;&#26041;&#27861;&#25193;&#23637;&#21040;&#39640;&#32423;&#25552;&#21319;&#26641;&#38598;&#25104;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#20266;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#26469;&#39564;&#35777;&#40065;&#26834;&#24615;&#65292;&#23545;&#22522;&#20110;$L_p$-&#33539;&#25968;&#30340;&#25915;&#20987;&#32773;&#20855;&#26377;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.14988</link><description>&lt;p&gt;
&#21487;&#39564;&#35777;&#30340;&#25552;&#21319;&#26641;&#38598;&#25104;
&lt;/p&gt;
&lt;p&gt;
Verifiable Boosted Tree Ensembles
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14988
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#21487;&#39564;&#35777;&#23398;&#20064;&#20174;&#22522;&#26412;&#38598;&#25104;&#26041;&#27861;&#25193;&#23637;&#21040;&#39640;&#32423;&#25552;&#21319;&#26641;&#38598;&#25104;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#20266;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#26469;&#39564;&#35777;&#40065;&#26834;&#24615;&#65292;&#23545;&#22522;&#20110;$L_p$-&#33539;&#25968;&#30340;&#25915;&#20987;&#32773;&#20855;&#26377;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#39564;&#35777;&#23398;&#20064;&#20513;&#23548;&#35757;&#32451;&#26131;&#20110;&#36827;&#34892;&#39640;&#25928;&#23433;&#20840;&#39564;&#35777;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#29305;&#23450;&#31867;&#30340;&#20915;&#31574;&#26641;&#38598;&#25104;&#65292;&#21363;&#31216;&#20026;&#22823;&#24191;&#27867;&#38598;&#25104;&#65292;&#21487;&#20197;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#38024;&#23545;&#20219;&#20309;&#22522;&#20110;&#33539;&#25968;&#30340;&#25915;&#20987;&#32773;&#36827;&#34892;&#40065;&#26834;&#24615;&#39564;&#35777;&#12290;&#26412;&#30740;&#31350;&#23558;&#21487;&#39564;&#35777;&#23398;&#20064;&#20174;&#22522;&#26412;&#38598;&#25104;&#26041;&#27861;&#65288;&#21363;&#30828;&#22810;&#25968;&#25237;&#31080;&#65289;&#25193;&#23637;&#21040;&#39640;&#32423;&#25552;&#21319;&#26641;&#38598;&#25104;&#65292;&#27604;&#22914;&#37027;&#20123;&#20351;&#29992;XGBoost&#25110;LightGBM&#35757;&#32451;&#30340;&#38598;&#25104;&#12290;&#25105;&#20204;&#30340;&#27491;&#24335;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#32771;&#34385;&#22522;&#20110;$L_\infty$-&#33539;&#25968;&#30340;&#25915;&#20987;&#32773;&#26102;&#65292;&#40065;&#26834;&#24615;&#39564;&#35777;&#21487;&#20197;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#23454;&#29616;&#65292;&#20294;&#23545;&#20110;&#20854;&#20182;&#22522;&#20110;&#33539;&#25968;&#30340;&#25915;&#20987;&#32773;&#26469;&#35828;&#20173;&#28982;&#26159;NP&#38590;&#30340;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20266;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#26469;&#39564;&#35777;&#38024;&#23545;&#22522;&#20110;$L_p$-&#33539;&#25968;&#30340;&#25915;&#20987;&#32773;&#30340;&#40065;&#26834;&#24615;&#65292;&#20854;&#20013;$p \in \mathbb{N} \cup \{0\}$&#65292;&#22312;&#23454;&#36341;&#20013;&#20855;&#26377;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35780;&#20272;&#34920;&#26126;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14988v1 Announce Type: new  Abstract: Verifiable learning advocates for training machine learning models amenable to efficient security verification. Prior research demonstrated that specific classes of decision tree ensembles -- called large-spread ensembles -- allow for robustness verification in polynomial time against any norm-based attacker. This study expands prior work on verifiable learning from basic ensemble methods (i.e., hard majority voting) to advanced boosted tree ensembles, such as those trained using XGBoost or LightGBM. Our formal results indicate that robustness verification is achievable in polynomial time when considering attackers based on the $L_\infty$-norm, but remains NP-hard for other norm-based attackers. Nevertheless, we present a pseudo-polynomial time algorithm to verify robustness against attackers based on the $L_p$-norm for any $p \in \mathbb{N} \cup \{0\}$, which in practice grants excellent performance. Our experimental evaluation shows th
&lt;/p&gt;</description></item><item><title>&#22312;&#25968;&#25454;&#26159;&#33391;&#22909;&#25351;&#23450;&#21644;&#24179;&#28369;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#20110;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;ERM&#65289;&#19982;&#24179;&#26041;&#25439;&#22833;&#30340;&#24615;&#33021;&#65292;&#24403;&#31867;&#26159;&#21487;&#20174; iid &#25968;&#25454;&#20013;&#23398;&#20064;&#26102;&#65292;ERM&#33021;&#22815;&#23454;&#29616;&#27425;&#32447;&#24615;&#35823;&#24046;&#12290;</title><link>https://arxiv.org/abs/2402.14987</link><description>&lt;p&gt;
&#22312;&#24179;&#28369;&#25968;&#25454;&#19978;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#24615;&#33021;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Performance of Empirical Risk Minimization with Smoothed Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14987
&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#25454;&#26159;&#33391;&#22909;&#25351;&#23450;&#21644;&#24179;&#28369;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#20110;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;ERM&#65289;&#19982;&#24179;&#26041;&#25439;&#22833;&#30340;&#24615;&#33021;&#65292;&#24403;&#31867;&#26159;&#21487;&#20174; iid &#25968;&#25454;&#20013;&#23398;&#20064;&#26102;&#65292;ERM&#33021;&#22815;&#23454;&#29616;&#27425;&#32447;&#24615;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#36991;&#24320;&#22312;&#24207;&#36143;&#20915;&#31574;&#20013;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#22256;&#38590;&#32467;&#26524;&#65292;&#26368;&#36817;&#30340;&#24037;&#20316;&#32771;&#34385;&#20102;&#24179;&#28369;&#30340;&#22312;&#32447;&#23398;&#20064;&#65292;&#20854;&#20013;&#20551;&#35774;&#27599;&#20010;&#26102;&#38388;&#28857;&#30340;&#25968;&#25454;&#20998;&#24067;&#22312;&#32473;&#23450;&#21382;&#21490;&#26465;&#20214;&#19979;&#30456;&#23545;&#20110;&#22522;&#30784;&#24230;&#37327;&#20855;&#26377;&#26377;&#30028;&#30340;&#20284;&#28982;&#27604;&#12290;&#34429;&#28982;&#20808;&#21069;&#30340;&#24037;&#20316;&#24050;&#32463;&#35777;&#26126;&#20102;&#24179;&#28369;&#24615;&#30340;&#22909;&#22788;&#65292;&#20294;&#23427;&#20204;&#35201;&#20040;&#20551;&#35774;&#22522;&#30784;&#24230;&#37327;&#23545;&#23398;&#20064;&#32773;&#26159;&#24050;&#30693;&#30340;&#65292;&#35201;&#20040;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#29305;&#27530;&#24773;&#20917;&#19979;&#20165;&#36866;&#29992;&#20110;&#35745;&#31639;&#25928;&#29575;&#20302;&#19979;&#12290;&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#26356;&#19968;&#33324;&#30340;&#35774;&#32622;&#65292;&#21363;&#22522;&#30784;&#24230;&#37327;&#23545;&#23398;&#20064;&#32773;&#26159;\emph{&#26410;&#30693;}&#30340;&#24773;&#20917;&#65292;&#29305;&#21035;&#20851;&#27880;&#22312;&#25968;&#25454;&#26126;&#30830;&#23450;&#21644;&#24179;&#28369;&#30340;&#24773;&#20917;&#19979;&#65292;&#24403;&#25968;&#25454;&#26159;&#33391;&#22909;&#25351;&#23450;&#26102;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;ERM&#65289;&#19982;&#24179;&#26041;&#25439;&#22833;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#23637;&#31034;&#65292;&#22312;&#36825;&#31181;&#35774;&#32622;&#19979;&#65292;&#21482;&#35201;&#31867;&#26159;&#21487;&#20174;iid&#25968;&#25454;&#20013;&#23398;&#20064;&#30340;&#65292;ERM&#23601;&#33021;&#22815;&#23454;&#29616;&#27425;&#32447;&#24615;&#35823;&#24046;&#65307;&#29305;&#21035;&#26159;&#65292;&#24403;&#25968;&#25454;&#26159;iid&#26102;&#65292;ERM&#23454;&#29616;&#30340;&#38169;&#35823;&#23610;&#24230;&#20026;$\tilde O(
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14987v1 Announce Type: cross  Abstract: In order to circumvent statistical and computational hardness results in sequential decision-making, recent work has considered smoothed online learning, where the distribution of data at each time is assumed to have bounded likeliehood ratio with respect to a base measure when conditioned on the history. While previous works have demonstrated the benefits of smoothness, they have either assumed that the base measure is known to the learner or have presented computationally inefficient algorithms applying only in special cases. This work investigates the more general setting where the base measure is \emph{unknown} to the learner, focusing in particular on the performance of Empirical Risk Minimization (ERM) with square loss when the data are well-specified and smooth. We show that in this setting, ERM is able to achieve sublinear error whenever a class is learnable with iid data; in particular, ERM achieves error scaling as $\tilde O(
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20998;&#25968;&#25289;&#26222;&#25289;&#26031;&#29305;&#24449;&#26144;&#23556;&#65292;&#24320;&#21457;&#20102;&#38024;&#23545;&#30495;&#23454;&#22238;&#24402;&#20989;&#25968;&#38750;&#20809;&#28369;&#24773;&#20917;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#26041;&#27861;&#65292;&#25104;&#21151;&#22788;&#29702;&#20102;&#35813;&#20989;&#25968;&#31867;&#22312;$L_2$-&#20998;&#25968; Sobolev &#31354;&#38388;&#20013;&#30340;&#29305;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#35823;&#24046;&#19978;&#30028;&#20026;$n^{-\frac{2s}{2s+d}}$&#12290;</title><link>https://arxiv.org/abs/2402.14985</link><description>&lt;p&gt;
&#36890;&#36807;&#20998;&#25968;&#25289;&#26222;&#25289;&#26031;&#29305;&#24449;&#26144;&#23556;&#36827;&#34892;&#38750;&#20809;&#28369;&#38750;&#21442;&#25968;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Nonsmooth Nonparametric Regression via Fractional Laplacian Eigenmaps
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14985
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20998;&#25968;&#25289;&#26222;&#25289;&#26031;&#29305;&#24449;&#26144;&#23556;&#65292;&#24320;&#21457;&#20102;&#38024;&#23545;&#30495;&#23454;&#22238;&#24402;&#20989;&#25968;&#38750;&#20809;&#28369;&#24773;&#20917;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#26041;&#27861;&#65292;&#25104;&#21151;&#22788;&#29702;&#20102;&#35813;&#20989;&#25968;&#31867;&#22312;$L_2$-&#20998;&#25968; Sobolev &#31354;&#38388;&#20013;&#30340;&#29305;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#35823;&#24046;&#19978;&#30028;&#20026;$n^{-\frac{2s}{2s+d}}$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20026;&#30495;&#23454;&#22238;&#24402;&#20989;&#25968;&#19981;&#19968;&#23450;&#24179;&#28369;&#30340;&#24773;&#20917;&#24320;&#21457;&#20102;&#38750;&#21442;&#25968;&#22238;&#24402;&#26041;&#27861;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#29992;&#20102;&#20998;&#25968;&#25289;&#26222;&#25289;&#26031;&#65292;&#24182;&#26088;&#22312;&#22788;&#29702;&#30495;&#23454;&#22238;&#24402;&#20989;&#25968;&#20301;&#20110;$L_2$-&#20998;&#25968; Sobolev &#31354;&#38388;&#65288;&#38454;&#25968;&#20026;$s\in (0,1)$&#65289;&#30340;&#24773;&#20917;&#12290;&#35813;&#20989;&#25968;&#31867;&#26159;&#19968;&#20010; Hilbert &#31354;&#38388;&#65292;&#20301;&#20110;&#24179;&#26041;&#21487;&#31215;&#20989;&#25968;&#31354;&#38388;&#21644;&#19968;&#38454; Sobolev &#31354;&#38388;&#20043;&#38388;&#65292;&#21253;&#25324;&#20998;&#25968;&#24130;&#20989;&#25968;&#12289;&#20998;&#27573;&#24120;&#25968;&#25110;&#22810;&#39033;&#24335;&#20989;&#25968;&#20197;&#21450;&#23574;&#23792;&#20989;&#25968;&#20316;&#20026;&#20856;&#22411;&#31034;&#20363;&#12290;&#23545;&#20110;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20851;&#20110;&#26679;&#26412;&#20869;&#22343;&#26041;&#20272;&#35745;&#35823;&#24046;&#30340;&#19978;&#30028;&#65292;&#20855;&#26377;$n^{-\frac{2s}{2s+d}}$&#30340;&#38454;&#65292;&#20854;&#20013;$d$&#26159;&#32500;&#25968;&#65292;$s$&#26159;&#21069;&#36848;&#39034;&#24207;&#21442;&#25968;&#65292;$n$&#26159;&#35266;&#27979;&#25968;&#37327;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#21021;&#27493;&#30340;&#23454;&#35777;&#32467;&#26524;&#65292;&#39564;&#35777;&#20102;&#25152;&#24320;&#21457;&#26041;&#27861;&#30340;&#23454;&#38469;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14985v1 Announce Type: cross  Abstract: We develop nonparametric regression methods for the case when the true regression function is not necessarily smooth. More specifically, our approach is using the fractional Laplacian and is designed to handle the case when the true regression function lies in an $L_2$-fractional Sobolev space with order $s\in (0,1)$. This function class is a Hilbert space lying between the space of square-integrable functions and the first-order Sobolev space consisting of differentiable functions. It contains fractional power functions, piecewise constant or polynomial functions and bump function as canonical examples. For the proposed approach, we prove upper bounds on the in-sample mean-squared estimation error of order $n^{-\frac{2s}{2s+d}}$, where $d$ is the dimension, $s$ is the aforementioned order parameter and $n$ is the number of observations. We also provide preliminary empirical results validating the practical performance of the developed
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#27604;&#36739;&#20102;&#25968;&#25454;&#39044;&#22788;&#29702;&#12289;&#29305;&#24449;&#36873;&#25321;&#21644;&#27169;&#22411;&#36873;&#25321;&#23545;&#35757;&#32451;&#36951;&#20256;&#25968;&#25454;&#38598;&#19978;&#27169;&#22411;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#24322;&#24120;&#20540;&#21644;&#20542;&#26012;&#20250;&#24433;&#21709;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.14980</link><description>&lt;p&gt;
&#25968;&#25454;&#39044;&#22788;&#29702;&#26041;&#27861;&#12289;&#29305;&#24449;&#36873;&#25321;&#25216;&#26415;&#21644;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#19981;&#24179;&#34913;&#36951;&#20256;&#25968;&#25454;&#19978;&#25552;&#39640;&#20998;&#31867;&#21644;&#22238;&#24402;&#24615;&#33021;&#30340;&#27604;&#36739;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Comparative Analysis of Data Preprocessing Methods, Feature Selection Techniques and Machine Learning Models for Improved Classification and Regression Performance on Imbalanced Genetic Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14980
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#27604;&#36739;&#20102;&#25968;&#25454;&#39044;&#22788;&#29702;&#12289;&#29305;&#24449;&#36873;&#25321;&#21644;&#27169;&#22411;&#36873;&#25321;&#23545;&#35757;&#32451;&#36951;&#20256;&#25968;&#25454;&#38598;&#19978;&#27169;&#22411;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#24322;&#24120;&#20540;&#21644;&#20542;&#26012;&#20250;&#24433;&#21709;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#22240;&#32452;&#27979;&#24207;&#25216;&#26415;&#30340;&#24555;&#36895;&#21457;&#23637;&#23548;&#33268;&#20102;&#22823;&#37327;&#22522;&#22240;&#32452;&#25968;&#25454;&#30340;&#25910;&#38598;&#12290;&#30740;&#31350;&#20154;&#21592;&#21487;&#33021;&#26377;&#20852;&#36259;&#22312;&#36825;&#20123;&#25968;&#25454;&#19978;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26469;&#39044;&#27979;&#22522;&#22240;&#31361;&#21464;&#30340;&#33268;&#30149;&#24615;&#25110;&#20020;&#24202;&#24847;&#20041;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#36951;&#20256;&#25968;&#25454;&#38598;&#21253;&#21547;&#19981;&#24179;&#34913;&#30340;&#30446;&#26631;&#21464;&#37327;&#65292;&#36825;&#32473;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#24102;&#26469;&#25361;&#25112;&#65306;&#22312;&#22238;&#24402;&#20219;&#21153;&#20013;&#35266;&#23519;&#32467;&#26524;&#20542;&#26012;/&#19981;&#24179;&#34913;&#65292;&#22312;&#20998;&#31867;&#20219;&#21153;&#20013;&#31867;&#21035;&#19981;&#24179;&#34913;&#12290;&#36951;&#20256;&#25968;&#25454;&#38598;&#36890;&#24120;&#20855;&#26377;&#39640;&#22522;&#25968;&#21644;&#20542;&#26012;&#30340;&#39044;&#27979;&#21464;&#37327;&#65292;&#36825;&#36827;&#19968;&#27493;&#22686;&#21152;&#20102;&#25361;&#25112;&#12290;&#25105;&#20204;&#26088;&#22312;&#30740;&#31350;&#25968;&#25454;&#39044;&#22788;&#29702;&#12289;&#29305;&#24449;&#36873;&#25321;&#25216;&#26415;&#21644;&#27169;&#22411;&#36873;&#25321;&#23545;&#35757;&#32451;&#22312;&#36825;&#20123;&#25968;&#25454;&#38598;&#19978;&#30340;&#27169;&#22411;&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#20351;&#29992;5&#25240;&#20132;&#21449;&#39564;&#35777;&#27979;&#37327;&#24615;&#33021;&#65292;&#24182;&#27604;&#36739;&#19981;&#21516;&#25216;&#26415;&#32452;&#21512;&#19979;&#30340;&#24179;&#22343;r&#24179;&#26041;&#21644;&#20934;&#30830;&#29575;&#25351;&#26631;&#12290;&#25105;&#20204;&#21457;&#29616;&#39044;&#27979;&#21464;&#37327;&#25110;&#30446;&#26631;&#21464;&#37327;&#20013;&#30340;&#24322;&#24120;&#20540;/&#20542;&#26012;&#20250;&#23545;&#27169;&#22411;&#30340;&#24615;&#33021;&#20135;&#29983;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14980v1 Announce Type: cross  Abstract: Rapid advancements in genome sequencing have led to the collection of vast amounts of genomics data. Researchers may be interested in using machine learning models on such data to predict the pathogenicity or clinical significance of a genetic mutation. However, many genetic datasets contain imbalanced target variables that pose challenges to machine learning models: observations are skewed/imbalanced in regression tasks or class-imbalanced in classification tasks. Genetic datasets are also often high-cardinal and contain skewed predictor variables, which poses further challenges. We aimed to investigate the effects of data preprocessing, feature selection techniques, and model selection on the performance of models trained on these datasets. We measured performance with 5-fold cross-validation and compared averaged r-squared and accuracy metrics across different combinations of techniques. We found that outliers/skew in predictor or t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20809;&#28369;&#33258;&#36866;&#24212;&#36801;&#31227;&#23398;&#20064;&#65288;SATL&#65289;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#20004;&#20010;&#38454;&#27573;&#22343;&#37319;&#29992;&#39640;&#26031;&#26680;&#65292;&#20351;&#20272;&#35745;&#22120;&#33021;&#22815;&#36866;&#24212;&#30446;&#26631;/&#28304;&#21450;&#20854;&#20559;&#31227;&#20989;&#25968;&#30340;&#26410;&#30693;&#20809;&#28369;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.14966</link><description>&lt;p&gt;
&#20809;&#28369;&#33258;&#36866;&#24212;&#20551;&#35774;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Smoothness Adaptive Hypothesis Transfer Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14966
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20809;&#28369;&#33258;&#36866;&#24212;&#36801;&#31227;&#23398;&#20064;&#65288;SATL&#65289;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#20004;&#20010;&#38454;&#27573;&#22343;&#37319;&#29992;&#39640;&#26031;&#26680;&#65292;&#20351;&#20272;&#35745;&#22120;&#33021;&#22815;&#36866;&#24212;&#30446;&#26631;/&#28304;&#21450;&#20854;&#20559;&#31227;&#20989;&#25968;&#30340;&#26410;&#30693;&#20809;&#28369;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#29616;&#26377;&#30340;&#22522;&#20110;&#26680;&#30340;&#20004;&#38454;&#27573;&#20551;&#35774;&#36801;&#31227;&#23398;&#20064;&#31639;&#27861;&#22312;&#19981;&#21516;&#38454;&#27573;&#22343;&#37319;&#29992;&#30456;&#21516;&#30340;&#26680;&#27491;&#21017;&#21270;&#65292;&#24182;&#20381;&#36182;&#20110;&#20989;&#25968;&#30340;&#24050;&#30693;&#20809;&#28369;&#24615;&#26469;&#23454;&#29616;&#26368;&#20248;&#24615;&#12290;&#22240;&#27492;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#23427;&#20204;&#26410;&#33021;&#36866;&#24212;&#30446;&#26631;/&#28304;&#21450;&#20854;&#20559;&#31227;&#20043;&#38388;&#30340;&#21464;&#21270;&#21644;&#26410;&#30693;&#20809;&#28369;&#24615;&#12290;&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#20809;&#28369;&#33258;&#36866;&#24212;&#36801;&#31227;&#23398;&#20064;&#65288;SATL&#65289;&#65292;&#19968;&#20010;&#22522;&#20110;&#20004;&#38454;&#27573;&#26680;&#23725;&#22238;&#24402;&#65288;KRR&#65289;&#30340;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#36825;&#20123;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#65292;&#22312;&#30446;&#26631;&#19987;&#29992;KRR&#23398;&#20064;&#20013;&#37319;&#29992;&#38169;&#35823;&#25351;&#23450;&#30340;&#22266;&#23450;&#24102;&#23485;&#39640;&#26031;&#26680;&#21487;&#20197;&#23454;&#29616;&#26497;&#23567;&#21270;&#26368;&#20248;&#24615;&#65292;&#24182;&#25512;&#23548;&#20986;&#19968;&#31181;&#36866;&#24212;&#26410;&#30693;Sobolev&#20809;&#28369;&#24615;&#30340;&#33258;&#36866;&#24212;&#36807;&#31243;&#12290;&#21033;&#29992;&#36825;&#20123;&#32467;&#26524;&#65292;SATL&#22312;&#20004;&#38454;&#27573;&#22343;&#37319;&#29992;&#39640;&#26031;&#26680;&#65292;&#20197;&#20351;&#20272;&#35745;&#37327;&#33021;&#22815;&#36866;&#24212;&#30446;&#26631;/&#28304;&#21450;&#20854;&#20559;&#31227;&#20989;&#25968;&#30340;&#26410;&#30693;&#20809;&#28369;&#24615;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#23398;&#20064;&#38382;&#39064;&#22312;&#36807;&#37327;&#39118;&#38505;&#20013;&#30340;&#26497;&#23567;&#20540;&#19979;&#38480;&#65292;&#24182;&#34920;&#26126;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14966v1 Announce Type: cross  Abstract: Many existing two-phase kernel-based hypothesis transfer learning algorithms employ the same kernel regularization across phases and rely on the known smoothness of functions to obtain optimality. Therefore, they fail to adapt to the varying and unknown smoothness between the target/source and their offset in practice. In this paper, we address these problems by proposing Smoothness Adaptive Transfer Learning (SATL), a two-phase kernel ridge regression(KRR)-based algorithm. We first prove that employing the misspecified fixed bandwidth Gaussian kernel in target-only KRR learning can achieve minimax optimality and derive an adaptive procedure to the unknown Sobolev smoothness. Leveraging these results, SATL employs Gaussian kernels in both phases so that the estimators can adapt to the unknown smoothness of the target/source and their offset function. We derive the minimax lower bound of the learning problem in excess risk and show that
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#38454;&#27573;&#22240;&#26524;&#26694;&#26550;&#65292;&#34701;&#20837;&#29359;&#32618;&#34892;&#20026;&#65292;&#29992;&#20110;&#35780;&#20272;&#25191;&#27861;&#31995;&#32479;&#20013;&#30340;&#31181;&#26063;&#20559;&#35265;&#65292;&#20197;&#35299;&#20915;&#20197;&#24448;&#30740;&#31350;&#20013;&#23384;&#22312;&#30340;&#38480;&#21046;&#65292;&#23545;&#20559;&#35265;&#36827;&#34892;&#37327;&#21270;&#65292;&#24182;&#30830;&#23450;&#20027;&#35201;&#20559;&#35265;&#26469;&#28304;&#12290;</title><link>https://arxiv.org/abs/2402.14959</link><description>&lt;p&gt;
&#35780;&#20272;&#25191;&#27861;&#31995;&#32479;&#20013;&#31181;&#26063;&#20559;&#35265;&#30340;&#22240;&#26524;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Causal Framework to Evaluate Racial Bias in Law Enforcement Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14959
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#38454;&#27573;&#22240;&#26524;&#26694;&#26550;&#65292;&#34701;&#20837;&#29359;&#32618;&#34892;&#20026;&#65292;&#29992;&#20110;&#35780;&#20272;&#25191;&#27861;&#31995;&#32479;&#20013;&#30340;&#31181;&#26063;&#20559;&#35265;&#65292;&#20197;&#35299;&#20915;&#20197;&#24448;&#30740;&#31350;&#20013;&#23384;&#22312;&#30340;&#38480;&#21046;&#65292;&#23545;&#20559;&#35265;&#36827;&#34892;&#37327;&#21270;&#65292;&#24182;&#30830;&#23450;&#20027;&#35201;&#20559;&#35265;&#26469;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#33268;&#21147;&#20110;&#24320;&#21457;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#26469;&#35780;&#20272;&#25191;&#27861;&#31995;&#32479;&#20013;&#31181;&#26063;&#35825;&#21457;&#30340;&#20559;&#35265;&#12290; &#22312;&#26368;&#36817;&#30340;&#30740;&#31350;&#20013;&#65292;&#24050;&#32463;&#35752;&#35770;&#20102;&#22312;&#35686;&#27665;&#20114;&#21160;&#32972;&#26223;&#19979;&#20351;&#29992;&#35686;&#23519;&#20572;&#36710;&#25968;&#25454;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#23384;&#22312;&#20004;&#20010;&#20851;&#38190;&#38480;&#21046;&#12290; &#39318;&#20808;&#65292;&#21482;&#26377;&#22312;&#23558;&#30495;&#23454;&#29359;&#32618;&#34892;&#20026;&#32771;&#34385;&#22312;&#20869;&#26102;&#65292;&#20559;&#35265;&#25165;&#33021;&#24471;&#21040;&#24688;&#24403;&#37327;&#21270;&#65292;&#20294;&#22312;&#20197;&#21069;&#30340;&#30740;&#31350;&#20013;&#32570;&#20047;&#12290; &#31532;&#20108;&#65292;&#25191;&#27861;&#31995;&#32479;&#26159;&#22810;&#38454;&#27573;&#30340;&#65292;&#22240;&#27492;&#37325;&#35201;&#30340;&#26159;&#22312;&#8220;&#22240;&#26524;&#20132;&#20114;&#38142;&#8221;&#20013;&#23396;&#31435;&#20986;&#20559;&#35265;&#30340;&#30495;&#27491;&#26469;&#28304;&#65292;&#32780;&#19981;&#20165;&#20165;&#20851;&#27880;&#26368;&#32456;&#32467;&#26524;&#65307; &#36825;&#26377;&#21161;&#20110;&#24341;&#23548;&#25913;&#38761;&#12290; &#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#19968;&#20010;&#21253;&#21547;&#29359;&#32618;&#34892;&#20026;&#30340;&#22810;&#38454;&#27573;&#22240;&#26524;&#26694;&#26550;&#26469;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#12290; &#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#29305;&#24449;&#21644;&#19968;&#20010;&#30456;&#20851;&#30340;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#26469;&#35780;&#20272;(a)&#20219;&#20309;&#24418;&#24335;&#30340;&#31181;&#26063;&#20559;&#35265;&#30340;&#23384;&#22312;&#65292;&#20197;&#21450;(b)&#22914;&#26524;&#26159;&#36825;&#26679;&#65292;&#36825;&#31181;&#20559;&#35265;&#30340;&#20027;&#35201;&#26469;&#28304;&#26159;&#31181;&#26063;&#21644;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14959v1 Announce Type: cross  Abstract: We are interested in developing a data-driven method to evaluate race-induced biases in law enforcement systems. While the recent works have addressed this question in the context of police-civilian interactions using police stop data, they have two key limitations. First, bias can only be properly quantified if true criminality is accounted for in addition to race, but it is absent in prior works. Second, law enforcement systems are multi-stage and hence it is important to isolate the true source of bias within the "causal chain of interactions" rather than simply focusing on the end outcome; this can help guide reforms. In this work, we address these challenges by presenting a multi-stage causal framework incorporating criminality. We provide a theoretical characterization and an associated data-driven method to evaluate (a) the presence of any form of racial bias, and (b) if so, the primary source of such a bias in terms of race and
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#32467;&#21512;&#32447;&#24615;&#27880;&#24847;&#21147;&#21644;&#32447;&#24615;MLP&#32452;&#20214;&#30340;&#32447;&#24615;Transformer&#22359;&#22312;&#19978;&#19979;&#25991;&#23398;&#20064;&#20013;&#30340;&#24615;&#33021;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#32447;&#24615;&#22238;&#24402;&#20219;&#21153;&#20013;&#20960;&#20046;&#21487;&#20197;&#36798;&#21040;&#36125;&#21494;&#26031;&#26368;&#20248;&#39118;&#38505;&#65292;&#24182;&#19988;&#19982;&#19968;&#27493;&#26799;&#24230;&#19979;&#38477;&#20272;&#35745;&#22120;&#26377;&#23545;&#24212;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2402.14951</link><description>&lt;p&gt;
&#19968;&#20010;&#32447;&#24615;Transformer&#22359;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#65306;MLP&#32452;&#20214;&#21644;&#19968;&#27493;GD&#21021;&#22987;&#21270;&#30340;&#20248;&#21183;
&lt;/p&gt;
&lt;p&gt;
In-Context Learning of a Linear Transformer Block: Benefits of the MLP Component and One-Step GD Initialization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14951
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#32467;&#21512;&#32447;&#24615;&#27880;&#24847;&#21147;&#21644;&#32447;&#24615;MLP&#32452;&#20214;&#30340;&#32447;&#24615;Transformer&#22359;&#22312;&#19978;&#19979;&#25991;&#23398;&#20064;&#20013;&#30340;&#24615;&#33021;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#32447;&#24615;&#22238;&#24402;&#20219;&#21153;&#20013;&#20960;&#20046;&#21487;&#20197;&#36798;&#21040;&#36125;&#21494;&#26031;&#26368;&#20248;&#39118;&#38505;&#65292;&#24182;&#19988;&#19982;&#19968;&#27493;&#26799;&#24230;&#19979;&#38477;&#20272;&#35745;&#22120;&#26377;&#23545;&#24212;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#32467;&#21512;&#32447;&#24615;&#27880;&#24847;&#21147;&#32452;&#20214;&#21644;&#32447;&#24615;&#22810;&#23618;&#24863;&#30693;&#22120;&#65288;MLP&#65289;&#32452;&#20214;&#30340;&#32447;&#24615;Transformer&#22359;&#65288;LTB&#65289;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#65288;ICL&#65289;&#33021;&#21147;&#12290;&#23545;&#20110;&#20855;&#26377;&#39640;&#26031;&#20808;&#39564;&#21644;&#38750;&#38646;&#22343;&#20540;&#30340;&#32447;&#24615;&#22238;&#24402;&#30340;ICL&#65292;&#25105;&#20204;&#34920;&#26126;LTB&#21487;&#20197;&#23454;&#29616;&#20960;&#20046;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;ICL&#39118;&#38505;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#20165;&#20351;&#29992;&#32447;&#24615;&#27880;&#24847;&#21147;&#24517;&#39035;&#20135;&#29983;&#19981;&#21487;&#36991;&#20813;&#30340;&#38468;&#21152;&#36817;&#20284;&#35823;&#24046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;LTB&#19982;&#20855;&#26377;&#21487;&#23398;&#20064;&#21021;&#22987;&#21270;&#30340;&#19968;&#27493;&#26799;&#24230;&#19979;&#38477;&#20272;&#35745;&#22120;&#65288;$\mathsf{GD}-\mathbf{\beta}$&#65289;&#20043;&#38388;&#30340;&#23545;&#24212;&#20851;&#31995;&#65292;&#20174;&#27599;&#20010;$\mathsf{GD}-\mathbf{\beta}$&#20272;&#35745;&#22120;&#21487;&#20197;&#36890;&#36807;LTB&#20272;&#35745;&#22120;&#23454;&#29616;&#65292;&#21040;&#26368;&#23567;&#21270;&#31867;&#20869;ICL&#39118;&#38505;&#30340;&#27599;&#20010;&#26368;&#20248;LTB&#20272;&#35745;&#22120;&#23454;&#38469;&#19978;&#26159;&#19968;&#20010;$\mathsf{GD}-\mathbf{\beta}$&#20272;&#35745;&#22120;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#34920;&#26126;$\mathsf{GD}-\mathbf{\beta}$&#20272;&#35745;&#22120;&#21487;&#20197;&#36890;&#36807;&#26799;&#24230;&#20248;&#21270;&#39640;&#25928;&#22320;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14951v1 Announce Type: cross  Abstract: We study the \emph{in-context learning} (ICL) ability of a \emph{Linear Transformer Block} (LTB) that combines a linear attention component and a linear multi-layer perceptron (MLP) component. For ICL of linear regression with a Gaussian prior and a \emph{non-zero mean}, we show that LTB can achieve nearly Bayes optimal ICL risk. In contrast, using only linear attention must incur an irreducible additive approximation error. Furthermore, we establish a correspondence between LTB and one-step gradient descent estimators with learnable initialization ($\mathsf{GD}\text{-}\mathbf{\beta}$), in the sense that every $\mathsf{GD}\text{-}\mathbf{\beta}$ estimator can be implemented by an LTB estimator and every optimal LTB estimator that minimizes the in-class ICL risk is effectively a $\mathsf{GD}\text{-}\mathbf{\beta}$ estimator. Finally, we show that $\mathsf{GD}\text{-}\mathbf{\beta}$ estimators can be efficiently optimized with gradient f
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#20923;&#32467;&#38543;&#26426;&#23376;&#38598;&#30340;&#21021;&#22987;&#26435;&#37325;&#26469;&#20943;&#23569;&#24378;&#22823;&#30340;&#24425;&#31080;&#31080;&#35777;&#65288;SLT&#65289;&#25628;&#32034;&#31354;&#38388;&#65292;&#20174;&#32780;&#29420;&#31435;&#20110;&#25152;&#38656;SLT&#31232;&#30095;&#24615;&#38477;&#20302;&#20102;SLT&#25628;&#32034;&#31354;&#38388;&#65292;&#20445;&#35777;&#20102;SLT&#22312;&#36825;&#31181;&#20943;&#23569;&#25628;&#32034;&#31354;&#38388;&#20013;&#30340;&#23384;&#22312;&#12290;</title><link>https://arxiv.org/abs/2402.14029</link><description>&lt;p&gt;
&#20923;&#32467;&#32593;&#32476;&#20013;&#30340;&#37096;&#20998;&#25628;&#32034;&#36275;&#20197;&#25214;&#21040;&#24378;&#22823;&#30340;&#24425;&#31080;&#31080;&#35777;
&lt;/p&gt;
&lt;p&gt;
Partial Search in a Frozen Network is Enough to Find a Strong Lottery Ticket
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14029
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#20923;&#32467;&#38543;&#26426;&#23376;&#38598;&#30340;&#21021;&#22987;&#26435;&#37325;&#26469;&#20943;&#23569;&#24378;&#22823;&#30340;&#24425;&#31080;&#31080;&#35777;&#65288;SLT&#65289;&#25628;&#32034;&#31354;&#38388;&#65292;&#20174;&#32780;&#29420;&#31435;&#20110;&#25152;&#38656;SLT&#31232;&#30095;&#24615;&#38477;&#20302;&#20102;SLT&#25628;&#32034;&#31354;&#38388;&#65292;&#20445;&#35777;&#20102;SLT&#22312;&#36825;&#31181;&#20943;&#23569;&#25628;&#32034;&#31354;&#38388;&#20013;&#30340;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14029v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#36328;&#36234; &#25688;&#35201;&#65306;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#31264;&#23494;&#32593;&#32476;&#21253;&#21547;&#21487;&#20197;&#22312;&#19981;&#36827;&#34892;&#26435;&#37325;&#23398;&#20064;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#39640;&#20934;&#30830;&#24230;&#30340;&#23376;&#32593;&#32476;--&#24378;&#22823;&#30340;&#24425;&#31080;&#31080;&#35777;&#65288;SLTs&#65289;&#12290;&#26368;&#36817;&#65292;Gadhikar&#31561;&#20154;&#65288;2023&#24180;&#65289;&#22312;&#29702;&#35770;&#21644;&#23454;&#39564;&#35777;&#26126;&#65292;SLTs&#20063;&#21487;&#20197;&#22312;&#38543;&#26426;&#20462;&#21098;&#30340;&#28304;&#32593;&#32476;&#20013;&#25214;&#21040;&#65292;&#20174;&#32780;&#20943;&#23569;SLT&#30340;&#25628;&#32034;&#31354;&#38388;&#12290;&#28982;&#32780;&#65292;&#36825;&#38480;&#21046;&#20102;&#23545;&#29978;&#33267;&#27604;&#28304;&#32593;&#32476;&#26356;&#31232;&#30095;&#30340;SLTs&#30340;&#25628;&#32034;&#65292;&#23548;&#33268;&#30001;&#20110;&#24847;&#22806;&#30340;&#39640;&#31232;&#30095;&#24615;&#32780;&#20934;&#30830;&#24230;&#36739;&#24046;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#29420;&#31435;&#20110;&#25152;&#38656;SLT&#31232;&#30095;&#24615;&#30340;&#20219;&#24847;&#27604;&#29575;&#20943;&#23569;SLT&#25628;&#32034;&#31354;&#38388;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20923;&#32467;&#19968;&#37096;&#20998;&#21021;&#22987;&#26435;&#37325;&#30340;&#38543;&#26426;&#23376;&#38598;&#65292;&#23558;&#20854;&#25490;&#38500;&#22312;&#25628;&#32034;&#31354;&#38388;&#20043;&#22806;--&#21363;&#65292;&#36890;&#36807;&#27704;&#20037;&#20462;&#21098;&#23427;&#20204;&#25110;&#23558;&#23427;&#20204;&#38145;&#23450;&#20026;SLT&#30340;&#22266;&#23450;&#37096;&#20998;&#12290;&#20107;&#23454;&#19978;&#65292;&#36890;&#36807;&#25105;&#20204;&#19982;&#38543;&#26426;&#20923;&#32467;&#21464;&#37327;&#30340;&#23376;&#38598;&#21644;&#36924;&#36817;&#65292;&#22312;&#36825;&#31181;&#20943;&#23569;&#30340;&#25628;&#32034;&#31354;&#38388;&#20013;&#65292;SLT&#30340;&#23384;&#22312;&#22312;&#29702;&#35770;&#19978;&#26159;&#24471;&#21040;&#20445;&#35777;&#30340;&#12290;&#38500;&#27492;&#20043;&#22806;&#65292;&#36824;&#21487;&#20197;&#20943;&#23569;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14029v1 Announce Type: cross  Abstract: Randomly initialized dense networks contain subnetworks that achieve high accuracy without weight learning -- strong lottery tickets (SLTs). Recently, Gadhikar et al. (2023) demonstrated theoretically and experimentally that SLTs can also be found within a randomly pruned source network, thus reducing the SLT search space. However, this limits the search to SLTs that are even sparser than the source, leading to worse accuracy due to unintentionally high sparsity. This paper proposes a method that reduces the SLT search space by an arbitrary ratio that is independent of the desired SLT sparsity. A random subset of the initial weights is excluded from the search space by freezing it -- i.e., by either permanently pruning them or locking them as a fixed part of the SLT. Indeed, the SLT existence in such a reduced search space is theoretically guaranteed by our subset-sum approximation with randomly frozen variables. In addition to reducin
&lt;/p&gt;</description></item><item><title>&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#23398;&#20064;&#19968;&#20010;&#23376;&#39640;&#26031;&#27010;&#29575;&#20998;&#24067;&#26063;&#20013;&#31361;&#30772;&#20102;&#32500;&#25968;&#28798;&#38590;&#65292;&#36890;&#36807;&#20998;&#25968;&#21305;&#37197;&#29983;&#25104;&#30340;&#20998;&#24067;&#20197;&#32500;&#24230;&#26080;&#20851;&#30340;&#36895;&#29575;&#36924;&#36817;&#30446;&#26631;&#20998;&#24067;&#30340;&#24635;&#21464;&#24046;&#12290;</title><link>https://arxiv.org/abs/2402.08082</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#23398;&#20064;&#19968;&#20010;&#23376;&#39640;&#26031;&#27010;&#29575;&#20998;&#24067;&#26063;&#20013;&#31361;&#30772;&#20102;&#32500;&#25968;&#28798;&#38590;
&lt;/p&gt;
&lt;p&gt;
Score-based generative models break the curse of dimensionality in learning a family of sub-Gaussian probability distributions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08082
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#23398;&#20064;&#19968;&#20010;&#23376;&#39640;&#26031;&#27010;&#29575;&#20998;&#24067;&#26063;&#20013;&#31361;&#30772;&#20102;&#32500;&#25968;&#28798;&#38590;&#65292;&#36890;&#36807;&#20998;&#25968;&#21305;&#37197;&#29983;&#25104;&#30340;&#20998;&#24067;&#20197;&#32500;&#24230;&#26080;&#20851;&#30340;&#36895;&#29575;&#36924;&#36817;&#30446;&#26631;&#20998;&#24067;&#30340;&#24635;&#21464;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;SGMs&#65289;&#22312;&#24040;&#22823;&#30340;&#22270;&#20687;&#29983;&#25104;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#65292;&#20294;&#23427;&#20204;&#30340;&#25968;&#23398;&#22522;&#30784;&#20173;&#28982;&#26377;&#38480;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;SGMs&#22312;&#23398;&#20064;&#19968;&#20010;&#23376;&#39640;&#26031;&#27010;&#29575;&#20998;&#24067;&#26063;&#20013;&#30340;&#36817;&#20284;&#21644;&#27867;&#21270;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#20851;&#20110;&#27010;&#29575;&#20998;&#24067;&#22797;&#26434;&#24615;&#30340;&#27010;&#24565;&#65292;&#21363;&#30456;&#23545;&#23494;&#24230;&#19982;&#26631;&#20934;&#39640;&#26031;&#27979;&#24230;&#30340;&#30456;&#23545;&#23494;&#24230;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22914;&#26524;&#23545;&#25968;&#30456;&#23545;&#23494;&#24230;&#21487;&#20197;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#23616;&#37096;&#36924;&#36817;&#65292;&#24182;&#19988;&#32593;&#32476;&#21442;&#25968;&#21487;&#20197;&#36866;&#24403;&#22320;&#21463;&#38480;&#65292;&#37027;&#20040;&#36890;&#36807;&#32463;&#39564;&#20998;&#25968;&#21305;&#37197;&#29983;&#25104;&#30340;&#20998;&#24067;&#20197;&#32500;&#24230;&#26080;&#20851;&#30340;&#36895;&#29575;&#36924;&#36817;&#30446;&#26631;&#20998;&#24067;&#30340;&#24635;&#21464;&#24046;&#12290;&#25105;&#20204;&#36890;&#36807;&#31034;&#20363;&#35828;&#26126;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#20854;&#20013;&#21253;&#25324;&#26576;&#20123;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#12290;&#25105;&#20204;&#35777;&#26126;&#30340;&#19968;&#20010;&#20851;&#38190;&#28857;&#26159;&#25512;&#23548;&#20986;&#19982;&#27491;&#21521;&#36807;&#31243;&#30456;&#20851;&#30340;&#30495;&#23454;&#24471;&#20998;&#20989;&#25968;&#30340;&#32500;&#24230;&#26080;&#20851;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
While score-based generative models (SGMs) have achieved remarkable success in enormous image generation tasks, their mathematical foundations are still limited. In this paper, we analyze the approximation and generalization of SGMs in learning a family of sub-Gaussian probability distributions. We introduce a notion of complexity for probability distributions in terms of their relative density with respect to the standard Gaussian measure. We prove that if the log-relative density can be locally approximated by a neural network whose parameters can be suitably bounded, then the distribution generated by empirical score matching approximates the target distribution in total variation with a dimension-independent rate. We illustrate our theory through examples, which include certain mixtures of Gaussians. An essential ingredient of our proof is to derive a dimension-free deep neural network approximation rate for the true score function associated with the forward process, which is inte
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#22312;&#19981;&#35268;&#21017;&#38388;&#38548;&#25968;&#25454;&#19978;&#30340;&#25554;&#20540;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22312;&#25968;&#25454;&#28857;&#38388;&#36317;&#25351;&#25968;&#32423;&#23567;&#30340;&#24773;&#20917;&#19979;&#38656;&#35201;$\Omega(N)$&#20010;&#21442;&#25968;&#65292;&#21516;&#26102;&#25351;&#20986;&#29616;&#26377;&#30340;&#20301;&#25552;&#21462;&#25216;&#26415;&#26080;&#27861;&#24212;&#29992;&#20110;&#36825;&#31181;&#24773;&#20917;&#12290;</title><link>https://arxiv.org/abs/2302.00834</link><description>&lt;p&gt;
&#29992;&#20110;&#19981;&#35268;&#21017;&#38388;&#38548;&#25968;&#25454;&#30340;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#25554;&#20540;&#30340;&#23574;&#38160;&#19979;&#30028;
&lt;/p&gt;
&lt;p&gt;
Sharp Lower Bounds on Interpolation by Deep ReLU Neural Networks at Irregularly Spaced Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2302.00834
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#22312;&#19981;&#35268;&#21017;&#38388;&#38548;&#25968;&#25454;&#19978;&#30340;&#25554;&#20540;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22312;&#25968;&#25454;&#28857;&#38388;&#36317;&#25351;&#25968;&#32423;&#23567;&#30340;&#24773;&#20917;&#19979;&#38656;&#35201;$\Omega(N)$&#20010;&#21442;&#25968;&#65292;&#21516;&#26102;&#25351;&#20986;&#29616;&#26377;&#30340;&#20301;&#25552;&#21462;&#25216;&#26415;&#26080;&#27861;&#24212;&#29992;&#20110;&#36825;&#31181;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#25554;&#20540;&#33021;&#21147;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#32771;&#34385;&#28145;&#24230;ReLU&#32593;&#32476;&#22914;&#20309;&#22312;&#21333;&#20301;&#29699;&#20013;&#30340;$N$&#20010;&#25968;&#25454;&#28857;&#19978;&#36827;&#34892;&#20540;&#30340;&#25554;&#20540;&#65292;&#36825;&#20123;&#28857;&#20043;&#38388;&#30456;&#36317;$\delta$&#12290;&#25105;&#20204;&#34920;&#26126;&#22312;$\delta$&#22312;$N$&#25351;&#25968;&#32423;&#23567;&#30340;&#21306;&#22495;&#20013;&#38656;&#35201;$\Omega(N)$&#20010;&#21442;&#25968;&#65292;&#36825;&#32473;&#20986;&#20102;&#35813;&#21306;&#22495;&#30340;&#23574;&#38160;&#32467;&#26524;&#65292;&#22240;&#20026;$O(N)$&#20010;&#21442;&#25968;&#24635;&#26159;&#36275;&#22815;&#30340;&#12290; &#36825;&#20063;&#34920;&#26126;&#29992;&#20110;&#35777;&#26126;VC&#32500;&#24230;&#19979;&#30028;&#30340;&#20301;&#25552;&#21462;&#25216;&#26415;&#26080;&#27861;&#24212;&#29992;&#20110;&#19981;&#35268;&#21017;&#38388;&#38548;&#30340;&#25968;&#25454;&#28857;&#12290;&#26368;&#21518;&#65292;&#20316;&#20026;&#24212;&#29992;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#22312;&#23884;&#20837;&#31471;&#28857;&#22788;&#20026;Sobolev&#31354;&#38388;&#23454;&#29616;&#30340;&#36817;&#20284;&#36895;&#29575;&#30340;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2302.00834v2 Announce Type: replace  Abstract: We study the interpolation power of deep ReLU neural networks. Specifically, we consider the question of how efficiently, in terms of the number of parameters, deep ReLU networks can interpolate values at $N$ datapoints in the unit ball which are separated by a distance $\delta$. We show that $\Omega(N)$ parameters are required in the regime where $\delta$ is exponentially small in $N$, which gives the sharp result in this regime since $O(N)$ parameters are always sufficient. This also shows that the bit-extraction technique used to prove lower bounds on the VC dimension cannot be applied to irregularly spaced datapoints. Finally, as an application we give a lower bound on the approximation rates that deep ReLU neural networks can achieve for Sobolev spaces at the embedding endpoint.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Group-Nonlinear-Lasso&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#21516;&#26102;&#20272;&#35745;&#28151;&#21512;&#29289;&#20013;&#30340;&#32447;&#24615;&#31995;&#25968;&#21644;&#29305;&#24449;&#30340;&#38750;&#32447;&#24615;&#21442;&#25968;&#65292;&#24182;&#20351;&#29992;&#35777;&#26126;&#20989;&#25968;&#23545;&#39044;&#27979;&#35823;&#24046;&#25552;&#20379;&#20102;&#39640;&#27010;&#29575;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2210.16311</link><description>&lt;p&gt;
&#26469;&#33258;&#36830;&#32493;&#23383;&#20856;&#30340;&#28151;&#21512;&#29289;&#30340;&#31163;&#25955;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Simultaneous off-the-grid learning of mixtures issued from a continuous dictionary
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2210.16311
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Group-Nonlinear-Lasso&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#21516;&#26102;&#20272;&#35745;&#28151;&#21512;&#29289;&#20013;&#30340;&#32447;&#24615;&#31995;&#25968;&#21644;&#29305;&#24449;&#30340;&#38750;&#32447;&#24615;&#21442;&#25968;&#65292;&#24182;&#20351;&#29992;&#35777;&#26126;&#20989;&#25968;&#23545;&#39044;&#27979;&#35823;&#24046;&#25552;&#20379;&#20102;&#39640;&#27010;&#29575;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35266;&#23519;&#20102;&#19968;&#32452;&#20449;&#21495;&#65292;&#21487;&#33021;&#26159;&#19968;&#20010;&#36830;&#32493;&#20449;&#21495;&#65292;&#21463;&#21040;&#22122;&#22768;&#30340;&#24178;&#25200;&#12290;&#27599;&#20010;&#20449;&#21495;&#26159;&#30001;&#19968;&#20010;&#26410;&#30693;&#25968;&#37327;&#30340;&#29305;&#24449;&#28151;&#21512;&#32780;&#25104;&#65292;&#36825;&#20123;&#29305;&#24449;&#23646;&#20110;&#19968;&#20010;&#36830;&#32493;&#23383;&#20856;&#12290;&#36830;&#32493;&#23383;&#20856;&#30001;&#19968;&#20010;&#23454;&#38750;&#32447;&#24615;&#21442;&#25968;&#36827;&#34892;&#21442;&#25968;&#21270;&#12290;&#25105;&#20204;&#20551;&#35774;&#36825;&#20123;&#20449;&#21495;&#20849;&#20139;&#19968;&#20010;&#22522;&#26412;&#32467;&#26500;&#65292;&#20551;&#23450;&#27599;&#20010;&#20449;&#21495;&#30340;&#27963;&#36291;&#29305;&#24449;&#21253;&#21547;&#22312;&#19968;&#20010;&#26377;&#38480;&#31232;&#30095;&#38598;&#21512;&#20013;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#27491;&#21017;&#21270;&#20248;&#21270;&#38382;&#39064;&#65292;&#21516;&#26102;&#20272;&#35745;&#28151;&#21512;&#29289;&#20013;&#30340;&#32447;&#24615;&#31995;&#25968;&#21644;&#29305;&#24449;&#30340;&#38750;&#32447;&#24615;&#21442;&#25968;&#12290;&#20248;&#21270;&#38382;&#39064;&#30001;&#25968;&#25454;&#20445;&#30495;&#24230;&#39033;&#21644;$(\ell_1,L^p)$-&#24809;&#32602;&#39033;&#32452;&#25104;&#12290;&#25105;&#20204;&#31216;&#20854;&#35299;&#20026;Group-Nonlinear-Lasso&#65292;&#24182;&#20351;&#29992;&#35777;&#26126;&#20989;&#25968;&#23545;&#39044;&#27979;&#35823;&#24046;&#25552;&#20379;&#20102;&#39640;&#27010;&#29575;&#30028;&#38480;&#12290;&#20511;&#37492;&#26368;&#36817;&#20851;&#20110;&#31163;&#25955;&#23398;&#20064;&#26041;&#27861;&#20960;&#20309;&#24615;&#36136;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#34920;&#26126;&#21482;&#35201;&#29305;&#23450;&#21442;&#25968;&#28385;&#36275;&#26465;&#20214;&#65292;&#23601;&#21487;&#20197;&#26500;&#36896;&#36825;&#26679;&#30340;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2210.16311v2 Announce Type: replace-cross  Abstract: In this paper we observe a set, possibly a continuum, of signals corrupted by noise. Each signal is a finite mixture of an unknown number of features belonging to a continuous dictionary. The continuous dictionary is parametrized by a real non-linear parameter. We shall assume that the signals share an underlying structure by assuming that each signal has its active features included in a finite and sparse set. We formulate regularized optimization problem to estimate simultaneously the linear coefficients in the mixtures and the non-linear parameters of the features. The optimization problem is composed of a data fidelity term and a $(\ell_1,L^p)$-penalty. We call its solution the Group-Nonlinear-Lasso and provide high probability bounds on the prediction error using certificate functions. Following recent works on the geometry of off-the-grid methods, we show that such functions can be constructed provided the parameters of t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#30340;&#35757;&#32451;&#21160;&#24577;&#26469;&#35780;&#20272;&#27599;&#20010;&#35757;&#32451;&#23454;&#20363;&#34892;&#20026;&#30340;&#26041;&#27861;&#65292;&#38024;&#23545;&#21253;&#21547;&#22823;&#37096;&#20998;&#34920;&#26684;&#21270;&#25110;&#32467;&#26500;&#21270;&#25968;&#25454;&#30340;&#25968;&#25454;&#38598;&#65292;&#30456;&#36739;&#20110;&#33258;&#20449;&#23398;&#20064;&#12289;&#30452;&#25509;&#21551;&#21457;&#24335;&#21644;&#20581;&#22766;&#25552;&#21319;&#31639;&#27861;&#65292;&#21462;&#24471;&#20102;&#26368;&#20339;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2210.11327</link><description>&lt;p&gt;
&#21033;&#29992;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#30340;&#35757;&#32451;&#21160;&#24577;&#25552;&#39640;&#25968;&#25454;&#36136;&#37327;
&lt;/p&gt;
&lt;p&gt;
Improving Data Quality with Training Dynamics of Gradient Boosting Decision Trees
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2210.11327
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#30340;&#35757;&#32451;&#21160;&#24577;&#26469;&#35780;&#20272;&#27599;&#20010;&#35757;&#32451;&#23454;&#20363;&#34892;&#20026;&#30340;&#26041;&#27861;&#65292;&#38024;&#23545;&#21253;&#21547;&#22823;&#37096;&#20998;&#34920;&#26684;&#21270;&#25110;&#32467;&#26500;&#21270;&#25968;&#25454;&#30340;&#25968;&#25454;&#38598;&#65292;&#30456;&#36739;&#20110;&#33258;&#20449;&#23398;&#20064;&#12289;&#30452;&#25509;&#21551;&#21457;&#24335;&#21644;&#20581;&#22766;&#25552;&#21319;&#31639;&#27861;&#65292;&#21462;&#24471;&#20102;&#26368;&#20339;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#20013;&#24120;&#24120;&#21253;&#21547;&#26377;&#38169;&#35823;&#26631;&#35760;&#30340;&#23454;&#20363;&#65292;&#36825;&#20250;&#24433;&#21709;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#23588;&#20854;&#26159;&#22312;&#27867;&#21270;&#36229;&#20986;&#20998;&#24067;&#33539;&#22260;&#26102;&#12290;&#21516;&#26102;&#65292;&#27599;&#20010;&#31034;&#20363;&#23545;&#23398;&#20064;&#36807;&#31243;&#21487;&#33021;&#26377;&#19981;&#21516;&#30340;&#36129;&#29486;&#12290;&#36825;&#20419;&#20351;&#30740;&#31350;&#32773;&#26356;&#22909;&#22320;&#29702;&#35299;&#25968;&#25454;&#23454;&#20363;&#22312;&#27169;&#22411;&#20013;&#23545;&#22909;&#25351;&#26631;&#30340;&#36129;&#29486;&#35282;&#33394;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#65288;GBDTs&#65289;&#35757;&#32451;&#21160;&#24577;&#35745;&#31639;&#30340;&#24230;&#37327;&#26469;&#35780;&#20272;&#27599;&#20010;&#35757;&#32451;&#23454;&#20363;&#34892;&#20026;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#21253;&#21547;&#22823;&#37096;&#20998;&#34920;&#26684;&#21270;&#25110;&#32467;&#26500;&#21270;&#25968;&#25454;&#30340;&#25968;&#25454;&#38598;&#65292;&#23545;&#20110;&#36825;&#31867;&#25968;&#25454;&#38598;&#65292;&#20915;&#31574;&#26641;&#38598;&#25104;&#22312;&#24615;&#33021;&#26041;&#38754;&#20173;&#22788;&#20110;&#39046;&#20808;&#22320;&#20301;&#12290;&#19982;&#33258;&#20449;&#23398;&#20064;&#12289;&#30452;&#25509;&#21551;&#21457;&#24335;&#21644;&#20581;&#22766;&#25552;&#21319;&#31639;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25972;&#20307;&#19978;&#21462;&#24471;&#20102;&#26368;&#20339;&#32467;&#26524;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#26816;&#27979;&#22024;&#26434;&#26631;&#31614;&#20197;&#28165;&#29702;&#25968;&#25454;&#38598;&#12289;&#25913;&#36827;&#27169;&#22411;&#25351;&#26631;&#26041;&#38754;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2210.11327v2 Announce Type: replace  Abstract: Real world datasets contain incorrectly labeled instances that hamper the performance of the model and, in particular, the ability to generalize out of distribution. Also, each example might have different contribution towards learning. This motivates studies to better understanding of the role of data instances with respect to their contribution in good metrics in models. In this paper we propose a method based on metrics computed from training dynamics of Gradient Boosting Decision Trees (GBDTs) to assess the behavior of each training example. We focus on datasets containing mostly tabular or structured data, for which the use of Decision Trees ensembles are still the state-of-the-art in terms of performance. Our methods achieved the best results overall when compared with confident learning, direct heuristics and a robust boosting algorithm. We show results on detecting noisy labels in order clean datasets, improving models' metri
&lt;/p&gt;</description></item><item><title>&#24178;&#39044;&#25968;&#25454;&#26377;&#21161;&#20110;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#65292;&#21487;&#20197;&#36890;&#36807;&#24178;&#39044;&#25968;&#25454;&#20013;&#28508;&#22312;&#22240;&#32032;&#25903;&#25345;&#30340;&#20960;&#20309;&#29305;&#24449;&#26469;&#35782;&#21035;&#28508;&#22312;&#30340;&#22240;&#26524;&#22240;&#32032;&#12290;</title><link>https://arxiv.org/abs/2209.11924</link><description>&lt;p&gt;
&#24178;&#39044;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Interventional Causal Representation Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2209.11924
&lt;/p&gt;
&lt;p&gt;
&#24178;&#39044;&#25968;&#25454;&#26377;&#21161;&#20110;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#65292;&#21487;&#20197;&#36890;&#36807;&#24178;&#39044;&#25968;&#25454;&#20013;&#28508;&#22312;&#22240;&#32032;&#25903;&#25345;&#30340;&#20960;&#20309;&#29305;&#24449;&#26469;&#35782;&#21035;&#28508;&#22312;&#30340;&#22240;&#26524;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#26088;&#22312;&#20174;&#20302;&#32423;&#24863;&#23448;&#25968;&#25454;&#20013;&#25552;&#21462;&#39640;&#32423;&#28508;&#22312;&#22240;&#32032;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#20381;&#36182;&#20110;&#35266;&#27979;&#25968;&#25454;&#21644;&#32467;&#26500;&#20551;&#35774;&#65288;&#22914;&#26465;&#20214;&#29420;&#31435;&#24615;&#65289;&#26469;&#35782;&#21035;&#28508;&#22312;&#22240;&#32032;&#12290;&#28982;&#32780;&#65292;&#24178;&#39044;&#25968;&#25454;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#26222;&#36941;&#23384;&#22312;&#12290;&#24178;&#39044;&#25968;&#25454;&#33021;&#21542;&#20419;&#36827;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#65311;&#26412;&#25991;&#25506;&#35752;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;&#20851;&#38190;&#35266;&#23519;&#26159;&#65292;&#24178;&#39044;&#25968;&#25454;&#36890;&#24120;&#25658;&#24102;&#28508;&#22312;&#22240;&#32032;&#25903;&#25345;&#30340;&#20960;&#20309;&#29305;&#24449;&#65288;&#21363;&#27599;&#20010;&#28508;&#22312;&#22240;&#32032;&#21487;&#33021;&#37319;&#21462;&#30340;&#20540;&#65289;&#12290;&#20030;&#20363;&#26469;&#35828;&#65292;&#24403;&#28508;&#22312;&#22240;&#32032;&#23384;&#22312;&#22240;&#26524;&#32852;&#31995;&#26102;&#65292;&#24178;&#39044;&#21487;&#20197;&#25171;&#30772;&#24178;&#39044;&#28508;&#22312;&#22240;&#32032;&#25903;&#25345;&#21644;&#23427;&#20204;&#31062;&#20808;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#21033;&#29992;&#36825;&#19968;&#20107;&#23454;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#33719;&#24471;&#23436;&#32654;$do$&#24178;&#39044;&#25968;&#25454;&#21518;&#65292;&#21487;&#20197;&#30830;&#23450;&#28508;&#22312;&#30340;&#22240;&#26524;&#22240;&#32032;&#65292;&#32780;&#19988;&#33021;&#22815;&#23454;&#29616;&#21306;&#22359;&#20223;&#23556;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2209.11924v4 Announce Type: replace-cross  Abstract: Causal representation learning seeks to extract high-level latent factors from low-level sensory data. Most existing methods rely on observational data and structural assumptions (e.g., conditional independence) to identify the latent factors. However, interventional data is prevalent across applications. Can interventional data facilitate causal representation learning? We explore this question in this paper. The key observation is that interventional data often carries geometric signatures of the latent factors' support (i.e. what values each latent can possibly take). For example, when the latent factors are causally connected, interventions can break the dependency between the intervened latents' support and their ancestors'. Leveraging this fact, we prove that the latent causal factors can be identified up to permutation and scaling given data from perfect $do$ interventions. Moreover, we can achieve block affine identific
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#38543;&#26426;&#30697;&#38453;&#35745;&#31639;&#30340;&#39640;&#25928;&#35823;&#24046;&#21644;&#26041;&#24046;&#20272;&#35745;&#26041;&#27861;&#65292;&#21487;&#24110;&#21161;&#35780;&#20272;&#36755;&#20986;&#36136;&#37327;&#24182;&#25351;&#23548;&#31639;&#27861;&#21442;&#25968;&#36873;&#25321;&#12290;</title><link>https://arxiv.org/abs/2207.06342</link><description>&lt;p&gt;
&#38024;&#23545;&#38543;&#26426;&#30697;&#38453;&#35745;&#31639;&#30340;&#39640;&#25928;&#35823;&#24046;&#21644;&#26041;&#24046;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Efficient error and variance estimation for randomized matrix computations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2207.06342
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#38543;&#26426;&#30697;&#38453;&#35745;&#31639;&#30340;&#39640;&#25928;&#35823;&#24046;&#21644;&#26041;&#24046;&#20272;&#35745;&#26041;&#27861;&#65292;&#21487;&#24110;&#21161;&#35780;&#20272;&#36755;&#20986;&#36136;&#37327;&#24182;&#25351;&#23548;&#31639;&#27861;&#21442;&#25968;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#30697;&#38453;&#31639;&#27861;&#24050;&#25104;&#20026;&#31185;&#23398;&#35745;&#31639;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#24517;&#19981;&#21487;&#23569;&#30340;&#24037;&#20855;&#12290;&#20026;&#20102;&#23433;&#20840;&#22320;&#22312;&#24212;&#29992;&#20013;&#20351;&#29992;&#36825;&#20123;&#31639;&#27861;&#65292;&#38656;&#35201;&#32467;&#21512;&#21518;&#39564;&#35823;&#24046;&#20272;&#35745;&#26469;&#35780;&#20272;&#36755;&#20986;&#30340;&#36136;&#37327;&#12290;&#20026;&#28385;&#36275;&#36825;&#19968;&#38656;&#27714;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#35786;&#26029;&#26041;&#27861;&#65306;&#29992;&#20110;&#38543;&#26426;&#20302;&#31209;&#36924;&#36817;&#30340;&#30041;&#19968;&#27861;&#35823;&#24046;&#20272;&#35745;&#22120;&#21644;&#19968;&#31181;&#26480;&#22522;&#20992;&#37325;&#37319;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#38543;&#26426;&#30697;&#38453;&#35745;&#31639;&#30340;&#36755;&#20986;&#26041;&#24046;&#12290;&#36825;&#20004;&#31181;&#35786;&#26029;&#26041;&#27861;&#23545;&#20110;&#38543;&#26426;&#20302;&#31209;&#36924;&#36817;&#31639;&#27861;&#65288;&#22914;&#38543;&#26426;&#22855;&#24322;&#20540;&#20998;&#35299;&#21644;&#38543;&#26426;Nystrom&#36924;&#36817;&#65289;&#35745;&#31639;&#36805;&#36895;&#65292;&#24182;&#25552;&#20379;&#21487;&#29992;&#20110;&#35780;&#20272;&#35745;&#31639;&#36755;&#20986;&#36136;&#37327;&#21644;&#25351;&#23548;&#31639;&#27861;&#21442;&#25968;&#36873;&#25321;&#30340;&#26377;&#29992;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2207.06342v4 Announce Type: replace-cross  Abstract: Randomized matrix algorithms have become workhorse tools in scientific computing and machine learning. To use these algorithms safely in applications, they should be coupled with posterior error estimates to assess the quality of the output. To meet this need, this paper proposes two diagnostics: a leave-one-out error estimator for randomized low-rank approximations and a jackknife resampling method to estimate the variance of the output of a randomized matrix computation. Both of these diagnostics are rapid to compute for randomized low-rank approximation algorithms such as the randomized SVD and randomized Nystr\"om approximation, and they provide useful information that can be used to assess the quality of the computed output and guide algorithmic parameter choices.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#22312;&#20989;&#25968;&#32447;&#24615;&#22238;&#24402;&#19979;&#25506;&#35752;&#20102;&#36801;&#31227;&#23398;&#20064;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;RKHS&#36317;&#31163;&#34913;&#37327;&#20219;&#21153;&#30456;&#20284;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#31639;&#27861;&#26469;&#22788;&#29702;&#36801;&#31227;&#65292;&#19968;&#31181;&#38656;&#35201;&#24050;&#30693;&#27491;&#28304;&#65292;&#21478;&#19968;&#31181;&#21033;&#29992;&#32858;&#21512;&#25216;&#26415;&#23454;&#29616;&#26080;&#28304;&#20449;&#24687;&#30340;&#31283;&#20581;&#20256;&#36755;&#12290;&#21516;&#26102;&#24314;&#31435;&#20102;&#23398;&#20064;&#38382;&#39064;&#30340;&#19979;&#30028;&#65292;&#24182;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#19978;&#30028;&#12290;</title><link>https://arxiv.org/abs/2206.04277</link><description>&lt;p&gt;
&#20851;&#20110;&#20989;&#25968;&#32447;&#24615;&#27169;&#22411;&#20551;&#35774;&#36801;&#31227;&#23398;&#20064;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Hypothesis Transfer Learning of Functional Linear Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2206.04277
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#22312;&#20989;&#25968;&#32447;&#24615;&#22238;&#24402;&#19979;&#25506;&#35752;&#20102;&#36801;&#31227;&#23398;&#20064;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;RKHS&#36317;&#31163;&#34913;&#37327;&#20219;&#21153;&#30456;&#20284;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#31639;&#27861;&#26469;&#22788;&#29702;&#36801;&#31227;&#65292;&#19968;&#31181;&#38656;&#35201;&#24050;&#30693;&#27491;&#28304;&#65292;&#21478;&#19968;&#31181;&#21033;&#29992;&#32858;&#21512;&#25216;&#26415;&#23454;&#29616;&#26080;&#28304;&#20449;&#24687;&#30340;&#31283;&#20581;&#20256;&#36755;&#12290;&#21516;&#26102;&#24314;&#31435;&#20102;&#23398;&#20064;&#38382;&#39064;&#30340;&#19979;&#30028;&#65292;&#24182;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#26694;&#26550;&#19979;&#30340;&#20989;&#25968;&#32447;&#24615;&#22238;&#24402;&#65288;FLR&#65289;&#30340;&#36801;&#31227;&#23398;&#20064;&#65288;TL&#65289;&#65292;&#35266;&#23519;&#21040;&#29616;&#26377;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;TL&#25216;&#26415;&#19982;&#22522;&#20110;&#25130;&#26029;&#30340;FLR&#26041;&#27861;&#19981;&#20860;&#23481;&#65292;&#22240;&#20026;&#20989;&#25968;&#25968;&#25454;&#22312;&#26412;&#36136;&#19978;&#26159;&#26080;&#38480;&#32500;&#30340;&#65292;&#24182;&#30001;&#24179;&#28369;&#30340;&#22522;&#30784;&#36807;&#31243;&#29983;&#25104;&#12290;&#25105;&#20204;&#20351;&#29992;RKHS&#36317;&#31163;&#26469;&#34913;&#37327;&#20219;&#21153;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65292;&#20801;&#35768;&#20256;&#36755;&#30340;&#20449;&#24687;&#31867;&#22411;&#19982;&#25152;&#26045;&#21152;&#30340;RKHS&#30340;&#23646;&#24615;&#30456;&#20851;&#32852;&#12290;&#22522;&#20110;&#20551;&#35774;&#20559;&#31227;&#36801;&#31227;&#23398;&#20064;&#33539;&#24335;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#31639;&#27861;&#65306;&#19968;&#31181;&#22312;&#24050;&#30693;&#27491;&#28304;&#26102;&#36827;&#34892;&#20256;&#36755;&#65292;&#21478;&#19968;&#31181;&#21033;&#29992;&#32858;&#21512;&#25216;&#26415;&#23454;&#29616;&#26080;&#38656;&#20808;&#39564;&#20449;&#24687;&#30340;&#31283;&#20581;&#20256;&#36755;&#12290;&#25105;&#20204;&#20026;&#36825;&#20010;&#23398;&#20064;&#38382;&#39064;&#24314;&#31435;&#20102;&#19979;&#30028;&#65292;&#24182;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#20139;&#26377;&#21305;&#37197;&#30340;&#28176;&#36817;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2206.04277v4 Announce Type: replace-cross  Abstract: We study the transfer learning (TL) for the functional linear regression (FLR) under the Reproducing Kernel Hilbert Space (RKHS) framework, observing the TL techniques in existing high-dimensional linear regression is not compatible with the truncation-based FLR methods as functional data are intrinsically infinite-dimensional and generated by smooth underlying processes. We measure the similarity across tasks using RKHS distance, allowing the type of information being transferred tied to the properties of the imposed RKHS. Building on the hypothesis offset transfer learning paradigm, two algorithms are proposed: one conducts the transfer when positive sources are known, while the other leverages aggregation techniques to achieve robust transfer without prior information about the sources. We establish lower bounds for this learning problem and show the proposed algorithms enjoy a matching asymptotic upper bound. These analyses
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#20271;&#24681;&#26031;&#22359;&#27969;&#21464;&#20998;&#25512;&#26029;&#65288;BF-VI&#65289;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#28789;&#27963;&#36924;&#36817;&#22797;&#26434;&#30340;&#22810;&#20803;&#21518;&#39564;&#65292;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;VI&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2202.05650</link><description>&lt;p&gt;
&#21464;&#20998;&#36125;&#21494;&#26031;&#20013;&#30340;&#26580;&#24615;&#21518;&#39564;&#30340;&#20271;&#24681;&#26031;&#22359;&#27969;
&lt;/p&gt;
&lt;p&gt;
Bernstein Flows for Flexible Posteriors in Variational Bayes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2202.05650
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#20271;&#24681;&#26031;&#22359;&#27969;&#21464;&#20998;&#25512;&#26029;&#65288;BF-VI&#65289;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#28789;&#27963;&#36924;&#36817;&#22797;&#26434;&#30340;&#22810;&#20803;&#21518;&#39564;&#65292;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;VI&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#25512;&#26029;&#65288;VI&#65289;&#26159;&#19968;&#31181;&#36890;&#36807;&#20248;&#21270;&#26469;&#36817;&#20284;&#38590;&#20197;&#35745;&#31639;&#21518;&#39564;&#30340;&#25216;&#26415;&#12290;&#19982;MCMC&#30456;&#27604;&#65292;VI&#21487;&#20197;&#25193;&#23637;&#21040;&#35768;&#22810;&#35266;&#27979;&#12290;&#28982;&#32780;&#65292;&#22312;&#22797;&#26434;&#21518;&#39564;&#30340;&#24773;&#20917;&#19979;&#65292;&#29616;&#26377;&#30340;VI&#26041;&#27861;&#36890;&#24120;&#20135;&#29983;&#20196;&#20154;&#19981;&#28385;&#24847;&#30340;&#21518;&#39564;&#36817;&#20284;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#20271;&#24681;&#26031;&#22359;&#27969;&#21464;&#20998;&#25512;&#26029;&#65288;BF-VI&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#31283;&#20581;&#19988;&#26131;&#20110;&#20351;&#29992;&#30340;&#26041;&#27861;&#65292;&#36275;&#22815;&#28789;&#27963;&#20197;&#36924;&#36817;&#22797;&#26434;&#30340;&#22810;&#20803;&#21518;&#39564;&#12290;BF-VI&#32467;&#21512;&#20102;&#24402;&#19968;&#21270;&#27969;&#21644;&#22522;&#20110;&#20271;&#24681;&#26031;&#22810;&#39033;&#24335;&#30340;&#36716;&#25442;&#27169;&#22411;&#30340;&#24605;&#24819;&#12290;&#22312;&#22522;&#20934;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23558;BF-VI&#35299;&#19982;&#20934;&#30830;&#30340;&#21518;&#39564;&#12289;MCMC&#35299;&#20197;&#21450;&#22522;&#20110;&#24402;&#19968;&#21270;&#27969;&#30340;VI&#31561;&#29616;&#26377;VI&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#25105;&#20204;&#21457;&#29616;&#22312;&#20302;&#32500;&#27169;&#22411;&#20013;&#65292;BF-VI&#21487;&#20197;&#20934;&#30830;&#36924;&#36817;&#30495;&#23454;&#21518;&#39564;&#65307;&#32780;&#22312;&#39640;&#32500;&#27169;&#22411;&#20013;&#65292;BF-VI&#20248;&#20110;&#20854;&#20182;VI&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21033;&#29992;BF-VI&#38024;&#23545;&#21322;&#32467;&#26500;&#21270;Mela&#24320;&#21457;&#20102;&#19968;&#20010;&#36125;&#21494;&#26031;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2202.05650v2 Announce Type: replace-cross  Abstract: Variational inference (VI) is a technique to approximate difficult to compute posteriors by optimization. In contrast to MCMC, VI scales to many observations. In the case of complex posteriors, however, state-of-the-art VI approaches often yield unsatisfactory posterior approximations. This paper presents Bernstein flow variational inference (BF-VI), a robust and easy-to-use method, flexible enough to approximate complex multivariate posteriors. BF-VI combines ideas from normalizing flows and Bernstein polynomial-based transformation models. In benchmark experiments, we compare BF-VI solutions with exact posteriors, MCMC solutions, and state-of-the-art VI methods including normalizing flow based VI. We show for low-dimensional models that BF-VI accurately approximates the true posterior; in higher-dimensional models, BF-VI outperforms other VI methods. Further, we develop with BF-VI a Bayesian model for the semi-structured Mela
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;State-Dependent Causal Inference&#65288;SDCI&#65289;&#26041;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#19968;&#31867;&#23485;&#27867;&#30340;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#65292;&#25104;&#21151;&#22320;&#22238;&#22797;&#20986;&#28508;&#22312;&#30340;&#22240;&#26524;&#20381;&#36182;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2110.06257</link><description>&lt;p&gt;
&#20174;&#26377;&#26465;&#20214;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#20013;&#36827;&#34892;&#22240;&#26524;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Causal Discovery from Conditionally Stationary Time Series
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2110.06257
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;State-Dependent Causal Inference&#65288;SDCI&#65289;&#26041;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#19968;&#31867;&#23485;&#27867;&#30340;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#65292;&#25104;&#21151;&#22320;&#22238;&#22797;&#20986;&#28508;&#22312;&#30340;&#22240;&#26524;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#21457;&#29616;&#65292;&#21363;&#20174;&#35266;&#27979;&#25968;&#25454;&#25512;&#26029;&#28508;&#22312;&#30340;&#22240;&#26524;&#20851;&#31995;&#65292;&#24050;&#34987;&#35777;&#26126;&#23545;AI&#31995;&#32479;&#20855;&#26377;&#26497;&#22823;&#25361;&#25112;&#12290;&#22312;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#32972;&#26223;&#19979;&#65292;&#20256;&#32479;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#20027;&#35201;&#32771;&#34385;&#20855;&#26377;&#23436;&#20840;&#35266;&#27979;&#21464;&#37327;&#21644;/&#25110;&#26469;&#33258;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#30340;&#25968;&#25454;&#30340;&#21463;&#38480;&#22330;&#26223;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#26469;&#22788;&#29702;&#19968;&#31867;&#23485;&#27867;&#30340;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#65292;&#21363;&#22312;&#26465;&#20214;&#19978;&#26159;&#24179;&#31283;&#30340;&#26465;&#20214;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#65292;&#20854;&#20013;&#38750;&#24179;&#31283;&#34892;&#20026;&#34987;&#24314;&#27169;&#20026;&#22312;&#19968;&#32452;&#65288;&#21487;&#33021;&#26159;&#38544;&#34255;&#30340;&#65289;&#29366;&#24577;&#21464;&#37327;&#19978;&#30340;&#24179;&#31283;&#24615;&#12290;&#21629;&#21517;&#20026;State-Dependent Causal Inference&#65288;SDCI&#65289;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#21487;&#35777;&#22320;&#22238;&#22797;&#20986;&#28508;&#22312;&#30340;&#22240;&#26524;&#20381;&#36182;&#20851;&#31995;&#65292;&#35777;&#26126;&#22312;&#23436;&#20840;&#35266;&#23519;&#21040;&#30340;&#29366;&#24577;&#19979;&#65292;&#24182;&#22312;&#23384;&#22312;&#38544;&#34255;&#29366;&#24577;&#26102;&#32463;&#39564;&#24615;&#22320;&#23454;&#29616;&#12290;&#21518;&#32773;&#36890;&#36807;&#23545;&#21512;&#25104;&#32447;&#24615;&#31995;&#32479;&#21644;&#38750;&#32447;&#24615;&#31890;&#23376;&#30456;&#20114;&#20316;&#29992;&#25968;&#25454;&#30340;&#23454;&#39564;&#36827;&#34892;&#39564;&#35777;&#65292;SDCI&#23454;&#29616;&#20102;&#20248;&#20110;&#22522;&#32447;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2110.06257v2 Announce Type: replace  Abstract: Causal discovery, i.e., inferring underlying causal relationships from observational data, has been shown to be highly challenging for AI systems. In time series modeling context, traditional causal discovery methods mainly consider constrained scenarios with fully observed variables and/or data from stationary time-series. We develop a causal discovery approach to handle a wide class of non-stationary time-series that are conditionally stationary, where the non-stationary behaviour is modeled as stationarity conditioned on a set of (possibly hidden) state variables. Named State-Dependent Causal Inference (SDCI), our approach is able to recover the underlying causal dependencies, provably with fully-observed states and empirically with hidden states. The latter is confirmed by experiments on synthetic linear system and nonlinear particle interaction data, where SDCI achieves superior performance over baseline causal discovery methods
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#26694;&#26550;&#65292;&#21033;&#29992;&#38543;&#26426;&#24615;&#27169;&#25311;&#38544;&#34255;&#23618;&#36755;&#20986;&#20998;&#24067;&#65292;&#20174;&#32780;&#25913;&#21892;&#23545;&#25239;&#26679;&#26412;&#26816;&#27979;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2105.08620</link><description>&lt;p&gt;
&#20855;&#26377;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#23545;&#25239;&#26679;&#26412;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Adversarial Examples Detection with Bayesian Neural Network
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2105.08620
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#26694;&#26550;&#65292;&#21033;&#29992;&#38543;&#26426;&#24615;&#27169;&#25311;&#38544;&#34255;&#23618;&#36755;&#20986;&#20998;&#24067;&#65292;&#20174;&#32780;&#25913;&#21892;&#23545;&#25239;&#26679;&#26412;&#26816;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#26469;&#26816;&#27979;&#23545;&#25239;&#26679;&#26412;&#65292;&#20854;&#28789;&#24863;&#26469;&#28304;&#20110;&#36825;&#26679;&#30340;&#35266;&#23519;&#32467;&#26524;&#65306;&#38543;&#26426;&#32452;&#20214;&#21487;&#20197;&#25552;&#39640;&#39044;&#27979;&#22120;&#30340;&#24179;&#28369;&#24615;&#65292;&#20351;&#24471;&#26356;&#23481;&#26131;&#27169;&#25311;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20986;&#20998;&#24067;&#12290;&#22522;&#20110;&#36825;&#20123;&#35266;&#23519;&#32467;&#26524;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36125;&#21494;&#26031;&#23545;&#25239;&#26679;&#26412;&#26816;&#27979;&#22120;&#65292;&#31616;&#31216;&#20026;BATer&#65292;&#20197;&#25552;&#39640;&#23545;&#25239;&#26679;&#26412;&#26816;&#27979;&#30340;&#24615;&#33021;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#33258;&#28982;&#26679;&#26412;&#21644;&#23545;&#25239;&#26679;&#26412;&#20043;&#38388;&#38544;&#34255;&#23618;&#36755;&#20986;&#30340;&#20998;&#24067;&#24046;&#24322;&#65292;&#24182;&#24314;&#35758;&#20351;&#29992;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#38543;&#26426;&#24615;&#26469;&#27169;&#25311;&#38544;&#34255;&#23618;&#36755;&#20986;&#20998;&#24067;&#65292;&#24182;&#21033;&#29992;&#20998;&#24067;&#30340;&#31163;&#25955;&#24615;&#26469;&#26816;&#27979;&#23545;&#25239;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2105.08620v3 Announce Type: replace-cross  Abstract: In this paper, we propose a new framework to detect adversarial examples motivated by the observations that random components can improve the smoothness of predictors and make it easier to simulate the output distribution of a deep neural network. With these observations, we propose a novel Bayesian adversarial example detector, short for BATer, to improve the performance of adversarial example detection. Specifically, we study the distributional difference of hidden layer output between natural and adversarial examples, and propose to use the randomness of the Bayesian neural network to simulate hidden layer output distribution and leverage the distribution dispersion to detect adversarial examples. The advantage of a Bayesian neural network is that the output is stochastic while a deep neural network without random components does not have such characteristics. Empirical results on several benchmark datasets against popular a
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#20855;&#26377;&#19981;&#20934;&#30830;&#26799;&#24230;&#30340; Langevin Monte Carlo &#31639;&#27861;&#30340;&#37319;&#26679;&#38382;&#39064;&#65292;&#24182;&#22312;Wasserstein-2&#36317;&#31163;&#20013;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;&#35823;&#24046;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/1710.00095</link><description>&lt;p&gt;
&#20855;&#26377;&#19981;&#20934;&#30830;&#26799;&#24230;&#30340; Langevin Monte Carlo &#30340;&#29992;&#25143;&#21451;&#22909;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
User-friendly guarantees for the Langevin Monte Carlo with inaccurate gradient
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/1710.00095
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#20855;&#26377;&#19981;&#20934;&#30830;&#26799;&#24230;&#30340; Langevin Monte Carlo &#31639;&#27861;&#30340;&#37319;&#26679;&#38382;&#39064;&#65292;&#24182;&#22312;Wasserstein-2&#36317;&#31163;&#20013;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;&#35823;&#24046;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20174;&#24050;&#30693;&#20809;&#28369;&#19988;&#24378;&#23545;&#25968;&#20985;&#20989;&#25968;&#30340;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#20013;&#37319;&#26679;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#22522;&#20110;(&#39640;&#24230;&#36807;&#38459;&#23612;) Langevin &#25193;&#25955;&#30340;&#31163;&#25955;&#21270;&#30340;&#36817;&#20284;&#37319;&#26679;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#22312;Wasserstein-2&#36317;&#31163;&#20013;&#27979;&#37327;&#30340;&#35823;&#24046;&#20445;&#35777;&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#26041;&#21521;&#19978;&#25913;&#36827;&#25110;&#25193;&#23637;&#20102;&#26368;&#26032;&#32467;&#26524;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23545;&#20248;&#21270;&#30340;&#19981;&#23450;&#27493;&#38271;&#19968;&#38454; Langevin Monte Carlo(LMC)&#31639;&#27861;&#30340;&#35823;&#24046;&#32473;&#20986;&#20102;&#19978;&#30028;&#12290;&#36825;&#20010;&#32467;&#26524;&#30340;&#20248;&#28857;&#26159;&#19981;&#21463;&#26102;&#38388;&#38480;&#21046;(&#25105;&#20204;&#26080;&#38656;&#20107;&#20808;&#30693;&#36947;&#30446;&#26631;&#31934;&#24230;)&#65292;&#24182;&#19988;&#22312;&#23545;&#24212;&#30340;&#24120;&#25968;&#27493;&#38271;&#32467;&#26524;&#22522;&#30784;&#19978;&#25552;&#21319;&#20102;&#23545;&#25968;&#22240;&#23376;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#24403;&#26080;&#27861;&#20934;&#30830;&#35780;&#20272;&#23545;&#25968;&#23494;&#24230;&#26799;&#24230;&#65292;&#20294;&#21487;&#20197;&#33719;&#24471;&#21069;&#36848;&#26799;&#24230;&#30340;&#36817;&#20284;&#26102;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:1710.00095v4 Announce Type: replace-cross  Abstract: In this paper, we study the problem of sampling from a given probability density function that is known to be smooth and strongly log-concave. We analyze several methods of approximate sampling based on discretizations of the (highly overdamped) Langevin diffusion and establish guarantees on its error measured in the Wasserstein-2 distance. Our guarantees improve or extend the state-of-the-art results in three directions. First, we provide an upper bound on the error of the first-order Langevin Monte Carlo (LMC) algorithm with optimized varying step-size. This result has the advantage of being horizon free (we do not need to know in advance the target precision) and to improve by a logarithmic factor the corresponding result for the constant step-size. Second, we study the case where accurate evaluations of the gradient of the log-density are unavailable, but one can have access to approximations of the aforementioned gradient.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24471;&#20998;&#32467;&#26500;&#20808;&#39564;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#37096;&#20998;&#24050;&#30693;&#39640;&#26031;&#22270;&#27169;&#22411;&#12290;&#36890;&#36807;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#20272;&#35745;&#22270;&#30340;&#24471;&#20998;&#20989;&#25968;&#65292;&#25105;&#20204;&#21487;&#20197;&#22312;&#29983;&#25104;&#26679;&#26412;&#26102;&#21033;&#29992;&#36864;&#28779;&#26391;&#26684;&#32500;&#33021;&#25193;&#25955;&#65292;&#20174;&#32780;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#21518;&#39564;&#20998;&#24067;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#26126;&#26174;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2401.14340</link><description>&lt;p&gt;
&#22522;&#20110;&#24471;&#20998;&#32467;&#26500;&#20808;&#39564;&#30340;&#37096;&#20998;&#24050;&#30693;&#39640;&#26031;&#22270;&#27169;&#22411;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Estimation of partially known Gaussian graphical models with score-based structural priors. (arXiv:2401.14340v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14340
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24471;&#20998;&#32467;&#26500;&#20808;&#39564;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#37096;&#20998;&#24050;&#30693;&#39640;&#26031;&#22270;&#27169;&#22411;&#12290;&#36890;&#36807;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#20272;&#35745;&#22270;&#30340;&#24471;&#20998;&#20989;&#25968;&#65292;&#25105;&#20204;&#21487;&#20197;&#22312;&#29983;&#25104;&#26679;&#26412;&#26102;&#21033;&#29992;&#36864;&#28779;&#26391;&#26684;&#32500;&#33021;&#25193;&#25955;&#65292;&#20174;&#32780;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#21518;&#39564;&#20998;&#24067;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#26126;&#26174;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#25903;&#25345;&#20272;&#35745;&#37096;&#20998;&#24050;&#30693;&#30340;&#39640;&#26031;&#22270;&#27169;&#22411;&#65292;&#24182;&#19988;&#32467;&#21512;&#20102;&#20851;&#20110;&#24213;&#23618;&#22270;&#30340;&#20808;&#39564;&#20449;&#24687;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;&#20256;&#32479;&#26041;&#27861;&#20351;&#29992;&#28857;&#20272;&#35745;&#26041;&#27861;&#22522;&#20110;&#26368;&#22823;&#20284;&#28982;&#25110;&#26368;&#22823;&#21518;&#39564;&#20934;&#21017;&#65292;&#24182;&#20351;&#29992;&#65288;&#31616;&#21333;&#30340;&#65289;&#31934;&#24230;&#30697;&#38453;&#20808;&#39564;&#26469;&#25552;&#20379;&#28857;&#20272;&#35745;&#12290;&#25105;&#20204;&#32771;&#34385;&#23545;&#22270;&#36827;&#34892;&#20808;&#39564;&#65292;&#24182;&#20381;&#36182;&#36864;&#28779;&#26391;&#26684;&#32500;&#33021;&#25193;&#25955;&#20174;&#21518;&#39564;&#20998;&#24067;&#20013;&#29983;&#25104;&#26679;&#26412;&#12290;&#30001;&#20110;&#26391;&#26684;&#32500;&#33021;&#37319;&#26679;&#22120;&#38656;&#35201;&#35775;&#38382;&#24213;&#23618;&#22270;&#20808;&#39564;&#30340;&#24471;&#20998;&#20989;&#25968;&#65292;&#22240;&#27492;&#25105;&#20204;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#26377;&#25928;&#22320;&#20174;&#22270;&#25968;&#25454;&#38598;&#65288;&#20107;&#20808;&#21487;&#29992;&#25110;&#20174;&#24050;&#30693;&#20998;&#24067;&#29983;&#25104;&#65289;&#20272;&#35745;&#24471;&#20998;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel algorithm for the support estimation of partially known Gaussian graphical models that incorporates prior information about the underlying graph. In contrast to classical approaches that provide a point estimate based on a maximum likelihood or a maximum a posteriori criterion using (simple) priors on the precision matrix, we consider a prior on the graph and rely on annealed Langevin diffusion to generate samples from the posterior distribution. Since the Langevin sampler requires access to the score function of the underlying graph prior, we use graph neural networks to effectively estimate the score from a graph dataset (either available beforehand or generated from a known distribution). Numerical experiments demonstrate the benefits of our approach.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20960;&#20046;&#31561;&#21464;&#24615;&#30340;&#20027;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#19981;&#21516;&#20110;&#29616;&#26377;&#23450;&#20041;&#30340;&#20960;&#20046;&#31561;&#21464;&#24615;&#23450;&#20041;&#65292;&#24182;&#36890;&#36807;&#21033;&#29992;&#26446;&#32676;&#30340;&#26446;&#20195;&#25968;&#32473;&#20986;&#20102;&#22312;&#27169;&#22411;&#20013;&#32534;&#30721;&#20960;&#20046;&#31561;&#21464;&#24615;&#30340;&#23454;&#29992;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.13164</link><description>&lt;p&gt;
&#20960;&#20046;&#31561;&#21464;&#24615;&#36890;&#36807;&#26446;&#20195;&#25968;&#21367;&#31215;
&lt;/p&gt;
&lt;p&gt;
Almost Equivariance via Lie Algebra Convolutions. (arXiv:2310.13164v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13164
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20960;&#20046;&#31561;&#21464;&#24615;&#30340;&#20027;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#19981;&#21516;&#20110;&#29616;&#26377;&#23450;&#20041;&#30340;&#20960;&#20046;&#31561;&#21464;&#24615;&#23450;&#20041;&#65292;&#24182;&#36890;&#36807;&#21033;&#29992;&#26446;&#32676;&#30340;&#26446;&#20195;&#25968;&#32473;&#20986;&#20102;&#22312;&#27169;&#22411;&#20013;&#32534;&#30721;&#20960;&#20046;&#31561;&#21464;&#24615;&#30340;&#23454;&#29992;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#27169;&#22411;&#30456;&#23545;&#20110;&#32676;&#20316;&#29992;&#30340;&#31561;&#21464;&#24615;&#24050;&#25104;&#20026;&#19968;&#20010;&#37325;&#35201;&#30340;&#30740;&#31350;&#35838;&#39064;&#12290;&#28982;&#32780;&#65292;&#36171;&#20104;&#19968;&#20010;&#26550;&#26500;&#20855;&#20307;&#30340;&#32676;&#31561;&#21464;&#24615;&#23545;&#27169;&#22411;&#25152;&#26399;&#26395;&#30475;&#21040;&#30340;&#25968;&#25454;&#21464;&#25442;&#31867;&#22411;&#26045;&#21152;&#20102;&#24378;&#22823;&#30340;&#20808;&#39564;&#12290;&#20005;&#26684;&#31561;&#21464;&#27169;&#22411;&#24378;&#21046;&#25191;&#34892;&#23545;&#31216;&#24615;&#65292;&#20294;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#24182;&#19981;&#24635;&#26159;&#31526;&#21512;&#36825;&#26679;&#30340;&#20005;&#26684;&#31561;&#21464;&#24615;&#65292;&#21487;&#33021;&#26159;&#22240;&#20026;&#25968;&#25454;&#20013;&#30340;&#22122;&#22768;&#25110;&#20165;&#32534;&#30721;&#20102;&#36817;&#20284;&#25110;&#37096;&#20998;&#23545;&#31216;&#24615;&#30340;&#28508;&#22312;&#29289;&#29702;&#23450;&#24459;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20005;&#26684;&#31561;&#21464;&#24615;&#30340;&#20808;&#39564;&#23454;&#38469;&#19978;&#21487;&#33021;&#36807;&#20110;&#24378;&#22823;&#65292;&#23548;&#33268;&#27169;&#22411;&#22312;&#30495;&#23454;&#25968;&#25454;&#19978;&#34920;&#29616;&#19981;&#20339;&#12290;&#22240;&#27492;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#30456;&#20851;&#30340;&#20027;&#39064;&#65292;&#21363;&#20960;&#20046;&#31561;&#21464;&#24615;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#19982;&#24403;&#21069;&#25991;&#29486;&#20013;&#29616;&#26377;&#23450;&#20041;&#19981;&#21516;&#30340;&#20960;&#20046;&#31561;&#21464;&#24615;&#23450;&#20041;&#65292;&#24182;&#36890;&#36807;&#21033;&#29992;&#26446;&#32676;&#30340;&#26446;&#20195;&#25968;&#32473;&#20986;&#20102;&#22312;&#27169;&#22411;&#20013;&#32534;&#30721;&#20960;&#20046;&#31561;&#21464;&#24615;&#30340;&#23454;&#29992;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, the equivariance of models with respect to a group action has become an important topic of research in machine learning. However, imbuing an architecture with a specific group equivariance imposes a strong prior on the types of data transformations that the model expects to see. While strictly-equivariant models enforce symmetries, real-world data does not always conform to such strict equivariances, be it due to noise in the data or underlying physical laws that encode only approximate or partial symmetries. In such cases, the prior of strict equivariance can actually prove too strong and cause models to underperform on real-world data. Therefore, in this work we study a closely related topic, that of almost equivariance. We provide a definition of almost equivariance that differs from those extant in the current literature and give a practical method for encoding almost equivariance in models by appealing to the Lie algebra of a Lie group. Specifically, we define Lie algebr
&lt;/p&gt;</description></item><item><title>DataInf&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;&#24433;&#21709;&#21147;&#36817;&#20284;&#26041;&#27861;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#29983;&#25104;&#22411;AI&#27169;&#22411;&#65292;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#22312;&#35745;&#31639;&#21644;&#20869;&#23384;&#25928;&#29575;&#19978;&#26377;&#26126;&#26174;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2310.00902</link><description>&lt;p&gt;
DataInf&#65306;&#22312;LLMs&#21644;&#25193;&#25955;&#27169;&#22411;&#20013;&#39640;&#25928;&#20272;&#35745;&#25968;&#25454;&#24433;&#21709;&#21147;
&lt;/p&gt;
&lt;p&gt;
DataInf: Efficiently Estimating Data Influence in LoRA-tuned LLMs and Diffusion Models. (arXiv:2310.00902v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00902
&lt;/p&gt;
&lt;p&gt;
DataInf&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;&#24433;&#21709;&#21147;&#36817;&#20284;&#26041;&#27861;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#29983;&#25104;&#22411;AI&#27169;&#22411;&#65292;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#22312;&#35745;&#31639;&#21644;&#20869;&#23384;&#25928;&#29575;&#19978;&#26377;&#26126;&#26174;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#21270;&#35757;&#32451;&#25968;&#25454;&#28857;&#30340;&#24433;&#21709;&#21147;&#23545;&#20110;&#29702;&#35299;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#36755;&#20986;&#21644;&#25552;&#39640;AI&#31649;&#36947;&#30340;&#36879;&#26126;&#24230;&#33267;&#20851;&#37325;&#35201;&#12290;&#24433;&#21709;&#20989;&#25968;&#26159;&#19968;&#31181;&#21407;&#21017;&#24615;&#21644;&#27969;&#34892;&#30340;&#25968;&#25454;&#24402;&#23646;&#26041;&#27861;&#65292;&#20294;&#20854;&#35745;&#31639;&#25104;&#26412;&#20351;&#20854;&#38590;&#20197;&#20351;&#29992;&#12290;&#36825;&#20010;&#38382;&#39064;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#25991;&#26412;&#21040;&#22270;&#20687;&#27169;&#22411;&#30340;&#35774;&#32622;&#20013;&#26356;&#21152;&#31361;&#20986;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;DataInf&#65292;&#19968;&#31181;&#39640;&#25928;&#30340;&#24433;&#21709;&#21147;&#36817;&#20284;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#29983;&#25104;&#22411;AI&#27169;&#22411;&#12290;&#36890;&#36807;&#21033;&#29992;&#26131;&#20110;&#35745;&#31639;&#30340;&#38381;&#24335;&#34920;&#36798;&#24335;&#65292;DataInf&#22312;&#35745;&#31639;&#21644;&#20869;&#23384;&#25928;&#29575;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#30340;&#24433;&#21709;&#35745;&#31639;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;DataInf&#29305;&#21035;&#36866;&#29992;&#20110;&#35832;&#22914;LoRA&#30340;&#21442;&#25968;&#26377;&#25928;&#24494;&#35843;&#25216;&#26415;&#12290;&#36890;&#36807;&#31995;&#32479;&#30340;&#23454;&#35777;&#35780;&#20272;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;DataInf&#33021;&#22815;&#20934;&#30830;&#22320;&#36817;&#20284;&#24433;&#21709;&#20998;&#25968;&#65292;&#24182;&#19988;&#27604;&#29616;&#26377;&#26041;&#27861;&#24555;&#20960;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantifying the impact of training data points is crucial for understanding the outputs of machine learning models and for improving the transparency of the AI pipeline. The influence function is a principled and popular data attribution method, but its computational cost often makes it challenging to use. This issue becomes more pronounced in the setting of large language models and text-to-image models. In this work, we propose DataInf, an efficient influence approximation method that is practical for large-scale generative AI models. Leveraging an easy-to-compute closed-form expression, DataInf outperforms existing influence computation algorithms in terms of computational and memory efficiency. Our theoretical analysis shows that DataInf is particularly well-suited for parameter-efficient fine-tuning techniques such as LoRA. Through systematic empirical evaluations, we show that DataInf accurately approximates influence scores and is orders of magnitude faster than existing methods
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#21367;&#31215;&#28145;&#24230;&#26680;&#26426;&#22120;&#30340;&#26032;&#22411;&#26680;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#32431;&#31929;&#20351;&#29992;&#26680;&#32780;&#19981;&#20351;&#29992;&#29305;&#24449;&#65292;&#36890;&#36807;&#39640;&#25928;&#30340;&#36328;&#22495;&#35825;&#23548;&#28857;&#36817;&#20284;&#26041;&#26696;&#21644;&#22810;&#31181;&#27169;&#22411;&#21464;&#20307;&#30340;&#35774;&#35745;&#65292;&#36798;&#21040;&#20102;&#22312;MNIST&#12289;CIFAR-10&#21644;CIFAR-100&#19978;&#25509;&#36817;&#29978;&#33267;&#36229;&#36807;&#20854;&#20182;&#26041;&#27861;&#30340;&#27979;&#35797;&#20934;&#30830;&#29575;&#12290;</title><link>http://arxiv.org/abs/2309.09814</link><description>&lt;p&gt;
&#21367;&#31215;&#28145;&#24230;&#26680;&#26426;&#22120;
&lt;/p&gt;
&lt;p&gt;
Convolutional Deep Kernel Machines. (arXiv:2309.09814v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09814
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#21367;&#31215;&#28145;&#24230;&#26680;&#26426;&#22120;&#30340;&#26032;&#22411;&#26680;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#32431;&#31929;&#20351;&#29992;&#26680;&#32780;&#19981;&#20351;&#29992;&#29305;&#24449;&#65292;&#36890;&#36807;&#39640;&#25928;&#30340;&#36328;&#22495;&#35825;&#23548;&#28857;&#36817;&#20284;&#26041;&#26696;&#21644;&#22810;&#31181;&#27169;&#22411;&#21464;&#20307;&#30340;&#35774;&#35745;&#65292;&#36798;&#21040;&#20102;&#22312;MNIST&#12289;CIFAR-10&#21644;CIFAR-100&#19978;&#25509;&#36817;&#29978;&#33267;&#36229;&#36807;&#20854;&#20182;&#26041;&#27861;&#30340;&#27979;&#35797;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#26680;&#26426;&#22120;(DKMs)&#26159;&#19968;&#31181;&#26368;&#36817;&#24341;&#20837;&#30340;&#20855;&#26377;&#20854;&#20182;&#28145;&#24230;&#27169;&#22411;&#28789;&#27963;&#24615;&#30340;&#26680;&#26041;&#27861;&#65292;&#21253;&#25324;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#28145;&#24230;&#39640;&#26031;&#36807;&#31243;&#12290;DKMs&#32431;&#31929;&#20351;&#29992;&#26680;&#65292;&#32780;&#19981;&#20351;&#29992;&#29305;&#24449;&#65292;&#22240;&#27492;&#19982;&#20854;&#20182;&#26041;&#27861;&#65288;&#20174;&#31070;&#32463;&#32593;&#32476;&#21040;&#28145;&#24230;&#26680;&#23398;&#20064;&#29978;&#33267;&#28145;&#24230;&#39640;&#26031;&#36807;&#31243;&#65289;&#19981;&#21516;&#65292;&#21518;&#32773;&#37117;&#20351;&#29992;&#29305;&#24449;&#20316;&#20026;&#22522;&#26412;&#32452;&#25104;&#37096;&#20998;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#21367;&#31215;DKMs&#65292;&#24182;&#37197;&#20197;&#19968;&#31181;&#39640;&#25928;&#30340;&#36328;&#22495;&#35825;&#23548;&#28857;&#36817;&#20284;&#26041;&#26696;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#24182;&#23454;&#39564;&#35780;&#20272;&#20102;&#35768;&#22810;&#27169;&#22411;&#21464;&#20307;&#65292;&#21253;&#25324;9&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#20026;&#21367;&#31215;DKMs&#35774;&#35745;&#30340;&#24402;&#19968;&#21270;&#26041;&#27861;&#65292;&#20004;&#31181;&#20284;&#28982;&#20989;&#25968;&#21644;&#20004;&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#39030;&#23618;&#12290;&#23613;&#31649;&#21482;&#22312;&#32422;28&#20010;GPU&#23567;&#26102;&#20869;&#35757;&#32451;&#65288;&#27604;&#23436;&#20840;&#30340;NNGP / NTK / Myrtle kernel&#24555;1-2&#20010;&#25968;&#37327;&#32423;&#65289;&#65292;&#20294;&#24471;&#21040;&#30340;&#27169;&#22411;&#22312;MNIST&#19978;&#23454;&#29616;&#20102;&#32422;99&#65285;&#30340;&#27979;&#35797;&#20934;&#30830;&#24615;&#65292;&#22312;CIFAR-10&#19978;&#20026;92&#65285;&#65292;&#22312;CIFAR-100&#19978;&#20026;71&#65285;&#65292;&#21516;&#26102;&#36798;&#21040;&#21487;&#27604;&#36739;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep kernel machines (DKMs) are a recently introduced kernel method with the flexibility of other deep models including deep NNs and deep Gaussian processes. DKMs work purely with kernels, never with features, and are therefore different from other methods ranging from NNs to deep kernel learning and even deep Gaussian processes, which all use features as a fundamental component. Here, we introduce convolutional DKMs, along with an efficient inter-domain inducing point approximation scheme. Further, we develop and experimentally assess a number of model variants, including 9 different types of normalisation designed for the convolutional DKMs, two likelihoods, and two different types of top-layer. The resulting models achieve around 99% test accuracy on MNIST, 92% on CIFAR-10 and 71% on CIFAR-100, despite training in only around 28 GPU hours, 1-2 orders of magnitude faster than full NNGP / NTK / Myrtle kernels, whilst achieving comparable performance.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20840;&#23556;&#24207;&#21015;&#31070;&#32463;&#20284;&#28982;&#20272;&#35745;&#65288;SSNL&#65289;&#36827;&#34892;&#22522;&#20110;&#20223;&#30495;&#30340;&#25512;&#26029;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#27169;&#22411;&#20013;&#26080;&#27861;&#35745;&#31639;&#20284;&#28982;&#20989;&#25968;&#24182;&#19988;&#21482;&#33021;&#20351;&#29992;&#27169;&#25311;&#22120;&#29983;&#25104;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;SSNL&#36890;&#36807;&#25311;&#21512;&#38477;&#32500;&#30340;&#20840;&#23556;&#24402;&#19968;&#21270;&#27969;&#27169;&#22411;&#65292;&#24182;&#23558;&#20854;&#20316;&#20026;&#26367;&#20195;&#20284;&#28982;&#20989;&#25968;&#65292;&#35299;&#20915;&#20102;&#20808;&#21069;&#22522;&#20110;&#20284;&#28982;&#26041;&#27861;&#22312;&#39640;&#32500;&#25968;&#25454;&#38598;&#20013;&#36935;&#21040;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#21508;&#31181;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.01054</link><description>&lt;p&gt;
&#20351;&#29992;&#20840;&#23556;&#24207;&#21015;&#31070;&#32463;&#20284;&#28982;&#20272;&#35745;&#36827;&#34892;&#22522;&#20110;&#20223;&#30495;&#30340;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Simulation-based inference using surjective sequential neural likelihood estimation. (arXiv:2308.01054v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01054
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20840;&#23556;&#24207;&#21015;&#31070;&#32463;&#20284;&#28982;&#20272;&#35745;&#65288;SSNL&#65289;&#36827;&#34892;&#22522;&#20110;&#20223;&#30495;&#30340;&#25512;&#26029;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#27169;&#22411;&#20013;&#26080;&#27861;&#35745;&#31639;&#20284;&#28982;&#20989;&#25968;&#24182;&#19988;&#21482;&#33021;&#20351;&#29992;&#27169;&#25311;&#22120;&#29983;&#25104;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;SSNL&#36890;&#36807;&#25311;&#21512;&#38477;&#32500;&#30340;&#20840;&#23556;&#24402;&#19968;&#21270;&#27969;&#27169;&#22411;&#65292;&#24182;&#23558;&#20854;&#20316;&#20026;&#26367;&#20195;&#20284;&#28982;&#20989;&#25968;&#65292;&#35299;&#20915;&#20102;&#20808;&#21069;&#22522;&#20110;&#20284;&#28982;&#26041;&#27861;&#22312;&#39640;&#32500;&#25968;&#25454;&#38598;&#20013;&#36935;&#21040;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#21508;&#31181;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#20840;&#23556;&#24207;&#21015;&#31070;&#32463;&#20284;&#28982;&#65288;SSNL&#65289;&#20272;&#35745;&#26041;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#22312;&#27169;&#22411;&#20013;&#26080;&#27861;&#35745;&#31639;&#20284;&#28982;&#20989;&#25968;&#24182;&#19988;&#21482;&#33021;&#20351;&#29992;&#21487;&#20197;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#30340;&#27169;&#25311;&#22120;&#26102;&#36827;&#34892;&#22522;&#20110;&#20223;&#30495;&#30340;&#25512;&#26029;&#30340;&#26032;&#26041;&#27861;&#12290;SSNL&#25311;&#21512;&#19968;&#20010;&#38477;&#32500;&#30340;&#20840;&#23556;&#24402;&#19968;&#21270;&#27969;&#27169;&#22411;&#65292;&#24182;&#23558;&#20854;&#29992;&#20316;&#26367;&#20195;&#20284;&#28982;&#20989;&#25968;&#65292;&#20174;&#32780;&#21487;&#20197;&#20351;&#29992;&#20256;&#32479;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#21253;&#25324;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#25110;&#21464;&#20998;&#25512;&#26029;&#12290;&#36890;&#36807;&#23558;&#25968;&#25454;&#23884;&#20837;&#21040;&#20302;&#32500;&#31354;&#38388;&#20013;&#65292;SSNL&#35299;&#20915;&#20102;&#20808;&#21069;&#22522;&#20110;&#20284;&#28982;&#26041;&#27861;&#22312;&#24212;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#38598;&#26102;&#36935;&#21040;&#30340;&#20960;&#20010;&#38382;&#39064;&#65292;&#20363;&#22914;&#21253;&#21547;&#26080;&#20449;&#24687;&#25968;&#25454;&#32500;&#24230;&#25110;&#20301;&#20110;&#36739;&#20302;&#32500;&#27969;&#24418;&#19978;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#23545;SSNL&#22312;&#21508;&#31181;&#23454;&#39564;&#20013;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#24182;&#34920;&#26126;&#23427;&#36890;&#24120;&#20248;&#20110;&#22312;&#22522;&#20110;&#20223;&#30495;&#25512;&#26029;&#20013;&#20351;&#29992;&#30340;&#29616;&#20195;&#26041;&#27861;&#65292;&#20363;&#22914;&#22312;&#19968;&#39033;&#26469;&#33258;&#22825;&#20307;&#29289;&#29702;&#23398;&#30340;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#30495;&#23454;&#19990;&#30028;&#20363;&#23376;&#19978;&#23545;&#30913;&#22330;&#27169;&#22411;&#30340;&#24314;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present Surjective Sequential Neural Likelihood (SSNL) estimation, a novel method for simulation-based inference in models where the evaluation of the likelihood function is not tractable and only a simulator that can generate synthetic data is available. SSNL fits a dimensionality-reducing surjective normalizing flow model and uses it as a surrogate likelihood function which allows for conventional Bayesian inference using either Markov chain Monte Carlo methods or variational inference. By embedding the data in a low-dimensional space, SSNL solves several issues previous likelihood-based methods had when applied to high-dimensional data sets that, for instance, contain non-informative data dimensions or lie along a lower-dimensional manifold. We evaluate SSNL on a wide variety of experiments and show that it generally outperforms contemporary methods used in simulation-based inference, for instance, on a challenging real-world example from astrophysics which models the magnetic fi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#28909;&#21147;&#23398;&#32422;&#26463;&#29366;&#24577;&#26041;&#31243;&#65292;&#24182;&#36827;&#34892;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#20197;&#25552;&#39640;&#26041;&#31243;&#39044;&#27979;&#30340;&#21487;&#20449;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.17004</link><description>&lt;p&gt;
&#23398;&#20064;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#28909;&#21147;&#23398;&#32422;&#26463;&#29366;&#24577;&#26041;&#31243;
&lt;/p&gt;
&lt;p&gt;
Learning thermodynamically constrained equations of state with uncertainty. (arXiv:2306.17004v1 [physics.data-an])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17004
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#28909;&#21147;&#23398;&#32422;&#26463;&#29366;&#24577;&#26041;&#31243;&#65292;&#24182;&#36827;&#34892;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#20197;&#25552;&#39640;&#26041;&#31243;&#39044;&#27979;&#30340;&#21487;&#20449;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#33021;&#37327;&#23494;&#24230;&#23454;&#39564;&#30340;&#25968;&#20540;&#27169;&#25311;&#38656;&#35201;&#26041;&#31243;&#29366;&#24577;&#27169;&#22411;&#65288;EOS&#65289;&#65292;&#29992;&#20110;&#20851;&#32852;&#26448;&#26009;&#30340;&#28909;&#21147;&#23398;&#29366;&#24577;&#21464;&#37327; - &#21363;&#21387;&#21147;&#12289;&#20307;&#31215;/&#23494;&#24230;&#12289;&#33021;&#37327;&#21644;&#28201;&#24230;&#12290;EOS&#27169;&#22411;&#36890;&#24120;&#37319;&#29992;&#21322;&#32463;&#39564;&#24615;&#21442;&#25968;&#21270;&#26041;&#27861;&#26500;&#24314;&#65292;&#20551;&#23450;&#20855;&#26377;&#19982;&#29289;&#29702;&#30456;&#20851;&#30340;&#20989;&#25968;&#24418;&#24335;&#65292;&#24182;&#20351;&#29992;&#23454;&#39564;/&#27169;&#25311;&#25968;&#25454;&#36827;&#34892;&#26657;&#20934;&#12290;&#30001;&#20110;&#26657;&#20934;&#25968;&#25454;&#65288;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#65289;&#21644;&#20551;&#23450;&#30340;EOS&#20989;&#25968;&#24418;&#24335;&#65288;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#65289;&#20013;&#23384;&#22312;&#22266;&#26377;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#25191;&#34892;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65288;UQ&#65289;&#20197;&#25552;&#39640;EOS&#39044;&#27979;&#30340;&#21487;&#20449;&#24230;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#23545;&#20110;UQ&#30740;&#31350;&#26469;&#35828;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#23427;&#38656;&#35201;&#25506;&#32034;&#25152;&#26377;&#21487;&#33021;&#30340;&#29289;&#29702;&#19968;&#33268;&#30340;&#20989;&#25968;&#24418;&#24335;&#31354;&#38388;&#12290;&#22240;&#27492;&#65292;&#36890;&#24120;&#22312;&#19981;&#36829;&#21453;&#28909;&#21147;&#23398;&#23450;&#24459;&#30340;&#24773;&#20917;&#19979;&#24573;&#30053;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#32780;&#20559;&#21521;&#20110;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#26469;&#23398;&#20064;EOS&#27169;&#22411;&#30340;&#28909;&#21147;&#23398;&#32422;&#26463;&#26041;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Numerical simulations of high energy-density experiments require equation of state (EOS) models that relate a material's thermodynamic state variables -specifically pressure, volume/density, energy, and temperature. EOS models are typically constructed using a semi-empirical parametric methodology, which assumes a physics-informed functional form with many tunable parameters calibrated using experimental/simulation data. Since there are inherent uncertainties in the calibration data (parametric uncertainty) and the assumed functional EOS form (model uncertainty), it is essential to perform uncertainty quantification (UQ) to improve confidence in the EOS predictions. Model uncertainty is challenging for UQ studies since it requires exploring the space of all possible physically consistent functional forms. Thus, it is often neglected in favor of parametric uncertainty, which is easier to quantify without violating thermodynamic laws. This work presents a data-driven machine learning a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#22522;&#20110;&#20027;&#21160;&#35810;&#38382;&#20915;&#31574;&#32773;&#20010;&#20154;&#20559;&#22909;&#30340;&#32622;&#20449;&#24230;&#26500;&#36896;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#32622;&#20449;&#24230;&#23545;&#20110;&#20915;&#31574;&#32773;&#20449;&#20219;&#20915;&#31574;&#30340;&#19981;&#20934;&#30830;&#38382;&#39064;&#65292;&#20174;&#32780;&#25552;&#39640;&#20915;&#31574;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.00074</link><description>&lt;p&gt;
&#20154;&#31867;&#23545;&#40784;&#26657;&#20934;&#29992;&#20110;AI&#36741;&#21161;&#20915;&#31574;&#21046;&#23450;
&lt;/p&gt;
&lt;p&gt;
Human-Aligned Calibration for AI-Assisted Decision Making. (arXiv:2306.00074v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00074
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#22522;&#20110;&#20027;&#21160;&#35810;&#38382;&#20915;&#31574;&#32773;&#20010;&#20154;&#20559;&#22909;&#30340;&#32622;&#20449;&#24230;&#26500;&#36896;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#32622;&#20449;&#24230;&#23545;&#20110;&#20915;&#31574;&#32773;&#20449;&#20219;&#20915;&#31574;&#30340;&#19981;&#20934;&#30830;&#38382;&#39064;&#65292;&#20174;&#32780;&#25552;&#39640;&#20915;&#31574;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20351;&#29992;&#20108;&#20803;&#20998;&#31867;&#22120;&#25552;&#20379;&#20915;&#31574;&#25903;&#25345;&#26102;&#65292;&#23427;&#36890;&#24120;&#25552;&#20379;&#26631;&#31614;&#39044;&#27979;&#21644;&#32622;&#20449;&#24230;&#20540;&#12290;&#28982;&#21518;&#65292;&#20915;&#31574;&#32773;&#24212;&#20351;&#29992;&#32622;&#20449;&#24230;&#20540;&#26469;&#26657;&#20934;&#23545;&#39044;&#27979;&#30340;&#20449;&#20219;&#31243;&#24230;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20154;&#20204;&#32463;&#24120;&#35748;&#20026;&#32622;&#20449;&#24230;&#20540;&#24212;&#23545;&#39044;&#27979;&#26631;&#31614;&#19982;&#23454;&#38469;&#26631;&#31614;&#21305;&#37197;&#30340;&#27010;&#29575;&#36827;&#34892;&#33391;&#22909;&#26657;&#20934;&#30340;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#22810;&#26465;&#23454;&#35777;&#35777;&#25454;&#34920;&#26126;&#65292;&#20915;&#31574;&#32773;&#38590;&#20197;&#20351;&#29992;&#36825;&#20123;&#32622;&#20449;&#24230;&#20540;&#24456;&#22909;&#22320;&#30830;&#23450;&#20309;&#26102;&#20449;&#20219;&#39044;&#27979;&#12290;&#26412;&#25991;&#30340;&#30446;&#26631;&#39318;&#20808;&#26159;&#29702;&#35299;&#20026;&#20160;&#20040;&#65292;&#28982;&#21518;&#30740;&#31350;&#22914;&#20309;&#26500;&#24314;&#26356;&#26377;&#29992;&#30340;&#32622;&#20449;&#24230;&#20540;&#12290;&#25105;&#20204;&#39318;&#20808;&#35748;&#20026;&#65292;&#22312;&#24191;&#27867;&#31867;&#30340;&#25928;&#29992;&#20989;&#25968;&#20013;&#65292;&#23384;&#22312;&#25968;&#25454;&#20998;&#24067;&#65292;&#23545;&#20110;&#36825;&#20123;&#20998;&#24067;&#65292;&#29702;&#24615;&#20915;&#31574;&#32773;&#36890;&#24120;&#38590;&#20197;&#20351;&#29992;&#20197;&#19978;&#32622;&#20449;&#24230;&#20540;&#21457;&#29616;&#26368;&#20339;&#20915;&#31574;&#25919;&#31574;&#8212;&#8212;&#26368;&#20339;&#30340;&#20915;&#31574;&#32773;&#38656;&#35201;&#20154;&#31867;&#23545;&#40784;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#20027;&#21160;&#35810;&#38382;&#20915;&#31574;&#32773;&#20182;&#20204;&#22312;&#25152;&#38754;&#20020;&#30340;&#20108;&#20803;&#20998;&#31867;&#20219;&#21153;&#30340;&#20915;&#31574;&#19978;&#30340;&#20010;&#20154;&#20559;&#22909;&#30340;&#26032;&#26041;&#27861;&#26469;&#26500;&#36896;&#32622;&#20449;&#24230;&#20540;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#20135;&#29983;&#30340;&#32622;&#20449;&#24230;&#20540;&#27604;&#20351;&#29992;&#26631;&#20934;&#32622;&#20449;&#24230;&#24230;&#37327;&#23548;&#33268;&#26356;&#22909;&#30340;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;
Whenever a binary classifier is used to provide decision support, it typically provides both a label prediction and a confidence value. Then, the decision maker is supposed to use the confidence value to calibrate how much to trust the prediction. In this context, it has been often argued that the confidence value should correspond to a well calibrated estimate of the probability that the predicted label matches the ground truth label. However, multiple lines of empirical evidence suggest that decision makers have difficulties at developing a good sense on when to trust a prediction using these confidence values. In this paper, our goal is first to understand why and then investigate how to construct more useful confidence values. We first argue that, for a broad class of utility functions, there exist data distributions for which a rational decision maker is, in general, unlikely to discover the optimal decision policy using the above confidence values -- an optimal decision maker wou
&lt;/p&gt;</description></item></channel></rss>