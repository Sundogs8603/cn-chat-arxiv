<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#23558;&#28857;&#39044;&#27979;&#36716;&#25442;&#20026;&#27010;&#29575;&#39044;&#27979;&#30340;&#30005;&#21147;&#20215;&#26684;&#21518;&#22788;&#29702;&#26041;&#27861;&#20013;&#65292;&#32467;&#21512;Isotonic Distributional Regression&#19982;&#20854;&#20182;&#20004;&#31181;&#26041;&#27861;&#30340;&#39044;&#27979;&#20998;&#24067;&#21487;&#20197;&#23454;&#29616;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>https://arxiv.org/abs/2404.02270</link><description>&lt;p&gt;
&#30005;&#21147;&#20215;&#26684;&#27010;&#29575;&#39044;&#27979;&#30340;&#28857;&#39044;&#27979;&#21518;&#22788;&#29702;&#65306;&#22810;&#26679;&#24615;&#33267;&#20851;&#37325;&#35201;
&lt;/p&gt;
&lt;p&gt;
Postprocessing of point predictions for probabilistic forecasting of electricity prices: Diversity matters
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02270
&lt;/p&gt;
&lt;p&gt;
&#23558;&#28857;&#39044;&#27979;&#36716;&#25442;&#20026;&#27010;&#29575;&#39044;&#27979;&#30340;&#30005;&#21147;&#20215;&#26684;&#21518;&#22788;&#29702;&#26041;&#27861;&#20013;&#65292;&#32467;&#21512;Isotonic Distributional Regression&#19982;&#20854;&#20182;&#20004;&#31181;&#26041;&#27861;&#30340;&#39044;&#27979;&#20998;&#24067;&#21487;&#20197;&#23454;&#29616;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20381;&#36182;&#20110;&#30005;&#21147;&#20215;&#26684;&#30340;&#39044;&#27979;&#20998;&#24067;&#36827;&#34892;&#25805;&#20316;&#20915;&#31574;&#30456;&#36739;&#20110;&#20165;&#22522;&#20110;&#28857;&#39044;&#27979;&#30340;&#20915;&#31574;&#21487;&#20197;&#24102;&#26469;&#26174;&#33879;&#26356;&#39640;&#30340;&#21033;&#28070;&#12290;&#28982;&#32780;&#65292;&#22312;&#23398;&#26415;&#21644;&#24037;&#19994;&#29615;&#22659;&#20013;&#24320;&#21457;&#30340;&#22823;&#22810;&#25968;&#27169;&#22411;&#20165;&#25552;&#20379;&#28857;&#39044;&#27979;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19977;&#31181;&#23558;&#28857;&#39044;&#27979;&#36716;&#25442;&#20026;&#27010;&#29575;&#39044;&#27979;&#30340;&#21518;&#22788;&#29702;&#26041;&#27861;&#65306;&#20998;&#20301;&#25968;&#22238;&#24402;&#24179;&#22343;&#12289;&#19968;&#33268;&#24615;&#39044;&#27979;&#21644;&#26368;&#36817;&#24341;&#20837;&#30340;&#31561;&#28201;&#20998;&#24067;&#22238;&#24402;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#34429;&#28982;&#31561;&#28201;&#20998;&#24067;&#22238;&#24402;&#34920;&#29616;&#26368;&#20026;&#22810;&#26679;&#21270;&#65292;&#20294;&#23558;&#20854;&#39044;&#27979;&#20998;&#24067;&#19982;&#21478;&#22806;&#20004;&#31181;&#26041;&#27861;&#32467;&#21512;&#20351;&#29992;&#65292;&#30456;&#36739;&#20110;&#20855;&#26377;&#27491;&#24577;&#20998;&#24067;&#35823;&#24046;&#30340;&#22522;&#20934;&#27169;&#22411;&#65292;&#22312;&#24503;&#22269;&#30005;&#21147;&#24066;&#22330;&#30340;4.5&#24180;&#27979;&#35797;&#26399;&#38388;&#65288;&#28085;&#30422;COVID&#22823;&#27969;&#34892;&#21644;&#20044;&#20811;&#20848;&#25112;&#20105;&#65289;&#65292;&#23454;&#29616;&#20102;&#32422;7.5%&#30340;&#25913;&#36827;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#31181;&#32452;&#21512;&#30340;&#24615;&#33021;&#19982;&#26368;&#20808;&#36827;&#30340;Dis
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02270v1 Announce Type: new  Abstract: Operational decisions relying on predictive distributions of electricity prices can result in significantly higher profits compared to those based solely on point forecasts. However, the majority of models developed in both academic and industrial settings provide only point predictions. To address this, we examine three postprocessing methods for converting point forecasts into probabilistic ones: Quantile Regression Averaging, Conformal Prediction, and the recently introduced Isotonic Distributional Regression. We find that while IDR demonstrates the most varied performance, combining its predictive distributions with those of the other two methods results in an improvement of ca. 7.5% compared to a benchmark model with normally distributed errors, over a 4.5-year test period in the German power market spanning the COVID pandemic and the war in Ukraine. Remarkably, the performance of this combination is at par with state-of-the-art Dis
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;&#20110;RMSProp&#21644;Adam&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#32039;&#33268;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#39318;&#27425;&#23637;&#31034;&#20102;&#22312;&#26368;&#23485;&#26494;&#30340;&#20551;&#35774;&#19979;&#30340;&#25910;&#25947;&#24615;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;RMSProp&#21644;Adam&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#20998;&#21035;&#20026;$\mathcal O(\epsilon^{-4})$&#12290;</title><link>https://arxiv.org/abs/2404.01436</link><description>&lt;p&gt;
RMSProp&#21644;Adam&#22312;&#20855;&#26377;&#20223;&#23556;&#22122;&#22768;&#26041;&#24046;&#30340;&#24191;&#20041;&#20809;&#28369;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Convergence Guarantees for RMSProp and Adam in Generalized-smooth Non-convex Optimization with Affine Noise Variance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01436
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;&#20110;RMSProp&#21644;Adam&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#32039;&#33268;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#39318;&#27425;&#23637;&#31034;&#20102;&#22312;&#26368;&#23485;&#26494;&#30340;&#20551;&#35774;&#19979;&#30340;&#25910;&#25947;&#24615;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;RMSProp&#21644;Adam&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#20998;&#21035;&#20026;$\mathcal O(\epsilon^{-4})$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#22352;&#26631;&#32423;&#21035;&#24191;&#20041;&#20809;&#28369;&#24615;&#21644;&#20223;&#23556;&#22122;&#22768;&#26041;&#24046;&#30340;&#26368;&#23485;&#26494;&#20551;&#35774;&#19979;&#65292;&#20026;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;RMSProp&#21644;Adam&#25552;&#20379;&#20102;&#39318;&#20010;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;&#39318;&#20808;&#20998;&#26512;&#20102;RMSProp&#65292;&#23427;&#26159;&#19968;&#31181;&#20855;&#26377;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#20294;&#27809;&#26377;&#19968;&#38454;&#21160;&#37327;&#30340;Adam&#30340;&#29305;&#20363;&#12290;&#20855;&#20307;&#22320;&#65292;&#20026;&#20102;&#35299;&#20915;&#33258;&#36866;&#24212;&#26356;&#26032;&#12289;&#26080;&#30028;&#26799;&#24230;&#20272;&#35745;&#21644;Lipschitz&#24120;&#25968;&#20043;&#38388;&#30340;&#20381;&#36182;&#25361;&#25112;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19979;&#38477;&#24341;&#29702;&#20013;&#30340;&#19968;&#38454;&#39033;&#25910;&#25947;&#65292;&#24182;&#19988;&#20854;&#20998;&#27597;&#30001;&#26799;&#24230;&#33539;&#25968;&#30340;&#20989;&#25968;&#19978;&#30028;&#38480;&#21046;&#12290;&#22522;&#20110;&#36825;&#19968;&#32467;&#26524;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#36866;&#24403;&#30340;&#36229;&#21442;&#25968;&#30340;RMSProp&#25910;&#25947;&#21040;&#19968;&#20010;$\epsilon$-&#31283;&#23450;&#28857;&#65292;&#20854;&#36845;&#20195;&#22797;&#26434;&#24230;&#20026;$\mathcal O(\epsilon^{-4})$&#12290;&#28982;&#21518;&#65292;&#23558;&#25105;&#20204;&#30340;&#20998;&#26512;&#25512;&#24191;&#21040;Adam&#65292;&#39069;&#22806;&#30340;&#25361;&#25112;&#26159;&#30001;&#20110;&#26799;&#24230;&#19982;&#19968;&#38454;&#21160;&#37327;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#19978;&#30028;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01436v1 Announce Type: cross  Abstract: This paper provides the first tight convergence analyses for RMSProp and Adam in non-convex optimization under the most relaxed assumptions of coordinate-wise generalized smoothness and affine noise variance. We first analyze RMSProp, which is a special case of Adam with adaptive learning rates but without first-order momentum. Specifically, to solve the challenges due to dependence among adaptive update, unbounded gradient estimate and Lipschitz constant, we demonstrate that the first-order term in the descent lemma converges and its denominator is upper bounded by a function of gradient norm. Based on this result, we show that RMSProp with proper hyperparameters converges to an $\epsilon$-stationary point with an iteration complexity of $\mathcal O(\epsilon^{-4})$. We then generalize our analysis to Adam, where the additional challenge is due to a mismatch between the gradient and first-order momentum. We develop a new upper bound on
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24191;&#20041;&#26368;&#20339;&#21452;&#36194;&#32447;&#24615;&#32972;&#26223;&#24378;&#21270;&#22411;&#36172;&#21338;&#26426;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#27425;&#20248;&#24615;&#24046;&#36317;&#21463;&#21040;&#19979;&#30028;&#38480;&#21046;&#26102;&#36951;&#25022;&#20026;$O(\log(T))$&#12290;&#21516;&#26102;&#24341;&#20837;&#20102;&#36793;&#32536;&#26465;&#20214;&#26469;&#25551;&#36848;&#27425;&#20248;&#24615;&#24046;&#36317;&#23545;&#38382;&#39064;&#38590;&#24230;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2403.03219</link><description>&lt;p&gt;
LC-Tsalis-INF: &#24191;&#20041;&#26368;&#20339;&#21452;&#36194;&#32447;&#24615;&#32972;&#26223;&#24378;&#21270;&#22411;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
LC-Tsalis-INF: Generalized Best-of-Both-Worlds Linear Contextual Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03219
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24191;&#20041;&#26368;&#20339;&#21452;&#36194;&#32447;&#24615;&#32972;&#26223;&#24378;&#21270;&#22411;&#36172;&#21338;&#26426;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#27425;&#20248;&#24615;&#24046;&#36317;&#21463;&#21040;&#19979;&#30028;&#38480;&#21046;&#26102;&#36951;&#25022;&#20026;$O(\log(T))$&#12290;&#21516;&#26102;&#24341;&#20837;&#20102;&#36793;&#32536;&#26465;&#20214;&#26469;&#25551;&#36848;&#27425;&#20248;&#24615;&#24046;&#36317;&#23545;&#38382;&#39064;&#38590;&#24230;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#32771;&#34385;&#20855;&#26377;&#29420;&#31435;&#21516;&#20998;&#24067;&#65288;i.i.d.&#65289;&#32972;&#26223;&#30340;&#32447;&#24615;&#32972;&#26223;&#24378;&#21270;&#22411;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#29616;&#26377;&#30740;&#31350;&#25552;&#20986;&#20102;&#26368;&#20339;&#21452;&#36194;&#65288;BoBW&#65289;&#31639;&#27861;&#65292;&#20854;&#36951;&#25022;&#22312;&#38543;&#26426;&#21306;&#22495;&#20013;&#28385;&#36275;$O(\log^2(T))$&#65292;&#20854;&#20013;$T$&#20026;&#22238;&#21512;&#25968;&#65292;&#20854;&#27425;&#20248;&#24615;&#24046;&#36317;&#30001;&#27491;&#24120;&#25968;&#19979;&#30028;&#65292;&#21516;&#26102;&#22312;&#23545;&#25239;&#24615;&#21306;&#22495;&#20013;&#28385;&#36275;$O(\sqrt{T})$&#12290;&#28982;&#32780;&#65292;&#23545;$T$&#30340;&#20381;&#36182;&#20173;&#26377;&#25913;&#36827;&#31354;&#38388;&#65292;&#24182;&#19988;&#27425;&#20248;&#24615;&#24046;&#36317;&#30340;&#20551;&#35774;&#21487;&#20197;&#25918;&#23485;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;&#65292;&#24403;&#27425;&#20248;&#24615;&#24046;&#36317;&#21463;&#21040;&#19979;&#30028;&#38480;&#21046;&#26102;&#65292;&#20854;&#36951;&#25022;&#28385;&#36275;$O(\log(T))$&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#36793;&#32536;&#26465;&#20214;&#65292;&#21363;&#23545;&#27425;&#20248;&#24615;&#24046;&#36317;&#30340;&#19968;&#20010;&#26356;&#28201;&#21644;&#30340;&#20551;&#35774;&#12290;&#35813;&#26465;&#20214;&#20351;&#29992;&#21442;&#25968;$\beta \in (0, \infty]$&#34920;&#24449;&#19982;&#27425;&#20248;&#24615;&#24046;&#36317;&#30456;&#20851;&#30340;&#38382;&#39064;&#38590;&#24230;&#12290;&#28982;&#21518;&#25105;&#20204;&#35777;&#26126;&#35813;&#31639;&#27861;&#30340;&#36951;&#25022;&#28385;&#36275;$O\left(\
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03219v1 Announce Type: new  Abstract: This study considers the linear contextual bandit problem with independent and identically distributed (i.i.d.) contexts. In this problem, existing studies have proposed Best-of-Both-Worlds (BoBW) algorithms whose regrets satisfy $O(\log^2(T))$ for the number of rounds $T$ in a stochastic regime with a suboptimality gap lower-bounded by a positive constant, while satisfying $O(\sqrt{T})$ in an adversarial regime. However, the dependency on $T$ has room for improvement, and the suboptimality-gap assumption can be relaxed. For this issue, this study proposes an algorithm whose regret satisfies $O(\log(T))$ in the setting when the suboptimality gap is lower-bounded. Furthermore, we introduce a margin condition, a milder assumption on the suboptimality gap. That condition characterizes the problem difficulty linked to the suboptimality gap using a parameter $\beta \in (0, \infty]$. We then show that the algorithm's regret satisfies $O\left(\
&lt;/p&gt;</description></item><item><title>&#23545;&#20110;&#21487;&#20998;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#27979;&#24230;&#19982;&#20854;&#32463;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#26368;&#22823;&#20999;&#29255;1-Wasserstein&#36317;&#31163;&#65292;&#24471;&#21040;&#20102;&#23574;&#38160;&#30340;&#19978;&#19979;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2403.00666</link><description>&lt;p&gt;
&#26368;&#22823;&#20999;&#29255;Wasserstein&#36317;&#31163;&#30340;&#23574;&#38160;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Sharp bounds for the max-sliced Wasserstein distance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00666
&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#21487;&#20998;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#27979;&#24230;&#19982;&#20854;&#32463;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#26368;&#22823;&#20999;&#29255;1-Wasserstein&#36317;&#31163;&#65292;&#24471;&#21040;&#20102;&#23574;&#38160;&#30340;&#19978;&#19979;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24471;&#21040;&#20102;&#20851;&#20110;&#22312;&#21487;&#20998;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#27979;&#24230;&#19982;&#20174;$n$&#20010;&#26679;&#26412;&#20013;&#33719;&#24471;&#30340;&#32463;&#39564;&#20998;&#24067;&#20043;&#38388;&#26399;&#26395;&#30340;&#26368;&#22823;&#20999;&#29255;1-Wasserstein&#36317;&#31163;&#30340;&#23574;&#38160;&#19978;&#19979;&#30028;&#12290;&#25105;&#20204;&#36824;&#24471;&#21040;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;Banach&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#27979;&#24230;&#30340;&#29256;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00666v1 Announce Type: cross  Abstract: We obtain sharp upper and lower bounds for the expected max-sliced 1-Wasserstein distance between a probability measure on a separable Hilbert space and its empirical distribution from $n$ samples. A version of this result for probability measures on Banach spaces is also obtained.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#22909;&#30340;&#27604;KL PAC-Bayes&#30028;&#38480;&#26041;&#27861;&#26469;&#20272;&#35745;&#24207;&#21015;&#22343;&#20540;&#65292;&#24212;&#29992;&#20110;&#39044;&#27979;&#22120;&#27867;&#21270;&#35823;&#24046;&#30340;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2402.09201</link><description>&lt;p&gt;
&#26356;&#22909;&#30340;&#27604;KL PAC-Bayes&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Better-than-KL PAC-Bayes Bounds
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09201
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#22909;&#30340;&#27604;KL PAC-Bayes&#30028;&#38480;&#26041;&#27861;&#26469;&#20272;&#35745;&#24207;&#21015;&#22343;&#20540;&#65292;&#24212;&#29992;&#20110;&#39044;&#27979;&#22120;&#27867;&#21270;&#35823;&#24046;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35753;$f(\theta, X_1),$ $ \dots,$ $ f(\theta, X_n)$&#25104;&#20026;&#19968;&#20010;&#38543;&#26426;&#20803;&#32032;&#24207;&#21015;&#65292;&#20854;&#20013;$f$&#26159;&#19968;&#20010;&#22266;&#23450;&#30340;&#26631;&#37327;&#20989;&#25968;&#65292;$X_1, \dots, X_n$&#26159;&#29420;&#31435;&#30340;&#38543;&#26426;&#21464;&#37327;&#65288;&#25968;&#25454;&#65289;&#65292;&#32780;$\theta$&#26159;&#26681;&#25454;&#19968;&#20123;&#25968;&#25454;&#30456;&#20851;&#30340;&#21518;&#39564;&#20998;&#24067;$P_n$&#20998;&#24067;&#30340;&#38543;&#26426;&#21442;&#25968;&#12290;&#26412;&#25991;&#32771;&#34385;&#20102;&#35777;&#26126;&#27987;&#24230;&#19981;&#31561;&#24335;&#26469;&#20272;&#35745;&#24207;&#21015;&#22343;&#20540;&#30340;&#38382;&#39064;&#12290;&#36825;&#26679;&#19968;&#20010;&#38382;&#39064;&#30340;&#19968;&#20010;&#20363;&#23376;&#26159;&#23545;&#26576;&#20123;&#36890;&#36807;&#38543;&#26426;&#31639;&#27861;&#35757;&#32451;&#30340;&#39044;&#27979;&#22120;&#30340;&#27867;&#21270;&#35823;&#24046;&#30340;&#20272;&#35745;&#65292;&#27604;&#22914;&#31070;&#32463;&#32593;&#32476;&#65292;&#20854;&#20013;$f$&#26159;&#19968;&#20010;&#25439;&#22833;&#20989;&#25968;&#12290;&#20256;&#32479;&#19978;&#65292;&#36825;&#20010;&#38382;&#39064;&#26159;&#36890;&#36807;PAC-Bayes&#20998;&#26512;&#26469;&#35299;&#20915;&#30340;&#65292;&#22312;&#36825;&#20010;&#20998;&#26512;&#20013;&#65292;&#38500;&#20102;&#21518;&#39564;&#20998;&#24067;&#65292;&#25105;&#20204;&#36824;&#36873;&#25321;&#19968;&#20010;&#33021;&#22815;&#25429;&#25417;&#21040;&#23398;&#20064;&#38382;&#39064;&#24402;&#32435;&#20559;&#24046;&#30340;&#20808;&#39564;&#20998;&#24067;&#12290;&#28982;&#21518;&#65292;PAC-Bayes&#27987;&#24230;&#30028;&#38480;&#20013;&#30340;&#20851;&#38190;&#25968;&#37327;&#26159;&#19968;&#20010;&#33021;&#22815;&#25429;&#25417;&#21040;&#23398;&#20064;&#38382;&#39064;&#22797;&#26434;&#24615;&#30340;&#20998;&#27495;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09201v1 Announce Type: new Abstract: Let $f(\theta, X_1),$ $ \dots,$ $ f(\theta, X_n)$ be a sequence of random elements, where $f$ is a fixed scalar function, $X_1, \dots, X_n$ are independent random variables (data), and $\theta$ is a random parameter distributed according to some data-dependent posterior distribution $P_n$. In this paper, we consider the problem of proving concentration inequalities to estimate the mean of the sequence. An example of such a problem is the estimation of the generalization error of some predictor trained by a stochastic algorithm, such as a neural network where $f$ is a loss function. Classically, this problem is approached through a PAC-Bayes analysis where, in addition to the posterior, we choose a prior distribution which captures our belief about the inductive bias of the learning problem. Then, the key quantity in PAC-Bayes concentration bounds is a divergence that captures the complexity of the learning problem where the de facto stand
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;MMM&#21644;MMMSynth&#31639;&#27861;&#65292;&#29992;&#20110;&#32858;&#31867;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#21644;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#12290;MMM&#31639;&#27861;&#21033;&#29992;EM&#31639;&#27861;&#65292;&#22312;&#21516;&#31867;&#31639;&#27861;&#20013;&#34920;&#29616;&#26356;&#20248;&#65292;&#23545;&#20110;&#30830;&#23450;&#21512;&#25104;&#25968;&#25454;&#30340;&#32858;&#31867;&#20197;&#21450;&#24674;&#22797;&#30495;&#23454;&#25968;&#25454;&#30340;&#32467;&#26500;&#26377;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290; MMMSynth&#31639;&#27861;&#21017;&#29992;&#20110;&#20174;&#30495;&#23454;&#25968;&#25454;&#29983;&#25104;&#21512;&#25104;&#34920;&#26684;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2310.19454</link><description>&lt;p&gt;
MMM&#21644;MMMSynth&#65306;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#30340;&#32858;&#31867;&#21644;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
MMM and MMMSynth: Clustering of heterogeneous tabular data, and synthetic data generation. (arXiv:2310.19454v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19454
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;MMM&#21644;MMMSynth&#31639;&#27861;&#65292;&#29992;&#20110;&#32858;&#31867;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#21644;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#12290;MMM&#31639;&#27861;&#21033;&#29992;EM&#31639;&#27861;&#65292;&#22312;&#21516;&#31867;&#31639;&#27861;&#20013;&#34920;&#29616;&#26356;&#20248;&#65292;&#23545;&#20110;&#30830;&#23450;&#21512;&#25104;&#25968;&#25454;&#30340;&#32858;&#31867;&#20197;&#21450;&#24674;&#22797;&#30495;&#23454;&#25968;&#25454;&#30340;&#32467;&#26500;&#26377;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290; MMMSynth&#31639;&#27861;&#21017;&#29992;&#20110;&#20174;&#30495;&#23454;&#25968;&#25454;&#29983;&#25104;&#21512;&#25104;&#34920;&#26684;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#19982;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#30456;&#20851;&#30340;&#20219;&#21153;&#30340;&#26032;&#31639;&#27861;&#65306;&#32858;&#31867;&#21644;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#12290;&#34920;&#26684;&#25968;&#25454;&#38598;&#36890;&#24120;&#30001;&#21015;&#20013;&#30340;&#24322;&#26500;&#25968;&#25454;&#31867;&#22411;&#65288;&#25968;&#20540;&#12289;&#26377;&#24207;&#12289;&#20998;&#31867;&#65289;&#32452;&#25104;&#65292;&#20294;&#34892;&#20013;&#21487;&#33021;&#36824;&#23384;&#22312;&#38544;&#34255;&#30340;&#32858;&#31867;&#32467;&#26500;&#65306;&#20363;&#22914;&#65292;&#23427;&#20204;&#21487;&#33021;&#26469;&#33258;&#24322;&#26500;&#30340;&#65288;&#22320;&#29702;&#12289;&#31038;&#20250;&#32463;&#27982;&#12289;&#26041;&#27861;&#35770;&#65289;&#26469;&#28304;&#65292;&#22240;&#27492;&#25152;&#25551;&#36848;&#30340;&#32467;&#26524;&#21464;&#37327;&#65288;&#22914;&#30142;&#30149;&#30340;&#23384;&#22312;&#65289;&#21487;&#33021;&#19981;&#20165;&#20381;&#36182;&#20854;&#20182;&#21464;&#37327;&#65292;&#36824;&#20381;&#36182;&#20110;&#32858;&#31867;&#19978;&#19979;&#25991;&#12290;&#27492;&#22806;&#65292;&#21307;&#23398;&#25968;&#25454;&#30340;&#20849;&#20139;&#36890;&#24120;&#21463;&#21040;&#24739;&#32773;&#38544;&#31169;&#27861;&#24459;&#30340;&#38480;&#21046;&#65292;&#22240;&#27492;&#30446;&#21069;&#23545;&#20110;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#31561;&#26041;&#27861;&#20174;&#30495;&#23454;&#25968;&#25454;&#29983;&#25104;&#21512;&#25104;&#34920;&#26684;&#25968;&#25454;&#30340;&#31639;&#27861;&#38750;&#24120;&#24863;&#20852;&#36259;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;EM&#30340;&#32858;&#31867;&#31639;&#27861;MMM&#65288;&#8220;Madras&#28151;&#21512;&#27169;&#22411;&#8221;&#65289;&#65292;&#23427;&#22312;&#30830;&#23450;&#21512;&#25104;&#24322;&#26500;&#25968;&#25454;&#30340;&#32858;&#31867;&#21644;&#24674;&#22797;&#30495;&#23454;&#25968;&#25454;&#32467;&#26500;&#26041;&#38754;&#20248;&#20110;&#26631;&#20934;&#31639;&#27861;&#12290;&#22522;&#20110;&#27492;&#65292;&#25105;&#20204;&#21487;&#23558;MMM&#24212;&#29992;&#20110;&#25968;&#25454;&#21512;&#25104;&#20219;&#21153;&#30340;MMMSynth&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide new algorithms for two tasks relating to heterogeneous tabular datasets: clustering, and synthetic data generation. Tabular datasets typically consist of heterogeneous data types (numerical, ordinal, categorical) in columns, but may also have hidden cluster structure in their rows: for example, they may be drawn from heterogeneous (geographical, socioeconomic, methodological) sources, such that the outcome variable they describe (such as the presence of a disease) may depend not only on the other variables but on the cluster context. Moreover, sharing of biomedical data is often hindered by patient confidentiality laws, and there is current interest in algorithms to generate synthetic tabular data from real data, for example via deep learning.  We demonstrate a novel EM-based clustering algorithm, MMM (``Madras Mixture Model''), that outperforms standard algorithms in determining clusters in synthetic heterogeneous data, and recovers structure in real data. Based on this, we
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#25955;&#30340;&#23433;&#20840;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#27809;&#26377;&#20013;&#22830;&#25511;&#21046;&#22120;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#37051;&#23621;&#36890;&#20449;&#26469;&#26368;&#22823;&#21270;&#32047;&#31215;&#22870;&#21169;&#24635;&#21644;&#65292;&#24182;&#21516;&#26102;&#28385;&#36275;&#27599;&#20010;&#26234;&#33021;&#20307;&#30340;&#23433;&#20840;&#32422;&#26463;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2310.14348</link><description>&lt;p&gt;
DePAint&#65306;&#32771;&#34385;&#23792;&#20540;&#21644;&#24179;&#22343;&#38480;&#21046;&#30340;&#20998;&#25955;&#23433;&#20840;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
DePAint: A Decentralized Safe Multi-Agent Reinforcement Learning Algorithm considering Peak and Average Constraints. (arXiv:2310.14348v1 [cs.MA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14348
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#25955;&#30340;&#23433;&#20840;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#27809;&#26377;&#20013;&#22830;&#25511;&#21046;&#22120;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#37051;&#23621;&#36890;&#20449;&#26469;&#26368;&#22823;&#21270;&#32047;&#31215;&#22870;&#21169;&#24635;&#21644;&#65292;&#24182;&#21516;&#26102;&#28385;&#36275;&#27599;&#20010;&#26234;&#33021;&#20307;&#30340;&#23433;&#20840;&#32422;&#26463;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23433;&#20840;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#65292;&#23613;&#31649;&#22312;&#26080;&#20154;&#26426;&#25237;&#36882;&#21644;&#36710;&#36742;&#33258;&#21160;&#21270;&#31561;&#21508;&#20010;&#39046;&#22495;&#20855;&#26377;&#28508;&#22312;&#24212;&#29992;&#65292;&#20294;&#20173;&#28982;&#30456;&#23545;&#26410;&#34987;&#25506;&#32034;&#12290;&#22312;&#35757;&#32451;&#26234;&#33021;&#20307;&#23398;&#20064;&#26368;&#20248;&#31574;&#30053;&#20197;&#26368;&#22823;&#21270;&#22870;&#21169;&#30340;&#21516;&#26102;&#32771;&#34385;&#29305;&#23450;&#38480;&#21046;&#65292;&#29305;&#21035;&#26159;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#26080;&#27861;&#26377;&#20013;&#22830;&#25511;&#21046;&#22120;&#21327;&#35843;&#26234;&#33021;&#20307;&#30340;&#22330;&#26223;&#20013;&#65292;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#38024;&#23545;&#20998;&#25955;&#29615;&#22659;&#19979;&#30340;&#22810;&#26234;&#33021;&#20307;&#31574;&#30053;&#20248;&#21270;&#38382;&#39064;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#20854;&#20013;&#26234;&#33021;&#20307;&#36890;&#36807;&#19982;&#37051;&#23621;&#36890;&#20449;&#20197;&#26368;&#22823;&#21270;&#20854;&#32047;&#31215;&#22870;&#21169;&#24635;&#21644;&#30340;&#21516;&#26102;&#28385;&#36275;&#27599;&#20010;&#26234;&#33021;&#20307;&#30340;&#23433;&#20840;&#32422;&#26463;&#12290;&#25105;&#20204;&#21516;&#26102;&#32771;&#34385;&#20102;&#23792;&#20540;&#21644;&#24179;&#22343;&#38480;&#21046;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#27809;&#26377;&#20013;&#22830;&#25511;&#21046;&#22120;&#21327;&#35843;&#26234;&#33021;&#20307;&#65292;&#22870;&#21169;&#21644;&#32422;&#26463;&#21482;&#22312;&#27599;&#20010;&#26234;&#33021;&#20307;&#26412;&#22320;/&#31169;&#26377;&#21487;&#30693;&#12290;&#25105;&#20204;&#23558;&#38382;&#39064;&#24418;&#24335;&#21270;&#20026;&#20998;&#25955;&#32422;&#26463;&#30340;&#22810;&#26234;&#33021;&#20307;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The field of safe multi-agent reinforcement learning, despite its potential applications in various domains such as drone delivery and vehicle automation, remains relatively unexplored. Training agents to learn optimal policies that maximize rewards while considering specific constraints can be challenging, particularly in scenarios where having a central controller to coordinate the agents during the training process is not feasible. In this paper, we address the problem of multi-agent policy optimization in a decentralized setting, where agents communicate with their neighbors to maximize the sum of their cumulative rewards while also satisfying each agent's safety constraints. We consider both peak and average constraints. In this scenario, there is no central controller coordinating the agents and both the rewards and constraints are only known to each agent locally/privately. We formulate the problem as a decentralized constrained multi-agent Markov Decision Problem and propose a 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#21152;&#26435;&#28378;&#21160;&#39564;&#35777;&#36807;&#31243;&#26469;&#25552;&#39640;&#22522;&#26412;&#20272;&#35745;&#22120;&#30340;&#33258;&#36866;&#24212;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#37325;&#35201;&#24615;&#21644;&#25935;&#24863;&#24615;</title><link>http://arxiv.org/abs/2310.12140</link><description>&lt;p&gt;
&#22312;&#32447;&#20272;&#35745;&#19982;&#28378;&#21160;&#39564;&#35777;&#65306;&#36866;&#24212;&#24615;&#38750;&#21442;&#25968;&#20272;&#35745;&#19982;&#25968;&#25454;&#27969;
&lt;/p&gt;
&lt;p&gt;
Online Estimation with Rolling Validation: Adaptive Nonparametric Estimation with Stream Data. (arXiv:2310.12140v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12140
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#21152;&#26435;&#28378;&#21160;&#39564;&#35777;&#36807;&#31243;&#26469;&#25552;&#39640;&#22522;&#26412;&#20272;&#35745;&#22120;&#30340;&#33258;&#36866;&#24212;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#37325;&#35201;&#24615;&#21644;&#25935;&#24863;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20854;&#39640;&#25928;&#35745;&#31639;&#21644;&#31454;&#20105;&#24615;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#22312;&#32447;&#38750;&#21442;&#25968;&#20272;&#35745;&#22120;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#19968;&#20010;&#37325;&#35201;&#30340;&#20363;&#23376;&#26159;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#21464;&#20307;&#12290;&#36825;&#20123;&#31639;&#27861;&#36890;&#24120;&#19968;&#27425;&#21482;&#21462;&#19968;&#20010;&#26679;&#26412;&#28857;&#65292;&#24182;&#31435;&#21363;&#26356;&#26032;&#24863;&#20852;&#36259;&#30340;&#21442;&#25968;&#20272;&#35745;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#36825;&#20123;&#22312;&#32447;&#31639;&#27861;&#30340;&#27169;&#22411;&#36873;&#25321;&#21644;&#36229;&#21442;&#25968;&#35843;&#25972;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#28378;&#21160;&#39564;&#35777;&#36807;&#31243;&#65292;&#19968;&#31181;&#22312;&#32447;&#30340;&#30041;&#19968;&#20132;&#21449;&#39564;&#35777;&#21464;&#20307;&#65292;&#23545;&#20110;&#35768;&#22810;&#20856;&#22411;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20272;&#35745;&#22120;&#26469;&#35828;&#65292;&#39069;&#22806;&#30340;&#35745;&#31639;&#25104;&#26412;&#26368;&#23567;&#12290;&#31867;&#20284;&#20110;&#25209;&#37327;&#20132;&#21449;&#39564;&#35777;&#65292;&#23427;&#21487;&#20197;&#25552;&#21319;&#22522;&#26412;&#20272;&#35745;&#22120;&#30340;&#33258;&#36866;&#24212;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#24456;&#31616;&#21333;&#65292;&#20027;&#35201;&#20381;&#36182;&#20110;&#19968;&#20123;&#19968;&#33324;&#30340;&#32479;&#35745;&#31283;&#23450;&#24615;&#20551;&#35774;&#12290;&#27169;&#25311;&#30740;&#31350;&#24378;&#35843;&#20102;&#28378;&#21160;&#39564;&#35777;&#20013;&#21457;&#25955;&#26435;&#37325;&#22312;&#23454;&#36341;&#20013;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#21363;&#20351;&#21482;&#26377;&#19968;&#20010;&#24456;&#23567;&#30340;&#20559;&#24046;&#65292;&#23427;&#30340;&#25935;&#24863;&#24615;&#20063;&#24456;&#39640;
&lt;/p&gt;
&lt;p&gt;
Online nonparametric estimators are gaining popularity due to their efficient computation and competitive generalization abilities. An important example includes variants of stochastic gradient descent. These algorithms often take one sample point at a time and instantly update the parameter estimate of interest. In this work we consider model selection and hyperparameter tuning for such online algorithms. We propose a weighted rolling-validation procedure, an online variant of leave-one-out cross-validation, that costs minimal extra computation for many typical stochastic gradient descent estimators. Similar to batch cross-validation, it can boost base estimators to achieve a better, adaptive convergence rate. Our theoretical analysis is straightforward, relying mainly on some general statistical stability assumptions. The simulation study underscores the significance of diverging weights in rolling validation in practice and demonstrates its sensitivity even when there is only a slim
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#40065;&#33725;&#34892;&#20026;&#24341;&#20837;&#22522;&#20110;&#30697;&#38453;&#20998;&#35299;&#30340;&#25512;&#33616;&#31995;&#32479;&#23398;&#20064;&#36807;&#31243;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25511;&#21046;&#39118;&#38505;&#27700;&#24179;&#26469;&#25552;&#39640;&#39044;&#27979;&#30340;&#25968;&#37327;&#21644;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2308.02058</link><description>&lt;p&gt;
&#25972;&#21512;&#40065;&#33725;&#34892;&#20026;&#21040;&#22522;&#20110;&#21327;&#21516;&#36807;&#28388;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;
&lt;/p&gt;
&lt;p&gt;
Incorporating Recklessness to Collaborative Filtering based Recommender Systems. (arXiv:2308.02058v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02058
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#40065;&#33725;&#34892;&#20026;&#24341;&#20837;&#22522;&#20110;&#30697;&#38453;&#20998;&#35299;&#30340;&#25512;&#33616;&#31995;&#32479;&#23398;&#20064;&#36807;&#31243;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25511;&#21046;&#39118;&#38505;&#27700;&#24179;&#26469;&#25552;&#39640;&#39044;&#27979;&#30340;&#25968;&#37327;&#21644;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21253;&#21547;&#21487;&#38752;&#24615;&#27979;&#37327;&#30340;&#25512;&#33616;&#31995;&#32479;&#24448;&#24448;&#22312;&#39044;&#27979;&#20013;&#26356;&#21152;&#20445;&#23432;&#65292;&#22240;&#20026;&#23427;&#20204;&#38656;&#35201;&#20445;&#25345;&#21487;&#38752;&#24615;&#12290;&#36825;&#23548;&#33268;&#20102;&#36825;&#20123;&#31995;&#32479;&#21487;&#20197;&#25552;&#20379;&#30340;&#35206;&#30422;&#33539;&#22260;&#21644;&#26032;&#39062;&#24615;&#30340;&#26174;&#33879;&#19979;&#38477;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#30697;&#38453;&#20998;&#35299;&#22411;&#25512;&#33616;&#31995;&#32479;&#30340;&#23398;&#20064;&#36807;&#31243;&#20013;&#21152;&#20837;&#19968;&#39033;&#26032;&#30340;&#39033;&#65292;&#31216;&#20026;&#40065;&#33725;&#34892;&#20026;&#65292;&#23427;&#21487;&#20197;&#25511;&#21046;&#22312;&#20570;&#20986;&#20851;&#20110;&#39044;&#27979;&#21487;&#38752;&#24615;&#30340;&#20915;&#31574;&#26102;&#25152;&#24076;&#26395;&#30340;&#39118;&#38505;&#27700;&#24179;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#40065;&#33725;&#34892;&#20026;&#19981;&#20165;&#20801;&#35768;&#36827;&#34892;&#39118;&#38505;&#35843;&#25511;&#65292;&#36824;&#25552;&#39640;&#20102;&#25512;&#33616;&#31995;&#32479;&#25552;&#20379;&#30340;&#39044;&#27979;&#30340;&#25968;&#37327;&#21644;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems that include some reliability measure of their predictions tend to be more conservative in forecasting, due to their constraint to preserve reliability. This leads to a significant drop in the coverage and novelty that these systems can provide. In this paper, we propose the inclusion of a new term in the learning process of matrix factorization-based recommender systems, called recklessness, which enables the control of the risk level desired when making decisions about the reliability of a prediction. Experimental results demonstrate that recklessness not only allows for risk regulation but also improves the quantity and quality of predictions provided by the recommender system.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#12289;&#19981;&#38656;&#35201;&#23454;&#29616;&#24433;&#21709;&#20989;&#25968;&#19988;&#21487;&#35745;&#31639;&#30340;&#21435;&#20559;&#25554;&#20540;&#20272;&#35745;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.08598</link><description>&lt;p&gt;
&#26680;&#21435;&#20559;&#25554;&#20540;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Kernel Debiased Plug-in Estimation. (arXiv:2306.08598v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08598
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#12289;&#19981;&#38656;&#35201;&#23454;&#29616;&#24433;&#21709;&#20989;&#25968;&#19988;&#21487;&#35745;&#31639;&#30340;&#21435;&#20559;&#25554;&#20540;&#20272;&#35745;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#24178;&#25200;&#21442;&#25968;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#26631;&#37327;&#30446;&#26631;&#21442;&#25968;&#30340;&#38382;&#39064;&#12290;&#37319;&#29992;&#38750;&#21442;&#25968;&#20272;&#35745;&#22120;&#65288;&#20363;&#22914;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#27169;&#22411;&#65289;&#26367;&#25442;&#26410;&#30693;&#24178;&#25200;&#21442;&#25968;&#26159;&#26041;&#20415;&#30340;&#65292;&#20294;&#22240;&#23384;&#22312;&#36739;&#22823;&#20559;&#24046;&#32780;&#25928;&#29575;&#20302;&#19979;&#12290;&#20026;&#20102;&#36991;&#20813;&#20559;&#24046;-&#26041;&#24046;&#26435;&#34913;&#30340;&#27425;&#20248;&#36873;&#25321;&#65292;&#29616;&#20195;&#26041;&#27861;&#20250;&#36827;&#34892;&#25554;&#20540;&#39044;&#20272;&#30340;&#21435;&#20559;&#24046;&#25805;&#20316;&#65292;&#22914;&#26377;&#30446;&#26631;&#26368;&#23567;&#25439;&#22833;&#20272;&#35745;&#65288;TMLE&#65289;&#21644;&#21452;&#26426;&#22120;&#23398;&#20064;&#65288;DML&#65289;&#31561;&#12290;&#29616;&#26377;&#30340;&#21435;&#20559;&#26041;&#27861;&#38656;&#35201;&#23558;&#30446;&#26631;&#21442;&#25968;&#30340;&#24433;&#21709;&#20989;&#25968;&#65288;IF&#65289;&#20316;&#20026;&#36755;&#20837;&#65292;&#28982;&#32780;&#65292;IF&#30340;&#25512;&#23548;&#38656;&#35201;&#19987;&#19994;&#30693;&#35782;&#65292;&#20174;&#32780;&#38459;&#30861;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#36866;&#24212;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#25554;&#20837;&#20272;&#35745;&#22120;&#30340;&#26041;&#27861;&#65292;&#23427;&#65288;i&#65289;&#39640;&#25928;&#12289;&#65288;ii&#65289;&#19981;&#38656;&#35201;&#23454;&#29616;IF&#12289;&#65288;iii&#65289;&#21487;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of estimating a scalar target parameter in the presence of nuisance parameters. Replacing the unknown nuisance parameter with a nonparametric estimator, e.g.,a machine learning (ML) model, is convenient but has shown to be inefficient due to large biases. Modern methods, such as the targeted minimum loss-based estimation (TMLE) and double machine learning (DML), achieve optimal performance under flexible assumptions by harnessing ML estimates while mitigating the plug-in bias. To avoid a sub-optimal bias-variance trade-off, these methods perform a debiasing step of the plug-in pre-estimate. Existing debiasing methods require the influence function of the target parameter as input. However, deriving the IF requires specialized expertise and thus obstructs the adaptation of these methods by practitioners. We propose a novel way to debias plug-in estimators which (i) is efficient, (ii) does not require the IF to be implemented, (iii) is computationally tractable, a
&lt;/p&gt;</description></item><item><title>TiDE&#26159;&#19968;&#31181;&#22522;&#20110;MLP&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#65292;&#29992;&#20110;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#12290;&#23427;&#26082;&#20855;&#22791;&#32447;&#24615;&#27169;&#22411;&#30340;&#31616;&#21333;&#24615;&#21644;&#36895;&#24230;&#65292;&#21448;&#33021;&#22788;&#29702;&#21327;&#21464;&#37327;&#21644;&#38750;&#32447;&#24615;&#20381;&#36182;&#65292;&#30456;&#36739;&#20110;&#26368;&#20339;&#30340;Transformer&#27169;&#22411;&#65292;&#36895;&#24230;&#24555;5-10&#20493;&#12290;</title><link>http://arxiv.org/abs/2304.08424</link><description>&lt;p&gt;
&#29992;TiDE&#36827;&#34892;&#38271;&#26399;&#39044;&#27979;&#65306;&#26102;&#38388;&#24207;&#21015;&#31264;&#23494;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Long-term Forecasting with TiDE: Time-series Dense Encoder. (arXiv:2304.08424v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08424
&lt;/p&gt;
&lt;p&gt;
TiDE&#26159;&#19968;&#31181;&#22522;&#20110;MLP&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#65292;&#29992;&#20110;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#12290;&#23427;&#26082;&#20855;&#22791;&#32447;&#24615;&#27169;&#22411;&#30340;&#31616;&#21333;&#24615;&#21644;&#36895;&#24230;&#65292;&#21448;&#33021;&#22788;&#29702;&#21327;&#21464;&#37327;&#21644;&#38750;&#32447;&#24615;&#20381;&#36182;&#65292;&#30456;&#36739;&#20110;&#26368;&#20339;&#30340;Transformer&#27169;&#22411;&#65292;&#36895;&#24230;&#24555;5-10&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#30456;&#27604;&#20110;&#22522;&#20110;Transformer&#30340;&#26041;&#27861;&#65292;&#31616;&#21333;&#30340;&#32447;&#24615;&#27169;&#22411;&#22312;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#34920;&#29616;&#26356;&#22909;&#12290;&#37492;&#20110;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#23618;&#24863;&#30693;&#26426;(MLP)&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#65292;&#21363;&#26102;&#38388;&#24207;&#21015;&#31264;&#23494;&#32534;&#30721;&#22120;(TiDE)&#65292;&#29992;&#20110;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#12290;&#23427;&#26082;&#20139;&#26377;&#32447;&#24615;&#27169;&#22411;&#30340;&#31616;&#21333;&#24615;&#21644;&#36895;&#24230;&#65292;&#21448;&#33021;&#22788;&#29702;&#21327;&#21464;&#37327;&#21644;&#38750;&#32447;&#24615;&#20381;&#36182;&#12290;&#20174;&#29702;&#35770;&#19978;&#35762;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#27169;&#22411;&#30340;&#26368;&#31616;&#32447;&#24615;&#31867;&#27604;&#22312;&#19968;&#20123;&#20551;&#35774;&#19979;&#21487;&#20197;&#36798;&#21040;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;(LDS)&#30340;&#36817;&#20046;&#26368;&#20248;&#35823;&#24046;&#29575;&#12290;&#23454;&#35777;&#19978;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#22312;&#27969;&#34892;&#30340;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#22522;&#20934;&#27979;&#35797;&#20013;&#21305;&#37197;&#25110;&#32988;&#36807;&#20197;&#21069;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#27604;&#26368;&#20339;&#30340;&#22522;&#20110;Transformer&#30340;&#27169;&#22411;&#24555;5-10&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work has shown that simple linear models can outperform several Transformer based approaches in long term time-series forecasting. Motivated by this, we propose a Multi-layer Perceptron (MLP) based encoder-decoder model, Time-series Dense Encoder (TiDE), for long-term time-series forecasting that enjoys the simplicity and speed of linear models while also being able to handle covariates and non-linear dependencies. Theoretically, we prove that the simplest linear analogue of our model can achieve near optimal error rate for linear dynamical systems (LDS) under some assumptions. Empirically, we show that our method can match or outperform prior approaches on popular long-term time-series forecasting benchmarks while being 5-10x faster than the best Transformer based model.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#23558;&#20998;&#26512;&#21644;&#25968;&#20540;&#25512;&#23548;&#32467;&#21512;&#65292;&#22312;&#22522;&#20110;&#24191;&#20041; Potts &#27169;&#22411;&#30340;&#25968;&#25454;&#19978;&#65292;&#23545;&#32463;&#36807;&#25913;&#36827;&#36866;&#24212;&#36825;&#31181;&#27169;&#22411;&#30340;self-attention&#26426;&#21046;&#36827;&#34892;&#35757;&#32451;&#65292;&#21457;&#29616;&#32463;&#36807;&#20462;&#25913;&#30340;self-attention&#26426;&#21046;&#21487;&#20197;&#22312;&#26497;&#38480;&#37319;&#26679;&#19979;&#20934;&#30830;&#23398;&#20064;Potts&#27169;&#22411;&#12290;&#36825;&#20010;&#8220;&#20998;&#35299;&#8221;&#27880;&#24847;&#21147;&#26426;&#21046;&#36890;&#36807;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#30456;&#20851;&#23646;&#24615;&#65292;&#21487;&#20197;&#25552;&#39640;Transformer&#30340;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.07235</link><description>&lt;p&gt;
&#21033;&#29992;&#20998;&#35299;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#21333;&#23618;Transformer&#23545;&#24191;&#20041;Potts&#27169;&#22411;&#36827;&#34892;&#26368;&#20248;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Optimal inference of a generalised Potts model by single-layer transformers with factored attention. (arXiv:2304.07235v1 [cond-mat.dis-nn])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07235
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;&#20998;&#26512;&#21644;&#25968;&#20540;&#25512;&#23548;&#32467;&#21512;&#65292;&#22312;&#22522;&#20110;&#24191;&#20041; Potts &#27169;&#22411;&#30340;&#25968;&#25454;&#19978;&#65292;&#23545;&#32463;&#36807;&#25913;&#36827;&#36866;&#24212;&#36825;&#31181;&#27169;&#22411;&#30340;self-attention&#26426;&#21046;&#36827;&#34892;&#35757;&#32451;&#65292;&#21457;&#29616;&#32463;&#36807;&#20462;&#25913;&#30340;self-attention&#26426;&#21046;&#21487;&#20197;&#22312;&#26497;&#38480;&#37319;&#26679;&#19979;&#20934;&#30830;&#23398;&#20064;Potts&#27169;&#22411;&#12290;&#36825;&#20010;&#8220;&#20998;&#35299;&#8221;&#27880;&#24847;&#21147;&#26426;&#21046;&#36890;&#36807;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#30456;&#20851;&#23646;&#24615;&#65292;&#21487;&#20197;&#25552;&#39640;Transformer&#30340;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer &#26159;&#19968;&#31181;&#38761;&#21629;&#24615;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#34507;&#30333;&#36136;&#31185;&#23398;&#26041;&#38754;&#21462;&#24471;&#20102;&#23454;&#36341;&#19978;&#30340;&#25104;&#21151;&#12290;&#23427;&#20204;&#30340;&#20851;&#38190;&#26500;&#24314;&#22359;&#26159;&#19968;&#20010;&#21483;&#20570;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26426;&#21046;&#65292;&#23427;&#34987;&#35757;&#32451;&#29992;&#20110;&#39044;&#27979;&#21477;&#23376;&#20013;&#32570;&#22833;&#30340;&#35789;&#12290;&#23613;&#31649;Transformer&#22312;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#23454;&#36341;&#19978;&#30340;&#25104;&#21151;&#65292;&#20294;&#26159;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#31350;&#31455;&#20174;&#25968;&#25454;&#20013;&#23398;&#21040;&#20102;&#20160;&#20040;&#20197;&#21450;&#23427;&#26159;&#24590;&#20040;&#20570;&#21040;&#30340;&#36824;&#19981;&#26159;&#24456;&#28165;&#26970;&#12290;&#26412;&#25991;&#38024;&#23545;&#20174;&#20855;&#26377;&#30456;&#20114;&#20316;&#29992;&#30340;&#20301;&#32622;&#21644; Potts &#39068;&#33394;&#20013;&#25552;&#21462;&#30340;&#25968;&#25454;&#22312;&#35757;&#32451;&#30340;Transformer&#19978;&#32473;&#20986;&#20102;&#31934;&#30830;&#30340;&#20998;&#26512;&#21644;&#25968;&#20540;&#21051;&#30011;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#34429;&#28982;&#19968;&#33324;&#30340;transformer&#38656;&#35201;&#22810;&#23618;&#23398;&#20064;&#25165;&#33021;&#20934;&#30830;&#23398;&#20064;&#36825;&#20010;&#20998;&#24067;&#65292;&#20294;&#26159;&#32463;&#36807;&#23567;&#25913;&#36827;&#30340;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#22312;&#26080;&#38480;&#37319;&#26679;&#30340;&#26497;&#38480;&#19979;&#21487;&#20197;&#23436;&#32654;&#22320;&#23398;&#20064;Potts&#27169;&#22411;&#12290;&#25105;&#20204;&#36824;&#35745;&#31639;&#20102;&#36825;&#20010;&#20462;&#25913;&#21518;&#30340;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#25152;&#35859;&#8220;&#20998;&#35299;&#8221;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#25968;&#20540;&#28436;&#31034;&#20102;&#25105;&#20204;&#30340;&#21457;&#29616;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20026;&#35299;&#37322;Transformer&#30340;&#20869;&#22312;&#24037;&#20316;&#21407;&#29702;&#20197;&#21450;&#25552;&#39640;&#20854;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#25552;&#20379;&#20102;&#26032;&#30340;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformers are the type of neural networks that has revolutionised natural language processing and protein science. Their key building block is a mechanism called self-attention which is trained to predict missing words in sentences. Despite the practical success of transformers in applications it remains unclear what self-attention learns from data, and how. Here, we give a precise analytical and numerical characterisation of transformers trained on data drawn from a generalised Potts model with interactions between sites and Potts colours. While an off-the-shelf transformer requires several layers to learn this distribution, we show analytically that a single layer of self-attention with a small modification can learn the Potts model exactly in the limit of infinite sampling. We show that this modified self-attention, that we call ``factored'', has the same functional form as the conditional probability of a Potts spin given the other spins, compute its generalisation error using t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#22312;&#32447;&#26368;&#23567;&#20108;&#20056;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#31639;&#27861;&#65292;&#20197;&#25968;&#25454;&#29983;&#25104;&#27169;&#22411;&#30340;&#24615;&#36136;&#20026;&#22522;&#30784;&#65292;&#24314;&#31435;&#20102;&#39640;&#32500;&#32553;&#25918;&#26497;&#38480;&#19982;&#27874;&#21160;&#27169;&#22411;&#12290;&#22312;&#20302;&#12289;&#20013;&#12289;&#39640;&#22122;&#22768;&#35774;&#32622;&#38454;&#27573;&#65292;&#25581;&#31034;&#20102;&#36845;&#20195;&#30340;&#31934;&#30830;&#19977;&#38454;&#27573;&#30456;&#21464;&#12290;</title><link>http://arxiv.org/abs/2304.00707</link><description>&lt;p&gt;
&#20855;&#26377;&#24179;&#28369;&#21327;&#26041;&#24046;&#30340;&#22312;&#32447;&#26368;&#23567;&#20108;&#20056;SGD&#31639;&#27861;&#30340;&#39640;&#32500;&#32553;&#25918;&#26497;&#38480;&#19982;&#27874;&#21160;
&lt;/p&gt;
&lt;p&gt;
High-dimensional scaling limits and fluctuations of online least-squares SGD with smooth covariance. (arXiv:2304.00707v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00707
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#22312;&#32447;&#26368;&#23567;&#20108;&#20056;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#31639;&#27861;&#65292;&#20197;&#25968;&#25454;&#29983;&#25104;&#27169;&#22411;&#30340;&#24615;&#36136;&#20026;&#22522;&#30784;&#65292;&#24314;&#31435;&#20102;&#39640;&#32500;&#32553;&#25918;&#26497;&#38480;&#19982;&#27874;&#21160;&#27169;&#22411;&#12290;&#22312;&#20302;&#12289;&#20013;&#12289;&#39640;&#22122;&#22768;&#35774;&#32622;&#38454;&#27573;&#65292;&#25581;&#31034;&#20102;&#36845;&#20195;&#30340;&#31934;&#30830;&#19977;&#38454;&#27573;&#30456;&#21464;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#25968;&#25454;&#29983;&#25104;&#27169;&#22411;&#30340;&#24615;&#36136;&#65292;&#23548;&#20986;&#20102;&#22312;&#32447;&#26368;&#23567;&#20108;&#20056;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#31639;&#27861;&#30340;&#39640;&#32500;&#32553;&#25918;&#26497;&#38480;&#19982;&#27874;&#21160;&#12290;&#25105;&#20204;&#23558;SGD&#36845;&#20195;&#35270;&#20026;&#30456;&#20114;&#20316;&#29992;&#30340;&#31890;&#23376;&#31995;&#32479;&#65292;&#20854;&#20013;&#26399;&#26395;&#30456;&#20114;&#20316;&#29992;&#30001;&#36755;&#20837;&#30340;&#21327;&#26041;&#24046;&#32467;&#26500;&#34920;&#24449;&#12290;&#25105;&#20204;&#20551;&#35774;&#23545;&#25152;&#26377;&#36798;&#21040;&#20843;&#38454;&#30697;&#30340;&#30697;&#39034;&#28369;&#65292;&#19988;&#26080;&#38656;&#26174;&#24335;&#20551;&#35774;&#39640;&#26031;&#24615;&#65292;&#23601;&#33021;&#22815;&#24314;&#31435;&#26080;&#31351;&#32500;&#30340;&#26222;&#36890;&#24494;&#20998;&#26041;&#31243;&#65288;ODEs&#65289;&#25110;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDEs&#65289;&#30340;&#39640;&#32500;&#32553;&#25918;&#26497;&#38480;&#21644;&#27874;&#21160;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25581;&#31034;&#20102;&#36845;&#20195;&#30340;&#31934;&#30830;&#19977;&#38454;&#27573;&#30456;&#21464;&#65307;&#24403;&#22122;&#22768;&#26041;&#24046;&#20174;&#20302;&#12289;&#20013;&#12289;&#39640;&#22122;&#22768;&#35774;&#32622;&#26102;&#65292;&#23427;&#20174;&#36712;&#36947;&#36816;&#21160;&#21464;&#20026;&#25193;&#25955;&#36816;&#21160;&#65292;&#26368;&#32456;&#21464;&#20026;&#32431;&#38543;&#26426;&#36816;&#21160;&#12290;&#22312;&#20302;&#22122;&#22768;&#35774;&#32622;&#19979;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#34920;&#24449;&#20102;&#31934;&#30830;&#30340;&#27874;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;
We derive high-dimensional scaling limits and fluctuations for the online least-squares Stochastic Gradient Descent (SGD) algorithm by taking the properties of the data generating model explicitly into consideration. Our approach treats the SGD iterates as an interacting particle system, where the expected interaction is characterized by the covariance structure of the input. Assuming smoothness conditions on moments of order up to eight orders, and without explicitly assuming Gaussianity, we establish the high-dimensional scaling limits and fluctuations in the form of infinite-dimensional Ordinary Differential Equations (ODEs) or Stochastic Differential Equations (SDEs). Our results reveal a precise three-step phase transition of the iterates; it goes from being ballistic, to diffusive, and finally to purely random behavior, as the noise variance goes from low, to moderate and finally to very-high noise setting. In the low-noise setting, we further characterize the precise fluctuation
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35843;&#26597;&#20102;&#36807;&#21435;25&#24180;&#20013;&#39118;&#38505;&#27979;&#24230;&#30340;&#24555;&#36895;&#21457;&#23637;&#65292;&#20171;&#32461;&#20102;&#20854;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#24212;&#29992;&#65292;&#20197;&#21450;&#19982;&#25928;&#29992;&#29702;&#35770;&#21644;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30340;&#20851;&#31995;&#65292;&#24182;&#25351;&#20986;&#20102;&#20844;&#24179;&#26426;&#22120;&#23398;&#20064;&#31561;&#26032;&#20852;&#24212;&#29992;&#39046;&#22495;&#12290;</title><link>http://arxiv.org/abs/2212.00856</link><description>&lt;p&gt;
&#23398;&#20064;&#21644;&#20915;&#31574;&#30340;&#39118;&#38505;&#33258;&#36866;&#24212;&#26041;&#27861;&#65306;&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Risk-Adaptive Approaches to Learning and Decision Making: A Survey. (arXiv:2212.00856v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.00856
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35843;&#26597;&#20102;&#36807;&#21435;25&#24180;&#20013;&#39118;&#38505;&#27979;&#24230;&#30340;&#24555;&#36895;&#21457;&#23637;&#65292;&#20171;&#32461;&#20102;&#20854;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#24212;&#29992;&#65292;&#20197;&#21450;&#19982;&#25928;&#29992;&#29702;&#35770;&#21644;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30340;&#20851;&#31995;&#65292;&#24182;&#25351;&#20986;&#20102;&#20844;&#24179;&#26426;&#22120;&#23398;&#20064;&#31561;&#26032;&#20852;&#24212;&#29992;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#22312;&#24037;&#31243;&#35774;&#35745;&#12289;&#32479;&#35745;&#23398;&#20064;&#21644;&#20915;&#31574;&#21046;&#23450;&#20013;&#26222;&#36941;&#23384;&#22312;&#12290;&#30001;&#20110;&#22266;&#26377;&#30340;&#39118;&#38505;&#35268;&#36991;&#21644;&#23545;&#20551;&#35774;&#30340;&#27169;&#31946;&#24615;&#65292;&#36890;&#24120;&#36890;&#36807;&#21046;&#23450;&#21644;&#35299;&#20915;&#20351;&#29992;&#39118;&#38505;&#21644;&#30456;&#20851;&#27010;&#24565;&#30340;&#20445;&#23432;&#20248;&#21270;&#27169;&#22411;&#26469;&#35299;&#20915;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#12290;&#25105;&#20204;&#23545;&#36807;&#21435;25&#24180;&#26469;&#39118;&#38505;&#27979;&#24230;&#30340;&#24555;&#36895;&#21457;&#23637;&#36827;&#34892;&#20102;&#35843;&#26597;&#12290;&#20174;&#23427;&#20204;&#22312;&#37329;&#34701;&#24037;&#31243;&#39046;&#22495;&#30340;&#36215;&#27493;&#65292;&#25105;&#20204;&#22238;&#39038;&#20102;&#23427;&#20204;&#22312;&#20960;&#20046;&#25152;&#26377;&#39046;&#22495;&#30340;&#24037;&#31243;&#21644;&#24212;&#29992;&#25968;&#23398;&#20013;&#30340;&#24212;&#29992;&#12290;&#39118;&#38505;&#27979;&#24230;&#25166;&#26681;&#20110;&#20984;&#20998;&#26512;&#65292;&#20026;&#22788;&#29702;&#19981;&#30830;&#23450;&#24615;&#25552;&#20379;&#20102;&#19968;&#20010;&#20855;&#26377;&#37325;&#35201;&#35745;&#31639;&#21644;&#29702;&#35770;&#20248;&#21183;&#30340;&#36890;&#29992;&#26694;&#26550;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#20851;&#38190;&#20107;&#23454;&#65292;&#21015;&#20030;&#20102;&#20960;&#31181;&#20855;&#20307;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#22823;&#37327;&#21442;&#32771;&#25991;&#29486;&#20379;&#36827;&#19968;&#27493;&#38405;&#35835;&#12290;&#35813;&#35843;&#26597;&#36824;&#22238;&#39038;&#20102;&#19982;&#25928;&#29992;&#29702;&#35770;&#21644;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30340;&#32852;&#31995;&#65292;&#25351;&#20986;&#20102;&#26032;&#20852;&#24212;&#29992;&#39046;&#22495;&#65292;&#22914;&#20844;&#24179;&#26426;&#22120;&#23398;&#20064;&#65292;&#24182;&#23450;&#20041;&#20102;&#30456;&#23545;&#27979;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty is prevalent in engineering design, statistical learning, and decision making broadly. Due to inherent risk-averseness and ambiguity about assumptions, it is common to address uncertainty by formulating and solving conservative optimization models expressed using measures of risk and related concepts. We survey the rapid development of risk measures over the last quarter century. From their beginning in financial engineering, we recount the spread to nearly all areas of engineering and applied mathematics. Solidly rooted in convex analysis, risk measures furnish a general framework for handling uncertainty with significant computational and theoretical advantages. We describe the key facts, list several concrete algorithms, and provide an extensive list of references for further reading. The survey recalls connections with utility theory and distributionally robust optimization, points to emerging applications areas such as fair machine learning, and defines measures of rel
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#38754;&#23545;&#33258;&#36866;&#24212;&#36873;&#25321;&#25968;&#25454;&#26679;&#26412;&#24341;&#36215;&#30340;&#36807;&#24230;&#25311;&#21512;&#38382;&#39064;&#65292;&#20351;&#29992;&#22122;&#22768;&#21152;&#31639;&#27861;&#21487;&#20197;&#25552;&#20379;&#19981;&#20381;&#36182;&#20110;&#26597;&#35810;&#35268;&#27169;&#30340;&#35823;&#24046;&#20445;&#35777;&#65292;&#36825;&#19968;&#32467;&#26524;&#34920;&#26126;&#36866;&#24212;&#25968;&#25454;&#20998;&#26512;&#30340;&#38382;&#39064;&#22312;&#20110;&#26032;&#26597;&#35810;&#19982;&#36807;&#21435;&#26597;&#35810;&#30340;&#21327;&#26041;&#24046;&#12290;</title><link>http://arxiv.org/abs/2106.10761</link><description>&lt;p&gt;
&#38754;&#23545;&#36866;&#24212;&#24615;&#27867;&#21270;&#65306;&#36125;&#21494;&#26031;&#35270;&#35282;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Generalization in the Face of Adaptivity: A Bayesian Perspective. (arXiv:2106.10761v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.10761
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#38754;&#23545;&#33258;&#36866;&#24212;&#36873;&#25321;&#25968;&#25454;&#26679;&#26412;&#24341;&#36215;&#30340;&#36807;&#24230;&#25311;&#21512;&#38382;&#39064;&#65292;&#20351;&#29992;&#22122;&#22768;&#21152;&#31639;&#27861;&#21487;&#20197;&#25552;&#20379;&#19981;&#20381;&#36182;&#20110;&#26597;&#35810;&#35268;&#27169;&#30340;&#35823;&#24046;&#20445;&#35777;&#65292;&#36825;&#19968;&#32467;&#26524;&#34920;&#26126;&#36866;&#24212;&#25968;&#25454;&#20998;&#26512;&#30340;&#38382;&#39064;&#22312;&#20110;&#26032;&#26597;&#35810;&#19982;&#36807;&#21435;&#26597;&#35810;&#30340;&#21327;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#36866;&#24212;&#36873;&#25321;&#26679;&#26412;&#21487;&#33021;&#23548;&#33268;&#36807;&#24230;&#25311;&#21512;&#65292;&#31616;&#21333;&#30340;&#22122;&#22768;&#21152;&#31639;&#27861;&#21487;&#20197;&#36991;&#20813;&#36825;&#19968;&#38382;&#39064;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;&#22122;&#22768;&#21152;&#31639;&#27861;&#21487;&#20197;&#25552;&#20379;&#19981;&#20381;&#36182;&#20110;&#26597;&#35810;&#35268;&#27169;&#30340;&#35823;&#24046;&#20445;&#35777;&#65292;&#36825;&#19968;&#32467;&#26524;&#26469;&#28304;&#20110;&#26356;&#22909;&#22320;&#29702;&#35299;&#33258;&#36866;&#24212;&#25968;&#25454;&#20998;&#26512;&#30340;&#26680;&#24515;&#38382;&#39064;&#12290;&#25105;&#20204;&#34920;&#26126;&#36866;&#24212;&#25968;&#25454;&#20998;&#26512;&#30340;&#38382;&#39064;&#22312;&#20110;&#26032;&#26597;&#35810;&#19982;&#36807;&#21435;&#26597;&#35810;&#30340;&#21327;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Repeated use of a data sample via adaptively chosen queries can rapidly lead to overfitting, wherein the empirical evaluation of queries on the sample significantly deviates from their mean with respect to the underlying data distribution. It turns out that simple noise addition algorithms suffice to prevent this issue, and differential privacy-based analysis of these algorithms shows that they can handle an asymptotically optimal number of queries. However, differential privacy's worst-case nature entails scaling such noise to the range of the queries even for highly-concentrated queries, or introducing more complex algorithms.  In this paper, we prove that straightforward noise-addition algorithms already provide variance-dependent guarantees that also extend to unbounded queries. This improvement stems from a novel characterization that illuminates the core problem of adaptive data analysis. We show that the harm of adaptivity results from the covariance between the new query and a 
&lt;/p&gt;</description></item></channel></rss>