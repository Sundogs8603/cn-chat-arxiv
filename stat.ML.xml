<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#23545;&#27604;&#24230;&#25104;&#20687;&#20013;&#30340;&#25968;&#25454;&#25554;&#20540;&#26041;&#27861;&#65292;&#36890;&#36807;&#20462;&#25913;&#26631;&#20934;Karhunen-Lo\`eve&#22270;&#20687;&#25237;&#24433;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#25955;&#26001;&#21435;&#38500;&#24182;&#24471;&#21040;&#20102;&#39640;&#36136;&#37327;&#30340;&#25104;&#20687;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.16912</link><description>&lt;p&gt;
Karhunen-Lo\`eve&#39640;&#23545;&#27604;&#24230;&#25104;&#20687;&#20013;&#30340;&#25968;&#25454;&#25554;&#20540;
&lt;/p&gt;
&lt;p&gt;
Karhunen-Lo\`eve Data Imputation in High Contrast Imaging. (arXiv:2308.16912v1 [astro-ph.IM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16912
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#23545;&#27604;&#24230;&#25104;&#20687;&#20013;&#30340;&#25968;&#25454;&#25554;&#20540;&#26041;&#27861;&#65292;&#36890;&#36807;&#20462;&#25913;&#26631;&#20934;Karhunen-Lo\`eve&#22270;&#20687;&#25237;&#24433;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#25955;&#26001;&#21435;&#38500;&#24182;&#24471;&#21040;&#20102;&#39640;&#36136;&#37327;&#30340;&#25104;&#20687;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#23545;&#27604;&#24230;&#25104;&#20687;&#20013;&#65292;&#26816;&#27979;&#21644;&#34920;&#24449;&#25193;&#23637;&#32467;&#26500;&#26159;&#19968;&#20010;&#33267;&#20851;&#37325;&#35201;&#30340;&#30446;&#26631;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#32467;&#26500;&#22312;&#25968;&#25454;&#38477;&#22122;&#26041;&#38754;&#38754;&#20020;&#25361;&#25112;&#65292;&#23548;&#33268;&#20102;&#20174;&#25955;&#26001;&#21644;&#33258;&#30456;&#20943;&#30340;&#36807;&#24230;&#20943;&#27861;&#20197;&#21450;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#30340;&#20809;&#27880;&#20837;&#12290;&#36845;&#20195;&#21518;&#22788;&#29702;&#26041;&#27861;&#25552;&#20379;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#65292;&#20294;&#23427;&#20204;&#30340;&#38598;&#25104;&#21040;&#29616;&#26377;&#30340;&#27969;&#31243;&#20013;&#21463;&#21040;&#36873;&#25321;&#24615;&#31639;&#27861;&#12289;&#39640;&#35745;&#31639;&#25104;&#26412;&#21644;&#31639;&#27861;&#27491;&#21017;&#21270;&#30340;&#38459;&#30861;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#22312;&#21442;&#32771;&#24046;&#20998;&#25104;&#20687;&#65288;RDI&#65289;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20197;Karhunen-Lo\`eve&#21464;&#25442;&#65288;DIKL&#65289;&#20026;&#22522;&#30784;&#30340;&#25968;&#25454;&#25554;&#20540;&#27010;&#24565;&#65292;&#36890;&#36807;&#20462;&#25913;&#26631;&#20934;Karhunen-Lo\`eve&#22270;&#20687;&#25237;&#24433;&#65288;KLIP&#65289;&#26041;&#27861;&#20013;&#30340;&#20004;&#20010;&#27493;&#39588;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23558;&#22270;&#20687;&#20998;&#21106;&#20026;&#20004;&#20010;&#30697;&#38453;&#65306;&#19968;&#20010;&#38170;&#23450;&#30697;&#38453;&#65292;&#20165;&#20851;&#27880;&#25955;&#26001;&#20197;&#33719;&#24471;DIKL&#31995;&#25968;&#65292;&#20197;&#21450;&#19968;&#20010;&#33337;&#22411;&#30697;&#38453;&#65292;&#19987;&#27880;&#20110;&#22825;&#20307;&#29289;&#29702;&#20852;&#36259;&#21306;&#22495;&#65292;&#20351;&#29992;DIKL&#25104;&#20998;&#36827;&#34892;&#25955;&#26001;&#21435;&#38500;&#12290;&#20316;&#20026;&#19968;&#31181;&#20998;&#26512;&#26041;&#27861;&#65292;DIKL&#21462;&#24471;&#20102;&#39640;&#36136;&#37327;&#30340;&#32467;&#26524;&#65292;&#20855;&#26377;&#26174;&#33879;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Detection and characterization of extended structures is a crucial goal in high contrast imaging. However, these structures face challenges in data reduction, leading to over-subtraction from speckles and self-subtraction with most existing methods. Iterative post-processing methods offer promising results, but their integration into existing pipelines is hindered by selective algorithms, high computational cost, and algorithmic regularization. To address this for reference differential imaging (RDI), here we propose the data imputation concept to Karhunen-Lo\`eve transform (DIKL) by modifying two steps in the standard Karhunen-Lo\`eve image projection (KLIP) method. Specifically, we partition an image to two matrices: an anchor matrix which focuses only on the speckles to obtain the DIKL coefficients, and a boat matrix which focuses on the regions of astrophysical interest for speckle removal using DIKL components. As an analytical approach, DIKL achieves high-quality results with sig
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#21160;&#24577;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DDAG&#65289;&#30340;&#20449;&#24687;&#29702;&#35770;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35266;&#27979;&#26102;&#38388;&#24207;&#21015;&#30340;&#21151;&#29575;&#35889;&#23494;&#24230;&#30697;&#38453;&#30340;&#24230;&#37327;&#21644;&#31639;&#27861;&#26469;&#37325;&#24314;DDAG&#12290;</title><link>http://arxiv.org/abs/2308.16859</link><description>&lt;p&gt;
&#23398;&#20064;&#21160;&#24577;&#26377;&#21521;&#26080;&#29615;&#22270;&#30340;&#20449;&#24687;&#29702;&#35770;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
Information Theoretically Optimal Sample Complexity of Learning Dynamical Directed Acyclic Graphs. (arXiv:2308.16859v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16859
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#21160;&#24577;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DDAG&#65289;&#30340;&#20449;&#24687;&#29702;&#35770;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35266;&#27979;&#26102;&#38388;&#24207;&#21015;&#30340;&#21151;&#29575;&#35889;&#23494;&#24230;&#30697;&#38453;&#30340;&#24230;&#37327;&#21644;&#31639;&#27861;&#26469;&#37325;&#24314;DDAG&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#65288;LDS&#65289;&#22312;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#19978;&#30340;&#24213;&#23618;&#30456;&#20114;&#20316;&#29992;/&#20381;&#36182;&#20851;&#31995;&#30340;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#23398;&#20064;DAG&#32467;&#26500;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#22312;&#38745;&#24577;&#31995;&#32479;&#20013;&#24050;&#32463;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#30740;&#31350;&#65292;&#20854;&#20013;&#33410;&#28857;&#29366;&#24577;&#30340;&#26679;&#26412;&#26159;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#65288;i.i.d.&#65289;&#12290;&#28982;&#32780;&#65292;&#22312;&#20855;&#26377;&#21160;&#24577;&#31995;&#32479;&#30340;DAG&#20013;&#65292;&#36825;&#26679;&#30340;&#30740;&#31350;&#36739;&#23569;&#12290;&#25105;&#20204;&#23558;&#36825;&#26679;&#30340;DAG&#31216;&#20026;\emph{&#21160;&#24577;}DAG&#65288;DDAG&#65289;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;DDAG&#65292;&#20854;&#20013;&#33410;&#28857;&#21160;&#21147;&#23398;&#30001;&#26410;&#35266;&#27979;&#30340;&#22806;&#29983;&#22122;&#22768;&#28304;&#39537;&#21160;&#65292;&#36825;&#20123;&#22122;&#22768;&#28304;&#22312;&#26102;&#38388;&#19978;&#26159;&#23485;&#24133;&#24179;&#31283;&#30340;&#65288;WSS&#65289;&#65292;&#20294;&#24444;&#27492;&#20043;&#38388;&#26159;&#19981;&#30456;&#20851;&#30340;&#65292;&#24182;&#19988;&#20855;&#26377;&#30456;&#21516;&#30340;&#21151;&#29575;&#35889;&#23494;&#24230;&#65288;PSD&#65289;&#12290;&#21463;&#38745;&#24577;&#35774;&#32622;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35266;&#27979;&#26102;&#38388;&#24207;&#21015;&#30340;PSD&#30697;&#38453;&#30340;&#24230;&#37327;&#21644;&#31639;&#27861;&#26469;&#37325;&#24314;DDAG&#12290;&#22122;&#22768;PSD&#30456;&#31561;&#30340;&#20551;&#35774;&#21487;&#20197;&#25918;&#23485;&#65292;&#20197;&#20351;&#20854;&#21487;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this article, the optimal sample complexity of learning the underlying interaction/dependencies of a Linear Dynamical System (LDS) over a Directed Acyclic Graph (DAG) is studied. The sample complexity of learning a DAG's structure is well-studied for static systems, where the samples of nodal states are independent and identically distributed (i.i.d.). However, such a study is less explored for DAGs with dynamical systems, where the nodal states are temporally correlated. We call such a DAG underlying an LDS as \emph{dynamical} DAG (DDAG). In particular, we consider a DDAG where the nodal dynamics are driven by unobserved exogenous noise sources that are wide-sense stationary (WSS) in time but are mutually uncorrelated, and have the same {power spectral density (PSD)}. Inspired by the static settings, a metric and an algorithm based on the PSD matrix of the observed time series are proposed to reconstruct the DDAG. The equal noise PSD assumption can be relaxed such that identifiabil
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22810;&#20803;&#23431;&#23449;&#20998;&#26512;&#35780;&#20272;&#27169;&#22411;&#35774;&#35745;&#20915;&#31574;&#23545;&#31639;&#27861;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#65292;&#21487;&#20197;&#25581;&#31034;&#31639;&#27861;&#20915;&#31574;&#31995;&#32479;&#20013;&#35774;&#35745;&#20915;&#31574;&#30340;&#20851;&#38190;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2308.16681</link><description>&lt;p&gt;
&#36890;&#36807;&#22810;&#20803;&#23431;&#23449;&#20998;&#26512;&#35780;&#20272;&#27169;&#22411;&#35774;&#35745;&#20915;&#31574;&#23545;&#31639;&#27861;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#65306;&#19968;&#20999;&#65292;&#26080;&#22788;&#19981;&#22312;&#65292;&#20840;&#26041;&#20301;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Everything, Everywhere All in One Evaluation: Using Multiverse Analysis to Evaluate the Influence of Model Design Decisions on Algorithmic Fairness. (arXiv:2308.16681v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16681
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22810;&#20803;&#23431;&#23449;&#20998;&#26512;&#35780;&#20272;&#27169;&#22411;&#35774;&#35745;&#20915;&#31574;&#23545;&#31639;&#27861;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#65292;&#21487;&#20197;&#25581;&#31034;&#31639;&#27861;&#20915;&#31574;&#31995;&#32479;&#20013;&#35774;&#35745;&#20915;&#31574;&#30340;&#20851;&#38190;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20840;&#29699;&#33539;&#22260;&#20869;&#30340;&#35768;&#22810;&#31995;&#32479;&#37117;&#21033;&#29992;&#31639;&#27861;&#20915;&#31574;&#26469;&#65288;&#37096;&#20998;&#65289;&#33258;&#21160;&#21270;&#20197;&#21069;&#30001;&#20154;&#31867;&#36827;&#34892;&#30340;&#20915;&#31574;&#12290;&#24403;&#35774;&#35745;&#33391;&#22909;&#26102;&#65292;&#36825;&#20123;&#31995;&#32479;&#25215;&#35834;&#26356;&#23458;&#35266;&#30340;&#20915;&#31574;&#65292;&#21516;&#26102;&#33410;&#30465;&#22823;&#37327;&#36164;&#28304;&#65292;&#33410;&#32422;&#20154;&#21147;&#12290;&#28982;&#32780;&#65292;&#24403;&#31639;&#27861;&#20915;&#31574;&#31995;&#32479;&#35774;&#35745;&#19981;&#33391;&#26102;&#65292;&#21487;&#33021;&#20250;&#23548;&#33268;&#23545;&#31038;&#20250;&#32676;&#20307;&#36827;&#34892;&#27495;&#35270;&#30340;&#19981;&#20844;&#24179;&#20915;&#31574;&#12290;&#31639;&#27861;&#20915;&#31574;&#31995;&#32479;&#30340;&#19979;&#28216;&#25928;&#24212;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#21462;&#20915;&#20110;&#31995;&#32479;&#35774;&#35745;&#21644;&#23454;&#26045;&#36807;&#31243;&#20013;&#30340;&#20915;&#31574;&#65292;&#22240;&#20026;&#25968;&#25454;&#20013;&#30340;&#20559;&#35265;&#21487;&#33021;&#20250;&#22312;&#24314;&#27169;&#36807;&#31243;&#20013;&#32531;&#35299;&#25110;&#21152;&#24378;&#12290;&#35768;&#22810;&#36825;&#20123;&#35774;&#35745;&#20915;&#31574;&#26159;&#38544;&#21547;&#36827;&#34892;&#30340;&#65292;&#19981;&#30693;&#36947;&#23427;&#20204;&#30830;&#20999;&#22320;&#22914;&#20309;&#24433;&#21709;&#26368;&#32456;&#31995;&#32479;&#12290;&#22240;&#27492;&#65292;&#26126;&#30830;&#31639;&#27861;&#20915;&#31574;&#31995;&#32479;&#35774;&#35745;&#20013;&#30340;&#20915;&#31574;&#24182;&#20102;&#35299;&#36825;&#20123;&#20915;&#31574;&#22914;&#20309;&#24433;&#21709;&#32467;&#26524;&#31995;&#32479;&#30340;&#20844;&#24179;&#24615;&#38750;&#24120;&#37325;&#35201;&#12290;&#20026;&#20102;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20511;&#37492;&#20102;&#24515;&#29702;&#23398;&#39046;&#22495;&#30340;&#35265;&#35299;&#65292;&#24182;&#24341;&#20837;&#20102;&#22810;&#20803;&#23431;&#23449;&#20998;&#26512;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
A vast number of systems across the world use algorithmic decision making (ADM) to (partially) automate decisions that have previously been made by humans. When designed well, these systems promise more objective decisions while saving large amounts of resources and freeing up human time. However, when ADM systems are not designed well, they can lead to unfair decisions which discriminate against societal groups. The downstream effects of ADMs critically depend on the decisions made during the systems' design and implementation, as biases in data can be mitigated or reinforced along the modeling pipeline. Many of these design decisions are made implicitly, without knowing exactly how they will influence the final system. It is therefore important to make explicit the decisions made during the design of ADM systems and understand how these decisions affect the fairness of the resulting system.  To study this issue, we draw on insights from the field of psychology and introduce the metho
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#24212;&#29992;&#22810;&#31181;&#26799;&#24230;&#20272;&#35745;&#25216;&#26415;&#23454;&#29616;&#23545;&#20855;&#26377;&#31163;&#25955;&#21644;&#20998;&#25903;&#38543;&#26426;&#24615;&#30340;&#31243;&#24207;&#36827;&#34892;&#27714;&#23548;&#30340;&#26041;&#27861;&#65292;&#24182;&#21457;&#23637;&#20102;&#39318;&#20010;&#23436;&#20840;&#21487;&#24494;&#20998;&#30340;&#20998;&#25903;&#31243;&#24207;&#65292;&#36825;&#39033;&#24037;&#20316;&#30340;&#36129;&#29486;&#22312;&#20110;&#20026;&#39640;&#33021;&#29289;&#29702;&#20013;&#30340;&#26799;&#24230;&#20248;&#21270;&#25552;&#20379;&#20102;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.16680</link><description>&lt;p&gt;
&#26641;&#30340;&#20998;&#25903;&#65306;&#22312;&#39640;&#33021;&#29289;&#29702;&#20013;&#23545;&#20855;&#26377;&#31163;&#25955;&#21644;&#20998;&#25903;&#38543;&#26426;&#24615;&#30340;&#31243;&#24207;&#36827;&#34892;&#27714;&#23548;
&lt;/p&gt;
&lt;p&gt;
Branches of a Tree: Taking Derivatives of Programs with Discrete and Branching Randomness in High Energy Physics. (arXiv:2308.16680v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16680
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#24212;&#29992;&#22810;&#31181;&#26799;&#24230;&#20272;&#35745;&#25216;&#26415;&#23454;&#29616;&#23545;&#20855;&#26377;&#31163;&#25955;&#21644;&#20998;&#25903;&#38543;&#26426;&#24615;&#30340;&#31243;&#24207;&#36827;&#34892;&#27714;&#23548;&#30340;&#26041;&#27861;&#65292;&#24182;&#21457;&#23637;&#20102;&#39318;&#20010;&#23436;&#20840;&#21487;&#24494;&#20998;&#30340;&#20998;&#25903;&#31243;&#24207;&#65292;&#36825;&#39033;&#24037;&#20316;&#30340;&#36129;&#29486;&#22312;&#20110;&#20026;&#39640;&#33021;&#29289;&#29702;&#20013;&#30340;&#26799;&#24230;&#20248;&#21270;&#25552;&#20379;&#20102;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#24212;&#29992;&#22810;&#31181;&#26799;&#24230;&#20272;&#35745;&#25216;&#26415;&#26469;&#23454;&#29616;&#23545;&#22312;&#39640;&#33021;&#29289;&#29702;&#20013;&#20855;&#26377;&#31163;&#25955;&#38543;&#26426;&#24615;&#30340;&#31243;&#24207;&#36827;&#34892;&#27714;&#23548;&#12290;&#30001;&#20110;&#23384;&#22312;&#20998;&#25903;&#36807;&#31243;&#21644;&#22522;&#20110;&#32858;&#31867;&#30340;&#20998;&#26512;&#65292;&#27492;&#31867;&#31243;&#24207;&#22312;&#39640;&#33021;&#29289;&#29702;&#20013;&#24456;&#24120;&#35265;&#12290;&#22240;&#27492;&#65292;&#23545;&#36825;&#31867;&#31243;&#24207;&#36827;&#34892;&#27714;&#23548;&#21487;&#20197;&#20026;&#26799;&#24230;&#20248;&#21270;&#22312;&#25506;&#27979;&#22120;&#35774;&#35745;&#20248;&#21270;&#12289;&#27169;&#25311;&#22120;&#35843;&#25972;&#25110;&#25968;&#25454;&#20998;&#26512;&#21644;&#37325;&#26500;&#20248;&#21270;&#31561;&#26041;&#38754;&#24320;&#36767;&#36947;&#36335;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#20960;&#31181;&#21487;&#33021;&#30340;&#26799;&#24230;&#20272;&#35745;&#31574;&#30053;&#65292;&#21253;&#25324;&#26368;&#36817;&#30340;&#38543;&#26426;&#33258;&#21160;&#24494;&#20998;&#65288;Stochastic AD&#65289;&#26041;&#27861;&#65292;&#24182;&#22312;&#31616;&#21270;&#30340;&#25506;&#27979;&#22120;&#35774;&#35745;&#23454;&#39564;&#20013;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#22312;&#36825;&#26679;&#20570;&#30340;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#36804;&#20170;&#20026;&#27490;&#39318;&#20010;&#23436;&#20840;&#21487;&#24494;&#20998;&#30340;&#20998;&#25903;&#31243;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose to apply several gradient estimation techniques to enable the differentiation of programs with discrete randomness in High Energy Physics. Such programs are common in High Energy Physics due to the presence of branching processes and clustering-based analysis. Thus differentiating such programs can open the way for gradient based optimization in the context of detector design optimization, simulator tuning, or data analysis and reconstruction optimization. We discuss several possible gradient estimation strategies, including the recent Stochastic AD method, and compare them in simplified detector design experiments. In doing so we develop, to the best of our knowledge, the first fully differentiable branching program.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#22810;&#20809;&#35889;&#20449;&#24687;&#35299;&#37322;&#39640;&#20869;&#23481;&#25104;&#20687;&#20013;&#32454;&#32990;&#29983;&#29289;&#23398;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#20219;&#24847;&#25968;&#37327;&#30340;&#36890;&#36947;&#36827;&#34892;&#22270;&#20687;&#21512;&#25104;&#21644;&#22788;&#29702;&#65292;&#35299;&#20915;&#20102;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#32570;&#20047;&#36890;&#36947;&#37325;&#35201;&#24615;&#20449;&#24687;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.16637</link><description>&lt;p&gt;
&#21033;&#29992;&#21487;&#35299;&#37322;&#30340;&#28145;&#24230;&#36755;&#20837;&#36890;&#36947;&#28151;&#21512;&#23398;&#20064;&#39640;&#20869;&#23481;&#25104;&#20687;&#20013;&#30340;&#36890;&#36947;&#37325;&#35201;&#24615;
&lt;/p&gt;
&lt;p&gt;
Learning Channel Importance for High Content Imaging with Interpretable Deep Input Channel Mixing. (arXiv:2308.16637v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16637
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#22810;&#20809;&#35889;&#20449;&#24687;&#35299;&#37322;&#39640;&#20869;&#23481;&#25104;&#20687;&#20013;&#32454;&#32990;&#29983;&#29289;&#23398;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#20219;&#24847;&#25968;&#37327;&#30340;&#36890;&#36947;&#36827;&#34892;&#22270;&#20687;&#21512;&#25104;&#21644;&#22788;&#29702;&#65292;&#35299;&#20915;&#20102;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#32570;&#20047;&#36890;&#36947;&#37325;&#35201;&#24615;&#20449;&#24687;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21457;&#29616;&#27835;&#30103;&#22797;&#26434;&#30142;&#30149;&#30340;&#26032;&#33647;&#20505;&#36873;&#29289;&#20173;&#28982;&#26159;&#26089;&#26399;&#21457;&#29616;&#30740;&#31350;&#20013;&#26368;&#20855;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#20043;&#19968;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#29983;&#29289;&#21307;&#33647;&#30740;&#31350;&#24314;&#31435;&#20102;&#19968;&#20010;&#26631;&#20934;&#21270;&#30340;&#39640;&#20869;&#23481;&#25104;&#20687;&#21327;&#35758;&#65292;&#23545;&#27599;&#20010;&#22270;&#20687;&#36890;&#36947;&#36827;&#34892;&#19981;&#21516;&#30340;&#32454;&#32990;&#21306;&#22495;&#26631;&#35760;&#12290;&#20026;&#20102;&#35780;&#21028;&#23454;&#39564;&#32467;&#26524;&#65292;&#31185;&#23398;&#23478;&#38656;&#35201;&#20102;&#35299;&#19982;&#26576;&#31181;&#34920;&#22411;&#30456;&#20851;&#30340;&#36890;&#36947;&#37325;&#35201;&#24615;&#65292;&#20197;&#35299;&#30721;&#28508;&#22312;&#30340;&#29983;&#29289;&#23398;&#12290;&#19982;&#20256;&#32479;&#30340;&#22270;&#20687;&#20998;&#26512;&#26041;&#27861;&#30456;&#27604;&#65292;&#36825;&#31181;&#23454;&#39564;&#29616;&#22312;&#26356;&#20542;&#21521;&#20110;&#20351;&#29992;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#36827;&#34892;&#20998;&#26512;&#65292;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#32570;&#20047;&#20851;&#20110;&#36890;&#36947;&#37325;&#35201;&#24615;&#30340;&#20851;&#38190;&#20449;&#24687;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#39640;&#20869;&#23481;&#22270;&#20687;&#30340;&#22810;&#20809;&#35889;&#20449;&#24687;&#26469;&#35299;&#37322;&#32454;&#32990;&#29983;&#29289;&#23398;&#30340;&#26576;&#20010;&#26041;&#38754;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#22522;&#20110;&#22270;&#20687;&#28151;&#21512;&#27010;&#24565;&#21644;alpha&#28151;&#21512;&#26041;&#27861;&#65292;&#23545;&#20219;&#24847;&#25968;&#37327;&#30340;&#36890;&#36947;&#36827;&#34892;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncovering novel drug candidates for treating complex diseases remain one of the most challenging tasks in early discovery research. To tackle this challenge, biopharma research established a standardized high content imaging protocol that tags different cellular compartments per image channel. In order to judge the experimental outcome, the scientist requires knowledge about the channel importance with respect to a certain phenotype for decoding the underlying biology. In contrast to traditional image analysis approaches, such experiments are nowadays preferably analyzed by deep learning based approaches which, however, lack crucial information about the channel importance. To overcome this limitation, we present a novel approach which utilizes multi-spectral information of high content images to interpret a certain aspect of cellular biology. To this end, we base our method on image blending concepts with alpha compositing for an arbitrary number of channels. More specifically, we in
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#39640;&#32423;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21644;&#22810;&#21464;&#37327;&#36755;&#20837;&#26469;&#39044;&#27979;&#24613;&#35786;&#23460;&#25317;&#25380;&#65292;&#21457;&#29616;N-BEATS&#21644;LightGBM&#30456;&#36739;&#20110;&#22522;&#20934;&#27169;&#22411;&#20998;&#21035;&#25552;&#20379;&#20102;11%&#21644;9%&#30340;&#24615;&#33021;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2308.16544</link><description>&lt;p&gt;
&#20351;&#29992;&#39640;&#32423;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21644;&#22810;&#21464;&#37327;&#36755;&#20837;&#39044;&#27979;&#24613;&#35786;&#23460;&#25317;&#25380;
&lt;/p&gt;
&lt;p&gt;
Forecasting Emergency Department Crowding with Advanced Machine Learning Models and Multivariable Input. (arXiv:2308.16544v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16544
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#39640;&#32423;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21644;&#22810;&#21464;&#37327;&#36755;&#20837;&#26469;&#39044;&#27979;&#24613;&#35786;&#23460;&#25317;&#25380;&#65292;&#21457;&#29616;N-BEATS&#21644;LightGBM&#30456;&#36739;&#20110;&#22522;&#20934;&#27169;&#22411;&#20998;&#21035;&#25552;&#20379;&#20102;11%&#21644;9%&#30340;&#24615;&#33021;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24613;&#35786;&#23460;&#25317;&#25380;&#23545;&#24739;&#32773;&#30340;&#23433;&#20840;&#26500;&#25104;&#37325;&#22823;&#23041;&#32961;&#65292;&#24182;&#19988;&#19982;&#22686;&#21152;&#30340;&#27515;&#20129;&#29575;&#26377;&#20851;&#12290;&#39044;&#27979;&#26410;&#26469;&#30340;&#26381;&#21153;&#38656;&#27714;&#26377;&#28508;&#22312;&#30340;&#24739;&#32773;&#32467;&#26524;&#12290;&#23613;&#31649;&#23545;&#36825;&#20010;&#20027;&#39064;&#36827;&#34892;&#20102;&#31215;&#26497;&#30340;&#30740;&#31350;&#65292;&#20294;&#20173;&#23384;&#22312;&#20960;&#20010;&#24046;&#36317;&#65306;1&#65289;&#30001;&#20110;&#24555;&#36895;&#22686;&#21152;&#30340;&#39640;&#32423;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65288;ML&#65289;&#65292;&#25152;&#25552;&#20986;&#30340;&#39044;&#27979;&#27169;&#22411;&#21464;&#24471;&#36807;&#26102;&#65292;2&#65289;&#22810;&#21464;&#37327;&#36755;&#20837;&#25968;&#25454;&#30340;&#37327;&#26377;&#38480;&#65292;3&#65289;&#24456;&#23569;&#25253;&#21578;&#20855;&#20307;&#30340;&#24615;&#33021;&#25351;&#26631;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35760;&#24405;&#20102;&#19968;&#32452;&#20808;&#36827;&#30340;ML&#27169;&#22411;&#22312;&#39044;&#27979;24&#23567;&#26102;&#21069;&#30340;&#24613;&#35786;&#23460;&#21344;&#29992;&#29575;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#22823;&#22411;&#32508;&#21512;&#24613;&#35786;&#23460;&#30340;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#25968;&#25454;&#21644;&#19968;&#31995;&#21015;&#35299;&#37322;&#21464;&#37327;&#65292;&#21253;&#25324;&#25937;&#27835;&#21306;&#22495;&#21307;&#38498;&#30340;&#24202;&#20301;&#21487;&#29992;&#24615;&#65292;&#26469;&#33258;&#24403;&#22320;&#35266;&#27979;&#31449;&#30340;&#20132;&#36890;&#25968;&#25454;&#65292;&#22825;&#27668;&#21464;&#37327;&#31561;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;N-BEATS&#21644;LightGBM&#22312;11&#65285;&#21644;9&#65285;&#30340;&#25913;&#36827;&#20013;&#36229;&#36234;&#20102;&#22522;&#20934;&#65292;&#24182;&#19988;DeepAR&#21487;&#20197;&#39044;&#27979;&#31532;&#20108;&#22825;&#30340;&#20154;&#21592;&#29366;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Emergency department (ED) crowding is a significant threat to patient safety and it has been repeatedly associated with increased mortality. Forecasting future service demand has the potential patient outcomes. Despite active research on the subject, several gaps remain: 1) proposed forecasting models have become outdated due to quick influx of advanced machine learning models (ML), 2) amount of multivariable input data has been limited and 3) discrete performance metrics have been rarely reported. In this study, we document the performance of a set of advanced ML models in forecasting ED occupancy 24 hours ahead. We use electronic health record data from a large, combined ED with an extensive set of explanatory variables, including the availability of beds in catchment area hospitals, traffic data from local observation stations, weather variables, etc. We show that N-BEATS and LightGBM outpeform benchmarks with 11 % and 9 % respective improvements and that DeepAR predicts next day cr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35760;&#24518;&#24433;&#21709;&#26426;&#21046;&#29992;&#20110;&#26368;&#23567;&#20108;&#20056;&#25903;&#25345;&#21521;&#37327;&#26426;&#65292;&#33021;&#22815;&#20934;&#30830;&#21010;&#20998;&#35757;&#32451;&#38598;&#24182;&#36991;&#20813;&#36807;&#25311;&#21512;&#65292;&#25552;&#20986;&#30340;&#26368;&#22823;&#35760;&#24518;&#24433;&#21709;&#27169;&#22411;&#21644;&#21152;&#26435;&#35760;&#24518;&#24433;&#21709;&#27169;&#22411;&#22312;&#27867;&#21270;&#24615;&#33021;&#21644;&#26102;&#38388;&#25104;&#26412;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2308.16456</link><description>&lt;p&gt;
&#26368;&#23567;&#20108;&#20056;&#27861;&#26368;&#22823;&#21270;&#21644;&#21152;&#26435;&#27867;&#21270;&#35760;&#24518;&#26426;
&lt;/p&gt;
&lt;p&gt;
Least Squares Maximum and Weighted Generalization-Memorization Machines. (arXiv:2308.16456v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16456
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35760;&#24518;&#24433;&#21709;&#26426;&#21046;&#29992;&#20110;&#26368;&#23567;&#20108;&#20056;&#25903;&#25345;&#21521;&#37327;&#26426;&#65292;&#33021;&#22815;&#20934;&#30830;&#21010;&#20998;&#35757;&#32451;&#38598;&#24182;&#36991;&#20813;&#36807;&#25311;&#21512;&#65292;&#25552;&#20986;&#30340;&#26368;&#22823;&#35760;&#24518;&#24433;&#21709;&#27169;&#22411;&#21644;&#21152;&#26435;&#35760;&#24518;&#24433;&#21709;&#27169;&#22411;&#22312;&#27867;&#21270;&#24615;&#33021;&#21644;&#26102;&#38388;&#25104;&#26412;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26368;&#23567;&#20108;&#20056;&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;LSSVM&#65289;&#30340;&#35760;&#24518;&#24433;&#21709;&#26426;&#21046;&#65292;&#23454;&#29616;&#35760;&#24518;&#30340;&#26032;&#26041;&#27861;&#12290;&#22312;&#19981;&#25913;&#21464;&#21407;&#22987;LSSVM&#26041;&#31243;&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#65292;&#35813;&#26426;&#21046;&#33021;&#22815;&#20934;&#30830;&#22320;&#23545;&#35757;&#32451;&#38598;&#36827;&#34892;&#21010;&#20998;&#65292;&#36991;&#20813;&#36807;&#25311;&#21512;&#12290;&#28982;&#21518;&#25552;&#20986;&#20102;&#26368;&#22823;&#35760;&#24518;&#24433;&#21709;&#27169;&#22411;&#65288;MIMM&#65289;&#21644;&#21152;&#26435;&#35760;&#24518;&#24433;&#21709;&#27169;&#22411;&#65288;WIMM&#65289;&#12290;&#23454;&#39564;&#35777;&#26126;&#36825;&#20123;&#27169;&#22411;&#21487;&#20197;&#36864;&#21270;&#20026;LSSVM&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#20026;MIMM&#21644;WIMM&#25552;&#20986;&#20102;&#19968;&#20123;&#19981;&#21516;&#30340;&#35760;&#24518;&#24433;&#21709;&#20989;&#25968;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#30456;&#27604;&#20110;LSSVM&#65292;&#25105;&#20204;&#30340;MIMM&#21644;WIMM&#22312;&#27867;&#21270;&#24615;&#33021;&#19978;&#26377;&#26356;&#22909;&#30340;&#34920;&#29616;&#65292;&#24182;&#19988;&#22312;&#26102;&#38388;&#25104;&#26412;&#19978;&#27604;&#20854;&#20182;&#35760;&#24518;&#27169;&#22411;&#20855;&#26377;&#26126;&#26174;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a new way of remembering by introducing a memory influence mechanism for the least squares support vector machine (LSSVM). Without changing the equation constraints of the original LSSVM, this mechanism, allows an accurate partitioning of the training set without overfitting. The maximum memory impact model (MIMM) and the weighted impact memory model (WIMM) are then proposed. It is demonstrated that these models can be degraded to the LSSVM. Furthermore, we propose some different memory impact functions for the MIMM and WIMM. The experimental results show that that our MIMM and WIMM have better generalization performance compared to the LSSVM and significant advantage in time cost compared to other memory models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#38544;&#24335;&#31070;&#32463;&#32593;&#32476;&#65292;&#25552;&#20379;&#20102;&#20849;&#36717;&#26680;&#21644;&#31070;&#32463;&#20999;&#21521;&#26680;&#30340;&#39640;&#32500;&#31561;&#20215;&#34920;&#36798;&#65292;&#24182;&#22312;&#39640;&#32500;&#31354;&#38388;&#24314;&#31435;&#20102;&#38544;&#24335;&#32593;&#32476;&#21644;&#26174;&#24335;&#32593;&#32476;&#30340;&#31561;&#20215;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.16425</link><description>&lt;p&gt;
&#38544;&#24335;&#31070;&#32463;&#32593;&#32476;&#19982;&#26174;&#24335;&#31070;&#32463;&#32593;&#32476;&#30340;&#31561;&#20215;&#24615;&#65306;&#39640;&#32500;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
On the Equivalence between Implicit and Explicit Neural Networks: A High-dimensional Viewpoint. (arXiv:2308.16425v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16425
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#38544;&#24335;&#31070;&#32463;&#32593;&#32476;&#65292;&#25552;&#20379;&#20102;&#20849;&#36717;&#26680;&#21644;&#31070;&#32463;&#20999;&#21521;&#26680;&#30340;&#39640;&#32500;&#31561;&#20215;&#34920;&#36798;&#65292;&#24182;&#22312;&#39640;&#32500;&#31354;&#38388;&#24314;&#31435;&#20102;&#38544;&#24335;&#32593;&#32476;&#21644;&#26174;&#24335;&#32593;&#32476;&#30340;&#31561;&#20215;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38544;&#24335;&#31070;&#32463;&#32593;&#32476;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#38544;&#24335;&#32593;&#32476;&#21644;&#26174;&#24335;&#32593;&#32476;&#20043;&#38388;&#30340;&#36830;&#25509;&#21644;&#24046;&#24322;&#32570;&#20047;&#29702;&#35770;&#20998;&#26512;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#38544;&#24335;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#20026;&#23545;&#24212;&#30340;&#20849;&#36717;&#26680;&#21644;&#31070;&#32463;&#20999;&#21521;&#26680;&#25552;&#20379;&#20102;&#39640;&#32500;&#31561;&#20215;&#34920;&#36798;&#12290;&#22522;&#20110;&#27492;&#65292;&#25105;&#20204;&#22312;&#39640;&#32500;&#31354;&#38388;&#24314;&#31435;&#20102;&#38544;&#24335;&#32593;&#32476;&#21644;&#26174;&#24335;&#32593;&#32476;&#30340;&#31561;&#20215;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Implicit neural networks have demonstrated remarkable success in various tasks. However, there is a lack of theoretical analysis of the connections and differences between implicit and explicit networks. In this paper, we study high-dimensional implicit neural networks and provide the high dimensional equivalents for the corresponding conjugate kernels and neural tangent kernels. Built upon this, we establish the equivalence between implicit and explicit networks in high dimensions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23646;&#24615;&#32593;&#32476;&#30340;&#31038;&#21306;&#26816;&#27979;&#26041;&#27861;&#65292;&#20351;&#29992;&#20102;&#38598;&#25104;&#33410;&#28857;&#20171;&#25968;&#20013;&#24515;&#24230;&#21644;&#32858;&#31867;&#31995;&#25968;&#30340;&#38543;&#26426;&#22359;&#27169;&#22411;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#35813;&#27169;&#22411;&#36824;&#32771;&#34385;&#20102;&#31038;&#21306;&#20043;&#38388;&#30340;&#27010;&#29575;&#65292;&#21487;&#20197;&#26816;&#27979;&#22810;&#26041;&#32467;&#26500;&#21644;&#28151;&#21512;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2308.16382</link><description>&lt;p&gt;
&#22522;&#20110;&#23646;&#24615;&#32593;&#32476;&#30340;&#31038;&#21306;&#26816;&#27979;&#30340;&#38543;&#26426;&#22359;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A stochastic block model for community detection in attributed networks. (arXiv:2308.16382v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16382
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23646;&#24615;&#32593;&#32476;&#30340;&#31038;&#21306;&#26816;&#27979;&#26041;&#27861;&#65292;&#20351;&#29992;&#20102;&#38598;&#25104;&#33410;&#28857;&#20171;&#25968;&#20013;&#24515;&#24230;&#21644;&#32858;&#31867;&#31995;&#25968;&#30340;&#38543;&#26426;&#22359;&#27169;&#22411;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#35813;&#27169;&#22411;&#36824;&#32771;&#34385;&#20102;&#31038;&#21306;&#20043;&#38388;&#30340;&#27010;&#29575;&#65292;&#21487;&#20197;&#26816;&#27979;&#22810;&#26041;&#32467;&#26500;&#21644;&#28151;&#21512;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#21306;&#26816;&#27979;&#26159;&#22797;&#26434;&#32593;&#32476;&#20998;&#26512;&#20013;&#30340;&#37325;&#35201;&#20869;&#23481;&#12290;&#29616;&#26377;&#30340;&#22522;&#20110;&#23646;&#24615;&#32593;&#32476;&#30340;&#31038;&#21306;&#26816;&#27979;&#26041;&#27861;&#22823;&#22810;&#20165;&#20851;&#27880;&#32593;&#32476;&#32467;&#26500;&#65292;&#32780;&#38598;&#25104;&#33410;&#28857;&#23646;&#24615;&#30340;&#26041;&#27861;&#20027;&#35201;&#29992;&#20110;&#20256;&#32479;&#30340;&#31038;&#21306;&#32467;&#26500;&#65292;&#26080;&#27861;&#26816;&#27979;&#32593;&#32476;&#20013;&#30340;&#22810;&#26041;&#32467;&#26500;&#21644;&#28151;&#21512;&#32467;&#26500;&#12290;&#27492;&#22806;&#65292;&#30446;&#21069;&#38024;&#23545;&#23646;&#24615;&#32593;&#32476;&#25552;&#20986;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#31038;&#21306;&#26816;&#27979;&#26041;&#27861;&#24182;&#27809;&#26377;&#20805;&#20998;&#32771;&#34385;&#33410;&#28857;&#30340;&#29420;&#29305;&#25299;&#25169;&#20449;&#24687;&#65292;&#20363;&#22914;&#20171;&#25968;&#20013;&#24515;&#24230;&#21644;&#32858;&#31867;&#31995;&#25968;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38598;&#25104;&#33410;&#28857;&#20171;&#25968;&#20013;&#24515;&#24230;&#21644;&#32858;&#31867;&#31995;&#25968;&#30340;&#38543;&#26426;&#22359;&#27169;&#22411;&#29992;&#20110;&#23646;&#24615;&#32593;&#32476;&#30340;&#31038;&#21306;&#26816;&#27979;&#65292;&#31216;&#20026;BCSBM&#27169;&#22411;&#12290;&#19982;&#20854;&#20182;&#23646;&#24615;&#32593;&#32476;&#29983;&#25104;&#27169;&#22411;&#19981;&#21516;&#65292;BCSBM&#27169;&#22411;&#20013;&#38142;&#25509;&#21644;&#23646;&#24615;&#30340;&#29983;&#25104;&#36807;&#31243;&#36981;&#24490;&#27850;&#26494;&#20998;&#24067;&#65292;&#24182;&#32771;&#34385;&#20102;&#31038;&#21306;&#20043;&#38388;&#30340;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Community detection is an important content in complex network analysis. The existing community detection methods in attributed networks mostly focus on only using network structure, while the methods of integrating node attributes is mainly for the traditional community structures, and cannot detect multipartite structures and mixture structures in network. In addition, the model-based community detection methods currently proposed for attributed networks do not fully consider unique topology information of nodes, such as betweenness centrality and clustering coefficient. Therefore, a stochastic block model that integrates betweenness centrality and clustering coefficient of nodes for community detection in attributed networks, named BCSBM, is proposed in this paper. Different from other generative models for attributed networks, the generation process of links and attributes in BCSBM model follows the Poisson distribution, and the probability between community is considered based on 
&lt;/p&gt;</description></item><item><title>&#22810;&#22686;&#24378;&#32553;&#20943;&#31209;&#22238;&#24402;&#65288;maRRR&#65289;&#26159;&#19968;&#31181;&#28789;&#27963;&#30340;&#30697;&#38453;&#22238;&#24402;&#21644;&#20998;&#35299;&#26041;&#27861;&#65292;&#29992;&#20110;&#21516;&#26102;&#23398;&#20064;&#21327;&#21464;&#39537;&#21160;&#21644;&#36741;&#21161;&#32467;&#26500;&#21270;&#21464;&#24322;&#12290;&#36890;&#36807;&#32452;&#21512;&#22810;&#20010;&#25968;&#25454;&#38598;&#65292;maRRR&#22312;&#20840;&#30284;&#30151;&#20998;&#26512;&#20013;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#21151;&#29575;&#22686;&#30410;&#12290;</title><link>http://arxiv.org/abs/2308.16333</link><description>&lt;p&gt;
&#22810;&#22686;&#24378;&#32553;&#20943;&#31209;&#22238;&#24402;&#29992;&#20110;&#20840;&#30284;&#30151;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Multiple Augmented Reduced Rank Regression for Pan-Cancer Analysis. (arXiv:2308.16333v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16333
&lt;/p&gt;
&lt;p&gt;
&#22810;&#22686;&#24378;&#32553;&#20943;&#31209;&#22238;&#24402;&#65288;maRRR&#65289;&#26159;&#19968;&#31181;&#28789;&#27963;&#30340;&#30697;&#38453;&#22238;&#24402;&#21644;&#20998;&#35299;&#26041;&#27861;&#65292;&#29992;&#20110;&#21516;&#26102;&#23398;&#20064;&#21327;&#21464;&#39537;&#21160;&#21644;&#36741;&#21161;&#32467;&#26500;&#21270;&#21464;&#24322;&#12290;&#36890;&#36807;&#32452;&#21512;&#22810;&#20010;&#25968;&#25454;&#38598;&#65292;maRRR&#22312;&#20840;&#30284;&#30151;&#20998;&#26512;&#20013;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#21151;&#29575;&#22686;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25104;&#21151;&#32467;&#21512;&#22810;&#20010;&#25968;&#25454;&#38598;&#30340;&#32479;&#35745;&#26041;&#27861;&#27604;&#21333;&#29420;&#20998;&#26512;&#26356;&#24378;&#22823;&#12289;&#39640;&#25928;&#21644;&#31185;&#23398;&#20449;&#24687;&#20016;&#23500;&#12290;&#20026;&#20102;&#27491;&#30830;&#21644;&#20840;&#38754;&#22320;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#22312;&#22810;&#20010;&#26679;&#26412;&#38598;&#65288;&#21363;&#38431;&#21015;&#65289;&#20013;&#30340;&#21464;&#21270;&#32467;&#26500;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22810;&#22686;&#24378;&#32553;&#20943;&#31209;&#22238;&#24402;&#65288;maRRR&#65289;&#65292;&#19968;&#31181;&#28789;&#27963;&#30340;&#30697;&#38453;&#22238;&#24402;&#21644;&#20998;&#35299;&#26041;&#27861;&#65292;&#21516;&#26102;&#23398;&#20064;&#21327;&#21464;&#39537;&#21160;&#21644;&#36741;&#21161;&#32467;&#26500;&#21270;&#21464;&#24322;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#21463;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#21551;&#21457;&#30340;&#32467;&#26500;&#26680;&#33539;&#25968;&#30446;&#26631;&#65292;&#20854;&#20013;&#22238;&#24402;&#25110;&#20998;&#35299;&#39033;&#21487;&#20197;&#26159;&#20849;&#20139;&#30340;&#65292;&#20063;&#21487;&#20197;&#29305;&#23450;&#20110;&#20219;&#24847;&#25968;&#37327;&#30340;&#38431;&#21015;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21253;&#21547;&#20102;&#20943;&#23569;&#31209;&#22238;&#24402;&#21644;&#26080;&#30417;&#30563;&#22810;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#31561;&#22810;&#31181;&#29616;&#26377;&#26041;&#27861;&#65292;&#24182;&#23558;&#21333;&#20010;&#25968;&#25454;&#38598;&#65288;aRRR&#65289;&#30340;&#22238;&#24402;&#21644;&#20998;&#35299;&#20316;&#20026;&#29305;&#20363;&#36827;&#34892;&#20102;&#26377;&#24076;&#26395;&#30340;&#21019;&#26032;&#24615;&#25506;&#32034;&#12290;&#27169;&#25311;&#23454;&#39564;&#34920;&#26126;&#65292;&#36890;&#36807;&#32452;&#21512;&#22810;&#20010;&#25968;&#25454;&#38598;&#21487;&#20197;&#33719;&#24471;&#26174;&#33879;&#30340;&#21151;&#29575;&#22686;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
Statistical approaches that successfully combine multiple datasets are more powerful, efficient, and scientifically informative than separate analyses. To address variation architectures correctly and comprehensively for high-dimensional data across multiple sample sets (i.e., cohorts), we propose multiple augmented reduced rank regression (maRRR), a flexible matrix regression and factorization method to concurrently learn both covariate-driven and auxiliary structured variation. We consider a structured nuclear norm objective that is motivated by random matrix theory, in which the regression or factorization terms may be shared or specific to any number of cohorts. Our framework subsumes several existing methods, such as reduced rank regression and unsupervised multi-matrix factorization approaches, and includes a promising novel approach to regression and factorization of a single dataset (aRRR) as a special case. Simulations demonstrate substantial gains in power from combining mult
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#22238;&#24402;&#38382;&#39064;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#35299;&#37322;&#26041;&#27861;&#30340;&#25193;&#23637;&#65292;&#21487;&#20197;&#37327;&#21270;&#29305;&#24449;&#37325;&#35201;&#24615;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.16245</link><description>&lt;p&gt;
&#22238;&#24402;&#38382;&#39064;&#30340;&#26657;&#20934;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Calibrated Explanations for Regression. (arXiv:2308.16245v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16245
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#22238;&#24402;&#38382;&#39064;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#35299;&#37322;&#26041;&#27861;&#30340;&#25193;&#23637;&#65292;&#21487;&#20197;&#37327;&#21270;&#29305;&#24449;&#37325;&#35201;&#24615;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#36890;&#24120;&#26159;&#29616;&#20195;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#65288;DSS&#65289;&#30340;&#19968;&#37096;&#20998;&#12290;&#22312;&#22522;&#20110;AI&#30340;DSS&#20013;&#20351;&#29992;&#30340;&#26368;&#20339;&#39044;&#27979;&#27169;&#22411;&#32570;&#20047;&#36879;&#26126;&#24230;&#12290;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#26088;&#22312;&#21019;&#24314;&#33021;&#22815;&#21521;&#20154;&#31867;&#29992;&#25143;&#35299;&#37322;&#20854;&#29702;&#30001;&#30340;AI&#31995;&#32479;&#12290;XAI&#20013;&#30340;&#23616;&#37096;&#35299;&#37322;&#21487;&#20197;&#25552;&#20379;&#20851;&#20110;&#20010;&#21035;&#39044;&#27979;&#30340;&#21407;&#22240;&#30340;&#20449;&#24687;&#65292;&#21363;&#29305;&#24449;&#37325;&#35201;&#24615;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#23616;&#37096;&#35299;&#37322;&#26041;&#27861;&#30340;&#19968;&#20010;&#20851;&#38190;&#32570;&#28857;&#26159;&#26080;&#27861;&#37327;&#21270;&#19982;&#29305;&#24449;&#37325;&#35201;&#24615;&#30456;&#20851;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#29305;&#24449;&#37325;&#35201;&#24615;&#35299;&#37322;&#26041;&#27861;Calibrated Explanations&#65288;CE&#65289;&#30340;&#25193;&#23637;&#65292;&#20043;&#21069;&#21482;&#25903;&#25345;&#20998;&#31867;&#65292;&#29616;&#22312;&#25903;&#25345;&#26631;&#20934;&#22238;&#24402;&#21644;&#27010;&#29575;&#22238;&#24402;&#65292;&#21363;&#30446;&#26631;&#36229;&#36807;&#20219;&#24847;&#38408;&#20540;&#30340;&#27010;&#29575;&#12290;&#22238;&#24402;&#38382;&#39064;&#30340;&#25193;&#23637;&#20445;&#30041;&#20102;CE&#30340;&#25152;&#26377;&#20248;&#28857;&#65292;&#20363;&#22914;&#23558;&#24213;&#23618;&#27169;&#22411;&#30340;&#39044;&#27979;&#19982;&#32622;&#20449;&#24230;&#26657;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
Artificial Intelligence (AI) is often an integral part of modern decision support systems (DSSs). The best-performing predictive models used in AI-based DSSs lack transparency. Explainable Artificial Intelligence (XAI) aims to create AI systems that can explain their rationale to human users. Local explanations in XAI can provide information about the causes of individual predictions in terms of feature importance. However, a critical drawback of existing local explanation methods is their inability to quantify the uncertainty associated with a feature's importance. This paper introduces an extension of a feature importance explanation method, Calibrated Explanations (CE), previously only supporting classification, with support for standard regression and probabilistic regression, i.e., the probability that the target is above an arbitrary threshold. The extension for regression keeps all the benefits of CE, such as calibration of the prediction from the underlying model with confidenc
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#27010;&#36848;&#20102;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#22238;&#24402;&#27169;&#22411;&#30340;&#26041;&#27861;&#21644;&#26368;&#26032;&#21457;&#23637;&#65292;&#21253;&#25324;&#30456;&#20851;&#25968;&#25454;&#30340;&#26497;&#38480;&#29702;&#35770;&#32467;&#26524;&#12289;&#19982;&#35768;&#22810;&#21327;&#21464;&#37327;&#30340;&#26102;&#38388;&#24207;&#21015;&#22238;&#24402;&#27169;&#22411;&#30456;&#20851;&#30340;&#28176;&#36817;&#29702;&#35770;&#21644;&#32479;&#35745;&#23398;&#20064;&#26041;&#27861;&#30340;&#22810;&#31181;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2308.16192</link><description>&lt;p&gt;
&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#22238;&#24402;&#27169;&#22411;&#65306;&#24212;&#29992;&#20110;&#32479;&#35745;&#23398;&#20064;&#26041;&#27861;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
High Dimensional Time Series Regression Models: Applications to Statistical Learning Methods. (arXiv:2308.16192v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16192
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#27010;&#36848;&#20102;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#22238;&#24402;&#27169;&#22411;&#30340;&#26041;&#27861;&#21644;&#26368;&#26032;&#21457;&#23637;&#65292;&#21253;&#25324;&#30456;&#20851;&#25968;&#25454;&#30340;&#26497;&#38480;&#29702;&#35770;&#32467;&#26524;&#12289;&#19982;&#35768;&#22810;&#21327;&#21464;&#37327;&#30340;&#26102;&#38388;&#24207;&#21015;&#22238;&#24402;&#27169;&#22411;&#30456;&#20851;&#30340;&#28176;&#36817;&#29702;&#35770;&#21644;&#32479;&#35745;&#23398;&#20064;&#26041;&#27861;&#30340;&#22810;&#31181;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#20123;&#35762;&#31295;&#27010;&#36848;&#20102;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#22238;&#24402;&#27169;&#22411;&#30340;&#29616;&#26377;&#26041;&#27861;&#21644;&#26368;&#26032;&#21457;&#23637;&#65292;&#21253;&#25324;&#39640;&#32500;&#30456;&#20851;&#25968;&#25454;&#30340;&#20027;&#35201;&#26497;&#38480;&#29702;&#35770;&#32467;&#26524;&#12289;&#19982;&#35768;&#22810;&#21327;&#21464;&#37327;&#30340;&#26102;&#38388;&#24207;&#21015;&#22238;&#24402;&#27169;&#22411;&#30456;&#20851;&#30340;&#28176;&#36817;&#29702;&#35770;&#20027;&#35201;&#26041;&#38754;&#20197;&#21450;&#32479;&#35745;&#23398;&#20064;&#26041;&#27861;&#22312;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#20013;&#30340;&#21508;&#31181;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
These lecture notes provide an overview of existing methodologies and recent developments for estimation and inference with high dimensional time series regression models. First, we present main limit theory results for high dimensional dependent data which is relevant to covariance matrix structures as well as to dependent time series sequences. Second, we present main aspects of the asymptotic theory related to time series regression models with many covariates. Third, we discuss various applications of statistical learning methodologies for time series analysis purposes.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#36235;&#21183;&#28388;&#27874;&#26041;&#27861;&#23545;&#20855;&#26377;&#26102;&#31354;&#20381;&#36182;&#24615;&#30340;&#25968;&#25454;&#36827;&#34892;&#20102;&#38750;&#21442;&#25968;&#22238;&#24402;&#20989;&#25968;&#30340;&#20272;&#35745;&#65292;&#30740;&#31350;&#20102;&#35813;&#26041;&#27861;&#22312;&#21333;&#21464;&#37327;&#21644;&#22810;&#21464;&#37327;&#24773;&#20917;&#19979;&#30340;&#24212;&#29992;&#65292;&#24182;&#39564;&#35777;&#20102;&#20854;&#26497;&#23567;&#21270;&#24615;&#12290;&#30740;&#31350;&#21457;&#29616;&#20102;&#20197;&#24448;&#26410;&#26366;&#25506;&#32034;&#30340;&#29420;&#29305;&#30456;&#21464;&#29616;&#35937;&#65292;&#24182;&#36890;&#36807;&#20223;&#30495;&#21644;&#23454;&#38469;&#25968;&#25454;&#24212;&#29992;&#39564;&#35777;&#20102;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.16172</link><description>&lt;p&gt;
&#36890;&#36807;&#36235;&#21183;&#28388;&#27874;&#36827;&#34892;&#26102;&#31354;&#27169;&#22411;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Temporal-spatial model via Trend Filtering. (arXiv:2308.16172v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16172
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#36235;&#21183;&#28388;&#27874;&#26041;&#27861;&#23545;&#20855;&#26377;&#26102;&#31354;&#20381;&#36182;&#24615;&#30340;&#25968;&#25454;&#36827;&#34892;&#20102;&#38750;&#21442;&#25968;&#22238;&#24402;&#20989;&#25968;&#30340;&#20272;&#35745;&#65292;&#30740;&#31350;&#20102;&#35813;&#26041;&#27861;&#22312;&#21333;&#21464;&#37327;&#21644;&#22810;&#21464;&#37327;&#24773;&#20917;&#19979;&#30340;&#24212;&#29992;&#65292;&#24182;&#39564;&#35777;&#20102;&#20854;&#26497;&#23567;&#21270;&#24615;&#12290;&#30740;&#31350;&#21457;&#29616;&#20102;&#20197;&#24448;&#26410;&#26366;&#25506;&#32034;&#30340;&#29420;&#29305;&#30456;&#21464;&#29616;&#35937;&#65292;&#24182;&#36890;&#36807;&#20223;&#30495;&#21644;&#23454;&#38469;&#25968;&#25454;&#24212;&#29992;&#39564;&#35777;&#20102;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20391;&#37325;&#20110;&#23545;&#20855;&#26377;&#21516;&#26102;&#26102;&#38388;&#21644;&#31354;&#38388;&#20381;&#36182;&#24615;&#30340;&#25968;&#25454;&#36827;&#34892;&#38750;&#21442;&#25968;&#22238;&#24402;&#20989;&#25968;&#30340;&#20272;&#35745;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#36235;&#21183;&#28388;&#27874;&#65292;&#36825;&#26159;&#19968;&#31181;&#38750;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#30001;Mammen&#21644;Rudin&#25552;&#20986;&#12290;&#22312;&#21333;&#21464;&#37327;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#30340;&#20449;&#21495;&#20551;&#35774;&#20855;&#26377;&#26377;&#30028;&#24635;&#21464;&#24322;&#24230;&#30340;k&#27425;&#24369;&#23548;&#25968;&#65292;&#20801;&#35768;&#19968;&#23450;&#31243;&#24230;&#30340;&#24179;&#28369;&#24615;&#12290;&#22312;&#22810;&#21464;&#37327;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;Padilla&#31561;&#20154;&#30340;K&#26368;&#36817;&#37051;&#34701;&#21512;&#22871;&#32034;&#20272;&#35745;&#22120;&#65292;&#37319;&#29992;&#36866;&#29992;&#20110;&#20855;&#26377;&#26377;&#30028;&#21464;&#24322;&#24230;&#19988;&#31526;&#21512;&#20998;&#27573;&#21033;&#26222;&#24076;&#33576;&#36830;&#32493;&#24615;&#20934;&#21017;&#30340;&#20449;&#21495;&#30340;ADMM&#31639;&#27861;&#12290;&#36890;&#36807;&#19982;&#19979;&#30028;&#23545;&#40784;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25105;&#20204;&#20272;&#35745;&#22120;&#30340;&#26497;&#23567;&#21270;&#24615;&#12290;&#36890;&#36807;&#20998;&#26512;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#20197;&#24448;&#36235;&#21183;&#28388;&#27874;&#30740;&#31350;&#20013;&#26410;&#26366;&#25506;&#32034;&#36807;&#30340;&#29420;&#29305;&#30456;&#21464;&#29616;&#35937;&#12290;&#20223;&#30495;&#30740;&#31350;&#21644;&#23454;&#38469;&#25968;&#25454;&#24212;&#29992;&#37117;&#31361;&#20986;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#20986;&#33394;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This research focuses on the estimation of a non-parametric regression function designed for data with simultaneous time and space dependencies. In such a context, we study the Trend Filtering, a nonparametric estimator introduced by \cite{mammen1997locally} and \cite{rudin1992nonlinear}. For univariate settings, the signals we consider are assumed to have a kth weak derivative with bounded total variation, allowing for a general degree of smoothness. In the multivariate scenario, we study a $K$-Nearest Neighbor fused lasso estimator as in \cite{padilla2018adaptive}, employing an ADMM algorithm, suitable for signals with bounded variation that adhere to a piecewise Lipschitz continuity criterion. By aligning with lower bounds, the minimax optimality of our estimators is validated. A unique phase transition phenomenon, previously uncharted in Trend Filtering studies, emerges through our analysis. Both Simulation studies and real data applications underscore the superior performance of o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22810;&#21709;&#24212;&#24322;&#26041;&#24046;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#23558;&#20854;&#24212;&#29992;&#20110;&#22238;&#24402;&#12289;&#20998;&#31867;&#21644;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#21464;&#20998;&#25512;&#26029;&#26469;&#36817;&#20284;&#21518;&#39564;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#22312;&#25429;&#25417;&#20989;&#25968;&#24179;&#28369;&#24615;&#30340;&#31361;&#21464;&#21644;&#36866;&#24212;&#24322;&#26041;&#24046;&#38169;&#35823;&#26041;&#38754;&#30340;&#23616;&#38480;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.15370</link><description>&lt;p&gt;
&#22810;&#21709;&#24212;&#24322;&#26041;&#24046;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#21450;&#20854;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Multi-Response Heteroscedastic Gaussian Process Models and Their Inference. (arXiv:2308.15370v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15370
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22810;&#21709;&#24212;&#24322;&#26041;&#24046;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#23558;&#20854;&#24212;&#29992;&#20110;&#22238;&#24402;&#12289;&#20998;&#31867;&#21644;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#21464;&#20998;&#25512;&#26029;&#26469;&#36817;&#20284;&#21518;&#39564;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#22312;&#25429;&#25417;&#20989;&#25968;&#24179;&#28369;&#24615;&#30340;&#31361;&#21464;&#21644;&#36866;&#24212;&#24322;&#26041;&#24046;&#38169;&#35823;&#26041;&#38754;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#34987;&#24191;&#27867;&#29992;&#20110;&#28789;&#27963;&#30340;&#38750;&#21442;&#25968;&#24314;&#27169;&#65292;&#20294;&#23427;&#20204;&#22312;&#26377;&#25928;&#25429;&#25417;&#20989;&#25968;&#24179;&#28369;&#24615;&#30340;&#31361;&#21464;&#21644;&#36866;&#24212;&#24322;&#26041;&#24046;&#38169;&#35823;&#26041;&#38754;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#24322;&#26041;&#24046;&#39640;&#26031;&#36807;&#31243;&#65288;HeGP&#65289;&#22238;&#24402;&#26088;&#22312;&#36890;&#36807;&#25215;&#35748;&#22238;&#24402;&#27169;&#22411;&#20013;&#21327;&#21464;&#37327;&#38388;&#27531;&#24046;&#26041;&#24046;&#30340;&#21487;&#21464;&#24615;&#26469;&#24341;&#20837;&#28789;&#27963;&#24615;&#12290;&#26412;&#25991;&#23558;HeGP&#27010;&#24565;&#25193;&#23637;&#21040;&#20998;&#31867;&#21644;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#23558;&#39640;&#26031;&#36807;&#31243;&#19982;&#21327;&#21464;&#37327;&#35825;&#23548;&#30340;&#31934;&#24230;&#30697;&#38453;&#36807;&#31243;&#30456;&#32467;&#21512;&#65292;&#37319;&#29992;&#28151;&#21512;&#24418;&#24335;&#12290;&#36825;&#31181;&#26041;&#27861;&#20351;&#24471;&#21487;&#20197;&#23545;&#21327;&#21464;&#37327;&#20043;&#38388;&#30340;&#24322;&#26041;&#24046;&#21327;&#26041;&#24046;&#20989;&#25968;&#36827;&#34892;&#24314;&#27169;&#12290;&#20026;&#20102;&#35299;&#20915;&#37319;&#26679;&#24102;&#26469;&#30340;&#35745;&#31639;&#25361;&#25112;&#65292;&#25105;&#20204;&#37319;&#29992;&#21464;&#20998;&#25512;&#26029;&#26469;&#36817;&#20284;&#21518;&#39564;&#24182;&#20415;&#21033;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the widespread utilization of Gaussian process models for versatile nonparametric modeling, they exhibit limitations in effectively capturing abrupt changes in function smoothness and accommodating relationships with heteroscedastic errors. Addressing these shortcomings, the heteroscedastic Gaussian process (HeGP) regression seeks to introduce flexibility by acknowledging the variability of residual variances across covariates in the regression model. In this work, we extend the HeGP concept, expanding its scope beyond regression tasks to encompass classification and state-space models. To achieve this, we propose a novel framework where the Gaussian process is coupled with a covariate-induced precision matrix process, adopting a mixture formulation. This approach enables the modeling of heteroscedastic covariance functions across covariates. To mitigate the computational challenges posed by sampling, we employ variational inference to approximate the posterior and facilitate p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31232;&#30095;&#24809;&#32602;&#30340;&#21452;&#32858;&#31867;&#26041;&#27861;&#65292;&#20027;&#35201;&#20851;&#27880;&#20102;SSVD&#26041;&#27861;&#65292;&#24182;&#23581;&#35797;&#20102;&#19968;&#31181;&#26032;&#30340;&#31232;&#30095;&#24809;&#32602;&#26041;&#27861;&#12290;&#27169;&#25311;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#28151;&#21512;&#30340;Prenet&#24809;&#32602;&#23545;&#20110;&#38750;&#37325;&#21472;&#25968;&#25454;&#38750;&#24120;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2308.14388</link><description>&lt;p&gt;
&#36890;&#36807;&#31232;&#30095;&#24809;&#32602;&#36827;&#34892;&#30340;&#21452;&#32858;&#31867;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Biclustering Methods via Sparse Penalty. (arXiv:2308.14388v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14388
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31232;&#30095;&#24809;&#32602;&#30340;&#21452;&#32858;&#31867;&#26041;&#27861;&#65292;&#20027;&#35201;&#20851;&#27880;&#20102;SSVD&#26041;&#27861;&#65292;&#24182;&#23581;&#35797;&#20102;&#19968;&#31181;&#26032;&#30340;&#31232;&#30095;&#24809;&#32602;&#26041;&#27861;&#12290;&#27169;&#25311;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#28151;&#21512;&#30340;Prenet&#24809;&#32602;&#23545;&#20110;&#38750;&#37325;&#21472;&#25968;&#25454;&#38750;&#24120;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#20808;&#22238;&#39038;&#20102;&#20960;&#31181;&#29992;&#20110;&#35782;&#21035;&#22522;&#22240;&#34920;&#36798;&#25968;&#25454;&#20013;&#26368;&#26174;&#33879;&#32858;&#31867;&#30340;&#21452;&#32858;&#31867;&#26041;&#27861;&#12290;&#25105;&#20204;&#20027;&#35201;&#20851;&#27880;&#20102;SSVD&#65288;&#31232;&#30095;SVD&#65289;&#26041;&#27861;&#65292;&#24182;&#23581;&#35797;&#20102;&#19968;&#31181;&#20165;&#29992;&#20110;&#22240;&#23376;&#20998;&#26512;&#30340;&#26032;&#30340;&#31232;&#30095;&#24809;&#32602;&#26041;&#27861;&#65292;&#31216;&#20026;"Prenet&#24809;&#32602;"&#12290;&#28982;&#21518;&#22312;&#27169;&#25311;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23581;&#35797;&#20102;&#19981;&#21516;&#31867;&#22411;&#30340;&#29983;&#25104;&#25968;&#25454;&#38598;&#65288;&#20855;&#26377;&#19981;&#21516;&#30340;&#31232;&#30095;&#24615;&#21644;&#32500;&#24230;&#65289;&#65292;&#24182;&#23581;&#35797;&#20102;&#19968;&#23618;&#36924;&#36817;&#21644;k&#23618;&#36924;&#36817;&#65292;&#32467;&#26524;&#34920;&#26126;&#28151;&#21512;&#30340;Prenet&#24809;&#32602;&#23545;&#20110;&#38750;&#37325;&#21472;&#25968;&#25454;&#38750;&#24120;&#26377;&#25928;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#20123;&#30495;&#23454;&#30340;&#22522;&#22240;&#34920;&#36798;&#25968;&#25454;&#26469;&#23637;&#31034;&#25105;&#20204;&#26041;&#27861;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we first reviewed several biclustering methods that are used to identify the most significant clusters in gene expression data. Here we mainly focused on the SSVD(sparse SVD) method and tried a new sparse penalty named "Prenet penalty" which has been used only in factor analysis to gain sparsity. Then in the simulation study, we tried different types of generated datasets (with different sparsity and dimension) and tried 1-layer approximation then for k-layers which shows the mixed Prenet penalty is very effective for non-overlapped data. Finally, we used some real gene expression data to show the behavior of our methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20809;&#28369;&#24615;&#20808;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#33410;&#28857;&#29305;&#24449;&#20013;&#25512;&#26029;&#36229;&#22270;&#30340;&#32467;&#26500;&#65292;&#24182;&#25429;&#25417;&#25968;&#25454;&#20869;&#22312;&#30340;&#20851;&#31995;&#12290;&#35813;&#26041;&#27861;&#19981;&#38656;&#35201;&#26631;&#35760;&#25968;&#25454;&#20316;&#20026;&#30417;&#30563;&#65292;&#33021;&#22815;&#25512;&#26029;&#20986;&#27599;&#20010;&#28508;&#22312;&#36229;&#36793;&#30340;&#27010;&#29575;&#12290;</title><link>http://arxiv.org/abs/2308.14172</link><description>&lt;p&gt;
&#20174;&#25968;&#25454;&#20013;&#22522;&#20110;&#20809;&#28369;&#24615;&#20808;&#39564;&#25512;&#26029;&#36229;&#22270;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
Hypergraph Structure Inference From Data Under Smoothness Prior. (arXiv:2308.14172v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14172
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20809;&#28369;&#24615;&#20808;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#33410;&#28857;&#29305;&#24449;&#20013;&#25512;&#26029;&#36229;&#22270;&#30340;&#32467;&#26500;&#65292;&#24182;&#25429;&#25417;&#25968;&#25454;&#20869;&#22312;&#30340;&#20851;&#31995;&#12290;&#35813;&#26041;&#27861;&#19981;&#38656;&#35201;&#26631;&#35760;&#25968;&#25454;&#20316;&#20026;&#30417;&#30563;&#65292;&#33021;&#22815;&#25512;&#26029;&#20986;&#27599;&#20010;&#28508;&#22312;&#36229;&#36793;&#30340;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36229;&#22270;&#22312;&#22788;&#29702;&#28041;&#21450;&#22810;&#20010;&#23454;&#20307;&#30340;&#39640;&#38454;&#20851;&#31995;&#25968;&#25454;&#20013;&#38750;&#24120;&#37325;&#35201;&#12290;&#22312;&#27809;&#26377;&#26126;&#30830;&#36229;&#22270;&#21487;&#29992;&#30340;&#24773;&#20917;&#19979;&#65292;&#24076;&#26395;&#33021;&#22815;&#20174;&#33410;&#28857;&#29305;&#24449;&#20013;&#25512;&#26029;&#20986;&#26377;&#24847;&#20041;&#30340;&#36229;&#22270;&#32467;&#26500;&#65292;&#20197;&#25429;&#25417;&#25968;&#25454;&#20869;&#22312;&#30340;&#20851;&#31995;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#26041;&#27861;&#35201;&#20040;&#37319;&#29992;&#31616;&#21333;&#39044;&#23450;&#20041;&#30340;&#35268;&#21017;&#65292;&#19981;&#33021;&#31934;&#30830;&#25429;&#25417;&#28508;&#22312;&#36229;&#22270;&#32467;&#26500;&#30340;&#20998;&#24067;&#65292;&#35201;&#20040;&#23398;&#20064;&#36229;&#22270;&#32467;&#26500;&#21644;&#33410;&#28857;&#29305;&#24449;&#20043;&#38388;&#30340;&#26144;&#23556;&#65292;&#20294;&#38656;&#35201;&#22823;&#37327;&#26631;&#35760;&#25968;&#25454;&#65288;&#21363;&#39044;&#20808;&#23384;&#22312;&#30340;&#36229;&#22270;&#32467;&#26500;&#65289;&#36827;&#34892;&#35757;&#32451;&#12290;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#23616;&#38480;&#20110;&#23454;&#38469;&#24773;&#26223;&#20013;&#30340;&#24212;&#29992;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20809;&#28369;&#24615;&#20808;&#39564;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#35774;&#35745;&#19968;&#31181;&#26041;&#27861;&#65292;&#22312;&#27809;&#26377;&#26631;&#35760;&#25968;&#25454;&#20316;&#20026;&#30417;&#30563;&#30340;&#24773;&#20917;&#19979;&#25512;&#26029;&#20986;&#27599;&#20010;&#28508;&#22312;&#36229;&#36793;&#30340;&#27010;&#29575;&#12290;&#25152;&#25552;&#20986;&#30340;&#20808;&#39564;&#34920;&#31034;&#36229;&#36793;&#20013;&#30340;&#33410;&#28857;&#29305;&#24449;&#19982;&#21253;&#21547;&#35813;&#36229;&#36793;&#30340;&#36229;&#36793;&#30340;&#29305;&#24449;&#39640;&#24230;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hypergraphs are important for processing data with higher-order relationships involving more than two entities. In scenarios where explicit hypergraphs are not readily available, it is desirable to infer a meaningful hypergraph structure from the node features to capture the intrinsic relations within the data. However, existing methods either adopt simple pre-defined rules that fail to precisely capture the distribution of the potential hypergraph structure, or learn a mapping between hypergraph structures and node features but require a large amount of labelled data, i.e., pre-existing hypergraph structures, for training. Both restrict their applications in practical scenarios. To fill this gap, we propose a novel smoothness prior that enables us to design a method to infer the probability for each potential hyperedge without labelled data as supervision. The proposed prior indicates features of nodes in a hyperedge are highly correlated by the features of the hyperedge containing th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;Riesz&#26680;&#23637;&#31034;&#20102;&#29983;&#25104;&#24335;&#20998;&#21106;MMD&#27969;&#30340;&#39640;&#25928;&#35745;&#31639;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#22823;&#35268;&#27169;&#24212;&#29992;&#20013;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2305.11463</link><description>&lt;p&gt;
&#21033;&#29992;Riesz&#26680;&#30340;&#29983;&#25104;&#24335;&#20998;&#21106;MMD&#27969;
&lt;/p&gt;
&lt;p&gt;
Generative Sliced MMD Flows with Riesz Kernels. (arXiv:2305.11463v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11463
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;Riesz&#26680;&#23637;&#31034;&#20102;&#29983;&#25104;&#24335;&#20998;&#21106;MMD&#27969;&#30340;&#39640;&#25928;&#35745;&#31639;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#22823;&#35268;&#27169;&#24212;&#29992;&#20013;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#35268;&#27169;&#35745;&#31639;&#20013;&#65292;&#26368;&#22823;&#24179;&#22343;&#24046;&#24322;&#24230;(MMD)&#27969;&#30340;&#35745;&#31639;&#25104;&#26412;&#24456;&#39640;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;Riesz&#26680;$K(x,y)=-\|x-y\|^r$&#65292;$r \in (0,2)$&#30340;MMD&#27969;&#20855;&#26377;&#26480;&#20986;&#30340;&#24615;&#36136;&#65292;&#21487;&#20801;&#35768;&#20854;&#36827;&#34892;&#39640;&#25928;&#35745;&#31639;&#12290;&#39318;&#20808;&#65292;Riesz&#26680;&#30340;MMD&#19982;&#20854;&#20998;&#21106;&#29256;&#26412;&#30340;MMD&#37325;&#21512;&#12290;&#22240;&#27492;&#65292;&#21487;&#20197;&#22312;&#19968;&#32500;&#35774;&#32622;&#20013;&#36827;&#34892;MMD&#26799;&#24230;&#30340;&#35745;&#31639;&#12290;&#22312;&#27492;&#22788;&#65292;&#23545;&#20110;$r=1$&#65292;&#21487;&#20197;&#24212;&#29992;&#31616;&#21333;&#30340;&#25490;&#24207;&#31639;&#27861;&#23558;&#20004;&#20010;&#32463;&#39564;&#24230;&#37327;&#30340;&#22797;&#26434;&#24230;&#20174;$O(MN+N^2)$&#38477;&#20302;&#21040;$O((M+N)\log(M+N))$&#65292;&#20854;&#20013;$M$&#21644;$N$&#26159;&#25903;&#25345;&#28857;&#12290;&#23545;&#20110;&#23454;&#29616;&#65292;&#25105;&#20204;&#36890;&#36807;&#20165;&#20351;&#29992;&#26377;&#38480;&#25968;&#37327;&#30340;$P$&#20010;&#20999;&#29255;&#26469;&#36817;&#20284;&#20998;&#21106;MMD&#30340;&#26799;&#24230;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#30001;&#27492;&#20135;&#29983;&#30340;&#35823;&#24046;&#20855;&#26377;$O(\sqrt{d/P})$&#30340;&#22797;&#26434;&#24230;&#65292;&#20854;&#20013;$d$&#26159;&#25968;&#25454;&#32500;&#24230;&#12290;&#36825;&#20123;&#32467;&#26524;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;MMD&#26799;&#24230;&#27969;&#26469;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#65292;&#29978;&#33267;&#29992;&#20110;&#22823;&#35268;&#27169;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Maximum mean discrepancy (MMD) flows suffer from high computational costs in large scale computations. In this paper, we show that MMD flows with Riesz kernels $K(x,y) = - \|x-y\|^r$, $r \in (0,2)$ have exceptional properties which allow for their efficient computation. First, the MMD of Riesz kernels coincides with the MMD of their sliced version. As a consequence, the computation of gradients of MMDs can be performed in the one-dimensional setting. Here, for $r=1$, a simple sorting algorithm can be applied to reduce the complexity from $O(MN+N^2)$ to $O((M+N)\log(M+N))$ for two empirical measures with $M$ and $N$ support points. For the implementations we approximate the gradient of the sliced MMD by using only a finite number $P$ of slices. We show that the resulting error has complexity $O(\sqrt{d/P})$, where $d$ is the data dimension. These results enable us to train generative models by approximating MMD gradient flows by neural networks even for large scale applications. We demo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#31070;&#32463;&#32593;&#32476;&#27714;&#35299;&#21021;&#20540;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#31283;&#23450;&#21487;&#25193;&#23637;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#22312;&#20840;&#23616;&#26368;&#23567;&#21270;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#20013;&#30340; PDE &#27531;&#24046;&#20013;&#36935;&#21040;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#21644; ODE &#26041;&#27861;&#20013;&#38543;&#30528;&#25968;&#37327;&#21576;&#31435;&#26041;&#32423;&#21035;&#25193;&#23637;&#31561;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2304.14994</link><description>&lt;p&gt;
&#29992;&#31070;&#32463;&#32593;&#32476;&#27714;&#35299;&#21021;&#20540;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#31283;&#23450;&#21487;&#25193;&#23637;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Stable and Scalable Method for Solving Initial Value PDEs with Neural Networks. (arXiv:2304.14994v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14994
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#31070;&#32463;&#32593;&#32476;&#27714;&#35299;&#21021;&#20540;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#31283;&#23450;&#21487;&#25193;&#23637;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#22312;&#20840;&#23616;&#26368;&#23567;&#21270;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#20013;&#30340; PDE &#27531;&#24046;&#20013;&#36935;&#21040;&#30340;&#28798;&#38590;&#24615;&#36951;&#24536;&#21644; ODE &#26041;&#27861;&#20013;&#38543;&#30528;&#25968;&#37327;&#21576;&#31435;&#26041;&#32423;&#21035;&#25193;&#23637;&#31561;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19982;&#20256;&#32479;&#30340;&#32593;&#26684;&#21644;&#22522;&#20110;&#32593;&#26684;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#31070;&#32463;&#32593;&#32476;&#26377;&#21487;&#33021;&#25171;&#30772;&#32500;&#25968;&#28798;&#38590;&#65292;&#22312;&#20351;&#29992;&#32463;&#20856;&#27714;&#35299;&#22120;&#22256;&#38590;&#25110;&#19981;&#21487;&#33021;&#30340;&#38382;&#39064;&#20013;&#25552;&#20379;&#36817;&#20284;&#35299;&#12290;&#20840;&#23616;&#26368;&#23567;&#21270;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#20013;&#30340; PDE &#27531;&#24046;&#23545;&#20110;&#36793;&#30028;&#20540;&#38382;&#39064;&#25928;&#26524;&#33391;&#22909;&#65292;&#20294;&#26159;&#28798;&#38590;&#24615;&#24536;&#21364;&#25439;&#23475;&#20102;&#36825;&#31181;&#26041;&#27861;&#23545;&#20110;&#21021;&#20540;&#38382;&#39064;&#30340;&#36866;&#29992;&#24615;&#12290;&#22312;&#26367;&#20195;&#30340;&#23616;&#37096;&#26102;&#38388;&#26041;&#27861;&#20013;&#65292;&#21487;&#20197;&#23558;&#20248;&#21270;&#38382;&#39064;&#36716;&#21270;&#20026;&#32593;&#32476;&#21442;&#25968;&#19978;&#30340;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#65292;&#24182;&#23558;&#35299;&#21521;&#21069;&#20256;&#25773;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#30446;&#21069;&#22522;&#20110;&#36825;&#31181;&#26041;&#27861;&#30340;&#26041;&#27861;&#23384;&#22312;&#20004;&#20010;&#20851;&#38190;&#38382;&#39064;&#12290;&#39318;&#20808;&#65292;&#36981;&#24490; ODE &#20250;&#23548;&#33268;&#38382;&#39064;&#26465;&#20214;&#22686;&#38271;&#26080;&#27861;&#25511;&#21046;&#65292;&#26368;&#32456;&#23548;&#33268;&#19981;&#21487;&#25509;&#21463;&#30340;&#22823;&#25968;&#20540;&#35823;&#24046;&#12290;&#20854;&#27425;&#65292;&#38543;&#30528; ODE &#26041;&#27861;&#38543;&#30528; m &#30340;&#25968;&#37327;&#21576;&#31435;&#26041;&#32423;&#21035;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unlike conventional grid and mesh based methods for solving partial differential equations (PDEs), neural networks have the potential to break the curse of dimensionality, providing approximate solutions to problems where using classical solvers is difficult or impossible. While global minimization of the PDE residual over the network parameters works well for boundary value problems, catastrophic forgetting impairs the applicability of this approach to initial value problems (IVPs). In an alternative local-in-time approach, the optimization problem can be converted into an ordinary differential equation (ODE) on the network parameters and the solution propagated forward in time; however, we demonstrate that current methods based on this approach suffer from two key issues. First, following the ODE produces an uncontrolled growth in the conditioning of the problem, ultimately leading to unacceptably large numerical errors. Second, as the ODE methods scale cubically with the number of m
&lt;/p&gt;</description></item><item><title>StyleDiff&#26159;&#19968;&#31181;&#22312;&#28508;&#22312;&#35299;&#32544;&#31354;&#38388;&#20013;&#27604;&#36739;&#26410;&#26631;&#35760;&#25968;&#25454;&#38598;&#23646;&#24615;&#24046;&#24322;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#24110;&#21161;&#24320;&#21457;&#20154;&#21592;&#20102;&#35299;&#20004;&#20010;&#25968;&#25454;&#38598;&#30340;&#24046;&#24322;&#65292;&#24182;&#20197;&#26131;&#20110;&#29702;&#35299;&#30340;&#26041;&#24335;&#25552;&#20379;&#20998;&#26512;&#12290;&#26041;&#27861;&#20855;&#26377;&#39640;&#25928;&#24615;&#33021;&#21644;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.05102</link><description>&lt;p&gt;
StyleDiff: &#22312;&#28508;&#22312;&#35299;&#32544;&#31354;&#38388;&#20013;&#27604;&#36739;&#26410;&#26631;&#35760;&#25968;&#25454;&#38598;&#30340;&#23646;&#24615;&#24046;&#24322;
&lt;/p&gt;
&lt;p&gt;
StyleDiff: Attribute Comparison Between Unlabeled Datasets in Latent Disentangled Space. (arXiv:2303.05102v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.05102
&lt;/p&gt;
&lt;p&gt;
StyleDiff&#26159;&#19968;&#31181;&#22312;&#28508;&#22312;&#35299;&#32544;&#31354;&#38388;&#20013;&#27604;&#36739;&#26410;&#26631;&#35760;&#25968;&#25454;&#38598;&#23646;&#24615;&#24046;&#24322;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#24110;&#21161;&#24320;&#21457;&#20154;&#21592;&#20102;&#35299;&#20004;&#20010;&#25968;&#25454;&#38598;&#30340;&#24046;&#24322;&#65292;&#24182;&#20197;&#26131;&#20110;&#29702;&#35299;&#30340;&#26041;&#24335;&#25552;&#20379;&#20998;&#26512;&#12290;&#26041;&#27861;&#20855;&#26377;&#39640;&#25928;&#24615;&#33021;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#30340;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#26159;&#35299;&#20915;&#24320;&#21457;&#20013;&#20351;&#29992;&#30340;&#25968;&#25454;&#38598;&#19982;&#23454;&#38469;&#24212;&#29992;&#20013;&#33719;&#21462;&#30340;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#12290;&#36825;&#20123;&#19981;&#21305;&#37197;&#21487;&#33021;&#23548;&#33268;&#39044;&#27979;&#19981;&#20934;&#30830;&#21644;&#38169;&#35823;&#65292;&#36827;&#32780;&#24433;&#21709;&#20135;&#21697;&#36136;&#37327;&#21644;&#31995;&#32479;&#30340;&#21487;&#38752;&#24615;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;StyleDiff&#65292;&#20197;&#20415;&#24320;&#21457;&#20154;&#21592;&#20102;&#35299;&#20004;&#20010;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#20197;&#23454;&#29616;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#30340;&#31283;&#23450;&#21457;&#23637;&#12290;&#20351;&#29992;&#26368;&#36817;&#25552;&#20986;&#30340;&#29983;&#25104;&#27169;&#22411;&#33719;&#24471;&#30340;&#35299;&#32544;&#22270;&#20687;&#31354;&#38388;&#65292;StyleDiff&#36890;&#36807;&#20851;&#27880;&#22270;&#20687;&#20013;&#30340;&#23646;&#24615;&#26469;&#27604;&#36739;&#20004;&#20010;&#25968;&#25454;&#38598;&#65292;&#24182;&#25552;&#20379;&#26131;&#20110;&#29702;&#35299;&#30340;&#24046;&#24322;&#20998;&#26512;&#12290;&#25152;&#25552;&#20986;&#30340;StyleDiff&#30340;&#24615;&#33021;&#20026;$O(dN\log N)$&#65292;&#20854;&#20013;$N$&#26159;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#65292;$d$&#26159;&#23646;&#24615;&#30340;&#25968;&#37327;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#35777;&#26126;StyleDiff&#33021;&#20934;&#30830;&#26816;&#27979;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#24182;&#20197;&#26131;&#20110;&#29702;&#35299;&#30340;&#26684;&#24335;&#21576;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
One major challenge in machine learning applications is coping with mismatches between the datasets used in the development and those obtained in real-world applications. These mismatches may lead to inaccurate predictions and errors, resulting in poor product quality and unreliable systems. In this study, we propose StyleDiff to inform developers of the differences between the two datasets for the steady development of machine learning systems. Using disentangled image spaces obtained from recently proposed generative models, StyleDiff compares the two datasets by focusing on attributes in the images and provides an easy-to-understand analysis of the differences between the datasets. The proposed StyleDiff performs in $O (d N\log N)$, where $N$ is the size of the datasets and $d$ is the number of attributes, enabling the application to large datasets. We demonstrate that StyleDiff accurately detects differences between datasets and presents them in an understandable format using, for 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#21327;&#20316;&#22810;&#26234;&#33021;&#20307;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25353;&#38656;&#36890;&#20449;&#21327;&#35758;ODC&#65292;&#21487;&#20197;&#26681;&#25454;&#26234;&#33021;&#20307;&#30340;&#32463;&#39564;&#25289;&#21160;&#26102;&#38388;&#35843;&#25972;&#27599;&#23545;&#26234;&#33021;&#20307;&#38388;&#30340;&#36890;&#20449;&#65292;&#21516;&#26102;&#23558;ODC&#38598;&#25104;&#21040;UCB&#21644;AAE&#31639;&#27861;&#30340;&#33258;&#28982;&#25193;&#23637;&#20013;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#36890;&#20449;&#25928;&#29575;&#39640;&#30340;&#21327;&#20316;&#31639;&#27861;&#65292;&#20998;&#26512;&#34920;&#26126;&#36825;&#20004;&#20010;&#31639;&#27861;&#22312;&#36951;&#25022;&#26041;&#38754;&#37117;&#25509;&#36817;&#26368;&#20248;&#12290;</title><link>http://arxiv.org/abs/2302.07446</link><description>&lt;p&gt;
&#24322;&#27493;&#22810;&#26234;&#33021;&#20307;&#36172;&#21338;&#26426;&#30340;&#25353;&#38656;&#36890;&#20449;
&lt;/p&gt;
&lt;p&gt;
On-Demand Communication for Asynchronous Multi-Agent Bandits. (arXiv:2302.07446v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07446
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#21327;&#20316;&#22810;&#26234;&#33021;&#20307;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25353;&#38656;&#36890;&#20449;&#21327;&#35758;ODC&#65292;&#21487;&#20197;&#26681;&#25454;&#26234;&#33021;&#20307;&#30340;&#32463;&#39564;&#25289;&#21160;&#26102;&#38388;&#35843;&#25972;&#27599;&#23545;&#26234;&#33021;&#20307;&#38388;&#30340;&#36890;&#20449;&#65292;&#21516;&#26102;&#23558;ODC&#38598;&#25104;&#21040;UCB&#21644;AAE&#31639;&#27861;&#30340;&#33258;&#28982;&#25193;&#23637;&#20013;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#36890;&#20449;&#25928;&#29575;&#39640;&#30340;&#21327;&#20316;&#31639;&#27861;&#65292;&#20998;&#26512;&#34920;&#26126;&#36825;&#20004;&#20010;&#31639;&#27861;&#22312;&#36951;&#25022;&#26041;&#38754;&#37117;&#25509;&#36817;&#26368;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#21327;&#20316;&#22810;&#26234;&#33021;&#20307;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#65292;&#20854;&#20013;&#26234;&#33021;&#20307;&#30340;&#25805;&#20316;&#26159;&#24322;&#27493;&#30340; - &#26234;&#33021;&#20307;&#30340;&#25289;&#21160;&#26102;&#38388;&#21644;&#36895;&#29575;&#26159;&#26410;&#30693;&#30340;&#12289;&#19981;&#35268;&#21017;&#30340;&#21644;&#24322;&#26500;&#30340; - &#24182;&#19988;&#38754;&#23545;&#30456;&#21516;&#30340;K&#33218;&#36172;&#21338;&#38382;&#39064;&#30340;&#23454;&#20363;&#12290;&#26234;&#33021;&#20307;&#21487;&#20197;&#20849;&#20139;&#22870;&#21169;&#20449;&#24687;&#20197;&#21152;&#24555;&#23398;&#20064;&#36807;&#31243;&#65292;&#20294;&#38656;&#35201;&#39069;&#22806;&#30340;&#36890;&#20449;&#25104;&#26412;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25353;&#38656;&#36890;&#20449;&#21327;&#35758;ODC&#65292;&#26681;&#25454;&#26234;&#33021;&#20307;&#30340;&#32463;&#39564;&#25289;&#21160;&#26102;&#38388;&#35843;&#25972;&#27599;&#23545;&#26234;&#33021;&#20307;&#38388;&#30340;&#36890;&#20449;&#12290;&#24403;&#26234;&#33021;&#20307;&#30340;&#25289;&#21160;&#26102;&#38388;&#39640;&#24230;&#19981;&#22343;&#21248;&#26102;&#65292;ODC&#20855;&#26377;&#39640;&#25928;&#24615;&#65292;&#24182;&#19988;&#20854;&#36890;&#20449;&#22797;&#26434;&#24615;&#21462;&#20915;&#20110;&#26234;&#33021;&#20307;&#30340;&#32463;&#39564;&#25289;&#21160;&#26102;&#38388;&#12290;ODC&#26159;&#19968;&#20010;&#36890;&#29992;&#30340;&#21327;&#35758;&#65292;&#21487;&#20197;&#38598;&#25104;&#21040;&#22823;&#22810;&#25968;&#21327;&#20316;&#36172;&#21338;&#31639;&#27861;&#20013;&#32780;&#19981;&#38477;&#20302;&#20854;&#24615;&#33021;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;ODC&#38598;&#25104;&#21040;UCB&#21644;AAE&#31639;&#27861;&#30340;&#33258;&#28982;&#25193;&#23637;&#20013;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#36890;&#20449;&#25928;&#29575;&#39640;&#30340;&#21327;&#20316;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#36825;&#20004;&#20010;&#31639;&#27861;&#22312;&#36951;&#25022;&#26041;&#38754;&#37117;&#25509;&#36817;&#26368;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies a cooperative multi-agent multi-armed stochastic bandit problem where agents operate asynchronously -- agent pull times and rates are unknown, irregular, and heterogeneous -- and face the same instance of a K-armed bandit problem. Agents can share reward information to speed up the learning process at additional communication costs. We propose ODC, an on-demand communication protocol that tailors the communication of each pair of agents based on their empirical pull times. ODC is efficient when the pull times of agents are highly heterogeneous, and its communication complexity depends on the empirical pull times of agents. ODC is a generic protocol that can be integrated into most cooperative bandit algorithms without degrading their performance. We then incorporate ODC into the natural extensions of UCB and AAE algorithms and propose two communication-efficient cooperative algorithms. Our analysis shows that both algorithms are near-optimal in regret.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;JKO&#26041;&#26696;&#30340;&#21487;&#36870;&#24402;&#19968;&#21270;&#27969;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#25353;&#22359;&#36827;&#34892;&#27531;&#24046;&#22359;&#30340;&#35757;&#32451;&#65292;&#20943;&#23569;&#20102;&#20869;&#23384;&#36127;&#36733;&#21644;&#28145;&#24230;&#27969;&#32593;&#32476;&#35757;&#32451;&#30340;&#38590;&#24230;&#12290;&#24182;&#19988;&#36890;&#36807;&#33258;&#36866;&#24212;&#26102;&#38388;&#37325;&#26032;&#21442;&#25968;&#21270;&#30340;&#27969;&#32593;&#32476;&#65292;&#22312;&#27010;&#29575;&#31354;&#38388;&#20013;&#36880;&#27493;&#32454;&#21270;&#36712;&#36857;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#35757;&#32451;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2212.14424</link><description>&lt;p&gt;
&#22522;&#20110;JKO&#26041;&#26696;&#30340;&#21487;&#36870;&#24402;&#19968;&#21270;&#27969;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Invertible normalizing flow neural networks by JKO scheme. (arXiv:2212.14424v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.14424
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;JKO&#26041;&#26696;&#30340;&#21487;&#36870;&#24402;&#19968;&#21270;&#27969;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#25353;&#22359;&#36827;&#34892;&#27531;&#24046;&#22359;&#30340;&#35757;&#32451;&#65292;&#20943;&#23569;&#20102;&#20869;&#23384;&#36127;&#36733;&#21644;&#28145;&#24230;&#27969;&#32593;&#32476;&#35757;&#32451;&#30340;&#38590;&#24230;&#12290;&#24182;&#19988;&#36890;&#36807;&#33258;&#36866;&#24212;&#26102;&#38388;&#37325;&#26032;&#21442;&#25968;&#21270;&#30340;&#27969;&#32593;&#32476;&#65292;&#22312;&#27010;&#29575;&#31354;&#38388;&#20013;&#36880;&#27493;&#32454;&#21270;&#36712;&#36857;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#35757;&#32451;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24402;&#19968;&#21270;&#27969;&#26159;&#19968;&#31867;&#29992;&#20110;&#39640;&#25928;&#37319;&#26679;&#21644;&#23494;&#24230;&#20272;&#35745;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#12290;&#23454;&#38469;&#20013;&#65292;&#27969;&#36890;&#24120;&#34920;&#31034;&#20026;&#19968;&#31995;&#21015;&#21487;&#36870;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22359;&#38142;; &#20026;&#20102;&#20415;&#20110;&#35757;&#32451;&#65292;&#29616;&#26377;&#30340;&#24037;&#20316;&#23545;&#27969;&#36712;&#36857;&#36827;&#34892;&#20102;&#27491;&#21017;&#21270;&#65292;&#24182;&#35774;&#35745;&#20102;&#29305;&#27530;&#30340;&#32593;&#32476;&#26550;&#26500;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#21463;Jordan-Kinderleherer-Otto (JKO)&#26041;&#26696;&#21551;&#21457;&#30340;&#31070;&#32463;ODE&#27969;&#32593;&#32476;&#65292;&#23427;&#20801;&#35768;&#26377;&#25928;&#22320;&#25353;&#22359;&#36827;&#34892;&#27531;&#24046;&#22359;&#30340;&#35757;&#32451;&#65292;&#26080;&#38656;&#37319;&#26679;SDE&#36712;&#36857;&#25110;&#20998;&#25968;&#21305;&#37197;&#25110;&#21464;&#20998;&#23398;&#20064;&#30340;&#20869;&#24490;&#29615;&#12290;&#30001;&#20110;JKO&#26041;&#26696;&#23637;&#24320;&#20102;&#26799;&#24230;&#27969;&#30340;&#21160;&#24577;&#65292;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#33258;&#28982;&#22320;&#36880;&#20010;&#22534;&#21472;&#27531;&#24046;&#32593;&#32476;&#22359;&#65292;&#38477;&#20302;&#20102;&#20869;&#23384;&#36127;&#36733;&#21644;&#36827;&#34892;&#31471;&#21040;&#31471;&#28145;&#24230;&#27969;&#32593;&#32476;&#35757;&#32451;&#30340;&#38590;&#24230;&#12290;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#33258;&#36866;&#24212;&#26102;&#38388;&#37325;&#26032;&#21442;&#25968;&#21270;&#30340;&#27969;&#32593;&#32476;&#65292;&#36890;&#36807;&#22312;&#27010;&#29575;&#31354;&#38388;&#20013;&#36880;&#27493;&#32454;&#21270;&#36712;&#36857;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#35757;&#32451;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Normalizing flow is a class of deep generative models for efficient sampling and density estimation. In practice, the flow often appears as a chain of invertible neural network blocks; to facilitate training, existing works have regularized flow trajectories and designed special network architectures. The current paper develops a neural ODE flow network inspired by the Jordan-Kinderleherer-Otto (JKO) scheme, which allows efficient block-wise training of the residual blocks without sampling SDE trajectories or inner loops of score matching or variational learning. As the JKO scheme unfolds the dynamic of gradient flow, the proposed model naturally stacks residual network blocks one by one, reducing the memory load and difficulty in performing end-to-end deep flow network training. We also develop adaptive time reparameterization of the flow network with a progressive refinement of the trajectory in probability space, which improves the model training efficiency and accuracy in practice.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#21512;&#24230;&#26816;&#39564;&#26041;&#27861;GRASP&#65292;&#29992;&#20110;&#35780;&#20272;&#36890;&#29992;&#20108;&#20998;&#31867;&#22120;&#23545;&#32473;&#23450;&#29305;&#24449;&#21521;&#37327;&#30340;&#26631;&#31614;&#30340;&#26465;&#20214;&#27010;&#29575;&#20998;&#24067;&#30340;&#25311;&#21512;&#31243;&#24230;&#12290;</title><link>http://arxiv.org/abs/2209.02064</link><description>&lt;p&gt;
GRASP: &#19968;&#31181;&#29992;&#20110;&#20998;&#31867;&#23398;&#20064;&#30340;&#36866;&#21512;&#24230;&#26816;&#39564;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
GRASP: A Goodness-of-Fit Test for Classification Learning. (arXiv:2209.02064v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.02064
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#21512;&#24230;&#26816;&#39564;&#26041;&#27861;GRASP&#65292;&#29992;&#20110;&#35780;&#20272;&#36890;&#29992;&#20108;&#20998;&#31867;&#22120;&#23545;&#32473;&#23450;&#29305;&#24449;&#21521;&#37327;&#30340;&#26631;&#31614;&#30340;&#26465;&#20214;&#27010;&#29575;&#20998;&#24067;&#30340;&#25311;&#21512;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#36890;&#24120;&#20197;&#27979;&#35797;&#25968;&#25454;&#30340;&#24179;&#22343;&#20934;&#30830;&#29575;&#34913;&#37327;&#12290;&#23613;&#31649;&#24179;&#22343;&#20934;&#30830;&#29575;&#26159;&#19968;&#31181;&#26631;&#20934;&#30340;&#34913;&#37327;&#26041;&#27861;&#65292;&#20294;&#23427;&#22312;&#25551;&#36848;&#27169;&#22411;&#23545;&#32473;&#23450;&#29305;&#24449;&#21521;&#37327;&#30340;&#26631;&#31614;&#30340;&#26465;&#20214;&#27010;&#29575;&#20998;&#24067;&#30340;&#25311;&#21512;&#31243;&#24230;&#26041;&#38754;&#23384;&#22312;&#32570;&#38519;&#65292;&#20363;&#22914;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#21270;&#12289;&#36807;&#25311;&#21512;&#21644;&#39640;&#32500;&#24230;&#31561;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#35780;&#20272;&#36890;&#29992;&#20108;&#20998;&#31867;&#22120;&#25311;&#21512;&#31243;&#24230;&#30340;&#22522;&#26412;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#19981;&#23545;&#26465;&#20214;&#27010;&#29575;&#20998;&#24067;$Y|X$&#36827;&#34892;&#20219;&#20309;&#21442;&#25968;&#20551;&#35774;&#65292;&#24182;&#23558;&#20854;&#35270;&#20026;&#40657;&#30418;&#23376;&#27169;&#22411;&#65292;&#21482;&#33021;&#36890;&#36807;&#26597;&#35810;&#35775;&#38382;&#12290;&#25105;&#20204;&#23558;&#36866;&#21512;&#24230;&#35780;&#20272;&#38382;&#39064;&#34920;&#36848;&#20026;&#23481;&#24525;&#24230;&#20551;&#35774;&#26816;&#39564;&#30340;&#24418;&#24335;\[ H_0: \mathbb{E}\Big[D_f\Big({\sf Bern}(\eta(X))\|{\sf Bern}(\hat{\eta}(X))\Big)\Big]\leq \tau\,, \]&#20854;&#20013;$D_f$&#34920;&#31034;&#19968;&#20010;$f$-&#25955;&#24230;&#20989;&#25968;&#65292;$\eta(x)$&#21644;$\hat{\eta}(x)$&#20998;&#21035;&#34920;&#31034;&#29305;&#24449;&#21521;&#37327;$x$&#30340;&#30495;&#23454;&#21644;&#20272;&#35745;&#30340;&#20284;&#28982;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Performance of classifiers is often measured in terms of average accuracy on test data. Despite being a standard measure, average accuracy fails in characterizing the fit of the model to the underlying conditional law of labels given the features vector ($Y|X$), e.g. due to model misspecification, over fitting, and high-dimensionality. In this paper, we consider the fundamental problem of assessing the goodness-of-fit for a general binary classifier. Our framework does not make any parametric assumption on the conditional law $Y|X$, and treats that as a black box oracle model which can be accessed only through queries. We formulate the goodness-of-fit assessment problem as a tolerance hypothesis testing of the form \[ H_0: \mathbb{E}\Big[D_f\Big({\sf Bern}(\eta(X))\|{\sf Bern}(\hat{\eta}(X))\Big)\Big]\leq \tau\,, \] where $D_f$ represents an $f$-divergence function, and $\eta(x)$, $\hat{\eta}(x)$ respectively denote the true and an estimate likelihood for a feature vector $x$ admitting
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#20687;&#30340;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#29983;&#25104;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#25299;&#23637;&#30340;&#26102;&#38388;&#24207;&#21015;&#38388;&#38548;&#22238;&#25253;&#22270;&#65288;XIRP&#65289;&#20316;&#20026;&#20108;&#32500;&#22270;&#20687;&#34920;&#31034;&#65292;&#33021;&#22815;&#20197;&#23610;&#24230;&#19981;&#21464;&#21644;&#21487;&#36870;&#30340;&#26041;&#24335;&#25429;&#25417;&#26102;&#38388;&#24207;&#21015;&#30340;&#21160;&#24577;&#29305;&#24615;&#65292;&#20174;&#32780;&#22312;&#38477;&#20302;&#35757;&#32451;&#26102;&#38388;&#21644;&#25552;&#39640;&#26679;&#26412;&#36136;&#37327;&#26041;&#38754;&#21462;&#24471;&#26174;&#33879;&#20248;&#21183;&#12290;&#36890;&#36807;&#19982;&#20854;&#20182;&#22270;&#20687;&#34920;&#31034;&#26041;&#27861;&#21644;&#27169;&#22411;&#30340;&#27604;&#36739;&#65292;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#22312;&#39044;&#27979;&#33021;&#21147;&#26041;&#38754;&#30340;&#20248;&#36234;&#24615;&#12290;&#21516;&#26102;&#65292;&#24341;&#20837;&#20102;&#25913;&#36827;&#30340;&#38543;&#26426;&#21453;&#28436;&#26041;&#27861;&#20197;&#25913;&#21892;&#26102;&#38388;&#24207;&#21015;&#30340;&#37325;&#24314;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2112.08060</link><description>&lt;p&gt;
&#21033;&#29992;&#22522;&#20110;&#22270;&#20687;&#30340;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#36827;&#34892;&#26102;&#38388;&#24207;&#21015;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Leveraging Image-based Generative Adversarial Networks for Time Series Generation. (arXiv:2112.08060v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.08060
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#20687;&#30340;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#29983;&#25104;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#25299;&#23637;&#30340;&#26102;&#38388;&#24207;&#21015;&#38388;&#38548;&#22238;&#25253;&#22270;&#65288;XIRP&#65289;&#20316;&#20026;&#20108;&#32500;&#22270;&#20687;&#34920;&#31034;&#65292;&#33021;&#22815;&#20197;&#23610;&#24230;&#19981;&#21464;&#21644;&#21487;&#36870;&#30340;&#26041;&#24335;&#25429;&#25417;&#26102;&#38388;&#24207;&#21015;&#30340;&#21160;&#24577;&#29305;&#24615;&#65292;&#20174;&#32780;&#22312;&#38477;&#20302;&#35757;&#32451;&#26102;&#38388;&#21644;&#25552;&#39640;&#26679;&#26412;&#36136;&#37327;&#26041;&#38754;&#21462;&#24471;&#26174;&#33879;&#20248;&#21183;&#12290;&#36890;&#36807;&#19982;&#20854;&#20182;&#22270;&#20687;&#34920;&#31034;&#26041;&#27861;&#21644;&#27169;&#22411;&#30340;&#27604;&#36739;&#65292;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#22312;&#39044;&#27979;&#33021;&#21147;&#26041;&#38754;&#30340;&#20248;&#36234;&#24615;&#12290;&#21516;&#26102;&#65292;&#24341;&#20837;&#20102;&#25913;&#36827;&#30340;&#38543;&#26426;&#21453;&#28436;&#26041;&#27861;&#20197;&#25913;&#21892;&#26102;&#38388;&#24207;&#21015;&#30340;&#37325;&#24314;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#29983;&#25104;&#27169;&#22411;&#33021;&#22815;&#20174;&#22797;&#26434;&#30340;&#25968;&#25454;&#20998;&#24067;&#20013;&#29983;&#25104;&#36924;&#30495;&#30340;&#26679;&#26412;&#65292;&#22240;&#27492;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#20013;&#65292;&#22522;&#20110;&#22270;&#20687;&#30340;&#29983;&#25104;&#27169;&#22411;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#20026;&#20102;&#21033;&#29992;&#22522;&#20110;&#22270;&#20687;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#26102;&#38388;&#24207;&#21015;&#39046;&#22495;&#30340;&#36827;&#23637;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20108;&#32500;&#22270;&#20687;&#34920;&#31034;&#26041;&#27861;&#65292;&#21363;&#25299;&#23637;&#30340;&#26102;&#38388;&#24207;&#21015;&#38388;&#38548;&#22238;&#25253;&#22270;&#65288;Extended Intertemporal Return Plot&#65292;XIRP&#65289;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20197;&#23610;&#24230;&#19981;&#21464;&#21644;&#21487;&#36870;&#30340;&#26041;&#24335;&#25429;&#25417;&#20102;&#26102;&#38388;&#24207;&#21015;&#30340;&#21160;&#24577;&#29305;&#24615;&#65292;&#38477;&#20302;&#20102;&#35757;&#32451;&#26102;&#38388;&#24182;&#25552;&#39640;&#20102;&#26679;&#26412;&#36136;&#37327;&#12290;&#25105;&#20204;&#20351;&#29992;&#24102;&#26377;&#26799;&#24230;&#24809;&#32602;&#30340;Wasserstein&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;WGAN-GP&#65289;&#23545;&#21512;&#25104;&#30340;XIRP&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#65292;&#19982;&#20854;&#20182;&#22270;&#20687;&#34920;&#31034;&#26041;&#27861;&#21644;&#27169;&#22411;&#36827;&#34892;&#20102;&#30456;&#20284;&#24615;&#21644;&#39044;&#27979;&#33021;&#21147;&#25351;&#26631;&#30340;&#27604;&#36739;&#12290;&#25105;&#20204;&#30340;&#21019;&#26032;&#24615;&#12289;&#32463;&#36807;&#39564;&#35777;&#30340;&#26102;&#38388;&#24207;&#21015;&#22270;&#20687;&#34920;&#31034;&#26041;&#27861;&#22312;&#39044;&#27979;&#33021;&#21147;&#26041;&#38754;&#22987;&#32456;&#26174;&#33879;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;RNN&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#25913;&#36827;&#30340;&#38543;&#26426;&#21453;&#28436;&#26041;&#27861;&#20351;&#24471;&#37325;&#24314;&#26102;&#38388;&#24207;&#21015;&#30340;&#25928;&#26524;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative models for images have gained significant attention in computer vision and natural language processing due to their ability to generate realistic samples from complex data distributions. To leverage the advances of image-based generative models for the time series domain, we propose a two-dimensional image representation for time series, the Extended Intertemporal Return Plot (XIRP). Our approach captures the intertemporal time series dynamics in a scale-invariant and invertible way, reducing training time and improving sample quality. We benchmark synthetic XIRPs obtained by an off-the-shelf Wasserstein GAN with gradient penalty (WGAN-GP) to other image representations and models regarding similarity and predictive ability metrics. Our novel, validated image representation for time series consistently and significantly outperforms a state-of-the-art RNN-based generative model regarding predictive ability. Further, we introduce an improved stochastic inversion to substantial
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#26469;&#27169;&#25311;&#20855;&#26377;&#22122;&#22768;&#20284;&#28982;&#30340;&#36817;&#20284;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#36873;&#25321;&#20855;&#26377;&#20449;&#24687;&#37327;&#30340;&#23545;&#25968;&#20284;&#28982;&#35780;&#20272;&#20301;&#32622;&#65292;&#25105;&#20204;&#33021;&#22815;&#20934;&#30830;&#22320;&#27169;&#25311;&#20986;&#31934;&#30830;&#30340;Metropolis-Hastings&#37319;&#26679;&#22120;&#30340;&#36335;&#24452;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#35745;&#31639;&#25928;&#29575;&#39640;&#19988;&#23545;GP&#24314;&#27169;&#20551;&#35774;&#36829;&#21453;&#26356;&#40065;&#26834;&#30340;&#36817;&#20284;&#37319;&#26679;&#22120;&#12290;</title><link>http://arxiv.org/abs/2104.03942</link><description>&lt;p&gt;
&#36890;&#36807;&#39640;&#26031;&#36807;&#31243;&#27169;&#25311;&#30340;MCMC&#36817;&#20284;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#30340;&#21547;&#26377;&#22122;&#22768;&#20284;&#28982;&#30340;&#36817;&#20284;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Approximate Bayesian inference from noisy likelihoods with Gaussian process emulated MCMC. (arXiv:2104.03942v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2104.03942
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#26469;&#27169;&#25311;&#20855;&#26377;&#22122;&#22768;&#20284;&#28982;&#30340;&#36817;&#20284;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#36873;&#25321;&#20855;&#26377;&#20449;&#24687;&#37327;&#30340;&#23545;&#25968;&#20284;&#28982;&#35780;&#20272;&#20301;&#32622;&#65292;&#25105;&#20204;&#33021;&#22815;&#20934;&#30830;&#22320;&#27169;&#25311;&#20986;&#31934;&#30830;&#30340;Metropolis-Hastings&#37319;&#26679;&#22120;&#30340;&#36335;&#24452;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#35745;&#31639;&#25928;&#29575;&#39640;&#19988;&#23545;GP&#24314;&#27169;&#20551;&#35774;&#36829;&#21453;&#26356;&#40065;&#26834;&#30340;&#36817;&#20284;&#37319;&#26679;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#26694;&#26550;&#65292;&#24403;&#30001;&#20110;&#35745;&#31639;&#38480;&#21046;&#32780;&#21482;&#33021;&#33719;&#24471;&#26377;&#38480;&#25968;&#37327;&#30340;&#21547;&#26377;&#22122;&#22768;&#30340;&#23545;&#25968;&#20284;&#28982;&#35780;&#20272;&#26102;&#65292;&#36825;&#22312;&#22797;&#26434;&#27169;&#22411;&#30340;&#24212;&#29992;&#20013;&#36234;&#26469;&#36234;&#24120;&#35265;&#12290;&#25105;&#20204;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#23545;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#36827;&#34892;&#24314;&#27169;&#65292;&#20027;&#35201;&#30340;&#26041;&#27861;&#21019;&#26032;&#26159;&#23558;&#35813;&#27169;&#22411;&#24212;&#29992;&#20110;&#27169;&#25311;&#31934;&#30830;&#30340;Metropolis-Hastings&#65288;MH&#65289;&#37319;&#26679;&#22120;&#22914;&#26524;&#36866;&#29992;&#30340;&#35805;&#23558;&#20250;&#37319;&#21462;&#30340;&#36335;&#24452;&#12290;&#20351;&#29992;&#39034;&#24207;&#23454;&#39564;&#35774;&#35745;&#31574;&#30053;&#36873;&#25321;&#20855;&#26377;&#20449;&#24687;&#37327;&#30340;&#23545;&#25968;&#20284;&#28982;&#35780;&#20272;&#20301;&#32622;&#65292;&#30452;&#21040;&#26681;&#25454;GP&#27169;&#22411;&#20934;&#30830;&#22320;&#23436;&#25104;MH&#25509;&#21463;/&#25298;&#32477;&#20915;&#31574;&#12290;&#24471;&#21040;&#30340;&#36817;&#20284;&#37319;&#26679;&#22120;&#22312;&#27010;&#24565;&#19978;&#31616;&#21333;&#19988;&#26679;&#26412;&#25928;&#29575;&#39640;&#12290;&#19982;&#26089;&#26399;&#30456;&#20851;&#30340;&#8220;&#31867;&#36125;&#21494;&#26031;&#20248;&#21270;&#8221;&#26041;&#27861;&#30456;&#27604;&#65292;&#23427;&#23545;GP&#24314;&#27169;&#20551;&#35774;&#30340;&#36829;&#21453;&#26356;&#20855;&#40065;&#26834;&#24615;&#65292;&#35813;&#26041;&#27861;&#19987;&#20026;&#36125;&#21494;&#26031;&#25512;&#26029;&#32780;&#35774;&#35745;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#19968;&#20123;&#29702;&#35770;&#26041;&#38754;&#21644;&#21508;&#31181;&#32467;&#26524;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a framework for approximate Bayesian inference when only a limited number of noisy log-likelihood evaluations can be obtained due to computational constraints, which is becoming increasingly common for applications of complex models. We model the log-likelihood function using a Gaussian process (GP) and the main methodological innovation is to apply this model to emulate the progression that an exact Metropolis-Hastings (MH) sampler would take if it was applicable. Informative log-likelihood evaluation locations are selected using a sequential experimental design strategy until the MH accept/reject decision is done accurately enough according to the GP model. The resulting approximate sampler is conceptually simple and sample-efficient. It is also more robust to violations of GP modelling assumptions compared with earlier, related "Bayesian optimisation-like" methods tailored for Bayesian inference. We discuss some theoretical aspects and various interpretations of the resul
&lt;/p&gt;</description></item></channel></rss>