<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#30740;&#31350;&#35299;&#20915;&#20102;&#35782;&#21035;&#20855;&#26377;&#26368;&#39640;&#39044;&#26399;&#25928;&#26524;&#30340;&#27835;&#30103;&#26041;&#26696;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20855;&#26377;&#22266;&#23450;&#39044;&#31639;&#30340;&#23616;&#37096;&#26368;&#20248;&#31639;&#27861;&#26469;&#38477;&#20302;&#38169;&#35823;&#35782;&#21035;&#30340;&#27010;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.19788</link><description>&lt;p&gt;
&#20855;&#26377;&#22266;&#23450;&#39044;&#31639;&#30340;&#23616;&#37096;&#26368;&#20248;&#26368;&#20339;&#33218;&#35782;&#21035;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Locally Optimal Best Arm Identification with a Fixed Budget. (arXiv:2310.19788v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19788
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#35299;&#20915;&#20102;&#35782;&#21035;&#20855;&#26377;&#26368;&#39640;&#39044;&#26399;&#25928;&#26524;&#30340;&#27835;&#30103;&#26041;&#26696;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20855;&#26377;&#22266;&#23450;&#39044;&#31639;&#30340;&#23616;&#37096;&#26368;&#20248;&#31639;&#27861;&#26469;&#38477;&#20302;&#38169;&#35823;&#35782;&#21035;&#30340;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#35782;&#21035;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#30340;&#38382;&#39064;&#65292;&#21363;&#20855;&#26377;&#26368;&#39640;&#39044;&#26399;&#25928;&#26524;&#30340;&#27835;&#30103;&#26041;&#26696;&#12290;&#25105;&#20204;&#26088;&#22312;&#36890;&#36807;&#38477;&#20302;&#38169;&#35823;&#35782;&#21035;&#30340;&#27010;&#29575;&#26469;&#30830;&#23450;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#65292;&#36825;&#19968;&#38382;&#39064;&#22312;&#35768;&#22810;&#30740;&#31350;&#39046;&#22495;&#20013;&#24050;&#34987;&#25506;&#32034;&#65292;&#21253;&#25324;&#26368;&#20339;&#33218;&#35782;&#21035;&#65288;Best Arm Identification&#65292;BAI&#65289;&#21644;&#24207;&#21015;&#20248;&#21270;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;&#27835;&#30103;&#20998;&#37197;&#30340;&#36718;&#25968;&#26159;&#22266;&#23450;&#30340;&#12290;&#22312;&#27599;&#19968;&#36718;&#20013;&#65292;&#20915;&#31574;&#32773;&#23558;&#19968;&#31181;&#27835;&#30103;&#26041;&#26696;&#20998;&#37197;&#32473;&#19968;&#20010;&#23454;&#39564;&#21333;&#20803;&#65292;&#24182;&#35266;&#23519;&#30456;&#24212;&#30340;&#32467;&#26524;&#65292;&#35813;&#32467;&#26524;&#36981;&#24490;&#19981;&#21516;&#27835;&#30103;&#26041;&#26696;&#20043;&#38388;&#26041;&#24046;&#19981;&#21516;&#30340;&#39640;&#26031;&#20998;&#24067;&#12290;&#22312;&#23454;&#39564;&#32467;&#26463;&#26102;&#65292;&#25105;&#20204;&#26681;&#25454;&#35266;&#23519;&#32467;&#26524;&#25512;&#33616;&#19968;&#31181;&#27835;&#30103;&#26041;&#26696;&#20316;&#20026;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#30340;&#20272;&#35745;&#20540;&#12290;&#20915;&#31574;&#32773;&#30340;&#30446;&#26631;&#26159;&#35774;&#35745;&#19968;&#20010;&#23454;&#39564;&#65292;&#20351;&#38169;&#35823;&#35782;&#21035;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#30340;&#27010;&#29575;&#26368;&#23567;&#21270;&#12290;&#22522;&#20110;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#35823;&#35782;&#21035;&#27010;&#29575;&#30340;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study investigates the problem of identifying the best treatment arm, a treatment arm with the highest expected outcome. We aim to identify the best treatment arm with a lower probability of misidentification, which has been explored under various names across numerous research fields, including \emph{best arm identification} (BAI) and ordinal optimization. In our experiments, the number of treatment-allocation rounds is fixed. In each round, a decision-maker allocates a treatment arm to an experimental unit and observes a corresponding outcome, which follows a Gaussian distribution with a variance different among treatment arms. At the end of the experiment, we recommend one of the treatment arms as an estimate of the best treatment arm based on the observations. The objective of the decision-maker is to design an experiment that minimizes the probability of misidentifying the best treatment arm. With this objective in mind, we develop lower bounds for the probability of misident
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#65292;&#31216;&#20026;&#38750;&#20809;&#28369;&#24369;&#20984;&#26377;&#38480;&#21644;&#32806;&#21512;&#32452;&#21512;&#20248;&#21270;(NSWC FCCO)&#65292;&#36890;&#36807;&#25193;&#23637;&#24050;&#26377;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38750;&#20809;&#28369;&#24369;&#20984;FCCO&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#31639;&#27861;&#26469;&#25214;&#21040;Moreau&#29615;&#30340;&#949;-&#31283;&#23450;&#28857;&#12290;</title><link>http://arxiv.org/abs/2310.03234</link><description>&lt;p&gt;
&#38750;&#20809;&#28369;&#24369;&#20984;&#26377;&#38480;&#21644;&#32806;&#21512;&#32452;&#21512;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Non-Smooth Weakly-Convex Finite-sum Coupled Compositional Optimization. (arXiv:2310.03234v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03234
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#65292;&#31216;&#20026;&#38750;&#20809;&#28369;&#24369;&#20984;&#26377;&#38480;&#21644;&#32806;&#21512;&#32452;&#21512;&#20248;&#21270;(NSWC FCCO)&#65292;&#36890;&#36807;&#25193;&#23637;&#24050;&#26377;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38750;&#20809;&#28369;&#24369;&#20984;FCCO&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#31639;&#27861;&#26469;&#25214;&#21040;Moreau&#29615;&#30340;&#949;-&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#26032;&#30340;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#65292;&#31216;&#20026;&#38750;&#20809;&#28369;&#24369;&#20984;&#26377;&#38480;&#21644;&#32806;&#21512;&#32452;&#21512;&#20248;&#21270;(NSWC FCCO)&#12290;&#30001;&#20110;&#20854;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#30340;&#24191;&#27867;&#24212;&#29992;&#20197;&#21450;&#20854;&#35299;&#20915;&#22522;&#20110;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#38543;&#26426;&#31639;&#27861;&#30340;&#23616;&#38480;&#24615;&#65292;FCCO&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23545;&#20110;FCCO&#30340;&#30740;&#31350;&#20551;&#35774;&#20869;&#22806;&#20989;&#25968;&#37117;&#26159;&#20809;&#28369;&#30340;&#65292;&#38480;&#21046;&#20102;&#20854;&#33021;&#22815;&#35299;&#20915;&#26356;&#22810;&#31181;&#31867;&#30340;&#38382;&#39064;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#20174;&#38750;&#20809;&#28369;&#24369;&#20984;FCCO&#30340;&#35282;&#24230;&#36827;&#34892;&#20102;&#25193;&#23637;&#65292;&#20854;&#20013;&#22806;&#20989;&#25968;&#26159;&#24369;&#20984;&#19988;&#38750;&#36882;&#20943;&#30340;&#65292;&#20869;&#20989;&#25968;&#26159;&#24369;&#20984;&#30340;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#31639;&#27861;&#65292;&#24182;&#30830;&#23450;&#20854;&#22312;&#25214;&#21040;Moreau&#29615;&#30340;&#949;-&#31283;&#23450;&#28857;&#30340;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates new families of compositional optimization problems, called $\underline{\bf n}$on-$\underline{\bf s}$mooth $\underline{\bf w}$eakly-$\underline{\bf c}$onvex $\underline{\bf f}$inite-sum $\underline{\bf c}$oupled $\underline{\bf c}$ompositional $\underline{\bf o}$ptimization (NSWC FCCO). There has been a growing interest in FCCO due to its wide-ranging applications in machine learning and AI, as well as its ability to address the shortcomings of stochastic algorithms based on empirical risk minimization. However, current research on FCCO presumes that both the inner and outer functions are smooth, limiting their potential to tackle a more diverse set of problems. Our research expands on this area by examining non-smooth weakly-convex FCCO, where the outer function is weakly convex and non-decreasing, and the inner function is weakly-convex. We analyze a single-loop algorithm and establish its complexity for finding an $\epsilon$-stationary point of the Moreau env
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#21644;&#22522;&#20110;&#29289;&#29702;&#30340;&#26426;&#22120;&#23398;&#20064;&#30456;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#39044;&#27979;&#25605;&#25292;&#25705;&#25830;&#22686;&#26448;&#21046;&#36896;&#20013;&#30340;&#23792;&#20540;&#28201;&#24230;&#20998;&#24067;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#38598;&#25104;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#39044;&#27979;&#20013;&#34920;&#29616;&#20986;&#20102;&#36739;&#22909;&#30340;&#24615;&#33021;&#65292;&#26368;&#20339;&#30340;SML&#26041;&#27861;&#20026;&#26799;&#24230;&#25552;&#21319;&#27861;&#65292;&#26368;&#20302;&#30340;&#22343;&#26041;&#35823;&#24046;&#20026;165.78&#12290;</title><link>http://arxiv.org/abs/2309.06838</link><description>&lt;p&gt;
&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#21644;&#22522;&#20110;&#29289;&#29702;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#29992;&#20110;&#39044;&#27979;&#38109;&#21512;&#37329;&#25605;&#25292;&#25705;&#25830;&#22686;&#26448;&#21046;&#36896;&#20013;&#30340;&#23792;&#20540;&#28201;&#24230;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Supervised Machine Learning and Physics based Machine Learning approach for prediction of peak temperature distribution in Additive Friction Stir Deposition of Aluminium Alloy. (arXiv:2309.06838v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06838
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#21644;&#22522;&#20110;&#29289;&#29702;&#30340;&#26426;&#22120;&#23398;&#20064;&#30456;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#39044;&#27979;&#25605;&#25292;&#25705;&#25830;&#22686;&#26448;&#21046;&#36896;&#20013;&#30340;&#23792;&#20540;&#28201;&#24230;&#20998;&#24067;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#38598;&#25104;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#39044;&#27979;&#20013;&#34920;&#29616;&#20986;&#20102;&#36739;&#22909;&#30340;&#24615;&#33021;&#65292;&#26368;&#20339;&#30340;SML&#26041;&#27861;&#20026;&#26799;&#24230;&#25552;&#21319;&#27861;&#65292;&#26368;&#20302;&#30340;&#22343;&#26041;&#35823;&#24046;&#20026;165.78&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22686;&#26448;&#25605;&#25292;&#25705;&#25830;&#27785;&#31215;&#65288;AFSD&#65289;&#26159;&#19968;&#31181;&#26032;&#22411;&#30340;&#22266;&#24577;&#22686;&#26448;&#21046;&#36896;&#25216;&#26415;&#65292;&#23427;&#35299;&#20915;&#20102;&#20256;&#32479;&#31881;&#26411;&#24202;&#29076;&#28860;&#21644;&#23450;&#21521;&#33021;&#37327;&#27785;&#31215;&#26041;&#27861;&#20013;&#23384;&#22312;&#30340;&#23380;&#38553;&#29575;&#12289;&#24320;&#35010;&#21644;&#24615;&#33021;&#21508;&#21521;&#24322;&#24615;&#31561;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;AFSD&#20013;&#30340;&#24037;&#33402;&#21442;&#25968;&#12289;&#28909;&#37327;&#20998;&#24067;&#21644;&#24471;&#21040;&#30340;&#26174;&#24494;&#32467;&#26500;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#20173;&#28982;&#19981;&#22815;&#28165;&#26970;&#65292;&#36825;&#22952;&#30861;&#20102;&#24615;&#33021;&#30340;&#24037;&#33402;&#20248;&#21270;&#12290;&#26412;&#30740;&#31350;&#36816;&#29992;&#20102;&#19968;&#31181;&#20808;&#36827;&#30340;&#26694;&#26550;&#65292;&#23558;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#65288;SML&#65289;&#21644;&#22522;&#20110;&#29289;&#29702;&#30340;&#31070;&#32463;&#32593;&#32476;&#65288;PINNs&#65289;&#30456;&#32467;&#21512;&#65292;&#20197;&#20174;&#24037;&#33402;&#21442;&#25968;&#39044;&#27979;AFSD&#20013;&#30340;&#23792;&#20540;&#28201;&#24230;&#20998;&#24067;&#12290;&#23545;&#20110;SML&#24314;&#27169;&#65292;&#20351;&#29992;&#20102;&#20843;&#31181;&#22238;&#24402;&#31639;&#27861;&#65292;&#32780;&#23545;&#20110;PINNs&#65292;&#20351;&#29992;&#20102;&#36816;&#36755;&#12289;&#27874;&#20256;&#25773;&#12289;&#28909;&#20256;&#23548;&#21644;&#37327;&#23376;&#21147;&#23398;&#30340;&#25511;&#21046;&#26041;&#31243;&#12290;&#22312;&#22810;&#20010;&#32479;&#35745;&#25351;&#26631;&#19978;&#65292;&#38598;&#25104;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#34920;&#29616;&#20986;&#20102;&#36739;&#22909;&#30340;&#24615;&#33021;&#65292;&#26799;&#24230;&#25552;&#21319;&#27861;&#26159;&#26368;&#20339;&#30340;SML&#26041;&#27861;&#65292;&#26368;&#20302;&#30340;&#22343;&#26041;&#35823;&#24046;&#20026;165.78&#12290;
&lt;/p&gt;
&lt;p&gt;
Additive friction stir deposition (AFSD) is a novel solid-state additive manufacturing technique that circumvents issues of porosity, cracking, and properties anisotropy that plague traditional powder bed fusion and directed energy deposition approaches. However, correlations between process parameters, thermal profiles, and resulting microstructure in AFSD remain poorly understood. This hinders process optimization for properties. This work employs a cutting-edge framework combining supervised machine learning (SML) and physics-informed neural networks (PINNs) to predict peak temperature distribution in AFSD from process parameters. Eight regression algorithms were implemented for SML modeling, while four PINNs leveraged governing equations for transport, wave propagation, heat transfer, and quantum mechanics. Across multiple statistical measures, ensemble techniques like gradient boosting proved superior for SML, with lowest MSE of 165.78. The integrated ML approach was also applied 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20869;&#22312;&#32500;&#24230;&#23545;&#21387;&#32553;&#19979;&#30340;&#24230;&#37327;&#23398;&#20064;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#22312;&#23545;&#25968;&#25454;&#36827;&#34892;&#38543;&#26426;&#21387;&#32553;&#21518;&#22312;&#20302;&#32500;&#31354;&#38388;&#20869;&#35757;&#32451;&#20840;&#31209;&#24230;&#37327;&#30340;&#26041;&#27861;&#12290;&#29702;&#35770;&#20445;&#35777;&#20102;&#22312;&#19981;&#20381;&#36182;&#29615;&#22659;&#32500;&#24230;&#30340;&#24773;&#20917;&#19979;&#65292;&#24230;&#37327;&#23398;&#20064;&#30340;&#35823;&#24046;&#21487;&#20197;&#34987;&#25511;&#21046;&#65292;&#24182;&#19988;&#22312;&#23384;&#22312;&#33391;&#24615;&#20960;&#20309;&#32467;&#26500;&#26102;&#25928;&#26524;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2309.05751</link><description>&lt;p&gt;
&#20869;&#22312;&#32500;&#24230;&#23545;&#21387;&#32553;&#19979;&#30340;&#24230;&#37327;&#23398;&#20064;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
The Effect of Intrinsic Dimension on Metric Learning under Compression. (arXiv:2309.05751v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05751
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20869;&#22312;&#32500;&#24230;&#23545;&#21387;&#32553;&#19979;&#30340;&#24230;&#37327;&#23398;&#20064;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#22312;&#23545;&#25968;&#25454;&#36827;&#34892;&#38543;&#26426;&#21387;&#32553;&#21518;&#22312;&#20302;&#32500;&#31354;&#38388;&#20869;&#35757;&#32451;&#20840;&#31209;&#24230;&#37327;&#30340;&#26041;&#27861;&#12290;&#29702;&#35770;&#20445;&#35777;&#20102;&#22312;&#19981;&#20381;&#36182;&#29615;&#22659;&#32500;&#24230;&#30340;&#24773;&#20917;&#19979;&#65292;&#24230;&#37327;&#23398;&#20064;&#30340;&#35823;&#24046;&#21487;&#20197;&#34987;&#25511;&#21046;&#65292;&#24182;&#19988;&#22312;&#23384;&#22312;&#33391;&#24615;&#20960;&#20309;&#32467;&#26500;&#26102;&#25928;&#26524;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24230;&#37327;&#23398;&#20064;&#26088;&#22312;&#22312;&#36755;&#20837;&#31354;&#38388;&#20013;&#25214;&#21040;&#36866;&#24403;&#30340;&#36317;&#31163;&#24230;&#37327;&#65292;&#20197;&#25913;&#21892;&#22522;&#20110;&#36317;&#31163;&#30340;&#23398;&#20064;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;&#22312;&#39640;&#32500;&#29615;&#22659;&#20013;&#65292;&#24230;&#37327;&#23398;&#20064;&#36824;&#21487;&#20197;&#20316;&#20026;&#38477;&#32500;&#30340;&#25163;&#27573;&#65292;&#36890;&#36807;&#23545;&#23398;&#20064;&#30340;&#24230;&#37327;&#26045;&#21152;&#19968;&#20010;&#20302;&#31209;&#32422;&#26463;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#30340;&#26159;&#23545;&#25968;&#25454;&#30340;&#19968;&#20010;&#38543;&#26426;&#21387;&#32553;&#29256;&#26412;&#65292;&#28982;&#21518;&#22312;&#20854;&#20013;&#35757;&#32451;&#19968;&#20010;&#20840;&#31209;&#30340;&#24230;&#37327;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#20851;&#20110;&#36317;&#31163;&#24230;&#37327;&#23398;&#20064;&#30340;&#35823;&#24046;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#36825;&#20123;&#20445;&#35777;&#19981;&#20381;&#36182;&#20110;&#29615;&#22659;&#32500;&#24230;&#12290;&#25105;&#20204;&#30340;&#36793;&#30028;&#38500;&#20102;&#23545;&#26469;&#33258;&#26377;&#30028;&#25903;&#25345;&#30340;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#27809;&#26377;&#26174;&#24335;&#30340;&#20551;&#35774;&#20043;&#22806;&#65292;&#24182;&#19988;&#22312;&#23384;&#22312;&#33391;&#24615;&#20960;&#20309;&#32467;&#26500;&#26102;&#33258;&#21160;&#25910;&#25947;&#12290;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#25903;&#25345;&#25105;&#20204;&#22312;&#39640;&#32500;&#29615;&#22659;&#20013;&#30340;&#29702;&#35770;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Metric learning aims at finding a suitable distance metric over the input space, to improve the performance of distance-based learning algorithms. In high-dimensional settings, metric learning can also play the role of dimensionality reduction, by imposing a low-rank restriction to the learnt metric. In this paper, instead of training a low-rank metric on high-dimensional data, we consider a randomly compressed version of the data, and train a full-rank metric there. We give theoretical guarantees on the error of distance-based metric learning, with respect to the random compression, which do not depend on the ambient dimension. Our bounds do not make any explicit assumptions, aside from i.i.d. data from a bounded support, and automatically tighten when benign geometrical structures are present. Experimental results on both synthetic and real data sets support our theoretical findings in high-dimensional settings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26816;&#27979;&#28040;&#36153;&#32773;&#25237;&#35785;&#21465;&#36848;&#20013;&#30340;&#31995;&#32479;&#24322;&#24120;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#35299;&#20915;&#20998;&#31867;&#31639;&#27861;&#23545;&#20110;&#36739;&#23567;&#19988;&#39057;&#32321;&#20986;&#29616;&#30340;&#31995;&#32479;&#24322;&#24120;&#26816;&#27979;&#30340;&#38382;&#39064;&#65292;&#24182;&#23558;&#25237;&#35785;&#21465;&#36848;&#36716;&#21270;&#20026;&#23450;&#37327;&#25968;&#25454;&#36827;&#34892;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2308.11138</link><description>&lt;p&gt;
&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#28040;&#36153;&#32773;&#25237;&#35785;&#21465;&#36848;&#20013;&#31995;&#32479;&#24322;&#24120;&#30340;&#26816;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
NLP-based detection of systematic anomalies among the narratives of consumer complaints. (arXiv:2308.11138v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11138
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26816;&#27979;&#28040;&#36153;&#32773;&#25237;&#35785;&#21465;&#36848;&#20013;&#30340;&#31995;&#32479;&#24322;&#24120;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#35299;&#20915;&#20998;&#31867;&#31639;&#27861;&#23545;&#20110;&#36739;&#23567;&#19988;&#39057;&#32321;&#20986;&#29616;&#30340;&#31995;&#32479;&#24322;&#24120;&#26816;&#27979;&#30340;&#38382;&#39064;&#65292;&#24182;&#23558;&#25237;&#35785;&#21465;&#36848;&#36716;&#21270;&#20026;&#23450;&#37327;&#25968;&#25454;&#36827;&#34892;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26816;&#27979;&#25237;&#35785;&#21465;&#36848;&#20013;&#30340;&#31995;&#32479;&#24322;&#24120;&#65292;&#31616;&#31216;&#20026;&#31995;&#32479;&#24322;&#24120;&#12290;&#23613;&#31649;&#20998;&#31867;&#31639;&#27861;&#34987;&#29992;&#20110;&#26816;&#27979;&#26126;&#26174;&#30340;&#24322;&#24120;&#65292;&#20294;&#22312;&#36739;&#23567;&#19988;&#39057;&#32321;&#20986;&#29616;&#30340;&#31995;&#32479;&#24322;&#24120;&#24773;&#20917;&#19979;&#65292;&#31639;&#27861;&#21487;&#33021;&#20250;&#22240;&#20026;&#21508;&#31181;&#21407;&#22240;&#32780;&#22833;&#25928;&#65292;&#21253;&#25324;&#25216;&#26415;&#21407;&#22240;&#21644;&#20154;&#24037;&#20998;&#26512;&#24072;&#30340;&#33258;&#28982;&#38480;&#21046;&#12290;&#22240;&#27492;&#65292;&#22312;&#20998;&#31867;&#20043;&#21518;&#30340;&#19979;&#19968;&#27493;&#20013;&#65292;&#25105;&#20204;&#23558;&#25237;&#35785;&#21465;&#36848;&#36716;&#21270;&#20026;&#23450;&#37327;&#25968;&#25454;&#65292;&#28982;&#21518;&#20351;&#29992;&#19968;&#31181;&#31639;&#27861;&#26469;&#26816;&#27979;&#31995;&#32479;&#24322;&#24120;&#12290;&#25105;&#20204;&#20351;&#29992;&#28040;&#36153;&#32773;&#37329;&#34701;&#20445;&#25252;&#23616;&#30340;&#28040;&#36153;&#32773;&#25237;&#35785;&#25968;&#25454;&#24211;&#20013;&#30340;&#25237;&#35785;&#21465;&#36848;&#26469;&#35828;&#26126;&#25972;&#20010;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop an NLP-based procedure for detecting systematic nonmeritorious consumer complaints, simply called systematic anomalies, among complaint narratives. While classification algorithms are used to detect pronounced anomalies, in the case of smaller and frequent systematic anomalies, the algorithms may falter due to a variety of reasons, including technical ones as well as natural limitations of human analysts. Therefore, as the next step after classification, we convert the complaint narratives into quantitative data, which are then analyzed using an algorithm for detecting systematic anomalies. We illustrate the entire procedure using complaint narratives from the Consumer Complaint Database of the Consumer Financial Protection Bureau.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32852;&#21512;&#31934;&#31639;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#30340;&#27178;&#26029;&#38754;&#21644;&#32437;&#21521;&#32034;&#36180;&#35745;&#25968;&#27169;&#22411;&#65292;&#36890;&#36807;&#32467;&#21512;&#20256;&#32479;&#31934;&#31639;&#27169;&#22411;&#21644;&#31070;&#32463;&#32593;&#32476;&#65292;&#20805;&#20998;&#21033;&#29992;&#20102;&#20004;&#20010;&#27169;&#22411;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2308.01729</link><description>&lt;p&gt;
&#22522;&#20110;&#32852;&#21512;&#31934;&#31639;&#31070;&#32463;&#32593;&#32476;&#30340;&#27178;&#26029;&#38754;&#21644;&#32437;&#21521;&#32034;&#36180;&#35745;&#25968;&#25968;&#25454;&#30340;&#36710;&#36733;&#36890;&#20449;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Telematics Combined Actuarial Neural Networks for Cross-Sectional and Longitudinal Claim Count Data. (arXiv:2308.01729v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01729
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32852;&#21512;&#31934;&#31639;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#30340;&#27178;&#26029;&#38754;&#21644;&#32437;&#21521;&#32034;&#36180;&#35745;&#25968;&#27169;&#22411;&#65292;&#36890;&#36807;&#32467;&#21512;&#20256;&#32479;&#31934;&#31639;&#27169;&#22411;&#21644;&#31070;&#32463;&#32593;&#32476;&#65292;&#20805;&#20998;&#21033;&#29992;&#20102;&#20004;&#20010;&#27169;&#22411;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Mario W\"uthrich&#21644;Michael Merz&#25552;&#20986;&#30340;&#32852;&#21512;&#31934;&#31639;&#31070;&#32463;&#32593;&#32476;&#65288;CANN&#65289;&#26694;&#26550;&#30340;&#27178;&#26029;&#38754;&#21644;&#32437;&#21521;&#32034;&#36180;&#35745;&#25968;&#27169;&#22411;&#12290;CANN&#26041;&#27861;&#23558;&#20256;&#32479;&#30340;&#31934;&#31639;&#27169;&#22411;&#65288;&#22914;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65289;&#19982;&#31070;&#32463;&#32593;&#32476;&#30456;&#32467;&#21512;&#65292;&#24418;&#25104;&#20102;&#19968;&#20010;&#21253;&#21547;&#32463;&#20856;&#22238;&#24402;&#27169;&#22411;&#21644;&#31070;&#32463;&#32593;&#32476;&#37096;&#20998;&#30340;&#21452;&#32452;&#20214;&#27169;&#22411;&#12290;CANN&#27169;&#22411;&#20805;&#20998;&#21033;&#29992;&#20102;&#20004;&#20010;&#27169;&#22411;&#30340;&#20248;&#21183;&#65292;&#26082;&#21487;&#20197;&#25552;&#20379;&#32463;&#20856;&#27169;&#22411;&#30340;&#21487;&#38752;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#21448;&#21487;&#20197;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#28789;&#27963;&#24615;&#21644;&#23545;&#22797;&#26434;&#20851;&#31995;&#21644;&#20132;&#20114;&#20316;&#29992;&#30340;&#25429;&#25417;&#33021;&#21147;&#12290;&#22312;&#25105;&#20204;&#25552;&#20986;&#30340;&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#24191;&#20026;&#20154;&#30693;&#30340;&#23545;&#25968;&#32447;&#24615;&#32034;&#36180;&#35745;&#25968;&#22238;&#24402;&#27169;&#22411;&#20316;&#20026;&#32463;&#20856;&#22238;&#24402;&#37096;&#20998;&#65292;&#20351;&#29992;&#20102;&#22810;&#23618;&#24863;&#30693;&#22120;&#65288;MLP&#65289;&#20316;&#20026;&#31070;&#32463;&#32593;&#32476;&#37096;&#20998;&#12290;MLP&#37096;&#20998;&#29992;&#20110;&#22788;&#29702;&#20197;&#21521;&#37327;&#24418;&#24335;&#34920;&#31034;&#30340;&#36710;&#36742;&#39550;&#39542;&#34892;&#20026;&#30340;&#36710;&#36733;&#36890;&#20449;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present novel cross-sectional and longitudinal claim count models for vehicle insurance built upon the Combined Actuarial Neural Network (CANN) framework proposed by Mario W\"uthrich and Michael Merz. The CANN approach combines a classical actuarial model, such as a generalized linear model, with a neural network. This blending of models results in a two-component model comprising a classical regression model and a neural network part. The CANN model leverages the strengths of both components, providing a solid foundation and interpretability from the classical model while harnessing the flexibility and capacity to capture intricate relationships and interactions offered by the neural network. In our proposed models, we use well-known log-linear claim count regression models for the classical regression part and a multilayer perceptron (MLP) for the neural network part. The MLP part is used to process telematics car driving data given as a vector characterizing the driving behavior 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#23567;&#38543;&#26426;&#32534;&#30721;&#23398;&#20064;&#65288;MIRACLE&#65289;&#30340;&#20004;&#20010;&#21464;&#20307;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21442;&#25968;&#21270;&#26041;&#27861;Mean-KL&#65292;&#22312;&#21387;&#32553;&#21464;&#20998;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20013;&#23454;&#29616;&#20102;&#26356;&#24555;&#30340;&#25910;&#25947;&#21644;&#33391;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.07816</link><description>&lt;p&gt;
&#24102;&#26377;Mean-KL&#21442;&#25968;&#21270;&#30340;&#26368;&#23567;&#38543;&#26426;&#32534;&#30721;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Minimal Random Code Learning with Mean-KL Parameterization. (arXiv:2307.07816v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07816
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#23567;&#38543;&#26426;&#32534;&#30721;&#23398;&#20064;&#65288;MIRACLE&#65289;&#30340;&#20004;&#20010;&#21464;&#20307;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21442;&#25968;&#21270;&#26041;&#27861;Mean-KL&#65292;&#22312;&#21387;&#32553;&#21464;&#20998;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20013;&#23454;&#29616;&#20102;&#26356;&#24555;&#30340;&#25910;&#25947;&#21644;&#33391;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#23567;&#38543;&#26426;&#32534;&#30721;&#23398;&#20064;&#65288;MIRACLE&#65289;&#30340;&#20004;&#20010;&#21464;&#20307;&#22312;&#21387;&#32553;&#21464;&#20998;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#23450;&#24615;&#34892;&#20026;&#21644;&#40065;&#26834;&#24615;&#12290;MIRACLE&#23454;&#29616;&#20102;&#24378;&#22823;&#30340;&#26465;&#20214;&#39640;&#26031;&#21464;&#20998;&#36817;&#20284;&#26435;&#37325;&#21518;&#39564;$Q_{\mathbf{w}}$&#65292;&#24182;&#20351;&#29992;&#30456;&#23545;&#29109;&#32534;&#30721;&#26469;&#21387;&#32553;&#20174;&#21518;&#39564;&#20013;&#25277;&#26679;&#30340;&#26435;&#37325;&#65292;&#20351;&#29992;&#39640;&#26031;&#32534;&#30721;&#20998;&#24067;$P_{\mathbf{w}}$&#12290;&#20026;&#20102;&#36798;&#21040;&#25152;&#38656;&#30340;&#21387;&#32553;&#29575;&#65292;&#24517;&#39035;&#23545;$Q_{\mathbf{w}} \Vert P_{\mathbf{w}}$&#36827;&#34892;&#32422;&#26463;&#65292;&#36825;&#38656;&#35201;&#22312;&#20256;&#32479;&#30340;&#22343;&#20540;-&#26041;&#24046;&#65288;Mean-Var&#65289;&#21442;&#25968;&#21270;&#19979;&#36827;&#34892;&#35745;&#31639;&#19978;&#26114;&#36149;&#30340;&#36864;&#28779;&#36807;&#31243;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#36890;&#36807;&#20854;&#24179;&#22343;&#20540;&#21644;KL&#25955;&#24230;&#26469;&#21442;&#25968;&#21270;$Q_{\mathbf{w}}$&#65292;&#20197;&#36890;&#36807;&#26500;&#36896;&#23558;&#21387;&#32553;&#25104;&#26412;&#32422;&#26463;&#20026;&#25152;&#38656;&#20540;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20351;&#29992;Mean-KL&#21442;&#25968;&#21270;&#30340;&#21464;&#20998;&#35757;&#32451;&#25910;&#25947;&#36895;&#24230;&#26159;&#20256;&#32479;&#26041;&#27861;&#30340;&#20004;&#20493;&#65292;&#24182;&#19988;&#22312;&#35757;&#32451;&#21518;&#20445;&#25345;&#20102;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the qualitative behavior and robustness of two variants of Minimal Random Code Learning (MIRACLE) used to compress variational Bayesian neural networks. MIRACLE implements a powerful, conditionally Gaussian variational approximation for the weight posterior $Q_{\mathbf{w}}$ and uses relative entropy coding to compress a weight sample from the posterior using a Gaussian coding distribution $P_{\mathbf{w}}$. To achieve the desired compression rate, $D_{\mathrm{KL}}[Q_{\mathbf{w}} \Vert P_{\mathbf{w}}]$ must be constrained, which requires a computationally expensive annealing procedure under the conventional mean-variance (Mean-Var) parameterization for $Q_{\mathbf{w}}$. Instead, we parameterize $Q_{\mathbf{w}}$ by its mean and KL divergence from $P_{\mathbf{w}}$ to constrain the compression cost to the desired value by construction. We demonstrate that variational training with Mean-KL parameterization converges twice as fast and maintains predictive performance after 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#32452;&#21512;&#24615;&#25968;&#25454;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#23545;&#38543;&#26426;&#23618;&#27425;&#27169;&#22411;&#36827;&#34892;&#20998;&#31867;&#20219;&#21153;&#65292;&#21457;&#29616;&#28145;&#24230;CNN&#23398;&#20064;&#36825;&#20010;&#20219;&#21153;&#25152;&#38656;&#30340;&#35757;&#32451;&#25968;&#25454;&#25968;&#37327;&#38543;&#30528;&#31867;&#21035;&#25968;&#12289;&#32452;&#21512;&#25968;&#21644;&#36845;&#20195;&#27425;&#25968;&#30340;&#22686;&#21152;&#32780;&#28176;&#36827;&#22686;&#21152;&#12290;</title><link>http://arxiv.org/abs/2307.02129</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22914;&#20309;&#23398;&#20064;&#32452;&#21512;&#24615;&#25968;&#25454;&#65306;&#38543;&#26426;&#23618;&#27425;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
How Deep Neural Networks Learn Compositional Data: The Random Hierarchy Model. (arXiv:2307.02129v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02129
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#32452;&#21512;&#24615;&#25968;&#25454;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#23545;&#38543;&#26426;&#23618;&#27425;&#27169;&#22411;&#36827;&#34892;&#20998;&#31867;&#20219;&#21153;&#65292;&#21457;&#29616;&#28145;&#24230;CNN&#23398;&#20064;&#36825;&#20010;&#20219;&#21153;&#25152;&#38656;&#30340;&#35757;&#32451;&#25968;&#25454;&#25968;&#37327;&#38543;&#30528;&#31867;&#21035;&#25968;&#12289;&#32452;&#21512;&#25968;&#21644;&#36845;&#20195;&#27425;&#25968;&#30340;&#22686;&#21152;&#32780;&#28176;&#36827;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#19968;&#33324;&#39640;&#32500;&#20219;&#21153;&#26159;&#38750;&#24120;&#22256;&#38590;&#30340;&#65292;&#22240;&#20026;&#23427;&#38656;&#35201;&#19982;&#32500;&#24230;&#25104;&#25351;&#25968;&#22686;&#38271;&#30340;&#35757;&#32451;&#25968;&#25454;&#25968;&#37327;&#12290;&#28982;&#32780;&#65292;&#28145;&#24230;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#22312;&#20811;&#26381;&#36825;&#19968;&#25361;&#25112;&#26041;&#38754;&#26174;&#31034;&#20986;&#20102;&#21331;&#36234;&#30340;&#25104;&#21151;&#12290;&#19968;&#31181;&#26222;&#36941;&#30340;&#20551;&#35774;&#26159;&#21487;&#23398;&#20064;&#20219;&#21153;&#20855;&#26377;&#39640;&#24230;&#32467;&#26500;&#21270;&#65292;CNN&#21033;&#29992;&#36825;&#31181;&#32467;&#26500;&#24314;&#31435;&#20102;&#25968;&#25454;&#30340;&#20302;&#32500;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#23545;&#23427;&#20204;&#38656;&#35201;&#22810;&#23569;&#35757;&#32451;&#25968;&#25454;&#20197;&#21450;&#36825;&#20010;&#25968;&#23383;&#22914;&#20309;&#21462;&#20915;&#20110;&#25968;&#25454;&#32467;&#26500;&#30693;&#20043;&#29978;&#23569;&#12290;&#26412;&#25991;&#22238;&#31572;&#20102;&#38024;&#23545;&#19968;&#20010;&#31616;&#21333;&#30340;&#20998;&#31867;&#20219;&#21153;&#30340;&#36825;&#20010;&#38382;&#39064;&#65292;&#35813;&#20219;&#21153;&#26088;&#22312;&#25429;&#25417;&#30495;&#23454;&#25968;&#25454;&#30340;&#30456;&#20851;&#26041;&#38754;&#65306;&#38543;&#26426;&#23618;&#27425;&#27169;&#22411;&#12290;&#22312;&#36825;&#20010;&#27169;&#22411;&#20013;&#65292;$n_c$&#20010;&#31867;&#21035;&#20013;&#30340;&#27599;&#19968;&#20010;&#23545;&#24212;&#20110;$m$&#20010;&#21516;&#20041;&#32452;&#21512;&#30340;&#39640;&#23618;&#27425;&#29305;&#24449;&#65292;&#24182;&#19988;&#36825;&#20123;&#29305;&#24449;&#21448;&#36890;&#36807;&#19968;&#20010;&#37325;&#22797;$L$&#27425;&#30340;&#36845;&#20195;&#36807;&#31243;&#30001;&#23376;&#29305;&#24449;&#32452;&#25104;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#38656;&#35201;&#28145;&#24230;CNN&#23398;&#20064;&#36825;&#20010;&#20219;&#21153;&#30340;&#35757;&#32451;&#25968;&#25454;&#25968;&#37327;$P^*$&#65288;i&#65289;&#38543;&#30528;$n_c m^L$&#30340;&#22686;&#38271;&#32780;&#28176;&#36827;&#22320;&#22686;&#38271;&#65292;&#36825;&#21482;&#26377;...
&lt;/p&gt;
&lt;p&gt;
Learning generic high-dimensional tasks is notably hard, as it requires a number of training data exponential in the dimension. Yet, deep convolutional neural networks (CNNs) have shown remarkable success in overcoming this challenge. A popular hypothesis is that learnable tasks are highly structured and that CNNs leverage this structure to build a low-dimensional representation of the data. However, little is known about how much training data they require, and how this number depends on the data structure. This paper answers this question for a simple classification task that seeks to capture relevant aspects of real data: the Random Hierarchy Model. In this model, each of the $n_c$ classes corresponds to $m$ synonymic compositions of high-level features, which are in turn composed of sub-features through an iterative process repeated $L$ times. We find that the number of training data $P^*$ required by deep CNNs to learn this task (i) grows asymptotically as $n_c m^L$, which is only
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#20989;&#25968;&#35299;&#37322;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#22120;&#12290;&#37319;&#26679;&#22120;&#34920;&#29616;&#20986;&#20102;&#26368;&#20808;&#36827;&#30340;FID&#24471;&#20998;&#65292;&#24182;&#33021;&#22815;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#12290;</title><link>http://arxiv.org/abs/2306.04848</link><description>&lt;p&gt;
&#21033;&#29992;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#20989;&#25968;&#35299;&#37322;&#21644;&#25913;&#36827;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Interpreting and Improving Diffusion Models Using the Euclidean Distance Function. (arXiv:2306.04848v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04848
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#20989;&#25968;&#35299;&#37322;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#22120;&#12290;&#37319;&#26679;&#22120;&#34920;&#29616;&#20986;&#20102;&#26368;&#20808;&#36827;&#30340;FID&#24471;&#20998;&#65292;&#24182;&#33021;&#22815;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21435;&#22122;&#30452;&#35273;&#19978;&#19982;&#25237;&#24433;&#26377;&#20851;&#12290;&#20107;&#23454;&#19978;&#65292;&#22312;&#27969;&#24418;&#20551;&#35774;&#19979;&#65292;&#28155;&#21152;&#38543;&#26426;&#22122;&#22768;&#36817;&#20284;&#31561;&#20215;&#20110;&#27491;&#20132;&#25200;&#21160;&#12290;&#22240;&#27492;&#65292;&#23398;&#20064;&#21435;&#22122;&#36817;&#20284;&#20110;&#23398;&#20064;&#25237;&#24433;&#12290;&#26412;&#25991;&#21033;&#29992;&#36825;&#19968;&#35266;&#23519;&#32467;&#26524;&#65292;&#23558;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#35299;&#37322;&#20026;&#24212;&#29992;&#20110;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#20989;&#25968;&#30340;&#36817;&#20284;&#26799;&#24230;&#19979;&#38477;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#22522;&#20110;&#23545;&#21435;&#22122;&#22120;&#25237;&#24433;&#35823;&#24046;&#30340;&#31616;&#21333;&#20551;&#35774;&#65292;&#25552;&#20379;DDIM&#65288;Denoising Diffusion Implicit Models&#65289;&#37319;&#26679;&#22120;&#30340;&#31616;&#21333;&#25910;&#25947;&#20998;&#26512;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22522;&#20110;&#29702;&#35770;&#32467;&#26524;&#30340;&#27934;&#35265;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#23545;DDIM&#30340;&#20004;&#20010;&#31616;&#21333;&#20462;&#25913;&#30340;&#26032;&#37319;&#26679;&#22120;&#12290;&#20165;&#38656;&#35201;5-10&#20010;&#20989;&#25968;&#35780;&#20272;&#65292;&#25105;&#20204;&#30340;&#37319;&#26679;&#22120;&#23601;&#33021;&#22312;&#39044;&#35757;&#32451;&#30340;CIFAR-10&#21644;CelebA&#27169;&#22411;&#19978;&#36798;&#21040;&#26368;&#20808;&#36827;&#30340;FID&#24471;&#20998;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#19978;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Denoising is intuitively related to projection. Indeed, under the manifold hypothesis, adding random noise is approximately equivalent to orthogonal perturbation. Hence, learning to denoise is approximately learning to project. In this paper, we use this observation to reinterpret denoising diffusion models as approximate gradient descent applied to the Euclidean distance function. We then provide straight-forward convergence analysis of the DDIM sampler under simple assumptions on the projection-error of the denoiser. Finally, we propose a new sampler based on two simple modifications to DDIM using insights from our theoretical results. In as few as 5-10 function evaluations, our sampler achieves state-of-the-art FID scores on pretrained CIFAR-10 and CelebA models and can generate high quality samples on latent diffusion models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20048;&#35266;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#20248;&#21270;&#26694;&#26550;&#65292;&#37319;&#29992;&#20048;&#35266;&#31574;&#30053;&#35780;&#20272;&#23376;&#31243;&#24207;&#20197;&#40723;&#21169;&#25506;&#32034;&#65292;&#36866;&#29992;&#20110;&#32447;&#24615;MDP&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#20855;&#26377;&#26368;&#20248;&#32500;&#24230;&#20381;&#36182;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2305.11032</link><description>&lt;p&gt;
&#20048;&#35266;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#65306;&#19968;&#31181;&#31616;&#21333;&#39640;&#25928;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#20248;&#21270;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Optimistic Natural Policy Gradient: a Simple Efficient Policy Optimization Framework for Online RL. (arXiv:2305.11032v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11032
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20048;&#35266;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#20248;&#21270;&#26694;&#26550;&#65292;&#37319;&#29992;&#20048;&#35266;&#31574;&#30053;&#35780;&#20272;&#23376;&#31243;&#24207;&#20197;&#40723;&#21169;&#25506;&#32034;&#65292;&#36866;&#29992;&#20110;&#32447;&#24615;MDP&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#20855;&#26377;&#26368;&#20248;&#32500;&#24230;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#23545;&#20110;&#36817;&#26399;&#24378;&#21270;&#23398;&#20064;&#30340;&#23454;&#35777;&#25104;&#21151;&#21457;&#25381;&#20102;&#37325;&#35201;&#20316;&#29992;&#65292;&#20294;&#31574;&#30053;&#20248;&#21270;&#30340;&#29616;&#26377;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#30456;&#24403;&#26377;&#38480; - &#23427;&#20204;&#35201;&#20040;&#23616;&#38480;&#20110;&#34920;&#26684;MDP&#65292;&#35201;&#20040;&#22312;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#23384;&#22312;&#39640;&#24230;&#20122;&#26368;&#20248;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#39640;&#25928;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#20248;&#21270;&#26694;&#26550; - &#20048;&#35266;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#12290;&#20048;&#35266;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#21487;&#20197;&#30475;&#20316;&#26159;&#23558;&#32463;&#20856;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;[Kakade&#65292;2001]&#19982;&#20048;&#35266;&#31574;&#30053;&#35780;&#20272;&#23376;&#31243;&#24207;&#31616;&#21333;&#32452;&#21512;&#20197;&#40723;&#21169;&#25506;&#32034;&#12290;&#23545;&#20110;$d$-&#32500;&#32447;&#24615;MDP&#65292;&#20048;&#35266;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#65292;&#24182;&#19988;&#22312;$\tilde{O}(d^2/\varepsilon^3)$ &#27425;&#37319;&#26679;&#20869;&#23398;&#20064; $\varepsilon$ -&#26368;&#20248;&#31574;&#30053;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#20855;&#26377;&#26368;&#20248;&#32500;&#24230;&#20381;&#36182;&#20851;&#31995;$\tilde {\Theta}(d^2)$&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#35745;&#31639;&#39640;&#25928;&#31639;&#27861;&#12290;&#23427;&#20063;&#36229;&#36234;&#20102;&#30446;&#21069;&#39046;&#20808;&#30340;&#19968;&#20123;&#29366;&#24577;of-the-art&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
While policy optimization algorithms have played an important role in recent empirical success of Reinforcement Learning (RL), the existing theoretical understanding of policy optimization remains rather limited -- they are either restricted to tabular MDPs or suffer from highly suboptimal sample complexity, especial in online RL where exploration is necessary. This paper proposes a simple efficient policy optimization framework -- Optimistic NPG for online RL. Optimistic NPG can be viewed as simply combining of the classic natural policy gradient (NPG) algorithm [Kakade, 2001] with optimistic policy evaluation subroutines to encourage exploration. For $d$-dimensional linear MDPs, Optimistic NPG is computationally efficient, and learns an $\varepsilon$-optimal policy within $\tilde{O}(d^2/\varepsilon^3)$ samples, which is the first computationally efficient algorithm whose sample complexity has the optimal dimension dependence $\tilde{\Theta}(d^2)$. It also improves over state-of-the-a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#38543;&#26426;&#22806;&#25512;&#25216;&#26415;&#65292;&#29992;&#20110;&#38477;&#20302;&#26465;&#20214;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#20013;&#30340;&#20559;&#24046;&#65292;&#24182;&#35777;&#26126;&#22312;&#38750;&#20984;&#20809;&#28369;&#30446;&#26631;&#20989;&#25968;&#20013;&#65292;&#23558;&#22806;&#25512;&#19982;&#26041;&#24046;&#32553;&#20943;&#25216;&#26415;&#30456;&#32467;&#21512;&#21487;&#20197;&#26174;&#33879;&#25913;&#21892;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2304.10613</link><description>&lt;p&gt;
&#28040;&#38500;&#26465;&#20214;&#38543;&#26426;&#20248;&#21270;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Debiasing Conditional Stochastic Optimization. (arXiv:2304.10613v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10613
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#38543;&#26426;&#22806;&#25512;&#25216;&#26415;&#65292;&#29992;&#20110;&#38477;&#20302;&#26465;&#20214;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#20013;&#30340;&#20559;&#24046;&#65292;&#24182;&#35777;&#26126;&#22312;&#38750;&#20984;&#20809;&#28369;&#30446;&#26631;&#20989;&#25968;&#20013;&#65292;&#23558;&#22806;&#25512;&#19982;&#26041;&#24046;&#32553;&#20943;&#25216;&#26415;&#30456;&#32467;&#21512;&#21487;&#20197;&#26174;&#33879;&#25913;&#21892;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35206;&#30422;&#20102;&#22810;&#20010;&#24212;&#29992;&#39046;&#22495;&#65292;&#21253;&#25324;&#25237;&#36164;&#32452;&#21512;&#36873;&#25321;&#12289;&#24378;&#21270;&#23398;&#20064;&#12289;&#40065;&#26834;&#23398;&#20064;&#12289;&#22240;&#26524;&#25512;&#26029;&#31561;&#30340;&#26465;&#20214;&#38543;&#26426;&#20248;&#21270;&#65288;CSO&#65289;&#38382;&#39064;&#12290;&#30001;&#20110;&#20854;&#23884;&#22871;&#32467;&#26500;&#65292;CSO&#30446;&#26631;&#30340;&#26679;&#26412;&#24179;&#22343;&#26799;&#24230;&#23384;&#22312;&#20559;&#24046;&#65292;&#22240;&#27492;&#38656;&#35201;&#36739;&#39640;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#25165;&#33021;&#36798;&#21040;&#25910;&#25947;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26377;&#25928;&#38477;&#20302;&#20559;&#24046;&#30340;&#36890;&#29992;&#38543;&#26426;&#22806;&#25512;&#25216;&#26415;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#38750;&#20984;&#20809;&#28369;&#30446;&#26631;&#20989;&#25968;&#20013;&#65292;&#23558;&#36825;&#31181;&#22806;&#25512;&#19982;&#26041;&#24046;&#32553;&#20943;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#36798;&#21040;&#27604;&#29616;&#26377;&#30028;&#38480;&#26356;&#22909;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#29992;&#20110;&#26377;&#38480;&#21644;&#21464;&#37327;&#30340;CSO&#30340;&#26032;&#31639;&#27861;&#65292;&#20063;&#26174;&#33879;&#25913;&#36827;&#20102;&#29616;&#26377;&#32467;&#26524;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35748;&#20026;&#25105;&#20204;&#30340;&#21435;&#20559;&#25216;&#26415;&#20063;&#21487;&#33021;&#26159;&#36866;&#29992;&#20110;&#20854;&#20182;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#30340;&#26377;&#36259;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the conditional stochastic optimization (CSO) problem which covers a variety of applications including portfolio selection, reinforcement learning, robust learning, causal inference, etc. The sample-averaged gradient of the CSO objective is biased due to its nested structure and therefore requires a high sample complexity to reach convergence. We introduce a general stochastic extrapolation technique that effectively reduces the bias. We show that for nonconvex smooth objectives, combining this extrapolation with variance reduction techniques can achieve a significantly better sample complexity than existing bounds. We also develop new algorithms for the finite-sum variant of CSO that also significantly improve upon existing results. Finally, we believe that our debiasing technique could be an interesting tool applicable to other stochastic optimization problems too.
&lt;/p&gt;</description></item><item><title>TiDE&#26159;&#19968;&#31181;&#22522;&#20110;MLP&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#65292;&#29992;&#20110;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#12290;&#23427;&#26082;&#20855;&#22791;&#32447;&#24615;&#27169;&#22411;&#30340;&#31616;&#21333;&#24615;&#21644;&#36895;&#24230;&#65292;&#21448;&#33021;&#22788;&#29702;&#21327;&#21464;&#37327;&#21644;&#38750;&#32447;&#24615;&#20381;&#36182;&#65292;&#30456;&#36739;&#20110;&#26368;&#20339;&#30340;Transformer&#27169;&#22411;&#65292;&#36895;&#24230;&#24555;5-10&#20493;&#12290;</title><link>http://arxiv.org/abs/2304.08424</link><description>&lt;p&gt;
&#29992;TiDE&#36827;&#34892;&#38271;&#26399;&#39044;&#27979;&#65306;&#26102;&#38388;&#24207;&#21015;&#31264;&#23494;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Long-term Forecasting with TiDE: Time-series Dense Encoder. (arXiv:2304.08424v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08424
&lt;/p&gt;
&lt;p&gt;
TiDE&#26159;&#19968;&#31181;&#22522;&#20110;MLP&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#65292;&#29992;&#20110;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#12290;&#23427;&#26082;&#20855;&#22791;&#32447;&#24615;&#27169;&#22411;&#30340;&#31616;&#21333;&#24615;&#21644;&#36895;&#24230;&#65292;&#21448;&#33021;&#22788;&#29702;&#21327;&#21464;&#37327;&#21644;&#38750;&#32447;&#24615;&#20381;&#36182;&#65292;&#30456;&#36739;&#20110;&#26368;&#20339;&#30340;Transformer&#27169;&#22411;&#65292;&#36895;&#24230;&#24555;5-10&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#30456;&#27604;&#20110;&#22522;&#20110;Transformer&#30340;&#26041;&#27861;&#65292;&#31616;&#21333;&#30340;&#32447;&#24615;&#27169;&#22411;&#22312;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#34920;&#29616;&#26356;&#22909;&#12290;&#37492;&#20110;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#23618;&#24863;&#30693;&#26426;(MLP)&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#65292;&#21363;&#26102;&#38388;&#24207;&#21015;&#31264;&#23494;&#32534;&#30721;&#22120;(TiDE)&#65292;&#29992;&#20110;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#12290;&#23427;&#26082;&#20139;&#26377;&#32447;&#24615;&#27169;&#22411;&#30340;&#31616;&#21333;&#24615;&#21644;&#36895;&#24230;&#65292;&#21448;&#33021;&#22788;&#29702;&#21327;&#21464;&#37327;&#21644;&#38750;&#32447;&#24615;&#20381;&#36182;&#12290;&#20174;&#29702;&#35770;&#19978;&#35762;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#27169;&#22411;&#30340;&#26368;&#31616;&#32447;&#24615;&#31867;&#27604;&#22312;&#19968;&#20123;&#20551;&#35774;&#19979;&#21487;&#20197;&#36798;&#21040;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;(LDS)&#30340;&#36817;&#20046;&#26368;&#20248;&#35823;&#24046;&#29575;&#12290;&#23454;&#35777;&#19978;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#22312;&#27969;&#34892;&#30340;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#22522;&#20934;&#27979;&#35797;&#20013;&#21305;&#37197;&#25110;&#32988;&#36807;&#20197;&#21069;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#27604;&#26368;&#20339;&#30340;&#22522;&#20110;Transformer&#30340;&#27169;&#22411;&#24555;5-10&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work has shown that simple linear models can outperform several Transformer based approaches in long term time-series forecasting. Motivated by this, we propose a Multi-layer Perceptron (MLP) based encoder-decoder model, Time-series Dense Encoder (TiDE), for long-term time-series forecasting that enjoys the simplicity and speed of linear models while also being able to handle covariates and non-linear dependencies. Theoretically, we prove that the simplest linear analogue of our model can achieve near optimal error rate for linear dynamical systems (LDS) under some assumptions. Empirically, we show that our method can match or outperform prior approaches on popular long-term time-series forecasting benchmarks while being 5-10x faster than the best Transformer based model.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#29289;&#29702;&#23398;&#30693;&#35782;&#25351;&#23548;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#26041;&#27861;&#65292;&#35299;&#20915;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#27714;&#35299;&#22120;&#26080;&#27861;&#37327;&#21270;&#36817;&#20284;&#35823;&#24046;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2212.12474</link><description>&lt;p&gt;
&#29289;&#29702;&#23398;&#30693;&#35782;&#25351;&#23548;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#24212;&#29992;&#20110;&#35299;&#20915;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;
&lt;/p&gt;
&lt;p&gt;
Physics-Informed Gaussian Process Regression Generalizes Linear PDE Solvers. (arXiv:2212.12474v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.12474
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#29289;&#29702;&#23398;&#30693;&#35782;&#25351;&#23548;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#26041;&#27861;&#65292;&#35299;&#20915;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#27714;&#35299;&#22120;&#26080;&#27861;&#37327;&#21270;&#36817;&#20284;&#35823;&#24046;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#26159;&#19968;&#31867;&#37325;&#35201;&#19988;&#24191;&#27867;&#24212;&#29992;&#30340;&#26426;&#26800;&#27169;&#22411;&#65292;&#25551;&#36848;&#20102;&#29289;&#29702;&#36807;&#31243;&#65292;&#20363;&#22914;&#28909;&#20256;&#23548;&#12289;&#30005;&#30913;&#23398;&#21644;&#27874;&#20256;&#25773;&#31561;&#12290;&#23454;&#36341;&#20013;&#65292;&#36890;&#24120;&#20351;&#29992;&#22522;&#20110;&#31163;&#25955;&#21270;&#30340;&#19987;&#38376;&#25968;&#20540;&#26041;&#27861;&#26469;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#36825;&#20123;&#27714;&#35299;&#22120;&#36890;&#24120;&#20351;&#29992;&#26410;&#30693;&#27169;&#22411;&#21442;&#25968;&#30340;&#20272;&#35745;&#20540;&#20197;&#21450;&#22914;&#26524;&#21487;&#29992;&#30340;&#35805;&#65292;&#29289;&#29702;&#27979;&#37327;&#20540;&#29992;&#20110;&#21021;&#22987;&#21270;&#12290;&#36825;&#20123;&#27714;&#35299;&#22120;&#32463;&#24120;&#23884;&#20837;&#21040;&#20855;&#26377;&#19979;&#28216;&#24212;&#29992;&#30340;&#26356;&#22823;&#30340;&#31185;&#23398;&#27169;&#22411;&#20013;&#65292;&#22240;&#27492;&#35823;&#24046;&#37327;&#21270;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#32463;&#20856;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#27714;&#35299;&#22120;&#24573;&#30053;&#21442;&#25968;&#21644;&#27979;&#37327;&#19981;&#30830;&#23450;&#24615;&#65292;&#21487;&#33021;&#26080;&#27861;&#20135;&#29983;&#19968;&#33268;&#24615;&#30340;&#20272;&#35745;&#20540;&#65292;&#20197;&#29992;&#20110;&#35745;&#31639;&#20854;&#22266;&#26377;&#30340;&#36924;&#36817;&#35823;&#24046;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;&#27714;&#35299;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#35299;&#37322;&#20026;&#29289;&#29702;&#23398;&#30693;&#35782;&#25351;&#23548;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#25512;&#29702;&#23450;&#29702;&#30340;&#19968;&#20010;&#20851;&#38190;&#25512;&#24191;&#65292;&#35813;&#23450;&#29702;&#36866;&#29992;&#20110;&#36890;&#36807;&#20219;&#24847;&#30028;&#38754;&#36827;&#34892;&#35266;&#23519;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Linear partial differential equations (PDEs) are an important, widely applied class of mechanistic models, describing physical processes such as heat transfer, electromagnetism, and wave propagation. In practice, specialized numerical methods based on discretization are used to solve PDEs. They generally use an estimate of the unknown model parameters and, if available, physical measurements for initialization. Such solvers are often embedded into larger scientific models with a downstream application and thus error quantification plays a key role. However, by ignoring parameter and measurement uncertainty, classical PDE solvers may fail to produce consistent estimates of their inherent approximation error. In this work, we approach this problem in a principled fashion by interpreting solving linear PDEs as physics-informed Gaussian process (GP) regression. Our framework is based on a key generalization of the Gaussian process inference theorem to observations made via an arbitrary bou
&lt;/p&gt;</description></item></channel></rss>