<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#33021;&#22815;&#35780;&#20272;&#38750;&#31169;&#23494;&#25968;&#25454;&#30456;&#20851;&#39044;&#22788;&#29702;&#31639;&#27861;&#24341;&#36215;&#30340;&#39069;&#22806;&#38544;&#31169;&#25104;&#26412;&#65292;&#24182;&#21033;&#29992;&#24179;&#28369;DP&#21644;&#39044;&#22788;&#29702;&#31639;&#27861;&#30340;&#26377;&#30028;&#25935;&#24863;&#24615;&#24314;&#31435;&#25972;&#20307;&#38544;&#31169;&#20445;&#35777;&#30340;&#19978;&#38480;</title><link>https://arxiv.org/abs/2403.13041</link><description>&lt;p&gt;
&#20855;&#26377;&#38750;&#31169;&#23494;&#39044;&#22788;&#29702;&#30340;&#21487;&#35777;&#26126;&#38544;&#31169;
&lt;/p&gt;
&lt;p&gt;
Provable Privacy with Non-Private Pre-Processing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13041
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#33021;&#22815;&#35780;&#20272;&#38750;&#31169;&#23494;&#25968;&#25454;&#30456;&#20851;&#39044;&#22788;&#29702;&#31639;&#27861;&#24341;&#36215;&#30340;&#39069;&#22806;&#38544;&#31169;&#25104;&#26412;&#65292;&#24182;&#21033;&#29992;&#24179;&#28369;DP&#21644;&#39044;&#22788;&#29702;&#31639;&#27861;&#30340;&#26377;&#30028;&#25935;&#24863;&#24615;&#24314;&#31435;&#25972;&#20307;&#38544;&#31169;&#20445;&#35777;&#30340;&#19978;&#38480;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20998;&#26512;&#24046;&#20998;&#31169;&#23494;&#65288;DP&#65289;&#26426;&#22120;&#23398;&#20064;&#31649;&#36947;&#26102;&#65292;&#36890;&#24120;&#20250;&#24573;&#30053;&#25968;&#25454;&#30456;&#20851;&#30340;&#39044;&#22788;&#29702;&#30340;&#28508;&#22312;&#38544;&#31169;&#25104;&#26412;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;&#30001;&#38750;&#31169;&#23494;&#25968;&#25454;&#30456;&#20851;&#39044;&#22788;&#29702;&#31639;&#27861;&#24341;&#36215;&#30340;&#39069;&#22806;&#38544;&#31169;&#25104;&#26412;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#36890;&#36807;&#21033;&#29992;&#20004;&#20010;&#26032;&#30340;&#25216;&#26415;&#27010;&#24565;&#24314;&#31435;&#20102;&#25972;&#20307;&#38544;&#31169;&#20445;&#35777;&#30340;&#19978;&#38480;&#65306;&#19968;&#31181;&#31216;&#20026;&#24179;&#28369;DP&#30340;DP&#21464;&#20307;&#20197;&#21450;&#39044;&#22788;&#29702;&#31639;&#27861;&#30340;&#26377;&#30028;&#25935;&#24863;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13041v1 Announce Type: cross  Abstract: When analysing Differentially Private (DP) machine learning pipelines, the potential privacy cost of data-dependent pre-processing is frequently overlooked in privacy accounting. In this work, we propose a general framework to evaluate the additional privacy cost incurred by non-private data-dependent pre-processing algorithms. Our framework establishes upper bounds on the overall privacy guarantees by utilising two new technical notions: a variant of DP termed Smooth DP and the bounded sensitivity of the pre-processing algorithms. In addition to the generic framework, we provide explicit overall privacy guarantees for multiple data-dependent pre-processing algorithms, such as data imputation, quantization, deduplication and PCA, when used in combination with several DP algorithms. Notably, this framework is also simple to implement, allowing direct integration into existing DP pipelines.
&lt;/p&gt;</description></item><item><title>&#35777;&#26126;&#20102;&#31890;&#23376;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#23545;&#20110;&#19968;&#33324;&#21270;&#30340;log-Sobolev&#21644;Polyak-Lojasiewicz&#19981;&#31561;&#24335;&#27169;&#22411;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#20197;&#21450;&#25512;&#24191;&#20102;Bakry-Emery&#23450;&#29702;&#12290;</title><link>https://arxiv.org/abs/2403.02004</link><description>&lt;p&gt;
&#31890;&#23376;&#26799;&#24230;&#19979;&#38477;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#20197;&#21450;log-Sobolev&#21644;Talagrand&#19981;&#31561;&#24335;&#30340;&#25512;&#24191;
&lt;/p&gt;
&lt;p&gt;
Error bounds for particle gradient descent, and extensions of the log-Sobolev and Talagrand inequalities
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02004
&lt;/p&gt;
&lt;p&gt;
&#35777;&#26126;&#20102;&#31890;&#23376;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#23545;&#20110;&#19968;&#33324;&#21270;&#30340;log-Sobolev&#21644;Polyak-Lojasiewicz&#19981;&#31561;&#24335;&#27169;&#22411;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#20197;&#21450;&#25512;&#24191;&#20102;Bakry-Emery&#23450;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;&#31890;&#23376;&#26799;&#24230;&#19979;&#38477;(PGD)~(Kuntz&#31561;&#20154;&#65292;2023)&#30340;&#38750;&#28176;&#36817;&#35823;&#24046;&#30028;&#38480;&#65292;&#36825;&#26159;&#19968;&#31181;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#31163;&#25955;&#21270;&#33258;&#30001;&#33021;&#26799;&#24230;&#27969;&#33719;&#24471;&#30340;&#22823;&#22411;&#28508;&#21464;&#37327;&#27169;&#22411;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#23545;&#20110;&#28385;&#36275;&#19968;&#33324;&#21270;log-Sobolev&#21644;Polyak-Lojasiewicz&#19981;&#31561;&#24335;&#65288;LSI&#21644;PLI&#65289;&#30340;&#27169;&#22411;&#65292;&#27969;&#20197;&#25351;&#25968;&#36895;&#24230;&#25910;&#25947;&#21040;&#33258;&#30001;&#33021;&#30340;&#26497;&#23567;&#21270;&#38598;&#21512;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#26368;&#20248;&#36755;&#36816;&#25991;&#29486;&#20013;&#20247;&#25152;&#21608;&#30693;&#30340;&#32467;&#26524;&#65288;LSI&#24847;&#21619;&#30528;Talagrand&#19981;&#31561;&#24335;&#65289;&#21450;&#20854;&#22312;&#20248;&#21270;&#25991;&#29486;&#20013;&#30340;&#23545;&#24212;&#29289;&#65288;PLI&#24847;&#21619;&#30528;&#25152;&#35859;&#30340;&#20108;&#27425;&#22686;&#38271;&#26465;&#20214;&#65289;&#25193;&#23637;&#24182;&#24212;&#29992;&#21040;&#25105;&#20204;&#30340;&#26032;&#35774;&#32622;&#65292;&#26469;&#23454;&#29616;&#36825;&#19968;&#28857;&#12290;&#25105;&#20204;&#36824;&#25512;&#24191;&#20102;Bakry-Emery&#23450;&#29702;&#65292;&#24182;&#23637;&#31034;&#20102;&#23545;&#20110;&#20855;&#26377;&#24378;&#20985;&#23545;&#25968;&#20284;&#28982;&#30340;&#27169;&#22411;&#65292;LSI/PLI&#30340;&#27010;&#25324;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02004v1 Announce Type: new  Abstract: We prove non-asymptotic error bounds for particle gradient descent (PGD)~(Kuntz et al., 2023), a recently introduced algorithm for maximum likelihood estimation of large latent variable models obtained by discretizing a gradient flow of the free energy. We begin by showing that, for models satisfying a condition generalizing both the log-Sobolev and the Polyak--{\L}ojasiewicz inequalities (LSI and P{\L}I, respectively), the flow converges exponentially fast to the set of minimizers of the free energy. We achieve this by extending a result well-known in the optimal transport literature (that the LSI implies the Talagrand inequality) and its counterpart in the optimization literature (that the P{\L}I implies the so-called quadratic growth condition), and applying it to our new setting. We also generalize the Bakry--\'Emery Theorem and show that the LSI/P{\L}I generalization holds for models with strongly concave log-likelihoods. For such m
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35299;&#20915;&#20102;&#22312;&#39532;&#23572;&#21487;&#22827;&#25104;&#26412;&#36807;&#31243;&#20013;&#20272;&#35745;&#26080;&#38480;&#26102;&#38388;&#25240;&#29616;&#25104;&#26412;&#30340;VaR&#21644;CVaR&#30340;&#38382;&#39064;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#20272;&#35745;&#35823;&#24046;&#30340;&#26368;&#23567;&#26368;&#22823;&#19979;&#30028;&#65292;&#24182;&#20351;&#29992;&#26377;&#38480;&#26102;&#38388;&#25130;&#26029;&#26041;&#26696;&#24471;&#20986;&#20102;&#19978;&#30028;&#12290;&#36825;&#26159;&#22312;&#39532;&#23572;&#21487;&#22827;&#35774;&#32622;&#20013;&#39318;&#27425;&#25552;&#20379;&#20219;&#20309;&#39118;&#38505;&#24230;&#37327;&#20272;&#35745;&#35823;&#24046;&#30340;&#19979;&#30028;&#21644;&#19978;&#30028;&#30340;&#24037;&#20316;&#12290;</title><link>http://arxiv.org/abs/2310.11389</link><description>&lt;p&gt;
&#22312;&#39532;&#23572;&#21487;&#22827;&#25104;&#26412;&#36807;&#31243;&#20013;&#30340;VaR&#21644;CVaR&#20272;&#35745;&#65306;&#19979;&#30028;&#21644;&#19978;&#30028;
&lt;/p&gt;
&lt;p&gt;
VaR\ and CVaR Estimation in a Markov Cost Process: Lower and Upper Bounds. (arXiv:2310.11389v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11389
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35299;&#20915;&#20102;&#22312;&#39532;&#23572;&#21487;&#22827;&#25104;&#26412;&#36807;&#31243;&#20013;&#20272;&#35745;&#26080;&#38480;&#26102;&#38388;&#25240;&#29616;&#25104;&#26412;&#30340;VaR&#21644;CVaR&#30340;&#38382;&#39064;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#20272;&#35745;&#35823;&#24046;&#30340;&#26368;&#23567;&#26368;&#22823;&#19979;&#30028;&#65292;&#24182;&#20351;&#29992;&#26377;&#38480;&#26102;&#38388;&#25130;&#26029;&#26041;&#26696;&#24471;&#20986;&#20102;&#19978;&#30028;&#12290;&#36825;&#26159;&#22312;&#39532;&#23572;&#21487;&#22827;&#35774;&#32622;&#20013;&#39318;&#27425;&#25552;&#20379;&#20219;&#20309;&#39118;&#38505;&#24230;&#37327;&#20272;&#35745;&#35823;&#24046;&#30340;&#19979;&#30028;&#21644;&#19978;&#30028;&#30340;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35299;&#20915;&#20102;&#22312;&#39532;&#23572;&#21487;&#22827;&#25104;&#26412;&#36807;&#31243;&#20013;&#20272;&#35745;&#26080;&#38480;&#26102;&#38388;&#25240;&#29616;&#25104;&#26412;&#30340;&#39118;&#38505;&#20215;&#20540;&#65288;Value-at-Risk&#65292;VaR&#65289;&#21644;&#26465;&#20214;&#39118;&#38505;&#20215;&#20540;&#65288;Conditional Value-at-Risk&#65292;CVaR&#65289;&#30340;&#38382;&#39064;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#19968;&#20010;&#26368;&#23567;&#26368;&#22823;&#19979;&#30028;&#65292;&#35813;&#19979;&#30028;&#22312;&#26399;&#26395;&#24847;&#20041;&#21644;&#27010;&#29575;&#24847;&#20041;&#19979;&#37117;&#25104;&#31435;&#65292;&#20854;&#35823;&#24046;&#30028;&#20026;$\Omega(1/\sqrt{n})$&#12290;&#28982;&#21518;&#65292;&#21033;&#29992;&#26377;&#38480;&#26102;&#38388;&#25130;&#26029;&#26041;&#26696;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;CVaR&#20272;&#35745;&#35823;&#24046;&#30340;&#19978;&#30028;&#65292;&#35813;&#19978;&#30028;&#19982;&#25105;&#20204;&#30340;&#19979;&#30028;&#21305;&#37197;&#65292;&#21482;&#26377;&#24120;&#25968;&#22240;&#23376;&#30340;&#24046;&#24322;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#25105;&#20204;&#30340;&#20272;&#35745;&#26041;&#26696;&#30340;&#25193;&#23637;&#65292;&#28085;&#30422;&#20102;&#26356;&#36890;&#29992;&#30340;&#28385;&#36275;&#19968;&#23450;&#36830;&#32493;&#24615;&#20934;&#21017;&#30340;&#39118;&#38505;&#24230;&#37327;&#65292;&#20363;&#22914;&#35889;&#39118;&#38505;&#24230;&#37327;&#21644;&#22522;&#20110;&#25928;&#29992;&#30340;&#32570;&#21475;&#39118;&#38505;&#24230;&#37327;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#26159;&#31532;&#19968;&#20010;&#22312;&#39532;&#23572;&#21487;&#22827;&#35774;&#32622;&#20013;&#20026;&#20219;&#20309;&#39118;&#38505;&#24230;&#37327;&#25552;&#20379;&#20272;&#35745;&#35823;&#24046;&#30340;&#19979;&#30028;&#21644;&#19978;&#30028;&#30340;&#24037;&#20316;&#12290;&#25105;&#20204;&#25351;&#20986;&#65292;&#25105;&#20204;&#30340;&#19979;&#30028;&#20063;&#21487;&#25193;&#23637;&#21040;&#26080;&#38480;&#26102;&#38388;&#25240;&#29616;&#25104;&#26412;&#30340;&#22343;&#20540;&#12290;&#21363;&#20351;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;$\Omega(1/\sqrt{n})$&#20063;&#20248;&#20110;&#29616;&#26377;&#32467;&#26524;$\Omega(
&lt;/p&gt;
&lt;p&gt;
We tackle the problem of estimating the Value-at-Risk (VaR) and the Conditional Value-at-Risk (CVaR) of the infinite-horizon discounted cost within a Markov cost process. First, we derive a minimax lower bound of $\Omega(1/\sqrt{n})$ that holds both in an expected and in a probabilistic sense. Then, using a finite-horizon truncation scheme, we derive an upper bound for the error in CVaR estimation, which matches our lower bound up to constant factors. Finally, we discuss an extension of our estimation scheme that covers more general risk measures satisfying a certain continuity criterion, e.g., spectral risk measures, utility-based shortfall risk. To the best of our knowledge, our work is the first to provide lower and upper bounds on the estimation error for any risk measure within Markovian settings. We remark that our lower bounds also extend to the infinite-horizon discounted costs' mean. Even in that case, our result $\Omega(1/\sqrt{n}) $ improves upon the existing result $\Omega(
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#21457;&#29616;&#27934;&#23519;&#29616;&#35937;&#21487;&#33021;&#26159;&#30001;&#31070;&#32463;&#32593;&#32476;&#20174;&#25042;&#24816;&#35757;&#32451;&#21160;&#24577;&#36807;&#28193;&#21040;&#20016;&#23500;&#30340;&#29305;&#24449;&#23398;&#20064;&#27169;&#24335;&#30340;&#32467;&#26524;&#65292;&#36890;&#36807;&#36319;&#36394;&#36275;&#22815;&#30340;&#32479;&#35745;&#37327;&#65292;&#21457;&#29616;&#27934;&#23519;&#26159;&#22312;&#32593;&#32476;&#39318;&#20808;&#23581;&#35797;&#25311;&#21512;&#26680;&#22238;&#24402;&#35299;&#20915;&#26041;&#26696;&#21518;&#65292;&#36827;&#34892;&#21518;&#26399;&#29305;&#24449;&#23398;&#20064;&#25214;&#21040;&#36890;&#29992;&#35299;&#20915;&#26041;&#26696;&#20043;&#21518;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.06110</link><description>&lt;p&gt;
&#20174;&#25042;&#24816;&#21040;&#20016;&#23500;&#35757;&#32451;&#21160;&#24577;&#30340;&#27934;&#23519;&#21147;
&lt;/p&gt;
&lt;p&gt;
Grokking as the Transition from Lazy to Rich Training Dynamics. (arXiv:2310.06110v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06110
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#27934;&#23519;&#29616;&#35937;&#21487;&#33021;&#26159;&#30001;&#31070;&#32463;&#32593;&#32476;&#20174;&#25042;&#24816;&#35757;&#32451;&#21160;&#24577;&#36807;&#28193;&#21040;&#20016;&#23500;&#30340;&#29305;&#24449;&#23398;&#20064;&#27169;&#24335;&#30340;&#32467;&#26524;&#65292;&#36890;&#36807;&#36319;&#36394;&#36275;&#22815;&#30340;&#32479;&#35745;&#37327;&#65292;&#21457;&#29616;&#27934;&#23519;&#26159;&#22312;&#32593;&#32476;&#39318;&#20808;&#23581;&#35797;&#25311;&#21512;&#26680;&#22238;&#24402;&#35299;&#20915;&#26041;&#26696;&#21518;&#65292;&#36827;&#34892;&#21518;&#26399;&#29305;&#24449;&#23398;&#20064;&#25214;&#21040;&#36890;&#29992;&#35299;&#20915;&#26041;&#26696;&#20043;&#21518;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#27934;&#23519;&#29616;&#35937;&#65292;&#21363;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#25439;&#22833;&#22312;&#27979;&#35797;&#25439;&#22833;&#20043;&#21069;&#22823;&#24133;&#19979;&#38477;&#65292;&#21487;&#33021;&#26159;&#30001;&#20110;&#31070;&#32463;&#32593;&#32476;&#20174;&#25042;&#24816;&#30340;&#35757;&#32451;&#21160;&#24577;&#36716;&#21464;&#20026;&#20016;&#23500;&#30340;&#29305;&#24449;&#23398;&#20064;&#27169;&#24335;&#12290;&#20026;&#20102;&#35828;&#26126;&#36825;&#19968;&#26426;&#21046;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#27809;&#26377;&#27491;&#21017;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;Vanilla&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#22312;&#22810;&#39033;&#24335;&#22238;&#24402;&#38382;&#39064;&#19978;&#36827;&#34892;&#30340;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#65292;&#35813;&#35757;&#32451;&#23637;&#29616;&#20102;&#26080;&#27861;&#29992;&#29616;&#26377;&#29702;&#35770;&#35299;&#37322;&#30340;&#27934;&#23519;&#29616;&#35937;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#35813;&#32593;&#32476;&#27979;&#35797;&#25439;&#22833;&#30340;&#36275;&#22815;&#32479;&#35745;&#37327;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#36319;&#36394;&#36825;&#20123;&#32479;&#35745;&#37327;&#25581;&#31034;&#20102;&#27934;&#23519;&#29616;&#35937;&#30340;&#21457;&#29983;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#32593;&#32476;&#39318;&#20808;&#23581;&#35797;&#20351;&#29992;&#21021;&#22987;&#29305;&#24449;&#25311;&#21512;&#26680;&#22238;&#24402;&#35299;&#20915;&#26041;&#26696;&#65292;&#25509;&#30528;&#22312;&#35757;&#32451;&#25439;&#22833;&#24050;&#32463;&#24456;&#20302;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#21518;&#26399;&#29305;&#24449;&#23398;&#20064;&#65292;&#20174;&#32780;&#25214;&#21040;&#20102;&#19968;&#20010;&#33021;&#22815;&#27867;&#21270;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#27934;&#23519;&#20135;&#29983;&#30340;&#20851;&#38190;&#22240;&#32032;&#26159;&#29305;&#24449;&#23398;&#20064;&#30340;&#36895;&#29575;&#65292;&#36825;&#21487;&#20197;&#36890;&#36807;&#32553;&#25918;&#32593;&#32476;&#21442;&#25968;&#26469;&#31934;&#30830;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose that the grokking phenomenon, where the train loss of a neural network decreases much earlier than its test loss, can arise due to a neural network transitioning from lazy training dynamics to a rich, feature learning regime. To illustrate this mechanism, we study the simple setting of vanilla gradient descent on a polynomial regression problem with a two layer neural network which exhibits grokking without regularization in a way that cannot be explained by existing theories. We identify sufficient statistics for the test loss of such a network, and tracking these over training reveals that grokking arises in this setting when the network first attempts to fit a kernel regression solution with its initial features, followed by late-time feature learning where a generalizing solution is identified after train loss is already low. We find that the key determinants of grokking are the rate of feature learning -- which can be controlled precisely by parameters that scale the ne
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#31070;&#32463;&#24076;&#23572;&#20271;&#29305;&#38454;&#26799;(NHL)&#30340;&#27010;&#24565;&#65292;&#23427;&#23558;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#25551;&#36848;&#20026;&#19968;&#31995;&#21015;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65292;&#36827;&#19968;&#27493;&#25512;&#24191;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#29702;&#35770;&#30740;&#31350;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#22312;&#20989;&#25968;&#31354;&#38388;&#20869;&#30340;&#24615;&#36136;&#21644;&#24212;&#29992;&#12290;&#36890;&#36807;&#35777;&#26126;&#19981;&#21516;&#23618;&#27425;&#30340;NHL&#19982;&#22810;&#23618;NNs&#20043;&#38388;&#30340;&#23545;&#24212;&#20851;&#31995;&#65292;&#35777;&#26126;&#20102;&#23398;&#20064;NHL&#30340;&#27867;&#21270;&#20445;&#35777;&#65292;&#24182;&#25552;&#20986;&#20102;NHL&#30340;&#29305;&#24449;&#21160;&#21147;&#23398;&#27169;&#22411;&#12290;&#26368;&#21518;&#65292;&#22312;ReLU&#21644;&#20108;&#27425;&#28608;&#27963;&#20989;&#25968;&#19979;&#23637;&#31034;&#20102;NHLs&#20013;&#30340;&#28145;&#24230;&#20998;&#31163;&#29616;&#35937;&#12290;</title><link>http://arxiv.org/abs/2307.01177</link><description>&lt;p&gt;
&#31070;&#32463;&#24076;&#23572;&#20271;&#29305;&#38454;&#26799;&#65306;&#20989;&#25968;&#31354;&#38388;&#20013;&#30340;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Neural Hilbert Ladders: Multi-Layer Neural Networks in Function Space. (arXiv:2307.01177v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01177
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#31070;&#32463;&#24076;&#23572;&#20271;&#29305;&#38454;&#26799;(NHL)&#30340;&#27010;&#24565;&#65292;&#23427;&#23558;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#25551;&#36848;&#20026;&#19968;&#31995;&#21015;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65292;&#36827;&#19968;&#27493;&#25512;&#24191;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#29702;&#35770;&#30740;&#31350;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#22312;&#20989;&#25968;&#31354;&#38388;&#20869;&#30340;&#24615;&#36136;&#21644;&#24212;&#29992;&#12290;&#36890;&#36807;&#35777;&#26126;&#19981;&#21516;&#23618;&#27425;&#30340;NHL&#19982;&#22810;&#23618;NNs&#20043;&#38388;&#30340;&#23545;&#24212;&#20851;&#31995;&#65292;&#35777;&#26126;&#20102;&#23398;&#20064;NHL&#30340;&#27867;&#21270;&#20445;&#35777;&#65292;&#24182;&#25552;&#20986;&#20102;NHL&#30340;&#29305;&#24449;&#21160;&#21147;&#23398;&#27169;&#22411;&#12290;&#26368;&#21518;&#65292;&#22312;ReLU&#21644;&#20108;&#27425;&#28608;&#27963;&#20989;&#25968;&#19979;&#23637;&#31034;&#20102;NHLs&#20013;&#30340;&#28145;&#24230;&#20998;&#31163;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;(NNs)&#25152;&#25506;&#32034;&#30340;&#20989;&#25968;&#31354;&#38388;&#30340;&#29305;&#24449;&#21270;&#26159;&#28145;&#24230;&#23398;&#20064;&#29702;&#35770;&#30340;&#37325;&#35201;&#26041;&#38754;&#12290;&#26412;&#25991;&#23558;&#20855;&#26377;&#20219;&#24847;&#23485;&#24230;&#30340;&#22810;&#23618;NN&#35270;&#20026;&#23450;&#20041;&#29305;&#23450;&#23618;&#27425;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;(RKHS)&#30340;&#31070;&#32463;&#24076;&#23572;&#20271;&#29305;&#38454;&#26799;(NHL)&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#23450;&#20041;&#19968;&#20010;&#20989;&#25968;&#31354;&#38388;&#21644;&#19968;&#20010;&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#35813;&#24230;&#37327;&#25512;&#24191;&#20102;&#27973;&#23618;NNs&#30340;&#20808;&#21069;&#32467;&#26524;&#65292;&#24182;&#30740;&#31350;&#20102;&#23427;&#20204;&#22312;&#20960;&#20010;&#26041;&#38754;&#30340;&#29702;&#35770;&#29305;&#24615;&#21644;&#24433;&#21709;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;L&#23618;NNs&#34920;&#31034;&#30340;&#20989;&#25968;&#19982;&#23646;&#20110;L&#23618;NHLs&#30340;&#20989;&#25968;&#20043;&#38388;&#30340;&#23545;&#24212;&#20851;&#31995;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23398;&#20064;&#20855;&#26377;&#21463;&#25511;&#22797;&#26434;&#24230;&#24230;&#37327;&#30340;NHL&#30340;&#27867;&#21270;&#20445;&#35777;&#12290;&#31532;&#19977;&#65292;&#23545;&#24212;&#20110;&#22312;&#26080;&#31351;&#23485;&#22343;&#22330;&#26497;&#38480;&#19979;&#35757;&#32451;&#22810;&#23618;NNs&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;NHL&#30340;&#29305;&#24449;&#21160;&#21147;&#23398;&#65292;&#35813;&#21160;&#21147;&#23398;&#34987;&#25551;&#36848;&#20026;&#22810;&#20010;&#38543;&#26426;&#22330;&#30340;&#28436;&#21270;&#12290;&#31532;&#22235;&#65292;&#22312;ReLU&#21644;&#20108;&#27425;&#28608;&#27963;&#20989;&#25968;&#19979;&#23637;&#31034;&#20102;NHLs&#20013;&#30340;&#28145;&#24230;&#20998;&#31163;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
The characterization of the functions spaces explored by neural networks (NNs) is an important aspect of deep learning theory. In this work, we view a multi-layer NN with arbitrary width as defining a particular hierarchy of reproducing kernel Hilbert spaces (RKHSs), named a Neural Hilbert Ladder (NHL). This allows us to define a function space and a complexity measure that generalize prior results for shallow NNs, and we then examine their theoretical properties and implications in several aspects. First, we prove a correspondence between functions expressed by L-layer NNs and those belonging to L-level NHLs. Second, we prove generalization guarantees for learning an NHL with the complexity measure controlled. Third, corresponding to the training of multi-layer NNs in the infinite-width mean-field limit, we derive an evolution of the NHL characterized as the dynamics of multiple random fields. Fourth, we show examples of depth separation in NHLs under ReLU and quadratic activation fun
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#39318;&#27425;&#30740;&#31350;&#20102;&#20174;&#39640;&#32500;&#39640;&#26031;&#28151;&#21512;&#22359;&#27169;&#22411;&#20013;&#25277;&#26679;&#30340;&#22270;&#32858;&#31867;&#21644;&#23884;&#20837;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.00979</link><description>&lt;p&gt;
&#39640;&#26031;&#28151;&#21512;&#22359;&#27169;&#22411;&#20013;&#30340;&#35889;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Spectral clustering in the Gaussian mixture block model. (arXiv:2305.00979v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00979
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#30740;&#31350;&#20102;&#20174;&#39640;&#32500;&#39640;&#26031;&#28151;&#21512;&#22359;&#27169;&#22411;&#20013;&#25277;&#26679;&#30340;&#22270;&#32858;&#31867;&#21644;&#23884;&#20837;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#28151;&#21512;&#22359;&#27169;&#22411;&#26159;&#29992;&#20110;&#27169;&#25311;&#29616;&#20195;&#32593;&#32476;&#30340;&#22270;&#20998;&#24067;&#65306;&#23545;&#20110;&#36825;&#26679;&#30340;&#27169;&#22411;&#29983;&#25104;&#19968;&#20010;&#22270;&#65292;&#25105;&#20204;&#23558;&#27599;&#20010;&#39030;&#28857; $i$ &#19982;&#19968;&#20010;&#20174;&#39640;&#26031;&#28151;&#21512;&#20013;&#25277;&#26679;&#21040;&#30340;&#28508;&#22312;&#29305;&#24449;&#21521;&#37327; $u_i \in \mathbb{R}^d$ &#30456;&#20851;&#32852;&#65292;&#24403;&#19988;&#20165;&#24403;&#29305;&#24449;&#21521;&#37327;&#36275;&#22815;&#30456;&#20284;&#65292;&#21363; $\langle u_i,u_j \rangle \ge \tau$ &#26102;&#65292;&#25105;&#20204;&#25165;&#20250;&#28155;&#21152;&#36793; $(i,j)$&#12290;&#39640;&#26031;&#28151;&#21512;&#30340;&#19981;&#21516;&#32452;&#25104;&#37096;&#20998;&#34920;&#31034;&#21487;&#33021;&#20855;&#26377;&#19981;&#21516;&#29305;&#24449;&#20998;&#24067;&#30340;&#19981;&#21516;&#31867;&#22411;&#30340;&#33410;&#28857;&#65292;&#20363;&#22914;&#22312;&#31038;&#20132;&#32593;&#32476;&#20013;&#65292;&#27599;&#20010;&#32452;&#25104;&#37096;&#20998;&#37117;&#34920;&#31034;&#29420;&#29305;&#31038;&#21306;&#30340;&#19981;&#21516;&#23646;&#24615;&#12290;&#36825;&#20123;&#32593;&#32476;&#28041;&#21450;&#21040;&#30340;&#33258;&#28982;&#31639;&#27861;&#20219;&#21153;&#26377;&#23884;&#20837;&#65288;&#24674;&#22797;&#28508;&#22312;&#30340;&#29305;&#24449;&#21521;&#37327;&#65289;&#21644;&#32858;&#31867;&#65288;&#36890;&#36807;&#20854;&#28151;&#21512;&#32452;&#20998;&#23558;&#33410;&#28857;&#20998;&#32452;&#65289;&#12290;&#26412;&#25991;&#24320;&#21551;&#20102;&#23545;&#20174;&#39640;&#32500;&#39640;&#26031;&#28151;&#21512;&#22359;&#27169;&#22411;&#25277;&#26679;&#30340;&#22270;&#36827;&#34892;&#32858;&#31867;&#21644;&#23884;&#20837;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian mixture block models are distributions over graphs that strive to model modern networks: to generate a graph from such a model, we associate each vertex $i$ with a latent feature vector $u_i \in \mathbb{R}^d$ sampled from a mixture of Gaussians, and we add edge $(i,j)$ if and only if the feature vectors are sufficiently similar, in that $\langle u_i,u_j \rangle \ge \tau$ for a pre-specified threshold $\tau$. The different components of the Gaussian mixture represent the fact that there may be different types of nodes with different distributions over features -- for example, in a social network each component represents the different attributes of a distinct community. Natural algorithmic tasks associated with these networks are embedding (recovering the latent feature vectors) and clustering (grouping nodes by their mixture component).  In this paper we initiate the study of clustering and embedding graphs sampled from high-dimensional Gaussian mixture block models, where the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;Rashomon&#30340;&#22235;&#37325;&#22863;&#65292;&#36825;&#26159;&#19968;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#26469;&#33258;&#19981;&#21516;&#31867;&#21035;&#30340;&#22235;&#20010;&#27169;&#22411;&#20855;&#26377;&#20960;&#20046;&#30456;&#21516;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#21516;&#26102;&#20854;&#21487;&#35270;&#21270;&#25581;&#31034;&#20102;&#26497;&#20854;&#19981;&#21516;&#30340;&#26041;&#27861;&#26469;&#29702;&#35299;&#25968;&#25454;&#20013;&#30340;&#30456;&#20851;&#24615;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2302.13356</link><description>&lt;p&gt;
&#34920;&#29616;&#19981;&#36275;&#20197;&#20026;&#30408;&#65292;&#28145;&#31350;Rashomon&#30340;&#22235;&#37325;&#22863;
&lt;/p&gt;
&lt;p&gt;
Performance is not enough: a story of the Rashomon's quartet. (arXiv:2302.13356v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.13356
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;Rashomon&#30340;&#22235;&#37325;&#22863;&#65292;&#36825;&#26159;&#19968;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#26469;&#33258;&#19981;&#21516;&#31867;&#21035;&#30340;&#22235;&#20010;&#27169;&#22411;&#20855;&#26377;&#20960;&#20046;&#30456;&#21516;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#21516;&#26102;&#20854;&#21487;&#35270;&#21270;&#25581;&#31034;&#20102;&#26497;&#20854;&#19981;&#21516;&#30340;&#26041;&#27861;&#26469;&#29702;&#35299;&#25968;&#25454;&#20013;&#30340;&#30456;&#20851;&#24615;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#24314;&#27169;&#36890;&#24120;&#34987;&#31616;&#21270;&#20026;&#23547;&#25214;&#26368;&#20248;&#27169;&#22411;&#26469;&#20248;&#21270;&#36873;&#23450;&#30340;&#24615;&#33021;&#24230;&#37327;&#12290;&#20294;&#22914;&#26524;&#31532;&#20108;&#20248;&#27169;&#22411;&#33021;&#22815;&#20197;&#23436;&#20840;&#19981;&#21516;&#30340;&#26041;&#24335;&#21516;&#26679;&#25551;&#36848;&#25968;&#25454;&#21602;&#65311;&#31532;&#19977;&#20010;&#27169;&#22411;&#21602;&#65311;&#26368;&#26377;&#25928;&#30340;&#27169;&#22411;&#20250;&#23398;&#21040;&#23436;&#20840;&#19981;&#21516;&#30340;&#25968;&#25454;&#20851;&#31995;&#21527;&#65311;&#21463;&#21040;Anscombe&#22235;&#37325;&#22863;&#30340;&#21551;&#21457;&#65292;&#26412;&#25991;&#20171;&#32461;&#20102;Rashomon&#30340;&#22235;&#37325;&#22863;&#65292;&#36825;&#26159;&#19968;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#26469;&#33258;&#19981;&#21516;&#31867;&#21035;&#30340;&#22235;&#20010;&#27169;&#22411;&#20855;&#26377;&#20960;&#20046;&#30456;&#21516;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#21487;&#35270;&#21270;&#25581;&#31034;&#20102;&#26497;&#20854;&#19981;&#21516;&#30340;&#26041;&#27861;&#26469;&#29702;&#35299;&#25968;&#25454;&#20013;&#30340;&#30456;&#20851;&#24615;&#32467;&#26500;&#12290;&#24341;&#20837;&#30340;&#31616;&#21333;&#31034;&#20363;&#26088;&#22312;&#36827;&#19968;&#27493;&#20419;&#36827;&#21487;&#35270;&#21270;&#20316;&#20026;&#27604;&#36739;&#39044;&#27979;&#27169;&#22411;&#36229;&#36234;&#24615;&#33021;&#30340;&#24517;&#35201;&#24037;&#20855;&#12290;&#25105;&#20204;&#38656;&#35201;&#24320;&#21457;&#23500;&#26377;&#27934;&#23519;&#21147;&#30340;&#25216;&#26415;&#26469;&#35299;&#37322;&#27169;&#22411;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Predictive modelling is often reduced to finding the best model that optimizes a selected performance measure. But what if the second-best model describes the data equally well but in a completely different way? What about the third? Is it possible that the most effective models learn completely different relationships in the data? Inspired by Anscombe's quartet, this paper introduces Rashomon's quartet, a synthetic dataset for which four models from different classes have practically identical predictive performance. However, their visualization reveals drastically distinct ways of understanding the correlation structure in data. The introduced simple illustrative example aims to further facilitate visualization as a mandatory tool to compare predictive models beyond their performance. We need to develop insightful techniques for the explanatory analysis of model sets.
&lt;/p&gt;</description></item></channel></rss>