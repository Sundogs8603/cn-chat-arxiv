<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20048;&#39640;&#31215;&#26408;&#65292;&#36890;&#36807;&#38598;&#25104;&#23616;&#37096;&#29305;&#24449;&#20016;&#23500;&#21644;&#20840;&#23616;&#20869;&#23481;&#21327;&#35843;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#19988;&#21487;&#33258;&#36866;&#24212;&#30340;&#36845;&#20195;&#32454;&#21270;&#25193;&#25955;&#24314;&#27169;&#12290;&#36825;&#20123;&#31215;&#26408;&#21487;&#20197;&#22534;&#21472;&#22312;&#19968;&#36215;&#65292;&#29992;&#20110;&#22312;&#27979;&#35797;&#26102;&#26681;&#25454;&#38656;&#35201;&#36827;&#34892;&#37325;&#26500;&#65292;&#20174;&#32780;&#20943;&#23569;&#37319;&#26679;&#25104;&#26412;&#24182;&#29983;&#25104;&#39640;&#20998;&#36776;&#29575;&#22270;&#20687;&#12290;</title><link>http://arxiv.org/abs/2310.06389</link><description>&lt;p&gt;
&#23398;&#20064;&#21487;&#22534;&#21472;&#21644;&#21487;&#36339;&#36807;&#30340;&#20048;&#39640;&#31215;&#26408;&#20197;&#23454;&#29616;&#39640;&#25928;&#12289;&#21487;&#37325;&#26500;&#21644;&#21487;&#21464;&#20998;&#36776;&#29575;&#30340;&#25193;&#25955;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Learning Stackable and Skippable LEGO Bricks for Efficient, Reconfigurable, and Variable-Resolution Diffusion Modeling. (arXiv:2310.06389v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06389
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20048;&#39640;&#31215;&#26408;&#65292;&#36890;&#36807;&#38598;&#25104;&#23616;&#37096;&#29305;&#24449;&#20016;&#23500;&#21644;&#20840;&#23616;&#20869;&#23481;&#21327;&#35843;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#19988;&#21487;&#33258;&#36866;&#24212;&#30340;&#36845;&#20195;&#32454;&#21270;&#25193;&#25955;&#24314;&#27169;&#12290;&#36825;&#20123;&#31215;&#26408;&#21487;&#20197;&#22534;&#21472;&#22312;&#19968;&#36215;&#65292;&#29992;&#20110;&#22312;&#27979;&#35797;&#26102;&#26681;&#25454;&#38656;&#35201;&#36827;&#34892;&#37325;&#26500;&#65292;&#20174;&#32780;&#20943;&#23569;&#37319;&#26679;&#25104;&#26412;&#24182;&#29983;&#25104;&#39640;&#20998;&#36776;&#29575;&#22270;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#22312;&#29983;&#25104;&#30495;&#23454;&#24863;&#22270;&#20687;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#35757;&#32451;&#21644;&#37319;&#26679;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;&#23613;&#31649;&#26377;&#21508;&#31181;&#25216;&#26415;&#26469;&#35299;&#20915;&#36825;&#20123;&#35745;&#31639;&#25361;&#25112;&#65292;&#20294;&#19968;&#20010;&#36739;&#23569;&#25506;&#32034;&#30340;&#38382;&#39064;&#26159;&#35774;&#35745;&#19968;&#20010;&#39640;&#25928;&#19988;&#36866;&#24212;&#24615;&#24378;&#30340;&#32593;&#32476;&#39592;&#24178;&#65292;&#29992;&#20110;&#36845;&#20195;&#32454;&#21270;&#12290;&#24403;&#21069;&#30340;&#36873;&#39033;&#22914;U-Net&#21644;Vision Transformer&#36890;&#24120;&#20381;&#36182;&#20110;&#36164;&#28304;&#23494;&#38598;&#22411;&#30340;&#28145;&#24230;&#32593;&#32476;&#65292;&#32570;&#20047;&#22312;&#21464;&#37327;&#20998;&#36776;&#29575;&#19979;&#29983;&#25104;&#22270;&#20687;&#25110;&#20351;&#29992;&#27604;&#35757;&#32451;&#20013;&#26356;&#23567;&#30340;&#32593;&#32476;&#25152;&#38656;&#30340;&#28789;&#27963;&#24615;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#20048;&#39640;&#31215;&#26408;&#65292;&#23427;&#20204;&#26080;&#32541;&#38598;&#25104;&#20102;&#23616;&#37096;&#29305;&#24449;&#20016;&#23500;&#21644;&#20840;&#23616;&#20869;&#23481;&#21327;&#35843;&#12290;&#36825;&#20123;&#31215;&#26408;&#21487;&#20197;&#22534;&#21472;&#22312;&#19968;&#36215;&#65292;&#21019;&#24314;&#19968;&#20010;&#27979;&#35797;&#26102;&#21487;&#37325;&#26500;&#30340;&#25193;&#25955;&#39592;&#24178;&#65292;&#20801;&#35768;&#36873;&#25321;&#24615;&#36339;&#36807;&#31215;&#26408;&#20197;&#20943;&#23569;&#37319;&#26679;&#25104;&#26412;&#65292;&#24182;&#29983;&#25104;&#27604;&#35757;&#32451;&#25968;&#25454;&#26356;&#39640;&#20998;&#36776;&#29575;&#30340;&#22270;&#20687;&#12290;&#20048;&#39640;&#31215;&#26408;&#36890;&#36807;MLP&#23545;&#23616;&#37096;&#21306;&#22495;&#36827;&#34892;&#20016;&#23500;&#65292;&#24182;&#20351;&#29992;Transformer&#22359;&#36827;&#34892;&#21464;&#25442;&#65292;&#21516;&#26102;&#20445;&#25345;&#19968;&#33268;&#30340;&#20840;&#20998;&#36776;&#29575;
&lt;/p&gt;
&lt;p&gt;
Diffusion models excel at generating photo-realistic images but come with significant computational costs in both training and sampling. While various techniques address these computational challenges, a less-explored issue is designing an efficient and adaptable network backbone for iterative refinement. Current options like U-Net and Vision Transformer often rely on resource-intensive deep networks and lack the flexibility needed for generating images at variable resolutions or with a smaller network than used in training. This study introduces LEGO bricks, which seamlessly integrate Local-feature Enrichment and Global-content Orchestration. These bricks can be stacked to create a test-time reconfigurable diffusion backbone, allowing selective skipping of bricks to reduce sampling costs and generate higher-resolution images than the training data. LEGO bricks enrich local regions with an MLP and transform them using a Transformer block while maintaining a consistent full-resolution i
&lt;/p&gt;</description></item><item><title>SmoothLLM&#26159;&#31532;&#19968;&#20010;&#29992;&#20110;&#20943;&#36731;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19978;&#36234;&#29425;&#25915;&#20987;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#36755;&#20837;&#25552;&#31034;&#19978;&#38543;&#26426;&#25200;&#21160;&#24182;&#27719;&#24635;&#39044;&#27979;&#32467;&#26524;&#26469;&#26816;&#27979;&#23545;&#25239;&#24615;&#36755;&#20837;&#65292;&#23558;&#25915;&#20987;&#25104;&#21151;&#29575;&#38477;&#20302;&#33267;&#19981;&#21040;&#19968;&#20010;&#30334;&#20998;&#28857;&#65292;&#24182;&#25552;&#20379;&#20102;&#21487;&#35777;&#26126;&#30340;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2310.03684</link><description>&lt;p&gt;
SmoothLLM&#65306;&#38450;&#24481;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20813;&#21463;&#36234;&#29425;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks. (arXiv:2310.03684v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03684
&lt;/p&gt;
&lt;p&gt;
SmoothLLM&#26159;&#31532;&#19968;&#20010;&#29992;&#20110;&#20943;&#36731;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19978;&#36234;&#29425;&#25915;&#20987;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#36755;&#20837;&#25552;&#31034;&#19978;&#38543;&#26426;&#25200;&#21160;&#24182;&#27719;&#24635;&#39044;&#27979;&#32467;&#26524;&#26469;&#26816;&#27979;&#23545;&#25239;&#24615;&#36755;&#20837;&#65292;&#23558;&#25915;&#20987;&#25104;&#21151;&#29575;&#38477;&#20302;&#33267;&#19981;&#21040;&#19968;&#20010;&#30334;&#20998;&#28857;&#65292;&#24182;&#25552;&#20379;&#20102;&#21487;&#35777;&#26126;&#30340;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#21162;&#21147;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#19982;&#20154;&#31867;&#20215;&#20540;&#35266;&#20445;&#25345;&#19968;&#33268;&#65292;&#20294;&#24191;&#27867;&#20351;&#29992;&#30340;LLM&#65288;&#22914;GPT&#12289;Llama&#12289;Claude&#21644;PaLM&#65289;&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#36234;&#29425;&#25915;&#20987;&#65292;&#21363;&#23545;&#30446;&#26631;LLM&#36827;&#34892;&#27450;&#39575;&#65292;&#20197;&#29983;&#25104;&#19981;&#21512;&#36866;&#30340;&#20869;&#23481;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#28431;&#27934;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;SmoothLLM&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#26088;&#22312;&#20943;&#36731;LLM&#19978;&#30340;&#36234;&#29425;&#25915;&#20987;&#30340;&#31639;&#27861;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;&#21457;&#29616;&#65292;&#23545;&#25239;&#24615;&#29983;&#25104;&#30340;&#25552;&#31034;&#23545;&#23383;&#31526;&#32423;&#21035;&#30340;&#25913;&#21464;&#24456;&#33030;&#24369;&#65292;&#25105;&#20204;&#30340;&#38450;&#24481;&#39318;&#20808;&#38543;&#26426;&#25200;&#21160;&#32473;&#23450;&#36755;&#20837;&#25552;&#31034;&#30340;&#22810;&#20010;&#21103;&#26412;&#65292;&#28982;&#21518;&#27719;&#24635;&#30456;&#24212;&#30340;&#39044;&#27979;&#32467;&#26524;&#26469;&#26816;&#27979;&#23545;&#25239;&#24615;&#36755;&#20837;&#12290;SmoothLLM&#23558;&#20247;&#22810;&#28909;&#38376;LLM&#30340;&#25915;&#20987;&#25104;&#21151;&#29575;&#38477;&#20302;&#33267;&#19981;&#21040;&#19968;&#20010;&#30334;&#20998;&#28857;&#65292;&#36991;&#20813;&#20102;&#19981;&#24517;&#35201;&#30340;&#20445;&#23432;&#24615;&#65292;&#24182;&#23545;&#25915;&#20987;&#32531;&#35299;&#25552;&#20379;&#20102;&#21487;&#35777;&#26126;&#30340;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#38450;&#24481;&#20351;&#29992;&#30340;&#26597;&#35810;&#25968;&#37327;&#27604;&#29616;&#26377;&#30340;&#25915;&#20987;&#26041;&#27861;&#23569;&#24471;&#22810;&#65292;&#24182;&#19988;&#19982;&#20219;&#20309;LLM&#20860;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite efforts to align large language models (LLMs) with human values, widely-used LLMs such as GPT, Llama, Claude, and PaLM are susceptible to jailbreaking attacks, wherein an adversary fools a targeted LLM into generating objectionable content. To address this vulnerability, we propose SmoothLLM, the first algorithm designed to mitigate jailbreaking attacks on LLMs. Based on our finding that adversarially-generated prompts are brittle to character-level changes, our defense first randomly perturbs multiple copies of a given input prompt, and then aggregates the corresponding predictions to detect adversarial inputs. SmoothLLM reduces the attack success rate on numerous popular LLMs to below one percentage point, avoids unnecessary conservatism, and admits provable guarantees on attack mitigation. Moreover, our defense uses exponentially fewer queries than existing attacks and is compatible with any LLM.
&lt;/p&gt;</description></item><item><title>CoLA&#26159;&#19968;&#20010;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#20013;&#22823;&#35268;&#27169;&#32447;&#24615;&#20195;&#25968;&#38382;&#39064;&#30340;&#31616;&#21333;&#20294;&#36890;&#29992;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#32452;&#21512;&#35843;&#24230;&#35268;&#21017;&#21644;&#32447;&#24615;&#25805;&#20316;&#31526;&#25277;&#35937;&#65292;&#33258;&#21160;&#26500;&#24314;&#20102;&#20869;&#23384;&#21644;&#36816;&#34892;&#26102;&#39640;&#25928;&#30340;&#25968;&#20540;&#31639;&#27861;&#65292;&#25552;&#20379;&#20102;&#20869;&#23384;&#39640;&#25928;&#30340;&#33258;&#21160;&#24494;&#20998;&#12289;&#20302;&#31934;&#24230;&#35745;&#31639;&#21644;GPU&#21152;&#36895;&#65292;&#21516;&#26102;&#21487;&#20197;&#36866;&#24212;&#19979;&#28216;&#36719;&#20214;&#21253;&#20013;&#30340;&#26032;&#23545;&#35937;&#12289;&#25805;&#20316;&#21644;&#35268;&#21017;&#12290;</title><link>http://arxiv.org/abs/2309.03060</link><description>&lt;p&gt;
CoLA: &#28145;&#20837;&#21033;&#29992;&#32452;&#21512;&#32467;&#26500;&#23454;&#29616;&#33258;&#21160;&#21644;&#39640;&#25928;&#30340;&#25968;&#20540;&#32447;&#24615;&#20195;&#25968;
&lt;/p&gt;
&lt;p&gt;
CoLA: Exploiting Compositional Structure for Automatic and Efficient Numerical Linear Algebra. (arXiv:2309.03060v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03060
&lt;/p&gt;
&lt;p&gt;
CoLA&#26159;&#19968;&#20010;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#20013;&#22823;&#35268;&#27169;&#32447;&#24615;&#20195;&#25968;&#38382;&#39064;&#30340;&#31616;&#21333;&#20294;&#36890;&#29992;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#32452;&#21512;&#35843;&#24230;&#35268;&#21017;&#21644;&#32447;&#24615;&#25805;&#20316;&#31526;&#25277;&#35937;&#65292;&#33258;&#21160;&#26500;&#24314;&#20102;&#20869;&#23384;&#21644;&#36816;&#34892;&#26102;&#39640;&#25928;&#30340;&#25968;&#20540;&#31639;&#27861;&#65292;&#25552;&#20379;&#20102;&#20869;&#23384;&#39640;&#25928;&#30340;&#33258;&#21160;&#24494;&#20998;&#12289;&#20302;&#31934;&#24230;&#35745;&#31639;&#21644;GPU&#21152;&#36895;&#65292;&#21516;&#26102;&#21487;&#20197;&#36866;&#24212;&#19979;&#28216;&#36719;&#20214;&#21253;&#20013;&#30340;&#26032;&#23545;&#35937;&#12289;&#25805;&#20316;&#21644;&#35268;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#21644;&#31185;&#23398;&#39046;&#22495;&#28041;&#21450;&#21040;&#22823;&#35268;&#27169;&#30340;&#32447;&#24615;&#20195;&#25968;&#38382;&#39064;&#65292;&#22914;&#29305;&#24449;&#20998;&#35299;&#12289;&#35299;&#32447;&#24615;&#31995;&#32479;&#12289;&#35745;&#31639;&#30697;&#38453;&#25351;&#25968;&#21644;&#36857;&#20272;&#35745;&#31561;&#12290;&#28041;&#21450;&#30340;&#30697;&#38453;&#36890;&#24120;&#20855;&#26377;Krondor&#12289;&#21367;&#31215;&#12289;&#22359;&#23545;&#35282;&#12289;&#27714;&#21644;&#25110;&#20056;&#31215;&#31561;&#32467;&#26500;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#20294;&#36890;&#29992;&#30340;&#26426;&#22120;&#23398;&#20064;&#22823;&#35268;&#27169;&#32447;&#24615;&#20195;&#25968;&#38382;&#39064;&#30340;&#26694;&#26550;&#65292;&#21517;&#20026;CoLA&#65288;&#32452;&#21512;&#32447;&#24615;&#20195;&#25968;&#65289;&#12290;&#36890;&#36807;&#23558;&#32447;&#24615;&#25805;&#20316;&#31526;&#25277;&#35937;&#19982;&#32452;&#21512;&#35843;&#24230;&#35268;&#21017;&#30456;&#32467;&#21512;&#65292;CoLA&#33021;&#22815;&#33258;&#21160;&#26500;&#24314;&#20869;&#23384;&#21644;&#36816;&#34892;&#26102;&#39640;&#25928;&#30340;&#25968;&#20540;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;CoLA&#36824;&#25552;&#20379;&#20869;&#23384;&#39640;&#25928;&#30340;&#33258;&#21160;&#24494;&#20998;&#12289;&#20302;&#31934;&#24230;&#35745;&#31639;&#21644;JAX&#21644;PyTorch&#20013;&#30340;GPU&#21152;&#36895;&#65292;&#21516;&#26102;&#36824;&#33021;&#22815;&#36890;&#36807;&#22810;&#37325;&#35843;&#24230;&#36866;&#24212;&#19979;&#28216;&#36719;&#20214;&#21253;&#20013;&#30340;&#26032;&#23545;&#35937;&#12289;&#25805;&#20316;&#21644;&#35268;&#21017;&#12290;CoLA&#21487;&#20197;&#21152;&#36895;&#35768;&#22810;&#20195;&#25968;&#25805;&#20316;&#65292;&#21516;&#26102;&#20063;&#20415;&#20110;&#21407;&#22411;&#21270;&#30697;&#38453;&#32467;&#26500;&#21644;&#31639;&#27861;&#65292;&#25552;&#20379;&#20102;&#21487;&#34892;&#24615;&#30340;&#38477;&#20302;-
&lt;/p&gt;
&lt;p&gt;
Many areas of machine learning and science involve large linear algebra problems, such as eigendecompositions, solving linear systems, computing matrix exponentials, and trace estimation. The matrices involved often have Kronecker, convolutional, block diagonal, sum, or product structure. In this paper, we propose a simple but general framework for large-scale linear algebra problems in machine learning, named CoLA (Compositional Linear Algebra). By combining a linear operator abstraction with compositional dispatch rules, CoLA automatically constructs memory and runtime efficient numerical algorithms. Moreover, CoLA provides memory efficient automatic differentiation, low precision computation, and GPU acceleration in both JAX and PyTorch, while also accommodating new objects, operations, and rules in downstream packages via multiple dispatch. CoLA can accelerate many algebraic operations, while making it easy to prototype matrix structures and algorithms, providing an appealing drop-
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#20855;&#26377;&#34987;&#31713;&#25913;&#30340;&#20108;&#36827;&#21046;&#20449;&#21495;&#30340;Lipschitz&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#33104;&#36133;&#40065;&#26834;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#22312;&#19981;&#21516;&#25439;&#22833;&#20989;&#25968;&#19979;&#23454;&#29616;&#20102;&#19981;&#21516;&#31243;&#24230;&#30340;&#21518;&#24724;&#12290;</title><link>http://arxiv.org/abs/2307.13903</link><description>&lt;p&gt;
&#33104;&#36133;&#40065;&#26834;&#30340;Lipschitz&#19978;&#19979;&#25991;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
Corruption-Robust Lipschitz Contextual Search. (arXiv:2307.13903v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13903
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#20855;&#26377;&#34987;&#31713;&#25913;&#30340;&#20108;&#36827;&#21046;&#20449;&#21495;&#30340;Lipschitz&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#33104;&#36133;&#40065;&#26834;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#22312;&#19981;&#21516;&#25439;&#22833;&#20989;&#25968;&#19979;&#23454;&#29616;&#20102;&#19981;&#21516;&#31243;&#24230;&#30340;&#21518;&#24724;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#30740;&#31350;&#20102;&#23398;&#20064;&#20855;&#26377;&#34987;&#31713;&#25913;&#30340;&#20108;&#36827;&#21046;&#20449;&#21495;&#30340;Lipschitz&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;&#23398;&#20064;&#32773;&#35797;&#22270;&#23398;&#20064;&#19968;&#20010;&#30001;&#23545;&#25163;&#36873;&#25321;&#30340;Lipschitz&#20989;&#25968;$f$&#12290;&#22312;&#27599;&#19968;&#36718;&#20013;&#65292;&#23545;&#25163;&#22312;&#36755;&#20837;&#31354;&#38388;&#20013;&#36873;&#25321;&#19968;&#20010;&#19978;&#19979;&#25991;&#21521;&#37327;$x_t$&#65292;&#23398;&#20064;&#32773;&#23545;&#30495;&#23454;&#20989;&#25968;&#20540;$f(x_t)$&#36827;&#34892;&#29468;&#27979;&#65292;&#24182;&#25509;&#25910;&#19968;&#20010;&#25351;&#31034;&#29468;&#27979;&#26159;&#39640;&#36824;&#26159;&#20302;&#30340;&#20108;&#36827;&#21046;&#20449;&#21495;&#12290;&#22312;&#24635;&#20849;$C$&#36718;&#20013;&#65292;&#20449;&#21495;&#21487;&#33021;&#34987;&#31713;&#25913;&#65292;&#20294;&#23398;&#20064;&#32773;&#19981;&#30693;&#36947;$C$&#30340;&#20540;&#12290;&#23398;&#20064;&#32773;&#30340;&#30446;&#26631;&#26159;&#36896;&#25104;&#23567;&#30340;&#32047;&#31215;&#25439;&#22833;&#12290;&#25105;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#28982;&#32780;&#24378;&#22823;&#30340;&#25216;&#26415;&#39564;&#35777;&#65292;&#23545;&#35774;&#35745;&#33104;&#36133;&#40065;&#26834;&#31639;&#27861;&#38750;&#24120;&#26377;&#29992;&#12290;&#25105;&#35774;&#35745;&#20102;&#19968;&#20123;&#31639;&#27861;&#65288;&#23558;Lipschitz&#21442;&#25968;$L$&#35270;&#20026;&#24120;&#25968;&#65289;&#65306;&#23545;&#20110;&#23545;&#31216;&#25439;&#22833;&#65292;&#23398;&#20064;&#32773;&#22312;$d=1$&#26102;&#36798;&#21040;&#21518;&#24724;$O(C\log T)$&#65292;&#22312;$d&gt;1$&#26102;&#36798;&#21040;&#21518;&#24724;$O_d(C\log T + T^{(d-1)/d})$&#65307;&#23545;&#20110;&#35745;&#20215;&#25439;&#22833;&#65292;&#23398;&#20064;&#32773;&#22312;$d/(d+1)$&#26102;&#36798;&#21040;&#21518;&#24724;$\widetilde{O}(T^{d/(d+1)} + C\cdot T^{1/(d+1)})$&#12290;
&lt;/p&gt;
&lt;p&gt;
I study the problem of learning a Lipschitz function with corrupted binary signals. The learner tries to learn a Lipschitz function $f$ that the adversary chooses. In each round, the adversary selects a context vector $x_t$ in the input space, and the learner makes a guess to the true function value $f(x_t)$ and receives a binary signal indicating whether the guess was high or low. In a total of $C$ rounds, the signal may be corrupted, though the value of $C$ is unknown to the learner. The learner's goal is to incur a small cumulative loss. I present a natural yet powerful technique sanity check, which proves useful in designing corruption-robust algorithms. I design algorithms which (treating the Lipschitz parameter $L$ as constant): for the symmetric loss, the learner achieves regret $O(C\log T)$ with $d = 1$ and $O_d(C\log T + T^{(d-1)/d})$ with $d &gt; 1$; for the pricing loss the learner achieves regret $\widetilde{O} (T^{d/(d+1)} + C\cdot T^{1/(d+1)})$.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#39640;&#32500;&#35266;&#27979;&#30740;&#31350;&#30340;&#26041;&#27861;&#65292;&#23558;&#22240;&#26524;&#20272;&#35745;&#27867;&#21270;&#21040;&#20219;&#24847;&#32500;&#24230;&#25110;&#21487;&#27979;&#31354;&#38388;&#30340;&#32467;&#26524;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#21517;&#20041;&#21464;&#37327;&#30340;&#22240;&#26524;&#20559;&#24046;&#27979;&#35797;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#30456;&#27604;&#29616;&#26377;&#31574;&#30053;&#22312;&#26377;&#38480;&#26679;&#26412;&#26377;&#25928;&#24615;&#21644;&#21151;&#29575;&#26041;&#38754;&#26377;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2307.13868</link><description>&lt;p&gt;
&#20174;&#39640;&#32500;&#35266;&#27979;&#30740;&#31350;&#20013;&#23398;&#20064;&#21464;&#24322;&#28304;
&lt;/p&gt;
&lt;p&gt;
Learning sources of variability from high-dimensional observational studies. (arXiv:2307.13868v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13868
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#39640;&#32500;&#35266;&#27979;&#30740;&#31350;&#30340;&#26041;&#27861;&#65292;&#23558;&#22240;&#26524;&#20272;&#35745;&#27867;&#21270;&#21040;&#20219;&#24847;&#32500;&#24230;&#25110;&#21487;&#27979;&#31354;&#38388;&#30340;&#32467;&#26524;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#21517;&#20041;&#21464;&#37327;&#30340;&#22240;&#26524;&#20559;&#24046;&#27979;&#35797;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#30456;&#27604;&#29616;&#26377;&#31574;&#30053;&#22312;&#26377;&#38480;&#26679;&#26412;&#26377;&#25928;&#24615;&#21644;&#21151;&#29575;&#26041;&#38754;&#26377;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#25512;&#26029;&#30740;&#31350;&#26159;&#21542;&#23384;&#22312;&#19968;&#20010;&#21464;&#37327;&#24433;&#21709;&#35266;&#27979;&#32467;&#26524;&#12290;&#36890;&#36807;&#35832;&#22914;&#8220;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#8221;&#31561;&#37327;&#21270;&#25351;&#26631;&#65292;&#36825;&#19968;&#33539;&#24335;&#22312;&#35768;&#22810;&#29983;&#29289;&#39046;&#22495;&#20013;&#34987;&#37319;&#29992;&#65292;&#20174;&#30123;&#33495;&#21644;&#33647;&#29289;&#24320;&#21457;&#21040;&#25919;&#31574;&#24178;&#39044;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#22823;&#22810;&#25968;&#26041;&#27861;&#36890;&#24120;&#20165;&#38480;&#20110;&#21333;&#21464;&#37327;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#23558;&#22240;&#26524;&#20272;&#35745;&#27867;&#21270;&#21040;&#20219;&#24847;&#32500;&#24230;&#25110;&#21487;&#27979;&#31354;&#38388;&#30340;&#32467;&#26524;&#65292;&#24182;&#23558;&#20256;&#32479;&#30340;&#22240;&#26524;&#20272;&#35745;&#24418;&#24335;&#21270;&#20026;&#21517;&#20041;&#21464;&#37327;&#30340;&#22240;&#26524;&#20559;&#24046;&#27979;&#35797;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#25216;&#26415;&#26469;&#35843;&#25972;&#19968;&#33268;&#24615;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20123;&#27979;&#35797;&#26159;&#19968;&#33268;&#24615;&#22240;&#26524;&#20559;&#24046;&#27979;&#35797;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#19982;&#29616;&#26377;&#31574;&#30053;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;Causal CDcorr&#22312;&#26377;&#38480;&#26679;&#26412;&#26377;&#25928;&#24615;&#21644;&#21151;&#29575;&#26041;&#38754;&#22343;&#26377;&#25913;&#36827;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#37117;&#26159;&#24320;&#28304;&#30340;&#65292;&#21487;&#22312;github.com/ebridge2/cdcorr&#19978;&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal inference studies whether the presence of a variable influences an observed outcome. As measured by quantities such as the "average treatment effect," this paradigm is employed across numerous biological fields, from vaccine and drug development to policy interventions. Unfortunately, the majority of these methods are often limited to univariate outcomes. Our work generalizes causal estimands to outcomes with any number of dimensions or any measurable space, and formulates traditional causal estimands for nominal variables as causal discrepancy tests. We propose a simple technique for adjusting universally consistent conditional independence tests and prove that these tests are universally consistent causal discrepancy tests. Numerical experiments illustrate that our method, Causal CDcorr, leads to improvements in both finite sample validity and power when compared to existing strategies. Our methods are all open source and available at github.com/ebridge2/cdcorr.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38754;&#21521;&#26041;&#21521;&#30340;&#22810;&#30446;&#26631;&#38382;&#39064;&#65292;&#24182;&#32473;&#20986;&#20102;&#20004;&#31181;&#38543;&#26426;&#31639;&#27861;&#20197;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#29702;&#35770;&#19978;&#25910;&#25947;&#21040;&#24085;&#32047;&#25176;&#31283;&#23450;&#28857;&#12290;</title><link>http://arxiv.org/abs/2305.18409</link><description>&lt;p&gt;
&#38754;&#21521;&#26041;&#21521;&#30340;&#22810;&#30446;&#26631;&#23398;&#20064;&#65306;&#31616;&#21333;&#19988;&#21487;&#35777;&#26126;&#30340;&#38543;&#26426;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Direction-oriented Multi-objective Learning: Simple and Provable Stochastic Algorithms. (arXiv:2305.18409v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18409
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38754;&#21521;&#26041;&#21521;&#30340;&#22810;&#30446;&#26631;&#38382;&#39064;&#65292;&#24182;&#32473;&#20986;&#20102;&#20004;&#31181;&#38543;&#26426;&#31639;&#27861;&#20197;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#29702;&#35770;&#19978;&#25910;&#25947;&#21040;&#24085;&#32047;&#25176;&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#30446;&#26631;&#20248;&#21270;&#65288;MOO&#65289;&#24050;&#25104;&#20026;&#35768;&#22810;&#19982;&#22810;&#20010;&#30446;&#26631;&#30456;&#20851;&#30340;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#65288;&#22914;&#22810;&#26631;&#20934;&#23398;&#20064;&#21644;&#22810;&#20219;&#21153;&#23398;&#20064;&#65288;MTL&#65289;&#65289;&#20013;&#19968;&#20010;&#26377;&#24433;&#21709;&#21147;&#30340;&#26694;&#26550;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38754;&#21521;&#26041;&#21521;&#30340;&#22810;&#30446;&#26631;&#38382;&#39064;&#65292;&#36890;&#36807;&#22312;&#19968;&#20010;&#26041;&#21521;&#30340;&#37051;&#22495;&#20869;&#38480;&#21046;&#20844;&#20849;&#19979;&#38477;&#26041;&#21521;&#26469;&#35268;&#33539;&#32447;&#24615;&#32452;&#21512;&#30446;&#26631;&#30340;&#26368;&#20248;&#26041;&#21521;&#65292;&#20363;&#22914;MTL&#20013;&#30340;&#24179;&#22343;&#25439;&#22833;&#12290; &#36825;&#20010;&#20844;&#24335;&#21253;&#25324;GD&#21644;MGDA&#20316;&#20026;&#29305;&#27530;&#24773;&#20917;&#65292;&#20139;&#21463;&#20687;CAGrad&#20013;&#30340;&#38754;&#21521;&#26041;&#21521;&#30340;&#22909;&#22788;&#65292;&#20197;&#21450;&#26377;&#21033;&#20110;&#38543;&#26426;&#31639;&#27861;&#30340;&#35774;&#35745;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#38543;&#26426;&#26041;&#21521;&#23548;&#21521;&#22810;&#30446;&#26631;&#26799;&#24230;&#19979;&#38477;&#65288;SDMGrad&#65289;&#65292;&#23427;&#20351;&#29992;&#31616;&#21333;&#30340;SGD&#31867;&#22411;&#30340;&#26356;&#26032;&#31639;&#27861;&#65292;&#20197;&#21450;&#22312;&#30446;&#26631;&#25968;&#37327;&#36739;&#22810;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#39640;&#25928;&#30340;&#30446;&#26631;&#37319;&#26679;&#30340;SDMGrad-OS&#31639;&#27861;&#12290; &#23545;&#20110;&#24658;&#23450;&#30340;&#27491;&#21017;&#21270;&#21442;&#25968;&#955;&#65292;&#25105;&#20204;&#35777;&#26126;SDMGrad&#21644;SDMGrad-OS&#30830;&#23454;&#25910;&#25947;&#21040;&#24085;&#32047;&#25176;&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-objective optimization (MOO) has become an influential framework in many machine learning problems with multiple objectives such as learning with multiple criteria and multi-task learning (MTL). In this paper, we propose a new direction-oriented multi-objective problem by regularizing the common descent direction within a neighborhood of a direction that optimizes a linear combination of objectives such as the average loss in MTL. This formulation includes GD and MGDA as special cases, enjoys the direction-oriented benefit as in CAGrad, and facilitates the design of stochastic algorithms. To solve this problem, we propose Stochastic Direction-oriented Multi-objective Gradient descent (SDMGrad) with simple SGD type of updates, and its variant SDMGrad-OS with an efficient objective sampling in the setting where the number of objectives is large. For a constant-level regularization parameter $\lambda$, we show that SDMGrad and SDMGrad-OS provably converge to a Pareto stationary poin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#21644;&#23454;&#29992;&#30340;&#26041;&#27861;{\sc LegendreTron}&#65292;&#29992;&#20110;&#32852;&#21512;&#23398;&#20064;&#22810;&#31867;&#21035;&#38382;&#39064;&#30340;&#27491;&#30830;&#26631;&#20934;&#25439;&#22833;&#21644;&#27010;&#29575;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#22522;&#20934;&#27979;&#35797;&#20013;&#32463;&#24120;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2301.11695</link><description>&lt;p&gt;
LegendreTron&#65306;&#21319;&#32423;&#29256;&#22810;&#31867;&#21035;&#27491;&#30830;&#22810;&#39033;&#25439;&#22833;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
LegendreTron: Uprising Proper Multiclass Loss Learning. (arXiv:2301.11695v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11695
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#21644;&#23454;&#29992;&#30340;&#26041;&#27861;{\sc LegendreTron}&#65292;&#29992;&#20110;&#32852;&#21512;&#23398;&#20064;&#22810;&#31867;&#21035;&#38382;&#39064;&#30340;&#27491;&#30830;&#26631;&#20934;&#25439;&#22833;&#21644;&#27010;&#29575;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#22522;&#20934;&#27979;&#35797;&#20013;&#32463;&#24120;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25439;&#22833;&#20989;&#25968;&#26159;&#30417;&#30563;&#23398;&#20064;&#30340;&#22522;&#30784;&#65292;&#36890;&#24120;&#22312;&#27169;&#22411;&#24320;&#21457;&#20043;&#21069;&#36873;&#25321;&#12290;&#20026;&#36991;&#20813;&#36873;&#25321;&#25439;&#22833;&#20989;&#25968;&#21487;&#33021;&#20986;&#29616;&#30340;&#29305;&#23450;&#36873;&#25321;&#65292;&#32479;&#35745;&#20915;&#31574;&#29702;&#35770;&#25551;&#36848;&#20102;&#25439;&#22833;&#30340;&#19968;&#31181;&#29702;&#24819;&#23646;&#24615;&#65292;&#31216;&#20026;&#8220;&#27491;&#30830;&#24615;&#8221;&#65292;&#23427;&#26029;&#35328;&#36125;&#21494;&#26031;&#35268;&#21017;&#26159;&#26368;&#20248;&#30340;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#23581;&#35797;&#32852;&#21512;&#23398;&#20064;&#25439;&#22833;&#21644;&#27169;&#22411;&#12290;&#29616;&#26377;&#26041;&#27861;&#36890;&#36807;&#25311;&#21512;&#19968;&#20010;&#23558;$\mathbb{R}$&#21333;&#35843;&#26144;&#23556;&#21040;$[0,1]$&#30340;&#21453;&#35299;&#26631;&#20934;&#38142;&#25509;&#20989;&#25968;&#26469;&#20272;&#35745;&#20108;&#20803;&#38382;&#39064;&#30340;&#27010;&#29575;&#12290;&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#20984;&#20989;&#25968;&#26799;&#24230;&#30340;&#21333;&#35843;&#24615;&#23558;&#21333;&#35843;&#24615;&#25193;&#23637;&#21040;$\mathbb{R}^{C-1}$&#21040;&#27010;&#29575;&#30340;&#27491;&#25237;&#24433;$\tilde{\Delta}^{C-1}$&#30340;&#26144;&#23556;&#19978;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#32780;&#23454;&#29992;&#30340;&#26041;&#27861;{\sc LegendreTron}&#65292;&#29992;&#20110;&#32852;&#21512;&#23398;&#20064;&#22810;&#31867;&#21035;&#38382;&#39064;&#30340;&#27491;&#30830;&#26631;&#20934;&#25439;&#22833;&#21644;&#27010;&#29575;&#12290;&#22312;&#26368;&#22810;1,000&#31181;&#31867;&#21035;&#30340;&#39046;&#22495;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22987;&#32456;&#20248;&#20110;&#20854;&#20182;&#22522;&#20934;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Loss functions serve as the foundation of supervised learning and are often chosen prior to model development. To avoid potentially ad hoc choices of losses, statistical decision theory describes a desirable property for losses known as \emph{properness}, which asserts that Bayes' rule is optimal. Recent works have sought to \emph{learn losses} and models jointly. Existing methods do this by fitting an inverse canonical link function which monotonically maps $\mathbb{R}$ to $[0,1]$ to estimate probabilities for binary problems. In this paper, we extend monotonicity to maps between $\mathbb{R}^{C-1}$ and the projected probability simplex $\tilde{\Delta}^{C-1}$ by using monotonicity of gradients of convex functions. We present {\sc LegendreTron} as a novel and practical method that jointly learns \emph{proper canonical losses} and probabilities for multiclass problems. Tested on a benchmark of domains with up to 1,000 classes, our experimental results show that our method consistently ou
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27979;&#35797;&#26102;&#26631;&#31614;&#36716;&#31227;&#26657;&#27491;&#26041;&#27861;&#65292;&#36890;&#36807;&#36866;&#24212;&#20998;&#24067;&#30340;&#21464;&#21270;&#26469;&#25552;&#21319;&#39044;&#27979;&#27169;&#22411;&#24615;&#33021;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22788;&#29702;&#31867;&#21035;&#26631;&#31614;&#21644;&#22122;&#22768;&#22240;&#32032;&#30340;&#20381;&#36182;&#20851;&#31995;&#38543;&#22495;&#21464;&#21270;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2211.15646</link><description>&lt;p&gt;
&#36229;&#36234;&#19981;&#21464;&#24615;&#65306;&#38024;&#23545;&#20855;&#26377;&#8220;&#34394;&#20551;&#8221;&#30456;&#20851;&#24615;&#30340;&#20998;&#24067;&#30340;&#27979;&#35797;&#26102;&#26631;&#31614;&#36716;&#31227;&#36866;&#24212;&#24615;
&lt;/p&gt;
&lt;p&gt;
Beyond Invariance: Test-Time Label-Shift Adaptation for Distributions with "Spurious" Correlations. (arXiv:2211.15646v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.15646
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27979;&#35797;&#26102;&#26631;&#31614;&#36716;&#31227;&#26657;&#27491;&#26041;&#27861;&#65292;&#36890;&#36807;&#36866;&#24212;&#20998;&#24067;&#30340;&#21464;&#21270;&#26469;&#25552;&#21319;&#39044;&#27979;&#27169;&#22411;&#24615;&#33021;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22788;&#29702;&#31867;&#21035;&#26631;&#31614;&#21644;&#22122;&#22768;&#22240;&#32032;&#30340;&#20381;&#36182;&#20851;&#31995;&#38543;&#22495;&#21464;&#21270;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27979;&#35797;&#26102;&#25968;&#25454;&#20998;&#24067;&#30340;&#21464;&#21270;&#21487;&#33021;&#23545;&#39044;&#27979;&#27169;&#22411;p(y|x)&#30340;&#24615;&#33021;&#20135;&#29983;&#19981;&#33391;&#24433;&#21709;&#12290;&#25105;&#20204;&#32771;&#34385;&#23384;&#22312;&#38468;&#21152;&#20803;&#25968;&#25454;&#26631;&#31614;&#65288;&#20363;&#22914;&#32452;&#26631;&#31614;&#65289;z&#30340;&#24773;&#20917;&#65292;&#35813;&#26631;&#31614;&#21487;&#20197;&#35828;&#26126;&#20998;&#24067;&#30340;&#21464;&#21270;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#20551;&#35774;&#25551;&#36848;&#31867;&#21035;&#26631;&#31614;y&#21644;&#8220;&#22122;&#22768;&#8221;&#22240;&#32032;z&#20043;&#38388;&#20381;&#36182;&#20851;&#31995;&#30340;&#20808;&#39564;&#20998;&#24067;p(y, z)&#21487;&#33021;&#20250;&#38543;&#30528;&#22495;&#30340;&#21464;&#21270;&#32780;&#25913;&#21464;&#65292;&#35201;&#20040;&#26159;&#30001;&#20110;&#36825;&#20123;&#39033;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#30340;&#21464;&#21270;&#65292;&#35201;&#20040;&#26159;&#30001;&#20110;&#20854;&#20013;&#19968;&#20010;&#21464;&#37327;&#30340;&#36793;&#38469;&#20998;&#24067;&#30340;&#21464;&#21270;&#12290;&#20294;&#26159;&#65292;&#25105;&#20204;&#20551;&#35774;&#29305;&#24449;&#30340;&#29983;&#25104;&#27169;&#22411;p(x|y, z)&#22312;&#22495;&#38388;&#26159;&#19981;&#21464;&#30340;&#12290;&#25105;&#20204;&#27880;&#24847;&#21040;&#36825;&#30456;&#24403;&#20110;&#24191;&#27867;&#20351;&#29992;&#30340;&#8220;&#26631;&#31614;&#36716;&#31227;&#8221;&#20551;&#35774;&#30340;&#25193;&#23637;&#29256;&#26412;&#65292;&#20854;&#20013;&#26631;&#31614;&#29616;&#22312;&#20063;&#21253;&#25324;&#22122;&#22768;&#22240;&#32032;z&#12290;&#22522;&#20110;&#27492;&#35266;&#23519;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#27979;&#35797;&#26102;&#26631;&#31614;&#36716;&#31227;&#26657;&#27491;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#26410;&#26631;&#35760;&#26679;&#26412;&#24212;&#29992;&#26399;&#26395;&#26368;&#22823;&#21270;&#31639;&#27861;&#26469;&#36866;&#24212;p(y, z)&#30340;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Changes in the data distribution at test time can have deleterious effects on the performance of predictive models $p(y|x)$. We consider situations where there are additional meta-data labels (such as group labels), denoted by $z$, that can account for such changes in the distribution. In particular, we assume that the prior distribution $p(y, z)$, which models the dependence between the class label $y$ and the "nuisance" factors $z$, may change across domains, either due to a change in the correlation between these terms, or a change in one of their marginals. However, we assume that the generative model for features $p(x|y, z)$ is invariant across domains. We note that this corresponds to an expanded version of the widely used "label shift" assumption, where the labels now also include the nuisance factors $z$. Based on this observation, we propose a test-time label shift correction that adapts to changes in the joint distribution $p(y, z)$ using EM applied to unlabeled samples from 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#35777;&#26126;&#30340;&#38381;&#24335;&#26041;&#31243;&#65292;&#25551;&#36848;&#20102;&#19968;&#31867;&#22522;&#20110;&#26799;&#24230;&#30340;&#26041;&#27861;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#30340;&#31934;&#30830;&#28176;&#36827;&#24615;&#33021;&#65292;&#20026;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31561;&#31639;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#25903;&#25345;&#65292;&#24182;&#25552;&#20379;&#20102;&#25968;&#20540;&#23454;&#29616;&#12290;</title><link>http://arxiv.org/abs/2210.06591</link><description>&lt;p&gt;
&#20005;&#26684;&#30340;&#21160;&#21147;&#23398;&#22343;&#22330;&#29702;&#35770;&#29992;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Rigorous dynamical mean field theory for stochastic gradient descent methods. (arXiv:2210.06591v2 [math-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.06591
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#35777;&#26126;&#30340;&#38381;&#24335;&#26041;&#31243;&#65292;&#25551;&#36848;&#20102;&#19968;&#31867;&#22522;&#20110;&#26799;&#24230;&#30340;&#26041;&#27861;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#30340;&#31934;&#30830;&#28176;&#36827;&#24615;&#33021;&#65292;&#20026;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31561;&#31639;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#25903;&#25345;&#65292;&#24182;&#25552;&#20379;&#20102;&#25968;&#20540;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#31867;&#22522;&#20110;&#26799;&#24230;&#30340;&#26041;&#27861;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#30340;&#31934;&#30830;&#28176;&#36827;&#24615;&#33021;&#38381;&#24335;&#26041;&#31243;&#65292;&#35813;&#26041;&#27861;&#20174;&#39640;&#26031;&#25968;&#25454;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#23398;&#20064;&#20272;&#35745;&#22120;&#65288;&#20363;&#22914;M-&#20272;&#35745;&#22120;&#65292;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;...&#65289;&#12290;&#36825;&#21253;&#25324;&#20102;&#24191;&#27867;&#20351;&#29992;&#30340;&#31639;&#27861;&#65292;&#22914;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#25110;Nesterov&#21152;&#36895;&#12290;&#24471;&#21040;&#30340;&#26041;&#31243;&#19982;&#23558;&#21160;&#21147;&#23398;&#22343;&#22330;&#29702;&#35770;&#65288;DMFT&#65289;&#26041;&#31243;&#31163;&#25955;&#21270;&#21518;&#24212;&#29992;&#20110;&#26799;&#24230;&#27969;&#26102;&#20135;&#29983;&#30340;&#26041;&#31243;&#30456;&#21305;&#37197;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#26041;&#27861;&#20801;&#35768;&#25105;&#20204;&#26126;&#30830;&#25551;&#36848;&#35760;&#24518;&#26680;&#22312;&#26377;&#25928;&#21160;&#21147;&#23398;&#20013;&#22914;&#20309;&#26500;&#24314;&#65292;&#24182;&#19988;&#21253;&#25324;&#38750;&#21487;&#20998;&#31163;&#30340;&#26356;&#26032;&#20989;&#25968;&#65292;&#20801;&#35768;&#20855;&#26377;&#38750;&#21333;&#20301;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#25968;&#25454;&#38598;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20855;&#26377;&#36890;&#29992;&#25209;&#22788;&#29702;&#22823;&#23567;&#21644;&#24658;&#23450;&#23398;&#20064;&#29575;&#30340;SGD&#26041;&#31243;&#30340;&#25968;&#20540;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We prove closed-form equations for the exact high-dimensional asymptotics of a family of first order gradient-based methods, learning an estimator (e.g. M-estimator, shallow neural network, ...) from observations on Gaussian data with empirical risk minimization. This includes widely used algorithms such as stochastic gradient descent (SGD) or Nesterov acceleration. The obtained equations match those resulting from the discretization of dynamical mean-field theory (DMFT) equations from statistical physics when applied to gradient flow. Our proof method allows us to give an explicit description of how memory kernels build up in the effective dynamics, and to include non-separable update functions, allowing datasets with non-identity covariance matrices. Finally, we provide numerical implementations of the equations for SGD with generic extensive batch-size and with constant learning rates.
&lt;/p&gt;</description></item></channel></rss>