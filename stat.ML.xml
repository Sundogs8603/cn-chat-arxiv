<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36825;&#39033;&#24037;&#20316;&#39318;&#27425;&#20174;&#29702;&#35770;&#19978;&#29702;&#35299;&#20102;&#20851;&#31995;&#30693;&#35782;&#33976;&#39311;&#65292;&#36890;&#36807;&#31181;&#32676;&#19978;&#30340;&#35889;&#32858;&#31867;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20851;&#31995;&#30693;&#35782;&#33976;&#39311;&#33021;&#22815;&#23548;&#33268;&#20302;&#32858;&#31867;&#35823;&#24046;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22312;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#26631;&#31614;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2307.11030</link><description>&lt;p&gt;
&#38598;&#32676;&#24863;&#30693;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#65306;&#20851;&#31995;&#30693;&#35782;&#33976;&#39311;&#21487;&#35777;&#26126;&#30340;&#23398;&#20064;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Cluster-aware Semi-supervised Learning: Relational Knowledge Distillation Provably Learns Clustering. (arXiv:2307.11030v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11030
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#39318;&#27425;&#20174;&#29702;&#35770;&#19978;&#29702;&#35299;&#20102;&#20851;&#31995;&#30693;&#35782;&#33976;&#39311;&#65292;&#36890;&#36807;&#31181;&#32676;&#19978;&#30340;&#35889;&#32858;&#31867;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20851;&#31995;&#30693;&#35782;&#33976;&#39311;&#33021;&#22815;&#23548;&#33268;&#20302;&#32858;&#31867;&#35823;&#24046;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22312;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#26631;&#31614;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22522;&#20110;&#20851;&#31995;&#30340;&#30693;&#35782;&#33976;&#39311;&#22312;&#21305;&#37197;&#25945;&#24072;&#21644;&#23398;&#29983;&#27169;&#22411;&#20043;&#38388;&#30340;&#29305;&#24449;&#20851;&#31995;&#26041;&#38754;&#21462;&#24471;&#20102;&#23454;&#35777;&#25104;&#21151;&#21644;&#23454;&#38469;&#24847;&#20041;&#65292;&#20294;&#23545;&#20110;&#21508;&#31181;&#30693;&#35782;&#33976;&#39311;&#33539;&#24335;&#65292;&#20854;&#30456;&#24212;&#30340;&#29702;&#35770;&#35299;&#37322;&#20173;&#28982;&#26377;&#38480;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#20174;&#29702;&#35770;&#19978;&#29702;&#35299;&#20851;&#31995;&#30693;&#35782;&#33976;&#39311;&#65288;RKD&#65289;&#65292;&#24182;&#37325;&#28857;&#20851;&#27880;&#21322;&#30417;&#30563;&#20998;&#31867;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#23558;RKD&#35270;&#20026;&#25945;&#24072;&#27169;&#22411;&#25581;&#31034;&#30340;&#30001;&#31181;&#32676;&#20135;&#29983;&#30340;&#22270;&#19978;&#30340;&#35889;&#32858;&#31867;&#12290;&#36890;&#36807;&#34913;&#37327;&#39044;&#27979;&#21644;&#22522;&#26412;&#20107;&#23454;&#32858;&#31867;&#20043;&#38388;&#24046;&#24322;&#30340;&#32858;&#31867;&#35823;&#24046;&#27010;&#24565;&#65292;&#25105;&#20204;&#35828;&#26126;&#20102;&#31181;&#32676;&#19978;&#30340;RKD&#21487;&#35777;&#26126;&#22320;&#23548;&#33268;&#20302;&#32858;&#31867;&#35823;&#24046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#20110;&#26377;&#38480;&#26080;&#26631;&#31614;&#26679;&#26412;&#30340;RKD&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#12290;&#23545;&#20110;&#21322;&#30417;&#30563;&#23398;&#20064;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#36890;&#36807;&#38598;&#32676;&#24863;&#30693;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#26694;&#26550;&#23637;&#31034;&#20102;RKD&#30340;&#26631;&#31614;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the empirical success and practical significance of (relational) knowledge distillation that matches (the relations of) features between teacher and student models, the corresponding theoretical interpretations remain limited for various knowledge distillation paradigms. In this work, we take an initial step toward a theoretical understanding of relational knowledge distillation (RKD), with a focus on semi-supervised classification problems. We start by casting RKD as spectral clustering on a population-induced graph unveiled by a teacher model. Via a notion of clustering error that quantifies the discrepancy between the predicted and ground truth clusterings, we illustrate that RKD over the population provably leads to low clustering error. Moreover, we provide a sample complexity bound for RKD with limited unlabeled samples. For semi-supervised learning, we further demonstrate the label efficiency of RKD through a general framework of cluster-aware semi-supervised learning th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#26399;&#21464;&#20998;&#25512;&#26029;&#20316;&#20026;&#36817;&#20284;&#21518;&#39564;&#25512;&#26029;&#30340;&#19968;&#31181;&#36890;&#29992;&#26367;&#20195;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#20309;&#26102;&#33021;&#22815;&#36798;&#21040;&#19982;&#20256;&#32479;&#30340;&#22240;&#23376;&#21270;&#21464;&#20998;&#25512;&#26029;&#30456;&#21516;&#30340;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2307.11018</link><description>&lt;p&gt;
&#20998;&#26399;&#21464;&#20998;&#25512;&#26029;&#65306;&#20309;&#26102;&#20197;&#21450;&#20026;&#20160;&#20040;&#20351;&#29992;&#65311;
&lt;/p&gt;
&lt;p&gt;
Amortized Variational Inference: When and Why?. (arXiv:2307.11018v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11018
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#26399;&#21464;&#20998;&#25512;&#26029;&#20316;&#20026;&#36817;&#20284;&#21518;&#39564;&#25512;&#26029;&#30340;&#19968;&#31181;&#36890;&#29992;&#26367;&#20195;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#20309;&#26102;&#33021;&#22815;&#36798;&#21040;&#19982;&#20256;&#32479;&#30340;&#22240;&#23376;&#21270;&#21464;&#20998;&#25512;&#26029;&#30456;&#21516;&#30340;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#26399;&#21464;&#20998;&#25512;&#26029;&#65288;A-VI&#65289;&#26159;&#19968;&#31181;&#36817;&#20284;&#22788;&#29702;&#27010;&#29575;&#27169;&#22411;&#20013;&#30340;&#38590;&#20197;&#35745;&#31639;&#30340;&#21518;&#39564;&#20998;&#24067;&#30340;&#26041;&#27861;&#12290;A-VI&#30340;&#23450;&#20041;&#29305;&#28857;&#26159;&#23398;&#20064;&#19968;&#20010;&#20840;&#23616;&#25512;&#26029;&#20989;&#25968;&#65292;&#23558;&#27599;&#20010;&#35266;&#23519;&#26144;&#23556;&#21040;&#20854;&#23616;&#37096;&#28508;&#21464;&#37327;&#30340;&#36817;&#20284;&#21518;&#39564;&#20998;&#24067;&#12290;&#36825;&#19982;&#26356;&#20256;&#32479;&#30340;&#20998;&#35299;&#65288;&#25110;&#22343;&#22330;&#65289;&#21464;&#20998;&#25512;&#26029;&#65288;F-VI&#65289;&#24418;&#25104;&#23545;&#27604;&#65292;&#21518;&#32773;&#30452;&#25509;&#23398;&#20064;&#27599;&#20010;&#28508;&#21464;&#37327;&#30340;&#36817;&#20284;&#20998;&#24067;&#30340;&#21442;&#25968;&#12290;&#22312;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#20013;&#65292;A-VI&#29992;&#20316;&#21152;&#36895;&#23616;&#37096;&#28508;&#21464;&#37327;&#25512;&#26029;&#30340;&#35745;&#31639;&#25216;&#24039;&#12290;&#26412;&#25991;&#30740;&#31350;A-VI&#20316;&#20026;&#36817;&#20284;&#21518;&#39564;&#25512;&#26029;&#30340;&#19968;&#31181;&#36890;&#29992;&#26367;&#20195;&#26041;&#27861;&#12290;&#30001;&#20110;&#20998;&#26399;&#23478;&#26063;&#26159;&#20998;&#35299;&#23478;&#26063;&#30340;&#23376;&#38598;&#65292;A-VI&#26080;&#27861;&#20135;&#29983;&#27604;F-VI&#26368;&#20248;&#35299;&#26356;&#20302;&#30340;Kullback-Leibler&#25955;&#24230;&#30340;&#36817;&#20284;&#20540;&#12290;&#22240;&#27492;&#65292;&#19968;&#20010;&#26680;&#24515;&#30340;&#29702;&#35770;&#38382;&#39064;&#26159;&#21051;&#30011;A-VI&#20309;&#26102;&#20173;&#28982;&#36798;&#21040;F-VI&#30340;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Amortized variational inference (A-VI) is a method for approximating the intractable posterior distributions that arise in probabilistic models. The defining feature of A-VI is that it learns a global inference function that maps each observation to its local latent variable's approximate posterior. This stands in contrast to the more classical factorized (or mean-field) variational inference (F-VI), which directly learns the parameters of the approximating distribution for each latent variable. In deep generative models, A-VI is used as a computational trick to speed up inference for local latent variables. In this paper, we study A-VI as a general alternative to F-VI for approximate posterior inference. A-VI cannot produce an approximation with a lower Kullback-Leibler divergence than F-VI's optimal solution, because the amortized family is a subset of the factorized family. Thus a central theoretical problem is to characterize when A-VI still attains F-VI's optimal solution. We deri
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#27969;&#22270;&#23398;&#20064;&#65288;FML&#65289;&#30340;&#26694;&#26550;&#21644;&#23454;&#29616;&#32454;&#33410;&#65292;&#20197;&#21450;&#29992;&#20110;&#23398;&#20064;&#26410;&#30693;&#21160;&#21147;&#31995;&#32479;&#30340;&#22522;&#20934;&#38382;&#39064;&#12290;FML&#22312;&#37096;&#20998;&#35266;&#23519;&#31995;&#32479;&#20013;&#20135;&#29983;&#20934;&#30830;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#21363;&#20351;&#27809;&#26377;&#31934;&#30830;&#30340;&#25968;&#23398;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2307.11013</link><description>&lt;p&gt;
&#26410;&#30693;&#21160;&#21147;&#31995;&#32479;&#30340;&#27969;&#22270;&#23398;&#20064;&#65306;&#32508;&#36848;&#12289;&#23454;&#29616;&#21644;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Flow Map Learning for Unknown Dynamical Systems: Overview, Implementation, and Benchmarks. (arXiv:2307.11013v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11013
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#27969;&#22270;&#23398;&#20064;&#65288;FML&#65289;&#30340;&#26694;&#26550;&#21644;&#23454;&#29616;&#32454;&#33410;&#65292;&#20197;&#21450;&#29992;&#20110;&#23398;&#20064;&#26410;&#30693;&#21160;&#21147;&#31995;&#32479;&#30340;&#22522;&#20934;&#38382;&#39064;&#12290;FML&#22312;&#37096;&#20998;&#35266;&#23519;&#31995;&#32479;&#20013;&#20135;&#29983;&#20934;&#30830;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#21363;&#20351;&#27809;&#26377;&#31934;&#30830;&#30340;&#25968;&#23398;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27969;&#22270;&#23398;&#20064;&#65288;FML&#65289;&#19982;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#32467;&#21512;&#65292;&#24050;&#32463;&#26174;&#31034;&#20986;&#22312;&#25968;&#25454;&#39537;&#21160;&#24314;&#27169;&#26410;&#30693;&#21160;&#21147;&#31995;&#32479;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;FML&#30340;&#19968;&#20010;&#26174;&#33879;&#29305;&#28857;&#26159;&#65292;&#21363;&#20351;&#19981;&#23384;&#22312;&#20854;&#31934;&#30830;&#25968;&#23398;&#27169;&#22411;&#65292;&#23427;&#20063;&#33021;&#22815;&#20026;&#37096;&#20998;&#35266;&#23519;&#31995;&#32479;&#20135;&#29983;&#20934;&#30830;&#30340;&#39044;&#27979;&#27169;&#22411;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;FML&#26694;&#26550;&#30340;&#27010;&#36848;&#65292;&#20197;&#21450;&#20854;&#25104;&#21151;&#23454;&#26045;&#30340;&#37325;&#35201;&#35745;&#31639;&#32454;&#33410;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#32452;&#26126;&#30830;&#23450;&#20041;&#30340;&#22522;&#20934;&#38382;&#39064;&#65292;&#29992;&#20110;&#23398;&#20064;&#26410;&#30693;&#21160;&#21147;&#31995;&#32479;&#12290;&#25152;&#26377;&#36825;&#20123;&#38382;&#39064;&#30340;&#25968;&#20540;&#32454;&#33410;&#37117;&#34987;&#25552;&#20379;&#65292;&#20197;&#21450;&#23427;&#20204;&#30340;FML&#32467;&#26524;&#65292;&#20197;&#30830;&#20445;&#38382;&#39064;&#21487;&#20379;&#20132;&#21449;&#39564;&#35777;&#65292;&#24182;&#19988;&#32467;&#26524;&#21487;&#37325;&#22797;&#12290;
&lt;/p&gt;
&lt;p&gt;
Flow map learning (FML), in conjunction with deep neural networks (DNNs), has shown promises for data driven modeling of unknown dynamical systems. A remarkable feature of FML is that it is capable of producing accurate predictive models for partially observed systems, even when their exact mathematical models do not exist. In this paper, we present an overview of the FML framework, along with the important computational details for its successful implementation. We also present a set of well defined benchmark problems for learning unknown dynamical systems. All the numerical details of these problems are presented, along with their FML results, to ensure that the problems are accessible for cross-examination and the results are reproducible.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#21457;&#29616;&#65292;&#23574;&#38160;&#24615;&#26368;&#23567;&#21270;&#31639;&#27861;&#19981;&#20165;&#20165;&#26159;&#20026;&#20102;&#26368;&#23567;&#21270;&#23574;&#38160;&#24615;&#32780;&#36798;&#21040;&#26356;&#22909;&#30340;&#27867;&#21270;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#23574;&#38160;&#24615;&#19982;&#27867;&#21270;&#20043;&#38388;&#30340;&#20851;&#31995;&#21462;&#20915;&#20110;&#25968;&#25454;&#20998;&#24067;&#21644;&#27169;&#22411;&#26550;&#26500;&#12290;</title><link>http://arxiv.org/abs/2307.11007</link><description>&lt;p&gt;
&#23574;&#38160;&#24615;&#26368;&#23567;&#21270;&#31639;&#27861;&#19981;&#20165;&#20165;&#26159;&#20026;&#20102;&#26356;&#22909;&#22320;&#27867;&#21270;&#32780;&#26368;&#23567;&#21270;&#23574;&#38160;&#24615;
&lt;/p&gt;
&lt;p&gt;
Sharpness Minimization Algorithms Do Not Only Minimize Sharpness To Achieve Better Generalization. (arXiv:2307.11007v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11007
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#21457;&#29616;&#65292;&#23574;&#38160;&#24615;&#26368;&#23567;&#21270;&#31639;&#27861;&#19981;&#20165;&#20165;&#26159;&#20026;&#20102;&#26368;&#23567;&#21270;&#23574;&#38160;&#24615;&#32780;&#36798;&#21040;&#26356;&#22909;&#30340;&#27867;&#21270;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#23574;&#38160;&#24615;&#19982;&#27867;&#21270;&#20043;&#38388;&#30340;&#20851;&#31995;&#21462;&#20915;&#20110;&#25968;&#25454;&#20998;&#24067;&#21644;&#27169;&#22411;&#26550;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#30740;&#31350;&#65292;&#20294;&#36807;&#21442;&#25968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#27867;&#21270;&#30340;&#22522;&#26412;&#21407;&#22240;&#20173;&#28982;&#19981;&#26126;&#30830;&#12290;&#29616;&#26377;&#30340;&#29702;&#35770;&#34920;&#26126;&#65292;&#24120;&#35265;&#30340;&#38543;&#26426;&#20248;&#21270;&#22120;&#26356;&#20542;&#21521;&#20110;&#35757;&#32451;&#25439;&#22833;&#26356;&#24179;&#22374;&#30340;&#26368;&#23567;&#21270;&#22120;&#65292;&#22240;&#27492;&#33258;&#28982;&#32780;&#28982;&#30340;&#35299;&#37322;&#26159;&#24179;&#22374;&#24615;&#24847;&#21619;&#30528;&#27867;&#21270;&#12290;&#26412;&#25991;&#23545;&#36825;&#19968;&#35299;&#37322;&#36827;&#34892;&#20102;&#25209;&#21028;&#24615;&#30340;&#30740;&#31350;&#12290;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#35777;&#35843;&#26597;&#65292;&#25105;&#20204;&#21457;&#29616;&#23545;&#20110;&#20004;&#23618;ReLU&#32593;&#32476;&#23384;&#22312;&#20197;&#19979;&#19977;&#31181;&#24773;&#20917;&#65306;(1) &#24179;&#22374;&#24615;&#30830;&#23454;&#26263;&#31034;&#27867;&#21270;&#65307;(2) &#23384;&#22312;&#26368;&#24179;&#22374;&#30340;&#38750;&#27867;&#21270;&#27169;&#22411;&#65292;&#23574;&#38160;&#24615;&#26368;&#23567;&#21270;&#31639;&#27861;&#26080;&#27861;&#27867;&#21270;&#65307;(3) &#26356;&#21152;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#23384;&#22312;&#38750;&#27867;&#21270;&#26368;&#24179;&#22374;&#30340;&#27169;&#22411;&#65292;&#20294;&#23574;&#38160;&#24615;&#26368;&#23567;&#21270;&#31639;&#27861;&#20173;&#28982;&#33021;&#22815;&#27867;&#21270;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#23574;&#38160;&#24615;&#19982;&#27867;&#21270;&#20043;&#38388;&#30340;&#20851;&#31995;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#21462;&#20915;&#20110;&#25968;&#25454;&#20998;&#24067;&#21644;&#27169;&#22411;&#26550;&#26500;&#65292;&#23574;&#38160;&#24615;&#26368;&#23567;&#21270;&#31639;&#27861;&#19981;&#20165;&#20165;&#26159;&#20026;&#20102;&#26368;&#23567;&#21270;&#23574;&#38160;&#24615;&#32780;&#36798;&#21040;&#26356;&#22909;&#30340;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite extensive studies, the underlying reason as to why overparameterized neural networks can generalize remains elusive. Existing theory shows that common stochastic optimizers prefer flatter minimizers of the training loss, and thus a natural potential explanation is that flatness implies generalization. This work critically examines this explanation. Through theoretical and empirical investigation, we identify the following three scenarios for two-layer ReLU networks: (1) flatness provably implies generalization; (2) there exist non-generalizing flattest models and sharpness minimization algorithms fail to generalize, and (3) perhaps most surprisingly, there exist non-generalizing flattest models, but sharpness minimization algorithms still generalize. Our results suggest that the relationship between sharpness and generalization subtly depends on the data distributions and the model architectures and sharpness minimization algorithms do not only minimize sharpness to achieve bet
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#31169;&#26377;&#32852;&#37030;&#23398;&#20064;&#20013;&#33258;&#21160;&#35843;&#25972;&#21387;&#32553;&#29575;&#30340;&#26032;&#25216;&#26415;&#65292;&#26080;&#38656;&#25163;&#21160;&#35774;&#32622;&#25110;&#35843;&#25972;&#65292;&#36890;&#36807;&#20351;&#29992;&#23433;&#20840;&#32858;&#21512;&#21644;&#24046;&#20998;&#38544;&#31169;&#25552;&#20379;&#20102;&#21487;&#35777;&#26126;&#30340;&#38544;&#31169;&#20445;&#35777;&#65292;&#24182;&#22312;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.10999</link><description>&lt;p&gt;
&#31169;&#26377;&#32852;&#37030;&#23398;&#20064;&#20013;&#20351;&#29992;&#33258;&#21160;&#35843;&#20248;&#21387;&#32553;&#30340;&#26032;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Private Federated Learning with Autotuned Compression. (arXiv:2307.10999v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10999
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#31169;&#26377;&#32852;&#37030;&#23398;&#20064;&#20013;&#33258;&#21160;&#35843;&#25972;&#21387;&#32553;&#29575;&#30340;&#26032;&#25216;&#26415;&#65292;&#26080;&#38656;&#25163;&#21160;&#35774;&#32622;&#25110;&#35843;&#25972;&#65292;&#36890;&#36807;&#20351;&#29992;&#23433;&#20840;&#32858;&#21512;&#21644;&#24046;&#20998;&#38544;&#31169;&#25552;&#20379;&#20102;&#21487;&#35777;&#26126;&#30340;&#38544;&#31169;&#20445;&#35777;&#65292;&#24182;&#22312;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#31169;&#26377;&#32852;&#37030;&#23398;&#20064;&#20013;&#20943;&#23569;&#36890;&#20449;&#30340;&#26032;&#25216;&#26415;&#65292;&#26080;&#38656;&#35774;&#32622;&#25110;&#35843;&#25972;&#21387;&#32553;&#29575;&#12290;&#25105;&#20204;&#30340;&#21363;&#26102;&#26041;&#27861;&#20250;&#26681;&#25454;&#35757;&#32451;&#36807;&#31243;&#20013;&#24341;&#20837;&#30340;&#38169;&#35823;&#33258;&#21160;&#35843;&#25972;&#21387;&#32553;&#29575;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#23433;&#20840;&#32858;&#21512;&#21644;&#24046;&#20998;&#38544;&#31169;&#25552;&#20379;&#21487;&#35777;&#26126;&#30340;&#38544;&#31169;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#25216;&#26415;&#22312;&#22343;&#20540;&#20272;&#35745;&#26041;&#38754;&#34987;&#35777;&#26126;&#26159;&#23454;&#20363;&#26368;&#20248;&#30340;&#65292;&#24847;&#21619;&#30528;&#23427;&#20204;&#21487;&#20197;&#26681;&#25454;&#38382;&#39064;&#30340;&#8220;&#38590;&#24230;&#8221;&#36827;&#34892;&#26368;&#23567;&#20132;&#20114;&#24335;&#35843;&#25972;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#26377;&#21033;&#30340;&#21387;&#32553;&#29575;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose new techniques for reducing communication in private federated learning without the need for setting or tuning compression rates. Our on-the-fly methods automatically adjust the compression rate based on the error induced during training, while maintaining provable privacy guarantees through the use of secure aggregation and differential privacy. Our techniques are provably instance-optimal for mean estimation, meaning that they can adapt to the ``hardness of the problem" with minimal interactivity. We demonstrate the effectiveness of our approach on real-world datasets by achieving favorable compression rates without the need for tuning.
&lt;/p&gt;</description></item><item><title>&#23494;&#38598;&#26679;&#26412;&#28145;&#24230;&#23398;&#20064;&#26159;&#19968;&#31181;&#38024;&#23545;&#28145;&#24230;&#23398;&#20064;&#32593;&#32476;&#30340;&#30740;&#31350;&#26041;&#27861;&#65292;&#26088;&#22312;&#25581;&#31034;&#23398;&#20064;&#26426;&#21046;&#21644;&#34920;&#31034;&#30340;&#26410;&#30693;&#29305;&#24615;&#65292;&#24182;&#35299;&#20915;&#22823;&#35268;&#27169;&#25968;&#25454;&#21644;&#38544;&#34255;&#21333;&#20803;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.10991</link><description>&lt;p&gt;
&#23494;&#38598;&#26679;&#26412;&#28145;&#24230;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Dense Sample Deep Learning. (arXiv:2307.10991v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10991
&lt;/p&gt;
&lt;p&gt;
&#23494;&#38598;&#26679;&#26412;&#28145;&#24230;&#23398;&#20064;&#26159;&#19968;&#31181;&#38024;&#23545;&#28145;&#24230;&#23398;&#20064;&#32593;&#32476;&#30340;&#30740;&#31350;&#26041;&#27861;&#65292;&#26088;&#22312;&#25581;&#31034;&#23398;&#20064;&#26426;&#21046;&#21644;&#34920;&#31034;&#30340;&#26410;&#30693;&#29305;&#24615;&#65292;&#24182;&#35299;&#20915;&#22823;&#35268;&#27169;&#25968;&#25454;&#21644;&#38544;&#34255;&#21333;&#20803;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#26159;20&#19990;&#32426;80&#24180;&#20195;&#25552;&#20986;&#30340;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#31639;&#27861;&#30340;&#21464;&#20307;&#65292;&#22312;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#39046;&#22495;&#21462;&#24471;&#20102;&#20196;&#20154;&#24778;&#35766;&#30340;&#36827;&#23637;&#65292;&#21253;&#25324;&#35821;&#35328;&#32763;&#35793;&#12289;&#34507;&#30333;&#36136;&#25240;&#21472;&#12289;&#33258;&#21160;&#39550;&#39542;&#27773;&#36710;&#65292;&#20197;&#21450;&#26368;&#36817;&#30340;&#31867;&#20154;&#35821;&#35328;&#27169;&#22411;&#65288;CHATbots&#65289;&#12290;&#23613;&#31649;&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#32593;&#32476;&#30340;&#20351;&#29992;&#36234;&#26469;&#36234;&#24191;&#27867;&#65292;&#20294;&#23545;&#20110;&#20351;&#36825;&#20123;&#32593;&#32476;&#22312;&#22914;&#27492;&#24191;&#27867;&#30340;&#24212;&#29992;&#20013;&#26377;&#25928;&#30340;&#23398;&#20064;&#26426;&#21046;&#21644;&#34920;&#31034;&#20173;&#30693;&#20043;&#29978;&#23569;&#12290;&#37096;&#20998;&#21407;&#22240;&#21487;&#33021;&#26159;&#20854;&#22823;&#35268;&#27169;&#26550;&#26500;&#21644;&#22823;&#35268;&#27169;&#25968;&#25454;&#30340;&#20351;&#29992;&#65292;&#20294;&#28145;&#24230;&#23398;&#20064;&#34920;&#31034;&#30340;&#26412;&#36136;&#20173;&#28982;&#22823;&#37096;&#20998;&#26410;&#30693;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#20855;&#26377;&#25968;&#30334;&#19975;&#25110;&#25968;&#21313;&#20159;&#20010;&#26631;&#35760;&#30340;&#35757;&#32451;&#38598;&#23384;&#22312;&#26410;&#30693;&#30340;&#32452;&#21512;&#26041;&#24335;&#65292;&#21516;&#26102;&#25968;&#30334;&#19975;&#25110;&#25968;&#21313;&#20159;&#20010;&#38544;&#34255;&#21333;&#20803;&#30340;&#32593;&#32476;&#38590;&#20197;&#21487;&#35270;&#21270;&#65292;&#20854;&#26426;&#21046;&#20063;&#38590;&#20197;&#25581;&#31034;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23494;&#38598;&#26679;&#26412;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Learning (DL) , a variant of the neural network algorithms originally proposed in the 1980s, has made surprising progress in Artificial Intelligence (AI), ranging from language translation, protein folding, autonomous cars, and more recently human-like language models (CHATbots), all that seemed intractable until very recently. Despite the growing use of Deep Learning (DL) networks, little is actually understood about the learning mechanisms and representations that makes these networks effective across such a diverse range of applications. Part of the answer must be the huge scale of the architecture and of course the large scale of the data, since not much has changed since 1987. But the nature of deep learned representations remain largely unknown. Unfortunately training sets with millions or billions of tokens have unknown combinatorics and Networks with millions or billions of hidden units cannot easily be visualized and their mechanisms cannot be easily revealed. In this pap
&lt;/p&gt;</description></item><item><title>&#38750;&#32447;&#24615;&#20803;&#23398;&#20064;&#21487;&#20197;&#20445;&#35777;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2307.10870</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#20803;&#23398;&#20064;&#21487;&#20197;&#20445;&#35777;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;
&lt;/p&gt;
&lt;p&gt;
Nonlinear Meta-Learning Can Guarantee Faster Rates. (arXiv:2307.10870v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10870
&lt;/p&gt;
&lt;p&gt;
&#38750;&#32447;&#24615;&#20803;&#23398;&#20064;&#21487;&#20197;&#20445;&#35777;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#35768;&#22810;&#20851;&#20110;&#20803;&#23398;&#20064;&#30340;&#29702;&#35770;&#30740;&#31350;&#26088;&#22312;&#21033;&#29992;&#30456;&#20851;&#20219;&#21153;&#20013;&#30340;&#30456;&#20284;&#34920;&#31034;&#32467;&#26500;&#26469;&#31616;&#21270;&#30446;&#26631;&#20219;&#21153;&#65292;&#24182;&#23454;&#29616;&#25910;&#25947;&#36895;&#29575;&#30340;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#34920;&#31034;&#24448;&#24448;&#26159;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#65292;&#24341;&#20837;&#20102;&#27599;&#20010;&#20219;&#21153;&#20013;&#19981;&#21487;&#31616;&#21333;&#24179;&#22343;&#30340;&#38750;&#24179;&#20961;&#20559;&#24046;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#38750;&#32447;&#24615;&#34920;&#31034;&#25512;&#23548;&#20986;&#20803;&#23398;&#20064;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many recent theoretical works on \emph{meta-learning} aim to achieve guarantees in leveraging similar representational structures from related tasks towards simplifying a target task. Importantly, the main aim in theory works on the subject is to understand the extent to which convergence rates -- in learning a common representation -- \emph{may scale with the number $N$ of tasks} (as well as the number of samples per task). First steps in this setting demonstrate this property when both the shared representation amongst tasks, and task-specific regression functions, are linear. This linear setting readily reveals the benefits of aggregating tasks, e.g., via averaging arguments. In practice, however, the representation is often highly nonlinear, introducing nontrivial biases in each task that cannot easily be averaged out as in the linear case. In the present work, we derive theoretical guarantees for meta-learning with nonlinear representations. In particular, assuming the shared nonl
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21457;&#29616;&#32593;&#32476;&#26435;&#37325;&#30340;&#26041;&#24046;&#21644;&#22823;&#26435;&#37325;&#30340;&#31354;&#38388;&#38598;&#20013;&#26159;&#24433;&#21709;&#31070;&#32463;&#25345;&#20037;&#24615;&#30340;&#20027;&#35201;&#22240;&#32032;&#65292;&#24182;&#25552;&#20986;&#20102;&#23558;&#31070;&#32463;&#25345;&#20037;&#24615;&#25193;&#23637;&#21040;&#25972;&#20010;&#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#22270;&#25345;&#20037;&#24615;&#27979;&#37327;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.10865</link><description>&lt;p&gt;
&#36890;&#36807;&#28145;&#24230;&#22270;&#30340;&#25345;&#20037;&#24615;&#35299;&#20915;&#31070;&#32463;&#25345;&#20037;&#24615;&#30340;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Addressing caveats of neural persistence with deep graph persistence. (arXiv:2307.10865v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10865
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21457;&#29616;&#32593;&#32476;&#26435;&#37325;&#30340;&#26041;&#24046;&#21644;&#22823;&#26435;&#37325;&#30340;&#31354;&#38388;&#38598;&#20013;&#26159;&#24433;&#21709;&#31070;&#32463;&#25345;&#20037;&#24615;&#30340;&#20027;&#35201;&#22240;&#32032;&#65292;&#24182;&#25552;&#20986;&#20102;&#23558;&#31070;&#32463;&#25345;&#20037;&#24615;&#25193;&#23637;&#21040;&#25972;&#20010;&#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#22270;&#25345;&#20037;&#24615;&#27979;&#37327;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#25345;&#20037;&#24615;&#26159;&#19968;&#31181;&#29992;&#20110;&#37327;&#21270;&#31070;&#32463;&#32593;&#32476;&#22797;&#26434;&#24615;&#30340;&#37325;&#35201;&#25351;&#26631;&#65292;&#25552;&#20986;&#20110;&#28145;&#24230;&#23398;&#20064;&#20013;&#26032;&#20852;&#30340;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#22312;&#29702;&#35770;&#21644;&#23454;&#35777;&#19978;&#25105;&#20204;&#21457;&#29616;&#65292;&#32593;&#32476;&#26435;&#37325;&#30340;&#26041;&#24046;&#21644;&#22823;&#26435;&#37325;&#30340;&#31354;&#38388;&#38598;&#20013;&#26159;&#24433;&#21709;&#31070;&#32463;&#25345;&#20037;&#24615;&#30340;&#20027;&#35201;&#22240;&#32032;&#12290;&#34429;&#28982;&#36825;&#23545;&#20110;&#32447;&#24615;&#20998;&#31867;&#22120;&#26377;&#29992;&#30340;&#20449;&#24687;&#65292;&#20294;&#25105;&#20204;&#21457;&#29616;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#21518;&#20960;&#23618;&#20013;&#27809;&#26377;&#30456;&#20851;&#30340;&#31354;&#38388;&#32467;&#26500;&#65292;&#20351;&#24471;&#31070;&#32463;&#25345;&#20037;&#24615;&#22823;&#33268;&#31561;&#20110;&#26435;&#37325;&#30340;&#26041;&#24046;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#25152;&#25552;&#20986;&#30340;&#23618;&#38388;&#24179;&#22343;&#36807;&#31243;&#27809;&#26377;&#32771;&#34385;&#23618;&#38388;&#30340;&#20132;&#20114;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#31070;&#32463;&#25345;&#20037;&#24615;&#22522;&#30784;&#32467;&#26500;&#30340;&#25193;&#23637;&#65292;&#20174;&#21333;&#23618;&#25913;&#20026;&#25972;&#20010;&#31070;&#32463;&#32593;&#32476;&#65292;&#36825;&#30456;&#24403;&#20110;&#22312;&#19968;&#20010;&#29305;&#23450;&#30697;&#38453;&#19978;&#35745;&#31639;&#31070;&#32463;&#25345;&#20037;&#24615;&#12290;&#36825;&#24471;&#21040;&#20102;&#25105;&#20204;&#30340;&#28145;&#24230;&#22270;&#25345;&#20037;&#24615;&#27979;&#37327;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural Persistence is a prominent measure for quantifying neural network complexity, proposed in the emerging field of topological data analysis in deep learning. In this work, however, we find both theoretically and empirically that the variance of network weights and spatial concentration of large weights are the main factors that impact neural persistence. Whilst this captures useful information for linear classifiers, we find that no relevant spatial structure is present in later layers of deep neural networks, making neural persistence roughly equivalent to the variance of weights. Additionally, the proposed averaging procedure across layers for deep neural networks does not consider interaction between layers. Based on our analysis, we propose an extension of the filtration underlying neural persistence to the whole neural network instead of single layers, which is equivalent to calculating neural persistence on one particular matrix. This yields our deep graph persistence measur
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#22495;&#20559;&#31227;&#19979;&#20351;&#29992;&#26631;&#31614;&#26657;&#20934;&#26041;&#27861;&#26469;&#25552;&#21319;&#35821;&#20041;&#20998;&#21106;&#27169;&#22411;&#24615;&#33021;&#30340;&#26041;&#24335;&#12290;</title><link>http://arxiv.org/abs/2307.10842</link><description>&lt;p&gt;
&#26631;&#31614;&#26657;&#20934;&#22312;&#22495;&#20559;&#31227;&#19979;&#30340;&#35821;&#20041;&#20998;&#21106;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Label Calibration for Semantic Segmentation Under Domain Shift. (arXiv:2307.10842v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10842
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#22495;&#20559;&#31227;&#19979;&#20351;&#29992;&#26631;&#31614;&#26657;&#20934;&#26041;&#27861;&#26469;&#25552;&#21319;&#35821;&#20041;&#20998;&#21106;&#27169;&#22411;&#24615;&#33021;&#30340;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#30340;&#35821;&#20041;&#20998;&#21106;&#27169;&#22411;&#22312;&#26032;&#39046;&#22495;&#30340;&#25968;&#25454;&#19978;&#34920;&#29616;&#24456;&#21487;&#33021;&#22823;&#24133;&#24230;&#38477;&#20302;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#22495;&#20559;&#31227;&#19979;&#35745;&#31639;&#36719;&#26631;&#31614;&#21407;&#22411;&#65292;&#24182;&#26681;&#25454;&#19982;&#39044;&#27979;&#31867;&#21035;&#27010;&#29575;&#26368;&#25509;&#36817;&#30340;&#21407;&#22411;&#36827;&#34892;&#39044;&#27979;&#65292;&#26469;&#36866;&#24212;&#26410;&#26631;&#35760;&#30340;&#30446;&#26631;&#39046;&#22495;&#25968;&#25454;&#12290;&#25152;&#25552;&#20986;&#30340;&#36866;&#24212;&#36807;&#31243;&#24555;&#36895;&#19988;&#20960;&#20046;&#27809;&#26377;&#35745;&#31639;&#36164;&#28304;&#25104;&#26412;&#65292;&#24182;&#19988;&#33021;&#22815;&#26174;&#33879;&#25552;&#21319;&#24615;&#33021;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#39640;&#24230;&#23454;&#29992;&#30340;&#20174;&#21512;&#25104;&#21040;&#30495;&#23454;&#30340;&#35821;&#20041;&#20998;&#21106;&#38382;&#39064;&#19978;&#23637;&#31034;&#20102;&#26631;&#31614;&#26657;&#20934;&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
Performance of a pre-trained semantic segmentation model is likely to substantially decrease on data from a new domain. We show a pre-trained model can be adapted to unlabelled target domain data by calculating soft-label prototypes under the domain shift and making predictions according to the prototype closest to the vector with predicted class probabilities. The proposed adaptation procedure is fast, comes almost for free in terms of computational resources and leads to considerable performance improvements. We demonstrate the benefits of such label calibration on the highly-practical synthetic-to-real semantic segmentation problem.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#21069;&#39304;&#26041;&#27861;&#26469;&#35299;&#20915;&#28304;&#26080;&#20851;&#22495;&#36866;&#24212;&#38382;&#39064;&#65292;&#36890;&#36807;&#35745;&#31639;&#31867;&#30340;&#21407;&#22411;&#26469;&#22788;&#29702;&#22495;&#20559;&#31227;&#65292;&#30456;&#36739;&#20110;&#20351;&#29992;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#22312;&#31934;&#24230;&#21644;&#26102;&#38388;&#19978;&#37117;&#26377;&#26174;&#33879;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2307.10787</link><description>&lt;p&gt;
&#36890;&#36807;&#31867;&#21407;&#22411;&#23454;&#29616;&#30340;&#21069;&#39304;&#28304;&#26080;&#20851;&#22495;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
Feed-Forward Source-Free Domain Adaptation via Class Prototypes. (arXiv:2307.10787v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10787
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#21069;&#39304;&#26041;&#27861;&#26469;&#35299;&#20915;&#28304;&#26080;&#20851;&#22495;&#36866;&#24212;&#38382;&#39064;&#65292;&#36890;&#36807;&#35745;&#31639;&#31867;&#30340;&#21407;&#22411;&#26469;&#22788;&#29702;&#22495;&#20559;&#31227;&#65292;&#30456;&#36739;&#20110;&#20351;&#29992;&#39044;&#35757;&#32451;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#22312;&#31934;&#24230;&#21644;&#26102;&#38388;&#19978;&#37117;&#26377;&#26174;&#33879;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#27809;&#26377;&#35775;&#38382;&#28304;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#28304;&#26080;&#20851;&#22495;&#36866;&#24212;&#22240;&#20854;&#23454;&#29992;&#24615;&#21644;&#26080;&#38656;&#35775;&#38382;&#28304;&#25968;&#25454;&#32780;&#21464;&#24471;&#27969;&#34892;&#12290;&#28982;&#32780;&#65292;&#36866;&#24212;&#36807;&#31243;&#20173;&#28982;&#38656;&#35201;&#30456;&#24403;&#38271;&#30340;&#26102;&#38388;&#65292;&#24182;&#19988;&#20027;&#35201;&#22522;&#20110;&#20381;&#36182;&#20110;&#21453;&#21521;&#20256;&#25773;&#30340;&#20248;&#21270;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#21069;&#39304;&#26041;&#27861;&#65292;&#25361;&#25112;&#20102;&#22522;&#20110;&#21453;&#21521;&#20256;&#25773;&#30340;&#36866;&#24212;&#30340;&#24517;&#35201;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#20351;&#29992;&#39044;&#35757;&#32451;&#27169;&#22411;&#35745;&#31639;&#20986;&#30340;&#31867;&#22312;&#22495;&#20559;&#31227;&#19979;&#30340;&#21407;&#22411;&#12290;&#19982;&#39044;&#35757;&#32451;&#27169;&#22411;&#30456;&#27604;&#65292;&#23427;&#22312;&#31934;&#24230;&#19978;&#21462;&#24471;&#20102;&#24378;&#22823;&#30340;&#25913;&#36827;&#65292;&#24182;&#19988;&#21482;&#38656;&#35201;&#29616;&#26377;&#22495;&#36866;&#24212;&#26041;&#27861;&#25152;&#38656;&#26102;&#38388;&#30340;&#19968;&#23567;&#37096;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
Source-free domain adaptation has become popular because of its practical usefulness and no need to access source data. However, the adaptation process still takes a considerable amount of time and is predominantly based on optimization that relies on back-propagation. In this work we present a simple feed-forward approach that challenges the need for back-propagation based adaptation. Our approach is based on computing prototypes of classes under the domain shift using a pre-trained model. It achieves strong improvements in accuracy compared to the pre-trained model and requires only a small fraction of time of existing domain adaptation methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#32771;&#34385;&#36873;&#27665;&#23646;&#24615;&#26469;&#23454;&#29616;&#20844;&#27491;&#30340;&#24847;&#35265;&#27719;&#24635;&#30340;&#26041;&#27861;&#65292;&#24182;&#35780;&#20272;&#20102;&#27719;&#24635;&#32467;&#26524;&#30340;&#20844;&#27491;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.10749</link><description>&lt;p&gt;
&#20943;&#36731;&#36873;&#27665;&#23646;&#24615;&#20559;&#35265;&#20197;&#23454;&#29616;&#20844;&#27491;&#30340;&#24847;&#35265;&#27719;&#24635;
&lt;/p&gt;
&lt;p&gt;
Mitigating Voter Attribute Bias for Fair Opinion Aggregation. (arXiv:2307.10749v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10749
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#32771;&#34385;&#36873;&#27665;&#23646;&#24615;&#26469;&#23454;&#29616;&#20844;&#27491;&#30340;&#24847;&#35265;&#27719;&#24635;&#30340;&#26041;&#27861;&#65292;&#24182;&#35780;&#20272;&#20102;&#27719;&#24635;&#32467;&#26524;&#30340;&#20844;&#27491;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20010;&#24847;&#35265;&#30340;&#27719;&#24635;&#22312;&#20915;&#31574;&#20013;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#20363;&#22914;&#22312;&#25307;&#32856;&#21644;&#36151;&#27454;&#23457;&#26680;&#20013;&#65292;&#20197;&#21450;&#22312;&#20026;&#30417;&#30563;&#23398;&#20064;&#26631;&#35760;&#25968;&#25454;&#26102;&#12290;&#34429;&#28982;&#22810;&#25968;&#25237;&#31080;&#21644;&#29616;&#26377;&#30340;&#24847;&#35265;&#27719;&#24635;&#27169;&#22411;&#23545;&#20110;&#31616;&#21333;&#20219;&#21153;&#26159;&#26377;&#25928;&#30340;&#65292;&#20294;&#22312;&#27809;&#26377;&#23458;&#35266;&#30495;&#23454;&#26631;&#31614;&#30340;&#20219;&#21153;&#20013;&#65292;&#23427;&#20204;&#24182;&#19981;&#36866;&#29992;&#65292;&#22240;&#20026;&#21487;&#33021;&#20250;&#20986;&#29616;&#20998;&#27495;&#12290;&#29305;&#21035;&#26159;&#65292;&#24403;&#36873;&#27665;&#23646;&#24615;&#65288;&#22914;&#24615;&#21035;&#25110;&#31181;&#26063;&#65289;&#24341;&#20837;&#20559;&#35265;&#26102;&#65292;&#27719;&#24635;&#32467;&#26524;&#21487;&#33021;&#20250;&#22240;&#36873;&#27665;&#23646;&#24615;&#30340;&#32452;&#25104;&#32780;&#24322;&#12290;&#19968;&#20010;&#24179;&#34913;&#30340;&#36873;&#27665;&#32676;&#20307;&#23545;&#20110;&#20844;&#24179;&#30340;&#27719;&#24635;&#32467;&#26524;&#26159;&#29702;&#24819;&#30340;&#65292;&#20294;&#21487;&#33021;&#38590;&#20197;&#20934;&#22791;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#22522;&#20110;&#36873;&#27665;&#23646;&#24615;&#23454;&#29616;&#20844;&#27491;&#24847;&#35265;&#27719;&#24635;&#30340;&#26041;&#27861;&#65292;&#24182;&#35780;&#20272;&#20102;&#27719;&#24635;&#32467;&#26524;&#30340;&#20844;&#27491;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#23558;&#22810;&#25968;&#25237;&#31080;&#21644;Dawid&#21644;Skene&#27169;&#22411;&#65288;D&amp;S&#27169;&#22411;&#65289;&#31561;&#24847;&#35265;&#27719;&#24635;&#27169;&#22411;&#19982;&#37319;&#26679;&#21152;&#26435;&#31561;&#20844;&#24179;&#36873;&#39033;&#30456;&#32467;&#21512;&#30340;&#26041;&#27861;&#12290;&#20026;&#20102;&#35780;&#20272;&#27719;&#24635;&#32467;&#26524;&#30340;&#20844;&#27491;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The aggregation of multiple opinions plays a crucial role in decision-making, such as in hiring and loan review, and in labeling data for supervised learning. Although majority voting and existing opinion aggregation models are effective for simple tasks, they are inappropriate for tasks without objectively true labels in which disagreements may occur. In particular, when voter attributes such as gender or race introduce bias into opinions, the aggregation results may vary depending on the composition of voter attributes. A balanced group of voters is desirable for fair aggregation results but may be difficult to prepare. In this study, we consider methods to achieve fair opinion aggregation based on voter attributes and evaluate the fairness of the aggregated results. To this end, we consider an approach that combines opinion aggregation models such as majority voting and the Dawid and Skene model (D&amp;S model) with fairness options such as sample weighting. To evaluate the fairness of 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65292;&#31526;&#21512;Feldman&#30340;&#38271;&#23614;&#29702;&#35770;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#38271;&#23614;&#20998;&#24067;&#24773;&#20917;&#19979;&#65292;&#38750;&#32447;&#24615;&#20998;&#31867;&#22120;&#21487;&#20197;&#25552;&#39640;&#27867;&#21270;&#33021;&#21147;&#65292;&#32780;&#32447;&#24615;&#20998;&#31867;&#22120;&#19981;&#33021;&#12290;&#35813;&#32467;&#26524;&#24378;&#35843;&#20102;&#23545;&#20110;&#38271;&#23614;&#20998;&#24067;&#65292;&#38656;&#35201;&#32771;&#34385;&#32597;&#35265;&#30340;&#35757;&#32451;&#26679;&#26412;&#20197;&#23454;&#29616;&#26368;&#20339;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.10736</link><description>&lt;p&gt;
&#39640;&#26031;&#28151;&#21512;&#19979;&#30340;&#38271;&#23614;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Long-Tail Theory under Gaussian Mixtures. (arXiv:2307.10736v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10736
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65292;&#31526;&#21512;Feldman&#30340;&#38271;&#23614;&#29702;&#35770;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#38271;&#23614;&#20998;&#24067;&#24773;&#20917;&#19979;&#65292;&#38750;&#32447;&#24615;&#20998;&#31867;&#22120;&#21487;&#20197;&#25552;&#39640;&#27867;&#21270;&#33021;&#21147;&#65292;&#32780;&#32447;&#24615;&#20998;&#31867;&#22120;&#19981;&#33021;&#12290;&#35813;&#32467;&#26524;&#24378;&#35843;&#20102;&#23545;&#20110;&#38271;&#23614;&#20998;&#24067;&#65292;&#38656;&#35201;&#32771;&#34385;&#32597;&#35265;&#30340;&#35757;&#32451;&#26679;&#26412;&#20197;&#23454;&#29616;&#26368;&#20339;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#26469;&#29983;&#25104;&#36981;&#24490;Feldman&#30340;&#38271;&#23614;&#29702;&#35770;&#65288;2020&#65289;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#25552;&#20986;&#30340;&#27169;&#22411;&#20013;&#65292;&#32447;&#24615;&#20998;&#31867;&#22120;&#26080;&#27861;&#23558;&#27867;&#21270;&#35823;&#24046;&#38477;&#20302;&#21040;&#19968;&#23450;&#27700;&#24179;&#20197;&#19979;&#65292;&#32780;&#20855;&#26377;&#35760;&#24518;&#33021;&#21147;&#30340;&#38750;&#32447;&#24615;&#20998;&#31867;&#22120;&#21487;&#20197;&#12290;&#36825;&#35777;&#23454;&#20102;&#23545;&#20110;&#38271;&#23614;&#20998;&#24067;&#65292;&#24517;&#39035;&#32771;&#34385;&#32597;&#35265;&#30340;&#35757;&#32451;&#26679;&#26412;&#20197;&#23454;&#29616;&#23545;&#26032;&#25968;&#25454;&#30340;&#26368;&#20339;&#27867;&#21270;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#24403;&#23376;&#32676;&#20307;&#39057;&#29575;&#20998;&#24067;&#30340;&#23614;&#37096;&#21464;&#30701;&#26102;&#65292;&#32447;&#24615;&#27169;&#22411;&#21644;&#38750;&#32447;&#24615;&#27169;&#22411;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#36317;&#21487;&#20197;&#20943;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
We suggest a simple Gaussian mixture model for data generation that complies with Feldman's long tail theory (2020). We demonstrate that a linear classifier cannot decrease the generalization error below a certain level in the proposed model, whereas a nonlinear classifier with a memorization capacity can. This confirms that for long-tailed distributions, rare training examples must be considered for optimal generalization to new data. Finally, we show that the performance gap between linear and nonlinear models can be lessened as the tail becomes shorter in the subpopulation frequency distribution, as confirmed by experiments on synthetic and real data.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35745;&#31639;&#26465;&#20214;&#29256;&#26412;&#30340;&#65288;&#20195;&#29702;&#65289;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#22320;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#21644;&#20854;&#20182;&#22238;&#24402;&#27169;&#22411;&#30340;&#39044;&#27979;&#32467;&#26524;&#65292;&#24182;&#32771;&#34385;&#29305;&#24449;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#21516;&#26102;&#65292;&#35813;&#26041;&#27861;&#36824;&#21487;&#20197;&#24212;&#29992;&#20110;&#22797;&#26434;&#22238;&#24402;&#27169;&#22411;&#30340;&#20998;&#26512;&#65292;&#24182;&#25552;&#20379;&#27491;&#30830;&#30340;&#20559;&#20381;&#36182;&#22270;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2307.10654</link><description>&lt;p&gt;
&#26465;&#20214;&#26399;&#26395;&#32593;&#32476;&#29992;&#20110;SHAP
&lt;/p&gt;
&lt;p&gt;
Conditional expectation network for SHAP. (arXiv:2307.10654v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10654
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35745;&#31639;&#26465;&#20214;&#29256;&#26412;&#30340;&#65288;&#20195;&#29702;&#65289;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#22320;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#21644;&#20854;&#20182;&#22238;&#24402;&#27169;&#22411;&#30340;&#39044;&#27979;&#32467;&#26524;&#65292;&#24182;&#32771;&#34385;&#29305;&#24449;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#21516;&#26102;&#65292;&#35813;&#26041;&#27861;&#36824;&#21487;&#20197;&#24212;&#29992;&#20110;&#22797;&#26434;&#22238;&#24402;&#27169;&#22411;&#30340;&#20998;&#26512;&#65292;&#24182;&#25552;&#20379;&#27491;&#30830;&#30340;&#20559;&#20381;&#36182;&#22270;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
SHAP&#26159;&#19968;&#31181;&#38750;&#24120;&#27969;&#34892;&#30340;&#27169;&#22411;&#26080;&#20851;&#25216;&#26415;&#65292;&#29992;&#20110;&#35299;&#37322;&#39044;&#27979;&#27169;&#22411;&#12290;SHAP&#30340;&#20004;&#20010;&#26368;&#21463;&#27426;&#36814;&#30340;&#29256;&#26412;&#26159;&#26465;&#20214;&#26399;&#26395;&#29256;&#26412;&#21644;&#26080;&#26465;&#20214;&#26399;&#26395;&#29256;&#26412;&#65288;&#21518;&#32773;&#20063;&#31216;&#20026;&#24178;&#39044;SHAP&#65289;&#12290;&#38500;&#20102;&#22522;&#20110;&#26641;&#30340;&#26041;&#27861;&#20043;&#22806;&#65292;&#36890;&#24120;&#20351;&#29992;&#26080;&#26465;&#20214;&#29256;&#26412;&#65288;&#20986;&#20110;&#35745;&#31639;&#21407;&#22240;&#65289;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#65288;&#20195;&#29702;&#65289;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35745;&#31639;&#31070;&#32463;&#32593;&#32476;&#21644;&#20854;&#20182;&#22238;&#24402;&#27169;&#22411;&#30340;&#26465;&#20214;&#29256;&#26412;&#65292;&#24182;&#27491;&#30830;&#32771;&#34385;&#29305;&#24449;&#32452;&#20214;&#20043;&#38388;&#30340;&#20381;&#36182;&#32467;&#26500;&#12290;&#36825;&#20010;&#26041;&#27861;&#36824;&#21487;&#20197;&#29992;&#20110;&#25552;&#20379;&#19982;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65288;GLM&#65289;&#31867;&#20284;&#30340;&#22797;&#26434;&#22238;&#24402;&#27169;&#22411;&#30340;drop1&#21644;anova&#20998;&#26512;&#65292;&#24182;&#25552;&#20379;&#32771;&#34385;&#29305;&#24449;&#32452;&#20214;&#20013;&#27491;&#30830;&#20381;&#36182;&#32467;&#26500;&#30340;&#20559;&#20381;&#36182;&#22270;&#65288;PDP&#65289;&#30340;&#23545;&#24212;&#29256;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
A very popular model-agnostic technique for explaining predictive models is the SHapley Additive exPlanation (SHAP). The two most popular versions of SHAP are a conditional expectation version and an unconditional expectation version (the latter is also known as interventional SHAP). Except for tree-based methods, usually the unconditional version is used (for computational reasons). We provide a (surrogate) neural network approach which allows us to efficiently calculate the conditional version for both neural networks and other regression models, and which properly considers the dependence structure in the feature components. This proposal is also useful to provide drop1 and anova analyses in complex regression models which are similar to their generalized linear model (GLM) counterparts, and we provide a partial dependence plot (PDP) counterpart that considers the right dependence structure in the feature components.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#21644;&#40065;&#26834;&#30340;&#26041;&#27861;&#26469;&#36817;&#20284;&#35745;&#31639;&#22810;&#20803;&#27491;&#24577;&#20998;&#24067;&#20043;&#38388;&#30340;Fisher-Rao&#36317;&#31163;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31867;&#22522;&#20110;&#27491;&#24577;&#27969;&#24418;&#23884;&#20837;&#21040;&#39640;&#32500;&#23545;&#31216;&#27491;&#23450;&#38181;&#23376;&#27969;&#24418;&#30340;&#36317;&#31163;&#12290;</title><link>http://arxiv.org/abs/2307.10644</link><description>&lt;p&gt;
Fisher-Rao&#36317;&#31163;&#21644;&#36870;&#25512;&#21040;SPD&#38181;&#36317;&#31163;&#22312;&#22810;&#20803;&#27491;&#24577;&#20998;&#24067;&#20043;&#38388;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Fisher-Rao distance and pullback SPD cone distances between multivariate normal distributions. (arXiv:2307.10644v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10644
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#21644;&#40065;&#26834;&#30340;&#26041;&#27861;&#26469;&#36817;&#20284;&#35745;&#31639;&#22810;&#20803;&#27491;&#24577;&#20998;&#24067;&#20043;&#38388;&#30340;Fisher-Rao&#36317;&#31163;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31867;&#22522;&#20110;&#27491;&#24577;&#27969;&#24418;&#23884;&#20837;&#21040;&#39640;&#32500;&#23545;&#31216;&#27491;&#23450;&#38181;&#23376;&#27969;&#24418;&#30340;&#36317;&#31163;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#31185;&#23398;&#39046;&#22495;&#65292;&#22914;&#25193;&#25955;&#24352;&#37327;&#25104;&#20687;&#12289;&#32467;&#26500;&#24352;&#37327;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#38647;&#36798;&#20449;&#21495;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#31561;&#65292;&#37117;&#23384;&#22312;&#30528;&#22810;&#20803;&#27491;&#24577;&#20998;&#24067;&#30340;&#25968;&#25454;&#38598;&#12290;&#20026;&#20102;&#22788;&#29702;&#36825;&#20123;&#27491;&#24577;&#25968;&#25454;&#38598;&#20197;&#36827;&#34892;&#36807;&#28388;&#12289;&#20998;&#31867;&#25110;&#32858;&#31867;&#31561;&#19979;&#28216;&#20219;&#21153;&#65292;&#38656;&#35201;&#23450;&#20041;&#21512;&#36866;&#30340;&#27491;&#24577;&#21644;&#23427;&#20204;&#20043;&#38388;&#30340;&#36335;&#24452;&#20043;&#38388;&#30340;&#24046;&#24322;&#24230;&#37327;&#12290;Fisher-Rao&#36317;&#31163;&#65292;&#20316;&#20026;Fisher&#20449;&#24687;&#24230;&#37327;&#24341;&#36215;&#30340;Riemann&#20960;&#20309;&#36317;&#31163;&#65292;&#26159;&#19968;&#31181;&#21512;&#29702;&#30340;&#24230;&#37327;&#36317;&#31163;&#65292;&#20294;&#38500;&#20102;&#19968;&#20123;&#29305;&#27530;&#24773;&#20917;&#22806;&#65292;&#24182;&#27809;&#26377;&#38381;&#24335;&#27714;&#35299;&#12290;&#26412;&#25991;&#39318;&#20808;&#25253;&#21578;&#20102;&#19968;&#31181;&#24555;&#36895;&#19988;&#40065;&#26834;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#31934;&#30830;&#22320;&#36817;&#20284;&#35745;&#31639;&#22810;&#20803;&#27491;&#24577;&#20998;&#24067;&#20043;&#38388;&#30340;Fisher-Rao&#36317;&#31163;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31867;&#22522;&#20110;&#27491;&#24577;&#27969;&#24418;&#21040;&#39640;&#32500;&#23545;&#31216;&#27491;&#23450;&#38181;&#30340;&#23376;&#27969;&#24418;&#30340;&#24494;&#20998;&#21516;&#32986;&#23884;&#20837;&#30340;&#36317;&#31163;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data sets of multivariate normal distributions abound in many scientific areas like diffusion tensor imaging, structure tensor computer vision, radar signal processing, machine learning, just to name a few. In order to process those normal data sets for downstream tasks like filtering, classification or clustering, one needs to define proper notions of dissimilarities between normals and paths joining them. The Fisher-Rao distance defined as the Riemannian geodesic distance induced by the Fisher information metric is such a principled metric distance which however is not known in closed-form excepts for a few particular cases. In this work, we first report a fast and robust method to approximate arbitrarily finely the Fisher-Rao distance between multivariate normal distributions. Second, we introduce a class of distances based on diffeomorphic embeddings of the normal manifold into a submanifold of the higher-dimensional symmetric positive-definite cone corresponding to the manifold of
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#22522;&#20110;&#38598;&#25104;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#36125;&#21494;&#26031;&#36229;&#21442;&#25968;&#25935;&#24863;&#24615;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#29289;&#32852;&#32593;&#32593;&#32476;&#23433;&#20840;&#24322;&#24120;&#26816;&#27979;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20805;&#20998;&#21033;&#29992;&#20102;&#29289;&#32852;&#32593;&#25968;&#25454;&#30340;&#24322;&#26500;&#24615;&#21644;&#22810;&#26679;&#24615;&#29305;&#24449;&#12290;</title><link>http://arxiv.org/abs/2307.10596</link><description>&lt;p&gt;
&#22522;&#20110;&#38598;&#25104;&#23398;&#20064;&#30340;&#29289;&#32852;&#32593;&#32593;&#32476;&#23433;&#20840;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#36890;&#36807;&#36125;&#21494;&#26031;&#36229;&#21442;&#25968;&#25935;&#24863;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Ensemble Learning based Anomaly Detection for IoT Cybersecurity via Bayesian Hyperparameters Sensitivity Analysis. (arXiv:2307.10596v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10596
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#22522;&#20110;&#38598;&#25104;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#36125;&#21494;&#26031;&#36229;&#21442;&#25968;&#25935;&#24863;&#24615;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#29289;&#32852;&#32593;&#32593;&#32476;&#23433;&#20840;&#24322;&#24120;&#26816;&#27979;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20805;&#20998;&#21033;&#29992;&#20102;&#29289;&#32852;&#32593;&#25968;&#25454;&#30340;&#24322;&#26500;&#24615;&#21644;&#22810;&#26679;&#24615;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29289;&#32852;&#32593;&#25972;&#21512;&#20102;&#20840;&#29699;&#25968;&#21313;&#20159;&#26234;&#33021;&#35774;&#22791;&#65292;&#20855;&#22791;&#19982;&#20854;&#20182;&#36830;&#25509;&#35774;&#22791;&#36827;&#34892;&#27807;&#36890;&#30340;&#33021;&#21147;&#65292;&#23454;&#29616;&#20960;&#20046;&#26080;&#38656;&#20154;&#20026;&#24178;&#39044;&#12290;&#29289;&#32852;&#32593;&#33021;&#22815;&#36827;&#34892;&#22823;&#35268;&#27169;&#30340;&#25968;&#25454;&#32858;&#21512;&#21644;&#20998;&#26512;&#65292;&#20174;&#32780;&#25552;&#21319;&#21508;&#20010;&#39046;&#22495;&#30340;&#29983;&#27963;&#36136;&#37327;&#12290;&#29305;&#21035;&#26159;&#65292;&#29289;&#32852;&#32593;&#25910;&#38598;&#30340;&#25968;&#25454;&#23545;&#20110;&#24322;&#24120;&#26816;&#27979;&#38750;&#24120;&#26377;&#29992;&#12290;&#29289;&#32852;&#32593;&#30340;&#24322;&#26500;&#24615;&#26082;&#26159;&#32593;&#32476;&#23433;&#20840;&#30340;&#25361;&#25112;&#65292;&#20063;&#26159;&#26426;&#20250;&#12290;&#20256;&#32479;&#30340;&#32593;&#32476;&#23433;&#20840;&#30417;&#27979;&#26041;&#27861;&#36890;&#24120;&#38656;&#35201;&#23545;&#19981;&#21516;&#31867;&#22411;&#30340;&#25968;&#25454;&#36827;&#34892;&#39044;&#22788;&#29702;&#21644;&#22788;&#29702;&#65292;&#36825;&#23545;&#20110;&#21253;&#21547;&#24322;&#26500;&#29305;&#24449;&#30340;&#25968;&#25454;&#38598;&#21487;&#33021;&#20250;&#23384;&#22312;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#24322;&#26500;&#31867;&#22411;&#30340;&#32593;&#32476;&#35774;&#22791;&#24448;&#24448;&#21487;&#20197;&#25429;&#33719;&#27604;&#21333;&#19968;&#31867;&#22411;&#35774;&#22791;&#35835;&#25968;&#26356;&#22810;&#26679;&#21270;&#30340;&#20449;&#21495;&#65292;&#36825;&#23545;&#20110;&#24322;&#24120;&#26816;&#27979;&#29305;&#21035;&#26377;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#39033;&#20851;&#20110;&#20351;&#29992;&#38598;&#25104;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22686;&#24378;&#29289;&#32852;&#32593;&#32593;&#32476;&#23433;&#20840;&#24322;&#24120;&#26816;&#27979;&#30340;&#20840;&#38754;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Internet of Things (IoT) integrates more than billions of intelligent devices over the globe with the capability of communicating with other connected devices with little to no human intervention. IoT enables data aggregation and analysis on a large scale to improve life quality in many domains. In particular, data collected by IoT contain a tremendous amount of information for anomaly detection. The heterogeneous nature of IoT is both a challenge and an opportunity for cybersecurity. Traditional approaches in cybersecurity monitoring often require different kinds of data pre-processing and handling for various data types, which might be problematic for datasets that contain heterogeneous features. However, heterogeneous types of network devices can often capture a more diverse set of signals than a single type of device readings, which is particularly useful for anomaly detection. In this paper, we present a comprehensive study on using ensemble machine learning methods for enhanc
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#23637;&#31034;&#20102;&#19968;&#31181;&#21517;&#20026;&#22810;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#19968;&#20010;&#21333;&#19968;&#30340;&#20272;&#35745;&#22120;&#20013;&#21033;&#29992;&#22810;&#20010;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#36873;&#25321;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20013;&#26368;&#20339;&#36229;&#21442;&#25968;&#38598;&#30340;&#22256;&#38590;&#65292;&#20197;&#23454;&#29616;&#22312;&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2307.10536</link><description>&lt;p&gt;
&#12298;&#22312;&#22240;&#26524;&#25512;&#26029;&#20013;&#65292;&#22810;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;&#32469;&#36807;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#12299;
&lt;/p&gt;
&lt;p&gt;
Multiply Robust Estimator Circumvents Hyperparameter Tuning of Neural Network Models in Causal Inference. (arXiv:2307.10536v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10536
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#23637;&#31034;&#20102;&#19968;&#31181;&#21517;&#20026;&#22810;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#19968;&#20010;&#21333;&#19968;&#30340;&#20272;&#35745;&#22120;&#20013;&#21033;&#29992;&#22810;&#20010;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#36873;&#25321;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20013;&#26368;&#20339;&#36229;&#21442;&#25968;&#38598;&#30340;&#22256;&#38590;&#65292;&#20197;&#23454;&#29616;&#22312;&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATE&#65289;&#30340;&#20272;&#35745;&#36890;&#24120;&#20998;&#20026;&#20004;&#27493;&#36827;&#34892;&#65292;&#31532;&#19968;&#27493;&#26159;&#24314;&#31435;&#22788;&#29702;&#21644;&#32467;&#26524;&#27169;&#22411;&#65292;&#31532;&#20108;&#27493;&#23558;&#39044;&#27979;&#32467;&#26524;&#25554;&#20837;ATE&#20272;&#35745;&#22120;&#12290;&#22312;&#31532;&#19968;&#27493;&#20013;&#65292;&#21487;&#20197;&#20351;&#29992;&#22810;&#31181;&#27169;&#22411;&#26469;&#25311;&#21512;&#22788;&#29702;&#21644;&#32467;&#26524;&#65292;&#21253;&#25324;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;&#36873;&#25321;&#21738;&#20010;&#36229;&#21442;&#25968;&#32452;&#20250;&#23548;&#33268;&#26368;&#20339;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#21644;&#25512;&#26029;&#26159;&#19968;&#39033;&#22256;&#38590;&#30340;&#20219;&#21153;&#12290;&#22810;&#37325;&#31283;&#20581;&#65288;MR&#65289;&#20272;&#35745;&#22120;&#20801;&#35768;&#25105;&#20204;&#22312;&#19968;&#20010;&#21333;&#19968;&#30340;&#20272;&#35745;&#22120;&#20013;&#21033;&#29992;&#25152;&#26377;&#31532;&#19968;&#27493;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22914;&#26524;&#20854;&#20013;&#19968;&#20010;&#31532;&#19968;&#27493;&#22788;&#29702;&#25110;&#32467;&#26524;&#27169;&#22411;&#26159;$n^r$&#19968;&#33268;&#30340;&#65292;MR&#20272;&#35745;&#22120;&#23601;&#26159;$n^r$&#19968;&#33268;&#30340;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#65292;MR&#26159;&#19968;&#31867;&#24191;&#20041;&#20272;&#35745;&#26041;&#31243;&#30340;&#35299;&#65292;&#24182;&#19988;&#22914;&#26524;&#20854;&#20013;&#19968;&#20010;&#22788;&#29702;&#27169;&#22411;&#26159;$\sqrt{n}$-&#19968;&#33268;&#30340;&#35805;&#65292;MR&#26159;&#28176;&#36817;&#27491;&#24577;&#30340;&#12290;&#35745;&#31639;&#20102;MR&#30340;&#26631;&#20934;&#38169;&#35823;&#65292;&#23427;&#19981;&#38656;&#35201;&#23545;&#31532;&#19968;&#27493;&#30340;&#30495;&#23454;&#27169;&#22411;&#26377;&#25152;&#20102;&#35299;&#12290;&#25105;&#20204;&#30340;&#27169;&#25311;&#32467;&#26524;&#34920;&#26126;&#12290;&#12290;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimation of the Average Treatment Effect (ATE) is often carried out in 2 steps, wherein the first step, the treatment and outcome are modeled, and in the second step the predictions are inserted into the ATE estimator. In the first steps, numerous models can be fit to the treatment and outcome, including using machine learning algorithms. However, it is a difficult task to choose among the hyperparameter sets which will result in the best causal effect estimation and inference. Multiply Robust (MR) estimator allows us to leverage all the first-step models in a single estimator. We show that MR estimator is $n^r$ consistent if one of the first-step treatment or outcome models is $n^r$ consistent. We also show that MR is the solution to a broad class of estimating equations, and is asymptotically normal if one of the treatment models is $\sqrt{n}$-consistent. The standard error of MR is also calculated which does not require a knowledge of the true models in the first step. Our simulat
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#23454;&#29616;&#20855;&#26377;&#30828;&#32422;&#26463;&#36755;&#20986;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#26144;&#23556;&#38544;&#34255;&#21442;&#25968;&#21521;&#37327;&#21040;&#19968;&#20010;&#31526;&#21512;&#32422;&#26463;&#38598;&#30340;&#28857;&#23454;&#29616;&#32422;&#26463;&#65292;&#24182;&#36890;&#36807;&#38468;&#21152;&#30340;&#31070;&#32463;&#32593;&#32476;&#23618;&#26469;&#36827;&#34892;&#26144;&#23556;&#12290;&#35813;&#26041;&#27861;&#36824;&#21487;&#20197;&#22788;&#29702;&#19981;&#20165;&#23545;&#36755;&#20986;&#21521;&#37327;&#26045;&#21152;&#32422;&#26463;&#65292;&#36824;&#23545;&#20381;&#36182;&#20110;&#36755;&#20837;&#30340;&#32852;&#21512;&#32422;&#26463;&#26045;&#21152;&#32422;&#26463;&#30340;&#24773;&#20917;&#65292;&#24182;&#19988;&#21487;&#20197;&#22788;&#29702;&#19981;&#21516;&#31867;&#22411;&#30340;&#32422;&#26463;&#65292;&#21253;&#25324;&#32447;&#24615;&#21644;&#20108;&#27425;&#32422;&#26463;&#12289;&#31561;&#24335;&#32422;&#26463;&#21644;&#21160;&#24577;&#32422;&#26463;&#12290;</title><link>http://arxiv.org/abs/2307.10459</link><description>&lt;p&gt;
&#19968;&#31181;&#23454;&#29616;&#20855;&#26377;&#30828;&#32422;&#26463;&#36755;&#20986;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#35745;&#31639;&#31616;&#21333;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A New Computationally Simple Approach for Implementing Neural Networks with Output Hard Constraints. (arXiv:2307.10459v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10459
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#23454;&#29616;&#20855;&#26377;&#30828;&#32422;&#26463;&#36755;&#20986;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#26144;&#23556;&#38544;&#34255;&#21442;&#25968;&#21521;&#37327;&#21040;&#19968;&#20010;&#31526;&#21512;&#32422;&#26463;&#38598;&#30340;&#28857;&#23454;&#29616;&#32422;&#26463;&#65292;&#24182;&#36890;&#36807;&#38468;&#21152;&#30340;&#31070;&#32463;&#32593;&#32476;&#23618;&#26469;&#36827;&#34892;&#26144;&#23556;&#12290;&#35813;&#26041;&#27861;&#36824;&#21487;&#20197;&#22788;&#29702;&#19981;&#20165;&#23545;&#36755;&#20986;&#21521;&#37327;&#26045;&#21152;&#32422;&#26463;&#65292;&#36824;&#23545;&#20381;&#36182;&#20110;&#36755;&#20837;&#30340;&#32852;&#21512;&#32422;&#26463;&#26045;&#21152;&#32422;&#26463;&#30340;&#24773;&#20917;&#65292;&#24182;&#19988;&#21487;&#20197;&#22788;&#29702;&#19981;&#21516;&#31867;&#22411;&#30340;&#32422;&#26463;&#65292;&#21253;&#25324;&#32447;&#24615;&#21644;&#20108;&#27425;&#32422;&#26463;&#12289;&#31561;&#24335;&#32422;&#26463;&#21644;&#21160;&#24577;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#31070;&#32463;&#32593;&#32476;&#36755;&#20986;&#20540;&#19978;&#26045;&#21152;&#30828;&#20984;&#32422;&#26463;&#30340;&#35745;&#31639;&#31616;&#21333;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#30340;&#20851;&#38190;&#24605;&#24819;&#26159;&#36890;&#36807;&#23558;&#32593;&#32476;&#30340;&#38544;&#34255;&#21442;&#25968;&#21521;&#37327;&#26144;&#23556;&#21040;&#19968;&#20010;&#28857;&#65292;&#30830;&#20445;&#23427;&#22312;&#30001;&#19968;&#32452;&#32422;&#26463;&#23450;&#20041;&#30340;&#21487;&#34892;&#38598;&#20869;&#12290;&#26144;&#23556;&#26159;&#36890;&#36807;&#20855;&#26377;&#36755;&#20986;&#32422;&#26463;&#30340;&#38468;&#21152;&#31070;&#32463;&#32593;&#32476;&#23618;&#23454;&#29616;&#30340;&#12290;&#23558;&#35813;&#26041;&#27861;&#31616;&#21333;&#22320;&#25193;&#23637;&#21040;&#19981;&#20165;&#23545;&#36755;&#20986;&#21521;&#37327;&#26045;&#21152;&#32422;&#26463;&#65292;&#36824;&#23545;&#20381;&#36182;&#20110;&#36755;&#20837;&#30340;&#32852;&#21512;&#32422;&#26463;&#26045;&#21152;&#32422;&#26463;&#30340;&#24773;&#20917;&#12290;&#22312;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#26694;&#26550;&#20013;&#65292;&#21487;&#20197;&#31616;&#21333;&#22320;&#23454;&#29616;&#23545;&#36755;&#20986;&#30340;&#32422;&#26463;&#25237;&#24433;&#26041;&#27861;&#12290;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#19981;&#21516;&#31867;&#22411;&#30340;&#32422;&#26463;&#24341;&#20837;&#21040;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20013;&#65292;&#21253;&#25324;&#32447;&#24615;&#21644;&#20108;&#27425;&#32422;&#26463;&#12289;&#31561;&#24335;&#32422;&#26463;&#21644;&#21160;&#24577;&#32422;&#26463;&#65292;&#20197;&#21450;&#36793;&#30028;&#24418;&#24335;&#30340;&#32422;&#26463;&#12290;&#35813;&#26041;&#27861;&#30340;&#19968;&#20010;&#37325;&#35201;&#29305;&#28857;&#26159;&#23427;&#30340;&#35745;&#31639;&#31616;&#21333;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
A new computationally simple method of imposing hard convex constraints on the neural network output values is proposed. The key idea behind the method is to map a vector of hidden parameters of the network to a point that is guaranteed to be inside the feasible set defined by a set of constraints. The mapping is implemented by the additional neural network layer with constraints for output. The proposed method is simply extended to the case when constraints are imposed not only on the output vectors, but also on joint constraints depending on inputs. The projection approach to imposing constraints on outputs can simply be implemented in the framework of the proposed method. It is shown how to incorporate different types of constraints into the proposed method, including linear and quadratic constraints, equality constraints, and dynamic constraints, constraints in the form of boundaries. An important feature of the method is its computational simplicity. Complexities of the forward pa
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30740;&#31350;&#20102;&#20004;&#20010;&#27169;&#22411;&#30340;&#38750;&#24179;&#34913;&#24577;&#30456;&#21464;&#65292;&#24182;&#20351;&#29992;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#21644;DBSCAN&#31639;&#27861;&#30830;&#23450;&#20102;&#26377;&#21521;&#28183;&#36879;&#27169;&#22411;&#21644;&#32454;&#32990;&#33258;&#21160;&#26426;&#27169;&#22411;&#30340;&#20020;&#30028;&#28857;&#12290;</title><link>http://arxiv.org/abs/2307.10456</link><description>&lt;p&gt;
&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#30830;&#23450;&#26377;&#21521;&#28183;&#36879;&#31995;&#32479;&#30340;&#20020;&#30028;&#28857;
&lt;/p&gt;
&lt;p&gt;
Determination of the critical points for systems of directed percolation class using machine learning. (arXiv:2307.10456v1 [cond-mat.stat-mech])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10456
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30740;&#31350;&#20102;&#20004;&#20010;&#27169;&#22411;&#30340;&#38750;&#24179;&#34913;&#24577;&#30456;&#21464;&#65292;&#24182;&#20351;&#29992;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#21644;DBSCAN&#31639;&#27861;&#30830;&#23450;&#20102;&#26377;&#21521;&#28183;&#36879;&#27169;&#22411;&#21644;&#32454;&#32990;&#33258;&#21160;&#26426;&#27169;&#22411;&#30340;&#20020;&#30028;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#22312;&#30740;&#31350;&#24179;&#34913;&#24577;&#30456;&#21464;&#20013;&#34987;&#24191;&#27867;&#24212;&#29992;&#65292;&#20294;&#22312;&#38750;&#24179;&#34913;&#24577;&#30456;&#21464;&#20013;&#24212;&#29992;&#36739;&#23569;&#12290;&#26412;&#30740;&#31350;&#20351;&#29992;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#21644;&#23494;&#24230;&#22522;&#20934;&#30340;DBSCAN&#31639;&#27861;&#36827;&#34892;&#26377;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#65292;&#30740;&#31350;&#20004;&#20010;&#27169;&#22411;&#30340;&#38750;&#24179;&#34913;&#24577;&#30456;&#21464;&#12290;&#25105;&#20204;&#20998;&#21035;&#20351;&#29992;CNN&#21644;DBSCAN&#26469;&#30830;&#23450;&#26377;&#21521;&#38190;&#28183;&#36879;&#27169;&#22411;&#21644;Domany-Kinzel&#32454;&#32990;&#33258;&#21160;&#26426;&#27169;&#22411;&#30340;&#20020;&#30028;&#28857;&#12290;&#36825;&#20004;&#20010;&#27169;&#22411;&#37117;&#34987;&#35777;&#26126;&#23646;&#20110;&#26377;&#21521;&#28183;&#36879;&#26222;&#36866;&#31867;&#12290;&#22312;&#26377;&#30417;&#30563;&#23398;&#20064;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#20351;&#29992;&#20174;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#20013;&#29983;&#25104;&#30340;&#22270;&#20687;&#26469;&#35757;&#32451;CNN&#12290;&#25105;&#20204;&#20351;&#29992;&#35813;&#35757;&#32451;&#22909;&#30340;CNN&#26469;&#30740;&#31350;&#36825;&#20004;&#20010;&#27169;&#22411;&#30340;&#30456;&#21464;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, machine learning algorithms have been used remarkably to study the equilibrium phase transitions, however there are only a few works have been done using this technique in the nonequilibrium phase transitions. In this work, we use the supervised learning with the convolutional neural network (CNN) algorithm and unsupervised learning with the density-based spatial clustering of applications with noise (DBSCAN) algorithm to study the nonequilibrium phase transition in two models. We use CNN and DBSCAN in order to determine the critical points for directed bond percolation (bond DP) model and Domany-Kinzel cellular automaton (DK) model. Both models have been proven to have a nonequilibrium phase transition belongs to the directed percolation (DP) universality class. In the case of supervised learning we train CNN using the images which are generated from Monte Carlo simulations of directed bond percolation. We use that trained CNN in studding the phase transition for the two mod
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#32534;&#31243;&#26041;&#27861;&#65292;&#29992;&#20110;&#26657;&#20934;&#21644;&#39564;&#35777;&#36710;&#36742;&#36319;&#38543;&#27169;&#22411;&#65292;&#20197;&#25429;&#25417;&#21644;&#22797;&#21046;&#24037;&#20316;&#21306;&#20869;&#22806;&#30340;&#39550;&#39542;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2307.10437</link><description>&lt;p&gt;
&#29992;&#26377;&#38480;&#25968;&#25454;&#36827;&#34892;&#36125;&#21494;&#26031;&#32534;&#31243;&#26041;&#27861;&#30340;&#36710;&#36742;&#36319;&#38543;&#27169;&#22411;&#26657;&#20934;&#21644;&#39564;&#35777;
&lt;/p&gt;
&lt;p&gt;
A Bayesian Programming Approach to Car-following Model Calibration and Validation using Limited Data. (arXiv:2307.10437v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10437
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#32534;&#31243;&#26041;&#27861;&#65292;&#29992;&#20110;&#26657;&#20934;&#21644;&#39564;&#35777;&#36710;&#36742;&#36319;&#38543;&#27169;&#22411;&#65292;&#20197;&#25429;&#25417;&#21644;&#22797;&#21046;&#24037;&#20316;&#21306;&#20869;&#22806;&#30340;&#39550;&#39542;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20132;&#36890;&#20223;&#30495;&#36719;&#20214;&#34987;&#20132;&#36890;&#30740;&#31350;&#20154;&#21592;&#21644;&#24037;&#31243;&#24072;&#29992;&#20110;&#35774;&#35745;&#21644;&#35780;&#20272;&#36947;&#36335;&#21464;&#21270;&#12290;&#36825;&#20123;&#20223;&#30495;&#22120;&#30001;&#24494;&#35266;&#39550;&#39542;&#34892;&#20026;&#27169;&#22411;&#39537;&#21160;&#65292;&#21487;&#20197;&#20174;&#20013;&#25512;&#23548;&#20986;&#23439;&#35266;&#27979;&#37327;&#22914;&#27969;&#37327;&#21644;&#25317;&#22581;&#12290;&#35768;&#22810;&#27169;&#22411;&#35774;&#35745;&#29992;&#20110;&#21487;&#33021;&#30340;&#20132;&#36890;&#22330;&#26223;&#21644;&#36947;&#36335;&#37197;&#32622;&#30340;&#23376;&#38598;&#65292;&#32780;&#20854;&#20182;&#27169;&#22411;&#22312;&#24212;&#29992;&#19978;&#27809;&#26377;&#26126;&#30830;&#30340;&#38480;&#21046;&#12290;&#24037;&#20316;&#21306;&#65288;WZs&#65289;&#26159;&#19968;&#31181;&#21040;&#30446;&#21069;&#20026;&#27490;&#27809;&#26377;&#27169;&#22411;&#33021;&#22815;&#22797;&#29616;&#30495;&#23454;&#39550;&#39542;&#34892;&#20026;&#30340;&#22330;&#26223;&#12290;&#36825;&#20351;&#24471;&#22312;&#35774;&#35745;WZ&#26102;&#20248;&#21270;&#23433;&#20840;&#21644;&#20854;&#20182;&#25351;&#26631;&#21464;&#24471;&#22256;&#38590;&#12290;&#32654;&#22269;&#32852;&#37030;&#20844;&#36335;&#31649;&#29702;&#23616;&#22996;&#25176;USDOT Volpe&#20013;&#24515;&#24320;&#21457;&#19968;&#31181;&#24494;&#35266;&#20223;&#30495;&#22120;&#20013;&#33021;&#22815;&#20934;&#30830;&#25429;&#25417;&#21644;&#22797;&#21046;WZ&#20869;&#22806;&#30340;&#39550;&#39542;&#34892;&#20026;&#30340;&#36710;&#36742;&#36319;&#38543;&#65288;CF&#65289;&#27169;&#22411;&#12290;Volpe&#36824;&#36827;&#34892;&#20102;&#19968;&#39033;&#33258;&#28982;&#39550;&#39542;&#30740;&#31350;&#65292;&#25910;&#38598;&#20102;&#22312;&#20855;&#26377;WZ&#30340;&#36947;&#36335;&#19978;&#39550;&#39542;&#30340;&#36710;&#36742;&#30340;&#36965;&#27979;&#25968;&#25454;&#65292;&#29992;&#20110;&#27169;&#22411;&#26657;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
Traffic simulation software is used by transportation researchers and engineers to design and evaluate changes to roadways. These simulators are driven by models of microscopic driver behavior from which macroscopic measures like flow and congestion can be derived. Many models are designed for a subset of possible traffic scenarios and roadway configurations, while others have no explicit constraints on their application. Work zones (WZs) are one scenario for which no model to date has reproduced realistic driving behavior. This makes it difficult to optimize for safety and other metrics when designing a WZ. The Federal Highway Administration commissioned the USDOT Volpe Center to develop a car-following (CF) model for use in microscopic simulators that can capture and reproduce driver behavior accurately within and outside of WZs. Volpe also performed a naturalistic driving study to collect telematics data from vehicles driven on roads with WZs for use in model calibration. During mod
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30697;&#38453;&#38598;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#30340;&#22810;&#33218;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#20197;&#22312;&#26679;&#26412;&#37327;&#22826;&#23567;&#26080;&#27861;&#35757;&#32451;&#22810;&#33218;&#31070;&#32463;&#32593;&#32476;&#26102;&#20805;&#20998;&#36817;&#20284;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#12290;&#35813;&#26041;&#27861;&#36824;&#21487;&#20197;&#23545;&#20174;&#38271;&#30701;&#26399;&#35760;&#24518;&#32593;&#32476;&#65288;LSTM&#65289;&#33719;&#24471;&#30340;&#39044;&#27979;&#36171;&#20104;&#19981;&#30830;&#23450;&#24615;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#35206;&#30422;&#33539;&#22260;&#12290;</title><link>http://arxiv.org/abs/2307.10436</link><description>&lt;p&gt;
&#22522;&#20110;&#30697;&#38453;&#38598;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#30340;&#22810;&#33218;&#31070;&#32463;&#32593;&#32476;&#65292;&#20197;&#20805;&#20998;&#36817;&#20284;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
A Matrix Ensemble Kalman Filter-based Multi-arm Neural Network to Adequately Approximate Deep Neural Networks. (arXiv:2307.10436v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10436
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30697;&#38453;&#38598;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#30340;&#22810;&#33218;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#20197;&#22312;&#26679;&#26412;&#37327;&#22826;&#23567;&#26080;&#27861;&#35757;&#32451;&#22810;&#33218;&#31070;&#32463;&#32593;&#32476;&#26102;&#20805;&#20998;&#36817;&#20284;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#12290;&#35813;&#26041;&#27861;&#36824;&#21487;&#20197;&#23545;&#20174;&#38271;&#30701;&#26399;&#35760;&#24518;&#32593;&#32476;&#65288;LSTM&#65289;&#33719;&#24471;&#30340;&#39044;&#27979;&#36171;&#20104;&#19981;&#30830;&#23450;&#24615;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#35206;&#30422;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#32773;&#65288;DLs&#65289;&#26159;&#26368;&#20808;&#36827;&#30340;&#39044;&#27979;&#26426;&#21046;&#65292;&#22312;&#35768;&#22810;&#38656;&#35201;&#22797;&#26434;&#39640;&#32500;&#25968;&#25454;&#22788;&#29702;&#30340;&#39046;&#22495;&#20013;&#26377;&#24191;&#27867;&#24212;&#29992;&#12290;&#34429;&#28982;&#20256;&#32479;&#30340;DLs&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#21644;&#21453;&#21521;&#20256;&#25773;&#36827;&#34892;&#35757;&#32451;&#65292;&#20294;&#24050;&#32463;&#24320;&#21457;&#20986;&#20102;&#19981;&#38656;&#35201;&#26799;&#24230;&#35745;&#31639;&#30340;&#22522;&#20110;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;KF&#65289;&#30340;&#25216;&#26415;&#26469;&#36817;&#20284;DLs&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;KF&#30340;DL&#36817;&#20284;&#22120;&#30340;&#22810;&#33218;&#25193;&#23637;&#65292;&#24403;&#26679;&#26412;&#37327;&#22826;&#23567;&#26080;&#27861;&#35757;&#32451;&#22810;&#33218;DL&#26102;&#65292;&#21487;&#20197;&#27169;&#20223;DL&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#30697;&#38453;&#38598;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#22810;&#33218;ANN&#65288;MEnKF-ANN&#65289;&#36824;&#25191;&#34892;&#26174;&#24335;&#30340;&#27169;&#22411;&#22534;&#21472;&#65292;&#22312;&#35757;&#32451;&#26679;&#26412;&#20855;&#26377;&#19981;&#31561;&#23610;&#23544;&#29305;&#24449;&#38598;&#26102;&#20855;&#26377;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#25216;&#26415;&#21487;&#20197;&#36817;&#20284;&#38271;&#30701;&#26399;&#35760;&#24518;&#65288;LSTM&#65289;&#32593;&#32476;&#65292;&#24182;&#32473;&#20986;&#20174;&#36825;&#20123;LSTM&#39044;&#27979;&#20013;&#33719;&#24471;&#30340;&#20540;&#21152;&#19978;&#19981;&#30830;&#23450;&#24615;&#30340;&#29702;&#24819;&#35206;&#30422;&#33539;&#22260;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;MEnKF-ANN&#22914;&#20309;&#8220;&#20805;&#20998;&#8221;&#36817;&#20284;&#19968;&#20010;&#35757;&#32451;&#29992;&#20110;&#20998;&#31867;&#21738;&#20123;&#30899;&#27700;&#21270;&#21512;&#29289;&#22522;&#36136;&#34987;&#28040;&#21270;&#21644;&#21033;&#29992;&#30340;LSTM&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Learners (DLs) are the state-of-art predictive mechanism with applications in many fields requiring complex high dimensional data processing. Although conventional DLs get trained via gradient descent with back-propagation, Kalman Filter (KF)-based techniques that do not need gradient computation have been developed to approximate DLs. We propose a multi-arm extension of a KF-based DL approximator that can mimic DL when the sample size is too small to train a multi-arm DL. The proposed Matrix Ensemble Kalman Filter-based multi-arm ANN (MEnKF-ANN) also performs explicit model stacking that becomes relevant when the training sample has an unequal-size feature set. Our proposed technique can approximate Long Short-term Memory (LSTM) Networks and attach uncertainty to the predictions obtained from these LSTMs with desirable coverage. We demonstrate how MEnKF-ANN can "adequately" approximate an LSTM network trained to classify what carbohydrate substrates are digested and utilized by a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#25955;&#20999;&#21106;Wasserstein&#25439;&#22833;&#30340;&#24615;&#36136;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#27491;&#21017;&#24615;&#21644;&#20248;&#21270;&#24615;&#36136;&#20197;&#21450;&#36890;&#36807;&#33945;&#29305;&#21345;&#27931;&#36817;&#20284;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.10352</link><description>&lt;p&gt;
&#31163;&#25955;&#20999;&#21106;Wasserstein&#25439;&#22833;&#30340;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
Properties of Discrete Sliced Wasserstein Losses. (arXiv:2307.10352v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10352
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#25955;&#20999;&#21106;Wasserstein&#25439;&#22833;&#30340;&#24615;&#36136;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#27491;&#21017;&#24615;&#21644;&#20248;&#21270;&#24615;&#36136;&#20197;&#21450;&#36890;&#36807;&#33945;&#29305;&#21345;&#27931;&#36817;&#20284;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20999;&#21106;Wasserstein&#65288;SW&#65289;&#36317;&#31163;&#24050;&#25104;&#20026;&#27604;&#36739;&#27010;&#29575;&#27979;&#24230;&#30340;Wasserstein&#36317;&#31163;&#30340;&#19968;&#31181;&#27969;&#34892;&#26367;&#20195;&#26041;&#27861;&#12290;&#24191;&#27867;&#24212;&#29992;&#21253;&#25324;&#22270;&#20687;&#22788;&#29702;&#12289;&#39046;&#22495;&#33258;&#36866;&#24212;&#21644;&#29983;&#25104;&#24314;&#27169;&#65292;&#24120;&#24120;&#38656;&#35201;&#20248;&#21270;&#19968;&#20123;&#21442;&#25968;&#20197;&#26368;&#23567;&#21270;SW&#65292;&#35813;&#21442;&#25968;&#20805;&#24403;&#31163;&#25955;&#27010;&#29575;&#27979;&#24230;&#20043;&#38388;&#30340;&#25439;&#22833;&#20989;&#25968;&#65288;&#22240;&#20026;&#20855;&#26377;&#23494;&#24230;&#30340;&#27979;&#24230;&#22312;&#25968;&#20540;&#19978;&#26159;&#26080;&#27861;&#23454;&#29616;&#30340;&#65289;&#12290;&#25152;&#26377;&#36825;&#20123;&#20248;&#21270;&#38382;&#39064;&#37117;&#23384;&#22312;&#30456;&#21516;&#30340;&#23376;&#38382;&#39064;&#65292;&#21363;&#26368;&#23567;&#21270;&#20999;&#21106;Wasserstein&#33021;&#37327;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;$\mathcal{E}: Y \longmapsto \mathrm{SW}_2^2(\gamma_Y, \gamma_Z)$&#30340;&#23646;&#24615;&#65292;&#21363;&#20004;&#20010;&#20855;&#26377;&#19982;&#19968;&#20010;&#27979;&#24230;&#30340;&#25903;&#25745;&#30456;&#21516;&#25968;&#37327;&#30340;&#31163;&#25955;&#22343;&#21248;&#27979;&#24230;&#20043;&#38388;&#30340;SW&#36317;&#31163;&#20316;&#20026;&#25903;&#25745;$Y \in \mathbb{R}^{n \times d}$&#20989;&#25968;&#30340;&#33021;&#37327;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#36825;&#20010;&#33021;&#37327;&#30340;&#27491;&#21017;&#24615;&#21644;&#20248;&#21270;&#24615;&#36136;&#65292;&#20197;&#21450;&#20854;&#36890;&#36807;&#33945;&#29305;&#21345;&#27931;&#36817;&#20284;$\mathcal{E}_p$&#65288;&#20351;&#29992;SW&#20013;&#30340;&#26399;&#26395;&#20272;&#35745;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Sliced Wasserstein (SW) distance has become a popular alternative to the Wasserstein distance for comparing probability measures. Widespread applications include image processing, domain adaptation and generative modelling, where it is common to optimise some parameters in order to minimise SW, which serves as a loss function between discrete probability measures (since measures admitting densities are numerically unattainable). All these optimisation problems bear the same sub-problem, which is minimising the Sliced Wasserstein energy. In this paper we study the properties of $\mathcal{E}: Y \longmapsto \mathrm{SW}_2^2(\gamma_Y, \gamma_Z)$, i.e. the SW distance between two uniform discrete measures with the same amount of points as a function of the support $Y \in \mathbb{R}^{n \times d}$ of one of the measures. We investigate the regularity and optimisation properties of this energy, as well as its Monte-Carlo approximation $\mathcal{E}_p$ (estimating the expectation in SW using 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20998;&#26512;&#22810;&#31181;&#20307;&#32946;&#36187;&#20107;&#30340;&#23454;&#26102;&#35780;&#35770;&#65292;&#21033;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#33258;&#21160;&#35782;&#21035;&#20027;&#35201;&#34892;&#21160;&#65292;&#24182;&#36890;&#36807;&#20998;&#31867;&#21644;&#24773;&#24863;&#20998;&#26512;&#25552;&#21462;&#27934;&#35265;&#12290;</title><link>http://arxiv.org/abs/2307.10303</link><description>&lt;p&gt;
&#20998;&#26512;&#20307;&#32946;&#35780;&#35770;&#20197;&#23454;&#29616;&#33258;&#21160;&#35782;&#21035;&#20107;&#20214;&#24182;&#25552;&#21462;&#27934;&#35265;
&lt;/p&gt;
&lt;p&gt;
Analyzing sports commentary in order to automatically recognize events and extract insights. (arXiv:2307.10303v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10303
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20998;&#26512;&#22810;&#31181;&#20307;&#32946;&#36187;&#20107;&#30340;&#23454;&#26102;&#35780;&#35770;&#65292;&#21033;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#33258;&#21160;&#35782;&#21035;&#20027;&#35201;&#34892;&#21160;&#65292;&#24182;&#36890;&#36807;&#20998;&#31867;&#21644;&#24773;&#24863;&#20998;&#26512;&#25552;&#21462;&#27934;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20180;&#32454;&#30740;&#31350;&#20102;&#22914;&#20309;&#21033;&#29992;&#22810;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#21644;&#26041;&#27861;&#65292;&#20197;&#33258;&#21160;&#35782;&#21035;&#20307;&#32946;&#36187;&#20107;&#20013;&#30340;&#20027;&#35201;&#34892;&#21160;&#12290;&#25105;&#20204;&#36890;&#36807;&#20998;&#26512;&#19981;&#21516;&#26469;&#28304;&#30340;&#29616;&#22330;&#20307;&#32946;&#35780;&#35770;&#65292;&#24182;&#23558;&#36825;&#20123;&#20027;&#35201;&#34892;&#21160;&#20998;&#31867;&#21040;&#19981;&#21516;&#30340;&#31867;&#21035;&#20013;&#65292;&#26469;&#25552;&#21462;&#27934;&#35265;&#12290;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#24773;&#24863;&#20998;&#26512;&#26159;&#21542;&#21487;&#20197;&#24110;&#21161;&#26816;&#27979;&#36825;&#20123;&#20027;&#35201;&#34892;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we carefully investigate how we can use multiple different Natural Language Processing techniques and methods in order to automatically recognize the main actions in sports events. We aim to extract insights by analyzing live sport commentaries from different sources and by classifying these major actions into different categories. We also study if sentiment analysis could help detect these main actions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DRIG&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#35757;&#32451;&#25968;&#25454;&#20013;&#30340;&#19968;&#33324;&#24615;&#21487;&#21152;&#24178;&#39044;&#65292;&#22312;&#39044;&#27979;&#27169;&#22411;&#20013;&#32467;&#21512;&#20102;&#20869;&#20998;&#24067;&#39044;&#27979;&#21644;&#22240;&#26524;&#24615;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23545;&#26410;&#35265;&#24178;&#39044;&#30340;&#40065;&#26834;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2307.10299</link><description>&lt;p&gt;
&#22240;&#26524;&#24615;&#23548;&#21521;&#30340;&#40065;&#26834;&#24615;&#65306;&#21033;&#29992;&#19968;&#33324;&#24615;&#21487;&#21152;&#24178;&#39044;
&lt;/p&gt;
&lt;p&gt;
Causality-oriented robustness: exploiting general additive interventions. (arXiv:2307.10299v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10299
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DRIG&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#35757;&#32451;&#25968;&#25454;&#20013;&#30340;&#19968;&#33324;&#24615;&#21487;&#21152;&#24178;&#39044;&#65292;&#22312;&#39044;&#27979;&#27169;&#22411;&#20013;&#32467;&#21512;&#20102;&#20869;&#20998;&#24067;&#39044;&#27979;&#21644;&#22240;&#26524;&#24615;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23545;&#26410;&#35265;&#24178;&#39044;&#30340;&#40065;&#26834;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#22312;&#29616;&#23454;&#24212;&#29992;&#20013;&#32463;&#24120;&#21457;&#29983;&#20998;&#24067;&#21464;&#21270;&#65292;&#24613;&#38656;&#24320;&#21457;&#23545;&#36825;&#31181;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#39044;&#27979;&#27169;&#22411;&#12290;&#29616;&#26377;&#30340;&#26694;&#26550;&#65292;&#22914;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#25110;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65292;&#35201;&#20040;&#23545;&#26410;&#35265;&#20998;&#24067;&#32570;&#20047;&#36890;&#29992;&#24615;&#65292;&#35201;&#20040;&#20381;&#36182;&#20110;&#20551;&#23450;&#30340;&#36317;&#31163;&#24230;&#37327;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#22240;&#26524;&#24615;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#21644;&#32467;&#26500;&#30340;&#31283;&#20581;&#39044;&#27979;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#25152;&#38656;&#30340;&#20551;&#35774;&#21487;&#33021;&#36807;&#20110;&#20005;&#26684;&#65292;&#36825;&#31181;&#22240;&#26524;&#27169;&#22411;&#25552;&#20379;&#30340;&#40065;&#26834;&#24615;&#24120;&#24120;&#32570;&#20047;&#28789;&#27963;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#22240;&#26524;&#24615;&#23548;&#21521;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DRIG&#65288;Distributional Robustness via Invariant Gradients&#65289;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#35757;&#32451;&#25968;&#25454;&#20013;&#30340;&#19968;&#33324;&#24615;&#21487;&#21152;&#24178;&#39044;&#65292;&#20197;&#23454;&#29616;&#23545;&#26410;&#35265;&#24178;&#39044;&#30340;&#40065;&#26834;&#39044;&#27979;&#65292;&#24182;&#22312;&#20869;&#20998;&#24067;&#39044;&#27979;&#21644;&#22240;&#26524;&#24615;&#20043;&#38388;&#33258;&#28982;&#22320;&#36827;&#34892;&#25554;&#20540;&#12290;&#22312;&#32447;&#24615;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;DRIG&#20135;&#29983;&#30340;&#39044;&#27979;&#26159;
&lt;/p&gt;
&lt;p&gt;
Since distribution shifts are common in real-world applications, there is a pressing need for developing prediction models that are robust against such shifts. Existing frameworks, such as empirical risk minimization or distributionally robust optimization, either lack generalizability for unseen distributions or rely on postulated distance measures. Alternatively, causality offers a data-driven and structural perspective to robust predictions. However, the assumptions necessary for causal inference can be overly stringent, and the robustness offered by such causal models often lacks flexibility. In this paper, we focus on causality-oriented robustness and propose Distributional Robustness via Invariant Gradients (DRIG), a method that exploits general additive interventions in training data for robust predictions against unseen interventions, and naturally interpolates between in-distribution prediction and causality. In a linear setting, we prove that DRIG yields predictions that are 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;IPW&#30340;&#26080;&#20559;&#25490;&#24207;&#24230;&#37327;&#26041;&#27861;&#65292;&#38024;&#23545;&#21452;&#36793;&#24066;&#22330;&#20013;&#29992;&#25143;&#20043;&#38388;&#30340;&#20559;&#35265;&#30456;&#20114;&#20316;&#29992;&#65292;&#35299;&#20915;&#20102;&#20301;&#32622;&#20559;&#35265;&#21644;&#20004;&#20010;&#29992;&#25143;&#32676;&#20307;&#30340;&#20301;&#32622;&#20559;&#24046;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.10204</link><description>&lt;p&gt;
&#22522;&#20110;IPW&#30340;&#21452;&#36793;&#24066;&#22330;&#20013;&#30340;&#26080;&#20559;&#25490;&#24207;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
An IPW-based Unbiased Ranking Metric in Two-sided Markets. (arXiv:2307.10204v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10204
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;IPW&#30340;&#26080;&#20559;&#25490;&#24207;&#24230;&#37327;&#26041;&#27861;&#65292;&#38024;&#23545;&#21452;&#36793;&#24066;&#22330;&#20013;&#29992;&#25143;&#20043;&#38388;&#30340;&#20559;&#35265;&#30456;&#20114;&#20316;&#29992;&#65292;&#35299;&#20915;&#20102;&#20301;&#32622;&#20559;&#35265;&#21644;&#20004;&#20010;&#29992;&#25143;&#32676;&#20307;&#30340;&#20301;&#32622;&#20559;&#24046;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#20195;&#25512;&#33616;&#31995;&#32479;&#20013;&#65292;&#26080;&#20559;&#23398;&#20064;&#25490;&#24207;&#65288;LTR&#65289;&#23545;&#20110;&#20248;&#20808;&#32771;&#34385;&#26469;&#33258;&#26377;&#20559;&#30340;&#38544;&#24335;&#29992;&#25143;&#21453;&#39304;&#65288;&#22914;&#28857;&#20987;&#25968;&#25454;&#65289;&#30340;&#39033;&#30446;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#19968;&#20123;&#25216;&#26415;&#65292;&#20363;&#22914;&#20498;&#25968;&#20542;&#21521;&#24615;&#21152;&#26435;&#65288;IPW&#65289;&#65292;&#29992;&#20110;&#21333;&#36793;&#24066;&#22330;&#12290;&#28982;&#32780;&#65292;&#22312;&#21452;&#36793;&#24066;&#22330;&#65288;&#22914;&#24037;&#20316;&#24179;&#21488;&#25110;&#32422;&#20250;&#26381;&#21153;&#65289;&#20013;&#65292;&#25104;&#21151;&#36716;&#21270;&#38656;&#35201;&#21305;&#37197;&#20004;&#20010;&#29992;&#25143;&#30340;&#20559;&#22909;&#65292;&#20294;&#23545;&#20110;&#36825;&#31181;&#24773;&#20917;&#20851;&#27880;&#36739;&#23569;&#12290;&#26412;&#25991;&#35299;&#20915;&#20102;&#21452;&#36793;&#24066;&#22330;&#20013;&#29992;&#25143;&#20043;&#38388;&#30340;&#20559;&#35265;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#29305;&#23450;&#30340;LTR&#26041;&#27861;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#21452;&#36793;&#21305;&#37197;&#24179;&#21488;&#20013;&#21453;&#39304;&#26426;&#21046;&#30340;&#24418;&#24335;&#21270;&#65292;&#24182;&#25351;&#20986;&#23427;&#20204;&#30340;&#38544;&#24335;&#21453;&#39304;&#21487;&#33021;&#21253;&#21547;&#26469;&#33258;&#20004;&#20010;&#29992;&#25143;&#32676;&#20307;&#30340;&#20301;&#32622;&#20559;&#24046;&#12290;&#22522;&#20110;&#36825;&#19968;&#35266;&#23519;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;IPW&#20272;&#35745;&#22120;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20272;&#35745;&#22120;&#65292;&#31216;&#20026;&#21452;&#36793;IPW&#65292;&#20197;&#35299;&#20915;&#21452;&#36793;&#24066;&#22330;&#20013;&#30340;&#20301;&#32622;&#20559;&#35265;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#20272;&#35745;&#22120;&#28385;&#36275;&#30495;&#23454;&#25490;&#21517;&#30340;&#26080;&#20559;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In modern recommendation systems, unbiased learning-to-rank (LTR) is crucial for prioritizing items from biased implicit user feedback, such as click data. Several techniques, such as Inverse Propensity Weighting (IPW), have been proposed for single-sided markets. However, less attention has been paid to two-sided markets, such as job platforms or dating services, where successful conversions require matching preferences from both users. This paper addresses the complex interaction of biases between users in two-sided markets and proposes a tailored LTR approach. We first present a formulation of feedback mechanisms in two-sided matching platforms and point out that their implicit feedback may include position bias from both user groups. On the basis of this observation, we extend the IPW estimator and propose a new estimator, named two-sided IPW, to address the position bases in two-sided markets. We prove that the proposed estimator satisfies the unbiasedness for the ground-truth ran
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#37325;&#35201;&#24615;&#37319;&#26679;&#36827;&#34892;&#38544;&#31169;&#25918;&#22823;&#65292;&#21487;&#20197;&#21516;&#26102;&#22686;&#24378;&#38544;&#31169;&#20445;&#25252;&#21644;&#25552;&#39640;&#25928;&#29992;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#19968;&#33324;&#30340;&#32467;&#26524;&#26469;&#37327;&#21270;&#36873;&#25321;&#27010;&#29575;&#26435;&#37325;&#23545;&#38544;&#31169;&#25918;&#22823;&#30340;&#24433;&#21709;&#65292;&#24182;&#23637;&#31034;&#20102;&#24322;&#36136;&#37319;&#26679;&#27010;&#29575;&#21487;&#20197;&#22312;&#20445;&#25345;&#23376;&#37319;&#26679;&#22823;&#23567;&#19981;&#21464;&#30340;&#24773;&#20917;&#19979;&#33719;&#24471;&#26356;&#22909;&#30340;&#38544;&#31169;&#21644;&#25928;&#29992;&#12290;</title><link>http://arxiv.org/abs/2307.10187</link><description>&lt;p&gt;
&#38544;&#31169;&#25918;&#22823;&#36890;&#36807;&#37325;&#35201;&#24615;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Privacy Amplification via Importance Sampling. (arXiv:2307.10187v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10187
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#37325;&#35201;&#24615;&#37319;&#26679;&#36827;&#34892;&#38544;&#31169;&#25918;&#22823;&#65292;&#21487;&#20197;&#21516;&#26102;&#22686;&#24378;&#38544;&#31169;&#20445;&#25252;&#21644;&#25552;&#39640;&#25928;&#29992;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#19968;&#33324;&#30340;&#32467;&#26524;&#26469;&#37327;&#21270;&#36873;&#25321;&#27010;&#29575;&#26435;&#37325;&#23545;&#38544;&#31169;&#25918;&#22823;&#30340;&#24433;&#21709;&#65292;&#24182;&#23637;&#31034;&#20102;&#24322;&#36136;&#37319;&#26679;&#27010;&#29575;&#21487;&#20197;&#22312;&#20445;&#25345;&#23376;&#37319;&#26679;&#22823;&#23567;&#19981;&#21464;&#30340;&#24773;&#20917;&#19979;&#33719;&#24471;&#26356;&#22909;&#30340;&#38544;&#31169;&#21644;&#25928;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#36890;&#36807;&#37325;&#35201;&#24615;&#37319;&#26679;&#23545;&#25968;&#25454;&#38598;&#36827;&#34892;&#23376;&#37319;&#26679;&#20316;&#20026;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#30340;&#39044;&#22788;&#29702;&#27493;&#39588;&#26469;&#22686;&#24378;&#38544;&#31169;&#20445;&#25252;&#30340;&#24615;&#36136;&#12290;&#36825;&#25193;&#23637;&#20102;&#24050;&#26377;&#30340;&#36890;&#36807;&#23376;&#37319;&#26679;&#36827;&#34892;&#38544;&#31169;&#25918;&#22823;&#30340;&#32467;&#26524;&#21040;&#37325;&#35201;&#24615;&#37319;&#26679;&#65292;&#20854;&#20013;&#27599;&#20010;&#25968;&#25454;&#28857;&#30340;&#26435;&#37325;&#20026;&#20854;&#34987;&#36873;&#25321;&#27010;&#29575;&#30340;&#20498;&#25968;&#12290;&#27599;&#20010;&#28857;&#30340;&#36873;&#25321;&#27010;&#29575;&#30340;&#26435;&#37325;&#23545;&#38544;&#31169;&#30340;&#24433;&#21709;&#24182;&#19981;&#26126;&#26174;&#12290;&#19968;&#26041;&#38754;&#65292;&#36739;&#20302;&#30340;&#36873;&#25321;&#27010;&#29575;&#20250;&#23548;&#33268;&#26356;&#24378;&#30340;&#38544;&#31169;&#25918;&#22823;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#26435;&#37325;&#36234;&#39640;&#65292;&#22312;&#28857;&#34987;&#36873;&#25321;&#26102;&#65292;&#28857;&#23545;&#26426;&#21046;&#36755;&#20986;&#30340;&#24433;&#21709;&#23601;&#36234;&#24378;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#19968;&#33324;&#30340;&#32467;&#26524;&#26469;&#37327;&#21270;&#36825;&#20004;&#20010;&#24433;&#21709;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24322;&#36136;&#37319;&#26679;&#27010;&#29575;&#21487;&#20197;&#21516;&#26102;&#27604;&#22343;&#21248;&#23376;&#37319;&#26679;&#20855;&#26377;&#26356;&#24378;&#30340;&#38544;&#31169;&#21644;&#26356;&#22909;&#30340;&#25928;&#29992;&#65292;&#24182;&#20445;&#25345;&#23376;&#37319;&#26679;&#22823;&#23567;&#19981;&#21464;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#21046;&#23450;&#21644;&#35299;&#20915;&#20102;&#38544;&#31169;&#20248;&#21270;&#37319;&#26679;&#30340;&#38382;&#39064;&#65292;&#21363;&#23547;&#25214;...
&lt;/p&gt;
&lt;p&gt;
We examine the privacy-enhancing properties of subsampling a data set via importance sampling as a pre-processing step for differentially private mechanisms. This extends the established privacy amplification by subsampling result to importance sampling where each data point is weighted by the reciprocal of its selection probability. The implications for privacy of weighting each point are not obvious. On the one hand, a lower selection probability leads to a stronger privacy amplification. On the other hand, the higher the weight, the stronger the influence of the point on the output of the mechanism in the event that the point does get selected. We provide a general result that quantifies the trade-off between these two effects. We show that heterogeneous sampling probabilities can lead to both stronger privacy and better utility than uniform subsampling while retaining the subsample size. In particular, we formulate and solve the problem of privacy-optimal sampling, that is, finding
&lt;/p&gt;</description></item><item><title>&#36825;&#37324;&#26159;&#20013;&#25991;&#24635;&#32467;&#20986;&#30340;&#19968;&#21477;&#35805;&#35201;&#28857;&#65306;&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#25552;&#39640;&#29992;&#25143;&#38271;&#26399;&#28385;&#24847;&#24230;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#24320;&#21457;&#19968;&#20010;&#39044;&#27979;&#24310;&#36831;&#22870;&#21169;&#30340;&#27169;&#22411;&#21644;&#35774;&#35745;&#19968;&#20010;&#21033;&#29992;&#35813;&#27169;&#22411;&#30340;&#36172;&#21338;&#31639;&#27861;&#26469;&#35299;&#20915;&#20102;&#36890;&#36807;&#27979;&#37327;&#30701;&#26399;&#20195;&#29702;&#22870;&#21169;&#21453;&#26144;&#23454;&#38469;&#38271;&#26399;&#30446;&#26631;&#19981;&#23436;&#32654;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2307.09943</link><description>&lt;p&gt;
&#36825;&#37324;&#26159;&#32763;&#35793;&#36807;&#30340;&#35770;&#25991;&#26631;&#39064;: &#36807;&#21435;&#26366;&#32763;&#35793;&#12298;Impatient Bandits: Optimizing for the Long-Term Without Delay&#12299;
&lt;/p&gt;
&lt;p&gt;
Impatient Bandits: Optimizing for the Long-Term Without Delay. (arXiv:2307.09943v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09943
&lt;/p&gt;
&lt;p&gt;
&#36825;&#37324;&#26159;&#20013;&#25991;&#24635;&#32467;&#20986;&#30340;&#19968;&#21477;&#35805;&#35201;&#28857;&#65306;&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#25552;&#39640;&#29992;&#25143;&#38271;&#26399;&#28385;&#24847;&#24230;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#24320;&#21457;&#19968;&#20010;&#39044;&#27979;&#24310;&#36831;&#22870;&#21169;&#30340;&#27169;&#22411;&#21644;&#35774;&#35745;&#19968;&#20010;&#21033;&#29992;&#35813;&#27169;&#22411;&#30340;&#36172;&#21338;&#31639;&#27861;&#26469;&#35299;&#20915;&#20102;&#36890;&#36807;&#27979;&#37327;&#30701;&#26399;&#20195;&#29702;&#22870;&#21169;&#21453;&#26144;&#23454;&#38469;&#38271;&#26399;&#30446;&#26631;&#19981;&#23436;&#32654;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#37324;&#26159;&#32763;&#35793;&#36807;&#30340;&#35770;&#25991;&#25688;&#35201;&#65306;&#25512;&#33616;&#31995;&#32479;&#22312;&#22312;&#32447;&#24179;&#21488;&#19978;&#26159;&#19968;&#20010;&#26222;&#36941;&#23384;&#22312;&#30340;&#21151;&#33021;&#12290;&#36234;&#26469;&#36234;&#22810;&#30340;&#24773;&#20917;&#19979;&#65292;&#23427;&#20204;&#26126;&#30830;&#22320;&#34987;&#20219;&#21153;&#20026;&#25552;&#39640;&#29992;&#25143;&#30340;&#38271;&#26399;&#28385;&#24847;&#24230;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#20869;&#23481;&#25506;&#32034;&#20219;&#21153;&#65292;&#23558;&#20854;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#20855;&#26377;&#24310;&#36831;&#22870;&#21169;&#30340;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#22312;&#36873;&#25321;&#23398;&#20064;&#20449;&#21495;&#26102;&#23384;&#22312;&#26126;&#26174;&#30340;&#26435;&#34913;&#65306;&#31561;&#24453;&#23436;&#20840;&#30340;&#22870;&#21169;&#21487;&#33021;&#38656;&#35201;&#20960;&#21608;&#26102;&#38388;&#65292;&#36825;&#20250;&#24433;&#21709;&#23398;&#20064;&#21457;&#29983;&#30340;&#36895;&#24230;&#65292;&#32780;&#27979;&#37327;&#30701;&#26399;&#20195;&#29702;&#22870;&#21169;&#21017;&#19981;&#23436;&#32654;&#22320;&#21453;&#26144;&#20102;&#23454;&#38469;&#30340;&#38271;&#26399;&#30446;&#26631;&#12290;&#25105;&#20204;&#36890;&#36807;&#20004;&#20010;&#27493;&#39588;&#26469;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#39044;&#27979;&#24310;&#36831;&#22870;&#21169;&#30340;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#25972;&#21512;&#36804;&#20170;&#25152;&#33719;&#24471;&#30340;&#25152;&#26377;&#20449;&#24687;&#12290;&#36890;&#36807;&#36125;&#21494;&#26031;&#28388;&#27874;&#22120;&#32452;&#21512;&#23436;&#25972;&#30340;&#35266;&#23519;&#32467;&#26524;&#20197;&#21450;&#37096;&#20998;&#65288;&#30701;&#26399;&#25110;&#20013;&#26399;&#65289;&#30340;&#32467;&#26524;&#65292;&#20174;&#32780;&#24471;&#21040;&#27010;&#29575;&#20449;&#24565;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#21033;&#29992;&#36825;&#20010;&#26032;&#30340;&#39044;&#27979;&#27169;&#22411;&#30340;&#36172;&#21338;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#21487;&#20197;&#24555;&#36895;&#23398;&#20064;&#35782;&#21035;&#20869;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems are a ubiquitous feature of online platforms. Increasingly, they are explicitly tasked with increasing users' long-term satisfaction. In this context, we study a content exploration task, which we formalize as a multi-armed bandit problem with delayed rewards. We observe that there is an apparent trade-off in choosing the learning signal: Waiting for the full reward to become available might take several weeks, hurting the rate at which learning happens, whereas measuring short-term proxy rewards reflects the actual long-term goal only imperfectly. We address this challenge in two steps. First, we develop a predictive model of delayed rewards that incorporates all information obtained to date. Full observations as well as partial (short or medium-term) outcomes are combined through a Bayesian filter to obtain a probabilistic belief. Second, we devise a bandit algorithm that takes advantage of this new predictive model. The algorithm quickly learns to identify conten
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#35270;&#35282;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#22810;&#21464;&#37327;&#36890;&#36947;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#20043;&#38388;&#36827;&#34892;&#36801;&#31227;&#23398;&#20064;&#12290;&#36890;&#36807;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#65292;&#32467;&#21512;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#21644;TS2Vec&#25439;&#22833;&#65292;&#35813;&#26041;&#27861;&#22312;&#22823;&#22810;&#25968;&#35774;&#32622;&#19979;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.09614</link><description>&lt;p&gt;
&#22810;&#35270;&#35282;&#33258;&#30417;&#30563;&#23398;&#20064;&#29992;&#20110;&#22810;&#21464;&#37327;&#36890;&#36947;&#26102;&#38388;&#24207;&#21015;
&lt;/p&gt;
&lt;p&gt;
Multi-view self-supervised learning for multivariate variable-channel time series. (arXiv:2307.09614v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.09614
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#35270;&#35282;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#22810;&#21464;&#37327;&#36890;&#36947;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#20043;&#38388;&#36827;&#34892;&#36801;&#31227;&#23398;&#20064;&#12290;&#36890;&#36807;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#65292;&#32467;&#21512;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#21644;TS2Vec&#25439;&#22833;&#65292;&#35813;&#26041;&#27861;&#22312;&#22823;&#22810;&#25968;&#35774;&#32622;&#19979;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#22810;&#21464;&#37327;&#29983;&#29289;&#21307;&#23398;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#36827;&#34892;&#26631;&#27880;&#26159;&#19968;&#39033;&#32321;&#37325;&#21644;&#26114;&#36149;&#30340;&#20219;&#21153;&#12290;&#33258;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#36890;&#36807;&#23545;&#26410;&#26631;&#35760;&#25968;&#25454;&#36827;&#34892;&#39044;&#35757;&#32451;&#26469;&#20943;&#23569;&#23545;&#22823;&#22411;&#26631;&#35760;&#25968;&#25454;&#38598;&#30340;&#38656;&#27714;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#36755;&#20837;&#36890;&#36947;&#30340;&#38598;&#21512;&#22312;&#19981;&#21516;&#24212;&#29992;&#20043;&#38388;&#36890;&#24120;&#20250;&#26377;&#25152;&#21464;&#21270;&#65292;&#32780;&#22823;&#22810;&#25968;&#29616;&#26377;&#24037;&#20316;&#24182;&#19981;&#20801;&#35768;&#22312;&#20855;&#26377;&#19981;&#21516;&#36755;&#20837;&#36890;&#36947;&#38598;&#21512;&#30340;&#25968;&#25454;&#38598;&#20043;&#38388;&#36827;&#34892;&#36801;&#31227;&#23398;&#20064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#19968;&#31181;&#32534;&#30721;&#22120;&#26469;&#20998;&#21035;&#22788;&#29702;&#25152;&#26377;&#36755;&#20837;&#36890;&#36947;&#30340;&#26041;&#27861;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#22312;&#36890;&#36947;&#20043;&#38388;&#25552;&#21462;&#21333;&#19968;&#34920;&#31034;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#19968;&#20010;&#20855;&#26377;&#20845;&#20010;&#33041;&#30005;&#22270;&#36890;&#36947;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#65292;&#24182;&#22312;&#19968;&#20010;&#20855;&#26377;&#20004;&#20010;&#19981;&#21516;&#33041;&#30005;&#22270;&#36890;&#36947;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#24494;&#35843;&#26469;&#23637;&#31034;&#36825;&#31181;&#26041;&#27861;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#20855;&#26377;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#21644;&#19981;&#20855;&#26377;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#30340;&#32593;&#32476;&#22312;&#19981;&#21516;&#23545;&#27604;&#25439;&#22833;&#20989;&#25968;&#19979;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#21457;&#29616;&#25105;&#20204;&#30340;&#26041;&#27861;&#32467;&#21512;&#20102;TS2Vec&#25439;&#22833;&#22312;&#22823;&#22810;&#25968;&#35774;&#32622;&#20013;&#30340;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#25152;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Labeling of multivariate biomedical time series data is a laborious and expensive process. Self-supervised contrastive learning alleviates the need for large, labeled datasets through pretraining on unlabeled data. However, for multivariate time series data the set of input channels often varies between applications, and most existing work does not allow for transfer between datasets with different sets of input channels. We propose learning one encoder to operate on all input channels individually. We then use a message passing neural network to extract a single representation across channels. We demonstrate the potential of this method by pretraining our network on a dataset with six EEG channels and finetuning on a dataset with two different EEG channels. We compare networks with and without the message passing neural network across different contrastive loss functions. We show that our method combined with the TS2Vec loss outperforms all other methods in most settings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#38543;&#26426;&#39640;&#26031;&#26435;&#37325;&#21644;&#20559;&#32622;&#30340;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#24067;&#65292;&#24471;&#21040;&#20102;&#22312;&#22823;&#20294;&#26377;&#38480;&#30340; $n$ &#21644;&#20219;&#24847;&#22266;&#23450;&#32593;&#32476;&#28145;&#24230;&#19979;&#25104;&#31435;&#30340;&#27491;&#24577;&#36924;&#36817;&#30340;&#23450;&#37327;&#30028;&#38480;&#65292;&#35777;&#26126;&#20102;&#38543;&#26426;&#20840;&#36830;&#25509;&#32593;&#32476;&#19982;&#30456;&#24212;&#30340;&#26080;&#38480;&#23485;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#36317;&#31163;&#25353;&#29031; $n^{-\gamma}$ &#32553;&#25918;&#65292;&#30028;&#38480;&#22312;&#32593;&#32476;&#23485;&#24230;&#30340;&#20381;&#36182;&#24615;&#26041;&#38754;&#20248;&#20110;&#20197;&#21069;&#30340;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2307.06092</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#23450;&#37327;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;
&lt;/p&gt;
&lt;p&gt;
Quantitative CLTs in Deep Neural Networks. (arXiv:2307.06092v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06092
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#38543;&#26426;&#39640;&#26031;&#26435;&#37325;&#21644;&#20559;&#32622;&#30340;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#24067;&#65292;&#24471;&#21040;&#20102;&#22312;&#22823;&#20294;&#26377;&#38480;&#30340; $n$ &#21644;&#20219;&#24847;&#22266;&#23450;&#32593;&#32476;&#28145;&#24230;&#19979;&#25104;&#31435;&#30340;&#27491;&#24577;&#36924;&#36817;&#30340;&#23450;&#37327;&#30028;&#38480;&#65292;&#35777;&#26126;&#20102;&#38543;&#26426;&#20840;&#36830;&#25509;&#32593;&#32476;&#19982;&#30456;&#24212;&#30340;&#26080;&#38480;&#23485;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#36317;&#31163;&#25353;&#29031; $n^{-\gamma}$ &#32553;&#25918;&#65292;&#30028;&#38480;&#22312;&#32593;&#32476;&#23485;&#24230;&#30340;&#20381;&#36182;&#24615;&#26041;&#38754;&#20248;&#20110;&#20197;&#21069;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#38543;&#26426;&#39640;&#26031;&#26435;&#37325;&#21644;&#20559;&#32622;&#30340;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#24067;&#65292;&#20854;&#20013;&#38544;&#34255;&#23618;&#23485;&#24230;&#19982;&#22823;&#24120;&#25968; $n$ &#25104;&#27604;&#20363;&#12290;&#22312;&#38750;&#32447;&#24615;&#30340;&#28201;&#21644;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#22312;&#22823;&#20294;&#26377;&#38480;&#30340; $n$ &#21644;&#20219;&#24847;&#22266;&#23450;&#32593;&#32476;&#28145;&#24230;&#19979;&#25104;&#31435;&#30340;&#27491;&#24577;&#36924;&#36817;&#30340;&#23450;&#37327;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#23450;&#29702;&#34920;&#26126;&#65292;&#26080;&#35770;&#26159;&#23545;&#20110;&#26377;&#38480;&#32500;&#20998;&#24067;&#36824;&#26159;&#25972;&#20010;&#36807;&#31243;&#65292;&#38543;&#26426;&#20840;&#36830;&#25509;&#32593;&#32476;&#65288;&#21450;&#20854;&#23548;&#25968;&#65289;&#19982;&#30456;&#24212;&#30340;&#26080;&#38480;&#23485;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#36317;&#31163;&#37117;&#20250;&#25353;&#29031; $n^{-\gamma}$ &#32553;&#25918;&#65292;&#20854;&#20013; $\gamma&gt;0$&#65292;&#25351;&#25968;&#21462;&#20915;&#20110;&#29992;&#20110;&#24230;&#37327;&#24046;&#24322;&#30340;&#24230;&#37327;&#26041;&#24335;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#22312;&#32593;&#32476;&#23485;&#24230;&#30340;&#20381;&#36182;&#24615;&#26041;&#38754;&#27604;&#25991;&#29486;&#20013;&#20197;&#21069;&#25552;&#20379;&#30340;&#20219;&#20309;&#30028;&#38480;&#37117;&#35201;&#24378;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the distribution of a fully connected neural network with random Gaussian weights and biases in which the hidden layer widths are proportional to a large constant $n$. Under mild assumptions on the non-linearity, we obtain quantitative bounds on normal approximations valid at large but finite $n$ and any fixed network depth. Our theorems show, both for the finite-dimensional distributions and the entire process, that the distance between a random fully connected network (and its derivatives) to the corresponding infinite width Gaussian process scales like $n^{-\gamma}$ for $\gamma&gt;0,$ with the exponent depending on the metric used to measure discrepancy. Our bounds are stronger in terms of their dependence on network width than any previously available in the literature.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#31283;&#20581;&#23494;&#24230;&#21151;&#29575;&#20998;&#27495;&#65288;DPD&#65289;&#22312;&#19968;&#33324;&#21442;&#25968;&#23494;&#24230;&#27169;&#22411;&#20013;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#24212;&#29992;&#20256;&#32479;&#30340;&#38543;&#26426;&#20248;&#21270;&#29702;&#35770;&#26469;&#39564;&#35777;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.05251</link><description>&lt;p&gt;
&#29992;&#20110;&#19968;&#33324;&#21442;&#25968;&#23494;&#24230;&#27169;&#22411;&#30340;&#26368;&#23567;&#21270;&#31283;&#20581;&#23494;&#24230;&#21151;&#29575;&#20998;&#27495;&#30340;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A stochastic optimization approach to minimize robust density power-based divergences for general parametric density models. (arXiv:2307.05251v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05251
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#31283;&#20581;&#23494;&#24230;&#21151;&#29575;&#20998;&#27495;&#65288;DPD&#65289;&#22312;&#19968;&#33324;&#21442;&#25968;&#23494;&#24230;&#27169;&#22411;&#20013;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#24212;&#29992;&#20256;&#32479;&#30340;&#38543;&#26426;&#20248;&#21270;&#29702;&#35770;&#26469;&#39564;&#35777;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23494;&#24230;&#21151;&#29575;&#20998;&#27495;&#65288;DPD&#65289;&#26159;&#19968;&#31181;&#29992;&#20110;&#31283;&#20581;&#22320;&#20272;&#35745;&#35266;&#27979;&#25968;&#25454;&#28508;&#22312;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#23427;&#21253;&#25324;&#19968;&#20010;&#35201;&#20272;&#35745;&#30340;&#21442;&#25968;&#23494;&#24230;&#27169;&#22411;&#30340;&#24130;&#30340;&#31215;&#20998;&#39033;&#12290;&#34429;&#28982;&#23545;&#20110;&#19968;&#20123;&#29305;&#23450;&#30340;&#23494;&#24230;&#65288;&#22914;&#27491;&#24577;&#23494;&#24230;&#21644;&#25351;&#25968;&#23494;&#24230;&#65289;&#21487;&#20197;&#24471;&#21040;&#31215;&#20998;&#39033;&#30340;&#26174;&#24335;&#24418;&#24335;&#65292;&#20294;DPD&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#20351;&#24471;&#20854;&#26080;&#27861;&#24212;&#29992;&#20110;&#26356;&#19968;&#33324;&#30340;&#21442;&#25968;&#23494;&#24230;&#27169;&#22411;&#65292;&#36825;&#24050;&#32463;&#36229;&#36807;&#20102;DPD&#25552;&#20986;&#30340;25&#24180;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#19968;&#33324;&#21442;&#25968;&#23494;&#24230;&#27169;&#22411;&#26368;&#23567;&#21270;DPD&#30340;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#21442;&#32771;&#38543;&#26426;&#20248;&#21270;&#30340;&#20256;&#32479;&#29702;&#35770;&#35828;&#26126;&#20102;&#20854;&#36866;&#29992;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#36824;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#26410;&#24402;&#19968;&#21270;&#27169;&#22411;&#26469;&#26368;&#23567;&#21270;&#21478;&#19968;&#20010;&#22522;&#20110;&#23494;&#24230;&#21151;&#29575;&#30340;&#947;-&#31163;&#24046;[Kanamori&#21644;Fujisawa&#65288;2015&#65289;&#65292;Biometrika]&#12290;
&lt;/p&gt;
&lt;p&gt;
Density power divergence (DPD) [Basu et al. (1998), Biometrika], designed to estimate the underlying distribution of the observations robustly, comprises an integral term of the power of the parametric density models to be estimated. While the explicit form of the integral term can be obtained for some specific densities (such as normal density and exponential density), its computational intractability has prohibited the application of DPD-based estimation to more general parametric densities, over a quarter of a century since the proposal of DPD. This study proposes a stochastic optimization approach to minimize DPD for general parametric density models and explains its adequacy by referring to conventional theories on stochastic optimization. The proposed approach also can be applied to the minimization of another density power-based $\gamma$-divergence with the aid of unnormalized models [Kanamori and Fujisawa (2015), Biometrika].
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#31995;&#32479;&#30740;&#31350;&#27969;&#24335;&#21644;&#27744;&#24335;&#20027;&#21160;&#23398;&#20064;&#19979;&#30340;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31561;&#25928;&#25439;&#22833;&#30340;&#27010;&#24565;&#65292;&#24182;&#35777;&#26126;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#31639;&#27861;&#23454;&#36136;&#19978;&#26159;&#38024;&#23545;&#35813;&#31561;&#25928;&#25439;&#22833;&#36827;&#34892;&#20248;&#21270;&#12290;</title><link>http://arxiv.org/abs/2307.02719</link><description>&lt;p&gt;
&#29702;&#35299;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Understanding Uncertainty Sampling. (arXiv:2307.02719v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02719
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#31995;&#32479;&#30740;&#31350;&#27969;&#24335;&#21644;&#27744;&#24335;&#20027;&#21160;&#23398;&#20064;&#19979;&#30340;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31561;&#25928;&#25439;&#22833;&#30340;&#27010;&#24565;&#65292;&#24182;&#35777;&#26126;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#31639;&#27861;&#23454;&#36136;&#19978;&#26159;&#38024;&#23545;&#35813;&#31561;&#25928;&#25439;&#22833;&#36827;&#34892;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#26159;&#19968;&#31181;&#24120;&#35265;&#30340;&#20027;&#21160;&#23398;&#20064;&#31639;&#27861;&#65292;&#23427;&#39034;&#24207;&#22320;&#26597;&#35810;&#24403;&#21069;&#39044;&#27979;&#27169;&#22411;&#23545;&#25968;&#25454;&#26679;&#26412;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#28982;&#32780;&#65292;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#30340;&#20351;&#29992;&#24448;&#24448;&#26159;&#21551;&#21457;&#24335;&#30340;&#65306;&#65288;i&#65289;&#20851;&#20110;&#22312;&#29305;&#23450;&#20219;&#21153;&#21644;&#29305;&#23450;&#25439;&#22833;&#20989;&#25968;&#19979;&#23545;&#8220;&#19981;&#30830;&#23450;&#24615;&#8221;&#30340;&#20934;&#30830;&#23450;&#20041;&#27809;&#26377;&#20849;&#35782;&#65307;&#65288;ii&#65289;&#27809;&#26377;&#29702;&#35770;&#20445;&#35777;&#33021;&#22815;&#32473;&#20986;&#19968;&#20010;&#26631;&#20934;&#21327;&#35758;&#26469;&#23454;&#26045;&#35813;&#31639;&#27861;&#65292;&#20363;&#22914;&#65292;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31561;&#20248;&#21270;&#31639;&#27861;&#26694;&#26550;&#19979;&#22914;&#20309;&#22788;&#29702;&#39034;&#24207;&#21040;&#36798;&#30340;&#27880;&#37322;&#25968;&#25454;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#31995;&#32479;&#22320;&#30740;&#31350;&#20102;&#27969;&#24335;&#21644;&#27744;&#24335;&#20027;&#21160;&#23398;&#20064;&#19979;&#30340;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#31639;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31561;&#25928;&#25439;&#22833;&#30340;&#27010;&#24565;&#65292;&#35813;&#27010;&#24565;&#21462;&#20915;&#20110;&#20351;&#29992;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#21644;&#21407;&#22987;&#25439;&#22833;&#20989;&#25968;&#65292;&#24182;&#30830;&#31435;&#20102;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#31639;&#27861;&#26412;&#36136;&#19978;&#26159;&#38024;&#23545;&#36825;&#31181;&#31561;&#25928;&#25439;&#22833;&#36827;&#34892;&#20248;&#21270;&#12290;&#36825;&#19968;&#35266;&#28857;&#39564;&#35777;&#20102;&#31639;&#27861;&#30340;&#36866;&#24403;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty sampling is a prevalent active learning algorithm that queries sequentially the annotations of data samples which the current prediction model is uncertain about. However, the usage of uncertainty sampling has been largely heuristic: (i) There is no consensus on the proper definition of "uncertainty" for a specific task under a specific loss; (ii) There is no theoretical guarantee that prescribes a standard protocol to implement the algorithm, for example, how to handle the sequentially arrived annotated data under the framework of optimization algorithms such as stochastic gradient descent. In this work, we systematically examine uncertainty sampling algorithms under both stream-based and pool-based active learning. We propose a notion of equivalent loss which depends on the used uncertainty measure and the original loss function and establish that an uncertainty sampling algorithm essentially optimizes against such an equivalent loss. The perspective verifies the properne
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#31181;&#24050;&#30693;&#30340;UCB&#31867;&#22411;&#26041;&#27861;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#29366;&#24577;&#34920;&#31034;&#65288;PSRs&#65289;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#26032;&#30340;&#22870;&#21169;&#39033;&#26469;&#19978;&#30028;t</title><link>http://arxiv.org/abs/2307.00405</link><description>&lt;p&gt;
&#21487;&#35777;&#26126;&#39640;&#25928;&#30340;UCB&#31867;&#22411;&#31639;&#27861;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#29366;&#24577;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Provably Efficient UCB-type Algorithms For Learning Predictive State Representations. (arXiv:2307.00405v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00405
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#31181;&#24050;&#30693;&#30340;UCB&#31867;&#22411;&#26041;&#27861;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#29366;&#24577;&#34920;&#31034;&#65288;PSRs&#65289;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#26032;&#30340;&#22870;&#21169;&#39033;&#26469;&#19978;&#30028;t
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#33324;&#30340;&#39034;&#24207;&#20915;&#31574;&#38382;&#39064;&#26088;&#22312;&#36890;&#36807;&#22522;&#20110;&#36807;&#21435;&#35266;&#23519;&#21644;&#34892;&#21160;&#30340;&#21382;&#21490;&#26469;&#26368;&#22823;&#21270;&#32047;&#31215;&#22870;&#21169;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22914;&#26524;&#39034;&#24207;&#20915;&#31574;&#38382;&#39064;&#21487;&#20197;&#29992;&#39044;&#27979;&#29366;&#24577;&#34920;&#31034;&#65288;PSRs&#65289;&#24314;&#27169;&#20302;&#31209;&#32467;&#26500;&#65292;&#37027;&#20040;&#23427;&#26159;&#21487;&#32479;&#35745;&#23398;&#20064;&#30340;&#12290;&#23613;&#31649;&#26377;&#36825;&#20123;&#36827;&#23637;&#65292;&#20294;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#38656;&#35201;&#20351;&#29992;&#39044;&#20808;&#35774;&#35745;&#22909;&#30340;&#27493;&#39588;&#25110;&#32773;&#26159;&#35745;&#31639;&#25928;&#29575;&#20302;&#19979;&#30340;&#25110;&#32773;&#26159;&#19981;&#21487;&#35745;&#31639;&#30340;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#19978;&#38480;&#32622;&#20449;&#21306;&#38388;&#65288;UCB&#65289;&#26041;&#27861;&#22312;&#36172;&#21338;&#26426;&#21644;MDPs&#20013;&#34987;&#25104;&#21151;&#22320;&#20316;&#20026;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#26041;&#27861;&#65292;&#20294;&#23545;PSR&#36825;&#31181;&#26356;&#20855;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#36824;&#27809;&#26377;&#36827;&#34892;&#30740;&#31350;&#65292;&#36825;&#26159;&#30001;&#20110;&#22312;&#36825;&#31181;&#26356;&#20855;&#25361;&#25112;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#20048;&#35266;&#22411;&#22870;&#21169;&#30340;&#35774;&#35745;&#21313;&#20998;&#22256;&#38590;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;PSRs&#30340;&#31532;&#19968;&#31181;&#24050;&#30693;&#30340;UCB&#31867;&#22411;&#26041;&#27861;&#65292;&#20854;&#20013;&#21253;&#21547;&#20102;&#19968;&#20010;&#26032;&#30340;&#22870;&#21169;&#39033;&#26469;&#19978;&#30028;t
&lt;/p&gt;
&lt;p&gt;
The general sequential decision-making problem, which includes Markov decision processes (MDPs) and partially observable MDPs (POMDPs) as special cases, aims at maximizing a cumulative reward by making a sequence of decisions based on a history of observations and actions over time. Recent studies have shown that the sequential decision-making problem is statistically learnable if it admits a low-rank structure modeled by predictive state representations (PSRs). Despite these advancements, existing approaches typically involve oracles or steps that are not computationally efficient. On the other hand, the upper confidence bound (UCB) based approaches, which have served successfully as computationally efficient methods in bandits and MDPs, have not been investigated for more general PSRs, due to the difficulty of optimistic bonus design in these more challenging settings. This paper proposes the first known UCB-type approach for PSRs, featuring a novel bonus term that upper bounds the t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#21487;&#20197;&#26377;&#25928;&#32416;&#27491;&#25968;&#25454;&#20559;&#24046;&#21644;&#20132;&#21449;&#20559;&#24046;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#26500;&#36896;&#20102;&#19968;&#20010;&#37325;&#26032;&#21152;&#26435;&#26041;&#26696;&#65292;&#21487;&#20197;&#31934;&#30830;&#35780;&#20272;&#20219;&#20309;&#20551;&#35774;&#22312;&#30495;&#23454;&#20998;&#24067;&#19978;&#30340;&#25439;&#22833;&#12290;</title><link>http://arxiv.org/abs/2306.11112</link><description>&lt;p&gt;
&#32416;&#27491;&#20844;&#24179;&#20998;&#31867;&#20013;&#30340;&#20302;&#20272;&#20559;&#24046;&#21644;&#20132;&#21449;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Correcting Underrepresentation and Intersectional Bias for Fair Classification. (arXiv:2306.11112v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11112
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#21487;&#20197;&#26377;&#25928;&#32416;&#27491;&#25968;&#25454;&#20559;&#24046;&#21644;&#20132;&#21449;&#20559;&#24046;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#26500;&#36896;&#20102;&#19968;&#20010;&#37325;&#26032;&#21152;&#26435;&#26041;&#26696;&#65292;&#21487;&#20197;&#31934;&#30830;&#35780;&#20272;&#20219;&#20309;&#20551;&#35774;&#22312;&#30495;&#23454;&#20998;&#24067;&#19978;&#30340;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#23398;&#20064;&#34987;&#20302;&#20272;&#20559;&#24046;&#25439;&#22351;&#30340;&#25968;&#25454;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#27491;&#20363;&#22312;&#22266;&#23450;&#25968;&#37327;&#30340;&#25935;&#24863;&#32452;&#20013;&#20197;&#19981;&#21516;&#30340;&#26410;&#30693;&#36895;&#29575;&#20174;&#25968;&#25454;&#20013;&#36807;&#28388;&#25481;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312;&#26377;&#23569;&#37327;&#26080;&#20559;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#21487;&#20197;&#26377;&#25928;&#22320;&#20272;&#35745;&#27599;&#20010;&#32452;&#30340;&#20943;&#23569;&#21442;&#25968;&#65292;&#21363;&#20351;&#22312;&#20132;&#21449;&#32452;&#25104;&#21592;&#36164;&#26684;&#20351;&#24471;&#23398;&#20064;&#27599;&#20010;&#20132;&#21449;&#29575;&#21464;&#24471;&#35745;&#31639;&#19978;&#19981;&#21487;&#34892;&#30340;&#24773;&#20917;&#19979;&#12290;&#21033;&#29992;&#36825;&#20010;&#20998;&#32452;&#20002;&#22833;&#29575;&#30340;&#20272;&#35745;&#65292;&#25105;&#20204;&#26500;&#36896;&#20102;&#19968;&#20010;&#37325;&#26032;&#21152;&#26435;&#26041;&#26696;&#65292;&#21487;&#20197;&#20351;&#25105;&#20204;&#36817;&#20284;&#35780;&#20272;&#20219;&#20309;&#20551;&#35774;&#22312;&#30495;&#23454;&#20998;&#24067;&#19978;&#30340;&#25439;&#22833;&#65292;&#21363;&#20351;&#25105;&#20204;&#21482;&#33021;&#22312;&#19968;&#20010;&#26377;&#20559;&#26679;&#26412;&#19978;&#35266;&#23519;&#21040;&#32463;&#39564;&#35823;&#24046;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23553;&#35013;&#20102;&#36825;&#20010;&#23398;&#20064;&#21644;&#37325;&#26032;&#21152;&#26435;&#36807;&#31243;&#30340;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#24378;PAC&#39118;&#26684;&#30340;&#20445;&#35777;&#65292;&#21363;&#26377;&#24456;&#39640;&#30340;&#27010;&#29575;&#25105;&#20204;&#23545;&#20551;&#35774;&#22312;&#30495;&#23454;&#20998;&#24067;&#19978;&#30340;&#39118;&#38505;&#30340;&#20272;&#35745;&#23558;&#19982;&#30495;&#23454;&#39118;&#38505;&#20219;&#24847;&#25509;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning from data corrupted by underrepresentation bias, where positive examples are filtered from the data at different, unknown rates for a fixed number of sensitive groups. We show that with a small amount of unbiased data, we can efficiently estimate the group-wise drop-out parameters, even in settings where intersectional group membership makes learning each intersectional rate computationally infeasible. Using this estimate for the group-wise drop-out rate, we construct a re-weighting scheme that allows us to approximate the loss of any hypothesis on the true distribution, even if we only observe the empirical error on a biased sample. Finally, we present an algorithm encapsulating this learning and re-weighting process, and we provide strong PAC-style guarantees that, with high probability, our estimate of the risk of the hypothesis over the true distribution will be arbitrarily close to the true risk.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#19981;&#21464;&#22240;&#26524;&#38598;&#35206;&#30422;&#26426;&#30340;&#31639;&#27861;&#65292;&#23427;&#36991;&#20813;&#20102;&#20135;&#29983;&#34394;&#20551;&#20851;&#32852;&#65292;&#21487;&#20197;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#35782;&#21035;&#24863;&#20852;&#36259;&#21464;&#37327;&#30340;&#22240;&#26524;&#29238;&#33410;&#28857;&#12290;</title><link>http://arxiv.org/abs/2306.04777</link><description>&lt;p&gt;
&#19981;&#21464;&#22240;&#26524;&#38598;&#35206;&#30422;&#26426;
&lt;/p&gt;
&lt;p&gt;
Invariant Causal Set Covering Machines. (arXiv:2306.04777v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04777
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#19981;&#21464;&#22240;&#26524;&#38598;&#35206;&#30422;&#26426;&#30340;&#31639;&#27861;&#65292;&#23427;&#36991;&#20813;&#20102;&#20135;&#29983;&#34394;&#20551;&#20851;&#32852;&#65292;&#21487;&#20197;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#35782;&#21035;&#24863;&#20852;&#36259;&#21464;&#37327;&#30340;&#22240;&#26524;&#29238;&#33410;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#35268;&#21017;&#30340;&#27169;&#22411;&#65292;&#22914;&#20915;&#31574;&#26641;&#65292;&#22240;&#20854;&#21487;&#35299;&#37322;&#30340;&#29305;&#24615;&#21463;&#21040;&#20174;&#19994;&#32773;&#30340;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#20135;&#29983;&#36825;&#31181;&#27169;&#22411;&#30340;&#23398;&#20064;&#31639;&#27861;&#24448;&#24448;&#23481;&#26131;&#21463;&#21040;&#34394;&#20551;&#20851;&#32852;&#30340;&#24433;&#21709;&#65292;&#22240;&#27492;&#19981;&#33021;&#20445;&#35777;&#25552;&#21462;&#30340;&#26159;&#20855;&#26377;&#22240;&#26524;&#20851;&#31995;&#30340;&#27934;&#35265;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20511;&#37492;&#20102;&#19981;&#21464;&#22240;&#26524;&#39044;&#27979;&#25991;&#29486;&#20013;&#30340;&#24605;&#24819;&#65292;&#25552;&#20986;&#20102;&#19981;&#21464;&#30340;&#22240;&#26524;&#38598;&#35206;&#30422;&#26426;&#65292;&#36825;&#26159;&#19968;&#31181;&#32463;&#20856;&#30340;&#38598;&#35206;&#30422;&#26426;&#31639;&#27861;&#30340;&#25193;&#23637;&#65292;&#29992;&#20110;&#20108;&#20540;&#35268;&#21017;&#30340;&#21512;&#21462;/&#26512;&#21462;&#65292;&#21487;&#20197;&#35777;&#26126;&#23427;&#36991;&#20813;&#20102;&#34394;&#20551;&#20851;&#32852;&#12290;&#25105;&#20204;&#29702;&#35770;&#19978;&#21644;&#23454;&#36341;&#19978;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#35782;&#21035;&#24863;&#20852;&#36259;&#21464;&#37327;&#30340;&#22240;&#26524;&#29238;&#33410;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Rule-based models, such as decision trees, appeal to practitioners due to their interpretable nature. However, the learning algorithms that produce such models are often vulnerable to spurious associations and thus, they are not guaranteed to extract causally-relevant insights. In this work, we build on ideas from the invariant causal prediction literature to propose Invariant Causal Set Covering Machines, an extension of the classical Set Covering Machine algorithm for conjunctions/disjunctions of binary-valued rules that provably avoids spurious associations. We demonstrate both theoretically and empirically that our method can identify the causal parents of a variable of interest in polynomial time.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39044;&#27979;&#30340;&#36172;&#21338;&#31574;&#30053;&#26469;&#35299;&#20915;&#39640;&#32500;&#25110;&#32467;&#26500;&#21270;&#25968;&#25454;&#19979;&#38750;&#21442;&#25968;&#21452;&#26679;&#26412;&#21644;&#29420;&#31435;&#24615;&#26816;&#39564;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.00143</link><description>&lt;p&gt;
&#39034;&#24207;&#39044;&#27979;&#21452;&#26679;&#26412;&#21644;&#29420;&#31435;&#24615;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Sequential Predictive Two-Sample and Independence Testing. (arXiv:2305.00143v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00143
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39044;&#27979;&#30340;&#36172;&#21338;&#31574;&#30053;&#26469;&#35299;&#20915;&#39640;&#32500;&#25110;&#32467;&#26500;&#21270;&#25968;&#25454;&#19979;&#38750;&#21442;&#25968;&#21452;&#26679;&#26412;&#21644;&#29420;&#31435;&#24615;&#26816;&#39564;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#39034;&#24207;&#38750;&#21442;&#25968;&#21452;&#26679;&#26412;&#21644;&#29420;&#31435;&#24615;&#26816;&#39564;&#30340;&#38382;&#39064;&#12290;&#39034;&#24207;&#26816;&#39564;&#22312;&#32447;&#22788;&#29702;&#25968;&#25454;&#65292;&#20801;&#35768;&#20351;&#29992;&#35266;&#23519;&#21040;&#30340;&#25968;&#25454;&#26469;&#20915;&#23450;&#26159;&#21542;&#20572;&#27490;&#24182;&#25298;&#32477;&#21407;&#20551;&#35774;&#65292;&#25110;&#22312;&#20445;&#25345;&#31867;&#22411;I&#38169;&#35823;&#25511;&#21046;&#30340;&#21516;&#26102;&#25910;&#38598;&#26356;&#22810;&#25968;&#25454;&#12290;&#25105;&#20204;&#24314;&#31435;&#22312;(&#38750;&#21442;&#25968;)&#27979;&#35797;&#36172;&#21338;&#21407;&#21017;&#20043;&#19978;&#65292;&#20854;&#20013;&#36172;&#24466;&#22312;&#26410;&#26469;&#35266;&#23519;&#20013;&#19979;&#27880;&#65292;&#20182;&#20204;&#30340;&#36130;&#23500;&#23545;&#35777;&#25454;&#21453;&#23545;&#21407;&#20551;&#35774;&#36827;&#34892;&#34913;&#37327;&#12290;&#26368;&#36817;&#24320;&#21457;&#30340;&#22522;&#20110;&#26680;&#30340;&#36172;&#21338;&#31574;&#30053;&#22312;&#31616;&#21333;&#20998;&#24067;&#19978;&#36890;&#24120;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#23545;&#20110;&#39640;&#32500;&#25110;&#32467;&#26500;&#21270;&#25968;&#25454;&#65288;&#22914;&#25991;&#26412;&#21644;&#22270;&#20687;&#65289;&#36873;&#25321;&#21512;&#36866;&#30340;&#26680;&#36890;&#24120;&#26159;&#26840;&#25163;&#30340;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#22522;&#20110;&#39044;&#27979;&#30340;&#36172;&#21338;&#31574;&#30053;&#65292;&#20381;&#36182;&#20110;&#20197;&#19979;&#20107;&#23454;&#65306;&#22914;&#26524;&#19968;&#20010;&#39034;&#24207;&#26356;&#26032;&#30340;&#39044;&#27979;&#22120;&#24320;&#22987;&#19968;&#33268;&#22320;&#30830;&#23450;(a)&#19968;&#20010;&#23454;&#20363;&#20174;&#21738;&#20010;&#20998;&#24067;&#20013;&#32472;&#21046;&#65292;&#25110;&#32773;(b)&#19968;&#20010;&#23454;&#20363;&#26159;&#20174;&#32852;&#21512;&#20998;&#24067;&#36824;&#26159;&#20174;&#36793;&#32536;&#20998;&#24067;&#30340;&#20056;&#31215;&#20013;&#32472;&#21046;&#30340;&#65292;&#21017;&#20998;&#24067;&#26159;&#19981;&#21516;&#25110;&#30456;&#20851;&#30340;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28789;&#27963;&#65292;&#24182;&#23545;&#22522;&#30784;&#25968;&#25454;&#20998;&#24067;&#21644;&#32500;&#24230;&#19981;&#21487;&#30693;&#65292;&#21516;&#26102;&#20445;&#25345;&#19968;&#23450;&#30340;&#26368;&#20248;&#24615;&#20445;&#35777;&#12290;&#25105;&#20204;&#22312;&#27169;&#25311;&#21644;&#23454;&#38469;&#25968;&#25454;&#19978;&#28436;&#31034;&#20102;&#25105;&#20204;&#30340;&#39034;&#24207;&#27979;&#35797;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problems of sequential nonparametric two-sample and independence testing. Sequential tests process data online and allow using observed data to decide whether to stop and reject the null hypothesis or to collect more data while maintaining type I error control. We build upon the principle of (nonparametric) testing by betting, where a gambler places bets on future observations and their wealth measures evidence against the null hypothesis. While recently developed kernel-based betting strategies often work well on simple distributions, selecting a suitable kernel for high-dimensional or structured data, such as text and images, is often nontrivial. To address this drawback, we design prediction-based betting strategies that rely on the following fact: if a sequentially updated predictor starts to consistently determine (a) which distribution an instance is drawn from, or (b) whether an instance is drawn from the joint distribution or the product of the marginal distributio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35777;&#26126;&#25910;&#25947;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#26071;&#22411;&#27969;&#24418;&#19978;&#35745;&#31639;&#19968;&#32452;&#28857;&#30340;&#26071;&#24418;&#22343;&#20540;&#21644;&#26071;&#24418;&#20013;&#20540;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#38382;&#39064;&#20013;&#38750;&#24120;&#26377;&#29992;&#12290;</title><link>http://arxiv.org/abs/2303.13501</link><description>&lt;p&gt;
&#26071;&#22411;&#27969;&#24418;&#19978;&#30340;&#24358;&#22343;&#20540;&#21450;&#20854;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Chordal Averaging on Flag Manifolds and Its Applications. (arXiv:2303.13501v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.13501
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35777;&#26126;&#25910;&#25947;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#26071;&#22411;&#27969;&#24418;&#19978;&#35745;&#31639;&#19968;&#32452;&#28857;&#30340;&#26071;&#24418;&#22343;&#20540;&#21644;&#26071;&#24418;&#20013;&#20540;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#38382;&#39064;&#20013;&#38750;&#24120;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#12289;&#21487;&#35777;&#26126;&#25910;&#25947;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#24358;&#24230;&#37327;&#19979;&#35745;&#31639;&#26071;&#22411;&#27969;&#24418;&#19978;&#19968;&#32452;&#28857;&#30340;&#26071;&#24418;&#22343;&#20540;&#21644;&#26071;&#24418;&#20013;&#20540;&#12290;&#26071;&#22411;&#27969;&#24418;&#26159;&#19968;&#31181;&#25968;&#23398;&#31354;&#38388;&#65292;&#30001;&#23884;&#22871;&#30340;&#21521;&#37327;&#31354;&#38388;&#23376;&#31354;&#38388;&#24207;&#21015;&#32452;&#25104;&#65292;&#24182;&#19988;&#22312;&#32500;&#24230;&#19978;&#36880;&#28176;&#22686;&#21152;&#12290;&#26071;&#22411;&#27969;&#24418;&#26159;&#24050;&#30693;&#30340;&#35768;&#22810;&#30697;&#38453;&#32676;&#30340;&#36229;&#38598;&#65292;&#21253;&#25324;Stiefel&#21644;Grassmanians&#65292;&#20351;&#20854;&#25104;&#20026;&#22312;&#21508;&#31181;&#35745;&#31639;&#26426;&#35270;&#35273;&#38382;&#39064;&#20013;&#38750;&#24120;&#26377;&#29992;&#30340;&#36890;&#29992;&#23545;&#35937;&#12290;&#20026;&#20102;&#35299;&#20915;&#35745;&#31639;&#19968;&#38454;&#26071;&#24092;&#32479;&#35745;&#25968;&#25454;&#30340;&#25361;&#25112;&#65292;&#25105;&#20204;&#39318;&#20808;&#23558;&#38382;&#39064;&#36716;&#21270;&#20026;&#28041;&#21450;&#36741;&#21161;&#21464;&#37327;&#21463;Stiefel&#27969;&#24418;&#32422;&#26463;&#30340;&#38382;&#39064;&#12290;Stiefel&#27969;&#24418;&#26159;&#19968;&#32452;&#27491;&#20132;&#26694;&#26550;&#30340;&#31354;&#38388;&#65292;&#21033;&#29992;Stiefel&#27969;&#24418;&#20248;&#21270;&#30340;&#25968;&#20540;&#31283;&#23450;&#24615;&#21644;&#25928;&#29575;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#35745;&#31639;&#26071;&#24418;&#22343;&#20540;&#12290;&#36890;&#36807;&#19968;&#31995;&#21015;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;Grassmann&#21644;&#26059;&#36716;&#22343;&#20540;&#20197;&#21450;&#20027;&#25104;&#20998;&#38382;&#39064;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a new, provably-convergent algorithm for computing the flag-mean and flag-median of a set of points on a flag manifold under the chordal metric. The flag manifold is a mathematical space consisting of flags, which are sequences of nested subspaces of a vector space that increase in dimension. The flag manifold is a superset of a wide range of known matrix groups, including Stiefel and Grassmanians, making it a general object that is useful in a wide variety computer vision problems.  To tackle the challenge of computing first order flag statistics, we first transform the problem into one that involves auxiliary variables constrained to the Stiefel manifold. The Stiefel manifold is a space of orthogonal frames, and leveraging the numerical stability and efficiency of Stiefel-manifold optimization enables us to compute the flag-mean effectively. Through a series of experiments, we show the competence of our method in Grassmann and rotation averaging, as well as princi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#24314;&#31435;&#19978;&#19979;&#30028;&#38480;&#26469;&#36229;&#36234;Poincar&#233;&#19981;&#31561;&#24335;&#65292;&#20174;&#32780;&#25512;&#21160;Langevin&#25193;&#25955;&#21644;Langevin Monte Carlo&#65288;LMC&#65289;&#22312;&#24369;Poincar&#233;&#19981;&#31561;&#24335;&#19979;&#30340;&#30740;&#31350;&#12290;&#30740;&#31350;&#32467;&#26524;&#21487;&#20197;&#37327;&#21270;&#21021;&#22987;&#20540;&#23545;LMC&#31639;&#27861;&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2303.03589</link><description>&lt;p&gt;
&#23545;Langevin Monte Carlo&#30340;&#23436;&#25972;&#20998;&#26512;&#65306;&#36229;&#36234;Poincar&#233;&#19981;&#31561;&#24335;
&lt;/p&gt;
&lt;p&gt;
Towards a Complete Analysis of Langevin Monte Carlo: Beyond Poincar\'e Inequality. (arXiv:2303.03589v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.03589
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#24314;&#31435;&#19978;&#19979;&#30028;&#38480;&#26469;&#36229;&#36234;Poincar&#233;&#19981;&#31561;&#24335;&#65292;&#20174;&#32780;&#25512;&#21160;Langevin&#25193;&#25955;&#21644;Langevin Monte Carlo&#65288;LMC&#65289;&#22312;&#24369;Poincar&#233;&#19981;&#31561;&#24335;&#19979;&#30340;&#30740;&#31350;&#12290;&#30740;&#31350;&#32467;&#26524;&#21487;&#20197;&#37327;&#21270;&#21021;&#22987;&#20540;&#23545;LMC&#31639;&#27861;&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36866;&#24403;&#30340;&#21151;&#33021;&#19981;&#31561;&#24335;&#20551;&#35774;&#19979;&#65292;Langevin&#25193;&#25955;&#20855;&#26377;&#24555;&#36895;&#25910;&#25947;&#24615;&#12290;&#22240;&#27492;&#65292;&#21487;&#20197;&#26399;&#26395;&#22312;&#22788;&#29702;&#31163;&#25955;&#21270;&#35823;&#24046;&#30340;&#38468;&#21152;&#20809;&#28369;&#26465;&#20214;&#19979;&#65292;&#23427;&#20204;&#30340;&#31163;&#25955;&#21270;&#26041;&#27861;&#22914;Langevin Monte Carlo&#65288;LMC&#65289;&#20063;&#20250;&#20197;&#31867;&#20284;&#30340;&#26041;&#24335;&#25910;&#25947;&#12290;&#36825;&#20010;&#30740;&#31350;&#35745;&#21010;&#30001;Vempala&#21644;Wibisono&#65288;2019&#65289;&#21457;&#36215;&#65292;&#20182;&#20204;&#24314;&#31435;&#20102;&#22312;&#23545;&#25968;Sobolev&#19981;&#31561;&#24335;&#19979;&#30340;&#32467;&#26524;&#12290;Chewi&#31561;&#20154;&#65288;2022&#65289;&#23558;&#32467;&#26524;&#25512;&#24191;&#21040;&#22788;&#29702;Poincar&#233;&#19981;&#31561;&#24335;&#30340;&#24773;&#20917;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36229;&#36234;&#20102;Poincar&#233;&#19981;&#31561;&#24335;&#65292;&#23558;&#36825;&#20010;&#30740;&#31350;&#35745;&#21010;&#25512;&#21040;&#20102;&#26497;&#38480;&#12290;&#25105;&#20204;&#36890;&#36807;&#24314;&#31435;Langevin&#25193;&#25955;&#21644;LMC&#22312;&#28385;&#36275;&#24191;&#27867;&#31867;&#21035;&#30340;&#23494;&#24230;&#65288;&#21253;&#25324;&#22810;&#39033;&#24335;&#34928;&#20943;&#37325;&#23614;&#23494;&#24230;&#65292;&#21363;&#26607;&#35199;&#22411;&#23494;&#24230;&#65289;&#30340;&#24369;Poincar&#233;&#19981;&#31561;&#24335;&#19979;&#30340;&#19978;&#19979;&#30028;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26126;&#30830;&#37327;&#21270;&#20102;&#21021;&#22987;&#20540;&#23545;LMC&#31639;&#27861;&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#23614;&#37096;&#20174;s
&lt;/p&gt;
&lt;p&gt;
Langevin diffusions are rapidly convergent under appropriate functional inequality assumptions. Hence, it is natural to expect that with additional smoothness conditions to handle the discretization errors, their discretizations like the Langevin Monte Carlo (LMC) converge in a similar fashion. This research program was initiated by Vempala and Wibisono (2019), who established results under log-Sobolev inequalities. Chewi et al. (2022) extended the results to handle the case of Poincar\'e inequalities. In this paper, we go beyond Poincar\'e inequalities, and push this research program to its limit. We do so by establishing upper and lower bounds for Langevin diffusions and LMC under weak Poincar\'e inequalities that are satisfied by a large class of densities including polynomially-decaying heavy-tailed densities (i.e., Cauchy-type). Our results explicitly quantify the effect of the initializer on the performance of the LMC algorithm. In particular, we show that as the tail goes from s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#20998;&#31867;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#22270;&#29983;&#25104;&#27169;&#22411;&#65292;&#25512;&#23548;&#20986;&#20102;&#32473;&#23450;&#22270;&#30340;&#31867;&#26631;&#31614;&#27010;&#29575;&#30340;&#20998;&#31867;&#20844;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26465;&#20214; ELBO &#29992;&#20110;&#35757;&#32451;&#29983;&#25104;&#22270;&#33258;&#32534;&#30721;&#22120;&#27169;&#22411;&#12290;&#36825;&#26159;&#19968;&#31181;&#22312;&#22270;&#20998;&#31867;&#20013;&#20855;&#26377;&#21019;&#26032;&#24615;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2302.07989</link><description>&lt;p&gt;
&#20174;&#22270;&#29983;&#25104;&#21040;&#22270;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
From Graph Generation to Graph Classification. (arXiv:2302.07989v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07989
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#20998;&#31867;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#22270;&#29983;&#25104;&#27169;&#22411;&#65292;&#25512;&#23548;&#20986;&#20102;&#32473;&#23450;&#22270;&#30340;&#31867;&#26631;&#31614;&#27010;&#29575;&#30340;&#20998;&#31867;&#20844;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26465;&#20214; ELBO &#29992;&#20110;&#35757;&#32451;&#29983;&#25104;&#22270;&#33258;&#32534;&#30721;&#22120;&#27169;&#22411;&#12290;&#36825;&#26159;&#19968;&#31181;&#22312;&#22270;&#20998;&#31867;&#20013;&#20855;&#26377;&#21019;&#26032;&#24615;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25551;&#36848;&#20102;&#19968;&#31181;&#21033;&#29992;&#22270;&#29983;&#25104;&#27169;&#22411; (GGM) &#36827;&#34892;&#22270;&#20998;&#31867;&#30340;&#26032;&#26041;&#27861;&#12290;&#20551;&#35774;&#19968;&#20010;&#23450;&#20041;&#20102;&#22270;&#21450;&#20854;&#31867;&#26631;&#31614;&#30340;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#30340; GGM&#65292;&#25105;&#25512;&#23548;&#20102;&#35745;&#31639;&#32473;&#23450;&#22270;&#30340;&#31867;&#26631;&#31614;&#27010;&#29575;&#30340;&#20998;&#31867;&#20844;&#24335;&#12290;&#21487;&#20197;&#20351;&#29992;&#26032;&#30340;&#26465;&#20214; ELBO &#26469;&#35757;&#32451;&#29983;&#25104;&#22270;&#33258;&#32534;&#30721;&#22120;&#27169;&#22411;&#36827;&#34892;&#21306;&#20998;&#12290;&#34429;&#28982;&#21033;&#29992;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#20998;&#31867;&#22312;&#38750;&#20851;&#31995; i.i.d. &#25968;&#25454;&#20013;&#24050;&#32463;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#30740;&#31350;&#65292;&#20294;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#19968;&#31181;&#22270;&#20998;&#31867;&#30340;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This note describes a new approach to classifying graphs that leverages graph generative models (GGM). Assuming a GGM that defines a joint probability distribution over graphs and their class labels, I derive classification formulas for the probability of a class label given a graph. A new conditional ELBO can be used to train a generative graph auto-encoder model for discrimination. While leveraging generative models for classification has been well explored for non-relational i.i.d. data, to our knowledge it is a novel approach to graph classification.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;EPGP&#30340;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#65292;&#29992;&#20110;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#31995;&#32479;&#65292;&#24182;&#19988;&#26500;&#36896;&#20102;&#21453;&#26144;&#26631;&#20934;&#35889;&#26041;&#27861;&#30340;GP&#26680;&#20989;&#25968;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#25512;&#26029;&#32447;&#24615;PDE&#31995;&#32479;&#30340;&#21487;&#33021;&#35299;&#65292;&#24182;&#20855;&#26377;&#31639;&#27861;&#24615;&#24378;&#12289;&#26222;&#36866;&#24615;&#24191;&#12289;&#36866;&#29992;&#20110;&#22823;&#25968;&#25454;&#38598;&#30340;&#31232;&#30095;&#29256;&#26412;&#12290;</title><link>http://arxiv.org/abs/2212.14319</link><description>&lt;p&gt;
&#31995;&#32479;&#30340;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#19982;&#24120;&#31995;&#25968;&#65288;&#32763;&#35793;&#33258;arXiv:2212.14319v3 [stat.ML] &#26356;&#26032;&#65289;
&lt;/p&gt;
&lt;p&gt;
Gaussian Process Priors for Systems of Linear Partial Differential Equations with Constant Coefficients. (arXiv:2212.14319v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.14319
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;EPGP&#30340;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#65292;&#29992;&#20110;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#31995;&#32479;&#65292;&#24182;&#19988;&#26500;&#36896;&#20102;&#21453;&#26144;&#26631;&#20934;&#35889;&#26041;&#27861;&#30340;GP&#26680;&#20989;&#25968;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#25512;&#26029;&#32447;&#24615;PDE&#31995;&#32479;&#30340;&#21487;&#33021;&#35299;&#65292;&#24182;&#20855;&#26377;&#31639;&#27861;&#24615;&#24378;&#12289;&#26222;&#36866;&#24615;&#24191;&#12289;&#36866;&#29992;&#20110;&#22823;&#25968;&#25454;&#38598;&#30340;&#31232;&#30095;&#29256;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDE&#65289;&#26159;&#24314;&#27169;&#29289;&#29702;&#31995;&#32479;&#30340;&#37325;&#35201;&#24037;&#20855;&#65292;&#23558;&#23427;&#20204;&#32435;&#20837;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26159;&#23558;&#29289;&#29702;&#30693;&#35782;&#32435;&#20837;&#30340;&#37325;&#35201;&#26041;&#24335;&#12290;&#23545;&#20110;&#20219;&#20309;&#20855;&#26377;&#24120;&#31995;&#25968;&#30340;&#32447;&#24615;PDE&#31995;&#32479;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#26063;&#31216;&#20026;EPGP&#30340;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#20808;&#39564;&#65292;&#20351;&#24471;&#25152;&#26377;&#23454;&#29616;&#37117;&#26159;&#35813;&#31995;&#32479;&#30340;&#31934;&#30830;&#35299;&#12290;&#25105;&#20204;&#24212;&#29992;Ehrenpreis-Palamodov&#22522;&#26412;&#21407;&#29702;&#65292;&#23427;&#20316;&#20026;&#19968;&#31181;&#38750;&#32447;&#24615;&#20613;&#37324;&#21494;&#21464;&#25442;&#65292;&#26500;&#24314;&#20102;GP&#26680;&#20989;&#25968;&#65292;&#21453;&#26144;&#20102;&#26631;&#20934;&#30340;&#35889;&#26041;&#27861;&#29992;&#20110;GP&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20174;&#20219;&#20309;&#25968;&#25454;&#65288;&#22914;&#26377;&#22122;&#22768;&#30340;&#27979;&#37327;&#25968;&#25454;&#25110;&#28857;&#23450;&#20041;&#30340;&#21021;&#22987;&#21644;&#36793;&#30028;&#26465;&#20214;&#65289;&#25512;&#26029;&#32447;&#24615;PDE&#31995;&#32479;&#30340;&#21487;&#33021;&#35299;&#12290;&#26500;&#36896;EPGP&#20808;&#39564;&#30340;&#31639;&#27861;&#24615;&#24378;&#65292;&#26222;&#36866;&#24615;&#24191;&#65292;&#24182;&#19988;&#26377;&#19968;&#20010;&#31232;&#30095;&#29256;&#26412;&#65288;S-EPGP&#65289;&#65292;&#21487;&#20197;&#23398;&#20064;&#30456;&#20851;&#30340;&#35889;&#39057;&#29575;&#65292;&#24182;&#22312;&#22823;&#25968;&#25454;&#38598;&#19978;&#36816;&#34892;&#25928;&#26524;&#26356;&#22909;&#12290;&#25105;&#20204;&#22312;&#19977;&#31867;PDE&#31995;&#32479;&#19978;&#28436;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#28909;&#26041;&#31243;&#21644;&#27874;&#26041;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Partial differential equations (PDEs) are important tools to model physical systems and including them into machine learning models is an important way of incorporating physical knowledge. Given any system of linear PDEs with constant coefficients, we propose a family of Gaussian process (GP) priors, which we call EPGP, such that all realizations are exact solutions of this system. We apply the Ehrenpreis-Palamodov fundamental principle, which works as a non-linear Fourier transform, to construct GP kernels mirroring standard spectral methods for GPs. Our approach can infer probable solutions of linear PDE systems from any data such as noisy measurements, or pointwise defined initial and boundary conditions. Constructing EPGP-priors is algorithmic, generally applicable, and comes with a sparse version (S-EPGP) that learns the relevant spectral frequencies and works better for big data sets. We demonstrate our approach on three families of systems of PDEs, the heat equation, wave equati
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#26041;&#24046;&#32593;&#32476;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26641;&#29366;&#32467;&#26500;&#23398;&#20064;&#23558;&#29305;&#24449;&#31354;&#38388;&#20998;&#21106;&#20026;&#22810;&#20010;&#21306;&#22495;&#65292;&#24182;&#20351;&#29992;&#21306;&#22495;&#29305;&#23450;&#30340;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#22343;&#20540;&#21644;&#26041;&#24046;&#26469;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#26032;&#30340;&#20998;&#35010;&#20934;&#21017;&#65292;&#22312;&#35745;&#31639;&#19978;&#21451;&#22909;&#19988;&#19981;&#38656;&#35201;&#20462;&#21098;&#65292;&#36824;&#21487;&#20197;&#26500;&#24314;&#38598;&#21512;&#29256;&#26412;&#26469;&#20272;&#35745;&#24635;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2212.12658</link><description>&lt;p&gt;
&#25552;&#39640;&#26041;&#24046;&#32593;&#32476;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#26641;&#29366;&#32467;&#26500;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Improving Uncertainty Quantification of Variance Networks by Tree-Structured Learning. (arXiv:2212.12658v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.12658
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#26041;&#24046;&#32593;&#32476;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26641;&#29366;&#32467;&#26500;&#23398;&#20064;&#23558;&#29305;&#24449;&#31354;&#38388;&#20998;&#21106;&#20026;&#22810;&#20010;&#21306;&#22495;&#65292;&#24182;&#20351;&#29992;&#21306;&#22495;&#29305;&#23450;&#30340;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#22343;&#20540;&#21644;&#26041;&#24046;&#26469;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#26032;&#30340;&#20998;&#35010;&#20934;&#21017;&#65292;&#22312;&#35745;&#31639;&#19978;&#21451;&#22909;&#19988;&#19981;&#38656;&#35201;&#20462;&#21098;&#65292;&#36824;&#21487;&#20197;&#26500;&#24314;&#38598;&#21512;&#29256;&#26412;&#26469;&#20272;&#35745;&#24635;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#25552;&#39640;&#26041;&#24046;&#32593;&#32476;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26641;&#29366;&#32467;&#26500;&#23616;&#37096;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#26681;&#25454;&#19981;&#30830;&#23450;&#24615;&#30340;&#24322;&#36136;&#24615;&#23558;&#29305;&#24449;&#31354;&#38388;&#21010;&#20998;&#20026;&#22810;&#20010;&#21306;&#22495;&#12290;&#26681;&#25454;&#35757;&#32451;&#25968;&#25454;&#65292;&#24314;&#31435;&#19968;&#26869;&#26641;&#65292;&#20854;&#21494;&#33410;&#28857;&#20195;&#34920;&#19981;&#21516;&#30340;&#21306;&#22495;&#65292;&#22312;&#36825;&#20123;&#21306;&#22495;&#29305;&#23450;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#36827;&#34892;&#35757;&#32451;&#65292;&#20197;&#39044;&#27979;&#22343;&#20540;&#21644;&#26041;&#24046;&#20197;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#19981;&#30830;&#23450;&#24615;&#20998;&#35010;&#31070;&#32463;&#22238;&#24402;&#26641; (USNRT)&#37319;&#29992;&#20102;&#26032;&#39062;&#30340;&#20998;&#35010;&#20934;&#21017;&#12290;&#22312;&#27599;&#20010;&#33410;&#28857;&#19978;&#65292;&#39318;&#20808;&#23545;&#20840;&#25968;&#25454;&#36827;&#34892;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#65292;&#28982;&#21518;&#23545;&#27531;&#24046;&#36827;&#34892;&#32479;&#35745;&#26816;&#39564;&#65292;&#25214;&#21040;&#26368;&#20339;&#20998;&#35010;&#65292;&#23545;&#24212;&#20855;&#26377;&#26368;&#26174;&#33879;&#19981;&#30830;&#23450;&#24615;&#24322;&#36136;&#24615;&#30340;&#20004;&#20010;&#23376;&#21306;&#22495;&#12290;USNRT&#22312;&#35745;&#31639;&#19978;&#21451;&#22909;&#65292;&#21482;&#38656;&#24456;&#23569;&#30340;&#21494;&#33410;&#28857;&#21363;&#21487;&#28385;&#36275;&#35201;&#27714;&#65292;&#26080;&#38656;&#36827;&#34892;&#20462;&#21098;&#12290;&#27492;&#22806;&#65292;&#36824;&#21487;&#20197;&#36731;&#26494;&#26500;&#24314;&#38598;&#21512;&#29256;&#26412;&#20197;&#20272;&#35745;&#21253;&#25324; aleatory &#30340;&#24635;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
To improve the uncertainty quantification of variance networks, we propose a novel tree-structured local neural network model that partitions the feature space into multiple regions based on uncertainty heterogeneity. A tree is built upon giving the training data, whose leaf nodes represent different regions where region-specific neural networks are trained to predict both the mean and the variance for quantifying uncertainty. The proposed Uncertainty-Splitting Neural Regression Tree (USNRT) employs novel splitting criteria. At each node, a neural network is trained on the full data first, and a statistical test for the residuals is conducted to find the best split, corresponding to the two sub-regions with the most significant uncertainty heterogeneity between them. USNRT is computationally friendly because very few leaf nodes are sufficient and pruning is unnecessary. Furthermore, an ensemble version can be easily constructed to estimate the total uncertainty including the aleatory a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#30340;&#22238;&#39038;&#20013;&#30340;&#22909;&#22855;&#24515;&#26041;&#27861;&#65292;&#29992;&#20110;&#31232;&#30095;&#22870;&#21169;&#25110;&#26080;&#22870;&#21169;&#29615;&#22659;&#20013;&#30340;&#25506;&#32034;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#23398;&#20064;&#26410;&#26469;&#30340;&#34920;&#24449;&#65292;&#20197;&#25429;&#25417;&#27599;&#20010;&#32467;&#26524;&#30340;&#19981;&#21487;&#39044;&#27979;&#37096;&#20998;&#65292;&#24182;&#23558;&#20854;&#29992;&#20316;&#39044;&#27979;&#30340;&#39069;&#22806;&#36755;&#20837;&#65292;&#20174;&#32780;&#33719;&#24471;&#40065;&#26834;&#30340;&#20869;&#22312;&#22870;&#21169;&#12290;</title><link>http://arxiv.org/abs/2211.10515</link><description>&lt;p&gt;
&#22238;&#39038;&#20013;&#30340;&#22909;&#22855;&#24515;&#65306;&#38543;&#26426;&#29615;&#22659;&#20013;&#30340;&#20869;&#22312;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Curiosity in Hindsight: Intrinsic Exploration in Stochastic Environments. (arXiv:2211.10515v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.10515
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#30340;&#22238;&#39038;&#20013;&#30340;&#22909;&#22855;&#24515;&#26041;&#27861;&#65292;&#29992;&#20110;&#31232;&#30095;&#22870;&#21169;&#25110;&#26080;&#22870;&#21169;&#29615;&#22659;&#20013;&#30340;&#25506;&#32034;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#23398;&#20064;&#26410;&#26469;&#30340;&#34920;&#24449;&#65292;&#20197;&#25429;&#25417;&#27599;&#20010;&#32467;&#26524;&#30340;&#19981;&#21487;&#39044;&#27979;&#37096;&#20998;&#65292;&#24182;&#23558;&#20854;&#29992;&#20316;&#39044;&#27979;&#30340;&#39069;&#22806;&#36755;&#20837;&#65292;&#20174;&#32780;&#33719;&#24471;&#40065;&#26834;&#30340;&#20869;&#22312;&#22870;&#21169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#31232;&#30095;&#22870;&#21169;&#25110;&#26080;&#22870;&#21169;&#29615;&#22659;&#20013;&#30340;&#25506;&#32034;&#38382;&#39064;&#65292;&#22914;Montezuma's Revenge&#12290;&#22312;&#22909;&#22855;&#24515;&#39537;&#21160;&#33539;&#24335;&#20013;&#65292;&#20195;&#29702;&#34987;&#22870;&#21169;&#23454;&#38469;&#32467;&#26524;&#19982;&#39044;&#27979;&#32467;&#26524;&#30340;&#24046;&#24322;&#12290;&#20294;&#22312;&#38543;&#26426;&#29615;&#22659;&#20013;&#65292;&#20351;&#29992;&#39044;&#27979;&#35823;&#24046;&#20316;&#20026;&#20869;&#22312;&#21160;&#26426;&#26159;&#33030;&#24369;&#30340;&#65292;&#22240;&#20026;&#20195;&#29702;&#21487;&#33021;&#34987;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#20013;&#39640;&#29109;&#21306;&#22495;&#65288;&#22914;&#8220;&#22122;&#22768;&#30005;&#35270;&#8221;&#65289;&#25152;&#22256;&#20303;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#30340;&#33258;&#28982;&#35299;&#20915;&#26041;&#26696;&#65306;&#23398;&#20064;&#26410;&#26469;&#30340;&#34920;&#24449;&#65292;&#31934;&#30830;&#22320;&#25429;&#25417;&#27599;&#20010;&#32467;&#26524;&#30340;&#19981;&#21487;&#39044;&#27979;&#26041;&#38754;&#65292;&#24182;&#23558;&#20854;&#29992;&#20316;&#39044;&#27979;&#30340;&#39069;&#22806;&#36755;&#20837;&#65292;&#20174;&#32780;&#20351;&#20869;&#22312;&#22870;&#21169;&#20165;&#21453;&#26144;&#19990;&#30028;&#21160;&#24577;&#30340;&#21487;&#39044;&#27979;&#26041;&#38754;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#23558;&#36825;&#31181;&#22238;&#39038;&#34920;&#24449;&#32467;&#21512;&#21040;&#27169;&#22411;&#20013;&#65292;&#20197;&#23558;&#8220;&#22122;&#22768;&#8221;&#19982;&#8220;&#26032;&#22855;&#8221;&#21306;&#20998;&#24320;&#26469;&#65292;&#24471;&#21040;&#20102;&#22238;&#39038;&#20013;&#30340;&#22909;&#22855;&#24515;&#65306;&#19968;&#31181;&#31616;&#21333;&#32780;&#21487;&#25193;&#23637;&#30340;&#22909;&#22855;&#24515;&#27867;&#21270;&#26041;&#27861;&#65292;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consider the problem of exploration in sparse-reward or reward-free environments, such as in Montezuma's Revenge. In the curiosity-driven paradigm, the agent is rewarded for how much each realized outcome differs from their predicted outcome. But using predictive error as intrinsic motivation is fragile in stochastic environments, as the agent may become trapped by high-entropy areas of the state-action space, such as a "noisy TV". In this work, we study a natural solution derived from structural causal models of the world: Our key idea is to learn representations of the future that capture precisely the unpredictable aspects of each outcome -- which we use as additional input for predictions, such that intrinsic rewards only reflect the predictable aspects of world dynamics. First, we propose incorporating such hindsight representations into models to disentangle "noise" from "novelty", yielding Curiosity in Hindsight: a simple and scalable generalization of curiosity that is robust t
&lt;/p&gt;</description></item><item><title>&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#21033;&#29992;&#31163;&#32447;&#25968;&#25454;&#30340;&#35774;&#32622;&#65292;&#20026;&#20855;&#26377;&#32447;&#24615;&#32467;&#26500;&#30340;MDPs&#30830;&#23450;&#20102;&#25152;&#38656;&#30340;&#22312;&#32447;&#26679;&#26412;&#25968;&#37327;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#30340;&#24615;&#36136;&#21644;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2211.04974</link><description>&lt;p&gt;
&#22312;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#21033;&#29992;&#31163;&#32447;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Leveraging Offline Data in Online Reinforcement Learning. (arXiv:2211.04974v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.04974
&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#21033;&#29992;&#31163;&#32447;&#25968;&#25454;&#30340;&#35774;&#32622;&#65292;&#20026;&#20855;&#26377;&#32447;&#24615;&#32467;&#26500;&#30340;MDPs&#30830;&#23450;&#20102;&#25152;&#38656;&#30340;&#22312;&#32447;&#26679;&#26412;&#25968;&#37327;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#30340;&#24615;&#36136;&#21644;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#20986;&#29616;&#20102;&#20004;&#20010;&#26680;&#24515;&#33539;&#24335;&#65306;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#21644;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#12290;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#26234;&#33021;&#20307;&#23545;&#29615;&#22659;&#27809;&#26377;&#20808;&#39564;&#30693;&#35782;&#65292;&#24517;&#39035;&#19982;&#29615;&#22659;&#20132;&#20114;&#20197;&#25214;&#21040;&#19968;&#20010; &#949;-&#26368;&#20248;&#31574;&#30053;&#12290;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#23398;&#20064;&#22120;&#21487;&#20197;&#20174;&#19968;&#20010;&#22266;&#23450;&#30340;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#65292;&#20294;&#26080;&#27861;&#19982;&#29615;&#22659;&#36827;&#34892;&#20132;&#20114;&#65292;&#24517;&#39035;&#36890;&#36807;&#31163;&#32447;&#25968;&#25454;&#33719;&#21462;&#26368;&#20339;&#31574;&#30053;&#12290;&#23454;&#38469;&#24773;&#20917;&#36890;&#24120;&#38656;&#35201;&#19968;&#20010;&#20013;&#38388;&#30340;&#35774;&#32622;&#65306;&#22914;&#26524;&#25105;&#20204;&#26377;&#19968;&#20123;&#31163;&#32447;&#25968;&#25454;&#65292;&#24182;&#19988;&#36824;&#21487;&#20197;&#19982;&#29615;&#22659;&#36827;&#34892;&#20132;&#20114;&#65292;&#25105;&#20204;&#22914;&#20309;&#26368;&#22909;&#22320;&#21033;&#29992;&#31163;&#32447;&#25968;&#25454;&#26469;&#20943;&#23569;&#23398;&#20064;&#19968;&#20010; &#949;-&#26368;&#20248;&#31574;&#30053;&#25152;&#38656;&#30340;&#22312;&#32447;&#20132;&#20114;&#27425;&#25968;&#65311;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#36825;&#20010;&#35774;&#32622;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;FineTuneRL&#35774;&#32622;&#65292;&#29992;&#20110;&#20855;&#26377;&#32447;&#24615;&#32467;&#26500;&#30340;MDPs&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#22312;&#32473;&#23450;&#19968;&#20123;&#31163;&#32447;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#38656;&#35201;&#30340;&#22312;&#32447;&#26679;&#26412;&#25968;&#37327;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20123;&#24615;&#36136;&#21644;&#31639;&#27861;&#26469;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
Two central paradigms have emerged in the reinforcement learning (RL) community: online RL and offline RL. In the online RL setting, the agent has no prior knowledge of the environment, and must interact with it in order to find an $\epsilon$-optimal policy. In the offline RL setting, the learner instead has access to a fixed dataset to learn from, but is unable to otherwise interact with the environment, and must obtain the best policy it can from this offline data. Practical scenarios often motivate an intermediate setting: if we have some set of offline data and, in addition, may also interact with the environment, how can we best use the offline data to minimize the number of online interactions necessary to learn an $\epsilon$-optimal policy?  In this work, we consider this setting, which we call the \textsf{FineTuneRL} setting, for MDPs with linear structure. We characterize the necessary number of online samples needed in this setting given access to some offline dataset, and de
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#31163;&#25955;&#36873;&#25321;&#27169;&#22411;&#31867;&#65292;RUMnets&#65292;&#21487;&#20197;&#36817;&#20284;&#34920;&#31034;&#20219;&#20309;&#38543;&#26426;&#25928;&#29992;&#26368;&#22823;&#21270;&#25512;&#23548;&#20986;&#30340;&#27169;&#22411;&#65292;&#24182;&#19988;&#22312;&#36873;&#25321;&#25968;&#25454;&#19978;&#26377;&#33391;&#22909;&#30340;&#39044;&#27979;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2207.12877</link><description>&lt;p&gt;
&#29992;&#31070;&#32463;&#32593;&#32476;&#34920;&#31034;&#38543;&#26426;&#25928;&#29992;&#36873;&#25321;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Representing Random Utility Choice Models with Neural Networks. (arXiv:2207.12877v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.12877
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#31163;&#25955;&#36873;&#25321;&#27169;&#22411;&#31867;&#65292;RUMnets&#65292;&#21487;&#20197;&#36817;&#20284;&#34920;&#31034;&#20219;&#20309;&#38543;&#26426;&#25928;&#29992;&#26368;&#22823;&#21270;&#25512;&#23548;&#20986;&#30340;&#27169;&#22411;&#65292;&#24182;&#19988;&#22312;&#36873;&#25321;&#25968;&#25454;&#19978;&#26377;&#33391;&#22909;&#30340;&#39044;&#27979;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28145;&#24230;&#23398;&#20064;&#30340;&#25104;&#21151;&#20043;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#31163;&#25955;&#36873;&#25321;&#27169;&#22411;&#31867;&#65292;&#31216;&#20026;RUMnets&#65292;&#21463;&#38543;&#26426;&#25928;&#29992;&#26368;&#22823;&#21270;&#65288;RUM&#65289;&#26694;&#26550;&#30340;&#21551;&#21457;&#12290;&#35813;&#27169;&#22411;&#20351;&#29992;&#26679;&#26412;&#24179;&#22343;&#36924;&#36817;&#26469;&#26500;&#24314;&#20195;&#29702;&#20154;&#30340;&#38543;&#26426;&#25928;&#29992;&#20989;&#25968;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;RUMnets&#21487;&#20197;&#23545;RUM&#31163;&#25955;&#36873;&#25321;&#27169;&#22411;&#31867;&#36827;&#34892;&#23574;&#38160;&#36924;&#36817;&#65306;&#20219;&#20309;&#20174;&#38543;&#26426;&#25928;&#29992;&#26368;&#22823;&#21270;&#25512;&#23548;&#20986;&#30340;&#27169;&#22411;&#37117;&#21487;&#20197;&#34987;RUMnet&#26080;&#38480;&#25509;&#36817;&#22320;&#36924;&#36817;&#12290;&#30456;&#21453;&#22320;&#65292;&#20219;&#20309;RUMnet&#37117;&#31526;&#21512;RUM&#21407;&#21017;&#12290;&#25105;&#20204;&#24471;&#21040;&#20102;&#22312;&#36873;&#25321;&#25968;&#25454;&#19978;&#25311;&#21512;&#30340;RUMnet&#30340;&#27867;&#21270;&#35823;&#24046;&#30340;&#19978;&#30028;&#65292;&#24182;&#19988;&#26681;&#25454;&#25968;&#25454;&#38598;&#21644;&#26550;&#26500;&#30340;&#20851;&#38190;&#21442;&#25968;&#65292;&#33719;&#24471;&#20102;&#20851;&#20110;&#20854;&#22312;&#26032;&#30340;&#26410;&#30693;&#25968;&#25454;&#19978;&#39044;&#27979;&#36873;&#25321;&#33021;&#21147;&#30340;&#29702;&#35770;&#27934;&#35265;&#12290;&#36890;&#36807;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#24320;&#28304;&#24211;&#65292;&#25105;&#20204;&#21457;&#29616;RUMnets&#22312;&#39044;&#27979;&#20934;&#30830;&#24615;&#26041;&#38754;&#19982;&#20960;&#31181;&#36873;&#25321;&#24314;&#27169;&#21644;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by the successes of deep learning, we propose a class of neural network-based discrete choice models, called RUMnets, inspired by the random utility maximization (RUM) framework. This model formulates the agents' random utility function using a sample average approximation. We show that RUMnets sharply approximate the class of RUM discrete choice models: any model derived from random utility maximization has choice probabilities that can be approximated arbitrarily closely by a RUMnet. Reciprocally, any RUMnet is consistent with the RUM principle. We derive an upper bound on the generalization error of RUMnets fitted on choice data, and gain theoretical insights on their ability to predict choices on new, unseen data depending on critical parameters of the dataset and architecture. By leveraging open-source libraries for neural networks, we find that RUMnets are competitive against several choice modeling and machine learning methods in terms of predictive accuracy on two rea
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#21033;&#29992;&#22823;&#26679;&#26412;&#28176;&#36817;&#29702;&#35770;&#23545;&#38543;&#26426;&#26799;&#24230;&#31639;&#27861;&#36827;&#34892;&#35843;&#20248;&#65292;&#21457;&#29616;&#20351;&#29992;&#22266;&#23450;&#30340;&#22823;&#27493;&#38271;&#36827;&#34892;&#36845;&#20195;&#24179;&#22343;&#21487;&#20197;&#40065;&#26834;&#22320;&#20248;&#21270;&#31639;&#27861;&#65292;&#19988;&#20855;&#26377;&#21644;MLE&#25277;&#26679;&#20998;&#24067;&#21327;&#26041;&#24046;&#25104;&#27604;&#20363;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#31867;&#20284;&#20110;Bernstein-von Mises&#30340;&#23450;&#29702;&#29992;&#20110;&#25351;&#23548;&#35843;&#20248;&#65292;&#21253;&#25324;&#38024;&#23545;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#40065;&#26834;&#30340;&#24191;&#20041;&#21518;&#39564;&#12290;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#32467;&#26524;&#21644;&#24314;&#35758;&#22312;&#23454;&#38469;&#26377;&#38480;&#26679;&#26412;&#24773;&#20917;&#19979;&#30340;&#26377;&#25928;&#24615;&#12290;&#36825;&#20123;&#25104;&#26524;&#20026;&#20998;&#26512;&#20854;&#20182;&#38543;&#26426;&#26799;&#24230;Markov Chain Monte Carlo&#31639;&#27861;&#25552;&#20379;&#20102;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2207.12395</link><description>&lt;p&gt;
&#36890;&#36807;&#22823;&#26679;&#26412;&#28176;&#36817;&#29702;&#35770;&#20248;&#21270;&#38543;&#26426;&#26799;&#24230;&#31639;&#27861;&#30340;&#32479;&#35745;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Tuning Stochastic Gradient Algorithms for Statistical Inference via Large-Sample Asymptotics. (arXiv:2207.12395v3 [stat.CO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.12395
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#21033;&#29992;&#22823;&#26679;&#26412;&#28176;&#36817;&#29702;&#35770;&#23545;&#38543;&#26426;&#26799;&#24230;&#31639;&#27861;&#36827;&#34892;&#35843;&#20248;&#65292;&#21457;&#29616;&#20351;&#29992;&#22266;&#23450;&#30340;&#22823;&#27493;&#38271;&#36827;&#34892;&#36845;&#20195;&#24179;&#22343;&#21487;&#20197;&#40065;&#26834;&#22320;&#20248;&#21270;&#31639;&#27861;&#65292;&#19988;&#20855;&#26377;&#21644;MLE&#25277;&#26679;&#20998;&#24067;&#21327;&#26041;&#24046;&#25104;&#27604;&#20363;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#31867;&#20284;&#20110;Bernstein-von Mises&#30340;&#23450;&#29702;&#29992;&#20110;&#25351;&#23548;&#35843;&#20248;&#65292;&#21253;&#25324;&#38024;&#23545;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#40065;&#26834;&#30340;&#24191;&#20041;&#21518;&#39564;&#12290;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#32467;&#26524;&#21644;&#24314;&#35758;&#22312;&#23454;&#38469;&#26377;&#38480;&#26679;&#26412;&#24773;&#20917;&#19979;&#30340;&#26377;&#25928;&#24615;&#12290;&#36825;&#20123;&#25104;&#26524;&#20026;&#20998;&#26512;&#20854;&#20182;&#38543;&#26426;&#26799;&#24230;Markov Chain Monte Carlo&#31639;&#27861;&#25552;&#20379;&#20102;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#20248;&#21270;&#21644;&#25277;&#26679;&#30340;&#38543;&#26426;&#26799;&#24230;&#31639;&#27861;&#65288;SGA&#65289;&#30340;&#35843;&#20248;&#36890;&#24120;&#22522;&#20110;&#35797;&#38169;&#21644;&#21551;&#21457;&#24335;&#26041;&#27861;&#65292;&#32780;&#19981;&#26159;&#21487;&#25512;&#24191;&#30340;&#29702;&#35770;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#31181;&#32852;&#21512;&#27493;&#38271;-&#26679;&#26412;&#22823;&#23567;&#32553;&#25918;&#26497;&#38480;&#26469;&#34920;&#24449;SGA&#30340;&#22823;&#26679;&#26412;&#32479;&#35745;&#28176;&#36817;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20351;&#29992;&#22266;&#23450;&#30340;&#22823;&#27493;&#38271;&#36827;&#34892;&#36845;&#20195;&#24179;&#22343;&#26159;&#23545;&#35843;&#20248;&#21442;&#25968;&#36873;&#25321;&#40065;&#26834;&#30340;&#65292;&#24182;&#19988;&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#65292;&#20855;&#26377;&#21644;MLE&#25277;&#26679;&#20998;&#24067;&#21327;&#26041;&#24046;&#25104;&#27604;&#20363;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#19968;&#31181;&#31867;&#20284;&#20110;Bernstein-von Mises&#30340;&#23450;&#29702;&#20197;&#25351;&#23548;&#35843;&#20248;&#65292;&#21253;&#25324;&#38024;&#23545;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#40065;&#26834;&#30340;&#24191;&#20041;&#21518;&#39564;&#12290;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#22312;&#23454;&#38469;&#26377;&#38480;&#26679;&#26412;&#33539;&#22260;&#20869;&#30340;&#32467;&#26524;&#21644;&#24314;&#35758;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#20026;&#22823;&#33539;&#22260;&#27169;&#22411;&#30340;&#20854;&#20182;&#38543;&#26426;&#26799;&#24230;Markov Chain Monte Carlo&#31639;&#27861;&#30340;&#31995;&#32479;&#20998;&#26512;&#22880;&#23450;&#20102;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
The tuning of stochastic gradient algorithms (SGAs) for optimization and sampling is often based on heuristics and trial-and-error rather than generalizable theory. We address this theory--practice gap by characterizing the large-sample statistical asymptotics of SGAs via a joint step-size--sample-size scaling limit. We show that iterate averaging with a large fixed step size is robust to the choice of tuning parameters and asymptotically has covariance proportional to that of the MLE sampling distribution. We also prove a Bernstein--von Mises-like theorem to guide tuning, including for generalized posteriors that are robust to model misspecification. Numerical experiments validate our results and recommendations in realistic finite-sample regimes. Our work lays the foundation for a systematic analysis of other stochastic gradient Markov chain Monte Carlo algorithms for a wide range of models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#22312;&#32447;&#24615;MDPs&#20013;&#30340;&#24212;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;\textsc{Pedel}&#65292;&#35813;&#31639;&#27861;&#22312;RL&#20013;&#30340;&#20989;&#25968;&#36924;&#36817;&#35774;&#32622;&#19979;&#23454;&#29616;&#20102;&#32454;&#31890;&#24230;&#30340;&#20381;&#36182;&#20110;&#23454;&#20363;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#30456;&#23545;&#20110;&#26368;&#20302;&#36951;&#25022;&#12289;&#26368;&#23567;&#26368;&#22823;&#26368;&#20248;&#31639;&#27861;&#20855;&#26377;&#26126;&#26174;&#25910;&#30410;&#12290;</title><link>http://arxiv.org/abs/2207.02575</link><description>&lt;p&gt;
&#22522;&#20110;&#22312;&#32447;&#23454;&#39564;&#35774;&#35745;&#30340;&#32447;&#24615;MDPs&#20013;&#30340;&#20381;&#36182;&#20110;&#23454;&#20363;&#30340;&#36817;&#26368;&#20248;&#31574;&#30053;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Instance-Dependent Near-Optimal Policy Identification in Linear MDPs via Online Experiment Design. (arXiv:2207.02575v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.02575
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#22312;&#32447;&#24615;MDPs&#20013;&#30340;&#24212;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;\textsc{Pedel}&#65292;&#35813;&#31639;&#27861;&#22312;RL&#20013;&#30340;&#20989;&#25968;&#36924;&#36817;&#35774;&#32622;&#19979;&#23454;&#29616;&#20102;&#32454;&#31890;&#24230;&#30340;&#20381;&#36182;&#20110;&#23454;&#20363;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#30456;&#23545;&#20110;&#26368;&#20302;&#36951;&#25022;&#12289;&#26368;&#23567;&#26368;&#22823;&#26368;&#20248;&#31639;&#27861;&#20855;&#26377;&#26126;&#26174;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#34429;&#28982;&#23545;&#20110;&#26368;&#22351;&#24773;&#20917;&#23454;&#20363;&#19979;&#30340;&#26368;&#23567;&#26368;&#22823;&#26679;&#26412;&#22797;&#26434;&#24230;&#26377;&#20102;&#24456;&#22823;&#30340;&#36827;&#23637;&#65292;&#20294;&#26159;&#36825;&#31181;&#22797;&#26434;&#24230;&#34913;&#37327;&#24448;&#24448;&#19981;&#33021;&#30495;&#27491;&#21453;&#26144;&#20986;&#23398;&#20064;&#30340;&#30495;&#27491;&#22256;&#38590;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#23545;&#20110;&#19968;&#20010;&#8220;&#31616;&#21333;&#8221;&#30340;&#23454;&#20363;&#65292;&#25105;&#20204;&#21487;&#33021;&#24076;&#26395;&#33021;&#22815;&#23454;&#29616;&#27604;&#26368;&#22351;&#23454;&#20363;&#19979;&#26356;&#22909;&#30340;&#22797;&#26434;&#24230;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24076;&#26395;&#20102;&#35299;&#22312;&#20855;&#26377;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;&#24378;&#21270;&#23398;&#20064;&#35774;&#32622;&#20013;&#65292;&#23398;&#20064;&#36817;&#26368;&#20248;&#31574;&#30053;&#65288;PAC RL&#65289;&#30340;&#8220;&#20381;&#36182;&#20110;&#23454;&#20363;&#8221;&#30340;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;\textsc{Pedel}&#65292;&#23427;&#23454;&#29616;&#20102;&#19968;&#31181;&#32454;&#31890;&#24230;&#30340;&#20381;&#36182;&#20110;&#23454;&#20363;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#36825;&#26159;&#22312;&#20989;&#25968;&#36924;&#36817;&#35774;&#32622;&#20013;&#39318;&#27425;&#20986;&#29616;&#30340;&#65292;&#20174;&#32780;&#25429;&#25417;&#20102;&#22312;&#27599;&#20010;&#29305;&#23450;&#38382;&#39064;&#23454;&#20363;&#19978;&#23398;&#20064;&#30340;&#22256;&#38590;&#31243;&#24230;&#12290;&#36890;&#36807;&#19968;&#20010;&#20855;&#20307;&#30340;&#20363;&#23376;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;\textsc{Pedel}&#30456;&#23545;&#20110;&#26368;&#20302;&#36951;&#25022;&#12289;&#26368;&#23567;&#26368;&#22823;&#26368;&#20248;&#31639;&#27861;&#30340;&#21487;&#35777;&#26126;&#25910;&#30410;&#65292;&#24182;&#19988;&#36825;&#20123;&#31639;&#27861;&#26080;&#27861;&#36798;&#21040;&#36825;&#31181;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
While much progress has been made in understanding the minimax sample complexity of reinforcement learning (RL) -- the complexity of learning on the "worst-case" instance -- such measures of complexity often do not capture the true difficulty of learning. In practice, on an "easy" instance, we might hope to achieve a complexity far better than that achievable on the worst-case instance. In this work we seek to understand the "instance-dependent" complexity of learning near-optimal policies (PAC RL) in the setting of RL with linear function approximation. We propose an algorithm, \textsc{Pedel}, which achieves a fine-grained instance-dependent measure of complexity, the first of its kind in the RL with function approximation setting, thereby capturing the difficulty of learning on each particular problem instance. Through an explicit example, we show that \textsc{Pedel} yields provable gains over low-regret, minimax-optimal algorithms and that such algorithms are unable to hit the insta
&lt;/p&gt;</description></item><item><title>Pythae&#26159;&#19968;&#20010;&#24320;&#28304;Python&#24211;&#65292;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#29983;&#25104;&#33258;&#32534;&#30721;&#22120;&#27169;&#22411;&#23454;&#29616;&#21644;&#26694;&#26550;&#65292;&#21487;&#29992;&#20110;&#36827;&#34892;&#22810;&#31181;&#20219;&#21153;&#30340;&#26696;&#20363;&#30740;&#31350;&#22522;&#20934;&#27979;&#35797;&#12290;</title><link>http://arxiv.org/abs/2206.08309</link><description>&lt;p&gt;
Pythae&#65306;&#32479;&#19968;&#30340;&#29983;&#25104;&#33258;&#32534;&#30721;&#22120;Python&#24211;&#8212;&#8212;&#22522;&#20934;&#27979;&#35797;&#29992;&#20363;
&lt;/p&gt;
&lt;p&gt;
Pythae: Unifying Generative Autoencoders in Python -- A Benchmarking Use Case. (arXiv:2206.08309v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.08309
&lt;/p&gt;
&lt;p&gt;
Pythae&#26159;&#19968;&#20010;&#24320;&#28304;Python&#24211;&#65292;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#29983;&#25104;&#33258;&#32534;&#30721;&#22120;&#27169;&#22411;&#23454;&#29616;&#21644;&#26694;&#26550;&#65292;&#21487;&#29992;&#20110;&#36827;&#34892;&#22810;&#31181;&#20219;&#21153;&#30340;&#26696;&#20363;&#30740;&#31350;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#22240;&#20854;&#23545;&#22797;&#26434;&#20998;&#24067;&#30340;&#24314;&#27169;&#33021;&#21147;&#32780;&#24341;&#36215;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#22312;&#36825;&#20123;&#27169;&#22411;&#20013;&#65292;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#22240;&#20854;&#22312;&#35745;&#31639;&#19978;&#30340;&#39640;&#25928;&#24615;&#21644;&#22312;&#22810;&#20010;&#39046;&#22495;&#20013;&#20135;&#29983;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#32467;&#26524;&#32780;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#12290;&#22312;&#36825;&#19968;&#31361;&#30772;&#20043;&#21518;&#65292;&#20026;&#20102;&#25913;&#36827;&#21407;&#22987;&#35770;&#25991;&#24050;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#30740;&#31350;&#24037;&#20316;&#65292;&#23548;&#33268;&#20102;&#21508;&#31181;&#19981;&#21516;&#30340;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#27169;&#22411;&#20197;&#24212;&#23545;&#19981;&#21516;&#30340;&#20219;&#21153;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;Pythae&#65292;&#19968;&#20010;&#36890;&#29992;&#30340;&#24320;&#28304;Python&#24211;&#65292;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#23454;&#29616;&#21644;&#19987;&#38376;&#30340;&#26694;&#26550;&#65292;&#21487;&#26041;&#20415;&#12289;&#21487;&#37325;&#29616;&#12289;&#21487;&#38752;&#22320;&#20351;&#29992;&#29983;&#25104;&#33258;&#32534;&#30721;&#22120;&#27169;&#22411;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#35813;&#24211;&#36827;&#34892;&#26696;&#20363;&#30740;&#31350;&#22522;&#20934;&#27979;&#35797;&#65292;&#22312;&#20854;&#20013;&#23637;&#31034;&#24182;&#27604;&#36739;&#20102;19&#20010;&#29983;&#25104;&#33258;&#32534;&#30721;&#22120;&#27169;&#22411;&#65292;&#36825;&#20123;&#27169;&#22411;&#20195;&#34920;&#20102;&#22312;&#22270;&#20687;&#37325;&#26500;&#12289;&#29983;&#25104;&#12289;&#20998;&#31867;&#12289;&#32858;&#31867;&#21644;&#25554;&#20540;&#31561;&#19979;&#28216;&#20219;&#21153;&#19978;&#30340;&#19968;&#20123;&#20027;&#35201;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, deep generative models have attracted increasing interest due to their capacity to model complex distributions. Among those models, variational autoencoders have gained popularity as they have proven both to be computationally efficient and yield impressive results in multiple fields. Following this breakthrough, extensive research has been done in order to improve the original publication, resulting in a variety of different VAE models in response to different tasks. In this paper we present Pythae, a versatile open-source Python library providing both a unified implementation and a dedicated framework allowing straightforward, reproducible and reliable use of generative autoencoder models. We then propose to use this library to perform a case study benchmark where we present and compare 19 generative autoencoder models representative of some of the main improvements on downstream tasks such as image reconstruction, generation, classification, clustering and interpola
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#39044;&#20808;&#35757;&#32451;&#30340;&#24863;&#30693;&#29305;&#24449;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;MMD&#65288;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65289;&#26469;&#25552;&#39640;&#24046;&#20998;&#38544;&#31169;&#22270;&#20687;&#29983;&#25104;&#30340;&#24615;&#33021;&#65292;&#24182;&#25104;&#21151;&#22320;&#29983;&#25104;&#20102;CIFAR10&#32423;&#21035;&#30340;&#22270;&#20687;&#12290;</title><link>http://arxiv.org/abs/2205.12900</link><description>&lt;p&gt;
&#39044;&#20808;&#35757;&#32451;&#30340;&#24863;&#30693;&#29305;&#24449;&#25552;&#39640;&#24046;&#20998;&#38544;&#31169;&#22270;&#20687;&#29983;&#25104;&#30340;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Pre-trained Perceptual Features Improve Differentially Private Image Generation. (arXiv:2205.12900v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.12900
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#39044;&#20808;&#35757;&#32451;&#30340;&#24863;&#30693;&#29305;&#24449;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;MMD&#65288;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65289;&#26469;&#25552;&#39640;&#24046;&#20998;&#38544;&#31169;&#22270;&#20687;&#29983;&#25104;&#30340;&#24615;&#33021;&#65292;&#24182;&#25104;&#21151;&#22320;&#29983;&#25104;&#20102;CIFAR10&#32423;&#21035;&#30340;&#22270;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;DP-SGD&#65289;&#36827;&#34892;&#20013;&#31561;&#35268;&#27169;&#29983;&#25104;&#27169;&#22411;&#30340;&#35757;&#32451;&#38750;&#24120;&#22256;&#38590;&#65306;&#20026;&#20102;&#20445;&#25345;&#21512;&#29702;&#30340;&#38544;&#31169;&#27700;&#24179;&#25152;&#38656;&#30340;&#22122;&#22768;&#27700;&#24179;&#36807;&#22823;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#24314;&#35758;&#21033;&#29992;&#20449;&#24687;&#20016;&#23500;&#30340;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#30340;&#33391;&#22909;&#30456;&#20851;&#34920;&#24449;&#65292;&#28982;&#21518;&#23398;&#20064;&#20351;&#29992;&#35813;&#34920;&#24449;&#27169;&#22411;&#21270;&#31169;&#26377;&#25968;&#25454;&#12290;&#29305;&#21035;&#30340;&#65292;&#25105;&#20204;&#20351;&#29992;&#20174;&#20844;&#20849;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#30340;&#24863;&#30693;&#29305;&#24449;&#30340;&#26680;&#20989;&#25968;&#65292;&#26368;&#23567;&#21270;&#31169;&#26377;&#30446;&#26631;&#25968;&#25454;&#19982;&#29983;&#25104;&#22120;&#20998;&#24067;&#20043;&#38388;&#30340;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65288;MMD&#65289;&#12290;&#20351;&#29992;MMD&#65292;&#25105;&#20204;&#21487;&#20197;&#19968;&#27425;&#24615;&#23545;&#25968;&#25454;&#30456;&#20851;&#39033;&#36827;&#34892;&#38544;&#31169;&#22788;&#29702;&#65292;&#32780;&#26080;&#38656;&#20687;DP-SGD&#19968;&#26679;&#22312;&#20248;&#21270;&#27599;&#19968;&#27493;&#20013;&#24341;&#20837;&#22122;&#22768;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20351;&#25105;&#20204;&#33021;&#22815;&#29983;&#25104;CIFAR10&#32423;&#21035;&#30340;&#22270;&#20687;&#65292;&#20854; $\epsilon \approx 2$&#65292;&#25429;&#25417;&#20102;&#20998;&#24067;&#20013;&#30340;&#29420;&#29305;&#29305;&#24449;&#65292;&#36828;&#36828;&#36229;&#36807;&#24403;&#21069;&#30340;&#25216;&#26415;&#27700;&#24179;&#65292;&#20027;&#35201;&#38598;&#20013;&#20110;&#25968;&#25454;&#38598;&#65292;&#22914;MNIST&#21644;FashionMNIST &#20197;&#36739;&#22823;&#30340; $\epsilon$&#12290;
&lt;/p&gt;
&lt;p&gt;
Training even moderately-sized generative models with differentially-private stochastic gradient descent (DP-SGD) is difficult: the required level of noise for reasonable levels of privacy is simply too large. We advocate instead building off a good, relevant representation on an informative public dataset, then learning to model the private data with that representation. In particular, we minimize the maximum mean discrepancy (MMD) between private target data and a generator's distribution, using a kernel based on perceptual features learned from a public dataset. With the MMD, we can simply privatize the data-dependent term once and for all, rather than introducing noise at each step of optimization as in DP-SGD. Our algorithm allows us to generate CIFAR10-level images with $\epsilon \approx 2$ which capture distinctive features in the distribution, far surpassing the current state of the art, which mostly focuses on datasets such as MNIST and FashionMNIST at a large $\epsilon \appro
&lt;/p&gt;</description></item><item><title>&#28145;&#24230;&#35777;&#25454;&#22238;&#24402;&#26159;&#19968;&#31181;&#36890;&#36807;&#23398;&#20064;&#35777;&#25454;&#20998;&#24067;&#26469;&#22788;&#29702;&#19981;&#30830;&#23450;&#24615;&#30340;&#26041;&#27861;&#65292;&#22312;&#19981;&#30830;&#23450;&#24615;&#25512;&#29702;&#20013;&#26174;&#31034;&#20986;&#30456;&#23545;&#20110;&#20256;&#32479;&#26041;&#27861;&#21644;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21183;&#12290;&#28982;&#32780;&#65292;&#23427;&#24182;&#38750;&#31934;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#32780;&#26159;&#19968;&#31181;&#21551;&#21457;&#24335;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2205.10060</link><description>&lt;p&gt;
&#28145;&#24230;&#35777;&#25454;&#22238;&#24402;&#30340;&#19981;&#21512;&#29702;&#26377;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;
The Unreasonable Effectiveness of Deep Evidential Regression. (arXiv:2205.10060v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.10060
&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#35777;&#25454;&#22238;&#24402;&#26159;&#19968;&#31181;&#36890;&#36807;&#23398;&#20064;&#35777;&#25454;&#20998;&#24067;&#26469;&#22788;&#29702;&#19981;&#30830;&#23450;&#24615;&#30340;&#26041;&#27861;&#65292;&#22312;&#19981;&#30830;&#23450;&#24615;&#25512;&#29702;&#20013;&#26174;&#31034;&#20986;&#30456;&#23545;&#20110;&#20256;&#32479;&#26041;&#27861;&#21644;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21183;&#12290;&#28982;&#32780;&#65292;&#23427;&#24182;&#38750;&#31934;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#32780;&#26159;&#19968;&#31181;&#21551;&#21457;&#24335;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#22312;&#23433;&#20840;&#20851;&#38190;&#39046;&#22495;&#30340;&#19981;&#26029;&#37096;&#32626;&#65292;&#23545;&#20110;&#22522;&#20110;&#21407;&#21017;&#30340;&#19981;&#30830;&#23450;&#24615;&#25512;&#29702;&#30340;&#38656;&#27714;&#26085;&#30410;&#36843;&#20999;&#12290;&#19968;&#31181;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#22238;&#24402;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#20851;&#20110;&#20869;&#37096;&#21464;&#37327;&#21644;&#22806;&#37096;&#21464;&#37327;&#30340;&#19981;&#30830;&#23450;&#24615;&#30340;&#35777;&#25454;&#20998;&#24067;&#65292;&#26174;&#31034;&#20986;&#30456;&#23545;&#20110;&#20256;&#32479;&#30830;&#23450;&#24615;&#26041;&#27861;&#21644;&#20856;&#22411;&#36125;&#21494;&#26031;NN&#30340;&#20248;&#21183;&#65292;&#23588;&#20854;&#22312;&#33021;&#22815;&#35299;&#32806;&#20869;&#37096;&#21644;&#22806;&#37096;&#19981;&#30830;&#23450;&#24615;&#26041;&#38754;&#12290;&#23613;&#31649;&#28145;&#24230;&#35777;&#25454;&#22238;&#24402;&#65288;DER&#65289;&#21462;&#24471;&#20102;&#19968;&#23450;&#30340;&#23454;&#35777;&#25104;&#21151;&#65292;&#20294;&#25968;&#23398;&#22522;&#30784;&#23384;&#22312;&#37325;&#35201;&#30340;&#19981;&#36275;&#65292;&#36825;&#24341;&#21457;&#20102;&#20026;&#20309;&#25152;&#25552;&#20986;&#30340;&#25216;&#26415;&#30475;&#20284;&#26377;&#25928;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#35814;&#32454;&#35828;&#26126;&#20102;&#29702;&#35770;&#19978;&#30340;&#19981;&#36275;&#65292;&#24182;&#20998;&#26512;&#20102;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#65292;&#34920;&#26126;&#28145;&#24230;&#35777;&#25454;&#22238;&#24402;&#26159;&#19968;&#31181;&#21551;&#21457;&#24335;&#32780;&#38750;&#31934;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#12290;&#25105;&#20204;&#32487;&#32493;&#35752;&#35770;&#22914;&#20309;&#20462;&#27491;&#21644;&#37325;&#26032;&#23450;&#20041;&#20869;&#37096;&#21644;&#22806;&#37096;&#19981;&#30830;&#23450;&#24615;&#30340;&#25552;&#21462;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is a significant need for principled uncertainty reasoning in machine learning systems as they are increasingly deployed in safety-critical domains. A new approach with uncertainty-aware regression-based neural networks (NNs), based on learning evidential distributions for aleatoric and epistemic uncertainties, shows promise over traditional deterministic methods and typical Bayesian NNs, notably with the capabilities to disentangle aleatoric and epistemic uncertainties. Despite some empirical success of Deep Evidential Regression (DER), there are important gaps in the mathematical foundation that raise the question of why the proposed technique seemingly works. We detail the theoretical shortcomings and analyze the performance on synthetic and real-world data sets, showing that Deep Evidential Regression is a heuristic rather than an exact uncertainty quantification. We go on to discuss corrections and redefinitions of how aleatoric and epistemic uncertainties should be extracte
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#23725;&#22238;&#24402;&#30340;&#31616;&#21333;&#38750;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#20272;&#35745;&#20171;&#23548;&#21644;&#26102;&#21464;&#21058;&#37327;&#21709;&#24212;&#26354;&#32447;&#12290;&#36890;&#36807;&#24341;&#20837;&#24207;&#36143;&#26680;&#23884;&#20837;&#25216;&#26415;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#23545;&#22797;&#26434;&#22240;&#26524;&#20272;&#35745;&#30340;&#31616;&#21270;&#12290;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#21644;&#30495;&#23454;&#25968;&#25454;&#30340;&#20272;&#35745;&#32467;&#26524;&#65292;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#24378;&#22823;&#24615;&#33021;&#21644;&#26222;&#36866;&#24615;&#12290;</title><link>http://arxiv.org/abs/2111.03950</link><description>&lt;p&gt;
&#24207;&#36143;&#26680;&#23884;&#20837;&#29992;&#20110;&#20171;&#23548;&#21644;&#26102;&#21464;&#21058;&#37327;&#21709;&#24212;&#26354;&#32447;
&lt;/p&gt;
&lt;p&gt;
Sequential Kernel Embedding for Mediated and Time-Varying Dose Response Curves. (arXiv:2111.03950v4 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.03950
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#23725;&#22238;&#24402;&#30340;&#31616;&#21333;&#38750;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#20272;&#35745;&#20171;&#23548;&#21644;&#26102;&#21464;&#21058;&#37327;&#21709;&#24212;&#26354;&#32447;&#12290;&#36890;&#36807;&#24341;&#20837;&#24207;&#36143;&#26680;&#23884;&#20837;&#25216;&#26415;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#23545;&#22797;&#26434;&#22240;&#26524;&#20272;&#35745;&#30340;&#31616;&#21270;&#12290;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#21644;&#30495;&#23454;&#25968;&#25454;&#30340;&#20272;&#35745;&#32467;&#26524;&#65292;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#24378;&#22823;&#24615;&#33021;&#21644;&#26222;&#36866;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#26680;&#23725;&#22238;&#24402;&#30340;&#20171;&#23548;&#21644;&#26102;&#21464;&#21058;&#37327;&#21709;&#24212;&#26354;&#32447;&#30340;&#31616;&#21333;&#38750;&#21442;&#25968;&#20272;&#35745;&#22120;&#12290;&#36890;&#36807;&#23884;&#20837;Pearl&#30340;&#20171;&#23548;&#20844;&#24335;&#21644;Robins&#30340;g&#20844;&#24335;&#19982;&#26680;&#20989;&#25968;&#65292;&#25105;&#20204;&#20801;&#35768;&#22788;&#29702;&#12289;&#20171;&#23548;&#32773;&#21644;&#21327;&#21464;&#37327;&#22312;&#19968;&#33324;&#31354;&#38388;&#20013;&#36830;&#32493;&#21464;&#21270;&#65292;&#20063;&#20801;&#35768;&#38750;&#32447;&#24615;&#30340;&#22788;&#29702;-&#28151;&#28102;&#22240;&#32032;&#21453;&#39304;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#21019;&#26032;&#26159;&#19968;&#31181;&#31216;&#20026;&#24207;&#36143;&#26680;&#23884;&#20837;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#25216;&#26415;&#65292;&#25105;&#20204;&#20351;&#29992;&#23427;&#26469;&#26500;&#24314;&#22797;&#26434;&#22240;&#26524;&#20272;&#35745;&#30340;&#31616;&#21333;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#20445;&#30041;&#20102;&#32463;&#20856;&#35782;&#21035;&#30340;&#26222;&#36866;&#24615;&#65292;&#21516;&#26102;&#23454;&#29616;&#20102;&#38750;&#28176;&#36827;&#22343;&#21248;&#25910;&#25947;&#36895;&#24230;&#12290;&#22312;&#20855;&#26377;&#35768;&#22810;&#21327;&#21464;&#37327;&#30340;&#38750;&#32447;&#24615;&#27169;&#25311;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#24378;&#22823;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#20272;&#35745;&#20102;&#32654;&#22269;&#32844;&#19994;&#35757;&#32451;&#22242;&#30340;&#20171;&#23548;&#21644;&#26102;&#21464;&#21058;&#37327;&#21709;&#24212;&#26354;&#32447;&#65292;&#24182;&#28165;&#27905;&#21487;&#33021;&#25104;&#20026;&#26410;&#26469;&#24037;&#20316;&#22522;&#20934;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#32467;&#26524;&#25512;&#24191;&#21040;&#20171;&#23548;&#21644;&#26102;&#21464;&#22788;&#29702;&#25928;&#24212;&#20197;&#21450;&#21453;&#20107;&#23454;&#20998;&#24067;&#65292;&#39564;&#35777;&#20102;&#21322;&#21442;&#25968;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose simple nonparametric estimators for mediated and time-varying dose response curves based on kernel ridge regression. By embedding Pearl's mediation formula and Robins' g-formula with kernels, we allow treatments, mediators, and covariates to be continuous in general spaces, and also allow for nonlinear treatment-confounder feedback. Our key innovation is a reproducing kernel Hilbert space technique called sequential kernel embedding, which we use to construct simple estimators for complex causal estimands. Our estimators preserve the generality of classic identification while also achieving nonasymptotic uniform rates. In nonlinear simulations with many covariates, we demonstrate strong performance. We estimate mediated and time-varying dose response curves of the US Job Corps, and clean data that may serve as a benchmark in future work. We extend our results to mediated and time-varying treatment effects and counterfactual distributions, verifying semiparametric efficiency 
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#32972;&#26223;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65288;ACB&#65289;&#65292;&#21487;&#20197;&#22312;&#19981;&#30693;&#36947;&#30495;&#23454;&#27169;&#22411;&#31867;&#21035;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#24182;&#19988;&#20855;&#26377;&#19982;&#24050;&#30693;&#27169;&#22411;&#31867;&#21035;&#31639;&#27861;&#30456;&#21305;&#37197;&#30340;&#36951;&#25022;&#29575;&#12290;&#27169;&#22411;&#36873;&#25321;&#30340;&#20195;&#20215;&#20165;&#23545;&#36951;&#25022;&#19978;&#30028;&#30340;&#20108;&#38454;&#39033;&#26377;&#36129;&#29486;&#65292;&#19988;&#20855;&#26377;&#30452;&#35266;&#30340;&#23646;&#24615;&#12290;</title><link>http://arxiv.org/abs/2107.03455</link><description>&lt;p&gt;
&#36890;&#29992;&#32972;&#26223;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Model Selection for Generic Contextual Bandits. (arXiv:2107.03455v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.03455
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#32972;&#26223;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65288;ACB&#65289;&#65292;&#21487;&#20197;&#22312;&#19981;&#30693;&#36947;&#30495;&#23454;&#27169;&#22411;&#31867;&#21035;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#24182;&#19988;&#20855;&#26377;&#19982;&#24050;&#30693;&#27169;&#22411;&#31867;&#21035;&#31639;&#27861;&#30456;&#21305;&#37197;&#30340;&#36951;&#25022;&#29575;&#12290;&#27169;&#22411;&#36873;&#25321;&#30340;&#20195;&#20215;&#20165;&#23545;&#36951;&#25022;&#19978;&#30028;&#30340;&#20108;&#38454;&#39033;&#26377;&#36129;&#29486;&#65292;&#19988;&#20855;&#26377;&#30452;&#35266;&#30340;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#21487;&#23454;&#29616;&#24615;&#20551;&#35774;&#19979;&#30340;&#36890;&#29992;&#38543;&#26426;&#32972;&#26223;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#33258;&#36866;&#24212;&#32972;&#26223;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#65288;ACB&#65289;&#30340;&#22522;&#20110;&#36830;&#32493;&#31934;&#28860;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20998;&#20026;&#22810;&#20010;&#38454;&#27573;&#65292;&#36880;&#27493;&#28040;&#38500;&#37027;&#20123;&#23545;&#32473;&#23450;&#23454;&#20363;&#26469;&#35828;&#36807;&#20110;&#31616;&#21333;&#30340;&#27169;&#22411;&#31867;&#21035;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#26159;&#33258;&#36866;&#24212;&#30340;&#65292;&#21363;&#22312;&#20219;&#20309;&#21487;&#35777;&#26126;&#30340;&#32972;&#26223;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65288;&#20363;&#22914;\cite{falcon}&#65289;&#30340;&#36951;&#25022;&#29575;&#19982;&#39034;&#24207;&#19968;&#33268;&#21305;&#37197;&#65292;&#21069;&#25552;&#26159;&#38656;&#35201;&#30693;&#36947;&#30495;&#23454;&#30340;&#27169;&#22411;&#31867;&#21035;&#12290;&#19981;&#30693;&#36947;&#27491;&#30830;&#30340;&#27169;&#22411;&#31867;&#21035;&#30340;&#20195;&#20215;&#23454;&#38469;&#19978;&#21482;&#26159;&#23548;&#33268;&#36951;&#25022;&#19978;&#30028;&#20013;&#30340;&#20108;&#38454;&#39033;&#30340;&#38468;&#21152;&#39033;&#12290;&#36825;&#20010;&#20195;&#20215;&#20855;&#26377;&#30452;&#35266;&#30340;&#23646;&#24615;&#65292;&#24403;&#27169;&#22411;&#31867;&#21035;&#21464;&#24471;&#26356;&#23481;&#26131;&#35782;&#21035;&#26102;&#65292;&#23427;&#21464;&#23567;&#65292;&#21453;&#20043;&#20134;&#28982;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#19968;&#31181;&#26356;&#31616;&#21333;&#30340;&#25506;&#32034;-&#21033;&#29992;&#65288;ETC&#65289;&#39118;&#26684;&#30340;&#31639;&#27861;&#20063;&#33021;&#33719;&#24471;&#31867;&#20284;&#30340;&#36951;&#25022;&#19978;&#30028;&#65292;&#23613;&#31649;&#19981;&#30693;&#36947;&#30495;&#23454;&#30340;&#27169;&#22411;&#31867;&#21035;&#12290;&#28982;&#32780;&#65292;&#27169;&#22411;&#36873;&#25321;&#30340;&#20195;&#20215;&#26159;...
&lt;/p&gt;
&lt;p&gt;
We consider the problem of model selection for the general stochastic contextual bandits under the realizability assumption. We propose a successive refinement based algorithm called Adaptive Contextual Bandit ({\ttfamily ACB}), that works in phases and successively eliminates model classes that are too simple to fit the given instance. We prove that this algorithm is adaptive, i.e., the regret rate order-wise matches that of any provable contextual bandit algorithm (ex. \cite{falcon}), that needs the knowledge of the true model class. The price of not knowing the correct model class turns out to be only an additive term contributing to the second order term in the regret bound. This cost possess the intuitive property that it becomes smaller as the model class becomes easier to identify, and vice-versa. We also show that a much simpler explore-then-commit (ETC) style algorithm also obtains similar regret bound, despite not knowing the true model class. However, the cost of model selec
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20013;&#20301;&#25968;&#27714;&#21644;&#21407;&#21017;&#30340;PCA&#26041;&#27861;&#65292;&#31216;&#20026;&#20013;&#20301;&#25968;&#27714;&#21644;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;MoMPCA&#65289;&#65292;&#20197;&#24212;&#23545;&#24322;&#24120;&#20540;&#23545;PCA&#30340;&#24433;&#21709;&#65292;&#24182;&#22312;&#26368;&#23567;&#20551;&#35774;&#26465;&#20214;&#19979;&#23454;&#29616;&#20102;&#26368;&#20248;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2102.03403</link><description>&lt;p&gt;
&#40065;&#26834;&#20027;&#25104;&#20998;&#20998;&#26512;&#65306;&#19968;&#31181;&#20013;&#20301;&#25968;&#27714;&#21644;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Robust Principal Component Analysis: A Median of Means Approach. (arXiv:2102.03403v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.03403
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20013;&#20301;&#25968;&#27714;&#21644;&#21407;&#21017;&#30340;PCA&#26041;&#27861;&#65292;&#31216;&#20026;&#20013;&#20301;&#25968;&#27714;&#21644;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;MoMPCA&#65289;&#65292;&#20197;&#24212;&#23545;&#24322;&#24120;&#20540;&#23545;PCA&#30340;&#24433;&#21709;&#65292;&#24182;&#22312;&#26368;&#23567;&#20551;&#35774;&#26465;&#20214;&#19979;&#23454;&#29616;&#20102;&#26368;&#20248;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#26159;&#25968;&#25454;&#21487;&#35270;&#21270;&#12289;&#21435;&#22122;&#21644;&#38477;&#32500;&#30340;&#22522;&#26412;&#24037;&#20855;&#12290;&#23427;&#22312;&#32479;&#35745;&#23398;&#12289;&#26426;&#22120;&#23398;&#20064;&#12289;&#35745;&#31639;&#26426;&#35270;&#35273;&#31561;&#39046;&#22495;&#24191;&#27867;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;PCA&#23481;&#26131;&#21463;&#21040;&#24322;&#24120;&#20540;&#30340;&#24433;&#21709;&#65292;&#24448;&#24448;&#26080;&#27861;&#26816;&#27979;&#21040;&#25968;&#25454;&#38598;&#20013;&#30495;&#23454;&#30340;&#20302;&#32500;&#32467;&#26500;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20013;&#20301;&#25968;&#27714;&#21644;&#21407;&#21017;&#30340;PCA&#26041;&#27861;&#65292;&#31216;&#20026;&#20013;&#20301;&#25968;&#27714;&#21644;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;MoMPCA&#65289;&#12290;&#35813;&#26041;&#27861;&#19981;&#20165;&#22312;&#35745;&#31639;&#19978;&#20855;&#26377;&#21560;&#24341;&#21147;&#65292;&#32780;&#19988;&#22312;&#26368;&#23567;&#20551;&#35774;&#26465;&#20214;&#19979;&#23454;&#29616;&#20102;&#26368;&#20248;&#25910;&#25947;&#36895;&#24230;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#36890;&#36807;Rademacher&#22797;&#26434;&#24230;&#26469;&#25506;&#32034;&#25152;&#24471;&#35299;&#30340;&#38750;&#28176;&#36817;&#35823;&#24046;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Principal Component Analysis (PCA) is a fundamental tool for data visualization, denoising, and dimensionality reduction. It is widely popular in Statistics, Machine Learning, Computer Vision, and related fields. However, PCA is well-known to fall prey to outliers and often fails to detect the true underlying low-dimensional structure within the dataset. Following the Median of Means (MoM) philosophy, recent supervised learning methods have shown great success in dealing with outlying observations without much compromise to their large sample theoretical properties. This paper proposes a PCA procedure based on the MoM principle. Called the \textbf{M}edian of \textbf{M}eans \textbf{P}rincipal \textbf{C}omponent \textbf{A}nalysis (MoMPCA), the proposed method is not only computationally appealing but also achieves optimal convergence rates under minimal assumptions. In particular, we explore the non-asymptotic error bounds of the obtained solution via the aid of the Rademacher complexiti
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#38544;&#24335;&#20989;&#25968;&#23548;&#25968;&#30340;&#21487;&#35270;&#21270;&#26041;&#27861;&#65292;&#26088;&#22312;&#29702;&#35299;&#22810;&#32500;&#25237;&#24433;&#23545;&#23616;&#37096;&#23376;&#31354;&#38388;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#20998;&#26512;&#23616;&#37096;&#23376;&#31354;&#38388;&#30340;&#24418;&#29366;&#21644;&#26041;&#21521;&#20449;&#24687;&#65292;&#25105;&#20204;&#33021;&#22815;&#33719;&#21462;&#26356;&#22810;&#20851;&#20110;&#25968;&#25454;&#20840;&#23616;&#32467;&#26500;&#30340;&#27934;&#23519;&#21147;&#65292;&#24182;&#23558;&#32467;&#26524;&#21487;&#35270;&#21270;&#20026;&#22270;&#24418;&#36827;&#34892;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2009.03259</link><description>&lt;p&gt;
&#38544;&#24335;&#22810;&#32500;&#25237;&#24433;&#23616;&#37096;&#23376;&#31354;&#38388;&#30340;&#21487;&#35270;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Implicit Multidimensional Projection of Local Subspaces. (arXiv:2009.03259v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2009.03259
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#38544;&#24335;&#20989;&#25968;&#23548;&#25968;&#30340;&#21487;&#35270;&#21270;&#26041;&#27861;&#65292;&#26088;&#22312;&#29702;&#35299;&#22810;&#32500;&#25237;&#24433;&#23545;&#23616;&#37096;&#23376;&#31354;&#38388;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#20998;&#26512;&#23616;&#37096;&#23376;&#31354;&#38388;&#30340;&#24418;&#29366;&#21644;&#26041;&#21521;&#20449;&#24687;&#65292;&#25105;&#20204;&#33021;&#22815;&#33719;&#21462;&#26356;&#22810;&#20851;&#20110;&#25968;&#25454;&#20840;&#23616;&#32467;&#26500;&#30340;&#27934;&#23519;&#21147;&#65292;&#24182;&#23558;&#32467;&#26524;&#21487;&#35270;&#21270;&#20026;&#22270;&#24418;&#36827;&#34892;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#38544;&#24335;&#20989;&#25968;&#23548;&#25968;&#30340;&#21487;&#35270;&#21270;&#26041;&#27861;&#65292;&#26469;&#29702;&#35299;&#22810;&#32500;&#25237;&#24433;&#23545;&#23616;&#37096;&#23376;&#31354;&#38388;&#30340;&#24433;&#21709;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#23558;&#23616;&#37096;&#23376;&#31354;&#38388;&#29702;&#35299;&#20026;&#25968;&#25454;&#28857;&#30340;&#22810;&#32500;&#23616;&#37096;&#37051;&#22495;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#20027;&#35201;&#20851;&#27880;&#22810;&#32500;&#25968;&#25454;&#28857;&#30340;&#25237;&#24433;&#65292;&#24573;&#30053;&#20102;&#37051;&#22495;&#20449;&#24687;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#20998;&#26512;&#23616;&#37096;&#23376;&#31354;&#38388;&#30340;&#24418;&#29366;&#21644;&#26041;&#21521;&#20449;&#24687;&#65292;&#36890;&#36807;&#24863;&#30693;&#23616;&#37096;&#32467;&#26500;&#26469;&#33719;&#21462;&#26356;&#22810;&#26377;&#20851;&#25968;&#25454;&#20840;&#23616;&#32467;&#26500;&#30340;&#27934;&#23519;&#21147;&#12290;&#23616;&#37096;&#23376;&#31354;&#38388;&#36890;&#36807;&#30001;&#22522;&#21521;&#37327;&#24352;&#25104;&#30340;&#22810;&#32500;&#26925;&#22278;&#25311;&#21512;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20934;&#30830;&#39640;&#25928;&#30340;&#21521;&#37327;&#36716;&#25442;&#26041;&#27861;&#65292;&#22522;&#20110;&#23558;&#22810;&#32500;&#25237;&#24433;&#34920;&#31034;&#20026;&#38544;&#24335;&#20989;&#25968;&#30340;&#35299;&#26512;&#24494;&#20998;&#12290;&#32467;&#26524;&#20197;&#22270;&#24418;&#30340;&#24418;&#24335;&#36827;&#34892;&#21487;&#35270;&#21270;&#65292;&#24182;&#21033;&#29992;&#19968;&#22871;&#23436;&#25972;&#30340;&#19987;&#38376;&#35774;&#35745;&#30340;&#20132;&#20114;&#25805;&#20316;&#65292;&#22312;&#25105;&#20204;&#39640;&#25928;&#30340;&#22522;&#20110;Web&#30340;&#21487;&#35270;&#21270;&#24037;&#20855;&#20013;&#36827;&#34892;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness o
&lt;/p&gt;</description></item></channel></rss>